
Lecture Notes of the Institute
for Computer Sciences, Social Informatics
and Telecommunications Engineering
7
Editorial Board
Ozgur Akan
Middle East Technical University, Ankara, Turkey
Paolo Bellavista
University of Bologna, Italy
Jiannong Cao
Hong Kong Polytechnic University, Hong Kong
Falko Dressler
University of Erlangen, Germany
Domenico Ferrari
Università Cattolica Piacenza, Italy
Mario Gerla
UCLA, USA
Hisashi Kobayashi
Princeton University, USA
Sergio Palazzo
University of Catania, Italy
Sartaj Sahni
University of Florida, USA
Xuemin (Sherman) Shen
University of Waterloo, Canada
Mircea Stan
University of Virginia, USA
Jia Xiaohua
City University of Hong Kong, Hong Kong
Albert Zomaya
University of Sydney, Australia
Geoffrey Coulson
Lancaster University, UK

Jean-Marie Bonnin Carlo Giannelli
Thomas Magedanz (Eds.)
Mobile Wireless Middleware,
Operating Systems,
and Applications
Second International Conference, Mobilware 2009
Berlin, Germany, April 28-29, 2009
Proceedings
1 3

Volume Editors
Jean-Marie Bonnin
École Nationale Supérieure
des Télécommunications de Bretagne
BP 78 - 2, rue de la Châtaigneraie
35512 Cesson-Sévigné, France
E-mail: jm.bonnin@telecom-bretagne.fr
Carlo Giannelli
Università degli Studi di Bologna
Facoltà di Ingegneria DEIS
Viale Risorgimento 2
40136 Bologna, Italy
E-mail: carlo.giannelli@unibo.it
Thomas Magedanz
Technical University Berlin
Institute for Telecommunications Systems
Franklinstr. 28/29, 10587 Berlin, Germany
E-mail: tm@cs.tu-berlin.de
Library of Congress Control Number: Applied for
CR Subject Classiﬁcation (1998): C.2, H.3.4, G.2.2, I.2.9
ISSN
0302-9743
ISBN-10
3-642-01801-7 Springer Berlin Heidelberg New York
ISBN-13
978-3-642-01801-5 Springer Berlin Heidelberg New York
This work is subject to copyright. All rights are reserved, whether the whole or part of the material is
concerned, speciﬁcally the rights of translation, reprinting, re-use of illustrations, recitation, broadcasting,
reproduction on microﬁlms or in any other way, and storage in data banks. Duplication of this publication
or parts thereof is permitted only under the provisions of the German Copyright Law of September 9, 1965,
in its current version, and permission for use must always be obtained from Springer. Violations are liable
to prosecution under the German Copyright Law.
springer.com
© Springer-Verlag Berlin Heidelberg 2009
Printed in Germany
Typesetting: Camera-ready by author, data conversion by Scientiﬁc Publishing Services, Chennai, India
Printed on acid-free paper
SPIN: 12668786
06/3180
5 4 3 2 1 0

 
Preface 
The advances in wireless communication technologies and the proliferation of mobile 
devices have enabled the realization of intelligent environments for people to commu-
nicate with each other, interact with information-processing devices, and receive a 
wide range of mobile wireless services through various types of networks and systems 
everywhere, anytime. This «Internet of Things» will dramatically modify our lives 
allowing progress in various domains such as health, security, and ITS (intelligent 
transportation systems).  
A key enabler of this pervasive and ubiquitous connectivity environment is the ad-
vancement of software technology in various communication sectors, ranging from 
communication middleware and operating systems to networking protocols and appli-
cations. The international conference series on Mobile Wireless Middleware, Operat-
ing Systems, and Applications (MOBILWARE) is dedicated to addressing emerging 
topics and challenges in various mobile wireless software-related areas. The scope of 
the conference includes the design, implementation, deployment, and evaluation of 
middleware, operating systems, and applications for computing and communications 
in mobile wireless systems.  
MOBILWARE 2009 was the second edition of this conference, which was made 
possible thanks to the sponsorship of ICST and Create-Net and most importantly the 
hard work of the TPC and reviewers. 
Similar to the first successful edition we had 63 submissions from 20 different 
countries this year, reflecting the international interest in the conference topics. After a 
thorough review process, we finalized an excellent technical program including 29 
papers. These papers were grouped into eight technical sessions on: 
• 
Location and tracking supports and services 
• 
Location-aware and context-aware mobile support and services I 
• 
Location-aware and context-aware mobile support and services II 
• 
Middleware for QoS awareness, adaptation, and fault-tolerance of mobile 
services 
• 
Mobility-aware wireless service discovery, management, and delivery 
• 
Middleware for mobile computing and intelligent and mobile agent technolo-
gies for mobile systems and services 
• 
OS/middleware for embedded systems, wearable networks, and personal area 
networks 
• 
Mobility management and handoff management in heterogeneous networks 
We want to express our sincere gratitude to all the authors who submitted their pa-
pers to this conference and to all the reviewers whose accurate work was crucial for 
the finalization of this high-quality final technical program.  

 
Preface 
VI 
The MOBILWARE 2009 technical program also included two excellent keynote 
speeches, namely, “The Footprint of European R&D Programmes on Future Internet 
Developments” given by Franco Accordino, Scientific Officer, European Commis-
sion's Information Society and Media Directorate-General, and “Application Devel-
opment Platforms for Emerging Smart Environments” presented by Petri Liuha,  
Director, Embedded Systems Technology Initiatives at Nokia Research Center, 
Finland. We thank the keynote speakers for contributing to the quality and the success 
of this event. 
In addition, MOBILWARE 2009 featured two pre-conference tutorials, one on 
standards for delivering IPTV services in managed environments and one on the the-
ory and practice of porting mobile applications. 
Furthermore, we enhanced the overall program by four pre-conference workshops, 
namely: 
• 
Workshop on User-Centric Pervasive Adaptation (UCPA 2009) 
• 
Workshop on Interconnecting Ubiquitous Islands using Mobile and  
Next-Generation Networks (Ubi-Islands 2009) 
• 
Workshop on Business Models for New Mobile Platforms (BMMP 2009)  
• 
Workshop on Wireless Sensor Networks Architectures, Simulation and Pro-
gramming (WASP 2009) 
We express our deepest thanks to the tutorial speakers and all the workshop organ-
izers and most importantly Cristian Hesselman, the MOBILWARE 2009 Tutorial and 
Workshop Chair. 
Finally, we would like to thank Paolo Bellavista and Linda Xie, the General  
Co-chairs, for their constant motivation and support, as well as Gergely Nagy, the 
Conference Organization Chair, and Carlo Giannelli, the Publication and Web Chair, 
for helping in all the organizational matters. In addition, we like to thank the whole 
ICST team for their constant support in making this event happen. 
We hope you enjoy the proceedings, which provide a snapshot of the state of the art 
in mobile wireless middleware, operating systems, and applications. 
 
 
 
 
March 2009 
Jean-Marie Bonnin  
Thomas Magedanz 
Technical Program Co-Chairs, 
MOBILWARE 2009 
 
 
 
 

 
Organization 
Steering Committee 
Dr. Imrich Chlamtac (Chair) 
Create-Net, Italy 
Paolo Bellavista 
University of Bologna, Italy 
Carl K. Chang 
Iowa State University, USA 
General Co-chairs 
Paolo Bellavista 
University of Bologna, Italy 
Linda Xie 
University of North Carolina at Charlotte, USA 
Technical Program Committee Co-chairs 
Jean-Marie Bonnin 
ENST, France 
Thomas Magedanz 
Fraunhofer FOKUS, Germany 
Conference Organization Chair 
Gergely Nagy   
ICST 
Conference Publicity Co-chairs 
Europe: Andrej Krenker 
Sintesio, Slovenia 
North America: Jatinder pal Singh 
Stanford University, USA 
North America: Janise McNair 
University of Florida, USA 
South America: C. Esteve 
Rothenberg 
CpQD, Brazil 
Middle East: Ghadaa Alaa 
Information Technology Institute, Egypt 
Asia: Michael Chen 
III INSTITUTION, Taiwan 
Publication and Web Chair 
Carlo Giannelli   
University of Bologna, Italy 
Workshop/Tutorial Chair 
Cristian Hesselman 
Telematica Instituut, The Netherlands 
Local Chair 
Julia Ovtchinnikova 
Fraunhofer FOKUS, Germany 
 

Table of Contents
A Base Solution for Exposing IMS Telecommunication Services to Web
2.0 Enabled Applications. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
Florian Deinert, Alin Murarasu, Andreas Bachmann, and
Thomas Magedanz
FINDR: Low-Cost Indoor Positioning Using FM Radio . . . . . . . . . . . . . . .
15
Andrei Papliatseyeu, Niko Kotilainen, Oscar Mayora, and
Venet Osmani
IEEE 802.21 Assisted Seamless and Energy Eﬃcient Handovers in
Mixed Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
Huaiyu Liu, Christian Maciocco, Vijay Kesavan, and Andy L.Y. Low
Intelligent Middle-Ware Architecture for Mobile Networks . . . . . . . . . . . . .
43
Rayene Ben Rayana and Jean-Marie Bonnin
Middleware Solutions for Self-organizing Multi-hop Multi-path Internet
Connectivity Based on Bluetooth . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
58
Paolo Bellavista and Carlo Giannelli
Location-Based Botany Guide: A Prototype of Web-Based Tracking
and Guiding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
Rui Zhou and Gerhard Schneider
Parallel Data Transfer with Voice Calls for Energy-Eﬃcient Mobile
Services. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
87
Jukka K. Nurminen and Janne N¨oyr¨anen
Policy-Based Device and Mobility Management . . . . . . . . . . . . . . . . . . . . . .
101
Pierre Imai, Bernd Lamparter, and Marco Liebsch
Policy-Based Middleware for QoS Management and Signaling in the
Evolved Packet System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
115
Richard Good, Fabricio Gouveia, Thomas Magedanz, and
Neco Ventura
Proactive Data Replication Using Semantic Information within
Mobility Groups in MANET . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
129
Hoa Ha Duong and Isabelle Demeure
Scalable Interactive Middleware Components for Ubiquitous
Fashionable Computers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
144
Gyudong Shim and Kyu Ho Park

X
Table of Contents
SeDeUse: A Model for Service-Oriented Computing in Dynamic
Environments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
157
Herv´e Paulino and Carlos Tavares
The Contextual Map - A Context Model for Detecting Aﬃnity between
Contexts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
171
Robert Schmohl and Uwe Baumgarten
Extending UPnP QoS Standard for Reducing Response Delay in
Multimedia Home Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
185
Jes´us S´aez, Alvaro Reina, Ralf Seepold, and
Natividad Mart´ınez Madrid
Extending an IMS Client with Peer-to-Peer Content Delivery . . . . . . . . . .
197
Jens Fiedler, Thomas Magedanz, and Julius M¨uller
Digital Terrain Model Interpolation for Mobile Devices Using DTED
Level 0 Elevation Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
208
Murat Ozyurt, Tuna Tugcu, and Fatih Alagoz
A Mission Management Framework for Unmanned Autonomous
Vehicles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
222
Eskindir Asmare, Anandha Gopalan, Morris Sloman,
Naranker Dulay, and Emil Lupu
A Quality of Context-Aware Approach to Access Control in Pervasive
Environments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
236
Alessandra Toninelli, Antonio Corradi, and Rebecca Montanari
A Service-Oriented Framework Supporting Ubiquitous Disaster
Response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
252
Michele Amoretti, Maria Chiara Laghi, and Gianni Conte
An Analysis of Navigation Algorithms for Smartphones Using J2ME . . .
266
Andr´e C. Santos, Lu´ıs Tarrataca, and Jo˜ao M.P. Cardoso
An IMS-Based Middleware Solution for Energy-Eﬃcient and
Cost-Eﬀective Mobile Multimedia Services . . . . . . . . . . . . . . . . . . . . . . . . . .
280
Paolo Bellavista, Antonio Corradi, and Luca Foschini
Announcement/Subscription/Publication: Message Based
Communication for Heterogeneous Mobile Environments . . . . . . . . . . . . . .
295
Henry Ristau
Building a Personal Symbolic Space Model from GSM CellID
Positioning Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
309
Filipe Meneses and Adriano Moreira
Chapar: A Cross-Layer Overlay Event System for MANETs . . . . . . . . . . .
325
Amir R. Khakpour and Isabelle Demeure

Table of Contents
XI
Context Aware Multiparty Session Support for Adaptive Multicasting
in Heterogeneous Mobile Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
340
Josephine Antoniou, Christian Riede, Filipe Cabral Pinto, and
Andreas Pitsillides
Context Inference for Mobile Applications in the UPCASE Project . . . . .
352
Andr´e C. Santos, Lu´ıs Tarrataca, Jo˜ao M.P. Cardoso,
Diogo R. Ferreira, Pedro C. Diniz, and Paulo Chainho
Design, Implementation and Case Study of WISEMAN: WIreless
Sensors Employing Mobile AgeNts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
366
Sergio Gonz´alez-Valenzuela, Min Chen, and Victor C.M. Leung
Developing and Benchmarking Native Linux Applications on
Android . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
381
Leonid Batyuk, Aubrey-Derrick Schmidt, Hans-Gunther Schmidt,
Ahmet Camtepe, and Sahin Albayrak
Towards an Opportunistic and Location-Aware Service Provision in
Disconnected Mobile Ad Hoc Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
393
Salma Ben Sassi and Nicolas Le Sommer
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
407

A Base Solution for Exposing IMS
Telecommunication Services
to Web 2.0 Enabled Applications
Florian Deinert, Alin Murarasu, Andreas Bachmann, and Thomas Magedanz
Fraunhofer Institute for Open Communication Systems (FOKUS)
Kaiserin-Augusta-Allee 31, 10589 Berlin, Germany
{florian.deinert,alin.murarasu,andreas.bachmann,
thomas.magedanz}@fokus.fraunhofer.de
http://www.fokus.fraunhofer.de
Abstract. The convergence of telecommunication and Web 2.0 services
is leading to new opportunities for the telecommunications market. Com-
panies are looking for ways to include their services in Web 2.0 applica-
tions. Predictions suggest that future telecommunication networks will
be based on the IP Multimedia Subsystem (IMS), an all IP telecommu-
nication core network. This paper describes an approach to combining
Web 2.0 enabled applications, namely widgets, with telecommunication
features using IMS. Widgets are small applications based on Web tech-
nologies that run on the client device. A new abstraction layer with inter-
faces for the diﬀerent telecommunication features will be introduced. In
addition a widget engine that makes these telecommunication interfaces
available to its widgets will be presented. This will allow the rapid devel-
opment of IMS applications for external developers and the combination
of other Web 2.0 services with IMS features.
Keywords: Web 2.0, Widgets, Widget Engine, IMS, API, JavaScript,
Google Android, Telecommunication, VoIP.
1
Introduction
Over the last few years there has been an identiﬁable tendency towards the
convergence of classic telecommunication methods and Internet services. The
availability of fast Internet connections with less delay is making new telecom-
munication applications that use the Internet possible. Services like Voice-over
IP or instant messaging have gained wide acceptance from users. IMS is a strong
candidate for a telecommunication network base of the future. It is speciﬁed by
3GPP and oﬀers services like Voice-over IP calls, presence, location information
and instant messaging. To access the IMS a client is usually required to be based
among others in the Session Initiation Protocol (SIP).
In the past telecommunication companies had a conservative strategy when
compared to web companies. Their services were traditionally not open and
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 1–14, 2009.
c
⃝Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

2
F. Deinert et al.
could only be accessed by commercial clients with the provider’s permission.
The Internet community introduced another approach, as Web companies have
tended to oﬀer their own APIs to let the user build their own applications or
services using the companies’ data and services. This type of business beneﬁts
both sides: the user and the operating company. Users get new functionality to
generate individual content while the vendor beneﬁts from more customers. Most
of these APIs are based on JavaScript, respectively Asynchronous JavaScript and
XML (AJAX), because it is available in almost all modern browsers and it is
not too complex. To reach various new developers those APIs have a simple
structure. This enables rapid development of new ideas and the combination of
diﬀerent services from diﬀerent companies: these are known as mash ups.
This paper will analyze the approaches to accessing telecommunication func-
tions inside small Web 2.0 enabled applications called widgets. In order to run a
widget, a runtime environment, called a widget engine, is required to host and
manage the widgets. Widget engines are standalone applications and are written
in a complex programming language. There is also another kind of widget called
a browser widget, which is displayed directly inside a web page and is not stored
and managed locally. Browser widgets will not be explored in this article.
Widgets usually use common web technologies like HTML, XML, CSS,
JavaScript and AJAX. They can be created by external Web developers as
these technologies are spread in the World Wide Web. This enables a big de-
veloper community. Due to the limitation to these Web technologies widgets
have restricted functionality. A widget is similar to a Web page. It uses almost
the same technologies and has the same limitations. HTML and XML are just
markup languages without control options. Hence the features of the widgets
are limited by the functions oﬀered by JavaScript. For instance widgets have no
direct access to the ﬁle system. Widgets can also not directly access the IMS be-
cause it is not possible to use SIP with JavaScript. Furthermore, due to security
issues JavaScript does not have the permission to access functions or resources
outside of its sandbox: other Web pages are the exception. All features which
are not realizable using native JavaScript must be carried out by the Widget
engine as the widget engine is not restricted in functionality. Thus the widget
engine must provide extensions to use a widget’s additional features. Other wid-
get engines provide extensions for monitoring resource consumption or accessing
device-speciﬁc capabilities such as calendar or contact list for instance.
This paper will introduce a telecommunication extension dealing with the
opportunity to create “IMS Widgets”, widgets that can use telecommunication
features based on IMS. In order to ease the development process for web pro-
grammers not familiar with IMS the widget engine must provide an abstraction
layer between Web technologies and the IMS world.
Section 2 will provide a brief introduction to widget engines currently available
from other companies, and the W3C widget standard draft.
Section 3 will introduce a JavaScript API that provides telecommunication
interfaces for services oﬀered by IMS.

A Base Solution for Exposing IMS Telecommunication Services
3
Section 4 describes a widget engine which oﬀers telecommunication functions
to its widgets by implementing the JavaScript telecommunication API.
2
Related Work
This section describes widget engines from big vendors which are widely used. A
shortintroductioninto theW3CwidgetrecommendationandBONDI,aninitiative
for standardizing JavaScript extensions on mobile devices, will follow. Concluding
with the Parlay X interfaces, a telecommunication API based on Web services.
2.1
Widget Engines
In the last few years a new kind of application has increasingly gained popular-
ity: the so called desktop widgets. These widgets are small frames that provide
services like weather forecasts or news headlines on the desktop. Widgets are in-
teresting because they are easy to develop, deploy and use. Since widgets cannot
run as stand-alone applications they require a widget engine in order to run.
Various companies have released their own widget engines. Konfabulator is
supposed to be the ﬁrst commercially successful widget engine. Apple’s Dash-
board which was integrated into the Mac OS X 10.4 operating system in 2005
was inspired by Konfabulator. In the same year Yahoo bought the Konfabulator
and renamed it Yahoo Widget Engine. In 2006 Google introduced its Google
Desktop Gadgets, another widget engine. Microsoft followed and integrated the
Vista Sidebar, as a replacement for Active Desktop from Windows 98, which
was also designed to display Web content on the client desktop but was not
very successful. Another popular widget engine comes from Opera. Microsoft
and Google use the term gadget which is in fact just another name for widget.
Almost all widget engines provide hardware device features like monitoring
battery status or CPU usage but none of these widget engines have telecom-
munication features. Dashboard oﬀers a Skype widget which is in fact able to
use telecommunication features like VoIP or instant messaging. But this widget
requires the normal Skype standalone-application to be installed on the system
because the widget engine communicates with the standalone Skype application.
Hence the communication part is not really integrated into the widget engine.
None of these widget engines gives the developer the opportunity to access IMS
services. Section 4 will introduce a widget engine that makes use of IMS services.
2.2
W3C Widget Standard
All widget engines named above are proprietary, meaning their widgets are not
compatible. In order to fulﬁll the speciﬁc requirements, a developer who wants to
deploy his widget on the most common engines has to write it several times. Nev-
ertheless they have a great deal in common. All engines use common ﬁle formats
like HTML, XML and JavaScript to ease development and to make integration of
other Web 2.0 services comfortable. W3C has done a survey on the widget engines

4
F. Deinert et al.
currently available and they are now in the process of developing a widget stan-
dard [1]. The widget structure, as deﬁned in the ﬁrst draft, looks very similar to
the Opera widgets’ structure [2]. The actual draft does not yet include any infor-
mation about JavaScript extensions oﬀered to the developer. Such extensions are
required to get access to additional features like hardware monitoring or telecom-
munication services from a widget. The widget engine, described in section 4,
implements the actual W3C widget draft for packaging and conﬁguration.
2.3
BONDI
While the W3C recommendation is focused on widget packaging and conﬁgura-
tion, BONDI targets the functional opportunities available for web applications.
BONDI is an initiative that is intended to address the problem of the non-
interoperability of today’s applications for mobile devices. The initiative was
founded in mid 2008 by the Open Mobile Terminal Platform (OMTP), a forum
of international market leading mobile operators and device manufactures.
Fragmentation of mobile platforms slows down the development of applica-
tions and in turn mobile Web usage. BONDI seeks to remedy that problem by
proposing interfaces for typical telecommunication and device-speciﬁc services.
The initiative sees the browser, and the underlying web rendering engine respec-
tively, as the environment for future mobile applications. BONDI interfaces are
proposed in a JavaScript API which can be used in normal websites as well as
in widgets. These interfaces provide access to the key local capabilities of mobile
handsets to ensure that web applications can access native functionality.
Release 1.0 of the BONDI JavaScript API is separated into 12 functional
groups such as Messaging, Media Gallery, Personal Information (Calendar, Con-
tacts), Location and Camera [3]. BONDI started integrating these features as
JavaScript extensions into the browser engine of Windows Mobile.
BONDI’s approach is similar to the JavaScript API introduced in this paper
but BONDI interfaces are focused on device-speciﬁc capabilities rather than IMS
telecommunication services.
2.4
Parlay X - Telecommunication API
Programming telecommunication networks is very complex. For this reason the
Parlay Group was founded, an industry consortium of several telecommunication
vendors. Its goal is to develop open standards for the telecommunication market.
In 2003 Parlay released the Parlay X API, a collection of Web service interfaces
to access telecommunication networks. These interfaces can be implemented by
diﬀerent vendors on diﬀerent networks. Parlay X provides high level functions but
is usually not intended for external Web developers from the Web community.
Even though Web services are easy to use it is not that easy for a Web developer to
integrate them into browser enabled Web 2.0 applications. A solution is required
for combining IMS services with browser based Web technologies like AJAX [4].
The JavaScript Telecommunication API, introduced in the next chapter, provides
an abstraction layer for the combination of Web technologies and IMS.

A Base Solution for Exposing IMS Telecommunication Services
5
3
JavaScript Telecommunication API
This section introduces a telecommunication API, used to access the IMS inside
of widgets. A brief introduction for the most relevant IMS services will be given.
3.1
API
All telecommunication features described in this paper are based on the IMS
network. IMS is a telecommunication core network speciﬁed by 3GPP that is
completely based on IP.
A new API for telecommunication features, oﬀered by IMS, is proposed. The
Telecommunication API is deﬁned by JavaScript functions that can be used
inside of a widget. JavaScript was chosen due its market diﬀusion and simplicity.
The JavaScript IMS functions are high level abstractions, meaning only one
line of code is necessary for accessing an IMS service which might invoke sev-
eral internal actions. Each function can either be called synchronously or asyn-
chronously. Synchronously means that the script waits until the execution of
the command is ﬁnished. Asynchronous calls execute the same command with
a callback function as an additional parameter. The script goes further and the
callback function is executed when the command is ﬁnished. Synchronous calls
are easier to develop but have the disadvantage that the application might freeze
if the invoked command takes a long time to return.
The API comes as a JavaScript ﬁle which must be included in all widgets that
want to use telecommunication features. Section 4.4 describes how to include the
API in a widget.
3.2
Telecommunication Services
IMS provides several kinds of telecommunication features. The aim of this API
is to provide high-level interfaces for the most relevant services. All provided
telecommunication functions are arranged into 8 service groups. Table 1 shows
the proposed groups in alphabetical order.
First of all it is possible to initiate voice calls routed by IMS. There are
three diﬀerent categories of voice calls: peer to peer calls, third party calls and
conference calls.
Table 1. JavaScript telecommunication API Service Groups
AddressBook
contains a set of functions for accessing user proﬁles via XDMS
Call
contains functions for outgoing and incoming voice over IP calls
ConferenceCall a set of functions for voice connection of multiple users
Location
provides functions for getting location information
Messaging
contains functions for sending and receiving instant messages
Presence
provides functions for getting and setting presence state
SMS
allows the user to send a short message to a mobile phone
ThirdPartyCall contains functions to start or end a third party call

6
F. Deinert et al.
Peer to peer calls connect two participants via a SIP protocol where voice
information is streamed over an IP based network (Voice over IP). A gateway
to the PSTN enables it to call using classic circuit-switched access as well. The
API makes it possible to initiate and receive VoIP calls and to get information
about a running VoIP call.
The second category of voice calls are third party calls. Third party calls also
establish a voice connection between two participants from the point of view of a
server which acts as the third party. A third party call expects two SIP addresses
or phone numbers. After initiating the call participant 1 receives an invitation for
an incoming call. When participant 1 has accepted the call participant 2 receives
the notice of an incoming call as well. The voice connection is only established
if participant 2 has also accepted the call. The control of the third party call lies
on the server side, meaning the third party may also disconnect the call.
Another kind of call is the conference call. Conference calls are voice con-
nections between at least two participants. The initiator of the conference may
invite new participants and disconnect participants from a running conference.
A further telecommunication service oﬀered by IMS is instant messaging.
Instant messages are widely known from the Internet. The API makes it possible
to send messages to the SIP address and to receive instant messages. This kind
of service facilitates chat applications.
The IMS network includes a gateway to send short messages (SMS) to mo-
bile phones. Thus it is possible with the telecommunication API to send a SMS.
The next functional group of the API is called AddressBook. It includes all
functions that are necessary for managing personal contacts. Contacts are nor-
mally stored on the XML document management server (XDMS), which acts as
an XML database for user management and conﬁguration. User proﬁles may con-
tain information like name, address, age, gender, telephone numbers or optional
free text. Contacts can be arranged into diﬀerent groups like “friends” and “team-
mates” for instance. The SIP address of each contact acts as its primary key.
Presence is another functional service group. The IMS network includes a
presence server which contains the actual presence state for all registered users.
The presence state is presented as one of the following strings: “ONLINE”,
“OFFLINE”, “BUSY”, “AWAY”. The telecommunication API allows a user to
set its own state, to get the actual state of the other users and to react to other
users’ presence state changes.
The IMS also provides features for ﬁnding the location in terms of GPS
coordinates. If the device that runs the client provides location information it
can be accessed by the telecommunication API.
4
Widget Engine
This section introduces the new widget engine, which makes use of the telecom-
munication API, including its implementation on desktop computers and Google
Android based mobile phones.

A Base Solution for Exposing IMS Telecommunication Services
7
4.1
Requirements for a Widget Engine with Telecommunication
Features
The widget engine cares about hosting, including managing and rendering the
widgets. It should run on diﬀerent platforms: Windows XP, Windows Vista,
Linux, Windows Mobile and Google Android. Widgets should be portable, mean-
ing a widget that was written for the desktop engine should run on other plat-
forms too.
The widget engine is compliant to the current W3C draft standard [2]. That
is to say a widget uses only common ﬁle formats known from the web. For this
purpose the widget engine must include an interpreter for HTML and JavaScript
code. The goal of this paper is to introduce telecommunication features into wid-
gets. Hence the widget engine must additionally provide interfaces for telecom-
munication features to the widgets by oﬀering the JavaScript functions of the
Telecommunication API described in section 3.
Any incoming notiﬁcation message must be delivered to the appropriate wid-
get. This is the situation in which the widget engine receives an incoming call, an
incoming instant message or a presence change. The web developer may deﬁne
JavaScript functions that will be invoked when such an incoming notiﬁcation
occurs. If no widget is open while an incoming call arrives the user may deﬁne
a standard widget which will be opened automatically when a call arrives.
4.2
Architectural Design
The widget engine comes as a stand-alone application which is installed on the
terminal. On startup it logs in to the conﬁgured IMS network automatically.
Each widget is packaged as a zip ﬁle containing no more than the common Web
ﬁle formats. Widgets can be installed from external media storages or Web sites
into the engine. They are stored in a local directory as part of the widget engine.
The graphical interface of the engine diﬀers depending on the operating system.
Figure 1 illustrates the interaction of the components. IMS access is realized
via MONSTER, a standards-compliant client framework developed at Fraun-
hofer FOKUS that implements JSR 281 [6][7]. The acronym MONSTER stands
for Multimedia Open Internet Services and Telecommunication Environment,
an extendible framework that provides communication interfaces for accessing
the IMS network. Due to its Java implementation, MONSTER is applicable on
multiple platforms. MONSTER was implemented and tested in the Open IMS
Playground, a Fraunhofer FOKUS IMS environment, but is applicable on other
IMS networks too [10].
When a widget invokes a JavaScript function of the telecommunication API,
the widget is responsible for doing the mapping to the appropriate MONSTER
interface. In the other direction MONSTER provides listener services which are
ﬁred when an incoming notiﬁcation arrives. The incoming notiﬁcation will be
delivered to the appropriate widget by the widget engine. The challenge is how
to map the functions of the JavaScript API to the underlying IMS services. Some

8
F. Deinert et al.
Fig. 1. Widget engine with interacting components
features, like short messaging for instance, are executed by calling Web services
oﬀered by OpenSE, a server based implementation of the Parlay X interfaces
described in section 2.3. Both MONSTER and OpenSE access the IMS via SIP
protocol. Because JavaScript has no built-in access to Java and certainly no
possibility of using SIP, the widget engine provides a way for communicating
between Java and JavaScript.
4.3
Implementation of the Desktop Widget Engine
Each widget runs in a dedicated window, which in fact contains a lightweight
Web browser to render the widget. The desktop version allows drag and drop of
the widgets on the screen. Moreover it allows multiple widgets to be opened in
parallel.

A Base Solution for Exposing IMS Telecommunication Services
9
The implementation uses Java Standard Edition, thus it is possible to use the
same code on Windows and Linux. The Standard Widget Toolkit (SWT)1, de-
veloped by the Eclipse foundation, was chosen as the GUI toolkit [11]. SWT is an
open source GUI toolkit, designed to provide user interface elements based on the
operating system. It meets the requirements in terms of portability, performance
and the GUI facilities provided. Because it uses native user interface facilities
from the operating system, SWT is much more eﬃcient than Swing or AWT.
SWT oﬀers a Web browser element, which is able to interpret HTML, JavaScript
and CSS ﬁles and to display image ﬁles like any other modern browser.
The SWT browser element uses Xulrunner, a runtime package that can be
used for the interpretation of HTML and JavaScript code [7]. Xulrunner was
developed by Mozilla and is available for Windows and Linux. It uses the Gecko
engine, known from the Firefox Web browser. On Windows systems it is also
possible to exchange Xulrunner with Internet Explorer.
Two diﬀerent approaches were considered for the mapping from JavaScript to
Java. Both use Jabsorb, an open source Java tool for Java-JavaScript interac-
tion [8]. Jabsorb provides methods for marshalizing Java objects into JavaScript
Object Notation (JSON) strings. JSON is a text-based format used to exchange
data which is similar to XML but with a simpler structure and less overhead.
The invocation of Java methods is done by JSON-RPC, a text based protocol for
calling on remote procedures. These JSON strings can be sent from JavaScript
to Java and vice versa. The receiving side unmarshalizes the JSON string into
a Java or JavaScript object. The two approaches for the JavaScript to Java
mapping diﬀer in the way in which they transmit the JSON strings.
The ﬁrst approach uses the browser status bar as a buﬀer. When JavaScript
wants to invoke a Java method a JSON string is written on the browser status
bar. The user will not notice that because the status bar is invisible. In Java
the browser element has an onChange listener method for the status bar which
is invoked when the status text changes. The JSON string on the status bar is
unmarshalized by Jabsorb into Java objects / method calls and the appropriate
Java method will be invoked. This approach is eﬃcient because the delay between
method invocation and execution is very small. The disadvantage of this kind
of communication is that it does not allow synchronous calls. JavaScript has no
built-in support for multithreading. Thus it is not possible for the JavaScript
code to wait until Java returns.
The second approach is based on a local lightweight Web server with a small
memory footprint. The JSON string is transmitted via AJAX to the local HTTP
server. The server receives the string and sends it to Jabsorb which unmarshalizes
it, executes the appropriate Java method and sends a reply to JavaScript. This
kind of communication requires a local server. A lightweight HTTP server has
been implemented and integrated into the widget engine for this purpose. Due to
the server request this kind of communication suﬀers a longer delay than the ﬁrst
1 Please note that the term widget is used in another context when talking about GUI
toolkits. A GUI toolkit widget is a graphical element for user interaction like an
input ﬁeld or a check box.

10
F. Deinert et al.
approach. The advantage of this approach is the opportunity to use synchronous
calls. AJAX makes use of the XML.HTTP request object which is able to invoke
both asynchronous and synchronous calls.
Incoming notiﬁcations can be delivered directly to JavaScript by using the
browser.execute() command which is included into the SWT browser. In this
way incoming messages may cause the browser element to invoke the appropri-
ate JavaScript function inside a widget. A widget must register for incoming
messages since not all widgets are interested in knowing when an incoming mes-
sage arrives. Therefore the widget developer can write a JavaScript function
called init(), which is invoked on startup after the widget ﬁnishes loading.
Each widget using the telecommunication API on the desktop version must
include two JavaScript ﬁles in its initial HTML ﬁle. The ﬁrst .js ﬁle manages the
JavaScript to Java mapping and the second one contains the telecommunication
interfaces.
4.4
Mobile Version Using Google Android
Android is a new open-source platform for mobile devices introduced by Google
at the end of 2007. It was released in the form of a development toolkit including
an emulator for testing new applications. Android is based on Linux Kernel 2.6
and the Dalvik virtual machine, a JVM with some additional features like the
built-in GUI toolkit. Indeed it has some restrictions as well. Due to security
issues an Android application cannot access ﬁles outside of its own application
directory for instance.
Android applications are usually composed of multiple so called activities. An
activity is mostly a single screen that interacts with the user. Every activity has
its own complex lifecycle including a large set of controlling points. When writing
their own widget a developer does not need to be concerned about Android’s
programming model. They can use normal JavaScript in the same way as they
do when creating a Web site.
The Android version of the widget engine uses the same MONSTER commu-
nication interfaces to access the IMS as the desktop version. For the GUI no
extra toolkit like SWT is required because Android has built in GUI elements
that can be used. The widgets are interpreted by an element called WebView,
which is part of WebKit, a library included in Android. WebKit is known as the
rendering engine of Apple’s Safari browser. This WebView element replaces the
SWT browser of the desktop version. Because of the smaller display the Android
version of the widget engine will not show more than one widget at the same
time. The engine itself is realized using the GUI element “gallery” of Android.
The end-user may load new widgets from an SD-card into the engine or Web
and remove old widgets. Every icon in the gallery represents a stored widget.
The communication between Java and JavaScript is very eﬃcient on Android.
WebView elements provide the opportunity to expose Java objects to JavaScript,
whose methods can be accessed directly inside the JavaScript code. In the oppo-
site direction Java can invoke JavaScript functions inside a WebView by calling
WebView.loadUrl(“javascript: code”). Due to the diﬀerent mapping from Java to

A Base Solution for Exposing IMS Telecommunication Services
11
JavaScript, widgets loaded into Android have to include another JavaScript ﬁle
for the telecommunication API than the desktop version. The following section
describes this process. Nevertheless the telecommunication API for Android pro-
vides the same interfaces but uses a diﬀerent system for mapping to the widget
engine.
4.5
IMS Widgets
As deﬁned in the W3C draft, every widget contains at least a conﬁg.xml for
the meta data and a starting HTML ﬁle, usually called index.html [2]. As an
extension of the widget engine the conﬁg.xml must include a link to an image
ﬁle which describes the shape of the widget.
5
Evaluation
The aim of this work is to explore widgets’ IMS telecommunication features.
In order to prove their usability, portability and ease of development an exam-
ple widget was created for every service group of the telecommunication API.
This section shows some of these example widgets using the new widget engine,
including telecommunication services.
5.1
Call Widget Example
Figure 2 shows an example call widget. When inserting a number or SIP address
into the input ﬁeld and clicking the green button on the left a new connection will be
established. Another use case appears when an incoming call arrives and the user
clicks on the green button. In this case the incoming call will be answered, instead
of initiating a new call. The user has the power to cancel the call or see viewing
information about the call by pushing the buttons on the bottom of the widget.
Each widget may contain an init function, which can be written by the de-
veloper. This function is executed after the widget has ﬁnished loading. The
Fig. 2. Call Widget
Fig. 3. Address Book / Presence Widget

12
F. Deinert et al.
init function is meant to deﬁne what happens when incoming events, like an
incoming call for instance, occur.
The following JavaScript code shows the functional part for the green button
in order to demonstrate the simplicity of the API. If the status equals “Incom-
ing” the ring tone stops and the incoming call is answered. answerCall function is
invoked asynchronously with a callback function as input parameter while make-
Call invokes the Java method synchronous. This shows the diﬀerent options for
invoking the telecommunication API.
function
connect () {
i f
( actualStatus==”Incoming ” )
{
/∗when
c a l l
i s
arriving
answer
c a l l
∗/
var
callBackFunction = function ( r e s u l t ) {
stopRing ( ) ;
/∗
stops
the
ringtone sound ∗/
}
FOKUS. Call . answerCall ( callBackFunction ) ;
}
else {
/∗when number entered
i n i t i a t e
c a l l
∗/
var
t e l = document . getElementById ( ” t e l ” ) . value ;
i f
( t e l !=”” ) FOKUS. Call . makeCall( t e l ) ;
}
}
The high-level function makeCall executes a lot of consecutive actions. First of
all the request is sent to the widget engine which executes the appropriate Java
method in MONSTER. MONSTER sends a SIP invite packet to the P-CSCF of
the client’s IMS network. The P-CSCF redirects the invitation to the I-CSCF
which looks up the called user’s S-CSCF in its HSS. Subsequently the S-CSCF
forwards the invitation to the called user’s client. MONSTER also manages the
authentication, authorization and accounting (AAA).
The invocation of Java methods by JavaScript causes a delay of less than 10ms
when using the implementation based on status bar communication. The local
server based communication requires no more than 20ms on a regular desktop
computer.
As can be seen the invocation of the IMS service is very comfortable using the
JavaScript telecommunication API. A widget developer does not have to worry
about the complexity behind the JavaScript functions. The high-level functions
hide all consecutive actions. The use of JavaScript allows the integration of other
Web 2.0 services.
5.2
Presence and Address Book Example Widget
The second example widget based on the widget engine combines the address
book service with the presence service. It displays all buddies entered in the user’s
address book and shows their actual presence state. Inside of its init function
the widget invokes the following actions:

A Base Solution for Exposing IMS Telecommunication Services
13
1. read all entries from the user’s address book
2. get presence information for every entry
3. subscribe to be notiﬁed of presence changes for all entries
4. set callback function for incoming presence state change
5. display all entries with their presence state
When any of the buddies changes his presence state the widget gets noticed
immediately and displays the new presence state. With the select box on the
bottom of the widget a user may publish its own presence state to the IMS’
presence server. The whole widget implementation requires about 40 lines of
JavaScript code and less than 30 lines of HTML code. Design is deﬁned in an
extra stylesheet ﬁle.
5.3
Widgets on Android
The same widgets deployed on the desktop widget engine will also run on An-
droid. This enables rapid development of Android IMS applications without
knowing anything about Java or the Android code model. Only some lines
of HTML and JavaScript must be written to create an IMS application on
Android.
Figure 4 shows the widget engine on an Android emulator. The GUI of the
widgets was adapted in order to take the issue of ﬁngertip handling into account.
The functional part is the same as for the desktop version. On the top you can
see the engine, where every icon represents a widget. The actual opened widget
is displayed below. The ﬁgure on the left shows the presence / address book
Fig. 4. Widget Engine on Android Emulator

14
F. Deinert et al.
widget which was presented in section 5.2 for the desktop version. The ﬁgure
in the middle shows a chat widget which allows to send and receive instant
messages based on the IMS network. The ﬁgure on the right shows an example
widget for sending an SMS.
6
Conclusion
The widget engine described in this paper makes it possible to develop IMS client
applications in a fast and easy way. The telecommunication API provides a layer
of abstraction between the IMS and the widgets. Using this high-level abstraction
layer, a developer with only web programming experience can easily handle the
functional complexity behind IMS. This allows the creation of customized IMS
clients for a wide range of users. Due to the fact that widgets make use of
Web technologies, exposing IMS based telecommunication services to Web 2.0
enabled applications becomes an exploitable opportunity. It has been proven
that the developed widgets are easy to create, are highly portable and run on
various operating systems and hardware platforms.
Future work will enhance the telecommunication API with services for music
and video streaming that can be used inside of Web applications. These features
are already supported by the MONSTER framework and it is planned to make
them available to widgets. At the moment Android restricts VoIP calls because
Google has disabled audio streaming. Another open issue is widget to widget
communication. Widgets can interact with the widget engine but cannot interact
with each other yet. Future work will concentrate on this issue. As another next
step the widget engine will be ported to Windows Mobile.
References
1. Widgets 1.0: The Widget Landscape, W3C (April 2008)
2. Widgets 1.0: W3C Working Draft, W3C (April 2008)
3. BONDI – Interfaces Requirements Version 1.0, OMTP (February 2009)
4. Hughes Systique Corporation. Telco-ajax: A concept approach at bringing legacy
telecom application servers to web 2.0. Whitepaper (Feburary 2008)
5. Parlay X Web Services, Parlay Group, Version 3.0 (June 2007)
6. JSR 281 IMS Services API, Java Community Process, Ericsson (July 2008)
7. Design of a Coherent Mobile Multimedia Framework for Convergent Services, Al-
berto Diez Albaladejo, Alin Murarasu, Thomas Magedanz, TU-Berlin (2008)
8. Jabsorb 1.3, Open Source (May 2008)
9. Xulrunner 1.8.1, Mozilla (March 2008)
10. IMS Playground, Fraunhofer FOKUS, http://www.open-ims.org
11. Standard Widget Toolkit, Eclipse Foundation, http://www.eclipse.org/swt/

FINDR: Low-Cost Indoor Positioning
Using FM Radio
Andrei Papliatseyeu1, Niko Kotilainen2, Oscar Mayora3, and Venet Osmani3
1 University of Trento, Via Sommarive 14, Povo (TN), 38050, Italy
papliats@disi.unitn.it
2 University of Jyv¨askyl¨a, P.O. Box 35, 40014 Jyv¨askyl¨a, Finland
niko.kotilainen@jyu.fi
3 Create-Net, Via alla Cascata 56/D, Povo (TN), 38050, Italy
oscar.mayora@create-net.org, venet.osmani@create-net.org
Abstract. This paper presents an indoor positioning system based on
FM radio. The system is built upon commercially available, short-range
FM transmitters. The features of the FM radio which make it distinct
from other localisation technologies are discussed. Despite the low cost
and oﬀ-the-shelf components, the performance of the FM positioning is
comparable to that of other positioning technologies (such as Wi-Fi).
From our experiments, the median accuracy of the system is around
1.3 m and in 95% of cases the error is below 4.5 m.
Keywords: Indoors positioning, FM radio, location awareness.
1
Introduction
Location awareness is an important requirement for many modern applications,
spanning from mobile maps and geotagging to Internet of Things and health-
care. The Global Positioning System (GPS) is most widely used for location
sensing, but it is limited to outdoors-only applications. A body of research has
addressed indoor positioning using diﬀerent technologies, like ultrasound and
infrared beacons, Wi-Fi and GSM networks, or other types of radios [1]. Most
of these systems are limited in terms of expensive/custom hardware, laborious
deployment or low accuracy.
Our paper explores the applicability of short-range FM radio transmitters
for indoor positioning. We have installed our FINDR (FM INDooR) positioning
system in our lab and this paper presents performance evaluation results of the
system as well as an overview of particular properties of FM radio with respect
to localisation.
FM has a number of advantages over other positioning technologies, like
Wi-Fi. Firstly, although Wi-Fi infrastructure is readily available in oﬃce build-
ings, the installation of a localisation system in domestic environment requires
additional hardware. In this case, FM is a cheaper alternative to the deployment
of multiple Wi-Fi access points per apartment. FM transmitters are cheaply
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 15–26, 2009.
c
⃝Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

16
A. Papliatseyeu et al.
available from many consumer electronics shops; the client device can be rep-
resented by a PDA or a cellphone with an embedded FM receiver. Secondly,
FM radio can be safely used in sensitive environments, e.g. hospitals, whereas
GSM, Wi-Fi or Bluetooth devices must be switched oﬀthere. Finally, FM is
very power-eﬀective: an average FM receiver consumes about 15 mW, compared
to almost 300 mW of Wi-Fi (in receiving mode) [2, 3].
The paper is organized as follows. Section 2 provides and overview of the
related work. Section 3 then introduces our approach and our experimental
testbed. Section 4 presents results pertaining to performance evaluation of
FINDR, while Section 5 describes the possible application scenarios of the sys-
tem. Finally, Section 6 draws the conclusions and outlines the future work.
2
Related Work
2.1
Wireless Positioning Techniques
In the last decade, a large body of research has been dedicated to the develop-
ment of location-aware systems. Indoors positioning systems rely on several types
of sensors: ultrasound [4, 5], infrared (IR) [5, 6], digital compass [4], RFID [7],
and various kinds of radio: Wi-Fi [8, 9], GSM [10], Bluetooth [11], domestic pow-
erline [12, 13], and others [14, 15]. Such systems usually rely on one or a number
of the following criteria: user proximity to some ﬁxed beacons, time of signal
propagation, and received signal strength. In the sections that follow we brieﬂy
describe each of these approaches to localisation.
Proximity-Based. Given an environment with a number of beacons with
known positions, the algorithm assumes that the user’s position is that of the
nearest beacon. Due to its simplicity, the method is widely adapted by the sys-
tems using custom radio beacons [15], as well as Bluetooth [16], IR [5] and GSM
base stations [17, 18]. Unfortunately, the accuracy of such systems is low and
depends on the density and the number of installed beacons.
Time-Based. Time-based methods use information about signal propagation
time between the mobile device and beacons with known positions, in order
to estimate the position of the mobile user. The most prominent example of
this class of methods is GPS. Using the signals from a set of GPS satellites, a
basic GPS receiver is able to compute its position with the accuracy of about
8 m [19, p. 22]. However, GPS has long start-up times (up to a few minutes) and
does not work indoors and in dense urban areas, which limits GPS’s applicabil-
ity for ubiquitous location-based services. Ultrasonic localisation systems, like
Cricket [4], also rely on the travel time of an ultrasound pulse. While provid-
ing a good accuracy, time-based systems usually require custom hardware and
expensive installation.

FINDR: Low-Cost Indoor Positioning Using FM Radio
17
Signal Strength-Based. There are two general positioning approaches that
use Received Signal Strength Indication (RSSI), namely propagation modelling
and ﬁngerprinting. The ﬁrst approach attempts to build a model of the signal
propagation in the space in order to identify the distance between the user and
beacons. The ﬁngerprinting approach, in turn, relies on a database associating
RSSI measurements with corresponding coordinates and then uses statistics and
machine learning algorithms in order to recognize user position among those
learned during the training phase. RSSI-based methods are the most powerful,
as they can provide a rather high accuracy with a few beacons.
One of the pioneering projects in RSSI-based positioning was RADAR [20].
The authors applied both propagation modelling and ﬁngerprinting within a
Wi-Fi network, and, with some enhancements, the system error was as low as
2 m [8]. With more advanced probabilistic methods, the median error of a Wi-Fi
based system can reach 1.2–1.45 m [9, 21]. RSSI ﬁngerprinting has also been
successfully applied for indoor localisation using GSM base stations. In [10], the
authors employed so-called wide ﬁngerprints, which included RSSIs of up to 35
GSM channels, and thus managed to achieve a Wi-Fi-like median positioning
accuracy. However, the topology of a GSM network can be changed at any time
by the network operator, thus requiring system recalibration. [12] proposed a
more reliable approach for indoors positioning. In their system, two beacons were
injecting high-frequency signals into domestic powerline. These signals could
then be detected by a specialised receiver and associated with the user’s location.
An extended, wideband version of the system achieved a 90% accurate room
recognition [13]. Despite the easy installation, the system requires specialised
hardware with limited availability.
To the best of our knowledge, there is only one work dedicated to positioning
with FM radio. [14] described their experiments on using prototype hand watch
with an embedded FM radio, to localise using commercial FM broadcasting sta-
tions. The authors applied a Bayesian classiﬁer to distinguish six areas of Seattle,
based on RSSI ranking of the local FM stations. In the best case, the recognition
accuracy was 82%. Although the paper does not provide any information about
error distances, the system accuracy can be estimated as hundreds of meters to
kilometers, which renders it impracticable for indoor environments. Our system,
instead, is based on readily available hardware and is particularly suitable for
indoor use.
3
FM Positioning
3.1
Our Approach
The FINDR positioning system employs a set of short-range FM transmitters
as wireless beacons and a programmable radio on the client device. Most of the
beacon-based positioning technologies have two general requirements: measuring
of user to beacon relative position and the ability to distinguish diﬀerent beacons.
In the next two sections we identify possible solutions how FM radio can address
these requirements.

18
A. Papliatseyeu et al.
Relative Position-Dependent Features. The relative position of the user
with regard to a beacon can be characterised by angle between directed antennas,
signal propagation time and RSSI. For the FM positioning, we have identiﬁed
three features that can be used as a measure of distance between the beacons
and the user.
The ﬁrst feature is RSSI, deﬁned as the amplitude of the received radio-
frequency signal. Most of the current FM receivers employ RSSI value internally,
to enable auto-tuning capability.
When RSSI is not available, one can use the signal-to-noise ratio (SNR) of
the demodulated signal. In this case, the beacon is set to transmit a known
periodic signal (for example, a sine wave of 1kHz) and the receiver performs a fast
Fourier transform (FFT) of the demodulated signal, calculating the intensities of
diﬀerent frequency bands. Then, the intensity of the band of interest is divided
by the average intensity of the all bands, thus representing signal-to-noise ratio.
A similar method was applied by [12] to an amplitude-modulated (AM) signal.
However, our experiments show that SNR of an FM signal is almost a step
function, which considerably limits applicability of this approach to FM-based
positioning (see Section 4.1).
There is also another feature that depends on the signal quality and, conse-
quently, on the distance between the transmitter and the receiver, namely, stereo
channels separation. In good reception conditions the stereo channels are well
separated, providing best sound quality. However, as the radio signal deterio-
rates, the receiver’s circuitry will start to reduce the audio bandwidth and thus
decrease channel separation in order to ﬁlter out the noise [22]. Ultimately, this
results in a plain mono signal.
Distinguishing Beacons. For a beacon-based positioning system it is crucial
to distinguish current beacon from the others. The beacons can be identiﬁed ei-
ther by their carrier frequencies or by the signals they transmit (e.g. coordinates,
ID, name, etc).
Unfortunately, due to the properties of FM, it is impossible to use the same
frequency for all beacons. Due to the so-called “capture eﬀect”, when a num-
ber of stations transmit on the same (or close by) frequency, the signal from
the strongest one will dominate the others, while the weaker signals get atten-
uated [23]. Therefore, in our experiments we had to tune each transmitter to a
diﬀerent frequency and switch between them at the receiver side. Despite this,
no special network planning is required for larger-scale deployments to avoid
beacons interference, as any distant interfering beacons will not be observed due
to the capture eﬀect.
3.2
Experimental Setup
The FINDR was evaluated with empirical measurements in the Multimedia,
Interaction and Smart Environments (MISE) lab of Create-Net [24]. The room
dimensions were 12 x 6 m, and the room contained ordinary oﬃce furnishing.

FINDR: Low-Cost Indoor Positioning Using FM Radio
19
Fig. 1. Floorplan of the measurement area. The antennas mark the positions of the
three transmitters and the dashed lines mark room furniture.
Fig. 2. MP3 player with an embedded FM transmitter, connected to power adapter.
The antenna is not connected.
Figure 1 presents the layout of the room. A grid of 1 x 1 m cells was created for
testing, and measurements were carried out in all accessible points of the grid
(totally 46 points).
The receiving device used in the tests was a Nokia N800 Internet Tablet. The
N800 is an based on an ARM processor and features a built-in FM receiver.
The N800 is running an open, Linux-based operating system, so developing low-
level custom applications for the device is relatively easy. The prototype locating
software was programmed in Python and used the PyFMRadio-library to tune
the FM-receiver to each of the transmitter’s frequency one after another and
read the signal strength from the FM-receiver hardware. The signal strength
was reported on a 16-step scale (normalized to range 0. . . 1) and was measured
300 times in a row for each frequency, with about 0.01 second between the
measurements. The standard N800 headset was used as an antenna.

20
A. Papliatseyeu et al.
The transmitter used was a K¨onig mp3 player, which features a built-in FM-
transmitter (Figure 2) [25]. To increase the range of the transmitters, a 1.8-meter
audio cable was connected to the player’s audio output to act as an antenna.
Initially, the whole FM band was scanned and manually checked for frequen-
cies with little interference from local FM-radio stations. The transmitters were
then tuned to these frequencies. To avoid the eﬀect of battery degradation, the
transmitters were powered by USB power adapters.
4
Results
4.1
RSSI Dependency on Distance
In order to estimate the feasibility of the FM positioning, we ﬁrst carried out a
test to see which of the features discussed in Section 3.1 are more suitable for
positioning. Stereo channel separation method has not been implemented yet
and will be addressed in the future work.
The RSSI dependence on the distance from the transmitter is presented in
Figure 3. To avoid any interference from the testbed’s furniture, this test was
performed outdoors. The graph is relatively smooth and monotone starting from
0.5 m, and proves RSSI to be a good feature for positioning. Eventual plateau-
looking areas can be explained by the limited number of RSSI levels recognized
by our receiver.
Figure 4 corresponds to the indoors measurements and shows the RSSI from
each of three transmitters while the user was moving from Transmitter 1 to
Transmitter 3 (as of ﬂoorplan in Figure 1). The dependencies are not very
smooth, which is caused by the distortions from the furniture and multipath
propagation. Nevertheless, the general trends are clearly observable.
For the RSSISNR method, the transmitter was set to broadcast a continuous
dual tone multi-frequency (DTMF) signal for digit “1” (1209 Hz and 697 Hz).
Fig. 3. RSSI dependence on distance

FINDR: Low-Cost Indoor Positioning Using FM Radio
21
Fig. 4. RSSI variation while moving from Transmitter 1 to Transmitter 3, with Trans-
mitter 2 placed between them
Fig. 5. RSSISNR dependence on distance
At the receiver side, the audio signal from an FM radio was sampled by a laptop
sound card at 8 kHz sampling frequency and transformed to the frequency do-
main using 1024-band FFT. For each point, 32 spectra were recorded and then
averaged. RSSISNR was then calculated as follows:
RSSISNR = band697Hz + band1209Hz
mean(all bands)

22
A. Papliatseyeu et al.
The experiment discovered no clear dependency of RSSISNR from the dis-
tance to the transmitter (see Figure 5). In range from 0.5 m to 3.6 m the mean
RSSISNR value barely changed, between 3.6 m and 4.5 m it became unstable,
and then rapidly degraded to the noise level. Such a behaviour can be explained
by the capture eﬀect, which improves the post-detection SNR for non-linear mod-
ulations (such as FM) when the pre-detection SNR is above a certain threshold,
“capture threshold”; below this threshold the SNR drops dramatically [26]. In
our case, the capture eﬀect is complemented by the receiver noise-reduction cir-
cuitry which automatically mutes the audio output if the received signal is too
weak [2].
Thus, RSSISNR dependency on the distance is almost a step function due to
intrinsic properties of FM. Therefore, we did not consider RSSISNR for further
experiments.
4.2
2D Positioning
To estimate the FINDR accuracy in two-dimensional positioning, we have used
ﬁngerprinting approach with two evaluation methods: leave-one-out validation
and an independent test set. In leave-one-out method, we sequentially selected
one of the RSSI measurements and excluded all the measurements related to the
same coordinates from the training set. The selected measurement was then used
as test data. It should be noted however, that leave-one-out evaluation tends to
Fig. 6. Error distributions for two-dimensional positioning

FINDR: Low-Cost Indoor Positioning Using FM Radio
23
worsen the actual positioning accuracy, as the classiﬁer is unable to recognize the
class it has not been trained on (that is, the error distance is always greater than
zero) [20]. Besides that, in order to estimate the real-world system accuracy, we
have tested the FINDR on an independent data set collected by another person.
For classiﬁcation, a k-nearest neighbour (kNN) method was used [27]. The
kNN classiﬁer evaluates the distance from the test point to all the training
points, and selects the labels (classes) of the k nearest training points. From
these k labels, the prevailing one is returned as the classiﬁcation result. For
our task, we employed the Euclidean distance measure. The optimal value of k
(k = 9) was selected by leave-one-out validation and then reused for cross-person
evaluation.
The error distance distributions for both approaches are shown in Figure 6.
The baseline performance is represented by a random classiﬁer. The median ac-
curacy for the leave-one-out evaluation method is 1.3 m, falling to about 4.5 m at
95% conﬁdence level. For the independent test set, 29% of places are recognized
correctly. The median accuracy is 1.3 m. Despite the long tail, caused by distant
outliers, in 95% of the cases the positioning error stays below 6.8 m.
4.3
RSSI Stability over Time
For a ﬁngerprinting-based system, it is very important that the values measured
during calibration phase do not drift over time. Otherwise, the system accuracy
may diminish signiﬁcantly, and the system will require recalibration. It has been
demonstrated, that many current ﬁngerprinting-based systems are aﬀected by
the signal stability problems [13, 28].
In order to estimate the stability of the FM signal strength in FINDR, we
placed a transmitter 4 meters apart from the receiver and left it recording the
RSSI over the weekend. However, in four hours the device ran out of memory
and only 1.7 million samples have been recorded. Their mean value was 0.57975
and the variance was 0.00097.
The RSSI distribution in Figure 7 proves the FM RSSI to be rather stable.
The two peaks are diﬀerent by one quantization step only. There are about 4000
outliers, which constitute only about 30 seconds of the whole 4-hour dataset.
Note that the measurements have been done by a receiver that distinguishes only
16 RSSI levels; a more advanced receiver could improve both the distribution
detail and the positioning accuracy.
5
Application Scenarios
The need for ﬁnding one’s position has sprung up a number of technologies that
fulﬁl this purpose with varying degrees of success. While outdoor positioning is a
relatively mature technology (i.e. GPS), the indoor localisation has been proven
an interesting research challenge. The interest in indoor positioning has been fu-
elled by the potential it oﬀers in creating novel applications that can span across
diverse domains. Applications ranging from locating lost keys within home, up

24
A. Papliatseyeu et al.
(a) Normal scale
(b) Logarithmic scale
Fig. 7. RSSI distribution for 4-hour long measurements
to detecting mobility patterns of elderly that aid disease diagnosis, are made
possible by utilising technologies that oﬀer relatively precise location informa-
tion, while considering the cost beneﬁts. FM localisation method, described thus
far, is such technology that can give rise to a number of interesting applications.
Applications that make use of localisation can be found in the realm of social
sciences, amongst other domains. Localisation can be utilised to infer mobility
patterns of users. A study, described in [29], tracked location of 100.000 mobile
phones. Analysis of the data revealed that users have predictable mobility be-
haviour patterns, which authors were able to infer by analysing only half of the
data collected. However, this study was limited since location data was based on
GSM localisation, thus had a low granularity, typical of a GSM cell tower range.
FM localisation will allow analysis of data that has much higher localisation
granularity, by simply utilising a mobile phone with built-in FM receiver. This
information then can be used, not only to infer mobility patterns, but by using
the concept of group location, the social network of a user can also be deduced. In
other words FM localisation method will allow inference of human relationships,
for example colleagues that spent time in the same oﬃce, through analysis of
sub-room mobility patterns.
Naturally, localisation technology is applicable to a number of other domains,
including health care, where it can be used to aid elderly locate misplaced objects
(such as their mobile phone), or even deliver location dependent reminders -
locking the front door when entering the house for instance. These applications
can be enabled by a low-cost, sub room location solution, which FM positioning
is able to provide.
6
Conclusion
This paper presented the FINDR, an indoor positioning system based on FM
radio technology. The system is a low-cost solution that does not require any

FINDR: Low-Cost Indoor Positioning Using FM Radio
25
specialised hardware, thus is easily deployable. FM transmitters, used as beacons,
are easily available in the most of electronics shops. Virtually any cellphone or
PDA, with an embedded FM tuner can be used as a client device. FM receiver
is by an order of magnitude more power-eﬃcient than Wi-Fi. The preliminary
results of the system evaluation show a median accuracy of about 1.3 m and
4.5 m at 95% conﬁdence level that is favourably comparable to other state-of-
the-art positioning systems.
In the future we plan to conduct a more comprehensive evaluation of FINDR
using probabilistic classiﬁers and perform a same-environment comparison with
other positioning systems. These results will be applied to a number of previously
described application domains.
References
[1] Hightower, J., Borriello, G.: Location systems for ubiquitous computing. Com-
puter 34(8), 57–66 (2001)
[2] TDA7088 Datasheet (1996)
[3] Broadcomm
BCM4326
Single-Chip
IEEE
802.11b/g
MAC/baseband/radio
Datasheet (2006)
[4] Priyantha, N.B., Miu, A.K.L., Balakrishnan, H., Teller, S.: The cricket compass for
context-aware mobile applications. In: Proceedings of the 7th Annual International
Conference on Mobile Computing and Networking, pp. 1–14. ACM Press, New
York (2001)
[5] Fox, D., Hightower, J., Liao, L., Schulz, D., Borriello, G.: Bayesian Filtering for
Location Estimation. IEEE Pervasive Computing (2003)
[6] Liao, L., Fox, D., Hightower, J., Kautz, H., Schulz, D.: Voronoi Tracking: Location
Estimation Using Sparse and Noisy Sensor Data. In: Proceedings of the IEEE/RSJ
International Conference on Intelligent Robots and Systems (IROS 2003) (2003)
[7] Hightower, J., Borriello, G.: Particle Filters for Location Estimation in Ubiquitous
Computing: A Case Study. In: Davies, N., Mynatt, E.D., Siio, I. (eds.) UbiComp
2004. LNCS, vol. 3205, pp. 88–106. Springer, Heidelberg (2004)
[8] Bahl, P., Padmanabhan, V.N., Balachandran, A.: Enhancements to the RADAR
User Location and Tracking System. Technical Report MSR-TR-2000-12, Mi-
crosoft Research, Redmond, WA, USA (2000)
[9] Youssef, M.A., Agrawala, A., Shankar, A.U.: WLAN location determination via
clustering and probability distributions. In: Proceedings of the 1st IEEE Interna-
tional Conference on Pervasive Computing and Communications (PerCom), pp.
143–150 (2003)
[10] Varshavsky, A., de Lara, E., Hightower, J., LaMarca, A., Otsason, V.: GSM indoor
localization. Pervasive and Mobile Computing 3(6), 698–720 (2007)
[11] Kotanen, A., H¨annik¨ainen, M., Lepp¨akoski, H., H¨am¨al¨ainen, T.D.: Experiments on
local positioning with Bluetooth. In: Proceedings of the International Conference
on Information Technology: Coding and Computing (ITCC 2003), pp. 297–303
(2003)
[12] Patel, S.N., Truong, K.N., Abowd, G.D.: PowerLine Positioning: A Practical Sub-
Room-Level Indoor Location System for Domestic Use. In: Dourish, P., Friday, A.
(eds.) UbiComp 2006. LNCS, vol. 4206, pp. 441–458. Springer, Heidelberg (2006)

26
A. Papliatseyeu et al.
[13] Stuntebeck, E.P., Patel, S.N., Robertson, T., Reynolds, M.S., Abowd, G.D.: Wide-
band powerline positioning for indoor localization. In: Proceedings of Ubicomp
2008 (2008)
[14] Krumm, J., Cermak, G., Horvitz, E.: RightSPOT: A Novel Sense of Location
for a Smart Personal Object. In: Dey, A.K., Schmidt, A., McCarthy, J.F. (eds.)
UbiComp 2003. LNCS, vol. 2864, pp. 36–43. Springer, Heidelberg (2003)
[15] Bulusu, N., Heidemann, J., Estrin, D.: GPS-less low-cost outdoor localization for
very small devices. Personal Communications, IEEE 7(5), 28–34 (2000)
[16] Hallberg, J., Nilsson, M., Synnes, K.: Positioning with Bluetooth. In: Proceedings
of 10th International Conference on Telecommunications (ICT 2003), 23 February–
1 March 2003, vol. 2, pp. 954–958 (2003) doi:10.1109/ICTEL.2003.1191568
[17] LaMarca, A., Chawathe, Y., Consolvo, S., Hightower, J., Smith, I., Scott, J.,
Sohn, T., Howard, J., Hughes, J., Potter, F., Tabert, J., Poweldge, P., Borriello,
G., Schilit, B.: Place Lab: Device Positioning Using Radio Beacons in the Wild.
In: Gellersen, H.-W., Want, R., Schmidt, A. (eds.) PERVASIVE 2005. LNCS,
vol. 3468, pp. 116–133. Springer, Heidelberg (2005)
[18] Laasonen, K., Raento, M., Toivonen, H.: Adaptive On-Device Location Recogni-
tion. In: Ferscha, A., Mattern, F. (eds.) PERVASIVE 2004. LNCS, vol. 3001, pp.
287–304. Springer, Heidelberg (2004)
[19] US Department of Defence. GPS SPS Performance Standard. (September 2008),
http://www.navcen.uscg.gov/gps/geninfo/
2008SPSPerformanceStandardFINAL.pdf
[20] Bahl, P., Padmanabhan, V.N.: RADAR: an in-building RF-based user location
and tracking system. In: Proceedings of 9th Annual Joint Conference of the IEEE
Computer and Communications Societies (INFOCOM 2000), March 26-30, 2000,
vol. 2, pp. 775–784 (2000) doi:10.1109/INFCOM.2000.832252
[21] Roos, T., Myllym¨aki, P., Tirri, H., Misikangas, P., Siev¨anen, J.: A Probabilistic
Approach to WLAN User Location Estimation. International Journal of Wireless
Information Networks 9(3), 155–164 (2002)
[22] Honjo, K., Simpson Jr., D.L.: Stereo FM receiver, noise control circuit therefor.
US Patent 5432854 (July 1995)
[23] Leentvaar, K., Flint, J.H.: The capture eﬀect in FM receivers. IEEE Transactions
on Communications 24, 531–539 (1976)
[24] http://www.create-net.org/mise
[25] http://www.koniggaming.com/mp3withfmtransmitter.html
(as
accessed
on
2009.02.19)
[26] JPL’s Wireless Communication Reference Website. Analog Transmission over Fad-
ing
Channels,
http://www.wirelesscommunication.nl/reference/chaptr05/
analog/analog.htm (as accessed on 2008.11.20)
[27] Mitchell, T.: Machine Learning. McGraw-Hill, New York (1997)
[28] Kaemarungsi, K.: Distribution of WLAN Received Signal Strength Indication for
Indoor Location Determination. In: Proceedings of the 1st International Sympo-
sium on Wireless Pervasive Computing, pp. 1–6 (2006)
[29] Smith, K.: Mobile phones demystify commuter rat race. Nature News, June 4
(2008)

C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 27–42, 2009. 
© Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009 
IEEE 802.21 Assisted Seamless and Energy Efficient 
Handovers in Mixed Networks 
Huaiyu Liu1, Christian Maciocco1, Vijay Kesavan1, and Andy L.Y. Low2 
1 Communication Technology Lab, Corporate Technology Group,  
Intel, Hillsboro, OR 97124 
{huaiyu.liu, christian.maciocco, vijay.s.kesavan}@intel.com 
2 BT Innovate, Malaysia Research Center, Kuala Lumpur, Malaysia  
andy.low@bt.com 
Abstract. Network selection is the decision process for a mobile terminal to 
handoff between homogeneous or heterogeneous networks. With multiple 
available networks, the selection process must evaluate factors like network 
services/conditions, monetary cost, system conditions, user preferences etc. In 
this paper, we investigate network selection using a cost function and 
information provided by IEEE 802.21. The cost function provides flexibility to 
balance different factors in decision making and our research is focused on 
improving both seamlessness and energy efficiency of handovers. Our solution 
is evaluated using real WiFi, WiMax, and 3G signal strength traces. The results 
show that appropriate networks were selected based on selection policies, 
handovers were triggered at optimal times to increase overall network 
connectivity as compared to traditional triggering schemes, while at the same 
time the energy consumption of multi-radio devices for both on-going 
operations as well as during handovers is optimized.  
Keywords: IEEE 802.21, Mixed Networks, Heterogeneous Handovers, Energy 
Efficient Handovers.  
1   Introduction 
Wireless connectivity is becoming pervasive in our life. IEEE 802.11 a/b/g, IEEE 
802.16, 3G and other radios are reaching price points, sizes and power consumption 
levels that allow for their inclusion in almost every mobile device. Due to their widely 
varied characteristics, no single wireless access technology can simultaneously 
provide a low-latency, high-bandwidth and wire-area data service to a large number 
of mobile users. One solution is to use a combination of multiple access technologies 
to provide the best possible connectivity. A future mobile terminal will be equipped 
with several network access interfaces, and switches between these interfaces 
depending on its physical environment and requirements. We refer to this multi-radio 
usage as Mixed Networking (MxN), where vertical handoff [1][2] (roaming across 
heterogeneous access technologies) is one of the most important features. 
Traditionally, network selection has been based on evaluation of the received 
signal strength (RSS): e.g. an access point with the strongest RSS is selected. In MxN, 
such physical characteristics are usually not directly comparable. Besides, we need to 

28 
H. Liu et al. 
consider additional factors such as monetary cost, power consumption, network 
conditions, terminal conditions, and user preferences. In [1], multi-radio architectural 
issues were explored, and a neural-network-based network selection algorithm was 
developed to satisfy user bandwidth requirements. In [3], a policy-enabled handoff 
decision algorithm is proposed along with a cost function that considers several of the 
factors mentioned above. Further, several optimizations to the handoff decision 
process are proposed in [4][5]. While significant work has been done on network 
selection initiated on the mobile device side, there is no literature available describing 
how mobile devices and network operators can cooperate to achieve an optimal 
network selection in a deployable approach. This is an area where the 802.21 standard 
[6] will facilitate the exchange of information between these entities to enable the 
mobile device to obtain relevant network information, including link layer triggers or 
higher layer information elements.  
In this paper, a cost-function-based network selection architecture assisted by the 
802.21 standard is investigated. Such an algorithm is flexible and can take into account 
the relevant factors with minimal user involvement. 802.21 is defining a generic media-
independent-handoff (MIH) framework to support information exchange between 
network elements that support network selection, as well as a set of functional 
components to execute the roaming process. The 802.21 event service provides early 
indication of upcoming lost connectivity, therefore enabling pro-active action for 
network selection and a smoother handoff. The 802.21 information service provides 
data that enable a mobile client to optimize networks scanning frequency and enable 
energy efficient network selection. To the best of our knowledge, there has been no 
work on using 802.21 to optimize network selection in an energy efficient manner using 
real environment data. We show in this paper that using additional information provided 
by 802.21, we can achieve significant energy efficiency improvement for mobile 
devices without significant overhead. Using prediction of loss of network connectivity 
we show that session continuity is also improved.  
The rest of the paper is organized as follow. In Section 2, the background of this 
research, our handoff system architecture and its elemental technologies are 
explained. In Section 3, our network selection architecture assisted by IEEE 802.21 is 
discussed in detail, and evaluated in Section 4, using a multi-radio system and usage 
scenario (Wi-Fi, WiMAX, and HSDPA). Finally, we conclude in Section 5.  
2   Background and Related Work 
2.1   IEEE 802.21 Media Independent Handover 
There are currently various efforts underway in standard organizations and industry 
forums to standardize heterogeneous handovers, including IEEE 802.21 [7] and 3GPP 
SA WG2 [14]. For instance, IEEE 802.21 specifies three media-independent services: 
event service, command service, and information service. 
Media-Independent Event Service (MIES) indicates changes in state and 
transmission behavior of the physical, data link and logical link layers, or predict state 
changes of these layers. Events defined include Link-Parameters-Change, Link-Up 
(LU), Link-Down (LD), Link-Going-Down (LGD), etc. LGD may be used by upper 

 IEEE 802.21 Assisted Seamless and Energy Efficient Handovers in Mixed Networks 
29 
layer entities, such as Multi-radio Connection Manager, to search for a new point of 
attachment before the current one ceases to carry frames, thus reduce the handover 
delays between attachment points. 
Media-Independent Command Service (MICS) defines a set of primitives or 
handover commands that allow clients and/or networks to initiate and coordinate the 
handover process from one network to another. 
Media-Independent Information Service (MIIS) provides a data store of available 
networks and network parameters, and defines standard query/response messages to 
access and retrieve such information for each available access network. Such 
information is critical for the handover process. For instance, the information of 
available networks is very useful for optimizing the network selection process. 
2.2   Mixed Network Architecture 
On the client side, the vertical handover process can be classified into three steps, i) 
“when and why” should the device transition to a new network, ii) “where” should the 
device transition to, and iii) “how” should the device transition between networks? 
The “when and why” step corresponds to what we describe as the triggering process 
when the mobile device receives an indication that it should operate on another 
network. This indication can be generated by external condition such as signal 
degradation, by device level condition such as critical battery level requiring a switch 
to a more energy efficient network, or be user initiated. The “where” step is when the 
mobile device selects on which network to operate, either on a similar network type (a 
homogeneous network) where a link layer transition is sufficient, or on a 
heterogeneous network where both network and service transitions need to be 
performed. The last step, the “how” is defining the execution of the handover and 
how the device performs the transition, e.g. either doing a horizontal handover to 
transition to a similar network or a vertical handover using techniques like break-
before-make or make-before-break. 
Intel and BT have collaborated to prototype a WiFi/WiMax multi-radio system in 
the BT 21CN environment [7]. Figure 1 shows the high level architecture of the 
prototype at the client side, which we refer to as the MxN architecture. Applications 
can use the services provided by the MxN system through the MxN interface. These 
services include 802.21 MIH services, connection management and network adaptor 
management. Applications such as VPN and SIP-based applications that are not 
capable of switching across adaptors can use the connection management service. 
Connection managers from other parties can use the MIH and adaptor management 
services alone and handle connection management themselves. The MxN architecture 
also defines an adapter control layer that spans across various adapters and provides 
the ability to interface with the adapters. To handle session mobility we used SIP for 
the session initiation and control protocol. 
For the function blocks inside the MxN system, the Smart Triggers block addresses 
the “when and why” step in a handover, and provides the mechanism to monitor 
changes to MAC and PHY state, including link triggers. The Information Exchange 
block interfaces with Information Server (in the networks), retrieve network 
information, and provide it to the Network Selection engine, which then chooses the 
best network to operate on. Together these two address the “where” step. Finally, the 
Network Switching module work closely with SIP to address the “how” step. 

30 
H. Liu et al. 
INTC Driver
SIP 
Apps
Connection 
Management
TPV Driver
SIP
UMA
Legacy Apps
Intel 
WLAN / WiMax
TPV
Cellular
Network/Transport
MIP
Access Authentication
P-MIP
 
Fig. 1. MxN Architecture 
The work in this paper focuses on the Network Selection module and the 
Information Exchange & Location Management module. 
2.3   Smart Handover Trigger 
We have developed a smart trigger scheme [8]. The purpose of the smart trigger 
scheme is to provide accurate and predictive link layer triggers to enable seamless 
handovers and minimize service interruption. It addresses how to detect link status 
changes (e.g. Link-Going-Down) and how to accurately predict such changes. The 
ability to predict link triggers accurately and early in time, especially the Link-Going-
Down and Link-Down triggers, will send early warnings to entities such as 
connection managers and give it extra time to prepare for handover and seamlessly 
transfer application sessions, hence further reduce the service interruption. 
In the smart trigger scheme, we used signal strength to reflect link quality, such as 
RSSI for WiFi networks and CINR for WiMax networks. For trigger generation, we 
first apply an exponential moving-average filter to smooth out raw RSSI measurements 
that fluctuate, then compare the smoothed RSSI to predefined thresholds and generate 
link triggers when necessary. The smart trigger scheme also includes a trigger prediction 
step. A link trigger is predicted based on predicted future (smoothed) RSSI values using 
a long as well as short history window. Then trend analysis algorithm is used to analyze 
the long and short term trends of RSSI. Evaluation and implementation of the algorithm 
based on real WiFi and WiMax devices demonstrate that our algorithms provide early 
and accurately prediction. In Section 4, we will also analyze the performance benefits 
for network selection by using different triggering schemes. 
2.4   Cost-Function-Based Media Independent Handover 
A policy–based network selection algorithm with a cost function is first introduced in 
[3] and several optimizations to the algorithm and cost functions are proposed in 
[4][5]. As described in [4], in MxN, the network with the lowest cost is the network 

 IEEE 802.21 Assisted Seamless and Energy Efficient Handovers in Mixed Networks 
31 
that would provide the most benefit to the user and is the optimal handoff target, 
n_opt, which is determined as follows: 
)
,...,
,
min(
_
2
1
n
C
C
C
opt
n
=
 
where Cn  is the cost function evaluated for network n. Cn  includes the cost of 
receiving each of the user’s requested services from network n, and it is calculated: 
Cn =
Cs
n
∑
, where 
.
n
s
n
s
n
s
Q
E
C
=
 
Here s is the index representing the user-requested services, Cs
n is the per-service 
cost function for network n, Es
n  is the network elimination factor for requested 
service s at network n, and Qs
n is the QoS factor for service s at network n. Es
n is 
used to filters out networks that cannot guarantee the QoS constraints expected by a 
service. Qs
n is calculated as follows: 
Qs
n =
Ws, j
n Qs, j
n ,
j∑
 
where Qs, j
n  is the normalized QoS provided by network n for parameter j for service 
s, and Ws, j
n  is the weight indicating the impact of the QoS parameter on the user or 
the network. 
According to [3], the natural log is used as the normalization factor. If a network 
offers twice as much bandwidth, but is twice as expensive as the other network, then 
they are considered these as equally good (this means they have the same cost). The 
property of logarithm 
)
/
log(
log
log
b
a
b
a
=
−
 can reflect this logic. 
For example, a cost to use network A, CA, is calculated as below. This is when 
only bandwidth, delay, and power consumption are in consideration, and network A is 
abstracted as 1Mbps, 10ms, 900mW. Additionally, weights on bandwidth, delay, and 
power are assigned 0.5, 0.1, 0.4, respectively. 
502661
.0
   
)
900
ln(
4.0
)
10
ln(
1.0
)
1000
1
ln(
5.0
−
=
+
+
=
A
C
 
In the past, cost functions only consider traditional network properties like 
bandwidth, delay and power. With 802.21, we now have the ability to also consider 
the physical location of networks, the services offered by these networks, security 
requirements, etc, which can be used to optimize the network selection process. 
3   IEEE 802.21 Assisted Network Selection 
The cost function and the elimination function together enable network selection and 
are integrated in the MxN architecture (Section 2.2) as shown in Figure 2. The 
inputsto the network selection block can be broadly classified as (i) a comprehensive 
list of networks (ii) network commands and (iii) network and device conditions. The 
network selection logic considers these inputs in the context of user preferences and 
 

32 
H. Liu et al. 
 
Fig. 2. MxN Network Selection Architecture 
policies, resulting in an ordered list of networks for connectivity. In this paper we 
explore how the primitives defined in 802.21 can be used with the cost-based function 
to select a network in an energy efficient way. 
The criteria that govern the selection of one network over another in MxN are 
policies. The policies include several parameters like monetary cost, bandwidth, 
latency, power etc to which weights can be associated to indicate importance of one 
parameter over another. The policies can be configured by the user, e.g. always 
connect to the network that offers highest bandwidth; set by the network operator, e.g. 
when home network is unavailable only connect to the operators who have roaming 
agreements; or requested by applications running on the mobile device. The first step 
in network selection is the discovery of networks. A rudimentary way of network 
discovery is periodic scanning on all the radios in the device. However, scanning is a 
power intensive process. Usually network discovery is optimized by building a local 
repository of previously visited and scanned networks. Most modern mobile device 
support GPS capability, which can be used to store network coordinates. While this 
optimization reduces periodic scans in previously visited locations, scanning cannot 
be avoided in new locations. 802.21 MIIS provides a repository of networks and their 
static parameters. Using a standardized query/response mechanism, devices can 
retrieve information about different networks using any network interface to build a 
network map. The ability of discovering new networks, independent of the connected 
media, minimizes scanning operation on network interfaces and the time for these 
interfaces to remain in the ON state, therefore extending the battery life. Figure 3 
compares state machines of the scanning operations, with and without MIIS service. 
If the network map from MIIS indicates there are no networks in the vicinity the radio 
need not be turned ON for scanning. If the network map indicates the presence of a 
network, the elimination function checks to see if the network’s parameters, as 
provided by MIIS service, satisfies all the policies and only then is the network 
considered as a potential candidate in network selection. Thus the information from 
MIIS along with the elimination function is able to further reduce scanning operations 
and improve the battery life of the device. 
 

 IEEE 802.21 Assisted Seamless and Energy Efficient Handovers in Mixed Networks 
33 
 
Fig. 3. Scanning and Radio-On-Time Optimization 
The network selection process is triggered by any of the following events: (i) the 
physical location of the mobile device changes and new networks discovered using 
MIIS, (ii) current network conditions change as indicated by MIES, (iii) device 
receives handover command from the network, and (iv) policy changes initiated by 
user, application or operator. The focus of our research is to obtain network maps 
from MIIS service and detect link-going-down by implementing MIES functions, and 
provide this information to the elimination-based cost function to enable energy 
efficient handover.  
4   Evaluation 
4.1   Network Selection Simulator 
In order to evaluate different network selection algorithms, we have implemented a 
network selection simulator. The architecture of the simulator is shown in Figure 4. 
The simulator consists of three main components: Network Selector (with cost 
function), Access Network, and Mobile Node. Network selector implements the 
network selection algorithm, where information used in the algorithm is obtained 
from the other components. It also implements the cost function to calculate the cost 
 
 
Fig. 4. Simulator architecture 

34 
H. Liu et al. 
Table 1. Implemented features in the simulator 
Feature 
Description 
Moving average (50 RSSIs window) 
Trigger 
Smart Trigger (Exponential average) 
Smart Trigger (Exponential average with prediction) 
Static Preference (WiFi>WiMax>3G) 
Network Selection 
Cost Function 
of each access network regarding the current conditions of the Mobile Node. Mobile 
Node provides conditions such as the name of the current network, status (during 
communication, scanning, or handoff), and static information (number of handoff, 
number of scanning, etc.). Access Network provides conditions of available networks, 
where signal strength and AP load histories were considered in the simulations. 
Finally, MIIS inputs provides network information that could be obtained from MIIS 
service. For each simulation, we recorded the number of handoffs, number of scans, 
and radio duty cycle. We have implemented three trigger methods and two network 
selection algorithms as listed in Table 1.  
The simulations were based on a scenario that a user living in a suburban area goes 
to his office in a city area, as shown in Figure 5(a), where each circle represents the 
approximate coverage area of each network along the route. RSSI/CINR traces as the 
user travels from home to office are shown in Figure 5(b), where x axis is the time, 
and y axis is the RSSI/CINR value the users device would see in the corresponding 
time. Network 1 is a Wi-Fi network at home. Network 2 is an HSDPA based 3G 
networks which covers the entire route. Network 3 and Network 4 are WiMax 
networks that cover the city area. Network 5, 6, 7, and 8 are office Wi-Fi networks. 
The assumption is that the trip from home to office takes 30 minutes. 
The RSSI and CINR traces shown in Figure 5(b) were collected from real 
networks. The RSSI traces for Networks 5 to 8 were collected by walking inside Intel 
office buildings with a laptop equipped with Intel 3965 wireless card. The RSSI trace 
for Network 1 was collected by walking from inside to outside of a house, using the 
same laptop. The CINR traces for WiMax networks were collected driving in field 
trials where WiMax base stations were deployed (Hillsboro, OR). Similarly, the 3G 
(HSPDA) RSSI trace was obtained by driving along a route in Hillsboro, OR, using a 
 
 
Fig. 5. (a) Network coverage, and (b) the RSSI/CINR trace of each network used in simulations 

 IEEE 802.21 Assisted Seamless and Energy Efficient Handovers in Mixed Networks 
35 
laptop with a Sierra Wireless card connecting to AT&T network. We assume the 
mobile device is a phone type of device and it always maintains its connection to 
cellular networks for phone calls. However, for data transmission, it needs to choose 
the most appropriate networks, where the network selection is applied. 
In our simulation, AP (or BS) load is defined as total traffic currently served by an 
AP. The traces of AP loads are generated for each network based on a Markov 
Modulated Poisson Process [9]. In practice, AP load can be estimated or obtained in 
several ways. For example, AP load in WiFi network could be obtained if APs 
support 802.11k, or by using methods as proposed in [10]. Estimation of cellular or 
WiMax networks might be done considering the modulation and coding scheme a BS 
supports, as well as the received signal level on the broadcast channel, the carrier-to-
interference power ratio ("C/I"), and the raw BER estimate [11]. 
The cost function used in the experiments is as follows: 
C
W
P
W
B
W
C
ln
ln
1
ln
C
P
B
+
+
=
 
where B denotes available bandwidth, P the power, and C the monetary cost. 
In our simulations, to get the available bandwidth of an AP or BS, we subtracted 
the AP’s load from the highest data rate that can be provided by the network (this 
information could be provided by MIIS service). For WiFi networks, we assume they 
are 802.11b APs with 11 Mbps data rate; for WiMax, we assume 30 Mbps data rate 
(the data rate depends on the modulation scheme, the coding scheme, etc [12]); and 
for 3G, we assume 1.2 Mbps data rate. Effectively estimating available bandwidth is 
an active research area and beyond the scope of this paper. 
For monetary cost, we assume that WiFi is of flat cost (a fixed monthly fee), while 
costs for WiMax and 3G access are based on the amount of bytes transmitted through 
that network; and we assume that WiMax costs somewhat less than 3G. (In practice, 
the monetary costs could be different, for instance, WiFi may cost a lot higher when 
the user is in a hotel.) For power consumption, studies have shown that 3G card 
consumes more transmit power than WiFi card [13], partly due to the long radio 
range. For the same reason, we assume that WiMax redio consumes higher power 
than WiFi in transmission (but less than 3G). 
4.2   Performance Analysis 
Our ultimate goals for network selection and seamless handover are to select the most 
appropriate network, optimize for energy efficiency, and switch at the best timing. In 
this section, we evaluate our algorithms in each aspect of the goals. 
4.2.1   Network Selection 
To study the effectiveness and flexibility of cost-function-based network selection, we 
run experiments with different weights for each factor in the cost function. Figure 6 
and Figure 7 show some snapshots of network selection in areas that were under 
coverage of all three networks. 
Figure 6 shows some results where the weight of one of the parameters in the cost 
function was assigned 1. The number on each bar is the cost as calculated using the 
 

36 
H. Liu et al. 
 
Fig. 6. Network selection, (a) WC = 1, (b) WB=1 
 
Fig. 7. Network selection, (a) WB = 0.1, WP = 0.9 (b) WC=0.1, WP=0.9 
cost function. The solid bar represents the network selected after applying the cost 
function. In Figure 6(a), the weight of monetary cost is assigned 1 and the WiFi 
network was selected. In Figure 6(b), the weight of bandwidth is assigned 1, and the 
WiMax network was selected. The results in this figure demonstrate that with certain 
weight assignments, cost function enables similar selection as using a static network 
selection method. 
Figure 7 shows some results where different weights were assigned to different 
factors. In both experiments, the weight of power is assigned 0.9. In the experiment in 
Figure 7(a), the weight of bandwidth was 0.1, while in Figure 7(b), the weight of 
monetary cost was 0.1. Hence, in both experiments, power is the utmost factor in 
selecting an access network, yet the selection in Figure 7(a) should result in higher 
potential available bandwidth and the selection in Figure 7(b) should result in lower 
monetary cost. As we can see from Figure 7, WiMax was selected in the first 
experiment, while WiFi was selected in the second experiment (recall that both are 
more power efficient than 3G). The results demonstrate the flexibility of cost function 
to take different factors into consideration. 
Figure 8 shows the results of network selection along time in two simulations that 
have different weight settings. The top one has the settings of “max battery life” 
(more weight was given to the power factor), while the bottom one has “max 
throughput” (more weight was given to the bandwidth factor). Due to the limited 
coverage of WiFi/WiMax networks as in Figure 5(a), choices of network selection 
were limited to one or two networks in some time of each simulation. For instance, in 
the first 2 minutes, only Network 1 (WiFi) and Network 2 (3G) were available, in the 
next 6-7 minutes, only Network 2 was available. Hence, the selected networks in the 
two diagrams in Figure 8 look similar in many time points. However, the times that 
 

 IEEE 802.21 Assisted Seamless and Energy Efficient Handovers in Mixed Networks 
37 
 
Fig. 8. History of active network for different settings of cost function 
 
Fig. 9. Average bandwidth comparison for different settings of cost function 
Networks 3 and 4 were selected were different. In the “max throughput”, Network 4 
was selected earlier than in the “max battery life”, due to higher estimation of AP 
available bandwidth of Network 4 than that of Network 3. 
To demonstrate that the selections in the “maximize throughput setting” resulted in 
higher available bandwidth, we plotted the average available bandwidth in both 
settings, as shown in Figure 9. (Recall that the available bandwidth was calculated as 
the amount of highest possible data rate minus AP load). As we can see from the 
figure, by making different selections between Network 3 and Network 4, the average 
available bandwidth (averaged across the entire 30 minutes of simulation) in the “max 
throughput setting” is higher that the other setting. 
4.2.2   Energy Efficient Network Selection with MIIS 
Applying MIIS support can reduce both handoff delay (by reducing the time for 
network discoveries) and power consumption during network selection. In this 
section, we focus on studying the power saving benefit by applying MIIS. 
As explained before, the operation in the network selection process that consumes 
the most power is scanning for available networks and obtaining necessary 
information. Typically, without MIIS optimization, to discover and obtain network 
information in time, WiFi networks are scanned once a minute (e.g. every minute 
Windows ZeroConfig queries driver for network update), and cellular networks are 
 

38 
H. Liu et al. 
Table 2. Average platform power increase due to periodic scan, based on measurements on 
Ultra Mobile PC 
Radio type 
Mobile device’s power consumption increase when 
radio periodically scans for networks before 
connection is established (averaged across time) 
WiFi 
100mw 
Cellular  
200mw-600mw 
WiMax 
100mw-300mw 
scanned every 30 seconds to 1 minutes until a connection is established. With MIIS, 
however, a mobile device only needs to scan a network if it is in its coverage area and 
has access to such a network. For example, the device needs to scan for WiFi 
networks only when it is in WiFi coverage and has access to at least one of the WiFi 
networks in range. (To identify network coverage, the device needs to know its 
location. The location could be obtained by the cell tower technology provided by 
cellular networks. It could also be obtained by using a GPS radio, however, 
continuously using GPS radio consumes significant power). Our measurements 
indicated that if the WiFi radio goes to low power mode after each scanning, then 
when WiFi radio scans every minute, on average a mobile device’s (e.g. an Ultra 
Mobile PC) power consumption increased by about 100mw over time. When cellular 
radio scans every minute, the device’s power consumption increased 200 to 600mw 
(power consumption varies with different radio chipsets). For WiMax, our 
measurements indicate 100 to 300mw increase of platform power. Hence, significant 
amount of power would be saved by disabling scanning or even turning off radio, if it 
is known that a radio is out of the coverage of accessible networks. 
To evaluate the energy savings enabled by applying MIIS service, we assume that 
for each radio, the scanning power is the same when it is connected to a network or 
not.1 Also, since we assume that 3G is always available in the simulation setup, and 
the mobile device maintains the 3G network connection all the time, we only compare 
the scanning power consumptions for WiFi and WiMax radio below. As shown in 
Figure 10(a), without MIIS service, the radio has to remain on and scan for networks 
all the time (although it may go to low power state after each scan), in order to obtain 
information for network selection. With MIIS service, when a radio is out of 
coverage, there is no need to turn it on for scanning during that period. Hence the 
radio-on time is greatly reduced especially when networks are far less than 100% of 
coverage. Figure 10(b) shows that by turning off a radio, the proportion of scanning 
power has been saved. For WiMax, since 40% of time the mobile device was out of 
coverage, at least 40% percent of scanning power could be saved; and for WiFi, 86% 
of scanning power could be saved. 
 
                                                           
1 This might not always be the case in real implementations. Once a device is connected, 
scanning process to update network information can be provided by current network, and 
hence could cost less power than when the radio is not connected. Note that in this case, 
majority of scanning power is consumed when a radio is not connected, hence the proportion 
of scanning power saved by applying MIIS would be even higher than the results in Figure 
10(b). 

 IEEE 802.21 Assisted Seamless and Energy Efficient Handovers in Mixed Networks 
39 
 
Fig. 10. Power saving benefit by applying MIIS 
 
Fig. 11. Energy overhead of MIIS querying for 1 hour 
Therefore, MIIS optimization is especially useful when there is a significant 
portion of time that a device is out of coverage of some networks. Network coverage 
varies a lot depending on where people live, their daily commute pattern, etc. By 
collecting traces from different people’s daily life, a recent study [13] shows that on 
average, 49% of time a person is within WiFi coverage. In the future, it is still 
unlikely that WiFi coverage will be 100%. WiMax and 3G have better coverage, 
however, right now they are much less than 100% of coverage and will likely to 
remain under 100% at least in the near future. Hence, by applying MIIS optimization, 
significant amount of power could be saved by avoiding unnecessary scanning. 
On the other hand, there is some overhead associated with MIIS optimization. 
Querying for and retrieving MIIS information also consumes power. In order to 
evaluate this energy overhead, we did some empirical experiments in which a Sony 
UMPC (VAIO UX280P), with Windows XP installed, is connected with a WiFi AP 
and a laptop serving as the MIIS server was also connected to the AP. We did two 
sets of experiments. In one set, the UMPC simply stayed connected to the AP and 
remained idle. In the other set of experiment, the UMPC queried 100KB of MIIS 
response every 5 minute. Note that 100KB of MIIS response carries more than 2000 
Wi-Fi APs information. The average remaining battery capacities from each set of 
experiments are plotted in Figure 11. As we can see, the average power consumption 
by querying MIIS information every 5 min is about 10mw, much lower comparing to 
that of periodic scanning.2 We also did experiments of pulling 1000KB of MIIS 
                                                           
2 The power consumption for fetching MIIS information with 3G or WiMax radios could be 
slightly higher, since communication range of these radios is longer and hence transmission 
power is higher. 

40 
H. Liu et al. 
responses every 5 minutes. The average power consumption was similar. In reality, 
MIIS information could be pulled less often, and each time with a slightly large 
amount of response (say every 30 minutes of 1000KB responses instead of every 5 
minutes of 100KB), and hence further reduce the corresponding power consumption. 
Note that in reality, the MIIS server is more likely to be multiple hops away from a 
mobile device, since such server usually resides inside some network. However, more 
hops only increase the delay in receiving the responses, and since the mobile device’s 
radio could go to low power mode while waiting for the response, the power 
consumption would not increase much due to longer delays. 
4.2.3   Triggering Methods Comparison 
Finally, we study the triggering time of handovers and its impacts on quality of 
connections. As implemented by most WiFi drivers, a handover trigger is generated if 
the average signal strength is below a threshold, where the average value is obtained 
by averaging across the past signal strength measurements. We refer to this method as 
the “average” method. 
In our handover algorithm design, we applied our smart trigger scheme to initiate a 
handover process. The objective of smart trigger is to provide early and accurate 
indication to a Connection Manager (CM) and hence gives the CM enough time to 
discover surrounding networks, select the most appropriate one, and establish 
connection on that network before the current network’s quality goes too bad (i.e. to 
enable make-before-break). In this section, we present some results that demonstrate 
the advantage of the smart trigger scheme over the traditional average method. We 
use the metric “link-up time” to measure the quality of connections. By link-up time, 
we mean the amount of time that the signal strength of the current connection is above 
a certain Link-Down threshold, for instance, -80dB for WiFi networks, -110dB for 
cellular networks, and 0 (CINR) for WiMax networks. The longer the link-up time, 
the better the quality of connections is. 
Figure 12 highlights the connection and signal quality of the current network from 
simulation time 70s to 100s during one simulation. For each time point, if the current 
selected network was in link-up status (that is, the signal strength is above the Link-
Down threshold), a point was plotted in the figure. In other words, gaps between the 
points indicate the signal quality during that period was below a minimum threshold 
to maintain connectivity. The top graph in Figure 12 shows that around time 76s, the 
device switched from WiFi to 3G network. On the contrary, in the bottom graph, 
where the traditional average method was used for handover triggering, the device did 
not switch from WiFi to 3G until around 91s. As we can see, in the bottom figure, 
from 76s to 91s, there were many gaps between the points, indicating more time of 
bad signal quality before handover happened. 
Figure 13(a) shows the total link-up time from the same experiment. Similar trend 
was observed in other experiments. Among the 1800s of total simulation time, using 
the average method for handover triggering resulted in 1759 sec of connected time, 
while using the smart trigger method resulted in 1778 sec of link-up time. Clearly, the 
smart trigger method provides the benefit of fast and accurate prediction of link 
quality and enables handover to a different network before link quality becomes too 
bad. Note that differences between link-up times are due to the triggering time of 
handovers. The handover itself, although may introduce some short time interruption 
between connections, does not contribute to the link-up time as we defined above. 
 

 IEEE 802.21 Assisted Seamless and Energy Efficient Handovers in Mixed Networks 
41 
 
Fig. 12. Trigger Methods Comparison (70s-100s): “Smart Triggering” (Exponential Average 
with Prediction) vs. “Average” 
 
Fig. 13. (a) Total connected time (b) Total connected time comparison with or without MIIS 
optimizations 
This is because handover only happens after it is triggered by the triggering method 
and the handover delays are the same in both cases (as they both switched from WiFi 
to 3G) no matter what trigger method is used. 
Figure 13(b) shows the comparison of total connected time when using and not 
using MIIS service. Together with a trigger method, MIIS could help provide better 
connectivity. This is because unnecessary scanning has been eliminated so that 
service interruptions due to off-channel scanning have also been eliminated. 
5   Conclusion 
For multi-radio devices the overall energy consumption of the device is a key issue as 
the number of radios on these devices increase while at the same time end-users 
expect a seamless connectivity across all radios. To address these issues we have 
developed a flexible network selection architecture to optimize seamless operation as 
well as the energy efficiency of these devices. As a component of this architecture, 
our research on handover triggers providing early indication of connectivity improves 
the seamless aspect by optimizing the connected time. In this paper, starting from a 
known mechanism to perform network selection using a cost function, we enriched 
this mechanism by using additional properties of the mobile devices and access 
networks, provided by an 802.21 Information Server, to optimize the network 
selection for optimal energy efficiency. Under a realistic scenario with real network 

42 
H. Liu et al. 
traces for a multi-radio device, our optimized network selection algorithm showed a 
power saving opportunity of up to 40% for WiMax and 80% for WiFi. The 802.21 
Information Service provides information that enables the device to reduce its 
scanning frequency and optimize the network selection with limited energy overhead. 
We also showed that there is almost negligible energy cost to acquire the required 
additional information from the 802.21 Information Server using an appropriate 
request rate. As a next step, we are integrating this optimized network selection 
algorithm into our existing multi-radio WiFi/WiMax multi-radio prototype. 
 
Acknowledgment. The authors thank Koshiro Mitsuya for his contributions during 
his time in Intel Corporation. 
References 
[1] Pahlavan, K., Krishnamurthy, P., Hatami, A., Ylianttila, M., Makela, J.P., Pichna, R., 
Vallstron, J.: Handoff in Hybrid Mobile Data Networks. Personal Communications 7(2), 
34–47 (2000) 
[2] Stemm, M., Katz, R.H.: Vertical handoffs in wireless overlay networks. Mobile Networks 
and Applications 3(4), 335–350 (1998) 
[3] Wang, H.J., Katz, R.H., Giese, J.: Policy-Enabled Handoffs Across Heterogeneous 
Wireless Networks. In: Proceedings of the 2nd Workshop on Mobile Computing Systems 
and Applications (WMCSA), New Orleans, LA (1999) 
[4] Fang, Z., McNair, J.: Optimizations for Vertical Handoff Decision Algorithms. In: 
Proceedings of IEEE Wireless Communications and Networking Conference (WCNC), 
Atlanta, Georgia (2004) 
[5] Fang, Z., McNair, J.: Multiservice Vertical Handoff Decision Algorithms. EURASIP 
Journal on Wireless Communications and Networking 2006(2), 52–64 (2006) 
[6] IEEE P802.21/D14 (October 2008)  
[7] Choong, K.N., Kesavan, V.S., Ng, S.L., de Carvalho, F., Low, A.L.Y., Maciocco, C.: 
SIP-based IEEE802.21 media independent handover — a BT Intel collaboration. BT 
Technology Journal 25(2) (April 2007)  
[8] Liu, H., Maciocco, C., Kesasvan, V.S., Low, A.: A Smart Triggering Scheme to Reduce 
Service Interruption During Heterogeneous Handovers. In: IEEE International 
Conference on Dependable Systems and Networks (DSN) (2008)  
[9] Muscariello, L., Mellia, M., Meo, M., Lo Cigno, R., Marsan, M.A.: A Simple Markovian 
Approach to Model Internet Traffic at Edge Routers, COST279, Technical Document, 
No.TD(03)032 (May 2003), 
  http://www.tlc-networks.polito.it/muscariello/papers/ 
 279TD-03-032.pdf  
[10] Chen, J., Cheng, T., Zhang, T., van den Berg, E.: Effective AP Selection and Load 
Balancing in IEEE 802.11 Wireless LANs, GlobeCom (2006)  
[11] Schramm, P., Peter, F.M., Olofsson, H.G.: Cell selection in mobile radio systems, US 
Patent 6542742  
[12] IEEE Std 802.16-2004, Table B.29  
[13] Rahmati, A., Zhang, L.: Context-for-Wireless: context-sensitive energy-efficient wireless 
data transfer, MobiSys (2007)  
[14] 3GPP Architecture Enchancements for non-3GPP accesses (3GPP TS 23.402)  
 

Intelligent Middle-Ware Architecture for Mobile
Networks
Rayene Ben Rayana and Jean-Marie Bonnin
Institut TELECOM, TELECOM Bretagne, France,
Universit´e europ´eenne de Bretagne,
{rayene.benrayana,jm.bonnin}@telecom-bretagne.eu
Abstract. Recent advances in electronic and automotive industries as
well as in wireless telecommunication technologies have drawn a new pic-
ture where each vehicle became “fully networked”. Multiple stake-holders
(network operators, drivers, car manufacturers, service providers, etc.)
will participate in this emerging market, which could grow following vari-
ous models. To free the market from technical constraints, it is important
to return to the basics of the Internet, i.e., providing embarked devices
with a fully operational Internet connectivity (IPv6).
A new device, the Mobile Router (MR), will take place in vehicle to
manage mobility and take advantages of the surrounding wireless tech-
nology diversity to oﬀer seamless IP connectivity to on-board devices. It
has to take into account various constraints, in its decision regarding the
management of wireless network interfaces and the routing of the ﬂows.
These constraints are many-fold. They could be technical, depend on the
environment of the MR or on the ﬂow characteristics. They also have to
respect usage policies provided by stake-holders.
This leads to the necessity to design a middle-ware able to gather all
kind of information and requirements and to provide the routing engine
(at the network layer) with a comprehensive set of elementary rules.
This article presents a MR architecture and show how such a middle-
ware could make decisions which are context aware and policies aware
while allowing a comprehensive resource management.
Keywords: Mobile Middleware, Heterogeneous networking, Context
awareness, Mobile network, NEMO.
1
Introduction
Public transportation users are more and more interested in being able to use
Internet-based applications while they travel. Having continuous connectivity
can make their transportation time pleasant (browsing the web), eﬃcient (con-
sulting emails on the way to work) or even opportune (attending at a work
session although being stuck in a traﬃc jam). Modern public transport compa-
nies are already providing such services for their waiting time in airports and
train stations. Recently, in Europe, several commercial oﬀers that provide such
a service appeared. For example, travellers using the high speed train Thalys
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 43–57, 2009.
c
⃝Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

44
R. Ben Rayana and J.-M. Bonnin
Internet
3G Celular Network
WiFi Hotspot
MR
MNN 3
MNN 2
MNN 4
Fig. 1. Example of a Mobile Network
can remain on-line while crossing over the countryside at 350 km/h. The de-
velopment of IPv6, the growing success of Intelligent Transport Systems (ITS)
equipment and the wireless access network diversity will soon take us along to
the next step.
As embarked devices and communication expenses become aﬀordable, info-
tainment applications relying on the Internet connectivity will invade personal
vehicles. Additionally, The growing interest in sustainable development issues
is another important trigger for developing a “fully networked car”1. In fact,
organising multi-modal transportation requires a tight coupling among diﬀerent
transportation systems through extensive usage of communications. This would
help to provide travellers with up to date information helping them to reduce
the overall trip time and global energy consumption.
Nevertheless, current technologies do not allow small-sized devices to have
more than one or two wireless interfaces because of energy consumption, size
and cost issues. Therefore, these devices would not beneﬁt from the diversity
oﬀered by the various network technologies. They also will not be capable of
managing mobility and maintaining an ubiquitous access to the Internet. How-
ever, considering the problem otherwise, one can notice that these devices are
often used in environments such as personal vehicles and public transportation
systems. Those environments can manage the ubiquitous access issue for the
attached devices and provide them with a stable and easy-to-use access network
(e.g., WiFi or Bluetooth).
Several aspects have to be studied to achieve a seamless mobility through
multiple access networks. A ﬁrst step was the design of the NEMO (NEtwork
MObility) Basic Support protocol at the IETF. NEMO’s approach introduces
the Mobile Routers (MR) which will be part of modern vehicles and manage
all complexities related to multi-interfaces and seamless mobility management.
1 It is the name of a workshop organised each year by the ITU at the International
Motor Show in Geneva.

Intelligent Middle-Ware Architecture for Mobile Networks
45
Fig. 2. Example of a NEMO + MCoA Use Case
A heterogeneous network is a combination of several access networks, each of
them being optimised for some particular service. Consequently a comprehensive
system should deliver each service through the network that is most eﬃcient for
that service. Diﬀerent access networks may also be combined to increase the
available capacity.
Many stake-holders, spanning from public authorities to end users via man-
ufacturers, are involved in ITS-related services and most of these services sup-
pose co-operation between them. Interfaces between various devices must be
fully open to allow a well-balanced market development. Standardisation bod-
ies are working on the deﬁnition of a communication architecture providing,
among other features, Internet connectivity for vehicles. A survey of standardi-
sation works leads to several conclusions. First, all the three main architectures
(WAVE [12], C2C-CC [5], CALM [21]) design a management plan that has to
decide while taking into account high level policies and requirements. It is a
common form of cross layer architecture where it is needed to decide considering
information coming from several communication layers. This management plan
could be implemented as a distributed middle-ware embarked on board devices.
Second, IPv6 and companion protocols have been chosen as a network layer
in all architecture. No other choice was reasonable since hundreds of billions of
cars will need addresses and it is impossible to provide them in IPv4.
Third, if C2C-CC (Car to Car Communications Consortium) architecture
allows the use of WiFi network interfaces along with the dedicated DSRC one,
only CALM has been design to fully support multiple heterogeneous wireless
access networks (802.11-based, 3G, WiMAX, Millimetre Waves, . . . ).
In addition to IPv6, ITU2 has been chosen the NEMO Basic Support protocol
[6] to manage mobility in the CALM Mobile router. The later is responsible for
updating its position to a location server inside the operator network, namely
the Home Agent (HA). All the traﬃc from, and to the mobile network (the on-
board network) is conveyed through a tunnel established with the HA. Moreover,
2 International Telecommunication Union (www.itu.int).

46
R. Ben Rayana and J.-M. Bonnin
a recent work in progress (draft MCoA [20]) deﬁnes a way to establish simultane-
ously multiple tunnels. Another work in progress [10] allows to exchange routing
policies with the HA to enforce them at both tunnel end-points (see ﬁg.2).
These protocols provide technically the support of multiple interfaces in the
TCP/IP architecture, but further works have to be made to develop a fully
operational CALM architecture. In fact, the decision process and how it take
into account various policies provided by stake-holders and requirements given
by application is essential to properly use multiple interfaces.
This article is organised as follows : The next section explores some related
works. The third section gives an overview of the proposed architecture. The
fourth section focuses on how stake-holders policies are taken into account.
Finally, the last section describes how the decision modules reﬁne these poli-
cies and produce the corresponding system-level policies.
2
Related Works
The InternetCar Project (1996–2002) is one of the pioneer projects proposing
a network mobility solution for vehicles. According to [11], it is based upon
two main technologies: Interface Switching and Preﬁx Scope Binding Update
(PSBU) which is similar to NEMO Basic Support. The MR uses a policy-based
mechanism to choose the most suitable interface at a given moment called Mul-
tiple Network Interface Support by Policy-Based Routing on Mobile IPv6. The
project highlights the importance of multi-homing to ensure continuous connec-
tivity. Unfortunately, it was not possible to use simultaneously several interfaces.
MAR (Mobile Access Router) is a network mobility management framework
developed in 2004 [14]. It dynamically instantiates channels based on traﬃc re-
quests, aggregates the bandwidth and dynamically moves load from poor qual-
ity to better quality channels. MAR is based upon the Mobile IPv4 protocol
rather than Mobile IPv6. It uses a policy-based mechanism to exploit simultane-
ously multiple interfaces through the concept of “virtual link”. In this solution
the mobile router also takes care of packet losses and disordering to save TCP
performances.
The integration of various access technologies in a mobile terminals has also
been studied in several other works (e.g., [15,22]). The main idea is to provide
a uniﬁed platform architecture oﬀering a seamless integration of heterogeneous
technologies (e.g., [1,24]). Previously proposed handoﬀsolutions (e.g., [16,23])
try simply to keep the mobile user “Always Best Connected”. However, it is
important to use for each running applications the most adapted technology
among the currently available ones. At the same time, it is important to provide
the best trade-oﬀbetween bandwidth, bit error rate, one way delay and its
induced cost (e.g., [7]).
Various vertical handoﬀschemes have been proposed recently to oﬀer seamless
session continuity. However, there is still a lack of mechanisms allowing a com-
prehensive network connectivity management while providing means to control
some essential parameters such as monetary costs, device energy consumption
and service satisfaction.

Intelligent Middle-Ware Architecture for Mobile Networks
47
Ubique is a Mobile IPv6-based framework designed to oﬀer ubiquitous access
to mobile users [17,18]. Ubique proposes to generate routing policies dynamically
regarding high-level proﬁles speciﬁed by the users, the administrator or the appli-
cations [4]. Adaptive applications communicate directly with the framework to in-
form it about new ﬂows and to specify their requirements. The framework matches
the ﬂow requirements with the interfaces and available access networks. It ensures
the respect of the administrator limitations and conveys the ﬂow through the most
suitable interface. Ubique has been partially adapted to be implemented in a mo-
bile router in [9]. It proﬁted from the ability to manage multiple tunnel toward
the Home Agent (i.e., MCoA) to allow simultaneous use of multiple interfaces.
It has been designed to cope with various preferences. Although few of them de-
pend on the current environment, they are mainly given during the conﬁguration
process and do not allow the operator to control how resources are used. We also
showed in [4] that it is possible to inﬂuence the behaviour of a ﬂeet of terminals
just modifying an administrator-given preference proﬁle.
This quick survey of mobile router architectures points out the remaining need
for a comprehensive middle-ware able to take care of multiple sets of policies po-
tentially contradictory. Moreover, it has to take into account the current context
to decide which part of policies apply in the considered situation.
3
Architecture Overview
A high-level mobility management framework has been developed in the con-
text of the REMORA project3. As ﬁg.3 suggests, the framework produces and
enforces three kinds of policies: a ﬂow routing policy, an interface management
policy and an application management policy. To obtain them, decision mod-
ules process the preferences given by diﬀerent stake-holders and try to maximise
their satisfaction using input from monitoring modules to adapt the decisions
to the context the network is evolving in. The result is then fed to enforcement
modules to be applied.
The main purpose of this paper is to show how high-level stake-holders policies
can be combined to obtain regular system-level policies and rules to be enforced
at the network layer. The motivations of this work and the protocols used in the
REMORA framework are extensively described in [2,3].
A simpliﬁed view of the REMORA framework appears in ﬁg.4. It presents the
three types of modules: Monitoring, Decision and Enforcement. Arrows schema-
tise inter-module interaction. As you can see, these modules co-operate to achieve
the three major tasks of the middle-ware: Flow Routing, Interface Management
and Application Management.
3.1
Interface Management
The Interface Activation Policy Processor is in charge of continuously looking for
access networks that ﬁts better with application requirements and stake-holders
3 This project is a collaborative project supported by the ANR (French government).

48
R. Ben Rayana and J.-M. Bonnin
Fig. 3. Overview of the REMORA Mobile Router architecture
Fig. 4. Modular view of the REMORA architecture
policies. Additionally, this module is responsible for cost and power management.
It shut-downs interfaces when they are not needed. This happens when there is
no critical ﬂows that require the interface and when the non-critical ﬂows can
be dispatched on the other interfaces. The best combination is then chosen and
the module generates a policy that reﬂects this decision. Of course, hysteresis is
necessary to avoid redirecting ﬂows back and forth on the interfaces.
The result obtained is a list of interface-network associations. The indicated
interfaces should be activated if needed and connected to the corresponding
network. The other interfaces have to be deactivated. Once this policy en-
forced, the Flow Routing Decision Module will adapt itself and redirect the ﬂows
conveniently.

Intelligent Middle-Ware Architecture for Mobile Networks
49
3.2
Flow Management
The Flow List contains the characteristics of the ﬂows to be conveyed. For each
ﬂow it speciﬁes the manner to recognise belonging packets (port numbers, IP
addresses, . . . ). The Flow Monitor adds information about whether the ﬂow is
alive or not and evaluates the throughput of each ﬂow.
The Interface Management module manages to distribute the available re-
sources regarding ﬂow priorities and requirements. For example, when resource
level declines, the MR can choose to drop FTP packets in favour of videoconfer-
ence packets.
A list of ﬂow-tunnel associations is produced. It speciﬁes the ﬂows that have
to be sent (or received) through the corresponding tunnels. Packets that do not
match any rule are simply discarded. The enforcement uses standard packet
ﬁltering of the underlying operating system to be highly portable (e.g., netﬁlter
on Unix/Linux systems).
3.3
Application Management
It is essential to let applications take part in the mobility management as stated
in [2]. Applications requirements vary through time and may depend on available
resources. Some applications can adapt their behaviour to the network conditions
experienced by the mobile router. For example, a video conference application
can reduce video quality if the MR experiences a disconnection of one of its in-
terfaces and have to reduce its throughput. Applications can also announce their
requirement to feed the decision process. With these notiﬁcations, the MR will
be able to dimension the overall requirements and decide if additional interfaces
should be waked up or, on the contrary, shut down.
The CALM architecture [21] proposes such interactions between application
and a management plan, which have to be present in MNNs and in MRs. Refer-
ence [2] shows that a simple middle-ware present in MNNs could free applications
to implement complex adaptation policies while allowing advanced management
of mobile network resources. It is also possible to consider the networking en-
vironment as a context and to use context awareness framework to exchange
this information with the applications. It can also be interesting to use a CMS
(Context Management System) [19] to share context-related information among
nodes.
4
Stake-Holders Policies Awareness
As stated before, the matter of this paper is to highlight the ability of the pro-
posed architecture to take into account high level considerations to produce the
corresponding system-level policies. This considerations are described through
policies given by various stake-holders (see ﬁg.5). Three sets of rules are produced
to manage interfaces, to route traﬃc and to allow application adaptation.
This decision could have a substantial economic impact on stake-holders.
First, an operator can be interested in privileging the choice of networks that

50
R. Ben Rayana and J.-M. Bonnin
belong to it or that belong to its commercial partners. While the Mobile Network
administrator can be tempted, on the contrary, to take advantage of the compe-
tition between several operators. In the case of mobile routers sold with vehicles,
car manufacturers can also propose to customers to update their equipment with
a conﬁguration that corresponds to their commercial partnerships. Finally, the
user using applications would be interested to inﬂuence the decision in a way to
serve its interests. For these reasons, the architecture proposes means to be deal
with several, and potentially contradictory, high level sets of policies.
4.1
Car Manufacturers and Operators Policy Awareness
It is expected that, in the near future, a customer could get a mobile router in
two ways. It could be either provided built-in the car (built-in) or purchased a
part on the market. In both cases, the manufacturer may propose a subscription
to its policy update system which guarantee the costumer to take full advantages
of the commercial partnerships of the manufacturer. The later could then have
a certain control over the device.
Nothing have been speciﬁed in the CALM architecture to allow external poli-
cies to be taken into account in the decision process nor to exchange such policies.
Fig. 5. From Stake-holders Policies to System Policies

Intelligent Middle-Ware Architecture for Mobile Networks
51
Anyway, there is a policy description language that could be used to exchange
policies [8].
The control concerns mainly the networks that the user will be allowed to
connect to. The inﬂuence of the manufacturer on the decision can be handled in
several ways. An interesting solution is given by [8]. The document speciﬁes the
syntax of the policy as well as the policy exchange scheme. It suggests that the
manufacturer policy will provide a way to associate each (port number, network)
combination with one of the following directives : (mandatory, optional, not
mentioned, unadvised, forbidden). When a “mandatory” directive is associated
with a (port, network) tuple, the network, if available, has to be used for the
transfer of ﬂows having this port number. Whereas, “optional” directive is just
a hint given to the decision module to privilege a network over others having
a “not speciﬁed” directive. This can be useful for load balancing over diﬀerent
access networks (i.e., privilege load-free networks).
In practice, most mobile network administrators will follow the manufacturer
recommendations but more experienced users may want to limit the eﬀect of the
manufacturer on the decision to ﬁt better with their interests. And they will be
able to do that using a simple weighting mechanism (see ﬁg.5).
4.2
Applications and Final Users Requirements Awareness
A ﬂow notiﬁcation consists in declaring the ﬂow’s minimum requirements under
which the ﬂow cannot be properly sent. When two (or more) tunnels that fulﬁl
these requirements are available, it is interesting for an application to choose
a tunnel that is more adapted to its needs. For example, an FTP client will
choose a tunnel with more bandwidth while a VoIP application would privilege
security and steadiness. These are declared through the declaration of weights
that will inﬂuence the decision algorithm. The ﬂow notiﬁcation and application
adaptation mechanism is extensively described in [2].
TCP
20 Outbound
# FTP Downloading
Priority = 2;
# The flow priority
Privilege = download ;
#
The significant flow direction
Download Requirements
Cost <= 0.3 Euro/ MB;
LossRate <= 10\% ;
Upload
Requirements
Cost <= 0.3 Euro / MB; # don’t download if expensive
LossRate <= 10\% ;
# don’t download if too much loss
Weights
Cost = 60;
# cost is important
LossRate = 20;
ConnectionStability = 20 ;
Security = 20;
Jittter = 20;
Bandwidth = 80
# bandwidth is important too
The example above is a very simpliﬁed version of what a ﬂow declaration
looks like. It illustrates an FTP client that refuses to operate if the cost is high
or if the loss rate is important. In addition, it tells the decision algorithm that
if it had to choose among several tunnels, it would prefer the ones with a higher
bandwidth and a lower cost.
Each application associates a priority with its ﬂows. A Mobile Network ad-
ministrator can clip the priority of certain ﬂows. With priority clipping, he can

52
R. Ben Rayana and J.-M. Bonnin
deny high priority ﬂow declarations to “basic users” while granting access to
“premium users” who will pay more for this privilege. A car driver can also
refuse high priority ﬂows requests coming from his children’s game console to
ensure that his own ﬂows will be sent in better conditions.
4.3
Mobile Network Administrator Policy Awareness
Usually administrator preferences consist in static routing entries. This means
that the system’s administrator decides for each type of ﬂow (based upon port
numbers, IP addresses, etc.) the tunnels in which it will be routed. Nevertheless,
using static rules is nor simple nor eﬃcient. First, it is very hard for a human
being to translate his high level considerations into routing rules. The result is
rarely what is expected and the complexity grows with the number of users and
interfaces. Second, the permanence of static rules contrasts with the changing
network conditions, the changing stake-holders requirements, the changing ap-
plications needs and the changing context. It is by far more interesting for an
administrator to express his high level objectives in a more natural way. For
example, instead of telling the system to avoid sending FTP(port 20/21) ﬂows
into a 3G based tunnel because it is too expensive, he just tells the system to
reduce the overall cost. Given the high-level objectives, the problem can be ex-
pressed as an optimisation problem and a comprehensive intermediary module
is responsible to convert high level policies into system level rules. An example
of an administrator policies description is given bellow.
Minimize Cost;
Minimize PowerConsumption;
Maximize Bandwidth;
Maximize ConnectionStability;
Maximize Security;
Minimize Jitter;
An administrator could specify various objectives. Anyway the system should
have the capability to evaluate their fulﬁlment. For example, if an objective is
to minimise the error rate, the system should integrate tools to evaluate (even
roughly) the error rate of each route/tunnel.
If objectives rarely vary through the time, their relative importance could.
For example, power consumption is less important when the engine is on than
it is when the engine is stopped. The security (encryption level) of the link is
more important than cost during working hours and vice versa.
To formalise that, the administrator speciﬁes a weight for each objective that
relativize its importance. This leads to the deﬁnition of several Operating Modes.
The administrator must provide an operating mode corresponding to the be-
haviour of the system in a particular situation as seen in the example below:
Mode: Work
Mode: CostEconomy
Mode: PowerEconomy
Cost = 10
Cost = 99
Cost = 50
PowerConsumption = 0
PowerConsumption = 0
PowerConsumption = 99
Bandwidth = 70
Bandwidth = 20
Bandwidth = 20
ConnectionStability = 80
ConnectionStability = 10
ConnectionStability = 20
Security = 99
Security = 0
Security = 100
In this example, the administrator declares three modes. The ﬁrst mode gives
more importance to security and QoS than the other modes. It is planned to be

Intelligent Middle-Ware Architecture for Mobile Networks
53
used during working hours. The second gives more importance to the cost and
can be used during weekends and holidays. Finally, the last mode can be used
when the battery level becomes low.
Only one mode can be active at the same time. Of course, this mode can be
selected by the administrator, but, this requires an interaction with the driver,
which can be annoying and dangerous.
We prefer by far the idea of a fully autonomous system that is conﬁgured
using solely high-level parameters that allow the system to react in function of
the current context and to select the appropriate operating mode.
5
Context Awareness
As stated before, the administrator needs depend closely on the context. When
environment changes, weights change and thus, the relative importance of objec-
tives changes. Therefore, the system conﬁguration has to be decontextualised. In
other words, instead of the operating mode to be used, the administrator should
rather tell the system under which conditions he would have set this mode. To
achieve this, it could use a pseudo-algorithm-based description, which allows to
express conditional statements in a human-like language. Below, you can ﬁnd an
example of an administrator conﬁguration ﬁle.
VehicleLocation in (’France’)
BatteryLevel in [20..100]
DayOfWeek in (’Saturday’, ’Sunday’)
RETURN CostEconomy
DayOfWeek in other
HourOfDay in [8..12, 14..18];
RETURN Work
HourOfDay in other;
RETURN CostEconomy
BatteryLevel in [0..20];
RETURN PowerEconomy
VehicleLocation in other;
RETURN CostEconomy
In this example, the user chose to give priority to cost when he is abroad.
When he is at home (i.e., France), the user privileges low energy consumption
when battery level is low. As the company is charged during work hours, the
user privileges quality over cost during the day and the cost reduction otherwise.
The pseudo algorithm-based description allows to express the administrator
needs in a natural way. It allows an inﬁnite number of conﬁgurations that ﬁt the
needs of every user.
You will also notice that this mechanism requires to be fed with up-to-date
values for the time, the battery level and the geographic position. A module
called “Environment Monitor” is responsible for fetching this information which
used to decontextualise the policy description. The system is able to provide the
user mode that would have been set by the administrator in the current context.
The selected mode is then fed to the decision process to inﬂuence its output in
a way that serves administrator’s interests.
Decontextualisation can be very useful to automate the selection of the mode.
But, user modes are not the only parameter that changes depending on environ-
ment. Access network characteristics also depend on the context. For example,

54
R. Ben Rayana and J.-M. Bonnin
the current date and the time of the day give are necessary to choose the cheaper
networks if some of them have complex billing schemes (e.g., UMTS is cheaper
from 8 p.m. to 6 a.m. and during weekends, roaming is expensive, etc.).
Vehicle speed could be used to privilege WiFi networks when the vehicle
is stationary and 3G networks when it is on the move. The example bellow
shows two network entries with parameters decontextualised using the policy
description illustrating the examples above.
Network UMTS_1
Network WiFi_1
ConnectionScript = "pppd ..."
ConnectionScript = "iwconfig ..."
ConnectionStability = high
ConnectionStability =
CASE VehicleSpeed
[0..20] RETURN high
Security = High
CASE VehicleSpeed [20..50] RETURN medium
Download, Upload
ELSE RETURN low
Cost
= CASE VehicleLocation in (’France’)
Security = Low
CASE HourOfDay in [6..20]
Download, Upload
RETURN 0.3 Euro/MB
Cost
=
0
ELSE RETURN 0.1 Euro/MB
Bandwidth = 2000kb/s
ELSE VehicleLocation RETURN 1 Euro/MB
Jitter = DEFAULT
Bandwidth = 600kb/s
BitErrorRate = DEFAULT
Jitter = DEFAULT
Delay = DEFAULT
BitErrorRate = DEFAULT
Delay = DEFAULT
6
Processing Policies and Producing Rules
Once the current mode has been set, applications requirements have been ﬁltered
and the network list updated regarding the current context, the decision process
can be launched. The output of the decision modules are, as stated before (see
ﬁg. 5), three system policies: the ﬂow routing policy, the interface management
policy and the application management policy.
This decision process have to take into account high level considerations such
as operator preferences, all available networks and all running ﬂows. Such impor-
tant input could result in a heavy process that could not be triggered each time
a signiﬁcant event happens. Especially, in a mobility context, where networks
events (handover, disconnection, etc.) are frequent and require fast reaction that
cannot be aﬀorded while taking into account such high level consideration. To
overcome this, the decision process is split in two phases.
The ﬁrst step consists in evaluating the matching degree of ﬂows with the
networks stored in the Network List while respecting the restrictions and the
preferences of the manufacturer, the administrator and the ﬂows. To achieve this,
a utility score is calculated for each network-ﬂow tuple (Scorei,j(ni, fj)) where
ni is an entry in the network list and fj is an entry in the ﬂow list. Of course,
the greater the score is, the more compatible the tuple is. Having a score of zero
means that the ﬂow fj must not be conveyed through the network ni. The score
of a network-ﬂow tuple is weighted with the manufacturer policy associated with
this tuple. For example, if the manufacturer policy tells the system to prevent a
ﬂow fj from being sent through a network ni and if the network administrator
gives a full control to the manufacturer, the obtained Scorei,j will be set to 0
even if the tuple is highly compatible. In this ﬁrst step, each ﬂow is considered
on its own, as if it is the only ﬂow to be treated in the system. The output, and
therefore the input, of this ﬁrst step, does not change very often, therefore it is
not executed very often.

Intelligent Middle-Ware Architecture for Mobile Networks
55
The second step considers ﬂows as a whole and tries to apportion the avail-
able resources to them regarding their Scorei,j, their priority and the remaining
network resources. In practice, this can be assimilated to the addition of a cor-
rection parameter called δi,j which is high for high priority ﬂows that require
abundant resource and is negative for low priority ﬂows. This could require to
send it over a heavily loaded link since if the overall score becomes negative for a
link, the ﬂow must not be sent over it. If a ﬂow does not obtain a positive score
for at least one candidate network, it is simply discarded. At the end of this sec-
ond step, the MR translates the obtained scores into the ﬂow routing policy and
applications are made aware of the changes if any. Additionally, a utility score is
computed for each network to ﬁnd out which are the less used, respectively the
much solicited, ones. This is used to decide to shutdown, respectively to wake
up and conﬁgure, corresponding interfaces.
7
Conclusion
Taking advantage of the Internet ﬂexibility is for sure the right way to simplify
the development of various ITS services (from security to infotainment). This
paper deals with the network diversity (multi-homing) management and gives an
overview of various works done at standardisation bodies and in the academic
world. It identiﬁes the missing part in current standardisation proposals of a
Mobile Router architecture such as the CALM architecture designed at ISO
TC 204 WG 16 (see [4]). It also sketches up the architecture designed in the
REMORA project. In addition, it shows how context awareness is integrated
in the multi-interfaces management middle-ware. Moreover, it is tightly coupled
with what we call policies awareness to feed a comprehensive decision process
which is able to take high level consideration to route the ﬂow.
Further works are necessary to design a fully operational CALM implemen-
tation and more generally a fully operational NEMO Mobile Router. It is ﬁrst
necessary to provide a way to distribute decision and routing operation when
several mobile routers are present in the mobile network. Moreover, the man-
agement plan should be able to interact smoothly with routing optimisation [13]
and non-IP networking layers devoted to V2V communications such as CALM
FAST and Geo-casting.
This works has also been the occasion to work on the relation between the
MR and applications running on-board [2]. The REMORA architecture has been
implemented as a proof-of-concept with which experiments and demonstrations
have been successfully conducted.
Additionally, we are developing a network emulator to study distributed ver-
sus centralised resource management approaches. This will allow us to study
carefully the relation between decision mechanisms embedded into adaptive ap-
plications and the one built-in the mobile router middle-ware.
Remark: First results will certainly be ready by the time to deliver the camera-
ready version of this article. They will be presented during the conference. These
ﬁrst results will give a functional-proof of the design in various ITS scenarios

56
R. Ben Rayana and J.-M. Bonnin
and compare the behaviour of the REMORA architecture with the one of a basic
NEMO mobile router statically conﬁgured.
References
1. Andr´e, F., Bonnin, J.-M., Deniaud, B., Guillouard, K., Montavont, N., No¨el, T.,
Suciu, L.: Optimized support of multiple wireless interfaces within an ipv6 end-
terminal. In: SOC 2003 (Smart Objects Conference), Grenoble, France (May 2003)
2. Ben Rayana, R., Bonnin, J.M.: Mobility aware application manager for mobile
networks. In: ITST 2008 (Intelligent Transportation Systems and Telecommunica-
tion), Phuket, Thailand (October 2008)
3. Bonnin, J.-M., Rayana, R.B.: Wireless Technologies for Intelligent Transportation
Systems. In: Heterogeneous Networks and Mobility Management for ITS (2009)
4. Bonnin, J.-M., Lassoued, I., Hamouda, Z.B.: Automatic multi-interface manage-
ment through proﬁle handling. In: Mobile networks and applications, special issue
on Mobile Middleware. Springer, Heidelberg (2008) (online)
5. C2C Communications Consortium. Car-2-car communication consortium - mani-
festo (2007)
6. Devarapalli, V., Wakikawa, R., Petrescu, A., Thubert, P.: Network Mobility
(NEMO) Basic Support Protocol. RFC 3963 (Proposed Standard) (January 2005)
7. Gustafsson, E., Jonsson, A.: Always best connected. IEEE Wireless Communica-
tions (February 2003)
8. Larson, C., Eriksson, M., Mitsuya, K., Tasaka, K., Kuntz, R.: Flow distribution
rule language for multi-access nodes. IETF working draft (work in progress) (July
2008)
9. Mahamat-faki, M., Bonnin, J.-M., Ben Rayana, R.: Traﬃc ﬂow control on multi-
tunneled mobile router. In: short paper in WNEPT2006 (Workshop on Networking
in Public Transport), Waterloo, Canada (August 2006)
10. Mitsuya, K., Tsakada, K., Wakikawa, R., Kuntz, R.: A policy data set for
ﬂow distribution. Draft IETF (Work in progress) draft-mitsuya-monami6-ﬂow-
distribution-policy-04.txt (August 2007)
11. Mitsuya, K., Uehara, K., Murai, J.: The In-vehicle Router System to support Net-
work Mobility. In: International Conference on Information Networking (ICOIN),
South Korea (February 2003)
12. IEEE P1609. Ieee p1609.1 standard for wireless access in vehicular environment
(wave) - multi-channel operation. IEEE draft Standard (2006)
13. Perkins, C.E., Johnson, D.B.: Route Optimization for Mobile IP. Cluster Comput-
ing 1(2), 161–176 (1998)
14. Rodriguez, P., Chakravorty, R., Chesterﬁeld, J., Pratt, I., Banerjee, S.: Mar: a com-
muter router infrastructure for the mobile internet. In: MobiSys 2004: Proceedings
of the 2nd international conference on Mobile systems, applications, and services,
pp. 217–230. ACM Press, New York (2004)
15. Siddiqui, F., Zeadally, S.: Mobility management across hybrid wireless networks:
Trends and challenges. Computer Communications 29(9), 1363–1385 (2006)
16. Stevens-Navarro, E., Wong, V.W.S.: Comparison between vertical handoﬀdecision
algorithms for heterogeneous wireless networks. In: IEEE Vehicular Technology
Conference (VTC), Melbourne/Australia (May 2006)

Intelligent Middle-Ware Architecture for Mobile Networks
57
17. Suciu, L., Bonnin, J.-M., Guillouard, K., St´evant, B.: Achieving “always best
connected” through extensive proﬁle management. In: Niemegeers, I.G.M.M., de
Groot, S.H. (eds.) PWC 2004. LNCS, vol. 3260, pp. 421–430. Springer, Heidelberg
(2004)
18. Suciu, L., Bonnin, J.-M., Guillouard, K., St´evant, B.: Towards a highly adapt-
able user-centric terminal architecture. In: The 7th Intl. Symposium on Wireless
Personal Multimedia Communications (WPMC 2004), Abano, Italie (September
2004)
19. van Kranenburg, H., Bargh, S., Iacob, M.S., Peddemors, A.: A context manage-
ment framework for supporting context-aware distributed applications. pp. 67–74
(August 2006)
20. Wakikawa, R., Uehara, K., Ernst, T., Nagamix, K.: Multiple Care-of Address
Registration. Draft IETF (Work in progress) draft-wakikawa-mobileip-multiplecoa-
05.txt (February 2006)
21. Williams, B.: The calm handbook: Continuous communications with and between
vehicles. ISO/TC204/WG16 (work in progess v2.0) (November 2005).
22. Williams, M.: Directions in media independent handover. IEICE Transactions on
Fundamentals of Electronics, Communications and Computer Sciences - Special
Section on Multi-dimensional Mobile Information Networks (July 2005)
23. Xing, B., Venkatasubramanian, N.: Multi-constraint dynamic access selection in
always best connected networks. In: IEEE MobiQuitous 2005, pp. 56–64, San
Diego/CA/USA (July 2005)
24. Zhang, W., Jaehnert, J., Dolzer, K.: Design and evaluation of a handover deci-
sion strategy for 4th generation mobile networks. In: 57th Semiannual Vehicular
Technology Conference (VTC 2003-Spring) (April 2003)

C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 58–71, 2009. 
© Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009 
Middleware Solutions for Self-organizing Multi-hop 
Multi-path Internet Connectivity Based on Bluetooth 
Paolo Bellavista and Carlo Giannelli 
Dept. Electronics Computer Science and Systems (DEIS), University of Bologna  
Viale Risorgimento, 2 – 40136 Bologna, Italy 
{paolo.bellavista,carlo.giannelli}@unibo.it 
Abstract. The availability of heterogeneous wireless interfaces and of growing 
computing resources on widespread portable devices pushes for enabling inno-
vative deployment scenarios where mobile nodes dynamically self-organize to 
offer Internet connectivity to their peers via dynamically established multi-hop 
multi-path opportunities. We claim the suitability of novel, mobility-aware, and 
application-layer middleware based on lightweight evaluation indicators to  
support the complexity of that scenario, involving heterogeneous wireless  
technologies over differentiated and statically unpredictable execution envi-
ronments. To validate these claims, we have implemented an innovative mid-
dleware that manages the durability/throughput-aware formation and selection 
of different multi-hop paths simultaneously. This paper specifically focuses on 
how our middleware effectively exploits Bluetooth for multi-hop multi-path 
networking, by pointing out the crucial role of i) compliance with standard  
solutions to favor rapid deployment over off-the-shelf equipment and ii) the re-
duction of the usual overhead associated with some expensive Bluetooth opera-
tions, e.g., device inquiry. In particular, the paper shows how it is possible, on 
the one hand, to extend JSR-82 to portably access monitoring indicators for 
lightweight mobility/throughput estimations and, on the other hand, to reduce 
the time needed to update the set of available Bluetooth-based connectivity op-
portunities via approximated and lightweight forms of discovery.  
Keywords: Mobile Computing, Middleware, Bluetooth, Always Best Served 
Networks, Multi-hop Multi-path Connectivity, Collaborative Connectivity. 
1   Introduction 
Nowadays mobile devices, usually equipped with multiple wireless interfaces, can get 
connectivity to the traditional wired Internet by taking advantage of multiple connec-
tivity opportunities provided by many infrastructure-based components, which tend to 
be ubiquitously available, e.g., IEEE 802.11 Access Points (APs) or UMTS Base 
Stations (BSs). In the following, we will call these connectivity components as infra-
structure connectors. In addition, the increasing and increasing resources of mobile 
terminals potentially enable novel and more complex scenarios where client nodes 
can also help other clients to achieve Internet connectivity in a peer-to-peer way, e.g., 
via Bluetooth Personal Area Network (PAN) or IEEE 802.11 Independent Basic  

 Middleware Solutions for Self-organizing Multi-hop Multi-path Internet Connectivity 
59 
Service Set (IBSS) connections. In other words, peer nodes can offer their resources 
by acting as intermediate entities in a multi-hop (possibly heterogeneous) path to-
wards the Internet. We use the term peer connectors to indicate these novel connec-
tivity opportunities. In these envisioned scenarios peer connectors are in charge of 
creating and properly managing a simple and small Mobile Ad-hoc NETwork (MA-
NET) with the peers in proximity and of correctly routing packets between their MA-
NET and the Internet by exploiting the near infrastructure connectors. 
The increased complexity of this scenario, enabled by the concurrent exploitation 
of infrastructure/peer connectors, is widely counterbalanced by its potential benefits. 
In fact, benefits include not only the possibility to exploit a significantly wider set of 
connectivity opportunities, but also to dynamically select which opportunity to use at 
any time depending on system/user/node/application-specific requirements. For in-
stance, a dynamic selection mechanism could be useful for connector load balancing, 
for always privileging connectivity opportunities that are for free, for preserving cli-
ent/global node battery, or for respecting bandwidth requirements (see Section 2). 
However, the dynamic selection of the wireless interface for a client to exploit with its 
connectors is not trivial. Only to mention an example of such complexity from the 
beginning, let us consider that, nowadays, most mobile phones integrate 
GPRS/UMTS and Bluetooth interfaces (and several of them are equipped also with 
IEEE 802.11). In addition, many laptops and PDAs already combine medium/short-
range IEEE 802.11 and Bluetooth wireless technologies with wide-range 
GPRS/UMTS/HSDPA cellular communication interfaces. We claim that it is inap-
propriate to leave to client application designers the whole burden of properly manag-
ing the wide set of Multi-hop Multi-path Heterogeneous Connectivity (MMHC)  
opportunities that are dynamically available. Therefore, in our opinion there is the 
need for novel, suitable, and lightweight middleware solutions for effective MMHC 
management, which should mainly work at the client side in a decentralized way to 
minimize management overhead and generated network traffic. 
These middlewares should have visibility of different kinds of innovative context 
data to take proper MMHC decisions, especially to ensure the usability of enabled 
MMHC opportunities by selecting the ones expected to be more reliable during the 
service session that is going to be established. In particular, lightweight estimations 
about client mobility (with regards to both fixed infrastructure and mobile peer con-
nectors) could allow to exclude the connectors that are probably going out of the 
coverage area of the considered client soon. In that way it is possible to reduce the 
search space of potential connectivity opportunities to take into account. Similarly, 
context data about estimated throughput (achievable by a single wireless hop and by 
the multi-hop paths including that hop) can help filtering out connectors that do not 
comply with session quality requirements. Finally, context data about connector re-
sidual energy could help in balancing energy consumption and in taking proactive  
re-configuration of exploited paths if some composing hops are expected to fail soon 
due to power exhaustion. 
Our previous work has already demonstrated the crucial role of context to dynami-
cally evaluate networking opportunities in MMHC scenarios [1] and presented the 
architecture and the primary design guidelines of our MMHC middleware [2, 3]. Our 
MMHC prototype is able to self-organize client nodes, by dynamically retrieving the 
set of available infrastructure and peer connectors. In addition, MMHC client nodes 

60 
P. Bellavista and C. Giannelli 
self-hail multi-hop paths to the Internet, by possibly modifying routing rules at run-
time in case of intermediate peer failure. Here, the paper originally focuses on how 
our novel middleware supports the exploitation of Bluetooth to get and provide Inter-
net connectivity via peer-to-peer multi-hop paths. In general, let us notice that Blue-
tooth is widely considered as a complementary connectivity technology to IEEE 
802.11 and cell-based communications: in fact, on the one hand, it exhibits signifi-
cantly lower power consumption, thus maximizing node battery life, and, on the other 
hand, its limited throughput (less than 1Mbps for Bluetooth1.2, about 3Mbps for 
Bluetooth2.0EDR) is sufficient for many commercial applications, e.g., periodic 
download of email messages. Also note that only a subset of Bluetooth capabilities 
are currently exploited by a large public of users: Bluetooth is mainly used only to 
connect mobile clients with remote devices, e.g., a wireless mouse/keyboard or a 
printer, with a very few industrially-relevant support solutions for exploiting it to 
get/provide Internet connectivity, as MMHC can enable.  
In particular, this paper originally addresses (and presents related de-
sign/implementation solutions) two key aspects for the support of Bluetooth-based 
multi-hop multi-path networking, i.e., the adoption of standard solutions capable to 
be rapidly deployed over off-the-shelf equipment and the achievement of perform-
ance efficiency by limiting the usual overhead associated with some expensive Blue-
tooth operations. Standardization is crucial to provide a solution that can run on  
different mobile clients, equipped with heterogeneous resources in terms of operating 
systems, wireless card interfaces, and related drivers, provided by different manufac-
tures. That is particularly relevant given the high heterogeneity of current wireless 
devices, from PDAs to smart phones. In addition, the efficiency improvement of some 
Bluetooth mechanisms, such as device discovery via the Bluetooth inquiry procedure, 
is of primary importance to quickly determine new paths at runtime. In fact, node 
mobility may delve into frequent abrupt disconnections, periodically requiring dis-
covery and reconnection phases which call for fast, effective, and possibly approxi-
mated lightweight solutions for the dynamic update of available connectivity  
opportunities. 
The remainder of the paper is organized as follows. Section 2 presents our target 
deployment scenario, by pointing out the main characteristics of Bluetooth-based 
multi-hop multi-path networking and the need for improved efficiency in Bluetooth 
connector discovery and connectivity establishment. Section 3 sketches the architec-
ture and the primary components of our MMHC middleware, while Section 4 details 
the MMHC tasks to support multi-hop paths, by specifically showing how Bluetooth 
devices may represent a performance bottleneck for path management. Section 5 
proposes our original extension of the JSR-82 Java APIs for Bluetooth [4], integrated 
in the MMHC middleware to easily achieve a portable and efficient solution for Blue-
tooth-based MMHC networks. Conclusive remarks and directions of current research 
end the paper. 
2   Deployment Scenario, Motivations, and Solution Guidelines 
The MMHC scenario relevantly improves the traditional networking capabilities of 
wireless environments. First of all, it extends connectivity opportunities via multi-hop 

 Middleware Solutions for Self-organizing Multi-hop Multi-path Internet Connectivity 
61 
ad-hoc paths, thus allowing the Internet access of nodes not directly in the coverage 
area of infrastructure connectors. Second, it enables the exploitation of multiple paths 
simultaneously, e.g., to improve the overall throughput available at clients. Third, it 
permits to increase connectivity availability, e.g., by enabling the rapid rerouting of 
traffic flows to alternative paths when the exploited ones become unavailable.  
To better and practically point out these advantages, let us rapidly sketch an exam-
ple of a possible MMHC deployment scenario, involving different wireless interfaces, 
Bluetooth included. Consider the realistic case of a group of tourists moving together 
and sharing pictures via Bluetooth single-hop links. Due to their limited coverage 
range, there could be the need for multi-hop paths to reach target friends who are 
currently lingering in a shop; that is enabled by collaborating tourist devices that, for 
instance, can transparently exploit Bluetooth to receive and forward packets along the 
right direction, e.g., node C in Fig. 1. In addition, some tourists may be willing to 
periodically publish their pictures on their Web blogs even if they have no direct 
UMTS connectivity, e.g., they do not want to subscribe to a local UMTS provider 
while visiting Italy. These tourists can benefit from Bluetooth multi-hop ad-hoc con-
nectivity toward the devices of friends with flat-rate UMTS subscription, who offer 
them free Internet connectivity, e.g., the E-C-A node chain toward BS1. In that way 
client nodes greatly benefit from the widening of connectivity opportunities: thanks to 
MMHC, they can reach other peers and infrastructure connectors even if they are not 
directly available via single-hop links. Note that tourists' mobility may reduce the 
reliability of MMHC opportunities; usually there is the need to favor the selection of 
MMHC opportunities with application-compatible reliability (especially in terms of 
expected durability).  
Similarly, when moving from city to city by train, tourists should be able to exploit 
MMHC opportunities offered by other passengers, possibly in other cars, reachable 
via multi-hop heterogeneous paths, and connected to the Internet via Wi-Fi/WiMAX 
APs, such as node B. In this case the nodes tend to move together (joint mobility) and 
MMHC opportunities have similar expected durability. Therefore, MMHC selection 
should not only be mobility-aware, but also consider application-specific quality 
 
A
C
D
E
Internet
Internet
BS1
BS2
UMTS
Bluetooth
Wi-MAX
getting
connectivity
offering
connectivity
F
B
IEEE 802.11
Bluetooth
 
Fig. 1. An example of MMHC scenario 

62 
P. Bellavista and C. Giannelli 
requirements, e.g., expected throughput. MMHC enables to fully take advantage of all 
the paths that are simultaneously available, e.g., by dynamically switching to a path 
with estimated larger bandwidth. Moreover, if node A leaves the network, e.g., to 
limit its battery consumption, node D can reroute its active connections from node A 
to B, thus minimizing user-perceived service disruption. However, in that case, node 
C would have no access to the Internet anymore, since A was its only connector. In 
that simple MANET, MMHC self-organizes to provide new Internet access opportu-
nities, e.g., with node F starting to serve as connector, thus providing C with connec-
tivity towards BS2. Thus, MMHC contributes to increase connectivity availability, by 
self-healing paths via dynamic reconfiguration of network topology. 
To clearly position our approach with regards to very recent related literature, our 
novel MMHC middleware solution enables multi-hop multi-path networking in a 
similar way, to some extent, to what the Extended Service Set mesh network intends 
to do in the upcoming IEEE 802.11s standard [5]. MMHC and IEEE 802.11s scenar-
ios have some similarities but also relevant differences in terms of node roles, multi-
hop multi-path connectivity establishment, and management metrics for routing rules.  
First of all, both MMHC and IEEE 802.11s define different possible roles for par-
ticipating nodes: the nodes getting and providing connectivity to others (i.e., MMHC 
peer connectors and IEEE 802.11s Mesh Points) and the ones only getting connec-
tivity (client nodes in MMHC, client stations or STAs in the traditional IEEE 802.11 
terminology). In addition, IEEE 802.11s supports the exploitation of Mesh Access 
Points, to provide also mesh-external nodes with connectivity, and of Mesh Portals, to 
interconnect the supported mesh network with other external networks. Our MMHC 
solution does not remark the static distinction among Mesh Points, Mesh Access 
Points, and Mesh Portals; any (peer) connector can dynamically decide which of the 
three roles to play depending on the execution environment and also different roles 
simultaneously. Moreover, MMHC connectors offer connectivity opportunities  
without requiring a global notion of the mesh network, thus promoting local and de-
centralized management decisions. 
Furthermore, both MMHC and IEEE 802.11s provide multi-hop multi-path access 
to the Internet, also in order to facilitate and improve the effectiveness of connectivity 
self-healing in the case of intermediate node failure. However, for routing purposes 
IEEE 802.11s can only exploit Mesh Nodes, Mesh Access Points, and Mesh Portals 
based on IEEE 802.11s. On the contrary, MMHC enables the exploitation of multiple 
wireless technologies simultaneously, integrated into the MMHC solution with an 
application-layer approach, thus allowing also the exploitation of paths made up by 
heterogeneous single-hop links. Finally, IEEE 802.11s exploits a low-level radio-
aware link metric, mainly based on bit error rate. On the contrary, to evaluate link and 
multi-hop paths, MMHC can exploit more expressive context information: node mo-
bility estimations for reliability purposes, path throughput estimations to maximize 
quality, and energy availability estimations to enhance long-term availability [1].  
In our opinion, there is wide space for proposing innovative solutions for evolving 
towards more powerful and dynamic heterogeneous scenarios where nodes can col-
laborate by exploiting different interfaces simultaneously to receive and send data in 
multi-hop paths. For instance, [6] proposes a two-hop-relay architecture, based on 
Relay Gateway (RG) nodes that can behave both as usual nodes and as cellular gate-
ways. They can seamlessly switch interfaces depending on network availability. In 

 Middleware Solutions for Self-organizing Multi-hop Multi-path Internet Connectivity 
63 
addition, they can improve WLAN coverage by exploiting cellular interfaces where 
WLAN connectivity is not available. Mobile nodes have to explicitly request for RG-
based connectivity in a non-transparent way. In [7] mobile nodes, namely the Proxy 
Client, can interwork with both cellular and IEEE 802.11 ad-hoc networks. Differ-
ently from previous examples, in [7] mobile nodes can interact with Proxy Clients not 
only directly, but also via intermediate mobile nodes in a multi-hop ad-hoc way. With 
an additional degree of mobile node involvement, there are a very few proposals  
aiming at the coordination of a set of mobile nodes to create MANET connectivity 
opportunities. Cooperating ad Hoc networking to sUpport Messaging (CHUM) dy-
namically elects one node to play the role of gateway between the MANET and the 
fixed network infrastructure [8]. In particular, CHUM exploits WLAN connectivity 
on the MANET side and 3G on the infrastructure side. [9] provides a similar example 
of MANET-3G integration, by exploiting SIP as the signaling protocol between nodes 
and the gateway. 
In short, as a final comparative consideration, we claim that our MMHC middle-
ware can relevantly extend the potential benefits targeted by IEEE 802.11s Extended 
Service Set mesh networks via the interconnection and exploitation of heterogeneous 
wireless technologies. In addition, MMHC can easily integrate with IEEE 802.11s 
and other wireless technologies, e.g., IEEE 802.11abg and Bluetooth, by exploiting 
them as possible wireless interfaces for its connectors.  
By focusing on Bluetooth-enabled connectivity, which is the specific original topic 
of this paper, we claim that, nowadays, the primary issues limiting the adoption of 
Bluetooth in multi-hop multi-path scenarios are i) the lack of a portable and standard 
solution to enable multi-hop paths on heterogeneous clients and ii) the poor efficiency 
of currently adopted Bluetooth discovery/connection procedures.  
First, Bluetooth is supported in a differentiated way, e.g., with differentiated APIs 
with heterogeneous functions and capabilities, over different operating systems and 
even depending on implementor-specific drivers. That calls for support solutions that 
can identify the execution context at runtime, in order to load and use specific mod-
ules to access the dynamically available drivers by exploiting different facilities (or 
sequence of facilities) to achieve the same goal in different environments. To this 
purpose, JSR-82 Java APIs for Bluetooth represents a notable example of industrial 
standardization effort. The JSR-82 APIs provide a uniform interface to Bluetooth 
capabilities, already available on many execution environments; however, they do not 
provide some features that are crucial for MMHC, such as gathering Received Signal 
Strength Indication (RSSI) values and establishing Bluetooth Network Encapsulation 
Protocol (BNEP) connections, as better detailed in Section 5. 
Secondly, despite Bluetooth is primarily designed for mobile environments, it does 
not manage dynamically available connections promptly, requiring a long time period 
for pairing (i.e., connecting, according to Bluetooth terminology) two devices. For 
instance, it requires 10.24s for a complete inquiry procedure (i.e., remote device dis-
covery in the Bluetooth terminology) and more than 6s for PAN connection plus 
DHCP configuration [3]. Of course, in mobile environments where clients can freely 
and abruptly move, there is the central need of efficient mechanisms for node discov-
ery and connection creation. For instance, just to give a rough, preliminary, but  
practical idea, considering that the Bluetooth coverage range of most devices is 
around 10m, two mobile nodes should have a relative speed of less than 2m/s just to 

64 
P. Bellavista and C. Giannelli 
have enough time to perform mutual discovery; to enable real data transferring, addi-
tional time for pairing and setup network configuration is required.  
Starting from the above considerations, we have worked to include in our MMHC 
middleware novel facilities to access Bluetooth-related low-level details in a portable 
and effective way. On the one hand, our MMHC prototype exploits the JSR-82 APIs 
to minimize connection activation time portably. On the other hand, we have signifi-
cantly extended the JSR-82 APIs to fully support the monitoring features required by 
our advanced MMHC estimation functions (portable and effective visibility of RSSI 
values for node mobility evaluation) and the efficient creation of BNEP connections. 
3   The MMHC Architecture 
By following the above design guidelines and considerations, we have developed and 
experimentally validated our MMHC solution, an open-source middleware prototype 
for the wireless management research community, available for download at our 
MMHC-companion Web site, in different distributions for the most spread operating 
systems (Linux, MS Windows XP/Vista, and MacOSX1).  
Fig. 2 gives a high-level overview of our MMHC middleware architecture. Its main 
components are Network Interface Provider (NIP), which provides homogeneous 
management access to heterogeneous interfaces, Connection Manager (CM), which 
operates to establish and manage single-hop links, and Routing Manager (RM), which 
creates and dynamically handles multi-hop paths. 
Network Interface Provider
provide connectivity
single-hop
opportunities
multi-hop
paths
Connection
Manager
connect
IEEE 802.11
Bluetooth
UMTS
Routing
Manager
local node
requirements
single-hop
connections
receive remote context
send local context
 
Fig. 2. Our MMHC middleware architecture 
3.1   Network Interface Provider (NIP) 
NIP interacts with network interfaces and provides upper layers with a transparent 
access to interface capabilities, by hiding low-level details of heterogeneous interface 
drivers and operating systems. NIP is organized into two layers: features and  
                                                           
1 http://lia.deis.unibo.it/Research/MMHC/ 

 Middleware Solutions for Self-organizing Multi-hop Multi-path Internet Connectivity 
65 
wrappers. At middleware initiation time the feature layer considers the underlying 
execution environment and loads the right wrappers to communicate with the avail-
able interface drivers. In addition, it exposes an API to upper layers in order to enable 
the access to wireless interfaces even without any knowledge of low-level and inter-
face-specific implementation details. The wrapper layer is in charge of directly  
interacting with interface drivers to perform the commanded operations, possibly in a 
system-dependent way. Note that the upper layer is developed once for all interfaces, 
while the lower layer has been implemented in different versions for each supported 
operating system. In that way, NIP also facilitates the introduction and exploitation of 
new interfaces over different operating systems by simply extending the only lower 
layer. 
By delving into finer details, the feature component of NIP provides a set of capa-
bilities common to any interface: 
• 
perform as peer connector, to start offering connectivity with a specific interface 
in a peer-to-peer way; 
• 
connect to a connector, to require the connection of an interface with a given 
connector and consequently establishing the associated channel, thus enabling  
inter-node communication; 
• 
get available connectors, to obtain the list of connectors and their related infor-
mation (e.g., the RSSI value) that an interface can currently access. 
Additional details on how MMHC provides these features with Bluetooth devices on 
heterogeneous client nodes in the Section 5. 
3.2   Connector Manager (CM) 
CM gathers RSSI sequences from wireless interfaces in order to estimate node mobil-
ity for any single-hop MMHC opportunity. On this basis, it takes local decisions on 
the sub-set of single-hop paths to activate. CM is a crucial component of the MMHC 
middleware because it has a direct and relevant impact on client channel decisions. It 
interacts with the underlying interfaces to change their configuration. Due to the criti-
cality of the actions it performs, CM cannot be directly configured by a single appli-
cation: in fact, one application may be selfish and require always the maximum  
connectivity performance at the expense of other applications running at the same 
node. For these reasons, CM provides RM and any application with a limited set of 
channel possibilities, i.e., only with the channels that are considerable feasible for the 
whole client node, with “no risks” for other running applications. In order to correctly 
estimate whether a connector is suitable for establishing a channel, CM has to gather 
and consider many client-related context data, since channel realization may affect the 
capabilities of the whole mobile client. In first approximation, CM determines the set 
of single-hop paths to activate based on durability estimation inferred by mutual dis-
tance monitoring: if several one-hop-distant devices have durability estimation values 
compliant with application requirements, CM prioritizes APs and BSs (see [1] for 
additional details on MMHC connector evaluation and selection schemas). 
 
 

66 
P. Bellavista and C. Giannelli 
By delving into finer details, CM is in charge of:  
1) discovering new connectors for all the supported wireless interfaces;  
2) evaluating their suitability degree;  
3) performing layer2 connections with the subset of selected connectors; 
4) configuring layer3 parameters of established connections via DHCP.  
The implementation of steps 1 and 3 strictly depends on the adopted wireless tech-
nology, e.g., inquiry procedure and PAN connection for Bluetooth and AP scan and  
association for IEEE 802.11, while steps 2 and 4 are independent from it.  
3.3   Routing Manager (RM) 
RM is in charge of establishing, controlling, and updating heterogeneous multi-hop 
channels by properly managing routing rules at runtime. It works to send/collect in-
formation/requirements on path suitability to/from collaborating nodes with the goal 
of estimating path durability (based on both node mobility end energy availability) 
and throughput. It interacts with CM to get the set of activated single-hop connec-
tions. When notified of a single-hop path disruption, it autonomously changes routing 
rules. In addition, routing rules are updated in an on-demand way anytime a new 
device becomes available or there is the need for a path renegotiation, e.g., because a 
path goes below the negotiated thresholds for expected throughput. 
Since the main goal of RM is to modify paths based on local information provided 
by CM and remote information from collaborating nodes, the RM implementation 
does not depend on any particular wireless technology. In fact, RM:  
1) interacts with one-hop distant nodes to send/receive context information;  
2) evaluates the suitability of available single-hop links to form activated multi-
hop and possibly heterogeneous channels; 
3) changes routing rules to force the creation/update of valuable multi-hop paths.  
By specifically focusing on Bluetooth exploitation in our MMHC middleware, let 
us stress that RM can interconnect multiple piconets together to form the dynamically 
needed multi-hop path and does not work to create a single multi-hop scatternet. In 
fact, while piconet-based multi-hop connectivity may introduce slightly additional 
overhead, that is greatly counterbalanced by a notable improvement in terms of proper 
dynamic selection of the most suitable connectivity opportunity depending on high-
level context information. In addition, in this way MMHC can manage Bluetooth and 
IEEE 802.11 single-hop links in a homogeneous manner, with relevant advantages in 
terms of middleware/application development. 
4   Implementation Insights and Performance Considerations 
Based on our in-the-field experience with the creation and management of Bluetooth-
based multi-hop paths, we have observed that the complexity of the middleware tasks 
needed for MMHC usually varies if they have to exploit basic mechanisms offered by 
either the operating system or the wireless technology.  

 Middleware Solutions for Self-organizing Multi-hop Multi-path Internet Connectivity 
67 
First of all, middleware operations that do not depend on the local operating system 
and on the exploited wireless interface have minimum impact on total overhead and 
on the MMHC performance. For instance, the dynamic evaluation of remote Blue-
tooth connectors simply depends on quantitative data related to context information: 
CM spends about 120ms to evaluate a set of 5 connectors (further details on the 
adopted quantitative indicators are in [1]).  
On the contrary, the operating-system-dependent middleware tasks are generally 
more complex to design and implement because they should perform equivalent but 
different actions on different execution environments. For instance, to create a new 
multi-hop Bluetooth path on Linux nodes, RM should perform the commands re-
ported in Fig. 3, where interfNameInt is the name of the local interface offering 
connectivity and interfNameExt is the name of the local interface connected to the 
next hop of the path (an infrastructure connector in case of single-hop paths, a peer 
connector in case of multi-hop paths). In particular, lines 1-6 enable incoming, outgo-
ing, and traversing packets to exploit interfNameInt and interfNameExt interfaces. 
It is the last line that actually creates the multi-hop path, by changing the routing rules 
to forward packets coming from the remote client with clientIP address connected 
via the interfNameInt interface to the external interfNameExt one. 
 
 
iptables -A INPUT -i interfNameInt -j ACCEPT 
iptables -A INPUT -i interfNameExt -j ACCEPT 
iptables -A FORWARD -i interfNameInt -o interfNameExt -j ACCEPT 
iptables -A FORWARD -o interfNameInt -i interfNameExt -j ACCEPT") 
iptables -A OUTPUT -o interfNameInt -j ACCEPT 
iptables -A OUTPUT -o interfNameExt -j ACCEPT" 
 
iptables -t nat -A POSTROUTING -o interfNameExt -s clientIP -j MASQUERADE 
Fig. 3. Example of RM commands on Linux to create a new Bluetooth-based multi-hop path 
On the opposite, on MSWindows nodes, RM should perform the command 
ROUTE ADD destination_ip MASK 255.255.255.0 gateway IF interface_number  
where destination_ip is the destination network address, gateway the peer connec-
tor address, interface_number the identifier of the interface according to the MS 
Windows interface ordering. Anyway, despite the heterogeneity-related complexity 
and the need to perform different actions on different operating system, multi-hop 
path creation is not the most relevant source of overhead in MMHC: for instance, on 
Linux nodes, RM takes less than 300ms to create a new multi-hop path [3] by exploit-
ing the commands in Fig. 3. 
Instead, the MMHC tasks that significantly depend on specific features of the ex-
ploited wireless technologies may impose the most relevant delays. In particular, we 
have already shown in a previous paper [3] that the performance results achieved by 
MMHC when establishing new Bluetooth single-hop links are mainly the result of 
overheads due to the discovery of remote Bluetooth connectors and to PAN connec-
tion. The former's latency is about 11s (10.24s for the inquiry procedure, the remain-
der because of process initialization and result parsing), the latter more than 3s. It is 
worth noting that this relevant delay greatly limits (indeed, it is the primary bottle-
neck) the MMHC capability to quickly react to connectivity changes in Bluetooth-
based deployment environments. This is particularly true at system startup and  

68 
P. Bellavista and C. Giannelli 
whenever in-use connectors become abruptly unavailable, because there is the need to 
wait for a whole inquiry procedure before evaluating and connecting to new connec-
tors. In other words, this heavy overhead significantly limits the degree of node mo-
bility/dynamicity that MMHC can support when exploiting Bluetooth. 
While it is impossible to shorten the PAN connection phase without modifying the 
Bluetooth standard, the latency of the inquiry procedure can be relevantly reduced at 
the potential cost of not discovering all available connectors. Peterson et al. [10] have 
demonstrated that it is possible to shorten the Bluetooth inquiry of 50%, by assuming 
the risk of not discovering, on the average, less than 1% of the totally available Blue-
tooth devices. We have followed a similar approach and designed CM to minimize 
the latency in creating single-hop Bluetooth connections: our CM implementation 
adopts a quick discovery procedure (with halved inquiry time according to Peterson's 
guidelines) at system startup and whenever there are no Bluetooth connectors avail-
able; otherwise, when latency requirements are less stringent, a "traditional" discovery 
procedure is exploited to ensure the completeness of the set of discovered connectors. 
NIP exploits the JSR-82 APIs standard to access Bluetooth devices and, through 
the invocation of these APIs, CM implements the optimized inquiry in a portable way. 
However, as better detailed in the following section, even if the JSR-82 adoption 
permits to achieve relevant advantages in terms of portability, the JSR-82 APIs are 
insufficient to support some crucial features of the MMHC middleware, such as 
BNEP networking and RSSI monitoring, thus calling for a portable extension of both 
the JSR-82 specification and its reference implementation. Finally, let us observe that 
the JSR-82 APIs are a relevant support for NIP and for its rapid deployment over off-
the-shelf equipment, but cannot be in place of it. In fact, JSR-82 provides a homoge-
neous access only to Bluetooth devices (operating system and driver independency), 
while NIP supports homogeneous access to a set of heterogeneous wireless technolo-
gies, by supporting common features independently of the exploited wireless  
interface. In other words, in the MMHC architecture, NIP exploits JSR-82 as much as 
possible to access Bluetooth devices portably, while CM exploits NIP to access any 
heterogeneous interface available on MMHC nodes in an interface-independent way. 
5   The MMHC Extensions to the JSR-82 APIs  
The JSR-82 Java APIs for Bluetooth has the purpose of providing Java developers 
with homogeneous access to Bluetooth features, transparently with regards to under-
lying operating systems, Bluetooth drivers, and card implementors. For instance,  
JSR-82 portably supports the discovery of remote devices, the browsing of services 
offered by discovered devices, and the creation of RFCOMM/L2CAP/OBEX connec-
tions. In addition, by exploiting the mechanisms provided by JSR-82, it is possible to 
reduce the latency of the inquiry procedure (see the DiscoveryAgent class and its 
startInquiry() and cancelInquiry() methods).  
To the purpose of easy and runtime portability, our NIP wrapper exploits the JSR-
82 APIs to access Bluetooth devices as much as possible. In particular, it exploits the 
JSR-82 implementation by BlueCove [11], an open-source project for the Mac OS X, 
Linux, and MS Windows operating systems; over MS Windows, BlueCove supports 
multiple drivers, such as Widcomm, BlueSoleil, and the ones compliant with the MS 
Bluetooth stack available starting from Windows XP SP2. However, as already 

 Middleware Solutions for Self-organizing Multi-hop Multi-path Internet Connectivity 
69 
pointed out, JSR-82 cannot provide some features that are central for MMHC working 
and, for that reason, we have decided to significantly extend its capabilities as detailed 
in the following. 
First of all, JSR-82 does not provide any support for the BNEP protocol, which is 
extremely suitable to setup an IP-based network via DHCP in an Ethernet-like style. 
In fact, the JSR-82 specification is mainly oriented on the simple provisioning of 
communication channels for data exchange. It does not support, instead, the possibil-
ity of setting up networking capabilities via the discovery/pairing of remote devices 
and the explicit successive establishment of higher-layer channels, e.g., standard 
TCP/IP sockets exploited by application-level clients and servers. Secondly, JSR-82 
does not provide any facility to gather RSSI values describing the quality of active 
connections. Instead, the periodic monitoring of RSSI values is crucial for CM to 
correctly evaluate the mobility degree of candidate connectors [12]. 
Given the above limitations, we have worked to extend the JSR-82 APIs and refer-
ence implementation (on both Linux and MS Windows XP/Vista2) primarily to  
provide BNEP and RSSI features. We have implemented our extensions by properly 
modifying the Bluecove project source code; on Linux we have exploited BlueZ, its 
official Bluetooth protocol stack; on MS Windows we have focused on Widcomm 
drivers for Bluetooth.  
In particular, by referring to the functionality supported by NIP, the Perform as 
peer connector feature requires setting up a Group ad-hoc Network (PAN GN) [13] 
and activating a DHCP server to automatically configure client-side network parame-
ters. Analogously, Connect to a connector requires accessing to a remote PAN GN 
network and then activating the DHCP client.  
To that purpose, we have extended the JSR-82 APIs by adding a novel BNEPCon-
nector class: it supports both server- and client-side BNEP capabilities via the serv-
er() and client(String remote_addr) methods, respectively exploited by Perform 
as peer connector and Connect to a connector. The server() method is provided on 
Linux nodes based on the exploitation of the BlueZ pand command: 
pand -i hciX --listen --role GN --devup ./devup.sh --master 
where hciX is the identifier of the local Bluetooth device and devup.sh is a script that 
activates a DHCP server whenever a new remote device connects. Note that it is im-
possible to activate the DHCP server before the execution of the BlueZ pand  
command because BlueZ creates a new bnepX virtual interface only after actual con-
nection establishment. For this reason, in this case the DHCP server is started only 
after connection establishment in MMHC, by introducing an additional delay when 
performing new Bluetooth connections. The server() method is not currently im-
plemented on MS Windows because the Widcomm driver does not support the setup 
of a PAN server. In addition, MS Windows XP/Vista does not provide a standardized 
command to configure and start a DHCP server from MMHC, forcing to rely on addi-
tional manual configurations (a command-line and standardized DHCP server is 
available only on MS Windows Server 2008). Therefore, the current implementation 
of MMHC supports Perform as peer connector only for Linux machines, while MS 
Windows nodes can only behave as clients. 
                                                           
2 We are currently working on the prototype of the extended JSR-82 implementation for Ma-
cOSX; that version is the only one not available yet on the MMHC Web site. 

70 
P. Bellavista and C. Giannelli 
On Linux nodes, also the client(String remote_addr) method is provided by 
exploiting the BlueZ pand command but in this case with PAN User role: 
pand -i hciX --connect remote_addr --role PANU --service GN 
where remote_addr is the Bluetooth address of the remote device offering the PAN 
GN network. Once connected, NIP activates the DHCP client via dhclient bnepX 
where bnepX is the virtual interface created at PAN connection establishment. On MS 
Windows the client(String remote_addr) method, instead, exploits the Widcomm 
function: 
LAP_RETURN_CODE CreateConnection( 
BD_ADDR bda,  
GUID guid,  
CSdpDiscoberyRec &sdp_rec 
) 
where bda represents the Bluetooth address of the remote device and guid the PAN type 
(set to CBtlf::guid_SERVCLASS_GN for PAN GN networks). Once connected, NIP per-
forms ipconfig /renew * to properly update the related IP parameters via DHCP. 
The Get available connectors function implemented in our NIP prototype has two 
operating modes: a basic one performing an entire inquiry procedure and another one 
reducing the discovery latency by properly invoking startInquiry() and cancelIn-
quiry() methods of the JSR-82 DiscoveryAgent class according to Peterson's pro-
posal. Moreover, Get available connectors requires gathering not only the list of 
available remote Bluetooth devices, but also their RSSI values. To this purpose we 
provide an implementation of the JSR-82 DiscoveryListener listener which, when-
ever a new remote device is discovered, i) performs a Baseband connection, ii)  
gathers the corresponding RSSI value and iii) provides it to the upper layers (to the 
requesting middleware and/or applications). Note that the establishment of the Base-
band connection is necessary because in Bluetooth there is visibility of RSSI indica-
tions only after device connection. In particular, our MMHC prototype exploits, on 
Linux nodes: 
hcitool -i hciX cc remote_addr 
hcitool -i hciX rssi remote_addr 
to respectively get a Baseband connection (not requiring PIN authentication) and to 
gather RSSI values. Instead, the implementation for MS Windows nodes exploits:  
BOND_RETURN_CODE Bond(BD_ADDR bda, BT_CHAR *pin_code); 
BOOL GetConnectionStats(BD_ADDR bda, tBT_CONN_STATS *p_conn_stats); 
where pin_code is a PIN code of at most 16 characters and p_conn_stats includes 
various data about the connections, such as their RSSI. Note that, differently from 
BlueZ, Widcomm does not currently provide the capability to perform Baseband 
connections; instead it supports the pairing of remote nodes via the Bond function, 
which provides Baseband-like connections with the additional requirement of typing 
PIN codes. 
6   Conclusions  
Our research efforts for the design/implementation of the MMHC prototype and our 
practical experience on its in-the-field deployment over multi-hop networks with  
off-the-shelf equipment demonstrate the feasibility of middleware solutions for  

 Middleware Solutions for Self-organizing Multi-hop Multi-path Internet Connectivity 
71 
self-organizing MMHC solutions. By specifically focusing on Bluetooth multi-hop 
networking, this paper contributes to show the crucial importance of considering both 
client heterogeneity and wireless technology efficiency to support MMHC challeng-
ing scenarios in a feasible, effective, and easily deployable way. Our novel middle-
ware solution exploits the JSR-82 APIs to access Bluetooth devices in an efficient and 
portable manner by realizing an enhanced JSR-82 version to fully support BNEP 
networking and RSSI gathering. The current prototype fully supports Linux nodes, 
while implementation limitations of Widcomm drivers allow MS Windows nodes to 
behave only as MMHC clients. 
The encouraging results that we have already obtained are stimulating our further 
research work in the field. In particular, we are working on lightweight and com-
pletely decentralized models for trust management and incentives to encourage the 
collaborative peer offering of MMHC opportunities in a completely open and dy-
namic execution environment.  
References 
1. Bellavista, P., Corradi, A., Giannelli, C.: Context-aware Middleware for Reliable Multi-
hop Multi-path Connectivity. In: 6th IFIP Work. on Software Technologies for Future 
Embedded & Ubiquitous Systems (SEUS 2008), Anacapri, Italy (October 2008) 
2. Bellavista, P., Corradi, A., Giannelli, C.: A Layered Infrastructure for Mobility-Aware 
Best Connectivity in the Heterogeneous Wireless Internet. In: 1st Int. Conf. on MOBILe 
Wireless MiddleWARE, Operating Systems, and Applications (Mobilware 2008), Inns-
bruck, Austria (February 2008) 
3. Bellavista, P., Corradi, A., Giannelli, C.: Mobility-aware Middleware for Self-Organizing 
Heterogeneous Networks with Multi-hop Multi-path Connectivity. IEEE Wireless Com-
munications Magazine 15(6), 22–30 (2008) 
4. JSR-82 Bluetooth API, http://java.sun.com/javame/reference/apis/  
  jsr082/  
5. Camp, J., Knightly, E.: The IEEE 802.11s Extended Service Set Mesh Networking Stan-
dard. IEEE Communications Magazine 46(8), 120–126 (2008) 
6. Wei, H.-Y., Gitlin, R.D.: Two-hop-relay Architecture for Next-Generation WWAN/ 
WLAN Integration. IEEE Wireless Communications 11(2), 24–30 (2004) 
7. Luo, H., Ramjee, R., Sinha, P., Li, L.E., Lu, S.: UCAN: a Unified Cellular and Ad-hoc 
Network Architecture. In: 9th Int. Conf. Mobile Computing and Networking, San Diego, 
CA, September 2003, pp. 353–367 (2003) 
8. Kang, S.-S., Mutka, M.W.: A Mobile Peer-to-peer Approach for Multimedia Content 
Sharing using 3G/WLAN Dual Mode Channels. Wiley Journal on Wireless Communica-
tions and Mobile Computing 5(6), 633–645 (2005) 
9. Fu, C., Khendek, F., Glitho, R.: Signaling for Multi-media Conferencing in 4G: the Case 
of Integrated 3G/MANETs. IEEE Communications Magazine 44(8), 90–99 (2006) 
10. Peterson, B.S., Baldwin, R.O., Kharoufeh, J.P.: Bluetooth Inquiry Time Characterization 
and Selection. IEEE Trans. on Mobile Computing 5(9), 1173–1187 (2006) 
11. BlueCove JSR-82 Project, http://www.bluecove.org/ 
12. Bellavista, P., Corradi, A., Giannelli, C.: Mobility-Aware Connectivity for Seamless Mul-
timedia Delivery in the Heterogeneous Wireless Internet. In: 2nd Work. on multiMedia 
Applications over Wireless Networks (MediaWiN 2007), Aveiro, Portugal (July 2007) 
13. Bluetooth Profile Specifications, Personal Area Networking Profile (February 2003), 
http://www.bluetooth.com/ 

Location-Based Botany Guide:
A Prototype of Web-Based Tracking and
Guiding
Rui Zhou and Gerhard Schneider
Communication Systems
Institute for Computer Science
University of Freiburg, Germany
{rui.zhou, gerhard.schneider}@rz.uni-freiburg.de
Abstract. Wireless positioning technologies make it possible to keep
track of mobile devices, and Web technologies make Web applications
highly interactive. The combination of them gives rise to location-based
Web applications, which generate and deliver Web content tailored to
user locations. Location-based Web applications are able to utilize the
enormous resources on the Web and allow users to use diﬀerent location-
based services without installing speciﬁc software. The paper presents
a prototype of Web-based tracking and guiding - the Location-Based
Botany Guide, which is a Web-based multimedia guiding system used in
botanical gardens for biology students and visitors. The system adopts a
general architecture for Web-based tracking and guiding, which consists
of the Location Server, the Content Server, the Botanical Guiding Web
Server and the clients. Personalization technology is applied to provide
the users with personalized recommendations and presentations.
Keywords: location-based services, Web, location-based Web applica-
tions, guiding, personalization, botany.
1
Introduction
Development of positioning technologies and wireless networks has given rise to
location-based services, which provide users with services that are tailored to
their locations. Tremendous research has been conducted on location-based ser-
vices over the years [1,2,3]. For example, CyberGuide [4], GUIDE [5], MobiDENK
[6], Hippie [7], CRUMPET [8] and PEACH [9] for tourism services; ActiveCam-
pus [10] deployed on the campus of University of California, San Diego; Safe
& Sound [11] used to monitor children’s locations. Most existent location-based
applications are either standalone programs running on mobile devices or ap-
plications working in client-server mode. The majority lack generality. Diﬀerent
applications require diﬀerent software to be installed on the user’s mobile device.
There is a great need for a general solution.
At present the World Wide Web is the platform for communication, research,
business and many other things. Vast information and resources exist on the
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 72–86, 2009.
c
⃝Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

Location-Based Botany Guide
73
Web. Integrating location-awareness with the World Wide Web not only allows
users to utilize the vast resources on the Web but also enable them to use var-
ious location-based applications and services without installing extra software.
There are some researches on the integration of location-awareness with the
Web. GPSWeb [12] introduces the concept of location-based browsing and aims
to provide GPS support for Web browsers. LAWS [13] is a location-aware sys-
tem built on top of HTTP with a modiﬁed Web browser. Web-Enhanced GPS
[14] demonstrates the possibilities of creating location-based services on mobile
devices using existing data on the Web and the position information from a GPS
receiver. HP Labs Cooltown project [15] builds a software model, the Web pres-
ence manager, to support the integration of the physical world and the Web.
Simon et al. [16] present an application framework that leverages geospatial
content on the Web on mobile phones and PDAs.
The Location-Based Botany Guide is a prototype of Web-based tracking and
guiding to be used in the Botanical Garden of Freiburg in Germany. Diﬀerent
from the previous work in both architecture and application ﬁeld, it demonstrates
how a Web-based tracking and guiding system works and how it is implemented.
Botanical gardens are places where people often visit. The conventional ways of
providing botanical information include guided tours by a botanist or expla-
nations on speciﬁc web sites. Guided tours by a botanist can provide detailed
and scientiﬁc information but are rather expensive. Information on the web sites
is usually free of charge, but not tailored to the users. The Location-Based
Botany Guide solves the problem well by tracking the users and providing them
with location-based, personalized, scientiﬁc and cohesive multimedia informa-
tion about the nearby plants. It can be used as a learning system for biology
students as well as an electronic guide for visitors. Personalization is applied to
enhance the guiding and learning process.
The paper is organized as follows. Section 2 ﬁrst describes the functions and
features of the Location-Based Botany Guide. Section 3 presents the general
architecture of the system. The implementation of the location-based and per-
sonalized services is presented in Section 4. Privacy issues are discussed in Section
5. Section 6 concludes the paper and presents the directions for the future work.
2
The Location-Based Botany Guide
The Location-Based Botany Guide is a prototypical application of Web-based
tracking and guiding that we are developing for the Botanical Garden of Freiburg,
Germany. When the users walk in the botanical garden, the system provides
them with personalized, scientiﬁc and cohesive multimedia presentations about
the nearby plants according to their locations, context and characteristics. The
botanical garden is covered with wireless LAN. The users must be equipped
with a laptop, tablet PC or handheld that is Wi-Fi-enabled and optionally GPS-
enabled. Before a user uses the system, he or she must log in. After authenticating
the user, the system sets up an initial user and context model of him or her and
updates the model continuously during the whole course until the user logs out.

74
R. Zhou and G. Schneider
The system can be used as a location-based learning system for biology students
as well as an electronic botany guide for visitors.
Let us take an example: a student goes to the botanical garden. She opens the
Web browser, types in the Web address of the Location-Based Botany Guide,
logs in and begins to study with the system. The system provides the map mode
and the guide mode. In the map mode, she gets a dynamic interactive online
map of the garden with the botanical information embedded. While walking in
the garden, her real-time location is displayed on the map. In the guide mode,
the system keeps track of her and presents the personalized multimedia learning
material of the nearby plants in her Web browser automatically.
2.1
Botanical Domain
The system is an application in the ﬁeld of botany. Therefore, the contents are
organized and presented based on the botanical domain, which is categorized
Fig. 1. Part of the botanical taxonomy of angiosperm

Location-Based Botany Guide
75
Fig. 2. Plantation of angiosperm in the Botanical Garden of Freiburg
to the botanical taxonomy. Fig. 1 shows part of the botanical taxonomy of
angiosperm stored in our database. We use the following botanical taxonomical
levels: system, group, class, order, family, subfamily, genus and species. Although
the plantation in the botanical garden is according to the botanical taxonomy, it
has a diﬀerent geographic hierarchy. As shown in Fig. 2, the tree structure on the
map is the plantation of the system of angiosperm, according to its evolution.
The circles on the tree structure are orders, in which are planted individuals.
Based on the plantation, we use the plantation levels of garden, system, order
and individual for location-based content queries.
2.2
Interactive Map
An interactive map is always necessary for a guiding system, which shows where
the user is and what is around and guides the user through the tour. The
Location-Based Botany Guide is no exception, which provides an online interac-
tive map of the botanical garden with the botanical information embedded and
the user’s real-time location marked. The map and the embedded botanical in-
formation are dynamically generated from the Content Server via Simple Object
Access Protocol (SOAP), and the information is grouped into layers so that the
users can choose which layers to display. Using GPS and Wi-Fi ﬁngerprinting,
the system is able to locate and track the user and mark his or her real-time
location on the map continuously. The system is also able to display the plant
that the user searches for and guide him or her to that plant.
The interactive map is implemented with OpenLayers technology [17], which
is an open source map viewing library written in pure JavaScript and can dis-
play map tiles and markers loaded from any source. OpenLayers implements a
JavaScript API that we can use to put a dynamic map in web pages easily and
build rich Web-based geographic applications.

76
R. Zhou and G. Schneider
Fig. 3. Guide mode of the Location-Based Botany Guide
2.3
Botany Guide
The botany guide is the most important function of the system. Fig. 3 shows
a snapshot of the guide mode. The user can choose between locate mode and
track mode. In track mode, the system keeps track of the user and presents
the botanical information about the nearby plants promptly and automatically
while the user is walking around in the botanical garden. In locate mode, the
system determines the current location of the user and presents the botani-
cal information after the user issues the locate command. In both track and
locate mode, the system ﬁrst performs location-dependent content queries to
retrieve the plants in the vicinity and recommends a short list of related plants
based on the user characteristics and the context. After the user chooses what
to learn from the list, the system composes a personalized presentation of the
chosen plant and delivers it to the user. The user can choose the query type
from planar point query, window query, nearest neighbour(s) query or com-
posite query. He or she can choose the notiﬁcation mode (update the page
automatically or give a hint). The information can be presented in one page,
in multiple pages, or as slideshow. The botanical information presented in-
cludes the botanical description of the plant, additional multimedia informa-
tion, hyperlinks to its taxonomical parents and ancestors, hyperlinks to its
taxonomical children or planted individuals, scientiﬁc self-tests, and personal
recommendations.

Location-Based Botany Guide
77
3
Architecture
The architecture of the Location-Based Botany Guide is a general-purpose so-
lution for Web-based tracking and guiding. Web-based tracking and guiding in-
tegrates location-awareness even context-awareness with Web applications and
realizes tracking and guiding on the Web. The clients are standard Web browsers
and the server is a standard Web server capable of generating location-based Web
content in real time.
The process of Web-based tracking and guiding can be divided to four parts:
location-aware Web system, location determination, location-dependent content
query and personalized presentation. A location-aware Web system is the under-
lying infrastructure for Web-based tracking and guiding. It allows the transmis-
sion of location information from the Web browser to the Web server (since most
positioning devices, such as GPS, are on the user side) and enables the automatic
update of Web pages in the Web browser. Location determination is one of the
most important prerequisites and ingredients for any location-based application.
With knowledge of user locations, the Web server performs location-dependent
content queries to retrieve the relevant content. After receiving the location-
dependent content, the Web server generates the personalized presentation and
delivers the presentation to the user. [18]
Based on the process of Web-based tracking and guiding, the architecture of
the Location-Based Botany Guide is composed of the Botanical Guiding Web
Server, the Location Server, the Content Server, and the clients, as Fig. 4 illus-
trates. The Botanical Guiding Web Server, the Location Server and the Content
Server constitute the server side of the system. The Botanical Guiding Web
Server interacts with the clients, while the Location Server and the Content
Server serve the Botanical Guiding Web Server.
Fig. 4. Architecture of the Location-Based Botany Guide

78
R. Zhou and G. Schneider
3.1
Client
The client of the system is standard Web browsers. Since positioning devices
are usually installed on the user side, the location-related parameters, such as
GPS coordinate and Wi-Fi ﬁngerprint, must be retrieved from the local hard-
ware by the Web browser and transmitted to the Web server. This feature
will be supported by standard Web browsers in the near future [19]. Currently
we rely on a Web browser extension, called the Location Control, to retrieve
the location-related parameters from the local positioning hardware. An Asyn-
chronous JavaScript and XML (AJAX) program running within the Web browser
invokes the Location Control, collects the GPS data and Wi-Fi data, then trans-
mits them to the Web server so that the Web server can keep track of the client.
The location-based Web content generated by the Web server is delivered and
displayed in the Web browser automatically through the AJAX program. The
Location Control is general purpose and can be used by any location-based Web
applications using the same framework.
3.2
Botanical Guiding Web Server
The Botanical Guiding Web Server is a standard Web server hosting the tracking
and guiding system. It authenticates the users, performs location queries to
the Location Server for user locations, performs content queries to the Content
Server, generates location-based Web content, implements the interactive map
and the botany guide. The Botanical Guiding Web Server builds and updates
the user and context model for every user and hence realizes personalization.
When receiving a locate or track request from a client, the Botanical Guiding
Web Server ﬁrst extracts the location-related parameters from the client request,
queries the Location Server about the current location of the user, then queries
the Content Server about the location-dependent content, afterwards generates
personalized Web content and delivers it back to the client.
3.3
Location Server
The Location Server runs the location determination algorithms and provides
location services via SOAP. This way it is independent from any particular ap-
plication and can be used by other applications. It receives location queries with
location-related parameters and replies with the coordinates. GPS and Wi-Fi
ﬁngerprinting are combined to provide an improved and more stable positioning
service. Management of the Location Server is via Web pages, which includes
conﬁguration of positioning algorithms, calibration of Wi-Fi ﬁngerprinting, man-
agement of the radio map. There are two reasons that we implement location
determination on the dedicated Location Server. One is that the client should
be general-purpose and lightweight since it is a Web browser with an extension,
the other is that mobile devices are not suitable for complex algorithms due to
limited computing and battery capabilities. Therefore, our solution is that the
client only collects the location-related parameters from the local hardware and

Location-Based Botany Guide
79
leaves the location determination algorithm to the dedicated Location Server.
Any location-aware Web system adopting such an architecture can share the
same Web browser extension.
3.4
Content Server
With knowledge of user locations, the Botanical Guiding Web Server performs
location-dependent content queries to the Content Server to retrieve the relevant
content. The Content Server stores the multimedia content in a MySQL database
and provides the content services via SOAP as well, which makes the database
structure transparent and independent. It receives both location-dependent and
non-location-dependent content queries, performs appropriate spatial or non-
spatial search in the database, and replies with the relevant content. Management
of the Content Server is Web-based. Organization of the content in the database
takes into account both botanical and spatial features. The database is organized
according to the botanical taxonomy. The records in the database are bound to
a geographic location (i.e. a point) or a geographic area (i.e. a polygon) in order
for location-awareness. The database is indexed on the geographic attribute to
improve search eﬃciency.
4
Location-Based and Personalized Services
4.1
User and Context Modeling
Personalization is of signiﬁcant value to location-based applications. It tailors
the content to the users based on their locations, knowledge, interests and so on.
Personalization constitutes an iterative process of user and context modeling and
adaptive content presentation. Personalization is based on the user and context
model, which is the collection of information that characterizes the user and the
contextual situation in which he or she is. [20,21]
Stereotype. The Location-Based Botany Guide requires the user to log in with a
username. After authentication, the system sets up the initial user and context
model based on the registration information of the user and determines his or her
stereotype accordingly. Three stereotypes exist in the system: teachers, biology
students, and visitors. Diﬀerent stereotypes require diﬀerent contents.
User knowledge. User knowledge modeling enables the system to adapt the learn-
ing activity to the user’s knowledge level. The user knowledge model in the
Location-Based Botany Guide is based on the botanical taxonomy and mod-
els the user’s knowledge of every taxonomical entity independently via qualita-
tive values (novice, intermediate and advanced). An example of user knowledge
model is {(Magnoliales, intermediate), (Magnoliaceae, intermediate), (Ranuncu-
lales, novice)}. Before the system presents the content for a plant, it ﬁrst checks
the user knowledge level and presents the content accordingly. The system de-
termines the user knowledge by botanical self-tests predeﬁned by the teachers.

80
R. Zhou and G. Schneider
Change of the knowledge level of a plant will lead to the change of the knowledge
level of its botanical parents and children (a process of knowledge propagation).
User interests. User interest modeling allows the system to provide the informa-
tion that the user is interested in. Similar to the user knowledge model, the user
interest model is based on the botanical taxonomy too and models the user’s
interest in every taxonomical entity independently via qualitative values (low,
intermediate and high). For example, {(Magnoliales, intermediate), (Magnoli-
aceae, intermediate), (Ranunculales, low)}. The user interest model is empty
initially, and gets updated through the interaction between the user and the
system. The interest level of a plant will be increased if the user chooses to read
it. The longer the user stays at the plant, the higher the interest level can be.
If the user is interested in a plant, he or she may be interested in its botanical
parents and botanical children (called interest propagation).
Preferences, device and season. The user can specify the multimedia types that
he or she prefers, the notiﬁcation mode when a new presentation is available
(auto start or give a hint), and the presentation mode (all in one page, multi-
pages, or slideshow). Diﬀerent portable devices have diﬀerent operating systems,
screen sizes, software and capabilities, which makes the user experiences quite
diﬀerent. The system is able to adapt the presentation to the device. Since
there are many combinations of features of portable devices, the system maps
the combinations of features to a few stereotypes and presents the information
according to the stereotype. The system also adapts the presentation to the
season as the plants are seasonal.
4.2
Location Determination
Many systems have tackled the problem of location determination over the years,
such as GPS, Wi-Fi, GSM and RFID. GPS is currently the predominant mech-
anism for outdoor positioning. With its modernization it aims to provide signal
redundancy and improve positioning accuracy, signal availability and system in-
tegrity [22]. GALILEO, the European satellite navigation system supposed to
be in operation by 2013, will provide a highly accurate, guaranteed global posi-
tioning service under civilian control, and promises real-time positioning down
to less than a meter [23]. For indoors, Wi-Fi positioning is a promising ap-
proach, which makes use of 802.11 signal for location determination and is able
to achieve the accuracy of a few meters [24,25]. Diﬀerent positioning approaches
can be combined for improved accuracy and performance.
One of our design principles is to make use of available and cheap devices.
Current GPS has diﬃculties providing accurate locations under pool signal con-
ditions and takes up to a few minutes for the ﬁrst position ﬁx. Therefore, both
GPS and Wi-Fi ﬁngerprinting positioning are adopted in our system. According
to the number of satellites in view and Horizontal Dilution of Precision (HDOP),
we can decide to use GPS, Wi-Fi ﬁngerprinting, or a combination of them, as
illustrated in Fig. 5.

Location-Based Botany Guide
81
Fig. 5. Combine GPS and Wi-Fi ﬁngerprinting for location determination
As Wi-Fi signal strength oscillates randomly and users can not jump big
distances, a history-based Wi-Fi ﬁngerprinting algorithm is used in our system,
which makes use of a series of consecutive signal strength instead of only the
current one for location determination. According to the Euclidean distance of
signal strength, the k most likely estimations of the unknown location, called
the “k nearest neighbors”, can be determined. Repeat this step periodically, an
h-depth history of “k nearest neighbors” will be formed. Calculate the shortest
path from the ﬁrst column to the last column in the h-depth history vector, the
end node on the shortest path is the current estimated location. In the indoor
area, the layout and interior structure of the building is applied which is proved
to be able to reduce logical errors such as wrong estimations of rooms or wrong
estimations of ﬂoors. Even if the cubical spatial distance between two locations
on two diﬀerent ﬂoors may be short, the path between them is long since they
can only be connected via staircases or lifts. Using the path distance instead of
the cubical spatial distance as the physical distance, the history-based algorithm
can reduce the wrong estimations of rooms and ﬂoors eﬀectively. [26]
4.3
Content Query and Recommendations
The system supports three basic types of location-dependent content queries:
planar point query, window query and nearest neighbours query. With planar
point queries [27], the system queries whether the user is in the garden or in a
certain plantation subarea. With window queries [28], using the user’s current
location as the center and a speciﬁed distance as the radius, the system returns
all the plants or subareas that are within or intersect with the circle window.
With nearest neighbours queries [28], the system returns the nearest plants or
subareas to the user.
Plants in botanical gardens are planted in a systematic and hierarchical way.
Therefore, the query should be performed in a systematic way too. We adopt
a combination of planar point query and window query (illustrated in Fig. 6)
to ﬁnd the most relevant information. The system ﬁrst performs a planar point
query to determine whether the user enters a new subarea or stays in the same
subarea. If the user enters a new subarea, the system gives him or her a hint that
he or she is entering a new subarea and presents the introductory information
about the new subarea. If the user stays in the same subarea, the system performs

82
R. Zhou and G. Schneider
Fig. 6. Location-dependent content query
window query within the subarea and makes ranked recommendations of nearby
plants (or subareas) based on the user and context model.
Plants in botanical gardens are usually planted densely. It is often impossible
to distinguish individual plants with the currently available and cheap position-
ing devices. Therefore, the system makes a short list of recommendations based
on the query result and the user and context model, from which the user can
choose. The plants on the list have a picture of the current season to help the
user choose the plant that he or she is interested in or looking at. In addition,
the system marks the recommended plants on a properly zoomed map for visual
navigation. The recommendation will be ranked according to the user and con-
text model, in order that the most relevant plants appear ﬁrst. The process of
ranking is as follows [21]:
1. Remove irrelevant plants. Each plant goes through the user and context
model and only the matched plants pass through. The plants must match
the stereotype of the user, the knowledge level of the user, the interest level,
the preferences and the season.
2. Rank relevant plants. The plants are ranked according to the following at-
tributes (the order of the attributes reﬂects their importance for ranking):
(a) the interest level of the user to the plant. The plant with a higher interest
level goes ﬁrst.
(b) the knowledge level of the user to the plant. The plant with a lower
knowledge level goes ﬁrst.
(c) the distance between the user and the plant.
4.4
Personalized Presentation
Recommendations are a list of plants, from which the user chooses which one
to see. After the user has chosen a plant, the system retrieves the multimedia

Location-Based Botany Guide
83
content about the plant from the Content Server, composes them to a cohesive
presentation and delivers it to the user. The content selection is based on:
– The stereotype of the user.
– The knowledge level of the user. If the user is a novice, the introductory
information will be selected; if intermediate, the intermediate information
will be selected; if advanced, the advanced information will be selected.
– The interest level of the user. If the interest level is low, only the very brief
information will be selected; if intermediate, more detailed information be
selected; if high, full explanation will be selected.
– Preferences, device and season.
As illustrated in Fig. 7, based on the user and context model and the prede-
ﬁned templates, the selected contents are composed to an internal multimedia
document tree [29], which contains the medium elements to be presented and
describes the spatial and temporal relationships between them and how they
will be presented. The multimedia document tree can be transformed to diﬀer-
ent formats such as HTML or Flash based on the user’s device and preferences,
hence makes it possible to dynamically author the personalized multimedia pre-
sentation in diﬀerent formats and for diﬀerent devices. [21]
Fig. 7. Personalized presentation
5
Privacy and Security
Privacy is always a concern for location-based services, since user locations are
disclosed which can be used to reason user activities and interests. The privacy

84
R. Zhou and G. Schneider
principles adopted in the Location-Based Botany Guide are to minimize informa-
tion disclosure while beneﬁting from the service and to leave the users in control
of their information revelation. In our system the positioning devices are on the
user side. The user decides when to start and when to stop tracking. Only after
the user issues a locate or track command, the location-related parameters will
be collected and sent to the server. This puts the users in control of location rev-
elation and allows them to trade privacy for utility on a case-by-case basis. User
information contained in the user and context model is stored on the Botanical
Guiding Web server temporarily for the current session. As soon as the user logs
out, his or her information will be deleted immediately, and stored as cookies
on his or her own mobile device. A user can use the system with a pseudoname
instead of his or her real identity. Thus there is no direct link between the stored
data and the real user identity, the privacy is hence enhanced.
The system uses wireless LAN for the data communication between the clients
and the servers, which is protected by VPN. The Botanical Guiding Web Server
and the clients authenticate to each other through secure HTTP. The users must
log in before using the system and the system authenticates itself by providing
a valid certiﬁcate. The Web browser extension (i.e. the Location Control) is a
program running locally on the mobile device and is able to access local resources.
A malicious one may result in severe privacy disclosure, information loss and
other damages. Therefore, the extension should be signed to make sure it is not
tampered with by third parties.
6
Conclusions and Future Work
We have presented a Web-based and personalized guiding system in botanical
gardens, which provides location-dependent and personalized botanical content
to students or visitors in the garden. The system demonstrates the possibility of
integrating location-awareness with the World Wide Web to create Web-based
tracking and guiding systems. The system consists of the Location Server, the
Content Server, the Botanical Guiding Web Server and the clients which are
standard Web browsers extended with the Location Control. The system allows
users to use location-based applications without speciﬁc software and to uti-
lize the vast resources on the Web. The architecture and design of the system
provides a general framework for similar applications.
Currently the system is a local application used in botanical gardens. In the
future, we will make a more general framework for applications in other ﬁelds,
which may be local area applications or wide area applications. There are vast
information and resources on the Web. Utilizing the information on the Web
will free us from the tedious process of creating the content database. How to
perform location-dependent Web search and how to retrieve location-dependent
Web content will be part of our next research. Personalized recommendation
and presentation based on user and context model still need to be improved.
Evaluation of the system and evaluation of how the users like the system will be
conducted in the near future.

Location-Based Botany Guide
85
References
1. Schwinger, W., Gr¨un, C., Pr¨oll, B., Retschitzegger, W., Schauerhuber, A.: Context-
awareness in Mobile Tourism Guides - A Comprehensive Survey. Technical Report
(2005)
2. Baus, J., Cheverst, K., Kray, C.: A Survey of Map-based Mobile Guides. In: Map-
based mobile services - Theories, Methods and Implementations Meng/Zipf (Hrsg),
pp. 197–213. Springer, Heidelberg (2005)
3. Baldauf, M., Dustdar, S., Rosenberg, F.: A Survey on Context-Aware Systems.
International Journal of Ad Hoc and Ubiquitous Computing 2(4), 263–277 (2007)
4. Long, S., Kooper, R., Abowd, G.D., Atkeson, C.G.: Rapid Prototyping of Mobile
Context-Aware Applications: The Cyberguide Case Study. In: 2nd ACM Interna-
tional Conference on Mobile Computing and Networking (MobiCom 1996) (1996)
5. Davies, N., Cheverst, K., Mitchell, K., Efrat, A.: Using and Determining Location
in a Context-Sensitive Tour Guide. IEEE computer 34(8), 35–41 (2001)
6. Kr¨osche, J., Baldzer, J., Boll, S.: MobiDENK-Mobile Multimedia in Monument
Conservation. IEEE MultiMedia 11(2), 72–77 (2004)
7. Oppermann, R., Specht, M.: A Context-Sensitive Nomadic Exhibition Guide. In:
2nd International Symposium on Handheld and Ubiquitous Computing, pp. 127–
142 (2000)
8. Poslad, S., Laamanen, H., Malaka, R., Nick, A., Buckle, P., Zipf, A.: CRUMPET:
Creation of User-friendly Mobile Services Personalized for Tourism. In: 2nd Inter-
national Conference on 3G Mobile Communication Technologies, pp. 28–32 (2001)
9. Personal Experience with Active Cultural Heritage (PEACH),
http://peach.itc.it/home.html
10. ActiveCampus, http://activecampus.ucsd.edu
11. Marmasse, M., Schmandt, C.: Safe & Sound: A Wireless Leash. In: Conference on
Human Factors in Computing Systems, pp. 726–727 (2003)
12. Carboni, D., Giroux, S., Piras, A., Sanna, S.: The Web around the Corner: Aug-
menting the Browser with GPS. In: 13th International World Wide Web Conference
on Alternate Track Papers & Posters, pp. 310–319 (2004)
13. Haghighat, A., Lopes, C.V., Givargis, T., Mandal, A.: Location-Aware Web Sys-
tem. In: Workshop on Building Software for Pervasive Computing (2004)
14. Hariharan, R., Krumm, J., Horvitz, E.: Web-Enhanced GPS. In: 1st International
Workshop on Location- and Context-Awareness, Germany, pp. 95–104 (2005)
15. Debaty, P., Goddi, P., Vorbau, A.: Integrating the Physical World with the Web
to Enable Context-Enhanced Mobile Services. Mobile Networks and Applica-
tions 10(4), 385–394 (2005)
16. Simon, R., Fr¨ohlich, P.: A Mobile Application Framework for the Geospatial Web.
In: 16th International Conference on World Wide Web, Banﬀ, Alberta, Canada,
pp. 381–390 (2007)
17. OpenLayers: Free Maps for the Web, http://openlayers.org/
18. Zhou, R.: Enable Web-Based Tracking and Guiding by Integrating Location-
Awareness and the World Wide Web. Campus-Wide Information Systems 25(5),
311–328 (2008)
19. Geolocation API Speciﬁcation, http://dev.w3.org/geo/api/spec-source.html
20. Brusilovsky, P., Millan, E.: User Models for Adaptive Hypermedia and Adaptive
Educational Systems. In: The Adaptive Web - Methods and Strategies of Web
Personalization. Springer, Heidelberg (2007)

86
R. Zhou and G. Schneider
21. Zhou, R., Rechert, K.: Personalization for Location-Based E-Learning. In: 2nd
IEEE Conference on Next Generation Mobile Applications, Services, and Tech-
nologies, Cardiﬀ, Wales, UK, pp. 247–253 (2008)
22. Alkan, R.M., Karaman, H., Sahin, M.: GPS, GALILEO and GLONASS satellite
navigation systems & GPS modernization. In: 2nd International Conference on
Recent Advances in Space Technologies, pp. 390–394 (2005)
23. Getting Galileo into Orbit by 2013, http://www.europarl.europa.eu/sides/
getDoc.do?language=EN&type=IM-PRESS&reference=20080414BKG26528
24. Bahl, P., Padmanabhan, V.N.: RADAR: An In-Building RF-Based Location and
Tracking Systems. In: IEEE INFOCOM 2000, Tel-Aviv, Israel (2000)
25. Youssef, M., Agrawal, A., Shankar, A.U.: WLAN Location Determination via Clus-
tering and Probability Distributions. In: 1st IEEE International Conference on
Pervasive Computing and Communications, pp. 143–150 (2003)
26. Zhou, R.: Enhanced Wireless Indoor Tracking System in Multi-ﬂoor Buildings with
Location Prediction. In: 12th International Conference of European University In-
formation Systems, pp. 448–453 (2006)
27. Xu, J., Zheng, B., Lee, W.-C., Lee, D.L.: The D-Tree: An Index Structure for
Planar Point Queries in Location-Based Wireless Services. IEEE Transactions on
Knowledge and Data Engineering 16(12), 1526–1542 (2004)
28. Zhang, J., Zhu, M., Papadias, D., Tao, Y., Lee, D.L.: Location-based Spatial
Queries. In: the 2003 ACM SIGMOD International Conference on Management
of Data, San Diego, California, pp. 443–454 (2003)
29. Scherp, A.: A Component Framework for Personalized Multimedia Applications.
Ph.D. dissertation, Dept. of Computer Science, University of Oldenburg, Olden-
burg, Germany (2006)

C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 87–100, 2009. 
© Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009 
Parallel Data Transfer with Voice Calls for  
Energy-Efficient Mobile Services 
Jukka K. Nurminen and Janne Nöyränen 
Nokia Research Center, Helsinki, Finland 
{jukka.k.nurminen,janne.noyranen}@nokia.com 
Abstract. Battery consumption is one challenge for mobile applications and 
services. In this paper we explore the scenario where mobile phones delay the 
transfer of non-urgent data and perform the communication while a voice call is 
active. Our measurements show that data transfer during voice call requires 
only slightly over 10% additional power and that simultaneous voice call slows 
down the file transfer by 3%-14%. As a result we can save over 80% of energy 
in data transfer if we can delay the communication to a time when user is speak-
ing at the mobile phone. For a user speaking 26 minutes a day this would allow 
50MB of low energy data communication. A large class of applications can de-
lay their data transfer without major effect to the user experience. The power 
saving mechanism can be implemented either in an application specific fashion 
or, preferably, at the middleware layer. 
Keywords: Energy-efficiency, mobile services, data transfer, application  
cooperation. 
1   Introduction 
The introduction of mobile services has resulted into increased need to transfer data 
between mobile phones and external computing devices, typically server computers. 
The communication between the mobile device and the server consumes energy. 
Extensive use of mobile services thus drains the battery and results into user 
dissatisfaction. 
In this research, we investigate new possibilities for energy efficiency that are 
based on co-operation between different applications residing on the mobile device. 
In particular, we explore the effect of parallel voice calls and data transfers. 
While some researchers have investigated the battery consumption of mobile 
applications [1-3], there is little work that studies the cooperation of different 
applications. Since the adoption of mobile services is still in an early state, it is not 
very common that a mobile phone accesses multiple services. However, this is likely to 
change when the popularity of mobile services grows. Intelligent cooperation between 
the different applications is likely to reduce needed energy in comparison to the case 
where each application in isolation tries to minimize its own energy consumption. 
In spite of the emergence of new mobile services, using the mobile phone for 
conversations, voice calls, is likely to be an important use case also in the future. The 

88 
J.K. Nurminen and J. Nöyränen 
idea we investigate in this paper is to delay non-time critical data transfers and 
perform them during voice calls. This kind of collaboration between the applications 
has potential for major energy savings. Once the radio of the mobile device is 
activated for voice communication, we can use it for the transfer of other data with 
little extra energy consumption. The bandwidth needed for voice is so small that in a 
typical network the radio channel can be used to transfer other data in parallel to the 
voice stream.  
For many application the needed data transfer is not very time critical. For instance, 
downloading of upgrades, podcasts, emails, or RSS feeds as well as uploading of 
photos, backups, or calendar settings can be delayed in many cases without major effect 
on user experience. Naturally, the needs of different users and different applications 
vary but the set of services a user is using is likely to contain also a number of non-time 
critical ones. The possibility to delay some of the communication to happen in parallel 
with voice calls may allow us to develop new mechanisms for energy efficiency. 
The key contribution of this research is to present the concept of delaying non-
urgent data transfers so that they would take place during voice calls. We evaluate the 
proposed approach by power measurements with actual mobile phones. Finally we 
discuss the applicability of this approach and discuss the implementation alternatives. 
The rest of the paper is structured as follows. Section 2 describes the situation when 
multiple services are in use in a mobile device. Section 3 presents our measurements 
that allow us to compare standalone data transfer with data transfer during a voice call 
in UMTS networks. Section 4 discusses the underlying mechanisms why data transfer 
in parallel with voice call is energy efficient. Section 5 discusses alternative 
architectural solution that would allow extending applications with this functionality.  
Section 6 discusses the solution and in particular evaluates its usage potential and its 
limitations. Section 7 reviews related research. Finally, section 8 concludes the paper 
and presents ideas for further research. 
2   Interoperability of Mobile Service Data Transfer and Voice 
Calls 
Currently, when multiple services are running on the same mobile device they  
typically schedule their activities independently without considering the other applica-
tions and services. Figure 1 shows an example of a case when the mobile phone is  
using email service and a photo upload service. The active periods of different  
applications are marked with colored rectangles.  
Email service is an example of a periodic service. It checks periodically (with in-
terval δemail) if new mail has arrived. If new mail has arrived it is downloaded to the 
mobile phone. The length of the activity period varies as a function of the number and 
size of the email messages. 
Photo upload is an example of a user (or application) triggered activity. User takes 
a photo and the system uploads it to a photo sharing service. The uploading activity is 
started by a user action (shooting the picture or decision to store it). 
Finally, voice call activities are started at arbitrary time points either by the user or 
by calls coming in from the network. 

 
Parallel Data Transfer with Voice Calls for Energy-Efficient Mobile Services 
89 
 
Fig. 1. Example sequence of events of three applications: email, photo upload, and voice call. 
Combined (trivial) shows the case where communication is started immediately for each appli-
cation. Combined (delayed) shows the case where the communication is delayed to the time of 
the next voice call. 
When we analyze the combined effect of these three services as depicted on the 
line “Combined (trivial)” in Figure 1, we can see that when the starting times of these 
activities are chosen independently from each other, they occupy a large part of the 
time axis. This means that whenever any single application is active and transferring 
data, the radio of the mobile phone has to be powered on. As a result the energy con-
sumption of the combined use case is high. 
However, if we have a possibility to delay the communication of the mobile ser-
vices we can improve the situation. The line “Combined (delayed)” of Figure 1 shows 
the case when we delay the data transfer of non-urgent communications (email and 
photo upload activities in the example). Instead of following application specific 
schedules we put the data transfer needs into a waitlist and whenever a user makes or 
receives a voice call we activate the data transfers of the waiting services. As can be 
seen from Figure 1 the time when there are no ongoing data transfer activities is much 
longer when the delayed combination of different services is done.  
Although the example shows the email and photo upload services as examples it 
should be easy to realize that there are a number of applications where such a combi-
nation makes sense. In fact, the more services the user is running on his device the 
higher the potential benefit from their smart combination. 
Building on the idea of Figure 1 it seems promising to schedule the data transfer of 
mobile services so that as much of the data transfer activities are taking place at the 
same time. A very simple mechanism to achieve this is to delay the data transfer of 
non-urgent services until a time when the user is having a phone call. The exact bene-
fit of this approach depends on the services the user is using, the available bandwidth, 
and on the pattern of events that take place. Naturally the potential savings also  

90 
J.K. Nurminen and J. Nöyränen 
depend on how much extra energy is consumed when data transfer is happening in 
parallel to voice call and on the slowdown that simultaneous voice call causes for the 
data transfer. In the next section we investigate these aspects in detail. 
3   Quantitative Evaluation with Nokia N95 
In this section we evaluate the potential of the concept by analyzing the energy con-
sumption of a mobile phone. We used Nokia N95 as the test device and performed 
the energy measurements with the Nokia Energy Profiler application that is available 
free of charge at Forum Nokia (www.forum.nokia.com). We performed the meas-
urements in downtown office area in Helsinki, Finland, using the network of Elisa 
cellular operator. 
Figure 2 shows the chart of an example measurement. The x-axis of the chart 
shows the time and the y-axis the power consumption. For this chart we downloaded a 
2M email attachment with IMAP protocol using the native messaging application of 
the mobile phone. 
 
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
2
0
5
10
15
20
25
30
35
40
45
50
55
60
65
70
75
80
85
90
95
100
105
110
115
120
125
Voice Call
2MB DL HSDPA
Both
W
s
 
Fig. 2. Power consumption when a) a voice call is active, b) a data download is active, and c) 
both voice call and data download are active at the same time 
The chart shows the energy consumption in three different cases: 
• The light gray/orange curve shows the energy consumption when only a voice call 
is active. In the early part 15-80s the voice call is active and the display light is on. 
When the display light is switched off at 80s the energy consumption drops from 
1.5 W to 1.2W. 

 
Parallel Data Transfer with Voice Calls for Energy-Efficient Mobile Services 
91 
• The dark grey/blue curve shows the energy consumption when the phone is 
downloading content. As the figure shows the energy consumption is rather similar 
than in the case of voice call. When the display light is on the power consumption 
is around 1.5W (20-90s and 110-115s). When the display light is off the power 
consumption is around 1.2W 
• The thick gray/green curve shows a case when both voice call and data download 
are active simultaneously. The energy consumption is around 1.7W and 1.4 W 
when the display light is on and off respectively. 
We can see from the combined curve than when data download is performed during a 
voice call the power consumption is only slightly higher than what the voice call 
would anyhow require. In this measurement the extra power is only 10%. Likewise 
we can see that the data transfer time increases when done during voice call but the 
increase is not very big, only 12%. As a result if we do the data transfer during a 
voice call we are able to perform the same activity with only 23% of the energy that it 
would take without the voice call.  
Table 1. Measurement results comparing parallel data transfer during voice call with stand-
alone data transfer 
 
Power (W) 
Transfer time (s) 
Energy (J) 
 
Avg 
Diff  
Total  
Diff  
Total  
Additional 
Ratio 
IMAP download of an email attachment (2.0 MB) 
Data 
transfer 
only 
1.25 
 
101 
 
126 
119 
 
Data 
transfer 
during 
voice call 
1.39 
11.2% 
109 
7.9% 
152 
16 
14% 
HTTP download of  a 3gp video (2.1 MB) 
Data 
transfer 
only 
1.22 
 
109 
 
133 
125 
 
Data 
transfer 
during 
voice call 
1.35 
10.7% 
124 
13.8% 
167 
14 
11% 
Video Center download (10.1 MB) 
Data 
transfer 
only 
1.23 
 
476 
 
585 
552 
 
Data 
transfer 
during 
voice call 
1.38 
12.2% 
488 
2.6% 
676 
68 
12% 
 
 
 

92 
J.K. Nurminen and J. Nöyränen 
The detailed measurement results are listed in Table 1. We measured three  
different cases:  
• download of a 2.0 MB email attachment with IMAP protocol with the native mes-
saging client,  
• download of a 2.1 MB video with HTTP protocol with the native browser (“Ein-
stein the bird” from www.free-3gp-video.com),  
• and download of a 10.1 MB video with the Video Center application (“E90” from 
“Nokia N-series” channel).  
To eliminate the variance of service load and network congestion we performed the 
measurements simultaneously with two similar Nokia N95 phones. One phone had a 
voice call connection during the entire download. The other one was only download-
ing. After the first measurement we swapped the roles of the phones and performed 
the same measurement again. The results are averages of these two measurements.  
The power and transfer time columns show the measured values and their growth 
percentage when data transfer takes place in parallel with the voice call. The energy 
column shows the absolute energy of the each case.  
The “Additional” subcolumn of energy shows the extra energy needed to perform 
the operation in comparison to the energy that the phone would anyhow consume dur-
ing the same time. For the baseline values we use the phone idle power consumption 
(0.07W) for data transfer only and voice call power consumption (1.24W) for data 
transfers during voice calls. Finally the “Ratio” subcolumn shows the ratio of the  
additional energies.  
The energy column, and especially its “Additional” subcolumn, shows clearly that 
the additional energy needed to transfer data during a voice call is small in compari-
son to the additional energy needed to transfer the same data without the voice call. 
This means that it is possible to save close to 90% of the data communication energy 
if we can perform the communication during voice calls.  
This is a remarkable saving and it can be achieved with only a small increase in 
transfer time (between 3% and 14%). Naturally the biggest impact for the user is not 
the actual transfer time but the delay before the data transfer is started. The potential 
applications and the data transfer potential of the mechanism are discussed in greater 
detail in the following sections. 
4   Background of the Phenomenon 
The phenomenon that the measurements of the previous chapter capture can be  
explained by looking at the way the cellular radio in modern mobile phones is work-
ing. In terms of energy consumption the radio interface is the most power hungry 
component of a mobile phone accounting to around 50% of energy consumption in a 
connectivity use case [4]. The radio resources of a mobile phone are managed by a set 
of radio resource control algorithms that in addition to battery consumption influence 
signal quality, interference, mobility management and response time. (see e.g. [5] for 
details WCDMA radio resource management). While the details vary between differ-
ent technologies the essential mechanism is that there are at least two main states. Idle 

 
Parallel Data Transfer with Voice Calls for Energy-Efficient Mobile Services 
93 
state when power consumption is low and there is no traffic. Or active state, in which 
case the amount of transferred data has minor effect on the power consumption. 
When the user is having a voice call the radio of his mobile phone has to be used to 
transfer the voice stream both to and from the mobile phone. Transferring the voice 
stream requires frequent activity from the radio circuitry so that there is not a possibil-
ity to power it down into an idle state. However, the radio interface of a mobile phone 
is able to handle a much larger bandwidth than what is needed for the voice. Whether 
this bandwidth is used or not does not have a major effect on the energy consumption. 
Therefore for the most energy efficient activity it makes sense to use as much of the 
available bandwidth as possible if the radio in any case is active.  
5   Implementation 
To illustrate the implementation alternatives we will use Nokia Podcasting application 
(http://europe.nokia.com/A4577364) as an example. Podcasting client is a good exam-
ple of an application that can benefit from the mechanism because downloading pod-
cast episodes in most cases is not time critical. The idea is to automatically download 
the new podcast episodes to your phone and listen or watch them later when you have 
time. Currently, the podcast application for Nokia phones only supports periodic 
downloading (every 15/60 min, twice/once a day). This will automatically turn on the 
selected radio at a specific time and start downloading eventual new episodes. If  
these automated downloads could be synchronized with phone calls, it would make a 
difference in power consumption with minimal change in the user experience. 
On a general level the implementation will consist of the following steps: 
• The application will register to a call listener, so that it can activate every time a 
call will be set up and deactivate when the call ends.  
• In the podcasting case, when a phone call begins, the application would refresh the 
RSS feed and start/continue downloading the episodes when activated.  
• When the phone call is terminated, podcasting application would be notified and it 
would pause ongoing downloads allowing radio to enter low-power state.  
The same kind of functionality could be implemented to any application that does not 
require instant data transfer. For most applications this feature should be configurable 
in the options settings. For instance, busy executives may want to receive their emails 
immediately while private users may not mind if there is some delay before they re-
ceive their emails.  
5.1   Application Level Implementation 
There are at least two basic alternatives to implement the mechanism. It can be im-
plemented at the application level or at the middleware level. 
The straightforward approach is to implement the concept at the application level. 
Each application would create a listener to recognize when voice calls are started and 
finished. Managing the communication would then be completely application 
specific. This would be an easy extension to applications which already have a 
mechanism to manage the frequency of the communication. For instance, the Video 
center application has settings for feed subscriptions for video podcasts that allow 

94 
J.K. Nurminen and J. Nöyränen 
selection of download times like night, morning, day, evening. It would be possible to 
add the new mechanism simply as another selection and implement the necessary 
functionality in the code. 
Although the application level implementation is easy it has a number of 
limitations. First, each application would need to implement the same mechanisms. 
Different implementations of the same mechanism would increase the risk of mistakes 
and enlarge the code base. Providing the common mechanisms in some form of 
library would reduce this problem. Secondly, smarter interoperability between 
different applications would not be possible. For instance, there would be no way to 
manage the order of the different communication activities when a voice call starts. In 
some cases sequencing the communication activities may be a better alternative than 
having all of them run in parallel.  
It would also be impossible to handle application specific deadlines in a 
cooperative way. We assume that many applications would need to limit the time how 
long the communication can be delayed. For instance, email user may require that the 
emails are synchronized once in every hour also in the absence of voice calls. If such 
deadline events are triggered independently by each application there would be no 
possibility to synchronize them. Instead, only the voice call initiation would allow the 
applications to synchronize their communication activities. 
5.2   Middleware Level Implementation 
The second way to implement the mechanism would be at the middleware level. In 
this case the basic mechanisms would be handled by the middleware and the applica-
tions would only perform the data communication according to the needs of the  
individual applications. The key parts of the mechanism would be made available to 
developers via an API. Note that in addition to the middleware support we would still 
need modifications to the applications using this mechanism. Applications would 
need to specify their communication policies and handle the details of the data trans-
fer. These aspects are so application-specific that it is difficult to think how to do this 
without changes in the actual applications.  
Figure 3 illustrates the middleware level implementation. The new component is 
the Schedule manager which is responsible for detecting the call event initiations and 
terminations, and signaling these to the applications.  
When the Schedule manager is used the following sequence of steps takes place: 
1. Applications will register to Schedule manager with a deadline value (max. delay 
for the download to start) 
2. Incoming/outgoing call activates Schedule manager. Alternatively Schedule man-
ager is activated when a deadline is reached. 
3. Schedule manager gives a notification to applications to start data transfer 
4. Applications start data transfer 
5. When the voice call is terminated the Schedule manager gets a notification from 
the operating system.  
6. Schedule manager tells the applications to finish their data transfer. Applications 
can react to this in an application specific way. For instance, they could continue 
the data transfer to a feasible termination point. 
7.  Applications can register a new deadline to schedule manager 

 
Parallel Data Transfer with Voice Calls for Energy-Efficient Mobile Services 
95 
Middlew are
Middlew are
Operating system
Operating system
Schedule manager
Schedule manager
App. 1
App. 1
App. 2
App. 2
App. 3
App. 3
App. 4
App. 4
Internet
Internet
 
Fig. 3. Implementation of the concept as a schedule manager in the middleware level 
The above sequence of steps allows room for extensions and added intelligence. 
Step 3 can be implemented in multiple ways. In the simplest case all registered appli-
cations would get the signal at the same time. In more sophisticated solutions the 
Schedule manager could further schedule the individual applications. For instance, for 
non-urgent bandwidth hungry applications a round robin scheduling might be better 
than activating all of them at a same time. This would need further mechanisms for 
the application to signal the Schedule manager when their data transfer activity has 
been finished. 
Notice that even in the absence of voice calls the above mechanism would provide 
energy savings. The system would queue all delayed communication requests and once 
the deadline of the first request is reached the system could active also the other ones. 
The resulting coordinated transfer of data from different applications would reduce the 
need to power on and off the radio and thus decrease the energy consumption.  
6   Discussion 
6.1   Data Transfer Potential During Voice Calls 
The potential for data transfer during voice calls is reasonably high as illustrated by 
the sample calculation in Table 2. According to StrategyAnalytics [6] the average  
 

96 
J.K. Nurminen and J. Nöyränen 
Table 2. Calculation showing the potential for data transfer during voice calls 
Average call duration (min) 
26 
Average data transfer speed during call (kB/s) 
30 
"Low energy" data transfer potential (MB/day) 
46.8 
MP3 songs (#) [4MB/song] 
12 
video clip (min) [2.5 MB/min Reuters News] 
19 
email messages (#) [10kB/message] 
4792 
 
minutes of use (MOU) per subscriber per day is 26 min in US. With such talk times 
and assuming a relatively slow data transfer rate (30 kB/s) the daily potential for low-
energy data transfer is already close to 50 MB. This amount of data is significant and 
allows the transfer of a large number of textual email messages and a considerable 
amount of multimedia content. 
6.2   User Experience 
In order to take advantage of this phenomenon for energy saving we need to postpone 
the data transfer to a later time point. For some applications such delay may not be 
tolerable. Fortunately, there is a large group of applications where the delayed data 
transfer is not likely to cause any major harm for the user experience.  
Some of the candidate applications where such a feature is likely to be useful are:  
• Synchronization: emails, calendar events, address book updates 
• Downloading content to the phone: podcasts, video episodes, software upgrades, 
RSS feeds 
• Uploading content to server: backups, photos 
The essential concept does not depend on the kind of data that is being transferred or 
on the protocol used. The only essential aspect is that the user experience is not  
dependent on immediate action. 
A further effect to the user experience is that notifications, for example of incom-
ing mail, would arrive when the user is on the phone and displayed when the call 
ends. The potential benefit is less disruptions for the user, since the notifications from 
different services would come roughly at the same time and the user has already been 
interrupted by the voice call.  
6.3   Limitations 
Perhaps the biggest challenge for the proposed mechanism is to find a proper balance 
between user experience and energy efficiency. For some applications and some users 
the delay requirements are much stricter than for others. As discussed in the Imple-
mentation section the system would allow setting a maximum delay for each applica-
tion. Naturally, the user could specify the delay but it would be yet another setting 
which would complicate the adoption of new service. How to provide the necessary 
flexibility but at the same time allow good enough control possibility to the user is a 
difficult question. The same question applies to many other parameters of mobile  
applications as well. 

 
Parallel Data Transfer with Voice Calls for Energy-Efficient Mobile Services 
97 
Our measurements show that the solution works nicely with current mobile phones. 
However, old model GSM phones supporting GPRS class B do not allow simultane-
ous voice and data connections. Therefore, even if the mechanism could be applied as 
a software upgrade also to older devices, it will not work unless the device supports 
class A functionality. 
In a similar fashion it is unclear how the future communication technologies will 
benefit from the idea. Voice over IP packets would be competing of the same channel 
with the data transfer needs of the applications. Excessive use of data connections 
during VoIP call could influence the voice quality unless the packets are prioritized 
differently. 
7   Related Research 
The sensitivity of mobile devices to energy consumption has been widely recognized. 
Solutions to the energy consumption can be found on different levels. For instance, 
Keqiu et al. [7] is a rather recent survey of techniques for energy-efficient mobile 
computing analyzing the solution in different levels. They summarize research on 
methods and techniques at network interface, network protocols, operating systems, 
and application design layers. In addition to the energy-efficient communication the 
techniques for energy-efficient hardware and low-level software (see e.g. [8]) apply.  
A lot of research has investigated the energy-efficiency of wireless sensor net-
works. Akyildiz et al. [9] present a good overview. More detailed, and more recent, 
survey of scheduling mechanisms in sensor networks is available by Wang and Xiao 
[10]. Anastasi et al. [11] is another survey of energy-efficiency in wireless sensor net-
works. Because the replacement of batteries is often very expensive in wireless sensor 
network the ability to maximize the run time of a wireless sensor is extremely impor-
tant. One of the obvious solutions is to enter power saving mode where the activity of 
the wireless sensor is reduced for a period of time. In comparison to our research in 
sensor networks the traffic is often homogeneous. Often there is just a single applica-
tion and in case of multiple applications there is seldom a dominant application. In 
mobile phones this is different since for most users the essential use is to make and 
receive phone calls. 
A lot of the research on different communication layers has been layer specific and 
application independent. Obviously, generic application independent layered solutions 
are ideal in the respect that they do not limit the solution to a certain context. Anastasi 
et al. [12] is an example of the protocol level ideas to improve the energy-efficiency. 
They analyze the TCP protocol behavior for mobile web access. When fetching a web 
page consisting of multiple components they fetch components first to an intermediate 
access point so that device does not need to wait for the server processing. Thus de-
vice radio is on only during actual data transmission. 
Many researchers see cross-layer design as a source of new solutions (see [13] for 
an overview). For instance, Anastasi et al. [14] show how taking the application level 
information into account can result into energy savings between 20% and 96%. The 
essence of their idea is that the mobile device is able to detect and differentiate be-
tween bursts and user think times. Our concept is similar but we apply it at higher 
protocol layers with different granularity. Instead of detecting burst and active  

98 
J.K. Nurminen and J. Nöyränen 
communication intervals we detect voice calls and dynamically schedule activities for 
those time intervals.  
In comparison to related research our approach is clearly application layer driven. 
Instead of focusing on the needs of a single application the starting point of our idea is 
the typical mix of different applications and services a user typically has (or is likely 
to have in the future). Furthermore it takes advantage of the fact that the dominant use 
case of mobile phone is voice calls.  
The area of mobile services is so new that very few energy-efficient general 
mechanisms have been investigated. Most of the effort has been invested in novel in-
novative services. The energy-efficiency of the services often comes as an after-
thought. Moreover, the battery consumption of each service is often optimized only 
within the context of the particular service. The fact that multiple services are likely to 
be used on the same device is frequently ignored. 
There are a couple of studies which present ideas a bit analogous to ours but on dif-
ferent applications and domains. 
Xiao et al. [15] propose an idea where the processing and user interface modules of 
the device are powered down when there is no incoming traffic. Our work shares the 
aspect with theirs that powering down components saves energy. In their work they 
always keep the communication interface powered up. However, in a modern mobile 
phone the communication is module is a major energy consumer and having a policy 
to allow it to sleep is very influential for the energy consumption of the device. 
Conceptually a related system is in use at another abstraction layer in Linux operat-
ing system. The GLIB library used by GTK has a function, g_timemout_add_seconds, 
which will fire after a given number of seconds or when the first such timeout expires.  
GTK collects all timeouts to a single queue and all of them are executed at the same 
time when the earliest wake-up happens. This reduces the number of times the proc-
essor needs wake up and thus provides a drop in the power consumption [8].  
A related concept is also available for energy-efficient disk I/O where the idea is to 
minimize the number of times the disk is spun up. The laptop mode of Linux kernel 
queues all write requests and executes them when the disk is spun up to serve a read 
request or when a timer value is exceeded [16]. 
8   Conclusions 
The essential observation of our research is that there is a huge saving in battery con-
sumption if we delay non-urgent data transfers and perform them while a voice call is 
active. Our measurements show that file transfer during voice call requires slightly 
over 10% extra power over the voice call and that simultaneous voice call slows down 
the file transfer only by 3%-14%. As a result we can save over 80% of energy in data 
transfer if we can delay the communication to a time when user is speaking at the 
mobile phone. For a typical user speaking 26 minutes a day there would be capacity 
for 50MB of data transfer during the voice calls. 
It turns out that there is a large class of applications where the delayed data transfer 
would be applicable without major effect to the user experience. Examples of such 
application include synchronization (emails, calendar events, address book updates), 
downloading content to the phone (podcasts, video episodes, software upgrades, RSS 
feeds), and updating content to the server (backups, photos). 

 
Parallel Data Transfer with Voice Calls for Energy-Efficient Mobile Services 
99 
Since voice calls are the “necessary evil" for power consumption and require the 
radio to be active we should take advantage of these periods and transfer data at the 
same time. 
The mechanism can be implemented either in an application specific fashion or, 
preferably, at the middleware layer. In any case applications need to be modified to 
take advantage of the mechanism. 
With the increasing number and popularity of mobile services the idea has wide 
applicability. Enabling more energy-efficient use it can boost the adoption and use of 
mobile services and increase user satisfaction. 
This paper presents and quantifies the basic phenomenon as well as discusses 
implementation alternatives. Further research would be needed on multiple areas. 
First, how sensitive are the users to the delayed content transfer? It seems that for 
many applications the delay is not an issue but this would require further 
confirmation. Second, what would be the optimal way to implement the solution and 
what kind API to use ssto expose the mechanism to application developers?  Third, 
how to extend the idea to cover cases we have not investigated? Could the idea, for 
instance, work together with voice over IP? Finally, energy-efficient data transfer 
during voice calls could be a basic building block that might enable new ideas on 
mobile services and on their protocols. 
References 
1. Xiao, Y., Kalyanaraman, R.S., Ylä-Jääski, A.: Energy Consumption of Mobile YouTube: 
Quantitative Measurement and Analysis. In: Second International Conference and Exhibi-
tion on Next Generation Mobile Applications, Services and Technologies, Cardiff, Wales, 
UK (2008) 
2. Nurminen, J.K., Nöyränen, J.: Energy-Consumption in Mobile Peer-to-Peer – Quantitative 
Results from File Sharing. In: 5th IEEE Consumer Communications & Networking Con-
ference CCNC 2008, Las Vegas, Nevada (2008) 
3. Kelenyi, I., Nurminen, J.K.: Energy Aspects of Peer Cooperation - Measurements with a 
Mobile DHT System. In: IEEE CoCoNet Workshop 2008 Cognitive and Cooperative 
Wireless Networks collocated with IEEE ICC 2008, Beijing, China (2008) 
4. Neuvo, Y.: Cellular phones as embedded systems. In: IEEE International Solid-State Cir-
cuits Conference, Digest of Technical Papers, vol. 1, pp. 32–37 (2004) 
5. Holma, H., Toskala, A.: WCDMA for UMTS. John Wiley & Sons, Chichester (2000) 
6. Wireless Operator Performance Benchmarking Q2 2008, Strategy Analytics (2008)  
7. Keqiu, L., Nanya, T., Wenyu, Q.: Energy Efficient Methods and Techniques for Mobile 
Computing. In: Third International Conference on Semantics, Knowledge and Grid, pp. 
212–217 (2007) 
8. Garrett, M.: Powering down. Commun. ACM 51(9), 42–46 (2008) 
9. Akyildiz, I.F., Su, W., Sankarasubramaniam, Y., Cayirci, E.: Wireless sensor networks: a 
survey. Computer Networks 38(4), 393–422 (2002) 
10. Wang, L., Xiao, Y.: A survey of energy-efficient scheduling mechanisms in sensor net-
works. Mob. Netw. Appl. 11(5), 723–740 (2006) 
11. Anastasi, G., Conti, M., Di Francesco, M., Passarella, A.: Energy Conservation in Wireless 
Sensor Networks: a Survey. Ad Hoc Networks 7(3) (2009) 

100 
J.K. Nurminen and J. Nöyränen 
12. Anastasi, G., Conti, M., Gregori, E., Passarella, A.: Performance comparison of power-
saving strategies for mobile web access. Perform. Eval. 53(3-4), 273–294 (2003) 
13. Srivastava, V., Motani, M.: Cross-layer design: a survey and the road ahead. IEEE Com-
munications Magazine 43(12), 112–119 (2005) 
14. Anastasi, G., Conti, M., Gregori, E., Passarella, A.: 802.11 power-saving mode for mobile 
computing in Wi-Fi hotspots: limitations, enhancements and open issues. Wirel. 
Netw. 14(6), 745–768 (2008) 
15. Xiao, Y., Chen, C.L.P., Kinateder, K.K.J.: An optimal power saving scheme for mobile 
handsets. In: Sixth IEEE Symposium on Computers and Communications, pp. 192–197 
(2001) 
16. Samwel, B.: Kernel korner: extending battery life with laptop mode. Linux J. 2004(125), 
10 (2004) 
 
 

Policy-Based Device and Mobility Management
Pierre Imai, Bernd Lamparter, and Marco Liebsch
NEC Europe Ltd., Heidelberg, Germany
{imai,lamparter,liebsch}@neclab.eu
Abstract. Each new generation of mobile terminals oﬀers more and
better functionality, e.g. terminal mobility, multi-homing or inter-device
session mobility. Furthermore, the interaction with consumer devices,
e.g. DLNA TV or stereo sets, is becoming more common. Every new
feature, however, is likely to result in increased complexity for the end
user: Most people do not know how to utilize all features of their mo-
bile terminals, hence devices that oﬀer only a reduced feature set are
becoming more popular. Additionally, while the end user expects to be
in control, the network operator might want to exert some inﬂuence over
which features are available or trigger actions, e.g. handovers, based on
contract, location, etc. The aim of our research is to oﬀer high ﬂexibility
and functionality combined with ease of use. We designed a policy man-
agement framework for the mentioned session mobility functions which
supports the user in the conﬁguration of the functions and automates
commonly performed actions.
Keywords: Policy management, session mobility, home automation.
1
Introduction
Future terminals for mobile communications will oﬀer users a variety of services
through multiple radio access technologies. Mobile communication systems will
implement heterogeneous access networks, where mobile terminals can attach
through to operator services or services of the public Internet. Mobility man-
agement will support reachability of the user of a mobile terminal and control
low latency handover even between access networks using diﬀerent technologies.
Simultaneous use of multiple radio connections will be supported and allows rout-
ing of diﬀerent service ﬂows through diﬀerent access networks. One argument to
route a particular ﬂow through the access network of a particular technology is
for example the need for a certain Quality-of-Service (QoS), which is handled
well by CDMA-based access networks of 3rd Generation mobile communications
systems. In case delay or jitter is not of major interest, but the need for high
bandwidth access is the most important aspect for the use of a particular ser-
vice, associated ﬂows may be routed through the network of a WiMAX (IEEE
802.16) provider or Wireless LAN (IEEE802.11) access.
Many users own other communication devices besides their mobile phone.
PCs can be equipped with microphone and camera and then be used for video
calls. Many modern TVs or hi-ﬁdevices can also be connected to the Internet
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 101–114, 2009.
c
⃝Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

102
P. Imai, B. Lamparter, and M. Liebsch
and support features of the Digital Living Network Alliance (DLNA) [1]. This
allows the complete or partial handover of sessions between devices, e.g. from
the mobile phone to the PC or only the video to the TV. For session mobility
IETF documents are available [2] and it is currently speciﬁed in 3GPP [3].
Certainly, operators have speciﬁc policies regulating the route of traﬃc. Aim-
ing at best performance and most satisﬁed users, future terminals and mobile
communication systems will allow ﬂexible conﬁguration of such policies not only
to gold subscribers, but any user can specify its own policy proﬁle on the mo-
bile terminal. Decisions about the use of a particular radio technology, service
or support device, such as an external loudspeaker, will take the user’s policy
proﬁle as well as network policies into account.
Related work addresses policy management for various use cases, such as for
the selection of a particular access technology to handover a dual-radio enabled
mobile device. The IST WINNER project [4] investigates policy-based mobil-
ity management and proposes an architecture for policy management as well as
rules to support decisions about access to diﬀerent resources and networks. Fur-
thermore, the proposal considers policy rules to prioritize traﬃc and to enforce
associated QoS to that traﬃc. The proposed architecture considers distributed
functional components in the network, which closely collaborate with the radio
resource management. The IST Daidalos project did some early investigation on
local policy management, which is processed on the mobile device, while taking
local as well as user and network preferences and information, such as available
access networks, into account. [5] describes inter-working between an interface
abstraction layer to handle heterogeneous access technologies and a mobile ter-
minal controller, which enforces policy decisions being taken by an intelligent
interface selection function. Policy decisions take user preferences and network
conditions into account. These and other related work on policy management
focus on clearly deﬁned functional requirements, such as IP- and link-layer han-
dover as well as maintenance of a certain QoS. [6], [7], and [8] for example utilize
policy management solely to choose the best access for terminal handover. In [7],
policies help network operators to select an access network on the arrival of a
new call or handover request. [8] describes adaptive terminal middleware for
session mobility.
Current solutions are designed and tailor-made for a very speciﬁc function
and do not consider a common policy management for diﬀerent kind of mobility
management schemes. Session mobility, as speciﬁed for the Session Initiation
Protocol (SIP) [9], has not attracted a lot of interest so far in the design of
policy management concepts whereas both types of mobility management, IP
mobility and Session mobility, have potential and will co-exist in future mobile
communication systems. The policy management can also play a vital role for
access control to resources both within the terminal and outside. In this case,
policies behave similar to ﬁrewall rules, e.g. granting or denying access to speciﬁc
services based on time, application or device ID, etc.
As the complexity of mobility management using heterogeneous access net-
works increases and multiple schemes to maintain reachability of a user’s device

Policy-Based Device and Mobility Management
103
co-exist with mobility-enabled session management along with a variety of ap-
proaches to control traﬃc ﬂow routing, we endorse a powerful policy management
on the mobile terminal, which takes various information sources and policy rules
as input to handle all relevant tasks in a centralized component. These tasks in-
clude the selection of an appropriate mobility management scheme (IP Mobility
vs. SIP mobility). The proposed policy management solution is meant to ease
handling of complex rules and tasks as well as to personalize associated decisions
taken by the policy management. At the same time, the level of user interactions
to build a policy database on a mobile device must be adjustable to not stress
unexperienced users with expected input or manual conﬁguration.
In Section 2, we motivate and support the design of a common policy manage-
ment solution for mobile devices by means of use cases and Section 3 describes
some user-related aspects of policy management. Section 4 describes the pro-
posed architecture and Section 5 describes the policy management mechanisms
and language. Section 6 provides an overview about sample protocol operations
between the architecture components. Section 7 concludes this paper.
2
Exemplary Use Cases
Making use of a scenario-based design, this section brieﬂy describes three dif-
ferent use cases and the role of policy management on the mobile terminal. In
a high-level design, the policy manager component implements a central func-
tion that takes decisions based on policy rules, states and events. Various event
sources provide input to the policy manager, whereas decisions result in input to
and control of action components. Event sources comprise for example a trigger
from a user or an application, whereas action components comprise for example
functions for mobility and session management.
A ﬁrst use case targets support of inter-technology handover along with IP
mobility management. As a result of a user’s mobility pattern and location, the
link quality of its currently used cellular radio access gets worse, which is re-
ported from network interface control components to the policy manager. As a
ﬁrst step, the mobile terminal initiates discovery of alternative network tech-
nologies and associated access points as well as operator preferences regarding
technologies to be used. Based on the result of the discovery, the mobile terminal
performs scanning of these technologies and provides the results to the policy
manager, which selects a handover target while taking the scan results, operator
preferences and user policies as well as costs aspects into account. In a last step,
the decision of the policy manager results in a controlled activation of the target
technology and handover to the associated access network.
A further use case describes a policy decision to activate and use a second
radio network interface simultaneously to beneﬁt from the maximum radio band-
width of each network connection and is depicted in Fig. 1. In this use case, a
mobile terminal has multiple IP ﬂows active, which ﬁrst share the dedicated
bandwidth of a single radio connection. An application may report the need
for more bandwidth to the policy manager. Same as for the handover use case,

104
P. Imai, B. Lamparter, and M. Liebsch
the mobile terminal ﬁrst discovers available network technologies and associ-
ated link characteristics. Based on the available bandwidth and costs as well as
other policies, such as user preferences and operator policies, the policy manager
may take the decision to activate a second radio network interface, for example
based on the Wireless LAN (WLAN) technology, and attach it to the network.
By means of an evaluation of both radio connections’ characteristics, the policy
manager takes the decision to distribute the applications’ IP ﬂows to diﬀerent
radio connections. Being driven by the policy manager, one or multiple action
components may take the responsibility to coordinate ﬂow distribution locally
on the mobile terminal and in the network.
Flow 2
Mobile
Terminal
Cellular Access
WLAN Access
Service 1
Service 2
Flow 1
Move Flow 2
Anchor
Mobility
Local
Fig. 1. Multi-homing scenario
A third interesting use case deals with session mobility, automatic detection /
classiﬁcation of devices, and semi-automatic policy generation (see also ﬁgure 2).
The ﬁrst part of the scenario begins when the user installs a newly bought DLNA-
capable TV with attached camera in the home network to which the MT is also
connected. The MT detects the broadcast advertisement messages of this device,
and asks the user how to proceed. This process can involve the presentation of
a menu from which the user can select which actions to perform under what
circumstances (see 3). The speciﬁed actions are automatically validated, encoded
into policy deﬁnitions and added to the policy database. This concludes the ﬁrst
part of the scenario. The second part starts with the user in a video call. While
still on the phone, he comes home and switches on the TV set. The MT’s policy
management detects that the TV set has become available and automatically
performs the actions associated with this event, e.g. splits the video stream from
the session and moves it to the TV with associated camera.
3
User-Related Aspects
One of the most important goals of interface design is to improve the device’s
usability. Automatically performing common tasks, reducing the necessary user
input to a minimum, e.g. by pre-selecting the user’s last choice is one possibility,

Policy-Based Device and Mobility Management
105
OE
TV
MT
0. in call
1. select
3. initialize transfer
4. transfer video
2. negotiate
Fig. 2. This ﬁgure shows the interaction between the individual devices when the video
component of a call is to be transferred to the TV set
providing only the most commonly needed options another. However, current
design is often based on assumed common user preferences, not on the preferences
of the actual user. By providing a means for the user to set their own policies,
everyday use of the device becomes easier and more comfortable.
The average user will not be aware of the policy management concept. Instead
the rules are generated according to the user’s input on the GUI. Additionally
expert users can insert their own rules and edit existing ones. How the policy
management can inﬂuence the user interface is described in the next section.
Afterwards we will discuss possibilities for detecting the user intention.
Menu-Based Selection
Even though the user’s eﬀort to interact with the device is limited to the neces-
sary minimum, sometimes extended user interaction is necessary. For example,
Fig. 3: Menu
when a new device is found, the user might want
to associate policies such as when to use this de-
vice and what actions to perform then. On a mobile
phone, this interaction is normally performed via a
menu (see Figure 3 on the left), where only the cur-
rently appropriate actions are presented. Menu items
are normally sorted such that the most commonly
selected items are easiest to reach and uncommon
items are either not present at all or hidden in a
sub-menu. In a simple implementation, the menu can
remain static, with only the current selection being
remembered for each menu. However, if the user’s
choice is predictable, the menu may be altered appro-
priately (see next Section). Depending on the user’s
choices, policies can be automatically created in re-
sponse or entered directly by the user. In the latter
case, an automatic ‘sanity check’ of the rules it ad-
visable before adding them to the policy manager.

106
P. Imai, B. Lamparter, and M. Liebsch
Automatic Estimation of User Preferences
The better and more reliably the policy manager is able to predict the intention
of the user, the easier it is to use the device. In our implementation, the prediction
can be based on similar previous decisions made by the user, predeﬁned rules
generated from test user data or operator settings. A better but far more complex
approach is to equip the policy management with limited artiﬁcial intelligence.
This approach is considered for future work.
4
Architecture
The architecture of our approach is build around the policy management com-
ponent (see Figure 4). The policy management receives events from the event
components when there is happening something and it sends triggers to the ac-
tion components. Those components might be the real source of an event and
the real target of a trigger, but they could also receive information from other
sources, like in the case of DLNA, where the major components run on remote
devices and communicate through the DLNA component on the device.
Additionally components for the user interface, for communication with the
network, and for storing rules and other things are necessary.
Database
Location
Discovery
Session Management
Handover Ctrl
Power Ctrl
operator
policy
server
FW Ctrl
RFID
Policy Forwarding Ctrl
DLNA
Define
Policies
Power Ctrl
GUI
Define Policies
Store/
Fetch
Action−Box
Event−Box
Policy
Management
Events
Commands
Application
IPMC
IF Ctrl
IF Ctrl
Fig. 4. Component architecture
In the following paragraphs the components are described brieﬂy.
Policy Management: This is the central component which takes the decisions. A
detailed description is given in section 5.
GUI: The graphical user interface enables the user to select, deﬁne and adapt
policies in an easy, yet powerful way. More details can be found in section 3.

Policy-Based Device and Mobility Management
107
Network: The network operator can push policies to the terminal. A new or
changed policy can then trigger the change of the access network. This allows
an operator e.g. to achieve load balancing across his access networks. It might
be considered advisable that the user is able to check and/or override the
rules provided by the operator.
Database: The database stores policies, networks, devices, base stations, etc.
Event-Components: Sources of Events towards the Policy
Management
The components of this group send events to the policy management. Usually
the components communicate with other entities on the same device or in the
network, get information from there and then send an event. There are also
situations where the policy management tells a component to perform some
action, e.g. scanning the network, and then send back an event, e.g. the result
of the scan.
Discovery: Discovery of network interfaces, devices, capability as well as network
preferences. This component uses DLNA and other technologies to discover
devices in the environment. Furthermore, it uses ANDSF ([10], sect. 4.8.2.1)
and IEEE 802.21 Information Services to discover available network tech-
nologies, handover candidates as well as network preferences.
DLNA: This component provides an interface to home electronics devices which
support DLNA, like TV sets. E.g. the event “new DLNA device found” is
sent when a corresponding message from a device is received.
Application: Applications might send information about their internal state or
the demand for more networking bandwidth. Examples are the phone appli-
cation and the chat application.
IF Ctrl: Network interface (IF) control to provide indications to the policy man-
agement about decreasing network link quality and to report results of a scan
for infrastructure access points of a particular or a set of network technolo-
gies. This component may utilize the event services of the IEEE 802.21 Media
Independent Handover standard.
RFID: The RFID reader/writer is a local device. The corresponding component
is a daemon process which reads tags and sends this information as an event.
Location: This component sends location information events. The location can
be determined by GPS, WLAN, bluetooth, and RFID.
IPMC: Inter-Policy Management Communication, providing interaction between
policy managements located on diﬀerent device, e.g. PCs.
Power Ctrl: Reports current power state and consumption.
Action-Components: Destination for the Commands from the Policy
Management
The components of this group receive triggers from the policy management and
then fulﬁll a task. Usually this can be done without further control from the

108
P. Imai, B. Lamparter, and M. Liebsch
policy management. However, in some failure situations, it might be useful to
inform the policy management with an event so that e.g. a message can be
displayed.
Session Management: Controls the handover of sessions or parts of a session to
another device. The component gets commands like “split video from the
current video session and hand it over to the TV-set”.
Handover Ctrl: Enables Handover control and registration for Cellular and IP
Mobility Management, This component may have a direct interface to the
IF Control component to align IP Mobility with the use of an appropriate
network interface.
Policy Forwarding Ctrl: Controls
routing
tables,
forwarding
information
bases and policy routing engines to perform according to the speciﬁed routing
policies. Furthermore, this component may represent an abstract interface
with a component, which performs protocol operation with the network to
negotiate routing policies.
IF Ctrl: Network interface (IF) control to initiate controlled scanning for access
points in the network infrastructure, (de-)activation of a network interface
or handover to a selected access point. This component may utilize the com-
mand services of the IEEE 802.21 Media Independent Handover standard.
Power Ctrl: Set power states to balance performance vs. battery drain.
FW Ctrl: Change the rules of the integrated ﬁrewall.
5
Policy Management
The policy management component is the central component of our system.
It has interfaces to the Event components to receive events and to the Action
components to send triggers. Basically said, the policy management subsequently
takes an event from the input queue, checks which policies apply, and sends out
triggers.
In order to allow complex policies, we distinguish between policy and policy
rules. A rule is a simple statement consisting of a condition and a statement. A
policy can then consist of several concatenated rules.
5.1
Policies
With a policy the user or the operator deﬁnes what should happen when a
certain event arrives. Most policies are set by the user, but the operator might
also want to inﬂuence the behaviour of the terminal. E.g. the operator might
want to shift traﬃc to a network with less load. In the following we provide a
few example policies.
For terminal mobility policies can mandate the usage of WLAN or give it a
higher priority than UMTS. Also policies might encourage or forbid the change
between access technologies. These policies can be inﬂuenced by the location, e.g.
home or oﬃce. Policies for session mobility deﬁne the concrete usage of devices

Policy-Based Device and Mobility Management
109
found in the close environment. E.g. a known TV in the home should be used for
video when the user comes into the room. Policies like that are also inﬂuenced by
the circumstances, e.g. if the current call is conﬁdential or if the TV is already
used by somebody else. If a new device is found, the policy management checks
if there is a rule for this type of device. According to the rule the decision can
be to ignore the device or to interrupt the user and ask for a decision on what
to do with the device now and in the future.
The policies deﬁned by a network in the area of vertical handover are very
similar to the discussed user policies. Additionally the rules could also depend
on time/date or position (e.g. deﬁned by cell id). This allows the operator to
balance the traﬃc between access networks.
In contrast we don’t foresee policies deﬁned by the network which inﬂuence
the session handover to another terminal.
Policies that are directly related to low-level functionality can be considered
an immutable part of the operating system and are not subject to inﬂuence by
user or operator.
The deﬁnition of policies can be either left directly to an advanced user or,
for the average user, they can automatically be generated by the UI based on
templates for predeﬁned common events and actions. For example, the user
could be presented with a menu where he can associate actions, e.g. ‘connect
to internet’ or ‘use my big TV screen for all video calls’ with events such as
‘coming home’ (i.e. home WLAN SSID detected) or ‘incoming call’. Concrete
design issues of a UI that is suitable for both advanced and average users are
not discussed in this paper, but considered for future work.
5.2
Policy Management Layout and Mechanism
The policy management acts on events. When an event is reported by a compo-
nent, the policy management examines all its stored policies whose event ﬁeld
matches. All rules are processed in the order stored, and the actions of all rules
that evaluate as true are executed in sequence. After each rule the state is up-
dated appropriately. Once all matching rules have been executed, the policy
management enters the idle state until a new event is received.
Variables and state information are locally stored within the policy manage-
ment. The management can execute functions provided by other components
to retrieve information and to execute actions. This includes informing the user
via e.g the GUI and retrieving input. The policy management can additionally
access the database which provides persistent storage.
The policy rules themselves are also stored within the database. Rules can be
provided and modiﬁed by the GUI and the network operator, but pass through
the policy management for validation before being stored in the database.
5.3
Policy Deﬁnition Language and Examples
All policies processed by the policy management are written in a script-like
language as deﬁned by the following rules (EBNF):

110
P. Imai, B. Lamparter, and M. Liebsch
<rule>
::= "if (" <event> [<tests>] ") {" <actions> "}";
<tests>
::= "&&" <test> [<tests>];
<test>
::= <entity> "==" <entity> | <entity> "!=" <entity> |
<entity> ">"
<entity> | <entity> "<"
<entity> |
["!"] <entity>;
<entity>
::= <function> | <variable> | <constant>;
<actions> ::= <action> [ ";" [ <actions> ] ];
<action>
::= <function> | <variable> = <expression> | <rule>;
In the following we give a few examples for policies derived from the use cases.
# Rule for the multihoming use cases
if (event == appl ind && appl ind.req == optimize) { net ctx = link opt; disc.net pref()
}
# Rule for the case of device recognition
if (event == device found && type == unknown) { gui.ask user(device) }
# Rule for the case of reading a tag and decide to transfer a session
if (event == tag read && tag id == X1 && dlna.device available(Y1)) { sessionmgmt.
transfer(Y1) }
6
Protocols
The following ﬂows give an overview of the interactions between the components.
The central component is the policy management which adheres to the following
design principles: It works as an extended ﬁnite state machine which can handle
multiple states in parallel. During processing of a use case, the states can change
and variables can be set. The processing of one use case can be divided into
several chunks. Between the chunks the policy engine might work on other use
cases. When a new event comes in, the processing continues at the stored state.
We will detail each of the use cases presented in section 2 by a ﬂow in the
following sections.
6.1
Protocol Operation for Device Recognition and Session
Mobility
The protocol is split into two parts: In the ﬁrst the device is detected for the ﬁrst
time and the user is asked for a decision on which actions are to be performed
when the device is detected again in the future. In the second part the device
is detected again and the video is split from the session and handed over to the
TV.
1. After plugging the new TV into the LAN, the policy management receives
a DLNA message
2. The database is queried and
3. answers with device unknown
4. Thus the policy management decides to make the device available to the
user
5. The device’s capabilities are gathered from the device via DLNA

Policy-Based Device and Mobility Management
111
5. check dev caps
make available to user
6. query user preferences
9. set dev info
5. move video to device
4. dev info
3. unknown dev
2. query dev info
1. device detected
1. call established
3. query dev info
2. device detected
GUI
DLNA
Policy
Management
Database
7. query user preferences
8. user associates actions
7. video split operation completed
Application
Session
Management
6. split video off from call
4. private device: 
Fig. 5. Device recognition and session mobility
6. The policy management decides to ask the user which actions should be
associated with the device
7. and sends the corresponding message to the GUI
8. After retrieving the information, the GUI sends new policy rules
9. The device information is stored in the database, the rules are added to the
policy management
Later the user arrives back at the device while in a video call.
1. When the call is established, the phone application notiﬁes the policy man-
agement
2. Once the user is close enough to the device to detect it, a notiﬁcation is sent.
3. The database is queried for information about the device
4. and sends back the stored information
5. The policy management decides to move the video stream to the TV
6. and orders the session management to split the video from the session and
move it to the TV
7. The application notiﬁes the policy management about the completed split
of the video

112
P. Imai, B. Lamparter, and M. Liebsch
6.2
Protocol Operation for Multi-access Flow Distribution
The following protocol operation follows a use case for multi-homing, where
multiple radio network interfaces are attached to the network infrastructure to
perform ﬂow distribution. Starting point is that multiple network applications
are running on the mobile terminal using a single 3G connection. Due to a
request from an application to optimize available bandwidth, the policy manager
decides to attach a second network interface to the infrastructure and share the
bandwidth of both connections.
Policy
Management
IF Control
Application
Application
Application
Context: Optimization; Search for
second or alternative technology
1. Quality Feedback:
Discovery
5. Selective Scan
6. Scan Report
− Authorize Multi−Attachment
− Select second IF, consider QoS, costs, etc.
− Decision: Keep voice on 3G, move FTP
to WiMax of the same operator
Registration
Handover Control/
Policy Forwarding
10. Set Routing Policy
12: Set Requirements for
11. Result
9. Result
8. Attach to WiMax
7.
3. Request Info
4. Reply
2.
Optimize Links
Control
new technology WiMax
[threshold level, etc.]
Fig. 6. Simultaneous attachment and ﬂow distribution
1. The policy management receives an indication from at least one active ap-
plication to optimize bandwidth and link quality
2. The policy management processes the request to optimize links and decides
to search for alternative or additional access technologies.
3. The policy management requests the Discovery component for operator pref-
erences regarding technology use
4. The discovery component replies with valid preferences settings.
5. The policy management requests the Interface Control component to per-
form a scan according to the operator’s technology preferences
6. The interface control component reports the scan results to the policy
management

Policy-Based Device and Mobility Management
113
7. The policy management selects candidate technology types according to link
requirements after having authorized simultaneous use of multiple network
interfaces. Due to applications’ diﬀerent link requirements, the policy man-
agement decides to keep voice traﬃc on the currently running 3G interface
while the ftp download, which runs in the background, should be moved to
a WiMAX interface.
8. The policy management requests the Handover Control/Registration com-
ponent to attach to the selected WiMAX access network
9. The handover control/registration component reports the result of the at-
tachment to the policy management
10. The policy management requests the policy forwarding control component
to set the forwarding rules according to the policy management’s decision to
use the 3G interface for voice and the WiMAX interface for ftp traﬃc
11. The policy forwarding control component reports the results of the setting
request to the policy management
12. The policy management updates the interface control component with qual-
ity threshold levels for the WiMAX technology
13. The policy management is idle
7
Conclusion
This paper describes the use of policy based management for session mobility.
As session mobility includes terminal mobility between wireless base stations
with diﬀerent technology, multi-homing, and the handover of sessions or parts of
multimedia sessions to other devices, the document starts with the description
of use cases in this areas. From the use cases an architecture, a policy language,
and protocols are derived.
An important factor of such a scheme is the usability. Therefore the user
interface plays an important role. Finally a prototypical implementation shows
the feasibility of the scheme and potential problems.
We identiﬁed the interworking of user deﬁned policies and policies set by the
operator as a potential conﬂicting scenario.
Future Work
The next steps are an analysis of the mentioned conﬂict between user and net-
work policies. This is not only a technical conﬂict, but also a conﬂict of the
interests of the user and the operator. While the user would like to be free in
his decision what network and device he uses, the operator wants to control his
network e.g. balance the load between access networks.
Another conﬂict arises when there are multiple devices with an own Policy
Management. If the policies deﬁned on those devices might contradict each other,
the behaviour might be surprising of the user. E.g. it might occur that a session
is moved frequently between devices or a session ends unexpectedly. Even if the
devices negotiate policies with each other in order to avoid those cases, it might

114
P. Imai, B. Lamparter, and M. Liebsch
be hard to explain the user why an action deﬁned on a device does not work as
expected.
The current implementation just adds new rules to the end of the list. Al-
though this works ﬁne in our demo setup, it is clear that a smarter sorting is
needed which considers interdependencies between the rules. This problem is
similar to adding rules to a ﬁrewall.
Furthermore we consider adding limited machine learning capabilities to the
policy management. This might increase the adaptability of the device to the
user’s need and therefore make the device easier to use.
References
1. DLNA Digital Living Network Alliance, http://www.dlna.org/
2. Sparks, R.: The session initiation protocol (sip) refer method. RFC 3515 (2003)
3. 3GPP. IP Multimedia Subsystem (IMS) service continuity. TS 23.237, 3rd Gener-
ation Parnership Project (3GPP) (September 2008)
4. Mihovska, A., Jijun, L., Mino, E., Tragos, E., Mensing, C., Vivier, G., Fracchina,
R.: Policy-based mobility management for heterogeneous networks. Mobile and
Wireless Communications Summit 2007, 1–6 (July 2007)
5. Wetterwald, M., Filali, F., Bonnet, C., Nussbaum, D., Gauthier, L., Banchs, A.,
Bernados, C., Liebsch, M., Melia, T., Lafouge, C., Ribeiro, J.: A ﬂexible frame-
work for the support of heterogeneous wireless networks. IST Mobile and Wireless
Communications Summit (June 2006)
6. Murray, K., Mathur, R., Pesch, D.: Policy based mobility management in hetero-
geneous wireless networks for smart space environment. In: 3rd annual Conference
on Information Technology and Telecommunications IT&T, Letterkenny, Ireland
(October 2003)
7. Murray, K., Mathur, R., Pesch, D.: Intelligent access and mobility management
in heterogeneous wireless networks using policy. In: ISICT 2003: Proceedings of
the 1st international symposium on Information and communication technologies,
Dublin, Ireland, pp. 181–186. Trinity College Dublin (2003)
8. Ohta, K., Yoshikawa, T., Nakagawa, T., Isoda, Y., Kurakake, S.: Adaptive termi-
nal middleware for session mobility. In: International Conference on Distributed
Computing Systems Workshops, p. 394 (2003)
9. Rosenberg, J., Schulzrinne, H., Camarillo, G., Peterson, J., Sparks, R., Handley,
M., Schooler, E.: SIP: Session Initiation Protocol. RFC 3261 (2002)
10. 3GPP. Architecture enhancements for non-3GPP accesses. TS 23.402, 3rd Gener-
ation Parnership Project (3GPP) (September 2008)

C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 115–128, 2009. 
© Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009 
Policy-Based Middleware for QoS Management and 
Signaling in the Evolved Packet System 
Richard Good1, Fabricio Gouveia2, Thomas Magedanz2, and Neco Ventura1 
1 University of Cape Town, Rondebosch, South Africa  
{rgood, neco}@crg.ee.uct.ac.za 
2 Fraunhofer Institute FOKUS, Kaiserin-Augusta-Alle 31, 10589, Berlin, Germany 
{fabricio.gouveia,thomas.magedanz}@fokus.fraunhofer.de 
Abstract. The 3GPP are currently finalizing their Evolved Packet System 
(EPS) with the Evolved Packet Core (EPC) central to this framework. The EPC 
is a simplified, flat, all IP-based architecture that supports mobility between 
heterogeneous access networks and incorporates an evolved QoS concept based 
on the 3GPP Policy Control and Charging (PCC) framework. The IP 
Multimedia Subsystem (IMS) is an IP service element within the EPS, 
introduced for the rapid provisioning of innovative multimedia services. The 
evolved PCC framework extends the scope of operation and defines new 
interactions – in particular the S9 reference point is introduced to facilitate 
inter-domain PCC communication. This paper proposes an enhancement to the 
IMS/PCC framework that uses SIP routing information to discover signaling 
and media paths. This mechanism uses standardized IMS/PCC operations and 
allows applications to effectively issue resource requests from their home 
domain enabling QoS-connectivity across multiple domains. Because the 
mechanism operates at the service control layer it does not require any 
significant transport layer modifications or the sharing of potentially sensitive 
internal topology information. The evolved PCC architecture and inter-domain 
route discovery mechanisms were implemented in an evaluation testbed and 
performed favorably without adversely effecting end user experience. 
Keywords: PCC, IMS, End-to-end, Inter-domain, Testbed. 
1   Introduction 
As part of the evolution of mobile communications 3GPP has defined a new air 
interface, known as Long Term Evolution – Radio Access Network (LTE-RAN), 
which forms part of the LTE work item. This evolved architecture provides higher 
data rates, increased spectral efficiency and lower infrastructure costs by simplifying 
the framework. Additionally a flat, all-IP based architecture has been defined, the 
Evolved Packet Core (EPC), which falls under the Service Architecture Evolution 
(SAE) work item. The architecture in its entirety is referred to as the Evolved Packet 
System (EPS). 
The EPC is a framework that supports seamless mobility between heterogeneous 
access networks, and incorporates an evolved Quality of Service (QoS) concept that is 
aligned with the 3GPP Policy Control and Charging (PCC) framework. The evolved 

116 
R. Good et al. 
PCC architecture maximizes operator control over QoS functions distributed across 
different network nodes. 
The 3GPP IP Multimedia Subsystem (IMS) forms part of the EPS as an IP service 
element and is the global standard for supporting multimedia services in IP networks. 
It is essentially a service enabler that integrates services horizontally as apposed to the 
traditional stovepipe architecture, ensuring the rapid creation of innovative 
applications [1].   
During the lengthy IMS standardization process the phenomenon known as Web 2.0 
has advanced. Web 2.0 refers to the new generation of Internet technologies 
characterized by the harnessing of collective intelligence. This has resulted in 
exceedingly innovative services, the majority of which are available free of charge with 
revenues based on the potential for personalized advertizing. This new communications 
model poses a threat to IMS service deployment – if operators are to charge for services 
that are available freely on the Internet, they will need to justify this by service 
differentiation. Increased reliability through efficient management of resources will be 
critical to this differentiation. 
While IMS standardization is largely complete, the architecture responsible for 
managing resources, the PCC framework, still faces several deployment challenges. 
Weak specification of interfaces and elements has led to interoperability problems and 
vendor specific implementations [2]. This is evident in the fact that most preliminary 
IMS deployments do not support policy controlled resource management, or do so in 
a very limited and scaled down manner for multiple wireless accesses. 
This latest evolution of the PCC architecture extends the scope of operation and 
introduces new interfaces. In particular an inter-domain interface, the S9 interface, is 
introduced to facilitate communication between PCC frameworks in neighboring IMS 
domains to achieve full end-to-end policy provisioning [3]. However the issues of 
inter-domain route discovery and QoS enforcement across all traversed transport 
segments of an IMS session still remain open areas, particularly in practical 
environments.    
This paper analyses the current state of the art on linking session based IMS services 
with transport layer resources, with particular emphasis on the evolved 3GPP PCC 
architecture. We propose an enhancement to the IMS/PCC framework to discover end-
to-end signaling and media routes. This mechanism uses SIP inherent routing 
information to discover origin, transit and destination IMS domains traversed by the 
media, and allows an application to effectively issue resource requests from its home 
domain enabling QoS-connectivity across all traversed transport segments. While this 
enhancement is limited to IMS services, the fact that it operates at the service control 
layer and uses SIP routing information to determine the media path means that the end-
to-end mediation of resources can occur in a network agnostic fashion without any 
significant modification to the legacy transport layer. Additionally the sharing of 
potentially sensitive topology information is not required, removing the need for 
complex information updating procedures. 
2   Evolution of 3GPP Policy Control Framework 
When IMS was first introduced as an overlay architecture for 3GPP UMTS it was 
immediately apparent that QoS provisioning would play an important role in enabling 

 
Policy-Based Middleware for QoS Management and Signaling 
117 
IP multimedia services.  Policy Based Network Management (PBMN) was adopted to 
ease the management of the network resources through automated and distributed 
structures using centralized policies.  
2.1   R5/R6 Service Based Local Policy Architecture 
3GPP R5 introduced the Service Based Local Policy Architecture; R6 further 
developed this framework by separating logical elements and defining new interfaces.  
A Policy Decision Function (PDF) and Policy Enforcement Point (PEP) were defined, 
as well as very basic mechanisms that allowed the service control layer IMS elements 
to request resources in the transport layer. This initial attempt did not address inter-
domain resource reservation and only supported Push mode operation or Service 
initiated QoS reservation. 
2.2   R7 PCC Architecture 
3GPP R7 combined the Flow Based Charging and Service Based Local Policy 
Architectures to form the Policy Control and Charging (PCC) Architecture.  The main 
elements in this architecture were the Policy and Charging Rule Function (PCRF) and 
the Policy and Charging Enforcement Function (PCRF). This architecture extended 
the interface between the PCRF and the signaling layer (Rx interface) [4], and the 
PCRF and PCEF (Gx interface) [5], both based on the Diameter protocol. Both Push 
and Pull mode operation were supported, but there was still no mechanism for inter-
domain resource reservation and the architecture was tailored specifically for UMTS 
access, though preliminary attempts were made to incorporate PacketCable and 
WLAN access [6]. 
2.3   R8 Evolved PCC Architecture 
The evolved PCC architecture specified in Release 8, maximizes operator control 
over QoS functions distributed across different network nodes; the critical 
components: the Application Function (AF), PCRF and PCEF are extended [7]. 
In this evolved architecture the IMS is seen as one of several IP service elements, 
hence the AF is no longer limited to IMS specific elements. The PCRF provides 
connectivity between the EPC and the IP service elements. This element performs the 
same role as before but has its functionality split into home domain and visited 
domain functions. The definition of home and visited PCRFs allows the EPC to offer 
breakthrough for data in the home and visited domains. This new system introduces 
service level QoS parameters that are conveyed in the PCC rules; in particular these 
parameters include a QoS Class Identifier (QCI), an Allocation and Retention Priority 
(ARP) and authorized Guaranteed and Maximum Bit Rate values for uplink and 
downlink [7]. The QCI is a scalar that represents the QoS characteristics that the EPC 
is expected to provide for each service data flow. This value is used by transport layer 
devices to access and configure device specific parameters that control packet 
forwarding treatment. 
The interaction between the PCRF and the transport layer has been extended; the 
PCRF interacts and enforces PCC rules across a greater number of access 
technologies and QoS models. The PCEF, as the element residing in the transport 

118 
R. Good et al. 
layer, is separated into the Serving Gateway, the Packet Data Network (PDN) 
Gateway and the evolved Packet Data Gateway (ePDG). The Serving Gateway is a 
router that resides in the local network to which the end-user is attached, it performs 
connectivity provisioning including access control and resource provisioning. The 
PDN Gateway has similar functionality but is located in the home network of the end-
user. The ePDG facilitates untrusted network access by authenticating end-users and 
monitoring traffic. PCC rules are received by these logical elements and are used to 
configure the transport layer devices accordingly. 
With the PCRF split into home and visited functionality as of Release 8, the S9 
interface has been introduced to facilitate inter-domain communication between 
PCRFs in neighboring domains [3]. This reference point is Diameter based and is in 
the early stages of development. It facilitates basic roaming scenarios and allows a 
PCRF to request resources in a neighboring domain. Fig. 1 shows the evolved PCC 
architecture and how it interacts with the EPC. 
 
Fig. 1. The 3GPP System Architecture Evolution extends the scope and interactions of the PCC 
framework  
Essentially two end-to-end QoS control scenarios exist. In the first scenario QoS 
requirements for a given service can be passed over the end-to-end path through the 
application signaling via the inter-domain reference point. In the second scenario QoS 
requirements are passed over the end-to-end path through path-coupled QoS 
signaling, using for example the Next Step In Signaling Layer Protocol (NSLP) or 
link-layer QoS signaling capabilities. NSLP signaling requires modification to all 
routing devices in the transport layer, and while this approach may be important for 
end-to-end service delivery in the future Internet, practical implementation challenges 
 

 
Policy-Based Middleware for QoS Management and Signaling 
119 
limit the applicability in the short to medium term. In particular network operators 
heavily invested in legacy networks will be hesitant to commit the necessary capital 
expenditure for such an overhaul, and link layer QoS signaling, like PDP context 
activation in UMTS, goes against the principle of separating core procedures from the 
subtleties of the access network [8]. However the first approach, using currently 
3GPP standardized elements and interfaces, does not facilitate end-to-end resource 
reservation across multiple domains, nor does it link the service control inter-domain 
routes with the routes followed by the media in the transport layer. 
3   Requirements for End-to-End Evolved 3GPP PCC 
The general functional requirements of the PCC architecture include admission 
control, resource reservation and policy enforcement. To ensure end-to-end policy 
provisioning, the PCC architecture should guarantee resources and perform policy 
control along all traversed transport segments. 
Secondary requirements have been identified that must be fulfilled by this evolved 
PCC architecture [9]. 
Minimal affect on Session Setup Delay – This is an important metric for validation 
as it gives an indication of the effect on end-user experience. 
Backwards Compatibility – The Evolved Packet Core should be compatible with R7 
and earlier implementations of the PCC architecture to ensure rapid adoption. 
Convergence Towards Agnostic Access – The Gx interface provides this network 
agnostic interaction, but it remains to be seen how this will be implemented. 
In no way hinder the Innovative creation of new services – The main purpose of 
the IMS is provide an environment for rapid service deployment, it should be possible 
to deploy new services without standardization of QoS support. 
3.1   Inter-domain Solutions 
To establish end-to-end connectivity, the routes traversed, and hence the domains 
where resources must be authorized, need to be determined. Having full knowledge of 
the intra-domain topology is an efficient but practically infeasible approach. A first 
level of inter-domain routing, where domains are considered as black box nodes and 
only inter-domain routes are taken into account, is necessary [10]. 
Topology discovery mechanisms that can be used to map out neighboring QoS 
elements have been defined [11], but no methods for discovering which domains need 
resource reservation were proposed. 3GPP propose a Diameter Routing Agent (DRA) 
to ensure that all Diameter sessions for a certain authorization request reach the same 
PCRF [12], but this is an intra-domain mechanism. 
The AQUILA project proposes an inter-domain resource reservation mechanism that 
extends the Border Gateway Reservation Protocol (BGRP) [13]. While the proposal 
exhibits scalability and can be implemented using standard router equipment, inter-
domain routing performed at this level requires significant modification to the legacy 
transport layer and requires the sharing of potentially sensitive topology information 

120 
R. Good et al. 
with neighboring domains. Additionally the framework is not specific to the IMS/PCC 
framework and replicates many of the standardized mechanisms. 
The End-to-End Quality of Service Support over Heterogeneous networks 
(EuQoS) is a European research project aimed at building an entire QoS framework, 
addressing all network layers, protocols and technologies [14]. They propose an inter-
domain QoS routing protocol that extends the Border Gateway Protocol (BGP) – EQ-
BGP. EQ-BGP takes into account intra- and inter-domain QoS information to create a 
roadmap of available QoS paths between source and destination networks; these end-
to-end QoS paths are advertised to neighboring domains using EQ-BGP. However 
like AQUILA this approach passes QoS information in path-coupled signaling and 
requires significant transport layer modifications. 
Mechanisms that allow the discovery of end-to-end routes and hence perform inter-
domain resource reservation are required. These mechanisms should utilize standardized 
IMS/PCC mechanisms, and not require transport layer modification by operating at the 
service control layer.  
4   Inter-domain Route Discovery 
We propose an extension to the IMS/PCC architecture that extracts SIP routing 
information during session establishment and uses this to determine the domains 
traversed by the signaling and hence the media. This proposal is specific to the IMS 
architecture and makes use of standardized mechanisms and interfaces provided by 
the PCC framework. Using this mechanism, resources need only be requested in the 
home domain of the originating end-user as authorization requests sent to the PCRF 
contain information on all necessary administrative domains and inter-domain 
requests are sent to the relevant PCC frameworks. Inter-domain routing is performed 
at the PCRF using signaling information, this means that no significant transport layer 
modifications are necessary nor is the sharing of potentially sensitive internal 
topology information. 
4.1   Necessary Assumptions 
Several assumptions are necessary for the validity of the proposed enhancements. 
All Services must be SIP based – The IMS is the global standard for IP multimedia 
service delivery; hence the most resource hungry applications will most likely be IMS 
services which are SIP based. 
Media and signaling must originate in the same domain, and media must follow 
a path between origin and destination domains – The media and signaling paths 
are still decoupled and follow entirely different paths, we do not envisage any IMS 
scenario that violates this assumption. 
PCRFs must know the address of PCRFs in neighboring domains – The addresses 
of neighboring PCRFs can be manually configured, exchanged through roaming 
agreements, or discovered automatically using topology discovery mechanisms [6].  

 
Policy-Based Middleware for QoS Management and Signaling 
121 
Route information in SIP signaling must be visible to traversed proxies – Route 
information in SIP signaling can be encrypted for security or privacy purposes, e.g. if 
a Topology Hiding Interworking Gateway is in operation, however the address of the 
gateway element is always present which is sufficient to determine the traversed 
domains. 
4.2   Signaling Path Discovery 
The SIP protocol defines a transaction as a request, any number of provisional 
responses and a final response, while a dialog is a SIP relationship that exists for 
some time [15]. All responses must traverse the same proxies as their relevant 
requests. This route is discovered using the Via header – as a request traverses each 
proxy along its path, the address of the proxy is added to the Via header. The 
subsequent response traverses all proxies listed in the Via header and strips each 
address as the proxy is traversed. 
Within the same dialog subsequent requests need not necessarily follow the same 
path – however if a proxy wants to ensure that it is included on the path for all 
requests in a dialog it can add its address to the Record-Route header of the initial 
request. An IMS Call Session Control Function (CSCF) is a prime example of this 
kind of proxy, as it would want to be traversed by all requests in a dialog to enforce 
charging, resource authorization and service invocation. When subsequent requests 
are created the proxies listed in the Record-Route header of the initial request are 
added to the Route header in the order in which they must be traversed. The Route 
header essentially defines the route a request will take, and each proxy address is 
stripped from the Route header as it is traversed. This means that for any request apart 
from the initial request, any proxy along the path can map out the entire signaling 
route from originating user to terminating user by examining the Route and Via 
headers. 
The calculation of the signaling path occurs at the element in the home domain of 
the originating end-user requesting resource authorization from the PCC framework; 
this element could be an Application Server or a Proxy – CSCF (P-CSCF). When an 
authorization request is created the relevant SIP request is examined and the path 
from origin to destination domain is mapped out using the Via and Route headers.  
Though these headers contain proxy addresses it is possible to determine the domains 
by taking only the network part of the URI. The addresses are examined and the 
origin, transit and destination domains are discovered (Duplicate domains are 
excluded.) This information is encapsulated into the Diameter Authorization Request 
- we define three new AVPs for the Rx Diameter Application: Origin-Domain, 
Transit-Domain and Destination-Domain. 
4.3   Bearer Path Discovery 
Once an Authorization Request is received by the PCRF the media path must be 
determined. While signaling must traverse IMS proxies as described, the media is 
decoupled and will usually traverse an optimized route between origin and destination 
domains. There are three cases to cater for: 

122 
R. Good et al. 
Origin and destination domains are the same – This is the simplest case, all transit 
domains are ignored and resource authorization and reservation is performed only in 
this domain. 
Origin and destination domains are different and there are no transit domains – 
In this scenario resources need to be authorized and reserved in both origin and 
destination domains, this is done simultaneously. 
Origin and destination domains are different and there are transit domains – In 
this case it needs to be determined whether the transit domains are traversed by the 
media or if they can be discarded as unnecessary transit domains along the signaling 
path. If a PCRF in the home domain of the originating end-user detects this case when 
performing inter-domain authorization, the authorization request is forwarded as is to 
the PCRF in the origin domain – the address of this PCRF would be known as it 
would be exchanged in the roaming agreement that allows the end-user to attach to 
this network. 
We utilize the assumption that all PCRFs know the address of neighboring PCRFs.  
The PCRF in the origin domain examines the route information in reverse order and 
when a neighboring domain, whose PCRF address is known, is found all subsequent 
transit domains are discarded – this new authorization request is forwarded to the 
neighboring PCRF where the same process is repeated. This operation repeats until 
the destination domain is reached; in this way the domains traversed by the media are 
discovered and unnecessary transit domains discarded. 
 
Fig. 2. With the evolved end to end 3GPP PCC framework resources are authorized and 
reserved only in the domains traversed by the media 

 
Policy-Based Middleware for QoS Management and Signaling 
123 
The mechanism is demonstrated in Fig. 2. There are 2 end-users, User Equipment 
(UE) 1 that connects via visited network 1 and is registered with home network 1, and  
User Equipment (UE) 2 that connects via visited network 2 and is registered with 
home network 2. UE 1 initiates a session with UE 2 by issuing a SIP Session Request 
(1), this request traverses visited network 1, home network 1, home network 2 and 
visited network 2 and is eventually delivery to UE 2 (2-5). UE 2 returns a SIP Session 
Response with preferred session parameters (6-8). An element in home network 1 
(e.g. Application Server, P-CSCF) extracts the service information from both SIP 
request and response as well as routing information and encapsulates it in a Diameter 
Authorization Request and sends it to the PCRF in home network 1 (9). Table 1 
shows the calculation of the signaling path. The PCRF extracts the information, and 
upon discovering that both origin and destination domains are different and there are 
transit domains, forwards the Authorization Request as is to the PCRF in visited 
network 1 as it is the origin domain (10). The PCRF in visited network 1 examines the 
route information in reverse and immediately finds that the destination domain, 
visited network 2, is a neighboring domain. All transit domains are discarded and the 
new Authorization Request is sent to PCRF in visited network 2 (11). The PCRF in 
visited network 2 performs policy, subscription and resource checks, enforces the 
policy decisions in the transport layer and sends a positive Authorization Response to 
the PCRF in visited network 1 (12). Similar policy, subscription and resource checks 
are performed here and the policy decisions are enforced in the transport layer of this 
domain. A positive Authorization Response is conveyed to the PCRF in home 
network 1 (13), which sends a positive Authorization Response to the control layer 
element (14). The SIP Session Response is conveyed back to UE 1 (15-16). In this 
way resources are reserved along all traversed transport segments enabling end-to-end 
QoS connectivity. Table 1 shows the subsequent calculated media paths. 
Table 1. Route Discovery from SIP Update Request 
 
 

124 
R. Good et al. 
In the third case, where both origin and destination domains are different and 
transit domains are present, resource reservation is performed in each domain 
consecutively, which increases session setup delay. However this is the worst and 
most unlikely case and for all other scenarios resource reservation is performed 
simultaneously in each domain. 
5   Implementation Experience 
As mentioned previously the core IMS specifications are largely finalized, though the 
PCC architecture still needs to mature and have various challenges addressed before 
deployment can be realized. The massive success and proliferation of Internet 
technology has shown that a large number of application developers working on an 
open infrastructure is needed for the development of successful market driven 
services. Open IMS testbed initiatives likes the Fokus Open Source IMS Core [16], 
and the UCT IMS Client [17] have helped expose this complex technology to an open 
set of developers, bringing academia and industry together. 
The Evolved PCC architecture and proposed extensions were implemented in a 
proof of concept testbed. One of the goals of this implementation was to verify and 
evaluate the proposed inter-domain route discovery mechanisms and to demonstrate 
the proposal in a real world scenario. To ensure reproducibility, encourage innovation 
and provide a convenient point of departure for future research in the field, the testbed 
used exclusively Free and Open Source software. 
A standards based IMS reference framework, the Fokus Open Source IMS Core, 
was used to implement the core IMS including CSCFs and Home Subscriber Server 
(HSS) [16]. These elements comprised the service control layer and provided a reliable 
IMS testing environment. The P-CSCF was extended to extract service and routing 
information, determine the full signaling path and interact with a PCRF via the Rx+ 
Diameter interface. The standardized Diameter application for this interface 
incorporated additional AVPs: OriginDomain, TransitDomain and DestinationDomain 
as per the inter-domain route discovery mechanism. 
 
Fig. 3. The testbed architecture is comprised exclusively of Free and Open Source software to 
expose the technologies to an open set of developers 

 
Policy-Based Middleware for QoS Management and Signaling 
125 
To provide PCC functionality the UCT Policy Control Framework was developed 
and released as Free and Open Source [18]. This standards based package contains 
software implementations of the PCRF and PCEF. The PCRF defines interfaces to the 
control layer and transport layer; upon receipt of Diameter Authorization requests 
from the control layer this element performs policy, resource and subscription checks 
and enforces the policy decisions on the PCEF in the transport layer. The inter-
domain route discovery mechanisms were incorporated into the PCRF logical 
architecture. The PCRF was extended to perform inter-domain resource reservation 
and interact with neighboring PCRFs via the Diameter S9 interface. 
To represent end-user equipment, the UCT IMS Client was used [17]. This 
standards based client emulation tool implements full IMS signaling, several rich 
services and a mechanism with which to test other IMS network components. Fig. 3 
shows the testbed architecture including two domains for proof of concept 
evaluations. 
5.1   Metrics of Interest 
A key requirement for the evolved 3GPP QoS concept is a negligible effect on session 
setup delay [9]. An equally important metric is the effect on signaling overhead; the 
PCC framework introduces a number of additional messages during session 
establishment, this increase in signaling overhead could overwhelm network elements 
and decrease network utility. Transport layer QoS metrics including jitter and packet 
loss are considered unnecessary in this study, the concentration is not on IP QoS 
models where such metrics might be pertinent.   
The testbed was capable of working with the end-to-end PCC architecture enabled 
or disabled – this provided a benchmark for evaluations. With the PCC architecture 
disabled no resource authorization took place and all media was treated as Best Effort. 
5.2   Session Setup Delay 
To analyze the affects on session setup delay, the delay when establishing sessions 
across domains was measured. Referring to Fig. 3 UE 1 and UE 2 were registered 
with open-home.net and connected via open-visited.net. When a session was setup the 
signaling followed the path: open-visited.net, open-home.net, open-visited.net. The 
inter-domain route discovery mechanism returned open-visited.net as the only domain 
that required resource authorization. An inter-domain request was sent from the PCRF 
in open-home.net to the PCRF in open-visited.net where policy, resource and 
subscription checks took place, and policy decisions were enforced on the PCEF in 
the transport layer. 
The time to setup a session across domains was measured both with and without 
the end-to-end PCC architecture enabled. Each session request represented a typical 
IMS session with audio and video component. Table 2 shows the results of this 
experiment; while the increase is not insignificant, the fact that end-to-end QoS is 
guaranteed is an important trade off. Similar tests were carried out to evaluate the 
increase in signaling overhead and results showed an acceptable effect on this metric. 

126 
R. Good et al. 
Table 2. IMS call setup delay results when establishing a session across domains 
 
5.3   Inter-domain Resource Reservation with Application Invocation 
To provide a real world use case scenario a Video on Demand (VoD) Application 
Server (AS) was deployed in the home domain, open-home.net.  Referring to Fig. 3 
UE 1 was registered with open-home.net and connected via open-visited.net. UE 1 
initiated a session with the VoD AS in open-home.net.  
  
 
Fig. 4. The throughput graph shown here gives a clear indication of the various steps involved 
in the inter-domain route discovery procedure 
Fig. 4 shows the throughput measured at the machine hosting the home domain 
elements and the VoD AS. This gives an indication of the various stages involved in the 
process. When UE 1 sent a VoD session request the IMS core forwarded the request to 
the VoD AS based on pre-set initial Filter Criteria (1). The VoD AS extracted service 
and route information and calculated the signaling path. An authorization request was 
sent to the PCRF in open-home.net (2), the inter-domain route discovery mechanism 
determined that open-visited.net and open-home.net required resource reservation to be 
performed. An authorization request was sent to the PCRF in open-visited.net, where 
policy, resource and subscription checks were carried out, and policy decisions were 
enforced in the transport layer (3). Upon receipt of the authorization response the PCRF 
in open-home.net enforced policy decisions in the transport layer (4), and eventually the 
video was streamed across an end-to-end QoS-enabled transport layer (5). These results 
are consistent with those reported in [11]. 

 
Policy-Based Middleware for QoS Management and Signaling 
127 
6   Conclusions 
Resource management will be a critical factor in differentiating IMS services from 
typical web services. The latest evolution of the 3GPP PCC framework extends the 
scope of operation and introduces new interfaces; however there are still challenges 
that need to be addressed before deployment can be realized.  
This paper has proposed an extension to the evolved PCC and IMS architectures 
that operates at the service control layer and uses SIP routing information to 
determine the paths traversed by signaling and media. This mechanism allows 
applications to effectively issue resource requests from their home domain and enable 
end-to-end QoS-connectivity. Unlike other inter-domain proposals this mechanism 
requires no significant transport layer modifications or the sharing of potentially 
sensitive internal topology information.   
The evolved PCC architecture including inter-domain route discovery enhancements 
was implemented in a proof of concept testbed. To expose this technology to an open 
set of developers and encourage innovation in the field, Free and Open Source software 
was used throughout the implementation. Examining important metrics: session setup 
delay and incurred signaling overhead, the architecture performed favorably without 
decreasing end-user experience. Future work includes extending the framework to 
demonstrate QoS negotiation for advanced multimedia services.  
References 
1. Camarillo, G., Kaupinnen, T., Kuparinen, M., Ivars, I.: Towards an Innovation Oriented IP 
Multimedia Subsystem. IEEE Communications Magazine, 130–135 (March 2007) 
2. Callejo-Rodriguez, M., Enriquez-Gabeiras, J.: Bridging the Standardization Gap to 
Provide QoS in Current NGN Architectures. IEEE Communications Magazine, 132–137 
(October 2008) 
3. 3GPP TS 29.215, Policy and Charging Control over S9 reference point (October 2008) 
4. 3GPP TS 29.214, Policy and Charging Control over Rx reference point (September 2008) 
5. 3GPP TS 29.212, Policy and Charging Control over Gx reference point (September 2008) 
6. 3GPP TS 23.234, 3GPP System to WLAN Interworking (June 2008) 
7. 3GPP TS 23.401, GPRS Enhancements for evolved UTRAN (September 2008) 
8. Good, R., Gouveia, F., Chen, S., Ventura, N., Magedanz, T.: Critical Issues for QoS 
Management and Provisioning in the IP Multimedia Subsystem. Journal of Network and 
Systems Management (JNSM) 16(2), 129–144 (2008) 
9. Ludwig, R., Ekstrom, H., Willars, P., Lundin, N.: An Evolved 3GPP QoS Concept. In: 
Vehicular Technology Conference (VTC 2006), pp. 388–392 (2006) 
10. Bouras, C., Stamos, K.: An efficient architecture for Bandwidth Brokers in DiffServ 
networks. International Journal of Network Management 18(1), 27–46 (2008) 
11. Baroncelli, F., Martini, B., Martini, V., Castoldi, P.: Supporting Control Plane-enabled 
Transport Networks within ITU-T Next Generation Network (NGN)., 2008 20th 
IEEE/IFIP Network Operations & Management Symposium (NOMS 2008) (April 2008) 
12. 3GPP TS 23.203, Policy and Charging Control Architecture (September 2008) 
13. Engel, T., et al.: AQUILA: Adaptive Resource Control for QoS Using an IP Based 
Layered Architecture. IEEE Communications Magazine, 46–53 (January 2003) 

128 
R. Good et al. 
14. Masip-Bruin, X., et al.: The EuQoS System: A Solution for QoS Routing in 
Heterogeneous Networks. IEEE Communications Magazine, 96–193 (February 2007) 
15. Rosenberg, J., et al.: RFC 3261 – SIP: Session Initiation Protocol (June 2002) 
16. Weik, P., Vingarzan, D., Magedanz, T.: The FOKUS Open IMS Core – A Global 
Reference Implementation. In: Ilyas, M., Ahson, S. (eds.) IMS Handbook: Concepts, 
Technologies, and Services, Mohammad Ilyas and Syed Ahson, pp. 113–132. Taylor & 
Francis, New York (2008) 
17. Waiting, D., Good, R., Spiers, R., Ventura, N.: Open Source Development Tools for IMS 
Research. In: 2008 4th International Conference on Testbeds and Research Infrastructures 
for the Development of Networks and Communities (TRIDENTCOM 2008) (March 2008) 
18. Good, R., Ventura, N.: An Evaluation of Transport Layer Policy Control in the IP 
Multimedia Subsystem. In: 2008 19th International Symposium on Personal, Indoor and 
Mobile Radio Communications (PIMRC 2008) (September 2008) 
 

Proactive Data Replication Using Semantic
Information within Mobility Groups in MANET
Hoa Ha Duong and Isabelle Demeure
Institut TELECOM - TELECOM ParisTech - CNRS LTCI, 46 rue Barrault,
75013 Paris, France
hoa.haduong@telecom-paristech.fr, isabelle.demeure@telecom-paristech.fr
Abstract. In this article we propose a distributed data replication
algorithm to be used for data sharing in Mobile Ad hoc NETworks
(MANETs). Our system replicates data before users access them. To
this purpose, it uses a predictive algorithm based on semantic informa-
tion about the user and the data and previous access patterns. It also
aims at creating enough replica to prevent data loss in case a peer unex-
pectedly disappears or a partition occurs. To this end, we also propose a
stable group creation algorithm based on long lasting connectivity. While
data sharing systems for MANET already exist, both the use of seman-
tic information and of temporal stability are new in this domain. We
illustrate the interest of the proposed algorithms by showing how a wiki
service on MANETs would beneﬁt from them.
Keywords:
MANET, data sharing, intelligent replication, mobility,
wiki.
1
Introduction
Mobile Ad hoc NETworks (MANETs) are networks established spontaneously
(with no pre-existing infrastructure) between mobile terminals. In MANETs,
terminals may act as routers as well as end users terminals. The toplogy of
the network evolves as the nodes move. These networks therefore create new
challenges for distributed systems and applications designers: they must design
algorithms that adapt to the dynamic network topology; they must also take into
account that there is no guarantee of a persistent access to a given terminal.
Algorithms should avoid the use of central coordinators and should therefore
be conceived as decentralised; they should also introduce redundancy to prevent
faults created by peer disappearance and network partition. The communications
are more scarce than in a wired network and the amount of communication
directly impacts the energy consumption and therefore the amount of time a
user can work before the battery “dies”. Most mobiles terminals also have less
storage space than desktops. Algorithms should thus be aware of the potentially
limited capacities of the terminals.
Collaborative services over MANETs are of interest to academics and indus-
tries as demonstrated by the existence of projects such as the POPEYE european
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 129–143, 2009.
c
⃝Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

130
H. Ha Duong and I. Demeure
research project [5] or the One Laptop Per Child (OLPC) project [2]. A classic
collaborative data sharing service is a distributed ﬁle system, such as adHocFS
[3], but other services may be useful, such as a distributed editor, or a social
networking application. These services may be used as an extension of a central-
ized service, when its users are out of reach of the server but still in group, or
even as a totally independent application.
In this article we focus on the problem of data replication to increase data
availability in a MANET. To each data we associate metada giving information
about data content and attributes. Users also share information about them-
selves, advertising their interests and the resources of their terminals. We use
this semantic information to provide an eﬃcient and adaptable replication mech-
anism. Since we aim at oﬀering a middleware for collaborative applications, we
postulate that while users are mobile, they are moving around in group. To opti-
mize the storage space, we enforce collaborative replication within these groups.
One of our contributions with respect to other existing data sharing systems for
mobile ad hoc networks, such a the ﬁle system adHocFS[3] or the middleware
XMiddle[11], is the introduction of semantic information that allows intelligent
management of data replication by predicting users acesses. Systems such as
Bayou[22], or Coda[21] allow users to work when they are disconnected, but
they use replicated servers to store the data. Since we are in a MANET environ-
ment, a decentralized peer to peer solution, not based on reliable peers to act as
servers is better suited to our problem.
The algorithms presented in this paper are currently being implemented in a
data sharing system that will be run on top of a middleware for MANETs that
was developed within the framework of the Transhumance projet [15].
The remainder of this paper is organised as follows. In Section 2, we present
a wiki service on MANETs that is used throughout this paper to illustrate
the interest of the proposed algorithms. In Section 3, we survey the current
replication mechanisms for MANETs. In Section 4, we present our proposal that
consists in an algorithm for creating stable neighbourhoods and a replication
algorithm that reduces the latency of data access, and prevents the loss of data
in case of partition. In Section 5, we discuss the validation of the proposed
algorithms. Finally, in Section 6, we conclude and discuss the work that still
needs to be done.
2
A Target Application: Wiki over MANETs
In the work presented herein, we focus on a wiki service suited to MANETs. A
wiki is a web application allowing its users to share information by creating and
editing articles in a quick and simple way [1].
Let us consider a scenario taking place in a school where students are en-
couraged to take a scientiﬁc approch to knowledge by the deployement of a wiki
where they describe new knowledge acquired by experimentations and observa-
tions. Each student has his/her own personal laptop, with wireless capability and
ad hoc network protocols. When a class leaves for a ﬁeld trip, the wiki content

Proactive Data Replication Using Semantic Information
131
is distributed on the students laptops so that they can access it even if the ﬁeld
trip location does not provide network access. The students can therefore gather
new information and contribute to the school knowledge base. Upon their return
to school, the new articles produced during the trip are added to the school wiki
and the modiﬁcations are merged.
In this article we focus on the management of the wiki when users are working
in ad hoc mode. We use this service to demonstrate our algorithms. The wiki
articles are structured by hypertext links and categories. Data may be simul-
taneously modiﬁed by several peers hence the need for a coherence protocol.
Data are associated with correlated data via hypertext links, and with seman-
tic information about their content, via categories, such as Science, or Birds of
Southeast Asia. For a given data, few users edit the data and most of them are
only readers.
The algorithms presented below take into account semantic information to
enforce intelligent replication.
3
State of the Art: Replication Mechanisms for MANETs
Replication may be done with two objectives: a data may be replicated to reduce
the latency of accesses, or to enforce the data presence in the network, even if a
fault occurs. We describe 3 kinds of algorithms below. The ﬁrst kind of algorithm
tries to solve the issue of fault, and more precisely partition, without overloading
the storage space. The second kind of algorithm aims at minimising the latency
without overloading the network. The third kind of algorithm attempts to solve
both issues.
In algorithms such as those proposed by Wang [12] and Chen [4], the authors
create the minimum amount of replica such that when the mobility causes the
network to split, all the parts of the network still hold a copy of every data.
To enforce this property, they predict partitioning using the users terminals
position to extrapolate their future position. These methods require GPS (Global
Positioning System) information or equivalent and complex costly computation.
The algorithms proposed by Jing [14] and Yin[13] inspect the data accesses to
decide if a replica should be created. Jing postulates that data often read should
be replicated to lower the access time while a data often written should not be
replicated as the replication would create additional coherence traﬃc. He counts
the accesses made in a neighbourhood and decides based on the read/write ratio.
Yin examines the traﬃc and counts the requests for a data. Depending on the
number of requests and the nature of the data (often edited or not), a peer may
cache the data, or a path to the closest copy.
Takahiro Hara has proposed several algorithms to determine how data should
be replicated. Depending on the information we have about the data, a quantiﬁer
is created to evaluate the pertinence of replicating the data. In [7], Hara considers
that for each user i and each non mutable data j, we know the access frequency
fi, j. In [8], Hara considers data periodically updated, with the period tj and the
probability pi,j a peer accesses a data in this period. He deﬁnes the quantiﬁer

132
H. Ha Duong and I. Demeure
pti,j = pi,j ∗tj, with tj denoting the remaining time to the next update; pti,j is
the probability that the peer accesses the data before it is updated and the local
copy becomes invalid. In [10], Hara considers correlated data. For each pair of
data i and j, the correlation ci,j is the probability that the two data are accessed
together is known. For each data, a priority is calculated in order to reﬂect the
frequency of access to it. In [9], Hara considers data updated aperiodically, with
the probability for each peer of reading the data pRi,j and writing the data pWi,j
known. He deﬁnes the ratio RWRi,j = pRi,j
pWi,j .
For each of those quantiﬁers, three algorithms are proposed. In the ﬁrst al-
gorithm, each peer replicates data for itself only, using the quantiﬁer to decide
which data should be replicated ﬁrst. This algorithm is simple but two neigh-
bours may end up hosting the same data. The second algorithm tries to ﬁx this
problem by having each peer broadcast how they quantify the data to their
neighbours. For each data, the neighbour with the highest quantiﬁer creates a
copy. This algorithm ﬁxes the problem of neighbours hosting the same data but
since the users are mobile, neighbours may be separated between two periods.
The third algorithm tries to ﬁx the problem caused by mobility by creating stable
neighbourhoods: a peer considers another peer to be part of his neighbourhood
if it can be attained by two paths. Within this neighbourhood, the peers have
the same behaviour as in the second algorithm.
Hara’s algorithms use precise information about the data and the accesses,
such as the update frequency or the access frequency. This approach is suitable
for some types of data, such as those produced by sensors, but this information
does not seem to be relevant for human accessed and edited data.
Our solution introduces semantic information about the data and the user
in order to predict the user accesses on the ﬂy by using keywords describing
the content of a data and the user interests. By observing the real accesses, we
correct our prognosis.
4
Proposal: Stable Neighbourhood and Replication
Algorithms
4.1
Asumptions
In our proposals, we make some assumptions about the target MANET system,
namely:
– First we assume that the terminals used are laptops. They have good capacity
and are scarcely mobile but nevertheless they may move and disappear.
– We do not make any speciﬁc assumptions about the communication protocols
that are out of our the scope of this research, except that the routing layer
may be queried to provide the number of hops between any two peers (which
is possible in a number of implementations such as, for example, The UniK
OLSR implementation [16].)
– Each user has a proﬁle, in which the user’s interests are described by a list
of keywords.

Proactive Data Replication Using Semantic Information
133
– Each data has related metadata, also in the form of keywords, outlining data
content. A data may also have a set of correlated data.
In our algorithms, the targetted data granularity is that of a memory page
with size ranging from a few kiloByte to a megaByte.
4.2
Stable Neighbourhood Algorithm
To share the load of hosting data and reduce the number of adjacent replica, we
propose to do collaborative replication: a peer should host data for itself as well
as for its neighbours. This should be done among peers staying in view of each
other on the long term, else the data would be stored without being accessed.
Since the topology is not ﬁxed, a peer needs to discover and maintain a stable
neighbourhood. Here we propose an adaptable algorithm 1 for a peer to construct
a neighbourhood that is stable over time.
In a nutshell, this algorithm 1, executed periodically, behaves as follows:
– For each peer
– If the peer is present this round, PresenceCounter is incremented, unless
the value is already at MaxPresence.
– If the peer is absent this round, PresenceCounter is decreased, unless the
value is 0 in which case we do not keep trace.
– It also stores the average distance between peers, in case an overlaying
algorithm needs this information.
– It decides on a group by setting a minimum threshold for the presence
counter value.
How we set the period of execution for the algorithm 1 is discussed in the
Validation Section (we use the OLSR algorithm route maintaining a period of 2
seconds).
The parameters of the algorithm 1 have the following meaning:
– maxPresence (line 11): the PresenceCounter value must have an upper bound
so that when a peer present for a long time disappears, it is removed from
the neighbourdhood.
– α (line 20) reﬂects how our evaluation of the average distance taking into
account the instant value. α must belong to [0,1]
– thresholdStable (line 26) reﬂects how volatile a peer in the neighbourhood
is allowed to be.
– thresholdDistance (line 26) reﬂects the acceptable width of the neighbour-
hood
The use of a maximum (MaxPresence) and a minimum (thresholdStable)
value for the presence counter instead of letting it increase indeﬁnitly allows
us to eliminate a peer from the group if it disappears, while tolerating a few
intermittent disconnections. They can be understood as time spans: e.g. for a
polling period of 10 seconds, a thresholdStable of 60 and a MaxPresence of 72,

134
H. Ha Duong and I. Demeure
we expect a peer to stay 60*10s=10 minutes in our vinicity before considering
it a neighbour. We tolerate at most (72-60)*10s=2 minutes of absence before we
remove it from the neighbourhood.
Init
1
Set Neighbourhood, Potential, Reachable= ∅;
2
This part of the algorithm is repeated periodically until line 29 to take
3
into account the mobility;
Reachable = { (peer reachable this period, distance) };
4
maxDist = distance to the furthest peer;
5
foreach (peer, distance) ∈Reachable and peer /∈Potential do
6
add (peer, distance, 1) to Potential;
7
end
8
foreach (peer, distance, PresenceCounter) ∈Potential do
9
if (peer, distanceNew) ∈Reachable) then
10
PresenceCounter = max(PresenceCounter++, maxPresence);
11
distance = α*distanceNew+(1 −α)*distance;
12
end
13
else
14
if (PresenceCounter =1) then
15
remove peer from Potential;
16
end
17
else
18
PresenceCounter- -;
19
averageNumberHops = α*maxDist+(1- α)*
20
averageNumberHops;
end
21
end
22
end
23
Neighbourhood =∅;
24
foreach (peer, distance, PresenceCounter ∈Potentials) do
25
if PresenceCounter ≥thresholdStable and averageNumberHops ≤
26
thresholdDistance then
add peer to Neighbourhood;
27
end
28
end
29
Algorithm 1. A stable group formation algorithm
As we have seen, our algorithm periodically checks which peers are within
reach. This can be done in diﬀerent ways, depending of the underlaying routing
algorithm:
– a proactive routing algorithm such as OLSR creates and maintains routes
between nodes even when their is no traﬃc.
– a reactive routing algorithm such as AODV creates routes only when re-
quested.

Proactive Data Replication Using Semantic Information
135
We do not discuss the pros and cons of each type of algorithm which is out of
the scope of this paper. The availability of the Transhumance middleware [15]
runing OLSR in our lab, led us to choose a proactive routing algorithm (OLSR);
we can therefore obtain the list of reachable terminals by “peeking” in the OLSR
routing tables.
This algorithm does not use location information to construct groups and may
be executed independently by each terminal. While it may not be as accurate
as GPS based algorithms, it is less compute-intensive and network greedy. Some
algorithms use an average distance between peers and assume that if peers are
close for long enough, they belong to the same group; we prefere to base our
algorithm on the time peers spend within reach of each other.
4.3
Replication Algorithms
Replicating data is a mechanism used to accelerate data access by caching it. It
is also used to introduce redundancy and provide alternate access when a fault
occurs, rather than loosing the data.
In this section we present two complementary replication algorithms to solve
both problems.
Replication Based on Interest. We propose to create local copies of poten-
tially interesting data before the user tries to access them. To do so, we need to
predict the user accesses.
For a data D, described by a set of keywords KD, and a user U, whose interests
are summed up by a set of interests IU, we deﬁne in 1 the interest U may have
in the data as PU,D:
PU,D = 1
2 ∗(card(KD ∩IU)
card KD
+ card(KD ∩IU)
card IU
)
(1)
PU,D calculates which proportion of the keywords are interesting for the user
with respect to the number of keyword and the number of interests.
Since we want to enable collaborative sharing, a peer should take into account
the interests of its neighbours when replicating data. As terminals may have
heterogeneous capacities, a peer should only provide this service to peers with
less resources.
With K the set of peers in the stable neighbourhood, each peer ki ∈K
evaluates the resources it possesses to produce a resource representant res, res ∈
[0, 1]. All the peers must use the same scale to establish their resources. resi is
then used to calculate how many peers may be generous in sharing their resources
with peer i. Interests and res are broadcasted in the stable neighbourhood. For
each keyword A found in the neighbourhood (ie present in at least one set of
interest), each peer kp ∈K determines the weight of A.
First of all, it aggregates the interest of other peers ki,i̸=k ∈K with less re-
sources than it has by summing the diﬀerences between its res and the one of
peers with less resources for which A is an interest as in 2 :
SumWeight(kp, KW) =

ki∈K,ki interested by A
max

(resp −reski), 0

,
(2)

136
H. Ha Duong and I. Demeure
To each keyword A we then associate a weight, AWeight, using formula 3:
AWeight(kp, KW) = SumWeight(kp, KW) +

1 if KW interest kp
0 else
(3)
Thus, each peer creates a set of aggregated interests, AG, containing a list of
pairs interests with their weight(A, AW).
For a dataD with associated keyword KW, and a user U, with aggregated
interests AG, the interest formula becomes 4:
c =

(A,AW)∈AG ∧A∈KW
AW, PU,D = 1
2 ∗(
c
card KW +
c

(A,AW)∈AG AW ) (4)
In the data sharing system that we are currently specifying, a message is
broadcasted to all peers to advertize the creation of a new data. This message
will also carry the keywords associated with this data. When a peer receives
such a creation message, it calculates its interest in the data. If P is superior to
a threshold the data is replicated. The values of the interests are also aggregated:
for each percent P between 0 and 100, we count how many data have an interest
rounded to P. If a data interest is superior to the N th centile, it may be replicated.
Example
interestThreshold : 0,8
data Keywords =A,B,C,E
if user Interests =A,B,C,D, PU,D = 0, 75 , the data is not replicated
if user AG=(A,1.3),(B,1),(C,2),(D, 1),(E,0.1), PU,D = 0, 99, the data is repli-
cated
Replication to Prevent the Loss of Data. We have seen how to decide if
a data may be interesting for the user and how to replicate it. Even with this
mechanism, since a peer is limited by its storage, some data may not be repli-
cated. We propose an algorithm to create enough replica so that, should a crash
happen, such as a crash or a network partition, no data would be lost.
This algorithm is executed when a peer learns of the existence of a new
data but is not interested enough to replicate it.
repeat
1
wait to be informed of replica creation in the previous step, ie the
2
RTT to the farthest node in the group ;
K = the number of copies that must be created);
3
N = the number of potential hosts for the data (i.e., hosts in the
4
neighbourhood with no copy);
if rand[0,1] ≤K/N then
5
Create a replica and broadcast the information;
6
end
7
until enough replica ∨a local replica has be created ;
8
Algorithm 2. An algorithm to enforce the creation of a minimum number
of replica

Proactive Data Replication Using Semantic Information
137
Combining the Algorithms. In the beginning, each peer establishes his stable
neighbourhood. We consider that all peers use the same parameters to tune the
algorithm. The relationship ”Belongs to neighbourhood” is thus symmetrical.
Each peer broadcast its proﬁle (resources level and interests) to its neighbours.
The stable neighbourhood is maintained by periodically checking the state of
the neighbours. When a modiﬁcation occurs in a peer proﬁle, it is broadcasted
and the neighbours integrate the modiﬁcations.
When information about a new data is received, a peer calculates its potential
interest for the data. If it is interested, the peer replicates the data and broad-
casts this information (ﬁrst algorithm). Else, it caches the metadata in case a
neighbour would later need the data. The peer then checks if there is enough
replica in the neighbourhood and if it is not the case, it attempts to create a
new one.
4.4
Learning New Interests
The user proﬁle includes a list of interests as keywords and associated metadata;
data are also described by keywords. In the preceeding section, we have described
how this information is used to predict the user accesses and gather data which
may interest him. This allows the user to access data even when the creator of
the data is out of reach.
As the user accesses data, we want to analyze the keywords associated to
these data to see if new interests may be detected.
In a wiki, editors are encouraged to structure the articles into categories. We
take those categories as keywords; the keywords are thus organized in a graph
of categories and subcategories.
This graph is a Direct Acyclic Diagram (DAG), and not a tree; e.g. an ar-
ticle about tourism in France should be part of both the France and Tourism
categories. The uppermost categories are under a category that we call root.
Furthermore, a category cannot be a subcategory of itself, so we do not have
cycles in the graph.
Each data comes with its DAG representing its categories and each peer stores
a DAG representing all the data it has accessed so far. Each node has a counter
indicating how many times this keyword has been meet.
When an user accesses a data for the ﬁrst time, the data DAG is merged with
the user DAG. To determine if a node may constitute a potential interest, we
distinguish the case of the leaf nodes and the case of the other nodes. If the
node is a leaf, we check if its value is superior to x + 2 ∗σ, with x being the
average of the value of the leaves, and σ the variance. If the node is not a leaf,
we check how many children it has, and how the counter values are distributed:
if the variance is low enough, we consider the node as a potential new interest.
5
Validation
As we have seen in Section 3, existing algorithms have tried to solve the problem
of data access latency and data loss by replication. Hara’s algorithms attempt

138
H. Ha Duong and I. Demeure
Fig. 1. Structured keywords space
This example references Figure 1.
For the leaves E, F and H x = 2, σ =≈
0.57
None of those nodes is considered as a
potential new interest.
For the nodes D, x = 3, σ =≈0.5
D children have an evenly distributed
load, so we consider D as a potential new
interest.
to ﬁx those two problems but his hypotheses are not adapted to an application
where data are edited by humans.
Our solution introduces semantic information about the data and the users
to predict their accesses. We also adapt to the user by extracting patterns from
his previous accesses.
A ﬁrst version of our system has been implemented in the POPEYE project
[5]. This version implements a simple replication mechanism based on interests,
and uses clusters created at a lower level as stable neighbourhoods. A more
advanced stand alone version that could be run on top of the Transhumance
middleware, as mentioned before, is under development.
Validation and evaluation of algorithms for MANET is a complex problem.
Since the terminals are mobile, a live experience requires moving participants
and thus cannot be reproduced ad lib. Furthermore, since terminals have wireless
connectivity, the reproductibility of an experiment is heavily dependant of the
environment (e.g. how many other wireless networks are presents that can create
interferences). We now explain how we intend to validate our algorithms.
5.1
Validating the Group Algorithm
Since we are building our prototype on top of a proactive routing algorithm,
OLSR, a peer just takes a peek at the content of its routing table to update
it stable neighbourhood. Thus, the cost in messages is in eﬀect null. We will
therefore validate our algorithm pertinency, by running it in a context where
we know the existing groups, and checking if the algorithm comes up with the
eﬀective groups. We want to see how volatile the peers within a group can be,
with our algorithm still detecting the eﬀective groups.
In order to validate and adjust our group algorithm, we have implemented it in
the NS-3 simulator [19]. NS-3 is an open source discrete event simulator intented
to eventually replace the NS-2 simulator. While NS-2 is much more widely used,
we choose NS-3 for several reasons. NS-2 has had a lot of contributions over the
years that make it more complete but the code is less homogeneous and more
complicated to grasp. NS-3 and NS-2 both implement the models that we need
to simulate our algorithm (WiFi, IP and OLSR routing), but while we need to

Proactive Data Replication Using Semantic Information
139
patch NS-2 to use OLSR, it is already part of the NS-3 simulator. Finally, since
NS-3 aimed at replacing NS-2, we believe that its designers learned from the
mistakes made in NS-2, and it should be, in the long term, a better tool. Even
if NS-3 is not as well documented and known as NS-2, we prefere to use it as we
think it should become more used in the future.
Since there is no Group Mobility model in NS-3, we have implemented a sim-
ple Group mobility model that allows us to predeﬁne groups of nodes sticking
together, that peers may join and leave from time to time. These peers move
at pedestrian speed and stop at times. We set the period of the algorithm at 2
seconds, namely the period of route refreshing in OLSR. We ran diﬀerent simula-
tions with diﬀerents values of parameters thresholdStable and MaxPresence, and
we made the size of the area and the number of peers vary. Then, we computed
the correlation between the actual groups as deﬁned by the mobility model and
the groups built by our algorithm. We simulated 20 minutes of execution.
In tables 1(a) and 1(b) we can see results for two particulars simulations.
In the ﬁrst one 1(a), thresholdStable=3 and MaxPresence=10 : a peer is part
of a neighbourhood as soon as it has been present for 6 seconds (threshold-
Stable*period); it leaves the neighbourhood if it is absent for more thant 14
seconds ( (MaxPresence-thresholdStable )*2 ). In the second table 1(b), thresh-
oldStable=90 and MaxPresence=150: a peer is part of a neighbourhood as long
as it as been present for 3 minutes; it is ejected when it is absent for more than
2 minutes. We simulated for 16, 25, 36 and 50 peers and for an area side length
of 500m, 1000m, 1500m, 2000m and 2500m.
The columns represent length of the size of the simulated area while the lines
represent the number of groups by the number of peers in each group. The values
in the table are the percentage of accuracy of our algorithm: for each round and
for each peer we have checked if the calculated neighbourhood is the eﬀective
group; we have then computed the portion of rounds where the neighbourhood
is accurate.
As we can see in 1(a) and 1(b), the accuracy of the algorithm seems to grow
when the simulated area is larger.
Figures 2 and 3 plot the percentage of accuracy, this time in relation with
the density of the terminal : nb groups∗nb peers per group
area side length2
. These ﬁgures show the
algorithm is more accurate if the density is low. Thus, those errors are due to the
Table 1. Simulation results. Columns: size of the simulated area; lines: number of
group by number of peers in each group
500 1000 1500 2000 2500
6x3 0,03 47.23 73.10 72.62
94
5x5 1.02
23
54.61 74.61
75
6x6
0
17.96 37.58
65
71
5x10 NA
NA
26.2
50
58.38
(a) thresholdStable= 3 and a Max-
Presence=10
500 1000 1500 2000 2500
6x3 0,03 16,88 55,95 71,23 68,55
5x5
0
24,75 58,96 81,23 62,88
6x6
0
23,3 50,63 59,31 57,78
5x10 NA 9,42 30,12 53,92 51,41
(b) thresholdStable = 90 and Max-
Presence = 150

140
H. Ha Duong and I. Demeure
Fig. 2.
Thresholdstable=3,
MaxPres-
ence=10,
accuracy
as
a
function
of
density
Fig. 3.
Thresholdstable=90,
MaxPres-
ence=150 , accuracy as a function of den-
sity
number of peers per square meter : if a lot of peers are present in a small space,
they cover enough ground to provide stable connectivity even with peers not in
their group. Other simulation results, not included, here conﬁrm this result.
The right values of thresholdStable and MaxPresence depend of the size of
the area, the volatility and the speed of the terminals. We intend our system to
work and terminals moving to pedestrian speed but the other parameters will
depend on the situation.
While these tests underline this issue, they also show that our algorithm does
recognize the eﬀective groups as being part of the neighbourhood, even is some
other peers happen to be connected for a time long enough to be included, mainly
because the density of peers is high enough to provide connectivity.
5.2
Validating the Replication Algorithm
We are now in the process of evaluating our replication algorithm, which leads
us to answer the following questions: What is the cost in terms of computing
power and number of messages of these algorithms? Is a replica accessed? How
many data must be fetched? How many requests cannot be satisﬁed because the
data is not available?
For the cost of the preemptive replication, we expect our results to be close
to the results obtained by the algorithms proposed in Hara’s works: similarly
to his proposal, the peers exchange information about their interests within a
group to decide what they should replicate.
Let us consider that we have M peers in total. How many messages are ex-
changed in a stable group of N peers? First of all, interests and resources co-
eﬃcient are exchanged once within the group, for a cost of N*(N-1) unicast
messages. If our group algorithm manages to detect stable groups, this step
should be rarely done. We also postulate that peers seldom update their inter-
est. When a new data is shared anywhere, this information is broadcasted to all
the peers, with either M-1 unicast messages, or 1 broadcast message. The cost
for a group of N peers is therefore N. Peers decide if they intend to replicate.

Proactive Data Replication Using Semantic Information
141
When a peer creates a replica, it send a message to ask for the data, receives it
(2 unicasts messages, one whose payload is the data) and informs its neighbours
(N-1 messages). Our algorithm creates K replica when a new data is shared, in a
group of N peers, the number of messages exchanged is therefore N+K(2+N-2)
messages.
The algorithm has been implemented in the Popeye project[5] and was tested
in real conditions, as can been seen on video available on the Popeye website[18].
While our algorithm has been tested functionally within Popeye, we are missing
evaluation of the scalability and the performance of the algorithm. We also would
like to be able to execute the algorithm several time while we change a parameter
to adjust it. As we have seen before, this must be done with a simulator. We are
currently conducting more evaluations.
Our problem with evaluating this algorithm lies in deciding if a replica has
been wrongly created, and if a replica should have been created: we propose a
predictive replication algorithm that estimates the behaviour of the user based
on a set on predeﬁned interests and its previous accesses.
We do not have for the moment a non biaised solution to validate our repli-
cation algorithm, as we do not have traces of accesses to a set of data with
semantics, by a set of users with established interests. We cannot use artiﬁ-
cial users either since it would give us strongly biaised results: our system itself
simulates the behaviour of the users to predict which data should be replicated.
To evaluate the replication algorithm, we are currently implementing our proof
of concept application, a P2P wiki for MANETs. This system will then be de-
ployed and used and we will collect real traces of usage to reinject in a simulator.
6
Conclusion and Future Work
Collaborative services over MANETs need to take into account the particularities
of MANETs, such as the dynamic topology, or the lack of a reliable server. In this
article, we focused on the problem of data replication in MANETs, to provide
small latency data access, and to prevent the loss of data in case of a fault (e.g.
peer becoming out of reach).
First of all, we propose an algorithm to build stable peers group. Rather than
using location information or topological proximity to outline a group, we shape
up a group by surveying the continuous connections between peers over time.
Then we propose to solve both replication problems by using a two phases
algorithm using those stable groups. First of all, data are replicated by peers they
interest. Then, if not enough replica exist to guarantee the survival of the data
in case of fault, new copies are created randomly within a stable neighbourhood.
Our solution diﬀers from existing algorithms because we introduce semantic
information about the data and the user to predict the user accesses on the ﬂy
and manage a more intelligent replication.
In future work, we will modify our algorithm to take into account editable
data in the replication algorithm. Let it be noted that editable data raises the
problem of coherence. While this is not addressed in this paper, we are handling

142
H. Ha Duong and I. Demeure
this issue; we oﬀer eventual consistency by using the commutative replicated
data type Treedoc[20].
We are currently developing a distributed wiki engine integrating the afore-
mentioned algorithms. We will use this application to demonstrate the validity
of our algorithms and evaluate their performance. To this end, we will also have
to decide on a positioning algorithm and a search algorithm.
References
1. http://en.wikipedia.org/wiki/wiki
2. OLPC Association, http://www.laptop.org
3. Boulkenafed, M., Issarny, V.: Adhocfs: sharing ﬁles in wlans. In: Second IEEE
International Symposium on Network Computing and Applications, 2003. NCA
2003, pp. 156–163, April 16-18 (2003)
4. Chen, K., Shah, S.H., Nahrstedt, K.: Cross-layer design for data accessibility in
mobile ad hoc networks. Wirel. Pers. Commun. 21(1), 49–76 (2002)
5. Popeye Consortium, http://www.ist-popeye.eu/
6. Inc. Google. picasa.google.com
7. Hara, T.: Eﬀective replica allocation in ad hoc networks for improving data acces-
sibility. In: INFOCOM, pp. 1568–1576 (2001)
8. Hara, T.: Replica allocation methods in ad hoc networks with data update. Mob.
Netw. Appl. 8(4), 343–354 (2003)
9. Hara, T., Madria, S.K.: Dynamic data replication using aperiodic updates in mobile
adhoc networks. In: Lee, Y., Li, J., Whang, K.-Y., Lee, D. (eds.) DASFAA 2004.
LNCS, vol. 2973, pp. 869–881. Springer, Heidelberg (2004)
10. Hara, T., Murakami, N., Nishio, S.: Replica allocation for correlated data items in
ad hoc sensor networks. SIGMOD Rec. 33(1), 38–43 (2004)
11. Mascolo, C., Capra, L., Zachariadis, S., Emmerich, W.: Xmiddle: A data-sharing
middleware for mobile computing. Wirel. Pers. Commun. 21(1), 77–103 (2002)
12. Wang, K., Li, B.: Eﬃcient and guaranteed service coverage in partitionable mobile
ad-hoc networks (2002)
13. Yin, L., Cao, G.: Supporting cooperative caching in ad hoc networks. IEEE Trans-
actions on Mobile Computing 5(1), 77–89 (2006)
14. Zheng, J., Su, J., Yang, K., Wang, Y.: Stable neighbor based adaptive replica allo-
cation in mobile ad hoc networks. In: International Conference on Computational
Science, pp. 373–380 (2004)
15. Demeure, I., Paroux, G., Hernando Ureta, J., Khakpour, A.R., Nowalczyk, J.:
An Energy Aware Middleware for collaboration on small scale MANets. In:
Autonomous and Spontaneous Networks Symposium Telecom ParisTech, Paris,
November 20-21 (2008)
16. Tannesen, A., Hafslund, A., Kure, O.: The UniK - OLSR plugin library. In: OLSR
interop workshop, San Diego, August 6-7 (2004)
17. Ha Duong, H.D., Melchiorre, C., Meyer, E.M., Nieto, I., Arrufat, M., Pelliccione,
P., Tastet-Cherel, F.: POPEYE: a simple and reliable collaborative working en-
vironment over mobile ad-hoc networks. In: The 3rd International Conference on
Collaborative Computing: Networking, Applications and Worksharing (Collabo-
rateCom 2007) Crowne Plaza White Plains, New York, USA, November 12-15
(2007) IEEE Catalog Number: 07EX1828C. ISBN: 1-4244-1317-6

Proactive Data Replication Using Semantic Information
143
18. http://www.ist-popeye.eu/
19. http://www.nsnam.org/
20. Shapiro, M., Preguica, N.: Designing a commutative replicated data type (2007)
21. Kistler, J.J., Satyanarayanan, M.: Disconnected Operation in the Coda File Sys-
tem. In: Proceedings of the 13th Symposium on Operating Systems Principles, pp.
213–225. ACM Press, New York (1991)
22. Demers, A.J., Petersen, K., Spreitzer, M.J., Terry, D.B., Theimer, M.M., Welch,
B.B.: The Bayou architecture: Support for data sharing among mobile users. In:
Proceedings IEEE Workshop on Mobile Computing Systems & Applications, Santa
Cruz, California, September 1994, pp. 2–7 (1994)

Scalable Interactive Middleware Components for
Ubiquitous Fashionable Computers
Gyudong Shim and Kyu Ho Park
KAIST, Daejeon, Korea
gdshim@core.kaist.ac.kr,
kpark@ee.kaist.ac.kr
http://core.kaist.ac.kr
Abstract. The middleware for location based interactive applications
requires scalability in large scale spaces. As the number of users and
target services are increased, the server has to process massive spatial
queries and event handling requests eﬃciently. Our middleware compo-
nents are developed to extend the U-interactive system for large scale
environments. The system manages the location information for large
number of users and target objects. In addition the system handles
events caused by user commands. We developed eﬃcient tuple indexing
and query mechanism by composite keys. As a new spatial query, Fan
search is invented to provide eﬃcient target selection by distance and an-
gle. We optimized the query processing by eﬃcient node traversing and
data-aware interval skipping. The tuple matching process is performed in
bounded time up to 100,000 objects. Fan search with C-Cuve has supe-
rior performance than Z-Curve in high density nodes in the experiment.
Keywords: Ubiquitous middleware, human machine interactions, tuple
spaces, spatial query indexing.
1
Introduction
Many researches have been come out to realize ubiquitous computing environ-
ments in the real world. The common philosophy of the researches is to make a
convenient life with interaction with surrounding computers. Users in the ubiq-
uitous environment can obtain any information by multiple interfaces and dis-
plays. Location based interactive applications in the ubiquitous environments
have been developed in many research projects [10], [11], [12], [13].
Our research project teams have developed testbed on KAIST campus called
U-TOPIA and a wearable computers named Ubiquitous Fashionable Computer
(UFC)[3]. U-TOPIA has been equipped with indoor and outdoor testbed for
location services which consist of ZigBee and UWB[9] sensor networks.[7].
UFC has been developed as a wearable gadget and cloth as shown in Fig.1 for
convenience and portability. In order to interact with the environments with in-
tuitive gestures, UFC has a gesture recognition device called iThrow[4]. iThrow is
a ring typed intuitive interface device. iThrow can recognize speciﬁc movements
and two dimensional pointing direction of the ﬁnger.
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 144–156, 2009.
c
⃝Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

Scalable Interactive Middleware Components for UFC
145
pKASSO, Security Server
µ-ware, Middleware
Testbed(Wi-Mesh [Outdoor])
UFC (Ubiquitous Fashionable Computer)
Testbed(ZigBee, UWB[Indoor])
iThrow
Main Module
Attachable Modules
Fig. 1. U-TOPIA architecture and UFC components
A UFC user can interacts with objects and services by gestures. A UFC user
can select a target inside the testbed by pointing it with iThrow. The selected
target is shown at the display of UFC as a feedback. After target selection, the
user can control the target through intuitive gestures such as throwing, pulling
up, and rolling left or right. For example, user can print a document ﬁle by
throwing to the printer after pointing the document object.
We designed an interactive middleware system, called U-interactive[5], that pro-
vides spontaneous interaction between UFC users and U-TOPIA. U-interactive
provides Virtual Map which is a container and interface to the interactive objects.
Each physical object can be assigned into the Virtual Map with location and
interactive attributes.
In this paper, we introduce scalable middleware components designed upon
the U-interactive system. It is important that the middleware should be scalable
to be eﬀective even in the massive environments such as subway stations, stadi-
ums, and auditoriums. We assume that the target service areas would have up to
hundreds of thousands objects with UFC users. We will focus on data indexing
and query processing for the interactive services with scalability.
In U-interactive system, the server contains many objects of tuples for the
target services and user locations. We developed a new tuple space based coor-
dination middleware, which manages tuples and provides scalable tuple matching
schemes in reverse time orders. In addition, it contains useful functionalities for
ﬁle transfer and event handling mechanisms.
We propose eﬃcient spatial query processing, which is called Fan search, will
reduce computing overhead from massive query processing from users. The ob-
jects are searched within a speciﬁc fan query region. Fan search diﬀers from
previous rectangular based query processing such as NN, k-NN by query region
and indexing scheme. Fan search indexes spatial objects by one-dimensional key

146
G. Shim and K.H. Park
which is converted by a space-ﬁlling curve. As implementation optimizations,
the path stacks of the index tree and skipping query regions are invented.
The paper is organized as follows. In Section 2, we describe the ubispace as
basic coordination middleware for our system. The target selection algorithm
will be presented in Section 3. In Section 4, the scalability of our components
is evaluated. Section 5, 6 related middlewares and algorithms are discussed and
concluded.
2
UbiSpace
Since many mobile clients and infrastructures exist in the ubiquitous environ-
ments, it is necessary computing paradigm for this distributed environment to
communicate each other in the application level. As a black board system, tuple
space has been researched and evolved by many researchers such as T-Spaces[6],
JavaSpaces[8]. These tuple space provides applications with useful and simpliﬁed
coordination. Due to the spatial and temporal decoupling eﬀect of tuple space,
many ubiquitous projects [1], [2] adopted tuple space as a core coordination
middleware.
2.1
Tuple Space
The peers can write or read a tuple from the tuple space. A tuple space contains
tuple which consist of a sequence of typed ﬁelds. Each ﬁeld can be formal or
actual, which are some type of an attribute or exact value of an attribute. These
tuples are inserted into the space by peers who retrieve the tuples by tuple
matching.
Tuple matching is explicit addressing method because it ﬁnds any tuple which
matches a template without considering of the insertion order. Tuple matching
between tuple t1, t2 can be deﬁned as follow conditions.
1. both t1 and t2 have the same tuple name.
2. both t1 and t2 have the same number of ﬁelds N.
3. each of ﬁelds of t1 matches the ﬁelds of t2 in order, i.e. t1.ﬁeldi matches
t2.ﬁeldi, ∀i ∈{0..N}
The matching of two ﬁelds are described as shown in Table 1. Notice that the
equals on two actual comparison means java.lang.Object.equals() method. After
that this tuple matching operation costs complex comparison of java objects.
Table 1. Tuple matching condition
Field(t1) Field(t2) matching condition
formal
formal
t1.class = t2.class
formal
actual
t2.object is assignable to t1.class
actual
formal
t1.object is assignable to t2.class
actual
actual
t1.object equals t2.object

Scalable Interactive Middleware Components for UFC
147
UbiSpace is inspired by T-Spaces which is an extension of Tuple space and
stable commercial product of IBM. T-Spaces provides event handler registration
for incoming tuple by tuple matching. This mechanism is useful for implementing
white board applications such as sharing distributed clipboard which reacts the
status change of sharing data [6].
2.2
Limitations of Tuple Space
However these tuple space has some problems directly adapted in ubiquitous
environments. First, tuple matching is implicit with the insertion order of tu-
ples. If status variables are described with tuples, most of application requires
the newest tuples in the tuple space. As a result, tuple space should provides
tuple order by LIFO but T-Spaces provides only FIFO tuple matching mecha-
nism. Second, tuple has expressive and general data description but it is a little
bit complex for application developers. Application developers should pay at-
tention to the tuple matching syntax. It requires redundant code fragments. So
the API should has simple and concise method. Third, In the worst case tuple
matching requires scanning of entire tuples to ﬁnd a matched tuple. This is the
most important disadvantage of tuple space. So T-Spaces provides indexed tuple
matching by naming a tuple to speciﬁc string. However it is a duty of application
developer that design and naming of tuple creation. If tuples are not properly
manipulated by users, it requires full scanning overhead and not scalable to large
number of tuples. Fourth, most of applications in our system operate a ﬁle as a
tuple. Application developer should convert ﬁle contents to a general tuple ﬁeld
but it is burden of space to the server repositories because most of tuple space
hold data in the memory of the server. Therefore tuple of File should be handled
diﬀerently to save the server’s memory space.
2.3
Design and Motivation of UbiSpace
From these limitation of tuple space, we designed and implemented a new tuple
space or UbiSpace. The important characteristic of UbiSpace as follow.
1. Design of String key based concise operations. Like a hash table, tuple
are indexed by string name tag. A tuple can be inserted, updated, and read
by exact string match. For event handling we added publish and subscribe
methods. subscribe method can register event handler for tuple event such
as insertion of tuple, delete of tuple, update of tuple. these operations are
anomaly of T-Spaces’ event register, deregister operation but we added the
count of event handler invocation. The event handler can be executed only
the count times.
2. Indexing tuples by name and tuple id for scalable and deterministic
tuple matching. UbiSpace prevents tuple matching from scanning entire tu-
ples. Each tuple has a given name and unique id for indexing. By default
there are two index of tuples, the ﬁst is index of tuple ID for direct tuple
addressing, the second is index of <tuple name, tuple ID> composite key.

148
G. Shim and K.H. Park
The tuple ID is sorted reverse order for LIFO of tuples. In order to guarantee
the bounded time of indexing insert, read operations, we adapted B+tree[14]
as a basic indexing tree.
3. Automatic ﬁle transfer by tuple operations. Any tuple which has a ﬁeld
of java.io.File objects are inspected during normal tuple space operations. If
a tuple has File ﬁeld, the content of the File object are transferred between
client and server. Since both server and client have the same copy of the
ﬁle in the given directory, the redundant ﬁle transfer is not performed by
caching of the ﬁle. This automatic ﬁle operation is very simple and useful
for ﬁle transferring application, especially in ithrow ﬁle throwing operations
2.4
Usage Example of UbiSpace
A typical usage of UbiSpace for interactions are outlined in Fig.2.4. In this
example, a UFC user throws a ﬁle to the target service 2. In order to receive
the command from the UFC, the services should register the subscription by
subscribe operation. The subscription is identiﬁed by the preﬁx of “ithrow data ”
and “X” of actual target object id. By this manner, each services register their
subscription by diﬀerent string key of own ID in the system. The type of data can
be recognized in the event handler of the subscription. After these registrations
of subscription, any inserted tuples are examined whether they are matched
to a speciﬁc subscription tuple template. The template tuples of ID 2, 3 and
4 are examined whether match the template key of “ithrow data 2”. Since the
templates are named by “ithrow data 2”, “ithrow data 3”, and “ithrow data 4”,
only the template tuple of ID 2 matches the inserted tuple <“ithrow data 2”,
cam.jpg>. It is published to the ID 2, and the second ﬁeld is type of File, the
ﬁle contents are delivered to the ID 2. Finally the event handler is performed.
The event handler has routine to display the image ﬁle.
<“ithrow_data_2”, cam.jpg>
ID: 1
ID:2
ID:3
ID:4
<“ithrow_data_2”,  * >
<“ithrow_data_3”,  * >
<“ithrow_data_4”,  * >
publish
subscribe
Formal
Actual
UbiSpace
Fig. 2. UbiSpace usage for interaction between UFC and services
2.5
Implementation of UbiSpace
UbiSpace is implemented by traditional thread level server/client model. Fig.3
describes the thread level architecture of UbiSpace implementation. Considering

Scalable Interactive Middleware Components for UFC
149
IO Thread
IO Thread
IO Thread
IO Thread
Process Thread 1
Process Thread N
UbiSpace Interface
Space 1
...
Tuple
Tuple
Tuple
B+Tree Key Indexing
Space N
Tuple
Tuple
Tuple
B+Tree Key Indexing
Subscribe Info
Subscribe Info
Server side
Client side
...
Request Queue
Response Queue
Event Handler
Subscription ID
s1
s2
eh1
eh2
Subscription Thread
IO Thread
Fig. 3. UbiSpace architecture in thread level
harsh or unstable network conditions, the ﬂow of request and response should be
reliable to the packet loss or error of internal server status. Therefore we imple-
mented timer based reliable request delivery mechanism. If a client cannot receive
the proper response in a given timeout from the server, the request is retransmit-
ted into the server. If a client fails to receive the response and retransmits the
request over than N times in a row, the connection is closed and the client regards
the server as unavailable. In order to implement timer based operations, we sep-
arated the application thread and IO thread which takes network IO handling.
In addition java.lang.Object.wait(timeout)’s monitor is used for timer’s timeout.
Due to synchronization problem of requests of clients, the requests are serialized
by the incoming order, i.e. FIFO in the synchronized queue. There are two queues
per the space, request queue and response queue. The request is put on the request
queue in a order, IO thread of the client take it from the right side. The response
queue is used for waiting condition variables. The application thread waits on this
queue to take the response. Because there are multiple spaces in the server, we bal-
anced the workload of the single space to single thread. This approach is proper
and beneﬁcial because any further synchronization mechanisms are necessary such
as condition variables or mutual exclusive locks.
B+tree has been implemented basically algorithm of [14]. We modiﬁed query
routine of nodes into bound check and binary search of a key. Since each node
contains ordered keys, ﬁnding a key can be performed binary search in O(logN)
complexity. However binary search requires constant time of key traversal to
escape the loop condition even when the lookup key is left or right side of the
node. In order to eliminate unnecessary binary search attempts, UbiSpace checks
the boundary of the traversing node whether this node has the key by with the
lowest key and the highest key comparison. It may be constant overhead when
a search key is inside of the traversing node range. Even though most of our
system workloads ﬁnd the newest key which resides on left side leaf nodes.

150
G. Shim and K.H. Park
Table 2. String key based basic operations of UbiSpace
Return Method signatures
long
insert(String key, java.io.Serializable obj)
Object take(String key)
Object read(String key)
long
publish(String key, java.io.Serializable obj)
long
subscribe (String key, java.lang.Class clazz,
EventHandler callback, boolean isWrite)
void
unsubscribe(long seqNumber)
void
update(long itemID, String key, java.io.Serializable obj)
void
delete (long itemID)
The basic string key based operations are listed in Table.2. The API doesn’t re-
quire additional tuple manipulation logic for tuple matching. Only single string key
can be assigned for tuple matching. The string key and object are sent in method
parameters. The general tuple indexing operations are omitted due to the limit of
this space. The general tuple space operation is similar with T-Spaces.
3
Fan Search: Target Selection Algorithm
Users can select an target service or an interactive object by pointing gesture
of iThrow. Yoo et al, proposed target selection algorithm which select a object
which has minimum angle diﬀerence.[4] They also proposed adaptive angle place-
ment scheme for easy target selection of clusted objects. We devised Fan search
in order to support a scalable target selection mechanism even in the large spaces
such as square or stadium. Therefore the target selection algorithm has to ﬁlter
objects by distance and angle eﬃciently.
3.1
Deﬁnition of Fan Search
The fan is deﬁned by 4 arguments - radius, θ1, θ2, and origin(the location of the
user) as shown in Fig.4(b). The radius is the maximum distance from the user
OB
OA
OD
OC
User
θC
Pointing direction
θB
The least angle 
difference OC is selected
(a) Ray-based minimum angle
OB
OA
OD
OC
User
Pointing direction
OC in the fan(r, θW )
is selected
r
θW
θ1
θ2
(b) Fan search
Fig. 4. Target selection algorithms

Scalable Interactive Middleware Components for UFC
151
location to the target. θ1 is the start angle in counter clock wise direction. θ2 is
the end angle in counter clock wise direction. The angle of the fan is 0 to 2π.
The target objects residing in the fan are selected as the result of the search.
The target objects are sorted by angle diﬀerence of the pointing direction and
distance from the user location.
Algorithm 1. Fan search pseudo code
if θ1, θ2 span multiple quadrants then
divide the angle from θ1 to θ2 by the piece of quadrants to Ai, i ∈{1, 2, 3, 4} {Ai
denotes the angle in the i’th quadrant}
end if
for all Ai do
calculate MBRs(Minimum Bounding Rectagles)-{Rˆxi}, ˆxi ∈representative value
of x-axis of Ai
add Rˆxi into ListR
end for
merge MBRs -Rˆxi ∈ListR which have same x-axis interval : ˆxi
for all Rˆxi ∈ListR do
lookup target objects by range query Rˆxi in the B+-tree indexed by representative
location.
insert the target object Oi into Queue Qr
end for
for all Oi ∈Qr do
calculate the distance and angle.
if Oi is outside the fan then
remove Oi from Qr
end if
end for
sort the Qr by the angle diﬀerence and distance from O.
return Qr
3.2
Multiple Interval Query Optimization in B+-tree
The localized objects can be indexed by one-dimensional value which can be re-
solved by space ﬁlling curves such as Z-curve, H-curve, and C-curve. Space ﬁlling
curve traverses entire points just once with given sequences. Since H-curve and Z-
curve has good space locality, they are used in spatial queries such as the nearest
neighbor query or k-nearest neighbor query. Most of spatial queries performs rect-
angular region query by region decomposition or approximation with sub-regions.
It is inevitable that this spatial query requires multiple interval queries in trans-
formed address space. If this spatial query is performed in separated queries, it
requires redundant index, leaf node traversals on the given index tree. When data
are distributed sparsely, we can eliminate unnecessary interval query by skipping
the query interval by checking next item in the leaf node.
In order to solve the overhead of separated multiple interval queries over B+-
tree, we adopted traverse path stack and data-aware interval jumps schemes to

152
G. Shim and K.H. Park
O1
O2
O3
O4
O5
O6
22
41
0
4
22
37
B+-tree indexing
41
46
O1
O2
O3
O4
O5
O6
Fig. 5. MBR calculation and B+-tree indexing for target objects
reduce the node traverse overhead. The traversed index nodes in a query are
cached in the memory.
4
Performance Evaluation
In order to verify scalable middleware components, the eﬃcient data indexing
scheme and the query process are evaluated in scales up to hundreds thousands of
data. The latency of implemented our middleware components are evaluated by
Linux PCs. As the number of objects in the space increases, the target selection
or tuple matching operation whould be the most overhead of the processing.
The tuple indexing in time and name will be shown as a scalable and eﬃcient
indexing scheme. The complexity of Fan search is measured by the diﬀerent node
numbers in the same space.
4.1
Tuple Indexing Eﬀect of UbiSpace
The performance characteristics of T-Spaces and UbiSpace are evaluated by
average latency of read and insert operations. The average latency of 100 op-
erations is collected since the latency of one operation is too small to collect.
Each experiment is repeated by 5 times. There are two Linux PCs in the same
rack which take the role of a server and a client machine. The average latency
of read, insert operations is measured between the server and the client. The
latency consists of network packet latency between request and response packet
and query processing time. The read operation ﬁnds the newest tuple which
matches the tuple name. In T-Spaces all of tuples are named by “tuple” and
indexed in string key automatically. In UbiSpace, all tuples are indexed by the
tuple name and sequence ID as a composite key. Fig.6(a) shows the average la-
tency of read operations on T-Spaces and UbiSpace. T-Spaces cannot take the
beneﬁt of tuple indexing for the given tuple matching by name and id. As result,
the read operation scans all of tuples in T-Spaces. This result indicates that the
indexing scheme for tuples should be designed carefully to be scalable for large
number of tuples. On the other hand, UbiSpace index the tuples by name and

Scalable Interactive Middleware Components for UFC
153
(a) Average latency of read operation by
tuple numbers
(b) Average latency of insert operation
by tuple numbers
Fig. 6. Scalability of Ubispace in tuple numbers
id by default, it is scalable for the string key based tuple operations with large
number of tuples in ﬁnding the newest matching tuple.
Fig.6(b) describes the average latency of insert operations on T-Spaces and
UbiSpace. The overall processing consist of pruning, distance and theta calcu-
lation, and Both T-Spaces and UbiSpace update the indexing trees in bounded
complexity. The latency is calculated by average of 100 insertions. UbiSpace has
about 15% less latency than T-Spaces. Since the initial latency is caused by
class loading of JVM, the latency of insertion in 0 tuples are the largest. Most
of reduced time comes from that UbiSpace takes beneﬁts of java object caching
in the Virtual Machine. Because the inserted objects are cached in the client
side, the retrieval of the object can skip the downloading of the cached object
from the server side. Since T-Spaces performs deep copying of tuple object for
persistency, all of the tuple objects should be downloaded from the server.
4.2
Fan Search with Space Filling Curves
Fan search algorithm is primarily designed by C-Curve space ﬁlling curve. In
order to ﬁnd out the relative computing overhead of fan search, we compared
the overall latency of the target selection algorithm with Z-Curve and C-Curve.
Fan search is performed with Z-Curve by single MBR range query over the
given fan. Z-curve is implemented by linear intersection algorithm [15]. Z-curve
should traverse more objects out of the fan due to discontinuity of the Z-curve.
The space has 1km by 1km space. The position of the fan is selected randomly.
The radius is 50 and the angle is 40 to 50 degrees. Each query is repeated
10 times. Fig.7-(a) shows latency of queries over variable node density. In high
node density, Fan search with C-Curve outperforms Z-Curve due to query region
approximation. Z-Curve suﬀers from coarse pruning objects out of the fan due
to single MBR query. However, Fan search with C-curve takes more latency
than Z-curve in low node density, because it has constant MBR calculation and

154
G. Shim and K.H. Park
(a) Latency of diﬀerent node density. In C-Curve with multi-
interval,the path stack and skipping interval optimizations are applied.
0
0.2
0.4
0.6
0.8
1
1.2
Latency(ms)
Pruning
Query
MBR
(b) Computing time of search operations. The number inside () means
the total number of objects.
Fig. 7. Fansearch target selection latency
query overhead. As an implementation optimization, C-Curve with multi interval
shows the eﬀect of the path stack and skipping intervals. However they have less
than 5% improvements and no beneﬁt on high node density.

Scalable Interactive Middleware Components for UFC
155
Fig.7-(b) shows the computing overhead of target selection. The query pro-
cessing consists of query decomposition into MBRs, B+-tree interval queries,
and pruning out of the fan objects. Most of latency comes from the B+-tree
interval queries. As the node density increases, the pruning process takes more
time because the candidate objects are increased. As the node density goes high,
Z-curve suﬀers from false hit on out of objects. Since Z-curve with DRU algo-
rithm [15] has few advantages of interval skips in high node distribution in the
interval query, it requires much computing time in fan query process.
5
Related Works
There are many location based interactive services in the literature such as [11],
[17], and [12]. In Virtual Information Tower, mobile users can interact with
visible items on the advertising columns. VIT provides a metaphor to access
information which is assigned to physical location. In the view of middleware
framework, VIT[11] is very similar to our system by server-client model. How-
ever VIT focuses on frameworks for information management by web-browser
interface of the wearable device.
Juha at el. presented an interactive middleware by gestures.[13]. The target
space is small indoors and no interaction with other users. They focus on the
ﬂexible gesture sets to extend general intuitions for VCR and lighting controls.
Round Eye[17] provides tracking continuous nearest surrounders by NS query.
The NS query is similar to Fan search in query by angle and distance aspects.
NS provides the one possible object for a given angle but Fan search may provide
multiple objects given directions. The NS query is optimized by MBR manage-
ment by considering moving objects in the query region. Round Eye achieves
low computing overhead in the server by query indexing scheme. In other while,
our Fan search tries to minimize given one spatial query by query region decom-
position with C-Curves.
The fan search MBR approximation is similar to that of SCUBA[16]. In
SCUBA, any arbitrary polygonal objects can be approximated by sum of squares
in Z-address. However we designed and implemented the query by diﬀerent C-
Curve not Z-Curve in order to minimize false hits on the interval queries. In
addition, the Z-curve should transform Z-address into x, y Cartesian point with
relatively high computing overhead.
6
Conclusions
Tuple indexing and spatial query are proposed to be scalable middleware compo-
nents in massive environments. The tuples are indexed by composite key to pro-
vide bounded latency on tuple matching with the newest object. Because UbiSpace
manages the tuples by composite keys by default, it can provide scalable comput-
ing overhead in our services. Fan search is proposed to provide distance and angle
queries for target selection. Fan search with C-Curve can provide low latency than
Z-Curve in high node densities. Fan search is optimized in tree traversing by path
stack and data-aware interval skipping. The paper focuses only on the indexing

156
G. Shim and K.H. Park
schemes and query processing. We would research further on the overall system
architecture to support massive environments with network limitations.
References
1. Johanson, B., Fox, A.: The event heap: A coordination infrastructure for interactive
workspaces. In: WMCSA, pp. 83–93. IEEE Computer Society Press, Los Alamitos
(2002)
2. Julien, C., Roman, G.C.: Egospaces: Facilitating rapid development of context-
aware mobile applications. IEEE Transactions on Software Engineering 32(5), 281–
298 (2006)
3. Lee, J., Lim, S.H., Yoo, J.W., Park, K.W., Choi, H.J., Park, K.H.: A Ubiquitous
Fashionable Computer with an i-Throw Device on a Location-based Service Envi-
ronment. In: PCAC (2007)
4. Yoo, J.W., Jeong, Y.W., Song, Y., Lee, J.P., Lim, S.H., Park, K.W., Park, K.H.:
iThrow: A New gesture-based wearable input device with target selection algo-
rithm. In: ICMLC (2007)
5. Shim, G.D., Moon, S.K., Song, Y., Kim, J.S., Park, K.H.: U-Interactive: A Mid-
dleware for Ubiquitous Fashionable Computer to Interact with the Ubiquitous
Environment by Gestures. In: IFIP International Conference on Embedded and
Ubiquitous Computing, pp. 694–705 (2007)
6. Lehman, T.J., Cozzi, A., Xiong, Y., Gottschalk, J., Vasudevan, V., Landis, S.,
Davis, P., Khavar, B., Bowman, P.: Hitting the distributed computing sweet spot
with TSpaces. In: Computing Networks, pp. 457–472 (2001)
7. KAIST UFC Project, http://core.kaist.ac.kr/UFC
8. Freeman, E., Arnold, K., Hupfer, S.: JavaSpaces Principles. In: Patterns, and Prac-
tice (1999)
9. UbiSense, http://www.ubisense.net
10. Want, R., Pering, T., Danneels, G., Kumar, M., Sundar, M., Light, J.: The Personal
Server: Changing the Way We Think about Ubiquitous Computing. In: Borriello,
G., Holmquist, L.E. (eds.) UbiComp 2002. LNCS, vol. 2498, p. 194. Springer, Hei-
delberg (2002)
11. Leonhardi, A., Kubach, U., Rothermel, K., Fritz, A.: Virtual Information Tow-
ers - A Metaphor for Intuitive, Location-Aware Information Access in a Mobile
Environment. In: ISWC (1999)
12. Nakajima, T., Satoh, A.: Software infrastructure for supporting spontaneous and
personalized interaction in home computing environments. Personal Ubiquitous
Comput. 10(6), 379–391 (2006)
13. Kela, J., Korpipaa, P., Mantyjarvi, J., Kallio, S., Savino, G., Jozzo, L., Marca, D.:
Accelerometer-based gesture control for a design environment. Personal Ubiquitous
Comput. 10(5), 285–299 (2006)
14. Silberschatz, A., Korth, H.F., Sudarshan, S.: Database System Concepts, 5th edn.,
pp. 481–500. McGraw-Hill, New York (2006)
15. Skopal, T., Kratky, M., Pokorny, J., Snasel, V.: A new range query algorithm for
Universal B-trees. Elsevier Information Systems 31(6), 489–511 (2006)
16. Hogers, C.: Approximation of arbitrary polygonal objects using space ﬁlling curves
versus a bouding box approach. In: Munich University of Technology Faculty for
Computer Science, Section III Database Systems, Knowledge Bases (2003)
17. Lee, K.C.K., Schiﬀman, J., Zheng, B., Lee, W.C., Leong, H.V.: Round-Eye: A
system for tracking nearest surrounders in moving object environments. Elsevier
Information Systems 80(12), 2063–2076 (2007)

SeDeUse: A Model for Service-Oriented
Computing in Dynamic Environments
Herv´e Paulino and Carlos Tavares
CITI - Departamento de Inform´atica
Faculdade de Ciˆencias e Tecnologia
Universidade Nova de Lisboa
Portugal
herve@di.fct.unl.pt
Abstract. The current state-of-the-art in service-oriented computing
targets mostly business-to-business interaction, as service directories
store business speciﬁc instead of general, abstract, interfaces. Moreover,
the established coordination models were designed to operate mainly
over business processes with immutable, previously known, locations and
tightly couple resource awareness and usage, inhibiting the program-
mer to separate the purpose of the program from its execution environ-
ment. In this paper we present SeDeUSe, a model that features novel
programming abstractions sustained by a middleware layer that hides
the idiosyncrasies of using service-oriented computing in highly dynamic
environments.
Keywords: Service-oriented computing, Middleware for service-oriented
computing, Middleware for mobile computing.
1
Introduction
The increase of networks composed of mobile and pervasive devices, and their
interaction with the Internet, has established these as one of the main driving
forces behind the research on distributed systems, and one of the top priori-
ties of the service-based Internet business market. Nowadays, with the Internet
available everywhere, the possibility of using a service deployed anywhere in the
world is a reality. This fact has highly contributed to the current popularity of
the service-oriented computing (SOC) paradigm.
Services, however, can be used not only to abstract businesses but also to ab-
stract common publicly available resources, such as a network printer. Nonethe-
less, the current state-of-the-art in SOC targets mainly business-to-business
interaction, as service directories store business speciﬁc instead of general, ab-
stract, interfaces. Moreover, the established coordination models, such as service
orchestration [1] and choreography [2], were designed to operate mostly over
business processes with immutable, previously known, locations and tightly cou-
ple resource awareness and usage, inhibiting the programmer to separate the
purpose of the program from its execution environment.
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 157–170, 2009.
c
⃝Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

158
H. Paulino and C. Tavares
Several solutions have been proposed to bridge these limitations [3, 4, 5, 6, 7]
but, in our opinion, it is time to think the problem from scratch and design
programming abstractions custom made for this kind of environment.
In this paper we present SeDeUse, a model that hides the idiosyncrasies of
using SOC in highly dynamic environments, such as the one composed of mo-
bile devices. The model was designed with the service end-user in mind and,
thus, focuses on the proposition of novel intuitive abstractions for service use.
Resource (or service) awareness is completely abstracted from the functional
logic by using the two-level application construction found in policy and aspect-
based approaches [8,9,5,7]. This provides complete resource awareness isolation,
which allows for the deﬁnition of a clean and simple coordination language for
the functional components.
A middleware layer abstracts the user from the dynamic nature of the execu-
tion environment. It resides between the application and the services’ technolo-
gies and provides transparent dynamic discovery, acquisition and management
of services.
As discussed in [10], services and software mobility provide a good execu-
tion environment for today’s networks. This reasoning inspired our middleware
that also supports the migration of computations, providing suitable support
for moving computation away from devices with low computational resources.
The novelty is that the migration is associated to the nature of the services in
use, being completely transparent to the functional logic. This means that the
exactly same functional code can be used in both stationary and mobile settings.
The remainder of the paper is structured as follows: the next two sections
present the state-of-the-art in services and software mobility in dynamic envi-
ronments; section 4 presents the SeDeUse model; section 5 better illustrates the
proposed concepts with a simple programming example; and, ﬁnally, section 6
presents some conclusions and future guiding lines.
2
Service-Oriented Computing in Dynamic Environments
Combining service-oriented with mobile and pervasive computing is a hot re-
search topic that intends to port to dynamic environments the concepts of
service-oriented architectures. However, as said before, services can be used not
only to abstract business services but also to abstract common publicly avail-
able resources, such as a network resource (e.g. a printer) or a sensor (e.g. road
condition information from sensors placed in a highway). This means that re-
source bindings may be ephemerous, thus requiring dynamic reconﬁguration on
the client side.
Although this execution model maps seamlessly in the loosely bound compo-
nents of service-oriented architectures, the porting of SOC to these environments
is not trivial. The state-of-the-art in SOC is mostly targeted at static environ-
ments and the coordination technologies operate over businesses, each with its
own interface and logic. Service directories, such as UDDI [11], are used to store
speciﬁc business interfaces instead of general, abstract, interfaces. For example,

SeDeUse: A Model for SOC in Dynamic Environments
159
every insurance company registers its own speciﬁc interface (a WSDL [12] de-
scription in the usual Web Service technology), even if all of them provide the
same kind of service, This is not the suitable for dynamic reconﬁgurations where
bindings must be done towards abstract interfaces instead of speciﬁc instances.
Some work as already been done in the ﬁeld of service description categoriza-
tion and uniformity. The most known concept is the one of semantic service-
oriented architectures that uses ontologies to upgrade service descriptions with
semantic information. Popular examples of these description languages are OWL-
S [13] and RDF [14]. Although some of these languages have been ported to Java
APIs [15,16] and semantic service discovery can be incorporated in current UDDI
directories [17], no standard APIs have yet aroused.
Regarding service coordination, this has been a research topic for quite some-
time, and technologies such as BPEL [1] are widely used. These, however, were
designed to coordinate business process that resort static bindings to services
and the support for dynamic binding is very limited. The limitations of BPEL
are discussed in detail in [3], a paper that proposes JOpera, a visual composition
language that uses reﬂection to control, from within a composition, the binding
and registry of the services available in the system.
Other approaches, such as WS-Binder [4] and the MASC middleware [5] pro-
vide dynamic binding by associating BPEL service bindings to locally generated
proxies instead of particular service instances. These proxies are responsible for
discovering services on-the-ﬂy and relaying the invocations. The diﬀerence be-
tween both is that WS-Binder uses a graphical interface (the service integrator)
for the user to specify the constrains to impose on a service (QoS or attribute
values) while MASC resorts to policies by extending WS-Policy [18].
Constraints over services can be seen as a cross-cutting concern and thus
the application of aspect-oriented programming (AOP) to this domain came
naturally. Aspects have been proposed to solve several limitations of BPEL.
AO4BPEL [6], for instance, concentrates in the ability to introduce cross-cutting
concerns, such as logging or auditing, and alter the composition logic at runtime,
i.e., use aspects to dynamically add/remove services to/from the process work-
ﬂow. WSML (Web Services Management Layer) [7] provides dynamic selection
and integration of services. Sequence diagrams are used to map abstract in-
terfaces into concrete ones, which requires the deﬁnition of a diagram for each
concrete service interface available. Based on this mappings, a middleware layer
selects among the services currently available the ones to use. Actual interaction
with services is done through a redirection aspect (a stub). Aspects are also used
to deﬁne the non-functional properties of services.
3
Software Mobility in Dynamic Environments
Software mobility has been a research for quite some time now and many ap-
proaches have been proposed. Here we present the systems that are closer to our
work, i.e., that focus on dynamic environments.

160
H. Paulino and C. Tavares
Lime (Linda in Mobile Environments) [19] brings the Linda model [20] to
the world of software mobility in mobile environments. Mobile agents travel
between (possibly) mobile hosts that are seen as roaming boxes which host the
agents, providing them an execution environment. Lime introduces the concept
of transiently shared tuple space to describe a shared tuple space between agents.
The transient concept also applies to hosts and works the same manner. Hosts
on the same network may constitute a federated tuple space.
Poema [8] uses policies to decouple mobility from the remainder functional-
ities. A computational component is divided in three parts: state, application
behavior and mobility behavior. State is the data used or created by the compo-
nent and the application behavior is the deﬁnition of how the application will use
or produce the data. No mobility behavior goes on the application behavior part,
there is complete separation of those concerns. Mobility is deﬁned externally in
a second phase through the use of policies: declarative event-condition-action
rules used to reconﬁgure the application.
Mob [10] is a service-oriented scripting language for programming mobile
agents in distributed systems. The main novelty of the language is the inte-
gration of both the service-oriented and mobile agent paradigms. Services may
be provided transparently by several agents in the network which is especially
important in networks with volatile resources. Agents may be simultaneously
clients and servers, creating a more ﬂexible framework for implementing dis-
tributed applications. The downside is that the language uses its own interfaces
to specify services instead of standard technologies, such as Web services.
4
The SeDeUse Model
The SeDeUse model intends to hide the idiosyncrasies of using SOC in dynamic
environments by proposing a set of intuitive programming abstractions sustained
by a middleware layer that lives between the application and the standard service
technologies.
The programming model follows the two-layer approach to software construc-
tion that can be found in most of the systems discussed in the previous section
(WS-Binder, MASC, Poema, and the AOP based approaches). This allows to
separate service usage (functionality) from awareness (non-functionality). The
two layers of SeDeUse are:
– The service awareness layer (SAL) that deﬁnes the kinds of services to be
used in the application, i.e., the services to be discovered in the network and
the criterias that each of these must obey. We denote as kind the constraining
of a service interface with a set of speciﬁc properties.
– The service use layer (SUL) that deﬁnes a simple coordination model,
orthogonal relatively to the common existing programming languages (as is
the Linda model [20]).
The model does not deﬁne a complete language and, thus, must rely on a
hosting language to perform computation and to interact with the middleware

SeDeUse: A Model for SOC in Dynamic Environments
161
SAL
Components
SUL
Components
Pre-processor
Hosting
Language
Compiler
Generated
Code
Code Implemented in the
Hosting Language
references
Run-time Libraries 
Implementing the
Middleware
references
Fig. 1. The compilation process
layer. As such, a pre-processing stage is required to generate code of the hosting
language, which is then compiled by the language’s own compiler, as illustrated
in ﬁgure 1.
The generated code will naturally resort to the run-time middleware libraries
that provide for service discovery based on structure and content, dynamic re-
conﬁguration of the service bindings, transparent process mobility and failure
recovery.
In the remainder of this section we will present both layers of the model in
an informal manner.
4.1
Service Awareness Layer
The syntax for both SAL and SUL relies on the identiﬁers and values deﬁned in
table 1. We denote a sequence of zero or more elements of a given category γ by
˜γ, an empty sequence by ϵ and an optional symbol or production by the usual
[ ] notation.
Table 1. Values and identiﬁers
s, r
Service identiﬁer
o
Service operation identiﬁer
a
Variable identiﬁer
t
Type identiﬁers of the hosting language
x
Exception identiﬁers of the hosting language
v
Values of the hosting language
As illustrated in table 2, the SAL is composed by a sequence of service
kind declarations. A kind is deﬁned by a service interface identiﬁer and a set
of attribute-value associations. The former deﬁnes the key for discovering the
service in the available repositories, while the later narrow the search space by

162
H. Paulino and C. Tavares
Table 2. Syntax of declarative components
D
::=
D D
Sequence of declarations
|
s { ˜A }
Service kind declaration
|
s { ˜A } alias r
Service kind declaration with alias
A
::=
[pref] a = v
Attribute constraint
|
[pref] a in { v1, v2, . . . , vn }
Attribute soft constraint
imposing constraints on the service’s attributes. These constraints may be hard,
deﬁned by a single value (the = operator), or soft, allowing the attribute to
range over a set of values (the in operator). It is also possbile to declare them
as simple preferences by using the pref keyword.
Aliases are introduced to avoid name clashing when requiring distinct kinds
of the same service. These aliases are service identiﬁers and thus can be used
both in the SAL and the SUL. To better illustrate these concepts we introduce
a small example.
Consider a service interface Printer that deﬁnes a printing service that features
attributes type, colors and paper, among others. We have, on the listing 1, the
deﬁnition of a printer that prints in black and white on letter paper and, on
listing 2, the deﬁnition of a second printer that prints in color on A4 paper. The
conjunction of a SUL with one of these printer declarations will produce diﬀerent
results, although the program is always the same. Recall that the declaration of
the attributes of the Printer service does not deﬁne a concrete printer, but rather
a printer kind.
Listing 1. A printer
P r i n t e r
{
c o l o r s = ” blackandwhite ” ,
paper = ” l e t t e r ”
}
Listing 2. Another printer
P r i n t e r
{
c o l o r s = ” c o l o r ” ,
paper = ”a4”
}
Many kinds of printers can be used in a single program. In order to distinguish
between them we must resort to aliases, as in the listing 3. The ColorPrinter iden-
tiﬁer stands for a service Printer with the speciﬁed attributes. ColorLaserPrinter
further constrains the scope of the search by deﬁning the type attribute of Col-
orPrinter as one of laser or ink jet.
Listing 3. More printer type deﬁnitions
P r i n t e r
{
c o l o r s = ” c o l o r ” ,
paper = ”a4” }
C o l o r P r i n t e r
C o l o r P r i n t e r
{ type
i n
{” l a s e r ” ,
” i n k
j e t ”} }
C o l o r L a s e r P r i n t e r
4.2
Service Usage Layer
At this level the purpose is to provide good programming abstractions and a
simple coordination model, in order to delegate computation in network services.
The syntax for this layer is deﬁned in table 3.

SeDeUse: A Model for SOC in Dynamic Environments
163
Table 3. Syntax of functional components
P
::=
use ˜S in c(˜a) P ˜X
Service use abstraction
|
P | P
Parallel composition
|
P ; P
Sequential composition
|
{ P }
Grouping
|
[a =] E
Assignment
|
retry in e
Restart a transaction
|
˜i
Hosting language process
E
::=
new c(˜e)
An instance of an use abstraction
|
s.o( ˜E)
|
s[e].o( ˜E)
Method invocation
|
e
Hosting language expression
S
::=
[volatile] E s
|
[volatile] all s
Service allocation
X
::=
catch (x a) { P }
Exception handling
Deﬁning Computations: Actual computation is performed by processes (se-
quences of instructions) of the hosting language or by external services. Processes
can be parallelly or sequentially composed1. For each parallel composition P | P ′
a new thread is created to execute the rightmost process. The ; operator deﬁnes
a synchronization point, guaranteeing that all threads spawned from the cur-
rent execution ﬂow have terminated their execution. An example is illustrated
in ﬁgure 2.
Fig. 2. Execution ﬂow for {{ P1 | P2 } ; P3 } | P4
Using services: Regarding process abstraction and service usage, the syntax bor-
rows many constructions from the Object-Oriented languages: the use construct
abstracts computation in a set of parameters much like a class; instances of such
abstractions are created by the new construct, that binds the parameters of
the abstraction to the values supplied as arguments, and; service operations are
invoked as methods upon objects.
The novelty regarding computation abstraction is that the use construct al-
lows for code to be also abstracted in service identiﬁers and that these are bound
transparently, and on-the-ﬂy, whenever an instance is created. Once bound, these
identiﬁers can be target of service operation invocations within the abstracted
code. For example, the value for the parameter doc in listing 4 is passed in the
1 Regarding parallel composition we borrowed the syntax behind some process alge-
bras, such as the π-calculus [21].

164
H. Paulino and C. Tavares
constructor, while the binding for service parameter Printer is obtained trans-
parently by the middleware.
Listing 4. Using a service
use
P r i n t e r
i n
MyPrinter ( doc ) {
P r i n t e r . p r i n t ( doc )
}
new
MyPrinter ( ‘ ‘ myDocument ’ ’ )
The pre-processor translates a use abstraction into a hosting language ab-
straction (e.g. a class in Java or C#). The constructor of this class will access
the middleware to obtain instances of the required services. For a given service
kind the procedure is as is illustrated in ﬁgure 3 and described below:
1. The program queries the middleware to obtain a service matching the Printer
kind.
2. Check if a proxy for the service interface exists2 (i.e. has already been gen-
erated)
– If so, this proxy has access to the middleware’s cache of previously discov-
ered services. Look up this cache and check if any of the stored services
is still available in the network.
- If so, return this service.
- If not, proceed to point 3.
– If not, proceed to point 3.
3. Perform a search on the available service repositories. Remember that this
discovery must obey the criterias deﬁned in the SAL.
4. Analyse the outcome of the search:
– If no service is found issue an exception.
– If a service is found proceed to point 5.
5. Check if proxies for the retrieved services have already been generated. This
step is required because proxies depend on the invocation technology sup-
ported by the server. For instance, the server may only support SOAP 1.1
and the middleware may only have generated a proxy that uses SOAP 2.0.
In this case a proxy using SOAP 1.1 would be generated.
6. Store the retrieved services in the cache.
Another feature provided by use is the ability to easily bind to distinct ser-
vices of a given kind. This is useful to load balance service requests or even to
synchronize data between service providers. In the code these services are ac-
cessed as an array, as is illustrated in listing 5 that uses two services of kind
SearchEngine.
Listing 5. Using several instances of a service
use 2
SearchEngine
i n
Search ( query ) {
SearchEngine [ 0 ] . s ea r ch ( query )
|
SearchEngine [ 1 ] . s ea r ch ( query )
}
2 Proxies are bound to service interfaces in general, this means that distinct kinds of
the same service interface use the same proxy.

SeDeUse: A Model for SOC in Dynamic Environments
165
Middleware
new MyPrinter("myDocument")
(1) Obtain service of kind Printer
Service
directory
Service
directory
Service
directory
(3) Discover
 service of kind 
Printer
Cache
(2) Proxy 
available?
Proxy
Query
cache
Return 
available
instance 
Yes
No
No available
service found
Result
(4) Found services?
(5) Generate proxy
if necessary
(6) Place services 
in cache
Yes
Issue exception
No
Fig. 3. Obtaining instances of a service kind
This feature raises the problem of issuing an exception whenever the number
of requested services is not available. To avoid this behavior, the value supplied
does not deﬁne the exact number of services to retrieve, but rather the upper
bound. This is a design choice that, in our opinion, provides a more ﬂexible
semantics desired for dynamic environments. To ensure that no out-of-bounds
exceptions occur, indexes are always converted to values between 0 and the
number of services available.
Often one wants the code to be agnostic regarding the number of services
currently in use, i.e., omit the index and simply invoke operation regardless of the
target. This is possible in SeDeUse because s.o(˜e) in fact stands for s[i++].o(˜e),
where i is an integer initialized with 0. Therefore, when more than one instance
of a required kind is available, the service identiﬁer ranges the instances using a
round-robin strategy.
The abstractions presented until now allow for the simple deﬁnition parallel
ﬂows of execution that may access distinct services of the same kind in the
network, and thus increase resource usage eﬃciency. for example in the listing
6 two search operations are done in parallel both in the client, since two ﬂows
of execution are deﬁned, and also (possibly) in the server side, since probably
more then one instance of SearchEngine is being transparently used.

166
H. Paulino and C. Tavares
Listing 6. Using several instances of a service transparently
use 2
SearchEngine
i n
Search ( query ) {
SearchEngine . s ea r ch ( query )
|
SearchEngine . s ea r ch ( query )
}
Failure recovery: SeDeUse features an exception handling mechanism that is
syntactically similar to the one found in Java [22]. This mechanism is used to
protect the code inside a use against broken service bindings. If the discovery
or the invocation of one of the required kinds fails the exception is raised. The
diﬀerence from the usual exception handling mechanisms is that here the scope
of the protection is not the delimited code, but rather the use of the services
required by the instance of use.
Consider the code in listing 7, once the setPrinter method invocation is ex-
ecuted the code in the use terminates. The service, however, is probably still
being used by vpc and while this is true the handler will be active, thus avoiding
duplicating exception handling code.
Listing 7. Handling exceptions
use
P r i n t e r
i n
V i r t u a l P r i n t e r ( VirtualPC
vpc ) {
vpc . s e t P r i n t e r ( P r i n t e r ) ;
}
catch
( Ser vi ceE xc e p t i o n
e ) {
vpc . u n s e t P r i n t e r ( ) ;
}
The code delimited by a use can be seen as a transaction. If an exception is
raised the transaction can be restarted with retry. The instruction restarts the
discovery procedure, eliminating the existing instance from the middleware’s
cache.
When the invocation of a service operation does not depend on any of the
previous there is no notion of state. In fact, the code could be decomposed in
several uses as in listing 9. In this case, use does not deﬁne a transaction but
simply the scope of the service kinds required, and so, the search for a new service
can be done without forcing the transaction to restart. This feature is supported
in SeDeUse by the qualifying the required kinds with the volatile keywork, as
shown in listing 9.
Listing 8. Decomposing a use
use
S e r v i c e
i n
Abs ( )
{
S e r v i c e . op1 ( )
}
use
S e r v i c e
i n
Abs ( )
{
S e r v i c e . op2 ( )
}
Listing 9. Using the volatile key-
word
use
v o l a t i l e
S e r v i c e
i n
Abs ( )
{
S e r v i c e . op1 ( ) ;
S e r v i c e . op2 ( )
}
Handling Software Mobility: It is not our intention to explicitly refer to mobility.
The program is not explicitly ordered to visit a certain host, as is common in

SeDeUse: A Model for SOC in Dynamic Environments
167
mobile agent systems [10,23,24]. It is the nature of the services it requires that
will deﬁne its location. A special attribute (@) allows the programmer to state if
a given resource must be, or should be, either local or remote to the computation
and to the device itself. Of course that this migration can only happen if the
target host is willing to accept the incoming code. The odd identiﬁer prevents
name clashes with existing attribute identiﬁers.
The values of the attribute may range from: local, to ensure that the resource
is local to the device, remote, to ensure the opposite; coupled, to ensure that the
resource is local to the computation (not the device), closest, to state that the
resource and the computation must as close as possible, and; performance, to
delegate in the system the choice of the best instance regarding performance.
When a new instance is created and the service bindings solved, the instance
is passed to the middleware that, according to the criterias chosen and the will-
ingness of the servers, decides where the execution takes place. Remote execution
may require proxies to be created on the server side and, more important, some
services may not be reachable from the new location. This will trigger a new
discovery procedure and possibly an exception.
5
Programming Example
We now present a simple programming example to better illustrate the concepts
and the capabilities of our model. We ﬁrst need to choose a hosting language, in
order to have completeness. Our choice falls on Java, since it is a widely known
language.
Our example is an operating system shell that enables a small portable device
to use existing resources in a local network to perform computation, display
its desktop environment and print documents. With this application the device
can simply serve as an interface between the user and the actual computational
resources it is using. In listing 10 we show how SeDeUse can be used to manage
the bindings of application.
We choose to associate state to the CPU service to simulate a remote shell
session. Thus, lines 29 to 47 are seen as a transaction. If no CPU service is found
or the connectivity is lost, the exception handling code is trigerred and the user
may decide to search for a new CPU (we assume the existence of classes Question
and Info that, respectively query and inform the user).
The actual code of the transaction creates an object instance of a local class
that manages the availability of the printer and display resources, instances of
VirtualPrinter and VirtualDisplay, respectively.
VirtualPrinter (lines 1 to 7) is responsible for discovering printers in the net-
work, making one available to the user whenever it is possible. Note that the
service is volatile, thus as long as printers are available no exception is raised.
The user is notiﬁed every time printers are made available or not.
VirtualDisplay (lines 9 to 27) discovers the displays available in the network
prompting the user if it must continue the search of keep the last service found.
If the connectivity to the display in use is lost, the application resorts only the
local display and restarts the discovery procedure.

168
H. Paulino and C. Tavares
Listing 10. A virtual PC - SUL layer
1
use
v o l a t i l e
P r i n t e r
i n
V i r t u a l P r i n t e r ( Vi rtual PC vpc ,
i n t
minutes ) {
2
vpc . s e t P r i n t e r ( P r i n t e r ) ;
3
}
4
catch
( S e r v i c e E x c e p t i o n e ) {
5
vpc . u n s e t P r i n t e r ()
;
6
r e t r y
i n
minutes ;
7
}
8
9
use
Di spl ay
i n
V i r t u a l D i s p l a y ( Vi rtual PC vpc ,
i n t
minutes ,
boolean
se arc h ) {
10
Question
q = new Question ( ”Found new
d i s p l a y :
” + Di spl ay . g e t I n f o () + ” .
Keep?” ) ;
11
i f
( q . getBool ( ) )
12
vpc . s e t D i s p l a y ( Di spl ay ) ;
13
}
14
catch
( S e r v i c e E x c e p t i o n e ) {
15
i f
( se arc h ) {
16
new
I n f o ( ” S wi tc hi ng
to
l o c a l
d i s p l a y
f o r
now .
Pe rformi ng
s e a r c h e s
p e r i o d i c a l l y ” ) ;
17
r e t r y
i n
minutes ;
18
}
19
e l s e {
20
Question
q = new Question ( ”Remote
d i s p l a y
not
a v a i l a b l e .
Want to
se arc h
f o r
a new one ?” ) ;
21
i f
( se arc h = q . getBool ( ) ) {
22
new
I n f o ( ” S wi tc hi ng
to
l o c a l
d i s p l a y
whi l e
pe rformi ng
se arc h ” )
|
23
r e t r y
i n
0;
24
}
25
}
26
}
27
28
use CPU i n
Vi rtu al PC () {
29
c l a s s
Vi rtu al PC (CPU c ) {
30
CPU c ;
31
P r i n t e r
p ;
32
Di spl ay
d ;
33
34
s e t P r i n t e r ( P r i n t e r
p ) {
35
t h i s . p = p ;
36
new
I n f o ( ” P r i n t e r
” + p . g e t I d () + ”
a v a i l a b l e ” ) ;
37
}
38
u n s e t P r i n t e r () {
39
t h i s . p = n u l l ;
40
new
I n f o ( ” P r i n t e r
not
a v a i l a b l e ” ) ;
41
}
42
s e t D i s p l a y ( Di spl ay
d ,
boolean
l o c a l ) { t h i s . d = d ; }
43
. . .
44
}
45
Vi rtu al PC
vpc = new
Vi rtual PC (CPU)
|
46
new
V i r t u a l D i s p l a y ( vpc ,
10 ,
f a l s e )
|
47
new
V i r t u a l P r i n t e r ( vpc ,
10)
48
}
49
catch
( S e r v i c e E x c e p t i o n e ) {
50
Question
q = new Question ( ”CPU
s e r v i c e
not
a v a i l a b l e .
Want to
se arc h
f o r
a new one?” ) ;
51
i f
( q . getBool ( ) ) {
52
r e t r y
i n
0;
53
}
54
}
55
new Vi rtu al PC ( ) ;
Listing 11. A virtual PC - SAL layer
P r i n t e r { @ = ” c l o s e s t ” }
Di spl ay { type = ”TFT” }
CPU { p r o c e s s o r
i n {I n t e l , AMD}, @ = ” c ou p l e d” }
In listing 11 we deﬁne a simple SAL to deﬁne the CPU, Display and Printer
kinds.
6
Conclusions and Future Work
The service-oriented computing paradigm provides the ideal framework for re-
source abstraction, since resources can be modelled as services. However, the
current state-of-the-art does not handle adequately the porting of these software
architectures to dynamic environments.
Some approaches have been proposed to cope with these limitations, but they
feel more like patches than real solutions. Our approach is to back to the foun-
dations and design a model that is tailored to use services in this context. The

SeDeUse: A Model for SOC in Dynamic Environments
169
SeDeUse model features novel abstractions that are simple and orthogonal rela-
tively to the common existing programming languages. It features two layers that
separate service usage from awareness and that must be combined to generate
the ﬁnal code to execute.
In order to move computation away from devices with low computational re-
sources, SeDeUse uses a special service attribute that provides complete trans-
parent software mobility to the functional components. Thus, mobility is no
longer coupled with computation. The exactly same functional code can be used
in both stationary and mobile settings. It all depends on the restrictions applied
to the services (resources).
The expressiveness and capabilities of the model were illustrated in a simple
example, by resorting to Java, as the hosting language. In our opinion, the model
provides a good framework for the development of distributed and mobile soft-
ware. In turn, the loosely-bound properties of service-oriented computing, plus
the ability to migrate computation provides a good support for the deployment
of applications in highly dynamic environments, such as the ones composed of
mobile devices.
Ongoing work focuses on the actual implementation of the model, using Java
as the hosting language. The middleware will resort to the language’s native
code mobility support and the APIs available for service discovery and usage,
namely for UDDI interaction and SOAP based communication.
References
1. Chen, L., Wassermann, B., Emmerich, W., Foster, H.: Web service orchestration
with bpel. In: ICSE 2006: Proceeding of the 28th international conference on Soft-
ware engineering, pp. 1071–1072. ACM, New York (2006)
2. Yang, H., Zhao, X., Qiu, Z., Pu, G., Wang, S.: A formal model for web service
choreography description language (ws-cdl). In: IEEE International Conference on
Web Services 2006, pp. 893–894. IEEE Computer Society, Los Alamitos (2006)
3. Pautasso, C., Heinis, T., Alonso, G.: Jopera: Autonomic service orchestration.
IEEE Data Engineering Bulletin 29 (2006)
4. Penta, M.D., Esposito, R., Villani, M.L., Codato, R., Colombo, M., Nitto, E.D.:
Ws binder: a framework to enable dynamic binding of composite web services. In:
SOSE 2006: Proceedings of the 2006 international workshop on Service-oriented
software engineering, pp. 74–80. ACM, New York (2006)
5. Erradi, A., Maheshwari, P.: Dynamic binding framework for adaptive web services.
In: ICIW 2008: Proceedings of the 2008 Third International Conference on Inter-
net and Web Applications and Services, pp. 162–167. IEEE Computer Society,
Washington (2008)
6. Charﬁ, A., Mezini, M.: Ao4bpel: An aspect-oriented extension to bpel. World Wide
Web 10(3), 309–344 (2007)
7. Verheecke, B., Cibr´an, M.A., Vanderperren, W., Suv´ee, D., Jonckers, V.: Aop
for dynamic conﬁguration and management of web services. Int. J. Web Service
Res. 1(3), 25–41 (2004)
8. Montanari, R., Lupu, E., Stefanelli, C.: Policy-based dynamic reconﬁguration of
mobile-code applications. Computer 37(7), 73–80 (2004)

170
H. Paulino and C. Tavares
9. Talcott, C.L.: Policy-based coordination in pagoda: A case study. Electronic Notes
Theoretical Computer Science 181, 97–112 (2007)
10. Paulino, H., Lopes, L.: A programming language for service-oriented computing
with mobile agents. Software Practice and Experience 38(7), 705–734 (2008)
11. Bellwood, T., et al.: Uddi version 3.0.2, http://uddi.org/pubs/uddi_v3.htm
12. Web Services Description Language (WSDL), http://www.w3.org/TR/wsdl
13. OWL-S: Semantic Markup for Web Services,
http://www.w3.org/Submission/OWL-S/
14. Resource Description Framework (RDF), http://www.w3.org/RDF/
15. McBride, B.: Jena: Implementing the rdf model and syntax speciﬁcation. In:
SemWeb (2001)
16. JRDF (Java RDF), http://jrdf.sourceforge.net/
17. Paolucci, M., Kawamura, T., Payne, T.R., Sycara, K.P.: Importing the seman-
tic web in UDDI. In: Bussler, C.J., McIlraith, S.A., Orlowska, M.E., Pernici, B.,
Yang, J. (eds.) CAISE 2002/WES 2002. LNCS, vol. 2512, pp. 225–236. Springer,
Heidelberg (2002)
18. Bajaj, S., Box, D., Chappell, D., Curbera, F., Daniels, G., Hallam-Baker, P.,
Hondo, M., Kaler, C., Langworthy, D., Nadalin, A., Nagaratnam, N., Prafullchan-
dra, H., von Riegen, C., Roth, D., Schlimmer, J., Sharp, C., Shewchuk, J.,
Vedamuthu, A., Yal¸cinalp, U., Orchard, D.: Web services policy 1.2 - framework
(ws-policy). Technical report, W3C (2006)
19. Murphy, A.L., Picco, G.P., Roman, G.C.: Lime: A coordination model and
middleware supporting mobility of hosts and agents. ACM Trans. Softw. Eng.
Methodol. 15(3), 279–328 (2006)
20. Gelernter, D.: Generative communication in linda. ACM Trans. Program. Lang.
Syst. 7(1), 80–112 (1985)
21. Milner, R., Parrow, J., Walker, D.: A Calculus of Mobile Processes (parts I and
II). Information and Computation 100(1), 1–77 (1992)
22. Sun Microsystems, Inc.: Java tutorial,
http://java.sun.com/docs/books/tutorial/
23. Lange, D.B., Oshima, M.: Programming and Deploying Java Mobile Agents with
Aglets. Addison-Wesley, Reading (1998)
24. Glass, G.: Objectspace voyager - the agent orb for java. In: Masunaga, Y.,
Tsukamoto, M. (eds.) WWCA 1998. LNCS, vol. 1368, pp. 38–55. Springer, Heidel-
berg (1998)

The Contextual Map - A Context Model for
Detecting Aﬃnity between Contexts
Robert Schmohl and Uwe Baumgarten
Institut f¨ur Informatik, Technische Universit¨at M¨unchen
Garching bei M¨unchen, Germany
schmohl@in.tum.de, baumgaru@in.tum.de
Abstract. Context-awareness represents an important research domain
in mobile computing by utilizing information about persons, places and
objects anytime and anywhere. The highly dynamic contexts created by
this paradigm raise questions how to eﬃciently determine alikeness and
aﬃnity between such contexts. Inspired by mechanisms from location-
aware computing, we tackle the issue of contextual proximity by con-
structing an n-dimensional map-model, which serves as a context model
for regular context repositories. This Contextual Map enables us to store
non-location contexts in a map-based way. Further, this model enables us
to conduct location-based n-dimensional proximity detection on the non-
location contexts, hence giving us the possibility to determine contextual
proximity. This paper introduces the contextual map model, describing
how principles from the location-based service domain can be leveraged
on general context-aware computing and how they can be employed to
detect aﬃnities between diﬀerent contexts.
Keywords: Context-aware computing, contextual aﬃnities, contextual
boundaries, proximity detection.
1
Introduction
Context-aware computing focusses on utilizing any information describing the
current context of an entity, which may be a place, a person, an object, etc. In
practice, this information comprises of the situation and possible actions of the
entity, derived from its current surrounding, which is captured by sensors of de-
vices associated with the entity, or the infrastructure hosting such devices [1,3].
To store and exploit such contextual information, context-aware systems uti-
lize sophisticated context models. Those models represent the context captured
from the real-world in a way suitable for further processing, such as identifying
contextual coherences and inferring new context.
Context-awareness is applicable in numerous application domains. Especially
the utilization of mobile devices emphasizes the exploitation of the highly dy-
namic environment in which mobile hosts usually roam. However, providing in-
formation about the most current context to mobile applications is an elaborate
eﬀort. For this reason, context-aware systems are usually middleware solutions
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 171–184, 2009.
c
⃝Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

172
R. Schmohl and U. Baumgarten
capable of acquiring and managing contextual data autonomously, hence pro-
viding the resultant context to high-level applications via a dedicated interface.
In order to identify similarities among individual entities’ contexts we employ
techniques known from location-based computing. Although exhibiting a high
degree of specialization, map-based location models yield principles, which can
be applied to conventional context-aware computing as well. We have discovered
that the principle of proximity in the location domain can be applied to face
certain aspects of context-awareness, too. The geographical proximity in the
location domain expresses that entities are close to each other. By projecting
this setting on more general contexts, contextual proximity may express that
contexts are alike or aﬃne, hence “close” to each other.
This approach has yielded the conceptualization of the contextual map model,
abstracting contextual information into an n-dimensional map, thus assigning
each piece of context a position in this map. Since this context model represents
contextual information in a n-dimensional cartesian map model, it allows the ap-
plication of mechanisms known from location-aware computing on non-location
contextual information.
For the identiﬁcation of contextual proximity, we calculate the Euclidean dis-
tance between n-dimensional contexts to determine their degree of alikeness, such
as we would calculate the distance between locations of objects in 3-dimensional
space. In our approach, we deﬁne context boundaries as the degree of alikeness be-
tween diﬀerent contexts. More precisely, we monitor dynamic aﬃnities between
pieces of context according to their changing distances to each other in the con-
textual map. Those distances allow us to determine, whether context boundaries
have been crossed, hence whether contexts become more aﬃne (converging) or
less aﬃne (separating). Figure 1 sketches the idea behind the contextual map.
A
Context of A
B
Context of B
A
B
Real World Contexts
Contexts in Contextual Map
Contextual Proximity
Fig. 1. Contexts in the Contextual Map
This paper explores the application possibilities of the contextual map model
as a middleware solution on mobile hosts. Section 2 enumerates the work related
to our project. Section 3 introduces the principles from the domains of location-
and context-awareness, that we base our work on. With this information given,
we introduce our contextual map model in section 4. Section 5 explains, how the
contextual map is employed to monitor aﬃnity between contexts and how this is
related to contextual boundaries. Subsequently, section 6 summarizes the overall

The Contextual Map - A Context Model for Detecting Aﬃnity
173
workﬂow of employing the contextual map model before the paper is concluded
in section 7, giving an outlook on the enhancements of the approaches presented
here.
2
Related Work
Prior to the conceptualization of the work presented here, we have surveyed
the domain of context-aware computing deriving an architecture that allows a
generalized view on the domain [10]. Here, we are presenting a novel concept of
a context model exploiting principles of the location-aware computing domain.
Since it is quite specialized in nature, it is to be regarded supplemental to well
proven context models [12], such as ontologies [1,2,4,5].
Proximity and separation detection allows the deﬁnition and utilization of
context boundaries when employed with the contextual map model. Such con-
text boundaries deﬁne distances between contexts in the contextual map hence
specifying degrees of aﬃnity between those contexts. Roman et. al [9] have con-
ducted similar work by deﬁning thresholds where exceeding of those thresholds
equals crossing of such boundaries. Proximity and separation detection, as pre-
sented by K¨upper and Treu [7], requires frequent location updates of the involved
mobile hosts. Besides the common update semantics including polling, periodic
updates, distance- and zone-based updates, there is a common endeavor on de-
signing update semantics, which minimize the amount of updates while keeping
the location of the target as current as possible [7,6]. K¨upper and Treu present
eﬃcient ways to achieve this objective by employing sophisticated algorithms
with circular and strip-like update zones in 2-dimensional space.
A notable alternative to our work is depicted by the theory of context spaces
introduced by Padovitz et al. [8]. As the contextual map, context spaces aim at
the multi-dimensional representation of contextual attributes. Multi-dimensional
context spaces are partitioned into regions denoting bounds of speciﬁc contextual
situations. Concrete context states mapped from real world entities are then
associated to such context regions according to their proximity in the context
space.
3
Background
3.1
Context-Aware Computing
Context-aware systems usually build upon the following fundamental workﬂow
visualized in ﬁgure 2. They capture information about their surrounding from
context sources, such as sensors, the network infrastructure, auxiliary software,
etc. Subsequently, this information is reﬁned by relating this information to the
context in question. This task is usually performed by a dedicated component,
namely the context capturing interface. The resultant contextual information is
stored in context models. Inference engines use this data to derive new contex-
tual information according to application-speciﬁc rules. The data derived at the

174
R. Schmohl and U. Baumgarten
Context Application
Context API
Context Repository
Inference Engine
Inferencing
Rules
Context Capturing Interface
Context Sensors
Planning Level
Application Level
Reasoning Level
Syntactical Level
Lexical Level
Context Sources
Fig. 2. Architectural Draft for context-aware computing
end of this process is made available by context APIs to any application utiliz-
ing the most current context. As stated, ﬁgure 2 shows a generic architecture
utilizing this workﬂow [10]. In summary, the context API provides transparent
access to a context-aware middleware, which utilizes all contextual data from
the attached context sources autonomously. This approach facilitates the devel-
opment of context-aware application and enables portability of a context-aware
system.
3.2
Proximity and Separation Detection in 2-Space
The detection of mobile entities approximating or departing each other depicts
important application cases for location-based services [7]. As with all of the
services implying location, proximity and separation detection requires frequent
location updates of the involved mobile hosts. Based upon the location commit-
ted by the targets, proximity or separation can be detected. There are four basic
mechanisms on how to trigger a location update [7]: polling, periodic updates,
zone-based updates and distance-based updates.
A common endeavor on designing update semantics is the minimization of the
amount of updates while keeping the location of the target as current as possi-
ble [7,6]. There are two eﬃcient ways to achieve this objective in combination
with detecting proximity or separation of mobile entities [7]. Both conduct the
detection mechanism following a mobile entity’s location update, which work as
followed. The ﬁrst approach is based on circular areas centered around mobile
hosts. Location updates are committed upon leaving those areas. Proximity and
separation are detected upon calculating the smallest (proximity) and largest
(separation) possible distances, which both depend on the circles’ radii. The sec-
ond approach focuses on deﬁning an orthogonal strip between two mobile entities

The Contextual Map - A Context Model for Detecting Aﬃnity
175
smallest possible distance
largest possible distance
update zone
update zone
update zone  (proximity)
update zone (separation)
mobile node
last known position
Fig. 3. Proximity and separation detection
and spanning a circle around the center of the line between them. Proximity is
detected upon a location update triggered by one of the targets entering the
strip. Separation detection is conducted after a location update committed by a
target leaving the circular zone. Figure 3 illustrates both approaches.
4
The Contextual Map Model
In this section we introduce the contextual map model for storing contextual
information in a context repository, as depicted in ﬁgure 2. After presenting
the model’s structural characteristics we focus on how contextual information is
mapped into this model. To improve the reader’s understanding, we are going to
illustrate the working principle of the contextual map by employing an example,
which exploits the context of a weather station.
4.1
Composition
The key idea of the contextual map model is to represent the context of entities
in an n-dimensional realm. The context of a single entity corresponds to a single
entry in the contextual map. Such an entry is composed of n coordinates and
hence can be interpreted as a position in the map. Referring to our example,
the context of our weather station denotes the current weather conditions at a
speciﬁc location. Its context represents a single position in the contextual map,
whereas the context of another weather station denotes another map position.
An entity’s context, captured by various context sensors, is mapped into the n
dimensions of the contextual map by employing a particular mapping function.
We are going to sketch such a function in the subsequent section 4.2. After
mapping the information into the contextual map, the entity’s current context
is represented by n coordinates inside the map. Analogously, one can imagine a 3-
dimensional map of space, which is employed to represent the location of entities

176
R. Schmohl and U. Baumgarten
in space. We extend this 3-dimensional model by adding additional dimensions,
in order to include further contextual information other than location. Finally,
each dimension corresponds to an elementary contextual attribute of a complete
piece of context. In the contextual map, a single dimension is the smallest unit
of context representation.
To further augment our model, we allow the contextual map to be partitioned
into ranges. A range groups the map’s dimensions, which share typological sim-
ilarities. For instance, our weather station’s location is a piece of context, de-
composing into three subordinate building blocks corresponding to the location’s
cartesian coordinates. In the contextual map, three dimensions can be dedicated
for coordinate representation, grouping them to one range dedicated to the rep-
resentation of locations. Since the weather station’s context includes more than
merely its location, additional ranges must be included. E.g., an additional range
may include the station’s environmental readings with a single dimension being
dedicated to each sensor (e.g. temperature, humidity, etc.). Table 1 sketches this
example.
The dimensions in the contextual map may be regarded as its axes, requiring
well deﬁned units of representation. The choice of those is virtually unrestricted
as long as it ﬁts the contextual attribute, which it is supposed to represent. How-
ever, within ranges units have to be uniform spawning a d-dimensional cartesian
coordinate system for each range with d being the amount of the range’s dimen-
sions. E.g., the dimensions of the weather station’s location range all need to be
deﬁned in kilometers, whereas all of the environment range’s dimensions have to
be deﬁned in a uniform way representing the particular weather condition (see
table 1). This is necessary to enable eﬃcient detection of contextual aﬃnity as
discussed later in section 5.
The n-dimensional representation of an entity’s context in the map is atomic
and thus exploitable for further analysis. Changes of its context can alter the
contextual correlation to other entities in regard to contextual boundaries. Since
contextual boundaries usually deﬁne the scope of similar context, we can employ
mechanisms known from 2- or 3-dimensional map models to detect proximity
among contexts inside the contextual map, hence identifying contextual aﬃnities
by identifying proximate context, as explained later on in section 5.
4.2
Context Mapping
Based on the context model introduced in the previous section 4.1, it remains
to be clariﬁed how contextual information is mapped into the contextual map.
The basic approach is to employ a mapping function, which inputs quantiﬁed
contextual data from according context sources and maps them to cartesian
coordinates of the diverse ranges in the contextual map. Formally, given an
entity, its context is mapped to the contextual map as followed:
m : s →
⎛
⎜
⎜
⎝
v1
v2
...
vn
⎞
⎟
⎟
⎠|s ∈S, v ∈Vn

The Contextual Map - A Context Model for Detecting Aﬃnity
177
Table 1. Example ranges
Range
# of dimensions
Axis deﬁnition
Location
3 (x, y, z)
Cartesian coordinates (km)
Environmental data
4
(temperature,
barometric
pressure, humidity, wind speed)
0 (min) to 100 (max)
where S is the set of quantiﬁed context source data and Vn the correspondent
n-dimensional realm in the contextual map. v represents a single context in
the contextual map with v corresponding to the entity’s real-world context.
According to the fragmentation of the contextual map into ranges discussed
in the previous section 4.1, m needs to map individual contextual data to the
correspondent ranges in Vn.
It is to be noted, that S may cover a very heterogeneous spectrum of contex-
tual sources [11] implying heterogeneous deﬁnitions of m as well. In the rest of
the paper we proceed with a mapping technique tailored to our weather station
example. We assume that the context of an entity is typiﬁed and hence given by
a set of scalars, each corresponding to its according type of context.
Given our weather station example, we ﬁrst deﬁne a representation for its
context in the contextual map model and deﬁne a mapping function for the con-
textual data to be mapped into that map, subsequently. We proceed as followed.
First, we deﬁne two context types: location and environmental data. We assign
each type a range with an according amount of dimensions in the contextual
map, as shown in table 1. Consequently, we assign the dimensions of each range
uniform axis deﬁnitions.
With this setting, it is possible to deﬁne a mapping function m, which transfers
the weather station’s context into the contextual map. First of all, we require
m to handle each context type and its corresponding range separately. m takes
the quantiﬁed contextual data captured and derived from the weather station’s
context and calculates its position in the contextual map adhering both range
and axis deﬁnitions. Mapping location into the map is quite straight forward:
The station’s coordinates are translated to cartesian coordinates in the map.
The coordinates for the environmental data are calculated by determining the
relation of the current value to the pre-deﬁned extremes. Let temperature to be
allowed to adopt a value between -50◦C and 50◦C resulting in 100 adoptable
units. With the axis of dimensions of the environment range ranging from 0 to
100, a currently measured temperature of 25◦C corresponds to a coordinate of
75 for the temperature dimension. The mapping of the remaining environmental
measurements works analogously.
The mapping function presented here covers a special use case, and must
not be seen as universally valid. The heterogeneous spectrum of context-aware
application cases [10,11] requires m to be adapted individually depending on
the required application cases. A large part of this heterogeneity comes from
the heterogeneous environment, which usually surrounds context-aware systems.
Given the assumption, that contextual data is captured and quantiﬁed, m is to
be deﬁned in a way to speciﬁcally handle the input given by that quantiﬁcation.

178
R. Schmohl and U. Baumgarten
Since the context of entities is dynamic, the mapping must be employed iter-
atively to ensure the most current context to be stored in the contextual map.
Such context actuality is achieved by frequent contextual updates. The according
update semantics are discussed later on in section 5.3.
5
Application of the Contextual Map
So far, we have solely depicted the contextual map model in the previous section
4. In this section we discuss the applicability of our context model. We assume
that entities possessing their own contexts utilize mobile devices, which acquire
and manage such contexts and commit contextual updates to distribute this
information. In the following we ﬁrst discuss the deﬁnition of context boundaries,
which form the basis for enabling triggers based on contextual proximity/aﬃnity.
With context boundaries deﬁned, the principles of measuring the proximity of
contexts are introduced, hence allowing to determine the aﬃnity between those
contexts. In addition, we reﬂect on eﬃcient update semantics, to derive the
current context to be most current despite of minimized eﬀorts.
5.1
Context Boundaries
Contextual boundaries represent the degree of alikeness between contextual in-
formation. More precisely, contextual boundaries may be deﬁned between dif-
ferent entities to determine the aﬃnity of their individual contexts. This aﬃnity
expresses how interesting or - contrarily - uninteresting another entity’s context
is. Concluding, context getting closer also raises its relevancy for the concerned
entity [9].
For example, a car driver may be interested in proper weather conditions
on his route, hence taking action if a proximate weather station reports strong
weather. We deﬁne the contextual boundaries between the entities car driver and
weather station on two ranges: location (Rloc) and environment (Renv) (compare
table 1). Both ranges compose the context of each entity. An entitiy’s physical
Location
Weather
Contextual Range Boundary
Context of Weather Station 
Context of Driver
Fig. 4. Crossing Context Boundary Example

The Contextual Map - A Context Model for Detecting Aﬃnity
179
position is represented in Rloc. Renv represents a weather station’s currently
measured environmental readings and the driver’s personal conception about
not-agreeable weather. Now, we can deﬁne a context boundary, which delimits
the driver’s willingness to drive according to how bad the weather is. The bound-
ary concerning Rloc expresses a weather station’s distance to the driver, so that
it actually becomes of his interest. The boundary on Renv focuses on how close
the current weather at a station may come to the weather conditions regarded
as critical by the driver. The contextual boundary between the entities driver
and weather station gets crossed if the driver gets close to the weather station,
which reports conditions close to the driver’s critical criteria. Figure 4 illustrates
the deﬁnition and crossing of this example boundary.
Given this example, we can formally deﬁne a contextual boundary B:
– A proximity threshold ti is deﬁned on each contextual range Ri, which is rel-
evant to B. Each ti is a single value dependent on all of the Ri’s dimensions,
hence, deﬁning the degree of alikeness of Ri’s contexts. Basically speaking,
the threshold represents the distance, which delimits the range’s contextual
information to be ”proximate” or not.
– The set of thresholds ti of all ranges R1, ..., Ri, ..., Rm relevant to B deﬁnes
the contextual boundary: B = (t1, ..., tm)
5.2
Detecting Aﬃnity of Contexts
With the principle of contextual boundaries deﬁned, we proceed with describing
how contextual boundaries can be exploited using the contextual map model.
As we have argued earlier, crossing context boundaries corresponds to diﬀer-
ent entities’ contexts getting either more ore less aﬃne (or rather contextually
”closer/farther” to/from each other), thus crossing the aﬃnity degree speciﬁed
by the boundary.
With context boundaries deﬁned in a contextual map, the next step is to de-
termine crossings of those boundaries indicating changes of contextual aﬃnities.
Each of a context boundary’s thresholds is deﬁned on a single range. For this
reason the check for two contexts having crossed the boundary by converging or
separating from each other is performed range-speciﬁcally. Given two entities P
and Q, their respective contexts P and Q are partitioned into multiple ranges.
Since ranges group contextual data of equal types, we compute the distances
between the two contexts inside each range separately (only ranges aﬀected by
the boundary). Such a range-level distance between P ands Q is represented by
the Euclidean distance D:
D =

	
	

d

i=1
(pi −qi)2
(1)
with pi and qi being the coordinates of dimension i of the contexts P and Q,
respectively, and d denoting the number of dimensions of the concerning range.

180
R. Schmohl and U. Baumgarten
With the distance D calculated, we employ proximity and separation detection
[7] to determine, if the contexts of the two entities are ”closing” or ”separating”
on range level. The thresholds of a contextual boundary serve as limits to enable
proximity or separation alerts. Such an alert is triggered when all of the bound-
ary’s thresholds have been breached, i.e. when the boundary has been crossed on
each relevant range. The ”direction” of exceeding a context boundary’s thresh-
olds declares whether P and Q have converged or separated while crossing the
context boundary, hence getting either more or less aﬃne, respectively.
Returning to our weather station example, we assume, that the contexts of
both the car driver and surrounding weather stations are iteratively captured
and mapped to the contextual map. Hence, each weather station and the car
driver get a constantly updated contextual map position associated with their
respective context. The car driver has deﬁned a contextual boundary deﬁning
dangerous weather, at which he is not willing to drive (i.e. weather coming close
to his critical weather deﬁnition). Hence this boundary is decomposed into two
thresholds deﬁned on two ranges as depicted earlier in section 5.1 and ﬁgure 4:
on Rloc expressing the driver’s tolerated distance to a weather station reporting
bad weather, and on Renv deﬁning the tolerance interval to weather conditions
at which the driver refuses driving. Let the boundary’s thresholds be further de-
ﬁned as 10 kilometers on Rloc and 15 units on Renv (as depicted in table 1). The
distances D between the contexts of driver and weather station are computed
for each range upon receiving a contextual update. In this example, such an up-
date may yield changing weather conditions and/or changing driver’s location.
As soon as the driver gets closer than 10 kilometers to a weather station, which
reports weather less than 15 units distant to the driver’s critical weather deﬁni-
tion, the deﬁned context boundary is crossed and a proximity alert is triggered.
Hence, the driver may take action changing his route or stop driving.
5.3
Update Semantics
An obvious precondition for detecting proximity/separation of contexts in the
contextual map is the knowledge about its most current positions in the map.
Context actuality is achieved by contextual updates, i.e. updates containing
an entity’s most current context information. The challenge is to deﬁne eﬃcient
update semantics, so that a minimal amount of updates delivers the most current
context possible. E.g., frequent updates issued in short intervals deliver very
actual context information, but are highly ineﬃcient, since most of them are
redundant due to missing context changes.
In section 3.2, we have outlined eﬃcient semantics for issuing location up-
dates to detect geographical proximity among mobile hosts [7]. Those mecha-
nisms allow the acquisition of the most current context with a minimal amount
of location updates. With little eﬀort, we can transfer those principles on the
contextual map. Both the geographical setting in section 3.2 and the contextual
map are settled in multi-dimensional Euclidean space (with the geographical
setting being 2-dimensional expressing width and depth). The proximity and

The Contextual Map - A Context Model for Detecting Aﬃnity
181
separation detection mechanisms from section 3.2 work zone-based based on
circles and strips. Extending those mechanisms on the contextual map concludes
the deﬁnition of those on d-dimensional hyperspheres and hyperplanes:
– Hyperspheres method: In the 2-dimensional realm (R2), contextual updates
are sent upon leaving the circular zone spawned around the according en-
tity’s position during the last update (last known position). Extending this
principle on the d-dimensional realm (Rd), we deﬁne a d-dimensional hyper-
sphere around this position in the contextual map. This position forms the
center point C of a hypersphere with its radius r denoting the update zone.
This deﬁnition allows us to determine, if the current context manifests itself
at a position outside the hypersphere, i.e. if the Euclidean distance between
the current context P and C is greater r. Formally, a contextual update is
triggered upon the following condition:

	
	

d

i=1
(Pi −Ci)2 > r
– Hyperplanes method: For proximity detection in the geographical realm,
strips are spawned orthogonally between two mobile nodes eligible for prox-
imity detection. Contextual updates are sent by a mobile node upon en-
tering such a strip. Thus, the update zone is bounded by two lines. The
d-dimensional analogy requires the deﬁnition of two (d −1)-dimensional hy-
perplanes, bounding the update-zone in Rd. Since this approach is still set-
tled in Euclidean space, we can formally deﬁne those two hyperplanes in Rd
analogously as in R3. Let there be two contexts, P and Q, with according
coordinates in the contextual map. First, the middle point C between those
contexts is to be deﬁned. Now, the hyperplanes need to be deﬁned orthogo-
nally to the line connecting P and Q, and they need to be equidistant from
the the center point C, in order to position the strip exactly in between P
and Q. With the update zone set we can now trigger a contextual update,
if one of both contexts enters the strip-area bounded be the two deﬁned
hyperplanes. However, this method is only feasible to conduct proximity de-
tection between the two contexts. For separation detection the strip-method
cannot be applied, as argued in section 3.2. In order to conduct separation
detection, we deﬁne an update zone bounded by a hypersphere, centered at
C. The contextual update is then triggered upon a context ”leaving” the
hypersphere, as we have discussed this process earlier already.
To demonstrate the applicability of the update semantics presented here, we
return to the example with the driver and the weather station. We have two con-
texts, the driver D and the station S. We further regard the two relevant ranges
in the contextual map: weather conditions Renv and location Rloc. However, the
dynamic changes, which take place here are restricted to the weather station’s
current weather and the driver’s location. Concluding, we have to pay attention
to D’s position in Rloc and S’s coordinates in Renv, only. To proceed with this

182
R. Schmohl and U. Baumgarten
example we employ an update zone bounded by hyperspheres. Therefore, hyper-
spheres are deﬁned around D and S on their respective ranges Rloc andRenv.
For D, it seems reasonable to select a radius of 10 on Rloc, denoting an update
necessity from the driver every 10 kilometers (neglecting the third dimension z
as denoted in table 1 for reasons of simplicity). For the update-sphere of S, we
deﬁne a radius of 5 on Renv. This corresponds to an update triggered when the
weather conditions at the weather station change by
1
20 of the scale (see range’s
axis deﬁnition in table 1).
6
Overall Workﬂow
With the basic working principle of the contextual map model discussed, we are
now about to summarize the general workﬂow of detecting aﬃnities between
contexts.
1. Context capturing: The ﬁrst step consists of abstracting the environmental
context into the context model. The contextual map has to be set up ac-
cording to this context, i.e. ranges, its axes are to be deﬁned (section 4.1).
Subsequently, the initial context is mapped into the contextual map. This
includes the identiﬁcation of entities possessing their own deﬁnable contexts
and mapping them into the contextual map (section 4.2). As a result, every
entity possesses a position in the map, corresponding to its initial context.
2. Setting of contextual boundary: In the next step, the contextual boundaries
have to be deﬁned, so that contextual aﬃnity detection becomes possible.
This includes the identiﬁcation of ranges aﬀecting the according boundary
and deﬁning the delimiter thresholds on the actual ranges (section 5.1).
3. Deﬁnition of update semantics: The entities’ terms for committing updates
about their most current contexts must be deﬁned. This regards the selection
of the appropriate bounding model for the update zones in Rd, (hypersphere
and hyperplane models in section 5), as well as the size of the update zones
(hypersphere = diameter, hyperplanes = distance between each other).
4. Monitoring current context: It is assumed, that a mobile host is attached to
each entity. It keeps track of the entity’s current context, hence maintaining a
contextual map representation of its entity locally. The mobile host captures
the most current context from its context sensors, quantiﬁes it in the context
capturing interface (see ﬁgure 2), and merges the resultant data into its local
contextual map (section 4.1). The entity’s changing context corresponds to
changing coordinates of its contextual position in the map.
5. Determine contextual update: The constant local monitoring of the entity’s
context enables the determination to commit a contextual update. This is
exactly the case, when the entity’s context in the local contextual map leaves
the update zone (section 5). A contextual update is committed to the system
by the entity’s mobile host.
6. Proximity/separation detection: The distances from the entity’s context to
other contexts are determined by calculating the Euclidean distance (5.2).
This process is conducted on each range aﬀecting a context boundary.

The Contextual Map - A Context Model for Detecting Aﬃnity
183
7. Trigger proximity and separation alerts: The calculated distances are checked
with the aﬀected contextual boundaries. If a change of distance equals a
crossing of a boundary (section 5.1), a proximity or separation alert is trig-
gered. The alert is available for applications utilizing the context API as
depicted in ﬁgure 2.
Figure 5 illustrates the workﬂow described above as a UML activity diagram.
Global System
Entity
Context
Capturing
Setting
boundary
Setting
Update
Semantics
Local
Context
Monitoring
Contextual Update
determined
Awaiting
Updates
continue monitoring
Proximity/
Separation
Detection
Application
-speciﬁc
Action
Alert
Fig. 5. Workﬂow
7
Conclusion and Outlook
With the contextual map, we have proposed a novel context model concept
facilitating the work with contextual aﬃnity. We have proposed a deﬁnition
for context boundaries consisting of the degree of alikeness between diﬀerent
contexts based on typiﬁed ranges of contextual information. Together with the
contextual map model, we are able to track speciﬁc alikeness of contexts and
put it into relation with contextual boundaries. This process ﬁnally enables us
to enrich the context API for context-aware applications (see ﬁgure 2) by pro-
viding contextual triggers, which report that a speciﬁed degree of contextual
alikeness has been reached. The contextual map suggest the implemented as
middleware concept augmenting existing context model by providing contextual
aﬃnity management.
With the conceptual sketch available, the next step encompasses the reﬁne-
ment of selected aspects of the conceptual map, especially the following two:
First, a major issue concerns the heterogeneity of the mapping function. Han-
dling heterogeneous context sources allows a more standardized process of map-
ping context to the map. The second issue in question regards the aspect of
distribution. Although clearly being applicable to pervasive computing environ-
ments, we have not yet proposed architectures on how to distribute the con-
textual map model and its peripheral components on mobile nodes, networks
infrastructures and so on.
Our most signiﬁcant mid-term goal is the construction of a prototype model,
which may allow a proof-of-concept simulation. This goal will then allow us to ana-
lyze issues on how to integrate the context model in proven context-awaresystems.

184
R. Schmohl and U. Baumgarten
References
1. Christopoulou, E., Goumopoulos, C., Kameas, A.: An ontology-based context man-
agement and reasoning process for ubicomp applications. In: sOc-EUSAI 2005: Pro-
ceedings of the 2005 joint conference on Smart objects and ambient intelligence [2],
pp. 265–270 (2005)
2. Christopoulou, E., Kameas, A.: Gas ontology: An ontology for collaboration among
ubiquitous computing devices. Journal of Human-Computer Studies [1], 664–685
(2005)
3. Gellersen, H.W., Schmidt, A., Beigl, M.: Multi-sensor context-awareness in mobile
devices and smart artifacts. Mob. Netw. Appl. 7(5), 341–351 (2002)
4. Rezwanul Huq, M., Thanh Tuyen, N.T., Lee, Y.-K., Jeong, B.-S., Lee, S.: Modeling
an ontology for managing contexts in smart meeting space. In: SWWS 2007: Pro-
ceedings of the 2007 International Conference on Semantic Web and Web Services
(2007)
5. Khouja, M., Juiz, C., Lera, I., Puigjaner, R., Kamoun, F.: An ontology-based model
for a context-aware service oriented architecture. In: SERP 2007: Proceedings of
the 2007 International Conference on Software Engineering Research and Practice
(2007)
6. Kieß, W., F¨ußler, H., Widmer, J., Mauve, M.: Hierarchical location service for
mobile ad-hoc networks. SIGMOBILE Mob. Comput. Commun. Rev. 8(4), 47–58
(2004)
7. K¨upper, A., Treu, G.: Eﬃcient proximity and separation detection among mo-
bile targets for supporting location-based community services. SIGMOBILE Mob.
Comput. Commun. Rev. 10(3), 1–12 (2006)
8. Padovitz, A., Loke, S.W., Zaslavsky, A.: Towards a theory of context spaces. In:
Proceedings of the Second IEEE Annual Conference on Pervasive Computing and
Communications Workshops, 2004, vol. 1, pp. 38–42 (March 2004)
9. Roman, G.-C., Julien, C., Huang, Q.: Network abstractions for context-aware mo-
bile computing. In: ICSE 2002: Proceedings of the 24th International Conference
on Software Engineering, pp. 363–373. ACM Press, New York (2002)
10. Schmohl, R., Baumgarten, U.: Context-aware computing: a survey preparing a
generalized approach. In: IMECS 2008: Proceedings of the International Multi-
Conference of Engineers and Computer Scientists 2008, International Association
of Engineers (2008)
11. Schmohl, R., Baumgarten, U.: A generalized context-aware architecture in hetero-
geneous mobile computing environments. In: The Fourth International Conference
on Wireless and Mobile Communications, 2008. ICWMC 2008, vol. 1, pp. 118–124
(August 2008)
12. Strang, T., Linnhoﬀ-Popien, C.: A context modeling survey. In: Davies, N., Mynatt,
E.D., Siio, I. (eds.) UbiComp 2004. LNCS, vol. 3205. Springer, Heidelberg (2004)

C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 185–196, 2009. 
© Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009 
Extending UPnP QoS Standard for Reducing Response 
Delay in Multimedia Home Networks 
Jesús Sáez, Alvaro Reina, Ralf Seepold, and Natividad Martínez Madrid 
Universidad Carlos III de Madrid, Leganés (Madrid), Spain 
Departamento de Ingeniería Telemática 
{jesus.saez,alvaro.reina,ralf.seepold, 
natividad.martinez}@uc3m.es 
Abstract. A model has been developed to provide an UPnP communication 
implementation that reduces QoS negotiation delay. The proposed model ex-
tends the UPnP QoS Architecture standard by adding status information about 
the network topology and the established traffic flows. The introduced exten-
sions are compatible to the existing UPnP standard. The implementation has 
been tested under different conditions and the obtained results confirm that  
response time can be reduced with respect to the standard architecture of  
about 60% to 92%. Furthermore, the implementation demonstrates that redun-
dant queries can be avoided while the management and distribution of the  
multimedia content will be optimized.  
Keywords: UPnP, Middleware, Multimedia, QoE, QoS. 
1   Introduction 
The number of mobile devices providing multimedia support is growing continu-
ously; several devices provide UPnP (Universal Plug and Play) functionality [1],  
implementing the UPnP Audiovisual (AV) architecture [2] that allows to act as a  
multimedia server or render (e.g. Nokia Nseries devices).   
The UPnP AV architecture defines interactions between an UPnP AV Control Point 
and multimedia devices. A Control Point coordinates and manages control messages 
sent to or received from multimedia devices. In a local network, all UPnP multimedia 
devices can be automatically discovered by the Control Point and any multimedia 
content will be directly transmitted from a server device to render device and not via 
the Control Point. UPnP Media Server and UPnP Media Renderer are two device types 
defined in the UPnP standard [3] in order to share and reproduce multimedia content. 
The UPnP Forum defined a specification for a QoS architecture for local networks 
[4] that is illustrated in Fig 1. This architecture allows deploying a system that is in 
charge of managing the quality for each communication request within the UPnP 
device network.   
Three types of entities are specified in the UPnP QoS architecture:  
y QosManager: manages the QoS provisioning for a certain traffic specification and 
calculates the path from origin to destination. 
y QosPolicyHolder: stores and manages traffic policies that will be applied to any 
reserved flow. 

186 
J. Sáez et al. 
y QosDevice: stores the status of any QoS traffic in a device and it provides infor-
mation about the state and capabilities of a node. This entity is available for any 
device that supports a certain quality of service (e.g. mobile phone, PDA, Pock-
etPC, etc).   
The QoS architecture provides a better quality for content reproduction, but it is 
important to reduce the response time when a user wants to assign a new stream. That 
means, the time a user needs to wait until the system will enable or deny a request. 
This is reflected by a factor called quality of user experience (QoE). The standard 
QoS Architecture does not take in account this parameter, so it is one of the objectives 
of proposed model to reduce the response time and thus increase QoE. This goal is 
achieved by introducing states that extend the standard model. A state stores both 
devices capabilities and network topology. With this new extension, the QoS Manager 
will provide faster response times. The extensions are implemented in a modular way 
in order to maintain the compatibility to the original standard. 
This work is focused on optimizing the QoS Manager. Several recent publications 
address different aspects of service oriented architectures to improve the performance 
of the UPnP QoS Architecture in different ways. Some of them, like Choi [5], intro-
duce just an implementation of the basic elements of the UPnP AV and QoS architec-
tures. Others suggest extensions to allow the adaptation of the content. Ditze [6]  
considers adaptation after event-based detection of bottlenecks caused by variable 
bandwidth flows. Lee [7] dynamically adapts the characteristics of requested or estab-
lished flows after refusals to establish new traffic due to resource limitations. Other 
works deal with the OSGi framework [8] like N. Goeminne [9], who proposes an im-
plementation of the UPnP QoS architecture over OSGi, but without any extension. All 
alternative solutions should be considered and tested to maintain the compatibility with 
the Standard. 
 
QoS Manager
Layer 2
802.3 / 802.11
Device
QoS Device Service
Layer 2
802.3 / 802.11
Device
QoS Device Service
Layer 2
802.3 / 802.11
Device
QoS Device Service
QoS Policy 
Holder
Control Point
Source
Sink
Intermediate
Traffic 
Streams
Traffic 
Streams
Traffic 
Streams
Request QoS (1)
Traffic Descriptor (2)
Set Policy
(Unspecified Interface)
Traffic Policy (3)
Traffic Descriptor (4)
Traffic 
Importance 
converted to 
specific Layer 
2 QoS
QoS Manager
Layer 2
802.3 / 802.11
Device
QoS Device Service
Layer 2
802.3 / 802.11
Device
QoS Device Service
Layer 2
802.3 / 802.11
Device
QoS Device Service
QoS Policy 
Holder
Control Point
Source
Sink
Intermediate
Traffic 
Streams
Traffic 
Streams
Traffic 
Streams
Request QoS (1)
Traffic Descriptor (2)
Set Policy
(Unspecified Interface)
Traffic Policy (3)
Traffic Descriptor (4)
Traffic 
Importance 
converted to 
specific Layer 
2 QoS
 
Fig. 1. UPnP QoS Architecture 

 
Extending UPnP QoS Standard for Reducing Response Delay 
187 
The rest of the article is organized as follows. In the next section the whole model 
is presented underlining extensions, and each path is described in detail. Section 3 
presents the results of the new model evaluation and finally the conclusions and the 
directions for future works are presented. 
2   Quality of Service Extension of the UPnP Standard 
When two UPnP AV devices want to exchange multimedia contents, the AV Control 
Point acts as a mediator that demands a QoS reservation for the transmission. Always 
when a new traffic request arrives, the AV Control Point checks with the QoS Man-
ager whether it is possible to establish the traffic stream or not. Therefore, all  
involved devices must be checked for spare capacity and capability to establish the 
requested flow. Also a route between source and destination must be computed. This 
process will result in submitting redundant queries because the results of (derived 
from device requests and routes) already obtained information will not be maintained 
(nowadays, the QoS UPnP specification considers that already obtained information 
expires after submitting a new request). 
Now, the proposed extension intends to develop a new model based on a central-
ized storage and update of all data above mentioned: This will accelerate the respond 
time in the future, i.e. for new requests. As a result, there is no need to repeat the 
submission of queries already sent nor to derive and rebuilt the network topology 
information or any data from already assigned flows. 
The next subsections characterize the features introduced by the new model. Firstly 
all implement variants of the extended model are described, regarding both the new 
functionality and the new modules introduced. Afterwards, the new operation modes 
are explained together with their advantages and problems. 
2.1   QoS Architecture Extension  
The extension proposed by this architecture is based on the implementation of a cen-
tralized storage of the local network capabilities and topology, maintaining its state 
updated at any time. To achieve this objective, the current state of the network must 
be locally updated and maintained by the QoS Manager, using, for instance, a model 
that provides database support. As proposed in [10], two conceptually differentiated 
informational sets have to be stored and managed. Firstly, a topology holder describes 
the structure of the network by means of the storage of links and nodes and capabili-
ties of both of them. Secondly, traffic flows configured by the QoS subsystem are 
managed and stored by a flow holder.  
This differentiation between the concepts of available resources of the network (to-
pology) and QoS reservation information (flows) focuses on modularity which is the 
main guideline for the deployment of this model. As a result two modules will be 
implemented in the QoS Manager: Topology Holder and Flow Holder.  
Another important element of the extended architecture (see Figure 2) is the Infor-
mation Agent Subsystem (IAS). The IAS is in charge of updating any data managed by 
Topology Holder and by the Flow Holder. This will help to maintain the consistency 
between the real network status and the correspondent image stored by QoS Manager.  

188 
J. Sáez et al. 
QoS Manager
IAS
Flow DB
Topology
DB
Topology
Holder
Flow
Holder
QoS Manager 
Controller
Admission
Control
QoS Control Point
QoS Manager Service
DMA
LMA
FCA
DCMA
UPnP 
Network
UPnP 
Network
QoS Policy Holder
QoS Devices
register
policy
 
Fig. 2. Block diagram of the extended model of QoS UPnP standard. Details of the QoS Man-
ager modules. 
The IAS consists of a set of dedicated agents running as daemons in background 
and listening to UPnP events. They analyze state variables delivered by QoS Devices 
to extract and filter relevant data for databases (DB) associated to each of the agents, 
in order to provide real-time information about the home network. 
All these new modules together with those ones implementing the QoS system will 
be described in the next sub-sections. 
2.1.1   Topology Holder 
Calculates the route for a traffic flow, and stores the capabilities of devices in this 
path. This module maintains a topology DB that stores previously calculated routes, 
network topology and devices capabilities. Three agents are in charge of updating this 
DB in three different ways. 
Devices Management Agent (DMA) 
The DMA listens to events associated to attachment and registration of new QoS 
Devices which are sent during the discovery phase in the UPnP protocol; DMA inte-
grates new QoS Devices into the Topology DB and creates initial connections be-
tween every reachable node. 
Link Management Agent (LMA) 
The LMA updates the links between QoS Devices. The state variable associated to 
this agent is called PathInformation, defined in the UPnP QoS Device specification 
[11]. This agent indicates links between nodes. When a QoS Device has added to or 
removed from a home network, an event dispatches the value of the PathInformation. 
Once an event is detected by the LMA, it invokes routines from the Topology Holder 
that update connections between QoS Devices on the Topology DB. 

 
Extending UPnP QoS Standard for Reducing Response Delay 
189 
Device Capabilities Management Agent (DCMA) 
This agent monitors available resources in each device attached to the network and 
updates this information in the topology DB. The information is obtained from a new 
state variable, called TrafficState, that is implemented in the new QoS Device model. 
This agent manages events published by all devices related to this variable, and it will 
update related values. 
2.1.2   Flow Holder 
The Flow Holder manages traffic flows currently configured in the UPnP QoS sub-
system, allowing the Admission Control module to submit queries about the flow 
status. In order to do this, the Flow Holder module implements the required routines 
to manage a centralized Flow Database. It stores every flow introduced into the net-
work and all QoS Devices involved. 
Its execution is based on the “Flow Control Agent” (FCA) which runs in the back-
ground in order to catch events from the TrafficState variable to update the Flow 
Database with these values.  
2.1.3   QoS Manager Controller 
The QoS Manager Controller is the operational center of the QoS Manager. It acts as 
a scheduler that sequentially invokes tasks on the rest of modules in order to reserve, 
release or update traffic flows. When initializing the QoS subsystem, the QoS Man-
ager Controller starts every internal module specifying witch configuration is desired 
by user. 
2.1.4   Admission Control 
It implements the necessaries routines in order to decide whether a flow can be re-
served or not. Before the operation can be invoked, the Topology Holder and the 
Flow Holder must contain updated information that is reflecting the current network 
state. 
2.1.5   QoS Manager Service 
This module acts as an UPnP device towards any UPnP client (e.g. AV Control 
Point). It publishes all services necessary for instantiating, releasing or updating cer-
tain traffics within the UPnP network by redirecting all requests to the QoS Manager 
Controller.  
2.1.6   QoS Control Point 
This module implements an UPnP client, being in charge of registering all QoS devices 
attached to the local network and querying for all services they may offers. It acts as a 
proxy towards the QoS Manager Controller. It provides information about registered 
UPnP services, so that the QoS Manager Controller can access to the functionality. 
2.1.7   Policy Holder 
This module centralizes the storage and manipulation of admission policies of the 
network. When required, it provides the Admission Control with information needed 
to make a decision about accepting any flow. 

190 
J. Sáez et al. 
UPnP QoS Policy Holder specification [12] defines only one action to recover poli-
cies from the Policy Holder database. The Admission Control module can query for 
policies related to one traffic specification that is included in the AV Control Point 
request (Traffic Descriptor). Typically, the QoS Manager receives several possibilities 
configurable specifications from the AV control point, so it needs to obtain more than 
one policy in order to take a decision on the admission of a particular flow. Therefore, 
the extended model implements a new functionality that allows the QoS Manager to 
ask for a list of policies at the same time. This feature saves processing time and 
avoids unnecessary iterations with the policy holder. 
2.1.8   QoS Device 
A new QoS Device only adds a one new state variable. Firstly, it consists of an event-
ing variable that reflects available resources per interface. This is a consequence of 
possible QoS actions (setup, release, and update traffics) and information derived 
from the last successfully completed action. Now, the ‘getQosState’ action belongs to 
the UPnP QoS Device specification that allows obtaining the same information from a 
specific QoS Device, but only on demand.  
This new feature provides QoS Device eventing directed to the QoS Manager. It is 
always executed when a request, a release or an update action has been submitted by the 
control point, and thus allowing the QoS Manager to keep track of all changes in devices. 
2.2   Operational Modes 
The operational modes describe several configurations of the QoS subsystem. They 
refer to the fact how modules work and how they cooperate to complete the QoS 
functionality. In the following, we enumerate some objectives that justify the defini-
tion of different operational modes:  
y Maintaining compatibility to the UPnP QoS v2 specification  
y Adapting to the home network environment behavior 
y Allowing administrators or advanced users to configure the QoS subsystem con-
form to the most suitable configuration and according to given circumstances 
2.2.1   Admission Control Operational Modes 
The Admission Control module implements several variations depending on which de-
vices which will be part of the decision process in a traffic flow. In this paper, the admis-
sion control mode that is defined in the UPnP QoS specification will be called hybrid 
mode. The extended model also includes the centralized and distributed Admission  
Control modes. Next, the three configurable modes will be described in detail. 
Hybrid Mode 
The admission control responsibility is shared between the QoS Manager and QoS 
Devices which are currently part (in the route) of the traffic flow. This mode avoids 
inconsistency when the QoS Manager counts on expired information about traffic in 
the network. This situation can occur when some of the QoS Devices of the network 
do not follow this QoS extended model. 
In this way, the Admission Control module filters the traffic specifications from 
the traffic descriptor that the AV Control Point provides. The filter is based on the 

 
Extending UPnP QoS Standard for Reducing Response Delay 
191 
information provided by the Topology Holder. Then, the decision is communicated to 
QoS Devices waiting for the response to accept or reject a traffic reservation. Full 
agreement is required before a traffic flow can be accepted. 
Distributed Mode 
The QoS Manager delegates the responsibility of admitting or refusing a specific 
traffic flow to the QoS Devices. It only preserves the role of a router, looking for the 
nodes in the path from the source to the destination. Once a path has been identified, 
it obtains the list of the QoS Devices that will be asked for admission control as a 
result. The QoS Manager does not make any previous analysis, so it is possible that 
many traffic specifications must be requested before obtaining acceptance positive 
response from every device. Distributed admission control does not require that the 
QoS Manager previously knows about the traffic status because the admission algo-
rithm is applied only for QoS Devices based on their own real-time registration of the 
network status and traffic reservation. So, this is the most robust mode in the sense of 
consistency. Despite this advantage, distributed admission control generates high 
control overhead affecting other factors as e.g. efficiency. 
Centralized Mode 
In this mode, the QoS Manager is the only admission control authority. The admission 
action is supported by the information retrieved from the Topology Holder and the 
Flow Holder. Once the network and device capabilities are retrieved, this module uses 
this information to implement the admission routines and checking the possibility of 
introducing a new stream into the network. High efficiency improvement is expected 
due to the next two facts: 
y Control traffic reduction because of delegating the approval request to the de-
vices. 
y Exploitation of major QoS Manager computing capabilities due to the fact that it 
runs in a device providing high potential of computation capacities. This is dif-
ferent from QoS Devices that may run on devices with computation limitations. 
Due to the fact that decisions are not corroborated by the devices, this mode is vul-
nerable to possible mistakes in the information offered by the Topology Holder and 
Flow Holder. So, it is important to establish this modality always when an exhaustive 
network control is carried out. 
2.2.2   Information Agent Subsystem Operational Modes 
The operational modes of the IAS module refer to how agents are working and 
whether their main function is enabled or disabled. This main function, called event-
ing, has been explicitly explained before. So the different modes are: 
y The event-based mode: listening to events coming from QoS Devices and trig-
gering update tasks within databases. 
y Based on polling mode: forcing periodic checks. Agents ignore events but they 
periodically invoke actions from the QoS Devices that return values for each of 
the state variables assigned to each of the agents in the IAS. This operational 
mode makes sense in an environment that suffers from a high rate of non-UPnP 
traffic. This is because the QoS Device only throws an event when resources 

192 
J. Sáez et al. 
have been increased or reduced after any UPnP traffic has been released or re-
served by the QoS subsystem. By forcing periodic polling, the QoS Manager is 
aware of any resource variation due to other kind of traffic, reducing inconsis-
tent data between the state of the network and its image stored in the QoS Man-
ager. Furthermore, efficiency of the QoS subsystem is affected by the polling  
interval.  
y The third mode allows merging the eventing operational modes and the periodic 
polling ones, depending on the device typology. In this way, a periodic polling 
for devices can be configured that is related to the QoS v2 standard and to the 
eventing mode for all others. This operational mode is justified by the objective 
of being compatible with QoS Devices from UPnP QoS v2, which do not in-
clude the TrafficState variable, which is needed by the Devices Capabilities 
Management Agent in order to execute database updating tasks, and to offer  
almost the same performance like the eventing mode. 
2.2.3   Topology Holder and Flow Holder Operational Modes 
Both the Topology Holder and the Flow Holder are continuously serving information 
to the Admission Control module. Independently of each other, they can be config-
ured to extract data from different sources, so they can be configured for two possible 
operational modes: local and remote. Whenever the Topology Holder and the Flow 
Holder are configured as local, they will receive data from the local databases (To-
pology DB and Flow DB) of the QoS Manager. If they work in remote mode, each 
one queries the correspondent QoS Devices in order to extract information about their 
current state.  
In the extended model explanation, the Flow Holder and the Topology Holder have 
been considered working in a local mode, saving control overhead because configur-
ing the remote mode involves several disadvantages which involve higher respond 
times: 
y Anytime a traffic reservation is requested, they must query all QoS Devices 
about topology and flow data. In a similar way, when a traffic release is re-
quested not only the devices in the path but every device must be informed.  
y Previously calculated routes by the Topology Holder are lost after each iterated 
traffic request.  
Nevertheless, the remote mode is a good decision whether a home network suffers 
from continuous changes. 
3   Evaluation Methodology 
In this section, the features offered by the extended UPnP QoS model are going to be 
analyzed. Table 1 lists a significant configuration subset that will be tested and com-
pared to the current UPnP QoS specification (#1 in Table 1). This makes it possible to 
observe individual improvements introduced by each of the new extensions. 
The evaluation scenario was composed of various UPnP devices working as QoS 
Devices, one QoS Manager and one QoS Policy Holder deployed at the same domain 
of a LAN network. 

 
Extending UPnP QoS Standard for Reducing Response Delay 
193 
Table 1. Description of a subset of possible configurations for the QoS UPnP extended model. 
Configuration #1 works as the UPnP QoS standard. 
 
Configuration modes 
Description 
#1 
 
Topology Holder: Remote  
Flow Holder: Remote 
Admission Control: Hybrid 
 
UPnP QoS Standard  
configuration. No topology or flow 
state are locally stored in the QoS 
Manager 
#2 
 
Topology Holder: Local  
Flow Holder: Local 
IAS: Event-based (DMA and LMA 
are enabled) & Polling (DCMA and FCA  
are disabled). 
Admission Control: Hybrid 
 
Fully compatible with the QoS 
UPnP standard. The TrafficState 
variable is not evented in this 
configuration. 
#3 
 
Topology Holder: Local  
Flow Holder:  Local 
IAS: Event-based (DMA, LMA, FCA 
and DCMA are enabled) 
Admission Control: Hybrid 
 
Complete extended model with 
hybrid admission control 
#4 
 
Topology Holder: Local  
Flow Holder: Local 
IAS: Event-based (DMA, LMA, FCA 
and DCMA are enabled) 
Admission Control: Centralized 
 
Complete extended model with 
centralized admission control. 
This configuration deploys the 
most efficient mechanisms of the 
extended model. 
#5 
 
Topology Holder: Local  
Flow Holder:  Local 
IAS:  Event-based (DMA, LMA, FCA 
and DCMA are enabled) 
Admission Control: Distributed 
 
Complete extended model with  
distributed admission control 
 
Efficiency assessment of each configuration was checked by measuring the  
response time to a traffic request and calculating the average (a.r.t.). Then, these val-
ues will be compared with those obtained with the UPnP QoS standard (#1 in  
Table 1) in order to show the efficiency improvement (e.i.) introduced by the new  
extensions.  
In the following two subsections, firstly the efficiency introduced by the new cen-
tralized storage of both topology and flows, will be studied. Finally it will discuss the 
modes in which the Admission Control can be configured, in addition to their  
capabilities and problems. 

194 
J. Sáez et al. 
3.1   Centralized Topology and Agents 
The configurations #2 and #3 will be evaluated in this section. These configurations 
keep up the same admission control mode like the UPnP QoS standard. It allows cen-
tering the analysis in how the following features affect in the efficiency improvement: 
y The local support of topology and flow states. 
y Enabling or disabling event-based mode for different agents in the IAS. 
Table 2. Topology storage evaluation 
Configuration 
a.r.t. (ms) 
e.i. (%) 
#1 (reference configuration) 
1400 
- 
#2 
1196 
14% 
#3 
554 
60% 
 
As it can be seen in Table 2, when enabling the QoS UPnP standard behaviour (#1) 
with no local storage of topology and flow state, the QoS subsystem generate worse 
response times than in any other configuration.  
In the second configuration #2, the centralized management of the network state as 
well as agents DMA and LMA are enabled. This is a configuration fully compatible with 
UPnP QoS standard, so no extensions of the QoS Device service are required. This re-
sults in a noticeable improvement of the response time (14 %) with respect to the con-
figuration #1 due to the reduction of queries to the devices in order to obtain relevant 
information about their types and characteristics. However, the absence of DCMA makes 
it necessary to query for each device and about its capacities in order to receive its state.  
The configuration #3 deploys all the potential of the extended model (except for 
the hybrid admission control mode), which is based on a centralized management of 
the network state and an event-based updating model. This configuration requires that 
the QoS Devices of the network fit into the QoS extended model of the TrafficState 
variable. The results show that configuration #3 presents the best performance, be-
cause it substitutes network messages with databases queries in order to obtain the 
network topology and the devices capabilities. 
Therefore, the last two configurations (#2 and #3) show substantial improvements 
over the first one. In this way, it can be said that the new QoS Manager and QoS De-
vice extended models, introduce a remarkable improvement regarding the delays intro-
duced by the QoS negotiation. Furthermore, in the last case the relative efficiency, in 
terms of response time, is close to the 60% compared to the UPnP QoS standard. 
3.2   Admission Control Functionality 
This section evaluates the efficiency improvement obtained by the introduction of 
new Admission Control operational modes. To do this, all modules and agents re-
sponsible for the centralized management of the UPnP network state will be activated. 
The results will be compared to those ones obtained for the configuration #1, the 
UPnP QoS standard. 
Analyzing the results (see Table 3) for the different Admission Control operational 
modes, it appears that the centralized one (configuration #4) generates the best results, 
 

 
Extending UPnP QoS Standard for Reducing Response Delay 
195 
Table 3. Admission Control modality evaluation 
Configuration 
a.r.t. (ms) 
e.i. (%) 
#1 (reference configuration) 
1400 
- 
#3 
554 
60% 
#4 
99 
92% 
#5 
714 
45% 
 
since it does not require communicating to devices in order to perform traffic man-
agement operations. However, this mode is vulnerable to inconsistent data received 
from the Topology Holder.  
The hybrid mode (configuration #3) presents a slightly higher response time be-
cause of the interactions between the Admission Control module of the QoS Manager 
and devices in order to compare the admission decisions. This pattern is also vulner-
able to inconsistent data received from the Topology Holder. Bit it prevents possible 
traffic admission errors.  
Finally, the distributed admission control mode (configuration #5) presents greater 
robustness but worse response times than the previous configurations. Robustness is 
due to the fact that admission decisions are only made by devices, independent of the 
state stored into the QoS Manager. The worse response time is due to the fact that 
devices must filter every traffic specifications. Furthermore, the interaction between 
the QoS Manager and the devices increases regarding to other configurations. In this 
way it can be said that this configuration is the less efficient but the surest. 
Thus, depending on the activity of the network and its features, a suited mode will be 
recommended. In very heterogeneous networks with a high degree of congestion, it is 
advisable to select distributed or at least hybrid admission control modes, which avoids 
problems due to potential inconsistencies within the database. On the other hand, net-
works with static features and not saturated status may go for a centralized admission 
control, benefiting from the high performance that this modality is capable of achieving. 
Finally, if the efficiency improvement of configurations #3, #4 and #5 are com-
pared to the QoS UPnP standard configuration (#1), it can be seen that any of the 
admission control procedures proposed in this paper have response times substantially 
better than those offered by the standard. 
4   Conclusions and Future Work 
The usability of multimedia services mainly depends on the capability to manage 
three aspects: the integration features of a multimedia infrastructure, the propagation 
and access to services and the ability to establish a QoS connection between a service 
provider and a consumer (device). The presented approach is focused on the third 
aspect, proposing a modular model, which extends the current UPnP QoS standard, 
capable of carrying out a centralised management of the network state, taking into 
account both flows and topology.  
The implemented system is fully configurable and capable of deploying different 
operation modes characterized by the retrieval of path and devices capabilities in a 
centralized or distributed way. The retrieval of the flows instantiated within a device 
in a centralized or distributed way, and the possibility to enable different admission 

196 
J. Sáez et al. 
control strategies is reflected by the following possibilities: centralized (decided by 
the QoS manager), distributed (decided by the devices) or hybrid (decided by the 
devices & QoS manager).   
After a subsequent evaluation, it has been shown that the centralized storage para-
digm introduced in this system, shows substantial improvements in response time 
compared to the standard UPnP.  
The future work is aimed at providing the QoS Manager with the ability to main-
tain a control of the streams’ priorities. It will allow the AV control point evict lower 
priority flows for those with higher priority. The new model focuses on devices lo-
cated in the same domain. In the future this model can be extended to provide QoS 
between two devices located indifferent sub networks. 
Acknowledgment 
The work has been partly supported by the projects: INCARE (Spanish Ministry of 
Education and Science; TSI2006-13390-C02-01), RAUDOS (Spanish Ministry of 
Industry, Tourism and Commerce; TSI-020302-2008-115), OSAMI (Spanish Ministry 
of Industry, Tourism and Commerce; TSI-020400-2008-114) and Caring Cars (Span-
ish Ministry of Industry, Tourism and Commerce; FIT-340000-2006-166). 
References 
1. Universal Plug and Play (UPnP) Forum (April 2008), http://www.upnp.org/ 
2. Universal Plug and Play (UPnP) Forum, UPnP AV Architecture:1 (June 2002),  http:// 
www.upnp.org/specs/av/UPnP-av-AVArchitecture-v1-20020622.pdf 
3. Universal Plug and Play (UPnP) Forum, MediaServer V 2.0 and MediaRenderer V 2.0 
(March 2006), http://www.upnp.org/specs/av/ 
4. Universal Plug and Play (UPnP) Forum, Quality of Service V 2.0 (October 2006), 
http://www.upnp.org/specs/qos/ 
5. Choi, S., Kang, D., Lee, J.: An UPnP based Media Distribution System supporting QoS in a 
Converged Home Network. In: Network Operations and Management Symposium (2006) 
6. Ditze, M., Bresser, T.: Resource Adaptation for Audio-Visual Devices in the UPnP QoS 
Architecture. In: Proceedings of the 20th International Conference on Advanced Informa-
tion Networking and Applications (2006) 
7. Lee, H., Moon, S., Kim, J., Joe, D.: UPnP-based QoSAgent for QoS-guaranteed Streaming 
Service in Home Networks. In: IEEE CCNC 2006 Proceedings (2006) 
8. Open Service Gateway Initiative (OSGi) Alliance (April 2008), 
  http://www.osgi.org 
9. Goeminne, N., Cauwel, K., De Turck, F., Dhoedt, B.: Deploying QoS sensitive services in 
OSGi enabled home networks based on UPnP. In: Proceedings of the 2006 International 
Conference on Internet Computing & Conference on Computer Games Development, 
ICOMP 2006 (June 2006) 
10. Seepold, R., Martínez, N., Martínez, J.: QoS Management for Distributed Multimedia Ser-
vices. In: Krishnaswamy, D., Pfeifer, T., Raz, D. (eds.) MMNS 2007. LNCS, vol. 4787, 
pp. 183–186. Springer, Heidelberg (2007) 
11. Universal Plug and Play (UPnP) Forum, QosDevice V 2.0 (April 2008), 
  http://www.upnp.org/specs/qos/ 
12. Universal Plug and Play (UPnP) Forum, QosPolicyHolder V 2.0 (April 2008),  
  http://www.upnp.org/specs/qos/ 

C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 197–207, 2009. 
© Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009 
Extending an IMS Client with Peer-to-Peer Content 
Delivery 
J. Fiedler1, T. Magedanz2, and J. Müller1 
1 Fraunhofer FOKUS, Kaiserin-Augusta-Allee 31, 10589 Berlin 
{Jens.fiedler,Julius.Mueller}@fokus.fraunhofer.de 
2 Technische Universität Berlin, FR 5-14, Franklinstr 28/29 10587 Berlin 
tm@cs.tu-berlin.de 
Abstract. The increasing demand for mobile applications implies an increase in 
service availability and content delivery capacities across the networks. Peer-to-
peer technologies have proven to be able to deliver media in an effective way to 
the end user. In this paper, we analyze and describe the necessary extensions 
and functionalities, which are needed to enable Peer-to-peer content delivery in 
an IMS client, namely the MONSTER framework. A special focus is directed to 
the interoperation between existing functional elements and newly developed 
peer-to-peer components. 
1   Introduction 
In today’s telecommunication world, several aspects of the service are important to 
the customer. These are e.g. mobility, service availability and diversity of services. 
The IP multimedia subsystem (IMS) [11] has proven to be an architectural 
framework, which grants exactly those aspects to the customer. IMS enables the 
standardized access to IP based services out of different types of networks. 
Due to its All-IP approach, the IMS is a key enabler for converged internet 
services, not limited to Voice-over-IP (VoIP) communication. Today, we see an 
increasing demand for additional services on the mobile phones, like television, 
gaming, community services, etc.  
Today, two basic ways exist to gain access to multimedia content. One way is by 
using a media server (central streaming), the other by joining a Peer-to-peer (P2P) 
content delivery overlay (distributed streaming). 
In this paper, we present a generic blueprint for a user client, suitable for  
IMS communication and P2P media delivery. As initial point we have chosen an IMS 
client, because IMS clients are supposed to have similar structures, while P2P clients 
heavily depend on the intended purpose, i.e. file-sharing, streaming, computing, etc. 
Therefore, the presented approach can be adapted easily to different existing IMS 
clients. 
The layout of this paper is as follows. In chapter 2, we shortly discuss IMS 
functionalities from the client point of view and Peer-to-peer media delivery 
technologies. Chapter 3 will give a short motivation, why it is suitable to implement 
P2P functionalities in an IMS client. In chapter 4, we introduce necessary P2P 

198 
J. Fiedler, T. Magedanz, and J. Müller 
functional blocks and present a generic way how to extend an IMS client with them. 
In chapter 5, we give an example by explaining, how a concrete IMS client is going to 
be extended for P2P media delivery. Finally, in chapter 6 we draw some conclusions 
and give an outlook to the future work. 
2   Background 
In this section we will give a brief introduction in IMS and P2P services. 
The IMS is an architectural framework for delivering IP-multimedia to mobile 
users. It was originally designed by the wireless standards body 3rd Generation 
Partnership Project (3GPP), and was intended to lead a way for mobile networks 
beyond GSM. Its original formulation (3GPP R5) represented an approach to 
delivering "Internet services" over GPRS. This vision was later updated by 3GPP, 
TISPAN by requiring support of networks other than GPRS, such as Wireless LAN 
and fixed line. The IMS network system consists of different functions, interacting 
over standardized interfaces (reference points), which form one IMS administrative 
network.  
 
Fig. 1. IMS Components and reference points 
An IMS-function is not necessarily identical to a node (hardware box). An 
implementer is free to combine 2 or more functions in one single node, or to spread a 
single function over multiple nodes. Each function can also be present multiple times 
in a single network, for load balancing, availability purposes or organizational issues. 
Reference points are realized by standardized protocols, like the session initiation 

 
Extending an IMS Client with Peer-to-Peer Content Delivery 
199 
protocol (SIP) [2] or DIAMETER [3]. Fig. 1 illustrates the most relevant IMS 
functions, the position of the user client and the related reference points between 
them. 
For P2P services, we examine P2P distributed hash tables (DHT), P2P media-
streaming and P2P file sharing. All P2P services are aiming on a distribution of data, 
may it be key-value pairs, stream chunks or file pieces. We do not focus on indexing 
here, i.e. the way how nodes discover content. We assume that this has been properly 
done before the envisaged content distribution, i.e. that nodes know which overlay to 
join for a specific content.  
Nevertheless, there are two operations, which all P2P algorithms have in common. 
These are join and leave. The join operation is performed by a node that wishes to 
become part of the corresponding overlay. It results in a message, which is sent to a 
particular node in the overlay, the bootstrap node for the joining node. The way this 
bootstrap node is detected depends highly on the associated P2P network. Lists of 
well-known nodes, broadcasting, etc. are suitable techniques to detect a bootstrap 
node. After a successful join operation, the performing node is part of the overlay and 
knows a relevant subset of nodes, its neighborhood. The leave operation is to be used 
when a node orderly leaves the overlay. As P2P networks are considered to be self-
healing, this operation must be understood as “the polite way” to leave an overlay. 
The remaining P2P network will continue to function even if a leaving node does not 
issue a leave message to the overlay. 
For a P2P DHT, the additional operation putkey and getkey are used. The 
underlying DHT algorithm is not of relevance here, it can be e.g. CHORD [5] or 
something similar. The putkey operation accepts a key and a value as its arguments 
and decides where in the overlay this information is going to be stored. It then issues a 
message either directly to the storing node, or to a node in its neighborhood, which 
then either routes the message further to the storing node or returns the address of it, 
optionally by recursively querying other nodes first. After the storing node received 
the putkey message, it will store the key with its value. The opposite operation to 
putkey is the getkey operation, which retrieves a value to a given key, basically in the 
same way, as the putkey operation stores it. 
For P2P streaming, many approaches exist, aiming on multiple different aspects 
of live streaming. A comprehensive comparison can be found in [1]. The operations, 
we are focusing on are sendstream, receivestream and requeststream. We assume that 
P2P streaming is realized by a distribution graph, which is thinner to the source, and 
wider, the further away in terms of overlay nodes from the source a node resides. The 
graph is intended to be, but is not necessarily a tree, as nodes (children) can receive 
partial streams from different senders (parents). The requeststream operation will 
select a stream from one or more senders. It will also define, how the stream is to be 
sent in terms of which parts of the stream (interleave), quality, etc., if this is not 
implicitly done by joining the specific overlay. The sendstream operation will send 
the selected stream in the requested way to the sink. The receivestream operation will 
receive the stream from one or multiple senders and optionally re-assemble the partial 
streams to a playable media stream. This is necessary if the stream consists of 
multiple chopped sub-streams, which were received from different sources. The 
requeststream operation needs to be performed only once per stream. 

200 
J. Fiedler, T. Magedanz, and J. Müller 
For P2P filesharing there are three operations which are required. They are 
requestblock, sendblock and receiveblock. The requestblock operation is used to 
instruct another node to send the specified part or piece of a content (file) to the 
requestor. The selection algorithm is independent from this operation. The 
requestblock operation must be performed either for each block, or for a group of 
blocks, depending on the distribution policy of the P2P algorithm. The sendblock 
operation is used to send the requested block to the requestor. Here it is dependant on 
the P2P technique, whether the block is transferred directly to the requestor or 
indirectly by routing it over a set of other nodes, e.g. super-nodes, or anonymizing 
nodes. The receiveblock operation receives a piece of content and places it at the 
correct location in the local storage for that content. 
As an IMS client uses the SIP for signaling with the IMS core and its components, 
it must have a SIP stack inside. This makes it feasible to use a SIP oriented protocol at 
least for the non-media part of P2P communication. Here, the P2PSIP comes in 
handy, which is currently developed by an IETF group [6]. P2PSIP focuses mainly on 
managing P2P overlays using the SIP. It extends SIP by defining new header-fields 
and is therefore fully compliant to the original SIP and can be expected to be 
supported by traditional SIP stacks.  
3   Motivation 
A single IMS client is exactly that, a client for the services, which are offered by the 
different IMS operators. By adding P2P functions, new aspects for the customer as 
well as for the providers and operators arise. Ongoing research has also discovered 
the benefits of combining P2P and IMS on different layers [9] and also already for 
static media [10].  
It has already been discussed in [4], that an external DHT, which could be a client 
based P2P network, could be used for storing contact addresses for the failure case of 
the central architecture. Clients could then store and retrieve their contacts in a client 
based distributed hash table (DHT) as long as the central architecture is not available. 
Naturally, this results in a security challenge against falsification of such contact 
records. This is currently discussed in the P2PSIP group of the IETF [7]. 
When talking about P2P media delivery, we must distinguish between 3 basic 
types of multimedia content and content consumption. These are Live-streaming, 
video on demand and static content. They differ in their real-time criticalness, which 
is very high for live-streaming as it does not allow a big pre-buffering, followed by 
video on demand, which does allow pre-buffering. Static content is basically classic 
file sharing, which has no hard real-time requirements, it is finished when it is 
finished, or when the user decides to cancel the download, because it takes too long 
for him. Hence, P2P content delivery can help to unburden media servers or make 
them superfluous. 
This is also the reason, why user-generated content experiences better support by 
P2P content delivery. A content generating user node can be seen as media server 
with extremely small banded upload capacities. Making it stream to every content 
sink is impossible by concept. The “IMS-way” would be to stream the content over a 
media server, resulting in the known load and availability problems of media servers. 

 
Extending an IMS Client with Peer-to-Peer Content Delivery 
201 
The P2P approach here makes it much easier for a user to place its own content in the 
network. 
4   Relevant Extensions 
The question of how an IMS client extension should look alike in a generic way, 
refers to the underlying question of how the architecture of a suitable IMS client 
should look like. The requirements for the architecture of an IMS client contain a 
modular and extensible design and should be conforming to the relevant standards to 
ensure interoperability with other IMS components. The architecture should roughly 
be able to be subdivided into at least three abstract layers. Additional requirements to 
the IMS client are, for instance: on top a presentation layer, in the middle an 
application layer and at the bottom a service layer. 
'h/
ƵĚŝŽ
ĐĂƉƚƵƌŝŶŐ
ͬ
ƉůĂǇŽƵƚ
sŝĚĞŽ
ĐĂƉƚƵƌŝŶŐ
^ĞƐƐŝŽŶ
ŵĂŶĂŐĞŵĞŶƚ
sŝĚĞŽ
ƉůĂǇŽƵƚ
WƌĞƐĞŶĐĞ
ĂůůŝŶŐ
DĞƐƐĂŐŝŶŐ
^/W
EĞƚǁŽƌŬ
ZdWͬZdW
WƌĞƐĞŶƚĂƚŝŽŶ
>ĂǇĞƌ
ƉƉůŝĐĂƚŝŽŶ
>ĂǇĞƌ
^ĞƌǀŝĐĞ
>ĂǇĞƌ
 
Fig. 2. Generic IMS Client Layer Model 
The presentation layer is responsible for the interaction with the user. It should be 
designed to be easily extensible, in order to implement new features and display 
options. The presentation layer has to handle different endpoints like mobiles or 
desktops concerning the presentation technology and has to provide a suitable 
adaption of it. 
The application layer enables the client functionalities like calling or messaging. 
Events coming from the user interface have to be interpreted and translated into 
program operations to provide the user interaction with the client. These operations 
then will trigger services in turn.  
The service layer provides core services of the IMS client and provides an API to 
the upper layer for e.g. SIP-messaging for IMS-core interaction.  
The described model is depicted in Fig. 2. 

202 
J. Fiedler, T. Magedanz, and J. Müller 
The following example maps the messaging service to the three presented layers. 
The user A sends a message to user B with an IMS client. Thereby the presentation 
layer interacts with the user over e.g. a text field for message content, the receiver 
selection and the send button. The presentation layer also includes the media capture 
and play-out capabilities. The application layer provides methods to write and store a 
message, send a message via the IMS core to the receiver(s) and handles incoming 
messages. The service layer provides the API to use the underlying SIP stack to 
perform the necessary SIP operations to send the message. 
If we now want to extend the client with P2P functionalities, a protocol for the 
communication between the peers is needed. All P2P tasks e.g. management of the 
overlay or DHT functionalities like put and get are message based. Since all 
participating peers are instantiated through IMS clients which uses the SIP protocol, it 
is assumed that the IMS client architecture comprised a SIP stack.  
One important technique of the domain software engineering is to reuse existing 
parts. In our case the existing SIP-stack should be reused and extended to provide an 
API for using P2PSIP (s.a.) operations.  
The obvious challenges of extending a SIP-stack with the methods of P2PSIP base 
upon the fact that SIP uses the unique SIP-URI to address a recipient whereas P2PSIP 
in contrast uses the IP and port information of the client. The P2PSIP functionality 
should be realized in the service layer to provide its service to the higher layer. 
There are task specific functionalities which could be grouped as the following 
functional blocks: general functions, overlay management, DHT, media streaming 
and file sharing. 
  
The general P2P functions are: 
• Determine the next hop, which realization depends on the used P2P algorithm. The 
presence of NAT lead to the fact that there occur cases in which the sending peer 
isn't able to reach the requesting peer directly and has to route packages indirectly 
to the requesting peer. All following tasks assume the appliance of this function to 
ensure a more reliable communication. 
• A method for generating hashes uses a known cryptographic hash function like 
(MD5) to generate hashes e.g. out of the unique IP address and port combination of 
a peer or the name of a given value. 
  
The overlay management functions are: 
• A peer uses the join method to participate in an overlay. This task has to be divided 
in the active and passive case. The active part would be the bootstrapping, where a 
new peer (N) contacts a known bootstrap peer (B) to receive an overlay position 
with the contact information of its successor peer (S) and its predecessor peer (P). 
• The passive part of joining an overlay would be 
• The task of the bootstrapping peer (B) describes the passive part of joining an 
overlay, in which peer (B) has to organize the arrival of peer (N). The resulting 
tasks are organizationally to maintain the overlay structure after the new peer (N) 
has finished the process of joining the overlay. The two adjacent peers (S) and (P) 
of (N) have to be informed of its arrival, what results in the modification of their 
routing tables in case of a DHT based algorithm like Chord. 

 
Extending an IMS Client with Peer-to-Peer Content Delivery 
203 
• To leave a network in a polite way means that the leaving peer (L) informs all 
relevant peers and to pass optionally stored values to peers which are responsible, 
when (L) leaves the overlay.  
The DHT functions are: 
• The method lookup maps a hash to an IP address and port tupel and is able to 
associate a key with a peer. 
• Since everything has its place in a DHT, each value has its defined place which 
depends on its referring hash. To store a value in the way that other peers are able 
to find it, a hash function is used to map the name of the value into an unique hash 
value: the key referring this value. The number space of the keys and that of the 
peerIDs were equal, which facilitates to assign a value with the help of its key to a 
peer.  
• To store a value in the DHT, a hash of the value has to be generated which refers to 
peer (R). Peer (R) has to be determined with the use of the hash function in 
combination with the lookup method. Finally a reference to the value has to be 
send from the initiating peer to the peer (R).  
• The get method is used to retrieve a value out of the overlay from other peers. 
Thereby a hash of the requested value identifies the referring peer (R). The 
requesting peer performs a lookup of the value and retrieves the contact 
information of the peer (S), which stores the value. Now the requesting peer is able 
to address peer (S).  
The streaming functions are: 
• The method send is used to send a particular part of a stream to a requesting peer. 
• The method request_stream requests a specific part of a stream from a parent node. 
• The method receive stores all requested parts of the stream to re-assemble them to 
a single stream. The parts needed to be encoded independent of other parts, that 
they are able to be consumed in pieces. 
• The method receive_request_stream handles an incoming request for a part of a 
stream. Either the request is allowed or it will be rejected. In case of free resources 
of the requested peer the demanding peer will be delivered with the requested part 
of the stream. In case of high utilization or missing capabilities a cancelation will 
be send to the requesting peer.  
The file sharing methods are: 
• The method request_block is used to request a specific part of a whole file from a 
known source. 
• With the help of receive_block a requested part can be received. 
• The interaction of the peers needs the receive_request_block method which 
handles block requests which are either served to the demanding peer in case of 
free recourses or rejected in case of problems. 
• The method send_block finally sends a block to the requesting peer. 
  

204 
J. Fiedler, T. Magedanz, and J. Müller 
To realize the mentioned P2P functions in the presented IMS client architecture, the 
following extensions need to be performed to the existing layers. Fig. 3 illustrates the 
distribution of the functional blocks over the different layers. 
The presentation layer should be extended with two control mechanisms. First the 
control of P2P streams like: select, start, stop, pause of a requested object have to be 
handled. The second part covers the content presentation with VRC controls like: 
start, stop and pause. As these changes affect only the GUI, they are not depicted in 
Fig. 3. 
'h/
ƵĚŝŽ
ĐĂƉƚƵƌŝŶŐ
ͬ
ƉůĂǇŽƵƚ
sŝĚĞŽ
ĐĂƉƚƵƌŝŶŐ
^ĞƐƐŝŽŶ
ŵĂŶĂŐĞŵĞŶƚ
sŝĚĞŽ
ƉůĂǇŽƵƚ
WƌĞƐĞŶĐĞ
ĂůůŝŶŐ
DĞƐƐĂŐŝŶŐ
^/W
EĞƚǁŽƌŬ
ZdWͬZdW
WƌĞƐĞŶƚĂƚŝŽŶ
>ĂǇĞƌ
ƉƉůŝĐĂƚŝŽŶ
>ĂǇĞƌ
^ĞƌǀŝĐĞ
>ĂǇĞƌ
WϮW^/W
ǆƚĞŶƐŝŽŶ
WϮWͲ^ƚƌĞĂŵŝŶŐ
WϮWͲ&ŝůĞ^ŚĂƌŝŶŐ
WϮW'ĞŶĞƌĂů
&ƵŶĐƚŝŽŶƐ
WϮW,d
WϮWKǀĞƌůĂǇ
DĂŶĂŐĞŵĞŶƚ
 
Fig. 3. Extended Generic IMS Client Model 
The tasks of the application layer are extended with the previously introduced 
functional blocks: general functions, overlay management, DHT, media streaming 
and file sharing. 
The service layer is extended with P2PSIP as a new service. This is attached to the 
existing SIP stack and needs no extra network operation by itself, but provides an API 
to the application layer. 
5   Case Study: MONSTER 
The Fraunhofer FOKUS MONSTER IMS client aims the rapid development and 
prototyping of NGN and internet applications.  
The most motivating factors to use this client are its modular architecture, its 
platform independence with a pure java implementation plus it is deployable on target 
platforms like mobiles, laptops and desktops as well. The MONSTER client is 
standard conform and extended the JSR281 specification which provides a high-level 
API to access IP Multimedia Subsystem (IMS) services. This API hides IMS 
technology details and exposes service-level support to enable easy development of 
IMS applications. In February 2009 MONSTER will be offered as free-to-use. It will 

 
Extending an IMS Client with Peer-to-Peer Content Delivery 
205 
provide several free basic functions and will be extensible through an open API which 
provides interfaces to enhance and extend its functionalities [8]. 
Since the architecture of MONSTER is modular, it is possible to divide its 
architecture into the three main parts of a presentation, an application and a service 
layer. Thereby it is possible to apply the presented P2P extension on it. The layers 
have to be modified as follows. 
The presentation layer of MONSTER provides interaction with the P2P module to 
perform the requested tasks of the user. These consist of the control of the requested 
content and the playback handling with the common video recording functions. 
The functional blocks from chapter 4 (general, management, DHT, streaming, file 
sharing) have to be aggregated to a P2P module which is needed to be adapted to the 
application layer. 
The domain of event handling needed to be extended, too. Notifications are 
redirected to the P2P module for sending or receiving P2PSIP messages or their 
retransmission.  
The functional blocks are message based and needed to reply incoming requests 
automatically. Therefore an instance is needed, which is able to answer requests 
automatically, by performing the required P2P specific tasks.  
The used SIP-stack of MONSTER has to be modified and extended to provide 
P2PSIP in the service layer. To reuse the SIP stack, a type P2PSIP message has to be 
derived from the type SIP message. 
Since each client communicate only directly to the PCSCF on a fix port over SIP, 
P2PSIP has to address clients dynamically on different ports and IP addresses.  
 
 
Fig. 4. MONSTER architecture 
 

206 
J. Fiedler, T. Magedanz, and J. Müller 
Fig. 4 depicts the interaction of the P2P module with the MONTER client. The P2P 
module is connected with the core service of monster as well as directly with the 
internet. Additional features of the MONSTER client are presented like the OCS-X 
Parley Interface, which is used for IPTV and VoD. The Web 2.0 Enabler allows the 
aggregation of web feeds like news, weather, Flickr, Facebook or Google APIs. The 
XDM Server enables service configuration like group management or presence.  
6   Conclusions and Future Work 
In this Paper, we have presented a generic approach to extend IMS clients with P2P 
functionalities. As an example, the necessary extensions to the Fraunhofer FOKUS 
MONSTER IMS client framework have been explained and depicted. Nevertheless, 
while exploring the potential of P2P and IMS coupling, it became obvious that many 
features require additional support of IMS components. As an example, authentication 
needs to be named along with the possibility to use the underlying NGN components 
for quality-of-service (QoS) control between peers. Also, the creation of topology 
aware overlays can be supported with knowledge from IMS core components. A 
topology aware overlay can drastically reduce latency and cross-network traffic, 
resulting in a reduction of costs for avoiding redundant traffic.  
Also content integrity and security need to be addressed. These are major problems 
of open P2P systems, where content poisoning and copyright infringements are a 
daily appearance. Also more complex approaches to detect copyrighted content could 
be considered, like distributed content fingerprint detection. 
Another thing is the question “Do other P2P services require other operations?” It 
is very likely, that e.g. a P2P community management will require different 
operations than those which are presented here. Nevertheless, the presented approach 
can be easily extended to integrate new operations, due to its modular construction. 
Acknowledgements 
Many thanks go to the MONSTER developer team at the group for Next Generation 
Networks Infrastructures (NGNI) at the Fraunhofer FOKUS Institute in Berlin, 
Germany for inspiring discussions. 
The work presented in this paper is related to the ongoing EU project VITAL++. 
VITAL++ is a Specific Targeted Research Project (STREP) supported by the 
European 7th Framework Programme, Contract number ICT-2-1.6-224287, Project 
starting date 1st June 2008 (duration 30 months). 
References 
[1] Magharei, N., Rejaie, R., Guo, Y.: Mesh or Multiple-Tree: A Comparative Study of Live 
P2P Streaming Approaches. In: 26th IEEE International Conference on Computer 
Communications (INFOCOM), pp. 1424–1432. IEEE Press, Anchorage (2007) 
[2] Rosenberg, J., Schulzrinne, H., Camarillo, G., Johnston, A.R., Peterson, J., Sparks, R., 
Handley, M., Schooler, E.: SIP: session initiation protocol, RFC 3261, IETF (June 2002) 

 
Extending an IMS Client with Peer-to-Peer Content Delivery 
207 
[3] Calhoun, P., Loughney, J., Guttman, E., Zorn, G., Arkko, J.: Diameter Base Protocol. RFC 
3588, IETF (September 2003) 
[4] Singh, K., Schulzrinne, H.: Using an External DHT as a SIP Location Service, Columbia 
University Technical Report CUCS-007-06, New York, NY (Feb. 2006) 
[5] Stoica, I., Morris, R., Karger, D., Kaashoek, M.F., Balakrishnan, H.: Chord: A Scalable 
Peer-to-Peer Lookup Service for Internet Applications. In: SIGCOMM (2001) 
[6] Bryan, D., Matthews, P., Shim, E., Willis, D., Dawkins, S.: Concepts and Terminology for 
Peer to Peer SIP, draft-ietf-p2psip-concepts-02, IETF, July 7 (2008) 
[7] Jennings, C., Lowekamp, B., Rescorla, E., Baset, S., Schulzrinne, H.: Resource Location 
And Discovery (RELOAD), draft-ietf-p2psip-reload-00, IETF, July 11 (2008) 
[8] Bachmann, A., Motanga, A., Magedanz, T.: Requirements for an extendible IMS client 
framework. In: ACM International Conference Proceeding Series, vol. 278 (Feburary 
2008) 
[9] Liotta, A., Ling, L.: The Operator’s Response to P2P Service Demand. In: 
Communications Magazine. IEEE, Los Alamitos (2007) 
[10] Fiedler, J., Magedanz, T., Menendez, A.: IMS secured content delivery over peer-to-peer 
networks. In: Proceedings of SIGMAP 2007, Spain, July 28-31, 2007, pp. 5–12. INSTICC 
Press, Portugal (2007) 
[11] TS 23.228, IP multimedia subsystem (IMS), 3GPP (2006) 
 

C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 208–221, 2009. 
© Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009 
Digital Terrain Model Interpolation for Mobile Devices 
Using DTED Level 0 Elevation Data 
Murat Ozyurt, Tuna Tugcu, and Fatih Alagoz 
Bogazici University Department of Computer Engineering  
P.K. 2 TR-34342 Bebek, Istanbul, Turkey  
{murat.ozyurt,tugcu,alagoz}@boun.edu.tr 
Abstract. Digital maps provide altitude data for regions on Earth. The amount 
of data to be processed increases with O(n2) complexity when resolution detail 
of the map in use increases. As the storage and processing capacity of handheld 
mobile devices are very limited compared to regular computer systems,  
the amount of data that can be stored in the device memory is also much less 
than of more complex computer systems. DTED Level 0 data provides 
approximately 1km resolution of elevation data which requires smaller storage 
space. The points in between the sampled points can be interpolated making use 
of the interpolation algorithms, with the addition of two sets of extra points 
whose coordinates are determined according to the existing sample points.  
Keywords: Mobile 3D Navigation Terrain Interpolation. 
1   Introduction 
DTED points are organized in a grid structure with sample points on the intersection 
of grid lines, which form the cells of the region. Each cell has a special data set 
indicating maximum, minimum and average elevation values of points that exist in 
the DTED Level 1 elevation data of the same region [1]. 
During DTED Level 0 data sampling from DTED Level 1 data, the maximum and 
minimum elevation values of the points in the cell are recorded with the average 
elevation value of all the points in the cell [2]. 
 
Fig. 1. Top view of a sample DTED level 0 grid of 3D terrain cells 

 
Digital Terrain Model Interpolation for Mobile Devices 
209 
The article is to propose an interpolation formulation that produces an elevation 
value for any point within the cell boundary, regardless of the resolution level 
preferred for the target application.  
 
Fig. 2. Conversion from DTED level 1 to DTED level 0 
2   Motivation 
A 3D navigation application [3] has been developed for mobile devices with pre-
generated elevation data. Although the geographical area was 120x120 km2 wide, the 
model had to be divided into 100 cells consisting of 50x50 elevation points each, in 
order to fit into the memory of the device. The elevation data for this small region 
takes more than 10MB of storage space and the distance between two points is nearly 
240 meters. 
Limitations on storage capacity lead to alternative methods for terrain generation. 
Interpolation from fewer points provides ability to store larger geographical regions 
on small memories. Sampling elevation data points with a relevant resolution, storing 
only the sample points and interpolating the area between these points at any 
resolution whenever necessary is a solution approach for mobile 3D navigation 
storage problem. 
 
 
Fig. 3. Mobile 3D navigation prototype application 

210 
M. Ozyurt, T. Tugcu, and F. Alagoz 
3   Digital Terrain Modeling 
Several methods exist for obtaining digital representation of Earth surface [4],[5],[6]. 
Qualities of these methods can be measured by their precision in elevation values and 
the percentage of data that are within the precision boundaries [7],[8]. Considering 
DTED Level 0 type of digital elevation data representation, data points are sampled 
with approximately 1 km apart both in latitude and longitude. In such a case precision 
quality naturally becomes a rather secondary constraint for mobile device applications 
using that sort of model data, while storage and processing are more crucial resources. 
    
Fig. 4. Terrain cells in 3D view 
Interpolation algorithms can be used to estimate the elevation value of a certain point 
that has not been provided in DTED Level 0 data. Interpolation result is directly related 
to number of point parameters involved in the interpolation. Algorithms discussed in 
this paper make use of sample points; maximum, minimum and average elevations. 
4   Locating Maximum and Minimum Points 
Sample points are located on the corners of the cells. For each cell, maximum and 
minimum elevation values are defined but their location is unknown in detail Level 0. 
Considering a sample cell, the corner points can be labeled as “p1” corresponding to 
South-West corner, “p2” to South-East corner, “p3” to North-East corner and “p4” to 
North-West corner.  
If at least one of the corner points has a different elevation value from the others, 
then a point “p5” is introduced as the maximum point, and another point “p6” is 
introduced as the minimum point of the cell. Locations of these two points are 
determined with respect to their elevation differences from all corner points. This 
method can be named as “singular positioning of maximum and minimum points”. 
Each cell with a maximum elevation value higher than all corner points contains at 
least one hill shaped geographic structure and each cell with a minimum elevation 
value lower than all corner points contains a hollow sunk shaped geographic structure. 
The principle in locating the maximum elevation point “p5” is “the higher altitude 
has a corner point, the closer it is to the maximum point” and similarly the principle 
in locating the minimum point “p6” is “the lower altitude has a corner point, the 
closer it is to the minimum point”. 
 

 
Digital Terrain Model Interpolation for Mobile Devices 
211 
 
Fig. 5. Sample cell with corner points numbered 
 
Fig. 6. Sample smooth interpolation with 4 corner points 
The reference system used throughout the paper for coordinates of the points is 
Cartesian coordinate system for simplicity of the explanation. Although the DTED 
implementation is a rather more complex algorithm involving longitudinal and 
latitudinal calculations, point coordinates are calculated relative to the existing points 
and this makes the algorithm applicable to any reference system.  
Without determining coordinates of p5 and p6, a smooth interpolation algorithm 
would yield a surface that all points are elevated only according to the available 
corner points, missing the information provided as maximum elevation and minimum 
elevation. Modifications can be made for the parameters of the algorithm to obtain 
close average elevation values to the average elevation value provided in the cell, but 
still lacking close to real view of the cell.  
For the following conditions, maximum and minimum points are located in the 
same coordinate pair, and another locating method called “circular positioning of 
maximum of minimum points” is to be used. These conditions are as follows:  
a.   All two non-adjacent sample point pairs have the same elevation values. (e.g. 
NW has same elevation with SE and NE has same elevation with SW) 
b.   All four sample points have the same elevation values. 
4.1   Singular Positioning 
Maximum and minimum points are positioned based on their elevation difference 
from sample points on the cells. First step in locating maximum or minimum point is 

212 
M. Ozyurt, T. Tugcu, and F. Alagoz 
to pair sample points with one of their neighboring points that has not been paired 
before, to obtain two distinct pairs (e.g. NW point paired with NE point and SW point 
paired with SE point) and partition the distance between two points in each pair into 
two segments, where the length of each segment is directly proportional to its 
elevation difference from maximum or minimum elevation value. 
 
Fig. 7. Interpolation after maximum and minimum points located 
When positioning the maximum elevated point, an elevation parameter E can be 
assigned the value of the maximum elevation. In case of positioning the minimum 
elevated point, E can be assigned the value of minimum elevation value.  
 
        E={ 
Maximum altitude, if positioning maximum point, 
Minimum altitude, if positioning minimum point. 
(1) 
 
If pI and pII are two points whose coordinates along with maximum and minimum 
elevation values of the cell will be used to calculate coordinates of an intermediate 
point pIII on the line connecting pI and pII, then the distance between pI and pII can 
be scaled to sum of difference between maximum or minimum elevation and 
elevation of pI, i.e. pIz, and difference between maximum or minimum elevation and 
pIIz, depending on case of positioning maximum point or minimum point.  
If distance between pI and pIII is ∆dI and distance between pIII and pII is ∆dII 
then scaling according to elevation differences can be performed as; 
 
∆dI  /  (∆dI  +  ∆dII)  =  (E – pIz)  / ((E – pIz) + (E – pIIz))                         (2) 
 
The coordinates of pIII, can be calculated as;  
pIIIx = pIx + ∆x,                                                        (3) 
pIIIy = pIy + ∆y,                                                        (4) 
pIIIz = pIz  + ∆z,  where;                                           (5) 
∆x = (∆dI / (∆dI + ∆dII)) (pIIx – pIx),                                 (6) 
∆y = (∆dI / (∆dI + ∆dII)) (pIIy – pIy),                                 (7) 
∆z = (∆dI / (∆dI + ∆dII)) (pIIz – pIz ).                                 (8) 

 
Digital Terrain Model Interpolation for Mobile Devices 
213 
Second step is to determine the elevation values of two points that are on the 
segmentation locations, linearly approximated from the two sample corner points 
constituting in the location of these points. Whenever these points are located and their 
elevation values are calculated, the distance between these points is also partitioned into 
two segments, where segment lengths are again proportional to elevation difference 
from maximum or minimum elevation value. The location that has just been found 
stands for longitude and latitude values of maximum or minimum point. 
In the sample cell, trying to locate the maximum point (p5), p1 and p2 are used to 
locate p5-I while p3 and p4 are used to locate p5-II. Afterwards p5-I and p5-II are 
used to locate p5. For p6, the minimum point; p1 and p2 are used to locate p6-I while 
p3 and p4 are used to locate p6-II. Later on p6-I and p6-II are used to locate p6.  
 
 
Fig. 8. Locating Segmentation Points. (Points Projected on x-y Plane). 
 
 
Fig. 9. Singular positioning of maximum and minimum points  
4.2   Circular Positioning 
If maximum elevation value is more close to average elevation value of the cell than 
minimum elevation value, this indicates that elevation values of most of the points in 
the cell are over average, and vice versa. If majority of the points are higher than 
average, the minimum point is located in the center of the cell and several maximum 
points are located on a concentric circle surrounding minimum point. If majority of 
the points are lower than average, the maximum point is located in the center, with 
several minimum points surrounding it. 
L = min{(Latitudinal width),(Longitudinal width)}                      (9) 
 
p4 
p3 
p5 
p6 
p5-II 
p6-II 
p6-I 
p2 
p5-I 
p1 

214 
M. Ozyurt, T. Tugcu, and F. Alagoz 
 
Fig. 10. Circular positioning 
Defining MAX as maximum elevation, AVG as average elevation, MIN as 
minimum elevation and L as the smaller of the latitudinal and longitudinal lengths of 
the cell, a circular region with radius R, that separates high altitude points from low 
altitude points, can be defined as; 
 
 R2 / (L/2)2  =  h1  / (MAX – MIN), where,                          (10) 
 h1 = min{(MAX – AVG), (AVG – MIN)}.                        (11) 
 
Comparing area inside this circle to the area outside, the inner portion is 
proportional to the smaller of the difference between MAX and AVG elevations, and 
difference between AVG and MIN elevations.  
 
Fig. 11. Central cross-sections for MAX or MIN in the center 
 
Fig. 12. Cell with opposite corners having same elevation 
 
  

 
Digital Terrain Model Interpolation for Mobile Devices 
215 
If MAX–AVG is smaller than AVG–MIN, then the number of points with elevation 
values higher than average elevation is more than those with elevation values lower 
than average elevation. This requires the smaller portion of the cell area to be 
occupied with low altitude points and the rest to be occupied with higher points, 
meaning that the minimum point will be placed in the center of the cell with several 
maximum points around. 
The algorithm includes control points around minimum and maximum points with 
intermediate elevation values, which are used to keep the interpolation algorithm 
smooth. Having calculated R, two other radius values, namely Rin and Rout, are 
obtained for inner and outer control points respectively, where;  
 (Rin)2 / (R)2  =  h2 / (MAX – MIN), with,                        (12) 
 h2 = MAX – MIN – h1 ,   and,                               (13) 
 Rout = ( R + L/2  ) / 2                                          (14) 
 
 
Fig. 13. Circular positioning details 
 
 
Fig. 14. Circular positioning with elevations: MAX – AVG > AVG - MIN 
Inner control points are four points located with 900 apart on the Rin circle with 
their elevations offset as much as ∆hin from elevation of the central point in the 
direction of AVG elevation, where, 
 
    ∆hin / h2 = h1 / (MAX - MIN)                                    (15) 
 

216 
M. Ozyurt, T. Tugcu, and F. Alagoz 
Four outer control points are located 900 apart on a circle with radius Rout – ∆r, and 
another four located 900 apart on the circle with radius Rout +  ∆r, where; 
 
     ∆r = Rout – (R + a),      with a obtained from    (16) 
 
      R2 / (R+a)2 = h2 / ( MAX – MIN )                                (17) 
 
Elevations of outer control points are offset as much as ∆hout from elevation of the 
points on the Rout circle in the direction of AVG elevation, where, 
 
 ∆hout / h1 = h1 / ( MAX – MIN ).                                  (18) 
Having calculated positions and elevations of all maximum, minimum and control 
points, four more points are to be located on the Rout circle with 450 offset from the 
points on Rout circle and with 900 apart from each other, with elevation values equal to 
that of the average elevation value of the cell. These points avoid abrupt elevation 
differences between the corner points and the rest of the cell. 
 
Fig. 15. Circular positioning with elevations: MAX – AVG < AVG – MIN 
 
Fig. 16. Sample region with 14400 cells 

 
Digital Terrain Model Interpolation for Mobile Devices 
217 
5   Cell Generation with Interpolation 
As soon as all maximum and minimum points are located, inverse distance weighting 
algorithm (IDW) [9],[10] is utilized to find elevation value of a specific coordinate 
within the cell. Reconstruction of higher level DTED with this methodology yields a 
close value to the average value specified in the DTED Level 0 data of the cell. 
IDW algorithm is based on weights that are calculated relative to the distance 
values of the point of which the elevation value is to be interpolated from the 
reference points with known elevation values. A weighted elevation value can be 
calculated as sum of weight values multiplied by the corresponding elevation value of 
the reference point that the weight has been calculated for.  
For “n” reference points, if wi indicates the weight value of a reference point and 
pzi indicates the elevation value of that point, weighted elevation we is obtained from: 
                             
   we =  ∑ (wi)(pzi)                                            (19) 
i =1..n 
 
A vector W of size “n” for weight values of reference points can be obtained by 
multiplying an n-by-n inverted distance matrix D-1 of the reference points with a 
distance vector V of the point that is to be interpolated. V contains distance values 
calculated as distance of the point to be interpolated, from reference points, on the x-y 
plane, while D contains the distance values of each reference point from all other 
reference points.  
 
 
                                    D =  
 
d11, d12, … , d1n 
d21, d22, … , d2n 
  .       .             . 
dn1, dn2, … , dnn 
 
 (20) 
 
In order to construct D, x-y distances of each reference point with other reference 
points are represented as a row in the matrix where dij on the ith row and jth column of 
the D matrix indicates the x-y distance of the ith reference point to the jth reference 
point. Similarly the V column vector is constructed with values di which is the x-y 
distance of the interpolation point to the ith reference point. 
 
  
                                             V =  
  d1 
  d2           
   .        
  dn 
 
 
(21) 
 
The n-by-1 weights vector W with wi in each row indicating weight value of ith 
reference value is then available in the form: 
 
W = D-1 x V.                                                       (22) 
After all reference points are determined, either using linear interpolation or 
circular interpolation, elevation value of a certain point can be estimated from the 
available reference points using the above formulation.  

218 
M. Ozyurt, T. Tugcu, and F. Alagoz 
6   Results 
In order to simulate a DTED Level 0 data set, a grey scale image of size 6001x6001 
pixels has been generated where darker pixels indicate lower altitudes and the area is 
considered to be 120x120 km2 wide and altitudes of the points are scaled to 0-4000 
meters range. Since the cells of DTED level 0 are generated from cells of DTED 
Level 1 data that contain 11x11 points each, the sample region covers 
120x120=14400 cells which is a reasonable simulation setup for the interpolation. 
Maximum, minimum and average values of each cell are calculated from the available 
points in the region.   
As each cell has a fixed average value calculated from real points, the two 
methodologies are compared in terms of closeness to the real average value. For each 
cell, all points within the cell are interpolated with both algorithms and their averages 
are calculated. For different number of points in the cells, the interpolation results for 
closeness to the average value can be observed on the following table as percentage of 
each algorithm yielding closer values over 14400 cell average values [11]. 
Interpolation algorithm is run to obtain interpolated cells with various resolutions. 
For detail level 11x11, among 14400 cells, IDW algorithm with only four points 
yields average elevation values more closer to the real average values than IDW 
algorithm that uses extra points, in 2.28% of the cells. In 96.67% of the cells, IDW 
with extra points yields smaller average elevation difference with real average, than 
IDW with four points. In 1.06 % of the cells, both methods yield equal average 
elevation difference values. 
Table 1. Closeness to real average 
 
% Of Cells, Where Each 
Method Finds Better Average 
Mean And Standard Deviation Of Average 
Value Difference For Each Method 
Cell 
Size  
(points) 
IDW  
IDW 
extra  
Equal 
Distance 
Mean 
for 
IDW  
Std.Dev. 
for IDW  
Mean for 
IDW 
extra  
Std.Dev. 
for IDW 
extra  
6x6 
3.55 % 
93.69 % 
2.76 % 
-57.74m 
45.38m 
-40.7 m 
39.05m 
11x11 
2.28 % 
96.67 % 
1.06 % 
-68.72m 
52.13m 
-44.1 m 
43.38m 
26x26 
1.82 % 
97.63 % 
0.56 % 
-77.39m 
56.58m 
-42.4 m 
43.76m 
51x51 
1.57 % 
97.83 % 
0.60 % 
-81.47m 
58.35m 
-39.6 m 
42.34m 
Table 2. Closeness to real elevation values 
 
% Of Cells, Each Method 
Finds Elevation Value Closer 
To Real Elevation Values  
Mean And Standard Deviation Of Elevation 
Value Difference For Each Method 
Cell 
Size  
(points) 
IDW  
IDW 
extra  
Equal 
Distance 
Mean for 
IDW  
Std.Dev. 
for IDW 
Mean 
for IDW 
extra  
Std.Dev. 
for IDW 
extra  
6x6 
17.30% 
46.38% 
36.32% 
-57.40m 
68.50m 
-40.52m 
63.05m 
11x11 
16.20% 
57.30% 
26.49% 
-68.35m 
71.25m 
-43.84m 
63.78m 
26x26 
14.10% 
67.84% 
18.06% 
-76.99m 
72.91m 
-42.18m 
62.03m 
51x51 
13.16% 
73.09% 
13.75% 
-81.07m 
73.72m 
-39.46m 
60.24m 

 
Digital Terrain Model Interpolation for Mobile Devices 
219 
In terms of mean and standart deviation as comparison metrics for the quality of 
interpolation methods, considering 11x11 interpolation scenario, IDW with four 
points yields a mean value of 68.72 meters below the real average values with a 
standart deviation of 52.13 meters, whereas IDW with extra sample points yields a 
better mean value of 44.10 meters below the real averages and a standart deviation of 
43.38 meters. Increase in detail level results in worse mean and standard deviation 
values for IDW using four points, while mean and standart deviation values for IDW 
with extra points are reasonably stable. 
All interpolated points of two methods have been compared analogous to Head and 
Hat algorithm [12] for surface matching in 3D magnetic resonance imaging. The 
distances of interpolated elevation values to the real elevation value of each point are 
compared for 14400 cells with varying number of points for different detail levels. 
For 11x11 resolution of interpolated cells, there are 1,742,400 point involved in 
interpolation. A fixed number of points, 14400x4 = 57600, correspond to the corner 
points with known elevation values causing lower resolution levels to yield higher 
percentage of equal elevation difference for two methods. 
For all interpolated points, IDW with four points gives smaller elevation difference 
in 16.20% of all interpolated points, while IDW with extra points produces smaller 
elevation difference than IDW with four points in 57.30% of all points. The two 
methods calculate equal elevation difference in 26.49% of all points, including the 
57,600 corner points that have zero elevation difference in both methods.  
In simulation of 11x11 resolution level of cells, mean elevation difference for all 
interpolated points of IDW with four points is 68.35 meters below the real elevation 
 
Table 3. Points with less than 50 and 20 meters interpolated elevation difference 
Cell 
Size  
Total 
Points  
IDW 
50m. 
IDW 
20m. 
IDW Extra 
50m. 
IDW Extra 
20m.  
6x6 
518,400 
58.39% 
33.30% 
66.72% 
42.67% 
11x11 
1,742,400 
50.46% 
23.68% 
64.03% 
37.39% 
26x26 
9,734,400 
43.35% 
17.68% 
64.91% 
37.06% 
51x51 
37,454,400 
39.67% 
15.76% 
66.43% 
37.97% 
 
Fig. 17. Distribution of point elevation difference values. (number of points vs. meters). 

220 
M. Ozyurt, T. Tugcu, and F. Alagoz 
of the points, with a standard deviation of 71.25 meters. For IDW with extra points, 
mean value is 43.84 meters below the real elevation values, with a standard deviation 
of 63.78 meters. Increase in detail level results in worse mean values for IDW using 
four points, while mean values for IDW with extra points are reasonably stable.
The percentage of points that are interpolated by IDW using four points, with less 
than 50 meters difference from their real elevation values is 50.46% in 11x11 detail 
level simulation, where at the same time IDW with extra points produces a value of 
64.03% within 50 meters elevation difference boundary. 
Similarly the percentage of points that are interpolated by IDW using four points, 
with less than 20 meters difference from their real elevation values, is 23.68% in 
11x11 detail level simulation. IDW with extra points produces a value of 37.39% 
within 20 meters elevation difference boundary. Although it seems that IDW using 
four reference points has a higher percentage of points within 50 and 20 meters 
boundaries in low resolution interpolations, this is because of 57,600 corner points 
that are interpolated with 0 elevation difference, taking up a relatively large fraction 
of total points. 
7   Conclusion and Future Work 
Additional to several terrain generation algorithms [13],[14],[15] that produce either 
random terrain surfaces with various parameters, or surfaces based on predefined set 
of constraints, we introduce extra information to be used in those algorithms for 
DTED Level 0 type of detail levels.  
Adding more points to the four corner points of each DTED Level 0 cell data, it is 
possible to obtain better interpolation values for elevations of unknown points. Using 
inverse distance weighting algorithm in interpolation with additional reference points 
yields a closer average value for  an entire cell, to the real cell average, in more than 
90% of 14400 sample cells, compared to IDW algorithm applied only to four corner 
points of DTED Level 0 data.  
This algorithm will be utilized in the mobile implementation of a 3D Navigation 
system. For the time being, the application uses static points at a resolution of 240m 
and this algorithm will bring in the flexibility of resolution variability to be used in 
civil applications [16],[17].  
Acknowledgments 
This research has been partially supported by The State Planning Organization of 
Turkey (DPT), under grant number DPT 07K120610. Ms. Aslı Bassa, Université 
Joseph Fourier, has also documented her contributions in her training report. 
References 
1. Darrah, C., Luke, D.: Site-specifc clutter modeling using DMA Digital Terrain Elevation 
Data (DTED), Digital Feature Analysis Data (DFAD), and Lincoln Laboratory five 
frequency clutter amplitude data. In: IEEE National Radar Conference - Proceedings, pp. 
178–183 (1996) 

 
Digital Terrain Model Interpolation for Mobile Devices 
221 
2. Magee, M., Collier, M., Cornell, D., Leal, J.: A system for the generation of digital terrain 
elevation data (DTED) from compressed Arc digitized raster graphics (CADRG) images. 
In: Proceedings of SPIE - The International Society for Optical Engineering, vol. 3454, pp. 
293–304 (1998) 
3. Ozyurt, M., Tugcu, T., Alagoz, F.: Effective Large Area Tactical Land Marking on 3D 
Mobile WLAN and GPS Enabled Devices. In: Proceedings International Workshop On 
Small Satellites, New Missions And New Technologies, Istanbul (2008) 
4. Weibel, R., Heller, M.: A Framework for Digital Terrain Modelling. In: Proceedings 4th 
International Symposium on Spatial Data Handling, Zürich, vol. 1, pp. 219–229 (1990) 
5. Weibel, R.: Digital Terrain Modelling for Environmental Applications: A Review of 
Techniques and Trends. In: Joint European Conference on Geographical Information 
(JECGI), Vienna, Austria, pp. 464–474 (1997) 
6. Leighty, B., Rinker, J.: The integration of high resolution DTED, hyperspectral data, and 
hypermedia data using the terrain analysis system. In: Proceedings of SPIE - The 
International Society for Optical Engineering, vol. 4381, pp. 253–264 (2001) 
7. Miliaresis, G., Paraschou, C.: Vertical accuracy of the SRTM DTED level 1 of Crete. 
International Journal Of Applied Earth Observation And Geoinformation 7(1), 49–59 
(2005) 
8. Quiring, D., Monforte, J.: Evaluation of the DTED resampling algorithm used on the 
Comanche program. In: AIAA/IEEE Digital Avionics Systems Conference - Proceedings, 
vol. 2, pp. 5–11 (1997) 
9. Lu, G.Y., Wong, D.W.: An adaptive inverse-distance weighting spatial interpolation 
technique. Computers & Geosciences 34, 1044–1055 (2008) 
10. Tomczak, M.: Spatial interpolation and its uncertainty using automated anisotropic inverse 
distance weighting (IDW)-crossvalidation/jackknife approach. Journal of Geographic 
Information and Decision Analysis 2(2), 18–30 (1998) 
11. Ostman, A.: Accuracy Estimation of Digital Elevation Data Banks. Photogrammetric 
Engineering and Remote Sensing 53(4), 425–430 (1987) 
12. Pelizzari, C.A., Chen, G.T., Spelbring, D.R., Weichselbaum, R.R., Chen, C.T.: Accurate 
three-dimensional registration of ct, pet, and/or mr images of the brain. J. Comput. Assist. 
Tomogr. 13, 20–26 (1989) 
13. Faust, N.L.: Integratıon of LANDSAT, DTED, And DFAD. In: Proceedingsof SPIE - The 
International Society for Optical Engineering, vol. 781, pp. 106–115 (1987) 
14. Phatak, G.F.G.L.J., Cox, M.: GPS and Digital Terrain Elevation Data (DTED) integration. 
In: Proceedings of the 17th International Technical Meeting of the Satellite Division of the 
Institute of Navigation, ION GNSS 2004, pp. 2074–2085 (2004). 
15. Hemminger, T.L., Gray, R.: A neural-based method of determining aircraft landing paths 
from DTED, vol. 12, pp. 995–1000 (2002) 
16. Bair, G.L., Johnston, D.A.: Radar Systems Analysis Using DTED Data. In: IEEE 
Proceedings of the National Aerospace and Electronics Conference, pp. 73–79 (1987) 
17. Hubbard, B.E., Sheridan, M.F., Carrasco-Nez, G., Daz-Castelln, R., Rodrguez, S.R.: 
Comparative lahar hazard mapping at Volcan Citlaltpetl, Mexico using SRTM, ASTER 
and DTED-1 digital topographic data. Journal of Volcanology and Geothermal 
Research 160(1-2), 99–124 (2007) 

A Mission Management Framework for
Unmanned Autonomous Vehicles
Eskindir Asmare, Anandha Gopalan, Morris Sloman, Naranker Dulay,
and Emil Lupu
Department of Computing, Imperial College London, London SW7 2RH
{e.asmare,a.gopalan,m.sloman,n.dulay,e.c.lupu}@imperial.ac.uk
Abstract. Unmanned Autonomous Vehicles (UAVs) are increasingly
deployed for missions that are deemed dangerous or impractical to per-
form by humans in many military and disaster scenarios. UAVs in a team
need to operate in sub-groups or independently to perform speciﬁc tasks,
but still synchronise state information regularly and cope with intermit-
tent communication failures as well as permanent UAV failures. This
paper describes a failure management scheme that copes with failures,
which may result in disjoint sub-networks within the team. A commu-
nication management protocol is proposed to control UAVs performing
disconnected individual operations, while maintaining the team’s struc-
ture by trying to ensure that all members of the mission rendezvous to
communicate at intermittent intervals. The evaluation of the proposed
approaches shows that the schemes are scalable and perform signiﬁcantly
better than similar centralised approaches.
Keywords:
Autonomic management, collaborating autonomous vehi-
cles, mission management, communication failure recovery.
1
Introduction
Unmanned Autonomous Vehicles (UAVs) are mobile robots that are often used
in civilian disaster-relief missions and military scenarios to reconnoiter in ar-
eas which are dangerous or impractical for humans. A challenge in using UAVs
for such missions is enabling adaptive self-management so that they can auto-
matically adapt to changes in context and failures without human intervention.
Collaborating UAVs form a Self-Managed Cell (SMC) [14], a general architec-
tural pattern for realising self management of individual and teams of UAVs.
An SMC team consists of multiple UAVs with at least one commander, which
could be a human or another UAV. The commander is provided with a mission
speciﬁcation by its command base and assembles the required UAVs to perform
the mission. The mission speciﬁcation [7] deﬁnes how speciﬁc roles are assigned
to certain UAVs based on their credentials and capabilities.
The mission speciﬁcation also deﬁnes a role management hierarchy and the
behaviour of these roles in terms of policies speciﬁed using the Ponder2 [17]
policy speciﬁcation language. When a mission is instantiated the commander will
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 222–235, 2009.
c
⃝Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

A Mission Management Framework for Unmanned Autonomous Vehicles
223
Fig. 1. Sample Ponder2 Policies
download its role behaviour speciﬁcations (the policies) and start the mission.
When new UAVs come into the communication range the commander gives
a subset of the mission speciﬁcation to those UAVs which have satisﬁed the
vetting process with respect to capability and credentials. These UAVs may in
turn allocate a subset of the mission roles to other UAVs and the whole process
ﬁnally results in a formation of a management tree which facilitates control and
state information collection. Fig. 1 shows examples of role assignment policies.
In the ﬁrst policy the commander authenticates a newly discovered UAV, and
assigns it to a surveyor role if it has the required capability with respect to motion
and video camera. In the second policy the commander performs reassignment
if the failed role type is a surveyor role.
To ensure that the UAVs comprising the SMC perform their tasks correctly,
it is important to cope with diﬀerent types of failures. Consider a mission sce-
nario that contains the following roles: a Commander (C), which has the initial
mission speciﬁcation, assigns roles and manages the SMC; an Aggregator (A),
which receives information from surveyors and builds up a map, a Surveyor (S)
containing a video camera, and a Relay (R) which maintains communication
by relaying messages in an ad-hoc network. Failures in such missions can occur
as a result of intermittent or permanent communication link failures as well as
individual node failure. A recent study on UAV failures [4] shows that reliability
in ﬁeld environment is only between 6 and 20 hours.
This paper extends the mission management framework from [6] by evaluating
the proposed schemes and elaborating the architecture. This architecture uses
a management tree (described in Section 3.1) to deﬁne management hierarchies
as well as data aggregation hierarchies during execution of the mission. If the
periodic state information is not received within a speciﬁed timeout period, a
failure is considered to have occurred. Various timeouts can diﬀerentiate between
the types of failures and each is handled accordingly.
In conjunction with failure management, we also actively try to maintain com-
munication between team members using two techniques: i) UAVs adapt their
movement to always be within radio range of a neighbour or follow each other
(similar to [1,3,19,12,18]) so as to maintain communication by using UAVs as
relays to reach distant nodes; ii) The UAVs gather within a deﬁned rendezvous
area at a speciﬁed time so as to exchange the requisite state information (this is
due to the fact that it may be impractical to restrict motion in some situations
and so we take a delay tolerant network approach to cater for UAVs being out
of communication range for short periods). In the event that a UAV is unable to

224
E. Asmare et al.
reach the rendezvous area, it is assumed to have failed and the appropriate fail-
ure management scheme is used. The rendezvous timeout is set to be less than
the communication failure timeout so that intermittent disconnection caused
by execution of the rendezvous algorithm does not trigger the failure manage-
ment protocol. It is also possible to change the communication failure timeout
dynamically through a policy.
The rest of this paper is organised as follows. Section 2 details the protocol
to ensure secure communication within the team. Section 3 details the failure
management scheme, while Section 4 details the communication management
scheme. Section 5 details the experiments and the ensuing results. Section 6
compares our approach with related work. Section 7 concludes the paper and
provides ideas for future work.
2
Security
The UAVs in a team can change over time with new UAVs joining or leaving.
These UAVs may also belong to diﬀerent organisations (e.g. allies). Authenticat-
ing a UAV before it joins the team and protecting the ensuing communication
is thus necessary to ensure the security of the mission, particularly for military
applications. We assume the coalition between diﬀerent organisations is achieved
by using a Central Command Centre (C3) and use the Certiﬁcate Public Key
Infrastructure (C-PKI) [9] to ensure authentication, conﬁdentiality and message
integrity. The system assumes a single certiﬁcation authority (C3), which issues
certiﬁed public/private keys to all UAVs in the mission and maintains a Cer-
tiﬁcate Revocation List (CRL). The C-PKI system is also used to exchange a
common secret key generated using the Diﬃe-Hellman protocol [5] between each
member of the team and the commander. The secret key eﬀectively establishes
a secure channel between the commander and each team member. The steps
involved in the authentication between a UAV (A) and the Commander (or any
other manager role performing discovery) (C) are shown below:
1. C →A: {Cid}. Broadcast Discovery Message.
2. A →C: {Join Request, Aid, NonceA}. A sends a request to join the SMC.
3. C →A: Sign

{Kc}K−1
C3 , Cid, NonceA + 1

K−1
c
. C authenticates itself to
A by sending its Public-Key Certiﬁcate (PKC) and a function applied to
NonceA, all signed with its private key.
4. A →C: Sign

{Ka}K−1
C3 , Aid, NonceA + 2

K−1
a
. A sends its PKC to C as
well as a function applied to the received Nonce, all signed by its private key.
If the certiﬁcates are veriﬁed by both A and C (using C3’s certiﬁcate), mutual
authentication is achieved.
5. C →A: Sign

{gx mod p}Ka , g, p, NonceC

K−1
c . C sends the Diﬃe-Hellman
parameters and keyshare encrypted with A’s public key.
6. A →C: Sign

{gy mod p}Kc , NonceC + 1

K−1
a . A sends its Diﬃe-Hellman
keyshare, encrypted with C’s public key.

A Mission Management Framework for Unmanned Autonomous Vehicles
225
Both A and C can now calculate a shared secret key (Kac) that is used to
establish a secure channel between A and C. The rest of the communication
uses the secure channel established above.
3
Failure Management
3.1
Management Tree
The UAVs in a mission are arranged in the form of a management tree during the
role assignment process to facilitate decentralisation with any of the UAVs po-
tentially performing discovery and role assignment. This tree is used for deﬁning
management hierarchies as well as for data aggregation during execution of the
mission. Consider a mission scenario with ﬁve UAVs, three hierarchies and ﬁve
roles in the management tree. Role C is at the top, roles P, Q and R are managed
by C and roles S and T are managed by P. Because roles P, Q and R have to
be assigned by C before P assigns S and T, C can optimise the assignment by
choosing the better suited UAVs for P, Q and R out of the ﬁve available UAVs
without compromising future assignments because C has a knowledge of future
roles to be assigned by P. This is in contrast to a completely distributed task as-
signment scheme used in architectures such as MURDOCH [8], where decisions
are made based only on the current and/or local situation without taking into
account how the decision might aﬀect the future and/or global situation. In the
following sections we present the management tree formation algorithms. Each
UAV, upon start-up runs the algorithm in Section 3.3. However, if the UAV is
started as a commander, it runs the Manager algorithm. In the event that a
UAV becomes a manager, it also runs the Manager algorithm (Section 3.2).
3.2
Manager UAV’s Algorithm
A manager role has a set of roles it is required to assign according to the mission
speciﬁcation. When the role is started, it prepares a waiting list (W ) containing
a set of roles to be assigned to UAVs : W = {R1,R2, ..., Rn} and a children list
(L) containing a set of assigned roles and their state information.
1. Broadcast ID periodically to discover other UAVs.
2. If a UAV replies with a join request the manager initiates a mutual authenti-
cation process which, if successful, will result in a shared secret key between
the managing and managed UAVs. If the authentication is not successful
return to step 1.
3. Authenticated UAV sends an encrypted capability summary s, check if there
is any role in W with a role assignment policy specifying a capability re-
quirement r, where r ⊆s. If there is such a role then send a request for a
full capability description to the UAV.
4. Check if the full capability description satisﬁes the requirements of the role
and if so send a role assignment message to the UAV. Remove the assigned
role from W and add it to L.

226
E. Asmare et al.
5. If a state update message is received, update L.
6. Check L for freshness of role state information. If the age of the state of
a role is higher than a given interval of time then publish an appropriate
failure event (the event could be communication link failure or UAV failure
event based on the age of the state). Return to step 5.
For each UAV which has responded to the broadcast, steps 2-4 of the above
algorithm execute in parallel. Any UAV can be assigned to a commander role to
cater for manager UAV failure.
3.3
Managed UAV’s Algorithm
1. Wait for broadcast.
2. If a broadcast message is received and if this UAV can be assigned to a role,
send a join request to the broadcaster.
3. If authentication is initiated by the broadcaster, then perform mutual au-
thentication. If the authentication is successful, send an encrypted capability
summary to the broadcaster else return to step 1.
4. If a full capability request from the broadcaster is received within a given
timeout then send the encrypted description else return to step 1.
5. If a role assignment message is received within a given timeout then download
the policies specifying the behaviour of the role, start the role and identify
the broadcaster as the parent (manager) UAV else return to step 1.
6. Send a state update message to the manager UAV periodically.
Fig. 2 illustrates a trace of the tree formation algorithms. Fig. 2(a) shows
the communication links between neighbouring nodes. In Fig. 2(b) the top node
broadcasts Discovery messages to its neighbours which form a team with the
top node as commander and the middle nodes as children assigned to various
roles (Fig. 2(c)). In Fig. 2(d), the middle nodes broadcast to their neighbours
but only lower nodes respond as the other middle nodes already have a parent.
Fig. 2(e) shows the resulting tree with a single parent for each node.
Fig. 2. Management Tree Formation

A Mission Management Framework for Unmanned Autonomous Vehicles
227
3.4
Failure Detection and Management
We use diﬀerent timeouts to distinguish between intermittent communication
link failures and permanent communication link or UAV node failures. Each
UAV periodically sends state information to its parent in the management tree;
if the state information is not received within a speciﬁed timeout it is consid-
ered that a failure has occurred. The timeouts are: (a) TC: detects intermittent
communication link failure (b) TN: detects permanent failures (TN > TC).
Failure of a communication link and/or a UAV causes partitioning of the
team as well as loss of functionality. We use a systematically deﬁned identity for
UAVs to facilitate merging and re-joining of partitioned teams. The identity I
of a UAV is deﬁned as: I = [M | H | S] where: M = mission ID, H = hierarchy
level and S = a numbering system to place all the UAVs in the management
tree in a total order. This identity lasts throughout the team conﬁguration.
3.5
Intermittent Link Failure
An intermittent communication link failure may be caused by either a temporary
signal blockage by physical objects or movement out of the communication range.
Although local functions can keep operating, a temporary partitioning of the
logical (overlay) network over which the management tree is formed can cause
disruption of state aggregation as well as the ﬂow of management commands. In
addition, remote operations will also be aﬀected. The desired response to this
type of failure is to continue mission execution with disconnected operations and
resolve inconsistencies when the communication link reappears.
When the team is partitioned as a result of failure, one or more teams with-
out commanders will be formed. In order to keep the mission execution during
the failure, the top UAV on the hierarchy (which was already managing this
sub-team during normal functioning) will become the commander of the team.
A partitioned sub-team can also admit new UAVs. When the sub-team rejoins
the parent team, the sub-team commander reports its current state to its parent
and the domain structure of all UAVs in the mission is updated to indicate new
members. To facilitate merging of partitioned teams, we deﬁne the hierarchy level
of the partitioned team to be the level of its manager. Merging is performed by
placing lower-level hierarchy teams under the management of higher-level hierar-
chy teams. Ideally, when there are more UAVs to choose from, more demanding
mission subsets (ones with more roles) are given to more capable UAVs. Hence,
we should keep more capable UAVs higher up in the hierarchy.
In this approach, there is no new role assignment or reassignment of existing
UAVs to roles diﬀerent from their original ones. The result being, that the map-
ping of existing UAVs to roles remains the same whereas the management tree
can be diﬀerent, as it is assumed that the adaptation is temporary. The initial
conﬁguration is shown in Fig. 3(a). When communication link disconnection oc-
curs, as shown in Fig. 3(b), partitioned sub-teams are created. These sub-teams
perform reconﬁguration where the partitioned role, H comes under the control
of the other sub-team as shown in Fig. 3(c).

228
E. Asmare et al.
Fig. 3. Reconﬁguration and Role Reassignment to Adapt to Failure
3.6
Permanent Failures
A permanent failure is caused by either a node or communication link hard-
ware failure (other UAVs cannot distinguish between these). The result is the
partitioning of the team as well as a loss of roles. The partitioning problem is
addressed using the approach in Section 3.5. The response to the loss of roles is
as follows (in order of priority): (i) use replicated roles, if available, (ii) if there
are unassigned or newly discovered UAVs, perform a role reassignment, while
keeping the existing team conﬁguration, to replace the lost role(s), and (iii) if
none of the above is feasible, reconﬁgure the team by swapping less crucial roles
for more crucial roles. Should the reconﬁguration incur role replacement this
takes place only in subsets of the team which are lower in hierarchy than the
failed UAV. This is due to the fact that roles assigned to higher level UAVs are
more crucial to the mission. In the case of role reassignment and reconﬁguration,
state information migration takes place.
Fig. 3 illustrates adaptation to permanent failures. The initial conﬁguration
is shown in Fig. 3(a). When a permanent failure occurs, as shown in Fig. 3(d),
partitioned sub-teams are created (Fig. 3(e)). The response can be either recon-
ﬁguration as shown in Fig. 3(f), where the partitioned sub-teams are moved up
in the management hierarchy and now managed by the main commander; or a
role replacement where the UAV which was previously assigned to role S is now
reassigned to the supposedly crucial role A as shown in 3(g). All reconﬁgurations,
reassignments and other responses are speciﬁed in terms of policies.
4
Communication Management
In this section, we present our communication management protocol that tries to
maintain the communication links between the UAVs in the mission in order to
prevent communication link failure. We assume: (a) Each UAV knows its current
location and its direction and speed of travel, (b) No clock synchronisation,
but relative time is assumed to be consistent i.e. 20 minutes on one UAV is
approximately equal to 20 minutes on another, (c) All UAVs have the same
communication range (CR) and, (d) A global/local co-ordinate system exists for

A Mission Management Framework for Unmanned Autonomous Vehicles
229
specifying location and direction of travel. For the purpose of our schemes, we
augment the periodic state update messages (sent between the UAVs, as speciﬁed
by the management tree) by the current location and speed of the UAV.
4.1
Adapt Movement to Maintain Communication
In this section, we detail the approach that controls the movement of the UAVs
to ensure that they stay within communication range.
S
R
H
S’
Φ
C
A
(a)
Time = T
H
S’
C
A
S’’
R’
(b)
Time = T’
Fig. 4. Position of UAVs in the mission
Assume that the position at time T of the 5 UAVs in the mission are as shown
in Fig. 4(a). At time T , UAV S starts moving from its current location to its
future location S′ with constant speed and direction (Φ). Since the direction
and speed of S are available to the rest of the UAVs in the team, it is easy
for them to predict the location of S at a later time (T ′). If this position is
beyond the communication range of the rest of the UAVs in the mission, the
closest UAV to S starts to move in a manner so as to make sure that it still
is within communication range of S. As per the scenario mentioned above, we
can see from Fig. 4(a) that UAV R is the closest to UAV S and it is R’s job
to make sure S is within communication range and it moves accordingly. When
S moves to S′ at time T ′, R moves to R′ (Fig. 4(b)). The amount that R has
to move depends on its location and the location and speed of S. If S moves
from position S′ to S′′ during the next time period, then R would also move to
keep S within communication range. In the event that R along with S move out
of communication range with respect to the rest of the UAVs in the group, the
UAV closest to R will start following R to keep it within communication range.
If S keeps moving away, the rest of the UAVs try and form a “chain” that allows
them to keep S within communication range. If it is not possible to cover S, the
protocol uses the scheme described in Section 4.2.
4.2
Rendezvous to Restore Communication
Though the approach detailed in Section 4.1 allows UAVs involved in a mission
to maintain communication links, it would not be feasible in the scenario when

230
E. Asmare et al.
UAVs need to reconnoiter. In this section, we will detail an approach that al-
lows UAVs to perform disconnected individual operations, while maintaining the
team structure by trying to ensure that all members of the mission regardless of
destination or task, communicate at intermittent intervals.
If the commander UAV notices that the distance between a child node and
another member is greater than the range threshold (TR, modelled as a % of the
communication range (CR)), it initiates the rendezvous algorithm. Using the
current location, speed and direction of the UAVs in the mission, the rendezvous
area is calculated and communicated to the team members. This is where all the
UAVs are expected to rendezvous after a speciﬁed time. Once an instance of the
rendezvous algorithm is running, future requests are ignored. After reaching the
rendezvous area, the algorithm is restarted only if the need arises again.
The rendezvous area is calculated as follows. The average direction of travel
(θ) is calculated by averaging the angle of the direction of travel of all the UAVs
in the mission with respect to a common axis. Once the direction is calculated,
the rendezvous area is calculated to be the area (using a suitable expression)
surrounding the rendezvous point that is achieved by projecting the speed of the
slowest UAV starting from the average location (X, Y ) onto the average direc-
tion of travel over the requested time (T , which is relative to current time and
indicates the future time when the nodes should rendezvous). The rendezvous
point is calculated as follows (D = distance to rendezvous):
XRP , YRP =
XRP = X + D ∗cosθ
YRP = Y + D ∗sinθ
(1)
5
Experiments and Results
The experimental setup consisted of machines on a Local Area Network. We
simulated diﬀerent subnets by using IP ﬁlter policies. Each manager role was
assigned to a separate machine and a diﬀerent subnet, while other roles were
running in parallel (with a maximum of 20 roles per machine).
5.1
Mission Setup Time
In this experiment we ﬁxed the depth of the management tree to 5 levels and
compared its performance, with respect to mission setup time, with a centralised
approach by varying the number of roles in the mission. Fig. 5(a) shows the result
for 25 experiments plotted with a 95% conﬁdence interval. The result illustrates
that as the number of roles increases the hierarchical management approach
outperforms the centralised one.
5.2
Eﬀect of Depth of the Management Tree and Number of Roles
In this experiment we varied the number of roles between 20 and 200 and the
depth of the management tree between 1 and 10. We then measured the mission

A Mission Management Framework for Unmanned Autonomous Vehicles
231
(a)
(b)
Fig. 5. Mission setup time
setup time. Fig. 5(b) shows the result for upto depth 7 (after depth 7, there is
very little change to the mission setup time with respect to the depth) for 25
experiments. For higher number of roles, the mission setup time decreases as we
increase the depth of the tree as a result of load balancing. However this trend
stops and the setup times start to increase slowly as the tree becomes deeper due
to the delay in role assignment created by an increase in the number of hops.
This behaviour suggests the existence of a ratio of number of roles to depth, for
a given management tree, which guarantees a minimal mission setup time. For
smaller number of roles the mission setup time is minimal at depths 1 and 2
after which the setup time increases with depth due to an overhead introduced
by the added number of hops without any gain in load balancing as the number
of roles managed is already suﬃciently small. It is also interesting to note that
the depth at which the minimal setup time occurs increases as we increase the
number of roles.
5.3
Mean Time to Reassign Roles After Failure
In this experiment we study the response time of our mission management sys-
tem when a cluster of failures occur, as in typical disaster response or military
scenarios it is likely that a group of UAVs could be aﬀected by an event causing
Fig. 6. Measurement of Time Taken to Reassign Roles in a Cluster Failure Scenario

232
E. Asmare et al.
them all to fail. We used a mission speciﬁcation which has 100 Surveyor roles and
100 Aggregator roles and a reassignment policy which dictates that whenever a
Surveyor role fails an Aggregator role should be withdrawn from a working UAV
and replaced by a Surveyor role. The results are shown in Fig. 6. We note that
the reassignment time scales linearly with the number of failed nodes.
5.4
Evaluation of Communication Management
The communication management scheme was implemented using the Webots
mobile robotics simulator [15], which is a prototyping environment for modelling,
programming and simulating mobile robots. In the ﬁrst experiment (Fig. 7(a)),
the eﬀect of range threshold was evaluated with respect to the speed of the UAVs,
while the second experiment (Fig. 7(b)) evaluated the update time versus the
speed of the UAVs. The success rate is deﬁned as the number of UAVs that
successfully manage to follow the lead UAV to its destination (including the
lead UAV itself). A total of ﬁve UAVs were used for this experiment and they
were arranged in a management tree with one commander, an aggregator, a
surveyor, a hazard detector and a relay. For the purpose of the experiments, the
relay was acting as the “lead” UAV. For the value of speed, a magnitude of 1
denotes a speed of 4.5 mm/s. For the ﬁrst experiment, the update time is set to
2s, while for the second experiment, the range threshold is set to 75%.
From Fig. 7(a), we see that the range threshold (TR) has a signiﬁcant impact
on the performance. As the value of TR increases, fewer and fewer UAVs are able
to follow the leader. This is especially true in the case when the speed is greater
than 30, since only the leader is able to reach its destination. Setting the value
of TR much lower (50%) enables everyone to reach the destination, but this may
be detrimental since this results in the leader being followed very closely and
may result in a cluster failure (due to a hazardous terrain). Instead of setting
the value of TR apriori, it is ideal to set the value dynamically based on the
current speed. For lower speeds, a high value of TR would suﬃce and vice versa.
From Fig. 7(b), we can see that the change in update time adversely aﬀects
the UAVs when they are travelling at a high speed. This is to be expected since
(a) Range-Threshold
(b) Update-Time
Fig. 7. Communication Management

A Mission Management Framework for Unmanned Autonomous Vehicles
233
the “follower” UAV uses the location updates of its leader to map its path.
Having a small update rate (0.5s) results in all UAVs following the leader to the
destination. However, this has an adverse eﬀect on the battery life of the UAVs
due to the excess communication. In case we wish to improve the performance
we can always decrease the value of TR, rather than increasing the update time.
6
Related Work
A distributed algorithm that allows autonomous mobile robots with limited vis-
ibility to converge to a single point is suggested in [1]. This uses their previous
work in [2,11] that allows the mobile robots to agree on a x−y coordinate system,
the common origin and the direction of the x-axis. This allows the mobile robots
to exchange their location information and use this information to converge to a
single point. Similarly [13,12] also addresses the collective behaviour of a group
of mobile autonomous agents and discusses two diﬀerent strategies that allow for
these to rendezvous at a speciﬁed location. Both strategies are “local” strategies,
wherein each agent independently calculates its new location based only on its
neighbour information. The ideas and protocols provided above are similar to
our idea of a rendezvous area but our rendezvous algorithm is only executed as
and when required. Also, we do not restrict the movement of the UAVs since
they are free to move in any manner to reach the rendezvous area.
Co-ordinating the movement of the mobile robots to keep them within com-
munication range is discussed in [19,16]. Although the ideas are similar to our
approach in Section 4.1, our robots do not keep following the lead robot, but
instead resort to the approach in Section 4.2 to maintain communication links.
In [10] the authors present an approach for exploration, mapping and tracking
targets using large scale heterogeneous robots. They classify the robots based
on their capabilities as highly-capable, slightly less-capable and simple. The less
capable robots (leader robots) are responsible for leading the simple robots as
the simple robots do not have the navigation capability. The failure detection
approach is slightly similar to our approach in that the leader robot detecting the
failure of the follower is comparable to a parent role detecting the failure of its
child. However, their approach to recovery is coded in the behaviour of the robots
while we use policies for managing failure. Also, whereas we use disconnected
operations in communication failure and reassignment in complete UAV failure;
in their approach the leader robots return home when communication failure
occurs and there is no deﬁned action for a complete leader robot failure.
Jamp [20] uses disconnected operations to handle communication link discon-
nections and deﬁnes an abstraction called container, in order to facilitate the
implementation of mobile applications. An application in Jamp is implemented
as an interaction between containers, since containers can be moved from node
to node. The container concept in the Jamp system and its mobility is similar
to our role concept. However, Jamp is not applicable for communication link
failures since it is not possible to transfer state information to the newly instan-
tiated container in another node. Our approach caters for link disconnections by
periodically collecting state information by using the management tree.

234
E. Asmare et al.
7
Conclusion
In this paper we have presented a failure management scheme for teams of Un-
manned Autonomous Vehicles performing a mission using a hierarchical mission
management approach. We evaluated the performance of both the hierarchical
mission management system and the failure management scheme. The results
show that the mission management system is scalable and also has the advan-
tage of having a shorter mission setup time, especially for large scale missions,
as compared to a centralised management approach. The failure management
scheme scales linearly with the failed number of roles which makes it suitable
for large scale failures in diﬃcult or dangerous mission areas.
We have also presented a communication maintenance scheme that tries to
maintain the communication links between the UAVs involved in the mission.
The proposed scheme was evaluated in the Webots simulator and the ensuing
results show that the scheme is robust and ﬂexible.
Future work will focus on studying the response of the failure management
scheme by using diﬀerent failure models. We also intend to study reconﬁgura-
tions of the mission management tree triggered by withdrawal of a role during
a reassignment. Also, the approach to maintain communication using the ren-
dezvous algorithm will be implemented on the Webots simulator and evaluated.
Acknowledgements
The work reported in this paper was funded by the Systems Engineering for
Autonomous Systems (SEAS) Defence Technology Centre established by the
UK Ministry of Defence.
References
1. Ando, H., Oasa, Y., Suzuki, I., Yamashita, M.: Distributed memoryless point con-
vergence algorithm for mobile robots with limited visibility. IEEE Transactions on
Robotics and Automation 15(5), 818–828 (1999)
2. Ando, H., Suzuki, I., Yamashita, M.: Formation and agreement problems for syn-
chronous mobile robots with limited visibility. In: Proceedings of the IEEE Inter-
national Symposium on Intelligent Control (1995)
3. Bicho, E., Monteiro, S.: Formation control for multiple mobile robots: A non-linear
attractor dynamics approach. In: Proceedings IEEE/RSJ International Conference
on Intelligent Robots and Systems (2003)
4. Carlson, J., Murphy, R.R.: How UGVs physically fail in the ﬁeld. IEEE Transac-
tions on Robotics 21(3), 423–437 (2005)
5. Diﬃe, W., Hellman, M.: New directions in cryptography. IEEE Transactions on
Information Theory 22(6), 644–654 (1976)
6. Asmare, E., Gopalan, A., Sloman, M., Dulay, N., Lupu, E.C.: Adaptive Self-
Management of Teams of Autonomous Vehicles. In: Proceedings of the 6th In-
ternational Workshop on Middleware for Pervasive and Ad-Hoc Computing (2008)

A Mission Management Framework for Unmanned Autonomous Vehicles
235
7. Asmare, E., Gopalan, A., Sloman, M., Dulay, N., Lupu, E.C.: A Policy-Based Man-
agement Architecture for Mobile Collaborative Teams. In: Proceedings of the 7th
Annual IEEE International Conference on Pervasive Computing and Communica-
tions (2009)
8. Gerkey, B.P., Mataric, M.J.: Principled communication for dynamic multi-robot
task allocation. In: ISER 2000: Experimental Robotics VII, London, UK, pp. 353–
362. Springer, London (2001)
9. Housley, R., Ford, W., Polk, W., Solo, D.: Internet X. 509 Public Key Infrastructure
Certiﬁcate and CRL Proﬁle. Technical report, RFC 2459 (January 1999)
10. Howard, A., et al.: The sdr experience: Experiments with a large-scale heterogenous
mobile robot team. In: 9th International Symposium on Experimental Robotics
(2004)
11. Suzuki, I., Yamashita, M.: Distributed Anonymous Mobile Robots—Formation
and Agreement Problems. In: Proceedings of the 3rd International Colloquium
on Structural Information and Communication Complexity (1996)
12. Lin, J., Morse, A.S., Anderson, B.D.O.: The multi-agent rendezvous problem. part
1: The synchronous case. SIAM J. Control Optim. 46(6), 2096–2119 (2007)
13. Lin, J.: Distributed mobility control for fault-tolerant mobile networks. In: Pro-
ceedings of Systems Communications (2005)
14. Lupu, E., et al.: AMUSE: Autonomic management of ubiquitous e-health systems.
Concurrency and Computation: Practice & Experience 20(3), 277–295 (2008)
15. Michel, O.: Webots: Professional mobile robot simulation. Journal of Advanced
Robotics Systems 1(1), 39–42 (2004)
16. Nguyen, H., et al.: Autonomous communication relays for tactical robots. In: Pro-
ceedings of the International Conference on Advanced Robotics (2003)
17. Ponder2, http://ponder2.net
18. Suzuki, I., Yamashita, M.: Distributed anonymous mobile robots: Formation of
geometric patterns. SIAM J. Comput. 28(4) (1999)
19. Sweeney, J., et al.: Coordinated teams of reactive mobile platforms. In: Proceedings
of IEEE International Conference on Robotics and Automation (2002)
20. Valente, M., Bighonha, R., Bigonha, M., Loureiro, A.: Disconnected Operation
in a Mobile Computation System. In: Proceedings of the Workshop on Software
Engineering and Mobility (2001)

A Quality of Context-Aware Approach to
Access Control in Pervasive Environments
Alessandra Toninelli, Antonio Corradi, and Rebecca Montanari
DEIS – Universit`a di Bologna, Viale Risorgimento 2, 40136 Bologna, Italy
{alessandra.toninelli,antonio.corradi,rebecca.montanari}@unibo.it
Abstract. The widespread diﬀusion of wireless-enabled portable de-
vices creates novel opportunities for users to share resources anywhere
and anytime, but makes access control a crucial issue. User/device mo-
bility and heterogeneity, together with network topology and conditions
variability, complicate access control and call for novel solutions to dy-
namically adapt access decisions to the diﬀerent operating conditions.
Several research eﬀorts have emerged in recent years that propose to ex-
ploit context-awareness to control access to resources based on context
visibility and changes. Context-based access control requires, however,
to take into account the quality of context information used to drive
access decisions (QoC). Quality of context has in fact a profound im-
pact on the correct behavior of any context-aware access control frame-
work. Using context information with insuﬃcient quality might increase
the risk of incorrect access control decisions, thus leading to danger-
ous security breaches in resource sharing. In this paper we propose a
QoC-aware approach to access control for anywhere, anytime resource
sharing. The paper describes the design, implementation and evaluation
of the Proteus policy framework, which combines two design guidelines
to enable dynamic adaptation of policies depending on context changes:
context-awareness with QoC guarantees and semantic technologies to al-
low high-level description of context/policy speciﬁcation and reasoning
about context/policies.
1
Introduction
Technological advances in telecommunications and mobile device capabilities
are paving the way towards an integrated pervasive scenario where users access
services anywhere and anytime, even when they are on the move, and engage
in opportunistic and temporary resource sharing with other users in absence
of a ﬁxed network infrastructure. In the new pervasive scenarios, characterized
by high heterogeneity and dynamicity in terms of available services, computing
devices/mobile users properties and executing environments, controlling access
to shared resources becomes a crucial problem.
Traditional systems rely on a relatively static characterization of the operating
conditions where changes in the set of users, devices and accessible resources are
relatively small, rare, or predictable. By contrast, user/device mobility causes
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 236–251, 2009.
c
⃝Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

A Quality of Context-Aware Approach to Access Control
237
frequent changes in physical user location, in accessible resources, and in the
visibility and availability of collaborating partners. Access conditions deﬁned at
design time to control resource management and sharing can be unpredictably
diﬀerent from those holding at execution time, when entities actually attempt
access to resources. To address this issue, some research eﬀorts have emerged in
recent years that propose context-aware access control policy models to control
access to resources based on context visibility and changes [1]. The term context
can be broadly deﬁned as any information that is useful to characterize the state
or activity of an entity or the world in which this entity operates [2]. Diﬀerently
from traditional solutions where context is an optional attribute used to restrict
the applicability scope of security policies, context-aware solutions adopt context
as the main design principle for policy speciﬁcation and enforcement. Context-
aware access control policies exploit not only identity/role information, but also
other contextual information, such as location, time and ongoing activities, to
allow access to resources, thus adapting to dynamically changing conditions. The
exploitation of context as a ﬁrst-class principle to regulate access control brings
several advantages. First, it is an example of active security model, i.e. it is
aware of the context associated with an ongoing activity and thus distinguishes
the passive concept of permission assignment from the active concept of context-
based permission activation. Moreover, similarly to the concept of role in role-
based access control (RBAC) models, which serves as a mechanism for grouping
subjects based on their properties [3], the concept of context provides a grouping
mechanism for policies that simpliﬁes policy management by increasing policy
reuse and making policy update and revocation easier.
Existing context-aware access control models, however, typically rely on the
implicit assumption that context information used to take security decisions
is correct and trustworthy. This hypothesis is clearly not compatible with real
operating conditions in pervasive scenarios, where context data are acquired
by heterogeneous (and possibly not trustworthy) sensors via variable network
connections, represented according to diﬀerent models, and aggregated through
various procedures that might introduce additional biases. Controlling access
based on context thus requires a careful analysis about the quality of context
information (QoC) used to take access decisions.
We claim that QoC has a tremendous impact on the behavior of a context-
aware access control system. Depending on the quality of used context data,
granting access to a resource might be associated to a variable risk level: the
less reliable context information is (i.e. the lower its quality), the higher risk is
associated to any access action allowed based on that context information. Using
context information with insuﬃcient quality might therefore increase the risk of
incorrect access control decisions, thus leading to dangerous security breaches in
resource sharing.
The importance of considering QoC in designing and managing context-aware
systems has recently started to be recognized [4, 5]. We believe, however, that
QoC impact on context-aware access control models has been underestimated so
far, mainly considered a low level issue dealing with raw data, sensor equipment,

238
A. Toninelli, A. Corradi, and R. Montanari
and system performance. As such, QoC management is typically delegated to
context provisioning platforms, while higher level applications are context-aware,
but largely QoC-unaware. In particular, to the best of our knowledge, none of
existing access control solutions addresses the issue of considering QoC when
assigning permissions based on context.
In this paper we present a novel QoC-aware access control framework for shar-
ing resources in pervasive environments. In our framework QoC is exploited as a
ﬁltering principle to both (i) discard context data whose quality does not com-
ply with minimum QoC requirements and (ii) select applicable policies based
not only on current context, but also on the extent to which that context can be
considered true. This helps minimizing the risk of granting access to resources
based on incorrect or ambiguous context information, while reducing policy eval-
uation/enforcement overhead by ﬁltering out contexts and policies that are un-
applicable due to their inadequate QoC. We have implemented this approach
in the Proteus middleware architecture, which exploits QoC-awareness and se-
mantic technologies for the speciﬁcation and the evaluation of access control
policies.
The paper is organized as follows. The Proteus QoC-aware policy model is
presented in Section 2, while Section 3 details policy management with QoC-
based ﬁltering. Section 4 describes the Proteus middleware architecture and its
prototype implementation, which is evaluated in Section 5 by providing some
experimental results. Conclusions and future work follow.
2
Proteus QoC-Aware Policy Model
Proteus is a semantic context-aware access control model that is centered around
the concept of context. Similarly to roles in traditional role-based access con-
trol models, contexts can act as intermediaries between entities and the set of
operations that they can perform on resources. For each context, policies deﬁne
allowed operations on resources. In particular, policies can be viewed as one-to-
one associations between contexts and allowed actions. Entities requesting access
to resources operate in one or more active context, i.e. contexts whose deﬁning
conditions match the operating conditions of the requesting entity and of the
environment as measured by speciﬁc sensors embedded in the system. We deﬁne
policy protection contexts those active contexts that have speciﬁed permissions
associated with. Entities can perform on resources only those actions associated
with the protection contexts currently in eﬀect [1].
When activating a set of permissions, Proteus takes into account the qual-
ity of information making the policy protection context active. In particular,
we exploit quality of context information to ﬁlter the set of potentially active
contexts: if data describing the current state (as measured by sensors) do not
satisfy certain quality requirements, such as freshness or accuracy, they are not
considered eligible for activating protection contexts (and associated policies).
This approach brings two advantages. First, it minimizes the risk of granting
access to resources based on incorrect or ambiguous context information. In

A Quality of Context-Aware Approach to Access Control
239
addition, it helps reducing policy evaluation/enforcement overhead by a-priori
ﬁltering out policies whose protection contexts cannot be activated because of
their insuﬃcient QoC level.
2.1
Context and Policy Model
A protection context in Proteus consists of all characterizing information that
is considered relevant for access control, logically organized in parts describing
the state of the resource associated with the protection context, such as avail-
ability or load (the resource part), the entities operating on the resource (the
policy/resource owner and the requestor), such as their roles, identities or secu-
rity credentials (the actor part), and the surrounding environment conditions,
such as time, or other available resources (the environment part). A protection
context is a set of attributes and predetermined values (called hereinafter con-
text elements), labeled in some meaningful way and associated with desirable
semantics [6]. Instead of a single value, an attribute could also deﬁne constraints
for a range of allowed values. Let us note that an attribute value can be assigned
to a ﬁxed constant or can be a variable over a value domain.
The current state of the surrounding world is also represented in terms of
attribute/value pairs (called context assertions), where the attribute values rep-
resent the output of sensors- with the term sensor used loosely. For a protection
context to be in eﬀect (active), the attribute values that deﬁne the current state
of the world have to match the deﬁnition of the context. More details on Proteus
context model can be found at [1].
A policy is represented as the association of a protection context and an ac-
cess action. Table 1 shows an example of protection context and policy related
to a pervasive healthcare scenario. The policy states that, in case of health emer-
gency, Alice’s health protected information (HPI) is accessible by any physician,
provided that (s)he is located in the healthcare center and owns a valid credential
(e.g., an oﬃcial certiﬁcate).
Table 1. (a) Proteus protection context deﬁnition example and (b) Proteus QoC-aware
policy example
(a)
PersonalEmergencyContext ≡
ProtectionContext ⊓∃owner.Alice ⊓∃requestor.InHospitalQualiﬁedPhysician ⊓
∃resource.AliceHPI ⊓∃environment.PersonalEmergency
InHospitalQualiﬁedPhysician ≡
Physician ⊓∃has credential.ValidQualiﬁcation ⊓∃located.HealthcareCenter
(b)
HPI Access Policy ≡AccessControlPolicy ⊓∃controls.ReadAction ⊓
∃context.PersonalEmergencyContext ⊓∃policy qoc.Policy QoC
Policy QoC ≡QualityOfContext ⊓∃has value.QoC over0.85

240
A. Toninelli, A. Corradi, and R. Montanari
2.2
Quality of Context Model
Proteus model handles QoC at two distinct levels: (i) context elements and (ii)
policies.
Proteus associates each context element with a quality attribute. In general,
it is possible to deﬁne several attributes to evaluate the quality of context infor-
mation, depending on both context sources and context collection/aggregation
mechanisms [4]. In our model we deﬁne a base quality attribute, called Quality
of Context (QoC), which is specialized in several diﬀerent attributes including
freshness, precision, correctness, trustworthiness, relevance and resolution, as
shown in Figure 1. Each quality attribute is also associated to a numeric value.
Similarly to context, the required quality of a context element is represented
as a set of attributes and constrained (range of) values. For instance, a QoC
constraint might require that any assertion about location must be up to date
to be considered as part of the current state (e.g., its normalized threshold value
for freshness is 0.8, as shown in Table 2). It is also possible to express QoC
constraints on speciﬁc context element values (e.g., the assertion “Dr. Green
is located in the Emergency Room” must have a QoC value higher than 0.6”)
or to any context element that is asserted in the current state knowledge base
(e.g., any context assertion must have the freshness value: very high”). Any
context assertion composing the current state is provided with a certain QoC
level, represented in terms of attribute/value pairs. For instance, the context
assertion “Dr Green is located in the Emergency Room” might be provided with
a QoC value of 0.7.
In addition, each access control policy is associated with a QoC threshold
value (see Table 1). This value represents the minimum quality level that any
Fig. 1. Quality of Context Ontology

A Quality of Context-Aware Approach to Access Control
241
state of the world activating the policy protection context must exhibit. In other
words, only if the current state has an overall QoC value exceeding the threshold,
the protection context and the associated policy will be considered active. Let us
note that this diﬀers from QoC constraints expressed on single context elements,
which are not bound to any speciﬁc policy.
2.3
Context and QoC Representation
We adopt description logics (DL) and associated inferencing to model and
process protection context data. A protection context is deﬁned as a subclass of
a generic context and consists of the resource, the actor and the environment
context elements. Each context element is characterized by an identity property,
and a location property deﬁning the physical or logical position of an entity. Sin-
gle context elements are characterized by speciﬁc additional properties. Figure 2
depicts Proteus base context ontology.
To model QoC, we exploit the support for reiﬁcation provided by RDF (and
inherited by OWL)1. Each context assertion can be thought as a triple connecting
a subject, a predicate and an object. For example, the assertion “Dr Green is
located in the E.R.” can be modeled as the following triple:
(Dr. Green, located, E.R.)
where the subject is Dr. Green, the object is E.R. and the predicate is located.
Such triple can be considered itself as a piece of information by means of
the RDF statement (rdf:Statement) abstraction. An RDF statement is the
statement made by a token of an RDF triple: the subject of an RDF statement
is the subject of the triple; the predicate is the predicate of the triple; the object
is the object of the triple.
We rely on this modeling structure and extend the rdf:Statement class with
a Context Assertion class, which inherits the rdf:subject, rdf:predicate
and rdf:object properties. To represent QoC information associated to each
context assertion, we add a quality property connecting each assertion to a
Quality Of Context class. This class is connected via property to several sub-
classes of the QoC attribute class representing diﬀerent QoC attributes, as
shown in Figure 1. QoC constraints on context elements are represented as classes
whose restrictions deﬁne the required quality. Table 2 shows an example of a QoC
constraint deﬁning a minimum threshold value for any context assertion about
the located property.
To calculate active protection contexts based on current state, we rely on DL-
based reasoning [6]. For instance, by considering protection contexts (i.e., sets of
context elements) as classes and a subset of the current state of the world (i.e.,
context assertions) as individuals, DL-based reasoning calculates the protection
contexts that are in eﬀect by verifying which protection context classes the cur-
rent state is an instance of, and by ﬁguring out how deﬁned protection contexts
relate to each other (nesting, etc.). We also exploit DL-based reasoning to verify
1 http://www.w3.org/TR/rdf-schema

242
A. Toninelli, A. Corradi, and R. Montanari
Fig. 2. Proteus Context Ontology
Table 2. (a) Proteus QoC constraint over a context element and (b) Context assertion
with QoC value
(a)
QoC over0.8 ≡QualityOfContext ⊓∃has value.{Over0.8}
QoC constraint ≡ContextAssertion ⊓∃quality.QoC over0.8 ⊓∃rdf:property.{located}
(b)
< Ctx assertion 11, Dr.Green >: rdf:subject
< Ctx assertion 11, EmergencyRoom >: rdf:object
< Ctx assertion 11, located >: rdf:predicate
< Ctx assertion 11, QoC value 11 >: quality
< QoC value 11, 0.7 >: has value
QoC constraints associated to both context element and policy deﬁnition. This
is a consequence of our modeling choice, which provides a uniform ontological
representation for both context and QoC data. Let us note that, in case QoC
constraints are expressed as numerical values, the comparison between required
(range of) values and actual QoC attribute values is performed via programming
procedures (since it is not supported by DL reasoners).
3
Policy Management in Proteus
To allow access to resources based on both context and its quality, Proteus ap-
plies a two-step QoC-ﬁltering process. Recalling the model described in
Section 2.2, Proteus allows to deﬁne QoC constraints both on context elements
and policies. Each type of constraint is exploited during a speciﬁc phase of the
ﬁltering process.

A Quality of Context-Aware Approach to Access Control
243
The QoC-based ﬁltering process is composed of the following two steps:
1. Context assertions pre-ﬁltering. Context assertions about the current state
are provided with certain QoC values. Prior to evaluating a request access,
Proteus retrieves all and only those context assertions that satisfy deﬁned
QoC constraints. The output of this ﬁltering phase is a set of context as-
sertions whose QoC values is compliant with imposed quality requirements,
regardless of any speciﬁc policy.
2. Protection contexts ﬁltering to activate policies. Proteus activates policies
based on current state information. Each policy has a speciﬁc QoC thresh-
old representing the minimum QoC value that any current state must satisfy
to activate the policy protection context. Among all potentially active poli-
cies (because context assertions, as ﬁltered at step 1, are instances of their
protection context), Proteus selects only those policies, whose QoC threshold
is reached by the QoC value of the current state. The output of this second
step (and of the whole QoC-based ﬁltering process) is a set of active policies
compliant with both context element and policy-speciﬁc QoC constraints.
3.1
Policy, Context and QoC Speciﬁcation
The application manager or the security manager can conﬁgure QoC constraints
for context elements at application deployment time, e.g., by setting values for
certain QoC attributes, such as freshness or accuracy, that apply to all context
elements. It is also possible to set values for context element QoC constraints
based on the speciﬁc application domain. For instance, if access control policies
are mainly based on location conditions, then the security manager can deﬁne
QoC constraints on any context element describing location information. Table 2
shows an example of context element QoC constraint deﬁnition.
The policy manager/security administrator deﬁnes Proteus policies by cre-
ating ontological associations between actions and policy activating contexts.
Table 1b shows a policy controlling access to a patient’s HPI. The policy man-
ager also sets the QoC threshold for the deﬁned policy. Such threshold value
typically depends on the sensitivity of the access resource and on the kind of
access action as well. For example, a read access on the HPI might be less critical
than a write access. OWL-based reasoning over contexts and policies is used to
infer new contexts and policies from existing ones, thus allowing policy reuse
and simplifying policy evaluation [1].
Let us note that context elements QoC constraints serve as a coarse-grained
ﬁlter since they apply to all context elements (and consequently to all installed
policies), while policy QoC provide a ﬁne-grained ﬁltering mechanism to ensure
that each policy is enforced under certain QoC conditions.
3.2
QoC-Based Policy Evaluation
In this section we describe in detail how Proteus evaluates access control policies
by applying the two-step QoC-based ﬁltering process.

244
A. Toninelli, A. Corradi, and R. Montanari
Context Assertions Pre-Filtering. Each context element might be associ-
ated to one or more QoC constraints. These constraints are expressed as OWL
restrictions on any RDF statement containing a speciﬁc subject, property or
object, or any combination of these elements (see, for example, Table 2). On the
other side, any context assertion (i.e., a triple composed of a subject, a predi-
cate and an object describing the current state) is provided with a QoC value.
Prior to performing policy reasoning, Proteus ﬁlters out information describing
the current state by selecting only those context assertions whose QoC value
satisﬁes any deﬁned QoC constraint on context elements. The output of this
pre-ﬁltering process is a base of context assertions whose quality is compliant
with QoC requirements.
Let us note that QoC values might be obtained according to diﬀerent ap-
proaches and mechanisms, from sensor training to utility functions [7]. Being
the aim of our present work the design of an access control framework, we do
not focus on QoC determination low level mechanisms by relying on existing
work on this topic.
Protection Contexts Filtering to Activate Policies. The second ﬁltering
step is speciﬁc to each policy. Once pre-ﬁltered current state information, Pro-
teus performs DL-based (subsumption) reasoning to determine which protection
contexts and associated policies could be activated by the current state. For each
protection context, Proteus needs to compare the policy QoC threshold value
with the QoC value of the (subset of) the current state activating the protection
context. The latter is calculated from the single QoC values of context assertions
by means of a weighted sum. Weights assigned to the diﬀerent context elements
can be deﬁned by the policy manager at policy deﬁnition time. In case weights
have not been deﬁned, Proteus assigns the same weight to each context assertion.
4
Proteus Middleware Architecture
The Proteus QoC-aware policy framework includes a middleware architecture
that supports policy speciﬁcation, semantic evaluation and enforcement based
on current context and QoC conditions. Figure 3 shows the main components
of Proteus architecture, namely: the Policy Installation Manager, the Reasoning
Core, the Policy Enforcement Manager and the Context Manager. Hereinafter
we particularly focus on the Context Manager that is mostly responsible for QoC
management in Proteus.
The Policy Installation Manager (PIM) is responsible for the setup, con-
ﬁguration and management of the Proteus systems. In particular, PIM provides
support to load context and policy ontologies, to install application-speciﬁc ac-
cess control policies, and to deﬁne policy QoC constraints.
The Reasoning Core (RC) performs reasoning over context and policies to
determine currently active policies, according to the QoC-aware policy model
described in Section 3. In particular, by exploiting DL-based reasoning, RC
determines which protection contexts and policies are active given the current
state and its QoC.

A Quality of Context-Aware Approach to Access Control
245
Fig. 3. Proteus Middleware Architecture
The Policy Enforcement Manager (PEM) is in charge of enforcing access
control policies on protected resources. When a tentative access is performed on
a resource controlled by Proteus, such as a ﬁle or a remote connection, PEM
intercepts it, collects relevant information about the action and interacts with
RC to verify whether access should be permitted or prohibited.
The Context Manager (CM) collects and manages current state and QoC
information from available context sources, and provide them to the Reasoning
Core. As shown in Figure 3, CM is designed as a layered component. More in detail:
– The Context Source Layer is in charge of interacting with context providers
to acquire context data and their associated QoC. Context providers reg-
ister to CM via the Context Source Layer, which implements provider-
speciﬁc modules (called Context Sources) to translate context data from the
provider’s format to CM internal representation. Translation also includes
the normalization of diﬀerent quality parameter values (e.g., freshness and
resolution).
– The Context Processing Layer acquires, stores, ﬁlters and reasons over con-
text assertions by implementing QoC-based ﬁltering, as detailed in the next
section.
– The Context Service Layer is the mediator between CM and Proteus Rea-
soning Core. This layer implements a module (a Context Service) for each
application that needs to be provided with context information according
to deﬁned QoC constraints. The Service Layer allows two diﬀerent modali-
ties for context/QoC provisioning, namely: (i) the context level agreement
(CLA)-based approach establishes QoC requirements that apply to all con-
text assertions provided by CM to RC; (ii) the query-based approach speciﬁes
associates QoC constraints to each context query from RC to CM.
4.1
Implementation Details
We have developed a Java prototype implementation of the Proteus middle-
ware architecture. Our deployment setting is a wireless Internet scenario, i.e., a

246
A. Toninelli, A. Corradi, and R. Montanari
computing environment where wireless solutions extend the accessibility of the
ﬁxed Internet infrastructure via access points, working as bridges between ﬁxed
and mobile devices.
For the sake of brevity, we only provide implementation insights about the
Context Manager, which is the middleware component that is actually in charge
of managing QoC in Proteus. Additional details and experimental results about
the prototype can be found at http://lia.deis.unibo.it/research/Proteus.
Both the Context Source and Service layers are designed as modular com-
ponents, thus allowing CM to interact with multiple context providers and
consumers via speciﬁc modules. At present we have implemented the Proteus
Context Service module, which interacts with Proteus RC and PIM, and the
Contory Context Source module, which interacts with the context provisioning
and management framework Contory [8]. In the current implementation, we sup-
port context acquisition by means of a context server. Contory is queried via its
SQL-like declarative language.
The Context Processing Layer is composed of four main sub-components,
each one addressing a speciﬁc functionality, and a context repository storing all
available data about the current state.
Query. This unit allows Proteus to install and remove context queries, which
are executed by the Proteus Context Service to retrieve context assertions. In
particular, it supports three query modalities, namely: single query, time-based
query (executed at ﬁxed intervals), event-based query. Queries are encoded in
SPARQL and the prototype includes a user-friendly query speciﬁcation tool for
non-expert users.
Contract. This unit allows the Proteus Context Service to deﬁne a context
provisioning contract deﬁning supported context queries and required QoC con-
straints. Proteus currently adopts a CLA approach, where QoC constraints are
deﬁned at system start up and stored in a conﬁguration ﬁle.
Collection. This is the most important unit since it is directly responsible
of managing QoC at the context element level. The Context Processing Layer
collects data from available context providers via the Context Source Layer,
manages their quality and keeps the current state repository up to date. Each
context assertion is provided with certain quality attributes values, which have
been normalized by the Contory Context Source module. For example, in Table 2,
the assertion “Dr.Green is located in the E.R.” is provided with freshness = 0.7.
The Collection unit exploits these single quality attribute values to determine a
global QoC value for each context assertion according to the following scoring
function:
QoCctx assertion =
n

i=0
wi ∗QoC attri.
0 ≤wi ≤1,
0 ≤QoC attri ≤1

A Quality of Context-Aware Approach to Access Control
247
Weights wi represent the contribution of diﬀerent quality attributes to the
global QoC value. Their value is set in a conﬁguration ﬁle at system installation
time. QoC attribute values are provided by sensors, except for freshness, which
is calculated by Proteus using appropriate timestamps. Let us note that setting
a speciﬁc weight to zero means that the corresponding attribute will not be
considered when calculating QoC. Conversely, if a quality attribute value is not
provided by the context source, the Context Processing Layer sets it to a pre-
determined value. If the QoC values of a context assertion do not satisfy CLA
requirements, that assertion is not stored in the repository.
Reasoning. The Reasoning unit is in charge of managing the Repository by
allowing ontology installation and removal, and periodically executing a back-up
transfer (currently on ﬁle). Ontologies include both concepts describing context
(TBox) and context assertions (ABox): while the former generally remains con-
stant unless the application domain is changed, the latter is frequently updated
due to changes in the current state of the world. To increase eﬃciency, the Rea-
soning unit therefore performs periodical checks on the ABox repository, and
removes those context assertions whose QoC is not compliant with the required
level, for example because their freshness has decreased over time. It is worth
noting that such QoC-based check not only allows to reduce the repository size
for improved eﬃciency, but it also ﬁlters out context information that are not
reliable enough to support access control decisions. In addition, this unit per-
forms DL-based reasoning to answer context queries and to ensure that the
current state knowledge base is consistent. This is important whenever context
assertions are added and especially when they are removed (due to their decayed
QoC). The current prototype exploits the DL reasoner Pellet (version 1.5)2, with
support for incremental reasoning, accessed via OWL-API and SPARQL queries.
5
Evaluating QoC-Aware Access Control in a Pervasive
Scenario
The exploitation of a QoC-aware semantic middleware for access control intro-
duces diﬀerent forms of overhead, depending on both the deployment environ-
ment and the performance of middleware facilities. The most critical aspects
for the performance and feasibility of our approach are (i) the introduction of
a QoC modeling and evaluation model, and (ii) the exploitation of semantic
technologies. In particular, the overhead due to these design choices should be
considered at two diﬀerent levels: when acquiring and managing context infor-
mation (i.e., at the Context Manager level), and in policy management and
evaluation (i.e., at the Reasoning Core level). We hereinafter provide some eval-
uations about CM performance. Additional implementation insights and evalu-
ations, e.g., about context and policy reasoning in Proteus RC, are available at
http://lia.deis.unibo.it/research/Proteus.
2 http://clarkparsia.com/pellet

248
A. Toninelli, A. Corradi, and R. Montanari
To build a test setting for our evaluations, we considered a mobile healthcare
scenario, where access control policies are needed to regulate access to private
health information (PHI) of patients, such as their electronic medical record.
Example policy, protection context and QoC constraints are represented in Table
1 and 2 according to a concise DL format. For our case study, we developed an
application speciﬁc ontology, including concepts like Physician, Healthcare center
and PHI, to integrate with Proteus policy, context and QoC ontologies.
5.1
Performance Evaluation
Our tests were executed on a AMD Athlon 2800+ processor @2.08GHz, with
1024 MB RAM, running Windows XP SP2, Java SE 1.6.0 03 and Pellet 1.5.
We also performed tests in a distributed deployment setting. To avoid a biased
evaluation of QoC-related overhead due to variable network conditions, however,
we do not consider them in this evaluation.
Context Repository Management. Managing the context Repository re-
quires to add and remove context assertions provided by context sources, to
keep the current state KB up to date and QoC-compliant. We have measured
the time needed to add/remove a new context assertion in the Repository with
the repository dimension growing up. After each context assertion addition or re-
moval, the CM Reasoning unit performs a consistency check. Pellet 1.5 provides
support for incremental reasoning (IR), i.e., optimized reasoning when variations
in the knowledge base only involve assertions (ABox) and not ontology concepts
(TBox). Results show that Pellet incremental reasoning signiﬁcantly increases
eﬃciency in case of context assertion addition: by enabling IR, addition times
tend to keep constant, around 10 ms, with repository size varying from 100 to
25k context assertions. As for removal times, IR does not bring any substantial
advantage: for example, with 1k context assertions in the repository, times keep
below 5.2 seconds, both with and without IR.
Query. Another critical evaluation regards the Reasoning unit response time to
context queries. We particularly focus on queries executed to periodically remove
context assertions based on their QoC. We measured the response time to four
diﬀerent types of SPARQL query with increasing complexity: each query basi-
cally retrieves context assertions having one/two/three constraints on quality
parameters, while the trivial query has no constraints on QoC (thus returning
all context assertions in the repository). Below is shown the most complex query:
SELECT ?ca WHERE
{ ?ca context:hasQuality ?q.
?q context:hasCorrectness ?qp1.
?q context:hasPrecision ?qp2.
?q context:hasFreshness ?qp3.
FILTER (?qp1 > 0.5 && ?qp2 > 0.5 && ?qp3 > 0) }

A Quality of Context-Aware Approach to Access Control
249
Fig. 4. Average times to answer QoC-based ﬁltering queries
In this test, the repository was initialized with a number of assertions hav-
ing the same predicate and diﬀerent subjects, objects and QoC attribute values
(randomly determined). As shown in Figure 4, queries with QoC constraints are
answered within 10 ms, while response times for the query with no QoC con-
straints (not shown here) indicate a linear dependence with the repository size.
These results show that QoC-based context assertion ﬁltering brings a signiﬁcant
advantage also in terms of performance.
6
Related Work
Several research eﬀorts have addressed the issue of ensuring security in mo-
bile/pervasive environments, particularly access control to shared resources.
Considering context as a design principle is a novel research direction with few
emerging proposals of context-based policy models, mainly in the ﬁeld of ac-
cess control. Quality of context has also been the subject of recent research
eﬀorts, which have investigated representation models, calculation techniques
and distributed architectures for applying QoC to context provisioning and
management/context-aware systems. To the best of our knowledge, however,
none of existing solutions considers the issue of modeling, evaluating and assess-
ing the security impact of QoC when used to regulate access to resources. In this
section we review some signiﬁcant research eﬀorts in the ﬁelds of context-based
security and QoC support for context management systems, respectively.
The security model presented in [9] extends role-based access control by cre-
ating a new type of role called environment role. Environmental roles, which
capture relevant conditions in the current situation, are used to restrict user
privileges in accessing resources. Acting as intermediaries between users and
permissions they are similar to Proteus protection contexts. The implicit assump-

250
A. Toninelli, A. Corradi, and R. Montanari
tion, however, is that environmental roles activation is always reliable and the
model does not deal with possibly incorrect or imprecise context information. In
addition, no integrated support for environmental role/policy representation at a
high level of abstraction and reasoning is provided. The context-sensitive access
control Cerberus framework implicitly deals with QoC by supporting authenti-
cation with a variable “conﬁdence level”: diﬀerent strengths of authentication
are associated with conﬁdence values representing how conﬁdent the authenti-
cation system is about the identity of the principal [10]. Although the concept
of conﬁdence is clearly related to QoC, mainly trustworthiness and correctness,
Cerberus does not provide any explicit modeling support for QoC and only deals
with quality for authentication mechanisms. Several other context-aware access
control solutions for distributed/pervasive environments have recently emerged,
such as [11] and [12], but they do not support QoC management not take QoC
security impact into account when controlling access to resources.
The term “quality of context” was ﬁrstly introduced in work by Buchholz,
which provided the original concept and a set of base QoC attributes [4]. Vari-
ous research works have deﬁned since then QoC abstraction and representation
models, mostly referring to a similar set of quality attributes, such as the ones de-
scribed in [5]. Proteus support the representation of all signiﬁcant attributes, but
also allows the application developer to personalize the set of needed attributes.
Some approaches provide ontology models to represent quality parameters, ei-
ther modeled with logic predicates [10], or with DL-based ontologies [13, 14].
With respect to these ontologies, the Proteus QoC ontology has the advantage
of being built on RDF reiﬁcation model, thus simplifying representation and
reasoning since based on the very structure of adopted semantic languages.
As far as QoC values calculation is concerned, very few existing systems ac-
tually provide applicable methods to numerically determine quality attribute
values: [7], for example, represents a promising direction as it describes func-
tions to concretely calculate accuracy and correctness values.
7
Conclusions and Future Work
Context-aware access control solutions, which exploit context-awareness to con-
trol access to resources based on context visibility and changes, should take into
account the security impact deriving from the quality of context information
used to regulate access decisions. In this paper we presented Proteus, a QoC-
aware access control framework for sharing resources in pervasive environments.
Proteus exploits QoC and semantic technologies to discard context data with
insuﬃcient quality, and to select applicable policies based not only on current
context, but also on its quality. This helps minimizing the risk of granting ac-
cess to resources based on incorrect or ambiguous context information, while
reducing the overhead due to policy management.
First evaluations on Proteus prototype middleware show encouraging results.
We are currently working on an optimized context data storage model to make

A Quality of Context-Aware Approach to Access Control
251
context assertion removal faster and more eﬃcient. We are also testing perfor-
mances with the new support for incremental reasoning provided with the Pellet
2.0. Finally, we are planning to extend the current CM implementation with
additional context source modules to support interaction with diﬀerent context
provisioning systems.
References
1. Toninelli, A., et al.: A semantic context-aware access control framework for secure
collaborations in pervasive computing environments. In: ISWC, pp. 473–486 (2006)
2. Dey, A.K.: Understanding and using context. Personal and Ubiquitous Comput-
ing 5(1), 4–7 (2001)
3. Sandhu, R.S., et al.: Role-based access control models. IEEE Computer 29(2), 38–
47 (1996)
4. Buchholz, T., Kupper, A., Schiﬀer, M.: Quality of context: What it is and why we
need it. In: HPOVUA 2003 (2003)
5. van Sinderen, M., et al.: Supporting context-aware mobile applications: an infras-
tructure approach. Communications Magazine 44(9), 96–104 (2006)
6. Lassila, O., Khushraj, D.: Contextualizing applications via semantic middleware.
In: MOBIQUITOUS 2005, pp. 183–191. IEEE Computer Society, Washington
(2005)
7. Kim, Y., Lee, K.: A quality measurement method of context information in ubiq-
uitous environments. In: ICHIT 2006, vol. 2, pp. 576–581 (November 2006)
8. Riva, O.: Contory: A middleware for the provisioning of context information on
smart phones. In: Middleware, pp. 219–239 (2006)
9. Covington, M.J., et al.: Securing context-aware applications using environment
roles. In: SACMAT 2001, pp. 10–20. ACM, New York (2001)
10. Al-Muhtadi, J., et al.: Cerberus: a context-aware security scheme for smart spaces.
In: PerCom 2003, pp. 489–496 (March 2003)
11. Dersingh, A., Liscano, R., Jost, A.: Utilizing semantic knowledge for access control
in pervasive and ubiquitous systems. In: WIMOB 2008, pp. 435–441 (October 2008)
12. Lachmund, S., et al.: Context-aware access control; making access control decisions
based on context information. In: Mobiquitous 2006, pp. 1–8 (July 2006)
13. Tang, S., Yang, J., Wu, Z.: A context quality model for ubiquitous applications.
In: IFIP NPC Workshops, pp. 282–287 (September 2007)
14. Bu, Y., et al.: Managing quality of context in pervasive computing. In: QSIC 2006,
pp. 193–200 (October 2006)

A Service-Oriented Framework
Supporting Ubiquitous Disaster Response
Michele Amoretti, Maria Chiara Laghi, and Gianni Conte
Information Engineering Department, University of Parma, 43100 Parma, Italy
michele.amoretti@unipr.it, laghi@ce.unipr.it, gianni.conte@unipr.it
http://dsg.ce.unipr.it
Abstract. The synergy of ubiquitous computing and service-oriented
technologies may lead to eﬃcient, pervasive and dependable solutions
in the challenging context of emergency management. Recently, novel
paradigms have been proposed, most of them envisioning arbitrary pairs
of peer application entities communicating and providing services di-
rectly with each other and to users. In order to enforce these paradigms
even to systems which include devices with limited processing and stor-
age resources, lightweight middleware components are required. We il-
lustrate how this is provided by JXTA-SOAP, a portable software com-
ponent supporting peer-to-peer sharing of Web Services, and we show
how it can be used to implement disaster response software applications.
Keywords: Mobility, disaster response, middleware, services, peer-to-
peer.
1
Introduction
Emergency management (or disaster management) is the discipline of dealing
with and avoiding risks [13]. It involves preparing for disaster before it happens,
disaster response (e.g. emergency evacuation, quarantine, mass decontamination,
etc.), as well as supporting and rebuilding society after natural or human-made
disasters have occurred. The disaster management cycle involves four key phases:
1. Mitigation: includes any activities that prevent a disaster, reduce the chance
of a disaster happening, or reduce the damaging eﬀects of unavoidable dis-
asters.
2. Preparedness: includes plans or preparations made to save lives or property,
and to help the response and rescue service operations.
3. Response: includes actions taken to save lives and prevent property dam-
age, and to preserve the environment during emergencies or disasters. The
response phase is the implementation of action plans.
4. Recovery: includes actions that assist a community to return to a sense of
normalcy after a disaster.
These four phases usually overlap. Information and Communication Technology
(ICT) is being used in all the phases, but the usage is more apparent in some
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 252–265, 2009.
c
⃝Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

A Service-Oriented Framework Supporting Ubiquitous Disaster Response
253
phases than in the others. For example, ICT support is very important dur-
ing the disaster response (DR) phase of an emergency, which may commence
with search and rescue, but in all cases the focus will quickly turn to fulﬁlling
the basic humanitarian needs of the aﬀected population. This assistance may
be provided by national or international agencies and organisations. Eﬀective
coordination of disaster assistance is often crucial, particularly when many or-
ganisations respond and local emergency management agency capacity has been
exceeded by the demand or diminished by the disaster itself. Tracing missing
people, coordinating donor groups, recording the locations of temporary camps
and shelters are examples of problems in the immediate post-disaster period that
can be eﬀectively addressed by using ICT.
In this paper we focus on disaster response exploitation based on the concept
of ubiquitous computing, whose main objective is to provide globally available
services and resources in a network by giving users the ability to access them
anytime and anywhere. In particular, we consider novel paradigms and propose
advanced technical solutions for DR-supporting distributed systems. Recently,
Gaber [8] has proposed two alternatives to the traditional client/server paradigm
(CSP) to design and implement ubiquitous and pervasive applications: the Adap-
tive Services/Client Paradigm (SCP) and the Spontaneous Service Emergence
Paradigm (SEP). In other words, the peer-to-peer paradigm is completed re-
spectively by the self-organization and the self-adaptation principles. In SCP a
decentralized and self-organizing middleware that implements an intelligent net-
work should be able to provide services to users according to their availability
and the network status. In SEP, spontaneous services can be created on the ﬂy
and be provided by mobile devices that interact through ad hoc connections
without any prior planning.
In order to enforce these paradigms to systems which include devices with
limited processing and storage resources, lightweight middleware components
are strongly required. In [5], Bodhuin et al. compare some traditional solutions
for net-centric computing middleware, such as Jini, OSGi and CORBA, listing
their pros and cons. Not surprisingly, the survey does not include Sun MicroSys-
tem’s JXTA [28], probably due to the fact that in year 2005 an implementation
for mobile devices was not completed. JXTA is mainly the speciﬁcation of a
set of open protocols for building overlay networks, independent from platforms
and languages. Currently there are three oﬃcial implementation of JXTA proto-
cols: J2SE-based, J2ME-based and C/C++/C♯-based. In particular, an almost
complete version of the JXTA Java Micro Edition (JXTA-J2ME, a.k.a. JXME)
has been recently released. It provides a JXTA compatible platform on resource
constrained devices using the Connected Limited Device Conﬁguration (CLDC)
with Mobile Information Device Proﬁle 2.0 (MIDP), or Connected Device Con-
ﬁguration (CDC). Supported devices range from smartphones to PDAs.
How does JXTA cope with the service concepts characterizing the previously
summarized paradigms for ubiquitous computing? The Web Service community
considers services as the only mean for accessing resources (this concept has been
explicitly formalized in the WSRF speciﬁcation [34]), yet centralized registries,

254
M. Amoretti, M.C. Laghi, and G. Conte
themselves exposed as services (like UDDI), are still deemed the primary tool to
support the publication and the discovery phases. Unfortunately, a peer-to-peer
network of Web Service providers with a publication/discovery infrastructure
implemented as a set of interacting Web Services would be absolutely uneﬃcient
due to the heavyness of the SOAP messaging protocol. On the other side, in
JXTA each peer’s service is just an example of resource which can be exploited
by the user which owns the peer, or shared in the network, i.e. advertised by the
user and exploited by other users. Resource descriptions have the shape of XML
documents, namely advertisements. A JXTA advertisement can be ﬁlled with
any document, e.g. a WSDL interface if the shared resource is a Web Service. In
summary, JXTA provides a lot of ﬂexibility by separating basic infrastructural
services, mandatory for all peers, from specialized services, with diﬀerent levels
of description and eﬃciency.
Within the context of JXTA and Web Service integration, we are responsi-
ble for the development and maintenance of the JXTA-SOAP component [16],
enabling Web Service deployment in JXTA peers, as well as distributed WSDL
publication and discovery, and SOAP message transport over JXTA pipes (i.e.
virtual communication channels which may connect peers that do not have a
direct physical link, resulting in a logical connection bound to peer endpoints
corresponding to available peer network interfaces with an example being a TCP
port and associated IP address). JXTA-SOAP is currently implemented in two
versions: J2SE-based (fully featured, extending JXTA-J2SE) and J2ME-based
(partially featured, extending JXME).
The remainder of the paper is organized as follows. Section 2 illustrates the
technological franework we propose to support disaster response activities. Sec-
tion 3 describes related work on disaster response ICT systems, middleware
for peer-to-peer service-oriented ubiquitous computing, and Web Services on
resource-constrained devices. An overview of the internal design of the JXTA-
SOAP component, and many details about its J2SE and J2ME implementations,
are given in section 4. Section 5 describes a disaster response application we de-
veloped on top of JXTA-SOAP. Finally, section 6 provides a conclusive discussion
and describes future work.
2
Proposed Technological Framework
Disasters can happen anywhere at any time. Some disasters can be prevented,
while some others cannot. Preparedness however greatly increases our chances
to reduce their impact. Developing eﬀective early warning and alert systems
often can save thousands of human lives. From the 2004 tsunami in the Indian
Ocean to the forest ﬁres that ravaged southern Europe in the summer of 2007,
recent natural and man-made disasters (including also conﬂict-related complex
emergencies) have highlighted the need for a more eﬀective response.
In the area of civil protection the European Commission has recently pro-
posed to improve the EU’s capacity through a number of important measures
[6]. Among others, building up the Monitoring and Information Centre (MIC),

A Service-Oriented Framework Supporting Ubiquitous Disaster Response
255
playing the role of operational centre for European civil protection interven-
tion. This requires a qualitative shift from information sharing/reacting to emer-
gencies towards proactive anticipation/real time monitoring of emergencies and
operational engagement/coordination. This includes early warning systems,
performing needs assessments, identifying matching resources, and providing
technical advice on response resources to the Member States; developing sce-
narios, standard operating procedures and lessons learned assessments; imple-
menting the Commission competencies to pool available transport and provide
co-ﬁnancing for transport; increasing training and exercise activities for Mem-
ber States and other experts; and helping the Member States to set up common
resources. This implies also the use of monitoring capabilities such as those
developed under the Global Monitoring for Environment and Security (GMES)
initiative [11] or enabling tools like GALILEO (the European satellite navigation
system) [9].
Our framework focuses on the problem of identifying matching resources in
response to disasters. The most important are human resources, i.e. Civil Protec-
tion volunteers, Red Cross doctors and medical attendants, ﬁremen, policemen,
army oﬃcers, etc. In a typical scenario, it is necessary to coordinate the ac-
tion of rescuers that are already in the disaster location, and those that are
on vehicles and may be requested to reach the disaster place. The purpose of
our work is also to support the work of the back-end operators, improving the
ICT infrastructure that must allow not only communications among actors, but
also automated gathering, elaboration and delivery of the huge amount of data
collected by each actor.
For example, in case of ﬂooding, ﬁrst volunteers arriving at the disaster loca-
tion may notice that some roads are interrupted. If they are equipped with a mo-
bile device including a camera, they may (1) send short alert messages, including
their coordinates obtained by means of GPS/GIS, and (2) take and send photos
to provide a more detailed description of the environment. The back-end system
collects and ﬁlter these data, and sends useful advices (such as the best route to
be followed) to rescue vehicles which are directed to the disaster place (ﬁg. 1).
Fig. 1. The back-end system, the rescue operators and vehicles are connected in a peer-
to-peer overlay network, oﬀering services to each others (left image). Connectivity is
guaranteed by diﬀerent technological solutions (right image).

256
M. Amoretti, M.C. Laghi, and G. Conte
The infrastructure of the service-oriented applications we envision is a peer-
to-peer overlay network, which is placed at level 5 in the TCP/IP stack and is
almost independent from the possible connectivity solutions, that we summarize
in the following.
For long distance communications, in Europe the most used infrastructure is
General Packet Radio Service (GPRS), which is a packet-oriented Mobile Data
Service available to users of Global System for Mobile Communications (GSM)
and IS-136 mobile phones (the so-called second generation - 2G). It provides
data rates from 56 up to 114 kbit/s. A more powerful technology which is as-
suming higher importance is the Universal Mobile Telecommunications System
(UMTS), one of the third-generation (3G) cell phone technologies, which is also
being developed into a 4G technology. Both 2G and 3G technologies require the
presence of base stations on the territory. In case of heavy disasters such as hur-
ricanes, base stations may be damaged, for which satellite and/or TETRA-based
communications are the other options. TETRA is a telecommunications stan-
dard for Private Mobile Radio (PMR) systems developed by ETSI as an answer,
at European level, to the evolving needs of PMR Operators, which have to cope
with traﬃc congestion and a growing demand for speech and data services.
For local communications among actors equipped with mobile devices, infras-
tructured commmunications are usually based on WiFi. If some devices are out
of the range of the WiFi access point, they can try to set up a mobile ad-hoc
network (MANET), which is a self-conﬁguring network of mobile routers (and
associated hosts) connected by wireless links, the union of which form an arbi-
trary topology. The routers are free to move randomly and organize themselves
arbitrarily; thus, the network’s wireless topology may change rapidly and un-
predictably. Such a network may operate in a standalone fashion, or may be
connected to the larger Internet.
3
Related Work
This section illustrates the state of the art of software architectures supporting
rescue operators during emergencies, technologies for ubiquitous peer-to-peer
service sharing, and middleware solutions for deploying and consuming Web
Services on resource-constrained devices.
3.1
State-of-Art DR Projects
In emergency scenarios, several teams belonging to diﬀerent organizations need
to collaborate in disaster management activities. The WORKPAD project [35],
funded by the EU Commission, focuses on response and short-term recovery
phases in which Public Safety Systems (PSS) use computer programs to give
instructions to the rescue teams. Each team member is equipped with hand-held
devices (PDAs) and communication technologies, and should carry on speciﬁc
tasks. The developed framework has two diﬀerent levels: an integrated back-
end community, mainly constituted by traditional computers, that interact in a

A Service-Oriented Framework Supporting Ubiquitous Disaster Response
257
peer-to-peer fashion, providing advanced services requiring high computational
power, knowledge and content integration, and a set of front end peer-to-peer
communities that provide services, mainly by adaptively enacting processes on
mobile ad-hoc networks, to human workers.
A service-oriented architecture may be developed to achieve integration and
data exchange among the diﬀerent organizations systems in a disaster scenario,
as proposed in AID-N project [37]. Individual tools interact with the shared
data models through a set of publicly available and descriptive Web Services.
The AID-N architecture addresses critical interoperability challenges through the
design of data models to support a diverse variety of data from disparate systems,
the design of data exchange standards to access the data model, and the design
of web services that support the information needs for each system. This archi-
tecture enables real-time data communication between three deployed systems:
a pre-hospital patient care reporting software system, a syndromic surveillance
system and a hazardous material reference software system.
In [38] an Artiﬁcial Emergency-Logistics-Planning System (AELPS) is en-
visioned, which is based on artiﬁcial-society theory and uses agent modeling
to describe the behaviour of basic elements in an emergency-logistics system.
AELPS can form the basis of a complex computational platform that generates
logistics activities during disaster relief and gives intuitive results that can be
used in emergency-logistics planning. The emergency-logistics planning for nat-
ural disaster must simultaneously consider diﬀerent types of request and manage
the formation of coalitions of diﬀerent working units in order to employ diﬀerent
subsystems to manage all the tasks in an emergency situation.
An agent-based simulation approach is described in [39,40] for the evaluation
of scenarios concerning diﬀerent possible rescue processes. A six step methodol-
ogy is proposed for developing a computer based simulator, that needs to know
all the cognitive activities of emergency personnel. Rescue operators have prede-
ﬁned roles but may also organize themselves dinamically in groups and teams.
As in real life, there are predeﬁned rules and procedures, but rescue personnel
often react to their environment in an unpredictable way. By modeling rescue
personnel as agents, these characteristics made an agent-based apppproach a
suitable tecnique to use. The multi-agent model also includes the notion of cen-
tralized rescue strategy used in real life; the simulator is used to test the eﬀects
of a distributed strategy, that is where independent sub-teams cooperate and
share resources.
3.2
Ubiquitous Peer-to-Peer Sharing of Services
OSGi [21] is a Java-based technology which provides a service-oriented plug-in-
based platform for application development. The core component of the OSGi
Speciﬁcations is the OSGi Framework, which provides a standardized environ-
ment to applications (called bundles). On top of the Framework, services are
speciﬁed by a Java interface. Bundles can implement this interface and regis-
ter the service with the Service Registry. Clients of the service can ﬁnd it in
the registry, or react to it when it appears or disappears. Advanced networking

258
M. Amoretti, M.C. Laghi, and G. Conte
features, such as e.g. peer-to-peer connectivity, are not provided by OSGi and
must be implemented on top of it.
To the best of our knowledge JXTA-SOAP is the sole open source project for
P2P sharing of Web services being actively maintained and updated. WSPeer
[14] is a J2SE toolkit for deploying and invoking Web Services in peer-to-peer
Grid environments, which wraps Globus Toolkit core libraries to support the
WS Resource Framework (WSRF) [34]. More interesting for ubiquitous comput-
ing environments is the Mobile Web Services Mediation Framework (MWSMF)
[26,27], an adaptation of Apache ServiceMix, which is an open source ESB (En-
terprise Service Bus). It provides an hybrid solution, since it must be conﬁgured
as JXTA-J2SE peer and established as an intermediary between Web Service
clients and mobile hosts, the latter being conﬁgured as JXME peers. Web Ser-
vice clients can invoke the services deployed on mobile hosts via the MWSMF,
which compresses SOAP messages (to BinXML format) and sends them through
JXTA pipes. The MWSMF also manages message persistence, guaranteed deliv-
ery, failure handling and transaction support. Unfortunately, the source code is
not publicly availble and few details are given about the realization of lightweight
Web Service providers running on mobile hosts.
3.3
Web Services on Resource-Constrained Devices
Besides hardware constraints, mobile devices introduce many other speciﬁc chal-
lenges which make diﬃcult the deployment of Web Services on top of them [4].
Unlike dedicated servers, mobile devices will typically have intermittent connec-
tivity to the network. As a result, the services oﬀered on a mobile device may
not be accessible all the time. An application that uses or composes such Web
Services needs to operate in an opportunistic manner, leveraging such services
when they become available. On the server side, Web Services on mobile de-
vices should also attempt to keep messages as short as possible. Another issue
is addressing: when a mobile device moves between diﬀerent locations, it may
move from one administrative domain to another, causing a change in the IP
address and even the Internet domain name. However, with the P2P in place,
the need for the Public IP can be eliminated and the mobiles can be addressed
with unique peer ID. Each device in the P2P network is associated with the
same peer ID, even though the peers can communicate with each other using
the best of the many network interfaces supported by the devices like Ethernet,
WiFi, etc. [26].
Since the WS message protocol, namely SOAP, introduces some signiﬁcant
overhead, few toolkits support the deployment of Web Services on limited de-
vices, such as PDAs, smart phones, etc. One is gSoap [30], which provides a WS
engine with run-time call de-serialization. Unfortunately, gSoap is written in
C/C++, thus requiring a priori stub/skeleton generation by means of a speciﬁc
compiler, which also means lack of portability.
Looking at the Java Micro Edition (J2ME) platform, most libraries are only
for client side functionality. The Java Wireless Toolkit (WTK) provides J2ME
Web Services API (WSA) [32], based on JSR 172 [17], which speciﬁes runtime

A Service-Oriented Framework Supporting Ubiquitous Disaster Response
259
ServiceProvider interface to allow the generation of portable stubs from WSDL
ﬁles. The speciﬁcation contains some notable limitations, most of them due to
the requirement for WS-I Basic Proﬁle compliance. Conforming to the proﬁle
ensures interoperability, but also prevents using alternative methods. Another
widely used solution is the kSoap2 [19] open source component, which is a parser
for SOAP messages (with RPC/literal or document/literal style encoding), not
supporting the generation of client side stubs. kSoap2 is compliant with devices
lacking JSR 172 support, and allows to access non WS-I conformant services.
To the best of our knowledge, the unique solution enabling J2ME applications
(CLDC, CDC) as service endpoints is the Micro Application Server (mAS) [20].
It can be considered a lightweight version of Axis, by which it is inspired. For
this reason we have chosen it to implement the J2ME version of JXTA-SOAP.
4
The JXTA-SOAP Component
JXTA is a Sun MicroSystems’ open framework which deﬁnes peer-to-peer pro-
tocols that should allow a vast class of networked devices (smartphones, PDAs,
PCs and servers) to communicate and collaborate seamlessly in a highly decen-
tralized fashion. The JXTA framework deﬁnes a naming scheme, advertisements,
peergroups, pipes, and a number of core policies, while the JXTA middleware
implements the speciﬁcations in Java and C++.
The JXTA-SOAP component is an oﬃcial extension for the Java version
of JXTA middleware, enabling Web Service sharing in peer-to-peer networks.
JXTA-SOAP has been designed having in mind ubiquitous computing needs,
to reduce the complexity otherwise required to build and deploy peer-to-peer
service-oriented applications. In a previous work we described the internal archi-
tecture of JXTA-SOAP, with the purpose of conceptualizing its main features
at a high abstraction level [2]. In particular we focused on service deployment,
publication, lookup and invocation, considering also security aspects.
Fig. 2. Architectural layers of service-oriented peers based on JXTA-SOAP. The J2SE
version (on the left) is based on Axis and JXSE, while the J2ME version (on the right)
is based on kSoap2 and mAS.

260
M. Amoretti, M.C. Laghi, and G. Conte
The internal architecture of JXTA-SOAP based peers is illustrated in ﬁgure 2.
We implemented two (interoperable) versions of JXTA-SOAP: J2SE-based, ex-
tending JXTA-J2SE, and J2ME-based, extending JXTA-J2ME. In the following
we describe their features and the diﬀerent technological solutions they rely on.
4.1
JXTA-SOAP for Java Standard Edition (J2SE)
The J2SE version of the JXTA-SOAP component supports service deployment,
discovery, and invocation, with optional use of standard mechanisms to secure
communications among peers. The core of the component is the Apache Axis
engine (v1.4), which is a producer/consumer of SOAP messages. Usually Axis
is deployed in a Web application server, such as Apache Tomcat, together with
the implementions of the Web Services to be deployed, while client applications
use the Axis Java API to create request instances. The Axis engine provides
the processing logic, either client or server. When running, it invokes a series
of Handlers according to a speciﬁc order which is determined by two factors -
deployment conﬁguration, and whether the engine is a client or a server. The
object which is passed to each Handler invocation is a MessageContext, i.e. is a
structure which contains several important parts: 1) a ”request” message, 2) a
”response” message, and 3) a bag of properties.
At runtime, for a service provider its service objects are deployed in the Axis
engine, which implements the JAX-RPC API, one of the standard ways to pro-
gram Java services, also supporting the lifecycle of service endpoint instances.
After being loaded and instantiated, the JAX-RPC runtime system is required
to initialize the service instance before any requests can be serviced. A context
parameter is pssed to the initialization function, enabling the service instance
to access the context provided by the underlying JXTA-SOAP based runtime
system. The context parameter is typecasted to an appropriate Java type. For
services deployed in a JXTA-SOAP based runtime system, the Java type of the
context parameter is deﬁned by the developer that is using the JXTA-SOAP
API, and passed to the service object. The latter instantiates the Service De-
scriptor, creates and publishes the public pipe and the service advertisement,
and notiﬁes itself to the Axis engine. Services can be deployed anytime, without
the need to restart the peer.
Once a service instance has been initialized, the Axis engine may dispatch
multiple remote invocations to it. After that, when the Axis engine determines
that the service instance needs to be removed from service of handling remote
invocations, it destroys it. In the implementation of the destruction functionality,
the service object releases its resources.
For remote service invocation, a consumer peer needs to intantiate a Call ob-
ject. JXTA-SOAP’s Call class extends Axis’ default one, overloading the use of
service URLs with the use of the Service Descriptor and the public pipe advertise-
ment of the service. To create Call instances, the peer uses the implementation
of the Call Factory class provided by Axis.
We previously described the tasks which are performed when a Web Ser-
vice is deployed by a peer, and we mentioned that some parameters are put in

A Service-Oriented Framework Supporting Ubiquitous Disaster Response
261
the Service Descriptor for further use by the Axis engine. In particular, one of
these parameters is the Web Service Deployment Descriptor (WSDD). When
the WSDD is sent to the Axis engine running in the peer, an Invoker [31] is in-
formed that it supports the new Web Service. Thus, when an invocation reaches
the peer, the Invoker looks up the class which implements the service, and lets
the instance handle the request message. In details, the Invoker reads incom-
ing messages and demarshals the parameters inserted by the consumer peer’s
Requestor (absolute reference of the service, operation name, arguments, return
value) and dispatches the message to the targeted service.
4.2
JXTA-SOAP for Java Micro Edition (J2ME)
The J2ME version of JXTA-SOAP supports Connected Device Conﬁguration
(CDC) and Personal Proﬁle. We implemented the API which enables the de-
velopment of peers that are able to deploy, provide, discover and consume Web
Services in a JXTA-SOAP network. Since Axis is not available for the CDC
platform, we adopted kSoap2 [19] as SOAP parser (for consumer functionalities)
and, for service provision, we integrated the mAS [20] lightweight engine.
Service invocation is allowed by a kSoap2 based implementation of the Call
Factory class. The latter instantiates a kSoap2’s Soap Object, and sets all the
properties for message exchanging through JXTA pipes. Soap Object is a highly
generic class which allows to build SOAP calls, by setting up a SOAP envelope.
We have maintained the same structure of J2SE-based version for Call Factory, to
allow portability of service consumer applications from desktop PCs or laptops to
PDAs. Internally, the Call Factory class creates a Soap Object passing references
to the Service Descriptor, the public pipe advertisement of the service and the
peergroup as parameters for the creation of the Call object.
The Call Factory class also allows to create an instance of kSoap Pipe Trans-
port, the class we implemented to manage the transmission of SOAP messages
using service pipes. The kSoap2 API provides a Transport class that encap-
sulates the serialization and deserialization of SOAP messages, but does not
manage communication with the service; the HTTP Transport subclass, both in
CDC and CLDC version, allows service invocation over HTTP, setting up the re-
quired properties, but it uses URLs as absolute references of remote services, and
it is not suitable for usage in JXTA-SOAP, where services (as every resource)
are identiﬁed by JXTA-IDs and must be invoked through JXTA pipes. Thus,
we extended the Transport class with the implementation of a call functionality
that conﬁgures a JXTA pipe and creates the messages to be sent over it.
After instantiating the transport using the Call Factory class, the consumer
peer creates the request object, indicating the name of the remote method to
invoke and setting the input parameters as additional properties. This object is
assigned to a Soap Serialization Envelope, as the outbound message for the soap
call; Soap Serialization Envelope is a kSoap2 class that extends the basic Soap
Envelope, providing support for the SOAP Serialization format speciﬁcation and
simple object serialization. The same class provides a getResponse method that
extracts the parsed response from the wrapper object and returns it.

262
M. Amoretti, M.C. Laghi, and G. Conte
Referring to service provision, we integrated the Server class of the Micro
Application Server (mAS) into the basic service class of the JXTA-SOAP API.
mAS implements the Chain of Responsibility pattern [12], the same used in
Axis. It avoids coupling the sender of a request to its receiver by giving more
than one object a chance to handle the request; receiving objects are chained
and and the request passed along the chain until an object handles it. Moreover,
mAS allows service invocation by users and service deployment by administrator;
it also supplies browser management of requests, distinguishing if the HTTP
message contains a Web page request or a SOAP envelope.
5
Example DR Application
Using JXTA-SOAP mobile, we developed a GUI-based application that allows
to join a JXTA-based P2P network to share services for supporting disaster
response activities. The application has several overlapping panels (or tabs),
each one being related to a speciﬁc function. In the following we describe them,
with the help of the screenshots that have been grouped in ﬁgure 3.
The Local panel (top left screenshot in ﬁgure 3) shows locally deployed ser-
vices. A table lists all services and a Share Service button allows to publish their
advertisements. The back-end system can invoke these services without inter-
rupting the activity of the rescue operator. For example, there could be a service
which provides the location of the rescue operator. Another (less obvious) service
Fig. 3. Local services panel (top left). Remote service selection panel (top right). Oper-
ation management panel (bottom left). A photo of the disaster location is taken, and a
short description written, both ready to be sent to the beck-end upon request, or proac-
tively by the rescue operator. Task panel (bottom right), where the rescue operator can
see its tasks (decided by the back-end) and ﬂag them as executed, when they are.

A Service-Oriented Framework Supporting Ubiquitous Disaster Response
263
provides the photos of the disaster location that have been taken from the op-
erator, without interrupting his activity. Other services could require the rescue
operator to provide information to the service requestor (the back-end system,
but also other operators).
The Remote panel shows discovered remote services. It is possible to search
for services in the P2P network (oﬀered by other rescue operators), and to select
one of them from the resulting list, in order to see all the operations it oﬀers,
which are shown in the Operation tab. The user puts a description of the desired
service in the search ﬁeld, and all the matching services are listed in the table.
Some services from the back-end are assumed to be always available, such as
getPhotoFromSatellite.
The Operation management panel shows all the functionalities provided by
the selected service; the operator can choose a particular operation and ﬁll the
input parameters table in the invocation panel.
The Invocation panel is where the user introduces the required parameters for
service invocation. If the service returns a result, the user can select where to save
it, for example in a ﬁle stored locally. Finally, the Task tab is the one in which
the rescue operator can see its task list, provided by the back-end depending on
the equipment of the operator.
6
Conclusions and Future Work
In this paper we proposed JXTA-SOAP as a powerful solution for building
service-oriented, peer-to-peer ubiquitous applications to support disaster re-
sponse activities. The JXTA-SOAP component enables Web Service deployment,
distributed publication and discovery, and SOAP message transport over the
JXTA peer-to-peer overlay network. All kinds of devices, also constrained ones,
can be used, because JXTA-SOAP comes in two interoperable versions: J2SE-
based and J2ME-based.
Future work on JXTA-SOAP will mainly focus on implementing the Web
Service Resource Framework [34], in order to provide peers the ability to access
and manipulate state, i.e. data values that persist across, and evolve as a re-
sult of, Web Service interactions. This is particularly important for services like
Disaster Location Monitoring, which requires to collect contextual data but also
historical information from services dispersed over the network.
References
1. MIT Computer Science and Artiﬁcial Intelligence Laboratory, AIRE Group,
http://aire.csail.mit.edu/index.shtml
2. Amoretti, M., Bisi, M., Zanichelli, F., Conte, G.: Enabling Peer-to-Peer Web
Service Architectures with JXTA-SOAP. In: IADIS International Conference
e-Society 2008, Algarve, Portugal (April 2008)

264
M. Amoretti, M.C. Laghi, and G. Conte
3. Avatangelou, E., Dommarco, R.F., Klein, M., Muller, S., Nielsen, C.F., Soriano,
M.P.S., Schmidt, A., Tazari, M.-R., Vichert, R.: Conjoint PERSONA-SOPRANO
Workshop. In: Proc. of the ﬁrst European Conference on Ambient Intelligence
(AmI 2007), Darmstadt, Germany (November 2007)
4. Berger, S., McFaddin, S., Narayaswami, C., Raghunath, M.: Web Services on
Mobile Devices - Implementation and Experience. In: Proc. of the Fifth IEEE
Workshop on Mobile Computing Systems & Applications, Monterey, CA, USA
(October 2003)
5. Bodhuin, T., Canfora, G., Preziosi, R., Tortorella, M.: Open Challenges in Ubiqui-
tous and Net-Centric Computing Middleware. In: 13th IEEE International Work-
shop on Software Technology and Engineering Practice (September 2005)
6. Commission of the European Communities. Communication on Reinforcing the
Union’s Disaster Response Capacity. Brussels (March 2008)
7. Edwards, S.: User Driven and Seamless Mobility Services for Disabled and Older
People: the ASK-IT Project. In: Proc. of the 5th Annual Moving On Conference,
Glasgow (March 2006)
8. Gaber, J.: Spontaneous Emergence Model for Pervasive Environments. In: IEEE
Globecom Workshop 2007, Washington DC (November 2007)
9. Gallup Organization. General public survey on the European Galileo Programme
(June 2007)
10. Granville, L.Z., Panisson, A.: GigaMAN P2P project,
http://gigamanp2p.inf.ufrgs.br
11. Commission of the European Communities. Communication on Global Monitoring
for Environment and Security (GMES): Establishing a GMES capacity by 2008,
Brussels (2004)
12. Gamma, E., Helm, R., Johnson, R., Vlissides, J.: Design Patterns. Addison-
Wesley, Reading (1995)
13. Haddow,
G.D.,
Bullock,
J.A.:
Introduction
to
Emergency
Management.
Butterworth-Heinemann, Amsterdam (2004)
14. Harrison, A., Taylor, I.: WSPeer - An Interface to Web Service Hosting and In-
vocation. In: Proc. of the 19th IEEE International Parallel and Distributed Pro-
cessing Symposium (IPDPS 2005), Denver, Colorado, USA (May 2005)
15. IST Advisory Group, Scenarios for Ambient Intelligence in 2010, European Com-
mission (2001)
16. Distributed Systems Group and Sun MicroSystems, JXTA-SOAP project,
https://soap.dev.java.net
17. Sun MicroSystems, JSR 172: J2ME Web Services Speciﬁcation,
http://jcp.org/en/jsr/detail?id=172
18. Krishna, A., Schmidt, D.C., Stal, M.: Context Object: A Design Pattern for Eﬃ-
cient Middleware Request Processing. In: Proc. of the 12th Pattern Language of
Programming Conference, Allerton Park, Illinois (September 2005)
19. Haustein, S., Seigel, J.: kSoap2 project, http://ksoap2.sourceforge.net
20. Plebani, P.: mAS project, https://sourceforge.net/projects/masproject
21. OSGi Alliance, OSGi: the Dynamic Module System for Java, http://www.osgi.org
22. Peters, S., Shrobe, H.: Using Semantic Networks for Knowledge Representation in
an Intelligent Environment. In: Proc. of 1st Annual IEEE International Confer-
ence on Pervasive Computing and Communications (PerCom 2003), Ft. Worth,
TX, USA (March 2003)

A Service-Oriented Framework Supporting Ubiquitous Disaster Response
265
23. Pyarali, I., Spivak, M., Cytron, R., Schmidt, D.C.: Evaluating and Optimizing
Thread Pool Strategies for Real-Time CORBA. In: Proc. of the ACM SIGPLAN
Workshop on Optimization of Middleware and Distributed Systems (OM 2001),
Snowbird, Utah, USA (June 2001)
24. Ramos, C., Augusto, J.C., Shapiro, D.: Ambient Intelligence - the Next Step for
Artiﬁcial Intelligence. IEEE Intelligent Systems 23(2) (March/April 2008)
25. Costa, P., Coulson, G., Mascolo, C., Motolla, L., Picco, G.P., Zachariadis, S.: A
Reconﬁgurable Component-Based Middleware for Networked Embedded Systems.
International Journal of Wireless Information Networks (2006)
26. Srirama, S.N., Jarke, M., Prinz, W.: A Mediation Framework for Mobile Web Ser-
vice Provisioning. In: Proc. of the 10th IEEE International Enterprise Distributed
Object Computing Conference Workshops (EDOCW 2006), Hong Kong, China
(October 2006)
27. Srirama, S.N., Jarke, M., Prinz, W.: MWSMF: a Mediation Framework Realizing
Scalable Mobile Web Service. In: Proc. of Mobilware 2008, Innsbruck, Austria
(February 2008)
28. Traversat, B., Arora, A., Abdelaziz, M., Duigou, M., Haywood, C., Hugly, J.-C.,
Poyoul, E., Yeager, B.: Project JXTA 2.0 Super-Peer Virtual Network, Technical
Report, Sun Microsystems (2003)
29. Vallee, M., Ramparany, F., Vercouter, L.: A multi-agent system for dynamic
service composition in ambient intelligence environments. In: Gellersen, H.-W.,
Want, R., Schmidt, A. (eds.) PERVASIVE 2005. LNCS, vol. 3468. Springer, Hei-
delberg (2005)
30. van Engelen, R.A., Gallivan, K.: The gSOAP Toolkit for Web Services and Peer-
To-Peer Computing Networks. In: Proc. of the 2nd IEEE International Sympo-
sium on Cluster Computing and the Grid (CCGrid 2002), Berlin, Germany, pp.
128–135 (May 2002)
31. Volter, M., Kircher, M., Zdun, U.: Remoting Patterns. Wiley, Chichester (2005)
32. Sun MicroSystems, J2ME Web Services APIs (WSA),
http://java.sun.com/products/wsa/
33. Banaei-Kashani, F., Chen, C., Shahabi, C.: WSPDS Web Services Peer-to-peer
Discovery Service. In: The 2004 International Symposium on Web Services and
Applications, Las Vegas, Nevada, USA (June 2004)
34. OASIS, Web Services Resource Framework (WSRF) v1.2 (April 2006)
35. Catarci, T., de Leoni, M., Marrella, A., Mecella, M., Salvatore, B., Vetere, G., Dust-
dar, S., Juszczyk, L., Manzoor, A., Truong, H.L.: Pervasive Software Environments
for Supporting Disaster Response. In: IEEE Internet Computing 2008 (2008)
36. Mecella, M., Catarci, T., Angelaccio, M., Buttarazzi, B., Krek, A., Dustdar, S.,
Vetere, G.: WORKPAD:an Adaptative Peer-to-Peer Software Infrastructure for
Supporting Collaborative work of Human Operators in Emergency/Disaster Sce-
narios (2006)
37. Hauenstein, L., Gao, T., Sze, T.W., Crawford, D., Alm, A., White, D.: A Cross-
Functional Service-Oriented Architecture to Support Real-Time Information Ex-
change in Emergency Medical Response (2006)
38. Li, L., Tang, S.: An artiﬁcial Emergency-Logistics-Planning System for Severe
Disasters. IEEE Intelligent Systems (July/August 2008)
39. Dugdale, J., Bellamine-Ben Saoud, N., Pavard, B., Pallamin, N.: Simulation and
Emergency Management (2008)
40. Bellamine-Ben Saoud, N., Ben Mena, T., Dugdale, J., Pavard, B., Ben Ahmed,
M.: Assessing large scaleemergency rescue plans: an agent-based approach. Special
Issue on Emergency Management Systems. International Journal of Intelligent
Control and Systems 11(4) (December 2006)

An Analysis of Navigation Algorithms for
Smartphones Using J2ME
Andr´e C. Santos1,3, Lu´ıs Tarrataca1,3, and Jo˜ao M.P. Cardoso2,3
1 IST - Technical University of Lisbon,
Avenida Prof. Dr. Cavaco Silva, 2780-990 Porto Salvo, Portugal
2 University of Porto, Faculty of Engineering, Department of Informatics Engineering
Rua Dr. Roberto Frias, 4200-465 Porto, Portugal
3 INESC-ID, Taguspark,
Avenida Prof. Dr. Cavaco Silva, 2780-990 Porto Salvo, Portugal
Abstract. Embedded systems are considered one of the most poten-
tial areas for future innovations. Two embedded ﬁelds that will most
certainly take a primary role in future innovations are mobile robotics
and mobile computing. Mobile robots and smartphones are growing in
number and functionalities, becoming a presence in our daily life. In this
paper, we study the current feasibility of a smartphone to execute nav-
igation algorithms. As a test case, we use a smartphone to control an
autonomous mobile robot. We tested three navigation problems: Map-
ping, Localization and Path Planning. For each of these problems, an
algorithm has been chosen, developed in J2ME, and tested on the ﬁeld.
Results show the current mobile Java capacity for executing computa-
tionally demanding algorithms and reveal the real possibility of using
smartphones for autonomous navigation.
Keywords: Embedded computing, navigation algorithms, visual land-
mark recognition, particle
ﬁlter, potential ﬁelds, mobile
robotics,
smartphones, J2ME.
1
Introduction
The potential of autonomous navigation is an important aspect for mobile
robotics and for mobile devices with the goal of helping the user to navigate
in certain environments. A mobile device such as a smartphone could be used to
guide the user in museums, shopping centers, exhibitions, city tours, and emer-
gency scenarios when a catastrophe occurs; to control more eﬀectively home
appliances like vacuum cleaners; to assist impaired people, etc.
However, to be eﬃcient and eﬀective, most navigation problems require com-
putationally demanding algorithms. Bearing in mind the previous applications,
this paper presents a performance study of three navigation algorithms when im-
plemented using J2ME technology for mobile devices. To test those algorithms on
the ﬁeld, we use a system composed by a mobile robot and two smartphones. In
this system, a smartphone executes the navigation algorithms and sends control
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 266–279, 2009.
c
⃝Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

An Analysis of Navigation Algorithms for Smartphones Using J2ME
267
Fig. 1. System organization
instructions to the mobile robot using Bluetooth1 (see the system organization
presented in Figure 1). A second smartphone acts as an intelligent visual sensor,
communicating processed visual information to the former smartphone.
By developing and studying the J2ME implementation of navigation algo-
rithms on smartphones, we hope to be contributing to a clear understanding
about the current capabilities of high-end smartphones and J2ME, and possibly
to highlight future improvements on both.
This paper is organized as follows: section 2 gives an overview of navigation
algorithms; section 3 presents the algorithms implemented and the experimental
setup used; section 4 shows experimental results and section 5 presents some
conclusions.
2
Autonomous Navigation
Autonomous navigation has been widely focused by the mobile robotics area
[13]. Navigation is deﬁned as the process or activity of accurately ascertaining
one’s position, planning and following a route. In robotics, navigation refers to
the way a robot ﬁnds its way in the environment [13] and is a common necessity
and requirement for almost any mobile robot.
Leonard and Durrant-Whyte [11] brieﬂy described the general problem of mo-
bile robot navigation by three questions (“Where am I?”, “Where am I going?”,
and “How do I get there?”), each one addressed for a subcategory: Localization,
Mapping and Path Planning.
2.1
Localization - “Where Am I?”
Localization is the process of estimating where the robot is, relatively to some
model of the environment, using whatever sensor measurements are available.
As the robot keeps moving, the estimation of its position drifts and changes,
1 The Oﬃcial Bluetooth Technology Info Site (www.bluetooth.com/bluetooth).

268
A.C. Santos, L. Tarrataca, and J.M.P. Cardoso
and has to be kept updated through active computation [13]. These updates are
performed based on the recognition of special features in landmarks, sensor data
and probabilistic models.
Localization uncertainty rises from the sensing of the robot, because of the
indirect estimation process. The measurements besides being noisy, because of
real-world sensor characteristics, may not be available at all times. Based on
the uncertainty characteristics of the localization problem, similarly to other
important mobile robotics problems, it has been tackled by probabilistic methods
[20]. Amongst the most commonly used are Markov Localization [4] and Particle
Filters [6].
2.2
Mapping - “Where Am I Going?”
The mapping problem exists when the robot does not have a map of its en-
vironment and incrementally builds one as it navigates. While in movement,
the robot senses the environment, identifying key features which will allow it
to register information of its surroundings. The main concern for the mapping
problem is how the mobile robot does perceive the environment. There are many
sensors used for mapping, being the most common sonar, digital cameras and
range lasers. The complexity of the mapping problem is the result of a diﬀerent
number of factors [20], the most important of which are: size of the environment,
noise in perception, and actuation and perceptual ambiguity.
Approaches for mapping have been accomplished considering the extraction of
natural features from the environment (see [12]) and through the identiﬁcation
of special artiﬁcial landmarks (see, e.g., [16] and [1]).
2.3
Path Planning - “How Do I Get There?”
Path Planning is the process of looking ahead at the outcomes of possible ac-
tions, and searching for the best sequence that will drive the robot to a desired
goal/location [13]. It involves ﬁnding a path from the robot’s current location to
the destination. The cost of planning is proportional to the size and complexity
of the environment. The bigger the distance and the number of obstacles, the
higher the cost of the overall planning. Path Planning techniques for navigation
can be divided in local path planning and global path planning, which diﬀer
on the quantity of information of the environment they need to possess. Local
techniques only need information of the environment that is near to the robot,
while global techniques use full information of the environment.
There are many diﬀerent approaches to path planning. A relevant Path Plan-
ning technique is the Artiﬁcial Potential Field [8].
3
Prototype and Navigation Algorithms Considered
The block diagram of the system is shown in Figure 1. A middleware component
is responsible for the interaction between the smartphones and the mobile robot.

An Analysis of Navigation Algorithms for Smartphones Using J2ME
269
The navigation algorithms are executed in the smartphone, and the control in-
structions are passed to the robot via the middleware. Raw data from sensing
by the robot are acquired by the middleware via Bluetooth interface.
3.1
Prototype
The prototype mobile robot consists of a Lego Mindstorms NXT2 kit coupled
with a smartphone (we have used the Nokia N803 and the Nokia N954)). The
smartphone is positioned so its built-in camera faces the front of the robot,
enabling it to act as an intelligent image sensor (Figure 2), which furnishes
sensing meta-data to the main navigation system (a smartphone responsible for
executing the navigation algorithms).
Fig. 2. Prototype mobile robot with a smartphone
Development for the smartphone was done in Java using its Micro Edition
version (J2ME5). The choice of J2ME development was mainly due to Java’s
known portability among the most common mobile phone manufacturers. De-
velopment for the mobile robot was also done using a subset of Java supported
by the JVM present in the custom ﬁrmware for the Lego’s NXT Brick known as
leJOS NXJ [19].
3.2
NXT Middleware
In order to provide seamless integration within the system, we developed a mid-
dleware component which helps J2ME application development for the smart-
phone to communicate with the NXT mobile robot. The core functionality of
the middleware consists in providing abstractions for Bluetooth communication
and also access to the mobile robot’s sensors and actuators. The middleware
component was developed in the Java programming language and was built on
top of the leJOS NXJ ﬁrmware [19].
2 The Lego Group (http://mindstorms.lego.com/)
3 Nokia N Series N80 smartphone (http://www.nseries.com/products/n80/)
4 Nokia N Series N95 smartphone (http://www.nseries.com/products/n95/
5 Sun Microsystems - Java ME Technology (http://java.sun.com/javame/technology/)

270
A.C. Santos, L. Tarrataca, and J.M.P. Cardoso
3.3
Visual Landmark Recognition
For real-time mapping we rely on feature extraction by the visual sensor. With
the objective of keeping the detection and recognition of the landmarks as fast
as possible, the approach implemented in this work uses solid-color cylindrical
artiﬁcial landmarks. The approach developed is similar to the method by [2]. In
our approach, the visual system detects one landmark, recognizes its color, and
calculates its distance and orientation to the visual sensor.
Color Segmentation represents the ﬁrst step for detecting the landmark on
a captured image by the smartphone. Previously, the landmark color features
were gathered and analyzed, providing the means to empirically produce a set
of rules in the RGB color space for detection of the colors used in the artiﬁcial
landmarks. These rules detect the presence of a landmark in an image thus
providing the corresponding landmark classiﬁcation based on its color. E.g., for
a green landmark, we used the rules presented in (1). R, G and B correspond
to the red, green and blue color components of the RGB color space. The value
X is an adjustment value, that is used to augment the green color component
relatively to the red and blue.
(G ≥130) and(G > R + X) and (G > B + X)
(1)
The color segmentation process transforms the captured image into a binary,
black and white image as can be seen in Figure 3. White color pixels indicate
the presence of the green range color and black pixels the absence of it.
Fig. 3. Image captured with a green landmark (left image); Binary image after the
application of the color segmentation (middle image) and landmark boundary detection
after the application of the image noise reduction ﬁlter (right image)
Image Noise Reduction is necessary for the elimination of salt and pepper
noise, caused by the color segmentation process. The noise may compromise
better results in future steps and therefore needs to be reduced or removed. The
ﬁlter implemented uses a 3×3 scanning window, that analyzes all the landmark
pixels present in the image. The window checks if the pixels surrounding the
current scanned pixel mostly belong to the landmark or the background. If they
are mostly background (≥50%) then the pixel is most likely noise and is erased
(see Figure 3).

An Analysis of Navigation Algorithms for Smartphones Using J2ME
271
Landmark Boundary Detection is needed for more accurate calculations of
distance and orientation. A minimum rectangular boundary contains the shape
detected and is used to help cope with some small variations in the shape’s
perspective, that can vary according to the view from which the image was
acquired.
Distance (d) and Orientation (θ) from the visual sensor to the landmark is
calculated based on one of the methods in [22]. By knowing the width, height
and center point of the landmark and having already performed measurements
for camera calibration, the distance and orientation information can be inferred
from the landmark’s size and position in the image (see (2) and (3)).
dy = ky × 1
y′
dx = kx × 1
x′
d = dx + dy
2
(2)
θ = m × xLandmarkCenter + l
(3)
3.4
Particle Filter
For localization, we implemented the Particle Filter method, based on the ap-
proach presented in [17]. The environment is represented as an occupancy grid
map, where each grid cell matches an area of the real environment at a spe-
ciﬁc ratio. Each grid cell can be assigned with estimation probabilities of the
mobile robot’s position or with a reference to the presence of an obstacle. The
Particle Filter method can be divided into three main stages: Prediction which
involves a motion and noise model for movement; Update, which concentrates
on sensing the environment and altering the particles relevance weight value;
and a Resample stage where the particle population is managed.
Motion Model is the robot’s path planner, which is responsible for providing
at each step a path for the mobile robot’s movement. In this work two motion
models were developed: an explorer type motion model which visits all free
locations in the map and a point to point motion model which is a predeﬁned
obstacle-free path from one location in the environment to another.
Noise Model is responsible for the odometry error that is added to the robot’s
motion, based on the noise model provided in [17]. The odometry error consid-
ered was divided into rotation error and translation error. Both were experi-
mentally established from the real odometry errors from the robotics kit used.
Translation and rotation with noise are accomplished using a pseudo-random
value, drawn as a sample from the Gaussian distribution.
Measurement Model provides, on each observation of the environment, nec-
essary information for the weighting function which will update the particle’s

272
A.C. Santos, L. Tarrataca, and J.M.P. Cardoso
weights. In this implementation, the particle’s weight is considered to be a nu-
meric value w greater than 0. An observation consists on sensing the environ-
ment. Sensing is done by using a simulated observation from the information
present in the internal map or by using the visual landmark recognition method
presented earlier.
Resampling occurs when a considerable amount of particles within the par-
ticle population have weight values below a threshold and therefore have low
contribution to the overall estimate of the robot’s position. The resampling pro-
cess recognizes particles with small weight values (< threshold) and replaces
them with a random particle, whose weight value is higher than the resampling
threshold (≥threshold). This random replacement minimizes the problem of
diversity loss. When all particles have weights bellow the threshold then a new
random set of particles is generated.
Robot Position Estimate at a determined time t, is given by the best par-
ticle which has the maximum weight value within the current particle set.
3.5
Potential Fields
For path planning we use the Potential Fields approach [8] which is used for
path planning and collision avoidance due to its mathematical simplicity and
elegance, providing acceptable and quick results [10] in real-time navigation.
This method is based upon the concept of attractive and repulsive forces, where
the goal is seen as a global minimum potential value (attractive force), and all
obstacles as high valued potential ﬁelds (repulsive force). The movement of the
robot is then deﬁned by the potential values present in its path, moving ideally
from high to low potentials.
Our approach uses as basis the potential ﬁeld functions presented by [5]. The
most diﬃcult problem for the Potential Field method, known as the local minima
has been addressed using escape techniques (e.g., Random Escape, Perpendicular
Vector Escape [21], Virtual Obstacle Concept Escape [15]). In order to provide
a smoother robot movement, a lookahead function was implemented which pre-
vents the mobile robot from falling into local minima locations by detecting them
in advance.
4
Experimental Results
In this section, we present and discuss experimental results for the navigation
problems: Mapping, Localization, and Path Planning. Here we evaluate the per-
formance of the algorithms developed, by comparing executions between the
used smartphones and a desktop PC (AMD Athlon 64 X2 Dual Core Processor
at 2.20 GHz with 1GB of RAM and running Windows XP SP3), and analyzing
the feasibility of smartphones for real-time autonomous navigation.

An Analysis of Navigation Algorithms for Smartphones Using J2ME
273
Fig. 4. Field environment for testing the navigation algorithms
A ﬁrst study of performance was done with proﬁling results gathered from a
PC MIDP emulator (Sun Java Wireless Toolkit6). Then, we conducted several
experiments on the ﬁeld. Figure 4 shows the experimental environment where
ﬁeld testing took place.
4.1
Mapping
Experiments with mapping test the application of the Visual Landmark Recog-
nition method while trying to map the environment present in Figure 4. Tests
executed indicated good identiﬁcation of the landmarks colors, being illumina-
tion changes the main source of the incorrect identiﬁcations.
Using a single captured image and considering a good landmark detection
and color segmentation process, the distance calculation revealed quite accurate
presenting an average relative error of 5.715%. Considering the angle orientation
measurement, it revealed reasonably accurate with an average relative error of
10.06%.
Fig. 5. Contribution to the overall execution time of each step associated to the Visual
Landmark Recognition algorithm
6 Sun Java Wireless Toolkit (http://java.sun.com/products/sjwtoolkit/)

274
A.C. Santos, L. Tarrataca, and J.M.P. Cardoso
Table 1. Execution time measurements for the Visual Landmark Recognition method
PC
Nokia N80 Nokia N95
Execution time (ms) 453.00
3079.40
5824.30
Fig. 6. Mapping results with estimated landmark positions
Figure 5 presents proﬁling results for capturing an image and applying the
landmark recognition algorithms. Table 1 compares the execution time obtained
when running the algorithms on the PC, on a Nokia N80, and on a Nokia N95.
Obviously, the PC is the fastest to execute the application. Comparing the two
smartphones, execution time is slower in the Nokia N95 compared to the N80.
The N95 has a more complex built-in camera with higher resolution, making it
slower when capturing an image with J2ME.
When testing on-the-ﬁeld, the mapping approach revealed less accurate than
expected. The robot’s movement and variable lighting conditions prevent the
method from achieving its best results. Although this solution cannot be consid-
ered a very reliable method for accurate mapping purposes in real-time mobile
robot navigation, it presents typical mapping tasks and it is used here as a bench-
mark for studying the performance obtained by the two smartphones used.
Figure 6 shows the achieved mapping accuracy using Visual Landmark Recog-
nition on the environment presented in Figure 4. The grid presents the obstacles
as black colored cells, obstacle estimates calculated in gray colored cells marked
with an “X” character, and the path taken by the mobile robot is presented in
lighter gray and marked with numbers.
4.2
Localization
Experiments for Localization were conducted considering only a global localiza-
tion approach based on the Particle Filter.

An Analysis of Navigation Algorithms for Smartphones Using J2ME
275
Fig. 7. Occupancy grid map for Particle Filter
For proﬁling the Particle Filter implementation, we considered one execution
of the method with a total number of 1,000 particles and using the environment
in Figure 7. We consider that the robot position estimation is only performed
at the end of the mobile robot’s movement. Figure 8 presents the percentages of
execution time of the main phases of the Particle Filter method. Table 2 presents
the execution time comparison between running the implemented localization
application on a PC, on a Nokia N80, and on a Nokia N95 smartphone.
According to the experiments, the phase which was responsible for the highest
percentage of execution time was the Prediction Phase with 48%. The Update
phase followed with 41%. Finally, and considering the number of particles used
and their distribution within the environment, the Resample Phase took 9% of
the total execution time. The last 2% of execution time is spent by auxiliary
tasks and by the attainment of the pose estimate.
Our next experience uses the Particle Filter method to localize the mobile
robot in the environment presented in Figure 4. The Localization approach is im-
plemented as a distributed system, were the Particle Filter approach is executed
on a Nokia’s N95 smartphone, considering 1,000 particles; and the measure-
ment model as a visual sensor performed with the Visual Landmark Recognition
method running on the Nokia N80 model.
Fig. 8. Contribution to the overall execution time of each phase of the Particle Filter

276
A.C. Santos, L. Tarrataca, and J.M.P. Cardoso
Table 2. Execution time measurements for the Particle Filter method
PC Nokia N80 Nokia N95
Time (ms) 78.00
3618.00
1725.00
Results for ﬁve executions of this ﬁeld experiment are presented in Table 3.
Consider that the positions are given as xy position and θ orientation: [x; y; θ].
The robot’s real position at the end of the predeﬁned path is [7; 0; 90◦]. By
analyzing Table 3, we can observe that only one of the experiments estimated
the robot to be at its exact physical location. In the other four experiments,
three were relatively close to the robot’s real position, and the last one was very
far from the robot’s position.
Table 3. Estimations for the same real position ([7; 0; 90◦]) for tests on-the-ﬁeld using
the Particle Filter method
Experiment
#1
#2
#3
#4
#5
Best Particle Position [4; 0; 90◦] [7; 0; 90◦] [9; 1; 90◦] [4; 0; 90◦] [0; 11; 180◦]
The random initialization of the particles makes the method diﬃcult to pre-
dict, by providing very diﬀerent results on diﬀerent runs of the algorithm since
areas in the environment can be highly populated with particles while others
deprived from them (see experiments #1 to #5 in Table 3). One possible solu-
tion to this problem is the increase of the number of particles, but with high
additional computational costs.
The visual sensing in the particle ﬁlter execution is time demanding and
cannot, without further optimizations, be used to navigate mobile robots at
high speed. Nevertheless, considering a slower motion, this solution was able to
provide a mechanism for mobile robot localization.
4.3
Path Planning
The next experiments analyze the Potential Fields. Figure 9 illustrates the main
stages of the algorithm and their contribution to the overall execution time. For
this particular implementation, we used a lookahead value of 5 for local minima
detection. As can be seen, this preemptive detection is responsible for about 80%
of the overall execution time, while the potential calculations for the eﬀective
next movement occupies around 20% of the total time.
Table 4 shows the execution time for the path presented in Figure 10. The
PC presents the lowest execution time, and the Nokia N95 has faster execution
than the Nokia N80. These results were expected. Due to the mathematical
requirements of the algorithm, it is able to execute faster in the N95, as it
includes a more powerful main microprocessor.
When performing experiments on-the-ﬁeld, the robot revealed some strange
orientation changes when avoiding obstacles. This fact was never very noticeable

An Analysis of Navigation Algorithms for Smartphones Using J2ME
277
Fig. 9. Contribution to the overall execution time of each stage of the Potential Fields
Table 4. Time and Memory measurements for the Potential Fields algorithm
PC
Nokia N80 Nokia N95
Average Step Time (ms)
11.00
377.00
278.75
Total Time (ms) 7664.60 253442.75 187882.75
in the simulations performed. We concluded that, even in the absence of local
minima locations, some raw directional vectors cannot be directly applied for the
robot’s movement. Some of these directional vectors force the robot to perform
expensive rotations that need to be smoothen beforehand.
Globally, the experiments revealed a considerable robustness of the current
JVM available in the mobile devices used and the potential for those devices
to execute complex navigation algorithms. However, the current J2ME platform
makes it diﬃcult to provide more eﬃcient implementations of the algorithms
used, which can be seen by the execution times presented. Nevertheless, their
execution is possible and there is still room for further improvements.
Fig. 10. Complex environment used for Potential Fields proﬁling

278
A.C. Santos, L. Tarrataca, and J.M.P. Cardoso
5
Conclusions
The work presented in this paper focused on a study of the viability to ac-
complish autonomous navigation with smartphones and J2ME. Tests with well
known navigation algorithms (e.g., potential ﬁelds and particle ﬁlter) have been
performed. To achieve realistic experiments, we use a mobile robot controlled by
a smartphone, able to execute complex and computationally intensive navigation
algorithms and to communicate with the robot via Bluetooth.
The mobile implementation of the algorithms revealed high consistency and
robustness. The experiments on-the-ﬁeld show that it is feasible to execute
real-time navigation algorithms without too much tight constraints in high-end
smartphones. Note, however, that the current processing capabilities of smart-
phones and J2ME can fully fulﬁll real-time requirements in environments where
the smartphone might be used to assist the user (e.g., navigating in a city, shop-
ping center).
From the experiments performed for visual landmark recognition, it is clear
that future enhancements of J2ME should include the capability to acquire video
streaming and to access individual frames. The current implementation needs to
perform single image capture, which is too slow for real-time video processing.
Acknowledgments
We would like to acknowledge the donations of smartphones by Nokia, Finland.
References
1. Baczyk, R., Kasinski, A., Skrzypczynski, P.: Vision-based mobile robot localization
with simple artiﬁcial landmarks. In: Prepr. 7th IFAC Symp. on Robot Control, pp.
217–222 (2003)
2. Bruce, J., Balch, T., Veloso, M.: Fast and inexpensive color image segmentation for
interactive robots. In: Proceedings of the 2000 IEEE/RSJ International Conference
on Intelligent Robots and Systems (IROS 2000), vol. 3, pp. 2061–2066 (2000)
3. Dorigo, M.: Optimization, Learning and Natural Algorithms. PhD thesis, Politec-
nico di Milano, Italy (1992)
4. Fox, D.: Markov Localization: A Probabilistic Framework for Mobile Robot Local-
ization and Navigation. PhD thesis, Institute of Computer Science III, University
of Bonn, Germany (December 1998)
5. Goodrich, M.A.: Potential ﬁelds tutorial. Class Notes (2002)
6. Gordon, N., Salmond, D., Smith, A.: Novel approach to nonlinear/non-gaussian
bayesian state estimation. IEEE Proceedings for Radar and Signal Process-
ing 140(2), 107–113 (1993)
7. Kalman, R.E.: A new approach to linear ﬁltering and prediction problems. Trans-
actions of the ASME–Journal of Basic Engineering 82(Series D), 35–45 (1960)
8. Khatib, O.: Real-time obstacle avoidance for manipulators and mobile robots. The
International Journal of Robotics Research 5(1), 90–98 (1986)

An Analysis of Navigation Algorithms for Smartphones Using J2ME
279
9. Kirkpatrick, S., Gelatt, C.D., Vecchi, M.P.: Optimization by simulated annealing.
The American Association for the Advancement of Science 220(4598), 671–680
(1983)
10. Lee, L.-F.: Decentralized motion planning within an artiﬁcial potential framework
(apf) for cooperative payload transport by multi-robot collectives. Master’s thesis,
Department of Mechanical and Aerospace Engineering (December 2004)
11. Leonard, J.J., Durrant-Whyte, H.F.: Mobile robot localization by tracking geo-
metric beacons. IEEE Transactions on Robotics and Automation 7(3), 376–382
(1991)
12. Lowe, D.G.: Object recognition from local scale-invariant features. In: The Pro-
ceedings of the 7th IEEE International Conference on Computer Vision, vol. 2, pp.
1150–1157 (1999)
13. Matari´c, M.J.: The Robotics Primer, 1st edn. MIT Press, Cambridge (2007)
14. Negenborn, R.: Robot localization and kalman ﬁlters. Master’s thesis, Utrecht Uni-
versity, Netherlands (September 2003)
15. Park, M.G., Lee, M.C.: Artiﬁcial potential ﬁeld based path planning for mobile
robots using a virtual obstacle concept. In: Proceedings of the 2003 IEEE/ASME
International Conference on Advanced Intelligent Mechatronics (AIM 2003), vol. 2,
pp. 735–740 (July 2003)
16. Prasser, D., Wyeth, G.: Probabilistic visual recognition of artiﬁcial landmarks for
simultaneous localization and mapping. In: Proceedings of the 2003 IEEE Interna-
tional Conference on Robotics and Automation, vol. 1, pp. 1291–1296 (September
2003)
17. Rekleitis, I.: Cooperative Localization and Multi-Robot Exploration. PhD thesis,
School of Computer Science, McGill University, Montr´eal (January 2003)
18. Smith, R., Self, M., Cheeseman, P.: Estimating uncertain spatial relationships in
robotics. In: Autonomous robot vehicles, pp. 167–193. Springer, New York (1990)
19. Sol´orzano, J., Bagnall, B., Stuber, J., Andrews, P.: lejos: Java for lego mindstorms,
http://lejos.sourceforge.net/ (last visited in June 2008)
20. Thrun, S., Burgard, W., Fox, D.: Probabilistic Robotics. MIT Press, Cambridge
(2005)
21. Veelaert, P., Bogaerts, W.: Ultrasonic potential ﬁeld sensor for obstacle avoidance.
IEEE Transactions on Robotics and Automation 15(4), 774–779 (1999)
22. Yoon, K.-J., Jang, G.-J., Kim, S.-H., Kweon, I.S.: Fast landmark tracking and
localization algorithm for the mobile robot self-localization. In: IFAC Workshop
on Mobile Robot Technology, pp. 190–195 (2001)

C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 280–294, 2009. 
© Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009 
An IMS-Based Middleware Solution for  
Energy-Efficient and Cost-Effective  
Mobile Multimedia Services 
Paolo Bellavista, Antonio Corradi, and Luca Foschini 
Dipartimento di Elettronica Informatica e Sistemistica - Università di Bologna 
Viale Risorgimento, 2 – 40136 Bologna – Italy  
Ph.: +39-051-2093001; Fax: +39-051-2093073 
{paolo.bellavista,antonio.corradi,luca.foschini}@unibo.it 
Abstract. Mobile multimedia services have recently become of extreme 
industrial relevance due to the advances in both wireless client devices and 
multimedia communications. That has motivated important standardization 
efforts, such as the IP Multimedia Subsystem (IMS) to support session control, 
mobility, and interoperability in all-IP next generation networks. Notwithstanding 
the central role of IMS in novel mobile multimedia, the potential of IMS-based 
service composition for the development of new classes of ready-to-use, energy-
efficient, and cost-effective services is still widely unexplored. The paper 
proposes an original solution for the dynamic and standard-compliant redirection 
of incoming voice calls towards WiFi-equipped smart phones. The primary design 
guideline is to reduce energy consumption and service costs for the final user by 
automatically switching from the 3G to the WiFi infrastructure whenever 
possible. The proposal is fully compliant with the IMS standard and exploits the 
recently released IMS presence service to update device location and current 
communication opportunities. The reported experimental results point out that our 
solution, in a simple way and with full compliance with state-of-the-art 
industrially-accepted standards, can significantly increase battery lifetime without 
negative effects on call initiation delay. 
Keywords: Mobile Multimedia, Energy Efficiency, Middleware, Standards, IP 
Multimedia Subsystem (IMS). 
1   Introduction 
Nowadays it starts to be more and more common that a number of mobile users 
require seamless access to multimedia services, such as audio/video voice calls, while 
they move across the available and possibly heterogeneous wireless infrastructures, 
spanning from IEEE 802.11 (WiFi) and Bluetooth (BT) to cellular 3G. Despite the 
great potential stemming from the possibility to integrate heterogeneous wireless 
networks, one of the most challenging issues in supporting mobile multimedia 
applications is still the reduction of energy consumption at battery-powered clients. 
Energy is a precious resource for portable devices and wireless interface cards are 

 
IMS-Based Energy-Efficient Mobile Multimedia 
281 
widely recognized to be one of the most relevant components that contribute to drain 
battery power, with a relatively greater role as device size decreases [1]. 
Of course, power consumption also depends on the wireless technology of 
exploited interface cards and unfortunately widespread wireless technologies, such as 
WiFi, despite their low per-bit monetary transmission cost, have a high per-bit energy 
transmission cost [2], [3]. To overcome that problem, some seminal research activities 
have started to propose the usage of low-power-consumption wireless technologies, 
even if with high per-bit transmission cost, e.g., cellular 3G, to opportunistically 
control and switch on other wireless interfaces with reduced economic costs only 
when needed, e.g., triggered by incoming calls [4], [5]. However, notwithstanding 
their potential, none of the above power management solutions have been deployed 
nor penetrated into the mobile multimedia market primarily because of the lack of 
widely accepted session control standards. 
A large group of standardization bodies has recently defined the IP Multimedia 
Subsystem (IMS) [6]. IMS defines an overlay architecture for session control in all-IP 
next generation networks to obtain openness and interoperability by adopting an 
application-layer approach, mainly via the Session Initiation Protocol (SIP). Some 
research activities have already exploited IMS to dynamically reconfigure ongoing 
working sessions when wireless access technology change, i.e., handoff management, 
but to the best of our knowledge none of them considered the possibility to use IMS 
to deliver highly innovative, interoperable, and ready-to-market power management 
solutions. 
The paper tackles the above issues by proposing a novel solution with three 
original core properties. First, it exploits terminal-based decentralized monitoring to 
update client wireless communication context (user/device profile, device location, 
available wireless access infrastructures, …). Second, it uses such awareness to 
jointly save energy and reduce economic cost of transmission by automatically 
switching on high-consumption and low-cost wireless interfaces only for the duration 
of service sessions. Third, it is fully compliant with the IMS standard: the diffusion of 
context updates exploits the recently standardized IMS-based Presence Service (PS) 
and our power management facility has been implemented as a novel IMS application 
server, part of our wider IMS-compliant Handoff Management Application Server 
(IHMAS) infrastructure. In particular, our power management facility, originally 
presented here, integrates with existing open-source IMS implementation platforms 
and tools such as the Open IMS Core, the Open SIPS, and the UCT Client. The 
facility is publicly available for wireless practitioners and the IMS community as an 
external IMS-compliant service1 [7], [8], [9]. 
2   Background and Related Work 
The provisioning of interoperable multimedia session control over heterogeneous 
wireless communication infrastructures is still a challenging issue. To tackle the 
problem, a large group of standardization entities that range from the 3rd Generation 
                                                           
1 Additional information, experimental results, and the prototype code of the IHMAS infrastructure are 
available at: http://lia.deis.unibo.it/Research/IHMAS/ 

282 
P. Bellavista, A. Corradi, and L. Foschini 
Partnership Project (3GPP) and 3GPP2 to Internet Engineering Task Force (IETF) 
and Open Mobile Alliance (OMA) has recently defined IMS [6]. This section briefly 
introduces the IMS architecture and the IMS-based PS, which are the crucial technical 
elements to fully understand our proposal; then, the section overviews the existing 
related proposals in the literature. 
2.1   Background about IMS 
IMS Standard. IMS mainly focuses on session control: it offers several facilities to 
allow the creation, modification, and termination of service sessions for an open set of 
potentially highly integrated and all-IP multimedia services (instant messaging, Video 
on Demand – VoD –, Voice over IP – VoIP –, …) independently of underlying data-
link layer technologies and transport protocols. 
The dynamic renegotiation and rebinding of multimedia sessions is one of the core 
session control activities in IMS, in order to react to the substantial and abrupt 
changes of the characteristics of wireless provisioning environments that may occur at 
runtime, e.g., when a Mobile Node (MN) disconnects from one access point and re-
connects to a new one. To that purpose, IMS proposes a framework and exploits the 
Session Description Protocol (SDP) for endpoint localization/rebinding and for 
decentralized proxy-based session management.  
Current IMS specifications do not include power management; however, the IMS 
standard facilitates the introduction of new services/extensions [6]. In the following, 
we rapidly introduce the three main components of the IMS infrastructure that 
directly participate in our power management solution, which is the central scope of 
the paper. 
The first component is the IMS Client, which controls session setup and media 
transport by implementing all SIP extensions specified by IETF and 3GPP IMS-
related standards. Any session is setup between two IMS clients. Here, without losing 
any generality and for the sake of presentation clarity, we always consider a fixed 
Correspondent Node (CN) as the originating SIP endpoint and MN as the terminating 
one. The second IMS component is the Application Server (AS), which allows the 
introduction of new IMS services and extensions. AS has full control over traversing 
SIP dialogs. The third one, the Serving-Call Session Control Function (S-CSCF), is 
the most important session control entity. S-CSCF authenticates and registers IMS 
clients to the IMS infrastructure; then, depending on filters/triggers specified by client 
profiles, S-CSCF may either route incoming SIP messages directly to their receiver or 
forward them to AS [6]. Let us stress that given its ability to change SIP message 
headers, S-CSCF can extend MN-to-CN session signaling paths through the 
interposition of convenient ASs. Fig. 1 shows the deployment of all main components 
presented in this and in the following subsections. 
Other primary IMS components, such as Proxy-/Interrogating-CSCF, Home 
Subscriber Server (HSS), and the standard Internet Dynamic Host Configuration 
Protocol (DHCP) are not overviewed because out of the scope of this paper. For a 
comprehensive introduction to the whole IMS architecture, please refer to [6]. 
 

 
IMS-Based Energy-Efficient Mobile Multimedia 
283 
P-CSCFCN
P-CSCFMN
Internet
I-CSCFCN
S-CSCFCN
PSCN
HSSCN
I-CSCFMN
S-CSCFMN
IMS MN Domain
HSSMN
WiFi
PSMN
IMS CN Domain 
IMS ClientMN P
ASMNW
IMS ClientCN
3G
P-CSCFCN
P-CSCFMN
Internet
I-CSCFCN
S-CSCFCN
PSCN
HSSCN
I-CSCFMN
S-CSCFMN
IMS MN Domain
HSSMN
WiFi
PSMN
IMS CN Domain 
IMS ClientMN P
IMS ClientMN P
ASMNW
IMS ClientCN
3G
 
Fig. 1. IMS distributed architecture at Correspondent Node (CN) and Mobile Node (MN) 
domains. The core IMS components are: Home Subscriber Server (HSS); Proxy-Call Session 
Control Function (P-CSCF); Session-Call Session Control Function (S-CSCF); Interrogating-
Call Session Control Function (I-CSCF); and Application Server (AS). The figure shows also 
IMS-based presence service components: Presence Server (PS); Watcher (we use the red label 
W to tag an entity acting as watcher); and Presentity (we use the red label P to tag an entity 
acting as presentity). 
IMS-based Presence Service. Presence is a well-known concept in the traditional 
Internet and widely used in applications such as Instant Messaging or multiparty 
games [10]: presence permits users and hw/sw components, called presentities, to 
convey their ability and willingness to communicate with watchers. In order to 
receive PS publish/update messages from presentities, i.e., presence notifications, 
watchers subscribe to presence servers that act as intermediaries in any PS-related 
communication between presentities and watchers. 
The concept of presence has been recently widened to include any context 
information useful to adapt service provisioning to the current state of the execution 
environment in a personalized way. That has made PS play a crucial role in several 
mobile services nowadays. For instance, instant messaging exploits the PS context 
information about one user’s online/offline/busy status to check whether she is 
reachable, while voice/video conferencing uses PS context to adapt sessions 
depending on profiles of currently exploited devices and wireless interfaces. By 
focusing on power management, PS may be used to periodically update context 
information about MNs, including their battery levels, wireless interfaces, and 
available wireless access infrastructures at their current locations.  
Recent IMS standardization efforts recognize PS as a core support facility for any 
novel mobility-enabled service [11], [12], [13]. The core IMS-based PS component is 
the presence server, which accepts and stores PS subscriptions from watchers, and 
notifies publish messages from presentities to registered watchers. The other two 
primary PS entities are presentities and watchers. More precisely, the presence user 
agent is the entity that provides PS information about a presentity (for the sake of 
presentation simplicity, in the following we use the single presentity term to refer 
both). In general, IMS clients and ASs may act as presentities or watchers depending 
on specific service requirements, as shown also in Fig. 1.  
In addition, PS defines other components, such as the PS network agent to 
collect/combine different information about a presentity, and specifies protocols, such 
as the XML Configuration Access Protocol (XCAP), to manipulate PS-related 
management data (subscription authorization policies, resource lists, …). For 
additional details about IMS and its PS, please refer to [11], [12], [13]. 

284 
P. Bellavista, A. Corradi, and L. Foschini 
2.2   Related Work 
As widely agreed [3], the best way to achieve energy saving is to take advantage from 
the inactivity/idle time intervals of wireless network interfaces. When inactive, the 
interface can be put in a low power-consuming state, either the sleep mode or the off 
state. By following this general design principle, various energy-saving solutions have 
been proposed for devices equipped with single/multiple wireless interface/s. 
For single-interface devices, the very crucial point for energy saving is traffic 
shaping. To reduce the active (on state) time intervals of the MN wireless interface, 
those solutions aim to schedule transmissions from/to MNs in data bursts of short 
duration, periodically sent at the highest rate allowed by the wireless link. For 
instance, by focusing on WiFi which is a notable example of energy-consumptive 
wireless technology, several traffic shaping solutions have been proposed both at the 
lower datalink OSI protocol stack layer, e.g., IEEE 802.11 Power-Saving Mode and 
its evolutions, and at the application layer, by tackling different services, spanning 
from Web browsing to multimedia mobile applications [2], [3], [14]. 
Energy-saving solutions for multi-interface devices, instead, tend to use an out-of-
band low-energy communication channel to switch on more energy-consumptive 
wireless interfaces only when needed for transmission. [4] and [5] exploit an always-
on low-consumption interface to send context data about MN wireless access locality 
back to the network in order to enable network-controlled handoff decisions aimed to 
save energy at MN. More recently, similar energy-saving techniques have been 
applied also to Wireless Sensor Networks (WSNs); ultra-low power receivers for out-
of-band wake-up signaling are currently under study and development [15]. 
Other work related to our proposal includes ongoing research efforts on IMS 
exploitation and IMS-based handoff. Application-layer IMS-based handoff 
management has its roots on SIP-based mobility management first proposed by 
Schulzrinne [16]. Thereafter, a number of SIP-based research efforts tackled session 
adaptation at different protocol stack layers [17], [18]. More recently, some support 
solutions are starting to face specific IMS-related handoff issues. For instance, 
Intelligent Network-Seamless Mobility Access (IN-SMA) proposes a new AS, called 
Mobility Application Server, for IMS-based 3G-to-WiFi handoff management [19]. 
By focusing on industrial standardization efforts, 3GPP Voice Call Continuity (VCC) 
is a recent IMS-based specification that tackles audio streaming continuity during 
inter-technology handoff [20]. However, differently from IHMAS, those and other 
similar IMS-based handoff solutions focus mainly on flow transfer and, to the best of 
our knowledge, none of them specifically address power management issues.  
3   Power Management in Our IHMAS Infrastructure 
In general, we claim the need for application-level supports to ease the design and 
implementation of mobile multimedia services [21]. By focusing on IMS-based power 
management, our IMS-compliant Handoff Management Application Server (IHMAS) 
proposal significantly differs from state-of-the-art work by combining several original 
technical aspects: 

 
IMS-Based Energy-Efficient Mobile Multimedia 
285 
• 
IHMAS is the first proposal in the field that explores the use of IMS to realize 
advanced energy-efficient and cost-effective services. Power management ASs, 
interposed in the CN-to-MN session control path, control MNs by switching on 
the wireless interfaces with high consumption and low transmission cost, e.g., 
WiFi, only for the needed time slots, e.g., only for the duration of calls. 
• 
IHMAS is context-aware. It monitors context changes at MNs and exploits 
context change notifications to update power management ASs with current MN 
conditions (user profile, wireless communications availability, battery level, …), 
thus enabling prompt management operations. To further reduce energy 
consumption, context updates are sent over communications channels with low 
consumption and high transmission cost, e.g., cellular 3G. 
• 
IHMAS is a real and ready-to-deploy IMS-based solution. It exploits IMS-based 
PS for context update notification: ASs act as watchers and IMS clients as 
presentities. The implemented power management components can be easily 
deployed and installed over existing IMS networks, without requiring any 
modification to existing standards and off-the-shelf equipment. 
To better understand the IHMAS original proposal for power management, let us 
overview first the main IHMAS components. The IHMAS architecture consists of 
two main components that interwork to handle the two core management functions: 
context monitoring and session control for power management. The former is realized 
by the Context Monitor (CM) that extends the IMS Client with lightweight and 
completely decentralized context monitoring via only local access to client wireless 
devices. The latter involves the AS for Power Management (ASPM), deployed at the 
MN home network, that participates to session initiation signaling to implement our 
IMS energy-saving optimization. In addition, IHMAS exploits the standard IMS-
based PS to facilitate the interaction between CM and ASPM. ASPM registers to PS 
to receive context updates published by CM. Fig. 2 depicts the main IHMAS 
components and their interactions. 
By delving into finer details, CM periodically monitors main context parameters, 
especially wireless infrastructure availability and battery level at MN. CM execution 
imposes very limited overhead since all monitoring data are local and data gathering 
periods are dynamically lengthened/shortened as monitored variations decrease/ 
increase. If monitored context values overcome monitoring threshold values, CM 
notifies context changes to ASPM by using low-consumption and always-on wireless 
interfaces, i.e., typically 3G cellular (step 1-3 in Fig. 2). ASPM maintains the current 
state of its corresponding IMS clients (including any possible information about 
connectivity status and IP configuration) and consumes all call initiation SIP 
messages that are automatically re-routed by MN S-CSCF (not shown here, see also 
Fig. 1). When receiving an INVITE message, ASPM promptly activates our novel 
power management SIP-based procedure to redirect incoming call session signaling 
procedure to the wireless interfaces with high consumption and low transmission cost, 
if available (steps 4-6). After that, multimedia data transmissions are established over 
switched-on wireless interfaces (step 7). When the call terminates the high-
consumption interface is switched off and MN re-registers itself to IMS over its 
always-on wireless card. 
 

286 
P. Bellavista, A. Corradi, and L. Foschini 
MN
IMS Client
CM
Data Tx/Rx
and Playout
IMS
CN
IMS Client
IMS-compliant
SIP Signalling
Data Tx/Rx
and Playout
SIP messages over  
low-consumption wireless 
interface
MN Visited Wireless Access Domain
CN Domain
Power-Saving 
Session Signaling
1.
2. <<publishes>>
Data 
Transport
MN Home Domain
AS Node
ASPM
PS
IMS-compliant
SIP Signalling
3. 
<<notifies>>
4.
5.
SIP messages over
high-consumption wireless 
interface
6.
7.
DATA
MN
IMS Client
CM
Data Tx/Rx
and Playout
IMS
CN
IMS Client
IMS-compliant
SIP Signalling
Data Tx/Rx
and Playout
SIP messages over  
low-consumption wireless 
interface
MN Visited Wireless Access Domain
CN Domain
Power-Saving 
Session Signaling
1.
2. <<publishes>>
Data 
Transport
MN Home Domain
AS Node
ASPM
PS
IMS-compliant
SIP Signalling
3. 
<<notifies>>
4.
5.
SIP messages over
high-consumption wireless 
interface
6.
7.
DATA
 
 
Fig. 2. The IHMAS architecture 
Let us stress that the IHMAS distributed architecture achieves energy-saving 
improvements with minimum overhead. ASPM is interposed in CN-to-MN session 
signaling path only during the initial session initiation phase; successive interactions 
between CN and MN go on in an end-to-end way, as usual. 
4   IHMAS Power Management Facility: Protocol Design and  
Implementation Insights 
IHMAS can support several types of mobile multimedia services. For our design/ 
implementation work on power management, we decided to focus on VoIP audio 
service for two main reasons: on the one hand, for its strict requirements in terms of 
session initiation time and, on the other hand, because it is one of the most widespread 
IMS services supported by most off-the-shelf IMS clients and devices. Moreover, our 
energy-saving technique has been tailored to WiFi given its wide diffusion and high 
energy consumption values, but remains valid and can be applied to other wireless 
technologies such as Bluetooth. This section presents our novel IMS-based energy-
saving protocol and gives an overview of the most relevant implementation insights 
about ASPM, IMS client, and CM. 
4.1   IHMAS Session Signaling for Power Management 
Our original power management process consists of two main session signaling 
phases. The first one enables context change notifications between MN and ASPM. 
The second one is the core signaling function for power management that is in charge 
of switching on target MN interfaces and of redirecting incoming calls. Fig. 3 depicts 
those two phases. Continuous black lines represent the IMS session signaling 
protocol, dashed black lines are our original message flow extensions, and dotted 
black lines represent local events/calls (e.g., context change event at MN). Grey IMS 
components are out of IHMAS scope, while white ones are the core IHMAS 
components. 

 
IMS-Based Energy-Efficient Mobile Multimedia 
287 
CN
(I-)S-CSCFMN
(13) INVITE
Context Change Notification
PSMN
ASPM
MN
(3) OK
(1) SUBSCRIBE
(2) SUBSCRIBE
(4) OK
(5) PUBLISH
context change
(6) PUBLISH
(7) OK
(8) OK
(9) NOTIFY
(10) NOTIFY context change
(11) OK
(12) OK
Always-on 
interface
Switched-on 
interface
(14) INVITE
(15) new-INVITE
Interface rebind
(17)  (de-)REGISTER
(18) 401 Unauth.
(19)  (de-)REGISTER
(20) OK
(21)   REGISTER
Dynamic switch on and call redirection
(16) 100 Trying
wait MN 
re-REGISTER
(23) 401 Unauth.
(29) 302 MOVED
(30) 302 MOVED
(31) INVITE
(32) INVITE
send MOVED
CM:
context 
changed
(22)   REGISTER
(24) 401 Unauth.
(25)   REGISTER
(27) OK
(26)   REGISTER
(28) OK
CN
(I-)S-CSCFMN
(13) INVITE
(13) INVITE
Context Change Notification
PSMN
ASPM
MN
(3) OK
(3) OK
(1) SUBSCRIBE
(1) SUBSCRIBE
(2) SUBSCRIBE
(2) SUBSCRIBE
(4) OK
(4) OK
(5) PUBLISH
context change
(5) PUBLISH
context change
(6) PUBLISH
(6) PUBLISH
(7) OK
(7) OK
(8) OK
(8) OK
(9) NOTIFY
(9) NOTIFY
(10) NOTIFY context change
(10) NOTIFY context change
(11) OK
(11) OK
(12) OK
(12) OK
Always-on 
interface
Switched-on 
interface
(14) INVITE
(14) INVITE
(15) new-INVITE
(15) new-INVITE
Interface rebind
(17)  (de-)REGISTER
(17)  (de-)REGISTER
(18) 401 Unauth.
(18) 401 Unauth.
(19)  (de-)REGISTER
(19)  (de-)REGISTER
(20) OK
(20) OK
(21)   REGISTER
(21)   REGISTER
Dynamic switch on and call redirection
(16) 100 Trying
wait MN 
re-REGISTER
(23) 401 Unauth.
(23) 401 Unauth.
(29) 302 MOVED
(29) 302 MOVED
(30) 302 MOVED
(30) 302 MOVED
(31) INVITE
(32) INVITE
(32) INVITE
send MOVED
CM:
context 
changed
(22)   REGISTER
(22)   REGISTER
(24) 401 Unauth.
(24) 401 Unauth.
(25)   REGISTER
(25)   REGISTER
(27) OK
(27) OK
(26)   REGISTER
(26)   REGISTER
(28) OK
(28) OK
 
Fig. 3. The IHMAS power management protocol. For sake of clarity we omit CN P-/I-/S-CSCF 
and MN P-CSCF in the figure; other standard signaling messages, not central to the scope of 
this paper, are not reported as well, e.g., the NOTIFY message by PS after subscription. 
At its activation, ASPM subscribes to PSMN to receive notifications for publish 
events emitted by all the MNs that it is serving; served MNs are maintained in a list 
that can be updated through a Web interface (steps 1-4). Afterwards, whenever CM 
perceives a context change at the MN, IMS client sends a PUBLISH message, with 
MAC/IP addresses and Received Signal Strength Indication (RSSI) values for all 
available wireless interfaces and battery level of the MN, which is notified by PSMN to 
ASPM (steps 5-12). Those context data permit ASPM to decide the wireless interface 
to switch on at call arrival time. In addition, S-CSCFMN forwards to ASPM any 
INVITE message over the always-on wireless interface and any registration message 
over switched-on wireless interface, as indicated by IMS triggers specified for MN. 
Power management begins when ASPM receives the INVITE message from CN 
(steps 13-14). Thanks to its awareness of MN wireless communication context, 
ASPM can promptly modify the received INVITE message by adding a line in the 

288 
P. Bellavista, A. Corradi, and L. Foschini 
SDP session description that indicates to MN the target wireless interface to switch on 
(step 15). Then, ASPM sends a TRYING message back to CN to signal that session 
initiation is ongoing (step16) and waits until MN concludes re-registration operations, 
that ASPM identifies from the last OK message forwarded by S-CSCFMN according to 
IMS triggers (steps 17-27). After that, ASPM forwards the OK message to MN and 
sends the MOVED message to CN to redirect the incoming call to the switched-on 
wireless interface (steps 28-30). The MOVED message reception at CN triggers a 
new INVITE message over the switched-on wireless interface and this terminates 
session initiation (steps 31-32). When the call terminates, after BYE message 
exchange, MN re-registers to the always-on wireless interface (not shown in Fig. 3).  
The proposed protocol is fully IMS-compliant. 302 MOVED call re-direction is 
supported by the vast majority of IMS clients and optional SDP fields are ignored by 
default by all IMS entities. In addition, power management only requires very limited 
modification at IMS client, as detailed in the next section. Moreover, let us note that 
in the current version of our prototype, CM obtains wireless interface context data 
(MAC and IP addresses, RSSIs, …) by periodically switching-on all wireless 
interfaces at MN. Even if already optimized by adaptively modifying the monitoring 
period, that operation is still energy-consuming. To further reduce battery 
consumption, CM could obtain and update only the context about the always-on 
wireless interface, i.e., MAC addresses and RSSI values of all cellular base stations in 
MN visibility, without any additional energy cost. ASPM would use notifications to 
keep track of MN location and to proactively obtain, from an external forecast mobile 
connectivity service, detailed information and security credentials to pass to MN in 
the INVITE message. Those new services are currently under analysis and 
development by both academia and industry, and several directory services are 
already available in the Internet to locate WiFi hotspots [22].  
4.2   Implementation Insights 
To grant wide interoperability and to facilitate deployment, we have based the 
development of our power management solution on the currently available standard 
technologies for next generation IMS-based mobile multimedia services. Hence, for 
session signaling we employed the OpenIMSCore, an IMS platform that is fully 
compliant with 3GPP IMS specifications [6], [8]. OpenIMSCore provides all the basic 
components of the IMS infrastructure, e.g., P-/I-/S-CSCFs and HSS, and a framework 
to support and manage new ASs. ASPM has been implemented in Java by exploiting 
the portable Java API for Integrated Networks (JAIN) SIP implementation by the 
National Institute of Standards and Technology [23]. CM has been implemented by 
using standard Linux tools for wireless interface query and designed to integrate with 
the open-source University of Cape Town (UCT) IMS Client that we significantly 
modified to support our power management protocol. Finally, we employed 
OpenSIPS for the PS server [9]. 
Fig. 4-a shows the processInvite Java method implemented by ASPM to 
build the new INVITE message. First, it extracts the SDP part of the message, then 
invokes the addPowerManagementAttribute method that chooses the wireless 
interface to switch on, adds our power management optional field at the end of SDP 
 

 
IMS-Based Energy-Efficient Mobile Multimedia 
289 
description, and finally recomposes and forwards the INVITE message to MN by 
invoking the sendRequest method on the local JAIN SIP stack. The result is the 
insertion of the optional “a=switchoninterface” attribute indicating MAC and 
IP addresses of the wireless interface to switch on as reported in Fig. 4-b; we enclose 
the SDP description within the red box and our new field is highlighted as bold text. 
 
INVITE sip:alice@open-ims.test SIP/2.0 
Record-Route: <sip:mt@scscf.open-ims.test:6060;lr>, 
<sip:mo@scscf.open-ims.test:6060;lr>, 
<sip:mo@pcscf.open-ims.test:4060;lr> 
From: "Bob" <sip:bob@open-ims.test>;tag=1262340263 
To: <sip:alice@open-ims.test> 
Call-ID: 885605810@192.168.3.11 
CSeq: 20 INVITE 
Contact: <sip:bob@192.168.3.11:5062> 
… 
Content-Type: application/sdp 
Content-Length: 414 
 
v=0 
o=- 0 0 IN IP4 192.168.3.11 
s=IMS Call 
c=IN IP4 192.168.3.11 
t=0 0 
m=audio 10281 RTP/AVP 3 0 14 101 
b=AS:64 
a=rtpmap:3 GSM/8000 
a=rtpmap:0 PCMU/8000 
a=rtpmap:14 MPA/90000 
a=rtpmap:101 telephone-event/8000 
a=fmtp:101 0-11 
a=curr:qos local none 
a=curr:qos remote none 
a=des:qos mandatory local sendrecv 
a=des:qos mandatory remote sendrecv 
a=switchoninterface:00:04:23:5E:48:DE 192.168.125.2 
private void processInvite(Request request) { 
SessionDescription sdp =  
  sipUtils.getSessionDescription(request); 
    sd=addPowerManagementAttribute(request, sd); 
    request.removeContent(); 
    try { 
      request.setContent(sd, 
      headerFactory. 
        createContentTypeHeader("application","sdp")); 
    } catch (ParseException e) { e.printStackTrace(); }
    try {  
      sipProvider.sendRequest(request);  
    } catch (SipException e) { e.printStackTrace(); } 
} 
(a)
(b)
INVITE sip:alice@open-ims.test SIP/2.0 
Record-Route: <sip:mt@scscf.open-ims.test:6060;lr>, 
<sip:mo@scscf.open-ims.test:6060;lr>, 
<sip:mo@pcscf.open-ims.test:4060;lr> 
From: "Bob" <sip:bob@open-ims.test>;tag=1262340263 
To: <sip:alice@open-ims.test> 
Call-ID: 885605810@192.168.3.11 
CSeq: 20 INVITE 
Contact: <sip:bob@192.168.3.11:5062> 
… 
Content-Type: application/sdp 
Content-Length: 414 
 
v=0 
o=- 0 0 IN IP4 192.168.3.11 
s=IMS Call 
c=IN IP4 192.168.3.11 
t=0 0 
m=audio 10281 RTP/AVP 3 0 14 101 
b=AS:64 
a=rtpmap:3 GSM/8000 
a=rtpmap:0 PCMU/8000 
a=rtpmap:14 MPA/90000 
a=rtpmap:101 telephone-event/8000 
a=fmtp:101 0-11 
a=curr:qos local none 
a=curr:qos remote none 
a=des:qos mandatory local sendrecv 
a=des:qos mandatory remote sendrecv 
a=switchoninterface:00:04:23:5E:48:DE 192.168.125.2 
private void processInvite(Request request) { 
SessionDescription sdp =  
  sipUtils.getSessionDescription(request); 
    sd=addPowerManagementAttribute(request, sd); 
    request.removeContent(); 
    try { 
      request.setContent(sd, 
      headerFactory. 
        createContentTypeHeader("application","sdp")); 
    } catch (ParseException e) { e.printStackTrace(); }
    try {  
      sipProvider.sendRequest(request);  
    } catch (SipException e) { e.printStackTrace(); } 
} 
(a)
(b)
 
Fig. 4. ASPM implementation insights: new INVITE message construction 
Fig. 5, instead, shows parts of the IMS Client code of the two C functions that 
process the new INVITE message and perform the switching on and MN re-
registration, respectively ims_process_incoming_invite and ims_send_ 
re_register. We pointed out all main management operations in bold. In the first 
function, the main operations are: the extraction of our novel power management 
attribute as a local IP address and the invocation of de-register/default invite 
depending on internal client state, i.e., newInvite flag. In the second function, they 
are: the execution of the scripts to switch on/off the wireless interface; the creation 
and initialization of a new eXosip stack (the C-based SIP stack used by UCT IMS 
Client); and the invocation of a new register phase. Finally, let us note that, depending 
on the internal state of the IMS client, re-registration may either occur on the wireless 
interface just switched on, for incoming calls, or on the always-on wireless interface, 
when the call has been terminated and is_bye flag is set.  
As regards CM implementation, to portably read RSSI values we exploit the 
Wireless Research API (WRAPI) under Windows and the iwconfig tool under 
Linux [24], [25]. In addition, we have implemented several monitoring scripts to 
periodically invoke those system commands and update monitored values and 
monitoring periods. 
 

290 
P. Bellavista, A. Corradi, and L. Foschini 
void ims_process_incoming_invite(eXosip_event *je) 
{ … 
  sdp_message_t * sdp_message; 
  eXosip_lock(); 
  sdp_message=eXosip_get_sdp_info(je->request); 
  eXosip_unlock(); 
  switchOnAddress=extractPowerManAttribute(sdp_message); 
if(newInvite) ims_send_de_register(); 
else { … /* standard session invite management */ } 
} 
 
void ims_send_re_register() 
{ 
int port=5060, pid, status; 
pid=fork(); 
if(pid==0) {  // child 
  if(!is_bye) { execl("../scripts/switchOnInterface.sh", 
                "switchOnInterface.sh", switchOnAddress, (char *)0 ); }   
  else { execl("../scripts/switchOffInterface.sh", 
         "switchOffInterface.sh", switchOnAddress, (char *)0 );  } 
} else {      // parent 
  wait(&status); 
  if(!is_bye) { while( eXosip_listen_addr(IPPROTO_UDP, switchOnAddress,  
                             port, AF_INET, 0) != 0 ) port++; } 
  else { while( eXosip_listen_addr(IPPROTO_UDP, alwaysOnAddress,  
                             port, AF_INET, 0) != 0 ) port++; } 
  ims_send_register(); 
} 
 
Fig. 5. IMS client implementation insights: new INVITE processing and re-registration 
5   Experimental Results 
We have thoroughly tested and evaluated the performance of IHMAS by deploying it 
in the heterogeneous wireless network at our campus. Our testbed consists of several 
Linux laptops equipped with two different wireless interfaces: 3G UMTS adaptors 
and OrinocoGold WiFi cards. The IMS infrastructure and IHMAS components run on 
Linux boxes, each one equipped with two 1.8 GHz CPUs and 2048MB RAM, by 
following the IHMAS deployment scheme of Fig. 1. To collect performance results, 
all machines are synchronized by using the lightweight precision time protocol, i.e., 
IEEE 1588 [26]. In addition, to analytically evaluate the battery saving achieved by 
our solution, we decided to use the Nokia N95 smart phone as our reference device. 
The choice of N95 is motivated by two main reasons. First, N95 was one of the first 
lightweight mobile devices to be equipped with WiFi and thus extensive battery 
consumption evaluations are already available for it. Second, N95 hosts the Java 2 
Micro Edition (J2ME) and, as part of our ongoing work, we are porting the IMS client 
implementation presented in this paper to the J2ME platform – our new J2ME IMS 
client exploits the Ericsson reference implementation of the IMS services API [27]. 
In the following, we report experimental results, averaged over 1,000 session 
initiation cases, while provisioning a VoIP service that offers GSM-encoded audio 
flows with constant frame rate = 50 frames/s, buffer slots storing GSM/RTP packets 
 

 
IMS-Based Energy-Efficient Mobile Multimedia 
291 
CN
(I-)S-CSCFMN
(1) INVITE
PSMN
ASPM
MN
(2) INVITE
(3) new-INVITE
Interface rebind
(5)  (de-)REGISTER
(6) 401 Unauth.
(7)  (de-)REGISTER
(8) OK
(17) 302 MOVED
(18) 302 MOVED
(19) INVITE
(20) INVITE
(4) 100 Trying
wait MN 
re-REGISTER
(11) 401 Unauth.
(10)   REGISTER
(12) 401 Unauth.
(13)   REGISTER
(15) OK
(14)   REGISTER
(16) OK
(9)   REGISTER
send MOVED
T0
T1
T2
T3
CN
(I-)S-CSCFMN
(1) INVITE
(1) INVITE
PSMN
ASPM
MN
(2) INVITE
(2) INVITE
(3) new-INVITE
(3) new-INVITE
Interface rebind
(5)  (de-)REGISTER
(5)  (de-)REGISTER
(6) 401 Unauth.
(6) 401 Unauth.
(7)  (de-)REGISTER
(7)  (de-)REGISTER
(8) OK
(8) OK
(17) 302 MOVED
(17) 302 MOVED
(18) 302 MOVED
(18) 302 MOVED
(19) INVITE
(20) INVITE
(20) INVITE
(4) 100 Trying
wait MN 
re-REGISTER
(11) 401 Unauth.
(11) 401 Unauth.
(10)   REGISTER
(10)   REGISTER
(12) 401 Unauth.
(12) 401 Unauth.
(13)   REGISTER
(13)   REGISTER
(15) OK
(15) OK
(14)   REGISTER
(14)   REGISTER
(16) OK
(16) OK
(9)   REGISTER
(9)   REGISTER
send MOVED
T0
T1
T2
T3
 
Fig. 6. Power management session initiation delay analysis 
(89B payload per packet), and 13.2Kbps bandwidth. The reported experimental 
results aim to evaluate three different and crucial aspects of our proposal: i) how the 
proposed power management solution is compatible even with the strict time 
requirements of VoIP session initiation; ii) the battery lifetime improvements 
achievable via our energy-saving techniques; and iii) the overhead due to ASPM 
interposition and CM execution. All experimental results have been collected by 
using 3G as the always-on wireless interface and WiFi as the wireless interface that is 
switched on at runtime. 
About session initiation delay imposed by call redirection, Fig. 6 shows the 
duration of all main power management phase. Results have been collected for the 
four main parts of the protocol. The first part starts with sending the CN INVITE 
message and terminates with TRYING reception; it occurs over 3G UMTS interface 
and lasts T0=285ms with a standard deviation (st.d.) of 87ms. The second part is MN 
de-registration, which also occurs over the always-on interface and lasts T1=570ms 
(st.d. 100ms). The third part is MN registration over WiFi that lasts T2=825ms (st.d. 
182ms), (assuming that MN IP address is configured). Finally, the fourth part relates 
to the time between the MOVED and the second INVITE messages sent at CN; we 
have measured T4=93 (st.d. 68). Let us note that T2 is longer than T1 due to the higher 
number of messages exchanged caused by ASPM interposition; however, T2 does not 
double T1 because the WiFi response time is shorter than the UMTS one T2.  
The sum of all the above delays is always below 3s, which is indicated by E.721 as 
the recommended call setup delay for local calls [28]. Of course, this delay does not 
account for subsequent session initiation delay over WiFi; nonetheless, this can be 
considered as another session initiation phase since any IMS client, at the reception of 
302 MOVED message, usually informs that a call re-direction is ongoing. 

292 
P. Bellavista, A. Corradi, and L. Foschini 
The second evaluation is an analytical evaluation of the benefits of our solution if 
deployed on off-the-shelf smart phones such as Nokia N95. Our evaluation also 
exploits the results of field trial experiments conducted by Arjona on always-on WiFi 
battery consumption of N95 [29]. Although the exact WiFi consumption depends on 
several parameters, including AP and client configuration, scanning frequency and 
additional power saving features, Arjona experiments demonstrate that the N95 WiFi 
antenna with default configuration shows an average consumption increase of 0.05W 
if left always-on (inactive); that is confirmed by the results for WiFi sleep mode 
consumption reported by Balakrishnan [14]. Considered that N95 battery lifetime is 
950mAH and is charged at 3.7V, this means that battery lifetime is 
950/((0.05/3.7)*1000) = 70.3 hours in the always-on configuration, by neglecting all 
other energy consumption contributions. That duration is significantly lower than the 
stand-by time of 200 hours with UMTS and of 188 hours with UMTS, IMS-based 
active registration, and network optimizations [29], [30]. With our power 
management technique, all the above WiFi energy cost can be completely cut off. 
Moreover, by focusing on WiFi call time duration and assuming 0.75W as the average 
consumption for active WiFi antenna [14], the total call time is 950/((0.75/3.7)*1000) 
= 4.6 hours, which is longer than the talk time duration specified by Nokia for UMTS, 
i.e., 160 minutes [30]. This also confirms the usefulness of our approach that enables 
the advantages of WiFi-based communication without paying its high standby energy 
costs. 
The third reported result validates our solution with regard to the overhead in terms 
of CPU work load and scalability. As a general consideration, we have experimented 
that IHMAS relevantly improves energy consumption at the expense of a limited, 
even if not negligible, overhead. ASPM can serve up to 550 requests per-second; to 
further increase ASPM scalability we are considering the possibility to re-implement 
it as a new C-based OpenSIPS module. In addition, to this, there is an overhead 
related to CM execution. For all conducted experiments, we monitored CM CPU 
overhead. In the worst case, i.e., for high user mobility, it is up to 20%; for fixed 
users, thanks to dynamic monitoring period adaptation, it drops to 5%. However, as 
already mentioned, we are studying possible alternatives to further decrease that value 
and increase energy savings, such as connectivity forecasting. 
6   Conclusions and Future Work 
The research work accomplished within the IHMAS project demonstrates the 
suitability of power management solutions based on the standard IMS infrastructure. 
IHMAS practically shows that energy-saving techniques can relevantly increase 
battery lifetime when using high-consumption and low-cost wireless interfaces, by 
preserving full compliance with the standard and, thus, enabling the deployment of 
the proposal over already installed IMS-conformant networks. In addition, the session 
initiation delays introduced by the IHMAS facility for power management are 
compatible even with the strict requirements that are usual for VoIP calls. 
The encouraging results that we have already obtained with IHMAS are 
stimulating our current research work on the extension and refinement of our solution 
prototype. On the one hand, we are developing a J2ME version of CM and IMS 

 
IMS-Based Energy-Efficient Mobile Multimedia 
293 
client, tailored to any consumer device hosting a J2ME platform. On the other hand, 
we are carefully evaluating the different IHMAS energy-saving results that can be 
obtained via either C-based or J2ME-based prototypes of IMS clients through 
extensive measurements of energy consumption in real and wide-scale deployment 
environments. 
References 
1. Kravets, R., Krishnan, P.: Power Management Techniques for Mobile Communication. In: 
4th Annual ACM/IEEE International Conference on Mobile Computing and Networking, 
pp. 157–168. ACM, New York (1998) 
2. Anastasi, G., Conti, M., Lapenna, W.: Power Saving Policies for Wireless Access to 
TCP/IP Networks. In: 8-th IFIP Workshop on Performance Modelling and Evaluation of 
ATM and IP Networks (2000) 
3. Anand, M., Nightingale, E.B., Flinn, J.: Self-Tuning Wireless Network Power 
Management. J. Wireless Networks 11(4), 451–469 (2005) 
4. Inoue, M., et al.: Novel out-of-band Signaling for Seamless Interworking Between 
Heterogeneous Networks. IEEE Wireless Communications 11(2), 56–63 (2004) 
5. Inoue, M., et al.: Context-Based Network and Application Management on Seamless 
Networking Platform. Wireless Personal Communications 35(1-2), 53–70 (2005) 
6. Camarillo, G., García-Martín, M.A.: The 3G IP Multimedia Subsystem (IMS). John Wiley, 
Chichester (2006) 
7. UCT IMS Client Project, http://uctimsclient.berlios.de/ 
8. Open IMS core Project, http://www.openimscore.org/ 
9. OpenSIPS Project, http://www.opensips.org/ 
10. Shacham, R., et al.: Composition for Enhanced SIP Presence. In: 12th Annual IEEE 
International Symposium on Computers and Communications, pp. 203–210. IEEE Press, 
New York (2007) 
11. 3rd Generation Partnership Project (3GPP): Presence Service: Architecture and functional 
description. TS 23.141 v8.0.0 (2008) 
12. 3rd Generation Partnership Project 2 (3GPP2): Presence Stage 3. X.S0027-003-0 v1.0 
(2008) 
13. Open Mobile Alliance: Presence SIMPLE Specification. TS-Presence_SIMPLE-V1_1-
20080128-C (2008) 
14. Krashinsky, R., Balakrishnan, H.: Minimizing Energy for Wireless Web Access with 
Bounded Slowdown. In: 8th Annual ACM International Conference on Mobile Computing 
and Networking, pp. 135–148. ACM Press, New York (2002) 
15. Pletcher, N., Rabaey, J.M.: Ultra-Low Power Wake-Up Receivers for Wireless Sensor 
Networks. Technical Report No. UCB/EECS-2008-59. EECS Department, University of 
California, Berkeley (2008) 
16. Schulzrinne, H., Wedlund, E.: Application-layer mobility using SIP. ACM Mobile 
Computing and Communications Review 4(3), 47–57 (2000) 
17. Vali, D., et al.: An efficient micro-mobility solution for SIP networks. In: IEEE Global 
Communications Conference, pp. 3088–3092. IEEE Press, New York (2003) 
18. Wu, W., et al.: SIP-based vertical handoff between WWANs and WLANs. IEEE Wireless 
Communications 12(3), 66–72 (2005) 
19. Kalmanek, C., et al.: A Network-Based Architecture for Seamless Mobility Services. IEEE 
Communications Magazine 44(6), 103–109 (2006) 
20. Bennett, A.: Voice Call Continuity (VCC) between Circuit Switched (CS) and IP 
Multimedia Subsystem (IMS)., Technical Specification (TS) 23.206, 3GPP (2007) 

294 
P. Bellavista, A. Corradi, and L. Foschini 
21. Bellavista, P., Corradi, A., Foschini, L.: Context-Aware Handoff Middleware for 
Transparent Service Continuity in Wireless Networks. Pervasive and Mobile Computing 
Journal 3(4), 439–466 (2007) 
22. Nicholson, A.J., Noble, B.: BreadCrumbs: Forecasting Mobile Connectivity. In: 12th 
Annual ACM International Conference on Mobile Computing and Networking, pp. 46–57. 
ACM Press, New York (2008) 
23. NIST, jain-sip Project, https://jain-sip.dev.java.net/ 
24. WRAPI Project, http://sysnet.ucsd.edu/pawn/wrapi/ 
25. Tourrilhes J., Wireless Tools for Linux Project,  
  http://www.hpl.hp.com/personal/Jean_Tourrilhes/Linux/ 
26. Precision Time Protocol Daemon Project, http://ptpd.sourceforge.net 
27. JSR 281: IMS Services API, http://jcp.org/en/jsr/detail?id=281 
28. ITU-T, Network Grade of Service Parameters and Target Values for Circuit Switched 
Services in the Evolving ISDN, Recommendation E.721, Telecommunication 
Standardization Sector of ITU (1999)  
29. Arjona, A., Yla-JMski, A.: VoIP Call Signaling Performance and Always-On Battery 
Consumption in HSDPA, WCDMA and WiFi. In: International Conference on Wireless 
Communications, Networking and Mobile Computing, pp. 2964–2967. IEEE Press, New 
York (2007) 
30. N95 Technical Specifications, http://europe.nokia.com/A4323297 
 

Announcement/Subscription/Publication:
Message Based Communication for
Heterogeneous Mobile Environments
Henry Ristau⋆
Chair for Information and Communication Services
University of Rostock
Albert-Einstein-Str. 21
18059 Rostock
Germany
henry.ristau@uni-rostock.de
Summary. Many tasks in smart environments can be implemented us-
ing message based communication paradigms that decouple applications
in time, space, synchronization and semantics. Current solutions for de-
coupled message based communication either do not support message
processing and thus semantic decoupling or rely on clearly deﬁned net-
work structures. In this paper we present ASP, a novel concept for such
communication that can directly operate on neighbor relations between
brokers and does not rely on a homogeneous addressing scheme or any-
more than simple link layer communication. We show by simulation that
ASP performs well in a heterogeneous scenario with mobile nodes and
decreases network or processor load signiﬁcantly compared to message
ﬂooding.
Keywords: Heterogeneous Mobile Environments, Publish/Subscribe,
Distributed Event-Based Systems, Content-Based Routing, Flooding.
1
Introduction
A growing application area for heterogeneous wireless networks are smart envi-
ronments. They emerge from the cooperation of many diﬀerent devices from tiny
sensors to powerful computers. This cooperation targets at a speciﬁc objective
which in smart environments usually is user assistance. While communication be-
tween applications on all of these devices is a basis for cooperation, heterogeneity
and mobility induce major problems here. Many devices can communicate using
multiple communication technologies, the technologies themselves however are
often incompatible. Homogeneous addressing schemes are not guaranteed to exist
throughout a smart environment. The network topology is constantly changing
⋆This research was supported by a grant of the German National Research Foundation
(DFG), Graduate School 1424, Multimodal Smart Appliance Ensembles for Mobile
Applications (MuSAMA).
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 295–308, 2009.
c
⃝Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

296
H. Ristau
through entering, leaving and mobile devices. Thus, to keep applications simple
it is essential that communication in a smart environment is as transparent from
the applications as possible.
Another problem in smart environments is the heterogeneity of devices and
applications themselves. Applications are supposed to communicate even if they
use diﬀerent document or data formats. Data from multiple devices might have
to be aggregated while it is communicated towards its sink. Again from the per-
spective of an application developer this data processing should be as transparent
as possible.
An example is the communication between a number of sensors and a PDA in a
heterogeneous environment. The applications on the sensors should only measure
and provide the temperature. Where, when and in which unit of measurement
this temperature is needed by other devices in the network should be of no
interest to these applications. On the other hand, the application on the PDA
should only display the room temperature. It should not be concerned about
where the temperature is measured, which units are used, and how many sensors
are available. The data communication and processing between the sensors and
the PDA should be eﬃcient and reliable. However it is not important how many
communication technologies are involved or how many systems are able to do
the processing, where these systems are located and if they are available.
In this paper we present Announcement/Subscription/Publication (ASP), a
concept to achieve message based communication between applications decou-
pled of time, space, synchronization and semantics in heterogeneous mobile en-
vironments. ASP allows an application to publish or receive and subscribe to
messages transparently with respect to the network infrastructure, the availabil-
ity and location of communication partners, asynchronously of any broker or
communication partner and transparently with respect to the semantic capabili-
ties of any communication partner. To achieve the transformation and processing
of messages, an application can register as processor. Such a processor applica-
tion only has to process messages according to its capabilities with the same
transparency as described before. It does not need to be able to describe its pro-
cessing abilities - of course it helps if it can somehow subscribe to its preferred
input messages.
The remainder of this paper is structured as follows: In the next section we
explain which kind of scenarios for message based communication we tackle in
this paper. In section 3 we present related work and give an elaborate problem
statement followed by a detailed description of the concept of ASP in section 4.
In section 5 we present the results of an evaluation of our concept and conclude
the paper in section 6.
2
Application Scenarios
Scenarios for message based communication in smart environments can be char-
acterized by message size and publication frequency. Small messages can be
transmitted from one device to another one completely before they are forwarded

Announcement/Subscription/Publication
297
Fig. 1. Scenarios for message based communication divided into four groups according
to message size and publication frequency
to a third device without a signiﬁcant loss of performance. Preferably they ﬁt
into one network packet. Large messages need to be fragmented and should only
be received completely if necessary, e.g. for processing to avoid high transmission
latencies. Individual messages are transmitted only once or so infrequent that it
is not eﬃcient to keep a routing path for the next message. Streams of messages
however are transmitted frequently on the same paths. This division results in
four groups labeled with some examples for each group in ﬁgure 1.
In the ﬁrst group ﬂooding algorithms are the method of choice sending the
individual message to all possible target locations. This results in the message
being delivered to every available sink. However in any other group more than
just one data packet is delivered and ﬂooding algorithms can easily overload parts
of the communication infrastructure or data processors with less performance.
In this paper we concentrate on scenarios of the second group and conclude
some means to extend our ideas for scenarios of groups three and four which we
however do not yet evaluate.
3
Related Work and Problem Description
Publish/subscribe is the communication paradigm of choice for decoupling of
message source (publisher) and sink (subscriber) in time, space and synchro-
nization [6] using a central broker to register the interest of subscribers and
subsequently forward publications to them. By content-based routing (CBR) [4]
it is possible to replace the broker as former central element by a network of dis-
tributed brokers and decouple the publish/subscribe system from the underlying
communication technologies at the same time.
Apart from subscribing to a message subject or channels, CBR allows sub-
scriptions to the content of a message, which can be for example values of a
tuple. The routing tables for CBR are initialized based on interest of subscribers
that is disseminated through the network using ﬂooding techniques. Depending
on the resulting routing tables, publications can be routed from publisher to
subscriber directly in a multipath fashion [3]. The distribution of interest was
optimized through the usage of beacons. This increases the fault-tolerance of the

298
H. Ristau
routing protocol to work in mobile environments like mobile ad hoc networks
(MANETs) [2][14].
Publish/subscribe especially for smart environments is provided by Mundo-
Core [1], a modular middleware for the requirements of pervasive computing
based on a microkernel design. It supports structured, hierarchical and single-
hop strategies for routing resulting in high scalability and adaptability. It allows
for channel and content-based subscriptions.
The processing of messages however is not integrated into or observed by the
publish/subscribe middleware. In [15] we analyzed two approaches of integrating
processors into a publish/subscribe middleware. The ﬁrst one, mapping the pro-
cessor to a sink for its input and a source for its output messages, induces much
unnecessary processing and communication if multiple processors for the same
operation are available. The second approach, the extension of CBR to allow
dissemination of interest through processors, leads to very complex processors
because apart from processing message type m to message type m′ they need to
be capable of processing a subscription for message type m′ into a subscription
for message type m which could even be impossible depending on the type of
processing.
Two very specialised approaches for message processing in communication are
composite event detection and event stream processing (ESP). The former one
denotes the composition of primitive events to monitor the state of a distributed
system and notify sinks of the detection of composite events. One such system
is GEM [12]. ESP systems like Borealis [7] or Cayuga [5] are able to execute a
continuous query over a stream of events delivering the queries result to sinks.
Both systems have in common that the sink has to provide the processing in-
structions in the form of a script or a query and thus is not decoupled from the
distributed system in terms of semantics.
A system for semantically decoupled communication in sensor networks is
presented in [17]. Data from diﬀerent sensor networks is collected in an IP-based
overlay network where the semantic decoupling is done using ontologies. The
resulting information is provided to connected sinks. The system is based on a
very strictly deﬁned topology and thus not applicable for heterogeneous mobile
networks as targeted by this paper.
4
Contribution
The ASP concept consists of a message routing algorithm based on a given sys-
tem architecture. We start by introducing the system architecture. Afterwards
we describe the three phases of the routing algorithm, Announcement, Subscrip-
tion and Publication. At the end of this section we identify the requirements to
implement a scenario using the ASP concept.
4.1
The System Architecture
To decouple the applications transparently from the network and all other ap-
plications we base our approach on a system architecture with one broker on

Announcement/Subscription/Publication
299
each participating node. All client applications are connected locally and other
brokers are connected through the network layer. We do not consider remote
applications on nodes without broker because it is no problem to implement
very slim brokers for nodes with less performance. Each broker keeps a cache
of virtual neighbors, which can be applications - source, sink and processor - or
neighboring brokers that can be reached with one hop through any communica-
tion technology as shown in ﬁgure 2.
Applications Interfaces. Source applications register at the broker and have
two main methods available. They can register a special descriptive announce-
ment message (see section 4.2) if they wish to and they can publish messages.
A sink application can register
Fig. 2. The system architecture for ASP fea-
tures one broker per node to transparently
decouple applications from each other and the
network topology
using an optional ﬁlter. If a ﬁlter
is provided the sink receives only
announcements matching the given
ﬁlter, otherwise they receive every
announcement received by their bro-
ker. After receiving an announce-
ment, a sink application can decide
to subscribe to that announcement
and will receive further publications
from that source.
Processor
applications
register
just like sinks with an optional ﬁl-
ter and receive announcements. If
they are able to process any of these
announcements, the result is to be
submitted back to their broker along with identiﬁcations of the processed source
announcements and a metric information denoting the complexity of the pro-
cessing. If the processor application is part of an active path later, further pub-
lications are sent to it for processing.
Network Abstraction Layer (NAL). The NAL decouples the routing al-
gorithm from any underlying communication technology. Its tasks are neighbor
discovery, neighbor cache updates and reliable message delivery. Brokers in com-
munication range have to be detected and inserted into the neighbor cache. Their
information in the cache, especially their connection metric, has to be updated
if it changes. Each message from the broker has to be delivered to the neighbor
or if it can not be delivered, the neighbor has to be removed from the neighbor
cache because it is not reachable anymore. For any of these actions, the broker
has to be notiﬁed.
Since the algorithm relies on communication links to its direct neighbors only
and the NAL provides neighbor discovery and reliable message delivery, ASP
can work directly on the link layer if necessary and can easily be implemented
for any communication technology by adding the appropriate NAL.

300
H. Ristau
Fig. 3. An example announcement with all necessary data ﬁelds
Terminology. Subsequently we denote a source application’s broker as “source”,
a sink application’s broker as “sink” and a processor application’s broker as “pro-
cessor”. A virtual neighbor of a broker, which can either be an application or a
neighboring broker, is meant by the term “neighbor” if not speciﬁed.
4.2
The Announcement Phase
When a source application publishes a message, the source disseminates the
availability of this message among all brokers by sending an announcement.
Contents. Figure 3 shows a minimal example for an announcement. The id is
generated together with the announcement by the source or processor using a
deﬁned hash algorithm on the message’s content right after the announcement
is created. It is used as content-based reference for the announcement and for
duplication and loop detection in the announcement’s distribution.
The metric is updated by every broker before the announcement is sent to
a neighbor and represents the path metric between the source and the receiv-
ing broker. The validity value is initiated by the source and represents the time
the announcement is valid. If an announcement is not prolonged before, all ref-
erences to it can be removed from a broker’s cache. To recognize an identical
announcement with the task to prolong an older one, the sequence number has
to be incremented. The ﬂags are needed in an extension of the algorithm to
distinguish individual mode from stream mode.
The message is the descriptive announcement message registered or the next
message published by a source application, or results from processing by a pro-
cessor application. The requirement for a message in an announcement is that it
has to be small enough for the announcement to ﬁt into one packet the NAL can
send out. The distribution algorithm itself is not meant to support announce-
ment fragmentation while packet fragmentation can be implemented in the NAL
if needed.
Distribution. The target of announcement distribution is for every broker to
receive the announcement and store the neighbor it was received from with the
lowest path metric as best announcer. Hence, if a sink application is interested in
this announcement, its broker can subscribe to this optimal path of distribution.
Therefore, an extended ﬂooding algorithm is utilized.
The full announcement is sent to every neighboring broker, except for the
sender if that was a neighboring broker. Furthermore it is distributed to every

Announcement/Subscription/Publication
301
Fig. 4. An example subscription with all necessary data ﬁelds
processor and sink application except if they have registered using a ﬁlter and
the ﬁlter does not ﬁt the announcement. If an announcement is re-received with a
better path metric, the message is stripped oﬀand the resulting short announce-
ment is forwarded according to the same rules as above to signal the better path
to the following brokers. Of course a short announcement is not forwarded to
sink applications because they can gain no new information from it and its pro-
cessing should only be simulated by the broker knowing the outcome and metric
from the preceding full announcement because the processor application could
not do any processing without the message.
4.3
The Subscription Phase
The subscription represents the control data in the ASP concept. It is used for
brokers to signal a subscription for a given path turning that path into an active
path. Other purposes are the removal of an active path or the indication of a
broken path towards the source for re-announcement.
Contents. Figure 4 shows the necessary ﬁelds for a subscription. The id is used
as reference for the associated announcement. The subscriberId is generated
randomly by the sink to represent that broker as the subscriber. It is needed to
distinguish between diﬀerent subscriptions for the same announcement to allow
multiple sinks. Two identical subscriberIds would eventually result in one sink
not receiving its publications for this announcement period but the probability
of this event is suﬃciently low. The metric is also set by the sink to the metric
of the best announcement received so far to allow path optimization if a better
announcement is received after a subscription has been generated.
The type signals the purpose of a subscription. So far, possible types are
subscribe, unsubscribe, and broken path. The sequence value is used to allow
for publication caching which is not yet necessary for small/stream scenarios as
described in section 2.
Distribution. If a new subscription or one with a better metric value is received
from a neighbor, that neighbor is marked as active path for the provided id and
subscriberId. Afterwards the subscription is forwarded to the best announcer if
it is a neighboring broker. If the best announcer is a processor application, one
subscription for every stored source announcement id is generated and forwarded
as described before. The neighbor a subscription is sent to is stored by the broker.

302
H. Ristau
Fig. 5. An example publication with all necessary data ﬁelds
If the best announcer changes after any subscription has been sent out, a
new subscription is sent out according to the above rules and an unsubscribe
subscription is sent to the target of the previous subscription to remove the
obsolete active path. If an unsubscribe subscription is received that matches an
active path with its subscriberId and metric, the active path is removed and the
unsubscribe subscription is forwarded to the former subscriptions target.
If an active path is detected to be not available anymore for any reason, a path
broken subscription is generated and forwarded according to the same rules as
above. If a source receives such a path broken subscription, it prepares to extend
the next publication to an announcement so a new path can be found if available.
4.4
The Publication Phase
Following an announcement, the source will send out all published messages
as publications until the next announcement is necessary due to announce-
ment expiration or path disintegration. A minimal publication is depicted by
ﬁgure 5. The id is used as reference for the associated announcement and sub-
scriptions. The sequence number is for fragmentation which is not necessary for
small/stream scenarios. The counter is used to recognize and remove unwanted
retransmissions.
A publication is forwarded on all known active paths just once. Hence, every
subscribed broker receives the publication and forwards it towards the subscribed
sink applications.
4.5
Requirements for a Scenario
ASP is a communication concept which can be implemented for a given scenario
or a full middleware if desired. A number of requirements have to be met by the
scenario which we present in the following.
Announcements. If published messages are too large to ﬁt into an announce-
ment (cf. 4.2) or descriptive announcements are needed for other reasons, a
means of describing messages is needed. Examples are meta-data as in document
headers or advertisements as in many publish/subscribe systems. Processor ap-
plications receiving a descriptive announcement must be able to decide whether
they can process the following publications.
Furthermore a hash algorithm is necessary to generate a suﬃcient unique id
from a published message or descriptive announcement. Eventually the accuracy
of ﬂoating point representation has to be limited before hashing to avoid multiple
instances of the same messages if processing by diﬀerent processing applications
can lead to diﬀerent rounding.

Announcement/Subscription/Publication
303
Fig. 6. Simulation scenario: station A and B are connected by Ethernet while all nodes
and stations are connected by wireless LAN with the given estimated transmission
range. The nodes move inside the 200m x 500m playground area.
Metrics. A metric is needed that can describe communication and processing
to result in optimal paths for message publication. We prefer time based metrics
because time can equally be measured for processing and communication and
it can be totalled to result in a path metric even if processing leads to data
aggregation.
System Size. Since ﬂooding does not scale for very large topologies a system
boundary is necessary. This can either be a limited environment like a smart
environment we are targeting, a limited number of systems that implement a
broker or an additional measure like for example a hop count or a maximum
metric for the ﬂooding of announcements.
5
Evaluation
Based on the ASP concept we implemented a scenario with source, processor
and sink applications, a broker implementation and a NAL for 802.2 logical link
control (LLC) [9] for simulation. Since 802.2 LLC is the link control layer for
802.3 Ethernet [10] and 802.11 wireless LAN [8] our scenario includes station-
ary devices as well as mobile nodes. We evaluated the completeness of message
delivery and the load induced by communication.
5.1
Simulation Scenario and Methodology
Figure 6 shows the simulation scenario. It consists of two stationary nodes, sta-
tion A and B, connected by Ethernet and ﬁve mobile nodes. All nodes are con-
nected by wireless LAN in ad-hoc mode according to 802.11b [8] with 11MB/s,
a maximum transmission power of 1 mW, and a limit of 3 retransmission. The
mobile nodes are moving according to the Random Waypoint Mobility model
[11] on the full playground with a random velocity of 1 to 5 m/s and random
pause lengths of 1 to 5 seconds (both uniform distribution).

304
H. Ristau
●
●
●
●
●
●
●
●
●
●●
●
●
●
●●●●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●●●●●
●
●
●●●
●
●
●
●
●
●●●
●
●
●
●
●●
●
●
●●●
●
●●●
●
●●●●●
●●●
●
●
●●
●
●
●●
●
●
●●●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●●●●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●●●●●
●
●
●●●
●
●
●
●
●
●●●
●
●
●
●
●●
●
●
●●●
●
●●●
●
●●●●●
●●●
●
●
●●
●
●
●●
●
●
●●●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●●
●
●
●
●●●●
●
●
●
●
●
●
●
●
●
●●
●
●
●●
●
●
●
●●●●
●
●●●●
●
●●
●
●●●●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●●
●●●
●
●●
●
●
●●●
●
●●
●
●
●●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●●
●
●
●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
Flooding
10s
20s
50s
100s
Flooding
10s
20s
50s
100s
80
85
90
95
100
mean
Fig. 7. Box-plots showing the number of messages received by sink 0 (left) and sink 1
(right) using Flooding compared to ASP with diﬀerent validity settings (10s, 20s, 50s,
and 100s) from 100 messages sent by the source
The scenario is a small/stream scenario with one temperature source appli-
cation on node 1 that generates 100 temperature values in degrees Celsius, one
every second. One processing application is on station A (Celsius to Fahrenheit)
and one on station B (Celsius to Kelvin). Two temperature sinks are on node 2
(Fahrenheit) and node 3 (Kelvin).
The scenario was implemented for the OMNeT++ discrete event simulator
[16] version 3.3 and the INET Framework version 20061020 [13]. The experiment
was run 1000 times with diﬀerent seeds, leading to diﬀerent starting positions
for the mobile nodes and diﬀerent movement patterns.
5.2
Completeness
We deﬁne completeness as the number of messages that are delivered to a given
sink application relative to the number of messages that could have been de-
livered if all messages published by any source application would have been
processed by all possible processor applications and delivered to that sink appli-
cation in the time of observation. Thereby the sink and any processor application
only count as available until the time they stop the registration at their local
broker for the last time in the observation interval.
In a mobile scenario a completeness of 1 as the theoretical maximum is not
always achievable because the availability of a path through the network topology
is not taken into account in the deﬁnition of completeness. Therefore we compare
the completeness of the ASP concept with the ﬂooding of every message to all
brokers. A higher completeness than ﬂooding is possible if caching is used which
however is not implemented in our small/stream scenario because the loss of
single messages is often not a problem in such scenarios.
Results. Figure 7 shows the number of messages received by sink 0, the sink
application on node 2, and sink 1 on node 3 for ﬂooding and ASP with diﬀering
announcement validity. For ﬂooding while most runs result in all 100 messages

Announcement/Subscription/Publication
305
Flooding
80
90
100
0
1
2
%
ASP 10s
40
60
80
100
ASP 20s
40
60
80
100
ASP 50s
40
60
80
100
Fig. 8. Histograms showing the number of messages received by sink 1 on the x-axis
and the percentage of experiment with this result on the y-axis. The small arrow in
the bottom of each histogram shows the mean value.
700
720
740
760
780
800
0
20
40
60
80
100
0
2
4
6
8
10
12
14
messages
announcements
lost
Fig. 9. The number of announcements initiated by the source, the number of announce-
ments not delivered to the sink and the number of messages received by sink 1 for the
given runs of the experiment using ASP with a validity of 100s
being delivered, a number of topology states lead to messages being lost. The
mean value with 99.8 for both sinks is very high. For ASP we recognized that for
most runs less than 6 messages are lost. However there are some outliers leading
to a drop of the mean value down to about 95 messages for a validity of 100
seconds.
The histograms for sink 1 in ﬁgure 8 show that in most runs, only few messages
are not transmitted. There is also a signiﬁcant fraction of runs where x or a few
more messages are missed with x = t/1s, with t being the announcement validity
and 1s being the time between every 2 messages.
Discussion. When an active path breaks in publication phase the publication is
not retransmitted and lost. This leads to a single message being lost and can be
recognized in ﬁgure 9 by more than one announcements being initiated. Without
path failures in that experiment one announcement should suﬃce which can be
seen in run 726 and 770 because the validity for ASP equals the duration of the
experiment.

306
H. Ristau
●
●
●●●●●●
●
●●●
●
●●●●●●●●●●●●●●●●●●●●●●●
●
●●
●
●●●●●●●●●
●
●●●●●●●●●●●●●●●
●
●
●
●●●●
●
●
●●
●
●
●●
●
●
●
●
●
●●
●
●
●
●●●●●●●●
●●
●●●●●●
●
●
●
●
●
●●●
●
●
●
●
●
●●
●
●
●
●
●●●●●●
●
●●●
●
●●●●●●●●●●●●●●●●●●●●●●●
●
●●
●
●●●●●●●●●
●
●●●●●●●●●●●●●●●
●
●
●
●●●●
●
●
●●
●
●
●●
●
●
●
●
●
●●
●
●
●
●●●●●●●●
●●
●●●●●●
●
●
●
●
●
●●●
●
●
●
●
●
●●
●
●
0
10000
20000
bytes
40000
Flooding
ASP 10s
ASP 20s
ASP 50s
ASP 100s
Fig. 10. Box-plots showing the average number of network transmissions sent by each
node using Flooding and ASP with diﬀerent validity settings
The histogram of the ﬂooding algorithm in ﬁgure 8 shows that there are
phases when no path is available at all. If this happens in announcement phase,
all publications are lost up to the next announcement. These are mostly x = t/1s
messages as observed before, or eventually less messages if the experiment stops
or a path to another sink is lost earlier. This behaviour can be observed in more
detail in ﬁgure 9 for runs 698, 711, 778, and 783.
5.3
Network Load
To represent network load we measure the number of bytes sent out by the
NAL of every node for the purpose of message transmission. We do not count
data sent for management purposes like neighbor discovery or heartbeats be-
cause we want to compare the broker’s dissemination algorithms and not the
NAL implementations. Again we compare to simple ﬂooding as the more ﬂexible
algorithm.
Results. Using the ﬂooding algorithm, every node sends an average of 30 kbyte
of algorithm messages throughout the experiment as shown in ﬁgure 10. Using
ASP with a validity of 10 seconds this is reduced to 10 kbyte and is further
reduced with a longer validity down to about 5 kbyte for 100 seconds.
Discussion. For announcement delivery we use an extended ﬂooding algorithm
that eventually generates more load than ﬂooding of a single message depending
on the metric and the topology of the scenario. Extending the announcement
validity does not lead to a linear decrease of initiated announcements because
of path failures. Furthermore subscriptions also need to be delivered. Therefore,
a network load inversely proportional to the announcement validity cannot be
expected. However in our scenario ASP reduces the network load signiﬁcantly
compared to simple ﬂooding.

Announcement/Subscription/Publication
307
6
Conclusion
In this paper we presented ASP, a concept for message based communication
in heterogeneous mobile networks decoupling source, sink and processor appli-
cations as well as brokers in time, space and synchronization. By transparent
processing message delivery from source to sink applications is decoupled in
semantics as well.
6.1
Beneﬁts
The algorithm signiﬁcantly decreases network traﬃc and processor load by using
optimal paths in subscription and publication phase. Since control messages are
only delivered in subscription phase on optimal paths, their ratio in overall traﬃc
is very low.
The ASP concept relies on neighbor relations between brokers only and thus, it
does not need a consistent addressing scheme throughout the network topology.
Through separation of the NAL which can directly operate on link layer, it can
easily be implemented for any available communication technology.
In our simulation we could show that even though the nodes were mobile in the
ad hoc network and the neighbor relations between nodes changed frequently,
ASP was able to adapt. Only few messages where lost compared to message
ﬂooding in most runs while network load was reduced signiﬁcantly.
6.2
Shortcomings
If an active path breaks in publication phase, a new announcement is initiated.
This leads to more load on the network and processors. Since the number of
damaged communication paths very probably rises with a large scenario or more
mobility, this is still an issue.
If there is no connection possible between a source and a sink, the sink applica-
tion will not receive any message throughout the entire publication phase. This is
also the case if a new sink applications enters the system after the announcement
phase. This leads to a trade-oﬀbetween ﬂexibility and resource usage. A shorter an-
nouncement validity leads to a faster integration of “new” sink applications while
a longer announcement validity leads to less network and processor load.
6.3
Future Work
For future work more scenarios need to be implemented and analyzed by simulation
or observation. Especially large/individual or large/stream scenarios posediﬀerent
requirements on the ASP concept because the loss of a single message will become
important when it leads to the loss of one or even the only larger message to be
delivered. Publication caching is one important step to fulﬁll these requirements.
Another task is the elimination or at least optimization of the aforementioned
shortcomings. Communication and processing load can be reduced if a broken
path can be repaired without the initiation of a new announcement by exploiting
multipath propagation characteristics of the utilized ﬂooding algorithm. Further-
more announcements can be cached to allow for faster integration of new sink

308
H. Ristau
applications even with high announcement validity. These enhancements will
also help ASP in dealing with large/individual and large/stream scenarios.
References
1. Aitenbichler, E., Kangasharju, J., Muhlhauser, M.: Mundocore: A light-weight in-
frastructure for pervasive computing. Pervasive and Mobile Computing 3(4), 332–
361 (2007)
2. Baldoni, R., Beraldi, R., Cugola, G., Migliavacca, M., Querzoni, L.: Structure-less
content-based routing in mobile ad hoc networks. In: International Conference on
Pervasive Services, 2005. ICPS 2005. Proceedings, July 11-14, pp. 37–46 (2005)
3. Carzaniga, A., Rutherford, M.J., Wolf, A.L.: A routing scheme for content-based
networking. In: INFOCOM 2004. Twenty-third AnnualJoint Conference of the IEEE
Computer and Communications Societies, March 7-11, vol. 2, pp. 918–928 (2004)
4. Carzaniga, A., Wolf, A.L.: Content-based networking: A new communication in-
frastructure. In: K¨onig-Ries, B., Makki, K., Makki, S.A.M., Pissinou, N., Scheuer-
mann, P. (eds.) IMWS 2001. LNCS, vol. 2538, pp. 59–68. Springer, Heidelberg
(2002)
5. Demers, A., Gehrke, J., Hong, M., Riedewald, M., White, W.: Towards expressive
publish/subscribe systems. In: Ioannidis, Y., Scholl, M.H., Schmidt, J.W., Matthes,
F., Hatzopoulos, M., B¨ohm, K., Kemper, A., Grust, T., B¨ohm, C. (eds.) EDBT
2006. LNCS, vol. 3896, pp. 627–644. Springer, Heidelberg (2006)
6. Eugster, P.T., Felber, P.A., Guerraoui, R., Kermarrec, A.-M.: The many faces of
publish/subscribe. ACM Comput. Surv. 35(2), 114–131 (2003)
7. Hwang, J.-H., Cetintemel, U., Zdonik, S.: Fast and reliable stream processing over
wide area networks. In: Cetintemel, U. (ed.) Proc. IEEE 23rd International Con-
ference on Data Engineering Workshop, pp. 604–613 (2007)
8. IEEE Std 802.11-2007 (Revision of IEEE Std 802.11-1999) (December 2007)
9. ISO Std 8802-2: 1998; IEEE Std 802.2-1998 (December 1989)
10. IEEE Std 802.3-2005 (Revision of IEEE Std 802.3-2002 including all approved
amendments). Section 1 - 5 (2005)
11. Johnson, D.B., Maltz, D.A.: Dynamic source routing in ad hoc wireless networks.
In: Mobile Computing, pp. 153–181 (1996)
12. Mansouri-Samani, M., Sloman, M.: GEM: A Generalised Event Monitoring Lan-
guage for Distributed Systems. Distributed Systems Engineering 4(2), 96–108
(1997), http://www.iop.org/EJ/article/0967-1846/4/2/004/ds7204.pdf
13. OMNeT++ Community Site (November 17, 2008), www.omnetpp.org
14. Petrovic, M., Muthusamy, V., Jacobsen, H.-A.: Content-based routing in mobile
ad hoc networks. In: The Second Annual International Conference on Mobile and
Ubiquitous Systems: Networking and Services, 2005. MobiQuitous 2005, July 17-
21, pp. 45–55 (2005)
15. Ristau, H.: Publish/process/subscribe: Message based communication for smart
environments. In: 2008 IET 4th International Conference on Intelligent Environ-
ments (July 2008)
16. Varga, A.: The OMNET++ discrete event simulation system. In: Proceedings of
the European Simulation Multiconference, pp. 319–324 (June 2001)
17. Wun, A., Petrovi, M., Jacobsen, H.-A.: A system for semantic data fusion in sen-
sor networks. In: Proceedings of the 2007 inaugural international conference on
Distributed event-based systems, pp. 75–79. ACM Press, New York (2007)

C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 309–324, 2009. 
© Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009 
Building a Personal Symbolic Space Model from GSM 
CellID Positioning Data 
Filipe Meneses and Adriano Moreira 
Department of Information Systems 
University of Minho, Portugal 
{meneses, adriano}@dsi.uminho.pt 
Abstract. The context in which a person uses a mobile context-aware 
application can be described by many dimensions, including the, most popular, 
location and position. Some of the data used to describe these dimensions can 
be acquired directly from sensors or computed by reasoning algorithms. In this 
paper we propose to contextualize the mobile user of context-aware 
applications by describing his/her location in a symbolic space model as an 
alternative to the use of a position represented by a pair of coordinates in a 
geometric absolute referential. By exploiting the ubiquity of GSM networks, we 
describe a method to progressively create this symbolic and personal space 
model, and propose an approach to compute the level of familiarity a person has 
with each of the identified places. The validity of the developed model is 
evaluated by comparing the identified places and the computed values for the 
familiarity index with a ground truth represented by GPS data and the detailed 
agenda of a few persons. 
Keywords: location; GSM; positioning; inference; space model. 
1   From Position to Location, to Space Models, to Context 
The position of a mobile user, described by a pair of coordinates in a geometric 
absolute referential, is one of the most used dimensions of context in location- and 
context-aware applications. Real time acquisition of the user’s position can be done 
using a number of different technologies. The Global Positioning System (GPS) [1] 
is, probably, the most popular and used of these technologies. Although GPS 
positioning is free and has worldwide coverage it has the disadvantage of working 
only in open areas, demanding a line-of-sight between a few GPS satellites and the 
receiver. There are, however, other well known solutions for positioning that 
complement GPS and that try to overcome some of its limitations. Systems like the 
Active Bat [2] or the Ubisense [3], that provide geometric position indoors, can be 
used to complement some of these limitations or to support applications in different 
scenarios. WiFi networks are also becoming available in an increasing number of 
places and can also be used for positioning a mobile user [4]. 
Geometric positioning, by it-self, described by a point in a 2D or 3D geometric 
referential (such as a pair of coordinates in the WGS-84 datum) are of little use for the 

310 
F. Meneses and A. Moreira 
majority of applications. More important is the location of the mobile user, often 
represented as a symbolic descriptor in a symbolic referential. Common examples 
include the name of streets, as used in car navigation systems, or the ZIP code used in 
many location-based services that provide nearby restaurants, monuments, etc. We 
therefore distinguish position from location, where position is mostly a geometric 
description in a relative (e.g. Active Bat) or absolute (e.g. WGS-84) referential, and 
where location is mostly the human-readable name of a place. 
Going from position to location requires a transformation operation. In GPS based 
systems, this transformation is mostly based on maps. In WiFi based positioning, this 
transformation can rely on local databases or on network services, but are dependent 
on the availability of universal geo-referenced databases (e.g. the Herecast service 
that transforms WiFi radio signatures into locations [5]). The Active Badge system [6] 
provides a similar transformation by converting infrared beacons into the 
identification of a room inside a building. 
The context of a person, even considering position and location, is however more 
than a simple pair of coordinates or the name of a place – with whom a person is, the 
type of place, the current state of that place (e.g. crowded or not), or how often a 
person visits that place are equally important characteristics of his/her context. Thus, 
the user’s context is much more than the context of the device from where the 
position or location is acquired. 
Cellular mobile networks, such as GSM, also provide the functionalities from 
where the user’s position can be retrieved, with the advantage that the mobile phones 
are well integrated in everyday life and are turned on most of the time. Given the 
additional fact that GSM networks are ubiquitous, a mobile phone can be exploited as 
a good proxy to capture the context of a mobile user. The positioning data can be even 
more valuable for location- and context-aware applications if high level contextual 
information about the users could be inferred from it. 
In this article we describe a solution that enables the semantic enrichment of the 
user’s context based on: 
a) the ubiquity of the GSM infrastructure; 
b) the scope of a device (the mobile phone) that, given its typical use, has a great 
potential to better model the user’s context; 
c) a personalized space model built from the self spatial-temporal behaviour of the 
user, and; 
d) the use of inference techniques to estimate high-level parameters used in the 
user’s context modelling (the familiarity level with the current place). 
In sections 2 and 3 we present a mathematical model that exploits the GSM cellID 
information to identify the places visited by the users and to compute a familiarity 
index for each of those places. The collection of identified places, together with the 
corresponding familiarity indexes, constitutes a personal symbolic space model that 
can be used by context-aware applications. Among others, this model may be used by 
applications in the security area (e.g. by taking special actions when a person is 
visiting a place for the first time) or in recommendation systems (e.g. by avoiding to 
disturb a user with local data when he/she is well aware of the neighbourhood). 

 
Building a Personal Symbolic Space Model from GSM CellID Positioning Data 
311 
The process used to build the proposed model relies only on the GSM cellID of the 
cells visited by the phone, dispenses any previous knowledge of the network topology 
and does not require any human intervention.  
Section 4 discusses the obtained results and the validity of the proposed model by 
comparing the inferred information with a ground truth represented by GPS traces and 
detailed diaries collected by a few persons while in their daily activities. Section 5 
presents the related work while the last section presents the conclusions. 
The work here described complements previous preliminary results that are 
described in [7], mostly by providing an extended validation of the created models. 
2   Positioning Model 
A GSM network is a telecommunications cellular network, whose radio infrastructure 
is built around a set of base stations usually installed on high places like the top of 
buildings or in towers spread over the terrain in order to cover a certain geographic 
area. 
A GSM network is made of cells which have different shapes and sizes. The 
coverage area of a cell is defined by the cell configuration and by the morphology of 
that area, which may create cells with several square kilometres of size or with just a 
few thousand of square meters. Each cell can be configured to cover a wide area, a 
tail-shaped area or just a small area for example in a city centre.  
In GSM networks the cells ensure the radio communications between the mobile 
terminal and the operator network core. A handset is linked to a cell, and by 
exchanging data with the cell base station it is able to receive and place phone calls 
and to transmit data. Because each cell supports only a limited number of channels, in 
some places, it is necessary to install more than one cell. By overlapping several cells 
it is possible to increase the network capacity inside a certain area. 
CellID positioning provides the handset location in a symbolic referential. A map 
with the position of the base stations easily allows the conversion of the cellID into 
the geographic position of the handset. However, network operators do not make their 
network configuration and base stations’ positions available to the public. Mapping 
each cell manually could be a solution but it would require a big effort and the new 
cells or changes in the network topology would have to be tracked in order to keep the 
service data updated. 
On the other hand, in fact, people on their living, deal with location in a symbolic 
referential. “Home”, “office”, “friends’ house” is the way people express their 
location and not by “I’m at 41º24’N, 8º31’W”. Computers, otherwise, do not have 
knowledge about the link existent between the locations and deal better with absolute 
locations expressed by coordinates. If John is in someone’s house then we know he is 
near the supermarket because we are aware of both places locations. However, 
computers do not have the notion of being “near” or “far”. They need to know the 
exact location to compute the distance between two places and have a definition of 
“near” as something that is at a distance less than a certain value. “Near” is also 
something that varies from people to people and is dependent on the context: it can be 
near if someone is travelling by car but far on foot.  

312 
F. Meneses and A. Moreira 
The positioning model adopted in this work is based on the detection of movement 
within the symbolic space model of the GSM cells. By detecting motion, a personal 
symbolic space model can be progressively created with the places where a user is 
seen to stay for a certain amount of time. This section describes how the movement of 
terminals is detected and how the proposed approach was validated using GPS 
positioning data. 
2.1   Movement Tracking 
When turned on a GSM handset is linked to a cell – the active cell – which is selected 
among the set of cells available in that place. In order to support the growing number 
of GSM users, the operators keep installing more cells and in almost all populated 
areas it is possible to find more than one cell covering the same area. The handset 
changes from one cell to another - changes the active cell - when fluctuation occurs in 
the radio signal level, due to fading or due to movement of the handset. Thus, the 
movement of a handset cannot be assumed from the change in the cellID. 
When a terminal is stopped in a certain place, the temporal sequence of active cells 
is limited to the set of cells that cover the terminal’s position. For different places the 
frequency with which a cell appears in the temporal sequence of active cells is 
different (cell fingerprint). When the user moves, we observe a bigger variation 
(faster and within a bigger set of cells) of the active cell in each moment. 
We created the Mobility Distance and Mobility Index metrics that allow us to infer 
the user motion, analysing the changes in the serving cell and the amount of time 
spent on each cell. For these, a Cellular Positioning Record (CPR) is defined as the 
identification of the GSM cell being used and the time spent in the cell, represented 
by {cellID, LAC, MNC, MCC, stayTime}. 
Each operator, in each country is identified by a Mobile Network Code (MNC) and 
a Mobile Country Code (MCC) assigned centrally by the ITU - International 
Telecommunication Union. For managing proposes, each operator can divide its 
network into small geographic areas, identifying each one by a Location Area Code 
(LAC). A LAC is made of several cells and each cell is identifiable by its cellID. 
Mobility Distance represents the distance between two CPRs. If two records 
represent the same cell then the user has not moved or moved just inside the cell area 
and the Mobility Distance is zero. If the records represent two different cells then the 
Mobility Distance is the sum of the inverse of the time spent in each cell (bigger time 
intervals represent smaller distances). Equation 1 represents the Mobility Distance, 
where time(r) is the time spent in cell r. 
 
⎪⎩
⎪⎨
⎧
≠
+
=
=
2
1
2
1
2
1
2
1
)
(
1
)
(
1
0
)
,
(
r
r
if
r
time
r
time
r
r
if
r
r
stance
MobilityDi
 
(1) 
 
When the user is moving fast the time spent in a place is small. Mobility Index 
(equation 2) considers that speed is proportionally inverse to the time spent in a place 
and therefore is an estimate of the level of mobility of a user. Given a list of records, 
Mobility Index is the sum of the Mobility Distance between each record and all the 
previous ones. 

 
Building a Personal Symbolic Space Model from GSM CellID Positioning Data 
313 
(
) ∑∑
=
=
=
n
i
i
j
n
stance
MobilityDi
r
dex
MobilityIn
1
1
j
i
..
1
)
r,
(r
 
(2) 
 
The user mobility level can be estimated by calculating the Mobility Index over a 
pre-defined period of time (timeMin). The Mobility Index is calculated over the set of 
records collected from the current time instant back to timeMin seconds ago. For a set 
of consecutive records it is possible to create a sliding window and calculate the 
Mobility Index as the time goes by.  
The Mobility Index varies according to the size of the sliding window (timeMin 
value), being higher when calculated for larger values of the timeMin parameter. In 
[7] we show that smaller sliding windows allow to detect fast the beginning and end 
of user movements. In order to detect the user movements, we define a threshold 
based on the sliding window size. The user is considered in motion if the Mobility 
Index is above the pre-defined threshold. 
2.2   Movement Tracking Validation 
The validation of how well the Mobility Index models the mobility of a user was 
performed by comparing this metric with a similar metric obtained from GPS real 
data. 
During a week, one user collected GPS positions simultaneously with the GSM 
cellID data (CPRs). From the GPS data the user was considered in motion when the 
calculated velocity was higher than 3km/h. From the GSM data the user motion was 
obtained from the periods of time when the Mobility Index was higher than a 
predefined threshold. We then calculated the correlation between the motion periods 
of time from the GPS data and from the GSM data as the percentage of time they 
were coincident. 
Using the correlation value we estimated the optimum values for the window size 
(timeMin) and the threshold value used in the Mobility Index. Figure 1 shows the 
cumulative correlation for a sliding window of 10 minutes and a threshold of 6. 
 
1
2
3
4
5
6
7
8
9
10
0.7
0.75
0.8
0.85
0.9
0.95
1
Time HdaysL
Correlation
 
 
Fig. 1. Correlation between the mobility periods calculated from GPS data and from the 
Mobility Index 

314 
F. Meneses and A. Moreira 
The correlation increases or decreases when GPS and GSM movement detection 
do match or do not match. The results present in figure 1 show a good correlation 
between the moving periods calculated from the GPS data and from the Mobility 
Index. Good correlation was achieved for a threshold value between 0.3 and 9. 
However, lower values reduce slightly the correlation but increase the number of 
situations where the movements of the user were correctly detected. 
3   Personal Symbolic Space Model 
3.1   Place Definition 
The Mobility Index allows us to detect when the user starts and stops moving. At the 
moment the user starts moving, we characterize the previously visited place by 
creating a fingerprint with the list of cells observed during the time the user was not 
moving. 
A fingerprint is the list of cells observed during the stay in a place and the time 
percentage stayed in each one, the total time spent on that place and a timestamp. A 
fingerprint is represented by: 
 
FP={{{cellID1, timePercentage1},{cellID2, timePercentage2},…,{cellIDk, 
timePercentagek}}, totaltime, timeStamp} . 
 
Every time a user visits a place a new fingerprint is created, using the data 
collected during the time the user spent on that place. However, a user can visit the 
same place many times, leading to different fingerprints for the same place. It is 
therefore necessary to identify which fingerprints represent the same place. 
The user’s mobile phone uses one of the available cells and changes, in an 
unpredicted way, among the available cells. Thus, several visits to the same place 
result in fingerprints where the time percentage associated to each cell is different. 
Although fingerprints for the same place may be different, they have some 
similarity. They are created with the cells used during the visit to a place and, thereby, 
are composed by the same cells or by a subset of the available cells. Clustering 
similar fingerprints allows us to create a cluster for each place, composed of the 
similar fingerprints. A cluster has the same structure as a fingerprint but it is created 
by the union of similar fingerprints instead of being created from the raw data 
acquired by the phone. 
To cluster similar fingerprints is necessary to compute the similarity between 
fingerprints. To measure the distance between two different fingerprints two functions 
are used: an adaptation of the Hamming Distance and a Similarity Distance function.  
Based on an adaptation of the Hamming Distance we created a distance function 
(HDistance in equation 3) that measures the similarity between two fingerprints. For a 
cell present in both fingerprints we calculate the absolute difference between the 
percentages of time spent in that cell in each fingerprint. If the user spends the same 
amount of time in both fingerprints then there is no difference and the calculated 
value is zero. For a cell present in just one of the fingerprints, it is considered zero 
percent in the other one. In the adapted Hamming Distance function the similarity 
between two fingerprints is half of the sum of distance between each cell present in 

 
Building a Personal Symbolic Space Model from GSM CellID Positioning Data 
315 
both fingerprints. For two completely different fingerprints the calculated value is one 
and for two perfectly equal fingerprints the calculated distance is zero. 
 
{
}{
}
{
}
{
}
{
}
{
}{
}
{
}
{
}
{
}
{
} {
} {
}
B
m
B
B
A
n
A
A
k
c
B
B
B
B
m
B
B
B
B
B
A
A
A
n
A
n
A
A
A
A
A
c
c
c
c
c
c
c
c
c
CL
ts
tt
p
c
p
c
p
c
FP
ts
tt
p
c
p
c
p
c
FP
m
,...,
,
,...,
,
,...,
,
,
,
,
,...,
,
,
,
,
,
,
,...,
,
,
,
2
1
2
1
1
2
2
1
1
2
2
1
1
∪
=
=
=
=
 
(
)
2
,
1
B
A
∑
=
−
=
k
i
B
i
A
i
p
p
FP
FP
HDistance
 
(3) 
 
Equation 3 shows the adapted Hamming Distance, where 
x
ic is the ith cell of a 
fingerprint (FPX), ttx is the total time spent on the fingerprint and tsx is a timestamp. 
For each cell (
x
ic ) there is a percentage (
x
ip ) of the total time of the fingerprint that 
was spent on that cell. Joining all the distinct cells present in both fingerprints creates 
list of cells (CL) with a length of k elements.  
Experiences with real data shows that two different visits of the same user to the 
same place may result in two different fingerprints for which the Hamming Distance 
is high. This is the result of a user’s mobile phone in one visit being most of the time 
in a certain cell while in another visit it uses mainly other cell. Thus, the use of the 
same set of cells, regarding the percentage of time spent in each one, can also be used 
as an indicator of visiting the same place. The Similarity Distance function measures 
the distance between a fingerprint and a cluster by calculating the percentage of cells 
of the fingerprint, with a percentage of time equal or superior of 1%, that are present 
in a cluster (or other fingerprint). The Similarity Distance returns a value between 0 
(if all cells are in the cluster) and a maximum of 1 (if all cells are not present). 
The distance between two fingerprints (FPDistance) is computed considering the 
Hamming Distance and the Similarity Distance (equation 4). 
 
(
)
))
,
(
5.0
(
))
,
(
5.0
(
,
B
A
B
A
B
A
FP
FP
Distance
Similarity
FP
FP
HDistance
FP
FP
FPDistance
×
+
×
=
 
(4) 
 
Joining two fingerprints creates a cluster in which the total time spent on the 
cluster is the sum of the time spent on both fingerprints, and the timestamp is the 
oldest of the timestamps. The cells of the cluster is a list of all the cells present in both 
fingerprints having a percentage of time calculated proportionally between the time 
spent in each fingerprint and the total time spent on both fingerprints. A cluster has 
the same structure as a fingerprint and, therefore, subsequent fingerprints can easily 
be joined to a cluster. 
A new cluster algorithm has been developed to cluster fingerprints, because data to 
be clustered is symbolic (the fingerprints) and because the clusters are to be 
discovered/created in real time. Many clustering algorithms demand that they have all 
the data available to start doing the clustering process, which invalidates the use in 
this system because data must be clustered while it is being collected by the mobile 
phone, and without previous knowledge about the total number of records that will be 
collected. Moreover, the total number of clusters to be created is not known in 
advance which invalidates also the use of many existent clustering algorithms like the 
k-means. The number of clusters is the number of places visited by the user which 

316 
F. Meneses and A. Moreira 
cannot be pre-determined, varying from one person to another and growing as time 
goes by and as the user moves and visits new areas.  
The first fingerprint represents the first place visited by the user and leads to the 
first cluster. After that, for each new fingerprint the similarity between the fingerprint 
and every existent cluster is calculated. Because a cluster has the same structure of a 
fingerprint, the Fingerprint Distance (FPDistance in equation 4) is used to calculate 
the similarity/distance between a fingerprint and a cluster.  
If the similarity (FPDistance) between the fingerprint and the most similar cluster 
is smaller than a pre-defined threshold then the fingerprint is joined to the cluster. An 
algorithm parameter defines the minimum similarity between a cluster and a 
fingerprint in order to join them.  
Another algorithm parameter defines the maximum number of clusters 
(kMaxNumberClusters) that can be created1. If a fingerprint cannot be joined to an 
existent cluster (it is not similar enough to any existent cluster) and the maximum 
number of clusters has not yet been reached then a new cluster is created. After the 
maximum number of clusters has been reached the fingerprint can be used to create a 
new cluster that will replace an existent one, or discarded. To determine if a cluster 
should be removed and replaced by a new one it was created a Fingerprint to Cluster 
Importance Ratio (FCIR in equation 5) that measures the relative importance of a 
fingerprint in relation to a cluster. If the FCIR is smaller than one for all the clusters 
then the fingerprint is discarded. If the importance ratio is higher than one for one or 
more clusters then the cluster with the highest ratio is replaced by the fingerprint. 
 
(
)
(
)
(
)
(
)
(
)
( )
(
)
cl
tt
KldgIdx
fp
cl
Age
FgIdx
fp
tt
KldgIdx
fp
cl
×
=
,
,
FCIR
 
(5) 
 
This process allows old and spurious clusters to be replaced by new and more 
relevant clusters. 
Clusters recently changed correspond to places recently visited by the user, and 
clusters where the user spent more time are also more valuable than places not visited 
for a long time or visited for a short period of time. The FCIR uses the Forget Index 
(FgIdx) that is calculated using the time elapse since the last fingerprint was added to 
the cluster (relative age) and the Knowledge Index (KldgIdx) that is calculated using 
the total time spent on a cluster (these functions are detailed in [7]).  
To measure how much a person forgets about a place after a certain amount of time 
without going there is something that cannot be done easily. There is no mathematical 
equation that can be applied, universally, to everybody. People’s memory is 
something that is very personal, varying as a result of many factors. Besides, as time 
goes by, places also change, with the construction of new buildings, new roads, etc. 
and some places change faster than others. 
The knowledge of a place cannot also be measured by a simple equation that is 
universally applied to everybody. Some persons tend to know a place better and faster 
than others. Besides, the knowledge about a place can be influenced by a number of 
factors like the mean of transportation used, the purpose of the visit or the time of the 
day.  
                                                           
1 This parameter exists only to limit the amount of memory to be used in the mobile device. 

 
Building a Personal Symbolic Space Model from GSM CellID Positioning Data 
317 
3.2   Familiarity Index  
An important place is usually visited more often by a user and the user spends more 
time there (like home or his office). However, places not visited for a long period of 
time can still be important in some circumstances. For example, it can be important to 
know that the user is visiting a place which has not been visited for a long time. 
Because a cluster is a small data structure then it is possible to keep a high number of 
clusters in a small device with limited storage capacity. 
The familiarity level with a certain place varies according to the total time spent in 
that place and with the time elapsed since the user visited a place for the last time. 
Equation 6 shows the function created to model the familiarity level that a user has 
with a cluster. 
 
( )
( )
( )
cl
FgIdx
cl
KldgIdx
cl
FmIdx
×
=
 
(6) 
4   Results 
In this section we show the results achieved by the presented algorithm. We show 
how data was collected and we overlap the achieved results with the ground truth to 
check the quality of the proposed solution. 
4.1   Data Collection 
An application was developed to collect the GSM cellID data. It runs on a Symbian 
mobile phone and creates a log file with the timestamp and the {cellID, LAC, MNC, 
MCC} data. It checks the cellID every eight seconds and records it on the log file 
whenever it changes. Considering that a phone can stay for several hours in the same 
cell, the application creates a record on the file every fifteen minutes even if the cell 
does not change. This way it is possible to distinguish between when the mobile 
phone is linked for a long period of time to the same cell, from the fact that 
application is not being executed (no data is being collected). 
Three different users collected data during several consecutive weeks and, 
simultaneously, manually recorded their movements. User A lives in the centre of a 
big city and works in a smaller village, located 35 km away, travelling by car between 
both cities. During data collection time most of his movements were made inside 
those two places and travelling between them. User B lives in an average size city and 
works in the University campus located in that same city. His movements are mainly 
inside this city, including visits to supermarkets, to the children’s schools, to relatives’ 
houses, etc. User C works in the same University campus but lives in the countryside, 
in a rural area, 17 kilometres away from the University. Data was collected for a 
period of several consecutive weeks and contains data for highly populated areas 
where there are numerous GSM cells and also data collected in rural areas, where the 
average size of a cell is larger and the number of available cells in each place is 
reduced.  
To manually record their movements, each user used a diary to register at what 
time he/she arrived at a place and what time he/she left that place. This manually 

318 
F. Meneses and A. Moreira 
recorded movement data (user diary) acts as ground truth and allows assessement of 
the quality of the results achieved, allowing the comparison of the results achieved by 
the proposed algorithms with the reality. 
Although data was collected into a log file and later processed according to the 
algorithms described in the previous section, we must emphasize that all records were 
processed in the order they were created. Thus, the achieved results are exactly the 
same as would be achieved if the records were processed in real time. 
4.2   Clustering Process Parameters 
The clustering process, described in section 4.1, is dependent on two variables: the 
maximum number clusters that can be created and the similarity threshold that must 
be achieved by a fingerprint to be joined to an existent cluster. 
Defining the maximum number of clusters as a high number does not cause any 
constraints to the system, neither does it influences the performance or the quality of 
the results. A cluster is a very simple data structure that occupies, on average, less 
than 350 bytes (the exact size occupied by each cluster depends on the number of 
cells and the number of visits to the place). We defined the limit to 100 clusters but 
this limit was not reached by any of our tests users. 
If the similarity threshold is defined to a very high number then only very similar 
fingerprints are joined to existing clusters resulting in different clusters for the same 
place. Good results were achieved joined fingerprints that have up to 65% of 
similarity. This threshold level makes the system create different clusters for different 
places (avoiding two places ending up in the same cluster) but, unfortunately, in some 
restricted circumstances, it creates more than one cluster for the same place (see 
results described in next section). 
4.3   Trial Users’ Results 
Table 1 summarizes the results obtained after processing the data with the algorithms 
presented in the previous sections. 
Although results achieved by the trial users show that the proposed algorithms 
detect most of the places, a more detailed analysis of the achieved results can explain 
many of the errors. 
User A has been in only four different places: his home, the workplace, a village 
3km away from his workplace and into a friend’s house. The two visits made to the 
friend’s house took between 5 and 10 minutes and were not detected by the system 
because they were too short. Some of the 6 visits made to the village located near his 
 
Table 1. Results achieved after processing all records collected during several weeks 
 
User A 
User B 
User C 
Places visited by the user 
4 
 
27 
 
29 
 
Places detected 
3 
(16 clusters) 
19 
(21 clusters) 
22 
(30 clusters) 
Places not detected 
1 
 
8 
 
7 
 
False positives 
1 cluster 
4 clusters 
6 clusters 
 

 
Building a Personal Symbolic Space Model from GSM CellID Positioning Data 
319 
workplace were not detected (also short duration) or were detected but the 
fingerprints were joined to clusters that represent the workplace.  
User A lives in the very centre of a big city and while at home the system detected 
19 different cells. Such a high number of cells and the long periods of time spent at 
home made the system create a total of 11 different clusters just for one place. 
However, 7 of those clusters were made with only one or two fingerprints and each 
one has less than an hour of total time. These clusters represent less than 1.2% of the 
total time of 442 hours spent by the user at home. 
User A travels 35 km between his house and his workplace every day by car, using 
the same road that crosses a rural area. For the user A the most common error was the 
creation of fingerprints that do not correspond to any place visited by the user (false 
positives). However, analysing the clustering process results shows that false positive 
errors occur always when the user is travelling between his house and the workplace. 
The trip is made through a rural area, lasts 40 minutes and crosses two valleys. The 
relatively slow speed through a low populated area causes the user to be inside the 
same reduced set of GSM cells for several minutes. Thus, the mobility index 
decreases below the threshold level creating a fingerprint. The clustering process 
grouped all these fingerprints in the same cluster, which would represent the “driving 
through place”. Indeed, travelling everyday along the same route makes the user to 
know the road very well and thus be familiar with the surrounding area. User B and C 
false positives also result from travelling in relatively low speed (traffic jam, narrow 
and twisted roads inside a natural park, etc). 
Trial users B and C spend most of the days at the university campus, which is 
located in a city with thousands of students. To support the communications for a big 
number of students and population around the campus, the mobile network operators 
have installed a considerable number of cells. Thus, the set of cells available in 
nearby places are not the same, but not different enough to distinguish those places.  
Trial user B has family members that live 500 meters away from the University 
and went to a restaurant located 350 meters away from the campus. Those very near 
geographic places not always were distinguished from the campus.  
Similarly, user C errors result mostly from a one week trip to a foreign country to 
participate on a conference and from visits made to a friend’s house located 700 
meters away from the University. While away, the conference took place in a hotel 
located 500 meters away from the one where the user was hosted. So short distance, 
made the system misclassify some of the visits to those places. 
Some places were visited only once while others were visited a number of times. 
Examples of places often visited are the users’ home and workplace. Table 2 
summarizes the results achieved showing the number of places that had all the visits 
correctly detected, the number of places that had some of the visits detected and 
number of visits made to places that did not have any visit detected by the system. 
The system is capable of detecting more than 75% of the places and 50% or more 
of all places visited by the user were always correctly detected. Results show that 
85% of the visits made to all the places were detected by the system. Short duration 
visits and places geographically very near are the main flaw of the proposed solution. 
 

320 
F. Meneses and A. Moreira 
Table 2. Results achieved considering the visits made to each place 
2 places 
53 visits 
53 detected visits 
100% 
1 place 
6 visits 
3 detected visits 
50% 
User A 
1 place 
3 visits 
0 detected visits 
0% 
18 places 
58 visits 
58 detected visits 
100% 
3 places 
71 visits 
62 detected visits 
87% 
User B 
6 places 
9 visits 
0 detected visits 
0% 
12 places 
18 visits 
18 detected visits 
100% 
10 places 
133 visits 
116 detected visits 
87% 
User C 
7 places 
11 visits 
0 detected visits 
0% 
 
Figure 2 shows the user agenda overlaid with the results of the movement tracking 
process and recognizer results. The gray areas represent the time spent on a place, 
according to the user B agenda. The solid line (over the gray area) show the user 
movement tracking process: it is at the high level when the user is classified as being 
visiting a place and is at the low level when it classifies the user as moving. 
The lines under each row represent the results of the recognizing process: wider 
lines represent the moments the system correctly identifies the user location and the 
thinner line represents the moments when the system identified a cluster that does not 
represent the user’s current location.  
The figure shows that tracking and recognizer processes works well, compared 
with the ground truth provided by the user agenda.  
Visits to a place cannot be detected if their duration is not long enough to allow the 
Mobility Index to decrease below the threshold. When the user arrives at a place the 
sliding window contain cells used by the user’s phone before he arrives at that place. 
 
0
6
12
18
24
Hours
Day 1
Day 2
Day 3
Day 4
Day 5
Day 6
Day 7
e
t
a
D
 
Fig. 2. User agenda overlapped with the tracking and recognizer processed results 
 

 
Building a Personal Symbolic Space Model from GSM CellID Positioning Data 
321 
Only after being in a place for several minutes the system will start to use the same 
limited set of cells and the Mobility Index will eventually decrease below the 
threshold level. Thus, the movement tracking process usually detects the user as being 
visiting a place only a few minutes after the timestamp recorded in the user agenda. 
A place is only recognized by the system after finishing the first visit to a place 
(the cluster is created after the visit). The recognizer is never capable of identifying a 
place when the user visits a place for the first time (any of the existent clusters 
represent that place) or it incorrectly identifies a place that is usually not far from the 
real place (sometimes places geographically near have similar clusters because of the 
use of the same subset of cells). 
4.4   Using the Personal Symbolic Space Model (PSSM) 
Knowing if a user is visiting a place or moving between places can be valuable 
information to some applications. However, we also compute a familiarity index to 
each place which is based on the time spent in a place and on the amount of time 
elapsed since the last visit.  
The recognizer is the process that identifies the user location, identifying the 
cluster in which the user is located. It searches the current fingerprint within the 
clusters and identifies the user location by selecting the cluster nearest to the current 
fingerprint. It uses the same measuring process that is used in the clustering process, 
including the maximum distance that can be measured between the fingerprint and a 
cluster. When the fingerprint is far from all the clusters, the user is in an unidentified 
place. 
As more time is spent in a place, bigger are the chances to correctly identify the 
cluster that represents that place because as time goes by the fingerprint changes and 
represents the place better. When a user arrives at a place the fingerprint is made with 
the first set of cells. As the user spends more time in a place, the fingerprint will 
contain more data collected in that place. 
Although we clustered the fingerprints based on their proximity, in some cases the 
system creates more than one cluster for one place. It happens in places where a very 
large number of cells are available. Trial user A lives in the centre of a big city and 
for his home we detected at least 8 cells. For user B and C, clients of two different 
network operators, we detected 6 and 8 different cells respectively just for the 
university campus area, where they spend most of their days. 
If the system creates two clusters for a place it will influence the familiarity index 
which is calculated for each cluster individually. In the cases where the user spends 
50% of the time in each cluster the familiarity index is always half of the real number. 
In cases where the user spends most of the time in one of the clusters the familiarity 
index is near the expected value for the cluster where the user spends more time (80% 
of time in a cluster means 80% of the real value) and far from the real value for the 
cluster that is «visited» rarely.  
Figure 3a and 3b show the Familiarity Index computed for trial user B, starting 
from the beginning of the learning process. Figure 3a presents the Familiarity Index 
with the current place, computed as the position data was being collected and 
processed. The graph value varied between zero (when the user is in motion or 
visiting a place for the first time) and the familiarity index calculated for the visited 
 

322 
F. Meneses and A. Moreira 
0
5
10
15
20
25
30
Time
Hin days L
0
10
20
30
40
50
60
y
t
i
r
a
i
l
i
m
a
F
l
e
v
e
L
H%L
   
0
5
10
15
20
25
30
Time HdaysL
2
5
10
20
50
ytiraili
m
a
F
x
e
d
nI
A
B
 
Fig. 3. Familiarity index with the places visited and familiarity index calculated for the 
different clusters 
place/cluster. The general trend of the Familiarity Index is to grow because as time 
goes by the total amount of time spent by the user in some places is also growing and 
thus the familiarity index for those places also grows. 
Figure 3b shows the Familiarity Index calculate for each cluster. The most familiar 
place (line A) is a cluster that represents the user’s home. The second most familiar 
place (line b) is the workplace which is the second place where the user spent more 
time. 
5   Related Work 
Hopefully, one day, location systems will be ubiquitous, accurate and have 
availability to be used everywhere by everybody. Meanwhile, many authors seek for 
the best possible solution with the existent technology.   
Mobile telephone positioning technologies have evolved a lot in the last years. The 
wireless E911 program [8] was one of the biggest motivations for the deployment of 
new and accurate positioning technologies, demanding that network operators must 
provide the location of a handset in case of emergency with a precision of 300 meters 
in most cases. This E911 initiative promoted the development of accurate location 
services but unfortunately the operators do not make it available to allow creation of 
location-based services and applications. 
A number of research projects used GSM networks to acquire the user’s position. 
BeaconPrint [9] uses WiFi and GSM radio fingerprints, collected at someone’s 
mobile device, to automatically learn the places they go and detect when they return 
to those places. BeaconPrint is up to 90% accurate in learning and recognizing places. 
Although it achieves good results it is a multi-sensor data approach, which makes it 
difficult to apply to real users.  
Place Lab [10] is a software approach providing low-cost, easy-to-use positioning 
for location-enhanced computing applications. It uses radio beacons sensed from 
WiFi access points, GSM networks and fixed Bluetooth devices to estimate the 
device’s position. It uses also a GPS receiver whenever it is available. When the GPS 
receiver is not available, the radio sensed beacons are converted into geographic 
points using a database that maps each beacon ID to a geographic point. The Place 
Lab approach is dependent on the existence of a database or a GPS receiver to build 
the user own database and provides the user location as a geographic point. Place Lab 

 
Building a Personal Symbolic Space Model from GSM CellID Positioning Data 
323 
goal is to bootstrap the dissemination of location-based services and applications by 
creating a platform that would use whatever technology the user may have. By 
placing the algorithms proposed in this paper over Place Lab platform it is possible to 
enhance the user’s context description, by adding the familiarity level for the current 
location for the user. 
In [11] the goal is to detect the places that people visit in their everyday lives using 
only client-based GSM phones. The achieved results show that it is possible to locate 
users inside a building, with considerable precision, just using client-based GSM 
position. However, results were achieved using the radio signal level and also the list 
of nearby cells and this kind of data is not available in many handsets, reducing the 
potential number of users. Similarly, results achieved by [12], [13] and [14] were only 
possible by computing data that include radio signal level from the current cell and 
from other nearby cells (used by the GSM standard). The solution described in this 
paper may not reach the same accuracy but has the advantage of using only cellID 
that can be read from a wide number of handsets, creating a more universal solution, 
and with enough accuracy to trace most of the places visited by a user.  
In [15], Laasonen presents a framework for recognizing personal locations in 
cellular networks, using cell-based location data. Although this approach was able to 
identify visited places it is not a pervasive system, demanding the user to give a name 
to each place and it is not able to distinguish between more important places and those 
that were visited occasionally. The ContextPhone [16], that relies on Lassonen work 
[15], show that mobile phones are well suited for context-aware computing. 
6   Conclusions 
Be able to acquire the user location everywhere, without using a specific equipment 
or relying on specific sensors network is fundamental to bootstrap the dissemination 
of location-based services and applications. The proposed solution, based on the 
cellID of the GSM network, has the advantage of being built over a widely 
disseminated device and not being dependent on any network service. It is a generic 
solution that allows the user to build a personal symbolic referential and use it to 
provide high-level context information to context-aware applications. 
The proposed solution can run on limited devices, like mobile phones, demanding 
a small quantity of memory to store data and very low CPU capabilities to execute the 
algorithms.  The clustering process and the familiarity index produce valuable data 
that can be used by a number of different kinds of applications in the selection of 
services and data or to adapt the application behaviour according to the user 
familiarity level with the surrounding place. 
References 
1. National Space-Based Positioning, Navigation, and Timing Coordination Office. Global 
Positioning System (2007), http://www.gps.gov/  
2. Want, R., et al.: The Active Badge Location System. In: ACM Transactions on 
Information Systems, pp. 91–102 (1992) 
 

324 
F. Meneses and A. Moreira 
3. Ubisense Ltd. Ubisense - Precise Real-time Location (2007), 
  http://www.ubisense.net/ 
4. LaMarca, A., et al.: Place Lab: Device Positioning Using Radio Beacons in the Wild. In: 
Gellersen, H.-W., Want, R., Schmidt, A. (eds.) PERVASIVE 2005. LNCS, vol. 3468, pp. 
116–133. Springer, Heidelberg (2005) 
5. Herecast. Herecast: WiFi Location-Based Services/802.11 Positioning System (2007), 
http://www.herecast.com/ 
6. Harter, A., Hopper, A.: A distributed location system for the active office. In: IEEE 
Network, pp. 62–70 (1994) 
7. Meneses, F., Moreira, A.: Using GSM CellID positioning for place discovering. In: Locare 
2006: First Workshop on Location Based Services for Health Care in the International 
Conference on Pervasive Computing Technologies for Healthcare, Innsbruck, Austria 
(2006) 
8. FCC - Federal Communications Commission. Enhanced 911 - Wireless Services (2006), 
http://www.fcc.gov/911/enhanced/ 
9. Hightower, J., et al.: Learning and Recognizing the Places We Go. In: Beigl, M., Intille, 
S.S., Rekimoto, J., Tokuda, H. (eds.) UbiComp 2005. LNCS, vol. 3660, pp. 159–176. 
Springer, Heidelberg (2005) 
10. Place Lab. Place Lab web site (2006), http://www.placelab.org 
11. Varshavsky, A., et al.: Are GSM phones THE solution for localization? In: 7th IEEE 
Workshop on Mobile Computing Systems and Applications (HotMobile 2006). IEEE 
Computer Society, Washington (2006) 
12. Otsason, V., et al.: Accurate GSM Indoor Localization. In: Beigl, M., Intille, S.S., 
Rekimoto, J., Tokuda, H. (eds.) UbiComp 2005. LNCS, vol. 3660, pp. 141–158. Springer, 
Heidelberg (2005) 
13. Sohn, T., et al.: Mobility Detection Using Everyday GSM Traces. In: Dourish, P., Friday, 
A. (eds.) UbiComp 2006. LNCS, vol. 4206, pp. 212–224. Springer, Heidelberg (2006) 
14. Chen, M., et al.: Practical Metropolitan-Scale Positioning for GSM Phones. In: Dourish, 
P., Friday, A. (eds.) UbiComp 2006. LNCS, vol. 4206, pp. 225–242. Springer, Heidelberg 
(2006) 
15. Laasonen, K., Raento, M., Toivonen, H.: Adaptive On-Device Location Recognition. In: 
Ferscha, A., Mattern, F. (eds.) PERVASIVE 2004. LNCS, vol. 3001, pp. 287–304. 
Springer, Heidelberg (2004) 
16. Raento, M., et al.: ContextPhone: A Prototyping Platform for Context-Aware Mobile 
Applications. In: IEEE Pervasive Computing, pp. 51–59 (2005) 
 
 

Chapar: A Cross-Layer Overlay Event System for
MANETs
Amir R. Khakpour and Isabelle Demeure
Ecole Nationale Sup´erieure des T´el´ecommunications (TELECOM ParisTech)
46, rue Barrault, 75634 Paris Cedex 13, France
{amir.khakpour,isabelle.demeure}@telecom-paristech.fr
Abstract. In this paper, we present Chapar, an event system designed for
mobile ad hoc networks that supports the publish-subscribe model as well as
point-to-point and point-to-multipoint message sending. Chapar supports event
persistency to resist transient disconnections and network partitioning. Following
a cross-layer approach, Chapar is designed as an overlay network that uses the
Multipoint Relays (MPRs) deﬁned in OLSR as distributed brokers, and uses the
OLSR routing table to disseminate the events. It therefore beneﬁts from the way
OLSR handles topology changes. The implementation performance is promising
in the sense that no extra signaling is generated by mobility support and the gen-
erated overlay trafﬁc is considerably less than the underlying routing protocol.
1
Introduction
A Mobile Ad hoc NETwork (MANET)[1] is a self-conﬁguring network of mobile
nodes connected by wireless links. The nodes are mobile therefore the network topol-
ogy changes over time. This infrastructureless nature nominate MANETs to be used
for a set of new spontaneous services in domains such as military, ﬁre ﬁghting and
gaming. However, MANETs are prone to frequent network disconnections and to net-
work partitioning. Also, nodes may enter and leave the network and the network should
be able to dynamically adapt to these ﬂuctuating conditions. In these conditions, the
use of the traditional client-server model that relies on the server accessibility should
be avoided; symmetrical (distributed) models using asynchronous communications that
are more robust to transient disconnections should be preferred. Hence, asynchronous
publish/subscribe systems receive a great deal of attention in the realm of MANETs.
Contribution. In this paper, we present “Chapar”1, a novel event system designed for
MANETs that uses OLSR routing protocol [2] for event dissemination. OLSR is often
said to have limited scalability, but it is well adapted to the small size ad hoc networks
with relatively high trafﬁc dissemination that we target in our project. Chapar supports
the publish/subscribe model, where no destination address(es) is assigned to the event
(the system delivers the events to the correponding events subscribers). It further sup-
ports point-to-point and point-to-multipoint message dispatching. In order to address
1 Chapar is the ﬁrst Mail and Message Delivery Service known in the History. It belonged to
the Persian Empire hundred years B.C. [Reference: Allyn Huntzinger, “Persians in the Bible”,
Global Commission Inc, 2004.]
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 325–339, 2009.
c⃝Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

326
A.R. Khakpour and I. Demeure
transient disconnections and network partitioning, Chapar supports event persistency
(an event may be kept in replicated data containers until its expiration time elapses or
it is delivered to all its subscribers). Contrary to other event systems [3,4] that rely on a
single broker to handle event publications and subscriptions, Chapar uses a distributed
approach to implement the event broker. This is to avoid having a single point of failure
and a performance bottleneck (the single broker and its links to neighbors)[10]. Follow-
ing a cross-layer approach, Chapar operates as an overlay network that uses the OLSR
Multipoint Relays (MPRs) as brokers, and uses the OLSR routing table to disseminate
the events. Using the underlying routing layer enables us to constitute the virtual mul-
ticast trees (with no additional signaling) to deliver events instead of using expensive
unicast communication and ﬂooding which is not scalable.
In addition, we show that Chapar yields good performance in particular, because it
causes considerably less network overhead than other solutions. We also investigate
the event system trafﬁc in different network density conditions and compare the results
with OLSR routing messages trafﬁc. The proposed system considers node mobility and
changes in network topology is handled by OLSR routing protocol.
Organization. The remainder of this paper is organized as follows. In Section 2, we
review the requirements for the event layer that were speciﬁed within the Framework
of the Transhumance project and that we addressed in the design of the Chapar system.
Section 3 provides an overview on related work. We then present the data structures and
algorithms used in Chapar, in Section 4. Section 5 is dedicated to Chapar evaluation and
performance analysis. We conclude in Section 6.
2
Requirements and Deﬁnitions
Chapar is an event management system designed and implemented as part of the French
National Research Agency (ANR) funded Transhumance Project [5], [6].
In this scheme, the event system is required to support the point-to-point, point-
to-multipoint (group communication), publish-subscribe system and a combination of
these. Following the record-based event model [7], the events are deﬁned as composite
messages including several attributes describing the event content. The subscription is
done accordingly, by expressing the interest into these attributes or topics [8].
In Chapar, the events are either destroyed after they are dispatched (real-time events),
or stored in the broker network for their lifetime (memorized events). The memorized
events are notiﬁed not only to the subscribers who are absent at the event publishing
time and eventually come back, but also to the subscribers who subscribed in the event
lifetime period (time decoupling support).
The underlying routing protocol is OLSR, a proactive and table-driven protocol. The
OLSR routing table held by each node contains the list of nodes available in the net-
work along with their corresponding next hop nodes through which the node is ac-
cessible. OLSR is a link-state routing protocol using a set of nodes called Multipoint
Relays(MPRs) to connect nodes to their 2-hop neighbors. In OLSR, nodes periodically
send HELLO messages to their neighbors to advertise their link status. The HELLO
messages also contain the nodes’ neighbor set. This is used by neighbors to determine
their own MPR set and also to identify if they are MPR or not. Each MPR periodically

Chapar: A Cross-Layer Overlay Event System for MANETs
327
generates and sends Topology Control (TC) messages to all of the nodes. It contains
the list of nodes that the TC sender has chosen as its MPR (MPR Selector Set (MS)).
Finally, each node is able to calculate its routing table based on received TC messages.
3
Related Work
There are many related work regarding event systems and Message-Oriented Middle-
ware (MOM) [23,24,25]; in this section, we focus on publish/subscribe systems for
mobile networks such as JEDI [7] and the systems presented in [9], [10],[11], and [12].
We identify three strategies for event dissemination in distributed publish-subscribe
systems: (1) event forwarding, (2) subscription forwarding and (3) hierarchical for-
warding. In event forwarding (aka message ﬂooding), an event is forwarded through an
acyclic graph, called dispatching tree, to all nodes in the network. Those whose sub-
scription matches the event are notiﬁed and others just forward the event to the next
hop in the tree. Although, this strategy supports mobility (if the tree is modiﬁed by the
new node location), it is not scalable. With this strategy, it would be impossible to store
events in order to support subscribers that may be unreachable at publishing time. This
makes the event system unreliable when network partitioning occurs.
In subscription forwarding, a subscriber sends a subscription message to all its neigh-
bors and each node holds a table including the subscriptions that it received. Once an
event is published, it is checked against all the subscriptions and then is forwarded to the
neighbor who has forwarded or generated the corresponding subscription. This strategy
is employed by ﬁlter-based event routing [13] which is used by many content-based
event systems such as SIENA [14] and the systems described in [8], [15], and [16].
Since the subscription tables are based on the nodes’ neighbors, these protocols cannot
support mobility and frequent network topology changes. To cope with this problem,
some mobility extensions are provided such as the MoveInMaster and MoveOutMaster
operations that allow SIENA to build a new multicast tree and reroute the events to the
displaced nodes.
Finally in the hierarchical forwarding strategy, events are notiﬁed based on a rooted
tree topology. In this tree which includes all of the nodes in the network, the subscrip-
tion messages are forwarded upwards the “root” in the dispatching tree and then routed
downwards to the subscribers. This strategy is used by JEDI to forward events from
publisher to subscriber(s). In JEDI, nodes called Dispatching Servers (DSs) are orga-
nized in a tree and forward subscription messages to the root. When a published event
is handed over to the root, each DS veriﬁes if any of their descendants has subscribed
to this event and forwards them a copy if appropriate. Handling mobility, similar to the
SIENA mobility extension, JEDI provides MoveIn and MoveOut operations.
However, to the best of our knowledge, none of the proposed publish-subscribe sys-
tems provide a comprehensive solution addressing network partitioning which is quite
likely to happen especially in sparse networks. In addition, the aforementioned publish-
subscribe systems mainly support push-based [17] publish-subscribe system (except for
JEDI) and they are not able to store events to be pulled later by the subscribers.

328
A.R. Khakpour and I. Demeure
Some other related works concerns applications and services on mobile ad hoc net-
works using overlay network with cross-layer approach (using routing layer informa-
tion). Delmastro et al. [18] proposed CrossROAD, an API on P2P system on mobile
networks using the OLSR routing information as the underlying layer to handle mobil-
ity and achieve better performance in terms of reducing the overhead of the overlay data
structures. Similar work presented in [19] uses the same concept for group communica-
tion within nodes in a mobile ad hoc network. Chapar however is quite different. We are
proposing a publish/subscribe system building upon the underlying routing protocol.
4
Chapar Data Structures and Algorithms
The main idea behind Chapar is to use the OLSR MPRs as the event system Broker
Nodes (BN). OLSR is therefore used to support mobility, to enable self-conﬁguration
of the broker network, to provide one-hop publishing and notiﬁcation, and to build the
virtual multicast trees from publisher to subscriber(s).
In this section, we ﬁrst present the main data structures used in Chapar. We then
explain the main algorithms in the event system.
4.1
Tables and Data Structures
Chapar uses three main data structures: the Node Vector (NV) and two tables main-
tained by the broker nodes (BNs) namely Filter Mapping Table (FMT) and Memorized
Event Table (MET). We describe each data structure in turn.
The Nodes Vector (NV) is a bitmap where each bit represents one node in the net-
work. The basic assumption is that the nodes addresses follow an ordering such that
we are able to deﬁne a hash function HNV () : {a1, a2, · · · , aN} →[1..N] to map the
address to a speciﬁc bit index (ﬁgure 1(a)). For instance, if we assign an IPv4 class C
address pool for at most (N = 255) nodes in the network, the HNV () is deﬁned to
return the last byte of the node address.
If identifying HNV () is not feasible due to randomness of the nodes addresses, an
alternative solutions called Bloom Filters [22] could be used. However, this solution
is costly, because to have negligible false positive error, an 8 times longer bit string
bitmap is required. Moreover, using logical operations to calculate the list of nodes for
each step may not be possible any more [20].
N bits
FID
SNV
0xFFFFFFFFFFFFFF
0 1  1  0 0  1 0  1 0
N bits
…
HNV (a1) HNV (a2)
HNV (aN)
Pointer to the event
USNV
Expiration Time
0xFFFFFF
12:12:12
0 1 0 0 0 0 0 1 0
(b) FMT Table Sample
(a) N bits Nodes Vector
0 1 0 0 0 0 0 1 0
(c) MET Table Sample
Fig. 1. Chapar’s different data structures examples

Chapar: A Cross-Layer Overlay Event System for MANETs
329
Each broker node (BNs) maintains a Filter Mapping Table (FMT) to keep the sub-
scription information. In this table, each ﬁlter is mapped to the list of the subscribers
represented by an NV called Subscribers Nodes Vector (SNV). The second table main-
tained by BNs is the Memorized Event Table (MET) that holds the memorized messages
with their corresponding Unavailable Subscribers Nodes Vector (USNV). Figure 1(b)
and 1(c) show examples of FMT and MET tables respectively.
The FMT table is modiﬁed upon the arrival of subscriptions and un-subscription
messages, whereas the MET table is updated upon the arrival of a memorized event and
when an absent subscriber returns (USNV purging).
4.2
Chapar Functions and Algorithms
In this section, we present the main functions of the publish/subscribe system and their
underlying algorithms.
Subscription/Un-subscription: Each subscriber dispatches the subscription message
to one BN in its neighborhood. In case it is already the BN, the subscription message is
looped back to itself.
A subscriber deﬁnes a ﬁlter by expressing its interest in some event attributes. Each
subscription message contains a Filter ID (FID). The FID is a hash string that is calcu-
lated as concatenation of hash result of each attribute. Note that if the subscriber does
not express its interest in a speciﬁc attribute, the hash result for that attribute is 0.
Once a BN (or MPR) receives the subscription message, it adds the subscription to
its FMT table, and forwards it to all neighbor broker nodes. This process is repeated
until all the BNs update their FMT table by the new subscription. The un-subscription
messages are treated similarly, yet has inverse effect on the FMT table.
Figure 2 demonstrates an example of an event and subscription/unsubscription mes-
sages in Transhumance middleware. This structure follows the record-based event sys-
tems where different ﬁelds of the event describe its characteristics. However, the ﬁelds
may differ for each application. In fact the only required ﬁelds in the event are the Event
Destination NV (EDNV) ﬁeld that represents the event destination nodes, and the event
class ﬂags by which different types of the events are distinguished. The required ﬁelds
The Event Structure
Sender ID Size
Sender ID
Subject Size
(supports string
Subject
Content Size
(supports content
Content
Destination NV (EDNV)
The Subscription/Unsubsctiption
Group ID
Lifetime
(supports string
with length up to 32 
characters)
(supports content
with size up to 
512MB)
Event Class
Event Type
Subscriber ID
Filter ID
p
p
Message Structure
Event Type
Event Class Code
(4bits: 0 Æ 3)
4:with content flag
5:persistant flag
6:with lifetime flag
0  0 0 0 0  0 0  0
Group ID
The event class for subscription
7:encrypted flag
0  0 0 1 0  0 0 0
The event class for unsubscription
Fig. 2. The examples of the event and subscription/unsubscription message in Transhumance

330
A.R. Khakpour and I. Demeure
Algorithm 1. Lookup Process Algorithm
1: for each ﬁlter in FMT do
2:
if (corresponding FID) ∧(EID) ̸= (corresponding FID) then
3:
Filter’s corresponding SNV ∨= the ﬁlter SNV;
{(it is to calculate the union of all of the SNVs of those ﬁlters matched against the
incoming event)}
4:
end if
5: end for
6: EDNV = ASNV = SNV ∧ANV {(ASNV= Available Subscribers Nodes Vector and
ANV= Available Nodes Vector)}
for the subscription/unsubscription messages are the event type, the ﬁlter ID, and sub-
scriber ID that are used for updating the FMT.
Publishing and Notiﬁcation: Publishing and notiﬁcation are one-hop communication.
The publisher sends an event to one of its BNs. The event is then notiﬁed by the BN to
its adjacent subscriber. If the publisher or the subscriber is a BN, the publishing and the
notiﬁcation are done through self-publishing and self-notiﬁcation, respectively.
The real-time events are disseminated through a multicast tree from the publisher
BN to the subscribers, whereas the memorized events are ﬂooded in the BN network up
to all BNs receive them and keep them in their MET until their lifetime is elapsed.
The broker network functionality description: Once the published event is received
by the ﬁrst BN, it is looked up in the FMT (Lookup Process) to specify who the event’s
subscribers are. Then the event EDNV ﬁeld is set by the subscribers who are avail-
able for notiﬁcation. The event subsequently is ready to be notiﬁed (Event Notiﬁcation
Process) or to be forwarded to other BNs (Event Multicasting Process).
Lookup Process: Upon the arrival of an event coming from the publisher, the Event
ID (EID) is calculated by concatenating the hash result of the event attributes (same as
FID). The hash result of each attribute is compared using Lookup Process Algorithm 1.
In the lookup algorithm, we are investigating whether the event (or event ID) matched
against any ﬁlter ID or not. We basically verify if (FID[i] ∧EID ==FID[i]) is held or
not for each record (ﬁlter) i in FMT. Using this algorithm, the false positive errors are
possible, however, the more bits we assign for the hash results, the less the probability
of false positives. False positive is calculated using the following formula2:
Pfalse positive =
n−1

i=1
n
i

· (2i −1)
22n
(1)
where n denotes the hash result length for each attribute. Formula (1) shows that we
can increase n to minimize the false positive error. For example, the false positive error
is reduced to ≈0.01 when n = 16. Note that we assume that the hash function is
uniformly random.
2 The formula detail justiﬁcation and proof is available in [20].

Chapar: A Cross-Layer Overlay Event System for MANETs
331
Taking advantage of FID and EID deﬁnition, Chapar supports dissemination of the
encrypted events. Since the subscription in all types of the publish/subscribe systems
is based on the value of different attributes, publish/subscribe systems usually do not
support security features and encrypted events. However, in Chapar the encrypted event
could be sent along with its EID so the ﬁrst BN does not need to calculate the EID
from event attributes and proceeds with the Lookup Process by the EID embedded in
the event.
Note that this Lookup Algorithm is designed based on the project speciﬁcation. How-
ever, other ﬁlters and ﬁlter matching algorithms can be used to determine the SNV.
Event Notiﬁcation: The event notiﬁcation is a one-hop event delivery. Thus, the BN
who has received the event checks whether the event’s subscriber(s) is itself, and/or is
one of its non-BN neighbors. Let NSNV represents the set of nodes that are notiﬁed in
current step, HNV represents the broker Host NV, NNV represents the set of neighbors,
and BNV represents the preceding broker who sent the event. Therefore,
NSNV = EDNV ∧(HNV ∨(NNV ⊕BNV ))
(2)
When the NSNV nodes are notiﬁed, the new EDNV is calculated as follows:
EDNVnew = EDNVold ⊕NSNV
(3)
The next step, Event Multicasting, proceeds with new EDNV.
The event notiﬁcation for memorized events follows the same procedure for the
nodes that are available at the publishing time. For the absent nodes, the BN MET
table periodically calculates the new NSNV to notify the absent subscribers that are
present in its neighborhood. The NSNV is calculated as follows:
NSNV = USNV ∧NNV
(4)
And subsequently the new USNV is:
NSNVnew = USNVold ⊕NSNV
(5)
To avoid event duplication for a returned absent node that may frequently connect
to different BNs, a periodic MET purging process is also required. Thus, the USNV
should be recalculated as follows based on the available nodes in the network (ANV):
USNVnew = USNVold ⊕(USNVold ∧ANV )
(6)
Event multicasting and ﬂooding: Memorized events, similar to the subscription mes-
sages, are ﬂooded in the BN network. Every BN stores a copy of the event in its MET
table. However, the real-time events are delivered through a virtual multicast tree to the
subscribers and the events are destroyed as soon as they are delivered.
As it is mentioned, once an event is published and forwarded to the publisher BN, the
event EDNV ﬁeld is set after the lookup process. The BN then execute the Event Notiﬁ-
cation process to notify the events to its neighbors that are in fact the event subscribers.
It then recalculates the EDNV using (3). In this stage, the BN requires to forward the

332
A.R. Khakpour and I. Demeure
S
P
S
FID
SNV
0xFB010050
…
00110011
//m=8 nodes
3
2
7
RNV
=00100010
RNV7Æ1=00100000
S
1
3
4
Dest
Next
Hops
1
7
2
2
2
1
3
7
3
FMT of node 4
RNV4Æ7=00100010
S
5
6
OLSR Routing Table for node 4
3
7
3
5
6
2
6
6
1
7
7
1
RNV4Æ6=00001000
Publishing
Multicasting
Notification
BN nodes (MPRs)
// node 4 is the root in multicast rooted tree (first MPR connected to publisher)
ANV    =  11111110
//node 8 is missing
SNV    =  00101011
ASNV  =  00101010
//ASNV = ANV & SNV
NNV4 =  01000110     NNV7 = 11010000       NNV6
= 10011000       NNV1
=  00100110 
BNV4    =  00000110      BNV7     = 10010000      BNV6      = 10010000       BNV1     =  00000110
NSNV4=  00000000      NSNV7 = 00000010      NSNV6 = 00001000       NSNV1 =  00100000
Fig. 3. Chapar real-time event publishing, multicasting and notiﬁcation based on the routing table
event to the rest of the BNs for event delivery. Thus, it groups the subscribers based
on their corresponding next-hop node (using the BN routing table). For each group, the
EDNV is changed to the group members represented by an RNV (Residual NV) and
is handed over to the corresponding next-hop. This procedure is repeated on each BN
until the event is notiﬁed to all available subscribers. In fact in this paradigm, for each
event a rooted multicast tree is built where each group represents a branch in the tree.
This multicasting scheme supports mobility, as the multicast tree is built for each pub-
lished event virtually using the current routing table. Note that we assume that the event
propagation delay is less than the network mobility rate.
Figure 3 shows how an event (real-time event) published by node 2 is multicasted
to the subscribers. In this example, an event is received by node 4 (node 2 MPR or
BN). Node 4 looks up the event in its FMT table. Once the event ID is matched to a
ﬁlter(s) it derives the SNV to know who are the subscribers (nodes 3, 5, 7, and 8). Node
4 then calculates ASNV, using its routing table to identify the hosts who are subscribers
and available at the moment (nodes 3, 5, and 7). The calculated ASNV is set as the
event destination (EDNV). Node 4 then calculates NSNV, the set of subscribers using
formula (2) that it can notify before it forwards the event to next hop (NSNV in this
stage contains no node). Node 4 then calculates the new EDNV (3) (in this example
same as the old EDNV) and groups the subscribers into two groups: one group is the
set of subscribers that can be reached by node 7 (nodes 3 and 7), and one group is the
set of subscribers that can be reached by node 6 (node 5). For each group, the EDNV
is changed to RNV and the event is sent to next corresponding hop. This process is
repeated in node 7 and 6. Finally the event is notiﬁed to all subscribers.
For the events with the designated destination (i.e., point-to-point (P2P) and point-to-
multipoint (P2MP)), the root of the multicast tree is the event publisher node. However,
for the multimode (combination of the pub/sub system, P2P and P2MP), the tree root is
the event publisher broker node, but the primitive EDNV is calculated as follows:

Chapar: A Cross-Layer Overlay Event System for MANETs
333
EDNVnew = EDNVoriginal ∨ASNV
(7)
Special cases: As pointed out, the OLSR MPRs are used to form the broker network.
However, in some network topologies, there could be no MPR in the network. For in-
stance, a full-mesh network where all of the nodes are adjacent and can communicate
through one-hop communication does not have any MPR. Also in some cases, the bro-
ker network is reduced to one node; this should be avoided since the availability of at
least two brokers for redundancy purposes is one of the basic requirements. Thus, for
these special cases which are detectable by all nodes thanks to nodes’ routing table [20],
we need an election mechanism to assign some nodes as broker. In the election mech-
anism we proposed for the Transhumance Project, nodes (at least two) with the lowest
index in the ANV are appointed broker nodes. Another special case which is likely to
happen addresses the single nodes send subscription messages or dispatch memorized
events while they are secluded from the network temporarily. Because the middleware
is not concerned with node connection status, these messages and events will be lost.
To avoid this loss, when nodes do not contain any host in their routing table (single-
node status), they are automatically appointed BN and perform self-subscription and
self-publishing and save the information in their local tables. When they reconnect to
the network, the FMT and MET changes are propagated to rest of the nodes through the
Table Consistency Check Process.
Table Consistency Check: Due to network partitioning and node transient disconnec-
tions, divergence of the nodes’ tables is inevitable. To maintain table consistency, a
periodic process is used to synchronize the content of the tables of different BNs.
In this process, each BN calculates the hash of each table and dispatches it to its ad-
jacent BNs. The incoming hash strings including MET hash and FMT hash are checked
by the adjacent BN’s tables hash result, if MET hash is different, the receiver sends the
list of all MET records. On the other hand, if FMT hash is different, the receiver sends
the list of hash of each FMT record. Then, the node compares the received lists with its
own tables, if it has a record which is not included in the lists, for memorized message
the event will be resent, and for FMT, the complete FMT record will be sent.
The repetition of such process helps BNs to complete each other’s tables by infor-
mation they have and their adjacent BNs do not. Note that using hash in this process
provides us with a light signaling for table comparison.
The table consistency check induces some table false positive errors in FMT. These
false positive errors occur when one BN (node A) receives an unsubscription message
while another BN (node B) does not. In this case, the correct table should not include
that speciﬁc subscription. However, after table consistency check process, node A’s
FMT will update the node B’s FMT with an obsolete subscription. The probability of
this kind of table false positive errors depends on the size and the density of the network,
the likelihood of message loss, and the rate of dispatching unsubscription messages.
Nonetheless, this error has negligible impact on the performance of the event system in
which some events may be notiﬁed to some nodes which are not the actual subscribers.
Inheritance and Dismissal (Check-out Process): Following the self-conﬁguring goals,
we provide an inheritance function by which a non-BN node may retrieves the tables

334
A.R. Khakpour and I. Demeure
from one of its adjacent BNs while it is appointed as BN. On the other hand, when a
BN is dismissed, it drops the tables it has. However, there may be some information in
the tables that other BNs do not have. Hence, a Check-out process is required before
any table elimination. The Check-out process is done similarly to the table consistency
check to notify the network about the contents which is not available in adjacent BN.
Because of node mobility, nodes status is ﬂapping from MPR to non-MPR and vice
versa. This causes frequent and unnecessary inheritance and check-out processes that
should be avoided in networks with random mobility. Coping with this problem, after
the BN dismissal, the node waits for the Dismissal Transient Time (DTT) before it drops
the table. The DTT can be addressed also as the table expiration date. If the dismissed
BN is reassigned to BN during DTT, it will not drop the tables and will not ask for
new tables through inheritance process. The DTT should be determined according to
the node mobility rate, subscription/memorized events generation rate, and the level of
consistency expected from event system [20].
Instant Notiﬁcation (Pull-based Notiﬁcation): When a node subscribes to an event,
the subscription ﬁlter is matched against all the events in MET, and in case it matches
any of them, the node will be notiﬁed at once. Note that the notiﬁcation is a neighbor-
to-neighbor communication. Thus, the event notiﬁcation in this model does not cause
event duplication.
5
Chapar Evaluation and Performance Analysis
The main objective of the work presented in this paper is to create a reliable self-
conﬁguring event system resilient enough to network partitioning and node mobility.
The resource awareness of the protocol is also important, since it is implemented in mo-
bile nodes (PDAs) with limited power and bandwidth resources. Chapar is programmed
and implemented as the event module of the Transhumance middleware on Nokia 770
[28]. The middleware including the event system is available on SourceForge 3 under
LGPL licence and it was tested successfully [6,20]. An experiment with a game involv-
ing 8 users has clearly shown the efﬁciency of the persistent event system [21].
In this section, we discuss the system functionality and present preliminary perfor-
mance evaluation. As the simulation tools, we used NS2 [27] with UM-OLSR [26]
package for supporting the underlaying OLSR routing protocol. The detail of the simu-
lation speciﬁcations are shown in Figure 4.
5.1
Functionality Analysis
Since Chapar uses the OLSR routing tables to build a real-time multicast tree in order
to deliver the published event to subscribers, the notiﬁcation is done regardless of node
location and movement. Network partitioning/mergingand node frequent disconnection
are also properly handled using Table Consistency Check, Inheritance, and Check-out
Process (They are explicitly investigated in [20]).
3 http://sourceforge.net/projects/transhumance

Chapar: A Cross-Layer Overlay Event System for MANETs
335
Simulation Parameters
Simulation Speciﬁcations
Tool: NS-2.28 + UM-OLSR [27]
Duration: 3600s
Simulation time slot (T): 30s
Size: variable
Network Speciﬁcations
Number of nodes: 40
Network routing protocol: OLSR (RFC3626)
TC interval=5s, HELLO interval=2s
Radio-propagation model: Two Ray Ground
Antenna: OmniDirectional
Node Speciﬁcations
MAC type: 802.11
Queue type and length: Drop-tail/Priority queue 50
Eﬀective coverage range (R): 250 m
Mobility Speciﬁcations
Mobility Model: Random
Speed: 1 m/s
Subscription: Almost constant (65B ≤size ≤70B)
PDF: Uniform
Traﬃc Speciﬁcations
Subscription rate: 6 subscription/minute (3 subs/T)
Memorized Messages: minimum: 94B, average: 362B,
PDF: log-normal
Memorized Events Rate: 2 event/minute (1 events/T)
Fig. 4. The simulation speciﬁcations
25
30
35
40
rofnodes
AverageNumberofMPRsandBrokerNodesVS.theNetwork
AreaDiameter
0
5
10
15
20
0
500
1000
1500
2000
2500
3000
Averagenumber
Diameter(m)
MPRs
BNs
Fig. 5. Average number of MPRs and BNs
Table 1. Desirable properties check list for different event system functionalities in Chapar
Orderedness
Consistency (avoiding event
duplication)
Completeness
Subscription
√
suffers from duplicated copies
in broker network
√
Real-time
Event
Publishing
√
√
√with some exceptions
Memorized
Event
Publishing
Event
reordering
(partially)
suffers from duplicated copies
in broker network and notiﬁ-
cation (partially)
√
The FMT and MET are replicated in each BN, and this redundancy prevents their
content from being lost. There are three desirable properties for redundant systems [10]
which are investigated in Chapar and shown in Table 1. Orderedness concerns the mes-
sage reordering in event systems. For some applications, it is important that the events
be notiﬁed in the same order they are published. Consistency addresses the message
duplication in the distributed system. And in completeness, the system is expected to be
as complete as the system with no replication.
5.2
Resource Awareness
The resource awareness is studied with respect to: memory usage, processes analysis,
and signaling and bandwidth allocation [20].
Memory usage concerns the size of the FMT and the MET tables on broker nodes.
First, using a subset of the nodes (the MPRs) as broker nodes reduces the number of
nodes whose memory is occupied by event system tables. Second, using the NV bitmap
and FID (a ﬁxed bitmap) minimizes the size of the FMT. For instance, if the number
of nodes is 40 and there are 100 available ﬁlters, the FMT table size is ≈1.5 KB.
The MET size mainly depends on the size of the events. Therefore, it is recommended
that the applications generate memorized messages with efﬁcient sizes and specify the
event lifetime value cautiously. To avoid overﬂows, tables sizes are bounded. Also, the

336
A.R. Khakpour and I. Demeure
memorized events are generated with some upper-bounds to minimize the impact of the
memorized messages on the event system. For instance, in Transhumance project, the
memorized event sizes could not exceeds 2KB and the MET table size is bounded to 50
entries [20]. The process analysis addresses to the CPU usage and power-awareness of
the system. All computations in Chapar are accomplished by simple logical operations
thanks to NVs and simple hash functions. In [20], we have shown that even the lookup
process which could be assumed as the heaviest procedure running on the system in-
volves a limited number of operations and are adapted to tiny mobile devices (for 40
nodes and 5 ﬁlter ID ﬁelds is less than 100 AND operations for each FMT entry).
Signaling and bandwidth allocation refer to network trafﬁc. Having minimum num-
ber of BNs is the key contribution in Chapar. It is important, since the number of BNs
identiﬁes not only the number the FMT and MET copies, but also the volume of the
subscription and memorized messages generated and forwarded in the network. Figure
5 shows that the number of MPRs and BNs increase when the network area diameter
grows and the network density declines. In dense networks (D < 450), there is no MPR
in the network (special case), thus two BNs will be elected. In the semi-dense network
(450 < D < 1000) the number of MPRs and BNs is the same and rises up to 45% of
the total nodes. These two areas are recommended working area sizes. In the third area,
the network experiences many network partitions and node seclusion. Thus, the number
of MPRs declines whereas the number of BN rises because of the several occurrences
of the special cases.
0
20
40
60
80
100
120
10
4
Traffic (B)
T
200mx200m (Diameter= 282.84m) − Full−Mesh Network 
0
20
40
60
80
100
120
10
4
Traffic (B)
T
400mx400m (Diameter= 565.68m) − Very Dense Network 
0
20
40
60
80
100
120
10
4
Traffic (B)
T
500mx500m (Diameter= 707.10m) − Dense Network
0
20
40
60
80
100
120
10
4
Traffic (B)
T
750mx750m (Diameter= 1060.66m) − Low Dense Network
0
20
40
60
80
100
120
10
4
Traffic (B)
T
1000mx1000m (Diameter= 1414.21m) − Low Sparse Network
0
20
40
60
80
100
120
10
4
Traffic (B)
T
1250mx1250m (Diameter= 1767.8 m) − Sparse Network
0
20
40
60
80
100
120
10
4
Traffic (B)
T
1500mx1500m (Diameter= 2121.3m) −  Very Sparse Network
0
20
40
60
80
100
120
10
4
Traffic (B)
T
2000mx2000m Diameter= 2828.4m) −  Very Sparse Network
TC
HELLO
Subscription
Memorized
Fig. 6. The OLSR routing and event system total trafﬁc in logarithmic scale in 120 time slots
(3600s) with different densities

Chapar: A Cross-Layer Overlay Event System for MANETs
337
3.00E+05
3.50E+05
4.00E+05
4.50E+05
5.00E+05
Bytes)
TheMeanValueoftheTrafficineachTimeSlot(T=30s)
MemorizedEvents
SubscriptionMessages
HELLOMessages
TCMessages
0.00E+00
5.00E+04
1.00E+05
1.50E+05
2.00E+05
2.50E+05
0
500
1000
1500
2000
2500
3000
Traffic(B
Diameter(m)
Fig. 7. The comparison between types of net-
work trafﬁc in different network densities
1.20E+04
1.40E+04
1.60E+04
1.80E+04
2.00E+04
s)
TheMeanValueoftheTrafficineachTimeSlot(T=30s)
MemorizedEvents
Subscription
DumbSubscription
DumbMemorizedEvents
0.00E+00
2.00E+03
4.00E+03
6.00E+03
8.00E+03
1.00E+04
0
500
1000
1500
2000
2500
3000
Traffic(Bytes
Diameter(m)
Fig. 8. Using MPRs as BNs VS using all nodes
as BN
Figure 6 is the result of one hour (120 × time slot(T )) simulation, of 40 nodes with
random mobility. As described in Figure 4, the subscription trafﬁc is generated at the
ﬁxed rate of 3 sub/T with uniformly random size (65B < sub size < 70B), whereas
the memorized event is created and dispatched in the ﬁxed rate of 1 (event/T) and ran-
dom size (with lognormal distribution) between minimum of 64B and average of 362B.
The lognormal trafﬁc distribution enable to show the seldom large memorized events
which is sent by some modules and applications. In fact, ﬁgure 6 demonstrates how the
number of MPRs and BNs may effect the amount of generated trafﬁc. Figure 7 (and
also 8) shows this difference more clearly. The average number of memorized mes-
sages when the network is sparse is almost twice more than the number of memorized
messages when the network is dense. Therefore, working on recommended area size
could be crucial in network performance. Indeed, Chapar satisﬁes the Transhumance’s
requirements quite well, since the goal in Transhumance is to support the middle-scales
ubiquitous ad hoc networks working in rural environment where users are not apart
from each other considerably.
Figure 7 also compares the subscription messages trafﬁc and memorized events traf-
ﬁc to OLSR messages. This ﬁgure clearly illustrates that the Chapar messages do not
add signiﬁcant trafﬁc to the network in comparison to the OLSR routing messages. We
have not shown the rest of event system trafﬁc measurements since they are really neg-
ligible in compare to the subscription and memorized events trafﬁc which should be
received by all nodes in the network. Nonetheless, more details can be found in [20].
Finally, we show the effectiveness of Chapar event system in reducing the number of
messages in the network. Figure 8 shows that using MPRs as BNs instead of using all
nodes as BNs can decrease the trafﬁc from 90% to 40% in the working area depending
on the network density and the number of MPRs.
Unfortunately, we are not able to compare Chapar with the mentioned related works,
because event systems are designed as middleware through which higher level appli-
cations may communicate. Thus, based on the system requirements and speciﬁcations,
event systems are different in most of the cases. Therefore, a comprehensive compar-
ison may not be feasible. Also, to the best of our knowledge there is no event system
working on the mobile ad hoc networks that fully supports all publish/subscribe system
decouplings. For instance, for time decoupling we use memorized messages with life

338
A.R. Khakpour and I. Demeure
time and replicated event container for Chapar, which is not supported by any of cur-
rent publish/subscribe systems. Moreover, the cross layer protocols are tightly bounded
to the underlying network layers, so the feasibility of proper comparison between the
cross-layer approaches and the independent ones is questionable.
6
Conclusion
In this paper, we have introduced Chapar, a novel event system designed for MANETs.
Chapar supports the publish-subscribe model as well as point-to-point and point-to-
multipoint message sending. Chapar uses a distributed reliable approach to implement
the event brokers. It provides consistent and reliable event dissemination in harsh mo-
bile environments. However, since Chapar is not dependent on any speciﬁc node and is
a ubiquitous event system, it could be implemented on stable homogeneous networks.
Chapar uses OLSR as an underlay network to propagate the events efﬁciently through
the network and support mobility and self-management. It is also robust to the network
partitioning and frequent topology changes thanks to Table Consistency Check, Inher-
itance, and Check-out Processes. We have shown that this protocol is light and well-
designed for mobile devices thanks to NVs and simple logical operations. The network
overhead of this protocol is also negligible compared to the OLSR routing messages.
Acknowledgment
The work presented in this paper was supported by the French National Research
Agency (ANR) funded Transhumance Project. We are thankful to Javier Hernando for
his support in Chapar implementation.
References
1. Chlamtac, I., Conti, M., Liu, J.: Mobile Ad hoc Networking: Imperatives and Challenges. Ad
Hoc Networks 1(1), 13–64 (2003)
2. Clausen, T., Jacquet, P.: Optimized Link State Routing Protocol. RFC 3626, Internet Engi-
neering Task Force (October 2003)
3. Hapner, M., Burridge, R., Sharma, R., Fiall, J., Stout, K.: Java Message Service. Sun Mi-
crosystems Inc., Santa Clara (2002)
4. OMG. CORBA Notiﬁcation Service Speciﬁcation. Object Management Group, Needham,
MA (August 2002)
5. Paroux, G., Martin, L., Nowalczyk, J., Demeure, I.: Transhumance: A power sensitive mid-
dleware for data sharing on mobile ad hoc networks. In: ASWN 2007, Santander, Spain (May
2007)
6. Transhumance Project web page,
http://www.infres.enst.fr/˜demeure/TRANSHUMANCE/\/index.html
7. Cugola, G., Di Nitto, E., Fuggetta, A.: The JEDI Event-Based Infrastructure and Its Appli-
cation to the Development of the OPSS WFMS. IEEE Tran. on Software Engineering 27(9),
827–850 (2001)
8. Eugster, P., Felber, P., Guerraoui, R., Kermarrec, A.: The many faces of publish/subscribe.
ACM Computing Surveys (CSUR) 35(2), 114–131 (2003)

Chapar: A Cross-Layer Overlay Event System for MANETs
339
9. Cugola, G., Murphy, A., Picco, G.: Content-based Publish-Subscribe in a Mobile Environ-
ment. In: Bellavista, P., Corradi, A. (eds.) Mobile Middleware, pp. 257–285. Auerbach Pub-
lications (2006)
10. Huang, Y., Garcia-Molina, H.: Publish/Subscribe in a mobile enviroment. In: Proc. of the
MobiDE 2001, Santa Barbara, CA, pp. 27–34 (May 2001)
11. Bacon, J., Moody, K., Bates, J., Hayton, R., Ma, C., McNeil, A., Seidel, O., Spiteri, M.:
Generic support for distributed applications. Computer 33(3), 68–76 (2000)
12. Fiege, L., Gartner, F., Kastenm, O., Zeidler, A.: Supporting Mobility in Content-Based Pub-
lish/Subscribe Middleware. In: Proc. of ACM/IFIP/USENIX Int. Middleware Conference
(Middleware 2003), Rio de Janeiro, Brazil, pp. 103–134 (June 2003)
13. Carzaniga, A., Rosenblum, D., Wolf, A.L.: Design and Evaluation of a Wide-Area Event
Notiﬁcation Service. ACM Tran. on Computer Systems (TOCS) 19(3), 332–383 (2001)
14. Cao, F., Singh, J.P.: Efﬁcient event routing in content-based publish-subscribe service net-
works. In: Proc. of IEEE INFOCOM 2004, Hong Kong, China (2004)
15. Banavar, G., Chandra, T., Mukherjee, B., Nagarajarao, J., Strom, R., Sturman, D.: An efﬁ-
cient multicast protocol for content-based publish-subscribe systems. In: Proc. ICDCS 1999
(1999)
16. Chand, R., Felber, P.: A Scalable Protocol for Content-Based Routing in Overlay Networks.
In: IEEE Int. Symposium on Network Computing and Applications (NCA 2003), Cambridge,
MA (April 2003)
17. Hauswirth, M., Jazayeri, M.: A component and communication model for push systems. In:
Proc. of the 7th European Software Engineering Conference, Toulouse, France, pp. 20–38
(September 1999)
18. Delmastro, F., Conti, M., Gregori, E.: P2P Common API for Structured Overlay Networks:
A Cross-Layer Extension. In: Proc. of MDC 2006, Niagara Falls, NY (June 2006)
19. Conti, M., Crowcroft, J., Delmastro, F., Passarella, A.: P2P Support for Group-
Communication Applications: a Cross-Layer Approach for MANET Environments. In:
Demo Session of INFOCOM 2006, Barcelona, Spain (April 2006)
20. Khakpour, A., Demeure, I.: Designing and Prototyping an Event-based Communication Sys-
tem on Mobile Ad Hoc Networks, Technical Report 2008D009, Ecole Nationale Sup´eure des
T´el´ecommunication (July 2008)
21. Demeure, I., Gent`es, A., Stuyck, J., Guyot-Mbodji, A., Martin, L.: Transhumance: a Plat-
form on a Mobile Ad hoc NETwork Challenging Collaborative Gaming. In: 1st International
Workshop on Collaborative Games (CoGames 2008), Irvine, CA, USA, May 19-23 (2008)
22. Bloom, B.H.: Space/time trade-offs in hash coding with allowable errors. Communications
of the ACM 13(7), 422–426 (1970)
23. Tran, P., Greenﬁeld, P., Gorton, I.: Behavior and Performance of Message-Oriented Middle-
ware Systems. In: Proc. of the ICDCS 2002, pp. 645–654 (2002)
24. Jung, D.: Design of MOBILE MOM: Message Oriented Middleware Service for Mobile
Computing. In: Proc. of the ICPP 1999, pp. 434–439 (1999)
25. Souto, E., Guimaraes, G., Vasconcelos, G.: A message-oriented middleware for sensor net-
works. In: Proc. of the MPAC 2004, vol. 77, pp. 127–134 (2004)
26. Ros, F.J.: Universidad de Murcia OLSR impelmentation for NS2,
http://masimum.dif.um.es/um-olsr/html/
27. NS2, The Network Simulator, http://www.isi.edu/nsnam/ns/
28. Nokia 770 Internet Tablet, Technical Speciﬁcations,
http://europe.nokia.com/A4145105

C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 340–351, 2009. 
© Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009 
Context Aware Multiparty Session Support for Adaptive 
Multicasting in Heterogeneous Mobile Networks 
Josephine Antoniou1, Christian Riede2, Filipe Cabral Pinto3, and Andreas Pitsillides1 
1 Comp. Science Dp., University of Cyprus,  
75 Kallipoleos str., P.O.Box 20537, CY-1678 Nicosia, Cyprus 
{josephin,andreas.pitsillides}@ucy.ac.cy 
2 Fraunhofer FOKUS, Next Generation Network Infrastructures, 
Kaiserin-Augusta-Allee 31, 10589 Berlin, Germany 
christian.riede@fokus.fraunhofer.de 
3 PT Inovação, SA, Rua Eng. José Ferreira Pinto Basto,  
3810 - 106 Aveiro, Portugal  
Filipe-c-pinto@ptinovacao.pt 
Abstract. The paper addresses the issue of achieving context-aware, adaptive 
multiparty sessions in a heterogeneous system by illustrating how to add elements 
of adaptivity and context-awareness to the session management functionality of 
such systems. The effective usage of situation/context information can lead to 
context-aware content casting, especially context-aware, adaptive multicasting. 
Therefore, regarding the multicast service, the key functionality of the enhanced 
session management is to create network subgroups based on network information 
as well as general user and environment context information to the extent that 
these are considered necessary for forming network-efficient groups, and in turn 
communicating the characteristics of these subgroups in the form of content 
stream descriptions to the media delivery function for obtaining the appropriate 
content for each subgroup. 
Keywords: session management, context, multicasting, heterogeneous mobile 
network, adaptivity. 
1   Introduction1 
Recent years, from about the early 2000s have been characterized by global 
broadband penetration, Fixed-Mobile-Convergence, Triple Play and content 
provisioning over All-IP networks, whether text, audio or video data. The Telco world 
is currently challenged by the competition with the Internet and their quick time-to-
market service provisioning. YouTube, Apple iTunes and social networking platforms 
like Facebook have impressively proven the dynamics of this new market led by the 
typical wired Internet services. Indeed, the Internet domain challenges the Telco’s 
                                                           
1 This work is funded by the ICT-2007-216462 C-CAST project. 

 
Context Aware Multiparty Session Support for Adaptive Multicasting 
341 
business models massively, now aiming to catch the Web 2.0 opportunities. However, 
the goal is not to fight the Internet but to use similar but Telco-enhanced assets in a 
greater extent, adding elements of adaptivity and context-awareness,  e.g. the user’s 
context information can lead to context-aware content casting, and for group-oriented 
services, context-aware, adaptive multicasting.  
Context, understood as sensed information that changes over time, has already led to 
some extent to service adaptivity in terms of recognizing and using simple context, e.g. 
location. Context may also include network state, location, weather or personal state. To 
allow for session adaptivity in specific services, such as multicasting addressed in this 
paper, it is key to use network context as well as user context to enhance the existing 
service adaptivity. Such enhancement would enable more efficient management of 
network resources while keeping the user satisfied throughout the multicast session. 
Context-aware multicasting is based on the creation of context awareness and the 
technology of mobile multicasting. There is a lot of ongoing research in context 
detection and sensing. Moreover, mobile multicasting technologies such as MBMS or 
eMBMS (evolved MBMS, based on LTE, with much higher bandwidth than MBMS) 
are already focused. What is interesting is the coupling of both, context detection and 
sensing, together with their management as a unified system. 
Session Manager is the entity in a Core Network architecture that manages all the 
user-to-content and, vice versa, the content-to-user relationships [7]. In fact, session 
management provides the necessary signaling to deliver a specific content to its 
consumers, handling different types of events regarding session control, specifically: 
session establishment, session renegotiation (upon a given trigger or change), session 
termination and session mobility. Session management thus participates in dynamic 
changes as for example switching between different content.  
Since session management is closely interlinked with media delivery, it is the 
responsible entity to ensure that the appropriate content is delivered to a given user and 
it acts as an intermediary platform, a middleware, between the content provider and the 
content consumer. It is thus the appropriate middleware to consider the coupling of the 
user context-awareness and the multicasting technology. This paper extends the session 
management functionality for multiparty sessions to consider context triggers in the 
creation, modification and teardown of sessions. With the proposed enhanced Session 
Manager, multiparty content distribution will be done in the most efficient way. 
The rest of the paper is as follows. Section 2 presents the motivation for this work 
including a description of how context is viewed in networking, a usage scenario, 
session management related work and open issues identified from a generic system 
model. Section 3 explores the proposed, adaptive, multiparty session management 
giving some requirements and providing a detailed description of how adaptivity is 
enabled in the proposed session management scheme, focusing only on multicasting 
as a service. Finally, Section 4 offers some conclusions. 
2   Motivation 
2.1   Context in Networking 
In the last years, the sensor area has been widely developed opening the doors to a 
world where everything is sensed. There are sensors for almost everything: movement 

342 
J. Antoniou et al. 
detectors, temperature measurements, raining detectors. The information made 
available by the sensors allows building models to be used by context-aware systems. 
The definition of context, in a broad sense, could be the set of information used to 
improve the efficiency of a system. Therefore, a context-aware system processes 
context information in order to perform its tasks in a more accurate way.  
Nowadays, there is already a link between context and mobile systems. A large 
number of services utilize user context information in order to deliver more accurate 
information to the end-users. Typical examples are location based services, such as 
“find the nearest pharmacy” or “where am I?” But more complex services are already 
planned. The use of mashups, i.e. the integration of simple services to give 
compound, more powerful ones, is useful to create innovative services linking 
different worlds making them personalized through the use of context information. 
An important use of context information is that it allows the creation of 
communities that are looking for the same information, making them appropriate 
candidates for the use of multicasting. Such examples could be: users inside a 
museum demanding the same informative content or people in the train station that 
need the same schedule information. Based on the users’ current situation, the mobile 
system requires mechanisms to create multiparty sessions to enable effective content 
delivery to users. For that, session management that supports the establishment of 
context aware multiparty sessions in a heterogeneous environment is needed 
So far, session management has been an autonomous process, well separated from 
the context, even for sessions carrying context-aware services. Certainly, session 
management has not been using context information for improving the connections of 
the multiparty sessions. An enhanced session management functionality, smart 
enough to select, for instance, the appropriate media coding for a set of users, or use 
environment noise measures to increase or decrease the audio quality, is proposed in 
this paper. The authors address this enhancement by using users’ situation 
information in order to provide more intelligent sessions for mobile communities.   
2.2   Adaptive Multicasting Service Scenario 
In the following scenario we illustrate how the eTourism and eAdvertisement 
industries may be enhanced, by offering context-aware, adaptive multicasting options 
to a mobile customer. Most of the available mobile applications are based on a pull 
transmission model where the unicast mode is used. Context-aware content delivery 
based on users’ needs and using multicast capabilities are currently not considered in 
the mobile network due to limited interaction with user environment and lack of 
content description. Taking context information into account, the mobile targeted 
advertisements for the user might create new revenues. 
The scenario’s main objective is the context-related content provision during a 
tourist stay. Alex is visiting Berlin and subscribes for a tourist service during his stay. 
When walking through the city, he passes by a lot of interesting sights. He has the 
option of viewing video clips about the sights (he has already indicated in his profile 
that he is interested in watching such videos). Alex is part of a group of users that 
have subscribed to the tourist service. At each tourist site that Alex visits he becomes 
part of the group of a subset of subscribed users that, due to their current location, will 
watch a particular film. The video is multicasted to each such group; context is 

 
Context Aware Multiparty Session Support for Adaptive Multicasting 
343 
location in this case. Alex and the co-located tourist group may be also informed of 
good restaurants and coffee-shops in the area. For this kind of information, context 
could be the time of day (e.g. lunch) and the current weather (e.g. propose a garden 
café only if it’s sunny). Furthermore, since Alex’s favorite food is pizza (indicated in 
profile) he gets a detailed list of pizza places, while other members of the group don’t. 
Profile information is thus used for adaptive multicasting.  
After Alex tries one of the nearby pizza places, he publishes recommendations and 
tags this content. The rest of the group is notified about the available multimedia 
contents which are created by Alex, one of the group members, as well as of contents 
by any professional or amateur content provider. According to the popularity of the 
content, several copies are distributed within network elements for further enquiries.  
Moving on to a different tourist site, Alex notices that the sunny sky is slowly 
replaced by grey clouds. At that point, he receives an advertisement on his mobile 
phone about umbrella shops nearby shortly before it starts to rain. Environmental 
information like weather forecast and also location information create context-aware 
space around the user. The advertisement clip is then delivered to the user in addition 
to some location information where to buy this umbrella (including maybe also a 
discount depending on the type of contract – premium vs. limited contract). Alex 
starts running towards the umbrella shop, and automatically the quality of the video 
he was watching was decreased by the system. This happened because the system has 
sufficient intelligence to know that a user moving is not able to completely enjoy high 
quality videos and thus the system achieves the saving of some resources. 
The tourist stay of Alex in Berlin has been enhanced by tourist information 
available “automatically” just by subscribing to the multicast service. He has received 
and offered content, sometimes personalized, about such locations as tourist sites, 
restaurants and coffee shops, by being made part of a multicast group that shared 
similar characteristics (e.g. location) and has subscribed to the service. Furthermore, 
Alex has received context-aware advertisement that has proved very helpful because 
it was immediately usable. Alex’s connection, i.e. his session, needs to be managed in 
an enhanced way to achieve the above scenario. The subsequent sections will describe 
in detail how such session management is achieved. 
2.3   Related Work 
There are currently a few initial solutions touching the session management issues we 
are facing. In the deliverables D4.x of EU FP6 C-MOBILE a converged, multi-bearer 
service architecture that supports broadcast and multicast services is defined. The 
architecture defined in C-MOBILE project already makes use of context information 
as input for the group creation. 
The work carried out in [1] addresses the impact of context, sensors and wireless 
networks in the telecommunications field. Several scenarios are proposed highlighting 
the possible synergies between the defined areas. 
The authors of [2] propose a Point-to-Multipoint session management scheme 
using Session Initiation Protocol in MPLS-based Next Generation Network service 
stratum. This scheme is simple and flexible to join, modify, and leave session for 
NGN multicast service. 

344 
J. Antoniou et al. 
Paper [3] proposes and develops a new mechanism that supports Web services 
session management by using SIP. This means adding session information in the 
SOAP header element and using SIP to manage the session state for Web services. 
The dissertation thesis of [4] forms a view on a group and session management 
system for collaborative applications. This thesis describes a system which provides 
designs of collaborative applications with group and session management functionality 
that can be used to easily build group communications. 
The paper [5] describes a framework for managing connections to mobile hosts in 
the Internet. The framework integrates the notions of quality of service management 
and mobility management and forms a base for overall session management. The 
work acts on IP level and covers mobility management of IP networked devices. The 
framework was designed with support for QoS management in mind and introduced a 
new semantic where open data streams are treated as being separate sessions. 
The approach of [6] is quite interesting for our issues as it exploits strategies 
involving the use of contextual information, strong process migration, context-
sensitive binding, and location agnostic communication protocols for as they call it 
“follow-me” sessions.  
2.4   Generic System Model and Open Issues 
System elements and their dependencies are identified in Fig.1. Identified are the 5 
key tasks to solve. This is not an architectural approach specifying core components 
but instead a general functional representation of the system, concentrating only on 
necessary system level functionalities. 
 
• 
Publishing & Discovery 
o 
The content provider needs to have an interface to the content management 
of the infrastructure to publish and announce available content. 
o 
The content management needs to define mechanisms to discover available 
content.  
• 
Sensing 
o 
The context management needs to define an interface for the global space to 
store sensed context information. 
• 
Triggering 
o 
The infrastructure needs to have mechanisms to invoke or trigger the content 
delivery to the end users (content consumer). 
o 
This mechanism is represented by the session management proposed in this 
paper. 
• 
Retrieving 
o 
The content delivery may obtain the available content either via pull 
mechanisms or the content provider pushes the content to the content 
delivery plane.  
• 
Relaying  
o 
The content delivery is relayed to the content consumer.  
o 
This is done via multicast in this paper. 
 
 

 
Context Aware Multiparty Session Support for Adaptive Multicasting 
345 
Content 
description
Content 1.4
Content 1.3
Content 1.2
Content 1.1
Content Manag. 
& Matching
Context Manag. 
& Reasoning
Global Space
Content Delivery 
& Storage
Content 
consuming
Publishing & 
Discovery 
triggering
sensing
relay
Push or pull
 
Fig. 1. Generic System model illustrating data flow between functional elements  
There are two key issues of context-aware, adaptive multicasting:  
(a) Context-to-content matching and,  
(b) Session handling based on context information. 
We consider issue (a) to be out of scope for the current paper, which concentrates 
on (b), the session enhancement. The generic system model of Fig.1 presents the data 
flow between the functional elements participating in a context-aware adaptive 
system and representing only the necessary functionalities. The model reflects both 
key issues, respectively in the system elements ‘Content Management & Matching’ 
and ‘Content Delivery & Storage’. The session management is the logical entity 
between these two elements named ‘triggering’ in Fig. 1. This triggering requires an 
enhanced functionality handling the content-to-user relationships, which must act not 
only on user but also on context input. We specify this functionality to be the Session 
Manager entity and the central theme of this paper 
3   Defining an Adaptive Multiparty Session Management 
3.1   Context-Aware Session Management Overview 
Session management is a core functionality of the context-aware, adaptive system. 
State-of-the-art includes several views on the topic, however, it does not address the 
participation of session management within a context-aware framework (apart from [6] 
which is more concentrating on ad-hoc networks) where the session management is 
required to handle context changes that act as triggers for session setup, renegotiation, 
termination or mobility. Such context could be identified as: (a) Network Context (e.g. 
available bandwidth), (b) Device Context (e.g. supported coding options) and (c) 
Environment Context (e.g. user preferred device per location). All these could 
effectively trigger a session to adapt. Specifically, we may summarize that context-
aware session management for adaptive multicasting must be able to support the 
following functionalities 
• 
Recognize a context trigger for session setup 
• 
Recognize a context trigger for session renegotiation 
• 
Recognize a context trigger for session termination 
• 
Recognize a context trigger for session mobility 
• 
Make additional requests for context when necessary to the appropriate 
functional entity 

346 
J. Antoniou et al. 
3.2   Technical Requirements 
With respect to Fig. 1 we move on to describe the main functionalities of the 
enhanced session management entity. The first requirement is to decide which type of 
context information is useful for session management. There is an infinite set of 
context data, from the network to the environment, and not all of them are useful for 
improving the session management functionality. Consequently, it is mandatory to 
narrow down the wide variety of and in turn, it is required to define ways to accept 
the selected context information, which can come from either the network or from the 
environment. 
The system is initially activated by a specific application, which supports context-
awareness. Such an application should trigger upon activation a subset of at least the 
environmental context. Once the application is activated, the Content Management & 
Matching will provide an identification of the participating group of users requesting 
a specific content. Session management will carry this group id to the Content 
Delivery & Storage entity and receive some information describing the specific 
content (e.g. media, codec, maximum bit rate). 
Based on this information the user group will be adapted based on the context of 
the users. The users in the group will be checked for common network characteristics 
(in a heterogeneous environment users in a group may not be served by the same 
access network). The decision of which network is selected for a specific user may 
affect the setup of the session, e.g. bandwidth limitations of the selected network may 
affect the selection of content coding. Therefore, the session management is notified 
upon a network change to renegotiate the session in question effectively. Furthermore, 
the session management may request the network information for a specific user for 
initial session setup.  
Other than the network change, session management needs to be able to accept 
triggers regarding additional environmental changes, or even be able to make request 
for user information like the user profile. Such information may include coding 
options supported by the user device (e.g. resolution, coding options supported) or 
even desired by the user based on user profiles and further information that have to do 
with the environment (e.g. user preferred device per location or even more dynamic 
information such as movement, proximity and others). Once the users can be 
characterized, the session management sets up a different session for each subset of 
users that demonstrate similar context characteristics. Each session for a specific sub-
group of users includes appropriate media attributes and it is sent back to the Content 
Delivery and Storage entity in order to receive the appropriate content.  
This is an important interface from a functional perspective as it needs to be clearly 
defined for the appropriate content to reach the content consumers, based on the 
users’ context and capabilities. The adaptivity is enabled by the sub-grouping activity 
of the Session Manager described in more detail in Section 3.3. 
3.3   Adaptivity in Session Manager: Forming Subgroups 
A key issue within the enhanced session management involves the study of the most 
efficient way to make decisions regarding subgroups based on the context information 
 

 
Context Aware Multiparty Session Support for Adaptive Multicasting 
347 
discussed previously. For this, we must consider the information available through the 
interface to the adjacent entities, specifically the session management needs to be able 
to: 
• 
Translate obtained context information into descriptions of content 
substreams; 
• 
Communicate the descriptions of the required streams in terms of content 
delivery recognizable parameters; 
• 
Receiving & Handling the requested stream. 
A lot of emphasis must be given to the interface between the session management 
and the Content Delivery & Storage. For example, in the case of video, parameters 
that need to be considered in this communication are quality preferences, device 
capabilities and bandwidth that will describe the required stream based on the 
subgroup decision. The subgroup decision will be based on more criteria including the 
acquired context information but will be translated into a media description 
appropriate for the particular session. 
Context-aware
Session 
Management
Context & 
Content 
information
(location, 
environmen,
situation, 
feeling …) 
User 
group 1
3rd Party Application
(API)
User 
group n
User 
group 1
User 
group n
 
Fig. 2. Logical representation of sub-grouping based on context 
In order to achieve efficient subgrouping, the Session Manager must successfully 
handle three interfaces: 
(a) The interface between the network and the SM, 
(b) The interface between the Content Management & Matching and the SM, 
(c) The interface between the Content Delivery & Storage and the SM  
For interface (a) the requirements have to do with transmission quality in terms of 
ensuring that the network has enough resources to make the transmission effective 
without any quality losses. For this requirement the SM needs to know the access 
network assigned to a user as well as the network’s capabilities. We assume that the 
network has the capability of providing intelligent context-aware network selection. 
Therefore, a multimode terminal will always receive multiparty sessions using the 

348 
J. Antoniou et al. 
best network interface at the time. Furthermore, the specific capabilities of the 
selected access network may be acquired by SM through its interaction with the 
network. 
For interface (b) the SM considers context information additional to the network 
information exchanged in the Network-SM interface, such as location, profile 
information or terminal capabilities. This kind of information is made available at the 
Content Management & Matching entity through the Context Management and 
reasoning functional entity, which acts as a repository of context information 
available to any entity acting as a context consumer (e.g. the SM). 
This brings the discussion to the next set of requirements mentioned in (c). For this 
interface the SM does not receive information as in (a) and (b) but instead, once it 
receives the group id from the Content Management & Matching entity, it sends it to 
the content processor, to receive back appropriate content information that aids in 
forming the network sub-groups. Once the sub-groups are formed a session for each is 
opened and a set of media parameters directly related to the specific sub-group and 
describing a content stream is sent to the Content Delivery & Storage entity in order 
to receive the content stream adapted for a specific sub-group. A subgroup may be 
defined by such parameters as content id, resolution of user terminal screen, codec, 
access network and available bandwidth, whereas a requested content stream may be 
defined by such parameters as content id, codec, resolution of user terminal screen 
and maximum data-rate, making the mapping of parameters almost trivial.    
Finally, since a multi-access network environment implies heterogeneity, a generic 
networking service should be available to establish QoS-aware multiparty sessions 
over heterogeneous networks, i.e. whenever SM needs to manage a multiparty 
connection, it will use the service provided by the multiparty transport layer in order 
to setup the desired connection. 
3.3.1   Specifying Context-Aware Multiparty Session Establishment for Adaptive 
Multicast Sessions 
The key functionality of the SM is to create network subgroups based on network 
information as well as general user & environment context information to the extent 
that these are considered necessary for forming network groups, and in turn 
communicating the characteristics of these subgroups in the form of content stream 
descriptions to the media delivery function for obtaining the appropriate content for 
each subgroup. To achieve this task it is a key requirement to have effective interfaces 
between the SM and the entities that provide input parameters to the SM as well as 
the entities that receive output parameters from the SM since the success of subgroup 
forming and receiving the content is gravely dependent on these communications.  
Fig.3 illustrates Context-Aware Multiparty Session Establishment using generic 
terms for functional entities as used in Fig.1, as well as throughout the description. 
The flow diagram clearly indicates the sequential interactions and communications 
between the functional entities that interact with the session management and further 
indicates the sub-grouping process responsible for achieving adaptive multicast 
sessions. Once the users register for a service (Step 1), they become context providers 
to the Context Management & Reasoning entity (Step 2). Simultaneously, the 
application provides the users registered for a service to the Content Management & 
Matching entity (Step 3). Once the multicast groups are built, the relevant information 

 
Context Aware Multiparty Session Support for Adaptive Multicasting 
349 
is communicated to the Session Manager as indicated in Step 5, at which point the 
Session Manager passes this information to the Content Delivery & Storage entity, 
which is responsible to match the group information to a specific content (Step 6). 
After obtaining the content description, the Session Manager contacts the network 
monitoring entity to get network-specific information (Step 7) as well as the Context 
Management & Reasoning entity to get user context & profile information that will 
help in forming more efficient user subgroups (Step 9). Once subgrouping is done, the 
user sessions are established (Step 10) as well as the media sessions (Step 11) and the 
media is delivered to the users (Step 12).  
A good candidate protocol for specifying the interfaces to the SM both for input 
and for output is Session Initiation Protocol (SIP) [8]. SIP (together with Session 
 
 
Fig. 3. Context-Aware Multiparty Session Establishment 

350 
J. Antoniou et al. 
Description Protocol (SDP) [9] for more elaborate session description) provides an 
access agnostic means of communication between different entities by providing a 
specification for application-level control signaling. SIP is an open stateless signaling 
protocol defined by RFC 3261 used for creating, modifying, and terminating 
multimedia communication sessions between user endpoints (SIP User Agents) to 
agree on a characterization of a session they would like to share. SIP works 
independently of underlying transport protocols and without dependency on the type 
of session that is being established. 
SIP supports five facets of establishing and terminating multimedia communications: 
• 
User location: determination of the end system to be used for 
communication; 
• 
User availability: determination of the willingness of the called party to 
engage in communications; 
• 
User capabilities: determination of the media and media parameters to 
be used; 
• 
Session setup: "ringing", establishment of session parameters at both 
called and calling party; 
• 
Session management: including transfer and termination of sessions, 
modifying session parameters, and invoking services. 
SIP acts as a carrier for the Session Description Protocol (SDP), which describes 
the media content of the session. In typical use, SIP "sessions" are simply packet 
streams of the Real-time Transport Protocol (RTP). RTP is the carrier for the actual 
voice or video content itself. SIP is similar to HTTP and shares some of its design 
principles: It is human readable and request-response structured. SIP supports the 
Offer/Answer model of RFC 3264, where one participant offers the other a 
description of the desired session from their perspective, and the other participant 
answers with the desired session from their perspective.  
4   Conclusions  
The world is experiencing a revolutionary transformation. The worldwide spread of 
sensors allows augmenting the reality interpretation. The context information made 
available by sensors may be used to improve the efficiency of a system. Such 
efficiency is already being added to the mobile industry since the usage of context 
information to deliver content in a more accurate manner is becoming more and more 
popular. Location-based services are disseminated all over the world.  
In addition, the use of context allows the definition of mobile communities that are 
characterized by requiring the same content. The users in similar situations should 
receive the same data. The mobile system, and specifically multicasting, should be 
enhanced to create multiparty sessions that allow content delivery to such groups of 
users. Session management provides the necessary signaling to deliver a specific 
content to its consumers, handling different types of events regarding session control. 
Session management thus participates in dynamic changes such as switching between 
different content.  

 
Context Aware Multiparty Session Support for Adaptive Multicasting 
351 
The work presented here addresses this kind of dynamic session, i.e. a multi-party 
session that may respond to context changes in order to adapt and satisfy the users of 
a group. By using the user’s situation information, the paper illustrates ways to 
provide more accurate sessions for mobile communities. An evolved Session Manager 
functional entity is described supporting the establishment of context aware 
multiparty sessions in a heterogeneous environment in an efficient way. 
References 
1. 
Aguiar, R., Gomes, D.: Quasi-omniscient Networks: Scenarios on Context Capturing and 
New Services through Wireless Sensor Networks. Wireless Pers. Commun. 45, 497–509 
(2008) 
2. 
Kwon, Y.H., Park, H.J., Choi, S.G., Choi, J., Lee, H.S.: P2MP Session Management 
Scheme using SIP in MPLS-based Next Generation Network. In: The Joint International 
Conference on Optical Internet and Next Generation Network, 2006. COIN-NGNCON 
2006, July 9-13, pp. 183–185 (2006) 
3. 
Dong, W., Newmarch, J.: Adding Session and Transaction Management to Web Services 
by using Sip. In: Proceedings of the IADIS International Conference e-Society 2005, pp. 
299–306. IADIS Press, Portugal (2005) 
4. 
Wilde, E.: Group and Session Management for Collaborative Applications, Ph.D. Thesis, 
Diss. ETH No. 12075, ETH Zürich (published by Shaker-Verlag, Aachen (April 1997) 
ISBN 3-8265-2411-X 
5. 
Landfeldt, B., Larsson, T., Ismailov, Y., Seneviratne, A.: SLM, A Framework for Session 
Layer Mobility Management. In: Proc. IEEE International Conference on Computer 
Communications and Networks, Natick, Massachusetts, pp. 452–456 (October 1999) 
6. 
Handorean, R., Sen, R., Hackmann, G., Roman, G.-C.: Context Aware Session 
Management for Services in Ad Hoc Networks. In: Proceedings of the 2005 IEEE 
International Conference on Services Computing, vol. 01, pp. 113–120 (2005) 
7. 
Riede, C., Al-Hezmi, A., Magedanz, T.: Quadruple Play - Session Management Enabler 
for Multimedia Streaming. In: 16th IST Mobile & Wireless Communications Summit, 
Budapest, Hungary, July 1-5 (2007) IEEE Catalog Number: 07EX1670C, ISBN 978-963-
8111-66-1 
8. 
IETF RFC 3261, SIP: Session Initiation Protocol 
9. 
IETF RFC 2327, SDP: Session Description Protocol 
 

Context Inference for Mobile Applications in the
UPCASE Project⋆
Andr´e C. Santos1, Lu´ıs Tarrataca1, Jo˜ao M.P. Cardoso2,⋆⋆, Diogo R. Ferreira1,
Pedro C. Diniz1, and Paulo Chainho3
1 IST – Technical University of Lisbon, Taguspark, Oeiras, Portugal
2 FEUP – Faculty of Engineering, University of Porto, Portugal
3 PT Inova¸c˜ao S.A., Portugal
jmpc@acm.org
Abstract. The growing processing capabilities of mobile devices cou-
pled with portable and wearable sensors have enabled the development
of context-aware services tailored to the user environment and its daily
activities. The problem of determining the user context at each particu-
lar point in time is one of the main challenges in this area. In this paper,
we describe the approach pursued in the UPCASE project, which makes
use of sensors available in the mobile device as well as sensors externally
connected via Bluetooth. We describe the system architecture from raw
data acquisition to feature extraction and context inference. As a proof of
concept, the inference of contexts is based on a decision tree to learn and
identify contexts automatically and dynamically at runtime. Preliminary
results suggest that this is a promising approach for context inference in
several application scenarios.
Keywords: Context-aware services, context inference, smartphones,
wearable sensors, decision trees.
1
Introduction
There is a growing desire of telecommunication operators to increase traﬃc vol-
ume even further by oﬀering value-added services to customers in addition to
traditional voice and data communication. These services can be enabled or
disabled depending on the speciﬁc user context. For example, when caught in
rush-hour traﬃc, a service could automatically estimate the delay for the user
to reach a child’s school. In case of excessive delay, it would notify an alternate
adult for pick-up. Other examples include anti-theft or near-emergency services.
Using sensors it might be possible to determine whether an elderly has fallen at
home and has been immobile for some time thus triggering an emergency call.
To enable such kind of services, mobile devices must be able to clearly identify
speciﬁc contexts the user goes through [12,27]. For this purpose, mobile devices
⋆This work was partially funded by PT Inova¸c˜ao S.A.
⋆⋆Corresponding author.
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 352–365, 2009.
  Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

Context Inference for Mobile Applications in the UPCASE Project
353
must include sensors that yield data such as position, lighting or sound condi-
tions from which user contexts can be determined. Accurate context inference,
however, is notoriously diﬃcult as there exist various sources of data signals
with possibly very distinct patterns which need to be captured and processed
in a timely fashion. Furthermore, the amount of raw sensor data can overwhelm
the resources of even the most sophisticated mobile devices. A possible solu-
tion would require each mobile device to acquire and transmit sensor data to a
centralized server for processing. Although conceptually simple, this centralized
solution is infeasible. It would require constant communication with a centralized
server as most sensors need to operate in real-time. This in turn would require
excessive computing power for each device to constantly transmit a possible
high volume of sensor data. On the server side fusing sensor data from millions
of devices would require a tremendous computing power. Instead, each mobile
unit should be able to infer user context by processing data originating from
its sensors and possibly from communicating with network services to obtain
additional information such as traﬃc or weather conditions.
In this paper, we describe the architecture and operation of a proof-of-concept
system for context inference based on a smartphone augmented with an ar-
ray of sensors connected via Bluetooth1. This system is part of the UPCASE
project (User-Programmable Context-Aware Services), an industry-funded R&D
project. The architecture of the system consists of three main layers: (1) the ac-
quisition layer which is concerned with sensor data acquisition and preprocessing,
(2) the feature extraction layer which assigns speciﬁc categories to the prepro-
cessed sensor data, and (3) the context inference layer which uses decision-tree
induction techniques to uncover the user context.
This paper is organized as follows. We begin with an overview of related work
and describe the developed system. Next, we present the various sensors used
in connection with the smartphone and the experimental results of context in-
ference in a simple scenario of daily activities. Lastly, we describe two potential
scenarios of application of the system developed in identifying meaningful con-
texts, namely in elderly care and emergency management scenarios.
2
Background and Related Work
Context identiﬁcation as been recognized as an enabling technology for proactive
applications and context-aware computing [4,11]. Sensor networks can be used
to capture intelligence (see, e.g., the e-SENSE2 project [17]), providing sensing
capabilities from the environment and opening opportunities for context-aware
computing.
Early context-aware applications were predominantly based on user location
deﬁned as typical user places (e.g., “at home”, “in a museum”, “in a shopping
center”). Projects such as GUIDE [3] and Cyberguide [1] addressed the use of
information about location and situation to guide the user when visiting touristic
1 The Oﬃcial Bluetooth Technology Info Site (www.bluetooth.com/bluetooth).
2 http://www.ist-esense.org/

354
A.C. Santos et al.
city spots. Recently, researchers have studied techniques to identify a richer set
of contexts or activities. These include simple user activities (e.g., “walking”,
“running”, “standing”), environment characteristics (e.g., “cold”, “warm”), or
even emotional condition of the user (e.g., “happy”, “sad”, “nervous”).
In the SenSay [23] project, researchers developed a smartphone prototype able
to exploit the user context to improve its usability. For example, if the user is
occupied and wishes not to be interrupted, the smartphone can answer/reply
automatically using an SMS. The SenSay prototype uses a smartphone and a
sensor unit consisting of a 3-axis accelerometer, two microphones (one to capture
sound from the environment and the other to capture voice from the user), and a
light sensor. The prototype makes use of simple techniques such as performing an
average of sensor readings over a given window and applying a numeric threshold
to identify each activity.
Generally, the identiﬁcation of contexts is done in stages. Processing raw data
from sensors may require a wide variety of techniques such as noise reduction,
mean and variance calculation, time- and frequency-domain transformations, es-
timation of time series or sensor fusion. Data collected from sensors is catalogued
(a process known as feature extraction) and the context-inference stage makes
use of features rather than raw data. Context inference has been addressed us-
ing diﬀerent techniques such as Kohonen Self-Organizing Maps (KSOMs) [14],
k-Nearest Neighbor [15], Neural Networks [20], and Hidden Markov Models
(HMMs) [24]. Some approaches even combine several of these techniques, as
in [13].
Regarding the inference of user activities such as “walking” or “running”, they
use a plethora of approaches, ranging from simple processing steps and threshold
operations [8,22,27] to the use of neural networks as the clustering algorithm [20];
or even using non-supervised time-series segmentation [9]. As an example, the
work presented in [12] infers activities such as “walking”, “running”, “standing”,
and “sitting” with a single 3-axis accelerometer claiming an accuracy of 96%.
In our approach, we extract signal features using techniques similar to those
described in [22,27]. For context inference we combine signal-processing and
machine-learning techniques, using decision trees [18] to fuse features and deter-
mine user activities. All data preprocessing and context inference is performed on
the mobile device. The results are sent to a server in order to monitor activities,
thus allowing for more advanced and possibly non-local context inferences.
3
The UPCASE Project
The UPCASE project aims at uncovering user contexts using a set of sensors
connected to the user’s mobile phone. These sensors can be embedded into per-
sonal clothes or items such as backpacks or purses. Sensors include accelerome-
ters, light, sound, and temperature sensors, and also virtual sensors to acquire
information such as time of day or approximate location via external services.
A goal of the project includes the development of robust algorithmic ap-
proaches
to
accurately
determine
user
context.
Speciﬁcally,
we
include

Context Inference for Mobile Applications in the UPCASE Project
355
supervised-based learning techniques. During a training phase the system collects
a suﬃcient number of data samples for context derivation using decision-tree
based techniques. After this training phase the system operates autonomously
and unobtrusively automatically deriving contexts.
3.1
System Sensors and Prototype
Figure 1(a) depicts the main system components used in the prototype we have
developed: the mobile device, a sensor node, and a set of sensors. The black box
contains the batteries (the 1-Euro coin is shown to provide an idea of scale).
Figure 1(b) depicts an experimental setup where the components are embed-
ded in a backpack used for testing purposes. In this early prototype, we have
deliberately not concealed the sensors to experiment with sensor sensitivity to
environment conditions. The prototype has been tested on a backpack and also
on a vest, ensuring that the sensors experience the same conditions as the user.
The only requirement is that some sensors must be exposed to allow for more
correct sound, temperature and light measurements.
(a)
(b)
Fig. 1. The system components (a) and an experimental setup in a backpack (b)
The system prototype comprises a Sony Ericsson W910i smartphone3 and
a BlueSentry external sensor node4. A sound sensor5, a temperature sensor6,
and a light sensor7 are wired to the sensor node. The BlueSentry sensor node
communicates with the smartphone via Bluetooth to provide sensor readings,
thus avoiding the need for physical connection between the two. In addition
to these, there are two other sensors being used: the internal accelerometer of
the smartphone and a virtual time sensor to provide the time of day. It is also
possible to connect a second accelerometer to the BlueSentry node.
3 http://www.sonyericsson.com/cws/products/mobilephones/overview/w910i
4 http://www.rovingnetworks.com/bluesentry.htm
5 http://www.inexglobal.com/products.php?model=zxsound
6 http://www.phidgets.com/products.php?product id=1124
7 http://www.phidgets.com/products.php?product id=1127

356
A.C. Santos et al.
3.2
System Sensors and Prototype
The overall system architecture is presented in ﬁgure 2. The application layer has
been developed using Java ME platform8, a technology that is widely used due to
its recognized portability across many mobile phone devices. At the lowest level,
the sensors gather data from the environment and provide it as raw analog signals
to the sensor node, which in turn converts them to digital and transmits the
digital representations to the mobile phone via Bluetooth. The mobile phone runs
a proprietary operating system (OS) which supports the execution of Java code.
We have developed a MIDP (Mobile Information Device Proﬁle) application that
acquires raw sensor data from the BlueSentry node and supports the extraction
of features to be used in the upper layers of the system architecture.
Fig. 2. The UPCASE system architecture
At runtime, there are three main stages: a sensor acquisition stage, a pre-
processing stage, and a context inference stage. Sensor data acquired from the
available sensors are fed to the preprocessing stage, which is responsible for
8 http://java.sun.com/javame/

Context Inference for Mobile Applications in the UPCASE Project
357
extracting signal features. The inference stage gathers these features and iden-
tiﬁes the context that is associated with them according to a set of rules. These
rules are either pre-deﬁned or derived by a learning phase. This synergy between
stages can be seen as a process that maps low-level sensor data into higher-level
context information. Both the preprocessing and the context inference stage can
be conﬁgured by specifying the available sensors and the default context rules.
In addition, it is possible to add new sensors or replace existing ones by means of
an XML conﬁguration ﬁle, thus providing an easy and simple way of managing
the set of system sensors.
The upper section of the ﬁgure depicts the context-inference stage and the
system interaction with external resources, such as a centralized server. Each
mobile device, upon having recognized a speciﬁc context, can (contingent on user
permission) publish it on a server to trigger other actions or custom services,
or to provide statistical data about user behavior that can be used to generate
other services or improve the performance of existing ones. A server can take
advantage of historical data to improve the accuracy of context information.
3.3
Sensor Data Acquisition
We make use of JSR-256 Mobile Sensor API9 whenever it is supported by the
mobile device. The JSR-256 API allows developers to retrieve data not only
from embedded sensors but also from sensors connected via infrared, bluetooth
and GPRS. When the JSR-256 is not supported, we use the JSR-82 Bluetooth
API10. At the moment we are using JSR-256 for the internal accelerometer in
the Sony Ericsson W910i device, and JSR-82 for all other data acquisition.
Sensor data are acquired at a ﬁxed rate. At regular intervals, the device sends
a request to the sensor node in order to retrieve data from the sensors connected
to that node. The sensor readings are buﬀered in the smartphone to be fed later
to the preprocessing stage. It is worth noting that sensors may have diﬀerent
acquisition rates. The diﬀerence in sampling frequency may force the acquisition
to run at the slowest rate, or at individual rates for each sensor. Currently we
are using the same acquisition rate for all sensors.
3.4
Preprocessing
The preprocessing stage converts raw sensor data into a set of features. This con-
version is performed by means of threshold operations that map sensor data into
a ﬁnite set of categories. Rather than using instant values, the system captures
a sequence of sensor readings and then preprocesses them in order to minimize
jitter and to provide a more accurate categorization. The preprocessing may
involve averaging, ﬁltering or transforming values, depending on the particular
sensor the data come from.
9 http://jcp.org/en/jsr/detail?id=256
10 http://jcp.org/en/jsr/detail?id=82

358
A.C. Santos et al.
Table 1. Categorization of the sensor values acquired
Sensor Category Value range
very silent
0% - 20%
silent
20% - 40%
sound
moderate
40% - 60%
loud
60% - 80%
very loud
80% - 100%
very dark
0 - 200
dark
200 - 400
light
normal
400 - 600
bright
600 - 800
very bright
800 - 1000
Sensor
Category
Value range
very cold
−50- 0
cold
0- 15
temperature
mild
15- 25
hot
25- 30
very hot
30- 150
dawn
0h - 5h
morning
6h - 11h
time
afternoon
12h - 17h
night
18h - 23h
not moving
variance-based
accelerometer
moving
variance-based
moving fast variance- and FFT-based
Table 1 presents the categories for each sensor, as well as the range of values for
each category. Clearly, a limited number of categories places some limits on the
total number of contexts that can be identiﬁed. However, a too large number
of categories can also divide the perception of the environment in too many
diﬀerent states. According to the user contexts to be identiﬁed and according to
the speciﬁc application domain, the categories of sensor values may have to be
adjusted. In general, however, most applications will make use of only a limited
set of contexts and the above categories, we believe, are enough to handle many
practical situations.
For some sensors, the raw sensor value can be mapped directly to a category,
while other sensors such as the accelerometer need more elaborated preprocess-
ing. For each sensor there is a ﬁxed buﬀer window. For the temperature, light
and sound sensors, the category is found by applying threshold operations to
the mean value inside the buﬀer, making context inference less prone to sensor
noise.
For the 3-axis accelerometer, the system calculates the variance for each axis
along a time-framed window (last 16 data samples). Those three variances ob-
tained are compared to a threshold in order to identify “moving” and “not
moving” activities. When movement is detected, the system performs an FFT
over the last 32 data samples and the amplitudes of the harmonics represent-
ing frequencies within the range of “running” activities (currently 0.5 to 2 Hz)
are added up. If the resulting value is greater than a speciﬁc threshold value a
“running” context is signaled. Otherwise, a “walking” context is determined.
4
Context Inference in the UPCASE Project
At any given moment, the set of sensor readings will have some relationship with
user activity of the surrounding environment. The purpose of context inference
is to discover this relationship so that when a similar set of readings occur, the
device will recognize the same context. While diﬀerent contexts can lead to the
same set of sensor readings the converse is also true: diﬀerent readings may cor-
respond to the same context, as there will be naturally some variation in sensor

Context Inference for Mobile Applications in the UPCASE Project
359
values. Context inference must therefore identify the range of measurements that
typically corresponds to each context.
4.1
Context Inference with Decision Trees
Decision trees are structures that ﬁt the purpose of induction and are fast to
build and process, which makes them attractive for implementation on mobile
devices. Provided with a set of training examples, decision tree induction attains
a classiﬁcation of contexts according to a set of sensor readings. Our implemen-
tation is based on the ID3 algorithm [19], which uses information entropy to
build the smallest tree that can correctly identify all the branches.
The decision tree is ﬁrst built from a set of default context rules. These initial
rules are represented in XML so that they can be provided as a diﬀerent starting
point for diﬀerent user proﬁles (e.g., student pack, sports pack, professional
pack). The tree is then updated as the user trains the system with new contexts.
As the system is being trained, the whole tree is recomputed and updated with
the learned contexts.
Figure 3 depicts an example of an induced decision tree using ﬁve sensors,
namely: time, sound, accelerometer, light and temperature. The tree has paths
from root to leaf nodes that provide the rules for context identiﬁcation based on
identiﬁed features. In this example the accelerometer provides the most distinc-
tive feature, followed by temperature and sounds sensors, and only then by light
and time sensors.
Learned contexts can be renamed or deleted, as the system provides means
for the user to manage existing contexts. This way the user can erase a learned
context and train the system again, or simply remove an unused context. We
are studying ways to allow the user to correct only some rules without having
Accelerometer
Sound
Not
moving
Temperature
Moving
Temperature
Moving
fast
Light
Very
silent
Light
Moderate Loud
Time
Very
dark
Working
Very
bright
Sleeping
Night
Dawn
Resting
Afternoon
Meeting
Bright
Very
bright
Walking
outside
Cold
Walking
inside
Mild
Running
inside
Mild
Running
outside
Cold
Fig. 3. Example of an induced decision tree

360
A.C. Santos et al.
to completely re-train the system. In any case, recomputing the decision tree is
suﬃciently fast for not being noticeable by the user.
The context identiﬁed via the decision tree is stored in a buﬀer which gathers
a ﬁnite number of contexts and returns the context that has been recorded
more often within a certain time window. This avoids momentaneous conditions
that would make the context change unexpectedly. Together with sensor data
buﬀering, this provides another layer that minimizes errors due to faulty sensor
readings or to activities that were detected for only a brief moment within a
diﬀerent context.
4.2
Application Layer
Figure 4 provides some screenshots of the UPCASE application running on the
smartphone. The application presents a simple yet eﬀective user interface, al-
lowing diﬀerent modes chosen from a list of available options. It includes the
possibility of editing existing contexts and printing the decision tree for debug-
ging purposes. Figure 4(c) presents an example of the initial conﬁguration for the
continuous context-learning mode which acquires sensor data during a period of
time when a certain context is active. In ﬁgure 4(a) we can see the diﬀerent sen-
sor readings and the identiﬁed context, as well as a conﬁdence value calculated
as the percentage of total records for the displayed context within the buﬀer
window. A suggestive icon is also presented to the user.
4.3
Learning Mode
The decision tree shown in ﬁgure 3 can be induced from a set of examples
collected during a training period. When the user sets a context and a learning
period as in ﬁgure 4(c), the system collects sensor readings during that period
and classiﬁes the readings as examples for a speciﬁed context. It then uses these
examples to update the decision tree. Figure 5 presents the sensor readings
collected for four diﬀerent contexts in a simple test scenario. The results are
shown for a period of ten minutes, where the system acquired approximately
300 examples for each context.
(a)
(b)
(c)
(d)
Fig. 4. The UPCASE application in operation mode (a), in selection mode (b), in
learning mode (c), and in context-editing mode (d)

Context Inference for Mobile Applications in the UPCASE Project
361
(a)
(b)
(c)
(d)
Fig. 5. Sensor readings for diﬀerent contexts: sleeping (a), working (b), exercising (c)
and driving (d)
As can be seen in ﬁgure 5, the sound sensor exhibits the highest variability
which can be explained by the fact that this sensor is particularly sensitive. The
light sensor shows no variation as the data for this experiment were captured in
constant lighting conditions. As a result, light will not become a discriminator
in the induced decision tree. A similar situation occurs with the temperature
sensor, where the Mild category is present in all contexts. The accelerometer
provides useful information, as some contexts can be distinguished in terms of
movement. Lastly, the time sensor allows the derivation of the most distinctive
feature, as it provides a constant value within each context, and a diﬀerent value
for three out of four contexts. Figure 6 depicts the induced decision tree for this
testing scenario.
4.4
Context Server
The context can be uploaded, upon user permission, to a centralized server at
the network operator over http and conforming to the REST API[5]. This has
several advantages. First, it is possible to enable, disable or change the behavior
of value-added services that depend on user context. Second, user context can
be augmented with information available at the network level, such as traﬃc

362
A.C. Santos et al.
Time
Sound
Afternoon
Sleeping
Dawn
Walking
Morning
Working
Very
silent
Silent
Moderate
Accelerometer
Loud
Driving
Very
loud
Driving
Moving
fast
Moving
Working
Not
moving
Fig. 6. Induced decision tree from the readings shown in ﬁgure 5
conditions or special services available at the user location. Last, the publication
and availability of user contexts open the way for advanced social networking
services and other applications.
5
Case-Study Scenarios
In this section we describe two potential scenarios of the application of the
UPCASE system for context detection and exploitation. Both cases require ad-
ditional sensors while still relying on the context-detection techniques described
in this paper. The applications exploit not only the ability of the system to
identify user contexts, but also of making context information available to other
users via a context server.
5.1
Elderly Care
Devising support technologies for elderly care is an active area of research [16,25]
where applications have traditionally focused on monitoring the location and
risk-prone activities of elderly persons. These applications usually require mul-
tiple sensors [10], or the user to carry appropriate sensors, for example for auto-
matic fall detection [7].
For elderly people that have an active life but still inspire some care, a general-
purpose, inexpensive system such as the one developed in the UPCASE project
can help a family member keep track of their daily activities. Such approach is
not intended to limit the activity of an elderly person, but simply to provide an
up-to-date account of the elderly person’s activities. For example, if a person is
resting or performing some activity at home, family members can be reassured
of the person’s well-being; on the other hand, knowing that the person is driving
or inside a car makes them aware of activities that inspire more care. In general,
such context-aware systems can enable family members to promptly respond to

Context Inference for Mobile Applications in the UPCASE Project
363
any situation that requires attention, while allowing elderly people the freedom
they desire.
In this scenario, as well as in medical applications, there are additional sensors
such as heart-rate monitors or blood-pressure sensors. Contexts can be published
in the context server, and family members can retrieve them using any Web-
enabled device. We are currently developing this scenario in connection with
wearable sensor systems equipped with physiological sensors such as ECG, heart
rate, oxygen, posture, and body temperature.
5.2
Emergency Management
Emergency management is the discipline that deals with preparing for, prevent-
ing, responding to, and recovering from emergency situations [6]. Under extreme
conditions, it is essential to be able to: make accurate decisions; coordinate a
number of team members and to keep track and dynamically allocate available
resources. These and other emergency-related challenges can be addressed by
having appropriate information systems in place [21].
Sensor-based and context-aware systems can play a key role in preventing and
also in responding to emergency situations. These systems usually make use of
front-end and back-end components in order to coordinate team members on the
ﬁeld [2,26]. A key requirement of any emergency response system is its ability
to know the state of readiness of the allocated workforce. For a given situation,
team members that are both on duty and oﬀ-duty may have to be called in.
Knowing the context of each staﬀmember can help determine which members
are more or readily available to promptly respond to the situation. For example,
it may be the case that only active, or free members, or members currently
driving, or in any other speciﬁc context, should be called to the scene, thereby
substantially reducing the emergency total response time.
The scenario can be supported by the UPCASE system, as sensors can be
easily merged into the members outﬁt. In the background, a server receives
context information from the smartphones and stores it in a database where all
contexts are kept up-to-date. In an emergency situation, the database can be
queried to quickly obtain a list of all team members in a speciﬁc context.
6
Conclusion
Being able to gather information about user context is a key enabling factor
for a new generation of context-aware services and applications. In this paper
we addressed the problem of distinguishing between a number of daily activ-
ity contexts by means of a prototype proof-of-concept system developed in the
context of the UPCASE project. The system prototype is based on a set of
general-purpose, inexpensive sensors connected to a regular smartphone via a
Bluetooth-enabled sensor node. It is small enough to be embedded in clothes or
other personal objects, and it operates in an unobtrusive manner after an ini-
tial training period. Context inference is based on decision tree induction, which

364
A.C. Santos et al.
provides a simple and lightweight procedure that can be implemented in devices
with limited processing capabilities. The approach is eﬀective in a number of
applications, and we hope it will spur the interest in similar methods to identify
and make use of contexts in mobile applications.
References
1. Abowd, G., Atkeson, C., Hong, J., Long, S., Kooper, R., Pinkerton, M.: Cyber-
guide: A Mobile Context-Aware Tour Guide. In: Proc. of the Intl. Conf. on Mobile
Computing and Networking (MobiCom 1996), pp. 421–433 (1996)
2. Catarci, T., de Leoni, M., Marrella, A., Mecella, M., Salvatore, B., Vetere, G.,
Dustdar, S., Juszczyk, L., Manzoor, A., Truong, H.: Pervasive Software Environ-
ments for Supporting Disaster Responses. In: IEEE Internet Computing, pp. 26–37
(January/Feburary 2008)
3. Cheverst, K., Davies, N., Mitchell, K., Friday, A.: Experiences of Developing and
Deploying a Context-Aware Tourist Guide: The GUIDE Project. In: Proc. of the
Sixth Annual Intl. Conf. on Mobile Computing and Networking, pp. 20–31. ACM
Press, New York (2000)
4. Coutaz, J., Crowley, J.L., Dobson, S., Garlan, D.: Context is Key. Communications
of the ACM 48(3), 49–53 (2005)
5. Fielding, R.T.: Architectural Styles and the Design of Network-based Software
Architectures. PhD thesis, Univ. California at Irvine (UCI), Irvine, Calif. (2000)
6. Haddow, G., Bullock, J., Coppola, D.: Introduction to Emergency Management.
Butterworth-Heinemann (2007)
7. Hansen, T., Eklund, J., Sprinkle, J., Bajcsy, R., Sastry, S.: Using smart sensors
and a camera phone to detect and verify the fall of elderly persons. In: Proc. of the
European Medicine, Biology and Engineering Conf. (EMBEC 2005) (November
2005)
8. Healey, J., Logan, B.: Wearable wellness monitoring using ecg and accelerometer
data. In: ISWC 2005, pp. 220–221. IEEE Computer Society Press, Washington
(2005)
9. Himberg, J., Korpiaho, K., Mannila, H., Tikanm¨aki, J., Toivonen, H.: Time series
segmentation for context recognition in mobile devices. In: Proc. of the 2001 IEEE
Intl. Conf. on Data Mining (CDM 2001), pp. 203–210. IEEE Computer Society
Press, Washington (2001)
10. Hori, T., Nishida, Y., Aizawa, H., Murakami, S., Mizoguchi, H.: Sensor network
for supporting elderly care home. Proc. of IEEE, 575–578 (October 2004)
11. Hull, R., Neaves, P., Bedford-Roberts, J.: Towards situated computing. In: Proc.
of the Intl. Conf. on Wearable Computers (ISWC 1997), pp. 146–153 (1997)
12. Kawahara, Y., Kurasawa, H., Morikawa, H.: Recognizing user context using mobile
handsets with acceleration sensors. In: (IEEE) Intl. Conf. on Portable Information
Devices (PORTABLE 2007), pp. 1–5 (2007)
13. Krause, A., Smailagic, A., Siewiorek, D.: Context-aware mobile computing: Learn-
ing context-dependent personal preferences from a wearable sensor array. IEEE
Trans. on Mobile Computing 5(2) (Feburary 2006)
14. Van Laerhoven, K.: Combining the kohonen self-organizing map and k-means for
on-line classiﬁcation of sensor data. In: Dorﬀner, G., Bischof, H., Hornik, K. (eds.)
ICANN 2001. LNCS, vol. 2130, pp. 464–470. Springer, Heidelberg (2001)

Context Inference for Mobile Applications in the UPCASE Project
365
15. Laerhoven, K.V., Cakmakci, O.: What shall we teach our pants. In: Proc. of the
Proc. Fourth Intl Symp. Wearable Computers (ISWC 2000) (2000)
16. Miskelly, F.: Assitive technology in elderly care. Oxford Journals Medicine Age and
Ageing 30(6), 455–458 (2001)
17. Presser, M., Gluhak, A., Babb, D., Herault, L., Tafazolli, R.: eSENSE - capturing
ambient intelligence for mobile communications through wireless sensor networks.
In: Proc. of the 13th Intl. Conf. on Telecommunications, pp. 27–32 (May 2006)
18. Quinlan, J.: Induction of Decision Trees. Machine Learning 1(1), 81–106 (1986)
19. Quinlan, J.: C4.5: Programs for Machine Learning. Morgan Kauﬀman, San Fran-
cisco (1993)
20. Randall, C., Muller, H.: Context awareness by analyzing accelerometer data. In:
Proc. 4th Intl Symp. on Wearable Computers (ISWC 2000), pp. 175–176 (October
2000)
21. Rao, R., Eisenberg, J., Schmitt, T.: Improving Disaster Management: The Role
of IT in Mitigation, Preparedness, Response, and Recovery. National Academies
Press, Washington (2007)
22. Si, H., Kawahara, Y., Kurasawa, H.M.H., Aoyama, T.: A context-aware collabora-
tive ﬁltering algorithm for real world oriented content delivery service. In: Proc. of
ubiPCMM (2005)
23. Siewiorek, D., Smailagic, A., Furukawa, J., Krause, A., Moraveji, N., Reiger, K.,
Shaﬀer, J., Wong, F.: Sensay: A context- aware mobile phone. In: Proc. 7th Inter-
national Symposium on Wearable Computers (ISWC) (2003)
24. Skaﬀ, S., Choset, H., Rizzi, A.: Context identiﬁcation for eﬃcient multiple-model
state estimation. In: Proc. of the IEEE/RSJ Intl. Conf. on Intelligent Robots and
Systems (IROS), San Diego, CA, USA, pp. 2435–2440 (October 2007)
25. Stanford, V.: Using pervasive computing to deliver elder care. Pervasive Comput-
ing 1(1), 10–13 (2002)
26. Truong, H.-L., Juszczyk, L., Manzoor, A., Dustdar, S.: ESCAPE – an adaptive
framework for managing and providing context information in emergency situa-
tions. In: Kortuem, G., Finney, J., Lea, R., Sundramoorthy, V. (eds.) EuroSSC
2007. LNCS, vol. 4793, pp. 207–222. Springer, Heidelberg (2007)
27. Welbourne, E., Lester, J., LaMarca, A., Borriello, G.: Mobile context inference us-
ing low-cost sensors. In: Strang, T., Linnhoﬀ-Popien, C. (eds.) LoCA 2005. LNCS,
vol. 3479, pp. 254–263. Springer, Heidelberg (2005)

C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 366–380, 2009. 
© Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009 
Design, Implementation and Case Study of WISEMAN: 
WIreless Sensors Employing Mobile AgeNts 
Sergio González-Valenzuela, Min Chen, and Victor C.M. Leung 
Department of Electrical and Computer Engineering 
The University of British Columbia 
2332 Main Mall, Vancouver BC, V6Z1T4, Canada 
{sergiog,minchen,vleung}@ece.ubc.ca 
Abstract. We describe the practical implementation of Wiseman: our proposed 
scheme for running mobile agents in Wireless Sensor Networks. Wiseman’s ar-
chitecture derives from a much earlier agent system originally conceived for 
distributed process coordination in wired networks. Given the memory con-
straints associated with small sensor devices, we revised the architecture of the 
original agent system to make it applicable to this type of networks.  Agents are 
programmed as compact text scripts that are interpreted at the sensor nodes. 
Wiseman is currently implemented in TinyOS ver. 1, its binary image occupies 
19Kbytes of ROM memory, and it occupies 3Kbytes of RAM to operate. We 
describe the rationale behind Wiseman’s interpreter architecture and unique 
programming features that can help reduce packet overhead in sensor networks. 
In addition, we gauge the proposed system’s efficiency in terms of task duration 
with different network topologies through a case study that involves an  
early-fire-detection application in a fictitious forest setting. 
Keywords: Mobile agents, wireless sensor networks, performance evaluation. 
1   Introduction 
The topic of Wireless Sensor Networks (WSN) continues to draw significant research 
interest at present. These investigations include studies on the feasibility of dynami-
cally re-tasking sensor nodes in the face of continuous changes in the underlying 
environment. To tackle this issue, code mobility can be used as a potentially efficient 
approach [1]. While some of these approaches have been proposed for operation over 
devices with plentiful hardware resources, we are rather interested in the type of 
agent-based re-tasking systems targeted at low-end sensor devices that are character-
ized by severe memory and processing constraints. The main motivation for studying 
WSN agent-based re-tasking is that it enables rapid modifications to the pre-
programmed behaviour of sensor nodes responding to a predefined type of events. 
Clearly, dynamic WSN re-tasking provides flexibility and convenience to its opera-
tors. Still, further studies are needed to determine whether this mechanism is not only 
practicable from an engineering perspective, but also whether the system that imple-
ments it fulfills performance expectations in terms of resources employed and  
response time. 

 
Design, Implementation and Case Study of WISEMAN 
367 
Initial accomplishments in the area of WSN re-tasking were achieved by schemes 
such as Deluge [2], Impala [3] and Maté [4]. These approaches introduced basic 
forms of code mobility to reprogram WSN nodes with a certain degree of flexibility 
and were soon followed by enhanced approaches. For instance, Agilla is a popular 
scheme that employs code mobility in the form of programmable agents to perform 
WSN re-tasking too [5]. The Agilla framework introduced significant improvements 
over existing proposals by employing a more robust agent interpreter capable of han-
dling certain tasks in devices severely constrained in hardware resources. Several 
lessons were learned during the implementation and testing of Agilla, including issues 
related to memory management and the agents’ programming language [6]. 
In a previous paper, we contested that middleware design for agent systems in 
WSN is highly dependent on several issues, which includes (1) the targeted system 
application and (2) the network navigation methodology implemented into the mobile 
codes to address the issue in question [7]. In addition, the use of mobile codes in 
WSNs is mostly warranted when collecting and/or aggregating data that is dispersed 
in various nodes. To this regard, we have previously proposed MAWSN and MADD 
as itinerary-planning schemes aimed at reducing the overhead incurred by the corre-
sponding process [8, 9]. One shortcoming with these and other proposed paradigms is 
that once the agent is dispatched by the sink node, its itinerary cannot be revised, 
which becomes an issue should the underlying environment conditions change after 
the agent has been dispatched [10]. By the same token, if on-the-go itinerary changes 
are needed, then this functionality needs to be supported by the agent middleware.  
To address the previous issue, we designed and implemented Wiseman: “WIreless 
Sensors Employing Mobile AgeNts”. Our proposed scheme overcomes the source-
based itinerary issue, enabling changes by any WSN node in the pre-defined path 
assigned to an agent. Our novel agent middleware system incorporates: (1) a high-
level text-based language system that acts as a compact action script, (2) the ability to 
dynamically modify agent itineraries that can employ hop-by-hop planning, and (3) a 
virtual-link navigation capability that mimics multicast routing through labelled paths. 
A combination of the latter 2 schemes is also possible. In addition to this, Wiseman is 
based on a framework that does not necessitate a program counter and execution stack 
to function. Instead, Wiseman incorporates a self-depleting command execution 
model that discards agent instructions once they are no longer needed. This implies 
that the agent size is variable, and may be structured to progressively shrink as it 
completes its task.  
The rest of the paper is organized as follows: In Section 2, we briefly introduce the 
original predecessor of the Wiseman system and describe its adaptation into a mid-
dleware system amenable to WSN use. Section 3 describes Wiseman’s simplified 
architecture and main system modules. In Section 4, we describe Wiseman’s language 
construct design based on the needs of the overall system. Practical implementation 
aspects of the system are discussed in Section 5. In Section 6, we illustrate a sample 
application scenario to evaluate the performance of the system in terms of agent mi-
gration delay. In Section 7, we discuss the results of our experiments. Finally, we 
present our conclusions in Section 8. 

368 
S. González-Valenzuela, M. Chen, and V.C.M. Leung 
2.   System Foundations 
Existing mobile agent approaches for WSN attempt to achieve a balance between the 
degrees of functionality incorporated into the actual code interpreter, and the one 
provided to the agents. On the one hand, a coarse-grained agent system for WSN that 
incorporates a high degree of functionality in the interpreter requires simple con-
structs on the agent side in order to accomplish a certain task (e.g., <run task A>, <run 
task B>, <end>). On the other hand, a code interpreter tailored for fine-grained agent 
language construct leads to larger programs that describe in detail the task to perform 
(e.g., <mov 1 x>, <and x 0xFB>, …) Once again, the degree of granularity used in the 
language constructs of the agent system should be a direct function of the intended 
WSN’s application. Given the specific nature of WSNs, it results intuitive to think of 
coarse-grained language constructs as a more suitable approach. In other words, it 
makes little sense here to provide agents with excessive control of the node’s data 
processing functionalities if the tasks to be performed are consistently repetitive. In 
fact, the case for code mobility in the form of agents hardly holds if the WSNs tasks 
they are set to solve are rather deterministic, or if they require minimal changes. The 
use of mobile agents in a WSN is therefore justified by the need of flexibility in the 
evolution of a system process. In such case, whereas the application of a WSN might 
be very well defined, external factors driven by the underlying environment might 
require different strategies to deal with the problem. For this reason, we propose an 
alternative approach to incorporate programmability in distributed tasks based on a 
simplified version of the Wave system for incorporation into WSN. 
The Wave system can be considered one of the earliest precursors of code mobility 
in data networks, with its foundations lying on the idea of efficient task coordination in 
distributed environments [11, 12]. To this effect, Wave’s high-level language construct 
allows creating highly compact programs that encompass a suitable degree of distrib-
uted coordination. This approach results highly appealing to WSNs, since it promotes 
the use of existing functionalities in the node, instead of creating agents that repeatedly 
perform the same task on every node they visit. In fact, overall system efficiency can 
arguably be improved by promoting local data processing through algorithms that run 
on native code. As a result: (1) the process coordination part of the distributed applica-
tion is decoupled from the data processing part and is now left for the agents to per-
form; (2) additional agent compactness can be achieved by defining language  
constructs that are sufficient to describe the desired coordination methodology of the 
mobile process; and (3) a condensed language construct translates into simplified in-
terpreter’s architecture, smaller memory footprint, and reduced forwarding overhead in 
terms of delay and bandwidth. In the next section we describe Wiseman’s architecture 
as a significantly simplified adaptation of the original Wave system. 
3   The Wiseman System Architecture 
The Wiseman interpreter is comprised of an incoming agent queue, a code parser, a 
processor block, and an agent dispatcher, as shown in Fig. 1. The incoming agent 
queue works in a simplistic first-in-first-out fashion, and accepts agents either arriving 
from other nodes, or those injected at the local node. The parser is in charge of proc-
essing agents as they are received from the wireless interface of the node. 

 
Design, Implementation and Case Study of WISEMAN 
369 
 
Fig. 1. Wiseman’s System architecture 
Agents are removed from the incoming queue one at a time and fragmented into 
their respective codes and data fields. Agent codes are further separated into two 
segments, hereto referred as head and tail. The head is the first code fragment defined 
by the language constructs, whereas the rest of the codes that follow are referred to as 
the tail. The head is then unwrapped from any delimiters until a single indivisible 
operation is found by the parser, and is subsequently passed onto the processor block 
for execution. When finished, the process control is returned to the parser, which then 
extracts the next operation from the agent’s tail if the previous operation was success-
fully processed. The new segment becomes the head that is processed in the exact 
same fashion. This way of processing agents implies that the agent’s size is system-
atically depleted as operations are being performed, and can help save forwarding 
time and bandwidth when hoping across the WSN. 
The processor performs the operation indicated by the head, whose outcome is  
determined as Boolean value (i.e., its execution is either successfully completed, or 
not). This outcome is employed to make decisions that affect the subsequent execu-
tion of the distributed process, as noted before. The agent execution process is halted 
if any of the following conditions occur: (1) an operation yields an unsuccessful out-
come, (2) an agent-hop operation is encountered, or (3) explicit process termination is 
indicated. In the first case, the agent’s tail is discarded and the agent simply termi-
nates executing, unless the head is contained within a language construct that instructs 
the parser to proceed otherwise. If the operation is successful, then the parser sends  
the next operation to the execution block and the process continues as defined by the 
agent’s codes. In the second case, the agent instructs the execution block to migrate 
the agent to another node, and so the tail is sent to the dispatcher block for subsequent 
forwarding to another node or set of nodes. In the third case, the agent may simply 
instruct the interpreter to explicitly halt the current process execution as needed. The 
process sequence in Wiseman’s architecture is shown in Fig. 2. 
An agent may hop to a node or set of nodes that are associated by sharing a single-
character label used as a unique identifier. If the agent’s codes specify a hop through 
one of these labelled (virtual) paths, then the dispatcher first ensures that the hop is 
actually possible by looking up the corresponding label entry in a local table that 
contains a list of the neighbouring nodes associated to it. The agent will be dispatched  
 

370 
S. González-Valenzuela, M. Chen, and V.C.M. Leung 
 
Fig. 2. Agent processing sequence in Wiseman 
out of the interpreter only if the corresponding label exists in the table. Otherwise, the 
agent is discarded. However, the agent may also be unicast to a specific node, or 
broadcast if no particular destination is specified. Finally, the dispatcher signals the 
parser once the agent has been forwarded, so that the next agent in the incoming 
queue can be processed, if one exists.  
Another novel feature of Wiseman is defined by its metamorphic capability. Since 
Wiseman agents are transmitted and processed in their raw text-string from, the archi-
tecture effectively allows the interpreter to substitute portions of the agent’s code with 
other codes. This characteristic introduces a degree of flexibility unmatched by exist-
ing agent approaches in WSNs. For example, a target-tracking agent may initially 
carry and execute the corresponding code of an energy-efficient algorithm that works 
best for slow moving objects. However, if the object’s rate of mobility increases, then 
the agent may instruct a WSN node to replace its target tracking algorithm with one 
that is more energy-demanding, but otherwise necessary to keep up with fast-moving 
objects. 
4   Language Constructs 
Wiseman’s constructs are simplified versions of Wave’s original operators, variables, 
rules, and delimiters, so that they can be employed in WSN nodes: 
4.1   Variables 
The Wiseman interpreter supports three kinds of fixed-type variables, all of which 
employ pre-assigned memory segments in the local node. The first type is coined as 
Numeric, represented by the letter N, and is predefined as being of floating point type. 
The second kind is the Character variable, intended for use with single characters 
through the letter C. Both of these variable types are semantically similar to public 
variables defined in object-oriented programming, meaning that all agents that arrive 
to the interpreter have access to them. In addition, agents carry with them Mobile 
variables, which are accessed through the letter M. Mobile variables’ role resembles 

 
Design, Implementation and Case Study of WISEMAN 
371 
that of private variables in object-oriented programming. Thus, manipulation of an 
agent’s own Mobile variables has no effect on other agents’ Mobile variables. Simi-
larly, the manipulation of Numeric and Character variables at the local node has no 
effect on the variables of remote nodes. However, all variables are expected to main-
tain their semantic meaning across the network according to how they are individually 
manipulated by programmers through the agents. Agents always carry with them 
associated Mobile variables, which are temporarily stored in predefined memory loca-
tions when visiting a node. The interpreter also implements the Clipboard variable B 
to temporarily store data. The execution environment also defines three extra Envi-
ronmental variables. Identity I is a read-only variable, whose content is defined by the 
local node’s identification number (i.e., 1, 2 …) The Predecessor P contains the iden-
tification number of the node where the agent being processed hopped from. Finally, 
the Link variable L holds the label of the virtual link through which the agent arrived 
from. The interpreter’s dispatcher appends these variables to the agent’s control field 
as soon as it arrives from the wireless channel. 
4.2   Operators 
Wiseman defines a mix of general purpose and system-specific operators. For  
instance, standard arithmetic operators are provided to allow simple calculations at 
the nodes (i.e., +, -, *, / and =). Ordinary comparison operators that return Boolean 
values that agents evaluate are also supported (i.e., <, <=, ==, =>, > and !=). The hop 
operator is employed to indicate that the agent needs to be forwarded either to the 
node specified in the right-hand side of the # character, or through the virtual link 
specified in its left-hand side that is associated with a certain subset of adjacent nodes. 
For the later case, this operator provides the functionality of automatically cloning the 
agent with as many copies as outgoing virtual links exist to the corresponding nodes. 
That is, if there are 3 such virtual links labelled with the letter s, then an identical 
number of agent copies will be forwarded by the dispatcher. Moreover, if a hop op-
eration is met by the interpreter when processing the codes, then the agent is  
forwarded and execution resumes at the next operation where the process had been 
previously suspended. This functionality provides Wiseman with a basic form of 
strong mobility that does not require any form of program counter or execution state 
that needs to be forwarded with the agent. Alternatively, a copy of the agent may be 
locally broadcast to all immediate neighbours by employing the @ operator. The 
execution operator $ indicates to the interpreter that a local function is to be called as 
specified by its left- and right-hand side parameters. The code injection operator ^ 
indicates the insertion of a locally stored code(s) segment into the agents structure. 
Finally, the halt operator ! indicates the explicit termination of the current agent with 
success if the right-side operand is 1 or failure if the operand is 0.  
4.3   Rules 
In Wiseman, the Repeat rule R indicates that codes embraced by the corresponding 
delimiters will be continuously executed. However, Wiseman processes cycling codes 
by extracting them from the delimiters and re-inserting them before the original Repeat 
construct. Therefore, an agent segment that possesses the corresponding structure for 

372 
S. González-Valenzuela, M. Chen, and V.C.M. Leung 
repeating code R{…} yields the modified structure …;R{…}. This process can be re-
peated consecutively until a certain condition is met. In addition, Or O and And A rules 
are defined as a way to manipulate execution of the agent by testing whether the code 
embraced within square brackets yields a true or false value for every code segment it 
includes. Therefore, an O[…;…;…] construct indicates that the code segments delim-
ited by semicolons are to be sequentially executed, stopping as soon as one of these 
segments results in a true value. Otherwise, the Or rule returns a false value and the 
whole agent’s process stops. A similar logic applies for the And rule, except that all of 
the segments must return a true value in order for the whole construct to succeed.  
4.4   Delimiters 
The main delimiter employed to separate code segments is the semicolon. In addition, 
round, square and curly brackets are designated to delimit code segments whose exe-
cution depends on a rule construct, as explained before. Distinct types of brackets are 
employed since they facilitate the parser’s task when tokenizing nested code segments 
prior to being processed (i.e., R{…O[…(…)…]…}). The use of a single type of 
bracket would have implied significantly more parsing functionalities, and therefore, 
added processing overhead. 
5   Practical Implementation Aspects 
Wiseman was initially evaluated employing the OMNeT++ Discrete Event Simulator 
[13] to verify the correctness of the design after undergoing significant changes from 
an earlier system proposal [14]. This preliminary evaluation step was crucial in 
streamlining its implementation over actual hardware devices given the difficulty of 
debugging firmware programs. After verification, Wiseman was ported to the NesC 
language and subsequently improved for more efficient operation over Crossbow 
Micaz [15]. The NesC programming language employed to code TinyOS ver. 1.1 
programs is in fact a modified version of the C language [16]. We decided to employ 
this wireless sensor platform since it provides an ideal example of a severely-
constrained hardware device type whereby our proposed system could be put to the 
test. In particular, these motes have 128Kbytes of instruction memory and 4Kbytes of 
data memory. Therefore, developing an agent system for this hardware platform is 
challenging due primarily to the limited amount of memory space. A mote attached to 
a Crossbow MIB510 interface board is used as a data sink node, whereas the MIB510 
itself interfaces data between the WSN and a regular laptop computer. Wiseman spans 
approximately 2400 lines of NesC code divided into modules that reflect the system 
architecture shown in Fig. 1. An additional module that includes a few uncommon 
string manipulation functions was also incorporated as required by the parser to proc-
ess agent codes. Wiseman can be currently obtained from [17]. 
As mentioned before, Wiseman’s binary image occupies 19Kbytes and just over 
3Kbytes of RAM space to operate in its current form. A good portion of the RAM 
space usage reflects the space reserved to manipulate agents that occupy a maximum 
of 170 bytes. Depending on the type of agent program created, this amount of re-
served memory suffices for our experiments. However, for agents that incorporate the 

 
Design, Implementation and Case Study of WISEMAN 
373 
Repeat rule R, we needed to ensure that there was enough memory space since this 
construct may effectively duplicate the size of the agent. For example, an agent with 
codes “R{…;#1}” yields the string “…;#1;R{#1;…}”, or simply “#1;R{…}” just be-
fore the agent is set to hop to node 1. However “R{#1;…}” leads to “#1;…;R{#1;…}”, 
nearly doubling the agent code’s size before being forwarded to node 1. It is also 
evident that agents can be larger than the data payload of the Zigbee packets used by 
the Micaz to communicate with other nodes. Consequently, we implemented a simple 
data forwarding mechanism that follows the signalling sequence illustrated in Fig. 3. 
 
Fig. 3. Forwarding sequence of Wiseman agent segments 
As seen here, every node wishing to forward an agent first must request permission 
to initiate the agent migration process by sending a Request-To-Send (RTS) packet to 
the intended destination node to ensure that it is currently available, since it might 
possibly be involved in another agent forwarding process with a different node. Sub-
sequent permission to send packets is granted upon receiving a Clear-To-Send (CTS) 
acknowledgement from the destination. These session initiation and control packets 
are comprised by three fields, which include: a source node ID number, a randomly 
generated session number, and the current segment number. CTS packets always 
indicate the segment number the target node is expecting next. Any discrepancy be-
tween the expected segment number, the session number, or the source node identifier 
resets the process and all of the previous segments are discarded. This procedure is 
done to ensure agent forwarding correctness and to avoid possible confusions with 
packets that may arrive from other nodes. A timeout process that expires after 300mS 
is always initiated at the sender’s side, and a maximum of 3 transmission attempts 
may take place. If unsuccessful, the interpreter first discards the current agent and 
then attempts to transmit the next agent in the outgoing agent queue, which may be 
destined to a different node. To this regard, two different agent queues are kept: one 
that holds a maximum of 3 incoming agents, and one for a maximum of 5 outgoing 
agents. This signifies that the interpreter may receive and queue up to 3 agents for 
future processing if it is currently busy with another agent. If the incoming queue is 
full, then additional RTS signals received are left unanswered. In addition to this, 

374 
S. González-Valenzuela, M. Chen, and V.C.M. Leung 
since the receiving end implements no timeout procedure during an agent forwarding 
process, if the current forwarding process fails, then the receiver will keep its last 
session values. Later, when another node attempts to begin transmissions, the old 
values at the receiver will trigger an immediate failure, and the current session will be 
reset. In this case, the sender will initiate the forwarding packets until the second 
attempt 300mS later. Agents are always forwarded according to the values received as 
parameters in a hop operation (#). Currently, no routing functionalities are incorpo-
rated into the system. Instead, the WSN operator may create virtual multicast trees by 
explicitly labelling links between nodes. The benefits of this approach will become 
apparent in the next section, which explains a sample deployment scenario where 
Wiseman can be conceivably employed. 
6   An Example Application: Early Detection of Forest Fires 
6.1   Rationale 
As an illustrative example to exhibit the capability of Wiseman system, we consider 
an application in the prevention of forest fires. Forest fires, also known as wild fires, 
are often uncontrolled events that occur in natural settings and cause significant dam-
age to both the environment, and to man-made infrastructure. Glitho et al. [18] have 
already addressed the weather monitoring issue, and Fok et al. [5] have addressed the 
issue of tracking fire while it is spreading. By comparison, this application study  
considers early detection/prevention of an unwanted event, since this can reduce dam-
age, and perhaps even human and wild-life casualties. Forest fires usually happen 
when two main conditions meet simultaneously: high temperature and low humidity. 
As exemplified in Fig. 4, a fictitious forest area is separated into three sections: A, B 
and C. We propose realizing early detection of forest fires by dividing the task into 
two stages. In the first stage, we collect temperatures for each forest section, in which 
the corresponding temperature sensor node (e.g., 1, 2 or 3 in Fig. 4) is regarded as the 
cluster-head. If the temperature is higher than a certain critical threshold, then  
 
 
Fig. 4. Wiseman for early detection of forest fires: (a) routine temperature checking; (b)  
primary temperature monitoring task; (c) secondary humidity monitoring task 

 
Design, Implementation and Case Study of WISEMAN 
375 
the second stage of the task is triggered. In this second stage, the humidity readings of 
the corresponding forest section are collected. If one of these readings is smaller than 
a certain threshold, then an alert signals is raised to inform personnel of the current 
hazardous situation. 
During normal circumstances, a mobile agent will collect temperature for each moni-
tored area in the path, as shown in Fig. 4 (a). The agent’s migration itinerary for the first 
stage is planned according to the priority of different forest areas. In the case shown in 
Fig. 4, forest area A has the highest priority, which means the trees in this area are the 
easiest to catch fire, and/or that such tree species might be the most precious. 
Occasionally, an abnormal reading may be detected by the mobile agent, which 
means that the temperature in a certain forest area exceeds a certain critical threshold. 
The forest section with abnormal temperature/humidity readings is circled, as shown 
in Fig. 4 (b) and (c). At this moment, there are three schemes that can be employed to 
initiate the task of stage 2: 
Scheme A: The current agent does not know how to handle the special event since 
there is no corresponding action script carried with it. Thus, the agent returns to the 
sink node immediately, which in turn dispatches the second agent whose task is to 
obtain the minimum humidity reading.  
Scheme B: The current agent already carries the action script to handle the emergent 
case. Thus, the agent will perform the task for stage 2 starting from node 2, as shown 
in Fig. 4(c). 
Scheme C: The current agent does not carry the processing code to handle the special 
case. Instead, it retrieves an action script already stored in node 2, and it replaces the 
old action script with the new one. This strategy enables the agent to obtain the mo-
bile codes that handle the emergent case locally. The agent itinerary is the same as 
that of Scheme B. However, the energy consumption incurred while otherwise trans-
mitting the action script portion that is only useful when handling the emergent event 
is avoided, and the corresponding agent migration delay is decreased as well.  
Note that in our previous agent-based approaches [8, 9] only Scheme A and Scheme 
B were supported. This is because the itinerary must be planned by the sink node in 
advance. Thus, two agents are dispatched in Scheme A that individually carry the 
possible itineraries for the temperature checking path, and for the emergent humidity 
data collecting task. By comparison, Wiseman enables changes on demand (e.g., at 
node 2 in Fig. 4) in the pre-defined path assigned to an agent, as seen in Scheme C. 
6.2   Experimental Setup 
Fig. 5 shows the four topologies used in our experiments. Compared to the scenario 
shown in Fig. 4, we incorporate humidity sensor nodes in the hot spot assigned to 
forest section 2 of Fig. 5(a), and omit them in the other forest sections (1 and 3). In 
this sample scenario, node 2 is the cluster-head of the area comprised by sensor nodes 
6, 7, 8 and 9. In Fig. 5(b), we add two more humidity sensor nodes to the hot spot in 
order to depict a larger forest area, whereas topology 3 in Fig. 5(c) adds two extra 
temperature sensor nodes compared to topology 1. Finally, we add two more humidity 
sensor nodes in Fig. 5(d) (compared with topology 3). 

376 
S. González-Valenzuela, M. Chen, and V.C.M. Leung 
 
Fig. 5. Topologies employed for our experiments 
Table 1 shows the agents are that were employed to set up the environment that the 
agents in Table 2 will encounter in accordance to our experiment setting for Schemes 
B and C. In these cases, the task of the agents in Table 1 is to set up labelled paths for 
subsequent agent navigation, creating the type of virtual links previously described. 
Links in the main temperature-reading circuit are labelled with the character a by 
employing the corresponding link assignment operation L=a before migrating to 
another node, whereas links in the humidity-reading circuit are labelled with the char-
acter b. Once these virtual paths are set, other agents can use them as they traverse the 
network. In addition, agents toggle-on the green LEDs as a visual aid to verify their 
itinerary through the WSN by means of the l$n operation. In this operation, character 
l on the left-hand side signifies an LED operation, and character n on the right-hand 
side signifies that the green LED is toggled-on. It can also be seen that the inter-
preter’s Clipboard B is set to a fictitious value of 45 at either node 2 or 3 depending to 
the current topology being employed, which signifies that the temperature at that 
particular node has reached the specified value. Finally, the numbers on the right-
hand side of the hop operator indicate the identity of the node to which the agent is set 
to migrate next (e.g., #1 migrates the agent to node 1). In accordance to the way 
agents are processed, all operations that have been already executed are removed from 
the agent’s code, and only the trailing operations are migrated (i.e., the tail of the 
agent, as described in Section 3). 
Table 1. Environment-setting agents 
Topology 
Agent Script for Itinerary Labelling 
1 
l$n;L=a;#1;l$n;#2;l$n;B=45;L=b;#6;l$n;#7;l$n;#8;l$n;#9;l$n;#2;L=a;#3;l$n;#0;l$n 
2 
l$n;L=a;#1;l$n;#2;l$n;B=45;L=b;#6;l$n;#7;l$n;#8;l$n;#9;l$n;#10;l$n;#11;l$n;#2;L=a;#3;l
$n;#0;l$n 
3 
l$n;L=a;#1;l$n;#2;l$n;#3;l$n;B=45;L=b;#6;l$n;#7;l$n;#8;l$n;#9;l$n;#3;L=a;#4;l$n;#5;l$n;
#0;l$n 
4 
l$n;L=a;#1;l$n;#2;l$n;#3;l$n;B=45;L=b;#6;l$n;#7;l$n;#8;l$n;#9;l$n;#10;l$n;#11;l$n;#3;L
=a;#4;l$n;#5;l$n;#0;l$n 

 
Design, Implementation and Case Study of WISEMAN 
377 
Table 2. Agents that implement distinct migration strategies 
Scheme 
Agent 
Script 
1 
l$n;M0=1;R{#M0;I!=0;M0+1;l$n;r$t;O[B<40;M1=I];O[M0<6;M0=0]} 
A 
2 
l$d;#1;#2;#3;M0=6;R{#M0;M0+1;l$d;I!=0;O[(I==9;M0=3);(I==5;M0=0);!1]; 
r$h;O[B>20;M1=I]} 
B 
1 
a#;R{l$w;I!=0;O[(I<4;r$t;B>40;M2<1;M2=1;M0=I;b#);(I>3;r$h;B<20;M1=I;!0)
;a#;b#]} 
1 
R{a#;l$w;I!=0;O[(B>40;M0=I;2^0);!1]} 
C 
2 
b#;R{l$d;I!=0;O[(I>5;r$h;B<20;M0=I;!0);a#;b#]} 
 
According to our experiment setup, Agent 1 (59 bytes long) in Scheme A explores 
the cluster-head circuit comprised by nodes 1-3 (topologies 1 and 2 in Fig. 5) or 1-5 
(for topologies 3 and 4 in Fig. 5). Since this scheme does not rely on virtual links, the 
value of mobile variable M0 is sequentially incremented (M0+1), and is then em-
ployed to determine the next agent hop destination once the current repeat rule cycles 
(#M0). Upon reaching the corresponding node, the agent toggles the green LED and 
reads the locally sensed temperature (l$n;r$t). If the temperature is less than the 
specified threshold (B<40), then the execution thread continues at the second Or rule. 
Otherwise, the ID of the local node is stored in mobile variable M1 (M1=I) to be 
returned to the sink node. Finally, the value of variable M0 will be set to 0 at the end 
of the itinerary, and the I!=0 operation will ensure that Agent 1 terminates when it 
gets back to the sink (ID 0). On the other hand, Agent 2 is dispatched in response to 
the value in M1 brought by Agent 1. It can be seen that the initial itinerary of Agent 2 
(85 bytes long) is set deterministically for topology 2. Here, the agent enters the hu-
midity-sensing circuit at node 3, traversing nodes 6 through 9, and exiting back to 
node 3 as indicated by the value in M0, which is in turn modified by the preceding 
operations (O[(I==9;M0=3);(I==5; M0=0);!1)]. The sequence of events is similar as 
before, and M1 will be set to the value of the current node’s ID if the humidity read-
ing exceeds a predefined threshold (r$h;O[B>20;M1=I]). 
In contrast to Scheme A, Scheme B relies on a virtual path previously set by a  
preceding agent (according to the current topology, as shown in Table 1). In this par-
ticular experiment, the path-setting agent needs to be executed only once for all sub-
sequent agents to use. We can see that the chain of operations is fairly similar to those 
agents in Scheme A, with the main difference that hoping is made through virtual links 
labeled with letter a for the main temperature-reading circuit, and with letter b for the 
humidity-sensing circuit. To this regard, the label identifier is set on the left-hand side 
of the hop operator (i.e., a#, or b#), and the hoping sequence within these circuits is 
controlled by the Or rules. Consequently, a single agent (79 bytes long) is needed for 
this scheme. Finally, Scheme C, employs the local injection operator (^) that is used 
by Agent 1 (36 bytes long) when the temperature reading exceeds the predefined 
threshold. Therefore, Agent 1 does not need to carry the associated code that specifies 
when to switch its navigation path to labeled circuits a or b when needed. Instead, a 
second agent (id = 0) will be injected with a 2-second delay (2^0) to the humidity-
sensing circuit from the node whose temperature value exceeded the corresponding 
threshold. Thus, Agent B (46 bytes long) needs to be already available at predefined 

378 
S. González-Valenzuela, M. Chen, and V.C.M. Leung 
WSN nodes. Each of these approaches addresses the event-prevention objective pro-
posed before, and they have their own advantages and disadvantages as evidenced by 
the results obtained through the experiments that we discuss next. 
7   Experiment Results 
We have conducted experiments for the four topologies described in Section 6.2. For 
each topology, this section will evaluate the performance of Schemes A, B and C in 
terms of task duration and incurred packet overhead. The task duration (or itinerary 
completion delay) indicates the time at which the sink node dispatched the first agent 
to the time when the task of the last stage is finished.  
0
1
2
3
4
5
6
7
Topology 1
Topology 2
Topology 3
Topology 4
Task Duration (seconds)
Scenario
Scheme A
Scheme B
Scheme C
 
Fig. 6. Itinerary completion delay 
As shown in Fig. 6, for each scheme, the task duration is the lowest in Topology 1, 
and it reaches the maximum value in Topology 4. This is because Topology 1 and 4 
yield the shortest and the longest agent itineraries respectively, and the task duration 
is proportional to the length of the itinerary. We can also observe in Fig. 6 that Scheme 
A always causes the largest task duration among the three schemes in each topology. 
This is because two agents are dispatched to perform the task in Scheme A, as illus-
trated in Section 6.1. Compared to Scheme B, Scheme C sees a decreased task dura-
tion since this smaller action script is stored locally. 
Table 3 illustrates the total number of Zigbee packets incurred by each scheme, and 
the results for individual agents 1 and 2 (denoted by A1 and A2) are shown in brackets 
below each corresponding sum for schemes A and C. The overhead incurred by the 
environment-setting agents is not accounted for. While it is evident that Scheme C per-
forms better than A and B, there needs to be a mechanism that allows locally existing 
agents to be modified at will to fully exploit the capabilities of the system. It is also 
evident that the label-based approach is the key to achieving performance improvements 
in terms of both itinerary completion delay and bandwidth used (number of packets). 

 
Design, Implementation and Case Study of WISEMAN 
379 
Table 3. Number of Zigbee packets incurred by the agents in each scheme 
Scheme 
Topology 1 
Topology 2 
Topology 3 
Topology 4 
A 
161 
[44(A1)+117(A2)] 
187 
[44(A1)+143(A2)] 
209 
[66(A1)+143(A2)] 
235 
[66(A1)+169(A2)] 
B 
135 
165 
165 
195 
C 
99 
[36(A1)+63(A2)] 
117 
[36(A1)+81(A2)] 
126 
[54(A1)+72(A2)] 
144 
[54(A1)+90(A2)] 
8   Conclusions 
We have presented Wiseman, a mobile code approach for WSN. We described 
Wiseman’s architecture, its language constructs, and its features as a suitable system 
for use in WSNs. We also described important implementation and programming 
details of our scheme. The design of our system is based on an earlier implementation 
of the Wave system for mobile processing in wired networks. However, a number of 
changes were introduced as required by the scarcity of hardware and energy resources 
that characterize WSN devices. Among these changes are: elimination of dynamic 
memory allocation, redefinition of the language constructs, simplification of the in-
terpreter’s architecture, and simplification of the agents’ program structure. Wiseman 
has been implemented and tested in the Crossbow Micaz running TinyOS ver. 1.1, 
which yielded a binary image of only 19Kbytes and RAM usage of around 3Kbytes. 
The benefits of employing Wiseman’s agents were readily evident as shown by their 
ultra-compact size, leading to very low bandwidth usage. In addition, Wiseman facili-
tates the creation of overlay networks, which also helps shorten the overall size of the 
agents and reduces operation overhead. 
Acknowledgments. This project was supported by the National Sciences and Engineer-
ing Research Council of the Canadian Government under grant STPGP 322208-05. 
References 
1. Bellavista, P., Corradi, A., Stefanelli, C.: Mobile Agent Middleware for Mobile Comput-
ing. IEEE Computer 34(3) (2001) 
2. Hui, J., Culler, D.: The Dynamic Behavior of a Data Dissemination Protocol for Network 
Programming at Scale. In: Proceedings of the 2nd International Conference on Embedded 
Networked Sensor Systems, Baltimore, USA (2004) 
3. Liu, T., Martonosi, M.: Impala: A Middleware System for Managing Autonomic, Parallel 
Sensor Systems. In: Proceedings of ACM SIGPLAN, San Diego, USA (June 2003) 
4. Levis, P., Culler, D.: Maté: A Tiny Virtual Machine for Sensor Networks. In: Proceedings 
of the 10th International Conference on Architectural Support for Programming Languages 
and Operating Systems, San Jose, USA (October 2002) 
5. Fok, C.-L., Roman, G.-C., Lu, C.: Rapid Development and Flexible Deployment of Adap-
tive Wireless Sensor Network Applications. In: Proceedings of the 24th International Con-
ference on Distributed Computing Systems (ICDCS), Columbus, USA (June 2005) 

380 
S. González-Valenzuela, M. Chen, and V.C.M. Leung 
6. Fok, C.-L., Roman, G.-C., Lu, C.: Mobile Agent Middleware for Sensor Networks: An 
Application Case Study. In: Proc. Of the 4th Int’l Conf. Information Processing in Sensor 
Networks. IEEE Press, Los Alamitos (2005) 
7. Chen, M., Gonzalez-Valenzuela, S., Leung, V.C.M.: Applications and Design Issues of 
Mobile Agents in Wireless Sensor Networks. IEEE Wireless Communications 14(6), 20–
26 (2007) 
8. Chen, M., Kwon, T.K., Yuan, Y., Choi, Y.H., Leung, V.C.M.: Mobile Agent Based Wire-
less Sensor Networks. Journal of Computers 1(1) (2006) 
9. Chen, M., Kwon, T.K., Yuan, Y., Choi, Y.H., Leung, V.C.M.: Mobile-agent-based Di-
rected Diffusion (MADD) in Wireless Sensor Networks. In: EURASIP Journal on Applied 
Signal Processing, vol. 2007(1) (January 2007) 
10. Qi, H., Iyengar, S.S., Chakrabarty, K.: Multiresolution Data Integration Using Mobile 
Agents in Distributed Sensor Networks. IEEE Transactions on Systems, Man and Cyber-
netics – Part C: Applications and Reviews 31(3), 383–391 (2001) 
11. Sapaty, P.: A Wave Language for Parallel Processing of Semantic Networks. Computers 
and Artificial Intelligence 5(4) (1986) 
12. Sapaty, P.: Mobile Processing in Distributed and Open Environments. John Wiley & Sons, 
Chichester (2000) 
13. The OMNeT++ Discrete Event Simulator, http://www.omnetpp.org 
14. González-Valenzuela, S., Vuong, S.T., Leung, V.C.M.: A Mobile Code Platform for Dis-
tributed Task Control in Wireless Sensor Networks. In: Proceedings of 6th ACM MobiDE, 
Chicago, USA (2006) 
15. Crossbow Technology, http://www.xbow.com 
16. TinyOS for wireless embedded sensor networks, http://www.tinyos.net  
17. The Wiseman Agent System for Sensor Networks,  
  http://www.ece.ubc.ca/~sergio/wiseman 
18. Glitho, R., Olougouna, E., Pierre, S.: Mobile Agents and Their Use for Information Re-
trieval: A Brief Overview and an Elaborate Case Study. IEEE Network Magazine 16(1) 
(2002) 
 
 
 
 

Developing and Benchmarking Native Linux
Applications on Android
Leonid Batyuk, Aubrey-Derrick Schmidt, Hans-Gunther Schmidt,
Ahmet Camtepe, and Sahin Albayrak
Technische Universit¨at Berlin, 10587 Berlin, Germany
{aubrey.schmidt,leonid.batyuk,hans-gunther.schmidt,ahmet.camtepe,
sahin.albayrak}@dai-labor.de
http://www.dai-labor.de
Abstract. Smartphones get increasingly popular where more and more
smartphone platforms emerge. Special attention was gained by the open
source platform Android which was presented by the Open Handset Al-
liance (OHA) hosting members like Google, Motorola, and HTC. An-
droid uses a Linux kernel and a stripped-down userland with a custom
Java VM set on top. The resulting system joins the advantages of both
environments, while third-parties are intended to develop only Java ap-
plications at the moment.
In this work, we present the beneﬁt of using native applications in
Android. Android includes a fully functional Linux, and using it for
heavy computational tasks when developing applications can bring in
substantional performance increase. We present how to develop native
applications and software components, as well as how to let Linux appli-
cations and components communicate with Java programs. Additionally,
we present performance measurements of native and Java applications
executing identical tasks.
The results show that native C applications can be up to 30 times as
fast as an identical algorithm running in Dalvik VM. Java applications
can become a speed-up of up to 10 times if utilizing JNI.
Keywords: software, performance, smartphones, android, C, Java.
1
Introduction
With the growing customer interest in smartphones the number of available
platforms increases steadily. Several open platforms emerged in the last years,
including OpenMoko, LiMo, Mobilinux and, the most hyped one, Android. The
latter has been presented by the Open Handset Alliance (OHA) where Google
is one member beside others, including carriers like T-Mobile and Telef´onica,
and handset manufacturers like Motorola and HTC. Android’s source code is
freely available under terms of several open source licenses, which makes it an
interesting open mobile platform. Android is modiﬁable and thus not limited to
smartphones - it targets mobile internet devices and netbooks, too.
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 381–392, 2009.
c
⃝Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

382
L. Batyuk et al.
The key feature of Android is that is has a Java application framework on
top of an Linux 2.6 Kernel - this construction uniﬁes the mature security model
of Linux with the convenient development in Java language. Most of the appli-
cations developed for Android are intentionally Java programs - but Linux-level
C/C++ programming is possible, too.
The question arises whether it makes always sense to stay on the Java layer,
or cases can be identiﬁed in which native C/C++ code is preferable. A very inter-
esting aspect is the performance of computation - time-critical applications or
software components which involve heavy computation might be moved to Linux
layer for improving the execution speed. Since the graphical user interface is only
accessible from Java framework (unless the user utilizes a terminal emulator),
another resulting question is how to provide access to the information produced
by native software components.
In this paper we will investigate the beneﬁt of moving applications to the
Linux layer of Android. We present mechanisms which enable communication
between native and Java applications. This is of special interest since the OHA
does not provide an oﬃcially supported way for doing so. Additionally, we present
a performance comparison of Java and native Linux applications in Android
for diﬀerent kinds of tasks. This will help software designers to create eﬃcient
Android applications.
This work is structured as follows: in Section 2, we give an overview of the
Android platform. In Section 3, we provide a summary on methods and tools
which can be utilized in order to build native applications for the Linux layer in
Android. In Section 4, we analyze the performance of the methods described in
Section 3. In Section 5, we draw conclusions and describe viable future work.
2
Android
Following the descriptions of the Open Handset Alliance (OHA) [1], Android
represents a software stack including an operating system, middleware, and ap-
plications. A signiﬁcant aspect of this software stack is that Android uses Linux
2.6 as underlying operating system for core system services such as security,
memory management, process management, network stack, and driver model.
On top of Linux OHA placed a modiﬁed Java interpreter and runtime envi-
ronment called Dalvik virtual machine (Dalvik VM). Intentionally, applications
developed for Android will only use the Java Dalvik VM for execution. A key
feature of this VM is the ability to run several instances of itself, each applica-
tion in its own process. Executables for the Dalvik VM (.dex ﬁles) are optimized
for minimal footprint where the Dalvik VM uses the threading and memory
management functionality of the underlying Linux system.
For developing Android applications, the OHA provides an SDK with
full access to the same framework APIs used by the core applications.
The corresponding application architecture is intended to simplify the reuse of
already developed components. In turn, this feature enables developers to replace

Developing and Benchmarking Native Linux Applications on Android
383
(b) T-Mobile G1 [14]
Application
Application Framework
Linux
Libraries
Dalvik VM
(a) Archtitecture [1]
Fig. 1. Android
already existing components. Android applications are developed using the Java
programming language. Therefore, Android includes a set of core libraries that
mostly match the core libraries of the Java standard edition. Additional libraries
were added to provide more convenient support for mobile needs, such as blue-
tooth and camera support.
The ﬁrst phone running a port of Android is G1, which has been manufactured
by HTC and introduced by T-Mobile in the USA. More devices running Android,
including unoﬃcial ports to existing hardware, are to be awaited since the source
code of Android has been released under terms of free software licenses.
3
Software Engineering Aspects of Android
In this section we discuss the possible ways to develop software for the Android
platform. In 3.1, we provide an overview on development of Java applications.
Section 3.2 describes tools and techniques used to compile native applications. 3.3
contains additional information on Android speciﬁcs and possible workarounds.
3.1
Android Java Application Development
Diﬀerent to most other mobile platforms, development of user applications for
Android is pretty straight-forward. First of all, you need to download the SDK
from Google page [1]. If you prefer to use an IDE for development, then you have
to obtain Eclipse [6] or Netbeans [7]. For improving the development process,
Eclipse users can download a plugin called Android Developer Tools (ADT)
[1]. The SDK includes a built-in emulator that supports most of the important
interfaces and can be used for application testing. If testing is successful, devel-
opers have to sign their application for making it available to devices. Android
applications are packaged in APK ﬁles, which contain the executable bytecode,
necessary resources (layout schemes, images, raw binary data), and application
metadata. The metadata includes the name of the application, its version and
the permissions which the program requires in order to run, such as access to
contact database, using the internet connection or even making calls. Then, the

384
L. Batyuk et al.
signed APK can be distributed to end devices through Android Market [3] - an
internet platform which is open for developers and promises low rejection rates
on new software. At this point it is important to mention that the signing of the
application is, contrary to the Symbian platform, free of any cost and is primarily
intended to make the distributor identiﬁable, and not to prevent software from
unsubscribed developers from running on end devices.
3.2
Android Linux Application Development
Android provides a complete operating system running currently on the ARM-
Architecture. Compiling software for ARM requires a speciﬁc environment. In
following sections, we will describe two diﬀerent ways of compiling software suc-
cessfully within an ARM-compatible environment. Additionally, a list of working
open source security tools running on Android can be found in our previous work
[15].
Base environment. Ubuntu i686 GNU/Linux [10], a Linux-distribution pro-
vided and supported by Canonical, provides the basis for all further steps. Based
on the Intel-architecture, a vast amount of tools, especially for creating and com-
piling software, can be obtained through Ubuntu’s package repositories. Addi-
tional, non-standard, package repositories can be easily integrated.
GNU toolchain for ARM processors. CodeSourcery [8] oﬀers the cross-
compile toolchain G++ Lite that can be used to cross-compile source code for
ARM on various architectures other than ARM. Consisting of C/C++-compiler,
linker, libraries, several tools for debugging and more, it oﬀers everything re-
quired for compiling tools that can be executed in an Android environment.
Providing the required information during conﬁguration run (passing parame-
ters to use a diﬀerent compiler, compile for a diﬀerent architecture, additional
usual compile parameters), there is little to no diﬀerence between compiling
source code for ARM or for Intel architectures. Once compiled, the software
needs to be transferred to the Android environment in order to test its function-
ality. This might be, at some times, a tiring task, and may be even restricted
on the end device. Therefore, a second way to compile source code for ARM is
presented in the next section.
Scratchbox cross-compilation toolkit. Scratchbox [9] not only provides the
necessary compilers and linkers, it also provides a complete environment simu-
lating an ARM platform-based operating system. All tools compiled within this
environment can be tested immediately giving a very fast feedback to the de-
veloper. Once, the Ubuntu package repository has been extended by the oﬃcial
Scratchbox repository, all necessary ﬁles for Scratchbox can be easily installed
via Ubuntu’s package management tools. Scratchbox oﬀers a wide variety of pos-
sible compilers, in diﬀerent versions and characteristics. After installation, a user
account has to be created for use within the Scratchbox environment. Shortly

Developing and Benchmarking Native Linux Applications on Android
385
after logging into the new environment, preliminary steps are required: select
the desired compiler and add additional tools if wanted (strace, gdb). From
this point, source code can be compiled as usual, no speciﬁc parameters have to
be provided. The host and build type are distinguished automatically, standard
locations for installing binaries, libraries, etc. are provided. As long as the given
source code is ARM-compatible, it will most likely compile within Scratchbox
without any signiﬁcant problems. Having successfully compiled all ﬁles, these
can be packed into an archive for being transferred to the Android environment
for deployment.
3.3
Important Facts for Native Development
Filesystem speciﬁcs. Google provides an ARM Linux with a ﬁlesystem layout
which greatly diﬀers from usual Linux ﬁlesystem layouts:
– System relevant ﬁles are found in the System image, mounted to /system
(binaries are, for the most part, found in /system/bin, libraries reside in
/system/lib, conﬁguration ﬁles in /system/etc, etc.)
– User data relevant ﬁles reside within the user data image, mounted to /data.
Handling these changes does not require much adaptation.
All-in-one binary toolbox. Furthermore, Google provides standard Linux
tools with the help of the all-in-one binary toolbox. It only oﬀers a very re-
stricted set of tools making it at certain times hard to accomplish standard
procedures. Special care has to be taken here when including shell scripts that
rely upon various Linux system tools, since, if at all available, their behaviour
would probably diﬀer from what one would expect.
Installing Busybox [11], also a all-in-one static binary oﬀering numerous stan-
dard Linux system tools, helps greatly, but is restricted on the G1.
Location-awareness of tools. Certain tools within Android are location-
aware. A speciﬁc action, e.g. changing ﬁle permissions or ownership, will execute
successfully without any further notice in /system. The same action, executed
for ﬁles in your SD-Card-image will simply fail. This implies that tools can only
be executed from within /system or /data. Adding and executing tools via a
freely resizeable SD-Card-image will not be possible.
Disk space limitations. /data and /system oﬀer only very limited ﬂexibility
as they are both limited to a maximum ﬁlesystem size of 65Mbytes. While in a
standard, untouched, Android Linux, there is about 40MB of space left within
/data, the System image, at the same time, oﬀers only approximately 20MB for
additional tools. This fact requires appropriate counter-measures when conﬁgur-
ing given source code for compilation (e.g. ClamAV database needs to be placed
in a diﬀerent location as it exceeds the given 20MB on /system).

386
L. Batyuk et al.
Page alignment causes changes in linking. Of very high impact on the
success of compiling software for Android is the fact that Google forces compat-
ible binaries to not be page aligned for the text and data section. This requires
changes in the way of linking object ﬁles. For self-written software, one can take
precautions and react on this fact with compiling all shared libraries accordingly.
For already existing source code, changing the linker’s behavior can present a
very tiring and, often, an even impossible task.
Static linking. Due to the diﬀerent approach of linking, the only way to run
open source software on Android without altering the source code is to compile
the source code statically. The output binary will have only small dependencies to
existing libraries making it relatively autonomous. For a fair amount of available
open source software, this method has been executed successfully. Still though,
tools like ”iptables” or ”Snort” will not accept this method and fail compiling.
3.4
Bridging between Java and Linux
As already discussed in Section 1, it could be an interesting option to delegate
certain computational tasks from Java to native binaries written in, e.g., the C
programming language. We cover two possible solutions - Java Native Interface
(JNI), a commonly accepted standard in the Java development community, and
named pipes which are commonly used on unixoid systems for simple inter-
process communication.
Java Native Interface (JNI). JNI is used to call native functions of the un-
derlying operating system. Using this interface, the developer risks losing the
platform independence of Java unless the native call exists on all intended plat-
forms. At the moment, JNI is not supported on Android although it is used
across the system. Following Romain Guy, an Android developer at Google, An-
droid currently uses JNI only for the framework and not for the applications [4].
Nonetheless, Google seems to be working on a native SDK oﬃcially providing
JNI calls.
Despite the oﬃcial Google statement that JNI is currently not supported for
user applications and won’t work, we have successfully compiled a Java applica-
tion which uses a custom JNI shared library. It was possible to install and run the
application on the G1 without any further modiﬁcation. The native component
has been packaged into an APK as a raw binary resource and unpacked upon
ﬁrst execution of the Java program. After doing so, it is possible to load the
shared object as a JNI library via invoking java.lang.System.load(String
filename).
From our point of view, JNI is rather hard to implement, since compiling a
shared library for Android is a challenging task because of the unusual page align-
ment. But, it is most probably going to become the only oﬃcial way to include
native code in Android applications, and also has shown good performance.

Developing and Benchmarking Native Linux Applications on Android
387
Pipes. Using pipes is a commonly used technique in Linux and Unix systems
to allow communication between separated processes. Two main types of pipes
are known: unnamed pipes [12] and named pipes (also called FIFOs) [13].
Unnamed pipes are well known to most Linux and Unix users: e.g. have a look
at the command cat help.txt | grep a. The ﬁrst command displays the every
line of the text ﬁle help.txt while the second command displays only the lines
which contain the letter a. The horizontal bar indicates the usage of unnamed
pipes where the results of the ﬁrst command are stored in the kernel-side-located
pipe and then are used by the second command. Writing and reading pipes works
line-by-line following the First-in-First-out paradigm.
Named pipes are called FIFOs and are similar to unnamed pipes in their func-
tionality. The main diﬀerence is that they are created explicitly and unrelated
pipes are able to use them if no appropriete access control speciﬁcations are
made. For creating named pipes the command mkfifo can be used. Additional
information on pipes can be found in the corresponding man pages.
Using pipes on Android for communication between Java and native executa-
bles is rather straight-forward, since Java provides a lot of convenient writer,
reader, and stream classes. But, when it comes to deploying and executing the
binary in the restricted environment where an application can only write to its
own folder, this approach requires decent programming skills. We have packaged
the binary as a “raw resource”, then the application itself unpacked it to the
writieable directory. Then, the binary has to be made executable in order to
be started, which is impossible from within Java. This is where the sources of
the Android OS are needed - using the Android Build System instead of Ant,
it is possible to utilize the class android.os.Exec, which is not included in
the SDK classpath. It allows execution of native binaries as a subprocess of the
Java application. Using Exec.createSubprocess("/system/bin/sh", ...), it
is possible to start the Linux shell and utilize chmod to make the binary exe-
cutable. Afterwards, we can launch the native program and communicate with
it through a named pipe.
We make use of an undocumented class, android.os.Exec. Still, the fact that
it is present on the G1, in the emulator and in the source code of the platform,
it is rather improbable that it will ever be removed, especially since some of the
Google and third-party software on the Android Market already utilizes it.
The pipe technique is much more complex in its deployment than JNI, but
it gives the developer a possibility to start a persistent daemon on a Linux
layer which would collect information while being independent from the Java
application lifecycle. The performance evaluations in Section 4 show that this
approach is rather unsuitable for data-intensive tasks. But it is still a good
option to consider if the application’s logic forces the developer to work around
the application lifecycle of Dalvik VM.
4
Software Performance on Android
Only few up-to-date references can be found pointing out comparisons between
diﬀerent programming languages and the corresponding compilers. The reason

388
L. Batyuk et al.
Fig. 2. Execution time of quick sort run in a Java VM and as a native binary, comparing
the relative performance of Java to C in Dalvik and in Sun’s JRE. While the execution
time of both techniques on a Linux PC grows similarly and no signiﬁcant diﬀerence
occurs, the Dalvik VM shows a very bad performance and takes up to 30 times as long
as a native Android executable.
for this might be the fast progress in the technology and computer sector that
renders such kinds of results useless only few years after gathering them. A
newer publication was made by McConnel [16] in the year 2004. In this book
he describes in “Chapter 25: Code-Tuning Strategies” how to improve software
code and presents performance comparisons on diﬀerent types of programming
styles as well as of diﬀerent programming languages and compilers. Additionally,
he states that Java programs have 50% higher relative execution time than, e.g.
C++ or Visual Basic. If these results were applicable to Android, this would mean
that a performance increase would be achieved by transferring data sets from
Java to a native executable, and retrieving back the results after computation.
Of course, this is only true if we assume that the speed of the data transfer
between the layers is fast enough for a trade-oﬀto be found.
We would beneﬁt from this increase until the prediction of Reinholtz [5] turns
true. He stated that, in future, Java will be faster than C++ since dynamic com-
pilation gives the Java compiler access to runtime information not available to a
C++ compiler. But regarding the current Android platform, our current ﬁndings
show that this state is far away from being reached in most cases.
4.1
Performance Evaluation
We have performed a series of microbenchmarks to compare the performance
of identical sorting algorithms on various platforms. In the ﬁrst experiment, we
have compared the performance of various sorting algorithms implemented as
standalone Java and C executables. Second, we have evaluated the performance
of possible techniques which allow delegation of heavy computational tasks to

Developing and Benchmarking Native Linux Applications on Android
389
the native layer or to built-in Java facilities, which we assumed to be faster than
our own implementations.
Raw performance of sorting algorithms. In [20], Okumura et al. propose
various benchmarking techniques to evaluate the performance of Java VMs. One
of those is sorting objects and primitives, which we see as the most ﬁtted for our
purpose, since we concentrate on data-intensive tasks.
First, we have implemented three common sorting algorithms in both Java and
C: bubble sort [17], quicksort [18], and heapsort [19]. Arrays of random integers
have been generated and sorted with the corresponding algorithms in standalone
executables. The time used for each of the algorithms has been recorded while the
size of the array steadily increased. This ﬁrst simple measurement was performed
on the Android emulator, and on a Linux PC for a reference.
Analysis of bridging and built-in techniques. After receiving the ﬁrst
benchmark results it becomes obvious that delegating computational tasks
Fig. 3. Performance of sorting algorithms using various techniques on Android. All test
runs involve random data generation on Java, handing over the unsorted array to the
sorting function, and then retrieving back the results. Using a priority queue for sorting
numbers has proved to be the slowest approach, followed by the pipe. All pure-Java
sorting algorithms show similar performance, and only JNI shows a signiﬁcant increase
in performance.

390
L. Batyuk et al.
Fig. 4. Performance of sorting algorithms using various techniques on a Linux based
OS using Sun JRE 1.6. The values on this environment show substantially diﬀerent
results. Using a pipe is the slowest approach, and JNI is also relatively slow. This
proves the eﬃciency of Sun’s Java platform and shows that the Dalvik VM has room
for optimization.
to the native layer could drastically improve the speed of Java applications.
We have analyzed the performance of the two bridging techniques intro-
duced in section 3.4: the more common JNI, and a more straight-forward
and platform-independent direct ﬁle communication through named pipes. Ad-
ditionally, built-in Java techniques are being evaluated: object-oriented sort-
ing using a java.util.PriorityQueue as a heap and a built-in sort with
java.util.Arrays.sort(int[]). For comparison, heapsort, and quicksort im-
plemented in plain Java are also presented. Figures 3 and 4 show the results for
the Android emulator and a Linux PC, respectively.
Benchmark results. Our measurements show clearly that there is a great
diﬀerence between the Dalvik VM and the JRE from Sun. Sun’s optimization of
byte code is very eﬀective, which results in performance which is comparable to
native binaries. Since JNI involves signiﬁcant overhead when a function is being
called, it is not the fastest technique on a regular PC.

Developing and Benchmarking Native Linux Applications on Android
391
Contrary to this, the fastest computational technique for Android devices
is JNI. It beats even the optimized built-in algorithm from java.util.Arrays.
Unfortunately, the simple approach of data delegation through a pipe has proven
to be relatively slow, which can be explained by the slow IO performance of the
Dalvik VM. The most disappointing results have been delivered by the object-
oriented method using Java’s PriorityQueue as a min-heap.
5
Conclusion and Future Work
Our results show that Google still has much room for optimization. On one
hand, just-in-time compilation should be considered, and on the other hand,
native implementations of computationally complex classpath methods should
be introduced. Since Google is supposedly planning to introduce JNI capabilities
to the Android SDK, we recommend developers to embrace its potential and shift
heavy computation to the native layer.
In our future work, we are planning to port an existing benchmarking suite
to Android, most probably LINPACK [21]. We will port the benchmark to both
Java and C for Android and test the performance of real hardware, including the
G1 and other handsets which will emerge this year. Benchmarking diﬀerent mo-
bile operating systems on the same hardware would also deliver valuable results.
Comparing the performance of OpenMoko and Android on the Neo FreeRunner
handset is currently the only option available, but we are looking forward to new
ﬂashable handsets in 2009.
References
1. Android - An Open Handset Alliance Project (2008/12/05), http://code.google.
com/android/
2. Android Open Source Project (2008/12/05), http://source.android.com/
3. Android Market (2008/12/05), http://www.android.com/market/
4. Android Developer Mailing List Post (2008/12/05), http://groups.google.com/
group/android-developers/browse thread/thread/f87e6fce2b26db36
5. Reinholtz, K.: Java will be faster than C++. ACM SIGPLAN Not. 35, 25–28 (2000)
6. Eclipse
Intergrated
Development
Environment
(2008/12/05),
http://www.
eclipse.org/
7. Netbeans Intergrated Development Environment (2008/12/05),
http://www.
netbeans.org/
8. Codesourcery (2008/12/05), http://www.codesourcery.com/
9. Scratchbox (2008/12/05), http://www.scratchbox.org/
10. Ubuntu Home Page (2008/12/05), http://www.ubuntu.com/
11. Busybox (2008/12/05), http://www.busybox.net/
12. Unnamed Pipes (2008/12/05), http://docs.sun.com/app/docs/doc/816-1042/
6m7g4ma79
13. Named
Pipes
(FIFOs)
(2008/12/05),
http://docs.sun.com/app/docs/doc/
816-1042/6m7g4ma7a
14. HTC
T-Mobile
G1
(2008/12/05),
http://www.htc.com/www/product/g1/
overview.html

392
L. Batyuk et al.
15. Schmidt, A.-D., Schmidt, H.-G., Clausen, J., Y¨uksel, K.A., Kiraz, O., Camtepe, A.,
Albayrak, S.: Enhancing Security of Linux-based Android Devices. In: Proceedings
of 15th International Linux Kongress. Lehman Verlag, Hamburg (2008)
16. McConnel, S.: Code Complete, 2nd edn., pp. 180–197. Microsoft Press, Redmond
(2004)
17. Knuth, D.E.: The Art of Computer Programming, 2nd edn. Sorting and Searching,
vol. 3, pp. 180–197. Addison-Wesley, Reading (1997)
18. Hoare, C.A.R.: Quicksort. Computer Journal 5(1), 10–15 (1962)
19. Williams, J.W.J.: Algorithm 232 - Heapsort. Communications of the ACM 7(6),
347–348 (1964)
20. Okumura, T., Childers, B., Moss´e, B.: Running a Java VM Inside an Operating
System Kernel. In: VEE 2008: Proceedings of the fourth ACM SIGPLAN/SIGOPS
international conference on Virtual execution environments, Seattle, WA, USA
(2008)
21. Dongarra, J.J.: The LINPACK Benchmark: An explanation. In: Houstis, E.N.,
Polychronopoulos, C.D., Papatheodorou, T.S. (eds.) ICS 1987. LNCS, vol. 297.
Springer, Heidelberg (1988)

Towards an Opportunistic and Location-Aware Service
Provision in Disconnected Mobile Ad Hoc Networks
Salma Ben Sassi and Nicolas Le Sommer
VALORIA Laboratory
Université Européenne de Bretagne, France
 	


	

Summary. Opportunistic networking has recently appeared as a promising me-
thod to support communication in disconnected mobile ad hoc networks. This
new communication model relies on the “store, carry and forward” principle, and
exploits ad hoc communication and device mobility in order to achieve a network-
wide message dissemination. It allows nomadic people to communicate together
without resorting to infrastructure-based networks and to have access to services
offered by infostations even if they are not in the area covered by these devices.
Nevertheless, to be efﬁcient this model requires to guide the message propagation
using contextual information, and especially location information.
In this paper, we present the middleware solution we have deﬁned in order
to support the provision of location-aware application services in disconnected
mobile ad hoc networks using opportunistic communications.
1
Introduction
With the signiﬁcant progress achieved since many years in the domains of hardware
computing and wireless communication, smartphones, personal digital assistants and
netbooks have become cheaper and more powerful, and are now widely spread. Ho-
wever, the main use of these devices lies so far in accessing the Internet via wireless
access point (i.e., hotspots) in order to send and receive email or to surf the Web. Yet,
all these devices are equipped with WiFi interfaces capable of ad hoc communication,
and could be used by nomadic people to communicate together without necessarily re-
sorting to an infrastructure-based network, and to access application services offered
by ﬁxed devices embedded in their physical environment, or even by mobile devices
themselves.
Opportunistic networking [2, 11, 12, 15] has recently appeared as a relevant mean to
support communication in mobile ad hoc networks (MANETs), which are in realistic
conditions intrinsically disconnected due to the sparse and irregular distribution of the
mobile devices and the ﬁxed infostations that composed them. Like delay-tolerant net-
working [5, 16, 17], the opportunistic networking exploits ad hoc communication and
device mobility to exchange data allowing hosts to communicate with each other even if
a route connecting them does not exist all the time. Indeed, in opportunistic networks,
messages are not simply routed in the network. While travelling from host to host in
the network, they can be stored temporarily on certain hosts and be forwarded later
when the circumstances are favourable. By thus exploiting ad hoc communication and
C. Giannelli (Ed.): Mobilware, LNICST 0007, pp. 393–406, 2009.
c⃝Institute for Computer Science, Social Informatics and Telecommunications Engineering 2009

394
S.B. Sassi and N. Le Sommer
device mobility, messages can be propagated network-wide. However, application ser-
vices are often relevant only in speciﬁc areas. Consequently, the messages inherent in
the discovery, the advertisement and the invocation phases should be restricted to these
areas instead of being propagated network-wide thus granting a sensible reduction of
the network load.
In this paper, we present a ﬂexible and extensible framework designed to support the
development of location-aware application services, as well as the provision of these
services using opportunistic communications. This framework deﬁnes several repre-
sentations of the location concept, and several location determination methods. It also
implements a location-aware and opportunistic service provision model. With this mo-
del, service providers are able to exhibit their location constraints, requirements and
properties and to include this piece of information in their service advertisements. Li-
kewise, service clients are aware of their real-time location, and able to perform service
discovery, service selection and service invocation based on this location. For instance,
a client application can discover and locate all service providers available in its neigh-
bourhood and invoke the nearest one. This service application model is supported by a
location-aware communication layer, where the opportunistic dissemination of applica-
tion messages can be restricted to given geographical areas (i.e., the areas speciﬁed as
relevant for the service discovery and invocation by the applications).
The remainder of this paper is structured as follows. Section 2 presents a frame-
work for mobile host location and environment modelling. Section 3 describes how
application services can use location information in the service discovery and invoca-
tion processes as well as in the message dissemination process. Section 4 presents the
results we obtained by running our middleware platform on a mobile ad hoc network
simulator. Section 5 compares our proposal with works targeting the same objectives
as ours, and Section 6 provides a summary of our contribution and concludes by giving
some perspectives.
2
Location Framework
2.1
Location Requirements for Opportunistic Service Provision
The provision of application services using opportunistic communication introduces
new issues that have not been identiﬁed so far with the single-hop synchronous com-
munication model that is traditionally used for service provision. Indeed, with oppor-
tunistic communication service messages are likely to be propagated network-wide.
Hence, application services can potentially be discovered and invoked in the whole net-
work by mobile clients, even if these services must only be accessed in speciﬁc areas.
Moreover, a network-wide dissemination of messages increases the global network load
and reduces its scalability. A message propagation control using an expiration time and
a number of hops is not sufﬁcient for service provision, which requires a location-
based propagation control. In order to underline both the issues inherent in the service
provision using opportunistic communication and the needs of having location-aware
services and middleware platforms, let us consider a campus populated with several
service providers offering wireless access to printing services for students (see
Figure 1).

Towards an Opportunistic and Location-Aware Service Provision
395
Fig. 1. Example of a disconnected mobile ad hoc network
For example, in order to propagate advertisement messages for printing services in
the whole campus, service providers SP1, SP2 and SP3 can decide to send their mes-
sages with a high number of hops. These messages will be widely disseminated in the
campus by the students’ devices, but also outside the campus. Indeed, without location
constraints these service advertisement messages will be stored, carried and forwar-
ded until their number of hops is equals to zero. For example, student S1 who is going
from building A to building B can propagate the service advertisement it received from
provider SP1 in A, in a location area close to building B. These services could thus
be discovered –and potentially invoked– outside the campus by service clients, even
if that should be prohibited. Furthermore, service clients having no information about
their own location and about the location of the providers can achieve bad provider
selections and invocations. For instance, after having received an advertisement from
providers SP1 and SP3, student S1 (or more precisely the middleware installed on the
device used by S1 after an action performed by the latter) can decide to select and in-
voke the service offered by SP1, whereas he is now closer to SP3 than SP1, since no
information allows to distinguish the services offered by SP1 and SP3.
Consequently, it could be convenient to have service providers able to give their
location and to deﬁne in which location area their service advertisements must be for-
warded, as well as to have location-aware service clients. This way, SP1, SP2 and SP3
could specify that their service advertisements must only be propagated in the campus,
and S1 could compare its own location with the location of the providers, and thus select
the nearest provider without ambiguity. Moreover, it is suitable that service providers
can specify, in addition to the location area in which they can be discovered, the location
area in which they can be invoked. Indeed, these two location areas can be different. For
example in the scenario of Figure 1, providers SP1, SP2 and SP3 should be discovered
by the students in the whole campus, but should only be invoked by their respective
surrounding students (i.e., by the students who are in the building where the providers
are deployed).

396
S.B. Sassi and N. Le Sommer
Similarly, the service discovery requests and the service invocation requests sent by
service clients must not be disseminated in the whole network, but only in speciﬁc loca-
tion areas. For that, clients should be able to specify their own location and the location
areas where their service messages can be propagated. Thus, only the providers located
in the location area speciﬁed by the client can receive these requests and can return a
response if they provide the required service. For example, if student S1 has not recei-
ved an advertisement from service provider SP2 when reaching building C, student S1
could initiate a service discovery by sending in the network a service discovery request
with a geographic-restricted location area and its own location, and it should receive in
return only an advertisement from SP2. On the contrary, if he wants to discover all the
services available in the campus, he should specify that its request must be propagated
in the whole campus.
The key issues thus lie in the deﬁnition of the location concept and location de-
termination methods, and in the design of service-oriented middleware platforms able
to efﬁciently exploit location information in service discovery, service selection and
service invocation, as well as in message routing. In the remainder of this section we
present a location framework, and in the next section we present how this framework
is used in a service management middleware layer and in middleware layer supporting
opportunistic communication.
2.2
Location Modelling
In many related works, the concept of location is often reduced to GPS coordinates
–which are deﬁned by a longitude and a latitude expressed in decimal degrees with res-
pect to the World Geodetic System 1986 (WGS84), and an elevation above the WGS84
ellipsoid that is expressed in meters. Yet, in a pervasive environment similar to that
considered in Figure 1, obtaining GPS coordinates is not always feasible, and this ex-
pression of location is not suitable in many cases. For instance, service providers SP1,
SP2 and SP3 deployed within buildings –where GPS signal cannot be received– should
not deﬁne their location and their discovery and invocation location areas using GPS
coordinates, but instead with symbolic names that can be expressed as a textual address
information divided into ﬁelds (e.g. street, postal code, city, etc.). The term location thus
should refer to the generic concept of a place that can be identiﬁed either by a symbolic
name, a position expressed in a speciﬁc coordinates system, or an area. Our location
framework, supports these different representations of the location concept, and deﬁnes
methods making it possible 1) to estimate the distance between two locations when
specifying intermediary locations or not, 2) to determinate if a location is included in
another, and 3) to return the method used to obtain (or to estimate) this location. Four
kinds of locations are deﬁned in our framework: 1) waypoints, 2) landmarks, 3) location
areas identiﬁed by a symbolic name, and 4) proximity-oriented location areas.
Waypoints are locations with no particular signiﬁcance. They are only described
by their position in a speciﬁc coordinate system. In contrast, Landmarks are locations
characterised by both a position and a symbolic name deﬁned as textual address infor-
mation divided into ﬁelds (e.g. street, postal code, city, etc.). They are typically used to
identify a place on a map.

Towards an Opportunistic and Location-Aware Service Provision
397
Like landmarks, the location areas are identiﬁed by a symbolic name deﬁned as
textual address information and/or by coordinates and a geometric shape. They can
be typically used by providers to specify where they are to deﬁne service discovery
and invocation areas, as well as by the clients to deﬁne their own location, the area in
which their service discovery requests can be propagated, and the area of the provider
they try to invoke if necessary. A location area can be deﬁned as an assembly of pre-
existing areas. A primitive location area is mainly deﬁned by a symbolic name and/or by
coordinates and a geometric shape. A composite location area is deﬁned so as to include
other location areas, and to deﬁne how these areas are composed together using binding
operators such as the union, the intersection, and difference (the default operator is
the union). Architectural elements of physical environments, such as buildings, can be
deﬁned with location areas. They can be identiﬁed by an address and a position, and
be described by the ﬂoors that compose it, which themselves can be structured as sets
of several rooms. Thanks to such a composite modelling, a location information can be
easily reﬁned or extended by our framework when needed, thus offering several levels
of precision to locate service clients and service providers.
Finally the proximity-based areas are characterised by a shape and geographic coor-
dinates. They are mainly used by mobile clients in order to discover what services are
in their neighbourhood, and by service providers to deﬁne in which area they can be
accessed knowing their own position.
2.3
Location Determination Method
A location can be determined using several methods and technologies. The technologies
used in location determination have been classiﬁed in [7] according to properties such
as media, type of information, method, scale, cost, accuracy and point of computation.
The media refers to the underlying technique (e.g., acoustic, video, electromagnetic).
The type of information can be a physical position or some symbolic information; both
can be absolute or relative. Symbolic location is deﬁned to be a position relative to some
known entity whose location may or may not be precisely known. In [7], three generic
location determination methods are identiﬁed: proximity, triangulation and scene ana-
lysis or pattern recognition. These methods are also classiﬁed according to the point of
computation, which can be server-based or client-based.
Our framework was designed with a similar classiﬁcation in mind. All the objects
modelling a location thus deﬁne a method returning an object that speciﬁes the loca-
tion type, the computation method and the technology used to obtain the location, and
the point of computation. A location type can be either absolute, relative or symbo-
lic. Landmarks and way points are absolute locations that are expressed with a po-
sition in a speciﬁc coordinate system (the default system is the WGS84), and which
can be obtained using a GPS typically. Relative location is deﬁned as a position esti-
mation with respect to another location information. Proximity-oriented locations are
examples of relative locations. Such location can be obtained using a proximity or tri-
angulation computation methods on the basis of wireless signals for instance. Finally,
symbolic locations are location areas identiﬁed by a symbolic name. In our current
implementation only two kinds of technology are considered in the location determi-
nation: the GPS and the wireless communication interfaces. Wireless technologies are

398
S.B. Sassi and N. Le Sommer
characterised by their communication range, their type (e.g., 802.11, 802.15), and other
information such as the signal level or the noise level. Moreover, four kinds of com-
putation methods have been identiﬁed: the direct method, the pattern-matching-based
method, the proximity-based method, and the triangulation method. In the current im-
plementation of our framework only the last method is not implemented yet. The direct
method is a simple method that is used to compute the coordinates obtained from a GPS
receiver. The proximity-based method is used for wireless technologies and implements
a linear attenuation model. The pattern-matching-based method relies on a hierarchical
pattern matching mechanism on textual address information divided into ﬁelds (e.g.
street, postal code, city, etc.). The location estimation can be computed either locally or
remotely by another device in the network. Indeed, if a device cannot estimate its loca-
tion itself, it can ask for a remote host (or a set of remote hosts) to compute this location
according to the messages they receive from the mobile device and of the characteristics
of the wireless technology.
2.4
Maps Projection and Environment Modelling
The environment modelling and maps projection are key features for the location-aware
service provision. Indeed, it is often necessary to build location databases, and to deploy
them on mobile devices in order to associate address information with GPS coordinates
for instance, or to indicate the position of people (or service providers) on maps. Coordi-
nate projection and conversion functions have thus been implemented in our framework.
Thanks to the landmarks and location areas, our framework provides general, yet easy
to use, means for environment modelling. Obviously, our framework does not perform
a 3D representation of the environment like CityGML [6], which is dedicated to 3D
urban representation and that covers a very large ﬁeld of places. Mobile devices do not
need to be equipped with a location database natively, they can build themselves their
own database (and therefore their own perception of the environment) by exploiting the
location information included in service messages roaming in the network.
Figure 2 shows an application that has been developed using our framework, and that
runs on a PDA. This application makes it possible, for instance for students, to model
Fig. 2. A service location application developed using our framework and running on an IPAQ

Towards an Opportunistic and Location-Aware Service Provision
399
the campus, to see where they are, and to locate the application services available in the
campus, such as the printing services.
3
Middleware Support for Location-Aware Application Services
In this section, we ﬁrst present how service messages are structured, and how they are
handled by the service management and the communication middleware layers. Then
we present how service clients and providers use the framework detailed in the previous
section in order to express their location requirements, constraints and properties, and
how location information is currently exploited in message routing.
3.1
Location Information and Service Message Structure
All the messages exchanged opportunistically by the devices are structured in two parts:
a set of headers and a content (see Figure 3). Some of message headers are compulsory,
such as origin and destination for routing purposes, number of hops to limit the propa-
gation of messages in term of hops, and expiration time and date to deﬁne the temporal
validity of messages. Other headers are optional, and are generally some complemen-
tary information speciﬁed by the application services so as to help in service selection
and message routing. The content of messages depends on the type of messages. For
example, the content of a service discovery request is a service pattern, whereas the
content of a service advertisement is a service descriptor (see Figure 3). The service
location properties and constraints mentioned in the previous section (e.g., service dis-
covery location area, service invocation location area, and service provider location) are
speciﬁed within the content of such messages. Some of these properties and constraints
are also deﬁned as optional headers by the service management middleware layer in
order to specify how these messages should be processed by the opportunistic commu-
nication middleware layer.
Fig. 3. UML methods of message structure

400
S.B. Sassi and N. Le Sommer
3.2
Location Management in the Service Management Middleware Layer
With our middleware platform each mobile host can maintain its own perception of the
services available in the network thanks to a dedicated service register. This register is
responsible for performing service discovery and service selection. The service disco-
very can be achieved either proactively or reactively. The reactive discovery consists in
listening and analysing the unsolicited service advertisements sent by providers in the
network. The proactive service discovery consists in sending service discovery requests
in the network and in listening and analysing the service advertisements returned in
response by providers.
Figure 4 shows how a printing service, comparable to those considered in the sce-
nario presented in Section 2.1, can describe its location properties and constraints in
its own service descriptor before registration. This descriptor will be then used by the
service management layer in order to build a service advertisement for this service. The
ﬁrst block of instructions shows how to model the place where the service provider is
located using a symbolic building (called A) with one ﬂoor (ﬂoor0), and whose address
is "building A, UEB Campus. The second block of instructions deﬁnes a service des-
criptor including the interface exhibited by the service, its non-functional properties,
and its locations properties and constraints. The last block of instructions registers the
service in the local service register. In short, it describes a printing service with ﬂoor0
as invocation access area and the entire campus as discovery access area.
Local service clients can invoke the local service register in order to discover the
remote services available in its neighbourhood. For example, to discover all printing
services available in a range of 200 meters, the client must create a service pattern des-
cribing the service it requires and specifying its location constraint. Figure 5 shows an
  







	





	











	




	












	
  




	




	














	
  








	





	













	








 






	






	





























 






	






	


































 






	






	


























 



	


!




	


"





 

#


$
#
	
%
	



#
	
%

	


"

&
%



'
%







 

#







 



	


!




	


"




(
)
*
$


 

#

(


+














#
	
%

	


"




$
#
	
%

	



(
"

)
*
$


 

#

(


+















 

#







#
	
%

	


"


'
%








&
%




(
&
%




(


#
	
%

	


"


  
	




	

	








!




	


	

,




	


"





#
	
%

	


"

!




	



	



,


-
"






 

#


!




	





	

	



'
%





+


,
	


.




	












+


,
	


.




	





(


	


	





,
	


(

(
'


#








/

	


+


,
	


(




	

	



	

,




	


"





	



,


-
"





  
	




	

	










+


,
	


0


	








	












	



Fig. 4. Example of descriptor deﬁnition for a location-aware service

Towards an Opportunistic and Location-Aware Service Provision
401
  











	



	


!




	






!



!




	


/


,
	








#





!




	





  
	












	






	




	

!




	



	



,


-
"







/


1
	
 
	

-
"








!











	













+


,
	


/

















+


,
	


/







(
'


#








/

	


+


,
	


(


	



,


-
"





  
	




	






+


,
	


/


,
	





'
+

,

+


,
	


0


	





%


2
#











Fig. 5. Example of service look-up
example of the deﬁnition of such a service pattern using an object of type ProxymityA-
rea. This service pattern will be included by the service register in a service discovery
request if it has no information about a provider satisfying the required service interface
and the location constraints expressed by the client. This discovery request will then be
sent in the network in order to perform a proactive service discovery. The selection pro-
cess aims at choosing the "best" provider to invoke among a set of providers, and at
returning its reference to the client application. Meaning that we have to ensure that the
selected provider is invokable (i.e, that the client is located within the invocation area
when invoking) and that the chosen provider is the closest one to the client’s current
position and thus would be the fastest one to respond. The reference is then used by the
client in order to build its service invocation request.
In our framework, the asynchronous service invocation is achieved using notably
the InvocationRequest and InvocationResponse messages and the ServiceInvoker and
ServiceResponseHandler objects. To invoke asynchronously a remote service (or a set
of remote services), a local client is expected to use the asyncInvoke() methods deﬁ-
ned by the ServiceInvoker object. The ﬁrst method asyncInvoke() takes as parameters a
InvocationResquest object and a ServiceReponseHandler object. The handler object is
used by the client to handle the responses it receives following an event-based program-
ming approach. This handler takes as parameters a timeout –which should be equals to
the expiration time speciﬁed in the request– and a number specifying how many res-
ponses must be handled. This handler is designed so as to receive responses from the
network. When the timeout it received as parameter is triggered, the handler is expec-
ted to unregister itself from the ServiceResponseListener. A ServiceResponseListener
is used to listen to a service response from the network and to dispatch them to objects
of type ServiceInvoker and/or ServiceResponseHandler. The second method asyncIn-
voke() only takes as parameter an InvocationRequest. This method is designed to be
running until a response is received from the network. When the timeout speciﬁed in
the request is triggered, the method is expected to return a null value. Since tempo-
ral, spatial and contextual properties are intrinsically service-dependent, client services
and service providers are responsible to specifying these properties themselves in the
ServiceRequest and ServiceResponse objects respectively.

402
S.B. Sassi and N. Le Sommer
Fig. 6. Framework elements for service invocation
3.3
Exploitation of Location Information While Routing
As underlined in the scenario presented in Section 2.1, with opportunistic communica-
tion, service messages may be forwarded outside the area where they are relevant. In
order to cope with this issue and relieve the network from irrelevant messages, we have
introduced, in addition to the compulsory headers presented in Figure 3, an optional
header, called restriction header, to restrain messages geographically. The opportunis-
tic communication middleware layer is designed to compare the current location of the
mobile host with the value of this header before relaying a message. Thus, mobile hosts
can forward a message if and only if they are within the area described in the restriction
header of this message. This header is speciﬁed by the service management middleware
layer on the basis of location information speciﬁed by application services in service
descriptor and service pattern and it usually represents the access area or the discovery
area of the targeted providers.
4
Evaluations
In order to evaluate our model, we have made a series of simulations using the Madhoc
simulator1,a metropolitan ad hoc network simulator that features the components re-
quired for both realistic and large-scale simulations, as well as the tools essential to an
effective monitoring of the simulated applications. This simulator, which is written in
Java, allow us to run our middleware platform on it.
In this section, we focus on a particular experiment whose objective was to measure
the ability to satisfy the client service invocation efﬁciently using location information.
For that, we compared our location-aware service discovery, selection and invocation
model with a classical model that does not exploit the location properties exhibited
by service providers and mobile devices. Moreover in the ﬁrst case, we use an oppor-
tunistic communication protocol based on an epidemic model that implements both a
hop-based and location-based message propagation control, and in the second case we
use an opportunistic communication protocol relying on an epidemic model implemen-
ting only a hop-based message propagation control (messages are limited to 4-hops in
our simulation). In the location-aware model, clients must await to be into the invoca-
tion area of a provider offering the service they require in order to start invoking this
1 http://agamemnon.uni.lu/~lhogie/madhoc/

Towards an Opportunistic and Location-Aware Service Provision
403
service, while in the other model, their service messages are forwarded by the other
mobile hosts freely and thus client applications do not require to meet any conditions
before invoking randomly one of the providers discovered (regardless of their positions
or access areas).
The simulation environment we consider is an open area of about 1km2 containing
4 buildings and populated with a 100 devices equipped with Wi-Fi interfaces: 10 ﬁxed
infostations located in the buildings and 90 mobile hosts that evolve from a building to
an other following a random way point mobility model and taking a 5 to 10 minutes
time pause in each building they reach. Each mobile host moves with a speed varying
between 0.5 and 2 m/s.
70 mobile hosts are chosen periodically to act as relay nodes. Relay nodes are expec-
ted to forward immediately all service messages they receive while the other hosts are
expected to forward their messages with a periodicity of 20 seconds. Each message has
an expiration time of 4 minutes (when a message has expired, it is removed from the
cache of messages and cannot be forwarded). Among the mobile hosts, only 60 hosts
run client applications for the services offered by the infostations. When they have dis-
covered a provider, the clients try to invoke them periodically (every 5 minutes) with a
different request.
In Tables 2 and 1 we summarise the simulation results we have obtained. The Table 2
shows that the network load has indeed been globally reduced by half and that the mes-
sage trafﬁc is controlled and restricted within the predeﬁned discovery and invocation
areas. Furthermore, the location-awareness has an impact on the service selection and
service invocation since the success invocation rate increases from 32,60% for a ran-
dom invocation to 66,25% for a location-based invocation (see Table 1). The average
delay for a successful invocation has also been considerably reduced attaining an ave-
rage value of 20s for location-aware applications. However, Table 1 also shows that
the location-aware invocation model we propose has induced an extra waiting time of
72s due to the fact that a client application is not allowed to invoke a provider until it
reaches its invocation area. A possible solution for this side effect would be to initiate
the invocation before attaining the invocation area.
Table 1. Simulation results for the ser-
vice discovery and invocation process
Random
invocation
Location-based
invocation
Average waiting time
before invocation (s)
1,08s
73,40s
Average delay for
successful invocations (s)
109,6s
20,1s
Standard Deviation
for the delay(s)
134,0s
51,9s
Average invocation
success ratio (%)
32,60%
66,25%
Table 2. Simulation results for the net-
work load
Restricted
dissemination
Unrestricted
dissemination
Global
network load
(messges number)
3537988
1948290
Invocation
trafﬁc load
(messges number)
2345738
743502
Inter-areas
trafﬁc rate
40,11%
2,31%
Intra-area
trafﬁc rate
59,89%
97,68%

404
S.B. Sassi and N. Le Sommer
5
Related Work
Many recent works have focused on problem of the opportunistic message forwarding
in mobile ad-hoc networks, and some of them [2, 4, 14, 17] have considered contextual
properties in order to deﬁne “smart” forwarding policies. However, despite the sprea-
ding use of positioning devices, only few location-based message forwarding protocols
have been proposed so far. GeOpps [12] is an example of such protocols. It implements
a store, carry and forward mechanism dedicated to vehicular networks, and exploits
location information available via navigation systems to select vehicles that are likely
to carry a message towards its destination. However such a protocol is not suited for
a human-based mobility model. Indeed, in contrast to vehicles, people do not neces-
sarily follow predeﬁned routes while they are moving, making it difﬁcult to determine
if or when they will reach a given destination. GPSR [10], Terminode routing [1], and
GRA [8] are also location-based routing protocols, and they use only neighbour location
information for forwarding data packets. Routing is done in a greedy way by forwarding
the packet to the closest neighbour to the physical location of the destination. This local
optimal choice is repeated at each intermediate node until the destination is reached or
the message’s time to live (TTL) expired.
As far as the exploitation of location information at the service level is concerned,
few works have been achieved to the best of our knowledge. In [13], Meier et al. present
a proximity-based service discovery protocol (PDS) for mobile ad hoc networks. Like
our framework, PDS proposes a discovery approach of ad hoc services that exploits
the fact that the relevance of such services is often limited to a speciﬁc geographical
scope. Service providers are thus expected to deﬁne the areas (so-called proximities) in
which their services are available. In PDS, clients register interest in speciﬁc services
and are subsequently informed whenever they come into a “proximity” within which
these services are available. In PDS, proximity areas are characterised by a given shape
and coordinates and are included in discovery requests in order to select relevant ser-
vice providers. However unlike our framework, PDS does not support several location
models, and especially the address-based model that is best suited for indoor places.
Other works have also been done in the domains of the location management and
location/environment modelling. These works have led to standards such as the loca-
tion API for Java (JSR 179) [9], the OpenGIS Location Services (OpenLS) [3] and
CityGML [6]. JSR 179 deﬁnes a framework to express a location with GPS coordinates
expressed in the World Geodetic System 84. It also makes it possible to associate a loca-
tion with an address-based information thanks to the concept of landmark, and deﬁnes
a publish/subscribe paradigm that enables subscribers to be notiﬁed when a given lo-
cation is reached. The OpenLS speciﬁcations detail the core services and abstract data
types that comprise the GeoMobility Server. This server is an open location services
platform for Web services deﬁned by the Open Geospatial Consortium2. It notably de-
ﬁnes functionalities to create routes and driving directions, to support map portrayal
and to ﬁnd points of interest using either a proximity-based model or an address-based
model. It relies on a complete XML-based location modelling and querying. Neverthe-
less in comparison to our framework, this speciﬁcation does not deﬁne a simple and
2 http://www.opengeospatial.org/

Towards an Opportunistic and Location-Aware Service Provision
405
ﬂexible API that could be used by service providers to specify where they are, what is
their service access areas, etc.
CityGML is a speciﬁcation aiming to represent an urban environmentin 3D. Different
elements such as buildings or city furnitureare identiﬁed using their geometrical,topolo-
gical, semantic, and appearance properties. These elements can also be described using
address information that conforms to the XML Schema deﬁnition of the Extensible Ad-
dress Language(xAL)and to the rules forrepresenting address informationin CityGML.
However, since CityGML is dedicated to 3D representation and thus covers a very large
ﬁeld of places that are unnecessary for our work such as water body or city furniture and
deﬁnes lots of irrelevant properties such as topology, colour or material type.
6
Conclusion and Future Work
In this paper, we have presented a middleware platform for location-aware services.
This platform implements an opportunistic communication protocol in order to support
service discovery and invocation in disconnected mobile ad hoc networks. It also deﬁnes
several kinds of location models and location determination methods. These models and
methods are used by application services in order to specify their own location and their
discovery and invocation areas, as well as by the middleware itself in order to discover
what services are available in a given location area, and to select and invoke service
providers according to their location properties.
The simulation results we obtained by running our middleware platform on a mobile
ad hoc network simulator show that our middleware offers a more reliable and efﬁcient
service provision than a classical random invocation model, while reducing the global
load of the network and thus improving the network scalability.
In the future, we plan to improve our middleware platform so as to opportunisti-
cally route messages toward targeted geographical locations, and not only limit their
propagation to certain geographical locations as in our current implementation.
Acknowledgments. This work is done in the project SARAH This project is supported
by the French ANR (Agence Nationale de la Recherche) in the framework of the 2005
ARA SSIA program.

	


 !
References
1. Blazevic, L., Le Boudec, J.-Y., Giordano, S.: A Location-Based Routing Method for Mobile
Ad Hoc Networks. IEEE Transactions on Mobile Computing 3(4), 1–15 (2004)
2. Boldrini, C., Conti, M., Iacopini, I., Passarella, A.: Hibop: a history based routing protocol
for opportunistic networks. In: Conti, M. (ed.) Proc. IEEE International Symposium on a
World of Wireless, Mobile and Multimedia Networks WoWMoM 2007, pp. 1–12 (2007)
3. Bychowski, T., Williams, J., Niedzwiadek, H., Bishr, Y., Jean-Francois, G., Crisp, N.,
Wilbrink, W., Horhammer, M., Roy, G., Margoulies, S., Fuchs, G., Hendrey, G.: OpenGIS
Location Services (OpenLS): Core Services. Open Geospatial Consortium, marwa mabrouk,
esri edition, September 9 (2008)

406
S.B. Sassi and N. Le Sommer
4. Conti, M., Delmastro, F., Passarella, A.: Context-aware ﬁle sharing for opportunistic net-
works. In: Proc. IEEE Internatonal Conference on Mobile Adhoc and Sensor Systems MASS
2007, pp. 1–3 (October 2007)
5. Fall, K.: A Delay-Tolerant Network Architecture for Challenged Internets. In: Proceedings
of ACM SIGCOMM 2003 (August 2003)
6. Groger, G., Kolbe, T.H., Czerwinski, A., Nagel, C.: OpenGIS City Geography Markup Lan-
guage (CityGML) Encoding Standard. In: Open Geospatial Consortium (August 2008)
7. Hightower, J., Borriello, G.: Location Systems for Ubiquitous Computing. IEEE Com-
puter 34, 57–66 (2001)
8. Jain, R., Puri, A., Sengupta, R.: Geographical Routing Using Partial Information for Wireless
Ad Hoc Networks. IEEE Personal Communications 8, 48–57 (2001)
9. Java Community Process, jsr-179-comments@jcp.org. JSR 179 Location API for J2ME
Speciﬁcation, nokia corporation edition (February 2006)
10. Karp, B., Kung, H.T.: GPSR: Greedy perimeter stateless routing for wireless networks. In:
6th International Conference on Mobile Computing and Networking (MobiCom 2000), pp.
243–254. ACM Press, New York (2000)
11. Leguay, J., Lindgren, A., Scott, J., Friedman, T., Crowcroft, J.: Opportunistic content distri-
bution in an urban setting. In: CHANTS 2006: Proceedings of the 2006 SIGCOMM work-
shop on Challenged networks, Pisa, Italy, pp. 205–212. ACM Press, New York (2006)
12. Leontiadis, I., Mascolo, C.: GeOpps: Geographical Opportunistic Routing for Vehicular Net-
works. In: IEEE Workshop on Autonomic and Opportunistic Communications (Colocated
with WOWMOM 2007), Helsinki, Finland, pp. 1–6. IEEE Computer Society Press, Los
Alamitos (2007)
13. Meier, R., Cahill, V., Nedos, A., Clarke, S.: Proximity-Based Service Discovery in Mobile
Ad Hoc Networks. In: Kutvonen, L., Alonistioti, N. (eds.) DAIS 2005. LNCS, vol. 3543, pp.
115–129. Springer, Heidelberg (2005)
14. Musolesi, M., Hailes, S., Mascolo, C.: Adaptive Routing for Intermittently Connected Mo-
bile Ad Hoc Networks. In: Proceedings of the IEEE 6th International Symposium on a World
of Wireless, Mobile, and Multimedia Networks (WoWMoM 2005), Taormina, Italy. IEEE
Computer Society Press, Los Alamitos (2005)
15. Pelusi, L., Passarella, A., Conti, M.: Opportunistic Networking: Data Forwarding in Discon-
nected Mobile Ad Hoc Networks. IEEE Communications Magazine (November 2006)
16. Shah, R., Hutchinson, N.C.: Delivering Messages in Disconnected Mobile Ad-Hoc Net-
works. In: Pierre, S., Barbeau, M., Kranakis, E. (eds.) ADHOC-NOW 2003. LNCS,
vol. 2865, pp. 72–83. Springer, Heidelberg (2003)
17. Sollazzo, G., Musolesi, M., Mascolo, C.: TACO-DTN: A Time-Aware COntent-based dis-
semination system for Delay Tolerant Networks. In: MobiOpp 2007: Proceedings of the
1st international MobiSys workshop on Mobile opportunistic networking, pp. 83–90. ACM
Press, New York (2007)

Author Index
Alagoz, Fatih
208
Albayrak, Sahin
381
Amoretti, Michele
252
Antoniou, Josephine
340
Asmare, Eskindir
222
Bachmann, Andreas
1
Batyuk, Leonid
381
Baumgarten, Uwe
171
Bellavista, Paolo
58, 280
Bonnin, Jean-Marie
43
Camtepe, Ahmet
381
Cardoso, Jo˜ao M.P.
266, 352
Chainho, Paulo
352
Chen, Min
366
Conte, Gianni
252
Corradi, Antonio
236, 280
Deinert, Florian
1
Demeure, Isabelle
129, 325
Diniz, Pedro C.
352
Dulay, Naranker
222
Duong, Hoa Ha
129
Ferreira, Diogo R.
352
Fiedler, Jens
197
Foschini, Luca
280
Giannelli, Carlo
58
Gonz´alez-Valenzuela, Sergio
366
Good, Richard
115
Gopalan, Anandha
222
Gouveia, Fabricio
115
Imai, Pierre
101
Kesavan, Vijay
27
Khakpour, Amir R.
325
Kotilainen, Niko
15
Laghi, Maria Chiara
252
Lamparter, Bernd
101
Le Sommer, Nicolas
393
Leung, Victor C.M.
366
Liebsch, Marco
101
Liu, Huaiyu
27
Low, Andy L.Y.
27
Lupu, Emil
222
Maciocco, Christian
27
Magedanz, Thomas
1, 115, 197
Mart´ınez Madrid, Natividad
185
Mayora, Oscar
15
Meneses, Filipe
309
Montanari, Rebecca
236
Moreira, Adriano
309
M¨uller, Julius
197
Murarasu, Alin
1
N¨oyr¨anen, Janne
87
Nurminen, Jukka K.
87
Osmani, Venet
15
Ozyurt, Murat
208
Papliatseyeu, Andrei
15
Park, Kyu Ho
144
Paulino, Herv´e
157
Pinto, Filipe Cabral
340
Pitsillides, Andreas
340
Rayana, Rayene Ben
43
Reina, Alvaro
185
Riede, Christian
340
Ristau, Henry
295
S´aez, Jes´us
185
Santos, Andr´e C.
266, 352
Sassi, Salma Ben
393
Schmidt, Aubrey-Derrick
381
Schmidt, Hans-Gunther
381
Schmohl, Robert
171
Schneider, Gerhard
72
Seepold, Ralf
185
Shim, Gyudong
144
Sloman, Morris
222
Tarrataca, Lu´ıs
266, 352
Tavares, Carlos
157
Toninelli, Alessandra
236
Tugcu, Tuna
208
Ventura, Neco
115
Zhou, Rui
72

