Advanced Textbooks in Control and Signal Processing

Series Editors
Professor Michael J. Grimble, Professor of Industrial Systems and Director
Professor Michael A. Johnson, Professor Emeritus of Control Systems and Deputy Director
Industrial Control Centre, Department of Electronic and Electrical Engineering,
University of Strathclyde, Graham Hills Building, 50 George Street, Glasgow G1 1QE, UK
Other titles published in this series:
Genetic Algorithms
K.F. Man, K.S. Tang and S. Kwong
Neural Networks for Modelling and Control of Dynamic Systems
M. Nørgaard, O. Ravn, L.K. Hansen and N.K. Poulsen
Modelling and Control of Robot Manipulators (2nd Edition)
L. Sciavicco and B. Siciliano
Fault Detection and Diagnosis in Industrial Systems
L.H. Chiang, E.L. Russell and R.D. Braatz
Soft Computing
L. Fortuna, G. Rizzotto, M. Lavorgna, G. Nunnari, M.G. Xibilia and R. Caponetto
Statistical Signal Processing
T. Chonavel
Discrete-time Stochastic Processes (2nd Edition)
T. Söderström
Parallel Computing for Real-time Signal Processing and Control
M.O. Tokhi, M.A. Hossain and M.H. Shaheed
Multivariable Control Systems
P. Albertos and A. Sala
Control Systems with Input and Output Constraints
A.H. Glattfelder and W. Schaufelberger
Analysis and Control of Non-linear Process Systems
K. Hangos, J. Bokor and G. Szederkényi
Model Predictive Control (2nd Edition)
E.F. Camacho and C. Bordons
Principles of Adaptive Filters and Self-learning Systems
A. Zaknich
Digital Self-tuning Controllers
V. Bobál, J. Böhm, J. Fessl and J. Macháˇcek
Robust Control Design with MATLAB®
D.-W. Gu, P.Hr. Petkov and M.M. Konstantinov
Publication due July 2005
Active Noise and Vibration Control
M.O. Tokhi
Publication due November 2005

R. Kelly, V. Santibáñez and A. Loría
Control of Robot
Manipulators in
Joint Space
With 110 Figures
123

Rafael Kelly, PhD
Centro de Investigación Cientíﬁca y de Educación Superior de Ensenada
(CICESE), Ensenada B.C. 22800, Mexico
Victor Santibáñez Davila, PhD
Instituto Tecnologico de la Laguna, Torreón, Coahuila, 27001, Mexico
Antonio Loría, PhD
CNRS, Laboratoire des Signaux et Systèmes, Supélec, 3 rue Joliot Curie,
91192 Gif-sur-Yvette, France
British Library Cataloguing in Publication Data
Kelly, R.
Control of robot manipulators in joint space. - (Advanced
textbooks in control and signal processing)
1. Robots - Control systems 2. Manipulators (Mechanism)
3. Programmable controllers
I. Title II. Santibáñez, V. III. Loría, A.
629.8’933
ISBN-10: 1852339942
Library of Congress Control Number: 2005924306
Apart from any fair dealing for the purposes of research or private study, or criticism or review, as
permitted under the Copyright, Designs and Patents Act 1988, this publication may only be reproduced,
stored or transmitted, in any form or by any means, with the prior permission in writing of the
publishers, or in the case of reprographic reproduction in accordance with the terms of licences issued
by the Copyright Licensing Agency. Enquiries concerning reproduction outside those terms should be
sent to the publishers.
Advanced Textbooks in Control and Signal Processing series ISSN 1439-2232
ISBN-10: 1-85233-994-2
ISBN-13: 978-1-85233-994-4
Springer Science+Business Media
springeronline.com
© Springer-Verlag London Limited 2005
The use of registered names, trademarks, etc. in this publication does not imply, even in the absence of
a speciﬁc statement, that such names are exempt from the relevant laws and regulations and therefore
free for general use.
The publisher makes no representation, express or implied, with regard to the accuracy of the infor-
mation contained in this book and cannot accept any legal responsibility or liability for any errors or
omissions that may be made.
Typesetting: Camera ready by authors
Production: LE-TEX Jelonek, Schmidt & Vöckler GbR, Leipzig, Germany
Printed in Germany
69/3141-543210 Printed on acid-free paper SPIN 11321323

To my parents,
with everlasting love, respect and admiration.
–AL

“Attentive readers, who spread their thoughts among
themselves, always go beyond the author”
—Voltaire∗, 1763.
∗Original citation in French: “Des lecteurs attentifs, qui se communiquent leurs
pens´ees, vont toujours plus loin que l’auteur”, in Trait´e sur la tol´erence `a
l’occasion de la mort de Jean Calas, Voltaire, 1763.

Series Editors’ Foreword
The topics of control engineering and signal processing continue to ﬂourish and
develop. In common with general scientiﬁc investigation, new ideas, concepts
and interpretations emerge quite spontaneously and these are then discussed,
used, discarded or subsumed into the prevailing subject paradigm. Sometimes
these innovative concepts coalesce into a new sub-discipline within the broad
subject tapestry of control and signal processing. This preliminary battle be-
tween old and new usually takes place at conferences, through the Internet and
in the journals of the discipline. After a little more maturity has been acquired
by the new concepts then archival publication as a scientiﬁc or engineering
monograph may occur.
A new concept in control and signal processing is known to have arrived
when suﬃcient material has evolved for the topic to be taught as a specialized
tutorial workshop or as a course to undergraduate, graduate or industrial
engineers. Advanced Textbooks in Control and Signal Processing are designed
as a vehicle for the systematic presentation of course material for both popular
and innovative topics in the discipline. It is hoped that prospective authors will
welcome the opportunity to publish a structured and systematic presentation
of some of the newer emerging control and signal processing technologies in
the textbook series.
One of our aims for the Advanced Textbooks in Control and Signal Pro-
cessing series is to create a set of course textbooks that are comprehensive
in their coverage. Even though a primary aim of the series is to service the
textbook needs of various types of advanced courses we also hope that the
industrial control engineer and the control academic will be able to collect
the series volumes and use them as a reference library in control and signal
processing.
Robotics is an area where the series has the excellent entry in the volume
by L. Sciavicco and B. Siciliano entitled Modelling and Control of Robot Ma-
nipulators, now in its second edition. To complement our coverage in Robotics,
we are pleased to welcome into the series this new volume Control of Robot
Manipulators in Joint Space by Rafael Kelly, V´ıctor Santib´a˜nez and Antonio
Lor´ıa. Other topics like models, kinematics and dynamics are introduced into

x
Series Editors’ Foreword
the narrative as and when they are needed to design and compute the robot
manipulator controllers. Another novel feature of the text is the extensive use
of the laboratory prototype Pelican robotic manipulator as the test-bed case
study for the robot manipulator controllers devised. This ensures that the
reader will be able to see how robot manipulator control is done in practice.
Indeed, this means that the text can be closely linked to “hands on” laboratory
experience. Control and mechatronics lecturers wishing to use the textbook
to support their advance course on robot manipulator control will ﬁnd the
lecture presentation slides, and the problem solutions, which are available at
springonline.com, an added bonus.
The style of the text is formally rigorous but avoids a lemma–theorem
presentation in favour of one of thorough explanation. Chapter 2 of the text
covers the main mathematical tools and introduces the concepts of the direct
(or second) method of Lyapunov for system stability analysis. This is needed
because the robot manipulator system is a nonlinear system. Since the cover-
age in this chapter includes a wide range of stability concepts, the reader will
be pleased to ﬁnd each new concept supported by a worked example. Robot
dynamics and their implications for robot manipulator control are covered in
Chapters 3 and 4 whilst Chapter 5 moves on to discuss the model details of
the Pelican prototype robotic manipulator. The kinematic and dynamic mod-
els are, described and model parameter values given. This chapter shows how
the Pelican prototype is “kitted out” with a set of models the properties of
which are then investigated in preparation for the control studies to follow.
Parts II to IV (covering Chapters 6 to 16) are devoted to robot manip-
ulator controller design and performance case studies. This shows just how
focused the textbook is on robot manipulator control. This study is given
in three stages: position control (Part II); motion control (Part Ill) and ad-
vanced control topics (Part IV). Remarkably, the workhorse controller type
being used is from the PID family so that the control focus is close to the
type of controllers used widely in industrial applications, namely from the
classical Proportional, Integral, Derivative controller family. In these chapter-
length controller studies, the earlier lessons in Lyapunov stability methods
come to the fore, demonstrating how Lyapunov theory is used for controllers
of a classical form being used with nonlinear system models to prove the
necessary stability results. The advanced control topics covered in Part IV
include a range of adaptive control methods. Four appendices are given with
additional material on the mathematical and Lyapunov methods used and on
the modelling details of direct current motors.
There is no doubt that this robot manipulator control course textbook
is a challenging one but ultimately a very rewarding one. From a general
viewpoint the reward of learning about how to approach classical control for
systems having nonlinear models is a valuable one with potential application in
other control ﬁelds. For robot manipulator control per se, the book is rigorous,
thorough and comprehensive in its presentation and is an excellent addition
to the series of advanced course textbooks in control and signal processing.
M.J. Grimble and M.A. Johnson
Glasgow, Scotland, U.K.
March 2005

Preface
The concept of robot has transformed from the idea of an artiﬁcial super-
human, materialized by the pen of science ﬁction writer Karel ˇCapek, into
the reality of animated autonomous machines. An important class of these
are the robot manipulators, designed to perform a wide variety of tasks in
production lines of diverse industrial sectors; perhaps the most clear exam-
ple is the automotive industry. Robotics, introduced by science ﬁction writer
Isaac Asimov as the study of robots, has become a truly vast ﬁeld of modern
technology involving specialized knowledge from a range of disciplines such as
electrical engineering, mechatronics, cybernetics, computer science, mechani-
cal engineering and applied mathematics.
As a result, courses on robotics continue to gain interest and, following the
demands of modern industry, every year more and more program studies, from
engineering departments and faculties of universities round the globe, include
robotics as a compulsory subject. While a complete course on robotics that
is, including topics such as modeling, control, technological implementation
and instrumentation, may need two terms at graduate level to be covered in
fair generality, other more specialized courses can be studied in one senior
year term. The present text addresses the subject in the second manner; it is
mostly devoted to the speciﬁc but vast topic of robot control.
Robot control is the spine of robotics. It consists in studying how to make a
robot manipulator do what it is desired to do automatically; hence, it consists
in designing robot controllers. Typically, these take the form of an equation
or an algorithm which is realized via specialized computer programs. Then,
controllers form part of the so-called robot control system which is physically
constituted of a computer, a data acquisition unit, actuators (typically elec-
trical motors), the robot itself and some extra “electronics”. Thus, the design
and full implementation of a robot controller relies on every and each of the
above-mentioned disciplines.
The simplest controller for industrial robot manipulators is the Propor-
tional Integral Derivative (PID) controller. In general, this type of controller

xii
Preface
is designed on the basis that the robot model is composed of independent cou-
pled dynamic (diﬀerential) equations. While these controllers are widely used
in industrial manipulators (robotic arms), depending on the task to be carried
out, they do not always result in the best performance. To improve the latter
it is current practice to design so-called model-based controllers, which require
a precise knowledge of the dynamic model including the values of the physi-
cal parameters involved. Other, non-model-based controllers, used mainly in
academic applications and research prototypes include the so-called variable-
structure controllers, fuzzy controllers, learning controllers, neural-net-based
controllers, to mention a few.
The majority of available texts on robotics cover all of its main aspects,
that is, modeling (of kinematics and dynamics), trajectory generation (that is,
the mathematical setting of a task to be performed by the robot), robot control
and some of them, instrumentation, software and other implementation issues.
Because of their wide scope, texts typically broach the mentioned topics in a
survey rather than a detailed manner.
Control of robot manipulators in joint space is a counter-fact to most avail-
able literature on robotics since it is mostly devoted to robot control, while ad-
dressing other topics, such as kinematics, mainly through case studies. Hence,
we have sacriﬁced generality for depth and clarity of exposition by choosing
to address in great detail a range of model-based controllers such as: Pro-
portional Derivative (PD), Proportional Integral Derivative (PID), Computed
torque and some variants including adaptive versions. For purely didactic rea-
sons, we have also chosen to focus on control in joint space, totally skipping
task space and end-eﬀector space based control. These topics are addressed in
a number of texts elsewhere.
The present book opens with an introductory chapter explaining, in gen-
eral terms, what robot control involves. It contains a chapter on preliminaries
which presents in a considerably detailed manner the main mathematical con-
cepts and tools necessary to study robot control. In particular, this chapter
introduces the student to advanced topics such as Lyapunov stability, the
core of control theory and therefore, of robot control. We emphasize at this
point that, while this topic is usually reserved for graduate students, we have
paid special attention to include only the most basic theorems and we have
reformulated the latter in simple statements. We have also included numer-
ous examples and explanations to make this material accessible to senior year
undergraduate students.
Kinematics is addressed mainly through examples of diﬀerent manipula-
tors. Dynamics is presented in two chapters but from a viewpoint that stresses
the most relevant issues for robot control; i.e. we emphasize certain funda-
mental properties of the dynamic model of robots, which are commonly taken
as satisﬁed hypotheses in control design.

Preface
xiii
We have also included a chapter entirely devoted to the detailed descrip-
tion of the Pelican prototype, a 2-degrees-of-freedom direct-drive planar ar-
ticulated arm that is used throughout the book as a case study to test the
performance of the studied controllers, in lab experimentation. Dynamic and
kinematic models are derived in detail for this particular robot. The rest of
the book (about 70%) is devoted to the study of a number of robot controllers,
each of which is presented in a separate chapter.
The text is organized in four main parts: I) Preliminaries, which contains
the two chapters on robot dynamics, the chapter on mathematical preliminar-
ies and the chapter describing the Pelican prototype. Parts II and III contain,
respectively, set-point and tracking model-based controllers. Part IV covers
additional topics such as adaptive versions of the controllers studied in parts
II and III, and a controller that does not rely on velocity measurements. Ap-
pendices containing some extra mathematical support, Lyapunov theory for
the advanced reader and a short treatment on DC motors, are presented at
the end of the book.
Thus, the present book is a self-contained text to serve in a course on robot
control e.g., within a program of Mechatronics or Electrical Engineering at
senior year of BSc or ﬁrst year of MSc. Chapter 1 may be covered in one or
two sessions. We strongly recommend taking the time to revise thoroughly
Chapter 2 which is instrumental for the remainder of the textbook. The rest
of the material may be taught in diﬀerent ways and depths depending on
the level of students and the duration of the course. For instance, Parts I
through III may be covered entirely in about 50 hours at senior year level. If
the course is to be shortened, the lecturer may choose to pass over Chapters
3 and 4 faster (or even completely skip them and refer to their contents only
when necessary) and to introduce the student to kinematics and dynamics
using Chapter 5; then, to focus on Parts II and III. For a yet shorter but
coherent basic course, the lecturer may choose to teach only Chapters 1, 2,
5 and, for the subsequent chapters of Parts II and III, concentrate on a brief
study of the control laws while emphasizing the examples that concern the
Pelican prototype. Further, support material for class -presentation slides for
the lecturer and problems’ solutions manual- are available in electronic form
at springonline.com.
For a graduate course the lecturer may choose to cover, in addition, the
three chapters on adaptive control (Chapters 14–16), or Chapter 13 on control
without velocity measurements and Chapter 14, to give a short introduction
to adaptive control. We remark that the advanced topics of Part IV require
the material in the appendices which could be taught, for instance, at the
beginning of the course or could be left as a self-study topic.
The textbook is written in a style and technical language targeted toward
undergraduate senior students. Hence, we have favored a thoroughly explana-
tory, yet rigorous, style over a stiﬀmathematical (theorem-proof streamed)
one. We have taken care to invoke a strictly minimum number of mathematical

xiv
Preface
terms and these are mostly explained when introduced. Mathematical objects
such as theorems and deﬁnitions are kept to a minimum; they are mainly
present in Chapter 2 (mathematical preliminaries) and some appendices. Yet,
when simplicity in the language may induce mathematical ambiguity or im-
precision we have added clarifying footnotes. A large number of examples,
illustrations and problems to be solved in class or as homework by the stu-
dent are provided.
The precedents of the text date back to lecture notes of the ﬁrst author
that were printed by the National Autonomous University of Mexico (UNAM)
in 1989. It has been enriched by the authors’ experience of teaching the topic
over more than 15 years at undergraduate (senior year) and graduate levels
(ﬁrst year), in several institutions in Europe and The Americas: National Au-
tonomous Univ. of Mexico (UNAM), Mexico; Technological Institute and of
High Studies of Monterrey (ITESM), Mexico; Center of Research and High
Studies of Ensenada (CICESE), Mexico; Laguna Institute of Technology, Mex-
ico; University of California at Santa Barbara, USA; National University of
Science and Technology (NTNU), Norway; San Juan National University, Ar-
gentina. This has provided the text with invaluable feedback from a varied
audience with diﬀerent technical and cultural backgrounds. Thus, the authors
are conﬁdent to say that this textbook has not been written to be tested but
to be used in class.
A few ﬁnal words on the nomenclature are necessary. Figures, Examples,
Equations, Tables, Theorems, Lemmas, Deﬁnitions are numbered indepen-
dently and carry the number of the chapter. We use the following abbrevia-
tions of Latin idioms:
i.e. –id est– meaning “that is”;
e.g. –exempli gratia– meaning “for instance”;
cf. –confer– meaning “see”;
etc. –etcetera– meaning “and the rest”.
Acknowledgments
The authors wish to thank the Mexican National Council of Science and Tech-
nology (CONACyT) whose sponsorship, to the ﬁrst author, yielded an early
version of this text (in Spanish). The ﬁrst author also acknowledges the sup-
port of the Mexican Centre for Scientiﬁc Research and High Studies of En-
senada (CICESE). The second author acknowledges the receipt of numerous
research grants from CONACyT and the Council of the National System of
Technological Education (COSNET), which served in part in the elaboration
of this text. Most of the writing of this textbook was realized while the third
author was holding a visiting professorship at CICESE in 2002 and 2003.
The third author acknowledges the grants obtained and praises the extraordi-
nary working conditions provided by the French National Centre for Scientiﬁc
Research (CNRS).

Preface
xv
The realization of this textbook would not have been possible without
the valuable feedback of numerous colleagues and students throughout the
years. In particular, the ﬁrst author is thanks Ricardo Carelli and Romeo
Ortega, the collaboration with whom extended over almost 20 years, and
which considerably improved both the contents and writing of the present
book. The authors also acknowledge the numerous exchanges on the topics of
the present book, with Mark Spong, Suguru Arimoto, Carlos Canudas de Wit,
Jean-Jacques Slotine, John T. Wen, Roberto Horowitz, Daniel Koditschek,
Claude Samson, Louis Whitcomb, Harry Berghuis, Henk Nijmeijer, Hebertt
Sira-Ram´ırez, Juan M. Ibarra, Alfonso P´amanes, Ilse Cervantes, Jos´e Alvarez-
Ram´ırez, Antoine Chaillet and Marco A. Arteaga.
Special words of thanks go to Ricardo Campa who actively participated
in the lab experiments presented in the examples throughout the book. The
authors wish to single out the invaluable comments, remarks and corrections
provided by the students of the numerous institutions where this material has
been taught.
The third author takes this opportunity to mention that it was with an
early version of the lecture notes that evolved into this text, that he was
introduced to Lyapunov theory and robotics, by the ﬁrst author. It is a honor
and a great pleasure to participate in writing this book. He also wishes to
express his deep gratitude to his friend and scientiﬁc mentor Romeo Ortega
for his valuable teaching, in particular, on robot control.
The authors acknowledge the valuable assistance of Oliver Jacksson, their
contact editor at Springer-Verlag, London, along the publication process of
this book; from the state of proposal to its realization. Last but not least,
the authors acknowledge both their technical and language reviewers; it goes
without saying that any error in the contents or in the typeset of the present
text is the entire responsibility of the authors.
Ensenada, Mexico
Rafael Kelly,
Torre´on, Mexico
V´ıctor Santib´a˜nez,
Gif sur Yvette, France
Antonio Lor´ıa
May 2005

Contents
List of Figures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .xxiii
Part I Preliminaries
Introduction to Part I . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1
What Does “Control of Robots” Involve? . . . . . . . . . . . . . . . . . .
7
1.1
Familiarization with the Physical System under Consideration.
8
1.2
Dynamic Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
1.3
Control Speciﬁcations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
1.4
Motion Control of Robot Manipulators . . . . . . . . . . . . . . . . . . . . . 12
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
2
Mathematical Preliminaries. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
2.1
Linear Algebra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
2.2
Fixed Points . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
2.3
Lyapunov Stability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
2.3.1
The Concept of Equilibrium . . . . . . . . . . . . . . . . . . . . . . . . 28
2.3.2
Deﬁnitions of Stability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
2.3.3
Lyapunov Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
2.3.4
Lyapunov’s Direct Method . . . . . . . . . . . . . . . . . . . . . . . . . 44
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
3
Robot Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59

xviii
Contents
3.1
Lagrange’s Equations of Motion . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
3.2
Dynamic Model in Compact Form . . . . . . . . . . . . . . . . . . . . . . . . . 71
3.3
Dynamic Model of Robots with Friction . . . . . . . . . . . . . . . . . . . . 75
3.4
Dynamic Model of Elastic-joint Robots . . . . . . . . . . . . . . . . . . . . . 77
3.5
Dynamic Model of Robots with Actuators . . . . . . . . . . . . . . . . . . 82
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
4
Properties of the Dynamic Model. . . . . . . . . . . . . . . . . . . . . . . . . . 95
4.1
The Inertia Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
4.2
The Centrifugal and Coriolis Forces Matrix
. . . . . . . . . . . . . . . . 97
4.3
The Gravitational Torques Vector . . . . . . . . . . . . . . . . . . . . . . . . . 101
4.4
The Residual Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
4.5
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
5
Case Study: The Pelican Prototype Robot . . . . . . . . . . . . . . . . . 113
5.1
Direct Kinematics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
5.2
Inverse Kinematics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
5.3
Dynamic Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
5.3.1
Lagrangian Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
5.3.2
Model in Compact Form . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
5.4
Desired Reference Trajectories . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
Part II Position Control
Introduction to Part II . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
6
Proportional Control plus Velocity Feedback and PD
Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
6.1
Robots without Gravity Term . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
6.2
Robots with Gravity Term . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
6.2.1
Unicity of the Equilibrium . . . . . . . . . . . . . . . . . . . . . . . . . . 146

Contents
xix
6.2.2
Arbitrarily Bounded Position and Velocity Error . . . . . . 148
6.3
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
7
PD Control with Gravity Compensation . . . . . . . . . . . . . . . . . . 157
7.1
Global Asymptotic Stability by La Salle’s Theorem . . . . . . . . . . 159
7.2
Lyapunov Function for Global Asymptotic Stability . . . . . . . . . . 163
7.2.1
Positivity of the Lyapunov Function . . . . . . . . . . . . . . . . . 164
7.2.2
Time Derivative of the Lyapunov Function . . . . . . . . . . . 165
7.3
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168
8
PD Control with Desired Gravity Compensation . . . . . . . . . . 171
8.1
Boundedness of Position and Velocity Errors, ˜q and ˙q . . . . . . . . 174
8.2
Unicity of Equilibrium . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180
8.3
Global Asymptotic Stability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
8.4
Lyapunov Function for Global Asymptotic Stability . . . . . . . . . . 190
8.5
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196
9
PID Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201
9.1
Lyapunov Function Candidate . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
9.2
Time Derivative of the Lyapunov Function Candidate . . . . . . . 209
9.3
Asymptotic Stability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
9.4
Tuning Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213
9.5
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218
Part III Motion Control
Introduction to Part III . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223
10
Computed-torque Control and Computed-torque+ Control 227

xx
Contents
10.1 Computed-torque Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227
10.2 Computed-torque+ Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232
10.3 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
11
PD+ Control and PD Control with Compensation . . . . . . . . . 243
11.1 PD Control with Compensation . . . . . . . . . . . . . . . . . . . . . . . . . . . 244
11.2 PD+ Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
11.2.1 Lyapunov Function for Asymptotic Stability . . . . . . . . . . 253
11.3 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260
12
Feedforward Control and PD Control plus Feedforward . . . . 263
12.1 Feedforward Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264
12.2 PD Control plus Feedforward . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
12.2.1 Unicity of the Equilibrium . . . . . . . . . . . . . . . . . . . . . . . . . . 271
12.2.2 Global Uniform Asymptotic Stability . . . . . . . . . . . . . . . . 273
12.3 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284
Part IV Advanced Topics
Introduction to Part IV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289
13
P“D” Control with Gravity Compensation and P“D”
Control with Desired Gravity Compensation. . . . . . . . . . . . . . . 291
13.1 P“D” Control with Gravity Compensation . . . . . . . . . . . . . . . . . . 292
13.2 P“D” Control with Desired Gravity Compensation. . . . . . . . . . . 300
13.3 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
14
Introduction to Adaptive Robot Control . . . . . . . . . . . . . . . . . . . 313
14.1 Parameterization of the Dynamic Model . . . . . . . . . . . . . . . . . . . . 314

Contents
xxi
14.1.1 Linearity in the Dynamic Parameters . . . . . . . . . . . . . . . . 315
14.1.2 The Nominal Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319
14.2 The Adaptive Robot Control Problem. . . . . . . . . . . . . . . . . . . . . . 325
14.3 Parameterization of the Adaptive Controller . . . . . . . . . . . . . . . . 327
14.3.1 Stability and Convergence of Adaptive Control Systems 329
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 334
15
PD Control with Adaptive Desired Gravity Compensation. 337
15.1 The Control and Adaptive Laws . . . . . . . . . . . . . . . . . . . . . . . . . . . 338
15.2 Stability Analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342
15.3 Examples. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349
15.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 357
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 358
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 359
16
PD Control with Adaptive Compensation . . . . . . . . . . . . . . . . . 361
16.1 The Control and Adaptive Laws . . . . . . . . . . . . . . . . . . . . . . . . . . . 361
16.2 Stability Analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365
16.3 Examples. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 368
16.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 377
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 377
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378
Appendices
A
Mathematical Support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 383
A.1 Some Lemmas on Linear Algebra . . . . . . . . . . . . . . . . . . . . . . . . . . 383
A.2 Vector Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 384
A.3 Functional Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 390
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 398
B
Support to Lyapunov Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 401
B.1 Conditions for Positive Deﬁniteness of Functions . . . . . . . . . . . . 401
C
Proofs of Some Properties of the Dynamic Model . . . . . . . . . 407

xxii
Contents
D
Dynamics of Direct-current Motors . . . . . . . . . . . . . . . . . . . . . . . . 411
D.1 Motor Model with Linear Friction . . . . . . . . . . . . . . . . . . . . . . . . . 416
D.2 Motor Model with Nonlinear Friction . . . . . . . . . . . . . . . . . . . . . . 417
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 418
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 419

List of Figures
I.1
Robot manipulator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.1
Freely moving robot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.2
Robot interacting with its environment. . . . . . . . . . . . . . . . . . . . . .
8
1.3
Robotic system: ﬁxed camera . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
1.4
Robotic system: camera in hand . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
1.5
Input–output representation of a robot . . . . . . . . . . . . . . . . . . . . . . 10
1.6
Point-to-point motion speciﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . 13
1.7
Trajectory motion speciﬁcation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
2.1
Concept of equilibrium . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
2.2
Pendulum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
2.3
Notion of stability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
2.4
Phase plane of the harmonic oscillator . . . . . . . . . . . . . . . . . . . . . . 33
2.5
Asymptotic stability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
2.6
Attractive but unstable equilibrium . . . . . . . . . . . . . . . . . . . . . . . . . 35
2.7
Phase plane of the van der Pol oscillator . . . . . . . . . . . . . . . . . . . . 40
2.8
Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
2.9
Phase plane of the pendulum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
3.1
Abstract diagram of an n-DOF robot manipulator . . . . . . . . . . . . 59
3.2
Example of a 4-DOF robot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
3.3
Example of a 1-DOF mechanism . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
3.4
Example of a 2-DOF robot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
3.5
Example of a 3-DOF Cartesian robot . . . . . . . . . . . . . . . . . . . . . . . 70

xxiv
List of Figures
3.6
Input–output representation of a robot . . . . . . . . . . . . . . . . . . . . . . 73
3.7
Diagram of a robot with elastic joints . . . . . . . . . . . . . . . . . . . . . . . 78
3.8
Link with an elastic joint . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
3.9
Example of a 2-DOF robot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
3.10 Example of a 2-DOF robot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82
3.11 Diagram of a DC motor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
3.12 Block-diagram of a robot with its actuators . . . . . . . . . . . . . . . . . . 84
3.13 Pendular device with a DC motor . . . . . . . . . . . . . . . . . . . . . . . . . . 85
3.14 Problem 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
3.15 Problems 3 and 4. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
3.16 Problem 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
3.17 Problem 6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
4.1
Graph of tangent hyperbolic: tanh(x) . . . . . . . . . . . . . . . . . . . . . . . 103
4.2
Belonging region for ∥g(qd) −g(qd −˜q)∥. . . . . . . . . . . . . . . . . . . . 105
4.3
Graph of the function s(˜q) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
4.4
Problem 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
5.1
Pelican: experimental robot arm at CICESE, Robotics lab. . . . . 114
5.2
Diagram of the 2-DOF Pelican prototype robot . . . . . . . . . . . . . . 114
5.3
Two solutions to the inverse kinematics problem . . . . . . . . . . . . . 117
5.4
“Bent-over” singular conﬁguration . . . . . . . . . . . . . . . . . . . . . . . . . . 119
5.5
Desired reference trajectories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
5.6
Norm of the desired positions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
5.7
Norm of the desired velocities vector . . . . . . . . . . . . . . . . . . . . . . . . 130
5.8
Norm of the desired accelerations vector . . . . . . . . . . . . . . . . . . . . . 131
II.1 Position control: closed-loop system . . . . . . . . . . . . . . . . . . . . . . . . . 137
II.2 Set-point control closed-loop system. Input–output
representation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
6.1
Block-diagram: Proportional control plus velocity feedback . . . . 141
6.2
Block-diagram: PD control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
6.3
Graph of ˜q(t)2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
6.4
Graph of ˙q(t)2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
6.5
Graph of the position errors ˜q1 and ˜q2 . . . . . . . . . . . . . . . . . . . . . . 152
7.1
Block-diagram: PD control with gravity compensation . . . . . . . . 158

List of Figures
xxv
7.2
Diagram of the Pelican robot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
7.3
Graph of the position errors ˜q1 and ˜q2 . . . . . . . . . . . . . . . . . . . . . . 162
7.4
Graph of the tangent hyperbolic function: tanh(x) . . . . . . . . . . . . 163
8.1
Block-diagram: PD control with desired gravity compensation . . 172
8.2
PD control with desired gravity compensation: graph of the
position error ˜q(t)2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178
8.3
PD control with desired gravity compensation: graph of
velocity, ˙q(t)2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179
8.4
Graph of the position errors ˜q1 and ˜q2 . . . . . . . . . . . . . . . . . . . . . . 186
8.5
Bifurcation diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188
8.6
Simulation with kp = −11, −4, 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
8.7
Catastrophic jump 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
8.8
Catastrophic jump 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
9.1
Block-diagram: PID control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
9.2
Desired joint positions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205
9.3
Diagram of the Pelican prototype robot . . . . . . . . . . . . . . . . . . . . . 214
9.4
Graphs of position errors ˜q1 and ˜q2 . . . . . . . . . . . . . . . . . . . . . . . . . 215
9.5
Graphs of position errors ˜q1 and ˜q2 . . . . . . . . . . . . . . . . . . . . . . . . . 216
III.1 Motion control: closed-loop system . . . . . . . . . . . . . . . . . . . . . . . . . 224
III.2 Motion control closed-loop system in its input–output
representation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
10.1 Block-diagram: computed-torque control . . . . . . . . . . . . . . . . . . . . 228
10.2 Graph of position errors against time . . . . . . . . . . . . . . . . . . . . . . . 232
10.3 Computed-torque+ control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234
10.4 Graph of position errors against time . . . . . . . . . . . . . . . . . . . . . . . 237
10.5 Problem 1. Cartesian 2-DOF robot. . . . . . . . . . . . . . . . . . . . . . . . . . 239
11.1 Block-diagram: PD control with compensation . . . . . . . . . . . . . . . 245
11.2 Diagram of the Pelican robot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247
11.3 Graph of position errors against time . . . . . . . . . . . . . . . . . . . . . . . 248
11.4 Block-diagram: PD+ control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249
11.5 Graph of the position errors against time . . . . . . . . . . . . . . . . . . . . 253
12.1 Block-diagram: feedforward control . . . . . . . . . . . . . . . . . . . . . . . . . 265
12.2 Diagram of the Pelican prototype . . . . . . . . . . . . . . . . . . . . . . . . . . 268

xxvi
List of Figures
12.3 Graphs of position errors ˜q1 and ˜q2 . . . . . . . . . . . . . . . . . . . . . . . . . 269
12.4 Block-diagram: PD control plus feedforward . . . . . . . . . . . . . . . . . 270
12.5 Graphs of position errors ˜q1 and ˜q2 . . . . . . . . . . . . . . . . . . . . . . . . . 282
13.1 Block-diagram: P“D” control with gravity compensation . . . . . . 293
13.2 Graphs of position errors ˜q1(t) and ˜q2(t) . . . . . . . . . . . . . . . . . . . . . 299
13.3 Block-diagram: P“D” control with desired gravity compensation 300
13.4 Graphs of position errors ˜q1(t) and ˜q2(t) . . . . . . . . . . . . . . . . . . . . . 307
14.1 Planar 2-DOF manipulator on a horizontal plane . . . . . . . . . . . . . 322
14.2 Block-diagram: generic adaptive control of robots. . . . . . . . . . . . . 329
14.3 Problem 2. Cartesian robot. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 335
15.1 Graphs of position errors ˜q1 and ˜q2 . . . . . . . . . . . . . . . . . . . . . . . . . 355
15.2 Graphs of adaptive parameters ˆθ1 and ˆθ2 . . . . . . . . . . . . . . . . . . . . 356
15.3 Graphs of position errors ˜q1 and ˜q2 . . . . . . . . . . . . . . . . . . . . . . . . . 357
15.4 Graphs of adaptive parameters ˆθ1 and ˆθ2 . . . . . . . . . . . . . . . . . . . . 357
16.1 Block-diagram: pendulum under PD control with adaptive
compensation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370
16.2 Planar 2-DOF manipulator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 371
16.3 Diagram of the Pelican robot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 373
16.4 Graphs of position errors ˜q1 and ˜q2 . . . . . . . . . . . . . . . . . . . . . . . . . 376
16.5 Graphs of adaptive parameters ˆθ1, ˆθ2, and ˆθ3 . . . . . . . . . . . . . . . . 377
16.6 Problem 4. Cartesian 2-DOF robot. . . . . . . . . . . . . . . . . . . . . . . . . . 380
A.1 Example A.1: graph of α . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 390
A.2 Problem 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 398
D.1 DC motor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 411
D.2 DC motor with cylindrical inertia . . . . . . . . . . . . . . . . . . . . . . . . . . 414
D.3 Pendular device . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 415
D.4 Nonlinear friction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 417

Part I
Preliminaries

Introduction to Part I
The high quality and rapidity requirements in production systems of our
globalized contemporary world demand a wide variety of technological ad-
vancements. Moreover, the incorporation of these advancements in modern
industrial plants grows rapidly. A notable example of this situation, is the
privileged place that robots occupy in the modernization of numerous sectors
of the society.
The word robot ﬁnds its origins in robota which means work in Czech.
In particular, robot was introduced by the Czech science ﬁction writer Karel
ˇCapek to name artiﬁcial humanoids – biped robots – which helped human
beings in physically diﬃcult tasks. Thus, beyond its literal deﬁnition the term
robot is nowadays used to denote animated autonomous machines. These ma-
chines may be roughly classiﬁed as follows:
• Robot manipulators
• Mobile robots
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
Ground robots

Wheeled robots
Legged robots
Submarine robots
Aerial robots
.
Both, mobile robots and manipulators are key pieces of the mosaic that con-
stitutes robotics nowadays. This book is exclusively devoted to robot manip-
ulators.
Robotics – a term coined by the science ﬁction writer Isaac Asimov – is
as such a rather recent ﬁeld in modern technology. The good understanding
and development of robotics applications are conditioned to the good knowl-
edge of diﬀerent disciplines. Among these, electrical engineering, mechanical
engineering, industrial engineering, computer science and applied mathemat-
ics. Hence, robotics incorporates a variety of ﬁelds among which is automatic
control of robot manipulators.

4
Part I
To date, we count several deﬁnitions of industrial robot manipulator not
without polemic among authors. According to the deﬁnition adopted by the
International Federation of Robotics under standard ISO/TR 8373, a robot
manipulator is deﬁned as follows:
A manipulating industrial robot is an automatically controlled, re-
programmable, multipurpose manipulator programmable in three
or more axes, which may be either ﬁxed in place or mobile for use
in industrial automation applications.
In spite of the above deﬁnition, we adopt the following one for the prag-
matic purposes of the present textbook: a robot manipulator – or simply,
manipulator – is a mechanical articulated arm that is constituted of links in-
terconnected through hinges or joints that allow a relative movement between
two consecutive links.
The movement of each joint may be prismatic, revolute or a combination
of both. In this book we consider only joints which are either revolute or pris-
matic. Under reasonable considerations, the number of joints of a manipulator
determines also its number of degrees of freedom (DOF ). Typically, a manip-
ulator possesses 6 DOF, among which 3 determine the position of the end of
the last link in the Cartesian space and 3 more specify its orientation.
q1
q2
q3
Figure I.1. Robot manipulator
Figure I.1 illustrates a robot manipulator. The variables q1, q2 and q3
are referred to as the joint positions of the robot. Consequently, these posi-
tions denote under the deﬁnition of an adequate reference frame, the positions
(displacements) of the robot’s joints which may be linear or angular. For ana-

Introduction to Part I
5
lytical purposes, considering an n-DOF robot manipulator, the joint positions
are collected in the vector q, i.e.2
q :=
⎡
⎢⎢⎣
q1
q2
...
qn
⎤
⎥⎥⎦.
Physically, the joint positions q are measured by sensors conveniently located
on the robot. The corresponding joint velocities ˙q :=
d
dtq may also be mea-
sured or estimated from joint position evolution.
To each joint corresponds an actuator which may be electromechanical,
pneumatic or hydraulic. The actuators have as objective to generate the forces
or torques which produce the movement of the links and consequently, the
movement of the robot as a whole. For analytical purposes these torques and
forces are collected in the vector τ, i.e.
τ :=
⎡
⎢⎢⎣
τ1
τ2
...
τn
⎤
⎥⎥⎦.
In its industrial application, robot manipulators are commonly employed
in repetitive tasks of precision and others, which may be hazardous for human
beings. The main arguments in favor of the use of manipulators in industry
is the reduction of production costs, enhancement of precision, quality and
productivity while having greater ﬂexibility than specialized machines. In ad-
dition to this, there exist applications which are monopolized by robot manip-
ulators, as is the case of tasks in hazardous conditions such as in radioactive,
toxic zones or where a risk of explosion exists, as well as spatial and sub-
marine applications. Nonetheless, short-term projections show that assembly
tasks will continue to be the main applications of robot manipulators.
2 The symbol “:=” stands for is deﬁned as.

1
What Does “Control of Robots” Involve?
The present textbook focuses on the interaction between robotics and electri-
cal engineering and more speciﬁcally, in the area of automatic control. From
this interaction emerges what we call robot control.
Loosely speaking (in this textbook), robot control consists in studying how
to make a robot manipulator perform a task and in materializing the results
of this study in a lab prototype.
In spite of the numerous existing commercial robots, robot control design
is still a ﬁeld of intensive study among robot constructors and research cen-
ters. Some specialists in automatic control might argue that today’s industrial
robots are already able to perform a variety of complex tasks and therefore,
at ﬁrst sight, the research on robot control is not justiﬁed anymore. Never-
theless, not only is research on robot control an interesting topic by itself but
it also oﬀers important theoretical challenges and more signiﬁcantly, its study
is indispensable in speciﬁc tasks which cannot be performed by the present
commercial robots.
As a general rule, control design may be divided roughly into the following
steps:
•
familiarization with the physical system under consideration;
•
modeling;
•
control speciﬁcations.
In the sequel we develop further on these stages, emphasizing speciﬁcally
their application in robot control.

8
1 What Does “Control of Robots” Involve?
1.1 Familiarization with the Physical System under
Consideration
On a general basis, during this stage one must determine the physical variables
of the system whose behavior is desired to control. These may be temperature,
pressure, displacement, velocity, etc. These variables are commonly referred to
as the system’s outputs. In addition to this, we must also clearly identify those
variables that are available and that have an inﬂuence on the behavior of the
system and more particularly, on its outputs. These variables are referred to
as inputs and may correspond for instance, to the opening of a valve, voltage,
torque, force, etc.
Figure 1.1. Freely moving robot
Figure 1.2. Robot interacting with its environment
In the particular case of robot manipulators, there is a wide variety of
outputs – temporarily denoted by y – whose behavior one may wish to control.

1.1 Familiarization with the Physical System under Consideration
9
For robots moving freely in their workspace, i.e. without interacting with
their environment (cf. Figure 1.1) as for instance robots used for painting,
“pick and place”, laser cutting, etc., the output y to be controlled, may cor-
respond to the joint positions q and joint velocities ˙q or alternatively, to the
position and orientation of the end-eﬀector (also called end-tool).
For robots such as the one depicted in Figure 1.2 that have physical contact
with their environment, e.g. to perform tasks involving polishing, deburring of
materials, high quality assembling, etc., the output y may include the torques
and forces f exerted by the end-tool over its environment.
Figure 1.3 shows a manipulator holding a marked tray, and a camera which
provides an image of the tray with marks. The output y in this system may
correspond to the coordinates associated to each of the marks with reference
to a screen on a monitor. Figure 1.4 depicts a manipulator whose end-eﬀector
has a camera attached to capture the scenery of its environment. In this case,
the output y may correspond to the coordinates of the dots representing the
marks on the screen and which represent visible objects from the environment
of the robot.
Image
Camera
Figure 1.3. Robotic system: ﬁxed camera
From these examples we conclude that the corresponding output y of a
robot system – involved in a speciﬁc class of tasks – may in general, be of the
form
y = y(q, ˙q, f) .
On the other hand, the input variables, that is, those that may be modiﬁed
to aﬀect the evolution of the output, are basically the torques and forces
τ applied by the actuators over the robot’s joints. In Figure 1.5 we show

10
1 What Does “Control of Robots” Involve?
Camera
Image
Figure 1.4. Robotic system: camera in hand
the block-diagram corresponding to the case when the outputs are the joint
positions and velocities, that is,
y = y(q, ˙q, f) =

q
˙q

while τ is the input. In this case notice that for robots with n joints one has,
in general, 2n outputs and n inputs.
ROBOT
-
-
-
˙  
Figure 1.5. Input–output representation of a robot
1.2 Dynamic Model
At this stage, one determines the mathematical model which relates the input
variables to the output variables. In general, such mathematical representa-
tion of the system is realized by ordinary diﬀerential equations. The system’s
mathematical model is obtained typically via one of the two following tech-
niques.

1.2 Dynamic Model
11
•
Analytical: this procedure is based on physical laws of the system’s motion.
This methodology has the advantage of yielding a mathematical model as
precise as is wanted.
•
Experimental: this procedure requires a certain amount of experimental
data collected from the system itself. Typically one examines the system’s
behavior under speciﬁc input signals. The model so obtained is in gen-
eral more imprecise than the analytic model since it largely depends on
the inputs and the operating point1. However, in many cases it has the
advantage of being much easier and quicker to obtain.
On certain occasions, at this stage one proceeds to a simpliﬁcation of the
system model to be controlled in order to design a relatively simple con-
troller. Nevertheless, depending on the degree of simpliﬁcation, this may yield
malfunctioning of the overall controlled system due to potentially neglected
physical phenomena. The ability of a control system to cope with errors due to
neglected dynamics is commonly referred to as robustness. Thus, one typically
is interested in designing robust controllers.
In other situations, after the modeling stage one performs the parametric
identiﬁcation. The objective of this task is to obtain the numerical values of
diﬀerent physical parameters or quantities involved in the dynamic model. The
identiﬁcation may be performed via techniques that require the measurement
of inputs and outputs to the controlled system.
The dynamic model of robot manipulators is typically derived in the an-
alytic form, that is, using the laws of physics. Due to the mechanical nature
of robot manipulators, the laws of physics involved are basically the laws of
mechanics.
On the other hand, from a dynamical systems viewpoint, an n-DOF system
may be considered as a multivariable nonlinear system. The term “multivari-
able” denotes the fact that the system has multiple (e.g. n) inputs (the forces
and torques τ applied to the joints by the electromechanical, hydraulic or
pneumatic actuators) and, multiple (2n) state variables typically associated
to the n positions q, and n joint velocities ˙q . In Figure 1.5 we depict the cor-
responding block-diagram assuming that the state variables also correspond
to the outputs. The topic of robot dynamics is presented in Chapter 3. In
Chapter 5 we provide the speciﬁc dynamic model of a two-DOF prototype of
a robot manipulator that we use to illustrate through examples, the perfor-
mance of the controllers studied in the succeeding chapters. Readers interested
in the aspects of dynamics are invited to see the references listed on page 16.
As was mentioned earlier, the dynamic models of robot manipulators are
in general characterized by ordinary nonlinear and nonautonomous2 diﬀer-
ential equations. This fact limits considerably the use of control techniques
1 That is the working regime.
2 That is, they depend on the state variables and time. See Chapter 2.

12
1 What Does “Control of Robots” Involve?
tailored for linear systems, in robot control. In view of this and the present
requirements of precision and rapidity of robot motion it has become neces-
sary to use increasingly sophisticated control techniques. This class of control
systems may include nonlinear and adaptive controllers.
1.3 Control Speciﬁcations
During this last stage one proceeds to dictate the desired characteristics for
the control system through the deﬁnition of control objectives such as:
•
stability;
•
regulation (position control);
•
trajectory tracking (motion control);
•
optimization.
The most important property in a control system, in general, is stabil-
ity. This fundamental concept from control theory basically consists in the
property of a system to go on working at a regime or closely to it for ever.
Two techniques of analysis are typically used in the analytical study of the
stability of controlled robots. The ﬁrst is based on the so-called Lyapunov sta-
bility theory. The second is the so-called input–output stability theory. Both
techniques are complementary in the sense that the interest in Lyapunov the-
ory is the study of stability of the system using a state variables description,
while in the second one, we are interested in the stability of the system from
an input–output perspective. In this text we concentrate our attention on
Lyapunov stability in the development and analysis of controllers. The foun-
dations of Lyapunov theory are presented in the Chapter 2.
In accordance with the adopted deﬁnition of a robot manipulator’s output
y, the control objectives related to regulation and trajectory tracking receive
special names. In particular, in the case when the output y corresponds to the
joint position q and velocity ˙q, we refer to the control objectives as “position
control in joint coordinates” and “motion control in joint coordinates” respec-
tively. Or we may simply say “position” and “motion” control respectively.
The relevance of these problems motivates a more detailed discussion which
is presented next.
1.4 Motion Control of Robot Manipulators
The simplest way to specify the movement of a manipulator is the so-called
“point-to-point” method. This methodology consists in determining a series
of points in the manipulator’s workspace, which the end-eﬀector is required

1.4 Motion Control of Robot Manipulators
13
to pass through (cf. Figure 1.6). Thus, the position control problem consists
in making the end-eﬀector go to a speciﬁed point regardless of the trajectory
followed from its initial conﬁguration.
Figure 1.6. Point-to-point motion speciﬁcation
A more general way to specify a robot’s motion is via the so-called (con-
tinuous) trajectory. In this case, a (continuous) curve, or path in the state
space and parameterized in time, is available to achieve a desired task. Then,
the motion control problem consists in making the end-eﬀector follow this
trajectory as closely as possible (cf. Figure 1.7). This control problem, whose
study is our central objective, is also referred to as trajectory tracking control.
Let us brieﬂy recapitulate a simple formulation of robot control which, as
a matter of fact, is a particular case of motion control; that is, the position
control problem. In this formulation the speciﬁed trajectory is simply a point
in the workspace (which may be translated under appropriate conditions into
a point in the joint space). The position control problem consists in driving the
manipulator’s end-eﬀector (resp. the joint variables) to the desired position,
regardless of the initial posture.
The topic of motion control may in its turn, be ﬁtted in the more general
framework of the so-called robot navigation. The robot navigation problem
consists in solving, in one single step, the following subproblems:
•
path planning;
•
trajectory generation;
•
control design.

14
1 What Does “Control of Robots” Involve?
Figure 1.7. Trajectory motion speciﬁcation
Path planning consists in determining a curve in the state space, connect-
ing the initial and ﬁnal desired posture of the end-eﬀector, while avoiding
any obstacle. Trajectory generation consists in parameterizing in time the so-
obtained curve during the path planning. The resulting time-parameterized
trajectory which is commonly called the reference trajectory, is obtained pri-
marily in terms of the coordinates in the workspace. Then, following the so-
called method of inverse kinematics one may obtain a time-parameterized
trajectory for the joint coordinates. The control design consists in solving the
control problem mentioned above.
The main interest of this textbook is the study of motion controllers and
more particularly, the analysis of their inherent stability in the sense of Lya-
punov. Therefore, we assume that the problems of path planning and trajec-
tory generation are previously solved.
The dynamic models of robot manipulators possess parameters which de-
pend on physical quantities such as the mass of the objects possibly held by
the end-eﬀector. This mass is typically unknown, which means that the values
of these parameters are unknown. The problem of controlling systems with
unknown parameters is the main objective of the adaptive controllers. These
owe their name to the addition of an adaptation law which updates on-line,
an estimate of the unknown parameters to be used in the control law. This
motivates the study of adaptive control techniques applied to robot control.
In the past two decades a large body of literature has been devoted to the
adaptive control of manipulators. This problem is examined in Chapters 15
and 16.
We must mention that in view of the scope and audience of the present
textbook, we have excluded some control techniques whose use in robot mo-

Bibliography
15
tion control is supported by a large number of publications contributing both
theoretical and experimental achievements. Among such strategies we men-
tion the so-called passivity-based control, variable-structure control, learning
control, fuzzy control and neural-networks-based. These topics, which demand
a deeper knowledge of control and stability theory, may make part of a second
course on robot control.
Bibliography
A number of concepts and data related to robot manipulators may be found
in the introductory chapters of the following textbooks.
•
Paul R., 1981, “Robot manipulators: Mathematics programming and con-
trol”, MIT Press, Cambridge, MA.
•
Asada H., Slotine J. J., 1986, “Robot analysis and control ”, Wiley, New
York.
•
Fu K., Gonzalez R., Lee C., 1987, “Robotics: Control, sensing, vision and
intelligence”, McGraw–Hill.
•
Craig J., 1989, “Introduction to robotics: Mechanics and control”, Addison-
Wesley, Reading, MA.
•
Spong M.,
Vidyasagar M., 1989, “Robot dynamics and control”, Wiley,
New York.
•
Yoshikawa T., 1990, “Foundations of robotics: Analysis and control”, The
MIT Press.
•
Nakamura Y., 1991, “Advanced robotics: Redundancy and optimization”,
Addison–Wesley, Reading, MA.
•
Spong M., Lewis F. L., Abdallah C. T., 1993, “Robot control: Dynamics,
motion planning and analysis”, IEEE Press, New York.
•
Lewis F. L.,
Abdallah C. T.,
Dawson D. M., 1993, “Control of robot
manipulators”, Macmillan Pub. Co.
•
Murray R. M., Li Z., Sastry S., 1994, “A mathematical introduction to
robotic manipulation”, CRC Press, Inc., Boca Raton, FL.
•
Qu Z., Dawson D. M., 1996, “Robust tracking control of robot manipula-
tors”, IEEE Press, New York.
•
Canudas C., Siciliano B., Bastin G., (Eds), 1996, “Theory of robot con-
trol”, Springer-Verlag, London.
•
Arimoto S., 1996, “Control theory of non–linear mechanical systems”, Ox-
ford University Press, New York.
•
Sciavicco L., Siciliano B., 2000, “Modeling and control of robot manipula-
tors”, Second Edition, Springer-Verlag, London.

16
1 What Does “Control of Robots” Involve?
•
de Queiroz M.,
Dawson D. M.,
Nagarkatti S. P.,
Zhang F., 2000,
“Lyapunov–based control of mechanical systems”, Birkh¨auser, Boston, MA.
Robot dynamics is thoroughly discussed in Spong, Vidyasagar (1989) and
Sciavicco, Siciliano (2000).
To read more on the topics of force control, impedance control and hy-
brid motion/force see among others, the texts of Asada, Slotine (1986), Craig
(1989), Spong, Vidyasagar (1989), and Sciavicco, Siciliano (2000), previously
cited, and the book
•
Natale C., 2003, “Interaction control of robot manipulators”, Springer,
Germany.
•
Siciliano B.,
Villani L., “Robot force control”, 1999, Kluwer Academic
Publishers, Norwell, MA.
Aspects of stability in the input–output framework (in particular, passivity-
based control) are studied in the ﬁrst part of the book
•
Ortega R., Lor´ıa A., Nicklasson P. J. and Sira-Ram´ırez H., 1998, “Passivity-
based control of Euler-Lagrange Systems Mechanical, Electrical and Elec-
tromechanical Applications”, Springer-Verlag: London, Communications
and Control Engg. Series.
In addition, we may mention the following classic texts.
•
Raibert M.,
Craig J., 1981, “Hybrid position/force control of manipu-
lators”, ASME Journal of Dynamic Systems, Measurement and Control,
June.
•
Hogan N., 1985, “Impedance control: An approach to manipulation. Parts
I, II, and III”, ASME Journal of Dynamic Systems, Measurement and
Control, Vol. 107, March.
•
Whitney D., 1987, “ Historical perspective and state of the art in robot
force control”, The International Journal of Robotics Research, Vol. 6,
No. 1, Spring.
The topic of robot navigation may be studied from
•
Rimon E., Koditschek D. E., 1992, “Exact robot navigation using artiﬁcial
potential functions”, IEEE Transactions on Robotics and Automation, Vol.
8, No. 5, October.
Several theoretical and technological aspects on the guidance of manipu-
lators involving the use of vision sensors may be consulted in the following
books.

Bibliography
17
•
Hashimoto K., 1993, “Visual servoing: Real–time control of robot manipu-
lators based on visual sensory feedback”, World Scientiﬁc Publishing Co.,
Singapore.
•
Corke P.I., 1996, “Visual control of robots: High–performance visual ser-
voing”, Research Studies Press Ltd., Great Britain.
•
Vincze M., Hager G. D., 2000, “Robust vision for vision-based control of
motion”, IEEE Press, Washington, USA.
The deﬁnition of robot manipulator is taken from
•
United Nations/Economic Commission for Europe and International Fed-
eration of Robotics, 2001, “World robotics 2001”, United Nation Pub-
lication sales No. GV.E.01.0.16, ISBN 92–1–101043–8, ISSN 1020–1076,
Printed at United Nations, Geneva, Switzerland.
We list next some of the most signiﬁcant journals focused on robotics
research.
•
Advanced Robotics,
•
Autonomous Robots,
•
IASTED International Journal of Robotics and Automation
•
IEEE/ASME Transactions on Mechatronics,
•
IEEE Transactions on Robotics and Automation3,
•
IEEE Transactions on Robotics,
•
Journal of Intelligent and Robotic Systems,
•
Journal of Robotic Systems,
•
Mechatronics,
•
The International Journal of Robotics Research,
•
Robotica.
Other journals, which in particular, provide a discussion forum on robot con-
trol are
•
ASME Journal of Dynamic Systems, Measurement and Control,
•
Automatica,
•
IEEE Transactions on Automatic Control,
•
IEEE Transactions on Industrial Electronics,
•
IEEE Transactions on Systems, Man, and Cybernetics,
•
International Journal of Adaptive Control and Signal Processing,
•
International Journal of Control,
•
Systems and Control Letters.
3 Until June 2004 only.

2
Mathematical Preliminaries
In this chapter we present the foundations of Lyapunov stability theory. The
deﬁnitions, lemmas and theorems are borrowed from specialized texts and,
as needed, their statements are adapted for the purposes of this text. The
proofs of these statements are beyond the scope of the present text hence, are
omitted. The interested reader is invited to consult the list of references cited
at the end of the chapter. The proofs of less common results are presented.
The chapter starts by brieﬂy recalling basic concepts of linear algebra
which, together with integral and diﬀerential undergraduate calculus, are a
requirement for this book.
Basic Notation
Throughout the text we employ the following mathematical symbols:
∀
meaning “for all”;
∃
meaning “there exists”;
∈
meaning “belong(s) to”;
=⇒
meaning “implies”;
⇐⇒
meaning “is equivalent to” or “if and only if”;
→
meaning “tends to” or “maps onto”;
:= and =: meaning “is deﬁned as” and “equals by deﬁnition” respectively;
˙x
meaning dx
dt .
We denote functions f with domain D and taking values in a set R by
f : D →R. With an abuse of notation we may also denote a function by f(x)
where x ∈D.

20
2 Mathematical Preliminaries
2.1 Linear Algebra
Vectors
Basic notation and deﬁnitions of linear algebra are the starting point of our
exposition.
The set of real numbers is denoted by the symbol IR. The real numbers are
expressed by italic small capitalized letters and occasionally, by small Greek
letters.
The set of non-negative real numbers, IR+, is deﬁned as
IR+ = {α ∈IR : α ∈[0, ∞)} .
The absolute value of a real number x ∈IR is denoted by |x|.
We denote by IRn, the real vector space of dimension n, that is, the set of
all vectors x of dimension n formed by n real numbers in the column format
x =
⎡
⎢⎢⎣
x1
x2
...
xn
⎤
⎥⎥⎦= [x1 x2
· · · xn]T ,
where x1, x2, · · · , xn ∈IR are the coordinates or components of the vector x
and the super-index T denotes transpose. The associated vectors are denoted
by bold small letters, either Latin or Greek.
Vector Product
The inner product of two vectors x, y ∈IRn is deﬁned as
xTy =
n

i=1
xiyi = [x1 x2
· · · xn]
⎡
⎢⎢⎣
y1
y2
...
yn
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
x1
x2
...
xn
⎤
⎥⎥⎦
T ⎡
⎢⎢⎣
y1
y2
...
yn
⎤
⎥⎥⎦.
It can be veriﬁed that the inner product of two vectors satisﬁes the following:
•
xTy = yT x for all x, y ∈IRn ;
•
xT(y + z) = xTy + xT z for all x, y, z ∈IRn.
Euclidean Norm
The Euclidean norm ∥x∥of a vector x ∈IRn is deﬁned as

2.1 Linear Algebra
21
∥x∥:=




n

i=1
x2
i =
√
xTx,
and satisﬁes the following axioms and properties:
•
∥x∥= 0 if and only if x = 0 ∈IRn;
•
∥x∥> 0 for all x ∈IRn with x ̸= 0 ∈IRn;
•
∥αx∥= |α| ∥x∥for all α ∈IR and x ∈IRn;
•
∥x∥−∥y∥≤∥x + y∥≤∥x∥+ ∥y∥for all x, y ∈IRn;
•
xTy
 ≤∥x∥∥y∥for all x, y ∈IRn (Schwartz inequality).
Matrices
We denote by IRn×m the set of real matrices A of dimension n ×m formed by
arrays of real numbers ordered in n rows and m columns,
A = {aij} =
⎡
⎢⎢⎣
a11
a12
· · ·
a1m
a21
a22
· · ·
a2m
...
...
...
...
an1
an2
· · ·
anm
⎤
⎥⎥⎦.
A vector x ∈IRn may be interpreted as a particular matrix belonging to
IRn×1 = IRn. The matrices are denoted by Latin capital letters and occasion-
ally by Greek capital letters.
The transpose matrix AT = {aji} ∈IRm×n is obtained by interchanging
the rows and the columns of A = {aij} ∈IRn×m.
Matrix Product
Consider the matrices A ∈IRm×p and B ∈IRp×n. The product of matrices A
and B denoted by C = AB ∈IRm×n is deﬁned as
C = {cij} = AB
=
⎡
⎢⎢⎣
a11
a12
· · ·
a1p
a21
a22
· · ·
a2p
...
...
...
...
am1
am2
· · ·
amp
⎤
⎥⎥⎦
⎡
⎢⎢⎣
b11
b12
· · ·
b1n
b21
b22
· · ·
b2n
...
...
...
...
bp1
bp2
· · ·
bpn
⎤
⎥⎥⎦

22
2 Mathematical Preliminaries
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
p
k=1 a1kbk1
p
k=1 a1kbk2
· · ·
p
k=1 a1kbkn
p
k=1 a2kbk1
p
k=1 a2kbk2
· · ·
p
k=1 a2kbkn
...
...
...
...
p
k=1 amkbk1
p
k=1 amkbk2
· · ·
p
k=1 amkbkn
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
It may be veriﬁed, without much diﬃculty, that the product of matrices satisfy
the following:
•
(AB)T = BT AT for all A ∈IRm×p and B ∈IRp×n ;
•
in general, AB ̸= BA ;
•
for all A ∈IRm×p, B ∈IRp×n :
A(B + C) = AB + AC
with C ∈IRp×n ;
ABC = A(BC) = (AB)C
with C ∈IRn×r .
In accordance with the deﬁnition of matrix product, the expression xTAy
where x ∈IRn, A ∈IRn×m and y ∈IRm is given by
xTAy =
⎡
⎢⎢⎣
x1
x2
...
xn
⎤
⎥⎥⎦
T ⎡
⎢⎢⎣
a11
a12
· · ·
a1m
a21
a22
· · ·
a2m
...
...
...
...
an1
an2
· · ·
anm
⎤
⎥⎥⎦
⎡
⎢⎢⎣
y1
y2
...
ym
⎤
⎥⎥⎦
=
n

i=1
m

j=1
aijxiyj.
Particular Matrices
A matrix A is square if n = m, i.e. if it has as many rows as columns. A square
matrix A ∈IRn×n is symmetric if it is equal to its transpose that is, if A = AT .
A is skew-symmetric if A = −AT . By −A we obviously mean −A := {−aij} .
The following property of skew-symmetric matrices is particularly useful in
robot control:
xTAx = 0,
for all x ∈IRn.
A square matrix A = {aij} ∈IRn×n is diagonal if aij = 0 for all i ̸= j. We
denote a diagonal matrix by diag{a11, a22, · · · , ann} ∈IRn×n, i.e.
diag{a11, a22, · · · , ann} =
⎡
⎢⎢⎣
a11
0
· · ·
0
0
a22
· · ·
0
...
...
...
...
0
0
· · ·
ann
⎤
⎥⎥⎦∈IRn×n.

2.1 Linear Algebra
23
Obviously, any diagonal matrix is symmetric. In the particular case when
a11 = a22 = · · · = ann = a, the corresponding diagonal matrix is denoted
by diag{a} ∈IRn×n. Two diagonal matrices of particular importance are the
following. The identity matrix of dimension n which is deﬁned as
I = diag{1} =
⎡
⎢⎢⎣
1
0
· · ·
0
0
1
· · ·
0
...
...
...
...
0
0
· · ·
1
⎤
⎥⎥⎦∈IRn×n
and the null matrix of dimension n which is deﬁned as 0n×n := diag{0} ∈
IRn×n.
A square matrix A ∈IRn×n is singular if its determinant is zero that is,
if det[A]=0. In the opposite case it is nonsingular. The inverse matrix A−1
exists if and only if A is nonsingular.
A square not necessarily symmetric matrix A ∈IRn×n, is said to be positive
deﬁnite if
xTAx > 0, for all x ∈IRn, with x ̸= 0 ∈IRn.
It is important to remark that in contrast to the deﬁnition given above, the
majority of texts deﬁne positive deﬁniteness for symmetric matrices. However,
for the purposes of this textbook, we use the above-cited deﬁnition. This
choice is supported by the following observation: let P be a square matrix of
dimension n and deﬁne
A = {aij} = P + P T
2
.
The theorem of Sylvester establishes that the matrix P is positive deﬁnite if
and only if
det[a11] > 0, det

a11
a12
a21
a22

> 0, · · · , det[A] > 0.
We use the notation A > 0 to indicate that the matrix A is positive
deﬁnite1. Any symmetric positive deﬁnite matrix A = AT > 0 is nonsingular.
Moreover, A = AT > 0 if and only if A−1 = (A−1)T > 0.
It can also be shown that the sum of two positive deﬁnite matrices yields
a positive deﬁnite matrix however, the product of two symmetric positive
deﬁnite matrices A = AT > 0 and B = BT > 0, yields in general a matrix
which is neither symmetric nor positive deﬁnite. Yet the resulting matrix AB
is nonsingular.
1 It is important to remark that A > 0 means that the matrix A is positive deﬁnite
and shall not be read as “A is greater than 0” which makes no mathematical
sense.

24
2 Mathematical Preliminaries
A square not necessarily symmetric matrix A ∈IRn×n, is positive semidef-
inite if
xTAx ≥0 for all x ∈IRn.
We employ the notation A ≥0 to denote that the matrix A is positive semidef-
inite.
A square matrix A ∈IRn×n is negative deﬁnite if −A is positive deﬁnite
and it is negative semideﬁnite if −A is positive semideﬁnite.
Lemma 2.1. Given a symmetric positive deﬁnite matrix A and a nonsingular
matrix B, the product BTAB is a symmetric positive deﬁnite matrix.
Proof. Notice that the matrix BTAB is symmetric. Deﬁne y = Bx which, by
virtue of the hypothesis that B is nonsingular, guarantees that y = 0 ∈IRn
if and only if x = 0 ∈IRn. From this we obtain
xT 
BTAB

x = yT Ay > 0
for all x ̸= 0 ∈IRn, which is equivalent to having that BTAB is positive
deﬁnite.
♦♦♦
Eigenvalues
For each square matrix A ∈IRn×n there exist n eigenvalues (in general, com-
plex numbers) denoted by λ1{A}, λ2{A}, · · · , λn{A}. The eigenvalues of the
matrix A ∈IRn×n are numbers that satisfy
det [λi{A}I −A] = 0,
for i = 1, 2, · · · , n
where I ∈IRn×n is the identity matrix of dimension n.
For the case of a symmetric matrix A = AT ∈IRn×n, its eigenvalues are
such that:
•
λ1{A}, λ2{A}, · · · , λn{A} ∈IR ; and,
•
expressing the largest and smallest eigenvalues of A by λMax{A} and
λmin{A} respectively, the theorem of Rayleigh–Ritz establishes that for
all x ∈IRn we have
λMax{A} ∥x∥2 ≥xTAx ≥λmin{A} ∥x∥2 .
A symmetric matrix A = AT ∈IRn×n is positive deﬁnite if and only if its
eigenvalues are positive, i.e. if and only if λi{A} > 0 where i = 1, 2, · · · , n.
Consequently, any square matrix A ∈IRn×n is positive deﬁnite if λi{A +
AT } > 0 where i = 1, 2, · · · , n.

2.1 Linear Algebra
25
Remark 2.1. Consider a matrix function A : IRm →IRn×n with A symmetric.
We say that A is positive deﬁnite if B := A(y) is positive deﬁnite for each
y ∈IRm. In other words, if for each y ∈IRm we have
xT A(y)x > 0 for all x ∈IRn , with x ̸= 0 .
By an abuse of notation, we deﬁne λmin{A} as the greatest lower-bound (i.e.
the inﬁmum) of λmin{A(y)} for all y ∈IRm, that is
λmin{A} :=
inf
y∈IRm λmin{A(y)} .
For the purposes of this textbook most relevant positive deﬁnite matrix func-
tions A : IRm →IRn×n satisfy λmin{A} > 0.
Spectral Norm
The spectral norm ∥A∥of a matrix A ∈IRn×m is deﬁned as2
∥A∥=

λMax{ATA},
where λMax{ATA} denotes the largest eigenvalue of the symmetric matrix
ATA ∈IRm×m.
In the particular case of symmetric matrices A = AT ∈IRn×n, we have
•
∥A∥= maxi |λi{A}| ;
•
A−1 =
1
mini |λi{A}| .
In the expressions above, the absolute value is redundant if A is symmetric
positive deﬁnite, i.e. if A = AT > 0.
The spectral norm satisﬁes the following properties and axioms:
•
∥A∥= 0 if and only if A = 0 ∈IRn×m ;
•
∥A∥> 0 for all A ∈IRn×m where A ̸= 0 ∈IRn×m ;
•
∥A + B∥≤∥A∥+ ∥B∥for all A, B ∈IRn×m ;
•
∥αA∥= |α| ∥A∥for all α ∈IR and A ∈IRn×m ;
•
ATB
 ≤∥A∥∥B∥for all A, B ∈IRn×m.
2 It is important to see that we employ the same symbol for the Euclidean norm of
a vector and the spectral norm of a matrix. The reader should take special care
in not mistaking them. The distinction can be clearly made via the fonts used for
the argument of ∥·∥, i.e. we use small bold letters for vectors and capital letters
for matrices.

26
2 Mathematical Preliminaries
An important result about spectral norms is the following. Consider the
matrix A ∈IRn×m and the vector x ∈IRm. Then, the norm of the vector Ax
satisﬁes
∥Ax∥≤∥A∥∥x∥,
where ∥A∥denotes the spectral norm of the matrix A while ∥x∥denotes the
Euclidean norm of the vector x. Moreover, since y ∈IRn, the absolute value
of yTAx satisﬁes
yTAx
 ≤∥A∥∥y∥∥x∥.
2.2 Fixed Points
We start with some basic concepts on what are called ﬁxed points; these are
useful to establish conditions for existence and unicity of equilibria for ordi-
nary diﬀerential equations. Such theorems are employed later to study closed-
loop dynamic systems appearing in robot control problems. To start with, we
present the deﬁnition of ﬁxed point that, in spite of its simplicity, is of great
importance.
Consider a continuous function f : IRn →IRn. The vector x∗∈IRn is a
ﬁxed point of f(x) if
f(x∗) = x∗.
According to this deﬁnition, if x∗is a ﬁxed point of the function f(x),
then x∗is a solution of f(x) −x = 0.
Some functions have one or multiple ﬁxed points but there also exist func-
tions which have no ﬁxed points. The function f(x) = sin(x) has a unique
ﬁxed point at x∗= 0, while the function f(x) = x3 has three ﬁxed points:
x∗= 1, x∗= 0 and x∗= −1. However, f(x) = ex has no ﬁxed point.
We present next a version of the contraction mapping theorem which pro-
vides a suﬃcient condition for existence and unicity of ﬁxed points.
Theorem 2.1. Contraction Mapping
Consider Ω⊂IRm, a vector of parameters θ ∈Ωand the continuous function
f : IRn × Ω→IRn. Assume that there exists a non-negative constant k such
that for all y, z ∈IRn and all θ ∈Ωwe have
∥f(y, θ) −f(z, θ)∥≤k ∥y −z∥.
If the constant k is strictly smaller than one, then for each θ∗∈Ω, the
function f(·, θ∗) possesses a unique ﬁxed point x∗∈IRn.
Moreover, the ﬁxed point x∗may be determined by
x∗= lim
n→∞x(n, θ∗)
where x(n, θ∗) = f(x(n −1, θ∗)) and with x(0, θ∗) ∈IRn being arbitrary.

2.3 Lyapunov Stability
27
An important interpretation of the contraction mapping theorem is the
following. Assume that the function f(x, θ) satisﬁes the condition of the theo-
rem then, for each θ∗∈Ωthe equation f(x, θ∗) −x = 0 has a solution in x
and moreover it is unique. To illustrate this idea consider the function h(x, θ)
deﬁned as
h(x, θ) = ax −b sin(θ −x)
(2.1)
= −a [f(x, θ) −x]
with a > 0, b > 0, θ ∈IR and
f(x, θ) = b
a sin(θ −x).
(2.2)
We wish to ﬁnd conditions on a and b so that h(x, θ) = 0 has a unique
solution in x. From (2.1) and (2.2) we see that this is equivalent to establishing
conditions to guarantee that b
a sin(θ −x) −x = 0 has a unique solution in x.
In other words, conditions to ensure that b
a sin(θ−x) has a unique ﬁxed point
for each θ. To solve this problem we may employ the contraction mapping
theorem. Notice that
|f(y, θ) −f(z, θ)| =

b
a [sin(θ −y) −sin(θ −z)]

and, invoking the mean value theorem (cf. Theorem A.2 on page 384) which
ensures that | sin(θ −y) −sin(θ −z)| ≤|y −z|, we obtain
|f(y, θ) −f(z, θ)| ≤b
a |y −z|
for all y, z and θ ∈IR. Hence, if 1 > b/a ≥0 for each θ, f(x, θ) has a unique
ﬁxed point and consequently, h(x, θ) = 0 has a unique solution in x.
2.3 Lyapunov Stability
In this section we present the basic concepts and theorems related to Lyapunov
stability and, in particular the so-called second method of Lyapunov or
direct method of Lyapunov.
The main objective in Lyapunov stability theory is to study the behavior
of dynamical systems described by ordinary diﬀerential equations of the form
˙x = f(t, x),
x ∈IRn,
t ∈IR+ ,
(2.3)
where the vector x corresponds to the state of the system represented by
(2.3). We denote solutions of this diﬀerential equation by x(t, t◦, x(t◦)). That

28
2 Mathematical Preliminaries
is, x(t, t◦, x(t◦)) represents the value of the system’s state at time t and with
arbitrary initial state x(t◦) ∈IRn and initial time t◦≥0. However, for sim-
plicity in the notation and since the initial conditions t◦and x(t◦) are ﬁxed,
most often we use x(t) to denote a solution to (2.3) in place of x(t, t◦, x(t◦)).
We assume that the function f : IR+ × IRn →IRn is continuous in t and
x and is such that:
•
Equation (2.3) has a unique solution corresponding to each initial condition
t◦, x(t◦) ;
•
the solution x(t, t◦, x(t◦)) of (2.3) depends continuously on the initial con-
ditions t◦, x(t◦).
Generally speaking, assuming existence of the solutions for all t ≥t◦≥0 is
restrictive and one may simply assume that they exist on a ﬁnite interval.
Then, existence on the inﬁnite interval may be concluded from the same the-
orems on Lyapunov stability that we present later in this chapter. However,
for the purposes of this book we assume existence on the inﬁnite interval.
If the function f does not depend explicitly on time, that is, if f(t, x) =
f(x) then, Equation (2.3) becomes
˙x = f(x),
x ∈IRn
(2.4)
and it is said to be autonomous. In this case it makes no sense to speak of
the initial time t◦since for any given t◦and t′
◦such that x(t◦) = x(t′
◦), we
have x(t◦+ T, t◦, x(t◦)) = x(t′
◦+ T, t′
◦, x(t′
◦)) for any T ≥0. Therefore, for
all autonomous diﬀerential equations we can safely consider that t◦= 0.
If f(t, x) = A(t)x + u(t) with A(t) being a square matrix of dimension
n and A(t) and vector u(t) being functions only of t – or constant – then
Equation (2.3) is said to be linear. In the opposite case it is nonlinear.
2.3.1 The Concept of Equilibrium
Among the basic concepts in Lyapunov theory that we underline are: equi-
librium, stability, asymptotic stability, exponential stability and uniformity.
We develop each of these concepts below. First, we present the concept of
equilibrium which plays a central role in Lyapunov theory.
Deﬁnition 2.1. Equilibrium
A constant vector xe ∈IRn is an equilibrium or equilibrium state of the system
(2.3) if
f(t, xe) = 0
∀t ≥0 .
A direct consequence of the deﬁnition of equilibrium, under regularity
appropriate conditions that exclude “pathological” situations, is that if the
initial state x(t◦) ∈IRn is an equilibrium (x(t◦) = xe ∈IRn) then,

2.3 Lyapunov Stability
29
•
x(t) = xe
∀t ≥t◦≥0
•
˙x(t) = 0
∀t ≥t◦≥0 .
This idea is illustrated in Figure 2.1, where the case x(t◦) ∈IR2 is depicted.
The initial state x(t◦) is precisely xe, so the evolution of the solution x(t)
corresponds exactly to the constant value xe for all times t ≥t◦.
•
•
•
x1
x2
t
x2
x1
 (t◦) =  e
 (t◦) =  e
t◦
0
0
 (t)
........ ........ ........ ........ ........ .............................
........ ........ ........ ........ .................................
..........................................................................................................................................................................................................................................................................................................................
.......................... .................

1
6
-
-
6
Figure 2.1. Concept of equilibrium
It is typically assumed that the origin of the state space IRn, that is,
x = 0 ∈IRn, is an equilibrium of (2.3). If this is not the case, it may be
shown that by a suitable change of variable, any equilibrium of (2.3) may be
translated to the origin.
In general, a diﬀerential equation may have more than one equilibrium,
indeed even an inﬁnite number of them! However, it is also possible that a
diﬀerential equation does not possess any equilibrium at all. This is illustrated
by the following example.
Example 2.1. Consider the following linear diﬀerential equation
˙x = a x + b u(t),
with initial conditions (t◦, x(t◦)) ∈IR+×IR and where a ̸= 0 and b ̸= 0
are real constants and u : IR+ →IR is a continuous function. If u(t) =
u0 for all t ≥0, that is, if the diﬀerential equation is autonomous,
then the unique equilibrium point of this equation is xe = −bu0/a.
On the other hand, one must be careful in concluding that any
autonomous system has equilibria. For instance, the autonomous non-
linear system
˙x = e−x
has no equilibrium point.
Consider the following nonlinear autonomous diﬀerential equation

30
2 Mathematical Preliminaries
˙x1 = x2
˙x2 = sin(x1) .
The previous set of equations has an inﬁnite number of (isolated)
equilibria, which are given by xe = [x1e
x2e]T = [nπ
0]T with
n = · · · , −1, 0, 1, · · ·.
♦
Systems with multiple equilibria are not restricted to mathematical ex-
amples but are fairly common in control practice and as a matter of fact,
mechanisms are a good example of these since in general, dynamic models
of robot manipulators constitute nonlinear systems. The following example
shows that even for robots with a simple mathematical model, multiple equi-
libria may co-exist.
Example 2.2. Consider a pendulum, as depicted in Figure 2.2, of mass
m, total moment of inertia about the joint axis J, and distance l
from its axis of rotation to the center of mass. It is assumed that the
pendulum is aﬀected by the force of gravity induced by the gravity
acceleration g.
q
l
m
τ
g
Figure 2.2. Pendulum
We assume that a torque τ(t) is applied at the axis of rotation.
Then, the dynamic model which describes the motion of such a system
is given by
J ¨q + mgl sin(q) = τ(t)

2.3 Lyapunov Stability
31
where q is the angular position of the pendulum with respect to the
vertical axis and ˙q is the corresponding angular velocity. Or, in terms
of the state [q
˙q]T , the dynamic model is given by
d
dt
⎡
⎣
q
˙q
⎤
⎦=
⎡
⎣
˙q
J−1 [τ(t) −mgl sin(q)]
⎤
⎦.
If τ(t) = 0, the equilibrium states are then given by [q
˙q]T = [nπ 0]T
for n = · · · , −2, −1, 0, 1, 2, · · · since mgl sin(nπ) = 0. Notice that if
τ(t) = τ ∗and |τ ∗| > mgl then, there does not exist any equilibrium
since there is no q∗∈IR such that τ ∗= mgl sin(q∗).
♦
2.3.2 Deﬁnitions of Stability
In this section we present the basic notions of stability of equilibria of diﬀer-
ential equations, evoked throughout the text. We emphasize that the stability
notions which are deﬁned below are to be considered as attributes of the
equilibria of the diﬀerential equations and not of the equations themselves.
Without loss of generality we assume in the rest of the text that the origin of
the state space, x = 0 ∈IRn, is an equilibrium of (2.3) and accordingly, we
provide the deﬁnitions of stability of the origin but they can be reformulated
for other equilibria by performing the appropriate changes of coordinate.
Deﬁnition 2.2. Stability
The origin is a stable equilibrium (in the sense of Lyapunov) of Equation (2.3)
if, for each pair of numbers ε > 0 and t◦≥0, there exists δ = δ(t◦, ε) > 0
such that
∥x(t◦)∥< δ
=⇒
∥x(t)∥< ε
∀t ≥t◦≥0 .
(2.5)
Correspondingly, the origin of Equation (2.4) is said to be stable if for each
ε > 0 there exists δ = δ(ε) > 0 such that (2.5) holds with t◦= 0.
In Deﬁnition 2.2 the constant δ (which is clearly smaller than ε) is not
unique. Indeed, notice that for any given constant δ that satisﬁes the condition
of the deﬁnition any δ′ ≤δ also satisﬁes it.
If one reads Deﬁnition 2.2 with appropriate care, it should be clear that
the number δ depends on the number ε and in general, also on the initial time
t◦. Indeed, note that the deﬁnition of stability for nonautonomous systems
requires existence of a number δ > 0 for each t◦≥0 and ε > 0 and not
just for some t◦≥0 and ε > 0. Correspondingly, in the case of autonomous
diﬀerential equations it is required that there exists δ > 0 for each ε > 0 and
not only for some ε.

32
2 Mathematical Preliminaries
Also, in Deﬁnition 2.2 one should not understand that the origin is Lya-
punov stable if for each δ > 0 one may ﬁnd ε > 0 such that
∥x(t◦)∥< δ
=⇒
∥x(t)∥< ε
∀t ≥t◦≥0 .
(2.6)
In other words, the latter statement establishes that “the origin is a stable
equilibrium if for any bounded initial condition, the corresponding solution
is also bounded”. This is commonly known as “boundedness of solutions” or
“Lagrange stability” and is a somewhat weaker property than Lyapunov sta-
bility. However, boundedness of solutions is neither a necessary nor a suﬃcient
condition for Lyapunov stability of an equilibrium.
•
•
•
x1
x2
t
x2
x1
ε
δ
ε
δ
 (t◦)






 (t)
 (t◦)
@
@@
R
 e
........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ...
........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ...
........................................
........
........
........
........
........
........
........
........................................................................................ ........ ........ ........ ........................................................
........................................
........
........
........
........
........
........
........
........................................................................................ ........ ........ ........ ........................................................
................................
........
........
........
........
................................................................ ........ ........ ....................................
................................
........
........
........
........
................................................................ ........ ........ ....................................
........................................
........
........
........
........
........
........
........
........
........
........................................................................................ ........ ........ ........ ........ ........ .....................................................
........................
........
........
........
........
........
........
........................................................ ........ ........ ........ ....................................
.........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
...................................................................................................................................................................................................................................................................................................................................................................................................
.............................. .................
................................. .................
............................
.................
...........................
.................

1
6
-
-
6
Figure 2.3. Notion of stability
To illustrate the concept of stability, Figure 2.3 shows a trajectory with
an initial state x(t◦) ∈IR2 such that the origin x = 0 ∈IR2 is a stable
equilibrium. In Figure 2.3 we also show ε and δ which satisfy the condition
from the deﬁnition of stability, that is, ∥x(t◦)∥< δ implies that ∥x(t)∥< ε
for all t ≥t◦≥0.
Deﬁnition 2.3. Uniform stability
The origin is a uniformly stable equilibrium (in the sense of Lyapunov) of
Equation (2.3) if for each number ε > 0 there exists δ = δ(ε) > 0 such that
(2.5) holds.
That is, the origin is uniformly stable if δ can be chosen independently
of the initial time, t◦. For autonomous systems this is always the case, i.e.
uniform stability and stability of the equilibrium are equivalent.
Example 2.3. Consider the system (harmonic oscillator) described by
the equations:

2.3 Lyapunov Stability
33
•
x1
x2
 e
0
0
........................................
...........................
....................................................
...........................
........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. .............
Figure 2.4. Phase plane of the harmonic oscillator
˙x1 = x2
(2.7)
˙x2 = −x1
(2.8)
and whose solution is
x1(t) = x1(0)cos(t) + x2(0)sin(t)
x2(t) = −x1(0)sin(t) + x2(0)cos(t).
Note that the origin is the unique equilibrium point. The graphs
of some solutions of Equations (2.7)–(2.8) on the plane x1–x2, are
depicted in Figure 2.4.
Notice that the trajectories of the system (2.7)–(2.8) describe con-
centric circles centered at the origin. For this example, the origin is
a stable equilibrium since for any ε > 0 there exists δ > 0 (actually
any3 δ ≤ε) such that
∥x(0)∥< δ
=⇒
∥x(t)∥< ε
∀t ≥0.
♦
Observe that in Example 2.3 stability is uniform since the system is au-
tonomous (notice that the solutions do not depend on t◦). It is also important
to stress that the solutions do not tend to the origin. That is, we say that the
origin is stable but not asymptotically stable, a concept that is deﬁned next.
Deﬁnition 2.4. Asymptotic stability
The origin is an asymptotically stable equilibrium of Equation (2.3) if:
1. the origin is stable;
3 From this inequality the dependence of δ on ε is clear.

34
2 Mathematical Preliminaries
•
•
x1
x2
t
 (t◦)



 (t)
ε
δ
δ′
 e
........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ...
........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ...
................................
........
........
........
........
........
........
................................................................................ ........ ........ ........ ...........................................
................................................
........
........
........
........
........
........
........
........
........................................................................................................ ........ ........ ........ ........ ........ .........................................................
................................
........
........
........
........
........
........
................................................................................ ........ ........ ........ ...........................................
................................
........
........
........
........
................................................................ ........ ........ ....................................
................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.............................. .................
..........................
.................

1
6
-
Figure 2.5. Asymptotic stability
2. the origin is attractive, i.e. for each t◦≥0, there exists δ′ = δ′(t◦) > 0
such that
∥x(t◦)∥< δ′
=⇒
∥x(t)∥→0
as
t →∞.
(2.9)
Asymptotic stability for the origin of autonomous systems is stated by
replacing above “for each t◦≥0, there exists δ′ = δ′(t◦) > 0” with “there
exists δ′ > 0”.
Figure 2.5 illustrates the concept of asymptotic stability for the case of
x(t◦) ∈IR2.
In Deﬁnition 2.4 above, one should not read that “the origin is stable
when t →∞” or that “attractivity implies stability in the sense of Deﬁnition
2.2”. As a matter of fact, even though it may seem counter-intuitive to some
readers, there exist systems for which all the trajectories starting close to an
equilibrium tend to that equilibrium but the latter is not stable. We see in
the following example that this phenomenon is not as unrealistic as one might
think.
Example 2.4. Consider the autonomous system with two state vari-
ables expressed in terms of polar coordinates:
˙r =
5
100r(1 −r)
˙θ = sin2(θ/2)
θ ∈[0, 2π) .
This system has an equilibrium at the origin [r
θ]T = [0
0]T
and another one at [r
θ]T = [1
0]T . The behavior of this system,
expressed in Cartesian coordinates x1 = rcos(θ) and x2 = r sin(θ),
is illustrated in Figure 2.6. All the solutions of the system (with the
exception of those that start oﬀat the equilibria) tend asymptoti-
cally to [x1
x2]T = [1
0]T . In particular, notice from Figure 2.6

2.3 Lyapunov Stability
35
•
•
x1
x2
0
1
0
........................................
...........................
.................................................
...........................
............................................
...........................
..................................................
...........................
........................................
...........................
........................................
...........................
...................................
..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
...........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
...............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
..............................................................................
......
.........................................................................................................................................................................................................................................
Figure 2.6. Attractive but unstable equilibrium
that for each initial condition inside the dashed disk (but excluding
[x1
x2]T = [1 0]T ) the generated trajectory goes asymptotically to
the equilibrium. That is, the equilibrium is attractive in the sense of
Deﬁnition 2.4. Intuitively, it may seem reasonable that this implies
that the equilibrium is also stable and therefore, asymptotically sta-
ble. However, as pointed out before, this is a fallacy since the ﬁrst item
of Deﬁnition 2.4 does not hold. To see this, pick ε to be the radius of
the dashed disk. For this particular ε there does not exist a number δ
such that
∥x(0)∥< δ
=⇒
∥x(t)∥< ε
∀t ≥0,
because there are always solutions that leave the disk before “coming
back” towards the equilibrium. Hence, the equilibrium [x1
x2]T =
[1 0]T is attractive but unstable (cf. Deﬁnition 2.9).
♦
Deﬁnition 2.5. Uniform asymptotic stability
The origin is a uniformly asymptotically stable equilibrium of Equation (2.3)
if:
1. the origin is uniformly stable;
2. the origin is uniformly attractive, i.e. there exists a number δ′ > 0 such
that (2.9) holds with a rate of convergence independent of t◦.
For autonomous systems, uniform asymptotic stability and asymptotic stabil-
ity are equivalent.
One may make precise the idea of “rate of convergence independent of t◦”
by saying that uniform attractivity means that there exists δ′ > 0 and, for
each ε′ (arbitrarily small) there exists T(ε′) > 0 such that

36
2 Mathematical Preliminaries
∥x(t◦)∥< δ′
=⇒
∥x(t)∥< ε′ ∀t ≥t◦+ T .
(2.10)
Therefore, the rate of convergence is determined by the time T and we say
that it is independent of t◦if T is independent of the initial time.
The following example shows that some nonautonomous systems may be
asymptotically stable but not with a uniform rate of convergence; hence, not
uniformly asymptotically stable.
Example 2.5. Consider the system
˙x = −
x
1 + t
with initial conditions t◦∈IR+ and x◦:= x(t◦) ∈IR and whose origin
is an equilibrium point. One can solve this diﬀerential equation by
simple integration of
dx
x = −dt
1 + t ,
i.e.
ln
 x(t)
x(t◦)

= ln
1 + t◦
1 + t

,
from which we obtain
x(t) = 1 + t◦
1 + t x◦.
(2.11)
From Equation (2.11) we see that |x(t)| →0 as t →∞; therefore, the
origin is an attractive equilibrium. More precisely, we see that given
any numbers ε′ and δ′ > 0, if |x◦| < δ′ then
|x(t)| < 1 + t◦
1 + t δ′
for all t ≥t◦.
It means that for |x(t)| to be smaller than ε′ we need to wait at least
until t = t◦+ T where
T > (1 + t◦)(δ′ −ε′)
ε′
.
However, since T grows proportionally with t◦, for any ﬁxed values
of δ′ and ε′, the origin is not uniformly attractive. In other words,
|x(t)| →0 as t →∞but no matter what the tolerance that we impose
on |x(t)| to come close to zero (that is, ε′) and how near the initial
states are to the origin (that is, δ′), we see that the later |x(t)| starts
to decay the slower it tends to zero. That is, the rate of convergence
becomes smaller as t◦becomes larger.

2.3 Lyapunov Stability
37
On the other hand, the origin is stable and, actually, uniformly
stable. To see this, observe from (2.11) that, since
1 + t◦
(1 + t) ≤1
for any t ≥t◦and any t ≥0 then, |x(t)| ≤|x◦|. We conclude that for
any given ε > 0 it holds, with δ = ε, that
|x◦| < δ
=⇒
|x(t)| < ε , ∀t ≥t◦.
We conclude that the origin is asymptotically stable and uniformly
stable but not uniformly asymptotically stable.
♦
The phenomena observed in the previous examples are proper to nonau-
tonomous systems. Nonautonomous systems appear in robot control when
the desired task is to follow a time-varying trajectory, i.e. in motion control
(cf. Part III) or when there is uncertainty in the physical parameters and
therefore, an adaptive control approach may be used (cf. Part IV).
The concept of uniformity for nonautonomous systems is instrumental be-
cause uniform asymptotic stability ensures a certain robustness with respect
to disturbances. We say that a system is robust with respect to disturbances
if, in the presence of the latter, the equilibrium of the system preserves ba-
sic properties such as stability and boundedness of solutions. In the control
of robot manipulators, disturbances may come from unmodeled dynamics or
additive sensor noise, which are fairly common in practice. Therefore, if for
instance we are able to guarantee uniform asymptotic stability for a robot con-
trol system in a motion control task, we will be sure that small measurement
noise will only cause small deviations from the control objective. However, one
should not understand that uniform asymptotic stability guarantees that the
equilibrium remains asymptotically stable under disturbances or measurement
noise.
In robot control we are often interested in studying the performance of
controllers, considering any initial conﬁguration for the robot. For this, we
need to study global deﬁnitions of stability.
Deﬁnition 2.6. Global asymptotic stability
The origin is a globally asymptotically stable equilibrium of Equation (2.3)
if:
1. the origin is stable;
2. the origin is globally attractive, that is,
∥x(t)∥→0
as
t →∞,
∀x(t◦) ∈IRn , t◦≥0 .

38
2 Mathematical Preliminaries
It should be clear from the deﬁnition above, that if the origin is globally
asymptotically stable then it is also asymptotically stable, but the converse is
obviously not always true.
Deﬁnition 2.7. Global uniform asymptotic stability
The origin is a globally uniformly asymptotically stable equilibrium of Equa-
tion (2.3) if:
1. the origin is uniformly stable with δ(ε) in Deﬁnition 2.3 which satisﬁes
δ(ε) →∞as ε →∞(uniform boundedness) and
2. the origin is globally uniformly attractive, i.e. for all x(t◦) ∈IRn and all
t◦≥0,
∥x(t)∥→0
as
t →∞
with a convergence rate that is independent of t◦.
For autonomous systems, global asymptotic stability and global uniform
asymptotic stability are equivalent.
As for Deﬁnition 2.5, we can make item 2 above more precise by saying
that for each δ′ and ε′ there exists T(δ′, ε′) – hence, independent of t◦– such
that the implication (2.10) holds.
It is important to underline the diﬀerences between Deﬁnitions 2.5 and 2.7.
First, in item 1 of Deﬁnition 2.7 one asks that δ grows unboundedly as ε →∞.
In particular, this implies that the norm of all solutions must be bounded and,
moreover, by a bound which is independent of t◦(uniform boundedness of all
solutions). Secondly, attractivity must be global which translates into: “for
each δ′ > 0 and ε′ > 0 there exists T(δ′, ε′) > 0 such that (2.10) holds”, i.e.
in Deﬁnition 2.7 we say “for each δ′ > 0” and not “there exists δ′ > 0” as in
Deﬁnition 2.5.
It is also convenient to stress that the diﬀerence between items 1 and
2 of Deﬁnitions 2.6 and 2.7 is not simply that the required properties of
stability and attractivity shall be uniform but also that all the solutions must
be uniformly bounded. The latter is ensured by the imposed condition that
δ(ε) can be chosen so that δ(ε) →∞as ε →∞.
We ﬁnish this section on deﬁnitions with a special case of global uniform
asymptotic stability.
Deﬁnition 2.8. Global exponential stability
The origin is a globally exponentially stable equilibrium of (2.3) if there exist
positive constants α and β, independent of t◦, such that
∥x(t)∥< α ∥x(t◦)∥e−β(t−t◦),
∀t ≥t◦≥0,
∀x(t◦) ∈IRn .
(2.12)

2.3 Lyapunov Stability
39
According to the previous deﬁnitions, if the origin is a globally exponen-
tially stable equilibrium then it is also globally uniformly asymptotically sta-
ble. The opposite is clearly not necessarily true since the convergence might
not be exponential.
We emphasize that the numbers α and β must be independent of t◦since in
some cases, one may establish that for a given system the bound (2.12) holds
but with constants α and β which depend on the initial times t◦. Then, we
may speak of global exponential (non-uniform) convergence and as a matter
of fact, of global asymptotic stability but it would be erroneous to say that
the origin is globally exponentially stable. Notice that in such case, neither
the origin is uniformly attractive nor the solutions are uniformly bounded.
Deﬁnition 2.9. Instability
The origin of Equation (2.3) is an unstable equilibrium if it is not stable.
Mathematically speaking, the property of instability means that there ex-
ists at least one ε > 0 for which no δ > 0 can be found such that
∥x(t◦)∥< δ
=⇒
∥x(t)∥< ε
∀t ≥t◦≥0 .
Or, in other words, that there exists at least one ε > 0 which is desired to be
a bound on the norm of the solution x(t) but there does not exist any pair
of initial conditions t◦∈IR+ and x(t◦) ̸= 0 ∈IRn whose solution x(t) may
satisfy ∥x(t)∥< ε for all t ≥t◦≥0 .
It must be clear that instability does not necessarily imply that the solution
x(t) grows to inﬁnity as t →∞. The latter is a contradiction of the weaker
property of boundedness of the solutions, discussed above.
We now present an example that illustrates the concept of instability.
Example 2.6. Consider the equations that deﬁne the motion of the van
der Pol system,
˙x1 = x2,
(2.13)
˙x2 = −x1 + (1 −x2
1)x2,
(2.14)
where x1 and x2 ∈IR. Notice that the origin is an equilibrium of these
equations.
The graph of some solutions generated by diﬀerent initial condi-
tions of the system (2.13)–(2.14) on the phase plane, are depicted in
Figure 2.7. The behavior of the system can be described as follows. If
the initial condition of the system is inside the closed curve Γ, and is
away from zero, then the solutions approach Γ asymptotically. If the
initial condition is outside of the closed curve Γ, then the solutions
also approach Γ.

40
2 Mathematical Preliminaries
•
x1
x2
Γ
0
0
ε0
....................................
...........................
...................................
...........................
...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
......................................................
......................................................................................................................................................................
Figure 2.7. Phase plane of the van der Pol oscillator
The origin of the system (2.13)–(2.14) is an unstable equilibrium.
To show this, we simply need to pick ε := ε0 (cf. Figure 2.7) to see
that there does not exist δ > 0 dependent on ε0 such that
∥x(0)∥< δ
=⇒
∥x(t)∥< ε0
∀t ≥0.
♦
We close this subsection by observing that some authors speak about “sta-
bility of systems” or “stability of systems at an equilibrium” instead of “sta-
bility of equilibria (or the origin)”. For instance the phrase “the system is
stable at the origin” may be employed to mean that “the origin is a stable
equilibrium of the system”. Both ways of speaking are correct and equiva-
lent. In this textbook we use the second one to be strict with respect to the
mathematical deﬁnitions.
2.3.3 Lyapunov Functions
We present deﬁnitions that determine a particular class of functions that are
fundamental in the use of Lyapunov’s direct method to study the stability of
equilibria of diﬀerential equations.
Deﬁnition 2.10. Locally and globally positive deﬁnite function
A continuous function W : IRn →IR+ is said to be locally positive deﬁnite if
1. W(0) = 0,
2. W(x) > 0
for small
∥x∦= 0.

2.3 Lyapunov Stability
41
A continuous function W : IRn →IR is said to be globally positive deﬁnite
(or simply positive deﬁnite) if
1. W(0) = 0,
2. W(x) > 0
∀x ̸= 0 .
According to this deﬁnition it should be clear that a positive deﬁnite func-
tion is also locally positive deﬁnite. Also, according to the deﬁnition of positive
deﬁnite matrix, a quadratic function f : IRn →IR, i.e. of the form
f(x) = xTPx ,
P ∈IRn×n
is positive deﬁnite if and only if P > 0.
The function W(x) is said to be (locally) negative deﬁnite if −W(x) is
(locally) positive deﬁnite.
For a continuous function V : IR+ × IRn →IR+, i.e. which also depends
on time, we say that V (t, x) is (resp. locally) positive deﬁnite if:
1. V (t, 0) = 0 ∀t ≥0 ;
2. V (t, x) ≥W(x),
∀t ≥0,
∀x ∈IRn (resp. for small ∥x∥)
where W(x) is a (resp. locally) positive deﬁnite function.
Deﬁnition 2.11. Radially unbounded function and decrescent func-
tion
A continuous function W : IRn →IR is said to be radially unbounded if
W(x) →∞
as
∥x∥→∞.
Correspondingly, we say that V (t, x) is radially unbounded if V (t, x) ≥
W(x) for all t ≥0.
A continuous function V : IR+ × IRn →IR is (locally) decrescent if there
exists a (locally) positive deﬁnite function W : IRn →IR+ such that
V (t, x) ≤W(x)
∀t ≥0
∀x ∈IRn (for small ∥x∥).
If V (t, x) is independent of t, i.e. if V (t, x) = V (x) then V (x) is decres-
cent.
The following examples illustrate the concepts presented above.
Example 2.7. Consider the graphs of the functions Vi(x) with i =
1, . . . , 4 as depicted in Figure 2.8. It is apparent from these graphs
that:

42
2 Mathematical Preliminaries
0
0
x
V1(x)
0
0
x
V2(x)
0
0
x
V3(x)
0
0
x
V4(x)
.......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.....................................................................................................................................................................................................................................................................................................................................................................................................................................
..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.........
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.........
Figure 2.8. Examples
•
V1(x) is locally positive deﬁnite but is not (globally) positive deﬁ-
nite;
•
V2(x) is locally positive deﬁnite, (globally) positive deﬁnite and
radially unbounded;
•
V3(x) is locally positive deﬁnite and (globally) positive deﬁnite but
it is not radially unbounded;
•
V4(x) is positive deﬁnite and radially unbounded.
♦
Example 2.8. The function W(x1, x2) = x2
1 + x2
2 is positive deﬁnite
and radially unbounded. Since W is independent of t, it follows im-
mediately that it is also decrescent.
♦

2.3 Lyapunov Stability
43
Example 2.9. The function V (t, x1, x2) = (t + 1)(x2
1 + x2
2) is positive
deﬁnite since V (t, x1, x2) ≥x2
1 + x2
2 and V (t, 0, 0) = 0 for all t ≥0.
However, V (t, x1, x2) is not decrescent.
♦
Example 2.10. The function W(x1, x2) = (x1 + x2)2 is not positive
deﬁnite since it does not satisfy W(x) > 0 for all x ̸= 0 such that
x1 = −x2. However, the function W(x1, x2) = (x1 + x2)2 + αx2
1, and
the function W(x1, x2) = (x1 + x2)2 + αx2
2, with α > 0 are positive
deﬁnite.
♦
In order to prepare the reader for the following subsection, where we
present Lyapunov’s direct method for the study of stability of equilibria, we
present below a series of concepts related to the notion of Lyapunov function
candidate.
Deﬁnition 2.12. Lyapunov function candidate
A continuous and diﬀerentiable4 function V : IR+ × IRn →IR+ is said to be a
Lyapunov function candidate for the equilibrium x = 0 ∈IRn of the equation
˙x = f(t, x) if:
1. V (t, x) is locally positive deﬁnite;
2. ∂V (t, x)
∂t
is continuous with respect to t and x ;
3. ∂V (t, x)
∂x
is continuous with respect to t and x .
Correspondingly, a continuous and diﬀerentiable function V : IRn →IR+ is
said to be a Lyapunov function candidate for the equilibrium x = 0 ∈IRn of
Equation (2.4), i.e. ˙x = f(x), if V (x) is locally positive deﬁnite and
dV (x)
dx
is continuous.
In other words, a Lyapunov function candidate for the equilibrium x = 0 ∈
IRn of Equations (2.3) or (2.4) is any locally positive deﬁnite and continuously
diﬀerentiable function; that is, with continuous partial derivatives.
The time derivative of a Lyapunov function candidate plays a key role in
drawing conclusions about the stability attributes of equilibria of diﬀerential
equations. For this reason, we present the following deﬁnition.
4 In some of the specialized literature authors do not assume diﬀerentiability. We
shall not deal with that here.

44
2 Mathematical Preliminaries
Deﬁnition 2.13. Time derivative of a Lyapunov function candidate
Let V (t, x) be a Lyapunov function candidate for the equation (2.3). The total
time derivative of V (t, x) along the trajectories of (2.3), denoted by ˙V (t, x),
is given by
˙V (t, x) := d
dt{V (t, x)} = ∂V (t, x)
∂t
+ ∂V (t, x)
∂x
T
f(t, x).
From the previous deﬁnition we observe that if V (x) does not depend
explicitly on time and Equation (2.3) is autonomous then,
˙V (x) = dV (x)
dx
T
f(x)
which does not depend explicitly on time either.
Deﬁnition 2.14. Lyapunov function
A Lyapunov function candidate V (t, x) for Equation (2.3) is a Lyapunov
function for (2.3) if its total time derivative along the trajectories of (2.3)
satisﬁes
˙V (t, x) ≤0
∀t ≥0
and for small ∥x∥.
Correspondingly, a Lyapunov function candidate V (x) for Equation (2.4) is a
Lyapunov function if ˙V (x) ≤0 for small ∥x∥.
2.3.4 Lyapunov’s Direct Method
With the above preliminaries we are now ready to present the basic results of
Lyapunov stability theory. Indeed, the theory of Lyapunov is the product of
more than a hundred years of intense study and there are numerous specialized
texts. The avid reader is invited to see the texts cited at the end of the chapter.
However, the list that we provide is by no means exhaustive; the cited texts
have been chosen specially for the potential reader of this book.
Theorem 2.2. Stability and uniform stability
The origin is a stable equilibrium of Equation (2.3), if there exists a Lya-
punov function candidate V (t, x) (i.e. a locally positive deﬁnite function with
continuous partial derivatives with respect to t and x) such that its total time
derivative satisﬁes
˙V (t, x) ≤0,
∀t ≥0
for small ∥x∥.
If moreover V (t, x) is decrescent for small ∥x∥then the origin is uniformly
stable.

2.3 Lyapunov Stability
45
This theorem establishes suﬃcient conditions for stability of the equilib-
rium in the sense of Lyapunov. It is worth remarking that the conclusion of
the theorem holds also if ˙V (t, x) ≤0 for all t ≥0 and for all x ∈IRn, or if
the Lyapunov function candidate V (t, x) is globally positive deﬁnite instead
of being only locally positive deﬁnite. The following theorem allows us to es-
tablish some results on stability of the equilibrium and on boundedness of
solutions.
Theorem 2.3. (Uniform) boundedness of solutions plus uniform sta-
bility
The origin is a uniformly stable equilibrium of Equation (2.3) and the so-
lutions x(t) are uniformly bounded for all initial conditions (t◦, x(t◦)) ∈
IR+×IRn if there exists a radially unbounded, globally positive deﬁnite, decres-
cent Lyapunov function candidate V (t, x) such that its total time derivative
satisﬁes
˙V (t, x) ≤0
∀t ≥t◦≥0
∀x ∈IRn .
In particular, item 1 of Deﬁnition 2.7 holds.
Example 2.11. Consider the dynamic model of an ideal pendulum
without friction as analyzed in Example 2.2 and shown in Figure 2.2
(cf. page 30) for which we now assume that no torque τ(t) is applied
at the axis of rotation, i.e. we consider the system described by the
diﬀerential equation
J ¨q + mgl sin(q) = 0
with
q(0), ˙q(0) ∈IR .
This equation may be rewritten in the state-space form as
˙x1 = x2
˙x2 = −mgl
J sin(x1),
where x1 = q and x2 =
˙q. Notice that these equations are au-
tonomous nonlinear, and the origin is an equilibrium. However, we
remind the reader that from Example 2.2, we know that the pen-
dulum has multiple equilibria, more precisely at [q
˙q]T = [nπ
0]T
for n = · · · , −2, −1, 0, 1, 2, · · · ; that is, the origin is the equilibrium
corresponding to the case n = 0.
In order to analyze the stability of the origin we use Theorem 2.2
with the following locally positive deﬁnite function:
V (x1, x2) = mgl [1 −cos(x1)] + J x2
2
2 .
Notice that the ﬁrst term on the right-hand side corresponds to the
potential energy, while the second one corresponds to the kinetic en-
ergy. Observe that V (x1, x2) is not a positive deﬁnite function since

46
2 Mathematical Preliminaries
it does not fulﬁl V (x1, x2) > 0 for all [x1 x2]T ̸= 0 ∈IR2. However, it
is locally positive deﬁnite because V (x1, x2) > 0 for ∥x∥> 0 small, in
the sense that ∥x∥< 2π .
Evaluating the total time derivative of V (x1, x2) we obtain
˙V (x1, x2) = mgl sin(x1) ˙x1 + Jx2 ˙x2
= 0 .
According to Theorem 2.2, the origin is a stable equilibrium, i.e.
the solutions x1(t) and x2(t) remain as close to the origin as desired
if the initial conditions x1(0) and x2(0) are suﬃciently small.
0
x1
x2
0
π
2π
−π
−2π
•
•
•
•
•
....................................
...........................
...................................
...........................
...................................
...........................
....................................
...........................
....................................
...........................
....................................
...........................
....................................
...........................
....................................
...........................
.....................................
...........................
.....................................
...........................
....................................
...........................
.....................................
...........................
..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
...............................................................................................................................................................................................................................................................................................................................................................................................................
..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Figure 2.9. Phase plane of the pendulum
Above, we proved that the origin is a stable equilibrium point; this
corresponds to n = 0. As a matter of fact, considering the multiple
equilibria, i.e. n ̸= 0, one can also show that the equilibria associated
to n even are stable while those for n odd are unstable.
We stress that although the origin (and strictly speaking, inﬁnitely
many other equilibria) is Lyapunov stable, this system has unbounded
solutions. Notice indeed from Figure 2.9, how the solution may grow
indeﬁnitely to the right or to the left, i.e. in the direction of the
displacements, x1; while the solution remains bounded in the direction
of the velocities, x2. In other words, if the pendulum starts to oscillate
at a speed larger than 2

mgl/J from any position then it will spin
for ever after!
♦
Thus, Example 2.2 shows clearly that stability of an equilibrium is not
synonymous with boundedness of the solutions.
We present next, suﬃcient conditions for global asymptotic and exponen-
tial stability.

2.3 Lyapunov Stability
47
Theorem 2.4. Global (uniform) asymptotic stability
The origin of Equation (2.3) (respectively of Equation 2.4) is globally asymp-
totically stable if there exists a radially unbounded, globally positive deﬁnite
Lyapunov function candidate V (t, x) (respectively V (x) ) such that its time
derivative is globally negative deﬁnite. If, moreover, the function V (t, x) is
decrescent, then the origin is globally uniformly asymptotically stable.
It should be clear that the origin of the autonomous Equation (2.4) is glob-
ally asymptotically stable if and only if it is globally uniformly asymptotically
stable.
Example 2.12. Consider the following scalar equation
˙x = −ax3 ,
x(0) ∈IR,
where a is a positive constant. The origin is a unique equilibrium. To
analyze its stability consider the following Lyapunov function candi-
date which is positive deﬁnite and radially unbounded:
V (x) = x2
2 .
Its total time derivative is
˙V (x) = x ˙x
= −ax4 .
So we see that from Theorem 2.4, the origin is globally asymptot-
ically stable.
♦
In the case that Equation (2.3) is autonomous there is no diﬀerence be-
tween global asymptotic stability and global uniform asymptotic stability.
Theorem 2.5. Global exponential stability
The origin of (2.3) is globally exponentially stable if there exists a Lyapunov
function candidate V (t, x) and positive constants α, β, γ and p ≥1 such that:
•
α∥x∥p ≤V (t, x) ≤β∥x∥p ;
•
˙V (t, x) ≤−γ∥x∥p
∀t ≥t◦≥0
∀x ∈IRn .
If all the above conditions hold only for small ∥x∥then we say that the origin
is an exponentially stable equilibrium.

48
2 Mathematical Preliminaries
Example 2.13. Consider the following scalar equation:
˙x = −a

1 −1
2 sin(t)

x
x(0) ∈IR,
where a is a positive constant. Note that the origin is a unique equilib-
rium. To analyze its stability consider the following Lyapunov function
candidate which is positive deﬁnite and radially unbounded:
V (x) = x2 .
Since V does not depend on t, it is decrescent. The total time deriva-
tive of V is
˙V (x) = 2x ˙x
= −2a

1 −1
2 sin(t)

x2
≤−ax2 .
So the conditions of Theorem 2.4 are satisﬁed and we conclude
that the origin is globally uniformly asymptotically stable. Moreover,
notice that the conditions of Theorem 2.5 also hold, with α = β = 1,
γ = a and p = 2 so the the origin is also globally exponentially stable.
♦
The following result establishes necessary conditions for certain global
properties of stability of equilibria.
Theorem 2.6. Consider the diﬀerential Equations (2.3) and (2.4). The unic-
ity of an existing equilibrium point is necessary for the following properties (or,
in other words, the following properties imply the unicity of an equilibrium):
•
global asymptotic stability;
•
global exponential stability.
The proof of Theorem 2.6 follows straightforwardly from the observation that
each of the above-cited concepts of stability implies that ∥x(t) −xe∥→0
when t →∞, and where xe is the equilibrium under analysis. In view of the
“globality” of the mentioned properties of stability, the convergence of the
solution x(t) to the equilibrium xe, must be veriﬁed for all initial conditions.
Clearly, this would not be the case if besides xe there existed other equilibria,
since in this case any solution starting oﬀat other equilibria, by deﬁnition,
would remain at that point forever after.

2.3 Lyapunov Stability
49
Notice that Theorem 2.6 does not establish as a necessary condition for
stability of the equilibrium, that the equilibrium in question be unique. It
is important to mention that for a given system there may coexist equilibria
with local stability properties and in particular, stable equilibria with unstable
equilibria.
Since for a given system the global properties of stability imply existence
of a unique equilibrium, it is correct to speak of not only the properties of
global stability of that equilibrium, but also of such properties for the system
itself. That is, sentences such as “such a system is globally asymptotically
stable” or, “the system is globally exponentially stable” are mathematically
meaningful and correct.
In control theory, i.e. when we are required to analyze the stability of
a particular system, ﬁnding a Lyapunov function with a negative deﬁnite
derivative is in general very hard. Nevertheless, if in spite of painstaking eﬀorts
we are unable to ﬁnd a Lyapunov function we must not conclude that the
origin of the system under analysis is unstable; rather, no conclusion can be
drawn. Fortunately, for autonomous systems, there are methods based on more
restrictive conditions but considerably easier to verify. A notable example
is the so-called La Salle’s invariance principle5 which is widely used in the
analysis of robot control systems. The following theorem is a simpliﬁed version
of La Salle’s invariance principle that appears adequate for the purposes of
this textbook.
Theorem 2.7. La Salle
Consider the autonomous diﬀerential equation
˙x = f(x)
whose origin x = 0 ∈IRn is an equilibrium. Assume that there exists a globally
positive deﬁnite and radially unbounded Lyapunov function candidate V (x),
such that
˙V (x) ≤0
∀x ∈IRn.
Deﬁne the set Ωas
Ω=

x ∈IRn : ˙V (x) = 0

.
(2.15)
If x(0) = 0 is the only initial state in Ωwhose corresponding solution, x(t),
remains forever in Ω(i.e. x(t) ∈Ωfor all t ≥0 ) then the origin x = 0 ∈IRn
is globally asymptotically stable.
5 While in the western literature this result is mainly attributed to the French math-
ematician J. P. La Salle, some authors call this “Krasovski˘ı–La Salle’s theorem”
to give credit to the Russian mathematician N. N. Krasovski˘ı who independently
reported the same theorem. See the bibliographical remarks at the end of the
chapter.

50
2 Mathematical Preliminaries
We stress that the application of the theorem of La Salle to establish global
asymptotic stability does not require that ˙V (x) be a negative deﬁnite function.
However, we recall that this theorem can be employed only for autonomous
diﬀerential equations. A practical way to verify the condition of La Salle’s
theorem and which suﬃces for most of this textbook is given in the following
statement.
Corollary 2.1. Simpliﬁed La Salle
Consider the set of autonomous diﬀerential equations
˙x = f x(x, z) ,
x ∈IRn
(2.16)
˙z = f z(x, z) ,
z ∈IRm .
(2.17)
where f x(0, 0) = 0 and f z(0, 0) = 0. That is, the origin is an equilibrium
point. Let V : IRn × IRm →IR+ be globally positive deﬁnite and radially un-
bounded in both arguments. Assume that there exists a globally positive deﬁnite
function W : IRm →IR+ such that
˙V (x, z) = −W(z) .
(2.18)
If x = 0 is the unique solution of f z(x, 0) = 0 then the origin [xT zT ]T = 0
is globally asymptotically stable.
The proof of this corollary is simple and follows by applying Theorem 2.7.
Therefore, for the sake of completeness and to illustrate the use of Theorem
2.7 we present it next.
Proof of Corollary 2.1. Since W(z) is globally positive deﬁnite in z we have
from (2.18) that the set Ωdeﬁned in (2.15) is in this case, {z = 0}∪{x ∈IRn}.
This means that for the solutions of (2.16), (2.17) to be contained in Ωthey
must verify that for all t ≥0, z(t) = ˙z(t) = 0 and
˙x(t) = f x(x(t), 0)
(2.19)
0 = f z(x(t), 0) .
(2.20)
However, by assumption the unique solution that satisﬁes (2.20) is the trivial
solution, i.e. x(t) = 0 for all t ≥0. In its turn, the trivial solution also satisﬁes
(2.19) since ˙x(t) = 0 and by assumption, f x(0, 0) = 0. Thus, the only initial
state for which [x(t)T z(t)T ]T ∈Ωfor all t ≥0 is [x(0)T z(0)T ]T = 0. Global
asymptotic stability of the origin follows from Theorem 2.7.
♦♦♦
We present next some examples to further illustrate the use of La Salle’s
theorem.

2.3 Lyapunov Stability
51
Example 2.14. Consider the autonomous equations
˙x = −k z,
x(0) ∈IR
˙z = −z3 + k x,
z(0) ∈IR
where k ̸= 0. Note that the origin is an equilibrium point. Consider
now the following Lyapunov function candidate – positive deﬁnite and
radially unbounded – to study the stability of the origin:
V (x, z) = 1
2

x2 + z2
.
The total time derivative of V (x, z) is given by
˙V (x, z) = −z4
≤0 .
Hence, according to Theorem 2.2 we may conclude stability of the
origin. However, note that ˙V (x, z) = 0 for any value of x and z = 0,
so it cannot be even locally negative deﬁnite. Therefore, since ˙V (x, z)
does not satisfy the conditions of Theorem 2.4 we may not conclude
global asymptotic stability of the origin from this result.
Nevertheless, since the equations under study are autonomous, we
may try to invoke La Salle’s theorem (Theorem 2.7). To that end, let
us follow the conditions of Corollary 2.1.
•
We already veriﬁed that the origin is an equilibrium point.
•
We also have veriﬁed that V (x, z) is globally positive deﬁnite and
radially unbounded in both arguments.
•
In addition, ˙V (x, z) = −z4 so we deﬁne W(z) := z4 which is a
globally positive deﬁnite function of z.
•
It is only left to verify that the only solution of fz(x, 0) = 0 is x = 0
which in this case, takes the form 0 = kx. Hence it is evident that
x = 0 is the only solution.
We conclude from Corollary 2.1 that the origin is globally asymptot-
ically stable.
♦
Example 2.15. Consider the following equations
˙x1 = −x1 + k1x2 + k2x3
x1(0) ∈IR
˙x2 = −k1x1
x2(0) ∈IR
˙x3 = −k2x1
x3(0) ∈IR

52
2 Mathematical Preliminaries
where k1 ̸= 0, k2 ̸= 0. These equations represent an autonomous linear
diﬀerential equation whose equilibria are the points
[x1
x2
x3] =

0
x2
−k1
k2
x2

.
Notice that there exist an inﬁnite number of equilibrium points, one
for each x2 ∈IR. In particular, for x2 = 0, the origin is an equilibrium.
To study its stability we consider the Lyapunov function candidate
which is positive deﬁnite and radially unbounded,
V (x) = 1
2

x2
1 + x2
2 + x2
3

,
and whose total time derivative is
˙V (x) = −x2
1.
Theorem 2.3 guarantees stability of the origin and boundedness of
the solutions. Theorem 2.4 on global asymptotic stability, may not be
used since ˙V (x) is zero at x1 = 0 and for any values of x2 and x3; that
is, it does not hold that ˙V (x) is negative deﬁnite. Even though the
equations under study are autonomous they have an inﬁnite number
of equilibria. For this reason and according to Theorem 2.6, the origin
may not be globally asymptotically stable.
♦
In the previous example it is not possible to conclude that the origin
is an asymptotically stable equilibrium however, under the above conditions
one may conclude that limt→∞x1(t) = 0. Indeed this can be achieved by
invoking the following Lemma which guarantees boundedness of the solutions
and convergence of part of the state. This is obviously a weaker property
than (global) asymptotic stability but it is still a useful property to evaluate,
rigorously, the performance of a controller.
Lemma 2.2. Consider the continuously diﬀerentiable functions x : IR+ →
IRn, z : IR+ →IRm, h : IR+ →IR+ and P : IR+ →IR(n+m)×(n+m). Assume
that P(t) is a symmetric positive deﬁnite matrix for each t ∈IR+ and P is
continuous. Deﬁne the function V : IR+ × IRn × IRm × IR+ →IR+ as
V (t, x, z, h) =

x
z
T
P(t)

x
z

+ h(t) ≥0 .
If the total time derivative of V (t, x, z, h), i.e.
˙V (t, x, z, h) := ∂V (t, x, z, h)
∂t
+ ∂V (t, x, z, h)
∂x
Tdx
dt
+ ∂V (t, x, z, h)
∂z
Tdz
dt + dh
dt ,

Bibliography
53
satisﬁes, for all t ∈IR+, x ∈IRn, z ∈IRm and h ∈IR+,
˙V (t, x, z, h) = −

x
z
T 
Q(t)
0
0
0
 
x
z

≤0
where Q(t) = Q(t)T > 0 for all t ≥0 then,
1. x(t), z(t) and h(t) are bounded for all t ≥0 and
2. x(t) is square-integrable, i.e.
 ∞
0
∥x(t)∥2 dt < ∞.
If, moreover, ˙x is also bounded then we have
lim
t→∞x(t) = 0 .
The proof of this lemma is presented in Appendix A.
Bibliography
What we know nowadays as Lyapunov theory was launched by the Russian
mathematician A. M. Lyapunov in his doctoral thesis in 1892. It is inter-
esting to stress that his work was largely inﬂuenced by that of the French
mathematicians H. Poincar´e (contemporary of and personally known by A.
M. Lyapunov) and Joseph La Grange, on stability of second-order diﬀeren-
tial equations such as, precisely, Lagrange’s equations. The reference for the
original work of A. M. Lyapunov is
•
Lyapunov, A. M., 1907, “Probl`eme de la stabilit´e du mouvement”, Annales
de la facult´e de sciences de Toulouse, volume 9, pp. 203-474. Translation
—revised by A. M. Lyapunov— from the original published in Russian in
Comm. Soc. Math., Kharkov 1892. Reprinted in Ann. Math. Studies 17,
Princeton 1949. See also the more recent edition “The general problem of
stability of motion”, Taylor and Francis: London, 1992.
La Salle’s Theorem as adapted here for the scope of this text, is a corol-
lary of the so-called La Salle’s invariance principle which was originally and
independently proposed by J. La Salle and by N. N. Krasovski˘ı and may be
found in its general form in
•
La Salle J., Lefschetz S., 1961, “Stability by Lyapunov’s direct method with
applications”, Academic Press, New York.

54
2 Mathematical Preliminaries
•
Krasovski˘ı N. N., 1963, “Problems of the theory of stability of motion”,
Stanford Univ. Press, 1963. Translation from the original Russian edition,
Moscow, 1959.
The theorems presented in this chapter are the most commonly employed
in stability analysis of control systems. The presentation that we used here
has been adapted from their original statements to meet the scope of this
textbook. This material is inspired from
•
Vidyasagar M., 1978 and 1993, “Nonlinear systems analysis”, Prentice-
Hall, Electrical Engineering Series.
•
Khalil H. 2001, “Nonlinear systems”, Third Edition, Prentice-Hall.
The deﬁnition and theorems on ﬁxed points may be found in
•
Kolmogorov A. N., Fomin S. V., 1970, “Introductory real analysis”, Dover
Pub. Inc.
•
Hale J. K., 1980, “Ordinary diﬀerential equations”, Krieger Pub. Co.
•
Khalil H., 1996, “Nonlinear systems”, Second Edition, Prentice-Hall.
•
Sastry S., 1999, “Nonlinear systems: analysis, stability and control”, Springer-
Verlag, New York.
Other references on diﬀerential equations and stability in the sense of
Lyapunov are:
•
Arnold V., 1973, “Ordinary diﬀerential equations”, MIT Press.
•
Borrelli R., Coleman C., 1987, “Diﬀerential equations–A modeling ap-
proach”, Prentice-Hall.
•
Slotine J. J., Li W., 1991, “Applied nonlinear control”, Prentice-Hall.
•
Khalil H., 1996, “Nonlinear systems”, Second Edition, Prentice-Hall.
•
Hahn W., 1967, “Stability of motion”, Springer-Verlag: New York.
•
Rouche N., Mawhin J., 1980 “Ordinary diﬀerential equations II: Stability
and periodical solutions”, Pitman publishing Ltd., London.
Problems
1. Consider the vectors x ∈IRn and y ∈IRm. Show that

x
y
 =

∥x∥
∥y∥
 .

Problems
55
2. Consider the matrix
P(x) =
⎡
⎣
k
−
ε
1 + 2x2
−
ε
1 + 2x2
1
⎤
⎦
where ε > 0. Show that if k > ε2 then P is positive deﬁnite, i.e. P(x) > 0
for all x ∈IR.
3. Consider the diﬀerential equation that describes the behavior of a Hopﬁeld
neuron:
˙x = −ax + w tanh(x) + b
where a > 0, w, b ∈IR.
a) Show by use of the contraction mapping theorem that if a −|w| > 0
then the diﬀerential equation has a unique equilibrium.
b) Assume that a = b = 1 and w = 1/2. Use the contraction mapping
theorem together with a numerical algorithm to obtain an approxi-
mated value of the unique equilibrium of the diﬀerential equation.
4. Consider the function
V (x1, x2) = [ x1
x2 ]

4
1
−10
3
 
x1
x2

.
Is V (x1, x2) positive deﬁnite?
5. Consider the function
V (x1, x2) = ax2
1 + 2bx1x2 + cx2
2 .
Show that if a > 0 and ac > b2 then V (x1, x2) is positive deﬁnite.
6. Consider the linear autonomous diﬀerential equation
˙x = Ax,
x ∈IRn .
Show that if there exists a pole of this equation at the origin of the complex
plane, then the equation has an inﬁnite number of equilibria.
Hint: Here, the “poles” are the eigenvalues of A.
7. An equilibrium xe ∈IRn is an isolated equilibrium of ˙x = f(x) if there
exists a real positive number α > 0 such that there may not be any
equilibrium other than xe in Ω, where
Ω= {x ∈IRn : ∥x −xe∥< α} .
In the case that there does not exist any α > 0 that satisﬁes the above
then the equilibrium xe is not isolated.
Assume that xe is a non-isolated equilibrium. Answer ‘true’ or ‘false’ to
the following claims:

56
2 Mathematical Preliminaries
a) the equilibrium xe may not be asymptotically stable;
b) the equilibrium xe is stable.
8. Consider the function f(x, y) : IR2 →IR2,
f(x, y) =

f1(x, y)
f2(x, y)

.
Assume that f(x, y) = 0 ⇐⇒x = 0 and y = 0. Does this imply that
f1(x, y) = 0 ⇐⇒x = 0 and y = 0 ?
9. Consider the following two diﬀerential equations:
˙x1 = ε[x1 −ε] + x2 −[x1 −ε]

[x1 −ε]2 + x2
2

,
x1(0) ∈IR
˙x2 = −[x1 −ε] + εx2 −x2

[x1 −ε]2 + x2
2

,
x2(0) ∈IR
where ε ∈IR is constant. Determine the equilibria.
10. Consider the following second-order diﬀerential equation,
¨y + [y2 −1] ˙y + y2 + 1 = 0,
y(0), ˙y(0) ∈IR .
Express this equation in the form ˙x = f(t, x) .
a) Is this equation linear in the state x ?
b) What are the equilibrium points? Discuss.
11. Consider the equation ˙x = f(x). Assume that xe = 0 ∈IRn is a stable
equilibrium. Does this imply that the solutions x(t) are bounded for all
t ≥0 ?
12. Consider the equations
˙x1 = x2 −x3
1
˙x2 = −x1 −x3
2
for which the origin is the unique equilibrium. Use the direct Lyapunov’s
method (propose a Lyapunov function) to show that the origin is stable.
13. Pick positive integer numbers m and n and appropriate constants a and
b to make up a Lyapunov function of the form
V (x1, x2) = ax2m
1
+ bx2n
2
in order to show stability of the origin for
a)
˙x1 = −2x3
2
˙x2 = 2x1 −x3
2

Problems
57
b)
˙x1 = −x3
1 + x3
2
˙x2 = −x3
1 −x3
2 .
14. Theorem 2.4 allows us to conclude global uniform asymptotic stability of
an equilibrium of a diﬀerential equation. To show only uniform asymptotic
stability (i.e. not global), the conditions of Theorem 2.4 that impose to
the Lyapunov function candidate V (t, x) to be:
•
(globally) positive deﬁnite;
•
radially unbounded;
•
(globally) decrescent and,
•
for ˙V (t, x), to be (globally) negative deﬁnite;
must be replaced by:
•
locally positive deﬁnite;
•
locally decrescent and,
•
for ˙V (t, x), to be locally negative deﬁnite.
If moreover, the diﬀerential equation is autonomous and the Lyapunov
function candidate V (x) is independent of time, then the equilibrium is
(locally) asymptotically stable provided that V (x) is locally positive def-
inite and ˙V (x) is locally negative deﬁnite.
An application of the latter is illustrated next.
Consider the model of a pendulum of length l and mass m concentrated
at the end of the pendulum and subject to the action of gravity g, and
with viscous friction at the joint (let f > 0 be the friction coeﬃcient), i.e.
ml2¨q + f ˙q + mgl sin(q) = 0,
where q is the angular position with respect to the vertical. Rewrite the
model in the state-space form ˙x = f(x) with x = [q
˙q]T .
a) Determine the equilibria of this equation.
b) Show asymptotic stability of the origin by use of the Lyapunov func-
tion
V (q, ˙q) = 2mgl[1 −cos(q)] + ml2
2
˙q2 + 1
2

f
l√mq + l√m ˙q
2
.
c) Is ˙V (q, ˙q) a negative deﬁnite function?
15. Complete the analysis of Example 2.15 by applying Lemma 2.2.

3
Robot Dynamics
Robot manipulators are articulated mechanical systems composed of links
connected by joints. The joints are mainly of two types: revolute and prismatic.
In this textbook we consider robot manipulators formed by an open kinematic
chain as illustrated in Figure 3.1.
q1
z1
z2
z3
q3
zn
qn
x =
⎡
⎢⎣
x1
x2...
xm
⎤
⎥⎦
q2
z0
x0
y0
joint 2
link 1
joint 1
link 2
joint n
link n
Figure 3.1. Abstract diagram of an n-DOF robot manipulator
Consider the generic conﬁguration of an articulated arm of n links shown
in Figure 3.1. In order to derive the mathematical model of a robot one typ-
ically starts by placing a 3-dimensional reference frame (e.g. in Cartesian
coordinates) at any location in the base of the robot. Here, axes will be la-
beled with no distinction using {x y z} or {x0 y0 z0} or {x1 x2 x3}. The
links are numbered consecutively from the base (link 0) up to the end-eﬀector
(link n). The joints correspond to the contact points between the links and

60
3 Robot Dynamics
are numbered in such a way that the ith joint connects the ith to the (i−1)th
link. Each joint is independently controlled through an actuator, which is usu-
ally placed at that joint and the movement of the joints produces the relative
movement of the links. We temporarily denote by zi, the ith joint’s axis of
motion. The generalized joint coordinate denoted by qi, corresponds to the
angular displacement around zi if the ith joint is revolute, or to the linear
displacement along zi if the ith joint is prismatic. In the typical case where
the actuators are placed at the joints among the links, the generalized joint
coordinates are named joint positions. Unless explicitly said otherwise, we
assume that this is the case.
x0
z0
z1
q1
q2
z2
z3
q3
z4
q4
y0
x =
⎡
⎣
x1
x2
x3
⎤
⎦
Figure 3.2. Example of a 4-DOF robot
Example 3.1. Figure 3.2 shows a 4-DOF manipulator. The placement
of the axes zi as well as the joint coordinates, are illustrated in this
ﬁgure.
♦
The joint positions corresponding to each joint of the robot, and which
are measured by sensors adequately placed at the actuators, that are usually
located at the joints themselves, are collected for analytical purposes, in the
vector of joint positions q. Consequently, for a robot with n joints, that is,
with n DOF (except for special cases, such as elastic-joints or ﬂexible-link
robots), the vector of joint positions q has n elements:

3 Robot Dynamics
61
q =
⎡
⎢⎢⎣
q1
q2
...
qn
⎤
⎥⎥⎦
i.e. q ∈IRn. On the other hand it is also of great interest, speciﬁcally from a
practical viewpoint, to determine the position and orientation (posture) of the
robot’s end-eﬀector since it is the latter that actually carries out the desired
task. Such position and orientation are expressed with respect to the reference
frame placed at the base of the robot (e.g. a Cartesian frame {x0, y0, z0}) and
eventually in terms of the so-called Euler angles. Such coordinates (and angles)
are collected in the vector x of operational positions1
x =
⎡
⎢⎢⎣
x1
x2
...
xm
⎤
⎥⎥⎦
where m ≤n. In the case when the robot’s end-eﬀector can take any position
and orientation in the Euclidean space of dimension 3 (e.g. the room where
the reader is at the moment), we have m = 6. On the other hand, if the
robot’s motion is on the plane (i.e. in dimension 2) and only the position of
the end-eﬀector is of interest, then m = 2. If, however, the orientation on the
plane is of concern then, m = 3.
The direct kinematic model of a robot, describes the relation between the
joint position q and the position and orientation (posture) x of the robot’s
end-eﬀector. In other words, the direct kinematic model of a robot is a function
ϕ : IRn →IRm such that
x = ϕ(q) .
Although lengthy, computation of the direct kinematic model, x = ϕ(q),
is methodical and in the case of robots of only few DOF, it involves simple
trigonometric expressions.
The inverse kinematic model consists precisely in the inverse relation of
the direct kinematic model, that is, it corresponds to the relation between the
operational posture x and the joint position q, i.e.
q = ϕ−1(x).
In contrast to the direct kinematic model, computation of the inverse kine-
matic model q = ϕ−1(x) may be highly complex and, as a matter of fact, may
yield multiple solutions.
The dynamic model of a robot consists of an ordinary diﬀerential equation
where the variable corresponds to the vector of positions and velocities, which
1 These are also known as positions in the operational space or workspace.

62
3 Robot Dynamics
may be in joint coordinates q, ˙q or in operational coordinates x, ˙x. In general,
these are second-order nonlinear models which can be written in the generic
form
f EL(q, ˙q, ¨q, τ) = 0 ,
(3.1)
f C(x, ˙x, ¨x, τ) = 0 .
(3.2)
The vector τ stands for the forces and torques applied at the joints by
the actuators. The dynamic model (3.1) is the dynamic model in joint space,
while (3.2) corresponds to the dynamic model in operational space. In this
text, we focus on the dynamic model in joint space and, for simplicity, we
omit the words “in joint space”.
Kinematics as much as dynamics, is fundamental to plan and carry out
speciﬁc tasks for robot manipulators. Both concepts are dealt with in consid-
erable detail in a large number of available textbooks (see the list of references
at the end of this chapter). However, for the sake of completeness we present
in this chapter the basic issues related to robot dynamics. In the next two
chapters we present properties of the dynamic model, relevant for control. In
Chapter 5 we present in detail the model of a real 2-DOF lab prototype which
serves as a case study throughout the book.
Besides the unquestionable importance that robot dynamics has in control
design, the dynamic models may also be used to simulate numerically (with a
personal computer and specialized software), the behavior of a speciﬁc robot
before actually being constructed. This simulation stage is important, since it
allows us to improve the robot design and in particular, to adapt this design
to the optimal execution of particular types of tasks.
One of the most common procedures followed in the computation of the
dynamic model for robot manipulators, in closed form (i.e. not numerical), is
the method which relies on the so-called Lagrange’s equations of motion. The
use of Lagrange’s equations requires the notion of two important concepts
with which we expect the reader to be familiar: kinetic and potential energies.
We describe next in some detail, how to derive the dynamic model of a
robot via Lagrange’s equations.
3.1 Lagrange’s Equations of Motion
The dynamic equations of a robot manipulator in closed form may be obtained
from Newton’s equations of motion or, via Lagrange’s equations. All of these
are well documented in textbooks on analytical mechanics and are only brieﬂy
presented here.
The disadvantage of the ﬁrst method is that the complexity of the analysis
increases with the number of joints in the robot. In such cases, it is better

3.1 Lagrange’s Equations of Motion
63
to use Lagrange’s equation of motion. The latter are named after the French
mathematician Joseph Louis de La Grange (today spelled “Lagrange”) which
ﬁrst reported them in 1788 in his celebrated work “M´ecanique analytique”2.
Consider the robot manipulator with n links depicted in Figure 3.1. The
total energy E of a robot manipulator of n DOF is the sum of the kinetic and
potential energy functions, K and U respectively, i.e.
E (q, ˙q) = K (q, ˙q) + U(q)
where q = [q1, · · · , qn]T .
The Lagrangian L(q, ˙q) of a robot manipulator of n DOF is the diﬀerence
between its kinetic energy K and its potential energy U, that is,
L (q, ˙q) = K (q, ˙q) −U(q) .
(3.3)
We assume here that the potential energy U is due only to conservative
forces such as gravitational energy and energy stored in compressed springs.
Then, the Lagrange equations of motion for a manipulator of n DOF, are
given by
d
dt
∂L(q, ˙q)
∂˙q

−∂L(q, ˙q)
∂q
= τ,
or in the equivalent form by
d
dt
∂L(q, ˙q)
∂˙qi

−∂L(q, ˙q)
∂qi
= τi,
i = 1, · · · , n
(3.4)
where τi correspond to the external forces and torques (delivered by the ac-
tuators) at each joint as well as to other (nonconservative) forces. In the class
of nonconservative forces we include those due to friction, the resistance to
the motion of a solid in a ﬂuid, and in general, all those that depend on time
and velocity and not only on position.
Notice that one has as many scalar dynamic equations as the manipulator
has degrees of freedom.
The use of Lagrange’s equations in the derivation of the robot dynamics
can be reduced to four main stages:
1. Computation of the kinetic energy function K(q, ˙q) .
2. Computation of the potential energy function U(q) .
3. Computation of the Lagrangian (3.3) L(q, ˙q) .
4. Development of Lagrange’s equations (3.4).
2 These equations are also called Euler–Lagrange equations in honor to the Swiss
scientist Leonhard Euler, contemporary of La Grange, who discovered a similar
but more general set of second-order diﬀerential equations.

64
3 Robot Dynamics
In the rest of this section we present some examples that illustrate the
process of obtaining the robot dynamics by the use of Lagrange’s equations
of motion.
z0
z0
x0
y0
x0
q1
y0
ϕ
l2
m2
m1
l1
Figure 3.3. Example of a 1-DOF mechanism
Example 3.2. Consider the mechanism shown in Figure 3.3. It consists
of a rigid link formed by two parts, of lengths l1 and l2, whose masses
m1 and m2 are, for simplicity, considered to be concentrated at their
respective centers of mass, located at the ends. The angle ϕ is constant.
The mechanism possesses only revolute motion about the z0 axis,
the angle of which is represented by q1. For this example, the only
degree-of-freedom is associated to the joint 1. Then, q is a scalar de-
ﬁned as q = q1.
We emphasize that the dynamic model of this mechanism may be
obtained using the concepts of dynamics of rigid bodies in rotation,
which are subjects of study in elementary courses of physics. However,
for the sake of illustration we employ Lagrange’s equations of motion.
The kinetic energy function K(q, ˙q) of the system is given by the
product of half the moment of inertia times the angular velocity
squared, i.e.
K (q, ˙q) = 1
2m2l2
2 cos2(ϕ) ˙q2
and the corresponding potential energy
U(q) = m1l1g + m2 (l1 + l2 sin(ϕ)) g

3.1 Lagrange’s Equations of Motion
65
where g is the gravity acceleration. Here, we assumed that the poten-
tial energy function is zero on the plane x0–y0. Actually, notice that
in this example the potential energy is constant so in particular, it
does not depend on the joint position q.
The Lagrangian L(q, ˙q), expressed by (3.3), is in this case
L(q, ˙q) = m2
2 l2
2 cos2(ϕ) ˙q2 −m1l1g −m2 (l1 + l2sin(ϕ)) g .
From this, one can obtain the following equations:
∂L
∂˙q = m2l2
2 cos2(ϕ) ˙q
d
dt
∂L
∂˙q

= m2l2
2 cos2(ϕ) ¨q
∂L
∂q = 0 .
Then, the corresponding Lagrange Equation (3.4) is
m2l2
2 cos2(ϕ) ¨q = τ ,
(3.5)
where τ is the torque applied at the joint 1. Equation (3.5) describes
the dynamic behavior of the mechanism. Notice that the dynamic
model is simply a linear second-order nonautonomous diﬀerential
equation.
Equation (3.5) may be expressed in terms of the state vector [q ˙q]T
as
d
dt
⎡
⎣
q
˙q
⎤
⎦=
⎡
⎢⎣
˙q
τ
m2l2
2 cos2(ϕ)
⎤
⎥⎦;
⎡
⎣
q(0)
˙q(0)
⎤
⎦∈IR2 .
The necessary and suﬃcient condition for the existence of equi-
libria is τ(t) = 0 for all t ≥0. In this situation, the equation has an
inﬁnite number of equilibria which are given by [q ˙q]T = [q∗0]T ∈IR2
with q∗∈IR. The interpretation of this result is the following. If at the
instant t = 0 the position q(0) has any value q∗∈IR, the velocity ˙q(0)
is zero and moreover no torque is applied at the joint (i.e. τ(t) = 0 for
all t) then, we have q(t) = q∗and ˙q(t) = 0 for all t ≥0. Note that the
latter is in accordance with the physical interpretation of the concept
of equilibrium.
♦
The following example illustrates the derivation of the dynamic model of
the 2-DOF robot with revolute joints shown in Figure 3.4 and that moves
about purely on the horizontal plane. Therefore, gravity has absolutely no

66
3 Robot Dynamics
inﬂuence on the robot dynamics. This should not surprise the reader; note
that the potential energy for this robot is constant since its mass does not
move in the vertical direction.
A particularity of this example, is that the actuators that deliver the
torques are not physically located at the joints themselves, but one of them
transmits the motion to the link through belts. Such types of transmission are
fairly common in industrial robots. The motivation for such conﬁgurations is
to lighten the weight (henceforth the inertia) of the arm itself by placing the
actuators as close to the base as possible.
l1
q1
x
y
τ1
z
τ2
m2
I2
δ
q2
lc2
m1
I1
lc1
Figure 3.4. Example of a 2-DOF robot
Example 3.3. Consider the robot manipulator with 2 DOF shown in
Figure 3.4. This manipulator consists of two rigid links where l1 is
the length the ﬁrst link. Both joints are revolute. The robot moves
about only on the horizontal plane x–y as is shown in Figure 3.4. The
masses of the links are denoted by m1 and m2 respectively. Notice
that the center of mass of link 2 may be physically placed “out” of
the link itself! This is determined by the value of the constant angle δ.
The distances of the rotating axes to the centers of mass, are denoted
by lc1 and lc2 respectively. Finally, I1 and I2 denote the moments
of inertia of the links with respect to axis that passes through their

3.1 Lagrange’s Equations of Motion
67
respective centers of mass and that are parallel to the z axis. The joint
positions associated to the angles q1 and q2 are measured between each
respective link and an axis which is parallel to the x axis. Both angles
are taken to be positive counterclockwise. The motion is transmitted
to link 2 by a belt since the corresponding actuator is placed at the
base of the robot. The vector of joint positions q is deﬁned as
q = [q1 q2]T .
The kinetic energy function K(q, ˙q) for this arm may be decom-
posed into the sum of two parts: K(q, ˙q) = K1(q, ˙q) + K2(q, ˙q), where
K1(q, ˙q) and K2(q, ˙q) are the kinetic energies associated with the
masses m1 and m2 respectively. In turn, the kinetic energy includes the
linear and angular motions. Thus, we have K1(q, ˙q) = 1
2m1v2
1 + 1
2I1 ˙q2
1,
where v1 is the speed3 of the center of mass of link 1. In this case,
K1(q, ˙q) = 1
2m1l2
c1 ˙q2
1 + 1
2I1 ˙q2
1 .
(3.6)
On the other hand, K2(q, ˙q) = 1
2m2v2
2 + 1
2I2 ˙q2
2, where v2 is the
speed of the center of mass of link 2. This speed squared, i.e. v2
2, is
given by
v2
2 = ˙x2
2 + ˙y2
2
where ˙x2 and ˙y2 are the components of the velocity vector of the
center of mass of link 2. The latter are obtained by evaluating the
time derivative of the positions x2 and y2 of the center of mass of link
2, i.e.
x2 = l1 cos(q1) + lc2 cos(q2 −δ)
y2 = l1 sin(q1) + lc2 sin(q2 −δ) .
Using the trigonometric identities, cos(θ)2 + sin(θ)2 = 1 and
sin(q1)sin(q2 −δ)+cos(q1)cos(q2 −δ) = cos(q1 −q2 +δ), we ﬁnally get
v2
2 = l2
1 ˙q2
1 + l2
c2 ˙q2
2 + 2l1lc2 cos(q1 −q2 + δ) ˙q1 ˙q2
which implies that
K2(q, ˙q) = m2
2 l2
1 ˙q2
1 + m2
2 l2
c2 ˙q2
2 + m2l1lc2 cos(q1 −q2 + δ) ˙q1 ˙q2
+ 1
2I2 ˙q2
2 .
(3.7)
Since the robot moves only on the horizontal plane, the potential
energy is constant, e.g. U(q) = 0 .
3 Some readers may be surprised that we use the word speed as opposed to velocity.
We emphasize that velocity is a vector quantity hence, it has a magnitude and
direction. The magnitude of the velocity is called speed.

68
3 Robot Dynamics
So from Equations (3.6) and (3.7), it is clear that the Lagrangian,
L(q, ˙q) = K(q, ˙q) −U(q) ,
takes the form
L(q, ˙q) = K1(q, ˙q) + K2(q, ˙q)
= 1
2(m1l2
c1 + m2l2
1) ˙q2
1 + 1
2m2l2
c2 ˙q2
2
+ m2l1lc2 cos(q1 −q2 + δ) ˙q1 ˙q2
+ 1
2I1 ˙q2
1 + 1
2I2 ˙q2
2.
From this equation we obtain the following expressions:
∂L
∂˙q1
= (m1l2
c1 + m2l2
1 + I1) ˙q1
+ m2l1lc2 cos(q1 −q2 + δ) ˙q2 ,
d
dt
 ∂L
∂˙q1

=
 
m1l2
c1 + m2l2
1 + I1
!
¨q1
+ m2l1lc2 cos(q1 −q2 + δ)¨q2
−m2l1lc2sin(q1 −q2 + δ)( ˙q1 −˙q2) ˙q2 ,
∂L
∂q1
= −m2l1lc2 sin(q1 −q2 + δ) ˙q1 ˙q2 ,
∂L
∂˙q2
= m2l2
c2 ˙q2 + m2l1lc2 cos(q1 −q2 + δ) ˙q1 + I2 ˙q2 ,
d
dt
 ∂L
∂˙q2

= m2l2
c2¨q2 + m2l1lc2 cos(q1 −q2 + δ)¨q1
−m2l1lc2 sin(q1 −q2 + δ) ˙q1( ˙q1 −˙q2) + I2¨q2 ,
∂L
∂q2
= m2l1lc2 sin(q1 −q2 + δ) ˙q1 ˙q2 .
Thus, the dynamic equations that model the robot manipulator
may be obtained by using Lagrange’s equations (3.4),
τ1 =

m1l2
c1 + m2l2
1 + I1

¨q1
+ m2l1lc2 cos(q1 −q2 + δ)¨q2
+ m2l1lc2 sin(q1 −q2 + δ) ˙q2
2
and,

3.1 Lagrange’s Equations of Motion
69
τ2 = m2l1lc2 cos(q1 −q2 + δ)¨q1 + [m2l2
c2 + I2]¨q2
−m2l1lc2 sin(q1 −q2 + δ) ˙q2
1 .
Finally using the identities
cos(q1 −q2 + δ) = cos(δ)cos(q1 −q2) −sin(δ)sin(q1 −q2)
= cos(δ)cos(q2 −q1) + sin(δ)sin(q2 −q1),
sin(q1 −q2 + δ) = cos(δ)sin(q1 −q2) + sin(δ)cos(q1 −q2)
= −cos(δ)sin(q2 −q1) + sin(δ)cos(q2 −q1) ,
and denoting C21 = cos(q2 −q1), S21 = sin(q2 −q1), one obtains
τ1 =

m1l2
c1 + m2l2
1 + I1

¨q1
+ [m2l1lc2 cos(δ)C21 + m2l1lc2 sin(δ)S21]¨q2
+ [−m2l1lc2 cos(δ)S21 + m2l1lc2 sin(δ)C21] ˙q2
2
(3.8)
and
τ2 = [m2l1lc2 cos(δ)C21 + m2l1lc2 sin(δ)S21]¨q1
+ [m2l2
c2 + I2]¨q2
+ [m2l1lc2 cos(δ)S21 −m2l1lc2 sin(δ)C21] ˙q2
1
(3.9)
which are of the form (3.1) with
f EL(q, ˙q, ¨q, τ) =

τ1 −RHS(3.8)
τ2 −RHS(3.9)

where RHS(3.8) and RHS(3.9) denote the terms on the right-hand
side of (3.8) and (3.9) respectively.
♦
In the following example we derive the dynamic model of a Cartesian robot
with 3 DOF whose main feature is that it has a linear dynamic model.
Example 3.4. Consider the 3-DOF Cartesian robot manipulator shown
in Figure 3.5. The manipulator consists of three rigid links mutually
orthogonal. The three joints of the robot are prismatic. The robot’s
displacements happen in the space x0–y0–z0 shown in Figure 3.5. The
vector of joint positions is q = [q1 q2 q3]T .
The kinetic energy function for this manipulator is given by (cf.
Figure 3.5):

70
3 Robot Dynamics
x0
y0
z0
q1
q2
q3
x0
y0
z0
q2
q3
q1
m3
m2
m1
Figure 3.5. Example of a 3-DOF Cartesian robot
K(q, ˙q) = 1
2

m1 ˙q2
3 + [m1 + m2] ˙q2
2 + [m1 + m2 + m3] ˙q2
1

.
(3.10)
On the other hand, the potential energy is given by
U(q) = [m1 + m2 + m3]gq1 .
(3.11)
From Equations (3.10) and (3.11) we obtain the Lagrangian,
L(q, ˙q) = K(q, ˙q) −U(q)
= 1
2

m1 ˙q2
3 + [m1 + m2] ˙q2
2 + [m1 + m2 + m3] ˙q2
1

−[m1 + m2 + m3]gq1 .
So we have
∂L
∂˙q1
= [m1 + m2 + m3] ˙q1
d
dt
 ∂L
∂˙q1

= [m1 + m2 + m3]¨q1
∂L
∂˙q2
= [m1 + m2] ˙q2
d
dt
 ∂L
∂˙q2

= [m1 + m2]¨q2
∂L
∂˙q3
= m1 ˙q3
d
dt
 ∂L
∂˙q3

= m1¨q3
∂L
∂q2
= ∂L
∂q3
= 0
∂L
∂q1
= −[m1 + m2 + m3]g.
The dynamic equations that model this robot may be obtained by
applying the Lagrange’s equations (3.4) to obtain

3.2 Dynamic Model in Compact Form
71
[m1 + m2 + m3]¨q1 + [m1 + m2 + m3]g = τ1
(3.12)
[m1 + m2]¨q2 = τ2
(3.13)
m1¨q3 = τ3
(3.14)
where τ1, τ2 and τ3 are the external forces applied at each joint. Notice
that in this example Equations (3.12)–(3.14) deﬁne a set of linear
autonomous diﬀerential equations.
In terms of the state vector [q1 q2 q3
˙q1
˙q2
˙q3] , the equations
(3.12), (3.13) and (3.14) may be expressed as
d
dt
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
q1
q2
q3
˙q1
˙q2
˙q3
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
˙q1
˙q2
˙q3
1
m1 + m2 + m3
[τ1 −[m1 + m2 + m3]g]
1
m1 + m2
τ2
1
m1
τ3
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
The necessary and suﬃcient condition for the existence of equilib-
ria is τ1 = [m1 + m2 + m3]g, τ2 = 0 and τ3 = 0 and actually we have
an inﬁnite number of them:
[q1 q2 q3
˙q1
˙q2
˙q3]T = [q∗
1 q∗
2 q∗
3 0 0 0]T
with q∗
1, q∗
2, q∗
3 ∈IR.
♦
3.2 Dynamic Model in Compact Form
In the previous section we presented some examples to illustrate the applica-
tion of Lagrange’s equations to obtain the dynamic equations for robots with
particular geometries. This same methodology, however, may be employed in
general to obtain the dynamic model of any robot of n DOF.
This methodology is commonly studied in classical texts on robotics and
theoretical mechanics and therefore, we present it here only in compact form.
The interested reader is invited to see the cited texts at the end of the chapter.
Consider a robot manipulator of n DOF composed of rigid links intercon-
nected by frictionless joints. The kinetic energy function K(q, ˙q) associated
with such an articulated mechanism may always be expressed as

72
3 Robot Dynamics
K(q, ˙q) = 1
2 ˙qTM(q) ˙q
(3.15)
where M(q) is a matrix of dimension n×n referred to as the inertia matrix.
M(q) is symmetric and positive deﬁnite for all q ∈IRn. The potential energy
U(q) does not have a speciﬁc form as in the case of the kinetic energy but it
is known that it depends on the vector of joint positions q.
The Lagrangian L(q, ˙q), given by Equation (3.3), becomes in this case
L(q, ˙q) = 1
2 ˙qTM(q) ˙q −U(q) .
With this Lagrangian, the Lagrange’s equations of motion (3.4) may be
written as
d
dt
 ∂
∂˙q
1
2 ˙qTM(q) ˙q

−∂
∂q
1
2 ˙qTM(q) ˙q

+ ∂U(q)
∂q
= τ .
On the other hand, it holds that
∂
∂˙q
1
2 ˙qTM(q) ˙q

= M(q) ˙q
(3.16)
d
dt
 ∂
∂˙q
1
2 ˙qTM(q) ˙q

= M(q)¨q + ˙M(q) ˙q.
(3.17)
Considering these expressions, the equation of motion takes the form
M(q)¨q + ˙M(q) ˙q −1
2
∂
∂q
 ˙qTM(q) ˙q

+ ∂U(q)
∂q
= τ,
or, in compact form,
M(q)¨q + C(q, ˙q) ˙q + g(q) = τ
(3.18)
where
C(q, ˙q) ˙q = ˙M(q) ˙q −1
2
∂
∂q
 ˙qTM(q) ˙q

(3.19)
g(q) = ∂U(q)
∂q
.
(3.20)
Equation (3.18) is the dynamic equation for robots of n DOF. Notice that
(3.18) is a nonlinear vectorial diﬀerential equation of the state [qT
˙qT ]T .
C(q, ˙q) ˙q is a vector of dimension n called the vector of centrifugal and
Coriolis forces, g(q) is a vector of dimension n of gravitational forces or
torques
and τ is a vector of dimension n called the vector of external

3.2 Dynamic Model in Compact Form
73
forces, which in general corresponds to the torques and forces applied by the
actuators at the joints.
The matrix C(q, ˙q) ∈IRn×n, called the centrifugal and Coriolis forces
matrix may be not unique, but the vector C(q, ˙q) ˙q is indeed unique. One way
to obtain C(q, ˙q) is through the coeﬃcients or so-called Christoﬀel symbols
of the ﬁrst kind, cijk(q), deﬁned as
cijk(q) = 1
2
∂Mkj(q)
∂qi
+ ∂Mki(q)
∂qj
−∂Mij(q)
∂qk

.
(3.21)
Here, Mij(q) denotes the ijth element of the inertia matrix M(q). Indeed, the
kjth element of the matrix C(q, ˙q), Ckj(q, ˙q), is given by (we do not show here
the development of the calculations to obtain such expressions, the interested
reader is invited to see the texts cited at the end of the chapter)
Ckj(q, ˙q) =
⎡
⎢⎢⎢⎣
c1jk(q)
c2jk(q)
...
cnjk(q)
⎤
⎥⎥⎥⎦
T
˙q .
(3.22)
The model (3.18) may be viewed as a dynamic system with input, the
vector τ, and with outputs, the vectors q and ˙q. This is illustrated in Figure
3.6.
ROBOT
-
-
-
˙  
Figure 3.6. Input–output representation of a robot
Each element of M(q), C(q, ˙q) and g(q) is in general, a relatively complex
expression of the positions and velocities of all the joints, that is, of q and ˙q.
The elements of M(q), C(q, ˙q) and g(q) depend of course, on the geometry of
the robot in question. Notice that computation of the vector g(q) for a given
robot may be carried out with relative ease since this is given by (3.20). In
other words, the vector of gravitational torques g(q), is simply the gradient
of the potential energy function U(q).
Example 3.5. The dynamic model of the robot from Example 3.2, that
is, Equation (3.5), may be written in the generic form (3.18) by taking
M(q) = m2l2
2 cos2(ϕ) ,

74
3 Robot Dynamics
C(q, ˙q) = 0 ,
g(q) = 0 .
♦
Example 3.6. The Lagrangian dynamic model of the robot manipula-
tor shown in Figure 3.4 was derived in Example 3.3. A simple inspec-
tion of Equations (3.8) and (3.9) shows that the dynamic model for
this robot in compact form is

M11(q)
M12(q)
M21(q)
M22(q)

"
#$
%
M(q)
¨q +

C11(q, ˙q)
C12(q, ˙q)
C21(q, ˙q)
C22(q, ˙q)

"
#$
%
C(q, ˙q)
˙q = τ(t)
where
M11(q) =

m1l2
c1 + m2l2
1 + I1

M12(q) = [m2l1lc2 cos(δ)C21 + m2l1lc2 sin(δ)S21]
M21(q) = [m2l1lc2 cos(δ)C21 + m2l1lc2 sin(δ)S21]
M22(q) = [m2l2
c2 + I2]
C11(q, ˙q) = 0
C12(q, ˙q) = [−m2l1lc2 cos(δ)S21 + m2l1lc2 sin(δ)C21] ˙q2
C21(q, ˙q) = [m2l1lc2 cos(δ)S21 −m2l1lc2 sin(δ)C21] ˙q1
C22(q, ˙q) = 0
That is, the gravitational forces vector is zero.
♦
The dynamic model in compact form is important because it is the model
that we use throughout the text to design controllers and to analyze the
stability, in the sense of Lyapunov, of the equilibria of the closed-loop system.
In anticipation of the material in later chapters of this text and in support of
the material of Chapter 2 it is convenient to make some remarks at this point
about the “stability of the robot system”.
In the previous examples we have seen that the model in compact form
may be rewritten in the state-space form. As a matter of fact, this property is
not limited to particular examples but stands as a fact for robot manipulators
in general. This is because the inertia matrix is positive deﬁnite and so is the
matrix M(q)−1; in particular, the latter always exists. This is what allows us
to express the dynamic model (3.18) of any robot of n DOF in terms of the
state vector [qT
˙qT ]T that is, as

3.3 Dynamic Model of Robots with Friction
75
d
dt
⎡
⎣
q
˙q
⎤
⎦=
⎡
⎣
˙q
M(q)−1 [τ(t) −C(q, ˙q) ˙q −g(q)]
⎤
⎦.
(3.23)
Note that this constitutes a set of nonlinear diﬀerential equations of the
form (3.1). In view of this nonlinear nature, the concept of stability of a robot
in open loop must be handled with care.
We emphasize that the deﬁnition of stability in the sense of Lyapunov,
which is presented in Deﬁnition 2.2 in Chapter 2, applies to an equilibrium
(typically the origin). Hence, in studying the “stability of a robot manipula-
tor” it is indispensable to ﬁrst determine the equilibria of Equation (3.23),
which describes the behavior of the robot.
The necessary and suﬃcient condition for the existence of equilibria of
Equation (3.23), is that τ(t) be constant (say, τ ∗) and that there exist a
solution q∗∈IRn to the algebraic possibly nonlinear equation, in g(q∗) = τ ∗.
In such a situation, the equilibria are given by [qT
˙qT ]T = [q∗T 0T ]T ∈IR2n.
In the particular case of τ ≡0, the possible equilibria of (3.23) are given
by [qT
˙qT ]T = [q∗T
0T ]T where q∗is a solution of g(q∗) = 0. Given the
deﬁnition of g(q) as the gradient of the potential energy U(q), we see that q∗
corresponds to the vectors where the potential energy possesses extrema.
A particular case is that of robots whose workspace corresponds to the
horizontal plane. In this case, g(q) = 0 and therefore it is necessary and
suﬃcient that τ(t) = 0 for equilibria to exist. Indeed, the point

qT
˙qT T =
[q∗T
0T ]T ∈IR2n where q∗is any vector of dimension n is an equilibrium.
This means that there exist an inﬁnite number of equilibria. See also Example
2.2.
The development above makes it clear that if one wants to study the topic
of robot stability in open loop (that is, without control) one must specify the
dynamic model as well as the conditions for equilibria to exist and only then,
select one among these equilibria, whose stability is of interest. Consequently,
the question “is the robot stable? ” is ambiguous in the present context.
3.3 Dynamic Model of Robots with Friction
It is important to notice that the generic Equation (3.18) supposes that the
links are rigid, that is, they do not present any torsion or any other defor-
mation phenomena. On the other hand, we also considered that the joints
between each pair of links are stiﬀand frictionless. The incorporation of these
phenomena in the dynamic model of robots is presented in this and the fol-
lowing section.
Friction eﬀects in mechanical systems are phenomena that depend on mul-
tiple factors such as the nature of the materials in contact, lubrication of the

76
3 Robot Dynamics
latter, temperature, etc. For this reason, typically only approximate models of
friction forces and torques are available. Yet, it is accepted that these forces
and torques depend on the relative velocity between the bodies in contact.
Thus, we distinguish two families of friction models: the static models, in
which the friction force or torque depends on the instantaneous relative ve-
locity between bodies and, dynamic models, which depend on the past values
of the relative velocity.
Thus, in the static models, friction is modeled by a vector f( ˙q) ∈IRn that
depends only on the joint velocity ˙q. Friction eﬀects are local, that is, f( ˙q)
may be written as
f( ˙q) =
⎡
⎢⎢⎢⎢⎢⎣
f1( ˙q1)
f2( ˙q2)
...
fn( ˙qn)
⎤
⎥⎥⎥⎥⎥⎦
.
An important feature of friction forces is that they dissipate energy, that
is,
˙qT f( ˙q) > 0
∀˙q ̸= 0 ∈IRn .
A “classical” static friction model is one that combines the so-called viscous
and Coulomb friction phenomena. This model establishes that the vector f( ˙q)
is given by
f( ˙q) = Fm1 ˙q + Fm2 sign( ˙q)
(3.24)
where Fm1 and Fm2 are n×n diagonal positive deﬁnite matrices. The elements
of the diagonal of Fm1 correspond to the viscous friction parameters while the
elements of Fm2 correspond to the Coulomb friction parameters. Furthermore,
in the model given by (3.24)
sign( ˙q) =
⎡
⎢⎢⎢⎣
sign( ˙q1)
sign( ˙q2)
...
sign( ˙qn)
⎤
⎥⎥⎥⎦
and sign(x) is the sign “function”, given by
sign(x) =

1 if x > 0
−1 if x < 0 .
However, sign(0) is undeﬁned in the sense that one do not associate a partic-
ular real number to the “function” sign(x) when x = 0.
In certain applications, this fact is not of much practical relevance, as for
instance, in velocity regulation, – when it is desired to maintain an operating
point involving high and medium-high constant velocity, but the deﬁnition of

3.4 Dynamic Model of Elastic-joint Robots
77
sign(0) is crucial both from theoretical and practical viewpoints, in position
control (i.e. when the control objective is to maintain a constant position).
For this reason, and in view of the fact that the “classical” model (3.24)
describes inadequately the behavior of friction at very low velocities, that is,
when bodies are at rest and start to move, this is not recommended to model
friction when dealing with the position control problem (regulation). In this
case it is advisable to use available dynamic models. The study of such models
is beyond the scope of this textbook.
Considering friction in the joints, the general dynamic equation of the
manipulator is now given by
M(q)¨q + C(q, ˙q) ˙q + g(q) + f( ˙q) = τ .
(3.25)
In general, in this text we shall not assume that friction is present in the
dynamic model unless it is explicitly mentioned. In such a case, we consider
only viscous friction.
3.4 Dynamic Model of Elastic-joint Robots
In many industrial robots, the motion produced by the actuators is transmit-
ted to the links via gears and belts. These, are not completely stiﬀbut they
have elasticity which can be compared to that of a spring. In the case of revo-
lute joints, where the actuators are generally electric motors these phenomena
boil down to a torsion in the axis that connects the link to the rotor of the
motor. The elasticity eﬀect in the joints is more noticeable in robots which
undergo displacements with abrupt changes in velocity. A direct consequence
of this eﬀect, is the degradation of precision in the desired motion of the robot.
Evidently, industrial robots are designed in a way to favor the reduction of
joint elasticity, however, as mentioned above, such an eﬀect is always present
to some degree on practically any mechanical device. An exception to this
rule is the case of the so-called direct-drive robots, in which the actuators are
directly connected to the links.
Robot dynamics and control under the consideration of joint elasticity, has
been an important topic of research since the mid-1980s and continues today.
We present below only a brief discussion.
Consider a robot manipulator composed of rigid n links connected through
revolute joints. Assume that the motion of each link is furnished by electric
motors and transmitted via a set of gears. Denote by Ji, the moment of inertia
of the rotors about their respective rotating axes. Let ri be the gear reduction
ratio of each rotor; e.g. if r = 50 we say that for every 50 rotor revolutions, the
axis after the corresponding gear undergoes only one full turn. Joint elasticity
between each link and the corresponding axis after the set of gears is modeled
via a torsional spring of constant torsional ‘stiﬀness’, ki. The larger ki, the

78
3 Robot Dynamics
stiﬀer the joint. Figure 3.7 illustrates the case of a robot with two joints.
The joint positions of each link are denoted, as usual by q while the angular
positions of the axes after the set of gears are θ = [θ1
θ2 · · · θn]T . Due to
the elasticity, and while the robot is in motion we have, in general, q ̸= θ.
q2
k2
r2 : 1
q1
k1
r1 : 1
τ2
θ2
θ1
τ1
Figure 3.7. Diagram of a robot with elastic joints
Typically, the position and velocity sensors are located at the level of the
rotors’ axes. Thus knowing the gears reduction rate, only θ may be determined
and in particular, q is not available. This observation is of special relevance in
control design since the variable to be controlled is precisely q, which cannot
be measured directly unless one is able to collocate appropriate sensors to
measure the links’ positions, giving a higher manufacturing cost.
Due to elasticity a given robot having n links has 2n DOF. Its generalized
coordinates are [qT θT ]T . The kinetic energy function of a robot with elastic
joints corresponds basically to the sum of the kinetic energies of the links and

3.4 Dynamic Model of Elastic-joint Robots
79
those of the rotors,4 that is,
K(q, ˙q, ˙θ) = 1
2 ˙qTM(q) ˙q + 1
2
˙θ
TJ ˙θ
where M(q) is the inertia matrix of the “rigid” (that is, assuming an inﬁnite
stiﬀness value of ki for all i) robot, and J is a diagonal positive deﬁnite
matrix, whose elements are the moments of inertia of the rotors, multiplied
by the square of the gear reduction ratio, i.e.
J =
⎡
⎢⎢⎣
J1r2
1
0
· · ·
0
0
J2r2
2
· · ·
0
...
...
...
...
0
0
· · ·
Jnr2
n
⎤
⎥⎥⎦.
On the other hand, the potential energy is the sum of the gravitational
energy plus that stored in the torsional ﬁctitious springs5, i.e.
U(q, θ) = U1(q) + 1
2[q −θ]TK[q −θ]
(3.26)
where U1(q) is the potential energy due to gravity and corresponds exactly
to that of the robot as if the joints were absolutely stiﬀ. The matrix K is
diagonal positive deﬁnite and its elements are the ‘torsion constants’, i.e.
K =
⎡
⎢⎢⎣
k1
0
· · ·
0
0
k2
· · ·
0
...
...
...
...
0
0
· · ·
kn
⎤
⎥⎥⎦.
The Lagrangian is in this case
L(q, θ, ˙q, ˙θ) = 1
2 ˙qTM(q) ˙q + 1
2
˙θ
TJ ˙θ −U1(q) −1
2[q −θ]TK[q −θ] .
Hence, using Lagrange’s motion equations (3.4) we obtain
d
dt
⎡
⎢⎢⎢⎢⎣
∂
∂˙q
1
2 ˙qT M(q) ˙q

∂
∂˙θ
1
2
˙θ
T J ˙θ

⎤
⎥⎥⎥⎥⎦
−
⎡
⎢⎢⎢⎢⎣
∂
∂q
1
2 ˙qT M(q) ˙q −U1(q) −1
2[q −θ]T K[q −θ]

∂
∂θ

−1
2[q −θ]T K[q −θ]

⎤
⎥⎥⎥⎥⎦
=

0
τ

.
4 Here, we neglect the gyroscopic and other coupling eﬀects between the rotors and
the links.
5 We assume here that the rotors constitute uniform cylinders so that they do not
contribute to the total potential energy. Therefore, in (3.26) there is no term
‘ U2( ) ’.

80
3 Robot Dynamics
Finally, using (3.16), (3.17), (3.19) and
∂
∂θ

−1
2[q −θ]TK[q −θ]

= K[q −θ] ,
we obtain the dynamic model for elastic-joint robots as
M(q)¨q + C(q, ˙q) ˙q + g(q) + K(q −θ) = 0
(3.27)
J¨θ −K[q −θ] = τ .
(3.28)
The model above may, in turn, be written in the standard form, that is
through the state vector [qT
θT
˙qT
˙θ
T ]T as
d
dt
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
q
θ
˙q
˙θ
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
˙q
˙θ
M −1(q) [−K[q −θ] −C(q, ˙q) ˙q −g(q)]
J−1 [τ + K[q −θ]]
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
.
Example 3.7. Consider the device shown in Figure 3.8, which consists
of one rigid link of mass m, and whose center of mass is localized
at a distance l from the rotation axis. The moment of inertia of the
link with respect to the axis that passes through its center of mass is
denoted by I. The joint is elastic and has a torsional constant k. The
rotor’s inertia is denoted by J .
The dynamic model of this device may be computed noticing that
K( ˙q, ˙θ) = 1
2[ml2 + I] ˙q2 + 1
2Jr2 ˙θ2
U(q, θ) = mgl[1 −cos(q)] + 1
2k[q −θ]2,
which, using Lagrange’s equations (3.4), leads to
[ml2 + I]¨q + mgl sin(q) + k[q −θ] = 0 ,
Jr2¨θ −k[q −θ] = τ .
♦

3.4 Dynamic Model of Elastic-joint Robots
81
τ
J
r : 1
θ
l
m
I,
q
k
Figure 3.8. Link with an elastic joint
Unless clearly stated otherwise, in this text we consider only robots with
stiﬀjoints i.e. the model that we use throughout this textbook is given by
(3.18).
v1
v2
q1
q2
Figure 3.9. Example of a 2-DOF robot

82
3 Robot Dynamics
v1
q1
v2
q2
Figure 3.10. Example of a 2-DOF robot
3.5 Dynamic Model of Robots with Actuators
On a real robot manipulator the torques vector τ, is delivered by actuators
that are typically electromechanical, pneumatic or hydraulic. Such actuators
have their own dynamics, that is, the torque or force delivered is the product
of a dynamic ‘transformation’ of the input to the actuator. This input may
be a voltage or a current in the case of electromechanical actuators, ﬂuid
(typically oil) ﬂux or pressure in the case of hydraulic actuators. In Figures
3.9 and 3.10 we illustrate two robotic arms with 2 DOF which have actuators
transmitting the motion through gears in the ﬁrst case, and through gear and
belt in the second.
Actuators with Linear Dynamics
In certain situations, some types of electromechanical actuators may be mod-
eled via second-order linear diﬀerential equations.
A common case is that of direct-current (DC) motors. The dynamic model
which relates the input voltage v applied to the motor’s armature, to the out-
put torque τ delivered by the motor, is presented in some detail in Appendix

3.5 Dynamic Model of Robots with Actuators
83
D. A simpliﬁed linear dynamic model of a DC motor with negligible armature
inductance, as shown in Figure 3.11, is given by Equation (D.16) in Appendix
D,
Jm¨q + fm ˙q + KaKb
Ra
˙q + τ
r2 = Ka
rRa
v
(3.29)
where:
•
Jm : rotor inertia [kg m2],
•
Ka : motor-torque constant [N m/A],
•
Ra : armature resistance [Ω],
•
Kb : back emf [V s/rad],
•
fm : rotor friction coeﬃcient with respect to its hinges [N m],
•
τ : net applied torque after the set of gears at the load axis [N m],
•
q : angular position of the load axis [rad],
•
r : gear reduction ratio (in general r ≫1),
•
v : armature voltage [V].
Equation (3.29) relates the voltage v applied to the armature of the motor
to the torque τ applied to the load, in terms of its angular position, velocity
and acceleration.
Ka, Kb, Ra
v
Jm
fm
1 : r
q
τ
Figure 3.11. Diagram of a DC motor
Considering that each of the n joints is driven by a DC motor we obtain
from Equation (3.29)
J¨q + B ˙q + Rτ = Kv
(3.30)
with
J = diag {Jmi}
B = diag

fmi +
KaKb
Ra

i
&

84
3 Robot Dynamics
R = diag
 1
r2
i
&
(3.31)
K = diag
Ka
Ra

i
1
ri
&
where for each motor (i = 1, · · · , n), Jmi corresponds to the rotor inertia, fmi
to the damping coeﬃcient, (KaKb/Ra)i to an electromechanical constant and
ri to the gear reduction ratio.
Thus, the complete dynamic model of a manipulator (considering friction
in the joints) and having its actuators located at the joints6 is obtained by
substituting τ from (3.30) in (3.25),
(R M(q) + J) ¨q + R C(q, ˙q) ˙q + R g(q) + R f( ˙q) + B ˙q = Kv .
(3.32)
The equation above may be considered as a dynamic system whose input
is v and whose outputs are q and ˙q. A block-diagram for the model of the
manipulator with actuators, given by (3.32), is depicted in Figure 3.12.
˙q
q
τ
v
¨q
ACTUATORS
ROBOT
Figure 3.12. Block-diagram of a robot with its actuators
Example 3.8. Consider the pendulum depicted in Figure 3.13. The de-
vice consists of a DC motor coupled mechanically through a set of
gears, to a pendular arm moving on a vertical plane under the action
of gravity.
The equation of motion for this device including its load is given
by

J + ml2
¨q + fL ˙q + [mblb + ml] g sin(q) = τ
where:
•
J : arm inertia without load (i.e. with m = 0), with respect to the
axis of rotation;
•
mb : arm mass (without load);
6 Again, we neglect the gyroscopic and other coupling eﬀects between the rotors
and the links.

3.5 Dynamic Model of Robots with Actuators
85
v
Ka, Kb, Ra
Jm
fm
1 : r
fL
lb
l
mb, J
m
q
Figure 3.13. Pendular device with a DC motor
•
lb : distance from the rotating axis to the arm center of mass
(without load);
•
m : load mass at the tip of the arm (assumed to be punctual7);
•
l : distance from the rotating axis to the load m;
•
g : gravity acceleration;
•
τ : applied torque at the rotating axis;
•
fL : friction coeﬃcient of the arm and its load.
The equation above may also be written in the compact form
JL¨q + fL ˙q + kL sin(q) = τ
where
JL = J + ml2
kL = [mblb + ml]g .
Hence, the complete dynamic model of the pendular device may
be obtained by substituting τ from the model of the DC motor, (3.29),
in the equation of the pendular arm, i.e.

Jm + JL
r2

¨q +

fm + fL
r2 + KaKb
Ra

˙q + kL
r2 sin(q) = Ka
rRa
v ,
from which, by simple inspection, comparing to (3.32), we identify
7 That is, it is all concentrated at a point – the center of mass – and has no “size”
or shape.

86
3 Robot Dynamics
M(q) = JL
R = 1
r2
B = fm + KaKb
Ra
C(q, ˙q) = 0
J = Jm
K = Ka
rRa
f( ˙q) = fL ˙q
g(q) = kL sin(q) .
♦
The robot-with-actuators Equation (3.32) may be simpliﬁed considerably
when the gear ratios ri are suﬃciently large. In such case (ri ≫1), we have
R ≈0 and Equation (3.32) may be approximated by
J¨q + B ˙q ≈Kv .
That is, the nonlinear dynamics (3.25) of the robot may be neglected. This can
be explained in the following way. If the gear reduction ratio is large enough,
then the associated dynamics of the robot-with-actuators is described only
by the dynamics of the actuators. This is the main argument that supports
the idea that a good controller for the actuators is also appropriate to control
robots having such actuators and geared transmissions with a high reduction
ratio.
It is important to remark that the parameters involved in Equation (3.30)
depend exclusively on the actuators, and not on the manipulator nor on its
load. Therefore, it is reasonable to assume that such parameters are constant
and known.
Since the gear ratio ri is assumed to be nonzero, the matrix R given by
(3.31) is nonsingular and therefore, R−1 exists and Equation (3.32) may be
rewritten as
M ′(q)¨q + C(q, ˙q) ˙q + g(q) + f( ˙q) + R−1B ˙q = R−1Kv
(3.33)
where M ′(q) = M(q) + R−1J .
The existence of the matrix M ′(q)−1 allows us to express the model (3.33)
in terms of the state vector [q
˙q] as
d
dt
⎡
⎣
q
˙q
⎤
⎦=
⎡
⎣
˙q
M ′(q)−1 
R−1 Kv −R−1 B ˙q −C(q, ˙q) ˙q −g(q) −f( ˙q)

⎤
⎦.
That is, the input torque becomes simply a voltage scaled by R−1K. At
this point and in view of the scope of this textbook we may already formulate
the problem of motion control for the system above, under the conditions

3.5 Dynamic Model of Robots with Actuators
87
previously stated. Given a set of bounded vectors qd, ˙qd and ¨qd, determine a
vector of voltages v, to be applied to the motors, in such a manner that the
positions q, associated to the joint positions of the robot, follow precisely qd .
This is the main subject of study in the succeeding chapters.
Actuators with Nonlinear Dynamics
A dynamic model that characterizes a wide variety of actuators is described
by the equations
˙x = m(q, ˙q, x) + G(q, ˙q, x)u
(3.34)
τ = l(q, x)
(3.35)
where u ∈IRn and x ∈IRn are the input vectors and the state variables
corresponding to the actuator and m, G and l are nonlinear functions. In
the case of DC motors, the input vector u, represents the vector of voltages
applied to each of the n motors. The state vector x represents, for instance,
the armature current in a DC motor or the operating pressure in a hydraulic
actuator. Since the torques τ are, generally speaking, delivered by diﬀerent
kinds of actuators, the vector m(q, ˙q, x) and the matrix G(q, ˙q, x) are such
that the ∂l(q, x)/∂xT and G(q, ˙q, x) are diagonal nonsingular matrices.
For the sake of illustration, consider the model of a DC motor with a non-
negligible armature inductance (La ̸≈0) as described in Appendix D, that
is,
v = La
dia
dt + Raia + Kbr ˙q
τ = rKaia
where v is the input (armature voltage), ia is the direct armature current and
τ is the torque applied to the load, after the set of gears. The rest of the
constants are deﬁned in Appendix D. These equations may be written in the
generic form (3.34) and (3.35),
d
x
$%"#
ia
dt
=
m(q, ˙q, x)
$
%"
#
−L−1
a
[Raia + Kbr ˙q] +
G(q, ˙q, x)
$%"#
L−1
a
u
$%"#
v
τ = rKaia
" #$ %
l(q, x)
.
Considering that the actuators’ models are given by (3.34) and (3.35), the
model of the robot with such actuators may be written in terms of the state
vector [q
˙q x], as

88
3 Robot Dynamics
d
dt
⎡
⎢⎢⎢⎣
q
˙q
x
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
˙q
M(q)−1 [l(q, x) −C(q, ˙q) ˙q −g(q)]
m(q, ˙q, x)
⎤
⎥⎥⎥⎦+
⎡
⎢⎢⎢⎣
0
0
G(q, ˙q, x)
⎤
⎥⎥⎥⎦u .
The dynamics of the actuators must be taken into account in the model
of a robot, whenever these dynamics are not negligible with respect to that of
the robot. Speciﬁcally for robots which are intended to perform high precision
tasks.
Bibliography
Further facts and detailed developments on the kinematic and dynamic models
of robot manipulators may be consulted in the following texts:
•
Paul R., 1982, “Robot manipulators: Mathematics, programming and con-
trol”, The MIT Press, Cambridge, MA.
•
Asada H., Slotine J. J., 1986, “Robot analysis and control”, Wiley, New
York.
•
Fu K., Gonzalez R., Lee C., 1987, “Robotics: control, sensing, vision, and
intelligence”, McGraw-Hill.
•
Craig J., 1989, “Introduction to robotics: Mechanics and control”, Addison-
Wesley, Reading, MA.
•
Spong M., Vidyasagar M., 1989, “Robot dynamics and control”, Wiley,
New York.
•
Yoshikawa T., 1990, “Foundations of robotics: Analysis and control”, The
MIT Press.
The method of assigning the axis zi as the rotation axis of the ith joint
(for revolute joints) or as an axis parallel to the axis of translation at the ith
joint (for prismatic joints) is taken from
•
Craig J., 1989, “Introduction to robotics: Mechanics and control”, Addison-
Wesley, Reading, MA.
•
Yoshikawa T., 1990, “Foundations of robotics: Analysis and control”, The
MIT Press.
It is worth mentioning that the notation above does not correspond to that of
the so-called Denavit–Hartenberg convention, which may be familiar to some
readers, but it is intuitively simpler and has several advantages.
Solution techniques to the inverse kinematics problem are detailed in

Bibliography
89
•
Chiaverini S., Siciliano B., Egeland O., 1994, “Review of the damped least–
square inverse kinematics with experiments on a industrial robot manipu-
lator”, IEEE Transactions on Control Systems Technology, Vol. 2, No. 2,
June, pp. 123–134.
•
Mayorga R. V., Wong A. K., Milano N., 1992, “A fast procedure for ma-
nipulator inverse kinematics evaluation and pseudo-inverse robustness”,
IEEE Transactions on Systems, Man, and Cybernetics, Vol. 22, No. 4,
July/August, pp. 790–798.
Lagrange’s equations of motion are presented in some detail in the above-
cited texts and also in
•
Hauser W., 1966, “Introduction to the principles of mechanics”, Addison-
Wesley, Reading MA.
•
Goldstein H., 1974, “Classical mechanics”, Addison-Wesley, Reading MA.
A particularly simple derivation of the dynamic equations for n-DOF
robots via Lagrange’s equations is presented in the text by Spong and
Vidyasagar (1989) previously cited.
The derivation of the dynamic model of elastic-joint robots may also be
studied in the text by Spong and Vidyasagar (1989) and in
•
Burkov I. V., Zaremba A. T., 1987, “Dynamics of elastic manipulators with
electric drives”, Izv. Akad. Nauk SSSR Mekh. Tverd. Tela, Vol. 22, No. 1,
pp. 57–64. English translation in Mechanics of Solids, Allerton Press.
•
Marino R., Nicosia S., 1985, “On the feedback control of industrial robots
with elastic joints: a singular perturbation approach”, 1st IFAC Symp.
Robot Control, pp. 11–16, Barcelona, Spain.
•
Spong M., 1987, “Modeling and control of elastic joint robots”, ASME
Journal of Dynamic Systems, Measurement and Control, Vol. 109, De-
cember.
The topic of electromechanical actuator modeling and its consideration in
the dynamics of manipulators is treated in the text by Spong and Vidyasagar
(1989) and also in
•
Luh J., 1983, “Conventional controller design for industrial robots–A tuto-
rial”, IEEE Transactions on Systems, Man and Cybernetics, Vol. SMC-13,
No. 3, June, pp. 298–316.
•
Tourassis V., 1988, “Principles and design of model-based robot con-
trollers”, International Journal of Control, Vol. 47, No. 5, pp. 1267–1275.
•
Yoshikawa T., 1990, “Foundations of robotics. Analysis and control”, The
MIT Press.

90
3 Robot Dynamics
•
Tarn T. J., Bejczy A. K., Yun X., Li Z., 1991, “Eﬀect of motor dynamics
on nonlinear feedback robot arm control”, IEEE Transactions on Robotics
and Automation, Vol. 7, No. 1, February, pp. 114–122.
Problems
1. Consider the mechanical device analyzed in Example 3.2. Assume now
that this device has friction on the axis of rotation, which is modeled here
as a torque or force proportional to the velocity (f > 0 is the friction
coeﬃcient). The dynamic model in this case is
m2l2
2cos2(ϕ)¨q + f ˙q = τ .
Rewrite the model in the form ˙x = f(t, x) with x = [q
˙q]T .
a) Determine the conditions on the applied torque τ for the existence of
equilibrium points.
b) Considering the condition on τ of the previous item, show by using
Theorem 2.2 (see page 44), that the origin [q
˙q]T = [0 0]T is a stable
equilibrium.
Hint: Use the following Lyapunov function candidate
V (q, ˙q) = 1
2

q + m2l2
2cos2(ϕ)
f
˙q
2
+ 1
2 ˙q2 .
2. Consider the mechanical device depicted in Figure 3.14.
A simplistic model of such a device is
m¨q + f ˙q + kq + mg = τ,
q(0), ˙q(0) ∈IR
where
•
m > 0 is the mass
•
f > 0 is the friction coeﬃcient
•
k > 0 is the stiﬀness coeﬃcient of the spring
•
g is the acceleration of gravity
•
τ is the applied force
•
q is the vertical position of the mass m with respect to origin of the
plane x–y.
Write the model in the form ˙x = f(t, x) where x = [q
˙q]T .
a) What restrictions must be imposed on τ so that there exist equilibria?
b) Is it possible to determine τ so that the only equilibrium is the origin,
x = 0 ∈IR2 ?

Problems
91
y
x
k
q
f
m
Figure 3.14. Problem 2
l1
x0
z0
y0
q1
m1
zo2
y0
l2
m2
q1
q2
q2
x0
z0
yo2
Figure 3.15. Problems 3 and 4
3. Consider the mechanical arm shown in Figure 3.15.
Assume that the potential energy U(q1, q2) is zero when q1 = q2 = 0.
Determine the vector of gravitational torques g(q),
g(q) =

g1(q1, q2)
g2(q1, q2)

.
4. Consider again this mechanical device but with its simpliﬁed description
as depicted in Figure 3.15.
a) Obtain the direct kinematics model of the device, i.e. determine the
relations
y02 = f1(q1, q2)
z02 = f2(q1, q2) .

92
3 Robot Dynamics
b) The analytical Jacobian J(q) of a robot is the matrix
J(q) = ∂
∂q ϕ(q) =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
∂
∂q1 ϕ1(q)
∂
∂q2 ϕ1(q) · · ·
∂
∂qn ϕ1(q)
∂
∂q1 ϕ2(q)
∂
∂q2 ϕ2(q) · · ·
∂
∂qn ϕ2(q)
...
...
...
...
∂
∂q1 ϕm(q)
∂
∂q2 ϕm(q) · · ·
∂
∂qn ϕm(q)
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
where ϕ(q) is the relation in the direct kinematics model (x = ϕ(q)),
n is the dimension of q and m is the dimension of x. Determine the
Jacobian.
5. Consider the 2-DOF robot shown in Figure 3.16, for which the meaning
of the constants and variables involved is as follows:
  

τ2
δ
q2
l1
lc1
q1
I1, m1
m2
y
z
x
τ1
Figure 3.16. Problem 5
•
m1, m2 are the masses of links 1 and 2 respectively;
•
I1 is the moment of inertia of link 1 with respect to the axis parallel
to the axis x which passes through its center of mass; the moment of
inertia of the second link is supposed negligible;
•
l1 is the length of link 1;
•
lc1 is the distance to the center of mass of link 1 taken from its rotation
axis;
•
q1 is the angular position of link 1 measured with respect to the hori-
zontal (taken positive counterclockwise);

Problems
93
•
q2 is the linear position of the center of mass of link 2 measured from
the edge of link 1;
•
δ is negligible (δ = 0).
Determine the dynamic model and write it in the form ˙x = f(t, x) where
x = [q
˙q]T .
6. Consider the 2-DOF robot depicted in Figure 3.17. Such a robot has a
transmission composed of a set of bar linkage at its second joint. Assume
that the mass of the lever of length l4 associated with actuator 2 is negli-
gible.
l1
lc2
I3
l4
I2, m2
q2
q1
l1
l4
z
y
lc1
I1, m1
lc3
x
m3
link 1
actuator 1
actuator 2
link 1
Figure 3.17. Problem 6
Determine the dynamic model. Speciﬁcally, obtain the inertia matrix
M(q) and the centrifugal and Coriolis matrix C(q, ˙q).
Hint: See the robot presented in Example 3.3. Both robots happen to be
mechanically equivalent when taking m3 = I3 = δ = 0 .

4
Properties of the Dynamic Model
In this chapter we present some simple but fundamental properties of the
dynamic model for n-DOF robots given by Equation (3.18), i.e.
M(q)¨q + C(q, ˙q) ˙q + g(q) = τ .
(4.1)
In spite of the complexity of the dynamic Equation (4.1), which describes
the behavior of robot manipulators, this equation and the terms which consti-
tute it have properties that are interesting in themselves for control purposes.
Besides, such properties are of particular importance in the study of control
systems for robot manipulators. Only properties that are relevant to control
design and stability analysis via Lyapunov’s direct method (see Section 2.3.4
in Chapter 2) are presented. The reader is invited to see the references at the
end of the chapter to prove further.
These properties, which we use extensively in the sequel, may be classiﬁed
as follows:
•
properties of the inertia matrix M(q);
•
properties of the centrifugal and Coriolis forces matrix C(q, ˙q);
•
properties of the gravitational forces and torques vector g(q);
•
properties of the residual dynamics.
Each of these items is treated independently and constitute the material of
this chapter. Some of the proofs of the properties that are established below
may be consulted in the references which are listed at the end of the chapter
and others are developed in Appendix C.
4.1 The Inertia Matrix
The inertia matrix M(q) plays an important role both in the robot’s dynamic
model as well as in control design. The properties of the inertia matrix which is

96
4 Properties of the Dynamic Model
closely related to the kinetic energy function K = 1
2 ˙qTM(q) ˙q, are exhaustively
used in control design for robots. Among such properties we underline the
following.
Property 4.1. Inertia matrix M(q)
The inertia matrix M(q) is symmetric positive deﬁnite and has dimension
n × n. Its elements are functions only of q. The inertia matrix M(q) satisﬁes
the following properties.
1.
There exists a real positive number α such that
M(q) ≥αI
∀q ∈IRn
where I denotes the identity matrix of dimension n×n. The matrix
M(q)−1 exists and is positive deﬁnite.
2.
For robots having only revolute joints there exists a constant β > 0
such that
λMax{M(q)} ≤β
∀q ∈IRn .
One way of computing β is
β ≥n

max
i,j,q |Mij(q)|

where Mij(q) stands for the ijth element of the matrix M(q).
3.
For robots having only revolute joints there exists a constant kM >
0 such that
∥M(x)z −M(y)z∥≤kM ∥x −y∥∥z∥
(4.2)
for all vectors x, y, z ∈IRn. One simple way to determine kM is
as follows
kM ≥n2

max
i,j,k,q

∂Mij(q)
∂qk


.
(4.3)
4.
For robots having only revolute joints there exists a number k′
M >
0 such that
∥M(x)y∥≤k′
M ∥y∥
for all x, y ∈IRn.
The reader interested in the proof of Inequality (4.2) is invited to see
Appendix C.

4.2 The Centrifugal and Coriolis Forces Matrix
97
An obvious consequence of Property 4.1 and, in particular of the fact that
M(q) is positive deﬁnite, is that the function V : IRn × IRn →IR+, deﬁned as
V (q, ˙q) = ˙qTM(q) ˙q
is positive deﬁnite in ˙q. As a matter of fact, notice that with the previous
deﬁnition we have V (q, ˙q) = 2K(q, ˙q) where K(q, ˙q) corresponds to the kinetic
energy function of the robot, (3.15).
4.2 The Centrifugal and Coriolis Forces Matrix
The properties of the Centrifugal and Coriolis matrix C(q, ˙q) are important
in the study of stability of control systems for robots. The main properties of
such a matrix are presented below.
Property 4.2. Coriolis matrix C(q, ˙q)
The centrifugal and Coriolis forces matrix C(q, ˙q) has dimension n×n and its
elements are functions of q and ˙q. The matrix C(q, ˙q) satisﬁes the following.
1.
For a given manipulator, the matrix C(q, ˙q) may not be unique
but the vector C(q, ˙q) ˙q is unique.
2.
C(q, 0) = 0 for all vectors q ∈IRn.
3.
For all vectors q, x, y, z ∈IRn and any scalar α we have
C(q, x)y = C(q, y)x
C(q, z + αx)y = C(q, z)y + αC(q, x)y .
4.
The vector C(q, x)y may be written in the form
C(q, x)y =
⎡
⎢⎢⎢⎢⎢⎣
xTC1(q)y
xTC2(q)y
...
xTCn(q)y
⎤
⎥⎥⎥⎥⎥⎦
(4.4)
where Ck(q) are symmetric matrices of dimension n × n for all
k = 1, 2, · · · , n. The ij-th element Ckij(q) of the matrix Ck(q)
corresponds to the so-called Christoﬀel symbol of the ﬁrst kind
cjik(q) and which is deﬁned in (3.21).

98
4 Properties of the Dynamic Model
5.
For robots having exclusively revolute joints, there exists a number
kC1 > 0 such that
∥C(q, x)y∥≤kC1 ∥x∥∥y∥
for all q, x, y ∈IRn.
6.
For robots having exclusively revolute joints, there exist numbers
kC1 > 0 and kC2 > 0 such that
∥C(x, z)w −C(y, v)w∥≤kC1 ∥z −v∥∥w∥
+kC2 ∥x −y∥∥w∥∥z∥
(4.5)
for all vector v, x, y, z, w ∈IRn.
7.
The matrix C(q, ˙q), deﬁned in (3.22) is related to the inertia ma-
trix M(q) by the expression
xT
1
2
˙M(q) −C(q, ˙q)

x = 0
∀q, ˙q, x ∈IRn
and as a matter of fact,
1
2 ˙M(q) −C(q, ˙q) is skew-symmetric.
Equivalently, the matrix ˙M(q) −2C(q, ˙q) is skew-symmetric, and
it is also true that
˙M(q) = C(q, ˙q) + C(q, ˙q)T .
Independently of the way in which C(q, ˙q) is derived, it always
satisﬁes
˙qT
1
2
˙M(q) −C(q, ˙q)

˙q = 0
∀q, ˙q ∈IRn .
We present next, the proof for the existence of a positive constant kC1
such that ∥C(q, x)y∥≤kC1 ∥x∥∥y∥for all vectors q, x, y ∈IRn.
Considering (4.4), the norm ∥C(q, x)y∥2 of the vector C(q, x)y is deﬁned
in the usual way that is, as the sum of its elements squared,
∥C(q, x)y∥2 =
n

k=1
 
xTCk(q)y
!2 .
This implies that

4.2 The Centrifugal and Coriolis Forces Matrix
99
∥C(q, x)y∥2 =
n

k=1
xTCk(q)y
2
≤
'
n

k=1
∥Ck(q)∥2
(
∥x∥2 ∥y∥2
(4.6)
where we have used the fact that for vectors x, y and a square matrix A of
compatible dimensions it holds that
xTAy
 ≤∥A∥∥x∥∥y∥.
Taking into account that the spectral norm ∥A∥of a symmetric matrix
A = {aij} of dimension n × n veriﬁes the inequality ∥A∥≤n maxi,j {|aij|},
we have
∥Ck(q)∥2 ≤n2

max
i,j,q
)Ckij(q)
*2
,
where Ckij(q) stands for the ijth element of the symmetric matrix Ck(q).
Therefore, we obtain
'
n

k=1
∥Ck(q)∥2
(
≤n2
n

k=1

max
i,j,q
)Ckij(q)
*2
≤n3

max
k,i,j,q
)Ckij(q)
*2
≤n4

max
k,i,j,q
)Ckij(q)
*2
where we used the fact that n ≥1. Though conservative, the last step above,
is justiﬁed to maintain integer exponents. Using this last inequality in (4.6)
we ﬁnally obtain
∥C(q, x)y∥≤n2

max
k,i,j,q
Ckij(q)


∥x∥∥y∥
(4.7)
where one clearly identiﬁes the constant kC1 as
kC1 = n2

max
k,i,j,q
Ckij(q)


.
(4.8)
As an immediate application of the expression in (4.7), ∥C(q, x)y∥≤
kC1 ∥x∥∥y∥, we have
∥C(q, ˙q) ˙q∥≤kC1∥˙q∥2 .
We present now an example with the purpose of illustrating the previous
computations.

100
4 Properties of the Dynamic Model
Example 4.1. Consider the centrifugal and Coriolis forces matrix
C(q, ˙q) =
⎡
⎣
−m2l1lc2 sin(q2) ˙q2
−m2l1lc2 sin(q2)[ ˙q1 + ˙q2]
m2l1lc2 sin(q2) ˙q1
0
⎤
⎦.
We wish to ﬁnd a positive constant kC1 such that ∥C(q, ˙q) ˙q∥≤
kC1 ∥˙q∥2. To that end, the vector C(q, ˙q) ˙q may be rewritten as
C(q, ˙q) ˙q =
⎡
⎣
−m2l1lc2 sin(q2)

2 ˙q1 ˙q2 + ˙q2
2

m2l1lc2 sin(q2) ˙q2
1
⎤
⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣

˙q1
˙q2
T
C1(q)
$
%"
#

0
−m2l1lc2 sin(q2)
−m2l1lc2 sin(q2)
−m2l1lc2 sin(q2)
 
˙q1
˙q2


˙q1
˙q2
T 
m2l1lc2 sin(q2)
0
0
0

"
#$
%
C2(q)

˙q1
˙q2

⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
Using the matrices C1(q) and C2(q) one can easily verify that
max
q
|C111(q)| = 0
max
q
|C112(q)| = m2l1lc2
max
q
|C121(q)| = m2l1lc2
max
q
|C122(q)| = m2l1lc2
max
q
|C211(q)| = m2l1lc2
max
q
|C212(q)| = 0
max
q
|C221(q)| = 0
max
q
|C222(q)| = 0 .
Hence, considering (4.8) we obtain
kC1 = 4m2l1lc2 .
♦
The reader interested in the proof of Inequality (4.5) is invited to see
Appendix C.

4.3 The Gravitational Torques Vector
101
4.3 The Gravitational Torques Vector
The vector of gravitational torques, g(q), is present in robots which from a
mechanical viewpoint, have not been designed with compensation of gravi-
tational torques. For instance, without counter-weights, springs or for robots
designed to move out of the horizontal plane. Some of the most relevant prop-
erties of this vector are enunciated next.
Property 4.3. Gravity vector g(q)
The gravitational torques vector g(q), of dimension n × 1, depends only on
the joint positions q. The vector g(q) is continuous and therefore bounded for
each bounded q. Moreover, g(q) also satisﬁes the following.
1.
The vector g(q) and the velocity vector ˙q are correlated as
 T
0
g(q(t))T˙q(t) dt = U(q(T)) −U(q(0))
(4.9)
for all T ∈IR+ .
2.
For robots having only revolute joints there exists a number kU
such that
 T
0
g(q(t))T˙q(t) dt + U(q(0)) ≥kU
for all T ∈IR+ and where kU = min
q
{U(q)}.
3.
For robots having only revolute joints, the vector g(q) is Lips-
chitz, that is, there exists a constant kg > 0 such that
∥g(x) −g(y)∥≤kg ∥x −y∥
(4.10)
for all x, y ∈IRn. A simple way to compute kg is by evaluating
its partial derivative
kg ≥n

max
i,j,q

∂gi(q)
∂qj


.
(4.11)
Furthermore, kg satisﬁes
kg ≥

∂g(q)
∂q
 ≥λMax
∂g(q)
∂q
&
.

102
4 Properties of the Dynamic Model
4.
For robots having only revolute joints there exists a constant k′
such that
∥g(q)∥≤k′
for all q ∈IRn.
To prove (4.9) consider the potential energy function U(q) for a given
manipulator. The partial time derivative of U(q) is given by
d
dtU(q(t)) = ∂U(q)
∂q
T
˙q
hence, replacing (3.20) we obtain
d
dtU(q(t)) = g(q)T˙q .
To integrate the above on both sides from 0 to T, deﬁne U0 := U(q(0))
and UT := U(q(T)) for any T ∈IR+ then,
 UT
U0
dU =
 T
0
g(q(t))T˙q(t) dt ,
which is equivalent to
U(q(T)) −U(q(0)) =
 T
0
g(q)T˙q dt .
The proof of (4.10) is presented in Appendix C.
4.4 The Residual Dynamics
To each robot dynamic model there is an associated function named “residual
dynamics” that is important in the study of stability of numerous controllers.
The residual dynamics h(t, ˜q, ˙˜q) is deﬁned as follows1:
h(t, ˜q, ˙˜q) = [M(qd) −M(qd −˜q)] ¨qd
+

C(qd, ˙qd) −C(qd −˜q, ˙qd −˙˜q)

˙qd
+ g(qd) −g(qd −˜q),
(4.12)
1 Note that, in general, because  d depends on time so does the function of residual
dynamics.

4.4 The Residual Dynamics
103
and with an abuse of notation it may be written as
h(t, ˜q, ˙˜q) = [M(qd) −M(q)] ¨qd + [C(qd, ˙qd) −C(q, ˙q)] ˙qd + g(qd) −g(q).
This function has the characteristic that h(t, 0, 0) = 0 for all t but more
importantly, the residual dynamics h(t, ˜q, ˙˜q) has the virtue of not growing
faster than ∥˙˜q∥and ∥˜q∥. Moreover it may grow arbitrarily fast only when so
does ∥˙˜q∥, independently of ∥˜q∥.
In order to make this statement formal we need to recall the deﬁnition and
properties of a continuously diﬀerentiable monotonically increasing function:
the tangent hyperbolic. As a matter of fact, the statement can be shown for a
large class of monotonically increasing functions but for clarity of exposition,
here we restrict our discussion to
tanh(x) = ex −e−x
ex + e−x
which is illustrated in Figure 4.1.
−4
−3
−2
−1
0
1
2
3
4
−1.0
−0.5
0.0
0.5
1.0
tanh(x)
x
.......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 4.1. Graph of tangent hyperbolic: tanh(x)
As it is clear from Figure 4.1, tanh(x) is continuous monotonically in-
creasing. Also, it has continuous derivatives and it satisﬁes |x| ≥|tanh(x)|
and 1 ≥|tanh(x)| for all x ∈IR. All these observations are stated formally
below.
Deﬁnition 4.1. Vectorial tangent hyperbolic function
We deﬁne the vectorial tangent hyperbolic function as
tanh(x) :=
⎡
⎢⎣
tanh(x1)
...
tanh(xn)
⎤
⎥⎦
(4.13)

104
4 Properties of the Dynamic Model
where x ∈IRn. The ﬁrst partial derivative of tanh(x) is given by
∂tanh
∂x
(x) =: Sech2(x) = diag{sech2(xi)}
(4.14)
where
sech(xi) :=
1
exi −e−xi .
The vectorial tangent hyperbolic function satisﬁes the following properties.
For any x, ˙x ∈IRn
•
∥tanh(x)∥≤α1 ∥x∥
•
∥tanh(x)∥≤α2
•
∥tanh(x)∥2 ≤α3 tanh(x)T x
•
Sech2(x) ˙x
 ≤α4 ∥˙x∥
where α1, · · · , α4 > 0. With tanh(x) deﬁned as in (4.13), the constants α1 =
1, α2 = √n, α3 = 1, α4 = 1.
Property 4.4. Residual dynamics vector h(t, ˜q, ˙˜q)
The vector of residual dynamics h(t, ˜q, ˙˜q) of n × 1 depends on the position
errors ˜q, velocity errors ˙˜q, and on the desired joint motion —qd, ˙qd, and
¨qd— that is supposed to be bounded. In this respect, we denote by ∥˙qd∥M
and ∥¨qd∥M the supreme values over the norms of the desired velocity and
acceleration. In addition, h(t, ˜q, ˙˜q) has the following property:
1.
There exist constants kh1, kh2 ≥0 such that the norm of the
residual dynamics satisﬁes
h(t, ˜q, ˙˜q)
 ≤kh1∥˙˜q∥+ kh2 ∥tanh(˜q)∥
(4.15)
for all ˜q, ˙˜q ∈IRn, where tanh(˜q) is the vectorial tangent hyper-
bolic function introduced in Deﬁnition 4.1.
Proof. According to the deﬁnition of the residual dynamics function (4.12),
its norm satisﬁes
h(t, ˜q, ˙˜q)
 ≤∥[M(qd) −M(qd −˜q)] ¨qd∥
+


C(qd, ˙qd) −C(qd −˜q, ˙qd −˙˜q)

˙qd

+ ∥g(qd) −g(qd −˜q)∥.
(4.16)

4.4 The Residual Dynamics
105
We wish to upperbound each of the three terms on the right-hand side of
this inequality. We start with ∥g(qd) −g(qd −˜q)∥. From Property 4.3 it fol-
lows that the vector of gravitational torques – considering robots with revolute
joints – satisﬁes the inequalities
∥g(qd) −g(qd −˜q)∥≤kg ∥˜q∥
∥g(qd) −g(qd −˜q)∥≤2k′
for all qd, ˜q ∈IRn and where we have used ∥g(q)∥≤k′ for the second in-
equality. This may be illustrated as in Figure 4.2 where ∥g(qd) −g(qd −˜q)∥
is in the dotted region, for all qd, ˜q ∈IRn.
0
0
2k′
kg
∥˜ ∥
∥ (d) − (d −˜)∥
2k′
...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.........................................................................................................................
..........................
slope kg
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
............. ............. ............. ............. .............
............. ............. ............. ............. ............. ............. ............. .............
.............
.............
.............
.............
.............
.............
.
Figure 4.2. Belonging region for ∥ (d) − (d −˜)∥
Regarding the ﬁrst term on the right-hand side of Inequality (4.16), we
have from Property 4.1 of the inertia matrix M(q), that the following two
inequalities hold:
∥[M(qd) −M(qd −˜q)] ¨qd∥≤kM ∥¨qd∥M ∥˜q∥,
∥[M(qd) −M(qd −˜q)] ¨qd∥≤2k′
M ∥¨qd∥M ,
where for the second inequality, we used that ∥M(x)¨qd∥≤k′
M ∥¨qd∥, which is
valid for all x ∈IRn .
Finally it is only left to bound the second term on the right-hand side
of Inequality (4.16). This operation requires the following computations. By
virtue of Property 4.2 it follows that (see (4.5))


C(qd, ˙qd) −C(qd −˜q, ˙qd −˙˜q)

˙qd
 ≤kC1 ∥˙qd∥M
 ˙˜q
 + kC2 ∥˙qd∥2
M ∥˜q∥.
(4.17)
Also, observe that the left-hand side of (4.17) also satisﬁes

106
4 Properties of the Dynamic Model


C(qd, ˙qd) −C(qd −˜q, ˙qd −˙˜q)

˙qd
 ≤∥C(qd, ˙qd) ˙qd∥
+
C(qd −˜q, ˙qd −˙˜q) ˙qd

(4.18)
but in view of the fact that ∥C(q, x)y∥≤kC1 ∥x∥∥y∥for all q, x, y ∈IRn,
the terms on the right-hand side also satisfy
∥C(qd, ˙qd) ˙qd∥≤kC1 ∥˙qd∥2
M
and,
C(qd −˜q, ˙qd −˙˜q) ˙qd
 ≤kC1 ∥˙qd∥M
 ˙qd −˙˜q

≤kC1 ∥˙qd∥2
M + kC1 ∥˙qd∥M
 ˙˜q
 .
Using the latter in (4.18) we obtain


C(qd, ˙qd) −C(qd −˜q, ˙qd −˙˜q)

˙qd
 ≤2kC1 ∥˙qd∥2
M + kC1 ∥˙qd∥M
˙˜q
 .
(4.19)
Hence, to bound the norm of the residual dynamics (4.16) we use (4.17)
and (4.19), as well as the previous bounds on the ﬁrst and third terms. This
yields that h(t, ˜q, ˙˜q) also satisﬁes
h(t, ˜q, ˙˜q)
 ≤kC1 ∥˙qd∥M
˙˜q
 +

kg + kM ∥¨qd∥M + kC2 ∥˙qd∥2
M

∥˜q∥,
and
h(t, ˜q, ˙˜q)
 ≤kC1 ∥˙qd∥M
˙˜q
 + 2

k′ + k′
M ∥¨qd∥M + kC1 ∥˙qd∥2
M

for all ˜q ∈IRn. In other terms,
h(t, ˜q, ˙˜q)
 ≤kC1 ∥˙qd∥M
 ˙˜q
 + s(˜q)
(4.20)
where the scalar function s(˜q) is given by
s(˜q) =

s1 ∥˜q∥
if
∥˜q∥< s2/s1
s2
if
∥˜q∥≥s2/s1
with
s1 =

kg + kM ∥¨qd∥M + kC2 ∥˙qd∥2
M

,
(4.21)
and
s2 = 2

k′ + k′
M ∥¨qd∥M + kC1 ∥˙qd∥2
M

.
(4.22)

4.4 The Residual Dynamics
107
0
0
s2
s1
∥˜ ∥
s(˜ )
s2
....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.........................................................................................................................
..........................
slope s1
............. ............. ............. ............. .............
............. ............. ............. ............. ............. ............. ............. .............
.............
.............
.............
.............
.............
.............
.
Figure 4.3. Graph of the function s(˜ )
The plot of s(˜q) is shown in Figure 4.3. It is clear that s(˜q) may be
upperbounded by the tangent hyperbolic function of ∥˜q∥that is,
|s(˜q)| ≤kh2 tanh(∥˜q∥)
(4.23)
where kh2 is any number that satisﬁes
kh2 ≥
s2
tanh
s2
s1
 .
(4.24)
Thus, we conclude that
h(t, ˜q, ˙˜q)
 in (4.20) satisﬁes
h(t, ˜q, ˙˜q)
 ≤kh1
 ˙˜q
 + kh2 ∥tanh(˜q)∥
where we have used the fact that
tanh(∥˜q∥) ≤∥tanh(˜q)∥,
where tanh(˜q) is the vectorial tangent hyperbolic function (4.13) and kh1 is
assumed to satisfy
kC1 ∥˙qd∥M ≤kh1 .
(4.25)
Thus, Property 4.4 follows.
♦♦♦
Residual Dynamics when ˙qd ≡0
In the situation when ˙qd ≡0, and therefore ¨qd ≡0, the residual dynamics
(4.12) boils down to

108
4 Properties of the Dynamic Model
h(t, ˜q, ˙˜q) = g(qd) −g(qd −˜q),
= g(qd) −g(q).
Notice also that s1 and s2 in (4.21) and (4.22) respectively, become
s1 = kg,
s2 = 2k′.
With this information and what we know about kh1 from (4.25) and about
kh2 from (4.24), we conclude that these constants
kh1 = 0 ,
kh2 ≥
2k′
tanh
2k′
kg
 .
From this last inequality one can show that kh2 satisﬁes
kh2 ≥kg .
Thus, we ﬁnally conclude from (4.20) and (4.23) that
h(t, ˜q, ˙˜q)
 = ∥g(qd) −g(qd −˜q)∥≤kh2 tanh(∥˜q∥),
≤kh2

⎡
⎢⎣
tanh(˜q1)
...
tanh(˜qn)
⎤
⎥⎦

,
for all qd, ˜q ∈IRn.
4.5 Conclusions
Properties 4.1, 4.2, 4.3 and 4.4 are exhaustively used in the succeeding chap-
ters in the stability analysis of the control schemes that we present. In particu-
lar, Property 4.1 is used to construct non-negative functions and occasionally,
Lyapunov functions to study stability and convergence properties for equilib-
ria in robot control systems.
To close the chapter we summarize, in Table 4.1, the expressions involved
in the computation of the main constants introduced, where s1 and s2 are
given by Equations (4.21) and (4.22), respectively.

Bibliography
109
Table 4.1. Bounds on the matrices involved in the Lagrangian model
Bound
Deﬁnition
β
n (maxi,j,q |Mij(q)|)
kM
n2

maxi,j,k,q

∂Mij(q)
∂qk


kC1
n2  
maxi,j,k,q
Ckij(q)
!
kC2
n3

maxi,j,k,l,q

∂Ckij(q)
∂ql


kg
n

maxi,j,q

∂gi(q)
∂qj


kh1
kc1 ∥˙ d∥M
kh2
s2
tanh
+s2
s1
,
Bibliography
Properties 4.1 and 4.2 are proved in
•
Spong M., Vidyasagar M., 1989, “Robot dynamics and control”, Wiley,
New York.
•
Craig J., 1988, “Adaptive control of mechanical manipulators”, Addison -
Wesley, Reading MA.
The property of skew-symmetry of 1
2
˙
$
#
M(q) −C(q, ˙q) was established in
•
Ortega R. and Spong M., 1989, “Adaptive motion control of rigid robots:
A tutorial,” Automatica, Vol. 25-6, pp. 877–888.
The concept of residual dynamics was introduced in
•
Arimoto S., 1995, “Fundamental problems of robot control: Part I: Inno-
vation in the realm of robot servo–loops”, Robotica, Vol. 13, Part 1, pp.
19–27.
•
Arimoto S., 1995, “Fundamental problems of robot control: Part II: A
nonlinear circuit theory towards an understanding of dexterous motions,
Robotica, Vol. 13, Part 2, pp. 111–122.

110
4 Properties of the Dynamic Model
One version of the proof of Property 4.4 on the residual dynamics h(t, ˜q, ˙˜q)
is presented in
•
Santib´a˜nez V., Kelly R., 2001, “PD control with feedforward compensation
for robot manipulators: Analysis and experimentation”, Robotica, Vol. 19,
pp. 11–19.
For other properties of robot manipulators not mentioned here and rele-
vant to control, see
•
Ortega R., Lor´ıa A., Nicklasson P. J., Sira-Ram´ırez H., 1998, “Passivity-
based control of Euler-Lagrange Systems Mechanical, Electrical and Elec-
tromechanical Applications”, Springer-Verlag: London, Communications
and Control Engg. Series.
Problems
1. Consider the simpliﬁed Cartesian mechanical device of Figure 4.4.
x0
y0
z0
q1
q2
x0
y0
z0
q1
q2
m1
m2
Figure 4.4. Problem 1
a) Obtain the dynamic model using Lagrange’s equations. Speciﬁcally,
determine M(q), C(q, ˙q) and g(q).
b) Verify that the matrix 1
2 ˙M(q) −C(q, ˙q) is skew-symmetric.
c) Express the dynamic model in terms of the state vector [q1
q2
˙q1
˙q2]T . Under which conditions on the external τ1 and τ2 do there exist
equilibria?

Problems
111
2. Is it true that the inertia matrix M(q) is constant if and only if C(q, ˙q) =
0 ? (The matrix C(q, ˙q) is assumed to be deﬁned upon the Christoﬀel
symbols of the ﬁrst kind.)
3. Consider the dynamic model (3.33) of robots with (linear) actuators. Sup-
pose that there is no friction (i.e. f( ˙q) = 0). Show that
1
2
˙
M ′(q) −C(q, ˙q) = 1
2
˙M(q) −C(q, ˙q) .
4. Consider the equation that characterizes the behavior of a pendulum of
length l and mass m concentrated at the edge and is submitted to the
action of gravity g to which is applied a torque τ on the axis of rotation,
ml2¨q + mgl sin(q) = τ
where q is the angular position of the pendulum with respect to the ver-
tical.
Show that there exists a constant β such that
 T
0
τ(s) ˙q(s) ds ≥β,
∀T ∈IR+ .
Hint: Using Property 4.3, show that for any T ≥0,
 T
0
˙q(s)sin(q(s)) ds ≥−K
with K ≥0.

5
Case Study: The Pelican Prototype Robot
The purpose of this chapter is twofold: ﬁrst, to present in detail the model of
the experimental robot arm of the Robotics lab. from the CICESE Research
Center, Mexico. Second, to review the topics studied in the previous chapters
and to discuss, through this case study, the topics of direct kinematics and
inverse kinematics, which are fundamental in determining robot models.
For the Pelican, we derive the full dynamic model of the prototype; in par-
ticular, we present the numerical values of all the parameters such as mass,
inertias, lengths to centers of mass, etc. This is used throughout the rest of the
book in numerous examples to illustrate the performance of the controllers
that we study. We emphasize that all of these examples contain experimen-
tation results.
Thus, the chapter is organized in the following sections:
•
direct kinematics;
•
inverse kinematics;
•
dynamic model;
•
properties of the dynamic model;
•
reference trajectories.
For analytical purposes, further on, we refer to Figure 5.2, which represents
the prototype schematically. As is obvious from this ﬁgure, the prototype is a
planar arm with two links connected through revolute joints, i.e. it possesses
2 DOF. The links are driven by two electrical motors located at the “shoulder”
(base) and at the “elbow”. This is a direct-drive mechanism, i.e. the axes of
the motors are connected directly to the links without gears or belts.
The manipulator arm consists of two rigid links of lengths l1 and l2, masses
m1 and m2 respectively. The robot moves about on the plane x–y as is illus-
trated in Figure 5.2. The distances from the rotating axes to the centers of
mass are denoted by lc1 and lc2 for links 1 and 2, respectively. Finally, I1 and

114
5 Case Study: The Pelican Prototype Robot
Figure 5.1. Pelican: experimental robot arm at CICESE, Robotics lab.
l2
lc2
q2
q1
I1
m1
g
y
x
l1
m2
I2
lc1
Link 1
Link 2
Figure 5.2. Diagram of the 2-DOF Pelican prototype robot
I2 denote the moments of inertia of the links with respect to the axes that
pass through the respective centers of mass and are parallel to the axis x.
The degrees of freedom are associated with the angle q1, which is measured
from the vertical position, and q2, which is measured relative to the extension
of the ﬁrst link toward the second link, both being positive counterclockwise.
The vector of joint positions q is deﬁned as
q = [q1 q2]T .

5.1 Direct Kinematics
115
The meaning of the diverse constant parameters involved as well as their
numerical values are summarized in Table 5.1.
Table 5.1. Physical parameters of Pelican robot arm
Description
Notation Value Units
Length of Link 1
l1
0.26
m
Length of Link 2
l2
0.26
m
Distance to the center of mass (Link 1)
lc1
0.0983
m
Distance to the center of mass (Link 2)
lc2
0.0229
m
Mass of Link 1
m1
6.5225
kg
Mass of Link 2
m2
2.0458
kg
Inertia rel. to center of mass (Link 1)
I1
0.1213 kg m2
Inertia rel. to center of mass (Link 2)
I2
0.0116 kg m2
Gravity acceleration
g
9.81
m/s2
5.1 Direct Kinematics
The problem of direct kinematics for robot manipulators is formulated as
follows. Consider a robot manipulator of n degrees-of-freedom placed on a
ﬁxed surface. Deﬁne a reference frame also ﬁxed at some point on this sur-
face. This reference frame is commonly referred to as ‘base reference frame’.
The problem of deriving the direct kinematic model of the robot consists in
expressing the position and orientation (when the latter makes sense) of a ref-
erence frame ﬁxed to the end of the last link of the robot, referred to the base
reference frame in terms of the joint coordinates of the robot. The solution to
the so-formulated problem from a mathematical viewpoint, reduces to solving
a geometrical problem which always has a closed-form solution.
Regarding the Pelican robot, we start by deﬁning the reference frame of
base as a Cartesian coordinated system in two dimensions with its origin
located exactly on the ﬁrst joint of the robot, as is illustrated in Figure 5.2. The
Cartesian coordinates x and y determine the position of the tip of the second
link with respect to the base reference frame. Notice that for the present case
study of a 2-DOF system, the orientation of the end-eﬀector of the arm makes
no sense. One can clearly appreciate that both Cartesian coordinates, x and

116
5 Case Study: The Pelican Prototype Robot
y, depend on the joint coordinates q1 and q2. Precisely it is this correlation
that deﬁnes the direct kinematic model,

x
y

= ϕ(q1, q2) ,
where ϕ : IR2 →IR2.
For the case of this robot with 2 DOF, it is immediate to verify that the
direct kinematic model is given by
x = l1sin(q1) + l2sin(q1 + q2)
y = −l1cos(q1) −l2cos(q1 + q2) .
From this model is obtained: the following relation between the velocities

˙x
˙y

=

l1cos(q1) + l2cos(q1 + q2)
l2cos(q1 + q2)
l1sin(q1) + l2sin(q1 + q2)
l2sin(q1 + q2)
 
˙q1
˙q2

= J(q)

˙q1
˙q2

where J(q) = ∂ϕ(q)
∂q
∈IR2×2 is called the analytical Jacobian matrix or
simply, the Jacobian of the robot. Clearly, the following relationship between
accelerations also holds,

¨x
¨y

=
 d
dtJ(q)
 
˙q1
˙q2

+ J(q)

¨q1
¨q2

.
The procedure by which one computes the derivatives of the Jacobian
and thereby obtains expressions for the velocities in Cartesian coordinates, is
called diﬀerential kinematics. This topic is not studied in more detail in this
textbook since we do not use it for control.
5.2 Inverse Kinematics
The inverse kinematic model of robot manipulators is of great importance
from a practical viewpoint. This model allows us to obtain the joint positions
q in terms of the position and orientation of the end-eﬀector of the last link
referred to the base reference frame. For the case of the Pelican prototype
robot, the inverse kinematic model has the form

q1
q2

= ϕ−1(x, y)

5.2 Inverse Kinematics
117
where ϕ−1 : Θ →IR2 and Θ ⊆IR2.
The derivation of the inverse kinematic model is in general rather complex
and, in contrast to the direct kinematics problem, it may have multiple solu-
tions or no solution at all! The ﬁrst case is illustrated in Figure 5.3. Notice
that for the same position (in Cartesian coordinates x, y) of the arm tip there
exist two possible conﬁgurations of the links, i.e. two possible values for q.
qd2
qd1
y
x
Figure 5.3. Two solutions to the inverse kinematics problem
So we see that even for this relatively simple robot conﬁguration there
exist more than one solution to the inverse kinematics problem.
The practical interest of the inverse kinematic model relies on its utility
to deﬁne desired joint positions qd = [qd1 qd2]T from speciﬁed desired posi-
tions xd and yd for the robot’s end-eﬀector. Indeed, note that physically, it
is more intuitive to specify a task for a robot in end-eﬀector coordinates so
that interest in the inverse kinematics problem increases with the complexity
of the manipulator (number of degrees of freedom).
Thus, let us now make our this discussion more precise by analytically
computing the solutions

qd1
qd2

= ϕ−1(xd, yd). The desired joint positions qd
can be computed using tedious but simple trigonometric manipulations to
obtain
qd1 = tan−1
 xd
−yd

−tan−1

l2sin(qd2)
l1 + l2cos(qd2)

qd2 = cos−1
x2
d + y2
d −l2
1 −l2
2
2l1l2

.

118
5 Case Study: The Pelican Prototype Robot
The desired joint velocities and accelerations may be obtained via the
diﬀerential kinematics1 and its time derivative. In doing this one must keep
in mind that the expressions obtained are valid only as long as the robot does
not “fall” into a singular conﬁguration, that is, as long as the Jacobian J(qd)
is square and nonsingular. These expressions are

˙qd1
˙qd2

= J−1(qd)

˙xd
˙yd


¨qd1
¨qd2

= −J−1(qd)
 d
dtJ(qd)

J−1(qd)
"
#$
%
d
dt

J−1(qd)


˙xd
˙yd

+ J−1(qd)

¨xd
¨yd

where J−1(qd) and
d
dt [J(qd)] denote the inverse of the Jacobian matrix and
its time derivative respectively, evaluated at q = qd. These are given by
J−1(qd) =
⎡
⎢⎢⎣
S12
l1S2
−C12
l1S2
−l1S1 −l2S12
l1l2S2
l1C1 + l2C12
l1l2S2
⎤
⎥⎥⎦,
and
d
dt [J(qd)] =
⎡
⎣
−l1S1 ˙qd1 −l2S12( ˙qd1 + ˙qd2)
−l2S12( ˙qd1 + ˙qd2)
l1C1 ˙qd1 + l2C12( ˙qd1 + ˙qd2)
l2C12( ˙qd1 + ˙qd2)
⎤
⎦,
where, for simplicity, we have used the notation S1 = sin(qd1), S2 = sin(qd2),
C1 = cos(qd1), S12 = sin(qd1 + qd2), C12 = cos(qd1 + qd2) .
Notice that the term S2 appears in the denominator of all terms in J(q)−1
hence, qd2 = nπ, with n ∈{0, 1, 2, . . .} and any qd1 also correspond to singular
conﬁgurations. Physically, these conﬁgurations (for any valid n) represent the
second link being completely extended or bent over the ﬁrst, as is illustrated
in Figure 5.4. Typically, singular conﬁgurations are those in which the end-
eﬀector of the robot is located at the physical boundary of the workspace
(that is, the physical space that the end-eﬀector can reach). For instance, the
singular conﬁguration corresponding to being stretched out corresponds to
the end-eﬀector being placed anywhere on the circumference of radius l1 + l2,
which is the boundary of the robot’s workspace. As for Figure 5.4 the origin
of the coordinates frame constitute another point of this boundary.
Having illustrated the inverse kinematics problem through the planar ma-
nipulator of Figure 5.2 we stop our study of inverse kinematics since it is
1 For a deﬁnition and a detailed treatment of diﬀerential kinematics see the book
(Sciavicco, Siciliano 2000) —cf. Bibliography at the end of Chapter 1.

5.3 Dynamic Model
119
qd1
x
y
qd2
Figure 5.4. “Bent-over” singular conﬁguration
beyond the scope of this text. However, we stress that what we have seen in
the previous paragraphs extends in general.
In summary, we can say that if the control is based on the Cartesian coor-
dinates of the end-eﬀector, when designing the desired task for a manipulator’s
end-eﬀector one must take special care that the conﬁgurations for the latter
do not yield singular conﬁgurations. Concerning the controllers studied in this
textbook, the reader should not worry about singular conﬁgurations since the
Jacobian is not used at all: the reference trajectories are given in joint coor-
dinates and we measure joint coordinates. This is what is called “control in
joint space”.
Thus, we leave the topic of kinematics to pass to the stage of modeling
that is more relevant for control, from the viewpoint of this textbook, i.e.
dynamics.
5.3 Dynamic Model
In this section we derive the Lagrangian equations for the CICESE proto-
type shown in Figure 5.1 and then we present in detail, useful bounds on
the matrices of inertia, centrifugal and Coriolis forces, and on the vector of
gravitational torques. Certainly, the model that we derive here applies to any
planar manipulator following the same convention of coordinates as for our
prototype.
5.3.1 Lagrangian Equations
Consider the 2-DOF robot manipulator shown in Figure 5.2. As we have
learned from Chapter 3, to derive the Lagrangian dynamics we start by writing

120
5 Case Study: The Pelican Prototype Robot
the kinetic energy function, K(q, ˙q), deﬁned in (3.15). For this manipulator,
it may be decomposed into the sum of the two parts:
•
the product of half the mass times the square of the speed of the center of
mass; plus
•
the product of half its moment of inertia (referred to the center of mass)
times the square of its angular velocity (referred to the center of mass).
That is, we have K(q, ˙q) = K1(q, ˙q)+K2(q, ˙q) where K1(q, ˙q) and K2(q, ˙q) are
the kinetic energies associated with the masses m1 and m2 respectively. Let
us now develop in more detail, the corresponding mathematical expressions.
To that end, we ﬁrst observe that the coordinates of the center of mass of link
1, expressed on the plane x–y, are
x1 = lc1 sin(q1)
y1 = −lc1 cos(q1) .
The velocity vector v1 of the center of mass of such a link is then,
v1 =

˙x1
˙y1

=

lc1 cos(q1) ˙q1
lc1 sin(q1) ˙q1

.
Therefore, the speed squared, ∥v1∥2 = vT
1v1, of the center of mass becomes
vT
1v1 = l2
c1 ˙q2
1 .
Finally, the kinetic energy corresponding to the motion of link 1 can be ob-
tained as
K1(q, ˙q) = 1
2m1vT
1v1 + 1
2I1 ˙q2
1
= 1
2m1l2
c1 ˙q2
1 + 1
2I1 ˙q2
1 .
(5.1)
On the other hand, the coordinates of the center of mass of link 2, expressed
on the plane x–y are
x2 = l1 sin(q1) + lc2 sin(q1 + q2)
y2 = −l1cos(q1) −lc2 cos(q1 + q2) .
Consequently, the velocity vector v2 of the center of mass of such a link is
v2 =

˙x2
˙y2

=

l1 cos(q1) ˙q1 + lc2 cos(q1 + q2)[ ˙q1 + ˙q2]
l1 sin(q1) ˙q1 + lc2 sin(q1 + q2)[ ˙q1 + ˙q2]

.

5.3 Dynamic Model
121
Therefore, using the trigonometric identities cos(θ)2 + sin(θ)2 = 1 and
sin(q1)sin(q1 + q2) + cos(q1)cos(q1 + q2) = cos(q2) we conclude that the speed
squared, ∥v2∥2 = vT
2v2, of the center of mass of link 2 satisﬁes
vT
2v2 = l2
1 ˙q2
1 + l2
c2

˙q2
1 + 2 ˙q1 ˙q2 + ˙q2
2

+ 2l1lc2

˙q2
1 + ˙q1 ˙q2

cos(q2)
which implies that
K2(q, ˙q) = 1
2m2vT
2v2 + 1
2I2[ ˙q1 + ˙q2]2
= m2
2 l2
1 ˙q2
1 + m2
2 l2
c2

˙q2
1 + 2 ˙q1 ˙q2 + ˙q2
2

+ m2l1lc2

˙q2
1 + ˙q1 ˙q2

cos(q2)
+ 1
2I2[ ˙q1 + ˙q2]2.
Similarly, the potential energy may be decomposed as the sum of the
terms U(q) = U1(q)+U2(q), where U1(q) and U2(q) are the potential energies
associated with the masses m1 and m2 respectively. Thus, assuming that the
potential energy is zero at y = 0, we obtain
U1(q) = −m1lc1g cos(q1)
and
U2(q) = −m2l1g cos(q1) −m2lc2g cos(q1 + q2) .
(5.2)
From Equations (5.1)–(5.2) we obtain the Lagrangian as
L(q, ˙q) = K(q, ˙q) −U(q)
= K1(q, ˙q) + K2(q, ˙q) −U1(q) −U2(q)
= 1
2[m1l2
c1 + m2l2
1] ˙q2
1 + 1
2m2l2
c2

˙q2
1 + 2 ˙q1 ˙q2 + ˙q2
2

+ m2l1lc2 cos(q2)

˙q2
1 + ˙q1 ˙q2

+ [m1lc1 + m2l1]g cos(q1)
+ m2glc2 cos(q1 + q2)
+ 1
2I1 ˙q2
1 + 1
2I2[ ˙q1 + ˙q2]2.
From this last equation we obtain the following expression:
∂L
∂˙q1
= [m1l2
c1 + m2l2
1] ˙q1 + m2l2
c2 ˙q1 + m2l2
c2 ˙q2
+ 2m2l1lc2 cos(q2) ˙q1 + m2l1lc2 cos(q2) ˙q2
+ I1 ˙q1 + I2[ ˙q1 + ˙q2].

122
5 Case Study: The Pelican Prototype Robot
d
dt
 ∂L
∂˙q1

=

m1l2
c1 + m2l2
1 + m2l2
c2 + 2m2l1lc2 cos(q2)

¨q1
+

m2l2
c2 + m2l1lc2 cos(q2)

¨q2
−2m2l1lc2sin(q2) ˙q1 ˙q2 −m2l1lc2 sin(q2) ˙q2
2
+ I1¨q1 + I2[¨q1 + ¨q2].
∂L
∂q1
= −[m1lc1 + m2l1]g sin(q1) −m2glc2 sin(q1 + q2).
∂L
∂˙q2
= m2l2
c2 ˙q1 + m2l2
c2 ˙q2 + m2l1lc2 cos(q2) ˙q1 + I2[ ˙q1 + ˙q2].
d
dt
 ∂L
∂˙q2

= m2l2
c2¨q1 + m2l2
c2¨q2
+ m2l1lc2 cos(q2)¨q1 −m2l1lc2 sin(q2) ˙q1 ˙q2
+ I2[¨q1 + ¨q2].
∂L
∂q2
= −m2l1lc2 sin(q2)

˙q1 ˙q2 + ˙q2
1

−m2glc2 sin(q1 + q2).
The dynamic equations that model the robot arm are obtained by applying
Lagrange’s Equations (3.4),
d
dt
 ∂L
∂˙qi

−∂L
∂qi
= τi
i = 1, 2
from which we ﬁnally get
τ1 =

m1l2
c1 + m2l2
1 + m2l2
c2 + 2m2l1lc2 cos(q2) + I1 + I2

¨q1
+

m2l2
c2 + m2l1lc2 cos(q2) + I2

¨q2
−2m2l1lc2 sin(q2) ˙q1 ˙q2 −m2l1lc2 sin(q2) ˙q2
2
+ [m1lc1 + m2l1]g sin(q1)
+ m2glc2 sin(q1 + q2)
(5.3)
and
τ2 =

m2l2
c2 + m2l1lc2 cos(q2) + I2

¨q1 + [m2l2
c2 + I2]¨q2
+ m2l1lc2 sin(q2) ˙q2
1 + m2glc2 sin(q1 + q2) ,
(5.4)
where τ1 and τ2, are the external torques delivered by the actuators at joints
1 and 2.
Thus, the dynamic equations of the robot (5.3)-(5.4) constitute a set of
two nonlinear diﬀerential equations of the state variables x = [qT ˙qT ]T , that
is, of the form (3.1) .

5.3 Dynamic Model
123
5.3.2 Model in Compact Form
For control purposes, it is more practical to rewrite the Lagrangian dynamic
model of the robot, that is, Equations (5.3) and (5.4), in the compact form
(3.18), i.e.

M11(q)
M12(q)
M21(q)
M22(q)

"
#$
%
M(q)
¨q +

C11(q, ˙q)
C12(q, ˙q)
C21(q, ˙q)
C22(q, ˙q)

"
#$
%
C(q, ˙q)
˙q +

g1(q)
g2(q)

"
#$
%
g(q)
= τ,
where
M11(q) = m1l2
c1 + m2

l2
1 + l2
c2 + 2l1lc2 cos(q2)

+ I1 + I2
M12(q) = m2

l2
c2 + l1lc2 cos(q2)

+ I2
M21(q) = m2

l2
c2 + l1lc2 cos(q2)

+ I2
M22(q) = m2l2
c2 + I2
C11(q, ˙q) = −m2l1lc2 sin(q2) ˙q2
C12(q, ˙q) = −m2l1lc2 sin(q2) [ ˙q1 + ˙q2]
C21(q, ˙q) = m2l1lc2 sin(q2) ˙q1
C22(q, ˙q) = 0
g1(q) = [m1lc1 + m2l1] g sin(q1) + m2lc2g sin(q1 + q2)
g2(q) = m2lc2g sin(q1 + q2) .
We emphasize that the appropriate state variables to describe the dynamic
model of the robot are the positions q1 and q2 and the velocities ˙q1 and ˙q2. In
terms of these state variables, the dynamic model of the robot may be written
as
d
dt
⎡
⎢⎣
q1
q2
˙q1
˙q2
⎤
⎥⎦=
⎡
⎢⎣
˙q1
˙q2
M(q)−1 [τ(t) −C(q, ˙q) ˙q −g(q)]
⎤
⎥⎦.
Properties of the Dynamic Model
We present now the derivation of certain bounds on the inertia matrix, the ma-
trix of centrifugal and Coriolis forces and the vector of gravitational torques.
The bounds that we derive are fundamental to properly tune the gains of the
controllers studied in the succeeding chapters. We emphasize that, as stud-
ied in Chapter 4, some bounds exist for any manipulator with only revolute
rigid joints. Here, we show how they can be computed for CICESE’s Pelican
prototype illustrated in Figure 5.2.

124
5 Case Study: The Pelican Prototype Robot
Derivation of λmin{M}
We start with the property of positive deﬁniteness of the inertia matrix. For
a symmetric 2×2 matrix

M11(q) M21(q)
M21(q) M22(q)

to be positive deﬁnite for all q ∈IRn, it is necessary and suﬃcient that2
M11(q) > 0 and its determinant
M11(q)M22(q) −M21(q)2
also be positive for all q ∈IRn.
In the worst-case scenario M11(q) = m1l2
c1 + I1 + I2 + m2(l1 −lc2)2 > 0,
we only need to compute the determinant of M(q), that is,
det[M(q)] = I1I2 + I2[l2
c1m1 + l2
1m2] + l2
c2m2I1 + l2
c1l2
c2m1m2
+ l2
1l2
c2m2
2[1 −cos2(q2)] .
Notice that only the last term depends on q and is positive or zero. Hence,
we conclude that M(q) is positive deﬁnite for all q ∈IRn, that is3
xT M(q)x ≥λmin{M}∥x∥2
(5.5)
for all q ∈IRn, where λmin{M} > 0.
Inequality (5.5) constitutes an important property for control purposes
since for instance, it guarantees that M(q)−1 is positive deﬁnite and bounded
for all q ∈IRn.
Let us continue with the computation of the constants β, kM, kC1, kC2
and kg from the properties presented in Chapter 4.
Derivation of λMax{M}
Consider the inertia matrix M(q). From its components it may be veriﬁed
that
2 Consider the partitioned matrix

A
B
BT
C

.
If A = AT > 0, C = CT > 0 and C −BT A−1B ≥0 (resp. C −BT A−1B > 0 ),
then this matrix is positive semideﬁnite (resp. positive deﬁnite). See Horn R. A.,
Johnson C. R., 1985, Matrix analysis, p. 473.
3 See also Remark 2.1 on page 25.

5.3 Dynamic Model
125
max
i,j,q |Mij(q)| = m1l2
c1 + m2

l2
1 + l2
c2 + 2l1lc2

+ I1 + I2 .
According to Table 4.1, the constant β may be obtained as a value larger or
equal to n times the previous expression, i.e.
β ≥n

m1l2
c1 + m2

l2
1 + l2
c2 + 2l1lc2

+ I1 + I2

.
Hence, deﬁning, λMax{M} = β we see that
xT M(q)x ≤λMax{M}∥x∥2
for all q ∈IRn. Moreover, using the numerical values presented in Table 5.1,
we get β = 0.7193 kg m2, that is, λMax{M} = 0.7193 kg m2.
Derivation of kM
Consider the inertia matrix M(q). From its components it may be veriﬁed
that
∂M11(q)
∂q1
= 0,
∂M11(q)
∂q2
= −2m2l1lc2sin(q2)
∂M12(q)
∂q1
= 0,
∂M12(q)
∂q2
= −m2l1lc2sin(q2)
∂M21(q)
∂q1
= 0,
∂M21(q)
∂q2
= −m2l1lc2sin(q2)
∂M22(q)
∂q1
= 0,
∂M22(q)
∂q2
= 0 .
According to Table 4.1, the constant kM may be determined as
kM ≥n2

max
i,j,k,q

∂Mij(q)
∂qk


,
hence, this constant may be chosen to satisfy
kM ≥n22m2l1lc2 .
Using the numerical values presented in Table 5.1 we get kM = 0.0974 kg m2 .
Derivation of kC1
Consider the vector of centrifugal and Coriolis forces C(q, ˙q) ˙q written as
C(q, ˙q) ˙q =
⎡
⎣
−m2l1lc2 sin(q2)
 
2 ˙q1 ˙q2 + ˙q2
2
!
m2l1lc2 sin(q2) ˙q2
1
⎤
⎦

126
5 Case Study: The Pelican Prototype Robot
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣

˙q1
˙q2
T
C1(q)
$
%"
#

0
−m2l1lc2 sin(q2)
−m2l1lc2 sin(q2)
−m2l1lc2 sin(q2)
 
˙q1
˙q2


˙q1
˙q2
T 
m2l1lc2 sin(q2)
0
0
0

"
#$
%
C2(q)

˙q1
˙q2

⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
(5.6)
According to Table 4.1, the constant kC1 may be derived as
kC1 ≥n2

max
i,j,k,q
Ckij(q)


hence, this constant may be chosen so that
kC1 ≥n2m2l1lc2
Consequently, in view of the numerical values from Table 5.1 we ﬁnd that
kC1 = 0.0487 kg m2.
Derivation of kC2
Consider again the vector of centrifugal and Coriolis forces C(q, ˙q) ˙q written
as in (5.6). From the matrices C1(q) and C2(q) it may easily be veriﬁed that
∂C111(q)
∂q1
= 0, ∂C111(q)
∂q2
= 0
∂C112(q)
∂q1
= 0, ∂C112(q)
∂q2
= −m2l1lc2cos(q2)
∂C121(q)
∂q1
= 0, ∂C121(q)
∂q2
= −m2l1lc2cos(q2)
∂C122(q)
∂q1
= 0, ∂C122(q)
∂q2
= −m2l1lc2cos(q2)
∂C211(q)
∂q1
= 0, ∂C211(q)
∂q2
= m2l1lc2cos(q2)
∂C212(q)
∂q1
= 0, ∂C212(q)
∂q2
= 0
∂C221(q)
∂q1
= 0, ∂C221(q)
∂q2
= 0

5.3 Dynamic Model
127
∂C222(q)
∂q1
= 0, ∂C222(q)
∂q2
= 0 .
Furthermore, according to Table 4.1 the constant kC2 may be taken to satisfy
kC2 ≥n3

max
i,j,k,l,q

∂Ckij(q)
∂ql


.
Therefore, we may choose kC2 as
kC2 ≥n3m2l1lc2 ,
which, in view of the numerical values from Table 5.1, takes the numerical
value kC2 = 0.0974 kg m2:
Derivation of kg
According to the components of the gravitational torques vector g(q) we have
∂g1(q)
∂q1
= (m1lc1 + m2l1) g cos(q1) + m2lc2g cos(q1 + q2)
∂g1(q)
∂q2
= m2lc2g cos(q1 + q2)
∂g2(q)
∂q1
= m2lc2g cos(q1 + q2)
∂g2(q)
∂q2
= m2lc2g cos(q1 + q2) .
Notice that the Jacobian matrix ∂g(q)
∂q
corresponds in fact, to the Hessian
matrix (i.e. the second partial derivative) of the potential energy function
U(q), and is a symmetric matrix even though not necessarily positive deﬁnite.
The positive constant kg may be derived from the information given in
Table 4.1 as
kg ≥n max
i,j,q

∂gi(q)
∂qj
 .
That is,
kg ≥n [m1lc1 + m2l1 + m2lc2] g
and using the numerical values from Table 5.1 may be given the numerical
value kg = 23.94 kg m2/s2.

128
5 Case Study: The Pelican Prototype Robot
Table 5.2. Numeric values of the parameters for the CICESE prototype
Parameter Value
Units
λMax{M}
0.7193
kg m2
kM
0.0974
kg m2
kC1
0.0487
kg m2
kC2
0.0974
kg m2
kg
23.94
kg m2/s2
Summary
The numerical values of the constants λMax{M}, kM, kC1, kC2 and kg obtained
above are summarized in Table 5.2.
5.4 Desired Reference Trajectories
With the aim of testing in experiments the performance of the controllers
presented in this book, on the Pelican robot, we have selected the following
reference trajectories in joint space:
⎡
⎣
qd1
qd2
⎤
⎦=
⎡
⎣
b1[1 −e−2.0 t3] + c1[1 −e−2.0 t3] sin(ω1t)
b2[1 −e−2.0 t3] + c2[1 −e−2.0 t3] sin(ω2t)
⎤
⎦
[rad]
(5.7)
where b1 = π/4 [rad], c1 = π/9 [rad] and ω1 = 4
[rad/s], are parameters
for the desired position reference for the ﬁrst joint and b2 = π/3 [rad], c2 =
π/6 [rad] and ω2 = 3
[rad/s] correspond to parameters that determine the
desired position reference for the second joint. Figure 5.5 shows graphs of
these reference trajectories against time.
Note the following important features in these reference trajectories:
•
the trajectory contains a sinusoidal term to evaluate the performance of the
controller following relatively fast periodic motions. This test is signiﬁcant
since such motions excite nonlinearities in the system.
•
It also contains a slowly increasing term to bring the robot to the operating
point without driving the actuators into saturation.
The module and frequency of the periodic signal must be chosen with
care to avoid both torque and speed saturation in the actuators. In other

5.4 Desired Reference Trajectories
129
0
2
4
6
8
10
0.0
0.5
1.0
1.5
2.0
[rad]
qd1
qd2
t [s]
..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 5.5. Desired reference trajectories
words, the reference trajectories must be such that the evolution of the robot
dynamics along these trajectories gives admissible velocities and torques for
the actuators. Otherwise, the desired reference is physically unfeasible.
Using the expressions of the desired position trajectories, (5.7), we may
obtain analytically expressions for the desired velocity reference trajectories.
These are obtained by direct diﬀerentiation, i.e.
˙qd1 = 6b1t2e−2.0 t3 + 6c1t2e−2.0 t3sin(ω1t) + [c1 −c1e−2.0 t3] cos (ω1t)ω1,
˙qd2 = 6b2t2e−2.0 t3 + 6c2t2e−2.0 t3sin(ω2t) + [c2 −c2e−2.0 t3] cos (ω2t)ω2 ,
(5.8)
in [ rad/s ]. In the same way we may proceed to compute the reference accel-
erations to obtain
¨qd1 = 12b1te−2.0 t3 −36b1t4e−2.0 t3 + 12c1te−2.0 t3sin(ω1t)
−36c1t4e−2.0 t3sin(ω1t) + 12c1t2e−2.0 t3 cos (ω1t)ω1
−[c1 −c1e−2.0 t3]sin(ω1t)ω2
1

rad/s2
,
¨qd2 = 12b2te−2.0 t3 −36b2t4e−2.0 t3 + 12c2te−2.0 t3 sin (ω2t)
−36c2t4e−2.0 t3 sin (ω2t) + 12c2t2e−2.0 t3 cos (ω2t)ω2
−[c2 −c2e−2.0 t3] sin (ω2t)ω2
2

rad/s2
.
(5.9)

130
5 Case Study: The Pelican Prototype Robot
0
2
4
6
8
10
0.0
0.5
1.0
1.5
2.0
|| d(t)|| [rad]
t [s]
...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Figure 5.6. Norm of the desired positions
0
2
4
6
8
10
0.0
0.6
1.2
1.8
2.4
|| ˙ d(t)|| [ rad
s ]
t [s]
.....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Figure 5.7. Norm of the desired velocities vector
Figures 5.6, 5.7 and 5.8 show the evolution in time of the norms corresponding
to the desired joint positions, velocities and accelerations respectively. From
these ﬁgures we deduce the following upper-bounds on the norms
∥qd∥Max ≤1.92 [rad]
∥˙qd∥Max ≤2.33 [rad/s]
∥¨qd∥Max ≤9.52 [rad/s2] .

Problems
131
0
2
4
6
8
10
0
2
4
6
8
10
||¨ d(t)|| [ rad
s2 ]
t [s]
...............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Figure 5.8. Norm of the desired accelerations vector
Bibliography
The schematic diagram of the robot depicted in Figure 5.2 and elsewhere
throughout the book, corresponds to a real experimental prototype robot arm
designed and constructed in the CICESE Research Center, Mexico4.
The numerical values that appear in Table 5.1 are taken from:
•
Campa R., Kelly R., Santib´a˜nez V., 2004, “Windows-based real-time con-
trol of direct-drive mechanisms: platform description and experiments”,
Mechatronics, Vol. 14, No. 9, pp. 1021–1036.
The constants listed in Table 5.2 may be computed based on data reported in
•
Moreno J., Kelly R., Campa R., 2003, “Manipulator velocity control using
friction compensation”, IEE Proceedings - Control Theory and Applica-
tions, Vol. 150, No. 2.
Problems
1. Consider the matrices M(q) and C(q, ˙q) from Section 5.3.2. Show that
the matrix

1
2 ˙M(q) −C(q, ˙q)

is skew-symmetric.
2. According to Property 4.2, the centrifugal and Coriolis forces matrix
C(q, ˙q), of the dynamic model of an n-DOF robot is not unique. In Sec-
tion 5.3.2 we computed the elements of the matrix C(q, ˙q) of the Pelican
4 “Centro de Investigaci´on Cient´ıﬁca y de Educaci´on Superior de Ensenada”.

132
5 Case Study: The Pelican Prototype Robot
robot presented in this chapter. Prove also that the matrix C(q, ˙q) whose
elements are given by
C11(q, ˙q) = −2m2l1lc2 sin(q2) ˙q2
C12(q, ˙q) = −m2l1lc2 sin(q2) ˙q2
C21(q, ˙q) = m2l1lc2 sin(q2) ˙q1
C22(q, ˙q) = 0
characterizes the centrifugal and Coriolis forces, C(q, ˙q) ˙q. With this def-
inition of C(q, ˙q), is 1
2 ˙M(q) −C(q, ˙q) skew-symmetric?
Does it hold that ˙qT 
1
2 ˙M(q) −C(q, ˙q)

˙q = 0 ? Explain.

Part II
Position Control

Introduction to Part II
Depending on their application, industrial robot manipulators may be classi-
ﬁed into two categories: the ﬁrst is that of robots which move freely in their
workspace (i.e. the physical space reachable by the end-eﬀector) thereby un-
dergoing movements without physical contact with their environment; tasks
such as spray-painting, laser-cutting and welding may be performed by this
type of manipulator. The second category encompasses robots which are de-
signed to interact with their environment, for instance, by applying a comply-
ing force; tasks in this category include polishing and precision assembling.
In this textbook we study exclusively motion controllers for robot manip-
ulators that move about freely in their workspace.
For clarity of exposition, we shall consider robot manipulators provided
with ideal actuators, that is, actuators with negligible dynamics or in other
words, that deliver torques and forces which are proportional to their inputs.
This idealization is common in many theoretical works on robot control as well
as in most textbooks on robotics. On the other hand, the recent technological
developments in the construction of electromechanical actuators allow one to
rely on direct-drive servomotors, which may be considered as ideal torque
sources over a wide range of operating points. Finally, it is important to
mention that even though in this textbook we assume that the actuators are
ideal, most studies of controllers that we present in the sequel may be easily
extended, by carrying out minor modiﬁcations, to the case of linear actuators
of the second order; such is the case of DC motors.
Motion controllers that we study are classiﬁed into two main parts based on
the control goal. In this second part of the book we study position controllers
(set-point controllers) and in Part III we study motion controllers (tracking
controllers).
Consider the dynamic model of a robot manipulator with n DOF, rigid
links, no friction at the joints and with ideal actuators, (3.18), and which we
recall below for convenience:

136
Part II
M(q)¨q + C(q, ˙q) ˙q + g(q) = τ .
(II.1)
where M(q) ∈IRn×n is the inertia matrix, C(q, ˙q) ˙q ∈IRn is the vector of
centrifugal and Coriolis forces, g(q) ∈IRn is the vector of gravitational forces
and torques and τ ∈IRn is a vector of external forces and torques applied
at the joints. The vectors q, ˙q, ¨q ∈IRn denote the position, velocity and joint
acceleration respectively.
In terms of the state vector

qT
˙qT T these equations take the form
d
dt
⎡
⎣
q
˙q
⎤
⎦=
⎡
⎣
˙q
M(q)−1 [τ(t) −C(q, ˙q) ˙q −g(q)]
⎤
⎦.
The problem of position control of robot manipulators may be formulated
in the following terms. Consider the dynamic equation of an n-DOF robot,
(II.1). Given a desired constant position (set-point reference) qd, we wish to
ﬁnd a vectorial function τ such that the positions q associated with the robot’s
joint coordinates tend to qd accurately.
In more formal terms, the objective of position control consists in ﬁnding
τ such that
lim
t→∞q(t) = qd
where qd ∈IRn is a given constant vector which represents the desired joint
positions.
The way that we evaluate whether a controller achieves the control ob-
jective is by studying the asymptotic stability of the origin of the closed-loop
system in the sense of Lyapunov (cf. Chapter 2). For such purposes, it appears
convenient to rewrite the position control objective as
lim
t→∞˜q(t) = 0
where ˜q ∈IRn stands for the joint position errors vector or is simply called
position error, and is deﬁned by
˜q(t) := qd −q(t) .
Then, we say that the control objective is achieved, if for instance the
origin of the closed-loop system (also referred to as position error dynamics)
in terms of the state, i.e. [˜qT ˙qT ]T = 0 ∈IR2n, is asymptotically stable.
The computation of the vector τ involves, in general, a vectorial nonlinear
function of q, ˙q and ¨q. This function is called the “control law” or simply,
“controller”. It is important to recall that robot manipulators are equipped
with sensors to measure position and velocity at each joint, hence, the vectors
q and ˙q are assumed to be measurable and may be used by the controllers.
In general, a control law may be expressed as

Introduction to Part II
137
τ = τ (q, ˙q, ¨q, qd, M(q), C(q, ˙q), g(q)) .
(II.2)
However, for practical purposes it is desirable that the controller does not
depend on the joint acceleration ¨q, because measurement of acceleration is
unusual and accelerometers are typically highly sensitive to noise.
Figure II.1 presents the block-diagram of a robot in closed loop with a
position controller.
ROBOT
CONTROLLER
τ
q
˙q
qd
Figure II.1. Position control: closed-loop system
If the controller (II.2) does not depend explicitly on M(q), C(q, ˙q) and
g(q), it is said that the controller is not “model-based”. This terminology is,
however, a little misfortunate since there exist controllers, for example of the
PID type (cf. Chapter 9), whose design parameters are computed as functions
of the model of the particular robot for which the controller is designed. From
this viewpoint, these controllers are model-dependent or model-based.
In this second part of the textbook we carry out stability analyses of
a group of position controllers for robot manipulators. The methodology to
analyze the stability may be summarized in the following steps.
1. Derivation of the closed-loop dynamic equation. This equation is obtained
by replacing the control action τ (cf. Equation II.2 ) in the dynamic model
of the manipulator (cf. Equation II.1). In general, the closed-loop equation
is a nonautonomous nonlinear ordinary diﬀerential equation.
2. Representation of the closed-loop equation in the state-space form, i.e.
d
dt

qd −q
˙q

= f(q, ˙q, qd, M(q), C(q, ˙q), g(q)) .
(II.3)
This closed-loop equation may be regarded as a dynamic system whose
inputs are qd, ˙qd and ¨qd, and with outputs, the state vectors ˜q = qd −q
and ˙q. Figure II.2 shows the corresponding block-diagram.
3. Study of the existence and possible unicity of equilibrium for the closed-
loop equation. For this, we rewrite the closed-loop equation (II.3) in the
state-space form choosing as the state, the position error and the velocity.

138
Part II
CONTROLLER
ROBOT
+
qd
˜q
˙q
Figure II.2. Set-point control closed-loop system. Input–output representation.
That is, let ˜q := qd−q denote the state of the closed-loop equation. Then,
(II.3) becomes
d
dt
 ˜q
˙q

= ˜f(˜q, ˙q)
(II.4)
where ˜f is obtained by replacing q with qd −˜q. Note that the closed-loop
system equation is autonomous since qd is constant.
Thus, for Equation (II.4) we want to verify that the origin, [˜qT ˙qT ]T =
0 ∈IR2n is an equilibrium and whether it is unique.
4. Proposal of a Lyapunov function candidate to study the stability of the
origin for the closed-loop equation, by using the Theorems 2.2, 2.3, 2.4
and 2.7. In particular, veriﬁcation of the required properties, i.e. positivity
and negativity of the time derivative.
5. Alternatively to step 4, in the case that the proposed Lyapunov function
candidate appears to be inappropriate (that is, if it does not satisfy all of
the required conditions) to establish the stability properties of the equilib-
rium under study, we may use Lemma 2.2 by proposing a positive deﬁnite
function whose characteristics allow one to determine the qualitative be-
havior of the solutions of the closed-loop equation.
It is important to underline that if Theorems 2.2, 2.3, 2.4, 2.7 and Lemma
2.2 do not apply because one of their conditions does not hold, it does not
mean that the control objective cannot be achieved with the controller under
analysis but that the latter is inconclusive. In this case, one should look for
other possible Lyapunov function candidates such that one of these results
holds.
The rest of this second part of the textbook is divided into four chapters.
The controllers that we present may be called “conventional” since they are
commonly used in industrial robots. These controllers are:
•
Proportional control plus velocity feedback and Proportional Derivative
(PD) control;
•
PD control with gravity compensation;

Bibliography
139
•
PD control with desired gravity compensation;
•
Proportional Integral Derivative (PID) control.
Bibliography
Among books on robotics, robot dynamics and control that include the study
of tracking control systems we mention the following:
•
Paul R., 1982, “Robot manipulators: Mathematics programming and con-
trol”, MIT Press, Cambridge, MA.
•
Asada H., Slotine J. J., 1986, “Robot analysis and control ”, Wiley, New
York.
•
Fu K., Gonzalez R., Lee C., 1987, “Robotics: Control, sensing, vision and
intelligence”, McGraw–Hill.
•
Craig J., 1989, “Introduction to robotics: Mechanics and control”, Addison-
Wesley, Reading, MA.
•
Spong M., Vidyasagar M., 1989, “Robot dynamics and control”, Wiley,
New York.
•
Yoshikawa T., 1990, “Foundations of robotics: Analysis and control”, The
MIT Press.
•
Spong M., Lewis F. L., Abdallah C. T., 1993, “Robot control: Dynamics,
motion planning and analysis”, IEEE Press, New York.
•
Sciavicco L., Siciliano B., 2000, “Modeling and control of robot manipula-
tors”, Second Edition, Springer-Verlag, London.
Textbooks addressed to graduate students are (Sciavicco and Siciliano,
2000) and
•
Lewis F. L., Abdallah C. T., Dawson D. M., 1993, “Control of robot ma-
nipulators”, Macmillan Pub. Co.
•
Qu Z., Dawson D. M., 1996, “Robust tracking control of robot manipula-
tors”, IEEE Press, New York.
•
Arimoto S., 1996, “Control theory of non–linear mechanical systems”, Ox-
ford University Press, New York.
More advanced monographs addressed to researchers and texts for gradu-
ate students are
•
Ortega R., Lor´ıa A., Nicklasson P. J., Sira-Ram´ırez H., 1998, “Passivity-
based control of Euler-Lagrange Systems Mechanical, Electrical and Elec-
tromechanical Applications”, Springer-Verlag: London, Communications
and Control Engg. Series.

140
Part II
•
Canudas C., Siciliano B., Bastin G. (Eds), 1996, “Theory of robot control”,
Springer-Verlag: London.
•
de Queiroz M., Dawson D. M., Nagarkatti S. P., Zhang F., 2000, “Lyapunov–
based control of mechanical systems”, Birkh¨auser, Boston, MA.
A particularly relevant work on robot motion control and which covers in
a uniﬁed manner most of the controllers that are studied in this part of the
text, is
•
Wen J. T., 1990, “A uniﬁed perspective on robot control: The energy
Lyapunov function approach”, International Journal of Adaptive Control
and Signal Processing, Vol. 4, pp. 487–500.

6
Proportional Control plus Velocity Feedback
and PD Control
Proportional control plus velocity feedback is the simplest closed-loop con-
troller that may be used to control robot manipulators. The conceptual ap-
plication of this control strategy is common in angular position control of DC
motors. In this application, the controller is also known as proportional control
with tachometric feedback. The equation of proportional control plus velocity
feedback is given by
τ = Kp˜q −Kv ˙q
(6.1)
where Kp, Kv ∈IRn×n are symmetric positive deﬁnite matrices preselected by
the practitioner engineer and are commonly referred to as position gain and
velocity (or derivative) gain, respectively. The vector qd ∈IRn corresponds to
the desired joint position, and the vector ˜q = qd −q ∈IRn is called position
error. Figure 6.1 presents a block-diagram corresponding to the control system
formed by the robot under proportional control plus velocity feedback.
˙q
q
ROBOT
qd
Σ
Σ
Kp
Kv
τ
Figure 6.1. Block-diagram: Proportional control plus velocity feedback
Proportional Derivative (PD) control is an immediate extension of propor-
tional control plus velocity feedback (6.1). As its name suggests, the control
law is not only composed of a proportional term of the position error as in the
case of proportional control, but also of another term which is proportional
to the derivative of the position, i.e. to its velocity error, ˙˜q. The PD control

142
6 Proportional Control plus Velocity Feedback and PD Control
law is given by
τ = Kp˜q + Kv ˙˜q
(6.2)
where Kp, Kv ∈IRn×n are also symmetric positive deﬁnite and selected by
the designer. In Figure 6.2 we present the block-diagram corresponding to the
control system composed of a PD controller and a robot.
Kp
Kv
τ
ROBOT
˙q
q
qd
˙qd
Σ
Σ
Σ
Figure 6.2. Block-diagram: PD control
So far no restriction has been imposed on the vector of desired joint posi-
tions qd to deﬁne the proportional control law plus velocity feedback and the
PD control law. This is natural, since the name that we give to a controller
must characterize only its structure and should not be reference-dependent.
In spite of the veracity of the statement above, in the literature on robot
control one ﬁnds that the control laws (6.1) and (6.2) are indistinctly called
“PD control”. The common argument in favor of this ambiguous terminology
is that in the particular case when the vector of desired positions qd is re-
stricted to be constant, then it is clear from the deﬁnition of ˜q that ˙˜q = −˙q
and therefore, control laws (6.1) and (6.2) become identical.
With the purpose of avoiding any polemic about these observations, and
to observe the use of the common nomenclature from now on, both control
laws (6.1) and (6.2), are referred to in the sequel as “PD control”.
In real applications, PD control is local in the sense that the torque or force
determined by such a controller when applied at a particular joint, depends
only on the position and velocity of the joint in question and not on those of
the other joints. Mathematically, this is translated by the choice of diagonal
design matrices Kp and Kv.
PD control, given by Equation (6.1), requires the measurement of positions
q and velocities ˙q as well as speciﬁcation of the desired joint position qd (cf.
Figure 6.1). Notice that it is not necessary to specify the desired velocity and
acceleration, ˙qd and ¨qd.

6.1 Robots without Gravity Term
143
We present next an analysis of PD control for n-DOF robot manipulators.
The behavior of an n-DOF robot in closed-loop with PD control is deter-
mined by combining the model Equation (II.1) with the control law (6.1),
M(q)¨q + C(q, ˙q) ˙q + g(q) = Kp˜q −Kv ˙q
(6.3)
or equivalently, in terms of the state vector

˜qT
˙˜q
T T
d
dt
⎡
⎣
˜q
˙˜q
⎤
⎦=
⎡
⎣
˙˜q
¨qd −M(q)−1 [Kp˜q −Kv ˙q −C(q, ˙q) ˙q −g(q)]
⎤
⎦
which is a nonlinear nonautonomous diﬀerential equation. In the rest of this
section we assume that the vector of desired joint positions, qd, is constant.
Under this condition, the closed-loop equation may be rewritten in terms of
the new state vector
˜qT
˙qT T , as
d
dt
⎡
⎣
˜q
˙q
⎤
⎦=
⎡
⎣
−˙q
M(q)−1 [Kp˜q −Kv ˙q −C(q, ˙q) ˙q −g(q)]
⎤
⎦.
(6.4)
Note that the closed-loop diﬀerential equation is still nonlinear but au-
tonomous. This is because qd is constant. The previous equation however, may
have multiple equilibria. If such is the case, they are given by
˜qT
˙qT T =
[sT
0T ]T where s ∈IRn is solution of
Kps −g(qd −s) = 0 .
(6.5)
Obviously, if the manipulator model does not include the gravitational
torques term g(q), then the only equilibrium is the origin of the state space,
i.e. [˜qT ˙qT ]T = 0 ∈IR2n. Also, if g(q) is independent of q, i.e. if g(q) = g
constant, then s = K−1
p g is the only solution.
Notice that Equation (6.5) is in general nonlinear in s due to the gravi-
tational term g(qd −s). For this reason, and given the nonlinear nature of
g(qd −s), derivation of the explicit solutions of s is in general relatively com-
plex.
In the future sections we treat separately the cases in which the robot
model contains and does not contain the vector of gravitational torques g(q).
6.1 Robots without Gravity Term
In this section we consider robots whose dynamic model does not contain the
gravitational g(q), that is

144
6 Proportional Control plus Velocity Feedback and PD Control
M(q)¨q + C(q, ˙q) ˙q = τ.
Robots that are described by this model are those which move only on
the horizontal plane, as well as those which are mechanically designed in a
speciﬁc convenient way.
Assuming that the desired joint position qd is constant, the closed-loop
Equation (6.4) becomes (with g(q) = 0),
d
dt
⎡
⎣
˜q
˙q
⎤
⎦=
⎡
⎣
−˙q
M(qd −˜q)−1 [Kp˜q −Kv ˙q −C(qd −˜q, ˙q) ˙q]
⎤
⎦
(6.6)
which, since qd is constant, represents an autonomous diﬀerential equation.
Moreover, the origin
˜qT
˙qT T = 0 is the only equilibrium of this equation.
To study the stability of the equilibrium we appeal to Lyapunov’s direct
method, to which the reader has already been introduced in Section 2.3.4 of
Chapter 2. Speciﬁcally, we use La Salle’s Theorem 2.7 to show asymptotic
stability of the equilibrium (origin).
Consider the following Lyapunov function candidate
V (˜q, ˙q) = 1
2
⎡
⎣
˜q
˙q
⎤
⎦
T⎡
⎣
Kp
0
0
M(qd −˜q)
⎤
⎦
⎡
⎣
˜q
˙q
⎤
⎦
= 1
2 ˙qTM(q) ˙q + 1
2 ˜qTKp˜q .
Notice that this function is positive deﬁnite since M(q) as well as Kp are
positive deﬁnite matrices.
The total derivative of V (˜q, ˙q) yields
˙V (˜q, ˙q) = ˙qTM(q)¨q + 1
2 ˙qT ˙M(q) ˙q + ˜qTKp ˙˜q.
Substituting M(q)¨q from the closed-loop Equation (6.6), we obtain
˙V (˜q, ˙q) = −˙qTKv ˙q
= −
⎡
⎣
˜q
˙q
⎤
⎦
T⎡
⎣
0
0
0
Kv
⎤
⎦
⎡
⎣
˜q
˙q
⎤
⎦≤0,
where we canceled the term ˙qT
1
2 ˙M −C

˙q by virtue of Property 4.2.7 and
we used the fact that ˙˜q = −˙q since qd is a constant vector.

6.1 Robots without Gravity Term
145
From this and the fact that ˙V (˜q, ˙q) ≤0 we conclude that the function
V (˜q, ˙q) is a Lyapunov function. From Theorem 2.3 we also conclude that the
origin is stable and, moreover, that the solutions ˜q(t) and ˙q(t) are bounded.
Since the closed-loop Equation (6.6) is autonomous, we may try to apply
La Salle’s theorem (Theorem 2.7) to analyze the global asymptotic stability
of the origin.
To that end, notice that here the set Ωis given by
Ω=

x ∈IR2n : ˙V (x) = 0

=

x =
 ˜q
˙q

∈IR2n : ˙V (˜q, ˙q) = 0
&
= {˜q ∈IRn, ˙q = 0 ∈IRn} .
Observe also that ˙V (˜q, ˙q) = 0 if and only if ˙q = 0. For a solution x(t) to
belong to Ωfor all t ≥0, it is necessary and suﬃcient that ˙q(t) = 0 for all
t ≥0. Therefore, it must also hold that ¨q(t) = 0 for all t ≥0. Considering all
this, we conclude from the closed-loop equation (6.6), that if x(t) ∈Ωfor all
t ≥0 then,
0 = M(qd −˜q(t))−1Kp˜q(t) .
Since M(qd −˜q(t))−1 and Kp are positive deﬁnite their matrix product
is nonsingular1, this implies that ˜q(t) = 0 for all t ≥0 and therefore,
˜q(0)T
˙q(0)T T = 0 ∈IR2n is the only initial condition in Ωfor which x(t) ∈
Ωfor all t ≥0. Thus, from La Salle’s theorem (Theorem 2.7), this is enough
to establish global asymptotic stability of the origin,
˜qT
˙qT T = 0 ∈IR2n
and consequently,
lim
t→∞˜q(t) = lim
t→∞[ qd −q(t) ] = 0
lim
t→∞˙q(t) = 0 .
In other words the position control objective is achieved.
It is interesting to emphasize at this point, that the closed-loop equation
(6.6) is exactly the same as the one which will be derived for the so-called PD
controller with gravity compensation and which we study in Chapter 7. In
that chapter we present an alternative analysis for the asymptotic stability of
the origin, by use of another Lyapunov function which does not appeal to La
Salle’s theorem. Certainly, this alternative analysis is also valid for the study
of (6.6).
1 Note that we are not claiming that the matrix product M( d −˜ (t))−1Kp is
positive deﬁnite. This is not true in general. We are only using the fact that this
matrix product is nonsingular.

146
6 Proportional Control plus Velocity Feedback and PD Control
6.2 Robots with Gravity Term
The behavior of the control system under PD control (cf. Equation 6.1) for
robots whose models include explicitly the vector of gravitational torques g(q)
and assuming that qd is constant, is determined by (6.4), which we repeat
below, i.e.
d
dt
⎡
⎣
˜q
˙q
⎤
⎦=
⎡
⎣
−˙q
M(q)−1 [Kp˜q −Kv ˙q −C(q, ˙q) ˙q −g(q)]
⎤
⎦.
(6.7)
The study of this equation is somewhat more complex than that for the
case when g(q) = 0.
In this section we analyze closed-loop Equation (6.7), and speciﬁcally, we
address the following issues:
•
unicity of the equilibrium;
•
boundedness of solutions.
The study of this section is limited to robots having only revolute joints.
6.2.1 Unicity of the Equilibrium
In general, system (6.7) may have several equilibrium points. This is illustrated
by the following example.
Example 6.1. Consider the model of an ideal pendulum, such as the
one studied in Example 2.2 (cf. page 30)
J ¨q + mgl sin(q) = τ .
In this case the expression (6.5) takes the form
kps −mgl sin(qd −s) = 0 .
(6.8)
For the sake of illustration consider the following numerical values
J = 1
mgl = 1
kp = 0.25 qd = π/2.
Either by a graphical method or using numerical algorithms, it
may be veriﬁed that Equation (6.8) has exactly three solutions in
s whose approximate values are: 1.25 (rad), −2.13 (rad) and −3.59
(rad). This means that the closed-loop system under PD control for
the ideal pendulum, has the equilibria

6.2 Robots with Gravity Term
147

˜q
˙q

∈

1.25
0

,

−2.13
0

,

−3.56
0
&
.
♦
Multiplicity of equilibria certainly poses a problem for the study of (global)
asymptotic stability; hence, it is desirable to avoid such a situation. For the
case of robots having only revolute joints we show below that, by choosing Kp
suﬃciently large, one may guarantee unicity of the equilibrium of the closed-
loop Equation (6.7). To that end, we use the contraction mapping theorem
presented in this textbook as Theorem 2.1.
The equilibria of the closed-loop Equation (6.7) satisfy
˜qT ˙qT T =

sT
0T T ,
where s ∈IRn is solution of
s = K−1
p g(qd −s)
= f(s, qd) .
If the function f(s, qd) satisﬁes the condition of the contraction mapping
theorem (Theorem 2.1) then the equation s = f(s, qd) has a unique solution
s∗and consequently, the unique equilibrium of the closed-loop Equation (6.7)
is
˜qT ˙qT T =

s∗T
0T T
.
Now, notice that for all vectors x, y, qd ∈IRn,
∥f(x, qd) −f(y, qd)∥=
K−1
p g(qd −x) −K−1
p g(qd −y)

=
K−1
p
{g(qd −x) −g(qd −y)}

≤λMax{K−1
p } ∥g(qd −x) −g(qd −y)∥.
On the other hand, using the fact that λMax{A−1} = 1/λmin{A} for any
symmetric positive deﬁnite matrix A, and Property 4.3.3 that guarantees the
existence of a positive constant kg such that ∥g(x) −g(y)∥≤kg ∥x −y∥, we
get
∥f(x, qd) −f(y, qd)∥≤
kg
λmin{Kp} ∥x −y∥
hence, invoking the contraction mapping theorem, a suﬃcient condition for
the unicity of the solution of f(s, qd) −s = K−1
p g(qd −s) −s = 0 and
consequently, for the unicity of the equilibrium of the closed-loop equation, is
that Kp be selected to satisfy λmin{Kp} > kg.

148
6 Proportional Control plus Velocity Feedback and PD Control
6.2.2 Arbitrarily Bounded Position and Velocity Error
We present next a qualitative study of the behavior of solutions of the
closed-loop Equation (6.7) for the case where Kp is not restricted to satisfy
λmin{Kp} > kg, but it is enough that Kp be positive deﬁnite.
For the purposes of the result presented here we make use of Lemma 2.2,
which, even though it does not establish any stability statement, enables one
to make conclusions about the boundedness of trajectories and eventually
about the convergence of some of them to zero. We assume that all joints are
revolute.
Deﬁne the following non-negative function
V (˜q, ˙q) = K(q, ˙q) + U(q) −kU + 1
2 ˜qTKp˜q
where K(q, ˙q) and U(q) denote the kinetic and potential energy functions of
the robot, and the constant kU is deﬁned as (cf. Property 4.3)
kU = min
q {U(q)} .
The function V (˜q, ˙q) may be expressed in the form
V (˜q, ˙q) =
⎡
⎣
˜q
˙q
⎤
⎦
T
P
$
%"
#
⎡
⎣
1
2Kp
0
0
1
2M(qd −˜q)
⎤
⎦
⎡
⎣
˜q
˙q
⎤
⎦
+ U(qd −˜q) −kU
"
#$
%
h
≥0.
(6.9)
or equivalently, as
V (˜q, ˙q) = 1
2 ˙qTM(q) ˙q + 1
2 ˜qTKp˜q + U(q) −kU ≥0 .
The derivative of V (˜q, ˙q) with respect to time yields
˙V (˜q, ˙q) = ˙qTM(q)¨q + 1
2 ˙qT ˙M(q) ˙q + ˜qTKp ˙˜q + ˙qT g(q)
(6.10)
where we used (3.20), i.e. g(q) =
∂
∂q U(q). Factoring out M(q)¨q from the
closed-loop equation (6.3) and substituting in (6.10),
˙V (˜q, ˙q) = ˙qTKp˜q −˙qTKv ˙q + ˜qTKp ˙˜q ,
(6.11)
where the term ˙qT
1
2 ˙M −C

˙q has been canceled by virtue of the Property
4.2. Recalling that the vector qd is constant and that ˜q = qd−q, then ˙˜q = −˙q.
Taking this into account Equation (6.11) boils down to

6.2 Robots with Gravity Term
149
˙V (˜q, ˙q) = −˙qT
Q
$%"#
Kv ˙q
= −
⎡
⎣
˜q
˙q
⎤
⎦
T⎡
⎣
0
0
0
Kv
⎤
⎦
⎡
⎣
˜q
˙q
⎤
⎦≤0 .
(6.12)
Using V (˜q, ˙q) and ˙V (˜q, ˙q) given in (6.9) and (6.12) respectively and in-
voking Lemma 2.2, we conclude that ˙q(t) and ˜q(t) are bounded for all t and
moreover, the velocities vector is square integrable, that is
 ∞
0
∥˙q(t)∥2dt < ∞.
(6.13)
Moreover, as we show next, we can determine the explicit bounds for
the position and velocity errors, ˜q and ˙q. Considering that V (˜q, ˙q) is a non-
negative function and non-increasing along the trajectories ( ˙V (˜q, ˙q) ≤0), we
have
0 ≤V (˜q(t), ˙q(t)) ≤V (˜q(0), ˙q(0))
for all t ≥0. Consequently, considering the deﬁnition of V (˜q, ˙q) it readily
follows that
1
2 ˜q(t)TKp˜q(t) ≤V (˜q(0), ˙q(0))
1
2 ˙q(t)TM(q(t)) ˙q(t) ≤V (˜q(0), ˙q(0))
for all t ≥0, from which we ﬁnally conclude that the following bounds:
∥˜q(t)∥2 ≤2V (˜q(0), ˙q(0))
λmin{Kp}
= ˙q(0)TM(q(0)) ˙q(0) + ˜q(0)TKp˜q(0) + 2U(q(0)) −2kU
λmin{Kp}
(6.14)
∥˙q(t)∥2 ≤2V (˜q(0), ˙q(0))
λmin{M(q)}
= ˙q(0)TM(q(0)) ˙q(0) + ˜q(0)TKp˜q(0) + 2U(q(0)) −2kU
λmin{M(q)}
(6.15)
hold for all t ≥0.
We can also show that actually limt→∞˙q(t) = 0. To that end, we use (6.3)
to obtain
¨q = M(q)−1 [Kp˜q −Kv ˙q −C(q, ˙q) ˙q −g(q)] .
(6.16)

150
6 Proportional Control plus Velocity Feedback and PD Control
Since ˙q(t) and ˜q(t) are bounded functions, then C(q, ˙q) ˙q and g(q) are
also bounded, this in view of Properties 4.2 and 4.3. On the other hand, since
M(q)−1 is bounded (from Property 4.1), we conclude from (6.16) that ¨q(t) is
also bounded. This, and (6.13) imply in turn that (by Lemma 2.2),
lim
t→∞˙q(t) = 0 .
Nevertheless, it is important to underline that the limit above does not
guarantee that q(t) →qd as t →∞and as a matter of fact, not even that2
q(t) →constant as t →∞.
Example 6.2. Consider again the ideal pendulum from Example 6.1
J ¨q + mgl sin(q) = τ,
where we clearly identify M(q) = J and g(q) = mgl sin(q). As was
shown in Example 2.2 (cf. page 30), the potential energy function is
U(q) = mgl[1 −cos(q)] .
Since minq{U(q)} = 0 the constant kU is zero.
Consider next the numerical values from Example 6.1
J = 1
mgl = 1
kp = 0.25
kv = 0.50
qd = π/2 .
Assume that we apply the PD controller to drive the ideal pendu-
lum from the initial conditions q(0) = 0 and ˙q(0) = 0.
According to the bounds (6.14) and (6.15) and considering the
information above, we get
˜q2(t) ≤˜q2(0) = 2.46 rad2
(6.17)
˙q2(t) ≤kp
J ˜q2(0) = 0.61
rad
s
2
(6.18)
for all t ≥0. Figures 6.3 and 6.4 show graphs of ˜q(t)2 and ˙q(t)2 respec-
tively, obtained in simulations. One can clearly see from these plots
that both variables satisfy the inequalities (6.17) and (6.18). Finally,
it is interesting to observe from these plots that limt→∞˜q2(t) = 1.56
and limt→∞˙q2(t) = 0 and therefore,
lim
t→∞

˜q(t)
˙q(t)

=

1.25
0

.
That is, the solutions tend to one of the three equilibria determined
in Example 6.1.
♦
2 Counter example: For x(t) = ln(t + 1) we have limt→∞˙x(t) = 0; however,
limt→∞x(t) = ∞!

6.2 Robots with Gravity Term
151
0
5
10
15
20
0
1
2
3
˜q(t)2 [rad2]
t [s]
.....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Figure 6.3. Graph of ˜q(t)2
0
5
10
15
20
0.00
0.02
0.04
0.06
0.08
˙q(t)2 [( rad
s )2]
t [s]
.............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Figure 6.4. Graph of ˙q(t)2
To close this section we present next the results we have obtained in ex-
periments with the Pelican prototype under PD control.
Example 6.3. Consider the 2-DOF prototype robot studied in Chapter
5. For ease of reference, we rewrite below the vector of gravitational
torques g(q) from Section 5.3.2, and its elements are
g1(q) = (m1lc1 + m2l1)g sin(q1) + m2glc2 sin(q1 + q2)
g2(q) = m2glc2 sin(q1 + q2).
The control objective consists in making

152
6 Proportional Control plus Velocity Feedback and PD Control
lim
t→∞q(t) = qd =

π/10
π/30

[rad].
It may easily be veriﬁed that g(qd) ̸= 0. Therefore, the origin
˜qT
˙qT T = 0 ∈IR4 of the closed-loop equation with the PD con-
troller, is not an equilibrium. This means that the control objective
cannot be achieved using PD control. However, with the purpose of
illustrating the behavior of the system we present next some experi-
mental results.
Consider the PD controller
τ = Kp˜q −Kv ˙q
with the following numerical values
Kp =

30
0
0
30

[Nm/rad] ,
Kv =

7
0
0
3

[Nms/rad] .
0.0
0.5
1.0
1.5
2.0
−0.1
0.0
0.1
0.2
0.3
0.4
[rad]
˜q1
0.1309
0.0174
˜q2
t [s]
.................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 6.5. Graph of the position errors ˜q1 and ˜q2
The initial conditions are ﬁxed at q(0) = 0 and ˙q(0) = 0. The
experimental results are presented in Figure 6.5 where we show the
two components of the position error, ˜q. One may appreciate that
limt→∞˜q1(t) = 0.1309 and limt→∞˜q2(t) = 0.0174 therefore, as was
expected, the control objective is not achieved. Friction at the joints
may also aﬀect the resulting position error.
♦

Problems
153
6.3 Conclusions
We may summarize what we have learned in this chapter, in the following
ideas. Consider the PD controller of n-DOF robots. Assume that the vector
of desired positions qd is constant.
•
If the vector of gravitational torques g(q) is absent in the robot model,
then the origin of the closed-loop equation, expressed in terms of the state
vector
˜qT
˙qT T , is globally asymptotically stable. Consequently, we have
limt→∞˜q(t) = 0.
•
For robots with only revolute joints, if the vector of gravitational torques
g(q) is present in the robot model, then the origin of the closed-loop equa-
tion expressed in terms of the state vector
˜qT
˙qT T , is not necessarily
an equilibrium. However, the closed-loop equation always has equilibria.
In addition, if λmin{Kp} > kg, then the closed-loop equation has a unique
equilibrium. Finally, for any matrix Kp = KT
p > 0, it is guaranteed that
the position and velocity errors, ˜q and ˙q, are bounded. Moreover, the
vector of joint velocities ˙q goes asymptotically to zero.
Bibliography
The analysis of global asymptotic stability of PD control for robots without
the gravitational term (i.e. with g(q) ≡0), is identical to PD control with
compensation of gravity and which was originally presented in
•
Takegaki M., Arimoto S., 1981, “A new feedback method for dynamic con-
trol of manipulators”, Transactions ASME, Journal of Dynamic Systems,
Measurement and Control, Vol. 105, p. 119–125.
Also, the same analysis for the PD control of robots without the gravita-
tional term may be consulted in the texts
•
Spong M., Vidyasagar M., 1989, “Robot dynamics and control”, John Wi-
ley and Sons.
•
Yoshikawa T., 1990, “Foundations of robotics: Analysis and control”, The
MIT Press.
Problems
1. Consider the model of the ideal pendulum studied in Example 6.1
J ¨q + mgl sin(q) = τ

154
6 Proportional Control plus Velocity Feedback and PD Control
with the numerical values
J = 1,
mgl = 1,
qd = π/2
and under PD control. In Example 6.1 we established that the closed-loop
equation possesses three equilibria for kp = 0.25.
a) Determine the value of the constant kg (cf. Property 4.3).
b) Determine a value of kp for which there exists a unique equilibrium.
c) Use the value of kp from the previous item and the contraction map-
ping theorem (Theorem 2.1) to obtain an approximate numerical value
of the unique equilibrium.
Hint: The equilibrium is [˜q
˙q]T = [x∗0]T , where x∗= limn→∞x(n)
with
x(n) = mgl
kp
sin(qd −x(n −1))
and, for instance x(−1) = 0.
2. Consider the model of the ideal pendulum studied in the Example 6.1
J ¨q + mgl sin(q) = τ
with the following numerical values,
J = 1,
mgl = 1,
qd = π/2 .
Consider the PD control with initial conditions q(0) = 0 and ˙q(0) = 0.
From this, we have ˜q(0) = π/2.
a) Obtain kp which guarantees that
| ˙q(t)| ≤c1
∀t ≥0
where c1 > 0. Compute a numerical value for kp with c1 = 1.
Hint: Use (6.15).
3. Consider the PD control of the 2-DOF robot studied in Example 6.3. The
experimental results in this example were obtained with Kp = diag {30}
and the following numerical values
l1 = 0.26
lc1 = 0.0983
lc2 = 0.0229
m1 = 6.5225
m2 = 2.0458
g = 9.81
qd1 = π/10
qd2 = π/30
Figure 6.5 shows that limt→∞˜q1(t) = 0.1309 and limt→∞˜q2(t) = 0.0174.

Problems
155
a) Show that
˜qT
˙qT T =
˜qT
0T T with
˜q =

˜q1
˜q2

=

0.1309
0.0174

is an equilibrium of the closed-loop equation. Explain.
4. Consider the 2-DOF robot from Chapter 5 and illustrated in Figure 5.2.
The vector of gravitational torques g(q) for this robot is presented in
Section 5.3.2, and its components are
g1(q) = (m1lc1 + m2l1)g sin(q1) + m2glc2 sin(q1 + q2)
g2(q) = m2glc2 sin(q1 + q2) .
Consider PD control. In view of the presence of g(q), in general the origin
˜qT
˙qT T = 0 ∈IR4 of the closed-loop equation is not an equilibrium.
However, for some values of qd, the origin happens to be an equilibrium.
a) Determine all possible vectors qd = [qd1 qd2]T for which the origin of
the closed-loop equation is an equilibrium.
5. Consider the 3-DOF Cartesian robot from Example 3.4 (cf. page 69) il-
lustrated in Figure 3.5. It dynamic model is given by
(m1 + m2 + m3)¨q1 + (m1 + m2 + m3)g = τ1
(m1 + m2)¨q2 = τ2
m1¨q3 = τ3.
Consider the PD control law
τ = Kp˜q −Kv ˙q
where qd is constant and Kp, Kv are diagonal positive deﬁnite matrices.
a) Obtain M(q), C(q, ˙q) and g(q). Verify that M(q) = M is a constant
diagonal matrix. Verify that g(q) = g is a constant vector.
b) Deﬁne ˜q = [˜q1 ˜q2 ˜q3]T . Obtain the closed-loop equation.
c) Verify that the closed-loop equation has a unique equilibrium at
 ˜q
˙q

=

K−1
p g
0

.
d) Deﬁne z = ˜q−K−1
p g. Rewrite the closed-loop equation in terms of the
new state

zT
˙qT T . Verify that the origin is the unique equilibrium.
Show that the origin is a stable equilibrium.
Hint: Use the Lyapunov function,
V (z, ˙q) = 1
2 ˙qT ˙q + 1
2zTM −1Kpz .

156
6 Proportional Control plus Velocity Feedback and PD Control
e) Use La Salle’s theorem (Theorem 2.7) to show that moreover the origin
is globally asymptotically stable.
6. Consider the model of elastic-joint robots (3.27) and (3.28), but without
the gravitational term (g(q) = 0), that is,
M(q)¨q + C(q, ˙q) ˙q + K(q −θ) = 0
J¨θ −K(q −θ) = τ.
It is assumed that only the positions vector corresponding to the motor
shafts θ, is available for measurement as well as its corresponding velocities
˙θ. The goal is that q(t) →qd as t →∞for any constant qd.
The PD controller is in this case,
τ = Kp˜θ −Kv ˙θ
where ˜θ = qd −θ and Kp, Kv ∈IRn×n are symmetric positive deﬁnite
matrices.
a) Obtain the closed-loop equation in terms of the state vector

˜qT
˜θ
T
˙qT
˙θ
T T
where ˜q = qd −q. Verify that the origin is the unique
equilibrium.
b) Show that the origin is a stable equilibrium.
Hint: Use the following Lyapunov function
V (˜q, ˜θ, ˙q, ˙θ) = 1
2 ˙qTM(q) ˙q + 1
2
˙θ
TJ ˙θ
+ 1
2

˜θ −˜q
T
K

˜θ −˜q

+ 1
2
˜θ
TKp˜θ
and the skew-symmetry of 1
2 ˙M −C.
c) Use La Salle’s theorem (Theorem 2.7) to show also that the origin is
globally asymptotically stable.

7
PD Control with Gravity Compensation
As studied in Chapter 6, the position control objective for robot manipulators
may be achieved via PD control, provided that g(q) = 0 or, for a suitable
selection of qd. In this case, the tuning – for the purpose of stability – of
this controller is trivial since it is suﬃcient to select the design matrices Kp
and Kv as symmetric positive deﬁnite. Nevertheless, PD control does not
guarantee the achievement of the position control objective for manipulators
whose dynamic models contain the gravitational torques vector g(q), unless
the desired position qd is such that g(qd) = 0.
In this chapter we study PD control with gravity compensation, which
is able to satisfy the position control objective globally for n DOF robots;
moreover, its tuning is trivial. The formal study of this controller goes back
at least to 1981 and this reference is given at the end of the chapter. The
previous knowledge of part of the dynamic robot model to be controlled is
required in the control law, but in contrast to the PID controller which, under
the tuning procedure proposed in Chapter 9, needs information on M(q) and
g(q), the controller studied here only uses the vector of gravitational torques
g(q).
The PD control law with gravity compensation is given by
τ = Kp˜q + Kv ˙˜q + g(q)
(7.1)
where Kp, Kv ∈IRn×n are symmetric positive deﬁnite matrices. Notice that
the only diﬀerence with respect to the PD control law (6.2) is the added term
g(q). In contrast to the PD control law, which does not require any knowledge
of the structure of the robot model, the controller (7.1) makes explicit use of
partial knowledge of the manipulator model, speciﬁcally of g(q). However,
it is important to observe that for a given robot, the vector of gravitational
torques, g(q), may be obtained with relative ease since one only needs to
compute the expression corresponding to the potential energy U(q) of the
robot. The vector g(q) is obtained from (3.20) and is g(q) = ∂U(q)/∂q.

158
7 PD Control with Gravity Compensation
The control law (7.1) requires information on the desired position qd(t)
and on the desired velocity ˙qd(t) as well as measurement of the position q(t)
and the velocity ˙q(t) at each instant. Figure 7.1 shows the block-diagram
corresponding to the PD controller with gravity compensation.
g(q)
ROBOT
Σ
Kp
Kv
Σ
Σ
˙qd
qd
q
˙q
Figure 7.1. Block-diagram: PD control with gravity compensation
The equation that describes the behavior in closed loop is obtained by
combining Equations (II.1) and (7.1) to obtain
M(q)¨q + C(q, ˙q) ˙q + g(q) = Kp˜q + Kv ˙˜q + g(q) .
Or, in terms of the state vector

˜qT
˙˜q
T T
,
d
dt
⎡
⎣
˜q
˙˜q
⎤
⎦=
⎡
⎣
˙˜q
¨qd −M(q)−1 
Kp˜q + Kv ˙˜q −C(q, ˙q) ˙q

⎤
⎦.
A necessary and suﬃcient condition for the origin

˜qT
˙˜q
T T
= 0 ∈IR2n,
to be an equilibrium of the closed-loop equation is that the desired position
qd(t) satisﬁes
M(qd)¨qd + C(qd, ˙qd) ˙qd = 0
or equivalently, that qd(t) be a solution of
d
dt

qd
˙qd

=

˙qd
−M(qd)−1C(qd, ˙qd) ˙qd

for any initial condition

qd(0)T
˙qd(0)T T ∈IR2n .

7.1 Global Asymptotic Stability by La Salle’s Theorem
159
Obviously, in the case that the desired position qd(t) does not satisfy
the established condition, then the origin may not be an equilibrium of the
closed-loop equation and, therefore, we may not expect to satisfy the control
objective. That is, to drive the position error ˜q(t) asymptotically to zero. Nev-
ertheless, we may achieve the condition that the position error ˜q(t) becomes,
asymptotically, as small as wished if the matrices Kp and Kv are chosen suf-
ﬁciently “large”. For the formal proof of this claim, the reader is invited to
see the corresponding cited reference at the end of the chapter.
A suﬃcient condition for the origin

˜qT
˙˜q
T T
= 0 ∈IR2n to be the unique
equilibrium of the closed-loop equation is that the desired joint position qd
be a constant vector. In what is left of this chapter we assume that this is the
case.
As we show next, this controller achieves the position control objective,
that is,
lim
t→∞q(t) = qd
where qd ∈IRn is any constant vector.
7.1 Global Asymptotic Stability by La Salle’s Theorem
Considering the desired position qd as constant, the closed-loop equation may
be written in terms of the new state vector
˜qT
˙qT T as
d
dt
⎡
⎣
˜q
˙q
⎤
⎦=
⎡
⎣
−˙q
M(qd −˜q)−1 [Kp˜q −Kv ˙q −C(qd −˜q, ˙q) ˙q]
⎤
⎦
(7.2)
which, in view of the fact that qd is constant, is an autonomous diﬀerential
equation. The origin
˜qT
˙qT T = 0 ∈IR2n is the unique equilibrium of this
equation.
The stability analysis that we present next is taken from the literature.
The reader may also consult the references cited at the end of the chapter.
To study the stability of the origin as an equilibrium, we use Lyapunov’s
direct method, which has already been presented in Chapter 2. Speciﬁcally,
we use Theorem 2.2 to prove stability of the equilibrium (origin).
Consider the following Lyapunov function candidate
V (˜q, ˙q) = K(q, ˙q) + 1
2 ˜qTKp˜q
where K(q, ˙q) stands for the kinetic energy function of the robot, i.e. Equa-
tion (3.15). The function V (˜q, ˙q) is globally positive deﬁnite since the kinetic

160
7 PD Control with Gravity Compensation
energy K(q, ˙q) is positive deﬁnite in ˙q and on the other hand, Kp is a positive
deﬁnite matrix. Then, also the quadratic form ˜qTKp˜q is a positive deﬁnite
function of ˜q.
The Lyapunov function candidate may be written as
V (˜q, ˙q) = 1
2
⎡
⎣
˜q
˙q
⎤
⎦
T⎡
⎣
Kp
0
0
M(qd −˜q)
⎤
⎦
⎡
⎣
˜q
˙q
⎤
⎦
= 1
2 ˙qTM(q) ˙q + 1
2 ˜qTKp˜q
(7.3)
and its total derivative with respect to time is
˙V (˜q, ˙q) = ˙qTM(q)¨q + 1
2 ˙qT ˙M(q) ˙q + ˜qTKp ˙˜q .
Substituting M(q)¨q from the closed-loop Equation (7.2) we get
˙V (˜q, ˙q) = −˙qTKv ˙q
= −
⎡
⎣
˜q
˙q
⎤
⎦
T⎡
⎣
0
0
0
Kv
⎤
⎦
⎡
⎣
˜q
˙q
⎤
⎦≤0
(7.4)
where we have eliminated the term ˙qT
1
2 ˙M −C

˙q by virtue of Property 4.2
and used ˙˜q = −˙q since qd is assumed to be a constant vector.
Therefore, the function V (˜q, ˙q) is a Lyapunov function since moreover
˙V (˜q, ˙q) ≤0 for all ˜q and ˙q and consequently, the origin is stable and all the
solutions ˜q(t) and ˙q(t) are bounded (cf. Theorem 2.3).
Since the closed-loop Equation (7.2) is independent of time (explicitly) we
may explore the use of of La Salle’s theorem (cf. Theorem 2.7) to analyze the
global asymptotic stability of the origin.
To that end, we ﬁrst remark that the set Ωis here given by
Ω=

x ∈IR2n : ˙V (x) = 0

=

x =
 ˜q
˙q

∈IR2n : ˙V (˜q, ˙q) = 0
&
= {˜q ∈IRn, ˙q = 0 ∈IRn} .
Observe that ˙V (˜q, ˙q) = 0 if and only if ˙q = 0. For a solution x(t) to
belong to Ωfor all t ≥0, it is necessary and suﬃcient that ˙q(t) = 0 for all
t ≥0. Therefore it must also hold that ¨q(t) = 0 for all t ≥0. Taking this into
account, we conclude from the closed-loop Equation (7.2) that if x(t) ∈Ωfor
all t ≥0 then

7.1 Global Asymptotic Stability by La Salle’s Theorem
161
0 = M(qd −˜q(t))−1Kp˜q(t)
which means that ˜q(t) = 0 for all t ≥0. Thus,
˜q(0)T
˙q(0)T T = 0 ∈IR2n is
the only initial condition in Ωfor which x(t) ∈Ωfor all t ≥0. Then, according
to La Salle’s theorem (cf. Theorem 2.7), this is enough to guarantee global
asymptotic stability of the origin
˜qT
˙qT T = 0 ∈IR2n.
As a result we have
lim
t→∞˜q(t) = 0
lim
t→∞˙q(t) = 0 ,
that is, the position control objective is achieved.
We present next an example with the purpose of showing the performance
of PD control with gravity compensation for the Pelican robot.
l2
lc2
q2
q1
I1
m1
g
y
x
l1
m2
I2
lc1
Link 1
Link 2
Figure 7.2. Diagram of the Pelican robot
Example 7.1. Consider the Pelican robot studied in Chapter 5, and
shown in Figure 7.2.
The components of the vector of gravitational torques g(q) are
given by
g1(q) = (m1lc1 + m2l1)g sin(q1) + m2lc2g sin(q1 + q2)
g2(q) = m2lc2g sin(q1 + q2) .

162
7 PD Control with Gravity Compensation
0.0
0.5
1.0
1.5
2.0
−0.1
0.0
0.1
0.2
0.3
0.4
[rad]
˜q1
0.0620
0.0144
˜q2
t [s]
........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 7.3. Graph of the position errors ˜q1 and ˜q2
Consider the PD control law with gravity compensation for this
robot where the design matrices Kp and Kd are positive deﬁnite. In
particular, let us pick (arbitrarily)
Kp = diag{kp} = diag{30}
[Nm/rad]
Kv = diag{kv} = diag{7, 3}
[Nm s/rad] .
The components of the control input vector τ, are given by
τ1 = kp˜q1 −kv ˙q1 + g1(q)
τ2 = kp˜q2 −kv ˙q2 + g2(q) .
The initial conditions corresponding to the positions and velocities
are chosen as
q1(0) = 0, q2(0) = 0
˙q1(0) = 0, ˙q2(0) = 0 .
The desired joint positions are chosen as
qd1 = π/10, qd2 = π/30 [rad] .
In terms of the state vector of the closed-loop equation, the initial
state is taken to be
⎡
⎣
˜q(0)
˙q(0)
⎤
⎦=
⎡
⎢⎣
π/10
π/30
0
0
⎤
⎥⎦=
⎡
⎢⎣
0.3141
0.1047
0
0
⎤
⎥⎦.
Figure 7.3 presents the components of the position error ˜q obtained
in the experiment. The steady state position errors shown this ﬁgure
are a product of the friction phenomenon which has not been included
in the robot dynamics.
♦

7.2 Lyapunov Function for Global Asymptotic Stability
163
7.2 Lyapunov Function for Global Asymptotic Stability
In this section we present an alternative proof for global asymptotic stability
without the use of La Salle’s theorem. Instead, we use a strict Lyapunov
function, i.e. a Lyapunov function whose time derivative is globally negative
deﬁnite. We consider the case of robots having only revolute joints and where
the proportional gain matrix Kp is diagonal instead of only symmetric, but
of course, positive deﬁnite. Some readers may wish to omit this somewhat
technical section and continue to Section 7.3.
−4
−3
−2
−1
0
1
2
3
4
−1.0
−0.5
0.0
0.5
1.0
tanh(x)
x
........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 7.4. Graph of the tangent hyperbolic function: tanh(x)
Before starting with the stability analysis of the equilibrium
˜qT
˙qT T
= 0 ∈IR2n of the closed-loop Equation (7.2), it is convenient to cite some
properties of the vectorial function1
tanh(x) = [ tanh(x1) tanh(x2)
· · ·
tanh(xn)]T
(7.5)
where tanh(x) (see Figure 7.4) denotes the hyperbolic tangent function,
tanh(x) = ex −e−x
ex + e−x .
Note that this function satisﬁes |x| ≥| tanh(x)|, and 1 ≥| tanh(x)| for all
x ∈IR therefore, the Euclidean norm of tanh(x) satisﬁes
∥tanh(x)∥≤

∥x∥
∀x ∈IRn
√n
∀x ∈IRn
(7.6)
1 See also Deﬁnition 4.1 on page 103.

164
7 PD Control with Gravity Compensation
and tanh(x) = 0 if and only if x = 0.
One can prove without much diﬃculty that for a symmetric positive deﬁ-
nite matrix A the inequality
˜qT A˜q ≥λmin{A} ∥tanh(˜q)∥2
∀˜q ∈IRn
holds. If moreover, A is diagonal, then
tanh(˜q)T A˜q ≥λmin{A} ∥tanh(˜q)∥2
∀˜q ∈IRn .
(7.7)
We present next our alternative stability analysis. To study the stability
properties of the origin
˜qT
˙qT T = 0 ∈IR2n, of the closed-loop Equation
(7.2), consider the Lyapunov function (7.3) with an added term, that is,
V (˜q, ˙q) = 1
2 ˙qT M(q) ˙q + 1
2 ˜qT Kp˜q −γtanh(˜q)T M(q) ˙q
(7.8)
where tanh(˜q) was deﬁned in (7.5) and γ > 0 is a constant suﬃciently small
so as to satisfy simultaneously,
λmin{Kp}λmin{M}
λ2
Max{M}
> γ2
(7.9)
and
4λmin{Kp}λmin{Kv}
λ2
Max{Kv} + 4λmin{Kp}[√n kC1 + λMax{M}] > γ .
(7.10)
Since the upper-bounds above are always strictly positive constants, there
always exists γ > 0 arbitrarily small and that satisﬁes both inequalities.
7.2.1 Positivity of the Lyapunov Function
In order to show that the Lyapunov function candidate (7.8) is positive deﬁnite
we ﬁrst observe that the third term in (7.8) satisﬁes
γtanh(˜q)T M(q) ˙q ≤γ ∥tanh(˜q)∥∥M(q) ˙q∥
≤γ λMax{M} ∥tanh(˜q)∥∥˙q∥
≤γ λMax{M} ∥˜q∥∥˙q∥
where we have used (7.6) in the last step. Therefore,
−γtanh(˜q)T M(q) ˙q ≥−γ λMax{M} ∥˜q∥∥˙q∥
and consequently the Lyapunov function candidate (7.8) satisﬁes the inequal-
ity
V (˜q, ˙q) ≥1
2

∥˜q∥
∥˙q∥
T 
λmin{Kp}
−γ λMax{M}
−γ λMax{M}
λmin{M}
 
∥˜q∥
∥˙q∥

Since by assumption Kp is positive deﬁnite – λmin{Kp} > 0 – and γ is sup-
posed to satisfy (7.9) it follows that V (˜q, ˙q) is a positive deﬁnite function and
moreover it is radially unbounded.

7.2 Lyapunov Function for Global Asymptotic Stability
165
7.2.2 Time Derivative of the Lyapunov Function
The time derivative of the Lyapunov function candidate (7.8) along the tra-
jectories of the closed-loop system (7.2) may be written as
˙V (˜q, ˙q) = ˙qT [Kp˜q −Kv ˙q −C(q, ˙q) ˙q] + 1
2 ˙qT ˙M(q) ˙q
−[Kp˜q]T ˙q + γ ˙qT Sech2(˜q)T M(q) ˙q −γtanh(˜q)T ˙M(q) ˙q
−γtanh(˜q)T [Kp˜q −Kv ˙q −C(q, ˙q) ˙q]
where we used Equation (4.14) in
d
dt{tanh(˜q)} = −Sech2(˜q) ˙q
that is, Sech2(˜q) := diag{sech2(˜qi)} where
sech(˜qi) :=
1
e˜qi + e−˜qi
and therefore, Sech2(˜q) is a diagonal matrix whose elements, sech2(˜qi), are
positive and smaller than 1.
Using Property 4.2, which establishes that ˙qT
1
2 ˙M −C

˙q = 0 and ˙M(q) =
C(q, ˙q) + C(q, ˙q)T , the time derivative of the Lyapunov function candidate
yields
˙V (˜q, ˙q) = −˙qT Kv ˙q + γ ˙qT Sech2(˜q)T M(q) ˙q −γtanh(˜q)T Kp˜q
+ γtanh(˜q)T Kv ˙q −γtanh(˜q)T C(q, ˙q)T ˙q .
(7.11)
We now proceed to upper-bound ˙V (˜q, ˙q) by a negative deﬁnite function
of the states ˜q and ˙q. To that end, it is convenient to ﬁnd upper-bounds for
each term of (7.11).
The ﬁrst term of (7.11) may be trivially bounded by
−˙qT Kv ˙q ≤−λmin{Kv}∥˙q∥2 .
To upper-bound the second term of (7.11) we use |sech2(x)| ≤1, so
Sech2(˜q) ˙q
 ≤∥˙q∥.
From this argument we also have
γ ˙qT Sech2(˜q)T M(q) ˙q ≤γλMax{M} ∥˙q∥2 .
On the other hand, note that in view of (7.7), the following inequality also
holds true since Kp is a diagonal positive deﬁnite matrix,

166
7 PD Control with Gravity Compensation
γtanh(˜q)T Kp˜q ≥γλmin{Kp} ∥tanh(˜q)∥2
which in turn, implies the key inequality
−γtanh(˜q)T Kp˜q ≤−γλmin{Kp} ∥tanh(˜q)∥2 .
A bound on γtanh(˜q)T Kv ˙q that is obtained directly is
γtanh(˜q)T Kv ˙q ≤γλMax{Kv} ∥˙q∥∥tanh(˜q)∥.
The upper-bound on the term −γtanh(˜q)T C(q, ˙q)T ˙q must be carefully
selected. Notice that
−γtanh(˜q)T C(q, ˙q)T ˙q = −γ ˙qT C(q, ˙q)tanh(˜q)
≤γ ∥˙q∥∥C(q, ˙q)tanh(˜q)∥.
Then, considering Property 4.2 but in its variant that establishes the existence
of a constant kC1 such that ∥C(q, x)y∥≤kC1 ∥x∥∥y∥for all q, x, y ∈IRn,
we obtain
−γtanh(˜q)T C(q, ˙q)T ˙q ≤γkC1 ∥˙q∥2 ∥tanh(˜q)∥.
Making use of the inequality (7.6) of tanh(˜q) which says that ∥tanh(˜q)∥≤
√n for all ˜q ∈IRn, we obtain
−γtanh(˜q)T C(q, ˙q)T ˙q ≤γ√n kC1 ∥˙q∥2 .
The previous bounds yield that the time derivative ˙V (˜q, ˙q) in (7.11), sat-
isﬁes
˙V (˜q, ˙q) ≤−γ
'
∥tanh(˜q)∥
∥˙q∥
(T
Q
'
∥tanh(˜q)∥
∥˙q∥
(
(7.12)
where
Q =
⎡
⎢⎣
λmin{Kp}
−1
2λMax{Kv}
−1
2λMax{Kv}
1
γ λmin{Kv} −√n kC1 −λMax{M}
⎤
⎥⎦.
The two following conditions guarantee that the matrix Q is positive deﬁ-
nite, hence, these conditions are suﬃcient to ensure that ˙V (˜q, ˙q) is a negative
deﬁnite function,
λmin{Kp} > 0
and
4λmin{Kp}λmin{Kv}
λ2
Max{Kv} + 4λmin{Kp}[√nkC1 + λMax{M}] > γ .

Bibliography
167
The ﬁrst condition is trivially satisﬁed since Kp is assumed to be diagonal
positive deﬁnite. The second condition also holds due to the upper-bound
(7.10) imposed on γ.
According to the arguments above, there always exists a strictly positive
constant γ such that the function V (˜q, ˙q), given by (7.8) is positive deﬁnite,
while ˙V (˜q, ˙q) expressed as (7.12), is negative deﬁnite. For this reason, V (˜q, ˙q)
is a strict Lyapunov function.
Finally, Theorem 2.4 allows one to establish global asymptotic stability of
the origin. It is important to underline that it is not necessary to know the
value of γ but only to know that it exists. This has been done to validate the
result on global asymptotic stability that was stated.
7.3 Conclusions
Let us restate the most important conclusion from the analyses done in this
chapter.
Consider the PD control law with gravity compensation for n-DOF robots
and assume that the desired position qd is constant.
•
If the symmetric matrices Kp and Kv of the PD control law with grav-
ity compensation are positive deﬁnite, then the origin of the closed-loop
equation, expressed in terms of the state vector
˜qT
˙qT T , is a globally
asymptotically stable equilibrium. Consequently, for any initial condition
q(0), ˙q(0) ∈IRn, we have limt→∞˜q(t) = 0 ∈IRn .
Bibliography
PD control with gravity compensation for robot manipulators was originally
analyzed in
•
Takegaki M., Arimoto S., 1981,“A new feedback method for dynamic con-
trol of manipulators”, Transactions ASME, Journal of Dynamic Systems,
Measurement and Control, Vol. 103, pp. 119–125.
The following texts present also the proof of global asymptotic stability
for the PD control law with gravity compensation of robot manipulators
•
Spong M., Vidyasagar M., 1989, “Robot dynamics and control”, John Wi-
ley and Sons.
•
Yoshikawa T., 1990, “Foundations of robotics: Analysis and control”, The
MIT Press.

168
7 PD Control with Gravity Compensation
A particularly simple proof of stability for the PD controller with gravity
compensation which makes use of La Salle’s theorem is presented in
•
Paden B., Panja R., 1988, “Globally asymptotically stable PD+ controller
for robot manipulators”, International Journal of Control, Vol. 47, No. 6,
pp. 1697–1712.
The analysis of the PD control with gravity compensation for the case in
which the desired joint position qd is time-varying is presented in
•
Kawamura S., Miyazaki F., Arimoto S., 1988, “Is a local linear PD feedback
control law eﬀective for trajectory tracking of robot motion?”, in Proceed-
ings of the 1988 IEEE International Conference on Robotics and Automa-
tion, Philadelphia, PA., pp. 1335–1340, April.
Problems
1. Consider the PD control with gravity compensation for robots. Let qd(t)
be the desired joint position.
Assume that there exists a constant vector x ∈IRn such that
x −K−1
p
[M(qd −x)¨qd + C(qd −x, ˙qd) ˙qd] = 0 ∈IRn .
a) Show that

˜qT
˙˜q
T T
=

xT
0T T ∈IR2n is an equilibrium of the
closed-loop equation.
2. Consider the model of an ideal pendulum studied in Example 2.2 (see
page 30)
J ¨q + mgl sin(q) = τ .
The PD control law with gravity compensation is in this case
τ = kp˜q + kv ˙˜q + mgl sin(q)
where kp and kv are positive constants.
a) Obtain the closed-loop equation in terms of the state vector

˜q
˙˜q
T .
Is this equation linear in the state ?
b) Assume that the desired position is qd(t) = αt where α is any real
constant. Show that
lim
t→∞˜q(t) = 0 .
3. Verify the expression of ˙V (˜q, ˙q) obtained in (7.4).

Problems
169
4. Consider the 3-DOF Cartesian robot studied in Example 3.4 (see page 69)
and shown in Figure 3.5. Its dynamic model is given by
(m1 + m2 + m3)¨q1 + (m1 + m2 + m3)g = τ1
(m1 + m2)¨q2 = τ2
m1¨q3 = τ3 .
Assume that the desired position qd is constant. Consider using the PD
controller with gravity compensation,
τ = Kp˜q −Kv ˙q + g(q)
where Kp, Kv are positive deﬁnite matrices.
a) Obtain g(q). Verify that g(q) = g is a constant vector.
b) Deﬁne ˜q = [˜q1
˜q2
˜q3]T . Obtain the closed-loop equation. Is the
closed-loop equation linear in the state ?
c) Is the origin the unique equilibrium of the closed-loop equation?
d) Show that the origin is a globally asymptotically stable equilibrium
point.
5. Consider the following variant of PD control with gravity compensation2
τ = Kp˜q −M(q)Kv ˙q + g(q)
where qd is constant, Kp is a symmetric positive deﬁnite matrix and Kv =
diag{kv} with kv > 0.
a) Obtain the closed-loop equation in terms of the state vector
˜qT
˙qT T .
b) Verify that the origin is a unique equilibrium.
c) Show that the origin is a globally asymptotically stable equilibrium
point.
6. Consider the PD control law with gravity compensation where the matrix
Kv is a function of time, i.e.
τ = Kp˜q −Kv(t) ˙q + g(q)
and where qd is constant, Kp is a positive deﬁnite matrix and Kv(t) is
also positive deﬁnite for all t ≥0.
a) Obtain the closed-loop equation in terms of the state vector
˜qT
˙qT T .
Is the closed-loop equation autonomous?
b) Verify that the origin is the only equilibrium point.
c) Show that the origin is a stable equilibrium.
7. Is the matrix Sech2(x) positive deﬁnite?
2 This problem is taken from Craig J. J., 1989, “ Introduction to robotics: Mechanics
and control”, Second edition, Addison–Wesley.

8
PD Control with Desired Gravity
Compensation
We have seen that the position control objective for robot manipulators
(whose dynamic model includes the gravitational torques vector g(q)), may be
achieved globally by PD control with gravity compensation. The correspond-
ing control law given by Equation (7.1) requires that its design symmetric
matrices Kp and Kv be positive deﬁnite. On the other hand, this controller
uses explicitly in its control law the gravitational torques vector g(q) of the
dynamic robot model to be controlled.
Nevertheless, it is worth remarking that even in the scenario of position
control, where the desired joint position qd ∈IRn is constant, in the imple-
mentation of the PD control law with gravity compensation it is necessary to
evaluate, on-line, the vector g(q(t)). In general, the elements of the vector g(q)
involve trigonometric functions of the joint positions q, whose evaluations, re-
alized mostly by digital equipment (e.g. ordinary personal computers) take a
longer time than the evaluation of the ‘PD-part’ of the control law. In certain
applications, the (high) sampling frequency speciﬁed may not allow one to
evaluate g(q(t)) permanently. Naturally, an ad hoc solution to this situation
is to implement the control law at two sampling frequencies: a high frequency
for the evaluation of the PD-part, and a low frequency for the evaluation of
g(q(t)). An alternative solution consists in using a variant of this controller,
the so-called PD control with desired gravity compensation. The study of this
controller is precisely the subject of the present chapter.
The PD control law with desired gravity compensation is given by
τ = Kp˜q + Kv ˙˜q + g(qd)
(8.1)
where Kp, Kv ∈IRn×n are symmetric positive deﬁnite matrices chosen by the
designer. As is customary, the position error is denoted by ˜q = qd −q ∈IRn,
where qd stands for the desired joint position. Figure 8.1 presents the block-
diagram of the PD control law with desired gravity compensation for robot
manipulators. Notice that the only diﬀerence with respect to the PD controller

172
8 PD Control with Desired Gravity Compensation
with gravity compensation (7.1) is that the term g(qd) replaces g(q). The
practical convenience of this controller is evident when the desired position
qd(t) is periodic or constant. Indeed, the vector g(qd), which depends on qd
and not on q, may be evaluated oﬀ-line once qd has been deﬁned and therefore,
it is not necessary to evaluate g(q) in real time.
qd
˙qd
g(qd)
Kv
Kp
Σ
Σ
Σ
ROBOT
q
˙q
Figure 8.1. Block-diagram: PD control with desired gravity compensation
The closed-loop equation we get by combining the equation of the robot
model (II.1) and the equation of the controller (8.1) is
M(q)¨q + C(q, ˙q) ˙q + g(q) = Kp˜q + Kv ˙˜q + g(qd)
or equivalently, in terms of the state vector

˜qT
˙˜q
T T
,
d
dt
⎡
⎣
˜q
˙˜q
⎤
⎦=
⎡
⎣
˙˜q
¨qd −M(q)−1 
Kp˜q + Kv ˙˜q −C(q, ˙q) ˙q + g(qd) −g(q)

⎤
⎦
which represents a nonautonomous nonlinear diﬀerential equation. The nec-
essary and suﬃcient condition for the origin

˜qT
˙˜q
T T
= 0 ∈IR2n to be an
equilibrium of the closed-loop equation, is that the desired joint position qd
satisﬁes
M(qd)¨qd + C(qd, ˙qd) ˙qd = 0 ∈IRn
or equivalently, that qd(t) be a solution of
d
dt
⎡
⎣
qd
˙qd
⎤
⎦=
⎡
⎣
˙qd
−M(qd)−1 [C(qd, ˙qd) ˙qd]
⎤
⎦

8 PD Control with Desired Gravity Compensation
173
for any initial condition

qd(0)T
˙qd(0)T T ∈IR2n.
Obviously, in the scenario where the desired position qd(t) does not satisfy
the established condition, the origin may not be an equilibrium point of the
closed-loop equation and therefore, it may not be expected to satisfy the mo-
tion control objective, that is, to drive the position error ˜q(t) asymptotically
to zero.
A suﬃcient condition for the origin

˜qT
˙˜q
T T
= 0 ∈IR2n to be an equi-
librium point of the closed-loop equation is that the desired joint position qd
be a constant vector. In what is left of this chapter we assume that this is the
case.
As we show below, this controller may verify the position objective globally,
that is,
lim
t→∞q(t) = qd
where qd ∈IRn is a any constant vector and the robot may start oﬀfrom any
conﬁguration. We emphasize that the controller “may achieve” the position
control objective under the condition that Kp is chosen suﬃciently ‘large’.
Later on in this chapter, we quantify ‘large’.
Considering the desired position qd to be constant, the closed-loop equa-
tion may be written in terms of the new state vector
˜qT
˙qT T as
d
dt
⎡
⎣
˜q
˙q
⎤
⎦=
⎡
⎣
−˙q
M(q)−1 [Kp˜q −Kv ˙q −C(q, ˙q) ˙q + g(qd) −g(q)]
⎤
⎦
(8.2)
that is, in the form of a nonlinear autonomous diﬀerential equation whose
origin
˜qT
˙qT T = 0 ∈IR2n is an equilibrium point. Nevertheless, besides the
origin, there may exist other equilibria. Indeed, there are as many equilibria
as solutions in ˜q, may have the equation
Kp˜q = g(qd −˜q) −g(qd) .
(8.3)
Naturally, the explicit solutions of (8.3) are hard to obtain. Nevertheless,
as we show that later, if Kp is taken suﬃciently “large”, then ˜q = 0 ∈IRn is
the unique solution.
Example 8.1. Consider the model of the ideal pendulum studied in
Example 2.2 (see page 30)
J ¨q + mgl sin(q) = τ
where we identify g(q) = mgl sin(q).
In this case, the expression (8.3) takes the form

174
8 PD Control with Desired Gravity Compensation
kp˜q = mgl [sin(qd −˜q) −sin(qd)] .
(8.4)
For the sake of illustration, consider the following numerical values,
J = 1
mgl = 1
kp = 0.25
qd = π/2 .
Either via a graphical method or numerical algorithms, one may
verify that Equation (8.4) possess exactly three solutions in ˜q. The
approximated values of these solutions are: 0 (rad), −0.51 (rad) and
−4.57 (rad). This means that the PD control law with desired gravity
compensation in closed loop with the model of the ideal pendulum
has as equilibria,

˜q
˙q

∈

0
0

,

−0.51
0

,

−4.57
0
&
.
Consider now a larger value for kp (suﬃciently “large”), e.g.
kp = 1.25
In this scenario, it may be veriﬁed numerically that Equation (8.4)
has a unique solution at ˜q = 0 (rad). This means that the PD control
law with desired gravity compensation in closed loop with the model
of the ideal pendulum, has the origin as its unique equilibrium, i.e.

˜q
˙q

=

0
0

∈IR2 .
♦
The rest of the chapter focuses on:
•
boundedness of solutions;
•
unicity of the equilibrium;
•
global asymptotic stability.
The studies presented here are limited to the case of robots whose joints
are all revolute.
8.1 Boundedness of Position and Velocity Errors, ˜q and ˙q
Assuming that the design matrices Kp and Kv are positive deﬁnite (without
assuming that Kp is suﬃciently “large”), and of course, for a desired constant
position qd to this point, we only know that the closed-loop Equation (8.2) has

8.1 Boundedness of Position and Velocity Errors, ˜q and ˙q
175
an equilibrium at the origin, but there might also be other equilibria. In spite
of this, we show by using Lemma 2.2 that both, the position error ˜q(t) and the
velocity error ˙q(t) remain bounded for all initial conditions
˜q(0)T
˙q(0)T T ∈
IR2n.
Deﬁne the function (later on, we show that it is non-negative deﬁnite)
V (˜q, ˙q) = K(q, ˙q) + U(q) −kU + 1
2 ˜qTKp˜q
+ ˜qT g(qd) + 1
2g(qd)TK−1
p g(qd)
where K(q, ˙q) and U(q) denote the kinetic and potential energy functions of
the robot, and the constant kU is deﬁned as (see Property 4.3)
kU = min
q {U(q)} .
The function V (˜q, ˙q) may be written as
V (˜q, ˙q) = ˙qTP(˜q) ˙q + h(˜q)
(8.5)
where
P(˜q) := 1
2M(qd −˜q)
h(˜q) := U(qd −˜q) −kU + 1
2 ˜qTKp˜q + ˜qT g(qd) + 1
2g(qd)TK−1
p g(qd) .
Since we assumed that the robot has only revolute joints, U(q) −kU ≥0
for all q ∈IRn. On the other hand, we have
1
2 ˜qTKp˜q + ˜qT g(qd) + 1
2g(qd)TK−1
p g(qd),
may be written as
1
2
⎡
⎣
˜q
g(qd)
⎤
⎦
T ⎡
⎣
Kp
I
I
K−1
p
⎤
⎦
⎡
⎣
˜q
g(qd)
⎤
⎦
which is non-negative for all ˜q, qd ∈IRn. Therefore, the function h(˜q) is
also non-negative. Naturally, since the kinetic energy 1
2 ˙qTM(q) ˙q is a positive
deﬁnite function of ˙q, then the function V (˜q, ˙q) is non-negative for all ˜q, ˙q ∈
IRn.
The time derivative of V (˜q, ˙q) is
˙V (˜q, ˙q) = ˙qTM(q)¨q + 1
2 ˙qT ˙M(q) ˙q + ˙qT g(q) + ˜qTKp ˙˜q + ˙˜q
T g(qd)
(8.6)

176
8 PD Control with Desired Gravity Compensation
where we used (3.20), i.e. g(q) =
∂
∂q U(q). Solving for M(q)¨q in the closed-
loop Equation (8.2) and substituting in (8.6) we get
˙V (˜q, ˙q) = ˙qTKp˜q −˙qTKv ˙q + ˙qT g(qd) + ˜qTKp ˙˜q + ˙˜q
T g(qd)
(8.7)
where the term ˙qT
1
2 ˙M −C

˙q was eliminated by virtue of Property 4.2. Re-
calling that the vector qd is constant and that ˜q = qd −q, then ˙˜q = −˙q.
Incorporating this in Equation (8.7) we obtain
˙V (˜q, ˙q) = −˙qT Kv ˙q .
(8.8)
Using V (˜q, ˙q) and ˙V (˜q, ˙q) given by (8.5) and (8.8) respectively, and in-
voking Lemma 2.2 (cf. page 52), we conclude that both, ˙q(t) and ˜q(t) are also
bounded and that the velocities vector ˙q(t), is square integrable, i.e.
 ∞
0
∥˙q(t)∥2dt < ∞.
(8.9)
As a matter of fact, it may be shown that the velocity ˙q is not only
bounded, but that it also tends asymptotically to zero. For this, notice from
(8.2) that
¨q = M(q)−1 [Kp˜q −Kv ˙q + g(qd) −g(q) −C(q, ˙q) ˙q] .
(8.10)
Since ˙q(t) and ˜q(t) were shown to be bounded then it follows from Prop-
erties 4.2 and 4.3 that C(q(t), ˙q(t)) ˙q(t) and g(q(t)) are also bounded. On the
other hand, M(q)−1 is a bounded matrix (from Property 4.1), and ﬁnally,
from (8.10) we conclude that the accelerations vector ¨q(t) is also bounded
and therefore, from (8.9) and Lemma 2.2, we conclude that
lim
t→∞
˙˜q(t) = lim
t→∞˙q(t) = 0 .
For the sake of completeness we show next how to compute explicit upper-
bounds on the position and velocity errors. Taking into account that V (˜q, ˙q) is
a non-negative function that decreases along trajectories (i.e.
d
dtV (˜q, ˙q) ≤0),
we have
0 ≤V (˜q(t), ˙q(t)) ≤V (˜q(0), ˙q(0))
for all t ≥0. Consequently, considering the deﬁnition of V (˜q, ˙q) we deduce
immediately that
1
2 ˜q(t)TKp˜q(t) + ˜q(t)T g(qd) + 1
2g(qd)TK−1
p g(qd) ≤V (˜q(0), ˙q(0))
(8.11)
1
2 ˙q(t)TM(q(t)) ˙q(t) ≤V (˜q(0), ˙q(0))
(8.12)

8.1 Boundedness of Position and Velocity Errors, ˜q and ˙q
177
for all t ≥0, and where
V (˜q(0), ˙q(0)) = 1
2 ˙q(0)TM(q(0)) ˙q(0) + U(q(0)) −kU
+ 1
2 ˜q(0)TKp˜q(0) + g(qd)T˜q(0) + 1
2g(qd)TK−1
p g(qd) .
The value of V (˜q(0), ˙q(0)) may be obtained if we know the inertia ma-
trix M(q) and the vector of gravitational torques g(q). Naturally, we assume
here that the position q(t), the velocity ˙q(t) and, in particular at the instant
t = 0, are measured by appropriate instruments physically collocated for this
purpose on the robot.
We obtain next, explicit bounds on ∥˜q∥and ∥˙q∥as a function of the initial
conditions. We ﬁrst notice that
λmin{Kp}
2
∥˜q∥2 −∥g(qd)∥∥˜q∥≤1
2 ˜qTKp˜q + g(qd)T˜q + 1
2g(qd)TK−1
p g(qd)
"
#$
%
c
where we used the fact that c ≥0 and that for all vectors x and y ∈IRn
we have −xT y ≤
xT y
 ≤∥x∥∥y∥, so −∥x∥∥y∥≤xT y. Taking (8.11) into
account, we have
λmin{Kp}
2
∥˜q∥2 −∥g(qd)∥∥˜q∥−V (˜q(0), ˙q(0)) ≤0
from which we ﬁnally obtain
∥˜q(t)∥≤
∥g(qd)∥+

∥g(qd)∥2 + 2λmin{Kp}V (˜q(0), ˙q(0))
λmin{Kp}
(8.13)
for all t ≥0.
On the other hand, it is clear from (8.12) that
∥˙q(t)∥2 ≤2V (˜q(0), ˙q(0))
λmin{M(q)}
(8.14)
for all t ≥0. The expressions (8.13) and (8.14) establish the bounds we were
looking for.
Example 8.2. Consider again the model of the ideal pendulum from
Example 8.1
J ¨q + mgl sin(q) = τ,
where we clearly identify M(q) = J and g(q) = mgl sin(q). As has
been shown before in Example 2.11 (see page 45), the potential energy
function is given by

178
8 PD Control with Desired Gravity Compensation
U(q) = mgl[1 −cos(q)] .
Since minq{U(q)} = 0, the constant kU takes the value of zero.
Consider the numerical values used in Example 8.1
J = 1
mgl = 1
kp = 0.25
kv = 0.50
qd = π/2 .
Assume that we use PD control with desired gravity compensation
to control the ideal pendulum from the initial conditions q(0) = 0 and
˙q(0) = 0.
0
10
20
30
0
5
10
15
20
25
30
35
˜q(t)2 [rad2]
t [s]
.......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Figure 8.2. PD control with desired gravity compensation: graph of the position
error ˜q(t)2
With the previous values it is easy to verify that
g(qd) = mgl sin(π/2) = 1
V (˜q(0), ˙q(0)) = 1
2kp˜q2(0) + mgl˜q(0) +
1
2kp
(mgl)2 = 3.87 .
According to the bounds (8.13) and (8.14) and taking into account
the previous information, we get
˜q2(t) ≤
⎡
⎣mgl +

[mgl + kp˜q(0)]2 + (mgl)2
kp
⎤
⎦
2
≤117.79 [ rad2 ]
(8.15)
˙q2(t) ≤2
J
kp
2 ˜q2(0) + mgl˜q(0) +
1
2kp
(mgl)2


8.1 Boundedness of Position and Velocity Errors, ˜q and ˙q
179
0
10
20
30
0
1
2
3
˙q(t)2 [( rad
s )2]
t [s]
..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
Figure 8.3. PD control with desired gravity compensation: graph of velocity, ˙q(t)2
≤7.75
rad
s
2
,
(8.16)
for all t ≥0. Figures 8.2 and 8.3 show the plots of ˜q(t)2 and ˙q(t)2
respectively, obtained by simulation. We clearly appreciate from the
plots that both variables satisfy the inequalities (8.15) and (8.16).
Finally, it is interesting to observe from Figure 8.2 that limt→∞˜q(t)2 =
20.88 (evidence from simulation shows that limt→∞˜q(t) = −4.57) and
limt→∞˙q2(t) = 0 and therefore
lim
t→∞

˜q(t)
˙q(t)

=

−4.57
0

.
This means that the solutions tend precisely to one among the three
equilibria computed in Example 8.1, but which do not correspond to
the origin. The moral of this example is that PD control with desired
gravity compensation may fail to meet the position control objective.
♦
To summarize the developments above we make the following remarks.
Consider the PD control law with desired gravity compensation for robots
with revolute joints. Assume that the design matrices Kp and Kv are positive
deﬁnite. If the desired joint position qd(t) is a constant vector, then:
•
the position error ˜q(t) and the velocity ˙q(t) are bounded. Maximal bounds
on their norms are given by the expressions (8.13) and (8.14) respectively.
•
lim
t→∞˙q(t) = 0 ∈IRn.

180
8 PD Control with Desired Gravity Compensation
8.2 Unicity of Equilibrium
For robots having only revolute joints, we show that with the choice of Kp
suﬃciently “large”, we can guarantee unicity of the equilibrium for the closed-
loop Equation (8.2). To that end, we use here the contraction mapping theorem
(cf. Theorem 2.1 on page 26).
The equilibria of the closed-loop Equation (8.2) satisfy
˜qT
˙qT T =
˜qT
0T T ∈IR2n where ˜q ∈IRn solves (8.3),
˜q = K−1
p
[g(qd −˜q) −g(qd)]
= f(˜q, qd) .
Naturally, ˜q = 0 ∈IRn is a trivial solution of ˜q = f(˜q, qd), but as has
been illustrated above in Example 8.1, there may exist other solutions.
If the function f(˜q, qd) satisﬁes the condition of the contraction mapping
theorem, that is, if f(˜q, qd) is Lipschitz (cf. page 101) with Lipschitz constant
strictly smaller than 1, then the equation ˜q = f(˜q, qd) has a unique solution
˜q∗and consequently, the unique equilibrium of the closed-loop Equation (8.2)
is
˜qT ˙qT T =

˜q∗T
0T T
∈IR2n.
Now, notice that for all vectors x, y ∈IRn
∥f(x, qd) −f(y, qd)∥=
K−1
p g(qd −x) −K−1
p g(qd −y)

=
K−1
p
{g(qd −x) −g(qd −y)}

≤λMax{K−1
p } ∥g(qd −x) −g(qd −y)∥.
On the other hand, using the fact that λMax{A−1} = 1/λmin{A} for any
symmetric positive deﬁnite matrix A, and Property 4.3 that guarantees the
existence of a positive constant kg such that ∥g(x) −g(y)∥≤kg ∥x −y∥, we
have
∥f(x, qd) −f(y, qd)∥≤
kg
λmin{Kp} ∥x −y∥,
which, according to the contraction mapping theorem, implies that a suﬃcient
condition for unicity of the solution of f(˜q, qd) −˜q = 0 or equivalently of
K−1
p
[g(qd −˜q) −g(qd)] −˜q = 0
and consequently, for the unicity of the equilibrium of the closed-loop equa-
tion, is that Kp be chosen so as to satisfy
λmin{Kp} > kg .
(8.17)

8.3 Global Asymptotic Stability
181
Therefore, assuming that Kp is chosen so that λmin{Kp} > kg, then the
unique equilibrium of the closed-loop Equation (8.2) is the origin,
˜qT
˙qT T =

0T
0T T ∈IR2n.
8.3 Global Asymptotic Stability
The objective of the present section is to show that the assumption that the
matrix Kp satisﬁes the condition (8.17) is actually also suﬃcient to guarantee
that the origin is globally asymptotically stable for the closed-loop Equation
(8.2). To that end we use as usual, Lyapunov’s direct method but comple-
mented with La Salle’s theorem. This proof is taken from the works cited at
the end of the chapter.
First, we present a lemma on positive deﬁnite functions of particular rel-
evance to ultimately propose a Lyapunov function candidate.1
Lemma 8.1. Consider the function f : IRn →IR given by
f(˜q) = U(qd −˜q) −U(qd) + g(qd)T˜q + 1
ε ˜qTKp˜q
(8.18)
where Kp = Kp
T > 0, qd ∈IRn is a constant vector, ε is a real positive
constant number and U(q) is the potential energy function of the robot. If
2
εKp + ∂g(qd −˜q)
∂(qd −˜q) > 0
for all qd, ˜q ∈IRn, then f(˜q) is a globally positive deﬁnite function. The
previous condition is satisﬁed if
λmin{Kp} > ε
2kg
where kg has been deﬁned in Property 4.3, and in turn is such that
kg ≥

∂g(q)
∂q
 .
Due to the importance of the above-stated lemma, we present next a de-
tailed proof.
Proof. It consists in establishing that f(˜q) has a global minimum at ˜q = 0 ∈
IRn. For this, we use the following result which is well known in optimization
techniques. Let f : IRn →IR be a function with continuous partial derivatives
up to at least the second order. The function f(x) has a global minimum at
x = 0 ∈IRn if
1 See also Example B.2 in Appendix B.

182
8 PD Control with Desired Gravity Compensation
1. The gradient vector of the function f(x), evaluated at x = 0 ∈IRn is
zero, i.e.
∂
∂xf(0) = 0 ∈IRn .
2. The Hessian matrix of the function f(x), evaluated at each x ∈IRn, is
positive deﬁnite, i.e.
H(x) =
∂2
∂xi∂xj
f(x) > 0 .
The gradient of f(˜q) with respect to ˜q is
∂
∂˜q f(˜q) = ∂U(qd −˜q)
∂˜q
+ g(qd) + 2
εKp˜q .
Recalling from (3.20) that g(q) = ∂U(q)/∂q and that2
∂
∂˜q U(qd −˜q) = ∂(qd −˜q)
∂˜q
T ∂U(qd −˜q)
∂(qd −˜q)
we ﬁnally obtain
∂
∂˜q f(˜q) = −g(qd −˜q) + g(qd) + 2
εKp˜q .
Clearly the gradient of f(˜q) is zero for ˜q = 0 ∈IRn. Indeed, one can show
that if λmin{Kp} > ε
2kg the gradient of f(˜q) is zero only at ˜q = 0 ∈IRn.
The proof of this claim is similar to the proof of unicity of the equilibrium in
Section 8.2.
The Hessian matrix
H(˜q) (which by the way, is symmetric) of f(˜q),
deﬁned as
H(˜q) = ∂
∂˜q
∂f(˜q)
∂˜q

=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
∂2f(˜ )
∂˜q1∂˜q1
∂2f(˜ )
∂˜q1∂˜q2
· · ·
∂2f(˜ )
∂˜q1∂˜qn
∂2f(˜ )
∂˜q2∂˜q1
∂2f(˜ )
∂˜q2∂˜q2
· · ·
∂2f(˜ )
∂˜q2∂˜qn
...
...
...
...
∂2f(˜ )
∂˜qn∂˜q1
∂2f(˜ )
∂˜qn∂˜q2
· · ·
∂2f(˜ )
∂˜qn∂˜qn
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
2 Let f : IRn →IR,   : IRn →IRn, ,  ∈IRn and  =  (). Then,
∂f()
∂
=

∂ ()
∂
T ∂f()
∂
.

8.3 Global Asymptotic Stability
183
corresponds to3
H(˜q) = ∂g(qd −˜q)
∂(qd −˜q) + 2
εKp .
Hence, f(˜q) has a (global) minimum at ˜q = 0 ∈IRn if H(˜q) > 0 for all
˜q ∈IRn, in other words, if the symmetric matrix
∂g(q)
∂q
+ 2
εKp
(8.19)
is positive deﬁnite for all q ∈IRn.
Here, we use the following result whose proof is given in Example B.2 of
Appendix B. Let A, B ∈IRn×n be symmetric matrices. Assume also that the
matrix A is positive deﬁnite but possibly not B. If λmin{A} > ∥B∥, then the
matrix A + B is positive deﬁnite. Deﬁning A = 2
εKp, B = ∂g(q)
∂q , and using
the result previously mentioned, we conclude that the matrix (8.19) is positive
deﬁnite if
λmin{Kp} > ε
2

∂g(q)
∂q
 .
(8.20)
Since the constant kg satisﬁes kg ≥
 ∂g(q)
∂q
, then the condition (8.20) is
implied by
λmin{Kp} > ε
2kg .
Therefore, if λmin{Kp} > ε
2kg, then f(˜q) has only one global minimum4 at
˜q = 0 ∈IRn. Moreover, f(0) = 0 ∈IR, then f(˜q) is a globally positive deﬁnite
function.
♦♦♦
We present next, the stability analysis of the closed-loop Equation (8.2) for
which we assume that Kp is suﬃciently “large” in the sense that its smallest
eigenvalue satisﬁes
λmin{Kp} > kg .
As has been shown in Section 8.2, with this choice of Kp, the closed-loop
equation has a unique equilibrium at the origin
˜qT
˙qT T = 0 ∈IR2n.
To study the stability of the latter, we consider the Lyapunov function
candidate
V (˜q, ˙q) = 1
2 ˙qTM(qd −˜q) ˙q + f(˜q)
(8.21)
3 Let  ,  : IRn →IRn, ,  ∈IRn and  = (). Then
∂ ()
∂
= ∂ ()
∂
∂()
∂
.
4 It is worth emphasizing that it is not redundant to speak of a unique global
minimum.

184
8 PD Control with Desired Gravity Compensation
where f(˜q) is given in (8.18) with ε = 2. In other words, this Lyapunov
function candidate may be written as
V (˜q, ˙q) = 1
2 ˙qTM(qd −˜q) ˙q + U(qd −˜q) −U(qd)
+ g(qd)T˜q + 1
2 ˜qTKp˜q .
The previous function is globally positive deﬁnite since it is the sum of
a globally positive deﬁnite term ˙q: ˙qT M(q) ˙q, and another globally positive
deﬁnite term of ˜q: f(˜q).
The time derivative of V (˜q, ˙q) is given by
˙V (˜q, ˙q) = ˙qTM(q)¨q + 1
2 ˙qT ˙M(q) ˙q
+ ˙qTg(qd −˜q) −g(qd)T˙q −˜qTKp ˙q ,
where we used g(qd −˜q) = ∂U(qd −˜q)/∂(qd −˜q) and also
d
dtU(qd −˜q) = ˙˜q
T∂U(qd −˜q)
∂˜q
= ˙˜q
T∂(qd −˜q)
∂˜q
T∂U(qd −˜q)
∂(qd −˜q)
= ˙˜q
T(−I)g(qd −˜q)
= ˙qTg(qd −˜q) .
Solving for M(q)¨q from the closed-loop Equation (8.2) and substituting
its value, we get
˙V (˜q, ˙q) = −˙qT Kv ˙q
where we also used Property 4.2 to eliminate ˙qT
1
2 ˙M −C

˙q. Since −˙V (˜q, ˙q)
is a positive semideﬁnite function, the origin is stable (cf. Theorem 2.2).
Since the closed-loop Equation (8.2) is autonomous, we may explore the
application of La Salle’s Theorem (cf. Theorem 2.7) to analyze the global
asymptotic stability of the origin.
To that end, notice that the set Ωis here given by
Ω=

x ∈IR2n : ˙V (x) = 0

=

x =
 ˜q
˙q

∈IR2n : ˙V (˜q, ˙q) = 0
&
= {˜q ∈IRn, ˙q = 0 ∈IRn} .

8.3 Global Asymptotic Stability
185
Observe that ˙V (˜q, ˙q) = 0 if and only if ˙q = 0. For a solution x(t) to
belong to Ωfor all t ≥0, it is necessary and suﬃcient that ˙q(t) = 0 for all
t ≥0. Therefore, it must also hold that ¨q(t) = 0 for all t ≥0. Taking this into
account, we conclude from the closed-loop Equation (8.2) that if x(t) ∈Ωfor
all t ≥0, then
0 = M(qd −˜q(t))−1 [Kp˜q(t) + g(qd) −g(qd −˜q(t)] .
Moreover, since Kp has been chosen so that λmin{Kp} > kg hence, ˜q(t) = 0
for all t ≥0 is its unique solution. Therefore,
˜q(0)T
˙q(0)T T = 0 ∈IR2n is
the unique initial condition in Ωfor which x(t) ∈Ωfor all t ≥0. Thus, from
La Salle’s theorem (cf. Theorem 2.7), it follows that the latter is enough to
guarantee global asymptotic stability of the origin
˜qT
˙qT T = 0 ∈IR2n.
In particular, we have
lim
t→∞˜q(t) = 0 ,
lim
t→∞˙q(t) = 0 ,
that is, the position control objective is achieved.
We present next an example with the purpose of showing the performance
achieved under PD control with desired gravity compensation on a 2-DOF
robot.
Example 8.3. Consider the 2-DOF prototype robot studied in Chapter
5 and illustrated in Figure 5.2.
The components of the gravitational torques vector g(q) are given
by
g1(q) = [m1lc1 + m2l1]g sin(q1) + m2lc2g sin(q1 + q2)
g2(q) = m2lc2g sin(q1 + q2) .
According to Property 4.3, the constant kg may be obtained as
(see also Example 9.2)
kg = n

max i,j,q

∂gi(q)
∂qj


= n [[m1lc1 + m2l1]g + m2lc2g]
= 23.94

kg m2/s2
.
Consider the PD control law with desired gravity compensation
of the robot shown in Figure 5.2 for position control, and where the
design matrices are taken positive deﬁnite and such that

186
8 PD Control with Desired Gravity Compensation
λmin{Kp} > kg .
In particular, we pick
Kp = diag{kp} = diag{30}
[Nm/rad] ,
Kv = diag{kv} = diag{7, 3}
[Nm s/rad] .
The components of the control input τ are given by
τ1 = kp˜q1 −kv ˙q1 + g1(qd) ,
τ2 = kp˜q2 −kv ˙q2 + g2(qd) .
The initial conditions corresponding to the positions and velocities,
are set to
q1(0) = 0,
q2(0) = 0 ,
˙q1(0) = 0,
˙q2(0) = 0 .
The desired joint positions are chosen as
qd1 = π/10 [rad]
qd2 = π/30 [rad] .
In terms of the state vector of the closed-loop equation, the initial
state is set to
⎡
⎣
˜q(0)
˙q(0)
⎤
⎦=
⎡
⎢⎣
π/10
π/30
0
0
⎤
⎥⎦=
⎡
⎢⎣
0.3141
0.1047
0
0
⎤
⎥⎦[ rad ] .
0.0
0.5
1.0
1.5
2.0
−0.1
0.0
0.1
0.2
0.3
0.4
[rad]
˜q1
0.0359
0.0138
˜q2
t [s]
..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 8.4. Graph of the position errors ˜q1 and ˜q2
Figure 8.4 shows the experimental results. In particular, it shows
that the components of the position error vector ˜q(t) tend asymptoti-
cally to a small value. They do not vanish due to non–modeled friction
eﬀects at the arm joints.

8.3 Global Asymptotic Stability
187
It is interesting to note the little diﬀerence between the results
shown in Figure 8.4 and those obtained with PD control plus gravity
compensation presented in Figure 7.3.
♦
The previous example clearly shows the good performance achieved under
PD control with desired gravity compensation for a 2-DOF robot. Certainly,
the suggested tuning procedure has been followed carefully, that is, the matrix
Kp satisﬁes λmin{Kp} > kg. Naturally, at this point one may ask the question:
What if the tuning procedure (λmin{Kp} ≤kg) is violated? As was previously
shown, if the matrix Kp is positive deﬁnite (of course, also with Kv positive
deﬁnite) then boundedness of the position and velocity errors ˜q and ˙q may
be guaranteed. Nevertheless, this situation where kg ≥λmin{Kp} yields an
interesting dynamic behavior of the closed-loop equation. Phenomena such as
bifurcations of equilibria and catastrophic jumps may occur. These types of
phenomena appear even in the case of one single link with a revolute joint.
We present next an example which illustrates these observations.
Example 8.4. Consider the pendulum model studied in Example 2.2
(see page 30),
J ¨q + mgl sin(q) = τ
where we identify g(q) = mgl sin(q).
The PD control law with desired gravity compensation applied in
the position control problem (qd constant) is in this case given by
τ = kp˜q −kv ˙q + mgl sin(qd)
where kv > 0 and we consider here that kp is a real number not
necessarily positive and not larger than kg = mgl.
The equation that governs the behavior of the control system in
closed loop may be described by
d
dt

˜q
˙q

=
⎡
⎣
−˙q
1
J [ kp˜q −kv ˙q + mgl[sin(qd) −sin(qd −˜q)] ]
⎤
⎦
which is an autonomous diﬀerential equation and whose origin [˜q
˙q]T =
0 ∈IR2 is an equilibrium regardless of the values of kp, kv and qd.
Moreover, given qd (constant) and deﬁning the set Ωqd as
Ωqd = {˜q ∈IR : kp˜q + mgl [sin(qd) −sin(qd −˜q)] = 0
∀kp} ,
any vector [˜q∗0]T ∈IR2 is also an equilibrium as long as ˜q∗∈Ωqd.
In the rest of this example we consider the innocuous case when
qd = 0, that is when the control objective is to drive the pendulum to

188
8 PD Control with Desired Gravity Compensation
•
˜q
˙q
kp
0
mgl





..................................................................................... equilibria
................................................................................................................................................................................................................................................................
..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.........................................
......................
......................
................















6
-
Figure 8.5. Bifurcation diagram
the vertical downward position. In this scenario the set Ωqd = Ω0 is
given by
Ω0 =

˜q ∈IR : ˜q = sinc−1

−kp
mgl
&
,
where the function sinc(x) =
sin(x)
x
. Figure 8.5 shows the diagram
of equilibria in terms of kp. Notice that with kp = 0 there are an
inﬁnite number of equilibria. In particular, for kp = −mgl the origin
[˜q
˙q]T = 0 ∈IR2 is the unique equilibrium. As a matter of fact, we
say that the closed-loop equation has a bifurcation of equilibria for
kp = −mgl since for slightly smaller values than −mgl there exists
a unique equilibrium while for values of kp slightly larger than −mgl
there exist three equilibria.
Even though we do not show it here, for values of kp slightly smaller
than −mgl, the origin (which is the unique equilibrium) is unstable,
while for values slightly larger than −mgl the origin is actually asymp-
totically stable and the two other equilibria are unstable. This type of
phenomenon is called pitchfork bifurcation. Figure 8.6 presents several
trajectories of the closed-loop equation for kp = −11, −4, 3, where we
considered J = 1, mgl = 9.8 and kv = 0.1
Besides the pitchfork bifurcation at kp = −mgl, there also exists
another type of bifurcation for this control system in closed loop:
saddle-node bifurcation. In this case, for some values of kp there exists
an isolated equilibrium, and for slightly smaller (resp. larger) values
there exist two equilibria, one of which is asymptotically stable and
the other unstable, while for values of kp slightly larger (resp. smaller)
there does not exist any equilibrium in the vicinity of the one which
exists for the original value of kp. As a matter of fact, for the closed-
loop control system considered here (with qd = 0), the diagram of

8.3 Global Asymptotic Stability
189
˙q
˜q
kp
kp = −11
kp = −4
kp = 3
Figure 8.6. Simulation with kp = −11, −4, 3
equilibria shown in Figure 8.5 suggests the possible existence of an
inﬁnite number of saddle-node bifurcations.
•
˜q
˙q
kp
1.8
2.6
........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ........ ....
...............................
...............................
....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
...................
........................ ..............
.......................
..............

1
6
-
Figure 8.7. Catastrophic jump 1

190
8 PD Control with Desired Gravity Compensation
The closed-loop equation also exhibits another interesting type of
phenomenon: catastrophic jumps. This situation may show up when
the parameter kp varies “slowly” passing through values that corre-
spond to saddle-node bifurcations. Brieﬂy, a catastrophic jump occurs
when for a small variation (and which moreover is slow with respect
to the dynamics determined by the diﬀerential equation in question)
of kp, the solution of the closed-loop equation whose tendency is to
converge towards a region of the state space, changes abruptly its be-
havior to go instead towards another region “far away” in the state
space. Figures 8.7 and 8.8 show such phenomenon; here we took
kp(t) = 0.01t + 1.8
•
•
˜q
˙q
t
..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.......... .........
................... ..............
...................
..............

1
6
-
Figure 8.8. Catastrophic jump 2
and we considered again the numerical values: J = 1, mgl = 9.8 and
kv = 0.1, with the initial conditions q(0) = 4 [rad] and ˙q(0) = 0 [rad/s].
When the value of kp is increased passing through 2.1288, the asymp-
totically stable equilibrium at [˜q
˙q]T = [1.43030π 0]T , disappears
and the system solution “jumps” to the unique (globally) asymptoti-
cally stable equilibrium: the origin [˜q
˙q]T = 0 ∈IR2.
♦
8.4 Lyapunov Function for Global Asymptotic Stability
A Lyapunov function which allows one to show directly global asymptotic
stability without using La Salle’s theorem is studied in this subsection. The
reference corresponding to this topic is given at the end of the chapter. We
present next this analysis for which we consider the case of robots having
only revolute joints. The reader may, if wished, omit this section and continue
his/her reading with the following section.

8.4 Lyapunov Function for Global Asymptotic Stability
191
Consider again the closed-loop Equation (8.2),
d
dt
⎡
⎣
˜q
˙q
⎤
⎦=
⎡
⎣
−˙q
M(q)−1 [Kp˜q −Kv ˙q −C(q, ˙q) ˙q + g(qd) −g(q)]
⎤
⎦.
(8.22)
As a design hypothesis, we assume here, as in Section 8.3, that the gain
position matrix Kp has been chosen to satisfy
λmin{Kp} > kg .
This selection of Kp satisﬁes the suﬃciency condition obtained in Section
8.2 to guarantee that the origin is the unique equilibrium of the closed-loop
Equation (8.22).
To study the stability properties of the origin, consider now the following
Lyapunov function candidate, which as a matter of fact, may be regarded as
a generalization of the function (8.21),
V (˜q, ˙q) = 1
2
⎡
⎣
˜q
˙q
⎤
⎦
T
P
$
%"
#
⎡
⎢⎣
2
ε2 Kp
−
ε0
1 + ∥˜ ∥M(q)
−
ε0
1 + ∥˜ ∥M(q)
M(q)
⎤
⎥⎦
⎡
⎣
˜q
˙q
⎤
⎦
+ U(q) −U(qd) + g(qd)T˜q + 1
ε1
˜qTKp˜q
"
#$
%
f(˜q)
,
= 1
2 ˙qTM(q) ˙q + U(q) −U(qd) + g(qd)T˜q
+
 1
ε1
+ 1
ε2

˜qTKp˜q −
ε0
1 + ∥˜q∥˜qTM(q) ˙q
(8.23)
where f(˜q) was deﬁned in (8.18) and the constants ε0 > 0, ε1 > 2 and ε2 > 2
are chosen so that
2λmin{Kp}
kg
> ε1 > 2
(8.24)
ε2 =
2ε1
ε1 −2 > 2
(8.25)
-
2λmin{Kp}
ε2β
> ε0 > 0
(8.26)
where β ( ≥λMax{M(q)} ) was deﬁned in Property 4.1. The condition (8.24)
guarantees that f(˜q) is a positive deﬁnite function (see Lemma 8.1), while
(8.26) ensures that P is a positive deﬁnite matrix. Finally (8.25) implies that
1
ε1 + 1
ε2 = 1
2.

192
8 PD Control with Desired Gravity Compensation
Alternatively, to show that the Lyapunov function candidate V (˜q, ˙q) is
positive deﬁnite, ﬁrst deﬁne ε as
ε = ε(∥˜q∥) =
ε0
1 + ∥˜q∥.
(8.27)
Consequently, Inequality (8.26) implies that the matrix
2
ε2
Kp −

ε0
1 + ∥˜q∥
2
M(q) = 2
ε2
Kp −ε2M(q)
is positive deﬁnite.
On the other hand, the Lyapunov function candidate (8.23) may be rewrit-
ten as
V (˜q, ˙q) = 1
2 [−˙q + ε˜q]T M(q) [−˙q + ε˜q] + 1
2 ˜qT
 2
ε2
Kp −ε2M(q)

˜q
+ U(q) −U(qd) + g(qd)T˜q + 1
ε1
˜qTKp˜q
"
#$
%
f(˜q)
,
which is clearly positive deﬁnite since the matrices M(q) and
2
ε2 Kp −ε2M(q)
are positive deﬁnite and f(˜q) is also a positive deﬁnite function (due to
λmin{Kp} > kg and Lemma 8.1).
The time derivative of the Lyapunov function candidate (8.23) along the
trajectories of the closed-loop Equation (8.22) takes the form
˙V (˜q, ˙q) = ˙qT [Kp˜q −Kv ˙q −C(q, ˙q) ˙q + g(qd) −g(q)] + 1
2 ˙qT ˙M(q) ˙q
+ g(q)T˙q −g(qd)T˙q −˜qTKp ˙q + ε ˙qTM(q) ˙q −ε˜qT ˙M(q) ˙q
−ε˜qT [Kp˜q −Kv ˙q −C(q, ˙q) ˙q + g(qd) −g(q)]
−˙ε˜qTM(q) ˙q,
where we used g(q) = ∂U(q)
∂q . After some simpliﬁcations, the time derivative
˙V (˜q, ˙q) may be written as
˙V (˜q, ˙q) = −˙qTKv ˙q + ˙qT
1
2
˙M(q) −C(q, ˙q)

˙q + ε ˙qTM(q) ˙q
−ε˜qT 
˙M(q) −C(q, ˙q)

˙q −ε˜qT [Kp˜q −Kv ˙q]
−ε˜qT [g(qd) −g(q)] −˙ε˜qTM(q) ˙q.
Finally, considering Property 4.2, i.e. that the matrix 1
2 ˙M(q) −C(q, ˙q) is
skew-symmetric and that
˙M(q) = C(q, ˙q) + C(q, ˙q)T , we get

8.4 Lyapunov Function for Global Asymptotic Stability
193
˙V (˜q, ˙q) = −˙qTKv ˙q + ε ˙qTM(q) ˙q −ε˜qTKp˜q + ε˜qTKv ˙q
−ε ˙qTC(q, ˙q)˜q −ε˜qT [g(qd) −g(q)] −˙ε˜qTM(q) ˙q .
(8.28)
As is well known, to conclude global asymptotic stability by Lyapunov’s
direct method, it is suﬃcient to prove that ˙V (0, 0) = 0 and ˙V (˜q, ˙q) < 0 for
all vectors
˜qT
˙qT T ̸= 0 ∈IR2n. These conditions are veriﬁed if ˙V (˜q, ˙q) is
a negative deﬁnite function. Observe that it is very diﬃcult to ensure from
(8.28), that ˙V (˜q, ˙q) is negative deﬁnite. With the aim of ﬁnding additional
conditions on ε0 such that ˙V (˜q, ˙q) is negative deﬁnite, we present now the
upper-bounds on the following three terms:
•
−ε ˙qTC(q, ˙q)˜q
•
−ε˜qT [g(qd) −g(q)]
•
−˙ε˜qTM(q) ˙q .
First, concerning −ε ˙qTC(q, ˙q)˜q, we have
−ε ˙qTC(q, ˙q)˜q ≤
−ε ˙qTC(q, ˙q)˜q

≤ε ∥˙q∥∥C(q, ˙q)˜q∥
≤εkC1 ∥˙q∥∥˙q∥∥˜q∥
≤ε0kC1 ∥˙q∥2
(8.29)
where we took into account Property 4.2, i.e. ∥C(q, x)y∥≤kC1 ∥x∥∥y∥, and
the deﬁnition of ε in (8.27).
Next, concerning the term −ε˜qT [g(qd) −g(q)] we have
−ε˜qT [g(qd) −g(q)] ≤
−ε˜qT [g(qd) −g(q)]

≤ε ∥˜q∥∥g(qd) −g(q)∥
≤εkg ∥˜q∥2
(8.30)
where we used Property 4.3, i.e. ∥g(x) −g(y)∥≤kg ∥x −y∥.
Finally, for the term −˙ε˜qT M(q) ˙q, we have
−˙ε˜qT M(q) ˙q ≤
−˙ε˜qT M(q) ˙q

=

ε0
∥˜q∥[1 + ∥˜q∥]2 ˜qT ˙q˜qTM(q) ˙q

≤
ε0
∥˜q∥[1 + ∥˜q∥]2 ∥˜q∥∥˙q∥∥˜q∥∥M(q) ˙q∥
≤
ε0
1 + ∥˜q∥∥˙q∥2 λMax{M(q})
≤ε0β ∥˙q∥2
(8.31)

194
8 PD Control with Desired Gravity Compensation
where we used again the deﬁnition of ε in (8.27) and Property 4.1, i.e. β ∥˙q∥≥
λMax{M(q)} ∥˙q∥≥∥M(q) ˙q∥.
From the inequalities (8.29), (8.30) and (8.31), the time derivative ˙V (˜q, ˙q)
in (8.28) reduces to
˙V (˜q, ˙q) ≤−˙qTKv ˙q + ε ˙qTM(q) ˙q −ε˜qTKp˜q + ε˜qTKv ˙q
+ ε0kC1 ∥˙q∥2 + εkg ∥˜q∥2 + ε0β ∥˙q∥2 ,
which in turn may be written as
˙V (˜q, ˙q) ≤−
⎡
⎣
˜q
˙q
⎤
⎦
T ⎡
⎣
εKp
−ε
2Kv
−ε
2Kv
1
2Kv
⎤
⎦
⎡
⎣
˜q
˙q
⎤
⎦+ εkg ∥˜q∥2
−1
2 [λmin{Kv} −2ε0(kC1 + 2β)] ∥˙q∥2 ,
(8.32)
where we used
−˙qTKv ˙q ≤−1
2 ˙qTKv ˙q −λmin{Kv}
2
∥˙q∥2
and ε ˙qTM(q) ˙q ≤ε0β ∥˙q∥2.
Finally, from (8.32) we get
˙V (˜q, ˙q) ≤−ε
⎡
⎣
∥˜q∥
∥˙q∥
⎤
⎦
T
Q
$
%"
#
⎡
⎣
λmin{Kp} −kg
−1
2λMax{Kv}
−1
2λMax{Kv}
1
2ε0 λmin{Kv}
⎤
⎦
⎡
⎣
∥˜q∥
∥˙q∥
⎤
⎦
−1
2 [λmin{Kv} −2ε0(kC1 + 2β)]
"
#$
%
δ
∥˙q∥2 .
(8.33)
Next, from the latter inequality we ﬁnd immediately the conditions on ε0
for ˙V (˜q, ˙q) to be negative deﬁnite. To that end, we ﬁrst require to guarantee
that the matrix Q is positive deﬁnite and that δ > 0. The matrix Q is positive
deﬁnite if it holds that
λmin{Kp} > kg ,
(8.34)
2λmin{Kv}(λmin{Kp} −kg)
λ2
Max{Kv}
> ε0 ,
(8.35)
and we have δ > 0 if
λmin{Kv}
2[kC1 + 2β] > ε0 .
(8.36)
Observe that (8.34) is veriﬁed since Kp was assumed to be picked so as
to satisfy λmin{Kp} > ε1
2 kg with ε1 > 2. It is important to stress that the

Bibliography
195
constant ε0 is only needed for the purposes of stability analysis and it is
not required to know its actual numerical value. Choosing ε0 so as to satisfy
simultaneously (8.35) and (8.36), we have λmin{Q} > 0. Under this scenario,
we get from (8.33) that
˙V (˜q, ˙q) ≤−
ε0
1 + ∥˜q∥λmin{Q}

∥˜q∥2 + ∥˙q∥2
−δ
2∥˙q∥2 ,
≤−ε0λmin{Q} ∥˜q∥2
1 + ∥˜q∥−δ
2∥˙q∥2 ,
which is a negative deﬁnite function. Finally, using Lyapunov’s direct method
(cf. Theorem 2.4), we conclude that the origin
˜qT
˙qT T = 0 ∈IR2n is a
globally asymptotically stable equilibrium of the closed-loop equation.
8.5 Conclusions
The conclusions drawn from the analysis presented in this chapter can be
summarized as follows.
Consider PD control with desired gravity compensation for n-DOF robots.
Assume that the desired position qd is constant.
•
If the symmetric matrices Kp and Kv of the PD control law with desired
gravity compensation are positive deﬁnite and moreover λmin{Kp} > kg,
then the origin of the closed-loop equation, expressed in terms of the state
vector
˜qT
˙qT T , is globally asymptotically stable. Consequently, for any
initial condition q(0), ˙q(0) ∈IRn we have limt→∞˜q(t) = 0 ∈IRn .
Bibliography
PD control with desired gravity compensation is the subject of study in
•
Takegaki M., Arimoto S., 1981, “A new feedback method for dynamic con-
trol of manipulators”, Journal of Dynamic Systems, Measurement, and
Control, Vol. 103, pp. 119–125.
•
Arimoto S., Miyazaki F., 1986, “Stability and robustness of PD feedback
control with gravity compensation for robot manipulators”, in F. Paul and
D. Youcef–Toumi (ed.), Robotics: Theory and Applications, DSC Vol. 3.
•
Tomei P., 1991, “Adaptive PD controller for robot manipulators”, IEEE
Transactions on Robotics and Automation, Vol. 7, No. 4, August, pp.
565–570.

196
8 PD Control with Desired Gravity Compensation
•
Kelly R., 1997, “PD control with desired gravity compensation of robotic
manipulators: A review”, The International Journal of Robotics Research,
Vol. 16, No. 5, pp. 660–672.
Topics on bifurcation of equilibria may be consulted in
•
Parker T. S., Chua L. O., 1989, “Practical numerical algorithms for chaotic
systems”, Springer-Verlag.
•
Guckenheimer J., Holmes P., 1990, “Nonlinear oscillations, dynamical sys-
tems, and bifurcation of vector ﬁelds”, Springer-Verlag.
•
Wiggins S., 1990, “Introduction to applied nonlinear dynamical systems
and chaos”, Springer-Verlag.
•
Hale J. K., Ko¸cak H., 1991, “Dynamics and bifurcations”, Springer-Verlag.
•
Jackson E. A., 1991, “Perspectives of nonlinear dynamics”, Vol. 1, Cam-
bridge University Press.
Study of the Lyapunov function for global asymptotic stability presented
in Section 8.4, is taken from
•
Kelly R., 1993, “Comments on: Adaptive PD controller for robot manip-
ulators”, IEEE Transactions on Robotics and Automation, Vol. 9, No. 1,
February, pp. 117–119.
Problems
1. Consider the model of the ideal pendulum studied in Example 8.2
J ¨q + mgl sin(q) = τ
with the following numerical values
J = 1,
mgl = 1,
qd = π/2 .
Consider the use of PD control with desired gravity compensation and
suppose the following initial conditions: q(0) = 0 and ˙q(0) = 0. From this,
we have ˜q(0) = π/2. Assume that kp = 4/π.
a) Obtain an upper-bound on ˙q(t)2.
Hint: Use (8.16).
2. Consider the PD control law with desired gravity compensation for the
pendulum described by the equation
J ¨q + mgl sin(q) = τ .

Problems
197
The equilibria of the closed-loop equation are [˜q
˙q]T = [s 0]T where s is
the solution of
kps + mgl [sin(qd) −sin(qd −s)] = 0 .
a) Show that s satisﬁes
|s| ≤2mgl
kp
.
b) Simulate the system in closed loop with the following numerical values:
J = 1, m = l = 1, g = 10, kp = 1/4, kv = 1 and with initial conditions:
q(0) = π/8 and ˙q(0) = 0. For the desired angular position qd = π/2,
verify by simulation that limt→∞q(t) ̸= qd.
c) Obtain by simulation the approximate value of limt→∞q(t). Verify
that limt→∞|qd −q(t)| ≤2mgl
kp .
3. Consider the model of the ideal pendulum studied in Example 8.1
J ¨q + mgl sin(q) = τ
with the following numerical values:
J = 1,
mgl = 1,
qd = π/2 .
Consider the use of PD control with desired gravity compensation.
a) Obtain the closed-loop equation in terms of the state vector [˜q
˙q]T .
b) Compute the value of the constant kg (see Property 4.3).
c) In Example 8.1 we showed that the closed-loop equation had three
equilibria for kp = 0.25. Compute a value for kp that guarantees that
the origin [˜q
˙q]T = 0 ∈IR2 is the unique equilibrium point of the
closed-loop equation.
d) Consider the previously obtained value for kp. Show that the origin is
a stable equilibrium point.
Hint: Show that
f(˜q) = −mgl cos(qd −˜q) + mgl cos(qd)
+ mgl sin(qd)˜q + 1
2kp˜q2
is a positive deﬁnite function. Use the Lyapunov function candidate
V (˜q, ˙q) = 1
2J ˙q2 + f(˜q) .
e) Use La Salle’s theorem (cf. Theorem 2.7) to show that the origin is
globally asymptotically stable.

198
8 PD Control with Desired Gravity Compensation
4. Verify the expression for ˙V (˜q, ˙q) given in Equation (8.7).
5. Consider the model of robots with elastic joints, (3.27) and (3.28), but with
an additional term for friction at the links f( ˙q) that satisﬁes ˙qT f( ˙q) >
0
∀˙q ̸= 0 and f(0) = 0 , i.e.
M(q)¨q + C(q, ˙q) ˙q + g(q) + f( ˙q) + K(q −θ) = 0 ,
J¨θ −K(q −θ) = τ .
It is assumed that only the vector of positions θ of the motors axes, and the
corresponding velocities ˙θ, are available from measurement. The control
objective is that q(t) →qd as t →∞where qd is constant.
A variant of the PD control with desired gravity compensation is5
τ = Kp˜θ −Kv ˙θ + g(qd)
where
˜θ = qd −θ + K−1g(qd) ,
˜q = qd −q ,
and Kp, Kv ∈IRn×n are symmetric positive deﬁnite matrices. The matrix
of elasticity K, is diagonal and positive deﬁnite.
a) Verify that the closed-loop equation in terms of the state vector

˜qT
˜θ
T
˙qT
˙θ
T T
, may be written as
d
dt
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
˜q
˜θ
˙q
˙θ
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
−˙q
−˙θ
M(q)−1 
−K(˜θ −˜q) + g(qd) −C(q, ˙q) ˙q −g(q) −f( ˙q)

J−1 
Kp˜θ −Kv ˙θ + K(˜θ −˜q)

⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
b) Verify that the origin is an equilibrium of the closed-loop equation.
c) Show that if λmin{Kp} > kg and λmin{K} > kg, then the origin is a
stable equilibrium point.
Hint: Use the following Lyapunov function:
V (˜q, ˜θ, ˙q, ˙θ) = V1(˜q, ˜θ, ˙q, ˙θ) + 1
2 ˜qTK˜q + V2(˜q)
5 This controller was proposed and analyzed in Tomei P., 1991, “A simple PD con-
troller for robots with elastic joints”, IEEE Transactions on Automatic Control,
Vol. 36, No. 10, October.

Problems
199
where
V1(˜q, ˜θ, ˙q, ˙θ) = 1
2 ˙qT M(q) ˙q + 1
2
˙θ
T J ˙θ + 1
2
˜θ
T Kp˜θ
+ 1
2
˜θ
T K˜θ −˜θ
T K˜q ,
V2(˜q) = U(qd −˜q) −U(qd) + ˜qT g(qd) ,
and verify that
˙V (˜q, ˜θ, ˙q, ˙θ) = −˙θ
T Kv ˙θ −˙qT f( ˙q) .

9
PID Control
With PD control we are able to achieve the position control objective for
robots whose models do not contain the gravitational term (i.e. g(q) = 0). In
this case, the tuning procedure1 for PD control is trivial since it is enough to
select the design matrices Kp and Kv to be symmetric and positive deﬁnite
(see Chapter 6).
In the case where the robot model contains the vector of gravitational
torques (i.e. g(q) ̸= 0) and if in particular, g(qd) ̸= 0, where qd is the joint
desired position, then the position control objective cannot be achieved by
means of a simple PD control law. As a matter of fact it may happen that the
position error ˜q tends to a constant vector but which is always diﬀerent from
the vector 0 ∈IRn. Then, from an automatic control viewpoint and with the
aim of satisfying the position control objective, in this case it seems natural
to introduce an Integral component to the PD control to drive the position
error to zero. This reasoning justiﬁes the application of Proportional Integral
Derivative (PID) control to robot manipulators.
The PID control law is given by
τ = Kp˜q + Kv ˙˜q + Ki
 t
0
˜q(σ) dσ
(9.1)
where the design matrices Kp, Kv, Ki ∈IRn×n, which are respectively called
“position, velocity and integral gains”, are symmetric positive deﬁnite and
suitably selected. Figure 9.1 shows the block-diagram of the PID control for
robot manipulators.
Nowadays, most industrial robot manipulators are controlled by PID con-
trollers. The wide use of robot manipulators in everyday applications, is testa-
ment to the performance that can be achieved in a large variety of applications
1 By ‘tuning procedure’ the reader should interpret the process of determining the
numerical values of the design parameters of the control law, which guarantee the
achievement of the control objective.

202
9 PID Control
ROBOT
Kp
Kv
τ
˙qd
Σ
Σ
Σ
Ki
. t
0
q
˙q
qd
Figure 9.1. Block-diagram: PID control
when using PID control. However, in contrast to PD control, the tuning proce-
dure for PID controllers, that is, the procedure to choose appropriate positive
deﬁnite matrices Kp, Kv and Ki, is far from trivial.
In practice, the tuning of PID controllers is easier for robots whose trans-
mission system includes reduction mechanisms such as gears or bands. The
use of these reductions eﬀectively increases the torque or force produced by
the actuators, and therefore, these are able to drive links of considerably large
masses. In principle, this has the consequence that large accelerations may
be reached for ‘light’ links. Nevertheless, the presence of reduction mecha-
nisms, such as gears and bands, may introduce undesired physical phenomena
that hamper the performance of the robot in its required task. Among these
phenomena we cite vibrations due to backlash among the teeth of the gears,
positioning errors and energy waste caused by friction in the gears, positioning
errors caused by vibrations and elasticity of the bands and by gear torsions.
In spite of all these the use of reduction mechanisms is common in most robot
manipulators. This has a positive impact on the tuning task of controllers, and
more particularly of PID controllers. Indeed, as has been shown in Chapter 3
the complete dynamic of the robot with high-reduction-ratio transmissions is
basically characterized by the model of the actuators themselves, which are
often modeled by linear diﬀerential equations. Thus, in this scenario the diﬀer-
ential equation that governs the behavior of the closed-loop system becomes
linear and therefore, the tuning of the controller becomes relatively simple.
This last topic is not treated here since it is well documented in the literature;
the interested reader is invited to see the texts cited at the end of the chapter.
Here, we consider the more general nonlinear case.
In the introduction to Part II we assumed that the considered robot ac-
tuators were ideal sources of torques and forces. Under this condition, the
dynamic model of a robot of n DOF is given by (3.18), i.e.
M(q)¨q + C(q, ˙q) ˙q + g(q) = τ ,
(9.2)

9 PID Control
203
where the vector of gravitational torques g(q) is clearly present. In this chap-
ter, we assume that the joints of the robot are all revolute.
We study the control system formed by the PID controller given by Equa-
tion (9.1) and the robot model (9.2). This study is slightly more complex than
that for the PID control of robots with high-reduction actuators. Speciﬁcally,
we obtain a tuning procedure for PID control that guarantees achievement of
the position control objective, locally. In other words, for the desired constant
position qd, tuning ensures that limt→∞˜q(t) = 0, as long as the initial posi-
tion error ˜q(0) and the initial velocity error ˙q(0) are suﬃciently “small”. From
an analytic viewpoint this is done by proving local asymptotic stability of the
origin of the equation that describes the behavior of the closed-loop system.
For this analysis, we use the following information drawn from Properties 4.1,
4.2, and 4.3:
•
The matrix 1
2
˙M(q) −C(q, ˙q) is skew-symmetric.
•
There exists a non-negative constant kC1 such that for all x, y, z ∈IRn,
we have
∥C(x, y)z∥≤kC1 ∥y∥∥z∥.
•
There exists a non-negative constant kg such that for all x, y ∈IRn, we
have
∥g(x) −g(y)∥≤kg ∥x −y∥,
where kg ≥

∂ ()
∂
 for all q ∈IRn.
The integral action of the PID control law (9.1) introduces an additional
state variable that is denoted here by ξ, and whose time derivative is ˙ξ = ˜q.
The PID control law may be expressed via the two following equations:
τ = Kp˜q + Kv ˙˜q + Kiξ
(9.3)
˙ξ = ˜q .
(9.4)
The closed-loop equation is obtained by substituting the control action τ
from (9.3) in the robot model (9.2), i.e.
M(q)¨q + C(q, ˙q) ˙q + g(q) = Kp˜q + Kv ˙˜q + Kiξ
˙ξ = ˜q,
which may be written in terms of the state vector

ξT
˜qT
˙˜q
T T
, as
d
dt
⎡
⎢⎢⎢⎣
ξ
˜q
˙˜q
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎢⎣
˜q
˙˜q
¨qd −M(q)−1 
Kp˜q + Kv ˙˜q + Kiξ −C(q, ˙q) ˙q −g(q)

⎤
⎥⎥⎥⎥⎦
.
(9.5)

204
9 PID Control
The equilibria of the equation above, if any, have the form

ξT
˜qT
˙˜q
T T
=

ξ∗T
0T
0T T
where
ξ∗= K−1
i
[M(qd)¨qd + C(qd, ˙qd) ˙qd + g(qd)]
must be a constant vector. Certainly, for ξ∗to be a constant vector, if the
desired joint position qd is time-varying, it may not be arbitrary but should
have a very particular form. One way to obtain a qd for which ξ∗is constant,
is by solving the diﬀerential equations
d
dt
⎡
⎣
qd
˙qd
⎤
⎦=
⎡
⎣
˙qd
M(qd)−1 [τ 0 −C(qd, ˙qd) ˙qd −g(qd)]
⎤
⎦,
⎡
⎣
qd(0)
˙qd(0)
⎤
⎦∈IR2n
(9.6)
where τ 0 ∈IRn is a constant vector. This way ξ∗= K−1
i
τ 0. In particular,
if τ 0 = 0 ∈IRn then the origin of the closed-loop Equation (9.5), is an
equilibrium. Notice that the solution of (9.6) is simply the position q and
velocity ˙q when one applies a constant torque τ = τ 0 to the robot in question.
In general, it is not possible to obtain an expression in closed form for qd, so
Equation (9.6) must be solved numerically. Nevertheless, the resulting desired
position qd, may have a capricious form and therefore be of little utility. This
is illustrated in the following example.
Example 9.1. Consider the Pelican prototype robot studied in Chapter
5, and shown in Figure 5.2.
Considering τ 0 = 0 ∈IR2 and the initial condition [qd1 qd2
˙qd1
˙qd2]T = [−π/20 π/20 0 0]T ; the numerical solution of (9.6) for
qd(t), is shown in Figure 9.2.
With qd(t), whose two components are shown in Figure 9.2, the
origin

ξT
˜qT
˙˜q
T T
= 0 ∈IR6 is an equilibrium of the closed-loop
equation formed by the PID control and the robot in question.
♦
In the case where the desired joint position qd is an arbitrary function
of time, and does not tend to a constant vector value, then the closed-loop
equation has no equilibrium. In such cases, we cannot study the stability in
the sense of Lyapunov and in particular, one may not expect that the position
error ˜q tend to zero. In the best case scenario, and under the hypothesis that
the initial position and velocity errors ˜q(0) and ˙q(0) are small, the position
error ˜q remains bounded. The formal proof of these claims is established in
the works cited at the end of the chapter.
Let us come back to our discussion on the determination of an equilibrium
for the closed-loop system. We said that a suﬃcient condition for the existence

9 PID Control
205
0
2
4
6
8
10
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
[rad]
qd1
qd2
t [s]
.............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 9.2. Desired joint positions
and unicity of the equilibrium for the closed-loop Equation (9.5) is that the
desired position qd(t) be constant. Denoting by qd such a constant vector the
equilibrium is
⎡
⎢⎢⎢⎣
ξ
˜q
˙˜q
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
Ki
−1 g(qd)
0
0
⎤
⎥⎥⎥⎦∈IR3n .
This equilibrium may of course, be translated to the origin via a suitable
change of variable, e.g. deﬁning
z = ξ −Ki
−1g(qd) .
Then, the corresponding closed-loop equation may be expressed in terms of
the state vector

zT
˜qT
˙qT T as
d
dt
⎡
⎢⎢⎢⎣
z
˜q
˙q
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
˜q
−˙q
M(q)−1 [Kp˜q −Kv ˙q + Kiz + g(qd) −C(q, ˙q) ˙q −g(q)]
⎤
⎥⎥⎥⎦.
(9.7)
Notice that the previous equation is autonomous and its unique equilibrium
is the origin

zT
˜qT ˙qT T = 0 ∈IR3n.
For the sequel, we ﬁnd it convenient to adopt the following global change
of variables,

206
9 PID Control
⎡
⎣
w
˜q
˙q
⎤
⎦=
⎡
⎣
α I
I
0
0
I
0
0
0
I
⎤
⎦
⎡
⎣
z
˜q
˙q
⎤
⎦
(9.8)
with α > 0.
The closed-loop Equation (9.7) may be expressed as a function of the new
variables as
d
dt
⎡
⎢⎢⎢⎣
w
˜q
˙q
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎢⎣
α ˜q −˙q
−˙q
M(q)−1 
Kp −1
αKi

˜q −Kv ˙q + 1
αKiw + g(qd) −C(q, ˙q) ˙q −g(q)

⎤
⎥⎥⎥⎥⎦
.
(9.9)
These equations are autonomous and the origin of the state space,

wT
˜qT
˙qT T
= 0 ∈IR3n is the unique equilibrium of the closed-loop system.
Moreover, due to the globality of the change of variable (9.8), the sta-
bility features of this equilibrium correspond to those for the equilibrium

zT
˜qT
˙qT T = 0 ∈IR3n of Equation (9.7).
If we can ﬁnd conditions on the matrices Kp, Kv and Ki of the PID con-
troller such that the origin of the closed-loop Equation (9.9) is asymptotically
stable, i.e. such that the origin is stable and at least for suﬃciently small val-
ues of the initial states z(0), ˜q(0) and ˙q(0), the state – particularly ˜q(t) – tend
asymptotically to zero, then we are able to conclude that the position control
objective is achieved (at least locally). Therefore, based on this argument we
use Lyapunov’s direct method via La Salle’s theorem to establish conditions
under which the choice of design matrices for the PID controller guarantee
asymptotic stability of the origin of the closed-loop Equation (9.9).
Thus, let us study the stability of the origin of the equation closed-loop
(9.9). This equation governs the behavior of n-DOF robot manipulators under
PID control in the case of a constant desired position qd. Speciﬁcally, we shall
see that if the matrices Kp and Kv are suﬃciently “large” and the integral
gain matrix Ki suﬃciently “small” in the following sense
λmin{M}λmin{Kv}
λMax
2{M}
>
λMax{Ki}
λmin{Kp} −kg
,
(9.10)

9.1 Lyapunov Function Candidate
207
and moreover
λmin{Kp} > kg
(9.11)
then, we can guarantee that the position control objective is achieved locally.
As a matter of fact, the larger the margin with which the inequality (9.10)
holds, the larger the domain of attraction2 of the equilibrium will be. The
property of asymptotic stability with domain of attraction arbitrarily large is
commonly referred to as semiglobal asymptotic stability.
9.1 Lyapunov Function Candidate
To study the stability of the origin of the state space, we use Lyapunov’s
direct method by proposing the following Lyapunov function candidate
V (˜q, ˙q, w) = 1
2
⎡
⎢⎢⎣
w
˜q
˙q
⎤
⎥⎥⎦
T ⎡
⎢⎢⎣
1
αKi
0
0
0
αKv
−αM(q)
0
−αM(q)
M(q)
⎤
⎥⎥⎦
⎡
⎢⎢⎣
w
˜q
˙q
⎤
⎥⎥⎦
+ 1
2 ˜qT

Kp −1
αKi

˜q + U(qd −˜q) −U(qd) + ˜qT g(qd)
(9.12)
where U(q) denotes as usual, the robot’s potential energy and α is the positive
constant used in the deﬁnition of the variable transformation (9.8). For the
sequel we assume that this number satisﬁes
λmin{M}λmin{Kv}
λMax
2{M}
> α >
λMax{Ki}
λmin{Kp} −kg
.
(9.13)
Following the tuning guide given by (9.10), there always exists α that
satisﬁes the above.
For the Lyapunov function candidate (9.12) to be a Lyapunov function we
must verify ﬁrst that it is positive deﬁnite. For this, consider the following
terms from this function,
1
2 ˜qT 
Kp −1
αKi

˜q + U(qd −˜q) −U(qd) + ˜qT g(qd) .
According to Example B.2 of Appendix B and taking ε = 2, we conclude
that the function deﬁned as the sum of these terms is positive deﬁnite, globally
for all ˜q if
2 Roughly, for the purposes of this book, a domain of attraction may be considered
as the set of all possible initial conditions which generate trajectories that tend
to the equilibrium asymptotically.

208
9 PID Control
λmin{Kp −1
αKi} > kg .
In its turn, this inequality is implied by3
λmin{Kp} −1
αλMax{Ki} > kg ,
which holds due to the lower-bound condition imposed on α, in accordance
with (9.13). Therefore, we may claim that the Lyapunov function candidate
(9.12) satisﬁes
V (˜q, ˙q, w) ≥1
2
⎡
⎢⎢⎣
w
˜q
˙q
⎤
⎥⎥⎦
T ⎡
⎢⎢⎣
1
αKi
0
0
0
αKv
−αM(q)
0
−αM(q)
M(q)
⎤
⎥⎥⎦
⎡
⎢⎢⎣
w
˜q
˙q
⎤
⎥⎥⎦.
On the other hand using the inequalities
1
αwT Kiw ≥1
αλmin{Ki} ∥w∥2 ,
α ˜qT Kv˜q ≥α λmin{Kv} ∥˜q∥2 ,
˙qT M(q) ˙q ≥λmin{M} ∥˙q∥2 ,
−α˜qT M(q) ˙q ≥−αλMax{M} ∥˜q∥∥˙q∥,
we come to the following lower-bound for the Lyapunov function candidate,
V (˜q, ˙q, w) ≥α
2
⎡
⎢⎢⎢⎣
∥w∥
∥˜q∥
∥˙q∥
⎤
⎥⎥⎥⎦
T⎡
⎢⎢⎢⎢⎣
1
α2 λmin{Ki}
0
0
0
λmin{Kv}
−λMax{M}
0
−λMax{M}
1
αλmin{M}
⎤
⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
∥w∥
∥˜q∥
∥˙q∥
⎤
⎥⎥⎥⎦.
This shows that V (˜q, ˙q, w) is globally positive deﬁnite, since α is supposed to
satisfy (9.13), in particular because
3 Theorem of Weyl (R. A. Horn and C. R. Johnson, 1985, “Matrix Analysis”,
Cambridge University Press, pp. 181.). For matrices A and B symmetric it holds
that
λmin{A + B} ≥λmin{A} + λmin{B} .
On the other hand, since λmin{A} = −λMax{−A}, we have
λmin{A −B} ≥λmin{A} −λMax{B}

9.2 Time Derivative of the Lyapunov Function Candidate
209
λmin{M}λmin{Kv}
λMax
2{M}
> α ,
which implies that the determinant of the ‘southeastern’ 2 × 2 sub-block in
the matrix above is positive for all q.
9.2 Time Derivative of the Lyapunov Function
Candidate
Once we have established the conditions under which the Lyapunov function
candidate is (globally) positive deﬁnite, we may proceed to compute its time
derivative. After some straightforward algebraic computations which involve
the use of the skew-symmetry of the matrix 1
2 ˙M(q)−C(q, ˙q) and the equality
˙M(q) = C(q, ˙q)+C(q, ˙q)T established in Property 4.2, the time derivative of
the Lyapunov function candidate (9.12) along the solutions of the closed-loop
Equation (9.9), may be written as
˙V (˜q, ˙q, w) = −˙qT [Kv −αM(q)] ˙q −˜qT [αKp −Ki] ˜q
−α˜qT C(q, ˙q)T ˙q −α˜qT [g(qd) −g(q)]
(9.14)
where we also used (3.20), i.e. g(q) = ∂U(q)/∂q .
From standard properties of symmetric positive deﬁnite matrices we con-
clude also that the ﬁrst two terms of the derivative of the Lyapunov function
candidate above, satisfy the following inequalities:
−˙qT [Kv −αM(q)] ˙q ≤−[λmin{Kv} −α λMax{M}] ∥˙q∥2
and
−˜qT [αKp −Ki] ˜q ≤−[α λmin{Kp} −λMax{Ki}] ∥˜q∥2
respectively.
On the other hand, from Properties 4.2 and 4.3 and using:
•
∥C(x, y)z∥≤kC1 ∥y∥∥z∥,
•
∥g(x) −g(y)∥≤kg ∥x −y∥,
we may show that the last two terms in the expression of the derivative of the
Lyapunov function candidate satisfy
−α˜qT C(q, ˙q)T ˙q ≤α kC1 ∥˜q∥∥˙q∥2
and
−α˜qT [g(qd) −g(q)] ≤α kg ∥˜q∥2 .

210
9 PID Control
Consequently, it also holds that
˙V (˜q, ˙q, w) ≤−

∥˜q∥
∥˙q∥
T 
Q11
0
0
Q22(˜q)
 
∥˜q∥
∥˙q∥

(9.15)
where
Q11 = α [λmin{Kp} −kg] −λMax{Ki},
Q22(˜q) = λmin{Kv} −α [λMax{M} + kC1 ∥˜q∥] .
We show next that there exists a ball D of radius η > 0 centered at the
origin of the state space, that is,
D :=
⎧
⎨
⎩˜q, ˙q, w ∈IRn :

w
˜q
˙q

< η
⎫
⎬
⎭
on which ˙V (˜q, ˙q, w) is negative semideﬁnite.
With this goal in mind, notice that we have from the condition (9.13)
imposed on α that
λmin{M}λmin{Kv} [λmin{Kp} −kg]
λMax{Ki}
> λ2
Max{M} .
Since obviously λMax{M} ≥λmin{M} , then
λmin{Kv} [λmin{Kp} −kg]
λMax{Ki}
> λMax{M}
and knowing that kC1 ≥0, it readily follows that
1
kC1
λmin{Kv} [λmin{Kp} −kg]
λMax{Ki}
−λMax{M}

≥0 .
(9.16)
It is now convenient to deﬁne the radius η of the ball D centered at the
origin of the state space to be exactly the term on the left-hand side of the
inequality (9.16), that is
η :=
1
kC1
λmin{Kv} [λmin{Kp} −kg]
λMax{Ki}
−λMax{M}

.
(9.17)
It is important to observe that the radius η is not only positive but it
increases as λmin{Kp} and λmin{Kv} increase and as λMax{Ki} decreases,
while always satisfying the condition (9.13) on α.
We now show that ˙V (˜q, ˙q, w) is negative semideﬁnite on the ball D. On
this region of the state space we have

9.3 Asymptotic Stability
211
∥˜q∥< η .
Incorporating the deﬁnition (9.17) of η we get
∥˜q∥<
1
kC1
λmin{Kv} [λmin{Kp} −kg]
λMax{Ki}
−λMax{M}

which, after some simple manipulations, yields the inequality
λmin{Kv}
λMax{M} + kC1 ∥˜q∥>
λMax{Ki}
λmin{Kp} −kg
which is valid on the region D.
Since α is any real number that satisﬁes the condition (9.13) and in par-
ticular it satisﬁes
α >
λMax{Ki}
λmin{Kp} −kg
,
it can always be picked to satisfy also,
λmin{Kv}
λMax{M} + kC1 ∥˜q∥> α >
λMax{Ki}
λmin{Kp} −kg
on the region D. It is precisely these inequalities that captures the conditions
on α such that the scalars Q11 and Q22(˜q) in the derivative (9.15) of the
Lyapunov function candidate are strictly positive. This implies that ˙V (˜q, ˙q, w)
is negative semideﬁnite on the ball D with radius η deﬁned by (9.17).
9.3 Asymptotic Stability
Summarizing, so far we have shown that if the matrices Kp, Kv and Ki of the
PID control law satisfy the conditions (9.10) and (9.11), then V (˜q, ˙q, w) is
a globally positive deﬁnite function while ˙V (˜q, ˙q, w) is negative semideﬁnite
– locally, though the domain of validity may be arbitrarily enlarged by an
appropriate choice of the control gains. Therefore, according to Theorem 2.2,
the origin of the closed-loop Equation (9.9), is a stable equilibrium. Since
˙V (˜q, ˙q, w) is not negative deﬁnite but only negative semideﬁnite, Theorem
2.4 cannot be invoked to prove asymptotic stability. Yet, since the closed-loop
Equation (9.9) is autonomous, we may use a local version of La Salle’s theorem
(i.e. a local version of Theorem 2.7).
Since the function ˙V (˜q, ˙q, w) obtained in (9.15) is negative semideﬁnite
but only locally, Theorem 2.7 may not be invoked directly. Even though we do
not show this here4, it is also true that if in the statement of Theorem 2.7 we
4 See any of the cited texts on nonlinear systems.

212
9 PID Control
replace “ ˙V (x) ≤0 for all x ∈IRn”, by “ ˙V (x) ≤0 for all x ∈IRn suﬃciently
small in norm” then, one can guarantee local asymptotic stability. We may
proceed to claim that in this case the set Ωis given by
Ω=

x ∈IR3n : ˙V (x) = 0

=
⎧
⎨
⎩x =
⎡
⎣
w
˜q
˙q
⎤
⎦∈IR3n :
˙V (˜q, ˙q, w) = 0
⎫
⎬
⎭
= {w ∈IRn, ˜q = 0 ∈IRn, ˙q = 0 ∈IRn} .
Observe that from (9.14) and with the restrictions imposed on the choice
of α, it follows that ˙V (˜q, ˙q, w) = 0 if and only if ˜q = 0 and ˙q = 0. For a
solution x(t) to belong to Ωfor all t ≥0, it is necessary and suﬃcient that
˜q = 0 and ˙q(t) = 0 for all t ≥0. Therefore it must also hold that ¨q(t) = 0
for all t ≥0. Taking this into consideration, we conclude from the closed-loop
Equation (9.9) that if x(t) ∈Ωfor all t ≥0, then
˙w(t) = 0
0 = 1
αM(qd)−1Kiw(t) ,
which, since M(qd) is positive deﬁnite, implies that w(t) = 0 for all t ≥0.
Therefore,

w(0)T
˜q(0)T
˙q(0)T T = 0 ∈IR3n is the only initial condition
in Ωfor which x(t) ∈Ωfor all t ≥0. Finally, we conclude from all this that the
origin of the closed-loop Equation (9.9) is locally asymptotically stable. It is
worth emphasizing that in the particular situation of robots for which kC1 = 0,
e.g. a pendulum, some Cartesian robots or with transmission by levers, the
function ˙V (˜q, ˙q, w) obtained in (9.15), is globally negative semideﬁnite. In
this situation, the asymptotic stability of the origin is also global.
The analysis developed so far applies to the classic PID control law given
by (9.3) and (9.4). We have also assumed that the joint desired position qd
is constant. In the practical implementation of the PID controller on ordi-
nary personal computers, the desired position qd may be a piecewise constant
function, being constant in between two sampling times. Therefore, before
and after the sampling times, the desired position qd takes constant values
which are usually diﬀerent, and at the sampling instant there occurs an abrupt
change of magnitude. For this reason, the position error ˜q = qd −q, and the
control action τ = Kp˜q−Kv ˙q+Kiξ also vary abruptly at the sampling times.
Consequently, the control action τ demands instantaneous variations to the
actuators; in this situation the latter may be damaged or, simply, we may
obtain unacceptable performance in some tasks.
With the aim of conserving the advantages of PID control but avoiding this
undesirable phenomenon, several modiﬁcations to the classical PID control
have been proposed in the literature. An interesting modiﬁcation is

9.4 Tuning Procedure
213
τ = −Kpq −Kv ˙q + Kiξ
where
ξ(t) =
 t
0
˜q(σ) dσ + ξ(0) .
This modiﬁed PID control preserves exactly the same closed-loop Equation
(9.7) that the classical PID control, but with z deﬁned by
z = ξ −K−1
i
[g(qd) + Kpqd] .
Therefore, the analysis and conclusions established above also apply to
this modiﬁed PID control.
9.4 Tuning Procedure
From the stability analysis presented in the previous subsections we can draw
a tuning procedure which is fairly simple for PID control. This method yields
symmetric matrices Kp, Kv and Ki that guarantee achievement of the position
control objective, locally.
The procedure stems from (9.11) and from the condition (9.13) imposed
on α and may be summarized in terms of the eigenvalues of the gain matrices
as follows:
•
λMax{Ki} ≥λmin{Ki} > 0 ;
•
λMax{Kp} ≥λmin{Kp} > kg ;
•
λMax{Kv} ≥λmin{Kv} >
λMax{Ki}
λmin{Kp} −kg
· λMax
2{M}
λmin{M} .
It is important to underline that this tuning procedure requires knowledge
of the structure of the inertia matrix M(q) and of the vector of gravita-
tional torques g(q) of the robot in question. This, is necessary to compute
λmin{M(q)}, λMax{M(q)} and kg respectively. Nonetheless, since it is suﬃ-
cient to have upper-bounds on λMax{M(q)} and kg, and a lower-bound for
λmin{M(q)} to use the tuning procedure, it is not necessary to know the exact
values of the dynamic parameters of the robot, e.g. masses and inertias, but
only the bounds.
Next, we present an example in order to show an application of the ideas
discussed above.
Example 9.2. Consider the 2-DOF Pelican robot shown in Figure 9.3.
The elements of the inertia matrix M(q) are

214
9 PID Control
l2
lc2
q2
q1
I1
m1
g
y
x
l1
m2
I2
lc1
Link 1
Link 2
Figure 9.3. Diagram of the Pelican prototype robot
M11(q) = m1l2
c1 + m2

l2
1 + l2
c2 + 2l1lc2 cos(q2)

+ I1 + I2
M12(q) = m2

l2
c2 + l1lc2 cos(q2)

+ I2
M21(q) = m2

l2
c2 + l1lc2 cos(q2)

+ I2
M22(q) = m2l2
c2 + I2.
The components of the gravitational torques vector g(q), are given
by
g1(q) = (m1lc1 + m2l1)g sin(q1) + m2lc2g sin(q1 + q2)
g2(q) = m2lc2g sin(q1 + q2).
The purpose of this example is to use the tuning procedure pre-
sented above in order to determine suitable gain matrices Kp, Kv and
Ki. First, we compute the value of kg and then that of the eigenvalues
λmin{M(q)} and λMax{M(q)}.
Using Property 4.3, as well as the elements of the vector of gravi-
tational torques g(q), we obtain
kg = n

Max i,j,q

∂gi(q)
∂qj


= n(m1lc1 + m2l1 + m2lc2)g
= 23.94

kg m2/s2
where we also used the numerical values of the robot parameters listed
in Table 5.1 on page 115.

9.4 Tuning Procedure
215
We proceed next to compute λmin{M(q)} and λMax{M(q)}, which
for this robot depend only on q2; we do this by evaluating the matrix
M(q) for a set of values of q2 between 0 and 2π, and extracting the
corresponding eigenvalues. The values obtained are
λmin{M(q)} = 0.011

kg m2
,
λMax{M(q)} = 0.361,

kg m2
which correspond to q2 = 0.
With the numerical values of λmin{M(q)}, λMax{M(q)} and kg,
and following the tuning procedure, we ﬁnally determine the following
matrices:
Ki = diag{1.5}
[Nm / (rad s)] ,
Kp = diag{30}
[Nm / rad] ,
Kv = diag{7, 3}
[Nm s / rad] .
0.0
12.5
25.0
37.5
50.0
−0.1
0.0
0.1
0.2
0.3
0.4
[rad]
˜q1
˜q2
t [s]
.......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 9.4. Graphs of position errors ˜q1 and ˜q2
Figure 9.4 depicts the position errors against time; notice that
the scale on the ordinates axis spans up to 50 s which is longer than
the intervals used elsewhere. We may conclude from this, that the
transient response is slower than those obtained with PD control with
gravity compensation (see Figure 7.3) and PD control with desired
gravity compensation (see Figure 8.4). This is due to the fact that the
control gains of the PID control law were chosen according with the
tuning procedure exposed in this chapter, which limits the maximal
eigenvalue of Ki by a relatively small upper-bound.
However, as may be appreciated from Figure 9.5, if the tuning pro-
cedure is violated the performance of PID control improves to parallel

216
9 PID Control
0.0
0.5
1.0
1.5
2.0
−0.1
0.0
0.1
0.2
0.3
0.4
[rad]
˜q1
˜q2
t [s]
...........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
...............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 9.5. Graphs of position errors ˜q1 and ˜q2
the respective performances of PD control with gravity compensation
and PD control with desired gravity compensation. The latter exper-
imental results have been obtained with the following gains:
Kp =

30
0
0
30

[Nm / rad] ,
Kv =

7
0
0
3

[Nm s / rad] ,
Ki =

70
0
0
100

[Nm / (rad s)] ,
that is, Kp and Kv have the same values than in the cases of the
PD-based control laws.
♦
9.5 Conclusions
We may summarize the ideas of this chapter as follows. Consider PID control
for n-DOF robots and assume that the desired position qd is constant.
•
If the symmetric matrices Kp, Kv and Ki of the PID control law satisfy
(i ) λMax{Ki} ≥λmin{Ki} > 0
(ii) λMax{Kp} ≥λmin{Kp} > kg
(iii) λMax{Kv} ≥λmin{Kv} >
λMax{Ki}
λmin{Kp} −kg
· λMax
2{M}
λmin{M}

Bibliography
217
then the origin of the closed-loop equation, expressed in terms of the state
vector

wT
˜qT
˙qT T is locally asymptotically stable. Consequently, if
the initial conditions are “suﬃciently small”, we have limt→∞˜q(t) = 0.
Nevertheless, this conclusion holds also for “large” initial conditions as long
as λmin{Kp} and λmin{Kv} also are “large” and λMax{Ki} are “small”.
If the terms of centrifugal and Coriolis forces, C(q, ˙q) do not appear in
the robot dynamic model then, the asymptotic stability is global.
Bibliography
The following works had a strong inﬂuence on the ﬁnal form that this chapter
took.
•
Arimoto S., Miyazaki F., 1984, “Stability and robustness of PID feedback
control for robot manipulators of sensory capability”, in M. Brady and R.
P. Paul (ed.), Robotics Research: First International Symposium, MIT
Press, pp. 783–799.
•
Ortega R., Lor´ıa A., Nicklasson P. J., Sira-Ram´ırez H., 1998, “Passivity-
based control of Euler-Lagrange systems mechanical, electrical and elec-
tromechanical applications”, Springer-Verlag: London, Communications
and Control Engg. Series.
•
Kelly R., 1995, “A tuning procedure for stable PID control of robot manip-
ulators”, Robotica, Vol. 13, Part 2, March–April, pp. 141–148.
•
Meza J. L., Santib´a˜nez V., 2001, “An´alisis simple de estabilidad asint´oti-
ca semiglobal de un regulador PID lineal para robots manipuladores”, 3er.
Congreso Mexicano de Rob´otica, Quer´etaro, Qro., Mexico.
The study of PID control for robots with dynamic models which are “dom-
inated” by the dynamics of the actuators (DC motors), is presented in the
following texts.
•
Paul R., 1981, “Robot manipulators: Mathematics, programming, and con-
trol”, The MIT Press.
•
Spong M., Vidyasagar M., 1989, “Robot dynamics and control”, John Wi-
ley and Sons.
The analysis of PID control for robots where the desired joint position qd
is a function of time, is treated in the following works:
•
Samson C., 1987, “Robust control of a class of non–linear systems and
application to robotics”, International Journal of Adaptive Control and
Signal Processing, Vol. 1, pp. 49–68.

218
9 PID Control
•
Kawamura S., Miyazaki F., Arimoto S., 1988, “Is a local linear PD feed-
back control law eﬀective for trajectory tracking of robot motion ?”, in
Proceedings of the 1988 IEEE International Conference on Robotics and
Automation, Philadelphia, PA., pp. 1335–1340, April.
•
Wen J. T., 1989, “PID control of robot manipulators”, Tech. Report, Rens-
selaer Polytechnic Institute, June.
•
Wen J. T., Murphy S., 1990, “PID control for robot manipulators”,
CIRSSE Document # 54, Rensselaer Polytechnic Institute, May.
•
Qu Z., Dorsey J., 1991, “Robust PID control of robots”, International Jour-
nal of Robotics and Automation, Vol. 6, No. 4, pp. 228–235.
•
Rocco P., 1996, “Stability of PID control for industrial robot arms”, IEEE
Transactions on Robotics and Automation, Vol. 12, No. 4, pp. 606–614.
•
Cervantes I., Alvarez–Ramirez J., 2001, “On the PID tracking control of
robot manipulators”, Systems and Control Letters, Vol. 42, pp. 37–46.
•
Choi Y., Chung W. K., 2004, “PID trajectory tracking control for mechan-
ical systems”, Lecture Notes in Control and Information Sciences, No. 298,
Springer-Verlag: London.
A proof of semi-global asymptotic stability, that is, when the domain of at-
traction may be enlarged at wish, by increasing the control gains, is presented
in
•
Ortega R., Lor´ıa A., Kelly R., 1995, “A semiglobally stable output feedback
PI2D regulator for robot manipulators”, IEEE Transactions on Automatic
Control, Vol. 40, No. 8, pp. 1432–1436.
•
Alvarez–Ramirez J., Cervantes I., Kelly R., 2000, “PID regulation of robot
manipulators: stability and performance”, Systems and Control Letters,
Vol. 41, pp. 73–83.
Studies on controllers with small modiﬁcations to the structure of the PID
control have been reported in Ortega, Lor´ıa, Kelly (1995) above and in
•
Kelly R., 1998, “Global positioning of robot manipulators via PD control
plus a class of nonlinear integral actions”, IEEE Transactions on Auto-
matic Control, Vol. 43, No. 7, pp. 934–938.
Problems
1. Consider the model of an ideal pendulum studied in Example 2.2 (see
page 30)
J ¨q + mgl sin(q) = τ .
Assume that the PID control

Problems
219
τ = kp˜q + kv ˙˜q + ki
 t
0
˜q(σ) dσ
is used to drive the position q to a desired constant position qd.
a) Obtain the closed-loop equation in terms of the state vector [w ˜q
˙q]T ,
where
w = α
 t
0
˜q(σ) dσ −αmgl
ki
sin(qd) + ˜q
with α > 0 .
b) Show, by means of a candidate Lyapunov function that if
•
ki > 0,
•
kp > mgl,
•
kv >
ki J
kp −mgl ,
then the origin of the closed-loop equation is globally asymptotically
stable.
c) Does this imply that limt→∞˜q(t) = 0 for all ˜q(0) ∈IR ?
2. Verify the expression of ˙V (˜q, ˙q, z) given in Equation (9.14).
3. Consider the PID control law with gravity compensation for the position
control problem (i.e. with constant desired position, qd) for n-DOF robots
and whose control law is
τ = Kp˜q + Kv ˙˜q + Kiξ + g(q)
˙ξ = ˜q .
a) Obtain the closed-loop equation in terms of the state vector

ξT
˜qT
˙qT T . Verify that the origin is an equilibrium of the closed-loop equa-
tion.
b) Explain why the following tuning policy guarantees local asymptotic
stability of the origin.
•
λMax{Ki} ≥λmin{Ki} > 0,
•
λMax{Kp} ≥λmin{Kp} > 0,
•
λMax{Kv} ≥λmin{Kv} > λMax{Ki}
λmin{Kp} · λMax
2{M}
λmin{M} .
Hint: The only diﬀerence with the tuning procedure established above is
the absence of kg in the expressions for Kp and Kv.
4. Consider the PID control law given by (9.1). Show that this is equivalent
to
τ = K′
p˜q −Kv ˙q + K′
i
 t
0

α˜q(σ) + ˙˜q(σ)

dσ

220
9 PID Control
where
K′
p = Kp −1
αKi
K′
i = 1
αKi
for all α ̸= 0 .
5. Consider the linear multivariable system described by the equation:
M ¨x + C ˙x + g = u
where x ∈IRn is part of the state and at the same time, the output of
the system, u ∈IRn is the input, M, C ∈IRn×n are symmetric positive
deﬁnite constant matrices and g ∈IRn is constant as well.
Consider the application of PID control to drive the state trajectories x(t)
to a constant vector xd ∈IRn, i.e.
u = Kp˜x −Kv ˙x + Kiξ
˙ξ = ˜x
where ˜x = xd −x.
a) Obtain the closed-loop equation expressed in terms of the state

ξT
˜xT
˙xT T
.
b) Verify that the point
⎡
⎢⎢⎣
ξ
˜x
˙x
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
K−1
i
g
0
0
⎤
⎥⎥⎦∈IR3n
of the closed-loop equation is the unique equilibrium.
c) Use the tuning procedure presented in this chapter to suggest a pol-
icy of tuning that guarantees asymptotic stability of the equilibrium
for the closed-loop equation. Can it be shown that the asymptotic
stability is actually global ?

Part III
Motion Control

Introduction to Part III
Consider the dynamic model of a robot manipulator with n degrees of freedom,
rigid links, no friction at the joints and with ideal actuators, (3.18), which we
repeat here for ease of reference:
M(q)¨q + C(q, ˙q) ˙q + g(q) = τ .
(III.1)
In terms of the state vector

qT
˙qT T these equations are rewritten as
d
dt
⎡
⎣
q
˙q
⎤
⎦=
⎡
⎣
˙q
M(q)−1 [τ(t) −C(q, ˙q) ˙q −g(q)]
⎤
⎦
where M(q) ∈IRn×n is the inertia matrix, C(q, ˙q) ˙q ∈IRn is the vector of
centrifugal and Coriolis forces, g(q) ∈IRn is the vector of gravitational torques
and τ ∈IRn is a vector of external forces and torques applied at the joints.
The vectors q, ˙q, ¨q ∈IRn denote the position, velocity and joint acceleration
respectively.
The problem of motion control, tracking control, for robot manipulators
may be formulated in the following terms. Consider the dynamic model of an
n-DOF robot (III.1). Given a set of vectorial bounded functions qd, ˙qd and ¨qd
referred to as desired joint positions, velocities and accelerations we wish to
ﬁnd a vectorial function τ such that the positions q, associated to the robot’s
joint coordinates follow qd accurately.
In more formal terms, the objective of motion control consists in ﬁnding τ
such that
lim
t→∞˜q(t) = 0
where ˜q ∈IRn stands for the joint position errors vector or is simply called
position error, and is deﬁned by
˜q(t) := qd(t) −q(t) .

224
Part III
Considering the previous deﬁnition, the vector ˙˜q(t) = ˙qd(t) −˙q(t) stands
for the velocity error. The control objective is achieved if the manipulator’s
joint variables follow asymptotically the trajectory of the desired motion.
The computation of the vector τ involves in general, a vectorial nonlinear
function of q, ˙q and ¨q. This function is called “control law” or simply, “con-
troller”. It is important to recall that robot manipulators are equipped with
sensors to measure position and velocity at each joint henceforth, the vectors
q and ˙q are measurable and may be used by the controllers. In some robots,
only measurement of joint position is available and joint velocities may be
estimated. In general, a motion control law may be expressed as
τ = τ (q, ˙q, ¨q, qd, ˙qd, ¨qd, M(q), C(q, ˙q), g(q)) .
However, for practical purposes it is desirable that the controller does not
depend on the joint acceleration ¨q since accelerometers are usually highly
sensitive to noise.
Figure III.1 presents the block-diagram of a robot in closed loop with a
motion controller.
ROBOT
CONTROLLER
τ
q
˙q
qd
˙qd
¨qd
Figure III.1. Motion control: closed-loop system
In this third part of the textbook we carry out the stability analysis of a
group of motion controllers for robot manipulators. As for the position control
problem, the methodology to analyze the stability may be summarized in the
following steps.
1. Derivation of the closed-loop dynamic equation. Such an equation is ob-
tained by replacing the control action control τ in the dynamic model of
the manipulator. In general, the closed-loop equation is a nonautonomous
nonlinear ordinary diﬀerential equation since qd = qd(t).
2. Representation of the closed-loop equation in the state-space form,
d
dt

qd −q
˙qd −˙q

= f(q, ˙q, qd, ˙qd, ¨qd, M(q), C(q, ˙q), g(q)) .

Introduction to Part III
225
This closed-loop equation may be regarded as a dynamic system whose
inputs are qd, ˙qd and ¨qd, and whose outputs are the state vectors ˜q =
qd−q and ˙˜q = ˙qd−˙q. Figure III.2 shows the corresponding block-diagram.
CONTROLLER
ROBOT
+
¨qd
˙qd
qd
˜q
˙˜q
Figure III.2. Motion control closed-loop system in its input–output representation
3. Study of the existence and possible unicity of the equilibrium for the
closed-loop equation
d
dt
 ˜q
˙˜q

= ˜f(t, ˜q, ˙˜q)
(III.2)
where ˜f is obtained by replacing q with qd(t) −˜q and ˙q with ˙qd(t) −˙˜q.
Whence the dependence of ˜f on t. That is, the closed-loop system equation
is nonautonomous.
Thus, for Equation (III.2) we want to verify that the origin, [˜qT , ˙˜q
T ]T = 0
∈IR2n is an equilibrium and whether it is unique.
4. Proposal of a Lyapunov function candidate to study the stability of any
equilibrium of interest for the closed-loop equation, by using the Theorems
2.2, 2.3 and 2.4. In particular, veriﬁcation of the required properties, i.e.
positivity and, negativity of the time derivative. Notice that in this case,
we cannot use La Salle’s theorem (cf. Theorem 2.7) since the closed-loop
system is described, in general, by a nonautonomous diﬀerential equation.
5. Alternatively to step 4, in the case that the proposed Lyapunov func-
tion candidate appears to be inappropriate (that is, if it does not satisfy
all of the required conditions) to establish the stability properties of the
equilibrium under study, we may use Lemma 2.2 by proposing a positive
deﬁnite function whose characteristics allow one to determine the quali-
tative behavior of the solutions of the closed-loop equation. In particular,
the convergence of part of the state.
The rest of this third part is divided in three chapters. The controllers
that we consider are, in order,
•
Computed torque control and computed torque+ control.
•
PD control with compensation and PD+ control.

226
Part III
•
Feedforward control and PD plus feedforward control.
For references regarding the problem of motion control of robot manipu-
lators see the Introduction of Part II on page 139.

10
Computed-torque Control and
Computed-torque+ Control
In this chapter we study the motion controllers:
•
Computed-torque control and
•
Computed-torque+ control.
Computed-torque control allows one to obtain a linear closed-loop equation
in terms of the state variables. This fact has no precedent in the study of the
controllers studied in this text so far. On the other hand, computed-torque+
control is characterized for being a dynamic controller, that is, its complete
control law includes additional state variables. Finally, it is worth anticipating
that both of these controllers satisfy the motion control objective with a trivial
choice of their design parameters.
The contents of this chapter have been taken from the references cited at
the end. The reader interested in going deeper into the material presented
here is invited to consult these and the references therein.
10.1 Computed-torque Control
The dynamic model (III.1) that characterizes the behavior of robot manipula-
tors is in general, composed of nonlinear functions of the state variables (joint
positions and velocities). This feature of the dynamic model might lead us
to believe that given any controller, the diﬀerential equation that models the
control system in closed loop should also be composed of nonlinear functions
of the corresponding state variables. This intuition is conﬁrmed for the case
of all the control laws studied in previous chapters. Nevertheless, there exists
a controller which is also nonlinear in the state variables but which leads to a
closed-loop control system which is described by a linear diﬀerential equation.
This controller is capable of fulﬁlling the motion control objective, globally

228
10 Computed-torque Control and Computed-torque+ Control
and moreover with a trivial selection of its design parameters. It receives the
name computed-torque control.
The computed-torque control law is given by
τ = M(q)

¨qd + Kv ˙˜q + Kp˜q

+ C(q, ˙q) ˙q + g(q) ,
(10.1)
where Kv and Kp are symmetric positive deﬁnite design matrices and ˜q =
qd −q denotes as usual, the position error.
Notice that the control law (10.1) contains the terms Kp˜q + Kv ˙˜q which
are of the PD type. However, these terms are actually premultiplied by the
inertia matrix M(qd −˜q). Therefore this is not a linear controller as the
PD, since the position and velocity gains are not constant but they depend
explicitly on the position error ˜q. This may be clearly seen when expressing
the computed-torque control law given by (10.1) as
τ = M(qd −˜q)Kp˜q + M(qd −˜q)Kv ˙˜q + M(q) ¨qd + C(q, ˙q) ˙q + g(q) .
Computed-torque control was one of the ﬁrst model-based motion control
approaches created for manipulators, that is, in which one makes explicit
use of the knowledge of the matrices M(q), C(q, ˙q) and of the vector g(q).
Furthermore, observe that the desired trajectory of motion qd(t), and its
derivatives ˙qd(t) and ¨qd(t), as well as the position and velocity measurements
q(t) and ˙q(t), are used to compute the control action (10.1).
The block-diagram that corresponds to computed-torque control of robot
manipulators is presented in Figure 10.1.
q
˙q
Σ
Σ
Σ
Σ
M(q)
C(q, ˙q)
ROBOT
g(q)
τ
Kv
Kp
¨qd
˙qd
qd
Figure 10.1. Block-diagram: computed-torque control
The closed-loop equation is obtained by substituting the control action τ
from (10.1) in the equation of the robot model (III.1) to obtain
M(q)¨q = M(q)

¨qd + Kv ˙˜q + Kp˜q

.
(10.2)

10.1 Computed-torque Control
229
Since M(q) is a positive deﬁnite matrix (Property 4.1) and therefore it is also
invertible, Equation (10.2) reduces to
¨˜q + Kv ˙˜q + Kp˜q = 0
which in turn, may be expressed in terms of the state vector

˜qT
˙˜q
T T
as
d
dt
⎡
⎣
˜q
˙˜q
⎤
⎦=
⎡
⎣
˙˜q
−Kp˜q −Kv ˙˜q
⎤
⎦
=
⎡
⎣
0
I
−Kp
−Kv
⎤
⎦
⎡
⎣
˜q
˙˜q
⎤
⎦,
(10.3)
where I is the identity matrix of dimension n.
It is important to remark that the closed-loop Equation (10.3) is repre-
sented by a linear autonomous diﬀerential equation, whose unique equilibrium
point is given by

˜qT
˙˜q
T T
= 0 ∈IR2n. The unicity of the equilibrium fol-
lows from the fact that the matrix Kp is designed to be positive deﬁnite and
therefore nonsingular.
Since the closed-loop Equation (10.3) is linear and autonomous, its so-
lutions may be obtained in closed form and be used to conclude about the
stability of the origin. Nevertheless, for pedagogical purposes we proceed to
analyze the stability of the origin as an equilibrium point of the closed-loop
equation. We do this using Lyapunov’s direct method.
To that end, we start by introducing the constant ε satisfying
λmin{Kv} > ε > 0 .
Multiplying by xT x where x ∈IRn is any nonzero vector, we obtain
λmin{Kv}xT x > εxT x. Since Kv is by design, a symmetric matrix then
xT Kvx ≥λmin{Kv}xT x and therefore,
xT [Kv −εI] x > 0
∀x ̸= 0 ∈IRn .
This means that the matrix Kv −εI is positive deﬁnite, i.e.
Kv −εI > 0 .
(10.4)
Considering all this, the positivity of the matrix Kp and that of the con-
stant ε we conclude that
Kp + εKv −ε2I > 0 .
(10.5)

230
10 Computed-torque Control and Computed-torque+ Control
Consider next the Lyapunov function candidate
V (˜q, ˙˜q) = 1
2
⎡
⎣
˜q
˙˜q
⎤
⎦
T ⎡
⎣
Kp + εKv
εI
εI
I
⎤
⎦
⎡
⎣
˜q
˙˜q
⎤
⎦
= 1
2

˙˜q + ε˜q
T
˙˜q + ε˜q

+ 1
2 ˜qT
Kp + εKv −ε2I
 ˜q
(10.6)
where the constant ε satisﬁes (10.4) and of course, also (10.5). From this, it
follows that the function (10.6) is globally positive deﬁnite. This may be more
clear if we rewrite the Lyapunov function candidate V (˜q, ˙˜q) in (10.6) as
V (˜q, ˙˜q) = 1
2
˙˜q
T˙˜q + 1
2 ˜qT[Kp + εKv] ˜q + ε˜qT ˙˜q .
Evaluating the total time derivative of V (˜q, ˙˜q) we get
˙V (˜q, ˙˜q) = ¨˜q
T ˙˜q + ˜qT [Kp + εKv] ˙˜q + ε ˙˜q
T˙˜q + ε˜qT ¨˜q .
Substituting ¨˜q from the closed-loop Equation (10.3) in the previous ex-
pression and making some simpliﬁcations we obtain
˙V (˜q, ˙˜q) = −˙˜q
T[Kv −εI] ˙˜q −ε˜qTKp˜q
= −
⎡
⎣
˜q
˙˜q
⎤
⎦
T⎡
⎣
εKp
0
0
Kv −εI
⎤
⎦
⎡
⎣
˜q
˙˜q
⎤
⎦.
(10.7)
Now, since ε is chosen so that Kv −εI > 0, and since Kp is by design
positive deﬁnite, the function ˙V (˜q, ˙˜q) in (10.7) is globally negative deﬁnite.
In view of Theorem 2.4, we conclude that the origin

˜qT
˙˜q
T T
= 0 ∈IR2n
of the closed-loop equation is globally uniformly asymptotically stable and
therefore
lim
t→∞
˙˜q(t) = 0
lim
t→∞˜q(t) = 0
from which it follows that the motion control objective is achieved. As a matter
of fact, since Equation (10.3) is linear and autonomous this is equivalent to
global exponential stability of the origin.
For practical purposes, the design matrices Kp and Kv may be chosen diag-
onal. This means that the closed-loop Equation (10.3) represents a decoupled
multivariable linear system that is, the dynamic behavior of the errors of each
joint position is governed by second-order linear diﬀerential equations which
are independent of each other. In this scenario the selection of the matrices
Kp and Kv may be made speciﬁcally as

10.1 Computed-torque Control
231
Kp = diag
)
ω2
1, · · · , ω2
n
*
Kv = diag {2ω1, · · · , 2ωn} .
With this choice, each joint responds as a critically damped linear system
with bandwidth ωi. The bandwidth ωi deﬁnes the velocity of the joint in
question and consequently, the decay exponential rate of the errors ˜q(t) and
˙˜q(t). Therefore, in view of these expressions we may not only guarantee the
control objective but we may also govern the performance of the closed-loop
control system.
Example 10.1. Consider the equation of a pendulum of length l and
mass m concentrated at its tip, subject to the action of gravity g and
to which is applied a torque τ at the axis of rotation that is,
ml2¨q + mgl sin(q) = τ,
where q is the angular position with respect to the vertical. For this
example we have M(q) = ml2, C(q, ˙q) = 0 and g(q) = mgl sin(q). The
computed-torque control law (10.1), is given by
τ = ml2 
¨qd + kv ˙˜q + kp˜q

+ mgl sin(q),
with kv > 0, kp > 0. With this control strategy it is guaranteed that
the motion control objective is achieved globally.
♦
Next, we present the experimental results obtained for the Pelican proto-
type presented in Chapter 5 under computed-torque control.
Example 10.2. Consider the Pelican prototype robot studied in Chap-
ter 5, and shown in Figure 5.2. Consider the computed-torque control
law (10.1) on this robot for motion control.
The desired reference trajectory, qd(t), is given by Equation (5.7).
The desired velocities and accelerations ˙qd(t) and ¨qd(t), were ana-
lytically found, and they correspond to Equations (5.8) and (5.9),
respectively.
The symmetric positive deﬁnite matrices Kp and Kv are chosen as
Kp = diag{ω2
1, ω2
2} = diag{1500, 14000}
[1/s]
Kv = diag{2ω1, 2ω2} = diag{77.46, 236.64}

1/s2
,
where we used ω1 = 38.7
[rad/s] and ω2 = 118.3
[rad/s].

232
10 Computed-torque Control and Computed-torque+ Control
0
2
4
6
8
10
−0.02
−0.01
0.00
0.01
0.02
[rad]
˜q1
˜q2
t [s]
.................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 10.2. Graph of position errors against time
The initial conditions which correspond to the positions and ve-
locities, are chosen as
q1(0) = 0,
q2(0) = 0
˙q1(0) = 0,
˙q2(0) = 0 .
Figure 10.2 shows the experimental position errors. The steady-
state position errors are not zero due to the friction eﬀects of the
actual robot which nevertheless, are neglected in the analysis.
♦
10.2 Computed-torque+ Control
Most of the controllers analyzed so far in this textbook, both for position as
well as for motion control, have the common structural feature that they use
static state feedback (of joint positions and velocities). The exception to this
rule are the PID control and the controllers that do not require measurement
of velocities, studied in Chapter 13.
In this section1 we study a motion controller which uses dynamic state
feedback. As we show next, this controller basically consists in one part that
1 The material of this section may appear advanced to some readers; in particular,
for a senior course on robot control since it makes use of results involving con-
cepts such as ‘functional spaces’, material exposed in Appendix A and reserved
for the advanced student. Therefore, the material may be skipped if convenient
without aﬀecting the continuity of the exposition of motion controllers. The ma-
terial is adapted from the corresponding references cited as usual, at the end of
the chapter.

10.2 Computed-torque+ Control
233
is exactly equal to the computed-torque control law given by the expression
(10.1), and a second part that includes dynamic terms. Due to this character-
istic, this controller was originally called computed-torque control with com-
pensation, however, in the sequel we refer to it simply as computed-torque+.
The reason to include the computed-torque+ control as subject of study
in this text is twofold. First, the motion controllers analyzed previously use
static state feedback; hence, it is interesting to study a motion controller whose
structure uses dynamic state feedback. Secondly, computed-torque+ control
may be easily generalized to consider an adaptive version of it, which allows
one to deal with uncertainties in the model (cf. Part IV).
The equation corresponding to the computed-torque+ controller is given
by
τ = M(q)

¨qd + Kv ˙˜q + Kp˜q

+ C(q, ˙q) ˙q + g(q) −C(q, ˙q)ν
(10.8)
where Kv and Kp are symmetric positive deﬁnite design matrices, the vector
˜q = qd −q denotes as usual, the position error and the vector ν ∈IRn is
obtained by ﬁltering the errors of position ˜q and velocity ˙˜q, that is,
ν = −
bp
p + λ
˙˜q −
b
p + λ

Kv ˙˜q + Kp˜q

,
(10.9)
where p is the diﬀerential operator (i.e. p :=
d
dt) and λ, b are positive design
constants. For simplicity, and with no loss of generality, we take b = 1.
Notice that the diﬀerence between the computed-torque and computed-
torque+ control laws given by (10.1) and (10.8) respectively, resides exclu-
sively in that the latter contains the additional term C(q, ˙q)ν.
The implementation of computed-torque+ control expressed by (10.8) and
(10.9) requires knowledge of the matrices M(q), C(q, ˙q) and of the vector
g(q) as well as of the desired motion trajectory qd(t), ˙qd(t) and ¨qd(t) and
measurement of the positions q(t) and of the velocities ˙q(t). It is assumed
that C(q, ˙q) in the control law (10.8) was obtained by using the Christoﬀel
symbols (cf. Equation 3.21). The block-diagram corresponding to computed-
torque+ control is presented in Figure 10.3.
Due to the presence of the vector ν in (10.8) the computed-torque+ control
law is dynamic, that is, the control action τ depends not only on the actual
values of the state vector formed by q and ˙q, but also on its past values. This
fact has as a consequence that we need additional state variables to completely
characterize the control law. Indeed, the expression (10.9) in the state space
form is a linear autonomous system given by
d
dt
⎡
⎣
ξ1
ξ2
⎤
⎦=
⎡
⎣
−λI
0
0
−λI
⎤
⎦
⎡
⎣
ξ1
ξ2
⎤
⎦+
⎡
⎣
Kp
Kv
0
−λI
⎤
⎦
⎡
⎣
˜q
˙˜q
⎤
⎦
(10.10)

234
10 Computed-torque Control and Computed-torque+ Control
¨qd
M(q)
Σ
Σ
Σ
τ
C(q, ˙q)
q
˙q
ROBOT
Σ
Σ
Σ
˙qd
qd
Kp
Kv
1
p + λ
p
p + λ
g(q)
Figure 10.3. Computed-torque+ control
ν = [ −I
−I ]
⎡
⎣
ξ1
ξ2
⎤
⎦−[ 0
I ]
⎡
⎣
˜q
˙˜q
⎤
⎦
(10.11)
where ξ1, ξ2 ∈IRn are the new state variables.
To derive the closed-loop equation we combine ﬁrst the dynamic equation
of the robot (III.1) with that of the controller (10.8) to obtain the expression
M(q)

¨˜q + Kv ˙˜q + Kp˜q

−C(q, ˙q)ν = 0 .
(10.12)
In terms of the state vector

˜qT
˙˜q
T
ξT
1
ξT
2
T
, the equations (10.12),
(10.10) and (10.11) allow one to obtain the closed-loop equation
d
dt
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
˜q
˙˜q
ξ1
ξ2
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
˙˜q
−M(q)−1C(q, ˙q)

ξ1 + ξ2 + ˙˜q

−Kv ˙˜q −Kp˜q
−λξ1 + Kp˜q + Kv ˙˜q
−λξ2 −λ ˙˜q
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
,
(10.13)
of which the origin

˜qT
˙˜q
T
ξT
1
ξT
2
T
= 0 ∈IR4n is an equilibrium point.

10.2 Computed-torque+ Control
235
The study of global asymptotic stability of the origin of the closed-loop
Equation (10.13) is actually an open problem in the robot control academic
community. Nevertheless we can show that the functions ˜q(t), ˙˜q(t) and ν(t) are
bounded and, using Lemma 2.2, that the motion control objective is veriﬁed.
To analyze the control system we ﬁrst proceed to write it in a diﬀerent
but equivalent form. For this, notice that the expression for ν given in (10.9)
allows one to derive
˙ν + λν = −

¨˜q + Kv ˙˜q + Kp˜q

.
(10.14)
Incorporating (10.14) in (10.12) we get
M(q) [ ˙ν + λν] + C(q, ˙q)ν = 0 .
(10.15)
The previous equation is the starting point in the analysis that we present
next. Consider now the following non-negative function
V (t, ν, ˜q) = 1
2νTM(qd −˜q)ν ≥0 ,
which, even though it does not satisfy the conditions to be a Lyapunov func-
tion candidate for the closed-loop Equation (10.13), it is useful in the proofs
that we present below. Speciﬁcally, V (ν, ˜q) may not be a Lyapunov function
candidate for the closed-loop Equation (10.13) since it is not a positive deﬁ-
nite function of the whole state, that is, considering all the state variables ˜q,
˙˜q, ξ1 and ξ2. Notice that it does not even depend on all the state variables.
The derivative with respect to time of V (ν, ˜q) is given by
˙V (ν, ˜q) = νTM(q) ˙ν + 1
2νT ˙M(q)ν .
Solving for M(q) ˙ν in Equation (10.15) and substituting in the previous
equation we obtain
˙V (ν, ˜q) = −νTλM(q)ν ≤0
(10.16)
where the term νT
1
2 ˙M −C

ν was canceled by virtue of Property 4.2. Now,
considering V (ν, ˜q) and (10.16) we see that
˙V (ν, ˜q) = −2λV (ν, ˜q) ,
which in turn implies that
V (ν(t), ˜q(t)) = V (ν(0), ˜q(0))e−2λt .
Invoking Property 4.1 that there exists a constant α > 0 such that M(q) ≥αI,
we obtain

236
10 Computed-torque Control and Computed-torque+ Control
α ν(t)Tν(t) ≤ν(t)TM(q(t))ν(t) = 2V (ν(t), ˜q(t))
from which we ﬁnally get
ν(t)Tν(t)
"
#$
%
∥ν(t)∥2
≤2V (ν(0), ˜q(0))
α
e−2λt .
(10.17)
This means that that ν(t) →0 exponentially.
On the other hand, the Equation (10.14) may also be written as
(p + λ)ν = −

p2I + pKv + Kp
 ˜q
or in equivalent form as
˜q = −(p + λ)

p2I + pKv + Kp
−1 ν .
(10.18)
Since λ > 0, while Kv and Kp are positive deﬁnite symmetric matrices,
Equation (10.14) written in the form above deﬁnes a linear dynamic system
which is exponentially stable and strictly proper (i.e. where the degree of
the denominator is strictly larger than that of the numerator). The input to
this system is ν which tends to zero exponentially fast, and its output ˜q. So
we invoke the fact that a stable strictly proper ﬁlter with an exponentially
decaying input produces an exponentially decaying output2, that is,
lim
t→∞˜q(t) = 0 ,
which means that the motion control objective is veriﬁed.
It is interesting to remark that the equation of the computed-torque+
controller (10.8), reduces to the computed-torque controller given by (10.1) in
the particular case of manipulators that do not have the centrifugal and forces
matrix C(q, ˙q). Such is the case for example, of Cartesian manipulators.
Next, we present the experimentation results obtained for the computed-
torque+ control on the Pelican robot.
Example 10.3. Consider the 2-DOF prototype robot studied in Chapter
5, and shown in Figure 5.2.
Consider the computed-torque+ control law given by (10.8), (10.10)
and (10.11) applied to this robot.
The desired trajectories are those used in the previous examples,
that is, the robot must track the position, velocity and acceleration
trajectories qd(t), ˙qd(t) and ¨qd(t) given by Equations (5.7)–(5.9).
2 The technical details of why the latter is true rely on the use of Corollary A.2
which is reserved to the advanced reader.

10.3 Conclusions
237
0
2
4
6
8
10
−0.02
−0.01
0.00
0.01
0.02
[rad]
˜q1
˜q2
t [s]
...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 10.4. Graph of position errors against time
The symmetric positive deﬁnite matrices Kp and Kv, and the con-
stant λ are taken as
Kp = diag{ω2
1, ω2
2} = diag{1500, 14000}
[1/s]
Kv = diag{2ω1, 2ω2} = diag{77.46, 236.64}

1/s2
λ = 60 .
The initial conditions of the controller state variables are ﬁxed at
ξ1(0) = 0,
ξ2(0) = 0 .
The initial conditions corresponding to the actual positions and
velocities are set to
q1(0) = 0,
q2(0) = 0
˙q1(0) = 0,
˙q2(0) = 0 .
Figure 10.4 shows the experimental tracking position errors. It is
interesting to remark that the plots presented in Figure 10.2 obtained
with the computed-torque control law, present a considerable similar-
ity to those of Figure 10.4.
♦
10.3 Conclusions
The conclusions drawn from the analysis presented in this chapter may be
summarized as follows.

238
10 Computed-torque Control and Computed-torque+ Control
•
For any choice of the symmetric positive deﬁnite matrices Kp and Kv, the
origin of the closed-loop equation by computed-torque control expressed in
terms of the state vector

˜qT
˙˜q
T T
, is globally uniformly asymptotically
stable. Therefore, computed-torque control satisﬁes the motion control ob-
jective, globally. Consequently, for any initial position error ˜q(0) ∈IRn
velocity error ˙˜q(0) ∈IRn, we have limt→∞˜q(t) = 0.
•
For any selection of the symmetric positive deﬁnite matrices Kp and Kv,
and any positive constant λ, computed-torque+ control satisﬁes the mo-
tion control objective, globally. Consequently, for any initial position error
˜q(0) ∈IRn and velocity error ˙˜q(0) ∈IRn, and for any initial condition of
the controller ξ1(0) ∈IRn, ξ2(0) ∈IRn, we have limt→∞˜q(t) = 0.
Bibliography
Computed-torque control is analyzed in the following texts.
•
Fu K., Gonzalez R., Lee C., 1987, “Robotics: Control, sensing, vision and
intelligence”, McGraw–Hill.
•
Craig J., 1989, “Introduction to robotics: Mechanics and control”, Addison–
Wesley.
•
Spong M., Vidyasagar M., 1989, “Robot dynamics and control”, John Wi-
ley and Sons.
•
Yoshikawa T., 1990, “Foundations of robotics: Analysis and control”, The
MIT Press.
The stability analysis for the computed-torque controller as presented in
Section 10.1 follows the guidelines of
•
Wen J. T., Bayard D., 1988, “New class of control law for robotic manipu-
lators. Part 1: Non-adaptive case”, International Journal of Control, Vol.
47, No. 5, pp. 1361–1385.
The computed-torque+ control law as presented here is an adaptation
from its original adaptive form, proposed in
•
Kelly R., Carelli R., 1988. “Uniﬁed approach to adaptive control of robotic
manipulators”, Proceedings of the 27th IEEE Conference on Decision and
Control, Austin, TX., December, Vol. 1, pp. 1598–1603.
•
Kelly R., Carelli R., Ortega R., 1989. “Adaptive motion control design of
robot manipulators: An input-output approach”, International Journal of
Control, Vol. 50, No. 6, September, pp. 2563–2581.

Problems
239
•
Kelly R., 1990, “Adaptive computed torque plus compensation control for
robot manipulators ”, Mechanism and Machine Theory, Vol. 25, No. 2, pp.
161–165.
Problems
1. Consider the Cartesian robot 2-DOF shown in Figure 10.5.
x0
y0
z0
q1
q2
x0
y0
z0
q1
q2
m1
m2
Figure 10.5. Problem 1. Cartesian 2-DOF robot.
a) Obtain the dynamic model and speciﬁcally determine explicitly M(q),
C(q, ˙q) and g(q).
b) Write the computed-torque control law and give explicitly τ1 and τ2.
2. Consider the model of an ideal pendulum with mass m concentrated at
the tip, at length l from its axis of rotation, under the control action of a
torque τ and a constant external additional torque τe,
ml2¨q + mgl sin(q) = τ −τe .
To control the motion of this device we use a computed-torque controller
that is,
τ = ml2 
¨qd + kv ˙˜q + kp˜q

+ mgl sin(q),
where kp > 0 and kv > 0. Show that
lim
t→∞˜q(t) =
τe
kpml2 .
Hint: Obtain the closed-loop equation in terms of the state vector

240
10 Computed-torque Control and Computed-torque+ Control
⎡
⎣
˜q −
τe
kpml2
˙˜q
⎤
⎦
T
and show that the origin is globally asymptotically stable.
3. Consider the model of an ideal pendulum as described in the previous
problem to which is applied a control torque τ, and an external torque τe
from torsional spring of constant ke > 0 (τe = keq),
ml2¨q + mgl sin(q) = τ −keq .
To control the motion of such a device we use the computed-torque con-
troller
τ = ml2 
¨qd + kv ˙˜q + kp˜q

+ mgl sin(q)
where kp > 0 and kv > 0. Assume that qd is constant. Show that
lim
t→∞˜q(t) =
ke
kpml2 + ke
qd .
Hint: Obtain the closed-loop equation in terms of the state vector
⎡
⎢⎣
˜q −
ke
kpml2 + ke
qd
˙q
⎤
⎥⎦
and show that the origin is a globally asymptotically stable equilibrium.
4. Consider the model of an ideal pendulum described in Problem 2 under
the control action of a torque τ, i.e.
ml2¨q + mgl sin(q) = τ .
Assume that the values of the parameters l and g are exactly known, but
for the mass m only an approximate value m0 is known. To control the
motion of this device we use computed-torque control where m has been
substituted by m0 since the value of m is assumed unknown, that is,
τ = m0l2 
¨qd + kv ˙˜q + kp˜q

+ m0gl sin(q),
where kp > 0 and kv > 0.
a) Obtain the closed-loop equation in terms of the state vector

˜q
˙˜q
T .
b) Verify that independently of the value of m and m0 (but with m ̸= 0),
the origin

˜q
˙˜q
T = 0 ∈IR2 is an equilibrium of the closed-loop
equation if the desired position qd(t) satisﬁes
¨qd(t) + g
l sin(qd(t)) = 0
∀t ≥0 .

Problems
241
5. Consider the closed-loop equation obtained with the computed-torque+
controller given by Equation (10.13) and whose origin

˜qT
˙˜q
T
ξT
1
ξT
2
T
= 0 is an equilibrium. Regarding the variable ν we shown in (10.17) that
ν(t)Tν(t)
"
#$
%
∥ν(t)∥2
≤2V (ν(0), ˜q(0))
α
e−2λt .
On the other hand we have from (10.10) and (10.18)
ξ1 =
1
p + λ

Kp˜q + Kv ˙˜q

ξ2 = −
λ
p + λ
˙˜q
˜q = −(p + λ)

p2I + pKv + Kp
−1 ν
where Kp and Kv are symmetric positive deﬁnite matrices. Assume that
the robot has only revolute joints.
a) May we also conclude that ˜q(t), ˙˜q(t), ξ1(t) and ξ2(t) tend exponen-
tially to zero ?
b) Would the latter imply that the origin is globally exponentially stable?
6. In this chapter it was shown that the origin of the robot system in closed
loop with the computed-torque controller is globally uniformly asymptot-
ically stable. Since the closed-loop system is linear autonomous, it was
observed that this is equivalent to global exponential stability. Verify this
claim using Theorem 2.5.

11
PD+ Control and PD Control with
Compensation
As we have seen in Chapter 10 the motion control objective for robot ma-
nipulators may be achieved globally by means of computed-torque control.
Computed-torque control belongs to the so-called class of feedback linearizing
controllers. Roughly, the technique of feedback linearization in its simplest
form consists in applying a control law such that the closed-loop equations
are linear. Historically, the motivation to develop feedback-linearization based
controllers is that the stability theory of linear systems is far more developed
than that of nonlinear systems. In particular, the tuning of the gains of such
controllers is trivial since the resulting system is described by linear diﬀeren-
tial equation.
While computed-torque control was one of the ﬁrst model-based controllers
for robot manipulators, and rapidly gained popularity it has the disadvantages
of other feedback-linearizing controllers: ﬁrst, it requires a considerable com-
puting load since the torque has to be computed on-line so that the closed-loop
system equations become linear and autonomous, and second, it relies on a
very accurate knowledge of the system. This second feature may be of signif-
icant importance since the computed-torque control law contains the vector,
of centrifugal and Coriolis forces vector, C(q, ˙q) ˙q, which contains quadratic
terms of the components of the joint velocities. The consequence of this is that
high order nonlinearities appear in the control law and therefore, in the case of
model uncertainty, the control law introduces undesirable high order nonlin-
earities in the equations of the closed-loop system. Moreover, even in the case
that the model is accurately known, the control law increases proportionally
to the square of certain components of the vector of joint velocities hence,
these demanded large control actions may drive the actuators into saturation.
In this chapter we present two controllers whose control laws are based on
the dynamic equations of the system but which also involve certain nonlinear-
ities that are evaluated along the desired trajectories, i.e. the desired motion.
These control systems are presented in increasing order of complexity with
respect to their stability analyses. They are:

244
11 PD+ Control and PD Control with Compensation
•
PD control with compensation and
•
PD+ control.
These controllers have been thoroughly studied in the literature and, as
for the other chapters, the corresponding references are given at the end. For
clarity of exposition each of these controllers is treated in separate sections.
11.1 PD Control with Compensation
In 1987 an adaptive controller to solve the motion control problem of robot
manipulators was reported in the literature. This controller, which over the
years has become increasingly popular within the academic environment, is
often referred to by the names of its creators: ‘Slotine and Li controller’. The
related references are presented at the end of the chapter. While this controller
is the subject of inquiry in Chapter 16 its ‘non-adaptive’ version is studied
in this ﬁrst section of the present chapter in its non-adaptive version. From a
purely structural viewpoint, the control law of this controller is formed by a
‘PD’ term plus a ‘compensation’ term hence, one could also call it “PD plus
compensation control”.
The material of this section has been taken from the references cited at
the end of the text. The PD control law with compensation may be written
as
τ = Kp˜q + Kv ˙˜q + M(q)

¨qd + Λ ˙˜q

+ C(q, ˙q) [ ˙qd + Λ˜q] + g(q),
(11.1)
where Kp, Kv ∈IRn×n are symmetric positive deﬁnite design matrices, ˜q =
qd −q denotes the position error and Λ is deﬁned as
Λ = Kv
−1Kp .
Notice that Λ is the product of two symmetric positive deﬁnite matrices.
Even though in general this matrix may or may not be symmetric or positive
deﬁnite, it is always nonsingular. This characteristic of Λ will be of utility
later on. It is assumed that the centrifugal and Coriolis matrix C(q, ˙q) is
built using the Christoﬀel symbols (cf. Equation 3.21).
Observe that the ﬁrst two terms on the right-hand side of the control
law (11.1) correspond to the PD control law. PD control with compensation
is model-based, that is, the control law explicitly uses the terms from the
model of the robot (III.1), M(q), C(q, ˙q) and g(q). Figure 11.1 presents the
block-diagram that corresponds to the PD control law with compensation.
The closed-loop equation is obtained by substituting the control action
τ from the control law (11.1) in the equation of the robot model (III.1), to
obtain

11.1 PD controller with compensation
245
q
˙q
Σ
Σ
Σ
Σ
Σ
Σ
C(q, ˙q)
Kp
Kv
Λ
Λ
¨qd
˙qd
qd
τ
ROBOT
g(q)
M(q)
Figure 11.1. Block-diagram: PD control with compensation
M(q)

¨˜q + Λ ˙˜q

+ C(q, ˙q)

˙˜q + Λ˜q

= −Kp˜q −Kv ˙˜q,
which may be expressed in terms of the state vector

˜qT
˙˜q
T T
as
d
dt
⎡
⎣
˜q
˙˜q
⎤
⎦=
⎡
⎣
˙˜q
M(q)−1 
−Kp˜q −Kv ˙˜q −C(q, ˙q)

˙˜q + Λ˜q

−Λ ˙˜q
⎤
⎦,
(11.2)
that is, this diﬀerential equation is nonautonomous and has the origin

˜qT
˙˜q
T T
=
0 ∈IR2n as an equilibrium point.
The stability analysis of the origin of the closed-loop equation may be
carried out by considering the Lyapunov function candidate
V (t, ˜q, ˙˜q) = 1
2
⎡
⎣
˜q
˙˜q
⎤
⎦
T⎡
⎣
2Kp + ΛTM(qd −˜q)Λ
ΛTM(qd −˜q)
M(qd −˜q)Λ
M(qd −˜q)
⎤
⎦
⎡
⎣
˜q
˙˜q
⎤
⎦.
At ﬁrst sight it may not appear evident that this Lyapunov function candidate
is positive deﬁnite but it may help that we rewrite it in the following form:
V (t, ˜q, ˙˜q) = 1
2

˙˜q + Λ˜q
T
M(q)

˙˜q + Λ˜q

+ ˜qTKp˜q
(11.3)
which is equivalent to
V (t, ˜q, ˙˜q) = 1
2
 ˙˜q
˜q
T 
I ΛT
0 I
 
2Kp
0
0
M(q)
 
I 0
Λ I

"
#$
%
BT AB
 ˙˜q
˜q

.
(11.4)

246
11 PD+ Control and PD Control with Compensation
And we see from Lemma 2.1 (cf. page 24) that the matrix product BT AB,
above, is positive deﬁnite since Kp and M(q) are positive deﬁnite1.
Also, it is apparent from (11.4) that V (t, ˜q, ˙˜q) satisﬁes
V (t, ˜q, ˙˜q) ≥1
2λmin{BT AB}

∥˙˜q∥2 + ∥˜q∥2
so it is also radially unbounded. Correspondingly, since the inertia matrix is
bounded uniformly in q, from (11.3), we have
V (t, ˜q, ˙˜q) ≤1
2λMax{M}
 ˙˜q + Λ˜q

2
+ λMax{Kp} ∥˜q∥2
hence, V (t, ˜q, ˙˜q) is also decrescent.
It is interesting to mention that the function (11.3) may be regarded as
an extension of the Lyapunov function (11.9) used in the study of the PD+
control. Indeed, both functions are the same if, as well as in the control laws,
Λ is set to zero.
The time derivative of the Lyapunov function candidate (11.3) is
˙V (˜q, ˙˜q) =

˙˜q + Λ˜q
T
M(q)

¨˜q + Λ ˙˜q

+ 1
2

˙˜q + Λ˜q
T ˙M(q)

˙˜q + Λ˜q

+ 2˜qTKp ˙˜q .
(11.5)
Solving for M(q)¨˜q in the closed-loop Equation (11.2) and substituting in
the previous equation, we obtain
˙V (t, ˜q, ˙˜q) = −

˙˜q + Λ˜q
T
Kv

˙˜q + Λ˜q

+ 2˜qT Kp ˙˜q,
where we canceled the term

˙˜q + Λ˜q
T 1
2
˙M(q) −C(q, ˙q)
 
˙˜q + Λ˜q

by virtue of Property 4.2. Now, using Kp = KvΛ, the equation of ˙V (t, ˜q, ˙˜q)
reduces ﬁnally to
˙V (t, ˜q, ˙˜q) = −˙˜q
TKv ˙˜q −˜qTΛTKvΛ˜q
= −
⎡
⎣
˜q
˙˜q
⎤
⎦
T ⎡
⎣
ΛT KvΛ
0
0
Kv
⎤
⎦
⎡
⎣
˜q
˙˜q
⎤
⎦.
(11.6)
Recalling again Lemma 2.1, since Kv is symmetric positive deﬁnite and Λ
is nonsingular, we conclude that ΛTKvΛ is positive deﬁnite. Consequently,
1 See Remark 2.1 on page 25.

11.1 PD controller with compensation
247
˙V (t, ˜q, ˙˜q) given by (11.6) is indeed a globally negative deﬁnite function. Since
moreover the Lyapunov function candidate (11.3) is globally positive deﬁnite,
from Theorem 2.4 we conclude immediately global uniform asymptotic sta-
bility of the equilibrium

˜qT
˙˜q
T T
= 0 ∈IR2n. Consequently, for any initial
position and velocity error we have
lim
t→∞
˙˜q(t) = lim
t→∞( ˙qd(t) −˙q(t)) = 0
lim
t→∞˜q(t) = lim
t→∞(qd(t) −q(t)) = 0,
thus, the motion control objective is veriﬁed.
Next, we present some experimental results for the PD control with com-
pensation on the Pelican robot.
l2
lc2
q2
q1
I1
m1
g
y
x
l1
m2
I2
lc1
Link 1
Link 2
Figure 11.2. Diagram of the Pelican robot
Example 11.1. Consider the Pelican robot presented in Chapter 5, and
shown in Figure 11.2. The numerical values of its parameters are listed
in Table 5.1.
Consider this robot under PD control with compensation (11.1). It
is desired that the robot tracks the trajectories qd(t), ˙qd(t) and ¨qd(t)
represented by Equations (5.7)–(5.9).
The symmetric positive deﬁnite matrices Kp and Kv are chosen so
that

248
11 PD+ Control and PD Control with Compensation
Kp = diag{200, 150}
[N m/rad] ,
Kv = diag{3}
[N m s/rad] ,
and therefore Λ = K−1
v Kp = diag{66.6, 50} [1/s].
The initial conditions corresponding to the positions and velocities
are
q1(0) = 0,
q2(0) = 0
˙q1(0) = 0,
˙q2(0) = 0 .
0
2
4
6
8
10
−0.02
−0.01
0.00
0.01
0.02
[rad]
˜q1
˜q2
t [s]
.......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 11.3. Graph of position errors against time
Figure 11.3 shows that the experimental tracking position errors
˜q(t) remain acceptably small. Although in view of the stability anal-
ysis of the control system we could expect that the tracking errors
vanish, a number of practical aspects – neglected in the theoretical
analysis – are responsible for the resulting behavior; for instance, the
fact of digitally implementing the robot control system, the sampling
period, the fact of estimating (and not measuring) velocities and, most
importantly, in the case of the Pelican, friction at the joints.
♦
11.2 PD+ Control
PD+ control is without doubt one of the simplest control laws that may be
used in the control of robot manipulators with a formal guarantee of the
achievement of the motion control objective, globally. The PD+ control law
is given by

11.2 PD+ Control
249
τ = Kp˜q + Kv ˙˜q + M(q)¨qd + C(q, ˙q) ˙qd + g(q)
(11.7)
where Kp, Kv ∈IRn×n are symmetric positive deﬁnite matrices chosen by
the designer and as is customary, ˜q = qd −q denotes the position error.
The centrifugal and Coriolis matrix C(q, ˙q) is assumed to be chosen by us-
ing the Christoﬀel symbols (cf. Equation 3.21). This ensures that the matrix
1
2 ˙M(q) −C(q, ˙q) is skew-symmetric; a feature that will be useful in the sta-
bility analysis.
The practical implementation of PD+ control requires the exact knowl-
edge of the model of the manipulator, that is, of M(q), C(q, ˙q) and g(q). In
addition, it is necessary to know the desired trajectories qd(t), ˙qd(t) and ¨qd(t)
as well as to have the measurements q(t) and ˙q(t). Figure 11.4 depicts the
corresponding block-diagram of the PD+ control for robot manipulators.
q
˙q
C(q, ˙q)
ROBOT
¨qd
˙qd
qd
g(q)
Σ
Σ
Σ
τ
M(q)
Kp
Kv
Figure 11.4. Block-diagram: PD+ control
Notice that in the particular case of position control, that is, when ˙qd =
¨qd = 0 ∈IRn, PD+ control described by (11.7) is equivalent to PD control
with gravity compensation, (7.1).
The equation which governs the behavior in closed loop is obtained by
substituting the control action τ of the control law (11.7) in the equation of
the robot model (III.1) to get
M(q)¨˜q + C(q, ˙q) ˙˜q = −Kp˜q −Kv ˙˜q .
Notice that the closed-loop equation may be written in terms of the state

˜qT
˙˜q
T T
as
d
dt
⎡
⎣
˜q
˙˜q
⎤
⎦=
⎡
⎣
˙˜q
M(qd −˜q)−1 
−Kp˜q −Kv ˙˜q −C(qd −˜q, ˙qd −˙˜q) ˙˜q

⎤
⎦,
(11.8)

250
11 PD+ Control and PD Control with Compensation
which is a nonlinear diﬀerential equation – in general, nonautonomous. The
latter is due to the fact that this equation depends explicitly on the functions
of time: qd(t) and ˙qd(t).
Moreover, it is immediate to see the only equilibrium point of the closed-
loop equation is the origin

˜qT
˙˜q
T T
= 0 ∈IR2n. Therefore, if q(0) = qd(0)
and ˙q(0) = ˙qd(0), then q(t) = qd(t) and ˙q(t) = ˙qd(t) for all t ≥0. Notice that
the latter follows simply from the concept of equilibrium without needing to
invoke any other argument. However, to draw conclusions for the case when
q(0) ̸= qd(0) or ˙q(0) ̸= ˙qd(0) it is necessary to proceed to the stability analysis
of the equilibrium.
To analyze the stability of the origin consider now the following Lyapunov
function candidate
V (t, ˜q, ˙˜q) = 1
2
⎡
⎣
˜q
˙˜q
⎤
⎦
T⎡
⎣
Kp
0
0
M(qd −˜q)
⎤
⎦
⎡
⎣
˜q
˙˜q
⎤
⎦
= 1
2
˙˜q
TM(q) ˙˜q + 1
2 ˜qTKp˜q,
(11.9)
which is positive deﬁnite since both the inertia matrix M(q) and the matrix
of position (or proportional) gains, Kp, are positive deﬁnite.
Taking the time derivative of (11.9) we obtain
˙V (t, ˜q, ˙˜q) = ˙˜q
TM(q)¨˜q + 1
2
˙˜q
T ˙M(q) ˙˜q + ˜qTKp ˙˜q .
Solving for M(q)¨˜q of the closed-loop Equation (11.8) and substituting in
the previous equation,
˙V (t, ˜q, ˙˜q) = −˙˜q
TKv ˙˜q
= −
⎡
⎣
˜q
˙˜q
⎤
⎦
T⎡
⎣
0
0
0
Kv
⎤
⎦
⎡
⎣
˜q
˙˜q
⎤
⎦≤0
(11.10)
where the term ˙˜q
T
1
2 ˙M −C

˙˜q has been canceled by virtue of Property
4.2. From Theorem 2.3 we immediately conclude stability of the origin

˜qT ˙˜q
T T
= 0 ∈IR2n and, by Theorem 2.3, the state remains bounded.
Notice that the expression (11.10) is similar to that obtained for the Lya-
punov function used to analyze the stability of the robot in closed loop with
PD control with gravity compensation (cf. Inequality 7.4). For that controller
we used La Salle’s theorem to conclude global asymptotic stability. With this
under consideration one might also be tempted to conclude global asymptotic
stability for the origin of the closed-loop system with the PD+ controller that

11.2 PD+ Control
251
is, for the origin of (11.8). Nevertheless, this procedure would be incorrect
since we remind the reader that the closed-loop Equation (11.8) is nonau-
tonomous due to the presence of qd = qd(t). Hence, Theorem (2.7) cannot be
used.
Alternatively, we may use Lemma 2.2 to conclude that the position and
velocity errors are bounded and the velocity error is square-integrable, i.e. it
satisﬁes:
 ∞
0
˙˜q(t)

2
dt < ∞.
(11.11)
Taking into account these observations, we show next that the velocity
error ˙˜q tends asymptotically to zero. For this, notice from the closed-loop
Equation (11.8) that
¨˜q = M(q)−1 
−Kp˜q −Kv ˙˜q −C(q, ˙q) ˙˜q

(11.12)
where the terms on the right-hand side are bounded due to the following. We
know that ˜q(t) and ˙˜q(t) are bounded and that M(q) and C(q, ˙q) are bounded
matrices provided that their arguments are also bounded. Now, due to the
boundedness of ˜q and ˙˜q, we have q(t) = −˜q(t)+qd(t), and ˙q(t) = −˙˜q(t)+ ˙qd(t)
are also bounded since the desired position and velocity qd and ˙qd are bounded
vector functions. Under these conditions, the acceleration error ¨˜q(t) in (11.12)
is a bounded vector function of time. The latter, together with (11.11) and
Lemma 2.2, imply that
lim
t→∞
˙˜q(t) = lim
t→∞( ˙qd(t) −˙q(t)) = 0 ∈IRn .
Unfortunately, from the study sketched above, it is not possible to draw
any immediate conclusion about the asymptotic behavior of the position error
˜q. For this, we need to show not only stability of the origin, as has already
been done, but we also need to prove asymptotic stability. As mentioned
above, La Salle’s theorem (cf. Theorem 2.7) cannot be used to study global
asymptotic stability since the closed-loop Equation (11.8) is nonautonomous.
However, we stress that one may show that the origin of (11.8) is global
uniform asymptotic stability by other means. For instance, invoking the so-
called Matrosov’s theorem which applies nonautonomous diﬀerential equations
speciﬁcally in the case that the derivative of the Lyapunov function is only
negative semideﬁnite. The study of this theorem is beyond the scope of this
text, hence reader is invited to see the references cited at the end of the chapter
for more details on this subject.
Yet for the sake of completeness, we present in the next subsection an alter-
native analysis of global uniform asymptotic stability by means of a Lyapunov
function which has a negative deﬁnite derivative.
Example 11.2. Consider the model of an ideal pendulum of length l
with mass m concentrated at its tip, subject to the action of gravity g

252
11 PD+ Control and PD Control with Compensation
and to which a torque τ is applied at the axis of rotation (see Example
2.2) that is,
ml2¨q + mgl sin(q) = τ
where we identify M(q) = ml2, C(q, ˙q) = 0 and g(q) = mgl sin(q).
For this example, the PD+ control law given by (11.7) becomes
τ = kp˜q + kv ˙˜q + ml2¨qd + mgl sin(q)
where kp and kv are real positive numbers. The closed-loop equation
is
ml2¨˜q + kv ˙˜q + kp˜q = 0
which constitutes a linear autonomous diﬀerential equation whose
unique equilibrium

˜q
˙˜q
T = 0 ∈IR2, as can easily be shown, is
globally exponentially stable.
♦
Next, we present experimental results obtained for the Pelican 2-DOF
robot under PD+ control.
Example 11.3. Consider the 2-DOF prototype robot studied in Chapter
5, and shown in Figure 11.2.
Consider the application of PD control+ (11.7) to this robot. The
joint desired trajectories of position, velocity and acceleration, qd(t),
˙qd(t) and ¨qd(t), are given by Equations (5.7)–(5.9) on page 128.
The symmetric positive deﬁnite matrices Kp and Kv are chosen as
Kp = diag{200, 150}
[N m/rad]
Kv = diag{3}
[N m s/rad] .
The initial conditions corresponding to the positions and velocities,
are ﬁxed at
q1(0) = 0,
q2(0) = 0
˙q1(0) = 0,
˙q2(0) = 0 .
Figure 11.5 presents the experimental steady state tracking posi-
tion errors ˜q(t), which, in view of the practical aspects mentioned in
Example 11.1 (mainly friction phenomena), do not vanish.
♦
Comparing the experimental results in Figures 11.5 and 11.3, we see that
PD control with compensation behaves better than PD+ control, in the sense
that the tracking error |˜q1| satisﬁes a smaller bound.

11.2 PD+ Control
253
0
2
4
6
8
10
−0.02
−0.01
0.00
0.01
0.02
[rad]
˜q1
˜q2
t [s]
......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 11.5. Graph of the position errors against time
11.2.1 Lyapunov Function for Asymptotic Stability
We present next an alternative stability analysis for the origin of the closed-
loop Equation (11.8). This study has been taken from the literature and its
reference is cited at the end of the chapter. The advantage of the study we
present in this section is that we use a Lyapunov function that allows one to
conclude directly global uniform asymptotic stability.
In the particular case that all the joints of the robot manipulator are rev-
olute, it may be shown that the origin

˜qT
˙˜q
T T
= 0 ∈IR2n is globally
uniformly asymptotically stable. This can be done by using a Lyapunov func-
tion somewhat more complex than the one proposed in (11.9) and exploiting
the properties presented in Chapter 4.
As stated in Property 4.1, the fact that a robot manipulator has only
revolute joints, implies that the largest eigenvalue λMax{M(q)} of the inertia
matrix is bounded. On the other hand, in this study we assume that the
desired joint velocity ˙qd(t) is a bounded vector, but the bound does not need
to be known.
We present now the formal stability analysis. To study the stability prop-
erties of the origin

˜qT
˙˜q
T T
= 0 ∈IR2n of the closed-loop Equation (11.8),
consider the following Lyapunov function candidate:
V (t, ˜q, ˙˜q) = 1
2
⎡
⎣
˜q
˙˜q
⎤
⎦
T⎡
⎢⎣
Kp
ε0
1 + ∥˜ ∥M(q)
ε0
1 + ∥˜ ∥M(q)
M(q)
⎤
⎥⎦
⎡
⎣
˜q
˙˜q
⎤
⎦
(11.13)

254
11 PD+ Control and PD Control with Compensation
= W(t, ˜q, ˙˜q) +
ε0
1 + ∥˜q∥
"
#$
%
ε(˜q)
˜qT M(q) ˙˜q
where W(t, ˜q, ˙˜q) is the Lyapunov function (11.9). The positive constant ε0 is
chosen so as to satisfy simultaneously the three inequalities:
•
-
λmin{Kp}
λMax{M(q)} > ε0 > 0 ;
•
λmin{Kv}
2 (kC1 + 2λMax{M(q)}) > ε0 > 0 ;
•
2λmin{Kp}λmin{Kv}
(λMax{Kv} + kC1 ∥˙qd∥Max)2 > ε0 > 0 ;
where kC1 > 0 is a constant such that ∥C(q, ˙q)˜q∥≤kC1 ∥˙q∥∥˜q∥for all q ∈IRn
(by Property 4.2) and ∥˙qd∥Max is the largest value of ∥˙qd(t)∥. It is important to
underline that in the study presented here, it is only required to guarantee the
existence of ε0 > 0 and it is not necessary to know its actual numerical value.
In particular, it is not necessary to know ∥˙qd∥Max. Fortunately, the existence
of ε0 > 0 is guaranteed since in the inequalities above, upper-bounds on ε0
exist (that is, they are ﬁnite) and are strictly positive.
Next, we show that the Lyapunov function candidate (11.13) is positive
deﬁnite provided that
-
λmin{Kp}
λMax{M(q)} > ε0 > 0
∀q ∈IRn .
(11.14)
To show that under the previous condition the function (11.13) is positive
deﬁnite, we proceed in two steps. First, notice that since ε2
0 ≥ε2 where ε =
ε0/(1 + ∥˜q∥), Inequality (11.14) implies that
λmin{Kp}
λMax{M(q)} > ε2 > 0
∀q ∈IRn .
This in turn, implies that the matrix Kp −ε2M(q) is positive deﬁnite, i.e.
Kp −ε2M(q) > 0 .
On the other hand, the function (11.13) may be rewritten as
V (t, ˜q, ˙˜q) = 1
2

˙˜q + ε˜q
T
M(q)

˙˜q + ε˜q

+ 1
2 ˜qT 
Kp −ε2M(q)
 ˜q
which is positive deﬁnite since so are M(q) and Kp −ε2M(q).

11.2 PD+ Control
255
To show that the function deﬁned in (11.13) is also decrescent, notice that
V (t, ˜q, ˙˜q) satisﬁes
V (t, ˜q, ˙˜q) ≤1
2
'
∥˜q∥
˙˜q

(T 
λMax{Kp}
ε0 λMax{M}
ε0 λMax{M}
λMax{M}
 '
∥˜q∥
˙˜q

(
,
(11.15)
for which we have used the fact that

ε0
1 + ∥˜q∥
 ∥˜q∥≤ε0∥˜q∥.
The matrix on the right-hand side of inequality (11.15) is positive deﬁnite
in view of the condition on ε0,
-
λMax{Kp}
λMax{M(q)} > ε0 > 0
∀q ∈IRn ,
which implies that the determinant of this matrix is positive, and which triv-
ially holds under hypothesis (11.14). Thus, the function (11.13) is positive
deﬁnite, radially unbounded and decrescent.
It is interesting to remark that the Lyapunov function candidate (11.13)
is very similar to that used for the study of the PD control law with gravity
compensation (7.8). On the other hand, the function (11.13) may be consid-
ered as a more general version of the previous Lyapunov function (11.9) which
corresponds to the case ε0 = 0.
Following the study of stability, the time derivative of the Lyapunov func-
tion candidate (11.13) is given by
˙V (t, ˜q, ˙˜q) = ˙W(t, ˜q, ˙˜q) + ε(˜q) ˙˜q
TM(q) ˙˜q + ε(˜q)˜qT ˙M(q) ˙˜q
+ ε(˜q)˜qTM(q)¨˜q + ˙ε(˜q)˜qTM(q) ˙˜q
(11.16)
where ˙W(t, ˜q, ˙˜q) corresponds to the right-hand side of (11.10), that is
˙W(t, ˜q, ˙˜q) = −˙˜q
TKv ˙˜q .
Taking into account the previous expression, substituting M(q)¨˜q from the
closed-loop Equation (11.8) and rearranging terms, Equation (11.16) becomes
˙V (t, ˜q, ˙˜q) = −˙˜q
TKv ˙˜q + ε(˜q) ˙˜q
TM(q) ˙˜q + ε(˜q)˜qT
˙M(q) −C(q, ˙q)

˙˜q
−ε(˜q)˜qT
Kp˜q + Kv ˙˜q

+ ˙ε(˜q)˜qTM(q) ˙˜q .
(11.17)
Now, considering Property 4.2 which establishes
˙M(q) = C(q, ˙q) +
C(q, ˙q)T , Equation (11.17) becomes

256
11 PD+ Control and PD Control with Compensation
˙V (˜q, ˙˜q) = −˙˜q
TKv ˙˜q + ε(˜q) ˙˜q
TM(q) ˙˜q + ε(˜q) ˙˜q
T C(q, ˙q)˜q
"
#$
%
a(˜q, ˙˜q)
−ε(˜q)˜qT
Kp˜q + Kv ˙˜q

+ ˙ε(˜q)˜qTM(q) ˙˜q
"
#$
%
b(˜q, ˙˜q)
.
(11.18)
Next, we proceed to obtain upper-bounds on the terms a(˜q, ˙˜q) and b(˜q, ˙˜q).
Regarding the term a(˜q, ˙˜q) we have
a(˜q, ˙˜q) ≤
a(˜q, ˙˜q)
 =
ε ˙˜q
T C(q, ˙q)˜q

≤ε
˙˜q
 ∥C(q, ˙q)˜q∥
≤εkC1
˙˜q
 ∥˙q∥∥˜q∥
≤εkC1
˙˜q

+ ˙˜q
 + ∥˙qd∥
,
∥˜q∥
=
ε0
1 + ∥˜q∥kC1 ∥˜q∥
 ˙˜q

2
+ εkC1 ∥˜q∥
˙˜q
 ∥˙qd∥
≤ε0kC1
˙˜q

2
+ εkC1 ∥˜q∥
˙˜q
 ∥˙qd∥
where once again, we used Property 4.2 (i.e. that ∥C(q, ˙q)˜q∥≤kC1 ∥˙q∥∥˜q∥
for all q ∈IRn).
Next, regarding the term b(˜q, ˙˜q), ﬁrst notice that
˙ε(˜q) = −
ε0
∥˜q∥[1 + ∥˜q∥]2 ˜qT˙˜q .
Taking this into account we obtain
b(˜q, ˙˜q) ≤
b(˜q, ˙˜q)
 =
 ˙ε(˜q)˜qTM(q) ˙˜q

≤
ε0
∥˜q∥[1 + ∥˜q∥]2
˜qT˙˜q

˜qTM(q) ˙˜q

≤
ε0
∥˜q∥[1 + ∥˜q∥]2 ∥˜q∥
˙˜q

˜qTM(q) ˙˜q

≤
ε0
∥˜q∥[1 + ∥˜q∥]2 ∥˜q∥
˙˜q
 ∥˜q∥
M(q) ˙˜q

≤
ε0
∥˜q∥[1 + ∥˜q∥]2 ∥˜q∥
˙˜q
 ∥˜q∥

λMax{M(q)TM(q)}
˙˜q

≤
ε0
1 + ∥˜q∥
"
#$
%
ε(˜q)
˙˜q

2
λMax{M(q)}

11.2 PD+ Control
257
where λMax{M} =

λMax{M TM}, since M(q) is a symmetric positive deﬁ-
nite matrix function.
Keeping in mind the upper-bounds on a(˜q, ˙˜q) and b(˜q, ˙˜q), the derivative
˙V (t, ˜q, ˙˜q) of the Lyapunov function given by Equation (11.18), may be upper-
bounded as
˙V (t, ˜q, ˙˜q) ≤−˙˜q
TKv ˙˜q + ε ˙˜q
TM ˙˜q + ε0kC1
˙˜q

2
+ εkC1 ∥˜q∥
 ˙˜q
 ∥˙qd∥
−ε˜qT
Kp˜q + Kv ˙˜q

+ ελMax{M}
˙˜q

2
(11.19)
where for simplicity in the notation we omitted the arguments of ε(˜q) and
M(q). Using the inequalities
•
−˙˜q
TKv ˙˜q ≤−1
2 ˙˜q
TKv ˙˜q −λmin{Kv}
2
 ˙˜q

2
•
ελMax{M}
˙˜q

2
≤ε0λMax{M}
˙˜q

2
•
ε ˙˜q
TM(q) ˙˜q ≤ελMax{M}
˙˜q

2
≤ε0λMax{M}
˙˜q

2
,
we see that Inequality (11.19) may be rewritten in the form
˙V (t, ˜q, ˙˜q) ≤−
⎡
⎣
˜q
˙˜q
⎤
⎦
T⎡
⎣
εKp
ε
2Kv
ε
2Kv
1
2Kv
⎤
⎦
⎡
⎣
˜q
˙˜q
⎤
⎦+ εkC1 ∥˜q∥
 ˙˜q
 ∥˙qd∥
−1
2 [λmin{Kv}−2ε0(kC1 + 2λMax{M})]
 ˙˜q

2
.
Notice that in addition ˙V (t, ˜q, ˙˜q) may be upper-bounded in the following
manner:
˙V (t, ˜q, ˙˜q) ≤−ε
⎡
⎣
∥˜q∥
˙˜q

⎤
⎦
T
Q
⎡
⎣
∥˜q∥
 ˙˜q

⎤
⎦
"
#$
%
h(∥˜q∥, ∥˙˜q∥)
−1
2 [λmin{Kv}−2ε0 (kC1 + 2λMax{M})]
"
#$
%
δ
˙˜q

2
,
(11.20)
where the symmetric matrix Q is given by
Q =
⎡
⎣
λmin{Kp}
−1
2 (λMax{Kv} + kC1 ∥˙qd∥)
−1
2 (λMax{Kv} + kC1 ∥˙qd∥)
1
2ε0 λmin{Kv}
⎤
⎦
and where we used

258
11 PD+ Control and PD Control with Compensation
•
−ε
2 ˜qTKv ˙˜q ≤ε
2
˜qTKv ˙˜q
 ≤ε
2 ∥˜q∥
Kv ˙˜q
 ≤ε
2 ∥˜q∥

λMax{KTvKv}
˙˜q

•
−1
2ελmin{Kv}
 ˙˜q

2
= −1 + ∥˜q∥
2ε0
λmin{Kv}
 ˙˜q

2
≤−1
2ε0
λmin{Kv}
˙˜q

2
.
To guarantee that ˙V (t, ˜q, ˙˜q) is a negative deﬁnite function, it is necessary
to pick ε0 appropriately. On one hand, it is required that δ > 0, that is
λmin{Kv}
2 (kC1 + 2λMax{M}) > ε0 .
On the other hand, it is also required that the matrix Q be positive deﬁnite.
The latter is guaranteed if
2λmin{Kp}λmin{Kv}
(λMax{Kv} + kC1 ∥˙qd∥Max)2 > ε0,
where ∥˙qd∥Max ≥∥˙qd(t)∥for all t ≥0, since the previous inequality implies
that
1
2ε0
λmin{Kp}λmin{Kv} −1
4(λMax{Kv} + kC1 ∥˙qd∥)2 > 0 ,
which actually corresponds to the determinant of Q.
To summarize, the inequality in (11.20) involving ˙V (t, ˜q, ˙˜q), may be writ-
ten as
˙V (t, ˜q, ˙˜q) ≤−ε(˜q) h(∥˜q∥, ∥˙˜q∥) −c∥˙˜q∥2,
where, with the choice we made for ε0, it follows that h(∥˜q∥,
 ˙˜q
) is a positive
deﬁnite function and c > 0. The function ˙V (t, ˜q, ˙˜q) is negative deﬁnite since
ε(˜q) h(∥˜q∥, ∥˙˜q∥)−c| ˙˜q∥2 is a positive deﬁnite function of q and ˙q. In particular,
•
˙V (t, 0, 0) = 0
•
˙V (t, ˜q, ˙˜q) < 0
∀
⎡
⎣
∥˜q∥
∥˙˜q∥
⎤
⎦̸= 0
•
˙V (t, ˜q, ˙˜q) →−∞
when
∥˜q∥2 + ∥˙˜q∥
2 →∞.
Thus, using Theorem 2.4 we conclude that the origin

˜qT ˙˜q
T T
= 0 ∈IR2n
is globally uniformly asymptotically stable.
11.3 Conclusions
We may summarize the ideas exposed in this chapter as follows:

Bibliography
259
•
For any selection of the symmetric positive deﬁnite matrices Kp and Kv,
the origin of the closed-loop equation of robots with the PD control law
with compensation, expressed in terms of the state vector

˜qT
˙˜q
T T
, is
globally uniformly asymptotically stable. Therefore, the PD control law
with compensation satisﬁes the motion control objective, globally. This
implies in particular, that for any initial position error ˜q(0) ∈IRn and any
velocity error ˙˜q(0) ∈IRn, we have limt→∞˜q(t) = 0.
•
For any choice of the symmetric positive deﬁnite matrices Kp and Kv, the
origin of the closed-loop equation of a robot with the PD+ control law,
expressed in terms of the state vector

˜qT
˙˜q
T T
, is globally uniformly
asymptotically stable. Therefore, PD+ control satisﬁes the motion control
objective, globally. In particular, for any initial position error ˜q(0) ∈IRn
and velocity error ˙˜q(0) ∈IRn, we have limt→∞˜q(t) = 0.
Bibliography
The structure of the PD control law with compensation has been proposed
and studied in
•
Slotine J. J., Li W., 1987. “On the adaptive control of robot manipulators”,
The International Journal of Robotics Research, Vol. 6, No. 3, pp. 49–59.
•
Slotine J. J., Li W., 1988. “Adaptive manipulator control: A case study”,
IEEE Transactions on Automatic Control, Vol. AC-33, No. 11, November,
pp. 995–1003.
•
Slotine J. J., Li W., 1991, “Applied nonlinear control”, Prentice-Hall.
The Lyapunov function (11.3) for the analysis of global uniform asymptotic
stability for the PD control law with compensation was proposed in
•
Spong M., Ortega R., Kelly R., 1990, “Comments on “Adaptive manip-
ulator control: A case study”, IEEE Transactions on Automatic Control,
Vol. 35, No. 6, June, pp.761–762.
•
Egeland O., Godhavn J. M., 1994, “A note on Lyapunov stability for an
adaptive robot controller”, IEEE Transactions on Automatic Control, Vol.
39, No. 8, August, pp. 1671–1673.
The structure of the PD+ control law was proposed in
•
Koditschek D. E., 1984, “Natural motion for robot arms”, Proceedings
of the IEEE 23th Conference on Decision and Control, Las Vegas, NV.,
December, pp. 733–735.

260
11 PD+ Control and PD Control with Compensation
PD+ control was originally presented in2
•
Paden B., Panja R., 1988, “Globally asymptotically stable PD+ controller
for robot manipulators”, International Journal of Control, Vol. 47, No. 6,
pp. 1697–1712.
The material in Subsection 11.2.1 on the Lyapunov function to show global
uniform asymptotic stability is taken from
•
Whitcomb L. L., Rizzi A., Koditschek D. E., 1993, “Comparative experi-
ments with a new adaptive controller for robot arms”, IEEE Transactions
on Robotics and Automation, Vol. 9, No. 1, February, pp. 59–70.
Problems
1. Consider the model of an ideal pendulum studied in Example 2.2 (see
page 30)
J ¨q + mgl sin(q) = τ .
Assume that we apply the PD controller with compensation
τ = kp˜q + kv ˙˜q + J[¨qd + λ˙˜q] + mgl sin(q)
where λ = kp/kv, kp and kv are positive numbers.
a) Obtain the closed-loop equation in terms of the state vector

˜q
˙˜q
T .
Verify that the origin is its unique equilibrium point.
b) Show that the origin

˜q
˙˜q
T = 0 ∈IR2 is globally asymptotically
stable .
Hint: Use the Lyapunov function candidate
V (˜q, ˙˜q) = 1
2J
˙˜q + λ˜q
2 + kp˜q2 .
2. Consider PD+ control for the ideal pendulum presented in Example 11.2.
Propose a Lyapunov function candidate to show that the origin

˜q
˙˜q

=
[0 0]T = 0 ∈IR2 of the closed-loop equation
ml2¨˜q + kv ˙˜q + kp˜q = 0
is a globally asymptotically stable equilibrium point.
2 This, together with PD control with compensation were the ﬁrst controls with
rigorous proofs of global uniform asymptotic stability proposed for the motion
control problem.

Problems
261
3. Consider the model of the pendulum from Example 3.8 and illustrated in
Figure 3.13,

Jm + JL
r2

¨q +

fm + fL
r2 + KaKb
Ra

˙q + kL
r2 sin(q) = Ka
rRa
v
where
•
v is the armature voltage (input)
•
q is the angular position of the pendulum with respect to the vertical
(output),
and the rest of the parameters are constants related to the electrical and
mechanical parts of the system and which are positive and known.
It is desired to drive the angular position q(t) to a constant value qd. For
this, we propose to use the following control law of type PD+3,
v = rRa
Ka

kp˜q −kv ˙q + kL
r2 sin(q)

with kp and kv positive design constants and ˜q(t) = qd −q(t).
a) Obtain the closed-loop equation in terms of the state [˜q
˙q]T .
b) Verify that the origin is an equilibrium and propose a Lyapunov func-
tion to demonstrate its stability.
c) Could it be possible to show as well that the origin is actually globally
asymptotically stable?
4. Consider the control law
τ = Kp˜q + Kv ˙˜q + M(q)¨qd + C(q, ˙qd) ˙q + g(q) .
a) Point out the diﬀerence with respect to the PD+ control law given by
Equation (11.7)
b) Show that in reality, the previous controller is equivalent to the PD+
controller.
Hint: Use Property 4.2.
5. Verify Equation (11.6) by use of (11.5) .
3 Notice that since the task here is position control, in this case the controller is
simply of type PD with gravity compensation.

12
Feedforward Control and PD Control plus
Feedforward
The practical implementation of controllers for robot manipulators is typically
carried out using digital technology. The way these control systems operate
consists basically of the following stages:
•
sampling of the joint position q (and of the velocity ˙q);
•
computation of the control action τ from the control law;
•
the ‘order’ to apply this control action is sent to the actuators.
In certain applications where it is required that the robot realize repetitive
tasks at high velocity, the previous stages must be executed at a high cadence.
The bottleneck in time-consumption terms, is the computation of the control
action τ. Naturally, a reduction in the time for computation of τ has the ad-
vantage of a higher processing frequency and hence a larger potential for the
execution of ‘fast’ tasks. This is the main reason for the interest in controllers
that require “little” computing power. In particular, this is the case for con-
trollers that use information based on the desired positions, velocities, and
accelerations qd(t), ˙qd(t), and ¨qd(t) respectively. Indeed, in repetitive tasks
the desired position qd(t) and its time derivatives happen to be vectorial pe-
riodic functions of time and moreover they are known once the task has been
speciﬁed. Once the processing frequency has been established, the terms in
the control law that depend exclusively on the form of these functions, may
be computed and stored in memory, in a look-up table. During computation
of the control action, these precomputed terms are simply collected out of
memory, thereby reducing the computational burden.
In this chapter we consider two control strategies which have been sug-
gested in the literature and which make wide use of precomputed terms in
their respective control laws:
•
feedforward control;
•
PD control plus feedforward.
Each of these controllers is the subject of a section in the present chapter.

264
12 Feedforward Control and PD Control plus Feedforward
12.1 Feedforward Control
Among the conceptually simplest control strategies that may be used to con-
trol a dynamic system we ﬁnd the so-called open-loop control, where the
controller is simply the inverse dynamics model of the system evaluated along
the desired reference trajectories.
For the case of linear dynamic systems, this control technique may be
roughly sketched as follows. Consider the linear system described by
˙x = Ax + u
where x ∈IRn is the state vector and at same time the output of the system,
A ∈IRn×n is a matrix whose eigenvalues λi{A} have negative real part,
and u ∈IRn is the input to the system. Assume that we specify a vectorial
function xd as well as its time derivative ˙xd to be bounded. The control goal
is that x(t) →xd(t) when t →∞. In other words, deﬁning the errors vector
˜x = xd −x, the control problem consists in designing a controller that allows
one to determine the input u to the system so that limt→∞˜x(t) = 0. The
solution to this control problem using the inverse dynamic model approach
consists basically in substituting x and ˙x with xd and ˙xd in the equation of
the system to control, and then solving for u, i.e.
u = ˙xd −Axd .
In this manner, the system formed by the linear system to control and the
previous controller satisﬁes
˙˜x = A˜x
which in turn is a linear system of the new state vector ˜x and moreover we
know from linear systems theory that since the eigenvalues of the matrix A
have negative real parts, then limt→∞˜x(t) = 0 for all ˜x(0) ∈IRn.
In robot control, this strategy provides the supporting arguments to the
following argument. If we apply a torque τ at the input of the robot, the
behavior of its outputs q and ˙q is governed by (III.1), i.e.
d
dt
⎡
⎣
q
˙q
⎤
⎦=
⎡
⎣
˙q
M(q)−1 [τ −C(q, ˙q) ˙q −g(q)]
⎤
⎦.
(12.1)
If we wish that the behavior of the outputs q and ˙q be equal to that
speciﬁed by qd and ˙qd respectively, it seems reasonable to replace q, ˙q and ¨q
by qd, ˙qd, and ¨qd in the Equation (12.1) and to solve for τ. This reasoning
leads to the equation of the feedforward controller, given by
τ = M(qd)¨qd + C(qd, ˙qd) ˙qd + g(qd) .
(12.2)

12.1 Feedforward Control
265
Notice that the control action τ does not depend on q nor on ˙q, that is,
it is an open loop control. Moreover, such a controller does not possess any
design parameter. As with any other open-loop control strategy, this approach
needs the precise knowledge of the dynamic system to be controlled, that is,
of the dynamic model of the manipulator and speciﬁcally, of the structure
of the matrices M(q), C(q, ˙q) and of the vector g(q) as well as knowledge
of their parameters (masses, inertias etc.). For this reason it is said that the
feedforward control is (robot-) ‘model-based’. The interest in a controller of
this type resides in the advantages that it oﬀers in implementation. Indeed,
having determined qd, ˙qd and ¨qd (in particular for repetitive tasks), one may
determine the terms M(qd), C(qd, ˙qd) and g(qd) oﬀ-line and easily compute
the control action τ according to Equation (12.2). This motivates the qualiﬁer
“feedforward” in the name of this controller.
Nonetheless, one should not forget that a controller of this type has the
intrinsic disadvantages of open-loop control systems, e.g. lack of robustness
with respect to parametric and structural uncertainties, performance degra-
dation in the presence of external perturbations, etc. In Figure 12.1 we present
the block-diagram corresponding to a robot under feedforward control.
C(qd, ˙qd)
g(qd)
τ
ROBOT
q
˙q
˙qd
qd
¨qd
M(qd)
Σ
Σ
Figure 12.1. Block-diagram: feedforward control
The behavior of the control system is described by an equation obtained
by substituting the equation of the controller (12.2) in the model of the robot
(III.1), that is
M(q)¨q + C(q, ˙q) ˙q + g(q) = M(qd)¨qd + C(qd, ˙qd) ˙qd + g(qd) .
(12.3)
To avoid cumbersome notation in this chapter we use from now on and
whenever it appears, the following notation
M = M(q)
Md = M(qd)
C = C(q, ˙q)

266
12 Feedforward Control and PD Control plus Feedforward
Cd = C(qd, ˙qd)
g = g(q)
gd = g(qd) .
Equation (12.3) may be written in terms of the state vector

˜qT
˙˜q
T T
as
d
dt
⎡
⎣
˜q
˙˜q
⎤
⎦=
⎡
⎣
˙˜q
−M −1 [(Md −M)¨qd + Cd ˙qd −C ˙q + gd −g]
⎤
⎦,
which represents an ordinary nonlinear nonautonomous diﬀerential equation.
The origin

˜qT
˙˜q
T T
= 0 ∈IR2n is an equilibrium point of the previous equa-
tion but in general, it is not the only one. This is illustrated in the following
examples.
Example 12.1. Consider the model of an ideal pendulum of length l
with mass m concentrated at the tip and subject to the action of
gravity g. Assume that a torque τ is applied at the rotating axis
ml2¨q + mgl sin(q) = τ
where we identify M(q) = ml2, C(q, ˙q) = 0 and g(q) = mgl sin(q).
The feedforward controller (12.2), reduces to
τ = ml2¨qd + mgl sin(qd) .
The behavior of the system is characterized by Equation (12.3),
ml2¨q + mgl sin(q) = ml2¨qd + mgl sin(qd)
or, in terms of the state

˜q
˙˜q
T , by
d
dt
⎡
⎣
˜q
˙˜q
⎤
⎦=
⎡
⎣
˙˜q
−g
l [sin(qd) −sin(qd −˜q)]
⎤
⎦.
Clearly the origin

˜q
˙˜q
T = 0 ∈IR2 is an equilibrium but so are
the points

˜q
˙˜q
T = [2nπ 0]T for any integer value that n takes.
♦
The following example presents the study of the feedforward control of a 3-
DOF Cartesian robot. The dynamic model of this manipulator is an innocuous
linear system.

12.1 Feedforward Control
267
Example 12.2. Consider the 3-DOF Cartesian robot studied in Exam-
ple 3.4 (see page 69) and shown in Figure 3.5. Its dynamic model is
given by
[m1 + m2 + m3]¨q1 + [m1 + m2 + m3]g = τ1
[m1 + m2] ¨q2 = τ2
m1¨q3 = τ3 ,
where we identify
M(q) =
⎡
⎣
m1 + m2 + m3
0
0
0
m1 + m2
0
0
0
m1
⎤
⎦
C(q, ˙q) = 0
g(q) =
⎡
⎣
[m1 + m2 + m3]g
0
0
⎤
⎦.
Notice that the dynamic model is characterized by a linear diﬀeren-
tial equation. The “closed-loop” equation1 obtained with feedforward
control is given by
d
dt
⎡
⎣
˜q
˙˜q
⎤
⎦=
⎡
⎣
0
I
0
0
⎤
⎦
⎡
⎣
˜q
˙˜q
⎤
⎦,
which has an inﬁnite number of non-isolated equilibria given by

˜qT
˙˜q
T T
=
˜qT
0T T ∈IR2n,
where ˜q is any vector in IRn. Naturally, the origin is an equilibrium
but it is not isolated. Consequently, this equilibrium (and actually
any other) may not be asymptotically stable even locally. Moreover,
due to the linear nature of the equation that characterizes the control
system, it may be shown that in this case any equilibrium point is
unstable (see problem 12.2).
♦
The previous examples makes it clear that multiple equilibria may coexist
for the diﬀerential equation that characterizes the behavior of the control
system. Moreover, due to the lack of design parameters in the controller, it is
impossible to modify either the location or the number of equilibria, and even
1 Here we write “closed-loop” in quotes since as a matter of fact the control system
in itself is a system in open loop.

268
12 Feedforward Control and PD Control plus Feedforward
less, their stability properties, which are determined only by the dynamics of
the manipulator. Obviously, a controller whose behavior in robot control has
these features is of little utility in real applications. As a matter of fact, its
use may yield catastrophic results in certain applications as we show in the
following example.
l2
lc2
q2
q1
I1
m1
g
y
x
l1
m2
I2
lc1
Link 1
Link 2
Figure 12.2. Diagram of the Pelican prototype
Example 12.3. Consider the 2-DOF prototype robot studied in Chapter
5, and shown in Figure 12.2.
Consider the feedforward control law (12.2) on this robot. The
desired trajectory in joint space is given by qd(t) which is deﬁned in
(5.7) and whose graph is depicted in Figure 5.5 (cf. page 129).
The initial conditions for positions and velocities are chosen as
q1(0) = 0,
q2(0) = 0
˙q1(0) = 0,
˙q2(0) = 0 .
Figure 12.3 presents experimental results; it shows the components
of position error ˜q(t), which tend to a largely oscillatory behavior.
Naturally, this behavior is far from satisfactory.
♦

12.2 PD Control plus Feedforward
269
0
2
4
6
8
10
−0.5
0.0
0.5
1.0
1.5
2.0
[rad]
˜q1
˜q2
t [s]
...............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
...........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 12.3. Graphs of position errors ˜q1 and ˜q2
So far, we have presented a series of examples that show negative features
of the feedforward control given by (12.2). Naturally, these examples might
discourage a formal study of stability of the origin as an equilibrium of the
diﬀerential equation which models the behavior of this control system.
Moreover, a rigorous generic analysis of stability or instability seems to
be an impossible task. While we presented in Example 12.2 the case when
the origin of the equation which characterizes the control system is unstable,
Problem 12.1 addresses the case in which the origin is a stable equilibrium.
The previous observations make it evident that feedforward control, given
by (12.2), even with exact knowledge of the model of the robot, may be
inadequate to achieve the motion control objective and even that of position
control. Therefore, we may conclude that, in spite of the practical motivation
to use feedforward control (12.2) should not be applied in robot control.
Feedforward control (12.2) may be modiﬁed by the addition, for example,
of a feedback Proportional–Derivative (PD) term
τ = M(qd)¨qd + C(qd, ˙qd) ˙qd + g(qd) + Kp˜q + Kv ˙˜q
(12.4)
where Kp and Kv are the gain matrices (n × n) of position and velocity
respectively. The controller (12.4) is now a closed-loop controller in view of
the explicit feedback of q and ˙q used to compute ˜q and ˙˜q respectively. The
controller (12.4) is studied in the following section.
12.2 PD Control plus Feedforward
The wide practical interest in incorporating the smallest number of computa-
tions in real time to implement a robot controller has been the main motiva-
tion for the PD plus feedforward control law, given by

270
12 Feedforward Control and PD Control plus Feedforward
τ = Kp˜q + Kv ˙˜q + M(qd)¨qd + C(qd, ˙qd) ˙qd + g(qd),
(12.5)
where Kp, Kv ∈IRn×n are symmetric positive deﬁnite matrices, called gains
of position and velocity respectively. As is customary in this textbook, ˜q =
qd −q stands for the position error. The term ‘feedforward’ in the name of the
controller results from the fact that the control law uses the dynamics of the
robot evaluated explicitly at the desired motion trajectory. In the control law
(12.5), the centrifugal and Coriolis forces matrix, C(q, ˙q), is assumed to be
computed via the Christoﬀel symbols (cf. Equation 3.21). This allows one to
ensure that the matrix 1
2 ˙M(q) −C(q, ˙q) is skew-symmetric, a property which
is fundamental to the stability analysis of the closed-loop control system.
It is assumed that the manipulator has only revolute joints and that the
upper-bounds on the norms of desired velocities and accelerations, denoted as
∥˙qd∥M and ∥¨qd∥M, are known.
The PD control law plus feedforward given by (12.5) may be regarded as
a generalization of the PD control law with gravity precompensation (8.1).
Figure 12.4 shows the block-diagram corresponding to the PD control law
plus feedforward.
g(qd)
Kv
Kp
Σ
Σ
qd
˙qd
C(qd, ˙qd)
˙q
Σ
Σ
Σ
τ
ROBOT
q
¨qd
M(qd)
Figure 12.4. Block-diagram: PD control plus feedforward
Reported experiences in the literature of robot motion control using the
control law (12.5) detail an excellent performance actually comparable with
the performance of the popular computed-torque control law, which is pre-
sented in Chapter 10. Nevertheless, these comparison results may be mislead-
ing since good performance is not only due to the controller structure, but
also to appropriate tuning of the controller gains.
The dynamics in closed loop is obtained by substituting the control action
τ from (12.5) in the equation of the robot model (III.1) to get
M(q)¨q + C(q, ˙q) ˙q + g(q) = Kp˜q + Kv ˙˜q + M(qd)¨qd + C(qd, ˙qd) ˙qd + g(qd) .
(12.6)

12.2 PD Control plus Feedforward
271
The closed-loop Equation (12.6) may be written in terms of the state
vector

˜qT
˙˜q
T T
as
d
dt
⎡
⎣
˜q
˙˜q
⎤
⎦=
⎡
⎣
˙˜q
M(q)−1 
−Kp˜q −Kv ˙˜q −C(q, ˙q) ˙˜q −h(t, ˜q, ˙˜q)

⎤
⎦
(12.7)
where we remind the reader that h(t, ˜q, ˙˜q) is the so-called residual dynamics,
given by
h(t, ˜q, ˙˜q) = [M(qd) −M(q)]¨qd + [C(qd, ˙qd) −C(q, ˙q)] ˙qd + g(qd) −g(q) .
See (4.12).
It is simple to prove that the origin [2qT
˙2q
T ]T = 0 ∈IR2n of the state space
is an equilibrium, independently of the gain matrices Kp and Kv. However,
the number of equilibria of the system in closed loop, i.e.(12.7), depends on
the proportional gain Kp. This is formally studied in the following section.
12.2.1 Unicity of the Equilibrium
We present suﬃcient conditions on Kp that guarantee the existence of a unique
equilibrium (the origin) for the closed-loop Equation (12.7).
For the case of robots having only revolute joints and with a suﬃciently
“large” choice of Kp, we can show that the origin

˜qT
˙˜q
T T
= 0 ∈IR2n is the
unique equilibrium of the closed-loop Equation (12.7). Indeed, the equilibria
are the constant vectors [2qT
˙2q
T ]T = [˜q∗T
0T ]T ∈IR2n, where ˜q∗∈IRn is a
solution of
Kp˜q∗+ h(t, ˜q∗, 0) = 0 .
(12.8)
The previous equation is always satisﬁed by the trivial solution ˜q∗= 0 ∈
IRn, but this does not exclude other vectors ˜q∗from being solutions, depending
of course, on the value of the proportional gain Kp. Explicit conditions on the
proportional gain to ensure unicity of the equilibrium are presented next. To
that end deﬁne
k(˜q∗) = K−1
p h(t, ˜q∗, 0) .
The idea is to note that any ﬁxed point ˜q∗∈IRn of k(˜q∗) is a solution of
(12.8). Hence, we wish to ﬁnd conditions on Kp so that k(˜q∗) has a unique
ﬁxed point. Given that ˜q∗= 0 is always a ﬁxed point, then this shall be
unique.
Notice that for all vectors x, y ∈IRn, we have

272
12 Feedforward Control and PD Control plus Feedforward
∥k(x) −k(y)∥≤
K−1
p
[h(t, x, 0) −h(t, y, 0)]

≤λMax
)
K−1
p
*
∥h(t, x, 0) −h(t, y, 0)∥.
On the other hand, using the deﬁnition of the residual dynamics (4.12),
we have
∥h(t, x, 0) −h(t, y, 0)∥≤∥[M(qd −y) −M(qd −x)] ¨qd∥
+ ∥[C(qd −y, ˙qd) −C(qd −x, ˙qd)] ˙qd∥
+ ∥g(qd −y) −g(qd −x)∥.
From Properties 4.1 to 4.3 we guarantee the existence of constants kM, kC1,
kC2 and kg, associated to the inertia matrix M(q), to the matrix of centrifugal
and Coriolis forces C(q, ˙q), and to the vector of gravitational torques g(q)
respectively, such that
∥M(x)z −M(y)z∥≤kM∥x −y∥∥z∥,
∥C(x, z)w −C(y, v)w∥≤kC1∥z −v∥∥w∥
+kC2∥z∥∥x −y∥∥w∥,
∥g(x) −g(y)∥≤kg∥x −y∥,
for all v, w, x, y, z ∈IRn. Taking into account this fact we obtain
∥h(t, x, 0) −h(t, y, 0)∥≤

kg + kM ∥¨qd∥M + kC2 ∥˙qd∥2
M

∥x −y∥.
From this and using λMax
)
K−1
p
*
= 1/λmin {Kp}, since Kp is a symmetric
positive deﬁnite matrix, we get
∥k(x) −k(y)∥≤
1
λmin {Kp}

kg + kM ∥¨qd∥M + kC2 ∥˙qd∥2
M

∥x −y∥.
Finally, invoking the contraction mapping theorem (cf. Theorem 2.1 on
page 26), we conclude that
λmin {Kp} > kg + kM ∥¨qd∥M + kC2 ∥˙qd∥2
M
(12.9)
is a suﬃcient condition for k(˜q∗) to have a unique ﬁxed point, and therefore,
for the origin of the state space to be the unique equilibrium of the closed-loop
system, i.e. Equation (12.7).
As has been shown before, the PD control law plus feedforward, (12.5),
reduces to control with desired gravity compensation (8.1) in the case when
the desired position qd is constant. For this last controller, we shown in Section
8.2 that the corresponding closed-loop equation had a unique equilibrium if
λmin{Kp} > kg. It is interesting to remark that when qd is constant we recover
from (12.9), the previous condition for unicity.

12.2 PD Control plus Feedforward
273
Example 12.4. Consider the model of an ideal pendulum of length l
with mass m concentrated at its tip and subject to the action of gravity
g. Assume that a torque τ is applied at the axis of rotation, that is
ml2¨q + mgl sin(q) = τ .
The PD control law plus feedforward, (12.5), is in this case
τ = kp˜q + kv ˙˜q + ml2¨qd + mgl sin(qd)
where kp and kv are positive design constants. The closed-loop equa-
tion is
d
dt
⎡
⎣
˜q
˙˜q
⎤
⎦=
⎡
⎣
˙˜q
−
1
ml2

kp˜q + kv ˙˜q + mgl [sin(qd) −sin(qd −˜q)]

⎤
⎦
which has an equilibrium at the origin

˜q
˙˜q
T = 0 ∈IR2. If qd(t) is
constant, there may exist additional equilibria

˜q
˙˜q
T = [˜q∗0]T ∈IR2
where ˜q∗is a solution of
kp˜q∗+ mgl [sin(qd) −sin(qd −˜q∗)] = 0 .
Example 8.1 shows the case when the previous equation has three
solutions. For the same example, if kp is suﬃciently large, it was shown
that ˜q∗= 0 is the unique solution.
We stress that according to Theorem 2.6, if there exist more than
one equilibrium, then none of them may be globally uniformly asymp-
totically stable.
♦
12.2.2 Global Uniform Asymptotic Stability
In this section we present the analysis of the closed-loop Equation (12.6) or
equivalently, of (12.7). In this analysis we establish conditions on the design
matrices Kp and Kv that guarantee global uniform asymptotic stability of
the origin of the state space corresponding to the closed-loop equation. We
assume that the symmetric positive deﬁnite matrix Kp is also diagonal.
Before studying the stability of the origin

˜qT
˙˜q
T T
= 0 ∈IR2n of the
closed-loop Equation (12.6) or (12.7), it is worth recalling Deﬁnition 4.1 of
the vectorial tangent hyperbolic function which has the form given in (4.13),
i.e.

274
12 Feedforward Control and PD Control plus Feedforward
tanh(x) =
⎡
⎢⎣
tanh(x1)
...
tanh(xn)
⎤
⎥⎦
(12.10)
with x ∈IRn. As stated in Deﬁnition 4.1, this function satisﬁes the following
properties for all x, ˙x ∈IRn
•
∥tanh(x)∥≤α1 ∥x∥
•
∥tanh(x)∥≤α2
•
∥tanh(x)∥2 ≤α3 tanh(x)T x
•
Sech2(x) ˙x
 ≤α4 ∥˙x∥
with α1, · · · , α4 > 0. For tanh(x) deﬁned as in (4.13), the constants involved
are taken as α1 = 1, α2 = √n, α3 = 1, α4 = 1.
In the sequel we assume that given a constant γ > 0, the matrix Kv is
chosen suﬃciently “large” in the sense that
λMax{Kv} ≥λmin{Kv} > kh1 + γ b ,
(12.11)
and so is Kp but in the sense that
λMax{Kp} ≥λmin{Kp} > α3
'
[2 γ a + kh2]2
4 γ [λmin{Kv} −kh1 −γb] + kh2
(
(12.12)
so that
λMax{Kp} ≥λmin{Kp} > γ2 α2
1 λ2
Max{M}
λmin{M}
(12.13)
where kh1 and kh2 are deﬁned in (4.25) and (4.24), while the constants a and
b are given by
a = 1
2 [λMax{Kv} + kC1 ∥˙qd∥M + kh1] ,
b = α4 λMax{M} + α2 kC1 .
Lyapunov Function Candidate
Consider the Lyapunov function candidate2 (7.3),
V (t, ˜q, ˙˜q) = 1
2
˙˜q
T M(q) ˙˜q + 1
2 ˜qT Kp˜q + γtanh(˜q)T M(q) ˙˜q
(12.14)
2 Notice that V = V (t, ˜ , ˙˜ ). The dependence of t comes from the fact that, to
avoid cumbersome notation, we have abbreviated M( d(t) −˜ ) to M( ).

12.2 PD Control plus Feedforward
275
where tanh(˜q) is the vectorial tangent hyperbolic function (12.10) and γ > 0
is a given constant.
To show that the Lyapunov function candidate (12.14) is positive deﬁnite
and radially unbounded, we ﬁrst observe that the third term in (12.14) satisﬁes
γtanh(˜q)T M(q) ˙˜q ≤γ ∥tanh(˜q)∥
M(q) ˙˜q

≤γ λMax{M} ∥tanh(˜q)∥∥˙˜q∥
≤γ α1λMax{M} ∥˜q∥∥˙˜q∥
where we used ∥tanh(˜q)∥≤α1 ∥˜q∥in the last step. From this we obtain
−γtanh(˜q)T M(q) ˙˜q ≥−γ α1λMax{M} ∥˜q∥
˙˜q
 .
Therefore, the Lyapunov function candidate (12.14) satisﬁes the following
inequality:
V (t, ˜q, ˙˜q) ≥1
2
⎡
⎣
∥˜q∥
˙˜q

⎤
⎦
T '
λmin{Kp}
−γ α1 λMax{M}
−γ α1 λMax{M}
λmin{M}
( ⎡
⎣
∥˜q∥
˙˜q

⎤
⎦
and consequently, it happens to be positive deﬁnite and radially unbounded
since by assumption, Kp is positive deﬁnite (i.e. λmin{Kp} > 0) and we also
supposed that it is chosen so as to satisfy (12.13).
Following similar steps to those above one may also show that the Lya-
punov function candidate V (t, ˜q, ˙˜q) deﬁned in (12.14) is bounded from above
by
V (t, ˜q, ˙˜q) ≤1
2
⎡
⎣
∥˜q∥
˙˜q

⎤
⎦
T '
λMax{Kp}
γ α1 λMax{M}
γ α1 λMax{M}
λMax{M}
( ⎡
⎣
∥˜q∥
 ˙˜q

⎤
⎦
which is positive deﬁnite and radially unbounded since the condition
λMax{Kp} > γ2α2
1 λMax{M}
is trivially satisﬁed under hypothesis (12.13) on Kp. This means that V (t, ˜q, ˙˜q)
is decrescent.
Time Derivative
The time derivative of the Lyapunov function candidate (12.14) along the
trajectories of the closed-loop system (12.7) is

276
12 Feedforward Control and PD Control plus Feedforward
˙V (t, ˜q, ˙˜q) = ˙˜q
T 
−Kp˜q −Kv ˙˜q −C(q, ˙q) ˙˜q −h(t, ˜q, ˙˜q)

+ 1
2
˙˜q
T ˙M(q) ˙˜q
+ ˜qT Kp ˙˜q + γ ˙˜q
T Sech2(˜q)T M(q) ˙˜q + γtanh(˜q)T ˙M(q) ˙˜q
+ γtanh(˜q)T 
−Kp˜q −Kv ˙˜q −C(q, ˙q) ˙˜q −h(t, ˜q, ˙˜q)

.
Using Property 4.2 which establishes the skew-symmetry of
1
2 ˙M −C and
˙M(q) = C(q, ˙q) + C(q, ˙q)T , the time derivative of the Lyapunov function
candidate yields
˙V (t, ˜q, ˙˜q) = −˙˜q
T Kv ˙˜q + γ ˙˜q
T Sech2(˜q)T M(q) ˙˜q −γtanh(˜q)T Kp˜q
−γtanh(˜q)T Kv ˙˜q + γtanh(˜q)T C(q, ˙q)T ˙˜q
−˙˜q
T h(t, ˜q, ˙˜q) −γ tanh(˜q)T h(t, ˜q, ˙˜q) .
(12.15)
We now proceed to upper-bound ˙V (t, ˜q, ˙˜q) by a negative deﬁnite function
in terms of the states ˜q and ˙˜q. To that end, it is convenient to ﬁnd upper-
bounds for each term of (12.15).
The ﬁrst term of (12.15) may be trivially bounded by
−˙˜q
T Kv ˙˜q ≤−λmin{Kv}∥˙˜q∥2 .
(12.16)
To upper-bound the second term of (12.15) we ﬁrst recall that the
vectorial tangent hyperbolic function tanh(˜q) deﬁned in (12.10) satisﬁes
Sech2(˜q) ˙˜q
 ≤α4
˙˜q
 with α4 > 0 . From this, it follows that
γ ˙˜q
T Sech2(˜q)T M(q) ˙˜q ≤γα4 λMax{M}
 ˙˜q

2
.
On the other hand, notice that in view of the fact that Kp is a diagonal
positive deﬁnite matrix, and ∥tanh(˜q)∥2 ≤α3 tanh(˜q)T ˜q, we get
γ α3 tanh(˜q)T Kp˜q ≥γλmin{Kp} ∥tanh(˜q)∥2
which ﬁnally leads to the important inequality,
−γtanh(˜q)T Kp˜q ≤−γ λmin{Kp}
α3
∥tanh(˜q)∥2 .
A bound on γtanh(˜q)T Kv ˙˜q is obtained straightforwardly and is given by
γtanh(˜q)T Kv ˙˜q ≤γλMax{Kv}
˙˜q
 ∥tanh(˜q)∥.
The upper-bound on the term γtanh(˜q)T C(q, ˙q)T ˙˜q must be carefully cho-
sen. Notice that

12.2 PD Control plus Feedforward
277
γtanh(˜q)T C(q, ˙q)T ˙˜q = γ ˙˜q
T C(q, ˙q)tanh(˜q)
≤γ
 ˙˜q
 ∥C(q, ˙q)tanh(˜q)∥.
Considering again Property 4.2 but in its variant that establishes the existence
of a constant kC1 such that ∥C(q, x)y∥≤kC1 ∥x∥∥y∥for all q, x, y ∈IRn,
we have
γtanh(˜q)T C(q, ˙q)T ˙˜q ≤γkC1
 ˙˜q
 ∥˙q∥∥tanh(˜q)∥,
≤γkC1
 ˙˜q

˙qd −˙˜q
 ∥tanh(˜q)∥,
≤γkC1
 ˙˜q
 ∥˙qd∥∥tanh(˜q)∥
+γkC1
˙˜q

 ˙˜q
 ∥tanh(˜q)∥.
Making use of the property that ∥tanh(˜q)∥≤α2 for all ˜q ∈IRn, we get
γtanh(˜q)T C(q, ˙q)T ˙˜q ≤γ kC1 ∥˙qd∥M
˙˜q
 ∥tanh(˜q)∥+ γα2 kC1
˙˜q

2
.
At this point it is only left to ﬁnd upper-bounds on the two terms which
contain h(t, 2q, ˙2q). This study is based on the use of the characteristics es-
tablished in Property 4.4 on the vector of residual dynamics h(t, ˜q, ˙˜q), which
indicates the existence of constants kh1, kh2 ≥0 – which may be computed
by (4.24) and (4.25) – such that the norm of the residual dynamics satisﬁes
(4.15),
h(t, ˜q, ˙˜q)
 ≤kh1
˙˜q
 + kh2 ∥tanh(˜q)∥.
First, we study the term −˙2q
T h(t, 2q, ˙2q):
−˙2q
T h(t, 2q, ˙2q) ≤
 ˙2q

h(t, 2q, ˙2q)
 ,
≤kh1
˙2q

2
+ kh2
 ˙2q
 ∥tanh(˜q)∥.
The remaining term satisﬁes
−γtanh(2q)T h(t, 2q, ˙2q) ≤γ ∥tanh(2q)∥
h(t, 2q, ˙2q)
 ,
≤γ kh1
˙2q
 ∥tanh(2q)∥+ γ kh2 ∥tanh(˜q)∥2 .
(12.17)
The bounds (12.16)–(12.17) yield that the time derivative ˙V (t, ˜q, ˙˜q) in
(12.15), satisﬁes

278
12 Feedforward Control and PD Control plus Feedforward
˙V (t, ˜q, ˙q) ≤
−γ
'
∥tanh(˜q)∥
∥˙q∥
(T
⎡
⎢⎣
λmin{Kp}
α3
−kh2
−a −1
γ
kh2
2
−a −1
γ
kh2
2
1
γ [λmin{Kv} −kh1] −b
⎤
⎥⎦
"
#$
%
R(γ)
'
∥tanh(˜q)∥
∥˙q∥
(
(12.18)
where
a = 1
2 [λMax{Kv} + kC1 ∥˙qd∥M + kh1] ,
b = α4 λMax{M} + α2 kC1.
According to the theorem of Sylvester, in order for the matrix R(γ) to be
positive deﬁnite it is necessary and suﬃcient that the component R11 and the
determinant det{R(γ)} be strictly positive. With respect to the ﬁrst condition
we stress that the gain Kp must satisfy
λmin{Kp} ≥α3 kh2 .
(12.19)
On the other hand, the determinant of R(γ) is given by
det{R(γ)} = 1
γ
λmin{Kp}
α3
−kh2

[λmin{Kv} −kh1]
−
λmin{Kp}
α3
−kh2

b −

a + 1
γ
kh2
2
2
.
The latter must be strictly positive for which it is necessary and suﬃcient
that the gain Kp satisﬁes
λmin{Kp} > α3
'
[2 γ a + kh2]2
4 γ [λmin{Kv} −kh1 −γb] + kh2
(
(12.20)
while it is suﬃcient that Kv satisﬁes
λmin{Kv} > kh1 + γ b
(12.21)
for the right-hand side of the inequality (12.20) to be positive. Observe that
in this case the inequality (12.19) is trivially implied by (12.20).
Notice that the inequalities (12.21) and (12.20) correspond precisely to
those in (12.11) and (12.12) as the tuning guidelines for the controller. This
means that R(γ) is positive deﬁnite and therefore, ˙V (t, ˜q, ˙˜q) is globally nega-
tive deﬁnite.
According to the arguments above, given a positive constant γ we may
determine gains Kp and Kv according to (12.11)–(12.13) in a way that the

12.2 PD Control plus Feedforward
279
function V (t, ˜q, ˙q) given by (12.14) is globally positive deﬁnite while ˙V (t, ˜q, ˙q)
expressed as (12.18) is globally negative deﬁnite. For this reason, V (t, ˜q, ˙q) is a
strict Lyapunov function. Theorem 2.4 allows one to establish global uniform
asymptotic stability of the origin of the closed-loop system.
Tuning Procedure
The stability analysis presented in previous sections allows one to obtain a
tuning procedure for the PD control law plus feedforward. This method deter-
mines the smallest eigenvalues of the symmetric design matrices Kp and Kv
– with Kp diagonal – which guarantee the achievement of the motion control
objective.
The tuning procedure may be summarized as follows.
•
Derivation of the dynamic robot model to be controlled. Particularly, com-
putation of M(q), C(q, ˙q) and g(q) in closed form.
•
Computation of the constants λMax{M(q)}, λmin{M(q)}, kM, k′
M,kC1,
kC2, k′ and kg. For this, it is suggested that the information given in
Table 4.1 (cf. page 109) is used.
•
Computation of ∥¨qd∥Max, ∥˙qd∥Max from the speciﬁcation of a given task
to the robot.
•
Computation of the constants s1 and s2 given respectively by (4.21) and
(4.22), i.e.
s1 =

kg + kM ∥¨qd∥M + kC2 ∥˙qd∥2
M

,
and
s2 = 2

k′ + k′
M ∥¨qd∥M + kC1 ∥˙qd∥2
M

.
Computation of kh1 and kh2 given by (4.24) and (4.25), i.e.
•
kh1 ≥kC1 ∥˙qd∥M ;
•
kh2 ≥
s2
tanh
+
s2
s1
, .
•
Computation of the constants a and b given by
a = 1
2 [λMax{Kv} + kC1 ∥˙qd∥M + kh1] ,
b = α4 λMax{M} + α2 kC1,
where α2 = √n, α4 = 1.
•
Select γ > 0 and determine the design matrices Kp and Kv so that their
smallest eigenvalues satisfy (12.11)–(12.13), i.e.
•
λmin{Kv} > kh1 + γ b,

280
12 Feedforward Control and PD Control plus Feedforward
•
λmin{Kp} > α3
'
[2 γ a + kh2]2
4 γ [λmin{Kv} −kh1 −γb] + kh2
(
,
•
λmin{Kp} > γ2 α2
1 λ2
Max{M}
λmin{M}
,
with α1 = 1, α3 = 1.
Next, we present an example in order to illustrate the ideas presented so
far.
Example 12.5. Consider the Pelican prototype robot shown in Figure
12.2, studied in Chapter 5 and in Example 12.3.
The elements of the inertia matrix M(q) are
M11(q) = m1l2
c1 + m2

l2
1 + l2
c2 + 2l1lc2 cos(q2)

+ I1 + I2
M12(q) = m2

l2
c2 + l1lc2 cos(q2)

+ I2
M21(q) = m2

l2
c2 + l1lc2 cos(q2)

+ I2
M22(q) = m2l2
c2 + I2 .
The elements of the centrifugal and Coriolis forces matrix C(q, ˙q)
are given by
C11(q, ˙q) = −m2l1lc2 sin(q2) ˙q2
C12(q, ˙q) = −m2l1lc2 sin(q2) [ ˙q1 + ˙q2]
C21(q, ˙q) = m2l1lc2 sin(q2) ˙q1
C22(q, ˙q) = 0 .
The elements of the vector of gravitational torques g(q) are
g1(q) = [m1lc1 + m2l1]g sin(q1) + m2lc2g sin(q1 + q2)
g2(q) = m2lc2g sin(q1 + q2) .
Using the numerical values of the constants given in Table 5.1 (cf.
page 115) as well as the formulas in Table 4.1 (cf. page 109), we get
kM = 0.0974

kg m2
,
kC1 = 0.0487

kg m2
,
kC2 = 0.0974

kg m2
,
kg = 23.94

kg m2/s2
,
k′
M = λMax{M(q)} = 0.3614

kg m2
,
λmin{M(q)} = 0.011

kg m2
.

12.2 PD Control plus Feedforward
281
For the computation of λMax{M(q)} and λmin{M(q)}, see the
explanation in Example 9.2 on page 213.
To obtain k′, we proceed numerically, that is, we evaluate the norm
g(q) for a set of values of q1 and q2 between 0 and 2π, and extract
the maximum. This happens for q1 = q2 = 0 and the maximum is
k′ = 7.664
[N m]
Consider the PD control law plus feedforward, (12.5), for this
robot. As in Example 12.3, the speciﬁcation of the task for the robot
is expressed in terms of the desired trajectory qd(t) shown in Figure
5.5 and whose analytical expression is given by (5.7). Equations (5.8)
and (5.9) correspond to the desired velocity ˙qd(t), and desired accel-
eration ¨qd(t) respectively. By numerical simulation, can be veriﬁed
the following upper-bounds on the norms of the desired velocity and
acceleration,
∥˙qd∥Max = 2.33 [ rad/s]
∥¨qd∥Max = 9.52 [ rad/s2] .
Using this information and the deﬁnitions of the constants from
the tuning procedure, we get
s1 = 25.385 [N m] ,
s2 = 22.733 [N m] ,
kh1 = 0.114

kg m2/s

,
kh2 = 31.834 [N m] ,
a = 1.614

kg m2/s

,
b = 0.43

kg m2
.
Finally, we set γ = 2 [s−1], so that it is only left to ﬁx the de-
sign matrices Kp and Kv in accordance with the conditions (12.11)–
(12.13). An appropriate choice is
Kp = diag{200, 150} [N m] ,
Kv = diag{3} [N m s/rad] .
The initial conditions corresponding to the positions and velocities
are chosen as
q1(0) = 0,
q2(0) = 0
˙q1(0) = 0,
˙q2(0) = 0 .
Figure 12.5 shows the experimental tracking errors ˜q(t). As pointed
out in previous examples, the trajectories q(t) do not vanish as ex-
pected due to several aspects always present in real implementations

282
12 Feedforward Control and PD Control plus Feedforward
0
2
4
6
8
10
−0.02
−0.01
0.00
0.01
0.02
[rad]
˜q1
˜q2
t [s]
................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 12.5. Graphs of position errors ˜q1 and ˜q2
– usually neglected in the theoretical analysis – such as digital im-
plementation of the continuous-time closed-loop control system (de-
scribed by an ordinary diﬀerential equation), measurement noise and,
most important in our experimental setting, friction at the arm joints.
Yet, in contrast to Example 12.3 where the controller did not carry
the PD term, the behavior obtained here is satisfactory.
♦
12.3 Conclusions
The conclusions drawn from the analysis presented in this chapter may be
summarized in the following terms.
•
The feedforward control for n-DOF robots is an open-loop control scheme
in open loop. For this reason, it is not advisable and moreover, in general
this control is unable to satisfy the motion control objective.
•
With PD control plus feedforward we may satisfy the control objective
globally for n-DOF robots under the condition that suﬃciently “large”
design matrices Kp and Kv are used. More signiﬁcantly, global uniform
asymptotic stability of the origin of the closed-loop equations may be
achieved under such conditions.
Bibliography
Interesting remarks on feedforward control and PD control plus feedforward
may be found in

Bibliography
283
•
Craig J., 1989, “Introduction to robotics: Mechanics and control”, Addison–
Wesley, Reading, MA.
•
Yoshikawa T., 1990, “Foundations of robotics: Analysis and control”, The
MIT Press.
(Local) asymptotic stability under PD control plus feedforward has been
analyzed in
•
Paden B., Riedle B. D., 1988, “A positive–real modiﬁcation of a class of
nonlinear controllers for robot manipulators”, Proceedings of the American
Control Conference, Atlanta, GA, pp. 1782–1785.
•
Wen J. T., 1990, “A uniﬁed perspective on robot control: The energy Lya-
punov function approach”, International Journal of Adaptive Control and
Signal Processing, Vol. 4, pp. 487–500.
•
Kelly R., Salgado R., 1994, “PD control with computed feedforward of
robot manipulators: A design procedure”, IEEE Transactions on Robotics
and Automation, Vol. 10, No. 4, August, pp. 566–571.
The proof of existence of proportional and derivative gains that guarantee
global asymptotic stability was reported in
•
Santib´a˜nez V., Kelly R., 2001, “PD control with feedforward compensation
for robot manipulators: Analysis and experimentation”, Robotica, Vol. 19,
pp. 11–19.
The following documents present experimental results for the application
of PD control plus feedforward on prototype robots.
•
Asada H., Kanade T., Takeyama I., 1983, “Control of a direct–drive arm”,
ASME Journal of Dynamic Systems, Measurement, and control, Vol. 105,
pp. 136–142.
•
An C., Atkeson C., Hollerbach J., 1988, “Model-based control of a robot
manipulator”, The MIT Press.
•
Khosla P. K., Kanade T., 1988, “Experimental evaluation of nonlinear
feedback and feedforward control schemes for manipulators”, The Interna-
tional Journal of Robotics Research, Vol. 7, No. 1, pp. 18–28.
•
Kokkinis T., Stoughton R., 1991, “Dynamics and control of a closed-chain
robot with application to a new direct-drive robot arm”, International Jour-
nal of Robotics and Automation, Vol. 6, No. 1.
•
Tarn T. J., Bejczy A. K., Marth G. T., Ramadarai A. K., 1993, “Per-
formance comparison of four manipulators servo schemes”, IEEE Control
Systems, Vol. 13, No. 1, February.
•
Caccavale F., Chiacchio P., 1994, “Identiﬁcation of dynamic parameters
and feedforward control for conventional industrial manipulators”, Control
Engineering Practice, Vol. 2, No. 6, pp. 1039–1050.

284
12 Feedforward Control and PD Control plus Feedforward
•
Reyes F., Kelly R., 2001, “Experimental evaluation of model-based con-
trollers on a direct-drive robot arm”, Mechatronics, Vol. 11, pp. 267–282.
Problems
1. Consider feedforward control of the ideal pendulum studied in Example
12.1. Assume that the desired position qd(t) is zero for all t ≥0.
a) Obtain the equation that governs the control system, in terms of
[˜q
˙q]T .
b) Show that the origin is a stable equilibrium.
Hint: See Example 2.2, on page 30.
2. Consider feedforward control of the 3-DOF Cartesian robot studied in
Example 12.2.
a) Show that if ˙˜q(0) ̸= 0, then limt→∞∥˜q(t)∥= ∞.
3. Consider the model of an ideal pendulum studied in Example 12.1 but
now including a term for viscous friction, that is,
ml2¨q + mgl sin(q) + f ˙q = τ
where f > 0 is the friction coeﬃcient. The feedforward controller (12.2)
obtained when neglecting the friction term is
τ = ml2¨qd + mgl sin(qd).
Assume that qd(t) = sin(t).
a) Obtain the equation ˙x = f(t, x) where x = [˜q ˙˜q]T . Does this equation
have any equilibria ?
b) Assume moreover that qd(0) = q(0) and ˙qd(0) = ˙q(0). May it be
expected that limt→∞˜q(t) = 0 ?
4. Consider a PD control law plus feedforward on the ideal pendulum ana-
lyzed in Example 12.4. In this example we derived the closed-loop equa-
tion,
d
dt
⎡
⎣
˜q
˙˜q
⎤
⎦=
⎡
⎣
˙˜q
−
1
ml2

kp˜q + kv ˙˜q + mgl (sin(qd) −sin(qd −˜q))

⎤
⎦.
Assume now that the desired position is given by
qd(t) = sin(t) .
On the other hand, the design constants kp and kv are chosen so that

Problems
285
kv > ml2
kp >
2

mgl + ml2
tanh
3
2

mgl + ml2
mgl
4 +
⎡
⎢⎢⎢⎢⎣
kv +
2

mgl + ml2
tanh
3
2

mgl + ml2
mgl
4
⎤
⎥⎥⎥⎥⎦
2
4 [kv −ml2]
.
a) Show that the origin

˜q
˙˜q
T = 0 ∈IR2 is a globally asymptotically
stable equilibrium.
Hint: Use the Lyapunov function candidate
V (˜q, ˙˜q) = 1
2ml2 ˙˜q
2 + 1
2kp˜q2 + ml2tanh(˜q)˙˜q
and verify that its time derivative satisﬁes
˙V (˜q, ˙˜q) ≤−
⎡
⎣
|tanh(˜q)|
˙˜q

⎤
⎦
T
R
⎡
⎣
|tanh(˜q)|
˙˜q

⎤
⎦
where
R =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
kp −
2

mgl + ml2
tanh
3
2

mgl + ml2
mgl
4
−1
2
⎡
⎢⎢⎢⎢⎣
kv +
2

mgl + ml2
tanh
3
2

mgl + ml2
mgl
4
⎤
⎥⎥⎥⎥⎦
−1
2
⎡
⎢⎢⎢⎢⎣
kv +
2

mgl + ml2
tanh
3
2

mgl + ml2
mgl
4
⎤
⎥⎥⎥⎥⎦
kv −ml2
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
5. Consider a PD control law plus feedforward on the 2-DOF robot proto-
type used in Example 12.5. In this example we presented some simulations
where Kp = diag{200, 150}. Verify that with such a selection, the corre-
sponding closed-loop equation has a unique equilibrium.
Hint: Verify that the condition (12.9) holds.

Part IV
Advanced Topics

Introduction to Part IV
In this last part of the textbook we present some advanced issues on robot
control. We deal with topics such as control without velocity measurements
and control under model uncertainty. We recommend this part of the text for
a second course on robot dynamics and control or for a course on robot control
at the ﬁrst year of graduate level. We assume that the student is familiar with
the notion of functional spaces, i.e. the spaces L2 and L∞. If not, we strongly
recommend the student to read ﬁrst Appendix A, which presents additional
mathematical baggage necessary to study these last chapters:
•
P“D” control with gravity compensation and P“D” control with desired
gravity compensation;
•
Introduction to adaptive robot control;
•
PD control with adaptive gravity compensation;
•
PD control with adaptive compensation.

13
P“D” Control with Gravity Compensation and
P“D” Control with Desired Gravity
Compensation
Robot manipulators are equipped with sensors for the measurement of joint
positions and velocities, q and ˙q respectively. Physically, position sensors may
be from simple variable resistances such as potentiometers to very precise
optical encoders. On the other hand, the measurement of velocity may be
realized through tachometers, or in most cases, by numerical approximation
of the velocity from the position sensed by the optical encoders. In contrast to
the high precision of the position measurements by the optical encoders, the
measurement of velocities by the described methods may be quite mediocre in
accuracy, speciﬁcally for certain intervals of velocity. On certain occasions this
may have as a consequence, an unacceptable degradation of the performance
of the control system.
The interest in using controllers for robots that do not explicitly require
the measurement of velocity, is twofold. First, it is inadequate to feed back a
velocity measurement which is possibly of poor quality for certain bands of
operation. Second, avoiding the use of velocity measurements removes the need
for velocity sensors such as tachometers and therefore, leads to a reduction in
production cost while making the robot lighter.
The design of controllers that do not require velocity measurements to
control robot manipulators has been a topic of investigation since broached
in the decade of the 1990s and to date, many questions remain open. The
common idea in the design of such controllers has been to propose state ob-
servers to estimate the velocity. Then the so-obtained velocity estimations are
incorporated in the controller by replacing the true unavailable velocities. In
this way, it has been shown that asymptotic and even exponential stability
can be achieved, at least locally. Some important references on this topic are
presented at the end of the chapter.
In this chapter we present an alternative to the design of observers to
estimate velocity and which is of utility in position control. The idea consists
simply in substituting the velocity measurement ˙q, by the ﬁltered position

292
P“D” Control
q through a ﬁrst-order system of zero relative degree, and whose output is
denoted in the sequel, by ϑ.
Speciﬁcally, denoting by p the diﬀerential operator, i.e. p =
d
dt, the com-
ponents of ϑ ∈IRn are given by
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
ϑ1
ϑ2
...
ϑn
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
b1p
p + a1
0
· · ·
0
0
b2p
p + a2
· · ·
0
...
...
...
...
0
0
· · ·
bnp
p + an
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
q1
q2
...
qn
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
(13.1)
or in compact form,
ϑ = diag
 bip
p + ai
&
q
where ai and bi are strictly positive real constants but otherwise arbitrary, for
i = 1, 2, · · · , n.
A state-space representation of Equation (13.1) is
˙x = −Ax −ABq
ϑ = x + Bq
where x ∈IRn represents the state vector of the ﬁlters, A = diag{ai} and
B = diag{bi}.
In this chapter we study the proposed modiﬁcation for the following con-
trollers:
•
PD control with gravity compensation and
•
PD control with desired gravity compensation.
Obviously, the derivative part of both control laws is no longer proportional
to the derivative of the position error ˜q; this motivates the quotes around “D”
in the names of the controllers. As in other chapters appropriate references
are presented at the end of the chapter.
13.1 P“D” Control with Gravity Compensation
The PD control law with gravity compensation (7.1) requires, in its derivative
part, measurement of the joint velocity ˙q with the purpose of computing the
velocity error ˙˜q = ˙qd −˙q, and to use the latter in the term Kv ˙˜q. Even in the
case of position control, that is, when the desired joint position qd is constant,
the measurement of the velocity is needed by the term Kv ˙q.

13.1 P“D” Control with Gravity Compensation
293
A possible modiﬁcation to the PD control law with gravity compensation
consists in replacing the derivative part (D), which is proportional to the
derivative of the position error, i.e. to the velocity error ˙˜q = ˙qd −˙q, by a
term proportional to
˙qd −ϑ
where ϑ ∈IRn is, as said above, the result of ﬁltering the position q by means
of a dynamic system of ﬁrst-order and of zero relative degree.
Speciﬁcally, the P“D” control law with gravity compensation is written as
τ = Kp˜q + Kv [ ˙qd −ϑ] + g(q)
(13.2)
˙x = −Ax −ABq
ϑ = x + Bq
(13.3)
where Kp, Kv ∈IRn×n are diagonal positive deﬁnite matrices, A = diag{ai}
and B = diag{bi} and ai and bi are real strictly positive constants but other-
wise arbitrary for i = 1, 2, · · · , n.
Figure 13.1 shows the block-diagram corresponding to the robot under
P“D” control with gravity compensation. Notice that the measurement of the
joint velocity ˙q is not required by the controller.
Σ
Σ
Σ
Σ
ROBOT
g(q)
Kv
Kp
B
ϑ
˙qd
qd
τ
q
(pI+A)−1AB
Figure 13.1. Block-diagram: P“D” control with gravity compensation
Deﬁne ξ = x + Bqd. The equation that describes the behavior in closed
loop may be obtained by combining Equations (III.1) and (13.2)–(13.3), which
may be written in terms of the state vector

ξT
˜qT
˙qT T
as

294
P“D” Control
d
dt
⎡
⎢⎢⎢⎣
ξ
˜q
˙˜q
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
−Aξ + AB˜q + B ˙qd
˙˜q
¨qd −M(q)−1 [Kp˜q + Kv[ ˙qd −ξ + B˜q] −C(q, ˙q) ˙q]
⎤
⎥⎥⎥⎦.
A suﬃcient condition for the origin

ξT
˜qT
˙˜q
T T
= 0 ∈IR3n to be a
unique equilibrium point of the closed-loop equation is that the desired joint
position qd be a constant vector. In what is left of this section we assume that
this is the case. Notice that in this scenario, the control law may be expressed
as
τ = Kp˜q −Kvdiag
 bip
p + ai
&
q + g(q),
which is close to the PD with gravity compensation control law (7.1), when
the desired position qd is constant. Indeed the only diﬀerence is replacement
of the velocity ˙q by
diag
 bip
p + ai
&
q,
thereby avoiding the use of the velocity ˙q in the control law.
As we show in the following subsections, P“D” control with gravity com-
pensation meets the position control objective, that is,
lim
t→∞q(t) = qd
where qd ∈IRn is any constant vector.
Considering the desired position qd as constant, the closed-loop equation
may be rewritten in terms of the new state vector

ξT
˜qT
˙qT T
as
d
dt
⎡
⎢⎢⎢⎣
ξ
˜q
˙q
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
−Aξ + AB˜q
−˙q
M(qd −˜q)−1 [Kp˜q −Kv[ξ −B˜q] −C(qd −˜q, ˙q) ˙q]
⎤
⎥⎥⎥⎦
(13.4)
which, in view of the fact that qd is constant, constitutes an autonomous
diﬀerential equation. Moreover, the origin

ξT
˜qT
˙qT T
= 0 ∈IR3n is the
unique equilibrium of this equation.
With the aim of studying the stability of the origin, we consider the Lya-
punov function candidate
V (ξ, ˜q, ˙q) = K(q, ˙q) + 1
2 ˜qTKp˜q + 1
2(ξ −B˜q)T KvB−1 (ξ −B˜q)
(13.5)

13.1 P“D” Control with Gravity Compensation
295
where K(q, ˙q) = 1
2 ˙qTM(q) ˙q is the kinetic energy function corresponding to
the robot. Notice that the diagonal matrix KvB−1 is positive deﬁnite. Con-
sequently, the function V (ξ, ˜q, ˙q) is globally positive deﬁnite.
The total time derivative of the Lyapunov function candidate yields
˙V (ξ, ˜q, ˙q) = ˙qTM(q)¨q + 1
2 ˙qT ˙M(q) ˙q + ˜qTKp ˙˜q
+ [ξ −B˜q]T KvB−1 
˙ξ −B ˙˜q

.
Using the closed-loop Equation (13.4) to solve for ˙ξ, ˙˜q and M(q)¨q, and
canceling out some terms we obtain
˙V (ξ, ˜q, ˙q) = −[ξ −B˜q]T KvB−1A [ξ −B˜q]
= −
⎡
⎣
ξ
˜q
˙q
⎤
⎦
T ⎡
⎣
KvB−1A
−KvA
0
−KvA
BKvA
0
0
0
0
⎤
⎦
⎡
⎣
ξ
˜q
˙q
⎤
⎦
(13.6)
where we used
˙qT
1
2
˙M(q) −C(q, ˙q)

˙q = 0 ,
which follows from Property 4.2.
Clearly, the time derivative ˙V (ξ, ˜q, ˙q) of the Lyapunov function candidate
is globally negative semideﬁnite. Therefore, invoking Theorem 2.3, we con-
clude that the origin of the closed-loop Equation (13.4) is stable and that all
solutions are bounded.
Since the closed-loop Equation (13.4) is autonomous, La Salle’s Theorem
2.7 may be used in a straightforward way to analyze the global asymptotic
stability of the origin (cf. Problem 3 at the end of the chapter). Neverthe-
less, we present below, an alternative analysis that also allows one to show
global asymptotic stability of the origin of the state-space corresponding to
the closed-loop Equation, (13.4). This alternative method of proof, which is
longer than via La Salle’s theorem, is presented to familiarize the reader with
other methods to prove global asymptotic stability; however, we appeal to the
material on functional spaces presented in Appendix A.
According to Deﬁnition 2.6, since the origin

ξT
˜qT
˙qT T
= 0 ∈IR3n is a
stable equilibrium, then if

ξ(t)T
˜q(t)T
˙q(t)T T →0 ∈IR3n as t →∞(for all
initial conditions), the origin is a globally asymptotically stable equilibrium.
It is precisely this property that we show next.
In the development that follows we use additional properties of the dy-
namic model of robot manipulators. Speciﬁcally, assume that q, ˙q ∈Ln
∞.
Then,

296
P“D” Control
•
M(q)−1, d
dtM(q) ∈Ln×n
∞
•
C(q, ˙q) ˙q ∈Ln
∞.
If moreover ¨q ∈Ln
∞then,
•
d
dt [C(q, ˙q) ˙q] ∈Ln
∞.
The Lyapunov function V (ξ, ˜q, ˙q) given in (13.5) is positive deﬁnite since
it is composed of the following three non-negative terms:
•
1
2 ˙qTM(q) ˙q
•
1
2 ˜qTKp˜q
•
1
2[ξ −B˜q]T KvB−1 [ξ −B˜q] .
Since the time derivative ˙V (ξ, ˜q, ˙q) expressed in (13.6) is negative semidef-
inite, the Lyapunov function V (ξ, ˜q, ˙q) is bounded along the trajectories.
Therefore, the three non-negative terms above are also bounded along tra-
jectories. From this conclusion we have
˙q, ˜q, [ξ −B˜q] ∈Ln
∞.
(13.7)
Incorporating this information in the closed-loop system Equation (13.4),
and knowing that M(qd −˜q)−1 is bounded for all qd, ˜q ∈Ln
∞and also that
C(qd −˜q, ˙q) ˙q is bounded for all qd, ˜q, ˙q ∈Ln
∞, it follows that the time deriva-
tive of the state vector is also bounded, i.e.
˙ξ, ˙˜q, ¨q ∈Ln
∞,
(13.8)
and therefore,
˙ξ −B ˙˜q ∈Ln
∞.
(13.9)
Using again the closed-loop Equation (13.4), we obtain the second time
derivative of the state variables,
¨ξ = −A˙ξ + AB ˙˜q
¨˜q = −¨q
q(3) = −M(q)−1
 d
dtM(q)

M(q)−1 [Kp˜q −Kv [ξ −B˜q] −C(q, ˙q) ˙q]
+ M(q)−1

Kp ˙˜q −Kv

˙ξ −B ˙˜q

−d
dt [C(q, ˙q) ˙q]

where q(3) denotes the third time derivative of the joint position q and we
used

13.1 P“D” Control with Gravity Compensation
297
d
dt

M(q)−1
= −M(q)−1
 d
dtM(q)

M(q)−1 .
In (13.7) and (13.8) we have already concluded that ξ, ˜q, ˙q, ˙ξ, ˙˜q, ¨q ∈Ln
∞
then, from the properties stated at the beginning of this analysis, we obtain
¨ξ, ¨˜q, q(3) ∈Ln
∞,
(13.10)
and therefore,
¨ξ −B¨˜q ∈Ln
∞.
(13.11)
On the other hand, integrating both sides of (13.6) and using that
V (ξ, ˜q, ˙˜q) is bounded along the trajectories, we obtain
[ξ −B˜q] ∈Ln
2 .
(13.12)
Considering (13.9), (13.12) and Lemma A.5, we obtain
lim
t→∞[ξ(t) −B˜q(t)] = 0 .
(13.13)
Next, we invoke Lemma A.6 with f = ξ−B˜q. Using (13.13), (13.7), (13.9)
and (13.11), we get from this lemma
lim
t→∞

˙ξ(t) −B ˙˜q(t)

= 0 .
Consequently, using the closed-loop Equation (13.4) we get
lim
t→∞−A[ξ(t) −B˜q(t)] + B ˙q = 0 .
From this expression and (13.13) we obtain
lim
t→∞˙q(t) = 0 ∈IRn .
(13.14)
Now, we show that limt→∞˜q(t) = 0 ∈IRn. To that end, we consider again
Lemma A.6 with f = ˙q. Incorporating (13.14), (13.7), (13.8) and (13.10) we
get
lim
t→∞¨q(t) = 0 .
Taking this into account in the closed-loop Equation (13.4) as well as
(13.13) and (13.14), we get
lim
t→∞M(qd −˜q(t))−1Kp˜q(t) = 0 .
So we conclude that
lim
t→∞˜q(t) = 0 ∈IRn .
(13.15)

298
P“D” Control
The last part of the proof, that is, the proof of limt→∞ξ(t) = 0 follows
trivially from (13.13) and (13.15). Therefore, the origin is a globally attractive
equilibrium point.
This completes the proof of global asymptotic stability of the origin of the
closed-loop Equation (13.4).
We present next an example with the purpose of illustrating the perfor-
mance of the Pelican robot under P“D” control with gravity compensation.
As for all other examples on the Pelican robot, the results that we present are
from laboratory experimentation.
Example 13.1. Consider the Pelican robot studied in Chapter 5, and
depicted in Figure 5.2. The components of the vector of gravitational
torques g(q) are given by
g1(q) = (m1lc1 + m2l1)g sin(q1) + m2lc2g sin(q1 + q2)
g2(q) = m2lc2g sin(q1 + q2) .
Consider the P“D” control law with gravity compensation on this
robot for position control and where the design matrices Kp, Kv, A, B
are taken diagonal and positive deﬁnite. In particular, pick
Kp = diag{kp} = diag{30}
[Nm/rad] ,
Kv = diag{kv} = diag{7, 3}
[Nm s/rad] ,
A = diag{ai} = diag{30, 70}
[1/s] ,
B = diag{bi} = diag{30, 70}
[1/s] .
The components of the control input τ are given by
τ1 = kp˜q1 −kvϑ1 + g1(q)
τ2 = kp˜q2 −kvϑ2 + g2(q)
˙x1 = −a1x1 −a1b1q1
˙x2 = −a2x2 −a2b2q2
ϑ1 = x1 + b1q1
ϑ2 = x2 + b2q2 .
The initial conditions corresponding to the positions, velocities and
states of the ﬁlters, are chosen as
q1(0) = 0,
q2(0) = 0
˙q1(0) = 0,
˙q2(0) = 0
x1(0) = 0,
x2(0) = 0 .

13.1 P“D” Control with Gravity Compensation
299
0.0
0.5
1.0
1.5
2.0
−0.1
0.0
0.1
0.2
0.3
0.4
[rad]
˜q1
0.0587
0.0151
˜q2
t [s]
.........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 13.2. Graphs of position errors ˜q1(t) and ˜q2(t)
The desired joint positions are chosen as
qd1 = π/10, qd2 = π/30 [rad] .
In terms of the state vector of the closed-loop equation, the initial
state is
⎡
⎢⎢⎢⎢⎢⎢⎣
ξ(0)
˜q(0)
˙q(0)
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
b1π/10
b2π/30
π/10
π/30
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
9.423
7.329
0.3141
0.1047
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
.
Figure 13.2 presents the experimental results and shows that the
components of the position error ˜q(t) tend asymptotically to a small
nonzero constant. Although we expected that the error would tend
to zero, the experimental behavior is mainly due to the presence of
unmodeled friction at the joints.
♦
In a real implementation of a controller on an ordinary personal computer
(as is the case of Example 13.1) typically the joint position q is sampled
periodically by optical encoders and this is used to compute the joint velocity
˙q. Indeed, if we denote by h the sampling period, the joint velocity at the
instant kh is obtained as
˙q(kh) = q(kh) −q(kh −h)
h
,
that is, the diﬀerential operator p = d
dt is replaced by (1 −z−1)/h, where z−1
is the delay operator that is, z−1q(kh) = q(kh −h). By the same argument,

300
P“D” Control
in the implementation of the P“D” control law with gravity compensation,
(13.2)–(13.3), the variable ϑ at instant kh may be computed as
ϑ(kh) = q(kh) −q(kh −h)
h
+ 1
2ϑ(kh −h)
where we chose A = diag{ai} = diag{h−1} and B = diag{bi} = diag{2/h}.
13.2 P“D” Control with Desired Gravity Compensation
In this section we present a modiﬁcation of PD control with desired gravity
compensation, studied in Chapter 7, and whose characteristic is that it does
not require the velocity term ˙q in its control law. The original references on
this controller are cited at the end of the chapter.
This controller, that we call here P“D” control with desired gravity com-
pensation, is described by
τ = Kp˜q + Kv [ ˙qd −ϑ] + g(qd)
(13.16)
˙x = −Ax −ABq
ϑ = x + Bq
(13.17)
where Kp, Kv ∈IRn×n are diagonal positive deﬁnite matrices, A = diag{ai}
and B = diag{bi} with ai and bi real strictly positive constants but otherwise
arbitrary for all i = 1, 2, · · · , n.
Figure 13.3 shows the block-diagram of the P“D” control with desired
gravity compensation applied to robots. Notice that the measurement of the
joint velocity ˙q is not required by the controller.
(pI+A)−1AB
Σ
Σ
Σ
Σ
g(qd)
ROBOT
B
ϑ
τ
q
Kp
Kv
qd
˙qd
Figure 13.3. Block-diagram: P“D” control with desired gravity compensation

13.2 P“D” Control with Desired Gravity Compensation
301
Comparing P“D” control with gravity compensation given by (13.2)–(13.3)
with P“D” control with desired gravity compensation (13.16)–(13.17), we im-
mediately notice the replacement of the term g(q) by the feedforward term
g(qd).
The analysis of the control system in closed loop is similar to that from
Section 13.1. The most noticeable diﬀerence is in the Lyapunov function con-
sidered for the proof of stability. Given the relative importance of the controller
(13.16)–(13.17), we present next its complete study.
Deﬁne ξ = x + Bqd. The equation that describes the behavior in closed
loop is obtained by combining Equations (III.1) and (13.16)–(13.17), which
may be expressed in terms of the state vector

ξT
˜qT
˙qT T
as
d
dt
⎡
⎢⎢⎢⎣
ξ
˜q
˙˜q
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
−Aξ + AB˜q + B ˙qd
˙˜q
¨qd−M(q)−1[Kp˜q+Kv[ ˙qd−ξ+B˜q]+g(qd)−C(q, ˙q) ˙q−g(q)]
⎤
⎥⎥⎥⎦
A suﬃcient condition for the origin

ξT
˜qT
˙˜q
T T
= 0 ∈IR3n to be a
unique equilibrium of the closed-loop equation is that the desired joint position
qd is a constant vector. In what follows of this section we assume that this is
the case. Notice that in this scenario, the control law may be expressed by
τ = Kp˜q −Kvdiag
 bip
p + ai
&
q + g(qd),
which is very close to PD with desired gravity compensation control law (8.1)
when the desired position qd is constant. The only diﬀerence is the substitution
of the velocity term ˙q by
ϑ = diag
 bip
p + ai
&
q,
thereby avoiding the use of velocity measurements ˙q(t) in the control law.
As we show below, if the matrix Kp is chosen so that
λmin{Kp} > kg ,
then the P“D” controller with desired gravity compensation veriﬁes the posi-
tion control objective, that is,
lim
t→∞q(t) = qd
for any constant vector qd ∈IRn.

302
P“D” Control
Considering the desired position qd to be constant, the closed-loop equa-
tion may then be written in terms of the new state vector

ξT
˜qT
˙qT T
as
d
dt
⎡
⎢⎢⎢⎣
ξ
˜q
˙q
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
−Aξ + AB˜q
−˙q
M(q)−1 [Kp˜q−Kv[ξ−B˜q]+g(qd)−C(qd−˜q, ˙q) ˙q−g(qd−˜q)]
⎤
⎥⎥⎥⎦
(13.18)
which, since qd is constant, is an autonomous diﬀerential equation. Since
the matrix Kp has been picked so that λmin{Kp} > kg, then the origin

ξT
˜qT
˙qT T
= 0 ∈IR3n is the unique equilibrium of this equation (see
the arguments in Section 8.2).
In order to study the stability of the origin, consider the Lyapunov function
candidate
V (ξ, ˜q, ˙q) = K(qd −˜q, ˙q) + f(˜q) + 1
2(ξ −B˜q)T KvB−1 (ξ −B˜q)
(13.19)
where
K(qd −˜q, ˙q) = 1
2 ˙qT M(qd −˜q) ˙q
f(˜q) = U(qd −˜q) −U(qd) + g(qd)T ˜q + 1
2 ˜qTKp˜q .
Notice ﬁrst that the diagonal matrix KvB−1 is positive deﬁnite. Since it
has been assumed that λmin{Kp} > kg, we have from Lemma 8.1 that f(˜q) is a
(globally) positive deﬁnite function of ˜q. Consequently, the function V (ξ, ˜q, ˙q)
is also globally positive deﬁnite.
The time derivative of the Lyapunov function candidate yields
˙V (ξ, ˜q, ˙q) = ˙qTM(q)¨q + 1
2 ˙qT ˙M(q) ˙q −˙˜q
T g(qd −˜q) + g(qd)T ˙˜q
+ ˜qTKp ˙˜q + [ξ −B˜q]T KvB−1 
˙ξ −B ˙˜q

.
Using the closed-loop Equation (13.18) to solve for ˙ξ, ˙˜q and M(q)¨q, and
canceling out some terms, we obtain
˙V (ξ, ˜q, ˙q) = −(ξ −B˜q)T KvB−1A (ξ −B˜q)
= −
⎡
⎣
ξ
˜q
˙q
⎤
⎦
T ⎡
⎣
KvB−1A
−KvA
0
−KvA
BKvA
0
0
0
0
⎤
⎦
⎡
⎣
ξ
˜q
˙q
⎤
⎦
(13.20)
where we used (cf. Property 4.2)

13.2 P“D” Control with Desired Gravity Compensation
303
˙qT
1
2
˙M(q) −C(q, ˙q)

˙q = 0 .
Clearly, the time derivative ˙V (ξ, ˜q, ˙q) of the Lyapunov function candidate
is a globally semideﬁnite negative function. For this reason, according to the
Theorem 2.3, the origin of the closed-loop Equation (13.18) is stable.
Since the closed-loop Equation (13.18) is autonomous, direct application
of La Salle’s Theorem 2.7 allows one to guarantee global asymptotic stability
of the origin corresponding to the state space of the closed-loop system (cf.
Problem 4 at the end of the chapter). Nevertheless, an alternative analysis,
similar to that presented in Section 13.1, may also be carried out.
Since the origin

ξT
˜qT
˙qT T
= 0 ∈IR3n is a stable equilibrium, then
if

ξ(t)T
˜q(t)T
˙q(t)T T →0 ∈IR3n when t →∞(for all initial conditions),
i.e. the equilibrium is globally attractive, then the origin is a globally asymp-
totically stable equilibrium. It is precisely this property that we show next.
In the development below we invoke further properties of the dynamic
model of robot manipulators. Speciﬁcally, assuming that q, ˙q ∈Ln
∞we have
•
M(q)−1, d
dtM(q) ∈Ln×n
∞
•
C(q, ˙q) ˙q, g(q), d
dtg(q) ∈Ln
∞.
The latter follows from the regularity of the functions that deﬁne M, g and
C. By the same reasoning, if moreover ¨q ∈Ln
∞then
•
d
dt [C(q, ˙q) ˙q] ∈Ln
∞.
The Lyapunov function V (ξ, ˜q, ˙q) given in (13.19) is positive deﬁnite and
is composed of the sum of the following three non-negative terms
•
1
2 ˙qTM(q) ˙q
•
U(qd −˜q) −U(qd) + g(qd)T ˜q + 1
2 ˜qTKp˜q
•
1
2(ξ −B˜q)T KvB−1 (ξ −B˜q) .
Since the time derivative
˙V (ξ, ˜q, ˙q), expressed in (13.6) is a negative
semideﬁnite function, the Lyapunov function V (ξ, ˜q, ˙q) is bounded along
trajectories. Therefore, the three non-negative listed terms above are also
bounded along trajectories. Since, moreover, the potential energy U(q) of
robots having only revolute joints is always bounded in its absolute value, it
follows that
˙q, ˜q, ξ, ξ −B˜q ∈Ln
∞.
(13.21)
Incorporating this information in the closed-loop Equation (13.18), and
knowing that M(qd −˜q)−1 and g(qd −˜q) are bounded for all qd, ˜q ∈Ln
∞and

304
P“D” Control
also that C(qd −˜q, ˙q) ˙q is bounded for all qd, ˜q, ˙q ∈Ln
∞, it follows that the
time derivative of the state vector is bounded, i.e.
˙ξ, ˙˜q, ¨q ∈Ln
∞,
(13.22)
and therefore, it is also true that

˙ξ −B ˙˜q

∈Ln
∞.
(13.23)
Using again the closed-loop Equation (13.18), we can compute the second
time derivative of the variables state to obtain
¨ξ = −A˙ξ + AB ˙˜q
¨˜q = −¨q
q(3) = −M(q)−1
 d
dtM(q)

M(q)−1 [Kp˜q −Kv [ξ −B˜q] −C(q, ˙q) ˙q
+g(qd) −g(q)]
+ M(q)−1

Kp ˙˜q −Kv
+
˙ξ −B ˙˜q
,
−d
dt (C(q, ˙q) ˙q) + d
dtg(q)

where q(3) denotes the third time derivative of the joint position q and we
used
d
dt

M(q)−1
= −M(q)−1
 d
dtM(q)

M(q)−1 .
In (13.21) and (13.22) we concluded that ξ, ˜q, ˙q, ˙ξ, ˙˜q, ¨q ∈Ln
∞then, from
the properties stated at the beginning of this analysis, we obtain
¨ξ, ¨˜q, q(3) ∈Ln
∞,
(13.24)
and therefore also
¨ξ −B¨˜q ∈Ln
∞.
(13.25)
On the other hand, from the time derivative
˙V (ξ, ˜q, ˙q), expressed in
(13.20), we get
ξ −B˜q ∈Ln
2 .
(13.26)
Considering next (13.23), (13.26) and Lemma A.5, we conclude that
lim
t→∞ξ(t) −B˜q(t) = 0 .
(13.27)
Hence, using (13.27), (13.21), (13.23) and (13.25) together with Lemma
A.6 we get
lim
t→∞
˙ξ(t) −B ˙˜q(t) = 0

13.2 P“D” Control with Desired Gravity Compensation
305
and consequently, taking ˙ξ and ˙˜q from the closed-loop Equation (13.18), we
get
lim
t→∞−A[ξ(t) −B˜q(t)] + B ˙q = 0 .
From this last expression and since we showed in (13.27) that limt→∞ξ(t)−
B˜q(t) = 0 it ﬁnally follows that
lim
t→∞˙q(t) = 0 .
(13.28)
We show next that limt→∞˜q(t) = 0 ∈IRn. Using again Lemma A.6 with
(13.28), (13.21), (13.22) and (13.24) we have
lim
t→∞¨q(t) = 0 .
Taking this into account in the closed-loop Equation (13.18) as well as
(13.27) and (13.28), we get
lim
t→∞M(qd −˜q(t))−1 [Kp˜q(t) + g(qd) −g(qd −˜q(t))] = 0
and therefore, since λmin{Kp} > kg we ﬁnally obtain from the methodology
presented in Section 8.2,
lim
t→∞˜q(t) = 0 .
(13.29)
The rest of the proof, that is that limt→∞ξ(t) = 0, follows directly from
(13.27) and (13.29).
This completes the proof of global attractivity of the origin and, since we
have already shown that the origin is Lyapunov stable, of global asymptotic
stability of the origin of the closed-loop Equation (13.18).
We present next an example that demonstrates the performance that may
be achieved with P“D” control with gravity compensation in particular, on
the Pelican robot.
Example 13.2. Consider the Pelican robot presented in Chapter 5 and
depicted in Figure 5.2. The components of the vector of gravitational
torques g(q) are given by
g1(q) = (m1lc1 + m2l1)g sin(q1) + m2lc2g sin(q1 + q2)
g2(q) = m2lc2g sin(q1 + q2) .
According to Property 4.3, the constant kg may be obtained as (see
also Example 9.2):

306
P“D” Control
kg = n

max i,j,q

∂gi(q)
∂qj


= n((m1lc1 + m2l1)g + m2lc2g)
= 23.94

kg m2/s2
.
Consider the P“D” control with desired gravity compensation for
this robot in position control. Let the design matrices Kp, KvA, B be
diagonal and positive deﬁnite and satisfy
λmin{Kp} > kg .
In particular, these matrices are taken to be
Kp = diag{kp} = diag{30}
[Nm/rad] ,
Kv = diag{kv} = diag{7, 3}
[Nm s/rad] ,
A = diag{ai} = diag{30, 70}
[1/s] ,
B = diag{bi} = diag{30, 70}
[1/s] .
The components of the control input τ are given by
τ1 = kp˜q1 −kvϑ1 + g1(qd)
τ2 = kp˜q2 −kvϑ2 + g2(qd)
˙x1 = −a1x1 −a1b1q1
˙x2 = −a2x2 −a2b2q2
ϑ1 = x1 + b1q1
ϑ2 = x2 + b2q2 .
The initial conditions corresponding to the positions, velocities and
states of the ﬁlters, are chosen as
q1(0) = 0,
q2(0) = 0
˙q1(0) = 0,
˙q2(0) = 0
x1(0) = 0,
x2(0) = 0 .
The desired joint positions are
qd1 = π/10,
qd2 = π/30 [rad] .
In terms of the state vector of the closed-loop equation, the initial
state is
⎡
⎢⎢⎢⎢⎢⎢⎣
ξ(0)
˜q(0)
˙q(0)
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
b1π/10
b2π/30
π/10
π/30
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
9.423
7.329
0.3141
0.1047
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
.

13.3 Conclusions
307
0.0
0.5
1.0
1.5
2.0
−0.1
0.0
0.1
0.2
0.3
0.4
[rad]
˜q1
0.0368
0.0145
˜q2
t [s]
...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 13.4. Graphs of position errors ˜q1(t) and ˜q2(t)
Figure 13.4 shows the experimental results; again, as in the previ-
ous controller, it shows that the components of the position error ˜q(t)
tend asymptotically to a small constant nonzero value due, mainly, to
the friction eﬀects in the prototype.
♦
13.3 Conclusions
We may summarize the material of this chapter in the following remarks.
Consider the P“D” control with gravity compensation for n-DOF robots.
Assume that the desired position qd is constant.
•
If the matrices Kp, Kv, A and B of the controller P“D” with gravity
compensation are diagonal positive deﬁnite, then the origin of the closed-
loop equation expressed in terms of the state vector

ξT
˜qT
˙qT T
, is a
globally asymptotically stable equilibrium . Consequently, for any initial
condition q(0), ˙q(0) ∈IRn, we have limt→∞˜q(t) = 0 ∈IRn.
Consider the P“D” control with desired gravity compensation for n-DOF
robots. Assume that the desired position qd is constant.
•
If the matrices Kp, Kv, A and B of the controller P“D” with desired
gravity compensation are taken diagonal positive deﬁnite, and such that
λmin{Kp} > kg, then the origin of the closed-loop equation, expressed
in terms of the state vector

ξT
˜qT
˙qT T
is globally asymptotically
stable. In particular, for any initial condition q(0), ˙q(0) ∈IRn, we have
limt→∞˜q(t) = 0 ∈IRn.

308
P“D” Control
Bibliography
Studies of motion control for robot manipulators without the requirement of
velocity measurements, started at the beginning of the 1990s. Some of the
early related references are the following:
•
Nicosia S., Tomei P., 1990, “Robot control by using joint position mea-
surements”, IEEE Transactions on Automatic Control, Vol. 35, No. 9,
September.
•
Berghuis H., L¨ohnberg P., Nijmeijer H., 1991, “Tracking control of robots
using only position measurements”, Proceedings of IEEE Conference on
Decision and Control, Brighton, England, December, pp. 1049–1050.
•
Canudas C., Fixot N., 1991, “Robot control via estimated state feedback”,
IEEE Transactions on Automatic Control, Vol. 36, No. 12, December.
•
Canudas C., Fixot N., ˚Astr¨om K. J., 1992, “Trajectory tracking in robot
manipulators via nonlinear estimated state feedback”, IEEE Transactions
on Robotics and Automation, Vol. 8, No. 1, February.
•
Ailon A., Ortega R., 1993, “An observer-based set-point controller for robot
manipulators with ﬂexible joints”, Systems and Control Letters, Vol. 21,
October, pp. 329–335.
The motion control problem for a time-varying trajectory qd(t) without ve-
locity measurements, with a rigorous proof of global asymptotic stability of
the origin of the closed-loop system, was ﬁrst solved for one-degree-of-freedom
robots (including a term that is quadratic in the velocities) in
•
Lor´ıa A., 1996, “Global tracking control of one degree of freedom Euler-
Lagrange systems without velocity measurements”, European Journal of
Control, Vol. 2, No. 2, June.
This result was extended to the case of n-DOF robots in
•
Zergeroglu E., Dawson, D. M., Queiroz M. S. de, Krsti´c M., 2000, “On
global output feedback tracking control of robot manipulators”, in Proceed-
ings of Conferenece on Decision and Control, Sydney, Australia, pp. 5073–
5078.
The controller called here, P“D” with gravity compensation and charac-
terized by Equations (13.2)–(13.3) was independently proposed in
•
Kelly R., 1993, “A simple set–point robot controller by using only position
measurements”, 12th IFAC World Congress, Vol. 6, Sydney, Australia,
July, pp. 173–176.
•
Berghuis H., Nijmeijer H., 1993, “Global regulation of robots using only
position measurements”, Systems and Control Letters, Vol. 21, October,
pp. 289–293.

Problems
309
The controller called here, P“D” with desired gravity compensation and
characterized by Equations (13.16)–(13.17) was independently proposed in
the latter two references; the formal proof of global asymptotic stability was
presented in the second.
Problems
1. Consider the following variant of the controller P“D” with gravity com-
pensation1:
τ = Kp˜q + Kvϑ + g(q)
˙x = −Ax −AB˜q
ϑ = x + B˜q
where Kp, Kv ∈IRn×n are diagonal positive deﬁnite matrices, A =
diag{ai} and B = diag{bi} with ai, bi real strictly positive numbers.
Assume that the desired joint position qd ∈IRn is constant.
a) Obtain the closed-loop equation expressed in terms of the state vector

xT
˜qT
˙qT T .
b) Verify that the vector
⎡
⎣
x
˜q
˙q
⎤
⎦=
⎡
⎣
0
0
0
⎤
⎦∈IR3n
is the unique equilibrium of the closed-loop equation.
c) Show that the origin of the closed-loop equation is a stable equilibrium
point.
Hint: Use the following Lyapunov function candidate2:
V (x, ˜q, ˙q) = 1
2 ˙qTM(q) ˙q + 1
2 ˜qTKp˜q
+ 1
2 (x + B˜q)T KvB−1 (x + B˜q) .
2. Consider the model of robots with elastic joints (3.27) and (3.28),
1 This controller was analyzed in Berghuis H., Nijmeijer H., 1993, “Global regulation
of robots using only position measurements”, Systems and Control Letters, Vol.
21, October, pp. 289–293.
2 By virtue of La Salle’s Theorem it may also be proved that the origin is globally
asymptotically stable.

310
P“D” Control
M(q)¨q + C(q, ˙q) ˙q + g(q) + K(q −θ) = 0
J¨θ −K(q −θ) = τ .
It is assumed that only the vector of positions θ of motors axes, but not
the velocities vector ˙θ, is measured. We require that q(t) →qd, where qd
is constant.
A variant of the P“D” control with desired gravity compensation is3
τ = Kp˜θ −Kvϑ + g(qd)
˙x = −Ax −ABθ
ϑ = x + Bθ
where
˜θ = qd −θ + K−1g(qd)
˜q = qd −q
and Kp, Kv, A, B ∈IRn×n are diagonal positive deﬁnite matrices.
a) Verify that the closed-loop equation in terms of the state vector

ξT
˜qT
˜θ
T
˙qT
˙θ
T T
may be written as
d
dt
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
ξ
˜q
˜θ
˙q
˙θ
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
−Aξ + AB˜θ
−˙q
−˙θ
M(q)−1
−K(˜θ −˜q) + g(qd) −C(q, ˙q) ˙q −g(q)

J−1 
Kp˜θ −Kv(ξ −B˜θ) + K(˜θ −˜q)

⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
where ξ = x + B

qd + K−1g(qd)

.
b) Verify that the origin is an equilibrium of the closed-loop equation.
c) Show that if λmin{Kp} > kg and λmin{K} > kg, then the origin is a
stable equilibrium point.
Hint: Use the following Lyapunov function and La Salle’s Theorem
2.7.
3 This controller was proposed and analyzed in Kelly R., Ortega R., Ailon A.,
Loria A., 1994, “Global regulation of ﬂexible joint robots using approximate dif-
ferentiation”, IEEE Transactions on Automatic Control, Vol. 39, No. 6, June, pp.
1222–1224.

Problems
311
V (˜q, ˜θ, ˙q, ˙θ) = V1(˜q, ˜θ, ˙q, ˙θ) + 1
2 ˜qTK˜q + V2(˜q)
+ 1
2

ξ −B˜θ
T
KvB−1 
ξ −B˜θ

where
V1(˜q, ˜θ, ˙q, ˙θ) = 1
2 ˙qT M(q) ˙q + 1
2
˙θ
T J ˙θ + 1
2
˜θ
T Kp˜θ
+ 1
2
˜θ
T K˜θ −˜θ
T K˜q
V2(˜q) = U(qd −˜q) −U(qd) + ˜qT g(qd)
and verify that
˙V (˜q, ˜θ, ˙q, ˙θ) = −

ξ −B˜θ
T
KvB−1A

ξ −B˜θ

.
3. Use La Salle’s Theorem 2.7 to show global asymptotic stability of the
origin of the closed-loop equations corresponding to the P“D” controller
with gravity compensation, i.e. Equation (13.4).
4. Use La Salle’s Theorem 2.7 to show global asymptotic stability of the
origin of the closed-loop equations corresponding to the P“D” controller
with desired gravity compensation, i.e. Equation (13.18).

14
Introduction to Adaptive Robot Control
Up to this chapter we have studied several control techniques which achieve
the objective of position and motion control of manipulators. The standing
implicit assumptions in the preceding chapters are that:
•
The model is accurately known, i.e. either all the nonlinearities involved
are known or they are negligible.
•
The constant physical parameters such as link inertias, masses, lengths to
the centers of mass and even the masses of the diverse objects which may
be handled by the end-eﬀector of the robot, are accurately known.
Obviously, while these considerations allow one to prove certain stability
and convergence properties for the controllers studied in previous chapters,
they must be taken with care. In robot control practice, either of these assump-
tions or both, may not hold. For instance, we may be neglecting considerable
joint elasticity, friction or, even if we think we know accurately the masses
and inertias of the robot, we cannot estimate the mass of the objects carried
by the end-eﬀector, which depend on the task accomplished.
Two general techniques in control theory and practice deal with these
phenomena, respectively: robust control and adaptive control. Roughly, the
ﬁrst aims at controlling, with a small error, a class of robot manipulators
with the same robust controller. That is, given a robot manipulator model,
one designs a control law which achieves the motion control objective, with a
small error, for the given model but to which is added a known nonlinearity.
Adaptive control is a design approach tailored for high performance ap-
plications in control systems with uncertainty in the parameters. That is,
uncertainty in the dynamic system is assumed to be characterized by a set
of unknown constant parameters. However, the design of adaptive controllers
requires the precise knowledge of the structure of the system being controlled.

314
14 Introduction to Adaptive Robot Control
Certainly one may consider other variants such as adaptive control for
systems with time-varying parameters, or robust adaptive control for systems
with structural and parameter uncertainty.
In this and the following chapters we concentrate speciﬁcally on adaptive
control of robot manipulators with constant parameters and for which we
assume that we have no structural uncertainties. In this chapter we present
an introduction to adaptive control of manipulators. In subsequent chapters
we describe and analyze two adaptive controllers for robots. They correspond
to the adaptive versions of
•
PD control with adaptive desired gravity compensation,
•
PD control with adaptive compensation.
14.1 Parameterization of the Dynamic Model
The dynamic model of robot manipulators1, as we know, is given by La-
grange’s equations, which we repeat here in their compact form:
M(q)¨q + C(q, ˙q) ˙q + g(q) = τ .
(14.1)
In previous chapters we have not emphasized the fact that the elements of the
inertia matrix M(q), the centrifugal and Coriolis forces matrix C(q, ˙q) and the
vector of gravitational torques g(q), depend not only on the geometry of the
corresponding robot but also on the numerical values of diverse parameters
such as masses, inertias and distances to centers of mass.
The scenario in which these parameters and the geometry of the robot are
exactly known is called in the context of adaptive control, the ideal case. A
more realistic scenario is usually that in which the numerical values of some
parameters of the robot are unknown. Such is the case, for instance, when the
object manipulated by the end-eﬀector of the robot (which may be considered
as part of the last link) is of uncertain mass and/or inertia. The consequence
in this situation cannot be overestimated; due to the uncertainty in some of
the parameters of the robot model it is impossible to use the model-based
control laws from any of the previous chapters since they rely on an accurate
knowledge of the dynamic model. The adaptive controllers are useful precisely
in this more realistic case.
To emphasize the dependence of the dynamic model on the dynamic pa-
rameters, from now on we write the dynamic model (14.1) explicitly as a
function of the vector of unknown dynamic parameters, θ, that is2,
1 Under the ideal conditions of rigid links, no elasticity at joints, no friction and
having actuators with negligible dynamics.
2 In this textbook we have used   to denote the joint positions of the motor shafts
for models of robots with elastic joints. With an abuse of notation, in this and the

14.1 Parameterization of the Dynamic Model
315
M(q, θ)¨q + C(q, ˙q, θ) ˙q + g(q, θ) = τ .
(14.2)
The vector of parameters θ may be of any dimension, that is, it does not
depend in any speciﬁc way on the number of degrees of freedom or on whether
the robot has revolute or prismatic joints etc. Notwithstanding, an upper-
bound on the dimension is determined by the number of degrees of freedom.
Therefore, we simply say that θ ∈IRm where m is some known constant. It is
also important to stress that the dynamic parameters, denoted here by θ, do
not necessarily correspond to the individual physical parameters of the robot,
as is illustrated in the following example.
Example 14.1. Consider the example of an ideal pendulum with its
mass m concentrated at the tip, at a distance l from its axis of rotation.
Its dynamic model is given by
ml2¨q + mgl sin(q) = τ
(14.3)
hence, compared to (14.2) we identify M(q, θ) = ml2, g(q, θ) =
mgl sin(q). Hence, assuming that both the mass m and the length
from the joint axis to the center of mass l, are unknown, we identify
the vector of dynamic parameters as
θ =

ml2
mgl

,
which is, strictly speaking, a nonlinear vectorial function of the phys-
ical parameters m and l, since θ depends on products of them.
♦
Note that here, the number of dynamic parameters coincides with the
number of physical parameters, however, this is in general not the case as is
clear from the examples below.
14.1.1 Linearity in the Dynamic Parameters
Example 14.1 also shows that the dynamic model (14.3) is linear in the pa-
rameters θ. To see this more clearly, notice that we may write
ml2¨q + mgl sin(q) = [¨q
sin(q)]

ml2
mgl

=: Φ(q, ¨q)θ .
other chapters on adaptive control, the symbol   denotes the vector of dynamic
parameters.

316
14 Introduction to Adaptive Robot Control
That is, the dynamic model (14.3) with zero input (τ = 0), can be rewritten as
the product of a vector function Φ which contains nonlinear terms of the state
(the generalized coordinates and its derivatives) and the vector of dynamic
parameters, θ.
This property is commonly known as “linearity in the parameters” or “lin-
ear parameterization”. It is a property possessed by many nonlinear systems
and, in particular, by a fairly large class of robot manipulators. It is also
our standing hypothesis for the subsequent chapters hence, we enunciate it
formally below.
Property 14.1. Linearity in the dynamic parameters.
For the matrices M(q, θ), C(q, ˙q, θ) and the vector g(q, θ) from the dynamic
model (14.2), we have the following.
1.
For all u, v, w ∈IRn it holds that
M(q, θ)u + C(q, w, θ)v + g(q, θ) = Φ(q, u, v, w)θ + κ(q, u, v, w)
(14.4)
where κ(q, u, v, w) is a vector of n × 1, Φ(q, u, v, w) is a matrix
of n × m and the vector θ ∈IRm depends only on the dynamic
parameters of the manipulator and its load.
2.
Moreover3, if q, u, v, w ∈Ln
∞then Φ(q, u, v, w) ∈Ln×m
∞
.
It is worth remarking that one may always ﬁnd a vector θ ∈IRm for which
κ(q, u, v, w) ≡0 ∈IRn. With this under consideration, setting u = ¨q,
v = w = ˙q, on occasions it appears useful to rewrite Equation (14.4) in
the simpliﬁed form
Y (q, ˙q, ¨q)θ = M(q, θ)¨q + C(q, ˙q, θ) ˙q + g(q, θ)
(14.5)
where Y (q, ˙q, ¨q) = Φ(q, ¨q, ˙q, ˙q) is a matrix of dimension n × m and θ is a
vector of dimension m × 1 which contains m constants that depend on the
dynamic parameters. The constant n is clearly the number of DOF and m
depends on the selection of the dynamic parameters of the robot.
Notice that Property 14.1 is stated in fair generality, i.e. it is not assumed,
as for many other properties stated in Chapter 4, that the robot must have
only revolute joints.
It is also important to underline, and it must be clear from Example 14.1,
that the dynamic model of the robot is not necessarily linear in terms of the
3 We remind the student reader that the notation L∞is described in detail in
Appendix A which is left as self-study.

14.1 Parameterization of the Dynamic Model
317
masses, inertias and distances of the centers of mass of the links but rather, it
is linear in terms of the dynamic parameters θ which in general, are nonlinear
functions of the physical parameters. Therefore, given a selection of masses,
inertias and distances to the centers of mass (of all the links), called here
‘parameters of interest’, the dynamic parameters are obtained from the robot
model according to (14.4).
In general, the relation between the parameters of interest and the dy-
namic parameters is not available in a simple manner, but by developing
(14.4) explicitly and using the fact that the matrix Φ(q, u, v, w) as well as
the vector κ(q, u, v, w), do not depend on the dynamic parameters θ. This
methodology is illustrated below through several examples; the procedure to
determine the dynamic parameters may be too elaborate for robots with a
large number of degrees of freedom. However, procedures to characterize the
dynamic parameters are available.
Example 14.2. The right-hand side of the dynamic model of the device
studied in Example 3.2, that is, of Equation (3.5),
m2l2
2cos2(ϕ)¨q = τ
may be expressed in the form (14.5) where
Y (q, ˙q, ¨q) = l2
2cos2(ϕ)¨q
θ = m2 .
♦
The following example shows that, as expected, the model of the Pelican
prototype of Chapter 5 satisﬁes the linear parameterization property. This is
used extensively later to design adaptive control schemes for this prototype
in succeeding examples.
Example 14.3. Consider the Pelican manipulator moving on a vertical
plane under the action of gravity as depicted in Figure 5.2. For sim-
plicity, the manipulator is assumed to have two rigid links of unitary
length (l1 = l2 = 1) and masses m1 and m2 concentrated at the ends
of the links (lc1 = lc2 = 1, and I1 = I2 = 0). The dynamic model
associated with the manipulator was obtained in Chapter 5 and is
described by Equations (5.3) and (5.4):
τ1 = [[m1 + m2] + m2 + 2m2 cos(q2)] ¨q1
+ [m2 + m2 cos(q2)] ¨q2
−2m2 sin(q2) ˙q1 ˙q2 −m2 sin(q2) ˙q2
2
+ [m1 + m2]g sin(q1)
+ m2g sin(q1 + q2)
(14.6)

318
14 Introduction to Adaptive Robot Control
τ2 = [m2 + m2 cos(q2)] ¨q1 + m2¨q2
+ m2 sin(q2) ˙q2
1 + m2g sin(q1 + q2) .
(14.7)
The dynamic parameters in the model are the masses m1 and m2.
Deﬁne the vector θ of dynamic parameters as θ = [m1 m2]T .
The set of dynamic Equations (14.6) and (14.7) may be rewritten
in linear terms of θ, that is, in the form (14.5):
Y (q, ˙q, ¨q)θ = τ ,
where Y (q, ˙q, ¨q) is the matrix of dimension 2 × 2:
Y (q, ˙q, ¨q) =

Y11(q, ˙q, ¨q)
Y12(q, ˙q, ¨q)
Y21(q, ˙q, ¨q)
Y22(q, ˙q, ¨q)

with
Y11(q, ˙q, ¨q) = ¨q1 + gS1
Y12(q, ˙q, ¨q) = 2¨q1 + ¨q2 + C2(2¨q1 + ¨q2)
−S2 ˙q2
2 −2S2 ˙q1 ˙q2 + gS12 + gS1
Y21(q, ˙q, ¨q) = 0
Y22(q, ˙q, ¨q) = C2¨q1 + ¨q1 + ¨q2 + S2 ˙q2
1 + gS12 .
where Ci = cos(qi), Si = sin(qi), C12 = cos(q1 + q2) and S12 =
sin(q1 + q2).
♦
From Property 14.1, one can also show that the dynamic model of robots
with (linear) actuators described by (3.33) also satisﬁes a linearity relation
in terms of the dynamic parameters of the robot as well as in terms of the
actuator constants. Speciﬁcally, for all q, ˙q, ¨q ∈IRn ,
Ω(q, ˙q, ¨q)θ = K−1 [R M(q) + J] ¨q + K−1R C(q, ˙q) ˙q
+ K−1R g(q) + K−1Rf( ˙q) + K−1B ˙q
= v
(14.8)
where Ω(q, ˙q, ¨q) is a matrix of dimension n×m and θ is a vector of dimension
m × 1 that contains m constants that depend on the dynamic parameters of
the robot and on those of the actuators.
Example 14.4. Consider the pendulum depicted in Figure 3.13 and
whose dynamic model is derived in Example 3.8, that is,

Jm + JL
r2

¨q +

fm + fL
r2 + KaKb
Ra

˙q + kL
r2 sin(q) = Ka
rRa
v .

14.1 Parameterization of the Dynamic Model
319
The dynamic equation may be written in linear terms of the vector
θ, that is, in the form (14.8),
Ω(q, ˙q, ¨q)θ = v
where
Ω(q, ˙q, ¨q) = [¨q
˙q
sin(q)]
θ = rRa
Ka

Jm + JL
r2
fm + KaKb
Ra
+ fL
r2
kL
r2
T
.
♦
14.1.2 The Nominal Model
We remark that for any given robot the vector of dynamic parameters θ is
not unique since it depends on how the parameters of interest are chosen. In
the context of adaptive control, the parameters of interest are those whose
numerical values are unknown. Usually, these are the mass, the inertia and
the physical location of the center of mass of the last link of the robot.
For instance, as mentioned and illustrated through examples above, the
vector κ(q, u, v, w) and the matrix Φ(q, u, v, w) are obtained from knowledge
of the dynamic model of the robot under study, as well as from the vector
θ ∈IRm formed by the selection of the m dynamic parameters of interest.
Naturally, it is always possible to choose a vector of dynamic parameters θ
for which (14.4) holds with κ(q, u, v, w) = 0 ∈IRn.
However, on certain occasions it may also appear useful to separate from
the dynamics (14.2), those terms (if any) which involve known dynamic pa-
rameters or simply, that are independent of these. In such case, the parame-
terization (14.4) may be expressed as
M(q, θ)u + C(q, w, θ)v + g(q, θ) =
Φ(q, u, v, w)θ + M0(q)u + C0(q, w)v + g0(q),
(14.9)
where we may identify the nominal model or nominal part of the model,
κ(q, u, v, w) = M0(q)u + C0(q, w)v + g0(q) .
That is, the matrices M0(q), C0(q, w) and the vector g0(q) represent
respectively, parts of the matrices M(q), C(q, ˙q) and of the vector g(q) that
do not depend on the vector of unknown dynamic parameters θ.
According with the parameterization (14.9), given a vector ˆθ ∈IRm, the
expression Φ(q, u, v, w)ˆθ corresponds to

320
14 Introduction to Adaptive Robot Control
Φ(q, u, v, w)ˆθ =
M(q, ˆθ)u+C(q, w, ˆθ)v+g(q, ˆθ)−M0(q)u−C0(q, w)v−g0(q).
(14.10)
A particular case of parameterization (14.9) is when u = v = w = 0 ∈
IRn. In this scenario we have the following parameterization of the vector of
gravitational torques:
g(q, θ) = Φ(q, 0, 0, 0)θ + g0(q) .
The following example is presented with the purpose of illustrating these ideas.
Example 14.5. Consider the model of a pendulum of mass m, inertia
J with respect to the axis of rotation, and distance l from the axis of
rotation to the center of mass. The torque τ is applied at the axis of
rotation, that is,
J ¨q + mgl sin(q) = τ .
We clearly identify M(q) = J, C(q, ˙q) = 0 and g(q) = mgl sin(q).
Consider as parameters of interest the mass m and the inertia J.
The parameterization (14.9) in this scenario is
M(q, θ)u + C(q, w, θ)v + g(q, θ)
= Ju + mgl sin(q)
= Φ(q, u, v, w)θ + M0(q)u + C0(q, w)v + g0(q)
(14.11)
where
Φ(q, u, v, w) = [u
gl sin(q)]
(14.12)
θ =

J
m

M0(q) = C0(q, w) = g0(q) = 0 .
(14.13)
The reader may appreciate that particularly for this example, the
dynamic parameters coincide precisely with the parameters of interest,
m and J.
On the other hand, deﬁning ˆθ ∈IR2 as
ˆθ =
 ˆJ
ˆm

,
the expression (14.10) becomes
M(q, ˆθ)u + C(q, w, ˆθ)v + g(q, ˆθ)
= ˆJu + ˆmgl sin(q)
= Φ(q, u, v, w)ˆθ + M0(q)u + C0(q, w)v + g0(q)

14.1 Parameterization of the Dynamic Model
321
where Φ(q, u, v, w), M0(q), C0(q, w) and g0(q) are exactly the same as
in (14.12) and (14.13) respectively.
Assume now that the unique parameter of interest is the inertia
J. The expression (14.9) is given again by (14.11) but now
Φ(q, u, v, w) = u
(14.14)
θ = J
M0(q) = 0
C0(q, w) = 0
g0(q) = mgl sin(q) .
(14.15)
On the other hand, deﬁning ˆθ = ˆJ, the expression (14.10) becomes
M(q, ˆθ)u + C(q, w, ˆθ)v + g(q, ˆθ)
= ˆJu + mgl sin(q)
= Φ(q, u, v, w)ˆθ + M0(q)u + C0(q, w)v + g0(q),
where Φ(q, u, v, w), M0(q), C0(q, w) and g0(q) are exactly (14.14)–
(14.15).
♦
We present next an example of a planar 2-DOF robot. This robot is used in
succeeding chapters with the aim of illustrating diﬀerent adaptive controllers.
Example 14.6. Consider the planar manipulator having two DOF il-
lustrated in Figure 14.1 and whose dynamic model was obtained in
Example 3.3.
The dynamic model of the considered 2-DOF planar manipulator
is given by (3.8)–(3.9), and may be written as
θ1¨q1 + (θ3C21 + θ4S21) ¨q2 −θ3S21 ˙q2
2 + θ4C21 ˙q2
2 = τ1
(14.16)
(θ3C21 + θ4S21) ¨q1 + θ2¨q2 + θ3S21 ˙q2
1 −θ4C21 ˙q2
1 = τ2
(14.17)
where
θ1 = m1l2
c1 + m2l2
1 + I1
θ2 = m2l2
c2 + I2
θ3 = m2l1lc2 cos(δ)
θ4 = m2l1lc2 sin(δ) .
It is easy to see that the previous model may be written in the
standard form of the robot model (14.1) where

322
14 Introduction to Adaptive Robot Control
l1
q1
x
y
τ1
z
τ2
m2
I2
δ
q2
lc2
m1
I1
lc1
Figure 14.1. Planar 2-DOF manipulator on a horizontal plane
M(q, θ) =

θ1
θ3C21 + θ4S21
θ3C21 + θ4S21
θ2

C(q, ˙q, θ) =

0
(θ4C21 −θ3S21) ˙q2
(θ3S21 −θ4C21) ˙q1
0

g(q, θ) = 0 .
The dynamic model of the robot has been written in terms of
the components θ1, θ2, θ3 and θ4 of the vector of unknown dynamic
parameters. As mentioned above, these depend on the physical char-
acteristics of the manipulator such as the masses and inertias of its
links. The vector of dynamic parameters θ is given directly by
θ =
⎡
⎢⎣
θ1
θ2
θ3
θ4
⎤
⎥⎦∈IR4 .
Next, deﬁne the vectors
u =

u1
u2

,
v =

v1
v2

,
w =

w1
w2

.
The parameterization (14.9) in this example yields

14.1 Parameterization of the Dynamic Model
323
M(q, θ)u + C(q, w, θ)v + g(q, θ)
=

θ1
θ3C21 + θ4S21
θ3C21 + θ4S21
θ2

u
+

0
(θ4C21 −θ3S21) w2
(θ3S21 −θ4C21) w1
0

v
=

Φ11
Φ12
Φ13
Φ14
Φ21
Φ22
Φ23
Φ24

⎡
⎢⎣
θ1
θ2
θ3
θ4
⎤
⎥⎦
+ M0(q)u + C0(q, w)v + g0(q).
After spelling out M(q, θ)u + C(q, w, θ)v + g(q, θ), it may be
veriﬁed that
Φ11 = u1
Φ12 = 0
Φ13 = C21u2 −S21w2v2
Φ14 = S21u2 + C21w2v2
Φ21 = 0
Φ22 = u2
Φ23 = C21u1 + S21w1v1
Φ24 = S21u1 −C21w1v1
M0(q) = 0 ∈IR2×2
C0(q, w) = 0 ∈IR2×2
g0(q) = 0 ∈IR2 .
♦
Finally, we present an example of the Pelican robot, with which the reader
must already be familiar.
Example 14.7. Consider the Pelican robot presented in Chapter 5, and
shown in Figure 5.2. Its dynamic model is repeated here for conve-
nience:

M11(q)
M12(q)
M21(q)
M22(q)

"
#$
%
M(q)
¨q +

C11(q, ˙q)
C12(q, ˙q)
C21(q, ˙q)
C22(q, ˙q)

"
#$
%
C(q, ˙q)
˙q +

g1(q)
g2(q)

"
#$
%
g(q)
= τ
where

324
14 Introduction to Adaptive Robot Control
M11(q) = m1l2
c1 + m2

l2
1 + l2
c2 + 2l1lc2 cos(q2)

+ I1 + I2
M12(q) = m2

l2
c2 + l1lc2 cos(q2)

+ I2
M21(q) = m2

l2
c2 + l1lc2 cos(q2)

+ I2
M22(q) = m2l2
c2 + I2
C11(q, ˙q) = −m2l1lc2 sin(q2) ˙q2
C12(q, ˙q) = −m2l1lc2 sin(q2) [ ˙q1 + ˙q2]
C21(q, ˙q) = m2l1lc2 sin(q2) ˙q1
C22(q, ˙q) = 0
g1(q) = [m1lc1 + m2l1] g sin(q1) + m2lc2g sin(q1 + q2)
g2(q) = m2lc2g sin(q1 + q2) .
For this example we have selected as parameters of interest, the
mass m2, the inertia I2 and the location of the center of mass of
the second link, lc2. In contrast to the previous example where the
dynamic model (14.16)–(14.17) was written directly in terms of the
dynamic parameters, here it is necessary to determine the latter as
functions of the parameters of interest.
To that end, deﬁne ﬁrst the vectors
u =

u1
u2

,
v =

v1
v2

,
w =

w1
w2

.
The development of the parameterization (14.9) in this example
leads to
M(q, θ)u + C(q, w, θ)v + g(q, θ) =

Φ11
Φ12
Φ13
Φ21
Φ22
Φ23
 ⎡
⎣
θ1
θ2
θ3
⎤
⎦+ M0(q)u + C0(q, w)v + g0(q),
where
Φ11 = l2
1u1 + l1g sin(q1)
Φ12 = 2l1 cos(q2)u1 + l1 cos(q2)u2 −l1 sin(q2)w2v1
−l1 sin(q2)[w1 + w2]v2 + g sin(q1 + q2)
Φ13 = u1 + u2
Φ21 = 0
Φ22 = l1 cos(q2)u1 + l1 sin(q2)w1v1 + g sin(q1 + q2)
Φ23 = u1 + u2
θ =
⎡
⎣
θ1
θ2
θ3
⎤
⎦=
⎡
⎣
m2
m2lc2
m2l2
c2 + I2
⎤
⎦

14.2 The Adaptive Robot Control Problem
325
M0(q) =

m1l2
c1 + I1
0
0
0

C0(q, w) =

0
0
0
0

g0(q) =

m1lc1g sin(q1)
0

.
Notice that eﬀectively, the vector of dynamic parameters θ depends
exclusively on the parameters of interest m2, I2 and lc2.
♦
14.2 The Adaptive Robot Control Problem
We have presented and discussed so far the fundamental property of linear
parameterization of robot manipulators. All the adaptive controllers that we
study in the following chapters rely on the assumption that this property
holds.
Also, it is assumed that uncertainty in the model of the manipulator con-
sists only of the lack of knowledge of the numerical values of the elements of
θ. Hence, the structural form of the model of the manipulator is assumed to
be exactly known, that is, the matrices Φ(q, u, v, w), M0(q), C0(q, w) and
the vector g0(q) are assumed to be known.
Formally, the control problem that we address in this text may be stated
in the following terms. Consider the dynamic equation of n-DOF robots (14.2)
taking into account the linear parameterization (14.9) that is,
M(q, θ)¨q + C(q, ˙q, θ) ˙q + g(q, θ) = τ
or equivalently,
Φ(q, ¨q, ˙q, ˙q)θ + M0(q)¨q + C0(q, ˙q) ˙q + g0(q) = τ .
Assume that the matrices Φ(q, ¨q, ˙q, ˙q) ∈IRn×m, M0(q), C0(q, ˙q) ∈IRn×n and
the vector g0(q) ∈IRn are known but that the constant vector of dynamic
parameters (which includes, for instance, inertias and masses) θ ∈IRm is un-
known4. Given a set of vectorial bounded functions qd, ˙qd and ¨qd, referred
to as desired joint positions, velocities and accelerations, we seek to design
controllers that achieve the position or motion control objectives. The solu-
tions given in this textbook to this problem consist of the so-called adaptive
controllers.
4 By ‘Φ(q, ¨q, ˙q, ˙q) and C0(q, ˙q) known’ we understand that Φ(q, u, v, w) and C0(q, w)
are known respectively. By ‘   ∈IRm unknown’ we mean that the numerical values
of its m components θ1, θ2, · · · , θm are unknown.

326
14 Introduction to Adaptive Robot Control
We present next an example with the purpose of illustrating the control
problem formulated above.
Example 14.8. Consider again the model of a pendulum of mass m,
inertia J with respect to the axis of rotation, and distance l from the
axis of rotation to its center of mass. The torque τ is applied at the
axis of rotation, that is,
J ¨q + mgl sin(q) = τ .
We clearly identify M(q) = J, C(q, ˙q) = 0 and g(q) = mgl sin(q).
Consider as parameter of interest, the inertia J. The model of the
pendulum may be written in the generic form (14.9)
M(q, θ)u + C(q, w, θ)v + g(q, θ)
= Ju + mgl sin(q)
= Φ(q, u, v, w)θ + M0(q)u + C0(q, w)v + g0(q),
where
Φ(q, u, v, w) = u
θ = J
M0(q) = 0
C0(q, w) = 0
g0(q) = mgl sin(q) .
Assume that the values of the mass m, the distance l and the
gravity acceleration g are known but that the value of the inertia
θ = J is unknown (yet constant). The control problem consists in
designing a controller that is capable of achieving the motion control
objective
lim
t→∞˜q(t) = 0 ∈IR
for any desired joint trajectory qd(t) (with bounded ﬁrst and second
time derivatives). The reader may notice that this problem formula-
tion has not been addressed by any of the controllers presented in
previous chapters.
♦
It is important to stress that the lack of knowledge of the vector of dynamic
parameters of the robot, θ and consequently, the uncertainty in its dynamic
model make impossible the use of controllers which rely on accurate knowledge
of the robot model, such as those studied in the chapters of Part II of this
textbook. This has been the main reason that motivates the presentation of

14.3 Parameterization of the Adaptive Controller
327
adaptive controllers in this part of the text. Certainly, if by any other means
it is possible to determine the dynamic parameters, the use of an adaptive
controller is unnecessary.
Another important observation about the control problem formulated
above is the following. We have said explicitly that the vector of dynamic
parameters θ ∈IRm is assumed unknown but constant. This means precisely
that the components of this vector do not vary as functions of time. Conse-
quently, in the case where the parametric uncertainty comes from the mass
or the inertia corresponding to the manipulated load by the robot5, this must
always be the same object, and therefore, it may not be latched or changed.
Obviously this is a serious restriction from a practical viewpoint but it is
necessary for the stability analysis of any adaptive controller if one is inter-
ested in guaranteeing achievement of the motion or position control objectives.
As a matter of fact, the previous remarks also apply universally to all con-
trollers that have been studied in previous chapters of this textbook. The
reader should not be surprised by this fact since in the stability analyses the
dynamic model of robot manipulators (including the manipulated object) is
given by
M(q)¨q + C(q, ˙q) ˙q + g(q) = τ
where we have implicitly involved the hypothesis that its parameters are con-
stant. Naturally, in the case of model-based controllers for robots, these con-
stant parameters must in addition, be known. In the scenario where the pa-
rameters vary with time then this variation must be known exactly.
14.3 Parameterization of the Adaptive Controller
The control laws to solve the position and motion control problems for robot
manipulators may be written in the functional form
τ = τ(q, ˙q, qd, ˙qd, ¨qd, M(q), C(q, ˙q), g(q)) .
(14.18)
In general, these control laws are formed by the sum of two terms; the
ﬁrst, which does not depend explicitly on the dynamic model of the robot to
be controlled, and a second one which does. Therefore, giving a little ‘more’
structure to (14.18), we may write that most of the control laws have the form
τ = τ 1(q, ˙q, qd, ˙qd, ¨qd) + M(q)u + C(q, w)v + g(q),
where the vectors u, v, w ∈IRn depend in general on the positions q, velocities
˙q and on the desired trajectory and its derivatives, qd, ˙qd and ¨qd. The term
5 The manipulated object (load) may be considered as part of the last link of the
robot.

328
14 Introduction to Adaptive Robot Control
τ 1(q, ˙q, qd, ˙qd, ¨qd), which does not depend on the dynamic model, usually
corresponds to linear control terms of PD type, i.e.
τ 1(q, ˙q, qd, ˙qd, ¨qd) = Kp[qd −q] + Kv[ ˙qd −˙q]
where Kp and Kv are gain matrices of position and velocity (or derivative
gain) respectively.
Certainly, the structure of some position control laws do not depend on
the dynamic model of the robot to be controlled; e.g. such is the case for PD
and PID control laws. Other control laws require only part of the dynamic
model of the robot; e.g. PD control with gravity compensation.
In general an adaptive controller is formed of two main parts:
•
control law or controller;
•
adaptive (update) law.
At this point it is worth remarking that we have not spoken of any partic-
ular adaptive controller to solve a given control problem. Indeed, there may
exist many control and adaptive laws that allow one to solve a speciﬁc control
problem. However, in general the control law is an algebraic equation that
calculates the control action and which may be written in the generic form
τ = τ 1(q, ˙q, qd, ˙qd, ¨qd) + M(q, ˆθ)u + C(q, w, ˆθ)v + g(q, ˆθ)
(14.19)
where in general, the vectors u, v, w ∈IRn depend on the positions q and
velocities ˙q as well as on the desired trajectory qd, and its derivatives ˙qd and
¨qd. The vector ˆθ ∈IRm is referred to as the vector of adaptive parameters
even though it actually corresponds to the vectorial function of time ˆθ(t),
which is such that (14.10) holds for all t ≥0. It is important to mention that
on some occasions, the control law may be a dynamic equation and not just
‘algebraic’.
Typically, the control law (14.19) is chosen so that when substituting the
vector of adaptive parameters ˆθ by the vector of dynamic parameters θ (which
yields a nonadaptive controller), the resulting closed-loop system meets the
control objective. As a matter of fact, in the case of control of robot manipu-
lators nonadaptive control strategies that do not guarantee global asymptotic
stability of the origin

˜qT
˙˜q
T T
= 0 ∈IR2n or
˜qT
˙qT T = 0 ∈IR2n for the
case when qd(t) is constant, are not candidates for adaptive versions, at least
not with the standard design tools.
The adaptive law allows one to determine ˆθ(t) and in general, may be
written as a diﬀerential equation of ˆθ. An adaptive law commonly used in
continuous adaptive systems is the so-called integral law or gradient type
ˆθ(t) = Γ
 t
0
ψ (s, q, ˙q, ¨q, qd, ˙qd, ¨qd) ds + ˆθ(0)
(14.20)

14.3 Parameterization of the Adaptive Controller
329
where6 Γ = Γ T ∈IRm×m and ˆθ(0) ∈IRm are design parameters while ψ is a
vectorial function to be determined, of dimension m.
The symmetric matrix Γ is usually diagonal and positive deﬁnite and is
called ‘adaptive gain’. The “magnitude” of the adaptive gain Γ is related
proportionally to the “rapidity of adaptation” of the control system vis-a-
vis the parametric uncertainty of the dynamic model. The design procedures
for adaptive controllers that use integral adaptive laws (14.20) in general, do
not provide any guidelines to determine speciﬁcally the adaptive gain Γ. In
practice one simply applies ‘experience’ to a trial-and-error approach until sat-
isfactory behavior of the control system is obtained and usually, the adaptive
gain is initially chosen to be “small”.
On the other hand, ˆθ(0) is an arbitrary vector even though in practice,
we choose it as the best approximation available to the unknown vector of
dynamic parameters, θ.
Figure 14.2 shows a block-diagram of the adaptive control of a robot.
An equivalent representation of the adaptive law is obtained by diﬀeren-
tiating (14.20) with respect to time, that is,
˙ˆθ(t) = Γψ (s, q, ˙q, ¨q, qd, ˙qd, ¨qd) .
(14.21)
τ
qd
˙qd
¨qd
ROBOT
qd
˙q
τ(t, q, ˙q, ˙qd, ¨qd, ˆθ)
 t
0
ψ (s, q, ˙q, ¨q, qd, ˙qd, ¨qd) ds
Figure 14.2. Block-diagram: generic adaptive control of robots
It is desirable, from a practical viewpoint, that the control law (14.19) as
well as the adaptive law (14.20) or (14.21), do not depend explicitly on the
joint acceleration ¨q.
14.3.1 Stability and Convergence of Adaptive Control Systems
An important topic in adaptive control systems is parametric convergence.
The concept of parametric convergence refers to the asymptotic properties of
6 In
(14.20)
as
in
other
integrals,
we
avoid
the
cumbersome
notation
ψ(t,  (t), ˙ (t), ¨ (t),  d(t), ˙ d(t), ¨ d(t) ).

330
14 Introduction to Adaptive Robot Control
the vector of adaptive parameters ˆθ. For a given adaptive system, if the limit
of ˆθ(t) when t →∞exists and is such that
lim
t→∞
ˆθ(t) = θ,
then we say that the adaptive system guarantees parametric convergence. As
a matter of fact, parametric convergence is not an intrinsic characteristic of an
adaptive controller. The latter depends, of course, on the adaptive controller
itself but also on the behavior of some functions which may be internal or
eventually external to the system in closed loop.
The study of the conditions to obtain parametric convergence in adaptive
control systems is in general elaborate and requires additional mathematical
tools to those presented in this text. For this reason, this topic is excluded.
The methodology of stability analysis for adaptive control systems for
robot manipulators that is treated in this textbook is based on Lyapunov sta-
bility theory, following the guidelines of their nonadaptive counterparts. The
main diﬀerence with respect to the analyses presented before is the inclusion
of the parametric errors vector ˜θ ∈IRm deﬁned as
˜θ = ˆθ −θ
in the closed loop equation’s state vector.
The dynamic equations that characterize adaptive control systems in
closed loop have the general form
d
dt
⎡
⎢⎢⎢⎣
˜q
˙˜q
˜θ
⎤
⎥⎥⎥⎦= f
+
t, q, ˙q, qd, ˙qd, ¨qd, ˜θ
,
,
for which the origin is an equilibrium point. In general, unless we make appro-
priate hypotheses on the reference trajectories, the origin in adaptive control
systems is not the only equilibrium point; as a matter of fact, it is not even
an isolated equilibrium! The study of such systems is beyond the scope of the
present text. For this reason, we do not study asymptotic stability (neither
local nor global) but only stability and convergence of the position errors.
That is, we show by other arguments, achievement of the control objective
lim
t→∞˜q(t) = 0 .
We wish to emphasize the signiﬁcance of the last phrase. Notice that we are
claiming that even though we do not study and in general do not guarantee
parameter convergence (to their true values) for any of the adaptive con-
trollers studied in this text, we are implicitly saying that one can still achieve

Bibliography
331
the motion control objective. This, in the presence of multiple equilibria and
parameter uncertainty.
That one can achieve the control objective under parameter uncertainty is
a fundamental truth that holds for many nonlinear systems and is commonly
known as certainty equivalence.
Bibliography
The ﬁrst adaptive control system with a rigorous proof of stability for the
problem of motion control of robots, as far as we know, was reported in
•
Craig J., Hsu P., Sastry S., 1986, “Adaptive control of mechanical ma-
nipulators”, Proceedings of the 1986 IEEE International Conference on
Robotics and Automation, San Francisco, CA., April, pp. 190–195. Also
reported in The International Journal of Robotics Research, Vol. 6, No. 2,
Summer 1987, pp. 16–28.
A key step in the study of this controller, and by the way, also in that
of the succeeding controllers in the literature, was the use of the linear-
parameterization property of the robot model (see Property 14.1 above). This
ﬁrst adaptive controller needed a priori knowledge of bounds on the dynamic
parameters as well as the measurement of the vector of joint accelerations
¨q. After this ﬁrst adaptive controller a series of adaptive controllers that did
not need knowledge of the bounds on the parameters nor the measurement of
joint accelerations were developed. A list containing some of the most relevant
related references is presented next.
•
Middleton R. H., Goodwin G. C., 1986. “Adaptive computed torque control
for rigid link manipulators”, Proceedings of the 25th Conference on Deci-
sion and Control, Athens, Greece, December, pp. 68–73. Also reported in
Systems and Control Letters, Vol. 10, pp. 9–16, 1988.
•
Slotine J. J., Li W., 1987, “On the adaptive control of robot manipulators”,
The International Journal of Robotics Research, Vol. 6, No. 3, pp. 49–59.
•
Sadegh N., Horowitz R., 1987. “Stability analysis of an adaptive controller
for robotic manipulators”, Proceedings of the 1987 IEEE International
Conference on Robotics and Automation, Raleigh NC., April, pp. 1223–
1229.
•
Bayard D., Wen J. T., 1988. “New class of control law for robotic manip-
ulators. Part 2: Adaptive case”, International Journal of Control, Vol. 47,
No. 5, pp. 1387–1406.
•
Slotine J. J., Li W., 1988, “Adaptive manipulator control: A case study”,
IEEE Transactions on Automatic Control, Vol. 33, No. 11, November, pp.
995–1003.

332
14 Introduction to Adaptive Robot Control
•
Kelly R., Carelli R., Ortega R., 1989, “Adaptive motion control design to
robot manipulators: An input–output approach”, International Journal of
Control, Vol. 50, No. 6, September, pp. 2563–2581.
•
Landau I. D., Horowitz R., 1989, “Applications of the passivity approach
to the stability analysis of adaptive controllers for robot manipulators”,
International Journal of Adaptive Control and Signal Processing, Vol. 3,
pp. 23–38.
•
Sadegh N., Horowitz R., 1990, “An exponential stable adaptive control law
for robot manipulators”, IEEE Transactions on Robotics and Automation,
Vol. 6, No. 4, August, pp. 491–496.
•
Kelly R., 1990, “Adaptive computed torque plus compensation control for
robot manipulators”, Mechanism and Machine Theory, Vol. 25, No. 2, pp.
161–165.
•
Johansson R., 1990, “Adaptive control of manipulator motion”, IEEE
Transactions on Robotics and Automation, Vol. 6, No. 4, August, pp.
483–490.
•
Lozano R., Canudas C., 1990, “Passivity based adaptive control for me-
chanical manipulators using LS–type estimation”, IEEE Transactions on
Automatic Control, Vol. 25, No. 12, December, pp. 1363–1365.
•
Lozano R., Brogliato B., 1992, “Adaptive control of robot manipulators
with ﬂexible joints”, IEEE Transactions on Automatic Control, Vol, 37,
No. 2, February, pp. 174–181.
•
Canudas C., Fixot N., 1992, “Adaptive control of robot manipulators via
velocity estimated feedback”, IEEE Transactions on Automatic Control,
Vol. 37, No. 8, August, pp. 1234–1237.
•
Hsu L., Lizarralde F., 1993, “Variable structure adaptive tracking control
of robot manipulators without velocity measurement”, 12th IFAC World
Congress, Sydney, Australia, July, Vol. 1, pp. 145–148.
•
Yu T., Arteaga A., 1994, “Adaptive control of robots manipulators based
on passivity”, IEEE Transactions on Automatic Control, Vol. 39, No. 9,
September, pp. 1871–1875.
An excellent introductory tutorial to adaptive motion control of robot
manipulators is presented in
•
Ortega R., Spong M., 1989. “Adaptive motion control of rigid robots: A
tutorial”, Automatica, Vol. 25, No. 6, pp. 877–888.
Nowadays, we also count on several textbooks that are devoted in part
to the study of adaptive controllers for robot manipulators. We cite among
these:
•
Craig J., 1988, “Adaptive control of mechanical manipulators”, Addison–
Wesley Pub. Co.

Bibliography
333
•
Spong M., Vidyasagar M., 1989, “Robot dynamics and control”, John Wi-
ley and Sons.
•
Stoten D. P., 1990, “Model reference adaptive control of manipulators”,
John Wiley and Sons.
•
Slotine J. J., Li W., 1991, “Applied nonlinear control”, Prentice-Hall.
•
Lewis F. L., Abdallah C. T., Dawson D. M., 1993, “Control of robot ma-
nipulators”, Macmillan Pub. Co.
•
Arimoto S., 1996, “Control theory of non–linear mechanical systems”, Ox-
ford University Press, New York.
A detailed description of the basic concepts of adaptive control systems
may be found in following texts.
•
Anderson B. D. O., Bitmead R. R., Johnson C. R., Kokotovi´c P., Kosut
R., Mareels I. M. Y., Praly L., Riedle B. D., 1986, “Stability of adaptive
systems: Passivity and averaging analysis”, The MIT Press, Cambridge,
MA.
•
Sastry S., Bodson M., 1989, “Adaptive control–stability, convergence and
robustness”, Prentice-Hall.
•
Narendra K., Annaswamy A., 1989, “Stable adaptive systems”, Prentice-
Hall.
•
˚Astr¨om K. J., Wittenmark B., 1995, Second Edition, “Adaptive control”,
Addison–Wesley Pub. Co.
•
Kristi´c M., Kanellakopoulos I., Kokotovi´c P., 1995, “Nonlinear and adap-
tive control design”, John Wiley and Sons, Inc.
•
Marino R., Tomei P., 1995, “Nonlinear control design”, Prentice-Hall.
•
Khalil H., 1996, “Nonlinear systems”, Second Edition, Prentice-Hall.
•
Landau I. D., Lozano R., M’Saad M., 1998, “Adaptive control”, Springer-
Verlag: London.
The following references present the analysis and experimentation of var-
ious adaptive controllers for robots
•
de Jager B., 1992, “Practical evaluation of robust control for a class of non-
linear mechanical dynamic systems”, PhD. thesis, Eindhoven University of
Technology, The Netherlands, November.
•
Whitcomb L. L., Rizzi A., Koditschek D. E., 1993, “Comparative experi-
ments with a new adaptive controller for robot arms”, IEEE Transactions
on Robotics and Automation, Vol. 9, No. 1, February.
•
Berghuis H., 1993, “Model-based robot control: from theory to practice”,
PhD. thesis, University of Twente, The Netherlands, June.
In recent years a promising approach appeared for robot control which is
called ‘learning’. This approach is of special interest in the case of paramet-

334
14 Introduction to Adaptive Robot Control
ric uncertainty in the model of the robot and when the speciﬁed motion is
periodic. The interested reader is invited to see
•
Arimoto S., 1990, “ Learning control theory for robotic motion”, Interna-
tional Journal of Adaptive Control and Signal Processing, Vol. 4, No. 6,
pp. 543–564.
•
Massner W., Horowitz R., Kao W., Boals M., 1991, “A new adaptive learn-
ing rule”, IEEE Transactions on Automatic Control, Vol. 36, No. 2, Febru-
ary, pp. 188–197.
•
Arimoto S., Naniwa T., Parra–Vega V., Whitcomb L. L., 1995, “A class
of quasi-natural potentials for robot servo loops and its role in adaptive
learning controls”, Intelligent and Soft Computing, Vol. 1, No. 1, pp. 85–
98.
Property 14.1 on the linearity of the robots dynamic model in the dynamic
parameters has been reported in
•
Khosla P., Kanade T., 1985, “Parameter identiﬁcation of robot dynam-
ics”, Proceedings 24th IEEE Conference on Decision and Control, Fort
Lauderdale FL, December.
•
Spong M., Vidyasagar M., 1989, “Robot dynamics and control”, John Wi-
ley and Sons.
•
Whitcomb L. L., Rizzi A., Koditschek D. E., 1991, “Comparative experi-
ments with a new adaptive controller for robot arms”, Center for Systems
Science, Dept. of Electrical Engineering, Yale University, Technical Report
TR9101, February.
To the best of the authors’ knowledge, the only rigorous proof of global
uniform asymptotic stability for adaptive motion control of robot manipula-
tors, i.e. including a proof of uniform global asymptotic convergence of the
parameters, is given in
•
A. Lor´ıa, R. Kelly and A. Teel, 2003, “Uniform parametric convergence
in the adaptive control of manipulators: a case restudied”, in Proceedings
of International Conference on Robotics and Automation, Taipei, Taiwan,
pp. 1062–1067.
Problems
1. Consider the simpliﬁed Cartesian mechanical device of Figure 14.3.
Express the dynamic model in the form
M(q)¨q + C(q, ˙q) ˙q + g(q) = Y (q, ˙q, ¨q)θ
where θ = [m1 + m2 m2]T .

Problems
335
x0
y0
z0
q1
q2
x0
y0
z0
q1
q2
m1
m2
Figure 14.3. Problem 2. Cartesian robot.

15
PD Control with Adaptive Desired Gravity
Compensation
It must be clear at this point that position control – regulation – is one of the
simplest control objectives that may be formulated for robot manipulators. In
spite of this apparent simplicity, the controllers which may achieve it globally
require, in general, knowledge of at least the vector of gravitational torques
g(q) of the dynamic robot model in question. Among the simplest controllers
we have the following:
•
PD control with gravity compensation;
•
PD control with desired gravity compensation.
The ﬁrst satisﬁes the position control objective globally with a trivial
choice of the design parameter (cf. Chapter 7) while the second, even though
it also achieves the position control objective globally, it requires a particular
choice of design parameters (cf. Chapter 8). Nevertheless, the second controller
is more attractive from a practical viewpoint due to its relative simplicity. As
mentioned above, a common feature of both controllers is the use of the vector
of gravitational torques g(q). The knowledge of this vector must be complete
in the sense that both the structure of g(q) and the numerical values of the
dynamic parameters must be known. Naturally in the case in which one of
them is unknown, the previous control schemes may not be implemented.
In this chapter we study an adaptive control that is capable of satisfying
the position control objective globally without requiring exact knowledge of
the numerical values involved in the dynamic model of the robot to be con-
trolled. We consider the scenario where all the joints of the robot are revolute.
Speciﬁcally, we study the adaptive version of PD control with desired gravity
compensation.
The material presented in this chapter has been taken from the corre-
sponding references cited at the end of the chapter.

338
15 PD Control with Adaptive Desired Gravity Compensation
15.1 The Control and Adaptive Laws
We start by recalling the PD control law with desired gravity compensation
given by (8.1), and which we repeat below for convenience,
τ = Kp˜q + Kv ˙˜q + g(qd) .
We also recall that Kp, Kv ∈IRn×n are symmetric positive deﬁnite matrices
chosen by the designer. As is customary, the position error is denoted by
˜q = qd −q, while qd ∈IRn stands for the desired joint position. In this
chapter we assume that the desired joint position qd is constant and therefore
the control law covers the form
τ = Kp˜q −Kv ˙q + g(qd) .
(15.1)
The practical convenience of this control law with respect to that of PD
control with gravity compensation, given by (7.1), is evident. Indeed, the
vector g(qd) used in the control law (15.1) depends on qd and not on q
therefore, it may be evaluated “oﬀ-line” once qd is deﬁned. In other words, it
is unnecessary to compute g(q) in real time.
For further development it is also worth recalling Property 14.1, which
establishes that the dynamic model of a n-DOF robot (with a manipulated
load included) may be written using the parameterization (14.9), i.e. as
M(q, θ)u + C(q, w, θ)v + g(q, θ) =
Φ(q, u, v, w)θ + M0(q)u + C0(q, w)v + g0(q),
(15.2)
where Φ(q, u, v, w) ∈IRn×m, M0(q) ∈IRn×n, C0(q, w) ∈IRn×n, g0(q) ∈IRn
and θ ∈IRm. The vector θ, known by the name vector of dynamic parameters,
contains elements that depend precisely on physical parameters such as masses
and inertias of the links of the manipulator and on the load. The matrices
M0(q), C0(q, w) and the vector g0(q) represent parts of the matrices M(q),
C(q, ˙q) and of the vector g(q) that do not depend on the vector of (unknown)
dynamic parameters θ.
By virtue of the previous fact, notice that the following expression is valid
for all x ∈IRn
g(x, θ) = Φ(x, 0, 0, 0)θ + g0(x),
(15.3)
where we set
u = 0
v = 0
w = 0 .
On the other hand, using (14.10), we conclude that for any vector ˆθ ∈IRm
and x ∈IRn

15.1 The Control and Adaptive Laws
339
g(x, ˆθ) = Φ(x, 0, 0, 0)ˆθ + g0(x) .
(15.4)
For notational simplicity, in the sequel we use the following abbreviation
Φg(x) = Φ(x, 0, 0, 0) .
(15.5)
Considering (15.3) with x = qd, the PD control law with desired gravity
compensation, (15.1), may also be written as
τ = Kp˜q −Kv ˙q + Φg(qd)θ + g0(qd) .
(15.6)
It is important to emphasize that in the implementation of the PD control
law with desired gravity compensation, (15.1) or, equivalently (15.6), knowl-
edge of the dynamic parameters θ of the robot (including the manipulated
load) is required.
In the sequel, we assume that the vector θ ∈IRm of dynamic parameters
is unknown but constant. Obviously, in this scenario, PD control with desired
gravity compensation may not be used for robot control. Nevertheless, we
assume that the unknown dynamic parameters θ lay in a known region Ω⊂
IRm of the space IRm. In other words, even though the vector θ is supposed to
be unknown, we assume that the set Ωin which θ lays is known. The set Ωmay
be arbitrarily “large” but has to be bounded. In practice, the set Ωmay be
determined from upper and lower-bounds on the dynamic parameters which,
as has been mentioned, are functions of the masses, inertias and location of
the centers of mass of the links.
The solution that we consider in this chapter to the position control prob-
lem formulated above consists in the so-called adaptive version of PD control
with desired gravity compensation, that is, PD control with adaptive desired
gravity compensation.
The structure of the motion adaptive control schemes for robot manipu-
lators that are studied in this text are deﬁned by means of a control law like
(14.19) and an adaptive law like (14.20). In the particular case of position
control these control laws take the form
τ = τ
+
t, q, ˙q, qd, ˆθ
,
(15.7)
ˆθ(t) = Γ
 t
0
ψ (t, q, ˙q, qd) dt + ˆθ(0),
(15.8)
where Γ = Γ T ∈IRm×m (adaptation gain) and ˆθ(0) ∈IRm are design pa-
rameters while ψ is a vectorial function to be determined, and has dimension
m.
The PD control with adaptive desired gravity compensation is described
in (15.7)–(15.8) where

340
15 PD Control with Adaptive Desired Gravity Compensation
τ = Kp˜q −Kv ˙q + g(qd, ˆθ)
(15.9)
= Kp˜q −Kv ˙q + Φg(qd)ˆθ + g0(qd),
(15.10)
and
ˆθ(t) = ΓΦg(qd)T
 t
0

ε0
1 + ∥˜q∥˜q −˙q

ds + ˆθ(0),
(15.11)
where Kp, Kv ∈IRn×n and Γ ∈IRm×m are symmetric positive deﬁnite design
matrices and ε0 is a positive constant that satisﬁes conditions that are given
later on. The pass from (15.9) to (15.10) was made by using (15.4) with
x = qd.
Notice that the control law (15.10) does not depend on the dynamic pa-
rameters θ but on the so-called adaptive parameters ˆθ that in their turn,
are obtained from the adaptive law (15.11) which of course, does not depend
either on θ.
Among the design parameters of the adaptive controller formed by Equa-
tions (15.10)–(15.11), only the matrix Kp and the real positive constant ε0
must be chosen carefully. To that end, we start by deﬁning λMax{M}, kC1
and kg as
•λMax{M(q, θ)} ≤λMax{M}
∀q ∈IRn,
θ ∈Ω
• ∥C(q, ˙q, θ)∥≤kC1 ∥˙q∥
∀q, ˙q ∈IRn,
θ ∈Ω
• ∥g(x, θ) −g(y, θ)∥≤kg ∥x −y∥
∀x, y ∈IRn,
θ ∈Ω.
Notice that these conditions are compatible with those established in Chapter
4. The constants λMax{M}, kC1 and kg are considered known. Naturally, to
obtain them it is necessary to know explicitly the matrices M(q, θ), C(q, ˙q, θ)
and of the vector g(q, θ), as well as of the set Ω, but one does not require to
know the exact vector of dynamic parameters θ.
The symmetric positive deﬁnite matrix Kp and the positive constant ε0
are chosen so that the following design conditions be veriﬁed.
C.1) λmin{Kp} > kg ,
C.2)
-
2λmin{Kp}
ε2λMax{M} > ε0 ,
C.3) 2λmin{Kv}[λmin{Kp} −kg]
λ2
Max{Kv}
> ε0 ,
C.4)
λmin{Kv}
2 [kC1 + 2λMax{M}] > ε0
where ε2 is deﬁned so that
ε2 =
2ε1
ε1 −2
(15.12)

15.1 The Control and Adaptive Laws
341
and ε1 satisﬁes the inequality
2λmin{Kp}
kg
> ε1 > 2 .
(15.13)
It is important to underline that once the matrix Kp is ﬁxed in accordance
with condition C.1 and the matrix Kv has been chosen arbitrarily but of
course, symmetric positive deﬁnite, then it is always possible to ﬁnd a set
of strictly positive values for ε0 for which the conditions C.2–C.4 are also
veriﬁed.
Before proceeding to derive the closed-loop equation we deﬁne the param-
eter errors vector ˜θ ∈IRm as
˜θ = ˆθ −θ .
(15.14)
The parametric errors vector ˜θ is unknown since this is obtained as a function
of the vector of dynamic parameters θ which is assumed to be unknown.
Nevertheless, the parametric error ˜θ is introduced here only for analytical
purposes and evidently, it is not used by the controller.
From the deﬁnition of the parametric errors vector ˜θ in (15.14), it may be
veriﬁed that
Φg(qd)ˆθ = Φg(qd)˜θ + Φg(qd)θ
= Φg(qd)˜θ + g(qd, θ) −g0(qd),
where we used (15.3) with x = qd.
Using the expression above, the control law (15.10) may be written as
τ = Kp˜q −Kv ˙q + Φg(qd)˜θ + g(qd, θ) .
Using the control law as written above and substituting the control action
τ in the equation of the robot model (14.2), we obtain
M(q, θ)¨q +C(q, ˙q, θ) ˙q = Kp˜q −Kv ˙q +Φg(qd)˜θ +g(qd, θ)−g(q, θ) . (15.15)
On the other hand, since the vector of dynamic parameters θ has been
assumed to be constant, its time derivative is zero, ˙θ = 0 ∈IRm. Therefore,
taking the derivative with respect to time of the parametric errors vector ˜θ,
deﬁned in (15.14), we obtain ˙˜θ = ˙ˆθ. In its turn, the time derivative of the
vector of adaptive parameters ˆθ is obtained by derivating with respect to time
the adaptive law (15.11). Using these arguments we ﬁnally get
˙˜θ = ΓΦg(qd)T

ε0
1 + ∥˜q∥˜q −˙q

.
(15.16)

342
15 PD Control with Adaptive Desired Gravity Compensation
From all the above conclude that the closed-loop equation is formed by
Equations (15.15) and (15.16) and it may be written as
d
dt
⎡
⎢⎢⎢⎣
˜q
˙q
˜θ
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎢⎢⎣
−˙q
M(q, θ)−1 
Kp˜q−Kv ˙q + Φg(qd)˜θ−C(q, ˙q, θ) ˙q+g(qd, θ) −g(q, θ)

ΓΦg(qd)T

ε0
1+∥˜q∥˜q −˙q

⎤
⎥⎥⎥⎥⎥⎦
(15.17)
Notice that this is a set of autonomous diﬀerential equations with state

˜qT ˙qT ˜θ
T T
and the origin of the state space, i.e.
⎡
⎢⎢⎢⎣
˜q
˙q
˜θ
⎤
⎥⎥⎥⎦= 0 ∈IR2n+m ,
is an equilibrium point of (15.17).
15.2 Stability Analysis
The stability analysis of the origin of the state space of closed-loop equation
follows along the guidelines of Section 8.4. Consider the following extension of
the Lyapunov function candidate (8.23) with the additional term 1
2 ˜θ
TΓ −1˜θ,
i.e.
V (˜q, ˙q, ˜θ) = 1
2
⎡
⎢⎢⎢⎣
˜q
˙q
˜θ
⎤
⎥⎥⎥⎦
T
P
$
%"
#
⎡
⎢⎢⎢⎢⎣
2
ε2 Kp
−
ε0
1+∥˜q∥M(q, θ)
0
−
ε0
1+∥˜q∥M(q, θ)
M(q, θ)
0
0
0
Γ −1
⎤
⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
˜q
˙q
˜θ
⎤
⎥⎥⎥⎦
+ U(q, θ) −U(qd, θ) + g(qd, θ)T˜q + 1
ε1
˜qTKp˜q
"
#$
%
f(˜q)

15.2 Stability Analysis
343
= 1
2 ˙qTM(q, θ) ˙q + U(q, θ) −U(qd, θ) + g(qd, θ)T˜q
+
 1
ε1
+ 1
ε2

˜qTKp˜q −
ε0
1 + ∥˜q∥˜qTM(q, θ) ˙q
+ 1
2
˜θ
TΓ −1˜θ ,
(15.18)
where f(˜q) is deﬁned as in (8.18) and the constants ε0 > 0, ε1 > 2 and ε2 > 2
are chosen so that
2λmin{Kp}
kg
> ε1 > 2
(15.19)
ε2 =
2ε1
ε1 −2
(15.20)
-
2λmin{Kp}
ε2λMax{M} > ε0 > 0 .
(15.21)
The condition (15.19) guarantees that f(˜q) is a positive deﬁnite function
(see Lemma 8.1), while (15.21) ensures that P is a positive deﬁnite matrix.
Finally (15.20) implies that
1
ε1 + 1
ε2 = 1
2. Notice that condition (15.21) cor-
responds exactly to condition C.2 which holds due to the hypothesis on the
choice of ε0.
Thus, to show that the Lyapunov function candidate V (˜q, ˙q, ˜θ) is positive
deﬁnite, we start by deﬁning ε as
ε = ε(∥˜q∥) :=
ε0
1 + ∥˜q∥.
(15.22)
Consequently, the inequality (15.21) implies that the matrix
2
ε2
Kp −

ε0
1 + ∥˜q∥
2
M(q, θ) = 2
ε2
Kp −ε2M(q, θ)
is positive deﬁnite.
On the other hand, the Lyapunov function candidate (15.18) may be
rewritten in the following manner:
V (˜q, ˙q, ˜θ) = 1
2 [−˙q + ε˜q]T M(q, θ) [−˙q + ε˜q]
+ 1
2 ˜qT
 2
ε2
Kp −ε2M(q, θ)

˜q
+ 1
2
˜θ
TΓ −1˜θ
+ U(q, θ) −U(qd, θ) + g(qd, θ)T˜q + 1
ε1
˜qTKp˜q
"
#$
%
f(˜q)
,

344
15 PD Control with Adaptive Desired Gravity Compensation
which is a positive deﬁnite function since the matrices M(q, θ) and
2
ε2 Kp −
ε2M(q, θ) are positive deﬁnite and f(˜q) is also a positive deﬁnite function
(since λmin{Kp} > kg and from Lemma 8.1).
Now we proceed to compute the total time derivative of the Lyapunov
function candidate (15.18). For notational simplicity, in the sequel we drop the
argument θ from the matrices M(q, θ), C(q, ˙q, θ), from the vectors g(q, θ),
g(qd, θ) and from U(q, θ) and U(qd, θ). However, the reader should keep in
mind that, strictly speaking, V depends on time since θ = ˆθ(t) −˜θ.
The time derivative of the Lyapunov function candidate (15.18) along the
trajectories of the closed-loop Equation (15.17) becomes, after some simpliﬁ-
cations,
˙V (˜q, ˙q, ˜θ) = ˙qT [Kp˜q −Kv ˙q −C(q, ˙q) ˙q + g(qd) −g(q)] + 1
2 ˙qT ˙M(q) ˙q
+ g(q)T˙q −g(qd)T˙q −˜qTKp ˙q + ε ˙qTM(q) ˙q −ε˜qT ˙M(q) ˙q
−ε˜qT [Kp˜q −Kv ˙q −C(q, ˙q) ˙q + g(qd) −g(q)]
−˙ε˜qTM(q) ˙q,
where we used g(q) = ∂U(q)
∂q
. After some further simpliﬁcations, the time
derivative ˙V (˜θ, ˜q, ˙q) may be written as
˙V (˜q, ˙q, ˜θ) = −˙qTKv ˙q + ˙qT
1
2
˙M(q) −C(q, ˙q)

˙q + ε ˙qTM(q) ˙q
−ε˜qT 
˙M(q) −C(q, ˙q)

˙q −ε˜qT [Kp˜q −Kv ˙q]
−ε˜qT [g(qd) −g(q)] −˙ε˜qTM(q) ˙q .
Finally, considering Property 4.2, i.e. that the matrix 1
2 ˙M(q) −C(q, ˙q) is
skew-symmetric and
˙M(q) = C(q, ˙q) + C(q, ˙q)T , we get
˙V (˜q, ˙q, ˜θ) = −˙qTKv ˙q + ε ˙qTM(q) ˙q −ε˜qTKp˜q + ε˜qTKv ˙q
−ε ˙qTC(q, ˙q)˜q −ε˜qT [g(qd) −g(q)]
−˙ε˜qTM(q) ˙q .
(15.23)
As we know now, to conclude stability by means of Lyapunov’s direct
method, it is suﬃcient to prove that ˙V (0, 0, 0) = 0 and that ˙V (˜q, ˙q, ˜θ) ≤0
for all vectors

˜qT
˙qT
˜θ
T T
̸= 0 ∈IR2n+m. These conditions are veriﬁed for
instance if ˙V (˜q, ˙q, ˜θ) is negative semideﬁnite. Observe that at this moment, it
is very diﬃcult to ensure from (15.23), that ˙V (˜q, ˙q, ˜θ) is a negative semideﬁnite
function. With the aim of ﬁnding additional conditions on ε0 so that ˙V (˜q, ˙q, ˜θ)
is negative semideﬁnite, we present next some upper-bounds over the following
three terms:

15.2 Stability Analysis
345
•
−ε ˙qTC(q, ˙q)˜q
•
−ε˜qT [g(qd) −g(q)]
•
−˙ε˜qTM(q) ˙q .
First, with respect to −ε ˙qTC(q, ˙q)˜q, we have
−ε ˙qTC(q, ˙q)˜q ≤
−ε ˙qTC(q, ˙q)˜q

≤ε ∥˙q∥∥C(q, ˙q)˜q∥
≤εkC1 ∥˙q∥∥˙q∥∥˜q∥
≤ε0kC1 ∥˙q∥2
(15.24)
where we took into account Property 4.2, i.e. that ∥C(q, x)y∥≤kC1 ∥x∥∥y∥,
and the deﬁnition of ε in (15.22).
Next, concerning the term −ε˜qT [g(qd) −g(q)], we have
−ε˜qT [g(qd) −g(q)] ≤
−ε˜qT [g(qd) −g(q)]

≤ε ∥˜q∥∥g(qd) −g(q)∥
≤εkg ∥˜q∥2
(15.25)
where we used Property 4.3, i.e. that ∥g(x) −g(y)∥≤kg ∥x −y∥.
Finally, for the term −˙ε˜qT M(q) ˙q, we have
−˙ε˜qT M(q) ˙q ≤
−˙ε˜qT M(q) ˙q

=

ε0
∥˜q∥(1 + ∥˜q∥)2 ˜qT ˙q˜qTM(q) ˙q

≤
ε0
∥˜q∥(1 + ∥˜q∥)2 ∥˜q∥∥˙q∥∥˜q∥∥M(q) ˙q∥
≤
ε0
1 + ∥˜q∥∥˙q∥2 λMax{M(q)}
≤ε0λMax{M} ∥˙q∥2
(15.26)
where we considered again the deﬁnition of ε in (15.22) and Property 4.1, i.e.
that λMax{M} ∥˙q∥≥λMax{M(q)} ∥˙q∥≥∥M(q) ˙q∥.
From the inequalities (15.24), (15.25) and (15.26), it follows that the time
derivative ˙V (˜q, ˙q, ˜θ) in (15.23) reduces to
˙V (˜q, ˙q, ˜θ) ≤−˙qTKv ˙q + ε ˙qTM(q) ˙q −ε˜qTKp˜q + ε˜qTKv ˙q
+ ε0kC1 ∥˙q∥2 + εkg ∥˜q∥2 + ε0λMax{M} ∥˙q∥2 .
which in turn may be rewritten as
˙V (˜q, ˙q, ˜θ) ≤−
⎡
⎣
˜q
˙q
⎤
⎦
T ⎡
⎣
εKp
−ε
2Kv
−ε
2Kv
1
2Kv
⎤
⎦
⎡
⎣
˜q
˙q
⎤
⎦+ εkg ∥˜q∥2
−1
2 [λmin{Kv} −2ε0(kC1 + 2λMax{M})] ∥˙q∥2 , (15.27)

346
15 PD Control with Adaptive Desired Gravity Compensation
where we used −˙qTKv ˙q ≤−1
2 ˙qTKv ˙q −λmin{Kv}
2
∥˙q∥2 and ε ˙qTM(q) ˙q ≤
ε0λMax{M} ∥˙q∥2. Finally, from (15.27) we get
˙V (˜q, ˙q, ˜θ) ≤−ε
⎡
⎣
∥˜q∥
∥˙q∥
⎤
⎦
T
Q
$
%"
#
⎡
⎢⎣
λmin{Kp} −kg
−1
2λMax{Kv}
−1
2λMax{Kv}
1
2ε0 λmin{Kv}
⎤
⎥⎦
⎡
⎣
∥˜q∥
∥˙q∥
⎤
⎦
−1
2 [λmin{Kv} −2ε0(kC1 + 2λMax{M})]
"
#$
%
δ
∥˙q∥2 .
(15.28)
From the inequality above, we may determine immediately the conditions
for ε0 to ensure that ˙V (˜q, ˙q, ˜θ) is a negative semideﬁnite function. For this,
we require ﬁrst to guarantee that the matrix Q is positive deﬁnite and that
δ > 0. The matrix Q is positive deﬁnite if
λmin{Kp} > kg
(15.29)
2λmin{Kv}(λmin{Kp} −kg)
λ2
Max{Kv}
> ε0
while δ > 0 if
λmin{Kv}
2(kC1 + 2λMax{M}) > ε0 .
(15.30)
Observe that the three conditions (15.29)–(15.30) are satisﬁed since by
hypothesis the matrix Kp and the constant ε0 verify conditions C.1 and C.3–
C.4 respectively. Therefore, the matrix Q is symmetric positive deﬁnite which
means that λmin{Q} > 0.
Next, invoking the theorem of Rayleigh–Ritz (cf. page 24), we obtain
−ε
⎡
⎣
∥˜q∥
∥˙q∥
⎤
⎦
T
Q
$
%"
#
⎡
⎢⎣
λmin{Kp} −kg
−1
2λMax{Kv}
−1
2λMax{Kv}
1
2ε0 λmin{Kv}
⎤
⎥⎦
⎡
⎣
∥˜q∥
∥˙q∥
⎤
⎦≤
−ελmin{Q}

∥˜q∥2 + ∥˙q∥2
.
Incorporating this inequality in (15.28) and using the deﬁnition of ε we
obtain
˙V (˜q, ˙q, ˜θ) ≤−
ε0
1 + ∥˜q∥λmin{Q}

∥˜q∥2 + ∥˙q∥2
−δ
2∥˙q∥2
≤−ε0λmin{Q} ∥˜q∥2
1 + ∥˜q∥−δ
2∥˙q∥2 .
(15.31)

15.2 Stability Analysis
347
Therefore, it appears that ˙V (˜q, ˙q, ˜θ) expressed in (15.31), is a globally neg-
ative semideﬁnite function. Since moreover the Lyapunov function candidate
(15.18) is globally positive deﬁnite, Theorem 2.3 allows one to guarantee that
the origin of the state space of the closed-loop Equation (15.17) is stable and
in particular that its solutions are bounded, that is,
˜q, ˙q ∈Ln
∞,
(15.32)
˜θ ∈Lm
∞.
Since ˙V (˜q, ˙q, ˜θ) obtained in (15.31) is not negative deﬁnite we may not
conclude yet that the origin is an asymptotically stable equilibrium point.
Hence, from the analysis presented so far it is not possible yet to conclude
anything about the achievement of the position control objective. For this it
is necessary to make some additional claims.
The idea consists in using Lemma A.5 (cf. page 392) which establishes
that if a continuously diﬀerentiable function f : IR+ →IRn satisﬁes f ∈Ln
2
and f, ˙f ∈Ln
∞then limt→∞f(t) = 0 ∈IRn.
Hence, if we wish to show that limt→∞˜q(t) = 0 ∈IRn, and we know from
(15.32) that ˜q ∈Ln
∞and ˙˜q = −˙q ∈Ln
∞, it is only left to prove that ˜q ∈Ln
2,
that is, to verify the existence of a ﬁnite positive constant k such that
k ≥
 ∞
0
∥˜q(t)∥2 dt .
This proof is developed below.
Since δ
2 ∥˙q∥2 ≥0 for all ˙q ∈IRn then, from (15.31), the following inequality
holds:
d
dtV (˜q(t), ˙q(t), ˜θ(t)) ≤−ε0λmin{Q} ∥˜q(t)∥2
1 + ∥˜q(t)∥.
(15.33)
The next step consists in integrating the inequality (15.33) from t = 0 to
t = ∞, that is1
 V∞
V0
dV ≤−ε0λmin{Q}
 ∞
0
∥˜q(t)∥2
1 + ∥˜q(t)∥dt
where we deﬁned V0 := V (0, ˜q(0), ˙q(0), ˜θ(0)) and
1 Recall that for functions g(t) and f(t) continuous in a ≤t ≤b, satisfying g(t) ≤
f(t) for all a ≤t ≤b, we have
 b
a
g(t) dt ≤
 b
a
f(t) dt .

348
15 PD Control with Adaptive Desired Gravity Compensation
V∞:= lim
t→∞V (˜q(t), ˙q(t), ˜θ(t)) .
The integral on the left-hand side of the inequality above may be trivially
evaluated to obtain
V∞−V0 ≤−ε0λmin{Q}
 ∞
0
∥˜q(t)∥2
1 + ∥˜q(t)∥dt ,
or in equivalent form
−V0 ≤−ε0λmin{Q}
 ∞
0
∥˜q(t)∥2
1 + ∥˜q(t)∥dt −V∞.
(15.34)
Here it is worth recalling that the Lyapunov function candidate V (˜q, ˙˜q, ˜θ)
is positive deﬁnite, hence we may claim that V∞≥0 and therefore, from the
inequality (15.34) we get
−V0 ≤−ε0λmin{Q}
 ∞
0
∥˜q(t)∥2
1 + ∥˜q(t)∥dt .
From the latter expression it readily follows that
V0
ε0λmin{Q} ≥
 ∞
0
∥˜q(t)∥2
1 + ∥˜q(t)∥dt ,
where the left-hand side of the inequality above is constant, positive and
bounded. This means that the position error ˜q divided by

1 + ∥˜q∥belongs
to the Ln
2 space, i.e.
˜q

1 + ∥˜q∥
∈Ln
2 .
(15.35)
Next, we use Lemma A.7. To that end, we express the position error ˜q as
the product of two functions in the following manner:
˜q =

1 + ∥˜q∥

"
#$
%
h
'
˜q

1 + ∥˜q∥
(
"
#$
%
f
.
As we showed in (15.32), the position error ˜q belongs to the Ln
∞space and
therefore,

1 + ∥˜q∥∈L∞. On the other hand in (15.35) we concluded that
the other factor belongs to the space Ln
2, hence ˜q is the product of a bounded
function times another which belongs to Ln
2. Using this and Lemma A.7 we
obtain
˜q ∈Ln
2,

15.3 Examples
349
which is what we wanted to prove .
Thus, from ˜q ∈Ln
2, (15.32) and Lemma A.5 we conclude that the position
error ˜q tends asymptotically to the zero vector, i.e.
lim
t→∞˜q(t) = 0 ∈IRn .
In words, the position control objective is achieved.
Invoking some additional arguments it may be veriﬁed that not only the
position error ˜q tends to zero asymptotically, but so does the velocity ˙q.
Nevertheless, these conclusions should not be extrapolated to the parametric
errors ˜θ(t).
Thus, from the previous analysis we conclude that in general, the origin of
the closed-loop Equation (15.17) may not be an asymptotically stable equi-
librium point, not even locally. Nevertheless, as has been demonstrated the
position control objective is guaranteed.
15.3 Examples
We present two examples that illustrate the application of PD control with
adaptive desired gravity compensation.
Example 15.1. Consider the model of a pendulum of mass m, inertia
J with respect to the axis of rotation, and distance l from the axis
of rotation to the center of mass. A torque τ is applied at the axis of
rotation, that is,
J ¨q + mgl sin(q) = τ .
We clearly identify M(q) = J, C(q, ˙q) = 0 and g(q) = mgl sin(q).
In Example 14.8 we stated the following control problem. Assume
that the values of mass m, distance l and gravity acceleration g, are
known but that the value of the inertia J is unknown (but constant).
The control problem consists now in designing a controller that is
capable of satisfying the position control objective
lim
t→∞q(t) = qd ∈IR
for any desired constant joint position qd.
We may try to solve this control problem by means of PD control
with adaptive desired gravity compensation. The parameter of interest
that has been assumed unknown is the inertia J.
The parameterization corresponding to (15.2) is, in this example:

350
15 PD Control with Adaptive Desired Gravity Compensation
M(q, θ)u + C(q, w, θ)v + g(q, θ)
= Ju + mgl sin(q)
= Φ(q, u, v, w)θ + M0(q)u + C0(q, w)v + g0(q),
where
Φ(q, u, v, w) = u
θ = J
M0(q) = 0
C0(q, ˙q) = 0
g0(q) = mgl sin(q) .
Notice that according to the deﬁnition of Φg(x) we have
Φg(x) = Φ(x, 0, 0, 0) = 0
for all x ∈IR.
Therefore, the adaptive control law given by Equations (15.10) and
(15.11) becomes
τ = kp˜q −kv ˙q + Φg(qd)ˆθ + g0(qd)
= kp˜q −kv ˙q + mgl sin(qd)
and
ˆθ(t) = γΦg(qd)
 t
0

ε0
1 + ∥˜q∥˜q −˙q

ds + ˆθ(0)
= ˆθ(0) .
As the reader may notice not without surprise, the design of the
PD controller with adaptive desired gravity compensation yields a
non-adaptive controller (observe that the control law does not depend
on the adaptive parameter ˆθ and consequently, there does not exist
any adaptive law). Therefore, it simply corresponds to PD control
with desired gravity compensation. This is because the parametric
uncertainty in the model of the pendulum considers only the inertia
J, otherwise the component g(q) = mgl sin(q) is completely known
and therefore, the control problem that has been formulated may be
solved directly for instance by the PD control law with desired gravity
compensation, that is without appealing to any concept from adaptive
control theory. Nevertheless, the control problem might not be solvable
by PD control with desired gravity compensation if for example, the
mass m were unknown. This interesting scenario is left as a problem
at the end of the chapter.

15.3 Examples
351
Recall that condition C.1 establishes that the gain kp must be
larger than kg; in this example, kg ≥mgl. This is a suﬃcient condi-
tion to guarantee global asymptotic stability for the origin of a PD
control with desired gravity compensation in closed loop with an ideal
pendulum (see Chapter 8).
The moral of this example is signiﬁcant: the application of adaptive
controllers in the case of parametric uncertainty in the system must
be carefully evaluated. As the control problem of this example shows
adaptive control approaches are unnecessary in some cases.
♦
We present next the design of PD control with adaptive compensation for
the Pelican robot presented in Chapter 5. The reader should notice that the
resulting adaptive controller is more complex than in the previous example.
Example 15.2. Consider the Pelican robot studied in Chapter 5 and
shown in Figure 5.2. Its dynamic model is recalled here for conve-
nience:

M11(q)
M12(q)
M21(q)
M22(q)

"
#$
%
M(q)
¨q +

C11(q, ˙q)
C12(q, ˙q)
C21(q, ˙q)
C22(q, ˙q)

"
#$
%
C(q, ˙q)
˙q +

g1(q)
g2(q)

"
#$
%
g(q)
= τ
where
M11(q) = m1l2
c1 + m2

l2
1 + l2
c2 + 2l1lc2 cos(q2)

+ I1 + I2
M12(q) = m2

l2
c2 + l1lc2 cos(q2)

+ I2
M21(q) = m2

l2
c2 + l1lc2 cos(q2)

+ I2
M22(q) = m2l2
c2 + I2
C11(q, ˙q) = −m2l1lc2 sin(q2) ˙q2
C12(q, ˙q) = −m2l1lc2 sin(q2) [ ˙q1 + ˙q2]
C21(q, ˙q) = m2l1lc2 sin(q2) ˙q1
C22(q, ˙q) = 0
g1(q) = [m1lc1 + m2l1] g sin(q1) + m2lc2g sin(q1 + q2)
g2(q) = m2lc2g sin(q1 + q2) .
For this example we consider parametric uncertainty in the mass
m2, the inertia I2 and in the location of the center of mass lc2 of the
second link; that is, the numerical values of these constants are not
known exactly. Nevertheless, we assume we know upper-bounds on
these constants, and they are denoted by m2, I2 and lc2 respectively,
that is,

352
15 PD Control with Adaptive Desired Gravity Compensation
m2 ≤m2;
I2 ≤I2;
lc2 ≤lc2 .
The control problem consists in driving asymptotically to zero the
position error ˜q(t) for any constant vector of desired joint positions
qd(t). Notice that in view of the supposed parametric uncertainty, the
solution of the control problem is not trivial. In particular, the lack of
knowledge of m2 and lc2 has a direct impact on the uncertainty in the
vector of gravitational torques g(q). The solution that we give below
is based on PD control with adaptive desired gravity compensation.
The robot considered here, including parametric uncertainty, was
analyzed in Example 14.7 where we used the (unknown) dynamic pa-
rameters vector θ ∈IR3,
θ =
⎡
⎣
θ1
θ2
θ3
⎤
⎦=
⎡
⎣
m2
m2lc2
m2l2
c2 + I2
⎤
⎦.
The structure of the PD control law with adaptive desired gravity
compensation is given by (15.10)–(15.11), i.e.
τ = Kp˜q −Kv ˙q + Φg(qd)ˆθ + g0(qd)
ˆθ(t) = ΓΦg(qd)T
 t
0

ε0
1 + ∥˜q∥˜q −˙q

ds + ˆθ(0)
where Kp, Kv ∈IRn×n and Γ ∈IRm×m are symmetric positive deﬁnite
design matrices and ε0 is a positive constant, which must be chosen
appropriately. The vector g0(q) was obtained previously for the robot
considered here, in Example 14.7, as
g0(qd) =

m1lc1g sin(qd1)
0

.
In Example 14.7 we determined Φ(q, u, v, w). Therefore, the matrix
Φg(qd) follows from (15.5) as
Φg(qd) = Φ(qd, 0, 0, 0)
=

l1g sin(qd1)
g sin(qd1 + qd2)
0
0
g sin(qd1 + qd2)
0

.
Once the structure of the controller has been deﬁned, we proceed
to determine its parameters. For this, we see that we need to compute
the matrices Kp and Kv, as well as the constant ε0 in accordance with
conditions C.1 through C.4 (cf. page 340). To that end, we ﬁrst need
to determine the numerical values of the constants λMax{M}, kC1 and
kg which must satisfy

15.3 Examples
353
•λMax{M(q, θ)} ≤λMax{M}
∀q ∈IRn,
θ ∈Ω
• ∥C(q, ˙q, θ)∥≤kC1 ∥˙q∥
∀q, ˙q ∈IRn,
θ ∈Ω
• ∥g(x, θ) −g(y, θ)∥≤kg ∥x −y∥∀x, y ∈IRn, θ ∈Ω.
Therefore, it appears necessary to characterize the set Ω⊂IR3 to
which belongs the vector of unknown dynamic parameters θ. This can
be done by using the upper-bounds m2, I2 and lc2 which are assumed
to be known. The set Ωis then given by
Ω=
⎧
⎨
⎩
⎡
⎣
x1
x2
x3
⎤
⎦∈IR3 : |x1| ≤m2; |x2| ≤m2lc2; |x3| ≤m2lc2
2 + I2
⎫
⎬
⎭.
Expressions for the constants λMax{M}, kC1 and kg were obtained
for the robot under study, in Chapter 5. In the case of parametric
uncertainty considered here, such expressions are
λMax{M} ≥m1l2
c1 + m2

l2
1 + 2lc2
2 + 3lc1lc2

+ I1 + I2
kC1 ≥n2m2l1lc2
kg ≥n

m1lc1 + m2l1 + m2lc2

g .
Considering the numerical values shown in Table 5.1 of Chapter 5,
and ﬁxing the following values for the bounds,
m2 = 2.898
[kg]
I2 = 0.0125

kg m2
lc2 = 0.02862
[m],
we ﬁnally obtain the values:
λMax{M} = 0.475

kg m2
kC1 = 0.086

kg m2
kg = 28.99

kg m2/s2
.
The next step consists in using the previous information together
with conditions C.1 through C.4 (cf. page 340) to calculate the matri-
ces Kp, Kv and the constants ε0 and ε2. As a matter of fact we may
simply choose Kp so as to satisfy condition C.1, any positive deﬁnite
matrix Kv and any constant ε2 strictly larger than two. Finally, using
conditions C.2 through C.4 we obtain ε0. The choice of the latter is
detailed below.
Condition C.1 establishes the inequality
λmin{Kp} > kg

354
15 PD Control with Adaptive Desired Gravity Compensation
where kg = 28.99. Hence the matrix Kp = diag{kp} = diag{30}
satisﬁes such a condition.
The matrix Kv is chosen arbitrarily but of course it must be
symmetric positive deﬁnite. For instance, we may ﬁx it at Kv =
diag{kv} = diag{7, 3}.
Next, we choose ε1 in accordance with the inequality (15.13), that
is,
2λmin{Kp}
kg
> ε1 > 2,
where for instance, ε1 = 2.01 is an appropriate value. The constant ε2
is determined from the deﬁnition (15.12), that is,
ε2 =
2ε1
ε1 −2,
so we get ε2 = 402 .
Using all this information, we immediately verify that
-
2λmin{Kp}
ε2λMax{M} = 0.561
2λmin{Kv}[λmin{Kp} −kg]
λ2
Max{Kv}
= 0.124
λmin{Kv}
2 [kC1 + 2λMax{M}] = 1.448
According to conditions C.2 through C.4, the positive constant ε0
must be strictly smaller than the previous quantities. Therefore, we
choose ε0 = 0.12.
The adaptation gains matrix Γ must be symmetric positive def-
inite. A choice is Γ = diag{γ1, γ2} = diag{500, 10}. The vector of
initial adaptive parameters is arbitrary, and here it is taken to be zero:
ˆθ(0) = 0.
In summary, the control law may be written as
τ1 = kp˜q1 −kv ˙q1 + l1g sin(qd1)ˆθ1 + g sin(qd1 + qd2)ˆθ2
+ m1lc1g sin(qd1)
τ2 = kp˜q2 −kv ˙q2 + g sin(qd1 + qd2)ˆθ2 .
Notice that the control law does not depend on the adaptive pa-
rameter ˆθ3. This is because the vector of gravitational torques g(q)
does not depend explicitly on the dynamic parameter θ3 = m2l2
c2 +I2.
Consequently, the adaptive law has only the following two components
instead of three:

15.3 Examples
355
ˆθ1(t) = γ1l1g sin(qd1)
 t
0

ε0
1 + ∥˜q∥˜q1 −˙q1

ds + ˆθ1(0)
ˆθ2(t) = γ2g sin(qd1 + qd2)
 t
0

ε0
1 + ∥˜q∥˜q1 −˙q1

ds
+ γ2g sin(qd1 + qd2)
 t
0

ε0
1 + ∥˜q∥˜q2 −˙q2

ds + ˆθ2(0) .
We describe next the laboratory experimental results. The initial
conditions corresponding to the positions and velocities, are chosen as
q1(0) = 0,
q2(0) = 0
˙q1(0) = 0,
˙q2(0) = 0 .
The desired joint positions are chosen as
qd1 = π/10,
qd2 = π/30
[rad] .
In terms of the state vector of the closed-loop equation, the initial
state is
⎡
⎣
˜q(0)
˙q(0)
⎤
⎦=
⎡
⎢⎣
π/10
π/30
0
0
⎤
⎥⎦=
⎡
⎢⎣
0.3141
0.1047
0
0
⎤
⎥⎦
[rad] .
0.0
12.5
25.0
37.5
50.0
−0.1
0.0
0.1
0.2
0.3
0.4
[rad]
˜q1
˜q2
t [s]
.......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 15.1. Graphs of position errors ˜q1 and ˜q2
Figures 15.1 and 15.2 present the experimental results. In particu-
lar, Figure 15.1 shows that the components of the position error ˜q(t)
tend asymptotically to zero in spite of the non-modeled friction phe-
nomenon. The evolution in time of the adaptive parameters is shown

356
15 PD Control with Adaptive Desired Gravity Compensation
0.0
12.5
25.0
37.5
50.0
−10.0
−7.5
−5.0
−2.5
0.0
2.5
5.0
7.5
10.0
ˆθ1
3.2902
0.1648
ˆθ2
t [s]
.........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
.............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 15.2. Graphs of adaptive parameters ˆθ1 and ˆθ2
in Figure 15.2 where we appreciate that both parameters tend to val-
ues which are relatively near the unknown values of θ1 and θ2, i.e.
lim
t→∞
 ˆθ1(t)
ˆθ2(t)

=

3.2902
0.1648

≈

θ1
θ2

=

m2
m2lc2

=

2.0458
0.047

.
As mentioned in Chapter 14 the latter phenomenon, i.e. that ˆθ(t) →
θ as t →∞is called parametric convergence and the proof of this
property relies on a property called persistency of excitation. Verifying
this property in applications is in general a diﬃcult task and as a
matter of fact, often in complex (nonlinear) adaptive control systems
it may be expected that parameters do not converge to their true
values.
Similarly as for PID control, it may be appreciated from Figure
15.1 that the temporal evolution of the position errors is slow. Note
that the timescale spans 50 s. Hence, as for the case of PID control
the transient response here is slower than that under PD control with
gravity compensation (see Figure 7.3) or PD control with desired grav-
ity compensation (see Figure 8.4). As before, if instead of limiting the
value of ε0 we use the same gains as for the latter controllers, the
performance is improved, as can be appreciated from Figure 15.3. For
this, we set the gains to
Kp =

30
0
0
30

[Nm/rad] ,
Kv =

7
0
0
3

[Nm s/rad] ,
Γ =

500
0
0
10

[Nm/rad s] ,

15.4 Conclusions
357
and ε0 = 5, i.e. Kp and Kv have the same values as for the PD
controllers.
0.0
0.5
1.0
1.5
2.0
−0.1
0.0
0.1
0.2
0.3
0.4
[rad]
˜q1
˜q2
t [s]
.............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 15.3. Graphs of position errors ˜q1 and ˜q2
0.0
0.5
1.0
1.5
2.0
−10.0
−7.5
−5.0
−2.5
0.0
2.5
5.0
7.5
10.0
ˆθ1
2.9053
0.1942
ˆθ2
t [s]
............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
...............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 15.4. Graphs of adaptive parameters ˆθ1 and ˆθ2
♦
15.4 Conclusions
We may draw the following conclusions from the analysis presented in this
chapter.

358
15 PD Control with Adaptive Desired Gravity Compensation
Consider the PD control law with adaptive desired compensation gravity
of robots with n revolute rigid joints.
•
Assume that the desired position qd is constant.
•
Assume that the symmetric matrices Kp and Kv of the control law satisfy
•
λMax{Kp} ≥λmin{Kp} > kg
•
Kv > 0.
Choose the constants ε1 and ε2 in accordance with
2λmin{Kp}
kg
> ε1 > 2,
ε2 =
2ε1
ε1 −2 .
If the symmetric matrix Γ and the constant ε0 from the adaptive law
satisfy
•
Γ > 0
•
-
2λmin{Kp}
ε2λMax{M} > ε0
•
2λmin{Kv}[λmin{Kp} −kg]
λ2
Max{Kv}
> ε0
•
λmin{Kv}
2 [kC1 + 2λMax{M}] > ε0,
then the origin of the closed-loop equation expressed in terms of the state
vector

˜qT
˙qT
˜θ
T T
, is a stable equilibrium. Moreover, the position con-
trol objective is achieved globally. In particular we have limt→∞˜q(t) = 0
for all initial condition

˜q(0)T
˙q(0)T
˜θ(0)T T
∈IR2n+m.
Bibliography
The material of this chapter has been adapted from
•
Kelly R., 1993, “Comments on ‘Adaptive PD controller for robot manipu-
lators’ ”, IEEE Transactions on Robotics and Automation, Vol. 9, No. 1,
p. 117–119.
The Lyapunov function (15.18) follows the ideas reported in

Problems
359
•
Whitcomb L. L., Rizzi A., Koditschek D. E., 1993, “Comparative experi-
ments with a new adaptive controller for robot arms”, IEEE Transactions
on Robotics and Automation, Vol. 9, No. 1, p. 59–70.
An adaptive version of PD control with gravity compensation has been
presented in
•
Tomei P., 1991, “Adaptive PD controller for robot manipulators”, IEEE
Transactions on Robotics and Automation, Vol. 7, No. 4, p. 565–570.
Problems
1. Consider the Example 15.1. In this example we assumed uncertainty in the
inertia J. Obtain explicitly the control and adaptive laws corresponding
to PD control with adaptive desired compensation assuming now that the
uncertainty is on the mass m.
2. Show that the PD control law with adaptive desired gravity compensation,
given by (15.10)–(15.11), may be written as a controller of type PID with
“normalized” integral action, that is,
τ = KP ˜q −Kv ˙q + Ki
 t
0
˜q
1 + ∥˜q∥ds
where we deﬁned
KP = Kp + Φg(qd)ΓΦg(qd)T
Ki = ε0Φg(qd)ΓΦg(qd)T
Φg(qd)ˆθ(0) = −g0(qd) .

16
PD Control with Adaptive Compensation
As mentioned in Chapter 11, in 1987 an adaptive control system – control
law and adaptive law – was proposed to solve the motion control problem for
robot manipulators under parameter uncertainty and, since then, this control
scheme has become increasingly popular in the study of robot control. This is
the so-called adaptive controller of Slotine and Li. In Chapter 11 we present
the ‘non-adaptive’ version of this controller, which we have called, PD control
with compensation. In the present chapter we study the same control law in
its original form, i.e. with adaptation. As usual, related references are cited
at the end of the chapter.
In Chapter 11 we showed that in the scenario that the dynamic robot
model is exactly known, that is, both its structure and its dynamic parame-
ters are known, this control law may be used to achieve the motion control
objective, globally; moreover, with a trivial choice of design parameters.
In this chapter we consider the case where the dynamic parameters are
unknown but constant.
16.1 The Control and Adaptive Laws
First, it is worth recalling that the PD control law with compensation is given
by (11.1), i.e.
τ = Kp˜q + Kv ˙˜q + M(q)

¨qd + Λ ˙˜q

+ C(q, ˙q) [ ˙qd + Λ˜q] + g(q),
(16.1)
where Kp, Kv ∈IRn×n are symmetric positive deﬁnite design matrices, ˜q =
qd −q denotes the position error, and Λ is deﬁned as
Λ = Kv
−1Kp .

362
16 PD Control with Adaptive Compensation
Notice that Λ is the product of two symmetric positive deﬁnite matrices.
Even though it is not necessarily symmetric nor positive deﬁnite, it is always
nonsingular. This property of Λ is used below.
Next, it is worth recalling Property 14.1, which establishes that the dy-
namic model of an n-DOF robot (with manipulated load included) may be
written according with the parameterization (14.9), i.e.
M(q, θ)u + C(q, w, θ)v + g(q, θ)
= Φ(q, u, v, w)θ + M0(q)u + C0(q, w)v + g0(q)
where Φ(q, u, v, w) ∈IRn×m, M0(q) ∈IRn×n, C0(q, w) ∈IRn×n, g0(q) ∈IRn
and θ ∈IRm. The vector θ, referred to as the vector of dynamic parameters,
contains elements that depend precisely on the dynamic parameters of the
manipulator and on the manipulated load. The matrices M0(q), C0(q, w)
and the vector g0(q) represent parts of the matrices M(q), C(q, ˙q) and of
the vector g(q) that do not depend on the vector of dynamic parameters θ
respectively.
By virtue of the previous fact, notice that the following holds:
M(q, θ)

¨qd + Λ ˙˜q

+ C(q, ˙q, θ) [ ˙qd + Λ˜q] + g(q, θ)
= Φ(q, ¨qd + Λ ˙˜q, ˙qd + Λ˜q, ˙q)θ + M0(q)

¨qd + Λ ˙˜q

+C0(q, ˙q) [ ˙qd + Λ˜q] + g0(q),
(16.2)
where we deﬁned
u = ¨qd + Λ ˙˜q
v = ˙qd + Λ˜q
w = ˙q .
On the other hand, from (14.10) we conclude that for any vector ˆθ ∈IRm,
M(q, ˆθ)

¨qd + Λ ˙˜q

+ C(q, ˙q, ˆθ) [ ˙qd + Λ˜q] + g(q, ˆθ)
= Φ(q, ¨qd + Λ ˙˜q, ˙qd + Λ˜q, ˙q)ˆθ + M0(q)

¨qd + Λ ˙˜q

+C0(q, ˙q) [ ˙qd + Λ˜q] + g0(q) .
(16.3)
For notational simplicity, in the sequel we use the abbreviation
Φ = Φ(q, ¨qd + Λ ˙˜q, ˙qd + Λ˜q, ˙q) .
Considering (16.2), the PD control law with compensation, (16.1) may also
be written as

16.1 The Control and Adaptive Laws
363
τ = Kp˜q+Kv ˙˜q+Φθ+M0(q)

¨qd + Λ ˙˜q

+C0(q, ˙q) [ ˙qd + Λ˜q]+g0(q) . (16.4)
It is important to emphasize that the realization of the PD control law
with compensation, (16.1), or equivalently (16.4), requires knowledge of the
dynamic parameters of the robot, including the manipulated load, i.e. θ. In
the sequel, we assume that the vector θ ∈IRm of dynamic parameters is
unknown but constant. Of course, in this scenario, the control law (16.4) may
not be implemented. Therefore, the solution considered in this chapter for
the formulated control problem consists in applying PD control with adaptive
compensation.
As is explained in Chapter 14, the structure of the adaptive controllers for
motion control of robot manipulators that are studied in this text are of the
form (14.19) with an adaptive law (14.20), i.e.1
τ = τ
+
t, q, ˙q, qd, ˙qd, ¨qd, ˆθ
,
(16.5)
ˆθ(t) = Γ
 t
0
ψ (s, q, ˙q, qd, ˙qd, ¨qd) ds + ˆθ(0)
(16.6)
where Γ = Γ T ∈IRm×m (adaptive gain) and ˆθ(0) ∈IRm are design parame-
ters while ψ is a vectorial function of dimension m to be determined.
The PD control law with adaptive compensation is given by (16.5)–(16.6)
where
τ = Kp˜q + Kv ˙˜q + M(q, ˆθ)

¨qd + Λ ˙˜q

+ C(q, ˙q, ˆθ) [ ˙qd + Λ˜q]
+g(q, ˆθ)
(16.7)
= Kp˜q + Kv ˙˜q + Φˆθ + M0(q)

¨qd + Λ ˙˜q

+ C0(q, ˙q) [ ˙qd + Λ˜q]
+g0(q),
(16.8)
and
ˆθ(t) = Γ
 t
0
ΦT 
˙˜q + Λ˜q

ds + ˆθ(0),
(16.9)
where Kp, Kv ∈IRn×n and Γ ∈IRm×m are symmetric positive deﬁnite design
matrices. The pass from (16.7) to (16.8) follows by using (16.3). It is assumed
that the centrifugal and Coriolis forces matrix C(q, ˙q, θ) is chosen by means
of the Christoﬀel symbols (cf. Equation 3.21).
Notice that the control law (16.8) does not depend on the dynamic param-
eters θ but on the adaptive parameters ˆθ, which in turn, are obtained from
the adaptive law (16.9), which of course, does not depend on θ either.
1 In (16.6) as in other integrals throughout the chapter, we avoid the correct but
cumbersome notation   (s, (s), ˙(s), d(s), ˙d(s), ¨d(s)).

364
16 PD Control with Adaptive Compensation
Before proceeding to derive the closed-loop equation we ﬁrst write the
parametric errors vector ˜θ ∈IRm as
˜θ = ˆθ −θ.
(16.10)
The parametric errors vector ˜θ is unknown since it is a function of the vector
of dynamic parameters θ that has been assumed to be unknown. Nevertheless,
the parametric error ˜θ is introduced only with analytic purposes, and it is not
used by the controller.
From the deﬁnition of the parametric errors vector ˜θ in (16.10), it may be
veriﬁed that
Φˆθ = Φ˜θ + Φθ
= Φ˜θ + M(q, θ)

¨qd + Λ ˙˜q

+ C(q, ˙q, θ) [ ˙qd + Λ˜q] + g(q, θ)
−M0(q)

¨qd + Λ ˙˜q

−C0(q, ˙q) [ ˙qd + Λ˜q] −g0(q)
where we used (16.2).
Making use of this last expression, the control law (16.8) takes the form
τ = Kp˜q + Kv ˙˜q + Φ˜θ
+M(q, θ)

¨qd + Λ ˙˜q

+ C(q, ˙q, θ) [ ˙qd + Λ˜q] + g(q, θ) .
Using the control law expressed above and substituting the control action
τ in the equation of the robot model (14.2), we get
M(q, θ)

¨˜q + Λ ˙˜q

+ C(q, ˙q, θ)

˙˜q + Λ˜q

= −Kp˜q −Kv ˙˜q −Φ˜θ .
(16.11)
On the other hand, since the vector of dynamic parameters θ has been
assumed constant, its time derivative is zero, that is ˙θ = 0 ∈IRm. Therefore,
the time derivative of the parametric errors vector ˜θ deﬁned in (16.10), satisﬁes
˙˜θ = ˙ˆθ. In turn, the time derivative of the vector of adaptive parameters ˆθ
is obtained by diﬀerentiating with respect to time the adaptive law (16.9).
Considering these facts we have
˙˜θ = ΓΦT 
˙˜q + Λ˜q

.
(16.12)
The closed-loop equation, which is formed of Equations (16.11) and
(16.12), may be written as
d
dt
⎡
⎢⎢⎢⎣
˜q
˙˜q
˜θ
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎢⎣
˙˜q
M(q, θ)−1 
−Kp˜q −Kv ˙˜q −Φ˜θ −C(q, ˙q, θ)

˙˜q + Λ˜q

−Λ ˙˜q
ΓΦT 
˙˜q + Λ˜q

⎤
⎥⎥⎥⎥⎦
,
(16.13)

16.2 Stability Analysis
365
which is a nonautonomous diﬀerential equation and the origin of the state
space, i.e.
⎡
⎢⎢⎢⎣
˜q
˙˜q
˜θ
⎤
⎥⎥⎥⎦= 0 ∈IR2n+m ,
is an equilibrium point.
16.2 Stability Analysis
The stability analysis of the origin of the state space for the closed-loop system
is carried out using the Lyapunov function candidate
V (t, ˜q, ˙˜q, ˜θ) = 1
2
⎡
⎢⎢⎢⎣
˜q
˙˜q
˜θ
⎤
⎥⎥⎥⎦
T⎡
⎢⎢⎢⎣
2Kp + ΛTM(q, θ)Λ
ΛTM(q, θ)
0
M(q, θ)Λ
M(q, θ)
0
0
0
Γ −1
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
˜q
˙˜q
˜θ
⎤
⎥⎥⎥⎦.
At ﬁrst sight, it may not appear evident that the Lyapunov function candidate
is positive deﬁnite, however, this may be clearer when rewriting it as
V (t, ˜q, ˙˜q, ˜θ) = 1
2

˙˜q + Λ˜q
T
M(q, θ)

˙˜q + Λ˜q

+ ˜qTKp˜q + 1
2
˜θ
TΓ −1˜θ . (16.14)
It is interesting to remark that the function deﬁned in (16.14) may be
regarded as an extension of the Lyapunov function (11.3) used in the study
of (nonadaptive) PD control with compensation. The only diﬀerence is the
introduction of the term 1
2 ˜θ
TΓ −1˜θ in the Lyapunov function candidate for
the adaptive version.
The time derivative of the Lyapunov function candidate (16.14) becomes
˙V (t, ˜q, ˙˜q, ˜θ) =

˙˜q + Λ˜q
T
M(q, θ)

¨˜q + Λ ˙˜q

+ 1
2

˙˜q + Λ˜q
T ˙M(q, θ)

˙˜q + Λ˜q

+ 2˜qTKp ˙˜q + ˜θ
TΓ −1 ˙˜θ .
Solving for M(q)¨˜q and ˙˜θ from the closed-loop Equation (16.13) and sub-
stituting in the previous equation, we obtain
˙V (t, ˜q, ˙˜q, ˜θ) = −

˙˜q + Λ˜q
T
Kv

˙˜q + Λ˜q

+ 2˜qT Kp ˙˜q,
where we canceled the term

366
16 PD Control with Adaptive Compensation

˙˜q + Λ˜q
T 1
2
˙M(q, θ) −C(q, ˙q, θ)
 
˙˜q + Λ˜q

by virtue of Property 4.2. Now, using Kp = KvΛ, the equation of ˙V (t, ˜q, ˙˜q, ˜θ)
reduces to
˙V (t, ˜q, ˙˜q, ˜θ) = −˙˜q
TKv ˙˜q −˜qTΛTKvΛ˜q
= −
⎡
⎢⎢⎢⎣
˜q
˙˜q
˜θ
⎤
⎥⎥⎥⎦
T ⎡
⎢⎢⎢⎣
ΛT KvΛ
0
0
0
Kv
0
0
0
0
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
˜q
˙˜q
˜θ
⎤
⎥⎥⎥⎦.
(16.15)
Recalling that Λ is a nonsingular matrix while Kv is a symmetric positive
deﬁnite matrix, it follows that the matrix ΛTKvΛ is also symmetric posi-
tive deﬁnite (cf. Lemma 2.1). Therefore, it follows that ˙V (t, ˜q, ˙˜q, ˜θ) expressed
in (16.15) is a globally negative semideﬁnite function. Since moreover the
Lyapunov function candidate (16.14) is globally positive deﬁnite, radially un-
bounded and decrescent, Theorem 2.3 guarantees that the origin of the closed-
loop Equation (16.13) is uniformly stable and all the solutions are bounded,
i.e.
˜q, ˙˜q ∈Ln
∞,
(16.16)
˜θ ∈Lm
∞.
Since ˙V (t, ˜q, ˙˜q, ˜θ) obtained in (16.15) is not negative deﬁnite, we may not
yet conclude that the origin is an asymptotically stable equilibrium point. On
the other hand, La Salle’s theorem may not be used either to show asymptotic
stability since the closed-loop Equation (16.13) is nonautonomous since it
depends implicitly on the functions qd(t) and ˆθ(t).
Thus, from the previous analysis, it is not possible yet to conclude anything
about the achievement of the motion control objective. For this, it is necessary
to present further arguments.
The idea consists in using Lemma A.5, which establishes the following.
Consider a continuously diﬀerentiable function f : IR+ →IRn which satisﬁes
•
f ∈Ln
2
•
f, ˙f ∈Ln
∞.
Then, the function f necessarily satisﬁes limt→∞f(t) = 0 ∈IRn.
Therefore, if we wish to prove that limt→∞˜q(t) = 0 ∈IRn, and we know
from (16.16) and Theorem 2.3, that ˜q, ˙˜q ∈Ln
∞, it is only left to prove that
˜q ∈Ln
2, that is, it is suﬃcient to show that there exists a ﬁnite positive
constant k such that
k ≥
 ∞
0
∥˜q(t)∥2 dt .

16.2 Stability Analysis
367
This proof is carried out below.
Since ˙˜q
TKv ˙˜q ≥0 for all ˙˜q ∈IRn, it follows from (16.15) that
d
dtV (t, ˜q(t), ˙˜q(t), ˜θ(t)) ≤−˜q(t)TΛT KvΛ˜q(t)
≤−λmin{ΛT KvΛ} ∥˜q(t)∥2
(16.17)
where we used the fact that ΛT KvΛ is a symmetric matrix and therefore (cf.
Theorem of Rayleigh–Ritz, on page 24),
˜qT 
ΛT KvΛ
 ˜q ≥λmin{ΛT KvΛ} ∥˜q∥2
for all ˜q ∈IRn. Notice that, moreover, λmin{ΛT KvΛ} > 0 since the matrix
ΛT KvΛ besides being symmetric, is also positive deﬁnite.
The next step consists in integrating the inequality (16.17) from t = 0 to
t = ∞, that is2
 V∞
V0
dV ≤−λmin{ΛT KvΛ}
 ∞
0
∥˜q(t)∥2 dt
where we deﬁned V0 := (0, ˜q(0), ˙˜q(0), ˜θ(0))
V∞:= lim
t→∞V (t, ˜q(t), ˙q(t), ˜θ(t)) .
The integral on the left-hand side of this inequality is calculated trivially to
obtain
V∞−V0 ≤−λmin{ΛT KvΛ}
 ∞
0
∥˜q(t)∥2 dt,
or in equivalent form
−V0 ≤−λmin{ΛT KvΛ}
 ∞
0
∥˜q(t)∥2 dt −V∞.
(16.18)
We recall that the Lyapunov function candidate V (t, ˜q, ˙˜q, ˜θ) is positive
deﬁnite, radially unbounded and decrescent and moreover, all the signals are
bounded. Therefore, ∞> V∞≥0 and, from Inequality (16.18), we get
2 Here we are using the following elementary facts:
 ∞
0
dV
dt dt =
 V∞
V0
dV and,
that for functions g(t) and f(t) continuous in a ≤t ≤b, satisfying g(t) ≤f(t) for
all a ≤t ≤b, we have
 b
a
g(t) dt ≤
 b
a
f(t) dt .

368
16 PD Control with Adaptive Compensation
−V0 ≤−λmin{ΛT KvΛ}
 ∞
0
∥˜q(t)∥2 dt .
From this expression we immediately conclude that
V0
λmin{ΛT KvΛ} ≥
 ∞
0
∥˜q(t)∥2 dt
where the left-hand side of the inequality is ﬁnite positive and constant. This
means that the position error ˜q belongs to the Ln
2 space which is precisely
what we wanted to prove.
Thus, according to the arguments above, we may conclude now that the
position error ˜q tends asymptotically to the zero vector, i.e.
lim
t→∞˜q(t) = 0 ∈IRn
or in words, that the motion control objective has been achieved.
Invoking further arguments one may also show that not only the position
error ˜q tends to zero asymptotically, but that so does the velocity error ˙˜q.
Nevertheless, these conclusions should not be extrapolated to the parametric
error ˜θ, unless the desired joint position qd(t) satisﬁes some special proper-
ties that are not discussed here. From these comments we conclude that, in
general, the origin of the closed-loop Equation (16.13) may not be asymptoti-
cally stable, not even locally. However, as has been demonstrated, the motion
control objective is guaranteed.
16.3 Examples
Next, we present a series of examples which illustrate the application of PD
control with adaptive compensation.
The ﬁrst example is presented as a solution to the formulated control
problem in Example 14.8.
Example 16.1. Consider the model of a pendulum of mass m, inertia
J with respect to the axis of rotation and distance l from the axis of
rotation to the center of mass. The torque τ is applied at the axis of
rotation, that is,
J ¨q + mgl sin(q) = τ .
We clearly identify M(q) = J, C(q, ˙q) = 0 and g(q) = mgl sin(q).
In Example 14.8 we formulated the following control problem. As-
sume that the values of the mass m, the distance l and the gravity
acceleration g are known but that the value of the inertia J is unknown

16.3 Examples
369
(yet constant). The control problem consists in designing a controller
that is capable of satisfying the motion control objective
lim
t→∞˜q(t) = 0 ∈IR
for any desired joint position qd(t) (with bounded ﬁrst and second
time derivatives).
The solution to this control problem may be obtained via PD con-
trol with adaptive compensation. The parameter of interest that has
been supposed unknown is the inertia J. The parameterization which
corresponds to (16.2) is, in this example,
M(q, θ)

¨qd + λ˙˜q

+ C(q, ˙q, θ) [ ˙qd + λ˜q] + g(q, θ)
= J

¨qd + λ˙˜q

+ mgl sin(q)
= Φθ + M0(q)

¨qd + λ˙˜q

+ C0(q, ˙q) [ ˙qd + λ˜q] + g0(q)
where
Φ = ¨qd + λ˙˜q
θ = J
M0(q) = 0
C0(q, ˙q) = 0
g0(q) = mgl sin(q) .
Therefore, the adaptive control system given by Equations (16.8)
and (16.9) becomes
τ = kp˜q + kv ˙˜q + Φˆθ + g0(q)
= kp˜q + kv ˙˜q +

¨qd + λ˙˜q
 ˆθ + mgl sin(q)
and
ˆθ(t) = γ
 t
0
Φ
˙˜q + λ˜q

ds + ˆθ(0)
= γ
 t
0

¨qd + λ˙˜q
 ˙˜q + λ˜q

ds + ˆθ(0),
where kp > 0, kv > 0, λ = kp/kv, γ > 0 and ˆθ(0) ∈IR. Figure 16.1
shows the block-diagram corresponding to this adaptive controller.
♦
We present next, the design of the PD control law with adaptive compen-
sation, the Slotine and Li controller, for a planar 2-DOF robot. As the reader
should notice, the resulting adaptive controller presents a higher degree of
complexity than the previous example.

370
16 PD Control with Adaptive Compensation
mgl
sin(·)
ROBOT
˙qd
¨qd
qd
Σ
Σ
Σ
Π
Σ
Σ
˙q
q
kv
kp
λ
λ
Π
Π
γ
.
τ
: multiplication operator
Figure 16.1. Block-diagram: pendulum under PD control with adaptive compen-
sation
Example 16.2. Consider the 2-DOF planar manipulator shown in Fig-
ure 16.2 and whose dynamic model is described in Example 3.3.
The dynamic model of this planar manipulator is given by (3.8)–
(3.9), and may be written as
θ1¨q1 + (θ3C21 + θ4S21) ¨q2 −θ3S21 ˙q2
2 + θ4C21 ˙q2
2 = τ1
(θ3C21 + θ4S21) ¨q1 + θ2¨q2 + θ3S21 ˙q2
1 −θ4C21 ˙q2
1 = τ2
where
θ1 = m1l2
c1 + m2l2
1 + I1
θ2 = m2l2
c2 + I2
θ3 = m2l1lc2 cos(δ)
θ4 = m2l1lc2 sin(δ) .
The four dynamic parameters θ1, θ2, θ3 and θ4 depend on the phys-
ical characteristics of the manipulator such as the masses and inertias

16.3 Examples
371
l1
q1
x
y
τ1
z
τ2
m2
I2
δ
q2
lc2
m1
I1
lc1
Figure 16.2. Planar 2-DOF manipulator
of its links. The vector of unknown constant dynamic parameters θ is
deﬁned as
θ =
⎡
⎢⎣
θ1
θ2
θ3
θ4
⎤
⎥⎦.
In Example 14.6 we obtained the parameterization (14.9) of the
dynamic model, i.e.
M(q, θ)u + C(q, w, θ)v + g(q, θ)
=

Φ11
Φ12
Φ13
Φ14
Φ21
Φ22
Φ23
Φ24

⎡
⎢⎣
θ1
θ2
θ3
θ4
⎤
⎥⎦
+M0(q)u + C0(q, w)v + g0(q)
where
Φ11 = u1
Φ12 = 0
Φ13 = C21u2 −S21w2v2
Φ14 = S21u2 + C21w2v2

372
16 PD Control with Adaptive Compensation
Φ21 = 0
Φ22 = u2
Φ23 = C21u1 + S21w1v1
Φ24 = S21u1 −C21w1v1
M0(q) = 0 ∈IR2×2
C0(q, ˙q) = 0 ∈IR2×2
g0(q) = 0 ∈IR2 .
Hence, the parameterization (16.2) yields
M(q, θ)

¨qd + Λ ˙˜q

+ C(q, ˙q, θ) [ ˙qd + Λ˜q] + g(q, θ)
=

θ1
θ3C21 + θ4S21
θ3C21 + θ4S21
θ2
 
¨qd + Λ ˙˜q

+

0
(θ4C21 −θ3S21) ˙q2
(θ3S21 −θ4C21) ˙q1
0

[˙qd + Λ˜q]
= Φθ
where this time,
u = ¨qd + Λ ˙˜q =

u1
u2

=

¨qd1 + λ11 ˙˜q1 + λ12 ˙˜q2
¨qd2 + λ21 ˙˜q1 + λ22 ˙˜q2

v = ˙qd + Λ˜q =

v1
v2

=

˙qd1 + λ11˜q1 + λ12˜q2
˙qd2 + λ21˜q1 + λ22˜q2

w = ˙q =

w1
w2

=

˙q1
˙q2

and
Λ =

λ11
λ12
λ21
λ22

∈IR2×2 .
The adaptive control system is given by Equations (16.8) and
(16.9). Notice that M0 = C0 = g0 = 0 therefore, the control law
becomes
τ = Kp˜q + Kv ˙˜q +

Φ11
Φ12
Φ13
Φ14
Φ21
Φ22
Φ23
Φ24

⎡
⎢⎢⎣
ˆθ1ˆθ2ˆθ3ˆθ4
⎤
⎥⎥⎦,
while the adaptive law is

16.3 Examples
373
⎡
⎢⎢⎢⎣
ˆθ1(t)
ˆθ2(t)
ˆθ3(t)
ˆθ4(t)
⎤
⎥⎥⎥⎦= Γ
 t
0
⎡
⎢⎢⎢⎣
Φ11[v1 −˙q1]
Φ22[v2 −˙q2]
Φ13[v1 −˙q1] + Φ23[v2 −˙q2]
Φ14[v1 −˙q1] + Φ24[v2 −˙q2]
⎤
⎥⎥⎥⎦ds +
⎡
⎢⎢⎢⎣
ˆθ1(0)
ˆθ2(0)
ˆθ3(0)
ˆθ4(0)
⎤
⎥⎥⎥⎦
where Kp = KT
p > 0, Kv = KT
v > 0, Λ = K−1
v Kp, Γ = Γ T > 0 and
ˆθ(0) ∈IRm .
♦
We end this section with an example that illustrates the performance of
PD control with adaptive compensation on the Pelican robot prototype.
l2
lc2
q2
q1
I1
m1
g
y
x
l1
m2
I2
lc1
Link 1
Link 2
Figure 16.3. Diagram of the Pelican robot
Example 16.3. Consider the Pelican robot presented in Chapter 5 and
shown in Figure 16.3. Its dynamic model is recalled below for ease of
reference:

M11(q)
M12(q)
M21(q)
M22(q)

"
#$
%
M(q)
¨q +

C11(q, ˙q)
C12(q, ˙q)
C21(q, ˙q)
C22(q, ˙q)

"
#$
%
C(q, ˙q)
˙q +

g1(q)
g2(q)

"
#$
%
g(q)
= τ
where

374
16 PD Control with Adaptive Compensation
M11(q) = m1l2
c1 + m2

l2
1 + l2
c2 + 2l1lc2 cos(q2)

+ I1 + I2
M12(q) = m2

l2
c2 + l1lc2 cos(q2)

+ I2
M21(q) = m2

l2
c2 + l1lc2 cos(q2)

+ I2
M22(q) = m2l2
c2 + I2
C11(q, ˙q) = −m2l1lc2 sin(q2) ˙q2
C12(q, ˙q) = −m2l1lc2 sin(q2) [ ˙q1 + ˙q2]
C21(q, ˙q) = m2l1lc2 sin(q2) ˙q1
C22(q, ˙q) = 0
g1(q) = [m1lc1 + m2l1] g sin(q1) + m2lc2g sin(q1 + q2)
g2(q) = m2lc2g sin(q1 + q2) .
For this example we selected as unknown parameters, the mass
m2, the inertia I2 and the distance to the center of mass, lc2.
We wish to design a controller that is capable of driving to zero
the articular position error ˜q. It is desired that the robot tracks the
trajectories qd(t), ˙qd(t) and ¨qd(t) represented by Equations (5.7)–
(5.9). To that end, we use PD control with adaptive compensation.
In Example 14.6 we derived the parameterization (14.9) of the
dynamic model, i.e.
M(q, θ)u + C(q, w, θ)v + g(q, θ)
=

Φ11
Φ12
Φ13
Φ21
Φ22
Φ23
 ⎡
⎣
θ1
θ2
θ3
⎤
⎦
+M0(q)u + C0(q, w)v + g0(q)
where
Φ11 = l2
1u1 + l1g sin(q1)
Φ12 = 2l1 cos(q2)u1 + l1 cos(q2)u2 −l1 sin(q2)w2v1
−l1 sin(q2)[w1 + w2]v2 + g sin(q1 + q2)
Φ13 = u1 + u2
Φ21 = 0
Φ22 = l1 cos(q2)u1 + l1 sin(q2)w1v1 + g sin(q1 + q2)
Φ23 = u1 + u2
θ =
⎡
⎣
θ1
θ2
θ3
⎤
⎦=
⎡
⎣
m2
m2lc2
m2l2
c2 + I2
⎤
⎦=
⎡
⎣
2.0458
0.047
0.0126
⎤
⎦
M0(q) =

m1l2
c1 + I1
0
0
0


16.3 Examples
375
C0(q, w) =

0
0
0
0

g0(q) =

m1lc1g sin(q1)
0

.
Since the numerical values of m2, I2 and lc2 are assumed unknown,
the vector of dynamic parameters θ is also unknown. This hypothesis
obviously complicates our task of designing a controller that is capable
of satisfying our control objective.
Let us now see the form that the PD control law with adaptive
compensation takes for the Pelican prototype. For this, we ﬁrst deﬁne
Λ =

λ11
λ12
λ21
λ22

∈IR2×2 .
Then, the parameterization (16.2) is simply
M(q, θ)

¨qd + Λ ˙˜q

+ C(q, ˙q, θ) [ ˙qd + Λ˜q] + g(q, θ)
= Φθ + M0(q)

¨qd + Λ ˙˜q

+ g0(q),
where
u = ¨qd + Λ ˙˜q =

u1
u2

=

¨qd1 + λ11 ˙˜q1 + λ12 ˙˜q2
¨qd2 + λ21 ˙˜q1 + λ22 ˙˜q2

v = ˙qd + Λ˜q =

v1
v2

=

˙qd1 + λ11˜q1 + λ12˜q2
˙qd2 + λ21˜q1 + λ22˜q2

w = ˙q =

w1
w2

=

˙q1
˙q2

.
The adaptive control system is given by Equations (16.8) and
(16.9). Therefore the control law becomes
τ = Kp˜q + Kv ˙˜q +

Φ11
Φ12
Φ13
Φ21
Φ22
Φ23
 ⎡
⎣
ˆθ1ˆθ2ˆθ3
⎤
⎦
+

(m1l2
c1 + I1)u1
0

+

m1lc1g sin(q1)
0

,
while the adaptive law is
⎡
⎢⎣
ˆθ1(t)
ˆθ2(t)
ˆθ3(t)
⎤
⎥⎦= Γ
 t
0
⎡
⎢⎢⎣
Φ11[v1 −˙q1]
Φ12[v1 −˙q1] + Φ22[v2 −˙q2]
Φ13[v1 −˙q1] + Φ23[v2 −˙q2]
⎤
⎥⎥⎦ds +
⎡
⎢⎣
ˆθ1(0)
ˆθ2(0)
ˆθ3(0)
⎤
⎥⎦.

376
16 PD Control with Adaptive Compensation
In this experiment the symmetric positive deﬁnite design matrices
were chosen as
Kp = diag{200, 150}
[N m/rad] ,
Kv = diag{3}
[N m s/rad] ,
Γ = diag{1.6

kg s2/m2
, 0.004

kg s2
, 0.004

kg m2 s2
},
and therefore Λ = K−1
v Kp = diag{66.6, 50} [1/s].
The corresponding initial conditions for the positions, velocities
and adaptive parameters are chosen as
q1(0) = 0,
q2(0) = 0
˙q1(0) = 0,
˙q2(0) = 0
ˆθ1(0) = 0,
ˆθ2(0) = 0
ˆθ3(0) = 0 .
0
2
4
6
8
10
−0.02
−0.01
0.00
0.01
0.02
[rad]
˜q1
˜q2
t [s]
.....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ............. ....
Figure 16.4. Graphs of position errors ˜q1 and ˜q2
Figures 16.4 and 16.5 show the experimental results. In particular,
Figure 16.4 shows the steady state tracking position errors ˜q(t), which,
by virtue of friction phenomena in the actual robot, are not zero. It is
remarkable, however, that if we take the upper-bound on the position
errors as a measure of performance, we see that the latter is better
than or similar to that of other nonadaptive control systems (compare
with Figures 10.2, 10.4, 11.3, 11.5 and 12.5).
Finally, Figure 16.5 shows the evolution in time of the adaptive
parameters. As mentioned before, these parameters were arbitrarily
assumed to be zero at the initial instant. This has been done for no
speciﬁc reason since we did not have any knowledge, a priori, about
any of the dynamic parameters θ.

Bibliography
377
0
2
4
6
8
10
0.0
0.5
1.0
1.5
2.0
2.5
3.0
ˆθ1
ˆθ2
ˆθ3
t [s]
........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............. ............. ............. ............. .............
Figure 16.5. Graphs of adaptive parameters ˆθ1, ˆθ2, and ˆθ3
♦
16.4 Conclusions
We conclude this chapter with the following remarks.
•
For PD control with adaptive compensation the origin of the state space
corresponding to the closed-loop equation, i.e.

˜qT
˙˜q
T
˜θ
T T
= 0, is
stable for any choice of symmetric positive deﬁnite matrices Kp, Kv and
Γ. Moreover, the motion control objective is achieved globally. That is,
for any initial position error ˜q(0) ∈IRn velocity error ˙˜q(0) ∈IRn, and
arbitrary uncertainty over the dynamic parameters θ ∈IRm of the robot
model, limt→∞˜q(t) = 0.
Bibliography
PD control with adaptive compensation was originally proposed in
•
Slotine J. J., Li W., 1987, “On the adaptive control of robot manipulators”,
The International Journal of Robotics Research, Vol. 6, No. 3, pp. 49–59.
This controller has also been the subject of study (among many others) in

378
16 PD Control with Adaptive Compensation
•
Slotine J. J., Li W., 1988. “Adaptive manipulator control: A case study”,
IEEE Transactions on Automatic Control, Vol. AC-33, No. 11, November,
pp. 995–1003.
•
Spong M., Vidyasagar M., 1989, “Robot dynamics and control”, John Wi-
ley and Sons.
•
Slotine J. J., Li W., 1991, “Applied nonlinear control”, Prentice-Hall.
•
Lewis F. L., Abdallah C. T., Dawson D. M., 1993, “Control of robot ma-
nipulators”, Macmillan.
The Lyapunov function (16.14) used in the stability analysis of PD control
with adaptive compensation follows
•
Spong M., Ortega R., Kelly R., 1990, “Comments on “Adaptive manipu-
lator control: A case study” ”, IEEE Transactions on Automatic Control,
Vol. 35, No. 6, June, pp. 761–762.
Example 16.2 has been adapted from Section III.B of
•
Slotine J. J., Li W., 1988. “Adaptive manipulator control: A case study”,
IEEE Transactions on Automatic Control, Vol. AC-33, No. 11, November,
pp. 995-1003.
Parameter convergence was shown in
•
J.J. Slotine and W. Li, 1987, “Theoretical issues in adaptive manipulator
control”, 5th Yale Workshop on Applied Adaptive Systems Theory, pp.
252–258.
Global uniform asymptotic stability for the closed-loop equation; in par-
ticular, uniform parameter convergence, for robots with revolute joints under
PD control with adaptive compensation, was ﬁrst shown in
•
A. Lor´ıa, R. Kelly and A. Teel, 2003, “Uniform parametric convergence
in the adaptive control of manipulators: a case restudied”, in Proceedings
of International Conference on Robotics and Automation, Taipei, Taiwan,
pp. 106–1067.
Problems
1. Consider Example 16.1 in which we studied control of the pendulum
J ¨q + mgl sin(q) = τ .

Problems
379
Supposing that the inertia J is unknown, the PD control law with adaptive
compensation is given by
τ = kp˜q + kv ˙˜q +

¨qd + λ˙˜q
 ˆθ + mgl sin(q)
ˆθ = γ
 t
0

¨qd + λ˙˜q
 ˙˜q + λ˜q

ds + ˆθ(0)
where kp > 0, kv > 0, λ = kp/kv, γ > 0 and ˆθ(0) ∈IR.
a) Obtain the closed-loop equation in terms of the state vector

˜q
˙˜q ˜θ
T
∈
IR3 where ˜θ = ˆθ −J.
b) Show that the origin of the closed-loop equation is a stable equilib-
rium, by using the following Lyapunov function candidate:
V (˜q, ˙˜q, ˜θ) = 1
2
⎡
⎢⎣
˜q
˙˜q
˜θ
⎤
⎥⎦
T⎡
⎢⎣
2kp + Iλ2 λI
0
Iλ
I
0
0
0 γ−1
⎤
⎥⎦
⎡
⎢⎣
˜q
˙˜q
˜θ
⎤
⎥⎦.
2. Consider again Example 16.1 in which we studied control of the pendulum
J ¨q + mgl sin(q) = τ .
Assume now that, in addition, the inertia J and the mass m are unknown.
Design a PD controller with adaptive compensation, i.e. give explicitly
the control and adaptive laws.
3. On pages 366–368 we showed that ˜q ∈Ln
2. Use similar arguments to prove
also that ˙˜q ∈Ln
2. May we conclude that limt→∞˙˜q(t) = 0 ?
4. Consider the 2-DOF Cartesian robot showed in Figure 16.6. The corre-
sponding dynamic model is given by M(q)¨q+g(q) = τ where q = [q1 q2]T
and
M(q) =

m1 + m2
0
0
m2

g(q) =

(m1 + m2)g
0

.
Assume that the masses m1 and m2 are constant but unknown.
a) Design a PD controller with adaptive compensation to achieve the
motion control objective. Speciﬁcally, determine the matrix Φ for the
control law and for the adaptive law
τ = Kp˜q + Kv ˙˜q + Φˆθ
ˆθ =
 t
0
ΦT 
˙˜q + Λ˜q

ds + ˆθ(0),

380
16 PD Control with Adaptive Compensation
x0
y0
z0
q1
q2
x0
y0
z0
q1
q2
m1
m2
Figure 16.6. Problem 4. Cartesian 2-DOF robot.
where
θ =
⎡
⎣
m1 + m2
(m1 + m2)g
m2
⎤
⎦.

Appendices

A
Mathematical Support
In this appendix we present additional mathematical tools that are employed
in the textbook, mainly in the advanced topics of Part IV. It is recommended
that the graduate student following these chapters read ﬁrst this appendix,
speciﬁcally the material from Section A.3 which is widely used in the text. As
for other chapters and appendices, references are provided at the end.
A.1 Some Lemmas on Linear Algebra
The following lemmas, whose proofs may be found in textbooks on linear
algebra, are used to prove certain properties of the dynamic model of the
robot stated in Chapter 4.
Lemma A.1. Consider a vector x ∈IRn. Its Euclidean norm, ∥x∥, satisﬁes
∥x∥≤n

max
i {|xi|}

.
Lemma A.2. Consider a symmetric matrix A ∈IRn×n and denote by aij its
ijth element. Let λ1{A}, · · · , λn{A} be its eigenvalues. Then, it holds that
|λk{A}| ≤n

max
i,j {|aij|}

for all k = 1, · · · , n .
Lemma A.3. Consider a symmetric matrix A = AT ∈IRn×n and denote by
aij its ijth element. The spectral norm of the matrix A, ∥A∥, induced by the
vectorial Euclidean norm satisﬁes
∥A∥=

λMax{ATA} ≤n

max
i,j {|aij|}

.

384
A Mathematical Support
We present here a useful theorem on partitioned matrices which is taken
from the literature.
Theorem A.1. Assume that a symmetric matrix is partitioned as
 A B
BT C

(A.1)
where A and C are square matrices. The matrix is positive deﬁnite if and only
if
A > 0
C −BT A−1B > 0 .
A.2 Vector Calculus
Theorem A.2. Mean-value
Consider the continuous function f : IRn →IR. If moreover f(z1, z2, · · · , zn)
has continuous partial derivatives then, for any two constant vectors x, y ∈
IRn we have
f(x) −f(y) =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
∂f(z)
∂z1
z=ξ
∂f(z)
∂z2
z=ξ
...
∂f(z)
∂zn
z=ξ
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
T
[x −y]
where ξ ∈IRn is a vector suitably chosen on the line segment which joins the
vectors x and y, i.e. which satisﬁes
ξ = y + α[x −y]
= αx + (1 −α)y
for some real α in the interval (0, 1). Notice moreover, that the norm of ξ
veriﬁes
∥ξ∥≤∥y∥+ ∥x −y∥
and also
∥ξ∥≤∥x∥+ ∥y∥.
An extension of the mean-value theorem for vectorial functions is presented
next

A Mathematical support
385
Theorem A.3. Mean-value theorem for vectorial functions
Consider the continuous vectorial function f : IRn →IRm. If fi(z1, z2, · · · , zn)
has continuous partial derivatives for i = 1, · · · , m, then for each pair of vec-
tors x, y ∈IRn and each w ∈IRm there exists ξ ∈IRn such that
[f(x) −f(y) ]T w = wT
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
∂f1( )
∂z1
 =
∂f1( )
∂z2
 =
· · ·
∂f1( )
∂zn
 =
∂f2( )
∂z1
 =
∂f2( )
∂z2
 =
· · ·
∂f2( )
∂zn
 =
...
...
...
...
∂fm( )
∂z1
 =
∂fm( )
∂z2
 =
· · · ∂fm( )
∂zn
 =
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
"
#$
%
Jacobian of f
evaluated in z = ξ
[x −y]
= wT ∂f(z)
∂z
z=ξ
[x −y]
where ξ is a vector on the line segment that joins the vectors x and y, and
consequently satisﬁes
ξ = y + α[x −y]
for some real α in the interval (0, 1).
We present next a useful corollary, which follows from the statements of
Theorems A.2 and A.3.
Corollary A.1. Consider the smooth matrix-function A : IRn →IRn×n. As-
sume that the partial derivatives of the elements of the matrix A are bounded
functions, that is, that there exists a ﬁnite constant δ such that

∂aij(z)
∂zk
z=z0
 ≤δ
for i, j, k = 1, 2, · · · , n and all vectors z0 ∈IRn .
Deﬁne now the vectorial function
[A(x) −A(y)] w,
with x, y, w ∈IRn. Then, the norm of this function satisﬁes
∥[A(x) −A(y)] w∥≤n2 max
i,j,k,z0
5
∂aij(z)
∂zk
z=z0

6
∥x −y∥∥w∥,
(A.2)
where aij(z) denotes the ijth element of the matrix A(z) while zk denotes the
kth element of the vector z ∈IRn.

386
A Mathematical Support
Proof. The proof of the corollary may be carried out by the use of Theorems
A.2 or A.3. Here we use Theorem A.2.
The norm of the vector A(x)w −A(y)w satisﬁes
∥A(x)w −A(y)w∥≤∥A(x) −A(y)∥∥w∥.
Considering Lemma A.3, we get
∥A(x)w −A(y)w∥≤n

max
i,j {|aij(x) −aij(y)|}

∥w∥.
(A.3)
On the other hand, since by hypothesis the matrix A(z) is a smooth func-
tion of its argument, its elements have continuous partial derivatives. Conse-
quently, given two constant vectors x, y ∈IRn, according to the mean-value
Theorem (cf. Theorem A.2), there exists a real number αij in the interval
[0, 1] such that
aij(x) −aij(y) =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
∂aij(z)
∂z1
z=y+αij[x−y]
∂aij(z)
∂z2
z=y+αij[x−y]
...
∂aij(z)
∂zn
z=y+αij[x−y]
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
T
[x −y].
Therefore, taking the absolute value on both sides of the previous equation
and using the triangle inequality, |aT b| ≤∥a∥∥b∥, we obtain the inequality
|aij(x) −aij(y)| ≤

∂aij(z)
∂z1
z=y+αij[x−y]
∂aij(z)
∂z2
z=y+αij[x−y]
...
∂aij(z)
∂zn
z=y+αij[x−y]

∥x −y∥
≤n
'
max
k
5
∂aij(z)
∂zk
z=y+αij[x−y]

6(
∥x −y∥,
where for the last step we used Lemma A.1 ( ∥x∥≤n [maxi {|xi|}]).
Moreover, since it has been assumed that the partial derivatives of the
elements of A are bounded functions then, we may claim that

A Mathematical support
387
|aij(x) −aij(y)| ≤n
'
max
k,z0
5
∂aij(z)
∂zk
z=z0

6(
∥x −y∥.
From the latter expression and from (A.3) we conclude the statement
contained in (A.2).
♦♦♦
Truncated Taylor Representation of a Function
We present now a result well known from calculus and optimization. In the
ﬁrst case, it comes from the ‘theorem of Taylor’ and in the second, it comes
from what is known as ‘Lagrange’s residual formula’. Given the importance
of this lemma in the study of positive deﬁnite functions in Appendix B the
proof is presented in its complete form.
Lemma A.4. Let f : IRn →IR be a continuous function with continuous
partial derivatives up to at least the second one. Then, for each x ∈IRn, there
exists a real number α (1 ≥α ≥0) such that
f(x) = f(0) + ∂f
∂x(0)T x + 1
2xT H(αx)x
where H(αx) is the Hessian matrix (that is, its second partial derivative) of
f(x) evaluated at αx.
Proof. Let x ∈IRn be a constant vector. Consider the time derivative of f(tx)
d
dtf(tx) =
 ∂f(s)
∂s

s=tx
T
x
= ∂f
∂x(tx)T x .
Integrating from t = 0 to t = 1,
 f(1·x)
f(0·x)
df(tx) =
 1
0
∂f
∂x(tx)T x dt
f(x) −f(0) =
 1
0
∂f
∂x(tx)T x dt .
(A.4)
The integral on the right-hand side above may be written as
 1
0
y(t)T x dt
(A.5)
where

388
A Mathematical Support
y(t) = ∂f
∂x(tx) .
(A.6)
Deﬁning
u = y(t)T x
v = t −1
and consequently
du
dt = ˙y(t)T x
dv
dt = 1,
the integral (A.5) may be solved by parts1
 1
0
y(t)T x dt = −
 1
0
[t −1] ˙y(t)T x dt + y(t)T x[t −1]
1
0
=
 1
0
[1 −t)] ˙y(t)T x dt + y(0)T x .
(A.7)
Now, using the mean-value theorem for integrals2, and noting that (1−t) ≥
0 for all t between 0 and 1, the integral on the right-hand side of Equation
(A.7) may be written as
 1
0
(1 −t) ˙y(t)T x dt = ˙y(α)T x
 1
0
(1 −t) dt
= 1
2 ˙y(α)T x
for some α (1 ≥α ≥0).
Incorporating this in (A.7) we get
1 We recall here the formula:
 1
0
udv
dt dt = −
 1
0
v du
dt dt + uv|1
0 .
2 Recall that for functions h(t) and g(t), continuous on the closed interval a ≤t ≤b,
and where g(t) ≥0 for each t from the interval, there always exists a number c
such that a ≤c ≤b and
 b
a
h(t)g(t) dt = h(c)
 b
a
g(t) dt .

A Mathematical support
389
 1
0
y(t)T x dt = 1
2 ˙y(α)T x + y(0)T x
and therefore, (A.4) may be written as
f(x) −f(0) = 1
2 ˙y(α)T x + y(0)T x.
(A.8)
On the other hand, using the deﬁnition of y(t) given in (A.6), we get
˙y(t) = H(tx)x,
and therefore ˙y(α) = H(αx)x. Incorporating this and (A.6) in (A.8), we
obtain
f(x) −f(0) = 1
2xT H(αx)T x + ∂f
∂x(0)T x
which is what we wanted to prove.
♦♦♦
We present next a simple example with the aim of illustrating the use of
the statement of Lemma A.4.
Example A.1. Consider the function f : IR →IR deﬁned by
f(x) = ex .
According to Lemma A.4, the function f(x) may be written as
f(x) = ex = 1 + x + 1
2eαxx2
where for each x ∈IR there exists an α (1 ≥α ≥0). Speciﬁcally, for
x = 0 ∈IR any α ∈[0, 1] applies (indeed, any α ∈IR). In the case
that x ̸= 0 ∈IR then α is explicitly given by
α =
ln
2(ex −1 −x)
x2

x
.
Figure A.1 shows the corresponding graph of α versus x.
♦

390
A Mathematical Support
−100
−50
0
50
100
0.00
0.25
0.50
0.75
1.00
α
x
...........................................................................................................................................................................................................................................................................................................................................................
............................................................................................................................................................................................................................................................................................................
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
.............
Figure A.1. Example A.1: graph of α
A.3 Functional Spaces
A special class of vectorial spaces are the so-called Ln
p (pronounce “el/pi:/en”)
where n is a positive integer and p ∈(0, ∞]. The elements of the Ln
p spaces
are functions with particular properties.
The linear spaces denoted by Ln
2 and Ln
∞, which are deﬁned below, are
often employed in the analysis of interconnected dynamical systems in the
theory of input–output stability. Formally, this methodology involves the use
of operators that characterize the behavior of the distinct parts of the inter-
connected dynamic systems.
We present next a set of deﬁnitions and properties of spaces of functions
that are useful in establishing certain convergence properties of solutions of
diﬀerential equations.
For the purposes of this book, we say that a function f : IRn →IRm is
said to be continuous if
lim
x→x0 f(x) = f(x0)
∀x0 ∈IRn.
A necessary condition for a function to be continuous is that it is deﬁned at
every point x ∈IRn. It is also apparent that it is not necessary for a function
to be continuous that the function’s derivative be deﬁned everywhere. For
instance the derivative of the continuous function f(x) = |x| is not deﬁned
at the origin, i.e. at x = 0. However, if a function’s derivative is deﬁned
everywhere then the function is continuous.
The space Ln
2 consists in the set of all the continuous functions f : IR+ →
IRn such that
 ∞
0
f(t)Tf(t) dt =
 ∞
0
∥f(t)∥2 dt < ∞.

A Mathematical support
391
In words, a function f belongs to the Ln
2 space (f ∈Ln
2) if the integral of
its Euclidean norm squared, is bounded from above. We also say that f is
square-integrable.
The Ln
∞space consists of the set of all continuous functions f : IR+ →IRn
such that their Euclidean norms are upperbounded as3,
sup
t≥0
∥f(t)∥< ∞.
The symbols L2 and L∞denote the spaces L1
2 and L1
∞respectively.
We present next an example to illustrate the above-mentioned deﬁnitions.
Example A.2. Consider the continuous functions f(t) = e−αt and
g(t) = α sin(t) where α > 0 . We want to determine whether f and g
belong to the spaces of L2 and L∞.
Consider ﬁrst the function f(t):
 ∞
0
|f(t)|2 dt =
 ∞
0
f 2(t) dt
=
 ∞
0
e−2αt dt
= 1
2α < ∞
hence, f ∈L2. On the other hand, |f(t)| = |e−αt| ≤1 < ∞for all
t ≥0, hence f ∈L∞. We conclude that f(t) is bounded and square-
integrable, i.e. f ∈L∞∩L2 respectively.
Consider next the function g(t). Notice that the integral
 ∞
0
|g(t)|2 dt = α2
 ∞
0
sin2(t) dt
does not converge; consequently g ̸∈L2. Nevertheless |g(t)| = |α sin(t)|
≤α < ∞for all t ≥0, and therefore g ∈L∞.
♦
A useful observation for analysis of convergence of solutions of diﬀerential
equations is that if we consider a function x : IR+ →IRn and a radially
unbounded positive deﬁnite function W : IRn →IR+ then, since W(x) is
continuous in x the composition w(t) := W(x(t)) satisﬁes w ∈L∞if and
only if x ∈Ln
∞.
3 For those readers not familiar with the sup of a function f(t), it corresponds
to the smallest possible number which is larger than f(t) for all t ≥0. For
instance sup | tanh(t)| = 1 but | tanh(t)| has no maximal value since tanh(t) is
ever increasing and tends to 1 as t →∞.

392
A Mathematical Support
We remark that a continuous function f belonging to the space Ln
2 may not
have a limit. We present next a result from the functional analysis literature
which provides suﬃcient conditions for functions belonging to the Ln
2 space
to have a limit at zero. This result is very often used in the literature of
motion control of robot manipulators and in general, in the adaptive control
literature.
Lemma A.5. Consider a once continuously diﬀerentiable function f : IR+ →
IRn. Suppose that f and its time derivative satisfy the following
•
f, ˙f = d
dtf ∈Ln
∞,
•
f ∈Ln
2.
Then, necessarily limt→∞f(t) = 0 ∈IRn.
Proof. It follows by contradiction4. Speciﬁcally we show that if the conclusion
of the lemma does not hold then the hypothesis that f ∈Ln
2 is violated.
To that end we ﬁrst need to establish a convenient bound for the function
∥f(t)∥2 = f(t)T f(t). Its total time derivative is 2f(t)T ˙f(t) and is continuous
by assumption so we may invoke the mean value theorem (see Theorem A.2)
to conclude that for any pair of numbers t, t1 ∈IR+ there exists a number s
laying on the line segment that joins t and t1, such that
 ∥f(t)∥2 −∥f(t1)∥2 ≤2f(s)T ˙f(s) |t −t1| .
On the other hand, since f, ˙f ∈Ln
∞it follows that there exists k > 0 such
that
 ∥f(t)∥2 −∥f(t1)∥2 ≤k |t −t1|
∀t, t1 ∈IR+ .
(A.9)
Next, notice that
∥f(t)∥2 = ∥f(t)∥2 −∥f(t1)∥2 + ∥f(t1)∥2
for all t, t1 ∈IR+. Now we use the inequality |a + b| ≥|a| −|b| which holds for
all a, b ∈IR, with a = ∥f(t1)∥2 and b =

∥f(t)∥2 −∥f(t1)∥2 
to see that
4 Proof “by contradiction” or, “by reductio ad absurdum”, is a technique widely
used in mathematics to prove theorems and other truths. To illustrate the method
consider a series of logical statements denoted A, B, C, etc. and their negations,
denoted A, B, C, etc. Then, to prove by contradiction the claim, “A and B =⇒
C”, we proceed as follows. Assume that A and B hold but not C. Then, we seek
for a series of implications that lead to a negation of A and B, i.e. we look for
other statements D, E, etc. such that C =⇒D =⇒E =⇒A and B. So we
conclude that C =⇒A and B. However, in view of the fact that A and B must
hold, this contradicts the initial hypothesis of the proof that C does not hold (i.e.
C). Notice that A and B = A or B.

A Mathematical support
393
∥f(t)∥2 ≥∥f(t1)∥2 −
∥f(t)∥2 −∥f(t1)∥2
for all t, t1 ∈IR+. Then, we use (A.9) to obtain
∥f(t)∥2 ≥∥f(t1)∥2 −k |t −t1| .
(A.10)
Assume now that the conclusion of the lemma does not hold i.e, either
limt→∞f(t) ̸= 0 or this limit does not exist. In either case, it follows that for
each T ≥0 there exists an inﬁnite unbounded sequence {t1 , t2 , . . .}, denoted
{tn} ∈IR+ with tn →∞as n →∞, and a constant ε > 0 such that
∥f(ti)∥2 > ε
∀ti ≥T .
(A.11)
To better see this, we recall that if limt→∞f(t) exists and is zero then,
for any ε there exists T(ε) such that for all t ≥T we have ∥f(t)∥2 ≤ε.
Furthermore, without loss of generality, deﬁning δ :=
ε
2k , we may assume
that for all i ≤n, ti+1 −ti ≥δ —indeed, if this does not hold, we may always
extract another inﬁnite unbounded subsequence {t′
i} such that t′
i+1 −t′
i ≥δ
for all i.
Now, since Inequality (A.10) holds for any t and t1 it also holds for any
element of {tn}. Then, in view of (A.11) we have, for each ti belonging to {tn}
and for all t ∈IR+,
∥f(t)∥2 > ε −k |t −ti| .
(A.12)
Integrating Inequality (A.12) from ti to ti + δ we obtain
 ti+δ
ti
∥f(t)∥2 dt >
 ti+δ
ti
ε dt −
 ti+δ
ti
k |t −ti| dt .
(A.13)
Notice that in the integrals above, t ∈[ti, ti + δ] therefore, −k|t −ti| ≥−kδ.
From this and (A.13) it follows that
 ti+δ
ti
∥f(t)∥2 dt > εδ −kδ2
and since by deﬁnition ε
2k = δ we ﬁnally obtain
 ti+δ
ti
∥f(t)∥2 dt > εδ
2 > 0 .
(A.14)
On the other hand, since ti+1 ≥ti + δ for each ti, it also holds that
lim
t→∞
 t
0
∥f(τ)∥2 dτ ≥

{ti}
 ti+1
ti
∥f(τ)∥2 dτ
(A.15)
≥

{ti}
 ti+δ
ti
∥f(τ)∥2 dτ .
(A.16)

394
A Mathematical Support
We see that on one hand, the term on the left-hand side of Inequality (A.15)
is bounded by assumption (since f ∈Ln
2 ) and on the other hand, since {tn}
is inﬁnite and (A.14) holds for each ti the term on the right-hand side of
Inequality (A.16) is unbounded. From this contradiction we conclude that it
must hold that limt→∞f(t) = 0 which completes the proof.
♦♦♦
As an application of Lemma A.5 we present below the proof of Lemma 2.2
used extensively in Parts II and III of this text.
Proof of Lemma 2.2. Since V (t, x, z, h) ≥0 and ˙V (t, x, z, h) ≤0 for all
x, z and h then these inequalities also hold for x(τ), z(τ) and h(τ) and all
τ ≥0. Integrating on both sides of ˙V (τ, x(τ), z(τ), h(τ)) ≤0 from 0 to t we
obtain5
V (0, x(0), z(0), h(0)) ≥V (t, x(t), z(t), h(t)) ≥0
∀t ≥0 .
Now, since P(t) is positive deﬁnite for all t ≥0 we may invoke the theorem
of Rayleigh–Ritz which establishes that xTKx ≥λmin{K}xTx where K is
any symmetric matrix and λmin{K} denotes the smallest eigenvalue of K, to
conclude that there exists6 pm > 0 such that yT P(t)y ≥pm{P}∥y∥2 for all
y ∈IRn+m and all t ∈IR+. Furthermore, with an abuse of notation, we will
denote such constant by λmin{P}. It follows that
⎡
⎣
x(0)
z(0)
⎤
⎦
T
P(0)
⎡
⎣
x(0)
z(0)
⎤
⎦+ h(0) ≥λmin{P}

x(t)
z(t)

2
+ h(t) ≥0
∀t ≥0
hence, the functions x(t), z(t) and h(t) are bounded for all t ≥0. This proves
item 1.
To prove item 2 consider the expression
˙V (t, x(t), z(t), h(t)) = −x(t)TQ(t)x(t) .
Integrating between 0 and T ∈IR+ we get
V (T, x(T), z(T), h(T)) −V (0, x(0), z(0), h(0)) = −
 T
0
x(τ)TQ(τ)x(τ) dτ
5 One should not confuse V (t,  ,  , h) with V (t, (t),  (t), h(t)) as often happens
in the literature. The ﬁrst denotes a function of four variables while the sec-
ond is a functional. In other words, the second corresponds to the function
V (t, ,  , h) evaluated on certain trajectories which depend on time. Therefore,
V (t, (t),  (t), h(t)) is a function of time.
6 In general, for such a bound to exist it may not be suﬃcient that P is positive
deﬁnite for each t but we shall not deal with such issues here and rather, we
assume that P is such that the bound exists. See also Remark 2.1 on page 25.

A Mathematical support
395
which, using the fact that V (0, x(0), z(0), h(0)) ≥V (T, x(T), z(T), h(T)) ≥0
yields the inequality
V (0, x(0), z(0), h(0)) ≥
 T
0
x(τ)TQ(τ)x(τ) dτ
∀T ∈IR+ .
Notice that this inequality continues to hold as T →∞hence,
V (0, x(0), z(0), h(0)) ≥
 ∞
0
x(τ)TQ(τ)x(τ) dτ
so using that Q is positive deﬁnite we obtain7 xT Q(t)x ≥λmin{Q}∥x∥2 for
all x ∈IRn and t ∈IR+ therefore
V (0, x(0), z(0), h(0))
λmin{Q}
≥
 ∞
0
x(τ)Tx(τ) dτ .
The term on the left-hand side of this inequality is ﬁnite, which means that
x ∈Ln
2.
Finally, since by assumption ˙x ∈Ln
∞, invoking Lemma A.5 we may con-
clude that limt→∞x(t) = 0.
♦♦♦
The following result is stated without proof. It can be established using the
so-called Barb˘alat’s lemma (see the Bibliography at the end of the appendix).
Lemma A.6. Let f : IR+ →IRn be a continuously diﬀerentiable function
satisfying
•
limt→∞f(t) = 0
•
f, ˙f, ¨f ∈Ln
∞.
Then,
•
limt→∞˙f(t) = 0 .
Another useful observation is the following.
Lemma A.7. Consider the two functions f : IR+ →IRn and h : IR+ →IR
with the following characteristics:
•
f ∈Ln
2
•
h ∈L∞.
Then, the product hf satisﬁes
•
hf ∈Ln
2.
7 See footnote 6 on page 394.

396
A Mathematical Support
Proof. According to the hypothesis made, there exist ﬁnite constants kf > 0
and kh > 0 such that
 ∞
0
f(t)T f(t) dt ≤kf
sup
t≥0
|h(t)| ≤kh .
Therefore ∞
0
[h(t)f(t)]T [h(t)f(t)] dt =
 ∞
0
h(t)2f(t)T f(t) dt
≤k2
h
 ∞
0
f(t)T f(t) dt ≤k2
hkf,
which means that hf ∈Ln
2.
♦♦♦
Consider a dynamic linear system described by the following equations
˙x = Ax + Bu
y = Cx
where x ∈IRm is the system’s state u ∈IRn, stands for the input, y ∈IRn for
the output and A ∈IRm×m, B ∈IRm×n and C ∈IRn×m are matrices having
constant real coeﬃcients. The transfer matrix function H(s) of the system is
then deﬁned as H(s) = C(sI −A)−1B where s is a complex number (s ∈C).
The following result allows one to draw conclusions on whether y and ˙y
belong to Ln
2 or Ln
∞depending on whether u belongs to Ln
2 or Ln
∞.
Lemma A.8. Consider the square matrix function of dimension n, H(s) ∈
IRn×n(s) whose elements are rational strictly proper8 functions of the complex
variable s. Assume that the denominators of all its elements have all their
roots on the left half of the complex plane (i.e. they have negative real parts).
1. If u ∈Ln
2 then y ∈Ln
2 ∩Ln
∞, ˙y ∈Ln
2 and y(t) →0 as t →∞.
2. If u ∈Ln
∞then y ∈Ln
∞, ˙y ∈Ln
∞.
To illustrate the utility of the lemma above consider the diﬀerential equation
˙x + Ax = u
where x ∈IRn and A ∈IRn×n is a constant positive deﬁnite matrix. If u ∈Ln
2,
then we have from Lemma A.8
that x ∈Ln
2 ∩Ln
∞, ˙x ∈Ln
2 and x(t) →0
when t →∞.
Finally, we present the following corollary whose proof follows immediately
from Lemma A.8.
8 That is, the degree of the denominator is strictly larger than that of the numer-
ator.

A Mathematical support
397
Corollary A.2. For the transfer matrix function H(s) ∈IRn×n(s), let u and
y denote its inputs and outputs respectively and let the assumptions of Lemma
A.8 hold. If u ∈Ln
2 ∩Ln
∞, then
•
y ∈Ln
2 ∩Ln
∞
•
˙y ∈Ln
2 ∩Ln
∞
•
y(t) →0 when t →∞.
The following interesting result may be proved without much eﬀort from
the deﬁnitions of positive deﬁnite function and decrescent function.
Lemma A.9. Consider a continuous function x : IR+ →IRn and a radially
unbounded, positive deﬁnite, decrescent continuous function V : IR+ × IRn →
IR+. The composition v(t) := V (t, x(t)) satisﬁes v ∈L∞if and only if x ∈
Ln
∞.
Bibliography
Lemma A.2 appears in
•
Marcus M., Minc H., 1965, “Introduction to linear algebra”, Dover Publi-
cations, p. 207.
•
Horn R. A., Johnson C. R., 1985, “Matrix analysis”, Cambridge University
Press, p. 346.
Theorem A.1 on partitioned matrices is taken from
•
Horn R. A., Johnson C. R., 1985, “Matrix analysis”, Cambridge University
Press.
The statement of the mean-value theorem for vectorial functions may be
consulted in
•
Taylor A. E., Mann W. R., 1983, “Advanced calculus”, John Wiley and
Sons.
The deﬁnition of Lp spaces are clearly exposed in Chapter 6 of
•
Vidyasagar M., 1993, “Nonlinear systems analysis”, Prentice-Hall, New
Jersey.
The proof of Lemma A.5 is based on the proof of the so-called Barb˘alat’s
lemma originally reported in

398
A Mathematical Support
•
Barb˘alat B., 1959, “Syst`emes d’´equations diﬀ´erentielles d’oscillations non-
lin´eaires”, Revue de math´ematiques pures et appliqu´ees, Vol. 4, No. 2, pp.
267–270.
See also Lemma 2.12 in
•
Narendra K., Annaswamy A., 1989, Stable adaptive systems, Prentice-Hall,
p. 85.
Lemma A.8 is taken from
•
Desoer C., Vidyasagar M., 1975, “Feedback systems: Input–output proper-
ties”, Academic Press, New York, p. 59.
Problems
1. Consider the continuous function
f(t) =
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
2n+2[t −n]
if n < t < n +
1
2n+2
1 −2n+2

t −

n +
1
2n+2

if n +
1
2n+2 ≤t < n +
1
2n+1
0
if n +
1
2n+1 ≤t ≤n + 1
with n = 0, 1, 2, · · ·. The limit when t →∞of f(t) does not exist (see the
Figure A.2). Show that f(t) belongs to L2 .
1
2
1
3
2
2
t
f(t)
Figure A.2. Problem 1
Hint: Notice that f 2(t) ≤h2(t) where

A Mathematical support
399
h2(t) =
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
1 if n < t < n +
1
2n+2
1 if n +
1
2n+2 ≤t < n +
1
2n+1
0 if n +
1
2n+1 ≤t ≤n + 1
and
 ∞
0
| h(t) |2dt =
∞

i=1
(1/2i) .

B
Support to Lyapunov Theory
B.1 Conditions for Positive Deﬁniteness of Functions
The interest of Lemma A.4 in this textbook resides in that it may be used
to derive suﬃcient conditions for a function to be positive deﬁnite (locally or
globally). We present such conditions in the statement of the following lemma.
Lemma B.1. Let f : IRn →IR be a continuously diﬀerentiable function with
continuous partial derivatives up to at least second order. Assume that
•
f(0) = 0 ∈IR
•
∂f
∂x(0) = 0 ∈IRn.
Furthermore,
•
if the Hessian matrix satisﬁes H(0) > 0, then f(x) is a positive deﬁnite
function (at least locally).
•
If the Hessian matrix H(x) > 0 for all x ∈IRn, then f(x) is a globally
positive deﬁnite function.
Proof. Considering Lemma A.4 and the hypothesis made on the function f(x)
we see that for each x ∈IRn there exists an α (1 ≥α ≥0) such that
f(x) = 1
2xT H(αx)x .
Under the hypothesis of continuity up to the second partial derivative, if
the Hessian matrix evaluated at x = 0 is positive deﬁnite (H(0) > 0), then
the Hessian matrix is also positive deﬁnite in a neighborhood of x = 0 ∈IRn,
e.g. for all x ∈IRn such that ∥x∥≤ε and for some ε > 0, i.e.
H(x) > 0
∀x ∈IRn : ∥x∥≤ε .

402
B Support to Lyapunov Theory
Of course, H(αx) > 0 for all x ∈IRn such that ∥x∥≤ε and for any α
(1 ≥α ≥0). Since for all x ∈IRn there exists an α (1 ≥α ≥0) and
f(x) = 1
2xT H(αx)x ,
then f(x) > 0 for all x ̸= 0 ∈IRn such that ∥x∥≤ε. Furthermore, since by
hypothesis f(0) = 0, it follows that f(x) is positive deﬁnite at least locally.
On the other hand, if the Hessian matrix H(x) is positive deﬁnite for all
x ∈IRn, it follows that so is H(αx) and this, not only for 1 ≥α ≥0 but for
any real α. Therefore, f(x) > 0 for all x ̸= 0 ∈IRn and, since we assumed
that f(0) = 0 we conclude that f(x) is globally positive deﬁnite.
♦♦♦
Next, we present some examples to illustrate the application of the previ-
ous lemma.
Example B.1. Consider the following function f : IR2 →IR used in the
study of stability of the origin of the diﬀerential equation that models
the behavior of an ideal pendulum, that is,
f(x1, x2) = mgl[1 −cos(x1)] + J x2
2
2 .
Clearly, we have f(0, 0) = 0 that is, the origin is an equilibrium
point. The gradient of f(x1, x2) is given by
∂f
∂x(x) =

mgl sin(x1)
Jx2

which, evaluated at x = 0 ∈IR2 is zero. Next, the Hessian matrix is
given by
H(x) =

mgl cos(x1)
0
0
J

and is positive deﬁnite at x = 0 ∈IR2. Hence, according to Lemma
B.1 the function f(x1, x2) is positive deﬁnite at least locally. Notice
that this function is not globally positive deﬁnite since cos(x1) = 0
for all x1 = nπ
2
with n = 1, 2, 3 . . . and cos(x1) < 0 for all x1 ∈
nπ
2 , (n + 2)π
2

for all n = 1, 5, 7, 9, . . .
♦
The following example, less trivial than the previous one, presents a func-
tion that is used as part of Lyapunov functions in the study of stability of
various control schemes of robots.

B Support to Lyapunov Theory
403
Example B.2. Consider the function f : IRn →IR deﬁned as
f(˜q) = U(qd −˜q) −U(qd) + g(qd)T ˜q + 1
ε ˜qT Kp˜q
where Kp = KT
p > 0, qd ∈IRn is a constant vector, ε is a real positive
constant and U(q) stands for the potential energy of the robot. Here,
we assume that all the joints of the robot are revolute.
The objective of this example is to show that if Kp is selected so
that 1
λmin{Kp} > ε
2kg
then f(˜q) is a globally positive deﬁnite function.
To prove the latter we use Lemma B.1. Notice ﬁrst that f(0) = 0.
The gradient of f(˜q) with respect to ˜q is
∂
∂˜q f(˜q) = ∂U(qd −˜q)
∂˜q
+ g(qd) + 2
εKp˜q .
Recalling from (3.20) that g(q) = ∂U(q)/∂q and2
∂
∂˜q U(qd −˜q) = ∂(qd −˜q)
∂˜q
T ∂U(qd −˜q)
∂(qd −˜q)
we ﬁnally obtain the expression:
∂
∂˜q f(˜q) = −g(qd −˜q) + g(qd) + 2
εKp˜q .
Clearly the gradient of f(˜q) is zero at ˜q = 0 ∈IRn.
On the other hand, the (symmetric) Hessian matrix H(˜q) of f(˜q),
deﬁned as
1 The constant kg has been deﬁned in Property 4.3 and satisﬁes
kg ≥

∂ ()
∂
 .
2 Let f : IRn →IR,   : IRn →IRn, ,  ∈IRn and  =  (). Then,
∂f()
∂
=

∂ ()
∂
T ∂f()
∂
.

404
B Support to Lyapunov Theory
H(˜q) = ∂
∂˜q
∂f(˜q)
∂˜q

=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
∂2f(˜ )
∂˜q1∂˜q1
∂2f(˜ )
∂˜q1∂˜q2
· · ·
∂2f(˜ )
∂˜q1∂˜qn
∂2f(˜ )
∂˜q2∂˜q1
∂2f(˜ )
∂˜q2∂˜q2
· · ·
∂2f(˜ )
∂˜q2∂˜qn
...
...
...
...
∂2f(˜ )
∂˜qn∂˜q1
∂2f(˜ )
∂˜qn∂˜q2
· · ·
∂2f(˜ )
∂˜qn∂˜qn
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
actually corresponds to3
H(˜q) = ∂g(qd −˜q)
∂(qd −˜q) + 2
εKp .
According to Lemma B.1, if H(˜q) > 0 for all ˜q ∈IRn, then the
function f(˜q) is globally positive deﬁnite.
To show that H(˜q) > 0 for all ˜q ∈IRn, we appeal to the follow-
ing result. Let A, B ∈IRn×n be symmetric matrices. Assume more-
over that the matrix A is positive deﬁnite, but B may not be so. If
λmin{A} > ∥B∥, then the matrix A + B is positive deﬁnite4. Deﬁning
3 Let  ,  : IRn →IRn, ,  ∈IRn and  = (). Then,
∂ ()
∂
= ∂ ()
∂
∂()
∂
.
4 Proof. Since by hypothesis λmin{A} > ∥B∥, then
λmin{A} ∥∥2 > ∥B∥∥∥2
for all  ̸= 0.
Observe that the left-hand side of the inequality above satisﬁes
T A ≥λmin{A} ∥∥2
while the right-hand side satisﬁes
∥B∥∥∥2 = ∥B∥∥∥∥∥
≥∥B∥∥∥
≥
T B

≥−T B .
Therefore,
T A > −T B
for all  ̸= 0, that is
T [A + B]  > 0 ,
which is equivalent to matrix A + B being positive deﬁnite.

B Support to Lyapunov Theory
405
A = 2
εKp, B = ∂g(q)
∂q
, and using the latter result, we conclude that
the Hessian matrix is positive deﬁnite provided that
λmin{Kp} > ε
2

∂g(q)
∂q
 .
(B.1)
Since the constant kg satisﬁes kg ≥
 ∂g(q)
∂q
, the condition (B.1)
is implied by
λmin{Kp} > ε
2kg .
♦
The following example may be considered as a corollary of the previous
example.
Example B.3. This example shows that the function f(˜q) deﬁned in
the previous example is lower-bounded by a quadratic function of ˜q
and therefore it is positive deﬁnite.
Speciﬁcally we show that
U(qd −˜q) −U(qd) + g(qd)T ˜q + 1
2 ˜qT Kp˜q ≥1
2 [λmin{Kp} −kg] ∥˜q∥2
is valid for all ˜q ∈IRn, with Kp = KT
p such that λmin{Kp} > kg,
where qd ∈IRn is a constant vector and U(q) corresponds to the
potential energy of the robot. As usual, we assume that all the joints
of the robot are revolute.
To carry out the proof, we appeal to the argument of showing that
the function
f(˜q) = U(qd−˜q)−U(qd)+g(qd)T ˜q+1
2 ˜qT Kp˜q−1
2 [λmin{Kp} −kg] ∥˜q∥2
is globally positive deﬁnite. With this objective in mind we appeal to
Lemma B.1. Notice ﬁrst that f(0) = 0.
The gradient of f(˜q) with respect to ˜q is
∂
∂˜q f(˜q) = −g(qd −˜q) + g(qd) + Kp˜q −[λmin{Kp} −kg] ˜q .
Clearly the gradient of f(˜q) is zero at ˜q = 0 ∈IRn.
The Hessian matrix H(˜q) of f(˜q) becomes
H(˜q) = ∂g(qd −˜q)
∂(qd −˜q) + Kp −[λmin{Kp} −kg] I .

406
B Support to Lyapunov Theory
We show next that the latter is positive deﬁnite. For this, we start
from the fact that the constant kg satisﬁes
kg >

∂g(q)
∂q

for all q ∈IRn. Therefore, it holds that
λmin{Kp} −λmin{Kp} + kg >

∂g(q)
∂q

or equivalently,
λmin{Kp} −λMax {[λmin{Kp} −kg] I} >

∂g(q)
∂q
 .
By virtue of the fact that for two symmetric matrices A and B we
have that λmin{A −B} ≥λmin{A} −λMax{B}, it follows that
λmin {Kp −[λmin{Kp} −kg] I} >

∂g(q)
∂q
 .
Finally, invoking the fact that for any given symmetric positive
deﬁnite matrix A, and a symmetric matrix B it holds that A + B > 0
provided that λmin{A} > ∥B∥, we conclude that
Kp −[λmin{Kp} −kg] I + ∂g(q)
∂q
> 0
which corresponds precisely to the expression for the Hessian. There-
fore, the latter is positive deﬁnite and according to Lemma B.1, we
conclude that the function f(˜q) is globally positive deﬁnite.
♦

C
Proofs of Some Properties of the Dynamic
Model
Proof of Property 4.1.3
The proof of the inequality (4.2) follows straightforward invoking Corollary
A.1. This is possible due to the fact that the inertia matrix M(q) is continuous
in q as well as the partial derivative of each of its elements Mij(q). Since
moreover we considered the case of robots whose joints are all revolute, we
obtain the additional characteristic that

∂Mij(q)
∂qk
q=q0

is a function of q0 bounded from above.
Therefore, given any two vectors x, y ∈IRn, according to Corollary A.1,
the norm of the vector M(x)z −M(y)z satisﬁes
∥M(x)z −M(y)z∥≤n2
max
i,j,k,q0
5
∂Mij(q)
∂qk
q=q0

6
∥x −y∥∥z∥.
Now, choosing the constant kM in accordance with (4.3), i.e.
kM = n2
max
i,j,k,q0
5
∂Mij(q)
∂qk
q=q0

6
,
we obtain
∥M(x)z −M(y)z∥≤kM ∥x −y∥∥z∥
which corresponds to the inequality stated in (4.2).
♦♦♦

408
C Proofs of Some Properties of the Dynamic Model
Proof of Property 4.2.6
To carry out the proof of inequality (4.5) we start by considering (4.4) which
allows one to express the vector C(x, z)w −C(y, v)w as
C(x, z)w −C(y, v)w =
⎡
⎢⎢⎢⎣
wT C1(x)z
wT C2(x)z
...
wT Cn(x)z−
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
wT C1(y)v
wT C2(y)v
...
wT Cn(y)v
⎤
⎥⎥⎥⎦
(C.1)
where Ck(q) is a symmetric matrix of dimension n, continuous in q and with
the characteristic of that all of its elements Ckij(q) are bounded for all q ∈IRn
and moreover, so are its partial derivatives (Ckij(q) ∈C∞).
According to Equation (C.1), the vector C(x, z)w −C(y, v)w may also
be written as
C(x, z)w −C(y, v)w =
⎡
⎢⎢⎢⎢⎣
wT [C1(x) −C1(y)] z −wT C1(y)[v −z]
wT [C2(x) −C2(y)] z −wT C2(y)[v −z]
...
wT [Cn(x) −Cn(y)] z −wT Cn(y)[v −z]
⎤
⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎣
wT [C1(x) −C1(y)] z
wT [C2(x) −C2(y)] z
...
wT [Cn(x) −Cn(y)] z
⎤
⎥⎥⎥⎥⎦
−C(y, v −z)w.
Evaluating the norms of the terms on each side of the equality above we
immediately obtain
∥C(x, z)w −C(y, v)w∥≤

wT [C1(x) −C1(y)] z
wT [C2(x) −C2(y)] z
...
wT [Cn(x) −Cn(y)] z

+ ∥C(y, v −z)w∥.
(C.2)
We proceed next to determine upper-bounds on the two normed terms on
the right-hand side of this inequality. First, using Lemma A.1 we get

wT [C1(x) −C1(y)] z
wT [C2(x) −C2(y)] z
...
wT [Cn(x) −Cn(y)] z

≤n max
k
)wT [Ck(x) −Ck(y)] z
*
.
(C.3)

C Proofs of Some Properties of the Dynamic Model
409
Furthermore, since the partial derivatives of the elements of the matrices
Ck(q) are bounded functions, Corollary A.1 leads to
wT [Ck(x) −Ck(y)] z
 ≤∥[Ck(x) −Ck(y)] z∥∥w∥
≤n2 max
i,j,l,q0
5
∂Ckij(q)
∂ql
q=q0

6
∥x −y∥
∥z∥∥w∥,
and therefore, it follows that
n max
k
)wT [Ck(x) −Ck(y)] z
*
≤n3
max
i,j,k,l,q0
5
∂Ckij(q)
∂ql
q=q0

6
∥x −y∥∥z∥∥w∥.
Incorporating this last inequality in (C.3) we ﬁnally obtain

wT [C1(x) −C1(y)] z
wT [C2(x) −C2(y)] z
...
wT [Cn(x) −Cn(y)] z

≤
n3
max
i,j,k,l,q0
5
∂Ckij(q)
∂ql
q=q0

6
∥x −y∥∥z∥∥w∥.
(C.4)
On the other hand, using (4.8) it follows that the second normed term on
the right-hand side of Inequality (C.2) may be bounded as
∥C(y, v −z)w∥≤n2

max
k,i,j,q
Ckij(q)


∥v −z∥∥w∥.
(C.5)
Deﬁning the constant kC1 and kC2 in accordance with table 4.1, i.e.
kC1 = n2

max
i,j,k,q
Ckij(q)


kC2 = n3

max
i,j,k,l,q

∂Ckij(q)
∂ql


,
and using (C.4) and (C.5) in the Inequality (C.2), we ﬁnally get
∥C(x, z)w −C(y, v)w∥≤kC1 ∥v −z∥∥w∥+ kC2 ∥x −y∥∥z∥∥w∥,
which is what we wanted to demonstrate.
♦♦♦

410
C Proofs of Some Properties of the Dynamic Model
Proof of Property 4.3.3
The proof of inequality (4.10) follows invoking Theorem A.3. Since the vector
of gravitational torques g(q) is a vectorial continuous function, then for any
two vectors x, y ∈IRn, we have
g(x) −g(y) = ∂g(q)
∂q
q=ξ
[x −y]
where ξ = y + α[x −y] and α is a number suitably chosen within the interval
[0, 1]. Evaluating the norms of the terms on both sides of the equation above
we obtain
∥g(x) −g(y)∥≤

∂g(q)
∂q
q=ξ
 ∥x −y∥.
(C.6)
On the other hand, using Lemma A.3, we get

∂g(q)
∂q
q=ξ
 ≤n max
i,j
5
∂gi(q)
∂qj
q=ξ

6
.
Furthermore, since we considered the case of robots with only revolute joints,
the function

∂gi(q)
∂qj

is bounded. Therefore, it is also true that

∂g(q)
∂q
q=ξ
 ≤n max
i,j,q

∂gi(q)
∂qj

&
.
Incorporating this inequality in (C.6), we obtain
∥g(x) −g(y)∥≤n max
i,j,q

∂gi(q)
∂qj

&
∥x −y∥.
Choosing next the constant kg as in (4.11), i.e.
kg = n

max
i,j,q

∂gi(q)
∂qj


which by the way implies, from Lemma A.3, that
kg ≥

∂g(q)
∂q
 ,
we ﬁnally get the expression
∥g(x) −g(y)∥≤kg ∥x −y∥
which is what we were seeking.
♦♦♦

D
Dynamics of Direct-current Motors
The actuators of robot manipulators may be electrical, hydraulic or pneu-
matic. The simplest electrical actuators used in robotics applications are
permanent-magnet direct-current motors (DC).
Ka, Kb, Ra
v
Jm
fm
1 : r
q
τ
Figure D.1. DC motor
An idealized mathematical model that characterizes the behavior of a
permanent-magnet DC motor controlled by the armature voltage is typically
described by the set of equations (see Figure D.1)
τm = Kaia
(D.1)
v = Raia + La
dia
dt + eb
(D.2)
eb = Kb ˙qm
(D.3)
qm = rq,
where
•
Ka : motor-torque constant (N m /A)
•
Ra : armature resistance (Ω)
•
La : armature inductance (H)
•
Kb : back emf constant (V s/rad)

412
D Dynamics of Direct-current Motors
•
τm : torque at the axis of the motor (N m)
•
ia : armature current (A)
•
eb : back emf (V)
•
qm : angular position of the axis of the motor (rad)
•
q : angular position of the axis of the mechanical load1 (rad)
•
r : gears reduction ratio (in general r ≫1)
•
v : armature voltage (V).
The equation of motion for this system is
Jm¨qm = τm −fm( ˙qm) −τ
r
(D.4)
where τ is the torque applied after the gear box at the axis of the load, Jm
is the rotor inertia of the rotor, and fm( ˙qm) is the torque due to friction
between the rotor and its bearings, which in general, is a nonlinear function
of its argument.
From a dynamic systems viewpoint, the DC motor may be regarded as
a device whose input is the voltage v and output is the torque τ, which is
applied after the gear box. Eventually, the time derivative ˙τ of the torque τ
may also be considered as an output.
The dynamic model that relates the voltage v to the torque τ is obtained
in the following manner. First, we proceed to replace ia from (D.1) and eb
from (D.3) in (D.2) to get
v = Ra
Ka
τm + La
dia
dt + Kb ˙qm .
(D.5)
Next, evaluating the time derivative on both sides of Equation (D.1) we
obtain dia
dt = ˙τm/Ka which, when replaced in (D.5) yields
v = Ra
Ka
τm + La
Ka
˙τm + Kb ˙qm .
(D.6)
On the other hand, from (D.4) we get τm as
τm = Jm¨qm + fm( ˙qm) + τ
r
and whose time derivative is
˙τm = Jm
d
dt ¨qm + ∂fm( ˙qm)
∂˙qm
¨qm + ˙τ
r
which, substituted in (D.6) yields
1 For instance, a link of a robot.

D Dynamics of Direct-current Motors
413
v = Ra
Ka

Jm¨qm + fm( ˙qm) + τ
r

+ La
Ka

Jm
d
dt ¨qm + ∂fm( ˙qm)
∂˙qm
¨qm + ˙τ
r

+ Kb ˙qm .
Finally, using the relation qm = rq, the previous equation may be written
as
Ka
rRa
v = LaJm
Ra
d
dt ¨q +

Jm + La
Ra
∂fm(r ˙q)
∂(r ˙q)

¨q + 1
r fm(r ˙q)
+ KaKb
Ra
˙q + τ
r2 +
La
r2Ra
˙τ ,
(D.7)
which may also be expressed in terms of the state vector [q
˙q ¨q ], as
d
dt
⎡
⎢⎢⎢⎣
q
˙q
La¨q
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎢⎣
˙q
¨q
1
Jm

Ka
r v −
+
RaJm + La
∂fm(r ˙q)
∂(r ˙q)
,
¨q + g( ˙q, τ, ˙τ)

⎤
⎥⎥⎥⎥⎦
(D.8)
where
g( ˙q, τ, ˙τ) = −Ra
r fm(r ˙q) −KaKb ˙q −Ra
τ
r2 −La
˙τ
r2 .
Equation (D.8) constitutes a diﬀerential equation of third order. In addi-
tion, this equation is nonlinear if the friction term fm(·) is a nonlinear function
of its argument. The presence of the armature inductance La multiplying d
dt ¨q,
causes the equation to be a ‘singularly-perturbed’2 diﬀerential equation for
“small” inductance values.
Negligible Armature Inductance (L  ≈0)
In several applications, the armature inductance La is negligible (La ≈0).
In the rest of the present appendix we assume that this is the case. Thus,
considering La = 0, Equation (D.7) becomes
Jm¨q + 1
r fm(r ˙q) + KaKb
Ra
˙q + τ
r2 = Ka
rRa
v
(D.9)
or equivalently, in terms of the state vector [q
˙q]
d
dt
⎡
⎢⎣
q
˙q
⎤
⎥⎦=
⎡
⎢⎣
˙q
1
Jm
 Ka
rRa
v −fm(r ˙q)
r
−KaKb
Ra
˙q −τ
r2

⎤
⎥⎦.
2 See for instance H. Khalil, Nonlinear Systems, Prentice-Hall, 1996.

414
D Dynamics of Direct-current Motors
This important equation relates the voltage v applied to the armature of
the motor, to the torque τ applied to the mechanical load, in terms of the
angular position, velocity and acceleration of the latter.
Example D.1. Model of a motor with a mechanical load whose center
of mass is located at the axis of rotation.
In the particular case when the load is modeled by a single inertia JL
with friction torques fL( ˙q) as illustrated in Figure D.2, the torque τ
is obtained from the equation of motion associated with the load as
JL¨q = τ −fL( ˙q) .
(D.10)
v
Ka, Kb, Ra
fm
Jm
1 : r
gears
τ
fL
q,
Figure D.2. DC motor with cylindrical inertia
The model of the motor-with-load for this case is obtained by
substituting τ from (D.10) in (D.9), that is,
JL
r2 + Jm

¨q + 1
r fm(r ˙q) + 1
r2 fL( ˙q) + KaKb
Ra
˙q = Ka
rRa
v .
(D.11)
♦
Example D.2. Model of a pendular device.
Consider the pendular device depicted in Figure D.3. The joint con-
sists of a DC motor connected through gears to the pendular arm.
The equation of motion for the arm and its load is given by
 
J + ml2!
¨q + fL( ˙q) + (mblb + ml) g sin(q) = τ
(D.12)
where
•
J : arm inertia (without load)
•
mb : arm mass (without load)
•
lb : distance from the axis of rotation to the center of mass of the
arm (without load)

D Dynamics of Direct-current Motors
415
•
m : load mass (assumed concentrated at the center of mass)
•
l : distance from the axis of rotation to the load m
•
g : gravity acceleration
•
τ : applied torque at the axis of rotation
•
fL( ˙q) : friction torque between the arm and its bearings.
v
Ka, Kb, Ra
Jm
fm
1 : r
fL
lb
l
mb, J
m
q
Figure D.3. Pendular device
Equation (D.12) may rewritten in compact form
JL¨q + fL( ˙q) + kL sin(q) = τ
(D.13)
where
JL = J + ml2
kL = (mblb + ml) g .
Thus, the complete model of the pendular device that we obtain
by substituting τ from (D.13) in the model of the DC motor (D.9) is
JL
r2 + Jm

¨q + 1
r fm(r ˙q) + 1
r2 fL( ˙q) + KaKb
Ra
˙q + kL
r2 sin(q) = Ka
rRa
v .
(D.14)
Notice that the previous model constitutes a nonlinear diﬀerential
equation due not only to the friction torques fm(r ˙q) and fL( ˙q) but
also due to the term (kL/r2) sin(q).
In the particular case where the gear reduction ratio r is high
(r ≫1) then, neglecting terms in 1/r2, the model (D.14) may be
approximated by the model of the DC motor (D.9) with zero torque
(τ = 0). Also, observe that if the center of mass of the arm and that of
the load are both located on the axis of rotation (i.e. lb = l = 0
⇒

416
D Dynamics of Direct-current Motors
kL = 0) then, Equation (D.11) corresponds to the model of a motor
with load whose center of mass is located on the axis of rotation.
♦
D.1 Motor Model with Linear Friction
In spite of the complexity of friction phenomena, typically linear models are
used to characterize their behavior, that is,
fm( ˙qm) = fm ˙qm
(D.15)
where fm is a positive constant.
Considering the linear model above for the friction torques, Equation
(D.9), that relates the voltage v applied at the armature of the motor to
the torque τ applied on the load, takes the form
Jm¨q +

fm + KaKb
Ra

˙q + τ
r2 = Ka
rRa
v .
(D.16)
Example D.3. Model of the motor with a load whose center of mass is
located on the axis of rotation (linear friction).
Consider the linear model (D.15) for the friction torque corresponding
to the rotor with respect to its bearings as well as the following linear
equation for the friction torque between the load and its bearings:
fL( ˙q) = fL ˙q
where fL is a positive constant. The model of the motor-with-load
(D.11) reduces to
JL
r2 + Jm

¨q +

fm + fL
r2 + KaKb
Ra

˙q = Ka
rRa
v
or, in compact form
JL
r2 + Jm

¨q + fL
r2 ˙q + b ˙q = kv
where
b = fm + KaKb
Ra
k = Ka
rRa
.
♦

D Dynamics of Direct-Current Motors
417
D.2 Motor Model with Nonlinear Friction
A more realistic model that characterizes the friction torques is given by the
nonlinear expression
fm( ˙qm) = fm ˙qm + c1 sign( ˙qm)
(D.17)
where fm and c1 are positive constants (see Figure D.4) and sign(·) is the sign
function which is deﬁned as sign(s) = −1 if s < 0, sign(s) = +1 if s > 0 and
at zero this function is discontinuous since clearly, its limits from the left and
from the right are diﬀerent.
fm
1
−c1
c1
˙q
f( ˙q)
fm
1
Figure D.4. Nonlinear friction
Strictly speaking one must be very careful in studying the stability of
a system described by a diﬀerential equation which contain discontinuous
functions. None of the theorems of stability presented here apply to this case.
In general one cannot even guarantee the basic assumption that we made on
page 28 that the solutions are unique for each initial condition. All this makes
the study of Lyapunov stability for these systems a highly complex problem
that is beyond the scope of this textbook.
Nevertheless, for the sake of completeness we present below the dynamic
model of the motor with a discontinuous friction term. Considering the nonlin-
ear model above for the friction torques, Equation (D.9) relating the voltage
v applied to the armature of the motor together with the torque τ applied to
the load, becomes
Jm¨q +

fm + KaKb
Ra

˙q + c1
r sign(r ˙q) + τ
r2 = Ka
rRa
v .

418
D Dynamics of Direct-current Motors
Example D.4. Model of the motor with load whose center of mass is
located on the axis of rotation (nonlinear friction).
Consider the model of nonlinear friction (D.17) for the friction torque
between the axis of the rotor and its bearings, and the corresponding
load’s friction,
fL( ˙q) = fL ˙q + c2 sign( ˙q)
(D.18)
where fL and c2 are positive constants.
Taking into account the functions (D.17) and (D.18), the motor-
with-load model (D.11) becomes
(JL + Jm) ¨q +

fm + KaKb
Ra
+ fL

˙q + (c1 + c2) sign( ˙q) = Ka
Ra
v
where for simplicity, we took r = 1.
♦
Bibliography
Derivation of the dynamic model of DC motors may be found in many texts,
among which we suggest the reader to consult the following on control and
robotics, respectively:
•
Ogata K., 1970, “Modern control engineering”, Prentice-Hall.
•
Spong M., Vidyasagar M., 1989, “Robot dynamics and control”, John Wi-
ley and Sons, Inc.
Various nonlinear models of friction for DC motors are presented in
•
Canudas C., ˚Astr¨om K. J., Braun K., 1987, “ Adaptive friction compen-
sation in DC-motor drives”, IEEE Journal of Robotics and Automation,
Vol. RA-3, No. 6, December.
•
Canudas C., 1988, “Adaptive control for partially known systems—Theory
and applications”, Elsevier Science Publishers.
•
Canudas C., Olsson H., ˚Astr¨om K. J., Lischinsky P., 1995, “A new model
for control of systems with friction”, IEEE Transactions on Automatic
Control, Vol. 40, No. 3, March, pp. 419–425.
An interesting paper dealing with the problem of deﬁnition of solutions
for mechanical systems with discontinuous friction is
•
Seung-Jean K., In-Joong Ha, 1999, “On the existence of Carath´eodory
solutions in mechanical systems with friction”, IEEE Transactions on Au-
tomatic Control, Vol. 44, No. 11, pp. 2086–2089.

Index
:= and =: . . . . . . . . . . . . . . . . . . . . . . . . . . 19
Ln
2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 390
Ln
∞. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 390
⇐⇒. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .19
=⇒. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
IR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
IRn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .20
IRn×m . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .21
IR+ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
˙x. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .19
∃. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .19
∀. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .19
∈. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
→. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .19
e.g.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .xiv
i.e. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiv
cf.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .xiv
etc.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .xiv
˚Astr¨om K. J. . . . . . . . . . . . . . 308, 333, 418
Abdallah C. T. . . . . . . . . . . . 139, 333, 378
absolute value . . . . . . . . . . . . . . . . . . . . . . . 20
actuators . . . . . . . . . . . . . . . . . . . 60, 82, 411
electromechanical . . . . . . . . . . . . . 82, 89
hydraulic . . . . . . . . . . . . . . . . . . . . . . . . . 82
linear . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82
nonlinear . . . . . . . . . . . . . . . . . . . . . . . . . 87
adaptive
gain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 329
update law. . . . . . . . . . . . . . . . . . . . . . .328
adaptive control
closed loop. . . . . . . . . . . . . . . . . . . . . . .330
law . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 328
parametric convergence . . . . . . . . . . 329
adaptive law . . . . . . . . . . . . . . . . . . . . . . . 328
Ailon A. . . . . . . . . . . . . . . . . . . . . . . . . . . . 308
Alvarez R. . . . . . . . . . . . . . . . . . . . . . . . . . . xv
Alvarez–Ramirez J. . . . . . . . . . . . . . . . . 218
An C.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .283
Anderson B. D. O. . . . . . . . . . . . . . . . . . 333
Annaswamy A. . . . . . . . . . . . . . . . . 333, 398
Arimoto S. . xv, 109, 139, 153, 167, 168,
195, 217, 218, 333, 334
armature current. . . . . . . . . . . . . . . . . . .412
armature resistance. . . . . . . . . . . . .83, 411
Arnold V. . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
Arteaga A. . . . . . . . . . . . . . . . . . . . . . . . . . 332
Arteaga, M. . . . . . . . . . . . . . . . . . . . . . . . . . xv
Asada H. . . . . . . . . . . . . . . . . . . 88, 139, 283
asymptotic stability
deﬁnition. . . . . . . . . . . . . . . . . . . . . .33, 35
Atkeson C.. . . . . . . . . . . . . . . . . . . . . . . . .283
back emf . . . . . . . . . . . . . . . . . . . . . . . 83, 412
back emf constant. . . . . . . . . . . . . . . . . .411
bandwidth . . . . . . . . . . . . . . . . . . . . . . . . . 231
Barb˘alat
lemma . . . . . . . . . . . . . . . . . . . . . . . . . . . 397
Bastin G. . . . . . . . . . . . . . . . . . . . . . . . . . . 140
Bayard D.. . . . . . . . . . . . . . . . . . . . . 238, 331
Bejczy A. K. . . . . . . . . . . . . . . . . . . . 90, 283
Berghuis H. . . . . . . . . . . . . . . . xv, 308, 333
bifurcation . . . . . . . . . . . . . . . . . . . . 187, 196
pitchfork. . . . . . . . . . . . . . . . . . . . . . . . .188
saddle-node . . . . . . . . . . . . . . . . . . . . . . 188
Bitmead R. R. . . . . . . . . . . . . . . . . . . . . . 333
Block-diagram
computed-torque control . . . . . . . . . 228

420
Index
feedforward control . . . . . . . . . . . . . . 265
generic adaptive control of robots 329
P“D” control with gravity compensa-
tion . . . . . . . . . . . . . . . . . . . . . . . . . . 293
PD control. . . . . . . . . . . . . . . . . . . . . . .142
PD control plus feedforward . . . . . 270
PD control with compensation . . . 245
PD control with desired gravity
compensation. . . . . . . . . . . . . . . . .172
PD control with gravity compensation
158
pendulum under PD control with
adaptive compensation. . . . . . . .370
PID control. . . . . . . . . . . . . . . . . . . . . .202
Proportional control plus velocity
feedback . . . . . . . . . . . . . . . . . . . . . . 141
robot with its actuators . . . . . . . . . . . 84
Boals M. . . . . . . . . . . . . . . . . . . . . . . . . . . . 334
Bodson M. . . . . . . . . . . . . . . . . . . . . . . . . . 333
Borrelli R. . . . . . . . . . . . . . . . . . . . . . . . . . . 54
boundedness of solutions . . . . . . 148, 174
uniform . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
Braun K. . . . . . . . . . . . . . . . . . . . . . . . . . . 418
Brogliato B.. . . . . . . . . . . . . . . . . . . . . . . .332
Burkov I. V. . . . . . . . . . . . . . . . . . . . . . . . . 89
Caccavale F. . . . . . . . . . . . . . . . . . . . . . . . 283
Campa R.. . . . . . . . . . . . . . . . . . . . . . . . . . .xv
Canudas C. . . . . . . . . . . 140, 308, 332, 418
Canudas de Wit C.. . . . . . . . . . . . . . . . . .xv
Carelli R.. . . . . . . . . . . . . . . . . .xv, 238, 332
Cartesian coordinates . . . . . . . . . . . . . . 115
Cartesian positions . . . . . . . . . . . . . . . . . . 61
catastrophic jumps . . . . . . . . . . . . . . . . . 187
Cervantes I. . . . . . . . . . . . . . . . . . . . . xv, 218
Chaillet A. . . . . . . . . . . . . . . . . . . . . . . . . . . xv
chaos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
Chiacchio P. . . . . . . . . . . . . . . . . . . . . . . . 283
Chiaverini S. . . . . . . . . . . . . . . . . . . . . . . . . 89
Choi Y. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218
Christoﬀel
symbol. . . . . . . . . . . . . . . . . . . . . . . . . . . .97
symbols. . . . . . . . . . . . . . . . . . . . . . . . . . .73
Chua L. O.. . . . . . . . . . . . . . . . . . . . . . . . .196
Chung W. K. . . . . . . . . . . . . . . . . . . . . . . 218
CICESE. . . . . . . . . . . . . . . . . . . . . . . . . . . .xiv
closed loop . . . . . . . . . . . . . . . . . . . . 137, 224
adaptive control . . . . . . . . . . . . . . . . . 330
Computed-torque control . . . . . . . . 229
Computed-torque+ control. . . . . . .234
control P“D” with gravity compensa-
tion . . . . . . . . . . . . . . . . . . . . . . . . . . 294
P“D” control with desired gravity
compensation. . . . . . . . . . . . . . . . .302
PD control with compensation . . . 245
PD control with desired gravity
compensation. . . . . . . . . . . . . . . . .173
PD control with gravity compensation
159
PD plus feedforward control . . . . . 271
PD+ control . . . . . . . . . . . . . . . . . . . . . 249
PID control. . . . . . . . . . . . . . . . . . . . . .205
closed-loop
PD control. . . . . . . . . . . . . . . . . . . . . . .143
Coleman C. . . . . . . . . . . . . . . . . . . . . . . . . . 54
Computed-torque control
closed loop. . . . . . . . . . . . . . . . . . . . . . .229
control law. . . . . . . . . . . . . . . . . . . . . . .228
pendulum. . . . . . . . . . . . . . . . . . . . . . . .231
Computed-torque+ control
closed loop. . . . . . . . . . . . . . . . . . . . . . .234
control law. . . . . . . . . . . . . . . . . . . . . . .233
CONACyT . . . . . . . . . . . . . . . . . . . . . . . . . xiv
control
adaptive. . . . . . . . .see adaptive control
adaptive Slotine and Li . . . . . . . . . . 361
Computed-torque. . . . . . . . . . . . . . . . .see
Computed-torque control
Computed-torque+. . . . . . . . . . . . . . . see
Computed-torque+ control
feedforward . . see feedforward control
force . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
fuzzy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
hybrid motion/force. . . . . . . . . . . . . . .16
impedance . . . . . . . . . . . . . . . . . . . . . . . . 16
law . . . . . . . . . . . . . . . . . . . . . . . . . 136, 224
learning . . . . . . . . . . . . . . . . . . . . . . 15, 333
motion. . . . . . . . . . . . . . . . . . . . . . . . . . .223
neural-networks-based. . . . . . . . . . . . .15
P. . . . . . . . . . . . . . . . . . . . .see PD control
P“D” with desired gravity compensa-
tion see P“D” control with desired
gravity compensation
P“D” with gravity compensation
see control P“D” with gravity
compensation
PD . . . . . . . . . . . . . . . . . . . see control PD

Index
421
PD plus feedforward. . . . .see PD plus
feedforward control
PD with desired gravity compensa-
tion . . see PD control with desired
compensation of gravity
PD with gravity compensation
see control PD with gravity
compensation
PD+ . . . . . . . . . . . . . . . see PD+ control
PID . . . . . . . . . . . . . . . . . see PID control
position. . . . . . . . . . . . . . . . . . . . . . . . . . .13
set-point. . . . . . . . . . . . . . . . . . . . . . . . .136
Slotine and Li see PD controller with
compensation
speciﬁcations. . . . . . . . . . . . . . . . . . . . . .12
variable-structure . . . . . . . . . . . . . . . . . 15
without measurement of velocity . 291
control law . . . . . . . . . . . . . . . . . . . . 136, 224
adaptive . . . . . . . . . . . . . . . . . . . . . . . . . 328
Computed-torque control . . . . . . . . 228
Computed-torque+ control. . . . . . .233
control P“D” with gravity compensa-
tion . . . . . . . . . . . . . . . . . . . . . . . . . . 293
feedforward control . . . . . . . . . . . . . . 264
P“D” control with desired gravity
compensation. . . . . . . . . . . . . . . . .300
PD control. . . . . . . . . . . . . . . . . . . . . . .142
PD control with desired gravity
compensation. . . . . . . . . . . . . . . . .171
PD control with gravity compensation
157
PD plus feedforward control . . . . . 269
PD+ control . . . . . . . . . . . . . . . . . . . . . 248
PID control. . . . . . . . . . . . . . . . . . . . . .201
Slotine and Li . . . . . . . . . . . . . . . . . . . 244
control P“D” with gravity compensation
closed loop. . . . . . . . . . . . . . . . . . . . . . .294
control law. . . . . . . . . . . . . . . . . . . . . . .293
controller. . . . . . . . . . . . . . . . . . . . . .136, 224
coordinates
Cartesian . . . . . . . . . . . . . . . . . . . . 61, 115
generalized. . . . . . . . . . . . . . . . . . . . . . . .78
joint . . . . . . . . . . . . . . . . . . . . . . . . . 60, 115
Coriolis
forces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
Craig J. 88, 109, 139, 238, 283, 331, 332
critically damped . . . . . . . . . . . . . . . . . . 231
damping coeﬃcient. . . . . . . . . . . . . . . . . .84
Dawson D. M. . . . . . . . 139, 140, 333, 378
Dawson, D. M. . . . . . . . . . . . . . . . . . . . . . 308
DC motors . . . . . . . . . . . . . . . . . . . . . . . . . 135
de Jager B. . . . . . . . . . . . . . . . . . . . . . . . . 333
de Queiroz M.. . . . . . . . . . . . . . . . . . . . . .140
degrees of freedom. . . . . . . . . . . . . . . . . . . .4
Denavit–Hartenberg . . . . . . . . . . . . . . . . . 88
desired trajectory . . . . . . . . . . . . . . . . . . 327
Desoer C. . . . . . . . . . . . . . . . . . . . . . . . . . . 398
diﬀerential equation
autonomous . . . . . . . . . . . . . . . . . . . 28, 49
linear . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
nonlinear . . . . . . . . . . . . . . . . . . . . . . . . . 28
digital technology . . . . . . . . . . . . . . . . . . 263
direct method of Lyapunov . . . . . . . . . . 27
direct-current motor
linear model . . . . . . . . . . . . . . . . . . . . . . 83
direct-current motors . . . . . . . . . . . 82, 411
model linear . . . . . . . . . . . . . . . . . . . . . 416
nonlinear model. . . . . . . . . . . . . . . . . .417
direct-drive
robot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
DOF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
Dorsey J. . . . . . . . . . . . . . . . . . . . . . . . . . . 218
dynamic linear . . . . . . . . . . . . . . . . . . . . . 396
dynamics
residual. . . . . . . . . . . . . . . . . . . . . . . . . .102
Egeland O. . . . . . . . . . . . . . . . . . . . . . 89, 259
eigenvalues . . . . . . . . . . . . . . . . . . . . . . . . . . 24
elasticity . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
electric motors . . . . . . . . . . . . . . . . . . . . . . 77
energy
kinetic . . . . . . . . . . . . . . . . . . . . . . . . 71, 78
potential . . . . . . . . . . . . . . . . . . . . . . 72, 79
equations of motion
Lagrange’s . . . . . . . . . . . . . . . . . . . . 62, 72
equilibrium
asymptotically stable . . . . . . . . . . 37, 38
bifurcation. . . . . . . . . . . . . . . . . . . . . . .187
deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . 28
exponentially stable . . . . . . . . . . . . . . . 38
isolated . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
stable . . . . . . . . . . . . . . . . . . . . . . . . . 31, 32
unstable . . . . . . . . . . . . . . . . . . . . . . . . . . 39
error
position . . . . . . . . . . . . . . . . . . . . . 136, 223
velocity . . . . . . . . . . . . . . . . . . . . . . . . . . 224

422
Index
feedforward control
control law. . . . . . . . . . . . . . . . . . . . . . .264
pendulum. . . . . . . . . . . . . . . . . . . . . . . .266
ﬁxed point . . . . . . . . . . . . . . . . . . . . . . . . . . 26
Fixot N.. . . . . . . . . . . . . . . . . . . . . . .308, 332
Fomin S. V. . . . . . . . . . . . . . . . . . . . . . . . . . 54
forces
centrifugal and Coriolis . . . . . . . . . . . 72
conservative. . . . . . . . . . . . . . . . . . . . . . .63
dissipative . . . . . . . . . . . . . . . . . . . . . . . . 76
external. . . . . . . . . . . . . . . . . . . . . . . . . . .73
friction. . . . . . . . . . . . . . . . . . . . . . . . . . . .76
gravitational . . . . . . . . . . . . . . . . . . . . . . 72
nonconservative . . . . . . . . . . . . . . . . . . . 63
friction
coeﬃcient . . . . . . . . . . . . . . . . . . . . . . . . . 83
forces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
nonlinear . . . . . . . . . . . . . . . . . . . . . . . . 417
Fu K.. . . . . . . . . . . . . . . . . . . . . .88, 139, 238
function
candidate Lyapunov. . . . . . . . . . . . . . .43
continuous . . . . . . . . . . . . . . . . . . . . . . . 390
decrescent . . . . . . . . . . . . . . . . . . . . . . . . 41
globally positive deﬁnite . . . . . . . . . . 41
locally positive deﬁnite. . . . . . . . . . . .40
Lyapunov . . . . . . . . . . . . . . . . . . . . . . . . . 44
positive deﬁnite . . . . . . . . . . . . . . 41, 401
quadratic . . . . . . . . . . . . . . . . . . . . . . . . . 41
radially unbounded . . . . . . . . . . . . . . . 41
strict Lyapunov . . . . . . . . 163, 167, 279
gain
adaptive . . . . . . . . . . . . . . . . . . . . . . . . . 329
derivative . . . . . . . . . . . . . . . . . . . . . . . . 141
integral . . . . . . . . . . . . . . . . . . . . . . . . . . 201
position . . . . . . . . . . . . . . . . . . . . . 141, 328
velocity . . . . . . . . . . . . . . . . . . . . . 141, 328
gear. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .83
gears . . . . . . . . . . . . . . . . . . . . . . . . . . . 77, 412
global asymptotic stability . . . . . . . . . . 48
deﬁnition. . . . . . . . . . . . . . . . . . . . . .37, 38
theorem. . . . . . . . . . . . . . . . . . . . . . . . . . .47
global exponential stability . . . . . . . . . . 48
deﬁnition of. . . . . . . . . . . . . . . . . . . . . . .38
theorem. . . . . . . . . . . . . . . . . . . . . . . . . . .47
global minimum. . . . . . . . . . . . . . . . . . . .181
global uniform asymptotic stability
theorem. . . . . . . . . . . . . . . . . . . . . . . . . . .47
Godhavn J. M.. . . . . . . . . . . . . . . . . . . . .259
Goldstein H. . . . . . . . . . . . . . . . . . . . . . . . . 89
Gonzalez R. . . . . . . . . . . . . . . . 88, 139, 238
Goodwin G. C.. . . . . . . . . . . . . . . . . . . . .331
gradient . . . . . . . . . . . . . . 73, 182, 403, 405
adaptive law . . . . . . . . see adaptive law
Guckenheimer J. . . . . . . . . . . . . . . . . . . . 196
Hahn W. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
Hale J. K. . . . . . . . . . . . . . . . . . . . . . . 54, 196
Hauser W. . . . . . . . . . . . . . . . . . . . . . . . . . . 89
Hessian. . . . . . . . . . . . . . . . . . .182, 387, 403
Hollerbach J.. . . . . . . . . . . . . . . . . . . . . . .283
Holmes P.. . . . . . . . . . . . . . . . . . . . . . . . . .196
Hopﬁeld. . . . . . . . . . . . . . . . . . . . . . . . . . . . .55
Horn R. A.. . . . . . . . . . . . . . . . . . . . . . . . .397
Horowitz R. . . . . . . . . . . xv, 331, 332, 334
Hsu L. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332
Hsu P. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331
Ibarra J. M.. . . . . . . . . . . . . . . . . . . . . . . . .xv
In-Joong Ha . . . . . . . . . . . . . . . . . . . . . . . 418
inductance . . . . . . . . . . . . . . . . . . . . . 83, 411
inertia
matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
rotor’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
input . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82, 84
input–output. . . . . . . . . . . . . . . . . . . . . . .390
inputs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .73
instability
deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . 39
integrator . . . . . . . . . . . . . . . . . . . . . . . . . . 201
Jackson E. A. . . . . . . . . . . . . . . . . . . . . . . 196
Jacobian . . . . . . . . . . . . . . . . . . . . . . . 92, 116
Johansson R.. . . . . . . . . . . . . . . . . . . . . . .332
Johnson C. R.. . . . . . . . . . . . . . . . . 333, 397
joint
elastic . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
prismatic . . . . . . . . . . . . . . . . . . . . . . . . . 59
revolute. . . . . . . . . . . . . . . . . . . . . . . . . . .59
joint positions . . . . . . . . . . . . . . . . . . . . . . . 60
Kanade T. . . . . . . . . . . . . . . . . . . . . 283, 334
Kanellakopoulos I. . . . . . . . . . . . . . . . . . 333
Kao W. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 334
Kawamura S.. . . . . . . . . . . . . . . . . .168, 218
Kelly R. . . . 196, 217, 218, 238, 239, 259,
283, 284, 308, 332, 358, 378
Khalil H. . . . . . . . . . . . . . . . . . . . . . . . 54, 333
Khosla P. . . . . . . . . . . . . . . . . . . . . . . . . . . 334

Index
423
Khosla P. K. . . . . . . . . . . . . . . . . . . . . . . . 283
kinematics
direct . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
inverse . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
Ko¸cak H. . . . . . . . . . . . . . . . . . . . . . . . . . . 196
Koditschek D. E. xv, 259, 260, 333, 334,
359
Kokkinis T. . . . . . . . . . . . . . . . . . . . . . . . . 283
Kokotovi´c P. . . . . . . . . . . . . . . . . . . . . . . . 333
Kolmogorov A. N.. . . . . . . . . . . . . . . . . . .54
Kosut R.. . . . . . . . . . . . . . . . . . . . . . . . . . .333
Krasovski˘ı N. N. . . . . . . . . . . . . . . . . . . . . 54
Kristi´c M.. . . . . . . . . . . . . . . . . . . . . . . . . .333
L¨ohnberg P.. . . . . . . . . . . . . . . . . . . . . . . .308
La Salle . . . . . . . . . . . . . . . . . . . see theorem
La Salle J. . . . . . . . . . . . . . . . . . . . . . . . . . . 53
Lagrange’s
equations of motion . . . . . . . . . . . . . . . 62
Lagrangian . . . . . . . . . . . . . . . . . . 63, 72, 79
Landau I. D. . . . . . . . . . . . . . . . . . . . . . . . 332
Landau I. D. . . . . . . . . . . . . . . . . . . . . . . . 333
Lee C. . . . . . . . . . . . . . . . . . . . . . 88, 139, 238
Lefschetz S. . . . . . . . . . . . . . . . . . . . . . . . . . 53
lemma
Barb˘alat’s . . . . . . . . . . . . . . . . . . . . . . . 397
Lewis F. L. . . . . . . . . . . . . . . . 139, 333, 378
Li W. . . . . . . . 54, 259, 331, 333, 377, 378
Li Z. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
linear dynamic system. . . . . . . . . . . . . .264
links
numeration of. . . . . . . . . . . . . . . . . . . . .59
Lipschitz . . . . . . . . . . . . . . . . . . . . . . 101, 180
Lischinsky P.. . . . . . . . . . . . . . . . . . . . . . .418
Lizarralde F. . . . . . . . . . . . . . . . . . . . . . . . 332
Lor´ıa A. . . . . . . . . . . . . . . . . . . . . . . . . . . . 218
Lozano R. . . . . . . . . . . . . . . . . . . . . . 332, 333
Luh J. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
Lyapunov
candidate function . . . . . . . . . . . . . . . . 43
direct method . . . . . . . . . . . . . . . . . 27, 44
function. . . . . . . . . . . . . . . . . . . . . . . . . . .44
second method . . . . . . . . . . . . . . . . . . . . 27
stability. . . . . . . . . . . . . . . . . . . . . . . . . . .27
stability in the sense of. . . . . . . . . . . .31
theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
uniform stability in the sense of . . . 32
Lyapunov, A. M. . . . . . . . . . . . . . . . . . . . . 53
M’Saad M. . . . . . . . . . . . . . . . . . . . . . . . . . 333
manipulator
deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . 4
Mann W. R. . . . . . . . . . . . . . . . . . . . . . . . 397
mapping contraction. . . . . . . see theorem
Marcus M. . . . . . . . . . . . . . . . . . . . . . . . . . 397
Mareels I. M. Y. . . . . . . . . . . . . . . . . . . . 333
Marino R. . . . . . . . . . . . . . . . . . . . . . . 89, 333
Marth G. T. . . . . . . . . . . . . . . . . . . . . . . . 283
Massner W. . . . . . . . . . . . . . . . . . . . . . . . . 334
matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
centrifugal and Coriolis. . . . . . . .73, 97
diagonal . . . . . . . . . . . . . . . . . . . . . . . . . . 22
Hessian . . . . . . . . . . . . . . . . 182, 387, 403
identity . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
inertia. . . . . . . . . . . . . . . . . . . . . . . . .72, 95
Jacobian . . . . . . . . . . . . . . . . . . . . . 92, 116
negative deﬁnite . . . . . . . . . . . . . . . . . . 24
negative semideﬁnite . . . . . . . . . . . . . . 24
nonsingular . . . . . . . . . . . . . . . . . . . . . . . 23
partitioned. . . . . . . . . . . . . . . . . .124, 384
positive deﬁnite . . . . . . . . . . . . . . . 23, 41
positive semideﬁnite . . . . . . . . . . . . . . 24
singular . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
skew-symmetric . . . . . . . . . . . . . . . 22, 98
square . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
symmetric . . . . . . . . . . . . . . . . . . . . . . . . 22
transfer . . . . . . . . . . . . . . . . . . . . . . . . . . 396
transpose . . . . . . . . . . . . . . . . . . . . . . . . . 21
Mawhin J. . . . . . . . . . . . . . . . . . . . . . . . . . . 54
Mayorga R. V. . . . . . . . . . . . . . . . . . . . . . . 89
Meza J. L. . . . . . . . . . . . . . . . . . . . . . . . . . 217
Middleton R. H. . . . . . . . . . . . . . . . . . . . 331
Milano N. . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
Minc H.. . . . . . . . . . . . . . . . . . . . . . . . . . . .397
Miyazaki F.. . . . . . . . . .168, 195, 217, 218
model
direct kinematic. . . . . . . . . . . . . .61, 115
dynamic. . . . . . . . . . . . . . . . . . . . . . .10, 71
elastic joints. . . . . . . . . . . . . . . . . . . . .77
with actuators. . . . . . . . . . . . . . . . . . .82
with elastic joints . . . . . . . . . . . . . . . 89
with friction. . . . . . . . . . . . . . . . . . . . .75
dynamics . . . . . . . . . . . . . . . . . . . . . . . . . 88
inverse kinematic. . . . . . . . . . . . .61, 116
kinematics . . . . . . . . . . . . . . . . . . . . . . . . 88
moment of inertia . . . . . . . . . . . . . . . . . . . 77
motion equations
Lagrange’s . . . . . . . . . . . . . . . . . . . . . . . . 79

424
Index
motor-torque constant . . . . . . . . . . 83, 411
multivariable linear system . . . . . . . . . 230
Murphy S. . . . . . . . . . . . . . . . . . . . . . . . . . 218
Nagarkatti S. P.. . . . . . . . . . . . . . . . . . . .140
Naniwa T. . . . . . . . . . . . . . . . . . . . . . . . . . 334
Narendra K.. . . . . . . . . . . . . . . . . . .333, 398
Nicklasson P. J. . . . . . . . . . . . . . . . . . . . . 139
Nicosia S. . . . . . . . . . . . . . . . . . . . . . . 89, 308
Nijmeijer H.. . . . . . . . . . . . . . . . . . . .xv, 308
norm
Euclidean . . . . . . . . . . . . . . . . . . . . . . . . . 20
spectral . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
numerical approximation . . . . . . . . . . . 291
observers. . . . . . . . . . . . . . . . . . . . . . . . . . .291
Ogata K.. . . . . . . . . . . . . . . . . . . . . . . . . . .418
Olsson H. . . . . . . . . . . . . . . . . . . . . . . . . . . 418
open loop . . . . . . . . . . . . . . . . . . . . . . . . . . 265
operator
delay . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299
diﬀerential . . . . . . . . . . . . . . . . . . . . . . . 292
optical encoder. . . . . . . . . . . . . . . . . . . . .291
optimization . . . . . . . . . . . . . . . . . . . . . . . 181
Ortega R. . . xv, 109, 139, 218, 238, 259,
308, 332, 378
oscillator
harmonic . . . . . . . . . . . . . . . . . . . . . . . . . 32
van der Pol . . . . . . . . . . . . . . . . . . . . . . . 39
output . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82
outputs. . . . . . . . . . . . . . . . . . . . . . . . . .73, 84
P´amanes A. . . . . . . . . . . . . . . . . . . . . . . . . . xv
P“D” control with desired gravity
compensation
closed loop. . . . . . . . . . . . . . . . . . . . . . .302
control law. . . . . . . . . . . . . . . . . . . . . . .300
Paden B. . . . . . . . . . . . . . . . . . 168, 260, 283
Panja R. . . . . . . . . . . . . . . . . . . . . . . 168, 260
parameters
adaptive . . . . . . . . . . . . . . . . . . . . . . . . . 328
of interest. . . . . . . . . . . . . . . . . . . . . . . .317
parametric convergence. . . . . . . .329, 330
parametric errors. . . . . . . . . . . . . . . . . . .330
Parker T. S.. . . . . . . . . . . . . . . . . . . . . . . .196
Parra–Vega V. . . . . . . . . . . . . . . . . . . . . . 334
passivity . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
Paul R.. . . . . . . . . . . . . . . . . . . .88, 139, 217
PD control . . . . . . . . . . . . . . . . . . . . . . . . . 141
closed-loop. . . . . . . . . . . . . . . . . . . . . . .143
control law. . . . . . . . . . . . . . . . . . . . . . .142
pendulum . . . . . . . . . . . . . . . . . . . 146, 150
PD control with adaptive compensation
363
closed loop. . . . . . . . . . . . . . . . . . . . . . .364
PD control with adaptive desired
gravity compensation
adaptive law . . . . . . . . . . . . . . . . . . . . . 339
closed loop. . . . . . . . . . . . . . . . . . . . . . .342
control law. . . . . . . . . . . . . . . . . . . . . . .339
PD control with compensation
closed loop. . . . . . . . . . . . . . . . . . . . . . .245
PD control with desired gravity
compensation
closed loop. . . . . . . . . . . . . . . . . . . . . . .173
control law. . . . . . . . . . . . . . . . . . . . . . .171
pendulum . . . . . . . . . . . . . . . . . . . 174, 187
PD control with gravity compensation
157
closed loop. . . . . . . . . . . . . . . . . . . . . . .159
control law. . . . . . . . . . . . . . . . . . . . . . .157
pendulum. . . . . . . . . . . . . . . . . . . . . . . .168
robustness . . . . . . . . . . . . . . . . . . . . . . . 168
PD control with gravity precompensa-
tion . . see PD control with desired
gravity compensation
PD plus feedforward control
closed loop. . . . . . . . . . . . . . . . . . . . . . .271
control law. . . . . . . . . . . . . . . . . . . . . . .269
experiments. . . . . . . . . . . . . . . . . . . . . .283
pendulum. . . . . . . . . . . . . . . . . . . . . . . .273
tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
PD+ control
closed loop. . . . . . . . . . . . . . . . . . . . . . .249
control law. . . . . . . . . . . . . . . . . . . . . . .248
pendulum. . . . . . . . . . . . . . . . . . . . . . . .252
pendulum . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
Computed-torque control . . . . . . . . 231
feedforward control . . . . . . . . . . . . . . 266
kinetic energy. . . . . . . . . . . . . . . . . . . . .45
PD control. . . . . . . . . . . . . . . . . . 146, 150
PD control with desired gravity
compensation. . . . . . . . . . . . . . . . .174
PD control with gravity compensation
168
PD plus feedforward control . . . . . 273
PD+ control . . . . . . . . . . . . . . . . . . . . . 252
PID control. . . . . . . . . . . . . . . . . . . . . .218

Index
425
potential energy. . . . . . . . . . . . . . . . . . .45
with friction . . . . . . . . . . . . . . . . . . . . . . 57
permanent-magnet . . . . . . . . . . . . . . . . . 411
PID control
closed loop. . . . . . . . . . . . . . . . . . . . . . .205
control law. . . . . . . . . . . . . . . . . . . . . . .201
modiﬁed . . . . . . . . . . . . . . . . . . . . . . . . . 213
robustness . . . . . . . . . . . . . . . . . . . . . . . 217
tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . 213
pitchfork. . . . . . . . . . . . . . . .see bifurcation
potentiometer . . . . . . . . . . . . . . . . . . . . . . 291
Praly L.. . . . . . . . . . . . . . . . . . . . . . . . . . . .333
properties
gravity vector. . . . . . . . . . . . . . . . . . . .101
of residual dynamics . . . . . . . . . . . . . 102
of the Centrifugal and Coriolis matrix
97
of the inertia matrix . . . . . . . . . . . . . . 95
Qu Z. . . . . . . . . . . . . . . . . . . . . . . . . . 139, 218
Queiroz M. S. de . . . . . . . . . . . . . . . . . . . 308
Ramadarai A. K.. . . . . . . . . . . . . . . . . . .283
Rayleigh–Ritz . . . . . . . . . . . . . see theorem
Reyes F. . . . . . . . . . . . . . . . . . . . . . . . . . . . 284
Riedle B. D.. . . . . . . . . . . . . . . . . . .283, 333
Rizzi A. . . . . . . . . . . . . . 260, 333, 334, 359
robot
Cartesian . . . . . . . . . . . . . . . . . . . . . . . . . 69
deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . 4
direct-drive . . . . . . . . . . . . . . . . . . . . . . . 77
dynamic model. . . . . . . . . . . . . . . . . . . .71
mobile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
robots
navigation . . . . . . . . . . . . . . . . . . . . . . . . 13
stability of . . . . . . . . . . . . . . . . . . . . . . . . 75
Rocco P. . . . . . . . . . . . . . . . . . . . . . . . . . . . 218
rotors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
Rouche N.. . . . . . . . . . . . . . . . . . . . . . . . . . .54
saddle-node . . . . . . . . . . . . . see bifurcation
Sadegh N. . . . . . . . . . . . . . . . . . . . . . 331, 332
Salgado R. . . . . . . . . . . . . . . . . . . . . . . . . . 283
sampling period . . . . . . . . . . . . . . . . . . . . 299
Samson C. . . . . . . . . . . . . . . . . . . . . . xv, 217
Santib´a˜nez V. . . . . . . . . . . . . 110, 217, 283
Sastry S. . . . . . . . . . . . . . . . . . . 54, 331, 333
Schwartz
inequality . . . . . . . . . . . . . . . . . . . . . . . . . 21
Schwartz inequality . . . . . . . . . . . . . . . . . 21
Sciavicco L. . . . . . . . . . . . . . . . . . . . . . . . . 139
sensors . . . . . . . . . . . . . . . . . . . . 78, 136, 224
Seung-Jean K. . . . . . . . . . . . . . . . . . . . . . 418
Siciliano B. . . . . . . . . . . . . . . . . 89, 139, 140
singular conﬁguration . . . . . . . . . . . . . . 118
Sira-Ram´ırez H. . . . . . . . . . . . . . . . . xv, 139
Slotine and Li . . . . . . . . . . . . . . see control
control law. . . . . . . . . . . . . . . . . . . . . . .244
Slotine J. J.. . .xv, 54, 88, 139, 259, 331,
333, 377, 378
space
Ln
2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .390
Ln
p . . . . . . . . . . . . . . . . . . . . . . . . . . 390, 397
Ln
∞. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 391
Spong M. xv, 88, 89, 109, 139, 153, 167,
217, 238, 259, 332–334, 378, 418
stability
deﬁnition. . . . . . . . . . . . . . . . . . . . . .31, 32
of robots . . . . . . . . . . . . . . . . . . . . . . . . . . 75
semiglobal . . . . . . . . . . . . . . . . . . . . . . . 207
theorem. . . . . . . . . . . . . . . . . . . . . . . . . . .44
Stoten D. P. . . . . . . . . . . . . . . . . . . . . . . . 333
Stoughton R.. . . . . . . . . . . . . . . . . . . . . . .283
Sylvester . . . . . . . . . . . . . . . . . . see theorem
symbols of Christoﬀel . . . . . . . . . . . . . . . 73
system dynamic lineal . . . . . . . . . . . . . .202
tachometer. . . . . . . . . . . . . . . . . . . . . . . . .291
Takegaki M. . . . . . . . . . . . . . . 153, 167, 195
Takeyama I.. . . . . . . . . . . . . . . . . . . . . . . .283
Tarn T. J. . . . . . . . . . . . . . . . . . . . . . . 90, 283
Taylor A. E. . . . . . . . . . . . . . . . . . . . . . . . 397
theorem
contraction mapping . . . . . . . . . . . . . . 26
application . . . . . . . . . . . . . . . . . . . . . 147
contraction mapping theorem
application . . . . . . . . . . . . . . . . . . . . . 180
global asymptotic stability . . . . . . . . 47
global exponential stability. . . . . . . .47
global uniform asymptotic stability47
La Salle
application . . . . . . . . . . . . . . . . . . . . . 145
La Salle’s . . . . . . . . . . . . . . . . . . . . . 49, 51
application . . . . . . . . . . . . . . . . 184, 211
use of . . . . . . . . . . . . . . . . . . . . . . . . . . 160
mean value . . . . . . . . . . . . . . . . . . . . . . 392
mean value for integrals. . . . . . . . . .388
of Rayleigh–Ritz . . . . . . . . . . . . . . . . . . 24

426
Index
of Sylvester . . . . . . . . . . . . . . . . . . . . . . . 23
of Taylor. . . . . . . . . . . . . . . . . . . . . . . . .387
stability. . . . . . . . . . . . . . . . . . . . . . . . . . .44
uniform stability . . . . . . . . . . . . . . . . . . 44
Tomei P.. . . . . . . . . . . . .195, 308, 333, 359
torsional ﬁctitious springs . . . . . . . . . . . 79
Tourassis V.. . . . . . . . . . . . . . . . . . . . . . . . .89
tuning. . . . . . . . . . . . . . . . . . . . . . . . .201, 213
PD plus feedforward control . . . . . 273
uncertainties
parametric. . . . . . . . . . . . . . . . . . . . . . .265
uncertainty . . . . . . . . . . . . . . . . . . . . . . . . 313
van der Pol . . . . . . . . . . . . . . . see oscillator
vector . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
gravity. . . . . . . . . . . . . . . . . . . . . . . . . . .101
of external forces. . . . . . . . . . . . . . . . . .73
of gravitational forces . . . . . . . . . . . . . 72
parametric errors . . . . . . . . . . . . . . . . 330
Vidyasagar M.. . .88, 109, 139, 153, 167,
217, 238, 333, 334, 378, 397, 398,
418
voltage . . . . . . . . . . . . . . . . . . . . . . . . . 83, 412
Wen J. T. . . . xv, 140, 218, 238, 283, 331
Whitcomb L. L.. .xv, 260, 333, 334, 359
Wiggins S. . . . . . . . . . . . . . . . . . . . . . . . . . 196
Wittenmark B.. . . . . . . . . . . . . . . . . . . . .333
Wong A. K. . . . . . . . . . . . . . . . . . . . . . . . . . 89
Yoshikawa T..88, 89, 139, 153, 167, 238
Yu T. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332
Yun X.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .90
Zhang F.. . . . . . . . . . . . . . . . . . . . . . . . . . .140

