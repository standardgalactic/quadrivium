Academic Press is an imprint of Elsevier
The Boulevard, Langford Lane, Kidlington, Oxford OX5 1GB, UK
225 Wyman Street, Waltham, MA 02451, USA
First edition 2014
Copyright © 2014 Elsevier Ltd. All rights reserved.
No part of this publication may be reproduced, stored in a retrieval system or transmitted in any form or by any 
means electronic, mechanical, photocopying, recording or otherwise without the prior written permission of the 
publisher.
Permissions may be sought directly from Elsevier’s Science & Technology Rights Department in Oxford, UK: 
phone (+44) (0) 1865 843830; fax (+44) (0) 1865 853333; email: permissions@elsevier.com. Alternatively you 
can submit your request online by visiting the Elsevier web site at http://elsevier.com/locate/permissions, and 
selecting Obtaining permission to use Elsevier material.
Notice
No responsibility is assumed by the publisher for any injury and/or damage to persons or property as a matter of 
products liability, negligence or otherwise, or from any use or operation of any methods, products, instructions or 
ideas contained in the material herein. Because of rapid advances in the medical sciences, in particular, indepen-
dent verification of diagnoses and drug dosages should be made.
Library of Congress Cataloging in Publication Data
A catalog record for this book is available from the Library of Congress
British Library Cataloguing in Publication Data
A catalogue record for this book is available from the British Library
ISBN: 978-0-12-411597-2
For information on all Elsevier publications
visit our website at www.store.elsevier.com
Printed and bound in Poland.
14  15  16  17  10  9  8  7  6  5  4  3  2  1

xxi
Signal Processing at Your Fingertips!
Let us flash back to the 1970s when the editors-in-chief of this e-reference were graduate students. 
One of the time-honored traditions then was to visit the libraries several times a week to keep track of 
the latest research findings. After your advisor and teachers, the librarians were your best friends. We 
visited the engineering and mathematics libraries of our Universities every Friday afternoon and poured 
over the IEEE Transactions, Annals of Statistics, the Journal of Royal Statistical Society, Biometrika, 
and other journals so that we could keep track of the recent results published in these journals. Another 
ritual that was part of these outings was to take sufficient number of coins so that papers of interest 
could be xeroxed. As there was no Internet, one would often request copies of reprints from authors 
by mailing postcards and most authors would oblige. Our generation maintained thick folders of hard-
copies of papers. Prof. Azriel Rosenfeld (one of RC’s mentors) maintained a library of over 30,000 
papers going back to the early 1950s!
Another fact to recall is that in the absence of Internet, research results were not so widely dis-
seminated then and even if they were, there was a delay between when the results were published in 
technologically advanced western countries and when these results were known to scientists in third 
world countries. For example, till the late 1990s, scientists in US and most countries in Europe had a 
lead time of at least a year to 18 months since it took that much time for papers to appear in journals 
after submission. Add to this the time it took for the Transactions to go by surface mails to various 
libraries in the world. Scientists who lived and worked in the more prosperous countries were aware of 
the progress in their fields by visiting each other or attending conferences.
Let us race back to 21st century! We live and experience a world which is fast changing with rates 
unseen before in the human history. The era of Information and Knowledge societies had an impact on 
all aspects of our social as well as personal lives. In many ways, it has changed the way we experience 
and understand the world around us; that is, the way we learn. Such a change is much more obvious to 
the younger generation, which carries much less momentum from the past, compared to us, the older 
generation. A generation which has grew up in the Internet age, the age of Images and Video games, the 
age of IPAD and Kindle, the age of the fast exchange of information. These new technologies comprise 
a part of their “real” world, and Education and Learning can no more ignore this reality. Although many 
questions are still open for discussions among sociologists, one thing is certain. Electronic publishing 
and dissemination, embodying new technologies, is here to stay. This is the only way that effective 
pedagogic tools can be developed and used to assist the learning process from now on. Many kids in the 
early school or even preschool years have their own IPADs to access information in the Internet. When 
they grow up to study engineering, science, or medicine or law, we doubt if they ever will visit a library 
as they would by then expect all information to be available at their fingertips, literally!
Another consequence of this development is the leveling of the playing field. Many institutions in 
lesser developed countries could not afford to buy the IEEE Transactions and other journals of repute. 
Even if they did, given the time between submission and publication of papers in journals and the time 
it took for the Transactions to be sent over surface mails, scientists and engineers in lesser developed 
countries were behind by two years or so. Also, most libraries did not acquire the proceedings of confer-
ences and so there was a huge gap in the awareness of what was going on in technologically advanced 
Introduction

xxii
Introduction
countries. The lucky few who could visit US and some countries in Europe were able to keep up with 
the progress in these countries. This has changed. Anyone with an Internet connection can request or 
download papers from the sites of scientists. Thus there is a leveling of the playing field which will lead 
to more scientist and engineers being groomed all over the world.
The aim of Online Reference for Signal Processing project is to implement such a vision. We all 
know that asking any of our students to search for information, the first step for him/her will be to click 
on the web and possibly in the Wikipedia. This was the inspiration for our project. To develop a site, 
related to the Signal Processing, where a selected set of reviewed articles will become available at a 
first “click.” However, these articles are fully refereed and written by experts in the respected topic. 
Moreover, the authors will have the “luxury” to update their articles regularly, so that to keep up with 
the advances that take place as time evolves. This will have a double benefit. Such articles, besides the 
more classical material, will also convey the most recent results providing the students/researchers with 
up-to-date information. In addition, the authors will have the chance of making their article a more 
“permanent” source of reference, that keeps up its freshness in spite of the passing time.
The other major advantage is that authors have the chance to provide, alongside their chapters, any 
multimedia tool in order to clarify concepts as well as to demonstrate more vividly the performance of 
various methods, in addition to the static figures and tables. Such tools can be updated at the author’s 
will, building upon previous experience and comments. We do hope that, in future editions, this aspect 
of this project will be further enriched and strengthened.
In the previously stated context, the Online Reference in Signal Processing provides a revolutionary 
way of accessing, updating and interacting with online content. In particular, the Online Reference will 
be a living, highly structured, and searchable peer-reviewed electronic reference in signal/image/video 
Processing and related applications, using existing books and newly commissioned content, which 
gives tutorial overviews of the latest technologies and research, key equations, algorithms, applications, 
standards, code, core principles, and links to key Elsevier journal articles and abstracts of non-Elsevier 
journals.
The audience of the Online Reference in Signal Processing is intended to include practicing engi-
neers in signal/image processing and applications, researchers, PhD students, post Docs, consultants, 
and policy makers in governments. In particular, the readers can be benefited in the following needs:
• 
To learn about new areas outside their own expertise.
• 
To understand how their area of research is connected to other areas outside their expertise.
• 
To learn how different areas are interconnected and impact on each other: the need for a 
“helicopter” perspective that shows the “wood for the trees.”
• 
To keep up-to-date with new technologies as they develop: what they are about, what is their 
potential, what are the research issues that need to be resolved, and how can they be used.
• 
To find the best and most appropriate journal papers and keeping up-to-date with the newest, best 
papers as they are written.
• 
To link principles to the new technologies.
The Signal Processing topics have been divided into a number of subtopics, which have also dic-
tated the way the different articles have been compiled together. Each one of the subtopics has been 
coordinated by an AE (Associate Editor). In particular:

xxiii
Introduction
	 1.	 Signal Processing Theory (Prof. P. Diniz)
	 2.	 Machine Learning (Prof. J. Suykens)
	 3.	 DSP for Communications (Prof. N. Sidiropulos)
	 4.	 Radar Signal Processing (Prof. F. Gini)
	 5.	 Statistical SP (Prof. A. Zoubir)
	 6.	 Array Signal Processing (Prof. M. Viberg)
	 7.	 Image Enhancement and Restoration (Prof. H. J. Trussell)
	 8.	 Image Analysis and Recognition (Prof. Anuj Srivastava)
	 9.	 Video Processing (other than compression), Tracking, Super Resolution, Motion Estimation, 
etc. (Prof. A. R. Chowdhury)
10.	 Hardware and Software for Signal Processing Applications (Prof. Ankur Srivastava)
11.	 Speech Processing/Audio Processing (Prof. P. Naylor)
12.	 Still Image Compression
13.		 Video Compression
We would like to thank all the Associate Editors for all the time and effort in inviting authors as well 
as coordinating the reviewing process. The Associate Editors have also provided succinct summaries 
of their areas.
The articles included in the current editions comprise the first phase of the project. In the second 
phase, besides the updates of the current articles, more articles will be included to further enrich the 
existing number of topics. Also, we envisage that, in the future editions, besides the scientific articles 
we are going to be able to include articles of historical value. Signal Processing has now reached an age 
that its history has to be traced back and written.
Last but not least, we would like to thank all the authors for their effort to contribute in this new 
and exciting project. We earnestly hope that in the area of Signal Processing, this reference will help 
level the playing field by highlighting the research progress made in a timely and accessible manner to 
anyone who has access to the Internet. With this effort the next breakthrough advances may be coming 
from all around the world.
The companion site for this work: http://booksite.elsevier.com/9780124166165 includes multimedia 
files (Video/Audio) and MATLAB codes for selected chapters.
Rama Chellappa
Sergios Theodoridis

xxv
Rama Chellappa received the B.E. (Hons.) degree in Electronics and Communication 
Engineering from the University of Madras, India in 1975 and the M.E. (with 
Distinction) degree from the Indian Institute of Science, Bangalore, India in 1977. 
He received the M.S.E.E. and Ph.D. Degrees in Electrical Engineering from Purdue 
University, West Lafayette, IN, in 1978 and 1981, respectively. During 1981–
1991, he was a faculty member in the department of EE-Systems at University 
of Southern California (USC). Since 1991, he has been a Professor of Electrical 
and Computer Engineering (ECE) and an affiliate Professor of Computer Science 
at University of Maryland (UMD), College Park. He is also affiliated with the 
Center for Automation Research, the Institute for Advanced Computer Studies (Permanent Member) 
and is serving as the Chair of the ECE department. In 2005, he was named a Minta Martin Professor 
of Engineering. His current research interests are face recognition, clustering and video summariza-
tion, 3D modeling from video, image and video-based recognition of objects, events and activities, 
dictionary-based inference, compressive sensing, domain adaptation and hyper spectral processing.
Prof. Chellappa received an NSF Presidential Young Investigator Award, four IBM Faculty 
Development Awards, an Excellence in Teaching Award from the School of Engineering at USC, and 
two paper awards from the International Association of Pattern Recognition (IAPR). He is a recipient 
of the K.S. Fu Prize from IAPR. He received the Society, Technical Achievement, and Meritorious 
Service Awards from the IEEE Signal Processing Society. He also received the Technical Achievement 
and Meritorious Service Awards from the IEEE Computer Society. At UMD, he was elected as a 
Distinguished Faculty Research Fellow, as a Distinguished Scholar-Teacher, received an Outstanding 
Innovator Award from the Office of Technology Commercialization, and an Outstanding GEMSTONE 
Mentor Award from the Honors College. He received the Outstanding Faculty Research Award and the 
Poole and Kent Teaching Award for Senior Faculty from the College of Engineering. In 2010, he was 
recognized as an Outstanding ECE by Purdue University. He is a Fellow of IEEE, IAPR, OSA, and 
AAAS. He holds four patents.
Prof. Chellappa served as the Editor-in-Chief of IEEE Transactions on Pattern Analysis and Machine 
Intelligence. He has served as a General and Technical Program Chair for several IEEE international 
and national conferences and workshops. He is a Golden Core Member of the IEEE Computer Society 
and served as a Distinguished Lecturer of the IEEE Signal Processing Society. Recently, he completed 
a two-year term as the President of the IEEE Biometrics Council.
About the Editors

xxvi
About the Editors
Sergios Theodoridis is currently Professor of Signal Processing and 
Communications in the Department of Informatics and Telecommunications 
of the University of Athens. His research interests lie in the areas of Adaptive 
Algorithms and Communications, Machine Learning and Pattern Recognition, 
Signal Processing for Audio Processing and Retrieval. He is the co-editor of the 
book “Efficient Algorithms for Signal Processing and System Identification,” 
Prentice Hall 1993, the co-author of the best selling book “Pattern Recognition,” 
Academic Press, 4th ed. 2008, the co-author of the book “Introduction to Pattern 
Recognition: A MATLAB Approach,” Academic Press, 2009, and the co-author of 
three books in Greek, two of them for the Greek Open University. He is Editor-in-Chief for the Signal 
Processing Book Series, Academic Press and for the E-Reference Signal Processing, Elsevier.
He is the co-author of six papers that have received best paper awards including the 2009 IEEE 
Computational Intelligence Society Transactions on Neural Networks Outstanding paper Award. He 
has served as an IEEE Signal Processing Society Distinguished Lecturer. He was Otto Monstead Guest 
Professor, Technical University of Denmark, 2012, and holder of the Excellence Chair, Department of 
Signal Processing and Communications, University Carlos III, Madrid, Spain, 2011.
He was the General Chairman of EUSIPCO-98, the Technical Program co-Chair for ISCAS-2006 
and ISCAS-2013, and co-Chairman and co-Founder of CIP-2008 and co-Chairman of CIP-2010. He 
has served as President of the European Association for Signal Processing (EURASIP) and as member 
of the Board of Governors for the IEEE CAS Society. He currently serves as member of the Board of 
Governors (Member-at-Large) of the IEEE SP Society.
He has served as a member of the Greek National Council for Research and Technology and he 
was Chairman of the SP advisory committee for the Edinburgh Research Partnership (ERP). He has 
served as Vice Chairman of the Greek Pedagogical Institute and he was for 4 years member of the 
Board of Directors of COSMOTE (the Greek mobile phone operating company). He is Fellow of IET, 
a Corresponding Fellow of the Royal Society of Edinburgh (RSE), a Fellow of EURASIP, and a Fellow 
of IEEE.

xxvii
Abdelhak M. Zoubir is a Fellow of the IEEE for contributions to statistical 
signal processing and an IEEE Distinguished Lecturer (Class 2010–2011). 
He received the Dipl.-Ing degree (B.Sc./B.Eng.) from Fachhochschule 
Niederrhein, Germany, in 1983, the Dipl.-Ing. (M.Sc./M.Eng.) and the Dr.-Ing. 
(Ph.D.) degree from Ruhr-Universität Bochum, Germany, in 1987 and 
1992, respectively, all in Electrical Engineering. Early placement in indus-
try (Klöckner-Moeller & Siempelkamp AG) was then followed by Associate 
Lectureship in the Division for Signal Theory at Ruhr-Universität Bochum, 
Germany. In June 1992, he joined Queensland University of Technology 
where he was Lecturer, Senior Lecturer, and then Associate Professor in the School of Electrical 
and Electronic Systems Engineering. In March 1999, he took up the position of Professor of 
Telecommunications at Curtin University of Technology, where he was Head of the School of 
Electrical & Computer Engineering from November 2001 until February 2003. He has been 
Professor of Signal Processing at Technische Universität Darmstadt since February 2003 and 
October 2012, respectively.
His research interest lies in statistical methods for signal processing with emphasis on boot-
strap techniques, robust detection and estimation, and array processing applied to telecom-
munications, radar, sonar, automotive monitoring and safety, and biomedicine. He published 
extensively on these areas. He was/is General Co-Chair or Technical Co-Chair of numerous 
international conferences. His current editorial work includes member of the Editorial Board 
of the EURASIP journal Signal Processing and Editor-In-Chief of the IEEE Signal Processing 
Magazine (2012–2014). He was Chair of the IEEE SPS Technical Committee Signal Processing 
Theory and Methods (SPTM). He currently serves on the Board of Directors of the European 
Association of Signal Processing (EURASIP).
Mats Viberg received the Ph.D. degree in Automatic Control from Linköping 
University, Sweden in 1989. He has held academic positions at Linköping 
University and visiting Scholarships at Stanford University and Brigham 
Young University, USA. Since 1993, he is a Professor of Signal Processing at 
Chalmers University of Technology, Sweden. During 1999–2004 he served as 
the Chair of the Department of Signals and Systems. Since 2011, he holds a 
position as First Vice President at Chalmers University of Technology. 
His research interests are in Statistical Signal Processing and its various 
applications, including Antenna Array Signal Processing, System Identification, 
Wireless Communications, Radar Systems, and Automotive Signal Processing.
He has served in various capacities in the IEEE Signal Processing Society, including Chair of 
the Technical Committee (TC) on Signal Processing Theory and Methods (2001–2003) Chair 
of the TC on Sensor Array and Multichannel (2011–2012), Associate Editor of the Transactions 
Section Editors
Section 1
Section 2

xxviii
﻿ Section Editors
on Signal Processing (2004–2005), member of the Awards Board (2005–2007), and member at 
large of the Board of Governors (2010–2012).
He has received two Paper Awards from the IEEE Signal Processing Society (1993 and 1999 
respectively), and the Excellent Research Award from the Swedish Research Council (VR) in 
2002. He is a Fellow of the IEEE since 2003, and his research group received the 2007 EURASIP 
European Group Technical Achievement Award. In 2008, he was elected into the Royal Swedish 
Academy of Sciences (KVA). He has published more than 45 journal papers, together cited more 
than 6800 times, and his H-index is 32 (Google Scholar, April 2013).

xxix
CHAPTER 2
Visa Koivunen received the D.Sc. degree from the University of Oulu, Finland. 
He was a visiting researcher at the University of Pennsylvania from 1992 
to 1995. Since 1999, he has been a Professor at Aalto University (Helsinki 
University of Technology, Finland), where he is currently Academy Professor. 
He is Vice Chair and one of the principal investigators in the Smart Radios and 
Wireless Systems Centre of Excellence in Research nominated by the Academy 
of Finland. He has been an adjunct faculty member at the University of 
Pennsylvania and a visiting fellow at Nokia Research Center. He spent his sab-
batical term at Princeton University and makes frequent research visits there.
His research interests include statistical, communications, and array signal processing. He has 
published over 350 journal and conference papers in these areas. He received the 2007 IEEE 
Signal Processing Society Best Paper Award. He is an Editorial Board Member of the IEEE Signal 
Processing Magazine and a Fellow of the IEEE.
Esa Ollila received the M.Sc. degree in mathematics from the University of 
Oulu, in 1998, Ph.D. degree in statistics with honors from the University of 
Jyvaskyla, in 2002, and the D.Sc. (Tech) degree with honors in signal process-
ing from Aalto University, in 2010. From 2004 to 2007 he was a post-doc-
toral fellow of the Academy of Finland. He has also been a Senior Researcher 
and a Senior Lecturer at Aalto University and University of Oulu, respec-
tively. Currently, from August 2010, he is appointed as an Academy Research 
Fellow of the Academy of Finland at the Department of Signal Processing and 
Acoustics, Aalto University, Finland. He is also Adjunct Professor (statistics) 
of University of Oulu.
During the Fall-term 2001 he was a Visiting Researcher with the Department of Statistics, 
Pennsylvania State University, State College, PA while the academic year 2010–2011 he spent as a 
Visiting Post-doctoral Research Associate with the Department of Electrical Engineering, Princeton 
University, Princeton, NJ. His research interests focus on theory and methods of statistical signal 
processing, independent component analysis and blind source separation, complex-valued signal 
processing, array and radar signal processing, and robust and non-parametric statistical methods.
CHAPTER 3
Ljubiša Stankovic was born in Montenegro on June 1, 1960. He received a B.S. in electrical engi-
neering from the University of Montenegro in 1982, with the award as the best student at the 
University. In 1984, he received an M.S. in communications from the University of Belgrade, 
and a Ph.D. in theory of electromagnetic waves from the University of Montenegro in 1988. 
As a Fulbright grantee, he spent the 1984–1985 academic year at the Worcester Polytechnic 
Institute in Worcester, MA. Since 1982, he has been on the faculty at the University of 
Authors Biography

xxx
Authors Biography
Montenegro, where he has been a Full Professor since 1995. In 1997–1999, 
he was on leave at the Ruhr University Bochum in Germany, supported 
by the Alexander von Humboldt Foundation. At the beginning of 2001, 
he was at the Technische Universiteit Eindhoven in the Netherlands as a 
Visiting Professor. During 2003–2008, he was the Rector of the University of 
Montenegro. He is the Ambassador of Montenegro to the United Kingdom, 
Ireland, and Iceland. His current interests are in signal processing. He pub-
lished about 350 technical papers, more than 120 of them in the leading 
journals, mainly the IEEE editions. He received the highest state award of 
Montenegro in 1997 for scientific achievements. He was a member the IEEE Signal Processing 
Society’s Technical Committee on Theory and Methods, an associate editor of the IEEE 
Transactions on Image Processing, and an associate editor of the IEEE Signal Processing Letters. 
He is an associate editor of the IEEE Transactions on Signal Processing. He has been a member 
of the National Academy of Science and Arts of Montenegro (CANU) since 1996 and a mem-
ber of the European Academy of Sciences and Arts. He is a Fellow of the IEEE for contributions 
to time-frequency signal analysis.
Miloš Dakovic was born in 1970 in Nikšić, Montenegro. He received a B.S. in 
1996, an M.S. in 2001, and a Ph.D. in 2005, all in electrical engineering from 
the University of Montenegro. He is an Associate Professor at the University 
of Montenegro. His research interests are in signal processing, time-fre-
quency signal analysis, and radar signal processing. He is a member of the 
Time-Frequency Signal Analysis Group (www.tfsa.ac.me) at the University of 
Montenegro, where he is involved in several research projects.
Thayananthan Thayaparan earned a B.S. (Hons.) in physics at the University 
of Jaffna, Sri-Lanka, an M.S. in physics at the University of Oslo, Norway 
in 1991, and a Ph.D. in atmospheric physics at the University of Western 
Ontario, Canada in 1996. From 1996 to 1997, he was employed as a post-
doctoral fellow at the University of Western Ontario. In 1997, he joined 
the Defence Research and Development Canada-Ottawa, Department of 
National Defence, Canada, as a defense scientist. His research interests 
include advanced radar signal and image processing methodologies and tech-
niques against SAR/ISAR and HFSWR problems, such as detection, classi-
fication, recognition, and identification. His current research includes synthetic aperture radar 
imaging algorithms, time-frequency analysis for radar imaging and signal analysis, radar micro-
Doppler analysis, and noise radar technology. Thayaparan is a Fellow of the IET (Institute of 
Engineering & Technology). Currently, he is an Adjunct Professor at McMaster University. He 
received IET Premium Award for Signal Processing for the best paper published in 2009–2010. 
He is currently serving in the editorial board of IET Signal Processing. He has authored or 
coauthored over 174 publications in journals, proceedings, and internal distribution reports.

xxxi
Authors Biography
CHAPTER 4
Simon Godsill is Professor of Statistical Signal Processing in the Engineering 
Department at Cambridge University and a Professorial Fellow and tutor at 
Corpus Christi College, Cambridge. He coordinates an active research group 
in Signal Inference and its Applications within the Signal Processing and 
Communications Laboratory at Cambridge, specializing in Bayesian computa-
tional methodology, multiple object tracking, audio and music processing, and 
financial time series modeling. A particular methodological theme over recent 
years has been the development of novel techniques for optimal Bayesian filter-
ing and smoothing, using Sequential Monte Carlo or Particle Filtering methods. 
He has published extensively in journals, books, and international conference proceedings. He 
was technical chair of the IEEE NSSPW workshop in 2006 on sequential and nonlinear filtering 
methods, was Technical Chair for Fusion 2010 in Edinburgh, and has been on the conference panel 
for numerous other conferences workshops. He has served as Associate Editor for IEEE Tr. Signal 
Processing and the journal Bayesian Analysis. He was Theme Leader in Tracking and Reasoning 
over Time for the UKâs Data and Information Fusion Defence Technology Centre (DIF-DTC) and 
Principal Investigator on grants funded by the EU, EPSRC, QinetiQ, General Dynamics, MOD, 
Microsoft UK, Citibank, and Mastercard. In 2009–2010 he was co-organizer of an 18-month 
research program in Sequential Monte Carlo Methods at the SAMSI Institute in North Carolina, 
and will coorganize an Isaac Newton Institute Programme on Sequential Monte Carlo in 2014. He 
is a Director of CEDAR Audio Ltd. (which has received a technical Oscar for its audio processing 
work), and Input Dynamics Ltd., both companies which utilize his research work in the audio area.
CHAPTER 5
Pramod K. Varshney (S’72–M’77–SM’82–F’97) was born in Allahabad, India, 
on July 1, 1952. He received the B.S. degree in electrical engineering and 
computer science (with highest honors), and the M.S. and Ph.D. degrees in 
electrical engineering from the University of Illinois at Urbana-Champaign in 
1972, 1974, and 1976 respectively.
From 1972 to 1976, he held teaching and research assistantships at the 
University of Illinois. Since 1976, he has been with Syracuse University, 
Syracuse, NY, where he is currently a Distinguished Professor of Electrical 
Engineering and Computer Science and the Director of CASE: Center for 
Advanced Systems and Engineering. He served as the Associate Chair of the department from 1993 
to 1996. He is also an Adjunct Professor of Radiology at Upstate Medical University, Syracuse. 
His current research interests are in distributed sensor networks and data fusion, detection and 
estimation theory, wireless communications, image processing, radar signal processing, and remote 
sensing. He has published extensively. He is the author of Distributed Detection and Data Fusion 
(New York: Springer-Verlag, 1997). He has served as a consultant to several major companies.
He was a James Scholar, a Bronze Tablet Senior, and a Fellow while with the University of 
Illinois. He is a member of Tau Beta Pi and is the recipient of the 1981 ASEE Dow Outstanding 
Young Faculty Award. He was elected to the grade of Fellow of the IEEE in 1997 for his 

xxxii
Authors Biography
contributions in the area of distributed detection and data fusion. He was the Guest Editor 
of the Special Issue on Data Fusion of the Proceedings of the IEEE, January 1997. In 2000, 
he received the Third Millennium Medal from the IEEE and Chancellor’s Citation for excep-
tional academic achievement at Syracuse University. He is the recipient of the IEEE 2012 
Judith A. Resnik Award. He serves as a Distinguished Lecturer for the IEEE Aerospace and 
Electronic Systems (AES) Society. He is on the Editorial Board of the Journal on Advances 
in Information Fusion. He was the President of International Society of Information Fusion 
during 2001.
Engin Masazade (S’03–M’10) got his B.S. degree from Electronics and 
Communications Engineering Department from Istanbul Technical University 
in 2003. He then obtained his M.S. and Ph.D. degrees from Sabanci University, 
Electronics Engineering Program, Istanbul, Turkey in 2006 and 2010 respec-
tively. He is currently an Assistant Professor with the Department of Electrical 
and Electronics Engineering, Yeditepe University, Istanbul, Turkey. Before 
joining Yeditepe University, he was a Postdoctoral Research Associate with 
the Department of Electrical Engineering and Computer Science, Syracuse 
University, Syracuse, NY, USA. His research interests include distributed 
detection, localization, and tracking for wireless sensor networks, dynamic resource management 
in sensor/communication networks.
CHAPTER 6
Venugopal V. Veeravalli (M’92–SM’98–F’06) received the B.Tech. degree 
(SilverMedal Honors) from the Indian Institute of Technology, Bombay, in 
1985, the M.S. degree from Carnegie Mellon University, Pittsburgh, PA, 
in 1987, and the Ph.D. degree from the University of Illinois at Urbana-
Champaign, in 1992, all in electrical engineering. 
He joined the University of Illinois at Urbana-Champaign in 2000, where 
he is currently a Professor in the Department of Electrical and Computer 
Engineering and the Coordinated Science Laboratory. He served as a 
Program Director for communications research at the US. National Science 
Foundation in Arlington,VA from 2003 to 2005. He has previously held academic positions at 
Harvard University, Rice University, and Cornell University, and has been on sabbatical at MIT, 
IISc Bangalore, and Qualcomm, Inc. His research interests include wireless communications, dis-
tributed sensor systems and networks, detection and estimation theory, and information theory.
He was a Distinguished Lecturer for the IEEE Signal Processing Society during 2010–2011. 
He has been on the Board of Governors of the IEEE Information Theory Society. He has been an 
Associate Editor for Detection and Estimation for the IEEE Transactions on Information Theory 
and for the IEEE Transactions on Wireless Communications. Among the awards he has received 
for research and teaching are the IEEE Browder J. Thompson Best Paper Award, the National 
Science Foundation CAREER Award, and the Presidential Early Career Award for Scientists and 
Engineers (PECASE).

xxxiii
Authors Biography
Taposh Banerjee received an M.E. in Telecommunications from the ECE 
Department of the Indian Institute of Science. He is now pursuing his 
Ph.D. at the Coordinated Science Laboratory and the ECE Department at 
the University of Illinois at Urbana-Champaign. His research interests are in 
detection and estimation theory, sequential analysis, and wireless communica-
tions and networks.
CHAPTER 7
Fredrik Gustafsson is Professor in Sensor Informatics at Department of 
Electrical Engineering, Linköping University, since 2005. He received the 
M.Sc. degree in electrical engineering 1988 and the Ph.D. degree in Automatic 
Control, 1992, both from Linkoping University. During 1992–1999 he held 
various positions in automatic control, and 1999–2005 he had a professor-
ship in Communication Systems. His research interests are in stochastic sig-
nal processing, adaptive filtering and change detection, with applications to 
communication, vehicular, airborne, and audio systems. He is a co-founder of 
the companies NIRA Dynamics (automotive safety systems), Softube (audio 
effects), and SenionLab (indoor positioning systems).
He was an associate editor for IEEE Transactions of Signal Processing 2000–2006, IEEE 
Transactions on Aerospace and Electronic Systems 2010–2012, and EURASIP Journal on Applied 
Signal Processing 2007–2012. He was awarded the Arnberg prize by the Royal Swedish Academy 
of Science (KVA) 2004, elected member of the Royal Academy of Engineering Sciences (IVA) 
2007, elevated to IEEE Fellow 2011, and awarded the Harry Rowe Mimno Award 2011 for the 
tutorial “Particle Filter Theory and Practice with Positioning Applications,” which was published 
in the AESS Magazine in July 2010.
CHAPTER 8
Brian M. Sadler received the B.S. and M.S. degrees from the University 
of Maryland, College Park, and the Ph.D. degree from the University of 
Virginia, Charlottesville, all in electrical engineering. He is a Fellow of the 
Army Research Laboratory (ARL) in Adelphi, MD, and a Fellow of the IEEE. 
He has been an Associate or Guest Editor for many journals, including the 
IEEE Transactions on Signal Processing and IEEE Signal Processing Letters, 
and he has served on three IEEE Technical Committees in signal process-
ing and networking. He received Best Paper Awards from the IEEE Signal 
Processing Society in 2006 and 2010. He has received several ARL and Army 
R&D awards, as well as a 2008 Outstanding Invention of the Year Award from the University of 
Maryland. His research interests include information science, networked and autonomous sys-
tems, sensing, and mixed-signal integrated circuit architectures.

xxxiv
Authors Biography
Terrence J. Moore received his B.S. and M.A. in Mathematics from American 
University 
in 1998 and 2000, respectively, and his Ph.D. in Mathematics from the 
University of Maryland, College Park, in 2010. He is a mathematician at the 
U.S. Army Research Laboratory in Adelphi, MD. His research interests 
include sampling theory, constrained statistical inference, stochastic optimiza-
tion, and graph theory. He is a member of the IEEE.
CHAPTER 9
Ali H. Sayed is Professor of electrical engineering at the University of 
California, Los Angeles, where he directs the UCLA Adaptive Systems 
Laboratory (http://www.ee.ucla.edu/asl). An author of over 400 scholarly 
publications and five books, his research involves several areas including 
adaptation and learning, network science, information processing theories, 
and biologically inspired designs. His work received several recognitions 
including the 2012 Technical Achievement Award from the IEEE Signal 
Processing Society, the 2005 Terman Award from the American Society for 
Engineering Education, a 2005 Distinguished Lecturer from the IEEE Signal 
Processing Society, the 2003 Kuwait Prize, and the 1996 IEEE Donald Fink Prize. His work 
has also been awarded several Best Paper Awards in 2002, 2005, and 2012 from the IEEE. He 
is a Fellow of both the IEEE and the American Association for the Advancement of Science 
(AAAS). He is the author of the textbooks Fundamentals of Adaptive Filtering (Wiley, 2003) 
and Adaptive Filters (Wiley, 2008). He is also co-author of the textbook Linear Estimation 
(Prentice Hall, 2000).
CHAPTER 12
Sergiy A. Vorobyov received the M.Sc. and Ph.D. degrees in systems and 
control from Kharkiv National University of Radio Electronics, Ukraine, in 
1994 and 1997, respectively. He is a Professor with the Department of Signal 
Processing and Acoustics, Aalto University, Finland and currently on leave 
from the Department of Electrical and Computer Engineering, University of 
Alberta, Edmonton, AB, Canada, where he has been an Assistant Professor 
in 2006, Associate Professor in 2010, and Full Professor in 2012. Since his 
graduation, he also held various research and faculty positions at Kharkiv 
National University of Radio Electronics, Ukraine; the Institute of Physical 
and Chemical Research (RIKEN), Japan; McMaster University, Canada; Duisburg-Essen 
University and Darmstadt University of Technology, Germany; and the Joint Research Institute 
between Heriot-Watt University and Edinburgh University, UK. He has also held visiting posi-
tions at Technion, Haifa, Israel and Ilmenau University of Technology, Ilmenau, Germany. His 
research interests include statistical and array signal processing, applications of linear algebra, 

xxxv
Authors Biography
optimization, and game theory methods in signal processing and communications, estimation, 
detection, and sampling theories, and cognitive systems.
He is a recipient of the 2004 IEEE Signal Processing Society Best Paper Award, the 2007 
Alberta Ingenuity New Faculty Award, the 2011 Carl Zeiss Award (Germany), and other 
awards. He has served as the Track Chair for Asilomar 2011, Pacific Grove, CA, the Technical 
Co-Chair for IEEE CAMSAP 2011, Puerto Rico, and the Plenary Chair of ISWCS 2013, 
Ilmenau, Germany.
CHAPTER 13
Sven E. Nordholm received his Ph.D., Licentiate of Engineering, and MScEE 
degrees from Lund University, Sweden. He was one of the founders of the 
Department of Signal Processing in Blekinge Institute of Technology, Sweden. 
In 1999, he was appointed as a Professor and Director of the Australian 
Telecommunications Research Institute, Curtin University of Technology, 
Perth. From 2009 he is a Professor of Signal Processing with Department 
of Electrical and Computer Engineering, Curtin University, Perth, Australia. 
From 2012 he is Head of the Department. He is also the co-founder and 
Chief Scientist of Sensear Pty Ltd.
He has more than 25 years of experience in acoustic signal processing. His work has been a 
mix of commercial and academic contributions. His scientific interests are in optimization of 
filters and broadband beamformers, blind signal separation, and speech enhancement.
Hai H. Dam received the Bachelor (with first-class Honors) and Ph.D. degrees 
(with distinction) from Curtin University of Technology, Perth, Australia in 
1996 and 2001, respectively. From 1999 to 2000, she was at the Blekinge 
Institute of Technology, Karlskrona, Sweden, as a Visiting Research Associate. 
From 2001 to 2005, she was a Research Fellow/Senior Research Fellow with 
the Western Australian Telecommunications Research Institute (WATRI), 
Curtin University of Technology, Australia. Currently, she is a Senior Lecturer 
with the Department of Mathematics and Statistics, Curtin University of 
Technology.
Her research interests are adaptive array processing, optimization methods, equalization, and 
filter design.
Chiong C. Lai received his B.Eng. (First Class Honors) in Electronic and 
Communication Engineering from Curtin University of Technology, Perth in 
2008. He continues onto his Ph.D. study in acoustic array signal processing 
at the same university. Currently, he is working as a Research Engineer for 
Electrical and Computer Engineering at Curtin University and at the same 
time, pursuing his Ph.D. study.
His research interests include robust steerable broadband beamformer, 
array signal processing, and acoustic source tracking.

xxxvi
Authors Biography
Eric A. Lehmann graduated in 1999 from the Swiss Federal Institute of 
Technology (ETHZ) in Zurich, Switzerland, with a Dipl.El.-Ing. degree 
(Electrical Engineering). He received the M.Phil. and Ph.D. degrees, both in 
electrical engineering, from the Australian National University, Canberra, in 
2000 and 2004, respectively. From 2004 to 2008, he held research positions 
with National ICT Australia (NICTA) in Canberra, as well as the Western 
Australian Telecommunications Research Institute (WATRI) in Perth, 
Australia. He is now working as Research Scientist for the Commonwealth 
Scientific and Industrial Research Organisation (CSIRO), within the Division 
of Mathematics, Informatics and Statistics in Perth. His current work involves the develop-
ment of statistical image processing techniques for remote sensing data analysis, with a focus on 
model-data fusion and integration of multisensor data for environmental resource management 
and monitoring. His scientific interests also include various aspects of signal processing (such as 
acoustics, speech, and array processing) as well as Bayesian estimation and tracking (sequential 
Monte Carlo methods).
CHAPTER 14
Pei-Jung Chung received Dr.-Ing. in 2002 from Ruhr-University at Bochum, 
Germany with distinction. From 2002 to 2004 she held a post-doctoral posi-
tion at Carnegie Mellon University and University of Michigan, Ann Arbor, 
USA, respectively. From 2004 to 2006 she was Assistant Professor with 
National Chiao Tung University, HsinChu, Taiwan. In 2006 she joined the 
Institute for Digital Communications, School of Engineering, the University 
of Edinburgh, UK as Lecturer. Currently, she is Associate Member of IEEE 
Signal Processing Society Sensor Array Multichannel Technical Committee 
and serves for IEEE Communications Society, Multimedia Communications 
Technical Committee as Vice Chair of Interest Group on Acoustic and Speech Processing for 
Communications. Her research interests include array processing, statistical signal processing, 
wireless MIMO communications, and distributed processing in wireless sensor networks.
Jia Yu received the B.Eng. degree in electronic information engineering and 
the MSc degree in electronic engineering from the University of Electronic 
Science and Technology of China, Chengdu, China, in 2007 and 2009, respec-
tively. From 2010 to 2012, he was a system engineer at Huawei Technologies 
Co., Shenzhen, China. He is currently working toward a Ph.D. degree at the 
University of Edinburgh. His research interest lies in statistical signal process-
ing and wireless sensor networks.

xxxvii
Authors Biography
CHAPTER 15
Martin Haardt has been a Full Professor in the Department of Electrical 
Engineering and Information Technology and Head of the Communications 
Research Laboratory at Ilmenau University of Technology, Germany, since 
2001. Since 2012, he has also served as an Honorary Visiting Professor in the 
Department of Electronics at the University of York, UK.
After studying electrical engineering at the Ruhr-University Bochum, 
Germany, and at Purdue University, USA, he received his Diplom-Ingenieur 
(M.S.) degree from the Ruhr-University Bochum in 1991 and his Doktor-
Ingenieur (Ph.D.) degree from Munich University of Technology in 1996.
In 1997 he joined Siemens Mobile Networks in Munich, Germany, where he was respon-
sible for strategic research for third generation mobile radio systems. From 1998 to 2001 
he was the Director for International Projects and University Cooperations in the mobile 
infrastructure business of Siemens in Munich, where his work focused on mobile communica-
tions beyond the third generation. During his time at Siemens, he also taught in the interna-
tional Master of Science in Communications Engineering program at Munich University of 
Technology.
He has received the 2009 Best Paper Award from the IEEE Signal Processing Society, the 
Vodafone (formerly Mannesmann Mobilfunk) Innovations-Award for outstanding research 
in mobile communications, the ITG Best Paper Award from the Association of Electrical 
Engineering, Electronics, and Information Technology (VDE), and the Rohde & Schwarz 
Outstanding Dissertation Award. He is a Senior Member of the IEEE. In the fall of 2006 and the 
fall of 2007 he was a Visiting Professor at the University of Nice in Sophia-Antipolis, France, and 
at the University of York, UK, respectively. His research interests include wireless communica-
tions, array signal processing, high-resolution parameter estimation, as well as numerical linear 
and multilinear algebra.
He has served as an Associate Editor for the IEEE Transactions on Signal Processing (2002–
2006 and since 2011), the IEEE Signal Processing Letters (2006–2010), the Research Letters 
in Signal Processing (2007–2009), the Hindawi Journal of Electrical and Computer Engineering 
(since 2009), the EURASIP Signal Processing Journal (since 2011), and as a guest editor for 
the EURASIP Journal on Wireless Communications and Networking. He has also served as 
an elected member of the Sensor Array and Multichannel (SAM) technical committee of the 
IEEE Signal Processing Society (since 2011), as the technical co-chair of the IEEE International 
Symposiums on Personal Indoor and Mobile Radio Communications (PIMRC) 2005 in Berlin, 
Germany, as the technical program chair of the IEEE International Symposium on Wireless 
Communication Systems (ISWCS) 2010 in York, UK, as the general chair of ISWCS 2013 
in Ilmenau, Germany, and as the general co-chair of the 5th IEEE International Workshop 
on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP) 2013 in Saint 
Martin, French Caribbean.
Marius Pesavento received the Dipl.-Ing. degree from Ruhr-Universität Bochum, Germany, in 
1999 and the M.Eng. degree from McMaster University, Hamilton, ON, Canada, in 2000, and 

xxxviii Authors Biography
the Dr.-Ing. degree in electrical engineering from Ruhr-Universität Bochum, 
Germany, in 2005. Between 2005 and 2007, he was a Research Engineer at 
FAG Industrial Services GmbH, Aachen, Germany. From 2007 to 2009, he was 
the Director of the Signal Processing Section at mimoOn GmbH, Duisburg, 
Germany. In 2010, he became a Professor for Robust Signal Processing at the 
Department of Electrical Engineering and Information Technology, Darmstadt 
University of Technology, Darmstadt, Germany, where he is currently the 
Head of the Communication Systems Group.
His research interests are in the area of robust signal processing and adap-
tive beamforming, high-resolution sensor array processing, transceiver design for cognitive radio 
systems, cooperative communications in relay networks, MIMO and multiantenna communi-
cations, space-time coding, multiuser and multicarrier wireless communication systems, con-
vex optimization for signal processing and communications, statistical signal processing, spectral 
analysis, parameter estimation, and detection theory.
He was a recipient of the 2003 ITG/VDE Best Paper Award, the 2005 Young Author Best 
Paper Award of the IEEE TRANSACTIONS ON SIGNAL PROCESSING, and the 2010 Best 
Paper Award of the CROWNCOM conference. He is a member of the Editorial board of the 
EURASIP Signal Processing Journal, an Associate Editor for the IEEE TRANSACTIONS ON 
SIGNAL PROCESSING, and a member of the Sensor Array and Multichannel (SAM) Technical 
Committee of the IEEE Signal Processing Society (SPS).
Florian Roemer has studied computer engineering at Ilmenau University 
of Technology, Germany, and McMaster University, Canada. He received 
the Diplom-Ingenieur (M.S.) degree in communications engineering from 
Ilmenau University of Technology in October 2006. He received the Siemens 
Communications Academic Award in 2006 for his diploma thesis. Since 
December 2006, he has been a Research Assistant in the Communications 
Research Laboratory at the Ilmenau University of Technology. His research 
interests include multidimensional signal processing, high-resolution param-
eter estimation, as well as multi-user MIMO precoding and relaying.
Mohammed Nabil El Korso was born in Oran, Algeria in 1983. He received the 
BSc degree in Mathematics and physics from ENPEI-National Preparatory 
School, Algeria in 2004. The M.Sc. in Electrical Engineering from the 
National Polytechnic School, Algeria in 2007. He obtained a Master Research 
degree in Signal and Image Processing from Paris-Sud XI University/Supélec, 
France in 2008. In 2011, he obtained a Ph.D. degree from Paris-Sud XI 
University/Supélec in the Modeling and Statistical Signal Processing team of 
the Laboratory of Signals and Systems. From 2011 to 2012, he was a postdoc-
toral research associate in the Communication Systems Group at Technische 
Universität Darmstadt, Germany. Since 2012, he has been temporary Assistant Professor at École 
Normale Supérieure de Cachan. His research interests include lower bounds on the mean-square 

xxxix
Authors Biography
error applied to statistical signal processing and estimation/detection theory with applications to 
array signal processing.
CHAPTER 16
Jean Pierre Delmas was born in France in 1950. He received the Engineering 
Degree from Ecole Centrale de Lyon, France in 1973, the Certificat d’Etudes 
Supérieures from Ecole Nationale Supérieure des Télécommunications, Paris, 
France in 1982 and the Habilitation à diriger des recherches degree from 
the University of Paris XI, Orsay, France in 2001. Since 1980, he has been 
with Telecom SudParis (formerly INT), where he is presently a Professor 
in the CITI department and Director of UMR CNRS 5157 (SAMOVAR) 
laboratory. His teaching and research interests are in the areas of statistical 
signal processing with application to communications and antenna array. He 
has served as an Associate Editor for the IEEE Transactions on Signal Processing (2002–2006) 
and presently for Signal Processing (Elsevier) and IEEE Transactions on Signal Processing. He is 
a member of the IEEE Sensor Array and Multichannel (SAM) Technical Committee and a IEEE 
Senior Member. He is author and co-author of more than 110 papers (journal, conference, and 
chapter of book).
CHAPTER 17
Moeness G. Amin received his Ph.D. degree from the University of Colorado, 
Boulder, in 1984. He has been on the Faculty of Villanova University, 
Villanova, PA, since 1985, where he is now a Professor in the Department 
of Electrical and Computer Engineering and the Director of the Center for 
Advanced Communications. He has over 600 publications in the areas of 
wireless communications, time-frequency analysis, smart antennas, inter-
ference cancelation in broadband communication platforms, direction find-
ing, GPS technologies, over-the-horizon radar, and radar imaging. He is the 
recipient of the 2009 Individual Technical Achievement Award from the 
European Association of Signal Processing. He is a Fellow of the Institute of Electrical and 
Electronics Engineers (IEEE); a Fellow of the International Society of Optical Engineering; 
recipient of the IEEE Third Millennium Medal; Distinguished Lecturer of the IEEE Signal 
Processing Society for 2003 and 2004. He was a Guest Editor of the Journal of Franklin 
Institute September 2008 Special Issue on Advances in Indoor Radar Imaging. He was a 
Guest Editor of the IEEE Transactions on Geoscience and Remote Sensing May 2009 Special 
Issue on Remote Sensing of Building Interior. He was the Co-Guest Editor of IET Signal 
Processing upcoming Special Issue on time-frequency Approach to Radar Detection, Imaging, 
and Classification. He serves on the Editorial Board of the Signal Processing Journal and the 
IEEE Signal Processing Magazine.

xl
Authors Biography
Yimin D. Zhang received his Ph.D. degree from the University of Tsukuba, 
Tsukuba, Japan, in 1988. He joined the faculty of the Department of Radio 
Engineering, Southeast University, Nanjing, China, in 1988. He served as 
a Technical Manager at the Communication Laboratory Japan, Kawasaki, 
Japan, from 1995 to 1997, and was a Visiting Researcher at ATR Adaptive 
Communications Research Laboratories, Kyoto, Japan, from 1997 to 1998. 
Since 1998, he has been with the Villanova University, Villanova, PA, 
where he is currently a Research Professor with the Center for Advanced 
Communications and the director of the Wireless Communications and 
Positioning Laboratory. He has more than 200 publications in the area of statistical signal and 
array processing for communications, radar, and navigation, including digital mobile com-
munications, wireless networks, MIMO systems, time-frequency analysis, source localiza-
tion and target tracking, over-the-horizon radar, radar imaging, cooperative communications, 
blind signal processing, jammer suppression, radio frequency identification (RFID), and 
image processing. He is an Associate Editor for the IEEE Transactions on Signal Processing 
and the Journal of the Franklin Institute, and serves on the editorial board of the Signal 
Processing Journal. He was an Associate Editor for the IEEE Signal Processing Letters from 
2006 to 2010.
CHAPTER 18
Yu Hen Hu received BSEE from National Taiwan University, Taiwan ROC in 
1976, and MSEE and Ph.D. degrees from University of Southern California, Los 
Angeles, CA, USA in 1982. He was in the faculty of the Electrical Engineering 
Department of Southern Methodist University, Dallas, Texas. Since 1987, 
he has been with the Department of Electrical and Computer Engineering, 
University of Wisconsin, Madison where he is currently a professor.
He has broad research interests ranging from design and implementation 
of signal processing algorithms, computer-aided design and physical design 
of VLSI, pattern classification and machine learning algorithms, and image 
and signal processing in general. He has published more than 300 technical papers, edited or co-
authored four books and many book chapters in these areas.
He has served as an associate editor for the IEEE Transaction of Acoustic, Speech, and Signal 
Processing, IEEE signal processing letters, European Journal of Applied signal Processing, Journal 
of VLSI Signal Processing, and IEEE Multimedia magazine. He has served as the secretary and an 
executive committee member of the IEEE signal processing society, a board of governor of IEEE 
neural network council representing the signal processing society, the chair of signal processing 
society neural network for signal processing technical committee, and the chair of IEEE signal 
processing society multimedia signal processing technical committee. He was also a steering com-
mittee member of the international conference of Multimedia and Expo on behalf of IEEE Signal 
processing society. He is a fellow of IEEE.

xli
Authors Biography
CHAPTER 19
Mário Costa was born in Portugal in 1984. He received the M.Sc. degree with 
distinction in communications engineering from the Universidade do Minho, 
Portugal, in 2008. He has been with the Department of Signal Processing and 
Acoustics, Aalto University, Finland, since 2007, first as a Research Assistant 
and since 2008, as a Researcher working toward the Doctor of Science degree 
in technology. From January to July 2011, he was an External Researcher 
at the Connectivity Solutions Team, Nokia Research Center. His current 
research interests include sensor array and statistical signal processing as well 
as wireless communications.
CHAPTER 20
A. Lee Swindlehurst received the B.S., summa cum laude, and M.S. degrees 
in Electrical Engineering from Brigham Young University, Provo, Utah, in 
1985 and 1986, respectively, and the Ph.D. degree in Electrical Engineering 
from Stanford University in 1991. From 1986 to 1990, he was employed 
at ESL, Inc., of Sunnyvale, CA, where he was involved in the design of 
algorithms and architectures for several radar and sonar signal process-
ing systems. He was on the faculty of the Department of Electrical and 
Computer Engineering at Brigham Young University from 1990 to 2007, 
where he was a Full Professor and served as Department Chair from 2003 
to 2006. During 1996–1997, he held a joint appointment as a visiting scholar at both Uppsala 
University, Uppsala, Sweden, and at the Royal Institute of Technology, Stockholm, Sweden. 
From 2006 to 07, he was on leave working as Vice President of Research for ArrayComm 
LLC in San Jose, California. He is currently a Professor and Associate Chair of the Electrical 
Engineering and Computer Science Department at the University of California, Irvine. His 
research interests include sensor array signal processing for radar and wireless communica-
tions, detection and estimation theory, and system identification, and he has over 230 publica-
tions in these areas.
He is a Fellow of the IEEE, a past Secretary of the IEEE Signal Processing Society, past 
Editor-in-Chief of the IEEE Journal of Selected Topics in Signal Processing, and past member of 
the Editorial Boards for the EURASIP Journal on Wireless Communications and Networking, 
IEEE Signal Processing Magazine, and the IEEE Transactions on Signal Processing. He 
is a recipient of several paper awards: the 2000 IEEE W. R. G. Baker Prize Paper Award, 
the 2006 and 2010 IEEE Signal Processing Society’s Best Paper Awards, the 2006 IEEE 
Communications Society Stephen O. Rice Prize in the Field of Communication Theory, and 
is co-author of a paper that received the IEEE Signal Processing Society Young Author Best 
Paper Award in 2001.

xlii
Authors Biography
Brian D. Jeffs received B.S. (magna cum laude) and M.S. degrees in electrical 
engineering from Brigham Young University in 1978 and 1982, respectively. 
He received the Ph.D. degree from the University of Southern California in 
1989, also in electrical engineering. He currently holds the rank of Professor 
in the Department of Electrical and Computer Engineering at Brigham Young 
University, where he lectures in the areas of signals and systems, digital sig-
nal processing, probability theory, and stochastic processes. Current research 
activity includes array signal processing for radio astronomy and radio fre-
quency interference mitigation.
Previous employment includes Hughes Aircraft Company where he served as a sonar signal 
processing systems engineer in the anti-submarine warfare group. Projects there included algo-
rithm development and system design for digital sonars in torpedo, surface ship towed array, and 
helicopter dipping array platforms.
He was a Vice General Chair for IEEE ICASSP-2001 held in Salt Lake City, Utah. He was a 
member of the executive organizing committee for the 1998 IEEE DSP Workshop, co-organized 
the 2010 Workshop on Phased Array Antennas Systems for Radio Astronomy, and served several 
years as chair of the Utah Chapter of the IEEE Communications and Signal Processing Societies.
Gonzalo Seco-Granados received the Ph.D. degree in telecommunication engi-
neering from the Universitat Politècnica de Catalunya (UPC), Barcelona, Spain, 
in 2000, and the M.B.A. degree from IESE-University of Navarra, Barcelona, 
in 2002. During 2002–2005, he was a member of the technical staff within 
the RF Payload Division, European Space Research and Technology Center 
(ESTEC), European Space Agency, Noordwijk, The Netherlands, where he 
was involved in the Galileo project. He led the activities concerning naviga-
tion receivers and indoor positioning for GPS and Galileo. Since 2006, he has 
been an Associate Professor with the Department of Telecommunications and 
Systems Engineering, Universitat Autònoma de Barcelona, Barcelona. From March 2007 to April 
2011, he was coordinator of the Telecommunications Engineering degree and, since May 2011, 
he has been Vice Director of the UAB Engineering School.
He has been principal investigator of more than 12 national and international research projects, 
and acts often as an advisor of the European Commission in topics related to communications 
and navigation. He has had several visiting appointments at Brigham Young University, Provo, 
UT, and the University of California at Irvine. He has published more than 20 journal papers and 
more than 80 conference contributions. He holds two patents under exploitation. His research 
interests include signal processing for wireless communications and navigation, estimation theory, 
synchronization, location-based communications and optimization. He was appointed Director 
of one of the six Chairs of Technology and Knowledge Transfer “UAB Research Park-Santander” 
in March 2008.

xliii
Authors Biography
Jian Li (S’87-M’91-SM’97-F’5) received the M.Sc. and Ph.D. degrees in elec-
trical engineering from The Ohio State University, Columbus, in 1987 and 
1991, respectively.
From April 1991 to June 1991, she was an Adjunct Assistant Professor 
with the Department of Electrical Engineering, The Ohio State University, 
Columbus. From July 1991 to June 1993, she was an Assistant Professor with 
the Department of Electrical Engineering, University of Kentucky, Lexington. 
Since August 1993, she has been with the Department of Electrical and 
Computer Engineering, University of Florida, Gainesville, where she is cur-
rently a Professor. In Fall 2007, she was on sabbatical leave at MIT, Cambridge, Massachusetts. 
Her current research interests include spectral estimation, statistical and array signal processing, 
and their applications. 
She is a Fellow of IEEE and a Fellow of IET. She is a member of Sigma Xi and Phi Kappa 
Phi. She received the 1994 National Science Foundation Young Investigator Award and the 1996 
Office of Naval Research Young Investigator Award. She was an Executive Committee Member 
of the 2002 International Conference on Acoustics, Speech, and Signal Processing, Orlando, 
Florida, May 2002. She was an Associate Editor of the IEEE Transactions on Signal Processing 
from 1999 to 2005, an Associate Editor of the IEEE Signal Processing Magazine from 2003 to 
2005, and a member of the Editorial Board of Signal Processing, a publication of the European 
Association for Signal Processing (EURASIP), from 2005 to 2007. She was a member of the 
Editorial Board of the IEEE Signal Processing Magazine from 2010 to 2012. She was a member 
of the Editorial Board of Digital Signal Processing—A Review Journal, a publication of Elsevier, 
from 2006 to 2012. She is a co-author of the papers that have received the First and Second Place 
Best Student Paper Awards, respectively, at the 2005 and 2007 Annual Asilomar Conferences on 
Signals, Systems, and Computers in Pacific Grove, California. She is a co-author of the paper that 
has received the M. Barry Carlton Award for the best paper published in IEEE Transactions on 
Aerospace and Electronic Systems in 2005. She is also a co-author of the paper that has received 
the Lockheed Martin Best Student Paper Award at the 2009 SPIE Defense, Security, and Sensing 
Conference in Orlando, Florida.

1
CHAPTER
Introduction to Statistical Signal
Processing
Abdelhak M. Zoubir
Signal processing Group, Technische Universität Darmstadt, Germany
3.01.1 A brief historical recount
Signals are either random in nature or deterministic, but subject to random measurement errors. There-
fore, Statistical Methods for Signal Processing or in short Statistical Signal Processing are the signal
processing practitioner’s choice to extracting useful information from measurements. Today, one can
conﬁdently claim that statistical signal processing is performed in every specialization of signal pro-
cessing. Early stages of statistical signal processing concerned parameter (signal) estimation, signal
detection, and signal classiﬁcation. These have their roots in probability theory and mathematical statis-
tics. For example, parameter estimation and signal detection are what is known under, respectively,
point estimation [1] and statistical hypothesis testing [2,3] in mathematical statistics while fundamental
concepts of classiﬁcation were treated in classical texts such as [4].
It is difﬁcult to trace back the time when the term statistical signal processing was established.
Undoubtedly, statistical signal processing was performed even before the birth of digital signal pro-
cessing, which started soon after the discovery of the Fast Fourier Transform by Cooley and Tukey [5].
Themes on statistical signal processing started as part of broader workshops in the early 1980s, such
as the IEEE Workshop on Spectrum Estimation and Modeling, the IEEE International Workshop on
Statistical Signal and Array Processing, or the IEEE International Workshop on Higher-Order Statistics,
to mention a few. The year 2001 gave birth to the IEEE International Workshop on Statistical Signal
Processing, which is organized biannually. Textbooks on the subject have been around since the 1990s.
They include, for example [6–8].
3.01.2 Content
Today, statistical signal processing ﬁnds a wide range of cross-fertilization and applications, far beyond
signal estimation, detection, or classiﬁcation. Examples include communications and networking, target
tracking, (adaptive) ﬁltering, multi-dimensional signal processing, and machine learning, to mention
a few. Recently, I came across a few newly edited books with the content statistical signal processing
for neuroscience. The authors of the chapters from both signal processing and neural computation aim
at promoting interaction between the two disciplines of signal processing and neural sciences. This is
surely not the ﬁrst and not the last attempt to bring two communities together. Signal Processing, and
in particular statistical signal processing, is such a dynamic discipline that calls for cross-fertilization
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00001-1
© 2014 Elsevier Ltd. All rights reserved.
3

4
CHAPTER 1 Introduction to Statistical Signal Processing
between disciplines. At no surprise, you will ﬁnd a wide range of statistical signal processing treatment in
other sections of this e-reference, such as in Signal processing for Communications or Signal Processing
for Machine Learning.
I was honored and delighted when Sergios Theodoridis approached me to be the area editor for
this section. I ﬁrst thought of key advances in statistical signal processing. They are numerous, but
space did not allow for all of these areas to be covered in this section. I had to select a subset and I
approached not only the very best researchers in these areas, but who also are experienced in writing
tutorial-style articles. Some of the contributors preferred to wait for the second edition of e-reference
for their manuscript to appear.
3.01.3 Contributions
The contributions in this section cover chapters on recent advances in detection, estimation and appli-
cations of statistical signal processing. All of these chapters are written in a tutorial style.
3.01.3.1 Quickest change detection
An important problem in engineering practice, such as engine monitoring, is to detect anomalies or
changes in the environment as quickly as possibly, subject to false alarm constraints. These changes can
be captured by a change in distribution of the observed data. The authors provide two formulations of
quickest change detection, a Bayesian and a minimax approach, along with their (asymptotically) opti-
malsolutions.Theauthorsalsodiscussdecentralizedquickestchangedetectionandprovidevariousalgo-
rithms that are asymptotically optimal. Several open problems in the context of quickest change detection
have been given by the authors. Among these, the authors mention an old, but to date an unsatisfactorily
solved problem with a large impact in statistical signal processing practice, that is, transient detection.
3.01.3.2 Distributed signal detection
Signal detection with a single sensor is a well-established theory with a wide range of applications,
such as in radar, sonar, communications, or biomedicine. Today, we encounter an enormous growth of
multi-sensor based detection. For example, in wireless sensor networks, one aims at making a global
decision based on local decisions. The deployment of multiple sensors for signal detection improves
system survivability, results in improved detection performance or in a shorter decision time to attain
a preset performance level. In classical multi-sensor detection, local sensors transmit their raw data
to a central processor where optimal detection is carried out. This has its drawbacks, including high
communicationbandwidth.Distributedprocessinghasitsadvantageinthatlocalsensorswithlowenergy
consumption carry out preliminary processing and communicate only the information relevant to the
global objective, such as the decision on the presence or absence of a target in radar. This leads to low
energy consumption, reduced communication bandwidth, and increases system reliability. The chapter
on distributed signal detection provides a survey and most recent advances in distributed detection, such
as distributed detection in the presence of dependent observations, using copula theory.

3.01.3 Contributions
5
3.01.3.3 Diffusion adaptation over networks
Wireless sensor networks, which consist of spatially distributed autonomous sensors, are becoming
fundamental to engineering practice. The sensors or agents in the network have the task to monitor
physical or environmental conditions, such as temperature, pressure, or vibrations. Cooperatively, these
sensors reach a global decision. The chapter on Diffusion Adaptation over Networks approaches the
problem of global inference using adaptation and learning, which are important abilities of the col-
lection of agents that are linked together through a connection topology. Adaptive networks are well
suited to performing decentralized information processing and optimization in real time. One of the
advantages of such networks is the continuous diffusion of information across the network that enables
adaptation of performance in relation to changing data and network conditions. This overview article on
diffusion strategies for adaptation and learning over networks provides fundamental principles and artic-
ulates the improved adaptation and learning performance of such networks relative to non-cooperative
networks.
3.01.3.4 Non-stationary signal analysis—a time-frequency approach
Non-stationary signal analysis plays an important role in statistical signal processing. For example, in
analyzing automotive engine signals, classical spectral analysis approaches fail as they do not capture
the non-stationary nature of signals due to motion of the piston. Linear time-frequency approaches, such
as the spectrogram, capture the non-stationary nature of signals whose spectral contents vary with time.
This class of time-frequency representation has its advantages, but also its drawbacks. Quadratic time-
frequency representations, although they lose the linearity property, have the advantage of providing a
higher time-frequency concentration as compared to linear methods. Also, higher-order time-frequency
representations have been proposed as they further improve the time-frequency concentration for a
certain class of non-stationary signals. In this chapter, Ljubi´sa Stankovi´c et al. provide an overview of
state-of-the-art methods for non-stationary signal analysis and their applications to real-life problems,
including inverse synthetic aperture radar.
3.01.3.5 Bayesian computational methods in signal processing
There are two schools of thoughts in statistical inference, i.e., the frequentist and the Bayesian
approaches. This chapter deals with Bayesian inference. The author ﬁrst illustrates Bayesian inference
through the linear Gaussian model. This model makes many of the required calculations straightfor-
ward and analytically computable. He then considers the practically more relevant problem where there
are intractable elements in the models. This problem can only be solved numerically. There is a wide
range of computational tools available for solving complex Bayesian inference problems, ranging from
simple Laplace approximations to posterior densities, through variational Bayes’ methods to highly
sophisticated Monte Carlo schemes. The author gives a ﬂavor of some of the techniques available today,
starting with one of the simplest and most effective: the Expectation-Maximization algorithm. He then
describes Markov Chain Monte Carlo (MCMC) methods, which have gained much importance in solv-
ing complicated problems, and concludes with the emerging topic of particle ﬁltering in statistical signal
processing.

6
CHAPTER 1 Introduction to Statistical Signal Processing
3.01.3.6 Model order selection
A problem encountered again and again in statistical signal processing is model selection. The signal
processing practitioners require a simple, but effective means to deciding on a model within a family of
models, given measurements. This problem is known as model selection. There exist a wealth of methods
available to solving this problem. However, for a given set of data different model selection procedures
give different results. For this reason, model selection and model order selection are still an active area
of research in statistical science as well as statistical signal processing. The authors of this chapter
describe the basic principles, challenges, and the complexity of the model selection problem. They treat
statistical inference-based methods in detail, and those techniques as well as their variants, widely used
by engineers. The chapter concludes with a practical engineering example in determining the dimension
of the signal subspace, a problem encountered in sensor array processing and harmonic retrieval.
3.01.3.7 Performance analysis and bounds
Bounds provide fundamental limits on estimation given some assumptions on the probability laws and
a model for the parameters of interest. In his chapter, Brian Sadler considers performance analysis of
estimators, as well as bounds on estimation performance. He introduces key ideas and avenues for anal-
ysis, referring to the literature for detailed examples. He seeks to provide a description of the analytical
procedure, as well as to provide some insight, intuition, and guidelines on applicability and results.
3.01.3.8 Geolocation
Geolocation denotes the position of an object in a geographical context. As Frederik describes it,
geolocation is characterized by the four Ms, which are the Measurements used, the Map, the Motion
model used for describing the motion of the object, and the ﬁltering Method. He describes a general
framework for geolocation based on the particle ﬁlter. He generalizes the concept of ﬁngerprinting for
describing the procedure of ﬁtting measurements (along a trajectory) to the map. Several examples
based on real data are used to illustrate various combinations of sensors and maps for geolocation.
He ﬁnally discusses different ways as to show how the tedious mapping steps can be automated.
3.01.4 Suggested further reading
Some readers will be inspired by the collection of chapters in this section and would want to deepen
further their knowledge and apply some of the techniques to their own signal processing problems.
Those readers are encouraged to consult textbooks, such as the ones provided in the list of references in
this introduction or the ones specially tailored to the subject contained in this section for further reading.
I also hope that the readers will ﬁnd inspirations in other tutorials on the above topics published earlier
in the IEEE Signal Processing Magazine or The Proceedings of the IEEE.
Acknowledgments
I am grateful to the contributors as well as the colleagues who provided a critical feedback on those contributions.

References
7
References
[1] E.L. Lehmann, Theory of Point Estimation, Wadsworth & Brooks/Cole Advanced Books & Software, 1983.
[2] E.L. Lehmann, Testing Statistical Hypotheses, John Wiley & Sons, Inc., New York, 1959.
[3] J. Neyman, E.S. Pearson, On the problem of the most efﬁcient tests of statistical hypotheses, Philos. Trans. R.
Soc., Ser. A 231 (1933) 289–337.
[4] T.W. Anderson, An Introduction to Multivariate Statistical Analysis, John Wiley & Sons, Inc., New York, 1958.
[5] J.W. Cooley, J.W. Tukey, An algorithm for the machine calculation of complex Fourier series, Math. Comput.
19 (90) (1965) 297–301.
[6] S.M. Kay, Fundamentals of Statistical Signal Processing, Estimation Theory, vol. I, Prentice-Hall, 1993.
[7] S.M. Kay, Fundamentals of Statistical Signal Processing, Detection Theory, vol. II, Prentice-Hall, 1998.
[8] L.L. Scharf, Statistical Signal Processing: Detection, Estimation, and Time Series Analysis, Addison Wesley,
Boston, 1991.

2
CHAPTER
Model Order Selection
Visa Koivunen and Esa Ollila
Department of Signal Processing and Acoustics, School of Electrical Engineering, Aalto University, Finland
3.02.1 Introduction
In model selection the main task is to choose a mathematical model for a phenomenon from a collection
of models given some evidence such as the observed data at hand. Informally, one aims at identifying
a proper complexity for the model. Typical application examples include ﬁnding the number of radio
frequency signals impinging an antenna array, choosing the order of an ARMA model used for analyzing
time series data, variable selection in the regression model in statistics, estimating the channel order
in wireless communication receiver and selecting the order of a state-space model used in tracking a
maneuvering target in radar.
Model order selection uses a set of observed data and seeks the best dimension for the parametric
model used. This is related to the idea of the inverse experiment and the maximum likelihood estimation
where one looks for the parameters that most likely have produced the observed data. Various methods
for model selection or model order estimation stem from the detection and estimation theory, statistical
inference, information and coding theory and machine learning. The outcome of a model order selection
is an integer-value describing the dimension of the model.
One of the well known heuristic approach used in model selection is Occam’s razor (e.g., [1]). It
usually favors parsimony, i.e., simpler explanations instead of more complex ones while retaining the
explanatory power of the model. Hence, Occam’s razor chooses the simplest model among the candidate
models. Simpler models tend to capture the underlying structure of the phenomenon (such as signal
of interest) better, and consequently provide better performance in predicting the output when new
observations are processed. More complex models tend to overﬁt the observed data and to be more
sensitive to noise. Moreover, the model may not generalize well to new data. The same problem is
addressed in statistical inference where there is a trade-off between bias and variance when explaining
the observed data. Too simple models lead to a bigger systematic error (bias), while too complex models
may lead to an increased variance of estimated parameters and higher Cramer-Rao Bound as well as
to ﬁnding structures in the data that do not actually exist. Parsimony is also favored in the probability
theory, since the probability of making an error will increase by introducing additional assumptions that
may be invalid or unnecessary.
Traditionally it is assumed that there is a single correct hypothesis within the set of hypotheses
considered that describe the (true) model generating the given data. In practice, any model that we
assume will be only an approximation to the truth: for example, a data does not necessarily follow
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00002-3
© 2014 Elsevier Ltd. All rights reserved.
9

10
CHAPTER 2 Model Order Selection
an exactly normal distribution. Yet the described criteria are still useful in selecting the “best model”
from the set which is most supported by the data within the mathematical paradigm of the selected
information criteria. There are many practical consequences for a misspeciﬁed model order. In state-
space models and Kalman ﬁltering, models with too low order make the innovation sequence correlated
and the optimality of the ﬁlter is lost. On the other hand, if the order is too high, one may end up with
tracking the noise that can lead to divergence of the Kalman ﬁlter. In regression, models with too low
order may lead to biased estimates since they do not have enough ﬂexibility to ﬁt the data with high
ﬁdelity. On the other hand, too many parameters increase the variance of the estimates unnecessarily
and cause the loss of optimality.
Model selection is of fundamental interest to the investigator seeking a better understanding of the
phenomenon under study and the literature on this subject is considerable. Several review articles [2–4]
are noticeable among others as well as the full length text-books [1,5,6]. In this overview, we ﬁrst review
the classical model selection paradigms: the Bayesian Information Criterion (BIC) with an emphasis on
its asymptotic approximation due to Schwarz [7], Akaike’s Information Criterion (AIC) [8,9], stochastic
complexity [10] and its early development, the Minimum Description Length (MDL) criterion due to
Rissanen [11] and the generalized likelihood ratio test (GLRT-) based sequential hypothesis testing (see,
e.g., [12]). Among the methods considered, the MDL and AIC have their foundations in the information
theory and coding whereas BIC and GLRT methods have their roots in major statistical inference
paradigms (Bayesian and likelihood principle). The AIC is based on the asymptotic approximation of
the Kullback-Leibler (K-L) divergence, a fundamental notion in information theory, whereas Rissanen’s
MDLisbasedonthecodingtheory.However,bothofthesemethodscanalsobelinkedwiththelikelihood
principle and the classiﬁcation of the statistical inference and the information theory based methods
is provided mainly for pedagogic and informative purpose. There are some more recent contributions
such as the exponentially embedded family (EEF) method by Kay [13] and Bozdogan’s extensions of
AIC [14] among others which are not reviewed herein.
This chapter is organized as follows. First, Section 3.02.2 describes the basic principles, challenges
and the complexity of the model selection problems with a simple example: variable selection in the
multiple linear regression model. Especially, the need for compromise with the goodness of ﬁt and
concision (“principle of parsimony”), which is the key idea of model selection, is illustrated and the
forward stepwise regression variable selection principle using the AIC is explained along with the cross-
validation principle. Section 3.02.3 addresses statistical inference based methods (BIC, GLRT) in detail.
Section 3.02.4 introduces the AIC, the MDL and its variants and enhancements. In Section 3.02.5, the
model selection methods are derived and illustrated using a practical engineering example in determining
the dimension of the signal subspace; such problems arise commonly in sensor array processing, and
in harmonic retrieval; see, e.g., [15–18].
Notations.
More speciﬁcally, model selection refers to the multihypothesis testing problem of deter-
mining which model best describes a given data (measurement) y of size N. Let Hm, m = 1, . . . , M,
denote the set of hypotheses which may not be nested (i.e., H1 ̸⊂H2 ⊂· · · ̸⊂HM), and that each
hypothesis speciﬁes a probability density function (p.d.f.) fm with a parameter vector θ of dimension
K = dim(θ|Hm) in the parameter space . For the notational convenience we often suppress the sub-
script m (the model index) from θ, K, and  but the reader should keep in mind that these differ for
each model. Model order selection refers to ﬁnding the true dimension K of the model commonly in

3.02.2 Example: Variable Selection in Regression
11
the nested set of hypotheses. Let
ℓm(θ|y) ≜ln fm(y|θ) and
pm ≜P(Hm) ≡P(y ∼fm)
denote the log-likelihood function of the data under the mth model and the a priori probability of the
mth hypothesis (M
m=1 pm = 1), respectively. Usually, all models are a priori equally likely, in which
case pm = 1/M for m = 1, . . . , M. In the likelihood theory, the natural point estimate of θ is the
maximum likelihood estimate (MLE) ˆθ ≜arg maxθ∈ ℓm(θ|y) which is assumed to be unique. Let us
denote by
Jm ≡Jm(θ) ≜−E
∂2ℓm(θ|y)
∂θ∂θ T

and

Jm ≜−∂2ℓm
∂θ∂θ T (θ|y)

θ= ˆθ
(2.1)
the (expected) Fisher information matrix (FIM) and the observed FIM, respectively.
3.02.2 Example: variable selection in regression
In the multiple linear regression model the data y is modeled as y = Xβ + ε, where β ∈Rk denotes
the unknown vector of regression coefﬁcients, X is the known N × k matrix of explanatory variables
(k < N) and ε is the N-variate noise vector with i.i.d. components from normal distribution N(0, σ 2)
with an unknown variance σ 2 > 0. Let us call the columns of X (explanatory) variables following the
convention in statistics, i.e., we use Xi to denote both the column of X and the ith variable of the model.
Thus, y ∼NN(Xβ, σ 2I) and the p.d.f. and the log-likelihood are
f (y|θ) = (2π)−N/2(σ 2)−N/2 exp

−1
2σ 2 ∥y −Xβ∥2

,
ℓ(θ|y) = −N
2 ln σ 2 −
1
2σ 2 ∥y −Xβ∥2,
where θ = (βT , σ 2)T denotes the parameter vector. Commonly there is a large set of explanatory
variablesandthemaininterestischoosingthesubsetofexplanatoryvariablesthatsigniﬁcantlycontribute
to the data (response variable) y; see [19,20]. Thus, we consider the hypotheses
HI : Only the subset of variables, say Xi1, . . . , Xim, contribute to y,
where I = (i1, . . . , im), 1 ≤i1 < i2 < · · · < im ≤k, denotes the index set of the contributing
variables. Then under HI, the MLEs of the regression coefﬁcient and the noise variance correspond
to the classic least squares (LS-)estimates ˆβ = (X T
I X I)−1X T
I y and the residual sample variance,
ˆσ 2 = (1/N)RSS( ˆβ), respectively, where RSS( ˆβ) = ∥y −X I ˆβ∥2 is the residual sum of squares. Hence
the −2 × (maximum log-likelihood) under hypothesis HI becomes
−2 × ℓ( ˆθ|y) = N ln ˆσ 2 + 1
ˆσ 2 ∥y −X I ˆβ∥2 = N ln ˆσ 2 + N,
(2.2)
which always decrease when we include additional variables in the model. This is because ˆσ 2
+1 ≤ˆσ 2,
where ˆσ 2
+1 denotes the residual variance with one additional variable in the model. Then, ˆσ 2 = 0 if we
introduce as many explanatory variables as responses. More generally, if two models that are compared
are nested, then the one with more parameters will always yield a larger maximum log-likelihood, even
though it is not necessarily a better model.

12
CHAPTER 2 Model Order Selection
3.02.2.1 AIC and the stepwise regression
Previously, we noticed that minimizing −2×ℓ( ˆθ|y) cannot be used as the criterion. An intuitive approach
is to introduce an additive term that penalizes overﬁtting. The penalty term needs to be an increasing
function of K = dim(θ|HI) = m + 1, so that the criterion −2 × (maximum log-likelihood) decreases
as the penalty term increases yielding a trade-off between goodness of ﬁt and simplicity. This principle
of parsimony is the fundamental idea of model selection. As we shall see, the classic approximations
of information criteria reduce to such forms. For example, the AIC can be stated as
AIC = −2 × (maximum log-likelihood) + 2 × (number of estimable parameters),
that is, AIC = −2ℓ( ˆθ|y)+2K, and the regression model (hypothesis HI) that minimize the criterion is
chosen. Here, the penalty term is 2K which increases with K and hence penalizes selecting too many
variables. In the regression setting,
AIC(m) = N ln ˆσ 2 + 2m,
where we have suppressed the irrelevant additive constant N from (2.2) and the “plus one” term from
K = m + 1 which does not depend on the number of explanatory variables m = |I| in the model. Note
that the robust versions of AIC have been proposed, e.g., [21] which utilizes robust M-estimation.
The AIC is not computationally feasible for variable selection when the number of explanatory
variable candidates k is large. We need to consider all index sets I of size |I| = m for each m = 1, . . . , k
and for each m, there are
	 k
m

possible index sets. More practical and commonly used approach is to
use stepwise regression variable selection method. In the forward stepwise search strategy one starts
with a model containing only an intercept term (or a subset of explanatory variables), and then includes
the variable that yields the largest reduction in the AIC, i.e., the largest reduction in the RSS (and
thus improving the ﬁt the most). One stops when no variable produces a normalized reduction greater
than a threshold. There are several variants of stepwise regression which differ based on the criterion
used for inclusion/exclusion of variables. For example, instead of AIC, Mallows Cp, BIC, etc. can be
used. One particularly simple stepwise regression is to include in each step the variable that is most
correlated with the current residual r = y −ˆy, where ˆy is the LS ﬁt based on the current selection
of variables. This strategy is called the orthogonal matching pursuit [22] in the engineering literature.
Some modern approaches for variable selection in regression that can be related to the forward stepwise
regression are the LASSO (least absolute shrinkage and selection operator) [23] and the LARS (least
angle regression) [24]. LASSO minimizes the usual LS criterion (the sum of squared residuals) with an
additional L1-norm constraint on the regression coefﬁcient. As a result, some regression coefﬁcients are
shrunk to(wards) zero. LARS is a forward stepwise regression method where the selection of variables
is done differently: namely a regression coefﬁcient of the variable is increased until that variable is no
longer the one most correlated with the residual r. A simple modiﬁcation of the LARS algorithm can
be used to compute the LASSO solution [24].
3.02.2.2 Cross-validation and bootstrap methods
Cross-validation (CV) is a widely used technique for model order selection in machine learning, regres-
sion analysis, pattern recognition, and density estimation; see [25]. In CV one is interested in not only

3.02.2 Example: Variable Selection in Regression
13
ﬁnding a statistical model for the observed data but also in prediction performance for other independent
data sets. The goal is to ensure that the model generalizes well, not adapting too much to the particular
data set at hand. Unlike many other model selection techniques, CV can be considered a computer-
based heuristic method that replaces some statistical analyses by repeated computations over subsets
of data.
In CV, one splits the data set into subsets, one training set for the initial statistical analysis and the
other (potentially multiple) subsets for testing or validating the analysis. If the test data are independent
and identically distributed (i.i.d.), they can be viewed as new data in prediction. If the sample size for
the training set is small or the dimension of the initial model is high, it is likely that the obtained model
will ﬁt the set of observations with too high ﬁdelity. Obviously, this speciﬁc model will not ﬁt the other
test data sets equally well and the prediction estimates produced by the initial model using the training
set may contain signiﬁcantly off-values than expected ones.
The prediction results from the testing (validation) sets are used to evaluate the goodness of the
model optimized for the training set. The original model may then be adjusted by combining with the
models estimated from the test sets to produce a single model, for example by averaging. CV may also
be used in cases where the response is indicator of a class membership instead of being continuous
valued. This is the case in M-ary detection problems and pattern recognition, for example.
There are many ways to subdivide the data into training and test sets. The assignment may be random
such that the training set and the test set have equal number of observations. These two data sets may
be used for training and testing in an alternating manner. A very commonly used approach is so-called
leave-one-out (LOO) cross-validation. Each individual observation in the data set is serving a test set at
its turn while the remaining data form the training set. This is done exhaustively until all the observations
have been used as a test set. It is obvious that LOO has a high computational complexity since the training
set is different and training process is repeated every time.
Cross-validation can also be used for model order selection in regression. Let us assume that we
have a “supermodel” of large number of explaining variables and we want to select which subset of
explaining or predictor variables gives the best model in terms of its prediction performance. By using
the cross-validation approach with the test sets of observations one may ﬁnd a subset of explaining
variables that gives the best prediction performance measured, for example, in terms of mean square
error. If cross-validation is not used, adding more predictor variables in the model decreases the risk
or error measure, such as mean square error, sum of squared residuals or classiﬁcation error for the
training set but the predictive performance may be very different.
A few remarks on the statistical performance of the CV method are in place. CV gives a too positive
view on the quality of the model optimized for the training set. The risk or error measure such as MSE
will be smaller for the training set than the one for the test set. The variance of the cross-validation
estimates depends on the data splitting scheme and it is difﬁcult to analyze the performance of the
method in a general case. However, it has been established in some special cases, see [25]. If the model
is estimated for each subset of test data, the values of estimates will vary (estimator is a random variable).
The CV estimators often have some bias that depends on the size of the training sample relative
to the whole sample size. It tends to decrease as the training sample size increases. For the same size
of training set the bias remains the same but differences may be attested in variance (accuracy). The
overall performance of the CV estimators depends on many factors including the size of training data
set, validation data set, and the number of data subsets.

14
CHAPTER 2 Model Order Selection
Bootstrapping [26] is a resampling method that is typically used for characterizing conﬁdence inter-
vals. It has found applications in hypothesis testing and model order estimation as well, see, e.g., [27].
Assuming independent and identically distributed (i.i.d.) data samples, it resamples the observed data
set with replacement to simulate new data called bootstrap data. Then the parameter of interest such
as the variance or the mean is computed for the bootstrap sample. It is a computer-based method since
it requires that a very large number of resamples are drawn, and bootstrap estimates for each boot-
strap sample are computed. Availability of highly powerful computing machinery has made the use of
bootstrap more feasible in different applications as well as allowed to increase the sample sizes. The
bootstrap method does not make any assumptions on the underlying distribution of the observed data.
It is a nonparametric method and allows for characterizing the distribution of the observed data. This is
particularly useful for non-Gaussian data where the distribution may not be symmetric or unimodal. An
example of model order estimation in a sensor array signal processing application is provided in [27].
3.02.3 Methods based on statistical inference paradigms
In this section, we review the model selection methods based on two main stream statistical inference
paradigms (Bayesian and likelihood principles). The widely used asymptotic approximation of the
Bayesian Information Criterion (BIC) due to Schwarz [7] is reviewed ﬁrst, followed by the GLRT-
based model selection method which is based on the sequential use of the generalized likelihood ratio
test (GLRT). The latter method is one of the oldest approaches in model selection.
3.02.3.1 Bayesian Information Criterion (BIC)
We start by recalling the steps and assumptions that lead to the classic asymptotic approximation of
BIC due to Schwarz [7] which can be stated as follows:
BIC = −2 × (maximum log-likelihood) + ln N × (number of estimable parameters)
so that BIC = −2ℓ( ˆθ|y)+( ln N)K and the hypothesis Hm (mth model) that minimizes the criterion is to
be chosen. This approximation is based on the second-order Taylor expansion of the log posterior density
and some regularity assumptions on the log-likelihood and log posterior. Recall from earlier discussion
on the nested hypotheses, the term −2 × (maximum log-likelihood) monotonically decreases with an
increasing m (model index), and cannot be used alone as it leads to the choice of the model with the
largest number of parameters. The second term is the penalty term that increases with K = dim(θ|Hm)
and hence penalizes the use of too many parameters.
In the Bayesian framework, the parameter vector is taken to be a random vector (r.v.) with a prior
density qm(θ), θ ∈. For the mth model, let
gm(θ|y) ≜ℓm(θ|y) + ln qm(θ)
denote the log posterior density (neglecting the irrelevant additive constant term). The full BIC is
obtained by integrating out the nuisance variable θ in the posterior density of θ given the data y and the
model m:
BIC(m) ≜pm


exp{gm(θ|y)}dθ.
(2.3)

3.02.3 Methods Based on Statistical Inference Paradigms
15
The mth model that maximizes BIC(m) over m = 1, . . . , M is selected for the data. In most cases, the
integration cannot be solved in a closed-form and approximations are sought for.
In Bayesian approach, the maximum-a-posteriori probability (MAP) estimate ˆθB ≜arg maxθ∈
gm(θ|y) is a natural point estimate of θ and assume that it is unique. An approximation of g(·|y) around
the MAP estimate based on second-order Taylor expansion yields
gm(θ|y) ≈gm( ˆθB|y) −1
2(θ −ˆθB)T 
Hm(θ −ˆθB);

Hm ≜∂2gm
∂θ∂θ T (θ|y)|θ= ˆθB.
Note that the ﬁrst-order term vanishes when evaluated at the maximum. Let us assume that gm is twice
continuously differentiable (gm ∈C2()). This means that its second-order partial derivatives w.r.t. θ
exist on  and that the resulting K × K (negative) Hessian matrix 
Hm is symmetric. Substituting the
approximation into (2.3) yields
BIC(m) ≈pm exp{gm( ˆθB|y)}

θm
exp

−1
2(θ −ˆθB)T 
Hm(θ −ˆθB)

dθ
= pm exp{gm( ˆθB|y)}(2π)K/2| 
Hm|−1/2,
where the last equality follows by noticing that the integrand is the density of K-variate NK ( ˆθB, 
H−1
m )
distribution up to a constant term (2π)−K/2| 
Hm|1/2, where | · | denotes the matrix determinant. Equiv-
alently, we can minimize the log of BIC. In logarithmic form, the BIC becomes
BIC(m) ≈ln pm + gm( ˆθB|y) + K
2 ln (2π) −1
2 ln | 
Hm|.
(2.4)
An alternative approximation for the BIC can be derived with the following assumption:
(A)
the prior distribution qm(θ) is sufﬁciently ﬂat around the MAP estimate ˆθB and does not depend
on N for m = 1, . . . , M.
Due to (A), when evaluating the integral in (2.3), we may extract the qm(θ) term from the integrand as
a constant proportional to qm( ˆθB), yielding the approximation
BIC(m) ≈pmqm( ˆθB)

θm
exp{ℓm(θ|y)}dθ,
(2.5)
≈pmqm( ˆθB) exp{ℓm( ˆθ|y)}(2π)K/2| 
Jm|−1/2,
(2.6)
where 
Jm is the Fisher information matrix of the mth model evaluated at the unique MLE ˆθ. Note that
(2.6) is an approximation of (2.5) using (similarly as earlier) the second-order Taylor expansion on
ℓm(θ|y) around the MLE. Thus in terms of logarithms, we have
BIC(m) ≈ln pm + ln qm( ˆθB) + K
2 ln (2π) + ℓm( ˆθ|y) −1
2 ln | 
Jm|.
(2.7)
Note that approximations (2.4) and (2.7) differ as the former (resp. the latter) is obtained for the case
that the full log posterior (resp. log-likelihood) is expanded to the second-order terms. Furthermore,
(2.7) relies upon (A).

16
CHAPTER 2 Model Order Selection
Next, note that under some regularity conditions and due to consistency of the MLE ˆθ, we can in
most cases approximate ln | 
Jm| for a sufﬁciently large N as
ln | 
Jm| ≈K ln N.
(2.8)
Since the three ﬁrst terms in (2.7) are independent of N [recall assumption (A)], we may neglect the ﬁrst
three terms in (2.7) for large N, yielding after multiplying by −2 the earlier stated classic approximation
due to Schwarz,
BIC(m) = −2ℓm( ˆθ|y) + K ln N.
(2.9)
Let us recall the assumptions for the above result. First of all, the log-likelihood function ℓought to be a
C2-function around the neighborhood of the unique MLE ˆθ. Second, the prior density is assumed to ver-
ify Assumption (A). Third, sufﬁcient regularity conditions based on likelihood theory, e.g., consistency
of ˆθ, are needed for the approximation (2.8) to hold. Note that the classic BIC approximation, in contrast
to approximations (2.4) or (2.7), is based on asymptotic arguments, i.e., N is assumed to be sufﬁciently
large. Naturally, how large N is required, depends on the application at hand. The beneﬁt of such an
approximation is its simplicity and good performance observed in many applications. As we shall see
in Section 3.02.4, Rissanen’s MDL derived using arguments in coding theory can be asymptotically
approximated in the same form as BIC in (2.9). This sometimes leads to misunderstanding that MDL
and BIC are the same.
If we assume that the set of hypotheses {Hm} includes the true model Hm⋆that generated the
data, then the probability that the true m⋆th model is selected can often be calculated analytically.
For example, in the regression setting, the BIC estimate has proven to be consistent [28], that is,
P(“correctly choosing Hm⋆”) →1 as N →∞. This can be contrasted with the AIC estimate that fails
to be consistent, due to a tendency of overﬁtting [28].
3.02.3.2 GLRT-based sequential hypothesis testing
Let us assume that sequence of model p.d.f.’s fm(y|θ), θ ∈m, belong to the same parametric family
(i.e., share the same functional form, so f = fm for m = 1, . . . , M) and are ordered in the sense that
m ⊂m+1. Hence, we have a nested set of hypotheses H1 ⊂H2 ⊂· · · ⊂Hm. We can consider HM
as the “full model” and Hm, m < M, a parsimonious model presuming that a subset of the parameters
of the full model are equal to zero. This type of situation can arise in many engineering applications;
a practical application is given in Section 3.02.5. In such a scenario, the GLRT statistic, deﬁned as the
−2× the log of the ratio of the likelihood functions maximized under Hm and under the full model HM:

m = −2{ℓ( ˆθm|y) −ℓ( ˆθM|y)} = −2 ln
 maxθ∈m f (y|θ)
maxθ∈M f (y|θ)

,
(2.10)
where ˆθm = arg maxθ∈m ℓ(θ|y) and ˆθM = arg maxθ∈M ℓ(θ|y) and ℓ(θ|y) = ln f (y|θ) denotes the
log-likelihood.Bythegeneralmaximumlikelihoodtheory,
m hasaχ2
DOF(m) distributionasymptotically
(i.e., chi-squared distribution with DOF(m) degrees of freedom), where
DOF(m) = dim(θ|HM) −dim(θ|Hm).

3.02.4 Information and Coding Theory Based Methods
17
The null hypothesis Hm is rejected if 
m exceeds a rejection threshold γm, where γm is (1−α)th quantile
of the χ2
DOF(m) distribution (i.e., P(
m > γm) = α when 
m ∼χ2
DOF(m)). Such a detector has an
asymptotic probability of false alarm (PFA) equal to α. For example, choosing PFA equal to α = 0.05
is quite reasonable for many applications; however, in radar applications, smaller PFA is often desired.
The sequential GLRT-based model selection procedure chooses the ﬁrst hypothesis Hm (and hence
dim(θ|Hm) as the model order) that is not rejected by the GLRT statistic. In other words, we ﬁrst test
H1 and if it is rejected by the GLRT statistic (2.10) (
1 > γ1 for some predetermined PFA α), then
test H2, etc. until acceptance, i.e., until 
m ≤γm. In case that all hypotheses are rejected, then we
accept the full model HM. Note that the above decision sequence is not statistically independent, even
asymptotically. Hence, even though the asymptotic PFA of each individual GLRT for testing Hm is α,
it does not mean that the asymptotic PFA of the GLRT-based model selection is α. It is also possible to
use a backward testing strategy, i.e., test the sequence of hypotheses H1, . . . , HM−2, HM−1 from the
reverse direction. Then we select the model in the sequence before the ﬁrst rejection. That is, we ﬁrst test
HM−1 and if it is accepted, then test HM−2. Continue until the ﬁrst rejection and select the hypothesis
tested prior the rejection. If it is known a priori that a large model order is more likely than a small
model order, then the backward strategy might be preferred from pure computational point of view.
3.02.4 Information and coding theory based methods
The information and coding theory based approaches for model order selection are frequently used.
We will consider two such techniques, Information Criterion proposed by Akaike [8,9] and Minimum
Description Length (MDL) methods proposed by Rissanen [10,11]. The enhanced versions of both
methods have been introduced in order to provide more accurate results for ﬁnite sample sizes and in
some cases to relax unnecessary assumptions on underlying distribution models.
3.02.4.1 Akaike Information Criterion (AIC)
The AIC criterion is based on an asymptotic approximation of the K-L divergence. Let f0(y) denote
the true p.d.f. of the data and let f (y|θ) denote the approximating model. The Kullback-Leibler (K-L)
divergence (or relative entropy), can be deﬁned as the integral (as f and f0 are continuous functions)
D( f0∥f ) = E0

ln
 f0(y)
f (y|θ)

=

f0(y) ln
 f0(y)
f (y|θ)

dy
and it can be viewed as the information loss when the model f is used to approximate f0 or as a “distance”
(discrepancy) between f and f0 since it veriﬁes
D( f0∥f ) ≥0 with equality if and only if f0 = f .
Clearly, among the models in the set of hypotheses Hm : y ∼fm(y|θm), the best one loses the least
information(havesmallest valueof D( fm∥f0)) relative to the other models. Note that the K-L divergence
can be expressed as
D( f0∥f ) = E0[ln f0(y)] −E0[ln f (y|θ)],

18
CHAPTER 2 Model Order Selection
where the model dependent part is −E0[ln f (y|θ)]. When ﬁnding the minimum of D( f0∥f ) over the
set of models considered is equivalent to ﬁnding the maximum of the function
I( f0, f ) = E0[ln f (y|θ)] = E0[ℓ(θ|y)]
among all the models. The function I( f0, f ), sometimes referred to as relative K-L information, cannot
be used directly in model selection because it requires the full knowledge of the true data p.d.f. f0 and
the true value of the parameter θ in the approximate model f (y|θ), both of which are unknown. Hence
we settle with its estimate
ˆI( f0, f ) = Ey

Ew[ln f (w| ˆθ(y))]

,
(2.11)
where w is an (imaginary) independent data vector from the same unknown true distribution f0 as the
observed data y and ˆθ = ˆθ(y) denotes the MLE of θ based on the assumed model f and the data y.
Note that the statistical expectations above are w.r.t. to the true (unknown) p.d.f. f0 and we maximize
(2.11) instead of I( f0, f ). Key ﬁnding is that for a large sample size N, the maximized log-likelihood
ℓ( ˆθ|y) = ln f (y| ˆθ) is a biased estimate of (2.11) where the bias is approximately equal to K, the number
of the estimable parameters in the model. The maximum log-likelihood corrected by the asymptotic
bias, i.e., ℓ( ˆθ|y) −K, can be viewed (under regularity conditions) as an unbiased estimator of I( f , f0)
when N is large. Multiplying by −2 gives the famous Akaike’s Information Criterion
AIC = −2ℓ( ˆθ|y) + 2K.
Unlike the BIC, the AIC is not consistent, namely the probability of correctly identifying the true model
does not converge to one with the sample length. It can be shown that for nested hypotheses and under
fairly general conditions,
P(“choosing Hk ⊂Htrue”) →0,
P(“choosing Hk ⊃Htrue”) →c > 0 as N →∞,
that is, AIC tends to overﬁt, i.e., choosing model order that is larger then the true model order. See,
e.g., [15].
Some enhanced versions have been introduced where the penalty term is larger to reduce the chance
of overﬁtting. The following corrected AIC rule [29,30]
AICc = −2ℓ( ˆθ|y) + 2K + 2K(K + 1)
N −K −1,
(2.12)
= −2ℓ( ˆθ|y) + CN · 2K,
where CN =
N
N −K −1
(2.13)
provides a ﬁnite sample (second-order bias correction) adjustment to AIC; asymptotically they are the
same since CN →1 when N →∞, but CN > 1 for ﬁnite N. Consequently the penalty term of AICc
is always larger than that of AIC, which means that the criterion is less likely to overﬁt. On the other
hand, this comes with an increased risk of underﬁtting, i.e., choosing a smaller model order than the true
one. Since the underﬁtting risk does not seem to be unduly large in many practical experiments, many
researchers recommend the use of AICc instead of AIC. It should be noted, however, that AICc possess

3.02.4 Information and Coding Theory Based Methods
19
a sound theoretical justiﬁcation only in the regression model with normal errors, where it is an unbiased
estimate of the relative K-L information; note that AIC is by its construction only an asymptotically
unbiased estimate of the relative K-L information. Besides the regression model, the reasonings for
CN, lay merely on its property of reducing the risk of overﬁtting. The so-called generalized information
criteria (GIC) [2], deﬁned as in (2.13) as
GIC = −2ℓ( ˆθ|y) + C′
N · 2K
can often outperform AIC for C′
N > 1. For example, when C′
N = CN the AICc is obtained and the
choice C′
N = (1/2) log N yields the MDL criterion.
3.02.4.2 Minimum Description Length
The Minimum Description Length [11] method stems from the algorithmic information and coding
theory. The basic idea is to ﬁnd any regularity in the observed data that can be used to compress the
data. This allows for condensing the data so that less symbols are needed to present it. The code used
for compressing the data should be such that the total length (in bits) of description of the code and
the description of the data is minimal. There exists a simple and reﬁned version of the MDL method.
The concept of stochastic complexity will be employed in estimating the model order. It deﬁnes the
code length of the data with respect to the employed probability distribution model. It also establishes a
connection to statistical model order estimation methods such as BIC and MDL. In some special cases,
the approximation of stochastic complexity and BIC leads to the same criterion. Detailed descriptions
of the MDL method can be found in [1,4].
The MDL method does not make any assumptions on the underlying distribution of the data. In fact,
it is considered to be less important since the task at hand is not to estimate the distribution that generated
the data but rather to extract useful information or model from the data that facilitates by compressing
it efﬁciently. However, codes used for compressing data and the probability mass functions are related.
The Kraft inequality establishes a correspondence between code lengths and probabilities whereas the
information inequality relates the optimal code in terms of the minimum expected code length with the
distribution of the data. If the data obeys the distribution f (y), then the code with the length −log f (y)
achieves the minimum code length on average.
A simple version of the MDL principle may now be stated as follows. Let H be a class of candidate
models or codes used to explain the data y. The best model H ∈H is the one that minimizes
L(H) + L(y|H),
i.e., the sum of the length of the description of the model and the length of the data encoded using
the model. Trading-off between complexity of the code and complexity of the data is built in the MDL
method.Hence,itislesslikelytooverestimatethemodelorderandoverﬁtthedatathanAIC,forexample.
A probability distribution where the parameter θ may vary deﬁnes a family of distributions. The
task of interest is to optimally encode the data and to use the whole family of distributions in order to
make the process efﬁcient. An obvious choice from the distribution family would be to use the code
corresponding to f (y| ˆθ) where ˆθ is the MLE of θ for the observed data, i.e., θ that most likely would
have produced the data set. Consequently, the code corresponding to the maximum likelihood (or the
probability model) depends on the data and the code cannot be speciﬁed before observing the data.

20
CHAPTER 2 Model Order Selection
This makes this approach less practical. One could avoid this problem by using an universal distribution
model that is representative of the entire family of distributions and would allow coding the data set
almost as efﬁciently as the code associated with the maximum likelihood function. The reﬁned MDL
uses normalized maximum likelihood approach for ﬁnding an universal distribution model used to assist
the coding. This will lead to an excessive code length that is often called regret. The Kullback-Leibler
divergence D(p∥f ) may be used as a starting point where p is employed to approximate the distribution
f. Finding the optimal universal distribution p∗can be formulated as a minimax problem:
p∗= arg
p
min
p max
q

ln f (y| ˆθ)
p(y)

,
where q denotes the set of all feasible distributions. The distribution q(y) represents the worst case
approximation of the maximum likelihood code and it is allowed to be almost any distribution within a
model class of feasible distributions. Hence, the assumption on the true distribution generating the data
may be considered to be relaxed. The so-called normalized maximum likelihood (NML) distribution
satisﬁes the above optimization problem. It may be written as [31]
p∗(y) =
f (y| ˆθ)

f (Y| ˆθ)dY
,
where ˆθ denotes the maximum likelihood estimate of θ over the observation set. The denominator is a
normalizingfactorthatisthesumofthemaximumlikelihoodsofallpotentialobservationsets Yacquired
in experiments, and the numerator represents the maximized likelihood value. With this solution, the
worst case data regret is minimized. It has been further shown that by solving a related minimax problem
p∗= arg
p
min
p max
q
Eq

ln f (y| ˆθ)
p(y)

,
the worst case of the expected regret is considered instead of the regret for the observed data set, see [32].
The code length associated with normalized maximum likelihood is called the stochastic complexity
of the data for a distribution family. It minimizes the worst case expected regret
Eq

ln f (y| ˆθ)
p∗(y)

.
The MDL method employs ﬁrst the normalized maximum likelihood distributions to order the candidate
models and chooses the model that gives minimal stochastic complexity. An early result by Rissanen
[11] and a frequently used approximation for the stochastic complexity is given as follows:
MDL(K) = −2 log f (y| ˆθ) + K log N,
which is the same result as the approximation of BIC by Schwarz given earlier in this section. Other
approximations of the stochastic complexity that are more accurate avoid some pitfalls of the above
approximation, for example:
MDL(K) = −2 log f (y| ˆθ) + K log N + log

θ

|I(θ)|dθ + o(1),

3.02.5 Example: Estimating Number of Signals in Subspace Methods
21
where I(θ) denotes the Fischer information matrix of sample size 1. The term o(1) contains the higher
order terms and vanishes as N →∞. The integral term with Fischer information needs to be ﬁnite.
See [33] for more detail on other approximations and their computation. The MDL principle and the
normalized maximum likelihood (NML) lead to the same expression as the Bayesian Information
Criterion (BIC) in some special cases, for example, when Jeffrey’s noninformative prior is used in a
Bayesian model and N →∞. In general, however, the NML and BIC have different formulations.
The MDL has been shown to provide consistent estimates of the model order, e.g., for estimating the
dimensionality of the signal subspace in the presence of white noise [34]. This problem is reviewed in
detail in the next section.
3.02.5 Example: estimating number of signals in subspace methods
We consider the problem of estimating the dimensionality of the signal subspace. Such a problem
commonly arises in array processing, time-delay estimation, frequency estimation, channel order esti-
mation, for example. In these applications, if the signals are not coherent and signals are narrow-band,
the dimension of the signal subspace deﬁnes the number of signals.
We consider the model, where the received data y ∈CM consists of (unobservable) random zero
mean signal vector v ∈CM plus additive zero mean white noise n ∈CM (E[nnH] = σ 2I with
σ 2 > 0 unknown) uncorrelated with the signal v which is supposed to lie in an m-dimensional sub-
space of CM (m ≤M), called the signal subspace. The covariance of the data y = v + n is then
 = E[yyH] =  + σ 2I, where the signal covariance matrix  = E[vvH] is of rank() = m ≤M.
Let λ1 ≥λ2 ≥· · · ≥λM ≥0 denote the ordered eigenvalues of . If rank() = m, then the smallest
eigenvalue λM equals σ 2 and has multiplicity M −m, whereas the m largest eigenvalues are equal to
the nonzero eigenvalues of  plus σ 2. Hence, testing that the signal subspace has dimensionality m
(m ∈{0, 1, . . . , M −1}) can be formulated as a hypothesis of the equality of the eigenvalues
Hm : λm+1 = λm+2 = · · · = λM
(2.14)
and a GLRT can be formed against a general alternative HM :  arbitrary. Thus, we have a set of
hypotheses {Hm, m = 0, 1, . . . , M} and a model selection method can be used to determine the best
model given the data. To this end, note that H0 corresponds to the noise-only hypothesis. Let us assume
that v and n possess M-variate circular complex normal (CN) distribution in which case the received
data y has a zero mean CN distribution with covariance matrix . Further suppose that an i.i.d. random
sample y1, . . . , yN is observed from y ∼CNM(0, ).
For the above problem, GLRT-based sequential test or the MDL and AIC criteria have been widely
in sensor array signal processing and subspace estimation methods; see, e.g., [15–17], where the task at
hand is to determine the number of signals m impinging on the sensor array. In this case, the signal v has a
representation v = a(ϑ1)s1+· · ·+a(ϑm)sm, where a(ϑi) denote the array response (steering vector) for
a random source signal si impinging on the array from the direction-of-arrival (DOA) ϑi (i = 1, . . . , m).
In this application, the sample y1, . . . , yN represents the array snapshots at time instants t1, . . . , tN and
the SCM  is the conventional estimate of the array covariance matrix , where the signal covariance
matrix  has a representation  = AE[ssH]AH, where A = (a(ϑ1) · · · a(ϑm)) denotes the array

22
CHAPTER 2 Model Order Selection
steering matrix and s = (s1, . . . , sm)T the vector of source signals. Another type of the problem such
as determining the degree of non-circularity of complex random signals is illustrated in detail in [35].
Let us proceed by ﬁrst constructing the sequential GLRT-based model order selection procedure for
the problem at hand. The p.d.f. of y ∼CNM(0, ) is f (y|) = π−M˙||−1 exp ( −yH−1y), and
thus the log-likelihood function of the sample is
ℓ(θ) =
N

i=1
ln f (yi|) ∝−N ln || −N Tr(−1),
where  = 1
N
N
i=1 yiyH
i
denotes the sample covariance matrix (SCM), Tr( · ) denotes matrix trace
and θ denotes the vector consisting of functionally independent real-valued parameters in . Naturally,
θ has different parameter space m under each hypothesis Hm dimension and hence also different order
dim(θ|Hm). Under no-structure hypothesis HM, dim(θ|HM) = M2. This follows as  is Hermitian and
hence there are M(M −1) estimable parameters due to Re(i j) and Im(i j) for i < j ∈{1, . . . , M}
and M estimable parameters ii ≥0, i = 1, . . . , M. For Hm, where m < M, K is the number of
functionally independent real parameters in  with rank m plus 1 due to σ 2 > 0. The eigenvalue
decomposition of  is  = m
i=1 ψiuiuH
i
where ψi = λi −σ 2 represent its nonzero eigenvalues and
uis the corresponding eigenvectors. There are 2Mm real parameters in the eigenvectors but they are
tied by 2m constraints due to the scale and phase indeterminacy of each eigenvector1 and an additional
m(m −1) constraints due to orthogonality of the eigenvectors, uH
i u j = 0 + j0 for i < j ∈{1, . . . , m}.
Since there are m eigenvalues ψi and σ 2, the total number of estimable parameters in θ is
dim(θ|Hm) = 2Mm + m + 1 −2m −m(m −1) = m(2M −m) + 1
(2.15)
when m < M.
Let us then derive the GLRT statistic 
m as deﬁned in (2.10). Under Hm for m ≤M, the maximum
log-likelihood is
ℓ( ˆθm) = max
θ∈m ℓ(θ) = −N ln
m

i=1
ˆλi −N(M −m) ln ˆσ 2 −N M,
(2.16)
where ˆλ1, ˆλ2, . . . , ˆλM denote the eigenvalues of the SCM  and ˆσ 2 =
1
M−m
M
i=m+1 ˆλi. The proof
of (2.16) follows similarly as in Anderson [36, Theorem 2] in the real case. Then given the expression
(2.16), it is easy to verify the GLRT statistic 
m = −2{ℓ( ˆθm) −ℓ( ˆθM)}, simpliﬁes into the form

m = −2N(M −m) ln ϱ(m),
(2.17)
where
ϱ(m) = 1
ˆσ 2 (ˆλm+1ˆλm+2 · · · ˆλM)
1
M−m
(2.18)
is the ratio of the geometric to the arithmetic mean of the noise subspace eigenvalues of the SCM. If Hm
holds, this ratio tends to unity as N →∞. Now recall from Section 3.02.3.2 that the GLRT statistic
1Recall that scale indeterminacy is ﬁxed by assuming uH
i ui = 1 and the phase of ui can be ﬁxed similarly by any suitable
convention.

References
23

m in (2.17) has a limiting χ2
DOF(m) distribution, where
DOF(m) = dim(θ|HM) −dim(θ|Hm) = M2 −{m(2M −m) + 1} = (M −m)2 −1.
The (forward) GLRT-based model selection procedure then chooses the ﬁrst Hm not rejected by the
GLRT, i.e., the ﬁrst m which veriﬁes 
m ≤γm, where (as discussed in Section 3.02.3.2) the detection
threshold γm can be set as the (1 −α)th quantile of the χ2
DOF(m). This choice yields the asymptotic PFA
α for testing hypothesis (2.14).
Let us now derive the AIC and MDL criteria. Let us ﬁrst point out that the −N M term in (2.16) can be
dropped as it does not depend on m whereas any constant term (namely, c = ln M
i=1 ˆλi) not dependent
on m can be added, thus showing that ℓ( ˆθm) in (2.16) can be written compactly as n(M −m) ln ϱ(m) up
to irrelevant additive constant not dependent on m. Further noting that the +1 can be dropped from the
penalty term dim(θ|Hm) in (2.15), we have the result that the AIC and the MDL criteria can be written
in the following forms:
AIC(m) = −2n(M −m) ln ϱ(m) + 2m(2M −m),
MDL(m) = −2n(M −m) ln ϱ(m) + 2m(2M −m) · ln N
2 .
An estimate of the AIC/MDL model order, i.e., the dimensionality of the signal subspace m, is found by
choosing m ∈{0, 1, . . . , M −1} that minimizes the AIC/MDL criterion above. As already pointed out,
the penalty term of the MDL is (1/2) ln N times the penalty term of AIC. Since (1/2) ln N > 1 already
at small sample lengths (N ≥8), the MDL method is less prone to overﬁtting the data compared to the
AIC. Note that ﬁrst term in the MDL and AIC criterions above is simply the GLRT statistic 
m. Wax
and Kailath [15] showed the MDL rule consistent in choosing the true dimensionality whereas the AIC
tends to overestimate the dimensionality (in the large sample limit). Later [34] proved the consistency
of the MDL rule when the CN assumption does not hold.
3.02.6 Conclusions
In this section, we provided an overview of model order estimation methods. The majority of well-
deﬁned methods stem from statistical inference or coding and information theory. The likelihood
function plays a crucial role in most methods based on solid theoretical foundation. Statistical and
information theoretical methods stem from fundamentally different theoretical background but have
been shown to lead to identical results under certain restrictive assumptions and model classes. A prac-
tical example of model order estimation in case of low-rank model that is commonly used in sensor
array signal processing and many other tasks that require high-resolution capability was provided.
References
[1] P.D. Grünwald, The Minimum Description Length Principle, MIT Press, 2007.
[2] P. Stoica, Y. Selen, Model-order selection: a review of information criterion rules, IEEE Signal Process. Mag.
21 (4) (2004) 36–47.

24
CHAPTER 2 Model Order Selection
[3] A.D. Lanterman, Schwarz, Wallace and Rissanen: intertwining themes in theories of model selection, Int.
Stat. Rev. 69 (2) (2001) 185–212.
[4] P.D. Grünwald, I. Myung, M. Pitt (Eds.), Advances in Minimum Description Length: Theory and Applications,
MIT Press, 2005.
[5] H. Linhart, W. Zucchini, Model Selection, Wiley, New York.
[6] K. Burnham, D. Anderson, Model Selection and Inference: A Practical Information-Theoretic Approach,
Springer, New York, 1998.
[7] G. Schwarz, Estimating the dimension of a model, Ann. Stat. 6 (2) (1978) 461–464.
[8] H. Akaike, Anewlookat thestatistical model identiﬁcation, IEEE Trans. Automat. Control 19(1974) 716–723.
[9] H. Akaike, On the likelihood of a time series model, The Statistician 27 (3) (1978) 217–235.
[10] J. Rissanen, Stochastic complexity and modeling, Ann. Stat. 14 (3) (1986) 1080–1100.
[11] J. Rissanen, Modeling by the shortest data description, Automatica 14 (1978) 465–471.
[12] S.M. Kay, Fundamentals of Statistical Signal Processing: Detection Theory, Prentice Hall, 1998.
[13] S. Kay, Exponentially embedded families—new approaches to model order estimation, IEEE Trans. Aerosp.
Electron. Syst. 41 (1) (2005) 333–344.
[14] H. Bozdogan, Model selection and Akaike’s information criterion (AIC): the general theory and its analytical
extensions, Psychometrika 52 (3) (1987) 345–370.
[15] T. Wax, T. Kailath, Detection of signals by information theoretic criteria, IEEE Trans. Acoust. Speech Signal
Process. 33 (2) (1985) 387–392.
[16] Q.T. Zhang, K.M. Wong, Information theoretic criteria for the determination of the number of signals in
spatially correlated noise, IEEE Trans. Signal Process. 41 (4) (1993) 1652–1663.
[17] G. Xu, R.H.I. Roy, T. Kailath, Detection of number of sources via exploitation of centro-symmetry property,
IEEE Trans. Signal Process. 42 (1) (1994) 102–112.
[18] A.A. Shah, D.W. Tufts, Determination of the dimension of a signal subspace from short data records, IEEE
Trans. Signal Process. 42 (9) (1994) 2531–2535.
[19] S. Weisberg, Applied Linear Regression, Wiley, New York, 1980.
[20] N.R. Draper, H. Smith, Applied Regression Analysis, third ed., Wiley, New York, 1998.
[21] E. Ronchetti, Robust model selection in regression, Stat. Prob. Lett. 3 (1985) 21–23.
[22] J.A. Tropp, A.C. Gilbert, Signal recovery from random measurements via orthogonal matching pursuit, IEEE
Trans. Inform. Theory 53 (12) (2007) 4655–4666.
[23] R. Tibshirani, Regression shrinkage and selection via the lasso, J. Roy. Stat. Soc. Ser. B 58 (1996) 267–288.
[24] B. Efron, T. Hastie, I. Johnstone, R. Tibshirani, Least angle regression, Ann. Stat. 32 (2) (2004) 407–451.
[25] S. Arlot, A. Celisse, A survey of cross-validation procedures for model selection, Stat. Surv. 4 (2010) 40–79.
[26] B. Efron, Bootstrap methods: another look at the jackknife, Ann. Stat. 7 (1) (1979) 1–26.
[27] R. Brcich, A.M. Zoubir, P. Pelin, Detection of sources using bootstrap techniques, IEEE Trans. Signal Process.
50 (2) 206–215.
[28] R. Nishii, Asymptotic properties of criteria for selection of variables in multiple regression, Ann. Stat. 2 (1984)
758–765.
[29] J.E. Cavanaugh, Unifying the derivations for the Akaike and corrected Akaike information criteria, Stat. Prob.
Lett. 33 (1977) 201–208.
[30] N. Sugiura, Further analysis of the data by Akaike information criterion and the ﬁnite corrections, Commun.
Stat. Theory Methods 7 (1978) 13–26.
[31] Y. Shtarkov, Block universal sequential coding of single messages, Prob. Inform. Transmission 23 (3) (1987)
175–186.
[32] J. Myung, D. Navarro, M. Pitt, Model selection by normalized maximum likelihood, J. Math. Psychol. 50
(2006) 167–179.

References
25
[33] P. Kontkanen, W. Buntine, P. Myllymaki, J. Rissanen, H. Tirri, Efﬁcient computation of stochastic complexity,
in: Proceedings of International Conference on Artiﬁcial Intelligence and, Statistics, 2003, pp. 233–238.
[34] L.C. Zhao, P.R. Krishnaiah, Z.D. Bai, On detection of the number of signals in presence of white noise,
J. Multivar. Anal. 20 (1) (1986) 1–25.
[35] M. Novey, E. Ollila, T. Adali, On testing the extent of noncircularity, IEEE Trans. Signal Process. 59 (11)
(2011) 5632–5637.
[36] T.W. Anderson, Asymptotic theory for principal component analysis, Ann. Math. Stat. 1 (1963) 122–148.

3
CHAPTER
Non-Stationary Signal Analysis
Time-Frequency Approach
Ljubiša Stankovi´c*, Miloš Dakovi´c*, and Thayananthan Thayaparan†
*Electrical Engineering Department, University of Montenegro, Montenegro
†Defense Scientist, Defence R&D, Ottawa, Canada
3.03.1 Introduction
The Fourier transform (FT) provides a unique mapping of a signal from the time domain to the frequency
domain. The frequency domain representation provides the signal’s spectral content. Although the phase
characteristic of the FT contains information about the time distribution of the spectral content, it is
very difﬁcult to use this information. Therefore, one may say that the FT is practically useless for this
purpose, i.e., that the FT does not provide a time distribution of the spectral components.
Depending on problems encountered in practice, various representations have been proposed to
analyze non-stationary signals in order to provide time-varying spectral description. The ﬁeld of the
time-frequency signal analysis deals with these representations of non-stationary signals and their
properties. Time-frequency representations may roughly be classiﬁed as linear, quadratic or higher
order representations.
Lineartime-frequencyrepresentationsexhibitlinearity,i.e.,therepresentationofalinearcombination
of signals equals the linear combination of the individual representations. From this class, the most
important one is the short-time Fourier transform (STFT) and its variations. A speciﬁc form of the
STFT was originally introduced by Gabor in mid 1940s. The energetic version of the STFT is called
spectrogram. It is the most frequently used tool in time-frequency signal analysis [1–6].
The second class of time-frequency representations are the quadratic ones. The most interesting
representations of this class are those which provide a distribution of signal energy in the time-frequency
plane. They will be referred to as distributions. The concept of a distribution is borrowed from the
probability theory, although there is a fundamental difference. For example, in time-frequency analysis,
distributions may take negative values. Other possible domains for quadratic signal representations are
the ambiguity domain, the time-lag domain and the frequency-Doppler frequency domain.
Despite the loss of the linearity, the quadratic representations are commonly used due to higher time-
frequency concentration compared to linear transforms. A quadratic time-frequency representation
known as the Wigner distribution was the ﬁrst representation introduced in 1932. It is interesting to note
that the motivation for deﬁnition of this distribution, as well as for some others, was found in quantum
mechanics. The Wigner distribution was introduced into the signal theory by Ville in 1948. Therefore,
it is often called the Wigner-Ville distribution. In order to reduce undesirable effects, other quadratic
time-frequency distributions have been introduced. A general form of all quadratic time-frequency
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00003-5
© 2014 Elsevier Ltd. All rights reserved.
27

28
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
distributions has been deﬁned by Cohen (1966) and introduced in time-frequency analysis by Claasen
and Mecklenbräuker (1981). This generalization prompted the introduction of new time-frequency
distributions, including the Choi-Williams distribution, Zhao-Atlas Marks distribution and many other
distributions referred to as the reduced interference distributions [1,2,6–18].
Higher order representations have been introduced in order to further improve the concentration of
time-frequency representations [6,19–22].
3.03.2 Linear signal transforms
A transform is linear if a linear combination of signals is equal to the linear combination of the trans-
forms. Various complex forms of signal representations satisfy this property, starting from the short-time
Fourier transform, via local polynomial Fourier transform and wavelet transform, up to general signal
decomposition forms, including chirplet transform. Although energetic versions of the linear trans-
forms, calculated as their squared moduli, do not preserve the linearity, they will be considered within
this section as well.
3.03.2.1 Short-time fourier transform
The Fourier transform (FT) of a signal x(t) and its inverse are deﬁned by
X() =
 ∞
−∞
x(t)e−jtdt,
(3.1)
x(t) = 1
2π
 ∞
−∞
X()e jtd.
(3.2)
The FT of a signal x(t) shifted in time for t0, i.e., x(t −t0), is equal to X() exp (−jt0). The amplitude
characteristics of x(t) and x(t −t0) are the same and equal to |X()|. The same holds for a real valued
signal x(t) and its shifted and reversed version x(t0 −t). We will illustrate this with two different signals
x1(t) and x2(t) (distributed over time in a different manner) producing the same amplitude of the FT
(see Figure 3.1)
x1(t) = sin

122π t
128

−cos

42π t
128 −16
11π
t −128
64
2
−1.2 cos

94π t
128 −2π
t −128
64
2
−π
t −120
64
3
e
−

t−140
75
2
−1.6 cos

15π t
128 −2π
t −50
64
2
e
−

t−50
16
2
,
(3.3)
x2(t) = x1(255 −t).
The idea behind the short-time Fourier transform (STFT) is to apply the FT to a portion of the
original signal, obtained by introducing a sliding window function w(t) which will localize, truncate
(and weight), the analyzed signal x(t). The FT is calculated for the localized part of the signal. It produces

3.03.2 Linear Signal Transforms
29
t
x1(t)
Ω
|X1(Ω)|
t
x2(t)
Ω
|X2(Ω)|
(a)
(b)
(c)
(d)
FIGURE 3.1
Two different signals x1(t) ̸= x2(t) with the same amplitudes of their Fourier transforms, |X1()| = |X2()|.
t
τ
τ
x(t)
w(τ)
x(t+τ)w(τ)
t
FIGURE 3.2
Illustration of the signal localization in the STFT calculation.
the spectral content of the portion of the analyzed signal within the time interval deﬁned by the width
of the window function. The STFT (a time-frequency representation of the signal) is then obtained by
sliding the window along the signal. Illustration of the STFT calculation is presented in Figure 3.2.
Analytic formulation of the STFT is
STFT(t, ) =
 ∞
−∞
x(t + τ)w(τ)e−jτ dτ.
(3.4)
From (3.4) it is apparent that the STFT actually represents the FT of a signal x(t), truncated by the
window w(τ) centered at instant t (see Figure 3.2). From the deﬁnition, it is clear that the STFT satisﬁes
properties inherited from the FT (e.g., linearity).

30
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
By denoting xt(τ) = x(t + τ) we can conclude that the STFT is the FT of the signal xt(τ)w(τ),
STFT(t, ) = FTτ{xt(τ)w(τ)}.
Another form of the STFT, with the same time-frequency performance, is
STFTII(t, ) =
 ∞
−∞
x(τ)w∗(τ −t)e−jτ dτ,
(3.5)
where w∗(t) denotes the conjugated window function.
It is obvious that deﬁnitions (3.4) and (3.5) differ only in phase, i.e., STFTII(t, )=e−jtSTFT(t, )
for real valued windows w(τ). In the sequel we will mainly use the ﬁrst deﬁnition of the STFT [23].
Example 1.
To illustrate the STFT application, let us perform the time-frequency analysis of the
following signal:
x(t) = δ(t −t1) + δ(t −t2) + e j1t + e j2t.
(3.6)
The STFT of this signal equals
STFT(t, ) = w(t1 −t)e−j(t1−t) + w(t2 −t)e−j(t2−t)
+ W( −1)e j1t + W( −2)e j2t,
(3.7)
where W() is the FT of the used window. The STFT is depicted in Figure 3.3 for various window
lengths, along with the ideal representation.
The STFT can be expressed in terms of the signal’s FT
STFT(t, ) = 1
2π
 ∞
−∞
 ∞
−∞
X(θ)e j(t+τ)θw(τ)e−jτdθ dτ
= 1
2π
 ∞
−∞
X(θ)W( −θ)e jtθ dθ =
	
X()e jt
∗ W(),
(3.8)
where ∗ denotes convolution in . It may be interpreted as an inverse FT of the frequency localized
version of X(), with localization window W() = FT{w(τ)}.
3.03.2.1.1
Windows
It is obvious that the window function plays a critical role in the localization of the signal in the time-
frequency plane. Thus, we will brieﬂy review windows commonly used for localization of non-stationary
signals.
Rectangular window: The simplest window is the rectangular one, deﬁned by
w(τ) =
 1 for |τ| < T ,
0 elsewhere,
whose FT is
WR() =
 T
−T
e−jτ dτ = 2 sin(T )

.
The rectangular window function has very strong side lobes in the frequency domain, since the
function sin(T )/ converges very slowly as  →∞. Thus, in order to enhance signal localization
in the frequency domain, other window functions have been introduced.

3.03.2 Linear Signal Transforms
31
t1
t2
Ω1
Ω2
Ω
t
STFTwide (t, Ω )
t1
t2
Ω1
Ω2
Ω
t
STFTnarrow (t, Ω )
t1
t2
Ω 1
Ω 2
Ω
t
STFT optimal (t, Ω)
t1
t2
Ω1
Ω2
Ω
t
Ideal TFR (t, Ω)
(a)
(b)
(c)
(d)
FIGURE 3.3
Time-frequency representation of a sum of two delta pulses and two sinusoids obtained by using: (a) a wide
window, (b) a narrow window, (c) a medium width window, and (d) the ideal time-frequency representation.
Hann(ing) window: This window is of the form
w(τ) =
 1
2(1 + cos (τπ/T )) for |τ| < T ,
0
elsewhere.
Since cos (τπ/T ) = [exp ( jπτ/T ) + exp (−jτπ/T )]/2, the FT of this window is related to the FT
of the rectangular window of the same width as
WH() = 1
2 WR() + 1
4WR( −π/T ) + 1
4WR( + π/T ) =
π2 sin (T )
(π2 −2T 2).
Function WH() decays in frequency much faster than WR(). The previous relation also implies
the relationship between the STFTs of the signal x(t) calculated using the rectangular and Hann(ing)

32
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
windows, STFTR(t, ) and STFTH(t, ), given as
STFTH(t, ) = 1
2STFTR(t, ) + 1
4STFTR(t,  −π/T ) + 1
4STFTR(t,  + π/T ).
(3.9)
For the Hann(ing) window w(τ) of the width 2T , in the analysis that follows, we may roughly assume
that its FT WH(),is non-zero only within the main lattice || < 2π/T , since the side lobes decay very
fast. It means that the STFT is non-zero-valued in the shaded regions in Figure 3.3a–c. We see that
the duration in time of the STFT of a delta pulse is equal to the widow width dt = 2T . The STFTs of
two delta pulses δ(t −t1) and δ(t −t2) (very short duration signals) do not overlap in time-frequency
domain if their distance is greater than the window duration |t1−t2| > dt. Since the FT of the Hann(ing)
window converges fast, we can intuitively assume that a measure of duration in frequency is the width
of its main lobe, d = 4π/T . Then, we may say that two (complex) sine waves e j1t and e j2t do not
overlap in frequency if the condition |1 −2| > d holds. It is important to observe that the product
of the window durations in time and frequency is a constant. In this example, considering time domain
duration of the Hann(ing) window and the width of its main lobe in the frequency domain, this product
is dtd = 8π. Therefore, if we improve the resolution in the time domain dt, by decreasing T, we
inherently increase value of d in the frequency domain. This essentially prevents us from achieving
the ideal resolution in both domains. A general formulation of this principle, stating that product of
window durations in time and in frequency cannot be arbitrary small, will be presented later.
Hamming window: This window has the form
w(τ) =
0.54 + 0.46 cos (τπ/T ) for |τ| < T ,
0
elsewhere.
Similar relations between the Hamming and the rectangular window transforms hold as in the case of
Hann(ing) window. This window has lower ﬁrst side lobe than the Hann(ing) window. However, since
it has a discontinuity at t = ±T , its convergence as  →∞is not faster in frequency than in the case
of a Hann(ing) window.
Gaussian window: This window localizes signal in time, although it is not time-limited. Its form is
w(τ) = e−τ 2/α2.
In some applications it is crucial that the nearest side lobes are suppressed as much as possible. This
is achieved by using windows of more complicated forms, like the Blackman window and the Kaiser
window [6].
3.03.2.1.2
Duration measures and uncertainty principle
We started discussion about the signal concentration (window duration) and resolution in the Hann(ing)
window case, with illustration in Figure 3.3. In general, window (any signal) duration in time or/and in
frequency is not obvious from its deﬁnition or form. Then, the effective duration is used as a measure
of window (signal) duration. In time domain the effective duration measure is deﬁned by
σ 2
t =
 ∞
−∞τ 2|w(τ)|2dτ
 ∞
−∞|w(τ)|2dτ .

3.03.2 Linear Signal Transforms
33
Similarly, the measure of duration in frequency is
σ 2
 =
 ∞
−∞2|W()|2d
 ∞
−∞|W()|2d .
Here, it has been assumed that the time and frequency domain forms of the window (signal) are centered,
i.e.,
 ∞
−∞τ|w(τ)|2dτ = 0 and
 ∞
−∞|W()|2d = 0. If this were not the case, then the widths of
centered forms in time and frequency would be calculated.
The uncertainty principle in signal processing states that the product of effective measures of duration
in time and frequency, for any function satisfying w(τ)√τ →0 as τ →±∞, is
σ 2
t σ 2
 ≥1/4.
(3.10)
Since this principle will be used in the further analysis, we will present its short proof. Since
w′(τ) =
d
dτ w(τ) is the inverse FT of jW(), according to the Parseval’s theorem we have
 ∞
−∞
| jW()|2d/2π =
 ∞
−∞
|w′(τ)|2dτ
and the product σ 2
t σ 2
 may be written as
σ 2
t σ 2
 =
1
E2w
 ∞
−∞
τ 2|w(τ)|2dτ
 ∞
−∞
|w′(τ)|2dτ,
where Ew is the energy of the window (signal),
Ew =
 ∞
−∞
|w(τ)|2dτ = 1
2π
 ∞
−∞
|W()|2d.
For any two integrable functions x1(τ) and x2(τ), the Cauchy-Schwartz inequality

 ∞
−∞
x1(τ)x∗
2(τ)dτ

2
≤
 ∞
−∞
|x1(τ)|2dτ
 ∞
−∞
|x2(τ)|2dτ
holds. The equality holds for
x1(τ) = ±γ x∗
2(τ),
where γ is a positive constant.
In our case, the equality holds for
τw(τ) = ±γ w′(τ).
The ﬁnite energy solution of this differential equation, with w(0) = 1, is the Gaussian function
w(τ) = exp

−τ 2/2γ

.
For the Gaussian window (signal) it may be shown that this product is equal to σ 2
t σ 2
 = 1/4, meaning that
the Gaussian window (signal) is the best localized window (signal) in the sense of effective durations.
In the sense of illustration in Figure 3.3, this fact also means that, for a given width of the STFT of a
pulse δ(t) in time direction, the narrowest presentation of a sinusoid in frequency direction is achieved
by using the Gaussian window.

34
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
3.03.2.1.3
Continuous STFT inversion
The original signal x(t) may be easily reconstructed from its STFT (3.4) by applying the inverse FT, i.e.,
x(t + τ) =
1
2πw(τ)
 ∞
−∞
STFT(t, )e jτd.
(3.11)
In this way, we can calculate the values of x(t + τ) for a given instant t (τ = 0) and for the values
of τ where w(τ) is non-zero. Then, we may skip the window width, take the time instant t + 2T , and
calculate the inverse of STFT(t + 2T , ), and so on.
Theoretically, for a window of the width 2T , it is sufﬁcient to know the STFT calculated at t =
2kR, k = 0, ±1, ±2, . . . , with R ≤T , in order to reconstruct signal for any t (reconstruction conditions
will be discussed in details later, within the discrete forms).
A special case for τ = 0 gives
x(t) =
1
2πw(0)
 ∞
−∞
STFT(t, )d.
(3.12)
For the STFT deﬁned by (3.5) the signal can be obtained as
x(τ) =
1
2πw∗(τ −t)
 ∞
−∞
STFTI I(t, )e jτd.
In order to reconstruct the signal from its STFT, we may skip the window width at t and take as the time
instant t + 2T . If we calculate STFT(t, ) for all values of t (which is a common case in the analysis
of highly non-stationary signals), the inversion results in multiple values of signal for a given instant,
which all can be used for better signal reconstruction as follows:
x(τ) =
1
2πW ∗(0)
 ∞
−∞
 ∞
−∞
STFTI I(, t)e jτ d dt.
In the case that we are interested only in a part of the time-frequency plane, relation (3.12) can be
used for the time-varying signal ﬁltering. The STFT, for a given t, can be modiﬁed by B(t, ) and the
ﬁltered signal obtained as
y(t) =
1
2πw(0)
 ∞
−∞
B(t, )STFT(t, )d.
For example we can use B(t, ) = 1 within the time-frequency region of interest and B(t, ) = 0
elsewhere.
The energetic version of the STFT, called the spectrogram, is deﬁned by
SPEC(t, ) = |STFT(t, )|2
=

 ∞
−∞
x(τ)w∗(τ −t)e−jτdτ

2
=

 ∞
−∞
x(t + τ)w∗(τ)e−jτdτ

2
.
Obviously, the linearity property is lost in the spectrogram. The spectrograms of the signals from
Figure 3.1 are presented in Figure 3.4.

3.03.2 Linear Signal Transforms
35
0
0.5
1
1.5
2
2.5
3
0
50
100
150
200
250
Ω
SPEC1 (t,Ω)
t
0
0.5
1
1.5
2
2.5
3
0
50
100
150
200
250
Ω
SPEC2 (t,Ω)
t
(a)
(b)
FIGURE 3.4
The spectrograms of the signals presented in Figure 3.1.
3.03.2.1.4
STFT of multi-component signals
Let us introduce multi-component signal x(t) as the sum of M components xm(t),
x(t) =
M

m=1
xm(t) =
M

m=1
Am(t)e jφm(t).
(3.13)

36
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
The STFT of this signal is equal to the sum of the STFTs of individual components,
STFT(t, ) =
M

m=1
STFTm(t, )
(3.14)
that will be referred to as the auto-terms. This is one of very appealing properties of the STFT, which
will be lost in the quadratic and higher order distributions.
The spectrogram of multi-component signal (3.13) is of the form:
SPEC(t, ) = |STFT(t, )|2 =
M

m=1
|STFTm(t, )|2
only if the STFTs of signal components, STFTm(t, ), m = 1, 2, . . . , M, do not overlap in the time-
frequency plane, i.e., if
STFTm(t, )STFT∗
n(t, ) = 0 for all (t, ) if m ̸= n.
In general
SPEC(t, ) =
M

m=1
|STFTm(t, )|2 +
M

m=1
M

n=1
n̸=m
STFTm(t, )STFT∗
n(t, ),
where the second term on the right side represents the terms resulting from the interaction between two
signal components. They are called cross-terms. The cross-terms are undesirable components, arising
due to non-linear structure of the spectrogram. Here, they appear only at the time-frequency points
where the auto-terms overlap. We will see that in other quadratic time-frequency representations they
may appear even if the components do not overlap.
3.03.2.2 Discrete form and realizations of the STFT
In numerical calculations the integral form of the STFT should be discretized. By sampling the signal
with sampling interval t we get
STFT(t, ) =
 ∞
−∞
x(t + τ)w(τ)e−jτdτ
≃
∞

m=−∞
x((n + m)t)w(mt)e−jmtt.
By denoting
x(n) = x(nt)t
and normalizing the frequency  by t, ω = t, we get the time-discrete form of the STFT as
STFT(n, ω) =
∞

m=−∞
w(m)x(n + m)e−jmω.
(3.15)

3.03.2 Linear Signal Transforms
37
We will use the same notation for continuous-time and discrete-time signals, x(t) and x(n). However,
we hope that this will not cause any confusion since we will use different sets of variables, for example
t and τ for continuous time and n and m for discrete time. Also, we hope that the context will be always
clear, so that there is no doubt what kind of signal is considered.
It is important to note that STFT(n, ω) is periodic in frequency with period 2π. The relation between
the analog and the discrete-time form is
STFT(n, ω) =
∞

k=−∞
STFT(nt,  + 2k0) with ω = t.
The sampling interval t is related to the period in frequency as t = π/0. According to the sampling
theorem, in order to avoid the overlapping of the STFT periods (aliasing), we should take
t = π
0
≤π
m
,
where m is the maximal frequency in the STFT. Strictly speaking, the windowed signal x(t + τ)w(τ)
is time limited, thus it is not frequency limited. Theoretically, there is no maximal frequency since the
width of the window’s FT is inﬁnite. However, in practice we can always assume that the value of
spectral content of x(t + τ)w(τ) above frequency m, i.e., for || > m, can be neglected, and that
overlapping of the frequency content above m does not degrade the basic frequency period.
The discretization in frequency should be done by a number of samples greater than or equal to the
window length N. If we assume that the number of discrete frequency points is equal to the window
length, then
STFT(n, k) = STFT(n, ω)|ω= 2π
N k =
N/2−1

m=−N/2
w(m)x(n + m)e−j2πmk/N
(3.16)
and it can be efﬁciently calculated using the fast DFT routines
STFT(n, k) = DFTm{w(m)x(n + m)}
for a given instant n. When the DFT routines with indices from 0 to N −1 are used, then a shifted
version of w(m)x(n + m) should be formed for the calculation for N/2 ≤m ≤N −1. It is obtained as
w(m −N)x(n + m −N), since in the DFT calculation periodicity of the signal w(m)x(n + m), with
period N, is inherently assumed.
For the rectangular window, the STFT values at an instant n can be calculated recursively from the
STFT values at n −1, as
STFTR(n, k) = [x(n + N/2 −1) −x(n −N/2 −1)](−1)ke j2πk/N
+ STFTR(n −1, k)e j2πk/N.
This recursive formula follows easily from the STFT deﬁnition (3.16).
For other window forms, the STFT can be obtained from the STFT obtained by using the rectangular
window. For example, according to (3.9) the STFT with Hann(ing) window STFTH(n, k) isrelated to

38
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
+
STFTR(n,k)
STFTR(n,k−1)
STFTR(n,k+1)
a−1
a1
a0
STFTH(n,k)
STFTR(n,k)
+
+
z−N
z−1
−1
(−1)k
e j2kπ/N
x(n+N/2−1)
FIGURE 3.5
A recursive implementation of the STFT for the rectangular and other windows.
the STFT with rectangular window STFTR(n, k) as
STFTH(n, k) = 1
2STFTR(n, k) + 1
4STFTR(n, k −1) + 1
4STFTR(n, k + 1).
This recursive calculation is important for hardware implementation of the STFT and other related time-
frequency representations (e.g., the higher order representations implementations based on the STFT).
A system for the recursive implementation of the STFT is shown in Figure 3.5. The STFT obtained by
using the rectangular window is denoted by STFTR(n, k), Figure 3.5, while the values of coefﬁcients are
(a−1, a0, a1) =
1
4, 1
2, 1
4

,
(a−1, a0, a1) = (0.23, 0.54, 0.23),
(a−2, a−1, a0, a1, a2) = (0.04, 0.25, 0.42, 0.25, 0.04)
for the Hann(ing), Hamming and Blackman windows, respectively.
3.03.2.2.1
Filter bank STFT implementation
According to (3.4), the STFT can be written as a convolution
ST F(t, ) =
 ∞
−∞
x(t −τ)w(τ)e jτdτ = x(t) ∗t
	
w(t)e jt
,
where an even, real valued, window function is assumed, w(τ) = w(−τ). For a discrete set of frequen-
cies k = k = 2πk/(Nt), k = 0, 1, 2, . . . , N −1, and discrete values of signal, we get that the
discrete STFT, (3.16), is an output of the ﬁlter bank with impulse responses
hk(n) = w(n)e j2πkn/N,
k = 0, 1, . . . , N −1
what is illustrated in Figure 3.6.

3.03.2 Linear Signal Transforms
39
x(n)
w(n)
STFT(n, 
↓R
w(n) e j2πn/N
STFT(n,1)
↓R
w(n) e j2πn(N−1)/N
STFT(n, N−1)
↓R
. . .
0)
FIGURE 3.6
Filter bank realization of the STFT.
Illustrative example: In order to additionally explain this form of realization, as well as to introduce
various possibilities for splitting the whole time-frequency plane, let us assume that the total length of
discrete signal x(n) is M = K N, where N is the length of the window used for the STFT analysis.
If the signal was sampled by t, then the time-frequency region of interest in the analog domain is
t ∈[0, K Nt] and  ∈[0, m], with m = π/t, or ω ∈[0, π] and n ∈[0, K N] in the discrete
time domain. For the illustration we will assume M = 16.
The ﬁrst special case of the STFT is the signal itself (in discrete time domain). This case corresponds
to window w(n) = δ(n). Here, there is no information about the frequency content, since the STFT
of one sample x(n) is the sample itself, i.e., STFT(n, ω) = x(n), for the whole frequency range. The
whole considered time-frequency plane is divided as in Figure 3.7a.
Let us now consider a two samples rectangular window, w(n) = δ(n) + δ(n + 1), with N = 2. The
corresponding two samples STFT is
STFT(n, 0) = x(n) + x(n −1)
for k = 0 (corresponding to ω = 0) and
STFT(n, 1) = x(n) −x(n −1)
for k = 1 (corresponding to ω = π). Thus, the whole frequency interval is represented by the low
frequency value STFT(n, 0) and the high frequency value STFT(n, 1). From the signal reconstruction
point of view, we can skip one sample in the STFT calculation and calculate STFT(n + 2, 0) =
x(n+2)+x(n+1) and STFT(n+2, 1) = x(n+2)−x(n+1), and so on. It means that STFT(n, k) could
be down-sampled in discrete time n by a factor of 2. The signal reconstruction, in this case, is based on
x(n) =

STFT(n, 0) + STFT(n, 1)

/2,
x(n −1) =

STFT(n, 0) −STFT(n, 1)

/2,

40
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
n
ω
for 4 samples window
n
ω
(n,ω) plane
(n,ω) plane
for 2 samples window
n
ω
(n,ω) plane
for 1 sample window,
w(n) = δ(n), signal x(n)
n
ω
for 4 samples window
calculated for each n
n
ω
for 8 samples window
n
ω
for 16 samples window,
Fourier transfom
(a)
(b)
(c)
(d)
(e)
(f)
(n,ω) plane
(n,ω) plane
(n,ω) plane
FIGURE 3.7
Time-frequency plane for a signal x(n) having 16 samples: (a) The STFT of signal x(n) using one-sample
window. (Note that STFT(n, k) = x(n), for w(n) = δ(n).) (b) The STFT obtained by using a two-samples
window w(n), without overlapping. (c) The STFT obtained by using a four-samples window w(n), without
overlapping. (d) The STFT obtained by using an eight-samples window w(n), without overlapping. (e) The
STFT obtained by using a 16-samples window w(n), without overlapping. (Note that STFT(n, k) = X (k) for
w(n) = 1 for all n.) (f) The STFT obtained by using a four-samples window w(n), calculated for each n.
Overlapping is present in this case.
where STFT(n, k) is calculated for every other n (every even or every odd n). In the time-frequency
plane, the time resolution is now 2t corresponding to the two samples, and the whole frequency
interval is divided into two parts (low-pass and high-pass), Figure 3.7b. In this way, we can proceed and
divide the low-pass part of the STFT, i.e., signal xl(n) = x(n) + x(n −1), into two parts, its low-pass
and high-pass parts, according to STFTl(n, 0) = xl(n)+xl(n−1) and STFTl(n, 1) = xl(n)−xl(n−1).
The same can be done to the high pass part xh(n) = x(n)−x(n−1). In this way, we divide the frequency
range into four parts and the STFT can be down-sampled in time by 4 (time resolution corresponding
to the four sampling intervals), Figure 3.7b. This may be continued, until we split the frequency region
into KN intervals, and down-sample the STFT in time by a factor of M = K N, thus producing the
spectral content with high resolution, without any time-resolution (time resolution is equal to the whole
considered time interval), Figure 3.7c–e.
The second special case is the FT of the whole signal, X(k), k = 0, 1, 2, . . . , K N −1. Its contains
KN frequency points, but there is no time resolution, since it is calculated over the entire time interval,

3.03.2 Linear Signal Transforms
41
Figure 3.7e. Let us split the signal into two parts x1(n) for n = 0, 1, 2, . . . , M/2 −1 and x2(n) for
n = M/2, M/2 + 1, . . . , M −1 (“lower” time and “higher” time intervals). By calculating the FT of
x1(n) we get a half of the frequency samples within the whole frequency interval. In the time domain,
these samples correspond to the half of the original signal duration, i.e., to the lower time interval
n = 0, 1, 2, . . . , M/2 −1. The same holds for signal x2(n), Figure 3.7d. In this way, we may continue
and split the signal into four parts, Figure 3.7c, and so on.
3.03.2.2.2
Time and frequency varying windows
In general, we may split the original signal into K signals of duration N: x1(n) for n = 0, 1, 2, . . . , N −1,
x2(n)forn = N, N+1, . . . , 2N−1,andsoonuntil xK (n)forn = (K−1)N, (K−1)N+1, . . . , K N−1.
Obviously by each signal xi(n) we cover N samples in time, while corresponding STFT covering N
samples of the whole frequency interval. Thus the time-frequency interval is divided as in Figure 3.7.
Consider a discrete-time signal x(n) of the length N and its discrete Fourier transform (DFT) X(k).
The STFT, with a rectangular window of the width M, is:
STFT(n, k) =
M−1

m=0
x(n + m)e−j2πmk/M.
(3.17)
In a matrix form, it can be written as:
STFTM(n) = WMx(n),
(3.18)
where STFTM(n) and x(n) are vectors:
STFTM(n) = [STFT(n, 0), STFT(n, 1), . . . , STFT(n, M −1)]T ,
(3.19)
x(n) = [x(n), x(n + 1), . . . , x(n + M −1)]T ,
and WM is the M × M DFT matrix with coefﬁcients:
WM(m, k) = exp (−j2πkm/M).
Considering non-overlapping contiguous data segments, the next STFT will be calculated at instant
n + M, as follows:
STFTM(n + M) = WMx(n + M).
The last STFT at instant n + N −M, (assuming that N/M is an integer) is:
STFTN−M(n + N −M) = WMx(n + N −M).
Combining all STFT vectors in a single vector, we obtain:
⎡
⎢⎢⎢⎣
STFTM(0)
STFTM(M)
...
STFTM(N −M)
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
WM
0M
· · ·
0M
0M
WM
· · ·
0M
...
...
...
...
0M
0M
· · · WM
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
x(0)
x(M)
...
x(N −M)
⎤
⎥⎥⎥⎦,
(3.20)
where 0M is a M ×M zero matrix. The vector [x(0), x(M), . . . , x(N −M)]T is the signal vector x, since
x = [x(0), x(M), . . . , x(N −M)]T = [x(0), x(1), . . . , x(N −1)]T .
(3.21)

42
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
Time varying window
A similar relations can be obtained if the STFT with a varying window width (for each time instant
n) is considered. Assume that we use the window width M0 for the instant n = 0 and calculate
STFTM0(0) = WM0x(0).Then,weskip M0 signalsamples.Atn = M0,awindowof M1 widthisusedto
calculate STFTM1(M0) = WM1x(M0), and so on, until the last one STFTML(ML) = WMLx(N −ML)
is obtained. Assuming that M0 + M1 + · · · + ML = N, we can write:
⎡
⎢⎢⎢⎣
STFTM0(0)
STFTM1(M0)
...
STFTML(N −ML)
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
WM0
0
· · ·
0
0
WM1
· · ·
0
...
...
...
...
0
0
· · · WML
⎤
⎥⎥⎥⎦x.
(3.22)
As a special case of time-varying windows, consider a dual wavelet form (see Figure 3.8). It means that
for a “low time” we have the best time-resolution, without frequency resolution. This is achieved with
a one sample window. So for “low time,” at n = 0, the best time resolution is obtained with M0 = 1,
STFT1(0) = W1x(0) = x(0).
For an even number N, the same should be repeated for the next lowest time, n = 1, when:
STFT1(1) = W1x(1) = x(1).
time
frequency
Wavelet
time
frequency
STFT
time
frequency
Hybrid STFT
time
frequency
Dual Wavelet
time
frequency
T−VW STFT
time
frequency
F−VW STFT
(a)
(b)
(c)
(d)
(e)
(f)
FIGURE 3.8
Time and frequency lattice illustration for: (a) the STFT with a constant window, (b) the wavelet transform,
(c) a frequency-varying window (F-VW) STFT, (d) a time-varying window (T-VW) STFT, (e) the dual wavelet
transform, and (f) a hybrid STFT with time and frequency varying window.

3.03.2 Linear Signal Transforms
43
At the time instant n = 2, we now decrease time resolution and increase frequency resolution by factor
of 2. It is done by using a two samples window in the STFT, M2 = 2, so we have:
STFT2(2) = W2x(2) =
 1
1
1 −1
  x(2)
x(3)

.
The next instant, for the non-overlapping STFT calculation is n = 4, when we again increase the
frequency resolution and decrease time resolution by using window of the width M4 = 4, STFT4(4) =
W4x(4). Continuing in this way, until the end of signal, we get a resulting matrix,
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
STFT1(0)
STFT1(1)
STFT2(2)
STFT4(4)
...
STFTN/2(N/2)
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
1 0
0
0
· · ·
0
0 1
0
0
· · ·
0
0 0 W2
0
· · ·
0
0 0
0
W4
· · ·
0
...
...
...
...
...
...
0 0
0
0
· · · WN/2
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
x(0)
x(1)
x(2)
x(3)
...
x(N −1)
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
.
(3.23)
This matrix corresponds to the dual wavelet transform, since we used the wavelet transform reasoning,
but in thetime instead of frequency.
Frequency varying window
The STFT can be calculated by using the signal’s DFT instead of the signal. There is a direct relation
between the time and the frequency domain STFT via coefﬁcients of the form exp ( j2πnk/M). A dual
form of the STFT is:
STFT(n, k) = 1
M
M−1

m=0
X(k + i)e j2πin/M,
(3.24)
STFTM(k) = W−1
M X(k).
Frequency domain window may be of frequency varying width (Figure 3.8). This form is dual to the
time-varying form.
Hybrid time and frequency varying windows
In general, spectral content of signal changes in time and frequency in an arbitrary manner. There are sev-
eral methods intheliteraturethat adapt windows or basis functions tothesignal form for eachtimeinstant
or even for every considered time and frequency point in the time-frequency plane (e.g., as in Figure 3.8).
Selection of the most appropriate form of the basis functions (windows) for each time-frequency point
includes a criterion for selecting the optimal window width (basis function scale) for each point.
If we consider a signal with N samples, then its time-frequency plane can be split in a large number
of different grids for the non-overlapping STFT calculation. All possible variations of time-varying or
frequency-varying windows, are just special cases of general hybrid time-varying grid. Covering a time-
frequency N × N plane, by any combination of non-overlapping rectangular areas, whose individual
area is N, corresponds to a valid non-overlapping STFT calculation scheme. The total number of ways
F(N), how an N ×N plane can be split (into non-overlapping STFTs of area N with dyadic time-varying
windows) is:
N
1 4
6
8
12
14
16
F(N)
1 6 18 56 542 1690 5272
· · ·

44
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
The approximative formula for F(N) can be written in the form, [6]:
F(N) ≈

1.0366(1.7664)N−1
,
(3.25)
where ⌊·⌋stands for an integer part of the argument. It holds with relative error smaller than 0.4% for
1 ≤N ≤1024. For example, for N = 16 we have 5272 different ways to split time-frequency plane
into non-overlapping time-frequency regions with dyadic time-varying windows. Of course, most of
them cannot be considered within the either time-varying or frequency-varying window case, since they
are time-frequency varying (hybrid) in general.
3.03.2.2.3
Signal reconstruction form the discrete STFT
Signal reconstruction from non-overlapping STFT values is obvious, according to (3.20), (3.22),
or (3.23).
Signal can be reconstructed from the STFT calculated with N signal samples, if the calculated STFT
is overlapped, i.e., down-sampled in time by R ≤N. Here, the signal general reconstruction scheme
from the STFT values, overlapped in time, will be presented. Consider the STFT, (3.16), written in a
vector form, as
STFT(n, k) =
N/2−1

m=−N/2
w(m)x(n + m)e−j2πmk/N
= e j2πnk/N
N/2−1

m=−N/2
w(n −m)x(m)e−j2πmk/N,
STFT(n) = WNHwx(n)
(3.26)
where the vector STFT(n) contains all frequency values of the STFT, for a given n,
STFT(n) =

STFT (n, 0), STFT (n, 1), . . . , STFT (n, N −1)
T .
Signal vector is
x(n) = [x(n −N/2), x(n −N/2 + 1), . . . , x(n + N/2 −1)]T ,
while WN is the DFT matrix with coefﬁcients WN(n, k) = e−j2πmk/N. A diagonal matrix Hw is the
window matrix Hw(m, m) = w(m) and Hw(m, n) = 0 for m ̸= n.
It has been assumed that the STFTs are calculated with a step 1 ≤R ≤N in time. So they are
overlapped for R < N. Available STFT values are
. . .
STFT(n −2R),
STFT(n −R),
STFT(n),
STFT(n + R),
STFT(n + 2R),
. . .

3.03.2 Linear Signal Transforms
45
Based on the available STFT values (3.26), the windowed signal values can be reconstructed as
Hwx(n + iR) = W−1
N STFT(n + iR),
i = . . . −2, −1, 0, 1, 2, . . .
(3.27)
For m = −N/2, −N/2 + 1, . . . , N/2 −1 we get
w(m)x(n + iR + m) = 1
N
N/2−1

k=−N/2
STFT(n + iR, k)e j2πmk/N
(3.28)
Let us reindex the reconstructed signal value (3.28) by substitution m = l −iR
w(l −iR)x(n + 1) =
1
N
N/2−1

k=−N/2
STFT(n + iR, k)e j2πlk/Ne−j2π Rk/N
−N/2≤l −i R≤N/2 −1.
By summing over i satisfying −N/2 ≤l −iR ≤N/2 −1 we get that the reconstructed signal is
undistorted (up to a constant) if
c(l) =

i
w(l −i R) = const.
(3.29)
Special cases:
1.
For R = N (non-overlapping), relation (3.29) is satisﬁed for the rectangular window, only.
2.
Forahalfoftheoverlappingperiod, R = N/2,condition(3.29)ismetfortherectangular,Hann(ing),
Hamming, triangular,…, windows.
3. The same holds for R = N/2, N/4, N/8, if the values of R are integers.
4. For R = 1 (the STFT calculation in each available time instant), any window satisﬁes the inversion
relation.
In analysis of non-stationary signals our primary interest is not in signal reconstruction with the fewest
number of calculation points. Rather, we are interested in tracking signals’ non-stationary parameters,
likeforexample,instantaneousfrequency.Theseparametersmaysigniﬁcantlyvarybetweenneighboring
time instants n and n+1. Quasi-stationarity of signal within R samples (implicitly assumed when down-
sampling by factor of R is done) in this case is not a good starting point for the analysis. Here, we have
to use the time-frequency analysis of signal at each instant n, without any down-sampling. Very efﬁcient
realizations, for this case, are the recursive ones.
3.03.2.3 Gabor transform
The Gabor transform is the oldest time-frequency form applied in the signal processing ﬁeld (since
the Wigner distribution remained for a long time within the quantum mechanics, only). It has been
introduced with the aim to expand a signal x(t) into a series of time-frequency shifted elementary

46
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
functions w(t −nT )e jkt (logons)
x(t) =
∞

k=−∞
∞

n=−∞
a(n, k)w(t −nT )e jkt.
(3.30)
The Gabor’s original choice was the Gaussian window
w(τ) = exp

−π τ 2
2T 2

,
due to its best concentration in the time-frequency plane. Gabor also used  = 2π/T .
In the time frequency-domain, the elementary functions w(τ −nT )e jkτ are shifted in time and
frequency for nT and k, respectively.
For the analysis of signal, Gabor has divided the whole information (time-frequency) plane by
a grid at t = nT and  = k, with area of elementary cell T /2π = 1. Then, the signal is
expanded at the central points of the grid (nT , k) using the elementary atom functions exp (−π(t −
nT )2/(2T 2)) exp ( jkt).
If the elementary functions w(τ −nT )e jkτ were orthogonal to each other, i.e.,
 ∞
−∞
w(τ −nT )e jkτw∗(τ −mT )e−jlτdτ = δ(n −m)δ(k −l),
then by multiplying (3.30) by w∗(t −mT)e−jlt and integrating over t we could get
a(n, k) =
 ∞
−∞
x(τ)w∗(τ −nT )e−jkτdτ,
which corresponds to the STFT at t = nT . However, the elementary logons do not satisfy the orthogo-
nality property. Gabor originally proposed an iterative procedure for the calculation of a(n, k).
Interest in the Gabor transform, had been lost for decades, until a simpliﬁed procedure for the
calculation of coefﬁcients has been developed. This procedure is based on introducing elementary
signal γ (τ) dual to w(τ) such that
 ∞
−∞
w(τ −nT )e jkτγ ∗(τ −mT )e−jlτdτ = δ(n −m)δ(k −l)
holds (Bastiaans logons). Then
a(n, k) =
 ∞
−∞
x(τ)γ ∗(τ −nT )e−jkτdτ.
However, the dual function γ (τ) has a poor time-frequency localization. In addition, there is no stable
algorithm to reconstruct the signal with the critical sampling condition T = 2π. One solution is to
use an oversampled set of functions with T < 2π.
3.03.2.4 Stationary phase method
When the signal
x(t) = A(t)e jφ(t)

3.03.2 Linear Signal Transforms
47
is not of simple analytic form, it may be possible, in some cases, to obtain an approximative expression
for the FT by using the method of stationary phase [24,25].
The method of stationary phase states:
If the function φ(t) is monotonous and A(t) is sufﬁciently smooth function, then
 ∞
−∞
A(t)e jφ(t)e−jtdt ≃A(t0)e jφ(t0)e−jt0

2π j
φ′′(t0),
(3.31)
where t0 is the solution of
φ′(t0) = .
The most signiﬁcant contribution to the integral on the left side of (3.31) comes from the region
where the phase of the exponential function exp ( j(φ(t) −t)) is stationary in time, since the contri-
bution of the intervals with fast varying φ(t) −t tends to zero. In other words, in the considered time
region, the signal’s phase φ(t) behaves as t. Thus, we may say that the rate of the phase change, φ′(t),
for that particular instant is its instantaneous frequency corresponding to frequency . The stationary
point t0 of phase φ(t) −t, of signal A(t)e jφ(t)−jt, is obtained as a solution of
d(φ(t) −t))
dt

t=t0
= 0.
By expanding φ(t) −t into a Taylor series up to the second order term, around the stationary point
t0, we have
φ(t) −t ≃φ(t0) −t0 + 1
2
d2φ(t)
dt2

t=t0
(t −t0)2,
 ∞
−∞
A(t)e jφ(t)e−jtdt ≃
 ∞
−∞
A(t)e j(φ(t0)−t0+ 1
2 φ′′(t0)(t−t0)2)dt.
(3.32)
Using the FT pair
exp ( jαt2/2) ←→

2π j
α
exp

−j 2
2α

,
for a large α = φ′′(t0) it follows FT
√α/(2π j) exp ( jαt2/2)

→1, i.e.,
lim
α→∞
 α
2π j exp ( jαt2/2) = δ(t).
(3.33)
Relation (3.31) is now easily obtained from (3.32) with (3.33), for large φ′′(t0).
If the equation φ′(t0) =  has two (or more) solutions t+
0 and t−
0 then the integral on the left side of
(3.31) is equal to the sum of functions at both (or more) stationary phase points. Finally, this relation
holds for φ′′(t0) ̸= 0. If φ′′(t0) = 0 then similar analysis may be performed, using the lowest non-zero
phase derivative at the stationary phase point.
Example 2.
Consider a frequency modulated signal
x(t) = exp ( jat2N).

48
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
By using the stationary phase method we get that the stationary phase point is 2Nat2N−1
0
=  with
t0 =
 
2Na
 1/(2N−1) and φ′′(t0) = 2N(2N −1)a
 
2Na
 (2N−2)/(2N−1). The amplitude and phase of
X(), according to (3.31), are
|X()|2 ≃

2π
φ′′(t0)
 =

2π
(2N −1)
 
2aN
1/(2N−1) ,
arg{X()} ≃φ(t0) −t0 + π/4 = (1 −2N)
2N

 
2aN
1/(2N−1)
+ π/4
for a large value of a. The integrand in (3.31) is illustrated in Figure 3.9, for N = 1, when |X()|2 =
|π/a| and arg{X()} = −2/(4a) + π/4.
3.03.2.4.1
Instantaneous frequency
Here, we present a simple instantaneous frequency (IF) interpretation when signal may be considered as
stationary within the localization window (quasistationary signal). Consider a signal x(t) = A(t)e jφ(t),
within the window w(τ) of the width 2T . If we can assume that the amplitude variations are small and
the phase variations are almost linear within w(τ), i.e.,
A(t + τ) ≃A(t),
φ(t + τ) ≃φ(t) + φ′(t)τ,
−500
−400
−300
−200
−100
0
100
200
300
400
500
−1
0
1
−500
−400
−300
−200
−100
0
100
200
300
400
500
−1
0
1
−500
−400
−300
−200
−100
0
100
200
300
400
500
−1
0
1
t
Stationary
point
(a)
(b)
(c)
FIGURE 3.9
Stationary phase method illustration: (a) a real part of a frequency modulated signal, (b) a real part of the
demodulation signal, and (c) a real part of the stationary phase method integrand.

3.03.2 Linear Signal Transforms
49
then it holds
x(t + τ) ≃A(t)e jφ(t)e jφ′(t)τ.
Thus, around a given instant t, the signal behaves as a sinusoid in the τ domain with amplitude A(t),
phase φ(t), and frequency φ′(t). The ﬁrst derivative of phase, φ′(t), plays the role of frequency within
the considered lag interval around t.
The stationary phase method relates the spectral content at the frequency  with the signal’s value
at time instant t, such that φ′(t) = . A signal in time domain, that satisﬁes stationary phase method
conditions, contributes at the considered instant t to the FT at the corresponding frequency
(t) = φ′(t).
Additional comments on this relation are given within the stationary phase method presentation sub-
section.
The instantaneous frequency is not so clearly deﬁned as the frequency in the FT. For example,
the frequency in the FT has the physical interpretation as the number of signal periods within the
considered time interval, while this interpretation is not possible if a single time instant is considered.
Thus, a signiﬁcant caution has to be taken in using this notion. Various deﬁnitions and interpretations
of the IF are given in the literature, with the most comprehensive review presented by Boashash.
Example 3.
The STFT of the signal
x(t) = e jat2
can be approximately calculated for a large a, by using the method of stationary phase, as
STFT(t, ) =
 ∞
−∞
e ja(t+τ)2w(τ)e−jτdτ ≃e jat2e j(2at−)τ0e jaτ 2
0 w(τ0)

2π j
2a
= e jat2e−j(2at−)2/4aw
 −2at
2a
 
π j
a ,
where the stationary point τ0 is obtained from
2a(t + τ0) = .
Note that the absolute value of the STFT reduces to
|STFT(t, )| ≃
w
 −2at
2a

π
a .
(3.34)
In this case, the width of |STFT(t, )| in frequency does not decrease with the increase of the window
w(τ) width. The width of |STFT(, t)| around the central frequency  = 2at is
D = 4aT ,
where 2T is the window width in time domain. Note that this relation holds for a wide window w(τ)
such that the stationary phase method may be applied. If the window is narrow with respect to the phase
variations of the signal, the STFT width is deﬁned by the width of the FT of window, being proportional
to 1/T . Thus, the overall STFT width is equal to the sum of the frequency variation caused width and
the window’s FT width, i.e.,
Do = 4aT + 2c/T ,

50
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
where c is a constant deﬁned by the window shape. Therefore, there is a window width T producing the
narrowest possible STFT for this signal. It is obtained by equating the derivative of the overall width to
zero, 2a −c/T 2 = 0, which results in
To =
!
c/(2a).
As expected, for a sinusoid, a →0, To →∞.
Consider now the general form of FM signal
x(t) = Ae jφ(t),
where φ(t) is a differentiable function. Its STFT is of the form
STFT(t, ) =
 ∞
−∞
Ae jφ(t+τ)w(τ)e−jτdτ
=
 ∞
−∞
Ae j

φ(t)+φ′(t)τ)+φ′′(t)τ 2/2+···

w(τ)e−jτdτ
= Ae jφ(t)FT
"
e jφ′(t)τ#
∗ FT{w(τ)} ∗ FT
$ ∞

k=2
e jφ(k)(t)τ k/k!
%
,
where φ(t + τ) is expanded into the Taylor series around t as
φ(t + τ) = φ(t) + φ′(t)τ + φ′′(t)τ 2/2 + · · · + φ(k)(t)τ k/k! + · · ·
Neglecting the higher order terms in the Taylor series we can write
STFT(t, ) = Ae jφ(t)FT
"
e jφ′(t)τ#
∗ FT{w(τ)} ∗ FT
"
e jφ′′(t)τ 2/2#
= 2π Ae jφ(t)δ( −φ′(t)) ∗ W() ∗ e−j2/(2φ′′(t))

2π j
φ′′(t),
where ∗ denotes the convolution in frequency. As expected, the inﬂuence of the window is manifested
as a spread of ideal concentration δ(−φ′(t)). In addition, the term due to the frequency non-stationarity
φ′′(t) causes an additional spread. This relation conﬁrms our previous conclusion that the overall STFT
width is the sum of the width of W() and the width caused by the signal’s non-stationarity.
3.03.2.5 Local polynomial Fourier transform
There are signals whose form is known up to an unknown set of parameters. For example, many signals
could be expressed as polynomial-phase signal
x(t) = Ae j(0t+a1t2+a2t3+··· )
with (unknown) parameters 0, a1, a2, . . . High concentration of such signals in the frequency domain
is achieved by the polynomial FT deﬁned by
PFT1,2,...(t, ) =
 ∞
−∞
x(t)e−j(t+1t2+2t3+··· )dt

3.03.2 Linear Signal Transforms
51
when parameters 1, 2, . . . are equal to the signal parameters a1, a2, . . . Finding values of unknown
parameters 1, 2, . . . that match signal parameters can be done by a simple search over a possible
set of values for 1, 2, . . . and stopping the search when the maximally concentrated distribution is
achieved (in ideal case, the delta function at  = 0, for 1 = a1, 2 = a2, . . . is obtained). This
procedure may be time consuming.
For non-stationary signals, this approach may be used if the non-stationary signal could be considered
asasignalwithconstantparameterswithintheanalysiswindow.Inthatcase,thelocalpolynomialFourier
transform (LPFT), proposed by Katkovnik, may be used [26]. It is deﬁned as
LPFT1,2,...(t, ) =
 ∞
−∞
x(t + τ)w(τ)e−j(τ+1τ 2+2τ 3+··· )dτ.
Example 4.
Consider the second order polynomial-phase signal
x(t) = e j(0t+a1t2).
Its LPFT has the form
LPFT1(t, ) =
 ∞
−∞
x(t + τ)w(τ)e−j(τ+1τ 2)dτ.
= e j(0t+1t2)
 ∞
−∞
w(τ)e−j(−0−2a1t)τe j(1−a1)τ 2dτ.
For 1 = a1, the second-order phase term does not introduce any distortion to the local polynomial
spectrogram,
|LPFT1=a1(t, )|2 = |W( −0 −2a1t)|2
with respect to the spectrogram of a sinusoid with constant frequency. For a wide window w(τ), like in
the case of the STFT of a pure sinusoid, we achieve high concentration.
The LPFT could be considered as the FT of signal demodulated with e−j(1τ 2+2τ 3+··· ). Thus, if
we are interested in signal ﬁltering, we can ﬁnd the coefﬁcients 1, 2, . . ., demodulate the signal by
multiplying it with e−j(1τ 2+2τ 3+··· ) and use a standard ﬁlter for a pure sinusoid.
In general, we can extend this approach to any signal x(t) = e jφ(t) by estimating its phase φ(t) with
ˆφ(t) (using the instantaneous frequency estimation that will be discussed later) and ﬁltering demodulated
signal x(t)e−j ˆφ(t) by a low-pass ﬁlter. The resulting signal is obtained when the ﬁltered signal is returned
back to the original frequencies, by modulation with e j ˆφ(t).
The ﬁltering of signal can be modeled by the following expression:
x f (t) = 1
2π
 +∞
−∞
Bt(t, )LPFT(t, )d,
(3.35)
where LPFT(t, ) is the LPFT of x(t), x f (t) is the ﬁltered signal, Bt(t, ) is a support function used
for ﬁltering. It could be 1 within the time-frequency region where we assume that the signal of interest
exists, and 0 elsewhere.

52
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
Note that the sufﬁcient order of the LPFT can be obtained recursively. We start from the STFT and
check whether its auto-term’s width is equal to the width of the FT of the used window. If true, it means
that a signal is a pure sinusoid and the STFT provides its best possible concentration. We should not
calculate the LPFT. If the auto-term is wider, it means that there are signal non-stationarities within the
window and the ﬁrst-order LPFT should be calculated. The auto-term’s width is again compared to the
width of the window’s FT and if they do not coincide we should increase the LPFT order.
In case of multi-component signals, the distribution will be optimized to the strongest component
ﬁrst. Then, the strongest component is ﬁltered out and the procedure is repeated for the next component
in the same manner, until the energy of the remaining signal is negligible, i.e., until all the components
are processed.
3.03.2.6 Relation between the STFT and the continuous wavelet transform
The ﬁrst form of functions having the basic property of wavelets was used by Haar at the beginning of
the 20th century. At the beginning of 1980s, Morlet introduced a form of basis functions for analysis
of seismic signals, naming them “wavelets.” Theory of wavelets was linked to the image processing by
Mallat in the following years. In late 1980s Daubechies presented a whole new class of wavelets that,
in addition to the orthogonality property, can be implemented in a simple way, by using digital ﬁltering
ideas. The most important applications of the wavelets are found in image processing and compression,
pattern recognition and signal denoising. As such they will be a separate topic of this book. Here, we
will only link continuous wavelet transform to the time-frequency analysis [5,27,28].
The STFT is characterized by constant time and frequency resolutions for both low and high fre-
quencies. The basic idea behind the wavelet transform is to vary the resolutions with scale (being related
to frequency), so that a high frequency resolution is obtained for low frequencies, whereas a high time
resolution is obtained for high frequencies, which could be relevant for some practical applications. It
is achieved by introducing a variable window width, such that it is decreased for higher frequencies.
The basic idea of the wavelet transform and its comparison with the STFT is illustrated in Figure 3.10.
Time and frequency resolution is schematically illustrated in Figure 3.8.
When the above idea is translated into the mathematical form, one gets the deﬁnition of a continuous
wavelet transform
WT(t, a) =
1
√|a|
 ∞
−∞
x(τ)h∗
τ −t
a

dτ,
(3.36)
where h(t) is a band-pass signal, and the parameter a is the scale. This transform produces a time-
scale, rather than the time-frequency signal representation. For the Morlet wavelet (that will be used for
illustrations in this short presentation) the relation between the scale and the frequency is a = 0/.
In order to establish a strong formal relationship between the WT and the STFT, we will choose the
basic wavelet h(t) in the form
h(t) = w(t)e j0t,
(3.37)
where w(t) is a window function and 0 is a constant frequency. For example, for the Morlet wavelet
we have a modulated Gaussian function
h(t) =

1
2π e−αt2e j0t,

3.03.2 Linear Signal Transforms
53
t
a
Wavelet expansion functions
t
a 1
t
a= 1/2
t
STFT expansion functions
Ω= Ω0/2
t
Ω = Ω0
t
Ω = Ω0
(a)
(b)
(c)
(d)
(e)
(f)
=
2
2
=
FIGURE 3.10
Expansion functions for the wavelet transform (left) and the short-time Fourier transform (right). Top row
presents high scale (low frequency), middle row is for a medium scale (medium frequency) and bottom row
is for a low scale (high frequency).
where the values of α and 0 are chosen such that the ratio of h(0) and the ﬁrst maximum is 1/2,
0 = 2π√α/ ln 2. From the deﬁnition of h(t) it is obvious that small  (i.e., large a) corresponds to a
wide wavelet, i.e., a wide window, and vice versa.
Substitution of (3.37) into (3.36) leads to a continuous wavelet transform form suitable for a direct
comparison with the STFT:
WT(t, a) =
1
√|a|
 ∞
−∞
x(τ)w∗
τ −t
a

e−j0 τ−t
a dτ.
(3.38)
From the ﬁlter theory point of view the wavelet transform, for a given scale a, could be considered
as the output of system with impulse response h∗(−t/a)√|a|, i.e., WT(t, a) = x(t) ∗t h∗(−t/a)√|a|,
where ∗t denotes a convolution in time. Similarly the STFT, for a given , may be considered as
STFTI I(t, ) = x(t) ∗t [w∗(−t)e jt]. If we consider these two band-pass ﬁlters from the bandwidth
point of view we can see that, in the case of STFT, the ﬁltering is done by a system whose impulse
response w∗(−t)e jt has a constant bandwidth, being equal to the width of the FT of w(t).
The S-transform (or the Stockwell transform) is conceptually a hybrid of short-time Fourier analysis
and wavelet analysis. It employs a variable window length but preserves the phase information by using

54
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
the STFT form in the signal decomposition. As a result, the phase spectrum is absolute in the sense
that it is always referred to a ﬁxed time reference. The real and imaginary spectrum can be localized
independently with resolution in time in terms of basis functions. The changes in the absolute phase
of a certain frequency can be tracked along the time axis and useful information can be extracted.
In contrast to wavelet transform, the phase information provided by the S-transform is referenced to
the time origin, and therefore provides supplementary information about spectra which is not available
from locally referenced phase information obtained by the continuous wavelet transform. The frequency
dependent window function produces higher frequency resolution at lower frequencies, while at higher
frequencies sharper time localization can be achieved.
Constant Q-factor transform
The quality factor Q for a band-pass ﬁlter, as measure of the ﬁlter selectivity, is deﬁned as
Q = Central Frequency
Bandwidth
.
In the STFT the bandwidth is constant, equal to the window FT width, Bw. Thus, factor Q is proportional
to the considered frequency,
Q = 
Bw
.
In the case of the wavelet transform the bandwidth of impulse response is the width of the FT of w(t/a).
It is equal to B0/a, where B0 is the constant bandwidth corresponding to the mother wavelet. It follows
Q =

B0/a = 0
B0
= const.
Therefore, the continuous wavelet transform corresponds to the passing a signal through a series of
band-pass ﬁlters centered at , with constant factor Q. Again we can conclude that the ﬁltering, that
produces WT, results in a small bandwidth (high frequency resolution and low time resolution) at low
frequencies and wide bandwidth (low frequency and high time resolution) at high frequencies.
Afﬁne transforms
A whole class of signal representations, including the quadratic ones, is deﬁned with the aim to preserve
the constant Q property. They belong to the area of the so called time-scale signal analysis or afﬁne time-
frequency representations [5,14,28–31]. The basic property of an afﬁne time-frequency representation
is that the representation of time shifted and scaled version of signal
y(t) =
1
√γ x
t −t0
γ

,
whose FT is Y() = √γ X(γ )e−jt0, results in a time-frequency representation
TFRy(t, ) = TFRx
t −t0
γ
, γ 

.
The name afﬁne comes from the afﬁne transformation of time, that is, in general a transformation of
the form t →αt + β. It is easy to verify that continuous wavelet transform satisﬁes this property.

3.03.2 Linear Signal Transforms
55
t1
t2
Ω1
Ω2
Ω
t
WT(t,Ω)
t1
t2
Ω1
Ω2
Ω
t
STFT(t,Ω)
(a)
(b)
FIGURE 3.11
Illustration of the wavelet transform (a) of a sum of two delta pulses and two sinusiods compared with STFT
in (b).
Example 5.
Consider signal (3.6). Its continuous wavelet transform is
WT(t, a) =
1
√|a|
	
w((t1 −t)/a)e−j0(t1−t)/a + w((t2 −t)/a)e−j0(t2−t)/a
+√a
	
e j1tW[a(0/a −1)] + e j2tW[a(0/a −2)]

.
(3.39)
The transform (3.39) has non-zero values in the region depicted in Figure 3.11a.
Scalogram:
In analogy with spectrogram, the scalogram is deﬁned as the squared magnitude of a wavelet transform:
SCAL(t, a) = |WT(t, a)|2.
(3.40)
The scalogram obviously loses the linearity property, and ﬁts into the category of quadratic transforms.
A Simple ﬁlter bank formulation
Time-frequency grid for wavelet transform is presented in Figure 3.8. Within the ﬁlter bank framework
in means that the original signal is processed in the following way. The signal’s spectral content is
divided into high frequency and low frequency part. An example, how to achieve this is presented in
the STFT analysis by using a two samples rectangular window w(n) = δ(n) + δ(n + 1), with N = 2.
Then, its two samples WT is xL(n, 0) = x(n) + x(n −1), for k = 0, corresponding to low frequency
ω = 0 and xH(n, 1) = x(n) −x(n −1) for k = 1 corresponding to high frequency ω = π. The high
frequency part, xH(n, 1), having high resolution in time, is not processed any more. It is kept with this
high resolution in time, expecting that this kind of resolution will be needed for a signal. The low pass
part xL(n, 0) = x(n) + x(n −1) is further processed, by dividing it into its low frequency part,
xLL(n, 0, 0) = xL(n, 0) + xL(n −2, 0)
= x(n) + x(n −1) + x(n −2) + x(n −3)

56
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
and its high frequency part
xL H(n, 0, 1) = xL(n, 0) −xL(n −2, 0)
= x(n) + x(n −1) −[x(n −2) + x(n −3)].
The high pass of this part is left with resolution four in time, while the low pass part is further processed,
by dividing it into its low and high frequency part, until the full length of signal is achieved, Figure 3.8b.
Chirplet transform
An extension of the wavelet transform, for time-frequency analysis, is the chirplet transform. By using
linear frequency modulated forms instead of the constant frequency ones, the chirplet is formed. Here
we will present a Gaussian chirplet atom that is a four parameter function
ϕ(τ; [t, , 1, σ]) =
1
!√πσ
exp

−1
2
τ −t
σ
2
+ j(1(τ −t)2 + j(τ −t)

,
where the parameter σ controls the width of the chirplet in time, parameter 1 stands for the chirplet
rate in time-frequency plane, while t and  are the coordinates of the central time and frequency point
in the time-frequency plane. In this way, for a given parameters [t, , 1, σ] we project signal onto a
Gaussian chirp, centered at t,  whose width is deﬁned by σ and rate is 1:
c(t, , 1, σ) =
 ∞
−∞
x(τ)ϕ∗(τ; [t, , 1, σ])dτ.
In general, projection procedure should be performed for each point in time-frequency plane, for all
possible parameter values. Interest in using a Gaussian chirplet atom stems from to the fact that it
provides the highest joint time-frequency concentration. In practice, all four parameters should be
discretized. The set of the parameter discretized atoms are called a dictionary. In contrast to the second
order local polynomial FT, here the window width is parametrized and varies, as well. Since we have a
multiparameter problem, computational requirements for this transform are very high.
In order to improve efﬁciency of the chirplet transform calculation, various adaptive forms of the
chirplet transform were proposed. The matching pursuit procedure is a typical example. The ﬁrst step of
this procedure is to choose a chirplet atom from the dictionary yielding the largest amplitude of the inner
product between the atom and the signal. Then the residual signal, obtained after extracting the ﬁrst atom,
is decomposed in the same way. Consequently, the signal is decomposed into a sum of chirplet atoms.
3.03.2.7 Generalization
In general, any set of well localized functions in time and frequency can be used for the time-frequency
analysis of a signal. Let us denote signal as x(τ) and the set of such functions with ϕ(τ; [Parameters]),
then the projection of the signal x(τ) onto such functions,
c([Parameters]) =
 ∞
−∞
x(τ)ϕ∗(τ; [Parameters])dτ
represents similarity between x(t) and ϕ(t; [Parameters]), at a given point with parameter values deﬁned
by [Parameters].
We may have the following cases:

3.03.2 Linear Signal Transforms
57
•
Frequency as the only one parameter. Then, we have projection onto complex harmonics with
changing frequency, and c([]) is the FT of signal x(τ) with
ϕ(τ; []) = e jτ.
•
Time and frequency as parameters. Varying t and  and calculating projections of signal x(τ) we
get the STFT. In this case we use w(τ −t) as a localization function around parameter t and
ϕ(τ; [t, ]) = w(τ −t)e jτ.
•
Time and frequency as parameters with a frequency dependent localization in time, we get wavelet
transform. It is more often expressed as function of scale parameter a = 0/, than the frequency
. The S-transform belongs to this class. For the continuous wavelet transform with mother wavelet
w(τ)e j0τ we have
ϕ(τ; [t, a]) = w((τ −t)/a)e j0(τ−t)/a.
•
Frequency and signal phase rate. We get the polynomial FT of the second order, with
ϕ(τ; [, 1]) = e j(τ+1τ 2).
•
Time, frequency, and signal phase rate as parameters results in a form of the local polynomial Fourier
transform with
ϕ(τ; [t, , 1]) = w(τ −t)e j(τ+1τ 2).
•
Time, frequency, and signal phase rate as parameters, with a varying time localization, as parameters
results in the chirplets with localization function with
ϕ(τ; [t, , 1, σ]) = w((τ −t)/σ) exp ( j(1(τ −t)2 + j(τ −t)).
•
Frequency, signal phase rate, and other higher order coefﬁcients, we get the polynomial FT of the
Nth order, with
ϕ(τ; [, 1, 2, . . . , N]) = e j(τ+1τ 2+2τ 3+···+N τ N ).
•
Time, frequency, signal phase rate, and other higher order coefﬁcients, we get the local polynomial
FT of the Nth order, with
ϕ(τ; [t, , 1, 2, . . . , N]) = w(τ −t)e j(τ+1τ 2+2τ 3+···+N τ N ).
•
Time, frequency, signal phase rate, and other higher order coefﬁcients, with a variable window width
we would get the Nth order-lets, with
ϕ(τ; [t, , 1, 2, . . . , N, σ]) = w((τ −t)/σ)e j(τ+1τ 2+2τ 3+···+N τ N ).
•
Time, frequency, and any other parametrized phase function form, like sinusoidal ones, with constant
or variable window width. . .

58
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
3.03.3 Quadratic time-frequency distributions
In order to provide additional insight into the ﬁeld of joint time-frequency analysis, as well as to improve
concentrationoftime-frequencyrepresentation,energydistributionsofsignalswereintroduced.Wehave
already mentioned the spectrogram which belongs to this class of representations and is a straightforward
extension of the STFT. Here, we will discuss other distributions and their generalizations.
Thebasicsconditionforthedeﬁnitionoftime-frequencyenergydistributionsisthatatwo-dimensional
function of time and frequency P(t, ) represents the energy density of a signal in the time-frequency
plane. Thus, the signal energy associated with the small time and frequency intervals t and ,
respectively, would be
Signal energy within [ + , t + t] = P(t, )t.
However, point by point deﬁnition of time-frequency energy densities in the time-frequency plane is not
possible, since the uncertainty principle prevents us from deﬁning concept of energy at a speciﬁc instant
and frequency. This is the reason why some more general conditions are being considered to derive
time-frequency distributions of a signal. Namely, one requires that the integral of P(t, ) over , for
a particular instant of time should be equal to the instantaneous power of the signal |x(t)|2, while the
integralovertimeforaparticularfrequencyshouldbeequaltothespectralenergydensity|X()|2.These
conditions are known as marginal conditions or marginal properties of time-frequency distributions.
Therefore, it is desirable that an energetic time-frequency distribution of a signal x(t) satisﬁes:
– Energy property
1
2π
 ∞
−∞
 ∞
−∞
P(t, )d dt = Ex,
(3.41)
– Time marginal properties
1
2π
 ∞
−∞
P(t, )d = |x(t)|2, and
(3.42)
– Frequency marginal property
 ∞
−∞
P(t, )dt = |X()|2,
(3.43)
where Ex denotes the energy of x(t). It is obvious that if either one of marginal properties (3.42), (3.43) is
fulﬁlled, so is the energy property. Note that relations (3.41)–(3.43), do not reveal any information about
the local distribution of energy at a point (t, ). The marginal properties are illustrated in Figure 3.12.
Next we will introduce some distributions satisfying these properties.
3.03.3.1 Rihaczek distribution
The Rihaczek distribution satisﬁes the marginal properties (3.41)–(3.43). This distribution is of limited
practical importance (some recent contributions show that it could be interesting in the phase synchrony
and stochastic signal analysis). We will present one of its derivations with a simple electrical engineering
foundation.

3.03.3 Quadratic Time-Frequency Distributions
59
|x(t)|2
|X(Ω)|2
t
Ω
t
Ω
P(t,Ω)
Integration over Ω
Integration over t
FIGURE 3.12
Illustration of the marginal properties as distribution projections.
Consider a simple electrical circuit analysis. Assume that a voltage v(t) is applied at the resistor
whose resistance is R = 1[], but only within a very narrow frequency band [,  + )
R(θ) =
1
for  ≤θ <  + ,
∞elsewhere.
In that case, the energy dissipated at the resistor within a short time interval (t, t + t) is deﬁned as:
E(t, ) =
 t+t
t
v(τ)i∗(τ)dτ,
(3.44)
where i(t) denotes the resulting current. It may be expressed in terms of the FT of the voltage:
i(τ) = 1
2π
 ∞
−∞
I(θ)e jθτ dθ = 1
2π
 +

V (θ)e jθt dθ,
(3.45)
where capital letters represent corresponding FTs of the current and voltage. Substitution of (3.45) into
(3.44) produces
E(t, ) = 1
2π
 t+t
t
 +

v(τ)V ∗(θ)e−jθτ dθ dτ.
(3.46)
Based on the above considerations, one may deﬁne a time-frequency energy distribution:
P(t, ) = 2π lim
→0
t→0
E(t, )
t = v(t)V ∗()e−jt.
(3.47)
The previous analysis may be generalized for an arbitrary signal x(t) with the associated FT X(). The
Rihaczek distribution is obtained in the following form:
RD(t, ) = x(t)X∗()e−jt
=
 ∞
−∞
x(t)x∗(t −τ)e−jτdτ = 1
2π
 ∞
−∞
X( + θ)X∗()e jθtdθ.
(3.48)

60
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
It seems that the Rihaczek distribution is an ideal one, we have been looking for. However, energy is
calculated over the intervals (t, t + t) and (,  + ), while V () was calculated over the entire
interval (−∞, ∞). This introduces the inﬂuence of other time periods onto the interval (t, t + t).
Therefore, it is not as local as it may seem from the derivation. This distribution exhibits signiﬁcant
drawbacks for possible time-frequency analysis, as well. The most important one is that it is complex
valued, despite the fact that it has been derived with the aim to represent signal energy density. In
addition, its time-frequency concentration for non-stationary signals is quite low.
3.03.3.2 Wigner distribution
The other quadratic distributions cannot be easily derived as the Rihaczek distribution. Partially this is
due to the lack of adequate simple physical interpretations. In order to derive some other quadratic time-
frequency distributions, observe that the Rihaczek distribution may be interpreted as the FT (over τ) of
the function
R(t, τ) = x(t)x∗(t −τ),
that will be referred to as the local autocorrelation function,
RD(t, ) =
 ∞
−∞
R(t, τ)e−jτ dτ.
(3.49)
This relation is in accordance with spectral density function for random signals. A general form of the
local autocorrelation function may be written as
R(t, τ) = x(t + (α + 1/2)τ)x∗(t + (α −1/2)τ),
(3.50)
where α is an arbitrary constant (α = −1/2 produces the RD; note that also α = 1/2 could be used as
a variant of the RD). For α = 0, the local autocorrelation function Rt(τ) is Hermitian, i.e.,
R(t, τ) = R∗(t, −τ),
(3.51)
and its FT is real valued. The distribution that satisﬁes this property is called the Wigner distribution
(or the Wigner-Ville distribution). It is deﬁned as
WD(t, ) =
 ∞
−∞
x(t + τ/2)x∗(t −τ/2)e−jτ dτ.
(3.52)
The Wigner distribution is originally introduced in quantum mechanics.
Expressing x(t) in terms of X() and substituting it into (3.52) we get
WD(t, ) = 1
2π
 ∞
−∞
X( + θ/2)X∗( −θ/2)e jθt dθ
(3.53)
what represents a deﬁnition of the Wigner distribution in the frequency domain.
A distribution deﬁned as the FT of (3.50) is called the Generalized Wigner Distribution (GWD). The
name stems from the fact that this distribution is based on the Wigner distribution (for α = 0), which
is the most important member of this class of distributions.

3.03.3 Quadratic Time-Frequency Distributions
61
It is easy to show that the Wigner distribution and all the other distributions from the GWD class
satisfy the marginal properties. From the Wigner distribution deﬁnition, it follows
x(t + τ/2)x∗(t −τ/2) = IFT{WD(t, )} = 1
2π
 ∞
−∞
WD(t, )e jτ d
(3.54)
which, for τ = 0, produces (3.42)
|x(t)|2 = 1
2π
 ∞
−∞
WD(t, )d.
(3.55)
Based on the deﬁnition of the Wigner distribution in the frequency domain, (3.53), one may easily
prove the fulﬁllment of the frequency marginal. The marginal properties are satisﬁed for the whole
class of GWD.
Example 6.
The Wigner distribution of signals x1(t) = δ(t −t1) and x2(t) = e j1t is given by
WD1(, t) = δ(t −t1)
and
WD2(, t) = 2πδ( −1),
respectively. The distribution concentration is very high, in both cases. Note that this fact does not mean
that, for one signal component, we will be able to achieve an arbitrary high concentration simultaneously
in both time and in frequency.
Example 7.
Let us now assume a linear frequency modulated signal, x(t) = Ae jat2/2. In this case
we have
x(t + τ/2)x∗(t −τ/2) = A2e jtτa
with
WD(, t) = 2π A2δ( −at).
Again, a high concentration in the time-frequency plane is achieved.
These two examples demonstrated that the Wigner distribution can provide superior time-frequency
representations in comparison to the STFT.
3.03.3.2.1
Distribution concentrated at the instantaneous frequency
For a general mono-component signal of the form x(t) = A(t) exp ( jφ(t)), with slow varying amplitude
comparing to the signal phase variations |A(t)|′ ≪|φ′(t)|, an ideal time-frequency (ITF) representation
(fully concentrated along the instantaneous frequency) can be deﬁned as:
ITF(t, ) = 2π|A(t)|2δ( −φ′(t)).
(3.56)
Note that the ideal TFD deﬁned by (3.56) satisﬁes the marginal properties for a wide class of frequency
modulated signals. The time marginal is satisﬁed since:
1
2π
 ∞
−∞
ITF(t, )d = |A(t)|2,

62
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
where a monotonous function φ′(t) is assumed, with t0 being the solution of  −φ′(t0) = 0. Since
the time marginal condition is satisﬁed, so is the energy condition. For signals satisfying the stationary
phase method, the frequency marginal is satisﬁed, as well. From a similar analysis in the frequency
domain one may deﬁne a distribution fully concentrated along the group delay, as well.
For a frequency modulated signal x(t) = A exp ( jφ(t) the Wigner distribution (3.52) assumes the
form:
WD(t, ) = A2
 ∞
−∞
e j[φ(t+τ/2)−φ(t−τ/2)] e−jτ dτ
= A2
 ∞
−∞
e j[φ(t+τ/2)−φ(t−τ/2)]−jφ′(t)τ e jφ′(t)τ e−jτ dτ.
Factor A2  ∞
−∞e jφ′(t)τe−jτdτ produces the ideal distribution concentration 2π A2δ(−φ′(t)), while
the term
Q =
	
φ

t + τ
2

−φ

t −τ
2

−φ′(t)τ = 1
24φ(3)(t)τ 3 + · · ·
(3.57)
causes distribution spread around the instantaneous frequency. Factor Q will be refereed to as the spread
factor.Itisequaltozeroifinstantaneousfrequencyφ′(t)isalinearfunction,i.e.,ifφ(n)(t) ≡0,forn ≥3.
Example 8.
Let us consider signal of the form
x(t) = e−1
2 (t/α)2.
The Wigner distribution of x(t) is FT of
x

t + τ
2

x∗
t −τ
2

= e−(t/α)2e−1
4 (τ/α)2,
WD(t, ) = 2√πe−(t/α)2e−(α)2.
Note that the duration in time is proportional to α while the duration in frequency is proportional to
1/α. Product of these durations is constant.
3.03.3.2.2
Signal reconstruction
The signal can be reconstructed from the Wigner distribution, Eq. (3.54) with τ/2 = t, as:
x(t) =
1
2πx∗(0)
 ∞
−∞
WD(t/2, )e jt d.
Due to the term x∗(0) ambiguity in the signal phase remains.
Since the Wigner distribution is a two-dimensional representation of a one-dimensional signal, obvi-
ously an arbitrary real valued two-dimensional function will not be a valid Wigner distribution. A
two-dimensional real function P(t, ) is the Wigner distribution of a signal if:
∂2 ln[ρ(t1, t2)]
∂t1∂t2
= 0,
(3.58)

3.03.3 Quadratic Time-Frequency Distributions
63
where
ρ(t1, t2) = 1
2π
 ∞
−∞
P
t1 + t2
2
, 

e j(t1−t2) d.
The solution of partial differential equation (3.58) is equal to ln[ρ(t1, t2)] = ϕ1(t1) + ϕ2(t2), where
ϕ1(t1) and ϕ2(t2) are arbitrary functions of t1 and t2. Therefore, ρ(t1, t2) = eϕ1(t1) eϕ2(t2) = f1(t1) f2(t2).
With t1 = t + τ
2 and t2 = t −τ
2, we get:
f1

t + τ
2

f2

t −τ
2

= 1
2π
 ∞
−∞
P(t, )e jτ d.
Since P(t, ) is a real function, it follows that f1(t) = f ∗
2 (t) = x(t). Thus, for P(t, ) satisfying
(3.58), there exists function x(t) such that x(t + τ
2)x∗(t −τ
2) and P(t, ) are the FT pair. A mean
squared approximation of an arbitrary two-dimensional function by a valid Wigner distribution, or a
sum of the Wigner distributions, will be discussed later.
3.03.3.2.3
Uncertainty principle and the Wigner distribution
The uncertainty principle for the Wigner distribution states that the product of effective durations of a
signal x(t) in time σt and in frequency σ cannot be arbitrary small. It satisﬁes the inequality:
σ 2
t σ 2
 ≥1/4,
(3.59)
where σ 2
t and σ 2
 are deﬁned by
σ 2
t =
1
2π Ex
 ∞
−∞
 ∞
−∞
(t −tc)2WD(t, )dt d = 1
Ex
 ∞
−∞
(t −tc)2|x(t)|2dt,
σ 2
 =
1
2π Ex
 ∞
−∞
 ∞
−∞
( −c)2WD(t, )dt d
=
1
2π Ex
 ∞
−∞
( −c)2|X()|2d,
(3.60)
where Ex is signal energy and
tc = 1
Ex
 ∞
−∞
t|x(t)|2dt,
c =
1
2π Ex
 ∞
−∞
|X()|2d.
The equality in (3.59) holds for the Gaussian signal x(t), when we get σ 2
t σ 2
 = 1/4. Thus, it is not
possible to achieve arbitrary high resolution in both directions, simultaneously. The product of effective
durations is higher than 1/4 for any other than the Gaussian signal.
The fact that the signal x(t) is located within [tg −σt, tg +σt] in time and within [i −σ, i +σ]
in frequency does not provide any information about the local concentration of the signal within this
time-frequency region. It can be spread all over the region or highly concentrated along a line within that

64
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
region. Thus, the conclusion that the Wigner distribution is highly concentrated along a line (that we
made earlier for a linear FM signal), does not contradict the uncertainty principle. Local concentration
measures are used to grade signal’s concentration in the time-frequency domain.
The duration of signal x(t) = A(t) exp ( jφ(t)) in frequency domain is
σ 2
 =
1
2π Ex
 ∞
−∞
2|X()|2d = 1
Ex
 ∞
−∞
x′(t)
2 dt
= 1
Ex
 ∞
−∞

A′(t)
 2 +

A(t)φ′(t)
 2
dt,
where, without loss of generality, i = 0 is assumed. Note that the product σ 2
t σ 2
 has a lower limit
1/4, but there is no upper limit. It can be very large. Signals whose product of durations in time and
frequency is large, σ 2
t σ 2
 ≫1, are called asymptotic signals.
3.03.3.2.4
Pseudo quantum signal representation
A distribution that parametrize the uncertainty, keeping the marginal properties and the location of the
instantaneous frequency, is deﬁned as a “pseudo quantum” signal representation:
SDL(t, ℘) =
 ∞
−∞
x[L] 
t + τ
2L

x[L]∗
t −τ
2L

e−j℘τ dτ
(3.61)
with
x[L](t) = A(t)e j Lφ(t).
The spreading factor in this representation is
Q(t, τ) =
	
Lφ

t + τ
2L

−Lφ

t −τ
2L

−φ′(t)τ =
1
24L2 φ(3)(t)τ 3 + · · ·
For the Gaussian chirp signal
x(t) = Ae−at2/2e j

bt2/2+ct
 
(3.62)
we get
SDL(t, ℘) = 2|A|2e−at2π
a Le
−(℘−bt−c)2
a/L2
.
For a large parameter L, when L
&
π
a e−L2℘2/a →πδ(℘), we get
SDL(t, ℘) = |A|2e−at22πδ(℘−bt −c),
being highly concentrated, simultaneously in time and in frequency ℘at (0, c) for a large a, if a/L2 →0.
The uncertainty principle for (3.61) is
σ 2
t σ 2
℘≥
1
4L2 .
(3.63)
Note that the distribution |A|2e−at22πδ(℘−bt −c) satisﬁes the energy and the time marginal
property for any set of parameters.

3.03.3 Quadratic Time-Frequency Distributions
65
t
Ω
−2
−1
0
1
2
−2
−1
0
1
2
t
−2
−1
0
1
2
−2
−1
0
1
2
t
−2
−1
0
1
2
−2
−1
0
1
2
t
Ω
(a)
−2
−1
0
1
2
−2
−1
0
1
2
t
(b)
−2
−1
0
1
2
−2
−1
0
1
2
t
(c)
(d)
(e)
(f)
−2
−1
0
1
2
−2
−1
0
1
2
FIGURE 3.13
The pseudo quantum signal representation of a Gaussian chirp with a low (a–c) and a high (d–f) frequency
rate for (a, d) L = 1 (the Wigner distribution), (b, e) L = 4, and (c, f) L = 16.
The pseudo quantum signal representation of signal (3.62) with a = 1, b = 1/2, and c = 0 for L = 1
(Wigner distribution), L = 4 and L = 16 is given in Figure 3.13. The pseudo quantum distribution
may be illustrated trough a physical experiment with a pendulum, for example, by changing the total
acceleration of the pendulum system, as described in [6].
3.03.3.2.5
Instantaneous bandwidth
From the deﬁnition of the signal width in frequency (3.60) we can conclude that, at a given instant t,
we may deﬁne similar local values
σ 2
(t) =
1
2π|x(t)|2
 ∞
−∞
( −i(t))2WD(t, )d
(3.64)
with
i(t) =
1
2π|x(t)|2
 ∞
−∞
WD(t, )d
playing a role of the instantaneous bandwidth σ 2
(t) and the mean frequency i(t). It is easy to show
that, for a signal x(t) = A(t)e jφ(t), the mean frequency is equal to the instantaneous frequency,
i(t) = φ′(t).

66
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
This relation is used for the instantaneous frequency estimation, in addition to the simple detection of
maximum position, for a given t.
For the instantaneous bandwidth we easily get:
σ 2
(t) = 1
2
' A′(t)
A(t)
2
−A′′(t)
A(t)
(
.
Note that both of these forms follow as special cases of conditional instantaneous moments. The nth
conditional moment of the Wigner distribution, at an instant t, is deﬁned as
mn
i (t) =
1
2π|x(t)|2
 ∞
−∞
nWD(t, )d.
Using the fact that the Wigner distribution and the local autocorrelation function are the FT pair,
WD(t, ) ←→
,τ x(t + τ/2)x∗(t −τ/2), resulting in
( j)nWD(t, ) ←→
,τ
dn
dτ n (x(t + τ/2)x∗(t −τ/2)),
the moments are calculated as
mn
i (t) =
(−j)n
dn
dτ n (x(t + τ/2)x∗(t −τ/2))

τ=0
|x(t)|2
,
=
(−j/2)n )n
l=0

n
l

(−1)lx∗(l)(t)x(n−l)(t)
|x(t)|2
.
In a similar way we can deﬁne moments for other distributions from the generalized Wigner distribution
form, including the Rihaczek distribution.
It is important to note that the instantaneous bandwidth is not a measure of the distribution spread
around the instantaneous frequency, in contrast to the global parameters σ 2
t and σ 2
, which indicate
a global region of the distribution spread. It is obtained with the Wigner distribution as a weighting
function, that can assume negative values. It may result in small values of σ 2
(t) even in the cases when
the Wigner distribution is quite spread.
Example 9.
Consider the instantaneous bandwidth of linear modulated Gaussian function
x(t) = e−1
2 (t/α)2 exp ( jat2).
Its Wigner distribution is
WD(t, ) = 2α√πe−(t/α)2e−(α(−2at))2
For a large value of α, as compared to a (slow-varying amplitude with respect to phase variations),
we get a very concentrated distribution along the IF i(t) = 2at. It is in a full agreement with the
instantaneous bandwidth deﬁnition which produces, for example for t = 0, value of σ 2
(0) = 1/(2α),
what is very small for large α. However, when the Wigner distribution assumes negative values, like in
the cubic phase signal that will be presented later (see example in Section 3.03.3.2.9), we have to be
very careful with the instantaneous bandwidth interpretation.

3.03.3 Quadratic Time-Frequency Distributions
67
3.03.3.2.6
Properties of the Wigner distribution
A list of the properties satisﬁed by the Wigner distribution follows:
P1—Realness for any signal
WD∗
x(t, ) = WDx(t, ).
P2—Time-shift property
WDy(t, ) = WDx(t −t0, )
for
y(t) = x(t −t0).
P3—Frequency shift property
WDy(t, ) = WDx(t,  −0)
for
y(t) = x(t)e j0t.
P4—Time marginal property
1
2π
 ∞
−∞
WDx(t, )d = |x(t)|2.
P5—Frequency marginal property
 ∞
−∞
WDx(t, )dt = |X()|2.
P6—Time moments
1
2π
 ∞
−∞
 ∞
−∞
tnWDx(t, )dtd =
 ∞
−∞
tn|x(t)|2dt.
P7—Frequency moments
 ∞
−∞
 ∞
−∞
nWDx(t, )dtd =
 ∞
−∞
n|X()|2d.
P8—Scaling
WDy(t, ) = WDx(at, /a)
for
y(t) =
!
|a|x(at),
a ̸= 0.
P9—Instantaneous frequency
 ∞
−∞WDx(t, )d
 ∞
−∞WDx(t, )d = i(t) = d
dt arg[x(t)].

68
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
P10—Group delay
 ∞
−∞tWDx(t, )dt
 ∞
−∞WDx(t, )dt = −tg() = −d
d arg[X()].
P11—Time constraint
If x(t) = 0 for t outside [t1, t2] then, also WDx(t, ) = 0 for t outside [t1, t2].
P12—Frequency constraint
If X() = 0 for  outside [1, 2], then, also WDx(t, ) = 0 for  outside [1, 2].
P13—Convolution
WDy(t, ) =
 ∞
−∞
WDh(t −t0, )WDx(t0, )dt0
if
y(t) =
 ∞
−∞
h(t −t0)x(t0)dt0.
P14—Product
WDy(t, ) = 1
2π
 ∞
−∞
WDh(t,  −0)WDx(t, 0)d0
for
y(t) = h(t)x(t).
P15—Fourier transform
WDy(t, ) = WDx(−/c, ct)
for
y(t) =
1
√(2π)
!
|c|X(ct),
c ̸= 0.
P16—Chirp convolution
WDy(t, ) = WDx

t −
c , 

for
y(t) = x(t) ∗
!
|c|e jct2/2.
P17—Chirp product
WDy(t, ) = WDx(t,  −ct)
for
y(t) = x(t)e jct2/2.
P18—Moyal property
1
2π
 ∞
−∞
 ∞
−∞
WDx(t, )WDy(t, )dt d =

 ∞
−∞
x(t)y(t)dt

2
.
Verifying of these properties is straightforward and it is left to the reader.

3.03.3 Quadratic Time-Frequency Distributions
69
3.03.3.2.7
Linear coordinate transforms of the Wigner distribution
Here we derive a general form of the linear coordinate transformation of the Wigner distribution, with
the coordinate rotation as a special case. From the property P17 it is easy to conclude that multiplication
of signal by a chirp, x(t)e jat2/2, leads to WDx(t,  −at). Similarly, for the convolution with a linear
FM signal, x(t)∗√|b|e jbt2/2, the transformation, according to P16, is WDy(t, ) = WDx(t −/b, ).
Now, we can easily conclude that for the signal
xL(t) =
"	
x(t)e jct2/2
∗
!
|b|e jbt2/2#
e jat2/2,
(3.65)
the coordinate transformation matrix is
L =

1 0
−c
1
  1 −1/b
0
1
 
1 0
−a
1

=

1 + a/b
−1/b
−c −a(c/b + 1) c/b + 1

=
 A
B
C
D

(3.66)
with b ̸= 0. Thus, we get the signal given by (3.65) results in the linear coordinate transformation of
the Wigner distribution:
WDL(t, ) = WDx(At + B, Ct + D),
(3.67)
where WDx(t, ) is the Wigner distribution of x(t), WDL(t, ) is the Wigner distribution of xL(t),
deﬁned by (3.65), and transformation matrix L has the form, with values of A, B, C, and D, deﬁned
by (3.66).
Rotation of the time-frequency plane
We may easily conclude that the fractional Fourier transform (FRFT) directly follows as a special case
of linear coordinate transformation, with transformation matrix:
L =
 cos α
−sin α
sin α
cos α

(3.68)
which corresponds to the coordinate rotation of the time-frequency plane. By comparing (3.66) and
(3.68) we easily get b = 1/ sin (α) = csc (α) and a = c = −tan (α/2). Substituting these values into
(3.65) we get:
xL(t) =
"	
x(t)e−j tan (α/2)t2/2
∗
!
csc (α)e j csc (α)t2/2#
e−j tan (α/2)t2/2
=
!
csc (α)e−j tan (α/2)t2/2
 ∞
−∞
x(τ)e−j tan (α/2)τ 2/2e j csc (α)(t−τ)2/2dτ
=
&
2π je−jα

1 −j cot α
2π
e j cot (α)t2/2
 ∞
−∞
x(τ)e j cot (α)τ 2/2e−jtτ csc (α)dτ,
which is exactly the fractional Fourier transform up to the constant factor
!
2π je−jα [8,32–34].

70
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
The fractional Fourier transform was reintroduced in the signal processing by Almeida. For an angle
α (α ̸= kπ) the fractional Fourier transform is deﬁned as
Xα(u) =
 ∞
−∞
x(τ)Kα(u, τ)dτ,
where
Kα(u, τ) =

1 −j cot α
2π
e j(u2/2) cot αe j(τ 2/2) cot αe−juτ csc α.
Its inverse can be considered as a rotation for angle −α:
x(t) =
 ∞
−∞
Xα(u)K−α(u, t)du.
Thus, the fractional Fourier transform is a special form of the signal transform which produces linear
coordinate transformation in the time-frequency domain. The windowed fractional Fourier transform is
Xw,α(t, u) =

1 −j cot α
2π
e j(u2/2) cot α
 ∞
−∞
xt(τ)w(τ)e j(τ 2/2) cot αe−juτ csc αdτ,
where the local signal is xt(τ) = x(t +τ). Relation between the windowed fractional Fourier transform
and the second order LPFT is
Xw,α(t, u) =

1 −j cot α
2π
e j(u2/2) cot αLPFT1(t, ),
where 1 = cot (α)/2 and  = u csc (α). Thus, all results can be easily converted from the second
order LPFT to the windowed fractional Fourier transform, and vice versa.
These relations, leading to the Wigner distribution linear coordinate transforms, may also be used
to produce some other signal transformation schemes (different from the fractional Fourier transform),
which may be interesting in signal processing.
3.03.3.2.8
Auto-terms and cross-terms in the Wigner distribution
A drawback of the Wigner distribution is the presence of cross-terms when the multi-component signals
are analyzed. For the multi-component signal
x(t) =
M

m=1
xm(t)
the Wigner distribution has the form
WD(t, ) =
M

m=1
M

n=1
 ∞
−∞
xm

t + τ
2

x∗
n

t −τ
2

e−jτ dτ.
Besides the auto-terms
WDat(t, ) =
M

m=1
 ∞
−∞
xm

t + τ
2

x∗
m

t −τ
2

e−jτ dτ,

3.03.3 Quadratic Time-Frequency Distributions
71
0
t1
t2
Ω1
Ω2
t
Ω
Auto−term
Auto−term
Oscillatory
cross−term
FIGURE 3.14
Wigner distribution of a two component signal.
the Wigner distribution contains a signiﬁcant number of cross-terms,
WDct(t, ) =
M

m=1
M

n=1
n̸=m
 ∞
−∞
xm

t + τ
2

x∗
n

t −τ
2

e−jτ dτ.
Usually, they are not desirable in the time-frequency signal analysis. Cross-terms can mask the presence
of auto-terms, which makes the Wigner distribution unsuitable for the time-frequency analysis of signals.
For a two-component signal with auto-terms located around (t1, 1) and (t2, 2) (see Figure 3.14)
the oscillatory cross-terms are located around ((t1 + t2)/2, (1 + 2)/2).
Example 10.
For two-component signal of the form
x(t) = e−1
2 (t−t1)2e j1t + e−1
2 (t+t1)2e−j1t
we have
WDx(t, ) = 2√πe−(t−t1)2−(−1)2 + 2√πe−(t+t1)2−(+1)2
+ 4√πe−t2−2 cos (2t1 −21t),
where the ﬁrst and second terms represent auto-terms while the third term is a cross-term. Note that
the cross-term is oscillatory in both directions. The oscillation rate along the time axis is proportional
to the frequency distance between components 21, while the oscillation rate along frequency axis is
proportional to the distance in time of components, 2t1. The oscillatory nature of cross-terms will be
used for their suppression.

72
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
3.03.3.2.9
Inner interferences in the Wigner distribution
Another serious drawback of the Wigner distribution is in the presence of inner interferences for non-
linear FM signals. Using the Taylor series expansion of the signal’s x(t) = A exp ( jφ(t)) phase we get:
WD(t, ) =
 ∞
−∞
A2e jφ(t+τ/2)e−jφ(t−τ/2)e−jτ dτ
= A2
 ∞
−∞
exp

jφ′(t)τ + 2 j
∞

k=1
φ(2k+1)(t)
(2k + 1)!
τ
2
2k+1
−jτ

dτ
= 2π A2δ( −φ′(t)) ∗ FT
$
exp

2 j
∞

k=1
φ(2k+1)(t)
(2k + 1)!
τ
2
2k+1
%
,
where FT
"
exp

2 j )∞
k=1
φ(2k+1)(t)
(2k+1)!
 τ
2
 2k+1#
is the term introducing interferences. The analytic form
of this term can be obtained by using the stationary phase approximation.
For example, let us consider a cubic phase signal (quadratic frequency modulated) with Gaussian
amplitude
x(t) = e−1
2 (t/α)2e jat3.
The Wigner distribution value is:
WD(t, ) = e−t2/α2  ∞
−∞
e−τ 2/(2α)2e jaτ 3/4e−j(−3at2)τdτ.
The stationary phase points are
3aτ 2
0 /4 =  −3at2
or τ0+ =
!
4( −3at2)/(3a) and τ0−= −
!
4( −3at2)/(3a) for ( −3at2) ≥0, and
φ′′(τ0) = 3aτ0/2.
The resulting stationary phase approximation of the Wigner distribution is obtained by summing con-
tribution from both stationary phase points, τ0+ and τ0−, as
WD(t, ) =

2π
!
3a( −3at2)
e−t2/α2
× exp

−
	
( −3at2)/(3aα2)


cos

4
3
√
3a
	
( −3at2)

3/2
−π/4

for  −3at2 ≥0 and WD(t, ) = 0 for  −3at2 < 0. For t = 0, signiﬁcant oscillatory values are
up to /(3aα2) ∼1, since the attenuation in frequency is exp (−[( −3at2)/(3aα2)]). Note that this
is not in agreement with the expectation that the instantaneous bandwidth σ 2
(0) = 1/(2α), calculated
according to (3.64), is small for a large α.

3.03.3 Quadratic Time-Frequency Distributions
73
0
0.05
0.1
0.15
0.2
−0.4
−0.2
0
0.2
0.4
Ω
The Wigner distribution at t = 0
0
0.05
0.1
0.15
0.2
−0.4
−0.2
0
0.2
0.4
Ω
Stationary phase approximation
of the Wigner distribution at t = 0
(b)
(a)
FIGURE 3.15
Stationary phase approximation of the Wigner distribution of a cubic-phase signal. The approximation error
is presented with thick red line. (For interpretation of the references to color in this Figure 3.15 legend, the
reader is referred to the web version of this book.)
Note that the stationary phase is an approximation, producing accurate results for large arguments. In
this case, exact Wigner distribution almost coincides with this approximation, already for  −3at2 >
π/4 as presented in Figure 3.15.
If these terms are not reduced, they can reduce the accuracy of the time-frequency representation of
a signal.
3.03.3.2.10
Pseudo and smoothed Wigner distribution
In practical realizations of the Wigner distribution, we are constrained with a ﬁnite time lag τ. A pseudo
form of the Wigner distribution is then used [2,9,10,13,18,23,35]. It is deﬁned as
PWD(t, ) =
 ∞
−∞
w(τ/2)w∗(−τ/2)x(t + τ/2)x∗(t −τ/2)e−jτ dτ,
(3.69)
where window w(τ) localizes the considered lag interval. If w(0) = 1, the pseudo Wigner distribu-
tion satisﬁes the time marginal property. Note that the pseudo Wigner distribution is smoothed in the
frequency direction with respect to the Wigner distribution
PWD(t, ) = 1
2π
 ∞
−∞
WD(t, θ)We( −θ)dθ,
where We() is a FT of w(τ/2)w∗(−τ/2). The pseudo Wigner distribution example for multi-
component signals is presented in Figure 3.16. Mono-component case with sinusoidally frequency
modulated signal is presented in Figure 3.17. Note that signiﬁcant inner interferences are present.
In order to reduce the interferences in the Wigner distribution, it is sometimes smoothed not only
in the frequency axis direction, but also in time, by using time-smoothing window G(t). This form is
called the smoothed Wigner distribution
SWD(t, ) = 1
2π
 ∞
−∞
 ∞
−∞
G(t −u)We( −θ)WD(u, θ)du dθ.
(3.70)

74
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
0
0.5
1
1.5
2
2.5
3
0
50
100
150
200
250
Ω
PWD1 (t,Ω)
t
0
0.5
1
1.5
2
2.5
3
0
50
100
150
200
250
Ω
PWD2(t ,Ω)
t
(a)
(b)
FIGURE 3.16
The pseudo Wigner distribution of signals from Figure 3.1.
The smoothed Wigner distribution with
G(t)We() = αe−γ t2e−β2 = αe−(γ t2+β2)
isequaltothespectrogramwithwindoww(τ) = e−γ τ 2/2 ifγ = 1/β.ThissmoothedWignerdistribution
is always positive.

3.03.3 Quadratic Time-Frequency Distributions
75
0
1
2
3
−100
−50
0
50
100
Ω
t
0
1
2
3
−100
−50
0
50
100
Ω
PWD(t , Ω)
PWD(t , Ω)
t
(a)
(b)
FIGURE 3.17
The pseudo Wigner distribution for a sinusoidally frequency modulated signal. A narrow window (left) and a
wide window (right).
3.03.3.2.11
Discrete pseudo Wigner distribution
The pseudo Wigner distribution of a discrete-time signal, with a ﬁnite length lag window, is given by
PWD(n, ω) =
N/2

m=−N/2
w(m)w∗(−m)x(n + m)x∗(n −m)e−j2mω.
(3.71)
Note that the pseudo Wigner distribution is periodic in ω with period π. The signal should be sampled
at a twice higher sampling rate than it is required by the sampling theorem, t ≤π/(2m). Thus,
with the same lag window length the pseudo Wigner distribution will have twice more samples than the
STFT. In order to produce an unbiased approximation of the analog form (3.69), the sampled signal in
(3.71) should be formed as x(n) = x(nt)
√
2t.
The discrete time and frequency form is given by
PWD(n, k) =
N/2

m=−N/2
w(m)w∗(−m)x(n + m)x∗(n −m)e−j4πmk/(N+1)
and may also be efﬁciently calculated by using the FFT routines. Note that discrete frequency ω is
related to frequency index k as ω = 2kπ/(N + 1).
In order to avoid the need for oversampling, as well as to eliminate cross-terms between positive and
negative frequency components in real signals, the real valued signals are usually transformed into their
analytic forms xa(t) = x(t) + jxh(t), where xh(t) is the signal’s Hilbert transform. In the frequency
domain Xa() = 2X(), for  > 0 and Xa() = 0 for  < 0, while Xa() = X(), for  = 0.
Pseudo Wigner distribution is then calculated based on the analytic form of a signal. A STFT-based
approach for creating the alias-free Wigner distribution will be also described later in the text.

76
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
3.03.3.2.12
Wigner distribution based inversion and synthesis
In order to deﬁne an efﬁcient algorithm for the synthesis of a signal with speciﬁed time-frequency
distribution, we will restate the Wigner distribution inversion within the eigenvalue and eigenvectors
decomposition framework. A discrete form of the Wigner distribution is deﬁned by
WD(n, k) =
N/2

m=−N/2
x(n + m)x∗(n −m)e−j 2π
N+1 2mk,
(3.72)
where we assume that the signal x(n) is time limited within |n| ≤N/2. Inversion relation for the Wigner
distribution reads
x(n + m)x∗(n −m) =
1
N + 1
N/2

k=−N/2
WD(n, k)e j 2π
N+1 m(2k).
After substitutions n1 = n + m and n2 = n −m we get
x(n1)x∗(n2) =
1
N + 1
N/2

k=−N/2
WD
n1 + n2
2
, k

e j 2π
N+1 k(n1−n2).
(3.73)
For cases when (n1 + n2)/2 is not an integer, an appropriate interpolation is performed in order to
calculate WD((n1 + n2)/2, k) .
Note that relation (3.73) is a discrete counterpart of the Wigner distribution inversion in analog
domain, that reads:
x(t1)x∗(t2) = 1
2π
 ∞
−∞
WD((t1 + t2)/2, )e j(t1−t2)d.
By discretization of angular frequency  = k and time t1 = n1t, t2 = n2t, with appropriate
deﬁnition of discrete values, we easily obtain (3.73).
Introducing the notation,
R(n1, n2) =
1
N + 1
N/2

k=−N/2
WD
n1 + n2
2
, k

e j 2π
N+1 k(n1−n2),
(3.74)
we get
R(n1, n2) = x(n1)x∗(n2).
(3.75)
Matrix form of (3.75) reads
R = x(n)xH(n),
(3.76)
where x(n) is a column vector whose elements are the signal values, xH(n) is a row vector (Hermitian
transpose of x(n)), and R is a matrix with the elements R(n1, n2), deﬁned by (3.74).
The eigenvalue decomposition of R reads
R = QQT =
N+1

i=1
λiqi(n)qH
i (n),
(3.77)

3.03.3 Quadratic Time-Frequency Distributions
77
where λi are eigenvalues and qi(n) are corresponding eigenvectors of R. By comparing (3.76) and
(3.77), it follows that the matrix with elements of form (3.74) can be decomposed by using only one
non-zero eigenvalue. Note that the energy of the corresponding eigenvector is equal to 1, by deﬁnition
∥q1(n)∥= 1. By comparing (3.76) and (3.77), having in mind that there is only one non-zero eigenvalue
λ1, we have
x(n)xH(n) = λ1q1(n)qH
1 (n) = (
!
λ1q1(n))(
!
λ1q1(n))H
and
λ1 =
***
!
λ1q1(n)
***
2
= ∥x(n)∥2 =
N/2

n=−N/2
x2(n) = Ex.
(3.78)
The eigenvector q1(n) is equal to the signal vector x(n), up to the constant amplitude and phase factor.
Therefore, an eigenvalue decomposition of the matrix, formed according to (3.74), can be used to check
if an arbitrary 2D function D(n, k) is a valid Wigner distribution.
These relations can be used in signal synthesis. Assume that we have a given function D(n, k), calcu-
late (3.74) and perform eigenvalue decomposition (3.77). If the given function is the Wigner distribution
of a signal it will result in one non-zero eigenvalue and corresponding eigenvector. If that is not the case
then the ﬁrst (largest) eigenvalue and corresponding eigenvector produce a signal such that its Wigner
distribution will be the closest possible Wigner distribution (in the LMS sense) to the given arbitrary
function D(n, k). This conclusion follows from the eigenvalue/eigenvectors decomposition properties.
3.03.3.3 Ambiguity function
To analyze auto-terms and cross-terms, the well-known ambiguity function can be used as well. It is
deﬁned as:
AF(θ, τ) =
 ∞
−∞
x

t + τ
2

x∗
t −τ
2

e−jθtdt.
(3.79)
It is already a classical tool in optics as well as in radar and sonar signal analysis.
The ambiguity function and the Wigner distribution form a two-dimensional FT pair
AF(θ, τ) = FT2D
t,{WD(t, )}.
Consider a signal whose components are limited in time to
xm(t) ̸= 0 only for |t −tm| < Tm.
In the ambiguity (θ, τ) domain we have xm(t + τ/2)x∗
m(t −τ/2) ̸= 0 only for
−Tm < t −tm + τ/2 < Tm,
−Tm < t −tm −τ/2 < Tm.
It means that xm(t +τ/2)x∗
m(t −τ/2) is located within |τ| < 2Tm, i.e., around the θ-axis independently
of the signal’s position tm. Cross-term between signal’s mth and nth component is located within
|τ +tn−tm| < Tm+Tn. It is dislocated from τ = 0 for two-components that do not occur simultaneously,
i.e., when tm ̸= tn.

78
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
From the frequency domain deﬁnition of the Wigner distribution a corresponding ambiguity function
form follows:
AF(θ, τ) = 1
2π
 ∞
−∞
X

 + θ
2

X∗

 −θ
2

e jτd.
(3.80)
From this form we can conclude that the auto-terms of the components, limited in frequency to
Xm() ̸= 0 only for | −m| < Wm, are located in the ambiguity domain around τ-axis within
the region |θ/2| < Wm. The cross-terms are within
|θ + n −m| < Wm + Wn,
where m and n are the frequencies around which the FT of each component lies.
Therefore, all auto-terms are located along and around the ambiguity domain axis. The cross-terms,
for the components which do not overlap in the time and frequency, simultaneously, are dislocated from
the ambiguity axes, Figure 3.18. This property will be used in the deﬁnition of the reduced interference
time-frequency distributions.
The ambiguity function of a four-component signal consisting of two Gaussian pulses, one sinusoidal
and one linear frequency modulated component is presented in Figure 3.19.
Example 11.
Let us consider signals of the form
x1(t) = e−1
2 t2,
x2(t) = e−1
2 (t−t1)2e j1t + e−1
2 (t+t1)2e−j1t .
0
0
θ2
θ1
τ1
τ2
θ
τ
Cross−term
Cross−term
Auto−terms
|AF(θ,τ) |
FIGURE 3.18
Auto and cross-terms in a two-component signal in the ambiguity domain.

3.03.3 Quadratic Time-Frequency Distributions
79
−3
−2
−1
0
1
2
3
−100
−50
0
50
100
θ
AF(θ,τ)
τ
FIGURE 3.19
Ambiguity function of the signal from Figure 3.1.
The ambiguity function of x1(t) is
AFx1(θ, τ) = √πe−1
4 τ 2−1
4 θ2
while the ambiguity function of two-component signal x2(t) is
AFx2(θ, τ) = √πe−1
4 τ 2−1
4 θ2e j1τe−jt1θ + √πe−1
4 τ 2−1
4 θ2e−j1τe jt1θ
+ √πe−1
4 (τ−2t1)2−1
4 (θ−21)2 + √πe−1
4 (τ+2t1)2−1
4 (θ+21)2.
In the ambiguity domain (θ, τ) auto-terms are located around (0, 0) while cross-terms are located around
(21, 2t1) and (−21, −2t1) as presented in Figure 3.18.
Example 12.
Show that the second order moment of the signal
xL(t) =

x(t)e jct2/2
∗
!
|b|e jbt2/2
e jat2/2
may be calculated based on the signal’s and the Fourier transform’s second order moments and the joint
ﬁrst order moment.
For signal xL(t), the Wigner distribution is obtained by linear coordinate transformation of the
Wigner distribution of a signal x(t),
WDxL(t, ) = WDx(u, v) = WDx(At + B, Ct + D).
(3.81)
The coordinate transformation matrix has the form
 u
v

=

1 + a/b
−1/b
−c −a(c/b + 1) c/b + 1
  t


with A, B, C, and D being related to a, b, c by the expressions in the transformation matrix.

80
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
The second order moment of xL(t) is
m2(a, b, c) = 1
2π
 ∞
−∞
 ∞
−∞
t2WDxL(t, )dt d
= 1
2π
 ∞
−∞
 ∞
−∞
t2WDx(At + B, Ct + D)dt d.
With a change of variables At + B = u and Ct + D = v, t = Du −Bv, having in mind that the
transformation is unitary, AD −BC = 1,
m2(a, b, c) = 1
2π
 ∞
−∞
 ∞
−∞
(D2u2 −2BDuv + B2v2)WDx(u, v)du dv
= D2
 ∞
−∞
t2 |x(t)|2 dt −2BDμ11 + B2 1
2π
 ∞
−∞
2 |X()|2 d
= D2m2 −2BDμ11 + B2M2,
(3.82)
where M2 could be calculated as M2 =
 ∞
−∞
x′(t)
2 dt and
μ11 = 1
2π
 ∞
−∞
 ∞
−∞
tWD(t, )dt d
= ∂2 A(θ, τ)
∂θ∂τ

θ=0, τ=0
= −j
2
 ∞
−∞
t(x′(t)x∗(t) −x(t)x∗′(t))dt.
This relation is useful for multiparameter optimization in order to ﬁnd time-frequency representation
(with distribution coordinate transformation) that would produce the best concentrated signal, with
minimal moment m2(a, b, c). Similar relation was obtained in the local polynomial Fourier transform
analysis. A special case, that reduces to the time-frequency plane rotation with −1/b = sin (α) = 1/
csc (α) and a = c = −tan (α/2) is used in practice by fractional Fourier transforms [8,33].
3.03.3.4 Cohen class of distributions
Time and frequency marginal properties (3.42) and (3.43) may be considered as the projections of the
distribution P(t, ) along the time and frequency axes, i.e., as the Radon transform of P(t, ) along
these two directions. It is known that the FT of the projection of a two-dimensional function on a given
line is equal to the value of the two-dimensional FT of P(t, ), denoted by AF(θ, τ), along the same
direction (inverse Radon transform property). Therefore, if P(t, ) satisﬁes marginal properties then
any other function having two-dimensional FT equals to AF(θ, τ) along the axes lines θ = 0 and τ = 0,
and arbitrary values elsewhere, will satisfy marginal properties, Figure 3.20.
Assuming that the Wigner distribution is a basic distribution which satisﬁes the marginal properties
(any other distribution satisfying marginals can be used as the basic one), then any other distribution
with two-dimensional FT
AFg(θ, τ) = c(θ, τ)FT2D
t,{WD(t, )} = c(θ, τ)AF(θ, τ),
(3.83)
where c(0, τ) = 1 and c(θ, 0) = 1, satisﬁes marginal properties as well.

3.03.3 Quadratic Time-Frequency Distributions
81
|x(t)|2
|X(Ω)|2
t
Ω
t
Ω
P(t,Ω)
Integration over Ω
Integration over t
AF(τ,θ)
τ
θ
FT [ |x(t)|2]
FT [ | X(Ω)|  ]
2
2D FT
FIGURE 3.20
Marginal properties and their relation to the ambiguity function.
The inverse two-dimensional FT of AFg(θ, τ) produces the Cohen class of distributions, introduced
from quantum mechanics into the time-frequency analysis by Claasen and Mecklenbäuker, in the form
CD(t, ) = 1
2π
 ∞
−∞
 ∞
−∞
 ∞
−∞
c(θ, τ)x(u + τ/2)x∗(u −τ/2)e jθt−jτ−jθudu dτ dθ,
(3.84)
where c(θ, τ) is called the kernel in the ambiguity domain.
Alternatively, the frequency domain deﬁnition of the Cohen class of distributions is
CD(t, ) =
1
(2π)2
 ∞
−∞
 ∞
−∞
 ∞
−∞
X(u −θ/2)X∗(u + θ/2)c(θ, τ)e jθt−jτ+ jτudu dτ dθ.
(3.85)
Various distributions can be obtained by altering the kernel function c(θ, τ). For example, c(θ, τ) = 1
produces the Wigner distribution, while for c(θ, τ) = e jθτ/2 the Rihaczek distribution follows.
The Cohen class of distributions, deﬁned in the ambiguity domain:
CD(t, ) = 1
2π
 ∞
−∞
 ∞
−∞
c(θ, τ)AF(θ, τ)e jθt−jτ dτ dθ
(3.86)
can be written in other domains, as well. The time-lag domain form is obtained from (3.84), after
integration on θ, as:
CD(t, ) =
 ∞
−∞
 ∞
−∞
cT (t −u, τ)x(u + τ/2)x∗(u −τ/2)e−jτ dτ du.
(3.87)
The frequency-Doppler frequency domain form follows from (3.85), after integration on τ, as:
CD(t, ) =
1
(2π)2
 ∞
−∞
 ∞
−∞
C(θ,  −u)X(u + θ/2)X∗(u −θ/2)e jθt dθ du.
(3.88)

82
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
Finally, the time-frequency domain form is obtained as a two-dimensional convolution of the two-
dimensional FTs, from (3.86), as:
CD(t, ) = 1
2π
 ∞
−∞
 ∞
−∞
(t −u,  −ξ)WD(u, ξ)du dξ.
(3.89)
Kernel functions in the respective time-lag, Doppler frequency-frequency and time-frequency domains
are related to the ambiguity domain kernel c(θ, τ) as:
cT (t, τ) = 1
2π
 ∞
−∞
c(θ, τ)e jθt dθ,
(3.90)
C(θ, ) =
 ∞
−∞
c(θ, τ)e−jτdτ,
(3.91)
(t, ) = 1
2π
 ∞
−∞
 ∞
−∞
c(θ, τ)e jθt−jτ dτ dθ.
(3.92)
According to (3.89) all distributions from the Cohen class may be considered as 2D ﬁltered versions
of the Wigner distribution. Although any distribution could be taken as a basis for the Cohen class
derivation, the form with the Wigner distribution is used because it is the bestconcentrated distribution
Table 3.1 Properties of the Distributions from the Cohen Class
Distribution property
Kernel constraint
P1
Realness
c(θ, τ) = c∗(−θ, −τ)
P2
Time shift
Any kernel
P3
Frequency shift
Any kernel
P4
Time marginal
c(θ, 0) = 1
P5
Frequency marginal
c(0, τ) = 1
P6
Time moments
c(θ, 0) = 1
P7
Frequency moments
c(0, τ) = 1
P8
Scaling
c(θ, τ) = c(aθ, τ/a)
P9
Instantaneous frequency
c(θ, 0) = 1, ∂c(θ, τ)
∂τ
τ=0
= 0
P10
Group delay
c(0, τ) = 1, ∂c(θ, τ)
∂θ
θ=0
= 0
P11
Time constraint
cT (t, τ) = 0 for |t/τ| > 1/2
P12
Frequency constraint
C(θ, ) = 0 for |/θ| > 1/2
P13
Convolution
c(θ, τ1)c(θ, τ2) = c(θ, τ1 + τ2)
P14
Product
c(θ1, τ)c(θ2, τ) = c(θ1 + θ2, τ)
P15
Fourier transform
c(θ, τ) = c(cτ, −θ/c)
P16
Chirp convolution
c(θ, τ) = c(θ, τ −θ/c)
P17
Chirp product
c(θ, τ) = c(θ + cτ, τ)
P18
Moyal property
|c(θ, τ)|2 = 1

3.03.3 Quadratic Time-Frequency Distributions
83
from the Cohen class with the signal independent kernels. Note that the Cohen class of distributions
is more general than the class of distributions, in the literature referred to as the smoothed Wigner
distributions (3.70), since generally (t −u,  −v) is not a separable function.
Desired properties of the time-frequency representations, presented in the case of the Wigner dis-
tribution, are satisﬁed for a distribution from the Cohen class under the kernel constraints presented in
Table 3.1 [2,4,6,10,30].
3.03.3.4.1
Reduced interference distributions
The analysis performed on ambiguity function and Cohen class of time-frequency distributions leads
to the conclusion that the cross-terms may be suppressed or eliminated, if a kernel c(θ, τ) is a function
of a two-dimensional low-pass type. In order to preserve the marginal properties c(θ, τ) values along
the axis should be c(θ, 0) = 1 and c(0, τ) = 1.
Choi and Williams exploited one of the possibilities deﬁning the distribution with the kernel of the
form
c(θ, τ) = e−θ2τ 2/σ 2.
The parameter σ controls the slope of the kernel function which affects the inﬂuence of cross-terms.
Small σ causes the elimination of cross-terms but it should not be too small because, for the ﬁnite width
of the auto-terms around θ and τ coordinates, the kernel will cause their distortion, as well. Thus, there
should be a trade-off in the selection of σ.
Here we will mention some other interesting kernel functions, producing corresponding distributions,
Figure 3.21 [2,4,10,13,18,36,37]:
Born-Jordan distribution
c(θ, τ) = sin
 θτ
2
 
θτ
2
,
Zhao-Atlas-Marks distribution
c(θ, τ) = w(τ) |τ| sin
 θτ
2
 
θτ
2
,
Sinc distribution
c(θ, τ) = rect
θτ
α

=
1 for |θτ/α| < 1/2,
0 otherwise.
Butterworth distribution
c(θ, τ) =
1
1 +

θτ
θcτc
2N ,
where w(τ) is a function corresponding to a lag window and α, N, θc, and τc are constants in the above
kernel deﬁnitions.
The spectrogram belongs to this class of distributions. Its kernel in (θ, τ) domain is the ambiguity
function of the window
c(θ, τ) =
 ∞
−∞
w

t −τ
2

w

t + τ
2

e−jθtdt = AFw(θ, τ).

84
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
−2
0
2
−100
−50
0
50
100
θ
c(θ,τ)
τ
−2
0
2
−100
−50
0
50
100
θ
c(θ,τ)
τ
−2
0
2
−100
−50
0
50
100
θ
c(θ,τ)
τ
−2
0
2
−100
−50
0
50
100
θ
c(θ,τ)
τ
(a)
(c)
(d)
(b)
FIGURE 3.21
Kernel functions in the ambiguity domain for: (a) the Choi-Williams distribution, (b) the Born-Jordan distri-
bution, (c) the sinc distribution, and (d) the Zhao-Atlas-Marks distribution.
Since the Cohen class is linear with respect to the kernel, it is easy to conclude that a distribution
from the Cohen class is positive if its kernel can be written as
c(θ, τ) =
M

i=1
aiAFwi (θ, τ),
where ai ≥0, i = 1, 2, . . . , M.

3.03.3 Quadratic Time-Frequency Distributions
85
There are several ways for calculation of the reduced interference distributions from the Cohen class.
The ﬁrst method is based on the ambiguity function (3.86):
1. Calculation of the ambiguity function.
2. Multiplication with the kernel.
3. Calculation of the inverse two-dimensional FT of this product.
The reduced interference distribution may also be calculated by using (3.87) or (3.89) with appropri-
ate kernel transformations deﬁned by (3.90) and (3.92). All these methods assume signal oversampling
in order to avoid aliasing effects. Figure 3.22 presents the ambiguity function along with kernel (Choi-
Williams). Figure 3.23a presents Choi-Williams distribution calculated according to the presented pro-
cedure. In order to reduce high side lobes of the rectangular window, the Choi-Williams distribution
is also calculated with the Hann(ing) window in the kernel deﬁnition c(θ, τ)w(τ) and presented in
Figure 3.23b. The pseudo Wigner distribution with Hann(ing) window is shown in Figure 3.16.
The optimal kernel form, introduce by Baraniuk and Jones, is based on the ambiguity function and
the kernel form optimization in the ambiguity domain [38,39]. For a given signal and its ambiguity
function, the optimal kernel is obtained as a real, non-negative function obtained as a solution of the
following optimization problem:
max

|A(θ, τ)c(θ, τ)|2 dθ dτ
θ
τ
AF(θ,τ) and CW kernel
−3
−2
−1
0
1
2
3
−100
−50
0
50
100
FIGURE 3.22
Ambiguity function for the signal from Figure 3.1 the Choi-Williams kernel (thick blue contour lines). (For
interpretation of the references to color in this Figure 3.22 legend, the reader is referred to the web version
of this book.)

86
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
0
0.5
1
1.5
2
2.5
3
0
50
100
150
200
250
Ω
CWD(t,Ω)
t
0
0.5
1
1.5
2
2.5
3
0
50
100
150
200
250
Ω
CWD(t,Ω)
t
(a)
(b)
FIGURE 3.23
The Choi-Williams distribution by a: (a) direct calculation and (b) calculation with the kernel multiplied by
a Hann(ing) lag window.
subject to
c(0, 0) = 1, unbiased signal energy condition,
c(θ, τ) is radially non-increasing function,
and kernel energy constraint:
1
2π

|c(θ, τ)|2 dθ dτ < α,
α > 0.

3.03.3 Quadratic Time-Frequency Distributions
87
In the derivation and the analysis these constraints were also expressed in the polar coordinate system
with θ = ρ cos ψ and τ = ρ sin ψ. We can understand this optimization as the procedure to ﬁnd the
kernel that passes auto-terms and suppresses cross-terms. Since the auto-terms are centered about the
ambiguity domain origin, while the cross-terms are dislocated form the origin, low-pass kernels are used.
The constraints force the kernel to be a low-pass ﬁlter of ﬁxed energy lower than α. These constraints
are quite general and do not dictate the exact shape of the kernel. It is determined by maximizing
the performance measure. Without the monotonicity constraint, the optimal kernel would be large,
regardless of whether the peaks correspond to auto-terms or cross-terms. However, assuming that the
auto-terms and cross-terms are separated in the ambiguity plane, the monotonicity constraint imposes
a penalty on kernels whose pass-bands extend over cross-terms.
3.03.3.4.2
Auto-terms form in the Cohen class of distributions
An ideally concentrated distribution of a signal x(t) = Ae jφ(t), having the form ITF(, t) = 2π A2δ
( −φ′(t)), may be easily translated into the general form (taking an inverse 2-D FT of ITF(, t)) as
ITF(, t) = A2
2π
 ∞
−∞
 ∞
−∞
 ∞
−∞
e jφ′(u)τe jθt−jτ−jθudu dθ dτ.
(3.93)
Comparing (3.93) with the Cohen class deﬁnition, while having in mind uniqueness of the FT, we get
that signal x(t) = Ae jφ(t) has the distribution equal to the ideal one if
c(θ, τ)e jφ(u+τ/2)−jφ(u−τ/2) = e jφ′(u)τ.
Expanding φ(u ± τ/2) into a Taylor series around u, up to the second order term, we get
c(θ, τ) = e−j φ(3)(u+τ1)+φ(3)(u−τ2)
3!
 τ
2
 3
,
where τ1 and τ2 are variables ranging from 0 to τ/2. From the last equation one may conclude that for any
signal x(t) there exists a signal dependent kernel, such that the Cohen distribution is equal to the ideal
one. With the assumption of signal independent kernel (which is of practical importance) we get that
the ideal distribution may be obtained only if φ(3)(u) ≡0, i.e., c(θ, τ) ≡1. The previous requirement
(φ(3)(u) ≡0) is met only if the signal is linear frequency modulated x(t) = Ae j(at2/2+bt). The kernel
c(θ, τ) ≡1 corresponds to the Wigner distribution. Any other distribution will have auto-terms that are
more or less distorted when compared with the ideal representation [35,37].
Let us consider how other members of the Cohen distribution behave for linear frequency modulated
signal x(t) = Ae j(at2/2+bt):
CD(, t) = A2
 ∞
−∞
c(aτ, τ)e j(at+b−)τdτ
= A2C( −at −b)
with
C() = FT{c(aτ, τ)}.
(3.94)
The auto-term shape is determined by the function C() which will be referred to as the auto-term
function. According to (3.94), one is able to derive the auto-term function for any distribution from

88
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
the Cohen class. In addition, based on (3.94), one may construct a distribution with the desired auto-
term shape, in the following way: If C() is a given auto-term function, for the linear frequency
modulated signal x(t) = Ae jat2/2+bt with an instantaneous frequency rate a, then the product kernel,
c(θ, τ) = c(θτ), which will produce this auto-term form, can be determined as
c(θτ) =
1
2π
 ∞
−∞
C()e jτd

aτ 2=θτ
.
(3.95)
Example 13.
We have seen that the width of c(τ, τ) (i.e., the width of c(aτ, τ) for a = 1) should
be as small as possible in order to have high cross-terms suppression. However, at the same time, the
width of auto-term function C() = FT{c(τ, τ)} should be small (i.e., c(τ, τ) wide) in order to produce
a concentrated and sharp distribution in the time-frequency plane. Product of the measures of widths
of c(τ, τ) (denoted by στ) and its FT C() (denoted by σ) is constant for a given kernel. It satisﬁes
the uncertainty principle relation στσ ≥1/2. Thus, if one ﬁxes the value of σ (the measure of the
auto-term width) then the remaining value στ (being the measure of cross-terms suppression) will be
minimal if στσ is minimal, i.e., equal to 1/2. The same is valid if one ﬁxes στ. A kernel deﬁned by
στσ = 1/2 (optimal in the described way) is
c(θτ) = e−|θτ|/σ
(3.96)
since its auto-term function is of the Gaussian form
c(τ, τ) = c(τ 2) = e−τ 2/σ.
3.03.3.5 Kernel decomposition method
Distributions from the Cohen class can be calculated by using decomposition of the kernel function in
the time-lag domain, introduced by Amin [40], Cunningham, and Williams. Starting from
CD(t, ) =
 ∞
−∞
 ∞
−∞
cT (t −u, τ)x(u + τ/2)x∗(u −τ/2)e−jτ dτ du
with substitutions u +τ/2 = t +v1 and u −τ/2 = t +v2 we get t −u = −(v1 +v2)/2 and τ = v1 −v2,
resulting in
CD(t, ) =
 ∞
−∞
 ∞
−∞
cT

−v1 + v2
2
, v1 −v2

x(t + v1)x∗(t + v2)e−j(v1−v2)dv1 dv2.
The discrete-time version of the Cohen class of distribution can be written, as
CD(n, ω) =

n1

n2
cT

−n1 + n2
2
, n1 −n2

[x(n + n1)e−jωn1][x(n + n2)e−jωn2]∗.
Assuming that C is a square matrix of ﬁnite dimension, with elements:
C(n1, n2) = cT

−n1 + n2
2
, n1 −n2

,
we can write
CD(n, ω) = xnCxH
n ,

3.03.3 Quadratic Time-Frequency Distributions
89
where xn is a vector with elements x(n+n1)e−jωn1. We can now perform the eigenvalue decomposition,
ﬁnding solutions of det (C −λI) = 0 and determining eigenvectors matrix Q that satisﬁes QQH = I
and C = QQH, where  is a diagonal matrix containing the eigenvalues. It results in
CD(n, ω) = (xnQ)(xnQ)H.
Then, it is easy to conclude that the Cohen class of distribution can be written as a sum of spectro-
grams:
CD(n, ω) =

i
λi|STFTqi (n, ω)|2,
where λi represents eigenvalues, while qi are corresponding eigenvectors of C, i.e., columns of Q, used
as windows in the STFT calculations. The eigenvalues and corresponding eigenvectors in the case of
Choi-Williams kernel are presented in Figure 3.24.
Alternative decomposition matrix scheme, singular value decomposition, can be applied to the matrix
of arbitrary shape.
3.03.3.6 S-method
The reduced interference distributions are derived in order to suppress cross-terms, while preserving the
marginal properties. Another method is based on the idea of preserving the auto-terms as in the Wigner
distribution, with elimination, or signiﬁcant reduction, of the cross-terms. This method has been derived
based on the relationship between the STFT and the pseudo Wigner distribution [23,35].
The pseudo Wigner distribution can be calculated as
PWD(t, ) = 1
π
 ∞
−∞
STFT(t,  + θ)STFT∗(t,  −θ)dθ,
(3.97)
where
STFT(t, ) =
 ∞
−∞
x(t + τ)w(τ)e−jτ dτ.
(3.98)
This can be proven by substituting (3.98) into (3.97).
Relation (3.97) has led to the deﬁnition of a time-frequency distribution
SM(t, ) = 1
π
 L P
−L P
P(θ)STFT(t,  + θ)STFT∗(t,  −θ)dθ,
(3.99)
where P(θ) is a ﬁnite frequency domain window (we also assume rectangular form), P(θ) = 0 for
|θ| > L P. Distribution obtained in this way is referred to as the S-method. Two special cases are: the
spectrogram P(θ) = πδ(θ) and the pseudo Wigner distribution P(θ) = 1.
The S-method can produce a representation of a multi-component signal such that the distribution
of each component is its Wigner distribution, avoiding cross-terms, if the STFTs of the components do
not overlap in time-frequency plane.
Consider a signal
x(t) =
M

m=1
xm(t),

90
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
0
5
10
15
20
25
30
35
40
−100
−50
0
50
100
Eigenvalues
−50
0
50
−0.4
−0.2
0
0.2
0.4
0.6 Eigenvector No 1 
−50
0
50
−0.4
−0.2
0
0.2
0.4
0.6 Eigenvector No 2 
−50
0
50
−0.4
−0.2
0
0.2
0.4
0.6 Eigenvector No 3 
−50
0
50
−0.4
−0.2
0
0.2
0.4
0.6 Eigenvector No 4 
−50
0
50
−0.4
−0.2
0
0.2
0.4
0.6 Eigenvector No 5 
−50
0
50
−0.4
−0.2
0
0.2
0.4
0.6 Eigenvector No 6 
(a)
(b)
(c)
(d)
(e)
(g)
(f)
FIGURE 3.24
Kernel decomposition example for the Choi-Williams distribution kernel: eigenvalues and six eigenvectors
corresponding to the highest magnitude eigenvalues.

3.03.3 Quadratic Time-Frequency Distributions
91
where xm(t) are mono-component signals. Assume that the STFT of each component lies inside the
region Dm(t, ), m = 1, 2, . . . , M and assume that regions Dm(t, ) do not overlap. Denote the length
of the mth region along , for a given t, by 2Bm(t), and its central frequency by 0m(t). Under this
assumptions the S-method of x(t) produces the sum of the pseudo Wigner distributions of each signal
component
SMx(t, ) =
M

m=1
PWDxm(t, ),
(3.100)
if the width of the rectangular window P(θ), for a point (t, ), is deﬁned by
L P(t, ) =
 Bm(t) −| −0m(t)| for (t, ) ∈Dm(t, ),
0
elsewhere.
To prove this consider a point (t, ) inside a region Dm(t, ). The integration interval in (3.99), for
the mth signal component is symmetrical with respect to θ = 0. It is deﬁned by the smallest absolute
value of θ for which  + θ or  −θ falls outside Dm(t, ), i.e.,
| ± θ −0m(t)| ≥Bm(t).
For  > 0m(t) and positive θ, the integration limit is reached for θ = Bm(t) −( −0m(t)). For
 < 0m(t) and positive θ, the limit is reached for θ = Bm(t) + ( −0m(t)). Thus, having in mind
the interval symmetry, an integration limit which produces the same value of integral (3.99) as the value
of (3.97), over the region Dm(t, ), is given by L P(t, ). Therefore, for (t, ) ∈Dm(t, ) we have
SMx(t, ) = PWDxm(t, ). Since regions Dm(t, ) do not overlap we have
SMx(t, ) =
M

m=1
PWDxm(t, ).
Note that any window P(θ) with constant width L P ≥max(t,){L P(t, )} produces SMx(t, f ) =
)M
m=1 PWDxm(t, ), if the regions Dm(t, ), m = 1, 2, . . . , M, are at least 2L P apart along the
frequency axis, i.e.,
0p(t) −0q(t)
 > Bp(t) + Bq(t) + 2L P, for each p, q, and t. This is the S-
method with constant window width. The best choice of L P is the value when P(θ) is wide enough to
enable complete integration over the auto-terms, but narrower than the distance between the auto-terms,
in order to avoid the cross-terms. If two components overlap for some time instants t, then the cross-term
will appear, but only between these two components and for that time instants.
Kernel function of the S-method is given by c(θ, τ) = P(θ/2)∗θ AFww(θ, τ)/2π, where AFww(θ, τ)
is the ambiguity function of window w(τ). It is generally a non-separable function.
3.03.3.6.1
Discrete S-method
The discrete form of the S-method reads
SM(n, k) =
Ld

i=−Ld
P(i)STFT(n, k + i)STFT∗(n, k −i),
(3.101)

92
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
SM(n, k) = |STFT(n, k)|2 + 2Re
⎡
⎣
Ld

i=1
P(i)STFT(n, k + i)STFT∗(n, k −i)
⎤
⎦,
(3.102)
where STFT(n, k) = DFTi→k{x(n + i)w(i)}. The terms in summation improve the quality of spectro-
gram |STFT(n, k)|2 toward the Wigner distribution quality.
A recursive relation for the S-method calculation with rectangular window P(i) is
SM(n, k; Ld) = SM(n, k; Ld −1)
+ 2Re[STFT(n, k + Ld)STFT∗(n, k −Ld)],
(3.103)
where SM(n, k; 0) = |STFT(n, k)|2, and SM(n, k; Ld) denotes SM(n, k) in (3.102) calculated with
Ld terms in the sum. In this way, we start from the spectrogram, and gradually make the transition
toward the pseudo Wigner distribution (see Figure 3.25).
For the S-method realization we have to implement the STFT ﬁrst, based either on the FFT routines
or recursive approaches suitable for hardware realizations. After we get the STFT we have to “correct”
the obtained values, according to (3.102), by adding few “correction” terms to the spectrogram values.
Note that S-method is one of the rare quadratic time-frequency distributions allowing easy hardware
realization, based on the hardware realization of the STFT, presented in the ﬁrst part, and its “correction”
according to (3.102).
In the S-method calculation:
1. There is no need for analytic signal since the cross-terms between negative and positive frequency
components are removed in the same way like the other cross-terms.
2. If we take that STFT(n, k) = 0 outside the basic period, i.e., when k < −N/2 or k > N/2 −1,
then there is no aliasing when the STFT is alias-free (in this way we can calculate the alias-free
Wigner distribution by taking Ld = N/2 and P(i) = 1 in (3.102).
3. The calculation in (3.102) and (3.103) does not need to be done for each point (n, k) separately. It
can be performed for the whole matrix of the S-method and the STFT. This can signiﬁcantly save
time in some matrix based calculation tools.
There are two possibilities to implement the summation in (3.102):
1. With a signal independent Ld. Theoretically, in order to get the pseudo Wigner distribution for each
individual component, we should use rectangular window with length 2Ld + 1 such that 2Ld is
equal to the width of the widest auto-term. This will guarantee cross-terms free distribution for all
components which are at least 2Ld samples apart. For components and time instants where this
condition is not satisﬁed, the cross-terms will appear, but still in a reduced form.
2. With a signal dependent Ld = Ld(n, k) where the summation, for each point (n, k), stops when the
absolute square value of STFT(n, k + i) or STFT(n, k −i) is smaller than an assumed reference
level R. If a zero value may be expected within a single auto-term, then the summation lasts until
two subsequent values below reference level are detected. The reference level is deﬁned as a few
percent of the spectrogram’s maximal value at a considered instant n
Rn = 1
Q2 max
k {|STFT(n, k)|2},

3.03.3 Quadratic Time-Frequency Distributions
93
+
| F (0,k)|2
=
SM  (0,k)
SM  (0,k)
SM  (0,k)
SM  (0,k)
0
+
2Re[F(0,k+1) F  (0,k−1)]
*
=
1
+
2Re[F(0,k+2) F  (0,k−2)]
*
=
2
−8
−6
−4
−2
0
2
4
6
8
2Re[F(0,k+3) F  (0,k−3)]
*
k
−8
−6
−4
−2
0
2
4
6
8
=
3
k
(c)
(a)
(b)
(d)
(f)
(h)
(e)
(g)
FIGURE 3.25
The S-method illustration for 16 point linear frequency modulated signal. Notation STFT(n, k) = F (n, k)
is used.

94
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
where Q ≥1 is a constant. Index n is added to show that the reference level R is time dependent. Note
that if Q2 →∞, the Wigner distribution will be obtained, while Q2 = 1 results in the spectrogram.
A choice of an appropriate value for design parameter Q will be discussed in the next Examples.
This is also known as adaptive S-method.
Example 14.
Consider a real-valued multi-component signals presented in Figure 3.1. The S-method
for Ld = 4 is presented in Figure 3.26.
0
0.5
1
1.5
2
2.5
3
0
50
100
150
200
250
Ω
SM  (t,Ω)
1
t
0
0.5
1
1.5
2
2.5
3
0
50
100
150
200
250
Ω
SM  (t,Ω)
2
t
(b)
(a)
FIGURE 3.26
The S-method of the signals from Figure 3.1.

3.03.3 Quadratic Time-Frequency Distributions
95
0
200
400
600
800
0
0.2
0.4
0.6
0.8
1
Ω
t
0
200
400
600
800
0
0.2
0.4
0.6
0.8
1
Ω
t
0
200
400
600
800
0
0.2
0.4
0.6
0.8
1
Ω
t
Ω
t
0
200
400
600
800
0
0.2
0.4
0.6
0.8
1
(a)
(c)
(d)
(b)
FIGURE 3.27
Time-frequency analysis of a multi-component signal: (a) The spectrogram. (b) The S-method with a constant
window, with LP = 3. (c) Regions of support for the S-method with a variable window width calculation,
corresponding to Q2 = 725. (d) The S-method with the variable window width.
Example 15.
The adaptive S-method realization will be illustrated on a ﬁve-component signal x(t)
deﬁned for 0 ≤t < 1 and sampled with t = 1/256. The Hamming window of the width Tw = 1/2
(128 samples) is used for STFT calculation. The spectrogram is presented in Figure 3.27a, while the
S-method with the constant Ld = 3 is shown in Figure 3.27b. The concentration improvement with
respect to the case Ld = 0, Figure 3.27a, is evident. Further increasing of Ld would improve the
concentration, but the cross-terms would also appear. Small changes are noticeable between the compo-
nents with constant IF and between quadratic and constant IF component. An improved concentration,
without cross-terms, can be achieved by using the variable window width Ld. The regions Di(n, k),
determining the summation limit Ld(n, k) for each point (n, k), are obtained by imposing the reference

96
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
level Rn corresponding to Q2 = 725. They are deﬁned as:
Di(n, k) =

1 when |STFTxi (n, k)|2 ≥Rn,
0 elsewhere,
and presented in Figure 3.27c. White regions mean that the value of spectrogram is below 0.14% of
its maximal value at that time instant n, meaning that the concentration improvement is not performed
at these points. The signal dependent S-method is given in Figure 3.27d. The method sensitivity, with
respect to the value of Q2, is low.
3.03.3.6.2
Smoothed spectrogram versus S-method
The S-method belongs to the general class of quadratic time-frequency distributions. Let us consider
the general form
CD(t, ) =
 ∞
−∞
 ∞
−∞
cT

−v1 + v2
2
, v1 −v2

x(t + v1)x∗(t + v2)e−j(v1−v2)dv1 dv2
and write it as
CD(t, ) =
 ∞
−∞
 ∞
−∞
[x(t + v1)e−jv1]GT (v1, v2)[x(t + v2)e−jv2]∗dv1 dv2.
If the inner product kernel GT (v1, v2) is factorized in the Hankel form GT (v1, v2) = 2w(ν1)p(ν1 +
ν2)w(ν2), then, by substituting its value into the previous relation, the S-method follows. The Toeplitz
factorization of the kernel GT (v1, v2) = 2w(ν1)p(ν1 −ν2)w(ν2) results in the smoothed spectrogram.
The smoothed spectrogram composes two STFTs in the same direction,
SSPEC(n, k) =
Ld

i=−Ld
P(i)STFT(n, k + i)STFT∗(n, k + i),
resulting in the distribution spread, in contrast to the S-method, where two STFTs are composed in
counterdirection,
SM(n, k) =
Ld

i=−Ld
P(i)STFT(n, k + i)STFT∗(n, k −i).
These forms led Scharf and Friedlander to divide all the estimators of discrete time-varying processes
into two classes, one smoothed spectrogram based and the other S-method based [41].
In this sense we may conclude that it is possible to deﬁne various forms of the S-method and use
it for various applications. It has been done in literature, for example, for the time-direction form of
the S-method, for the S-method composed in both time and frequency (two dimensional S-method),
for composing the windowed fractional Fourier transforms (fractional form of the S-method), and
composing wavelets and other time-scale transforms (afﬁne form of the S-method).

3.03.3 Quadratic Time-Frequency Distributions
97
3.03.3.6.3
Decomposition of multi-component signals
Let us consider a multi-component signal
x(n) =
M

i=1
xi(n),
where components xi(n) are mutually orthogonal, i.e., the components do not overlap in the time-
frequency plane.
For each signal component xi(n) we can write its inversion formula, corresponding to (3.73), as
xi(n1)x∗
i (n2) =
1
N + 1
N/2

k=−N/2
WDi
n1 + n2
2
, k

e j 2π
N+1 k(n1−n2),
i = 1, 2, . . . , M,
if the Wigner distribution WDi(n, k) of this component were known. By summing the above relations
for i = 1, 2, . . . , M we get
M

i=1
xi(n1)x∗
i (n2) =
1
N + 1
N/2

k=−N/2
M

i=1
WDi
n1 + n2
2
, k

e j 2π
N+1 k(n1−n2).
Having in mind (3.100), for the signals that satisfy the presented conditions, this relation reduces to:
M

i=1
xi(n1)x∗
i (n2) =
1
N + 1
N/2

k=−N/2
SM
n1 + n2
2
, k

e j 2π
N+1 k(n1−n2).
(3.104)
By denoting
RSM(n1, n2) =
1
N + 1
N/2

k=−N/2
SM
n1 + n2
2
, k

e j 2π
N+1 k(n1−n2)
(3.105)
and using the eigenvalue decomposition of matrix RSM, with the elements RSM(n1, n2), we get
RSM =
N+1

i=1
λiqi(n)q∗
i (n).
As in the case of the Wigner distribution, we can conclude that λi = Exi , i = 1, 2, . . . , M, and λi = 0
for i = M + 1, . . . , N.
The eigenvector qi(n) will be equal to the signal component xi(n), up to the phase and amplitude
constants, since the components orthogonality is assumed. Amplitude constants are again contained in
the eigenvalues λi. Thus, the reconstructed signal can be written as
xrec(n) =
M

i=1
!
λiqi(n).
It is equal to the original signal, up to the phase constants in each component. When we have several
components of different energies x1(n), x2(n), . . . , xM(n) and when they are of equal importance in

98
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
analysis, we can use normalized values of the signal components and calculate the time-frequency
representation of
xnor(n) =
M

i=1
k(λi)qi(n)
by using the weights k(λi) = 1 in the signal, i.e., when i = 1, 2, . . . , M.
Illustrative example
Consider a signal whose analog form reads
x(t) = e j
π
3200 t2e−( t
96 )2 +
5

k=2

26 −k
10
e jkte
−
 t−dk
16
2
within the interval −128 ≤t ≤128, where 2 = −3π
4 , 3 = −π
2 , 4 = π
2 , 5 = 3π
4 , d2 = d4 =
−85, and d3 = d5 = 85. The sampling interval is t = 1. The Wigner distribution is presented in
Figure 3.28, upper subplot. Based on the Wigner distribution, the elements of matrix R are calculated by
using (3.74). Eigenvalue decomposition (3.77) of this matrix produces exactly one non-zero eigenvalue,
λ1 = 299.7 (λ2 = 0.00, λ3 = 0.00, …), being equal (up to the numerical error) to the total signal
energy Ex = 299.9, as expected from (3.74)–(3.78).
The S-method of the same signal is calculated by using (3.101) with L = 12. The obtained results are
depicted in Figure 3.29. Matrix RSM is formed according to (3.105). Its eigenvalue decomposition results
inthesamenumberofnon-zeroeigenvaluesasthenumberofsignalcomponents.Eigenvaluescorrespond
to the components energies, while the eigenvectors correspond to the normalized signal components, up
to the phase constants. First seven components correspond to the signal, while the remaining ones are
with very small eigenvalues. Energies of discrete signal components are: E1 = 119.40, E2 = 48.12,
E3 = 46.12, E4 = 44.12, and E5 = 42.11, while the obtained eigenvalues by using the S-method with
L = 12 are: λ1 = 117.42, λ2 = 47.99, λ3 = 45.99, λ4 = 43.99, λ5 = 41.99, λ6 = 8.26, …
Sensitivity of the results with respect to L is quite low within a wide region. We have repeated
calculations with values of L from L = 10 up to L = 20 and obtained almost the same results. The
error in components energy, estimated by corresponding eigenvalues, was within ±0.25%.
A similar procedure can be used for signal synthesis from the given time-frequency distribution func-
tion D(n, k). We should calculate RD matrix by substituting D(n, k) instead of SM(n, k) in (3.105)
and calculate corresponding eigenvalues. If we obtain single non-zero eigenvalue then there exists a
signal x(n) such that D(n, k) is its Wigner distribution. In the case when M non-zero eigenvalues is
present (M > 1), the function D(n, k) can be approximated as sum of Wigner distribution of sev-
eral components. The approximation error can be estimated as a sum of the remaining eigenvalues
(λM+1 + λM+2 + · · ·).
Example 16.
A two dimensional function D(n, k), representing the desired time-frequency distri-
butions of signal energy, is given in Figure 3.30a. It consists of seven time-frequency regions. We
will now ﬁnd a seven component signals, such that the Wigner distribution of each component is the
mean squared estimation of each desired region. Performing the decomposition approach, by using
the S-method as an approximation of the Wigner distributions of individual components, we get the
eigenvalues (Figure 3.30b) with corresponding eigenvectors. Keeping the largest seven eigenvalues,

3.03.3 Quadratic Time-Frequency Distributions
99
−3
−2
−1
0
1
2
3
−100
−50
0
50
100
(a)
(b)
Ω
Wigner distribution
t
5
10
15
20
25
30
0
200
400
Eigenvalue No
Eigenvalue
FIGURE 3.28
Decomposition of the Wigner distribution. Only one non-zero eigenvalue is obtained.
with corresponding eigenvectors, we form a signal that is best time-frequency approximation of the
desired arbitrary function form Figure 3.30. The S-method, as a time-frequency representation, of the
synthesized signal is shown in Figure 3.31.
3.03.3.7 Reassignment in time-frequency
The reassignment method is an approach for post-processing of the time-frequency representations. It
was originally introduced by Kodera et al. to improve the readability of the spectrogram by using the
phase information in the STFT to relocate (reassign) the distribution values closer to the instantaneous
frequency or group delay.

100
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
−3
−2
−1
0
1
2
3
−100
−50
0
50
100
(a)
Ω
S−Method
t
5
10
15
20
25
30
0
50
100
150
Eigenvalue No
Eigenvalue
(b)
FIGURE 3.29
Decomposition of the S-method. Number of non-zero eigenvalues coincide with number of the signal
components.
In order to explain the principle of reassignment let us consider the STFT deﬁnition, that we used in
this book,
STFTw(t, ) =
 ∞
−∞
w(τ)x(t + τ)e−jτ dτ
= e jt
 ∞
−∞
w(τ −t)x(τ)e−jτ dτ = |STFT(t, )| e j(t,).
It may be understood as decomposing a localized signal xt(τ) = w(τ)x(t+τ) into the periodic functions
e−jτ. Here index w in the STFTw(t, ) indicates that a window w(τ) is used for the STFT calculation.
The signal can be reconstructed by
x(t) =
1
2π Ew
 ∞
−∞
 ∞
−∞
STFTw(v, )w(t −v)e−j(v−t) d dv,
(3.106)

3.03.3 Quadratic Time-Frequency Distributions
101
−3
−2
−1
0
1
2
3
−100
−50
0
50
100
(a)
Ω
Desired TFD
t
5
10
15
20
25
30
0
1
2
3
Eigenvalue No
Eigenvalue
(b)
FIGURE 3.30
Desired time-frequency distribution and corresponding eigenvalues.
−3
−2
−1
0
1
2
3
−100
−50
0
50
100
Ω
Sum of the WD of first seven components
t
FIGURE 3.31
Resulting time-frequency distribution after signal synthesis from the most signiﬁcant components.

102
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
where Ew is a window energy, since
1
2π Ew
 ∞
−∞
 ∞
−∞
 ∞
−∞
e jvw(u −t)x(u)e−juw(t −v)e−j(v−t) du d dv
=
1
Ew
 ∞
−∞
w(0)x(t)w(t −v)dv = x(t).
Relation (3.106) can be written as
x(t) =
1
2π Ew
 ∞
−∞
 ∞
−∞
|STFTw(v, )|w(t −v)e j((v,)−v+t) d dv.
(3.107)
According to the stationary phase method, the most signiﬁcant contribution to the reconstructed value
of x(t) is from the stationary point of the phase (v, ) −v + t, in time and in frequency. The
stationary phase point is obtained from the phase derivatives in the corresponding directions,
∂(v, )
∂
−(v −t) = 0,
∂(v, )
∂v
− = 0.
(3.108)
It means that the calculated distribution value (in this case the spectrogram value) should be assigned
not to the point (t, ) where it is calculated, but to the point where it contributes the most to the signal
reconstruction, according to the stationary phase principle. The shifts of the calculated values are
ˆt(t, ) = t −∂(t, )
∂
,
ˆ(t, ) =  −∂(t, )
∂t
.
(3.109)
Note that the crucial role here is played by the STFT phase function, that is ignored in the spectrogram
calculation and presentation.
In the case of the spectrogram, the reassigning shifts, are obtained as
ˆt(t, ) = t + Re
STFTτw(t, )STFT∗
w(t, )
|STFTw(t, )|2
+
,
(3.110)
ˆ(t, ) =  −Im
STFTDw(t, )STFT∗
w(t, )
|STFTw(t, )|2
+
,
(3.111)
where STFTτw(t, ) and STFTDw(t, ) are the STFTs calculated with windows τw(τ) and dw(τ)/dτ,
respectively. For |STFTw(t, )|2 = 0 there is nothing to reassign, so the expressions (3.110) are not
used.
To prove this, rewrite
|STFTw(t, )| e j(t,) =
 ∞
−∞
w(τ)x(t + τ)e−jτ dτ.

3.03.3 Quadratic Time-Frequency Distributions
103
Calculation of the STFTτw(t, ), with τw(τ) as the window function, corresponds to the derivative
over  of both sides of the previous equation. It results in
 ∞
−∞
τw(τ)x(t + τ)e−τ dτ
= j ∂|STFTw(t, )|
∂
e j(t,) −∂(v, )
∂
|STFTw(t, )|e j(t,).
Thus,
STFTτw(t, )STFT∗
w(t, )
= j ∂|STFTw(t, )|
∂
|STFTw(t, )| −∂(v, )
∂
|STFTw(t, )|2
with
Re

STFTτw(t, )STFT∗
w(t, )

= −∂(v, )
∂
|STFTw(t, )|2
(3.112)
producing the reassignment shift in time in (3.110).
In a similar way, using the frequency domain deﬁnitions of the STFT we obtain the reassignment
shift in frequency.
The previous procedure, stating that a value of the spectrogram SPEC(t, ) should not be placed at
(t, ) in the time-frequency plane but should be reassigned to the new positions ˆt(t, ) and ˆ(t, ),
results in the reassigned spectrogram:
SPECreassign(t, ) =
 ∞
−∞
 ∞
−∞
SPEC(u, v)δ(t −ˆt(u, v))δ( −ˆ(u, v))du dv.
(3.113)
The reassigned form of a distribution from the Cohen class CD(t, ), introduced by Flandrin et al.
is deﬁned by [42]
RTF(t, ) =
 ∞
−∞
 ∞
−∞
CD(u, v)δ(t −ˆt(u, v))δ( −ˆ(u, v))du dv,
where ˆt(u, v) and ˆ(u, v) are time and frequency displacements deﬁned respectively as:
ˆt(t, ) = t −
 ∞
−∞
 ∞
−∞u(u, v)WD(t −u,  −v)du dv
CD(t, )
,
ˆ(t, ) =  −
 ∞
−∞
 ∞
−∞v(u, v)WD(t −u,  −v)du dv
CD(t, )
.
A reassigned distribution can be understood as the one with assigned values of the basic time-frequency
representation to a center of gravity in the considered region.
The reassigned representations satisfy the following important properties.
1. Time-frequency shift: For a signal shifted in time and frequency y(t) = x(t −t0)e j0t the reas-
signed representation is shifted version of the reassigned distribution of the original signal x(t):
RTFy(t, ) = RTFx(t −t0,  −0).

104
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
2. Energy marginal: For basic time-frequency representation satisfying
1
2π
 ∞
−∞
 ∞
−∞
(t, v) = 1,
the reassigned distribution satisﬁes the energy property:
1
2π
 ∞
−∞
 ∞
−∞
RTF(t, )dt d =
 ∞
−∞
|x(t)|2dt.
3. Reassigned representation is ideally concentrated for linear FM signal and delta pulse: For linear
FM signal x(t) = A exp ( jat2/2 + jbt) the frequency displacement is ˆ(t, ) = b + aˆt(t, ).
Then, reassigned representation is
RTF(t, ) =
 1
2π
 ∞
−∞
 ∞
−∞
CD(u, v)δ(t −ˆt(u, v))du dv

δ( −at −b)
= G(t, )δ( −at −b).
For delta pulse x(t) = Aδ(t −t0) the time displacement is ˆt(t, ) = t0. Reassigned representation is
RTF(t, ) =
 1
2π
 ∞
−∞
 ∞
−∞
CD(u, v)δ(t −ˆ(u, v))du dv

δ(t −t0).
4. Reassigned Wigner distribution is the Wigner distribution itself: Namely, for the Wigner distribution
the time-frequency kernel is (t, ) = 2πδ(t)δ(). Then displacements are
ˆt(t, ) = t −
 ∞
−∞
 ∞
−∞u(u, v)WD(t −u,  −v)du dv
WD(t, )
= t,
ˆ(t, ) = .
Substituting these displacement into the reassignment method, deﬁnition the Wigner distribution easily
follows.
The reassigned version of spectrogram for wide and narrow analysis window along with the reas-
signed S-method are presented in Figure 3.32.
3.03.3.8 Afﬁne class of time-frequency representations
Time-scale distributions or time-frequency representations that are covariant to scale changes and time
translations,
y(t) =
1
√|a|x
τ −t
a

,
TFDy(t, ) = TFDx
τ −t
a
, a


3.03.3 Quadratic Time-Frequency Distributions
105
0
100
200
300
400
500
0
0.5
1
1.5
2
2.5
3
t
Ω
(a)
Original TFR
0
100
200
300
400
500
0
0.5
1
1.5
2
2.5
3
t
Ω
(c)
0
100
200
300
400
500
0
0.5
1
1.5
2
2.5
3
t
Ω
(e)
0
100
200
300
400
500
0
0.5
1
1.5
2
2.5
3
t
Spectrogram (wide window)
Ω
(b)
Reassingned TFR
0
100
200
300
400
500
0
0.5
1
1.5
2
2.5
3
t
Spectrogram (narrow window)
Ω
(d)
0
100
200
300
400
500
0
0.5
1
1.5
2
2.5
3
t
S−method
Ω
(f)
FIGURE 3.32
The spectrogram with a wide window (a) and the reassigned spectrogram with wide window (b). The spec-
trogram with a narrow window (c) and the reassigned spectrogram with a narrow window (d). The S-method
(e) and the reassigned S-method (f).

106
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
belong to the afﬁne class of distributions. Representations from the afﬁne class may be written in the
forms similar to the Cohen class of distributions. The simplest time-scale representation is the continuous
wavelet transform. It is a linear expansion of the signal onto a set of analyzing functions. However, in
time-frequency analysis applications, the resolution of this transform limits its applications.
In order to improve concentration and to satisfy some other desirable properties of a time-frequency
representation the quadratic afﬁne distributions are introduced [14,29–31,35]. They can be expressed
as a function of any time-frequency distribution (as in the Cohen class of time-frequency distributions).
Taking the Wigner distribution as the central one, we can write
AD(t, ) = 1
2π
 ∞
−∞
 ∞
−∞
AF(τ, θ)c(τ, θ/)e−jθt dθ dτ
= 1
2π
 ∞
−∞
 ∞
−∞
 ∞
−∞
x

u + τ
2

x

u + τ
2

c(τ, θ/)e juθ e−jθtdθ dτ du,
AD(t, ) = 1
2π
 ∞
−∞
 ∞
−∞
WD(λ, μ)((λ −t), μ/)dλ dμ.
The scalogram and the afﬁne Wigner distributions belong to the afﬁne class. Note that the scalogram
in this sense is the Wigner distribution smoothed by the Wigner distribution of the basis function
AD(t, ) = 1
2π
 ∞
−∞
 ∞
−∞
WD(λ, μ)WDψ((λ −t), μ/)dλ dμ.
Because of the scale covariance property, many time-frequency representations in the Afﬁne class
exhibit constant-Q behavior, permitting multi-resolution analysis.
The time-scale pseudo Wigner distribution is deﬁned by
WDT(t, a) =
 ∞
−∞
w0(τ/a)x

t + τ
2

x∗
t −τ
2

e j0τ/a dτ
The presented Wigner distribution deﬁnition means that the local autocorrelation function
r(x

t + τ
2
 
x∗
t −τ
2
 
is expanded onto the basis functions
h
τ
a

= w
τ
a

e j0τ/a.
Pseudo afﬁne Wigner distribution can be calculated by using the S-method with reduced interferences.
Continuous WT can be written as WT(t, ) =
 ∞
−∞x(τ)h∗((τ −t)/0)dτ/√|0/|. Here, we
used frequency instead of scale a = 0/. Consider again h(t) in the form h(t) = w(t) exp ( j0t).
Then, the pseudo afﬁne Wigner distribution may be written as
WDT(t, ) =
 ∞
−∞
w
 τ
20


w

−τ
20


x

t + τ
2

x∗
t −τ
2

e−jτ dτ.
(3.114)
The afﬁne S-method form reads:
SM(t, ) = 2
 ∞
−∞
P(θ)WT(t, ; 0 + θ)WT∗(t, ; 0 −θ)dθ,
(3.115)

3.03.4 Higher Order Time-Frequency Representations
107
where WT(t, ; 0+θ) is the WT calculated with h(t) = w(t) exp ( j2π(0+θ)t). If P(θ) = δ(θ)/2,
then SM(t, ) is equal to the scalogram of x(t), while for P(θ) = 1 it produces WDT(t, ) deﬁned
by (3.114). This form of the S-method has been extended to other time-scale representations.
3.03.4 Higher order time-frequency representations
A higher order spectral analysis have found its applications in many ﬁelds during the last decades:
radars, sonars, biomedicine, plasma physics, seismic data processing, image reconstruction, time-delay
estimation,adaptiveﬁltering,etc.Higherorderstatistics,knownascumulants,anditsFouriertransforms,
known as higher order spectra (polyspectra), are the basic forms in this analysis. Based on these forms,
higher order time-varying spectra are introduced and analyzed. The basic representation in the time-
varying higher order spectral analysis is the Wigner higher order spectra. After presenting full forms of
higher order time-varying spectra, higher order forms reduced to the two-dimensional time-frequency
plane are analyzed. The main representatives are the L-Wigner distributions (sliced version of the higher
order spectra) and the polynomial Wigner-Ville distributions (a projection of higher order spectra). Due
to slicing or projecting operation, these distributions will loose some of the basic properties of the
higher order spectra, but will be able to enhance some other desirable properties for non-stationary
signal analysis. A highly concentrated distribution based on complex argument function is presented,
as well. The higher order ambiguity function analysis, as a tool for higher order polynomial frequency
modulated signals, concludes this section.
3.03.4.1 Wigner bispectrum
The third order moment mx
3(τ1, τ2) is given by:
mx
3(τ1, τ2) = E[x∗(t)x(t + τ1)x(t + τ2)].
Without loss of generality, we have assumed that mx
1 = 0, when the third order cumulant is equal to the
third order moment cx
3(τ1, τ2) = mx
3(τ1, τ2).
The two-dimensional FT of cx
3(τ1, τ2) is called bispectrum:
B(1, 2) =
 ∞
−∞
 ∞
−∞
cx
3(τ1, τ2)e−j(1τ1+2τ2) dτ1 dτ2.
(3.116)
For deterministic non-stationary signals, replacing E[x∗(t + α)x(t + τ1 + α)x(t + τ2 + α)] with
the local autocorrelation function R2(t, τ1, τ2) = x∗(t + α)x(t + τ1 + α)x(t + τ2 + α) we arrive at the
Wigner bispectrum (WB):
WB(t, 1, 2) =
 ∞
−∞
 ∞
−∞
x∗(t + α)x(t + τ1 + α) x(t + τ2 + α)e−j(1τ1+2τ2) dτ1 dτ2, (3.117)
where the value of α = −τ1
3 −τ2
3 is chosen such that the mean value of the signal’s arguments in the
above integral is equal to t. The Wigner bispectrum was introduced by Gerr. In terms of the signal’s FT

108
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
it reads
WB(t, 1, 2) = 1
2π
 ∞
−∞
X∗

1 + 2 + θ
3

X

1 −θ
3

X

2 −θ
3

e−jθt dθ.
Its marginal over time is the bispectrum (of a deterministic signal):
 ∞
−∞
WB(t, 1, 2)dt = X∗(1 + 2)X(1)X(2) = B(1, 2).
For a sinusoidal signal, x(t) = exp ( j0t) with X() = 2πδ( −0), bispectrum is zero for all
frequencies, B(1, 2) ≡0. Bispectrum will produce a peak in frequency-frequency domain in the
case of a quadratic phase coupled signals (resulting when a sum of sinusoids passes through a non-linear
system, like y(t) = x2(t)). For example, for a signal of the form exp ( j0t)+exp ( j20t) there will be a
non-zero value (a peak) in the bispectrum, B(1, 2) = (2π)3δ(1−0)δ(2−0)δ(1+2−20)
for 1 = 0 and2 = 0. Asimilarsituationwillappearforexp ( j01t)+exp ( j02t)+exp ( j(01+
02)t), indicating that a coupling of two sinusoidal signals with frequencies 01 and 02 has occurred.
The Wigner bispectrum behaves differently. For a sinusoidal signal, x(t) = exp ( j0t), it will always
produce a non-zero value, due to the varying θ. Here we have
WB(t, 1, 2) = (2π)2
 ∞
−∞
δ

1 + 2 + θ
3 −0

δ

1 −θ
3 −0

× δ

2 −θ
3 −0

e−jθtdθ.
The peak value of the Wigner bispectrum is at (1, 2) = (20/3, 20/3) for θ/3 = −0/3. Note
that this value is obtained with a shift of frequency lag for θ/3 = −0/3, which is signal dependent.
3.03.4.2 Wigner higher order spectra
Following the idea of (3.117), the Wigner higher order spectra of order k, of a deterministic signal x(t),
are deﬁned as the k-dimensional FT of the local autocorrelation function by Fonolosa and Nikias, as:
Wk(t, 1, 2, . . . , k)
=
 ∞
−∞
 ∞
−∞
. . .
 ∞
−∞
x∗(t −α)
L−1
,
i=1
x∗(t −α + τi)
k,
i=L
x(t −α + τi)
k,
i=1
e−jiτi dτi
(3.118)
with L conjugated terms (1 ≤L ≤k). The value of α is
α =
1
k + 1
k

i=1
τi.
(3.119)
It is chosen such that the local moment function
Rk(t, τ1, τ2, . . . , τk) = x∗(t −α)
L−1
,
i=1
x∗(t −α + τi)
k,
i=L
x(t −α + τi)

3.03.4 Higher Order Time-Frequency Representations
109
is centered at the time instant t, i.e., the mean value of all its arguments is [(t −α)+)k
i=1 (t −α +τi)]/
(k + 1) = t.
In terms of the signal’s FT, the above equation becomes:
Wk(t, 1, 2, . . . , k)
= 1
2π
 ∞
−∞
X∗
 k

i=1
i +
θ
k + 1
 L−1
,
i=1
X∗

−i +
θ
k + 1

k,
i=L
X

i −
θ
k + 1

e−jθt dθ.
(3.120)
The mean frequency over the multi-frequency space is deﬁned by:
m(t) =
 ∞
−∞. . .
 ∞
−∞mWk(t, 1, 2, . . . , k) -k
i=1 di
 ∞
−∞. . .
 ∞
−∞Wk(t, 1, 2, . . . , k) -k
i=1 di
,
m = 1, 2, . . . , k.
For a signal x(t) = A exp ( jϕ(t)), having in mind the k-dimensional FT pair
Rk(t, τ1, τ2, . . . , τk) ←→Wk(t, 1, 2, . . . , k),
it can be calculated as:
m(t) = −j
∂
∂τm
	
x∗(t −α) -L−1
i=1 x∗(t −α + τi) -k
i=L x(t −α + τi)

τ1=τ2=···=τk=0
	
x∗(t −α) -L−1
i=1 x∗(t −α + τi) -k
i=L x(t −α + τi)

τ1=τ2=···=τk=0
.
(3.121)
For α being a linear function of τi (3.119), we get
m(t) = ϕ′(t)

L
k + 1 ± 1 −
1
k + 1(k −L + 1)

,
where −1 stands for m ≤L −1 and +1 for L ≤m ≤k. For the special case of L = 1, we get
m(t) =
2
k + 1ϕ′(t).
This is in agreement with our previous Wigner bispectrum (k = 2, L = 1) analysis of a sinusoidal
signal, when we obtained that the Wigner bispectrum peak is located at (1, 2) = (20/3, 20/3).
Locations of the peaks are biased with respect to the true IF position. An interesting case, that will be
used later, is for L = (k + 1)/2, when the IF positions are unbiased:
m(t) = ±ϕ′(t),
m = 1, 2, . . . , k.
(3.122)
In this case the number of conjugated and non-conjugated terms is equal. Sign −is for the m corre-
sponding to the axis associated with the conjugated terms, while m(t) = +ϕ′(t) stands for the axis
corresponding to the non-conjugated terms.

110
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
3.03.4.3 Wigner multi-time distribution
A distribution dual to the Wigner higher order spectra (3.118) and (3.120) is introduced and deﬁned as
the multi-time Wigner higher order distribution (MTWD). The MTWD in terms of signal x(t) in time
domain reads
Wk(, t1, t2, . . . , tk) =
 ∞
−∞
x∗
 k

i=1
ti +
τ
k + 1
 L−1
,
i=1
x∗

−ti +
τ
k + 1

×
k,
i=L
x

ti −
τ
k + 1

e jτ dτ.
(3.123)
All properties of the multi-time Wigner distribution are dual to the ones for the Wigner higher order
spectra. For example, the frequency marginal (i.e., integral of Wk(, t1, t2, . . . , tk) over frequency), for
k = 2 and L = 1, is a value dual to bispectrum, x∗(t1 + t2)x(t1)x(t2).
The multi-time Wigner distribution leads to the introduction of an efﬁcient higher order distribution,
the L-Wigner distribution, obtained as its slice. Consider a multi-component signal, formed as a sum of
short duration (pulse) signals:
x(t) =
M

m=1
xm(t −dm),
(3.124)
where xm(t) (m = 1, 2, . . . , M) are such that xm(t) = 0 for |t| ≥ϵ, with ϵ being small as compared to
the considered time interval.
As in the case of the instantaneous frequency, (3.122), we can show that the location of auto-terms
along τ (or group delay) depends on the signal’s position d, for any L, except for L = (k + 1)/2.
This case was also preferred in cumulant analysis. When L = (k + 1)/2, the auto-terms are located
at the τ axis origin and its vicinity. Also, we may easily conclude from (3.123) and (3.124) that for
L = (k + 1)/2 the auto-terms lie, in the k-dimensional t1, t2, . . . , tk space, along line s deﬁned by:
s : t1 = −t,
t2 = −t, . . . , tL−1 = −t,
tL = t,
tL+1 = t, . . . , tk = t
(3.125)
at the points t = dm. The illustration of multi-time Wigner distribution of the second order with
k = 2, dual to the Wigner bispectrum, which cannot satisfy the condition L = (k + 1)/2, as well as
the illustration of multi-time Wigner distribution of the third order (with k = 3, dual to the Wigner
trispectrum), as the lowest one satisfying the previous condition (if one does not count the well-known
Wigner distribution), are given in Figure 3.33.
For M > 1 in (3.124), and for L = (k +1)/2, considering only line s, it can be shown that the regions
corresponding to cross-terms, where the integrand in (3.123) is different from zero, are dislocated from
the τ axis origin.
The multi-time Wigner higher order distribution, with L = (k + 1)/2, along the line s, given by
(3.125), is equal to the L-Wigner distribution. It is deﬁned as
LWDL(t, ) =
 ∞
−∞
x∗L 
t −τ
2L

x L 
t + τ
2L

e−jτ dτ.
(3.126)

3.03.4 Higher Order Time-Frequency Representations
111
t1
t2
d
d
→
→
→
  +τ/3
+τ/3
+τ/3
 (2): t1−τ/3=d
(3): t2−τ/3=d
 (1): t1+t2+τ/3=d
+τ/4
+τ/4
+τ/4
→
+τ/4
t3
t2
d
d
−d
d
t1
FIGURE 3.33
Illustration of the multi-time Wigner distribution of: the second order (left), the third order (right).
For L = 1, the L-Wigner distribution reduces to the Wigner distribution. The L-Wigner distribution was
introduced before the time-varying higher order spectra, as a distribution that improves time-frequency
concentration along the instantaneous frequency, since its spread factor is
Q(t, τ) =
	
Lφ

t + τ
2L

−Lφ

t −τ
2L

−φ′(t)τ =
1
24L2 φ(3)(t)τ 3 + · · ·
Its pseudo form, as it will be used in the sequel, is deﬁned by introducing a lag localization window
wL(τ),
LWDL(t, ) =
 ∞
−∞
wL(τ)x∗L 
t −τ
2L

x L 
t + τ
2L

e−jτdτ.
(3.127)
Since we will use only this form in the analysis and realizations, we will not introduce a new notation
for it. For a signal x(t) = A exp ( jφ(t)), expanding φ(t ± τ/2L) into a Taylor series around t, up to
the third order term, we get:
LWDL(t, ) = 2π A2Lδ(ω −φ′(t)) ∗ WL() ∗ FT

e j φ′′′(t)
24L2 τ 3+
,
(3.128)
where ∗ denotes the frequency domain convolution and WL() = FT {wL(τ)}. From (3.128) one
may conclude that the generalized power A2L is concentrated at the instantaneous frequency φ′(t). The
distortions caused by the shape of the phase function are due to the existence of its third and higher
order derivatives. If the instantaneous frequency is a linear function of time, then the Wigner distribution
(L = 1) produces the ideal concentration. But, if that is not the case, then L > 1 reduces the distortion.
In other words, the pseudo L-Wigner distribution locally linearize the instantaneous frequency function,
by reducing the spreading term FT{exp ( jφ′′′(t)τ 3/(24L2))} inﬂuence by L2.
The pseudo L-Wigner distribution of an order L can be calculated based on the L-Wigner distribution
of order L/2 as
LWDL(t, ) = LWDL/2(t, 2) ∗ LWDL/2(t, 2).
(3.129)

112
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
−2
0
2
−50
0
50
(a)
Ω
t
−2
0
2
−50
0
50
(b)
Ω
t
−2
0
2
−50
0
50
(c)
Ω
t
−2
0
2
−50
0
50
(d)
Ω
t
FIGURE 3.34
Time-frequency representation of a sinusoidally (nonlinear) frequency modulated signal: (a) Wigner distri-
bution. (b) L-Wigner distribution with L = 2. (c) L-Wigner distribution with L = 4. (d) L-Wigner distribution
with L = 8.
Example 17.
The pseudo Wigner distribution, along with the L-Wigner distributions with L = 2,
L = 4, and L = 8 are shown in Figure 3.34 for a sinusoidally frequency modulated signal.
A form of the L-Wigner distribution, that preserves the signal energy property, is presented in the
Section 3.03.3.2.4 as the pseudo quantum signal representation.
3.03.4.4 Signal phase derivative and distributions deﬁnitions
Let us consider signal of the form
x(t) = Ae jϕ(t)
with the instantaneous frequency
ω(t) = dϕ(t)
dt
.

3.03.4 Higher Order Time-Frequency Representations
113
In order to estimate the instantaneous frequency from the phase function we can use the following
approximative relations for the ﬁrst derivative.
Quadratic distributions:
– First order backward estimation
ω(t) ≈ϕ(t) −ϕ(t −τ)
τ
= dϕ(t)
dt
+ O(ϕ′′(τ))
with error of ϕ′′(τ) order. Time-frequency distribution corresponding to this estimation is the
Richazek distribution
RD(t, ω) =
 ∞
−∞
x(t)x∗(t −τ)e−jωτdτ.
It is the FT of A2 exp ( j(ϕ(t) −ϕ(t −τ)), thus being concentrated at the ω = dϕ(t)/dt with the
spread factor depending on ϕ′′(τ).
– Symmetric derivative estimation
ω(t) ≈ϕ(t + τ/2) −ϕ(t −τ/2)
τ
= dϕ(t)
dt
+ O(ϕ′′′(τ))
obviously corresponds to the Wigner distribution with the spread factor depending on ϕ′′′(τ). For
a linear frequency modulated signal (quadratic phase) there is no estimation error in derivative.
Therefore, in this case, the Wigner distribution is ideally concentrated, as it is well known.
Higher order distributions
We can further improve the estimation accuracy but at the cost of the estimator complexity. For example,
ω(t) ≈−ϕ(t −τ/6) + 8ϕ(t −τ/12) −8ϕ(t + τ/12) + ϕ(t + τ/6)
τ
= dϕ(t)
dt
+O(ϕ(5)(τ)) (3.130)
corresponds to a distribution
PD(t, ) =
 ∞
−∞
x∗(t −τ/6)x8(t −τ/12)x∗8(t + τ/12)x(t + τ/6)e−jτ dτ
that is fully concentrated along the IF up to the ﬁfth order polynomial phase of the signal. However, it
is of a quite high order with all drawbacks from the increased order.
In general, an estimator (distribution), may be written as
ω(t) ≈
)
i biϕ(t + ciτ)
τ
= dϕ(t)
dt
+ O(ϕ(p)(τ)).
(3.131)
Coefﬁcients bi and ci follow from the system of equations, obtained by expanding biϕ(t + ciτ) into a
Taylor series around t,
biϕ(t + ciτ) = biϕ(t) + biϕ′(t)ciτ + biϕ′′(t)(ciτ)2
2!
+ biϕ′′′(t)(ciτ)3
3!
+ biϕ(4)(t)(ciτ)4
4!
+ · · ·
and the conditions that:

114
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
1. The sum of coefﬁcients with ϕ(t) is equal to 0.
2. The sum of coefﬁcients with ϕ′(t) is equal to 1.
3. The sum of coefﬁcients with ϕ(n)(t) is equal to 0 up to the desired order.
For a fourth order estimators of the ﬁrst derivative we get:
b1 + b2 + b3 + b4 = 0,
b1c1 + b2c2 + b3c3 + b4c4 = 1,
b1c2
1 + b2c2
2 + b3c2
3 + b4c2
4 = 0,
b1c3
1 + b2c3
2 + b3c3
3 + b4c3
4 = 0,
b1c4
1 + b2c4
2 + b3c4
3 + b4c4
4 = 0.
If we add the requirement that a distribution is real valued, i.e., that the estimator is symmetric, then
b1 = −b2,
c1 = −c2,
b3 = −b4,
c3 = −c4
resulting in the system of equations
b1c1 + b3c3 = 1/2,
b1c3
1 + b3c3
3 = 0.
Polynomial Wigner-Ville distribution
Assuming the lowest possible integer values (signal powers) b1 = 2 and b3 = −1 (negative b corre-
sponds to a conjugation of signal, i.e., for example for b = −2, we use with x∗2(t)) we get the fourth
order polynomial Wigner-Ville distributions (PWVD) coefﬁcients c1 ≃0.675 and c3 ≃0.85, deﬁned
(by Boashash et al.) as [24,43]
PD(t, ) =
 ∞
−∞
x2(t + 0.675τ)x∗2(t −0.675τ)x∗(t + 0.85τ)x(t −0.85τ)e−jτdτ.
(3.132)
The polynomial Wigner-Ville distribution corresponds to the estimator:
ω(t) ≈2ϕ(t + 0.675τ) −2ϕ(t −0.675τ) −ϕ(t + 0.85τ) + ϕ(t −0.85τ)
τ
= dϕ(t)
dt
+ O(ϕ(5)(τ))
that is of lower order than (3.130), with the same error order.
The polynomial Wigner-Ville distribution of a fourth order polynomial phase signal is shown in
Figure 3.35.
Another approach, that was used in literature to deﬁne polynomial Wigner-Ville distribution, was
to assume values for c1 and c2, appropriate for discrete realization without interpolation. It results in
rational values of b1 and b3, i.e., rational signal powers.

3.03.4 Higher Order Time-Frequency Representations
115
0
0.5
1
1.5
2
2.5
3
−100
−50
0
50
100
Ω
t
FIGURE 3.35
Polynomial Wigner-Ville distribution of a signal with the fourth order polynomial phase.
Complex argument distribution
A complex time distribution, that preserves energy and time marginal condition for frequency modulated
signals, may be derived from a similar analysis, allowing complex arguments. For example, the fourth
order form follows for b1 = 1 and b3 = j, when we get c1 = 1/4 and c3 = −j/4, with frequency (ﬁrst
derivative) estimator
(t) ≈φ

t + τ
4
 
−φ

t −τ
4
 
+ jφ

t −j τ
4
 
−jφ

t + j τ
4
 
τ
.
(3.133)
The corresponding distribution is
CTD(t, ) =
 ∞
−∞
x

t + τ
4

x∗
t −τ
4

x j 
t −j τ
4

x−j 
t + j τ
4

e−jτdτ.
(3.134)
In the derivation of (3.133), the series
φ(t + jτ) = φ(t) + jτφ′(t) −τ 2φ′′(t)/2! −jτ 3φ′′′(t)/3! + · · ·
is used. It is interesting to note that a few years after the complex-time argument derivative estimation
was proposed and used in signal analysis, the estimator based on the complex-argument, of the form
τφ′(t) ≈Im φ(t + jτ)
was reintroduced in mathematical journals.

116
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
The spread factor Q(t, τ) for this distribution is
Q(t, τ) = φ(5)(t) τ 5
445! + φ(9)(t) τ 9
489! + · · ·
(3.135)
The dominant term in Q(t, τ) is of the ﬁfth order. All existing terms are signiﬁcantly reduced as
compared to the respective ones in the Wigner distribution. Continuous form of the “complex-time”
signal x(ς) is dual to the Laplace transform of x(t). Complex time is denoted by ς = t + jτ.
x(ς) = x(t + jτ) = 1
2π
 ∞
−∞
X( j)e−τ e jt d.
The signal with a “complex-time” argument could be calculated in the same way as the Laplace transform
is calculated from the FT. Value x(ς) converges within the entire complex plane ς if x(t) is a band
limited signal. In practical realizations, the values of x(n) are available as a set of data along the real
axis only. The values of signal with complex argument are not known. They must be determined from
the samples on the real time axis. This problem is well studied mathematics. It is known as an analytical
extension (continuation) of the real argument function. An analytic extension of the signal x(n) is
deﬁned as a sum of the analytic extensions of complex exponential functions. It is of the form
x(η) = x(n + jm) = 1
N
N/2−1

k=−N/2
X(k)e−2π
N mk e j 2π
N nk.
If we multiply X(k) = FFT[x(n)] by exp (−2πmk/N), for a given m, then x(n + jm) is obtained as
x(n+ jm) = IFFT[X(k) exp (−2πmk/N)]. The presented form of x(n+ jm) could directly be used for
the realization of a complex-lag distribution. Real exponential functions exp (−2πmk/N), may be out
of the computer precision range, signiﬁcantly worsening the results. Thus, one should carefully use the
above relations in the direct numerical realization. Procedures for the cross-terms reduced calculation,
reducing the distribution sensitivity to the calculation precision, is based on the S-method.
Real Time Distributions
An interesting approximation
ω(t) ≈ϕ(t −τ) −4ϕ(t −τ/2) + 3ϕ(t)
τ
= dϕ(t)
dt
+ O(ϕ′′(τ))
leads to a distribution that is fully concentrated for linear frequency modulated signals, as the Wigner
distribution. However, in contrast to the Wigner distribution that uses past and future signal values
(arguments t + τ/2 and t −τ/2 are used), this distribution uses only past signal values:
RTD(t, ) =
 ∞
0
x(t −τ)x∗4(t −τ/2)x3(t)e−jτ dτ.
Its pseudo form is
RTD(t, ) =
 T
0
w(τ)x(t −τ)x∗4(t −τ/2)x3(t)e−jτdτ.

3.03.4 Higher Order Time-Frequency Representations
117
This distribution (although not real valued) can be efﬁciently used in many application when it is
important to work in real time and to estimate the instantaneous frequency not in the middle point
of the analyzed interval (as the Wigner distribution does for the middle point of the lag window) but
at the current, last point of the considered time interval. An example of such importance is in radar
signals, when the estimation of the target parameters at the middle of the considered interval (coherent
integration time of the order of seconds) could be quite late and inappropriate for decision.
3.03.4.5 STFT based realization of higher order representations
Here, we will extend the S-method based approach to the realization of the higher order time-frequency
forms, obtained by reducing the full higher order forms to the two-dimensional time-frequency plane.
This approach will provide two substantial advantages over the direct calculation: (1) It produces the
higher order distributions, without need for signal oversampling. (2) In the case of multi-component
signals the cross-terms are reduced (eliminated).
3.03.4.5.1
L-Wigner distribution realization
The relationship between the L-Wigner distribution of an order 2L and L-Wigner distribution of an
order L is of the form
LWD2L(t, ) = 1
π
 ∞
−∞
LWDL(t,  + θ)LWDL(t,  −θ)dθ.
(3.136)
The realization of cross-terms and alias free version of the L-Wigner distribution may be efﬁciently
done in the discrete domain, by using the S-method realization form, as
LWD2L(n, k) = LWD2
L(n, k) + 2
L P

i=1
LWDL(n, k + i)LWDL(n, k −i)
(3.137)
with LWD1(n, k) = SM(n, k), calculated according to the described procedure in Section 3.03.3.6.1,
LWD1(n, k) = |STFT(n, k)|2 + 2
L P

i=1
Re{STFT(n, k + i)STFT∗(n, k −i)}.
(3.138)
Form (3.137) is very convenient for software and hardware realizations since the same blocks, connected
in cascade, can provide a simple and efﬁcient system for higher order time-frequency analysis, based
on the STFT in the initial step, with signal sampled at the Nyquist rate (see Figure 3.36).
Example 18.
First we will present the L-Wigner distribution realization for the signal presented in
Figure 3.34. The spectrogram is shown in Figure 3.36a. The Wigner distribution realized according
to (3.138), without oversampling, is shown in Figure 3.36b. The L-Wigner distribution distributions,
calculated by using (3.137), are presented in Figure 3.36c and d, for L = 2 and L = 8 respectively. The
only difference from Figure 3.34 is that here we used a lag window w(τ) = exp (−|τ/σ| ) that is order
invariant, w(τ) = w(τ/2)w(−τ/2) = w2(τ/2)2w(−τ/2) = · · ·, so that we can make fair comparisons
of different order distributions.
Example 19.
Similar calculations were repeated for a two-component signal. In this case, in order to
provide a good graphical presentation at the point of intersection (where the distribution values increases

118
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
−2
0
2
−50
0
50
(a)
Ω
t
−2
0
2
−50
0
50
(b)
Ω
t
−2
0
2
−50
0
50
(c)
Ω
t
−2
0
2
−50
0
50
(d)
Ω
t
FIGURE 3.36
Time-frequency representation of a sinusoidally frequency modulated signal: (a) The spectrogram. (b) The
Wigner distribution. (c) The L-Wigner distribution with L = 2. (d) The L-Wigner distribution with L = 8.
with a power of 2L) the distribution values are normalized, for each time instant n, with a maximal
value for that instant over all k, i.e., just in Figure 3.37 the value LW2L(n, k)/ maxk (LW2L(n, k)) for
each n, is plotted.
3.03.4.5.2
Polynomial Wigner-Ville distribution realization
Modiﬁcation of the presented method for the realization of the polynomial Wigner-Ville distribution is
straightforward. The fourth order polynomial Wigner-Ville distribution
PD(t, ) =
 ∞
−∞
x2(t + 0.675τ)x∗2(t −0.675τ)x∗(t + 0.85τ)x(t −0.85τ)e−jτ dτ
(3.139)
can be written, by using the change of variables 0.675τ →τ/4 (or τ →τ/2.7) as
PD(t, ) =
 ∞
−∞
x2 
t + τ
4

x∗2 
t + τ
4

x∗

t + 1.7
2.7
τ
2

x

t + 1.7
2.7
τ
2

e−jτ/2.7 dτ.

3.03.4 Higher Order Time-Frequency Representations
119
−2
0
2
−60
−40
−20
0
20
40
60
(a)
Ω
t
−2
0
2
−60
−40
−20
0
20
40
60
(b)
Ω
t
−2
0
2
−60
−40
−20
0
20
40
60
(c)
Ω
t
−2
0
2
−60
−40
−20
0
20
40
60
(d)
Ω
t
FIGURE 3.37
Time-frequency representation of a multi-component signal: (a) the spectrogram, (b) the Wigner distribution,
(c) the L-Wigner distribution with L = 2, and (d) the L-Wigner distribution with L = 8.
In a frequency scaled form
PD(t, ) = 1
2.7
 ∞
−∞
x2 
t + τ
4

x∗2 
t −τ
4

x∗
t + Aτ
2

x

t −Aτ
2

e−jτsdτ,
(3.140)
where A = 1.7/2.7 and s = /2.7. Note that
PD(t, s) = 1
2.7LWD2(t, s) ∗s WDA(t, s),
(3.141)
where
W A(t, s) = FT
"
x∗
t + Aτ
2

x

t −Aτ
2
#

120
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
is a scaled and frequency reversed version (due to order of conjugate terms) of the pseudo Wigner
distribution and
LWD2(t, s) = FT
"
x2 
t + τ
4

x∗2 
t −τ
4
#
is the L-Wigner distribution with L = 2. The cross-terms free realization of the pseudo Wigner distri-
bution and the pseudo L-Wigner distribution is already presented.
In the discrete implementation of the above relation the only remaining problem is the evaluation of
WDA(t, s) on the discrete set of points on the frequency axis, s = −ks. Since WDA(t, s) is, by
deﬁnition, a scaled and frequency reversed version of WD(t, ). Therefore the values of WDA(t, s) at
s = −ks are the values of WD(t, ) at s = ks/A. However, these points do not correspond
to any sample location along the frequency axis grid. Thus, the interpolation of the pseudo Wigner
distribution has to be done (one way of doing it is in an appropriate zero padding of the signal).
A discrete form of convolution (3.140), including rectangular window P(θ) and the above consid-
erations, is
PD(n, k) =
L P

i=−L P
LW2(n, k + i).
WD(n, k + i/A),
(3.142)
where 2L P +1 is the width of P(θ) in the discrete domain, while .
WD(n, k +i/A) is the pseudo Wigner
distribution approximation. We can simply use .
WD(n, k + i/A) = SMx(n, k + [i/A]) where [i/A] is
the nearest integer to i/A, or use the linear interpolation of the pseudo Wigner distribution (S-method)
values at two nearest integers. The terms in (3.142), when k +i, or k +[i/A] is outside the basic period,
are considered as being zero in order to avoid aliasing.
Example 20.
Consider a real-valued multi-component signal
x(t) = cos (20 sin (πt) + 30πt) + sin (20 cos (πt) + 100πt)
within −1 ≤t < 1, with t = 1/128. In the realization, a Hann(ing) window of the width Tw = 2 is
used. Based on the STFT (using its positive frequencies), the cross-terms free form of the Wigner distri-
bution is obtained from (3.138) with L P = 15, by using the S-method, Figure 3.38a. Then the L-Wigner
distribution, with L = 2, is calculated according to (3.137). It is combined with the linearly interpolated
S-method value into the PWVD (3.142), shown in Figure 3.38b. For the precise implementation of [i/χ]
the lag window has been zero-padded by a factor of 2.
A similar approach can be used for the STFT based realization of the complex time distributions and
all other higher order representations.
3.03.4.6 Higher order ambiguity functions
A speciﬁc class of non-linear frequency modulated signals are the polynomial phase signals. This case
is of importance not only when the phase is of polynomial form, but also in quite general case, when
signals within a smaller time intervals can be approximated by ﬁnite order polynomial functions, using
the Taylor series. By using the multi-lag higher order instantaneous moments the polynomial order of
the phase function is reduced, in several steps, to the linear one. The FT of the multi-lag instantaneous
moments, known as the multi-lag higher order ambiguity function, is used to estimate the highest phase
coefﬁcient. After the original signal is demodulated, the procedure is repeated until all parameters of

3.03.4 Higher Order Time-Frequency Representations
121
0
100
200
300
400
−1
−0.5
0
0.5
1
(a)
Ω
t
0
100
200
300
400
−1
−0.5
0
0.5
1
(b)
Ω
t
FIGURE 3.38
Time-frequency representation of a real-valued multi-component signal: (a) The S-method (cross-terms and
alias free version of the Wigner distribution). (b) Polynomial Wigner-Ville distribution realized based on the
STFT by using the S-method and its order recursive form.
the phase are estimated. The product higher order ambiguity function (PHAF) is introduced to estimate
the polynomial phase signal coefﬁcients in the case of multi-component signals [21,44–46].
Consider a deterministic polynomial phase signal
x

t
 
= A exp ( jϕ(t)) = A exp
⎛
⎝j
P

p=0
αpt p
⎞
⎠
(3.143)
and see what will be the result of an operation corresponding the studied symmetric phase derivative
estimation
ˆ(t) = ϕ(t + τ1) −ϕ(t −τ1)
2τ1
.
In terms of signal, it means
x(t + τ1)x∗(t −τ1) = A2 exp ( j(ϕ(t + τ1) −ϕ(t −τ1)))
= A2 exp
⎛
⎝j
P

p=0
αp(t + τ1)p −j
P

p=0
αp(t −τ1)p
⎞
⎠.
(3.144)
The highest order phase term is transformed into
αP(t + τ1)P −αP(t −τ1)P = 2αPτ1
	
(t + τ1)P−1 + (t + τ1)P−2(t −τ1) + · · · + (t −τ1)P−1
.
Thus, the phase order in t is reduced in x(t + τ1)x∗(t −τ1) to P −1,
R(t, τ1) = x(t + τ1)x∗(t −τ1) = A2 exp
P−1

p=0
βp(τ1)t p.
(3.145)

122
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
The highest order coefﬁcient, with t P−1, in R(t, τ1) is
βP−1(τ1) = 2αPτ1P.
(3.146)
It is possible to continue in this way, by forming
R2(t, τ1, τ2) = R(t + τ2, τ1)R∗(t −τ2, τ1) = A4 exp
P−2

p=0
γp(τ1, τ2)t p.
The highest order coefﬁcient in R2(t, τ1, τ2), according to (3.146), is
γP−1(τ1, τ2) = 2βP−1(τ1)τ2(P −1) = 4αPτ1τ2P(P −1).
After P −1 steps, a pure complex sinusoidal signal in R(t, τ1, τ2, . . . , τP−1) is obtained. The functions
RP−1(t, τ1, τ2, . . . , τP−1) are called the multi-lag higher order instantaneous moments. The coefﬁcient
with t, in the ﬁnal sinusoid is obtained as
0 = 2P−1αPτ1τ2 . . . τP−1P!
(3.147)
It can be calculated by using the multi-lag higher order ambiguity function, deﬁned as the FT of the
multi-lag higher order instantaneous moment,
X P−1(, τ1, τ2, . . . , τP−1) =
 ∞
−∞
RP−1(t, τ1, τ2, . . . , τP−1)e−jt dt,
(3.148)
as
0 = arg

max

X P−1(, τ1, τ2, . . . , τP−1)
+
,
ˆαP =
0
2P−1αPτ1τ2 . . . τP−1P!.
(3.149)
Now, the original signal is demodulated by
x1

t
 
= x(t) exp (−j ˆαPt P),
producing, in an ideal case, a signal with a lower, P −1, order of the phase,
x1

t
 
= A exp
⎛
⎝j
P−1

p=0
αpt p
⎞
⎠.
All previous steps are repeated on x1

t
 
to produce the next highest coefﬁcient ˆαP−1. Here, P −2
steps are performed. In this way lower and lower order coefﬁcients are estimated. Note that if an error in
the estimation of a coefﬁcient ˆαP occurs, it will propagate and cause inaccurate lower order coefﬁcients
estimation.

3.03.4 Higher Order Time-Frequency Representations
123
Example 21.
Consider a third-order (P = 3) polynomial phase signal:
x(t) = A e j(a0+a1t+a2t2+a3t3).
Estimate its highest (third) order coefﬁcient.
The multi-lag higher order instantaneous moments of the signal x(t) are:
x(t) = A e j(a0+a1t+a2t2+a3t3),
R(t, τ1) = x(t + τ1)x∗(t −τ1) = |A|2 e j2a1τ1+2a3τ 3
1 e j4a2τ1te ja36t2τ1,
R2(t, τ1, τ2) = R(t + τ2, τ1)R∗(t −τ2, τ1) = |A|4 e j8a2τ1τ2e ja324τ1τ2t.
The multi-lag higher order ambiguity function is the FT (over t) of R2(t, τ1, τ2), i.e.,
X2(, τ1, τ2) = FTt{R2(t, τ1, τ2)} = 2π |A|4 e j8a2τ1τ2δ( −24a3τ1τ2).
Obviously, from the position of the FT maximum, at
0 = 24a3τ1τ2
(3.150)
follows
ˆα3 =
0
24τ1τ2
= a3.
The estimated coefﬁcient can be used to unwrap the original signal to
x1(t) = x

t
 
e−j ˆα3t3 = A e j(a0+a1t+a2t2+a3t3)e−ja3t3,
= A e j(a0+a1t+a2t2).
Now the multi-lag higher order instantaneous moments of the signal x1(t) are calculated
x1(t) = A e j(a0+a1t+a2t2),
R(t, τ1) = x1(t + τ1)x∗
1(t −τ1) = |A|2 e j2a1τ1 e ja24tτ1.
The FT is
X(, τ1) = FTt{R(t, τ1)} = 2π |A|2 e j2a1τ1δ( −4a2τ1)
with 0 = 4a2τ1 and ˆα2 = 0/(4τ1) = a2.
The estimated coefﬁcient is used to unwrap x1(t), as
x11(t) = x1(t)e−j ˆα2t2 = Ae j(a0+a1t).
Now the FT of x11(t), X1() = 2π Ae ja0δ( −a1), produces a1 and a0.

124
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
When x(t) is a multi-component polynomial phase signal, i.e.,
x

t
 
=
K

k=1
Ak exp
⎛
⎝j
P

p=0
αk,pt p
⎞
⎠,
(3.151)
where αk,p are the coefﬁcients of the kth component, the Pth order multi-lag higher instantaneous
moments will contain K sinusoids that correspond to the auto-terms. Each auto-term has the frequency
proportional tothecorrespondinghighest order phasecoefﬁcient. Inadditiontotheauto-terms, themulti-
lag higher instantaneous moments will contain a large number of cross-terms which are, in general,
Pth order polynomial phase signals. When the highest order phase coefﬁcients of some components
coincide, the corresponding cross-terms are complex sinusoids, implying that some of the peaks in the
multi-lag higher order ambiguity function correspond to the cross-terms. The maxima based estimation
of phase coefﬁcients is ambiguous, since a peak corresponding to a cross-term can be detected as a
maximum, leading to a false estimation.
The effect of cross-terms can be considerably attenuated by using the product higher order ambiguity
function (PHAF). The PHAF is based on the fact that, unlike the cross-terms, the auto-terms are at
frequencies proportional to the product of time lags used for the calculation of the multi-lag higher
order ambiguity function.
3.03.5 Processing of sparse signals in time-frequency
A signal is sparse in a certain transform domain if it contains a small number of nonzero coefﬁcients when
compared to the original discrete signal length. In the case of sparse signals, signal reconstruction can be
performed by using a fewer number of randomly chosen signal samples. This kind of signal acquisition is
referred to as compressive sensing. Compressive sensing is based on powerful mathematical algorithms
for error minimization [47–49]. The compressive sensing concepts are able to reconstruct the original
signal by using a small set of signal samples. Sparsity is one of the main requirements that should
be satisﬁed, in order to efﬁciently apply the compressive sensing. If the signal is not sparse, then the
compressive sensing cannot recover signal successfully. Sparsity in time-frequency analysis is closely
related to the signal concentration measures, especially the concentration measures being equal to the
area of the time-frequency region with non-zero time-frequency distribution values [50]. Thus, before
explaining the basic principles of processing of sparse signals in time-frequency, concentration measures
will be shortly reviewed.
3.03.5.1 Concentration measures
Concentration measures in time-frequency analysis were introduced in the sense of the optimization of
time-frequency presentations. Concentration measures are used for measurement of the representations
quality. Intuitively we can assume that better concentration in time-frequency domain means that the
signal energy is focused within smaller time-frequency region. Concentration measure can provide a
quantitative criterion for evaluation of various representations performance. It can be used for adaptive
and automatic parameter selection in time-frequency analysis, without supervision of a user.

3.03.5 Processing of Sparse Signals in Time-Frequency
125
In most cases, some quantities from statistics and information theory were the inspiration for deﬁning
concentration measures of time-frequency representations. The basic idea for measuring time-frequency
representation concentration can be explained on a simpliﬁed example motivated by the probability
theory. Consider a set of N non-negative numbers {p1, p2, . . . , pN}, such that
p1 + p2 + · · · + pN = 1.
(3.152)
Form a simple test function
M(p1, p2, . . . , pN) = p2
1 + p2
2 + · · · + p2
N.
It is easy to conclude that M(p1, p2, . . . , pN), under the constraint p1 + p2 + · · · + pN = 1, has the
minimal value for p1 = p2 = · · · = pN = 1/N, i.e., for maximally spread values of p1, p2, . . . , pN.
The highest value of M(p1, p2, . . . , pN), under the same constraint, is achieved when only one pi is
different from zero, pi = δ(i −˙i0), where i0 is an arbitrary integer 1 ≤i0 ≤N. This case corresponds
to the maximally concentrated values of p1, p2, . . . , pN, at a single pi0 = 1. Therefore, the function
M(p1, p2, . . . , pN) can be used as a measure of concentration of the set of numbers p1, p2, . . . , pN,
under the unity sum constraint. In general, constraint (3.152) can be included in the function itself by
using the form
M(p1, p2, . . . , pN) =
p2
1 + p2
2 + · · · + p2
N

p1 + p2 + · · · + pN
 2 .
For non-negative p1, p2, . . . , pN this function has the minimum for p1 = p2 = · · · = pN, and reaches
its maximal value when only one pi is different from zero.
In time-frequency analysis this idea has been used in order to measure the time-frequency represen-
tations concentration. Several forms of the concentration measure, based on this fundamental idea, are
introduced. Applying the previous reasoning to the spectrogram we may write a function for measuring
the concentration of the SPEC(n, k) and corresponding STFT(n, k) as:
M[SPEC(n, k)] =
)
n
)
k |SPEC(n, k)|2
)
n
)
k |SPEC(n, k)| 2 =
)
n
)
k |STFT(n, k)|4
)
n
)
k |STFT(n, k)|2 2 .
(3.153)
This form is just the fourth power of the ratio of the fourth and second order norms of STFT(n, k).
High values of M indicate that the representation STFT(n, k) is highly concentrated, and vice versa.
In general, it has been shown (Jones, Parks, Baraniuk, Flandrin, Williams, et al.) that any other ratio of
norms L p and Lq, p > q > 1, can also be used for measuring the concentration of STFT(n, k).
When there are two or more components (or regions in time-frequency plane of a single component)
of approximately equal energies (importance), whose concentrations are very different, the norm based
measures will favor the distribution with a “peaky” component, due to raising of distribution values to a
high power. It means that if one component (region) is “extremely highly” concentrated, and all the others
are “very poorly” concentrated, then the measure will not look for a trade-off, when all components are
“well” concentrated. In order to deal with this kind of problems, common in time-frequency analysis,
a concentration measure could be applied to smaller, local time-frequency regions with a localization
weighting function which determines the region where the concentration is measured.

126
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
Another direction to measure time-frequency representation concentration (analyzed by Stankovi´c
[50]) comes from a classical deﬁnition of the time-limited signal duration, rather than measuring signal
peakedness. If a signal x(n) is time-limited to the interval n ∈[n1, n2 −1], i.e., x(n) ̸= 0 only for
n ∈[n1, n2 −1], then the duration of x(n) is d = n2 −n1. It can be written as
d = lim
p→∞

n
|x(n)|1/p = ∥x(n)∥0 ,
(3.154)
where ∥x(n)∥0 denotes the norm zero of signal. The same deﬁnition applied to a two-dimensional
function |P(n, k)|2 ̸= 0 only for (n, k) ∈Dx, gives
ND = lim
p→∞

n

k
|P(n, k)|1/p ,
(3.155)
where ND is the number of points within Dx. In reality, there is no a sharp edge between |P(n, k)|2 ̸= 0
and |P(n, k)|2 = 0, so the value of (3.155) could, for very large p, be sensitive to small values of
|P(n, k)|2. The robustness may be achieved by using lower order forms, with p ≥1 in contrast to
(3.153) where, in this notation, p = 1/2.
Therefore, the spectrogram concentration can be measured with the function of the form
μ[SPEC(n, k)] =

n

k
|STFT(n, k)|2/p
(3.156)
with p > 1. Here, lower value of the concentration measure μ indicates better concentrated distribution.
For example, with p = 2, it is of the norm one form
μ[SPEC(n, k)] =

n

k
|STFT(n, k)| = ∥STFT(n, k)∥1.
In the case that variations of amplitude may be expected, an energy normalized version of mea-
sure μ[SPEC(n, k)] =
)
n
)
k |STFT(n, k)| 2 / )
n
)
k |STFT(n, k)|2 should be used. Concentration
measures were efﬁciently uses to optimize time-frequency representations parameters.
In the probability theory all results are derived for the probability values pi, assuming that )
i pi = 1
and pi ≥0. The same assumptions are made in classical signal analysis for the signal power. Since
a general time-frequency representation commonly does not satisfy non-negativity condition, the con-
centration measures should be carefully used, in that cases.
3.03.5.2 Sparse signals
In signal processing representations a signal is transformed from one domain into another. In many cases
it happens that a signal that covers whole considered interval in one domain (dense in that domain) is
located within much smaller regions in the other domain (sparse in this domain). For example, a discrete
time complex sinusoidal signal with N samples in discrete time domain, is just one sample in the DFT
domain (if the frequency is on a grid position). Similarly, M complex sinusoids covering N points in
discrete time domain, are represented by M values in frequency domain. This simple illustration leads

3.03.5 Processing of Sparse Signals in Time-Frequency
127
to the conclusion that, for a complex signal containing M complex sinusoids, we do not need N samples
in time domain, to reconstruct K samples in frequency domain. Then, it would be enough to have
M < K < N arbitrary and independent samples in time domain. Of course, the Fourier domain is just
one of possible domains to transform a signal. A signal may not be sparse in the time domain nor in
the Fourier domain, but could be, for example, sparse in polynomial Fourier domain or in the fractional
Fourier domain (a linear FM signal transforms into a one value in frequency and rate domain) or in the
STFT domain. Then, we will also be able to reconstruct the original signal if some samples are missing.
The samples could be missed due to their physical or measurements unavailability. In applications
it could happen that some, arbitrary positioned, samples of the signal are so heavily corrupted by
disturbances, that it is better to omit them in the analysis. Under some conditions, the processing could
be performed with the remaining samples, almost as in the case if missing samples were available. Of
course, some a priori information about the nature of the analyzed signal, its sparsity in a known domain,
should be used. Compressive sensing is a ﬁeld dealing with this problem and provides a solution that
differs from the classical signal theory approach. Sparsity is one of the main requirements that should
be satisﬁed, in order to efﬁciently apply the compressive sensing.
Example 22.
Four samples of a simple complex valued signal in discrete time domain are considered,
x(0) = 0.866 + j0.5, x(1) = −0.5 + j0.866, x(2) is missing and x(3) = 0.5 −j0.866. The third
sample is missing (not available or heavily corrupted). We know that the signal is sparse in the STFT
domain, as well as that its real and imaginary values are somewhere between −1 and 1. Find the value
of the third sample that will produce the best concentrated STFT of this signal, for a given instant n = 0.
For the signal x(n), with the missing sample being replaced by α + jβ, the STFT is of the form
STFT(0, k) =
3

n=0
x(0 + m)e−jmkπ/2
= x(0) + x(1)e−jkπ/2 +

α + jβ
 
e−jkπ + x(3)e−j3kπ/2,
STFT(0, 0) = 0.866 + j0.5 + α + jβ,
STFT(0, 1) = 2.598 + j1.5 −

α + jβ
 
,
STFT(0, 2) = 0.866 + j0.5 + α + jβ,
STFT(0, 3) = −0.866 −j0.5 −

α + jβ
 
.
Using the measure of concentration of the resulting STFT in the form
M(α, β) =
3

k=0
|STFT(k)|
(3.157)
and varying parameters α and β from −1 to 1, with step 0.001, we get the global minimum of M(α, β) at
M(−0.866, −0.500) = 4.
It means that the missing sample, producing the best concentrated STFT, is
x(2) = −0.866 −j0.5.

128
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
Then, STFT(0, 0) = 0, STFT(0, 1) = 0, STFT(2) = 3.4641 + j2 and STFT(0, 3) = 0.
Now reformulate this problem into matrix form. Denote the full DFT transformation matrix with
W =
⎡
⎢⎢⎣
1
1
1
1
1 e−j2π/N
e−j4π/N
e−j6π/N
1 e−j4π/N
e−j8π/N
e−j12π/N
1 e−j6π/N
e−j12π/N
e−j18π/N
⎤
⎥⎥⎦,
STFT(0) = Wx(0),
x(0) = W−1STFT(0),
where x(0) is a vector column with the signal values and STFT(0) is a vector column with the STFT
values, for n = 0. In the case of missing second signal sample, for the STFT coefﬁcients calculation,
we get three equations.
instant 0:
x(0) = 1
4

STFT(0, 0) + STFT(0, 1) + STFT(0, 2) + STFT(0, 3)
 
,
instant 1:
x(1) = 1
4

STFT(0, 0) + STFT(0, 1)e j2π/N + STFT(0, 2)e j4π/N + STFT(0, 3)e j6π/N
,
instant 2:
Missing value and equation.
instant 3:
x(3) = 1
4

STFT(0, 0) + STFT(0, 1)e j8π/N + STFT(0, 2)e j12π/N + STFT(0, 3)e j18π/N
.
The transformation matrix
W−1= 1
N
⎡
⎢⎢⎣
1
1
1
1
1 e j2π/N
e j4π/N
e j6π/N
1 e j4π/N
e j8π/N
e j12π/N
1 e j6π/N
e j12π/N
e j18π/N
⎤
⎥⎥⎦
is now reduced, by omitting the third row, to
A = 1
N
⎡
⎣
1
1
1
1
1 e j2π/N
e j4π/N
e j6π/N
1 e j6π/N
e j12π/N
e j18π/N
⎤
⎦
with
y = A STFT(0).
(3.158)

3.03.5 Processing of Sparse Signals in Time-Frequency
129
Thus, we have three equations with three signal samples x(n) in vector
y = [x(0), x(1), x(3)]T
and four unknown STFT values STFT(0, k) in vector
STFT(0)= [STFT(0, 0) STFT(0, 1) STFT(0, 2) STFT(0, 3)]T .
By varying the value for x(2) we have solved undetermined problem, as a minimization problem,
min ∥STFT(0)∥subject to y = A STFT(0),
(3.159)
where for ∥STFT(0)∥, the absolute value concentration measure is used, presented and discussed in
Chapter 2,
∥STFT(0)∥=
N−1

k=0
|STFT(0, k)| .
(3.160)
This measure is known as l1 norm, in notation ∥STFT(0)∥l1. Of course, other concentration measures,
describedintheprevioussection,arepossible,aswell.Themeasure ND = lim p→∞
)
n
)
k |P(n, k)|1/p
corresponds to l0 norm.
It is important to note the minimization solution with the l2 norm, would be trivial, in this case. For
this norm, we would attempt to minimize
∥STFT(0)∥l2 =
N−1

k=0
|STFT(0, k)|2 .
According to the Parseval’s theorem
∥STFT(0)∥l2 = N
N−1

n=0
|x(n)|2 .
(3.161)
Since, any value than x(n) = 0 for the non-available (missing) signal samples, would increase
∥STFT(0)∥2, then the solution for the non-available samples, with respect to the l2 norm, is trivial.
This was the reason why this norm was not used as a concentration measure.
Based on the previous example we may easily write a general sparse signals’ processing formulation.
Let the original signal be x(n) with n = 0, 1, . . . , N −1. Suppose that an arbitrary number of N −K
signal values are missing. Then, the available K signal values are denoted by vector y. If we denote by
A the inverse transformation matrix W−1 with omitted rows, corresponding to missing signal values,
then for the DFT coefﬁcients we have to solve K equations
y = A STFT(n)
with N unknowns. Thus, we have to ﬁnd the best concentrated STFT(n), solving the minimization
problem
min ∥STFT(n)∥subject to y = A STFT(n),
(3.162)
where ∥STFT(n)∥=
N−1

k=0
|STFT(n, k)| .

130
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
The condition that we will obtain a satisfactory result is that the considered signal was sparse in DFT
domain.
Consider a signal with unavailable samples, knowing that it is well concentrated and sparse in the
Wigner distribution domain. If a small number of samples is missing (eliminated), then we can still
calculate the Wigner distribution with missing samples as parameters and ﬁnd the parameter values
(missing samples) that produce the best concentration. For example, it would follow as the ones pro-
ducing minimum of
μ[WD(n, k)] =
N

k=1
N

n=1
|WD(n, k)|1/2 ,
since the Wigner distribution is energy distribution (the same form we used for an energetic version of
the FT |STFT(n)| = )N−1
k=0 |STFT(n, k)|). More often a measure with power 1 is used rather than 1/2,
corresponding to the l1 norm. If the exponent is 0 it will be l0 norm.
Another approach to the Wigner distribution based sparse signals’ processing is in the Fourier domain
formulation of the Wigner distribution proposed by Flandrin and Borgnat. It is a two-dimensional FT
of the ambiguity function
AF(p,l) =
N

k=1
N

n=1
WD(n, k)e−j2π(np−kl)/N.
(3.163)
This relation was used for efﬁcient deﬁnition of the reduced interference distribution. The ambiguity
function was multiplied by a low-pass kernel function. Here, we will use a different approach. A large
part of the ambiguity domain values will be not multiplied by zero kernel function, but they will be
just omitted and considered as unavailable. Only a small region around the ambiguity origin, where we
know that the auto-terms are located, is used. Then, we try to reconstruct other values (now missing,
since we removed them from analysis). Then, the linear programming formulation is based on
min
*****
N

k=1
N

n=1
|WD(n, k)|
***** subject to
(3.164)
N

k=1
N

n=1
WD(n, k)e−j2π(np−kl)/N = 1
N AF(p,l), for K selected points in (p,l).
Now, we have a complete formulation of the problem within the sparse signal processing framework.
We have reduced the formulation of this problem to the linear programming problem with norm one. It
can be then solved by using appropriate minimization algorithms.
Possible variation of this approach is when using highly concentrated distributions with reduced
cross-terms, like for example the S-method. Then, the ambiguity function of this distribution AFSM(p,l)
is used in the appropriate minimization problem over SM(n, k). In this case, we make two different
efforts to the same direction, to obtain a highly concentrated representation without cross-terms. The
marginal properties will be satisﬁed if within the K selected points in (p,l) all the values of AF(p,l)
along p = 0 or l = 0 are included.

3.03.5 Processing of Sparse Signals in Time-Frequency
131
3.03.5.3 Compressive sensing and the L-statistics in time-frequency
The compressive sensing (CS) processing of sparse signals, in combination with the L-statistics, has
recently been used in time-frequency analysis to separate a set of time-varying signals from an unknown
sparse signal in Fourier domain, by Stankovi´c et al. [51]. A case when these two sets of components
overlap in a signiﬁcant part of the time-frequency plane is considered. Different components of sparse
signal intersect non-stationary components at different, time-varying frequency intervals. By removing
overlapping points or intervals, a signal with large number of missing measurements in time-frequency
plane is formed, corresponding to a CS signal with time and frequency varying CS matrix. The CS
observations are taken in the time-frequency domain, rather than in time domain. This case can be
encountered in radar signal processing, where in many applications there are micro-Doppler effects that
can obscure rigid body points, rendering the radar image ineffective. Similar situation may, for example,
appear in communications, when narrowband signals are disturbed by a frequency hopping jammer that
is of shorter duration than the considered time-interval. Any other non-stationary jammer, with high
values and a large number of crossing points, lead to the same time-frequency varying CS formulation.
Since is has been assumed that components overlap in a signiﬁcant part of time-frequency plane, linear
signal transforms are used, in order to avoid dealing with emphatic cross-terms, spread over the entire
time-frequency plane. Since, the ﬁnal aim is the signal reconstruction, by using linear time-frequency
representations the components phases will be preserved.
The theory presented here may be considered as a variant of the CS approach in time-frequency
domain, being applied to the STFT as a time-frequency representation. The standard CS approach in
time domain can be viewed as a special case. In the standard CS deﬁnition, some points in time domain
are not available. In the time-frequency domain it would mean that these values are not available for
some time intervals and all frequencies, corresponding to these intervals. Thus, the standard CS approach
in time domain is just a special case of the case with missing arbitrary positioned measurements in the
time-frequency domain.
Consider a discrete-time signal x(n) of the length N and its discrete Fourier transform (DFT) X(k).
The STFT, with a rectangular window of the width M, in a matrix form, can be written as:
STFTM(n) = WMx(n),
(3.165)
where STFTM(n) and x(n) are vectors:
STFTM(n) = [STFT(n, 0), . . . , STFT(n, M −1)]T ,
(3.166)
x(n) = [x(n), x(n + 1), . . . , x(n + M −1)]T ,
and WM is the M × M DFT matrix with coefﬁcients WM(m, k) = exp (−j2πkm/M). Considering
non-overlapping cases, the next STFT will be calculated at instant n+ M, as follows STFTM(n+ M) =
WMx(n + M). Combining all STFT vectors in a single equation, we obtain:
STFT = WM,Nx.
(3.167)

132
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
The resulting STFT matrix is
STFT =
⎡
⎢⎢⎢⎣
STFTM(0)
STFTM(M)
...
STFTM(N −M)
⎤
⎥⎥⎥⎦
and the coefﬁcients N × N matrix is formed as:
WM,N=
⎡
⎢⎢⎢⎣
WM
0M
· · ·
0M
0M
WM
· · ·
0M
...
...
...
...
0M
0M
· · · WM
⎤
⎥⎥⎥⎦,
(3.168)
where 0M is a M × M matrix with all 0 elements. The vector [x(0), x(M), . . . , x(N −M)]T is the
signal vectorx, since:
x = [x(0), x(M), . . . , x(N −M)]T
(3.169)
= [x(0), x(1), . . . , x(N −1)]T .
Expressing the above vector in the Fourier domain,
x = W−1
N X,
(3.170)
where W−1
N denotes the inverse DFT matrix of the dimension N × N and X is the DFT vector, we have:
⎡
⎢⎢⎢⎣
STFTM(0)
STFTM(M)
...
STFTM(N −M)
⎤
⎥⎥⎥⎦= WM,NW−1
N
⎡
⎢⎢⎢⎣
X(0)
X(1)
...
X(N −1)
⎤
⎥⎥⎥⎦.
(3.171)
Accordingly, the relation between the STFT and DFT values can be written as follows:
STFT = A X.
(3.172)
Matrix A = WM,NW−1
N maps the global frequency information in X into local frequency information
in STFT.
As previously explained, we will not use all the STFT points, since a large number of them will be
considered as corrupted and thus will be omitted. Consequently, they will be considered as unavailable.
This corresponds to the CS approach in the time-frequency domain, where only some of the STFT
values (measurements) are available.
The separation of time-frequency points, that can be declared as the CS points (intervals), belonging
to the sparse stationary signal, will be done by using the L-statistics. For each frequency k, a vector of
STFT in time is formed
Sk(n) = [STFT(n, k), n = 0, M, . . . , N −M].
After sorting the elements of Sk(n), for a given frequency k, we obtain a new ordered set of elements
k(n) ∈Sk(n)

3.03.5 Processing of Sparse Signals in Time-Frequency
133
such that
|k(0)| ≤|k(1)| ≤· · · ≤|k(N −M)|.
In the L-statistics form, we omit NQ of the highest values of k(n) for each k. Note that, in some cases,
the overlapping components of the same order of amplitude may decrease the intersection value. This
happens when a disturbing component of the same value crosses the desired signal with the opposite
phase. These cases may also efﬁciently be treated within the L-statistics framework, by omitting some
of the lowest L-statistics values, in addition to NQ highest values. The omitted values of the STFT are
heavily corrupted. Thus, they are declared as useless or unavailable in the CS framework. The rest of
the STFT values is considered as CS in the time-frequency plane.
Denote now the vector of available STFT values by STFTCS. The corresponding CS matrix ACS
is formed by omitting the rows corresponding to the omitted STFT values. We want to reconstruct
the original sparse stationary signal, since it produces the best concentrated FT X(k). Therefore, the
corresponding minimization problem can be deﬁned as follows:
min ∥X∥= min
N−1

k=0
|X(k)|
(3.173)
subject to STFTCS = ACSX.
Thus, based on the STFTCS values, we are going to reconstruct the missing values such to provide
minimal )N−1
k=0 |X(k)|. This is a well known CS formulation of the problem that can be solved by using
linear programming tools.
Example 23.
Consider a signal that consists four complex sinusoids
x(n) = e j256πn/N + 1.5e−j2568πn/N+ jπ/8 + 0.7e j512πn/N+ jπ/4 + e−j512πn/N−jπ/3
with non-stationary disturbance in form of several short duration sinusoidal signals (some of them are
at the same frequencies as the stationary sinusoids) and four sinusoidally modulated signals. The signal
in time domain is shown in Figure 3.39.
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
−20
0
20
40
60
80
time
signal
FIGURE 3.39
Signal composed of a sparse part and a non-stationary part.

134
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
frequency
time
Absolute STFT values
(a)
frequency
index
(b)
frequency
time
CS mask in time−frequency
(c)
frequency
time
(d)
FIGURE 3.40
(a) The STFT of the composite signal. (b) Sorted values of the absolute STFT. (c) The compressive sensing
mask corresponding to the L-statistics based STFT values. (d) The STFT values that remain after applying
the compressive sensing mask on the absolute values of the STFT.
Its STFT is calculated for N = 1024 and M = 32. The STFT of the signal is presented in Figure 3.40
(left). After the L-statistics is performed and 50% of the largest values are removed, along with 10%
of the smallest values, the CS form of the STFT, with only 40% of the original values is obtained,
Figure 3.40 (middle). The STFT values that remained after the L-statistics based removal are shown in
Figure 3.40 (right).
The reconstruction is performed, based on the STFT values form Figure 3.40 (right). The recon-
structed signal’s FT is equal to the original FT, preserving amplitude and phase. Its amplitude is shown
in Figure 3.41 (bottom), along with the original FT of the signal Figure 3.41 (top).

3.03.6 Examples of Time-Frequency Analysis Applications
135
0
100
200
300
400
500
600
700
800
900
1000
0
1000
2000
3000
Fourier transform of the signal
0
100
200
300
400
500
600
700
800
900
1000
0
500
1000
1500
2000
Fourier transform of the reconstructed signal
frequency
FIGURE 3.41
Reconstructed Fourier transform by using the compressive sensing method of the STFT presented in the
previous ﬁgure corresponding to the sparse part of the composite signal (bottom) and the Fourier transform
of the original signal (top).
3.03.6 Examples of time-frequency analysis applications
In this section we present just a few of many possible applications of time-frequency analysis [6,12,
30,52–62]. We will explain the basic principles of the application area and its formulation within the
time-frequency framework. It will be emphasized what beneﬁts may be achieved by using the time-
frequency representations, over the classical tools. Since many of the presented time-frequency tools
may be then applied on such a formulated problem, it is left to the reader to apply other time-frequency
tools, with their advantages and drawbacks.
3.03.6.1 Time-frequency radar signal processing
When radar transmits an electromagnetic signal to a target, the signal reﬂects from it and returns to
radar. The reﬂected signal, as compared to the transmitted signal, is delayed, changed in amplitude,
and possibly shifted in frequency. These parameters of the received signal contain information about
the target’s characteristics. For example, delay is related to the target’s distance from the radar, while

136
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
the target’s velocity is related to the shift in frequency. Inverse synthetic aperture radar (ISAR) is a
method for obtaining high resolution image of a target based on the change in viewing angle of the
target with respect to the ﬁxed radar. Rotation, as a result of this angle change, introduces addition
velocity proportional to the rotation speed and the distance from the rotation center. Component of the
velocity in direction of the radar-target line is proportional to the normal distance of the point from
the center of rotation. Thus, in the case of ISAR, the distance and the velocity locate the target point
in the range-cross range domain. Since the range and cross range information are contained in two
dimensional sinusoids with corresponding frequencies, common technique used for the ISAR signal
analysis is the two dimensional FT. The application of the FT application on the ISAR signal of a point
target results in a highly concentrated function at a point whose position corresponds to the range and
cross range values. Similar situation appears in synthetic aperture radar (SAR) signal processing.
The basic property in spectral analysis is that higher concentration of the FT is achieved by using
longer signal sequences. However, within longer time intervals the target point velocity changes its
direction, meaning that even constant rotation speed results in the velocity projection changes. These
changes cause corresponding frequency changes, that spread FT, blurring information about the cross
range. The rotation itself can be non-constant, increasing the radar image distortion. In addition to these
disturbances in the radar image, target motion can also be three dimensional, changing the velocity
projection along the target-radar line in a very complex way. Standard techniques for these kind of
problems are in movement compensation by using time-frequency analysis base tools.
Another problem in radar imaging where the time-frequency analysis is used is the micro-Doppler
effect processing. Namely, very fast moving parts of a radar target can cause micro-Doppler effect that
can cover rigid parts of a target or degrade the ISAR image. Separation of patterns caused by rigid
parts of the target from the patterns caused by fast moving parts is an interesting area of time-frequency
analysis application.
Micro-Doppler effect appears in the ISAR radar imaging when the target has one or more very fast
moving parts. This effect can decrease the readability of radar images. However, the micro-Doppler
effect, at the same time, carries information about the features of moving parts (type, velocity, size, etc.).
Procedures for separation of signals coming from the rigid (slow moving) body and fast moving
parts are based on the time-frequency (more accurately space/spatial-frequency) analysis of the return
signal within the CIT.
Based on the order statistics of time-frequency representations, it is possible to make a decision
if the components belong to the rigid body or to the rotating target parts. Another approach is based
on the Radon transform of the time-frequency representation of signal returned from rotating parts
which produce sinusoidal FM signals. A time-frequency representation of the sinusoidal FM signal
can be concentrated in a single point by applying the inverse Radon transform to the time-frequency
representation. In this way, patterns of the rotating parts can be easily extracted from the signal mixture.
Another application of time-frequency analysis in radars is related to the spacial localization of
sources by passive sensor array. Direction-of-arrival (DOA) is the key parameter in this problem. Most
of the DOA estimators are based on the estimates of the data covariance matrix. In the case when phase
of the input is not linear, then the time-frequency distributions may be used to analyze the data snapshots
across the array. This kind of distributions is known as spatial time-frequency distributions. They are
able to spread the noise energy over the entire time-frequency plane, while localizing the energy of the
input signals, in the cases of non-linear phases. Better localization of signals permits the division of

3.03.6 Examples of Time-Frequency Analysis Applications
137
the time-frequency domain into smaller regions, each containing fewer signals than the input signal on
the array. It relaxes the condition on the array aperture and simpliﬁes optimization procedures.
3.03.6.2 Biomedical signal analysis
Biomedical signals usually contain interferences of different nature. The separation of undesirable
content from the considered signal is easier in joint-time-frequency plane. In some cases the detec-
tion of frequency content changes and irregularities carry the most important information about the
underlying process. Thus, analysis of highly non-stationary signals in biomedicine could beneﬁt from
using time-frequency tools. Such examples are EEG analysis in epilepsy patients, ECG analysis of car-
diac abnormalities, identiﬁcation of genetic abnormalities in brain tumors, early detection of multiple
sclerosis lesions, study of pediatric disorders, or analysis of respiration sounds in asthmatic patients.
3.03.6.3 Seismic signal analysis
Earthquakes analysis is very important since they cause many catastrophes all over the world. One of the
application in the analysis of seismic signals is in their reliable detection. Due to the high probability of
false earthquake alarms when the seismometers detect non-seismic signals, the time-frequency analysis
can be used for seismic signal separation and detection. It is based on the instantaneous frequency
analysis. Analyzing the energy of seismic signal it is possible to decide and send an earthquake alarm
if the energy above a speciﬁc level.
Seismic signals are also used in the analysis of propagation media, with application, for example,
in gas and oil detection. Seismic wave is a periodic wave which can transmit energy through the media
without causing their permanent deformation. The p-waves and s-waves are the waves used for the
time-frequency analysis. Seismic reﬂection patterns can provide information of subsurface imaging
by using the time-frequency tools (seismic stratigraphy). Analyzing the received reﬂected signal and
its energy at the surface, it is possible to observe the characteristics of subsurfaces where the signal
propagated. The subsurface imaging is widely used in gas and oil detection. A quantitative analysis in
seismic reﬂection patterns, in order to get more information of geology by seismic reﬂection pattern, is
possible by using the time-frequency analysis.
3.03.6.4 Car engine signal analysis
Structure-borne sound signals and more seldom pressure signals are used for efﬁcient combustion
control of spark-ignition engines. This control can increase efﬁciency, reduce pollution and noise, and
protect against knocks. A knock is an abnormal combustion that causes a rapid rise of the temperature
and pressure. Its detection is an important problem since a frequent knock occurrence can destroy the
engine or signiﬁcantly degrade its performances. By measuring the pressure at a suitable point inside the
cylinder we can observe the combustions. However pressure sensors are expensive, difﬁcult to mount
and not robust enough. These are the reasons why their application is mainly limited to test beds. Sound
signals can be considered as time-varying ﬁltered versions of the pressure and can be used for the
observation of diagnostic parameters, as resonance frequencies that are function of temperature, and
resonance energies that indicate knock. The application of acceleration sensors on the surface of the

138
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
engine is easy and economical, but sound signals are superimposed with mechanical noise that can
signiﬁcantly inﬂuence the analysis.
Such sound and pressure signals are highly non-stationary, therefore classical signal analysis tools in
time domain or in frequency domains are no efﬁcient here. Even the short-time Fourier transform and
its energetic version spectrogram, as extensions of the Fourier analysis to the non-stationary problems,
cannot be used due to high non-stationary effects in the car engine signals. These signals require higher
resolution joint time-frequency analysis. It has been shown that pressure signals and sound signals can be
considered as frequency modulated multi-component signals with random amplitudes and phases of the
components when low frequency parts are neglected. Due to cyclostationarity and the property that the
components of these signals are mutually not correlated, it has been found that the Wigner spectrum can
be used as an efﬁcient time-frequency tool for their analysis. The problem of cross-terms in the Wigner
distribution was resolved by averaging over pressure or sound signals of different combustion cycles of
the engine under similar working conditions. Since the components are not correlated the cross-terms
disappear and theoretically, using an inﬁnite number of combustions, the mean of Wigner distributions
converges to the Wigner-Ville spectrum containing the auto-terms only. The main disadvantage of this
approach is that the elimination of cross-terms requires a large number of combustions meaning a long
observation time and can mask the effects in a single combustion or a decision based on the analysis
can be too late for an action. Reduced interference time-frequency distributions are efﬁciently used for
a single realization based analysis and knock detection.
3.03.6.5 Velocities of moving objects in video sequence
In some video surveillance applications it is important to detect an analyze object motion in a video
sequence. A common approach for this problem is based on frame projections and the SLIDE (subspace-
based line detection) algorithm. A key step of the SLIDE algorithm is to map a line into a complex
sinusoid. By using frame projections on coordinate axes the velocity of an object is mapped into an
image, containing lines. In order to transform line parameters to the complex sinusoid parameters,
the SLIDE algorithm with constant μ-propagation is applied. Very accurate results are obtained when
objects have uniform velocities. However, for non-uniform velocities the SLIDE algorithm produces a
frequency modulated signal. This is the reason why the instantaneous frequency estimators, based on
the time-frequency distributions, are introduced in this area and efﬁciently used.
3.03.6.6 Time-variant ﬁltering
Speech signals are highly non-stationary, with a wide dynamic range of multiple frequency components
in the short-time spectra. Time-frequency distributions have been introduced for the analysis frequency
components as a function of time of non-stationary signals. The most common time-frequency rep-
resentation, the spectrogram, is characterized by a trade-off between time and frequency resolutions.
Consequently, the development of other quadratic time-frequency distributions for representation and
processing of non-stationary signals is an interesting challenge. For example, a possible application is
the Wiener optimum ﬁltering of speech signals corrupted by noise. A more accurate estimation of the
signal spectrum yields higher suppression of noise components.
Because of the non-stationary nature of speech signals, statistically optimum ﬁltering requires time-
variant ﬁltering methods. Filtering in the time-frequency domain could be advantageous compared to

3.03.6 Examples of Time-Frequency Analysis Applications
139
separate ﬁltering in the time or frequency domain. Since there exists no unique deﬁnition of time-
frequency spectra, many approaches for time-variant ﬁltering have been proposed. Zadeh suggested
to use the Rihaczek distribution. However, this time-frequency spectrum is complex valued and badly
concentrated in time. Therefore, ﬁltering in the time-frequency domain has been redeﬁned using the
Wigner distribution, using the Weyl correspondence. The time-variant transfer function has been deﬁned
as the Weyl symbol mapping of the impulse response into the time-frequency plane. The Wigner spec-
trum is used in order to average out the cross-terms. For single-realization cases, reduced interference
distributions are used.
3.03.6.7 Interference rejection in spread spectrum systems
Spread spectrum is a transmission coding technique used in digital telecommunication systems, where
pseudo-noise, or pseudo-random code, independent of the information data, is employed as a mod-
ulation waveform. The pseudo-random code signiﬁcantly expands the bandwidth of original signal.
The spread signal has a lower power density, but the same total power. At the receiver side signal is
“despreaded” using the synchronized replica of the pseudo-noise code. Spread spectrum technology
has been recognized as a good alternative to both frequency division multiple access (FDMA) and time
division multiple access (TDMA) for the cellular systems. The most common spread spectrum systems
are of the direct sequence or frequency hopping type. Direct sequence spread spectrum systems employ
a high-speed code sequence to introduce rapid phase transitions into the carrier containing the data. The
result of modulating the carrier is a signal centered at the carrier frequency, but with main lobe band-
width signiﬁcantly wider than the original bandwidth. The frequency hopping spread spectrum achieves
the band spreading by using the pseudo-noise sequence to pseudo-randomly hop the carrier frequency.
While the inﬂuence of low power interfering signals is signiﬁcantly reduced by despreading process
at the receiver, in case of very high power interferences preprocessing is required. This is a common
case, when the interference stations are much closer to the receiver than the signal transmitting station.
Different methods have been proposed for rejection or mitigation of interferences of this kind, in
order to improve robustness of spread spectrum systems and more reliable receiving and decoding of the
useful signal. Amin proposed an open-loop adaptive ﬁltering method for the case of narrowband jammer.
Wang and Amin applied multiple-zero FIR ﬁlters whose notch is in synchronization with the jammer
instantaneous frequency, in order to remove the jammer power at every time sample. Barbarossa and
Scaglione have proposed a method based on a generalized Wigner-Hough transform. They characterized
linear and sinusoidal jammers by the appropriate parametric models. Suleesathira and Chaparro used
a method for interference mitigation based on the evolutionary and Hough transform. The fractional
Fourier transform for the case of linear chirp signals can improve the presentation and an overall bit
error performance of the receiver when the angular parameter of the transform matches chirp rate
of the interferences. A non-parametric approach for the jammer excision by using local polynomial
Fourier transform, which is linear with respect to the signal is also used. The optimal order of the
local polynomial Fourier transform was determined and calculated for each considered instant with
appropriate optimization of the selected order transform parameters. The jammer was represented in
the domain of its best concentration. Time-varying ﬁltering is then implemented in that domain. In
this way the local polynomial Fourier transform based method can be used for a general, including
non-linear FM type of interferences.

140
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
3.03.6.8 Watermarking in the space/spatial-frequency domain
Digital watermarking has been rapidly developing in the last few years due to the widespread use of
multimedia contents. It can provide an image copyright protection, i.e., identiﬁcation of its owner and
authorized distributor. The most commonly used approaches for watermarking are either by embed-
ding in the spatial domain, or in the transformation (frequency) domain. Regardless the watermarking
approach, it is desirable to ensure that watermarking satisﬁes the following important properties: (a) it is
perceptually invisible; (b) watermark must be robust to the various image processing algorithms, such as
common geometric distortion (rotation, translation, cropping), resampling, ﬁltering, and compression;
(c) detection of the watermark by copyright owner should be possible without the original image.
A watermarking scheme in the space/spatial-frequency domain is also proposed and used. Two
dimensional chirp signals are used as watermarks, due to their geometrical symmetry and robustness to
stationary ﬁltering. An ideal space/spatial-frequency representation, for this type of signals, is achieved
by using the two-dimensional Wigner distribution. In order to additionally emphasize the watermark,
with respect to the Wigner distribution of the original image, the Wigner distribution projections (two
dimensional Radon Wigner distribution) are used. In this way the maximum watermark projection will
be dominant, as compared to the projections of the Wigner distribution, of the original image. It results
in an efﬁcient watermark detection procedure.
References and Further Reading
[1] F. Auger, F. Hlawatsch, Time-Frequency Analysis, Wiley-ISTE, November 2008.
[2] L. Cohen, Time-Frequency Analysis, Prentice-Hall, 1995.
[3] D. Gabor, Theory of communications, J. Inst. Electr. Eng. 93 (1946) 423–457.
[4] F. Hlawatch, G.F. Boudreaux-Bartels, Line and quadratic time-frequency signal representations, IEEE Signal
Process. Mag. (1992) 21–67.
[5] O. Rioul, M. Vetterli, Wavelets and signal processing, IEEE Signal Process. Mag. (1991) 14–38.
[6] L. Stankovic, M. Dakovic, T. Thayaparan, Time-Frequency Signal Analysis with Applications, Artech House,
Boston, April 2013.
[7] L.E.Atlas,Y.Zhao,R.J.MarksII,Theuseofconeshapekernelsforgeneralizedtime-frequencyrepresentations
of nonstationary signals, IEEE Trans. Acoust. Speech Signal Process. 38 (1990) 1084–1091.
[8] M.J. Bastiaans, T. Alieva, L. Stankovi´c, On rotated time-frequency kernels, IEEE Signal Proc. Lett. 9 (11)
(2002) 378–381.
[9] T.A.C.M. Claasen, W.F.G. Mecklenbrauker, The Wigner distribution—a tool for time frequency signal anal-
ysis, Parts I, II and III, Phillips J. Res. 35 (3/4/5/6) (1980) 217–250, 276–300, 372–389.
[10] P. Flandrin, Temps-Frequence, Paris, Hermes, 1993.
[11] W. Mecklenbrauker, The Wigner Distribution—Theory and Applications in Signal Processing, Elsevier Sci-
ence, Amsterdam, 1992.
[12] W. Martin, P. Flandrin, Wigner-Will spectral analysis of nonstationary processes, IEEE Trans. ASSP 33 (6)
(1985) 1461–1470.
[13] W.F.G. Mecklenbrauker, F. Hlawatsch (Eds.), The Wigner Distributions—Theory and Applications in Signal
Processing, Elsevier, 1997.
[14] S. Qian, Introduction to Time-Frequency and Wavelet Transforms, Prentice Hall, 2001.
[15] A.W. Rihaczek, Signal energy distribution in time and frequency, IEEE Trans. Info. Theory 14 (1968) 369–374.
[16] J. Ville, Theorie et applications de la notion de signal analytique, Cables es Transmission 2 (1) (1946) 61–74.

References and Further Reading
141
[17] P.E. Wigner, On the quantum correction for thermodynamic equilibrium, Phys. Rev. 40 (1932) 246–254.
[18] Y.M. Zhu, F. Peyrin, R. Goutte, Transformation de Wigner-Ville: description d′ un nouvel outil de traitement
du signal et des images, Ann. Telecommun. 42 (3–4) (1987) 105–117.
[19] B. Boashash, B. Risti´c, Polynomial time-frequency distributions and time-varying higher order spectra: appli-
cations to analysis of multi-component FM signals and to treatment of multiplicative noise, Signal Process.
67 (1) (1998) 1–23.
[20] J.R. Fonollosa, C.L. Nikias, Wigner higher order moment spectra: deﬁnitions, properties, computation and
application to transient signal analysis, IEEE Trans. Signal Process. 41 (1993) 245–266.
[21] B. Porat, B. Friedlander, Asymptotic analysis of the high-order ambiguity function for parameter estimation
of the polynomial-phase signal, IEEE Trans. Info. Theory 42 (1996) 995–1001.
[22] B. Ristic, B. Boashash, Relationship between the polynomial and higher order Wigner-Ville distribution, IEEE
Signal Process. Lett. 2 (12) (1995) 227–229.
[23] L. Stankovi´c, A method for time-frequency analysis, IEEE Trans. Signal Process. 42 (1) (1994) 225–229.
[24] B. Boashash, Estimating and interpreting the instantaneous frequency of a signal Part 1, IEEE Proc. 80 (4)
(1992) 519–538.
[25] A.J.E.M. Janssen, On the locus and spread of pseudo density functions in the time-frequency plane, Philips
J. Res. 37 (1982) 79–110.
[26] V. Katkovnik, A new form of the Fourier transform for time-frequency estimation, Signal Process. 47 (2)
(1995) 187–200.
[27] I. Daubechies, Ten Lecture on Wavelets, SIAM, Philadelphia, Pennsylvania, 1992.
[28] M. Vetterli, J. Kovaˇcevi´c, Wavelets and Subband Coding, Prentice Hall, 1994.
[29] P. Goncalves, R.G. Baraniuk, Pseudo afﬁne Wigner distributions: deﬁnition and kernel formulation, IEEE
Trans. Signal Process. 46 (6) (1998) 1505–1517.
[30] A. Papandreou-Suppappola, Applications in Time-Frequency Signal Processing, CRC Press, 2002.
[31] O. Rioul, P. Flandrin, Time-scale energy distributions: a general class extending wavelet transforms, IEEE
Trans. Signal Process. (7) (1992) 1746–1757.
[32] H.M. Ozatkas, N. Erkaya, M.A. Kutay, Effect of fractional Fourier transformation on time-frequncy distribu-
tions belonging to the Cohen class, IEEE Signal Process. Lett. 3 (2) (1996) 40–41.
[33] X.G. Xia, On bandlimited signals with fractional Fourier transform, IEEE Signal. Process. Lett. 3 (3) (1996)
72–74.
[34] L.B. Almeida, Product and convolution theorems for the fractional Fourier transform, IEEE Signal Process.
Lett. 4 (1) (1997) 15–17.
[35] L. Stankovi´c, An analysis of some time-frequency and time-scale distributions, Ann. Telecommun. 49 (9–10)
1 (994) 505–517.
[36] M.G. Amin, Minimum variance time-frequency distribution kernels for signals in additive noise, IEEE Trans.
Signal Process. 44 (9) (1996) 2352–2356.
[37] L. Cohen, Time-Frequency Analysis, Signal Process. Mag. (1999) 22–28.
[38] R.G. Baraniuk, D.L. Jones, Signal-dependent time-frequency analysis using radially-Gaussian kernel, IEEE
Trans. Signal Process. 41 (3) (1993) 263–284.
[39] D.L. Jones, R.G. Baraniuk, An adaptive optimal-kernel time-frequency representation, IEEE Trans. Signal
Process. 43 (10) (1995) 2361–2372.
[40] M.G. Amin, Spectral decomposition of time-frequency distribution kernels, IEEE Trans. Signal Process. 42
(5) (1994) 1156–1165.
[41] L.L. Scharf, B. Friedlander, Toeplitz and Hankel kernels for estimating time-varying spectra of discrete-time
random processes, IEEE Trans. Signal Process. 49 (1) (2001) 179–189.
[42] F. Auger, P. Flandrin, Improving the readability of time-frequency and time-scale representations by the
reassignment method, IEEE Trans. Signal Process. 43 (5) (1995) 1068–1089.

142
CHAPTER 3 Non-Stationary Signal Analysis Time-Frequency Approach
[43] B. Boashash, P. O’Shea, Polynomial Wigner-Ville distributions and their relationship to time-varying higher
order spectra, IEEE Trans. Signal Process. 42 (1) (1994) 216–220.
[44] S. Barbarossa, Analysis of multi-component LFM signals by a combined Wigner-Hough transform, IEEE
Trans. Signal Process. 43 (6) (1995) 1511–1515.
[45] B. Friedlander, J.M. Francos, Estimation of amplitude and phase parameters of multi-component signals,
IEEE Trans. Signal Process. 43 (4) (1995) 917–927.
[46] S. Peleg, B. Porat, Estimation and classiﬁcation of polynomial phase signals, IEEE Trans. Info. Theory (3)
(1991) 422–430.
[47] R. Baraniuk, Compressive sensing, IEEE Signal Process. Mag. 24 (4) (2007) 118–121.
[48] P. Flandrin, P. Borgnat, Time-frequency energy distributions meet compressed sensing, IEEE Trans. Signal
Process. 58 (6) (2010) 2974–2982.
[49] S. Stankovic, I. Orovic, E. Sejdic, Multimedia Signals and Systems, Springer, 2012.
[50] L. Stankovic, A measure of some time-frequency distributions concentration, Signal Process. 81 (3) (2001)
621–631.
[51] L. Stankovi´c, I. Orovi´c, S. Stankovi´c, M. Amin, Compressive sensing based separation of non-stationary and
stationary signals Overlapping in time-frequency, IEEE Trans. Signal Process. 61 (2013) in print.
[52] G.F. Boudreaux-Bartels, T.W. Parks, Time-varying ﬁltering and signal estimation using Wigner distribution
synthesis techniques, IEEE Trans. Acoust. Speech and Signal Process., 34 (3) (1986) 442–451.
[53] V.C. Chen, The Micro-Doppler Effect in Radar, Artech House, 2011.
[54] I. Djurovi´c, L. Stankovi´c, J.F. Bohme, Robust L-estimation based forms of signal transforms and time-
frequency representations, IEEE Trans. Signal Process. 51 (7) (2003) 1753–1761.
[55] V. Katkovnik, L. Stankovi´c, Instantaneous frequency estimation using the Wigner distribution with varying
and data-driven window length, IEEE Trans. Signal Process. 46 (9) (1998) 2315–2326.
[56] C. Richard, Time-frequency-based detection using discrete-time discrete-frequency Wigner distributions,
IEEE Trans. Signal Process. 50 (9) (2002) 2170–2176.
[57] E. Sejdic, I. Djurovic, J. Jiang, L. Stankovic, Time-Frequency Based Feature Extraction and Classiﬁcation,
VDM Verlag, 2009.
[58] L. Stankovic, Performance analysis of the adaptive algorithm for bias-to-variance trade-off, IEEE Trans.
Signal Process. 52 (5) (2004) 1228–1234.
[59] L. Stankovic, T. Thayaparan, M. Dakovic, Signal decomposition by using the s-method with application to
the analysis of HF radar signals in sea-clutter, IEEE Trans. Signal Process. 54 (11) (2006) 4332–4342.
[60] L. Stankovi´c, Analysis of noise in time-frequency distributions, IEEE Signal Process. Lett. 9 (9) (2002)
286–289.
[61] S. Stankovi´c, I. Djurovi´c, I. Pitas, Watermarking in the space/spatial-frequency domain using two-dimensional
Radon-Wigner distribution, IEEE Trans. Image Process. 10 (4) (2001) 650–658.
[62] L. Stankovi´c, I. Orovi´c, S. Stankovi´c, M. Amin, Robust time-frequency analysis based on the l-estimation
and compressive sensing, IEEE Signal Process. Lett. 20 5 (2013) 499–502.

4
CHAPTER
Bayesian Computational Methods
in Signal Processing
Simon Godsill
Signal Processing and Communications Laboratory, Department of Engineering, University of Cambridge, UK
3.04.1 Introduction
Over recent decades Bayesian computational techniques have risen from relative obscurity to becoming
one of the principal means of solving complex statistical signal processing problems. Methodology
is now mature and sophisticated. This article aims to provide a brief and basic introduction for those
starting on the topic, with the aim of inspiring further research work in this vibrant area.
The paper is structured as follows. Section 3.04.2 covers Bayesian parameter estimation, with a
worked case study in Bayesian linear Gaussian models. This section also introduces model uncertainty
from a Bayesian perspective. Section 3.04.3 introduces some of the computational tools available for
batch inference, including the expectation-maximization (EM) algorithm and the Markov chain Monte
Carlo (MCMC) algorithm. Section 3.04.4 moves on to sequential inference problems, covering linear
state-space models, Kalman ﬁlters, nonlinear state-space models, and particle ﬁltering.
3.04.2 Parameter estimation
In parameter estimation we suppose that a random process {Xn} depends in some well-deﬁned stochastic
manner upon an unobserved parameter vector θ. If we observe N data points from the random process,
we can form a vector x = [x1 x2 · · · xN]T . The parameter estimation problem is to deduce the value
of θ from the observations x. In general it will not be possible to deduce the parameters exactly from a
ﬁnite number of data points since the process is random, but various schemes will be described which
achieve different levels of performance depending upon the amount of data available and the amount
of prior information available regarding θ.
We now deﬁne a general parametric model, the linear Gaussian model, which will be referred to
frequently in this and subsequent sections. This model will be used as a motivating example in much
of the work in this section, with details of the calculations required to perform the various aspects
of inference in classical and Bayesian settings. This model is a fundamental building block for many
more complex and sophisticated non-linear or non-Gaussian models in signal processing, and so these
fundamentals will be referred to numerous times later in the text. However, although we use these models
as a motivating example throughout the early sections, it should be borne in mind that there are indeed
many classes of model in practical application that have none, or very little, linear Gaussian structure,
and for these results specialized techniques are required for inference; none of the analytic results here
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00004-7
© 2014 Elsevier Ltd. All rights reserved.
143

144
CHAPTER 4 Bayesian Computational Methods in Signal Processing
will apply in these cases, but the fundamental structure of the Bayesian inference methodology does
indeed carry through unchanged, and inference can still be successfully performed, albeit with more
effort and typically greater computational burden. The Monte Carlo methods described later, and in
particular the particle ﬁltering and Markov chain Monte Carlo (MCMC) approaches, are well suited to
inference in the hardest models with no apparent linear or Gaussian structure.
Another class of model that is amenable to certain simple analytic computations beyond the linear
Gaussian class is the discrete Markov chain model and its counterpart the hidden Markov model (HMM).
This model, not covered in this tutorial, can readily be combined with linear Gaussian structures to yield
sophisticated switching models that can be elegantly inferred within the fully Bayesian framework.
3.04.2.1 The linear Gaussian model
In the general model it is assumed that the data x are generated as a function of the parameters θ with
a random modeling error term en:
xn = gn(θ, en),
where gn(·) is a deterministic and possibly non-linear function of the parameter θ and the random error,
or “disturbance” en. Now we will consider the important special case where the function is linear and
the error is additive, so we may write
xn = gT
n θ + en,
where gn is a P-dimensional column vector, and the expression may be written for the whole vector x as
x = Gθ + e,
(4.1)
where
G =
⎡
⎢⎢⎢⎢⎢⎣
gT
1
gT
2...
gT
N
⎤
⎥⎥⎥⎥⎥⎦
=

h1 h2 . . . hP
	
.
The columns hi of G form a ﬁxed basis vector representation of the data, for example sinusoids of
different frequencies in a signal which is known to be made up of pure frequency components in noise.
A variant of this model will be seen later in the section, the autoregressive (AR) model, in which previous
data points are used to predict the current data point xn. The error sequence e will usually (but not neces-
sarily) be assumed drawn from an independent, identically distributed (i.i.d.) noise distribution, that is,
p(e) = pe(e1)·pe(e2) · · · pe(eN),
where pe(·) denotes some noise distribution which is identical for all n. Note that some powerful models
can be constructed using heterogeneous noise sources, in which the distribution p(en) can vary with n.
This might be for the purpose of modeling a time-varying noise term, or for modeling a heavy-tailed
noise distribution through the introduction of additional latent variables at each time point.1 {en} can be
1Whenever the context makes it unambiguous we will adopt from now on a notation p(·) to denote both probability density
functions (PDFs) and probability mass functions (PMFs) for random variables and vectors.

3.04.2 Parameter Estimation
145
viewed as a modeling error, innovation or observation noise, depending upon the type of model. When
pe( ) is the normal distribution and gn is a linear function, we have the linear Gaussian model.
There are many examples of the use of such a linear Gaussian modeling framework. Two very simple
and standard cases are the sinusoidal model and the autoregressive (AR) model.
Example.
(Sinusoidal model) If we write a single sinusoid as the sum of sine and cosine components
we have:
xn = a cos (ωn) + b sin (ωn).
Thus we can form a second order (P = 2) linear model from this if we take:
G = [c(ω) s(ω)],
θ =

a
b

,
where
c(ω) = [cos (ω),
cos (2ω),
cos (Nω)]T
and
s(ω) = [sin (ω),
sin (2ω),
sin (Nω)]T .
And similarly, if the model is composed of J sinusoids at different frequencies ω j we have
xn =

j
a j cos (ω jn) + b j sin (ω jn)
and the linear model expression is
G = [c(ω1) s(ω1) c(ω2) s(ω2)
· · ·
c(ωJ) s(ωJ)],
θ =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
a1
b1
a2
b2
...
aJ
bJ
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
Example.
(Autoregressive (AR) model) The AR model is a standard time series model based on an
all-pole ﬁltered version of the noise residual:
xn =
P

i=1
ai xn−i + en.
(4.2)
The coefﬁcients {ai; i = 1 . . . P} are the ﬁlter coefﬁcients of the all-pole ﬁlter, henceforth referred to
as the AR parameters, and P, the number of coefﬁcients, is the order of the AR process. The AR model
formulation is closely related to the linear prediction framework used in many ﬁelds of signal processing
(see e.g., [1,2]). The AR modeling equation of (4.2) is now rewritten for the block of N data samples as
x = Ga + e,
(4.3)

146
CHAPTER 4 Bayesian Computational Methods in Signal Processing
where e is the vector of (N −P) error values and the ((N −P) × P) matrix G is given by
G =
⎡
⎢⎢⎢⎢⎢⎣
xP
xP−1 · · ·
x2
x1
xP+1
xP
· · ·
x3
x2
...
...
...
xN−2 xN−3 · · ·
xN−P
xN−P−1
xN−1 xN−2 · · · xN−P+1
xN−P
⎤
⎥⎥⎥⎥⎥⎦
.
(4.4)
3.04.2.2 Maximum likelihood (ML) estimation
Prior to consideration of Bayesian approaches, we ﬁrst present the maximum likelihood (ML) estimator,
which treats the parameters as unknown constants about which we incorporate no prior information.
The observed data x is, however, considered random and we can often then obtain the PDF for x when
the value of θ is known. This PDF is termed the likelihood L(x; θ), which is deﬁned as
L(x; θ) = p(x|θ).
(4.5)
The likelihood is of course implicitly conditioned upon all of our modeling assumptions M, which
could more properly be expressed as p(x|θ, M).
The ML estimate for θ is then that value of θ which maximizes the likelihood for given observations x:
θML = argmax
θ
{p(x|θ)},
(4.6)
Maximum likelihood (ML) estimator.
The rationale behind this is that the ML solution corresponds to the parameter vector which would
have generated the observed data x with highest probability. The maximization task required for ML
estimation can be achieved using standard differential calculus for well-behaved and differentiable
likelihood functions, and it is often convenient analytically to maximize the log-likelihood function
l(x; θ) = log (L(x; θ)) rather than L(x; θ) itself. Since log is a monotonically increasing function the
two solutions are identical.
In data analysis and signal processing applications the likelihood function is arrived at through
knowledge of the stochastic model for the data. For example, in the case of the linear Gaussian model
(4.1) the likelihood can be obtained easily if we know the form of p(e), the joint PDF for the components
of the error vector. The likelihood p(x|θ) is then found from a transformation of variables e →x where
e = x −Gθ. The Jacobian for this transformation is unity, so the likelihood is:
L(x; θ) = p(x|θ) = pe(x −Gθ).
(4.7)
The ML solution may of course be posed for any error distribution, including highly non-Gaussian
and non-independent cases. Here we give the most straightforward case, for the linear model where the
elements of the error vector e are assumed to be i.i.d. and Gaussian and zero mean. If the variance of
the Gaussian is σ 2
e we then have:
pe(e) =
1
(2πσ 2e )N/2 exp

−1
2σ 2e
eT e

.

3.04.2 Parameter Estimation
147
The likelihood is then
L(x; θ) = p(x|θ) = pe(x −Gθ) =
1
(2πσ 2e )N/2 exp

−1
2σ 2e
(x −Gθ)T (x −Gθ)

,
(4.8)
which leads to the following log-likelihood expression:
l(x; θ) = −(N/2) log (2πσ 2
e ) −
1
2σ 2e
(x −Gθ)T (x −Gθ)
= −(N/2) log (2πσ 2
e ) −
1
2σ 2e
N

n=1

xn −gT
n θ
2
.
Maximization of this function w.r.t. θ is equivalent to minimizing the sum-squared of the error sequence
E = N
n=1 (xn −gT
n θ)2. This is exactly the criterion which is applied in the familiar least squares (LS)
estimation method. The ML estimator is obtained by taking derivatives w.r.t. θ and equating to zero:
θML = (GT G)−1GT x,
(4.9)
Maximum likelihood for the linear Gaussian model,
which is, as expected, the familiar linear least squares estimate for model parameters calculated from
ﬁnite length data observations. Thus we see that the ML estimator under the i.i.d. Gaussian error
assumption is exactly equivalent to the well known least squares (LS) parameter estimator.
3.04.2.3 Bayesian inference
TheMLmethodstreatparametersasunknownconstants.Ifwearepreparedtotreatparametersasrandom
variables it is possible to assign prior PDFs to the parameters. These PDFs should ideally express some
prior knowledge about the relative probability of different parameter values before the data are observed.
Of course if nothing is known a priori about the parameters then the prior distributions should in some
sense express no initial preference for one set of parameters over any other. Note that in many cases
a prior density is chosen to express some highly qualitative prior knowledge about the parameters. In
such cases the prior chosen will be more a reﬂection of a degree of belief concerning parameter values
than any true modeling of an underlying random process which might have generated those parameters.
This willingness to assign priors which reﬂect subjective information is a powerful feature and also one
of the most fundamental differences between the Bayesian and “classical” inferential procedures. For
various expositions of the Bayesian methodology and philosophy see, for example [3–6]. The precise
form of probability distributions assigned a priori to the parameters requires careful consideration since
misleading results can be obtained from erroneous priors, but in principle at least we can apply the
Bayesian approach to any problem where statistical uncertainty is present.
Bayes’ theorem is now stated as applied to estimation of random parameters θ from a random vector
x of observations, known as the posterior or a posteriori probability for the parameter:
p(θ|x) = p(x|θ)p(θ)
p(x)
,
(4.10)
Posterior probability.

148
CHAPTER 4 Bayesian Computational Methods in Signal Processing
Note that all of the distributions in this expression are implicitly conditioned upon all prior modeling
assumptions, as was the likelihood function earlier. The distribution p(x|θ) is the likelihood as used
for ML estimation, while p(θ) is the prior or a priori distribution for the parameters. This term is one
of the critical differences between Bayesian and “classical” techniques. It expresses in an objective
fashion the probability of various model parameters values before the data x has been observed. As we
have already observed, the prior density may be an expression of highly subjective information about
parameter values. This transformation from the subjective domain to an objective form for the prior
can clearly be of great signiﬁcance and should be considered carefully when setting up an inference
problem.
The term p(θ|x), the posterior or a posteriori distribution, expresses the probability of θ given the
observed data x. This is now a true measure of how “probable” a particular value of θ is, given the
observations x. p(θ|x) is in a more intuitive form for parameter estimation than the likelihood, which
expresses how probable the observations are given the parameters. The generation of the posterior
distribution from the prior distribution when data x is observed can be thought of as a reﬁnement to any
previous (“prior”) knowledge about the parameters. Before x is observed p(θ) expresses any information
previously obtained concerning θ. Any new information concerning the parameters contained in x is
then incorporated to give the posterior distribution. Clearly if we start off with little or no information
about θ then the posterior distribution is likely to obtain information obtained almost solely from x.
Conversely, if p(θ) expresses a signiﬁcant amount of information about θ then x will contribute less
new information to the posterior distribution.
The denominator p(x), referred to as the marginal likelihood, or the “evidence” in machine learning
circles, is a fundamentally useful quantity in model selection problems (see later), and is constant for any
given observation x; thus it may be ignored if we are only interested in the relative posterior probabilities
of different parameters. As a result of this, Bayes’ theorem is often stated in the form:
p(θ|x) ∝p(x|θ)p(θ),
(4.11)
Posterior probability (proportionality).
p(x) may be calculated in principle by integration:
p(x) =

p(x|θ)p(θ)dθ
(4.12)
and this effectively serves as the normalizing constant for the posterior density (in this and subsequent
results the integration would be replaced by a summation in the case of a discrete random vector θ).
It is worth reiterating at this stage that we are here implicitly conditioning in this framework on many
pieces of additional prior information beyond just the prior parameters of the model θ. For example,
we are assuming a precise form for the data generation process in the model; if the linear Gaussian
model is assumed, then the whole data generation process must follow the probability law of that model,
otherwise we cannot guarantee the quality of our answers; the same argument applies to ML estimation,
although in the Bayesian setting the distributional form of the Bayesian prior must be assumed in
addition. Some texts therefore adopt a notation p(θ|x, M) for Bayesian posterior distributions, where
M denotes all of the additional modeling and distributional assumptions that are being made. We will
omit this convention for the sake of notational simplicity. However, it will be partially reintroduced

3.04.2 Parameter Estimation
149
when we augment a model with other terms such as unknown hyperparameters (such as σe in the
linear Gaussian model) or a model index Mi, when we are considering several competing models (and
associated prior distributions) for explaining the data. In these cases, for example, the notation will be
naturally extended as required, e.g., p(θ|x, σe) or p(θ|x, Mi) in the two cases just described.
3.04.2.3.1
Posterior inference and Bayesian cost functions
The posterior distribution gives the probability for any chosen θ given observed data x, and as such
optimally combines our prior information about θ and any additional information gained about θ from
observing x. We may in principle manipulate the posterior density to infer any required statistic of θ
conditional upon x. This is a signiﬁcant advantage over ML and least squares methods which strictly
give us only a single estimate of θ, known as a “point estimate.” However, by producing a posterior PDF
with values deﬁned for all θ the Bayesian approach gives a fully interpretable probability distribution.
In principle this is as much as one could ever need to know about the inference problem. In signal
processing problems, however, we usually require a single point estimate for θ, and a suitable way to
choose this is via a “cost function” C(ˆθ, θ) which expresses objectively a measure of the cost associated
with a particular parameter estimate ˆθ when the true parameter is θ (see e.g., [3,6,7]). The form of cost
function will depend on the requirements of a particular problem. A cost of 0 indicates that the estimate
is perfect for our requirements (this does not necessarily imply that ˆθ = θ, though it usually will) while
positive values indicate poorer estimates. The risk associated with a particular estimator is then deﬁned
as the expected posterior cost associated with that estimate:
R(ˆθ) = E[C(ˆθ, θ)] =

x

θ
C(ˆθ, θ)p(θ|x)p(x)dθ dx.
(4.13)
We require the estimation scheme which chooses ˆθ in order to minimize the risk. The minimum risk is
known as the “Bayes risk.” For non-negative cost functions it is sufﬁcient to minimize only the inner
integral
I(ˆθ) =

θ
C(ˆθ, θ)p(θ|x)dθ
(4.14)
for all ˆθ. Typical cost functions are the quadratic cost function |ˆθ −θ|2 and the uniform cost function,
deﬁned for arbitrarily small ε as
C(ˆθ, θ) =

1,
|ˆθ −θ| > ε,
0,
otherwise.
(4.15)
The quadratic cost function leads to the minimum mean-squared error (MMSE) estimator and as such
is reasonable for many examples of parameter estimation, where we require an estimate representative
of the whole posterior density. To see the form of the resulting estimator, consider differentiation

150
CHAPTER 4 Bayesian Computational Methods in Signal Processing
under the integral:
dI(ˆθ)
d ˆθ
= d
d ˆθ

θ
C(ˆθ, θ)p(θ|x)dθ
=

θ
d
d ˆθ
|ˆθ −θ|2 p(θ|x)dθ
=

θ
2(ˆθ −θ)p(θ|x)dθ
= 2ˆθ −2

θ
θ p(θ|x)dθ.
And hence at the optimum estimator we have that the MMSE estimate equals the mean of the posterior
distribution:
ˆθ =

θ
θ p(θ|x)dθ.
(4.16)
Where the posterior distribution is symmetrical about its mean the posterior mean can in fact be shown
to be the minimum risk solution for any cost function which is a convex function of |ˆθ −θ| [8]. Thus the
posterior mean estimator is very often used as the “standard” Bayesian estimate of a parameter. It always
needs to be remembered however that there is a whole posterior distribution of parameters available
here and that at the very least posterior uncertainty should be summarized through the covariance of
the posterior distribution, or posterior standard deviations for the individual elements of the parameter
vector. It should be noted as well that in cases where the posterior distribution is multi-modal, that is
there is more than one maximum to p(θ|x), the posterior mean can give very misleading results.
The uniform cost function on the other hand is useful for the “all or nothing” scenario where we
wish to attain the correct parameter estimate at all costs and any other estimate is of no use. Therrien [2]
cites the example of a pilot landing a plane on an aircraft carrier. If he does not estimate within some
small ﬁnite error he misses the ship, in which case the landing is a disaster. The uniform cost function
for ε →0 leads to the maximum a posteriori (MAP) estimate, the value of ˆθ which maximizes the
posterior distribution:
θMAP = argmax
θ
{p(θ|x)},
(4.17)
Maximum a posteriori (MAP) estimator.
Note that for Gaussian posterior distributions the MMSE and MAP solutions coincide, as indeed
they do for any distribution symmetric about its mean with its maximum at the mean.
We now work through the MAP estimation scheme under the linear Gaussian model (4.1). Suppose
that the prior on parameter vector θ is the multivariate Gaussian (4.71):
p(θ) = N(mθ, Cθ) =
1
(2π)P/2|Cθ|1/2 exp

−1
2(θ −mθ)T Cθ −1(θ −mθ)

,
(4.18)
where mθ is the prior parameter mean vector, Cθ is the parameter covariance matrix and P is the number
of parameters in θ. If the likelihood p(x|θ) takes the same form as before (4.8), the posterior distribution

3.04.2 Parameter Estimation
151
is as follows:
p(θ|x) ∝
1
(2π)P/2|Cθ|1/2
1
(2πσ 2e )N/2
× exp

−1
2σ 2e
(x −Gθ)T (x −Gθ)
−1
2(θ −mθ)T Cθ −1(θ −mθ)

(4.19)
and the MAP estimate θMAP is obtained by differentiation of the log-posterior and ﬁnding its unique
maximizer as:
θMAP =

GT G + σ 2
e C−1
θ
−1 
GT x + σ 2
e Cθ −1mθ

,
(4.20)
MAP estimator—linear Gaussian model.
Inthisexpressionwecanclearlyseethe“regularizing”effectofthepriordensityontheMLestimateof
(4.9). As the prior becomes more “diffuse,” i.e., the diagonal elements of Cθ increase both in magnitude
and relative to the off-diagonal elements, we impose “less” prior information on the estimate. In the
limit the prior tends to a uniform (“ﬂat”) prior with all θ equally probable. In this limit C−1
θ
= 0 and
the estimate is identical to the ML estimate (4.9). This useful relationship demonstrates that the ML
estimate may be interpreted as the MAP estimate with a uniform prior assigned to θ. The MAP estimate
will also tend towards the ML estimate when the likelihood is strongly “peaked” around its maximum
compared with the prior. Once again the prior will then have little inﬂuence on the shape of the posterior
density. It is in fact well known [5] that as the sample size N tends to inﬁnity the Bayes solution tends to
the ML solution. This of course says nothing about small sample parameter estimates where the effect
of the prior may be very signiﬁcant.
The choice of a multivariate Gaussian prior may well be motivated by physical considerations about
the problem, or it may be motivated by subjective prior knowledge about the value of θ (before the
data x are seen!) in terms of a rough value mθ and a conﬁdence in that value through the covariance
matrix Cθ (a “subjective” prior). In fact the choice of Gaussian also has the very special property that
it makes the Bayesian calculations straightforward and available in closed form. Such a prior is known
as a “conjugate” prior [3].
3.04.2.3.2
Posterior distribution for parameters in the linear Gaussian model
Reconsidering the form of (4.19), we can obtain a lot more information than simply the MAP estimate
of (4.20). A fully Bayesian analysis of the problem will study the whole posterior distribution for the
unknowns, computing measures of uncertainty, conﬁdence intervals, and so on. The required distribution
can be obtained by rearranging the exponent of (4.19) using the result of (4.74),
1
σ 2e
(x −Gθ)T (x −Gθ) + (θ −mθ)T Cθ −1(θ −mθ)
= 1
σ 2e

θ −θMAPT


θ −θMAP
+ xT x + σ 2
e mθ T Cθ −1mθ −T θ MAP

(4.21)

152
CHAPTER 4 Bayesian Computational Methods in Signal Processing
with terms deﬁned as
θMAP = −1,
(4.22)
 = GT G + σ 2
e Cθ −1,
(4.23)
 = GT x + σ 2
e Cθ −1mθ.
(4.24)
Now we can observe that the ﬁrst term in (4.21),
1
σ 2e ((θ −θMAP)T (θ −θMAP)) , is in exactly the
correct form for the exponent of a multivariate Gaussian, see (4.71), with mean vector and covariance
matrix as follows:
mpost
θ
= θMAP
and Cpost
θ
= σ 2
e −1.
Since the remaining terms in (4.21) do not depend on θ, and we know that the multivariate density
function must be proper (i.e., integrate to 1), we can conclude that the posterior distribution is itself a
multivariate Gaussian,
p(θ|x) = N

θMAP, σ 2
e −1
.
(4.25)
This result will be fundamental for the construction of inference methods in later sections, in cases
where the model is at least partially linear/Gaussian, or can be approximated as linear and Gaussian.
3.04.2.3.3
Marginal likelihood
In problems where model choice or classiﬁcation are of importance, and in inference algorithms
which marginalize (“Rao-Blackwellize”) a Gaussian parameter (see later sections for details of these
approaches) it will be required to compute the marginal likelihood for the data, i.e.,
p(x) =

θ
p(x|θ)p(θ)dθ.
(4.26)
Now, ﬁlling in the required density functions for the linear Gaussian case, we have:
p(x) =

θ
1
(2π)P/2|Cθ|1/2
1
(2πσ 2e )N/2
× exp

−1
2σ 2e
(x −Gθ)T (x −Gθ)
−1
2(θ −mθ)T Cθ −1(θ −mθ)

dθ.
(4.27)
This multivariate Gaussian integral can be performed after some rearrangement using result (4.76)
to give:
p(x) =
1
(2π)P/2|Cθ|1/2||1/2(2πσ 2e )(N−P)/2
× exp

−1
2σ 2e
(xT x + σ 2
e mθ T Cθ −1mθ −T θMAP)

(4.28)
with terms deﬁned exactly as for the posterior distribution calculation above in (4.22)–(4.24).

3.04.2 Parameter Estimation
153
3.04.2.3.4
Hyperparameters and marginalization of unwanted parameters
In many cases we can formulate a likelihood function for a particular problem which depends on more
unknown parameters than are actually wanted for estimation. These will often be “scale” parameters
such as unknown noise or excitation variances but may also be unobserved (“missing”) data values or
unwanted system parameters. A simple example of such a parameter is σe in the linear Gaussian model
above. In this case we can directly express the likelihood function exactly as before, but now explicitly
conditioning on the unknown noise standard deviation:
log p(x|θ, σe) = −(N/2) log

2πσ 2
e

−
1
2σ 2e
N

n=1

xn −gT
n θ
2
.
A full ML procedure requires that the likelihood be maximized w.r.t. all of these parameters and the
unwanted values are then simply discarded to give the required estimate, a “concentrated likelihood”
estimate.2
However, this may not in general be an appropriate procedure for obtaining only the required
parameters—a cost function which depends only upon a certain subset of parameters leads to an esti-
mator which only depends upon the marginal probability for those parameters. The Bayesian approach
allows for the interpretation of these unwanted or “nuisance” parameters as random variables, for which
as usual we can specify prior densities. If the (possibly multivariate) hyperparameters are φ (φ would
be taken to equal σe in the above simple example) then the full model can be speciﬁed through a joint
prior on the parameters/hyperparameters and the joint likelihood:
p(θ, φ, x) = p(x|θ, φ)p(θ, φ)
= p(x|θ, φ)p(θ|φ)p(φ),
where the joint prior has been factored using probability chain rule in a way that is often convenient for
speciﬁcation and calculation.
The marginalisation identity can be used to eliminate these parameters from the posterior distribution,
and from this we are able to obtain a posterior distribution in terms of only the desired parameters.
Consider an unwanted parameter φ which is present in the modeling assumptions. The unwanted
parameter is now eliminated from the posterior expression by marginalisation:
p(θ|x) =

φ
p(θ, φ|x)dφ
∝

φ
p(x|θ, φ)p(θ, φ)dφ.
(4.29)
3.04.2.3.5
Hyperparameters for the linear Gaussian model
As indicated above, it will often be important to estimate or marginalize the unknown hyperparameters
of the linear Gaussian model. There is quite a lot that can be done in the special case of the linear
2Although in time series likelihood-based analysis it is common to treat missing and other unobserved data in a Bayesian
fashion, see [9,10] and references therein.

154
CHAPTER 4 Bayesian Computational Methods in Signal Processing
Gaussian model using analytic results. Studying the form of the likelihood function in (4.8), it can be
observed that the form of the likelihood is quite similar to that of an inverted-gamma distribution, when
considered as a function of σ 2
e , see Section A.4. This gives a hint as to a possible prior structure that
might be workable in this model. If we take the prior itself for σ 2
e to be inverted-gamma (IG) then it
is fairly straightforward to rearrange the conditional posterior distribution for σ 2
e into a tractable form.
Since we are now treating σe as an unknown, conditioning of all terms on this unknown is now made
explicit:
p

σ 2
e
 θ, x

= p

x
θ, σ 2
e

p

θ| σ 2
e

p

σ 2
e

p(θ, x)
∝p

x| θ, σ 2
e

p

θ
σ 2
e

p

σ 2
e

(4.30)
and initially we take θ to be independent of σ 2
e so that p(θ|σ 2
e ) = p(θ) and
p

σ 2
e
 θ, x

∝p

x| θ, σ 2
e

p

σ 2
e

.
Taking the IG prior p(σ 2
e ) = IG(αe, βe), the conditional probability becomes
p

σ 2
e
 θ, x

∝
1

2πσ 2e
N/2 exp

−1
2σ 2e
(x −Gθ)T (x −Gθ)
 βαe
e
	(αe)σe−2(αe+1) exp

−βe/σ 2
e

= IG

αe + N/2, βe + 1
2(x −Gθ)T (x −Gθ)

,
(4.31)
where the equality on the last line follows because we know that the posterior conditional distribution is a
proper (normalized) density function, following similar reasoning to the Gaussian posterior distribution
leading to (4.25). The IG prior is once again the conjugate prior for the scale parameter σ 2
e in the model:
the posterior distribution is in the same form as the prior distribution, with parameters updated to include
the effect of the data (through the likelihood function). This conditional posterior distribution can then
be employed later for construction of efﬁcient Gibbs sampling, expectation-maximization, variational
Bayes and particle ﬁltering solutions to models involving linear Gaussian components.
3.04.2.3.6
Normal-inverted-gamma prior
If a little more structure is included in the prior p(θ, σ 2
e ) then still more can be done analytically.
We retain the Gaussian and IG forms for the individual components, but introduce prior dependence
between the parameters. Speciﬁcally, let
C−1
θ
= Mθ/σ 2
e ,
where Mθ is a positive deﬁnite matrix, considered ﬁxed and known. Here then we are saying that the
prior covariance of θ is known up to a scale factor of σ 2
e . The joint prior is then:
p

θ, σ 2
e

= p

θ| σ 2
e

p

σ 2
e

= N

mθ, σ 2
e M−1
θ

IG

σ 2
e
 αe, βe

,
which is of normal-inverted-gamma form, see (4.83).

3.04.2 Parameter Estimation
155
Inserting the joint prior into the expression for joint posterior distribution in a similar way to the
simple Gaussian prior model for θ alone,
p

θ, σ 2
e
 x

∝p

x| θ, σ 2
e

p

θ| σ 2
e

p

σ 2
e

,
we obtain as an extension of (4.19),
p

θ, σ 2
e
 x

∝
1
(2π)P/2|Cθ|1/2
1
(2πσ 2e )N/2
× exp

−1
2σ 2e
(x −Gθ)T (x −Gθ)
−1
2(θ −mθ)T Cθ −1(θ −mθ)

× βαe
e
	(αe)σ −2(αe+1)
e
exp

−βe/σ 2
e

.
(4.32)
This joint distribution must factor, by the probability chain rule, into:
p

θ, σ 2
e
 x

= p

θ| σ 2
e , x

p

σ 2
e |x

.
The second term in this can be obtained directly from previous results since
p

σ 2
e
 x

∝p

x| σ 2
e

p

σ 2
e

but we already have the ﬁrst term p(x|σ 2
e ) in the marginal likelihood calculation of (4.28), now though
making the dependence on σ 2
e explicit and substituting the form C−1
θ
= Mθ/σ 2
e , so
p

σ 2
e
 x

∝
|Mθ|1/2
(2π)P/2||1/2(2πσ 2e )(N)/2
× exp

−1
2σ 2e

xT x + mT
θ Mθmθ −T θMAP
× βαe
e
	(αe)σ −2(αe+1)
e
exp

−βe/σ 2
e

= IG

αe + N/2, βe +

xT x + mθ T Mθmθ −T θMAP
2

with appropriately simpliﬁed terms taken from (4.22)–(4.24) and substituting the form C−1
θ
= Mθ/σ 2
e :
θMAP = −1,
 = GT G + Mθ,
 = GT x + Mθmθ.

156
CHAPTER 4 Bayesian Computational Methods in Signal Processing
It can then be seen by inspection that all of the θ terms in may be grouped together in (4.32) as for the
Gaussian model to give the remaining required conditional,
p

θ| x, σ 2
e

= N

θ MAP, σ 2
e −1
.
(4.33)
Multiplying these two conditionals back together we obtain:
p

θ, σ 2
e
 x

= p

θ| σ 2
e , x

p

σ 2
e
 x

= N

θ| θMAP, σ 2
e −1
IG

σ 2
e
 αe + N/2, βe +

xT x + mθ T Mθmθ −T θMAP
2

,
which is in normal-inverted-gamma form—once again, the normal-inverted-gamma prior is conjugate
to the linear Gaussian model with unknown linear parameters and noise variance.
The marginal likelihood can also be computed for this model, which will be required for Rao-
Blackwellized inference schemes and for model choice problems,
p(x) =

θ

σ 2e
p

x, θ, σ 2
e

dθdσ 2
e =

σ 2e
p

x| σ 2
e

p

σ 2
e

dσ 2
e ,
(4.34)
wheretheﬁrstterminthisintegrandhasalreadybeenobtainedfrom(4.28),onceagainwithappropriately
simpliﬁed terms taken from (4.22)–(4.24) and substituting the form C−1
θ
= Mθ/σ 2
e :
p

x|σ 2
e

=
|Mθ|1/2
||1/2 
2πσ 2e
N/2
× exp

−1
2σ 2e

xT x + mθ T Mθmθ −T θMAP
.
Now, substituting this back into (4.34), the integral can be completed using the integral result from (4.78),
p(x) =

σ 2e
p

x|σ 2
e

p

σ 2
e

dσ 2
e
=

|Mθ|1/2
||1/2 
2πσ 2e
(N)/2
× exp

−1
2σ 2e

xT x + mθ T Mθmθ −T θMAP
× βαe
e
	(αe)σ −2(αe+1)
e
exp ( −βe/σ 2
e )dσ 2
e
=
βαe
e
	(αe)
|Mθ|1/2	(αe + N/2)
||1/2(2π)N/2

βe + 1
2

xT x + mθ T Mθmθ −T θMAP−(αe+N/2)
.
Despite the advantage of its analytic structure, an obvious challenge of this prior structure is how to
specify the matrix Mθ. It can be chosen as some constant κ times the identity matrix in the absence

3.04.2 Parameter Estimation
157
of further information, in which case κ can be interpreted as a “parameter-to-noise-ratio” term in the
model. This could still be hard to specify in practice without unduly biasing results. One commonly
used version of the general structure is the G-prior, which has an interpretation as a signal-to-noise ratio
speciﬁcation.
3.04.2.3.7
G-prior
A commonly used form of the above normal-inverted-gamma prior structure is the so-called G-prior,
proposed by Zellner [11]. In this, the matrix Mθ is set as follows:
Mθ = gGT G,
where now g is a ﬁxed tuning parameter of the model and has the intuitively appealing interpretation
as a prior “signal-to-noise ratio” between the “signal” term Gθ and the “noise” term e.
The algebra for this prior follows through exactly as for the general case, but with further simpliﬁ-
cations. For example, the marginal likelihood becomes
p(x) =
βαe
e
	(αe)
gP/2	(αe + N/2)
(1 + g)P/2(2π)N/2

βe + 1
2

xT x + mθ T Mθmθ −T θMAP−(αe+N/2)
with
θMAP = −1,
 = GT G(1 + g),
 = GT x + gGT Gmθ.
The G-prior has been found to have useful properties for use in model choice problems.
3.04.2.3.8
Priors on covariance matrices
So far in the Bayesian linear Gaussian model no attempt has been made to model correlated structures,
either in the noise x or the parameters θ, other than through the speciﬁcation of the covariance matrix of
the parameters, Cθ, which thus far has ﬁxed value or well deﬁned structure (the normal-inverse-gamma
model). It is perfectly possible however to assign priors to full covariance matrices and integrate out the
matrix as a hyperparameter, or derive its posterior distribution, as required of the particular application.
In the linear Gaussian model this principle can be applied to the covariance matrix of the noise term
(so far considered to be proportional to the identity matrix, corresponding to independent noise), and/or
to the prior covariance matrix of the parameters θ. Take this latter case as an example. We will wish
to ﬁnd an appropriate prior over positive deﬁnite matrices that has some tractable properties. In fact,
remarkably, there is a conjugate prior for this case which gives full tractability in the linear Gaussian
model. This is the inverse Wishart distribution, see Section A.7.
The prior for Cθ would then be:
p(Cθ) = IWi(Mθ, αθ).

158
CHAPTER 4 Bayesian Computational Methods in Signal Processing
The full conditional distribution under the linear Gaussian model is obtained in a similar way to the IG
prior applied to σ 2
e in (4.31):
p

Cθ|θ, x, σ 2
e

∝p

x|θ, Cθ, σ 2
e

p

θ|Cθ, σ 2
e

p

Cθ|σ 2
e

p

σ 2
e

∝p(θ|Cθ)p(Cθ),
(4.35)
where the simpliﬁcation in the ﬁnal line is owing to the fact that p(x|θ, Cθ, σ 2
e ) = p(x|θ, σ 2
e ) is the
likelihood function, and does not depend upon Cθ, and the fact that the prior on θ does not depend on
σ 2
e , i.e., p(Cθ|σ 2
e ) = p(Cθ).
Now, substituting in the Gaussian and IWi prior terms here from (4.18) and (4.85) we have
p

Cθ|θ, x, σ 2
e

∝N(θ|mθ, Cθ)IWi(Cθ|Mθ, αθ)
∝
1
(2π)P/2|Cθ|1/2 exp

−1
2(θ −mθ)T Cθ −1(θ −mθ)

×
π−P(P−1)/4
P
i=1	(0.5(2αθ + 1 −i))
|Mθ|αθ |Cθ|−(αθ+(P+1)/2) exp

−tr

MθC−1
θ

= IWi

αθ + 1/2, Mθ + 1
2(θ −mθ)(θ −mθ)T

(4.36)
and we can see once again that the inverse Wishart prior is conjugate to the multivariate normal with
unknown covariance matrix. Here the result aT b = tr(baT ) for column vectors a and b has been used
to group together the exponent terms in the expression into a single trace expression.
3.04.2.4 Model uncertainty and Bayesian decision theory
In many problems of practical interest there are also issues of model choice and model uncertainty
involved. For example, how can one choose the number of basis functions P in the linear model (4.1)?
This could amount for example to a choice of how many sinusoids are necessary to model a given signal,
or how many coefﬁcients are required in an autoregressive model formulation. These questions should
be answered automatically from the data and can as before include any known prior information about
the models. There are a number of frequentist approaches to model choice, typically involving compu-
tation of the maximum likelihood parameter vector in each possible model order and then penalizing
the likelihood function to prevent over-ﬁtting by inappropriately high model orders. Such standard tech-
niques include the AIC, MDL, and BIC procedures [12], which are typically based on asymptotic and
information-theoretic considerations. In the fully Bayesian approach we aim to determine directly the
posterior probability for each candidate model. An implicit assumption of the approach is that the true
model which generated the data lies within the set of possible candidates; this is clearly an idealization
for most real-world problems.
As for Bayesian parameter estimation, we consider the unobserved variable (in this case the model
Mi) as being generated by some random process whose prior probabilities are known. These prior
probabilities are assigned to each of the possible model states using a probability mass function (PMF)

3.04.2 Parameter Estimation
159
p(Mi), which expresses the prior probability of occurrence of different states given all information
available except the data x. The required form of Bayes’ theorem for this discrete estimation problem
is then
p(Mi|x) = p(x|Mi)p(Mi)
p(x)
.
(4.37)
p(x) is constant for any given x and will serve to normalize the posterior probabilities over all i in the
same way that the marginal likelihood, or “evidence,” normalized the posterior parameter distribution
(4.10). In the same way that Bayes rule gave a posterior distribution for parameters θ, this expression
gives the posterior probability for a particular model given the observed data x. It would seem reasonable
to choose the model Mi corresponding to maximum posterior probability as our estimate for the true
state (we will refer to this state estimate as the MAP estimate), and this can be shown to have the desirable
property of minimum classiﬁcation error rate PE (see e.g., [7]), that is, it has minimum probability of
choosing the wrong model. Note that determination of the MAP model estimate will usually involve an
exhaustive search of p(Mi|x) for all feasible i.
These ideas are formalized by consideration of a “loss function” λ(αi|M j) which deﬁnes the penalty
incurred by taking action αi when the true state is M j. Action αi will usually refer to the action of
choosing model Mi as the estimate.
The expected risk associated with action αi (known as the conditional risk) is then expressed as
R(αi|x) =
NM

j=1
λ(αi|M j)p(M j|x).
(4.38)
where NM is the total number of models under consideration. It can be shown that it is sufﬁcient to
minimize this conditional risk in order to achieve the optimal decision rule for a given problem and loss
function.
Consider a loss function which is zero when i = j and unity otherwise. This “symmetric” loss
function can be viewed as the equivalent of the uniform cost function used for parameter estimation
(4.15). The conditional risk is then given by:
R(αi|x) =
Ns

j=1,( j̸=i)
p(M j|x)
(4.39)
= 1 −p(Mi|x).
(4.40)
The second line here is simply the conditional probability that action αi is incorrect, and hence mini-
mization of the conditional risk is equivalent to minimization of the probability of classiﬁcation error,
PE. It is clear from this expression that selection of the MAP state is the optimal decision rule for the
symmetric loss function.
3.04.2.4.1
Calculation of the marginal likelihood, p(x|Mi)
The term p(x|Mi) is equivalent to the marginal likelihood term p(x) which was encountered in the
parameter estimation section, since p(x) was implicitly conditioned on a particular model structure or
state in that scheme.

160
CHAPTER 4 Bayesian Computational Methods in Signal Processing
If one uses a uniform model prior p(Mi) =
1
NM , then, according to Eq. (4.37), it is only necessary
to compare values of p(x|Mi) for model selection since the remaining terms are constant for all models.
p(x|Mi) can then be viewed literally as the relative “evidence” for a particular model, and two candidate
models can be compared through their Bayes Factor:
BFi j = p(x|Mi)
p(x|M j).
Typically each model or state Mi will be expressed in a parametric form whose parameters θi are
unknown. As for the parameter estimation case it will usually be possible to obtain the state conditional
parameter likelihood p(x|θi, Mi). Given a model-dependent prior distribution for θi the marginal
likelihood may be obtained by integration to eliminate θi from the joint probability p(x, θi|Mi). The
marginal likelihood is then obtained using result (4.29) as
p(x|Mi) =

θi
p(x|θi, Mi)p(θi|Mi)dθi.
(4.41)
If the linear Gaussian model of (4.1) is extended to the multi-model scenario we obtain:
x = Giθi + ei,
(4.42)
where Gi refers to the state-dependent basis matrix and ei is the corresponding error sequence. For this
model the state dependent parameter likelihood p(x|θi, Mi) is (see (4.8)):
p(x|θi, Mi) =
1
(2πσ 2ei )N/2 exp

−1
2σ 2ei
(x −Giθi)T (x −Giθi)

.
(4.43)
If we for example take the same Gaussian form for the state conditional parameter prior p(θi|Mi)
(with Pi parameters) as we used for p(θ) in (4.18) the marginal likelihood is then given with minor
modiﬁcation as:
p(x|Mi) =
1
(2π)Pi/2|Cθi |1/2||1/2(2πσ 2ei )(N−Pi)/2
× exp

−1
2σ 2ei

xT x + σ 2
ei mθi
T Cθi
−1mθi −T θMAP
i

(4.44)
with terms deﬁned as
θMAP
i
= −1,
(4.45)
 = Gi T Gi + σ 2
ei Cθi
−1,
(4.46)
 = Gi T x + σ 2
ei Cθi
−1mθi .
(4.47)
Notice that θMAP
i
is simply the model-dependent version of the MAP parameter estimate given by (4.20).
We can also of course look at the more sophisticated models using normal-inverted-gamma priors or
G-priors, as before, and then the marginal likelihood expressions are again as given for the parameter
estimation case.

3.04.3 Computational Methods
161
3.04.2.5 Structures for model uncertainty
Model uncertainty may often be expressed in a highly structured way: in particular the models may
be nested or subset structures. In the nested structure for the linear model, the basis matrix for model
Mi+1 is obtained by adding an additional basis vector to the Gi:
Gi+1 = [Gihi+1]
and hence the model of higher order inherits part of its structure from the lower order models. In subset,
or “variable selection” models, a (potentially very large) pool of basis vectors hi, i = 1, . . . , Pmax is
available for construction of the model, and each candidate model is composed by taking a speciﬁc
subset of the available vectors. A particular model Mi is then speciﬁed by a set of Pi distinct integer
indices {i1, i2, . . . , iPi } and the Gi matrix is constructed as
Gi = [hi1hi2 · · · hiPi ].
In such a case there are 2Pmax possible subset models, which could be a huge number. Very often it will
be infeasible to explore the posterior probabilities of all possible subsets, and hence sub-optimal search
strategies are adopted, such as the MCMC algorithms of [13].
3.04.2.6 Bayesian model averaging
In many scenarios where there is model uncertainty, model choice is not the primary aim of the inference.
Take for example the case where a state vector x is common to all models, but each model has different
parameters θi, and the observed data are y. Then the correct Bayesian procedure for inference about x
is to perform marginalisation over all possible models, or perform Bayesian model averaging (BMA):
p(x|y) =

i
p(Mi|y)p(x|y, Mi).
Note though that p(Mi|y) and p(x|y, Mi) may not be analytically computable since they both require
marginalizations (over θi and/or x) and in these cases numerical strategies such as Markov chain Monte
Carlo (MCMC) would be required.
3.04.3 Computational methods
In previous sections we have considered the basic frameworks for Bayesian inference, illustrated through
the linear Gaussian model. This model makes many of the required calculations straightforward and
analytically computable. However, for most real-world problems there will nearly always be intractable
elements in the models, and for these numerical Bayesian methods are required. Take for example the
sinusoidal model presented earlier. If we make the frequencies {ω j} unknown then the model is highly
non-linear in these parameters. Similarly with the autoregressive model, if the signal is now observed
in noise vn as
yn = xn + vn
then the posterior distribution for the parameters is no longer obtainable in closed form.

162
CHAPTER 4 Bayesian Computational Methods in Signal Processing
There is a wide range of computational tools now available for solving complex Bayesian inference
problems, ranging from simple Laplace approximations to posterior densities, through variational Bayes
methods to highly sophisticated Monte Carlo schemes. We will only attempt to give a ﬂavor of some
of the techniques out there, starting with one of the simplest and most effective: the EM algorithm.
3.04.3.1 Expectation-maximization (EM) for MAP estimation
The expectation-maximization (EM) algorithm [14] is an iterative procedure for ﬁnding modes of a
posterior distribution or likelihood function, particularly in the context of “missing data.” EM has been
used quite extensively in the signal processing literature for maximum likelihood parameter estimation,
see e.g., [15–18]. The notation used here is essentially similar to that of Tanner [19, pp. 38–57].
The problem is formulated in terms of observed data y, parameters θ and unobserved (“latent” or
“missing”) data x. A prototypical example of such a set-up is the AR model in noise:
xn =
P

i=1
ai xn−i + en,
(4.48)
yn = xn + vn
in which the parameters to learn will be θ = [a1, . . . , aP]T .
EM is useful in certain cases where it is straightforward to manipulate the conditional posterior
distributions p(θ|x, y) and p(x|θ, y), but perhaps not straightforward to deal with the marginal distri-
butions p(θ|y) and p(x|y). The objective of EM in the Bayesian case is to obtain the MAP estimate for
parameters:
θMAP = argmax
θ
{p(θ|y)} = argmax
θ

x
p(x, θ|y)dx

.
The basic Bayesian EM algorithm can be summarized as:
1. Expectation step:
Given the current estimate θi, calculate:
Q(θ, θi) =

x
log (p(θ|y, x))p(x|θi, y)dx
= E[log (p(θ|y, x))|θi, y].
(4.49)
2. Maximization step:
θi+1 = argmax
θ
{Q(θ, θi)}.
(4.50)
These two steps are iterated until convergence is achieved. The algorithm is guaranteed to converge
to a stationary point of p(θ|y), although we must beware of convergence to local maxima when the
posterior distribution is multimodal. The starting point θ0 determines which posterior mode is reached
and can be critical in difﬁcult applications.
EM-based methods can be thought of as a special case of variational Bayes methods [20,21]. In these,
typically favoured by the machine learning community, a factored approximation to the joint posterior
density is constructed, and each factor is iteratively updated using formulae somewhat similar to EM.

3.04.3 Computational Methods
163
3.04.3.2 Markov chain Monte Carlo (MCMC)
At the more computationally expensive end of the spectrum we can consider Markov chain Monte Carlo
(MCMC) simulation methods [22,23]. The object of these methods is to draw samples from some target
distribution π(ω) which may be too complex for direct estimation procedures. The MCMC approach
sets up an irreducible, aperiodic Markov chain whose stationary distribution is the target distribution of
interest, π(ω). The Markov chain is then simulated from some arbitrary starting point and convergence
in distribution to π(ω) is then guaranteed under mild conditions as the number of state transitions
(iterations) approaches inﬁnity [24]. Once convergence is achieved, subsequent samples from the chain
form a (dependent) set of samples from the target distribution, from which Monte Carlo estimates of
desired quantities related to the distribution may be calculated.
For the statistical models considered in this chapter, the target distribution will be the joint posterior
distribution for all unknowns, p(x, θ|y), from which samples of the unknowns x and θ will be drawn
conditional upon the observed data y. Since the joint distribution can be factorised as p(x, θ|y) =
p(θ|x, y)p(x|y) it is clear that the samples in x which are extracted from the joint distribution are
equivalent to samples from the marginal posterior p(x|y). The sampling method thus implicitly performs
the (generally) analytically intractable marginalisation integral w.r.t. θ.
The Gibbs Sampler [25,26] is perhaps the most simple and popular form of MCMC currently in use
for the exploration of posterior distributions. This method, which can be derived as a special case of the
more general Metropolis-Hastings method [22], requires the full speciﬁcation of conditional posterior
distributions for each unknown parameter or variable. Suppose that the reconstructed data and unknown
parametersaresplitinto(possiblymultivariate)subsetsx = {x0, x1, . . . , xN−1}andθ = {θ1, θ2 . . . , θq}.
Arbitrary starting values x0 and θ0 are assigned to the unknowns. A single iteration of the Gibbs Sampler
then comprises sampling each variable from its conditional posterior with all remaining variables ﬁxed
to their current sampled value. The (i + 1)th iteration of the sampler may be summarized as:
θi+1
1
∼p

θ1|θi
2, . . . , θi
q, xi
0, xi
1, . . . , xi
N−1, y

,
θi+1
2
∼p

θ2|θi+1
1
, . . . , θi
q, xi
0, xi
1, . . . , xi
N−1, y

,
...
θi+1
q
∼p

θq|θi+1
1
, θi+1
2
, . . . , xi
0, xi
1, . . . , xi
N−1, y

,
xi+1
0
∼p

x0|θi+1
1
, θi+1
2
, . . . , θi+1
q
, xi
1, . . . , xi
N−1, y

,
xi+1
1
∼p

x1|θi+1
1
, θi+1
2
, . . . , θi+1
q
, xi+1
0
, xi
2, . . . , xi
N−1, y

,
...
xi+1
N−1 ∼p

xN−1|θi+1
1
, θi+1
2
, . . . , θi+1
q
, xi+1
0
, xi+1
1
, . . . , xi+1
N−2, y

,
where the notation “∼” denotes that the variable to the left is drawn as a random independent sample
from the distribution to the right.

164
CHAPTER 4 Bayesian Computational Methods in Signal Processing
The utility of the Gibbs Sampler arises as a result of the fact that the conditional distributions,
under appropriate choice of parameter and data subsets (θi and x j), will be more straightforward to
sample than the full posterior. Multivariate parameter and data subsets can be expected to lead to faster
convergence in terms of number of iterations (see e.g., [27,28]), but there may be a trade-off in the extra
computational complexity involved per iteration. Convergence properties are a difﬁcult and important
issue and concrete results are fairly rare. Numerous (but mostly ad hoc) convergence diagnostics have
been devised for more general scenarios and a review may be found in [29], for example.
Once the sampler has converged to the desired posterior distribution, inference can easily be made
from the resulting samples. One useful means of analysis is to form histograms or kernel density
estimates of any parameters of interest. These converge in the limit to the true marginal posterior
distribution for those parameters and can be used to estimate MAP values and Bayesian conﬁdence
intervals, for example. Alternatively a Monte Carlo estimate can be made for the expected value of any
desired posterior functional f (·) as a ﬁnite summation:
E[ f (x)|y] ≈
Nmax
i=N0+1 f (xi)
Nmax −N0
,
(4.51)
where N0 is the convergence (“burn in”) time and Nmax is the total number of iterations. The MMSE
estimator for example, is simply the posterior mean, estimated by setting f (x) = x in (4.51).
MCMC methods are computer-intensive and will only be applicable when off-line processing is
acceptable and the problem is sufﬁciently complex to warrant their sophistication. However, they are
currently unparalleled in ability to solve the most challenging of modeling problems. A more extensive
survey can be found in the E-reference article by A.T. Cemgil. Further reading material includes MCMC
for model uncertainty [30,31].
3.04.4 State-space models and sequential inference
In this section we describe inference methods that run sequentially, or on-line, using the state-space
formulation. These are vital in many applications, where either the data are too large to process in one
batch, or results need to be produced in real-time as new data points arrive. In sequential inference we
have seen some of the most exciting advances in methodology over the last decade.
3.04.4.1 Linear Gaussian state-space models
Most linear time series models, including the AR models discussed earlier, can be expressed in the state
space form:
yn = Zαn + vn
(observation equation),
(4.52)
αn+1 = T αn + Hen
(state update equation).
(4.53)
In the top line, the observation equation, the observed data yn is expressed in terms of an unobserved
state αn and a noise term vn. vn is uncorrelated (i.e., E[vnvT
m] = 0 for n ̸= m) and zero mean, with
covariance Cv. In the second line, the state update equation, the state αn is updated to its new value αn

3.04.4 State-Space Models and Sequential Inference
165
at time n + 1 and a second noise term en. en is uncorrelated (i.e., E[eneT
m] = 0 for n ̸= m) and zero
mean, with covariance Ce, and is also uncorrelated with vn. Note that in general the state αn, observation
yn and noise terms en/vn can be column vectors and the constants Z, T , and H are then matrices of the
implied dimensionality. Also note that all of these constants can be made time index dependent without
altering the form of the results given below.
Take, for example, an AR model {xt} observed in noise {vn}, so that the equations in standard
form are:
yn = xn + vn,
xn =
P

i=1
ai xn−i + en.
One way to express this in state-space form is as follows:
αn =
 xn
xn−1
xn−2
. . .
xn−P+1
	T ,
T =
⎡
⎢⎢⎢⎢⎢⎣
a1
a2
. . . aP
1
0
. . .
0
0
1
. . .
0
...
...
...
0
0
0
. . .
1
⎤
⎥⎥⎥⎥⎥⎦
,
H =
1 0 . . . 0 	T ,
Z = H T ,
Ce = σ 2
e ,
Cv = σ 2
v .
The state-space form is useful since some elegant results exist for the general form which can be
applied in many different special cases. In particular, we will use it for sequential estimation of the state
αn. In probabilistic terms this will involve updating the posterior probability for αn with the input of a
new observation yn+1:
p(αn+1|y1:n+1) = g(p(αn|y1:n), yn+1),
where y1:n = [y1, . . . , yn]T and g(·) denotes the sequential updating function.
Suppose that the noise sources en and vn are Gaussian. Assume also that an initial state probability
or prior p(α0) exists and is Gaussian N(m0, C0). Then the posterior distributions are all Gaussian
themselves and the posterior distribution for αn is fully represented by its sufﬁcient statistics: its mean
an = E[αn|y0, . . . , yn] and covariance matrix Pn = E[(αn −an)(αn −an)T | y0, . . . , yn]. The Kalman
ﬁlter [9,32,33] performs the update efﬁciently, as follows:
1. Initialise: a0 = m0, P0 = C0
2. Repeat for n = 1 to N:

166
CHAPTER 4 Bayesian Computational Methods in Signal Processing
a. Prediction:
an|n−1 = Tan−1,
Pn|n−1 = T Pn−1T T + HCeH T .
b. Correction:
an = an|n−1 + Kn(yn −Zan|n−1),
Pn = (I −Kn Z)Pn|n−1,
where
Kn = Pn|n−1Z T (Z Pn|n−1Z T
n + Cv)−1
(Kalman Gain).
Here an|n−1 is the predictive mean E[αn|yn−1], Pn|n−1 the predictive covariance E[(αn −an|n−1)(αn −
an|n−1)T |yn−1] and I denotes the (appropriately sized) identity matrix.
This is the probabilistic interpretation of the Kalman ﬁlter, assuming Gaussian distributions for noise
sources and initial state, and it is this form that we will require in the next section on sequential Monte
Carlo. In that section it will be more fully developed in the probabilistic version. The more standard
interpretation is as the best linear estimator for the state [9,32,33].
3.04.4.2 The prediction error decomposition
One remarkable property of the Kalman ﬁlter is the prediction error decomposition which allows exact
sequential evaluation of the likelihood function for the observations. If we suppose that the model
depends upon some hyperparameters θ, then the Kalman ﬁlter updates sequentially, for a particular
value of θ, the density p(αn|y1:n, θ). We deﬁne the likelihood for θ in this context to be:
p(y1:n|θ) =

p(αn, y1:n|θ)dαn
from which the ML or MAP estimator for θ can be obtained by optimization. The prediction error
decomposition [9, pp. 125–126] calculates this term from the outputs of the Kalman ﬁlter:
log (p(y1:n|θ)) = −Mn
2
log (2π) −1
2
n

t=1
log |Ft| −1
2
n

t=1
wT
t F−1
t
wt,
(4.54)
where
Ft = Z Pt|t−1Z T + Cv,
wt = yt −Zat|t−1
and where M is the dimension of the observation vector yn.

3.04.4 State-Space Models and Sequential Inference
167
3.04.4.3 Sequential Monte Carlo (SMC)
It is now many years since the pioneering contribution of Gordon et al. [34], which is commonly
regarded as the ﬁrst instance of modern sequential Monte Carlo (SMC) approaches. Initially focussed on
applications to tracking and vision, these techniques are now very widespread and have had a signiﬁcant
impact in virtually all areas of signal and image processing concerned with Bayesian dynamical models.
This section serves as a brief introduction to the methods for the practitioner.
Consider the following generic nonlinear extension of the linear state-space model:
•
System model:
xt = a(xt−1, ut) ↔
Transition Density



f (xt|xt−1)
.
(4.55)
•
Measurement model:
yt = b(xt, vt) ↔
Observation Density
  
g(yt|xt)
.
(4.56)
By these equations we mean that the hidden states xt and data yt are assumed to be generated by
nonlinear functions a(·) and b(·), respectively, of the state and noise disturbances ut and vt. The precise
form of the functions and the assumed probability distributions of the state ut and the observation vt
noises imply via a change of variables the transition probability density function f (xt|xt−1) and the
observation probability density function g(yt|xt). It is assumed that xt is Markovian, i.e., its conditional
probability density given the past states x0:t−1
def
= (x0, . . . , xt−1) depends only on xt−1 through the
transition density f (xt|xt−1), and that the conditional probability density of yt given the states x0:t
and the past observations y0:t−1 depends only upon xt through the conditional likelihood g(yt|xt). We
further assume that the initial state x0 is distributed according to a density function p(x0). Such nonlinear
dynamic systems arise frequently from many areas in science and engineering such as target tracking,
computer vision, terrain referenced navigation, ﬁnance, pollution monitoring, communications, audio
engineering, to list but a few.
A simple and standard example is now given to illustrate the model class.
Example 1.
(Nonlinear time series model) This model has been used quite extensively in the ﬁltering
literature [34–36]. The required equations are as follows:
xt = xt−1
2
+ 25
xt−1
1 + x2
t−1
+ 8 cos (1.2t) + ut,
yt = x2
t
20 + vt,
where ut ∼N(0, σ 2
u ) and vt ∼N(0, σ 2
v ) and here σ 2
u = 10 and σ 2
v = 1 are considered ﬁxed and known;
N(μ, σ 2) once again denotes the normal distribution with mean μ and variance σ 2. The representation

168
CHAPTER 4 Bayesian Computational Methods in Signal Processing
in terms of densities f (xt|xt−1) and g(yt|xt) is given by:
f (xt|xt−1) = N

xt
xt−1
2
+ 25
xt−1
1 + x2
t−1
+ 8 cos (1.2t), σ 2
u

,
g(yt|xt) = N

yt

x2
t
20, σ 2
v

.
The form of these densities was straightforward to obtain in this case. For more complex cases a Jacobian
term might be required when either xt or yt is a nonlinear function of ut or vt, respectively.
States may easily be simulated from a dynamical model of this sort owing to the Markovian assump-
tions on xt and yt, which imply that the joint probability density of states and observations, denoted
p(x0:T , y0:T ), may be factorized as
p(x0:T , y0:T ) = f (x0)
T
t=1
f (xt|xt−1)g(yt|xt).
A graphical representation of the dependencies between different states and observations is shown in
Figure 4.1.
The ability to simulate random states and to evaluate the transition and observation densities (at least
up to an unknown normalizing constant) will be principal components of the particle ﬁltering algorithms
described shortly.
Bayesian inference for the general nonlinear dynamic system above involves computing the posterior
distribution of a collection of state variables xs:s′ def
= (xs, . . . , xs′) conditioned on a batch of observations,
y0:t = (y0, . . . , yt), which we denote p(xs:s′|y0:t). Speciﬁc problems include ﬁltering, for s = s′ = t,
ﬁxed lag smoothing, when s = s′ = t −L and ﬁxed interval smoothing, if s = 0 and s′ = t. Despite
the apparent simplicity of the above problem, the posterior distribution can be computed in closed form
only in very speciﬁc cases, principally, the linear Gaussian model (where the functions a( ) and b( )
are linear and ut and vt are Gaussian) and the discrete hidden Markov model (where xt takes its values
in a ﬁnite alphabet). In the vast majority of cases, nonlinearity or non-Gaussianity render an analytic
solution intractable [32,37–39].
FIGURE 4.1
Graphical model illustrating the Markovian dependencies between states and observations.

3.04.4 State-Space Models and Sequential Inference
169
There are many classical (non-Monte Carlo-based) methods for nonlinear dynamic systems, includ-
ing the extended Kalman ﬁlter (EKF) and its variants [40], Gaussian sum ﬁlters [41], unscented and
quadrature Kalman ﬁlters [42–44]. However, limitations in the generality of these approaches to the
most nonlinear/non-Gaussian systems has stimulated interest in more general techniques. Among these,
Monte Carlo methods, in which the posterior distribution is represented by a collection of random points,
are central. Early approaches include sequential importance sampling in the pioneering works of Hand-
schin and Mayne [45] and Handschin [46]. The incorporation of resampling techniques was key though
to the practical success of such approaches, as given in [34]. Without resampling, as the number of time
points increases, the importance weights tend to degenerate, a phenomenon known as sample impov-
erishment or weight degeneracy. Since then, there have been several independent variants of similar
ﬁltering ideas, including the Condensation ﬁlter [47], Monte Carlo ﬁlter [35], Sequential imputations
[48], and the Particle ﬁlter [49]. So far, sequential Monte Carlo (SMC) methods have been successfully
applied in many different ﬁelds including computer vision, signal processing, tracking, control, econo-
metrics, ﬁnance, robotics, and statistics; see [37,39,50,51] and the references therein for a good review
coverage.
3.04.4.3.1
Predictor-corrector formulation
Wenowpresentthebasicupdateforthestate-spacemodel.Startingwiththeinitial,or“prior,”distribution
p(x0), the posterior density p(x0:t|y0:t) can be obtained using the following prediction-correction
recursion [52]:
•
Prediction:
p(x0:t|y0:t−1) = p(x0:t−1|y0:t−1) f (xt|xt−1),
(4.57)
•
Correction:
p(x0:t|y0:t) = g(yt|xt)p(x0:t|y0:t−1)
p(yt|y0:t−1)
,
(4.58)
where p(yt|y0:t−1) is a constant for any given data realization. It will not be necessary to compute
this term in standard implementations of SMC methods.
3.04.4.4 Particle ﬁltering and auxiliary sampling
We now present a general form for of the particle ﬁlter, using the auxiliary ﬁltering ideas of Pitt and
Shephard [53], and which includes most common variants as special cases. We ﬁrst represent the
posterior smoothing density approximately as a weighted sum of δ functions
p(x0:t) ≈
N

i=1
ω(i)
t δx(i)
0:t (x0:t),
(4.59)
where the notation δx(i)
0:t denotes the Dirac mass at point x(i)
0:t . Under suitable technical assumptions, this
is a consistent approximation, i.e., for any function h on the path space
N

i=1
ω(i)
t h

x(i)
0:t

,

170
CHAPTER 4 Bayesian Computational Methods in Signal Processing
converges to E[h(x0:t] as the number N of particles increases to inﬁnity, see [37,54–58] for technical
considerations.
The formulation given here is equivalent to that given by Pitt and Shephard [53], although we
avoid the explicit inclusion of an auxiliary indexing variable by considering a proposal over the entire
path of the process up to time t. The starting assumption is that the joint posterior at t −1 is well
approximated as
p(x0:t−1|y0:t−1) ≈
N

i=1
ω(i)
t−1δx(i)
0:t (x0:t).
Based on this assumption the joint posterior distribution at time t is approximated by substitution into
the prediction-correction equations:
p(x0:t|y0:t) ≈1
Z
N

i=1
ω(i)
t−1δx(i)
0:t−1(x0:t−1)g(yt|xt) f

xt|x(i)
t−1

,
(4.60)
where the normalization factor Z is given by
Z =
N

j=1
ω( j)
t−1

f

x|x( j)
t−1

g(yt|x)dx.
Now we consider a general joint proposal for the entire path of the new particles x(i)
0:t , that is,
qt(x0:t) = q0:t−1(x0:t−1|y0:t)qt(xt|xt−1, yt)
=
 N

i=1
v(i)
t−1δx(i)
0:t−1(x0:t−1)

×

qt(xt|x(i)
t−1, yt)

,
where N
i=1 v(i)
t−1 = 1 and v(i)
t−1 > 0. Notice that the proposal splits into two parts: a marginal proposal
q0:t−1 for the past path of the process x0:t−1 and a conditional proposal qt for the new state xt. Note that
the ﬁrst component is constructed to depend explicitly on data up to time t in order to allow adaptation
of the proposal in the light of the new data point yt (and indeed it may depend on future data points as
well if some look-ahead and latency is allowable). The ﬁrst part of the proposal is a discrete distribution
centered upon the old particle paths {x(i)
0:t−1}, but now with probability mass for each component in the
proposal distribution designed to be {v(i)
t−1}. The weighting function v(i)
t−1 can be data dependent, the
rationale being that we should preselect particles that are a good ﬁt to the new data point yt. For example,
Pitt and Shephard [53] suggest taking a point value μ(i) of the state, say the mean or mode of f (xt|x(i)
t−1),
and computing the weighting function as the likelihood evaluated at this point, i.e., v(i)
t−1 = g(yt|μ(i)
t );
or if the particles from t −1 are weighted, one would choose v(i)
t−1 = ω(i)
t−1g(yt|μ(i)
t ).

3.04.4 State-Space Models and Sequential Inference
171
Using this proposal mechanism it is then possible to deﬁne an importance ratio between the approx-
imate posterior in (4.60) and the full path proposal q, given by
˜ω(i)
t
= ω(i)
t−1
v(i)
t−1
×
g

yt
x(i)
t

f

x(i)
t
 x(i)
t−1

qt

x(i)
t
 x(i)
t−1, yt

.
The choice of the proposal terms vt−1 and qt then determines the behavior of the particle ﬁlter. With
vt−1 constant and qt set to equal the transition density, we achieve the standard bootstrap ﬁlter of [34].
With vt−1 constant and qt chosen to be a data-dependent proposal for the new state, we have the particle
ﬁlter of [59].
More general schemes that allow some exploration of future data points by so-called pilot sampling
to generate the weighting function have been proposed in, for example [60], while further discus-
sion of the framework can be found in [61]. A summary of the auxiliary particle ﬁlter is given in
Algorithm 1. We assume here that the selection (resampling) step occurs at each point, although it may
be omitted exactly as in the standard particle ﬁlter, in which case no weight correction is applied. These
techniques are developed and extensively reviewed in [37,39,44,59,62,63].
A diagrammatic representation of the bootstrap ﬁlter in operation is given in Figure 4.2, in which
the resampling (selection) step is seen to concentrate particles (asterisks) into the two high probability
modes of the density function.
3.04.4.4.1
Marginalized particle ﬁlters
In many practical scenarios, especially those found in the tracking domain, the models are not entirely
nonlinear and non-Gaussian. By this we mean that some subset of the state vector is linear and Gaussian,
conditional upon the other states. In these cases one may use standard linear Gaussian optimal ﬁltering
for the linear part, and particle ﬁltering for the nonlinear part. This may be thought of as an optimal
Gaussian mixture approximation to the ﬁltering distribution. See [59,64,65] for detailed descriptions
of this approach to the problem, which is referred to either as the Rao-Blackwellized particle ﬁlter, or
Mixture Kalman ﬁlter. Recent work [66,67] has studied in detail the possible classes of model that
may be handled by the marginalized ﬁlter, and computational complexity issues. The formulation is as
follows.3 First, the state is partitioned into two components, x L
t and x N
t , referring respectively to the
linear (“L”) and nonlinear (“N”) components. The linear part of the model is expressed in the form of
a linear Gaussian state-space model as follows, with state-space matrices that may depend upon the
nonlinear state x N
t :
3Karlsson et al. [67] and Schön et al. [66] present a more general class of models to which the marginalized ﬁlter may be
applied, but we present a more basic framework for the sake of simplicity here.

172
CHAPTER 4 Bayesian Computational Methods in Signal Processing
Algorithm 1. Auxiliary Particle Filter
for i = 1, . . . , N do
▷Initialisation
Sample ˜x(i)
0
∼q0(x0|y0).
Assign initial importance weights
˜ω(i)
0
=
g

y0|˜x(i)
0

π0

˜x(i)
0

q0

˜x(i)
0 |y0

.
end for
for t = 1, . . . , T do
Select N particle indices ji ∈{1, . . . , N} according to weights
 
v(i)
t−1
!N
i=1 .
for i = 1, . . . , N do
Set x(i)
t−1 = ˜x( ji)
t−1.
Set ﬁrst stage weights:
u(i)
t−1 =
ω( ji)
t−1
v( ji)
t−1
.
end for
for i = 1, . . . , N do
Propagate:
˜x(i)
t
∼qt

˜x(i)
t
 x(i)
t−1, yt

.
Compute weight:
˜ω(i)
t
= u(i)
t−1
g

yt
˜x(i)
t

f

˜x(i)
t
 x(i)
t−1

qt

˜x(i)
t
 x(i)
t−1, yt

.
end for
Normalize weights:
ω(i)
t
= ˜ω(i)
t
" N

j=1
˜ω( j)
t
,
i = 1, . . . , N.
end for

3.04.4 State-Space Models and Sequential Inference
173
FIGURE 4.2
The bootstrap ﬁlter in operation from time t to t + 1, nonlinear time series Example 1. Asterisks show the positions of (a small selection
of) the particles at each stage. The solid line shows a kernel density estimate of the distributions represented at each stage. Ten thousand
particles were used in total. Notice that resampling concentrates particles into the region of high probability.

174
CHAPTER 4 Bayesian Computational Methods in Signal Processing
x L
t = A

x N
t

x L
t−1 + uL
t ,
(4.61)
yt = B

x N
t

x L
t + vL
t .
(4.62)
Here uL
t and vL
t are independent, zero-mean, Gaussian disturbances with covariances Cu and Cv, respec-
tively, and A( ) and B( ) are matrices of compatible dimensions that may depend upon the nonlinear
state x N
t . At t = 0, the linear part of the model is initialised with x L
0 ∼N(μ0(x N
0 ), P0(x N
0 )).
Now the nonlinear part of the state obeys a general dynamical model (which is not necessarily
Markovian):
x N
t
∼f

x N
t
 x N
0:t−1

,
x N
0 ∼f

x N
0

.
(4.63)
In such a case, conditioning on the nonlinear part of the state x N
0:t and the observations y0:t, the linear
part of the state is jointly Gaussian and the means and covariances of this Gaussian representation may
be obtained by using the classical Kalman ﬁltering recursions [68]. The basic idea is then to marginalize
the linear part of the state vector to obtain the posterior distribution of the nonlinear part of the state:
p

x N
0:t|y0:t

=

p

x L
0:t, x N
0:t
 y0:t

dx L
0:t.
Particle ﬁltering is then run on the nonlinear state sequence only, with target distribution p(x N
0:t|y0:t).
The resulting algorithm is almost exactly as before, requiring only a slight modiﬁcation to the basic
particle ﬁlter to allow for the fact that the marginalized system is no longer Markovian, since
p(yt|y0:t−1, x N
0:t) ̸= p(yt|x N
t ).
Moreover, the dynamical model for the nonlinear part of the state may itself be non-Markovian, see
Eq. (4.63).
Thus, instead of the usual updating rule we have:
•
Prediction:
p

x N
0:t
 y0:t−1

= p

x N
0:t−1
 y0:t−1

f

x N
t
 x N
0:t−1

.
(4.64)
•
Correction:
p

x N
0:t
 y0:t

= p

yt
y0:t−1, x N
0:t

p

x N
0:t
 y0:t−1

p(yt|y0:t−1)
,
(4.65)
where as before p(yt|y0:t−1) is the predictive distribution of yt given the past observations y0:t−1,
which is a ﬁxed normalizing constant (independent of the state sequence x N
0:t).
Note that if {(x N,(i)
0:t
, ω(i)
t )}i=1,...,N denote the particles evolving in the state-space of the nonlinear
variables according to the above equations, and their associated importance weights, estimation of the

3.04.4 State-Space Models and Sequential Inference
175
linear part of the state may be done using a Rao-Blackwellized estimation scheme [69]: the posterior
density for the linear part is obtained as a random Gaussian mixture approximation given by
p

x L
t
 y0:t

≈
N

i=1
ω(i)
t
p

x L
t
 x N,(i)
0:t
, y0:t

,
(4.66)
where the conditional densities p(x L
t |x N,(i)
0:t
, y0:t) are Gaussian and computed again using Kalman
ﬁltering recursions. Equation (4.66) replaces the standard point-mass approximation (4.59) arising in
the generic particle ﬁlter. The Rao-Blackwellized estimate is usually better in terms of Monte Carlo
error than the corresponding scheme that performs standard particle ﬁltering jointly in both nonlinear
and linear states. The computational trade-off is more complex, however, since the marginalized ﬁlter
can be signiﬁcantly more time-consuming than the standard ﬁlter per particle. These trade-offs have
been extensively studied by Schön et al. [66] and in many cases the performance/computation trade-off
comes out in favor of the marginalized ﬁlter.
To give further detail to the approach, we ﬁrst summarize the Kalman ﬁlter itself in this probabilistic
setting [52], then we place the whole scheme back in the particle ﬁltering context. As a starting point,
assume the distribution p(x L
t−1|y0:t−1, x N
0:t−1) has been obtained. This is a Gaussian, denoted by
p

x L
t−1
 y0:t−1, x N
0:t−1

= N

x L
t−1
 μt−1|0:t−1, Ct−1|0:t−1

,
where the mean and covariance terms are dependent upon both y0:t−1 and x N
0:t−1. Now, (4.61) shows
how to update this distribution one step, since x L
t is just a summation of two transformed independent
Gaussian random vectors, A(x N
t )x L
t−1 and uL
t , which itself must be a Gaussian. Under the standard rules
for summation of independent Gaussian random vectors, we obtain the predictive distribution for x L
t ,
conditioned upon y0:t−1 and x N
0:t, as follows:
p

x L
t
 y0:t−1, x N
0:t

= N

x L
t
 μt|0:t−1, Ct|0:t−1

,
(4.67)
where
μt|0:t−1 = A

x N
t

μt−1|0:t−1,
Ct|0:t−1 = A

x N
t

Ct−1|0:t−1A

x N
t
T
+ Cu.
As a second step in the update, the new data point yt is incorporated through Bayes’ theorem:
p

x L
t
 y0:t, x N
0:t

= p

x L
t
 y0:t−1, x N
0:t

× p

yt| x L
t , x N
t

p

yt| y0:t−1, x N
0:t

(4.68)
∝N

x L
t |μt|0:t−1, Ct|0:t−1

× N

yt|B

x N
t

x L
t , Cv

= N

x L
t |μt|0:t, Ct|0:t

,

176
CHAPTER 4 Bayesian Computational Methods in Signal Processing
where μt|0:t and Ct|0:t are obtained by standard rearrangement formulae as
μt|0:t = μt|0:t−1 + Kt

yt −B

x N
t

μt|0:t−1

,
Ct|0:t =

I −Kt B

x N
t

Ct|0:t−1,
Kt = Ct|0:t−1BT 
x N
t
 
B

x N
t

Ct|0:t−1BT 
x N
t

+ Cv
−1
,
and where the term Kt is known as the Kalman Gain. In order to complete the analysis for particle ﬁlter
use, one further term is required, p(yt|y0:t−1, x N
0:t). This is obtained by the so-called prediction error
decomposition, which is easily obtained from (4.67), since yt is obtained by summing a transformed
version of x L
t , i.e., B(x N
t )x L
t , with an independent zero-mean Gaussian noise term vL
t having covariance
Cv, leading to:
p

yt| y0:t−1, x N
0:t

= N

yt| μyt , Cyt

,
(4.69)
where
μyt = B

x N
t

μt|0:t−1,
Cyt = B

x N
t

Ct|0:t−1BT 
x N
t

+ Cv.
In order to construct the marginalized particle ﬁlter, notice that for any realization of the nonlinear state
sequence x N
0:t, and data sequence y0:t, one may calculate the value of p(yt|y0:t−1, x N
0:t) in (4.69) through
sequential application of the formulae (4.67) and (4.68). The marginalized particle ﬁlter then requires
computation and storage of the term p(yt|y0:t−1, x N,(i)
0:t
) in (4.69), for each particle realization x N,(i)
0:t
. In
the marginalized particle ﬁlter the particles are stored as the nonlinear part of the state x N
t , the associated
sufﬁcient statistics for each particle, i.e., μt|0:t and Ct|0:t, and the weight for each particle. We do not
give the entire modiﬁed algorithm. The only signiﬁcant change is to the weighting step, which becomes
˜ω(i)
t
= ω(i)
t−1
p

yt
y0:t−1, ˜x N,(i)
t

f

˜x N,(i)
t
 x N,(i)
0:t−1

qt

˜x N,(i)
t
 x N,(i)
0:t−1, y0:t

.
As an important aside, we note that the marginalized ﬁlter may also be used to good effect when the
linear states are unknown but “static” over time, i.e., f (dx L
t |x L
t−1) = δx L
t−1(dx L
t ) with some Gaussian
initial distribution or prior x L
0 ∼N(μ0(x N
0 ), P0(x N
0 )), as before. Then the marginalized ﬁlter runs
exactly as before but we are now able to marginalize, or infer the value of, a static parameter θ = x L
t .
Early versions of such ﬁlters are found in the sequential imputations work of [48], for example.
We have focused here on the linear Gaussian case of the marginalized ﬁlter. However, another
importantclassofmodelsisthediscretestate-spacehiddenMarkovmodel,inwhichthestatesarediscrete
values and switching may occur between one time and the next according to a Markov transition matrix.
As for the linear Gaussian case, the discrete state values may be marginalized to form a marginalized
particle ﬁlter, using the HMM forward algorithm [70] instead of the Kalman ﬁlter [59]. For simulations
and examples within both frameworks, see [37,59].

3.04.4 State-Space Models and Sequential Inference
177
As mentioned before, several generalisations are possible to the basic model. The most basic of these
allow dependence of the matrices A( ), B( ), Cu, and Cv to depend on time, and any or all elements
of the nonlinear state sequence x N
0:t. None of these changes require any modiﬁcation to the algorithm
formulation. Another useful case allows a deterministic function of the nonlinear states to be present in
the observation and dynamical equations. These two features combined lead to the following form:
x L
t = At

x N
0:t

x L
t−1 + c

x N
0:t

+ uL
t ,
yt = Bt

x N
0:t

x L
t + d

x N
0:t

+ vL
t ,
and again the form of the algorithm is unchanged; see [9] for a good coverage of the most general form
of Kalman ﬁlters required in these cases.
One other important case involves nonlinear observations that are not a function of the linear state.
Then the linear observation Eq. (4.62) can be generalized to yt ∼g(yt|x N
t ), which is a general obser-
vation density. This form is quite useful in tracking examples, where observation functions are often
nonlinear (range and bearings, for example, or range-only), but dynamics can be considered as linear to
a good approximation [64,66,67]. If in addition the nonlinear state can be expressed in linear Gaussian
state-space form with respect to the linear state, i.e.:
x N
t
= B

x N
t

x L
t + c

x N
t−1

+ vL
t ,
x L
t = A

x N
t

x L
t−1 + uL
t ,
then once again the Kalman ﬁlter can be run to marginalize the linear state variable. In this case the
weight expression becomes:
˜ω(i)
t
= ω(i)
t−1
g

yt
˜x N,(i)
t

p

˜x N,(i)
t
 x N,(i)
0:t−1

qt

˜x N,(i)
t
 x N,(i)
0:t−1, y0:t

,
where now the term p(˜x N,(i)
t
|x N,(i)
0:t−1) is computed using the Kalman ﬁlter. In some cases the linear state
transition matrices and observation matrices A( ) and B( ) for this Kalman ﬁlter are independent of the
nonlinear state and the observations; then this form of marginalized particle ﬁlter may be computed very
efﬁciently, since the covariance matrices are identical for all particles and thus need only be computed
once at each time step.
3.04.4.4.2
Further material
In this section on particle ﬁltering we have given a general introduction. For further material please
see [50,71,72]. For smoothing with particle ﬁlters, see for example [35,58,59,73–81], for parameter
estimation with particle ﬁlters [34,37,63,77,82–93], and for recent combinations with MCMC [94].

178
CHAPTER Bayesian Computational Methods in Signal Processing
3.04.5 Conclusion
This article has introduced the basic principles of parameter inference and state estimation within the
Bayesian framework. We have considered a linear Gaussian parametric model by way of illustration.
We have also given an introductory coverage to some of the principal computational tools available for
the practitioner, including MCMC and the particle ﬁlter.
A Probability densities and integrals
A.1 Univariate Gaussian
The univariate Gaussian, or normal, density function with mean μ and variance σ 2 is deﬁned for a
real-valued random variable as:
N(x|μ, σ 2) =
1
√
2πσ 2 e−
1
2σ2 (x−μ)2
,
(4.70)
Univariate normal density.
A.2 Multivariate Gaussian
The multivariate Gaussian probability density function (PDF) for a column vector x with N real-valued
components is expressed in terms of the mean vector mx and the covariance matrix Cx = E[(x −mx)
(x −mx)T ] as:
NN(x|m, Cx) =
1
(2π)N/2|Cx|1/2 exp

−1
2

x −mx
T Cx−1 
x −mx

,
(4.71)
Multivariate Gaussian density.
An integral which is used on many occasions throughout the text is of the general form:
I =

y
exp

−1
2

a + bT y + yTCy

dy,
(4.72)
where dy is interpreted as the inﬁnitesimal volume element:
dy =
N

i=1
dyi
and the integral is over the real line in all dimensions, i.e., the single integration sign should be inter-
preted as:

y
≡
 ∞
y1=−∞
· · ·
 ∞
yN =−∞
.

A Probability Densities and Integrals
179
For non-singular symmetric C it is possible to form a “perfect square” for the exponent and hence
simplify the integral. Take negative of twice the exponent:
a + bT y + yTCy
(4.73)
and try to express it in the form:
(y −my)T C(y −my) + k
for some constants k and C, to be determined. Multiplying out this expression leads to the required
form:
yT Cy + mT
y Cmy −2mT
y Cy + k.
Here we have used the fact that mT
y Cy = yT Cmy, since C is assumed symmetric.
Hence, equating the constant, linear and quadratic terms in y, we arrive at the result:
a + bT y + yT Cy = (y −my)T C(y −my) + k,
(4.74)
where
my = −C−1b
2
and
k =

a −bT C−1b
4

.
Thus the integral I can be re-expressed as:
I =

y
exp

−1
2

(y −my)T C(y −my)

× exp

−1
2

a −bT C−1b
4

dy,
(4.75)
where, again
my = −C−1b
2
.
Comparison with the multivariate PDF of (4.71) which has unity volume leads directly to the result:

y
exp

−1
2

a + bT y + yT Cy

dy
= (2π)N/2
|C|1/2
exp

−1
2

a −bT C−1b
4

,
(4.76)
Multivariate Gaussian integral.
This result can be also be obtained directly by a transformation which diagonalizes C and this
approach then veriﬁes the normalization constant given for the PDF of (4.71).

180
CHAPTER Bayesian Computational Methods in Signal Processing
A.3 Gamma density
Another distribution which will be of use is the two parameter gamma density G(α, β), deﬁned for
α > 0, β > 0 as
G(y|α, β) =
βα
	(α) yα−1 exp ( −βy) (0 < y < ∞),
(4.77)
Gamma density.
	( ) is the Gamma function (see e.g., [95]), deﬁned for positive arguments. This distribution with
its associated normalization enables us to perform marginalisation of scale parameters with Gaussian
likelihoods and a wide range of parameter priors (including uniform, Jeffreys, Gamma, and Inverse
Gamma (see [96]) priors) which all require the following result:
 ∞
y=0
yα−1 exp ( −βy)dy = 	(α)/βα,
(4.78)
Gamma integral.
Furthermore the mean, mode and variance of such a distribution are obtained as:
μ = E[Y] = α/β,
(4.79)
m = argmax
y
(p(y)) = (α −1)/β,
(4.80)
σ 2 = E[(Y −μ)2] = α/β2.
(4.81)
A.4 Inverted-gamma distribution
A closely related distribution is the inverted-gamma distribution, IG(α, β) which describes the distri-
bution of the variable 1/Y, where Y is distributed as G(α, β):
IG(y|α, β) =
βα
	(α) y−(α+1) exp ( −β/y) (0 < y < ∞),
(4.82)
Inverted-gamma density.
The IG distribution has a unique maximum at β/(α + 1), mean value β/(α −1) (for α > 1) and
variance β2/((α −1)2(α −2)) (for α > 2).
It is straightforward to see that the improper Jeffreys prior p(x) = 1/x is obtained in the limit as
α →0 and β →0.
The family of IG distributions is plotted in Figure A.1 as α varies over the range 0.01–1000 and
with maximum value ﬁxed at unity. The variety of distributions available indicates that it is possible to
incorporate either very vague or more speciﬁc prior information about variances by choice of the mode
and degrees of freedom of the distribution. With high values of α the prior is very tightly clustered
around its mean value, indicating a high degree of prior belief in a small range of values, while for
smaller α the prior can be made very diffuse, tending in the limit to the uninformative Jeffreys prior.
Values of α and β might be chosen on the basis of mean and variance information about the unknown
parameter or from estimated percentile positions on the axis.

A Probability Densities and Integrals
181
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
0
0.1
0.2
0.3
0.4
normalized probability density
Inverted-gamma density
0.5
0.6
0.7
0.8
0.9
1
amptitude
alpha=1000
alpha=0.01
FIGURE A.1
Inverted-gamma family with mode = 1, α = 0.01 . . . 1000.
A.5 Normal-inverted-gamma distribution
p(θ, σ 2) = p(θ|σ 2)p(σ 2) = N(mθ, M−1
θ /σ 2).
(4.83)
A.6 Wishart distribution
If  is a P × P symmetric positive deﬁnite matrix, the Wishart distribution is deﬁned as
Wi(|M, α) =
π−P(P−1)/4
P
i=1 	(0.5(2α + 1 −i))
|M|α||α−(P+1)/2 exp ( −tr(M)),
(4.84)
where α > (P −1)/2. The mean of the distribution is
E[] = αM−1
and the mode (maximum) is
(α −(P + 1)/2)M−1.

182
CHAPTER Bayesian Computational Methods in Signal Processing
A.7 Inverse Wishart distribution
The inverse Wishart distribution is the distribution of C = −1, where  has the Wishart distribution
as described above,
IWi(C|M, α) =
π−P(P−1)/4
P
i=1 	(0.5(2α + 1 −i))
|M|α|C|−(α+(P+1)/2) exp ( −tr(MC−1)).
(4.85)
The mean of the distribution is
E[C] =
M
α −(P + 1)/2
and the mode (maximum) is
M
α + (P + 1)/2.
References
[1] J. Makhoul, Linear prediction: a tutorial review, Proc. IEEE 63 (4) (1975) 561–580.
[2] C.W. Therrien, Discrete Random Signals and Statistical Signal Processing, Prentice-Hall, 1992.
[3] J.M. Bernardo, A.F.M. Smith, Bayesian Theory, John Wiley & Sons, 1994.
[4] G.E.P. Box, G.C. Tiao, Bayesian Inference in Statistical Analysis, Addison-Wesley, 1973.
[5] H. Jeffreys, Theory of Probability, Oxford University Press, 1939.
[6] C.P. Robert, The Bayesian Choice, second ed., Springer, New York, 2001.
[7] R.O. Duda, P.E. Hart, Pattern Classiﬁcation and Scene Analysis, John Wiley and Sons, 1973.
[8] H. VanTrees, Decision, Estimation and Modulation Theory, Part 1, Wiley and Sons, 1968.
[9] A.C. Harvey, Forecasting Structural Time Series Models and the Kalman Filter, Cambridge University Press,
1989.
[10] G. Kitagawa, W. Gersch, Smoothness Priors Analysis of Time Series, Lecture Notes in Statistics, vol. 116,
Springer-Verlag, New York, 1996.
[11] A. Zellner, On assessing prior distributions and Bayesian regression analysis with g-prior distribution,
in: Bayesian Inference and Decision Techniques: Essays in Honour of Bruno de Finetti, Elsevier, 1986,
pp. 233–243.
[12] H. Akaike, A new look at the statistical model identiﬁcation, IEEE Trans. Automat Control 19 (6) (1974)
716–723.
[13] D. Madigan, J. York, Bayesian graphical models for discrete data, Int. Stat. Rev. 63 (1995) 215–232.
[14] A.P. Dempster, N.M. Laird, D.B. Rubin, Maximum likelihood from incomplete data via the EM algorithm,
J. Roy. Stat. Soc. Ser. B 39 (1) (1977) 1–38.
[15] M. Feder, A.V. Oppenheim, E. Weinstein, Maximum likelihood noise cancellation using the EM algorithm,
IEEE Trans. Acoust. Speech Signal Process. 37 (2) (1989).
[16] T.K. Moon, The expectation-maximization algorithm, IEEE Signal Process. Mag. (1996) 47–60.
[17] J.J.K. Ó Ruanaidh, W.J. Fitzgerald, Numerical Bayesian Methods Applied to Signal Processing, Springer-
Verlag, 1996.
[18] E. Weinstein, A.V. Oppenheim, M. Feder, J.R. Buck, Iterative and sequential algorithms for multisensor signal
enhancement, IEEE Trans. Signal Process. 42 (4) (1994).

References
183
[19] M.A. Tanner, Tools for Statistical Inference, second ed., Springer-Verlag, 1993.
[20] C.M. Bishop, Pattern Recognition and Machine Learning, Springer, 2006.
[21] David J.C. MacKay, Information Theory, Inference, and Learning Algorithms, CUP, 2003.
[22] W.K. Hastings, Monte Carlo sampling methods using Markov chains and their applications, Biometrika 57
(1970) 97–109.
[23] N. Metropolis, A.W. Rosenbluth, M.N. Rosenbluth, A.H. Teller, E. Teller, Equations of state calculations by
fast computing machines, J. Chem. Phys. 21 (1953) 1087–1091.
[24] L. Tierney, Markov chains for exploring posterior disiributions (with discussion), Ann. Stat. 22 (1994)
1701–1762.
[25] A.E. Gelfand, A.F.M. Smith, Sampling-based approaches to calculating marginal densities, J. Am. Stat. Assoc.
85 (1990) 398–409.
[26] S. Geman, D. Geman, Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images, IEEE
Trans. Pattern Anal. Mach. Intell. 6 (1984) 721–741.
[27] J. Liu, W.H. Wong, A. Kong, Covariance structure of the Gibbs sampler with applications to the comparison
of estimators and augmentation schemes, Biometrika 81 (1994) 27–40.
[28] G.O. Roberts, S.K. Sahu, Updating schemes, correlation structure, blocking and parameterization for the
Gibbs sampler, J. Roy. Stat. Soc. Ser. B 59 (1997) 291–317.
[29] M.K. Cowles, B.P. Carlin, Markov chain Monte Carlo convergence diagnostics—a comparative review, J. Am.
Stat. Assoc. 91 (434) (1996) 883–904.
[30] S.J. Godsill, On the relationship between MCMC methods for model uncertainty, J. Comput. Graph. Stat. 10
(2001) 230–248.
[31] P.J. Green, Reversible jump Markov chain Monte Carlo computation and Bayesian model determination,
Biometrika 82 (1995) 711–732.
[32] B.D.O. Anderson, J.B. Moore, Optimal Filtering, Prentice-Hall, 1979.
[33] R.E. Kalman, A new approach to linear ﬁltering and prediction problems, ASME J. Basic Eng. 82 (1960)
35–45.
[34] N. Gordon, D. Salmond, A.F. Smith, Novel approach to nonlinear/non-Gaussian Bayesian state estimation,
IEE Proc. F, Radar Signal Process. 140 (1993) 107–113.
[35] G. Kitagawa, Monte-Carlo ﬁlter and smoother for non-Gaussian nonlinear state space models, J. Comput.
Graph. Stat. 1 (1996) 1–25.
[36] M. West, Mixture models, Monte Carlo, Bayesian updating and dynamic models, Comput. Sci. Stat. 24 (1993)
325–333.
[37] O. Cappé, E. Moulines, T. Rydén, Inference in Hidden Markov Models, Springer, 2005.
[38] T. Kailath, A. Sayed, B. Hassibi, Linear Estimation, Prentice-Hall, 2000.
[39] B. Ristic, M. Arulampalam, A. Gordon, Beyond Kalman Filters: Particle Filters for Target Tracking, Artech
House, 2004.
[40] A.H. Jazwinski, Stochastic Processes and Filtering Theory, Academic Press, New York, 1970.
[41] D.L. Alspach, H.W. Sorenson, Nonlinear Bayesian estimation using Gaussian sum approximation, IEEE
Trans. Automat. Control 17 (4) (1972) 439–448.
[42] K. Ito, K. Xiong, Gaussian ﬁlters for nonlinear ﬁltering problems, IEEE Trans. Automat. Control 45 (2000)
910–927.
[43] S.J. Julier, J.K. Uhlmann, A new extension of the Kalman ﬁlter to nonlinear systems, in: Aerosense: The 11th
International Symposium on Aerospace/Defense Sensing, Simulation and Controls, 1997.
[44] R. Van der Merwe, A. Doucet, N. De Freitas, E. Wan, The unscented particle ﬁlter, in: T.K. Leen,
T.G. Dietterich, V. Tresp (Eds.), Advanced in Neural Information Processing System, vol. 13, MIT Press,
2000.

184
CHAPTER Bayesian Computational Methods in Signal Processing
[45] J. Handschin, D. Mayne, Monte Carlo techniques to estimate the conditionnal expectation in multi-stage
non-linear ﬁltering, Int. J. Control 9 (1969) 547–559.
[46] J. Handschin, Monte Carlo techniques for prediction and ﬁltering of non-linear stochastic processes,
Automatica 6 (1970) 555–563.
[47] A. Blake, M. Isard, Active Contours, Springer, 1998.
[48] J. Liu, R. Chen, Blind deconvolution via sequential imputations, J. Roy. Stat. Soc. Ser. B 430 (1995) 567–576.
[49] P. Del Moral, Nonlinear ﬁltering: interacting particle solution, Markov Process. Rel. Fields 2 (1996) 555–579.
[50] A. Doucet, N. De Freitas, N. Gordon (Eds.), Sequential Monte Carlo Methods in Practice, Springer, New York,
2001.
[51] J.S. Liu, Monte Carlo Strategies in Scientiﬁc Computing, Springer, New York, 2001.
[52] Y.C. Ho, R.C.K. Lee, A Bayesian approach to problems in stochastic estimation and control, IEEE Trans.
Automat. Control 9 (4) (1964) 333–339.
[53] M.K. Pitt, N. Shephard, Filtering via simulation: auxiliary particle ﬁlters, J. Am. Stat. Assoc. 94 (446) (1999)
590–599.
[54] N. Chopin, Central limit theorem for sequential Monte Carlo methods and its application to Bayesian inference,
Ann. Stat. 32 (6) (2004) 2385–2411.
[55] D. Crisan, A. Doucet, A survey of convergence results on particle ﬁltering methods for practitioners, IEEE
Trans. Signal Process. 50 (3) (2002) 736–746.
[56] P. Del Moral, Measure-valued processes and interacting particle systems, application to nonlinear ﬁltering
problems, Ann. Appl. Prob. 8 (1998) 69–95.
[57] P. Del Moral, Feynman-Kac Formulae, Genealogical and Interacting Particle Systems with Applications,
Springer, 2004.
[58] H.R. Künsch, Recursive Monte-Carlo ﬁlters: algorithms and theoretical analysis, Ann. Stat. 33 (5) (2005)
1983–2021.
[59] A. Doucet, S. Godsill, C. Andrieu, On sequential Monte-Carlo sampling methods for Bayesian ﬁltering, Stat.
Comput. 10 (2000) 197–208.
[60] J.L. Zhang, J.S. Liu, A new sequential importance sampling method and its application to the two-dimensional
hydrophobic-hydrophilic model, J. Chem. Phys. 117 (7) (2002).
[61] S. Godsill, T. Clapp, Improvement strategies for Monte Carlo particle ﬁlters, in: A. Doucet, N. De Freitas,
N. Gordon (Eds.), Sequential Monte Carlo Methods in Practice, Springer, 2001.
[62] M. Arulampalam, S. Maskell, N. Gordon, T. Clapp, A tutorial on particle ﬁlters for on line non-linear/non-
Gaussian Bayesian tracking, IEEE Trans. Signal Process. 50 (2002) 241–254.
[63] N. Shephard, M. Pitt, Likelihood analysis of non-Gaussian measurement time series, Biometrika 84 (3) (1997)
653–667 (Erratum in volume 91, 249–250, 2004).
[64] C. Andrieu, A. Doucet, Particle ﬁltering for partially observed Gaussian state space models, J. Roy. Stat. Soc.
Ser. B 64 (4) (2002) 827–836.
[65] R. Chen, J.S. Liu, Mixture Kalman ﬁlter, J. Roy. Stat. Soc. Ser. B 62 (3) (2000) 493–508.
[66] T. Schön, F. Gustafsson, P.-J. Nordlund, Marginalized particle ﬁlters for mixed linear/nonlinear state-space
models, IEEE Trans. Signal Process. 53 (7) (2005) 2279–2289.
[67] R. Karlsson, T. Schön, F. Gustafsson, Complexity analysis of the marginalized particle ﬁlter, IEEE Trans.
Signal Process. 53 (11) (2005) 4408–4411.
[68] R.E. Kalman, R. Bucy, New results in linear ﬁltering and prediction theory, J. Basic Eng. Trans. ASME, Ser.
D 83 (3) (1961) 95–108.
[69] C.P. Robert, G. Casella, Monte Carlo Statistical Methods, second ed., Springer, New York, 2004.
[70] L.R. Rabiner, A tutorial on hidden Markov models and selected applications in speech recognition, Proc.
IEEE 77 (2) (1989) 257–285.
[71] O. Cappé, S.J. Godsill, E. Moulines, An overview of existing methods and recent advances in sequential
Monte Carlo, Proc. IEEE 95 (5) (2007).

References
185
[72] A. Doucet, A.M. Johansen, A tutorial on particle ﬁltering and smoothing: ﬁfteen years later, in: D. Crisan,
B. Rozovsky (Eds.), Oxford Handbook of Nonlinear Filtering, OUP, 2011.
[73] M. Briers, A. Doucet, S. Maskell, Smoothing algorithms for state-space models, Technical Report TR-CUED-
F-INFENG 498, Department of Engineering, University of Cambridge, 2004.
[74] W. Fong, S. Godsill, A. Doucet, M. West, Monte Carlo smoothing with application to audio signal enhance-
ment, IEEE Trans. Signal Process. 50 (2) (2002) 438–449.
[75] S.J. Godsill, A. Doucet, M. West, Maximum a posteriori sequence estimation using Monte Carlo particle
ﬁlters, Ann. Inst. Stat. Math. 53 (1) (2001) 82–96.
[76] S.J. Godsill, A. Doucet, M. West, Monte Carlo smoothing for non-linear time series, J. Am. Stat. Assoc. 50
(2004) 438–449.
[77] M. Hürzeler, H.R. Künsch, Monte Carlo approximations for general state-space models, J. Comput. Graph.
Stat. 7 (1998) 175–193.
[78] M. Isard, A. Blake, CONDENSATION—conditional density propagation for visual tracking, Int. J. Comput.
Vis. 29 (1) (1998) 5–28.
[79] M. Klaas, M. Briers, N. De Freitas, A. Doucet, S. Maskell, D. Lang, Fast particle smoothing: if I had a million
particles, in: 23rd International Conference on Machine Learning (ICML), Pittsburgh, Pennsylvania, June
25–29, 2006.
[80] H.R. Künsch, State space and hidden Markov models, in: OE Barndorff-Nielsen, D.R. Cox, C. Klueppelberg
(Eds.), Complex Stochastic Systems, CRC Publisher, Boca Raton, 2001, pp. 109–173.
[81] S. Sarkka, P. Bunch, S. Godsill, A backward-simulation based rao-blackwellized particle smoother for con-
ditionally linear gaussian models, in: 16th IFAC Symposium on System Identiﬁcation, 2012.
[82] R. Shumway, D. Stoffer, An approach to time series smoothing and forecasting using the EM algorithm,
J. Time Ser. Anal. 3 (4) (1982) 253–264.
[83] C. Andrieu, A. Doucet, S.S. Singh, V.B. Tadic, Particle methods for change detection, system identiﬁcation,
and control, IEEE Proc. 92 (3) (2004) 423–438.
[84] F. Campillo, F. Le Gland, MLE for patially observed diffusions: direct maximization vs. the EM algorithm,
Stochast. Process. Appl. 33 (1989) 245–274.
[85] N. Chopin, A sequential particle ﬁlter method for static models, Biometrika 89 (2002) 539–552.
[86] P. Del Moral, A. Doucet, A. Jasra, Sequential monte carlo samplers, J. Roy. Stat. Soc. Ser. B 68 (3) (2006)
411.
[87] P. Fearnhead, Markov chain Monte Carlo, sufﬁcient statistics and particle ﬁlter, J. Comput. Graph. Stat. 11
(4) (2002) 848–862.
[88] Walter R. Gilks, Carlo Berzuini, Following a moving target—Monte Carlo inference for dynamic Bayesian
models, J. Roy. Stat. Soc. Ser. B 63 (1) (2001) 127–146.
[89] G. Kitagawa, A self-organizing state-space model, J. Am. Stat. Assoc. 93 (443) (1998) 1203–1215.
[90] J. Liu, M. West, Combined parameter and state estimation in simulation-based ﬁltering, in: N. De Freitas,
A. Doucet, N. Gordon (Eds.), Sequential Monte Carlo Methods in Practice, Springer, 2001.
[91] R.M. Neal, Annealed importance sampling, Stat. Comput. 11 (2) (2001) 125–139.
[92] Jimmy Olsson, Tobias Rydén, Asymptotic properties of the bootstrap particle ﬁlter maximum likelihood
estimator for state space models, Technical Report LUTFMS-5052-2005, Lund University, 2005.
[93] M. Segal, E. Weinstein, A new method for evaluating the log-likelihood gradient, the Hessian, and the Fisher
information matrix for linear dynamic systems, IEEE Trans. Inform. Theory 35 (1989) 682–687.
[94] C. Andrieu, A. Doucet, R. Holenstein, Particle Markov chain monte carlo methods, J. Roy. Stat. Soc. Ser. B
(Stat. Methodol.) 72 (3) (2010) 269–342.
[95] A.C. Bajpai, L.R. Mustoe, D, Walker, Advanced Engineering Mathematics, Wiley, 1977.
[96] Manouchehr Kheradmandnia, Aspects of Bayesian Threshold Autoregressive Modelling, PhD Thesis, Uni-
versity of Kent, 1991.

5
CHAPTER
Distributed Signal Detection1
Pramod K. Varshney* and Engin Masazade†
*Syracuse University, Department of Electrical Engineering and Computer Science,
4-206 Center for Science and Technology, Syracuse, NY, USA
†Department of Electrical and Electronics Engineering, Yeditepe University, Istanbul, Turkey
3.05.1 Introduction
There are many practical situations in which one is faced with a decision-making problem. For example,
in a radar detection context multiple radars work together to make a decision regarding the presence
or absence of a target based on the radar returns [1]. In a digital communication system, one of the
possible waveforms is transmitted over a channel and based on the received noisy observations, one
needs to determine the symbol that was transmitted [2,3]. In a biomedical application [4,5], based on a
smear of human tissue, one needs to determine if it is cancerous or not. In a pattern recognition problem
[6,7], the type of the aircraft being observed needs to be determined based on some aircraft features.
In cognitive radio networks [8,9], detection of spectrum holes and opportunistic use of under-utilized
frequency bands without causing harmful interference to legacy networks is an essential functionality.
In a wireless sensor network (WSN), detection of an event of interest is an important task of the network
before other attributes of the event are estimated (see [10,11] for different application scenarios). In
all of the above applications, the common underlying problem is to make a decision among several
possible choices. This is carried out based on available noisy measurements. The branch of statistics
dealing with these types of problems is known as statistical decision theory or hypothesis testing. In
the context of radar and communication theory, it is known as detection theory [12–15]. In distributed
signal detection, multiple detectors (sensors) work collaboratively to distinguish between two or more
hypotheses, e.g., the absence or presence of a signal of interest. Deployment of multiple sensors for
signal detection improves system survivability, results in improved detection performance or in a shorter
decision time to attain a prespeciﬁed performance level.
In classical multi-sensor detection, local sensors transmit their raw observations to a central pro-
cessor where optimal detection is carried out based on conventional statistical techniques. However,
centralized processing based on raw observations is neither efﬁcient nor necessary in many practi-
cal applications. It may consume excessive energy and bandwidth in communications, may impose a
heavy computation burden at the central processor. In distributed processing [12,16,17], on the other
hand, local sensors can carry out preliminary processing of data and only communicate with each other
1This work was supported by US Air Force Ofﬁce of Scientiﬁc Research (AFOSR) under Grant FA9550-10-1-0263 and
Army Research Ofﬁce (ARO) Grant W911NF-09-1-0244.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00005-9
© 2014 Elsevier Ltd. All rights reserved.
187

188
CHAPTER 5 Distributed Signal Detection
and/or the fusion center with the most informative information relevant to the global objective. With
advances in sensing technology and wireless communications, wireless sensors can be deployed in situ
to monitor phenomena of interest with increased precision and coverage. This has given rise to many
detection problems involving wireless sensor networks. Such detection ability of a wireless sensor
network is crucial for various applications. As an example, in a surveillance scenario, the presence or
absence of a target is usually determined before attributes, such as its position or velocity, are estimated.
Since wireless sensors are assumed to be tiny battery powered devices with limited on board signal
processing capabilities, energy limitation is one of the major differences between a WSN and other
wireless networks such as wireless local area networks. Therefore, prolonging the lifetime of a WSN
is important for both commercial and tactical applications. For instance, in order to maximize battery
lifetime and reduce communication bandwidth, it is essential for each sensor to locally compress its
observed data and transmit quantized measurements so that only low rate inter-sensor or sensor to fusion
center communication is required. The advantages of distributed processing are obvious, i.e., reduced
communication bandwidth requirement and energy consumption, increased reliability and robustness.
Moreover, there may be channel impairments such as fading and path loss in the network environment
that can considerably degrade the quality of wireless links among sensors. Such challenges should be
taken into account while designing the communication and local signal processing algorithms.
This survey paper is organized as follows. In Section 3.05.2, we focus on the distributed detection
problem with independent sensor observations. Under the conditional independence assumption, the
optimal design of decision rules at the local sensors and at the fusion center is discussed for both Bayesian
and Neyman-Pearson formulations. We subsequently talk about non-parametric, computationally and
energy-efﬁcient distributed detection approaches. Distributed detection over fading channels is also
addressed in this section. The problem of distributed detection in the presence of dependent observations
is considered in Section 3.05.3. Finally, the summary of the paper and some challenging issues for
distributed detection are presented in Section 3.05.4.
3.05.2 Distributed detection with independent observations
In this paper, we focus on a simple binary hypothesis testing problem in which the observations at each
of the N sensors, yi, i∈{1, 2, . . ., N}, correspond to either of the two hypotheses,
H0 ∼p0(θ),
H1 ∼p1(θ),
(5.1)
where p0(θ) and p1(θ) are the probability density functions (pdfs) under H0 and H1 respectively. More
speciﬁcally, if the problem is to detect the absence or presence of the signal of interest, hypothesis
H1 represents the presence of a signal and H0 represents the absence of a signal. Then the distributed
detection problem has the form,
yi =
ni,
under H0,
cT θ + ni, under H1,
(5.2)
where θ represent the parameter vector that is characterizing the hypothesis H1, if the measurement
model is linear c is an appropriate scaling vector which might have the same size as θ. If the measurement

3.05.2 Distributed Detection with Independent Observations
189
Fusion Center
Sensor N
Sensor 2
Sensor 1
u0 {0,1}
FIGURE 5.1
Parallel conﬁguration.
model is non-linear, the received sensor measurements have the form,
yi =
ni,
under H0,
f (θ) + ni, under H1,
(5.3)
where f ( · ) can be modeled according to the isotropic signal emission model [18], or disk model
[19]. ni represents the noise samples. In this paper, we focus on the binary hypothesis testing problem.
More detailed treatment for the multiple hypothesis testing (classiﬁcation) problem can be found in the
literature [6,7,20–23].
Parallel conﬁguration, as shown in Figure 5.1, is the most common topological structure that has
been studied quite extensively in the literature (see [11,24] and references therein). The sensors do not
communicate with each other and there is no feedback from the fusion center to any sensor. Sensors
either transmit their measurements yi directly to the fusion center or send a quantized version of their
local measurements deﬁned by the mapping rule ui = γi(yi). Based on the received information
u = [u1, . . . , uN], the fusion center arrives at a global decision u0 = γ0(u) that favors either H1
(decides u0 = 1) or H0 (decides u0 = 0). The goal is to obtain the optimal set of decision rules
 = (γ0, γ1, . . . , γN) according to the objective function under consideration which can be formulated
according to Bayesian formulation or Neyman-Pearson formulation. For general network structures, the
optimal solution to the distributed detection problem, i.e., the optimal decision rules (γ1, . . . , γN), is
NP-complete, i.e., in general cannot be solved in polynomial time [25–27]. Nonetheless, under certain
assumptions and speciﬁc network topologies, the optimum solution becomes tractable.

190
CHAPTER 5 Distributed Signal Detection
3.05.2.1 Conditional independence assumption
The conditional independence assumption implies that the joint density of the observations obeys
p(y1, . . ., yN|Hj) =
N

i=1
p(yi|Hj),
for j = 0, 1.
(5.4)
Consider a scenario in which the observations at the sensors are conditionally independent as well as
identically distributed. The symmetry in the problem suggests that the decision rules at the sensors
should be identical. But counterexamples have been found in which nonidentical decision rules are
optimal [27–30]. In the following subsections, the decision rules at local sensors and the fusion center
are designed according to Bayesian and Neyman-Pearson formulations under the parallel conﬁguration.
3.05.2.1.1
Bayesian formulation
In the Bayesian formulation, certain costs are assigned to different courses of actions under the knowl-
edge of prior probabilities, and the objective is to minimize the Bayesian risk of the overall system
operation which can be expressed as
min
=(γ0,γ1,...,γN )R,
(5.5)
where the Bayes risk R is deﬁned as
R ≜
1

i=0
1

j=0
Ci j P(u0 = i|H j)Pj
= C + CF

u
P(u0 = 1|u)P(u|H0) −CD

u
P(u0 = 1|u)P(u|H1).
(5.6)
Here,Ci j isdeﬁnedtobethecostofdeclaringHi truewhenH j ispresenttoreﬂectdifferentconsequences
of all decisions. CF = P0(C10 −C00), CD = (1−P0)(C01 −C11) and C = C01(1−P0)+C00P0. 
u
indicates summation over all possible values of u. Under the conditionally independence assumption,
it can be shown that the sensor decision rules and the fusion rule are likelihood ratio tests (LRTs) given
by [12]. The LRT at each sensor has the form,
p(yi|H1)
p(yi|H0)
ui=1
≷
ui=0

ui CF A(ui)N
k=1,k̸=i P(uk|H0)

ui CD A(ui)N
k=1,k̸=i P(uk|H1)
for i = 1, . . . , N.
(5.7)
Note that the LRT of each sensor depends on the decision rules of the other sensors. Given that the
decision rules of the other sensors remain ﬁxed, the right-hand side of (5.7) becomes constant. Then,
the LRT at the fusion center is,
N

i=1
P(ui|H1)
P(ui|H0)
u0=1
≷
u0=0
CF
CD
,
(5.8)

3.05.2 Distributed Detection with Independent Observations
191
where
ui = [u1 , . . . , ui−1, ui+1 , . . . , uN],
A(ui) = P(u0 = 1|ui1) −P(u0 = 1|ui0),
ui j = [u1, . . . , ui−1, ui = j, ui+1, . . . , uN],
j = 0, 1.
ToﬁndtheoptimalsetofdecisionrulesamountstosimultaneouslysolvingtheaboveNcouplednonlinear
equations. A popular method to design distributed detection systems is to employ a person-by-person
optimization (PBPO) technique. This technique consists of optimizing the decision rule of one sensor
at a time while keeping the decision rules of the remaining sensors ﬁxed. The overall performance at
the fusion center is guaranteed to improve (or, at least, to not worsen) with every iteration of the PBPO
algorithm. However, system design equations resulting from this PBPO procedure represent necessary
but not, in general, sufﬁcient conditions to determine the globally optimum solution. The Gauss-Seidel
cyclic coordinate descent algorithm has been proposed in the literature [31,32] to obtain the PBPO
solution satisfying the necessary conditions of optimality in an iterative manner.
3.05.2.1.2
Neyman-Pearson formulation
The Neyman-Pearson formulation of the distributed detection problem can be stated as follows: for a
prescribed bound on the global probability of false alarm, Pf = P(u0 = 1|H0), ﬁnd (optimum) local
and global decision rules that maximize the global probability of detection Pd = P(u0 = 1|H1) as,
max Pd,
(5.9)
Pf ≤α.
Under the conditional independence assumption, the mapping rules at the sensors as well as the decision
rule at the fusion center are threshold rules based on the appropriate likelihood ratios [33,34]:
p(yi|H1)
p(yi|H0)
⎧
⎨
⎩
> ti, then ui = 1,
= ti, then ui = 1 with probability ϵi,
< ti, then ui = 0,
(5.10)
for i = 1, . . ., N, and
N

i=1
P(ui|H1)
P(ui|H0)
⎧
⎨
⎩
> λ0, decide H1 or set u0 = 1,
= λ0, randomly decide H1 with probability ϵ,
< λ0, decide H0 or set u0 = 0.
(5.11)
If the likelihood ratio in (5.10) is a continuous random variable, ϵi can be assumed to be zero. The
threshold λ0 in (5.11) as well as the local thresholds ti in (5.10) need to be determined so as to maximize
Pd for a given Pf = α. This can still be quite difﬁcult because the local decision rules and the global
fusion rule are coupled to each other [12]. Since (5.11) is known to be a monotone fusion rule, one can
solve for the set of optimal local thresholds {ti, i = 1, . . . , N} for a given monotone fusion rule and
compute the corresponding Pd. One can then successively consider other possible monotone fusion rules
and obtain the corresponding detection probabilities. The ﬁnal optimal solution is the one monotone

192
CHAPTER 5 Distributed Signal Detection
fusion rule and the corresponding local decision rules that provide the largest Pd. An iterative gradient
method was proposed in [35] to ﬁnd the thresholds satisfying the preassigned false alarm probability.
Finding the optimal solution in this fashion is possible only for very small values of N. The complexity
increases with N because (1) the number of monotone rules grows exponentially with N and (2) ﬁnding
the optimal {ti, i = 1, . . . , N} for a given fusion rule is an optimization problem involving an N −1
dimensional search (it is one dimension less than N because of the constraint Pf = α).
3.05.2.1.3
The decision fusion problem
Given the local detectors, the problem is to determine the fusion rule to combine local decisions opti-
mally. Let us ﬁrst consider the case where local detectors makes only hard decisions, i.e., ui can take
only two values 0 or 1 corresponding to the two hypotheses H0 and H1 respectively. Let Pf i and Pdi
denote the probabilities of false alarm and detection of sensor i respectively, i.e., Pf i = P(ui = 1|H0)
and Pdi = P(ui = 1|H1). As we know, the optimum fusion rule is given by the likelihood ratio test:
N

i=1
P(ui|H1)
P(ui|H0)
u0=1
≷
u0=0
λ.
(5.12)
Here, λ is determined by the optimization criterion in use. The left-hand side of (5.12) can be written as
N

i=1
P(ui|H1)
P(ui|H0) =
N

i=1

 P(ui = 1|H1)
P(ui = 1|H0)
ui 
 P(ui = 0|H1)
P(ui = 0|H0)
1−ui
=
N

i=1

 Pdi
Pf i
ui 
 1 −Pdi
1 −Pf i
1−ui
.
(5.13)
Taking the logarithm of both sides of (5.12), we have the Chair-Varshney fusion rule [36]
N

i=1

uilog Pdi
Pf i
+ (1 −ui)log 1 −Pdi
1 −Pf i
 u0=1
≷
u0=0
logλ.
(5.14)
This rule can also be expressed as
N

i=1

log Pdi(1 −Pf i)
Pf i(1 −Pdi)

ui
u0=1
≷
u0=0
logλ +
N

i=1
log1 −Pf i
1 −Pdi



λ′
.
(5.15)
Thus, the optimum fusion rule can be implemented by forming a weighted sum of the incoming local
decisions and comparing it with a threshold λ′. The weights and the threshold are determined by the
local probabilities of detection and false alarm. If the local decisions have the same statistics, i.e.,
Pf ,1 = · · · = Pf ,N and Pd,1 = · · · = Pd,N, the Chair-Varshney fusion rule reduces to a K-out-of-N
form or a counting rule, i.e., the global decision u0 = 1 if K or more sensor decisions are one. This
structure of the fusion rule reduces the computational complexity considerably.

3.05.2 Distributed Detection with Independent Observations
193
If the local detectors are allowed to make multilevel or soft decisions, the observation space at
each local detector is partitioned into L mutually exclusive regions with L > 2. If the observation at
detector i lies in the partition l, we set ui = l,l = 0, . . ., L −1. Deﬁne αl
i = P(ui = l|H0) and
βl
i = P(ui = l|H1). The likelihood ratio in (5.12) can be written as
N

i=1
P(ui|H1)
P(ui|H0) =
L−1

l=0

Sl
βl
i
αl
i
,
(5.16)
where Sl is the set of local decisions ui that are equal to l. Taking the logarithm of both sides, the optimal
fusion rule is as follows:
L−1

l=0

Sl
logβl
i
αl
i
u0=1
≷
u0=0
logλ.
(5.17)
This fusion rule is a generalization of the fusion rule for the hard decision case [12].
So far, we have assumed that the parameters characterizing a hypothesis, θ, are ﬁxed and known and
the corresponding detection problem is known as simple hypothesis testing. In many situations, however,
these parameters can take unknown values or a range of values. Such hypotheses are called composite
hypotheses and the corresponding detection problem is known as composite hypothesis testing. If θ is
characterized as a random vector with known probability densities under the two hypotheses, the LRT
can be extended to composite hypothesis testing in a straightforward manner:
(y) =

	1 p(y|θ1)p(θ|H1)dθ

	0 p(y|θ1)p(θ|H0)dθ ,
(5.18)
where θ j is the random variable characterizing hypothesis H j and 	 j is the support of θ j. If θ is
nonrandom, one can use the maximum likelihood estimates of its value under the two hypotheses as the
true values in an LRT, resulting in a so called generalized likelihood ratio test (GLRT) [37]:
g(y) = maxθ∈	1 p(y|θ1, H1)
maxθ∈	0 p(y|θ0, H0)
D1
≷
D0
η.
(5.19)
Note that the optimum Neyman-Pearson or Bayesian detectors involve a likelihood ratio test (LRT)
as in (5.12). The complete knowledge of the likelihoods, p(u|H1) and p(u|H0), may not always be
available in a practical application. Also, there are many detection problems where the exact form of
the LRT is too complicated to implement. Therefore, simpler and more robust suboptimal detectors are
used in numerous applications [38]. For some suboptimal detectors, the detection performance can be
improved by adding an independent noise to the observations under certain conditions which is known
as stochastic resonance (SR) [39]. Given a suboptimal ﬁxed detector, the work in [40] ﬁrst discusses the
improvability of the detection performance by adding SR noise. If the performance can be improved,
then the best noise type is determined in order to maximize PD without increasing PF. The work in
[41] discusses variable detectors.

194
CHAPTER 5 Distributed Signal Detection
3.05.2.1.4
Asymptotic regime
It has been shown that for sensors whose observations are independent and identically distributed given
either hypothesis, identical decision rules are optimal in the asymptotic regime where the number of
sensors increases to inﬁnity [27,42]. In other words, the identical decision rule assumption often results
in little or no loss of optimality. Therefore, identical local decision rules are frequently assumed in many
situations, which reduces the computational complexity considerably.
For any reasonable collection of decision rules , the probability of error at the fusion center goes
to zero exponentially as the number of sensors N grows unbounded. It is then adequate to compare
collections of decision rules based on their exponential rate of convergence to zero,
lim
N→∞
logPe()
N
.
(5.20)
It was shown that, for the binary hypothesis testing problem, using identical local decision rules for
all the sensor nodes is asymptotically optimal in terms of the error exponent [42]. In [43], the exact
asymptotics of the minimum error probabilities achieved by the optimal parallel fusion network and
the system obtained by imposing the identical decision rule constraint was investigated. It was shown
analytically that the restriction of identical decision rules leads to little or no loss of performance.
Asymptotic regimes applied to distributed detection are convenient because they capture the dominating
behaviors of large systems. This leads to valuable insights into the problem structure and its solution.
In [44], by studying in the asymptotic regime, it is shown that sensors transmit binary decisions
that are optimal if there exists a binary quantization function γb whose Chernoff information exceeds
half of the information contained in an unquantized observation. The requirement is fulﬁlled by many
practical applications [45] such as the problem of detecting deterministic signals in Gaussian noise and
the problem of detecting ﬂuctuating signals in Gaussian noise using a square-law detector. In these
scenarios, the gain offered by having more sensor nodes outperforms the beneﬁts of getting detailed
information from each sensor.
3.05.2.2 Other network topologies
Solutions for arbitrary topologies such as serial and tree have been derived and are discussed in [12,46].
In serial, or tandem, topology (Figure 5.2) [12,47–49] all of the sensors are connected in series and
receive direct observations from the common phenomenon. The decision of the ﬁrst sensor is based
solely on its observation. This decision is transmitted to the second sensor which uses it in conjunction
with its direct observation. Then the decision of the second sensor is sent to its successor. This process is
repeated at each sensor until the decision of the last sensor is accepted as the ﬁnal decision of the system.
One can also envisage conﬁgurations that are combinations of parallel and serial topologies, e.g., a
tree or hierarchical network as shown in Figure 5.3 [50–52]. In the tree topology, the leaf sensors report
to their cluster heads and the cluster heads reports to their cluster heads hierarchically until reaching the
fusion center. It has been shown that the detection performance of parallel topology is superior than that
of serial and tree topologies [12,53]. Under the asymptotic regime, the work in [53] lists the conditions
where parallel and tree topologies achieve the same detection performance. Moreover, one may also
incorporate feedback in the system design as in [54,55]. There are other topologies also where a subset
of the sensors are allowed to both transmit their messages to the fusion center and to also broadcast

3.05.2 Distributed Detection with Independent Observations
195
Sensor   N
Sensor   N-1
Sensor   N-2
Sensor  2
Sensor  1
u0
{0,1}
FIGURE 5.2
Serial conﬁguration.
Fusion Center
u0
{0,1}
Sensor
Sensor
Sensor
Sensor
Sensor
Sensor
FIGURE 5.3
Tree conﬁguration.
them to the remaining sensors [56]. In the asymptotic regime and for the Neyman-Pearson formulation,
it has been proved in [56] that sharing of decisions does not improve the optimal error exponent.
In the parallel fusion structure, the channels between sensors and the fusion center have been assumed
as mutually independent. In sensor networks with a large number of sensors, this assumption is often

196
CHAPTER 5 Distributed Signal Detection
impractical and violated. An alternative is to utilize the multiple access channel (MAC), by taking
advantage of the shared nature of the wireless medium. Decentralized detection and estimation have
been considered as a MAC channel model in [57–62].
So far, we have discussed ﬁxed-sample-size detection problems where the fusion center arrives at a
decision after receiving the entire set of sensor observations. Sequential detectors may choose to stop
at any time and make a ﬁnal decision or continue to take an additional observations [63–66]. Moreover,
in consensus-based detection [67–69], which requires no fusion center, sensors ﬁrst collect sufﬁcient
observations over a period of time. Then, they subsequently run the consensus algorithm to fuse their
local log likelihood ratios.
3.05.2.3 Nonparametric rules in distributed detection
Most of the results discussed so far on distributed detection are based on the assumption that the local
sensors’ detection performances, namely either the local sensors’ signal to noise ratio (SNR) or their
probability of detection and false alarm rate, are known to the fusion center. For a wireless sensor network
consisting of passive sensors, it might be very difﬁcult to estimate local sensors’ performances via
experiments because sensors’ distances from the signal of interest might be unknown to the fusion center
and to the local sensors. Even if the local sensors can somehow estimate their detection performances
in real time, it can be still very expensive to transmit them to the fusion center, especially for a WSN
with very limited system resources. Hence, the knowledge of the local sensors’ performances cannot be
taken for granted and a fusion rule that does not require local sensors’ performances is highly preferable.
Without the knowledge of local sensors’ detection performances and their positions, an approach at the
fusion center is to treat every sensor equally. An intuitive solution is to use the total number of “1”s as
a statistic since the information about which sensor reports a “1” is of little use to the fusion center. In
[18,70,71], a counting based fusion rule is proposed, which uses the total number of detections (“1”s)
transmitted from local sensors as the statistic,
 =
N

i=1
ui
u0=1
≷
u0=0
T ,
(5.21)
where T is the threshold at the fusion center, which can be decided by a pre-speciﬁed probability of false
alarm PF. This fusion rule is called the counting rule. It is an attractive solution, since it is quite simple
to implement, and achieves very good detection performance in a WSN with randomly and densely
deployed low-cost sensor nodes.
When the received signal intensity at a sensor is assumed to be inversely proportional its the distance
from the source location, the sensor measurements and hence their decisions become conditionally
independent as long as the source location is known exactly. In [72], a generalized likelihood ratio test
(GLRT) based decision fusion method that uses quantized data from local sensors has been proposed
which jointly detects and localizes a target in a wireless sensor ﬁeld. The GLRT based fusion method
signiﬁcantly improves detection performance, as compared with the counting rule. Moreover, in a
scenario where the sensors which are located within the target’s ﬁnite radius of inﬂuence, receive
identical target signal and the rest of the sensors do not receive any target signal, the authors in [19]
control the false discovery rate (FDR) to determine the local sensor decision rules that are nonidentical.

3.05.2 Distributed Detection with Independent Observations
197
FDR based method improves the global detection performance as compared to employing identical
decision rules at each sensor.
3.05.2.4 Energy efﬁcient distributed detection and multi-objective optimization
In many detection applications, the event of interest occurs infrequently and the null hypothesis is
observed for the majority of time. For sensor networks operating on limited energy resources, an energy-
efﬁcient transmission technique is sensor censoring where sensors transmit only when the observations
indicate that the target event is likely [73–76]. When the event of interest becomes very unlikely, sensor
nodes can afford to go to sleep for an extended period of time, thus saving energy. On the other hand,
when in a critical situation, sensor nodes must stay awake [77,78].
In distributed detection in wireless sensor networks, let us consider a scenario where each sensor
compares its local observation with a threshold and transmits a binary decision to the fusion center. Also
consider, each sensor employs sensor censoring that is, a sensor transmits its decision to the fusion center
only if it decides on the presence of the signal. Then the sensor decision thresholds not only determine
the probability of error at the fusion center but also determine the total energy consumption of the
network. The decision thresholds minimizing the decision probability of error might require excessive
amount of energy consumption. Then the designer may wish to trade a slight increase in the probability
of error for a solution with less energy consumption. In [79], for a composite binary hypothesis testing
problem, where under H1, the source location is assumed to be a random variable uniformly distributed
in a given region of interest, the detection problem has been solved by formulating a multi-objective
optimization problem (MOP) with two conﬂicting objective functions, minimizing the probability of
error at the fusion center Pe and minimizing the total network energy consumption ET as,
min
t1,t2,...,tN {Pe(t1, t2, . . ., tN), ET (t1, t2, . . ., tN)}
(5.22)
tmin ≤ti ≤tmax,
i∈{1, 2, . . ., N}.
The variables of the MOP {t1, t2, . . ., tN} are the thresholds employed at the local sensors. As shown
in Figure 5.4, with parallel network topology and N = 5 sensors, the minimum Pe is achieved as
0.061 with energy consumption 525.56 nJ. By using the Pareto-optimal solutions for the MOP, one
can accept the neighboring solution with error probability 0.067, and energy consumption 279.77 nJ.
Therefore, a 10% increase in the probability of error, delivers around 88% saving in energy consumption.
Moreover, in [80], a MOP has been formulated for the sensor placement problem where the objectives
are maximizing the probability of detection and minimizing the total number of sensors.
3.05.2.5 Channel aware distributed detection
A distributed detection system can be designed in such a way that the channels between local sensors and
thechannelsbetweensensorsandthefusioncenterareconsiderederror-free,byadoptingahightransmis-
sion power and/or employing powerful error correction codes. In a wireless sensor network setting with
severe constraints on energy, bandwidth and delay, such mechanisms may become prohibitive. There-
fore, channel impairments should be taken into account in the design of distributed detection systems.
The distributed detection problem in the presence of non-ideal communication channels has been studied

198
CHAPTER 5 Distributed Signal Detection
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
0
100
200
300
400
500
600
Probability of Error
Energy Consumption [nJ]
  (0.061051,525.1485)
  (0.067441,279.7671)
Pareto−optimal front: NBI
Pareto−optimal front: NSGA−II
FIGURE 5.4
Pareto-optimal front between two objectives obtained with non-dominated sorting genetic algorithm-II
(NSGA-II) [81] and normal boundary intersection (NBI) [82] (P(H1) = 0.2, N = 5) [79].
quite extensively recently (see [83] and references therein). Under the Bayesian criterion, the optimality
of the LRT for local sensor decisions has been established for a binary hypothesis testing problem in a
sensor network with non-ideal channels [84]. For a ﬁnite number of sensors, Cheng et al. [85] provides
the conditions under which the channel outputs no longer reduce the error probability at the fusion
center. Channel aware decision fusion algorithms have been investigated with different degrees of chan-
nelstateinformationforbothsingle-hop[86–89]andmulti-hopWSNs[90,91],whilechannel-optimized
local quantizer design methods are provided in [92,93]. To counter sensor or channel failures, robust
binary quantizer design has been proposed in [94]. Channel aware distributed detection has also been
studied in the context of cooperative relay networks [95,96].
3.05.3 Distributed detection with dependent observations
In distributed detection, the likelihood ratio tests at the local sensors are optimal if observations are
conditionally independent given each hypothesis [27]. In general, it is reasonable to assume conditional
independence across sensor nodes if the uncertainty comes mainly from device and ambient noise.
However, for arbitrary sensor systems it does not necessarily hold. As an example, when sensors are
in close proximity of one another, it is very likely that their observations are strongly correlated. If the
observed signal is random in nature or the sensors are subject to common external noise, conditional

3.05.3 Distributed Detection with Dependent Observations
199
independence assumption may also fail. Without the conditional independence assumption, the joint
density of the observations, given the hypothesis, cannot be written as the product of the marginal
densities, as in (5.4). Then, the optimal tests at the sensors are no longer of the threshold type based
solely on the likelihood ratio of the observations. Then, ﬁnding the optimal solution to the distributed
detection problem becomes intractable [25].
Detection of known and unknown signals in correlated noise has been considered in [97]. For the
case of two sensors observing a shift-in-mean of Gaussian data, the authors in [98] develop sufﬁcient
conditions for the optimality of each sensor implementing a local likelihood ratio test. In [99], the
authors assume local likelihood ratio tests at multiple sensors. Then, the effect of correlated noise has
been studied by considering the detection of a known signal in additive Gaussian and Laplacian noise
where the authors show that system performance deteriorates when the correlation increases.
In [100], two correlation models are considered. In one, the correlation coefﬁcient between any
two sensors decreases geometrically as the sensor separation increases. In the other model, correlation
coefﬁcient between any two sensors is a constant. Asymptotic performance with Gaussian noise when
the number of sensors goes to inﬁnity is examined. In [101], distributed detection of known signals in
correlated non-Gaussian noise is studied, where the noise is restricted to be circularly symmetric. Fur-
thermore, the authors in [102] examine two-sensor distributed detection of known signals in correlated
t-distributed noise. A distributed M-ary hypothesis testing problem when observations are correlated is
examined from a numerical perspective in [103]. The authors in [104] discover that the nature of the
local decision rules can be quite complicated for the simplest meaningful problem one can consider,
i.e., the two detector case with dependent Gaussian observations.
Constraining the local sensor decision rules to be suboptimal binary quantizers for the dependent
observations problem, improvement in the global detection performance can still be attained by tak-
ing into account the correlation of local decisions while designing the fusion rule. Towards this end,
design of fusion rules using correlated decisions has been proposed in [105,106]. In [105], the authors
have developed an optimum fusion rule based on the Neyman-Pearson criterion for correlated decisions
assuming that the correlation coefﬁcients between the sensor decisions are known and local sensor
thresholds generating the correlated decisions are given. Using a special correlation structure, they
studied the performance of the detection system versus the degree of correlation and showed how
the performance advantage obtained by using a large number of sensors degrades as the degree of
correlation between local decisions increases. In [106], the authors employed the Bahadur-Lazarsfeld
series expansion of probability density functions to derive the optimum fusion rule for correlated local
decisions.
In many applications, the dependence can get manifested in many different non-linear ways. As
a result, more general descriptors of correlation than the Pearson correlation coefﬁcient, which only
characterizes linear dependence, may be required [107]. Moreover, the marginal distributions of sensor
observations characterizing their univariate statistics may also not be identical. Here, emphasis should
be laid on the fact that multivariate density (or mass) functions do not necessarily exist for arbitrary
marginal density (or mass) functions. In other words, given arbitrary marginal distributions, their joint
distribution function cannot be written in a straight-forward manner.
An interesting approach for the fusion of correlated decisions, that does not necessarily require
prior information about the joint statistics of the sensor observations or decisions, is described next.
Its novelty lies in the usage of copula theory [108]. The application of copula theory is widespread

200
CHAPTER 5 Distributed Signal Detection
in the ﬁelds of econometrics and ﬁnance. However, its use for signal processing applications has been
quite limited. The authors in [109,110] employ copula theory for signal detection problems involving
correlated observations as well as for heterogenous sensors observing a common scene. For the fusion
of correlated decisions, copula theory does not require prior information about the joint statistics of
the sensor observations or decisions and constructs the joint statistics based on a copula selection
procedure. From Figure 5.5, it is clear that the performance of the copula-based fusion rules is superior
to that of the Chair-Varshney fusion rule. Note that the copula function based fusion will fail to perform
better than the Chair-Varshney rule if the constructed joint distribution using a particular parametric
copula function does not adequately model the underlying joint distribution of the sensor observations.
Therefore, training is necessary in order to select the best copula function. The topic of copula function
selection for the distributed detection problem is considered in [111].
In Figure 5.6, the performance comparison of the copula based fusion rules and the Chair-Varshney
fusion rule with varying number of sensor observations (N) is shown with PF = 0.001. The correlation
parameters within the copula functions and the signal parameters under both hypotheses are maintained
the same. Again, the performance of the proposed copula based fusion methods is better than the Chair-
Varshney fusion rule, and they require fewer sensor observations than the Chair-Varshney rule to attain
the same value of PD.
10
−4
10
−3
10
−2
10
−1
10
0
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
System probability of false alarm
System probability of detection
Chair−Varshney Rule
Gaussian Copula Based Fusion
Student−t Copula Based Fusion
FIGURE 5.5
Theoretical ROC curves comparing the Chair-Varshney fusion rule and the copula based fusion rules [111].

3.05.4 Conclusion
201
50
100
150
200
250
300
350
400
450
500
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Number of sensor observations
System probability of detection
Chair−Varshney Rule
Gaussian Copula Based Fusion
Student−t Copula Based Fusion
FIGURE 5.6
Detection performance comparison of the Chair-Varshney test and copula based tests with increase in the
number of sensor observations [111].
3.05.4 Conclusion
In this chapter, distributed detection and decision fusion for a multi-sensor system have been discussed.
In a conventional distributed detection framework, it is assumed that local sensors’ performance indices
are known and communication channels between the sensors and fusion center are perfect. Under these
assumptions, the design for optimal decision fusion rule at the fusion center and the optimal local
decision rules at sensors have been discussed. Under the conditional independence assumption, optimal
decision rules at the local sensors and at the fusion center reduce to LRTs under Bayesian and Neyman-
Pearson formulations. Using the PBPO procedure, the determination of the optimal LRT thresholds at
the local sensors is still quite computationally complex, especially for a large scale sensor network.
However, as the number of sensors goes to inﬁnity an identical decision rule at all sensors become
optimal. Further, the performance indices of local sensors were assumed to be unknown to the detection
system. Non-parametric fusion rules have been discussed. Distributed detection system design under
energy constraints and distributed detection system design using multi-objective optimization has also
been presented.
Distributed detection with correlated observations remains a very difﬁcult problem, since in such
cases, the LRT test based solely on local observation is no longer an optimal test at sensors, and the
optimal solution is intractable in general. Suboptimal solutions that can still exploit the dependence

202
CHAPTER 5 Distributed Signal Detection
information are required. For the dependent observations problem, a framework for fusion of correlated
decisionsusingcopulatheoryhasbeendescribed.Thelocalsensordecisionrulesareassumedtobebased
on simple binary quantization of the sensor observations. The described method is particularly useful
when the marginal densities of sensor observations are non-Gaussian (and potentially nonidentical) and
when dependence between sensor observations can get manifested in several different non-linear ways.
While many advances have been made in the area of distributed detection and decision fusion, many
open and challenging problems remain that need further research. For example, distributed detection in
a sensor network where the signal decays following a non-isotropic model, is a very difﬁcult problem.
Another challenging problem is the design of the optimal local sensor decision rules when observations
from different sensors are dependent conditioned on either hypothesis. Copula theory has provided one
approach to treat dependence, further work on copula-based methods and other approaches will be quite
valuable.
References
[1] H.L. Van Trees, Detection, Estimation, and Modulation Theory, Radar-Sonar Signal Processing and Gaussian
Signals in Noise, Wiley-Interscience, 2003.
[2] J.G. Proakis, Digital Communications, McGraw-Hill, 2005.
[3] M. Schwartz, W.R. Bennett, S. Stein, Communication Systems and Techniques, Wiley-IEEE Press, 1995.
[4] Jinshan Tang, R.M. Rangayyan, Jun Xu, I. El Naqa, Yongyi Yang, Computer-aided detection and diagnosis
of breast cancer with mammography: recent advances, IEEE Trans. Inform. Technol. Biomed. 13 (2) (2009)
236–251.
[5] R. Peng, H. Chen, P.K. Varshney, Noise-enhanced detection of micro-calciﬁcations in digital mammograms,
IEEE J. Sel. Top. Signal Process. 3 (1) (2009) 62–73.
[6] Keinosuke Fukunaga, Introduction to Statistical Pattern Recognition, Academic Press, 1990.
[7] R.O. Duda, P.E. Hart, D.G. Stork, Pattern Classiﬁcation, vol. 2, Wiley, New York, 2001.
[8] S. Haykin,D.J.Thomson,J.H.Reed,Spectrum sensing for cognitive radio, IEEE Proc. 97 (5) (2009) 849–877.
[9] T. Yucek, H. Arslan, A survey of spectrum sensing algorithms for cognitive radio applications, IEEE Com-
mun. Surv. Tutor. 11 (1) (2009) 116–130.
[10] I.F. Akyildiz, Weilian Su, Y. Sankarasubramaniam, E. Cayirci, A survey on sensor networks, IEEE Commun.
Mag. 40 (8) (2002) 102–114.
[11] J.-F. Chamberland, V.V. Veeravalli, Wireless sensors in distributed detection applications, IEEE Signal Pro-
cess. Mag. 24 (3) (2007) 16–25.
[12] P.K. Varshney, Distributed Detection and Data Fusion, Springer, New York, 1997.
[13] H.L. Van Trees, Detection, Estimation and Modulation Theory, vol. 1, Wiley, New York, 1968.
[14] H.V. Poor, An Introduction to Signal Detection and Estimation, Springer-Verlag, New York, 1988.
[15] C.W. Helstrom, Elements of Signal Detection and Estimation, Prentice-Hall, Englewood Cliffs, NJ, 1995.
[16] R. Viswanathan, P.K. Varshney, Distributed detection with multiple sensors: Part I—Fundamentals, Proc.
IEEE 85 (1) (1997) 54–63.
[17] R.S. Blum, S.A. Kassam, H.V. Poor, Distributed detection with multiple sensors: Part II—Advanced topics,
Proc. IEEE 85 (1) (1997).
[18] R. Niu, P.K. Varshney, Performance analysis of distributed detection in a random sensor ﬁeld, IEEE Trans.
Signal Process. 56 (1) (2008) 339–349.
[19] P. Ray, P.K. Varshney, False discovery rate based sensor decision rules for the network-wide distributed
detection problem, IEEE Trans. Aerosp. Electron. Syst. 47 (3) (2011) 1785–1799.

References
203
[20] J.P. Shaffer, Multiple hypothesis testing, Annu. Rev. Psychol. 46 (1) (1995) 561–584.
[21] X. Zhu, Y. Yuan, C. Rorres, M. Kam, Distributed M-ary hypothesis testing with binary local decisions,
Inform. Fusion 5 (3) (2004) 157–167.
[22] Q. Zhang, P.K. Varshney, Decentralized M-ary detection via hierarchical binary decision fusion, Inform.
Fusion 2 (1) (2001) 3–16.
[23] C.W. Baum, V.V. Veeravalli, A sequential procedure for multihypothesis testing, IEEE Trans. Inform. Theory
40 (6) (1994).
[24] R. Viswanathan, P.K. Varshney, Distributed detection with multiple sensors I—Fundamentals, Proc. IEEE
85 (1) (1997) 54–63.
[25] J. Tsitsiklis, M. Athans, On the complexity of decentralized desicion making and detection problems, IEEE
Trans. Automat. Control 30 (1985) 440–446.
[26] N.S.V. Rao, Computational complexity issues in synthesis of simple distributed detection networks, IEEE
Trans. Syst. Man Cybern. 21 (1991) 1071–1081.
[27] J.N. Tsitsiklis, Decentralized detection, in: H.V. Poor, J.B Thomas (Eds.), Advances in Statistical Signal
Processing, JAI Press, Greenwich, CT, 1993.
[28] J.N. Tsitsiklis, On threshold rules in decentralized detection, in: Proceedings of the 25th IEEE Conference
on Decision and Control, Athens, Greece, 1986, pp. 232–236.
[29] P. Willet, D. Warren, Decentralized detection: when are identical sensors identical, in: Proceedings of the
Conference on Information Science and Systems, 1991, pp. 287–292.
[30] M. Cherikh, P.B. Kantor, Counterexamples in distributed detection, IEEE Trans. Inform. Theory 38 (1992)
162–165.
[31] Z.B. Tang, K.R. Pattipati, D. Kleinman, An algorithm for determining the detection thresholds in a distributed
detection problem, IEEE Trans. Syst. Man. Cybern. 21 (1991) 231–237.
[32] Z.B. Tang, Optimization of Detection Networks, Ph.D. Thesis, University of Connecticut, Storrs, CT, Decem-
ber 1990.
[33] A.R. Reibman, Performance and Fault-Tolerance of Distributed Detection Networks, Ph.D. Thesis, Duke
University, Durham, NC, 1987.
[34] S.C.A. Thomopoulos, R. Viswanathan, D.K. Bougoulias, Optimal distributed decision fusion, IEEE Trans.
Aerosp. Electron. Syst. 25 (1989) 761–765.
[35] C.W. Helstrom, Gradient algorithms for quantization levels in distributed detection systems, IEEE Trans.
Aerosp. Electron. Syst. 31 (1995) 390–398.
[36] Z. Chair, P.K. Varshney, Optimal data fusion in multiple sensor detection systems, IEEE Trans. Aerosp.
Electron. Syst. 22 (1986) 98–101.
[37] R. Niu, P.K. Varshney, Joint detection and localization in sensor networks based on local decisions, in: 40th
Asilomar Conference on Signals, Systems and Computers, November 2006, pp. 525–529.
[38] J.B. Thomas, Nonparametric detection, Proc. IEEE 58 (5) (1970) 623–631.
[39] S. Kay, Can detectability be improved by adding noise? IEEE Signal Proc. Lett. 7 (1) (2000) 8–10.
[40] H. Chen, P.K. Varshney, S.M. Kay, J.H. Michels, Theory of the stochastic resonance effect in signal detection:
Part I—Fixed detectors, IEEE Trans. Signal Process. 55 (7) (2007) 3172–3184.
[41] H. Chen, P.K. Varshney, Theory of the stochastic resonance effect in signal detection: Part II—Variable
detectors, IEEE Trans. Signal Process. 56 (10) (2008) 5031–5041.
[42] J.N. Tsitsiklis, Decentralized detection with a large number of sensors, Math. Control Signals Syst. 1 (1988)
167–182.
[43] P. Chen, A. Papamarcou, New asymptotic results in parallel distributed detection, IEEE Trans. Inform. Theory
39 (6) (1993) 1847–1863.
[44] J. Chamberland, V.V. Veeravalli, Decentralized detection in sensor networks, IEEE Trans. Signal Process.
51 (2003) 407–416.

204
CHAPTER 5 Distributed Signal Detection
[45] J.F. Chamberland, V.V. Veeravalli, Asymptotic results for decentralized detection in power constrained wire-
less sensor networks, IEEE J. Sel. Areas Commun. 22 (6) (2004) 1007–1015.
[46] S. Alhakeem, P.K. Varshney, A uniﬁed approach to the design of decentralized detection systems, IEEE
Trans. Aerosp. Electron. Syst. 31 (1) (1995) 9–20.
[47] P.F. Swaszek, On the performance of serial networks in distributed detection, IEEE Trans. Aerosp. Electron.
Syst. 29 (1) (1993) 254–260.
[48] Z.B. Tang, K.R. Pattipati, D.L. Kleinman, Optimization of detection networks. I. Tandem structures, IEEE
Trans. Syst. Man Cybern. 21 (5) (1991) 1044–1059.
[49] W.P. Tay, J.N. Tsitsiklis, M.Z. Win, On the subexponential decay of detection error probabilities in long
tandems, IEEE Trans. Inform. Theory 54 (10) (2008) 4767–4771.
[50] Z.-B. Tang, K.R. Pattipati, D.L. Kleinman, Optimization of detection networks. II. Tree structures, IEEE
Trans. Syst. Man Cybern. 23 (1) (1993) 211–221.
[51] W.P. Tay, J.N. Tsitsiklis, M.Z. Win, On the impact of node failures and unreliable communications in dense
sensor networks, IEEE Trans. Signal Process. 56 (6) (2008) 2535–2546.
[52] W.P. Tay, J.N. Tsitsiklis, M.Z. Win, Bayesian detection in bounded height tree networks, IEEE Trans. Signal
Process. 57 (10) (2009) 4042–4051.
[53] W.P. Tay, J.N. Tsitsiklis, M.Z. Win, Data fusion trees for detection: does architecture matter? IEEE Trans.
Inform. Theory 54 (9) (2008) 4155–4168.
[54] R. Srinivasan, Distributed detection with decision feedback (radar), IEE Proc. Radar Signal Process. 137 (6)
(1990) 427–432.
[55] S.Alhakeem,P.K.Varshney,DecentralizedBayesiandetectionwithfeedback,IEEETrans.Syst.ManCybern.
A 26 (4) (1996) 503–513.
[56] O.P. Kreidl, J.N. Tsitsiklis, S.I. Zoumpoulis, On decentralized detection with partial information sharing
among sensors, IEEE Trans. Signal Process. 59 (4) (2011) 1759–1765.
[57] T.M. Duman, M. Salehi, Decentralized detection over multiple-access channels, IEEE Trans. Aerosp. Elec-
tron. Syst. 34 (1998) 469–476.
[58] Y. Sung, L. Tong, A. Swami, Asymptotic locally optimal detector for large-scale sensor networks under the
poisson regime, IEEE Trans. Signal Process. 53 (6) (2005) 2005–2017.
[59] G. Mergen, L. Tong, Type based estimation over multiple access channels, IEEE Trans. Signal Process. 54
(2) (2006) 613–626.
[60] G. Mergen, V. Naware, L. Tong, Asymptotic detection performance of type-based multiple access over
multiaccess fading channels, IEEE Trans. Signal Process. 55 (3) (2007) 1081–1092.
[61] K. Liu, A.M. Sayeed, Type-based decentralized detection in wireless sensor networks, IEEE Trans. Signal
Process. 55 (5) (2007) 1899–1910.
[62] K. Liu, H. El Gamal, A.M. Sayeed, Decentralized inference over multiple-access channels, IEEE Trans.
Signal Process. 55 (7) (2007) 3445–3455.
[63] Q. Zou, S. Zheng, A.H. Sayed, Cooperative sensing via sequential detection, IEEE Trans. Signal Process.
58 (12) (2010) 6266–6283.
[64] Q. Cheng, P.K. Varshney, K.G. Mehrotra, C.K. Mohan, Bandwidth management in distributed sequential
detection, IEEE Trans. Inform. Theory 51 (8) (2005) 2954–2961.
[65] H. Chen, P.K. Varshney, J.H. Michels, Improving sequential detection performance via stochastic resonance,
IEEE Signal Process. Lett. 15 (2008) 685–688.
[66] V.V. Veeravalli, Decentralized quickest change detection, IEEE Trans. Inform. Theory 47 (4) (2001)
1657–1665.
[67] D. Bajovic, D. Jakovetic, J. Xavier, B. Sinopoli, J.M.F. Moura, Distributed detection via gaussian running
consensus: large deviations asymptotic analysis, IEEE Trans. Signal Process. 59 (9) (2011) 4381–4396.

References
205
[68] Z. Li, F.R. Yu, M. Huang, A distributed consensus-based cooperative spectrum-sensing scheme in cognitive
radios, IEEE Trans. Veh. Technol. 59 (1) (2010) 383–393.
[69] S.S. Stankovic, N. Ilic, M.S. Stankovic, K.H. Johansson, Distributed change detection based on a consensus
algorithm, IEEE Trans. Signal Process. 59 (12) (2011) 5686–5697.
[70] R. Niu, P.K. Varshney, Q. Cheng, Distributed detection in a large wireless sensor network, Int. J. Inform.
Fusion 7 (4) (2006) 380–394.
[71] R. Niu, P.K. Varshney, Distributed detection and fusion in a large wireless sensor network of random size,
EURASIP J. Wireless Commun. Network. 5 (4) (2005) 462–472.
[72] R. Niu, P.K. Varshney, Joint detection and localization in sensor networks based on local decisions, in:
Fortieth Asilomar (Ed.), Conference on Signals, Systems and Computers, November 2006, pp. 525–529.
[73] C. Rago, P.K. Willett, Y. Bar-Shalom, Censoring sensors: a low-communication-rate scheme for distributed
detection, IEEE Trans. Aerosp. Electron. Syst. 32 (1996) 554–568.
[74] S. Appadwedula, V.V. Veeravalli, D.L. Jones, Decentralized detection with censoring sensors, IEEE Trans.
Signal Process. 56 (4) (2008) 1362–1373.
[75] R. Jiang, Y. Lin, B. Chen, B. Suter, Distributed sensor censoring for detection in sensor networks under
communication constraints, in: 39th Asilomar Conference on Signals, Systems and Computers, October
2005, pp.946–950.
[76] P. Addesso, S. Marano, V. Matta, Sequential sampling in sensor networks for detection with censoring nodes,
IEEE Trans. Signal Process. 55 (11) (2007) 5497–5505.
[77] Q. Cao, T. Abdelzaher, T. He, J. Stankovic, Towards optimal sleep scheduling in sensor networks for rare-
event detection, in: Fourth International Symposium on Information Processing in Sensor Networks, IPSN,
April 2005, pp. 20–27.
[78] V.P. Sadaphal, B.N. Jain, Random and periodic sleep schedules for target detection in sensor net-
works, in: IEEE International Conference on Mobile Adhoc and Sensor Systems, MASS, October 2007,
pp. 1–11.
[79] E. Masazade, R. Rajagopalan, P.K. Varshney, C.K. Mohan, G.K. Sendur, M. Keskinoz, A multiobjective
optimization approach to obtain decision thresholds for distributed detection in wireless sensor networks,
IEEE Trans. Syst. Man Cybern. B 40 (2) (2010) pp. 444–457.
[80] R. Rajagopalan, P.K. Varshney, C.K. Mohan, K. Mehrotra, Sensor placement for distributed detection of
air pollutants: a constrained multi-objective optimization approach, in: Cognitive Systems with Interactive
sensors, November 2007.
[81] K. Deb, A. Pratap, S. Agarwal, T. Meyarivan, A fast and elitist multiobjective genetic algorithm: NSGA-II,
IEEE Trans. Evolut. Comput. 6 (2) (2002) 182–197.
[82] I. Das, J. Dennis, Normal-boundary interaction: a new method for generating the pareto surface in nonlinear
multicriteria optimization problems, SIAM J. Optim. 8 (1998) 631–657.
[83] B. Chen, L. Tong, P.K. Varshney, Channel aware distributed detection in wireless sensor networks, IEEE
Signal Process. Mag. 23 (4) (2006) 16–26 (special issue on Distributed Signal Processing for Sensor Net-
works).
[84] B. Chen, P.K. Willett, On the optimality of likelihood ratio test for local sensor decision rules in the presence
of non-ideal channels, IEEE Trans. Inform. Theory 51 (2) (2005) 693–699.
[85] Q. Cheng, B. Chen, P.K. Varshney, Detection performance limits for distributed sensor networks in the
presence of nonideal channels, IEEE Trans. Wireless Commun. 5 (11) (2006) 3034–3038.
[86] B. Chen, R. Jiang, T. Kasetkasem, P.K. Varshney, Channel aware decision fusion for wireless sensor networks,
IEEE Trans. Signal Process. 52 (2004) 3454–3458.
[87] R. Niu, B. Chen, P.K. Varshney, Fusion of decisions transmitted over Rayleigh fading channels in wireless
sensor networks, IEEE Trans. Signal Process. 54 (3) (2006) 1018–1027.

206
CHAPTER 5 Distributed Signal Detection
[88] R. Jiang, B. Chen, Fusion of censored decisions in wireless sensor networks, IEEE Trans. Wirel. Commun.
4 (2005) 2668–2673.
[89] I. Bahceci, G. Al-Regib, Y. Altunbasak, Parallel distributed detection for wireless sensor networks: perfor-
mance analysis and design, in: IEEE Global Telecommunications Conference, GLOBECOM ’05, vol. 4,
December 2005, pp. 2420–2424.
[90] Y. Lin, B. Chen, P.K. Varshney, Decision fusion rules in multi-hop wireless sensor networks, IEEE Trans.
Aerosp. Electron. Syst. 51 (2005) 475–488.
[91] I. Bahceci, G. Al-Regib, Y. Altunbasak, Serial distributed detection for wireless sensor networks, in: Inter-
national Symposium on Information Theory, ISIT, 2005, pp. 830–834.
[92] B. Liu, B. Chen, Channel optimized quantizers for decentralized detection in wireless sensor networks, IEEE
Trans. Inform. Theory 52 (2006) 3349–3358.
[93] B. Liu, B. Chen, Decentralized detection in wireless sensor networks with channel fading statistics, EURASIP
J. Wireless Commun. Network. 2007 (2007) 11–11.
[94] Y. Lin, B. Chen, B. Suter, Robust binary quantizers for distributed detection, IEEE Trans. Wireless Commun.
6 (6) (2007) 2172–2181.
[95] B. Liu, B. Chen, R.S. Blum, Minimum error probability cooperative relay design, IEEE Trans. Signal Process.
55 (2) (2007) 656–664.
[96] H. Chen, P.K. Varshney, B. Chen, Cooperative relay for decentralized detection, in: Proceedings of the 2008
IEEE International Conference on Acoustics, Speech and Signal Processing, Las Vegas, Nevada, March
2008, pp. 2293–2296.
[97] G.S. Lauer, N.R. Sandell Jr., Distributed detection with waveform observations: correlated observation pro-
cesses, in: Proceedings of the 1982 American Controls Conference, vol. 2, 1982, pp. 812–819.
[98] P. Chen, A. Papamarcou, Likelihood ratio partitions for distributed signal detection in correlated Gaussian
noise, in: Proceedings of the IEEE International Symposium on Information Theory, October 1996, p. 118.
[99] V. Aalo, R. Viswanathan, On distributed detection with correlated sensors: two examples, IEEE Trans.
Aerosp. Electron. Syst. 25 (1989) 414–421.
[100] V. Aalo, R. Viswanathan, Asymptotic performance of a distributed detection system in correlated Gaussian
noise, IEEE Trans. Signal Process. 40 (1992) 211–213.
[101] R. Blum, P. Willett, P. Swaszek, Distributed detection of known signals in nonGaussian noise which is
dependent from sensor to sensor, in: Proceedings of the Conference on Information Science and Systems,
March 1997, pp. 825–830.
[102] X. Lin, R. Blum, Numerical solutions for optimal distributed detection of known signals in dependent
t-distributed noise: the two-sensor problem, in: Proceedings of the Asilomar Conference on Signals, Systems
and Computers, November 1998, pp. 613–617.
[103] Z. Tang, K. Pattipati, D. Kleinman, A distributed M-ary hypothesis testing problem with correlated obser-
vations, IEEE Trans. Automat. Control 37 (1992) 1042–1046.
[104] P.K. Willett, P.F. Swaszek, R.S. Blum, The good, bad, and ugly: distributed detection of a known signal in
dependent Gaussian noise, IEEE Trans. Signal Process. 48 (2000) 3266–3279.
[105] E. Drakopoulos, C.-C. Lee, Optimum multisensor fusion of correlated local decisions, IEEE Trans. Aerosp.
Electron. Syst. 27 (4) (1991) 593–606.
[106] M. Kam, Q. Zhu, W.S. Gray, Optimal data fusion of correlated local decisions in multiple sensor detection
systems, IEEE Trans. Aerosp. Electron. Syst. 28 (3) (1992) 916–920.
[107] D.D. Mari, S. Kotz, Correlation and Dependence, Imperial College Press, 2001.
[108] R.B. Nelsen, An Introduction to Copulas, Springer-Verlag, New York, 1999.
[109] A. Sundaresan, P.K. Varshney, N.S.V. Rao, Copula-based fusion of correlated decisions, IEEE Trans. Aerosp.
Electron. Syst. 47 (1) (2011) 454–471.

References
207
[110] S.G. Iyengar, P.K. Varshney, T. Damarla, A parametric copula-based framework for hypothesis testing using
heterogeneous data, IEEE Trans. Signal Process. 59 (5) (2011) 2308–2319.
[111] A. Sundaresan, Detection and Source Location Estimation of Random Signal Sources Using Sensor Net-
works, Ph.D. Thesis, Syracuse University, 2010.

6
CHAPTER
Quickest Change Detection
Venugopal V. Veeravalli and Taposh Banerjee
ECE Department and Coordinated Science Laboratory, Urbana, IL, USA
3.06.1 Introduction
The problem of quickest change detection comprises three entities: a stochastic process under observa-
tion, a change point at which the statistical properties of the process undergo a change, and a decision
maker that observes the stochastic process and aims to detect this change in the statistical proper-
ties of the process. A false alarm event happens when the change is declared by the decision maker
before the change actually occurs. The general objective of the theory of quickest change detection is
to design algorithms that can be used to detect the change as soon as possible, subject to false alarm
constraints.
The quickest change detection problem has a wide range of important applications, including biomed-
ical signal and image processing, quality control engineering, ﬁnancial markets, link failure detection in
communication networks, intrusion detection in computer networks and security systems, chemical or
biological warfare agent detection systems (as a protection tool against terrorist attacks), detection of the
onset of an epidemic, failure detection in manufacturing systems and large machines, target detection
in surveillance systems, econometrics, seismology, navigation, speech segmentation, and the analysis
of historical texts. See Section 3.06.7 for a more detailed discussion of the applications and related
references.
To motivate the need for quickest change detection algorithms, in Figure 6.1a we plot a sample path
of a stochastic sequence whose samples are distributed as N(0, 1) before the change, and distributed as
N(0.1, 1) after the change. For illustration, we choose time slot 500 as the change point. As is evident
from the ﬁgure, the change cannot be detected through manual inspection. In Figure 6.1b, we plot the
evolution of the Shiryaev statistic (discussed in detail in Section 3.06.3), computed using the samples of
Figure6.1a.AsseeninFigure6.1b,thevalueoftheShiryaevstatisticstaysclosetozerobeforethechange
point, and grows up to one after the change point. The change is detected by using a threshold of 0.8.
We also see from Figure 6.1b that it takes around 500 samples to detect the change after it occurs. Can
we do better than that, at least on an average? Clearly, declaring change before the change point (time
slot 500) will result in zero delay, but it will cause a false alarm. The theory of quickest change detection
deals with ﬁnding algorithms that have provable optimality properties, in the sense of minimizing the
average detection delay under a false alarm constraint. We will show later that the Shiryaev algorithm,
employed in Figure 6.1b, is optimal for a certain Bayesian model.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00006-0
© 2014 Elsevier Ltd. All rights reserved.
209

210
CHAPTER 6 Quickest Change Detection
0
200
400
600
800
1000
1200
−4
−3
−2
−1
0
1
2
3
4
f0=N(0,1)    f1=N(0.1,1)
Samples
Time
0
200
400 500 600
800
1,000
1,200
0
0.1
0.2
0.3
0.6
0.7
0.8
0.9
Shiryaev’s
Algorithm
Time
Change Point = 500
(a)
(b)
FIGURE 6.1
Detecting a change in the mean of a Gaussian random sequence. (a) Stochastic sequence with samples from
f0 ∼N (0, 1) before the change (time slot 500), and with samples from f1 ∼N (0.1, 1) after the change.
(b) Evolution of the classical Shiryaev algorithm when applied to the samples given on the left. We see that
the change is detected approximately at time slot 1000.
Earliest results on quickest change detection date back to the work of Shewhart [1,2] and Page [3]
in the context of statistical process/quality control. Here the state of the system is monitored by taking
a sequence of measurements, and an alarm has to be raised if the measurements indicate a fault in the
process under observation or if the state is out of control. Shewhart proposed the use of a control chart
to detect a change, in which the measurements taken over time are plotted on a chart and an alarm is
raised the ﬁrst time the measurements fall outside some pre-speciﬁed control limits. In the Shewhart
control chart procedure, the statistic computed at any given time is a function of only the measurements
at that time, and not of the measurements taken in the past. This simpliﬁes the algorithm but may result
in a loss in performance (unacceptable delays when in detecting small changes). In [3], Page proposed
that instead of ignoring the past observations, a weighted sum (moving average chart) or a cumulative
sum (CuSum) of the past statistics (likelihood ratios) can be used in the control chart to detect the
change more efﬁciently. It is to be noted that the motivation in the work of Shewhart and Page was to
design easily implementable schemes with good performance, rather than to design schemes that could
be theoretically proven to be optimal with respect to a suitably chosen performance criterion.
Initial theoretical formulations of the quickest change detection problem were for an observation
model in which, conditioned on the change point, the observations are independent and identically
distributed (i.i.d.) with some known distribution before the change point, and i.i.d. with some other
known distribution after the change point. This observation model will be referred to as the i.i.d. case
or i.i.d. model in this article.
The i.i.d. model was studied by Shiryaev [4,5], under the further assumption that the change point
is a random variable with a known geometric distribution. Shiryaev obtained an optimal algorithm
that minimizes the average detection delay over all stopping times that meet a given constraint on the
probability of false alarm. We refer to Shiryaev’s formulation as the Bayesian formulation; details are
provided in Section 3.06.3.

3.06.1 Introduction
211
When the change point is modeled as non-random but unknown, the probability of false alarm is not
well deﬁned and therefore false alarms are quantiﬁed through the mean time to false alarm when the
system is operating under the pre-change state, or through its reciprocal, which is called the false alarm
rate. Furthermore, it is generally not possible to obtain an algorithm that is uniformly efﬁcient over all
possible values of the change point, and therefore a minimax approach is required. The ﬁrst minimax
theory is due to Lorden [6] in which he proposed a measure of detection delay obtained by taking
the supremum (over all possible change points) of a worst-case delay over all possible realizations of
the observations, conditioned on the change point. Lorden showed that the CuSum algorithm of [3] is
asymptotically optimal according to his minimax criterion for delay, as the mean time to false alarm
goes to inﬁnity (false alarm rate goes to zero). This result was improved upon by Moustakides [7] who
showed that the CuSum algorithm is exactly optimal under Lorden’s criterion. An alternative proof of
the optimality of the CuSum procedure is provided in [8]. See Section 3.06.4 for details.
Pollak [9] suggested modifying Lorden’s minimax criterion by replacing the double maximization
of Lorden by a single maximization over all possible change points of the detection delay conditioned
on the change point. He showed that an algorithm called the Shiryaev-Roberts algorithm, one that is
obtained by taking a limit on Shiryaev’s Bayesian solution as the geometric parameter of the change
point goes to zero, is asymptotically optimal as the false alarm rate goes to zero. It was later shown in
[10] that even the CuSum algorithm is asymptotically optimum under the Pollak’s criterion, as the false
alarm rate goes to zero. Recently a family of algorithms based on the Shiryaev-Roberts statistic was
shown to have strong optimality properties as the false alarm rate goes to zero. See [11] and Section
3.06.4 for details.
For the case where the pre- and post-change observations are not independent conditioned on the
change point, the quickest change detection problem was studied in the minimax setting by Lai [10]
and in the Bayesian setting by Tartakovsky and Veeravalli [12]. In both of these works, an asymptotic
lower bound on the delay is obtained for any stopping rule that meets a given false alarm constraint
(on false alarm rate in [10] and on the probability of false alarm in [12]), and an algorithm is proposed
that meets the lower bound on the detection delay asymptotically. Details are given in Sections 3.06.3.2
and 3.06.4.3
To summarize, in Sections 3.06.3 and 3.06.4, we discuss the Bayesian and Minimax versions of
the quickest change detection problem, where the change has to be detected in a single sequence of
random variables, and where the pre- and post-change distributions are given. In Section 3.06.6, we
discuss variants and generalizations of the classical quickest change detection problem, for which
signiﬁcant progress has been made. We consider the cases where the pre- or post-change distributions
are not completely speciﬁed (Section 3.06.6.1), where there is an additional constraint on the cost of
observations used in the detection process (Section 3.06.6.2), and where the change has to detected
using multiple geographically distributed sensor nodes (Section 3.06.6.3). In Section 3.06.7 we provide
a brief overview of the applications of quickest change detection. We conclude in Section 3.06.8 with
a discussion of other possible extensions and future research directions.
For a more detailed treatment of some of the topics discussed in this chapter, we refer the reader to
the books by Poor and Hadjiliadis [13] and Chow et al. [14], and the upcoming book by Tartakovsky
et al. [15]. We will restrict our attention in this chapter to detecting changes in discrete-time stochastic
systems; the continuous time setting is discussed in [13].
In Table 6.1, a glossary of important symbols used in this chapter is provided.

212
CHAPTER 6 Quickest Change Detection
Table 6.1 Glossary
Symbol
Deﬁnition/interpretation
o(1)
x = o(1) as c →c0, if ∀ϵ > 0, ∃δ > 0 s.t., |x| ≤ϵ if |c −c0| < δ
O(1)
x = O(1) as c →c0, if ∃ϵ > 0, δ > 0 s.t., |x| ≤ϵ if |c −c0| < δ
g(c) ∼h(c) as c →c0
limc→c0
g(c)
h(c) = 1 or g(c) = h(c)(1 + o(1)) as c →c0
{Xk }
Observation sequence
Stopping time τ on {Xk }
I{τ=n} = 0 or 1 depends only on the values of X1, . . . ,Xn
Change point ,γ
Time index at which distribution of observations changes from f0 to f1
Pn (En)
Probability measure (expectation) when the change occurs at time n
P∞(E∞)
Probability measure (expectation) when the change does not occur
ess sup X
Essential supremum of X , i.e., smallest K such that P(X ≤K ) = 1
D(f1∥f0)
K-L Divergence between f1 and f0, deﬁned as E1

log f1(X )
f0(X )

(x)+
max{x,0}
ADD(τ)
ADD(τ) = ∞
n=0 P( = n)En

(τ −n)+
PFA(τ)
PFA(τ) = P(τ < ) = ∞
n=0 P( = n)Pn(τ < n)
FAR(τ)
FAR(τ) =
1
E∞[τ]
WADD(τ)
WADD(τ) = sup
n≥1
ess sup En

(τ −n)+|X1, . . . ,Xn−1

CADD(τ)
CADD(τ) = sup
n≥1
En[τ −n|τ ≥n]
3.06.2 Mathematical preliminaries
A typical observation process will be denoted by sequence {Xn, n = 1, 2, . . .}. Before we describe
the quickest change detection problem, we present some useful deﬁnitions and results that summarize
the required mathematical background. For a detailed treatment of the topics discussed below we
recommend [14,16–18].
3.06.2.1 Martingales
Deﬁnition 1.
The random sequence {Xn, n = 1, 2, . . .} is called a martingale if E[Xn] is ﬁnite for all
n, and for any k1 < k2 < · · · < kn < kn+1,
E[Xkn+1|Xk1, . . . , Xkn] = Xkn.
(6.1)
If the “=” in (6.1) is replaced by “≤,” then the sequence {Xn} is called a supermartingale, and if the
“=” is replaced by “≥,” the sequence is called a submartingale. A martingale is both a supermartingale
and a submartingale.

3.06.2 Mathematical Preliminaries
213
Some important and useful results regarding martingales are as follows:
Theorem 1 (Kolmogorov’s Inequality [14]).
Let {Xn, n = 1, 2, . . .} be a submartingale. Then
P

max
1≤k≤n Xk ≥γ

≤E

X+
n

γ
, ∀γ > 0,
where X+
n = max{0, Xn}.
Kolmogorov’s inequality can be considered to be a generalization of Markov’s inequality, which is
given by
P
	
X ≥γ

≤E[X+]
γ
, ∀γ > 0.
(6.2)
As we will see in the following sections, quickest change detection procedures often involve compar-
ing a stochastic sequence to a threshold to make decisions. Martingale inequalities often play a crucial
role in the design of the threshold so that the procedure meets a false alarm constraint. We now state
one of the most useful results regarding martingales.
Theorem 2 (Martingale Convergence Theorem [16]).
Let {Xn, n = 1, 2, . . .} be a martingale (or
submartingale or supermartingale), such that supn E[|Xn|] < ∞. Then, with probability one, the limit
X∞= limk→∞Xn exists and is ﬁnite.
3.06.2.2 Stopping times
Deﬁnition 2.
A stopping time with respect to the random sequence {Xn, n = 1, 2, . . .} is a random
variable τ with the property that for each n, the event {τ = n} ∈σ(X1, . . . , Xn), where σ(X1, . . . , Xn)
denotes the sigma-algebra generated by (X1, . . . , Xn). Equivalently, the random variable I{τ=n}, which
is the indicator of the event {τ = n}, is a function of only X1, . . . , Xn.
Sometimes the deﬁnition of a stopping time τ also requires that τ be ﬁnite almost surely, i.e., that
P(τ < ∞) = 1.
Stopping times are essential to sequential decision making procedures such as quickest change
detection procedures, since the times at which decisions are made are stopping times with respect to
the observation sequence. There are two main results concerning stopping times that are of interest.
Theorem 3 (Doob’s Optional Stopping Theorem [14]).
Let {Xn, n = 1, 2, . . .} be a martingale, and
let τ be a stopping time with respect to {Xn, n = 1, 2, . . .}. If the following conditions hold:
1. P(τ < ∞) = 1,
2. E[|Xτ|] < ∞,
3. E[XnI{τ>n}] →0 as n →∞,
then
E[Xτ] = E[X1].
Similarly, if the above conditions hold, and if {Xn, n = 1, 2, . . .} is a submartingale, then
E[Xτ] ≥E[X1],

214
CHAPTER 6 Quickest Change Detection
and if {Xn, n = 1, 2, . . .} is a supermartingale, then
E[Xτ] ≤E[X1].
Theorem 4 (Wald’s Identity [17]).
Let {Xn, n = 1, 2, . . .} be a sequence of independent and identi-
callydistributed(i.i.d.)randomvariables,andlet τ beastoppingtimewithrespectto{Xn, n = 1, 2, . . .}.
Furthermore, deﬁne the sum at time n as
Sn =
n

k=1
Xk.
Then, if E[|X1|] < ∞and E[τ] < ∞,
E[Sτ] = E[X1]E[τ].
Like martingale inequalities, the optional stopping theorem is useful in the false alarm analysis of
quickest change detection procedures. Both the optional stopping theorem and Wald’s identity also play
a key role in the delay analysis of quickest change detection procedures.
3.06.2.3 Renewal and nonlinear renewal theory
As we will see in subsequent sections, quickest change detection procedures often involve comparing
a stochastic sequence to a threshold to make decisions. Often the stochastic sequence used in decision-
making can be expressed as a sum of a random walk and possibly a slowly changing perturbation.
To obtain accurate estimates of the performance of the detection procedure, one needs to obtain an
accurate estimate of the distribution of the overshoot of the stochastic sequence when it crosses the
decision threshold. Under suitable assumptions, and when the decision threshold is large enough, the
overshoot distribution of the stochastic sequence can be approximated by the overshoot distribution of
the random walk. It is then of interest to have asymptotic estimates of the overshoot distribution, when
a random walk crosses a large boundary.
Consider a sequence of i.i.d. random variables {Yn} (with Y denoting a generic random variable in
the sequence) and let
Sn =
n

k=1
Yk
and
τ = inf{n ≥1 : Sn > b}.
The quantity of interest is the distribution of the overshoot Sτ −b. If {Yn} are i.i.d. positive random
variables with cumulative distribution function (c.d.f.) F(y), then {Yn} can be viewed as inter-arrival
times of buses at a stop. The overshoot is then the time to next bus when an observer is waiting for a
bus at time b. The distribution of the overshoot, and hence also of the time to next bus, as b →∞is a
well known result in renewal theory.

3.06.2 Mathematical Preliminaries
215
Theorem 5 [17]. If {Yn} are nonarithmetic1 random variables, and P(Y > 0) = 1, then
lim
b→∞P(Sτ −b > y) = (E[Y])−1
 ∞
y
P{Y > x}dx.
Further, if E[Y 2] < ∞, then
lim
b→∞E(Sτ −b) = E[Y 2]
2E[Y].
When the {Yn} are i.i.d. but not necessarily non-negative, and E[Y] > 0, then the following concept
of ladder variables can be used. Let
τ+ = inf{n ≥1 : Sn > 0}.
Note that if τ+ < ∞, then Sτ+ is a positive random variable. Also, if
τ = inf{n ≥1 : Sn > b} < ∞
then the distribution of Sτ −b is the same as the overshoot distribution for the sum of a sequence of
i.i.d. positive random variables (each with distribution equal to that of Sτ+) crossing the boundary b.
Therefore, by applying Theorem 5, we have the following result.
Theorem 6 [17]. If {Yn} are nonarithmetic, then
lim
b→∞P(Sτ −b > y) = (E[Sτ+])−1
 ∞
y
P(Sτ+ > x)dx.
Further, if E[Y 2] < ∞, then
lim
b→∞E(Sτ −b) =
E

S2
τ+

2E

Sτ+
.
Techniques for computing the required quantities involving the distribution of the ladder height Sτ+ in
Theorem 6 can be found in [17].
As mentioned earlier, often the stochastic sequence considered in quickest change detection problem
can be written as a sum of a random walk and a sequence of small perturbations. Let
Zn =
n

k=1
Yk + ηn
and
τ = inf{n ≥1 : Zn > b}.
Then,
Zτ =
τ

k=1
Yk + ητ.
1A random variable is arithmetic if all of it probability mass is on a lattice. Otherwise it is said to be non-arithmetic.

216
CHAPTER 6 Quickest Change Detection
Therefore, assuming that E[τ] < ∞, Wald’s Identity (see Theorem 4) implies that
E[Zτ] = E
 τ

k=1
Yk

+ E[ητ],
(6.3)
= E[τ]E[Y] + E[ητ].
(6.4)
Thus,
E[τ] = E[Zτ] −E[ητ]
E[Y]
= b + E[Zτ −b] −E[ητ]
E[Y]
.
If E[ητ] and E[Zτ −b] are ﬁnite then it is easy to see that
E[τ] ∼
b
E[Y]
as b →∞,
where ∼is as deﬁned in Table 6.1.
But if we can characterize the overshoot distribution of {Zn} when it crosses a large threshold then
we can obtain better approximations for E[τ]. Nonlinear renewal theory allows us to obtain distribution
of the overshoot when {ηn} satisﬁes some properties.
Deﬁnition 3. {ηn} is a slowly changing sequence if
n−1 max{|η1|, . . . , |ηn|}
n→∞
−→
i.p. 0,
(6.5)
and for every ϵ > 0, there exists n∗and δ > 0 such that for all n ≥n∗
P

max
1≤k≤nδ |ηn+k −ηn| > ϵ

< ϵ.
(6.6)
If indeed {ηn} is a slowly changing sequence, then the distribution of Zτ −b, as b →∞, is equal to the
asymptotic distribution of the overshoot when the random walk Sn = n
k=1 Yk crosses a large positive
boundary, as stated in the following result.
Theorem 7 [17]. If {Yn} are nonarithmetic and {ηn} is a slowly changing sequence then
lim
b→∞P(Zτ −b ≤x) = lim
b→∞P(Sτ −b ≤x).
Further, if Var(Y) < ∞and certain additional conditions ((9.22)–(9.27) in [17]) are satisﬁed, then
E[τ] = b + ζ −E[η]
E[Y]
+ o(1) as b →∞,
where ζ =
E

S2
τ+

2E

Sτ+
, and η is the limit of {ηn} in distribution.

3.06.3 Bayesian Quickest Change Detection
217
3.06.3 Bayesian quickest change detection
As mentioned earlier we will primarily focus on the case where the observation process {Xn} is a discrete
time stochastic process, with Xn taking real values, whose distribution changes at some unknown change
point. In the Bayesian setting it is assumed that the change point is a random variable  taking values
on the non-negative integers, with πn = P{ = n}. Let Pn (correspondingly En) be the probability
measure (correspondingly expectation) when the change occurs at time τ = n. Then, P∞and E∞stand
for the probability measure and expectation when τ = ∞, i.e., the change does not occur. At each time
step a decision is made based on all the information available as to whether to stop and declare a change
or to continue taking observations. Thus the time at which the change is declared is a stopping time τ on
the sequence {Xn} (see Section 3.06.2.2). Deﬁne the average detection delay (ADD) and the probability
of false alarm (PFA), as
ADD(τ) = E

(τ −)+
=
∞

n=0
πnEn

(τ −n)+
,
(6.7)
PFA(τ) = P(τ < ) =
∞

n=0
πnPn(τ < n).
(6.8)
Then, the Bayesian quickest change detection problem is to minimize ADD subject to a constraint on
PFA. Deﬁne the class of stopping times that satisfy a constraint α on PFA:
Cα = {τ : PFA(τ) ≤α}.
(6.9)
Then the Bayesian quickest change detection problem as formulated by Shiryaev is as follows.
Shiryaev’s Problem: For a given α, ﬁnd a stopping time τ ∈Cα to minimize ADD(τ).
(6.10)
Under an i.i.d. model for the observations, and a geometric model for the change point , (6.10) can be
solved exactly by relating it to a stochastic control problem [4,5]. We discuss this i.i.d. model in detail
in Section 3.06.3.1. When the model is not i.i.d., it is difﬁcult to ﬁnd algorithms that are exactly optimal.
However, asymptotically optimal solutions, as α →0, are available in a very general non-i.i.d. setting
[12], as discussed in Section 3.06.3.2.
3.06.3.1 The Bayesian i.i.d. setting
Here it is assumed that conditioned on the change point , the random variables {Xn} are i.i.d. with
probability density function (p.d.f.) f0 before the change point, and i.i.d. with p.d.f. f1 after the change
point. The change point  is modeled as geometric with parameter ρ, i.e., for 0 < ρ < 1
πn = P{ = n} = ρ(1 −ρ)n−1I{n≥1},
π0 = 0
(6.11)
where I is the indicator function. The goal is to choose a stopping time τ on the observation sequence
{Xn} to solve (6.10).

218
CHAPTER 6 Quickest Change Detection
A solution to (6.10) is provided in Theorem 8 below. Let Xn
1 = (X1, . . . , Xn) denote the observations
up to time n. Also let
pn = P ( ≤n|Xn
1)
(6.12)
be the a posteriori probability at time n that the change has taken place given the observation up to time
n. Using Bayes’ rule, pn can be shown to satisfy the recursion
pn+1 = (Xn+1, pn),
(6.13)
where
(Xn+1, pn) =
˜pnL(Xn+1)
˜pnL(Xn+1) + (1 −˜pn),
(6.14)
˜pn = pn + (1 −pn)ρ, L(Xn+1) = f1(Xn+1)/ f0(Xn+1) is the likelihood ratio, and p0 = 0.
Deﬁnition 4 (Kullback-Leibler (K-L) Divergence). The K-L divergence between two p.d.f.’s f1 and
f0 is deﬁned as
D( f1∥f0) =

f1(x) log f1(x)
f0(x) dx.
Note that D( f1∥f0) ≥0 with equality iff f1 = f0 almost surely. We will assume that
0 < D( f1∥f0) < ∞.
Theorem 8 [4,5]. The optimal solution to Bayesian optimization problem of (6.10) is the Shiryaev
algorithm/test, which is described by the stopping time:
τS = inf {n ≥1 : pn ≥Aα}
(6.15)
if Aα ∈(0, 1) can be chosen such that
PFA(τS) = α.
(6.16)
Proof.
Towards solving (6.10), we consider a Lagrangian relaxation of this problem that can be solved
using dynamic programming.
J ∗= min
τ
	
E

(τ −)+
+ λ f P(τ < )

,
(6.17)
where λ f is the Lagrange multiplier, λ f ≥0. It is shown in [4,5] that under the assumption (6.16),
there exists a λ f such that the solution to (6.17) is also the solution to (6.10).
Let n denote the state of the system at time n. After the stopping time τ it is assumed that the
system enters a terminal state T and stays there. For n < τ, we have n = 0 for n < , and n = 1
otherwise. Then we can write
ADD(τ) = E
τ−1

n=0
I{n=1}

and PFA(τ) = E

I{τ =0}

.

3.06.3 Bayesian Quickest Change Detection
219
Furthermore, let Dn denote the stopping decision variable at time n, i.e., Dn = 0 if k < τ and Dn = 1
otherwise. Then the optimization problem in (6.17) can be written as a minimization of an additive cost
over time:
J ∗= min
τ
E
 τ

n=0
gn(n, Dn)

with
gn(θ, d) = I{θ̸=T }

I{θ=1}I{d=0} + λ f I{θ=0}I{d=1}

.
Using standard arguments [19] it can be seen that this optimization problem can be solved using inﬁnite
horizon dynamic programming with sufﬁcient statistic (belief state) given by:
P(n = 1|Xn
1) = P( ≤n|Xn
1) = pn,
which is the a posteriori probability of (6.12).
The optimal policy for the problem given in (6.17) can be obtained from the solution to the Bellman
equation:
J(pn) = min
dn
λ f (1 −pn)I{dn=1} + I{dn=0}

pn + AJ(pn)

,
(6.18)
where
AJ(pn) = E[J((Xn+1, pn))].
It can be shown by using an induction argument that both J and AJ are non-negative concave functions
on the interval [0, 1], and that J(1) = AJ(1) = 0. Then, it is easy to show that the optimal solution for
the problem in (6.17) has the following structure:
τS = inf {k ≥1 : pn ≥A} .
■
See Figure 6.2a for a plot of λ f (1 −pn) and pn + AJ(pn) as a function of pn. Figure 6.2b shows a
typical evolution of the optimal Shiryaev algorithm.
We now discuss some alternative descriptions of the Shiryaev algorithm. Let
n =
pn
(1 −pn)
and
Rn,ρ =
pn
(1 −pn)ρ .

220
CHAPTER 6 Quickest Change Detection
0
0.2
0.4
0.6
0.8
1
0
1
2
3
4
5
6
7
8
9
10
A
Cost 
Curves
pn
λf(1−p n)
p n+ AJ (pn)
(a)
0
50
100
150
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Γ
ADD path
PFA path
Threshold
A =0.99
pn
(b)
FIGURE 6.2
Cost curves and typical evolution of the Shiryaev algorithm. (a) A plot of the cost curves for λf = 10, ρ =
0.01, f0 ∼N (0,1), f1 ∼N(0.75,1). (b) Typical evolution of the Shiryaev algorithm. Threshold A = 0.99
and change point  = 100.
We note that n is the likelihood ratio of the hypotheses “H1 :  ≤n” and “H0 :  > n” averaged
over the change point:
n =
pn
(1 −pn)
= P
	
 ≤n|Xn
1

P
	
 > n|Xn
1

=
n
k=1 (1 −ρ)k−1ρ k−1
i=1 f0(Xi) n
i=k f1(Xi)
(1 −ρ)n n
i=1 f0(Xi)
=
1
(1 −ρ)n
n

k=1
(1 −ρ)k−1ρ
n

i=k
L(Xi),
(6.19)
where as deﬁned before L(Xi) = f1(Xi)
f0(Xi). Also, Rn,ρ is a scaled version of n:
Rn,ρ =
1
(1 −ρ)n
n

k=1
(1 −ρ)k−1
n

i=k
L(Xi).
(6.20)
Like pn, Rn,ρ can also be computed using a recursion:
Rn+1,ρ = 1 + Rn,ρ
1 −ρ
L(Xn+1),
R0,ρ = 0.
It is easy to see that n and Rn,ρ have one-to-one mappings with the Shiryaev statistic pn.

3.06.3 Bayesian Quickest Change Detection
221
Algorithm 1 (Shiryaev Algorithm). The following three stopping times are equivalent and deﬁne the
Shiryaev stopping time
τS = inf {n ≥1 : pn ≥A} ,
(6.21)
τS = inf {n ≥1 : n ≥a} ,
(6.22)
τS = inf

n ≥1 : Rn,ρ ≥a
ρ

(6.23)
with a =
A
1 −A.
We will later see that deﬁning the Shiryaev algorithm using the statistic n (6.19) will be useful in
Section3.06.3.2,wherewediscusstheBayesianquickestchangedetectionprobleminanon-i.i.d.setting.
Also, deﬁning the Shiryaev algorithm using the statistic Rn,ρ (6.20) will be useful in Section 3.06.4
where we discuss quickest change detection in a minimax setting.
3.06.3.2 General asymptotic Bayesian theory
As mentioned earlier, when the observations are not i.i.d. conditioned on the change point , then
ﬁnding an exact solution to the problem (6.10) is difﬁcult. Fortunately, a Bayesian asymptotic theory
can be developed for quite general pre- and post-change distributions [12]. In this section we discuss
the results from [12] and provide a glimpse of the proofs.
We ﬁrst state the observation model studied in [12]. When the process evolves in the pre-change
regime, the conditional density of Xn given Xn−1
1
is f0,n(Xn|Xn−1
1
). After the change happens, the
conditional density of Xn given Xn−1
1
is given by f1,n(Xn|Xn−1
1
).
As in the i.i.d. case, we can deﬁne the a posteriori probability of change having taken place before
time n, given the observation up to time n, i.e.,
pn = P
	
 ≤n|Xn
1

(6.24)
with the understanding that the recursion (6.13) is no longer valid, except for the i.i.d. model.
We note that in the non-i.i.d. case also n =
pn
1−pn is the likelihood ratio of the hypotheses
“H1 :  ≤n” and “H0 :  > n.” If πn = P{ = n}, then following (6.19), n can be written
for a general change point distribution {πn} as
n =
pn
(1 −pn)
= P
	
 ≤n|Xn
1

P
	
 > n|Xn
1

=
n
k=1 πn
k−1
i=1 f0,i
	
Xi|Xi−1
1

 n
i=k f1,i
	
Xi|Xi−1
1

P( > n) n
i=1 f0,i
	
Xi|Xi−1
1

=
1
P( > n)
n

k=1
πn
n

i=k
exp (Yi),

222
CHAPTER 6 Quickest Change Detection
where
Yi = log f1,i
	
Xi|Xi−1
1

f0,i
	
Xi|Xi−1
1

.
If  is geometrically distributed with parameter ρ, the above expression reduces to
n =
1
(1 −ρ)n
n

k=1
(1 −ρ)k−1ρ
n

i=k
exp (Yi).
In fact, n can even be computed recursively in this case:
n+1 = 1 + n
1 −ρ exp (Yn+1)
(6.25)
with 0 = 0.
In [12], it is shown that if there exists q such that
1
t
n+t

i=n
Yi →q
a.s. Pn
when t →∞∀n
(6.26)
(q = D( f1∥f0) for the i.i.d. model), and some additional conditions on the rates of convergence are
satisﬁed, then the Shiryaev algorithm (6.21) is asymptotically optimal for the Bayesian optimization
problem of (6.10) as α →0. In fact, τS minimizes all moments of the detection delay as well as the
moments of the delay, conditioned on the change point. The asymptotic optimality proof is based on
ﬁrst ﬁnding a lower bound on the asymptotic moment of the delay of all the detection procedures in the
class Cα, as α →0, and then showing that the Shiryaev stopping time (6.21) achieves that lower bound
asymptotically.
To state the theorem, we need the following deﬁnitions. Let q be the limit as speciﬁed in (6.26), and
let 0 < ϵ < 1. Then deﬁne
Tϵ(n) = sup

t ≥1 :

1
t
n+t

i=n
Yi −q
 > ϵ

.
Thus, Tϵ(n) is the last time that the log likelihood sum n+t
i=n Yi falls outside an interval of length ϵ
around q. In general, existence of the limit q in (6.26) only guarantees Pn(Tϵ(n) < ∞) = 1, and not the
ﬁniteness of the moments of Tϵ(n). Such conditions are needed for existence of moments of detection
delay of τS. In particular, for some r ≥1, we need:
En[Tϵ(n)]r < ∞for all ϵ > 0 and n ≥1,
(6.27)
and
∞

n=1
πnEn[Tϵ(n)]r < ∞for all ϵ > 0.
(6.28)

3.06.3 Bayesian Quickest Change Detection
223
Now, deﬁne
d = −lim
n→∞
log P( > n)
n
.
The parameter d captures the tail parameter of the distribution of . If  is “heavy tailed” then d = 0,
and if  has an “exponential tail” then d > 0. For example, for the geometric prior with parameter
ρ, d = | log (1 −ρ)|.
Theorem 9 [12]. If the likelihood ratios are such that (6.26) is satisﬁed then
1. If a = aα = 1−α
α , then τS as deﬁned in (6.21) belongs to the set Cα.
2. For all n ≥1, the mth moment of the conditional delay, conditioned on  = n, satisﬁes:
inf
τ∈Cα
En[(τ −n)+]m ≥
| log α|
q + d
m 	
1 + o(1)

as α →0.
(6.29)
3. For all n ≥1, if (6.27) is satisﬁed then for all m ≤r,
En[(τS −n)+]m ≤
 log a
q + d
m 	
1 + o(1)

as a →∞
=
| log α|
q + d
m 	
1 + o(1)

as α →0 if a = aα = 1 −α
α
.
(6.30)
4. The mth (unconditional) moment of the delay satisﬁes
inf
τ∈Cα
E[(τ −)+]m ≥
| log α|
q + d
m 	
1 + o(1)

as α →0.
(6.31)
5. If (6.27) and (6.28) are satisﬁed, then for all m ≤r
E[(τS −)+]m ≤
 log a
q + d
m 	
1 + o(1)

as a →∞
=
| log α|
q + d
m 	
1 + o(1)

as α →0 if a = aα = 1 −α
α
.
(6.32)
Proof.
We provide sketches of the proofs for part (1), (2), and (3). The proofs of (4) and (5) follow
by averaging the results in (2) and (3) over the prior on the change point.
1. Note that
PFA(τS) = E[1 −pτS] ≤1 −Aα.
Thus, Aα = 1 −α would ensure PFA(τS) ≤α. Since, aα =
Aα
1−Aα , we have the result.
2. Let Lα be a positive number. By Chebyshev inequality,
Pn
	
(τ −n)m > Lm
α

≤En[(τ −n)+]m
Lmα
.

224
CHAPTER 6 Quickest Change Detection
This gives a lower bound on the detection delay
En[(τ −n)+]m ≥Lm
α Pn
	
(τ −n)m > Lm
α

= Lm
α Pn(τ −n > Lα).
Minimizing over the family Cα, we get
inf
τ∈Cα
En[(τ −n)+]m ≥Lm
α

inf
τ∈Cα
Pn(τ −n > Lα)

.
Thus, if
inf
τ∈Cα
Pn(τ −n > Lα) →1 as α →0
(6.33)
then Lm
α is a lower found for the detection delay of the family Cα. It is shown in [12] that if (6.26)
is satisﬁed then (6.33) is true for Lα = (1 −ϵ) | log α|
q+d for all ϵ > 0.
3. We only summarize the technique used to obtain the upper bound. Let {Sn} be any stochastic process
such that
Sn
n →q as n →∞.
Let
η = inf{n ≥1 : Sn > b}
and for ϵ > 0
Tϵ = sup

n ≥1 :

Sn
n −b
 > ϵ

.
First note that Sη−1 < b < Sη. Also, on the set {k ≥Tϵ}, |Sn/n −q| < ϵ for all n ≥k. The event
{|Sn/n −q| < ϵ} implies n ≤
Sn
q−ϵ . Using these observations we have
η −1 = (η −1)I{η−1>Tϵ} + (η −1)I{η−1≤Tϵ}
≤(η −1)I{η−1>Tϵ} + Tϵ
≤
b
q −ϵ + Tϵ.
If E[Tϵ] < ∞, and because ϵ was chosen arbitrarily, we have
E[η] ≤b
q
	
1 + o(1)

as b →∞.
This also motivates the need for conditions on ﬁniteness of higher order moments of Tϵ to obtain
upper bound on the moments of the detection delay.
■
From the above theorem, the following corollary easily follows.
Corollary 1 [12]. If the likelihood ratios are such that (6.26−6.28) are satisﬁed for some r ≥1, then
for the Shiryaev stopping time τS deﬁned in (6.21)
inf
τ∈Cα
E[(τ −)+]m ∼E[(τS −)+]m ∼
| log α|
q + d
m
as α →0, for all m ≤r.
(6.34)
A similar result can be concluded for the conditional moments as well.

3.06.3 Bayesian Quickest Change Detection
225
3.06.3.3 Performance analysis for i.i.d. model with geometric prior
We now present the second order asymptotic analysis of the Shiryaev algorithm for the i.i.d. model,
provided in [12] using the tools from nonlinear renewal theory introduced in Section 3.06.2.3.
When the observations {Xn} are i.i.d. conditioned on the change point, condition (6.26) is satisﬁed
and
1
t
k+t

i=n
Yi →D( f1∥f0) a.s. Pn
when t →∞∀n,
where D( f1∥f0) is the K-L divergence between the densities f1 and f0 (see Deﬁnition 4). From
Thereom 9, it follows that for aα = 1−α
α ,
PFA(τS) ≤α.
Also, it is shown in [12] that if
0 < D( f1∥f0) < ∞and 0 < D( f0∥f1) < ∞,
then conditions (6.27) and (6.28) are satisﬁed, and hence from Corollary 1,
inf
τ∈Cα
E[(τ −)+]m ∼E[(τS −)+]m ∼

| log α|
D( f1∥f0) + | log (1 −ρ)|
m
as α →0.
(6.35)
Note that the above statement provides the asymptotic delay performance of the Shiryaev algorithm.
However, the bound for PFA can be quite loose and the ﬁrst order expression for the ADD (6.35) may
not provide good estimate for ADD if the PFA is not very small. In that case it is useful to have a second
order estimate based on nonlinear renewal theory, as obtained in [12].
First note that (6.25) for the i.i.d. model will reduce to
n+1 = 1 + n
1 −ρ L(Xn+1).
(6.36)
with 0 = 0. Now, let Zn = log n, and recall that Yk = log f1(Xk)
f0(Xk). Then, it can be shown that
Zn =
n

k=1
[Yk + | log (1 −ρ)|] + log

eZ0 + ρ

+
n−1

k=1
log

1 + e−Zkρ

=
n

k=1
Yk + n| log (1 −ρ)| + ηn.
(6.37)
Therefore the Shiryaev algorithm can be equivalently written as
τS = inf {n ≥1 : Zn ≥b}.
We now show how the asymptotic overshoot distribution plays a key role in second order asymptotic
analysis of PFA and ADD. Since, pτS ≥A implies that ZτS ≥log
A
1−A = log a = b, we have,
1
1 + e−ZτS ≥
a
1 + a .

226
CHAPTER 6 Quickest Change Detection
PFA(τS) = E[1 −pτS] = E

1
1 + eZτS

≤E

e−ZτS

= E
 1
eZτS
1
1 + e−ZτS

≥E
 1
eZτS
a
1 + a

= E

e−ZτS

(1 + o(1)) as a →∞.
Thus,
PFA(τS) = E[e−ZτS](1 + o(1)) = e−bE[e−(ZτS−b)](1 + o(1)) as b →∞
= e−bE[e−(ZτS−b)|τ ≥](1 + o(1)) as b →∞,
and we see that PFA is a function of the overshoot when Zn crosses a from below.
Similarly,
ZτS =
τS

k=1
Yk + τS| log (1 −ρ)| + ητS.
Following the developments in Section 3.06.2.3, if the sequence Yn satisﬁes some additional conditions,
then we can write2:
E1[τ] =
E1[Zτ] −E1[ητ]
| log (1 −ρ)| + D( f1∥f0)
= b + E1[Zτ −b] −E1[ητ]
| log (1 −ρ)| + D( f1∥f0).
It is shown in [12] that ηn is a slowly changing sequence, and hence the distribution of ZτS −b, as
b →∞, is equal to the asymptotic distribution of the overshoot when the random walk n
k=1 Yk +
n| log (1 −ρ)| crosses a large positive boundary. We deﬁne the following quantities: the asymptotic
overshoot distribution of a random walk
R(x) = lim
b→∞P
 τS

k=1
Yk + τS| log (1 −ρ)| −b ≤x

(6.38)
its mean
κ =
 ∞
0
xd R(x)
(6.39)
and its Laplace transform at 1
ζ =
 ∞
0
e−xd R(x).
(6.40)
Also, the sequence {Yn} satisﬁes some additional conditions and hence the following results are true.
2As explained in [12], this analysis is facilitated if we restrict to the worst-case detection delay, which is obtained by
conditioning on the event that the change happens at time 1.

3.06.3 Bayesian Quickest Change Detection
227
Table 6.2 f0 ∼N (0,1), f1 ∼N (1,1), ρ = 0.01
PFA
ADD
b
Simulations
Analysis
Simulations
Analysis
Theorem 10
Theorem 10
1.386
1.22 × 10−1
1.39 × 10−1
6.93
10.31
2.197
5.85 × 10−2
6.19 × 10−2
8.87
11.9
4.595
5.61 × 10−3
5.63 × 10−3
13.9
16.6
6.906
5.59 × 10−4
5.58 × 10−4
18.59
21.13
11.512
5.6 × 10−6
5.58 × 10−6
27.64
30.16
Theorem 10 [12]. If {Yn}s are nonarithmetic then ηn is a slowly changing sequence. Then by
Theorem 7
lim
b→∞P(ZτS−b ≤x) = R(x).
This implies
PFA(τS) ∼ζ e−b
as b →∞.
If in addition E[Y 2] < ∞then
E1[τS] =
b + κ −E1[η]
| log (1 −ρ)| + D( f1∥f0) + o(1) as b →∞,
where η is the a.s. limit of the sequence {ηn}.
In Table 6.2, we compare the asymptotic expressions for PFA and ADD given in Theorem 10
with simulations. As can be seen in the table, the asymptotic expressions get more accurate as PFA
approaches 0.
In Figure 6.3 we plot the ADD as a function of log (PFA) for Gaussian observations. For a PFA
constraint of α that is small, b ≈| log (α)|, and
ADD ≈E1[τS] ≈
| log (α)|
| log (1 −ρ)| + D( f1∥f0)
giving a slope of
1
| log (1−ρ)|+D( f1∥f0) to the trade-off curve.
When | log (1 −ρ)| ≪D( f1∥f0), the observations contain more information about the change
than the prior, and the tradeoff slope is roughly
1
D( f1∥f0). On the other hand, when | log (1 −ρ)| ≫
D( f1∥f0), the prior contains more information about the change than the observations, and the tradeoff
slope is roughly
1
| log (1−ρ)|. The latter asymptotic slope is achieved by the stopping time that is based
only on the prior:
τ = inf {n ≥1 : P( > n) ≤α} .
This is also easy to see from (6.14). With D( f1∥f0) small, L(X) ≈1, and the recursion for pk
reduces to
pn+1 = pn + (1 −pn)ρ,
p0 = 0.

228
CHAPTER 6 Quickest Change Detection
4
5
6
7
8
9
10
11
20
25
30
35
40
45
Shiryaev
|log(PFA)|
ADD
Slope = [D(f1  | f0 ) + |log(1−ρ)|] −1
|
FIGURE 6.3
ADD-PFA trade-off curve for the Shiryaev algorithm: ρ = 0.01, f0 = N (0,1), f1 = N (0.75,1).
Expanding we get pn = ρ n−1
k=0 (1 −ρ)k. The desired expression for the mean delay is obtained from
the equation pτ = 1 −α.
3.06.4 Minimax quickest change detection
When the distribution of the change point is not known, we may model the change point as a deterministic
but unknown positive integer γ . A number of heuristic algorithms have been developed in this setting.
The earliest work is due to Shewhart [1,2], in which the log likelihood based on the current observation
is compared with a threshold to make a decision about the change. The motivation for such a technique
is based on the following fact: if X represents the generic random variable for the i.i.d. model with f0
and f1 as the pre- and post-change p.d.fs, then
E∞

log L(X)

= −D( f0∥f1) < 0 and E1

log L(X)

= D( f1∥f0) > 0,
(6.41)
where as deﬁned earlier L(x) = f1(x)/ f0(x), and E∞and E1 correspond to expectations when γ = ∞
and γ = 1, respectively. Thus, after γ , the log likelihood of the observation X is more likely to be above
a given threshold. Shewhart’s method is widely employed in practice due to its simplicity; however,
signiﬁcant performance gain can be achieved by making use of past observations to make the decision
about the change. Page [3] proposed such an algorithm that uses past observations, which he called the
CuSum algorithm. The motivation for the CuSum algorithm is also based on (6.41). By the law of large
numbers, n
i=γ log L(Xi) grows to ∞as n →∞. Thus, if Sn = n
i=1 log L(Xi) is the accumulated
log likelihood sum, then before γ , Sn has a negative drift and evolves towards −∞. After γ , Sn has a

3.06.4 Minimax Quickest Change Detection
229
positive drift and climbs towards ∞. Therefore, intuition suggests the following algorithm should detect
this change in drift:
τC = inf

n ≥1 :

Sn −min
1≤k≤n Sk

≥b

,
(6.42)
where b > 0. Note that
Sn −min
1≤k≤n Sk = max
0≤k≤n
n

i=k+1
log L(Xi) =
max
1≤k≤n+1
n

i=k
log L(Xi).
Thus, τC can be equivalently deﬁned as follows.
Algorithm 2 (CuSum algorithm).
τC = inf {n ≥1 : Wn ≥b} ,
(6.43)
where
Wn =
max
1≤k≤n+1
n

i=k
log L(Xi).
(6.44)
The statistic Wn has the convenient recursion:
Wn+1 =
	
Wn + log L(Xn+1)

+,
W0 = 0.
(6.45)
It is this cumulative sum recursion that led Page to call τC the CuSum algorithm.
The summation on the right hand side (RHS) of (6.44) is assumed to take the value 0 when k = n+1.
It turns out that one can get an algorithm that is equivalent to the above CuSum algorithm by removing
the term k = n + 1 in the maximization on the RHS of (6.44), to get the statistic:
Cn = max
1≤k≤n
n

i=k
log L(Xi).
(6.46)
The statistic Cn also has a convenient recursion:
Cn+1 =
	
Cn

+ + log L(Xn+1),
C0 = 0.
(6.47)
Note that unlike the statistic Wn, the statistic Cn can be negative. Nevertheless it is easy to see that both
Wn and Cn will cross a positive threshold b at the same time (sample path wise) and hence the CuSum
algorithm can be equivalently deﬁned in terms of Cn as:
τC = inf {n ≥1 : Cn ≥b} .
(6.48)
An alternative way to derive the CuSum algorithm is through the maximum likelihood approach i.e., to
compare the likelihood of { ≤n} against { > n}. Formally,
τC = inf

n ≥1 : max1≤k≤n
k−1
i=1 f0(Xi) n
i=k f1(Xi)
n
i=1 f0(Xi)
≥B

.
(6.49)
Cancelling terms and taking log in (6.49) gives us (6.48) with b = log B.

230
CHAPTER 6 Quickest Change Detection
0
10
20
30
40
50
60
70
80
0
1
2
3
4
5
6
7
8
9
delay path
Wn
false alarm path
Threshold b = 8
γ
FIGURE 6.4
Typical Evolution of the CuSum algorithm. Threshold b = 8 and change point γ = 60.
See Figure 6.4 for a typical evolution of the CuSum algorithm.
Although, the CuSum algorithm was developed heuristically by Page [3], it was later shown in
[6–8,10], that it has very strong optimality properties. In this section, we will study the CuSum and
related algorithms from a fundamental viewpoint, and discuss how each of these algorithms is provably
optimal with respect to a meaningful and useful optimization criterion.
Without a prior on the change point, a reasonable measure of false alarms is the mean time to false
alarm, or its reciprocal, which is the false alarm rate (FAR):
FAR(τ) =
1
E∞[τ].
(6.50)
Finding a uniformly powerful test that minimizes the delay over all possible values of γ subject to a FAR
constraint is generally not possible. Therefore it is more appropriate to study the quickest change detec-
tion problem in a minimax setting in this case. There are two important minimax problem formulations,
one due to Lorden [6] and the other due to Pollak [9].
In Lorden’s formulation, the objective is to minimize the supremum of the average delay conditioned
on the worst possible realizations, subject to a constraint on the false alarm rate. In particular, if we
deﬁne3
WADD(τ) = sup
n≥1
ess sup En

(τ −n)+|X1, . . . , Xn−1

.
(6.51)
3Lorden deﬁned WADD with (τ −n + 1)+ inside the expectation, i.e., he assumed a delay penalty of 1 if the algorithm stops
at the change point. We drop this additional penalty in our deﬁnition in order to be consistent with the other delay deﬁnitions
in this chapter.

3.06.4 Minimax Quickest Change Detection
231
and denote the set of stopping times that meet a constraint α on the FAR by
Dα = {τ : FAR(τ) ≤α}.
(6.52)
We have the following problem formulation due to Lorden.
Lorden’s Problem: For a given α, ﬁnd a stopping time τ ∈Dα to minimize WADD(τ).
(6.53)
For the i.i.d. setting, Lorden showed that the CuSum algorithm (6.43) is asymptotically optimal for
Lorden’s formulation (6.53) as α →0. It was later shown in [7,8] that the CuSum algorithm is actually
exactly optimal for (6.53). Although the CuSum algorithm enjoys such a strong optimality property
under Lorden’s formulation, it can be argued that WADD is a somewhat pessimistic measure of delay.
A less pessimistic way to measure the delay was suggested by Pollak [9]:
CADD(τ) = sup
n≥1
En[τ −n|τ ≥n].
(6.54)
for all stopping times τ for which the expectation is well-deﬁned.
Lemma 1.
WADD(τ) ≥CADD(τ).
Proof.
Due to the fact that τ is a stopping time on {Xn},
{τ ≥n} = {τ ≤n −1}c ∈σ(X1, X2, . . . , Xn−1).
Therefore, for each n
ess sup En

(τ −n)+|X1, . . . , Xn−1

≥En[(τ −n)+|τ ≥n] = En[τ −n|τ ≥n]
and the lemma follows.
■
We now state Pollak’s formulation of the problem that uses CADD as the measure of delay.
Pollak’s Problem: For a given α, ﬁnd a stopping time τ ∈Dα to minimize CADD(τ).
(6.55)
Pollak’s formulation has been studied in the i.i.d. setting in [9,20], where it is shown that algorithms
based on the Shiryaev-Roberts statistic (to be deﬁned later) are within a constant of the best possible
performance over the class Dα, as α →0.
Lai [10] studied both (6.53) and (6.55) in a non-i.i.d. setting and developed a general minimax
asymptotic theory for these problems. In particular, Lai obtained a lower bound on CADD(τ), and hence
also on the WADD(τ), for every stopping time in the class Dα, and showed that an extension of the
CuSum algorithm for the non-i.i.d. setting achieves this lower bound asymptotically as α →0.
In Section 3.06.4.1 we introduce a number of alternatives to the CuSum algorithm for minimax
quickest change detection in the i.i.d. setting that are based on the Bayesian Shiryaev algorithm. We
then discuss the optimality properties of these algorithms in Section 3.06.4.2. While we do not discuss
the exact optimality of the CuSum algorithm from [7] or [8], we brieﬂy discuss the asymptotic optimality
result from [6]. We also note that the asymptotic optimality of the CuSum algorithm for both (6.53)
and (6.55) follows from the results in the non-i.i.d. setting of [10], which are summarized in Section
3.06.4.3.

232
CHAPTER 6 Quickest Change Detection
3.06.4.1 Minimax algorithms based on the Shiryaev algorithm
Recall that the Shiryaev algorithm is given by (see (6.20) and (6.23)):
τS = inf

n ≥1 : Rn,ρ ≥a

,
where
Rn,ρ =
1
(1 −ρ)n
n

k=1
(1 −ρ)k−1
n

i=k
L(Xi).
Also recall that Rn,ρ has the recursion:
Rn+1,ρ = 1 + Rn,ρ
1 −ρ
L(Xn+1),
R0,ρ = 0.
Setting ρ = 0 in the expression for Rn,ρ we get the Shiryaev-Roberts (SR) statistic [21]:
Rn =
n

k=1
n

i=k
L(Xi)
(6.56)
with the recursion:
Rn+1 = (1 + Rn)L(Xn+1),
R0 = 0.
(6.57)
Algorithm 3 (Shiryaev-Roberts (SR) Algorithm).
τSR = inf {n ≥1 : Rn ≥B, R0 = 0} .
(6.58)
It is shown in [9] that the SR algorithm is the limit of a sequence of Bayes tests, and in that limit
it is asymptotically Bayes efﬁcient. Also, it is shown in [20] that the SR algorithm is second order
asymptotically optimal for (6.55), as α →0, i.e., its delay is within a constant of the best possible delay
over the class Dα. Further, in [22], the SR algorithm is shown to be exactly optimal with respect to a
number of other interesting criteria.
It is also shown in [9] that a modiﬁed version of the SR algorithm, called the Shiryaev-Roberts-Pollak
(SRP) algorithm, is third order asymptotically optimal for (6.55), i.e., its delay is within a constant of
the best possible delay over the class Dα, and the constant goes to zero as α →0. To introduce the SRP
algorithm, let QB be the quasi-stationary distribution of the SR statistic Rn above:
QB(x) = lim
n→∞P0(Rn ≤x|τSR > n).
The new recursion, called the Shiryaev-Roberts-Pollak (SRP) recursion, is given by,
RB
n+1 = (1 + RB
n )L(Xn+1)
with RB
0 distributed according to QB.
Algorithm 4 (Shiryaev-Roberts-Pollak (SRP) Algorithm).
τSRP = inf

n ≥1 : RB
n ≥B

.
(6.59)

3.06.4 Minimax Quickest Change Detection
233
Although the SRP algorithm is strongly asymptotically optimal for Pollak’s formulation of (6.55),
in practice, it is difﬁcult to compute the quasi-stationary distribution QB. A numerical framework
for computing QB efﬁciently is provided in [23]. Interestingly, the following modiﬁcation of the SR
algorithm with a speciﬁcally designed starting point R0 = r ≥0 is found to outperform the SRP
procedure uniformly over all possible values of the change point [20]. This modiﬁcation, referred to as
the SR-r procedure, has the recursion:
Rr
n+1 = (1 + Rr
n)L(Xn+1),
R0 = r.
Algorithm 5 (Shiryaev-Roberts-r (SR-r) Algorithm).
τSR−r = inf

n ≥1 : Rr
n ≥B

.
(6.60)
It is shown in [20] that the SR-r algorithm is also third order asymptotically optimal for (6.55), i.e., its
delay is within a constant of the best possible delay over the class Dα, and the constant goes to zero as
α →0.
Notethatforanarbitrarystoppingtime,computingtheCADD metric(6.54)involvestakingsupremum
over all possible change times, and computing the WADD metric (6.51) involves another supremum over
all possible past realizations of observations. While we can analyze the performance of the proposed
algorithms through bounds and asymptotic approximations, as we will see in Section 3.06.4.2, it is not
obvious how one might evaluate CADD and WADD for a given algorithm in computer simulations. This
is in contrast with the Bayesian setting, where ADD (see (6.7)) can easily be evaluated in simulations
by averaging over realizations of change point random variable .
Fortunately, for the CuSum algorithm (6.43) and for the Shiryaev-Roberts algorithm (6.58), both
CADD and WADD are easy to evaluate in simulations due to the following lemma.
Lemma 2.
CADD(τC) = WADD(τC) = E1

(τC −1)

,
(6.61)
CADD(τSR) = WADD(τSR) = E1

(τSR −1)

.
(6.62)
Proof.
The CuSum statistic Wn (see (6.44)) has initial value 0 and remains non-negative for all n.
If the change were to happen at some time n > 1, then the pre-change statistic Wn−1 is greater than
or equal 0, which equals the pre-change statistic if the change happens at n = 1. Therefore, the delay
for the CuSum statistic to cross a positive threshold b is largest when the change happens at n = 1,
irrespective of the realizations of the observations, X1, X2, . . . , Xn−1. Therefore
WADD(τC) = sup
n≥1
ess sup En

(τC −n)+|X1, . . . , Xn−1

= E1

(τC −1)+
= E1

(τC −1)

and
CADD(τC) = sup
n≥1
En[τ −n|τC ≥n] = E1

(τC −1)|τC ≥1

= E1

(τC −1)

.
This proves (6.61). A similar argument can be used to establish (6.62).

234
CHAPTER 6 Quickest Change Detection
Note that the above proof crucially depended on the fact that both the CuSum algorithm and the Shiryaev-
Roberts algorithm start with the initial value of 0. Thus it is not difﬁcult to see that Lemma 2 does not
hold for the SR-r algorithm, unless of course r = 0. Lemma 2 holds partially for the SRP algorithm
since the initial distribution QB makes the statistic RB
n stationary in n. As a result En[τSRP−n|τSRP ≥n]
is the same for every n. However, as mentioned previously, QB is difﬁcult to compute in practice, and
this makes the evaluation of CADD and WADD in simulations somewhat challenging.
3.06.4.2 Optimality properties of the minimax algorithms
In this section we ﬁrst show that the algorithms based on the Shiryaev-Roberts statistics, SR, SRP, and
SR-r are asymptotically optimal for Pollak’s formulation of (6.55). We need an important theorem that
is proved in [22].
Theorem 11 [22]. If the threshold in the SR algorithm (6.58) can be selected to meet the constraint α
on FAR with equality, then
τSR = arg min
τ∈Dα
∞
n=1 En[(τ −n)+]
E∞[τ]
.
Proof.
We give a sketch of the proof here. Note that
∞

n=1
En[(τ −n)+] =
∞

n=1
En[τ −n|τ ≥n]P∞(τ ≥n)
≤CADD(τ)
∞

n=1
P∞(τ ≥n)
= CADD(τ)E∞[τ],
and hence is ﬁnite for all stopping times for which CADD and FAR are ﬁnite. The ﬁrst part of the proof
is to show that
∞

n=1
En[(τSR −n)+] = min
τ∈Dα
∞

n=1
En[(τ −n)+].
This follows from the following result of [9]. If
Jλ,ρ(τ) = min
τ
	
E

(τ −)+
+ λP(τ < )

with  having the geometric distribution of (6.11) with parameter ρ, and
τλ,ρ = arg min
τ
Jλ,ρ(τ).
(6.63)
Then for a given τSR (with a given threshold), there exists a sequence {(λi, ρi)} and with λi →λ∗and
ρi →0 such that τλi,ρi converge to τSR, as i →∞. Thus, the SR algorithm is the limit of a sequence
of Bayes tests. Moreover,
lim sup
ρ→0,λ→λ∗
1 −Jλ,ρ(τλ,ρ)
1 −Jλ,ρ(τSR) = 1.

3.06.4 Minimax Quickest Change Detection
235
By (6.63), for any stopping time τ, it holds that
1 −Jλ,ρ(τ)
1 −Jλ,ρ(τSR) ≤1 −Jλ,ρ(τλ,ρ)
1 −Jλ,ρ(τSR) .
Now by taking the limit ρ →0, λ →λ∗on both sides, using the fact that for any stopping time τ [22]
1 −Jλ,ρ(τ)
ρ
→λ∗E∞[τ] −
∞

n=1
E

(τ −n)+
as ρ →0
and using the hypothesis of the theorem that the FAR constraint can be met with equality by using τSR,
we have the desired result.
The next step in the proof is to show that it is enough to consider stopping times in the class Dα that
meet the constraint of α with quality. The result then follows easily from the fact that τSR is optimal
with respect to the numerator in
∞
n=1 En[(τ−n)+]
E∞[τ]
.
■
We now state the optimality proof for the procedures SR, SR-r and SRP. We only provide an outline
of the proof to illustrate the fundamental ideas behind the result.
Theorem 12 [20]. If E1

log f1(Xn)
f0(Xn)
2
< ∞, and log f1(Xn)
f0(Xn) is nonarithmetic then
1.
inf
τ∈Dα
CADD(τ) ≥
| log α|
D( f1∥f0) + ˆκ + o(1) as α →0,
(6.64)
where ˆκ is a constant that can be characterized using renewal theory [18].
2. For the choice of threshold B = 1
α , FAR(τSR) ≤α, and
CADD(τSR) =
| log α|
D( f1∥f0) + ˆζ + o(1) as α →0
= inf
τ∈Dα
CADD(τ) + O(1) as α →0,
(6.65)
where ˆζ is again a constant that can be characterized using renewal theory [18].
3. There exists a choice for the threshold B = Bα such that FAR(τSRP) ≤α(1 + o(1)) and
CADD(τSRP) = | log α|
D( f1∥f0) + ˆκ + o(1) as α →0
= inf
τ∈Dα
CADD(τ) + o(1) as α →0.
(6.66)
4. There exists a choice for the threshold B = Bα such that FAR(τSRP) ≤α(1 + o(1)) and a choice
for the initial point r such that
CADD(τSR−r) = | log α|
D( f1∥f0) + ˆκ + o(1) as α →0
= inf
τ∈Dα
CADD(τ) + o(1) as α →0.
(6.67)

236
CHAPTER 6 Quickest Change Detection
Proof.
To prove that the above mentioned choice of thresholds meets the FAR constraint, we note that
{Rr
n −n −r} is a martingale. Speciﬁcally, {Rn −n} is a martingale and the conditions of Theorem 3
are satisﬁed [24]. Hence,
E∞[RτSR −τSR] = 0.
Since, E∞[RτSR] ≥B, for B = 1
α we have
FAR(τSR) =
1
E∞[RτSR] ≤1
B = α.
For a description of how to set the thresholds for τSR−r and τSRP, we refer the reader to [20].
The proofs of the delay expressions for all the algorithms have a common theme. The ﬁrst part of
these proofs is based on Theorem 11. We ﬁrst show that
∞
n=1 En[(τ−n)+]
E∞[τ]
is a lower bound to CADD(τ).
CADD(τ) = sup
n
En[τ −n|τ ≥n] =
∞
j=1 supnEn[τ −n|τ ≥n]P∞(τ ≥j)
E∞[τ]
≥
∞
j=1 E j[τ −j|τ ≥j]P∞(τ ≥j)
E∞[τ]
=
∞
j=1 E j[(τ −j)+]
E∞[τ]
.
From Theorem 11, since τSR is optimal with respect to minimizing
∞
n=1 En[(τ−n)+]
E∞[τ]
, we have
inf
τ∈Dα
CADD(τ) ≥
∞
n=1 En[(τSR −n)+]
E∞[τSR]
.
The next step is to use nonlinear renewal theory (see Section 3.06.2.3) to obtain a second order
approximation for the right hand side of the above equation, as we did for the Shiryaev procedure in
Section 3.06.3.3:
∞
n=1 En[(τSR −n)+]
E∞[τSR]
=
| log α|
D( f1∥f0) + ˆκ + o(1) as α →0.
The ﬁnal step is to show that the CADD for the SR-r and SRP procedures are within o(1), and the CADD
for SR procedure is within O(1) of this lower bound (6.64). This is done by obtaining second order
approximations using nonlinear renewal theory for the CADD of SR, SRP, SR-r procedures, and get
(6.65–6.67), respectively.
Itisshownin[22]that
∞
n=1 En[(τ−n)+]
E∞[τ]
isalsoequivalenttotheaveragedelaywhenthechangehappens
at a “far horizon”: γ →∞. Thus, the SR algorithm is also optimal with respect to that criterion.
The following corollary follows easily from the above two theorems. Recall that in the minimax
setting, an algorithm is called third order asymptotically optimum if its delay is within an o(1) term of
the best possible, as the FAR goes to zero. An algorithm is called second order asymptotically optimum
if its delay is within an O(1) term of the best possible, as the FAR goes to zero. And an algorithm is
called ﬁrst order asymptotically optimal if the ratio of its delay with the best possible goes to 1, as the
FAR goes to zero.

3.06.4 Minimax Quickest Change Detection
237
Corollary 2. Under the conditions of Theorem 11, the SR-r (6.60) and the SRP (6.59) algorithms are
third order asymptotically optimum, and the SR algorithm is second order asymptotically optimum for
the Pollak’s formulation (6.55). Furthermore, using the choice of thresholds speciﬁed in Theorem 11 to
meet the FAR constraint of α, the asymptotic performance of all three algorithms are equal up to ﬁrst
order:
CADD(τSR) ∼CADD(τSRP) ∼CADD(τSR−r) ∼
| log α|
D( f1∥f0).
Furthermore, by Lemma 2, we also have:
WADD(τSR) ∼
| log α|
D( f1∥f0).
In [6] the asymptotic optimality of the CuSum algorithm (6.43) as α →0 is established for Lorden’s
formulation of (6.53). First, ergodic theory is used to show that choosing the threshold b = | log α|
ensures FAR(τC) ≤α. For the above choice of threshold B = | log α|, it is shown that
WADD(τC) ≤
| log α|
D( f1∥f0)(1 + o(1)) as α →0.
Then the exact optimality of the SPRT [25] is used to ﬁnd a lower bound on the WADD of the class Dα:
inf
τ∈Dα
WADD(τ) ≥
| log α|
D( f1∥f0)(1 + o(1)) as α →0.
These arguments establish the ﬁrst order asymptotic optimality of the CuSum algorithm for Lorden’s
formulation. Furthermore, as we will see later in Theorem 13, Lai [10] showed that:
inf
τ∈Dα
WADD(τ) ≥inf
τ∈Dα
CADD(τ) ≥| log α|
I
	
1 + o(1)

.
Thus by Lemma 2, the ﬁrst order asymptotic optimality of the CuSum algorithm extends to Pollak’s
formulation (6.55), and we have the following result.
Corollary 3.
The CuSum algorithm (6.43) with threshold b = | log α| is ﬁrst order asymptotically
optimum for both Lorden’s and Pollak’s formulations. Furthermore,
CADD(τC) = WADD(τC) ∼
| log α|
D( f1∥f0).
In Figure 6.5, we plot the trade-off curve for the CuSum algorithm, i.e., plot CADD as a function of
−log FAR. Note that the curve has a slope of 1/D( f1∥f0).
3.06.4.3 General asymptotic minimax theory
In [10], the non-i.i.d. setting earlier discussed in Section 3.06.3.2 is considered, and asymptotic lower
bounds on the WADD and CADD for stopping times in Dα are obtained under quite general conditions.

238
CHAPTER 6 Quickest Change Detection
7
7.5
8
8.5
9
9.5
10
16
17
18
19
20
21
22
23
24
25
26
f 0= N(0,1)  1= N(0.75,1)  
CUSUM
−log(FAR)
CADD
Slope = 1/D (f1 | | f 0)
f
FIGURE 6.5
ADD-PFA trade-off curve for the CuSum algorithm: f0 = N (0,1), f1 = N (0.75,1).
It is then shown that the an extension of the CuSum algorithm (6.43) to this non-i.i.d. setting achieves
this lower bound asymptotically as α →0.
Recall the non-i.i.d. model from Section 3.06.3.2. When the process evolves in the pre-change regime,
the conditional density of Xn given Xn−1
1
is f0,n(Xn|Xn−1
1
). After the change happens, the conditional
density of Xn given Xn−1
1
is given by f1,n(Xn|Xn−1
1
). Also
Yi = log f1,i
	
Xi|Xi−1
1

f0,i
	
Xi|Xi−1
1

.
The CuSum algorithm can be generalized to the non-i.i.d. setting as follows.
Algorithm 6 (Generalized CuSum algorithm). Let
Cn = max
1≤k≤n
n

i=k
Yi.
Then the stopping time for the generalized CuSum is
τG = inf {n ≥1 : Cn ≥b} .
(6.68)
Then the following result is proved in [10].

3.06.4 Minimax Quickest Change Detection
239
Theorem 13. If there exists a positive constant I such that the {Yi}s satisfy the following condition
lim
t→∞sup
n≥1
ess sup Pn

max
m≤t
n+m

i=n
Yi ≥I(1 + δ)n
 X1, . . . , Xn−1

= 0
∀δ > 0
(6.69)
then, as α →0
inf
τ∈Dα
WADD(τ) ≥inf
τ∈Dα
CADD(τ) ≥| log α|
I
	
1 + o(1)

.
(6.70)
Further
E∞[τG] ≥eb,
and under the additional condition of
lim
t→∞sup
m≥n
ess sup Pn

t−1
m+t

i=m
Yi ≥I −δ
 X1, . . . , Xm−1

= 0
∀δ > 0,
(6.71)
we have
CADD(τG) ≤WADD(τG) ≤b
I
	
1 + o(1)

as b →∞.
Thus, if we set b = | log α|, then
FAR(τG) =
1
E∞[τG] ≤α
and
WADD(τG) ≤| log α|
I
(1 + o(1)),
which is asymptotically equal to the lower bound in (6.70) up to ﬁrst order. Thus τG is ﬁrst-order
asymptotically optimum within the class Dα of tests that meet the FAR constraint of α.
Proof.
We only provide a sketch of the proof for the lower bound since it also based on the idea of
using Chebyshev’s inequality. The fundamental idea of the proof is to use Chebyshev’s inequality to
get a lower bound on any arbitrary stopping time τ from Dα, such that the lower bound is not a function
of τ. The lower bound obtained is then a lower bound on the CADD for the entire family Dα.
Let Lα and Vα be positive constants. To show that
sup
n≥1
En[τ −n|τ ≥n] ≥Lα(1 + o(1)) as α →0
it is enough to show that there exists n such that
En[τ −n|τ ≥n] ≥Lα(1 + o(1)) as α →0.
This n is obtained from the following condition. Let m be any positive integer. Then if τ ∈Dα, there
exists n such that
P∞(τ ≥n) > 0 and P∞(τ < n + m|τ ≥k) ≤mα.
(6.72)

240
CHAPTER 6 Quickest Change Detection
We use the n that satisﬁes the condition (6.72). Then, by Chebyshev’s inequality
Pn(τ −n ≥Lα|τ ≥n) ≤(Lα)−1En[τ −n|τ ≥n].
We can then write
En[τ −n|τ ≥n] ≥Lα Pn(τ −n ≥Lα|τ ≥n).
Now it has to be shown that Pn(τ −n ≥Lα|τ ≥n) →1 uniformly over the family Dα. To show this,
we condition on Vα.
Pn
	
τ −n < Lα|τ ≥n

= Pn

τ −n < Lα;
τ

i=n
Yi < Vα|τ ≥n

+Pn

τ −n < Lα;
τ

i=n
Yi ≥Vα|τ ≥n

.
The trick now is to use the hypothesis of the theorem and choose proper values of Vα and Lα such that
the two terms on the right hand side of the above equations are bounded by terms that go to zero and
are not a function of the stopping time τ. We can write
Pn

τ −n < Lα;
τ

i=n
Yi ≥Vα|τ ≥n

≤ess sup Pn

max
t≤Lα
n+t

i=n
Yi ≥Vα|X1, . . . , Xn−1

.
In [10], it is shown that if we choose
Lα = (1 −δ)| log α|
I
and
Vα = (1 −δ2)| log α|
then the condition (6.69) ensures that the above probability goes to zero. The other term goes to zero
by using a change of measure argument and using condition (6.72):
Pn

τ −n < Lα;
τ

i=n
Yi < Vα|τ ≥n

≤eVαP∞(τ < n + Lα|τ ≥n).
■
3.06.5 Relationship between the models
We have discussed the Bayesian formulation of the quickest change detection problem in Section 3.06.3
and the minimax formulations of the problem in Section 3.06.4. The choice between the Bayesian and the
minimax formulations is obvious, and is governed by the knowledge of the distribution of . However, it
is not obvious which of the two minimax formulations should be chosen for a given application. As noted

3.06.6 Variants and Generalizations of the Quickest Change Detection Problem
241
earlier, the formulations of Lorden and Pollak are equivalent for low FAR constraints, but differences
arise for moderate values of FAR constraints. Recent work by Moustakides [26] has connected these
three formulations and found possible interpretations for each of them. We summarize the result below.
Consider a model in which the change point is dependent on the stochastic process. That is, the
probability that change happens at time n depends on {X1, . . . , Xn}. Let
πn = P( = n|X1, . . . , Xn).
The distribution of  thus belongs to a family of distributions. Assume that while we are trying to ﬁnd
a suitable stopping time τ to minimize delay, an adversary is searching for a process {πn} such that the
delay for any stopping time is maximized. That is the adversary is trying to solve
J(τ) = sup
{πn}
E[τ −|τ ≥].
It is shown in [26] that if the adversary has access to the observation sequence, and uses this information
to choose πn, then J(τ) becomes the delay expression in Lorden’s formulation (6.53) for a given τ, i.e.,
J(τ) = sup
n≥1
ess sup En[(τ −n)+|X1, . . . , Xn−1].
However, if we assume that the adversary does not have access to the observations, but only has access
to the test performance, then J(τ) is equal to the delay in Pollak’s formulation (6.55), i.e.,
J(τ) = sup
n≥1
En[τ −n|τ ≥n].
Finally, the delay for the Shiryaev formulation (6.10) corresponds to the case when πn is restricted to
only one possibility, the distribution of .
3.06.6 Variants and generalizations of the quickest change
detection problem
In the previous sections we reviewed the state-of-the-art for quickest change detection in a single
sequence of random variables, under the assumption of complete knowledge of the pre- and post-
change distributions. In this section we review three important variants and extensions of the classical
quickest change detection problem, where signiﬁcant progress has been made. We discuss other variants
of the change detection problem as part of our future research section.
3.06.6.1 Quickest change detection with unknown pre- or post-change
distributions
In the previous sections we discussed quickest change detection problem when both the pre- and post-
change distributions are completely speciﬁed. Although this assumption is a bit restrictive, it helped
in obtaining recursive algorithms with strong optimality properties in the i.i.d. setting, and allowed the

242
CHAPTER 6 Quickest Change Detection
development of asymptotic optimality theory in a very general non-i.i.d. setting. In this section, we
provide a review of the existing results for the case where this assumption on the knowledge of the pre-
and post-change distributions is relaxed.
Often it is reasonable to assume that the pre-change distribution is known. This is the case when
changes occur rarely and/or the decision maker has opportunities to estimate the pre-change distribution
parameters before the change occurs. When the post-change distribution is unknown but the pre-change
distribution is completely speciﬁed, the post-change uncertainty may be modeled by assuming that
the post-change distribution belongs to a parametric family {Pθ}. Approaches for designing algorithms
in this setting include the generalized likelihood ratio (GLR) based approach or the mixture based
approach. In the GLR based approach, at any time step, all the past observations are used to ﬁrst obtain
a maximum likelihood estimate of the post-change parameter θ, and then the post-change distribution
corresponding to this estimate of θ is used to compute the CuSum, Shiryaev-Roberts or related statistics.
In the mixture based approach, a prior is assumed on the space of parameters, and the statistics (e.g.,
CuSum or Shiryaev-Roberts), computed as a function of the post change parameter, are then integrated
over the assumed prior.
In the i.i.d. setting this problem is studied in [6] for the case when the post-change p.d.f. belongs to a
single parameter exponential family { fθ}, and the following generalized likelihood ratio (GLR) based
algorithm is proposed:
τG = inf

n ≥1 : max
1≤k≤n sup
|θ|≥ϵα
 n

i=k
log fθ(Xi)
f0(Xi)

≥cα

.
(6.73)
If ϵα =
1
| log α|, and cα is of the order of | log α|, then it is shown in [6] that as the FAR constraint α →0,
FAR(τG) ≤α
	
1 + o(1)

,
and for each post-change parameter θ ̸= 0,
WADDθ(τG) ∼
| log α|
D( fθ, f0).
Here, the notation WADDθ[·] is used to denote the WADD when the post-change observations have
p.d.f fθ. Note that
| log α|
D( fθ, f0) is the best one can do asymptotically for a given FAR constraint of α, even
when the exact post-change distribution is known. Thus, this GLR scheme is uniformly asymptotically
optimal with respect to the Lorden’s criterion (6.53).
In [27], the post-change distribution is assumed to belong to an exponential family of p.d.f.s as above,
but the GLR based test is replaced by a mixture based test. Speciﬁcally, a prior G( · ) is assumed on the
range of θ and the following test is proposed:
τM = inf

n ≥1 : max
1≤k≤n

n

i=k
fθ(Xi)
f0(Xi)dG(θ)

≥1
α

.
(6.74)
For the above choice of threshold, it is shown that
FAR(τM) ≤α,

3.06.6 Variants and Generalizations of the Quickest Change Detection Problem
243
and for each post-change parameter θ ̸= 0, if θ is in a set over which G( · ) has a positive density, as
the FAR constraint α →0,
WADDθ[τM] ∼
| log α|
D( fθ, f0).
Thus, even this mixture based test is uniformly asymptotically optimal with respect to the
Lorden’s criterion.
Although the GLR and mixture based tests discussed above are efﬁcient, they do not have an equiv-
alent recursive implementation, as the CuSum test or the Shiryaev-Roberts tests have when the post-
change distribution is known. As a result, to implement the GLR or mixture based tests, we need to use
the entire past information (X1, . . . , Xn), which grows with n. In [10], asymptotically optimal sliding-
window based GLR and mixtures tests are proposed, that only used a ﬁnite number of past observations.
The window size has to be chosen carefully and is a function of the FAR. Moreover, the results here are
valid even for the non-i.i.d. setting discussed earlier in Section 3.06.4.3. Recall the non-i.i.d. model from
Section 3.06.3.2, with the prechange conditional p.d.f. given by f0,n(Xn|Xn−1
1
), and the post-change
conditional p.d.f. given by f1,n(Xn|Xn−1
1
). Then the generalized CuSum (6.68) GLR and mixture based
algorithms are given, respectively, by:
ˆτG = inf

n ≥1 :
max
n−mα≤k≤n−m′α
sup
θ
 n

i=k
log fθ,i
	
Xi|Xi−1
1

f0,i
	
Xi|Xi−1
1


≥cα

(6.75)
and
ˆτM = inf

n ≥1 :
max
n−mα≤k≤n

n

i=k
fθ,i
	
Xi|Xi−1
1

f0,i
	
Xi|Xi−1
1

dG(θ)

≥ecα

.
(6.76)
It is shown that for a suitable choice of cα, mα and m′
α, under some conditions on the likelihood ratios
and on the distribution G, both of these tests satisfy the FAR constraint of α. In particular,
FAR(ˆτM) ≤α
and as α →0,
FAR(ˆτG) ≤α
	
1 + o(1)

.
Moreover, under some conditions on the post-change parameter θ,
WADDθ[ˆτG] ∼WADDθ[ˆτM] ∼
| log α|
D( fθ, f0).
Thus, under the conditions stated, the above window-limited tests are also asymptotically optimal. We
remark that, although ﬁnite window based tests are useful for the i.i.d. setting here, we still need to store
the entire history of observations in the non-i.i.d. setting to compute the conditional densities, unless
the dependence is ﬁnite order Markov. See [10,28] for details.
To detect a change in mean of a sequence of Gaussian observations in an i.i.d. setting, i.e., when
f0 ∼N(0, 1) and f1 ∼N(μ, 1), μ ̸= 0, the GLR rule discussed above (6.75) (with mα = n and
m′
α = 1) reduces to
τv = inf

n ≥1 : max
0≤k<n
 n

i=k
|Sn −Sn|
√(n −k)

≥b

.
(6.77)

244
CHAPTER 6 Quickest Change Detection
This test is studied in [29] and performance of the test, i.e., expressions for FAR(τv) and E1[τv] are
obtained. In [28], it is shown that a window-limited modiﬁcation of the above scheme (6.77) can also
be designed.
When both pre- and post-change distributions are not known, again GLR based or mixture based
tests have been studied and asymptotic properties characterized. In [30], this problem has been studied
in the i.i.d setting (Bayesian and non-Bayesian), when both pre- and post-change distributions belong
to an exponential family. For the Bayesian setting, the change point is assumed to be geometric and
there are priors (again from an exponential family) on both the pre- and post-change parameters. GLR
and mixture based tests are proposed that have asymptotic optimality properties. For a survey of other
algorithms when both the pre- and post-change distributions are not known, see [28].
In [31], rather than developing procedures that are uniformly asymptotically optimal for each possible
post-change distribution, robust tests are characterized when the pre- and post-change distributions
belong to some uncertainty classes. The objective is to ﬁnd a stopping time that satisﬁes a given false
alarm constraint (probability of false alarm or the FAR depending on the formulation) for each possible
pre-change distribution, and minimizes the detection delay (Shiryaev, Lorden or the Pollak version)
supremized over each possible pair of pre- and post-change distributions. It is shown that under some
conditions on the uncertainty classes, the least favorable distribution from each class can be obtained,
and the robust test is the classical test designed according to the lease favorable distribution pair. It is
shown in [31] that although robust test is not uniformly asymptotically optimal, it can be signiﬁcantly
better than the GLR based test of [6] for some parameter ranges and for moderate values of FAR. The
robust solution also has the added advantage that it can be implemented in a simple recursive manner,
while the GLR test does not admit a recursive solution in general, and may require the solution to a
complex nonconvex optimization problem at every time instant.
3.06.6.2 Data-efﬁcient quickest change detection
In the classical problem of quickest change detection that we discussed in Section 3.06.3, a change in
the distribution of a sequence of random variables has to be detected as soon as possible, subject to a
constraint on the probability of false alarm. Based on the past information, the decision maker has to
decide whether to stop and declare change or to continue acquiring more information. In many engi-
neering applications of quickest change detection there is a cost associated with acquiring information
or taking observations, e.g., cost associated with taking measurements, or cost of batteries in sensor
networks, etc. (see [32] for a detailed motivation and related references). In [32], Shiryaev’s formulation
(Section 3.06.3) is extended by including an additional constraint on the cost of observations used in the
detection process. The observation cost is captured through the average number of observations used
before the change point, with the understanding that the cost of observations after the change point is
included in the delay metric.
In order to minimize the average number of observations used before , at each time instant, a
decision is made on whether to use the observation in the next time step, based on all the available
information. Let Sn ∈{0, 1}, with Sn = 1 if it is been decided to take the observation at time n, i.e.,
Xn is available for decision making, and Sn = 0 otherwise. Thus, Sn is an on-off (binary) control input
based on the information available up to time k −1, i.e.,
Sn = μk−1(Ik−1),
k = 1, 2, . . .

3.06.6 Variants and Generalizations of the Quickest Change Detection Problem
245
with μ denoting the control law and I deﬁned as:
In =

S1, . . . , Sn, X(S1)
1
, . . . , X(Sn)
n

.
Here, X(Si)
i
represents Xi if Si = 1, otherwise Xi is absent from the information vector In.
Let ψ = {τ, μ0, . . . , μτ−1} represent a policy for data-efﬁcient quickest change detection, where
τ is a stopping time on the information sequence {In}. The objective in [32] is to solve the following
optimization problem:
minimize
ψ
ADD(ψ) = E

(τ −)+
(6.78)
subject to PFA(ψ) = P(τ < ) ≤α,
and ANO(ψ) = E
⎡
⎣
min (τ,−1)

k=1
Sn
⎤
⎦≤β.
Here, ADD, PFA and ANO stand for average detection delay, probability of false alarm and average
number of observations used, respectively, and α and β are given constraints.
Deﬁne,
pn = P( ≤k|In).
Then, the two-threshold algorithm from [32] is:
Algorithm 7 (DE-Shiryaev: ψ(A, B)). Start with p0 = 0 and use the following control, with B < A,
for k ≥0:
Sk+1 = μn(pn) =
0 if
pn < B,
1 if
pn ≥B,
τ = inf {k ≥1 : pn > A} .
(6.79)
The probability pn is updated using the following recursions:
pk+1 =
⎧
⎨
⎩
˜pn = pn + (1 −pn)ρ if Sk+1 = 0,
˜pnL(Xk+1)
˜pnL(Xk+1) + (1 −˜pn) if Sk+1 = 1
with L(Xk+1) = f1(Xk+1)/ f0(Xk+1).
With B = 0 the DE-Shiryaev algorithm reduces to the Shiryaev algorithm. When the DE-Shiryaev
algorithm is employed, the a posteriori probability pn typically evolves as depicted in Figure 6.6a. It is
shown in [32] that for a ﬁxed β, as α →0:
ADD(ψ(A, B)) ∼
| log (α)|
D( f1, f0) + | log (1 −ρ)| as α →0
(6.80)
and
PFA(ψ(A, B)) ∼α
 ∞
0
e−xd R(x)

as α →0.
(6.81)

246
CHAPTER 6 Quickest Change Detection
0
10
20
30
40
50
60
70
80
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Γ
τ
Pk
B
A
(a)
4
5
6
7
8
9
10
11
20
30
40
50
60
70
80
f 0= N(0,1)  f1= N(0.75,1 )  ρ= 0.01  50% samples dropped
FS scheme
DE−Shiryaev
Shiryaev
−log (PFA)
ADD
(b)
FIGURE 6.6
Evolution and performance of the DE-Shiryaev algorithm. (a) Evolution of pn for f0 ∼N(0,1), f1 ∼N (0.5,1),
and ρ = 1.01, with thresholds A = 0.65 and B = 0.2. (b) Trade-off curves comparing performance of the
DE-Shiryaev algorithm with the Fractional Sampling scheme when B is chosen to achieve ANO equal to 50%
of mean time to change. Also f0 ∼N (0,1), f1 ∼N(0.75,1), and ρ = 0.01.
Here, R(x)istheasymptoticovershootdistributionoftherandomwalkn
k=1[log L(Xk)+| log (1−ρ)|],
when it crosses a large positive boundary. It is shown in [12] that these are also the performance
expressions for the Shiryaev algorithm. Thus, the PFA and ADD of the DE-Shiryaev algorithm approach
that of the Shiryaev algorithm as α →0, i.e., the DE-Shiryaev algorithm is asymptotically optimal.
The DE-Shiryaev algorithm is also shown to have good delay-observation cost trade-off curves: for
moderate values of probability of false alarm, for Gaussian observations, the delay of the algorithm
is within 10% of the Shiryaev delay even when the observation cost is reduced by more than 50%.
Furthermore, the DE-Shiryaev algorithm is substantially better than the standard approach of fractional
sampling scheme, where the Shiryaev algorithm is used and where the observations to be skipped are
determined a priori in order to meet the observation constraint (see Figure 6.6b).
In most practical applications, prior information about the distribution of the change point is not
available. As a result, the Bayesian solution is not directly applicable. For the classical quickest change
detection problem, an algorithm for the non-Bayesian setting was obtained by taking the geometric
parameter of the prior on the change point to zero (see Section 3.06.4.1). Such a technique cannot be
used in the data-efﬁcient setting. This is because when an observation is skipped in the DE-Shiryaev
algorithm in [32], the a posteriori probability is updated using the geometric prior. In the absence of
prior information about the distribution of the change point, it is by no means obvious what the right
substitute for the prior is. A useful way to capture the cost of observations in a minimax setting is also
needed.
In [33], the minimax formulation of [9] is used to propose a minimax formulation for data-efﬁcient
quickest change detection. We observe that in the two-threshold algorithm ψ(A, B), when the change
occursatafarhorizon,itisthefractionofobservationstakenbeforechangethatiscontrolled.Thisinsight

3.06.6 Variants and Generalizations of the Quickest Change Detection Problem
247
is used to formulate a duty cycle based metric to capture the cost of taking observations before the change
point. Also, we note that the duration for which observations are not taken in the algorithm in [32], is
also a function of the undershoot of the a posteriori probability when it goes below the threshold B.
Given the fact that
pn
1−pn for the DE-Shiryaev algorithm, has the interpretation of the likelihood ratio
of the hypotheses “H1 :  ≤n” and “H0 :  > n,” the undershoots essentially carry the information
on the likelihood ratio. It is shown in [33] that this insight can be used to design a good test in the
non-Bayesian setting. This algorithm is called the DE-CuSum algorithm and it is shown that it inherits
good properties of the DE-Shiryaev algorithm. The DE-CuSum algorithm is also asymptotically optimal
in a sense similar to (6.80) and (6.81), has good trade-off curves, and performs signiﬁcantly better than
the standard approach of fractional sampling.
3.06.6.3 Distributed sensor systems
In the previous sections, we provided a summary of existing work on quickest change detection
and classiﬁcation in the single sensor (equivalently, centralized multisensor) setting. For the prob-
lem of detecting biological and chemical agents, the setting that is more relevant is one where there
is a set of distributed sensors collecting the data relevant for detection, as shown in Figure 6.7.
Based on the observations that the sensors receive, they send messages (which could be local deci-
sions, but not necessarily) to a fusion center where a ﬁnal decision about the hypothesis or change
is made.
Since the information available for detection is distributed across the sensors in the network, these
detection problems fall under the umbrella of distributed (or decentralized) detection, except in the
impractical setting where all the information available at the sensors is immediately available without
any errors at the fusion center. Such decentralized decision making problems are extremely difﬁcult.
Fusion Center
Channel
Change 
Decision 
Event
Un
1
Xn
L
Xn
1
Un
L
S1
S2
SL
SL 1
FIGURE 6.7
Change detection using distributed sensors.

248
CHAPTER 6 Quickest Change Detection
Withoutcertainconditionalindependenceassumptionsacrosssensors,theproblemofﬁndingtheoptimal
solutions, even in the simplest case of static binary hypothesis testing, is computationally intractable
[34–39]. Decentralized dynamic decision making problems, of which the quickest change detection
problem is a special case, are even more challenging due to the fact that information pattern in
these problems is non-classical, i.e., the different decision makers have access to different pieces of
information [40].
The problem of decentralized quickest change detection in distributed sensor systems was introduced
in [41], and is described as follows. Consider the distributed multisensor system with L sensors, com-
municating with a fusion center shown in Figure 6.7. At time n, an observation Xℓ
n is made at sensor Sℓ.
The changes in the statistics of the sequences {Xℓ
n} are governed by the event. Based on the information
available at time n, a message Uℓ
n is sent from sensor Sℓto the fusion center. The fusion center may
possibly feedback some control signals to the sensors based on all the messages it has received so far.
For example, the fusion center might inform the sensors how to update their local decision thresholds.
The ﬁnal decision about the change is made at the fusion center.
There are two main approaches to generating the messages at the sensors. In the ﬁrst approach, the
sensors can be thought of simply quantizing their observations, i.e., Uℓ
n is simply a quantized version of
Xℓ
n. The goal then is to choose these quantizers over time and across the sensors, along with a decision
rule at the fusion center, to provide the best tradeoff between detection delay and false alarms. In the
second approach, the sensors perform local change detection, using all of their observations, and the
fusion center combines these decisions to make the ﬁnal decision about the change.
The simplest observation model for the decentralized setting is one where the sensors are affected
by the change at the same time, and the observations are i.i.d. in time at each sensor and independent
across sensors in both the pre-change and post-change modes. This model was introduced in [41], and
studied in a Bayesian setting with a geometric prior on the change point for the case of quantization
at the sensors. It was shown that, unlike the centralized problem for which the Shiryaev test is optimal
(see Section 3.06.3), in the decentralized setting the optimization problem is intractable in even for this
simple observation model. Some progress can be made if we allow for feedback from the fusion center
[41]. Useful results can be obtained in the asymptotic setting where the probability of false (Bayesian
formulation) or false alarm rate (minimax formulation) go to zero. These results can be summarized as
follows (see, e.g., [12,42,43] for more details):
•
It is asymptotically optimum for the sensors to use stationary monotone likelihood ratio quantiz-
ers, i.e., the sensors use the same quantization functions at all times, and the quantization regions
are obtained by dividing the likelihood ratio of the observations into intervals and assigning the
quantization levels to them in increasing order.
•
The optimum quantization thresholds at the sensors are chosen to maximize the K-L divergence
between the post-change and pre-change distributions at the sensors.
•
For ﬁxed stationary quantizers at the sensors, the fusion center is faced with a centralized quickest
change detection problem. Therefore, depending on the optimization criterion (Bayes or minimax),
asymptotically optimum change detection procedures can be designed using the techniques described
in Sections 3.06.3 and 3.06.4
•
The tradeoff between delay and false alarms is governed by the K-L divergence of the quantized
observations at the output of the sensors, and hence the ﬁrst order asymptotic performance with
quantization is at best equal to that without quantization.

3.06.6 Variants and Generalizations of the Quickest Change Detection Problem
249
For the case where the sensors make local decisions about the change, it is reasonable to assume
that the local detection procedures use (asymptotically) optimum centralized (single sensor) statistics.
For example, in the Bayesian setting, the Shiryaev statistic described in Algorithm 1 can be used, and
in the minimax setting one of the statistics described in Section 3.06.4.1 can be used depending on the
speciﬁc minimax criterion used. The more interesting aspect of the decision-making here is the fusion
rule used to combine the individual sensor decisions. There are three main basic options that can be
considered [43]:
•
τmin: the fusion center stops and declares the change as soon as one of the sensors’ statistics crosses
its decision threshold.
•
τmax: the sensors stop taking observations once their local statistics cross their thresholds, and the
fusion center stops and declares the change after all sensors have stopped.
•
τall: the sensors continue taking observations even if their local statistics cross their thresholds, and
the fusion center stops and declares the change after all the sensor statistics are above their local
thresholds simultaneously.
It was ﬁrst shown by [44] that the τall procedure using CuSum statistics at the sensors is globally
ﬁrst order asymptotically optimal under Lorden’s criterion (6.53) if the sensor thresholds are chose
appropriately. That is, the ﬁrst order performance is the same as that of the centralized procedure that
has access to all the sensor observations. A more detailed analysis of minimax setting was carried out
in [45], in which procedures based on using CuSum and Shiryaev-Roberts statistics at the sensors were
studied under Pollak’s criterion (6.55). It was again shown that τall is globally ﬁrst order asymptotically
optimal, and that τmax and τmin are not.
For the Bayesian case, if the sensors use Shiryaev statistics, then both τmax and τall can be shown to
be globally ﬁrst order asymptotically optimal, with an appropriate choice of sensor thresholds [43,46].
The procedure τmin does not share this asymptotic optimality property.
Interestingly, while tests based on local decision making at the sensors can be shown to have the
same ﬁrst order performance as that of the centralized test, simulations reveal that these asymptotics
“kick in” at unreasonably low values of false alarm probability (rate). In particular, even schemes based
on binary quantization at the sensors can perform better than the globally asymptotically optimum local
decision based tests at moderate values of false alarm probability (rate) [43]. These results point to
the need for further research on designing procedures that perform local detection at the sensors that
provide good performance at moderate levels of false alarms.
3.06.6.4 Variants of quickest change detection problem for distributed
sensor systems
InSection3.06.6.3,itisassumedforthedecentralizedquickestchangedetectionproblem,thatthechange
affects all the sensors in the system simultaneously. In many practical systems it is reasonable to assume
that the change will be seen by only a subset of the sensors. This problem can be modeled as quickest
change detection with unknown post-change distribution, with a ﬁnite number of possibilities. A GLRT
based approached can of course be used, in which multiple CuSum tests are run in parallel, corresponding
to each possible post-change hypotheses. But this can be quite expensive from an implementation view
point. In [47], a CuSum based algorithm is proposed in which, at each sensor a CuSum test is employed,

250
CHAPTER 6 Quickest Change Detection
the CuSum statistic is transmitted from the sensors to the fusion center, and at the fusion center, the
CuSum statistics from all the sensors are added and compared with a threshold. This test has much lower
computational complexity as compared to the GLR based test, and is shown to be asymptotically as good
as the centralized CuSum test, as the FAR goes to zero. Although this test is asymptotically optimal, the
noise from the sensors not affected by change can degrade the performance for moderate values of false
alarm rate. In [48], this work of [47], is extended to the case where information is transmitted from the
sensors only when the CuSum statistic at each sensor is above a certain threshold. It is shown that this
has the surprising effect of suppressing the unwanted noise and improving the performance. In [49], it
is proposed that a soft-thresholding function should be used to suppress these noise terms, and a GLRT
based algorithm is proposed to detect presence of a stationary intruder (with unknown position) in a
sensor network with Gaussian observations. A similar formulation is described in [50].
The Bayesian decentralized quickest change detection problem under an additional constraint on the
cost of observations used is studied in [51]. The cost of observations is captured through the average
number of observations used until the stopping time and it is shown that a threshold test similar to the
Shiryaev algorithm is optimal. Recently, this problem has been studied in a minimax setting in [52]
and asymptotically minimax algorithms have been proposed. Also, see [53,54] for other interesting
energy-efﬁcient algorithms for quickest change detection in sensor networks.
3.06.7 Applications of quickest change detection
As mentioned in the introduction, the problem of quickest change detection has a variety of applications.
A complete list of references to applications of quickest change detection can be quite overwhelming
and therefore we only provide representative references from some of the areas. For a detailed list
of references to application in areas such as climate modeling, econometrics, environment and public
health, ﬁnance, image analysis, navigation, remote sensing, etc., see [13,55].
1. Statistical process control (SPC): As discussed in the introduction, algorithms are required that
can detect a sudden fault arising in an industrial process or a production process. In recent years
algorithms for SPC with sampling rate and sampling size control have also been developed to
minimize the cost associated with sampling [56,57]. See [58,59] and the references therein for
some recent contributions.
2. Sensor networks: As discussed in [32], quickest change detection algorithms can be employed in
sensor networks for infrastructure monitoring [60], or for habitat monitoring [61]. Note that in these
applications, the sensors are deployed for a long time, and the change may occur rarely. Therefore,
data-efﬁcient quickest change detection algorithms are needed (see Section 3.06.6.2).
3. Computer network security: Algorithms for quickest change detection have been applied in the
detection of abnormal behavior in computer networks due to security breaches [62–64].
4. Cognitive radio: Algorithms based on the CuSum algorithm or other quickest change detection
algorithms can be developed for cooperative spectrum sensing in cognitive radio networks to detect
activity of a primary user. See [53,65–67].
5. Neuroscience: The evolution of the Shiryaev algorithm is found to be similar to the dynamics of the
Leaky Integrate-and-Fire model for neurons [68].

3.06.8 Conclusions and Future Directions
251
6. Social networks: It is suggested in [69,70] that the algorithms from the change detection literature
can be employed to detect the onset of the outbreak of a disease, or the effect of a bioterroist attack,
by monitoring drug sales at retail stores.
3.06.8 Conclusions and future directions
In this article we reviewed the state-of-the-art in the theory of quickest change detection. We saw that
while exactly or nearly optimal algorithms are available only for the i.i.d. model and for the detection of a
changeinasinglesequenceofobservations,asymptoticallyoptimalalgorithmscanbeobtainedinamuch
broader setting. We discussed the uniform asymptotic optimality of GLR and mixture based tests, when
the post-change distribution is not known. We discussed algorithms for data-efﬁcient quickest change
detection, and showed that they are also asymptotically equivalent to their classical counterparts. For the
decentralized quickest change detection model, we discussed various algorithms that are asymptotically
optimal. We also reviewed the asymptotic optimality theory in the Bayesian as well as in the minimax
setting for a general non-i.i.d. model, and showed that extensions of the Shiryaev algorithm and the
CuSum algorithm to the non-i.i.d. setting are asymptotically optimal. Nevertheless, the list of topics
discussed in this article is far from exhaustive.
Below we enumerate possible future directions in which the quickest change detection problem can
be explored. We also provide references to some recent articles in which some research on these topics
has been initiated.
1. Transient change detection: It is assumed throughput this article that the change is persistent, i.e.,
once the change occurs, the system stays in the post-change state forever. In many applications it
might be more appropriate to model change as transient, i.e., the system only stays in the post-change
state for a ﬁnite duration and then returns to the pre-change state; see e.g., [71–73]. In this setting,
in addition to false alarm and delay metrics, it may be of interest to consider metrics related to the
detection of the change while the system is still in the change state.
2. Change propagation: In applications with multiple sensors, unlike the model assumed in
Section 3.06.6.3, it may happen that the change does not affect all the sensors simultaneously
[74]. The change may propagate from one sensor to the next, with the statistics of the propagation
process being known before hand [75].
3. Multiple change points in networks: In some monitoring application there may be multiple change
points that affect different sensors in a network, and the goal is to exploit the relationship between
the change points and the sensors affected to detect the changes [76].
4. Quickest change detection with social learning: In the classical quickest change detection problem,
tocomputethestatisticateachtimestep,thedecisionmakerhasaccesstotheentirepastobservations.
An interesting variant of the problem is quickest change detection with social learning, when the
time index is replaced by an agent index, i.e., when the statistic is updated over agents and not over
time, and the agents do not have access to the entire past history of observations but only to some
processed version (e.g., binary decisions) from the previous agent; see [77–79].
5. Change detection with simultaneous classiﬁcation: In many applications, the post-change distri-
bution is not uniquely speciﬁed and may come from one of multiple hypotheses H1, . . . , HM,

252
CHAPTER 6 Quickest Change Detection
in which case along with detecting the change it of interest to identify which hypothesis is true.
See, e.g., [80,81].
6. Synchronization issues: If a quickest change detection algorithm is implemented in a sensor network
where sensors communicate with the fusion center using a MAC protocol, the fusion center might
receive asynchronous information from the sensors due to networking delays. It is of interest to
develop algorithms that can detect changes while handling MAC layer issues; see, e.g., [50].
Acknowledgments
The authors would like to thank Prof. Abdelhak Zoubir for useful suggestions, and Mr. Michael Fauss and Mr. Shang
Kee Ting for their detailed reviews of an early draft of this work. The authors would also like to acknowledge the
support of the National Science Foundation under Grants CCF 0830169 and CCF 1111342, through the University
of Illinois at Urbana-Champaign, and the U.S. Defense Threat Reduction Agency through subcontract 147755 at
the University of Illinois from prime award HDTRA1-10-1-0086.
Relevant Theory: Signal Processing Theory, and Machine Learning, Statistical Signal Processing
See Vol. 1, Chapter 11 Parametric Estimation
See Vol. 1, Chapter 12 Adaptive Filters
See Vol. 1, Chapter 18 Introduction to Probabilistic Graphical Models
See this Volume, Chapter 5 Distributed Signal Detection
References
[1] W.A. Shewhart, The application of statistics as an aid in maintaining quality of a manufactured product, J. Am.
Stat. Assoc. 20 (1925) 546–548.
[2] W.A. Shewhart, Economic Control of Quality of Manufactured Product, American Society for Quality Control,
1931.
[3] E.S. Page, Continuous inspection schemes, Biometrika 41 (1954) 100–115.
[4] A.N. Shiryaev, On optimum methods in quickest detection problems, Theory Probab. Appl. 8 (1963) 22–46.
[5] A.N. Shiryayev, Optimal Stopping Rules, Springer-Verlag, New York, 1978.
[6] G. Lorden, Procedures for reacting to a change in distribution, Ann. Math. Stat. 42 (1971) 1897–1908.
[7] G.V. Moustakides, Optimal stopping times for detecting changes in distributions, Ann. Stat. 14 (1986)
1379–1387.
[8] Y. Ritov, Decision theoretic optimality of the CUSUM procedure, Ann. Stat. 18 (1990) 1464–1469.
[9] M. Pollak, Optimal detection of a change in distribution, Ann. Stat. 13 (1985) 206–227.
[10] T.L. Lai, Information bounds and quick detection of parameter changes in stochastic systems, IEEE Trans.
Inf. Theory 44 (1998) 2917–2929.
[11] A. Polunchenko, A.G. Tartakovsky, State-of-the-art in sequential change-point detection, Methodol. Comput.
Appl. Probab. (2011) 1–36.
[12] A.G. Tartakovsky, V.V. Veeravalli, General asymptotic Bayesian theory of quickest change detection, SIAM
Theory Probab. Appl. 49 (2005) 458–497.
[13] H.V. Poor, O. Hadjiliadis, Quickest Detection, Cambridge University Press, 2009.
[14] Y.S. Chow, H. Robbins, D. Siegmund, Great Expectations: The Theory of Optimal Stopping, Houghton Mifﬂin,
1971.

References
253
[15] A.G. Tartakovsky, I.V. Nikiforov, M. Basseville, Sequential Analysis: Hypothesis Testing and Change-Point
Detection, Statistics, CRC Press, 2013.
[16] D. Williams, Probability with Martingales, Cambridge Mathematical Textbooks, Cambridge University Press,
1991.
[17] D. Siegmund, Sequential Analysis: Tests and Conﬁdence Intervals, Springer Series in Statistics, Springer-
Verlag, 1985.
[18] M. Woodroofe, Nonlinear Renewal Theory in Sequential Analysis, CBMS-NSF Regional Conference Series
in Applied Mathematics, SIAM, 1982.
[19] D. Bertsekas, Dynamic Programming and Optimal Control, vols. I and II, Athena Scientiﬁc, Belmont,
Massachusetts, 1995.
[20] A.G. Tartakovsky, M. Pollak, A. Polunchenko, Third-order asymptotic optimality of the generalized Shiryaev-
Roberts changepoint detection procedures, May, 2010, arXiv e-prints.
[21] S.W. Roberts, A comparison of some control chart procedures, Technometrics 8 (1966) 411–430.
[22] M. Pollak, A.G. Tartakovsky, Optimality properties of the Shiryaev-Roberts procedure, Stat. Sinica 19 (2009)
1729–1739.
[23] G.V. Moustakides, A.S. Polunchenko, A.G. Tartakovsky, A numerical approach to performance analysis of
quickest change-point detection procedures, Stat. Sinica 21 (2011) 571–596.
[24] M. Pollak, Average run lengths of an optimal method of detecting a change in distribution, Ann. Stat. 15
(1987) 749–779.
[25] A. Wald, J. Wolfowitz, Optimum character of the sequential probability ratio test, Ann. Math. Stat. 19 (3)
(1948) 326–339.
[26] G.V. Moustakides, Sequential change detection revisited, Ann. Stat. 36 (2008) 787–807.
[27] M. Pollak, D. Siegmund, Approximations to the expected sample size of certain sequential tests, Ann. Stat. 3
(1975) 1267–1282.
[28] T.L. Lai, Sequential changepoint detection in quality control and dynamical systems, J. Roy. Stat. Soc. Suppl.
57 (4) (1995) 613–658.
[29] D. Siegmund, E.S. Venkatraman, Using the generalized likelihood ratio statistic for sequential detection of a
change-point, Ann. Stat. 23 (1995) 255–271.
[30] T.L. Lai, H. Xing, Sequential change-point detection when the pre- and post-change parameters are unknown,
Sequent. Anal. 29 (2010) 162–175.
[31] J. Unnikrishnan, V.V. Veeravalli, S.P. Meyn, Minimax robust quickest change detection, IEEE Trans. Inf.
Theory 57 (2011) 1604–1614.
[32] T. Banerjee, V.V. Veeravalli, Data-efﬁcient quickest change detection with on-off observation control, Sequent.
Anal. 31 (2012) 40–77.
[33] T. Banerjee, V.V. Veeravalli, Data-efﬁcient minimax quickest change detection, in: IEEE Conference on
Acoustics, Speech, and Signal Processing (ICASSP), March 2012, pp. 3937–3940.
[34] J.N. Tsitsiklis, Decentralized detection, in: H.V. Poor, J.B. Thomas (Eds.), Advances in Statistical Signal
Processing, vol. 2, JAI Press, Greenwich, CT, 1993.
[35] P.K. Varshney, Distributed Detection and Data Fusion, Springer-Verlag, New York, 1996.
[36] P. Willett, P.F. Swaszek, R.S. Blum, The good, bad and ugly: distributed detection of a known signal in
dependent Gaussian noise, IEEE Trans. Signal Process. 48 (2000) 3266–3279.
[37] J.F. Chamberland, V.V. Veeravalli, Decentralized detection in sensor networks, IEEE Trans. Signal Process.
51 (2003) 407–416.
[38] J.-F.Chamberland,V.V.Veeravalli,Wirelesssensorsindistributeddetectionapplications,IEEESignalProcess.
Mag. 24 (2007) 16–25 (special issue on Resource-Constrained Signal Processing, Communications, and
Networking).

254
CHAPTER 6 Quickest Change Detection
[39] V.V. Veeravalli, P.K. Varshney, Distributed inference in wireless sensor networks, Philos. Trans. R. Soc. A:
Math. Phys. Eng. Sci. 370 (2012) 100–117.
[40] Y. Ho, Team decision theory and information structures, Proc. IEEE 68 (1980) 644–654.
[41] V.V. Veeravalli, Decentralized quickest change detection, IEEE Trans. Inf. Theory 47 (2001) 1657–1665.
[42] A.G. Tartakovsky, V.V. Veeravalli, Change-point detection in multichannel and distributed systems, in:
N. Mukhopadhyay, S. Datta, S. Chattopadhyay (Eds.), Applied Sequential Methodologies: Real-World Exam-
ples with Data Analysis, Statistics: A Series of Textbooks and Monographs, vol. 173, Marcel Dekker, Inc.,
New York, USA, 2004, pp. 339–370.
[43] A.G. Tartakovsky, V.V. Veeravalli, Asymptotically optimal quickest change detection in distributed sensor
systems, Sequent. Anal. 27 (2008) 441–475.
[44] Y. Mei, Information bounds and quickest change detection in decentralized decision systems, IEEE Trans.
Inf. Theory 51 (2005) 2669–2681.
[45] A.G. Tartakovsky, H. Kim, Performance of certain decentralized distributed change detection procedures, in:
IEEE International Conference on Information Fusion, Florence, Italy, July 2006, pp. 1–8.
[46] A.G. Tartakovsky, V.V. Veeravalli, Quickest change detection in distributed sensor systems, in: IEEE Interna-
tional Conference on Information Fusion, Cairns, Australia, July 2003, pp. 756–763.
[47] Y. Mei, Efﬁcient scalable schemes for monitoring a large number of data streams, Biometrika 97 (2010)
419–433.
[48] Y. Mei, Quickest detection in censoring sensor networks, in: IEEE International Symposium on Information
Theory (ISIT), August 2011, pp. 2148–2152.
[49] Y. Xie, D. Siegmund, Multi-sensor change-point detection, in: Joint Statistical Meetings, August 2011.
[50] K. Premkumar, A. Kumar, J. Kuri, Distributed detection and localization of events in large ad hoc wire-
less sensor networks, in: Allerton Conference on Communication, Control, and Computing, October 2009,
pp. 178–185.
[51] K. Premkumar, A. Kumar, Optimal sleep-wake scheduling for quickest intrusion detection using wire-
less sensor networks, in: IEEE Conference on Computer Communications (INFOCOM), April 2008,
pp. 1400–1408.
[52] T. Banerjee, V.V. Veeravalli, Energy-efﬁcient quickest change detection in sensor networks, in: IEEE Statistical
Signal Processing Workshop, August 2012.
[53] T. Banerjee, V. Sharma, V. Kavitha, A.K. JayaPrakasam, Generalized analysis of a distributed energy efﬁcient
algorithm for change detection, IEEE Trans. Wireless Commun. 10 (2011) 91–101.
[54] L. Zacharias, R. Sundaresan, Decentralized sequential change detection using physical layer fusion, IEEE
Trans. Wireless Commun. 7 (2008) 4999–5008.
[55] M.Basseville,I.V.Nikiforov,DetectionofAbruptChanges:TheoryandApplication,PrenticeHall,Englewood
Cliffs, NJ, 1993.
[56] G. Tagaras, A survey of recent developments in the design of adaptive control charts, J. Qual. Technol. 30
(1998) 212–231.
[57] Z.G. Stoumbos, M.R. Reynolds, T.P. Ryan, W.H. Woodall, The state of statistical process control as we proceed
into the 21st century, J. Am. Stat. Assoc. 95 (2000) 992–998.
[58] Z.G. Stoumbos, M.R. Reynolds, Economic statistical design of adaptive control schemes for monitoring the
mean and variance: an application to analyzers, Nonlinear Anal. Real World Appl. 6 (2005) 817–844.
[59] V. Makis, Multivariate bayesian control chart, Oper. Res. 56 (2008) 487–496.
[60] J.A. Rice, K. Mechitov, S. Sim, T. Nagayama, S. Jang, R. Kim, B.F. Spencer, G. Agha, Y. Fujino, Flexible smart
sensor framework for autonomous structural health monitoring, Smart Struct. Syst. 6 (5–6) (2010) 423–438.
[61] A. Mainwaring, D. Culler, J. Polastre, R. Szewczyk, J. Anderson, Wireless sensor networks for habitat monitor-
ing, in: Proceedings of the 1st ACM International Workshop on Wireless Sensor Networks and Applications,
WSNA ’02, New York, NY, USA, ACM, September 2002, pp. 88–97.

References
255
[62] M. Thottan, C. Ji, Anomaly detection in IP networks, IEEE Trans. Signal Process. 51 (2003) 2191–2204.
[63] A.G. Tartakovsky, B.L. Rozovskii, R.B. Blazek, H. Kim, A novel approach to detection of intrusions in
computer networks via adaptive sequential and batch-sequential change-point detection methods, IEEE Trans.
Signal Process. 54 (2006) 3372–3382.
[64] A.A. Cardenas, S. Radosavac, J.S. Baras, Evaluation of detection algorithms for MAC layer misbehavior:
theory and experiments, IEEE/ACM Trans. Network. 17 (2009) 605–617.
[65] L. Lai, Y. Fan, H.V. Poor, Quickest detection in cognitive radio: A sequential change detection framework,
in: IEEE GLOBECOM, December 2008, pp. 1–5.
[66] A.K. Jayaprakasam, V. Sharma, Cooperative robust sequential detection algorithms for spectrum sensing in
cognitive radio, in: International Conference on Ultramodern Telecommunications (ICUMT), October 2009,
pp. 1–8.
[67] A.K. Jayaprakasam, V. Sharma, Sequential detection based cooperative spectrum sensing algorithms in cogni-
tive radio, in: First UK-India International Workshop on Cognitive Wireless Systems (UKIWCWS), December
2009, pp. 1–6.
[68] A.J. Yu, Optimal change-detection and spiking neurons, in: B. Schölkopf, J. Platt, T. Hoffman (Eds.), Advances
in Neural Information Processing Systems, vol. 19, MIT Press, Cambridge, MA, 2007, pp. 1545–1552.
[69] M. Frisen, Optimal sequential surveillance for ﬁnance, public health, and other areas, Sequent. Anal. 28 (2009)
310–337.
[70] S.E. Fienberg, G. Shmueli, Statistical issues and challenges associated with rapid detection of bio-terrorist
attacks, Stat. Med. 24 (2005) 513–529.
[71] C. Han, P.K. Willett, D.A. Abraham, Some methods to evaluate the performance of Page’s test as used to
detect transient signals, IEEE Trans. Signal Process. 47 (1999) 2112–2127.
[72] Z. Wang, P.K. Willett, A performance study of some transient detectors, IEEE Trans. Signal Process. 48 (2000)
2682–2685.
[73] K. Premkumar, A. Kumar, V.V. Veeravalli, Bayesian quickest transient change detection, in: International
Workshop on Applied Probability (IWAP), July 2010.
[74] O. Hadjiliadis, H. Zhang, H.V. Poor, One shot schemes for decentralized quickest change detection, IEEE
Trans. Inf. Theory 55 (2009) 3346–3359.
[75] V. Raghavan, V.V. Veeravalli, Quickest change detection of a Markov process across a sensor array, IEEE
Trans. Inf. Theory 56 (2010) 1961–1981.
[76] X. Nguyen, A. Amini, R. Rajagopal, Message-passing sequential detection of multiple change points in
networks, in: IEEE International Symposium on Information Theory (ISIT), July 2012.
[77] V. Krishnamurthy, Quickest time change detection with social learning, in: IEEE International Conference on
Acoustics, Speech, and Signal Processing (ICASSP), March 2012, pp. 5257–5260.
[78] V. Krishnamurthy, Bayesian sequential detection with phase-distributed change time and nonlinear penalty;
a POMDP lattice programming approach, IEEE Trans. Inf. Theory 57 (2011) 7096–7124.
[79] V. Krishnamurthy, Quickest detection with social learning: interaction of local and global decision makers,
March 2012, arXiv e-prints.
[80] I.V. Nikiforov, A lower bound for the detection/isolation delay in a class of sequential tests, IEEE Trans. Inf.
Theory 49 (2003) 3037–3046.
[81] A.G. Tartakovsky, Multidecision quickest change-point detection: previous achievements and open problems,
Sequent. Anal. 27 (2008) 201–231.

7
CHAPTER
Geolocation—Maps,
Measurements, Models, and
Methods
Fredrik Gustafsson
Division of Automatic Control, Department of Electrical Engineering, Linköping University, Sweden
3.07.1 Introduction
Geolocation is commonly used to describe the position of an object as a geographical location. It is also
used to denote the process of how to compute a geolocation. It is closely related to the broader concepts of
position and positioning/localization/navigation, but with a focus on a particular geographical context.
Target tracking is an area which has much in common with geolocation. Also here the position
is delivered relative to a sensor network. The main difference is that the position is computed in the
network. We exclude such network-centric applications, and focus on user-centric solutions where the
network does not need to cooperate with the user.
The application areas where the phrase geolocation is used in literature, include the position of the
following objects:
•
Sensors, such as radars in a sensor network. Sensor geolocation is a pre-requisite in all target tracking
and surveillance systems.
•
Radio receivers and transmitters, such as cell phones in a cellular network. Geolocation of cell
phones is required in some countries for emergency response. It is also a basis for many location
based services, and an important tool for the operators to optimize the network.
•
Animals, such as migrating birds. Besides being an important branch of ecology, the study of long-
term migration is also important for understanding the spread of infectious desease risk [1].
•
Computers in the Internet.
We will here cover the ﬁrst three cases, but exclude the last item on geolocation of IP hosts, which
signiﬁcantly differs from the other ones, see [2,3]. We will exclude positioning methods that only
provide a set of coordinates such as longitude and latitude on a globe. This rules out satellite based
localization and terrestial navigation, the latter based on the position of planets and stars [4]. In summary,
our deﬁnition of geolocation is as follows:
Positioning—the process of computing a position as coordinates on a ﬂat surface or a sphere.
Geolocation—position or positioning in a geographical context.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00007-2
© 2014 Elsevier Ltd. All rights reserved.
257

258
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
FIGURE 7.1
Dynamic ﬁngerprint in road networks, where a sufﬁciently long trajectory provides a unique ﬁngerprint in the
road map.
The geographical context is provided by what is usually referred to as a geographical information
system (GIS) in general terms. We will simply use the term map. The sensors typically measure range,
angle or orientation to landmarks in the map.
The geographical (static or dynamic) ﬁngerprint is a key concept introduced here to distinguish dif-
ferent applications. The term ﬁngerprint of course comes from human identiﬁcation, and in this context
the human retina also provides a unique “ﬁngerprint” of each human. On the contrary, one sample of
speech is not sufﬁcient for identifying the speaker, but a sequence of speech samples provides a “dynamic
ﬁngerprint.” We extend this example to geographical ﬁngerprints for geolocation. One or a sequence of
ranges/bearings to given landmarks in the map forms a static or dynamic ﬁngerprint. Some examples:
•
Geolocation of road-bound vehicles using the driven path as a dynamic ﬁngerprint, which is ﬁtted
to a road map. Figure 7.1 illustrates the principle.
•
Geolocation of airborne platforms using a measured terrain proﬁle as a dynamic ﬁngerpring, which
is ﬁtted to a terrain elevation map.
•
Geolocation of underwater vessels using a measured seaﬂoor proﬁle similar to the case above.
•
Geolocation of surface vessels using the shore proﬁle from a scanning radar as a dynamic ﬁngerprint,
which is compared to a sea chart.
•
Local variations on the earth magnetic ﬁeld provides a map to which magnetometer measurements
can be mapped in a ﬁngerprint manner [5].
•
A lightlogger [6,7] mounted on an animal can detect sunset and sunrise. Each detection corresponds
to a one-dimensional manifold of position on earth, and two such detections from sunset and sunrise
have a unique intersection (except twice a year). This information can be merged with maps of
possible resting areas for the bird (excluding water for instance), to form a geolocation estimate.
•
Water animals can be gelocalized by logging the water temperature and pressure [7].

3.07.2 Theory—Overview
259
•
At each point on earth, radio waves from a number of stationary radio transmitters (cellular networks,
television, etc.) can be detected. The received signal strength (RSS) is one radio measurement [8]
that can be used to form a ﬁngerprint in the following two conceptually different ways:
– The vector of RSS measurements from available transmitters forms a static ﬁngerprint which is
more or less unique for each point, provided that such an RSS map is available. The advantage is
that the method is completely independent of the deployment of transmitters, and the drawback
is that it requires a separate mapping procedure in advance. The location service in Google Maps
is a good example to show the ﬂexibility and strength of this approach.
– If the position and emitted power of each transmitter are known, then generic path loss models
can be used to compute the ﬁngerprint, without the need for a map. This is a common principle
for how the cellular phone operators implement their localization algorithms.
RSS based geolocation is particularly challenging for indoor applications [9–11].
Note that a geolocation is in many cases of higher relevance to the user than the exact position given in
latitude and longitude. Take for instance road navigation. A road map is seldom correct, so the actual
true position might be 10–30 m off the road network. Thus, the true position would be quite confusing
information for the user.
The discussion and examples above can be summarized as follows:
A sequence of measurements, related to landmarks in a map, along a trajectory forms a dynamic
ﬁngerprint.
3.07.2 Theory—overview
Figure 7.2 shows the main blocks in a geolocation system. The concepts and main function of each
block in Figure 7.2 can be summarized as follows:
•
Sensors:
– The inertial sensors indicate how the object is moving, for instance by measuring the speed and
course changes.
– The imagery sensors can be used to recognize landmarks, and they provide primarily the angle
to the landmark, but also orientation and distance if the landmark is sufﬁciently well known. A
camera is a simple example.
– The ranging sensors provide range to landmarks. A radar is the typical example, but also time of
ﬂight and received signal strength (RSS) of radio signals are commonly used.
– There are sensors that provide both range and angle, such as stereo cameras. An antenna array
of radio receivers also provides both range (from time of ﬂight) and angle.
•
The motion model is used to predict how the object is moving over time. For instance, odometric
sensor data can be integrated to a trajectory. This procedure is known as dead-reckoning or path
integration.

260
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
FIGURE 7.2
Framework of geolocation. The important and distinguishing features are the kind of sensors, the sensor
model providing a geographic ﬁngerprint, the motion model describing how the object moves in time, the
map and the state estimation algorithm.
•
The map contains the landmarks that the sensors can detect.
•
The sensor model connects the range and bearing measurements to landmarks in the map. The sensor
model is a function of the position of the object.
•
The state estimation method computes an estimate of the state vector, given all models and informa-
tion above. The state includes at least the position of the object, and possibly also speed and course.
Geographical information systems (GIS) represent our world with:
•
Landmarks stored as point objects.
•
Lines and polylines to represent topography, rivers, roads, railways, etc.
•
Areas stored as polygons to represent land use, lakes, islands, city boundaries, etc.
All of these GIS data may be used to deﬁne the map to be used for geolocation. The examples in
Section 3.07.5 use land and water depth topography, land use and coast line.
The following sections will describe each block in more detail, with some concrete examples. The
description is primarily verbal, but in parallel some detailed mathematical formulas will be provided,
to show what kind of computations that are involved and perhaps stimulate interested readers to make
their own implementations. The following section sets up the mathematical estimation framework, and
outlines the most important methods. The reader not interesting in this more theoretical part can skip
this section, or only read the more verbal description of the theory.
3.07.3 Estimation methods
3.07.3.1 Mathematical framework
The mathematical framework can be summarized in a state space model with state xk, position dependent
measurement yk, input signal uk, process noise wk, and measurement noise ek:
xk+1 = f (xk, uk, wk),
(7.1a)

3.07.3 Estimation Methods
261
yk = h(xk) + ek.
(7.1b)
The state includes at least position (Xk, Yk) and possibly also heading (or course) ψk and speed vk. In
our geolocation framework, (7.1a) corresponds to the motion model and (7.1b) the measurement model.
In summary, the measurement model (7.1b) describes how the measurement yk relates to the map h(xk)
and sensor errors ek, while the motion model (7.1a) describes how the next state xk+1 depends on the
previous state xk and the measured system inputs uk and unmeasured system inputs wk. State estima-
tion is the problem of estimating xk from the measurements yk. A dynamic ﬁngerprint shows how a
sequence of L measurements yk−L+1:k = (yT
k−L+1, . . . , yT
k )T ﬁts the map for the trajectory xk−L+1:k =
(xT
k−L+1, . . . , xT
k )T .
The following subsections will substantiate the mathematical framework.
3.07.3.2 Nonlinear ﬁltering
The problem of estimating the state, given a dynamical model for the time evolution of the state and a
measurement model showing how the measurements relate to the state, is called ﬁltering. When one or
more models are nonlinear, the problem is called nonlinear ﬁltering. The theory has developed during
the past 50 years, and today there are many powerful methods available. The output of a nonlinear
ﬁlter is a conditional distribution of the state, and the different classes of algorithms can be classiﬁed
according to how they parametrize this distribution, see Figure 7.3.
•
Kalman ﬁlter variants: the state is represented with a Gaussian distribution.
•
Kalman ﬁlter banks based on multiple model approaches: the state is represented with a mixture
of Gaussian distributions, where each Gaussian mode has an associated weight.
•
Point mass and particle ﬁlters: the state is represented with a set of grid points or samples with
an associated weight.
•
Marginalized, or Rao-Blackwellized, particle ﬁlters: the state is represented with a number
of trajectories over the geolocation area, each one has an associated weight and Gaussian
distribution for the other state variables than position.
We will here focus on the last one, since it focuses on estimating trajectories, and for that reason it
is the approach that best ﬁts the dynamic ﬁngerprinting concept.
3.07.3.3 Nonlinear ﬁlter theory
3.07.3.3.1
Bayes optimal ﬁlter
The Bayesian approach to nonlinear ﬁltering represents the information in the observations in a posterior
distribution p(xk|y1:k). This can be seen as a conditional probability density function (PDF) of the
current state xk given all previous observations y1:k. The Bayesian optimal ﬁlter propagates the posterior
distribution via a time update and a measurement update, respectively,
p(xk|y1:k) = p(yk|xk)p(xk|y1:k−1)
p(yk|y1:k−1)
,
(7.2)

262
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
−2
0
2
4
−2
0
2
4
0
0.05
0.1
0.15
x1
x2
(a) True pdf
−2
−1
0
1
2
3
4
5
−2
−1
0
1
2
3
4
5
x1
x2
(b) Kalman ﬁlter Gaussian
approximation
−2
−1
0
1
2
3
4
5
−2
−1
0
1
2
3
4
5
x1
x2
(c) Kalman ﬁlter bank Gaussian
mixture approximation
−2
−1
0
1
2
3
4
5
−2
−1
0
1
2
3
4
5
x1
x2
(d) Point-mass ﬁlter approximation
−2
−1
0
1
2
3
4
5
−2
−1
0
1
2
3
4
5
x1
x2
(e) Particle ﬁlter approximation
−2
0
2
4
−2
0
2
4
0
0.05
0.1
0.15
x1
x2
(f) Marginalized particle ﬁlter
approximation
FIGURE 7.3
True probability density function and different approximate representations.
p(xk+1|y1:k) =

Rn p(xk+1|xk)p(xk|y1:k) dxk.
(7.3)
The derivation of this recursion is quite straightforward and based on Bayes law and the marginalization
theorem, see Chapter 6 in [12] for instance.

3.07.3 Estimation Methods
263
3.07.3.3.2
Mean and covariance
The mean and covariance are deﬁned as
¯xk|k =

xk p(xk|y1:k) dxk,
(7.4)
Pk|k =
 
xk −ˆxk|k
 
xk −ˆxk|k
T p(xk|y1:k) dxk.
(7.5)
The double index notation in ¯xk|k should be interpreted as the estimate of the stochastic variable xk
given observations up to time k. The interpretation for Pk|k is the same. With this convention, ¯xk|k−1
is the expected value of the state prediction of xk and ¯xk|N is the expected value of the state xk given
observations y1:N, which is the smoothing solution for N > k and general prediction solution for N < k.
An estimator provides approximations of the mean and covariance. These will be denoted ˆxk|k and
Pk|k, respectively.
Covariance has a natural interpretation as providing a conﬁdence area for geolocation. This area is
represented with an ellipsoid centered around the mean where there is a, say, 99% probability to ﬁnd the
true position (note that the true position is considered to be a random variable in the Bayesian approach).
3.07.3.3.3
Covariance bound
In order to provide a conﬁdence ellipsoid to a geolocation problem, we need ﬁrst to get data, then
compute the posterior PDF with a speciﬁc method (which might involve approximations) and from
this compute the mean and covariance. An alternative is provided by the Cramer-Rao Lower Bound
(CRLB). This gives a lower bound on the covariance matrix
Pk|k ≥PCRLB
k|k
.
(7.6)
This bound applies to all methods that give an unbiased state estimate. There are two versions of this
bound with a bit different interpretations and computational complexity:
•
The parametric CRLB PparCRLB
k|k
, where the true state sequence xo
1:k is assumed to be known. The
bound is then a function of this sequence PparCRLB
k|k

xo
1:k

. This bound is simple to compute, and
the formulas are closely related to the covariance update in the (extended) Kalman ﬁlter, with a
measurement update
Hk = dh(x)
dx

x=xo
k
,
(7.7a)
Pk|k = Pk|k−1 −Pk|k−1H T
k

Hk Pk|k−1H T
k + Rk
−1
Hk Pk|k−1,
(7.7b)
and time update
Fk = d f (x, u, w)
dx

x=xo
k ,u=uk,w=0
,
(7.7c)
Gw,k = d f (x, u, w)
dw

x=xo
k ,u=uk,w=0
,
(7.7d)
Pk+1|k = Fk Pk|k FT
k + Gw,k QkGT
w,k.
(7.7e)

264
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
•
The posterior CRLB PpostCRLB
k|k
, where the true state sequence is assumed to be random according to
the Bayesian paradigm (this version is sometimes referred to as the Bayesian CRLB for this reason).
The relation between the bounds can be written
PpostCRLB
k|k
=

PparCRLB
k|k

x1:k

p(x1:k) dx1:k,
(7.8)
where p(x1:k) is the prior of the state sequence. This high-dimensional integral makes this bound
harder to compute, however, there are recursive algorithms, see [13,14].
3.07.3.3.4
The Kalman ﬁlter
The posterior (7.2) in the Bayes optimal ﬁlter is in general not possible to compute or even represent
in a computer. Instead, a common solution is to update the mean and covariance rather than the the full
PDF. This coincides with the optimal Bayes ﬁlter only for a linear Gaussian model
xk+1 = Fkxk + Gu,kuk + Gw,kwk,
(7.9a)
yk = Hkxk + Dkuk + ek,
(7.9b)
in which case the Kalman ﬁlter provides the mean and covariance in a Gaussian posterior p(xk|y1:k) =
N(ˆxk|k, Pk|k). The measurement and time update, respectively, are given by
ˆxk|k = ˆxk|k−1 + Pk|k−1H T
k

Hk Pk|k−1H T
k + Rk
−1
(yk −Hk ˆxk|k−1 −Dkuk),
(7.10a)
Pk|k = Pk|k−1 −Pk|k−1H T
k

Hk Pk|k−1H T
k + Rk
−1
Hk Pk|k−1,
(7.10b)
ˆxk+1|k = Fk ˆxk|k + Gu,kuk,
(7.10c)
Pk+1|k = Fk Pk|k FT
k + Gw,k QkGT
w,k.
(7.10d)
This can be seen as a special case of Algorithm 1. The derivation, variations and properties are described
in any text book on Kalman ﬁltering, for instance Chapter 7 in [12].
3.07.3.4 The extended Kalman ﬁlter
The Kalman ﬁlter recursions can be used for nonlinear ﬁltering problems by applying a ﬁrst order Taylor
expansion of the model,
xk+1 = f (xk, uk, wk)
≈f (ˆxk|k, uk, 0) + f ′
x(ˆxk|k, uk, 0)

x −ˆxk|k

+ f ′
w(ˆxk|k, uk, 0)wk,
yk = h(ˆxk|k−1) + h′
x(ˆxk|k−1)

x −ˆxk|k−1

+ ek.
By re-arranging these equations, it can be seen as a linear model (7.10) with some additional terms in
the right-hand side that do not depend on the state xk. Thus, the Kalman ﬁlter is easily modiﬁed for
this approximate model. The resulting approximation of the Bayes optimal ﬁlter is called the extended
Kalman ﬁlter.

3.07.3 Estimation Methods
265
The extended Kalman ﬁlter consists of the following main steps:
•
Deﬁne an initial Gaussian distribution N(ˆx1|0, P1|0) for the state x1 before the ﬁrst observation
y1 is provided.
•
Iterate in k = 1, 2, . . .:
1.
Measurement update: use a Taylor approximation of (7.1b) and the analytical solution
provided by the Kalman ﬁlter to get N(ˆxk|k, Pk|k) from N(ˆxk|k−1, Pk|k−1).
2.
Time update: use a Taylor approximation of (7.1a) and a simple formula from multivariate
statistics to get N(ˆxk+1|k, Pk+1|k) from N(ˆxk|k, Pk|k).
See Algorithm 1 for the details.
More details are given in for instance Chapter 8 in [12].
3.07.3.5 The unscented Kalman ﬁlter
The EKF takes care of the ﬁrst two terms in a Taylor expansion of the model. The unscented Kalman ﬁlter
(UKF) makes an attempt to also include the information in the quadratic term. Consider the following
nonlinear mapping z = g(x) of a Gaussian vector x,
x ∈N(μx, Px),
z = g(x) ≈N(μz, Pz).
Algorithm 1. The Extended Kalman Filter
Given: Motion model (7.1a), measurement model (7.1b), the noise covariances Q = Cov(w) and
R = Cov(e), respectively, and the prior mean x0 and covariance P0.
Design parameter: None. Initialization: Let ˆx1|0 = x0 and P1|0 = P0
Iteration: For k = 1, 2, . . .
1. Measurement update:
Hk = dh(x)
dx

x=ˆxk|k−1
,
(7.11a)
ˆxk|k = ˆxk|k−1 + Pk|k−1H T
k

Hk Pk|k−1H T
k + Rk
−1 
yk −h(ˆxk|k−1)

,
(7.11b)
Pk|k = Pk|k−1 −Pk|k−1H T
k

Hk Pk|k−1H T
k + Rk
−1
Hk Pk|k−1.
(7.11c)
2. Time update:
Fk = d f (x, u, w)
dx

x=ˆxk|k,u=uk,w=0
,
(7.11e)
Gw,k = d f (x, u, w)
dw

x=ˆxk|k,u=uk,w=0
,
(7.11f)

266
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
ˆxk+1|k = f (ˆxk|k, uk, 0),
(7.11e)
Pk+1|k = Fk Pk|k FT
k + Gw,k QkGT
w,k.
(7.11f)
The unscented transform generates samples of x(i), called sigma points, systematically on the surface
of an ellipsoid centered around its mean, maps these points to z(i) = g(x(i)), and then computes the
ﬁrst two moments of the samples z(i). The procedure is quite similar to a Monte Carlo simulations, but
there are two important differences: (1) the samples are deterministically chosen and (2) the weights in
the mean and covariance estimators are not simply 1/N, where N is the number of samples.
The following equations summarize the unscented transform. Let
x(0) = μx,
x(±i) = μx ±

nx + λσiui,
(7.12a)
ω(0) =
λ
nx + λ,
ω(±i) =
1
2(nx + λ),
(7.12b)
where i = 1, . . . , nx. Let z(i) = g(x(i)), and apply
μz =
nx
	
i=−nx
ω(i)z(i),
(7.13a)
Pz =
nx
	
i=−nx
ω(i) 
z(i) −μz
 
z(i) −μz
T
(7.13b)
+ (1 −α2 + β)

z(0) −μz
 
z(0) −μz
T
.
(7.13c)
The design parameters of the UT are summarized below:
•
λ is deﬁned by λ = α2(nx + κ) −nx.
•
α controls the spread of the sigma points and is suggested to be approximately 10−3.
•
β compensates for the distribution, and should be chosen to β = 2 for Gaussian distributions.
•
κ is usually chosen to zero.
Table 7.1 Different Versions of the UT in (7.12) and (7.13) Using the Deﬁnition λ = α2
(nx + κ) −nx
Parameter
UT1
UT2
CT
α

3/nx
10−3
1
β
3/nx −1
2
0
κ
0
0
0
λ
3 −nx
10−6nx −nx
0
√nx + λ
√
3
10−3√nx
√nx
ω(0)
1 −nx /3
−106
0

3.07.3 Estimation Methods
267
Note that nx + λ = α2nx when κ = 0, and that for nx + λ →0+ the central weight ω(0) →−∞.
Furthermore, 
i ω(i) = 1. We will consider the two versions of UT in Table 7.1, corresponding to
the original one in [15] and an improved one in [16]. Most interestingly, [17] describes a completely
different approach yielding the same transformation with a different tuning. This approach starts from
the integral deﬁning the ﬁrst two moments, and applies the cubature integration rule, hence the name
cubaturetransformusedhere.Itappearsthatthistuninggivesagoodresultinmanypracticallyinteresting
cases, see Chapter 8 in [12] or [18].
As an illustration, the following mapping has a well-known distribution
z = g(x) = xT x,
x ∈N(0, In) ⇒z ∈χ2
n .
(7.14)
This distribution has mean n and variance 2n. For the Taylor expansion, we get z ∼N(0, 0). This is
of course not a useful approximation, but it is still what an EKF uses implicitly for quadratic functions.
Now, the unscented transform gives z ∼N(n, (3−n)n), z ∼N(n, 2n2) and z ∼N(n, n), respectively,
for the three tunings in Table 7.1 (UT1, UT2, CT). This leads to useful approximations in ﬁltering, except
for the original UT1 for n > 3 (when the variance becomes negative).
Having deﬁned the UT, the UKF can now be summarized as follows.
The unscented Kalman ﬁlter consists of the following main steps:
•
Deﬁne an initial Gaussian distribution N(ˆx1|0, P1|0) for the state x1 before the ﬁrst observation
y1 is provided.
•
Iterate in k = 1, 2, . . .:
1.
Measurement update: apply the unscented transform to (7.1b) and use an analytical result
to get N(ˆxk|k, Pk|k) from N(ˆxk|k−1, Pk|k−1).
2.
Time update: apply the unscented transform to (7.1a) to immediately get N(ˆxk+1|k, Pk+1|k)
from N(ˆxk|k, Pk|k).
See Algorithm 2 for the details.
3.07.3.6 The particle ﬁlter
The particle ﬁlter (PF) works with a set of random trajectories. Each trajectory is formed recursively
by iteratively simulating the model with some randomness, and then updating the likelihood of each
trajectory based on the observed ﬁngerprint:
The (marginalized) particle ﬁlter, (M)PF, for geolocation consists of the following main steps:
•
Deﬁne a set of random positions (hypotheses, particles).
•
For each particle, deﬁne a random velocity vector.
•
Iterate:
1.
Compute the likelihood of the measurement ﬁngerprint using the map.

268
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
2.
Modify the weight (probability) of each particle.
3.
Resample the set of particles.
4.
Predict next position of the particles.
5.
Marginalization step: update the velocity mean and covariance by a conditional Kalman
ﬁlter.
See Algorithm 3 for the details.
Algorithm 2. Unscented Kalman Filter
Given: Motion model (7.1a), measurement model (7.1b), the noise covariances Q = Cov(w) and
R = Cov(e), respectively, and the prior mean x0 and covariance P0.
Design parameter: α, β, κ in the UT, see Table 7.1.
Initialization: Let ˆx1|0 = x0 and P1|0 = P0
Iteration: For k = 1, 2, . . ..
1. Measurement update: Let
¯x =
 xk
ek

∼N
 ˆxk|k−1
0

,
 Pk|k−1 0
0
Rk

,
(7.15a)
z =
 xk
yk

=

xk
h(xk, uk, ek)

.
(7.15b)
UT in (7.12) and (7.13) gives
z ∼N
 ˆxk|k−1
ˆyk|k−1

,

Pxx
k|k−1 Pxy
k|k−1
P yx
k|k−1 P yy
k|k−1

.
(7.15c)
The measurement update is then
Kk = Pxy
k|k−1

P yy
k|k−1
−1
,
(7.15d)
ˆxk|k = ˆxk|k−1 + Kk

yk −ˆyk|k−1

,
(7.15e)
Pxx
k|k = Pxx
k|k−1 −Kk P yy
k|k−1K T
k .
(7.15f)
2. Time update: Let
¯x =
 xk
vk

∼N
 ˆxk|k
0

,
 Pk|k 0
0
Qk

,
(7.15g)
z = xk+1 = f (xk, uk, vk).
(7.15h)
UT in (7.12) and (7.13) gives
z ∼N

ˆxk+1|k, Pk+1|k

.
(7.15i)

3.07.3 Estimation Methods
269
3.07.3.6.1
Particle ﬁlter illustration
Figure7.4illustrateshowthedynamicﬁngerprintdepictedinFigure7.1isﬁttedtoaroad-maprecursively
in time. Initially, the particles are spread uniformly over a part of the road network corresponding to
prior knowledge. The initial particle cloud can be seen in Figure 7.4b. Figure 7.4 shows how the particle
cloud improves after each turn, to eventually become one single cloud, where a marker indicates that
the position can be unambiguously estimated and used as input to the navigation system.
3.07.3.6.2
Particle ﬁlter details
Nonlinear ﬁltering is the branch of statistical signal processing concerned with recursively estimating
the state xk in (7.1) based on the measurements up to time k, y1:k ≜{y1, . . . , yk} from sample 1 to k. The
(a) After ﬁrst turn
(b) After second turn
(c) After third turn
(d) After fourth turn
FIGURE 7.4
Illustration of how the particle representation of the position posterior distribution (course state is now shown)
improves as the ﬁngerprint becomes more informative. After four turns, the ﬁngerprint is unique (unimodal
posterior distribution), and a marker for geolocation is shown. The circle denotes GPS position, which is only
used for evaluation purposes. Compare with Figure 7.1.

270
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
most general problem it solves is to compute the Bayesian conditional posterior density p(x1:k|y1:k).
The posterior distribution is in the particle ﬁlter approximated with
p(x1:k|y1:k) ≈
N
	
i=1
ω(i)
k|kδ

x(i)
1:k −x1:k

.
(7.16)
This is a weighted sum of Dirac distributions. A Dirac distribution is characterized with the identity

g(x)δ(x) dx = g(0) for all smooth functions g(x). This implies for instance that the mean of the
trajectory is approximated with
ˆx1:k|k ≈
N
	
i=1
ω(i)
k|kx(i)
1:k.
(7.17)
Here ω(i)
k|m denotes the likelihood of trajectory x(i)
1:k, given the observations y1:m. The likelihood of the
dynamic ﬁngerprint can be expressed as a conditional probability density function p(y1:k|x1:k). Given
a set of trajectories {x(i)
1:k}N
i=1 with prior probabilities {ω(i)
k|0}N
i=1, the posterior probabilities become
ω(i)
k|k ∝ω(i)
k|0 p

y1:k|x(i)
1:k

.
(7.18)
This is the main principle for how the ﬁngerprint is used to objectively compare the set of state trajec-
tories. The particle ﬁlter does this in a recursive manner. Its simplest form is given in Algorithm 3.
Algorithm 3 gives the basic bootstrap or SIR particle ﬁlter, that works well when the sensor obser-
vations are not very accurate (of course, a relative notion). For more accurate observations, other so
called proposal distributions should be used for the prediction step, and the weight update is modiﬁed
accordingly, see [19] for the details. The last marginalization step will be illustrated in Section 3.07.4,
when concrete motion models are given.
3.07.4 Motion models
The motion model xk+1 = f (xk, uk, wk) in (7.1b) provides a description of how the object moves from
time tk to time tk+1 when the next measurement is available. One interpretation is that the motion model
describes how to interpolate between the position estimates computed from the measurements. It also
relates position to other state variables, such as course and speed, and makes it possible to estimate
these as well. The different classes of motion models are summarized below:
The trajectory may be obtained from one of the following motion model principles.
1. Integrating a kinematic model with white noise inputs.
2. Inertial navigation using accelerometers and gyroscopes as inputs to a model of a rigid body
dead-reckoning model.
3. Odometry using wheel speeds as inputs to an odometric model.

3.07.4 Motion Models
271
4. Simulation using control signals (engine speed and steering angle) as inputs to a dynamic model.
In all cases, the dead-reckoned trajectory is subject to drift, and the dynamic ﬁngerpring can stabilize
the drift relative to the map.
Algorithm 3. The (Marginalized) Particle Filter
Given: Motion model (7.1a), measurement model (7.1b), the noise distributions pw(w) and pe(e),
respectively, and the prior px0(x).
Design parameter: The number of particles N.
Initialization: Generate x(i)
1
∼px0, i = 1, . . . , N, from prior knowledge and let ω(i)
1|0 = 1/N.
Iteration: For k = 1, 2, . . .
1. Measurement update: For i = 1, 2, . . . , N,
ω(i)
k|k = 1
ck
ω(i)
k|k−1 pe

yk −h

x(i)
k

,
(7.19a)
where the normalization weight is given by
ck =
N
	
i=1
ω(i)
k|k−1 pe

yk −h

x(i)
k

.
(7.19b)
2. Estimation: The state can be estimated by the conditional mean (MAP is another example)
ˆx1:k ≈
N
i=1 ω(i)
k|kx(i)
1:k.
3. Resampling: Take N random samples with replacement from the set {x(i)
1:k}N
i=1 where the proba-
bility to take sample i is ω(i)
k|k and let ω(i)
k|k = 1/N.
4. Time update: Generate predictions by simulating trajectories
w(i)
k
∼pw,
(7.19c)
x(i)
k+1 = f

x(i)
k , uk, w(i)
k

,
(7.19d)
and append this to the trajectory x(i)
1:k+1 = {x(i)
k+1, x(i)
1:k}.
5. Marginalization: Update states that are not part of the ﬁngerprint and that appear linearly in the
motion model using a Kalman ﬁlter (see (7.24) and (7.28) for two examples).
We here describe a couple of speciﬁc and simple two-dimensional motion models that are typical
for geolocation applications. Three-dimensional extensions do exist, but are much more complex, so
we prefer to focus on horizontal position in two dimensions. See [20] or Chapters 12 and 13 in [12] for
a survey on motion models.

272
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
3.07.4.1 Dead-reckoning model
A very instructive and also quite useful motion model is based on a state vector consisting of position
(X, Y) and course (yaw angle) ψ. This assumes that there are measurements of yaw rate (derivative
of course) ˙ψ and speed ϑ, in which case the principle of dead-reckoning can be applied. In ecology,
dead-reckoning is more commonly called path integration.
The dead-reckoning model can be formulated in continuous time using the following equations:
x(t) =
⎛
⎝
X(t)
Y(t)
ψ(t)
⎞
⎠,
˙x(t) =
⎛
⎝
ϑ(t) cos (ψ(t))
ϑ(t) sin (ψ(t))
˙ψ(t)
⎞
⎠.
(7.20)
A discrete time model expressed at the sampling instants kT for the nonlinear dynamics is given by
Xk+1 = Xk + 2ϑk
˙ψk
sin
 ˙ψkT
2

cos

ψk +
˙ψkT
2

≈Xk + ϑkT cos (ψk),
(7.21a)
Yk+1 = Yk + 2ϑk
˙ψk
sin
 ˙ψkT
2

sin

ψk +
˙ψkT
2

≈Yk + ϑkT sin (ψk),
(7.21b)
ψk+1 = ψk + T ˙ψk.
(7.21c)
If the yaw rate ˙ψk is small compared to the sample interval T, then the model can be simpliﬁed. Further,
assume that the speed ϑm
k and angular velocity ˙ψm
k are measured with some error wk = (wϑ
k , w
˙ψ
k ), with
variance Qϑ
k and Q
˙ψ
k , respectively. This gives the following dynamic model with process noise wk:
Xk+1 = Xk + ϑm
k T cos (ψk) + T cos (ψk)wϑ
k ,
(7.22a)
Yk+1 = Yk + ϑm
k T sin (ψk) + T sin (ψk)wϑ
k ,
(7.22b)
ψk+1 = ψk + T ˙ψm
k + T w
˙ψ
k .
(7.22c)
This model has the following structure:
xk+1 = f (xk, uk) + g(xk, uk)wk,
uk =
 ϑm
k˙ψm
k

,
wk =

wϑ
w
˙ψ
k

(7.22d)
that ﬁts the particle ﬁlter perfectly. Note that the speed and the angular velocity measurements are
modeled as inputs, rather than measurements. This is in accordance to many navigation systems, where
inertial measurements are dead-reckoned in similar ways. The main advantage is that the state dimen-
sion is kept as small as possible, which is important for the particle ﬁlter performance and efﬁciency.
This basic model can be used in a few different cases described next.
3.07.4.1.1
Odometric models
The wheel speeds ωleft and ωright of two wheels with radius r on one axle of length L can be transformed
to speed and yaw rate,
ϑm
k = r
2

ωleft
k
+ ω right
k

,
(7.23a)

3.07.4 Motion Models
273
˙ψm
k = r
L

ωleft
k
−ω right
i

.
(7.23b)
This ﬁts the dead-reckoning model, and this special case is commonly referred to as odometry. The state
vector might needs to be augmented with parameters for deviations from nominal wheel radius. For the
road navigation example, the time update in Algorithm 3 can be given explicitly as in Algorithm 4
Algorithm 4. PF time update for odometry
In step 4 of Algorithm 3, do
1. Generate N samples of noise and add these to the wheel speed measurements ωleft
k
and ωright
i
to
get N samples of wheel speeds.
2. Compute the speed and yaw rate from (7.23) for each sample.
3. Propagate the set of particles according to (7.22).
3.07.4.1.2
Inertial models
A course gyro provides ˙ψm
k and a longitudinal accelerometer give the acceleration ˙ϑm
k . If the state vector
is extended with speed ϑk to xk = (Xk, Yk, ψk, vk), and the state space model (7.22a–c) is extended
with vk+1 = vk + wv
k, then we are back in the structure of (7.22d).
3.07.4.1.3
Dynamical models
The steering and accelerator inputs to a car, or the rudder and engine commands to a vessel, can be
statically mapped to speed ϑm
k and yaw rate ψm
k , and the dead-reckoning model can be applied directly.
However, here the dynamics can be included to improve the motion model.
3.07.4.1.4
Marginalization of speed
In inertial navigation, the state consists of four elements. Also in odometry and dynamical models, the
speed is often used as a state. This fourth state usually increases the number of required particles in
the PF substantially, and marginalization is recommended. The marginalization step 4 in Algorithm 3
can be used to eliminate the state ϑk from the PF. The marginalized particle ﬁlter is in general quite
complex to implement [21], but for special cases like this the formulas become quite concrete, as shown
in Algorithm 5.
Algorithm 5. PF marginalization for dead-reckoning
In step 5 of Algorithm 3, do
1. Let the longitudinal acceleration ak be an unknown continuous time white noise input with
intensity Qa.
2. Use ϑm
k ∼N

ˆϑk|k, Pa
k|k

as the speed in the motion model (7.22a,b).

274
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
3. Reformulate (7.22a,b) as a measurement of speed. Step 5 in Algorithm 3 consists of a time update
ˆϑ(i)
k+1|k = ˆϑ(i)
k|k + Tak,
(7.24a)
Pa(i)
k+1|k = Pa(i)
k|k + Qa,
(7.24b)
and an artiﬁcial measurement update based on the simulated new value of position in step 4,
ε(i)
k+1 =
⎛
⎜⎜⎝
X(i)
k+1−X(i)
k
T cos (ψ(i)
k )
Y (i)
k+1−Y (i)
k
T sin (ψ(i)
k )
⎞
⎟⎟⎠−ˆϑ(i)
k+1|k,
(7.24c)
H = (1, 1)T ,
(7.24d)
Sk+1 = H Pa(i)
k+1|k H T + T 2Qϑ12×2,
(7.24e)
Kk+1 = Pa
k+1|k H T S−1
k+1,
(7.24f)
ˆϑ(i)
k+1|k+1 = ˆϑ(i)
k+1|k + Kk+1ε(i)
k+1,
(7.24g)
Pa
k+1|k+1 = Pa
k+1|k −Kk+1Sk+1K T
k+1.
(7.24h)
We have only discussed two-dimensional models here, but the principles are easily extended to three
dimensions. The state vector then includes the height Zk, the roll φk and the pitch θk angles. Thus,
the state vector becomes about twice as large. In most practical application, the height is either trivial
(surface vessels, cars) or an almost separate estimation problem (underwater vessels, aircraft), where
pressure sensors provide accurate information to estimate height.
3.07.4.2 Kinematic model
The simplest possible motion model, yet one of the most common ones in target tracking applica-
tions where no inertial measurements are available, is given by a two-dimensional version of Newton’s
force law:
x(t) =
⎛
⎜⎜⎝
X(t)
Y(t)
˙X(t)
˙Y(t)
⎞
⎟⎟⎠,
˙x(t) =
⎛
⎜⎜⎝
˙X(t)
˙Y(t)
wX(t)
wY (t)
⎞
⎟⎟⎠.
(7.25a)
The corresponding discrete time model is given by
xk+1 =
⎛
⎜⎜⎝
1 0 T 0
0 1 0 T
0 0 1 0
0 0 0 1
⎞
⎟⎟⎠xk +
⎛
⎜⎜⎝
T 2/2
0
T
0
0
T 2/2
0
T
⎞
⎟⎟⎠
wX
k
wY
k

.
(7.25b)
The time update in Algorithm 3 is here explicitly formulized in Algorithm 6.

3.07.4 Motion Models
275
Algorithm 6. PF time update for kinematic models
In step 4 of Algorithm 3, do
1. Simulate N noise vectors w(i)
k .
2. Propagate the set of particles according to (7.25b).
3.07.4.2.1
Marginalization of speed
Suppose the sensor model depends on the position only, which is typical in geolocation applications,
yk = h(Xk, Yk) + ek.
(7.26)
Since the motion model is linear in the state and noise, the marginalized PF applies, so the velocity
component can be handled in a numerically very efﬁcient way.
Let pk = (Xk, Yk)T and vk = ( ˙Xk, ˙Yk)T . Then, (7.25b) and (7.26) can be rewritten as
pk+1 = pk + T vk + T 2
2 wk,
(7.27a)
yk = h(pk) + ek,
(7.27b)
vk+1 = vk + T wk,
(7.27c)
pk+1 −pk = T vk + T 2
2 wk.
(7.27d)
We here use the particle ﬁlter for (7.27a,b) and the Kalman ﬁlter for (7.27c,d). Note that (7.27a) and
(7.27d) are the same, but interpreted in two different ways. The time update in the particle ﬁlter becomes
v(i)
k
= N

ˆv(i)
k|k−1, Pk|k−1

,
(7.28a)
w(i)
k
= N

0, Qk

,
(7.28b)
p(i)
k+1 = p(i)
k
+ T v(i)
k
+ T 2
2 w(i)
k ,
(7.28c)
where we treat the velocity as a noise term. Conversely, we use the position as a measurement in the
Kalman ﬁlter. For this particular structure, the general result given in Theorem 2.1 in [21] simpliﬁes a
lot, and we get a combined update
ˆv(i)
k+1|k = p(i)
k+1 −p(i)
k
T
,
(7.28d)
Pk+1|k = Pk|k−1 −Pk|k−1

Pk|k−1 + T 2
4 Qk
−1
Pk|k−1.
(7.28e)
Note that each particle has an individual velocity estimate ˆv(i)
k|k−1 but a common covariance Pk|k−1.
Furthermore, if Qk > 0, the covariance matrix converges quite quickly to zero, Pk|k−1 →0, and the
Kalman ﬁlter is in fact not needed for the particle ﬁlter. The prediction step (7.28a,b) in the PF consists
only of sampling from w(i)
k
= N

0, Q

in (7.28a). The Kalman and particle ﬁlters are thus decoupled.

276
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
3.07.5 Maps and applications
This part describes a number of applications in more detail. A summary of the applications and their
features is provided in Table 7.2. The common theme of these applications is that they have been applied
to real data and real maps, all using the (marginalized) particle ﬁlter. A detailed mathematical description
of the particle ﬁlter and marginalized particle ﬁlter for some of these applications is provided in [19].
To give some objective performance measure of the particle ﬁlter, the root mean square error (RMSE)
of position (loosely speaking the standard deviation of the position error in meters) from the particle
ﬁlter is in most cases below compared to a lower bound provided by the Cramer-Rao theory for nonlinear
ﬁlters [14,22]. The lower bound is an information bound, that depends on the assumption in the model.
Only asymptotically in information, the lower bound can be obtained. Since the same models are used
in both the ﬁlter and bound, it can be used to judge the performance of the estimation method, here
the particle ﬁlter. The particle ﬁlter performance can in theory never beat the lower bound. However,
in practice it can, the typical case being when the actual measurements are more accurate than what is
assumed in the model.
3.07.5.1 Road-bound vehicles
This application illustrates how the odometric model (7.22) with the wheel speed transformed measure-
ments (7.23) is combined with a road map. First, the road map is discussed.
Figure 7.5 illustrates how a standard map can be converted to a likelihood function for the position.
Positions on roads get the highest likelihood, and the likelihood quickly decays as the distance to the
closest road increases. A small offset can be added to the likelihood function to allow for off-road
driving, for instance on un-mapped roads and parking areas.
The weights in the particle ﬁlter in Algorithm 3 are multiplied with the likelihood function in the
measurement update (7.19a) as
ω(i)
k|k = ω(i)
k|k−1l

X(i)
k , Y (i)
k

,
(7.29)
where one example of the likelihood function l

X(i)
k , Y (i)
k

is shown graphically in Figure 7.5.
Table 7.2 Overview of the Illustrative Applications. The (marginalized) Particle Filter is Used
in All of Them
Application
Map
Measurements
Fingerprinting
Motion Model
Road-bound vehicles
Road
Wheel speeds
Dynamic
Odometry
Airborne fast vehicles
Terrain elevation
Staring radar
Dynamic
INS
Airborne slow vehicles
Aerial image
Camera
Static
INS
Underwater vessles
Depth
Sonar
Dynamic
Dynamic
Surface vessels
Sea chart
Scanning radar
Static
INS or dynamic
Cell phones
RSS
Radio receiver
Static
Kinematic

3.07.5 Maps and Applications
277
(a) Original map
(b) Filtered binary map
(c) On-road likelihood
FIGURE 7.5
(a) Original map. (b) The road color is masked out, and local maxima over a 4 × 4 region is computed to
remove text information. (c) The resulting map is low-pass ﬁltered to allow for small deviations from the road
boarders, which yields a smooth likelihood function for on-road vehicles.
(a)
(b) First Implementation
Framework
FIGURE 7.6
(a) Framework of geolocation of road-bound vehicles. (b) A ﬁrst implementation from 2001, running 15,000
particles in 2 Hz in parallel with voice-based route guidance.
The likelihood function l(X, Y) in (7.29), shown graphically in Figure 7.5c, is here used as a ﬁnger-
print. This summarizes the whole algorithm. This algorithm together with a complete navigation system
including voice guidance was implemented in a student project on the platform shown in Figure 7.6 in
2001 [23]. Here, 15,000 particles were used in 2 Hz ﬁlter speed in this real-time GPS-free car navigation

278
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
system. The conclusion from this project is that the computational complexity of the particle ﬁlter should
not be overemphasized in practice.
3.07.5.2 Airborne fast vehicles
Figure 7.7 illustrates the main concepts of terrain navigation [24,25]. The ﬂying platform can compute
the terrain altitude variations, and this dynamic ﬁngerprint is matched to a terrain elevation map,
ω(i)
k|k = ω(i)
k|k−1 pe

yk −h

X(i)
k , Y (i)
k

.
(7.30)
A separate vegetation classiﬁcation map can be used to change the measurement noise distribution
pe(e), where the idea is that the measurement from the radar is more reliable over an open ﬁeld compared
to a forest, for instance. In [24], it was shown that a Gaussian mixture is a good model for the radar
altitude measurement error.
Framework
(b)
(a)
Illutrations
FIGURE 7.7
(a) Framework of geolocation of airborne vehicles. The principle is that the down-looking radar provides
distance to ground, while the barometer connected to the INS gives a reliable altitude estimate. The difference
gives the altitude on ground. (b) The measured ground altitude is compared to a terrain elevation map, where
the noise distribution models possible errors due to the radar lobe width and reﬂectors such as tree tops.

3.07.5 Maps and Applications
279
Test trajectory on elevation map
(b) PDF after the first measurement updates
(a)
FIGURE 7.8
Flight trajectory overlayed the terrain elevation map (a). The position distribution after the ﬁrst few iterations
of the particle ﬁlter (b). Figures from [24].
Figure 7.8a shows a ﬂight trajectory overlayed on the topographic map. Figure 7.8b shows how the
particle ﬁlter approximates the position distribution after the ﬁrst few measurements. It is quite clear
that the distribution is peaky with a lot of local maxima corresponding to positions with a good ﬁt to
the ﬁngerprint. This is the strength of the particle ﬁlter compared to the classical Kalman ﬁlter, that can
only handle one peak, or ﬁlterbanks, where the number of peaks must be speciﬁed beforehand.
Figure 7.9a shows the RMSE performance over time for the trajectory in Figure 7.8. The typical
error is 10 m. One can notice that the RMSE grows when the aircraft is over the sea, since there is no
information in the measurements.
Figure 7.9b shows the convergence of the particle ﬁlter, compared to the Cramer-Rao lower bound.
Interestingly, the performance reaches the bound after 160 samples.
Finally, Figure 7.10 illustrates the information in the terrain elevation map. Figure 7.10a shows the
map itself, and Figure 7.10b the RMSE bound as a function of position. One can here clearly identify
the most informative areas at the highland, and the least informative over sea and lakes.

280
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
RMSE for whole trajectory
(a)
RMSE and CRLB for transient
(b)
FIGURE 7.9
(a) RMSE as a function of sample number for the whole trajectory. (b) Zoom for the ﬁrst initial phase. The
RMSE is in both plots compared to the Cramer-Rao lower bound. Figures from [24].
3.07.5.3 Airborne slow vehicles
The principle in the previous section assumes that the ﬂying platform moves quickly compared to the
terrain variations. For slow platforms such as unmanned aerial vehicles (UAV’s), this principle does
not work. We here summarize another approach based on camera images of the ground.
Figure 7.11a shows the framework of the airborne geolocation system. A down-looking camera
provides an aerial image that can in principle be compared to aerial photos in a database. However, this
does not work in practice, due to large variations in light conditions and shadows, and also the seasonal
variations. There is also a problem with a large dimensional search space. Even if the altitude of the
platform is known, and the platform is assumed to be horizontal, there are still three degrees of freedom
(two-dimensionaltranslationandrotation).Thesolutiondescribedin[26]isbasedonthefollowingsteps:
•
Make a circular cut of the image.
•
Segment the image and classify each segment.
•
Use a histogram of the different segments as the ﬁngerprint.

3.07.5 Maps and Applications
281
(a)
(b)
FIGURE 7.10
(a) Terrain elevation map. (b) Information content in the map, expressed as an expected value of the Cramer-
Rao lower bound for each position. Figures from [24].
Framework
(a)
AUV (true, geolocated, and dead-reckoned)
(b)
FIGURE 7.11
(a) Framework of geolocation of airborne vehicles. (b) Virtual reality snapshot of the AUV experiment.

282
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
FIGURE 7.12
Overview of the airborne geolocation system. The camera image in the upper left corner is segmented and
classiﬁed to the image in the upper right corner. The histogram of the classes is used as the ﬁngerprint. The
lower plot shows the particle cloud after a few iterations.
Figure 7.12 summarizes some of the main steps in the particle ﬁlter. Due to the circular area of interest,
the method is rotation invariant. A database of ﬁngerprints for each position can easily be pre-computed
from aerial photos. The resulting matching process is in this way computationally very attractive.
3.07.5.4 Underwater vessels
Figure 7.13 illustrates the framework for underwater navigation [27]. A sonar measures the distance to
the seaﬂoor. The control inputs (propeller speed and rudder angle) can be simulated in a dynamic model
between the sampling instants in the prediction step in the particle ﬁlter. Alternatively, an inertial mea-
surement unit can be used for the prediction step, possibly in combination with a Doppler velocity log.
Figure 7.14 shows an underwater map as described in [28]. Figure 7.14a shows the systematic
trajectory used for mapping the seaﬂoor using a surface vessel with sonar and GPS, together with a

3.07.5 Maps and Applications
283
(a) Framework
(b) Underwater vessel and seaﬂoor
topography
FIGURE 7.13
(a) Framework of geolocation of underwater vessels. (b) The principle is that a down-looking sonar provides
distance to seaﬂoor, while a pressure sensor (or up-looking sonar) gives the depth of the vessel. The difference
gives the depth of the seaﬂoor, which can be compared to a terrain elevation map.
benchmark trajectory for evaluation purposes. Figure 7.14b shows the resulting seaﬂoor map, with the
ground truth trajectory, and the one obtained by just using the dynamical model (a simulation).
Figure 7.15 shows the RMSE in the two position coordinates, compared to the Cramer-Rao lower
bound. The performance is within a few meter error, and actually better than the bound, indicating that
the measurements are more accurate than what is modeled.
3.07.5.5 Surface vessels
Figure 7.16a shows the framework for surface navigation using radar map matching principle [27].
Figure 7.16b shows a zoom of the sea chart in the upper left corner. The detections from a scanning
radar are shown in polar coordinates in the top right corner. This is a ﬁngerprint, which can be ﬁtted in
the area of the sea chart corresponding to our prior knowledge of position. This is a three-dimensional
search (two position coordinates and one rotation). The particle ﬁlter solves this optimization for each
radar scan, using a motion model to predict the motion and rotation of the radar platform.
The performance of the ﬁlter is shown for one test trajectory in Figure 7.17a. The precision is most
of the time in the order of 5 m, which is often more accurate than the coastline in a sea chart. Thus, this
geolocation is even more useful for navigation than GPS, and in contrast to GPS it is not possible to

284
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
(a)
(b)
Map generation path and test trajectory
Map, test trajectory and particles after
first measurement
FIGURE 7.14
A surface vessel with GPS was used to map the area of interest in advance according to the systematic
trajectory in (a), which also shows the test trajectory. The test trajectory is shown on the ﬁnal map in (b).

3.07.5 Maps and Applications
285
FIGURE 7.15
RMSE for the X and Y coordinates, respectively, for the whole trajectory in Figure 7.14.
jam. Between 50 and 60 s, the ship is moving out closer to open sea, thus decreasing the information in
the radar scan. The performance is here somewhat worse than the lower bound.
Figure 7.17b shows the lower bound on RMSE as a function of position. In this case, a number of
random straight line trajectories are used to average the bound.
3.07.5.6 Cellular phones
Figure 7.18 shows the framework of geolocation based on received signal strength (RSS) and the
transmitter’s identiﬁcation number (ID). In this section, we survey results from a Wimax deployment
in Brussels [29,30], but the same principle applies to all other cellular radio systems. At each time, a
vector with n observed RSS values is obtained. The map provides a vector of m RSS values at each
position (some grid is assumed here). A ﬁrst problem is that n and m do not necessarily have to be the
same, and the n ID’s do not even need to be a subset of the m ID’s in the map. One common solution is
to only consider the largest set of common RSS elements. The advantage is that we can use the usual
vector norms in the comparison of the measured ﬁngerprint with the map. The disadvantage is that a
missing ID gives a kind of negative information that is lost. That is, we can exclude areas based on a
missing value from a certain site. A theoretically justiﬁed approach is still missing.

286
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
(a) Framework
(b) Fingerprinting illustration
FIGURE 7.16
(a) Framework of geolocation of surface vessels. (b) The principle is that the scanning radar provides a 360◦
view of the distance to shore, which can be compared to sea chart.
3.07.5.6.1
Continuous RSS measurements
Figure 7.19 shows the RSS maps from three sites over the test area [29]. There are certain combinations
of knowledge in the geolocation algorithm:
•
One can use the static ﬁngerprint and estimate the position independently at each time, or use a
motion model and the particle ﬁlter to ﬁt a dynamic ﬁngerprint. We call these approaches static and
dynamic, respectively.
•
One can assume an arbitrary position, or that the position is constrained to the road network. We
label this off-road or on-road, respectively.
•
The RSS vector from the map can either be an average computed from ﬁeld tests, or based on generic
path loss models, such as the Okamura-Hata model. The latter gives a quite course ﬁngerprint map
compared to the ﬁrst one. We call these approaches OH and ﬁngerprinting, respectively.

3.07.5 Maps and Applications
287
(a) RMSE and CRLB for trajectory
(b) CRLB for whole area
FIGURE 7.17
(a) RMSE for test trajectory as a function of time, in comparison to the CRLB. (b) The CRLB as a function
of position, averaged over a set of straight line trajectories ending up at this spot. Figures from [27].

288
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
(a) Framework
(b) Mapped area
FIGURE 7.18
Framework of geolocation of cellular phones (a). The RSS map covers the highlighted road network from
three sites (b) (from [29]).
This gives in principle eight combinations, of which six ones are compared in Figure 7.20. The solid
line is the same. The plots show the position error cumulative distribution function (CDF), rather than
the averaged RMSE plots used otherwise. The reason is that the US FCC legislations for geolocation as
required in the emergency response system. The rules are speciﬁed for the two marked levels (horizontal
lines). For mobile-centric solutions, the error should be less than 50 m in 67% of all cases and less than
150 m in 95% of all cases.

3.07.5 Maps and Applications
289
(a)Site 1
(b)Site 2
(c) Site 3
FIGURE 7.19
RSS ﬁngerprint consists of the submaps from the available sites in the map. Figures from [29].
FIGURE 7.20
RSS ﬁngerprint consists of the submaps from the available sites in the map. Figures from [29].
Figure 7.20a shows that ﬁltering improves the tail compared to snapshot estimation in the case of
OH model for RSS. That is, ﬁltering avoids heavy tails in the position error. The on-road constraint
contributes signiﬁcantly to the performance. With ﬁltering, the FCC requirements are satisﬁed.
Figure 7.20b compares four different particle ﬁlters. It is here concluded that either the road constraint
or the RSS ﬁngerprint map should be used to get a signiﬁcant improvement over a solution based on
the OH model and arbitrary position. In that case, the FCC requirements are satisﬁed with margin.
3.07.5.6.2
Binary RSS measurements
A drawback with the continuous RSS map in the previous section is memory requirement. RSS is stored
as integers in [0,127] for a dense grid on the road network. An alternative described in [30], is to store
a binary value in larger grid areas. Figure 7.21 shows a binary dynamic ﬁngerprint for a test drive.
Figure 7.22a illustrates one grid area in the map. Each site serves two or three cells. The arrows
shows the probability to get an RSS measurement from each cell averaged over the whole grid area.
Figure 7.22b shows the cumulative density function when the algorithm is evaluated on a number of tests.

290
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
FIGURE 7.21
Example of dynamic ﬁngerprint for binary RSS measurements. Figure from [30].
3.07.5.7 Small migrating animals
Figure 7.23 shows how the sunset or sunrise at each time deﬁnes a manifold on earth [4]. A sensor
consisting of a light-logger and clock can detect these two events. This principle is applied in animal
geolocation [31] using lightweight sensor units (0.5 g). The theory of geolocation by light levels is
described in [6] for elephant seals, where sensitivity and geometrical relations are discussed in detail.
The accuracy of the geolocation is evaluated on different sharks by comparing to a satellite navigation
system, and the error is shown to be in the order of 1◦in longitude and latitude. The ﬁrst ﬁlter approach
to this problem is presented in [32], where a particle ﬁlter is applied.
The measurement model in the form of (7.1b) for the two events of sunset and sunrise, respectively, is
ysunset(tk) = hsunset(tk, Xk, Yk) + ek,
(7.31a)
ysunrise(tk+1) = h sunrise(tk+1, Xk+1, Yk+1) + ek+1.
(7.31b)
In this case, the measurement update (7.19a) in Algorithm 3 is
ω(i)
k|k = ω(i)
k|k−1 psunset
e

ysunset(tk) −h sunset(tk, Xk, Yk)

(7.32)
ω(i)
k+1|k+1 = ω(i)
k+1|k psunrise
e

ysunrise(tk+1) −h sunrise(tk+1, Xk+1, Yk+1)

.
Here, psunset
e
and psunrise
e
denote the probability density functions for the light events.

3.07.5 Maps and Applications
291
(a) Map for one area of interest
(b) CDF
FIGURE 7.22
(a) Illustration of binary RSS map averaged over an area. (b) Result of binary ﬁngerprinting. Compare with
the measurement sequence in Figure 7.21. Figures from [30].

292
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
FIGURE 7.23
Binary day-light model for a particular time t. The shape of the dark area depends on the time of the year,
and the horizontal position of the dark area depends on the time of the day.Source: Wikipedia.
If the animal is known to be at rest during the night, the two positions (Xk, Yk) = (Xl, Yl) can be
assumed the same, and the two unknowns can be solved from the two measurements uniquely, except
for the two days of equinox when the sun is in the same plane as the equator, and thus the two manifolds
in Figure 7.23 are vertical lines. Still, the PF gives useful information though the uncertainty in latitude
increases, see Figure 7.24.
3.07.6 Mapping in practice
Many of the maps described here are publically or commerically available. Highly accurate topographic
maps on dense grids are now available from satellite radar or laser measurements. Road maps and sea
charts over whole continents are also available, though still with some absolute errors. This error will
likely be corrected in the future based on aerial imagery and satellite measurements.
Maps of seaﬂoor and magnetic ﬁeld variations are still quite sparsely gridded, and not useful for
geolocation. In particular the magnetic ﬁeld, is time-varying, so regular updates of the map are required.
Cellular network maps of RSS or base station locations are also rapidly changing. Changes in the
environment also affect the RSS values, which is particular true in indoor scenarios.
Thus, there is a need for efﬁcient mapping algorithms that avoid manual tests to the largest possible
extent. There are two main principles:
•
Creating and adapting the map at the same time as performing geolocation. This approach is known
as simultaneous localization and mapping (SLAM) in literature [33,34].
•
Opportunistic reports from objects with a reference system.
Google Maps is an interesting project that illustrates two different principles for localization when GPS
is not available. If a known WLAN is detected, whose ID is found in a database, the geolocation is
based on the coverage of WLAN. The database is created by the company during street view campaigns.
Second, if no WLAN is detected, the strongest RSS from the cellular network is used. Again, the ID is

3.07.6 Mapping in Practice
293
FIGURE 7.24
Estimated path of a Swift from 298 sunsets and sunrises, respectively. The ellipsoids illustrate a conﬁdence
interval at selected days. Figure from [32].

294
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
FIGURE 7.25
Simultaneous geolocation of surface ships and generation of a sea chart. Figures from [35].
looked up in a map. This time, the map is created by users with GPS available. The map contains for
each ID a circle covering a large fraction of the GPS reports.
The SLAM approach is best illustrated with an example, here taken from [35]. The surface navigation
application based on radar scan matching to a sea chart in Section 3.07.5.5 is revisited, assuming that
there is no sea chart available. This might not be a relevant example in practice, but the idea is easily
extended to seaﬂoor mapping, earth magnetic ﬁeld mapping, indoor RSS mapping, etc.
Figure 7.25 shows the test trajectory (upper left), the boat (lower left) and the radar scans overlayed
on eachother to form a sea chart like map (right). Here, also the estimated ﬁrst half of the test trajectory
is plotted. No other information than the radar scans has been used, which shows that clever algorithms
can actually solve the complex mapping task autonomously.
3.07.7 Conclusion
Geolocation is the art of innovative combination of properties of nature and sensor technology. We have
provided a set of applications illustrating how different sensors and maps (geographical information
systems) can be used to compute geolocation. The particle ﬁlter has been used as a general method for
geolocation. Fingerprinting is a general concept for ﬁtting measurements (along a trajectory) to a map.
Acknowledgment
This work has been supported by the Swedish Research Council (VR) under the Linnaeus Center CADICS, the
VR project grant Extended Target Tracking and the SSF project Cooperative Localization.
Relevant Theory: Statistical Signal Processing and Machine Learning
See Vol. 1, Chapter 19 A Tutorial Introduction to Monte Carlo Methods, Markov Chain Monte Carlo and Particle
Filtering
See this Volume, Chapter 1 Introduction to Statistical Signal Processing
See this Volume, Chapter 4 Bayesian Computational Methods in Signal Processing

References
295
References
[1] S. Altizer, R. Bartel, B.A. Han, Animal migration and infectious disease risk, Science 331 (2011) 296–302.
[2] J.A. Muir, P.C. Van oorschot, Internet geolocation: evasion and counterevasion, ACM Comput. Surv. (CSUR)
42 (1) (2009).
[3] E. Katz-Bassett, J.P. John, A. Krishnamurthy, D. Wetherall, T. Anderson, Y. Chawathe, Towards IP geolocation
using delay and topology measurements, in: Proceedings of the Sixth ACM SIGCOMM Conference on
Internet, Measurement, 2006.
[4] J.H. Meeus, Astronomical Algorithms, Willmann-Bell, Inc., 1991.
[5] C. Tyren, Magnetic terrain navigation, in: Fifth International Symposium on Unmanned Untethered Sub-
mersible Technology, 1987.
[6] Roger D. Hill, Theory of geolocation by light levels, in: Burney J. Le Boeuf, Richard M. Laws (Eds.), Elephant
Seals: Population Ecology, Behavior, and Physiology, University of California Press, 1994.
[7] S.L.H. Teo, A. Boustany, S. Blackwell, A. Walli, K.C. Weng, B.A. Block, Validation of geolocation estimates
based on light level and sea surface temperature from electronic tags, Mar. Ecol. Prog. Ser. 283 (2004) 81–88.
[8] F. Gustafsson, F. Gunnarsson, Mobile positioning using wireless networks: possibilities and fundamental
limitations based on available wireless network measurements, IEEE Signal Process. Mag. 22 (2005) 41–53.
[9] L. Hui, H. Darabi, P. Banerjee, L. Jing, Survey of wireless indoor positioning techniques and systems, IEEE
Trans. Syst. Man Cybern. Part C Appl. Rev. 37 (6) (2007) 1067–1080.
[10] K. Pahlavan, L. Xinrong, J.P. Makela, Indoor geolocation science and technology, IEEE Commun. Mag. 40
(2) (2002) 112–118.
[11] Jouni Rantakokko, Joakim Rydell, Peter Stromback, Peter Handel, Jonas Callmer, David Törnqvist, Fredrik
Gustafsson, Magnus Jobs, Mathias Gruden, Accurate and reliable soldier and ﬁrst responder indoor position-
ing: multisensor systems and cooperative localization, IEEE Wirel. Commun. 18 (2) (2011) 10–18.
[12] F. Gustafsson, Statistical Sensor Fusion, Studentlitteratur, second ed., 2010.
[13] N. Bergman, Recursive Bayesian Estimation: Navigation and Tracking Applications, Dissertation no. 579,
Linköping University, Sweden, 1999.
[14] P. Tichavsky, C.H. Muravchik, A. Nehorai, Posterior Cramér-Rao bounds for discrete-time nonlinear ﬁltering,
IEEE Trans. Signal Process. 46 (5) (1998) 1386–1396.
[15] S.J. Julier, J.K. Uhlmann, Hugh F. Durrant-Whyte, A new approach for ﬁltering nonlinear systems, in: IEEE
American Control Conference, 1995, pp. 1628–1632.
[16] E.A. Wan, R. van der Merwe, The unscented Kalman ﬁlter for nonlinear estimation, in: Proceedings of IEEE
Symposium (AS-SPCC), pp. 153–158.
[17] I. Arasaratnam, S. Haykin, R.J. Elliot, Cubature Kalman ﬁlter, IEEE Trans. Autom. Control 54 (2009)
1254–1269.
[18] Fredrik Gustafsson, Gustaf Hendeby, Some relations between extended and unscented Kalman ﬁlters, IEEE
Trans. Signal Process. 60 (2) (2012) 545–555 (funding agencies—Swedish research council (VR)).
[19] F. Gustafsson, Particle ﬁlter theory and practice with positioning applications, IEEE Trans. Aerosp. Electron.
Mag. 7 (2010) 53–82.
[20] X.R. Li, V.P. Jilkov, Survey of maneuvering target tracking. Part I: dynamic models, IEEE Trans. Aerosp.
Electron. Syst. 39 (4) (2003) 1333–1364.
[21] T.B. Schön, F. Gustafsson, P.J. Nordlund, Marginalized particle ﬁlters for nonlinear state-space models, IEEE
Trans. Signal Process. 53 (2005) 2279–2289.
[22] N. Bergman, Posterior Cramér-Rao bounds for sequential estimation, in: A. Doucet, N. de Freitas, N. Gordon
(Eds.), Sequential Monte Carlo Methods in Practice, Springer-Verlag, 2001.
[23] U. Forssell, P. Hall, S. Ahlqvist, F. Gustafsson, Novel map-aided positioning system, in: Proceedings of
FISITA, No. F02-1131, Helsinki, 2002.

296
CHAPTER 7 Geolocation—Maps, Measurements, Models, and Methods
[24] N. Bergman, L. Ljung, F. Gustafsson, Terrain navigation using Bayesian statistics, IEEE Control Syst. Mag.
19 (3) (1999) 33–40.
[25] P.-J. Nordlund, F. Gustafsson, Marginalized particle ﬁlter for accurate and reliable terrain-aided navigation,
IEEE Trans. Aerosp. Electron. Syst. (2009).
[26] P. Skoglar, U. Orguner, D. Törnqvist, F. Gustafsson, in: IEEE Aerospace Conference, 2010.
[27] R. Karlsson, F. Gustafsson, Bayesian surface and underwater navigation, IEEE Trans. Signal Process. 54 (11)
(2006) 4204–4213.
[28] T. Karlsson, Terrain aided underwater navigation using Bayesian statistics, Master Thesis LiTH-ISY-EX-3292,
Dept. Elec. Eng., Linköping University, S-581 83 Linköping, Sweden, 2002.
[29] M. Bshara, U. Orguner, F. Gustafsson, L. Van Biesen, Fingerprinting localization in wireless networks based
on received signal strength measurements: a case study on wimax networks, 2010. <www.control.isy.liu.se/
fredrik/reports/09tvtmussa.pdf>.
[30] M. Bshara, U. Orguner, F. Gustafsson, L. VanBiesen, Robust tracking in cellular networks using HMM ﬁlters
and cell-ID measurements, 60 (3) (2011) 1016–1024.
[31] T. Alerstam, A. Hedenström, S. Åkesson, Long-distance migration: evolution and determinants, Oikos 103
(2) (2003) 247–260.
[32] Niklas Wahlström, Fredrik Gustafsson, Susanne Åkesson, A voyage to Africa by Mr. Swift, in: Proceedings
of 15th International Conference on Information Fusion, Singapore, July 2012.
[33] T. Bailey, H. Durrant-Whyte, Simultaneous localization and mapping (SLAM): Part II, IEEE Robot. Autom.
Mag. 13 (3) (2006) 108–117.
[34] H. Durrant-Whyte, T. Bailey, Simultaneous localization and mapping (SLAM): Part I, IEEE Robot. Autom.
Mag. 13 (2) (2006) 99–110.
[35] J. Callmer, D. Törnqvist, H. Svensson, P. Carlbom, F. Gustafsson, Radar SLAM using visual features,
EURASIP J. Adv. Signal Process. (2011).

8
CHAPTER
Performance Analysis and Bounds
Brian M. Sadler and Terrence J. Moore
Army Research Laboratory, Adelphi, MD, USA
3.08.1 Introduction
In this chapter we consider performance analysis of estimators, as well as bounds on estimation perfor-
mance. We introduce key ideas and avenues for analysis, referring to the literature for detailed examples.
We seek to provide a description of the analytical procedure, as well as to provide some insight, intuition,
and guidelines on applicability and results.
Bounds provide fundamental limits on estimation given some assumptions on the probability laws
and a model for the parameters of interest. Bounds are intended to be independent of the particular
choice of estimator, although any nontrivial bound requires some assumptions, e.g., a bound may hold
for some class of estimators, or may be applicable only for unbiased estimators, and so on.
On the other hand, given a speciﬁc estimation algorithm, we would like to analytically characterize
its performance as a function of the relevant system parameters, such as available data length, signal-
to-noise ratio (SNR), etc. Together, fundamental bounds and analysis of algorithms go hand in hand to
provide a complete picture.
We begin with the speciﬁc, examining the classic theory of parameterized probability models, and
the associated Cramér-Rao bounds and their relationship with maximum likelihood estimation. These
ideas are fundamental to statistical signal processing, and understanding them provides a signiﬁcant
foundation for general understanding. We then consider mean square error analysis more generally, as
well as perturbation methods for algorithm small-error analysis that is especially useful for algorithms
that rely on subspace decompositions. We also describe the more recent theory of the constrained
Cramér-Rao bound, and its relationship with constrained maximum-likelihood estimation.
We examine the case of a parameterized signal with both additive and multiplicative noise in detail,
including Gaussian and non-Gaussian cases. The multiplicative random process introduces signal vari-
ations as commonly arise with propagation through a randomly ﬂuctuating medium. General forms
for the CRB for estimating signal parameters in multiplicative and additive noise are available that
encompass many cases of interest.
We next consider asymptotic analysis, as facilitated by the law of large numbers and the central
limit theorem. In particular, we consider two fundamental and broadly applied cases, the asymptotics of
Fourier coefﬁcients, and asymptotics of nonlinear least squares estimators. Under general conditions,
both result in tractable expressions for the estimator distribution as it converges to a Gaussian.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00008-4
© 2014 Elsevier Ltd. All rights reserved.
297

298
CHAPTER 8 Performance Analysis and Bounds
Finally, we look at Monte Carlo methods for evaluating expressions involving random variables,
such as numerical evaluation of the Cramér-Rao bound when obtaining an analytical expression is
challenging. We close with a discussion of conﬁdence intervals that provide statistical evidence of
estimator quality, often based on asymptotic arguments, and can be computed from the given data.
3.08.2 Parametric statistical models
Let p(x; θ) denote an N-dimensional probability density function (pdf) that depends on the parameters
in the vector θ ∈Rm. The vector x is a collection of random variables. For example, suppose p(x; θ)
describes a normal distribution with independent and identically distributed (iid) elements each with
variance σ 2
x . Then the parameters describing the pdf are θ = [μT
x , σx]T , where E[x] = μx is the mean
vector. With the iid assumption, the covariance is completely determined by the scalar variance σ 2
x ;
see Section 3.08.2.1.4. Here, x = [x(0), x(1), . . . , x(N −1)]T are random variables from a normal
distribution with the speciﬁed mean and variance. In the 1-D case, such as a scalar time series x(n), the
random variables may be stacked into the vector x = [x(0), x(1), . . . , x(N −1)]T , and p(x; θ) is the
joint pdf of N consecutive observations of x(n).
When we have samples from the random process then we can think of the vector x as containing
a realization of the random process governed by the pdf; now the contents of x are also often called
the observations. This can be confusing because we have not altered the notation, but have altered our
interpretation of p(x; θ) to be a function of θ, with a given set of observations x regarded as ﬁxed and
known constants. In this interpretation, the pdf is called the likelihood function.
The functional description p(x; θ) is remarkably general, incorporating knowledge of the underlying
model via the functional dependence on the parameters in θ, and expressing randomness (i.e., lack of
speciﬁc knowledge about x) through the distribution. Much of the art of statistical signal processing
is deﬁning the model for a speciﬁc problem, expressed in p(x; θ), that can sufﬁciently capture the
essential nature of the observations, lead to tractable and useful signal processing algorithms, and
enable performance analysis. We seek the smallest dimensionality in θ such that the underlying model
remains sufﬁciently detailed to capture the behavior of the observations, while not over-parameterizing
in a way that adds too much complexity or unneeded model variation. It is important to keep in mind that
a model is a useful abstraction. Over-specifying the model may be as bad as underspeciﬁcation. While
a large number of parameters may be appealing to better ﬁt some observed data, the model can easily
lose generality and become too cumbersome to manipulate and estimate its parameters. On the other
hand, if the model is underspeciﬁed then it may be too abstract to capture essential behavior. All of this
motivates exploration of families of models and levels of abstraction. A key component of performance
analysis in this context is to explore the pros and cons of models in their descriptive power.
In statistical signal processing we are often interested in a signal plus noise model. Expressed in 1-D,
we have
x(n) = s(n; θ) + v(n),
n = 0, 1, . . . , N −1,
(8.1)
where s(n; θ) is a deterministic parameterized signal model, and v(n) is an additive random process
modeling noise and/or interference. The most basic assumptions typically begin with assuming v(n) are
samples from a stationary independent Gaussian process, i.e., additive white Gaussian noise (AWGN).

3.08.2 Parametric Statistical Models
299
AWGN is fundamental for several reasons; it models additive thermal noise arising in sensors and their
associated electronics, it arises through the combination of many small effects as described through the
central limit theorem, it is often the worst case as compared with additive iid non-Gaussian noise (see
Section 3.08.7), and Gaussian processes are tractable and fully speciﬁed by their ﬁrst and second-order
statistics. (We can generalize (8.1) so that the signal s(n; θ) is also a random process, in which case it is
also common to assume the noise is statistically independent of the signal.) Note that for E[v(n)] = 0,
then information about θ in the observations x(n) is contained in the time-varying mean s(n; θ). If
instead v(n) = v(n; θ) is a function of the parameters in θ, then there is information about θ in the
covariance of x(n). A fundamental extension to (8.1) incorporates propagation of s(n; θ) through a
linear channel, given by x(n) = h(n) ∗s(n; θ) + v(n) where ∗denotes convolution. The observation
model (8.1) is the tip of the iceberg for a vast array of models that incorporate aspects such as man-
made signals or naturally occurring signals, interference, and the physics of sensors and electronics.
Understanding of performance analysis for (8.1) is fundamental to these many cases.
Given observations x, let
t(x) = ˆθ
(8.2)
be an estimator of θ. Performance analysis primarily focuses on two objectives. First, we wish to ﬁnd
bounds on the possible performance of t(x), without specifying t(x). To do this we typically need some
further assumptions or restrictions on the possible form or behavior of t(x). For example, we might
consider only those estimators that are unbiased so that E[ˆθ] = θ. Or, we might restrict our attention
to the class of t(x) that are linear functions of the observations, so ˆθ = H x for some matrix H. The
second objective is to analyze the performance of a speciﬁc estimator. We are given a speciﬁc estimation
algorithm t0(x) and we wish to assess its performance. These two objectives are bound together, and
their combination provides a clear picture; comparing algorithm performance with bounds will reveal
the optimality or sub-optimality of the algorithm, and helps guide the development of good algorithms.
The most commonly applied algorithm and performance framework for parametric models is max-
imum likelihood estimation (MLE) and the Cramér-Rao bound (CRB). These are directly related, as
described in the following.
In the context of performance analysis, it can be useful to evaluate the MLE and compare it to the
CRB, even if the MLE has undesirably high complexity. This gives us a benchmark to compare other
algorithms against. For example, we might simplify our assumptions, or derive an approximation to the
MLE, resulting in an algorithm with lower complexity. We can then explore the complexity-performance
tradeoff in a meaningful way.
3.08.2.1 Cramér-Rao bound on parameter estimation
The Cramér-Rao bound (CRB) is the most widely applied technique for bounding our ability to estimate
θ given observations from p(x; θ). The basic deﬁnition is as follows. Suppose we have an observation
x in X ⊂Rn from the pdf p(x; θ) where θ is a vector of deterministic parameters in an open set
 ⊂Rm. The Fisher information matrix (FIM) for this model is given by
I(θ) = Eθ

s(x; θ)sT (x; θ)

,
(8.3)

300
CHAPTER 8 Performance Analysis and Bounds
where s(x; θ) is the Fisher score deﬁned by
s(x; θ) = ∂log p(x; θ′)
∂θ′

θ′=θ
(8.4)
and the expectation is evaluated at θ, i.e., Eθ(·) =

X (·)p(x; θ)dx. We assume certain regularity
conditions, namely that the pdf is differentiable with respect to θ and satisﬁes
∂
∂θ′T Eθ′(h(x))

θ′=θ
= Eθ(h(x)sT (x; θ))
(8.5)
for both h(x) ≡1 and h(x) ≡t(x) where t(x) is an unbiased estimator of θ [1]. Intuitively, existence
of the bound relies on the smoothness of the pdf in the parameters, and that the allowable range of the
parameters does not have hard boundaries where the derivatives may fail to exist. Regularity and the
assumption that θ is in an open set guarantee this.
Evaluation of I(θ) in (8.3) uses the product of ﬁrst derivatives of log p(x; θ). Note the condition in
(8.5) when h(x) = 1 permits us to substitute
−Eθ

∂
∂θ′T s(x; θ′)

θ′=θ

(8.6)
in (8.3), yielding
I(θ) = −Eθ

∂2
∂θ′∂θ′T log p(x; θ′)

θ′=θ

.
(8.7)
Equation (8.7) provides an alternative expression for the FIM in terms of second-order derivatives of
log p(x; θ), that in some cases may be easier to evaluate.
The regularity condition in (8.5) is assured when the Jacobian and Hessian of the density function
p(x; θ) are absolutely integrable with respect to both x and θ [2], and this essentially permits switching
the order of integration and differentiation. This is the most commonly assumed regularity condition,
although other scenarios can ensure regularity is satisﬁed. Under these assumptions, we have the fol-
lowing Cramér-Rao bound theorem (sometimes referred to as the information inequality) [1–4], that
was independently developed by Cramér [5] and Rao [6].
Given appropriate regularity conditions on p(x; θ) as above, the variance of any unbiased estimator
t(x) of θ satisﬁes the inequality
Var(t(x)) ≥I−1(θ),
(8.8)
if the inverse exists, and the variance is exactly I−1(θ) if and only if
I(θ)

t(x) −θ
	
= s(x; θ)
(8.9)
(in the mean-square sense). We refer to the inverse of the Fisher information matrix as the Cramér-Rao
bound and denote it as
CRB(θ) = I−1(θ),
(8.10)
where the CRB on the ith element of θ is given by the ith element of the diagonal of I−1(θ).

3.08.2 Parametric Statistical Models
301
3.08.2.1.1
CRB on transformations of the parameters
The performance of estimation of a function of the parameters, e.g., the transformation α = k(θ), is
often of more interest than the performance of direct estimation of the parameters. Note that α and θ
need not have the same dimension. If the Jacobian of the transformation function is K(θ) = ∂k(θ′)
∂θ′T

θ′=θ,
then the CRB on the performance of an unbiased estimator tα(x) of α is given in the following [1,4].
The variance of any unbiased estimator tα(x) of α = k(θ) satisﬁes the inequality
Var(tα(x)) ≥CRB(α) = K(θ)CRB(θ)K T (θ)
(8.11)
with equality if and only if tα(x)−α = K(θ)I−1(θ)s(x; θ) (in the mean-square sense). Equation (8.11)
relates the CRB on θ to the CRB on α by incorporating the Jacobian of the function k that transforms
θ to α. Implicit in (8.11) is that α is differentiable with respect to θ and (8.5) must also be satisﬁed for
h(x) ≡tα(x).
3.08.2.1.2
The bias-informed CRB
The CRB theory above applies only to unbiased estimates. But suppose we have a particular biased
estimator of θ, given by tb(x), with bias given by b(θ) = Eθ[tb(x) −θ]. We can use (8.11) to ﬁnd a
bound on α = θ + b(θ). Because tb(x) is an unbiased estimator of the function α = k(θ) = θ + b(θ),
it follows that
Var(tb(x)) ≥CRB(θ + b(θ)),
(8.12)
where
CRB(θ + b(θ)) =

Im + B(θ)
	
CRB(θ)

Im + BT (θ)

(8.13)
with B(θ) = ∂b(θ′)
∂θ′T

θ′=θ. We refer to (8.12) as the bias-informed CRB.
The bias-informed CRB only applies to the class of estimators with the speciﬁed bias gradient B(θ),
and does not provide a general bound for an arbitrary biased estimator. Because of this the bias-informed
CRB has limited use and has not found broad application. An approach that seeks to overcome this to
some extent is the uniform CRB, that broadens the applicability of the bias-informed CRB to the class
of estimators whose bias function is nearly constant over a region [7,8]. When a closed form is not
available the bias-gradient can be computed numerically, at least for problems that have relatively few
parameters [7].
3.08.2.1.3
A general CRB expression
The above results on parameter transformation and estimator bias are special cases of a combined
general CRB expression, given by
Var(t(x)) ≥CRB(α) = H(θ)I−1(θ)HT (θ),
(8.14)
where t(x) is an estimator of α = k(θ) with bias b(θ), I−1(θ) is the CRB matrix for estimating θ, and
H(θ) = K(θ) + B(θ)
(8.15)
isthesumoftheJacobianoftheparametertransformationandthebiasgradient.Thepreviousexpressions
then follow as special cases. For example, the CRB on estimation of α for unbiased estimators is given by

302
CHAPTER 8 Performance Analysis and Bounds
(8.11) with H(θ) = K(θ) since b(θ) = 0. Or, the CRB on estimation of θ with a biased estimator t(x)
whose bias is b(θ), is given by (8.12) with H(θ) = I + B(θ) since there is no parameter transformation
(i.e., k(θ) = θ is the identity transformation). When introducing the CRB, some texts begin with (8.10),
whereas others begin with (8.14) or one of the variations.
3.08.2.1.4
Normal distributions
Whenthedensityfunction p(x; θ)isGausian,denoted x ∼N(μ(θ), (θ)),thentheCramér-Raobound
is completely characterized by the dependence on the parameter θ of the mean μ(θ) and covariance
(θ). Assuming differentiability with respect to θ, then the CRB can be evaluated in terms of otherwise
arbitrary functions for the mean μ(θ) and covariance (θ), and the CRB is given by the Slepian-Bangs
formula [9,10],

I(θ)

i j = ∂μT (θ′)
∂θ′
i
−1(θ′)∂μ(θ′)
∂θ′
j
+ 1
2tr

−1(θ′)∂(θ′)
∂θ′
i
−1(θ′)∂(θ′)
∂θ′
j

θ′=θ
.
(8.16)
There are many examples of application of (8.16), e.g., see Kay [4]. When the signal plus Gaussian
noise model of (8.1) holds, then covariance  is not a function of θ, and the second term in (8.16)
vanishes.
3.08.2.1.5
Properties of the CRB
We discuss some properties and interpretation of the CRB.
• CRB existence and regularity conditions: An example where the CRB does not exist due to violation
of the regularity conditions occurs when estimating the parameters of a uniform distribution. Specif-
ically, suppose we have observations x(n) from a uniform distribution on [0, θ], and we seek the
CRB on estimation of θ. Now, the regularity conditions do not hold and the CRB cannot be applied.
This is a classic text book example, see Kay [4, Problem 3.1].
• The CRB is a local bound: As we know from basic calculus, the second derivative corresponds to the
curvature or concavity of the function at a point on the curve. Thus the CRB, evaluated at a particular
value of the parameter θ, can be interpreted as the expected value of the curvature of the likelihood
around the parameter. This is an important interpretation since the curvature measure is local, and
consequently the CRB is often referred to as a local bound. We remark on this point again when
considering the asymptotic behavior of the MLE in the next section. Because it is a local bound the
CRB at a parameter value θ0 gives us a tight lower bound on the variance of any unbiased estimator
of θ0 only when the estimation errors are small. Depending on the particular scenario, this might
correspond to obtaining a large number of observations, or a high signal-to-noise ratio (SNR). This
also means that the CRB can be a loose lower bound for the opposite cases, when the number of
observations is low, or at low SNR.
• Effect of adding parameters: If an additional parameter is brought into the model, so that the dimen-
sion of θ grows by one, then the bound on the previously existing parameters will remain the same
or rise. It will remain the same if the new parameter is decoupled from the previous parameters in
the model. Or, if the parameters are coupled, the bound can only increase. Intuitively, this is because
the introduction of a new unknown into the model can only increase uncertainty, implying more

3.08.3 Maximum Likelihood Estimation and the CRB
303
difﬁculty in obtaining accurate parameter estimates, and hence a larger bound. The proof relies on
linear algebra and is a standard textbook problem, e.g., see Kay [4, Problem 3.11].
• Not necessarily a tight bound: Generally there is no guarantee that an estimator exists that can achieve
the CRB. More typically, under certain conditions the MLE can be shown to asymptotically achieve
the CRB, but there is no guarantee this will occur with ﬁnite data; see the discussion below on the
MLE in Section 3.08.3. Other bounds exist that may be tighter than the CRB in the non-asymptotic
region, such as bounding the mean square error; see Section 3.08.4.
• Identiﬁability: Given the parametric model, we would like the distribution function to be distin-
guishable by the choice of the parameters. In other words, we want a given pdf p(x; θ) to be unique
on some non-zero measurable set for different choices of θ. If not, e.g., supposing θ1 ̸= θ2 yet
p(x; θ1) = p(x; θ2) for almost every x ∈X, then we cannot uniquely infer anything about the
parameters even with an inﬁnite number of observations. This is the problem of identiﬁability. While
there are various deﬁnitions and contexts for identiﬁability, here we can note that a fundamental
requirement for the existence of the CRB is that the Fisher information matrix be full rank so that it’s
inverseexists. GenerallynonsingularityintheFIM evaluatedat thetruevalueof theparameter implies
identiﬁability locally about the parameter [11], reﬂecting the fact that the CRB is a local bound gov-
erned by the local smooth behavior of the pdf. For example, for the Gaussian pdf case, Hochwald and
Nehorai showed there exists a strong link between identiﬁability and nonsingularity in the FIM [12].
Consider scalar cases such as x = a · b + v, or x = a + b + v, where ν is additive Gaussian noise
and we wish to ﬁnd the CRB on estimation of a and b. For both examples we ﬁnd that the FIM is not
full rank, hence the CRB does not exist. Studying the models for the observation x, it is apparent that
we cannot uniquely identify the parameter(s). This situation can be resolved if there is additional
information in the form of equality constraints on the parameters; see Section 3.08.6.
• Biased estimators: It can happen that the MLE is a biased estimator, even with inﬁnite data. An
interesting example is the estimation of the covariance of a multivariate normal distribution. Given
x ∼N(μ(θ), (θ)), the maximum likelihood estimator for (θ) is the sample covariance using
observations of x. However, it has been shown that this estimate is biased, and so the CRB does
not bound the MLE in this case, e.g., see Chen et al. [13]. For more on biased estimators see Sec-
tions 3.08.2.1.2 and 3.08.4.
• Estimation versus classiﬁcation bounds: The CRB bounds continuous estimation of a continuous
parameter. In this case perfect (zero-error) estimation is not possible. Suppose instead the parameter
is drawn from a ﬁnite set, e.g., we draw from a ﬁnite alphabet for communicating symbols. Now,
the parameter is discrete valued, and perfect estimation is possible. In such a case the CRB goes
to zero; it is uninformative. The problem is now one of classiﬁcation, rather than estimation, and
a classiﬁcation bound is needed for performance analysis, such as bit error rate bounds in digital
communications [14,15].
3.08.3 Maximum likelihood estimation and the CRB
The CRB provides a lower bound on the variance of any unbiased estimator, subject to the regularity
conditions on p(x; θ). Next we consider the maximum-likelihood estimator, which has the remarkable

304
CHAPTER 8 Performance Analysis and Bounds
property that under some basic assumptions the estimate will asymptotically achieve the CRB, and
therefore achieves asymptotic optimality.
The maximum likelihood approach to estimation of θ chooses as an estimator tML(x) = ˆθML
that, if true, would have the highest probability (the maximum likelihood) of resulting in the given
observations x. Thus, the MLE results from the optimization problem
tML(x) = ˆθML = arg max
θ
log p(x; θ),
(8.17)
where for convenience log p(x; θ) may be equivalently maximized since log (·) is a monotonic trans-
formation. Previously we thought of θ as ﬁxed constants in the pdf p(x; θ). Now, in (8.17), we are given
observations x and regard p(x; θ) as a function of θ. In this case p(x; θ) is referred to as the likelihood
function.
Using basic optimization principles, a solution of (8.17) follows by solving the equations resulting
from differentiating with respect to the parameters and setting these equations equal to zero. The
derivatives of the log-likelihood are the Fisher score previously deﬁned in (8.4), so the ﬁrst-order
conditions for ﬁnding the MLE are solutions ˆθML of
s(x; θ′) = 0.
(8.18)
Applying (8.18) requires smoothness in the parameters so that the derivatives exist. The parameters
lie in a (possibly inﬁnite) set, denoted θ ∈. Then, assuming the derivatives exist and provided 
is an open set, ˆθML will satisfy (8.18). Intuitively, the solution to (8.18) relies on the smoothness of
the function in the parameters, and the parameters themselves do not have hard boundaries where the
derivatives may fail to exist. This is similar to the assumptions needed for the existence of the CRB on
θ; see the discussion in Section 3.08.2.1.
The principle of maximum likelihood provides a systematic approach to estimation given the para-
metric model p(x; θ). If (8.18) cannot be solved in closed form, we can fall back on optimization
algorithms applied directly to (8.17). Many sophisticated tools and algorithms have been developed for
this over the past several decades. Very often the maximization is non-convex, although our smoothness
conditions guarantee local convexity in some neighborhood around the true value for θ, so algorithms
often consist of ﬁnding a good initial value and then seeking the local maximum.
If the parameters take on values from a discrete set then the assumptions on the solution of (8.18)
are violated. However, the MLE may still exist although estimation will generally rely directly on
(8.17). Note that in this case we have a classiﬁcation rather than an estimation problem: choose θ
from a discrete set of possible values that provides the maximum in (8.17). Consequently, the CRB
is not applicable and performance analysis will rely on classiﬁcation bounds; see the comment in
Section 3.08.2.1.5.
3.08.3.1 Asymptotic normality and consistency of the MLE
As we noted, the MLE has a fundamental link with the CRB, as described next. Let the samples
x1, x2, . . . , xn be iid observations from the pdf p(x; θ). Denote yn = (x1, x2, . . . , xn) to be the
collection of these samples. Then, the likelihood is given by p(yn; θ) = n
i=1 p(xi; θ), and we denote
the maximum likelihood estimate from these samples as tML(yn) = ˆθML(yn).

3.08.4 Mean-Square Error Bound
305
Assuming appropriate regularity conditions on the pdf p(x; θ) hold, such as described above, then
the MLE of the parameter θ is asymptotically distributed according to
√n

ˆθ(yn) −θ

d→N 
0, I−1(θ)
	
,
(8.19)
where I(θ) is derived from the pdf p(x; θ), i.e., it is the Fisher information of a single observation or
sample, and
d→denotes convergence in distribution.
This remarkable property states that the MLE is asymptotically normally distributed as observation
sizengoestoinﬁnity,isunbiasedsothat ˆθML(yn)convergestoθ inthemean,andhascovariancegivenby
the CRB. Thus, the MLE is asymptotically optimal because the CRB is a lower bound on the variance of
anyunbiasedestimator.Intuitively,theasymptoticnormaldistributionoftheestimateoccursduetoacen-
tral limit theorem effect. Note that only general regularity conditions (e.g., smoothness) are required on
p(·) for this to (eventually) be true. We discuss the central limit theorem more generally in Section 3.08.8.
Equation (8.19) shows that the MLE is consistent. A consistent estimator is one that converges in
probability to θ, meaning that the distribution of ˆθML(yn) becomes more tightly concentrated around
θ as n grows. In the speciﬁc case of the MLE, as n grows the distribution of the estimator converges to
a Gaussian distribution with mean given by the true parameter and covariance given by the CRB, and
this distribution is collapsing around the true value as we obtain more observations. If the mean of ˆθML
were not equal to the true value of θ, then the estimator would be converging to the wrong answer. And,
since the variance of the MLE converges to the CRB, we are assured that the MLE is asymptotically
optimal, implying that as the data size becomes large no other estimator will have a distribution that
collapses faster around the true value.
3.08.4 Mean-square error bound
As we have noted the CRB is only valid for unbiased estimators, whereas we may have an estimator
that is biased. If the bias is known and we can compute its gradient then we can use the bias-informed
CRB, but as we noted this is rarely the case. More generally we may be interested in analyzing the bias-
variance tradeoff, for example with ﬁnite data an estimator may be biased even if it is asymptotically
unbiased and approaches the CRB for large data size. This naturally leads to the mean-square error
(MSE) of the estimator, given by
MSE(t(x)) = Eθ

t(x) −θ)
	 
t(x) −θ
	T 
.
(8.20)
The variance and the MSE of the estimator t(x) are easily related through
MSE(t(x)) = Var(t(x)) + b(θ)bT (θ),
(8.21)
and they are equivalent in the unbiased case, so that if t(x) is unbiased then the CRB bounds both the
variance and the MSE. If the estimator remains biased even as the observation size grows, then the MSE
may become dominated by the bias error asymptotically.
Study of the MSE can be valuable when relatively fewer observations are available. In this regime
an estimator may trade off bias and variance, with the goal of minimizing the MSE. It may be tempting
to say that a particular biased estimator is “better” than the CRB when MSE(t(x)) < Var(t(x)), but

306
CHAPTER 8 Performance Analysis and Bounds
the CRB only bounds unbiased estimators; it is better to refer to Eqs. (8.20) or (8.21) that quantify the
relationship. Ultimately, as the number of observations grows, then it is desired to have the estimate
become unbiased and the variance of the estimator diminish, otherwise the estimator will asymptotically
converge to the wrong answer.
The MSE and bias-variance tradeoff is also valuable for choosing a particular model, e.g., see Spall
[16, Chapter 12].
In Section 3.08.2.1.5, when discussing biased estimators, we noted that the MLE for the covariance
of a multivariate normal distribution is just the sample covariance, and that in this case the MLE is a
biased estimator. In addition, the sample covariance is not a minimum MSE estimator for this problem,
in the sense of minimizing the expected Frobenius norm squared of the error matrix. In fact, a lower
MSE can be obtained by the James-Stein estimator, that uses a shrinkage-regularization estimation
technique [13,17]. This example illustrates that the maximum likelihood estimator is not necessarily
guaranteed to achieve the minimum MSE among biased or unbiased estimators.
3.08.5 Perturbation methods for algorithm analysis
Perturbation methods provide an approach to small-error analysis of algorithms. This is a close relative
of using a Taylor expansion and dropping higher order terms. Consequently, perturbation analysis is
accurate for larger data size, and so can be thought of as an asymptotic analysis, and it will generally
predict asymptotic performance. The idea has been broadly applied, especially for cases when the
estimationalgorithmisahighlynonlinearfunctionofthedataand/orthemodelparameters.Animportant
application area occurs when algorithms incorporate matrix decompositions, such as subspace methods
in array processing. However, we emphasize that the ideas are general and can be readily applied in
many scenarios.
3.08.5.1 Perturbations and statistical analysis
Thegeneralideaisasfollows.Astatisticalperturbationerroranalysisconsistsoftwobasicsteps.Theﬁrst
is a deterministic step, adding small perturbations into the model at the desired place. The perturbations
can be applied to the original data such as occurs with additive noise. But, the perturbations can also be
applied at other stages, such as perturbing the estimate itself. The perturbed model is then manipulated
to obtain an expression for the estimation error as a function of the perturbations, where (typically)
only the ﬁrst order perturbation terms are kept, and terms that involve higher order functions of the
perturbation are dropped under the assumption that they are negligible. The second step is statistical.
We now assume the perturbations are random variables drawn from a stationary process with ﬁnite
variance (typically zero-mean), and proceed to evaluate the statistics of the estimation error expression.
This typically involves the mean and variance of the ﬁrst-order perturbed estimation error expression.
Let ˆθ be an estimator of parameters θ, which we write as ˆθ = θ + θ, where θ is a small
perturbation. Therefore, we have the simple estimation error expression
θ = ˆθ −θ.
(8.22)
To quantify the error in the estimator, we wish to ﬁnd quantities such as the mean and variance of the
estimation error expression. Thus we treat θ as samples from a stationary random process, commonly

3.08.5 Perturbation Methods for Algorithm Analysis
307
assumed to be zero-mean independent and identically distributed; it is not necessary to specify the pdf
of the perturbation. The important point is that when deriving (8.22) for the speciﬁc estimator of interest
we make use of the small error assumption and keep only ﬁrst-order terms in θ. Derivation of (8.22)
is the primary hurdle to this analytical approach, so that we can evaluate Eθ[ˆθ −θ] and Varθ(ˆθ −θ).
If Eθ[ˆθ −θ] = 0 then the algorithm is unbiased for small error (this may mean the algorithm is
asymptotically unbiased).
The perturbation method is appealing when an algorithm is biased. If Eθ[ˆθ −θ] ̸= 0 then we can
use it with Varθ(ˆθ −θ) to ﬁnd the MSE in Eq. (8.21). This enables study of the bias-variance tradeoff,
for cases where the CRB does not apply due to the estimator bias. For example, the perturbation method
has been applied to geolocation based on biased range measurements, such that the estimation of the
source location is inherently biased [18].
While the accuracy of ﬁrst order perturbation analysis is generally limited to the high SNR and/or
large data regime, the perturbation method can be broadened by considering second-order terms, as
developed by Xu for subspace methods [19]. The resulting error expressions now contain more terms,
but the resulting analyses are more accurate over a larger range of SNR and data size (roughly speaking,
the second-order analyses are accurate for moderate to large SNR or data size).
3.08.5.2 Matrix perturbations
As we noted an important application of these ideas is for algorithms that involve matrix decomposi-
tions. These algorithms are typically not very amenable to error analysis because the estimation error
expression becomes highly nonlinear in the parameters of interest. Instead, we can apply a perturbation
to the matrix and then study the effect of the perturbation after the matrix decomposition.
Suppose we have an m × n matrix A = A(θ), that is input to an algorithm for estimating some
parameters θ. Often an algorithm includes an eigendecomposition of A (for m = n), or more generally
with a singular value decomposition (SVD) of A (for m ̸= n). To carry out the ﬁrst step in the perturbation
based analysis, we would like to express the matrix decomposition as a function of a perturbation on A.
Let ¯A = A + A be a perturbed version of A, where A is small. Regarding A as deterministic,
Stewartdevelopedexpressionsformanyimportantcases,carryingtheperturbationsalong. Theseinclude
the eigenvalues of A, the singular values of A, the subspaces of A, as well as the pseudo-inverse of A,
projections, and linear least squares algorithms [20–22]. These expressions generally rely on keeping
only ﬁrst-order terms in A, and dropping higher-order terms under the assumption that A is small,
where here small is meant in the sense of some appropriate matrix norm [22].
If an estimation algorithm is a function of A and involves subspace decomposition say, then we
can use the expressions from Stewart in our approach. Given the perturbed subspace, we then ﬁnd the
estimation error expression, that is now a function of A, again keeping only the ﬁrst order terms.
The analysis is then completed by ﬁnding the statistical properties of the error, such as mean and
variance.
Many array processing methods rely on subspace decomposition and eigenvalue expressions [23],
and consequently the perturbation ideas have been broadly applied to develop small error analysis [24].
Perturbations can be applied to the data, or to the estimated spatial covariance matrix, for example [19].
These applications typically use complex values, and the perturbation ideas readily go over from the
real-valued to the complex-valued case.

308
CHAPTER 8 Performance Analysis and Bounds
3.08.5.3 Obtaining the CRB through perturbation analysis of the MLE
An important special case is the application of perturbation analysis to the MLE. Now, under the
conditions for which the MLE is consistent, i.e., is asymptotically unbiased and attains the CRB, then
the perturbation approach can yield the CRB by ﬁnding the variance of the estimation error expression as
above. This follows because we are carrying out a small error (asymptotic) analysis for an algorithm that
is asymptotically guaranteed to achieve a variance that is equal to the CRB. For examples, see [18,25].
3.08.6 Constrained Cramér-Rao bound and constrained MLE
In this section we show how the classic parametric statistical modeling framework from Sections 3.08.2
and 3.08.3, including the CRB and MLE, can be extended by incorporating additional information in
the form equality constraints. We make the same assumptions as in Section 3.08.2, given observations
x ∈X ⊂Rn from a probability density function p(x; θ) where θ ∈ ⊂Rm is a vector of unknown
deterministic parameters. Suppose now that these parameters satisfy k consistent and nonredundant
continuously differentiable parametric equality constraints. These constraints can be expressed as a
vector function f (θ) = 0 for some f :  →Rk. Equivalently, the constraints can also be stated
θ ∈ f , i.e., the equality constraints act to restrict the parameters to a subset of the original parameter
space. The constraints being consistent means that the set  f is nonempty, and the constraints being
nonredundant means that the Jacobian F(θ′) = f (θ′)
∂θ′T has rank k whenever f (θ′) = 0.
The presence of the constraints provides further speciﬁc additional information about the model
p(x; θ), expressed functionally as f (θ′) = 0. Equivalently, in addition to obeying p(x; θ) the parame-
ters are also restricted to live in  f . Intuitively, we can expect that more accurate estimation should be
possible,andthatwecanincorporatetheconstraintsintobothperformanceboundsandestimators.Thisis
the case, and we detail the extension of the CRB and MLE to incorporate the constraints in the following.
3.08.6.1 Constrained CRB
The following relates the Fisher information I(θ) for the original unconstrained model p(x; θ), to a new
bound on θ that incorporates the constraints [26, Theorem 1]. Let t(x) be an unbiased estimator of θ,
where in addition equality constraints are imposed as above so that θ ∈ f , or equivalently f (θ) = 0.
Then
Var(t(x)) ≥CCRB(θ) = U(θ)

UT (θ)I(θ)U(θ)
−1
UT (θ),
(8.23)
where U(θ) is a matrix whose column vectors form an orthonormal basis for the null space of the
Jacobian F(θ), i.e.,
F(θ)U(θ) = 0, UT (θ)U(θ) = I(m−k)×(m−k).
(8.24)
In (8.24), I(m−k)×(m−k) is an (m −k) × (m −k) identity matrix (not to be confused with the Fisher
information matrix I(θ)). Equation (8.23) deﬁnes the constrained Cramér-Rao bound (CCRB) on θ.
Equality in the bound is achieved if and only if t(x) −θ = CCRB(θ) s(x; θ) (in the mean-square
sense), where s(x; θ) is the Fisher score deﬁned in (8.4). This is similar to the condition for achieving
equality with the CRB noted earlier.

3.08.6 Constrained Cramér-Rao Bound and Constrained MLE
309
The CCRB can be extended to bound transformations of parameters, just as for the CRB in
Section 3.08.2.1.1. Consider a continuously differentiable function of the parameters k :  f →Rq
and denote its Jacobian as K(θ) = ∂k(θ′)
∂θ′T

θ′=θ. Given constraints f (θ) = 0, then the variance of any
unbiased estimator t(x) of α = k(θ) satisﬁes the inequality
Var(t(x)) ≥CCRB(α) = K(θ)CCRB(θ)K T (θ).
(8.25)
This extends the CCRB on θ to the parameters α = k(θ), and has a form similar to (8.11).
3.08.6.2 Comments and properties of the CCRB
• Existence and regularity conditions: It is important to recognize that the CCRB relies on the Fisher
information I(θ) expressed through the probability density p(x; θ). We have not altered the con-
struction of the Fisher score or FIM in (8.4) and (8.3). The constraints are regarded as additional
side information, resulting in the CCRB.
Note that the CCRB does not require I(θ) be nonsingular, but does require that UT (θ)I(θ)U(θ)
be nonsingular. Thus the addition of constraints can lead to a meaningful bound on estimation even
when the original model is not identiﬁable. For example, constraints can lead to bounds on blind
estimation problems [26,27].
• Constrained estimators versus constrained parameters: Stoica and Ng actually developed a bound for
an unbiased, constrained estimator, as opposed to a bound for an unbiased estimator of constrained
parameters [26]. This is an important distinction since, in general, a parameter and its unbiased
estimator will not simultaneously satisfy a constraint. The conditions for when this does occur,
i.e., when f (Eθ t(x)) = Eθ f (t(x)), are the equality conditions for Jensen’s inequality. Many of
the citations of Stoica and Ng mistakenly apply the bound to the case of constrained parameters.
Fortunately,theresultundereitherassumptionisthesameCCRBexpression,eveniftheinterpretation
is different [28].
• Reparameterizing the model: An equally valid approach to bounding estimation performance is to
reparameterize the pdf in a way that incorporates the constraints, resulting in a distribution p(x; θ′)
with new parameter vector θ′. Then the Fisher information I(θ′) can be obtained for the reparam-
eterized model, and the CRB results in Section 3.08.2 can be applied to bound estimation of θ′ or
functions of θ′. Obviously I(θ′) ̸= I(θ), and it often happens that the dimension of θ′ is less than the
dimension of θ because the constraints amount to a manifold reduction by requiring  ∈ f [29].
However, reparameterizing the model into p(x; θ′) can often be analytically impractical or numer-
ically complex. The CCRB offers an alternative way to incorporate parametric equality constraints
into the CRB and, for example, enables comparison of a variety of constraints in a straightforward
way.
• Inequality constraints: The CCRB directly incorporates equality constraints. In some problems, the
parameters are speciﬁed to obey inequality constraints. In such a case, the conventional CRB applies
so long as the speciﬁed value of θ obeys the inequality, and so is a feasible value.
• Evaluating the CCRB: Evaluating the CCRB requires evaluating F(θ), which is typically straight-
forward analytically, and then ﬁnding the nullspace basis U(θ) (and note that U(θ) is not unique).
The matrix U(θ) may be found analytically, or it can be readily computed numerically, e.g., using
standard software packages.

310
CHAPTER 8 Performance Analysis and Bounds
3.08.6.3 Constrained MLE
Just as the CRB is intimately related with maximum-likelihood estimation, the CCRB is related with
constrained maximum-likelihood estimation (CMLE). The CMLE ˆθCML solves the constrained opti-
mization problem given by
arg max
θ′
log p(x; θ′)
s.t.
f (θ′) = 0.
(8.26)
We can also show that given appropriate smoothness conditions, ˆθCML converges in distribution to
N(θ, CCRB(θ). Thus, asymptotically, the CMLE becomes normally distributed with mean equal to
the true parameter and covariance given by the CCRB. This is analogous to the classic results for the
MLE in (8.19). For derivations and details, including CMLE cast as a constrained scoring algorithm,
see Moore et al. [30].
3.08.7 Multiplicative and non-Gaussian noise
In this section we consider two broad generalizations of the signal plus additive noise model in (8.1),
multiplicative noise on the signal, and allowing the noise distributions to be non-Gaussian. For clarity
we focus on the one-dimensional time series case, and show general CRB results. This model is broadly
applicable and widely studied in many disciplines, for both man-made and naturally occurring signals.
3.08.7.1 Multiplicative and additive noise model
The signal and noise observation model in one dimension is given by
y(n) = m(n)s(n; θ) + w(n),
n = 0, . . . , N −1,
(8.27)
where s(n; θ) is a signal parameterized by θ, and m(n) and w(n) are stationary random processes.
We denote E[m(n)] = μm and Var{m(n)} = σ 2
m, and similarly for w(n) we have μw and σ 2
w. With
m(n) ≡1 we revert to (8.1).
Including m(n) in the model introduces random amplitude and phase ﬂuctuations into the signal, and
so is often referred to as multiplicative noise [31]. Some important applications include propagation in
a randomly ﬂuctuating medium such as aeroacoustic signals in a turbulent atmosphere [32], underwater
acoustics [33], radar Doppler spreading [34], and radio communications fading due to the superposition
of multipath arrivals (such as Rayleigh-Ricean distributions) [15]. The model can be generalized to
y(n) = h(n) ∗s(n; θ) + w(n), where h(n) is the impulse response of a linear ﬁlter and ∗represents
convolution, and h(n) can be modeled as having random elements.
The rate of variation in m(n) can be slow or fast relative to the signal bandwidth and the observation
time. A constant but random complex amplitude is an important special case of time-varying multi-
plicative noise, e.g., so-called ﬂat fading, such that each block realization of y(n), n = 0, 1, . . . , N −1,
has a scalar random coefﬁcient m(n) ≡m. At the other extreme, fast variation in m(n) can play havoc
in applications, e.g., fast fading in communications, that can yield dramatic signal distortion and thus
can signiﬁcantly degrade estimation of θ.

3.08.7 Multiplicative and Non-Gaussian Noise
311
3.08.7.2 Gaussian case
A Gaussian model for m(n) is reasonable for many applications, such as those mentioned above.
Propagation distortion is often the result of many small effects, culminating in a Gaussian distribution.
It is typically assumed that m(n) and w(n) are independent, arising from separate physical mechanisms,
such as ﬂuctuation caused by propagation combined with additive sensor noise.
Suppose m(n) and w(n) are iid Gaussian. Now y(n) is Gaussian and non-stationary, with mean and
variance given by
E[y(n)] = μy(n) = μms(n; θ) + μw
(8.28)
and
σ 2
y (n) = σ 2
ms2(n; θ) + σ 2
w.
(8.29)
With E[m(n)] = 0 then y(n) becomes stationary in the mean, but μm = 0 is generally undesirable,
and from the standpoint of detection and estimation of s(n; θ) large |μm| is much preferred. It is often
assumed that μw = 0, which is reasonably safe because in practice μw can be estimated and subtracted
from y(n). However, it should not be assumed that the multiplicative noise has mean μm = 0 if in fact
it does not.
For real-valued y(n) several cases of the FIM and CRB are derived by Swami in [35]. In the iid
Gaussian case, with μw = 0, then the parameter vector of size p + 4 is given by
θ = [θs, σ 2
m, σ 2
w, μm],
(8.30)
where θs are the p + 1 signal parameters from s(n; θs). Now, the elements of the Fisher information
matrix Ii j, i, j = 0, 1, . . . , p + 3 are given by [35, Eqs. (4) and (5)]. Several foundational results are
available in [35], including a polynomial signal model for s(n; θ), as well as the iid non-Gaussian noise
case (see Section 3.08.7.3).
Speciﬁc signal models and estimators that have been addressed for the multiplicative and additive
noise model include non-linear least squares estimation of sinusoids [36,37], the CRB for change point
detection of a step-like signal [38], and Doppler shift [34,39]. Estimation of a single harmonic in
multiplicative and additive noise arises in communications, radar, and other applications and has been
studied extensively (e.g., see references in the above citations).
3.08.7.3 Non-Gaussian case
Next we consider the case when m(n) and w(n) in (8.27) may be non-Gaussian. While AWGN may
always be present to some degree there are times when the central limit theorem is not applicable, such
as a structured additive interference that is signiﬁcantly non-Gaussian, and in such a case we might rely
on a non-Gaussian pdf model for w(n). For example, some electromagnetic interference environments
are well modeled with a non-Gaussian pdf that has tails signiﬁcantly heavier than Gaussian [40]. The
study of the heavy-tailed non-Gaussian case is also strongly motivated to model the presence of outliers,
leading to robust detection and estimation algorithms [41].
Let pm(m) and pw(w) denote the respective pdf’s of m(n) and w(n) in (8.27). Closed forms for
py(y) are typically not available, and it is difﬁcult to obtain general results for the case when both m(n)
and w(n) are present and at least one of them is non-Gaussian. However, following Swami [35], we can
at least treat them separately as follows.

312
CHAPTER 8 Performance Analysis and Bounds
Consider (8.27) with m(n) a random constant so that E[m(n)] = μm, and Var{m(n)} = σ 2
m = 0.
Let pw(w) be a symmetric, not necessarily Gaussian pdf, and assume that w(n) is iid. Now, the FIM
for θ has elements given by [35, Eq. (21)]
Ii j = γw0
μ2
m
σ 2w
N−1

n=0
∂s(n; θ)
∂θi
∂s(n; θ)
∂θ j
,
i, j = 0, 1, . . . , p,
(8.31)
where dim(θ) = p + 1, θi is the ith element of θ, and we deﬁne [35, Eq. (20)]
γxk =
1
σ k−2
x
 dpx(x)
dx
2 (x −μx)k
px(x)
dx,
(8.32)
where x indicates the random variable with pdf px(x), and k is integer with k = 0 in (8.31). Thus the
FIM I depends on pw(w) through its variance σ 2
w and the value of γw0. In the Gaussian case γw0 = 1, and
(8.31) is well known, e.g., see Kay [42, Chapter 3]. For any symmetric px(x) it follows that γx0 ≥1,
so that non-Gaussian pw(w) increases the Fisher information (i.e., lowers the CRB), and therefore
AWGN is the worst case for estimating θ. For example, the CRB for estimation of the parameters of an
autoregressive process is minimized when the process is Gaussian [43]. On the other hand, it is often
the case in practice with non-Gaussian noise that the exact form of the pdf is not known, so it may be
necessary to estimate both the signal parameters and the parameters of a non-Gaussian pdf model.
The impact of non-Gaussian pm(m) can be studied by setting σ 2
w = 0. This purely multiplicative
noise case has Fisher information given by [35, Eq. (25)]
Ii j =

γm2 + 2μmγm1
σm
+ μ2
mγm0
σ 2m
−1
 N−1

n=0
∂s(n; θ)
∂θi
∂s(n; θ)
∂θ j
1
s2(n; θ).
(8.33)
The FIM now depends on pm(m) entirely through the ﬁrst bracketed term in (8.33). This term is a
function of the ratio μm/σm, and γmk, k = 0, 1, 2. Note that information is lost when μm = 0, and that
large μm/σm is desired to increase the FIM. Intuitively, when μm ≫σm, then the observed random
ﬂuctuation in y(n) is reduced. When m(n) is Gaussian, then γm1 = 0, γm2 = 3.
The preceding was limited to iid processes. The more general non-iid case is typically not very
analytically tractable, because with dependence in m(n) or w(n) the joint pdf on all the observations
is required, unlike the Gaussian case where second-order statistics are sufﬁcient to characterize depen-
dence. An exception is linear non-Gaussian processes, obtained as the output of a linear ﬁlter driven by
an iid non-Gaussian random process. Here it may be of interest to identify the ﬁlter parameters [43], and
if the ﬁlter is invertible then the problem can be returned to the iid case by a linear operation (whitening)
[44,45]. Further discussion of non-iid issues in the non-Gaussian case is given by Poor and Thomas [46].
In our discussion around (8.27) we have largely focused on the signal parameters, but when we
consider the non-Gaussian case we can also draw on the rich selection of parameterized non-Gaussian
distributions. Well known families include Gaussian mixtures (GM) [47–50], stable distributions [51],
and others [52].
The stable distributions include the normal distribution as a special limiting case, but otherwise
have inﬁnite variance. For almost all values of the stable distribution parameters simple closed form

3.08.8 Asymptotic Analysis and the Central Limit Theorem
313
expressions are not available, with the notable exception of the Cauchy pdf. Consequently specialized
tools and estimators have been developed for the case when w(n) is drawn from the stable distribution
family, such as fractional lower order statistics, in order to accommodate the inﬁnite variance of the
pdf. For the case of linear (or iid) stable processes, normalized versions of conventional covariance
and cumulant estimates are convergent and enable the use of many estimation algorithms originally
developed for AWGN, e.g., covariance matrix based subspace algorithms [53,54].
CRBs are generally available for the cases mentioned here with additive iid non-Gaussian noise,
using the expressions in [35]. Several cases are described in [50,55], generalizing the AWGN cases to
non-Gaussian noise.
3.08.8 Asymptotic analysis and the central limit theorem
TheCRBanalysisaboveappealstoasymptotics,inthesensethattheboundisgenerallytightonlyasymp-
totically, and application of the CRB requires a fully speciﬁed parametric probability model. However,
we can often employ a more general asymptotic analysis without a parameteric model, and without
completely specifying the pdf, by resorting to the central limit theorem (CLT) and related ideas. This
approach is generally useful for analysis of algorithms. And, if there is an underlying parameteric model,
then we can compare algorithm performance analysis with parameter estimation bounds such as the
CRB. However, the asymptotic tools are general and apply even when there is no underlying parametric
model. We consider the application of the CLT to two broad classes of algorithms in Section 3.08.9.
Given an estimation algorithm, a full statistical analysis requires the pdf of the estimate, as a function
of the observations. If we know this pdf we can ﬁnd meaningful measures of performance such as the
mean, variance, and MSE, and compare these to benchmark bounds. We would like to do this as
a function of the number of observations (data size), as well as other parameters such as the SNR.
However, even if we have full statistical knowledge of the observations, it may be intractable to ﬁnd the
pdf of the estimates due to the often complicated and nonlinear estimation function.
An alternative approach is to appeal to asymptotics as the observation size grows [56]. The basic
tools are two probability limit laws, (i) the law of large numbers (LLN) and (ii) the central limit theorem.
The LLN reveals when a sample average of a sequence of n random variables converges to the expected
mean as n goes to inﬁnity, and the CLT tells us about the distribution of the sample average (or more
generally about the distribution of a normalized sum of random variables).
The basic CLT theorem states that the sample average asymptotically converges in distribution to
normal,
1
n
n

i=1
xi
d→N(μ, σ 2/n),
(8.34)
where xi are iid, E[xi] = μ, and Var{xi} = σ 2 < ∞. There are many extensions, such as the vector
case, when the xi are non-identically distributed, and when the xi are not independent. A generalized
version of the CLT also exists for the non-Gaussian case with convergence to a stable distribution [57].
Intuitively, when summing random variables, we recognize that the sum of independent random
variables has pdf given by the convolution of the individual pdfs, and the repeated convolution results
in smoothing to a Gaussian distribution. For example, suppose we average n random variables that
are iid from a uniform distribution on [0, 1]. In this case n = 10 is sufﬁcient to provide a very good

314
CHAPTER 8 Performance Analysis and Bounds
ﬁt to a normal distribution (up to the ﬁnite region of support of the ten-fold convolution) [58], so the
asymptotics may be effective even for relatively small n in some cases.
A physical intuition is also broadly applicable, that a combination of many small effects yields Gaus-
sian behavior on the macro-scale, such as thermal noise in electronic devices resulting from electron
motion.
3.08.8.1 Comments on application of the CLT
• Bounding asymptotic deviation from normality: The deviation of the asymptotic distribution from
a normal pdf can be bounded. Perhaps the best known result is the Berry-Esséen theorem [56], that
bounds the maximum deviation from Gaussian. The bound is proportional to γ = E[|xi −μ|3],
the third central moment. γ is a measure of skewness of a pdf, i.e., it measures asymmetry in the
pdf. If γ < 0 then the pdf is skewed left (e.g., has a heavier tail on left), and vice-versa. Generally
then, asymmetry in the pdf of x will slow the asymptotic convergence to Gaussian.
• Deviation from normality is generally worse in the tails of the pdf: The approximation to a normal
process is generally more accurate when closer to the peak of the normal distribution, and may
require a very large n for the ﬁt to be accurate in the tails of the distribution. The ﬁt between the
distribution of the sample mean and its normal approximation worsens, at a given n, as we go
out in the tails. This is intuitively evident in the example mentioned above, summing uniformly
distributed random variables, because the convolution of multiple uniform pdfs will always have
a ﬁnite support beyond which the true pdf is zero and so will always have error with respect to a
normal distribution with it’s inﬁnite support. Consequently, some care is needed when inferring
from the tail behavior of the CLT Gaussian approximation. This is especially true in considering
extreme tail behavior based on the form of the normal approximation, such as deriving tests of
signiﬁcance, conﬁdence intervals (error bars), and rare events.
• Applying the CLT to arbitrary functions: The various statements of the CLT usually stem from a
(perhaps weighted) linear combination of random variables. However, in practice we are interested
in applying the asymptotic theorem with empirical observations from an arbitrary function of the
observations of the random variables, such as an estimator t(x). The CLT ideas are generally useful
in this context when the estimator function stabilizes as n grows, i.e., given a sequence of random
observations the estimator asymptotically converges to some value. If for large enough n then t(x)
is reasonably Gaussian we can ﬁnd its mean and variance, and the resulting normal distribution
is a useful description of the pdf of the estimator. Note that, if we have a parametric model, then
if ˆθ = t(x) is asymptotically normally distributed, is unbiased, and the variance approaches the
CRB, then this estimator has asymptotic optimality. However, we stress that the CLT ideas are very
general and don’t require an underlying parameteric model.
• Tests for Gaussianity: Various statistical tests exist to determine if a random variable is well
described by a Gaussian pdf, and these can and should be applied to verify the CLT effect in a
particularcase.Forexample,testscanbebasedonsamplemomentssuchascomparingthecomputed
skewness and kurtosis with those expected for a normal distribution, as well as comparison through
plots such as the Q-Q and P-P plots. Issues with such tests include obtaining sufﬁcient data to
accurately characterize the tail behavior, and that the test will provide some level of statistical
evidence but not certainty.

3.08.9 Asymptotic Analysis and Parametric Models
315
• Proving convergence to normality: Given an algorithm, we can rely on simulation and tests for
Gaussianitytodeterminethevalidityoftheasymptoticapproximation.Ingeneral,itcanberelatively
difﬁcult to prove convergence of the distribution of the output of a particular algorithm or estimator
to normality. One approach is to show that the skewness and kurtosis converge to their expected
values under a normal assumption (e.g., the skewness will approach zero because the normal
distribution is symmetric). An example of this form of analysis is given by Brillinger, demonstrating
that sample estimates of higher order statistics become normally distributed [59].
3.08.9 Asymptotic analysis and parametric models
In the previous section we noted that asymptotic analysis of nonparametric algorithms is often facilitated
by the law of large numbers and results associated with the central limit theorem. These ideas apply
equally well to parameter estimators, even if we have the full parametric model speciﬁed in p(x; θ).
While we may have the CRB or other bound that is applicable to a broad class of estimators, we would
still like to carry out performance analysis for speciﬁc estimators, that may be the MLE or not.
In this section we consider asymptotic analysis for two fundamentally important and widely appli-
cable cases, Fourier based algorithms, and weighted least squares (LS) estimators. In both cases we
can appeal to the CLT to show asymptotic normality, and then the algorithm performance can be
characterized by the mean and covariance.
3.08.9.1 Fourier transform
The Fourier transform is a fundamental linear decomposition that can be exploited to facilitate perfor-
mance analysis, because the transformation yields Fourier coefﬁcients that tend to a complex-valued
Gaussian distribution. The Fourier transform approach to analysis is particularly useful for wideband
problems, such as wideband array processing [60], and bit error rate (BER) analysis of OFDM systems
in a fading environment [61]. This represents an extremely small fraction of the literature using these
ideas, and the basic concept can be readily extended to other signal decompositions.
We illustrate the idea in the following. Suppose we have observations from a random process y(t; θ),
that depend on the deterministic parameters θ. We observe y(t; θ) over M intervals each of length T
seconds. We may treat both the discrete-time and the continuous-time cases similarly. In discrete-time,
samples y(t; θ) are placed in a vector and the DFT is applied. In continuous-time, we apply the short-time
Fourier transform to obtain
xm(ωk; θ) = 1
T
 T /2
−T /2
y(t; θ)e−jωktdt,
(8.35)
over m = 1, . . . , M intervals, for k = 1, . . . , L distinct frequencies, and it is understood the integral is
over successive time intervals of length T. We will drop the explicit mention of θ, keeping in mind the
Fourier coefﬁcients are functions of the parameters in the underlying pdf model that generates y(t; θ).
Asymptotically in T, the Fourier coefﬁcients xm(ωk) become normally distributed via the central limit
theorem. In addition, in many cases, the xm(ωk) become uncorrelated at different frequencies. This
generally occurs when T is large compared to the time lag τ0 such that y(t) and y(t + τ0) are weakly
or completely uncorrelated, i.e., E[y(t)y(t + τ0)] ≈0. For example, for a bandlimited random process
with bandwidth B Hz, then the decorrelation time is roughly τ0 ≈1/B seconds.

316
CHAPTER 8 Performance Analysis and Bounds
Under the above assumptions, we place the LM complex-valued Fourier coefﬁcients into L vectors
xk = [x1(ωk), . . . , xM(ωk)]T ,
k = 1, . . . , L,
(8.36)
and let μk and Ck be the mean and covariance matrix of xk, respectively. Note that Ck describes the
correlation at the frequency ωk across time intervals; we are assuming that the Fourier coefﬁcients
are uncorrelated accross frequencies. Asymptotically the vectors xk are independent with a normal
distribution, so the log-likelihood function can be written as
L(x; θ) = −
L

k=1
(xk −μk)HC−1
k (xk −μk) + log det(πCk),
(8.37)
where H denotes conjugate-transpose (the Hermitian operator), and det(·) is the determinant. Recalling
that μk and Ck are functions of the parameters θ, we can now use L(x; θ) to ﬁnd the MLE and CRB for
estimation of θ. Note, however, that the MLE and CRB we are referring to are asymptotic approximations
and were not derived directly from the original model.
If the original random process y(t; θ) is Gaussian then the Fourier coefﬁcients are also normally
distributed because the Fourier transform is a linear operation. In this case, the only assumption leading
to (8.37) is T ≫τ0, to ensure that the coefﬁcients are uncorrelated at distinct frequencies. This does not
require application of the CLT. More generally, if y(t; θ) is non-Gaussian, then we rely on the CLT to
ensure the Fourier coefﬁcients are approaching a normal distribution. This depends on the observation
interval length T (or equivalently the number of Nyquist samples when applying the DFT). For example,
it is not difﬁcult to accept that a DFT whose length is on the order of 103 or greater will produce a
strong CLT effect.
As we noted in Section 3.08.8, it is important to validate the Gaussian assumption, such as using tests
for Gaussianity as a function of the Fourier window time T. In addition, the assumption that the Fourier
coefﬁcients are uncorrelated should also be veriﬁed analytically or, e.g., using sample cross correlations.
Note also that the Gaussian model can be readily modiﬁed to include frequency cross-correlation.
3.08.9.2 Least squares estimation
As a second example of the application of the CLT in parametric models, we consider weighted least
squares nonlinear estimation, an extremely general tool. We will speciﬁcally assume the parameterized
signal plus noise model in Eq. (8.1), where the noise is a stationary process with ﬁnite variance (not
necessarily Gaussian). The least squares approach seeks to minimize the sum of squared errors criterion
JN(θ) =
N

n=1
(x(n) −s(n; θ))2,
(8.38)
so that
ˆθLS = arg min
θ
JN(θ).
(8.39)
Unless s(n; θ) is linear in θ, then solving (8.39) is a nonlinear optimization problem. If the additive
noise is Gaussian then (8.39) corresponds to maximum likelihood estimation, and we can appeal to

3.08.10 Monte Carlo Methods
317
classic CRB results, e.g., see [4]. If the noise pdf is unknown, then we cannot readily compute a CRB
for estimation of θ.
The following is based on Wu [62]. Consider the parameterized signal plus additive noise model in
(8.1). We assume that the additive noise is stationary with ﬁnite variance, but do not necessarily assume
the noise pdf is known, nor do we assume the signal model is linear in the parameters θ. Putting the noisy
observation into (8.38), the LS criterion seeks to ﬁt the signal model to the noisy observations using
the squared-error penalty for deviation from the model. This approach is very general and reasonable.
Solution of (8.38) will require optimization, and with a nonlinear signal model there will generally be
local optima, i.e., the cost function will not generally be convex. Thus the optimization algorithm may
require search or a good initial estimate. For many examples of this scenario see Kay [4, Chapter 8].
Generally LS (or weighted LS) does not have any particular guaranteed ﬁnite sample optimality, but we
can appeal to asymptotics.
Wu has shown the following asymptotic (as N grows) properties of LS for the case of a parametric
signal in additive noise given by (8.1), resulting in (8.38). The LS estimator is consistent, i.e., it converges
in probability to the true value of θ, meaning that the LS estimate has a probability distribution that
is collapsing about the true value of θ. This assumes continuity in the pdf, and requires the LS error
to grow with N except when the LS criterion is evaluated at the correct parameter. Intuitively, this
last requirement implies that the signal does not die out. For example, suppose the signal undergoes
an exponential decay. Then, the asymptotic properties are not guaranteed, but this is not surprising
since the signal is dying off making additional observations of decreasing value. The signal must have
sufﬁcient energy and duration relative to the noise power for the asymptotic results to be meaningful.
(Alternatively, we might have multiple observations of a ﬁnite length signal.)
The asymptotic results still hold when the noise is non-identically distributed (independent, but non-
identical), so long as the variance is bounded. The same ideas hold even if the parameter θ is taken
from a ﬁnite set, implying we are solving a classiﬁcation problem rather than a continuous parameter
estimation problem; see Section 3.08.2.1.5. Also, the average of the errors squared (the average sum of
residuals squared) converges to the noise variance, so it is straightforward to asymptotically estimate
the noise power.
Finally, note that the LS estimate is asymptotically normally distributed [62, Thrm. 5]. The variance
of the normal distribution provides a large sample conﬁdence level on the estimate of θ, which provides
a probability statement about our conﬁdence in a particular realization of the estimate, and this can
be computed based on the observations. It is important to recognize that a conﬁdence level provides
statistical evidence, and should not be confused with a bound such as the CRB; see Section 3.08.11.
As with the Fourier case discussed previously, the validity of the asymptotic assumption should
be carefully checked for a particular problem. For example, if the additive noise distribution strongly
deviates from normal, or if there is signiﬁcant dependence in the noise, then the convergence rate to the
asymptotic regime may be slow.
3.08.10 Monte Carlo methods
A Monte Carlo method (MCM) is a computational algorithm that utilizes random sampling in some way
during the computation, such as computing an expected value, where the algorithm uses realizations of

318
CHAPTER 8 Performance Analysis and Bounds
some random process. This is a broad area of applications, and we consider some basic ideas as applied
to performance analysis.
3.08.10.1 Using Monte Carlo to approximate an expectation
Consider numerically computing (or approximating) an expected value Eθ(·) =

X (·)p(x; θ)dx. As
a simple example, suppose we wish to compute E[x], where x is a scalar random variable. We can
generate many realizations of x and compute the sample average, which will converge to the expectation
in most cases of interest based on the law of large numbers. Similar thinking applies to E[ f (x)],
for some function f (x); generate realizations of x, and then compute the sample average of f (x).
Because the expectation involves random variables, we can exploit random sampling in a straightforward
averagingprocedure.AparticularmotivationforMCMiswhenweareunabletocarryouttheexpectation
analytically. For example, the function f (x) may be highly nonlinear such that no closed form is known
for the expectation integral.
Thus we see that applying MCM is a fundamentally different sample-based approach to approxi-
mating the integral, as opposed to classic numerical methods such as using the trapezoidal rule. The
integral may have inﬁnite limits, and be of high dimension, cases that often confound classic numerical
methods. Consequently, it may be more efﬁcient and more accurate to employ MCM.
To reduce complexity, and to avoid excessive sampling in regions of small probability, additional
sophistication can be employed in the sampling strategy; an example is importance sampling.
3.08.10.2 Computing the CRB via Monte Carlo
The MCM can be applied to numerically computing the CRB at a speciﬁed value of the parameter θ.
Realizations of x are generated according to p(x; θ). These are then plugged into the Fisher score in
(8.4), followed by averaging to estimate the FIM given by (8.3). Note that the averaging is over x for a
ﬁxed value of θ.
An alternative is to use the realizations of x in (8.7). Note that in (8.7) the expectation is over the
Hessian (the matrix of second derivatives). Thus, in this case, each realization of x results in a realization
of the Hessian, and the Hessian matrices are averaged to approximate the FIM in (8.7).
Using either (8.3) or (8.7) assumes that the score or Hessian are known in closed form. If these
derivatives are not known, then a Monte Carlo method may ﬁrst be applied to estimate the derivatives
for a given x and θ. Then, these are averaged over the realizations x. This procedure is described in
detail by Spall [16,63, chapter 12].
3.08.11 Conﬁdence intervals
As described in Sections 3.08.8 and 3.08.9, in many cases we can exploit asymptotics to obtain an
approximate (typically Gaussian) distribution for an estimate. For example, under the normal assump-
tion, then an interval can be deﬁned around the mean based on the variance σ of say, ±σ. While the
mean of the distribution is our estimate, the variance provides a measure of conﬁdence or reliability
in the estimate, because it provides a statistical picture of the range over which the estimate might
reasonably deviate given a new set of observations.

References
319
Note that the distribution parameters, and hence the conﬁdence interval, are derived from the obser-
vations. So, the estimate and the conﬁdence interval will change given a new set of observations. This
should not be confused with a bound such as the CRB. The CRB is based on complete statistical
knowledge of the underlying probability model p(x; θ).
Conﬁdence intervals have been extensively applied in regression analysis, especially for additive
Gaussian noise, but also more generally in the asymptotic sense with additive noise modeled as samples
from an arbitrary stationary process. For example, see the comprehensive treatment by Draper and
Smith [64].
An interesting alternative to estimating conﬁdence levels is to use the bootstrap method; see Efron
[65]. This approach does not rely on asymptotics, instead using resampling of the data. The approach is
relatively simple to implement using the given observations, and does not require extensive knowledge
of the underlying probability model, although it can be computationally demanding due to extensive
resampling. An overview of the bootstrap in statistical signal processing is given by Zoubir [66].
3.08.12 Conclusion
We have introduced many key concepts in performance analysis for statistical signal processing. But of
course, given the decades of developments in statistics and signal processing, there are many topics left
untouched. These include treatment of random parameters, for example see the edited paper collection,
Van Trees and Bell [67]. These are often referred to as Bayesian bounds. Alternatives to the CRB include
the Ziv-Zakai bound [68,69], and the Chapman-Robbins bound [70]. These may be more challenging
to derive analyically, but typically result in a tighter bound in the non-asymptotic region.
Relevant Theory: Signal Processing Theory, Machine Learning, and Statistical Signal Processing
See Vol. 1, Chapter 11 Parametric Estimation
See Vol. 1, Chapter 19 A Tutorial Introduction to Monte Carlo Methods, Markov Chain Monte Carlo
and Particle Filtering
See Vol. 1, Chapter 25 Model Selection
See this Volume, Chapter 2 Model Order Selection
See this Volume, Chapter 4 Bayesian Computational Methods in Signal Processing
References
[1] Jun Shao, Mathematical Statistics, Springer-Verlag, New York, NY, 2003.
[2] Harry L. Van Trees, Detection, Estimation, and Modulation Theory, Part I, Wiley, 1968.
[3] George Casella, Roger L. Berger, Statistical Inference, second ed., Duxbury Press, Boca-Raton, FL, 2002.
[4] S.M. Kay, Fundamentals of Statistical Signal Processing: Estimation Theory, Prentice Hall, Englewood Cliffs,
NJ, 1993.
[5] H. Cramér, Mathematical Methods of Statistics, Princeton University Press, Princeton, NJ, 1946.
[6] Calyampudi Radakrishna Rao, Information and the accuracy attainable in the estimation of statistical param-
eters, Bull. Calcutta Math. Soc. 37 (1945) 81–89.

320
CHAPTER 8 Performance Analysis and Bounds
[7] A.O. Hero, J.A. Fessler, M. Usman, Exploring estimator bias-variance tradeoffs using the uniform CR bound,
IEEE Trans. Signal Process. 44 (8) (1996) 2026–2042.
[8] A.O. Hero, J.A. Fessler, M. Usman, Bias-resolution-variance tradeoffs for single pixel estimation tasks using
the uniform Cramér-Rao bound, in: Proc. of IEEE Nuclear Science Symposium, vol. 2, pp. 296–298.
[9] W.J. Bangs. Array processing with generalized beamformers. PhD Thesis, Yale University, New Haven, CT,
1971.
[10] D. Slepian, Estimation of signal parameters in the presence of noise, Trans. IRE Prof. Group Inform. Theory
PG IT-3 (1954) 68–69.
[11] Thomas J. Rothenberg, Identiﬁcation in parametric models, Econometrica 39 (3) (1971) 577–591 (May).
[12] B. Hochwald, A. Nehorai, On identiﬁability and information-regularity in parameterized normal distributions,
Circ. Syst. Signal Process. 16 (1) (1997) 83–89.
[13] Y. Chen, A. Wiesel, Y.C. Eldar, A.O. Hero, Shrinkage algorithms for MMSE covariance estimation, IEEE
Trans. Signal Process. 58 (10) (2010) 5016–5029.
[14] J.G. Proakis, M. Salehi, Digital Communications, ﬁfth ed., McGraw-Hill, 2007.
[15] M.K. Simon, M.-S. Alouini, Digital Communications Over Fading Channels, second ed., Wiley, 2005.
[16] J.C. Spall, Introduction to Stochastic Search and Optimization, Wiley, 2003.
[17] Y. Chen, A. Wiesel, A.O. Hero, Robust shrinkage estimation of high dimensional covariance matrices, IEEE
Trans. Signal Process. 59 (9) (2011) 4097–4107.
[18] N. Liu, Z. Xu, B.M. Sadler, Geolocation performance with biased range measurements, IEEE Trans. Signal
Process. 60 (5) (2012) 2315–2329.
[19] Z. Xu, Perturbation analysis for subspace decomposition with applications in subspace-based algorithms,
IEEE Trans. Signal Process. 50 (11) (2002) 2820–2830.
[20] G.W. Stewart, Error and perturbation bounds for subspaces associated with certain eigenvalue problems, SIAM
Rev. 15 (4) (1973) 727–764.
[21] G.W. Stewart, On the perturbation of psuedo-inverses, projections and linear least squares problems, SIAM
Rev. 19 (4) (1977) 634–662.
[22] G.W. Stewart, J. Sun, Matric Perturbation Theory, Academic Press, 1990.
[23] Harry L. Van, Trees, Optimum Array Processing, Wiley, 2002.
[24] F. Li, H. Liu, R.J. Vaccaro, Performance analysis for DOA estimation algorithms: uniﬁcation, simpliﬁcation,
and observations, IEEE Trans. Aerosp. Electron. Syst. 29 (4) (1993) 1170–1184.
[25] A.J. Weiss, J. Picard, Maximum-likelihood position estimation of network nodes using range measurements,
IET Signal Process. 2 (4) (2008) 394–404.
[26] Petre Stoica, Boon Chong Ng, On the Cramér-Rao bound under parametric constraints, IEEE Signal Process.
Lett. 5 (7) (1998) 177–179.
[27] Terrence J. Moore, Brian M. Sadler, Sufﬁcient conditions for regularity and strict identiﬁability in MIMO
systems, IEEE Trans. Signal Process. 52 (9) (2004) 2650–2655.
[28] Zvika Ben-Haim, Yonina Eldar, On the constrained Cramér-Rao bound with a singular Fisher information
matrix, IEEE Signal Process. Lett. 16 (6) (2009) 453–456.
[29] Terrence J. Moore, Richard J. Kozick, Brian M. Sadler, The constrained Cramér-Rao bound from the perspec-
tive of ﬁtting a model, IEEE Signal Process. Lett. 14 (8) (2007) 564–567.
[30] Terrence J. Moore, Brian M. Sadler, Richard J. Kozick, Maximum-likelihood estimation, the Cramér-Rao
bound, and the method of scoring with parameter constraints, IEEE Trans. Signal Process. 56 (3) (2008)
895–908.
[31] P.K. Rajasekaran, N. Satyanarayana, M.D. Srinath, Optimum linear estimation of stochastic signals in the
presence of multiplicative noise, IEEE Trans. Aerosp. Electron. Syst. 7 (3) (1971) 462–468.
[32] R.J. Kozick, B.M. Sadler, D.K. Wilson, Signal Processing and Propagation for Aeroacoustic Networks in
Distributed Sensor Networks, CRC Press, 2004.

References
321
[33] Petre Stoica, Olivier Besson , Alex. B. Gershman, Direction-of-arrival estimation of an amplitude-distorted
wavefront, IEEE Trans. Signal Process. 49 (2) (2001) 269–276.
[34] M. Ghogho, A. Swami, T.S. Durrani, Frequency estimation in the presence of Doppler spread: performance
analysis, IEEE Trans. Signal Process. 49 (4) (2001) 777–789.
[35] A. Swami, Cramer-Rao bounds for deterministic signals in additive and multiplicative noise, Signal Process.
53 (1996) 231–244.
[36] G.B. Giannakis, G. Zhou, Harmonics in Gaussian multiplicative and additive noise: Cramer-Rao bounds,
IEEE Trans. Signal Process. 43 (5) (1995) 1217–1231.
[37] M. Ghogho, A. Swami, A.K. Nandi, Non-linear least squares estimation for harmonics in multiplicative and
additive noise. Signal Process. 78 (1999) 43–60.
[38] J.Y. Tourneret, A. Ferrari, A. Swami, Cramer-Rao lower bounds for change points in additive and multiplicative
noise, Signal Process. 84 (2004) 1071–1088.
[39] P. Ciblat, M. Ghogho, P. Forster, P. Larzabal, Harmonic retrieval in the presence of non-circular Gaussian
multiplicative noise: performance bounds. Signal Process. 85 (2005) 737–749.
[40] D. Middleton, A.D. Spaulding, Elements of weak signal detection in non-gaussian noise environments, in:
Advances in Statistical Signal Processing, vol. 2, JAI Press, 1993.
[41] P.J. Huber, E.M. Ronchetti, Robust Statistics, second ed., Wiley, 2009.
[42] S.M. Kay, Fundamentals of Statistical Signal Processing: Estimation Theory, Prentice-Hall, 1993.
[43] D. Sengupta, S. Kay, Efﬁcient estimation of parameters for a non-Gaussian autoregressive process, IEEE
Trans. Acoust. Speech Signal Process. 37 (6) (1989) 785–794.
[44] B.M. Sadler, G.B. Giannakis, K.-S. Lii, Estimation and detection in non-Gaussian noise using higher order
statistics, IEEE Trans. Signal Process. 42 (10) (1994) 2729–2741.
[45] B.M.Sadler,Detectionincorrelatedimpulsivenoiseusingfourth-ordercumulants,IEEETrans.SignalProcess.
44 (11) (1996) 2793–2800.
[46] H.V. Poor, J.B. Thomas, Signal detection in dependent non-gaussian noise, in: Advances in Statistical Signal
Processing, vol. 2, JAI Press, 1993.
[47] R.O. Duda, P.E. Hart, D.G. Stork, Pattern Classiﬁcation, second ed., Wiley, 2001.
[48] R.J. Kozick, R.S. Blum, B.M. Sadler, Signal processing in non-Gaussian noise using mixture distributions
and the EM algorithm, in: Proc. 31st Asilomar Conference on Signals, Systems, and Computers, vol. 1, 1997,
pp. 438–442.
[49] R.S. Blum, R.J. Kozick, B.M. Sadler, An adaptive spatial diversity receiver for non-gaussian interference and
noise, IEEE Trans. Signal Process. 47 (8) (1999) 2100–2111.
[50] R.J. Kozick, B.M. Sadler, Maximum-likelihood array processing in non-Gaussian noise with Gaussian mix-
tures, IEEE Trans. Signal Process. 48 (12) (2000) 3520–3535.
[51] G. Samorodnitsky, M.S. Taqqu, Stable Non-Gaussian Random Processes: Stochastic Models with Inﬁnite
Variance, Chapman and Hall, 1994.
[52] S.A. Kassam, J.B. Thomas, Signal Detection in Non-Gaussian Noise, Springer, 1987.
[53] R.A.Davis,S.I.Resnick,Limittheoryforthesamplecovariancesandcorrelationfunctionsofmovingaverages,
Ann. Stat. 14 (1986) 533–558.
[54] A. Swami, B.M. Sadler, On some detection and estimation problems in heavy-tailed noise, Signal Process. 82
(2002) 1829–1846.
[55] A. Swami, B.M. Sadler, Parameter estimation for linear alpha-stable processes, IEEE Signal Process. Lett. 5
(2) (1998) 48–50.
[56] Robert J. Serﬂing, Approximation Theorems of Mathematical Statistics, Wiley, 1980.
[57] W. Feller, An Introduction to Probability Theory and Its Applications, vol. II, Wiley, 1971.
[58] G. Marsaglia, Ratios of normal variables and ratios of sums of uniform variables, J. Am. Statist. Assoc. 60
(1965) 193–204.

322
CHAPTER 8 Performance Analysis and Bounds
[59] D.R. Brillinger, M. Rosenblatt, Spectral analysis of time series, in: B. Harris (Ed.), Asymptotic Theory of
Estimates of k-th Order Spectra, Wiley, 2002, pp. 153–188 (Chapter 7).
[60] P.M. Schultheiss, H. Messer, Optimal and sub-optimal broad-band source location estimation, IEEE Trans.
Signal Process. 41 (9) (1993) 2752–2763.
[61] W.P. Siriwongpairat, K.J.R. Liu, Ultra-Wideband Communications Systems, IEEE Press, Wiley, 2008.
[62] Chien-Fu Wu, Asymptotic theory of nonlinear least squares estimation, Ann. Stat. 9 (3) (1981) 501–513.
[63] J.C. Spall, On Monte Carlo methods for estimating the Fisher information matrix in difﬁcult problems, in:
43rd Annual Conference on Information Sciences and Systems, 2009, pp. 741–746.
[64] N.R. Draper, H. Smith, Applied Regression Analysis, third ed., Wiley, 1998.
[65] B. Efron, R. Tibshirani, An Introduction to the Bootstrap, Chapman and Hall, 1993.
[66] A.M. Zoubir, D.R. Iskander, Bootstrap methods and applications, IEEE Signal Process. Mag. 24 (4) (2007)
10–19.
[67] H.L. Van Trees, K.L. Bell, Bayesian Bounds for Parameter Estimation and Nonlinear/Filtering Tracking,
IEEE Press, Wiley, 2007.
[68] J. Ziv, M. Zakai, Some lower bounds on signal parameter estimation, IEEE Trans. Inform. Theory (1969)
386–391.
[69] D. Chazan, M. Zakai, J. Ziv, Improved lower bounds on signal parameter estimation, IEEE Trans. Inform.
Theory 21 (1) (1975) 90–93.
[70] D.G. Chapman, H. Robbins, Minimum variance estimation without regularity assumptions, Ann. Math. Stat.
22 (6) (1951) 581–586.

9
CHAPTER
Diffusion Adaptation
Over Networks∗
Ali H. Sayed
Electrical Engineering Department, University of California at Los Angeles, USA
Adaptive networks are well-suited to perform decentralized information processing and optimization
tasks and to model various types of self-organized and complex behavior encountered in nature. Adaptive
networks consist of a collection of agents with processing and learning abilities. The agents are linked
together through a connection topology, and they cooperate with each other through local interactions to
solve distributed optimization, estimation, and inference problems in real-time. The continuous diffusion
of information across the network enables agents to adapt their performance in relation to streaming
data and network conditions; it also results in improved adaptation and learning performance relative
to non-cooperating agents. This chapter provides an overview of diffusion strategies for adaptation
and learning over networks. The chapter is divided into several sections and includes appendices with
supporting material intended to make the presentation rather self-contained for the beneﬁt of the reader.
3.09.1 Motivation
Consider a collection of N agents interested in estimating the same parameter vector, wo, of size M ×1.
The vector is the minimizer of some global cost function, denoted by J glob(w), which the agents seek
to optimize, say,
wo = argmin
w
J glob(w) .
(9.1)
We are interested in situations where the individual agents have access to partial information about
the global cost function. In this case, cooperation among the agents becomes beneﬁcial. For example,
by cooperating with their neighbors, and by having these neighbors cooperate with their neighbors,
procedures can be devised that would enable all agents in the network to converge towards the global
optimum wo through local interactions. The objective of decentralized processing is to allow spatially
distributed agents to achieve a global objective by relying solely on local information and on in-network
processing. Through a continuous process of cooperation and information sharing with neighbors, agents
in a network can be made to approach the global performance level despite the localized nature of their
interactions.
∗The work was supported in part by NSF grants EECS-060126, EECS-0725441, CCF-0942936, and CCF-1011918.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00009-6
© 2014 Elsevier Ltd. All rights reserved.
323

324
CHAPTER 9 Diffusion Adaptation Over Networks
3.09.1.1 Networks and neighborhoods
In this chapter we focus mainly on connected networks, although many of the results hold even if the
network graph is separated into disjoint subgraphs. In a connected network, if we pick any two arbitrary
nodes, then there will exist at least one path connecting them: the nodes may be connected directly by
an edge if they are neighbors, or they may be connected by a path that passes through other intermediate
nodes. Figure 9.1 provides a graphical representation of a connected network with N = 10 nodes. Nodes
that are able to share information with each other are connected by edges. The sharing of information
over these edges can be unidirectional or bi-directional. The neighborhood of any particular node is
deﬁned as the set of nodes that are connected to it by edges; we include in this set the node itself.
The ﬁgure illustrates the neighborhood of node 3, which consists of the following subset of nodes:
N 3 = {1, 2, 3, 5}. For each node, the size of its neighborhood deﬁnes its degree. For example, node 3
in the ﬁgure has degree |N3| = 4, while node 8 has degree |N8| = 5. Nodes that are well connected
have higher degrees. Note that we are denoting the neighborhood of an arbitrary node k by Nk and its
size by |Nk|. We shall also use the notation nk to refer to |Nk|.
The neighborhood of any node k therefore consists of all nodes with which node k can exchange
information. We assume a symmetric situation in relation to neighbors so that if node k is a neighbor
of node ℓ, then node ℓis also a neighbor of node k. This does not necessarily mean that the ﬂow
of information between these two nodes is symmetrical. For instance, in future sections, we shall
assign pairs of nonnegative weights to each edge connecting two neighboring nodes—see Figure 9.2.
In particular, we will assign the coefﬁcient aℓk to denote the weight used by node k to scale the data
it receives from node ℓ; this scaling can be interpreted as a measure of trustworthiness or reliability
that node k assigns to its interaction with node ℓ. Note that we are using two subscripts, ℓk, with the
FIGURE 9.1
A network consists of a collection of cooperating nodes. Nodes that are linked by edges can share information.
The neighborhood of any particular node consists of all nodes that are connected to it by edges (including the
node itself). The ﬁgure illustrates the neighborhood of node 3, which consists of nodes {1,2,3,5}. Accordingly,
node 3 has degree 4, which is the size of its neighborhood.

3.09.1 Motivation
325
FIGURE 9.2
In the top part, and for emphasis purposes, we are representing the edge between nodes k and ℓby two
separate directed links: one moving from k to ℓand the other moving from ℓto k. Two nonnegative weights
are used to scale the sharing of information over these directed links. The scalar akℓdenotes the weight
used to scale data sent from node k to ℓ, while aℓk denotes the weight used to scale data sent from node
ℓto k. The weights {akℓ, aℓk} can be different, and one or both of them can be zero, so that the exchange of
information over the edge connecting any two neighboring nodes need not be symmetric. The bottom part of
the ﬁgure illustrates directed links arriving to node k from its neighbors {ℓ1, ℓ2, ℓ3, . . .} (left) and leaving
from node k towards these same neighbors (right).
ﬁrst subscript denoting the source node (where information originates from) and the second subscript
denoting the sink node (where information moves to) so that:
aℓk ≡aℓ→k (information ﬂowing from node ℓto node k) .
(9.2)
In this way, the alternative coefﬁcient akℓwill denote the weight used to scale the data sent from
node k to ℓ:
akℓ≡ak→ℓ(information ﬂowing from node k to node ℓ) .
(9.3)
The weights {akℓ, aℓk} can be different, and one or both of them can be zero, so that the exchange of
information over the edge connecting the neighboring nodes (k, ℓ) need not be symmetric. When one of
the weights is zero, say, akℓ= 0, then this situation means that even though nodes (k, ℓ) are neighbors,
node ℓis either not receiving data from node k or the data emanating from node k is being annihilated
before reaching node ℓ. Likewise, when akk > 0, then node k scales its own data, whereas akk = 0
corresponds to the situation when node k does not use its own data. Usually, in graphical representations
like those in Figure 9.1, edges are drawn between neighboring nodes that can share information. And,
it is understood that the actual sharing of information is controlled by the values of the scaling weights
that are assigned to the edge; these values can turn off communication in one or both directions and
they can also scale one direction more heavily than the reverse direction, and so forth.

326
CHAPTER 9 Diffusion Adaptation Over Networks
3.09.1.2 Cooperation among agents
Now, depending on the application under consideration, the solution vector wo from (9.1) may admit
different interpretations. For example, the entries of wo may represent the location coordinates of a
nutrition source that the agents are trying to ﬁnd, or the location of an accident involving a dangerous
chemical leak. The nodes may also be interested in locating a predator and tracking its movements
over time. In these localization applications, the vector wo is usually two or three-dimensional. In other
applications, the entries of wo may represent the parameters of some model that the network wishes to
learn, such as identifying the model parameters of a biological process or the occupied frequency bands
in a shared communications medium. There are also situations where different agents in the network
may be interested in estimating different entries of wo, or even different parameter vectors wo altogether,
say, {wo
k} for node k, albeit with some relation among the different vectors so that cooperation among the
nodes can still be rewarding. In this chapter, however, we focus exclusively on the special (yet frequent
and important) case where all agents are interested in estimating the same parameter vector wo.
Since the agents have a common objective, it is natural to expect cooperation among them to be
beneﬁcial in general. One important question is therefore how to develop cooperation strategies that can
lead to better performance than when each agent attempts to solve the optimization problem individually.
Another important question is how to develop strategies that endow networks with the ability to adapt
and learn in real-time in response to changes in the statistical properties of the data. This chapter provides
an overview of results in the area of diffusion adaptation with illustrative examples. Diffusion strategies
are powerful methods that enable adaptive learning and cooperation over networks. There have been
other useful works in the literature on the use of alternative consensus strategies to develop distributed
optimization solutions over networks. Nevertheless, we explain in Appendix E why diffusion strategies
outperform consensus strategies in terms of their mean-square-error stability and performance. For this
reason, we focus in the body of the chapter on presenting the theoretical foundations for diffusion
strategies and their performance.
3.09.1.3 Notation
In our treatment, we need to distinguish between random variables and deterministic quantities. For this
reason, we use boldface letters to represent random variables and normal font to represent deterministic
(non-random) quantities. For example, the boldface letter d denotes a random quantity, while the normal
font letter d denotes an observation or realization for it. We also need to distinguish between matrices
and vectors. For this purpose, we use CAPITAL letters to refer to matrices and small letters to refer
to both vectors and scalars; Greek letters always refer to scalars. For example, we write R to denote a
covariance matrix and w to denote a vector of parameters. We also write σ 2
v to refer to the variance of
a random variable. To distinguish between a vector d (small letter) and a scalar d (also a small letter),
we use parentheses to index scalar quantities and subscripts to index vector quantities. Thus, we write
d(i) to refer to the value of a scalar quantity d at time i, and di to refer to the value of a vector quantity
d at time i. Thus, d(i) denotes a scalar while di denotes a vector. All vectors in our presentation are
column vectors, with the exception of the regression vector (denoted by the letter u), which will be
taken to be a row vector for convenience of presentation. The symbol T denotes transposition, and the
symbol ∗denotes complex conjugation for scalars and complex-conjugate transposition for matrices.
The notation col{a, b} denotes a column vector with entries a and b stacked on top of each other,

3.09.2 Mean-Square-Error Estimation
327
Table 9.1 Summary of Notation Conventions Used in the Chapter
d
Boldface notation denotes random variables
d
Normal font denotes realizations of random variables
A
Capital letters denote matrices
a
Small letters denote vectors or scalars
α
Greek letters denote scalars
d(i)
Small letters with parenthesis denote scalars
di
Small letters with subscripts denote vectors
T
Matrix transposition
∗
Complex conjugation for scalars and complex-conjugate transposition for matrices
col{a, b}
Column vector with entries a and b
diag{a, b}
Diagonal matrix with entries a and b
vec(A)
Vectorizes matrix A and stacks its columns on top of each other
∥x∥
Euclidean norm of its vector argument
∥x∥2

Weighted square value x∗x
∥x∥b,∞
Block maximum norm of a block vector—see Appendix D
∥A∥b,∞
Block maximum norm of a matrix—see Appendix D
∥A∥
2-induced norm of matrix A (its largest singular value)
ρ(A)
Spectral radius of its matrix argument
IM
Identity matrix of size M × M; sometimes, we drop the subscript M
and the notation diag{a, b} denotes a diagonal matrix with entries a and b. Likewise, the notation
vec(A) vectorizes its matrix argument and stacks the columns of A on top of each other. The notation
∥x∥denotes the Euclidean norm of its vector argument, while ∥x∥b,∞denotes the block maximum
norm of a block vector (deﬁned in Appendix D). Similarly, the notation ∥x∥2
 denotes the weighted
square value, x∗x. Moreover, ∥A∥b,∞denotes the block maximum norm of a matrix (also deﬁned in
Appendix D), and ρ(A) denotes the spectral radius of the matrix (i.e., the largest absolute magnitude
among its eigenvalues). Finally, IM denotes the identity matrix of size M ×M; sometimes, for simplicity
of notation, we drop the subscript M from IM when the size of the identity matrix is obvious from the
context. Table 9.1 provides a summary of the symbols used in the chapter for ease of reference.
3.09.2 Mean-square-error estimation
Readers interested in the development of the distributed optimization strategies and their adaptive
versions can move directly to Section 3.09.3. The purpose of the current section is to motivate the
virtues of distributed in-network processing, and to provide illustrative examples in the context of
mean-square-error estimation. Advanced readers may skip this section.
We start our development by associating with each agent k an individual cost (or utility) function,
Jk(w). Although the algorithms presented in this chapter apply to more general situations, we neverthe-
less assume in our presentation that the cost functions Jk(w) are strictly convex so that each one of them

328
CHAPTER 9 Diffusion Adaptation Over Networks
has a unique minimizer. We further assume that, for all costs Jk(w), the minimum occurs at the same
value wo. Obviously, the choice of Jk(w) is limitless and is largely dependent on the application. It is
sufﬁcient for our purposes to illustrate the main concepts underlying diffusion adaptation by focusing
on the case of mean-square-error (MSE) or quadratic cost functions. In the sequel, we provide several
examples to illustrate how such quadratic cost functions arise in applications and how cooperative pro-
cessing over networks can be beneﬁcial. At the same time, we note that most of the arguments in this
chapter can be extended beyond MSE optimization to more general cost functions and to situations
where the minimizers of the individual costs Jk(w) need not agree with each other—as already shown
in [1–3]; see also Section 3.09.10.4 for a brief summary.
In non-cooperative solutions, each agent would operate individually on its own cost function Jk(w)
and optimize it to determines wo, without any interaction with the other nodes. However, the analysis and
derivations in future sections will reveal that nodes can beneﬁt from cooperation between them in terms
of better performance (such as converging faster to wo or tracking a changing wo more effectively)—see,
e.g., Theorems 9.6.3–9.6.5 and Section 3.09.7.3.
3.09.2.1 Application: autoregressive modeling
Our ﬁrst example relates to identifying the parameters of an auto-regressive (AR) model from noisy
data. Thus, consider a situation where agents are spread over some geographical region and each agent
k is observing realizations {dk(i)} of an AR zero-mean random process {dk(i)}, which satisﬁes a model
of the form:
dk(i) =
M

m=1
βmdk(i −m) + vk(i).
(9.4)
The scalars {βm} represent the model parameters that the agents wish to identify, and vk(i) represents
an additive zero-mean white noise process with power:
σ 2
v,k ≜E|vk(i)|2.
(9.5)
It is customary to assume that the noise process is temporally white and spatially independent so that
noise terms across different nodes are independent of each other and, at the same node, successive noise
samples are also independent of each other with a time-independent variance σ 2
v,k:
 Evk(i)v∗
k( j) = 0,
for all i ̸= j (temporal whiteness),
Evk(i)v∗
m( j) = 0,
for all i, j whenever k ̸= m (spatial whiteness).
(9.6)
The noise process vk(i) is further assumed to be independent of past signals {dℓ(i −m), m ≥1} across
all nodes ℓ. Observe that we are allowing the noise power proﬁle, σ 2
v,k, to vary with k. In this way, the
quality of the measurements is allowed to vary across the network with some nodes collecting noisier
data than other nodes. Figure 9.3 illustrates an example of a network consisting of N = 10 nodes spread
over a region in space. The ﬁgure shows the neighborhood of node 2, which consists of nodes {1, 2, 3}.
3.09.2.1.1
Linear model
To illustrate the difference between cooperative and non-cooperative estimation strategies, let us ﬁrst
explain that the data can be represented in terms of a linear model. To do so, we collect the model

3.09.2 Mean-Square-Error Estimation
329
FIGURE 9.3
A collection of nodes, spread over a geographic region, observes realizations of an AR random process and
cooperates to estimate the underlying model parameters {βm} in the presence of measurement noise. The
noise power proﬁle can vary over space.
parameters {βm} into an M × 1 column vector wo:
wo ≜col{β1, β2, . . . , βM}
(9.7)
and the past data into a 1 × M row regression vector uk,i:
uk,i ≜
dk(i −1) dk(i −2) · · · dk(i −M)
.
(9.8)
Then, we can rewrite the measurement equation (9.4) at each node k in the equivalent linear model form:
dk(i) = uk,iwo + vk(i) .
(9.9)
Linear relations of the form (9.9) are common in applications and arise in many other contexts (as
further illustrated by the next three examples in this section).
We assume the stochastic processes {dk(i), uk,i} in (9.9) have zero means and are jointly wide-sense
stationary. We denote their second-order moments by:
σ 2
d,k ≜E|dk(i)|2
(scalar),
(9.10)
Ru,k ≜Eu∗
k,iuk,i
(M × M),
(9.11)
rdu,k ≜Edk(i)u∗
k,i
(M × 1).
(9.12)
As was the case with the noise power proﬁle, we are allowing the moments

σ 2
d,k, Ru,k,rdu,k

to depend
on the node index k so that these moments can vary with the spatial dimension as well. The covariance

330
CHAPTER 9 Diffusion Adaptation Over Networks
matrix Ru,k is, by deﬁnition, always nonnegative deﬁnite. However, for convenience of presentation,
we shall assume that Ru,k is actually positive-deﬁnite (and, hence, invertible):
Ru,k > 0.
(9.13)
3.09.2.1.2
Non-cooperative mean-square-error solution
One immediate result that follows from the linear model (9.9) is that the unknown parameter vector wo
can be recovered exactly by each individual node from knowledge of the local moments {rdu,k, Ru,k}
alone. To see this, note that if we multiply both sides of (9.9) by u∗
k,i and take expectations we obtain
Eu∗
k,idk(i)

	

rdu,k
= (Eu∗
k,iuk,i)

	

Ru,k
wo + Eu∗
k,ivk(i)

	

=0
,
(9.14)
so that
rdu,k = Ru,kwo ⇐⇒wo = R−1
u,krdu,k .
(9.15)
It is seen from (9.15) that wo is the solution to a linear system of equations and that this solution can be
computed by every node directly from its moments {Ru,k,rdu,k}. It is useful to re-interpret construction
(9.15) as the solution to a minimum mean-square-error (MMSE) estimation problem [4,5]. Indeed, it
can be veriﬁed that the quantity R−1
u,krdu,k that appears in (9.15) is the unique solution to the following
MMSE problem:
min
w E|dk(i) −uk,iw|2 .
(9.16)
To verify this claim, we denote the cost function that appears in (9.16) by
Jk(w) ≜E|dk(i) −uk,iw|2
(9.17)
and expand it to ﬁnd that
Jk(w) = σ 2
d,k −w∗rdu,k −r∗
du,kw + w∗Ru,kw.
(9.18)
The cost function Jk(w) is quadratic in w and it has a unique minimizer since Ru,k > 0. Differentiating
Jk(w) with respect to w we ﬁnd its gradient vector:
∇w J(w) = (Ru,kw −rdu,k)∗.
(9.19)
It is seen that this gradient vector is annihilated at the same value w = wo given by (9.15). Therefore,
we can equivalently state that if each node k solves the MMSE problem (9.16), then the solution vector
coincides with the desired parameter vector wo. This observation explains why it is often justiﬁed to
consider mean-square-error cost functions when dealing with estimation problems that involve data that
satisfy linear models similar to (9.9).
Besides wo, the solution of the MMSE problem (9.16) also conveys information about the noise
level in the data. Note that by substituting wo from (9.15) into expression (9.16) for Jk(w), the resulting

3.09.2 Mean-Square-Error Estimation
331
minimum mean-square-error value that is attained by node k is found to be:
MSEk ≜Jk(wo)
= E|dk(i) −uk,iwo|2
(9.9)
= E|vk(i)|2
= σ 2
v,k
(9.20)
≜Jk,min.
We shall use the notation Jk(wo) and Jk,min interchangeably to denote the minimum cost value of
Jk(w). The above result states that, when each agent k recovers wo from knowledge of its moments
{Ru,k,rdu,k} using expression (9.15), then the agent attains an MSE performance level that is equal
to the noise power at its location, σ 2
v,k. An alternative useful expression for the minimum cost can be
obtained by substituting expression (9.15) for wo into (9.18) and simplifying the expression to ﬁnd that
MSEk = σ 2
d,k −r∗
du,k R−1
u,krdu,k.
(9.21)
This second expression is in terms of the data moments {σ 2
d,k,rdu,k, Ru,k}.
3.09.2.1.3
Non-cooperative adaptive solution
The optimal MMSE implementation (9.15) for determining wo requires knowledge of the statistical
information {rdu,k, Ru,k}. This information is usually not available beforehand. Instead, the agents are
more likely to have access to successive time-indexed observations {dk(i), uk,i} of the random processes
{dk(i), uk,i} for i ≥0. In this case, it becomes necessary to devise a scheme that would allow each
node to use its measurements to approximate wo. It turns out that an adaptive solution is possible. In
this alternative implementation, each node k feeds its observations {dk(i), uk,i} into an adaptive ﬁlter
and evaluates successive estimates for wo. As time passes by, the estimates would get closer to wo.
The adaptive solution operates as follows. Let wk,i denote an estimate for wo that is computed by
node k at time i based on all the observations {dk( j), uk, j, j ≤i} it has collected up to that time
instant. There are many adaptive algorithms that can be used to compute wk,i; some ﬁlters are more
accurate than others (usually, at the cost of additional complexity) [4–7]. It is sufﬁcient for our purposes
to consider one simple (yet effective) ﬁlter structure, while noting that most of the discussion in this
chapter can be extended to other structures. One of the simplest choices for an adaptive structure is the
least-mean-squares (LMS) ﬁlter, where the data are processed by each node k as follows:
ek(i) = dk(i) −uk,iwk,i−1,
(9.22)
wk,i = wk,i−1 + μku∗
k,iek(i),
i ≥0.
(9.23)
Starting from some initial condition, say, wk,−1 = 0, the ﬁlter iterates over i ≥0. At each time instant,
i, the ﬁlter uses the local data {dk(i), uk,i} at node k to compute a local estimation error, ek(i), via (9.22).
The error is then used to update the existing estimate from wk,i−1 to wk,i via (9.23). The factor μk that
appears in (9.23) is a constant positive step-size parameter; usually chosen to be sufﬁciently small to
ensure mean-square stability and convergence, as discussed further ahead in the chapter. The step-size

332
CHAPTER 9 Diffusion Adaptation Over Networks
parameter can be selected to vary with time as well; one popular choice is to replace μk in (9.23) with
the following construction:
μk(i) ≜
μk
ϵ + ∥uk,i∥2 ,
(9.24)
where ϵ > 0 is a small positive parameter and μk > 0. The resulting ﬁlter implementation is known
as normalized LMS [5] since the step-size is normalized by the squared norm of the regression vector.
Other choices include step-size sequences {μ(i) ≥0} that satisfy both conditions:
∞

i=0
μ(i) = ∞,
∞

i=0
μ2(i) < ∞.
(9.25)
Such sequences converge slowly towards zero. One example is the choice μk(i) =
μk
i+1. However, by
virtue of the fact that such step-sizes die out as i →∞, then these choices end up turning off adaptation.
As such, step-size sequences satisfying (9.25) are not generally suitable for applications that require
continuous learning, especially under non-stationary environments. For this reason, in this chapter, we
shall focus exclusively on the constant step-size case (9.23) in order to ensure continuous adaptation
and learning.
Equations (9.22) and (9.23) are written in terms of the observed quantities {dk(i), uk,i}; these are
deterministic values since they correspond to observations of the random processes {dk(i), uk,i}. Often,
when we are interested in highlighting the random nature of the quantities involved in the adaptation
step, especially when we study the mean-square performance of adaptive ﬁlters, it becomes more useful
to rewrite the recursions using the boldface notation to highlight the fact that the quantities that appear
in (9.22) and (9.23) are actually realizations of random variables. Thus, we also write:
ek(i) = dk(i) −uk,iwk,i−1,
(9.26)
wk,i = wk,i−1 + μku∗
k,iek(i),
i ≥0,
(9.27)
where {ek(i), wk,i} will be random variables as well.
The performance of adaptive implementations of this kind are well-understood for both cases of sta-
tionary wo and changing wo [4–7]. For example, in the stationary case, if the adaptive implementation
(9.26) and (9.27) were to succeed in having its estimator wk,i tend to wo with probability one as i →∞,
then we would expect the error signal ek(i) in (9.26) to tend towards the noise signal vk(i) (by virtue
of the linear model (9.9)). This means that, under this ideal scenario, the variance of the error signal
ek(i) would be expected to tend towards the noise variance, σ 2
v,k, as i →∞. Recall from (9.20) that
the noise variance is the least cost that the MSE solution can attain. Therefore, such limiting behavior
by the adaptive ﬁlter would be desirable. However, it is well-known that there is always some loss in
mean-square-error performance when adaptation is employed due to the effect of gradient noise, which
is caused by the algorithm’s reliance on observations (or realizations) {dk(i), uk,i} rather than on the
actual moments {rdu,k, Ru,k}. In particular, it is known that for LMS ﬁlters, the variance of ek(i) in
steady-state will be larger than σ 2
v,k by a small amount, and the size of the offset is proportional to the
step-size parameter μk (so that smaller step-sizes lead to better mean-square-error (MSE) performance
albeit at the expense of slower convergence). It is easy to see why the variance of ek(i) will be larger

3.09.2 Mean-Square-Error Estimation
333
than σ 2
v,k from the deﬁnition of the error signal in (9.26). Introduce the weight-error vector
˜wk,i ≜wo −wk,i
(9.28)
and the so-called a priori error signal
ea,k(i) ≜uk,i ˜wk,i−1 .
(9.29)
This second error measures the difference between the uncorrupted term uk,iwo and its estimator prior
to adaptation, uk,iwk,i−1. It then follows from the data model (9.9) and from the deﬁning expression
(9.26) for ek(i) that
ek(i) = dk(i) −uk,iwk,i−1
= uk,iwo + vk(i) −uk,iwk,i−1
= ea,k(i) + vk(i).
(9.30)
Since the noise component, vk(i), is assumed to be zero-mean and independent of all other random
variables, we conclude that
E|ek(i)|2 = E|ea,k(i)|2 + σ 2
v,k .
(9.31)
This relation holds for any time instant i; it shows that the variance of the output error, ek(i), is larger
than σ 2
v,k by an amount that is equal to the variance of the a priori error, ea,k(i). We deﬁne the ﬁlter mean-
square-error (MSE) and excess-mean-square-error (EMSE) as the following steady-state measures:
MSEk ≜lim
i→∞E|ek(i)|2,
(9.32)
EMSEk ≜lim
i→∞E|ea,k(i)|2,
(9.33)
so that, for the adaptive implementation (compare with (9.20)):
MSEk = EMSEk + σ 2
v,k .
(9.34)
Therefore, the EMSE term quantiﬁes the size of the offset in the MSE performance of the adaptive ﬁlter.
We also deﬁne the ﬁlter mean-square-deviation (MSD) as the steady-state measure:
MSDk ≜lim
i→∞E∥˜wk,i∥2,
(9.35)
which measures how far wk,i is from wo in the mean-square-error sense in steady-state. It is known that
the MSD and EMSE of LMS ﬁlters of the form (9.26) and (9.27) can be approximated for sufﬁciently
small-step sizes by the following expressions [4–7]:
EMSEk ≈μkσ 2
v,kTr(Ru,k)/2,
(9.36)
MSDk ≈μkσ 2
v,k M/2.
(9.37)
It is seen that the smaller the step-size parameter is, the better the performance of the adaptive solution.

334
CHAPTER 9 Diffusion Adaptation Over Networks
3.09.2.1.4
Cooperative adaptation through diffusion
Observe from (9.36) and (9.37) that even if all nodes employ the same step-size, μk = μ, and even if
the regression data are spatially uniform so that Ru,k = Ru for all k, the mean-square-error performance
across the nodes still varies in accordance with the variation of the noise power proﬁle, σ 2
v,k, across
the network. Nodes with larger noise power will perform worse than nodes with smaller noise power.
However, since all nodes are observing data arising from the same underlying model wo, it is natural to
expect cooperation among the nodes to be beneﬁcial. By cooperation we mean that neighboring nodes
can share information (such as measurements or estimates) with each other as permitted by the network
topology. Starting in the next section, we will motivate and describe algorithms that enable nodes to
carry out adaptation and learning in a cooperative manner to enhance performance.
Speciﬁcally, we are going to see that one way to achieve cooperation is by developing adaptive
algorithms that enable the nodes to optimize the following global cost function in a distributed manner:
min
w
N

k=1
E|dk(i) −uk,iw|2 ,
(9.38)
where the global cost is the aggregate objective:
J glob(w) ≜
N

k=1
E|dk(i) −uk,iw|2 =
N

k=1
Jk(w).
(9.39)
Comparing (9.38) with (9.16), we see that we are now adding the individual costs, Jk(w), from across
all nodes. Note that since the desired wo satisﬁes (9.15) at every node k, then it also satisﬁes
 M

k=1
Ru,k

wo =
N

k=1
rdu,k.
(9.40)
But it can be veriﬁed that the optimal solution to (9.38) is given by the same wo that satisﬁes (9.40).
Therefore, solving the global optimization problem (9.38) also leads to the desired wo. In future sections,
we will show how cooperative and distributed adaptive schemes for solving (9.38), such as (9.153) or
(9.154) further ahead, lead to improved performance in estimating wo (in terms of smaller mean-square-
deviation and faster convergence rate) than the non-cooperative mode (9.26) and (9.27), where each
agent runs its own individual adaptive ﬁlter—see, e.g., Theorems 9.6.3–9.6.5 and Section 3.09.7.3.
3.09.2.2 Application: tapped-delay-line models
Our second example to motivate MSE cost functions, Jk(w), and linear models relates to identifying
the parameters of a moving-average (MA) model from noisy data. MA models are also known as
ﬁnite-impulse-response (FIR) or tapped-delay-line models. Thus, consider a situation where agents are
interested in estimating the parameters of an FIR model, such as the taps of a communications channel
or the parameters of some (approximate) model of interest in ﬁnance or biology. Assume the agents are
able to independently probe the unknown model and observe its response to excitations in the presence

3.09.2 Mean-Square-Error Estimation
335
FIGURE 9.4
The network is interested in estimating the parameter vector w o that describes an underlying tapped-delay-
line model. The agents are assumed to be able to independently probe the unknown system, and observe its
response to excitations, under noise, as indicated in the highlighted diagram for node 4.
of additive noise; this situation is illustrated in Figure 9.4, with the probing operation highlighted for
one of the nodes (node 4).
The schematics inside the enlarged diagram in Figure 9.4 is meant to convey that each node k probes
the model with an input sequence {uk(i)} and measures the resulting response sequence, {dk(i)}, in the
presence of additive noise. The system dynamics for each agent k is assumed to be described by a MA
model of the form:
dk(i) =
M−1

m=0
βmuk(i −m) + vk(i).
(9.41)
In this model, the term vk(i) again represents an additive zero-mean noise process that is assumed to be
temporally white and spatially independent; it is also assumed to be independent of the input process,
{uℓ( j)}, for all i, j, and ℓ. The scalars {βm} represent the model parameters that the agents seek to
identify. If we again collect the model parameters into an M × 1 column vector wo:
wo ≜col{β0, β1, . . . , βM−1}
(9.42)
and the input data into a 1 × M row regression vector:
uk,i ≜
uk(i) uk(i −1) · · · uk(i −M + 1)
(9.43)

336
CHAPTER 9 Diffusion Adaptation Over Networks
then, we can again express the measurement equation (9.41) at each node k in the same linear model as
(9.9), namely,
dk(i) = uk,iwo + vk(i) .
(9.44)
As was the case with model (9.9), we can likewise verify that, in view of (9.44), the desired parameter
vector wo satisﬁes the same normal equations (9.15), i.e.,
rdu,k = Ru,kwo ⇐⇒wo = R−1
u,krdu,k,
(9.45)
where the moments {rdu,k, Ru,k} continue to be deﬁned by expressions (9.11) and (9.12) with uk,i now
deﬁned by (9.43). Therefore, each node k can determine wo on its own by solving the same MMSE
estimation problem (9.16). This solution method requires knowledge of the moments {rdu,k, Ru,k} and,
according to (9.20), each agent k would then attain an MSE level that is equal to the noise power level
at its location.
Alternatively, when the statistical information {rdu,k, Ru,k} is not available, each agent k can estimate
wo iteratively by feeding data {dk(i), uk,i} into the adaptive implementation (9.26) and (9.27). In this
way, each agent k will achieve the same performance level shown earlier in (9.36) and (9.37), with the
limiting performance being again dependent on the local noise power level, σ 2
v,k. Therefore, nodes with
larger noise power will perform worse than nodes with smaller noise power. However, since all nodes are
observing data arising from the same underlying model wo, it is natural to expect cooperation among the
nodes to be beneﬁcial. As we are going to see, starting from the next section, one way to achieve cooper-
ation and improve performance is by developing algorithms that optimize the same global cost function
(9.38) in an adaptive and distributed manner, such as algorithms (9.153) and (9.154) further ahead.
3.09.2.3 Application: target localization
Our third example relates to the problem of locating a destination of interest (such as the location of a
nutrition source or a chemical leak) or locating and tracking an object of interest (such as a predator or
a projectile). In several such localization applications, the agents in the network are allowed to move
towards the target or away from it, in which case we would end up with a mobile adaptive network [8].
Biological networks behave in this manner such as networks representing ﬁsh schools, bird formations,
bee swarms, bacteria motility, and diffusing particles [8–12]. The agents may move towards the target
(e.g., when it is a nutrition source) or away from the target (e.g., when it is a predator). In other
applications, the agents may remain static and are simply interested in locating a target or tracking it
(such as tracking a projectile).
To motivate mean-square-error estimation in the context of localization problems, we consider the
situation corresponding to a static target and static nodes. Thus, assume that the unknown location of the
target in the cartesian plane is represented by the 2 × 1 vector wo = col{xo, yo}. The agents are spread
over the same region of space and are interested in locating the target. The location of every agent k
is denoted by the 2 × 1 vector pk = col{xk, yk} in terms of its x and y coordinates—see Figure 9.5.
We assume the agents are aware of their location vectors. The distance between agent k and the target
is denoted by ro
k and is equal to:
ro
k = ∥wo −pk∥.
(9.46)

3.09.2 Mean-Square-Error Estimation
337
FIGURE 9.5
The distance from node k to the target is denoted by r o
k and the unit-norm direction vector from the same
node to the target is denoted by uo
k . Node k is assumed to have access to noisy measurements of

r o
k , uo
k

.
The 1 × 2 unit-norm direction vector pointing from agent k towards the target is denoted by uo
k and is
given by:
uo
k = (wo −pk)T
∥wo −pk∥.
(9.47)
Observe from (9.46) and (9.47) that ro
k can be expressed in the following useful inner-product form:
ro
k = uo
k(wo −pk).
(9.48)
In practice, agents have noisy observations of both their distance and direction vector towards the
target. We denote the noisy distance measurement collected by node k at time i by:
rk(i) = ro
k + vk(i),
(9.49)
where vk(i) denotes noise and is assumed to be zero-mean, and temporally white and spatially in-
dependent with variance
σ 2
v,k ≜E|vk(i)|2.
(9.50)
We also denote the noisy direction vector that is measured by node k at time i by uk,i. This vector is a
perturbed version of uo
k. We assume that uk,i continues to start from the location of the node at pk, but
that its tip is perturbed slightly either to the left or to the right relative to the tip of uo
k—see Figure 9.6.
The perturbation to the tip of uo
k is modeled as being the result of two effects: a small deviation that
occurs along the direction that is perpendicular to uo
k, and a smaller deviation that occurs along the
direction of uo
k. Since we are assuming that the tip of uk,i is only slightly perturbed relative to the tip
of uo
k, then it is reasonable to expect the amount of perturbation along the parallel direction to be small
compared to the amount of perturbation along the perpendicular direction.

338
CHAPTER 9 Diffusion Adaptation Over Networks
FIGURE 9.6
The tip of the noisy direction vector is modeled as being approximately perturbed away from the actual
direction by two effects: a larger effect caused by a deviation along the direction that is perpendicular to uo
k ,
and a smaller deviation along the direction that is parallel to uo
k .
Thus, we write
uk,i = uo
k + αk(i)uo⊥
k
+ βk(i)uo
k
(1 × 2),
(9.51)
whereuo⊥
k
denotesaunit-normrowvectorthatliesinthesameplaneandwhosedirectionisperpendicular
to uo
k. The variables αk(i) and βk(i) denote zero-mean independent random noises that are temporally
white and spatially independent with variances:
σ 2
α,k ≜E|αk(i)|2,
σ 2
β,k ≜E|βk(i)|2.
(9.52)
We assume the contribution of βk(i) is small compared to the contributions of the other noise sources,
αk(i) and vk(i), so that
σ 2
β,k ≪σ 2
α,k,
σ 2
β,k ≪σ 2
v,k.
(9.53)
The random noises {vk(i), αk(i), βk(i)} are further assumed to be independent of each other.
Using (9.48) we ﬁnd that the noisy measurements {rk(i), uk,i} are related to the unknown wo via:
rk(i) = uk,i(wo −pk) + zk(i),
(9.54)
where the modiﬁed noise term zk(i) is deﬁned in terms of the noises in rk(i) and uk,i as follows:
zk(i) ≜vk(i) −αk(i)uo⊥
k (wo −pk) −βk(i)uo
k(wo −pk)
= vk(i) −βk(i)ro
k
≈vk(i),
(9.55)
since, by construction,
uo⊥
k (wo −pk) = 0
(9.56)

3.09.2 Mean-Square-Error Estimation
339
and the contribution by βk(i) is assumed to be sufﬁciently small. If we now introduce the adjusted
signal:
dk(i) ≜rk(i) + uk,i pk,
(9.57)
then we arrive again from (9.54) and (9.55) at the following linear model for the available measurement
variables {dk(i), uk,i} in terms of the target location wo:
dk(i) ≈uk,iwo + vk(i) .
(9.58)
There is one important difference in relation to the earlier linear models (9.9) and (9.44), namely, the
variables {dk(i), uk,i} in (9.58) do not have zero means any longer. It is nevertheless straightforward
to determine the ﬁrst and second-order moments of the variables {dk(i), uk,i}. First, note from (9.49),
(9.51), and (9.57) that
Euk,i = uo
k,
Edk(i) = ro
k + uo
k pk.
(9.59)
Even in this case of non-zero means, and in view of (9.58), the desired parameter vector wo can still be
shown to satisfy the same normal equations (9.15), i.e.,
rdu,k = Ru,kwo ⇐⇒wo = R−1
u,krdu,k,
(9.60)
where the moments {rdu,k, Ru,k} continue to be deﬁned as
Ru,k ≜Eu∗
k,iuk,i,
rdu,k ≜Eu∗
k,idk(i).
(9.61)
To verify that (9.60) holds, we simply multiply both sides of (9.58) by u∗
k,i from the left, compute the
expectations of both sides, and use the fact that vk(i) has zero mean and is assumed to be independent
of {uℓ, j} for all times j and nodes ℓ. However, the difference in relation to the earlier normal equations
(9.15) is that the matrix Ru,k is not the actual covariance matrix of uk,i any longer. When uk,i is not
zero mean, its covariance matrix is instead deﬁned as:
covu,k ≜E

uk,i −uo
k
∗
uk,i −uo
k

= Eu∗
k,iuk,i −uo∗
k uo
k,
(9.62)
so that
Ru,k = covu,k + uo∗
k uo
k.
(9.63)
We conclude from this relation that Ru,k is positive-deﬁnite (and, hence, invertible) so that expression
(9.60) is justiﬁed. This is because the covariance matrix, covu,k, is itself positive-deﬁnite. Indeed, some
algebra applied to the difference uk,i −uo
k from (9.51) shows that
covu,k =

uo⊥
k
∗

uo
k
∗ σ 2
α,k
σ 2
β,k
 
uo⊥
k
uo
k

,
(9.64)
where the matrix

uo⊥
k
uo
k

(9.65)
is full rank since the rows {uo
k, uo⊥
k } are linearly independent vectors.

340
CHAPTER 9 Diffusion Adaptation Over Networks
Therefore, each node k can determine wo on its own by solving the same minimum mean-square-
error estimation problem (9.16). This solution method requires knowledge of the moments {rdu,k, Ru,k}
and, according to (9.20), each agent k would then attain an MSE level that is equal to the noise power
level, σ 2
v,k, at its location.
Alternatively, when the statistical information {rdu,k, Ru,k} is not available beforehand, each agent
k can estimate wo iteratively by feeding data {dk(i), uk,i} into the adaptive implementation (9.26) and
(9.27). In this case, each agent k will achieve the performance level shown earlier in (9.36) and (9.37),
with the limiting performance being again dependent on the local noise power level, σ 2
v,k. Therefore,
nodes with larger noise power will perform worse than nodes with smaller noise power. However, since
all nodes are observing distances and direction vectors towards the same target location wo, it is natural
to expect cooperation among the nodes to be beneﬁcial. As we are going to see, starting from the next
section, one way to achieve cooperation and improve performance is by developing algorithms that
solve the same global cost function (9.38) in an adaptive and distributed manner, by using algorithms
such as (9.153) and (9.154) further ahead.
3.09.2.3.1
Role of adaptation
The localization application helps highlight one of the main advantages of adaptation, namely, the
ability of adaptive implementations to learn and track changing statistical conditions. For example, in
the context of mobile networks, where nodes can move closer or further away from a target, the location
vector for each agent k becomes time-dependent, say, pk,i = col{xk(i), yk(i)}. In this case, the actual
distance and direction vector between agent k and the target also vary with time and become:
ro
k (i) = ∥wo −pk,i∥,
uo
k,i = (wo −pk,i)T
∥wo −pk,i∥.
(9.66)
The noisy distance measurement to the target is then:
rk(i) = ro
k (i) + vk(i),
(9.67)
where the variance of vk(i) now depends on time as well:
σ 2
v,k(i) ≜E|vk(i)|2.
(9.68)
In the context of mobile networks, it is reasonable to assume that the variance of vk(i) varies both with
time and with the distance to the target: the closer the node is to the target, the less noisy the measurement
of the distance is expected to be. Similar remarks hold for the variances of the noises αk(i) and βk(i)
that perturb the measurement of the direction vector, say,
σ 2
α,k(i) ≜E|αk(i)|2,
σ 2
β,k(i) ≜E|βk(i)|2,
(9.69)
where now
uk,i = uo
k,i + αk(i)uo⊥
k,i + βk(i)uo
k,i.
(9.70)
The same arguments that led to (9.58) can be repeated to lead to the same model, except that now the
means of the variables {dk(i), uk,i} become time-dependent as well:
Euk,i = uo
k,i,
Edk(i) = ro
k (i) + uo
k,i pk,i.
(9.71)

3.09.2 Mean-Square-Error Estimation
341
Nevertheless, adaptive solutions (whether cooperative or non-cooperative), are able to track such time-
variations because these solutions work directly with the observations {dk(i), uk,i} and the successive
observations will reﬂect the changing statistical proﬁle of the data. In general, adaptive solutions are able
to track changes in the underlying signal statistics rather well [4,5], as long as the rate of non-stationarity
is slow enough for the ﬁlter to be able to follow the changes.
3.09.2.4 Application: collaborative spectral sensing
Our fourth and last example to illustrate the role of mean-square-error estimation and cooperation relates
to spectrum sensing for cognitive radio applications. Cognitive radio systems involve two types of users:
primary users and secondary users. To avoid causing harmful interference to incumbent primary users,
unlicensed cognitive radio devices need to detect unused frequency bands even at low signal-to-noise
(SNR) conditions [13–16]. One way to carry out spectral sensing is for each secondary user to estimate
the aggregated power spectrum that is transmitted by all active primary users, and to locate unused
frequency bands within the estimated spectrum. This step can be performed by the secondary users with
or without cooperation.
Thus, consider a communications environment consisting of Q primary users and N secondary
users. Let Sq(e jω) denote the power spectrum of the signal transmitted by primary user q. To facilitate
estimation of the spectral proﬁle by the secondary users, we assume that each Sq(e jω) can be represented
as a linear combination of some basis functions, { fm(e jω)}, say, B of them [17]:
Sq(e jω) =
B

m=1
βqm fm(e jω),
q = 1, 2, . . . , Q.
(9.72)
In this representation, the scalars {βqm} denote the coefﬁcients of the basis expansion for user q. The
variable ω ∈[−π, π] denotes the normalized angular frequency measured in radians/sample. The power
spectrum is often symmetric about the vertical axis, ω = 0, and therefore it is sufﬁcient to focus on
the interval ω ∈[0, π]. There are many ways by which the basis functions, { fm(e jω)}, can be selected.
The following is one possible construction for illustration purposes. We divide the interval [0, π] into
B identical intervals and denote their center frequencies by {ωm}. We then place a Gaussian pulse at
each location ωm and control its width through the selection of its standard deviation, σm, i.e.,
fm(e jω) ≜e
−(ω−ωm)2
σ2m
.
(9.73)
Figure 9.7 illustrates this construction. The parameters {ωm, σm} are selected by the designer and are
assumed to be known. For a sufﬁciently large number, B, of basis functions, the representation (9.72)
can approximate well a large class of power spectra.
We collect the combination coefﬁcients {βqm} for primary user q into a column vector wq:
wq ≜col{βq1, βq2, βq3, . . . , βq B} (B × 1)
(9.74)
and collect the basis functions into a row vector:
fω ≜

f1(e jω)
f2(e jω) · · ·
fB(e jω)

(1 × B).
(9.75)

342
CHAPTER 9 Diffusion Adaptation Over Networks
FIGURE 9.7
The interval [0, π] is divided into B sub-intervals of equal width; the center frequencies of the sub-intervals
are denoted by {ωm}. A power spectrum Sq(ejω) is approximated as a linear combination of Gaussian basis
functions centered on the {ωm}.
Then, the power spectrum (9.72) can be expressed in the alternative inner-product form:
Sq(e jω) = fωwq.
(9.76)
Let pqk denote the path loss coefﬁcient from primary user q to secondary user k. When the transmitted
spectrum Sq(e jω) travels from primary user q to secondary user k, the spectrum that is sensed by node
k is pqkSq(e jω). We assume in this example that the path loss factors {pqk} are known and that they
have been determined during a prior training stage involving each of the primary users with each of the
secondary users. The training is usually repeated at regular intervals of time to accommodate the fact
that the path loss coefﬁcients can vary (albeit slowly) over time. Figure 9.8 depicts a cognitive radio
system with 2 primary users and 10 secondary users. One of the secondary users (user 5) is highlighted
and the path loss coefﬁcients from the primary users to its location are indicated; similar path loss
coefﬁcients can be assigned to all other combinations involving primary and secondary users.
Each user k senses the aggregate effect of the power spectra that are transmitted by all active primary
users. Therefore, adding the effect of all primary users, we ﬁnd that the power spectrum thatarrives at
secondary user k is given by:
Sk(e jω) =
Q

q=1
pqkSq(e jω) + σ 2
k
=
Q

q=1
pqk fωwq + σ 2
k
≜uk,ωwo + σ 2
k ,
(9.77)
where σ 2
k denotes the receiver noise power at node k, and where we introduced the following vector
quantities:
wo ≜col{w1, w2, . . . , wQ} (BQ × 1),
(9.78)
uk,ω ≜
 p1k fω
p2k fω
· · ·
pQk fω

(1 × BQ).
(9.79)

3.09.2 Mean-Square-Error Estimation
343
FIGURE 9.8
A network of secondary users in the presence of two primary users. One of the secondary users is highlighted
and the path loss coefﬁcients from the primary users to its location are indicated as p15 and p25.
The vector wo is the collection of all combination coefﬁcients for all Q primary users. The vector uk,ω
contains the path loss coefﬁcients from all primary users to user k. Now, at every time instant i, user k
observers its received power spectrum, Sk(e jω), over a discrete grid of frequencies, {ωr}, in the interval
[0, π] in the presence of additive measurement noise. We denote these measurements by:
dk,r(i) = uk,ωr wo + σ 2
k + vk,r(i),
r = 1, 2, . . . , R.
(9.80)
The term vk,r(i) denotes sampling noise and is assumed to have zero mean and variance σ 2
v,k; it is also
assumed to be temporally white and spatially independent; and is also independentof all other random
variables. Since the row vectors uk,ω in (9.79) are deﬁned in terms of the path loss coefﬁcients {pqk}, and
since these coefﬁcients are estimated and subject to noisy distortions, we model the uk,ωr as zero-mean
random variables in (9.80) and use the boldface notation for them.
Observe that in this application, each node k collects R measurements at every time instant i and not
only a single measurement, as was the case with the three examples discussed in the previous sections
(AR modeling, MA modeling, and localization). The implication of this fact is that we now deal with
an estimation problem that involves vector measurements instead of scalar measurements at each node.
The solution structure continues to be the same. We collect the R measurements at node k at time i into
vectors and introduce the R × 1 quantities:
dk,i ≜
⎡
⎢⎢⎢⎢⎣
dk,1(i) −σ 2
k
dk,2(i) −σ 2
k
...
dk,R(i) −σ 2
k
⎤
⎥⎥⎥⎥⎦
,
vk,i ≜
⎡
⎢⎢⎢⎣
vk,1(i)
vk,2(i)
...
vk,R(i)
⎤
⎥⎥⎥⎦
(9.81)

344
CHAPTER 9 Diffusion Adaptation Over Networks
and the regression matrix:
Uk,i ≜
⎡
⎢⎢⎢⎣
uk,ω1
uk,ω2
...
uk,ωR
⎤
⎥⎥⎥⎦
(R × QB).
(9.82)
The time subscript in Uk,i is used to model the fact that the path loss coefﬁcients can change over time
due to the possibility of node mobility. With the above notation, expression (9.80) is equivalent to the
linear model:
dk,i = Uk,iwo + vk,i .
(9.83)
Compared to the earlier examples (9.9), (9.44), and (9.58), the main difference now is that each agent
k collects a vector of measurements, dk,i, as opposed to the scalar dk(i), and its regression data are
represented by the matrix quantity, Uk,i, as opposed to the row vector uk,i. Nevertheless, the estimation
approach will continue to be the same. In cognitive network applications, the secondary users are
interested in estimating the aggregate power spectrum of the primary users in order for the secondary
users to identify vacant frequency bands that can be used by them. In the context of model (9.83), this
amounts to determining the parameter vector wo since knowledge of its entries allows each secondary
user to reconstruct the aggregate power spectrum deﬁned by:
SA(e jω) ≜
Q

q=1
Sq(e jω) = (1T
Q ⊗fω)wo,
(9.84)
where the notation ⊗denotes the Kronecker product operation, and 1Q denotes a Q × 1 vector whose
entries are all equal to one.
As before, we can again verify that, in view of (9.83), the desired parameter vector wo satisﬁes the
same normal equations:
RdU,k = RU,kwo ⇐⇒wo = R−1
U,k RdU,k,
(9.85)
where the moments {RdU,k, RU,k} are now deﬁned by
RdU,k ≜EU∗
k,idk,i
(QB × 1),
(9.86)
RU,k ≜EU∗
k,iUk,i
(QB × QB).
(9.87)
Therefore, each secondary user k can determine wo on its own by solving the following minimum
mean-square-error estimation problem:
min
w E∥dk,i −Uk,iw∥2.
(9.88)
This solution method requires knowledge of the moments {RdU,k, RU,k} and, in an argument similar to
the one that led to (9.20), it can be veriﬁed that each agent k would attain an MSE performance level
that is equal to the noise power level, σ 2
v,k, at its location.

3.09.3 Distributed Optimization Via Diffusion Strategies
345
Alternatively, when the statistical information {RdU,k, RU,k} is not available, each secondary user
k can estimate wo iteratively by feeding data {dk,i, Uk,i} into an adaptive implementation similar to
(9.26) and (9.27), such as the following vector LMS recursion:
ek,i = dk,i −Uk,iwk,i−1,
(9.89)
wk,i = wk,i−1 + μkU∗
k,iek,i.
(9.90)
In this case, each secondary user k will achieve performance levels similar to (9.36) and (9.37) with M
replaced by QB and Ru,k replaced by RU,k. The performance will again be dependent on the local noise
level, σ 2
v,k. As a result, secondary users with larger noise power will perform worse than secondary users
with smaller noise power. However, since all secondary users are observing data arising from the same
underlying model wo, it is natural to expect cooperation among the users to be beneﬁcial. As we are
going to see, starting from the next section, one way to achieve cooperation and improve performance
is by developing algorithms that solve the following global cost function in an adaptive and distributed
manner:
min
w
N

k=1
E∥dk,i −Uk,iw∥2.
(9.91)
3.09.3 Distributed optimization via diffusion strategies
The examples in the previous section were meant to illustrate how MSE cost functions and linear models
are useful design tools and how they arise frequently in applications. We now return to problem (9.1) and
study the distributed optimization of global cost functions such as (9.39), where J glob(w) is assumed to
consist of the sum of individual components. Speciﬁcally, we are now interested in solving optimization
problems of the type:
min
w
N

k=1
Jk(w),
(9.92)
where each Jk(w) is assumed to be differentiable and convex over w. Although the algorithms presented
in this chapter apply to more general situations, we shall nevertheless focus onmean-square-error cost
functions of the form:
Jk(w) ≜E|dk(i) −uk,iw|2 ,
(9.93)
where w is an M × 1 column vector, and the random processes {dk(i), uk,i} are assumed to be jointly
wide-sense stationary with zero-mean and second-order moments:
σ 2
d,k ≜E|dk(i)|2,
(9.94)
Ru,k ≜Eu∗
k,iuk,i > 0 (M × M),
(9.95)
rdu,k ≜Edk(i)u∗
k,i
(M × 1).
(9.96)
It is clear that each Jk(w) is quadratic in w since, after expansion, we get
Jk(w) = σ 2
d,k −w∗rdu,k −r∗
du,kw + w∗Ru,kw .
(9.97)

346
CHAPTER 9 Diffusion Adaptation Over Networks
A completion-of-squares argument shows that Jk(w) can be expressed as the sum of two squared
terms, i.e.,
Jk(w) =

σ 2
d,k −r∗
du,k R−1
u,krdu,k

+ (w −wo)∗Ru,k(w −wo)
(9.98)
or, more compactly,
Jk(w) = Jk,min + ∥w −wo∥2
Ru,k ,
(9.99)
where wo denotes the minimizer of Jk(w) and is given by
wo ≜R−1
u,krdu,k
(9.100)
and Jk,min denotes the minimum value of Jk(w) when evaluated at w = wo:
Jk,min ≜σ 2
d,k −r∗
du,k R−1
u,krdu,k = Jk(wo) .
(9.101)
Observe that this value is necessarily nonnegative since it can be viewed as the Schur complement of
the following covariance matrix:
E
d∗
k(i)
u∗
k,i
 dk(i) uk,i

=
 σ 2
d,k
r∗
du,k
rdu,k
Ru,k

(9.102)
and covariance matrices are nonnegative-deﬁnite.
The choice of the quadratic form (9.93) or (9.97) for Jk(w) is useful for many applications, as
was already illustrated in the previous section for examples involving AR modeling, MA modeling,
localization, and spectral sensing. Other choices for Jk(w) are of course possible and these choices
can even be different for different nodes. It is sufﬁcient in this chapter to illustrate the main concepts
underlying diffusion adaptation by focusing on the useful case of MSE cost functions of the form
(9.97); still, most of the derivations and arguments in the coming sections can be extended beyond MSE
optimization to more general cost functions and to situations where the minimizers of the individual costs
do not necessarily occur at the same location—as already shown in [1–3]; see also Section 3.09.10.4.
The positive-deﬁniteness of the covariance matrices {Ru,k} ensures that each Jk(w) in (9.97) is strictly
convex, as well as J glob(w) from (9.39). Moreover, all these cost functions have a uniqueminimum at
the same wo, which satisﬁes the normal equations:
Ru,kwo = rdu,k,
for every k = 1, 2, . . . , N.
(9.103)
Therefore, given knowledge of {rdu,k, Ru,k}, each node can determine wo on its own by solving (9.103).
One then wonders about the need to seek distributed cooperative and adaptive solutions in this case.
There are a couple of reasons:
a. First, even for MSE cost functions, it is often the case that the required moments {rdu,k, Ru,k} are not
known beforehand. In this case, the optimal wo cannot be determined from the solution of the normal
equations (9.103). The alternative methods that we shall describe will lead to adaptive techniques
that enable each node k to estimate wo directly from data realizations.

3.09.3 Distributed Optimization Via Diffusion Strategies
347
b. Second, since adaptive strategies rely on instantaneous data, these strategies possess powerful track-
ing abilities. Even when the moments vary with time due to non-stationary behavior (such as wo
changing with time), these changes will be reﬂected in the observed data and will in turn inﬂuence
the behavior of the adaptive construction. This is one of the key advantages of adaptive strategies:
they enable learning and tracking in real-time.
c. Third, cooperation among nodes is generally beneﬁcial. When nodes act individually, their perfor-
mance is limited by the noise power level at their location. In this way, some nodes can perform
signiﬁcantly better than other nodes. On the other hand, when nodes cooperate with their neighbors
and share information during the adaptation process, we will see that performance can be improved
across the network.
3.09.3.1 Relating the global cost to neighborhood costs
Let us therefore consider the optimization of the following global cost function:
J glob(w) =
N

k=1
Jk(w) ,
(9.104)
where Jk(w) is given by (9.93) or (9.97). Our strategy to optimize J glob(w) in a distributed manner is
based on two steps [2,18]. First, using a completion-of-squares argument (or, equivalently, a second-
order Taylor series expansion), we approximate the global cost function (9.104) by an alternative local
cost that is amenable to distributed optimization. Then, each node will optimize the alternative cost via
a steepest-descent method.
To motivate the distributed diffusion-based approach, we start by introducing a set of nonnegative
coefﬁcients {ckℓ} that satisfy two conditions:
for k = 1, 2, . . . , N :
ckℓ≥0,
N

ℓ=1
ckℓ= 1,
and ckℓ= 0 if ℓ/∈Nk,
(9.105)
where Nk denotes the neighborhood of node k. Condition (9.105) means that for every node k, the sum
of the coefﬁcients {ckℓ} that relate it to its neighbors is one. The coefﬁcients {ckℓ} are free parameters
that are chosen by the designer; obviously, as shown later in Theorem 9.6.8, their selection will have a
bearing on the performance of the resulting algorithms. If we collect the entries {ckℓ} into an N × N
matrix C, so that the kth row of C is formed of {ckℓ, ℓ= 1, 2, . . . , N}, then condition (9.105) translates
into saying that each of row of C adds up to one, i.e.,
C1 = 1 ,
(9.106)
where the notation 1 denotes an N × 1 column vector with all its entries equal to one:
1 ≜col{1, 1, . . . , 1}.
(9.107)

348
CHAPTER 9 Diffusion Adaptation Over Networks
We say that C is a right stochastic matrix. Using the coefﬁcients {ckℓ} so deﬁned, we associate with
each node ℓ, a local cost function of the following form:
J loc
ℓ(w) ≜

k∈Nℓ
ckℓJk(w).
(9.108)
This cost consists of a weighted combination of the individual costs of the neighbors of node ℓ(including
ℓitself)—see Figure 9.9. Since the {ckℓ} are all nonnegative and each Jk(w) is strictly convex, then
J loc
ℓ(w) is also strictly convex and its minimizer occurs at the same w = wo. Using the alternative
representation (9.99) for the individual Jk(w), we can re-express the local cost J loc
ℓ(w) as
J loc
ℓ(w) =

k∈Nℓ
ckℓJk,min +

k∈Nℓ
ckℓ∥w −wo∥2
Ru,k
(9.109)
or, equivalently,
J loc
ℓ(w) = J loc
ℓ,min + ∥w −wo∥2
Rℓ,
(9.110)
where J loc
ℓ,min corresponds to the minimum value of J loc
ℓ(w) at the minimizer w = wo:
J loc
ℓ,min ≜

k∈Nℓ
ckℓJk,min
(9.111)
FIGURE 9.9
A network with N = 10 nodes. The nodes in the neighborhood of node 3 are highlighted with their individual
cost functions, and with the combination weights {c13,c23,c53} along the connecting edges; there is also a
combination weight associated with node 3 and is denoted by c33. The expression for the local cost function,
Jloc
3 (w), is also shown in the ﬁgure.

3.09.3 Distributed Optimization Via Diffusion Strategies
349
and Rℓis a positive-deﬁnite weighting matrix deﬁned by:
Rℓ≜

k∈Nℓ
ckℓRu,k.
(9.112)
That is, Rℓis a weighted combination of the covariance matrices in the neighborhood of node ℓ. Equality
(9.110) amounts to a (second-order) Taylor series expansion of J loc
ℓ(w) around w = wo. Note that the
right-hand side consists of two terms: the minimum cost and a weighted quadratic term in the difference
(w −wo).
Now note that we can express J glob(w) from (9.104) as follows:
J glob(w)
(9.105)
=
N

k=1
 N

ℓ=1
ckℓ

Jk(w)
=
N

ℓ=1
 N

k=1
ckℓJk(w)

(9.108)
=
N

ℓ=1
J loc
ℓ(w)
=
J loc
k (w) +
N

ℓ̸=k
J loc
ℓ(w).
(9.113)
Substituting (9.110) into the second term on the right-hand side of the above expression gives:
J glob(w) = J loc
k (w) +

ℓ̸=k
∥w −wo∥2
Rℓ+

ℓ̸=k
J loc
ℓ,min.
(9.114)
The last term in the above expression does not depend on w. Therefore, minimizing J glob(w) over w is
equivalent to minimizing the following alternative global cost:
J glob′(w) = J loc
k (w) +

ℓ̸=k
∥w −wo∥2
Rℓ.
(9.115)
Expression (9.115) relates the optimization of the original global cost function, J glob(w) or its equivalent
J glob′(w),tothenewly-introducedlocalcostfunction J loc
k (w).Therelationisthroughthesecondtermon
the right-hand side of (9.115), which corresponds to a sum of quadratic factors involving the minimizer
wo; this term tells us how the local cost J loc
k (w) can be corrected to the global cost J glob′(w). Obviously,
the minimizer wo that appears in the correction term is not known since the nodes wish to determine
its value. Likewise, not all the weighting matrices Rℓare available to node k; only those matrices that
originate from its neighbors can be assumed to be available. Still, expression (9.115) suggests a useful
way to replace J loc
k
by another local cost that is closer to J glob′(w). This alternative cost will be shown
to lead to a powerful distributed solution to optimize J glob(w) through localized interactions.

350
CHAPTER 9 Diffusion Adaptation Over Networks
Our ﬁrst step is to limit the summation on the right-hand side of (9.115) to the neighbors of node
k (since every node k can only have access to information from its neighbors). We thus introduce the
modiﬁed cost function at node k:
J glob′
k
(w) ≜J loc
k (w) +

ℓ∈Nk\{k}
∥w −wo∥2
Rℓ.
(9.116)
The cost functions J loc
k (w) and J glob′
k
(w) are both associated with node k; the difference between them
is that the expression for the latter is closer to the global cost function (9.115) that we want to optimize.
The weighting matrices {Rℓ} that appear in (9.116) may or may not be available because the second-
order moments {Ru,ℓ} may or may not be known beforehand. If these moments are known, then we can
proceedwiththeanalysisbyassumingknowledgeofthe{Rℓ}.However,themoreinterestingcaseiswhen
these moments are not known. This is generally the case in practice, especially in the context of adaptive
solutions and problems involving non-stationary data. Often, nodes can only observe realizations {uℓ,i}
of the regression data {uℓ,i} arising from distributions whose covariance matrices are the unknown
{Ru,ℓ}. One way to address the difﬁculty is to replace each of the weighted norms ∥w −wo∥2
Rℓin
(9.116) by a scaled multiple of the un-weighted norm, say,
∥w −wo∥2
Rℓ≈bℓk∥w −wo∥2,
(9.117)
where bℓk is some nonnegative coefﬁcient; we are even allowing its value to change with the node index
k. The above substitution amounts to having each node k approximate the {Rℓ} from its neighbors by
multiples of the identity matrix
Rℓ≈bℓk IM.
(9.118)
Approximation (9.117) is reasonable in view of the fact that all vector norms are equivalent [19–21];
this norm property ensures that we can bound the weighted norm ∥w −wo∥2
Rℓby some constants
multiplying the un-weighted norm ∥w −wo∥2, say, as:
r1∥w −wo∥2 ≤∥w −wo∥2
Rℓ≤r2∥w −wo∥2
(9.119)
for some positive constants (r1,r2). Using the fact that the {Rℓ} are Hermitian positive-deﬁnite matrices,
and calling upon the Rayleigh-Ritz characterization of eigenvalues [19,20], we can be more speciﬁc
and replace the above inequalities by
λmin(Rℓ) · ∥w −wo∥2 ≤∥w −wo∥2
Rℓ≤λmax(Rℓ) · ∥w −wo∥2.
(9.120)
We note that approximations similar to (9.118) are common in stochastic approximation theory and
they mark the difference between using a Newton’s iterative method or a stochastic gradient method
[5,22]; the former uses Hessian matrices as approximations for Rℓand the latter uses multiples of the
identity matrix. Furthermore, as the derivation will reveal, we do not need to worry at this stage about
how to select the scalars {bℓk}; they will end up being embedded into another set of coefﬁcients {aℓk}
that will be set by the designer or adjusted by the algorithm—see (9.132) further ahead.

3.09.3 Distributed Optimization Via Diffusion Strategies
351
Thus, we replace (9.116) by
J glob′′
k
(w) = J loc
k (w) +

ℓ∈Nk\{k}
bℓk∥w −wo∥2.
(9.121)
The argument so far has suggested how to modify J loc
k (w) from (9.108) and replace it by the cost (9.121)
that is closer in form to the global cost function (9.115). If we replace J loc
k (w) by its deﬁnition (9.108),
we can rewrite (9.121) as
J glob′′
k
(w) =

ℓ∈Nk
cℓk Jℓ(w) +

ℓ∈Nk\{k}
bℓk∥w −wo∥2 .
(9.122)
With the exception of the variable wo, this approximate cost at node k relies solely on information that
is available to node k from its neighborhood. We will soon explain how to handle the fact that wo is not
known beforehand to node k.
3.09.3.2 Steepest-descent iterations
Node k can apply a steepest-descent iteration to minimize J glob′′
k
(w). Let wk,i denote the estimate for
the minimizer wo that is evaluated by node k at time i. Starting from an initial condition wk,−1, node k
can compute successive estimates iteratively as follows:
wk,i = wk,i−1 −μk

∇w J glob′′
k
(wk,i−1)
∗
,
i ≥0,
(9.123)
where μk is a small positive step-size parameter, and the notation ∇w J(a) denotes the gradient vector
of the function J(w) relative to w and evaluated at w = a. The step-size parameter μk can be selected to
vary with time as well. One choice that is common in the optimization literature [5,22,23] is to replace
μk in (9.123) by step-size sequences {μ(i) ≥0} that satisfy the two conditions (9.25). However, such
step-size sequences are not suitable for applications that require continuous learning because they turn
off adaptation as i →∞; the steepest-descent iteration (9.123) would stop updating since μk(i) would
be tending towards zero. For this reason, we shall focus mainly on the constant step-size case described
by (9.123) since we are interested in developing distributed algorithms that will endow networks with
continuous adaptation abilities.
Returning to (9.123) and computing the gradient vector of (9.122) we get:
wk,i = wk,i−1 −μk

ℓ∈Nk
cℓk[∇w Jℓ(wk,i−1)]∗−μk

ℓ∈Nk\{k}
bℓk(wk,i−1 −wo).
(9.124)
Using the expression for Jℓ(w) from (9.97) we arrive at
wk,i = wk,i−1 + μk

ℓ∈Nk
cℓk(rdu,ℓ−Ru,ℓwk,i−1) + μk

ℓ∈Nk\{k}
bℓk(wo −wk,i−1).
(9.125)

352
CHAPTER 9 Diffusion Adaptation Over Networks
This iteration indicates that the update from wk,i−1 to wk,i involves adding two correction terms to
wk,i−1. Among many other forms, we can implement the update in two successive steps by adding one
correction term at a time, say, as follows:
ψk,i = wk,i−1 + μk

ℓ∈Nk
cℓk(rdu,ℓ−Ru,ℓwk,i−1),
(9.126)
wk,i = ψk,i + μk

ℓ∈Nk\{k}
bℓk(wo −wk,i−1).
(9.127)
Step (9.126) updates wk,i−1 to an intermediate value ψk,i by using local gradient vectors from the
neighborhood of node k. Step (9.127) further updates ψk,i to wk,i. Two issues stand out from examining
(9.127):
a. First, iteration (9.127) requires knowledge of the minimizer wo. Neither node k nor its neighbors
know the value of the minimizer; each of these nodes is actually performing steps similar to (9.126)
and (9.127) to estimate the minimizer. However, each node ℓhas a readily available approximation
for wo, which is its local intermediate estimate ψℓ,i. Therefore, we replace wo in (9.127) by ψℓ,i.
This step helps diffuse information throughout the network. This is because each neighbor of node
k determines its estimate ψℓ,i by processing information from its own neighbors, which process
information from their neighbors, and so forth.
b. Second, the intermediate value ψk,i at node k is generally a better estimate for wo than wk,i−1
since it is obtained by incorporating information from the neighbors through the ﬁrst step (9.126).
Therefore, we further replace wk,i−1 in (9.127) by ψk,i. This step is reminiscent of incremental-type
approaches to optimization, which have been widely studied in the literature [24–27].
With the substitutions described in items (a) and (b) above, we replace the second step (9.127) by
wk,i = ψk,i + μk

ℓ∈Nk\{k}
bℓk(ψℓ,i −ψk,i)
=
⎛
⎝1 −μk

ℓ∈Nk\{k}
bℓk
⎞
⎠ψk,i + μk

ℓ∈Nk\{k}
bℓkψℓ,i.
(9.128)
Introduce the weighting coefﬁcients:
akk ≜1 −μk

ℓ∈Nk\{k}
bℓk,
(9.129)
aℓk ≜μkbℓk,
ℓ∈Nk\{k},
(9.130)
aℓk ≜0,
ℓ/∈Nk,
(9.131)

3.09.3 Distributed Optimization Via Diffusion Strategies
353
and observe that, for sufﬁciently small step-sizes μk, these coefﬁcients are nonnegative and, moreover,
they satisfy the conditions:
for k = 1, 2, . . . , N :
aℓk ≥0,
N

ℓ=1
aℓk = 1,
and aℓk = 0 if ℓ/∈Nk.
(9.132)
Condition (9.132) means that for every node k, the sum of the coefﬁcients {aℓk} that relate it to its
neighbors is one. Just like the {cℓk}, from now on, we will treat the coefﬁcients {aℓk} as free weighting
parameters that are chosen by the designer according to (9.132); their selection will also have a bearing
on the performance of the resulting algorithms—see Theorem 9.6.8. If we collect the entries {aℓk} into
an N × N matrix A, such that the kth column of A consists of {aℓk, ℓ= 1, 2, . . . , N}, then condition
(9.132) translates into saying that each column of A adds up to one:
AT 1 = 1 .
(9.133)
We say that A is a left stochastic matrix.
3.09.3.3 Adapt-then-Combine (ATC) diffusion strategy
Using the coefﬁcients {aℓk} so deﬁned, we replace (9.126) and (9.128) by the following recursions
for i ≥0:
(ATC strategy)
ψk,i = wk,i−1 + μk

ℓ∈Nk
cℓk(rdu,ℓ−Ru,ℓwk,i−1)
wk,i =

ℓ∈Nk
aℓkψℓ,i
(9.134)
for some nonnegative coefﬁcients {cℓk, aℓk} that satisfy conditions (9.106) and (9.133), namely,
C1 = 1,
AT 1 = 1
(9.135)
or, equivalently,
for k = 1, 2, . . . , N:
cℓk ≥0,
N

k=1
cℓk = 1,
cℓk = 0 if ℓ/∈Nk,
aℓk ≥0,
N

ℓ=1
aℓk = 1,
aℓk = 0 if ℓ/∈Nk.
(9.136)
To run algorithm (9.134), we only need to select the coefﬁcients {aℓk, cℓk} that satisfy (9.135) or (9.136);
there is no need to worry about the intermediate coefﬁcients {bℓk} any longer since they have been
blended into the {aℓk}. The scalars {cℓk, aℓk} that appear in (9.134) correspond to weighting coefﬁcients

354
CHAPTER 9 Diffusion Adaptation Over Networks
FIGURE 9.10
Interpretation of the columns and rows of combination matrices. The pair of entries {ckℓ,cℓk} correspond to
weighting coefﬁcients used over the edge connecting nodes k and ℓ. When nodes (k,ℓ) are not neighbors,
then these weights are zero.
over the edge linking node k to its neighbors ℓ∈Nk. Note that two sets of coefﬁcients are used to
scale the data that are being received by node k: one set of coefﬁcients, {cℓk}, is used in the ﬁrst step
of (9.134) to scale the moment data {rdu,ℓ, Ru,ℓ}, and a second set of coefﬁcients, {aℓk}, is used in the
second step of (9.134) to scale the estimates {ψℓ,i}. Figure 9.10 explains what the entries on the columns
and rows of the combination matrices {A, C} stand for using an example with N = 6 and the matrix
C for illustration. When the combination matrix is right-stochastic (as is the case with C), each of its
rows would add up to one. On the other hand, when the matrix is left-stochastic (as is the case with A),
each of its columns would add up to one.
At every time instant i, the ATC strategy (9.134) performs two steps. The ﬁrst step is an information
exchange step where node k receives from its neighbors their moments {Ru,ℓ,rdu,ℓ}. Node k combines
this information and uses it to update its existing estimate wk,i−1 to an intermediate value ψk,i. All other
nodes in the network are performing a similar step and updating their existing estimates {wℓ,i−1} into
intermediate estimates {ψℓ,i} by using information from their neighbors. The second step in (9.134) is an
aggregation or consultation step where node k combines the intermediate estimates of its neighbors to
obtain its updated estimate wk,i. Again, all other nodes in the network are simultaneously performing a
similar step. The reason for the name Adapt-then-Combine (ATC) strategy is that the ﬁrst step in (9.134)
will be shown to lead to an adaptive step, while the second step in (9.134) corresponds to a combination
step. Hence, strategy (9.134) involves adaptation followed by combination or ATC for short. The reason
for the qualiﬁcation “diffusion” is that the combination step in (9.134) allows information to diffuse
through the network in real time. This is because each of the estimates ψℓ,i is inﬂuenced by data beyond
the immediate neighborhood of node k.

3.09.3 Distributed Optimization Via Diffusion Strategies
355
InthespecialcasewhenC = I,sothatnoinformationexchangeisperformedbutonlytheaggregation
step, the ATC strategy (9.134) reduces to:
(ATC strategy without
information exchange)
ψk,i = wk,i−1 + μk(rdu,k −Ru,kwk,i−1)
wk,i =

ℓ∈Nk
aℓkψℓ,i
,
(9.137)
where the ﬁrst step relies solely on the information {Ru,k,rdu,k} that is available locally at node k.
Observe in passing that the term that appears in the information exchange step of (9.134) is related
to the gradient vectors of the local costs {Jℓ(w)} evaluated at wk,i−1, i.e., it holds that
rdu,ℓ−Ru,ℓwk,i−1 = −[∇w Jℓ(wk,i−1)]∗,
(9.138)
so that the ATC strategy (9.134) can also be written in the following equivalent form:
(ATC strategy)
ψk,i = wk,i−1 −μk

ℓ∈Nk
cℓk[∇w Jℓ(wk,i−1)]∗
wk,i =

ℓ∈Nk
aℓkψℓ,i
.
(9.139)
The signiﬁcance of this general form is that it is applicable to optimization problems involving more
general local costs Jℓ(w) that are not necessarily quadratic in w, as detailed in [1–3]—see also
Section 3.09.10.4. The top part of Figure 9.11 illustrates the two steps involved in the ATC proce-
dure for a situation where node k has three other neighbors labeled {1, 2, ℓ}. In the ﬁrst step, node k
evaluates the gradient vectors of its neighbors at wk,i−1, and subsequently aggregates the estimates
{ψ1,i, ψ2,i, ψℓ,i} from its neighbors. The dotted arrows represent ﬂow of information towards node k
from its neighbors. The solid arrows represent ﬂow of information from node k to its neighbors. The
CTA diffusion strategy is discussed next.
3.09.3.4 Combine-then-Adapt (CTA) diffusion strategy
Similarly, if we return to (9.125) and add the second correction term ﬁrst, then (9.126) and (9.127) are
replaced by:
ψk,i−1 = wk,i−1 + μk

ℓ∈Nk\{k}
bℓk(wo −wk,i−1),
(9.140)
wk,i = ψk,i−1 + μk

ℓ∈Nk
cℓk(rdu,ℓ−Ru,ℓwk,i−1).
(9.141)
Following similar reasoning to what we did before in the ATC case, we replace wo in step (9.140) by
wℓ,i−1 and replace wk,i−1 in (9.141) by ψk,i−1. We then introduce the same coefﬁcients {aℓk} and arrive

356
CHAPTER 9 Diffusion Adaptation Over Networks
FIGURE 9.11
Illustration of the ATC and CTA strategies for a node k with three other neighbors {1,2,ℓ}. The updates involve
two steps: information exchange followed by aggregation in ATC and aggregation followed by information
exchange in CTA. The dotted arrows represent the data received from the neighbors of node k, and the solid
arrows represent the data sent from node k to its neighbors.
at the following Combine-then-Adapt (CTA) strategy:
(CTA strategy)
ψk,i−1 =

ℓ∈Nk
aℓkwℓ,i−1
wk,i = ψk,i−1 + μk

ℓ∈Nk
cℓk(rdu,ℓ−Ru,ℓψk,i−1) ,
(9.142)
where the nonnegative coefﬁcients {cℓk, aℓk} satisfy the same conditions (9.106) and (9.133), namely,
C1 = 1,
AT 1 = 1
(9.143)

3.09.3 Distributed Optimization Via Diffusion Strategies
357
or, equivalently,
for k = 1, 2, . . . , N:
cℓk ≥0,
N

k=1
cℓk = 1,
cℓk = 0 if ℓ/∈Nk,
aℓk ≥0,
N

ℓ=1
aℓk = 1,
aℓk = 0 if ℓ/∈Nk.
(9.144)
At every time instant i, the CTA strategy (9.142) also consists of two steps. The ﬁrst step is an aggregation
step where node k combines the existing estimates of its neighbors to obtain the intermediate estimate
ψk,i−1. All other nodes in the network are simultaneously performing a similar step and aggregating
the estimates of their neighbors. The second step in (9.142) is an information exchange step where
node k receives from its neighbors their moments {Rdu,ℓ,rdu,ℓ} and uses this information to update its
intermediate estimate to wk,i. Again, all other nodes in the network are simultaneously performing a
similar information exchange step. The reason for the name Combine-then-Adapt (CTA) strategy is that
the ﬁrst step in (9.142) involves a combination step, while the second step will be shown to lead to an
adaptive step. Hence, strategy (9.142) involves combination followed by adaptation or CTA for short.
The reason for the qualiﬁcation “diffusion” is that the combination step of (9.142) allows information
to diffuse through the network in real time.
InthespecialcasewhenC = I,sothatnoinformationexchangeisperformedbutonlytheaggregation
step, the CTA strategy (9.142) reduces to:
(CTA strategy without
information exchange)
ψk,i−1 =

ℓ∈Nk
aℓkwℓ,i−1
wk,i = ψk,i−1 + μk(rdu,k −Ru,kψk,i−1)
,
(9.145)
where the second step relies solely on the information {Ru,k,rdu,k} that is available locally at node k.
Again, the CTA strategy (9.142) can be rewritten in terms of the gradient vectors of the local costs
{Jℓ(w)} as follows:
(CTA strategy)
ψk,i−1 =

ℓ∈Nk
aℓkwℓ,i−1
wk,i = ψk,i−1 −μk

ℓ∈Nk
cℓk[∇w Jℓ(ψk,i−1)]∗
.
(9.146)
The bottom part of Figure 9.11 illustrates the two steps involved in the CTA procedure for a situation
where node k has three other neighbors labeled {1, 2, ℓ}. In the ﬁrst step, node k aggregates the esti-
mates {w1,i−1, w2,i−1, wℓ,i−1} from its neighbors, and subsequently performs information exchange
by evaluating the gradient vectors of its neighbors at ψk,i−1.
3.09.3.5 Useful properties of diffusion strategies
Note that the structure of the ATC and CTA diffusion strategies (9.134) and (9.142) are fundamentally
the same: the difference between the implementations lies in which variable we choose to correspond

358
CHAPTER 9 Diffusion Adaptation Over Networks
Table 9.2 Summary of Steepest-Descent Diffusion Strategies for the Distributed Optimization
of Problems of the form (9.92), and their Specialization to the Case of
Mean-Square-Error (MSE) Individual Cost Functions Given by (9.93)
Algorithm
Recursions
Equation
ATC strategy
(general case)
ψk,i = wk,i−1 −μk

ℓ∈N k
cℓk [∇w Jℓ(wk,i−1)]∗
wk,i =

ℓ∈Nk
aℓk ψℓ,i
(9.139)
ATC strategy
(MSE costs)
ψk,i = wk,i−1 + μk

ℓ∈Nk
cℓk (rdu,ℓ−Ru,ℓwk,i−1)
wk,i =

ℓ∈Nk
aℓk ψℓ,i
(9.134)
CTA strategy
(general case)
ψk,i−1 =

ℓ∈Nk
aℓk wℓ,i−1
wk,i = ψk,i−1 −μk

ℓ∈Nk
cℓk [∇w Jℓ(ψk,i−1)]∗
(9.146)
CTA strategy
(MSE costs)
ψk,i−1 =

ℓ∈Nk
aℓk wℓ,i−1
wk,i = ψk,i−1 + μk

ℓ∈Nk
cℓk (rdu,ℓ−Ru,ℓψk,i−1)
(9.142)
to the updated weight estimate wk,i. In the ATC case, we choose the result of the combination step to
be wk,i, whereas in the CTA case we choose the result of the adaptation step to be wk,i.
For ease of reference, Table 9.2 lists the steepest-descent diffusion algorithms derived in the previous
sections. The derivation of the ATC and CTA strategies (9.134) and (9.142) followed the approach
proposed in [18,28]. CTA estimation schemes were ﬁrst proposed in the works [29–33], and later
extended in [18,28,34,35]. The earlier versions of CTA in [29–31] used the choice C = I. This form
of the algorithm with C = I, and with the additional constraint that the step-sizes μk should be time-
dependent and decay towards zero as time progresses, was later applied by [36,37] to solve distributed
optimization problems that require all nodes to reach consensus or agreement. Likewise, special cases of
the ATC estimation scheme (9.134), involving an information exchange step followed by an aggregation
step, ﬁrst appeared in the work [38] on diffusion least-squares schemes and subsequently in the works
[18,34,35,39–41] on distributed mean-square-error and state-space estimation methods. A special case
of the ATC strategy (9.134) corresponding to the choice C = I with decaying step-sizes was adopted
in [42] to ensure convergence towards a consensus state. Diffusion strategies of the form (9.134) and
(9.142) (or, equivalently, (9.139) and (9.146)) are general in several respects:

3.09.4 Adaptive Diffusion Strategies
359
1. These strategies do not only diffuse the local weight estimates, but they can also diffuse the local
gradient vectors. In other words, two sets of combination coefﬁcients {aℓk, cℓk} can be used.
2. In the derivation that led to the diffusion strategies, the combination matrices C and A are only
required to be right-stochastic (for C) and left-stochastic (for A). In comparison, it is common in
consensus-type strategies to require the corresponding combination matrix A to be doubly stochastic
(i.e., its rows and columns should add up to one)—see, e.g., Appendix E and [36,43–45].
3. As the analysis in Section 3.09.6 will reveal, ATC and CTA strategies do not force nodes to converge
to an agreement about the desired parameter vector wo, as is common in consensus-type strategies
(see Appendix E and [36,46–52]). Forcing nodes to reach agreement on wo ends up limiting the
adaptation and learning abilities of these nodes, as well as their ability to react to information in real-
time. Nodes in diffusion networks enjoy more ﬂexibility in the learning process, which allows their
individual estimates, {wk,i}, to tend to values that lie within a reasonable mean-square-deviation
(MSD) level from the optimal solution, wo. Multi-agent systems in nature behave in this manner;
they do not require exact agreement among their agents (see, e.g., [8–10]).
4. The step-size parameters {μk} are not required to depend on the time index i and are not required to
vanish as i →∞(as is common in many works on distributed optimization, e.g., [22,23,36,53]).
Instead, the step-sizes can assume constant values, which is a critical property to endow networks
with continuous adaptation and learning abilities. An important contribution in the study of diffusion
strategies is to show that distributed optimization is still possible even for constant step-sizes, in
addition to the ability to perform adaptation, learning, and tracking. Sections 3.09.5 and 3.09.6
highlight the convergence properties of the diffusion strategies—see also [1–3] for results pertaining
to more general cost functions.
5. Even the combination weights {aℓk, cℓk} can be adapted, as we shall discuss later in Section 3.09.8.3.
In this way, diffusion strategies allow multiple layers of adaptation: the nodes perform adaptive
processing, the combination weights can be adapted, and even the topology can be adapted especially
for mobile networks [8].
3.09.4 Adaptive diffusion strategies
The distributed ATC and CTA steepest-descent strategies (9.134) and (9.142) for determining the wo that
solves (9.92) and (9.93) require knowledge of the statistical information {Ru,k,rdu,k}. These moments
are needed in order to be able to evaluate the gradient vectors that appear in (9.134) and (9.142), namely,
the terms:
−[∇w Jℓ(wk,i−1)]∗= (rdu,ℓ−Ru,ℓwk,i−1),
(9.147)
−[∇w Jℓ(ψk,i−1)]∗= (rdu,ℓ−Ru,ℓψk,i−1),
(9.148)
for all ℓ∈Nk. However, the moments {Ru,ℓ,rdu,ℓ} are often not available beforehand, which means
that the true gradient vectors are generally not available. Instead, the agents have access to observations
{dk(i), uk,i} of the random processes {dk(i), uk,i}. There are many ways by which the true gradient
vectors can be approximated by using these observations. Recall that, by deﬁnition,
Ru,ℓ≜Eu∗
ℓ,iuℓ,i,
rdu,ℓ≜Edℓ(i)u∗
ℓ,i.
(9.149)

360
CHAPTER 9 Diffusion Adaptation Over Networks
One common stochastic approximation method is to drop the expectation operator from the deﬁnitions
of {Ru,ℓ,rdu,ℓ} and to use the following instantaneous approximations instead [4–7]:
Ru,ℓ≈u∗
ℓ,iuℓ,i,
rdu,ℓ≈dℓ(i)u∗
ℓ,i.
(9.150)
In this case, the approximate gradient vectors become:
(rdu,ℓ−Ru,ℓwk,i−1) ≈u∗
ℓ,i[dℓ(i) −uℓ,iwk,i−1],
(9.151)
(rdu,ℓ−Ru,ℓψk,i−1) ≈u∗
ℓ,i[dℓ(i) −uℓ,iψk,i−1].
(9.152)
Substituting into the ATC and CTA steepest-descent strategies (9.134) and (9.142), we arrive at the
following adaptive implementations of the diffusion strategies for i ≥0:
(adaptive ATC strategy)
ψk,i = wk,i−1 + μk

ℓ∈Nk
cℓku∗
ℓ,i[dℓ(i) −uℓ,iwk,i−1]
wk,i =

ℓ∈Nk
aℓkψℓ,i
(9.153)
and
(adaptive CTA strategy)
ψk,i−1 =

ℓ∈Nk
aℓkwℓ,i−1
wk,i = ψk,i−1 + μk

ℓ∈Nk
cℓku∗
ℓ,i[dℓ(i) −uℓ,iψk,i−1]
,
(9.154)
where the coefﬁcients {aℓk, cℓk} are chosen to satisfy:
for k = 1, 2, . . . , N :
cℓk ≥0,
N

k=1
cℓk = 1,
cℓk = 0 if ℓ/∈Nk,
aℓk ≥0,
N

ℓ=1
aℓk = 1, aℓk = 0 if ℓ/∈Nk.
(9.155)
The adaptive implementations usually start from the initial conditions wℓ,−1 = 0 for all ℓ, or from some
other convenient initial values. Clearly, in view of the approximations (9.151) and (9.152), the successive
iterates {wk,i, ψk,i, ψk,i−1} that are generated by the above adaptive implementations are different from
the iterates that result from the steepest-descent implementations (9.134) and (9.142). Nevertheless, we
shall continue to use the same notation for these variables for ease of reference. One key advantage of
the adaptive implementations (9.153) and (9.154) are that they enable the agents to react to changes in
the underlying statistical information {rdu,ℓ, Ru,ℓ} and to changes in wo. This is because these changes
end up being reﬂected in the data realizations {dk(i), uk,i}. Therefore, adaptive implementations have
an innate tracking and learning ability that is of paramount signiﬁcance in practice.

3.09.4 Adaptive Diffusion Strategies
361
We say that the stochastic gradient approximations (9.151) and (9.152) introduce gradient noise into
each step of the recursive updates (9.153) and (9.154). This is because the updates (9.153) and (9.154)
can be interpreted as corresponding to the following forms:
(adaptive ATC strategy)
ψk,i = wk,i−1 −μk

ℓ∈Nk
cℓk 
[∇w Jℓ(wk,i−1)]∗
wk,i =

ℓ∈Nk
aℓkψℓ,i
(9.156)
and
(adaptive CTA strategy)
ψk,i−1
=

ℓ∈Nk
aℓkwℓ,i−1
wk,i
= ψk,i−1 −μk

ℓ∈Nk
cℓk 
[∇w Jℓ(ψk,i−1)]∗
,
(9.157)
where the true gradient vectors, {∇w Jℓ(·)}, have been replaced by approximations, { 
∇w Jℓ(·)}—compare
with (9.139) and (9.146). The signiﬁcance of the alternative forms (9.156) and (9.157) is that they are
applicable to optimization problems involving more general local costs Jℓ(w) that are not necessarily
quadratic, as detailed in [1–3]; see also Section 3.09.10.4. In the next section, we examine how gradient
noise affects the performance of the diffusion strategies and how close the successive estimates {wk,i}
get to the desired optimal solution wo. Table 9.3 lists several of the adaptive diffusion algorithms derived
in this section.
The operation of the adaptive diffusion strategies is similar to the operation of the steepest-descent
diffusion strategies of the previous section. Thus, note that at every time instant i, the ATC strategy
(9.153) performs two steps; as illustrated in Figure 9.12. The ﬁrst step is an information exchange
step where node k receives from its neighbors their information {dℓ(i), uℓ,i}. Node k combines this
information and uses it to update its existing estimate wk,i−1 to an intermediate value ψk,i. All other
nodes in the network are performing a similar step and updating their existing estimates {wℓ,i−1} into
intermediate estimates {ψℓ,i} by using information from their neighbors. The second step in (9.153)
is an aggregation or consultation step where node k combines the intermediate estimates {ψℓ,i} of its
neighbors to obtain its updated estimate wk,i. Again, all other nodes in the network are simultaneously
performing a similar step. In the special case when C = I, so that no information exchange is performed
but only the aggregation step, the ATC strategy (9.153) reduces to:
(adaptive ATC strategy
without information exchange)
ψk,i = wk,i−1 + μku∗
k,i[dk(i) −uk,iwk,i−1]
wk,i =

ℓ∈Nk
aℓkψℓ,i
.
(9.158)
Likewise, at every time instant i, the CTA strategy (9.154) also consists of two steps—see Figure 9.13.
The ﬁrst step is an aggregation step where node k combines the existing estimates of its neighbors to
obtain the intermediate estimate ψk,i−1. All other nodes in the network are simultaneously performing a

362
CHAPTER 9 Diffusion Adaptation Over Networks
Table 9.3 Summary of Adaptive Diffusion Strategies for the Distributed Optimization of
Problems of the form (9.92), and their Specialization to the Case of Mean-
Square-Error (MSE) Individual Cost Functions Given by (9.93). These Adaptive
Solutions Rely on Stochastic Approximations
Algorithm
Recursions
Equation
Adaptive ATC strategy
(general case)
ψk,i = wk,i−1 −μk

ℓ∈Nk
cℓk 
[∇w Jℓ(wk,i−1)]∗
wk,i =

ℓ∈Nk
aℓk ψℓ,i
(9.156)
Adaptive ATC strategy
(MSE costs)
ψk,i = wk,i−1 + μk

ℓ∈Nk
cℓk u∗
ℓ,i [dℓ(i) −uℓ,i wk,i−1]
wk,i =

ℓ∈Nk
aℓk ψℓ,i
(9.153)
Adaptive ATC strategy
(MSE costs)
(no information exchange)
ψk,i = wk,i−1 + μk u∗
k,i [dk (i) −uk,i wk,i−1]
wk,i =

ℓ∈Nk
aℓk ψℓ,i
(9.158)
Adaptive CTA strategy
(general case)
ψk,i−1 =

ℓ∈Nk
aℓk wℓ,i−1
wk,i = ψk,i−1 −μk

ℓ∈Nk
cℓk 
[∇w Jℓ(ψk,i−1)]∗
(9.157)
Adaptive CTA strategy
(MSE costs)
ψk,i−1 =

ℓ∈Nk
aℓk wℓ,i−1
wk,i = ψk,i−1 + μk

ℓ∈Nk
cℓk u∗
ℓ,i [dℓ(i) −uℓ,i ψk,i−1]
(9.154)
Adaptive CTA strategy
(MSE costs)
(no information exchange)
ψk,i−1 =

ℓ∈Nk
aℓk wℓ,i−1
wk,i = ψk,i−1 + μk u∗
k,i [dk (i) −uk,i ψk,i−1]
(9.159)
similar step and aggregating the estimates of their neighbors. The second step in (9.154) is an information
exchange step where node k receives from its neighbors their information {dℓ(i), uℓ,i} and uses this
information to update its intermediate estimate to wk,i. Again, all other nodes in the network are

3.09.4 Adaptive Diffusion Strategies
363
FIGURE 9.12
Illustration of the adaptive ATC strategy, which involves two steps: information exchange followed by
aggregation.
FIGURE 9.13
Illustration of the adaptive CTA strategy, which involves two steps: aggregation followed by information
exchange.

364
CHAPTER 9 Diffusion Adaptation Over Networks
simultaneously performing a similar information exchange step. In the special case when C = I, so that
no information exchange is performed but only the aggregation step, the CTA strategy (9.154) reduces to:
(adaptive CTA strategy
without information exchange)
ψk,i−1 =

ℓ∈Nk
aℓkwℓ,i−1
wk,i = ψk,i−1 + μku∗
k,i[dk(i) −uk,iψk,i−1]
.
(9.159)
We further note that the adaptive ATC and CTA strategies (9.153) and (9.154) reduce to the non-
cooperative adaptive solution (9.22) and (9.23), where each node k runs its own individual LMS ﬁlter,
when the coefﬁcients {aℓk, cℓk} are selected as
aℓk = δℓk = cℓk
(non-cooperative case),
(9.160)
where δℓk denotes the Kronecker delta function:
δℓk ≜
 1, ℓ= k,
0, otherwise.
(9.161)
In terms of the combination matrices A and C, this situation corresponds to setting
A = IN = C
(non-cooperative case).
(9.162)
3.09.5 Performance of steepest-descent diffusion strategies
Before studying in some detail the mean-square performance of the adaptive diffusion implementations
(9.153) and (9.154), and the inﬂuence of gradient noise, we examine ﬁrst the convergence behavior of
the steepest-descent diffusion strategies (9.134) and (9.142), which employ the true gradient vectors.
Doing so will help introduce the necessary notation and highlight some features of the analysis in
preparation for the more challenging treatment of the adaptive strategies in Section 3.09.6.
3.09.5.1 General diffusion model
Rather than study the performance of the ATC and CTA steepest-descent strategies (9.134) and (9.142)
separately, it is useful to introduce a more general description that includes the ATC and CTA recursions
as special cases. Thus, consider a distributed steepest-descent diffusion implementation of the following
general form for i ≥0:
φk,i−1 =

ℓ∈Nk
a1,ℓkwℓ,i−1,
(9.163)
ψk,i = φk,i−1 + μk

ℓ∈Nk
cℓk[rdu,ℓ−Ru,ℓφk,i−1],
(9.164)
wk,i =

ℓ∈Nk
a2,ℓkψℓ,i,
(9.165)

3.09.5 Performance of Steepest-Descent Diffusion Strategies
365
where the scalars {a1,ℓk, cℓk, a2,ℓk} denote three sets of nonnegative real coefﬁcients corresponding to
the (ℓ, k) entries of N × N combination matrices {A1, C, A2}, respectively. These matrices are assumed
to satisfy the conditions:
AT
1 1 = 1,
C1 = 1,
AT
2 1 = 1 ,
(9.166)
so that {A1, A2} are left stochastic and C is right-stochastic, i.e.,
for k = 1, 2, . . . , N :
cℓk≥0,
N$
k=1
cℓk = 1,
cℓk = 0 if ℓ/∈Nk,
a1,ℓk≥0,
N$
ℓ=1
a1,ℓk = 1, a1,ℓk = 0 if ℓ/∈Nk,
a2,ℓk≥0,
N$
ℓ=1
a2,ℓk = 1, a2,ℓk = 0 if ℓ/∈Nk.
(9.167)
As indicated in Table 9.4, different choices for {A1, C, A2} correspond to different cooperation modes.
For example, the choice A1 = IN and A2 = A corresponds to the ATC implementation (9.134), while
the choice A1 = A and A2 = IN corresponds to the CTA implementation (9.142). Likewise, the choice
C = IN corresponds to the case in which the nodes only share weight estimates and the distributed
diffusion recursions (9.163) to (9.165) become:
φk,i−1 =

ℓ∈Nk
a1,ℓkwℓ,i−1,
(9.168)
ψk,i = φk,i−1 + μk(rdu,k −Ru,kφk,i−1),
(9.169)
wk,i =

ℓ∈Nk
a2,ℓkψℓ,i.
(9.170)
Furthermore, the choice A1 = A2 = C = IN corresponds to the non-cooperative mode of operation, in
which case the recursions reduce to the classical (stand-alone) steepest-descent recursion [4–7], where
each node minimizes individually its own quadratic cost Jk(w), deﬁned earlier in (9.97):
wk,i = wk,i−1 + μk[rdu,k −Ru,kwk,i−1],
i ≥0.
(9.171)
Table 9.4 Different Choices for the Combination Matrices {A1, A2, C} in (9.163)–(9.165)
Correspond to Different Cooperation Strategies
A1
A2
C
Cooperation Mode
IN
A
C
ATC strategy (9.134)
IN
A
IN
ATC strategy (9.137) without information exchange
A
IN
C
CTA strategy (9.142)
A
IN
IN
CTA strategy (9.145) without information exchange
IN
IN
IN
non-cooperative steepest-descent (9.171)

366
CHAPTER 9 Diffusion Adaptation Over Networks
3.09.5.2 Error recursions
Our objective is to examine whether, and how fast, the weight estimates {wk,i} from the distributed
implementation (9.163)–(9.165) converge towards the solution wo of (9.92) and (9.93). To do so, we
introduce the M × 1 error vectors:
˜φk,i ≜wo −φk,i,
(9.172)
˜ψk,i ≜wo −ψk,i,
(9.173)
˜wk,i ≜wo −wk,i.
(9.174)
Each of these error vectors measures the residual relative to the desired minimizer wo. Now recall from
(9.100) that
rdu,k = Ru,kwo.
(9.175)
Then, subtracting wo from both sides of relations in (9.163)–(9.165) we get
˜φk,i−1 =

ℓ∈Nk
a1,ℓk ˜wℓ,i−1,
(9.176)
˜ψk,i =
⎛
⎝IM −μk

ℓ∈Nk
cℓk Ru,ℓ
⎞
⎠˜φk,i−1,
(9.177)
˜wk,i =

ℓ∈Nk
a2,ℓk ˜ψℓ,i.
(9.178)
We can describe these relations more compactly by collecting the information from across the network
into block vectors and matrices. We collect the error vectors from across all nodes into the following
N × 1 block vectors, whose individual entries are of size M × 1 each:
˜ψi ≜
⎡
⎢⎢⎢⎣
˜ψ1,i
˜ψ2,i
...
˜ψN,i
⎤
⎥⎥⎥⎦,
˜φi ≜
⎡
⎢⎢⎢⎣
˜φ1,i
˜φ2,i
...
˜φN,i
⎤
⎥⎥⎥⎦,
˜wi ≜
⎡
⎢⎢⎢⎣
˜w1,i
˜w2,i
...
˜wN,i
⎤
⎥⎥⎥⎦.
(9.179)
The block quantities { ˜ψi, ˜φi, ˜wi} represent the state of the errors across the network at time i. Likewise,
we introduce the following N × N block diagonal matrices, whose individual entries are of size M ×
M each:
M ≜diag{μ1IM, μ2IM, . . . , μN IM},
(9.180)
R ≜diag
⎧
⎨
⎩

ℓ∈N1
cℓ1Ru,ℓ,

ℓ∈N2
cℓ2Ru,ℓ, . . . ,

ℓ∈NN
cℓN Ru,ℓ
⎫
⎬
⎭.
(9.181)

3.09.5 Performance of Steepest-Descent Diffusion Strategies
367
Each block diagonal entry of R, say, the kth entry, contains the combination of the covariance
matrices in the neighborhood of node k. We can simplify the notation by denoting these neighborhood
combinations as follows:
Rk ≜

ℓ∈Nk
cℓk Ru,ℓ,
(9.182)
so that R becomes
R ≜diag{R1, R2, . . . , RN}
(when C ̸= I).
(9.183)
In the special case when C = IN, the matrix R reduces to
Ru = diag{Ru,1, Ru,2, . . . , Ru,N}
(when C = I)
(9.184)
with the individual covariance matrices appearing on its diagonal; we denote R by Ru in this special
case. We further introduce the Kronecker products
A1 ≜A1 ⊗IM,
A2 ≜A2 ⊗IM.
(9.185)
The matrix A1 is an N × N block matrix whose (ℓ, k) block is equal to a1,ℓk IM. Likewise, for A2.
In other words, the Kronecker transformation deﬁned above simply replaces the matrices {A1, A2}
by block matrices {A1, A2} where each entry {a1,ℓk, a2,ℓk} in the original matrices is replaced by the
diagonal matrices {a1,ℓk IM, a2,ℓk IM}. For ease of reference, Table 9.5 lists the various symbols that
have been deﬁned so far, and others that will be deﬁned in the sequel.
Returning to (9.176)–(9.178), we conclude that the following relations hold for the block quantities:
˜φi−1 = AT
1 ˜wi−1,
(9.186)
˜ψi = (IN M −MR) ˜φi−1,
(9.187)
˜wi = AT
2 ˜ψi,
(9.188)
so that the network weight error vector, ˜wi, ends up evolving according to the following dynamics:
˜wi = AT
2 (IN M −MR)AT
1 ˜wi−1,
i ≥0
(diffusion strategy).
(9.189)
For comparison purposes, if each node in the network minimizes its own cost function, Jk(w), separately
from the other nodes and uses the non-cooperative steepest-descent strategy (9.171), then the weight
error vector across all N nodes would evolve according to the following alternative dynamics:
˜wi = (IN M −MRu) ˜wi−1,
i ≥0
(non-cooperative strategy),
(9.190)
where the matrices A1 and A2 do not appear, and R is replaced by Ru from (9.184). This recursion is
a special case of (9.189) when A1 = A2 = C = IN.

368
CHAPTER 9 Diffusion Adaptation Over Networks
3.09.5.3 Convergence behavior
Note from (9.189) that the evolution of the weight error vector involves block vectors and block matrices;
this will be characteristic of the distributed implementations that we consider in this chapter. To examine
the stability and convergence properties of recursions that involve such block quantities, it becomes
useful to rely on a certain block vector norm. In Appendix D, we describe a so-called block maximum
norm and establish some of its useful properties. The results of the appendix will be used extensively
in our exposition. It is therefore advisable for the reader to review the properties stated in the appendix
at this stage.
Using the result of Lemma D.6, we can establish the following useful statement about the convergence
of the steepest-descent diffusion strategy (9.163)–(9.165). The result establishes that all nodes end up
converging to the optimal solution wo if the nodes employ positive step-sizes μk that are small enough;
the lemma provides a sufﬁcient bound on the {μk}.
Theorem 9.5.1 (Convergence to Optimal Solution).
Consider the problem of optimizing the global
cost (9.92) with the individual cost functions given by (9.93). Pick a right stochastic matrix C and
left stochastic matrices A1 and A2 satisfying (9.166) or (9.167); these matrices deﬁne the network
topology and how information is shared over neighborhoods. Assume each node in the network runs
the (distributed) steepest-descent diffusion algorithm (9.163)–(9.165). Then, all estimates {wk,i} across
Table 9.5 Deﬁnitions of Network Variables Used Throughout the Analysis
Variable
Equation
A1 = A1 ⊗IM
(9.185)
A2 = A2 ⊗IM
(9.185)
C = C ⊗IM
(9.245)
Rk = $
ℓ∈Nk cℓk Ru,ℓ
(9.182)
R = diag{R1, R2, . . . , RN}
(9.183)
Ru = diag{Ru,1, Ru,2, . . . , Ru,N}
(9.241)
Rv = diag{σ 2
v,1, σ 2
v,2, . . . , σ 2
v,N}
(9.319)
M = diag{μ1IM, μ2IM, . . . , μNIM}
(9.180)
S = diag{σ 2
v,1Ru,1, σ 2
v,2Ru,2, . . . , σ 2
v,NRu,N}
(9.241)
G = AT
2 MCT
(9.263)
B = AT
2 (INM −MR)AT
1
(9.264)
Y = GSGT
(9.280)
F ≈BT ⊗B∗
(9.277)
Jk = diag{0M, . . . , 0M, IM, 0M, . . . , 0M}
(9.294)
Tk = diag{0M, . . . , 0M, Ru,k , 0M, . . . , 0M}
(9.298)

3.09.5 Performance of Steepest-Descent Diffusion Strategies
369
the network converge to the optimal solution wo if the positive step-size parameters {μk} satisfy
μk <
2
λmax(Rk) ,
(9.191)
where the neighborhood covariance matrix Rk is deﬁned by (9.182).
Proof.
The weight error vector ˜wi converges to zero if, and only if, the coefﬁcient matrix AT
2 (IN M −
MR)AT
1 in (9.189) is a stable matrix (meaning that all its eigenvalues lie strictly inside the unit disc).
From property (9.605) established in Appendix D, we know that AT
2 (IN M −MR)AT
1 is stable if the
block diagonal matrix (IN M −MR) is stable. It is now straightforward to verify that condition (9.191)
ensures the stability of (IN M −MR). It follows that
˜wi −→0
as i −→∞.
(9.192)
□
Observe that the stability condition (9.191) does not depend on the speciﬁc combination matrices A1
and A2. Thus, as long as these matrices are chosen to be left-stochastic, the weight-error vectors will
converge to zero under condition (9.191) no matter what {A1, A2} are. Only the combination matrix C
inﬂuences the condition on the step-size through the neighborhood covariance matrices {Rk}. Observe
further that the statement of the lemma does not require the network to be connected. Moreover, when
C = I, in which case the nodes only share weight estimates and do not share the neighborhood moments
{rdu,ℓ, Ru,ℓ}, as in (9.168)–(9.170), condition (9.191) becomes
μk <
2
λmax(Ru,k)
(cooperation with C = I),
(9.193)
in terms of the actual covariance matrices {Ru,k}. Conditions (9.191) and (9.193) are reminiscent of
a classical result for stand-alone steepest-descent algorithms, as in the non-cooperative case (9.171),
where it is known that the estimate by each individual node in this case will converge to wo if, and only
if, its positive step-size satisﬁes
μk <
2
λmax(Ru,k)
(non-cooperative case (9.171) with A1 = A2 = C = IN).
(9.194)
This is the same condition as (9.193) for the case C = I.
The following statement provides a bi-directional statement that ensures convergence of the (dis-
tributed) steepest-descent diffusion strategy (9.163)–(9.165) for any choice of left-stochastic combina-
tion matrices A1 and A2.
Theorem 9.5.2 (Convergence for Arbitrary Combination Matrices).
Consider the problem of
optimizing the global cost (9.92) with the individual cost functions given by (9.93). Pick a right stochastic
matrix C satisfying (9.166). Then, the estimates {wk,i} generated by (9.163)–(9.165) converge to wo,
for all choices of left-stochastic matrices A1 and A2 satisfying (9.166) if, and only if,
μk <
2
λmax(Rk) .
(9.195)

370
CHAPTER 9 Diffusion Adaptation Over Networks
Proof.
The result follows from property (b) of Corollary D.1, which is established in
Appendix D.
□
More importantly, we can verify that under fairly general conditions, employing the steepest-descent
diffusion strategy (9.163)–(9.165) enhances the convergence rate of the error vector towards zero relative
to the non-cooperative strategy (9.171). The next three results establish this fact when C is a doubly
stochastic matrix, i.e., it has nonnegative entries and satisﬁes
C1 = 1,
CT 1 = 1
(9.196)
with both its rows and columns adding up to one. Compared to the earlier right-stochastic condition on
C in (9.105), we are now requiring

ℓ∈Nk
ckℓ= 1,

ℓ∈Nk
cℓk = 1.
(9.197)
For example, these conditions are satisﬁed when C is right stochastic and symmetric. They are also
automatically satisﬁed for C = I, when only weight estimates are shared as in (9.168)–(9.170); this
latter case covers the ATC and CTA diffusion strategies (9.137) and (9.145), which do not involve
information exchange.
Theorem 9.5.3 (Convergence Rate is Enhanced: Uniform Step-Sizes).
Consider the problem
of optimizing the global cost (9.92) with the individual cost functions given by (9.93). Pick a doubly
stochasticmatrixC satisfying(9.196)andleftstochasticmatrices A1 and A2 satisfying(9.166).Consider
two modes of operation. In one mode, each node in the network runs the (distributed) steepest-descent
diffusion algorithm (9.163)–(9.165). In the second mode, each node operates individually and runs the
non-cooperative steepest-descent algorithm (9.171). In both cases, the positive step-sizes used by all
nodes are assumed to be the same, say, μk = μ for all k, and the value of μ is chosen to satisfy the
required stability conditions (9.191) and (9.194), which are met by selecting
μ < min
1≤k≤N

2
λmax(Ru,k)
+
.
(9.198)
Itthenholdsthatthemagnitudeoftheerrorvector, ∥˜wi∥, inthediffusioncasedecaystozeromorerapidly
than in the non-cooperative case. In other words, diffusion cooperation enhances convergence rate.
Proof.
Let us ﬁrst establish that any positive step-size μ satisfying (9.198) will satisfy both stability
conditions (9.191) and (9.194). It is obvious that (9.194) is satisﬁed. We verify that (9.191) is also
satisﬁed when C is doubly stochastic. In this case, each neighborhood covariance matrix, Rk, becomes
a convex combination of individual covariance matrices {Ru,ℓ}, i.e.,
Rk =

ℓ∈Nk
cℓk Ru,ℓ,
where now

ℓ∈Nk
cℓk = 1 (when C is doubly stochastic).

3.09.5 Performance of Steepest-Descent Diffusion Strategies
371
To proceed, we recall that the spectral norm (maximum singular value) of any matrix X is a convex
function of X [54]. Moreover, for Hermitian matrices X, their spectral norms coincide with their spectral
radii (largest eigenvalue magnitude). Then, Jensen’s inequality [54] states that for any convex function
f (·) it holds that
f

m
θm Xm

≤

m
θm f (Xm)
for Hermitian matrices Xm and nonnegative scalars θm that satisfy

m
θm = 1.
Choosing f (·) as the spectral radius function, and applying it to the deﬁnition of Rk above, we get
ρ(Rk) = ρ
⎛
⎝
ℓ∈Nk
cℓk Ru,ℓ
⎞
⎠
≤

ℓ∈Nk
cℓk · ρ(Ru,ℓ)
≤

ℓ∈Nk
cℓk ·

max
1≤ℓ≤N ρ(Ru,ℓ)

= max
1≤ℓ≤N ρ(Ru,ℓ).
In other words,
λmax(Rk) ≤max
1≤k≤N

λmax(Ru,k)

.
It then follows from (9.198) that
μ <
2
λmax(Rk),
for all k = 1, 2, . . . , N,
so that (9.191) is satisﬁed as well.
Let us now examine the convergence rate. To begin with, we note that the matrix (IN M −MR) that
appears in the weight-error recursion (9.189) is block diagonal:
(IN M −MR) = diag{(IM −μR1), (IM −μR2), . . . , (IM −μRN)}
and each individual block entry, (IM −μRk), is a stable matrix since μ satisﬁes (9.191). Moreover,
each of these entries can be written as
IM −μRk =

ℓ∈Nk
cℓk(IM −μRu,ℓ),

372
CHAPTER 9 Diffusion Adaptation Over Networks
which expresses (IM −μRk) as a convex combination of stable terms (IM −μRu,ℓ). Applying Jensen’s
inequality again we get
ρ
⎛
⎝
ℓ∈Nk
cℓk(IM −μRu,ℓ)
⎞
⎠≤

ℓ∈Nk
cℓkρ(IM −μRu,ℓ).
Now, we know from (9.189) that the rate of decay of ˜wi to zero in the diffusion case is determined by
the spectral radius of the coefﬁcient matrix AT
2 (IN M −MR)AT
1 . Likewise, we know from (9.190) that
the rate of decay of ˜wi to zero in the non-cooperative case is determined by the spectral radius of the
coefﬁcient matrix (IN M −MRu). Then, note that
ρ

AT
2 (IN M −MR)AT
1
 (9.605)
≤
ρ(IN M −MR)
=
max
1≤k≤N ρ(IM −μRk)
=
max
1≤k≤N ρ
⎛
⎝
ℓ∈Nk
cℓk(IM −μRu,ℓ)
⎞
⎠
≤
max
1≤k≤N

ℓ∈Nk
cℓkρ(IM −μRu,ℓ)
≤
max
1≤k≤N

ℓ∈Nk
cℓk

max
1≤ℓ≤N ρ(IM −μRu,ℓ)

=
max
1≤k≤N
⎧
⎨
⎩

max
1≤ℓ≤N ρ(IM −μRu,ℓ)

·

ℓ∈Nk
cℓk
⎫
⎬
⎭
=
max
1≤k≤N

max
1≤ℓ≤N ρ(IM −μRu,ℓ)

=
max
1≤ℓ≤N ρ(IM −μRu,ℓ)
=
ρ(IN M −MRu).
Therefore, the spectral radius of AT
2 (IN M −MR)AT
1 is at most as large as the largest individual spectral
radius in the non-cooperative case.
□
The argument can be modiﬁed to handle different step-sizes across the nodes if we assume uniform
covariance data across the network, as stated below.
Theorem 9.5.4 (Convergence Rate is Enhanced: Uniform Covariance Data).
Consider the same
setting of Theorem 9.5.3. Assume the covariance data are uniform across all nodes, say, Ru,k = Ru is
independent of k. Assume further that the nodes in both modes of operation employ steps-sizes μk that
are chosen to satisfy the required stability conditions (9.191) and (9.194), which in this case are met by:
μk <
2
λmax(Ru),
k = 1, 2, . . . , N.
(9.199)

3.09.5 Performance of Steepest-Descent Diffusion Strategies
373
It then holds that the magnitude of the error vector, ∥˜wi∥, in the diffusion case decays to zero more
rapidly than in the non-cooperative case. In other words, diffusion enhances convergence rate.
Proof.
Since Ru,ℓ= Ru for all ℓand C is doubly stochastic, we get Rk = Ru and IN M −MR =
IN M −MRu. Then,
ρ

AT
2 (IN M −MR)AT
1
 (9.605)
≤
ρ(IN M −MR)
=
ρ(IN M −MRu).
□
The next statement considers the case of ATC and CTA strategies (9.137) and (9.145) without infor-
mation exchange, which corresponds to the case C = IN. The result establishes that these strategies
always enhance the convergence rate over the non-cooperative case, without the need to assume uniform
step-sizes or uniform covariance data.
Theorem 9.5.5 (Convergence Rate is Enhanced when C = I).
Consider the problem of optimizing
the global cost (9.92) with the individual cost functions given by (9.93). Pick left stochastic matrices A1
and A2 satisfying (9.166) and set C = IN. This situation covers the ATC and CTA strategies (9.137) and
(9.145), which do not involve information exchange. Consider two modes of operation. In one mode,
each node in the network runs the (distributed) steepest-descent diffusion algorithm (9.168)–(9.170).
In the second mode, each node operates individually and runs the non-cooperative steepest-descent
algorithm (9.171). In both cases, the positive step-sizes are chosen to satisfy the required stability
conditions (9.193) and (9.194), which in this case are met by
μk <
2
λmax(Ru,k),
k = 1, 2, . . . , N.
(9.200)
Itthenholdsthatthemagnitudeoftheerrorvector, ∥˜wi∥, inthediffusioncasedecaystozeromorerapidly
than in the non-cooperative case. In other words, diffusion cooperation enhances convergence rate.
Proof.
When C = IN, we get Rk = Ru,k and, therefore, R = Ru and IN M −MR = IN M −MRu.
Then,
ρ

AT
2 (IN M −MR)AT
1
 (9.605)
≤
ρ(IN M −MR)
=
ρ(IN M −MRu).
□
The results of the previous theorems highlight the following important facts about the role of the
combination matrices {A1, A2, C} in the convergence behavior of the diffusion strategy (9.163)–(9.165):
a. The matrix C inﬂuences the stability of the network through its inﬂuence on the bound in (9.191).
This is because the matrices {Rk} depend on the entries of C. The matrices {A1, A2} do not inﬂuence
network stability in that they can be chosen arbitrarily and the network will remain stable under
(9.191).
b. The matrices {A1, A2, C} inﬂuence the rate of convergence of the network since they inﬂuence the
spectral radius of the matrix AT
2 (IN M −MR)AT
1 , which controls the dynamics of the weight error
vector in (9.189).

374
CHAPTER 9 Diffusion Adaptation Over Networks
3.09.6 Performance of adaptive diffusion strategies
We now move on to examine the behavior of the adaptive diffusion implementations (9.153) and
(9.154), and the inﬂuence of both gradient noise and measurement noise on convergence and steady-state
performance. Due to the random nature of the perturbations, it becomes necessary to evaluate the
behavior of the algorithms on average, using mean-square convergence analysis. For this reason, we
shall study the convergence of the weight estimates both in the mean and mean-square sense. To do so,
we will again consider a general diffusion structure that includes the ATC and CTA strategies (9.153)
and (9.154) as special cases. We shall further resort to the boldface notation to refer to the measurements
and weight estimates in order to highlight the fact that they are now being treated as random variables. In
this way, the update equations become stochastic updates. Thus, consider the following general adaptive
diffusion strategy for i ≥0:
φk,i−1 =

ℓ∈Nk
a1,ℓkwℓ,i−1,
(9.201)
ψk,i = φk,i−1 + μk

ℓ∈Nk
cℓk u∗
ℓ,i[dℓ(i) −uℓ,iφk,i−1],
(9.202)
wk,i =

ℓ∈Nk
a2,ℓkψℓ,i.
(9.203)
As before, the scalars {a1,ℓk, cℓk, a2,ℓk} are nonnegative real coefﬁcients corresponding to the (ℓ, k)
entries of N × N combination matrices {A1, C, A2}, respectively. These matrices are assumed to satisfy
the same conditions (9.166) or (9.167). Again, different choices for {A1, C, A2} correspond to different
cooperation modes. For example, the choice A1 = IN and A2 = A corresponds to the adaptive ATC
implementation (9.153), while the choice A1 = A and A2 = IN corresponds to the adaptive CTA
implementation (9.154). Likewise, the choice C = IN corresponds to the case in which the nodes only
share weight estimates and the distributed diffusion recursions (9.201)–(9.203) become
φk,i−1 =

ℓ∈Nk
a1,ℓk wℓ,i−1,
(9.204)
ψk,i = φk,i−1 + μku∗
k,i[dk(i) −uk,iφk,i−1],
(9.205)
wk,i =

ℓ∈Nk
a2,ℓkψℓ,i.
(9.206)
Furthermore, the choice A1 = A2 = C = IN corresponds to the non-cooperative mode of operation,
where each node runs the classical (stand-alone) least-mean-squares (LMS) ﬁlter independently of the
other nodes [4–7]:
wk,i = wk,i−1 + μkuk,i[dk(i) −uk,iwk,i−1],
i ≥0.
(9.207)
3.09.6.1 Data model
Whenwestudiedtheperformanceofthesteepest-descentdiffusionstrategy(9.163)–(9.165)weexploited
result (9.175), which indicated how the moments {rdu,k, Ru,k} that appeared in the recursions related

3.09.6 Performance of Adaptive Diffusion Strategies
375
to the optimal solution wo. Likewise, in order to be able to analyze the performance of the adaptive
diffusion strategy (9.201)–(9.203), we need to know how the data {dk(i), uk,i} across the network relate
to wo. Motivated by the several examples presented earlier in Section 3.09.2, we shall assume that the
data satisfy a linear model of the form:
dk(i) = uk,iwo + vk(i) ,
(9.208)
where vk(i) is measurement noise with variance σ 2
v,k:
σ 2
v,k ≜E|vk(i)|2
(9.209)
and where the stochastic processes {dk(i), uk,i} are assumed to be jointly wide-sense stationary with
moments:
σ 2
d,k ≜E|dk(i)|2
(scalar),
(9.210)
Ru,k ≜Eu∗
k,iuk,i > 0
(M × M),
(9.211)
rdu,k ≜Edk(i)u∗
k,i
(M × 1).
(9.212)
All variables are assumed to be zero-mean. Furthermore, the noise process {vk(i)} is assumed to be
temporally white and spatially independent, as described earlier by (9.6), namely,
Evk(i)v∗
k( j) = 0,
for all i ̸= j (temporal whiteness),
Evk(i)v∗
m( j) = 0,
for all i, j whenever k ̸= m (spatial whiteness).
(9.213)
The noise process vk(i) is further assumed to be independent of the regression data um, j for all k, m
and i, j so that:
Evk(i)u∗
m, j = 0,
for all k, m, i, j.
(9.214)
We shall also assume that the regression data are temporally white and spatially independent so that:
Eu∗
k,iuℓ, j = Ru,kδkℓδi j.
(9.215)
Although we are going to derive performance measures for the network under this independence assump-
tion on the regression data, it turns out that the resulting expressions continue to match well with sim-
ulation results for sufﬁciently small step-sizes, even when the independence assumption does not hold
(in a manner similar to the behavior of stand-alone adaptive ﬁlters) [4,5].
3.09.6.2 Performance measures
Our objective is to analyze whether, and how fast, the weight estimates {wk,i} from the adaptive diffusion
implementation (9.201)–(9.203) converge towards wo. To do so, we again introduce the M × 1 weight
error vectors:
˜φk,i ≜wo −φk,i,
(9.216)
˜ψk,i ≜wo −ψk,i,
(9.217)
˜wk,i ≜wo −wk,i.
(9.218)

376
CHAPTER 9 Diffusion Adaptation Over Networks
Each of these error vectors measures the residual relative to the desired wo in (9.208). We further
introduce two scalar error measures:
ek(i) ≜dk(i) −uk,iwk,i−1
(output error),
(9.219)
ea,k(i) ≜uk,i ˜wk,i−1
(a priori error).
(9.220)
The ﬁrst error measures how well the term uk,iwk,i−1 approximates the measured data, dk(i); in view
of (9.208), this error can be interpreted as an estimator for the noise term vk(i). If node k is able to
estimate wo well, then ek(i) would get close to vk(i). Therefore, under ideal conditions, we would
expect the variance of ek(i) to tend towards the variance of vk(i). However, as remarked earlier in
(9.31), there is generally an offset term for adaptive implementations that is captured by the variance of
the a priori error, ea,k(i). This second error measures how well uk,iwk,i−1 approximates the uncorrupted
term uk,iwo. Using the data model (9.208), we can relate {ek(i), ea,k(i)} as
ek(i) = ea,k + vk(i).
(9.221)
Since the noise component, vk(i), is assumed to be zero-mean and independent of all other random
variables, we recover (9.31):
E|ek(i)|2 = E|ea,k(i)|2 + σ 2
v,k .
(9.222)
This relation conﬁrms that the variance of the output error, ek(i), is at least as large as σ 2
v,k and away
from it by an amount that is equal to the variance of the a priori error, ea,k(i). Accordingly, in order
to quantify the performance of any particular node in the network, we deﬁne the mean-square-error
(MSE) and excess-mean-square-error (EMSE) for node k as the following steady-state measures:
MSEk ≜lim
i→∞E|ek(i)|2,
(9.223)
EMSEk ≜lim
i→∞E|ea,k(i)|2.
(9.224)
Then, it holds that
MSEk = EMSEk + σ 2
v,k .
(9.225)
Therefore, the EMSE term quantiﬁes the size of the offset in the MSE performance of each node. We
also deﬁne the mean-square-deviation (MSD) of each node as the steady-state measure:
MSDk ≜lim
i→∞E∥˜wk,i∥2,
(9.226)
which measures how far wk,i is from wo in the mean-square-error sense.
We indicated earlier in (9.36) and (9.37) how the MSD and EMSE of stand-alone LMS ﬁlters in the
non-cooperative case depend on {μk, σ 2
v , Ru,k}. In this section, we examine how cooperation among
the nodes inﬂuences their performance. Since cooperation couples the operation of the nodes, with data
originating from one node inﬂuencing the behavior of its neighbors and their neighbors, the study of the
network performance requires more effort than in the non-cooperative case. Nevertheless, when all is
said and done, we will arrive at expressions that approximate well the network performance and reveal
some interesting conclusions.

3.09.6 Performance of Adaptive Diffusion Strategies
377
3.09.6.3 Error recursions
Using the data model (9.208) and subtracting wo from both sides of the relations in (9.201)–(9.203)
we get
˜φk,i−1 =

ℓ∈Nk
a1,ℓk ˜wℓ,i−1,
(9.227)
˜ψk,i =
⎛
⎝IM −μk

ℓ∈Nk
cℓku∗
ℓ,iuℓ,i
⎞
⎠˜φk,i−1 −μk

ℓ∈Nk
cℓku∗
ℓ,ivℓ(i),
(9.228)
˜wk,i =

ℓ∈Nk
a2,ℓk ˜ψℓ,i.
(9.229)
Comparing the second recursion with the corresponding recursion in the steepest-descent case
(9.176)–(9.178), we see that two new effects arise: the effect of gradient noise, which replaces the
covariance matrices Ru,ℓby the instantaneous approximation u∗
ℓ,iuℓ,i, and the effect of measurement
noise, vℓ(i).
We again describe the above relations more compactly by collecting the information from across
the network in block vectors and matrices. We collect the error vectors from across all nodes into the
following N × 1 block vectors, whose individual entries are of size M × 1 each:
˜ψi ≜
⎡
⎢⎢⎢⎣
˜ψ1,i
˜ψ2,i
...
˜ψ N,i
⎤
⎥⎥⎥⎦,
˜φi ≜
⎡
⎢⎢⎢⎣
˜φ1,i
˜φ2,i
...
˜φN,i
⎤
⎥⎥⎥⎦,
˜wi ≜
⎡
⎢⎢⎢⎣
˜w1,i
˜w2,i
...
˜wN,i
⎤
⎥⎥⎥⎦.
(9.230)
The block quantities { ˜ψi, ˜φi, ˜wi} represent the state of the errors across the network at time i. Likewise,
we introduce the following N × N block diagonal matrices, whose individual entries are of size M × M
each:
M ≜diag{μ1IM, μ2IM, . . . , μN IM},
(9.231)
Ri ≜diag
⎧
⎨
⎩

ℓ∈N1
cℓ1u∗
ℓ,iuℓ,i,

ℓ∈N2
cℓ2u∗
ℓ,iuℓ,i, . . . ,

ℓ∈NN
cℓNu∗
ℓ,iuℓ,i
⎫
⎬
⎭.
(9.232)
Each block diagonal entry of Ri, say, the kth entry, contains a combination of rank-one regression terms
collected from the neighborhood of node k. In this way, the matrix Ri is now stochastic and dependent
on time, in contrast to the matrix R in the steepest-descent case in (9.181), which was a constant matrix.
Nevertheless, it holds that
ERi = R ,
(9.233)
so that, on average, Ri agrees with R. We can simplify the notation by denoting the neighborhood
combinations as follows:
Rk,i ≜

ℓ∈Nk
cℓku∗
ℓ,iuℓ,i,
(9.234)

378
CHAPTER 9 Diffusion Adaptation Over Networks
so that Ri becomes
Ri ≜diag{R1,i, R2,i, . . . , RN,i} (when C ̸= I).
(9.235)
Again, compared with the matrix Rk deﬁned in (9.182), we ﬁnd that Rk,i is now both stochastic and
time-dependent. Nevertheless, it again holds that
ERk,i = Rk .
(9.236)
In the special case when C = I, the matrix Ri reduces to
Ru,i ≜diag{u∗
1,iu1,i, u∗
2,iu2,i, . . . , u∗
N,iuN,i} (when C = I)
(9.237)
with
ERu,i = Ru ,
(9.238)
where Ru was deﬁned earlier in (9.184).
We further introduce the following N × 1 block column vector, whose entries are of size M × 1
each:
si ≜col{u∗
1,iv1(i), u∗
2,iv2(i), . . . , u∗
N,ivN(i)}.
(9.239)
Obviously, given that the regression data and measurement noise are zero-mean and independent of
each other, we have
Esi = 0
(9.240)
and the covariance matrix of si is N × N block diagonal with blocks of size M × M:
S ≜Esis∗
i = diag{σ 2
v,1Ru,1, σ 2
v,2Ru,2, . . . , σ 2
v,N Ru,N} .
(9.241)
Returning to (9.227)–(9.229), we conclude that the following relations hold for the block quantities:
˜φi−1 = AT
1 ˜wi−1,
(9.242)
˜ψi = (IN M −MRi) ˜φi−1 −MCT si,
(9.243)
˜wi = AT
2 ˜ψi,
(9.244)
where
C ≜C ⊗IM ,
(9.245)
so that the network weight error vector, ˜wi, ends up evolving according to the following stochastic
recursion:
˜wi = AT
2 (IN M −MRi)AT
1 ˜wi−1 −AT
2 MCT si,
i ≥0
(diffusion strategy).
(9.246)
For comparison purposes, if each node operates individually and uses the non-cooperative LMS recur-
sion (9.207), then the weight error vector across all N nodes would evolve according to the following
stochastic recursion:
˜wi = (IN M −MRu,i) ˜wi−1 −Msi,
i ≥0
(non-cooperative strategy),
(9.247)
where the matrices A1 and A2 do not appear, and Ri is replaced by Ru,i from (9.237).

3.09.6 Performance of Adaptive Diffusion Strategies
379
3.09.6.4 Convergence in the mean
Taking expectations of both sides of (9.246) we ﬁnd that:
E ˜wi = AT
2 (IN M −MR)AT
1 · E ˜wi−1,
i ≥0
(diffusion strategy),
(9.248)
where we used the fact that ˜wi−1 and Ri are independent of each other in view of our earlier assumptions
on the regression data and noise in Section 3.09.6.1. Comparing with the error recursion (9.189) in the
steepest-descent case, we ﬁnd that both recursions are identical with ˜wi replaced by E ˜wi. Therefore, the
convergence statements from the steepest-descent case can be extended to the adaptive case to provide
conditions on the step-size to ensure stability in the mean, i.e., to ensure
E ˜wi −→0 as i −→∞.
(9.249)
When (9.249) is guaranteed, we say that the adaptive diffusion solution is asymptotically unbiased. The
following statements restate the results of Theorems 9.5.1–9.5.5 in the context of mean error analysis.
Theorem 9.6.1(ConvergenceintheMean).
Considertheproblemofoptimizingtheglobalcost (9.92)
with the individual cost functions given by (9.93). Pick a right stochastic matrix C and left stochastic
matrices A1 and A2 satisfying (9.166) or (9.167). Assume each node in the network measures data
that satisfy the conditions described in Section 3.09.6.1, and runs the adaptive diffusion algorithm
(9.201)–(9.203). Then, all estimators {wk,i} across the network converge in the mean to the optimal
solution wo if the positive step-size parameters {μk} satisfy
μk <
2
λmax(Rk) ,
(9.250)
where the neighborhood covariance matrix Rk is deﬁned by (9.182). In other words, Ewk,i →wo for
all nodes k as i →∞.
Observe again that the mean stability condition (9.250) does not depend on the speciﬁc combination
matrices A1 and A2 that are being used. Only the combination matrix C inﬂuences the condition on the
step-size through the neighborhood covariance matrices {Rk}. Observe further that the statement of the
lemma does not require the network to be connected. Moreover, when C = IN, in which case the nodes
only share weight estimators and do not share neighborhood data {dℓ(i), uℓ,i} as in (9.204)–(9.206),
condition (9.250) becomes
μk <
2
λmax(Ru,k)
(adaptive cooperation with C = IN).
(9.251)
Conditions (9.250) and (9.251) are reminiscent of a classical result for the stand-alone LMS algorithm,
as in the non-cooperative case (9.207), where it is known that the estimator by each individual node in
this case would converge in the mean to wo if, and only if, its step-size satisﬁes
μk <
2
λmax(Ru,k)
(non-cooperative adaptation).
(9.252)

380
CHAPTER 9 Diffusion Adaptation Over Networks
The following statement provides a bi-directional result that ensures the mean convergence of the
adaptive diffusion strategy for any choice of left-stochastic combination matrices A1 and A2.
Theorem 9.6.2 (Mean Convergence for Arbitrary Combination Matrices).
Consider the problem
of optimizing the global cost (9.92) with the individual cost functions given by (9.93). Pick a right
stochastic matrix C satisfying (9.166). Assume each node in the network measures data that satisfy the
conditions described in Section 3.09.6.1. Then, the estimators {wk,i} generated by the adaptive diffusion
strategy (9.201)–(9.203), converge in the mean to wo, for all choices of left stochastic matrices A1 and
A2 satisfying (9.166) if, and only if,
μk <
2
λmax(Rk) .
(9.253)
As was the case with steepest-descent diffusion strategies, the adaptive diffusion strategy (9.201)–
(9.203) also enhances the convergence rate of the mean of the error vector towards zero relative to the
non-cooperative strategy (9.207). The next results restate Theorems 9.5.3–9.5.5; they assume C is a
doubly stochastic matrix.
Theorem 9.6.3 (Mean Convergence Rate is Enhanced: Uniform Step-Sizes).
Consider the problem
of optimizing the global cost (9.92) with the individual cost functions given by (9.93). Pick a doubly
stochastic matrix C satisfying (9.196) and left stochastic matrices A1 and A2 satisfying (9.166). Assume
each node in the network measures data that satisfy the conditions described in Section 3.09.6.1.
Consider two modes of operation. In one mode, each node in the network runs the adaptive diffusion
algorithm (9.201)–(9.203). In the second mode, each node operates individually and runs the non-
cooperative LMS algorithm (9.207). In both cases, the positive step-sizes used by all nodes are assumed
to be the same, say, μk = μ for all k, and the value of μ is chosen to satisfy the required mean stability
conditions (9.250) and (9.252), which are met by selecting
μ < min
1≤k≤N

2
λmax(Ru,k)
+
.
(9.254)
It then holds that the magnitude of the mean error vector, ∥E ˜wi∥in the diffusion case decays to
zero more rapidly than in the non-cooperative case. In other words, diffusion enhances convergence
rate.
Theorem 9.6.4 (Mean Convergence Rate is Enhanced: Uniform Covariance Data).
Consider
the same setting of Theorem 9.6.3. Assume the covariance data are uniform across all nodes, say,
Ru,k = Ru is independent of k. Assume further that the nodes in both modes of operation employ
steps-sizes μk that are chosen to satisfy the required stability conditions (9.250) and (9.252), which in
this case are met by:
μk <
2
λmax(Ru),
k = 1, 2, . . . , N.
(9.255)
It then holds that the magnitude of the mean error vector, ∥E ˜wi∥, in the diffusion case also decays to
zero more rapidly than in the non-cooperative case. In other words, diffusion enhances convergence
rate.
The next statement considers the case of ATC and CTA strategies (9.204)–(9.206) without information
exchange, which correspond to the choice C = IN. The result establishes that these strategies always

3.09.6 Performance of Adaptive Diffusion Strategies
381
enhance the convergence rate over the non-cooperative case, without the need to assume uniform step-
sizes or uniform covariance data.
Theorem 9.6.5 (Mean Convergence Rate is Enhanced when C = I).
Consider the problem of
optimizing the global cost (9.92) with the individual cost functions given by (9.93). Pick left stochastic
matrices A1 and A2 satisfying (9.166) and set C = IN. This situation covers the ATC and CTA strategies
(9.204)–(9.206) that do not involve information exchange. Assume each node in the network measures
data that satisfy the conditions described in Section 3.09.6.1. Consider two modes of operation. In one
mode, each node in the network runs the adaptive diffusion algorithm (9.163)–(9.165). In the second
mode, each node operates individually and runs the non-cooperative LMS algorithm (9.207). In both
cases, the positive step-sizes are chosen to satisfy the required stability conditions (9.251) and (9.252),
which in this case are met by
μk <
2
λmax(Ru,k),
k = 1, 2, . . . , N.
(9.256)
It then holds that the magnitude of the mean error vector, ∥E ˜wi∥, in the diffusion case decays to zero more
rapidly than in the non-cooperative case. In other words, diffusion cooperation enhances convergence
rate.
The results of the previous theorems again highlight the following important facts about the role of
the combination matrices {A1, A2, C} in the convergence behavior of the adaptive diffusion strategy
(9.201)–(9.203):
a. The matrix C inﬂuences the mean stability of the network through its inﬂuence on the bound in
(9.250). This is because the matrices {Rk} depend on the entries of C. The matrices {A1, A2} do not
inﬂuence network mean stability in that they can be chosen arbitrarily and the network will remain
stable under (9.250).
b. The matrices {A1, A2, C} inﬂuence the rate of convergence of the mean weight-error vector over the
network since they inﬂuence the spectral radius of the matrix AT
2 (IN M −MR)AT
1 , which controls
the dynamics of the weight error vector in (9.248).
3.09.6.5 Mean-square stability
It is not sufﬁcient to ensure the stability of the weight-error vector in the mean sense. The error vectors,
˜wk,i, may be converging on average to zero but they may have large ﬂuctuations around the zero value.
We therefore need to examine how small the error vectors get. To do so, we perform a mean-square-error
analysis. The purpose of the analysis is to evaluate how the variances E∥˜wk,i∥2 evolve with time and
what their steady-state values are, for each node k.
In this section, we are particularly interested in evaluating the evolution of two mean-square-errors,
namely,
E∥˜wk,i∥2
and E|ea,k(i)|2.
(9.257)
The steady-state values of these quantities determine the MSD and EMSE performance levels at node
k and, therefore, convey critical information about the performance of the network. Under the inde-
pendence assumption on the regression data from Section 3.09.6.1, it can be veriﬁed that the EMSE

382
CHAPTER 9 Diffusion Adaptation Over Networks
variance can be written as:
E|ea,k(i)|2 ≜E|uk,i ˜wk,i−1|2
= E ˜w∗
k,i−1u∗
k,iuk,i ˜wk,i−1
= E[E( ˜w∗
k,i−1u∗
k,iuk,i ˜wk,i−1| ˜wk,i−1)]
= E ˜w∗
k,i−1[Eu∗
k,iuk,i] ˜wk,i−1
= E ˜w∗
k,i−1Ru,k ˜wk,i−1
= E∥˜wk,i−1∥2
Ru,k,
(9.258)
in terms of a weighted square measure with weighting matrix Ru,k. Here we are using the notation ∥x∥2

to denote the weighted square quantity x∗x, for any column vector x and matrix . Thus, we can
evaluate mean-square-errors of the form (9.257) by evaluating the means of weighted square quantities
of the following form:
E∥˜wk,i∥2
k
(9.259)
for an arbitrary Hermitian nonnegative-deﬁnite weighting matrix k that we are free to choose. By
setting k to different values (say, k = I or k = Ru,k), we can extract various types of information
about the nodes and the network, as the discussion will reveal. The approach we follow is based on the
energy conservation framework of [4,5,55].
So, let  denote an arbitrary N × N block Hermitian nonnegative-deﬁnite matrix that we are free
to choose, with M × M block entries {ℓk}. Let σ denote the (N M)2 × 1 vector that is obtained by
stacking the columns of  on top of each other, written as
σ ≜vec().
(9.260)
In the sequel, it will become more convenient to work with the vector representation σ than with the
matrix  itself.
We start from the weight-error vector recursion (9.246) and re-write it more compactly as:
˜wi = Bi ˜wi−1 −Gsi,
i ≥0 ,
(9.261)
where the coefﬁcient matrices Bi and G are short-hand representations for
Bi ≜AT
2 (IN M −MRi)AT
1
(9.262)
and
G ≜AT
2 MCT .
(9.263)
Note that Bi is stochastic and time-variant, while G is constant. We denote the mean of Bi by
B ≜EBi = AT
2 (IN M −MR)AT
1
,
(9.264)
where R is deﬁned by (9.181). Now equating weighted square measures on both sides of (9.261) we get
∥˜wi∥2
 = ∥Bi ˜wi−1 −Gsi∥2
.
(9.265)

3.09.6 Performance of Adaptive Diffusion Strategies
383
Expanding the right-hand side we ﬁnd that
∥˜wi∥2
 = ˜w∗
i−1B∗
i Bi ˜wi−1 + s∗
i GT Gsi −˜w∗
i−1B∗
i Gsi −s∗
i GT Bi ˜wi−1.
(9.266)
Under expectation, the last two terms on the right-hand side evaluate to zero so that
E∥˜wi∥2
 = E( ˜w∗
i−1B∗
i Bi ˜wi−1) + E(s∗
i GT Gsi).
(9.267)
Let us evaluate each of the expectations on the right-hand side. The last expectation is given by
E(s∗
i GT Gsi)
=
Tr(GT GEsis∗
i )
(9.241)
=
Tr(GT GS)
=
Tr(GSGT ),
(9.268)
where S is deﬁned by (9.241) and where we used the fact that Tr(AB) = Tr(B A) for any two matrices A
and B of compatible dimensions. With regards to the ﬁrst expectation on the right-hand side of (9.267),
we have
E( ˜w∗
i−1B∗
i Bi ˜wi−1) = E[E( ˜w∗
i−1B∗
i Bi ˜wi−1| ˜wi−1)]
= E ˜w∗
i−1[E(B∗
i Bi)] ˜wi−1
≜E ˜w∗
i−1′ ˜wi−1
= E∥˜wi−1∥2
′,
(9.269)
where we introduced the nonnegative-deﬁnite weighting matrix
′
≜
EB∗
i Bi
(9.270)
=
EA1(IN M −RiM)A2AT
2 (IN M −MRi)AT
1
=
A1A2AT
2 AT
1 −A1A2AT
2 MRAT
1 −A1RMA2AT
2 AT
1 + O(M2), (9.270)
where R is deﬁned by (9.181) and the term O(M2) denotes the following factor, which depends on the
square of the step-sizes, {μ2
k}:
O(M2) = E(A1RiMA2AT
2 MRiAT
1 ).
(9.271)
The evaluation of the above expectation depends on higher-order moments of the regression data. While
we can continue with the analysis by taking this factor into account, as was done in [4,5,18,55], it is
sufﬁcient for the exposition in this chapter to focus on the case of sufﬁciently small step-sizes where
terms involving higher powers of the step-sizes can be ignored. Therefore, we continue our discussion
by letting
′ ≜A1A2AT
2 AT
1 −A1A2AT
2 MRAT
1 −A1RMA2AT
2 AT
1
.
(9.272)
The weighting matrix ′ is fully deﬁned in terms of the step-size matrix, M, the network topology
through the matrices {A1, A2, C}, and the regression statistical proﬁle through R. Expression (9.272)

384
CHAPTER 9 Diffusion Adaptation Over Networks
tells us how to construct ′ from . The expression can be transformed into a more compact and
revealing form if we instead relate the vector forms σ ′ = vec(′) and σ = vec(). Using the following
equalities for arbitrary matrices {U, W, } of compatible dimensions [5]:
vec(UW) = (W T ⊗U)σ,
(9.273)
Tr(W) = [vec(W T )]T σ,
(9.274)
and applying the vec operation to both sides of (9.272) we get
σ ′ = (A1A2 ⊗A1A2)σ −(A1RT MA2 ⊗A1A2)σ −(A1A2 ⊗A1RMA2)σ.
That is,
σ ′ ≜Fσ ,
(9.275)
where we are introducing the coefﬁcient matrix of size (N M)2 × (N M)2:
F ≜(A1A2 ⊗A1A2) −(A1RT MA2 ⊗A1A2) −(A1A2 ⊗A1RMA2) .
(9.276)
A reasonable approximate expression for F for sufﬁciently small step-sizes is
F ≈BT ⊗B∗.
(9.277)
Indeed, if we replace B from (9.264) into (9.277) and expand terms, we obtain the same factors that
appear in (9.276) plus an additional term that depends on the square of the step-sizes, {μ2
k}, whose effect
can be ignored for sufﬁciently small step-sizes.
In this way, and using in addition property (9.274), we ﬁnd that relation (9.267) becomes:
E∥˜wi∥2
 = E∥˜wi−1∥2
′ + [vec(GST GT )]T σ .
(9.278)
The last term is dependent on the network topology through the matrix G, which is deﬁned in terms of
{A2, C, M}, and the noise and regression data statistical proﬁle through S. It is convenient to introduce
the alternative notation ∥x∥2
σ to refer to the weighted square quantity ∥x∥2
, where σ = vec(). We
shall use these two notations interchangeably. The convenience of the vector notation is that it allows
us to exploit the simpler linear relation (9.275) between σ ′ and σ to rewrite (9.278) as shown in (9.279)
below, with the same weight vector σ appearing on both sides.
Theorem 9.6.6 (Variance Relation).
Consider the data model of Section 3.09.6.1 and the inde-
pendence statistical conditions imposed on the noise and regression data, including (9.208)–(9.215).
Assume further sufﬁciently small step-sizes are used so that terms that depend on higher-powers of
the step-sizes can be ignored. Pick left stochastic matrices A1 and A2 and a right stochastic matrix
C satisfying (9.166). Under these conditions, the weight-error vector ˜wi = col{ ˜wk,i}N
k=1 associated
with a network running the adaptive diffusion strategy (9.201)–(9.203) satisﬁes the following variance
relation:
E∥˜wi∥2
σ = E∥˜wi−1∥2
Fσ + [vec(YT )]T σ
(9.279)

3.09.6 Performance of Adaptive Diffusion Strategies
385
for any Hermitian nonnegative-deﬁnite matrix  with σ = vec(), and where {S, G, F} are deﬁned
by (9.241), (9.263), and (9.277), and
Y ≜GSGT .
(9.280)
□
Note that relation (9.279) is not an actual recursion; this is because the weighting matrices {σ, Fσ}
on both sides of the equality are different. The relation can be transformed into a true recursion by
expanding it into a convenient state-space model; this argument was pursued in [4,5,18,55] and is not
necessary for the exposition here, except to say that stability of the matrix F ensures the mean-square
stability of the ﬁlter—this fact is also established further ahead through relation (9.327). By mean-square
stability we mean that each term E∥˜wk,i∥2 remains bounded over time and converges to a steady-state
MSDk value. Moreover, the spectral radius of F controls the rate of convergence of E∥˜wi∥2 towards its
steady-state value.
Theorem 9.6.7 (Mean-Square Stability).
Consider the same setting of Theorem 9.6.6. The adaptive
diffusion strategy (9.201)–(9.203) is mean-square stable if, and only if, the matrix F deﬁned by (9.276),
or its approximation (9.277), is stable (i.e., all its eigenvalues lie strictly inside the unit disc). This
condition is satisﬁed by sufﬁciently small positive step-sizes {μk} that are also smaller than the following
bound:
μk <
2
λmax(Rk),
(9.281)
where the neighborhood covariance matrix Rk is deﬁned by (9.182). Moreover, the convergence rate of
the algorithm is determined by the value [ρ(B)]2 (the square of the spectral radius of B).
Proof.
Recall that, for two arbitrary matrices A and B of compatible dimensions, the eigenvalues of
the Kronecker product A ⊗B is formed of all product combinations λi(A)λ j(B) of the eigenvalues
of A and B [19]. Therefore, for sufﬁciently small step-sizes, we can use expression (9.277) to note
that ρ(F) = [ρ(B)]2. It follows that F is stable if, and only if, B is stable. We already noted earlier
in Theorem 9.6.1 that condition (9.281) ensures the stability of B. Therefore, step-sizes that ensure
stability in the mean and are sufﬁciently small will also ensure mean-square stability.
□
Remark.
More generally, had we not ignored the second-order term (9.271), the expression for F
would have been the following. Starting from the deﬁnition ′ = EB∗
i Bi, we would get
σ ′ =

EBT
i ⊗B∗
i

σ,
so that
F ≜E

BT
i ⊗B∗
i

(for general step-sizes)
(9.282)
= (A1 ⊗A1) ·

I −(RT M ⊗I) −(I ⊗RM) + E

RT
i M ⊗RiM

· (A2 ⊗A2).
Mean-square stability of the ﬁlter would then require the step-sizes {μk} to be chosen such that they
ensure the stability of this matrix F (in addition to condition (9.281) to ensure mean stability).
□

386
CHAPTER 9 Diffusion Adaptation Over Networks
3.09.6.6 Network mean-square performance
We can now use the variance relation (9.279) to evaluate the network performance, as well as the
performance of the individual nodes, in steady-state. Since the dynamics is mean-square stable for
sufﬁciently small step-sizes, we take the limit of (9.279) as i →∞and write:
lim
i→∞E∥˜wi∥2
σ = lim
i→∞E∥˜wi−1∥2
Fσ + [vec(YT )]T σ.
(9.283)
Grouping terms leads to the following result.
Corollary 9.6.1 (Steady-State Variance Relation).
Consider the same setting of Theorem 9.6.6. The
weight-error vector, ˜wi = col{ ˜wk,i}N
k=1, of the adaptive diffusion strategy (9.201)–(9.203) satisﬁes the
following relation in steady-state:
lim
i→∞E∥˜wi∥2
(I−F)σ = [vec(YT )]T σ
(9.284)
for any Hermitian nonnegative-deﬁnite matrix  with σ = vec(), and where {F, Y} are deﬁned by
(9.277) and (9.280).
□
Expression (9.284) is a very useful relation; it allows us to evaluate the network MSD and EMSE through
proper selection of the weighting vector σ (or, equivalently, the weighting matrix ). For example, the
network MSD is deﬁned as the average value:
MSDnetwork ≜lim
i→∞
1
N
N

k=1
E∥˜wk,i∥2,
(9.285)
which amounts to averaging the MSDs of the individual nodes. Therefore,
MSDnetwork = lim
i→∞
1
N E∥˜wi∥2 = lim
i→∞E∥˜wi∥2
1/N.
(9.286)
This means that in order to recover the network MSD from relation (9.284), we should select the
weighting vector σ such that
(I −F)σ = 1
N vec(IN M).
Solving for σ and substituting back into (9.284) we arrive at the following expression for the network
MSD:
MSDnetwork = 1
N · [vec(YT )]T · (I −F)−1 · vec(IN M) .
(9.287)
Likewise, the network EMSE is deﬁned as the average value
EMSEnetwork ≜lim
i→∞
1
N
N

k=1
E|ea,k(i)|2
= lim
i→∞
1
N
N

k=1
E∥˜wk,i∥2
Ru,k,
(9.288)

3.09.6 Performance of Adaptive Diffusion Strategies
387
which amounts to averaging the EMSEs of the individual nodes. Therefore,
EMSEnetwork = lim
i→∞
1
N E∥˜wi∥2
diag{Ru,1,Ru,2,...,Ru,N } = lim
i→∞
1
N E∥˜wi∥2
Ru,
(9.289)
where Ru is the matrix deﬁned earlier by (9.184), and which we repeat below for ease of reference:
Ru = diag{Ru,1, Ru,2, . . . , Ru,N}.
(9.290)
This means that in order to recover the network EMSE from relation (9.284), we should select the
weighting vector σ such that
(I −F)σ = 1
N vec(Ru).
(9.291)
Solving for σ and substituting into (9.284) we arrive at the following expression for the network EMSE:
EMSEnetwork = 1
N · [vec(YT )]T · (I −F)−1 · vec(Ru) .
(9.292)
3.09.6.7 Mean-square performance of individual nodes
We can also assess the mean-square performance of the individual nodes in the network from (9.284).
For instance, the MSD of any particular node k is deﬁned by
MSDk ≜lim
i→∞E∥˜wk,i∥2.
(9.293)
Introduce the N × N block diagonal matrix with blocks of size M × M, where all blocks on the diagonal
are zero except for an identity matrix on the diagonal block of index k, i.e.,
Jk ≜diag{0M, . . . , 0M, IM, 0M, . . . , 0M}.
(9.294)
Then, we can express the node MSD as follows:
MSDk ≜lim
i→∞E∥˜wi∥2
Jk.
(9.295)
The same argument that was used to obtain the network MSD then leads to
MSDk = [vec(YT )]T · (I −F)−1 · vec(Jk) .
(9.296)
Likewise, the EMSE of node k is deﬁned by
EMSEk ≜lim
i→∞E|ea,k(i)|2
= lim
i→∞E∥˜wk,i∥2
Ru,k.
(9.297)
Introduce the N × N block diagonal matrix with blocks of size M × M, where all blocks on the diagonal
are zero except for the diagonal block of index k whose value is Ru,k, i.e.,
Tk ≜diag{0M, . . . , 0M, Ru,k, 0M, . . . , 0M}.
(9.298)

388
CHAPTER 9 Diffusion Adaptation Over Networks
Then, we can express the node EMSE as follows:
EMSEk ≜lim
i→∞E∥˜wi∥2
Tk.
(9.299)
The same argument that was used to obtain the network EMSE then leads to
EMSEk = [vec(YT )]T · (I −F)−1 · vec(Tk) .
(9.300)
We summarize the results in the following statement.
Theorem 9.6.8 (Network Mean-Square Performance).
Consider the same setting of Theorem 9.6.6.
Introduce the 1 × (N M)2 row vector hT deﬁned by
hT ≜[vec(YT )]T · (I −F)−1,
(9.301)
where {F, Y} are deﬁned by (9.277) and (9.280). Then the network MSD and EMSE and the individual
node performance measures are given by
MSDnetwork = hT · vec(IN M)/N,
(9.302)
EMSEnetwork = hT · vec(Ru)/N,
(9.303)
MSDk = hT · vec(Jk),
(9.304)
EMSEk = hT · vec(Tk),
(9.305)
where {Jk, Tk} are deﬁned by (9.294) and (9.298).
□
We can recover from the above expressions the performance of the nodes in the non-cooperative imple-
mentation(9.207),whereeachnodeperformsitsadaptationindividually,bysetting A1 = A2 = C = IN.
We can express the network MSD, and its EMSE if desired, in an alternative useful form involving
a series representation.
Corollary 9.6.2 (Series Representation for Network MSD).
Consider the same setting of Theo-
rem 9.6.6. The network MSD can be expressed in the following alternative series form:
MSDnetwork = 1
N
∞

j=0
Tr(B jYB∗j) ,
(9.306)
where
Y = GSGT ,
(9.307)
G = AT
2 MCT ,
(9.308)
B = AT
2 (I −MR)AT
1 .
(9.309)
Proof.
Since F is stable when the ﬁlter is mean-square stable, we can expand (I −F)−1 as
(I −F)−1
=
I + F + F2 + · · ·
(9.277)
=
I + (BT ⊗B∗) + (BT ⊗B∗)2 + · · · .
Substituting into (9.287) and using property (9.274), we obtain the desired result.
□

3.09.6 Performance of Adaptive Diffusion Strategies
389
3.09.6.8 Uniform data proﬁle
We can simplify expressions (9.307)–(9.309) for {Y, G, B} in the case when the regression covariance
matrices are uniform across the network and all nodes employ the same step-size, i.e., when
Ru,k = Ru,
for all k
(uniform covariance proﬁle),
(9.310)
μk = μ,
for all k
(uniform step-sizes),
(9.311)
and when the combination matrix C is doubly stochastic, so that
C1 = 1,
CT 1 = 1 .
(9.312)
We refer to conditions (9.310)–(9.312) as corresponding to a uniform data proﬁle environment. The
noise variances, {σ 2
v,k}, do not need to be uniform so that the signal-to-noise ratio (SNR) across the
network can still vary from node to node. The simpliﬁed expressions derived in the sequel will be useful
in Section 3.09.7 when we compare the performance of various cooperation strategies.
Thus, under conditions (9.310)–(9.312), expressions (9.180), (9.181), and (9.263) for {M, R, G}
simplify to
M = μIN M,
(9.313)
R = IN ⊗Ru,
(9.314)
G = μAT
2 CT .
(9.315)
Substituting these values into expression (9.309) for B we get
B = AT
2 (I −MR)AT
1
=

AT
2 ⊗I
 
I −μ(I ⊗Ru)
 
AT
1 ⊗I

=

AT
2 ⊗I
 
AT
1 ⊗I

−μ

AT
2 ⊗I
 
I ⊗Ru
 
AT
1 ⊗I

=

AT
2 AT
1 ⊗I

−μ

AT
2 AT
1 ⊗Ru

= AT
2 AT
1 ⊗(I −μRu),
(9.316)
where we used the useful Kronecker product identities:
(X + Y) ⊗Z = (X ⊗Z) + (Y ⊗Z),
(9.317)
(X ⊗Y)(W ⊗Z) = (XW ⊗Y Z),
(9.318)
for any matrices {X, Y, Z, W} of compatible dimensions. Likewise, introduce the N × N diagonal
matrix with noise variances:
Rv ≜diag

σ 2
v,1, σ 2
v,2, . . . , σ 2
v,N

.
(9.319)
Then, expression (9.241) for S becomes
S = diag

σ 2
v,1Ru, σ 2
v,2Ru, . . . , σ 2
v,N Ru

= Rv ⊗Ru.
(9.320)

390
CHAPTER 9 Diffusion Adaptation Over Networks
It then follows that we can simplify expression (9.307) for Y as:
Y = μ2AT
2 CT SCA2
= μ2 ·

AT
2 ⊗I

· (CT ⊗I) ⊗(Rv ⊗Ru) · (C ⊗I) · (A2 ⊗I)
= μ2 
AT
2 CT RvC A2 ⊗Ru

.
(9.321)
Corollary 9.6.3 (Network MSD for Uniform Data Proﬁle).
Consider the same setting of Theorem
9.6.6 with the additional requirement that conditions (9.310)–(9.312) for a uniform data proﬁle hold.
The network MSD is still given by the same series representation (9.306) where now
Y = μ2 
AT
2 CT RvC A2 ⊗Ru

,
(9.322)
B = AT
2 AT
1 ⊗(I −μRu).
(9.323)
Using these expressions, we can decouple the network MSD expression (9.306) into two separate
factors: one is dependent on the step-size and data covariance {μ, Ru}, and the other is dependent on
the combination matrices and noise proﬁle {A1, A2, C, Rv}:
MSDnetwork = μ2
N
∞

j=0
Tr

AT
2 AT
1
 j 
AT
2 CT RvC A2

(A1A2) j

⊗[(I −μRu) j Ru(I −μRu) j]

.
(9.324)
□
Proof.
Using (9.306) and the given expressions (9.322) and (9.323) for {Y, B}, we get
MSDnetwork = μ2
N
∞

j=0
Tr

AT
2 AT
1
 j
⊗(I −μRu) j

×

AT
2 CT RvC A2 ⊗Ru
 
(A1A2) j ⊗(I −μRu) j
.
Result (9.324) follows from property (9.317).
□
3.09.6.9 Transient mean-square performance
Before comparing the mean-square performance of various cooperation strategies, we pause to comment
that the variance relation (9.279) can also be used to characterize the transient behavior of the network,
and not just its steady-state performance. To see this, iterating (9.279) starting from i = 0, we ﬁnd that
E∥˜wi∥2
σ = E∥˜w−1∥2
Fi+1σ + [vec(YT )]T ·
⎛
⎝
i
j=0
F jσ
⎞
⎠,
(9.325)

3.09.7 Comparing the Performance of Cooperative Strategies
391
where
˜w−1 ≜wo −w−1
(9.326)
in terms of the initial condition, w−1. If this initial condition happens to be w−1 = 0, then ˜w−1 = wo.
Comparing expression (9.325) at time instants i and i −1 we can relate E∥˜wi∥2
σ and E∥˜wi−1∥2
σ as
follows:
E∥˜wi∥2
σ = E∥˜wi−1∥2
σ + [vec(YT )]T · Fiσ −E∥˜w−1∥2
(I−F)Fiσ .
(9.327)
This recursion relates the same weighted square measures of the error vectors { ˜wi, ˜wi−1}. It therefore
describes how these weighted square measures evolve over time. It is clear from this relation that, for
mean-square stability, the matrix F needs to be stable so that the terms involving Fi do not grow
unbounded.
The learning curve of the network is the curve that describes the evolution of the network EMSE
over time. At any time i, the network EMSE is denoted by ζ(i) and measured as:
ζ(i) ≜1
N
N

k=1
E|ea,k(i)|2
(9.328)
= 1
N
N

k=1
E∥˜wk,i∥2
Ru,k.
The above expression indicates that ζ(i) is obtained by averaging the EMSE of the individual nodes at
time i. Therefore,
ζ(i) = 1
N E∥˜wi∥2
diag{Ru,1,Ru,2,...,Ru,N } = 1
N E∥˜wi∥2
Ru,
(9.329)
where Ru is the matrix deﬁned by (9.290). This means that in order to evaluate the evolution of the
network EMSE from relation (9.327), we simply select the weighting vector σ such that
σ = 1
N vec(Ru).
(9.330)
Substituting into (9.327) we arrive at the learning curve for the network.
Corollary 9.6.4 (Network Learning Curve).
Consider the same setting of Theorem 9.6.6. Let ζ(i)
denote the network EMSE at time i, as deﬁned by (9.328). Then, the learning curve of the network
corresponds to the evolution of ζ(i) with time and is described by the following recursion over i ≥0:
ζ(i) = ζ(i −1) + 1
N [vec(YT )]T · Fi · vec(Ru) −1
N E∥˜w−1∥2
(I−F)Fivec(Ru) ,
(9.331)
where {F, Y, Ru} are deﬁned by (9.277), (9.280), and (9.290).
□
3.09.7 Comparing the performance of cooperative strategies
Using the expressions just derived for the MSD of the network, we can compare the performance
of various cooperative and non-cooperative strategies. Table 9.6 further ahead summarizes the results
derived in this section and the conditions under which they hold.

392
CHAPTER 9 Diffusion Adaptation Over Networks
3.09.7.1 Comparing ATC and CTA strategies
We ﬁrst compare the performance of the adaptive ATC and CTA diffusion strategies (9.153) and (9.154)
when they employ a doubly stochastic combination matrix A. That is, let us consider the two scenarios:
C,
A1 = A,
A2 = IN
(adaptive CTA strategy),
(9.332)
C,
A1 = IN,
A2 = A (adaptive ATC strategy),
(9.333)
where A is now assumed to be doubly stochastic, i.e.,
A1 = 1,
AT 1 = 1
(9.334)
with its rows and columns adding up to one. For example, these conditions are satisﬁed when A is left
stochastic and symmetric. Then, expressions (9.307) and (9.309) give:
Bcta = (I −MR)AT ,
Ycta = MCT SCM,
(9.335)
Batc = AT (I −MR),
Yatc = AT MCT SCMA,
(9.336)
where
A = A ⊗IM.
(9.337)
Following [18], introduce the auxiliary nonnegative-deﬁnite matrix
H j ≜[(I −MR)AT ] j · MCT SCM · [(I −MR)AT ]∗j.
(9.338)
Then, it is immediate to verify from (9.306) that
MSDnetwork
cta
= 1
N
∞

j=0
Tr(H j),
(9.339)
MSDnetwork
atc
= 1
N
∞

j=0
Tr(AT H jA),
(9.340)
so that
MSDnetwork
cta
−MSDnetwork
atc
= 1
N
∞

j=0
Tr

H j −AT H jA

.
(9.341)
Now, since A is doubly stochastic, it also holds that the enlarged matrix A is doubly stochastic. Moreover,
for any doubly stochastic matrix A and any nonnegative-deﬁnite matrix H of compatible dimensions,
it holds that (see part (f) of Theorem C.3):
Tr(AT HA) ≤Tr(H).
(9.342)
Applying result (9.342) to (9.341) we conclude that
MSDnetwork
atc
≤MSDnetwork
cta
(doubly stochastic A),
(9.343)
so that the adaptive ATC strategy (9.153) outperforms the adaptive CTA strategy (9.154) for doubly
stochastic combination matrices A.

3.09.7 Comparing the Performance of Cooperative Strategies
393
3.09.7.2 Comparing strategies with and without information exchange
We now examine the effect of information exchange (C ̸= I) on the performance of the adaptive ATC
and CTA diffusion strategies (9.153) and (9.154) under conditions (9.310)–(9.312) for uniform data
proﬁle.
3.09.7.2.1
CTA Strategies
We start with the adaptive CTA strategy (9.154), and consider two scenarios with and without infor-
mation exchange. These scenarios correspond to the following selections in the general description
(9.201)–(9.203):
C ̸= I,
A1 = A,
A2 = IN
(adaptive CTA with information exchange),
(9.344)
C = I,
A1 = A,
A2 = IN
(adaptive CTA without information exchange).
(9.345)
Then, expressions (9.322) and (9.323) give:
Bcta,C̸=I = AT ⊗(I −μRu),
Ycta,C̸=I = μ2(CT RvC ⊗Ru),
(9.346)
Bcta,C=I = AT ⊗(I −μRu),
Ycta,C=I = μ2(Rv ⊗Ru),
(9.347)
where the matrix Rv is deﬁned by (9.319). Note that Bcta,C̸=I = B cta, C= I, so we denote them simply
by B in the derivation that follows. Then, from expression (9.306) for the network MSD we get:
MSDnetwork
cta,C=I −MSDnetwork
cta,C̸=I = μ2
N
∞

j=0
Tr

B j 
Rv −CT RvC

⊗Ru

B∗j
.
(9.348)
It follows that the difference in performance between both CTA implementations depends on how the
matrices Rv and CT RvC compare to each other:
1. When Rv −CT RvC ≥0, we obtain
MSDnetwork
cta,C=I ≥MSDnetwork
cta,C̸=I

when CT RvC ≤Rv

,
(9.349)
so that a CTA implementation with information exchange performs better than a CTA implementa-
tion without information exchange. Note that the condition on {Rv, C} corresponds to requiring
CT RvC ≤Rv,
(9.350)
which can be interpreted to mean that the cooperation matrix C should be such that it does not
amplify the effect of measurement noise. For example, this situation occurs when the noise proﬁle
is uniform across the network, in which case Rv = σ 2
v IM. This is because it would then hold that
Rv −CT RvC = σ 2
v (I −CT C) ≥0
(9.351)
in view of the fact that (I −CT C) ≥0 since C is doubly stochastic (cf. property (e) in Lemma C.3).

394
CHAPTER 9 Diffusion Adaptation Over Networks
2. When Rv −CT RvC ≤0, we obtain
MSDnetwork
cta,C=I ≤MSDnetwork
cta,C̸=I

when CT RvC ≥Rv

,
(9.352)
so that a CTA implementation without information exchange performs better than a CTA imple-
mentation with information exchange. In this case, the condition on {Rv, C} indicates that the
combination matrix C ends up amplifying the effect of noise.
3.09.7.2.2
ATC Strategies
We can repeat the argument for the adaptive ATC strategy (9.153), and consider two scenarios with and
without information exchange. These scenarios correspond to the following selections in the general
description (9.201)–(9.203):
C ̸= I,
A1 = IN,
A2 = A (adaptive ATC with information exchange),
(9.353)
C = I,
A1 = IN,
A2 = A (adaptive ATC without information exchange).
(9.354)
Then, expressions (9.322) and (9.323) give:
Batc,C̸=I = AT ⊗(I −μRu),
Yatc,C̸=I = μ2(AT CT RvC A ⊗Ru),
(9.355)
Batc,C=I = AT ⊗(I −μRu),
Yatc,C=I = μ2(AT Rv A ⊗Ru).
(9.356)
Note again that Batc,C̸=I = Batc,C=I , so we denote them simply by B. Then,
MSDnetwork
atc,C=I −MSDnetwork
atc,C̸=I = μ2
N
∞

j=0
Tr

B j 
AT 
Rv −CT RvC

A ⊗Ru

B∗j
.
(9.357)
It again follows that the difference in performance between both ATC implementations depends on how
the matrices Rv and CT RvC compare to each other and we obtain:
MSDnetwork
atc,C=I ≥MSDnetwork
atc,C̸=I

when CT RvC ≤Rv

(9.358)
and
MSDnetwork
atc,C=I ≤MSDnetwork
atc,C̸=I

when CT RvC ≥Rv

.
(9.359)
3.09.7.3 Comparing diffusion strategies with the non-cooperative strategy
We now compare the performance of the adaptive CTA strategy (9.154) to the non-cooperative LMS
strategy (9.207) assuming conditions (9.310)–(9.312) for uniform data proﬁle. These scenarios corre-
spond to the following selections in the general description (9.201)–(9.203):
C,
A1 = A,
A2 = I
(adaptive CTA),
(9.360)
C = I,
A1 = I,
A2 = I
(non-cooperative LMS),
(9.361)

3.09.7 Comparing the Performance of Cooperative Strategies
395
where A is further assumed to be doubly stochastic (along with C) so that
A1 = 1,
AT 1 = 1.
(9.362)
Then, expressions (9.322) and (9.323) give:
Bcta = AT ⊗(I −μRu),
Ycta = μ2 
CT RvC ⊗Ru

,
(9.363)
Blms = I ⊗(I −μRu),
Ylms = μ2(Rv ⊗Ru).
(9.364)
Now recall that
C = C ⊗IM,
(9.365)
so that, using the Kronecker product property (9.317),
Ycta = μ2(CT RvC ⊗Ru)
= μ2(CT ⊗IM)(Rv ⊗Ru)(C ⊗IM)
= μ2CT (Rv ⊗Ru)C
= CT YlmsC.
(9.366)
Then,
MSDnetwork
lms
−MSDnetwork
cta
= 1
N
∞

j=0
Tr

B j
lmsYlmsB∗j
lms

−1
N
∞

j=0
Tr

B j
ctaCT YlmsCB∗j
cta

= 1
N
∞

j=0
Tr

B∗j
lmsB j
lmsYlms

−1
N
∞

j=0
Tr

CB∗j
ctaB j
ctaCT Ylms

= 1
N
∞

j=0
Tr

B∗j
lmsB j
lms −CB∗j
ctaB j
ctaCT 
Ylms

.
(9.367)
Let us examine the difference:
B∗j
lmsB j
lms −CB∗j
ctaB j
ctaCT
=
(I ⊗(I −μRu)2 j) −(C A j ⊗(I −μRu) j)(A jT CT ⊗(I −μRu) j)
(9.317)
=
(I ⊗(I −μRu)2 j) −(C A j A jT CT ⊗(I −μRu)2 j)
=
(I −C A j A jT CT ) ⊗(I −μRu)2 j.
(9.368)
Now, due to the even power, it always holds that (I −μRu)2 j ≥0. Moreover, since A j and C are doubly
stochastic, it follows that C A j A jT CT is also doubly stochastic. Therefore, the matrix (I −C A j A jT CT )
is nonnegative-deﬁnite as well (cf. property (e) of Lemma C.3). It follows that
B∗j
lmsB j
lms −CB∗j
ctaB j
ctaCT ≥0.
(9.369)
But since Ylms ≥0, we conclude from (9.367) that
MSDnetwork
lms
≥MSDnetwork
cta
.
(9.370)

396
CHAPTER 9 Diffusion Adaptation Over Networks
This is because for any two Hermitian nonnegative-deﬁnite matrices A and B of compatible dimen-
sions, it holds that Tr(AB) ≥0; indeed if we factor B = X X∗with X full rank, then Tr(AB) =
Tr(X∗AX) ≥0. We conclude from this analysis that adaptive CTA diffusion performs better than
non-cooperative LMS under uniform data proﬁle conditions and doubly stochastic A. If we refer to the
earlier result (9.343), we conclude that the following relation holds:
MSDnetwork
atc
≤MSDnetwork
cta
≤MSDnetwork
lms
.
(9.371)
Table 9.6 lists the comparison results derived in this section and lists the conditions under which the
conclusions hold.
Table 9.6 Comparison of the MSD Performance of Various Cooperative Strategies
Comparison
Conditions
MSDnetwork
atc
≤MSDnetwork
cta
A doubly stochastic, C right stochastic
MSDnetwork
cta,C̸=I ≤MSDnetwork
cta,C=I
CT Rv C ≤Rv , C doubly stochastic, Ru,k = Ru, μk = μ
MSDnetwork
cta,C=I ≤MSDnetwork
cta,C̸=I
CT Rv C ≥Rv , C doubly stochastic, Ru,k = Ru, μk = μ
MSDnetwork
atc,C̸=I ≤MSDnetwork
atc,C=I
CT Rv C ≤Rv , C doubly stochastic, Ru,k = Ru, μk = μ
MSDnetwork
atc,C=I ≤MSDnetwork
atc,C̸=I
CT Rv C ≥Rv , C doubly stochastic, Ru,k = Ru, μk = μ
MSDnetwork
atc
≤MSDnetwork
cta
≤MSDnetwork
lms
{A, C} doubly stochastic, Ru,k = Ru, μk = μ
3.09.8 Selecting the combination weights
The adaptive diffusion strategy (9.201)–(9.203) employs combination weights {a1,ℓk, a2,ℓk, cℓk} or,
equivalently, combination matrices {A1, A2, C}, where A1 and A2 are left-stochastic matrices and C is
a right-stochastic matrix. There are several ways by which these matrices can be selected. In this section,
we describe constructions that result in left-stochastic or doubly-stochastic combination matrices, A.
When a right-stochastic combination matrix is needed, such as C, then it can be obtained by transposition
of the left-stochastic constructions shown below.

3.09.8 Selecting the Combination Weights
397
3.09.8.1 Constant combination weights
Table 9.7 lists a couple of common choices for selecting constant combination weights for a network
with N nodes. Several of these constructions appeared originally in the literature on graph theory. In
the table, the symbol nk denotes the degree of node k, which refers to the size of its neighborhood.
Table 9.7 Selections for Combination Matrices A = [aℓk]
Entries of Combination Matrix A
Type of A
1. Averaging rule [56]:
aℓk =
,
1/nk ,
if k ̸= ℓare neighbors or k = ℓ
0,
otherwise
left-stochastic
2. Laplacian rule [50,57]:
A = IN −γ L, γ > 0
symmetric and doubly-stochastic
3. Laplacian rule using γ = 1/nmax :
aℓk =
⎧
⎪⎨
⎪⎩
1/nmax,
if k ̸= ℓare neighbors
1 −(nk −1)/nmax,
k = ℓ
0,
otherwise
symmetric and doubly-stochastic
4. Laplacian rule using γ = 1/N(maximum-degree rule [51]):
aℓk =
⎧
⎪⎨
⎪⎩
1/N,
if k ̸= ℓare neighbors
1 −(nk −1)/N,
k = ℓ
0,
otherwise
symmetric and doubly-stochastic
5. Metropolis rule [50,58,59]:
aℓk =
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
1/ max{nk , nℓ},
if k ̸= ℓare neighbors
1 −

m∈Nk \{k}
amk ,
k = ℓ
0,
otherwise
symmetric and doubly-stochastic
6. Relative-degree rule [39]:
aℓk =
⎧
⎪⎪⎨
⎪⎪⎩
nℓ
.⎛
⎝
m∈Nk
nm
⎞
⎠,
if k and ℓare neighbors or k = ℓ
0,
otherwise
left-stochastic

398
CHAPTER 9 Diffusion Adaptation Over Networks
Likewise, the symbol nmax refers to the maximum degree across the network, i.e.,
nmax = max
1≤k≤N{nk}.
(9.372)
The Laplacian rule, which appears in the second line of the table, relies on the use of the Lapla-
cian matrix L of the network and a positive scalar γ . The Laplacian matrix is deﬁned by (9.574) in
Appendix B, namely, it is a symmetric matrix whose entries are constructed as follows [60–62]:
[L]kℓ=
⎧
⎨
⎩
nk −1, if k = ℓ,
−1,
if k ̸= ℓand nodes k and ℓare neighbors,
0,
otherwise.
(9.373)
The Laplacian rule can be reduced to other forms through the selection of the positive parameter γ .
One choice is γ = 1/nmax, while another choice is γ = 1/N and leads to the maximum-degree rule.
Obviously, it always holds that nmax ≤N so that 1/nmax ≥1/N. Therefore, the choice γ = 1/nmax
ends up assigning larger weights to neighbors than the choice γ = 1/N. The averaging rule in the ﬁrst
row of the table is one of the simplest combination rules whereby nodes simply average data from their
neighbors.
In the constructions in Table 9.7, the values of the weights {aℓk} are largely dependent on the degree
of the nodes. In this way, the number of connections that each node has inﬂuences the combination
weights with its neighbors. While such selections may be appropriate in some applications, they can
nevertheless degrade the performance of adaptation over networks [63]. This is because such weighting
schemes ignore the noise proﬁle across the network. And since some nodes can be noisier than others, it
is not sufﬁcient to rely solely on the amount of connectivity that nodes have to determine the combination
weights to their neighbors. It is important to take into account the amount of noise that is present at the
nodes as well. Therefore, designing combination rules that are aware of the variation in noise proﬁle
across the network is an important task. It is also important to devise strategies that are able to adapt
these combination weights in response to variations in network topology and data statistical proﬁle. For
this reason, following [64,65], we describe in the next subsection one adaptive procedure for adjusting
the combination weights. This procedure allows the network to assign more or less relevance to nodes
according to the quality of their data.
3.09.8.2 Optimizing the combination weights
Ideally, we would like to select N × N combination matrices {A1, A2, C} in order to minimize the
network MSD given by (9.302) or (9.306). In [18], the selection of the combination weights was
formulated as the following optimization problem:
min
{A1,A2,C}
MSDnetwork given by (9.302) or (9.306)
over left and right-stochastic matrices with nonnegative entries:
AT
1 1 = 1,
a1,ℓk = 0 if ℓ/∈Nk,
AT
2 1 = 1,
a2,ℓk = 0 if ℓ/∈Nk,
C1 = 1,
cℓk = 0 if ℓ/∈Nk.
(9.374)

3.09.8 Selecting the Combination Weights
399
We can pursue a numerical solution to (9.374) in order to search for optimal combination matrices,
as was done in [18]. Here, however, we are interested in an adaptive solution that becomes part of the
learning process so that the network can adapt the weights on the ﬂy in response to network conditions.
We illustrate an approximate approach from [64,65] that leads to one adaptive solution that performs
reasonably well in practice.
We illustrate the construction by considering the ATC strategy (9.158) without information exchange
where A1 = IN, A2 = A, and C = I. In this case, recursions (9.204)–(9.206) take the form:
ψk,i = wk,i−1 + μku∗
k,i[dk(i) −uk,iwk,i−1],
(9.375)
wk,i =

ℓ∈Nk
aℓkψℓ,i,
(9.376)
and, from (9.306), the corresponding network MSD performance is:
MSDnetwork
atc
= 1
N
∞

j=0
Tr

B j
atcYatcB∗j
atc

,
(9.377)
where
Batc = AT (I −MRu),
(9.378)
Yatc = AT MSMA,
(9.379)
Ru = diag{Ru,1, Ru,2, . . . , Ru,N},
(9.380)
S = diag{σ 2
v,1Ru,1, σ 2
v,2Ru,2, . . . , σ 2
v,N Ru,N},
(9.381)
M = diag{μ1IM, μ2IM, . . . , μN IM},
(9.382)
A = A ⊗IM.
(9.383)
Minimizing the MSD expression (9.377) over left-stochastic matrices A is generally non-trivial. We
pursue an approximate solution.
To begin with, for compactness of notation, let r denote the spectral radius of the N × N block matrix
I −MRu:
r ≜ρ(I −MRu).
(9.384)
We already know, in view of the mean and mean-square stability of the network, that |r| < 1. Now,
consider the series that appears in (9.377) and whose trace we wish to minimize over A. Note that its
block maximum norm can be bounded as follows:
//////
∞

j=0
B j
atcYatcB∗j
atc
//////
b,∞
≤
∞

j=0
///B j
atc
///
b,∞· ∥Yatc∥b,∞·
///B∗j
atc
///
b,∞
(a)
≤N ·
⎛
⎝
∞

j=0
///B j
atc
///
2
b,∞· ∥Yatc∥b,∞
⎞
⎠

400
CHAPTER 9 Diffusion Adaptation Over Networks
≤N ·
⎛
⎝
∞

j=0
∥Batc∥2 j
b,∞· ∥Yatc∥b,∞
⎞
⎠
(b)
≤N ·
⎛
⎝
∞

j=0
r2 j · ∥Yatc∥b,∞
⎞
⎠
=
N
1 −r2 · ∥Yatc∥b,∞,
(9.385)
where for step (b) we use result (9.602) to conclude that
∥Batc∥b,∞
=
///AT (I −MRu)
///
b,∞
≤
///AT ∥b,∞· ∥I −MRu
///
b,∞
=
∥I −MRu∥b,∞
(9.602)
=
r.
(9.386)
To justify step (a), we use result (9.584) to relate the norms of B j
atc and its complex conjugate,

B j
atc
∗
, as
///B∗j
atc
///
b,∞≤N ·
///B j
atc
///
b,∞.
(9.387)
Expression (9.385) then shows that the norm of the series appearing in (9.377) is bounded by a scaled
multiple of the norm of Yatc, and the scaling constant is independent of A. Using property (9.586) we
conclude that there exists a positive constant c, also independent of A, such that
Tr
⎛
⎝
∞

j=0
B j
atcYatcB∗j
atc
⎞
⎠≤c · Tr(Yatc).
(9.388)
Therefore, instead of attempting to minimize the trace of the series, the above result motivates us to
minimize an upper bound to the trace. Thus, we consider the alternative problem of minimizing the ﬁrst
term of the series (9.377), namely,
min
A
Tr(Yatc)
subject to AT 1 = 1, aℓk ≥0,
aℓk = 0 if ℓ/∈Nk.
(9.389)
Using (9.379), the trace of Yatc can be expressed in terms of the combination coefﬁcients as follows:
Tr(Yatc) =
N

k=1
N

ℓ=1
μ2
ℓa2
ℓkσ 2
v,ℓTr(Ru,ℓ),
(9.390)

3.09.8 Selecting the Combination Weights
401
so that problem (9.389) can be decoupled into N separate optimization problems of the form:
min
{aℓk}N
ℓ=1
N

ℓ=1
μ2
ℓa2
ℓkσ 2
v,ℓTr(Ru,ℓ),
k = 1, . . . , N
subject to
aℓk ≥0,
N

ℓ=1
aℓk = 1,
aℓk = 0 if ℓ/∈Nk
.
(9.391)
With each node ℓ, we associate the following nonnegative noise-data-dependent measure:
γ 2
ℓ≜μ2
ℓσ 2
v,ℓTr(Ru,ℓ) .
(9.392)
This measure amounts to scaling the noise variance at node ℓby μ2
ℓand by the power of the regression
data (measured through the trace of its covariance matrix). We shall refer to γ 2
ℓas the noise-data variance
product (or variance product, for simplicity) at node ℓ. Then, the solution of (9.391) is given by:
aℓk =
⎧
⎪⎨
⎪⎩
γ −2
ℓ
$
m∈Nk γ −2
m
, if ℓ∈Nk
0,
otherwise
(relative-variance rule).
(9.393)
We refer to this combination rule as the relative-variance combination rule [64]; it leads to a left-
stochastic matrix A. In this construction, node k combines the intermediate estimates {ψℓ,i} from
its neighbors in (9.376) in proportion to the inverses of their variance products, {γ −2
m }. The result is
physically meaningful. Nodes with smaller variance products will generally be given larger weights.
In comparison, the following relative-degree-variance rule was proposed in [18] (a typo appears in
Table III in [18], where the noise variances appear written in the table instead of their inverses):
aℓk =
⎧
⎪⎨
⎪⎩
nℓσ −2
v,ℓ
$
m∈Nk nmσ −2
v,m
, if ℓ∈Nk
0,
otherwise
(relative degree-variance rule).
(9.394)
This second form also leads to a left-stochastic combination matrix A. However, rule (9.394) does not
take into account the covariance matrices of the regression data across the network. Observe that in the
special case when the step-sizes, regression covariance matrices, and noise variances are uniform across
the network, i.e., μk = μ, Ru,k = Ru and σ 2
v,k = σ 2
v for all k, expression (9.393) reduces to the simple
averaging rule (ﬁrst line of Table 9.7). In contrast, expression (9.394) reduces the relative degree rule
(last line of Table 9.7).
3.09.8.3 Adaptive combination weights
To evaluate the combination weights (9.393), the nodes need to know the variance products, {γ 2
m}, of their
neighbors. According to (9.392), the factors {γ 2
m} are deﬁned in terms of the noise variances, {σ 2
v,m},

402
CHAPTER 9 Diffusion Adaptation Over Networks
and the regression covariance matrices, {Tr(Ru,m)}, and these quantities are not known beforehand.
The nodes only have access to realizations of {dm(i), um,i}. We now describe one procedure that allows
every node k to learn the variance products of its neighbors in an adaptive manner. Note that if a
particular node ℓhappens to belong to two neighborhoods, say, the neighborhood of node k1 and the
neighborhood of node k2, then each of k1 and k2 need to evaluate the variance product, γ 2
ℓ, of node ℓ.
The procedure described below allows each node in the network to estimate the variance products of
its neighbors in a recursive manner.
To motivate the algorithm, we refer to the ATC recursion (9.375), (9.376) and use the data model
(9.208) to write for node ℓ:
ψℓ,i = wℓ,i−1 + μℓu∗
ℓ,i[uℓ,i ˜wℓ,i−1 + vℓ(i)],
(9.395)
so that, in view of our earlier assumptions on the regression data and noise in Section 3.09.6.1, we
obtain in the limit as i →∞:
lim
i→∞E∥ψℓ,i −wℓ,i−1∥2 = μ2
ℓ·

lim
i→∞E∥˜wi−1∥2
E

u∗
ℓ,i∥uℓ,i∥2uℓ,i


+ μ2
ℓ· σ 2
v,ℓ· Tr(Ru,ℓ).
(9.396)
We can evaluate the limit on the right-hand side by using the steady-state result (9.284). Indeed, we
select the vector σ in (9.284) to satisfy
(I −F)σ = vec

E

u∗
ℓ,i∥uℓ,i∥2uℓ,i

.
(9.397)
Then, from (9.284),
lim
i→∞E∥˜wi−1∥2
E

u∗
ℓ,i∥uℓ,i∥2uℓ,i
 = [vec(YT )]T · (I −F)−1 · vec

E

u∗
ℓ,i∥uℓ,i∥2uℓ,i

.
(9.398)
Now recall from expression (9.379) for Y that for the ATC algorithm under consideration we have
Y = AT MSMA,
(9.399)
so that the entries of Y depend on combinations of the squared step-sizes, {μ2
m, m = 1, 2, . . . , N}.
This fact implies that the ﬁrst term on the right-hand side of (9.396) depends on products of the form
{μ2
ℓμ2
m}; these fourth-order factors can be ignored in comparison to the second-order factor μ2
ℓfor small
step-sizes so that
lim
i→∞E∥ψℓ,i −wℓ,i−1∥2 ≈μ2
ℓ· σ 2
v,ℓ· Tr(Ru,ℓ)
= γ 2
ℓ
(9.400)
in terms of the desired variance product, γ 2
ℓ. Using the following instantaneous approximation at node
k (where wℓ,i−1 is replaced by wk,i−1):
E∥ψℓ,i −wℓ,i−1∥2 ≈∥ψℓ,i −wk,i−1∥2.
(9.401)

3.09.9 Diffusion with Noisy Information Exchanges
403
We can now motivate an algorithm that enables node k to estimate the variance product, γ 2
ℓ, of its
neighbor ℓ. Thus, let γ 2
ℓk(i) denote an estimate for γ 2
ℓthat is computed by node k at time i. Then, one
way to evaluate γ 2
ℓk(i) is through the recursion:
γ 2
ℓk(i) = (1 −νk) · γ 2
ℓk(i −1) + νk · ∥ψℓ,i −wk,i−1∥2 ,
(9.402)
where 0 < νk ≪1 is a positive coefﬁcient smaller than one. Note that under expectation, expression
(9.402) becomes
Eγ 2
ℓk(i) = (1 −νk) · Eγ 2
ℓk(i −1) + νkE∥ψℓ,i −wk,i−1∥2,
(9.403)
so that in steady-state, as i →∞,
lim
i→∞Eγ 2
ℓk(i) ≈(1 −νk) · lim
i→∞Eγ 2
ℓk(i −1) + νkγ 2
ℓ.
(9.404)
Hence, we obtain
lim
i→∞Eγ 2
ℓk(i) ≈γ 2
ℓ.
(9.405)
That is, the estimator γ 2
ℓk(i) converges on average close to the desired variance product γ 2
ℓ. In this way,
we can replace the optimal weights (9.393) by the adaptive construction:
aℓk(i) =
⎧
⎪⎨
⎪⎩
γ −2
ℓk (i)
$
m∈Nk
γ −2
mk (i), if ℓ∈Nk
0,
otherwise
.
(9.406)
Equations (9.402) and (9.406) provide one adaptive construction for the combination weights {aℓk}.
3.09.9 Diffusion with noisy information exchanges
The adaptive diffusion strategy (9.201)–(9.203) relies on the fusion of local information collected
from neighborhoods through the use of combination matrices {A1, A2, C}. In the previous section,
we described several constructions for selecting such combination matrices. We also motivated and
developed an adaptive scheme for the ATC mode of operation (9.375) and (9.376) that computes
combination weights in a manner that is aware of the variation of the variance-product proﬁle across
the network. Nevertheless, in addition to the measurement noises {vk(i)} at the individual nodes, we
also need to consider the effect of perturbations that are introduced during the exchange of information
among neighboring nodes. Noise over the communication links can be due to various factors including
thermal noise and imperfect channel information. Studying the degradation in mean-square performance
that results from these noisy exchanges can be pursued by straightforward extension of the mean-square
analysis of Section 3.09.6, as we proceed to illustrate. Subsequently, we shall use the results to show
how the combination weights can also be adapted in the presence of noisy exchange links.

404
CHAPTER 9 Diffusion Adaptation Over Networks
3.09.9.1 Noise sources over exchange links
To model noisy links, we introduce an additive noise component into each of the steps of the diffusion
strategy (9.201)–(9.203) during the operations of information exchange among the nodes. The notation
becomes a bit cumbersome because we need to account for both the source and destination of the
information that is being exchanged. For example, the same signal dℓ(i) that is generated by node ℓ
will be broadcast to all the neighbors of node ℓ. When this is done, a different noise will interfere with
the exchange of dℓ(i) over each of the edges that link node ℓto its neighbors. Thus, we will need to
use a notation of the form dℓk(i), with two subscripts ℓand k, to indicate that this is the noisy version
of dℓ(i) that is received by node k from node ℓ. The subscript ℓk indicates that ℓis the source and k is
the sink, i.e., information is moving from ℓto k. For the reverse situation where information ﬂows from
node k to ℓ, we would use instead the subscript kℓ.
With this notation in mind, we model the noisy data received by node k from its neighbor ℓas
follows:
wℓk,i−1 = wℓ,i−1 + v(w)
ℓk,i−1,
(9.407)
ψℓk,i = ψℓ,i + v(ψ)
ℓk,i,
(9.408)
uℓk,i = uℓ,i + v(u)
ℓk,i,
(9.409)
dℓk(i) = dℓ(i) + v(d)
ℓk (i),
(9.410)
where v(w)
ℓk,i−1(M × 1), v(ψ)
ℓk,i(M × 1), and v(u)
ℓk,i(1 × M) are vector noise signals, and v(d)
ℓk (i) is a scalar
noise signal. These are the noise signals that perturb exchanges over the edge linking source ℓto sink
k (i.e., for data sent from node ℓto node k). The superscripts {(w), (ψ), (u), (d)} in each case refer
to the variable that these noises perturb. Figure 9.14 illustrates the various noise sources that perturb
the exchange of information from node ℓto node k. The ﬁgure also shows the measurement noises
{vℓ(i), vk(i)} that exist locally at the nodes in view of the data model (9.208).
We assume that the following noise signals, which inﬂuence the data received by node k,

vk(i), v(d)
ℓk (i), v(w)
ℓk,i−1, v(ψ)
ℓk,i, v(u)
ℓk,i

(9.411)
are temporally white and spatially independent random processes with zero mean and variances or
covariances given by

σ 2
v,k, σ 2
v,ℓk, R(w)
v,ℓk, R(ψ)
v,ℓk, R(u)
v,ℓk

.
(9.412)
Obviously, the quantities

σ 2
v,ℓk, R(w)
v,ℓk, R(ψ)
v,ℓk, R(u)
v,ℓk

(9.413)
are all zero if ℓ/∈Nk or when ℓ= k. We further assume that the noise processes (9.411) are independent
of each other and of the regression data um, j for all k, ℓ, m and i, j.

3.09.9 Diffusion with Noisy Information Exchanges
405
FIGURE 9.14
Additive noise sources perturb the exchange of information from node ℓto node k. The subscript ℓk in this
illustration indicates that ℓis the source node and k is the sink node so that information is ﬂowing from ℓto k.
3.09.9.2 Error recursion
Using the perturbed data (9.407)–(9.410), the adaptive diffusion strategy (9.201)–(9.203) becomes
φk,i−1 =

ℓ∈Nk
a1,ℓkwℓk,i−1,
(9.414)
ψk,i = φk,i−1 + μk

ℓ∈Nk
cℓku∗
ℓk,i[dℓk(i) −uℓk,iφk,i−1],
(9.415)
wk,i =

ℓ∈Nk
a2,ℓkψℓk,i.
(9.416)
Observe that the perturbed quantities {wℓk,i−1, uℓk,i, dℓk(i), ψℓk,i}, with subscripts ℓk, appear in
(9.414)–(9.416) in place of the original quantities {wℓ,i−1, uℓ,i, dℓ(i), ψℓ,i} that appear in
(9.201)–(9.203). This is because these quantities are now subject to exchange noises. As before, we are
still interested in examining the evolution of the weight-error vectors:
˜wk,i ≜wo −wk,i,
k = 1, 2, . . . , N.
(9.417)
For this purpose, we again introduce the following N × 1 block vector, whose entries are of size M × 1
each:
˜wi ≜
⎡
⎢⎢⎢⎣
˜w1,i
˜w2,i
...
˜wN,i
⎤
⎥⎥⎥⎦
(9.418)

406
CHAPTER 9 Diffusion Adaptation Over Networks
and proceed to determine a recursion for its evolution over time. The arguments are largely similar to
what we already did before in Section 3.09.6.3 and, therefore, we shall emphasize the differences that
arise. The main deviation is that we now need to account for the presence of the new noise signals;
they will contribute additional terms to the recursion for ˜wi—see (9.442) further ahead. We may note
that some studies on the effect of imperfect data exchanges on the performance of adaptive diffusion
algorithms are considered in [66–68]. These earlier investigations were limited to particular cases in
which only noise in the exchange of wℓ,i−1 was considered (as in (9.407)), in addition to setting C = I
(in which case there is no exchange of {dℓ(i), uℓ,i}), and by focusing on the CTA case for which A2 = I.
Here, we consider instead the general case that accounts for the additional sources of imperfections
shown in (9.408)–(9.410), in addition to the general diffusion strategy (9.201)–(9.203) with combination
matrices {A1, A2, C}.
To begin with, we introduce the aggregate M × 1 zero-mean noise signals:
v(w)
k,i−1 ≜

ℓ∈Nk
a1,ℓkv(w)
ℓk,i−1,
v(ψ)
k,i ≜

ℓ∈Nk
a2,ℓkv(ψ)
ℓk,i.
(9.419)
These noises represent the aggregate effect on node k of all exchange noises from the neighbors of node
k while exchanging the estimates {wℓ,i−1, ψℓ,i} during the two combination steps (9.201) and (9.203).
The M × M covariance matrices of these noises are given by
R(w)
v,k ≜$
ℓ∈Nk
a2
1,ℓk R(w)
v,ℓk,
R(ψ)
v,k ≜$
ℓ∈Nk
a2
2,ℓk R(ψ)
v,ℓk .
(9.420)
These expressions aggregate the exchange noise covariances in the neighborhood of node k; the
covariances are scaled by the squared coefﬁcients {a2
1,ℓk, a2
2,ℓk}. We collect these noise signals, and
their covariances, from across the network into N ×1 block vectors and N × N block diagonal matrices
as follows:
v(w)
i−1 ≜col

v(w)
1,i−1, v(w)
2,i−1, . . . , v(w)
N,i−1

,
(9.421)
v(ψ)
i
≜col

v(ψ)
1,i , v(ψ)
2,i , . . . , v(ψ)
N,i

,
(9.422)
R(w)
v
≜diag

R(w)
v,1 , R(w)
v,2 , . . . , R(w)
v,N

,
(9.423)
R(ψ)
v
≜diag

R(ψ)
v,1 , R(ψ)
v,2 , . . . , R(ψ)
v,N

.
(9.424)
We further introduce the following scalar zero-mean noise signal:
vℓk(i) ≜vℓ(i) + v(d)
ℓk (i) −v(u)
ℓk,iwo,
(9.425)
whose variance is
σ 2
ℓk = σ 2
v,ℓ+ σ 2
v,ℓk + wo∗R(u)
v,ℓkwo .
(9.426)
In the absence of exchange noises for the data {dℓ(i), uℓ,i}, the signal vℓk(i) would coincide with the
measurement noise vℓ(i). Expression (9.425) is simply a reﬂection of the aggregate effect of the noises

3.09.9 Diffusion with Noisy Information Exchanges
407
in exchanging {dℓ(i), uℓ,i} on node k. Indeed, starting from the data model (9.208) and using (9.409)
and (9.410), we can easily verify that the noisy data {dℓk(i), uℓk,i} are related via:
dℓk(i) = uℓk,iwo + vℓk(i).
(9.427)
Wealsodeﬁne(comparewith(9.234)and(9.235)andnotethatwearenowusingtheperturbedregression
vectors {uℓk,i}):
R′
k,i ≜

ℓ∈Nk
cℓku∗
ℓk,iuℓk,i,
(9.428)
R′
i ≜diag

R′
1,i, R′
2,i, . . . , R′
N,i

.
(9.429)
It holds that
ER′
k,i = R′
k ,
(9.430)
where
R′
k ≜

ℓ∈Nk
cℓk

Ru,ℓ+ R(u)
v,ℓk

.
(9.431)
When there is no noise during the exchange of the regression data, i.e., when R(u)
v,ℓk = 0, the expressions
for {R′
k,i, R′
i, R′
k} reduce to expressions (9.234), (9.235), and (9.182) for {Rk,i, Ri, Rk}.
Likewise, we introduce (compare with (9.239)):
zk,i ≜

ℓ∈Nk
cℓku∗
ℓk,ivℓk(i),
(9.432)
zi ≜col{z1,i, z2,i, . . . , zN,i}.
(9.433)
Compared with the earlier deﬁnition for si in (9.239) when there is no noise over the exchange links,
we see that we now need to account for the various noisy versions of the same regression vector uℓ,i
and the same signal dℓ(i). For instance, the vectors uℓk,i and uℓm,i would denote two noisy versions
received by nodes k and m for the same regression vector uℓ,i transmitted from node ℓ. Likewise, the
scalars dℓk(i) and dℓm(i) would denote two noisy versions received by nodes k and m for the same
scalar dℓ(i) transmitted from node ℓ. As a result, the quantity zi is not zero mean any longer (in contrast
to si, which had zero mean). Indeed, note that
Ezk,i =

ℓ∈Nk
cℓkEu∗
ℓk,ivℓk(i)
=

ℓ∈Nk
cℓkE

uℓ,i + v(u)
ℓk,i
∗
·

vℓ(i) + v(d)
ℓk (i) −v(u)
ℓk,iwo
= −
⎛
⎝
ℓ∈Nk
cℓk R(u)
v,ℓk
⎞
⎠wo.
(9.434)

408
CHAPTER 9 Diffusion Adaptation Over Networks
It follows that
Ezi = −
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣

ℓ∈N1
cℓ1R(u)
v,ℓ1

ℓ∈N2
cℓ2R(u)
v,ℓ2
...

ℓ∈NN
cℓN R(u)
v,ℓN
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
wo.
(9.435)
Although we can continue our analysis by studying this general case in which the vectors zi do not have
zero-mean (see [65,69]), we shall nevertheless limit our discussion in the sequel to the case in which
there is no noise during the exchange of the regression data, i.e., we henceforth assume that:
v(u)
ℓk,i = 0,
R(u)
v,ℓk = 0,
uℓk,i = uℓ,i
(assumption from this point onwards).
(9.436)
We maintain all other noise sources, which occur during the exchange of the weight estimates
{wℓ,i−1, ψℓ,i} and the data {dℓ(i)}. Under condition (9.436), we obtain
Ezi = 0,
(9.437)
σ 2
ℓk = σ 2
v,ℓ+ σ 2
v,ℓk,
(9.438)
R′
k =

ℓ∈Nk
cℓk Ru,ℓ
(9.182)
=
Rk.
(9.439)
Then, the covariance matrix of each term zk,i is given by
Rz,k ≜

ℓ∈Nk
c2
ℓkσ 2
ℓk Ru,ℓ
(9.440)
and the covariance matrix of zi is N × N block diagonal with blocks of size M × M:
Z ≜Eziz∗
i = diag{Rz,1, Rz,2, . . . , Rz,N} .
(9.441)
Now repeating the argument that led to (9.246) we arrive at the following recursion for the weight-error
vector:
˜wi = AT
2

IN M −MR′
i

AT
1 ˜wi−1 −AT
2 Mzi −AT
2

IN M −MR′
i

v(w)
i−1 −v(ψ)
i
(noisy links).
(9.442)
For comparison purposes, we repeat recursion (9.246) here (recall that this recursion corresponds to the
case when the exchanges over the links are not subject to noise):
˜wi = AT
2 (IN M −MRi)AT
1 ˜wi−1 −AT
2 MCT si
(perfect links).
(9.443)
Comparing (9.442) and (9.443) we ﬁnd that:

3.09.9 Diffusion with Noisy Information Exchanges
409
1. The covariance matrix Ri in (9.443) is replaced by R′
i. Recall from (9.429) that R′
i contains the
inﬂuence of the noises that arise during the exchange of the regression data, i.e., the {R(u)
v,ℓk}. But
since we are now assuming that R(u)
v,ℓk = 0, then R′
i = Ri.
2. The term CT si in (9.443) is replaced by zi. Recall from (9.432) that zi contains the inﬂuence of
the noises that arise during the exchange of the measurement data and the regression data, i.e., the
{σ 2
v,ℓk, R(u)
v,ℓk}.
3. Two new driving terms appear involving v(w)
i−1 and v(ψ)
i
. These terms reﬂect the inﬂuence of the
noises during the exchange of the weight estimates {wℓ,i−1, ψℓ,i}.
4. Observe further that:
a. The term involving v(w)
i−1 accounts for noise introduced at the information-exchange step (9.414)
before adaptation.
b. The term involving zi accounts for noise introduced during the adaptation step (9.415).
c. The term involving v(ψ)
i
accounts for noise introduced at the information-exchange step (9.416)
after adaptation.
Therefore, since we are not considering noise during the exchange of the regression data, the weight-
error recursion (9.442) simpliﬁes to:
˜wi = AT
2

IN M −MRi

AT
1 ˜wi−1 −AT
2 Mzi −AT
2

IN M −MRi

v(w)
i−1 −v(ψ)
i
(noisy links),
(9.444)
where we used the fact that R′
i = Ri under these conditions.
3.09.9.3 Convergence in the mean
Taking expectations of both sides of (9.444) we ﬁnd that the mean error vector evolves according to the
following recursion:
E ˜wi = AT
2 (IN M −MR)AT
1 · E ˜wi−1, i ≥0
(9.445)
with R deﬁned by (9.181). This is the same recursion encountered earlier in (9.248) during perfect
data exchanges. Note that had we considered noises during the exchange of the regression data, then
the vector zi in (9.444) would not be zero mean and the matrix R′
i will have to be used instead of Ri.
In that case, the recursion for E ˜wi will be different from (9.445); i.e., the presence of noise during the
exchange of regression data alters the dynamics of the mean error vector in an important way—see
[65,69] for details on how to extend the arguments to this general case with a driving non-zero bias
term. We can now extend Theorem 9.6.1 to the current scenario.
Theorem 9.9.1 (Convergence in the Mean).
Consider the problem of optimizing the global cost
(9.92) with the individual cost functions given by (9.93). Pick a right stochastic matrix C and left
stochastic matrices A1 and A2 satisfying (9.166). Assume each node in the network runs the per-
turbed adaptive diffusion algorithm (9.414)–(9.416). Assume further that the exchange of the variables
{wℓ,i−1, ψℓ,i, dℓ(i)} is subject to additive noises as in (9.407), (9.408), and (9.410). We assume that the

410
CHAPTER 9 Diffusion Adaptation Over Networks
regressors are exchanged unperturbed. Then, all estimators {wk,i} across the network will still converge
in the mean to the optimal solution wo if the step-size parameters {μk} satisfy
μk <
2
λmax(Rk) ,
(9.446)
where the neighborhood covariance matrix Rk is deﬁned by (9.182). That is, Ewk,i →wo as
i →∞.
□
3.09.9.4 Mean-square convergence
Recall from (9.264) that we introduced the matrix:
B ≜AT
2 (IN M −MR)AT
1 .
(9.447)
We further introduce the N × N block matrix with blocks of size M × M each:
H ≜AT
2 (IN M −MR).
(9.448)
Then, starting from (9.444) and repeating the argument that led to (9.279) we can establish the validity
of the following variance relation:
E∥˜wi∥2
σ = E∥˜wi−1∥2
Fσ +

vec(AT
2 MZT MA2) + vec

(HR(w)T
v
H∗)T 
+ vec

R(ψ)T
v
T
σ
(9.449)
for an arbitrary nonnegative-deﬁnite weighting matrix  with σ = vec(), and where F is the
same matrix deﬁned earlier either by (9.276) or (9.277). We can therefore extend the statement of
Theorem 9.6.7 to the present scenario.
Theorem 9.9.2 (Mean-Square Stability).
Consider the same setting of Theorem 9.9.1. Assume
sufﬁciently small step-sizes to justify ignoring terms that depend on higher powers of the step-sizes.
The perturbed adaptive diffusion algorithm (9.414)–(9.416) is mean-square stable if, and only if, the
matrix F deﬁned by (9.276), or its approximation (9.277), is stable (i.e., all its eigenvalues are strictly
inside the unit disc). This condition is satisﬁed by sufﬁciently small step-sizes {μk} that also satisfy:
μk <
2
λmax(Rk) ,
(9.450)
where the neighborhood covariance matrix Rk is deﬁned by (9.182). Moreover, the convergence rate
of the algorithm is determined by [ρ(B)]2.
□
We conclude from the previous two theorems that the conditions for the mean and mean-square con-
vergence of the adaptive diffusion strategy are not affected by the presence of noises over the exchange
links (under the assumption that the regression data are exchanged without perturbation; otherwise,

3.09.9 Diffusion with Noisy Information Exchanges
411
the convergence conditions would be affected). The mean-square performance, on the other hand, is
affected as follows. Introduce the N × N block matrix:
Yimperfect ≜AT
2 MZMA2 + HR(w)
v
H∗+ R(ψ)
v
(imperfect exchanges),
(9.451)
which should be compared with the corresponding quantity deﬁned by (9.280) for the perfect exchanges
case, namely,
Yperfect = AT
2 MCT SCMA2
(perfect exchanges).
(9.452)
When perfect exchanges occur, the matrix Z reduces to CT SC. We can relate Yimperfect and Yperfect as
follows. Let
R(du) ≜diag
⎧
⎨
⎩

ℓ∈N1
c2
ℓ1σ 2
v,ℓ1Ru,ℓ,

ℓ∈N2
c2
ℓ2σ 2
v,ℓ2Ru,ℓ, . . .

ℓ∈NN
c2
ℓNσ 2
v,ℓN Ru,ℓ
⎫
⎬
⎭.
(9.453)
Then, using (9.438) and (9.441), it is straightforward to verify that
Z = CT SC + R(du)
(9.454)
and it follows that:
Yimperfect = Yperfect + AT
2 MR(du)MA2 + HR(w)
v
H∗+ R(ψ)
v
≜Yperfect + Y.
(9.455)
Expression (9.455) reﬂects the inﬂuence of the noises {R(w)
v
, R(ψ)
v
, σ 2
v,ℓk}. Substituting the deﬁnition
(9.451) into (9.449), and taking the limit as i →∞, we obtain from the latter expression that:
lim
i→∞E∥˜wi∥2
(I−F)σ =

vec(YT
imperfect)
T
σ ,
(9.456)
which has the same form as (9.284); therefore, we can proceed analogously to obtain:
MSDnetwork
imperfect = 1
N ·

vec(YT
imperfect)
T
· (I −F)−1 · vec(IN M)
(9.457)
and
EMSEnetwork
imperfect = 1
N ·

vec(YT
imperfect)
T
· (I −F)−1 · vec(Ru) .
(9.458)
Using (9.455), we see that the network MSD and EMSE deteriorate as follows:
MSDnetwork
imperfect = MSDnetwork
perfect + 1
N ·

vec(YT )
T
· (I −F)−1 · vec(IN M),
(9.459)
EMSEnetwork
imperfect = EMSEnetwork
perfect + 1
N ·

vec(YT )
T
· (I −F)−1 · vec(Ru).
(9.460)

412
CHAPTER 9 Diffusion Adaptation Over Networks
3.09.9.5 Adaptive combination weights
We can repeat the discussion from Sections 3.09.8.2 and 3.09.8.3 to devise one adaptive scheme to adjust
the combination coefﬁcients in the noisy exchange case. We illustrate the construction by considering
the ATC strategy corresponding to A1 = IN, A2 = A, C = IN, so that only weight estimates are
exchanged and the update recursions are of the form:
ψk,i = wk,i−1 + μku∗
k,i[dk(i) −uk,iwk,i−1],
(9.461)
wk,i =

ℓ∈Nk
aℓkψℓk,i,
(9.462)
where from (9.408):
ψℓk,i = ψℓ,i + v(ψ)
ℓk,i.
(9.463)
In this case, the network MSD performance (9.457) becomes
MSDnetwork
atc,C=I,imperfect = 1
N
∞

j=0
Tr

B j
atc,C=I Yatc,imperfectB∗j
atc,C=I

,
(9.464)
where, since now Z = S and R(w)
v
= 0, we have
Batc,C=I = AT (I −MRu),
(9.465)
Yatc,imperfect = AT MSMA + R(ψ)
v
,
(9.466)
R(ψ)
v
= diag

R(ψ)
v,1 , R(ψ)
v,2 , . . . , R(ψ)
v,N

,
(9.467)
R(ψ)
v,k =

ℓ∈Nk
a2
ℓk R(ψ)
v,ℓk,
(9.468)
Ru = diag

Ru,1, Ru,2, . . . , Ru,N

,
(9.469)
S = diag

σ 2
v,1Ru,1, σ 2
v,2Ru,2, . . . , σ 2
v,N Ru,N

,
(9.470)
M = diag{μ1IM, μ2IM, . . . , μN IM},
(9.471)
A = A ⊗IM.
(9.472)
To proceed, as was the case with (9.389), we consider the following simpliﬁed optimization problem:
min
A
Tr(Yatc,imperfect)
subject to AT 1 = 1, aℓk ≥0, aℓk = 0 if ℓ/∈Nk.
(9.473)
Using (9.466), the trace of Yatc,imperfect can be expressed in terms of the combination coefﬁcients as
follows:
Tr(Yatc,imperfect) =
N

k=1
N

ℓ=1
a2
ℓk

μ2
ℓσ 2
v,ℓTr(Ru,ℓ) + Tr

R(ψ)
v,ℓk

,
(9.474)

3.09.9 Diffusion with Noisy Information Exchanges
413
so that problem (9.473) can be decoupled into N separate optimization problems of the form:
min
{aℓk}N
ℓ=1
N

ℓ=1
a2
ℓk

μ2
ℓσ 2
v,ℓTr(Ru,ℓ) + Tr

R(ψ)
v,ℓk

,
k = 1, . . . , N
subject to
aℓk ≥0,
N

ℓ=1
aℓk = 1,
aℓk = 0 if ℓ/∈Nk
.
(9.475)
With each node ℓ, we associate the following nonnegative variance products:
γ 2
ℓk ≜μ2
ℓ· σ 2
v,ℓ· Tr(Ru,ℓ) + Tr

R(ψ)
v,ℓk

,
k ∈Nℓ.
(9.476)
This measure now incorporates information about the exchange noise covariances {R(ψ)
v,ℓk}. Then, the
solution of (9.475) is given by:
aℓk =
⎧
⎪⎨
⎪⎩
γ −2
ℓk
$
m∈Nk γ −2
mk
, if ℓ∈Nk
0,
otherwise
(relative-variance rule).
(9.477)
We continue to refer to this combination rule as the relative-variance combination rule [64]; it leads
to a left-stochastic matrix A. To evaluate the combination weights (9.477), the nodes need to know the
variance products, {γ 2
mk}, of their neighbors. As before, we can motivate one adaptive construction as
follows.
We refer to the ATC recursion (9.461)–(9.463) and use the data model (9.208) to write for node ℓ:
ψℓk,i = wℓ,i−1 + μℓu∗
ℓ,i[uℓ,i ˜wℓ,i−1 + vℓ(i)] + v(ψ)
ℓk,i,
(9.478)
so that, in view of our earlier assumptions on the regression data and noise in Sections 3.09.6.1 and
3.09.9.1, we obtain in the limit as i →∞:
lim
i→∞E∥ψℓk,i −wℓ,i−1∥2 = μ2
ℓ·

lim
i→∞E∥˜wi−1∥2
E(u∗
ℓ,i∥uℓ,i∥2uℓ,i)

+ μ2
ℓ· σ 2
v,ℓ· Tr(Ru,ℓ) + Tr

R(ψ)
v,ℓk

.
(9.479)
In a manner similar to what was done before for (9.396), we can evaluate the limit on the right-hand
side by using the corresponding steady-state result (9.456). We select the vector σ in (9.456) to satisfy:
(I −F)σ = vec

E

u∗
ℓ,i∥uℓ,i∥2uℓ,i

.
(9.480)
Then, from (9.456),
lim
i→∞E∥˜wi−1∥2
E(u∗
ℓ,i∥uℓ,i∥2uℓ,i) =

vec

YT
atc,imperfect
T
· (I −F)−1 · vec

E

u∗
ℓ,i∥uℓ,i∥2uℓ,i

.
(9.481)

414
CHAPTER 9 Diffusion Adaptation Over Networks
Now recall from expression (9.466) that the entries of Yatc,imperfect depend on combinations of the
squared step-sizes, {μ2
m, m = 1, 2, . . . , N}, and on terms involving {Tr(R(ψ)
v,m)}. This fact implies that
the ﬁrst term on the right-hand side of (9.479) depends on products of the form {μ2
ℓμ2
m}; these fourth-
order factors can be ignored in comparison to the second-order factor μ2
ℓfor small step-sizes. Moreover,
the same ﬁrst term on the right-hand side of (9.479) depends on products of the form {μ2
ℓTr(R(ψ)
v,m)},
which can be ignored in comparison to the last term, Tr(R(ψ)
v,ℓk), in (9.479), which does not appear
multiplied by a squared step-size. Therefore, we can approximate:
lim
i→∞E∥ψℓk,i −wℓ,i−1∥2 ≈μ2
ℓ· σ 2
v,ℓ· Tr(Ru,ℓ) + Tr

R(ψ)
v,ℓk

= γ 2
ℓk
(9.482)
in terms of the desired variance product, γ 2
ℓk. Using the following instantaneous approximation at node
k (where wℓ,i−1 is replaced by wk,i−1):
E∥ψℓk,i −wℓ,i−1∥2 ≈∥ψℓk,i −wk,i−1∥2,
(9.483)
we can motivate an algorithm that enables node k to estimate the variance products γ 2
ℓk. Thus, let ˆγ 2
ℓk(i)
denote an estimate for γ 2
ℓk that is computed by node k at time i. Then, one way to evaluate ˆγ 2
ℓk(i) is
through the recursion:
ˆγ 2
ℓk(i) = (1 −νk) · ˆγ 2
ℓk(i −1) + νk · ∥ψℓk,i −wk,i−1∥2 ,
(9.484)
where νk is a positive coefﬁcient smaller than one. Indeed, it can be veriﬁed that
lim
i→∞E ˆγ 2
ℓk(i) ≈γ 2
ℓk,
(9.485)
so that the estimator ˆγ 2
ℓk(i) converges on average close to the desired variance product γ 2
ℓk. In this way,
we can replace the weights (9.477) by the adaptive construction:
aℓk(i) =
⎧
⎪⎨
⎪⎩
ˆγ −2
ℓk (i)
$
m∈Nk ˆγ −2
mk (i)
, if ℓ∈Nk
0,
otherwise
.
(9.486)
Equations (9.484) and (9.486) provide one adaptive construction for the combination weights {aℓk}.
3.09.10 Extensions and further considerations
Severalextensionsandvariationsofdiffusionstrategiesarepossible.Amongthosevariationswemention
strategies that endow nodes with temporal processing abilities, in addition to their spatial cooperation
abilities. We can also apply diffusion strategies to solve recursive least-squares and state-space estima-
tion problems in a distributed manner. In this section, we highlight select contributions in these and
related areas.

3.09.10 Extensions and Further Considerations
415
3.09.10.1 Adaptive diffusion strategies with smoothing mechanisms
In the ATC and CTA adaptive diffusion strategies (9.153) and (9.154), each node in the network shares
information locally with its neighbors through a process of spatial cooperation or combination. In
this section, we describe brieﬂy an extension that adds a temporal dimension to the processing at the
nodes. For example, in the ATC implementation (9.153), rather than have each node k rely solely
on current data, {dℓ(i), uℓ,i, ℓ∈Nk}, and on current weight estimates received from the neighbors,
{ψℓ,i, ℓ∈Nk}, node k can be allowed to store and process present and past weight estimates, say, P of
them as in {ψℓ, j, j = i, i −1, . . . , i −P + 1}. In this way, previous weight estimates can be smoothed
and used more effectively to help enhance the mean-square-deviation performance especially in the
presence of noise over the communication links.
To motivate diffusion strategies with smoothing mechanisms, we continue to assume that the random
data {dk(i), uk,i} satisfy the modeling assumptions of Section 3.09.6.1. The global cost (9.92) continues
to be the same but the individual cost functions (9.93) are now replaced by
Jk(w) =
P−1

j=0
qkjE|dk(i −j) −uk,i−jw|2
(9.487)
so that
J glob(w) =
N

k=1
⎛
⎝
P−1

j=0
qkjE|dk(i −j) −uk,i−jw|2
⎞
⎠,
(9.488)
where each coefﬁcient qkj is a nonnegative scalar representing the weight that node k assigns to data
from time instant i −j. The coefﬁcients {qkj} are assumed to satisfy the normalization condition:
qko > 0,
P−1

j=0
qkj = 1,
k = 1, 2, . . . , N.
(9.489)
When the random processes dk(i) and uk,i are jointly wide-sense stationary, as was assumed in
Section 3.09.6.1, the optimal solution wo that minimizes (9.488) is still given by the same normal
equations (9.40). We can extend the arguments of Sections 3.09.3 and 3.09.4 to (9.488) and arrive at
the following version of a diffusion strategy incorporating temporal processing (or smoothing) of the
intermediate weight estimates [70,71]:
φk,i = wk,i−1 + μk

ℓ∈Nk
cℓk qℓo u∗
ℓ,i[dℓ(i) −uℓ,iwk,i−1] (adaptation),
(9.490)
ψk,i =
P−1

j=0
fkjφk,i−j
(temporal processing or smoothing),
(9.491)
wk,i =

ℓ∈Nk
aℓkψℓ,i
(spatial processing),
(9.492)

416
CHAPTER 9 Diffusion Adaptation Over Networks
where the nonnegative coefﬁcients {cℓk, aℓk, fkj, qlo} satisfy:
for k = 1, 2, . . . , N:
cℓk ≥0,
N

k=1
cℓk = 1,
cℓk = 0 if ℓ/∈Nk,
(9.493)
aℓk ≥0,
N

ℓ=1
aℓk = 1,
aℓk = 0 if ℓ/∈Nk,
(9.494)
fkj ≥0,
P−1

j=0
fkj = 1,
(9.495)
0 < qℓo≤1.
(9.496)
Since only the coefﬁcients {qℓo} are needed, we alternatively denote them by the simpler notation {qℓ}
in the listing in Table 9.8. These are simply chosen as nonnegative coefﬁcients:
0 < qℓ≤1,
ℓ= 1, 2, . . . , N.
(9.497)
Note that algorithm (9.490)–(9.492) involves three steps: (a) an adaptation step (A) represented by
(9.490); (b) a temporal ﬁltering or smoothing step (T) represented by (9.491), and a spatial cooperation
step (S) represented by (9.492). These steps are illustrated in Figure 9.15. We use the letters (A,T,S)
to label these steps; and we use the sequence of letters (A,T,S) to designate the order of the steps.
According to this convention, algorithm (9.490)–(9.492) is referred to as the ATS diffusion strategy
since adaptation is followed by temporal processing, which is followed by spatial processing. In total,
we can obtain six different combinations of diffusion algorithms by changing the order by which the
temporal and spatial combination steps are performed in relation to the adaptation step. The resulting
variations are summarized in Table 9.8. When we use only the most recent weight vector in the temporal
ﬁltering step (i.e., set ψk,i = φk,i), which corresponds to the case P = 1, the algorithms of Table 9.8
reduce to the ATC and CTA diffusion algorithms (9.153) and (9.154). Speciﬁcally, the variants TSA,
STA, and SAT (where spatial processing S precedes adaptation A) reduce to CTA, while the variants
TAS, ATS, and AST (where adaptation A precedes spatial processing S) reduce to ATC.
The mean-square performance analysis of the smoothed diffusion strategies can be pursued by
extending the arguments of Section 3.09.6. This step is carried out in [70,71] for doubly stochastic
combination matrices A when the ﬁltering coefﬁcients { fkj} do not change with k. For instance, it is
shown in [71] that whether temporal processing is performed before or after adaptation, the strategy that
performs adaptation before spatial cooperation is always better. Speciﬁcally, the six diffusion variants
can be divided into two groups with the respective network MSDs satisfying the following relations:
Group #1 :
MSDnetwork
TSA
= MSDnetwork
STA
≥MSDnetwork
TAS
,
(9.498)
Group #2 :
MSDnetwork
SAT
≥MSDnetwork
ATS
= MSDnetwork
AST
.
(9.499)
Note that within groups 1 and 2, the order of the A and T operations is the same: in group 1, T precedes
A and in group 2, A precedes T. Moreover, within each group, the order of the A and S operations
determines performance; the strategy that performs A before S is better. Note further that when P = 1,

3.09.10 Extensions and Further Considerations
417
Table 9.8 Six Diffusion Strategies with Temporal Smoothing Steps
TSA Diffusion:
TAS Diffusion:
φk,i−1 =
P−1
$
j=0
fkj wk,i−j−1
φk,i−1 =
P−1
$
j=0
fkj wk,i−j−1
ψk,i−1 =
$
ℓ∈Nk
aℓk φℓ,i−1
ψk,i = φk,i−1 + μk
$
ℓ∈Nk
qℓcℓk u∗
ℓ,i

dℓ(i) −uℓ,i φk,i−1

wk,i = ψk,i−1 + μk
$
ℓ∈Nk
qℓcℓk u∗
ℓ,i

dℓ(i) −uℓ,i ψk,i−1

wk,i =
$
ℓ∈Nk
aℓ,k ψℓ,i
STA Diffusion:
ATS Diffusion:
φk,i−1 =
$
ℓ∈Nk
aℓk wℓ,i−1
φk,i = wk,i−1 + μk
$
ℓ∈Nk
qℓcℓk u∗
ℓ,i

dℓ(i) −uℓ,i wk,i−1

ψk,i−1 =
P−1
$
j=0
fkj φk,i−j−1
ψk,i =
P−1
$
j=0
fkj φk,i−j
wk,i = ψk,i−1 + μk
$
ℓ∈Nk
qℓcℓk u∗
ℓ,i

dℓ(i) −uℓ,i ψk,i−1

wk,i =
$
ℓ∈Nk
aℓk ψℓ,i
SAT Diffusion:
AST Diffusion:
φk,i−1 =
$
ℓ∈Nk
aℓk wℓ,i−1
φk,i = wk,i−1 + μk
$
ℓ∈Nk
qℓcℓk u∗
ℓ,i

dℓ(i) −uℓ,i wk,i−1

ψk,i = φk,i−1 + μk
$
ℓ∈Nk
qℓcℓk u∗
ℓ,i

dℓ(i) −uℓ,i φk,i−1

ψk,i =
$
ℓ∈Nk
aℓk φℓ,i
wk,i =
P−1
$
j=0
fkj ψk,i−j
wk,i =
P−1
$
j=0
fkj ψk,i−j

418
CHAPTER 9 Diffusion Adaptation Over Networks
Adaptation (A)
adaptation 
filtering
aggregation
Spatial Processing (S)
Temporal Processing (T)
FIGURE 9.15
Illustration of the three steps involved in an ATS diffusion strategy: adaptation, followed by temporal pro-
cessing or smoothing, followed by spatial processing.
so that temporal processing is not performed, then TAS reduces to ATC and TSA reduces to CTA. This
conclusion is consistent with our earlier result (9.343) that ATC outperforms CTA.
In related work, reference [72] started from the CTA algorithm (9.159) without information exchange
and added a useful projection step to it between the combination step and the adaptation step; i.e., the
work considered an algorithm with an STA structure (with spatial combination occurring ﬁrst, followed
by a projection step, and then adaptation). The projection step uses the current weight estimate, φk,i,
at node k and projects it onto hyperslabs deﬁned by the current and past raw data. Speciﬁcally, the
algorithm from [72] has the following form:
φk,i−1 =

ℓ∈Nk
aℓk wℓ,i−1,
(9.500)
ψk,i−1 = P′
k,i[φk,i−1],
(9.501)
wk,i = ψk,i−1 −μk
⎧
⎨
⎩ψk,i−1 −
P−1

j=0
fkj · Pk,i−j[φk,i−1]
⎫
⎬
⎭,
(9.502)
where the notation ψ = Pk,i[φ] refers to the act of projecting the vector φ onto the hyperslab Pk,i that
consists of all M × 1 vectors z satisfying (similarly for the projection P′
k,i):
Pk,i ≜{z such that |dk(i) −uk,iz| ≤ϵk},
(9.503)
P′
k,i ≜

z such that |dk(i) −uk,iz| ≤ϵ′
k

,
(9.504)
where {ϵk, ϵ′
k} are positive (tolerance) parameters chosen by the designer to satisfy ϵ′
k > ϵk. For generic
values {d, u, ϵ}, where d is a scalar and u is a row vector, the projection operator is described analytically

3.09.10 Extensions and Further Considerations
419
by the following expression [73]:
P[φ] = φ +
⎧
⎪⎪⎨
⎪⎪⎩
u∗
∥u∥2 [d −ϵ −uφ], if d −ϵ > uφ,
0,
if |d −uφ| ≤ϵ,
u∗
∥u∥2 [d + ϵ −uφ], if d + ϵ < uφ.
(9.505)
The projections that appear in (9.501) and (9.502) can be regarded as another example of a tempo-
ral processing step. Observe from the middle plot in Figure 9.15 that the temporal step that we are
considering in the algorithms listed in Table 9.8 is based on each node k using its current and past
weight estimates, such as {φk,i, φk,i−1, . . . , φk,i−P+1}, rather than only φk,i and current and past raw
data {dk(i), dk(i −1), . . . , dk(i −P + 1), uk,i, uk,i−1, . . . , uk,i−P+1}. For this reason, the temporal
processing steps in Table 9.8 tend to exploit information from across the network more broadly and the
resulting mean-square error performance is generally improved relative to (9.500)–(9.502).
3.09.10.2 Diffusion recursive least-squares
Diffusion strategies can also be applied to recursive least-squares problems to enable distributed solu-
tions of least-squares designs [38,39]; see also [74]. Thus, consider again a set of N nodes that are
spatially distributed over some domain. The objective of the network is to collectively estimate some
unknown column vector of length M, denoted by wo, using a least-squares criterion. At every time
instant i, each node k collects a scalar measurement, dk(i), which is assumed to be related to the
unknown vector wo via the linear model:
dk(i) = uk,iwo + vk(i).
(9.506)
In the above relation, the vector uk,i denotes a row regression vector of length M, and vk(i) denotes
measurement noise. A snapshot of the data in the network at time i can be captured by collecting the
measurements and noise samples, {dk(i), vk(i)}, from across all nodes into column vectors yi and vi of
sizes N × 1 each, and the regressors {uk,i} into a matrix Hi of size N × M:
yi =
⎡
⎢⎢⎢⎣
d1(i)
d2(i)
...
dN(i)
⎤
⎥⎥⎥⎦(N × 1),
vi =
⎡
⎢⎢⎢⎣
v1(i)
v2(i)
...
vN(i)
⎤
⎥⎥⎥⎦(N × 1),
Hi =
⎡
⎢⎢⎢⎣
u1,i
u2,i
...
uN,i
⎤
⎥⎥⎥⎦(N × M).
(9.507)
Likewise, the history of the data across the network up to time i can be collected into vector quantities
as follows:
Yi =
⎡
⎢⎢⎢⎣
yi
yi−1
...
y0
⎤
⎥⎥⎥⎦,
Vi =
⎡
⎢⎢⎢⎣
vi
vi−1
...
v0
⎤
⎥⎥⎥⎦,
Hi =
⎡
⎢⎢⎢⎣
Hi
Hi−1
...
H0
⎤
⎥⎥⎥⎦.
(9.508)
Then, one way to estimate wo is by formulating a global least-squares optimization problem of the
form:
min
w ∥w∥2
i + ∥Yi −Hiw∥2
Wi ,
(9.509)

420
CHAPTER 9 Diffusion Adaptation Over Networks
where i > 0 represents a Hermitian regularization matrix and Wi ≥0 represents a Hermitian
weighting matrix. Common choices for i and Wi are
Wi = diag

IN, λIN, . . . , λi IN

,
(9.510)
i = λi+1δ−1,
(9.511)
where δ > 0 is usually a large number and 0 ≪λ ≤1 is a forgetting factor whose value is generally
very close to one. In this case, the global cost function (9.509) can be written in the equivalent form:
min
w λi+1∥w∥2 +
i
j=0
λi−j
 N

k=1
|dk( j) −uk, jw|2

,
(9.512)
which is an exponentially weighted least-squares problem. We see that, for every time instant j, the
squared errors, |dk( j)−uk, jw|2, are summed across the network and scaled by the exponential weighting
factor λi−j. The index i denotes current time and the index j denotes a time instant in the past. In this
way, data occurring in the remote past are scaled more heavily than data occurring closer to present
time.The global solution of (9.509) is given by [5]:
wi = [i + HiWiHi]−1H∗
i WiYi
(9.513)
and the notation wi, with a subscript i, is meant to indicate that the estimate wi is based on all data
collected from across the network up to time i. Therefore, the wi that is computed via (9.513) amounts
to a global construction.
In [38,39] a diffusion strategy was developed that allows nodes to approach the global solution wi by
relying solely on local interactions. Let wk,i denote a local estimate for wo that is computed by node k at
timei. The diffusion recursive-least-squares (RLS) algorithm takes the following form. For every node k,
we start with the initial conditions wk,−1 = 0 and Pk,−1 = δIM, where Pk,−1 is an M ×M matrix. Then,
for every time instant i, each node k performs an incremental step followed by a diffusion step as follows:
Diffusion RLS.
Step 1 (incremental update)
ψk,i ←wk,i−1
Pk,i ←λ−1Pk,i−1
for every neighboring node ℓ∈Nk, update:
ψk,i ←ψk,i +
cℓk Pk,iu∗
ℓ,i
1 + cℓkuℓ,i Pk,iu∗
ℓ,i
[dℓ,i −uℓ,iψk,i]
Pk,i ←Pk,i −
cℓk Pk,iu∗
ℓ,iuℓ,i Pk,i
1 + cℓkuℓ,i Pk,iu∗
ℓ,i
(9.514)
end
Step 2 (diffusion update)
wk,i = $
ℓ∈Nk
aℓkψℓ,i,

3.09.10 Extensions and Further Considerations
421
where the symbol ←denotes a sequential assignment, and where the scalars {aℓk, cℓk} are nonnegative
coefﬁcients satisfying:
for k = 1, 2, . . . , N:
cℓk ≥0,
N

k=1
cℓk = 1,
cℓk = 0 if ℓ/∈Nk,
(9.515)
aℓk ≥0,
N

ℓ=1
aℓk = 1,
aℓk = 0 if ℓ/∈Nk.
(9.516)
The above algorithm requires that at every instant i, nodes communicate to their neighbors their mea-
surements {dℓ(i), uℓ,i} for the incremental update, and the intermediate estimates {ψℓ,i} for the diffusion
update. During the incremental update, node k cycles through its neighbors and incorporates their data
contributions represented by {dℓ(i), uℓ,i} into {ψk,i, Pk,i}. Every other node in the network is performing
similar steps. At the end of the incremental step, neighboring nodes share their intermediate estimates
{ψℓ,i} to undergo diffusion. Thus, at the end of both steps, each node k would have updated the quantities
{wk,i−1, Pk,i−1} to {wk,i, Pk,i}. The quantities Pk,i are matrices of size M × M each. Observe that the
diffusion RLS implementation (9.514) does not require the nodes to share their matrices {Pℓ,i}, which
would amount to a substantial burden in terms of communications resources since each of these matrices
has M2 entries. Only the quantities {dℓ(i), uℓ,i, ψℓ,i} are shared. The mean-square performance and
convergence of the diffusion RLS strategy are studied in some detail in [39].
The incremental step of the diffusion RLS strategy (9.514) corresponds to performing a number of
|Nk| successive least-squares updates starting from the initial conditions {wk,i−1, Pk,i−1} and ending
with the values {ψk,i, Pk,i} that move onto the diffusion update step. It can be veriﬁed from the properties
of recursive least-squares solutions [4,5] that these variables satisfy the following equations at the end
of the incremental stage (step 1):
P−1
k,i = λP−1
k,i−1 +

ℓ∈Nk
cℓku∗
ℓ,iuℓ,i,
(9.517)
P−1
k,i ψk,i = λP−1
k,i−1wk,i−1 +

ℓ∈Nk
cℓku∗
ℓ,idℓ(i).
(9.518)
Introduce the auxiliary M × 1 variable:
qk,i ≜P−1
k,i ψk,i.
(9.519)
Then, the above expressions lead to the following alternative form of the diffusion RLS strategy (9.514).
Alternative form of diffusion RLS.
wk,i−1 =

ℓ∈Nk
aℓkψℓ,i−1
P−1
k,i = λP−1
k,i−1 +

ℓ∈Nk
cℓku∗
ℓ,iuℓ,i
qk,i = λP−1
k,i−1wk,i−1 +

ℓ∈Nk
cℓku∗
ℓ,idℓ(i)
ψk,i = Pk,iqk,i
(9.520)

422
CHAPTER 9 Diffusion Adaptation Over Networks
Under some approximations, and for the special choices A = C and λ = 1, the diffusion RLS strategy
(9.520) can be reduced to a form given in [75] and which is described by the following equations:
P−1
k,i =

ℓ∈Nk
cℓk

P−1
ℓ,i−1 + u∗
ℓ,iuℓ,i

,
(9.521)
qk,i =

ℓ∈Nk
cℓk

qℓ,i−1 + u∗
ℓ,idℓ(i)

,
(9.522)
ψk,i = Pk,iqk,i.
(9.523)
Algorithm (9.521)–(9.523) is motivated in [75] by using consensus-type arguments. Observe that the
algorithm requires the nodes to share the variables {dℓ(i), uℓ,i, qℓ,i−1, Pℓ,i−1}, which corresponds to
more communications overburden than required by diffusion RLS; the latter only requires that nodes
share {dℓ(i), uℓ,i, ψℓ,i−1}. In order to illustrate how a special case of diffusion RLS (9.520) can be
related to this scheme, let us set
A = C
and λ = 1.
(9.524)
Then, Eqs. (9.520) give:
Special form of diffusion RLS when A = C and λ = 1.
wk,i−1 =

ℓ∈Nk
cℓkψℓ,i−1
P−1
k,i = P−1
k,i−1 +

ℓ∈Nk
cℓku∗
ℓ,iuℓ,i
qk,i = P−1
k,i−1wk,i−1 +

ℓ∈Nk
cℓku∗
ℓ,idℓ(i)
ψk,i = Pk,iqk,i
(9.525)
Comparing these equations with (9.521)–(9.523), we ﬁnd that algorithm (9.521)–(9.523) of [75] would
relate to the diffusion RLS algorithm (9.520) when the following approximations are justiﬁed:

ℓ∈Nk
cℓk P−1
ℓ,i−1 ≈P−1
k,i−1,
(9.526)

ℓ∈Nk
cℓkqℓ,i−1 =

ℓ∈Nk
cℓk P−1
ℓ,i−1ψℓ,i−1
≈

ℓ∈Nk
cℓk P−1
k,i−1ψℓ,i−1

3.09.10 Extensions and Further Considerations
423
= P−1
k,i−1

ℓ∈Nk
cℓkψℓ,i−1
(9.527)
= P−1
k,i−1wk,i−1.
(9.528)
It was indicated in [39] that the diffusion RLS implementation (9.514) or (9.520) leads to enhanced
performance in comparison to the consensus-based update (9.521)–(9.523).
3.09.10.3 Diffusion Kalman ﬁltering
Diffusion strategies can also be applied to the solution of distributed state-space ﬁltering and smoothing
problems [35,40,41]. Here, we describe brieﬂy the diffusion version of the Kalman ﬁlter; other variants
and smoothing ﬁlters can be found in [35]. We assume that some system of interest is evolving according
to linear state-space dynamics, and that every node in the network collects measurements that are linearly
related to the unobserved state vector. The objective is for every node to track the state of the system
over time based solely on local observations and on neighborhood interactions.
Thus, consider a network consisting of N nodes observing the state vector, xi, of size n × 1 of a
linear state-space model. At every time i, every node k collects a measurement vector yk,i of size p ×1,
which is related to the state vector as follows:
xi+1 = Fixi + Gini,
(9.529)
yk,i = Hk,ixi + vk,i,
k = 1, 2, . . . , N.
(9.530)
The signals ni and vk,i denote state and measurement noises of sizes n × 1 and p × 1, respectively, and
they are assumed to be zero-mean, uncorrelated and white, with covariance matrices denoted by
E
 ni
vk,i
  n j
vk, j
∗
≜
 Qi
0
0
Rk,i

δi j.
(9.531)
The initial state vector, xo, is assumed to be zero-mean with covariance matrix
Exox∗
o = o > 0
(9.532)
and is uncorrelated with ni and vk,i, for all i and k. We further assume that Rk,i > 0. The parameter
matrices {Fi, Gi, Hk,i, Qi, Rk,i, o} are assumed to be known by node k.
Let ˆxk,i| j denote a local estimator for xi that is computed by node k at time i based solely on local
observations and on neighborhood data up to time j. The following diffusion strategy was proposed
in [35,40,41] to approximate predicted and ﬁltered versions of these local estimators in a distributed
manner for data satisfying model (9.529)–(9.532). For every node k, we start with ˆxk,0|−1 = 0 and
Pk,0|−1 = o, where Pk,0|−1 is an M × M matrix. At every time instant i, every node k performs an
incremental step followed by a diffusion step:

424
CHAPTER 9 Diffusion Adaptation Over Networks
Time and measurement-form of the diffusion Kalman ﬁlter.
Step 1 (incremental update)
ψk,i ←ˆxk,i|i−1
Pk,i ←Pk,i|i−1
for every neighboring node ℓ∈Nk, update:
Re ←Rℓ,i + Hℓ,i Pk,i H∗
ℓ,i
ψk,i ←ψk,i + Pk,i H∗
ℓ,i R−1
e

yℓ,i −Hℓ,iψk,i

Pk,i ←Pk,i −Pk,i H∗
ℓ,i R−1
e
Hℓ,i Pk,i
(9.533)
end
Step 2 (diffusion update)
ˆxk,i|i = $
ℓ∈Nk
aℓkψℓ,i
Pk,i|i = Pk,i
ˆxk,i+1|i = Fi ˆxk,i|i
Pk,i+1|i = Fi Pk,i|i F∗
i + Gi QiG∗
i .
where the symbol ←denotes a sequential assignment, and where the scalars {aℓk} are nonnegative
coefﬁcients satisfying:
for k = 1, 2, . . . , N:
aℓk ≥0,
N

ℓ=1
aℓk = 1,
aℓk = 0 if ℓ/∈Nk.
(9.534)
The above algorithm requires that at every instant i, nodes communicate to their neighbors their mea-
surement matrices Hℓ,i, the noise covariance matrices Rℓ,i, and the measurements yℓ,i for the incre-
mental update, and the intermediate estimators ψℓ,i for the diffusion update. During the incremental
update, node k cycles through its neighbors and incorporates their data contributions represented by
{yℓ,i, Hℓ,i, Rℓ,i} into {ψk,i, Pk,i}. Every other node in the network is performing similar steps. At
the end of the incremental step, neighboring nodes share their updated intermediate estimators {ψℓ,i}
to undergo diffusion. Thus, at the end of both steps, each node k would have updated the quantities
{ˆxk,i|i−1, Pk,i|i−1} to {ˆxk,i+1|i, Pk,i+1|i}. The quantities Pk,i|i−1 are n × n matrices. It is important to
note that even though the notation Pk,i|i and Pk,i|i−1 has been retained for these variables, as in the
standard Kalman ﬁltering notation [5,76], these matrices do not represent any longer the covariances
of the state estimation errors, ˜xk,i|i−1 = xi −ˆxk,i|i−1, but can be related to them [35].
An alternative representation of the diffusion Kalman ﬁlter may be obtained in information form by
further assuming that Pk,i|i−1 > 0 for all k and i; a sufﬁcient condition for this fact to hold is to requires
the matrices {Fi} to be invertible [76]. Thus, consider again data satisfying model (9.529)–(9.532). For
every node k, we start with ˆxk,0|−1 = 0 and P−1
k,0|−1 = −1
o . At every time instant i, every node k
performs an incremental step followed by a diffusion step:

3.09.10 Extensions and Further Considerations
425
Information form of the diffusion Kalman ﬁlter.
Step 1 (incremental update)
Sk,i =

ℓ∈Nk
H∗
ℓ,i R−1
ℓ,i Hℓ,i
qk,i =

ℓ∈Nk
H∗
ℓ,i R−1
ℓ,i yℓ,i
P−1
k,i|i = P−1
k,i|i−1 + Sk,i
ψk,i = ˆxk,i|i−1 + Pk,i|i[qk,i −Sk,i ˆxk,i|i−1]
(9.535)
Step 2 (diffusion update)
ˆxk,i|i =

ℓ∈Nk
aℓkψℓ,i
ˆxk,i+1|i = Fi ˆxk,i|i
Pk,i+1|i = Fi Pk,i|i F∗
i + Gi QiG∗
i
The incremental update in (9.535) is similar to the update used in the distributed Kalman ﬁlter derived
in [49]. An important difference in the algorithms is in the diffusion step. Reference [49] starts from a
continuous-time consensus implementation and discretizes it to arrive at the following update relation:
ˆxk,i|i = ψk,i + ϵ

ℓ∈Nk
(ψℓ,i −ψk,i),
(9.536)
which, in order to facilitate comparison with (9.535), can be equivalently rewritten as:
ˆxk,i|i = (1 + ϵ −nkϵ) · ψk,i +

ℓ∈Nk\{k}
ϵ · ψℓ,i,
(9.537)
where nk denotes the degree of node k (i.e., the size of its neighborhood, Nk). In comparison, the
diffusion step in (9.535) can be written as:
ˆxk,i|i = akk · ψk,i +

ℓ∈Nk\{k}
aℓk · ψℓ,i.
(9.538)
Observe that the weights used in (9.537) are (1 + ϵ −nkϵ) for the node’s estimator, ψk,i, and ϵ
for all other estimators, {ψℓ,i}, arriving from the neighbors of node k. In contrast, the diffusion step
(9.538) employs a convex combination of the estimators {ψℓ,i} with generally different weights {aℓk}
for different neighbors; this choice is motivated by the desire to employ combination coefﬁcients that
enhance the fusion of information at node k, as suggested by the discussion in Appendix D of [35]. It was
veriﬁed in [35] that the diffusion implementation (9.538) leads to enhanced performance in comparison

426
CHAPTER 9 Diffusion Adaptation Over Networks
to the consensus-based update (9.537). Moreover, the weights {aℓk} in (9.538) can also be adjusted over
time in order to further enhance performance, as discussed in [77]. The mean-square performance and
convergence of the diffusion Kalman ﬁltering implementations are studied in some detail in [35], along
with other diffusion strategies for smoothing problems including ﬁxed-point and ﬁxed-lag smoothing.
3.09.10.4 Diffusion distributed optimization
The ATC and CTA steepest-descent diffusion strategies (9.134) and (9.142) derived earlier in Sec-
tion 3.09.3 provide distributed mechanisms for the solution of global optimization problems of the
form:
min
w
N

k=1
Jk(w),
(9.539)
where the individual costs, Jk(w), were assumed to be quadratic in w, namely,
Jk(w) = σ 2
d,k −w∗rdu,k −r∗
du,kw + w∗Ru,kw
(9.540)
for given parameters {σ 2
d,k,rdu,k, Ru,k}. Nevertheless, we remarked in that section that similar diffusion
strategies can be applied to more general cases involving individual cost functions, Jk(w), that are
not necessarily quadratic in w [1–3]. We restate below, for ease of reference, the general ATC and
CTA diffusion strategies (9.139) and (9.146) that can be used for the distributed solution of global
optimization problems of the form (9.539) for more general convex functions Jk(w):
(ATC strategy)
ψk,i = wk,i−1 −μk

ℓ∈Nk
cℓk[∇w Jℓ(wk,i−1)]∗
wk,i =

ℓ∈Nk
aℓkψℓ,i
(9.541)
and
(CTA strategy)
ψk,i−1 =

ℓ∈Nk
aℓkwℓ,i−1
wk,i = ψk,i−1 −μk

ℓ∈Nk
cℓk[∇w Jℓ(ψk,i−1)]∗
(9.542)
for positive step-sizes {μk} and for nonnegative coefﬁcients {cℓk, aℓk} that satisfy:
for k = 1, 2, . . . , N:
cℓk ≥0,
N

k=1
cℓk = 1,
cℓk = 0 if ℓ/∈Nk,
aℓk ≥0,
N

ℓ=1
aℓk = 1,
aℓk = 0 if ℓ/∈Nk.
(9.543)
That is, the matrix A = [aℓk] is left-stochastic while the matrix C = [cℓk] is right-stochastic:
C1 = 1,
AT 1 = 1.
(9.544)

3.09.10 Extensions and Further Considerations
427
We can again regard the above ATC and CTA strategies as special cases of the following general diffusion
scheme:
φk,i−1 =

ℓ∈Nk
a1,ℓkwℓ,i−1,
(9.545)
ψk,i = φk,i−1 −μk

ℓ∈Nk
cℓk[∇w Jℓ(φk,i−1)]∗,
(9.546)
wk,i =

ℓ∈Nk
a2,ℓkψℓ,i,
(9.547)
where the coefﬁcients {a1,ℓk, a2,ℓk, cℓk} are nonnegative coefﬁcients corresponding to the (l, k)th entries
of combination matrices {A1, A2, C} that satisfy:
AT
1 1 = 1,
AT
2 1 = 1,
C1 = 1.
(9.548)
The convergence behavior of these diffusion strategies can be examined under both conditions of
noiseless updates (when the gradient vectors are available) and noisy updates (when the gradient vectors
are subject to gradient noise). The following properties can be proven for the diffusion strategies (9.545)–
(9.547) [2]. The statements that follow assume, for convenience of presentation, that all data are real-
valued; the conditions would need to be adjusted for complex-valued data.
3.09.10.4.1
Noiseless updates
Let
J glob(w) =
N

k=1
Jk(w)
(9.549)
denote the global cost function that we wish to minimize. Assume J glob(w) is strictly convex so that
its minimizer wo is unique. Assume further that each individual cost function Jk(w) is convex and
has a minimizer at the same wo. This case is common in practice; situations abound where nodes in a
network need to work cooperatively to attain a common objective (such as tracking a target, locating
the source of chemical leak, estimating a physical model, or identifying a statistical distribution). The
case where the {Jk(w)} have different individual minimizers is studied in [1,3], where it is shown that
the same diffusion strategies of this section are still applicable and nodes would converge instead to a
Pareto-optimal solution.
Theorem 9.10.1 (Convergence to Optimal Solution: Noise-Free Case).
Consider the problem of
minimizing the strictly convex global cost (9.549), with the individual cost functions {Jk(w)} assumed
to be convex with each having a minimizer at the same wo. Assume that all data are real-valued and
suppose the Hessian matrices of the individual costs are bounded from below and from above as follows:
λℓ,minIM ≤∇2
w Jℓ(w) ≤λℓ,maxIM,
ℓ= 1, 2, . . . , N
(9.550)
for some positive constants {λℓ,min, λℓ,max}. Let
σk,min ≜

ℓ∈Nk
cℓkλℓ,min,
σk,max ≜

ℓ∈Nk
cℓkλℓ,max.
(9.551)

428
CHAPTER 9 Diffusion Adaptation Over Networks
Assume further that σk,min > 0 and that the positive step-sizes are chosen such that:
μk ≤
2
σk,max
,
k = 1, . . . , N.
(9.552)
Then, it holds that wk,i →wo as i →∞. That is, the weight estimates generated by (9.545)–(9.547)
at all nodes will tend towards the desired global minimizer.
□
We note that in works on distributed sub-gradient methods (e.g., [36,78]), the norms of the sub-gradients
are usually required to be uniformly bounded. Such a requirement is restrictive in the unconstrained
optimization of differentiable functions. Condition (9.550) is more relaxed since it allows the gradient
vector ∇w Jℓ(w) to have unbounded norm. This extension is important because requiring bounded gra-
dient norms, as opposed to bounded Hessian matrices, would exclude the possibility of using quadratic
costs for the Jℓ(w) (since the gradient vectors would then be unbounded). And, as we saw in the body
of the chapter, quadratic costs play a critical role in adaptation and learning over networks.
3.09.10.4.2
Updates with gradient noise
It is often the case that we do not have access to the exact gradient vectors to use in (9.546), but to noisy
versions of them, say,

∇w Jℓ(φk,i−1) ≜∇w Jℓ(φk,i−1) + vℓ( ˜φk,i−1),
(9.553)
where the random vector variable vℓ(·) refers to gradient noise; its value is generally dependent on the
weight-error vector realization,
˜φk,i−1 ≜wo −φk,i−1
(9.554)
at which the gradient vector is being evaluated. In the presence of gradient noise, the weight estimates
at the various nodes become random quantities and we denote them by the boldface notation {wk,i}. We
assume that, conditioned on the past history of the weight estimators at all nodes, namely,
Fi−1 ≜{wm, j, m = 1, 2, . . . , N, j < i}
(9.555)
the gradient noise has zero mean and its variance is upper bounded as follows:
E{vℓ( ˜φk,i−1)|Fi−1} = 0,
(9.556)
E{∥vℓ( ˜φk,i−1)∥2|Fi−1} ≤α∥˜φk,i−1∥2 + σ 2
v
(9.557)
for some α > 0 and σ 2
v ≥0. Condition (9.557) allows the variance of the gradient noise to be time-
variant, so long as it does not grow faster than E∥˜φk,i−1∥2. This condition on the noise is more general
than the “uniform-bounded assumption” that appears in [36], which required instead:
E{∥vℓ( ˜φk,i−1)∥2} ≤σ 2
v ,
E{∥vℓ( ˜φk,i−1)∥2|Fi−1} ≤σ 2
v .
(9.558)
These two requirements are special cases of (9.557) for α = 0. Furthermore, condition (9.557) is similar
to condition (4.3) in [79], which requires the noise variance to satisfy:
E{∥vℓ( ˜φk,i−1)∥2|Fi−1} ≤α[∥∇w Jℓ(φk,i−1)∥2 + 1].
(9.559)

3.09.10 Extensions and Further Considerations
429
This requirement can be veriﬁed to be a combination of the “relative random noise” and the “absolute
random noise” conditions deﬁned in [22]—see [2].
Now, introduce the column vector:
zi ≜
N

ℓ=1
col{cℓ1vℓ(wo), cℓ2vℓ(wo), . . . , cℓNvℓ(wo)}
(9.560)
and let
Z = E ziz∗
i
(9.561)
Let further
˜wi ≜col{ ˜wi,1, ˜wi,2, . . . , ˜wi,N},
(9.562)
where
˜wk,i ≜wo −wk,i.
(9.563)
Then, the following result can be established [2]; it characterizes the network mean-square deviation in
steady-state, which is deﬁned as
MSDnetwork ≜lim
i→∞

1
N
N

k=1
E∥˜wk,i∥2

.
(9.564)
Theorem 9.10.2 (Mean-Square Stability: Noisy Case).
Consider the problem of minimizing the
strictly convex global cost (9.549), with the individual cost functions {Jk(w)} assumed to be convex
with each having a minimizer at the same wo. Assume all data are real-valued and suppose the Hessian
matrices of the individual costs are bounded from below and from above as stated in (9.550). Assume
further that the diffusion strategy (9.545)–(9.547) employs noisy gradient vectors, where the noise
terms are zero mean and satisfy conditions (9.557) and (9.561). We select the positive step-sizes to be
sufﬁciently small and to satisfy:
μk < min
,
2σk,max
σ 2
k,max + α∥C∥2
1
,
2σk,min
σ 2
k,min + α∥C∥2
1
0
(9.565)
for k = 1, 2, . . . , N. Then, the diffusion strategy (9.545)–(9.547) is mean-square stable and the mean-
square-deviation of the network is given by:
MSDnetwork ≈1
N [vec(AT
2 MZT MA2)]T · (I −F)−1 · vec(IN M),
(9.566)
where
A2 = A2 ⊗IM,
(9.567)
M = diag{μ1IM, μ2IM, . . . , μN IM},
(9.568)
F ≈BT ⊗B∗,
(9.569)
B = AT
2 (I −MR)AT
1 ,
(9.570)
R =
N

ℓ=1
diag

cℓ1∇2
w Jℓ(wo), cℓ2∇2
w Jℓ(wo), . . . , cℓN∇2
w Jℓ(wo)

.
(9.571)
□

430
CHAPTER 9 Diffusion Adaptation Over Networks
Appendices
A Properties of Kronecker products
For ease of reference, we collect in this appendix some useful properties of Kronecker products. All
matrices are assumed to be of compatible dimensions; all inverses are assumed to exist whenever neces-
sary. Let E = [ei j]n
i, j=1 and B = [bi j]m
i, j=1 be n ×n and m ×m matrices, respectively. Their Kronecker
product is denoted by E ⊗B and is deﬁned as the nm × nm matrix whose entries are given by [20]:
E ⊗B =
⎡
⎢⎢⎢⎣
e11B
e12B
. . . e1n B
e21B
e22B
. . . e2n B
...
...
en1B
en2B
. . . enn B
⎤
⎥⎥⎥⎦.
(9.572)
In other words, each entry of E is replaced by a scaled multiple of B. Let {λi(E), i = 1, . . . , n} and
{λ j(B), j = 1, . . . , m} denote the eigenvalues of E and B, respectively. Then, the eigenvalues of E ⊗B
will consist of all nm product combinations {λi(E)λ j(B)}. Table 9.9 lists some well-known properties
of Kronecker products.
Table 9.9 Properties of Kronecker Products
(E + B) ⊗C = (E ⊗C) + (B ⊗C)
(E ⊗B)(C ⊗D) = (EC ⊗BD)
(E ⊗B)T = ET ⊗BT
(E ⊗B)∗= E∗⊗B∗
(E ⊗B)−1 = E−1 ⊗B−1
(E ⊗B)ℓ= Eℓ⊗Bℓ
{λ(E ⊗B)} = {λi (E)λj (B)}n,m
i=1,j=1
det (E ⊗B) = ( det E)m( det B)n
Tr(E ⊗B) = Tr(E)Tr(B)
Tr(EB) = [vec(BT )]T vec(E)
vec(ECB) = (BT ⊗E)vec(C)
B Graph Laplacian and network connectivity
Consider a network consisting of N nodes and L edges connecting the nodes to each other. In the
constructions below, we only need to consider the edges that connect distinct nodes to each other; these

B Graph Laplacian and Network Connectivity
431
edges do not contain any self-loops that may exist in the graph and which connect nodes to themselves
directly.Inotherwords,whenwerefertothe L edgesofagraph,weareexcludingself-loopsfromthisset;
but we are still allowing loops of at least length 2 (i.e., loops generated by paths covering at least 2 edges).
The neighborhood of any node k is denoted by Nk and it consists of all nodes that node k can share
information with; these are the nodes that are connected to k through edges, in addition to node k itself.
The degree of node k, which we denote by nk, is deﬁned as the positive integer that is equal to the size
of its neighborhood:
nk ≜|Nk|.
(9.573)
Since k ∈Nk, we always have nk ≥1. We further associate with the network an N × N Laplacian
matrix, denoted by L. The matrix L is symmetric and its entries are deﬁned as follows [60–62]:
[L]kℓ=
⎧
⎨
⎩
nk −1, if k = ℓ,
−1,
if k ̸= ℓand nodes k and ℓare neighbors,
0,
otherwise.
(9.574)
Note that the term nk −1 measures the number of edges that are incident on node k, and the locations
of the −1′s on row k indicate the nodes that are connected to node k. We also associate with the graph
an N × L incidence matrix, denoted by I. The entries of I are deﬁned as follows. Every column of
I represents one edge in the graph. Each edge connects two nodes and its column will display two
nonzero entries at the rows corresponding to these nodes: one entry will be +1 and the other entry will
be −1. For directed graphs, the choice of which entry is positive or negative can be used to identify
the nodes from which edges emanate (source nodes) and the nodes at which edges arrive (sink nodes).
Since we are dealing with undirected graphs, we shall simply assign positive values to lower indexed
nodes and negative values to higher indexed nodes:
[I]ke =
⎧
⎨
⎩
+1, if node k is the lower-indexed node connected to edge e,
−1, if node k is the higher-indexed node connected to edge e,
0,
otherwise.
(9.575)
Figure 9.16 shows the example of a network with N = 6 nodes and L = 8 edges. Its Laplacian and
incidence matrices are also shown and these have sizes 6 × 6 and 6 × 8, respectively. Consider, for
example, column 6 in the incidence matrix. This column corresponds to edge 6, which links nodes 3
and 5. Therefore, at location I36 we have a +1 and at location I56 we have −1. The other columns of
I are constructed in a similar manner.
Observe that the Laplacian and incidence matrices of a graph are related as follows:
L = IIT .
(9.576)
The Laplacian matrix conveys useful information about the topology of the graph. The following is a
classical result from graph theory [60–62,80].
Lemma B.1 (Laplacian and Network Connectivity).
Let
θ1 ≥θ2 ≥· · · ≥θN
(9.577)

432
CHAPTER 9 Diffusion Adaptation Over Networks
1        2       3      4       5      6
1
nodes
nodes
edges
2
3
4
5
6
1
2
3
4
5
6
1      2      3       4      5      6
7      8
FIGURE 9.16
A network with N = 6 nodes and L = 8 edges. The nodes are marked 1 through 6 and the edges are marked
1 through 8. The corresponding Laplacian and incidence matrices L and I are 6 × 6 and 6 × 8.
denote the ordered eigenvalues of L. Then the following properties hold:
a. L is symmetric nonnegative-deﬁnite so that θi ≥0.
b. The rows of L add up to zero so that L1 = 0. This means that 1 is a right eigenvector of L
corresponding to the eigenvalue zero.
c. The smallest eigenvalue is always zero, θN = 0. The second smallest eigenvalue, θN−1, is called the
algebraic connectivity of the graph.
d. The number of times that zero is an eigenvalue of L (i.e., its multiplicity) is equal to the number of
connected subgraphs.
e. The algebraic connectivity of a connected graph is nonzero, i.e., θN−1 ̸= 0. In other words, a graph
is connected if, and only if, its algebraic connectivity is nonzero.
Proof.
Property (a) follows from the identity L = IIT . Property (b) follows from the deﬁnition
of L. Note that for each row of L, the entries on the row add up to zero. Property (c) follows from
properties (a) and (b) since L1 = 0 implies that zero is an eigenvalue of L. For part (d), assume the
network consists of two separate connected subgraphs. Then, the Laplacian matrix would have a block
diagonal structure, say, of the form L = diag{L1, L2}, where L1 and L2 are the Laplacian matrices of
the smaller subgraphs. The smallest eigenvalue of each of these Laplacian matrices would in turn be
zero and unique by property (e). More generally, if the graph consists of m connected subgraphs, then
the multiplicity of zero as an eigenvalue of L would be m. To establish property (e), ﬁrst observe that if
the algebraic connectivity is nonzero then it is obvious that the graph must be connected; otherwise, the
Laplacian matrix would be block diagonal and θN−1 would be zero (a contradiction). For the converse
statement, assume the graph is connected and let x denote an arbitrary eigenvector of L corresponding
to the eigenvalue at zero. Then, xT Lx = 0, from which we can conclude that all entries of x must
be equal. Therefore, the algebraic multiplicity of the eigenvalue of L at zero is equal to one and the
algebraic connectivity of the graph must be nonzero.
□

C Stochastic Matrices
433
C Stochastic matrices
Consider N × N matrices A with nonnegative entries, {aℓk ≥0}. The matrix A = [aℓk] is said to be
right-stochastic if it satisﬁes
A1 = 1 (right-stochastic),
(9.578)
in which case each row of A adds up to one. The matrix A is said to be left-stochastic if it satisﬁes
AT 1 = 1 (left-stochastic),
(9.579)
in which case each column of A adds up to one. And the matrix is said to be doubly stochastic if both
conditions hold so that both its columns and rows add up to one:
A1 = 1,
AT 1 = 1 (doubly-stochastic).
(9.580)
Stochastic matrices arise frequently in the study of adaptation over networks. This appendix lists some
of their properties.
Lemma C.1 (Spectral Norm of Stochastic Matrices).
Let A be an N × N right or left or doubly
stochastic matrix. Then, ρ(A) = 1 and, therefore, all eigenvalues of A lie inside the unit disc, i.e.,
|λ(A)| ≤1.
Proof.
We prove the result for right stochastic matrices; a similar argument applies to left or doubly
stochastic matrices. Let A be a right-stochastic matrix. Then, A1 = 1, so that λ = 1 is one of the
eigenvalues of A. Moreover, for any matrix A, it holds that ρ(A) ≤∥A∥∞, where ∥· ∥∞denotes the
maximum absolute row sum of its matrix argument. But since all rows of A add up to one, we have
∥A∥∞= 1. Therefore, ρ(A) ≤1. And since we already know that A has an eigenvalue at λ = 1, we
conclude that ρ(A) = 1.
□
The above result asserts that the spectral radius of a stochastic matrix is unity and that A has an eigenvalue
at λ = 1. The result, however, does not rule out the possibility of multiple eigenvalues at λ = 1, or
even other eigenvalues with magnitude equal to one. Assume, in addition, that the stochastic matrix
A is regular. This means that there exists an integer power jo such that all entries of A jo are strictly
positive, i.e.,
for all (ℓ, k), it holds that [A jo]ℓk > 0,
for some jo > 0.
(9.581)
Then a result in matrix theory known as the Perron-Frobenius Theorem [20] leads to the following
stronger characterization of the eigen-structure of A.
Lemma C.2 (Spectral Norm of Regular Stochastic Matrices).
Let A be an N × N right stochastic
and regular matrix. Then:
a. ρ(A) = 1.
b. All other eigenvalues of A are strictly inside the unit circle (and, hence, have magnitude strictly less
than one).

434
CHAPTER 9 Diffusion Adaptation Over Networks
c. The eigenvalue at λ = 1 is simple, i.e., it has multiplicity one. Moreover, with proper sign scaling,
all entries of the corresponding eigenvector are positive. For a right-stochastic A, this eigenvector
is the vector 1 since A1 = 1.
d. All other eigenvectors associated with the other eigenvalues will have at least one negative or
complex entry.
Proof.
Part (a) follows from Lemma C.1. Parts (b) and (d) follow from the Perron-Frobenius Theorem
when A is regular [20].
□
Lemma C.3(UsefulPropertiesofDoublyStochasticMatrices).
Let A bean N×N doublystochastic
matrix. Then the following properties hold:
a. ρ(A) = 1.
b. AAT and AT A are doubly stochastic as well.
c. ρ(AAT ) = ρ(AT A) = 1.
d. The eigenvalues of AAT or AT A are real and lie inside the interval [0, 1].
e. I −AAT ≥0 and I −AT A ≥0.
f. Tr(AT H A) ≤Tr(H), for any N × N nonnegative-deﬁnite Hermitian matrix H.
Proof.
Part (a) follows from Lemma C.1. For part (b), note that AAT is symmetric and AAT 1 =
A1 = 1. Therefore, AAT is doubly stochastic. Likewise for AT A. Part (c) follows from part (a) since
AAT and AT A are themselves doubly stochastic matrices. For part (d), note that AAT is symmetric and
nonnegative-deﬁnite. Therefore, its eigenvalues are real and nonnegative. But since ρ(AAT ) = 1, we
must have λ(AAT ) ∈[0, 1]. Likewise for the matrix AT A. Part (e) follows from part (d). For part (f),
since AAT ≥0 and its eigenvalues lie within [0, 1], the matrix AAT admits an eigen-decomposition of
the form:
AAT = UU T ,
where U is orthogonal (i.e., U −1 = U T ) and  is diagonal with entries in the range [0, 1]. It then
follows that
Tr(AT H A) = Tr(AAT H)
= Tr(UU T H)
= Tr(U T HU)
(∗)
≤Tr(U T HU)
= Tr(UU T H)
= Tr(H),
where step (∗) is because U T HU = U −1HU and, by similarity, the matrix U −1HU has the same
eigenvalues as H. Therefore, U T HU ≥0. This means that the diagonal entries of U T HU are
nonnegative. Multiplying U T HU by  ends up scaling the nonnegative diagonal entries to smaller
values so that ( ∗) is justiﬁed.
□

D Block Maximum Norm
435
D Block maximum norm
Let x = col{x1, x2, . . . , xN} denote an N × 1 block column vector whose individual entries are of size
M×1 each. Following [23,63,81], the block maximum norm of x is denoted by ∥x∥b,∞and is deﬁned as
∥x∥b,∞≜max
1≤k≤N ∥xk∥,
(9.582)
where ∥· ∥denotes the Euclidean norm of its vector argument. Correspondingly, the induced block
maximum norm of an arbitrary N × N block matrix A, whose individual block entries are of size
M × M each, is deﬁned as
∥A∥b,∞≜max
x̸=0
∥Ax∥b,∞
∥x∥b,∞
.
(9.583)
The block maximum norm inherits the unitary invariance property of the Euclidean norm, as the fol-
lowing result indicates [63].
Lemma D.1 (Unitary Invariance).
Let U = diag{U1, U2, . . . ,UN} be an N × N block diagonal
matrix with M × M unitary blocks {Uk}. Then, the following properties hold:
a. ∥Ux∥b,∞= ∥x∥b,∞
b. ∥UAU∗∥b,∞= ∥A∥b,∞
for all block vectors x and block matrices A of appropriate dimensions.
□
The next result provides useful bounds for the block maximum norm of a block matrix.
Lemma D.2 (Useful Bounds).
Let A be an arbitrary N × N block matrix with blocks Aℓk of size
M × M each. Then, the following results hold:
a. The norms of A and its complex conjugate are related as follows:
∥A∗∥b,∞≤N · ∥A∥b,∞.
(9.584)
b. The norm of A is bounded as follows:
max
1≤ℓ,k≤N ∥Aℓk∥≤∥A∥b,∞≤N ·

max
1≤ℓ,k≤N ∥Aℓk∥

,
(9.585)
where ∥· ∥denotes the 2-induced norm (or maximum singular value) of its matrix argument.
c. If A is Hermitian and nonnegative-deﬁnite (A ≥0), then there exist ﬁnite positive constants c1 and
c2 such that
c1 · Tr(A) ≤∥A∥b,∞≤c2 · Tr(A).
(9.586)
Proof.
Part (a) follows directly from part (b) by noting that
∥A∗∥b,∞≤N ·

max
1≤ℓ,k≤N
//A∗
ℓk
//

= N ·

max
1≤ℓ,k≤N ∥Aℓk∥

≤N · ∥A∥b,∞,

436
CHAPTER 9 Diffusion Adaptation Over Networks
where the equality in the second step is because ∥A∗
ℓk∥= ∥Aℓk∥; i.e., complex conjugation does not
alter the 2-induced norm of a matrix.
To establish part (b), we consider arbitrary N ×1 block vectors x with entries x = col{x1, x2, . . . , xN}
and where each xk is M × 1. Then, note that
∥Ax∥b,∞= max
1≤ℓ≤N
/////
N

k=1
Aℓkxk
/////
≤max
1≤ℓ≤N
 N

k=1
∥Aℓk∥· ∥xk∥

≤

max
1≤ℓ≤N
N

k=1
∥Aℓk∥

· max
1≤k≤N ∥xk∥
≤

max
1≤ℓ≤N
N

k=1
max
1≤k≤N ∥Aℓk∥

· ∥x∥b,∞
≤N ·

max
1≤ℓ,k≤N ∥Aℓk∥

· ∥x∥b,∞,
so that
∥A∥b,∞≜max
x̸=0
∥Ax∥b,∞
∥x∥b,∞
≤N ·

max
1≤ℓ,k≤N ∥Aℓk∥

,
which establishes the upper bound in (9.585).
To establish the lower bound, we assume without loss of generality that max1≤ℓ,k≤N ∥Aℓk∥is attained
at ℓ= 1 and k = 1. Let σ1 denote the largest singular value of A11 and let {v1, u1} denote the
corresponding M × 1 right and left singular vectors. That is,
∥A11∥= σ1,
A11v1 = σ1u1,
(9.587)
where v1 and u1 have unit norms. We now construct an N × 1 block vector xo as follows:
xo ≜col{v1, 0M, 0M, . . . , 0M}.
(9.588)
Then, obviously,
∥xo∥b,∞= 1
(9.589)
and
Axo = col{A11v1, A21v1, . . . , AN1v1}.
(9.590)

D Block Maximum Norm
437
It follows that
∥Axo∥b,∞= max{∥A11v1∥, ∥A21v1∥, . . . , ∥AN1v1∥}
≥∥A11v1∥
= ∥σ1u1∥
= σ1
= ∥A11∥
=
max
1≤ℓ,k≤N ∥Aℓk∥.
(9.591)
Therefore, by the deﬁnition of the block maximum norm,
∥A∥b,∞≜max
x̸=0
∥Ax∥b,∞
∥x∥b,∞

≥∥Axo∥b,∞
∥xo∥b,∞
= ∥Axo∥b,∞
≥
max
1≤ℓ,k≤N ∥Aℓk∥,
(9.592)
which establishes the lower bound in (9.585).
To establish part (c), we start by recalling that all norms on ﬁnite-dimensional vector spaces are
equivalent [20,21]. This means that if ∥· ∥a and ∥· ∥d denote two different matrix norms, then there
exist positive constants c1 and c2 such that for any matrix X,
c1 · ∥X∥a ≤∥X∥d ≤c2 · ∥X∥a.
(9.593)
Now, let ∥A∥∗denote the nuclear norm of the square matrix A. It is deﬁned as the sum of its singular
values:
∥A∥∗≜

m
σm(A).
(9.594)
Since A is Hermitian and nonnegative-deﬁnite, its eigenvalues coincide with its singular values and,
therefore,
∥A∥∗=

m
λm(A) = Tr(A).
Now applying result (9.593) to the two norms ∥A∥b,∞and ∥A∥∗we conclude that
c1 · Tr(A) ≤∥A∥b,∞≤c2 · Tr(A),
(9.595)
as desired.
□
The next result relates the block maximum norm of an extended matrix to the ∞—norm (i.e., maximum
absolute row sum) of the originating matrix. Speciﬁcally, let A be an N × N matrix with bounded entries
and introduce the block matrix
A ≜A ⊗IM.
(9.596)
The extended matrix A has blocks of size M × M each.

438
CHAPTER 9 Diffusion Adaptation Over Networks
Lemma D.3 (Relation to Maximum Absolute Row Sum).
Let A and A be related as in (9.596).
Then, the following properties hold:
a. ∥A∥b,∞= ∥A∥∞, where the notation ∥·∥∞denotes the maximum absolute row sum of its argument.
b. ∥A∗∥b,∞≤N · ∥A∥b,∞.
Proof.
Theresultsareobviousforazeromatrix A.Soassume A isnonzero.Let x = col{x1, x2, . . . , xN}
denote an arbitrary N × 1 block vector whose individual entries {xk} are vectors of size M × 1 each.
Then,
∥Ax∥b,∞= max
1≤k≤N
/////
N

ℓ=1
akℓxℓ
/////
≤max
1≤k≤N
 N

ℓ=1
|akℓ| · ∥xℓ∥

≤

max
1≤k≤N
N

ℓ=1
|akℓ|

· max
1≤ℓ≤N ∥xℓ∥
= ∥A∥∞· ∥x∥b,∞,
(9.597)
so that
∥A∥b,∞≜max
x̸=0
∥Ax∥b,∞
∥x∥b,∞
≤∥A∥∞.
(9.598)
The argument so far establishes that ∥A∥b,∞≤∥A∥∞. Now, let ko denote the row index that corresponds
to the maximum absolute row sum of A, i.e.,
∥A∥∞=
N

ℓ=1
|akoℓ|.
We construct an N × 1 block vector z = col{z1, z2, . . . , zN}, whose M × 1 entries {zℓ} are chosen as
follows:
zℓ= sign(akoℓ) · e1,
where e1 is the M × 1 basis vector:
e1 = col{1, 0, 0, . . . , 0}
and the sign function is deﬁned as
sign(a) =
 1,
if a ≥0,
−1, otherwise.
Then, note that z ̸= 0 for any nonzero matrix A, and
∥z∥b,∞= max
1≤ℓ≤N ∥zℓ∥= 1.

D Block Maximum Norm
439
Moreover,
∥A∥b,∞≜max
x̸=0
∥Ax∥b,∞
∥x∥b,∞
≥∥Az∥b,∞
∥z∥b,∞
= ∥Az∥b,∞
= max
1≤k≤N
/////
N

ℓ=1
akℓzℓ
/////
≥
/////
N

ℓ=1
akoℓzℓ
/////
=
/////
N

ℓ=1
akoℓ· sign(akoℓ)e1
/////
=
N

ℓ=1
|akoℓ| · ∥e1∥
=
N

ℓ=1
|akoℓ|
= ∥A∥∞.
(9.599)
Combining this result with (9.598) we conclude that ∥A∥b,∞= ∥A∥∞, which establishes part (a). Part
(b) follows from the statement of part (a) in Lemma D.2.
□
The next result establishes a useful property for the block maximum norm of right or left stochastic
matrices; such matrices arise as combination matrices for distributed processing over networks as in
(9.166) and (9.185).
Lemma D.4 (Right and Left Stochastic Matrices).
Let C be an N × N right stochastic matrix, i.e.,
its entries are nonnegative and it satisﬁes C1 = 1. Let A be an N × N left stochastic matrix, i.e., its
entries are nonnegative and it satisﬁes AT 1 = 1. Introduce the block matrices
AT ≜AT ⊗IM,
C ≜C ⊗IM.
(9.600)
The matrices A and C have blocks of size M × M each. It holds that
∥AT ∥b,∞= 1,
∥C∥b,∞= 1 .
(9.601)
Proof.
Since AT and C are right stochastic matrices, it holds that ∥AT ∥∞= 1 and ∥C∥∞= 1. The
desired result then follows from part (a) of Lemma D.3.
□
The next two results establish useful properties for the block maximum norm of a block diagonal matrix
transformed by stochastic matrices; such transformations arise as coefﬁcient matrices that control the
evolution of weight error vectors over networks, as in (9.189).

440
CHAPTER 9 Diffusion Adaptation Over Networks
Lemma D.5 (Block Diagonal Hermitian Matrices).
Consider an N × N block diagonal Hermitian
matrix D = diag{D1, D2, . . . , DN}, where each Dk is M × M Hermitian. It holds that
ρ(D) = max
1≤k≤N ρ(Dk) = ∥D∥b,∞,
(9.602)
where ρ(·) denotes the spectral radius (largest eigenvalue magnitude) of its argument. That is, the
spectral radius of D agrees with the block maximum norm of D, which in turn agrees with the largest
spectral radius of its block components.
Proof.
We already know that the spectral radius of any matrix X satisﬁes ρ(X) ≤∥X∥, for any
induced matrix norm [19,20]. Applying this result to D we readily get that ρ(D) ≤∥D∥b,∞. We now
establish the reverse inequality, namely, ∥D∥b,∞≤ρ(D). Thus, pick an arbitrary N × 1 block vector
x with entries {x1, x2, . . . , xN}, where each xk is M × 1. From deﬁnition (9.583) we have
∥D∥b,∞≜max
x̸=0
∥Dx∥b,∞
∥x∥b,∞
= max
x̸=0

1
∥x∥b,∞
· max
1≤k≤N ∥Dkxk∥

≤max
x̸=0

1
∥x∥b,∞
· max
1≤k≤N (∥Dk∥· ∥xk∥)

= max
x̸=0 max
1≤k≤N

∥Dk∥·
∥xk∥
∥x∥b,∞

≤max
1≤k≤N ∥Dk∥
= max
1≤k≤N ρ(Dk),
(9.603)
where the notation ∥Dk∥denotes the 2-induced norm of Dk (i.e., its largest singular value). But since
Dk is assumed to be Hermitian, its 2-induced norm agrees with its spectral radius, which explains the
last equality.
□
Lemma D.6 (Block Diagonal Matrix Transformed by Left Stochastic Matrices).
Consider an
N × N block diagonal Hermitian matrix D = diag{D1, D2, . . . , DN}, where each Dk is M × M
Hermitian. Let A1 and A2 be N × N left stochastic matrices, i.e., their entries are nonnegative and they
satisfy AT
1 1 = 1 and AT
2 1 = 1. Introduce the block matrices
AT
1 = AT
1 ⊗IM,
AT
2 ≜AT
2 ⊗IM.
(9.604)
The matrices A1 and A2 have blocks of size M × M each. Then it holds that
ρ

AT
2 · D · AT
1

≤ρ(D) .
(9.605)

D Block Maximum Norm
441
Proof.
Since the spectral radius of any matrix never exceeds any induced norm of the same matrix,
we have that
ρ

AT
2 · D · AT
1

≤
///AT
2 · D · AT
1
///
b,∞
≤
///AT
2
///
b,∞· ∥D∥b,∞·
///AT
1
///
b,∞
(9.601)
=
∥D∥b,∞
(9.602)
=
ρ(D).
(9.606)
□
In view of the result of Lemma D.5, we also conclude from (9.605) that
ρ

AT
2 · D · AT
1

≤max
1≤k≤N ρ(Dk) .
(9.607)
It is worth noting that there are choices for the matrices {A1, A2, D} that would result in strict inequality
in (9.605). Indeed, consider the special case:
D =
 2 0
0 1

,
AT
1 =
1 1
3
2
3
2
3
1
3
2
,
AT
2 =
1 1
3
2
3
2
3
1
3
2
.
This case corresponds to N = 2 and M = 1 (scalar blocks). Then,
AT
2 DAT
1 =
1 2
3
2
3
2
3
1
2
and it is easy to verify that
ρ(D) = 2,
ρ

AT
2 DAT
1

≈1.52.
The following conclusions follow as corollaries to the statement of Lemma D.6, where by a stable
matrix X we mean one whose eigenvalues lie strictly inside the unit circle.
Corollary D.1(StabilityProperties).
UnderthesamesettingofLemmaD.6,thefollowingconclusions
hold:
a. The matrix AT
2 DAT
1 is stable whenever D is stable.
b. The matrix AT
2 DAT
1 is stable for all possible choices of left stochastic matrices A1 and A2 if, and
only if, D is stable.
Proof.
Since D is block diagonal, part (a) follows immediately from (9.605) by noting that ρ(D) < 1
whenever D is stable. [This statement ﬁxes the argument that appeared in Appendix I of [18] and Lemma
2 of [35]. Since the matrix X in Appendix I of [18] and the matrix M in Lemma 2 of [35] are block
diagonal, the ∥· ∥b,∞norm should replace the ∥· ∥ρ norm used there, as in the proof that led to (9.606)

442
CHAPTER 9 Diffusion Adaptation Over Networks
and as already done in [63].] For part (b), assume ﬁrst that D is stable, then AT
2 DAT
1 will also be stable
by part (a) for any left-stochastic matrices A1 and A2. To prove the converse, assume that AT
2 DAT
1 is
stable for any choice of left stochastic matrices A1 and A2. Then, AT
2 DAT
1 is stable for the particular
choice A1 = I = A2 and it follows that D must be stable.
□
E Comparison with consensus strategies
Consider a connected network consisting of N nodes. Each node has a state or measurement value xk,
possibly a vector of size M × 1. All nodes in the network are interested in evaluating the average value
of their states, which we denote by
wo ≜1
N
N

k=1
xk.
(9.608)
A centralized solution to this problem would require each node to transmit its measurement xk to a
fusion center. The central processor would then compute wo using (9.608) and transmit it back to
all nodes. This centralized mode of operation suffers from at least two limitations. First, it requires
communications and power resources to transmit the data back and forth between the nodes and the
central processor; this problem is compounded if the fusion center is stationed at a remote location.
Second, the architecture has a critical point of failure represented by the central processor; if it fails,
then operations would need to be halted.
E.1 Consensus recursion
The consensus strategy provides an elegant distributed solution to the same problem, whereby nodes
interact locally with their neighbors and are able to converge to wo through these interactions. Thus,
consider an arbitrary node k and assign nonnegative weights {aℓk} to the edges linking k to its neighbors
ℓ∈Nk. For each node k, the weights {aℓk} are assumed to add up to one so that
for k = 1, 2, . . . , N :
aℓk ≥0,
N$
ℓ=1
aℓk = 1,
aℓk = 0 if ℓ/∈Nk.
(9.609)
The resulting combination matrix is denoted by A and its kth column consists of the entries {aℓk, ℓ=
1, 2, . . . , N}. In view of (9.609), the combination matrix A is seen to satisfy AT 1 = 1. That is, A is
left-stochastic. The consensus strategy can be described as follows. Each node k operates repeatedly on
the data from its neighbors and updates its state iteratively according to the rule:
wk,n =

ℓ∈Nk
aℓk wℓ,n−1,
n > 0 ,
(9.610)
where wℓ,n−1 denotes the state of node ℓat iteration n −1, and wk,n denotes the updated state of node
k after iteration n. The initial conditions are
wk,o = xk,
k = 1, 2, . . . , N.
(9.611)

E Comparison with Consensus Strategies
443
If we collect the states of all nodes at iteration n into a column vector, say,
zn ≜col{w1,n, w2,n, . . . , wN,n}.
(9.612)
Then, the consensus iteration (9.610) can be equivalently rewritten in vector form as follows:
zn = AT zn−1,
n > 0 ,
(9.613)
where
AT = AT ⊗IM.
(9.614)
The initial condition is
zo ≜col{x1, x2, . . . , xN}.
(9.615)
E.2 Error recursion
Note that we can express the average value, wo, from (9.608) in the form
wo = 1
N (1T ⊗IM)zo ,
(9.616)
where 1 is the vector of size M × 1 and whose entries are all equal to one. Let
˜wk,n = wo −wk,n
(9.617)
denote the weight error vector for node k at iteration n; it measures how far the iterated state is from the
desired average value wo. We collect all error vectors across the network into an N × 1 block column
vector whose entries are of size M × 1 each:
˜wn ≜
⎡
⎢⎢⎢⎣
˜w1,n
˜w2,n
...
˜wN,n
⎤
⎥⎥⎥⎦.
(9.618)
Then,
˜wn = (1 ⊗IM)wo −zn .
(9.619)
E.2.1
Convergence conditions
The following result is a classical result on consensus strategies [43–45]. It provides conditions under
which the state of all nodes will converge to the desired average, wo, so that ˜wn will tend to zero.
Theorem E.1 (Convergence to Consensus).
For any initial states {xk}, the successive iterates wk,n
generated by the consensus iteration (9.610) converge to the network average value wo as n →∞if,
and only if, the following three conditions are met:
AT 1 = 1,
(9.620)
A1 = 1,
(9.621)
ρ

AT −1
N 11T

< 1.
(9.622)

444
CHAPTER 9 Diffusion Adaptation Over Networks
That is, the combination matrix A needs to be doubly stochastic, and the matrix AT −1
N 11T needs to
be stable.
Proof (Sufﬁciency).
Assume ﬁrst that the three conditions stated in the theorem hold. Since A is
doubly stochastic, then so is any power of A, say, An for any n ≥0, so that
[An]T 1 = 1,
An1 = 1.
(9.623)
Using this fact, it is straightforward to verify by induction the validity of the following equality:

AT −1
N 11T
n
= [An]T −1
N 11T .
(9.624)
Likewise, using the Kronecker product identities
(E + B) ⊗C = (E ⊗C) + (B ⊗C),
(9.625)
(E ⊗B)(C ⊗D) = (EC ⊗BD),
(9.626)
(E ⊗B)n = En ⊗Bn,
(9.627)
for matrices {E, B, C, D} of compatible dimensions, we observe that
(An)T −1
N · (1 ⊗IM) · (1T ⊗IM)
=

(An)T ⊗IM

−1
N ·

11T ⊗IM

=

(An)T −1
N · 11T

⊗IM
(9.624)
=

AT −1
N 11T
n
⊗IM
=

AT −1
N 11T

⊗IM
n
.
(9.628)
Iterating (9.613) we ﬁnd that
zn = [An]T zo
(9.629)
and, hence, from (9.616) and (9.619),
˜wn
=
−

(An)T −1
N · (1 ⊗IM) · (1T ⊗IM)

· zo
(9.628)
=
−

AT −1
N 11T

⊗IM
n
· zo.
(9.630)
Now recall that, for two arbitrary matrices C and D of compatible dimensions, the eigenvalues of the
Kronecker product C ⊗D is formed of all product combinations λi(C)λ j(D) of the eigenvalues of
C and D [19]. We conclude from this property, and from the fact that AT −1
N 11T is stable, that the
coefﬁcient matrix

AT −1
N · 11T

⊗IM

E Comparison with Consensus Strategies
445
is also stable. Therefore,
˜wn →0 as n →∞.
(9.631)
(Necessity). In order for zn in (9.629) to converge to (1 ⊗IM)wo, for any initial state zo, it must hold
that
lim
n→∞(An)T · zo = 1
N ·

1 ⊗IM

· (1T ⊗IM) · zo
(9.632)
for any zo. This implies that we must have
lim
n→∞(An)T = 1
N · (11T ⊗IM)
(9.633)
or, equivalently,
lim
n→∞(An)T = 1
N 11T .
(9.634)
This in turn implies that we must have
lim
n→∞AT · (An)T = AT · 1
N 11T .
(9.635)
But since
lim
n→∞AT · (An)T = lim
n→∞(An+1)T = lim
n→∞(An)T ,
(9.636)
we conclude from (9.634) and (9.635) that it must hold that
1
N 11T = 1
N AT · 11T .
(9.637)
That is,
1
N (AT 1 −1) · 1T = 0
(9.638)
from which we conclude that we must have AT 1 = 1. Similarly, we can show that A1 = 1 by studying
the limit of (An)T AT . Therefore, A must be a doubly stochastic matrix. Now using the fact that A
is doubly stochastic, we know that (9.624) holds. It follows that in order for condition (9.634) to be
satisﬁed, we must have
ρ

AT −1
N 11T

< 1.
(9.639)
□
E.2.2
Rate of convergence
From (9.630) we conclude that the rate of convergence of the error vectors { ˜wk,n} to zero is determined
by the spectrum of the matrix
AT −1
N 11T .
(9.640)

446
CHAPTER 9 Diffusion Adaptation Over Networks
Now since A is a doubly stochastic matrix, we know that it has an eigenvalue at λ = 1. Let us denote
the eigenvalues of A by λk(A) and let us order them in terms of their magnitudes as follows:
0 ≤|λM(A)| ≤· · · ≤|λ3(A)| ≤|λ2(A)| ≤1,
(9.641)
where λ1(A) = 1. Then, the eigenvalues of the coefﬁcient matrix (AT −1
N 11T ) are equal to
{λM(A), . . . , λ3(A), λ2(A), 0}.
(9.642)
It follows that the magnitude of λ2(A) becomes the spectral radius of AT −1
N 11T . Then condition
(9.639) ensures that |λ2(A)| < 1. We therefore arrive at the following conclusion.
Corollary E.1 (Rate of Convergence of Consensus).
Under conditions (9.620)–(9.622), the rate of
convergence of the successive iterates {wk,n} towards the network average wo in the consensus strategy
(9.610) is determined by the second largest eigenvalue magnitude of A, i.e., by |λ2(A)| as deﬁned in
(9.641).
□
It is worth noting that doubly stochastic matrices A that are also regular satisfy conditions (9.620)–
(9.622). This is because, as we already know from Lemma C.2, the eigenvalues of such matrices satisfy
|λm(A)| < 1, for m = 2, 3, . . . , N, so that condition (9.622) is automatically satisﬁed.
Corollary E.2 (Convergence for Regular Combination Matrices).
Any doubly-stochastic and reg-
ular matrix A satisﬁes the three conditions (9.620) −(9.622) and, therefore, ensures the convergence
of the consensus iterates {wk,n} generated by (9.610) towards wo as n →∞.
□
A regular combination matrix A would result when the two conditions listed below are satisﬁed by the
graph connecting the nodes over which the consensus iteration is applied.
Corollary E.3 (Sufﬁcient Condition for Regularity).
Assume the combination matrix A is doubly
stochastic and that the graph over which the consensus iteration (9.610) is applied satisﬁes the following
two conditions:
a. The graph is connected. This means that there exists a path connecting any two arbitrary nodes in
the network. In terms of the Laplacian matrix that is associated with the graph (see Lemma B.1),
this means that the second smallest eigenvalue of the Laplacian is nonzero.
b. aℓk = 0 if, and only if, ℓ/∈Nk. That is, the combination weights are strictly positive between any
two neighbors, including akk > 0.
Then, the corresponding matrix A will be regular and, therefore, the consensus iterates {wk,n} generated
by (9.610) will converge towards wo as n →∞.
Proof.
We ﬁrst establish that conditions (a) and (b) imply that A is a regular matrix, namely, that there
should exist an integer jo > 0 such that
[A jo]ℓk > 0
(9.643)
for all (ℓ, k). To begin with, by the rules of matrix multiplication, the (ℓ, k) entry of the ith power of A
is given by
[Ai]ℓk =
N

m1=1
N

m2=1
. . .
N

mi−1=1
aℓm1am1m2 . . . ami−1k.
(9.644)

E Comparison with Consensus Strategies
447
Thesummandin(9.644)isnonzeroif,andonlyif,thereissomesequenceofindices (ℓ, m1, . . . , mi−1, k)
that forms a path from node ℓto node k. Since the network is assumed to be connected, there exists a
minimum (and ﬁnite) integer value iℓk such that a path exists from node ℓto node k using iℓk edges and
that
[Aiℓk]ℓk > 0.
In addition, by induction, if [Aiℓk]ℓk > 0, then
[Aiℓk+1]ℓk =
N

m=1
[Aiℓk]ℓm amk
≥[Aiℓk]ℓk akk
> 0.
Let
jo =
max
1≤k,ℓ≤N{iℓk}.
Then, property (9.643) holds for all (ℓ, k). And we conclude from (9.581) that A is a regular matrix.
It then follows from Corollary E.2 that the consensus iterates {wk,n} converge to the average network
value wo.
□
E.2.3
Comparison with diffusion strategies
Observe that in comparison to diffusion strategies, such as the ATC strategy (9.153), the consensus
iteration (9.610) employs the same quantities wk,· on both sides of the iteration. In other words, the
consensus construction keeps iterating on the same set of vectors until they converge to the average
value wo. Moreover, the index n in the consensus algorithm is an iteration index. In contrast, diffusion
strategies employ different quantities on both sides of the combination step in (9.153), namely, wk,i and
{ψℓ,i}; the latter variables have been processed through an information exchange step and are updated
(or ﬁltered) versions of the wℓ,i−1. In addition, each step of the diffusion strategy (9.153) can incorporate
new data, {dℓ(i), uℓ,i}, that are collected by the nodes at every time instant. Moreover, the index i in the
diffusion implementation is a time index (and not an iteration index); this is because diffusion strategies
are inherently adaptive and perform online learning. Data keeps streaming in and diffusion incorporates
the new data into the update equations at every time instant. As a result, diffusion strategies are able to
respond to data in an adaptive manner, and they are also able to solve general optimization problems: the
vector wo in adaptive diffusion iterations is the minimizer of a global cost function (cf. (9.92)), while
the vector wo in consensus iterations is the average value of the initial states of the nodes (cf. (9.608)).
It turns out that diffusion strategies inﬂuence the evolution of the network dynamics in an interesting
and advantageous manner in comparison to consensus strategies. We illustrate this point by means of
an example. Consider initially the ATC strategy (9.158) without information exchange, whose update
equation we repeat below for ease of reference:
ψk,i = wk,i−1 + μku∗
k,i[dk(i) −uk,iwk,i−1],
(9.645)
wk,i =

ℓ∈Nk
aℓk ψℓ,i
(ATC diffusion).
(9.646)

448
CHAPTER 9 Diffusion Adaptation Over Networks
These recursions were derived in the body of the chapter as an effective distributed solution for optimiz-
ing (9.92) and (9.93). Note that they involve two steps, where the weight estimator wk,i−1 is ﬁrst updated
to the intermediate estimator ψk,i, before the intermediate estimators from across the neighborhood are
combined to obtain wk,i. Both steps of ATC diffusion (9.645) and (9.646) can be combined into a single
update as follows:
wk,i =

ℓ∈Nk
aℓk[wℓ,i−1 + μℓu∗
ℓ,i(dℓ(i) −uℓ,iwℓ,i−1)]
(ATC diffusion).
(9.647)
Likewise, consider the CTA strategy (9.159) without information exchange, whose update equation we
also repeat below:
ψk,i−1 =

ℓ∈Nk
aℓkwℓ,i−1
(CTA diffusion),
(9.648)
wk,i = ψk,i−1 + μku∗
k,i[dk(i) −uk,iψk,i−1].
(9.649)
Again, the CTA strategy involves two steps: the weight estimators {wℓ,i−1} from the neighborhood of
node k are ﬁrst combined to yield the intermediate estimator ψk,i−1, which is subsequently updated to
wk,i. Both steps of CTA diffusion can also be combined into a single update as follows:
wk,i =

ℓ∈Nk
aℓkwℓ,i−1 + μku∗
k,i
⎡
⎣dk(i) −uk,i

ℓ∈Nk
aℓkwℓ,i−1
⎤
⎦
(CTA diffusion).
(9.650)
Now, motivated by the consensus iteration (9.610), and based on a procedure for distributed opti-
mization suggested in [23] (see expression (7.1) in that reference), some works in the literature (e.g.,
[46,53,82–88]) considered distributed strategies that correspond to the following form for the optimiza-
tion problem under consideration (see, e.g., expression (1.20) in [53] and expression (9) in [87]):
wk,i =

ℓ∈Nk
aℓkwℓ,i−1 + μku∗
k,i[dk(i) −uk,iwk,i−1]
(consensus strategy).
(9.651)
This strategy can be derived by following the same argument we employed earlier in Sections 3.09.3.2
and 3.09.4 to arrive at the diffusion strategies, namely, we replace wo in (9.127) by wℓ,i−1 and then
apply the instantaneous approximations (9.150). Note that the same variable wk,· appears on both sides
of the equality in (9.651). Thus, compared with the ATC diffusion strategy (9.647), the update from
wk,i−1 to wk,i in the consensus implementation (9.651) is only inﬂuenced by data {dk(i), uk,i} from
node k. In contrast, the ATC diffusion structure (9.645), (9.646) helps incorporate the inﬂuence of the
data {dℓ(i), uℓ,i} from across the neighborhood of node k into the update of wk,i, since these data are
reﬂected in the intermediate estimators {ψℓ,i}. Likewise, the contrast with the CTA diffusion strategy
(9.650) is clear, where the right-most term in (9.650) relies on a combination of all estimators from
across the neighborhood of node k, and not only on wk,i−1 as in the consensus strategy (9.651). These
facts have desirable implications on the evolution of the weight-error vectors across diffusion networks.

E Comparison with Consensus Strategies
449
Some simple algebra, similar to what we did in Section 3.09.6, will show that the mean of the extended
error vector for the consensus strategy (9.651) evolves according to the recursion:
E ˜wi = (AT −MRu) · E ˜wi−1,
i ≥0
(consensus strategy),
(9.652)
where Ru is the block diagonal covariance matrix deﬁned by (9.184) and ˜wi is the aggregate error vector
deﬁned by (9.230). We can compare the above mean error dynamics with the ones that correspond to
the ATC and CTA diffusion strategies (9.645), (9.646) and (9.648)–(9.650); their error dynamics follow
as special cases from (9.248) by setting A1 = I = C and A2 = A for ATC and A2 = I = C and
A1 = A for CTA:
E ˜wi = AT (IN M −MRu) · E ˜wi−1,
i ≥0
(ATC diffusion)
(9.653)
and
E ˜wi = (IN M −MRu)AT · E ˜wi−1,
i ≥0
(CTA diffusion).
(9.654)
We observe that the coefﬁcient matrices that control the evolution of E ˜wi are different in all three cases.
In particular,
consensus strategy (9.652) is stable in the mean ⇐⇒ρ(AT −MRu) < 1,
(9.655)
ATC diffusion (9.653) is stable in the mean ⇐⇒ρ[AT (IN M −MRu)] < 1,
(9.656)
CTA diffusion (9.654) is stable in the mean ⇐⇒ρ[(IN M −MRu)AT ] < 1.
(9.657)
It follows that the mean stability of the consensus network is sensitive to the choice of the combination
matrix A. This is not the case for the diffusion strategies. This is because from property (9.605) estab-
lished in Appendix D, we know that the matrices AT (IN M −MRu) and (IN M −MRu)AT are stable
if (IN M −MRu) is stable. Therefore, we can select the step-sizes to satisfy μk < 2/λmax(Ru,k) for the
ATC or CTA diffusion strategies and ensure their mean stability regardless of the combination matrix
A. This also means that the diffusion networks will be mean stable whenever the individual nodes are
mean stable, regardless of the topology deﬁned by A. In contrast, for consensus networks, the network
can exhibit unstable mean behavior even if all its individual nodes are stable in the mean. For further
details and other results on the mean-square performance of diffusion networks in relation to consensus
networks, the reader is referred to [89,90].
Acknowledgments
The development of the theory and applications of diffusion adaptation over networks has beneﬁted greatly from
the insights and contributions of several UCLA Ph.D. students, and several visiting graduate students to the UCLA
Adaptive Systems Laboratory (http://www.ee.ucla.edu/asl). The assistance and contributions of all students are
hereby gratefully acknowledged, including Cassio G. Lopes, Federico S. Cattivelli, Sheng-Yuan Tu, Jianshu Chen,
Xiaochuan Zhao, Zaid Towﬁc, Chung-Kai Yu, Noriyuki Takahashi, Jae-Woo Lee, Alexander Bertrand, and Paolo
Di Lorenzo. The author is also particularly thankful to S.-Y. Tu, J. Chen, X. Zhao, Z. Towﬁc, and C.-K. Yu for their
assistance in reviewing an earlier draft of this chapter.

450
CHAPTER 9 Diffusion Adaptation Over Networks
References
[1] J. Chen, A.H. Sayed, On the limiting behavior of distributed optimization strategies, in: Proc. 50th Annual
Allerton Conference on Communication, Control, and Computing, Allerton, IL, October 2012, pp. 1535–1542.
[2] J. Chen, A.H. Sayed, Diffusion adaptation strategies for distributed optimization and learning over networks,
IEEE Trans. Signal Process. 60 (8) (2012) 4289–4305.
[3] J. Chen, A.H. Sayed, Distributed Pareto optimization via diffusion strategies, IEEE J. Sel. Top. Signal Process.
7 (2) (2013) 205–220.
[4] A.H. Sayed, Fundamentals of Adaptive Filtering, Wiley, NJ, 2003.
[5] A.H. Sayed, Adaptive Filters, Wiley, NJ, 2008.
[6] S. Haykin, Adaptive Filter Theory, Prentice Hall, NJ, 2002.
[7] B. Widrow, S.D. Stearns, Adaptive Signal Processing, Prentice Hall, NJ, 1985.
[8] S.-Y. Tu, A.H. Sayed, Mobile adaptive networks, IEEE J. Sel. Top. Signal Process. 5 (4) (2011) 649–664.
[9] F. Cattivelli, A.H. Sayed, Modeling bird ﬂight formations using diffusion adaptation, IEEE Trans. Signal
Process. 59 (5) (2011) 2038–2051.
[10] J. Li, A.H. Sayed, Modeling bee swarming behavior through diffusion adaptation with asymmetric information
sharing, EURASIP J. Adv. Signal Process. 2012 (18) 2012, doi:10.1186/1687-6180-2012-18.
[11] J. Chen, A.H. Sayed, Bio-inspired cooperative optimization with application to bacteria motility, in: Proceed-
ings of the ICASSP, Prague, Czech Republic, May 2011, pp. 5788–5791.
[12] A.H. Sayed, F.A. Sayed, Diffusion adaptation over networks of particles subject to Brownian ﬂuctuations, in:
Proceedings of the Asilomar Conference on Signals, Systems, and Computers, Paciﬁc Grove, CA, November
2011, pp. 685–690.
[13] J. Mitola, G.Q. Maguire, Cognitive radio: making software radios more personal, IEEE Personal Commun. 6
(1999) 13–18.
[14] S. Haykin, Cognitive radio: brain-empowered wireless communications, IEEE J. Sel. Areas Commun. 23 (2)
(2005) 201–220.
[15] Z. Quan, W. Zhang, S.J. Shellhammer, A.H. Sayed, Optimal spectral feature detection for spectrum sensing
at very low SNR, IEEE Trans. Commun. 59 (1) (2011) 201–212.
[16] Q. Zou, S. Zheng, A.H. Sayed, Cooperative sensing via sequential detection, IEEE Trans. Signal Process. 58
(12) (2010) 6266–6283.
[17] P. Di Lorenzo, S. Barbarossa, A.H. Sayed, Bio-inspired swarming for dynamic radio access based on diffusion
adaptation, in: Proceedings of the EUSIPCO, Barcelona, Spain, August 2011, pp. 402–406.
[18] F.S. Cattivelli, A.H. Sayed, Diffusion LMS strategies for distributed estimation, IEEE Trans. Signal Process.
58 (3) (2010) 1035–1048.
[19] G.H. Golub, C.F. Van Loan, Matrix Computations, third ed., The John Hopkins University Press, Baltimore,
1996.
[20] R.A. Horn, C.R. Johnson, Matrix Analysis, Cambridge University Press, 2003.
[21] E. Kreyszig, Introductory Functional Analysis with Applications, Wiley, NY, 1989.
[22] B. Poljak, Introduction to Optimization, Optimization Software, NY, 1987.
[23] D.P. Bertsekas, J.N. Tsitsiklis, Parallel and Distributed Computation: Numerical Methods, ﬁrst ed., Athena
Scientiﬁc, Singapore, 1997.
[24] D.P. Bertsekas, A new class of incremental gradient methods for least squares problems, SIAM J. Optim. 7
(4) (1997) 913–926.
[25] A.Nedic,D.P.Bertsekas,Incrementalsubgradientmethodsfornondifferentiableoptimization,SIAMJ.Optim.
12 (1) (2001) 109–138.

References
451
[26] M.G. Rabbat, R.D. Nowak, Quantized incremental algorithms for distributed optimization, IEEE J. Sel. Areas
Commun. 23 (4) (2005) 798–808.
[27] C.G. Lopes, A.H. Sayed, Incremental adaptive strategies over distributed networks, IEEE Trans. Signal
Process. 55 (8) (2007) 4064–4077.
[28] F.S. Cattivelli, A.H. Sayed, Diffusion LMS algorithms with information exchange, in: Proceedings of the
Asilomar Conference on Signals, Systems and Computers, Paciﬁc Grove, CA, November 2008, pp. 251–255.
[29] C.G. Lopes, A.H. Sayed, Distributed processing over adaptive networks, in: Proceedings of the Adaptive
Sensor Array Processing Workshop, MIT Lincoln Laboratory, MA, June 2006, pp. 1–5.
[30] A.H. Sayed, C.G. Lopes, Adaptive processing over distributed networks, IEICE Trans. Fund. Electron. Com-
mun. Comput. Sci. E90-A (8) (2007) 1504–1510.
[31] C.G. Lopes, A.H. Sayed, Diffusion least-mean-squares over adaptive networks, in: Proceedings of the IEEE
ICASSP, Honolulu, Hawaii, vol. 3, 2007, pp. 917–920.
[32] C.G. Lopes, A.H. Sayed, Steady-state performance of adaptive diffusion least-mean squares, in: Proceedings
of the IEEE Workshop on Statistical Signal Processing (SSP), Madison, WI, August 2007, pp. 136–140.
[33] C.G. Lopes, A.H. Sayed, Diffusion least-mean squares over adaptive networks: Formulation and performance
analysis, IEEE Trans. Signal Process. 56 (7) (2008) 3122–3136.
[34] A.H. Sayed, F. Cattivelli, Distributed adaptive learning mechanisms, in: S. Haykin, K.J. Ray Liu (Eds.),
Handbook on Array Processing and Sensor Networks, Wiley, NJ, 2009, pp. 695–722.
[35] F. Cattivelli, A.H. Sayed, Diffusion strategies for distributed Kalman ﬁltering and smoothing, IEEE Trans.
Autom. Control 55 (9) (2010) 2069–2084.
[36] S.S. Ram, A. Nedic, V.V. Veeravalli, Distributed stochastic subgradient projection algorithms for convex
optimization, J. Optim. Theory Appl. 147 (3) (2010) 516–545.
[37] P. Bianchi, G. Fort, W. Hachem, J. Jakubowicz, Convergence of a distributed parameter estimator for sensor
networks withlocal averagingof theestimates, in: Proceedings of theIEEE ICASSP, Prague, Czech, May2011,
pp. 3764–3767.
[38] F.S. Cattivelli, C.G. Lopes, A.H. Sayed, A diffusion RLS scheme for distributed estimation over adaptive
networks, in: Proceedings of the IEEE Workshop on Signal Processing Advances Wireless Communications
(SPAWC), Helsinki, Finland, June 2007, pp. 1–5.
[39] F.S. Cattivelli, C.G. Lopes, A.H. Sayed, Diffusion recursive least-squares for distributed estimation over
adaptive networks, IEEE Trans. Signal Process. 56 (5) (2008) 1865–1877.
[40] F.S. Cattivelli, C.G. Lopes, A.H. Sayed, Diffusion strategies for distributed Kalman ﬁltering: formulation
and performance analysis, in: Proceedings of the IAPR Workshop on Cognitive Information Process. (CIP),
Santorini, Greece, June 2008, pp. 36–41.
[41] F.S. Cattivelli, A.H. Sayed, Diffusion mechanisms for ﬁxed-point distributed Kalman smoothing, in: Proceed-
ings of the EUSIPCO, Lausanne, Switzerland, August 2008, pp. 1–4.
[42] S.S. Stankovic, M.S. Stankovic, D.S. Stipanovic, Decentralized parameter estimation by consensus based
stochastic approximation, IEEE Trans. Autom. Control 56 (3) (2011) 531–543.
[43] M.H. DeGroot, Reaching a consensus, J. Am. Stat. Assoc. 69 (345) (1974) 118–121.
[44] R.L. Berger, A necessary and sufﬁcient condition for reaching a consensus using DeGroot’s method, J. Am.
Stat. Assoc. 76 (374) (1981) 415–418.
[45] J. Tsitsiklis, M. Athans, Convergence and asymptotic agreement in distributed decision problems, IEEE Trans.
Autom. Control 29 (1) (1984) 42–50.
[46] A. Jadbabaie, J. Lin, A.S. Morse, Coordination of groups of mobile autonomous agents using nearest neighbor
rules, IEEE Trans. Autom. Control 48 (6) (2003) 988–1001.
[47] R. Olfati-Saber, R.M. Murray, Consensus problems in networks of agents with switching topology and time-
delays, IEEE Trans. Autom. Control 49 (2004) 1520–1533.

452
CHAPTER 9 Diffusion Adaptation Over Networks
[48] R. Olfati-Saber, Distributed Kalman ﬁlter with embedded consensus ﬁlters, in: Proceedings of the 44th IEEE
Conference Decision Control, Sevilla, Spain, December 2005, pp. 8179–8184.
[49] R. Olfati-Saber, Distributed Kalman ﬁltering for sensor networks, in: Proceedings of the 46th IEEE Conference
Decision Control, New Orleans, LA, December 2007, pp. 5492–5498.
[50] L. Xiao, S. Boyd, Fast linear iterations for distributed averaging, Syst. Control Lett. 53 (1) (2004) 65–78.
[51] L. Xiao, S. Boyd, S. Lall, A scheme for robust distributed sensor fusion based on average consensus, in:
Proceedings of the IPSN, Los Angeles, CA, April 2005, pp. 63–70.
[52] U.A. Khan, J.M.F. Moura, Distributing the Kalman ﬁlter for large-scale systems, IEEE Trans. Signal Process.
56 (10) (2008) 4919–4935.
[53] A. Nedic, A. Ozdaglar, Cooperative distributed multi-agent optimization, in: Y. Eldar, D. Palomar (Eds.),
Convex Optimization in Signal Processing and Communications, Cambridge University Press, 2010,
pp. 340–386.
[54] S. Boyd, L. Vandenberghe, Convex Optimization, Cambridge University Press, 2004.
[55] T.Y. Al-Naffouri, A.H. Sayed, Transient analysis of data-normalized adaptive ﬁlters, IEEE Trans. Signal
Process. 51 (3) (2003) 639–652.
[56] V.D. Blondel, J.M. Hendrickx, A. Olshevsky, J.N. Tsitsiklis, Convergence in multiagent coordination, consen-
sus, and ﬂocking, in: Proceedings of the Joint 44th IEEE Conference on Decision and Control and European
Control Conference (CDC-ECC), Seville, Spain, December 2005, pp. 2996–3000.
[57] D.S. Scherber, H.C. Papadopoulos, Locally constructed algorithms for distributed computations in ad-hoc
networks, in: Proceedings of the Information Processing in Sensor Networks (IPSN), Berkeley, CA, April
2004, pp. 11–19.
[58] N. Metropolis, A.W. Rosenbluth, M.N. Rosenbluth, A.H. Teller, E. Teller, Equations of state calculations by
fast computing machines, J. Chem. Phys. 21 (6) (1953) 1087–1092.
[59] W.K. Hastings, Monte Carlo sampling methods using Markov chains and their applications, Biometrika 57
(1) (1970) 97–109.
[60] D.M. Cvetkovi´c, M. Doob, H. Sachs, Spectra of Graphs: Theory and Applications, Wiley, NY, 1998.
[61] B. Bollobas, Modern Graph Theory, Springer, 1998.
[62] W. Kocay, D.L. Kreher, Graphs, Algorithms and Optimization, Chapman & Hall/CRC Press, Boca Raton,
2005.
[63] N. Takahashi, I. Yamada, A.H. Sayed, Diffusion least-mean-squares with adaptive combiners: formulation
and performance analysis, IEEE Trans. Signal Process. 9 (2010) 4795–4810.
[64] S.-Y. Tu, A.H. Sayed, Optimal combination rules for adaptation and learning over networks, in: Procee-
ings of the IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing
(CAMSAP), San Juan, Puerto Rico, December 2011, pp. 317–320.
[65] X. Zhao, S.-Y. Tu, A.H. Sayed, Diffusion adaptation over networks under imperfect information exchange
and non-stationary data, IEEE Trans. Signal Process. 60 (7) (2012) 3460–3475.
[66] R. Abdolee, B. Champagne, Diffusion LMS algorithms for sensor networks over non-ideal inter-sensor wire-
less channels, in: Proceedings of the IEEE Int. Conference on Distributed Computing in Sensor Systems
(DCOSS), Barcelona, Spain, June 2011, pp. 1–6.
[67] A. Khalili, M.A. Tinati, A. Rastegarnia, J.A. Chambers, Steady state analysis of diffusion LMS adaptive
networks with noisy links, IEEE Trans. Signal Process. 60 (2) (2012) 974–979.
[68] S.-Y. Tu, A.H. Sayed, Adaptive networks with noisy links, in: Proceedings of the IEEE Globecom, Houston,
TX, December 2011, pp. 1–5.
[69] X. Zhao, A.H. Sayed, Combination weights for diffusion strategies with imperfect information exchange, in:
Proceedings of the IEEE ICC, Ottawa, Canada, June 2012, pp. 1–5.
[70] J.-W. Lee, S.-E. Kim, W.-J. Song, A.H. Sayed, Spatio-temporal diffusion mechanisms for adaptation over
networks, in: Proceedings of the EUSIPCO, Barcelona, Spain, August–September 2011, pp. 1040–1044.

References
453
[71] J.-W. Lee, S.-E. Kim, W.-J. Song, A.H. Sayed, Spatio-temporal diffusion strategies for estimation and detection
over networks, IEEE Trans. Signal Process. 60 (8) (2012) 4017–4034.
[72] S. Chouvardas, K. Slavakis, S. Theodoridis, Adaptive robust distributed learning in diffusion sensor networks,
IEEE Trans. Signal Process. 59 (10) (2011) 4692–4707.
[73] K. Slavakis, Y. Kopsinis, S. Theodoridis, Adaptive algorithm for sparse system identiﬁcation using projections
onto weighted ℓ1 balls, in: Proceedings of the IEEE ICASSP, Dallas, TX, March 2010, pp. 3742–3745.
[74] A.H. Sayed, C.G. Lopes, Distributed recursive least-squares strategies over adaptive networks, in: Proceedings
of Asilomar Conference on Signals, Systems and Computers, Paciﬁc Grove, CA, October–November 2006,
pp. 233–237.
[75] L. Xiao, S. Boyd, S. Lall, A space-time diffusion scheme peer-to-peer least-squares-estimation, in: Proceedings
of the Information Processing in Sensor Networks (IPSN), Nashville, TN, April 2006, pp. 168–176.
[76] T. Kailath, A.H. Sayed, B. Hassibi, Linear Estimation, Prentice Hall, NJ, 2000.
[77] F. Cattivelli, A.H. Sayed, Diffusion distributed Kalman ﬁltering with adaptive weights, in: Proceedings of the
Asilomar Conference on Signals, Systems and Computers, Paciﬁc Grove, CA, November 2009, pp. 908–912.
[78] A. Nedic, A. Ozdaglar, Distributed subgradient methods for multi-agent optimization, IEEE Trans. Autom.
Control 54 (1) (2009) 48–61.
[79] D.P. Bertsekas, J.N. Tsitsiklis, Gradient convergence in gradient methods with errors, SIAM J. Optim. 10 (3)
(2000) 627–642.
[80] M. Fiedler, Algebraic connectivity of graphs, Czech. Math. J. 23 (1973) 298–305.
[81] N. Takahashi, I. Yamada, Parallel algorithms for variational inequalities over the cartesian product of the
intersections of the ﬁxed point sets of nonexpansive mappings, J. Approx. Theory 153 (2) (2008) 139–160.
[82] S. Barbarossa, G. Scutari, Bio-inspired sensor network design, IEEE Signal Process. Mag. 24 (3) (2007)
26–35.
[83] R. Olfati-Saber, Kalman-consensus ﬁlter: optimality, stability, and performance, in: Proceedings of the IEEE
CDC, Shangai, China, 2009, pp. 7036–7042.
[84] I.D. Schizas, G. Mateos, G.B. Giannakis, Distributed LMS for consensus-based in-network adaptive process-
ing, IEEE Trans. Signal Process. 57 (6) (2009) 2365–2382.
[85] G. Mateos, I.D. Schizas, G.B. Giannakis, Performance analysis of the consensus-based distributed LMS
algorithm, EURASIP J. Adv. Signal Process. (2009) 1–19.
[86] S. Kar, J.M.F. Moura, Distributed consensus algorithms in sensor networks: link failures and channel noise,
IEEE Trans. Signal Process. 57 (1) (2009) 355–369.
[87] S. Kar, J.M.F. Moura, Convergence rate analysis of distributed gossip (linear parameter) estimation: funda-
mental limits and tradeoffs, IEEE J. Sel. Top. Signal Process. 5 (4) (2011) 674–690.
[88] A.G. Dimakis, S. Kar, J.M.F. Moura, M.G. Rabbat, A. Scaglione, Gossip algorithms for distributed signal
processing, Proc. IEEE 98 (11) (2010) 1847–1864.
[89] S.-Y. Tu, A.H. Sayed, Diffusion networks outperform consensus networks, in: Proceedings of the IEEE
Statistical Signal Processing Workshop, Ann Arbor, Michigan, August 2012, pp. 313–316.
[90] S.-Y. Tu, A.H. Sayed, Diffusion strategies outperform consensus strategies for distributed estimation over
adaptive networks, IEEE Trans. Signal Process. 60 (12) (2012) 6217–6234.

10
CHAPTER
Array Signal Processing: Overview
of the Included Chapters
Mats Viberg
Department of Signals and Systems, Chalmers University of Technology, Göteborg, Sweden
3.10.1 Some history
The ﬁrst Radio Direction Finding system was patented in the early 20th century [1]. The idea was
to compare the signal strength from a direction-sensitive antenna when it was “steered” in different
directions. The main application of the technology was maritime and aircraft navigation, but being able
to localize incoming signal energy also found other civilian and military uses. It was soon realized that
the performance could be signiﬁcantly enhanced by employing an array of spatially separated antennas.
The outputs of the antennas were combined to increase the directionality of the antenna system, which
also enabled localization of multiple spatially separated signal sources. During the 1930s, the radio
localization was further developed by actively transmitting signal energy in narrow lobes [2]. The
return signal was monitored, and a high energy indicated that some object was present. The system
is known as RAdio Detection And Ranging (RADAR), and the use of coherently combined array
antennas can be considered the birth of Array Signal Processing. Since the early days, the technology
has spread to a variety of sensor types as well as application areas. Electronically steered antenna arrays
are used in mobile communication systems, to provide both increased range and directional ﬁltering
(sectorization). During the last decade or so, more “intelligent” use of adaptive antenna technology
at both the transmit and the receiving ends (MIMO systems) has started to revolutionize wireless
communications by offering both vastly improved capacity and interference resilience. Acoustic sensors
are used in the air (microphone arrays), underwater (SONAR), as well as in the ground for earthquake
monitoring. Furthermore, the mathematical algorithms developed in array signal processing have found
use in several other ﬁelds, not necessarily involving sensor arrays. All these developments motivate a
separate section on Array Signal Processing in the present electronic reference publication.
3.10.2 Summary of the included chapters
Array Signal Processing is a rather generic area, and it is not clear how to draw the borderlines to
neighboring areas such as Statistical Signal Processing, Wireless Communications, Radar, and Acoustic
Signal Processing. Some coordination between the corresponding sections has been necessary, and much
related work will therefore be found also in other sections. We have tried to make a balanced selection
between theory and applications and not focusing on any particular sensor type. Thus, most of the
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00010-2
© 2014 Elsevier Ltd. All rights reserved.
457

458
CHAPTER 10 Array Signal Processing: Overview of the Included Chapters
chapters present generic array signal processing techniques that are broadly applicable. Yet, we are
happy to have the two last chapters giving some hints on how these methods need to be modiﬁed when
faced with various practical aspects as well as speciﬁc application demands.
3.10.2.1 Introduction to Array Processing
The ﬁrst chapter by Mats Viberg gives an expanded introduction to the area of Array Signal Processing.
Themathematicalmodelingofcoherentarraydataisgivenspecialattentionaswellasthebasicproperties
of sensor arrays from a spatial ﬁltering point of view. This includes the inherent properties of a given
sensor array as well as shaping of the response using beamforming. Several array geometries in one
and two dimensions are considered as well as the effect of bandwidth. The chapter then gives a short
introduction to Direction-Of-Arrival (DOA) estimation using a passive listening array followed by some
examples of non-coherent array signal processing applications.
3.10.2.2 Adaptive and Robust Beamforming
The chapter by Sergiy A. Vorobyov further elaborates on the issues of adaptive and robust beamforming.
The chapter is dedicated to the memory of Alex B. Gershman, who was a major contributor in these ﬁelds
as well as several other array signal processing related topics. The received data is assumed to contain
a desired signal corrupted by interference and noise, and most designs are based on maximizing the
Signal-to-Interference-plus-Noise Ratio (SINR) or some equivalent measure. Time-recursive solutions
are introduced as approximations of the exact data-adaptive beamformers. The chapter also presents
several formulations to make beamforming less susceptible to small sample support (data-adaptive
approaches), to correlated interference as well as to imperfectly known array responses. Classical
constrained beamforming techniques are considered as well as more recent approaches based on convex
optimization.
3.10.2.3 Broadband Beamforming and Optimization
This chapter by Sven E. Nordholm, Hai H. Dam, Chiong C. Lai, and Eric A. Lehmann explores the
concept of spatial ﬁltering using beamforming in some detail. A particular concern is applications
where there is a demand for broadband operation, such as acoustic microphone and SONAR arrays.
The chapter gives an insightful physical background to modeling of broadband data using two different
approaches: aperture theory and solution of the wave equation in the frequency domain. For both of
these models, various optimization approaches are presented for broadband beamforming, which is
actually a multi-channel ﬁlter design. Robustness to deviations from the assumed ideal model is also
considered. The chapter gives several illustrative design examples.
3.10.2.4 DOA Estimation Methods and Algorithms
Originating in passive radio direction ﬁnding more than a century ago, Direction-Of-Arrival estimation
is now a fairly mature research area, and a vast plethora of algorithms has appeared in the literature.
The chapter by Pei-Jung Chung, Mats Viberg, and Jia Yu presents a comprehensive overview of both
classical spectral-based methods and parametric approaches. Since the latter often involves solving
a computationally expensive optimization problem, the most popular algorithmic solutions are brieﬂy

3.10.2 Summary of the Included Chapters
459
surveyed.Thepracticalissuesofwidebanddataandnumberofsignalsdetectionareaddressedinseparate
sections. The chapter ends with a list of special topics with references to more detailed treatments.
3.10.2.5 Subspace Methods and Exploitation of Special Array Structures
One of the most inﬂuential outcomes of Array Signal Processing research is subspace methods. These
exploit an inherent low-rank structure of the array covariance matrix in order to enhance the SNR prior
to further processing, thus signiﬁcantly improving the DOA estimation performance. The methods
have been extended to several other research areas, most notably subspace-based system identiﬁcation
and blind channel estimation and equalization to name a few. The chapter by Martin Haardt, Marius
Pesavento, Florian Roemer, and M. Nabil El Korso gives a comprehensive exposure of subspace meth-
ods, with a special emphasis of computationally efﬁcient algorithms that exploit special array geome-
tries. The chapter also introduces the emerging area of tensor-based array processing, which involves
modeling and processing higher dimensional data.
3.10.2.6 Performance Bounds and Statistical Analysis of DOA Estimation
In most practical estimation problems involving a ﬁnite set of noisy data, the statistical properties of a
given DOA estimate are of major concern. Indeed, the choice of an estimator typically involves trading
performance for computational simplicity. The chapter by Jean Pierre Delmas focuses on fundamental
performance bounds for a given data model, and it introduces the main tools for analyzing a given
DOA estimation algorithm. The analysis assumes a large enough data set, so that the DOA estimate
can be linearly related to a certain ﬁnite statistic, whose statistical moments can be easily derived.
The analysis is carried out for a few key algorithms, including beamforming, maximum likelihood, and
some subspace-based techniques. A key issue in DOA estimation is resolution of closely spaced sources,
since most methods perform similarly when the sources are well separated. Thus, the chapter ﬁnishes
with a special study of DOA estimation performance in the context of two closely spaced sources, and
shows how statistical analysis can be useful for predicting the resolution capability of a given algorithm.
3.10.2.7 DOA Estimation of Nonstationary Signals
Many applications of practical interest involve nonstationary signals. An illustrative example is the
ultrasonic localization system employed by bats, which uses a narrowband signal with time-varying
frequency. Similarly, many practical radar systems use linear frequency modulation to provide resolution
in both range and speed (Doppler). The chapter by Moeness G. Amin and Yimin D. Zhang focuses on
DOA estimation using nonstationary signal models. The main tool is the Spatial Time-Frequency Distri-
bution (STFD), which is a generalization of the classical Cohen class of time-frequency distributions. It
is shown how nonstationary space-time ﬁltering using the STFD can enhance the SNR, much in the same
way as subspace methods do for stationary data. The chapter shows how “standard” DOA estimation
methods can be applied using the STFD framework, resulting in signiﬁcantly enhanced performance as
compared to not taking the nonstationary nature of the data into account. A more recent development
of joint DOA and Direction-Of-Departure estimation using Multiple Input Multiple Output (MIMO)
radar data is also presented.

460
CHAPTER 10 Array Signal Processing: Overview of the Included Chapters
3.10.2.8 Source Localization and Tracking
The classical DOA estimation problem uses coherent data sampled by an array of sensors. The chapter
by Yu-Hen Hu considers the related but different problems of source localization using non-coherent
sensor data. Each sensor, which itself could be an array of coherent sensor elements, locally processes
the received data, producing measurements of the received signal strength, distance to the signal source,
and/or angle of arrival. These local measurements are then used at some fusion center for estimating
the xy-coordinates of the transmitter. The simplest and most well-known technique is triangulation,
based on angle-of-arrival measurements. More generally, techniques based on linear or non-linear least-
squares and Bayesian estimation are employed. The chapter also introduces the problem of tracking of
nonstationary targets.
3.10.2.9 Array Processing in the Face of Nonidealities
All high resolution DOA estimation methods are based on a precise mathematical model of the received
array data. In practice, such a model is often obtained by measuring the array response to distant sources
at known locations, i.e., array calibration, and the model is at best a good approximation of the reality.
The chapter by Visa Koivunen, Mário Costa, and Mats Viberg considers DOA estimation in the absence
of a perfectly known array model. The most common sources of error are ﬁrst introduced and their
detrimental effects are explained. Given array calibration data, two main approaches are then presented.
The ﬁrst assumes a parametric model for the array response, and the unknown parameters are estimated
using the calibration data. The second approach is based on array interpolation and wave ﬁeld modeling.
A particularly attractive feature of the latter approach is that an approximate model of the array response
is obtained that resembles that of a Uniform Linear Array (ULA). Thus, the various computationally
attractive methods for DOA estimation using a ULA (see Section 3.10.2.5) can be applied to arbitrary
arrays using only samples of the array response at known directions.
3.10.2.10 Applications of Array Signal Processing
The fact that Array Signal Processing has been highly inﬂuential in other ﬁelds than DOA estimation
using passive listening arrays is very well illustrated in the chapter by A. Lee Swindlehurst, Brian D.
Jeffs, Gonzalo Seco-Granados, and Jian Li. Though not claiming to be exhaustive, the chapter presents
an impressive set of practical engineering applications where array signal processing plays a key role.
First, active sensing using radar is considered, and several special issues such as Space-Time Adaptive
Processing (STAP) and MIMO radar are explored. Next, applications in radio astronomy are consid-
ered, where the objective is to observe signals from distant stars, pulsars, galaxies, and even black
holes. The “sensor arrays” may in this case cover a whole continent. The chapter then presents the prob-
lem of positioning and navigation using a Global Navigation Satellite System (GNSS) from an array
processing perspective. Next, the use of space-time coding technology in MIMO wireless communi-
cation for improving the communication performance by diversity and/or multiplexing is explained.
Several biomedical applications are then introduced, using ultrasonic data as well as EEG/MEG. The
chapter then surveys acoustic applications underwater (SONAR) and in the air (microphone arrays).
Finally, a more recent application of array signal processing using chemical sensor arrays is described.
The objective is to detect, for example, a chemical spill, and the main difference to “normal” array
processing is that the propagation is governed by diffusion rather than the wave equation.

References
461
3.10.3 Outlook
While array signal processing has been around for several decades, there is still much important ongoing
research, see, e.g., [3]. Much of the theoretical work is related to sparse signal modeling and estimation.
This can ﬁt into the standard array processing framework by sampling the array response on a dense grid.
Given a limited number of point sources, the received data can then be modeled as a linear combination of
arelativelysmallsetofbasisfunctions,i.e.,asparserepresentation.Wemayalsoexpecttoseemoreappli-
cations of compressive sampling technology in array signal processing, just as subspace methods and
other array signal processing algorithms are used to recover data in compressed sensing (see, e.g., [4]).
An area which has seen much theoretical advancements in the last few decades is distributed pro-
cessing and localization (see also Section 3.10.2.8). This has been much driven by military applications,
but more recently the potential to use wireless sensor networks in vehicle safety applications has been
explored [5]. Besides short-term safety systems, one can also expect this to be useful for large-scale
trafﬁc control in the future. Other areas where theoretical work has paved the way for engineering appli-
cations are MIMO systems, both for wireless communication and radar. In communication, MIMO is
already part of the recent standards, but an area yet to be explored in practice is large-scale MIMO [6].
Similarly, the theoretical advantages of MIMO radar over standard phased array radar [7] are yet to
manifest itself in commercial products.
Finally, as illustrated in the chapter by Swindlehurst et al., theory and methods from array signal
processing have found their way into a rich plethora of other areas, and we can expect this quest to
continue well into the future. An emerging area of great interest is microwave-based imaging, which
has been used in biomedical applications such as breast cancer detection [8]. The same technology may
prove useful in a variety of monitoring applications in the process industry [9]. This has already resulted
in commercial products for the food industry, but we look forward to an interesting development in other
branches with similar needs for resolution in time and space and at the same time penetration beneath
the surface of the matter under investigation.
References
[1] J. Dellinger, Principles of Radio Transmission and Reception with Antenna and Coil Aerials, Govt. Print. Off.,
1919, No. 330–368 (Online). <http://books.google.se/books?id=7rrA5ZFH3gUC>.
[2] L. Brown, A Radar History of World War II: Technical and Military Perspectives, IOP Publishing Ltd., Bristol,
UK, 1999.
[3] J. Li, B. Sadler, M. Viberg, Sensor array and multichannel signal processing [in the spotlight], IEEE Signal
Process. Mag. 28 (5) (2011) 157–158.
[4] K. Gedalyahu, Y. Eldar, Time-delay estimation from low-rate samples: a union of subspaces approach, IEEE
Trans. Signal Process. 58 (6) (2010) 3017–3031.
[5] S. Biswas, R. Tatchikou, F. Dion, Vehicle-to-vehicle wireless communication protocols for enhancing highway
trafﬁc safety, IEEE Commun. Mag. 44 (1) (2006) 74–82.
[6] F. Rusek, D. Persson, B. Lau, E. Larsson, T. Marzetta, O. Edfors, F. Tufvesson, Scaling up MIMO: opportunities
and challenges with very large arrays, IEEE Signal Process. Mag. 30 (1) (2013) 40–60.
[7] J. Li, P. Stoica, MIMO radar with colocated antennas, IEEE Signal Process. Mag. 24 (5) (2007) 106–114.

462
CHAPTER 10 Array Signal Processing: Overview of the Included Chapters
[8] E. Fear, S. Hagness, P. Meaney, M. Okoniewski, M. Stuchly, Enhancing breast tumor detection with near-ﬁeld
imaging, IEEE Microwave Mag. 3 (1) (2002) 48–56.
[9] Z. Wu, A.H. Boughriet, H. McCann, L.E. Davis, A.T. Nugroho, Investigation of microwave tomographic
imaging techniques for industrial processes, in: Proceedings of the SPIE 4188, Process Imaging for Automatic
Control, Boston, MA, November 2001, pp. 151–158.

11
CHAPTER
Introduction to Array Processing⋆
Mats Viberg
Department of Signals and Systems, Chalmers University of Technology,G¨oteborg, Sweden
3.11.1 Introduction
Array processing generally deals with signal processing applications using an array of spatially separated
sensors of the same type. These sensors typically sample an incoming wave-ﬁeld generated by far-ﬁeld
emitters. As such, the area dates back to the early use of radars about a century ago, and in particular to
microwave Phased Arrays in the 1950s [1]. Today, the processing of sensor array data is mainly done
using Digital Signal Processing (DSP). This has opened up a vast ﬂora of opportunities, and the area
has found a rich plethora of engineering applications over the past several decades. Just like radar uses
electromagnetic (EM) antennas in the air, sonar arrays are used underwater to localize distant objects
[2,3], either by passive listening or by actively transmitting waveforms and analyzing the return echo.
Both antenna arrays and sonar arrays are also employed in communication applications, where the
purpose is to transmit and receive messages over long distances in the presence of severe interference
[4,5]. Other types of sensors include microphone, ultrasound and infrared sensors used in air. An
emerging technology over the past decade or so is sensor networks, where sensors are distributed over
a wide area. The purpose is generally to monitor the environment and/or to localize a certain signal
source [6].
In classical radar and sonar applications, the sensor array is used to focus and steer the energy of
a signal in the spatial domain, so that a potential target return is enhanced in favor of surrounding
interference, clutter and noise. On transmit, this is done by distributing the signal waveform over the
various sensor elements with suitable time delays, which will make the energy from all sensors add
coherently in the desired (look) direction, while it is attenuated in other directions. The same technique
is used on receive, by ﬁrst applying the same time delays the sensor outputs, and then summing the
result. The result can be interpreted as a matched ﬁlter to a hypothesized signal arriving from the look
direction. This “scalar” way of processing the signal is referred to as beam forming, and it is the spatial
equivalent of temporal Finite Impulse Response (FIR) ﬁltering. The performance of this approach in
terms of resolution and interference suppression capability depends critically on the number of sensor
elements and the physical size (aperture) of the array. More elaborate ﬁlter functions can be designed
to avoid some of the drawbacks of the classical beamformer or matched ﬁlter, and this is the subject
of Chapters 13 and 20 of this book. Although this is very useful, in particular in applications involving
⋆This work was supported in part by the Swedish Foundation for Strategic Research within the Strategic Research Center
Charmant.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00011-4
© 2014 Elsevier Ltd. All rights reserved.
463

464
CHAPTER 11 Introduction to Array Processing
transmission or reception of scalar signals, more ﬂexibility is offered by treating the sensor elements
separately. Sampling the individual sensor outputs allows for applying more sophisticated digital signal
processing algorithms that take full advantage of the multidimensional nature of the array outputs.
In particular, a physical model of the array output can be exploited to enable, for example, accurate
localization of multiple closely-spaced signal sources [7,8]. In particular, the invention of so-called
subspace methods [9,10] sparked a tremendous interest in Direction-of-Arrival (DOA) estimation, and
a plethora of algorithms were developed. Given the importance of this topic in array signal processing,
several chapters in the current book are devoted to DOA estimation: Chapter 15 gives more details on
subspace methods and in particular how to take advantage of special array structures, Chapter 14 gives a
general survey of DOA estimation algorithms, Chapter 17 presents methods designed for non-stationary
signals, Chapter 19 treats estimation with real-world arrays and Chapter 16 concerns statistical accuracy
aspects.
In applications involving active transmission, the classical way is to transmit a coherent wavefront
as alluded to above. However, the sensors can be treated individually also in transmit arrays. Thus,
in the so-called MIMO (Multiple Input Multiple Output) technology, the sensors transmit different
(often orthogonal) signal waveforms, and the individual sensor outputs are then digitized at a receiving
array. This technique has revolutionized wireless communication in terms of offering substantially
increased capacity without requiring additional bandwidth or power [11], while the advantages of
MIMO radar include enhanced resolution capability and diversity [12,13]. Although array processing
methods are designed for a multichannel signal model, they are often useful even in single sensor
applications. An important example is time series modeling (or spectral analysis), where an artiﬁcial
sensor array is created by a tapped-delay line so that the different “array elements” contain the same
signal with different time delays. Indeed, this is the case also if physical arrays are used and a plane
wave is propagating across the array. Thus, it comes as no surprise that array processing methods are
useful also for time series analysis. See, e.g., [14] for spectral analysis and [15,16] for subspace-based
system identiﬁcation methods. Chapter 20 of this book presents more examples where Array Signal
Processing technology can be applied other than the archetypical problem of DOA estimation using a
passive listening array, and in Chapter 18 the particular area of source localization in sensor networks is
surveyed.
The present chapter gives a brief introduction to the general area of array signal processing as well as
to the other chapters in this book. It should be stressed that we do not attempt to give a survey of the area—
all chapters together may serve that purpose. Rather the ambition is to illustrate the nature of array signal
processing methodology, and exemplify by some typical problem formulations and algorithms. Towards
this goal, in Section 3.11.2 we go in some detail into the underlying mathematical modeling of sensor
array data in the context of narrowband signals from far-ﬁeld emitters arriving at an array of closely
spaced (in relation to the wavelength) sensors. The nature of the problem is illustrated by investigating
the properties of this model in the form of spatial ﬁltering functions (beam patterns) for some standard
array conﬁgurations in Section 3.11.3.1. The connection to temporal Finite Impulse Response (FIR)
ﬁltering and Discrete Fourier Transform (DFT) give some additional insight. Next, in Section 3.11.4
a short introduction to beam forming and signal waveform estimation is given, followed in Section 3.11.5
by some examples of Direction-of-Arrival (DOA) estimation methods. The chapter ends in
Section 3.11.6 with an outlook towards applications that do not necessarily involve sampling a wave-ﬁeld
coherently using closely spaced sensors. Indeed, the rich activities in array processing has lead to

3.11.2 Geometric Data Model
465
applications reaching far beyond the generic DOA estimation using EM sensors as is also evident from
Chapter 20 of this book.
3.11.2 Geometric data model
This section presents the underlying modeling ideas in array processing. The sensor array data are
introduced as ideal samples of a transmitted wave in a linear and non-dispersive medium. The inﬂuence
of imperfect sensors and other sources of perturbation are brieﬂy mentioned, referring to Chapter 2 of
this book for more details.
3.11.2.1 Wave propagation
The generic problem in array processing is to estimate the parameters of incoming waves from distant
sources. This can, for example, be electromagnetic energy transmitted and captured by antennas or
acoustic waves propagated by transducers under water or loudspeakers in the air. In either case, provided
the medium of propagation is homogenous and non-dispersive, the “signal” E(t, r) (e.g., EM ﬁeld or
acoustic pressure) at a time t and location r = (x, y, z)T is governed by the wave equation
∂2E(t, r)
∂x2
+ ∂2E(t, r)
∂y2
+ ∂2E(t, r)
∂z2
= 1
c2
∂2E(t, r)
∂t2
,
(11.1)
where c represents the speed of propagation. In general, E(t, r) can be vector-valued, for example
due to polarization (see, e.g., [17]), but for simplicity we only consider a scalar ﬁeld here. Some more
details about vector ﬁelds and vector sensors are provided in Chapters 14 and 16 in this book. We are
particularly interested in signals transmitted from a point source. It can be shown that the solutions
of the wave equation then depend only on the distance to the emitter, and not on the direction. It is
well-known that such solutions must satisfy the so-called spherical wave equation:
∂2{r E(t, r)}
∂r2
= 1
c2
∂2{r E(t, r)}
∂t2
,
(11.2)
where r is the distance between the observation point r and the source. It is easy to see that the following
general form satisﬁes (11.2):
E(t, r) = 1
r s+(t −r/c) + 1
r s−(t + r/c),
where s+(t −r/c) and s−(t + r/c) are two arbitrary functions, whose shape will depend on the initial
conditions. Due to the dependence on t ± r/c, these functions are interpreted as waves traveling out
from and in towards the point source, respectively. In our case, we are mainly concerned with the out-
going wave s+(t −r/c). Assuming a relatively small array of sensors situated in the far-ﬁeld, the 1/r
scaling, being approximately constant, can be absorbed into the function itself, leading to the form
E(t, r) = s(t −r/c).

466
CHAPTER 11 Introduction to Array Processing
z
x
k
θ
ϕ
y
FIGURE 11.1
Coordinate system used in the deﬁnition of (11.4). Note that azimuth is measured counter-clockwise relative
to the positive x-axis, and elevation is deﬁned relative to the xy-plane.
With some abuse of notation, let us deﬁne s(t) as the signal at some origin which is near the sensor
array and far from the signal source. Then r above is replaced by the difference in travel distance from
the source to the origin and to the observation point respectively. This is given by r · ur, where ur is
a unit vector pointing in the direction of propagation and r is the coordinates of the observation point.
A case of special interest is a mono-chromatic signal s(t) = Ae jωt, which leads to
E(t, r) = Ae jω(t−r·ur/c) = Ae j(ωt−r·k),
(11.3)
where k = ω/c is termed the wave number and k = kur is the wave vector. The latter can be expressed
in Cartesian coordinates as
k =
⎡
⎣
kx
ky
kz
⎤
⎦= −k
⎡
⎣
cos φ cos θ
cos φ sin θ
sin φ
⎤
⎦,
(11.4)
where θ and φ denote, respectively, the azimuth and elevation angles with respect to the coordinate
system, see Figure 11.1. Note that these are the same for all sensors due to the far-ﬁeld assumption.
For the same reason, the wave vector is perpendicular to a plane where E(t, r) depends only on time,
called the phase front and deﬁned by k · r = 0. A single-frequency propagating wave in the far-ﬁeld is
therefore termed a plane wave.
3.11.2.2 Ideal data model
In many applications of interest, the transmitted signal occupies a very small bandwidth B as compared
to its center frequency ω. Using a complex-valued representation, such a signal can be expressed as
A(t)e jωt, where the complex amplitude A(t) varies much slower than e jωt, so that it can be modeled as
constant during the propagation of the wave across the array. Suppose a narrowband signal is received
by an array of M sensors at positions rm, m = 1, . . . , M relative to the origin, see Figure 11.2.

3.11.2 Geometric Data Model
467
Phase front
Receiver
Electronics
Receiver
Electronics
Receiver
Electronics
Receiver
Electronics
Array Processing
. . .
FIGURE 11.2
Plane waves from far-ﬁeld sources arrive at an array of antennas. The problem of interest here is to estimate
the directions to the sources.
Assuming A(t −rm/c) ≈A(t −r/c), ∀m, where r is the distance between the source and the origin,
the ﬁeld at the mth sensor is expressed using (11.3) as
E(t, rm) = A(t −r/c)e j(ωt−k·rm).
If the Radio-Frequency (RF) signal E(t, rm) is captured by an ideal sensor, and the resulting signal is
down-converted to baseband,1 the resulting output of the mth sensor is given by
xm(t) = e−jk·rms(t),
(11.5)
1In this complex-valued representation, down-conversion is performed by multiplication by e−jωt.

468
CHAPTER 11 Introduction to Array Processing
where we have deﬁned the complex envelope signal at the origin as s(t) = A(t −r/c). Thus, in the
narrowband case, the sensors outputs are all coherent and differ only by a phase shift. In reality, both
the sensor and the receiver electronics, see Figure 11.2, may introduce distortions to the ideal model
(11.5). Some more details regarding this are given in below, and especially in Chapter 19 of this book.
The simple geometrical model (11.5) implies that we can collect the sensor outputs into an M-vector
x(t), termed the array output, modeled by
x(t) =
⎡
⎢⎣
x1(t)
...
xM(t)
⎤
⎥⎦= a(θ, φ)s(t),
(11.6)
where
a(θ, φ) =
⎡
⎢⎣
e−jk(θ,φ)·r1
...
e−jk(θ,φ)·rM
⎤
⎥⎦
(11.7)
is termed the steering vector (propagation vector or array response vector are other popular names).
Note that we have stressed the dependence of the wave vector on the Direction-or-Arrival (DOA), here
expressed in a 3D space by the azimuth and elevation angles θ and φ respectively. The steering vector
models the relative phase shifts of a narrowband signal at the various sensor locations due to their differ-
ent spatial locations. For this reason the models (11.6) and (11.7) are termed the geometrical data model.
In many applications, the scenario is two-dimensional, so that the DOA is determined by only one
parameter. The by far most studied sensor conﬁguration is that of a Uniform Linear Array (ULA). Using
a linear array, it is of course not possible to determine the direction in 3D due to inherent ambiguities.
It is then commonly assumed that the sensors and the sources all reside in a plane, for instance the
plane z = 0. Thus, setting the elevation in (11.4) to φ = 0◦and placing the sensors along the y-axis,
so that rm = (0, (m −1), 0)T , where  is the inter-element separation, (11.4) and (11.7) yield to
k · rm = k(m −1) sin θ, resulting in
aULA(θ) =

1, e jk sin θ, . . . , e jk(M−1) sin θ	T
.
(11.8)
If the elevation is unknown, sin θ in (11.8) corresponds to sin θ cos φ in (11.4), which can be interpreted
as a cone angle with respect to the array axis. A so-called standard ULA has k = π, i.e.,  = π/k =
λ/2, where λ = c/ f is the wavelength. This is the maximum element separation to avoid ambiguities,
or grating lobes, see Figure 11.6. Ambiguities arise because two or more different DOAs give the same
array response, which is normally undesired. In the sequel, we will use the shorter notation a(θ) for
the steering vector, keeping in mind that the DOA parameter θ is two-dimensional in the 3D case. In
general, the steering vector may also be parameterized by other parameters, for example related to the
array geometry or to polarization.
In the presence of multiple emitters we can apply the superposition principle for linear sensors,
resulting in the ubiquitous data model
x(t) =
P

p=1
a(θp)sp(t) + n(t),
(11.9)

3.11.2 Geometric Data Model
469
where θp represents the DOA of the pth signal source, sp(t) the corresponding signal waveform, and n(t)
is a vector-valued additive noise term. The noise represents all un-modeled phenomena in the simple data
model (11.6), such as hardware imperfections and various internal and external noise sources. For a well
calibrated array, n(t) is often assumed to be dominated by thermal noise in the receivers, which can be
well-modeled as a stationary white (temporally as well as spatially) and circularly symmetric Gaussian
random process. A compact matrix form for (11.9) is obtained by deﬁning the M × P steering matrix
A(θ) = [a(θ1), . . ., a(θP)], where θ = [θ1, . . ., θP]T , and the signal vector s(t) = [s1(t), . . . , sP(t)]T .
This results in
x(t) = A(θ)s(t) + n(t).
(11.10)
Whether the main objective is to determine the DOAs or to reconstruct one or more of the incoming
signals, the estimation is typically based on a ﬁnite set of N samples of x(t), taken at arbitrary time
intervals tn, n = 1, . . . , N. Replacing x(tn) by the discrete-time notation x(n), we express the available
data as
x(n) = A(θ)s(n) + n(n),
n = 1, . . . , N.
(11.11)
Most estimation methods use only second-order properties of the data. The array correlation matrix
is deﬁned as Rx = E[x(n)xH(n)], where E[·] is statistical expectation and (·)H denotes complex
conjugate and transpose (the Hermitian operator). If the signal and noise vectors are assumed to be
independent zero-mean stationary random processes with correlation matrices Rs = E[s(n)sH(n)] and
Rn = E[n(n)nH(n)] respectively, we obtain
Rx = A(θ)RsAH(θ) + Rn.
(11.12)
As previously alluded to, the noise is often modeled as spatially white, i.e., Rn = σ 2I, where I is the
M × M identity matrix and σ 2 the noise power. If this is not the case, but Rn is known, then x(n) can
be pre-multiplied by an inverse square-root factor R−1/2
n
of Rn, which renders the resulting noise white
(and also alters the steering vectors in a predictable way). The array correlation matrix is estimated from
the available data by the sample correlation matrix
Rx = 1
N
N

n=1
x(n)xH(n).
(11.13)
Under mild assumptions on the involved random processes (see Chapter 16 in this book for more details
regarding large sample analysis), it holds that2 Rx →Rx as N →∞. Many estimation methods are
based on properties of the “true” array correlation matrix Rx, but applied to the sample correlation. If
the sample size is large enough and the data model is sufﬁciently good, such an approach can result in
highly accurate DOA estimates.
A number of problem formulations can now be stated based on the available data. The most basic
problem is that of signal detection, i.e., to determine if there is anything except noise in the data.
Formally, this is stated as deciding between the two hypotheses:
H0 : x(n) = A(θ)s(n) + n(n),
H1 : x(n) = n(n).
(11.14)
2Strictly speaking, the convergence is random and needs to be given a more precise statistical meaning. We avoid such
technical details in this introductory chapter.

470
CHAPTER 11 Introduction to Array Processing
The main difﬁculty in this formulation is of course that the signal parameters (if there is a signal) are
unknown. Closely related to this is the problem to determine the number of signals P. This is often also
referred to as the detection problem, although in some literature the term source enumeration is used.
In communication applications, the problem of main interest is to disentangle the signal waveforms
s(n). One of these may be the signal-of-interest while the others are due to co-channel interference.
In this case, there is usually a rich information regarding the signal structure available, such as each
sp(n) belonging to a ﬁnite set of constellation symbols (digital modulation). Finally, the problem that
has received the most interest by far is that of estimating the DOA parameters from the given data.
The archetypical problem is that of a passive listening array, where (11.11), and (11.12) is the only
information available about the model. However, in applications such as Doppler radar, there may be
additional signal structure information available, for example that the signal is a complex exponential
with an unknown frequency. All these problem formulations call for different treatment, and this has
lead to a rich ﬂora of publications over the last several decades. See [7,8,18–20] for some overview
treatments. As illustrated in Section 3.11.6 (see also Chapters 18 and 20 of this book), there are several
important applications of multi-sensor array processing techniques where the data does not originate
from an array of coherent sensors, but where models and ideas from array processing have inspired new
theory and methods.
3.11.2.3 Non-ideal data models
In any parametric estimation problem, it is of course crucial to have an accurate model of the received
data. There are many reasons why a real-world antenna array would deviate from the idealistic sampling
of a wave-ﬁeld as given above. In reality, both the sensor and the receiver electronics, see Figure 11.2,
may introduce perturbations. In particular, each sensor has its own characteristics depending on its
position in the array, and its presence affects the wave-ﬁeld. This leads to mutual coupling between the
sensors,which,ifnotproperlyaccountedfor,canhavedetrimentaleffectsontheestimationperformance.
It is common to model the mutual coupling using a so-called coupling matrix C (see, e.g., [21]), which
modiﬁes the steering vectors from the ideal a(θ) to Ca(θ). For simple geometries and sensors, such as
a ULA of dipoles operating in free space, it is possible to compute C theoretically. However, in more
practical scenarios one has to resort to numerical computation or experimental characterization. The
latter has the additional advantage that any other imperfections not accounted for in the ideal model
will also be captured. Some of the more commonly encountered non-idealities include:
•
Uncertain element positions or orientations.
•
Channel imbalances, leading to gain and phase errors at the different sensors.
•
Imbalances between the I and Q channels (i.e., real and imaginary parts of the received data).
•
Non-linearities in ampliﬁers, A/D converters, modulators and other hardware.
•
Near-ﬁeld scattering and other diffuse multipath phenomena.
In addition to this, the color of the background noise may not be perfectly known. In this introductory
chapter, we mainly raise the awareness of these practical issues. It is clear that accurate calibration is
necessary for a successful implementation of real-world direction ﬁnding. More details are given in
Chapter 19, whereas Chapter 20 considers beam forming methods that are robust to calibration errors.

3.11.3 Spatial Filtering and Beam Patterns
471
3.11.3 Spatial ﬁltering and beam patterns
Just as in temporal signal processing, a basic operation in sensor array (i.e., spatial) signal processing
is that of linear ﬁltering. The purpose of this section is to give some insight into spatial ﬁltering and
into the basic properties of the data model (11.11). We also introduce some common 1D and 2D array
structures.
3.11.3.1 Spatial ﬁltering
A linear spatial ﬁlter is simply obtained by weighting and summing the sensor outputs, see Figure 11.3.
Deﬁning the weights3 as {w∗
m}M
m=1, the output of the so-called beamformer is given by
y(n) =
M

m=1
w∗
mxm(n) = wHx(n),
(11.15)
where w = [w1, . . . , wM]T is termed the weight vector (or beamforming vector). In the presence of a
single source with DOA parameter(s) θ, the array output is given by
y(n) = wHa(θ)s(n).
(11.16)
Thus, we can think of wHa(θ) as the spatial transfer function from s(n), at the direction θ (and at the
frequency ω), to y(n). Its magnitude G(θ) = |wHa(θ)| is the gain of the spatial ﬁlter towards a signal
coming in from the direction θ. It is instructive to compare to temporal Finite Impulse Response (FIR)
ﬁltering. Thus, if s(n) is the discrete-time input to an FIR ﬁlter with coefﬁcients {hm}M−1
m=0 , the output
is given by (see, e.g., [22])
y(n) =
M−1

m=0
hms(t −mT ),
where T is the sampling interval. Deﬁning h = [h0, . . . , hM−1]T and s(n) = [s(n), s(t −T ), . . . ,
s(t −(M −1)T )]T , we can express this in compact form as
y(n) = hT s(n).
(11.17)
Now, the spatial gain function G(θ) = |wHa(θ)| is the response to a point source at the DOA θ. This
can be interpreted as a spatial line spectrum. The corresponding case in temporal processing is a single
frequency input. Putting s(n) = e jωt we have, with some abuse of notation,
s(n) = [1, e−jωT , . . . , e−jω(M−1)T ]T e jωt = a(ω)s(n).
Thus, (11.17) yields the FIR-ﬁlter response to a pure sinusoid as
y(n) = hT a(ω)s(n) =
M−1

m=0
hme−jωmT s(n).
(11.18)
3The weights are commonly deﬁned with complex conjugate, so as to obtain a proper inner product in (11.15).

472
CHAPTER 11 Introduction to Array Processing
. . .
w 2*
w *
1
w *
3
w *
M
FIGURE 11.3
Linear spatial ﬁltering through beamforming. The output is the weighted sum of the various antenna signals.
As expected, the ﬁlter transfer function M−1
m=0 hme−jωmT is simply given by the Discrete-Time Fourier
Transform (DTFT) of the FIR-ﬁlter coefﬁcients hm. A similar relation is obtained in the case of uniform
linear sampling in space. From (11.8), the ideal ULA beamformer output is given by
yULA(n) = wHaULA(θ)s(n) =
M−1

m=0
w∗
me jmk sin θs(n).
Deﬁning the electrical angle as ξ = k sin θ, the ULA beamforming gain is expressed as
G(ξ) =

M−1

m=0
w∗
me jmξ
 =

M−1

m=0
wme−jmξ
 .
Thus, also in this case the gain is obtained using the DTFT of the ﬁlter coefﬁcients. The only difference
is that the weights are applied to spatially sampled data at the same time instant, rather than to temporally
sampled data at the same spatial location as in the FIR case. In both cases, the choice of weights inﬂuence
the gain as a function of frequency (spatial or temporal). In particular, a spatial ﬁlter can be used to
block interference from certain directions in favor of a desired signal. This aspect will be explored in
more detail in Section 3.11.4, and in particular in Chapters 13 and 20 of this book.
3.11.3.2 One-dimensional arrays
In the previous section, the beamforming gain is deﬁned as G(θ) = |wHa(θ)|, where w is the weight vec-
tor and a(θ) the array steering vector. We will now introduce the important concept of array beam pattern.

3.11.3 Spatial Filtering and Beam Patterns
473
This is simply given by the beamforming gain |wHa(θ)| when the beamforming weights are selected
as w = a(θ0), where θ0 is the look direction. Since the weights depend on θ0, we use the notation
G(θ, θ0) = |aH(θ0)a(θ)|.
(11.19)
By Cauchy-Schwartz’s inequality, | aH(θ0)a(θ) | ≤∥aH(θ0) ∥× ∥a(θ)∥, with equality for θ = θ0.
Thus, when w = a(θ0) the gain G(θ, θ0) will have a maximum in the direction of θ = θ0. We say that
the array is steered to the direction θ0. Conversely, the choice w = a(θ0) maximizes the gain |wHa(θ0)|
in the direction θ0, subject to the norm constraint ∥w∥2 = ∥a(θ)∥2 = M. Since it equalizes all phases
in a(θ0) before summing up the gains, we call this a matched ﬁlter. For a ULA, (11.8) gives the beam
pattern as
GULA(θ, θ0) =

M−1

m=0
e jmk( sin θ−sin θ0)
 =
sin

Mk( sin θ −sin θ0)/2

sin

k( sin θ −sin θ0)/2
 .
(11.20)
Figure 11.4 shows the beam pattern for a 10-element ULA with different look directions. Due to
symmetry, the beam pattern is plotted only for −90◦≤θ < 90◦. Because of the sin θ-dependence in
(11.20), the spatial ﬁlter is broadened as θ0 approaches 90◦, which corresponds to array endﬁre. This is
expected, since the baseline of a linear array vanishes from this angle. In terms of the electrical angle
ξ = k sin θ, the beam pattern is a function only of the difference ξ −ξ0,
GULA(ξ −ξ0) =

M−1

m=0
e jm(ξ−ξ0)
 =
sin

M(ξ −ξ0)/2

sin

(ξ −ξ0)/2
 .
(11.21)
It is now easy to see that the maximum is given by GULA(0) = M and that GULA(ξ) has nulls when
sin (Mξ/2) = 0, i.e., for ξ = ±2πl/M where l is an integer. The location of the ﬁrst null, ξBW = 2π/M
−80 −60 −40 −20
0
20
40
60
80
−20
−15
−10
−5
0
5
10
15
20
DOA [deg]
Beam Pattern [dB]
θ0=0°
θ0=40°
θ0=80°
FIGURE 11.4
Beam pattern versus DOA for a 10-element ULA with k = π for different look directions θ0.

474
CHAPTER 11 Introduction to Array Processing
−150
−100
−50
0
50
100
150
−20
−15
−10
−5
0
5
10
15
20
25
30
Electrical Angle [deg]
Beam Pattern [dB]
M=5
M=20
FIGURE 11.5
Beam pattern versus electrical angle ξ for a uniform linear arrays with M = 5 and M = 20 sensors,
respectively.
is termed the (Rayleigh) beamwidth of the array. It is clear that the array beam pattern is sharper the
larger M is, as illustrated in Figure 11.5. A narrow main lobe implies a better capability to discriminate
between multiple sources at different positions, i.e., resolution. Besides the main lobe, the beam pattern
also displays sidelobes, the largest being about 13 dB below that of the main lobe peak. The peak
sidelobe level is approximately independent of the number of sensors. For large M, we can approximate
the Rayleigh beamwidth in terms of the DOA parameter θ as
θBW ≈
2π/M
k cos θ0
=
1
(/λ)M cos θ0
,
(11.22)
where in the second equality we used that k = 2π/λ, where λ is the wavelength. This demonstrates
clearly that the beamwidth is widened as cos θ0 approaches 0, as previously seen in Figure 11.4.
Equation (11.22) also shows that the beamwidth is inversely proportional to d = /λ, which is the ele-
ment separation normalized to the wavelength. Thus, a larger element separation yields a sharper beam
pattern. However, if d > 1/2, i.e., half wavelength element separation, we may have so-called grating
lobes in the beam pattern. This means that GULA(θ, θ0) in (11.20) reaches its maximum value of M at
more than one location. This effect is illustrated in Figure 11.6 for different look directions θ0, using
the element separation d = 1. Using the analogy to temporal ﬁltering, introduced e.g., in (11.18), we
see that the phenomenon is similar to aliasing in temporal sampling. The element separation d = 1/2,
or  = λ/2, is the spatial analogy of the well-known Nyquist frequency. A ULA with d = 1/2 is
hereafter referred to as a standard ULA.
It is possible to increase the physical extent of a linear array of M sensors beyond that of a standard
ULA, without causing grating lobes, namely by using a non-uniform element separation. A commonly
used geometry is that of a so-called Minimum Redundancy Array (MRA) [23]. The idea of this design

3.11.3 Spatial Filtering and Beam Patterns
475
−80 −60 −40 −20
0
20
40
60
80
−20
−15
−10
−5
0
5
10
15
20
DOA [deg]
Beam Pattern [dB]
θ0=0°
θ0=40°
FIGURE 11.6
Beam pattern versus DOA for a 10-element ULA with one wavelength element separation using the look
directions θ0 = 0◦and θ0 = 40◦respectively.
is to choose the pairwise element separations as multiples of d = 1/2 in such a way that all separations
l/2, for l = 1, . . . , 2M −1 are achieved exactly once by some element pair. For M = 4, the element
separations are {1, 3, 2}, resulting in a total aperture (array length) of 3λ, which is twice that of a
4-element standard ULA. It has been shown that no perfect MRA exists for M > 4, so one has to give
up either the requirement to cover all element separations or allow more than one pair for some ls.
In fact, ﬁnding good sparse (or “thinned”) array designs has been the subject of a signiﬁcant research
effort over several decades, see, e.g., [1,24]. The M = 4 MRA beam pattern is compared to that of
standard ULAs with M = 4 and M = 7, the latter having the same aperture as the MRA, in Figure 11.7.
It is seen that the 4-element MRA offers signiﬁcantly increased resolution, in fact similar to that of the
7-element ULA, at the expense of increased sidelobes. The latter can be a drawback in the presence of
multiple signal sources and/or interference. In Section 3.11.4 we will study how weight vector design
can be used to shape the beam pattern of any array, thus alleviating the problem of high sidelobes to
some extent.
3.11.3.3 Two-dimensional arrays
To localize a source in 3D, it is necessary to employ a 2D (or even 3D) array. In this case, the steering
vector (11.7) is a function of both azimuth and elevation, and consequently so is the beam pattern.
Similar to (11.19), we deﬁne the 2D beam pattern as
G(θ, φ) =
aH(θ0, φ0)a(θ, φ)
 ,
(11.23)
where the dependence of G(θ, φ) on the look direction (θ0, φ0) has been suppressed for notational
convenience. Below, we illustrate the shape of the beam pattern for three popular 2D array structures,

476
CHAPTER 11 Introduction to Array Processing
−80 −60 −40 −20
0
20
40
60
80
−20
−15
−10
−5
0
5
10
15
20
DOA [deg]
Beampattern [dB]
ULA, M=4
ULA, M=7
MRA, M=4
FIGURE 11.7
Beam pattern versus DOA for a 4- and 7-element ULA as well as a 4-element Maximum Redundancy
Array (MRA).
namely the Uniform Circular Array (UCA), Uniform Rectangular Array (URA), and the L-shaped array.
For simplicity, we assume that the array elements are placed in the xy-plane, although the emitters may
be in 3D space. The UCA has it’s elements uniformly placed along a circle of radius R. Placing the
origin of the coordinate system at the center of the array, the coordinates are given by
(xm, ym, zm) = (R cos ηm, R sin ηm, 0),
m = 1, . . . , M,
where ηm = 2π(m −1)/M. Since also this array may suffer from grating lobes, it is customary to
choose the radius such that the minimum element separation is close to λ/2, as in the case of a ULA.
Figure 11.8 shows the beam pattern for a M = 36 element UCA with radius R = 3λ, steered to the
look direction (θ0, φ0) = (160◦, 45◦).
The URA is another natural extension of the ULA to two dimensions. In this case, the element
positions are placed in the xy-plane on a uniform rectangular grid of size
√
M ×
√
M (it is assumed
that M is an even square in this case). Figure 11.9 shows the beam pattern of a URA with λ/2 element
separation. Again, M = 36 and the array is steered to the “look direction” (θ0, φ0) = (160◦, 45◦).
The uniform L-shaped array consists of two uniform linear arrays, one along the x axis and the other
along the y axis. Using the same parameters as for the UCA and URA, the beam pattern for the L-shaped
array is illustrated in Figure 11.10. Comparing the three 2D arrays illustrated here, we see that for a
given number of sensors, the L-shaped array has the narrowest main beam whereas the URA has the
widest. In return, the L-shaped array has a ridge of high sidelobes (peak value approximately −6 dB).
One may conclude that the UCA has the most “balanced” beam pattern, offering good resolution and
nearly equi-ripple sidelobes, but this must of course be given a more precise meaning depending on the
application.

3.11.3 Spatial Filtering and Beam Patterns
477
FIGURE 11.8
Beam pattern versus azimuth and elevation angle for a M = 36 element uniform circular array steered to
(θ0, φ0) = (160◦, 45◦).
FIGURE 11.9
Beam pattern versus azimuth and elevation angle for a M = 36 element standard uniform rectangular array
steered to (θ0, φ0) = (160◦, 45◦).
3.11.3.4 Wideband array response
The development this far relies heavily on the assumption of narrowband signals. To arrive at (11.5)
it is necessary that the baseband waveform remains approximately constant as the signal traverses the
array. The result is that the time-delay at different sensor locations translates to a phase shift due to
change in carrier phase. In some applications, in particular those involving acoustic waves, this is a
poor approximation due to the inherent wideband nature of the signal. Also in other applications there

478
CHAPTER 11 Introduction to Array Processing
FIGURE 11.10
Beam pattern versus azimuth and elevation angle for a M = 36 element L-shaped array steered to (θ0, φ0) =
(160◦, 45◦).
is a constant interest to increase the bandwidth in order to enable more information to be transmitted
or to increase the range resolution. In these cases, the wideband characteristics of the signal needs to
be accounted for. A natural extension of the narrowband model is to apply the Fourier transform to the
signal (after demodulation in case there is a carrier) and express the model in the frequency domain.
The counterpart of (11.5) is then
Xm(ω) = e−jk(ω)·rm S(ω),
(11.24)
where S(ω) denotes the Fourier transform of the transmitted signal, Xm(ω) is the received signal in the
frequency domain and the dependency of k on the frequency has been stressed. Thus, the frequency-
domain array output is modeled by
X(ω) = a(θ, ω)S(ω).
(11.25)
It is clear that the only difference to the time-domain model is that the steering vector is now a function
of frequency, which needs to be taken into account when designing beamformers and DOA estimation
algorithms. This is illustrated in Figure 11.11, which shows the beam patterns for two different beam
forming strategies. In the left plot, a so-called true time-delay beam former is used, i.e., the weight
vector w(ω) = a(θ0, ω) is a function of frequency. In contrast, in the right plot a ﬁxed weight vector
w = a(θ0, ωH) is used, designed for the highest frequency ωH. The relatively high bandwidth (20% in
this case) causes an effect known as beam squinting when a frequency-independent beamformer is used,
meaning that the peak of the beam pattern appears at the intended look direction only for the design
frequency, and is shifted away from θ0 at other frequencies. The true time-delay beamformer can be
approximately implemented either by pre-processing the digital sensor outputs using FFT and applying
frequency-dependent beamformers, or by applying fractional time-delay ﬁlters at each digital sensor
output to approximate the required time-delay (see, e.g., [25]). While true time-delay beam forming
maintains a constant look direction, the beam width and the region outside the main beam still depends

3.11.3 Spatial Filtering and Beam Patterns
479
−80 −60 −40 −20
0
20
40
60
80
−20
−15
−10
−5
0
5
10
15
20
DOA [deg]
Beam Pattern [dB]
−80 −60 −40 −20
0
20
40
60
80
−20
−15
−10
−5
0
5
10
15
DOA [deg]
Beam Pattern [dB]
FIGURE 11.11
Beam patterns at different frequencies versus azimuth for an M = 10 element wideband ULA steered
to θ0 = 20◦. The relative bandwidth is 20%. Left: true time-delay beamforming, right: narrowband
beamforming.
−80 −60 −40 −20
0
20
40
60
80
−5
0
5
10
15
20
DOA [deg]
Beam Pattern [dB]
FIGURE 11.12
Wideband beam pattern versus azimuth for an M = 10 element wideband ULA steered to θ0 = 20◦. The
plot shows the average beam pattern over the 20% relative bandwidth.
on frequency. One can deﬁne a wideband beam pattern, for example by averaging the power response
of the array over frequency, as illustrated in Figure 11.12. The averaging has the effect of a smoothing
of the beam pattern outside the main beam so that the wideband beam pattern does not display any sharp
nulls as in the narrowband case.

480
CHAPTER 11 Introduction to Array Processing
3.11.4 Beam forming and signal detection
The previous section introduced spatial ﬁltering as an inherent property of an antenna array. In this
section, we consider the design of a spatial ﬁlter, or beamformer, to achieve a certain goal. The reader
is referred to e.g., [19] for a good overview on the topic, as well as to Chapters 13 and 20 of this book.
3.11.4.1 Beamforming as spatial ﬁlter design
A scalar spatial ﬁlter is introduced in (11.15) as a weighted linear combination of the sensor outputs
y(n) = wHx(n).
(11.26)
Assuming a single source from the direction θ, so that x(n) = a(θ)s(n), the gain of the spatial ﬁlter
is G(θ) = |wHa(θ)|. The spatial ﬁlter design problem is then to choose the weight vector w to meet
some design objectives. We have previously seen that the matched ﬁlter w = a(θ0) maximizes the gain
in the direction θ0. This is usually referred to as conventional, or Bartlett, beamforming. As illustrated
in (11.21) and in Figure 11.5, it inherits the properties of the DFT for ULAs, and similarly for other
geometries. Among all possible spatial ﬁlters it has the narrowest beamwidth, but this comes at the
expense of sidelobes (−13 dB in the ULA case). In analogy with Fourier-based spectral analysis, one
can trade beamwidth for reduced sidelobes by applying an amplitude window (sometimes referred to
as tapering) to the elements of a(θ0). Thus, the weighting is chosen as
w = wwin ⊙a(θ0),
(11.27)
where ⊙is the Schur product (elementwise multiplication), and wwin is the desired window, see, e.g.,
[26,27]. Figure 11.13 illustrates the application of different window functions to an M = 20 element
ULA. A 60 dB damping is speciﬁed for the Chebyshev window, which then clearly has the lowest peak
sidelobe. Although the analogy to spectral analysis is for ULAs, extensions have been proposed for
other array geometries, see, e.g., [1,28] and also [29]. In general, the idea is to transform the given array
response to that of a ULA using the concept of phase modes or a similar approach. Another simple
generalization of the window-based beamformer design is to enforce a null in the direction of a strong
jammer, say θ j, in case the suppression offered by the window is not sufﬁcient. This can easily be
achieved by a projection, resulting in the beamformer
w = ⊥
j

wwin ⊙a(θ0)

,
(11.28)
where ⊥
j = I −a(θ j)[aH(θ j)a(θ j)]−1aH(θ j) is a projection matrix onto the orthogonal complement
of a(θ j).
A more general approach to beamforming or spatial ﬁlter design is to formulate the choice of weight
vector as a formal optimization problem. Such a design can be very ﬂexible, in that an arbitrary desired
beam pattern can be approximated, and the functional form a(θ) of the steering vectors can be arbitrary
(it may even be known only in the form of a table lookup). Several formulations have been proposed in
the literature, see, e.g., [1], some of them leading to high computational complexity. Fortunately, most
design objectives can be formulated as a convex optimization problem [30,31], implying that an optimal

3.11.4 Beam Forming and Signal Detection
481
−80 −60 −40 −20
0
20
40
60
80
−80
−70
−60
−50
−40
−30
−20
−10
0
10
DOA [deg]
Beam Pattern [dB]
Rectangular
Triangular
Hamming
Chebyshev
FIGURE 11.13
Spatial ﬁlter gain versus DOA for different window functions. ULA with look direction θ0 = 20◦, M = 20.
Filter responses are normalized to unit gain in the look direction.
solution can always be found with an acceptable computational effort. As an example, the following
Chebyshev-like approach is of practical relevance. Let G(θ) = |wHa(θ)| and introduce the stop-band
region θ ∈s. Itisassumedthatunitgaininthelookdirectionisdesired,expressedas wHa(θ0) = 1, and
that an upper bound (peak sidelobe) ϵ(θ) on G(θ) is speciﬁed in the stop-band. Given these constraints,
the optimization problem is to minimize the white noise gain, which is given by ∥w∥2. To see this,
let x(n) = n(n) with E[n(n)nH(n)] = σ 2I. The output power is then E[|wHx(n)|2] = σ 2∥w∥2. The
optimization problem is now formulated as:
min
w
∥w∥2
s.t. wHa(θ0) = 1
G(θ) ≤ϵ(θ),
θ ∈s,
(11.29)
where ϵ(θ)>0 is an arbitrary application-speciﬁc function (or constant). This problem is easily imple-
mented in publicly available software, such as CVX [32] (in fact, (11.29) is readily available as an
application example in the CVX code). The choice of stop-band damping and stop-band region is left to
the discretion of the user, and in general it requires some trial and error. Note that the problem (11.29)
may lack any feasible solution at all if the speciﬁcations are too tight. To illustrate the generality of
this approach, Figure 11.14 shows the conventional and the optimized beam pattern for a 20-element
random linear array. It is not possible to achieve more than about 20 dB damping for this array, but
the response is still considerably improved by the optimization. In closing this section, we point to the
possibility to include robustness to certain sources of error into the optimization formulation. This can
be, for example, that the position of the desired source (look direction) is not perfectly known, or that
the array response is subject to errors. Chapter 20 of this book addresses this issue, and the reader is
also referred to [33].

482
CHAPTER 11 Introduction to Array Processing
−80 −60 −40 −20
0
20
40
60
80
−40
−35
−30
−25
−20
−15
−10
−5
0
5
10
DOA [deg]
Gain [dB]
Beam Pattern
Convex Opt
FIGURE 11.14
Conventional beam pattern and optimized ﬁlter response for a random linear array. Look direction θ0 = 20◦,
M = 20. Filter responses are normalized to unit gain in the look direction.
3.11.4.2 Adaptive beamforming
The approach in the previous section is essentially to shape the beamforming response of the beamformer
to meet certain requirements. In many situations, the scenario is not precisely known, and it might
be impossible to design a ﬁlter to work under all circumstances. An attractive alternative is then a
beamformer that is adapted to the statistical properties of the desired signal and possible interference
and noise sources. Such a ﬁlter can also be automatically tuned using the received data (adaptive
ﬁltering). A commonly used criterion for an adaptive ﬁlter is the Mean-Squared Error (MSE) of the
ﬁlter output. The latter is given by wHx(n), and denoting the desired signal by d(n), the objective is to
minimize the MSE:
MSE = E[(d(n) −wHx(n))2].
(11.30)
Assuming that d(n) and x(n) are jointly stationary, this is the well-known Wiener Filter (WF), or Linear
Minimum Mean-Square Error (LMMSE) problem (see, e.g., [34]). The minimizing weight vector is
given by
wWF = R−1
x rxd,
(11.31)
where Rx = E[x(n)xH(n)] is the array correlation matrix and rxd = E[x(n)d H(n)] is the cross-
correlation between the array output and the desired signal. If the array output is modeled by x(n) =
a(θ0)s(n) + n(n), where the desired signal d(n) = s(n) is independent of the interference-plus-noise
term n(n), we get rxd = a(θ0)σ 2
s so that wWF = σ 2
s R−1
x a(θ0). Here, σ 2
s denotes the signal power.
AnalternativeperformancecriterionistheSignal-to-Interference-plus-NoiseRatio(SINR).If x(n) =
a(θ0)s(n) + z(n), where z(n) represents interference plus noise, we can deﬁne the signal part of the
beamformer output as wHa(θ0)s(n) and the interference-plus-noise part as wHz(n). Thus, the SINR is
obtained as

3.11.4 Beam Forming and Signal Detection
483
SINR = E|wHa(θ0)s(n)|2
E|wHz(n)|2
= σ 2
s |wHa(θ0)|2
wHRzw
.
(11.32)
It is easy to show, e.g., using the Cauchy-Schwartz inequality, that the SINR is maximized by the choice
wSINR = μR−1
z a(θ0),
(11.33)
where μ is an arbitrary scalar (i.e., it does not affect the SINR). As expected, wWF and wSINR are closely
related, and if μ = rs/[1 + rsaH(θ0)R−1
z a(θ0)] it holds that wWF = wSINR. Thus, the Wiener Filter
solution also maximizes the SINR for the case of one signal observed in independent but (possibly)
spatially colored noise.
Another possibility worth mentioning is the Minimum Variance Distortionless Response (MVDR)
beamformer. In this case, the ﬁlter design is again cast as an optimization problem:
min
w
E|wHx(n)|2
s.t. wHa(θ0) = 1.
(11.34)
The idea of minimizing the output power is that the beamformer should automatically put nulls in
the direction of possible interfering sources, in contrast to e.g., (11.29) where all directions are sup-
pressed. The constraint wHa(θ0) = 1 guarantees that the desired signal is preserved despite the power
minimization. As is well-known, the solution to this problem is given by
wMVDR =
1
aH(θ0)R−1
x a(θ0)
R−1
x a(θ0).
(11.35)
Clearly, also wMVDR maximizes the SINR, and hence all of the mentioned design principles lead to
the same weight vector up to a scaling. Figure 11.15 shows the MVDR response together with the
conventional beam pattern for a difﬁcult case with two jammers, of which one (10 dB above the noise
ﬂoor) is within the main beam of the array and the other (20 dB above the noise) is near the peak
sidelobe. As expected the MVDR gain has a deep null at the location of the strongest jammer, and a
somewhat lesser null towards the mainbeam jammer. As a result of the latter nulling, the main beam of
the MVDR beamformer is somewhat shifted towards the other end. We remark here that the constraint
in (11.34) can easily be generalized to an arbitrary linear constraint, say CHw = b. The solution (11.35)
is then replaced by wLCMV = R−1
x C(CHR−1
x C)−1b, where LCMV stands for Linearly Constrained
Minimum Variance. The extra constraints can be used e.g., to enforce nulls in certain directions and/or
to increase the robustness to certain types of errors.
The WF, Max SINR, and MVDR approaches all yield weight vectors of the form w = αR−1
x a(θ0)
for some scalar α, which we take as unity for the sake of brevity. In a practical situation, the array
correlation matrix Rx may not be known. An obvious approach is then to replace Rx by the sample
correlation matrix Rx, deﬁned in (11.13). This is commonly referred to as Sample Matrix Inversion
(SMI) [35]. For large enough number of samples N, the performance of the SMI beamformer is identical
to that of the optimal MVDR. A rule of thumb according to [35] is that N has to be at least twice the
number of jammers in order for the expected value of the SINR to be within 3 dB of the optimal one, see
also [18]. However, for small number of samples, the resulting ﬁlter response may have an unacceptably

484
CHAPTER 11 Introduction to Array Processing
−20
−10
0
10
20
30
40
50
60
−80
−70
−60
−50
−40
−30
−20
−10
0
10
DOA [deg]
Gain [dB]
Beam Pattern
MVDR Response
FIGURE 11.15
Conventional beam pattern and MVDR ﬁlter response for a 20-element ULA. A 0 dB desired source is present
at the look direction θ0 = 20◦, a 10 dB jammer is located in the main beam at 17◦and a 20 dB jammer
near the peak sidelobe at 30◦.
high variance. To alleviate this, it is popular to use regularization (known as diagonal loading in the
radar literature). The correlation matrix in (11.35) is then replaced by the regularized version
Rx,λ = 1
N
N

n=1
x(n)xH(n) + λI,
(11.36)
where λ is the regularization parameter. The addition of the λI term tends to stabilize the inverse R−1
x,λ,
and the procedure is standard when dealing with ill-conditioned least-squares problems. An additional
beneﬁt of the regularization is that it also reduces the sensitivity to various mismatches, such as imprecise
knowledge of the look direction and/or array response. Choosing an optimal regularization parameter
is not a trivial task, though, and several approaches have been proposed in the literature, see, e.g.,
[36,37] and Chapter 20 of this book. In radar applications, it is often possible to collect samples of
the interference-plus-noise only. Thus, the formulation (11.33) can be used, with Rz replaced by the
sample covariance matrix taken from the signal-free data. Provided these secondary data are indeed
representative of the interference environment in the primary data, the use of R−1
z
instead of R−1
x
is
known to improve the performance for small samples as well as the robustness to signal-related modeling
errors, see, e.g., [38].
In many cases it is desired to update the adaptive beamformer on-line, as new data becomes available.
This is similar to other adaptive ﬁltering applications, and a multitude of algorithms are available, see,
e.g., [39,40]. Besides simplicity of implementation, such a recursive implementation can cope with
a non-stationary signal environment. Tuning an adaptive ﬁlter requires some additional information
to enable distinguishing signal from noise. If the look direction is known, one can apply a recursive
implementation of the weight vector w(n) at time n:

3.11.4 Beam Forming and Signal Detection
485
w(n) = R−1(n)a(θ0).
(11.37)
This can be achieved by a Recursive Least Squares (RLS) type update of the matrix inverse, see, e.g.,
[39,40]fordetails.Gradient-basedsolutionsarealsopossible,see,e.g.,[41].Inacommunicationorradar
scenario, a so-called reference signal d(n) is often be available, which is identical to or highly correlated
with the signal transmitted from the desired look direction (which in this case may be unknown). Given
such a reference, one can base the update on the MSE criterion (11.30). The well-known Least Mean
Squares (LMS) algorithm (see, e.g., [42]) is based on an instantaneous gradient search of (11.30), with
the expectation dropped. This leads to the formula
w(n + 1) = w(n) + αx(n)

d(n) −wH(n)x(n)
∗
,
(11.38)
where w(n) is the weight vector at time n, which is updated using the new data d(n) and x(n) to form the
next weight vector w(n + 1). The steplength parameter α controls the speed of convergence as well as
the stationary variance of the weight vector (for a time-invariant scenario). In general, it should be tuned
so that the adaptive algorithm can follow the time variations of the “true” scenario. The LMS algorithm
is a stochastic gradient algorithm, since the expectation in (11.30) had to be dropped. This means that
the search direction is random, but correct “on average.” Provided the scenario is not too rapidly time-
varying, a small steplength should be used to alleviate the random ﬂuctuations. The LMS algorithm
is highly popular in practical implementations of adaptive ﬁltering, mainly due to its simplicity and
computational efﬁciency. Other, more complex algorithms such as Recursive Least Squares (RLS) and
Kalman Filtering (KF) can provide faster convergence speed at the expense of a higher complexity.
There are also even cheaper versions of LMS available, see, e.g., [39,40]. In concluding this section we
remark that given sufﬁcient information, one can estimate all or a subset of the signals that are present
in a given scenario at the same time, see, e.g., [43].
3.11.4.3 Signal detection
The acronym “radar” stands for radio detection and ranging, and this clariﬁes that the main purpose of a
radar system is to detect the presence of objects by transmitting radio signals and analyze the response.
The basic principle is to transmit a signal in a narrow beam, so that the direction to a potential target
(if present) can be assumed to be known, and to sample the return signal (after matched ﬁltering) in
time, where each sample corresponds to a certain range bin. Several pulses can be used to increase the
SNR and/or to determine the speed of a moving target. The response from one pulse at a certain DOA
θ0 and range bin is modeled by one of the two hypotheses:
H0 : x = n,
H1 : x = a0s + n,
(11.39)
where a0 = a(θ0) and the time index has been dropped for convenience. To decide between the two
hypotheses, a statistical model is postulated, and based on this a test statistic is derived. Under H0, x is
distributed as N(0, Rn) and under H1, one can use either x ∈N(a0s, Rn) or x ∈N(0, Rn + σ 2
s a0aH
0 ).
We consider only the former model here, which means that the signal amplitude s is regarded as a
deterministic constant. The most powerful test in terms of maximizing the Probability of Detection

486
CHAPTER 11 Introduction to Array Processing
(PD) for a given False Alarm (FA) rate is given by the Likelihood Ratio Test (LRT). The logarithm of
the ratio of the likelihood functions under H1 and H0 respectively, is easily found as
lr = −(x −a0s)HR−1
n (x −a0s) + xHR−1
n x.
(11.40)
The optimal test is now to compare lr to a threshold, and decide in favor of H1 when lr exceeds the
threshold. The latter is usually selected to achieve a pre-speciﬁed FA rate, which is the probability
that lr exceeds the threshold when H0 is true. In practice, the signal amplitude s as well as the noise
correlation matrix Rn are both unknown. A useful procedure is to replace s by its Maximum Likelihood
(ML) estimate, which leads to the Generalized LRT (GLRT). Maximizing (11.40) w.r.t. s leads to
ˆs = aH
0 R−1
n x
aH
0 Rna0
.
(11.41)
Substituting (11.41) back into (11.40) and canceling the common term leads to
glr = |aH
0 R−1
n x|2
aH
0 R−1
n a0
.
(11.42)
It is clear that Rn cannot be estimated from the single data x alone. Instead, it is assumed that a secondary
data set is available with only interference-plus-noise. This can be taken from adjacent range bins
or data at other frequencies for example. Thus, the sample correlation Rn is computed from the secondary
data and used in (11.42), which gives the so-called Adaptive Matched Filter (AMF) [44]. In view of
the fact that R−1
x a0 ∝R−1
n a0, one can also use data that (possibly) contains the signal, although this
may require more data for the same performance. The AMF test is now to decide in favor of H1 if

glr > γ , and for H0 otherwise, where γ is the threshold and 
glr is glr with Rn replaced by Rn. The
AMF enjoys the Constant False Alarm Ratio (CFAR) property, i.e., its FA ratio is independent of the
true noise covariance matrix. For a large sample size, K, of the secondary data set, the FA rate can be
approximated by [44,45]
Prob(glr > γ |H0) = (1 −γ )(K+1−M).
(11.43)
The power of the test, which is Prob(glr > γ |H1) is not available in closed form, but can easily be
numerically evaluated.
3.11.5 Direction-of-arrival estimation
In this section we give a brief introduction to the vast area of Direction-of-Arrival (DOA) estimation.
For more details, refer to Chapter 14 of this book, as well as, e.g., [7,8]. From Section 3.11.2, the general
problem is formulated as follows: Given data x(n), n = 1, . . . , N, modeled by the relation
x(n) = A(θ)s(n) + n(n),
(11.44)
we wish to estimate the parameter vector θ, which contains the P DOAs of interest. The noise is
usually assumed to be spatially and temporally white, so that E[n(n)nH(m)] = δn,mσ 2I, where δn,m

3.11.5 Direction-of-Arrival Estimation
487
is the Kronecker delta. The spatial whiteness can be relaxed, provided the noise correlation matrix Rn is
known. Temporal correlation is generally not a problem, but might imply that a larger number of samples
N is needed for the same performance. Note that θ can contain more than P parameters, for example
azimuth and elevation as well as polarization parameters. However, we will here assume that there is
only one parameter per source, referred to as the DOA θ. Inherent in the DOA estimation problem is to
determine the number of signals P. The signal waveforms s(n) can be regarded as nuisance parameters
when estimating the DOAs, although some techniques exploit certain signal properties that might be
known, for example constant modulus or cyclo-stationarity [46,47].
3.11.5.1 Beamforming methods
In view of the connection to temporal ﬁltering and DFT (see Section 3.11.3.1), a natural approach to
DOA estimation is to apply Fourier-based techniques for spectrum estimation. Thus, a beamforming
vector w(θ) is selected, with the objective to steer the array in the direction θ. In the classical (Bartlett)
beamforming case, w(θ) is taken as the steering vector a(θ), which means that w(θ) is a matched
ﬁlter in the direction θ. Given the beamforming vector, the output energy at time instant n is given by
|wH(θ)x(n)|2, and the total output power is computed as
P(θ) = 1
N
N

n=1
|wH(θ)x(n)|2 = wH(θ)Rw(θ),
(11.45)
where the second equality follows by writing |wH(θ)x(n)|2 = wH(θ)x(n)xH(n)w(θ). Now, P(θ) is
regarded as a spatial spectrum, and it is expected to exhibit peaks near the locations of the true DOAs
θ1, . . . , θP. Thus, the DOA estimates are taken as the parameter values ˆθ1, . . . , ˆθP of the P highest peaks
(isolated) of P(θ). Indeed, in the presence of a single source in temporally and spatially white noise, the
peak location of the Conventional Beam Former (CBF) with w(θ) = a(θ) coincides with the Maximum
Likelihood (ML) estimator, and thus shares its optimality properties. However, the presence of multiple
signal sources tends to move the peaks due to signal leakage, and if two sources are too close they will
only give rise to a single peak. This limited resolution capability is similar to Fourier-based spectral
analysis. According to (11.22), the resolution is given by θBW ≈
1
Md cos θ0 for a ULA, where θ0 is the true
DOA and d = /λ is the element separation measured in wavelengths. It may also happen that a strong
source masks a nearby weaker one through the sidelobes. This frequency masking can be alleviated by
the use of windowing, see Section 3.11.4.1, although at the expense of a reduced resolution.
Conventional beamforming-based DOA estimation does not take full advantage of the available
data. Indeed, its performance is essentially independent of the Signal-to-Noise Ratio (SNR). The use
of adaptive beamforming (11.34), with Rx replaced by the sample correlation Rx offers an improved
resolution at high SNR. Inserting (11.35) into (11.45) leads to the MVDR, or Capon [48] spectrum
PMVDR(θ) =
1
aH(θ)R−1
x a(θ)
.
(11.46)
As before, the DOA estimates are taken as the locations of the P largest peaks of (11.46). As shown,
e.g., in [49], the resolution of the MVDR spectrum improves with increasing SNR. Still, the method is
unable not take full advantage of the data. For example, neither the resolution nor the bias is essentially
improved even if an inﬁnite amount of data is available, i.e., if the true Rx is known.

488
CHAPTER 11 Introduction to Array Processing
3.11.5.2 Subspace methods
A new class of methods was introduced in the late 1970s to further improve the resolution of spectral-
based DOA estimation. The idea is to exploit the geometrical properties of the data model in a more
explicit way than, e.g., the adaptive beamforming techniques. From (11.12), the array correlation matrix
is given by
Rx = A(θ0)RsAH(θ0) + σ 2I,
(11.47)
where it is assumed that Rn = σ 2I and we have used θ0 to stress that Rx depends on the true DOA
parameter vector. Clearly, if some vector e is orthogonal to A(θ0), (11.47) shows that Rxe = σ 2e,
implying that e is an eigenvector of Rx with the eigenvalue σ 2. Provided P<M and Rs has full rank,
the matrix A(θ0)RsAH(θ0) is positive semi-deﬁnite and has rank P. Thus, there exists a basis of M −P
vectors {eP+1, . . . , eM} that are orthogonal to A(θ0), and all of them are eigenvectors of Rx with
the same eigenvalue σ 2. We call these the noise eigenvectors. Recall that eigenvectors of Hermitean
matrices that belong to different eigenvalues are orthogonal. Therefore, the remaining P eigenvectors
{e1, . . . , eP} that correspond to eigenvalues λ1, . . . , λP that are all greater than σ 2, constitute an orthog-
onal basis for the span of the matrix A(θ0), which we call the Signal Subspace. We can thus express
the eigendecomposition of the array correlation matrix, with eigenvalues in non-increasing order, as
Rx =
M

m=1
λmemeH
m = EssEH
s + EnnEH
n ,
(11.48)
where Es = [e1, . . . , eP] contains the signal eigenvectors, and the noise eigenvector matrix En =
[eP+1, . . . , eM] obeys AH(θ0)En = 0, where 0 is a matrix of suitable dimension. Clearly, the relation
aH(θ)En = 0 for θ ∈{θ1, . . . , θP} is useful to determine the DOA parameters θp. Provided the array
is unambiguous, meaning that any M steering vectors that correspond to distinct DOA parameters
are linearly independent, the relation aH(θ)En = 0 does not have any false solutions. The above
observations lead to the invention of the MUSIC (MUltiple SIgnal Characterization) algorithm [9,10].
First one computes the eigendecomposition of the sample correlation matrix
Rx = 1
N
N

n=1
x(n)xH(n) = EssEH
s + EnnEH
n ,
(11.49)
similarly to (11.48). The number of signals can be determined by using the fact that the multiplicity of
the smallest eigenvalue is M −P [50,51], although this is far from a trivial task in a practical case. Given
a ﬁnite number of samples only, aH(θ)En = 0 will not hold for any value of θ. A visually attractive
solution is to search for the P largest peaks of the so-called MUSIC pseudo-spectrum
PMUSIC(θ) =
1
∥aH(θ)En∥2 =
1
aH(θ)EnEH
n a(θ).
(11.50)
Note that this is not a spectrum in the sense of, e.g., (11.45), since it does not have the dimension of
power. However, it is clear that the locations of the peaks will coincide with the true DOAs when either
σ 2 →0 or N →∞, because the noise subspace will then be correctly estimated. Thus, the MUSIC

3.11.5 Direction-of-Arrival Estimation
489
0
5
10
15
20
25
30
35
40
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
DOA [deg]
Normalized Spectrum
CBF
MVDR
MUSIC
FIGURE 11.16
Normalized spectra for the Conventional Beam Former (CBF), MVDR and MUSIC methods, assuming a
20-element ULA and N = 100 samples. Two 10 dB uncorrelated sources are present at θ1 = 12◦and
θ2 = 20◦respectively.
estimator is statistically consistent. However, in ﬁnite samples it too has a limited resolution. See e.g.,
[52] or Chapter 16 for details. In addition, the MUSIC algorithm is unable to cope with the presence of
multipath propagation, since Rs is required to have full rank. We refer to Chapter 14 for extensions of
MUSIC leading to increased resolution and/or reduced sensitivity to multipath, and also to Chapter 15
for subspace-based methods that exploit special array structures and that work in higher dimensions.
Example 1 illustrates the performance of the three spectral based methods presented here in a simple
scenario of two uncorrelated sources.
Example 1 (Resolution of Spectral-Based DOA Estimation Methods).
Suppose a standard ULA
with M = 20 elements. Two uncorrelated sources are present, both with 10 dB power above the white
noise ﬂoor. The Classical Beam Forming (CBF), MVDR and MUSIC spectra are calculated based on
N = 100 snapshots of data. Figure 11.16 shows one (typical) realization of the spectra for a DOA
separation of 8◦. In this case, all three methods are able to resolve the sources with good results. In
Figure 11.17, the DOA separation is reduced to 5◦. This is within the beamwidth, so CBF can no longer
resolve the sources, but both MVDR and MUSIC provide accurate estimates. When the sources are
moved even closer, as in Figure 11.18, also the MVDR fails to resolve them in most realizations while
MUSIC still succeeds with high probability.
3.11.5.3 Parametric methods
Similar to any estimation problem, the data model (11.44) can be cast in a statistical framework in
order to arrive at an estimator with certain optimality properties. In most of the literature, the noise term
n(n) is assumed to be temporally and spatially white with a circularly symmetric Gaussian distribution.

490
CHAPTER 11 Introduction to Array Processing
0
5
10
15
20
25
30
35
40
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
DOA [deg]
Normalized Spectrum
CBF
MVDR
MUSIC
FIGURE 11.17
Normalized spectra for the Conventional Beam Former (CBF), MVDR and MUSIC methods, assuming a
20-element ULA and N = 100 samples. Two 10 dB uncorrelated sources are present at θ1 = 15◦and
θ2 = 20◦respectively.
10
12
14
16
18
20
22
24
26
28
30
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
DOA [deg]
Normalized Spectrum
CBF
MVDR
MUSIC
FIGURE 11.18
Normalized spectra for the Conventional Beam Former (CBF), MVDR and MUSIC methods, assuming a
20-element ULA and N = 100 samples. Two 10 dB uncorrelated sources are present at θ1 = 18◦and
θ2 = 20◦respectively.
Considering the signal waveforms s(n), they can either be regarded as unknown deterministic parameters
to be estimated along with θ, or they too can be given a statistical model, which is typically temporally
white and N(0, Rs). In some applications, more structure is available, for example that the signals are
complex sinusoids or that their transposed correlation matrix E[s(n)sT (n)] is non-zero. For the sake of

3.11.5 Direction-of-Arrival Estimation
491
brevity, we only consider the case where s(n) is deterministic and unknown. The corresponding ML
estimator is usually referred to as Deterministic ML (DML), or Conditional ML (CML) in the literature.
Under the stated assumptions, the data x(n) is temporally white and distributed as N(A(θ)s(n), σ 2I).
Thus, the negative log-likelihood function, ignoring constants, is given by
l

θ, {s(n)}N
n=1, σ 2
= N M log σ 2 + 1
σ 2
N

n=1
∥x(n) −A(θ)s(n)∥2.
(11.51)
The ML estimates of θ, {s(n)}N
n=1 and σ 2 are the minimizing arguments of l(·). It is straightforward to
show that for a ﬁxed, although yet unknown, value of θ; minimizing (11.51) w.r.t. the noise variance
and the signal waveforms yields
ˆs(n) = A†(θ)x(n),
(11.52)
ˆσ 2 = 1
M Tr

⊥
ARx

,
(11.53)
where A† = (AHA)−1AH is the Moore-Penrose pseudo-inverse, Tr is the matrix trace operator, and
⊥
A = I −A = I −AA† is the projection matrix onto the orthogonal complement of the matrix
A = A(θ). Inserting (11.52) and (11.53) into (11.51) shows that the ML DOA parameters are obtained
as the minimizing arguments of the function [53,54]
l(θ) = Tr

⊥
ARx

.
(11.54)
The close relation to the noise variance estimate (11.53) shows a nice interpretation of (11.54). The pro-
jection tries to remove all signal components of Rx, and then the trace measures the remaining (noise)
power. Clearly, this should be smallest when θ is close to θ0, but since the noise will have random com-
ponents along both the signal and the noise subspaces, the estimates will not be exact in ﬁnite samples.
By the general theory of ML estimation, we expect ˆθML = arg min l(θ) to be an approximately mini-
mum variance unbiased estimate in large samples. However, since the number of parameters increases
with increasing N, this turns out to hold only for large enough M (or small σ 2). Indeed, for correlated
sources, the ML estimator derived under the Gaussian assumption, termed Stochastic ML (SML) [55],
can result in improved DOA estimates, but the difference is often negligible in practical scenarios. We
refer to Chapters 14 and 16 of this book for more details and comparisons. Although the DML estimator
has a nice formulation (11.54), its computation is far from trivial. The function l(θ) has in general
multiple local minima, and to ﬁnd the global optimum with certainty may require a full P-dimensional
grid search. Several optimization methods have been proposed in the literature, see [56,57] and Chapter
14 of this book for more details. In this introductory chapter, we mention brieﬂy a popular iterative
procedure related to the SAGE algorithm of [58], and termed RELAX in [59], since it is a relaxed opti-
mization procedure. The idea is to compute the DOA estimates by optimizing l(θ, {s(n)}N
n=1) (the noise
variance can be ignored, since its value is not needed for the other parameters) with respect to one pair
{θp, sp(n)} at the time, keeping the others ﬁxed. This is achieved by subtracting the already estimated
components (if any) from x(n), forming the “cleaned” signal xp(n) = x(n) −
k̸=p a( ˆθk)ˆsk(n). Then,
updated parameter estimates for signal p are computed as

492
CHAPTER 11 Introduction to Array Processing
ˆθp = arg min
θ
Tr

⊥
a(θ)Rx p

= arg max
θ
aH(θ)Rx pa(θ)
aH(θ)a(θ)
,
ˆsp(n) = a† 
ˆθp

xp(n),
where Rx p is the sample correlation matrix of xp(n). One iteration of the algorithm now constitutes
applying the above procedure for p = {1, 2, . . . , P}, and the iterations continue until some convergence
criterion is met, such as that the DOA estimates do not change signiﬁcantly between two iterations. The
SAGE/RELAX algorithm and its variations (mostly varying the order in which the estimates are com-
puted) has been found to be quite successful for “nice” arrays, that do not exhibit “too high” sidelobes
in their beam pattern.
3.11.5.4 Modeling errors and array calibration
It is clear that any model-based estimator requires a reliable description of the sensor response as a
function of the parameter to be estimated. Concerning DOA estimation, this means that the steering
vector a(θ) must be a known function of the DOA parameter. As explained in Section 3.11.2.3, the
response of a real-world sensor array can be quite different from the ideal wave-ﬁeld model introduced
in Section 3.11.2.2. This will inevitably lead to a performance degradation of the DOA estimator.
To illustrate this effect, consider the same scenario as in Example 1. The source locations are ﬁxed at
θ1 = 15◦and θ2 = 20◦. However, the sensor positions in the xy-plane (normalized to the wavelength) are
perturbed by i.i.d. Gaussian random variables with zero mean and variance σ 2
xy. A “typical” realization
of the resulting MUSIC spectra is plotted in Figure 11.19, for several values of σ 2
xy. Although MUSIC is
0
5
10
15
20
25
30
35
40
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
DOA [deg]
Normalized Spectrum
σ    =0.1
xy
2
σ    =0.03
xy
2
σ    =0.01
xy
2
σ    =0
xy
2
FIGURE 11.19
Normalized spectra for the MUSIC method, assuming N = 100 samples and two 10 dB uncorrelated sources
at θ1 = 15◦and θ2 = 20◦. The x and y coordinates of the nominal M = 20-element standard ULA are
perturbed by i.i.d. N (0, σ 2
xy ) random variables, where σ 2
xy is varied.

3.11.6 Non-Coherent Array Applications
493
reasonably robust to certain types of modeling errors [60], the performance degrades as σ 2
xy is increased,
and in particular the ability to resolve closely spaced sources rapidly decreases. For σxy > 0.2, there is a
signiﬁcant probabilitythat thesensors switchplace(thenominal sensor separations are0.5wavelengths),
leading to a breakdown of any DOA estimation procedure. This example clearly illustrates the need for
array calibration when large modeling errors are present. There are two main approaches to calibration.
The ﬁrst attempt, termed auto-calibration, is to estimate certain array parameters along with the unknown
DOAs. The array parameters can include individual sensor gains, phases and positions and/or mutual
coupling parameters. In general, this leads to a large number of unknown parameters and thus high
sensitivity to noise, or even non-uniqueness. The other approach is to measure the array response in a
controlled experiment, using sources at known positions. A possible alternative to generate such data
artiﬁcially is a full-scale electromagnetic (or acoustic) simulation, provided sufﬁcient details of the
sensors and receiver circuitry as well as the environment surrounding the array is available. Chapter 19
of this book treats DOA estimation using real-world sensor arrays in more detail.
3.11.6 Non-coherent array applications
Classical DOA estimation deals with signals that are perfectly coherent at the different sensors. Yet,
the data model (11.11) and hence the associated estimation methods have found application in a vast
array of applications that do not involve coherent multi-sensor array data. This section gives a brief
introduction to such generalizations of DOA estimation, starting with the concept of spatially spread
sources.
3.11.6.1 Spread sources
In certain applications of array signal processing, the received signal from one source is not perfectly
coherent in all sensors, as predicted by the point-source model (11.6). This may be due to multipath or
to propagation through a random medium. In effect, the signal then appears to be coming from a cluster
of arrival angles, rather than from just one. A commonly adopted signal model for such situations is
that of a randomly time-varying “spatial signature” vector v(n), which has zero mean due to the random
phase of the scattering, and a correlation matrix that contains information of the scenario at hand. Thus,
the received signal at the sensor array due to a transmitted signal s(n) is modeled by
x(n) = v(n)s(n).
(11.55)
Due to the random nature of the propagation, the individual realizations of the spatial signatures are not
useful, but their statistics may reveal important information that can be used, e.g., to localize the signal
source (by the mean angle) and to characterize the nature of the propagation channel. A natural model
for the correlation matrix is given by
Rv = E[v(n)vH(n)] =

θ
a(θ)aH(θ)pθ(θ)dθ,
(11.56)
where a(θ) is the steering vector, i.e., the response to a signal from the direction θ, and pθ(θ)dθ
represents the part of the signal power that comes from the direction in question. Thus, one can view

494
CHAPTER 11 Introduction to Array Processing
pθ(θ) as a Probability Density Function (PDF) over the DOAs in a cluster. In general, the precise form
of pθ(θ) is not important, and also very difﬁcult to predict, but its mean angle and spread parameter is of
interest. Therefore, pθ(θ) is often taken as Gaussian N(θ0, σθ), and θ0 and σθ become the parameters
to be estimated. In the presence of spatially white noise, the array output x(n) will also be zero mean,
and its correlation matrix is given by
Rx = σ 2
s Rv(θ0, σθ) + σ 2I,
(11.57)
where σ 2
s is the signal power. Depending on the sampling time, x(n) may or not be temporally correlated,
but it is clear that a “sufﬁciently long” observation time is necessary in order for v(n) to reveal enough
information of Rv. Thus, assume that a batch of N samples of x(n) are available, where N is large enough
so that the sample correlation Rx is “close to” the true Rx in (11.57).
A very simple yet effective technique in the one-cluster case is proposed in [61]. The idea is to
exploit a spatial spectrum estimate P(θ), as given, e.g., by the conventional or the MVDR beamformer.
Provided the resolution is sufﬁcient, the spatial spectrum is approximately proportional to pθ(θ). Thus,
the mean DOA and the spread can be estimated as
ˆθ0 =

θ∈ θ P(θ)dθ

θ∈ P(θ)dθ ,
(11.58)
ˆσ 2 =

θ∈

θ −ˆθ0
2 P(θ)dθ

θ∈ P(θ)dθ
,
(11.59)
where  is the expected support of the DOA cluster. In general, the above non-parametric estimate of
ˆθ0 is accurate, whereas ˆσ 2 is more sensitive to the choice of  and to the resolution of the beamformer.
For multiple clusters, one may extend (11.57) to
Rx =
P

p=1
σ 2
pRv

θp, σθp

+ σ 2I,
(11.60)
where P is the number of clusters. In this case, a parametric technique is preferable. The most effective
methods are based on covariance matching [62]. Since these are computationally costly, suboptimal
techniques have been proposed, that only require searching over the mean DOA and spread parameters.
An interesting class of methods is based on generalizations of spectral-based techniques for point
sources, e.g., the MVDR spectrum [63,64]. In particular, in the method of [64], the parameter estimates
are found by localizing the P smallest minima of the 2D function
P(θ, σθ) =
R−1
x Rv(θ, σθ)

F = Tr

R−2
x R2
v(θ, σθ)

,
(11.61)
where ∥· ∥F denotes the Frobenius matrix norm. Clearly, for a point source model, pθ(θ) = δ(θ) and
Rv = a(θ0)aH(θ0), so if ∥a(θ)∥2 = M, (11.61) reduces to a non-parametric version of the Pisarenko
family of methods [65].

3.11.6 Non-Coherent Array Applications
495
An important special case of (11.55) is the case of a multiplicative noise, for example due to a
randomly time-varying medium. This is of relevance, e.g., in sonar applications. In this case, the received
signal is modeled as
x(n) =

a(θ) ⊙g(n)

s(n) + n(n),
(11.62)
where ⊙denotes the Schur product (elementwise multiplication). The ML estimator to this problem is
derived in [66], assuming g(n) to be a sequence of deterministic quantities to be estimated along with θ.
The resulting estimator has a surprisingly simple form, reminiscent of beamforming using the squared
data x(n) ⊙x(n) with the corresponding steering vector a(θ) ⊙a(θ).
3.11.6.2 Time series modeling
We have previously noted the close relation between spatial ﬁltering using a ULA and the DTFT. Thus,
it should not come as a surprise that methods derived for array processing are also useful for modeling
time series, even if only one sensor is available. The closest case is that of a pure complex sinusoidal
signal
s(n) = Ae jωt.
(11.63)
Suppose a batch of K samples of s(n), n = 1, . . . , K are available. Choosing an equivalent “array size”
M, 1 < M ≤K, we can form N = K −M vector-valued “array outputs”
x(n) =
⎡
⎢⎢⎢⎣
s(n)
s(n + 1)
...
s(n + M −1)
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
1
e jω
...
e j(M−1)ω
⎤
⎥⎥⎥⎦s(n) = a(ω)s(n).
(11.64)
Clearly, this model is identical to (11.6), here with a(ω) representing a DTFT vector. In the presence
of multiple sinusoids and noise, the model is identical to the spatial data model (11.11), with the only
difference that the noise vector samples will be temporally correlated due to the overlapping noise
samples in adjacent array outputs. Provided the scalar measurement noise is temporally white, it still
holds that the vector-valued noise is spatially white. Thus, all methods for DOA estimation are readily
available also for estimating the frequencies of superimposed sinusoids in white noise. Since the steering
vector has the form of a Vandermonde vector, as in the ULA case, the vast ﬂora of computationally
efﬁcient methods developed for such arrays are applicable, see Chapter 15 for details. It should be noted
that the same model (11.64) can be derived also for damped sinusoids, although the steering vector is
then a function of both the frequency and the damping, and the signal is obviously no longer stationary.
Next, consider the problem of blind multi-channel FIR modeling. Thus, an unknown signal sn is
transmitted and captured at an m-element antenna array. The receiver wishes to decode the transmitted
message, and therefore needs an estimate of the propagation channel. The received signal xn ∈Cm is
assumed to be an FIR ﬁltered version of the transmitted signal,
xn =
L−1

l=0
hlsn−l + nn,
(11.65)

496
CHAPTER 11 Introduction to Array Processing
where {hl}L
l=0 are the vector-valued channel taps to be estimated and nn is the receiver noise. It should be
noted that the same model can be obtained also for a scalar receiving antenna, provided over-sampling
by a factor of m is used (see [67] for details). Similar to (11.64), we choose an equivalent array size M
and form the array output vector (this time sampling backwards, due to the causality in (11.65))
x(n) =
⎡
⎢⎢⎢⎣
xn
xn−1
...
xn−M+1
⎤
⎥⎥⎥⎦= A(h)s(n) + n(n),
(11.66)
where we have deﬁned the signal vector
s(n) = [sn, sn−1, . . . , sn−L−M+2]T ,
(11.67)
and the “steering matrix” A(h) is given by
A(h) =
⎡
⎢⎢⎢⎢⎣
h1 h2 . . . hL−1 0
. . . 0
0 h1
...
hL−1
...
...
...
0
0 . . . 0
h1
h2
. . . hL−1
⎤
⎥⎥⎥⎥⎦
.
(11.68)
It is clear that (11.66) resembles the DOA estimation model (11.11), except that A(h) has a rather
different structure. The fact that A(h) is linear in its parameters, h = [hT
0 , . . . , hT
L−1]T , can of course be
exploited. Note that A(h) is full column rank by construction, as long as h0 and hL−1 are both different
from the null vector (implying that the FIR ﬁlter order must be properly chosen). Its dimensions are
Mm × (M + L −1), so if Mm > M + L −1, i.e., M > (L −1)/(m −1), then AH(h) has an
M −(L −1)/(m −1)-dimensional null-space. Similarly to (11.49), an estimate En of that nullspace can
be computed from the minor eigenvectors of the sample covariance matrix of x(n). Ideally A(h) ⊥En,
so the following blind FIR channel estimator is now natural [67],
ˆh = arg min
h
AH(h)En

2
F .
(11.69)
The linearity of A(h) in h means that (11.69) is nothing but a linear least-squares problem, which can
be solved very efﬁciently (although its dimensions can be large).
Subspace methods have also been successfully applied in a more general system identiﬁcation setting,
see, e.g., [15,68,69]. The problem then is to determine a general ﬁnite-dimensional model of a linear
multi-variable input-output system along with a stochastic model of the disturbances and noise from
measurements of input-output data. The case of purely stochastic modeling (output-data only), similar
to the multi-channel blind FIR modeling outlined above, is also treated. The subspace techniques are
capable of providing consistent estimates of a multi-variable state-space model of the data, without
resorting to iterative non-linear search procedures as required by traditional approaches. The methods
are now standard components in system identiﬁcation software, such as Matlab’s System Identiﬁcation
Toolbox.

3.11.6 Non-Coherent Array Applications
497
3.11.6.3 Source localization in sensor networks
Conventional DOA estimation methods are based on data collected by a relatively small sensor array
in the far-ﬁeld of the sources. The received data due to a single point source is usually assumed to
be perfectly coherent among the different sensors. In contrast, a sensor network consists of a set
of widely separated sensors, where each sensor can be a small array itself. Thus, it is not realis-
tic to assume perfect phase synchronization between the sensors and the processing cannot be done
coherently among all sensors. In return, the wide separation of sensors implies that the complete 2D
(or even 3D) positions of signal sources can be determined, and not just the directions of incoming
sources, provided sufﬁciently many of the sensors receive the transmitted signal. The sensors may be
of many different kinds, such as electromagnetic antennas, acoustic sensors, infrared or other envi-
ronmental monitoring systems. In most cases, they communicate by wireless communication links.
Common to these applications is the desire to reduce energy consumption and thus to increase bat-
tery lifetime. Thus, GPS may not be available and a major problem can be to localize the sensors
themselves [6].
Ingeneral,sourcelocalizationinsensornetworksisbasedononeormoreofthefollowingphenomena:
•
Direction-of-Arrival (DOA) from several sensor arrays.
•
Time Difference-of-Arrival (TDOA) between sensor pairs.
•
Signal strength measurements.
DOA-based estimation is possible by clustering sensors into coherent groups (subarrays), and measur-
ing the DOA from each such subarray. The estimated DOAs are then transmitted to a central node,
that performs a triangulation-type fusion of the various sensor data to determine the source posi-
tion. DOA-based estimation can be done using narrowband or wideband data. In contrast, TDOA-
based source localization requires wideband data to determine the relative time-delays between the
signals received at the various sensors. We refer to [70] for a review of such methods. A practical
approach that requires relatively little inter-sensor communication is to use the signal strength received
at the various sensors. If a model of the power loss as a function of the distance to the transmit-
ter is known, this can be used to combine the various power measurements at a central node. See
[71] for details, and Chapter 18 of this book for a more complete overview of the source localization
problem.
3.11.6.4 Microwave and ultrasound imaging
Classical radar assumes that targets are in the far-ﬁeld, and thus can be modeled as point sources.
The situation is quite different in ultrasonic imaging of a human body, see, e.g., [72]. In recent years
there has also been an increasing interest in near-ﬁeld radar applications, including microwave imaging
for breast cancer [73,74]. Although in most cases one is still concerned with one or a few strong
sources of backscattered energy, the medium of propagation causes the received signal to be severely
distorted. Thus, DOA estimation techniques designed for point sources are therefore not applicable.
The spread source modeling approach of Section 3.11.6.1 can be useful, but in general the presence
of severe background noise requires special treatment. The most common approach is to view the
problem as a spatial spectrum estimation and apply beamforming techniques similar to the MVDR

498
CHAPTER 11 Introduction to Array Processing
beamformer (11.35) [72–74]. A promising emerging technique is to apply a full-scale electromagnetic
(or acoustic) model of the scenario, including sensor and receiver characteristics as well as the “target”
in its environment (e.g., a cancer tumor) [75]. Although this is computationally very costly, the rapid
progress in numerical computation and parallel processing makes it a promising candidate for future
diagnostic imaging systems.
An application facing similar problems is through-the-wall imaging using a wideband radar tech-
nique. For the case of a relatively simple scenario with a known obstacle (wall), a geometric
beamforming-like approach is taken in [76]. In more complicated scenarios one can envision that
numerical approaches similar to [75] can give more accurate localization and increased resolution, but
the physical extent of the scenario (in wavelengths) makes the computational load challenging. In inter-
ferometric Synthetic Aperture Radar (SAR) imaging, two slightly displaced antenna arrays are used to
create a topographic map of the earth. In this case the narrowband assumption can be considered to
hold, and the effect of the random medium can therefore be modeled as a multiplicative noise, similar
to (11.62) but with g(n) a constant. In [77], several beamforming techniques are evaluated together with
parametric techniques. A combination of using MVDR (11.46) DOA estimation and Least-Squares
amplitude estimation (11.52) is favored.
3.11.7 Concluding remarks
Originating from the use antenna arrays in radar more than a century ago, array signal processing
has emerged as an active ﬁeld of research which has inﬂuenced a variety of application areas. We
have mentioned several of these in this introductory chapter, and more are presented in Chapter 20. One
obvious reason for the success is that multi-sensor processing is becoming increasingly more important,
and the power of DSP is readily available at low cost and ease of use. In addition, as we have seen
for example in Section 3.11.6, the generic sensor array model (11.10) ﬁnds applications way beyond
localization of plane waves arriving at an array of coherent sensors. See also [78] for an extensive list of
applications of the separable Non-Linear Least-Squares (NLLS) formulation (11.51). All of these are
candidates for trying other array signal processing methods than NLLS, some of which are mentioned
herein. Some of the emerging topics in sensor array and multi-channel signal processing are surveyed
in [79]. Thus, we may expect to see more inﬂuence of MIMO technology in practical systems, both for
wireless communication (where it is already included in the LTE and WIMAX standards) and radar. Not
the least important is near-ﬁeld microwave tomography using MIMO radar, which so far has focused
mostly on biomedical applications. Measurements that are resolved both in space and time are sought
for in the entire process industry (chemical processes, forestry, food processing etc.), and microwave
tomography has the potential to revolutionize this area. Techniques for distributed processing are also an
emerging topic that may walk into our everyday lives as the world becomes more and more connected.
In terms of mathematical methods, convex optimization has ﬁnally become a ubiquitous tool for array
signal processing researchers, and we foresee more attempts to marry “conventional” model-based
estimation techniques with machine learning. A particularly promising arena for such attempts is sparse
signal modeling, see, e.g., [80].

References
499
Relevant Theory: Signal Processing Theory
See Vol. 1, Chapter 1 Introduction: Signal Processing Theory
See Vol. 1, Chapter 2 Continuous-Time Signals and Systems
See Vol. 1, Chapter 3 Discrete-Time Signals and Systems
See Vol. 1, Chapter 4 Random Signals and Stochastic Processes
See Vol. 1, Chapter 9 Discrete Multi-Scale Transforms in Signal Processing
See Vol. 1, Chapter 11 Parametric Estimation
See Vol. 1, Chapter 12 Adaptive Filters
References
[1] R.J. Mailloux, Phased Array Antenna Handbook, second ed., Artech House, Boston and London, UK, 2005.
[2] N. Owsley, Sonar array processing, in: S. Haykin (Ed.), Array Signal Processing, Prentice-Hall, Englewood
Cliffs, NJ, 1985.
[3] A. Farina, Antenna-Based Signal Processing Techniques for Radar Systems, Artech House, Norwood, MA,
1992.
[4] A. Paulraj, R. Nabar, D. Gore, Introduction to Space-Time Wireless Communications, Cambridge University
Press, Cambridge, UK, 2003.
[5] A. Singer, J. Nelson, S. Kozat, Signal processing for underwater acoustic communications, IEEE Commun.
Mag. 47 (1) (2009) 90–96.
[6] N. Patwari, J. Ash, S. Kyperountas, A.O. Hero, R. Moses, N. Correal, Locating the nodes: cooperative
localization in wireless sensor networks, IEEE Signal Process. Mag. 22 (4) (2005) 54–69.
[7] H. Krim, M. Viberg, Two decades of array signal processing research: the parametric approach, IEEE Signal
Process. Mag. 13 (4) (1996) 67–94.
[8] H.V. Trees, Optimum Array Processing, John Wiley & Sons, Canada, 2002.
[9] G. Bienvenu, L. Kopp, Principle de la goniometrie passive adaptive, in: Proceedings of 7’eme Colloque
GRESIT, Nice, France, 1979, pp. 106/1–106/10.
[10] R. Schmidt, Multiple emitter location and signal parameter estimation, in: Proceedings of RADC Spectrum
Estimation Workshop, Rome, NY, 1979, pp. 243–258.
[11] G. Foschini, M. Gans, On limits of wireless communications in a fading environment when using multiple
antennas, Wireless Personal Commun. 6 (1998) 311–335.
[12] J. Li, P. Stoica, MIMO radar with colocated antennas, IEEE Signal Process. Mag. 24 (5) (2007) 106–114.
[13] A. Haimovich, R. Blum, L.J. Cimini, MIMO radar with widely separated antennas, IEEE Signal Process.
Mag. 25 (1) (2008) 116–129.
[14] P. Stoica, R. Moses, Spectral Analysis of Signals, Prentice Hall, Upper Saddle River, NJ, 2005.
[15] M. Viberg, On subspace-based methods for the identiﬁcation of linear time-invariant systems, Automatica 31
(12) (1995) 1835–1851.
[16] P. Van Overschee, B. De Moor, Subspace Identiﬁcation of Linear Systems: Theory, Implementation, Appli-
cations, Kluwer Academic Publishers, 1996.
[17] A. Nehorai, E. Paldi, Vector-sensor array processing for electromagnetic source localization, IEEE Trans.
Signal Process. 42 (2) (1994) 376–398.
[18] J. Hudson, Adaptive Array Principles, Peter Peregrinus, 1981.
[19] B.V. Veen, K. Buckley, Beamforming: a versatile approach to spatial ﬁltering, IEEE Acoust. Speech Signal
Process. Mag. (1988) 4–24.

500
CHAPTER 11 Introduction to Array Processing
[20] R. Monzingo, T. Miller, Introduction to Adaptive Arrays, SciTech Publishing, Inc., Raleig, NC, 2004.
[21] H. Steyskal, J. Herd, Mutual coupling compensation in small array antennas, IEEE Trans. Antennas Propag.
38 (1990).
[22] S. Mitra, Digital Signal Processing—A Computer-Based Approach, second ed., McGraw-Hill, New York,
2001.
[23] A. Moffet, Minimum-redundancy linear arrays, IEEE Trans. Antennas Propag. 16 (2) (1968) 172–175.
[24] H. Pumphrey, Design of sparse arrays in one, two, and three dimensions, J. Acoust. Soc. Am. 93 (3) (1993)
1620–1628.
[25] T. Laakso, V. Välimäki, M. Karjalainen, U. Laine, Splitting the unit delay, IEEE Signal Process. Mag. 13
(1996) 30–60.
[26] F. Harris, On the use of windows for harmonic analysis with the discrete Fourier transform, Proc. IEEE 66
(1) (1978) 51–83.
[27] P. Stoica, R. Moses, Introduction to Spectral Analysis, Prentice Hall, Upper Saddle River, NJ, 1997.
[28] B. Lau, Y. Leung, A Dolph-Chebyshev approach to the synthesis of array patterns for uniform circular arrays,
in: Proceedings ISCAS, Geneva, Switzerland, vol. 1, 2000, pp. 124–127.
[29] M. Doron, E. Doron, Waveﬁeld modeling and array processing, part I–spatial sampling, IEEE Trans. Signal
Process. 42 (10) (1994) 2549–2559.
[30] H. Lebret, S. Boyd, Antenna array pattern synthesis via convex optimization, IEEE Trans. Signal Process. 45
(3) (1997) 526–532.
[31] S. Boyd, L. Vandenberghe, Convex Optimization, Cambridge University Press, Cambridge, UK, 2004.
[32] M. Grant, S. Boyd, Y. Ye, CVX: Matlab software for disciplined convex programming, 2008.
<http://www.stanford.edu/boyd/cvx/>.
[33] J. Li, P. Stoica, Robust Adaptive Beamforming, John Wiley & Sons, Inc., Hoboken, NJ, 2006.
[34] S.Kay,FundamentalsofStatisticalSignalProcessing:EstimationTheory,Prentice-HallInternationalEditions,
Englewood Cliffs, NJ, 1998.
[35] I. Reed, J. Mallett, L. Brennan, Rapid convergence rate in adaptive arrays, IEEE Trans. Aerosp. Electron.
Syst. 10 (6) (1974) 853–863.
[36] J. Li, P. Stoica, Z. Wang, On robust capon beamforming and diagonal loading, IEEE Trans. Signal Process.
51 (7) (2003) 1702–1715.
[37] S. Vorobyov, A. Gershman, Z.-Q. Luo, Robust adaptive beamforming using worst-case performance opti-
mization: a solution to the signal mismatch problem, IEEE Trans. Signal Process. 51 (2) (2003) 313–324.
[38] D. Boroson, Sample size considerations for adaptive arrays, IEEE Trans. Aerosp. Electron. Syst. 16 (4) (1980)
446–451.
[39] F. Gustavsson, Adaptive Filtering and Change Detection, John Wiley & Sons, Ltd., Chichester, UK, 2000.
[40] A. Sayed, Fundamentals of Adaptive Filtering, John Wiley & Sons, Ltd., Hoboken, NJ, 2003.
[41] O.L. Frost III, An algorithm for linearly constrained adaptive array processing, Proc. IEEE 60 (8) (1972)
926–935.
[42] B. Widrow, P. Mantey, L. Grifﬁths, B. Goode, Adaptive antenna systems, Proc. IEEE 55 (1967) 2143–2159.
[43] B. Ottersten, R. Roy, T. Kailath, Signal waveform estimation in sensor array processing, in: Pro-
ceedings of 23rd Asilomar Conference on Circuits, Systems and Computers, November 1989,
pp. 787–791.
[44] F. Robey, D. Fuhrmann, E. Kelly, R. Nitzberg, A CFAR adaptive matched ﬁlter detector, IEEE Trans. Aerosp.
Electron. Syst. 28 (1) (1992) 208–216.
[45] E. Kelly, An adaptive detection algorithm, IEEE Trans. Aerosp. Electron. Syst. 22 (2) (1986) 115–127.
[46] A. Leshem, A.-J.V. der Veen, Direction-of-arrival estimation for constant modulus signals, IEEE Trans. Signal
Process. 47 (11) (1999) 3125–3129.

References
501
[47] G. Xu, T. Kailath, Direction-of-arrival estimation via exploitation of cyclostationary—a combination of tem-
poral and spatial processing, IEEE Trans. Signal Process. 40 (7) (1992) 1775–1786.
[48] J. Capon, High resolution frequency wave number spectrum analysis, Proc. IEEE 57 (1969)
1408–1418.
[49] C. Richmond, The CAPON-MVDR algorithm: threshold SNR prediction and the probability of resolution,
in: Proceedings of ICASSP 2004, Montreal, Canada, vol. 2, May 2004, pp. 217–220.
[50] M. Wax, T. Kailath, Detection of signals by information theoretic criteria, IEEE Trans. Acoust. Speech Signal
Process. 33 (2) (1985) 387–392.
[51] L. Zhao, P. Krishnaiah, Z. Bai, On detection of the number of signals in presence of white noise, J. Multivariate
Anal. 20 (1) (1986) 1–25.
[52] M. Kaveh, A.J. Barabell, The statistical performance of the MUSIC and the minimum-norm algorithms in
resolving plane waves in noise, IEEE Trans. Acoust. Speech Signal Process. 34 (1986) 331–341.
[53] J.Böhme,Estimationofsourceparametersbymaximumlikelihoodandnonlinearregression,in: Proc.ICASSP
84, vol. 9, 1984, pp. 271–274.
[54] M. Wax, Detection and estimation of superimposed signals, Ph.D. Dissertation, Stanford University, Stanford,
CA, March 1985.
[55] J. Böhme, Estimation of spectral parameters of correlated signals in waveﬁelds, Signal Process. 11 (1986)
329–337.
[56] P. Stoica, R. Moses, B. Friedlander, T. Söderström, Maximum likelihood estimation of the parameters of
multiple sinusoids from noisy measurements, IEEE Trans. Acoust. Speech Signal Process. 37 (1989) 378–
392.
[57] M. Viberg, B. Ottersten, Sensor array processing based on subspace ﬁtting, IEEE Trans. Signal Process. 39
(5) (1991) 1110–1121.
[58] J. Fessler, A. Hero, Space-alternating generalized expectation-maximization algorithm, IEEE Trans. Signal
Process. 42 (10) (1994) 2664–2677.
[59] J. Li, D. Zheng, P. Stoica, Angle and waveform estimation via RELAX, IEEE Trans. Aerosp. Electron. Syst.
33 (3) (1997) 1077–1087.
[60] A. Swindlehurst, T. Kailath, A performance analysis of subspace-based methods in the pres-
ence of model errors—Part I: The MUSIC algorithm, IEEE Trans. Signal Process. 40 (7) (1992)
1758–1774.
[61] M. Tapio, On the use of beamforming for estimation of spatially distributed signals, in: Proc. ICASSP 03,
Hong Kong, vol. 3, May 2003, pp. 3005–3008.
[62] B. Ottersten, P. Stoica, R. Roy, Covariance matching estimation techniques for array signal processing appli-
cations, Digital Signal Process. 8 (3) (1998) 185–210.
[63] A. Hassanien, S. Shahbazpanahi, A. Gershman, A generalized Capon estimator for multiple spread sources,
IEEE Trans. Signal Process. 52 (1) (2004) 280–283.
[64] A. Zoubir, Y. Wang, P. Charge, Efﬁcient subspace-based estimator for localization of multiple incoherently
distributed sources, IEEE Trans. Signal Process. 56 (2) (2008) 532–542.
[65] V.F. Pisarenko, On the estimation of spectra by means of non-linear functions of the covariance matrix,
Geophys. J. Roy. Astron. Soc. 28 (1972) 522–531.
[66] P. Stoica, O. Besson, A. Gershman, Direction-of-arrival estimation of an amplitude-distorted wavefront, IEEE
Trans. Signal Process. 49 (2) (2001) 269–276.
[67] E. Moulines, P. Duhamel, J.-F. Cardoso, S. Mayrargue, Subspace methods for the blind identiﬁcation of
multichannel FIR ﬁlters, IEEE Trans. Signal Process. 43 (2) (1995) 516–525.
[68] P. Van Overschee, B. De Moor, N4SID: subspace algorithms for the identiﬁcation of combined deterministic-
stochastic systems, Automatica 30 (1) (1994) 75–93 (special issue on Statistical Signal Processing and
Control).

502
CHAPTER 11 Introduction to Array Processing
[69] T. Katayama, Subspace Methods for System Identiﬁcation, Springer-Verlag, London, UK, 2005.
[70] J. Chen, K. Yao, R. Hudson, Source localization and beamforming, IEEE Signal Process. Mag. 19 (2) (2002)
30–39.
[71] X. Sheng, Y.-H. Hu, Maximum likelihood multiple-source localization using acoustic energy measurements
with wireless sensor networks, IEEE Trans. Signal Process. 53 (1) (2005) 44–53.
[72] J.-F. Synnevag, A. Austeng, S. Holm, Adaptive beamforming applied to medical ultrasound imaging, IEEE
Trans. Ultrason. Ferroelectr. Freq. Control 54 (8) (2007) 1606–1613.
[73] E. Fear, S. Hagness, P. Meaney, M. Okoniewski, M. Stuchly, Enhancing breast tumor detection with near-ﬁeld
imaging, IEEE Microwave Mag. 3 (1) (2002) 48–56.
[74] Y. Xie, B. Guo, L. Xu, J. Li, P. Stoica, Multistatic adaptive microwave imaging for early breast cancer detection,
IEEE Trans. Biomed. Eng. 53 (8) (2006) 1647–1657.
[75] A. Fhager, P. Hashemzadeh, M. Persson, Reconstruction quality and spectral content of an electromagnetic
time-domain inversion algorithm, IEEE Trans. Biomed. Eng. 53 (8) (2006) 1594–1604.
[76] M. Amin, F. Ahmad, Wideband synthetic aperture beamforming for through-the-wall imaging [lecture notes],
IEEE Signal Process. Mag. 25 (4) (2008) 110–113.
[77] F. Gini, F. Lombardini, Multibaseline cross-track SAR interferometry: a signal processing perspective, IEEE
Aerosp. Electron. Syst. Mag. 20 (8) (2005) 71–93.
[78] G. Golub, V. Pereyra, Separable nonlinear least squares: the variable projection method and its applications,
Inverse Prob. 19 (2) (2003) R1–R26 (topical review).
[79] J. Li, B. Sadler, M. Viberg, Sensor array and multichannel signal processing [in the spotlight], IEEE Signal
Process. Mag. 28 (5) (2011) 157–158.
[80] R.Chartrand,R.G.Baraniuk,Y.C.Eldar,M.A.T.Figueiredo,J.Tanner,Introductiontotheissueoncompressive
sensing, IEEE J. Sel. Top. Signal Process. 4 (2) (2010) 241–243.

12
CHAPTER
Adaptive and Robust
Beamforming⋆
Sergiy A. Vorobyov
Department of Signal Processing and Acoustics, Aalto University, FI-00076 AALTO, Finland and Department of
Electrical and Computer Engineering, University of Alberta, Edmonton, AB T6G 2V4, Canada
3.12.1 Introduction
Adaptive beamforming is a versatile approach to detect and estimate the signal-of-interest (SOI) at
the output of sensor array using data adaptive spatial or spatio-temporal ﬁltering and interference
cancellation [1–3]. Being a very central problem of array processing (see [4]), adaptive beamform-
ing has found numerous application to radar [5,6], sonar [7], speech processing [8], radio astronomy
[9,10], biomedicine [11,12], wireless communications [13–15], cognitive communications [16], and
other ﬁelds. The connection of adaptive beamforming to adaptive ﬁltering is emphasized in [4]. The
major differences, however, come from the fact that adaptive ﬁltering is based on temporal process-
ing of a signal, while adaptive beamforming stresses on spatial processing. The latter indicates also
that the signal is sampled in space, i.e., the signal is measured/observed by an array of spatially
distributed antenna elements/sensors. Electronic beamforming design problem consists of computing
optimal (in some sense that will be speciﬁed) complex beamforming weights for sensor measure-
ments of the signal. If such complex beamforming weights are optimized based on the input/output
array data/measurements, the corresponding beamforming is called adaptive to distinguish it from
the conventional beamforming where the beamforming weights do not depend on input/output array
data.
The traditional approach to the design of adaptive beamforming is to maximize the beamformer
output signal-to-interference-plus-noise ratio (SINR) assuming that there is no SOI component in
the beamforming training data [2,3]. Although such SOI-free data assumption may be relevant to
certain radar applications, in typical practical applications, the beamforming training snapshots also
include the SOI [17,18]. In the latter case, the SINR performance of adaptive beamforming can
severely degrade even in the presence of small signal steering vector errors/mismatches, because
the SOI component in the beamformer training data can be mistakenly interpreted by the adaptive
beamforming algorithm as an interferer and, consequently, it can be suppressed rather than being
protected. The steering vector errors are, however, very common in practice and can be caused by
a number of reasons such as signal look direction/pointing errors; array calibration imperfections;
non-linearities in ampliﬁers, A/D converters, modulators and other hardware; distorted antenna shape;
⋆Dedicated to the memory of Professor Alex B. Gershman.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00012-6
© 2014 Elsevier Ltd. All rights reserved.
503

504
CHAPTER 12 Adaptive and Robust Beamforming
unknown wavefront distortions/ﬂuctuations; signal fading; near-far wavefront mismodeling; local scat-
tering; and many other effects. The performance degradation of adaptive beamformer can also take
place even when the SOI steering vector is precisely known, but the sample size (the number of
samples at the training stage) is small [18]. One more reason for performance degradation is the
environmental non-stationarities because of the fast variations of the propagation channel and rapid
motion of interfering sources or antenna array [19]. As a result, the environment can signiﬁcantly
change from the beamforming training stage, at which the adaptive beamforming weights are com-
puted, to the beamforming testing stage, at which the beamforming weights are used. This may
severely limit the training sample size and increase the required frequency of beamforming weights
updates. To protect against the aforementioned imperfections, the robust adaptive beamforming is
considered.
This chapter is dedicated to the review of the main results in the ﬁelds of adaptive beamforming and
robust adaptive beamforming. We start by introducing the array data and beamforming models for both
cases on narrowband and wideband signals. Adaptive beamforming techniques are then reviewed includ-
ing the basic principles of adaptive beamforming design, minimum variance distortionless response
adaptive beamforming technique, analysis of optimal SINR, adaptive beamforming technique for gen-
eral rank sources. The general numerical algorithms for solving the adaptive beamforming problem such
as the gradient algorithm, the sample matrix inversion algorithm, and the projection adaptive beamform-
ing algorithm are also reviewed. Finally, the reduced complexity approaches to adaptive beamforming
and some techniques for wideband adaptive beamforming are explained. The motivations for robust
adaptive beamforming then follow. The particular robust adaptive beamforming techniques explained
in this chapter include the diagonally loaded sample matrix inversion beamforming technique, the
robust adaptive beamforming techniques with point and derivative mainbeam constraints, the gener-
alized sidelobe canceler, the adaptive beamforming techniques robust against the correlation between
the SOI and interferences such as spatial and forward-backward smoothing, the adaptive beamform-
ing techniques robust against rapidly moving interferences. A uniﬁed principle to minimum variance
distortionless response robust adaptive beamforming design is given and several most popular robust
adaptive beamforming techniques based on this principle are explained including the eigenspace-based
beamforming technique, the worst-case-based and doubly constrained robust adaptive beamforming
techniques, the probabilistically constrained robust adaptive beamforming, and the recently proposed
robust adaptive beamforming that uses as little as possible prior information, and others. Robust adap-
tive beamforming for general-rank source model and robust adaptive wideband beamforming are also
considered.
3.12.2 Data and beamforming models
In this chapter, the discussion is focussed on adaptive and robust adaptive beamforming and is based
on the assumptions of linear antenna geometry consisting of omni-directional antenna elements. Other
considerations, which are not directly related to the adaptive beamforming problem, such as non-linear
multi-dimensional antenna geometries and antenna elements with directional beampattern stay outside
of the scope of this chapter.

3.12.2 Data and Beamforming Models
505
3.12.2.1 Narrowband case
3.12.2.1.1
Point source
Consider an antenna array with M omni-directional antenna elements see also the introduction to array
processing in this encyclopedia [4]. The narrowband signal received by the antenna array at the time
instant k can be mathematically represented as
x(k) = xs(k) + xi(k) + xn(k),
(12.1)
where xs(k), xi(k), and xn(k) denote the M ×1 vectors of the SOI, interference, and noise, respectively.
The interference signal is generated by other than SOI sources that are not of interest (interferers and
possibly a jammer). For simplicity, all these components of the received signal (12.1) are assumed to be
statistically independent to each other. This assumption is fairly practical since the SOI and the signals
from interferers (other objects or users) are typically independent. The case of correlated/coherent
SOI and interference signals, however, can occur in practice, for example, because of the scattering
effect. This case will be considered separately in the chapter as well. The noise is typically isotropic or
diffuse and it can be accurately modeled as spatially white Gaussian noise (i.e., the noise components
are spatially uncorrelated at different antenna elements with the same noise power at each antenna
element). In other words, the M × M covariance matrix of the noise at the antenna array can be
expressed as Rn ≜E[xn(k)xH
n (k)] = σ 2
n I, where σ 2
n is the noise variance/power at a single antenna
element, I denotes the identity matrix of the same size as the number of antenna elements in the array,
and (·)H and E[·] stand for the Hermitian transpose and mathematical expectation, respectively. As
such, the noise is statistically independent from the SOI and interference signals.
In the case of point source, it is assumed that the SOI xs(k) arrives at the antenna array as a single
plane wave and it can be mathematically represented as
xs(k) = s(k)a(θs),
(12.2)
where s(k) is the signal waveform, a(θs) is the M×1 steering vector associated with the SOI, and θs is the
direction-of-arrival (DOA) of the SOI. Although the steering vector a(θs) is expressed only as a function
of the DOA θs, which is the source characteristic in the case of far distant point source, one should keep in
mind that it is in fact also a function of array geometry as well as propagation media characteristics. The
covariance matrix of the SOI for the case of point source can be, therefore, expressed in the form of the
following M × M rank-one matrix: Rs ≜E[xs(k)xH
s (k)] = E[|s(k)|2a(θs)aH(θs)] = σ 2
s a(θs)aH(θs),
where σ 2
s ≜E[|s(k)|2] is the SOI power.
The beamformer output is a weighted (with complex weights) linear combination of the signals
received by different antenna elements (see also Figure 1.3 in Chapter 1 of this book [4]) at the time
instant k and it can be mathematically expressed as
y(k) ≜
M

m=1
w∗
mxm(k) = wHx(k),
(12.3)
where wm is the complex weight corresponding to the mth antenna element, xm(k) in the signal received
by the mth antenna element at the time instant k, w ≜[w1, . . . , wM]T is the M × 1 complex weight

506
CHAPTER 12 Adaptive and Robust Beamforming
(beamforming) vector of the antenna array, and (·)T and (·)∗denote the transpose and conjugate,
respectively. The expression (12.3) is in fact a linear spatial ﬁlter. The beamforming complex weights
{w∗
m}M
m=1 can be applied to the signals received by the correspondent antenna elements right at these
antenna elements or at the receiver electronics. The weights {w∗
m}M
m=1 must be designed so that the SOI
would be presumed/ampliﬁed at the beamformer output, the interference signals would be canceled,
and the noise would be suppressed.
If only the SOI component is present, the beamformer output in the case of point source becomes
y(k) = wHa(θs)s(k). From the latter expression the interpretation of the beamformer in terms of a
special ﬁlter becomes intuitive. Indeed, wHa(θs) can be thought as the spatial transfer function from
s(k) at the direction θs to y(k). The magnitude G(θs) ≜|wHa(θs)| is the gain of the spatial ﬁlter towards
the SOI. It is similar to the ﬁnite impulse response (FIR) ﬁltering in the temporal domain where instead
of the spatial steering vector a(θs) we have a vector of time-delayed values of the input signal. For more
details see the introduction to array processing in this encyclopedia [4].
Under the assumption that the SOI steering vector a(θs) is known precisely, the optimal beamforming
vector w can be obtained by maximizing the beamformer output signal-to-noise-plus-interference ratio
(SINR) given as
SINR ≜
E

|wHxs(k)|2
E

|wH 
xi(k) + xn(k)

|2 = σ 2
s |wHa|2
wHRi+nw ,
(12.4)
where Ri+n ≜E[(xi(k) + xn(k))(xi(k) + xn(k))H] is the M × M interference-plus-noise covariance
matrix.
Because of the fact that Ri+n is unknown in practice, it is typically substituted in (12.4) by the
following data sample covariance matrix
R ≜1
K
K

k=1
x(k)xH(k),
(12.5)
where K is the number of training data samples which also include the desired signal component. Other
estimates of the data covariance matrix than (12.5) can be used [20]. It is worth mentioning here that
since the noise is spatially white Gaussian and uncorrelated with the SOI and interference signals, the
actual data covariance matrix can be found as
R ≜E[x(k)xH(k)] = ASAH + σ 2
n I,
(12.6)
where A ≜[a(θs), ai1, . . . , aiL] is the M × (L + 1) matrix of steering vectors of the SOI and the
interference sources under the assumption that all sources are the point sources, L is the number of
interference sources, S is the (L + 1) × (L + 1) source covariance matrix. The matrix S is diagonal if
the SOI and all interference signals are uncorrelated.
3.12.2.1.2
General-rank source
Typical situations in practice, however, are when the source signal is incoherently scattered (spatially
distributed) [21,22] and/or when it is characterized by ﬂuctuating (randomly distorted) wavefronts
[23,24]. Such situations are very typical, for example, for sonar and wireless communications. Partic-
ularly in sonar, effects of signal propagation through a randomly inhomogeneous underwater channel

3.12.2 Data and Beamforming Models
507
lead to a substantial perturbation of a regular wakeﬁeld in a random way and cause its coherence loss.
The result of such coherence loss is that the SOI may be subject to fast ﬂuctuations that destroy the point
source structure (12.2). In wireless communications, the common situation is the fast fading due to local
scattering in the vicinity of the mobile user. Local scattering also destroys the point source structure
(12.2). In such applications, the SOI can no longer be viewed by the antenna array as a point source and
the source model needs to be modiﬁed. Typically, the SOI is modeled as a spatially distributed source
with some central angle and angular spread. The source covariance matrix is, therefore, no longer a
rank-one matrix and, for example, in the incoherently scattered source case can be given as [25]
Rs =
 π/2
−π/2
ρ(θ)a(θ)aH(θ)dθ,
(12.7)
where ρ(θ) is the normalized angular power density (i.e.,
	 π/2
−π/2 ρ(θ)dθ = 1). The name “general rank
source” is reﬂecting the fact that the covariance matrix (12.7) can have any rank from 1 in a degenerate
case to M.
In the case of general-rank SOI, the SINR expression is given as
SINR = wHRsw
wHRi+nw.
(12.8)
Since the matrix Ri+n is not known in practice it is substituted by the data sample covariance matrix
(12.5) in practice.
3.12.2.2 Wideband case
In the wideband case, the SOI and/or the interference signals are widely spread in the frequency domain.
As a result, it is not possible to factorize the processing in temporal and spatial parts. Therefore, joint
space-time adaptive processing (STAP) has to be performed. The name STAP stresses on the fact that
the adaptive beamforming in the wideband case is no longer a spatial ﬁltering technique as for the
narrowband case, but rather a joint spatial and temporal ﬁltering. For more details see the chapter on
broadband beamforming in this encyclopedia [26].
Let the number of taps in the time domain be denoted as P. Let also the M array sensors be uniformly
spaced with the inter-element spacing less than or equal to c/2 fu, where fu = fc + Bs/2 is the
maximum frequency of the SOI/maximum passband frequency, fc is the carrier frequency, Bs is the
signal bandwidth, and c is the wave propagation speed. The general case of not necessarily uniform linear
array (ULA) is considered in a specialized chapter on broadband beamforming of this encyclopedia
[26]. The received signal at the mth antenna element goes to a wideband presteering delay ﬁlter with
the delay m. Let the output of the wideband presteering delay ﬁlter be sampled with the sampling
frequency fs = 1/τ, where τ in the sampling time and fs is greater than or equal to 2 fu. Then the
M P × 1 stacked snapshot vector containing P delayed presteered data vectors is the data vector x(k).
The beamformer output y(k) is then given by [27]
y(k) = wHx(k) = wT x(k),
(12.9)
where w is the real-valued M P × 1 beamformer weight vector, i.e., wM(p−1)+m = wm,p and, thus, wH
is equivalently substituted by wT .

508
CHAPTER 12 Adaptive and Robust Beamforming
In the wideband case, the steering vector also depends on frequency and in the case of a ULA is
given as
a( f , θ) = [e j2π f z1 sin (θ)/c, . . . , e j2π f zM sin (θ)/c]T ,
(12.10)
where zm is the mth antenna element location that for ULA is given as zm = (m −1)d with d denoting
the inter-element spacing. The overall M P × 1 steering vector can be expressed as
¯a( f , θ) = d( f ) ⊗(B( f )a( f , θ)),
(12.11)
where d( f ) ≜[1, e−j2π f τ, . . . , e−j2π f (P−1)τ]T , B( f ) ≜diag

e−j2π f 1, . . . , e−j2π f M 
, and ⊗
denotes the Kronecker product. Then the array response to a plane wave with the frequency f and angle
or arrival θ is
H( f , θ) = wT ¯a( f , θ).
(12.12)
The presteering delays are selected so that the SOI arriving from the look direction θ0 appears
coherently at the output of the M presteering ﬁlters so that [27]
B( f )a( f , θ0) = 1M,
(12.13)
where 1M is the M × 1 vector containing all ones. Then the steering vector towards the look direction
θ0 becomes
¯a( f , θ0) = d( f ) ⊗1M
(12.14)
and the array response towards such signal becomes
H( f , θ0) = wT ¯a( f , θ0) = wT C0d( f ),
(12.15)
where C0 ≜IP ⊗1M.
3.12.3 Adaptive beamforming
3.12.3.1 Basic principles
The signal-to-noise ratio (SNR) gain due to coherent processing of the signal x(k) received at the antenna
array, i.e., due to receive beamforming, is proportional to the quantity |wHa(θs)| in the case of a point
source. Here θs is the presumed SOI DOA. Using the Cauchy-Schwarz inequality, it can be easily found
that |wHa(θs)| ≤∥w∥· ∥a(θs)∥, where equality holds when
w = a(θs).
(12.16)
The expression (12.16) is referred to as the conventional nonadaptive beamforming. In the case when
a single point source signal is observed in the background of white Gaussian noise, the conventional
nonadaptive beamformer (12.16) is known to be optimal in the sense that it provides the highest possible
output SNR gain [3]. The idealistic condition of a single point source (no interferences) is, however,
impractical. Moreover, the precise estimate of the SOI steering vector a(θs) is required in (12.16). In
the presence of interferences, (12.16) is no longer optimal and, thus, adaptive beamforming technique
are of interest.

3.12.3 Adaptive Beamforming
509
The goal of adaptive beamforming as a spatial adaptive ﬁlter is to ﬁlter out (suppress) the undesired
interference and noise components xi(k) and xn(k) as much as possible, and to detect and obtain as
good as possible approximation/estimation of the desired signal xs(k), the estimate is denoted as ˆxs(k).
The beamforming weight vector w is optimized based on the received data x(k) for a number of time
instants k = 1, . . . , K during the training interval. Since the adaptive beamforming problem consists
of optimizing the beamforming weight vector w, the optimization criterion must be deﬁned.
One of the standard in ﬁlter design and estimation theory criteria is the mean-square error (MSE).
In the context of adaptive beamforming design, the MSE criterion can be expressed as
MSE ≜E[|d(k) −wHx(k)|2],
(12.17)
where d(k) is the desired signal copy. The corresponding optimization problem is then formulated as
follows:
min
w E[|d(k) −wHx(k)|2].
(12.18)
The solution of the minimum MSE problem is well known to be the Wiener-Hopf equation, which for
the optimization problem (12.18) becomes
wMSE = (E[x(k)xH(k)])−1E[xH(k)d(k)] = R−1rxd,
(12.19)
where R ≜E[x(k)xH(k)] is the data covariance matrix and rxd ≜E[xH(k)d(k)] in the correlation
vector between the data vector x and the reference signal d.
The block scheme of the adaptive beamformer based on MSE minimization (12.19) is shown in
Figure 12.1. The adaptive beamformer consists of the “master” and “slave” beamformers. The beam-
forming weights are adjusted at the “master” beamformer based on minimizing the difference between
the desired signal copy and the computed (using the antenna array measurements) output of the adaptive
beamformer. These weights are then passed to the “slave” beamformer for computing the estimate of the
desired signal ˆxs. The main limitation of such adaptive beamformer is the necessity to know the desired
signal copy d(k). In Figure 12.1, this necessity is reﬂected by introducing the generator of desired signal
copy. Although the knowledge of the desired signal copy is common in adaptive ﬁltering, in adaptive
beamforming the SOI is unknown. Thus, the adaptive beamformer based on MSE minimization is
impractical in most of the situations of interest.
The practically appealing criterion for adaptive beamforming design is the SINR (12.4) for the case
of a point source or (12.8) for the case of a general-rank source. Obviously, the SINR does not depend
on re-scaling of the beamforming vector w, that is, if wopt is an optimal weight vector then αwopt is
another optimal weight vector as well. Here α is a scaling factor. Therefore, in the case of point source,
the maximization of the SINR (12.4) is equivalent to the following constrained optimization problem
min
w wHRi+nw subject to wHa(θs) = const,
(12.20)
where “const” is any constant, for example, const = 1. The optimization problem (12.20) and its
solution are known under the name of minimum variance distortionless response (MVDR) adaptive
beamforming. Here the “minimum variance” stands for the fact that the objective of the optimization
problem (12.20) corresponds to the variance minimization of the signal at the output of the adaptive

510
CHAPTER 12 Adaptive and Robust Beamforming
w
w
w
wN
1
2
3
Σ
+
−
+
d
w
w
w
wN
Σ
3
2
1
S
x^
MASTER
SLAVE
GENERATOR
OF DESIRED
SIGNAL
COPY
FIGURE 12.1
Adaptive beamforming based on MSE minimization.
beamformer. The term “distortionless response” refers to the constraint of the optimization problem
(12.20), which requires the response of the adaptive beamformer towards the direction of the SOI
steering vector a(θs) to be ﬁxed and undistorted.
Theoptimizationproblem(12.20)canbesolvedinclosed-formusingtheLagrangemultipliermethod.
Speciﬁcally, the Lagrangian for the problem (12.20) is given as
L(w, λ) = wHRi+nw + λ(1 −wHa(θs)),
(12.21)
where λ is a Lagrange multiplier. The solution of (12.20) is then obtained by ﬁnding the gradient of the
Lagrangian (12.21), equating it to zero, and solving the so-obtained equation. This equation is
∇wL(w, λ) = Ri+nw −λa(θs) = 0
(12.22)
and it can be rewritten equivalently as
Ri+nw = λa(θs).
(12.23)
Then, the solution of (12.23) can be easily found as
wopt = λ R−1
i+na(θs).
(12.24)

3.12.3 Adaptive Beamforming
511
This is a spatial version of the Wiener-Hopf equation. Compared to (12.19), there is the SOI spatial
signature/steering vector a(θs) in (12.24) instead of the correlation vector rxd. Moreover, there is the
interference-plus-noise covariance matrix Ri+n instead of the data covariance matrix R. The Lagrange
multiplier λ can be easily found by substituting (12.24) in the distortionless response constraint of the
original optimization problem (12.20) and solving the corresponding equation for λ. The result is
λ =
1
aH(θs)R−1
i+na(θs)
.
(12.25)
Finally, substituting (12.25) in (12.24), the closed-form expression for the MVDR beamforming can be
obtained in the following form:
wMVDR =
1
aH(θs)R−1
i+na(θs)
R−1
i+na(θs).
(12.26)
The block scheme of the adaptive beamformer based on SINR maximization is shown in Figure 12.2.
According to this block scheme, the beamforming weights are computed at the adaptive processor, which
implements the estimation of the covariance matrix Ri+n and then computes the beamforming weight
vectoraccordingto(12.26). Theinputdatafortheadaptiveprocessoraretheantennaarraymeasurements
x(k), while the output, which is passed to the antenna elements, is the vector of optimal beamforming
weights w. If the received signal is free of the desired signal component, the sample estimate of the
w
w
w
wN
1
2
3
Σ
xS^
ADAPTIVE
PROCESSOR
FIGURE 12.2
Adaptive beamforming based on SINR maximization.

512
CHAPTER 12 Adaptive and Robust Beamforming
covariance matrix Ri+n can be obtained based on the expression (12.5). Otherwise, only the sample
estimate of the data covariance matrix R can be found by using (12.5). The latter case when the signal
of interest is present in the data vector x is, however, common in practice.
3.12.3.2 MVDR beamforming with data covariance matrix
Even if the SOI is present in the data vector x(k), but the estimate of the data covariance matrix is
perfect and the steering vector of the SOI a(θs) is known precisely, the resulting beamformer that uses
the data covariance matrix instead of the interference-plus-noise covariance matrix is equivalent to the
MVDR beamformer of (12.26). Indeed, the data covariance matrix in the case of point source can be
represented by explicitly using the interference-plus-noise covariance matrix as
R ≜E[x(k)xH(k)] = σ 2
s a(θs)aH(θs) + Ri+n.
(12.27)
Ignoring the immaterial for the SINR at the output of the adaptive beamformer coefﬁcient
1/aH(θs)R−1
i+na(θs) in (12.26), using the data covariance matrix (12.27) instead of the interference-plus-
noise covariance matrix, and applying consequently the matrix inversion lemma, it can be shown that
R−1a(θs) =

Ri+n + σ 2
s a(θs)aH(θs)
−1
a(θs) =

R−1
i+n −
R−1
i+na(θs)aH(θs)R−1
i+n
1/σ 2s + aH(θs)R−1
i+na(θs)

a(θs)
= R−1
i+na(θs) −R−1
i+na(θs)aH(θs)R−1
i+na(θs)
1/σ 2s + aH(θs)R−1
i+na(θs)
=

1 −
aH(θs)R−1
i+na(θs)
1/σ 2s + aH(θs)R−1
i+na(θs)

R−1
i+na(θs)
= αR−1
i+na(θs),
(12.28)
where the coefﬁcient α ≜1

1 + σ 2
s aH(θs)R−1
i+na(θs)

is immaterial for the output SINR of the
adaptive beamformer.
3.12.3.3 Optimal SINR
The optimal output SINR is the maximum SINR obtained by substituting the optimal MVDR beam-
forming vector (12.26) in the SINR expression (12.4). Speciﬁcally, the optimal SINR in the case of a
point source is given by
SINRopt =
σ 2
s

aH(θs)R−1
i+na(θs)
2
aH(θs)R−1
i+nRi+nR−1
i+na(θs)
= σ 2
s aH(θs)R−1
i+na(θs).
(12.29)
The expression (12.29) is in fact an upper bound for the output SINR, obtained for the case of no
interference.
For rough estimation of the optimal SINR in the case when there are only a few uncorrelated
interferences and the signal is well separated from them, the interference-plus-noise covariance matrix
can be approximated by a scaled identity matrix with a scaling coefﬁcient representing the aggregate

3.12.3 Adaptive Beamforming
513
power of the interferences and noise denoted as σ 2. Then the upper bound for the optimal SINR
(12.29) is
SINRopt ≃σ 2
s
σ 2 aH(θs)a(θs) = M σ 2
s
σ 2 ,
(12.30)
where for obtaining the last equality, the fact that the squared norm of the steering vector equals to the
number of sensors in the antenna array, i.e., ∥a(θs)∥2 = M, has been used. Thus, roughly, the optimal
SINR is upper bounded by the product of the input SINRs at the individual antenna elements and the
total number of antenna elements in the antenna array.
3.12.3.4 Adaptive beamforming for general-rank source
In the case of general-rank source, the SINR expression (12.8) is the one that has to be used. The
corresponding MVDR-type optimization problem can be then formulated as
min
w wHRi+nw subject to wHRsw = 1.
(12.31)
The solution of the optimization problem (12.31) is well known to be the principal eigenvector of the
matrix product R−1
i+nRs, that is mathematically expressed as
wopt = P

R−1
i+nRs

,
(12.32)
where P[·] denotes the operator that computes the principal eigenvector of a matrix. The solution
(12.32) is of a limited practical use because in most applications, the matrix Rs is unknown, and often
no reasonable estimate of it is available. However, if the estimate of Rs is available as well as the estimate
of Ri+n, (12.32) provides a simple solution to the adaptive beamforming problem for the general-rank
source. The solution of (12.32) can be equivalently found as the solution of the characteristic equation
for the matrix R−1
s Ri+n, that is, R−1
s Ri+nw = λw, if the matrix Rs is full-rank invertible. In practice,
however, the rank of the desired source can be smaller than the number of sensors in the antenna array
and the source covariance matrix Rs may not be invertible, while the matrix Ri+n is guaranteed to be
invertible due to the presence of the noise component. Therefore, the solution (12.32) is always preferred
practically.
3.12.3.5 Gradient adaptive beamforming algorithms
The interference-plus-noise and data covariance matrices are unknown in practice. Assuming that there
is a ﬁnite number of training snapshots x(k) that do not contain the SOI component and that the SOI
steering vector a(θs) is known precisely, the historically ﬁrst adaptive beamforming method is the
gradient algorithm developed back in the 1960s of the last century [28]. Similar to the least-mean
square (LMS) adaptive ﬁltering, the gradient adaptive beamforming algorithm can be mathematically
expresed as
w(k + 1) = w(k) + μ

a(θs) −x(k)xH(k)w(k)

,
(12.33)
where w(k) stands for the beamforming weight vector at the kth iteration, i.e., after processing the kth
data snapshot, and μ is the step size of the LMS algorithm. The convergence condition for the gradient

514
CHAPTER 12 Adaptive and Robust Beamforming
adaptive beamforming algorithm is similar to that of the LMS convergence condition and is formulated
as follows. The beamforming vector w(k) converges to the MVDR beamforming solution (12.26) if
0 < μ <
2
λmax[Ri+n],
(12.34)
where λmax[·] denotes the maximum eigenvalue of a square matrix. Finding the maximum eigenvalue
required in (12.34) is computationally complex. Hence, using the property that the maximum eigenvalue
of a positive semi-deﬁnite square matrix is smaller or equal to the trace of such matrix, (12.34) can be
simpliﬁed as
0 < μ <
2
Tr(Ri+n),
(12.35)
where Tr(·) stands for the trace of a square matrix.
The covariance matrix Ri+n is, however, not known in practice. Thus, the choice of the step size
μ that guarantees the convergence of the algorithm (12.33) is a nontrivial practical issue. Another
main disadvantage of the gradient adaptive beamforming algorithm is that the convergence depends on
eigenvalue spread of the matrix Ri+n and may be very slow. To demonstrate it, the following simulation
example is considered.
A ULA consists of M = 8 omni-directional sensors spaced half-wavelength apart from each other.
A single SOI impinges on the antenna array form the direction θs = 0◦with SNR = 0 dB, while a
single interference impinges on the antenna array form the direction θi = 30◦with interference-to-
noise ratio (INR) = 40 dB. The gradient adaptive beamforming algorithm (12.33) is tested for three
different values of the step size: μ1 = 1/50 Tr(Ri+n), μ2 = 1/15 Tr(Ri+n), and μ3 = 1/5 Tr(Ri+n).
The results are shown in Figure 12.3 which demonstrates the convergence of (12.33) for different values
of μ in terms of the output SINR in (dB) versus the number of snapshots, i.e., the number of algorithm
iterations. The optimal SINR (12.29) that provides an absolute upper bound for the output SINR of an
adaptive beamformer is also shown. It can be seen from Figure 12.3 that the convergence is faster for
larger μ, but the variance of the output SINR values distribution is signiﬁcantly higher compared to the
case of small μ. Moreover, even in the case of fastest convergence, the number of iterations required
for convergence, i.e., the required number of training snapshots is well above 1000 which is too large
number in most practical applications. As an extreme example, in radar ﬁeld only a single snapshot may
be available.
3.12.3.6 Sample matrix inversion adaptive beamformer
The sample matrix inversion (SMI) adaptive beamformer [29] is obtained by replacing the interference-
plus-noise covariance matrix Ri+n in the MVDR beamformer (12.26) with the sample estimate of the
data covariance matrix (12.5). Then the expression for the corresponding beamformer is given as
wSMI = R−1a(θs).
(12.36)
Under the assumption shared by all traditional adaptive beamforming techniques that the SOI com-
ponent is not present in the training data, the requirement of the SMI beamformer on the number of
training snapshots is given by the so-called Reed-Mallett-Brennan (RMB) rule [29]. It states that the

3.12.3 Adaptive Beamforming
515
0
1000
2000
3000
4000
5000
6000
7000
−30
−25
−20
−15
−10
−5
0
5
10
15
20
MU1
MU2
MU3
OPTIMAL SINR
NUMBER OF ITERATION
SINR (DB)
FIGURE 12.3
SINR versus the number of training snapshots (number of iterations) for the gradient adaptive beamforming
algorithm with different choices of the algorithm step size.
mean losses (relative to the optimal SINR) due to the SMI approximation of wMVDR (12.26) do not
exceed 3 dB if
K ≥2M.
(12.37)
Hence, the SMI beamformer has in general fast convergence rate that is much faster than that of the
gradient adaptive bemforming algorithm.
3.12.3.7 Projection adaptive beamforming methods
Although the RMB rule for the SMI beamformer provides a signiﬁcantly faster convergence rate com-
pared to the gradient adaptive beamforming algorithm, the number of required training snapshots may
be still quite signiﬁcant especially for large arrays. The so-called Hung-Turner or projection adaptive
beamformer allows to reduce the number of training snapshots even further [30].
Under the standard for traditional adaptive beamforming techniques assumption that the SOI compo-
nent is not present in the training data and also under the assumption that the noise power is negligible,
the inverse of the data covariance matrix R−1 can be closely approximated by the orthogonal pro-
jection matrix P⊥
A ≜I −A(AHA)−1AH where the matrix A in the absence of the SOI becomes
A ≜[ai1, . . . , aiL], i.e., it only consists of L interference steering vectors. The interference steering vec-
tors are unknown in practice and, thus, P⊥
A is also unknown. However, under the aforementioned assump-
tions of no SOI and negligible noise power, P⊥
A can be closely approximated by the data-orthogonal

516
CHAPTER 12 Adaptive and Robust Beamforming
projection matrix P⊥
X ≜I −X(XHX)−1XH, where X is the matrix of available training snapshots.
Thus, the following train of approximate equalities holds:
R−1
i+n ≃P⊥
A ≃P⊥
X.
(12.38)
Replacing R−1
i+n in (12.26) by the data-orthogonal projection matrix as in (12.38), the Hung-Turner
adaptive beamforming algorithm can be written as
wHT = (I −X(XHX)−1XH)a(θs).
(12.39)
For this method, a satisfactory performance can be achieved with [30]
K ≥L.
(12.40)
The optimal value of K is [30]
Kopt =

(M + 1)L −1
(12.41)
which may be signiﬁcantly smaller than the value given by the RMB rule for the SMI beamformer
especially for large antenna arrays and for the scenarios with small number of interferences. The
drawback of the projection adaptive beamformer is, however, that the number of interference sources
should be known a priori.
3.12.3.8 Reduced complexity approaches to adaptive beamforming
The Hung-Turner adaptive beamforming algorithm (12.39) is especially efﬁcient when the number of
sensors in the array is much larger than the number of interferences. However, in some applications the
number of sensors in the array, or equivalently, the number of adaptive degrees of freedom (adaptive
beamforming weights) is so large that the computational complexity of the beamformer (12.39) becomes
high. For example, the over-the-horizon radar may consists of hundreds and thousands of antenna
elements [31], while the number of interferences may be relatively few. In such cases, partially adaptive
arrays can be used to reduce the amount of computations [3].
The idea of partially adaptive array is to use nonadaptive (data-independent) preprocessor to reduce
the number of adaptive channels. Mathematically, such nonadaptive preprocessor can be expressed as
y(k) = THx(k),
(12.42)
where T is an M × N (N < M) ﬁxed preprocessing full-rank matrix and y(k) has a reduced dimension
of N × 1 relative to M × 1 for the original data vector x(k). The block scheme of the partially adaptive
beamformer is shown in Figure 12.4 where the M measurements of the antenna array are ﬁrst prepro-
cessed by multiplying the vector x(k) to the preprocessing matrix T. Then the adaptive beamformer is
applied to the preprocessed vector y(k).
There are two type of preprocessors: subarray preprocessing and beamspace preprocessing. An
example of partially adaptive beamformer with subarray preprocessor is shown in Figure 12.5. In this
example, the matrix T takes a form of
TT =
1
√
3
⎡
⎣
1 1 1 0 0 0 0 0 0
0 0 0 1 1 1 0 0 0
0 0 0 0 0 0 1 1 1
⎤
⎦.
(12.43)

3.12.3 Adaptive Beamforming
517
T
Σ
w1
w2 w3
wM
1
2
3
N
1
2
3
M
FIGURE 12.4
Block scheme of the partially adaptive beamformer.
Σ
Σ
Σ
Σ
w
w
w
1
2
3
FIGURE 12.5
An example of partially adaptive beamformer based on subarray preprocessing.

518
CHAPTER 12 Adaptive and Robust Beamforming
It can be easily seen that TT T = I for (12.43). It is a desired property since the preprocessing may lead
to colored noise if TT T ̸= I. However, the noise remains spatially white if TT T = I.
The preprocessing of type (12.43) or a general preprocessing that follows (12.42) changes the array
manifold. We say that the element-space of the antenna array is transformed into the beam-space of a
smaller dimension to stress on the fact that the resulting array manifold is changed and, thus, the new
SOI steering vector is
˜a(θs) = THa(θs).
(12.44)
The relationship between the element-space and beam-space is also shown in Figure 12.6 for a certain
partially adaptive beamformer based on subarray preprocessing. For an arbitrary preprocessor, the
covariance matrix of the preprocessed data y(k) can be expressed as
Ry ≜E[y(k)yH(k)] = THE[x(k)xH(k)]T = THRT.
(12.45)
Substituting the expression (12.6) for the actual data covariance matrix in (12.45), we obtain
Ry = THASAHT + σ 2
n THT = ASAH + Q,
(12.46)
where
A ≜THA,
(12.47)
Q ≜σ 2
n THT,
(12.48)
beam 1
beam 2
beam 3
beamspace
elementspace
1
w
2
w
w3
Σ
FIGURE 12.6
Element-space and beam-space of a partially adaptive beamformer based on subarray preprocessing.

3.12.3 Adaptive Beamforming
519
and the noise covariance matrix for the preprocessed data Q may not be a scaled identity matrix in
general. Thus, while designing the preprocessing matrix the condition
THT = I
(12.49)
has to be ensured.
Existing designs for the preprocessing matrix T that satisfy the condition (12.49) are the discrete
Fourier transform (DFT)-based beamspace preprocessing technique and the spheroidal sequences tech-
nique [3,32,33]. Both techniques consider an angular sector [θmin, θmax] where the SOI is likely to be
located, i.e., θs ∈[θmin, θmax], and attempt to design a set of vectors that are orthonormal in this sector.
Such orthonormal vectors form the preprocessing matrix T and guarantee that the property (12.49) is
satisﬁed.
The DFT-based beamspace preprocessing matrix is expressed as
T =

a(θmin), a(θmin + θ), . . . , a(θmax −θ), a(θmax)

,
(12.50)
where all vectors are DFT orthonormal vectors covering the angular sector [θmin, θmax] with an angular
sampling interval θ.
The essence of the spheroidal sequence technique [33] to the design of the preprocessing matrix T
(beamspace transformation) [32] is to take the principal eigenvectors of the matrix
 θmax
θmin
a(θ)aH(θ)dθ
(12.51)
as columns of T. Since these columns are the eigenvectors, they will be orthonormal as desired.
3.12.3.9 Wideband adaptive beamforming
One popular approach to wideband beamforming is to decompose the baseband waveforms into narrow-
band frequency components by the means of fast Fourier transform (FFT) [34,35]. Subsequently, the
subbands can be processed independently from each other using narrowband beamforming techniques
as it is shown in Figure 12.7. Then any of the above discussed adaptive beamforming methods can be
used to solve each narrowband beamforming problem. Thus, P adaptive beamforming problems, each
for the beamforming vector of length M, are needed to be solved. The time-domain beamformer output
samples are obtained by applying an inverse FFT (IFFT) of the output samples of the individual narrow-
band beamformers. However, such FFT-based wideband beamforming technique is not optimal, since
correlations between the frequency domain snapshot vectors of different subbands are not taken into
account. Although these correlations can be reduced by increasing the FFT length, the latter requires a
larger training data set [34].
Based on the wideband data and beamforming models introduced in Section 3.12.2.2, another
approach to wideband beamforming that does not require subband decomposition has been devel-
oped [27]. The block scheme of such adaptive beamformer is shown in Figure 12.8. As explained in
Section 3.12.2.2, this beamformer uses a presteering delay front-end consisting of presteering delay
ﬁlters to time-align the desired signal components in different sensors. Then the presteering delays are

520
CHAPTER 12 Adaptive and Robust Beamforming
FFT
FFT
FFT
narrowband
adaptive
beamformer
Σ
(subband  2)
narrowband
adaptive
beamformer
(subband  1)
narrowband
adaptive
beamformer
(subband    )
P
FIGURE 12.7
Subband processing scheme for wideband adaptive beamforming.
τ
τ
τ
τ
τ
τ
w11
w12
w1
w21
w22
w2
wN
wN
wN
1
2
Δ
Δ
Δ
1
2
N
Σ
P
P
P
FIGURE 12.8
Block scheme of the presteered wideband adaptive beamformer.

3.12.4 Robust Adaptive Beamforming
521
followed by FIR ﬁlters, each of length P. The beamformer output is then the sum of the ﬁltered wave-
forms. The weights of such spatial-temporal ﬁlter for the wideband MVDR beamformer are designed
to minimize the output power subject to the distortionless response constraint for the SOI. Multiple
mainbeam constraints are required to protect the SOI in the frequency band of interest. The distor-
tionless response constraint is formulated for the steering vector (12.14) after the SOI components in
different sensors are made identical at the presteering stage. Then the narrowband adaptive beamform-
ing algorithms introduced in this section can be extended relatively straightforwardly for the STAP
shown in Figure 12.8. Moreover, the so-called generalized sidelobe canceler-type of techniques that
will be explained in Section 3.12.4.4 can be straightforwardly used [27]. For more details and designs
for wideband adaptive beamforming see also the specialized chapter on broadband beamforming in this
encyclopedia [26].
3.12.4 Robust adaptive beamforming
3.12.4.1 Motivations
The result (12.28) on the equivalence between the MVDR adaptive beamformer with the interference-
to-noise covariance matrix and the one with the data covariance matrix holds true only under the
conditions that
•
there is inﬁnite number of snapshots available at the training stage and the data covariance matrix
can be estimated exactly or at least with high accuracy,
•
the SOI steering vector a(θs) is known precisely.
However, these conditions are not satisﬁed in practice since the data covariance matrix R cannot be
known exactly and its estimate R typically contains the SOI component where the desired signal steering
vector a(θs) may be known imprecisely. The applications where the SOI component is always present in
the training data include mobile communications, passive source location, microphone array speech pro-
cessing, medical imaging, radio astronomy, etc. The inaccuracies in the knowledge of the SOI steering
vector may appear for multiple reasons associated with imperfect knowledge of the source characteris-
tics, propagation media or antenna array itself. For example, even small look direction/signal pointing
errors can lead to signiﬁcant degradation of the adaptive beamformer performance [36,37]. Similarly,
an imperfect array calibration and distorted antenna shape can also lead to signiﬁcant degradations [38].
Other common causes of the adaptive beamformer’s performance degradation are the array manifold
mismodeling due to source wavefront distortions resulting from environmental inhomogeneities [39],
nea-far problem [40], source spreading and local scattering [41–43], and so on.
All the aforementioned issues are addressed in the ﬁeld of robust adaptive beamforming. One of
the earlier excellent reviews of the ﬁeld is [44]. However, many new techniques and approaches have
been developed since this review. This section aims at revising the most signiﬁcant robust adaptive
beamforming techniques.

522
CHAPTER 12 Adaptive and Robust Beamforming
3.12.4.2 Diagonally loaded SMI beamformer
Even in the ideal case when the SOI steering vector is precisely known, the SOI presence in the training
data may dramatically reduce the convergence rates of adaptive beamforming algorithms as compared
with the SOI-free training data case [18]. This may cause a much more substantial degradation of the
performance of adaptive beamforming techniques in situations of small training sample size compared
to the prediction given, for example, by the RMB rule (12.37) for the SMI adaptive beamformer (12.36).
By adding a regularization term in the objective function of the optimization problem (12.20) that
penalizes the imperfections in the data covariance matrix estimate due to small sample size and other
effects, the problem (12.20) can be reformulated as
min
w wHRw + γ ∥w∥2
subject to wHa(θs) = 1,
(12.52)
where γ is some penalty parameter. The solution to the problem (12.52) is given by the well known
diagonally loaded or shortly just loaded SMI (LSMI) beamformer [17,45,46]
wLSMI = R−1
DLa(θs),
RDL ≜R + γ I,
(12.53)
where the empirically-optimal penalty weight γ equals to double the noise power [17]. LSMI beam-
former allows to converge faster than in 2M snapshots suggested by the RMB rule.
LSMI convergence rule: the mean losses (relative to the optimal SINR) due to the LSMI approxima-
tion of wMVDR in (12.26) do not exceed a few dB’s if
K ≥L.
(12.54)
Interestingly, for properly selected γ , the LSMI beamformer is also efﬁcient in the case when the
desired signal steering vector is mismatched. This fact will be explained in details later. However, the
choice of γ is not a trivial problem for the LSMI beamformer. Another important observation is that
the convergence rule for the LSMI beamformer coincides with that of the Hung-Turner beamformer.
Thus, the Hung-Turner beamformer can also be classiﬁed as robust against small sample size.
To demonstrate the efﬁciency of the LSMI beamformer compared to the SMI beamformer, the
following simulation example is considered. A ULA consists of 10 omni-directional sensors spaced
half wavelength apart from each other. The DOA of a single SOI is θs = 0◦and SNR = 0 dB, while
the DOA of a single interference is θi = 30◦and INR = 40 dB. Figures 12.9 and 12.10 show the
beampatterns of the SMI and LSMI beamformers, respectively. The number of training snapshots for
the SMI beamformer equals to K = 20 that satisﬁes the RMB rule (12.37), while the number of training
snapshots for the LSMI beamformer equals only K = 2 that satisﬁes the LSMI convergence rule (12.54).
It can be seen from the ﬁgures that despite the fact that the number of training snapshots for the LSMI
beamformer is 10 times smaller than that for the SMI beamformer, the beampattern corresponding to the
LSMI beamformer has a signiﬁcantly higher mainlobe and lower sidelobes. The parameter γ for the
LSMI beamformer has been selected as double the noise power.
In addition, Figure 12.11 demonstrates the convergence rate for the SMI beamformer for two cases
when the SOI component is not present in the training snapshots and when it is present. The same
simulation set up as above has been used. It can be seen from this ﬁgure that the presence of the SOI
component in the training snapshots signiﬁcantly slows down the convergence of the SMI beamformer.
The same conclusion is true for the LSMI beamformer with ﬁxed diagonal loading factor γ that is
selected as double the noise power.

3.12.4 Robust Adaptive Beamforming
523
−80
−60
−40
−20
0
20
40
60
80
−60
−50
−40
−30
−20
−10
0
DIRECTIONAL PATTERN (DB)
ANGLE (DEGREES)
SMI, 20 SNAPSHOTS
FIGURE 12.9
Beampattern of the SMI beamformer for the number of snapshots K = 2M = 20 that satisﬁes the RMB rule
(12.37).
3.12.4.3 Look direction mismatch (pointing error) problem
Although the mismatch in the desired signal steering vector can be caused by a number of reasons,
the look direction mismatch (pointing error) has been considered historically ﬁrst. Even a very slight
look direction mismatch can lead to the effect that is known as the signal cancellation phenomenon.
This phenomenon is schematically demonstrated in Figure 12.12 where the presumed DOA of the SOI
differs from the real DOA by few degrees. The adaptive beamformer misinterprets the desired signal
with an interference and puts the null in the direction of the SOI. The signal cancellation phenomenon
may cause a performance breakdown for adaptive beamformer and, thus, robust adaptive beamforming
techniques become vital.
To stabilize the mainbeam response of adaptive beamformer in the case of pointing error, additional
constraints are required. If all additional constraints are of the same type as the destortionless response
constraint, i.e., linear constraints, the optimization problem can be reformulated as
min
w wHRw subject to CHw = f,
(12.55)
where C and f are some Q × M and Q × 1 matrix and vector, respectively. Depending on the choice
of C or f, we may have point or derivative mainbeam constraints [27,47].

524
CHAPTER 12 Adaptive and Robust Beamforming
−80
−60
−40
−20
0
20
40
60
80
−60
−50
−40
−30
−20
−10
0
LSMI, 2 SNAPSHOTS
ANGLE (DEGREES)
DIRECTIONAL PATTERN (DB)
FIGURE 12.10
Beampattern of the LSMI beamformer for the number of snapshots K = 2L = 2 that satisﬁes the LSMI
convergence rule (12.54).
Point mainbeam constraints: In this case, the matrix of constrained directions is given as
C = [a(θs,1), a(θs,2), . . . , a(θs,Q)],
(12.56)
where a(θs,q), q = 1, . . . , Q are all taken in the neighborhood of the steering vector in the presumed
direction a(θs) and include the steering vector in the presumed direction as well. Then the vector of
constraints f is
f = [1, 1, . . . , 1]T .
(12.57)
The constraint in the optimization problem (12.55) consists of multiple point constraints similar to the
distortionless response constraints, but covers not only the presumed direction, but also the directions
in the neighborhood of the presumed direction. The work principle of the point mainlobe constraint is
demonstrated in Figure 12.13.
The disadvantage of using multiple distortionless response constraints is that additional degrees of
freedom are used by the beamformer in order to satisfy these constraints. Since for an antenna array of
M sensors, the number of degrees of freedom is M, the use of each additional degree of freedom for
satisfying additional distortionless response constraints limits the remaining degrees of freedom that
may be needed for suppressing interference signals.

3.12.4 Robust Adaptive Beamforming
525
0
50
100
150
200
250
300
350
400
450
−4
−2
0
2
4
6
8
10
12
CONVERGENCE OF LSMI/SMI
OPTIMAL SINR
SINR (DB)
SNAPSHOT NUMBER
LSMI/SMI WITH SIGNAL FREE CM
LSMI/SMI WHEN SIGNAL IS PRESENT
FIGURE 12.11
SINR versus the number of training snapshots for the SMI beamformer in the SOI-free scenario and in the
case when SOI is present in the training data.
Derivative mainbeam constraints: In this case, the matrix of constrained directions is given as
C =

a(θs), ∂a(θ)
∂θ

θ=θs
, . . . , ∂M−1a(θ)
∂θ M−1

θ=θs

(12.58)
and the vector of constraints is
f = [1, 0, . . . , 0]T .
(12.59)
Here
∂ka(θ)
∂θk

θ=θs
= Dkas,
(12.60)
where D is the matrix that depends on the SOI presumed DOA θs and the array geometry.
The solution of the optimization problem can be found in a similar way as the solution of the MVDR
beamformer, and it can be written as
wopt = R−1C(CHR−1C)−1f.
(12.61)
Since the data covariance matrix is unknown in practice, its sample estimate has to be used. Then the
SMI version of the beamformer (12.61) is
wSMI = R−1C(CHR−1C)−1f.
(12.62)

526
CHAPTER 12 Adaptive and Robust Beamforming
angle
signal  direction
assumed
real
interference
FIGURE 12.12
Look direction mismatch (pointing error) problem. The SOI arrives from a different direction than the pre-
sumed direction.
angle
FIGURE 12.13
Pointing error. Effect of point mainlobe constraints.

3.12.4 Robust Adaptive Beamforming
527
3.12.4.4 Generalized sidelobe canceler
The solution (12.61) can be decomposed into two components, one in the constrained subspace and the
other in the orthogonal subspace to the constrained subspace, as follows [27]:
wopt =

PC + P⊥
C




I
wopt
= C(CHC)−1 CHR−1C

CHR−1C
−1



I
f
+P⊥
CR−1C

CHR−1C
−1f,
(12.63)
where PC ≜C(CHC)−1CH and P⊥
C ≜I −C(CHC)−1CH are the projection matrix on the constrained
subspace and the orthogonal projection matrix on the constrained subspace, respectively.
The decomposition (12.63) can be written in a general form as
wGSC = wq −Bwa,
(12.64)
where
wq ≜C(CHC)−1f
(12.65)
is the so-called quiescent beamforming vector, which is independent of the input/output data of the
antenna array. The matrix B in (12.64) must be selected so that
BHC = 0
(12.66)
and it is called the blocking matrix. The vector wa is the new adaptive weight vector, while wq is non-
adaptive. The beamformer (12.64) is called the generalized sidelobe canceler (GSC). Its block scheme
is shown in Figure 12.14 and it consists of the non-adaptive branch and adaptive branch, in which the
adaptive beamforming vector is applied to the data vector z(k) after the blocking matrix B that blocks
the constrained directions.
The choice of the blocking matrix B in the GSC (12.64) is not unique. In (12.63), for example, the
blocking matrix B ≜P⊥
C is used. However, in this case, B is not a full-rank matrix. Therefore, it is
+
+
-
x
Wq
Wa
B
z
H
H
H
FIGURE 12.14
The block scheme of generalized sidelobe canceler.

528
CHAPTER 12 Adaptive and Robust Beamforming
more common to select an M × (M −N) full-rank matrix B. Then, the vectors z(k) ≜BHx(k) and
wa both have shorter length of (M −N) × 1 relative to the M × 1 vectors x(k) and wq. Since the non-
adaptive component wq is data independent and has to be pre-computed only once, the GSC reduces the
computational complexity by requiring to compute only the adaptive component wa of a shorter length.
Moreover, the blocking matrix can be interpreted as a spatial ﬁlter and designed accordingly, which is a
very fruitful approach especially in non-ideal situations when the assumptions of the plane waves and
identical channels from air into digital processor do not hold [48].
In order to ﬁnd the adaptive component wa, it can be observed that since the constrained directions
are blocked by the matrix B, it is guaranteed that the SOI cannot be suppressed and, therefore, the
weight vector wa can adapt freely to suppress interferences by minimizing the output GSC power
PGSC = wH
optRwopt = (wq −Bwa)HR(wq −Bwa)
= wH
q Rwq −wH
q RBwa −wH
a BHRwq + wH
a BHRBwa.
(12.67)
The unconstrained minimization of (12.67) results in the following expression for the adaptive
component of the GSC:
wa,opt =

BHRB
−1BHRwq.
(12.68)
Noting that
y(k) ≜wH
q x(k),
z(k) ≜BHx(k)
(12.69)
the following covariance matrix of the data vector z(k) and the correlation vector between z(k) and y(k)
can be introduced:
Rz ≜E[z(k)zH(k)] = BHE[x(k)xH(k)]B
= BHRB,
(12.70)
ryz ≜E[z(k)y∗(k)] = BHE[x(k)xH(k)]wq
= BHRwq.
(12.71)
Using the notations (12.70) and (12.71), the expression (12.68) can be ﬁnally written as
wa,opt = R−1
z ryz
(12.72)
which is again the Wiener-Hopf equation for ﬁnding optimal wa of a shorter length than w.
The remaining question is how to choice the blocking matrix B, if it is different from the projection
matrix P⊥
C. The blocking matrix B must satisfy the condition (12.66). In addition, it is desired that the
dimension of the data vector at the output of B, i.e., the dimension of the vector z(k), be smaller than
the dimension of the data vector x(k). Thus, the matrix B should be composed by linearly independent
vectors bi so that B = [b1, . . . , bM−N] and the condition (12.66) becomes
bi ⊥ck,
i = 1, . . . , M −N;
k = 1, . . . , N,
(12.73)
where ck is the kth column of the matrix C.

3.12.4 Robust Adaptive Beamforming
529
FIGURE 12.15
The GSC in the case of normal direction and a single distortionless constraint for a particular choice of
blocking matrix.
There are many possible choices of B. For example, for the GSC shown in Figure 12.15, the matrix
C becomes a vector
C = [1, 1, . . . , 1]T ,
(12.74)
while the blocking matrix B is of the form
BH =
⎡
⎢⎢⎢⎣
1 −1
0
· · · 0
0
0
1
−1 · · · 0
0
...
...
...
...
...
...
0
0
0
· · · 1 −1
⎤
⎥⎥⎥⎦.
(12.75)
The corresponding vectors x(k) and z(k) are
x(k) = [x1(k), x2(k), . . . , xM(k)]T ,
(12.76)
z(k) = [x1(k) −x2(k), x2(k) −x3(k), . . . , xM−1(k) −xM(k)]T
(12.77)
and the vector z(k) has a shorter length then the vector x(k) by one element.
3.12.4.5 Correlated (coherent) SOI and interferences: spatial smoothing
Correlation between the SOI and interferences can occur, for example, because of signal multipath
propagation (this effect is shown in Figure 12.16) or because of “smart” jammers [49]. The correlation
between the SOI and interferences leads to a strong signal cancellation effect. It is because the optimal
beamforming vector is obtained by minimizing the array output power subject to the SOI distortionless

530
CHAPTER 12 Adaptive and Robust Beamforming
direct path
("signal")
secondary path
("interference")
source
multichannel
receiver
FIGURE 12.16
Correlated (coherent) signal and interferences occurring because of multipath propagation.
response constraint. If an interference is correlated (coherent) with the SOI, the minimum will be
achieved if the array gain toward the interference is such that the interfering source exactly cancels the
SOI. The distortionless response constraint is of no help in such a situation, since the array output does
not have already the SOI component. As a result, robust techniques which would speciﬁcally address
the situation of such correlation have been developed [49,50].
The following example visualizes the destructive effect of coherence (when the SOI and interference
are correlated with the correlation coefﬁcient 1). A ULA with M = 10 omni-directional sensors spaced
half-wavelength apart from each other is assumed. The DOA of a single SOI is θs = 0◦and SNR = 0 dB,
while the DOA of a single interference is θi = 30◦and INR = 20 dB. Figure 12.17 depicts the
beampattern of the SMI adaptive beamformer for two cases of no correlation between the SOI and
interference and full coherence between the SOI and interference. It can be seen that in the incoherent
case, the directional pattern of the SMI beamformer has perfect mainlobe, low sidelobes and a deep null
in the direction of the interference. However, in the coherent case, the directional pattern is completely
destroyed.
The main idea of adaptive beamforming techniques robust against the SOI and interferences correla-
tion is a decorrelation of the SOI and interferences by the means of electronic subaperture motion. Such
technique is called spatial smoothing and it is demonstrated in Figure 12.18. On the left, the antenna
array partitioned into subarrays is shown, while on the right, the blocks of the data covariance matrix
that correspond to different subarrays are singled out.
Recall that the snapshot model is
x(k) = s(k)a(θs) + xi(k) + xn(k)
=
As(k)
  
signal + interference
+ xn(k),
(12.78)
where s(k) is the vector of the waveforms of the SOI and the interferences.
According to Figure 12.18, the data vector in the pth subarray is
˜xp(k) = ADp−1s(k) + ˜xn,p(k),
(12.79)

3.12.4 Robust Adaptive Beamforming
531
−80
−60
−40
−20
0
20
40
60
80
−40
−35
−30
−25
−20
−15
−10
−5
0
5
COHERENT CASE
INCOHERENT CASE
ANGLE (DEGREES)
DIRECTIONAL PATTERN (DB)
FIGURE 12.17
Directional patterns of SMI beamformer for incoherent and coherent cases.
subarray 1
subarray 2
subarray 3
spatial smoothing
FIGURE 12.18
Decorrelation of the desired signal and interference by the means of electronic subaperture motion. The
array consists of 6 sensors which form 3 subarrays of 4 sensors (on the left). A block of the data covariance
matrix corresponds to each subarray (on the right). There are 3 covariance matrices for 3 subarrays.

532
CHAPTER 12 Adaptive and Robust Beamforming
where A has a reduced dimension relative to A and for the ULA conﬁguration
D ≜diag
"
e j ω
c d sin θs, e j ω
c d sin θi2 , . . . , e j ω
c d sin θiL
#
(12.80)
is a diagonal matrix, where θs, θi2, . . . , θiL are the DOA’s of the SOI and L interferences and d is the
distance between any two adjacent antenna elements in ULA.
Let the number of subarrays be
P = M −J + 1,
(12.81)
where J is the subarray dimension, i.e., the number of antenna elements in one subarray. Then the J × J
spatially smoothed covariance matrix can be determined as
R ≜1
P
P

p=1
Rp,
(12.82)
where
Rp ≜E{˜xp(k)˜xH
p (k)}
(12.83)
is the covariance matrix for the pth subarray.
Substituting (12.79) in (12.83) and then substituting the result in (12.82), we obtain that
R ≜1
P
P

p=1
Rp = 1
P
P

p=1
E

˜xp(k)˜xH
p (k)

= 1
P
P

p=1
ADp−1 E[s(k)sH(k)]



S
(D∗)p−1AH + σ 2
n I
= A
⎡
⎣1
P
P

p=1
Dp−1S(D∗)p−1
⎤
⎦AH + σ 2
n I
= ASAH + σ 2
n I,
(12.84)
where the new notation
S ≜1
P
P

p=1
Dp−1S(D∗)p−1
(12.85)
is introduced.
Coherence between the SOI and interferences leads to a singular source covariance matrix S. It is
straightforward to see from (12.85) that even in the case of singular S, the matrix ˜S becomes nonsingular
if the number of subarrays is greater then the number of sources, that is,
P > L + 1.
(12.86)

3.12.4 Robust Adaptive Beamforming
533
The decorrelation factor between sources i and l due to spatial smoothing can also be found and it is
expressed as [51]
|gil| =

sin{P(ωd/2c)( sin θi −sin θl)}
P sin{(ωd/2c)( sin θi −sin θl)}
 .
(12.87)
Then the (i,l)th elements of the matrices S and ˜S are given, respectively, as
[S]i,l = σiσlρi,l,
[S]i,l = σiσlρi,lgi,l,
(12.88)
whereσ 2
i andσ 2
l arethevariancesofithandlthsources,respectively,andρi,l isthecorrelationcoefﬁcient
between the ith and lth sources.
3.12.4.6 Forward-backward averaging and spatial smoothing
The spatial smoothing source decorrelation method, however, severely reduces the antenna array length
because the number of subarrays must be larger than the number of correlated sources according to
(12.81). Moreover, the spatial smoothing method does not exploit the structure of ULA or, in general, any
array with centro-symmetric geometry, in a full measure. The antenna array length can be enlarged by
the means of the so-called forward-backward (FB) spatial smoothing [52]. It is based on the observation
that for any array with centro-symmetric geometry, we have
Ja(θ) =
⎡
⎢⎢⎢⎣
0 · · ·
0
0 1
0 · · ·
0
1 0
...
...
...
...
...
1
0
· · · 0 0
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
1
e j ω
c d sin θ
...
e j ω
c (N−1)d sin θ
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
e j ω
c (N−1)d sin θ
...
e j ω
c d sin θ
1
⎤
⎥⎥⎥⎦= e j ω
c (N−1)d sin θ,
(12.89)
where J is the exchange matrix.
In application to the covariance matrix for uncorrelated sources, the observation (12.89) leads to the
following interesting result:
JR∗J = J
L+1

l=1
σ 2
l a(θl)aH(θl)
∗
J + σ 2
n J2

I
=
L+1

l=1
σ 2
l a∗(θl)aT (θl)
∗
+ σ 2
n I
=
L+1

l=1
σ 2
l a(θl)aH(θl) + σ 2
n I = R
(12.90)
that is, the covariance matrix R is the so-called centro-Hermitian matrix, satisfying R = JR∗J.
Using (12.90), the idea of the FB averaging is to decorrelate the coherent/correlated sources by
the means of enforcing the centro-Hermitian property, i.e., by computing the following FB covariance
matrix:
RFB ≜1
2

R + JR∗J

.
(12.91)

534
CHAPTER 12 Adaptive and Robust Beamforming
Combining the FB averaging with spatial smoothing, it is possible to double the number of subarrays
while keeping the subarray length the same as in the conventional spatial smoothing. Then the covariance
matrix for the FB spatial smoothing is deﬁned as
RFB ≜1
2P
P

p=1

Rp + JR∗
pJ

.
(12.92)
As a result, the same decorrelation factor can be archived by the FB spatial smoothing with the use of
subarrays of a bigger size as the one achieved by the conventional spatial smoothing with subarrays of
a smaller size.
The FB spatial smoothing method can be further generalized by introducing the weights cp
(p = 1, · · · , P) as follows
RwFB ≜1
2P
P

p=1
cp

Rp + JR∗
pJ

(12.93)
and optimizing these weights to minimize the source decorrelation factor further.
One more simple source decorrelation method, named redundancy averaging [53], is based on the
fact that the true data covariance matrix in a ULA must be a Toeplitz matrix. The sample estimate of
the data covarince matrix is in general not a Toeplitz matrix. However, the Toeplitz structure can be
enforced, for example, by averaging the diagonals of the sample covariance matrix as it is shown in
Figure 12.19. In addition to enforcing the Toeplitz structure, such redundancy averaging also leads to
source decorrelation.
FIGURE 12.19
Redundancy averaging source decorrelation method. All diagonals are averaged and each element in the
same diagonal takes the corresponding average value. It also leads to source decorrelation.

3.12.4 Robust Adaptive Beamforming
535
FIGURE 12.20
Example of rapidly moving interference.
3.12.4.7 Rapidly moving interferences
If the rate/vilosity of interference motion is faster than the rate of adaptation of the adaptive array, the
antenna array may be unable to follow such rapid changes of the interference position. The situation of
fast moving interference is, however, common in a large number of applications [19]. An example of
such situation is shown in Figure 12.20. The nulls of the beampattern are very narrow and even relatively
slow interference motion may lead to the situation when the interference leaks to the output of adaptive
beamformer through a sidelobe that may signiﬁcantly reduce the output SINR of adaptive beamformer.
The situation of rapidly moving interferences is typically addressed in terms of broadening the
adaptive pattern nulls towards the interfering sources. The main difﬁculty here is that the DOAs of
interferingsourcesareunknown.However,thenullwidtheventowardsinterferingsourceswithunknown
DOAs can be increased by replacing the sample covariance matrix with the modiﬁed covariance matrix
of the form [19,54]
Rtap = R ⊙T,
(12.94)
where ⊙stands for element-wise Hadamard product of matrices and the matrix T is a positive semi-
deﬁnite matrix that is called a taper matrix. The choice of tapper is not unique. In the most popular

536
CHAPTER 12 Adaptive and Robust Beamforming
tapper proposed in [54], the (i,l)th element of the taper matrix T is given by
[T]i,l = sin (|i −l|)
|i −l|
,
(12.95)
where  deﬁnes the required null width.
Broadening the adaptive pattern nulls can also be archived by the means of enforcing the so-called
data-dependent derivative constraints [55]. The resulting covariance matrix takes the form
Rddc = R + ξDRD,
(12.96)
where D is the known diagonal matrix of sensor coordinates and the parameter ξ deﬁnes the tradeoff
between null depth and width. It has been shown that the null broadening method based on (12.96) can
be also interpreted in terms of the covariance tapering method of (12.94) (see [55]).
3.12.4.8 Uniﬁed principle to MVDR robust adaptive beamforming design
As we have seen earlier, the SMI beamformer is not robust to an imperfect knowledge of the SOI
steering vector. Different robust adaptive beamforming techniques which use different speciﬁc notions
of robustness such as robustness against small sample size, pointing error, coherence between the SOI
and interferences, and rapid interference motion have been revised. Each of these notions of robustness is
very speciﬁc. For example, the point or derivative mainbeam constraint-based beamforming technique is
very useful for overcoming pointing error problem, but it does not help in the general case of mismatched
SOI wavefront and ﬁnite sample size when the SOI is present in the antenna array measurements.
The general meaning of robustness for any robust adaptive beamforming technique can be, how-
ever, deﬁned as the ability of such technique to compute the beamforming vector so that the SINR
is maximized despite possibly imperfect and incomplete knowledge of required prior information.
More speciﬁcally, the aforementioned signal cancellation effect for the SMI beamformer occurs in
the situation when the SOI steering vector is misinterpreted with any of the interference steering
vectors of their linear combinations. Thus, if with incomplete and/or imperfect prior information, a
robust adaptive beamforming technique is able to estimate the SOI steering vector so that the esti-
mate does not converge to any of the interferences and their linear combinations, such technique is
called robust. Using this notion of robustness, the uniﬁed principle to robust adaptive beamforming
design based on MVDR beamformer can be formulated as follows. Use the standard SMI beamformer
(12.36) in tandem with SOI steering vector estimation performed based on some possibly incom-
plete and inaccurate prior information. The difference between different MVDR robust adaptive beam-
forming techniques can be then shown to boil down to the differences in the assumed prior informa-
tion, the speciﬁc notions of robustness, and the corresponding steering vector estimation techniques
used.
Hereafter, the imperfectly known presumed SOI steering vector is denoted as p, while a stands
for the actual SOI steering vector that is different from p, i.e., a ̸= p. The estimate of the actual SOI
steering vector is denoted as ˆa. In the techniques that follow, the estimate ˆa is found by using different
prior information and based on different principles. Other than that, all the techniques are based on the
aforementioned uniﬁed principle.

3.12.4 Robust Adaptive Beamforming
537
Many modern robust adaptive beamforming techniques are based on convex optimization theory
[16,56,57]. Most of such robust beamformers cannot be expressed in closed-form, i.e., cannot be written
in terms of the covariance matrix inversion or eigenvalue decomposition. However, the complexity of
solving optimization problems that correspond to such beamforming techniques is comparable to the
complexity of matrix inversion. Thus, there is no signiﬁcant difference in terms of computational
complexity between the so-called closed-form solutions and numerical solutions of convex problems.
3.12.4.9 Eigenspace-based beamformer
Using the a priori knowledge of the presumed SOI steering vector p, the eigenspace-based beamformer
computes and uses the projection of p onto the sample signal-plus-interference subspace as a corrected
estimate of the actual SOI steering vector. The eigendecomposition of (12.5) yields
R = EEH + GGH,
(12.97)
where the M × (L + 1) matrix E and M × (M −L −1) matrix G contain the signal-plus-interference
subspace eigenvectors of R and the noise subspace eigenvectors, respectively, while the (L + 1) ×
(L + 1) matrix  and (M −L −1) × (M −L −1) matrix  contain the eigenvalues corresponding to
E and G, respectively, and as before L stands for the number of interfering signals.
The estimate of the actual SOI steering vector is found as
ˆa = EEHp,
(12.98)
where EEH is the projection matrix to the desired signal-plus-interference subspace. Then the
eigenspace-based beamformer is obtained by substituting the so-obtained estimate of the steering vector
to the SMI beamformer (12.36), and it can be expressed as [58]
weig = R−1ˆa = R−1EEHp = E−1EHp,
(12.99)
where the fact that
R−1EEH = (EEH + GGH)−1EEH = E−1EH
(12.100)
has been used for obtaining the last equality and GHE = 0 because G and E are orthogonal (see the
decomposition (12.97)).
Summarizing, the essence of the eigenspace-based beamforming technique is to project the presumed
SOI steering vector onto the measured signal-plus-interference subspace prior to processing in order to
reduce the signal wavefront mismatch. Then, the estimate of the actual SOI steering vector is plugged to
the standard SMI beamformer. The interference rejection part remains unchanged for this beamformer
as compared to the SMI beamformer. The prior information used is the presumed steering vector p
and the number of interfering sources L. The notion of robustness is the projection of the presumed
steering vector to the signal-plus-interference subspace. It is, however, well known that at low SNR, the
eigenspace-based beamformer suffers from a high probability of subspace swap and incorrect estimation
of the signal-plus-interference subspace dimension [59].

538
CHAPTER 12 Adaptive and Robust Beamforming
3.12.4.10 Worst-case-based robust adaptive beamforming
This approach is based on explicitly modeling of the actual SOI steering vector a as a sum of the
presumed steering vector and a deterministic norm bounded mismatch vector δ, that is,
a ≜p + δ,
∥δ∥≤ε,
(12.101)
where ε is some a priori known bound. Thus, the worst-case-based robust adaptive beamformer uses the
prior information about the presumed steering vector and the information that the mismatch vector is
norm bounded [60]. An ellipsoidal uncertainty region can also be considered instead of the mentioned
in (12.101) spherical uncertainty [61]. However, a more sophisticated prior information has to be
available in the case of ellipsoidal uncertainty. Assuming spherical uncertainty for δ, i.e., introducing
the uncertainty set
A(δ) ≜{a = p + δ | ∥δ∥≤ε}
(12.102)
the worst-case-based robust adaptive beamforming aims at solving the following optimization
problem [60]
min
w wHRw subject to
min
ˆa∈A(δ) |wH ˆa| ≥1.
(12.103)
The optimization problem (12.103) is equivalent to the following second-order cone (SOC) pro-
gramming problem [60]
min
w wHRw subject to wHp ≥ε∥w∥+ 1,
(12.104)
which can be solved efﬁciently using standard numerical optimization methods with complexity com-
parable to the complexity of matrix inversion.
The worst-case-based robust adaptive beamforming technique (12.103) can be equivalently inter-
preted as the standard SMI beamformer used in tandem with the SOI steering vector estimate obtained
by solving the following covariance ﬁtting problem [62]
min
σ 2,ˆa σ 2
subject to R −σ 2ˆaˆaH ≥0 for any ˆa satisfying ∥δ∥≤ε.
(12.105)
Summarizing, the prior information used in the worst-case-based robust adaptive beamforming tech-
niques is the presumed steering vector and the value ε, which may be difﬁcult to obtain in practice.
The notion of robustness is the uncertainty region for the presumed steering vector. The robustness
to the rapidly moving interference sources can also be added to the worst-case-based robust adaptive
beamforming [63].
3.12.4.11 Relationship between the worst-case-based and the LSMI
adaptive beamformers
Notethattheconstraintintheoptimizationproblem(12.103)mustbesatisﬁedwithequalityatoptimality.
Indeed, if the constraint is not satisﬁed with equality, then the minimum of the objective function in
(12.103) is achieved when κ ≜minˆa∈A(δ) |wH ˆa| > 1. However, by replacing w with w/√κ, the
objective function of (12.103) can be decreased by the factor of κ > 1, whereas the constraint in
(12.103) will be still satisﬁed. This contradicts the original statement that the objective function is

3.12.4 Robust Adaptive Beamforming
539
minimized when κ > 1. Therefore, the minimum of the objective function is achieved at κ = 1, and
the inequality constraint in (12.103) is equivalent to the equality constraint. This also means that wH ˆa
is real-valued and positive. Using these facts, the problem (12.103) can be rewritten as
min
w wHRw subject to (wHp −1)2 = ε2wHw.
(12.106)
The solution to (12.106) can be found by using the method Lagrange multipliers, i.e., by optimizing
the following Lagrangian:
L(w, λ) = wHRw + λ(ε2wHw −(wHp −1)2),
(12.107)
where λ is a Lagrange multiplier. Taking the gradient of (12.107) and equating it to zero, it can be
found that
w = −λ(R + λε2I −λppH)−1p.
(12.108)
Furthermore, applying the matrix inversion lemma to (12.108), the beamforming vector can be
expressed as [60]
w =
λ
λpH(R + λε2I)−1p −1(R + λε2I)−1p,
(12.109)
which is the LSMI beamformer with adaptive diagonal loading factor. The expression (12.109) cannot
be used practically since the optimal value of λ has to be ﬁrst found. The numerical algorithms designed
in [61] are particularly based on ﬁnding λ numerically, while the general SOC programming is used in
[60]. The complexity of both type of methods is, however, the same and is comparable to the matrix
inversion as in SMI and LSMI beamformers.
3.12.4.12 Doubly constrained robust adaptive beamforming
The doubly constrained robust adaptive beamforming [64] is similar to the worst-case-based one
(12.103) (equivalently (12.105)), but it exposes also an additional constraint to the norm of the steering
vector estimate, that is, ∥ˆa∥2 = M. Then the corresponding optimization problem for ﬁnding ˆa is
min
σ 2,ˆa σ 2 subject to R −σ 2ˆaˆaH ≥0,
for any ˆa satisfying ∥δ∥≤ε, ∥ˆa∥2 = M.
(12.110)
This method uses the same prior information as the worst-case-based robust adaptive beamforming
method and obviously ﬁts under the aforementioned uniﬁed framework. Although the spherical uncer-
tainty region is considered in [64], it can be relatively straightforwardly extended to the ellipsoidal
uncertainty region [65]. Clearly, the notion of robustness for this method is the same as for the worst-
case-based one. Due to the constraint ∥ˆa∥2 = M, the doubly constrained robust adaptive beamforming
provides a better estimate of the SOI than the worst-case-based robust adaptive beamforming. It can be
important in the applications where such estimate is needed.

540
CHAPTER 12 Adaptive and Robust Beamforming
3.12.4.13 Probabilistically constrained robust adaptive beamforming
Another approach to robust adaptive beamforming is based on the assumption that the mismatch vector
δ is random. Then the problem has to be formulated in probabilistic terms in contrast to the deterministic
terms used in the worst-case-based design. Speciﬁcally, the probabilistically constrained robust adaptive
beamforming problem is formulated as [66]
min
w wHRw subject to Pr{|wHa| ≥1} ≥p0,
(12.111)
where Pr{·} denotes probability and p0 is preselected probability value. In this case, the prior information
is the presumed steering vector p as before, but since the steering vector mismatch is assumed to be
random, the other prior information is the distribution type and the distribution variance of δ as well as
the non-outage probability p0 for the distortionless response constraint. In two cases when δ is Gaussian
distributed and the distribution of δ is unknown and assumed to be the worst possible, it has been shown
that the problem (12.111) can be closely approximated by the following problem [66]:
min
w wHRw subject to
˜ε∥Q1/2
δ
w∥≤wHp −1,
(12.112)
where Qδ is the covariance matrix of the random mismatch vector δ and ˜ε = √−ln (1 −p0) if δ is
Gaussian distributed and ˜ε = 1/√1 −p0 if the distribution of δ is unknown. Thus, the latter problem
boils down mathematically to the same form as the worst-case-based robust adaptive beamforming
problem and can also be considered as a part of the earlier explained uniﬁed framework. However, the
prior information required for the probabilistically constrained robust adaptive beamforming may be
easier to obtain than that for the worst-case-based approach since it is typically easier to estimate the
statistics of the mismatch distribution reliably, while p0 has a clear physical meaning. The non-outage
probability p0 for the distortionless response constraint is the speciﬁc notion of robustness used in this
approach.
3.12.4.14 Sequential quadratic programming-based robust
adaptive beamforming
The title of this approach refers to the optimization technique used, but its essence is signiﬁcantly
different from the above approaches that are based on the same aforementioned uniﬁed principle to
robust MVDR beamforming design. According to this approach the estimate of the actual steering
vector a is found so that the beamformer output power is maximized while the convergence of the
estimate ˆa to any interference steering vector is prohibited [67]. The rationale behind maximization
of the beamformer output power is the following. In the steering vector mismatched case, the solution
(12.36) can be re-written as a function of unknown δ, that is, w(δ) = αR−1(p + δ). Using w(δ), the
beamformer output power can be also written as a function of the mismatch δ as
P(δ) =
1
(p + δ)HR−1(p + δ).
(12.113)
Thus, the estimate of δ or, equivalently, the estimate of a that maximizes (12.113) will be the best
estimate of the actual steering vector a under the constraints that the norm of ˆa equals
√
M and ˆa does

3.12.4 Robust Adaptive Beamforming
541
not converge to any of the interference steering vectors. The latter is guaranteed in this method by
requiring that
P⊥(p + ˆδ) = P⊥ˆa = 0,
(12.114)
where P⊥≜I −UUH, U ≜[u1, u2, . . . , uT ], ul,l = 1, . . . , T are the T dominant eigenvectors of the
matrix C ≜
	
 d(θ)dH(θ)dθ, d(θ) is the steering vector associated with direction θ and having the
structure deﬁned by the antenna geometry,  is the angular sector in which the SOI is located, ˆδ and ˆa
stand for the estimates of the steering vector mismatch and the actual SOI steering vector, respectively.
The optimization problem for ﬁnding the estimate ˆa can be written as [67]
min
ˆa
ˆaHR−1ˆa
subject to P⊥ˆa = 0,
∥ˆa∥2 = M,
(12.115)
ˆaHCˆa ≤pHCp,
where C ≜
	
˜ d(θ)dH(θ)dθ and the sector ˜ is the complement of the sector . The last constraint in
(12.115) limits the noise power collected in ˜.
Since the optimization problem (12.115) is non-convex and difﬁcult to solve, it is modiﬁed so
that the orthogonal component of δ (here δ is decomposed to colinear and orthogonal components) is
estimated iteratively as shown in Figure 12.21, while at each iteration the following quadratic (convex)
optimization problem is solved
min
ˆδ⊥
(p + ˆδ⊥)HR−1(p + ˆδ⊥)
subject to P⊥(p + ˆδ⊥) = 0,
∥p + ˆδ⊥∥2 ≤M,
(12.116)
pH ˆδ⊥= 0,
∥ˆa∥2 = M,
ˆaHCˆa ≤pHCp,
where ˆδ⊥is the component of ˆδ that is orthogonal to p and the orthogonality between ˆδ and p is
imposed by adding the constraint pH ˆδ⊥= 0. Because the quadratic programming problem (12.116)
has to be solved sequentially, the corresponding method is called the sequential quadratic programming
(SQP)-based robust adaptive beamforming.
It can be seen that the prior information used in this approach is the presumed steering vector and the
angular sector  in which the desired signal is located. Note that if the constraint (12.114) is replaced
by the constraint ∥δ∥≤ε, the convergence to an interference steering vector is also be avoided, but
the problem then becomes equivalent to the worst-case-based robust adaptive beamforming (see [64]).
This technique can be simpliﬁed for more structured uncertainties, for example, when it is known
that the array is partially calibrated [68]. However, the amount of required prior information about the
uncertainty then increases.
3.12.4.15 Eigenvalue beamforming using multi-rank MVDR beamformer
If the desired signal and interference steering vectors lie in known signal subspaces and the rank of the
signal correlation matrix is known, the eigenvalue beamforming using multi-rank MVDR beamformer

542
CHAPTER 12 Adaptive and Robust Beamforming
First iteration
Last iteration
e
a
p
a
p
√
⊥
δ
Μ
FIGURE 12.21
Convergence trajectory of the iterative robust adaptive beamforming algorithm.
can be efﬁcient [69]. The multi-rank beamformer matrix is computed as
W = R−1( HR−1)−1Q,
(12.117)
where Q is a data dependent left-orthogonal matrix, i.e., QHQ = I, and  is the matrix with the
columns that span the linear subspace in which the SOI lies. For example, for resolving a signal with
a rank-one covariance matrix and an unknown but ﬁxed DOA, the columns of Q should be selected as
the dominant eigenvectors of the mismatch covariance matrix, i.e.,
Rδ = ( HR−1)−1.
(12.118)
If it is assumed that the signal lies in a known subspace, but the DOA is unknown and unﬁxed (randomly
changes from snapshot to snapshot), it is the subdominant eigenvectors of the mismatch covariance
matrix that should be used as the columns of the matrix Q.
The prior information required for this beamforming technique is the linear subspace in which the
desired signal lies and the rank of the desired signal covariance matrix. The main disadvantages are that
a very speciﬁc modeling of the covariance matrix is used and the signal subspace has to be known.
3.12.4.16 Robust adaptive beamforming based on steering vector
estimation with as little as possible prior information
The essence of robustness can be practically viewed as an ability of adaptive beamformer to achieve
acceptably high output SINR despite imprecise and perhaps very limited prior information. This beam-
forming technique aims at fulﬁlling such most general notion of robustness. Assume that the SOI lies
in the known angular sector  = [θmin, θmax] that is distinguishable from general locations of the
interfering signals. The estimate ˆa can be forced not to converge to any vector with DOAs within the
complement of  including the interference steering vectors and their linear combinations by the means

3.12.4 Robust Adaptive Beamforming
543
of the following constraint [70,71]:
ˆaHCˆa ≤0,
(12.119)
where 0 is a uniquely selected value for a given angular sector , that is,
0 ≜max
θ∈ dH(θ)Cd(θ).
(12.120)
It is worth stressing that no restrictions/assumptions on the structure of the interferences are needed.
Moreover, the interferences do not need to have the same structure as the SOI.
In order to illustrate how the quadratic constraint (12.119) works, let us consider the following
example. Consider ULA of 10 omni-directional antenna elements spaced half wavelength apart from
each other. Let the range of the SOI angular locations be  = [0◦, 10◦]. Figure 12.22 depicts the values
of the quadratic term dH(θ)Cd(θ) for different angles. The rectangular bar in the ﬁgure marks the
directions within the angular sector . It can be observed from this ﬁgure that the term dH(θ)Cd(θ)
takes the smallest values within the angular sector  and increases outside of the sector. Therefore, if 0
is selected to be equal to the maximum value of the term dH(θ)Cd(θ) within the angular sector , the
constraint (12.119) guarantees that the estimate of the desired signal steering vector does not converge to
any of the interference steering vectors and their linear combinations. The equality dH(θ)Cd(θ) = 0
must occur at one of the edges of . However, the value of the quadratic term might be smaller than
0 at the other edge of . Therefore, a possibly larger sector a ≥ has to be deﬁned, at which the
equality d(θ)HCd(θ) = 0 holds at both edges.
Although for computing the matrix C, the presumed knowledge of the antenna array geometry is
used, an inaccurate information about the antenna array geometry is sufﬁcient. It further stresses on the
−80
−60
−40
−20
0
20
40
60
80
θ
dH(θ) C d(θ)
∼
FIGURE 12.22
Values of the term dH(θ)˜Cd(θ) in the constraint (12.119) for different angles.

544
CHAPTER 12 Adaptive and Robust Beamforming
robustness of such beamforming design to the imperfect prior information [71]. Taking into account the
normalization constraint and the constraint (12.119), the problem of estimating the SOI steering vector
based on the knowledge of the sector  can be formulated as the following optimization problem:
min
ˆa
ˆaHR−1ˆa
subject to ∥ˆa∥2 = M,
(12.121)
ˆaHCˆa ≤0.
Compared to the other MVDR robust adaptive beamforming methods, which require the knowledge of
the presumed steering vector and, thus, the knowledge of the presumed antenna array geometry and
propagation media and source characteristics, only imprecise knowledge of the antenna array geometry
and approximate knowledge of the angular sector  are needed for the robust adaptive beamformer
(12.121).
As cooperated to the SQP-based beamformer (12.116), where the constraint P⊥ˆa = 0 enforces the
estimated steering vector to be a linear combination of T dominant eigenvectors U ≜[u1, u2, . . . , uT ],
the steering vector in (12.121) is not restricted by such linear combination requirement, while the
convergence to any of the interference steering vectors and their linear combinations is avoided by the
means of the constraint (12.119). As a result, the beamformer (12.121) has more degrees of freedom
compared to the SQP-based beamformer. Thus, it is expected that it outperform the latter one. Finally,
due to the non-convex equality constraint, the problem (12.121) is non-convex and NP-hard in general.
The efﬁcient polynomial-time solution to this problem is developed in [71] based on the semi-deﬁnite
programming relaxation theory [57,72,73].
3.12.4.17 Comparison by simulation
To compare a number of aforementioned MVDR robust adaptive beamforming methods based on the
uniﬁed approach, the following example is considered. A ULA of 10 omni-directional sensors with
the inter-element spacing of half wavelength is used. Additive noise in antenna elements is modeled as
spatially and temporally independent complex Gaussian noise with zero mean and unit variance. Two
interfering sources are assumed to impinge on the antenna array from the directions 30◦and 50◦, while
the presumed direction towards the SOI is assumed to be 3◦. The INR equals 30 dB and the desired
signal is always present in the training data.
The robust adaptive beamforming (12.121) is compared with the eigenspace-based, the worst-case-
based, the SQP-based, and the LSMI robust adaptive beamforming techniques. For the beamformer
(12.121) and the SQP-based one, the angular sector of interest  is assumed to be  = [θp−5◦, θp+5◦],
where θp is the presumed DOA of the SOI. The difference between the presumed and actual positions of
each antenna element is modeled as a uniform random variable distributed in the interval [−0.05, 0.05]
measured in wavelength. In addition to the antenna element displacements, the signal steering vector
is distorted by wave propagation effects in an inhomogeneous medium. Independent-increment phase
distortions are accumulated by the components of the presumed steering vector. It is assumed that the
phase increments remain ﬁxed in each simulation run.
Figure 12.23 depict the output SINR performance of the aforementioned robust adaptive beamform-
ing techniques tested versus the SNR for ﬁxed training data size K = 30. As it can be observed from

3.12.4 Robust Adaptive Beamforming
545
−20
−15
−10
−5
0
5
10
15
20
−20
−15
−10
−5
0
5
10
15
20
25
30
SNR (DB)
OUTPUT SINR (DB)
OPTIMAL SINR
WORST−CASE−BASED BEAMFORMER
EIGENSPACE−BASED BEAMFORMER
BEAMFORMER (20.121)
SQP−BASED BEAMFORMER
SMI BEAMFORMER
FIGURE 12.23
Output SINR versus SNR for training data size of K = 30 and INR = 30 dB for the case of perturbations in
antenna array geometry.
the ﬁgures, the beamformer (12.121) has a better performance even if there is an error in the knowledge
of the antenna array geometry.
3.12.4.18 Robust adaptive beamforming for the general-rank signal model
Robust adaptive beamforming techniques for general-rank signal model address the situation when the
desired signal covariance matrix Rs is not known precisely as well as the sample estimate of the data
covariance matrix (12.5) is inaccurate because of small sample size.
In order to provide robustness against the norm-bounded mismatches ∥1∥
≤
ϵ and
∥2∥≤γ (where ϵ and γ are some preselected bounds) in the SOI and data sample covariance
matrices, respectively, the following worst-case-based robust adaptive beamformer has been derived
[74,75]
w = P{(R + γ I)−1(Rs −ϵI)}.
(12.122)
Although it is a simple closed-form solution, it is overly conservative due to the fact that the negatively
diagonally loaded signal covariance matrix Rs−ϵI can be indeﬁnite. A less conservative robust adaptive
beamforming problem formulation, which enforces the matrix Rs + 1 to be positive semi-deﬁnite has
been considered in [76]. Deﬁning Rs = QHQ, which is for example the Cholesky decomposition, the
corresponding robust adaptive beamforming problem for a norm bounded-mismatch ∥∥≤η (where

546
CHAPTER 12 Adaptive and Robust Beamforming
η is some value found based on the bound value ϵ) to the matrix Q is given as [76]
min
w
max
∥2∥≤γ wH(R + 2)w
subject to min
∥∥≤η wH(Q+)H(Q+)w≥1.
(12.123)
If the mismatch of the signal covariance matrix is small enough, the optimization problem (12.123) can
be equivalently recast as
min
w wH(R + γ I)w subject to ∥Qw∥−η∥w∥≥1.
(12.124)
Due to the non-convex (difference-of-convex functions (DC)) constraint, the problem (12.124) is non-
convex. Although the DC programming problems are believed to be NP-hard in general, the problem
(12.124) is shown to have very efﬁcient polynomial-time solution [77].
3.12.4.19 Wideband robust adaptive beamforming
In the wideband case (see Figure 12.8), the SOI components at different frequencies are typically not
perfectly phased-aligned by the presteering delays because of multiple practical imperfections. The
reasons for imperfections are accentually the same as in the narrowband case with an addition of more
error sources such as the presteering delay quantization effects. Therefore, there are errors that can be
modeled in terms of the phase error vector δ( f ) that is the function of the frequency f. Then the actual
components of the SOI arriving from DOA θs after the presteering delay ﬁlter are [78]
B( f )a( f , θs) = e jπ f ς1M + δ( f ),
∀f ∈[ fl, fu]
(12.125)
instead of (12.13) in the case of no mismatch. Here ς is a common time delay at each of the M sensors
and fl is the minimum frequency of the SOI.
Deﬁning the mismatch set that contains all possible phase error vectors at the frequency f as
Aε( f ) ≜{δ( f ) ∈CM|∥δ( f )∥≤ε( f )}, the wideband robust adaptive beamforming problem can
be written as
min
δ( f )∈Aε( f ) |H( f , θs)| ≥1 ∀f ∈[ fl, fu].
(12.126)
Using (12.15) and (12.125), the array response towards DOA θs can be written as [78]
H( f , θs) = e jπ f ςwT C0d( f ) + wT Q( f )δ( f ),
(12.127)
where Q( f ) ≜d( f ) ⊗IM is M P × M matrix.
Using the triangular and then Cauchy-Schwarz inequalities, the magnitude of the lower bound for
the array responde (12.127) can be found as
|H( f , θs)| = |e jπ f ςwT C0d( f ) + wT Q( f )δ( f )|
≥|wT C0d( f )| −|wT Q( f )δ( f )|
≥|wT C0d( f )| −ε( f )∥QT ( f )w∥.
(12.128)

3.12.4 Robust Adaptive Beamforming
547
Finally, using the lower bound (12.128) for the constraint |H( f , θs)| ≥1 in (12.126) and imposing a
linear phase constraint on each of the M FIR ﬁlters of the array processor Figure 12.8, the optimization
problem (12.126) can be reformulated as the following output power minimization problem:
min
w
wT Rw
subject to |wT C0d( f )| −ε( f )∥QT ( f )w∥≥1,
f ∈[ fl, fu],
wm,l = wm,P−l+1,
∀m ∈ZM
1 ,
l ∈ZPc−1
1
,
(12.129)
where R is the covariance matrix of the stacked snapshot vectors, Pc = (P + 1)/2, and Z j
i denotes
the ring of integers from i to j. The last constraint in the optimization problem (12.129) ensures the
linear phase at each of the M FIR ﬁlters and it provides additional robustness against presteering errors
[78]. The problem (12.129) is non-convex, but it can be reformulated to a convex problem that can be
solved efﬁciently [78]. The disadvantage is, however, that the constraint on the magnitude of the array
response is strengthened by using the triangular and Cauchy-Schwarz inequalities (see (12.128)). More
sophisticated wideband robust adaptive beamforming designs can be also found in [79,80].
3.12.4.20 Summary
The applicability of different robust adaptive beamforming techniques is mainly deﬁned by the corre-
sponding notions of robustness used for designing a particular method and by the required prior infor-
mation needed to run a method. A majority of the existing robust adaptive beamforming techniques such
as the above mentioned techniques as eigenspace-based, worst-case-based, doubly constrained, prob-
abilistically constrained techniques as well as the eigenvalue beamforming using multi-rank MVDR
beamformer and their various modiﬁcations require the knowledge of the presumed steering vector.
In turn, the availability of this knowledge implies that the source and propagation media characteris-
tics as well as antenna geometry are known with a certain accuracy. Each method also requires some
additional information. For example, the eigenspace-based beamformer needs to know the number of
interferences, which may be a challenging practical problem. The worst-case-based and the doubly
constrained beamforming techniques need to know the upper-bound to the norm of the steering vector
mismatch, which is fortunately irrelevant to speciﬁc causes of mismatch and which is practically easy
to guess or estimate in a particular application. It is important that the performance of these methods
is not very sensitive to the over- or under-estimation of upper-bound to the norm of the steering vector
mismatch that makes these approaches practically attractive and widely applicable. The probabilisti-
cally constrained robust adaptive beamforming enables to quantify the upper-bound to the norm of
the steering vector mismatch in terms of the variance of the steering vector estimation and the prac-
tically tolerable outage probability that the distortionless response constraint is satisﬁed. This may be
an advantage in a number of applications especially when the variance of the steering vector/channel
estimation is already the existing information that does not require any additional efforts to obtain.
However, the least restrictive in terms of the required prior information is the robust adaptive beam-
forming technique based on steering vector estimation with as little as possible prior information. It
does not need the information about the presumed steering vector, but only needs a very approximate
knowledge of the array geometry, which is easy to have even in such challenging applications as sonar.
Similarly, it does not need any nearly accurate estimates of the source characteristics, but rather needs

548
CHAPTER 12 Adaptive and Robust Beamforming
only the very approximate knowledge of a sector where the source of interest is located. In this respect,
the latter technique can be most appropriately called “robust.” Moreover, it outperforms other existing
technique in terms of the beamformer output SINR. However, the complexity of the latter technique
is equivalent to the complexity of solving SDP problem that may be higher than the complexity of
matrix inversion, i.e., the complexity of SMI and LSMI beamformers, and nearly the complexity of the
worst-case-based and other aforementioned beamforming techniques. Finally, the notion of robustness
used by the robust adaptive beamforming technique based on steering vector estimation with as little as
possible prior information is the most general that makes its applicability essentially unlimited (limited
only by the source model as the source is assumed to be narrowband). The extension of this technique
to the wideband case is the topic of future promising research.
The ﬁeld of robust adaptive beamforming is an actively developing research ﬁeld which is strongly
connected to the progress in optimization theory. While the notion of robustness used in [71] is the most
general as mentioned above, new methods have been actively developing within the other approaches to
robust adaptive beamforming design with more speciﬁc notions of robustness. As an example, within the
worst-case-based approach, it has been recently noticed in [81] that although the above described worst-
case-based beamforming designs can be formulated as 1D covariance ﬁtting problems (as explained in
this section), these beamformers lead to inherently non-optimum results in the presence of interferers.
To mitigate the detrimental effect of interferers, the 1D covariance ﬁtting approach is extended to
multi-dimensional (MD) covariance ﬁtting in [81].
The adaptive and robust beamforming problem is originated from array processing, but it has found
a number of very fruitful applications in other actively developing ﬁelds which successfully applied
the ideas and designs developed ﬁrst in array processing framework. To mention just a few of such
applications we refer the reader to such wireless communication problems as downlink beamforming
in cellular wireless networks [82], code-division multiple-access (CDMA) multiuser detection [83–
85], linear receiver design for multi-access space-time codded systems [86,87], multicast beamforming
[15,88], secondary multicast beamforming for spectrum sharing in cognitive radio systems [16], relay
network beamforming [89], etc. For more details on such applications see [90] and other sections of the
Encyclopedia.
Acknowledgments
The author of this chapter would like to acknowledge the input of Prof. Alex B. Gershman (formerly of Darmstadt
University of Technology, Germany). While still alive, Prof. Gershman has shared with the author some materials
on adaptive beamforming including a number of ﬁgures used in this chapter. Without these ﬁgures, the presentation
would be signiﬁcantly less illustrative.
Relevant Theory: Array Signal Processing
See this volume, Chapter 13, Broadband Beamforming and Optimisation
See this volume, Chapter 15, Subspace Methods and Exploitation of Special Array Structures
See this volume, Chapter 17, DOA Estimation of Nonstationary Signals
See this volume, Chapter 19, Array Processing in the Face of Nonidealities
See this volume, Chapter 20, Applications of Array Signal Processing

References
549
References
[1] B. Widrow, P.E. Mantey, J.L. Grifﬁths, B.B. Goode, Adaptive antenna systems, Proc. IEEE 55 (1967)
2143–2159.
[2] R.A. Monzingo, T.W. Miller, Introduction to Adaptive Arrays, Wiley, NY, 1980.
[3] H.L. Van Trees, Optimum Array Processing, Wiley, NY, 2002.
[4] M. Viberg, Introduction to array processing, Signal Processing Encyclopedia, 2013.
[5] S. Haykin, J. Litva, T. Shepherd (Eds.), Radar Array Processing, Springer-Verlag, 1992.
[6] A. Farina, Antenna-Based Signal Processing Techniques for Radar Systems, Artech Hause, Norwood, MA,
1992.
[7] R.J. Vaccaro (Ed.), The Past, Present, and the Future of Underwater Acoustic Signal Processing, IEEE Signal
Process. Mag. 15 (1998) 21–51.
[8] Y. Kameda, J. Ohga, Adaptive microphone-array system for noise reduction, IEEE Trans. Acoust. Speech
Signal Process. 34 (1986) 1391–1400.
[9] S.W. Ellingson, G.A. Hampson, A subspace-tracking approach to interference nulling for phased array-based
radio telescopes, IEEE Trans. Antennas Propag. 50 (2002) 25–30.
[10] A. Leshem, J. Christou, B.D. Jeffs, E. Kuruoglu, A.J. van der Veen (Eds.), Issue on Signal Processing for
Space Research and Astronomy, IEEE J. Sel. Top. Signal Process. 2 (5) (2008).
[11] K. Sekihara, Performance of an MEG adaptive beamformer source reconstruction technique in the presence
of adaptive low-rank interference, IEEE Trans. Biomed. Eng. 51 (2004) 90–99.
[12] K.-M. Chen, D. Misra, H. Wang, H.-R. Chuang, E. Postow, An X-band microwave life-detection system,
IEEE Trans. Biomed. Eng. 33 (1986) 697–701.
[13] T.S. Rapapport (Ed.), Smart Antennas: Adaptive Arrays, Algorithms, and Wireless Position Location, IEEE
Press, 1998.
[14] A.B. Gershaman, N.D. Sidiropoulos (Eds.), Space-Time Processing for MIMO Communications, John Wiley
and Sons, 2005.
[15] N.D. Sidiropoulos, T.N. Davidson, Z.-Q. Luo, Transmit beamforming for physical-layer multicasting, IEEE
Trans. Signal Process. 54 (2006) 2239–2251.
[16] K.T. Phan, S.A. Vorobyov, N.D. Sidiropoulos, C. Tellambura, Spectrum sharing in wireless networks via
QoS-aware secondary multicast beamforming, IEEE Trans. Signal Process. 57 (2009) 2323–2335.
[17] H. Cox, R.M. Zeskind, M.H. Owen, Robust adaptive beamforming, IEEE Trans. Acoust. Speech Signal
Process. 35 (1987) 1365–1376.
[18] D.D. Feldman, L.J. Grifﬁths, A projection approach to robust adaptive beamforming, IEEE Trans. Signal
Process. 42 (1994) 867–876.
[19] J.R. Guerci, Theory and application of covariance matrix tapers to robust adaptive beamforming, IEEE Trans.
Signal Process. 47 (2000) 977–985.
[20] O. Leodit, M. Wolf, Improved estimation of the covariance matrix of the stock returns with an application to
portfolio selection, J. Empirical Finance 10 (2003) 603–621.
[21] K.I. Pedersen, P.E. Mogensen, B.H. Fleury, A stochastic model of the temporal and azimuthal dispersion seen
at the base station in outdoor propagation environments, IEEE Trans. Veh. Technol. 49 (2000) 437–447.
[22] O. Besson, P. Stoica, Decoupled estimation of DOA and angular spread for a spatially distributed source,
IEEE Trans. Signal Process. 48 (2000) 1872–1882.
[23] H. Cox, Line array performance when the signal coherence is spatially dependent, J. Acoust. Soc. Am. 54
(1973) 1743–1746.

550
CHAPTER 12 Adaptive and Robust Beamforming
[24] A.B. Gershman, V.I. Turchin, V.A. Zverev, Experimental results of localization of moving underwater signal
by adaptive beamforming, IEEE Trans. Signal Process. 43 (1995) 2249–2257.
[25] A.B. Gershman, C.F. Mecklenbräuker, J.F. Boehme, Matrix ﬁtting approach to direction of arrival estimation
with imperfect spatial coherence of wavefronts, IEEE Trans. Signal Process. 45 (1997) 1894–1899.
[26] S.E. Nordholm, H.H. Dam, C.C. Lai, E.A. Lehmann, Broadband Beamforming and Optimization, Signal
Process. Encyclopedia, 2013.
[27] O.L. Frost, An algorithm for linearly constrained adaptive array processing, Proc. IEEE 60 (1972) 926–935.
[28] B. Widrow, S.D. Stearns, Adaptive Signal Processing, Prentice Hall, Englewood Cliffs, NJ, 1985.
[29] I.S. Reed, J.D. Mallett, L.E. Brennan, Rapid convergence rate in adaptive arrays, IEEE Trans. Aerosp. Electron.
Syst. 10 (1974) 853–863.
[30] E.K. Hung, R.M. Turner, A fast beamforming algorithm for large arrays, IEEE Trans. Aerosp. Electron. Syst.
19 (1983) 598–607.
[31] G.A. Fabrizio, A.B. Gershman, M.D. Turley, Robust adaptive beamforming for HF surface wave over-the-
horizon radar, IEEE Trans. Aerosp. Electron. Syst. 40 (2004) 510–625.
[32] P. Forster, G. Vezzosi, Application of spheroidal sequences to array processing, in: Proc. IEEE Int. Conf.
Acoust. Speech Signal Process., Dallas, TX, May 1987, pp. 2268–2271.
[33] D. Slepian, Prolate spheroidal wave functions, Fourier analysis, and uncertainty. V—the discrete case, Bell
Syst. Tech. J. (1978) 1371–1430.
[34] T.J. Cornwell, A novel principle for optimization of the instantaneous Fourier plane coverage of correlation
arrays, IEEE Trans. Antennas Propag. 36 (8) (1988) 1165–1167.
[35] Z. Wang, J. Li, P. Stoica, T. Nishida, M. Sheplak, Constantbeamwidth and constant-powerwidth wideband
robust Capon beamformers for acoustic imaging, J. Acoust. Soc. Am. 116 (3) (2004) 1621–1631.
[36] L.C. Godara, The effect of phase-shift errors on the performance of an antenna-array beamformer, IEEE J.
Ocean. Eng. 10 (1985) 278–284.
[37] J.W. Kim, C.K. Un, An adaptive array robust to beam pointing error, IEEE Trans. Signal Process. 40 (1992)
1582–1584.
[38] N.K. Jablon, Adaptive beamforming with the generalized sidelobe canceller in the presence of array imper-
fections, IEEE Trans. Antennas Propag. 34 (1986) 996–1012.
[39] A.B. Gershman, V.I. Turchin, V.A. Zverev, Experimental results of localization of moving underwater signal
by adaptive beamforming, IEEE Trans. Signal Process. 43 (1995) 2249–2257.
[40] Y.J. Hong, C.C. Yeh, D.R. Ucci, The effect of a ﬁnite-distance signal source on a far-ﬁeld steering Applebaum
array: two dimensional array case, IEEE Trans. Antennas Propag. 36 (1988) 468–475.
[41] J. Goldberg, H. Messer, Inherent limitations in the localization of a coherently scattered source, IEEE Trans.
Signal Process. 46 (1998) 3441–3444.
[42] O. Besson, P. Stoica, Decoupled estimation of DOA and angular spread for a spatially distributed source,
IEEE Trans. Signal Process. 48 (2000) 1872–1882.
[43] D. Astely, B. Ottersten, The effects of local scattering on direction of arrival estimation with MUSIC, IEEE
Trans. Signal Process. 47 (1999) 3220–3234.
[44] A.B. Gershman, Robust adaptive beamforming in sensor arrays, Int. J. Electron. Commun. 53 (1999) 305–314
(invited paper).
[45] Y.I. Abramovich, Controlled method for adaptive optimization of ﬁlters using the criterion of maximum SNR,
Radio Eng. Electron. Phys. 26 (1981) 87–95.
[46] B.D. Carlson, Covariance matrix estimation errors and diagonal loading in adaptive arrays, IEEE Trans.
Aerosp. Electron. Syst. 24 (7) (1988) 397–401.
[47] W.F. Gabriel (Ed.), Special issue on adaptive antennas, IEEE Trans. Antennas Propag. 24 (1976).
[48] I. Claesson, S. Nordholm, A spatial ﬁltering approach to robust adaptive beamforming, IEEE Trans. Antennas
Propag. 40 (1992) 1093–1096.

References
551
[49] T.J. Shan, T. Kailath, Adaptive beamforming for coherent signals and interferece, IEEE Trans. Acoust. Speech
Signal Process. 33 (1985) 527–536.
[50] M.D. Zoltowski, On the performance of the MVDR beamformer in the presence of correlated interference,
IEEE Trans. Acoust. Speech Signal Process. 36 (1988) 945–947.
[51] A.B. Gershman, V.T. Ermolaev, Optimal subarray size for spatial smoothing, IEEE Signal Process. Lett. 2
(1995) 28–30.
[52] R.T. Williams, S. Prasad, A.K. Mahalanabis, L. Sibul, An improved spatial smoothing technique for bearing
estimation in a multipath enviroment, IEEE Trans. Acoust. Speech Signal Process. 36 (1988) 425–432.
[53] K. Takao, N. Kikuma, T. Yano, Toeplization of correlation matrix in multipath enviroment, in: Proc.
ICASSP’86, Tokyo, Japan, 1986, pp. 1873–1876.
[54] R.J. Mallioux, Covariance matrix augmentation to produce adaptive array pattern thrughs, Electron. Lett. 31
(1995) 771–772.
[55] A.B. Gershman, U. Nickel, J.F. Boehme, Adaptive beamforming algorithms with robustness against jammer
motion, IEEE Trans. Signal Process. 45 (1997) 1878–1885.
[56] Z.-Q. Luo, W. Yu, An introduction to convex optimization for communications and signal processing, IEEE
J. Sel. Areas Commun. 24 (2006) 20–34.
[57] Z.-Q.Luo,W.-K.Ma,A.M.-C.So,Y.Ye,S.Zhang,Semideﬁniterelaxationofquadraticoptimizationproblems,
IEEE Signal Process. Mag. 27 (3) (2010) 20–34.
[58] L. Chang, C.C. Yeh, Performance of DMI and eigenspace-based beamformers, IEEE Trans. Antennas Propag.
40 (1992) 1336–1347.
[59] J.K. Thomas, L.L. Scharf, D.W. Tufts, The probability of a subspace swap in the SVD, IEEE Trans. Signal
Process. 43 (1995) 730–736.
[60] S.A. Vorobyov, A.B. Gershman, Z.-Q. Luo, Robust adaptive beamforming using worst-case performance
optimization: a solution to the signal mismatch problem, IEEE Trans. Signal Process. 51 (2003) 313–324.
[61] R.G. Lorenz, S.P. Boyd, Robust minimum variance beamforming, IEEE Trans. Signal Process. 53 (2005)
1684–1696.
[62] J. Li, P. Stoica, Z. Wang, On robust Capon beamforming and diagonal loading, IEEE Trans. Signal Process.
51 (2003) 1702–1715.
[63] S.A. Vorobyov, A.B. Gershman, Z.-Q. Luo, N. Ma, Adaptive beamforming with joint robustness against
mismatched signal steering vector and interference nonstationarity, IEEE Signal Process. Lett. 11 (2004)
108–111.
[64] J. Li, P. Stoica, and Z. Wang, Doubly constrained robust capon beamformer, IEEE Trans. Signal Process. 52
(2004) 2407–2423.
[65] A. Beck, Y. Eldar, Doubly constrained robust Capon beamformer with ellipsoidal uncertainty set, IEEE Trans.
Signal Process. 55 (2007) 753–758.
[66] S.A. Vorobyov, H. Chen, A.B. Gershman, On the relationship between robust minimum variance beamformers
with probabilistic and worst-case distrortionless response constraints, IEEE Trans. Signal Process. 56 (2008)
5719–5724.
[67] A. Hassanien, S.A. Vorobyov, K.M. Wong, Robust adaptive beamforming using sequential programming: an
iterative solution to the mismatch problem, IEEE Signal Process. Lett. 15 (2008) 733–736.
[68] L. Lei, J.P. Lie, A.B. Gershman, C.M.S. See, Robust adaptive beamforming in partly calibrated sparse sensor
arrays, IEEE Trans. Signal Process. 58 (2010) 1661–1667.
[69] A. Pezeshki, B.D. Van Veen, L.L. Scharf, H. Cox, M. Lundberg, Eigenvalue beamforming using a multi-rank
MVDR beamformer and subspace selection, IEEE Trans. Signal Process. 56 (5) (2008) 1954–1967.
[70] A. Khabbazibasmenj, S.A. Vorobyov, A. Hassanien, Robust adaptive beamforming via estimating steering vec-
tor based on semideﬁnite relaxation, in: Proc. 44th Asilomar Conference on Signals, Systems and Computers,
Paciﬁc Grove, California, November 2010, pp. 1102–1106.

552
CHAPTER 12 Adaptive and Robust Beamforming
[71] A. Khabbazibasmenj, S.A. Vorobyov, A. Hassanien, Robust adaptive beamforming based on steering vector
estimation with as littele as possible prior information, IEEE Trans. Signal Process. 60 (2012) 2974–2987.
[72] Y.S. Nesterov, Semideﬁnite relaxation and nonconvex quadratic optimization, Optim. Methods Softw. 9 (1–3)
(1998) 141–160.
[73] S. Zhang, Quadratic maximization and semideﬁnite relaxation, Math. Program. A 87 (2000) 453–465.
[74] S. Shahbazpanahi, A.B. Gershman, Z.-Q. Luo, K.M. Wong, Robust adaptive beamforming for general-rank
signal models, IEEE Trans. Signal Process. 51 (2003) 2257–2269.
[75] A.B.Gershman,Z.-Q.Luo,S.Shahbazpanahi,Robustadaptivebeamformingbasedonworst-caseperformance
optimization, in: P. Stoica, J. Li (Eds.), Robust Adaptive Beamforming, Wiley, Hoboken, NJ, 2006, pp. 49–89.
[76] H.H. Chen, A.B. Gershman, Robust adaptive beamforming for general-rank signal models with positive semi-
deﬁnite constraints, in: Proc. IEEE Int. Conf. Acoustic, Speech, and Signal Processing, Las Vegas, USA, April
2008, pp. 2341–2344.
[77] A. Khabbazibasmenj, S.A. Vorobyov, A computationally efﬁcient robust adaptive beamforming for general-
rank signal model with positive semi-deﬁnite constraint, in: Proc. Inter. Workshop Comp. Advances in Multi-
Sensor Adaptive Processing, San Juan, Puerto Rico, December 2011, pp. 185–188.
[78] A. El-Keyi, T. Kirubarajan, A.B. Gershman, Adaptive wideband beamforming with robustness against
presteering errors, in: Proc. IEEE Workshop on Sensor Arrays and Multi-Channel Processing, Waltham,
MA, USA, July 2006, pp. 11–15.
[79] M. Ruebsamen, A. El-Keyi, A.B. Gershman, T. Kirubarajan, Robust broadband adaptive beamforming using
convex optimization, in: D.P. Palomar, Y.C. Eldar (Eds.), Convex Optimization in Signal Processing and
Communications, Cambridge University Press, 2010, pp. 315–339 (Chapter 9).
[80] M. Ruebsamen, Advanced Direction-of-Arrival Estimation and Beamforming Techniques for Multiple
Antenna Systems, Ph.D. Thesis, Darmstadt University of Technology, 2011 (Chapter 5).
[81] M. Ruebsamen, A.B. Gershman, Robust adaptive beamforming using multi0dimentions covariance ﬁtting,
IEEE Trans. Signal Process. 60 (2012) 740–753.
[82] M. Bengtsson, B. Ottersten, Optimal and suboptimal transmit beamforming, in: L. Godara (Ed.), Handbook
of Antennas in Wireless Communications, CRC Press: Boca Raton, FL, 2001 (Chapter 18).
[83] S. Verdu, Multiuser Detection, Cambridge University Press, Cambridge, UK, 1998.
[84] K. Zariﬁ, S. Shahbazpanahi, A.B. Gershman, Z.-Q. Luo, Robust blind multiuser detection based on the worst-
case performance optimization of the MMSE receiver, IEEE Trans. Signal Process. 53 (2005) 295–305.
[85] S.A. Vorobyov, Robust CDMA multiuser detectors: probability-constrained versus the worst-case based
design, IEEE Signal Process. Lett. 15 (2008) 273–276.
[86] S. Shahbazpanahi, M. Beheshti, A.B. Gershman, M. Gharavi-Alkhansari, K.M. Wong, Minimum variance
linear receivers for multi-access MIMO wireless systems with space-time block coding, IEEE Trans. Signal
Process. 52 (2004) 3306–3313.
[87] Y. Rong, S.A. Vorobyov, A.B. Gershman, Robust linear receivers for multi-access space-time block coded
MIMO systems: a probabilistically constrained approach, IEEE J. Sel. Areas Commun. 24 (2006) 1560–1570.
[88] E. Karipidis, N.D. Sidiropoulos, Z.-Q. Luo, Far-ﬁeld multicast beamforming for uniform linear antenna arrays,
IEEE Trans. Signal Process. 55 (2007) 4916–4927.
[89] V. Havary-Nassab, S. Shahbazpanahi, A. Grami, Z.-Q. Luo, Distributed beamforming for relay networks based
on second-order statistics of the channel state information, IEEE Trans. Signal Process. 56 (2008) 4306–4316.
[90] A.B. Gershman, N.D. Sidiropoulos, S. Shahbazpanahi, M. Bengtsson, B. Ottersten, Convex optimization-
based beamforming, IEEE Signal Process. Mag. 27(3) (2010) 62–75.

13
CHAPTER
Broadband Beamforming
and Optimization
Sven E. Nordholm*, Hai H. Dam†, Chiong C. Lai*, and Eric A. Lehmann‡
*Department of Electrical and Computer Engineering, Curtin University of Technology, Perth, WA, Australia
†Department of Mathematics and Statistics, Curtin University of Technology, Perth, WA, Australia
‡Mathematics, Informatics and Statistics, CSIRO, Wembley, WA, Australia
3.13.1 Introduction
Broadband beamformers [1–4] have been studied extensively over many years due to their wide applica-
tions in many areas such as radar, geology, sonar, biomedicine, radio astronomy, speech acquisition and
acoustics. Broadband beamformers, in contrast to single point sensor observations of a signal, employ
spatially distributed sensors to gain information on the spatial properties of the incoming waves. These
spatially separated sensor observations provide extra information about signal properties and noise
characteristics. Using an array of sensors allows the use of spatial domain information as well as time
domain information. Accordingly, multidimensional ﬁlters can be designed such that a signal of a cer-
tain beam-width and bandwidth can be extracted while signals that are not overlapping spatially or in
frequency can be suppressed. This multidimensional ﬁlter is usually referred to as a broadband beam-
former. The beamformer response processes the data such that the gain for each frequency becomes a
function of the direction of the incoming wave. This provides an increased gain for the spatially selected
incoming wave if it falls within the beam direction and a suppression if the wave falls outside the beam
direction. For narrowband beamformers this improvement is usually deﬁned as an array gain. It is also
common to provide an array pattern or beampattern which is a function of the angular direction of the
incoming wave. In most cases, one is mainly concerned with the array gain in the azimuthal plane and
thus the plot becomes two-dimensional. For broadband beamformers, the frequency dependent array
pattern is integrated over the bandwidth of interest and is presented as an integrated array pattern plot.
As an alternative, a frequency dependent array pattern can be presented in form of a three-dimensional
plot over angle and frequency. Thus the beam direction is a function of angle and frequency.
An effective utilization of spatial and temporal processing will lead to an efﬁcient processing solution.
There are multiple aspects that need to be considered in this design; the ﬁlter weight design, the spatial
distribution of the elements, the required spatial selectivity or beamwidth, and the frequency range and
propagation speed.
The actual solutions and requirements are application dependent. For microphone arrays, the beam-
former design is usually made over many octaves. In high end audio for high quality recordings, the
bandwidth can be 100 Hz to 20 kHz. But most applications have a more limited bandwidth such as
300–3400 Hz for audio, and 200–7000 Hz for high quality audio conferencing. In these types of speech
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00013-8
© 2014 Elsevier Ltd. All rights reserved.
553

554
CHAPTER 13 Broadband Beamforming and Optimization
applications one of the signiﬁcant degradations is room reverberation. To resolve those problems, the
array needs to grow in size and number of elements. Another problem with microphone arrays is that
the free ﬁeld assumption usually imposed is not valid. Often the microphone arrays should be operating
both in near ﬁeld and far ﬁeld. Far ﬁeld is considered when the distance from the center of the array to
the source rs is larger than 2L2
λ , where L is the largest aperture of the array and λ is the shortest wave
length of signals considered.
In other applications such as sonar, the necessary bandwidth is also a few octaves. Radar is usually
more narrowband and some modulation technique such as a chirped FM signal is used to create the
signal. As the demand for higher resolution increases, higher bandwidth is needed. In radio physics,
very broadband antennas are used in combination with narrow steerable beams. The common denom-
inator in the applications is the need for joint space and time-frequency analysis. This imposes design
requirements on broadband beamforming, such as the capability to have a similar beamwidth over a
wide range of frequencies given an array constellation and also low linear distortion of the signal of
interest (SOI). There are usually physical constraints on the array size and this constrains the beamwidth
for large wavelengths.
In general terms, the problem that the broadband beamformer shall solve can be deﬁned as follows.
Problem statement: The broadband beamformer shall operate upon the incoming waveforms in such
a way that Signal(s) of Interest (SOI), transmitted from point(s) in space, shall be extracted while all
other signals shall be suppressed.
This task is of course not possible in all practical scenarios, but it is this problem formulation that
will be discussed in this chapter. Some of the questions that will be discussed are: What methods are
available for extraction? What are the limitations for the processing? What a priori information is
available? How well do available techniques work in realistic environments?
Numerous techniques have been suggested for the design of broadband beamformers. The main chal-
lenge in the design is to be able to handle the wide frequency range required. The techniques that will be
discussed here are optimized designs, which are non-data-dependent weight design methods, and opti-
mum beamformers, where the weight design is dependent on statistical properties of the presented data.
An optimized beamformer is a design where the weights are designed according to a propagation
model, array geometry and a design speciﬁcation. Common ways to do the design is either to start from
a sampled domain where the sensor elements are considered as points in some given spatial pattern
(linear, circular, etc.) or from the wave ﬁeld domain where the receiver is a volume of a certain shape and
dimension [4,5]. For the sampled domain design, the problem can be considered as a multidimensional
ﬁlter design problem with an objective function and speciﬁcation. The design domain is over space and
frequency. In the case of a wave ﬁeld domain design, the problem is considered over a volume aperture
using aperture theory. For certain shapes, such as a sphere or a circle, the wave ﬁeld solution can naturally
be expressed in spherical harmonics which results in modal beamformer design. This allows separation
of spatial processing and temporal processing such that beam steering becomes simple. In theory, this
gives an efﬁcient means to design a beamformer of relatively low complexity and high quality, but
requires sensors of very high quality. There exist commercial microphone arrays available using this
wave domain technique for spherical arrays. Optimized beamformers are designed using criteria such as
Least Squares (LS), Weighted Least Squares (WLS), Total Least Squares (TLS), or Chebyshev (min-max
criteria). These criteria will be discussed in detail in a later section including some design examples.

3.13.1 Introduction
555
An optimum beamformer is a beamformer with weights designed based on data and the statistical
properties of those data. Since the receiving array only has access to the received signal and not the
original signal, it is blind to the actual SOI. To accommodate for this, the design criteria need to
include some form of constraint to maintain a desired direction and signal. The challenge when using
optimum beamformers is to maintain the signal integrity or to have low signal distortion and thus no
source cancelation. Signiﬁcant work has been done to ﬁnd ways to maintain signal integrity while still
providing capability to suppress noise and directional disturbance. The task for the optimum broadband
beamformerisusuallytwofold,namelytosuppressdirectionaldisturbingsignals,usuallycalledjammers
in the radar literature, and to compensate the convolutional effects stemming from the environment. The
most common criteria that are used for optimum broadband beamformers are Minimum Mean Square
Error (MMSE) or Signal to Noise Ratio (SNR) with distortion constraints.
Another aspect of broadband beamforming is the capability to track the SOI. Accordingly, the array
pattern is steered according to tracking information of a source. Thus the direction of the beamformer
needs to be steerable. This is usually the case when the overall system is implemented for real scenarios
in all of the above applications. In some cases, several SOI need to be tracked in parallel, which
requires multi-source tracking. Then the broadband beamformer needs to implement several beams
simultaneously.
The problem outlined above can also be posed as a communication problem. The SOI is ﬁltered
through an unknown channel which corresponds to the transmission environment and is also disturbed
by directional noise and non-directional noise. The classic techniques for source estimation are Min-
imum Mean Square Error (MMSE) estimation, or Wiener ﬁlter. However for most applications, these
techniques cannot be directly applied to this problem since the SOI is not available. The unavailability
of the SOI differentiates this problem from the classic communication problem where usually a known
pilot signal can be transmitted. However, for active radar and active sonar, partial knowledge of the
transmitted waveform is available.
It can also be necessary to consider channel modeling since the medium is usually not the ideal
free ﬁeld or anechoic situation. However, one needs to be aware that any model is just a model, and
it is imperative to verify broadband beamforming schemes based on real or at least measured data.
The better the design models one has, the fewer iterations are needed between the design phase and
implementation phase. Research work is pursued with the aim of being able to predict performance in
computer simulations without building the actual broadband beamformer. This would allow the use of
these advanced models into the actual design phase of the array.
For speech acquisition in particular, microphone arrays are commonly deployed to reduce the level
of localized and ambient noise signals as well as undesired reverberation from a desired direction via
beamforming. Then the capability to track speakers is necessary. The beamformer acts as a spatial ﬁlter
and utilizes the spatial domain as well as the time domain. An effective combination of spatial and
temporal processing will lead to a computationally efﬁcient solution.
The radar and sonar situations are different in the sense that often only the detection information
is needed and not the actual waveforms. At current time, there is also a research interest to obtain
contextual information. In such cases, there is a desire to extract more content out of the received signal
than a simple decision on the detection or presence of an object. This research is very active at current
time since providing a higher level of contextual analysis of the received signal allows to obtain more
information on the object. This is particularly the case for active sonar and active radar, which transmit

556
CHAPTER 13 Broadband Beamforming and Optimization
a known signal. This known signal is subjected to a channel and reﬂected on a surface. Based on the
received signal, one can form an optimum beamformer such that important information can be extracted.
The contextual information can be obtained either by training or modeling.
3.13.2 Environment and channel modeling
The operational scenario in applications such as radar, geology, sonar, biomedicine, speech acquisition
and acoustics, are that the sensor array receives signals in form of acoustic or electromagnetic waves
transmitted from sources that are spatially separated in space. Those waves are generated from either a
SOI, or undesired sources usually called jammers. In addition to that, independent noise is incumbent
on each element. Incoming waves are considered as noise when they do not have a distinct point of
origin or when they are too many to be modeled as individual sources. Whereas SOI and interference
signals are directional, noise is usually considered to be non-directive or diffuse.
The theory describing the relationship between a source and a sensor is usually called aperture theory
[4]. The theoretical background needed to understand those phenomena is vector calculus, linear system
theory and wave theory. Aperture theory describes the relationship between a transmitter and a receiver.
The study of air and underwater acoustics is dedicated to the mathematical modeling and measurement
of the propagation and scattering of sound waves in ﬂuid and elastic media. Since this is not the topic
of this chapter, only very limited background information is presented here so as to explain the relevant
concepts of beamforming design.
3.13.2.1 Aperture theory
In the acoustics literature [4], the word aperture is used to describe either a single electro-acoustic trans-
ducer or an array of transducers. An active transducer emits acoustic energy and is called a transmitter.
An electro-acoustic device converts electric signal to acoustic signal. In a similar manner, a passive
transducer is operating as a receiver. As such the electro-acoustic receiver converts acoustic signal to
electric signal. These transducers are usually called sensors in modern language. They are commonly
modeled as omni-directional point sources. The general theory that connects the electrical signal in a
transmitter to a receiver is called aperture theory. It combines linear systems theory and wave theory.
Only a few main results are discussed here and their details can be found in [4]. The aperture func-
tion AT (ω, rT ), which is the complex transducer function in frequency domain for each point on the
transducer body, determines the far-ﬁeld directivity function or beampattern and is given by
DT (ω, α) =
 ∞
−∞
AT (ω, rT ) exp (i2παT rT )drT ,
(13.1)
where α = [ f
c sin θ cos φ, f
c sin θ sin φ, f
c cos θ] is the unit vector in directions θ and ψ according to
Figure 13.1, and (·)T denotes transpose. The integral is taken over the transducer body. It is however
more common to work directly on the sampled space assuming ideal point source elements. These
elements sample the aperture function AT (ω, rT ), so the aperture function can be expressed in terms
of those sample values
AT (ω, rT ) =
L

n=1
cn(ω)δ(rT −rn),
(13.2)

3.13.2 Environment and Channel Modeling
557
x
y
z
(
)
,
θ φ
Ω =
~
~ ~
θ
φ
(
)
,
θ φ
Ω =
FIGURE 13.1
Figure illustrating the choice of 3-D variables.
where rn gives the element positions. Inserting this expression (13.2) in (13.1) yields
DT (ω, α) =
 ∞
−∞
L

n=1
cn(ω)δ(rT −rn) exp (i2παT rT )drT
=
L

n=1
cn(ω) exp (i2παT rn) = cH(ω)da(α,rn).
(13.3)
where (·)H denotes the Hermitian transpose, i.e., transpose and conjugate.
Thus the beampattern is determined by a vector of complex weights c(ω) and an array response
vector d(α, rn). The array response vector is deﬁned by the frequency, the unit directivity vector α and
placements of elements. The expression (13.3) gives the far ﬁeld response in a free ﬁeld for identical
omni-directional elements. This equation can then be used as a design equation for the far ﬁeld beam-
former weight design. For near ﬁeld designs, a near ﬁeld model needs to be considered. The Green
function for free ﬁeld can be used to model near ﬁeld response
HM(ω, rM, rT , ν) = HM(ω, ρ) = −exp (−i ω
c |rM −rT |)
4π|rM −rT |
= −exp (−i ω
c ρ)
4πρ
.
(13.4)
This expression is valid for time invariant and space invariant settings (unbounded and homogeneous
medium). In a more general modeling case, one needs to consider a propagation model and also include
reﬂections.
3.13.2.2 Array geometries
An array can be considered as a sampled aperture where the elements are chosen as sample values on
a surface of various shape. In the previous section, the far-ﬁeld directivity pattern (beam pattern) was
connected to the aperture function Eq. (13.1). That gives the general far ﬁeld response for any given set of
sample points. When one considers certain geometries such as a linear array, planar array, circular array,
cylindric array or spherical array, the array response vector will have a different structure. The positions

558
CHAPTER 13 Broadband Beamforming and Optimization
Table 13.1 Array Element Positions for Some Common Array Geometries
Structure
Element position
Linear array
rn = [(n −1)dx , 0, 0]
2-D rectangular
rk,n = [(k −1)dx , (n −1)dy , 0]
Multi-ring circular
rk,n =

rn cos
 2π(kN+n)
KN

, rn sin
 2π(kN+n)
KN

, 0

Cylindrical
rk,n =

r cos
 2π(k)
K

, r sin
 2π(k)
K

, zn

Spherical
rk,n = r

cos

2πk
K

sin

2πn
N

, sin

2πk
K

sin

2πn
N

, cos

2πn
N

Table 13.2 Array Response for Some Common Array Geometries
Structure
[da(ω, φ, θ)]k,n
Linear array
d0,n(ω, φ) = exp

i ωd sin (θ) cos (φ)(n−1)
c

2-D
rectan-
gular
dk,n(ω, φ) = exp

j ω
c (dx sin (θ) cos (φ)(k −1) + dy sin (θ) sin (φ)(n −1)
	
Multi-ring
circular
dk,n(ω, φ, θ) = exp

j ωrp
c sin (θ) cos

φ −2π(kN+n)
KN

Cylindrical
dk,n(ω, φ, θ) = exp

j ω
c

r sin (θ) cos

φ −2πk
K

+ zn cos (θ)

Spherical
dk,n(ω, φ, θ) = exp

j ωr
c

sin (θ) sin
 π(n−1)
N−1

cos

φ −2πk
K

+ cos (θ) cos
 π(n−1)
N−1

of the array elements for some common geometries, assuming that the origin of the coordinate system
has been chosen as one of the points, can be found in Table 13.1.
From the array element positions given in Table 13.1 and utilizing the unit direction vector α, the
array response vector for the far ﬁeld can be calculated. They have been tabulated in Table 13.2.
The array response vector is connected to the far ﬁeld response via the weighted sum in (13.3). Using
this equation, a design model of the broadband beamformer can be found. It is also possible to design
beamformers using wave propagation modeling, which is considered in a separate section.
3.13.3 Broadband beamformer design in element space
In this section, we consider the broadband beamformer design in element space, thus in a spatially
sampled domain. The design can be considered for time domain implementation using conventional
FIR ﬁlters or possibly IIR ﬁlters, according to Figure 13.2. Pre-steering delays κp(t) have also been
included. These delays steer the array to a prescribed direction. This direction is usually determined
by some tracking algorithm which is outside the scope of this chapter. Alternatively, the design can
be considered in transform domain using multi-rate ﬁltering techniques, see Figure 13.3. This element
space design contrasts to the wave propagation domain which considers orthonormal expansion of

3.13.3 Broadband Beamformer Design in Element Space
559
z-1
z-1
z-1
+
+
z-1
z-1
z-1
+
+
...
...
...
+
0th mic
(P-1)th mic
w0(0)
w0(L-1)
w0(1)
wP-1(0)
wP-1(L-1)
wP-1(1)
P-1(t)
0(t)
FIGURE 13.2
Broadband beamformer, time domain.
...
+
0th mic
(P-1)th mic
W0(ωi)
κ0(ωi)
WP-1(ωi)
κP-1(ωi)
FFT
IFFT
FFT
FIGURE 13.3
Broadband beamformer, frequency domain.
the wave ﬁeld on the receiver shape. Then the orthonormal expansion is sampled in such a way that
necessary orthogonality properties are maintained. Using that technique allows the spatial and temporal
domain to be separated such that steering of beams is independent of the beamforming. This topic will
be discussed in a separate section.

560
CHAPTER 13 Broadband Beamforming and Optimization
Now consider the frequency domain output of an element space broadband beamformer for a point
source in position rm
Ym(ω) = Sm(ω)WH(ω)H(ω, rm),
(13.5)
where S(ω) is the spectral density of the source, and H(ω, rm) is the array response vector consisting
of the Green function Eq. (13.4) describing the individual channel between the source and each of the
sensor array elements
H(ω, rm) =
⎛
⎜⎜⎜⎝
H1(ω, rm)
H2(ω, rm)
...
HP(ω, rm)
⎞
⎟⎟⎟⎠.
(13.6)
Furthermore, W(ω) is a vector with the frequency function of the beamformer weights for each
element and is described by
W(ωs) =
⎛
⎜⎜⎜⎝
wT
1
wT
2...
wT
P
⎞
⎟⎟⎟⎠e(ωs),
(13.7)
where wp = [wp(0), wp(1), . . . , wp(L −1)]T is the weight vector with real valued weights for the
pth FIR ﬁlter in the broadband array, and the ﬁlter response vector is given by e(ωs) = [1, e−jωs, . . . ,
e−j(L−1)ωs]T , where ωs = ωTs denotes discrete frequency. The assumption is that the signal at every
element is bandlimited and sampled with sample frequency fs = 1/Ts. Now, instead of using matrix
form for the ﬁlter weights, stack the weight vectors wp into an PL × 1 weight vector w and also
combining the array response from the source to every element with the FIR response of every ﬁlter
d(ω, rm) = H(ω, rm) ⊗e(ωs),
(13.8)
where ⊗deﬁnes Kronecker product. The overall response from a position rm is given by
G(ω, rm) = wT d(ω, rm),
(13.9)
where d(ω, rm) is a column vector of length N = PL. The optimized beamformer is designed by ﬁnding
the coefﬁcients of the ﬁlters such that the actual response G(ω, rm) = wT d(ω, rm) ﬁts a given desired
response Gd(ω, rm). The performance measure used here is the error between an actual frequency
response G(ω, rm) and a desired frequency response Gd(ω, rm),
ξ(ω, rm) = G(ω, rm) −Gd(ω, rm).
(13.10)
The coefﬁcients of the ﬁlters are found such that this error measure is minimized. This expression
is now formed so it is valid for a general channel model for a homogeneous medium. Under simpliﬁed
modeling considerations (free and far ﬁeld), it is possible to express Eq. (13.4) using the far ﬁeld
array response vector da(ω, φ, θ). This relationship normally assumes a choice of coordinate system
such that the origin is located in one of the array elements. In that case, one has one common Green

3.13.3 Broadband Beamformer Design in Element Space
561
function to one element and then the relative delay to the other sensors; these response functions can be
found in Table 13.2 for various geometries. Then the response will be a function of (ω, θ, φ). Since the
response is dependent on direction and frequency, directivity patterns for each frequency can be plotted
accordingly. In the near ﬁeld, the response is dependent on every point and not just the direction.
The minimization of ξ(ω, rm) can be performed by employing standard ﬁlter design methods such
as Weighted Least-Squares (WLS) or Chebyshev (min-max) optimization. However, there has also
been suggested solutions based on Total Least Squares (TLS) and Eigen-Filter (EF) methods. These
techniques are similar to those used for multi-dimensional ﬁlter design, except that the main difference
for broadband beamforming design is convolutive channel and sensor amplitude and phase uncertainty.
Accordingly, that uncertainty also needs to be considered in the design which leads to various robust
design techniques. In the sequel, we will discuss those methods in details.
3.13.3.1 Weighted Least Squares design
The nominal Weighted Least Square (WLS) design is the standard way to ﬁnd optimal weights for
the broadband beamformer. The details of the method are as follows. The transfer function from a
spatial point with position vector rT to the nth weight wn of the broadband beamformer is denoted by
dn(ω, rT ). Let Gd(ω, rT ) and G(ω, rT ) be the speciﬁed desired response and the nominal response of
the broadband beamformer, respectively. The response vectors are deﬁned in space and frequency. The
nominal array response vector d(ω, rm) is assumed to be known. The WLS formulation is given by
min
w JWLS(w) = min
w



R
V (ω, rT )|ξ(ω, rT )|2 drT dω
= min
w (wT AWLSw −2Re

aH
WLSw

+ bWLS),
(13.11)
where  is the range of frequencies and R is spatial area of the design and
AWLS =



R
V (ω, rT )d(ω, rT )dH(ω, rT )drT dω,
(13.12)
aWLS =



R
V (ω, rT )d(ω, rT )G H
d (ω, rT )drT dω,
(13.13)
bWLS =



R
V (ω, rT )|Gd(ω, rT )|2 drT dω.
(13.14)
The optimal solution is found as
w = A−1
WLSaWLS.
(13.15)
One property of the WLS optimization is that one has little control of the sidelobes of the beampattern.
To achieve such control, sidelobe constraints can be included into (13.11), yielding
min
w
JWLS(w) = wT AWLSw −2Re

aH
WLSw

+ bWLS
(13.16)
subject to |dH(ω, rT )w|2 ≤ϵ
(ω, rT ) ∈stop region,
where AWLS, aWLS, and bWLS have already been deﬁned and ϵ gives the sidelobe tolerance. The stop
region is formed by the spectral stop-band region st and the spatial stop-band region Rst, respectively.

562
CHAPTER 13 Broadband Beamforming and Optimization
This problem is a quadratic semi-deﬁnite program which can be solved directly by discretizing the
constraints. However, it becomes a large-scale problem, especially when the spatial domain is a two or
three dimensional region. For large-scale constrained optimization problems, the most efﬁcient algo-
rithm is the interior point algorithm, which has polynomial time computational complexity and has been
applied successfully for linear programming, linear semi-deﬁnite programming, second-order cone pro-
gramming and convex programming. As the constraints are quadratic functions, this problem can be
transformed into a linear semi-deﬁnite programming problem and the interior point algorithm can be
applied. For references, see the section on further reading.
3.13.3.2 Total Least Squares design and Eigen-Filters
Another popular way to design beamformer coefﬁcients is to use Eigen-Filters. The Eigen-Filter cost
function is obtained by using the following expression:
max
w
J ′
Eig(w) = max
w
wT AROIw
wT ATOTw,
(13.17)
where
AROI =

ROI

RROI
V (ω, rT )d(ω, rT )dH(ω, rT )drT dω
(13.18)
is a power measure deﬁned over the passband region, thus it is deﬁned by the spectral passband region
ROI and the spatial passband region RROI, respectively. In a similar manner the power measure for the
total region is
ATOT =

TOT

RTOT
V (ω, rT )d(ω, rT )dH(ω, rT )drT dω,
(13.19)
where TOT and RTOT are the spectral total region and the spatial total region, respectively. The denom-
inator matrix ATOT is constructed from all regions. The optimal weights are found by maximizing
J ′
Eig(w) with respect to w, which is also known as a generalized eigenvalue problem. This optimization
usually gives low sidelobes, thus high suppression outside the ROI. However there is no control over
the passband region and it does not work well for broadband arrays. This results in high distortion of
the input signal from the ROI in the low frequency band. To improve this and still maintain a high noise
suppression, an alternative formulation has been suggested. This so called Total Least Squares (TLS)
formulation seeks a solution comprising both the WLS error and the Eigen-Filter formulation.
In this case, the response for the region of interest versus the overall region or the region of rejection
is optimized with the equation given by
ξTLS(ω, rT ) =
|ξ(ω, rT )|

wT Ae,TOTw + 1
,
(13.20)
where ξ(ω, rT ) is deﬁned as in Eq. (13.10). Now suppose that the beamformer design is based on
(13.20), i.e., deﬁne the cost function as
JTLS(w) =



R
V (ω, rT )ξ2
TLS(ω, rT )drT dω
= wT
e ATLSwe
wTe Ae,TOTwe
,
(13.21)

3.13.3 Broadband Beamformer Design in Element Space
563
where
ATLS =
 AWLS
aWLS
aH
WLS
bWLS

,
Ae,TOT =
 ATOT
0
0
1

,
we =
 w
−1

.
(13.22)
Thus the Total Least Squares Eigen-Filter design formulation is given by
min
we JTLS(w) = min
we
wT
e Ae,TLSwe
wTe Ae,TOTwe
.
(13.23)
The solution to (13.23) is the generalized eigenvector of Ae,TLS and Ae,TOT that corresponds to the
smallest generalized eigenvalue. The ﬁlter coefﬁcients w can be extracted from we after scaling it such
that the last element is −1. The advantage of this formulation is that a measure of desired response has
been included, thus less distortion can be achieved.
3.13.3.3 Chebyshev design
It is also possible to optimize the Chebyshev error or min-max error instead of the Least Squares. This
optimization problem minimizes the maximum deviation of the error. In this case the problem is written
as follows:
J(wc) = min
wc
max
(ω,rT )∈S V (ω, rT )
wT
c d(ω, rT ) −Gd(ω, rT )
 ,
(13.24)
where G(ω, rT ) = wT
c d(ω, rT ) is the beamformer response function and Gd(ω, rT ) is the desired
response vector as deﬁned previously. The frequency and source location vector should belong to the
optimization set S. This set S is given by the passband region and the stopband region both in frequency
and space. The weighting V (ω, rT ) is a positive function. The original Chebyshev problem (13.24) can
be rewritten in an equivalent form as follows:
min
δ
δ
subject to
V 2(ω, rT )|wT
c d(ω, rT ) −Gd(ω, rT )|2 ≤δ,
∀(ω, rT ) ∈S,
(13.25)
where δ is the maximum deviation. The equivalence follows from the fact that δ is the maximum
deviation of the non-linear constraint and this δ is minimized. Thus the original Chebyshev problem has
been converted to a sequential quadratic programming problem. This problem can also be converted into
a linear semi-deﬁnite programming problem. The original problem is semi-inﬁnite and thus continuous,
but it can be discretized. Although the constrained optimization problem (13.25) can be solved directly,
the number of constraints is usually large. For a broadband beamforming case it becomes a large-scale
problem since the number of constraints grow, especially when the spatial domain is a two or three-
dimensional region. This will be the case for near-ﬁeld problems. As stated earlier in Section 3.13.3.1,
the most efﬁcient algorithm to solve this problem is the interior point algorithm.
3.13.3.4 Model and robust formulation
As mentioned earlier, the performance of broadband beamformers designed with the nominal WLS,
TLS and min-max optimization methods are severely degraded due to model errors. The design of
robust beamformers topic is extensive, see [6], here we concentrate on the problem of designing data

564
CHAPTER 13 Broadband Beamforming and Optimization
independent broadband beamformers. For adaptive beamformers the problems that occur are things
like SOI cancelation or source distortion. In the data independent broadband case the main concern
is the deviation between the nominal array response and the actual channel response a source input is
subjected to. In many cases this deviation means that the weights designed on the basis of the nominal
model are not useful since this deviation become exorbitant. Typically, errors could arise from phase
and amplitude mismatch of sensors and ampliﬁers, as well as sensor placement errors. Another aspect
of importance is the difference between the actual environment and propagation model used for the
design. Thus, it is important to be able to model those errors and include them in the design. Normally,
the errors are considered to be either multiplicative or additive. Accordingly, the perturbed response
vector is given either by
H(ω, rT ) = H(ω, rT ) ⊙δH(ω, rT )
(13.26)
or
H(ω, rT ) = H(ω, rT ) + δH(ω, rT ),
(13.27)
where δH(ω, rT ) is modeled as a complex random vector and H(ω, rT ) is the nominal array response
vector and ⊙denotes direct product.
We ﬁrst consider the multiplicative case according to Eq. (13.26), the pth element in the random
vector δH(ω, rT )|p = δH,p(ω, rT ) can be characterized by its gain error |δH,p(ω, rT )| and phase error
arg (δH,p(ω, rT )). The gain and phase are assumed to be independent errors. This perturbation model
can now be incorporated in the array response vector given in Eq. (13.8) yielding
˜d(ω, rT ) = H(ω, rT ) ⊗e(ω),
(13.28)
which can be rewritten using some simple matrix manipulations into
˜d(ω, rT ) = (δH(ω, rT ) ⊗1) ⊙d(ω, rT ),
where 1 is a L × 1 vector with all elements equal to one. Based on the perturbed array response, form
the outer product such that
Q(ω, rT ) = ˜d(ω, rT )˜dH(ω, rT )
=

δH(ω, rT )δH
H(ω, rT )

⊗11T 
⊙Q(ω, rT ),
(13.29)
where Q(ω, rT ) = d(ω, rT )dH(ω, rT ). Now also form the cross-term with the desired response
˜g(ω, rT ) = ˜d(ω, rT )G H
d (ω, rT ),
(13.30)
which can be rewritten as
˜g(ω, rT ) = (δH(ω, rT ) ⊗1) ⊙g(ω, rT ).
Note that the sensor gain and phase errors can be considered as random variables and it is the error
vector δH(ω, rT ) that is of interest. Let the matrix containing the perturbations be deﬁned according to
(ω, rT ) = δH(ω, rT )δH
H(ω, rT ).
(13.31)

3.13.3 Broadband Beamformer Design in Element Space
565
These perturbations are considered as a random vector, and to optimize the mean performance, the gain
and phase probability density functions (PDFs) are assumed to be known, i.e.,
(ω, rT ) = E[(ω, rT )] = E

δH(ω, rT )δH
H(ω, rT )

,
(13.32)
¯δH(ω, rT ) = E[δH(ω, rT )].
(13.33)
Thus the perturbed quantities for the multiplicative error can be written as
Q(ω, rT ) = E[Q(ω, rT )] = ((ω, rT ) ⊗11T ) ⊙Q(ω, rT ),
(13.34)
¯g(ω, rT ) = E[˜g(ω, rT )] = (¯δH(ω, rT ) ⊗1) ⊙d(ω, rT )G H
d (ω, rT ).
(13.35)
The additive disturbance is the next situation to be studied. One interpretation of this is that the
additive disturbance is a random reﬂection of the incoming wave, local scattering or distributed source.
In this case, the perturbed response vector is given by
H(ω, rT ) = H(ω, rT ) + δa,H(ω, rT ).
(13.36)
The outer product of the perturbed response is given by
Qa(ω, rT ) = ˜da(ω, rT ) ˜da
H(ω, rT )
= (δa,H(ω, rT ) ⊗e(ω) + d(ω, rT ))(δa,H(ω, rT ) ⊗e(ω) + d(ω, rT ))H.
This expression can be expanded as follows:
Qa(ω, rT ) = Q(ω, rT ) + Qa(ω, rT ),
where
Qa(ω, rT ) =

a(ω, rT ) + δa,H(ω, rT )HH(ω, rT ) + H(ω, rT )δH
a,H(ω, rT )

⊗e(ω)eH(ω)
and
˜ga(ω, rT ) = ˜d(ω, rT )G H
d (ω, rT ) = (δa,H(ω, rT ) ⊗e(ω) + d(ψ, ω, rT ))Gd(ω, rT )
= g(ψ, ω, rT ) + δa,H(ω, rT ) ⊗e(ω)Gd(ω, rT ).
The expectation can be taken on those equations resulting in
Qa(ω, rT ) = Q(ω, rT ) + Qa(ω, rT ),
(13.37)
¯g(ω, rT ) = g(ω, rT ) + ¯δa,H(ω, rT ) ⊗e(ω)Gd(ω, rT ),
(13.38)
where the model error is given by
Qa(ω, rT ) =

a(ω, rT ) + ¯δa,H(ω, rT )HH(ω, rT ) + H(ω, rT )¯δ
H
a,H(ω, rT )

⊗e(ω)eH(ω),
the correlation matrix of the perturbation error is
a(ω, rT ) = E

δa,H(ω, rT )δH
a,H(ω, rT )


566
CHAPTER 13 Broadband Beamforming and Optimization
and the mean of the perturbation vector is
¯δa,H(ω, rT ) = E[δa,H(ω, rT )].
These expressions are given in form of an expectation which is the mean of the errors on each
element. Thus, to obtain those expressions, one needs a model on the probability density of the errors.
It is also possible to study a worst case scenario but this is more difﬁcult to obtain, since it is not easy
to ﬁnd worst case bounds.
3.13.3.5 Robust WLS design
In the robust formulated WLS design, a model of the random vector is employed. The robust design is
based on the same set of weighting coefﬁcients V (ω, rT ) and desired response Gd(ω) as in the nominal
design, but with an unknown (random) array response vector added to or multiplied with the nominal
array response vector. The robust WLS formulation is based on the averaged response
min
w JWLS(w) = min
w E



R
V (ω, rT )
˜ξ(ψ, ω, rT )

2
drT dω

= min
w

wHAWLSw −2ℜ

¯aH
WLSw

+ bLS

,
(13.39)
where  is the range of frequencies and R is the spatial region for the design, and
AWLS =



R
V (ω, rT )Q(ω, rT )drT dω
(13.40)
¯aWLS =



R
V (ω, rT )g(ω, rT )drT dω
(13.41)
bWLS =



R
V (ω, rT )b(ω, rT )drT dω,
(13.42)
where V (ω, rT ) is the weighting function, and  and R are the regions of interest for ω and rT ,
respectively. Q(ω, rT ) and ¯g(ω, rT ) are given in (13.34) and (13.35), respectively, for the multiplicative
case. In the additive error model case, the structure does not change but Qa(ω, rT ) and ¯ga(ω, rT ) are
given by (13.37) and (13.38) instead. There is no change to the optimization per se, only in the way the
problem is set up. In the examples, we will see the difference in results when inserting the robust model.
It is also possible to extend the constrained WLS design as a robust formulation; the design equations
are as follows:
min
w
JCLS(w) = wHACLSw −2ℜ

¯aH
CLSw

+ bCLS
(13.43)
subject to
|¯dH(ω, rT )w| ≤ϵ
(ω, rT ) ∈stop region,
where
ACLS =

pb

Rpb
V (ω, rT )Q(ω, rT )drT dω
(13.44)
¯aCLS =

pb

Rpb
V (ω, rT )¯g(ω, rT )drT dω
(13.45)

3.13.3 Broadband Beamformer Design in Element Space
567
bCLS =

pb

Rpb
V (ω, rT )b(ω, rT )drT dω
(13.46)
¯d(ω, rT ) = V (ω, rT )¯g(ψ, ω, rT )/Gd(ω, rT )
(13.47)
with ϵ the tolerance of the sidelobes, and pb and Rpb are the spectral and spatial pass region,
respectively.
3.13.3.6 Robust Total Least Squares design
The TLS optimization can also be extended to a robust formulation, where its error function is
expressed as
¯ξ2
TLS(ω, rT ) = E[|˜ξ(ω, rT )|2]
wHATOTw + 1
.
(13.48)
This TLS error can be formulated into a cost function as follows
min
we JTLS(we) = min
we E



R
V (ω, rT )˜ξ2
TLS(ω, rT )drT dω

= min
we
wH
e ATLSwe
wH
e Ae,TOTwe
,
(13.49)
where
Ae,TLS =

AWLS
¯aLS
¯aH
LS
bLS

,
Ae,TOT =

ATOT
0
0
1

,
we =
 w
−1

.
(13.50)
Its solution is given by the generalized eigenvector of Ae,TLS and Ae,TOT that corresponds to the smallest
generalized eigenvalue. Again, the ﬁlter coefﬁcients w can be extracted from we after scaling its last
element to −1.
3.13.3.7 Robust Chebyshev design
The above non-robust design of the Chebyshev error can be extended to include robustness constraints.
The robust array response includes a perturbation in the same way as for the WLS design
min
wc J(wc) = min
wc ∥(E[˜ξ(ω, rT )])∥
= min
wc
max
(ω,rT )∈S V (ω, rT )

E
wH
c ˜d(ω, rT ) −Gd(ω, rT )

2
,
(13.51)
where V (ω, rT ) is the positive weighting function.
Now take the square of the Chebyshev error and expand
V (ω, rT )

E
wH
c ˜d(ω, rT ) −Gd(ω, rT )

2
,

568
CHAPTER 13 Broadband Beamforming and Optimization
which yields
V 2(ω, rT )E
wT
c ˜d(ω, rT ) −Gd(ω, rT )

2
= V 2(ω, rT )

wT
c Q(ω, rT )wc −2ℜ{¯g(ω, rT )}Hwc + |Gd(ω, rT )|2
.
Deﬁne E(|εκ(wc)|2) = E[|wH
c ˜dκ −Gd,κ|2] where κ is the index set of sample points over the design
area given by  ∈[ωlow, ωupper], R ∈[spatial design region]; the functions are now sampled over that
grid. Accordingly, the robust Chebyshev problem can be formulated as
min
δ
δ
subject to V 2
κ E
wH
c ˜dκ −Gd,κ

2
≤δ,
∀κ ∈{1, . . . , K}.
(13.52)
This problem is the same as Eq. (13.25) above structurally, but with a random perturbation included.
Thus, this problem can be reformulated and solved in the same way.
This concludes the discussion on optimal design of broadband beamformers. For more details, there
is a lot of literature available. But the main consideration is how to make the design robust such that it
can be applied in real world problems. This will be made even clearer in some design examples.
3.13.3.8 Design examples
A few design examples are presented to illustrate the formulations discussed. The design examples
are for the non-robust WLS, TLS and Chebyshev. A broadside linear array is used with inter-element
spacing of 4 cm. The design parameters are as speciﬁed in Table 13.3.
Figure 13.4 shows the normalized beampatterns for non-robust WLS, TLS and Chebyshev designs
under ideal conditions. It can be seen from the plots that the TLS gives lower sidelobes than WLS. But
the TLS will give more distortion in the passband. The Chebyshev design has equiripple characteristics.
This means that the response deviation has been controlled in both passband and stopband. In order to
illustrate the beneﬁts with robust formulation, a comparison between normalized beamformer response
Table 13.3 Common Design Parameters
Parameters
Values
Number of microphones, K
5
FIR ﬁlter length, N
65
Spectral passband, p
[200, 3800] Hz
Spectral stopband, s
[0, 100] ∪[3950, 4000] Hz
Sampling frequency, fs
8000 Hz
Speed of sound, c
343 m s−1
Spatial pass region, p
[−15◦, 15◦]
Spatial stop region, s
[−180◦, −25◦] ∪[25◦, 180◦]

3.13.3 Broadband Beamformer Design in Element Space
569
0
1000
2000
3000
4000
−100
−50
0
50
100
−50
−40
−30
−20
−10
0
10
φ (degree)
Look direction = 0.0 [0.0, 0.0]
f (Hz)
Magnitude (dB)
−30
−25
−20
−15
−10
−5
0
FIGURE 13.4
Beampatterns for non-robust (a) WLS, (b) TLS, and (c) Chebyshev designs under ideal conditions.

570
CHAPTER 13 Broadband Beamforming and Optimization
FIGURE 13.5
Beampatterns for (a) non-robust and (b) robust WLS designs with perturbation.
for non-robust and robust WLS with perturbation is shown in Figure 13.5, which clearly highlights
the robustness. The perturbations are made on phase and amplitude response on each element, the
perturbations are made according to a Gaussian distributed in amplitude |δH(ω, rT )| ∈(1, 0.05) and
rectangular distributed in phase arg (δH(ω, rT )) ∈R(−0.05, 0.05) rad. Similar results can be obtained
for the other formulations but only one example is provided as an illustration. This clearly shows the
effectiveness of a robust formulation. The WLS problem formulation gives very little extra complexity
in the design phase compared to the non-robust but provide a practical beamformer design. In the robust
design it has been assumed the same distribution of each individual element as the perturbation above.

3.13.3 Broadband Beamformer Design in Element Space
571
Of course in the design case the expectation has been calculated and in the example it is an outcome
using that distribution.
3.13.3.9 Steerable broadband beamformer
A steerable beamformer can be created in two steps. The ﬁrst step is to steer the beam using broadband
fractional delays on each sensor element, and then broadband beamforming is applied. The fractional
delay steering is usually implemented using either a Farrow structure or sub-sampling technique. How-
ever, it is also possible to combine the fractional delays directly in the beamforming design, resulting in
an integrated system. The steering can then be done by adjusting one single parameter which is a func-
tion of the steering direction. From the formulation of the problem, it can be seen that the beamformer
weight design can be performed by using any of the previously discussed design techniques.
The broadband steerable Farrow beamformer structure is described in Figure 13.6. The Farrow
beamformer consists of M parallel FIR ﬁlters combined with a polynomial interpolation. This allows
an approximation of a fractional delay which is used to provide both the capabilities of beam steering
and broadband beamforming. For simplicity, we present the case for the horizontal plane, where the
steerable beamformer structure using the time domain FIR Farrow ﬁlters is shown in Figure 13.6. The
beamformer response is given by
G(ψ, ω, rT ) =
P−1

p=0
K−1

k=0
L−1

l=0
wp,k[l]Hp(ω, rT )ψk exp (−jωlTs),
(13.53)
where P is the number of microphones, K −1 is the order of Farrow’s structure, L is the number of
ﬁlter taps, Hp(ω, rT ) is the array response and wp,k(l) is the ﬁlter coefﬁcients, which are considered to
be real. The steering variable ψ, typically normalized to be between −0.5 and 0.5 inclusively, is related
to the look direction as in
ψ =
˜ψ
˜ψmax
,
(13.54)
where ˜ψmax is the maximum range of steerable look direction. Note that (13.53) can be written more
compactly in matrix form as given by
G(ψ, ω, rT ) = wT d(ψ, ω, rT ),
(13.55)
where
w =
wT
0,0
. . . wT
0,K−1
| · · · | wT
P−1,0
· · · wT
P−1,K−1
T ,
(13.56)
wp,k =
wp,k[0] · · · wp,k[L −1] T ,
(13.57)
d(ψ, ω, rT ) = H(ω, rT ) ⊗ψ ⊗e(ω),
(13.58)
H(ω, rT ) =
 h0(ω, rT ) · · · h P−1(ω, rT )T ,
(13.59)
ψ =

ψ0
· · · ψ K−1 T ,
(13.60)
e(ω) =

1 · · · e(−jω(L−1)Ts) T .
(13.61)

572
CHAPTER 13 Broadband Beamforming and Optimization
FIGURE 13.6
TD Farrow ﬁlter structure for steerable broadband beamformer.
Deﬁning the difference between the designed response G(ψ, ω, rT ) and desired response
Gd(ψ, ω, rT ) as
ξ(ψ, ω, rT ) = G(ψ, ω, rT ) −Gd(ψ, ω, rT )
(13.62)
now deﬁne the squared difference as
|ξ(ψ, ω, rT )|2 = wT Q(ψ, ω, rT )w −2ℜ

wT g(ψ, ω, rT )

+ b(ψ, ω, rT ),
(13.63)
where
Q(ψ, ω, rT ) = d(ψ, ω, rT )dH(ψ, ω, rT ),
(13.64)

3.13.3 Broadband Beamformer Design in Element Space
573
g(ψ, ω, rT ) = d(ψ, ω, rT )G H
d (ψ, ω, rT ),
(13.65)
b(ψ, ω, rT ) = |Gd(ψ, ω, rT )|2.
(13.66)
The form of the error function for the Farrow structure is similar as deﬁned in previous sections. Hence,
the same optimization techniques can be used. The only difference is that there is a need to expand the
equations to optimize over ψ as well. The usefulness of this formulation will be shown in some examples.
It allows the direct steering of broadband beams from one single parameter ψ. Since the steering is
included in the design, the beampattern can more or less be maintained. It is however more challenging
to design the beampattern because the number of parameters grows with a factor K. Furthermore, as the
matrix Q(ψ, ω, rT ) is evaluated for various (ψ, ω, rT ), there is less variations which leads to numerical
difﬁculty in solving the problem in some cases. The TLS and WLS solutions can still be found. However,
the constrained optimizations, Constrained Weighted Least Squares (CWLS) and Chebyshev, result in
large scale optimization problems which are a challenge to solve [7].
As an example, a design with the same design speciﬁcations as in Table 13.3 is provided with the
order of Farrow structure M = 4. Figures 13.7 and 13.8 show the beampattern steered to ψ = −20◦
and 35◦, respectively.
FIGURE 13.7
Beampattern of steerable beamformer steered to ψ = −20◦.

574
CHAPTER 13 Broadband Beamforming and Optimization
FIGURE 13.8
Beampattern of steerable beamformer steered to ψ = 35◦.
3.13.3.10 Discussion on optimization and design of broadband beamformers
The design of broadband beamformers are in many ways equivalent to designing multidimensional
ﬁlters. The important property to remember however is the connection to the physical room and space.
The main difﬁculty to be faced with in the design stems from the low frequency end of the spectrum.
Since broadband beamformers are designed over many octaves, the wavelength is very large for the lower
frequency end. But the distance between array elements needs to be spaced such that spatial aliasing
is avoided. Accordingly, in the lower frequency end, the array operates almost like a point receiver
and observes the same signal at each element resulting in poor spatial selectivity. Thus, if a constant
beamwidth is desired for all frequencies, very large beamformer weights are needed to compensate
for the small variations in the signals in the low frequencies. Which means that even small modeling
errors will have a large impact on the response. For practical use, robustness design is very important
for broadband beamformers if they are to be used without extensive calibration.
3.13.4 Broadband beamformer design using the wave equation
An alternative to the point sensor element view is that one can consider the broadband beamformer as
a rigid body and perform an eigenexpansion on that body. The eigenexpansion corresponds to a spatial

3.13.4 Broadband Beamformer Design using the Wave Equation
575
Fourier transform [5]. To ﬁnd these eigenexpansions on the surface of the body, one usually considers
very simple geometries, such as a sphere. There are a number of advantages with this approach, one being
the fact that the beampattern can be steered to any direction in 3-D space. This follows from the fact that
the eigenfunctions are not a function of frequency. It is only the modal coefﬁcients that are frequency
dependent. The spherical array naturally couples to the spherical representation of the wave equation.
The modal decomposition separates the problem into an orthogonal decomposition. The main results
follow from the expression of the time-independent lossless Helmholtz equation in spherical coordinates
∇2ϕ f (r) + k2ϕ f (r) = 0,
(13.67)
where k = 2π f /c is the wave number. To obtain this equation, it is assumed that the input is a com-
plex sinusoid. The solution to this equation in spherical coordinates [4,5] is obtained by the method of
separation of variables. This solution also follows from the spherical Fourier transform.
One main result from this solution is the following relationship:
eiαr = 4π
∞

n=0
in jn(kr)
n

m=−n
Y m
n (θ, φ)Y m∗
n
(θs, φs),
(13.68)
where jn(kr), n ∈[0, ∞] is the spherical Bessel functions and Y m
n (θ, φ) are the orthonormal spherical
harmonic eigenfunctions. The spherical harmonics are deﬁned as
Y m
n (θ, φ) =

(2n + 1)
4π
(n −m)!
(n + m)! Pm
n ( cos (θ))eimφ,
(13.69)
where Pm
n ( cos (θ)) are the associated Legendre functions of degree m and order n of the ﬁrst kind. For
the particular case of scattering on a sphere of radius a, the total acoustic pressure on the surface for an
impinging plane wave from the direction (θ, φ) at the location (a, θs, φs) on the sphere is given by
ϕs(θs, φs, ka, θ, φ) = 4π
∞

n=0
inbn(ka)
n

m=−n
Y m
n (θ, φ)Y m∗
n
(θs, φs),
(13.70)
where the normalized modal coefﬁcients are given by
bn(ka) =

jn(ka) −
j′
n(ka)
h(2)′
n
(ka)h(2)
n (ka) for a rigid sphere,
jn(ka)
for an open sphere,
(13.71)
where h(2)
n (ka) is the spherical Hankel function of second kind and (·)′ denotes the derivative. From
the expression (13.70), it can be seen that the frequency dependency is in the modal coefﬁcients. For
the rigid sphere, the ﬁrst term in the modal component describes the incoming wave and the second
term describes the scattered wave. The boundary condition for a rigid sphere is that the radial velocity
is zero. This condition gives the above modal coefﬁcients for a rigid sphere. For non-rigid spheres, the
boundary condition changes but the solution will remain in the same form but with different modal
coefﬁcients. The ﬁrst seven modal functions have been plotted as a function of ka in Figure 13.9 for an
open sphere and a rigid sphere, respectively.
As can be seen from (13.15), the sound pressure ﬁeld varies with the incoming wave and the position
on the sphere. If the spherical harmonic function Y m
n (s) can be formed on the surface of the sphere, it

576
CHAPTER 13 Broadband Beamforming and Optimization
0.2
0.5
1
2
5
8
40
35
30
25
20
15
10
5
0
ka
mode magntiude (dB)
Modal components for an open sphere
/
Mode 0
Mode 1
Mode 2
Mode 3
Mode 4
Mode 5
Mode 6
0.2
0.5
1
2
5
8
40
35
30
25
20
15
10
5
0
ka
mode magntiude (dB)
Modal components for a rigid sphere
Mode 0
Mode 1
Mode 2
Mode 3
Mode 4
Mode 5
Mode 6
FIGURE 13.9
Top: Modal components bn(ka) for an open sphere. Bottom: Modal components bn(ka) for a rigid sphere.

3.13.4 Broadband Beamformer Design using the Wave Equation
577
can operate as a eigenfunction beamforming receiver that matches to the incoming wave. Thus consider
the output of the eigenfunction beamformer for an incident plane wave, and considering only one
spherical harmonic function Y m
n (s), then we have
ϕn,m(ka, 0) =

s
ϕs, f (s, ka, 0)Y m
n (s)∗ds
=

s
4π
∞

n′=0
inbn(ka)
n′

m′=−n′
Y m′
n′ (0)

Y m′
n′ (s)
∗
Y m
n (s)∗ds
= 4π(−i)nbn(ka)Y m
n (0)∗,
(13.72)
where

s ds represents an integration over the surface of the sphere. This equation follows from the
orthonormal property of the spherical harmonics functions:

s

Y m′
n′ (s)
∗
Y m
n (s)ds = δ(n −n′, m −m′),
(13.73)
where δ(n, m) denotes the Kronecker delta function. Also, the impinging wave can be recovered from
the inverse of the operation in (13.72), which corresponds to an inverse spherical harmonic Fourier
transform:
ϕs(ka, 0, s) = 4π
∞

n=0
n

m=−n
ϕn,m(ka, 0)Y m
n (s).
(13.74)
Now assume that there are D incoming waves from directions 0, 1, . . . , D−1, and noise impinging
on the sphere. Then the sound pressure on the sphere is given by
x(ka, s) =
D−1

d=0
ϕs(ka, d, s)Sd(ω) + N(ω, s),
(13.75)
where Sd(ω) is the spectrum of the wave from direction d and the noise spectrum is denoted N(ω, s).
Then, the spherical Fourier transform can be taken on the sphere, resulting in
xn,m(ka) =

s
x(ka, s)Y m
n (s)ds
=

s
D−1

d=0
ϕs(ka, d, s)Sd(ω) + N(ω, s)

Y m
n (s)ds
=
D−1

d=0
ϕn,m(ka, d)Sd(ω) + Nn,m(ω).
(13.76)
We are now ready to discuss the impact of an aperture weighting function. The aperture weighting
function on the sphere operates like beamformer weights, where it is applied as a window over the
sphere and the output is obtained by integrating over the sphere as follows:
y(ka) =

s
x(ka, s)w∗(k, s)ds.
(13.77)

578
CHAPTER 13 Broadband Beamforming and Optimization
Both x(ka, s) and w(k, s) can be expanded into the spherical harmonics domain using the spher-
ical Fourier transform. This operation results in the following:
y(ka) =
∞

n=0
n

m=−n
xn,m(ka)w∗
n,m(k).
(13.78)
This summation is a weighting in the spherical harmonics domain and is usually called phase-mode
processing. Furthermore, the directivity pattern for the beamformer is deﬁned as the response of the
beamformer to a unit signal from any direction of interest , thus
D(k, ) =

s
ϕ(ka, , s)w∗(k, s)ds
=
∞

n=0
n

m=−n
ϕn,m(ka, )w∗
n,m(k).
(13.79)
This expression gives the response for a unit complex sinusoid. It is common to split the weighting
vector into one frequency dependent component and one spatial component such that
w∗
n,m(k) = cn(k)Y m
n (0).
(13.80)
This choice of weighting results in a rotational symmetric response [8]. Since the expansion of the unit
signal from any point of interest  is given by
ϕn,m(ka, ) = 4π(−i)nbn(ka)Y m
n ()∗
we can insert the expression (13.80) in (13.79), which results in
D(k, ) =
∞

n=0
n

m=−n
4πinbn(ka)cn(k)Y m
n ()∗Y m
n (0)
=
∞

n=0
(−i)nbn(ka)cn(k)(2n + 1)Pn( cos ()).
(13.81)
ThisexpressionfollowsfromtheLegendepolynomialadditiontheorem[9]whichstatesthefollowing:
Pn( cos ()) =
4π
2n + 1
n

m=−n
Y m
n ()∗Y m
n (0),
(13.82)
where  is the angle between two unit vectors from direction  and 0. Note that when  = 0, the
response should be one with the correct scaling. Thus, one can steer the beamformer to the position
0. The design of a given beampattern can be achieved by designing the coefﬁcients cn(k). One simple
way to do that is to set them as the inverse of the modal components. In view of the properties of the
modal components, those coefﬁcients needs to provide a high gain at low frequencies. To get frequency
independent beams over a wide frequency band, one needs to equalize the modal components, and as
the frequency becomes lower the gain needs to increase. The zero modal component gives an omni-
directional response. To have high resolution, high order components are needed. From the modal
function plots in Figure 13.9, it can be seen that the open sphere is more difﬁcult to control as it has
nulls and larger variations.

3.13.4 Broadband Beamformer Design using the Wave Equation
579
Another practical aspect is that the sound pressure wave on the sphere needs to be sampled. The
sampling is performed by sensors which are usually considered to be point sources. An exact repre-
sentation between the sampled information and the continuous information is obtained if the spherical
Fourier coefﬁcients can be calculated from the spatial samples without errors such as
xn,m(ka) =
R

r=1
αsx(ka, r)Y m
n (r),
(13.83)
where r ∈[1, . . . , R] are the sample points on the sphere and αs is a scaling depending on the sampling.
From (13.74), this condition can also be expressed as
R

r=1
αs[Y m′
n′ (r)]∗Y m
n (r) = δ(n −n′, m −m′).
(13.84)
Thus, the sampling points should be chosen such that the orthogonality properties are fulﬁlled. A
common approach which fulﬁlls these properties is the equiangle sampling. This sampling is performed
in such a way that the sphere is sampled uniformly in θ and φ. In this case the parameter is given by
αs = 4π/R. This sampling does not lead to a case with uniform distance between points and will not
give the lowest number of points. However it gives rotational invariance which is practical when the
array is moved. Now given that (13.84) is fulﬁlled, the discretized processing can be used.
The actual processing can be separated into four parts:
1. take the STFT, Short-time Fourier Transform, of the A/D converted signal for each sensor element;
this gives an approximation of x(ka, r);
2. multiply each channel with the sampled spherical harmonic Y m
n (r), then sum up the components
according to (13.83) to get xn,m(ka);
3. multiply with the steered spherical harmonic Y m
n (0);
4. multiply with the beamformer coefﬁcients and sum according to (13.78);
5. take the ISTFT, Inverse STFT, of the output.
This provides the basic theoretical framework for the design of a broadband beamformer in spherical
coordinates. Now, compared to the conventional broadband beamforming case, the difference is that it
is performed in frequency domain and that the signals are pre-beamformed using the spherical harmonic
functions, which have different patterns depending on the order according to Figure 13.10.
3.13.4.1 Broadband beamformer design based on the Wave equation
The design equation used to design a beamformer is given by the directivity pattern
D(ω, , 0) =
∞

n=0
(−i)nbn(ωa/c)cn(ω)(2n + 1)Pn( cos ()).
(13.85)
Here, (13.81) was used but the argument was changed from wave number to frequency. The relation-
ship between wave number and frequency is k = ω/c and thus ω = kc. There are different approaches
to ﬁnd weights for this beamformer. As mentioned, the direct way is just to compensate the modal
components; by doing so, one can get a frequency invariant beamformer over a certain bandwidth.
However, for a large bandwidth, some of the modal components become very small and thus one needs

580
CHAPTER 13 Broadband Beamforming and Optimization
+
Y0
0*(
S)
Yn
m*(
S)
YN
N*(
S)
Y0
0*(
1)
Yn
m*(
1)
YN
N*(
1)
...
...
...
...
...
+
+
X(f,
1)
X(f,
S)
Y0
0*(
0)
Yn
m*(
0)
YN
N*(
0)
...
...
Modal 
decomposition
Beam steering
Filtering
Wn
m(f)
WN
N(f)
+
Y(f)
W0
0(f)
Ω
Ω
Ω
Ω
Ω
Ω
Ω
Ω
Ω
Ω
Ω
FIGURE 13.10
Wave domain beamformer.
to have a high gain in cn(ω) for low frequencies. This limits the number of eigenbeams one can use. To
be able to stretch the frequency range, one needs low noise sensor elements. Thus, an alternative to the
direct approach is to use an optimization method to design the weights. To do this, form a cost function
based on a desired response and compare that with the response given by (13.85). This expression is
then optimized with respect to the ﬁlter weights cn(ω). The ﬁrst step is to limit the number of spherical
harmonic functions used in the optimization. They are set to be less than S ≤(N + 1)2. Since the
expression (13.85) is a ﬁnite sum, it can be rewritten in vector form as
D(ω, ) = WH(ω)d(ω, , 0),
(13.86)
where
d(ω, , 0) = [b0(ωa/c)(1)P0( cos ()), (−i)b1(ωa/c)3P1( cos ()), . . . ,
(−i)NbN(ωa/c)]T .
(13.87)
Also note that the modal components are frequency dependent but the spatial component is only depend-
ing on the spatial properties, thus
d(ω, , 0) = b(ω)P(),
(13.88)
where
b(ω) =
⎡
⎢⎢⎢⎣
b0(ωa/c)
b1(ωa/c)
...
bN(ωa/c)
⎤
⎥⎥⎥⎦

3.13.4 Broadband Beamformer Design using the Wave Equation
581
and
P() =
⎡
⎢⎢⎢⎣
P0( cos ())
0
· · ·
0
0
(−i)3P1( cos ()) · · ·
0
...
...
...
...
0
0
· · · (−i)N(2N + 1)PN( cos ())
⎤
⎥⎥⎥⎦.
Thus, D(ω, ) can be rewritten as
D(ω, ) = WH(ω)b(ω)P().
(13.89)
From this equation it can be seen that one term is not depending on frequency but is constant for all
frequencies. The other term contains all the frequency dependency. Also, note that the term P() is
depending on the shape of the beamformer and b(ω) determines the array response for frequency ω.
Based on this simpliﬁed beamforming approach, which is very common to use for spherical arrays, it
becomes straightforward to formulate the performance measure as the error between an actual frequency
response D(ω, ) and a desired frequency response Dd(ω, ),
ξ(ω, ) = D(ω, ) −Dd(ω, ).
(13.90)
Based on this expression, any of the already presented optimization methods can be used to ﬁnd the
optimal weights Wn(ω). Thus from (13.90) it immediately follows that optimum weights in WLS sense
can be found as
min
c
JWLS(c) = min
c

ωR

R
V (ω, )|ξ(ω, )|2d dω
= min
c

cHAs,WLSc −2ℜ

aH
s,WLSc

+ bs,WLS

,
(13.91)
where ωs is the range of frequencies and s is angular region in (θ, φ) of the design, and
As,WLS =

ωs

s
V (ω, )f(ω, , 0)f H(ω, , 0)d dω,
(13.92)
as,WLS =

ωs

s
V (ω, )f(ω, , 0)DH
d (ω, )d dω,
(13.93)
bs,WLS =

ωs

s
V (ω, )DH
d (ω, )Dd(ω, )d dω,
(13.94)
where 0 is the steering direction which can be set to (0, 0) in the design phase. In a similar way, the
weight design can be generalized to the other norm criterion including the robust formulations.
3.13.4.2 Time domain design of spherical broadband beamformer
As a matter of fact, (13.89) also forms the basis for the design of a time domain beamformer. In this
case, express Wn(ω) = wT
n e(ω) where wn is a vector of FIR ﬁlter weights and e(ω) is the FIR ﬁlter
response vector. Since the design equation is the same as for a general broadband beamformer, the same
techniques can be used. Thus the following expression can be used:
D(ω, ) = wT e(ω) × f(ω, , 0),
(13.95)

582
CHAPTER 13 Broadband Beamforming and Optimization
where w = [w1, w2, . . . , wN]T . This expression can now be used in the error equation and consequently
in the design equations. Thus, the design of a broadband beamformer using spherical harmonics can be
performed either in frequency domain or time domain. Note that the spherical harmonics are independent
of frequency the only frequency dependency is in the modal components. This means that the time
domain design can be viewed as an approximation of the frequency domain expression.
3.13.4.3 Design examples
In order to illustrate the design formulation discussed, a design example is presented. The design param-
eters used are as listed in Table 13.4, where the microphones are sampled using the equiangle sampling
Table 13.4 Design Parameters
Parameters
Value
Highest spherical harmonics order, N
5
Number of sensor, P
144
FIR ﬁlter length, L
64
Sampling frequency, fs
8000 Hz
Spectral passband, pb
[200, 3800] Hz
Radius of spherical array, a
4 cm
0
0.2
0.4
0.6
0.8
1
0
1000
2000
3000
4000
−120
−100
−80
−60
−40
−20
0
20
Frequency, f (Hz)
Elevation angle, θ (xπ)
Magnitude (dB)
dB
−30
−25
−20
−15
−10
−5
0
FIGURE 13.11
Beampattern steered to 0 = (0, 0).

3.13.4 Broadband Beamformer Design using the Wave Equation
583
scheme, which requires a total of 144 microphones to resolve up to 5th order spherical harmonics
[8,10,11]. Figure 13.11 shows the normalized beampattern steered to 0 = (0, 0) (azimuth angle φ is
not shown in the ﬁgure since the beampattern is invariant to azimuth angle). The frequency invariant
property of the design is clearly highlighted in this ﬁgure. Figures 13.12 and 13.13 show the normalized
−0.2
0
0.2
0.4
0.6
0.8
−0.2
0
0.2
0.4
0.6
−0.2
0
0.2
0.4
0.6
0.8
X
Y
Z
FIGURE 13.12
Beampattern at f = 2 kHz steered to 0 = (40, 30).
−0.6 −0.5 −0.4 −0.3 −0.2 −0.1 0
0.1
−0.5
0
0.5
1
−0.1
−0.05
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
X
Y
Z
FIGURE 13.13
Beampattern at f = 2 kHz steered to 0 = (80,120).

584
CHAPTER 13 Broadband Beamforming and Optimization
beampattern (at f = 2 kHz) steered to 0 = (40, 30) and 0 = (80, 120), respectively. These ﬁgures
clearly shows the steerability of the design while at the same time, the beampattern is maintained.
3.13.5 Optimum and adaptive broadband beamforming
For the optimum beamformer, the weights are formed based on properties of the data presented at each
sensor element. There are a number of methods available for the design of the broadband beamformer
weights. Since the design is based on measured data where the SOI is usually not available, some a
priori information about the source is needed to extract it. This is in contrast to blind signal separation
which assumes less a priori information, merely independence or sparsity. The most common way to
apply optimum beamforming is to use a constrained method. This type of methods relies on geometrical
constraints, where the location of the source is known either perfectly or almost perfectly. It also requires
a free ﬁeld or almost free ﬁeld environment and good calibration of the array. This limits the use of the
standard techniques in practical scenarios since model errors are evident. Accordingly, various different
robustness constraints have been developed. It also possible to combine optimum beamforming with
the methods discussed above to view the problem as a mix of an optimal and optimum beamforming
problem. In this section, some optimum beamforming methods will be reviewed.
3.13.5.1 Common signal modeling
In order to provide a consistent description, a general signal model and propagation model have been
used. It is general in the sense that microphone elements and sources can be placed arbitrarily with
any spectral content. The scenario is assumed to consist of M different point signal sources sm(t),
m = 1, . . . , M with spectral densities Rsmsm(ω). The sources are assumed to be mutually uncorrelated,
i.e., the cross power spectral density Rslsm(ω) is zero if l ̸= m. The waves from the M sources impinge
on an array of P microphone elements, each corrupted with non-directional diffuse noise nl(t) (the sim-
plest case is when the noise sources are independent). For a single point to single point transmission,
the propagation can be modeled using a transfer function (Green function) between source m and array
element p, denoted Hm,p(ω), and is either obtained from measurements or a model. In the model, a
spherical source in a free ﬁeld and homogeneous medium is the simple model usually used. In a real
world scenario, it is only possible to work on measured data. The sensor element signals x p(t) are
x p(t) =
M

m=1
sm(t) ∗hm,p(t) + n p(t) p = 1, . . . , P,
(13.96)
where ∗denotes convolution. This means that each source signal is described as a point source and is
ﬁltered by a linear time invariant system. By this is meant that the variations of the acoustic channel are
small relative to the update of optimal ﬁlters or adaptive ﬁlters. In the sequel, all the signals are assumed
to be band limited and sampled.
3.13.5.2 Linearly Constrained Minimum Variance beamforming
The Linearly Constrained Minimum Variance (LCMV) beamforming minimizes the output of a broad-
band array while maintaining a constant gain constraint towards the SOI. In the time domain imple-
mentation, the signal x p(t) at each element is sampled and is ﬁltered by an FIR ﬁlter of length L.

3.13.5 Optimum and Adaptive Broadband Beamforming
585
The output of the beamformer is given as
y(k) =
P−1

p=0
wT
p xp(k) = wT x(k),
(13.97)
where P is the number of elements and with the weight vector
wp = [ wp,0
wp,1
· · · wp,L−1]T ,
and the input data vector
xp(k) = [x p(k)
x p(k −1) · · ·
x p(k −L + 1)]T
has length L. Stacking weight and data vectors will give vectors of length PL × 1.
The expression to be minimized is the Mean Square Error E[|y(k)|2] with respect to the ﬁlter weights
ryy(0) = E[|y(k)|2] = wT E[x(k)xT (k)]w,
(13.98)
where E[·], is the expectation operator and the minimum is obviously zero. To avoid this trivial solution,
a constraint needs to be included. This constraint can be formed such that ys0(k) = s0(k −k0), i.e., the
output is distortion free apart from a possible delay. The SOI is assumed to be the zeroth source. To
create such a constraint, the impulse response hm,p(t) between the SOI and each array element needs
to be known. To derive the constraint for a broadband LCMV beamformer, assume that the P impulse
responses hm,p(t) can be represented by FIR responses hm,p(k) of length N. By using convolution
matrix techniques, the response between the SOI and the output of the beamformer can be expressed as
Hw = g,
(13.99)
where the convolutional matrix H of size (N + L −1) × (PL) is given by
H =
 H0,0
H0,1
· · · H0,P−2
H0,P−1

,
(13.100)
where the convolutional matrix from the SOI to sensor element p is given by
H0,p =
⎡
⎢⎢⎢⎢⎢⎣
h0,p(0)
0
· · ·
0
0
h0,p(1) h0,p(0)
· · ·
0
0
h0,p(2) h0,p(1) h0,p(0) · · ·
0
...
...
...
...
...
0
0
0
· · · h0,p(N −1)
⎤
⎥⎥⎥⎥⎥⎦
.
(13.101)
Here, w is the same stacked vector as before and g is the resulting response vector. To achieve the
distortion free property, the output g should have an entry that is one in position k0 and zero otherwise.
The LCMV problem can now be stated as
min
w
wT Rxxw
(13.102)
subject to Hw = g,

586
CHAPTER 13 Broadband Beamforming and Optimization
where
Rxx = E[x(k)xT (k)].
(13.103)
The solution to this problem can be found analytically
w = R−1
xx HT (HR−1
xx HT )−1g.
(13.104)
As can be seen from (13.99), this constraint may be very restrictive and degrees of freedom are lost.
This prevents the beamformer from suppressing directional interference, so called jammers. This is
particularly the case when the propagation impulse response has high complexity. In most studies and
as a ﬁrst approximation, one would only consider the direct path and use a pre-steering ﬁlter to align
the source signal to the correct direction of arrival of the SOI. As the SOI signals on the array are now
all aligned, the medium’s impulse response can be ignored. This corresponds to the free ﬁeld scenario
as stated in Section 3.13.2.1; this assumption leads to a convolutional matrix H of size (L −1) × (PL)
and the constraint simpliﬁes to the average of the column weights in the beamformer FIR matrix being
zero for all columns apart from the k0 column. This highlights the difﬁculty of using this technique in
reverberant rooms or when there is a mismatch between model and real signals, since the constraint is
only valid under ideal situations. To improve the response for those scenarios, extra constraints such
as a derivative constraints or quadratic constraints are usually added. These will lower the degrees of
freedom of the optimum beamformer. As an alternative to the time domain approach, the problem can be
formulated in frequency domain combined with multi-rate techniques for the processing. That will give
a number of narrowband problems which are usually easier to handle in practical scenarios. From this
discussion, we can also see the challenge in using broadband beamforming in reverberant environment.
For example, if the impulse responses from the SOI to every element can be determined accurately, then
for high reverberations the channels are long and thus (N + L −1) > (PL) and there is no degrees of
freedom to do beamforming, only an inverse ﬁlter of the propagation response.
3.13.5.3 LCMV in frequency domain
The frequency domain formulation of the LCMV broadband beamformer follows directly from the
narrow-band formulation. The input data xp(k) is transformed to a time-frequency representation
X p(ω,l). Assuming enough resolution in the time-frequency representation, X p(ω,l) can be ex-
pressed as
X p(ω,l) =
M−1

m=0
Sm(ω,l)Hm,p(ω) + Np(ω),
p = 0, 1, . . . , P −1.
(13.105)
Based on this assumption, the beamformer is formed in each frequency band
Y(ω,l) =
P−1

p=0
W H
p (ω)X p(ω,l) = WH(ω)X(ω,l),
(13.106)
where W(ω) is the beamformer response for frequency component ω, and X(ω,l) is the input data
vector. The LCMV objective is to minimize the following expression:
SYY (ω) = WH(ω)SXX(ω)W(ω)
(13.107)

3.13.5 Optimum and Adaptive Broadband Beamforming
587
for each frequency component. The matrix, SXX(ω) is deﬁned as
SXX(ω) =
⎛
⎜⎜⎜⎝
SX0X0(ω)
SX0X1(ω)
· · ·
SX1X P−1(ω)
SX1X0(ω)
SX1X1(ω)
· · ·
SX1X P−1(ω)
...
...
...
...
SX P−1X0(ω) SX P−1X1(ω) · · · SX P−1X P−1(ω)
⎞
⎟⎟⎟⎠.
(13.108)
The constraint is formed for each frequency component such that the SOI is not distorted. To achieve
this, the constraint is given by
HH
0 (ω)W(ω) = G(ω).
(13.109)
The frequency domain LCMV problem can now be stated as follows:
min
W
WH(ω)SXX(ω)W(ω)
(13.110)
subject to HH
0 (ω)W(ω) = G(ω),
where the solution to this problem can be found analytically
W(ω) =
S−1
xx (ω)H0(ω)
G(ω)HH
0 (ω)S−1
xx (ω)H0(ω)
.
(13.111)
In the simplest scenario, it is assumed that the beamformer is aligned to the SOI and the environment
is homogeneous and free ﬁeld. In this case the constraint vector is given by H0(ω) = [1, 1, . . . , 1]T and it
will be frequency independent. That assumes perfect pre-steering. Thus to make this type of processing
more robust, several constraints around the direction where the SOI is located are included; these
constraints can either be derivative constraints or several point constraints. Also, quadratic constraints
that model uncertainty in the model have been suggested.
3.13.5.4 Generalized Sidelobe Canceler
The LCMV problem can be converted to an unconstrained problem. This unconstrained beamformer
is usually called a Generalized Sidelobe Canceler (GSC). In its simplest form, it can be viewed as a
constrained beamformer that has been converted to a non-constrained design by means of a blocking
matrix. Thus the problem has been separated into two parts: one is a ﬁxed beamforming part that
determines the response for the desired source, and the other part blocks the desired source from
entering into the canceler. The relationship between LCMV and GSC follows from straightforward
algebra. It relies on the fact that the weights of the LCMV beamformer can be decomposed into two
parts, one part fulﬁlling the constraint and another part that can be minimized.
The LCMV constraint matrix H is of size (N + L −1) × (PL) and should have a rank given by the
minimum of (N + L −1) and (PL). Assume that the rank is (N + L −1), then a new matrix can be
constructed
U = [HT |Ha]
(13.112)

588
CHAPTER 13 Broadband Beamforming and Optimization
which is full rank and thus is invertible, and HHa = 0. This means that Ha is the orthogonal complement
to HT . Accordingly, Ha can be found from the following relationship:
Ha = (I −HT (HHT )−1H).
(13.113)
Now assume the following:
w = Uq,
(13.114)
where q = [v−wa]T . Using this relationship with (13.112) yields
w = HT v −Hawa
(13.115)
and furthermore w fulﬁlls the LCMV constraint, thus
Hw = HHTv −HHawa = HHTv = g.
(13.116)
It follows that
v = (HHT )−1g.
(13.117)
Inserting (13.117) in (13.115), the ﬁnal decomposition is found as
w = HT(HHT)−1g −Hawa = wq −Hawa.
(13.118)
This is the GSC decomposition where wq are the optimum beamformer weights depending only on
the constraint, and wa are the weights that are free to minimize the cost function. Accordingly, the GSC
consists of three parts (see Figure 13.14): one upper ﬁxed beamformer wq, a blocking matrix Ha, and
an interference canceler wa.
FIGURE 13.14
Generalized Sidelobe Canceler structure.

3.13.5 Optimum and Adaptive Broadband Beamforming
589
It operates in the following way. The input signal vector x(k) will be ﬁltered by the upper beamformer
wq, which forms a beam towards the SOI, creating an output
yd(k) = wT
q x(k).
(13.119)
This output yd(k) has been ﬁltered towards the SOI and in its simplest form, will correspond to a
summing beamformer. In its general form, it will consist of stacked FIR ﬁlters which form a broadband
optimized beamformer. The blocking matrix Ha forms beams that are orthogonal to the desired signal.
Thus, the input to the interference canceler should contain only undesired signals,
z(k) = HT
a x(k),
(13.120)
where z(k) is a vector of length (P −1)L −N + 1. The weights wa are obtained by minimizing the
following expression:
min
wa E
yd(k) −wT
a z(k)

2
.
(13.121)
The original optimum beamformer problem has now been turned into an interference cancelation
problem. One interpretation of the signal blocking matrix is that it consists of PL −N −L + 1 lower
beamformers hk implementing the signal blocking matrix. In theory, this formulation will provide a
blocking of the SOI. In practice this is not feasible, since it requires very accurate knowledge of the
Green function from the desired source to the input of the lower beamformers. However, based on
this unconstrained formulation a number of practical ways to approximate this formulation have been
suggested. One such way is to view the problem as a ﬁlter design problem where the desired signal
should be suppressed below a certain level. Where this level is determined by how much of the desired
signal leaks into the cancelation structure.
As an alternative to this ﬁxed constrained approach, one can form various adaptive schemes to obtain
the blocking matrix. More details on these will be found in the further reading section.
In summary, the broadband GSC provides a very good suppression of interfering signals but the
signal distortion is difﬁcult to control and also the calibration for a combined array is difﬁcult. This is
because the design model and real life scenarios need to match very accurately, which is difﬁcult to
achieve in practical scenarios.
3.13.5.5 Generalized Sidelobe Canceler in frequency domain
Similarly to the LCMV, the GSC can be directly transferred to the frequency domain. The derivations
for the time domain are still valid and the weight vector can be reformulated as follows:
W(ω) = H0(ω)

HH
0 (ω)H0(ω)
−1
G(ω) −Ha(ω)Wa(ω)
= Wq(ω) −Ha(ω)Wa(ω).
(13.122)
The blocking matrix is given by Ha(ω) = (I−H0(ω)

HH
0 (ω)H0(ω)
	−1 HH
0 (ω)). Since the response
vector of the array for the SOI corresponds to H0(ω), it follows that the response from the SOI to the
output is given by G(ω). In this case, the spectral density of the error
ϵ(ω) = Yd(ω) −Wa(ω)HZ(ω)
(13.123)

590
CHAPTER 13 Broadband Beamforming and Optimization
should be minimized with respect to Wa(ω). The critical part in order to avoid SOI distortion is to have
no SOI signal leaking into Z(ω). In practice, the most difﬁcult situation to use the GSC is for high SNR
scenario, when small leakage of SOI signal is able to cancel parts of the SOI signal. To combat this,
robust constraints are necessary which are either similar to those suggested in the time domain case or
norm constraints on the weights. By applying norm constraints on the weights, there will be a cost on
large weights and the optimum ﬁlter will be more robust.
3.13.5.6 Wiener ﬁlter
The Wiener ﬁlter can also be used as an optimum broadband beamformer. For a broadband FIR beam-
former in time domain, the objective can be formulated as
wopt = arg

min
w
E[(s0(k) −y(k))2]

,
(13.124)
where the output y(k) from the beamformer is given in (13.97), and the SOI observation s0(k) is the
source signal. Thus, the theory states that the source signal s0(k) needs to be available. In practice it is
desirable to use only sensor observations instead. Since the source signal is usually not accessible, an
estimate is used instead. As an alternative, it is sometimes possible to use a training signal or integrate
a model.
The optimal Wiener weights are given by
wopt = [Rxx]−1rxs,
(13.125)
where the cross correlation vector, rxs, is deﬁned as
rxs0 = [rx1s0
rx2s0
· · ·
rxPs0]
(13.126)
with
rxps = [rx ps0(0) rx ps0(1)
· · ·
rx ps0(L −1)],
p = 0, 1, . . . , P −1,
(13.127)
where each element is deﬁned as
rx ps0(l) = E[x p(k −l)s0(k)],
p = 0, 1, . . . , P −1,
l = 0, 1, . . . , L −1.
(13.128)
The matrix Rxx is deﬁned as in (13.103). The weights w are arranged in the same way as in (13.97).
It is thus straightforward to formulate the problem but the difﬁculty comes down to ensuring that the
matrix Rxx is invertible and that the reference signal s0(k) is available. In communication systems, the
reference can usually be made available by training. For speech applications, it is common to use either
a Voice Activity Detector (VAD) to detect when the SOI is active. As an alternative, a pre-calibration
can be used. In radar and sonar applications, the SOI is not available but sometimes partial information
can be available. Note that the number of ﬁlter coefﬁcients becomes large if the frequency bandwidth
of the beamformer is wide.

3.13.5 Optimum and Adaptive Broadband Beamforming
591
3.13.5.7 Frequency domain Wiener ﬁlter
In the frequency domain, the objective can be formulated similarly as for the time domain. For each
frequency, the objective will be
Wopt(ω) = arg
&
min
W(ω) Sϵϵ(ω)
'
,
(13.129)
where the error signal Sϵϵ(ω) is the Fourier transform of rϵϵ(0) = E[(s0(k) −y(k))2]. The optimal
weights, which minimize the expectational square difference in (13.129) between the output and the
reference signal for each frequency, is found by
Wopt(ω) = [SXX(ω)]−1SXS0(ω),
(13.130)
where the spectral density matrix SXX(ω) is deﬁned in (13.108). The cross correlation vector rxs(ω) is
deﬁned as
SXS0(ω) = [SX0S0(ω)
SX1S0(ω)
· · ·
SX P−1S0(ω)]T
(13.131)
with each element deﬁned as
SX pS0(ω) = F(E[x p(k −l)s0(k)]),
(13.132)
where F means Fourier transform
p = 0, 1, . . . , P −1.
The weights Wopt(ω) are deﬁned as complex valued vectors of dimension P. This solution gives the
non-causal Wiener ﬁlter which is usually approximated by using discrete FFT. This type of ﬁlter has
the same limitations as the time domain solution. However, it is much more efﬁcient to implement since
the size of the problem is determined by P and not P · L. Also in practical scenarios, various ways have
been suggested to estimate the SOI. For speech processing, it usually involves pre-calibration or VAD,
whereas in communication systems, training sequences are included.
3.13.5.8 Optimal near-ﬁeld signal-to-noise plus interference beamformer (SNIB)
The desired criteria for many applications such as radar and sonar is to maximize the output signal-to-
noise plus interference power ratio (SNIR). This criteria is deﬁned as
Q =
average signal output power
average noise-plus-interference output power
(13.133)
and the beamformer which maximizes the ratio Q is the optimal signal-to-noise plus interference beam-
former (SNIB). We need to express the mean signal output power as a function of the ﬁlter weights in
the beamformer, and ﬁnd the optimal weights maximizing Q.
3.13.5.8.1
Time domain formulation
The power of the beamformer output, when only the SOI s0(n) is active, is given by the zero lag of the
autocorrelation function, rys ys(0), as follows:
rys ys(0) = wHRssw,
(13.134)

592
CHAPTER 13 Broadband Beamforming and Optimization
where Rss is deﬁned as
Rss =
⎛
⎜⎜⎜⎝
Rs0,0s0,0
Rs0,0s0,1
· · ·
Rs0,0s0,P−1
Rs0,1s0,0
Rs0,1s0,1
· · ·
Rs0,1s0,P−1
...
...
...
...
Rs0,P−1s0,0
Rs0,P−1s0,1
· · · Rs0,P−1s0,P−1
⎞
⎟⎟⎟⎠
(13.135)
with submatrices
Rs0,ms0,n =
⎛
⎜⎜⎜⎝
rs0,ms0,n(0)
rs0,ms0,n(1)
· · · rs0,ms0,n(L −1)
rs0,ms0,n(1)
rs0,ms0,n(0)
· · · rs0,ms0,n(L −2)
...
...
...
...
rs0,ms0,n(L −1) r∗
s0,ms0,n(L −2) · · ·
rs0,ms0,n(0)
⎞
⎟⎟⎟⎠
(13.136)
and
rs0,ms0,n(l) = E[s0,m(k −l)s0,n(k)],
l = 0, 1, . . . , L −1,
(13.137)
where s0,m(k) is the received signal at sensor element m from the SOI s0(k). The ﬁlters w are arranged
according to
w =

wT
1 wT
2 · · · wT
I
T
,
(13.138)
where
wp = [wi(0) wi(1)
· · ·
wi(L −1)]T ,
p = 0, 1, . . . , P −1.
(13.139)
In the same way, one may write an expression for the noise-plus-interference power, ryn yn(0), when
all the surrounding noise sources are active but the source signal of interest is inactive, as
ryn yn(0) = wT Rnnw.
(13.140)
Now, the optimal weights are found by maximizing a ratio of two quadratic forms according to
wopt = arg
&
max
w
wT Rssw
wT Rnnw
'
.
(13.141)
The solution to this problem is given by the eigenvector corresponding to the maximum eigenvalue of
the generalized eigenvalue problem of Rss and Rnn.
It is important that one can estimate the signal correlation matrix separately from the noise correlation
matrix. This is not possible, so in practice only Rxx = Rnn + Rss is available. In many cases (for radar
and sonar), the noise correlation matrix can be estimated. Then an estimate of Rss can be obtained as
(Rss = Rxx −Rnn. This will work as long as the SNR is reasonably good and the noise can be estimated
when there is no signal. This will require a VAD for speech applications or a communication protocol for
communication applications. In active sonar and radar applications, it is possible to do this estimation in
periods when the receiver acts in a passive mode. This time domain formulation is usually not well suited
for broadband problems since optimization only consider one eigenvalue the corresponding eigenvector
does not represent the signal space of the SOI as a result the signal output will be very distorted. The
frequency domain formulation is more useful since Rss represented in frequency domain has low rank.

3.13.5 Optimum and Adaptive Broadband Beamforming
593
3.13.5.8.2
Frequency domain formulation
The time domain problem has high complexity for broadband scenarios when the number of sensors is
high and the bandwidth covers a wide range, such that the length of the FIR ﬁlters is large. To lower
the overall computational complexity, the optimal signal-to-noise plus interference beamformer can be
formulated for each frequency individually. The two problems will not be equivalent in general but
that fact is usually ignored to be able to provide an efﬁcient solution. The weights that maximize the
quadratic ratios for all frequencies represent the optimal beamformer that maximizes the total output
power ratio. This is true provided that the different frequency bands are independent and the full-band
signal can be created perfectly. The time domain and frequency domain criteria will not be equivalent
since there is no direct relationship between the two solutions. The SNIB optimization is an eigenvalue
problem; in one case it is solved frequency by frequency, and in the other case it is solved for the overall
time domain problem.
Now consider the SNIB problem for frequency ω. The quadratic ratio between the output SOI power
spectral density and the output noise-plus-interference power density is given by
Wopt(ω) = arg

max
W(ω)
W(ω)HSs0s0(ω)W(ω)
W(ω)HSnn(ω)W(ω)

(13.142)
and the spectral density matrix for the SOI is deﬁned as
Ss0s0(ω) =
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
rs0,0s0,0(ω)
Ss0,0s0,1(ω)
· · ·
Ss0,0s0,P−2(ω)
Ss0,0s0,P−1(ω)
Ss0,1s0,0(ω)
Ss0,1s0,1(ω)
...
· · ·
Ss0,1s0,P−1(ω)
...
...
...
...
...
Ss0,P−2s0,0(ω)
Ss0,P−2s0,1(ω)
...
Ss0,P−2s0,P−2(ω)
Ss0,P−2s0,P−1(ω)
Ss0,P−1s0,0(ω)
Ss0,P−1s0,1(ω) · · ·
Ss0,P−1s0,P−1(ω)
Ss0,P−1s0,P−1(ω)
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
,
(13.143)
where
Ss0,is0, j (ω) = F(E[s0,i(k −l)s0, j(k)]).
(13.144)
In a similar way, one may deﬁne the noise-plus-interference correlation spectral density matrix, Snn(ω),
when only the disturbing sources are active.
The frequency domain weights W(ω) for frequency ω are deﬁned as complex valued vectors of
dimension P. The problem is solved as a generalized eigenvalue problem for each frequency. However,
the weights have been calculated for each frequency and thus an independent scaling may occur for
each frequency. Therefore, when the beamformer weights are used to process data using STFT for
instance, large SOI distortion may occur. To resolve this, the weights are converted to time domain and
a continuity constraint is applied such that the equivalent time domain weights are smooth. But note
that the frequency domain and time domain problem are not equivalent. In the time domain formulation
the SOI is severely distorted even if one achieve a higher SNIR improvement.
3.13.5.9 Examples for optimal beamformers
As a comparison between the various methods and provide an idea on how the performance varies a few
design examples are presented. The design examples are for the GSC, Wiener and SNR optimization

594
CHAPTER 13 Broadband Beamforming and Optimization
Table 13.5 Common Design Parameters
Parameters
Values
Number of microphones, K
5
Spectral passband, p
[300, 7000] Hz
Sampling frequency, fs
16,000 Hz
Speed of sound, c
343 m s−1
Interfering jammer signal
θ = 30◦
with the formulation in time and frequency domain. A broadside linear array is used with inter-element
spacing of 5 cm. The design parameters are as speciﬁed in Table 13.5. The target signal and the jammer
signal has the same spectral shape and the same power. The target is impinging from 0◦and the jammer
from 30◦. The noise is additive diffuse noise independent between the elements with an SNR of 30 dB.
As can be seen from the Figure 13.15 for this rather simple anechoic case the Wiener solution and GSC
provide more or less the same Signal to Interference Noise Ratio, SINR. For this very broadband case
a high number of FIR taps are needed to reach the frequency domain bound. SINR optimization gives
better results in the SINR measure, in frequency domain the results does not give as high values. But this
does not provide a full picture of the problem since the SINR optimization does not take into account
the distortion of the source signal. Since, in the time domain design only the generalized eigenvector
corresponding to largest generalized eigenvalue is considered means that much of the original source
might have been suppressed as well. In the example the rank of the matrix Rss is much larger than one
in the time domain problem but the spectral density matrix Ss0s0(ω) has rank one in frequency domain
thus in the frequency domain more of the original source is maintained and also more of the diffuse
noise giving less improvement in the overall SNIR. In time domain optimization less of the source is
maintained and more of the noise is suppressed.
3.13.6 Conclusion
Thisstudyhasprovidedinsightsintothedesignandprocessingofbroadbandbeamformers,withthemain
applications being microphone arrays, sonar, radar and broadband communications. Currently there has
been signiﬁcant interest for broadband beamformer design from the radio physics community, particu-
larly within the Square Kilometer Array (SKA) project. The two mainstream approaches for broadband
beamforming are optimal beamforming and optimum beamforming. In the former, optimization tools
are used to design weights which are data independent, and in the latter, the statistics of the input data are
included in the optimization design. A natural extension of the optimum beamforming techniques is to
apply adaptive algorithms to ﬁnd the weights. In the optimization, it is important to include robustness
in the design, and this is quintessential in broadband beamforming since the element spacing is chosen
to avoid spatial aliasing. Spatial aliasing is connected to the upper frequency considered in the design.
Since broadband beamforming covers one or several octaves, the resolution of the beam will be limited
in the lowest frequency band. Thus for a design with constant beamwidth, the low frequency design

3.13.6 Conclusion
595
20
40
60
80
100 120 140 160 180 200
10
15
20
25
30
35
40
Angle of Jammer = 30oWiener Filte
r
FIR Length
SINR [dB]
Frequency domain
FIR filter
20
40
60
80
100 120 140 160 180 200
10
15
20
25
30
35
40
Angle of Jammer = 30o       GSC Filter
FIR Length
SINR [dB]
 
 
Frequency domain
FIR filter
20
40
60
80
100 120 140 160
180 200
10
15
20
25
30
35
40
Angle of Jammer = 30o     SINR Filter
FIR Length
SINR [dB]
 
 
Frequency domain
FIR filter
FIGURE 13.15
Signal to Interference and Noise Ratio for varying length and compared to frequency domain solution for
(a) Wiener ﬁlter, (b) GSC, and (c) SINR optimization.

596
CHAPTER 13 Broadband Beamforming and Optimization
is highly demanding and the design without robustness constraints becomes very sensitive. Also for
optimum designs to constrain the solution over a large range of frequencies is almost futile.
Relevant Theory: Signal Processing Theory and Array Signal Processing
See Vol. 1, Chapter 4 Random Signals and Stochastic Processes
See Vol. 1, Chapter 8 Modern Transform Design for Practical Audio/Image/Video Coding Applications
See Vol. 1, Chapter 12 Adaptive Filters
See this volume, Chapter 18 Source Localization and Tracking
3.13.6.1 Further reading
For further reading in the area of modeling and wave propagation we suggest the following books
[4,5,9]. Those books provide a detailed theory and understanding of propagation models and acoustics.
A very detailed modeling of underwater acoustics using so called matched ﬁeld processing has also
been suggested in [12,13].
For broadband beamformer design, the literature is extensive; some suggestions are [1,14–19]. The
broadband beamformer problem has been studied in nearﬁeld and farﬁeld and using various optimization
methods [7,18]; in this chapter, we have discussed a general formulation.
Design methods that combine steering and beamformer design have been suggested for element
space processing [20,21] and of course for wave domain processing, see [8,10,11,19] and many other
references.
Optimum beamforming methods are discussed in some books [2] and overview papers [3,22]. For
some discussion on practical aspects of the optimum beamforming problem, see [23–26].
The important topic of robust and adaptive beamforming has been studied in many research works;
some relevant ones are [6,22,27]. For a current reference we would like to refer to [6].
The pre-steering and beam steering is a vital part of the beamformer system, even if we have left
out details in this chapter. That topic needs methods for tracking and localization algorithms. Here are
some suggested adequate reading for these areas: Ref. [28] is the classic paper on localization using
generalized coherence function; this work has been extended to the so-called phase transform (PHAT),
which is more or less a de facto standard for microphone arrays [29]. For tracking, particle ﬁlter based
methods are usually used [30–32].
For broadband beamformer applications with microphone arrays, we would suggest a number of
books [29,33] and some well known articles [34,35].
Radar beamforming applications can be found in these articles [36–38] and in these books [39,40].
Broadband beamforming for sonar application can be found in the following articles [41–43], and they
are also discussed in these books [1,4,44,45].
References
[1] D.H. Johnson, D.E. Dudgeon, Array Signal Processing, Prentice Hall, 1993, ISBN: 0130485136.
[2] H.L. Van Trees, Knovel (ﬁrme), Optimum Array Processing, Wiley Online Library, 2002, ISBN: 0471463833.
[3] B.D. Van Veen, K.M. Buckley, Beamforming: a versatile approach to spatial ﬁltering, IEEE Acoust. Speech
Signal Process. Mag. 5 (1988) 4–24.

References
597
[4] J. Lawrence, Ziomek, Acoustic Field Theory and Space-Time Signal Processing, CRC Press, Boca Raton,
Florida, 1995.
[5] E.G. Williams, Fourier Acoustics: Sound Radiation and Nearﬁeld Acoustical Holography, Academic Press,
1999.
[6] S.A. Vorobyov, Adaptive and Robust Beamforming, Academic Press Library in Statistical and Array Signal
Processing, Elsevier, in press.
[7] Z. Feng, C. Yiu, S. Nordholm, A two-stages method for the design of near ﬁeld broadband beamformer, IEEE
Trans. Signal Process. 1 (2011) 99, doi:10.1109/TSP.2011.2133490, ISSN: 1053-587X.
[8] S. Yan, H. Sun, U.P. Svensson, X. Ma, J.M. Hovem, Optimal modal beamforming for spherical microphone
arrays, IEEE Trans. Audio Speech Lang. Process. 19 (2) (2011) 361–371.
[9] P.M.C. Morse, K.U. Ingard, Theoretical Acoustics, Princeton University Press, 1968.
[10] J. Meyer, G. Elko, A highly scalable spherical microphone array based on an orthonormal decomposition of
the soundﬁeld, in: IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)
2002, vol. 2, IEEE, 2002, pp. 1781–1784.
[11] B. Rafaely, Analysis and design of spherical microphone arrays, IEEE Trans. Speech Audio Process. 13 (1)
(2005) 135–143.
[12] A.B. Baggeroer, W.A. Kuperman, H. Schmidt, Matched ﬁeld processing: source localization in correlated
noise as an optimum parameter estimation problem, J. Acoust. Soc. Am. 83 (1988) 571.
[13] A. Tolstoy, Matched Field Processing for Underwater Acoustics, vol. 52, World Scientiﬁc, Singapore, 1993.
[14] Huawei Chen, Wee Ser, Design of robust broadband beamformers with passband shaping characteristics
using tikhonov regularization, IEEE Trans. Audio Speech Lang. Process. 17 (4) (2009) 665–681, doi:10.1109/
TASL.2008.2012318, ISSN: 1558-7916.
[15] S. Doclo, M. Moonen, Design of broadband beamformers robust against gain and phase errors in the micro-
phone array characteristics, IEEE Trans. Signal Process. 51 (10) (2003) 2511–2526, ISSN: 1053-587X.
[16] R.A. Kennedy, T.D. Abhayapala, D.B. Ward, Broadband nearﬁeld beamforming using a radial beampattern
transformation, IEEE Trans. Signal Process. 46 (8) (1998) 2147–2156, ISSN: 1053-587X.
[17] S. Nordebo, I. Claesson, S. Nordholm, Weighted Chebyshev approximation for the design of broadband
beamformers using quadratic programming, IEEE Signal Process. Lett. 1 (7) (1994) 103–105.
[18] SE Nordholm, V. Rehbock, KL Tee, S. Nordebo, Chebyshev optimization for the design of broadband beam-
formers in the near ﬁeld, IEEE Trans. Circ. Syst. II: Analog Digital Signal Process. 45(1) (1998) 141–143,
ISSN: 1057-7130.
[19] D.B. Ward, R.A. Kennedy, RC Williamson, Theory and design of broadband sensor arrays with frequency
invariant far-eld beam patterns, J. Acoust. Soc. Am. 97 (2) (1995) 1023–1034.
[20] C.C. Lai, S. Nordholm, Y.H. Leung, Design of robust steerable broadband beamformers with spiral arrays
and the farrow ﬁlter structure, in: Proceeding of the International Workshop Acoustic Echo Noise, Control,
August 2010.
[21] L.C. Parra, Steerable frequency-invariant beamforming for arbitrary arrays, J. Acoust. Soc. Am. 119 (2006)
3839.
[22] H. Krim, M. Viberg, Two decades of array signal processing research: the parametric approach, IEEE Signal
Process. Mag. 13 (4) (1996) 67–94.
[23] I. Claesson, S. Nordholm, A spatial ﬁltering approach to robust adaptive beamforming, IEEE Trans. Antennas
Propag. 40 (9) (1992) 1093–1096.
[24] S. Doclo, M. Moonen, GSVD-based optimal ﬁltering for single and multimicrophone speech enhancement,
IEEE Trans. Acoust. Speech Signal Process. 50 (9) (2002) 2230–2244.
[25] N. Grbi´c, S. Nordholm, Soft constrained subband beamforming for handsfree speech enhancement, IEEE Int.
Conf. Acoust. Speech Signal Process. 1 (2002) 885–888.

598
CHAPTER 13 Broadband Beamforming and Optimization
[26] S.A. Vorobyov, A.B. Gershman, Z.Q. Luo, Robust adaptive beamforming using worst-case performance
optimization: a solution to the signal mismatch problem, IEEE Trans. Signal Process. 51 (2) (2003) 313–324,
ISSN: 1053-587X.
[27] J.E. Hudson, Adaptive Array Principles, vol. 11, Institute of Engineering and Technology, 1981.
[28] G.C. Carter, Time delay estimation for passive sonar signal processing, IEEE Trans. Acoust. Speech Signal
Process. 29 (3) (1981) 463–470.
[29] M.Brandstein,D.Ward,MicrophoneArrays:SignalProcessingTechniquesandApplications,SpringerVerlag,
2001.
[30] Z. Khan, T. Balch, F. Dellaert, Mcmc-based particle ﬁltering for tracking a variable number of interacting
targets, IEEE Trans. Pattern Anal. Mach. Intell. 27 (11) (2005) 1805–1819.
[31] E. Lehmann, A. Johansson, Particle ﬁlter with integrated voice activity detection for acoustic source tracking,
EURASIP J. Adv. Signal Process. (2007) Article ID 50870, 11 pp.
[32] D.B. Ward, E.A. Lehmann, R.C. Williamson, Particle ﬁltering algorithms for tracking an acoustic source in a
reverberant environment, IEEE Trans. Speech Audio Process. 11 (6) (2003) 826–836.
[33] J. Benesty, J. Chen, Y. Huang, Microphone Array Signal Processing, vol. 1, Springer Verlag, 2008.
[34] J.L. Flanagan, J.D. Johnston, R. Zahn, G.W. Elko, Computer-steered microphone arrays for sound transduction
in large rooms, J. Acoust. Soc. Am. 78 (1985) 1508.
[35] Y. Kaneda, J. Ohga, Adaptive microphone-array system for noise reduction, IEEE Trans. Acoust. Speech
Signal Process. 34 (6) (1986) 1391–1400.
[36] J.R. Guerci, E.J. Baranoski, Knowledge-aided adaptive radar at DARPA: an overview, IEEE Signal Process.
Mag. 23 (1) (2006) 41–50, ISSN: 1053-5888.
[37] A. Haimovich, The eigencanceler: adaptive radar by eigenanalysis methods, IEEE Trans. Aerosp. Electron.
Syst. 32 (2) (1996) 532–542.
[38] J. Ward, Space-time adaptive processing for airborne radar, in: IEE Colloquium on Space-Time Adaptive
Processing (Ref. No. 1998/241), IET, 1998, pp. 2/1–2/6.
[39] J.C. Curlander, R.N. McDonough, Synthetic Aperture Radar: Systems and Signal Processing, vol. 199, Wiley,
New York, 1991.
[40] M.I. Skolnik et al., Radar Handbook, vol. 2, McGraw-Hill, New York, 1990.
[41] H. Cox, R. Zeskind, M. Owen, Robust adaptive beamforming, IEEE Trans. Acoust. Speech Signal Process.
35 (10) (1987) 1365–1376.
[42] A. Elfes, Sonar-based real-world mapping and navigation, IEEE J. Robot. Autom. 3 (3) (1987) 249–265,
ISSN: 0882-4967.
[43] W.C. Knight, R.G. Pridham, S.M. Kay, Digital signal processing for sonar, Proc. IEEE 69 (11) (1981)
1451–1506.
[44] R.O. Nielsen, Sonar Signal Processing, Artech House, Inc., 1991.
[45] N.L. Owsley, Sonar Array Processing, Prentice-Hall, Englewood Cliffs, NJ, 1985.

14
CHAPTER
DOA Estimation Methods
and Algorithms
Pei-Jung Chung*, Mats Viberg†, and Jia Yu*
*The University of Edinburgh, UK
†Chalmers University of Technology, Sweden
3.14.1 Background
The problem of retrieving information conveyed in propagating waves occurs in a wide range of applica-
tions including radar, sonar, wireless communications, geophysics and biomedical engineering. Meth-
ods for processing data measured by sensor arrays have attracted lots of attention of many researchers
over last three decades. Recent advances in computational technology have enabled implementation of
sophisticated algorithms in practical systems.
Early space-time processing techniques view direction of arrival (DOA) as a spatial spectrum. The
Fourier transform based conventional beamformer is subject to resolution limitation due to ﬁnite array
aperture. Similar to its temporal counterpart, the spatial periodogram can not beneﬁt from increasing sig-
nal to noise ratio (SNR) or number of samples. Better estimates can be achieved by applying windowing
function to reduce spectral leakage effects. The minimum variance distortionless (MVDR) beamformer
[1] overcomes the resolution limitation of Fourier based techniques by formulating the spectrum esti-
mation as a constrained optimization problem. Also, its performance can be enhanced by high SNR. The
multiple signal classiﬁcation (MUSIC) algorithm [2] is representative of subspace methods based on
eigenstructure of the spatial correlation matrix. In addition to high resolution, MUSIC takes advantage
of SNR, number of sensors and number of samples. It improves estimation accuracy with respect to all
dimensions and is statistically efﬁcient. However, in the presence of correlated source signals, subspace
methods degrade dramatically as the signal subspace suffers from rank deﬁciency. On the other hand,
parametric methods such as the maximum likelihood (ML) approach exploit the data model fully, leading
to statistically efﬁcient estimators. More importantly, they remain robust in critical scenarios involv-
ing signal coherence, closely located signals and low SNRs. The optimal properties come along with
increased computational complexity. Hence, efﬁcient implementation is crucial for parametric methods.
The importance of array processing methods has been reﬂected by the huge amount of publications.
Among these contributions, several review articles [3–5] have proven to be an excellent guide for ﬁrst
exposure to this research ﬁeld, while the textbooks [6,7] have been valuable references for in-depth
learning. Thanks to the advances in both theoretical methods and computational powers over the last
decade,arrayprocessingmethodshavebeenre-examinedfromvariousaspectstoaddressnewchallenges
arising in these new application areas such as wireless communications. The purpose of this article is to
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00014-X
© 2014 Elsevier Ltd. All rights reserved.
599

600
CHAPTER 14 DOA Estimation Methods and Algorithms
provide interested readers an overview of traditional array processing methods and recent development
in the ﬁeld.
The organization of this article is as follows. The data model based on plane wave propagation is intro-
duced in Section 3.14.2. Important quantities including array response vector and second order statis-
tics are derived therein. Standard direction ﬁnding algorithms are covered in Sections 3.14.3–3.14.5.
Section 3.14.3 is devoted to spectral analysis based methods: conventional beamforming, MVDR beam-
forming techniques. The sparse data representation based approach is presented in the same section.
The subspace methods and related issues are treated in Section 3.14.4. In the subsequent Section 3.14.5,
the parametric approach is illustrated. Important algorithms based on the maximum likelihood principle
and subspace ﬁtting are illustrated. The implementation of the aforementioned estimators are also dis-
cussed. While the algorithms discussed in Sections 3.14.3–3.14.5 deal with narrow band data, we treat
the broadband case separately in Section 3.14.6. The number of signals is a fundamental assumption
in most array processing methods. The problem of signal detection is addressed in Section 3.14.7. In
Section 3.14.8, we treat scenarios with non-standard assumptions by highlighting relevant techniques
and references. A brief discussion is given in Section 3.14.9.
3.14.2 Data model
Propagating waves carry energy radiated by sources to sensors. To extract information conveyed in the
propagating waves, such as source location or propagation direction, one needs a proper description
of waveﬁelds. In Section 3.14.2.1, we start with a brief discussion on the physics of wave propagation
and formulate the transmission between signal sources and receiving sensors as a linear time invariant
system. Then a frequency domain data model for far-ﬁeld sources is developed in Section 3.14.2.2. The
fundamental issue on identiﬁability is discussed in Section 3.14.2.3.
3.14.2.1 Wave propagation
The physics of propagating waves is governed by the wave equation for medium of interest. The
homogeneous wave equation for a general scalar ﬁeld E(t, r) at time instant t and location r = [x y z]T
is given by
∂2E(t, r)
∂x2
+ ∂2E(t, r)
∂y2
+ ∂2E(t, r)
∂z2
= 1
c2
∂2E(t, r)
∂t2
,
(14.1)
where the parameter c represents the propagation velocity. E(t, r) can be an electric density ﬁeld in
electromagnetics or acoustic pressure in acoustic waves.
A solution of special interest to (14.1) takes a complex exponential form:
E(t, r) = Aexp[ j(ωt −kT r)],
(14.2)
where ω = 2π f is the temporal frequency and k = [kx ky kz]T is the wave number vector. Here k is
considered as the spatial frequency of this mono-chromatic wave. Inserting (14.2) into (14.1), one can
readily see how temporal frequency ω and the spatial frequency k are related:
∥k∥2 = k2
x + k2
y + k2
z = ω2
c2 .
(14.3)

3.14.2 Data Model
601
FIGURE 14.1
Plane wave propagation and coordinate system.
Replacing the propagation velocity with c = f λ in (14.3) where λ is the wavelength, the magnitude of
the wave number vector is given by |k| = 2π/λ.
The elementary wave (14.2) also represents a propagating wave
E(t −ξ T r) = Aexp[ jω(t −ξ T r)],
(14.4)
where ξ = k/ω is termed slowness vector. It points in the same direction as k and has the magnitude
|ξ| = 1/c, which is the inverse of the propagation velocity. From (14.4), it can be readily seen that the
direction of propagation is given by ur = ξ/|ξ|. Let the origin of the coordinate system be close to the
sensor array. The slowness vector ξ can then be expressed as
ξ = −1
c
⎡
⎣
sin φ cos θ
sin φ sin θ
cos φ
⎤
⎦,
(14.5)
where φ and θ denote the elevation and azimuth angles, respectively. Both parameters characterize the
direction of propagation and are referred to as direction of arrival (DOA) (see Figure 14.1).
Far-ﬁeld assumption: For far-ﬁeld sources, the propagation distance to a sensor array is much larger
than the aperture of the array, the DOA parameter is approximately the same to all sensors. According
to (14.2), the wave front of constant phase at time instant t is a plane perpendicular to the propagating
direction given by k · r = constant. The term, plane wave assumption is alternatively used in the
literature.
3.14.2.2 Frequency domain description
In an ideal medium, the propagation between signal sources and a sensor array is considered as a linear
time-invariant system. Due to the applicability of the superposition principle and the Fourier transform,

602
CHAPTER 14 DOA Estimation Methods and Algorithms
the analysis of wave propagation is greatly simpliﬁed. In the following, we will develop a general
frequency domain model and discuss the narrow band case. The general model is useful for broadband
data that may be measured in underwater acoustical or geophysical experiments. The narrow band model
is preferred in applications where the signal bandwidth is much smaller than the carrier frequency, for
example, wireless communications and radar.
3.14.2.2.1
General model
Consider an array of sensors located at rm, m = 1, . . . , M receiving signals generated by P sources.
Without loss of generality, the ﬁrst sensor coincides with the origin of the coordinate system. Let
sp(t), p = 1, . . . , P denote the signals received by the ﬁrst sensor. The signal observed by the mth
sensor is the sum of a time-delayed version of original signals corrupted by noise nm(t):
xm(t) =
P

p=1
sp(t −τmp) + nm(t),
(14.6)
where τmp denotes the propagation time difference between the origin and the mth sensors. The time
difference is given by τmp = ξ p · rm where ξ p is associated with the pth wave. It is related to the DOA
parameter through k = ωξ and (14.5).
Applying the Fourier transform to the array output x(t) = [x1(t), . . . , xM(t)]T , the time delay
τmp translates to a phase shift e−jωτmp. In the presence of noise, the array output vector x(ω) can be
written as
x(ω) =
⎡
⎢⎣
x1(ω)
...
xM(ω)
⎤
⎥⎦=
P

p=1
a(φp, θp)sp(ω) + n(ω),
(14.7)
where the steering vector a(φp, θp) is the spatial signature for the pth incoming wave:
a(φp, θp) =
⎡
⎢⎣
e−jkp·r1
...
e−jkp·r M
⎤
⎥⎦.
(14.8)
Deﬁne the steering matrix as
A(ω, φ, θ) =
⎡
⎢⎢⎣
...
...
a(ω, φ1, θ1) · · · a(ω, φp, θp)
...
...
⎤
⎥⎥⎦.
(14.9)
A compact expression for (14.7) is as follows:
x(ω) = A(ω, φ, θ)s(ω) + n(ω),
(14.10)
where the signal vector s(ω) = [s1(ω), . . . , sp(ω)]T . According to the asymptotic theory of Fourier
transform, the frequency domain data is complex normally distributed regardless of the distribution in
the time domain. In addition, frequency bins are mutually independent. These properties form the basis
for broadband DOA estimation.

3.14.2 Data Model
603
3.14.2.2.2
Narrow band data
In many applications, the signal of interest is modulated by a carrier frequency ωc for transmission.
At the receive side, the radio frequency signals are demodulated to baseband for further processing.
Suppose the signal is band limited with the bandwidth Bs, and the maximal travel time between two
sensors of the array for a plane wave is 	T . The narrow band assumption is valid if Bs	T ≪1. Then
the complex baseband signal waveforms are approximately equal for all sensors. The general expression
(14.10) can be simpliﬁed to the narrow band model
x(t) = A(φ, θ)s(t) + n(t),
(14.11)
where the steering matrix A(φ, θ) is computed at the carrier frequency ωc and s(t) represents the
baseband signal waveform. The frequency dependence in (14.11) is omitted as relevant information is
centered at ωc.
As DOA estimation is typically based on sampled values of x(t) at time instants tn, n = 1, . . . , N,
we consider temporally discrete samples of (14.11) and replace tn with the index n. Then the snapshot
model is given by
x(n) = A(φ, θ)s(n) + n(n),
n = 1, . . . , N.
(14.12)
Many array processing methods exploit second order statistics of the data. Assume the signal and noise
are independent, stationary random processes with zero mean, correlation matrices Rs = E[s(n)s(n)H]
and Rn = E[n(n)n(n)H], respectively where (·)H denotes Hermitian transposition. Then the array
correlation matrix can be expressed as
Rx = E[x(n)x(n)H] = A(φ, θ)Rs A(φ, θ)H + Rn.
(14.13)
The noise process is often considered as spatially white, i.e., Rn = σ 2I, where σ 2 denotes the noise
level and I is an M × M matrix. This assumption is valid for sensors with sufﬁcient spacing. In
the presence of colored noise, the noise correlation matrix is no longer diagonal. In such case, the
data can be pre-whitened by multiplying (14.12) with the inverse square root of the noise correlation
matrix, R−1/2
n
.
The array correlation matrix is estimated from array observations x(n), n = 1, . . . , N by the sample
correlation matrix
	Rx = 1
N
N

n=1
x(n)x(n)H.
(14.14)
Under weak assumptions, the sample correlation matrix is a consistent estimator for the true correlation
matrix, i.e., 	Rx converges with probability one to Rx as the sample size increases. More details can be
found in the book [8].
In many applications, sensors are located on a plane, for example, the yz-plane. Setting the elevation
to be φ = 90◦in (14.5), one can easily see that the slowness vector is characterized by only the azimuthal
parameter, θ. In the two dimensional scenario, the uniform linear array (ULA) is one of the most popular
array conﬁgurations. Let the sensors of a ULA be placed along the y-axis, rm = [0, (m −1)	, 0]T
where 	 denotes or the inter-sensor distance. Then the phase shift term evaluated at φ = π/2 and θ
becomes k · rm = k(m −1)	 sin θ, leading to the steering vector
aULA(θ) = [1, e jk	 sin θ, . . . , e jk(M−1)	 sin θ]T .
(14.15)

604
CHAPTER 14 DOA Estimation Methods and Algorithms
If 	 is measured in wavelength, k	 = 2π
λ 	 = 2πd where d = 	/λ, aULA(θ) can be expressed as
aULA(θ) = [1, e j2πd sin θ, . . . , e j(M−1)2πd sin θ]T .
(14.16)
For a standard ULA, the inter-element spacing is half a wavelength, d = 1/2, the mth element in
(14.16) becomes e j(m−1)π sin θ.
For the 2D case, we shall use a shorter notation for the steering matrix, A(θ), in (14.11)–(14.13).
More speciﬁcally, the sampled array outputs and correlation matrix are expressed as
x(n) = A(θ)s(n) + n(n)
(14.17)
and
Rx = E[x(n)x(n)H] = A(θ)Rs A(θ)H + Rn.
(14.18)
Given the observations {x(n), n = 1, . . . , N}, the primary interest is to estimate the DOA parame-
ter. In the following, we will present DOA estimation methods based on various ideas ranging from
nonparametric spectral analysis, high resolution methods to the parametric approach. Our discussion
will focus on the mostly investigated 2D case. The majority of the methods can be extended to multiple
parameters per source in a straightforward manner. The broadband case will be discussed in detail in a
separate chapter.
3.14.2.3 Uniqueness
A fundamental issue in the direction ﬁnding problem is whether the DOA parameters can be identiﬁed
unambiguously. From the ideal data model (14.12) or (14.17), we know that the array output lies in a
subspace spanned by the columns of the M × P array steering matrix if the noise part n(n) is ignored.
For simplicity, we will present the results for the model (14.17). Assume any subset of vectors a(θp),
p = 1, . . . , P, are linearly independent. The study in [9,10] speciﬁes the conditions for the maximal
number of sources that can be uniquely localized in terms of the number of sensors M and the rank of the
signal correlation matrix R. The condition (1) P < (M + R)/2 guarantees uniqueness for every batch of
data, while the weaker condition (2) P < 2RM/(2R +1) guarantees uniqueness for almost every batch
ofdata,withtheexceptionofasetofbatchesofmeasurezero.Whenallsourcesareuncorrelatedimplying
that R = P, condition (1) is always satisﬁed and uniqueness is always guaranteed. When the sources
are fully correlated, R = 1, then uniqueness is ensured if P < (M + 1)/2 by condition (1). The weaker
condition (2) leads to a less stringent condition P < 2M/3. Details on the proof are to be found in [10].
3.14.3 Beamforming methods
Ahomogenouswaveﬁeld E(t, r)hasaninterpretationasenergydistributioninafrequency-wavenumber
spectrum. The power spectrum of E(t, r) contains information about the source distribution over space
[3]. From this perspective, estimation of DOA parameters is equivalent to ﬁnding the location in a
spatial power spectrum where most power is concentrated. Beamforming techniques are spatial ﬁlters
that combine weighted sensor outputs linearly
y(n) =
M

m=1
w∗
mxm(n) = wH x(n),
(14.19)

3.14.3 Beamforming Methods
605
where w = [w1, w2, . . . , wM]T . The weight vector is usually a function of the DOA parameter, i.e.,
w = w(θ). The power of the beamformer output y(n) provides an estimate for the power spectrum at
the direction θ:
P(θ) = 1
N
N

n=1
|y(n)|2 = wH 	Rxw.
(14.20)
where 	Rx = 1
N

N
n=1 x(n)x(n)H is the sample covariance matrix. The maximum of P(θ) is an indica-
tion for a signal source. Assuming P signals are present in the waveﬁeld, we change the look direction θ
and evaluate P(θ) over the range of interest. Then the P largest maxima are chosen as DOA estimates.
The expected beamformer output (14.20) is a smoothed version of the true power spectrum. Smooth-
ing is carried out with the kernel |G(θ −θ0)|2 centered at the look direction θ = θ0, where
|G(θ)| = |wH a(θ)| is the array beam pattern [3]. An ideal beam pattern G(θ) = δ(θ) would lead
to an unbiased estimate for the power spectrum. However, in practice, due to ﬁnite array aperture, the
beampattern consists of a main lobe and several sidelobes, leading to leakage from neighboring fre-
quencies. Hence, the shape of the beampattern determines resolution capability and estimation accuracy
of the spectral analysis based approach.
We will introduce the conventional beamformer in Section 3.14.3.1 and minimum variance distortion-
less (MVDR) beamformer in Section 3.14.3.2, respectively. A recently proposed sparse data approach
that matches array measurements to a set of candidate directions will be discussed in Section 3.14.3.3.
3.14.3.1 Conventional beamformer
The conventional beamformer, also termed as delay-and-sum beamformer, combines the output of each
sensor (14.6) coherently to obtain an enhanced signal from the noisy observation. For simplicity, assume
P = 1 for now. In its most general form, the conventional beamformer compensates the time delayed
observation at the mth sensor sm(t −τm) by the amount of τm. The sum of aligned sensor outputs leads
to an estimate for the signal:
ˆs(t) = 1
M
M

m=1
xm(t + τm) = s(t) + 1
M
M

m=1
nm(t + τm).
(14.21)
From the above equation, it is clear that the signal to noise ratio is improved by a factor of M. For
wideband data, the sum in (14.21) is often called true time-delay beamforming. It can be approximately
implemented using various ﬁltering techniques, see e.g., [6,7]. For narrow band data, the shift in the
time domain becomes phase shift in the frequency domain. Therefore, we have
y(n) = 1
M
M

m=1
e jωτm xm(n) = 1
M a(θ)H x(n),
(14.22)
where a(θ)H is the steering vector evaluated at the look direction θ. Since for any steering vectors,
∥a(θ)H a(θ)∥2 = M, the weight vector has unit length ∥wconv = 1∥and
wconv =
a(θ)

a(θ)H a(θ)
.
(14.23)

606
CHAPTER 14 DOA Estimation Methods and Algorithms
An estimate for the power spectrum is then obtained as
Pconv(θ) = a(θ)H 	Rx a(θ)
a(θ)H a(θ) .
(14.24)
In the context of spectral analysis, the above expression corresponds to the periodogram in the spatial
domain [3]. The expected value of Pconv(θ) is the convolution between the beam pattern and the true
power spectrum. A good beam pattern should be as close to the delta function δ(θ) as possible to
minimize leakage from neighboring frequencies.
For a uniform linear array, the beam pattern G(θ, θ0) =
1
M aULA(θ0)H aULA(θ) has a main lobe
around the look direction θ0. The Rayleigh beamwidth, the distance between the ﬁrst two nulls of
G(θ, θ0), is approximately given by
θBW ≈
2
|Md cos θ0|.
(14.25)
The beamformer can only distinguish two sources with DOA separation larger than half of θBW. Note
that d = D/λ is the ratio between actual distance D and wavelength λ. As θBW is inversely proportional
to Md, the aperture of the array, the resolution capability improves with increasing number of sensors
and sensor spacing. However, d = 1/2 is the maximally allowed sensor distance. For d > 1/2, grating
lobes appear in the beampattern and create ambiguity in the DOA estimation.
For a standard ULA with M = 12 sensors, d = 1/2, θ0 = 30◦, the beamwidth θBW ≈0.3849,
meaning that the DOA separation between two sources must be larger than 11◦to generate two peaks
in the power spectrum Pconv(θ).
3.14.3.2 Minimum variance distortionless response (MVDR) beamformer
The minimum variance distortionless response (MVDR) beamformer [1] alleviates the resolution limit
of the conventional beamformer by considering the following constrained optimization problem:
min wH 	Rxw
(14.26)
subject to wH a(θ) = 1.
(14.27)
The objective function (14.26) represents the output power to be minimized. The constraint (14.27)
ensures that signals from the desired direction θ remain undistorted. In other words, while the power
from all other directions is minimized, the beamformer concentrates only on the look direction. The
behavior of the MVDR beamformer was also discussed by Lacoss [11]. The resulting beampattern
has a sharp peak at the target DOA, leading to resolution capability beyond the Rayleigh beamwidth.
Applying the method of Lagrange multipliers, we obtain the solution as
wMVDR =
	R−1
x a(θ)
a(θ)H 	R−1
x a(θ)
.
(14.28)
Replacing (14.28) into (14.20), one obtains the power function as
PMVDR(θ) =
1
a(θ)H 	R−1
x a(θ)
.
(14.29)

3.14.3 Beamforming Methods
607
A condition on the MVDR beamformer follows immediately from (14.28) where the inversion of the
sample covariance matrix requires that 	Rx is full rank, implying that the number of samples must be
larger than the number of sensors, i.e., N ≥M. When rank deﬁciency occurs or the sample number
is small compared to the number of sensors, a popular technique known as diagonal loading is often
employed to improve robustness. As the name implies, the sample covariance matrix (14.14) is modiﬁed
by adding a small perturbation term to improve the conditioning:
Rx = 1
N
N

n=1
x(n)x(n)H + σϵ I,
(14.30)
where σϵ is a properly chosen small number and I is an M × M identity matrix. The choice of the
coefﬁcient σϵ is essential. Several criteria for optimal choice of diagonal loading have been reported in
[12] and the references therein.
A variant of the MVDR beamformer, proposed in [13], replaces the constraint (14.27) by wHw = 1.
This formulation leads to the adapted angular response spectrum a(θ)H 	R−1
x a(θ)
a(θ)H 	R−2
x a(θ). This Borgiorri-Kaplan
beamformer is known to provide higher spatial resolution than that of the MVDR beamformer. In [14],
the denominator of (14.29) is replaced by a(θ)H 	R−k
x a(θ) where k > 1. Simulation results therein show
that using higher order covariance matrix has superior resolution capability and robustness against signal
correlation and low SNR.
The performance of the MVDR beamformer depends on the number of snapshots, array aperture, and
SNR. Several interesting results are reported in [15]. In the presence of coherent or strongly correlated
interferences, the performance of the MVDR beamformer degrades dramatically. Alternative methods
addressing this issue are reported in [16–21]. Due to the distortionless response constraint, the MVDR
beamformer is sensitive to errors in the target direction and array response imperfection. Robust methods
to tackle this problem have been suggested in [22,23].
3.14.3.3 Sparse data representation based approach
The beamforming methods localize the signal sources by estimating the power spectrum associated with
various DOAs. Since the number of signals is usually small in array processing, the methods proposed
in [24,25] view DOA estimation as sparse data reconstruction and assign DOA estimates to signals with
nonzero amplitude. In this approach, the ﬁrst step is to ﬁnd a sparse representation of the array output
data. The beamforming output in the frequency domain [24] or the array observation (14.12) [25] can
be used to construct a sparse data representation. Then the underlying optimization problem (typically
convex) will be solved to ﬁnd nonzero components. DOA estimates are obtained from angles associated
with nonzero components. Recently this approach has attracted many researchers’ attention thanks to
advances in the theory and methodology of sparse data reconstruction [26].
For representational convenience, we follow the formulation in [25]. Let ˜θ = [ ˜θ1, ˜θ2, . . . , ˜θNθ ] be a
sampling grid of source locations of interest. An important assumption here is that the number of signals
is much smaller than the number of sample grids, i.e., P ≪Nθ. The overcomplete array manifold matrix
A = [a( ˜θ1), a( ˜θ1), . . . , a( ˜θNθ )] consists of Nθ steering vectors. The Nθ × 1 signal vector ˜s(n) has a
nonzero component ˜sk if a signal source is present at ˜θk. For a single snapshot, the array output (14.12)

608
CHAPTER 14 DOA Estimation Methods and Algorithms
can be re-expressed in terms of the sparse vector ˜s(n) as:
x(n) = A˜s(n) + n(n).
(14.31)
Now the problem reduces to ﬁnding the nonzero component in ˜s(n). In the noiseless case, the ideal
measure would be ∥˜s(n)∥0
0 which counts the nonzero entries. This would in fact lead to the deterministic
ML method over a grid search. But this metric will lead to a complicated combinatorial optimization
problem. Therefore, one tries to approximate the solution by using l1 norm, ∥˜s(n)∥1. The signiﬁcant
advantage of l1 relaxation is that the convex optimization problem,
min
˜s(n) ∥˜s(n)∥1 subject to x(n) = A˜s(n)
(14.32)
has a unique global minimum and can be solved by computationally efﬁcient numerical methods such
as linear programming. For noisy measurements (14.31), the constraint x(n) = A˜s(n) can not hold and
needs to be relaxed. An appropriate objective function is suggested in [24,25]
min
˜s(n) ∥x(n) −A˜s(n)∥+ δ∥˜s(n)∥1,
(14.33)
where δ is a regularization parameter.
For multiple snapshots, we deﬁne the data matrix X = [x(1) x(2) . . . x(N)], the signal matrix
S = [˜s(1) ˜s(2) . . . ˜s(N)] and the noise matrix N = [n(1) n(2) . . . n(N)]. They are related as follows:
X = AS + N.
(14.34)
To measure sparsity for multiple time samples, we deﬁne the ith row vector of S corresponding to a
particular DOA grid point θi as ˜si = [˜si(1), ˜si(2), . . . , ˜si(N)] and compute its l2 norm ∥˜si∥2. Then
the spatial sparsity is imposed on the Nθ × 1 vector ˜sl2 = [∥˜s1∥2, ∥˜s2∥2, . . . , ∥˜sNθ ∥2]T . The multiple
sample version of (14.33) becomes
min
S
∥X −AS∥2
F + δ∥˜sl2∥1,
(14.35)
where ∥·∥F is the Forbenius norm. The regularization parameter δ is a tradeoff between the ﬁt to data
and the sparsity. In [24,25], statistically motivated strategies for selecting δ are discussed.
The computational cost for solving (14.35) increases signiﬁcantly with the number of snapshots N.
A coherent combination based on singular value decomposition (SVD) of the data matrix is suggested
in [25]. A mixed norm approach for joint recovery is proposed in [27]. This problem can be avoided
when other forms of sparsity are used, for example, the beamforming output in [24] and the covariance
matrix in [28]. The resolution capability of this approach is investigated in [29].
Simulation results in the above mentioned references show that the sparse data representation based
approach has a much better resolution than the conventional and MVDR beamformers at the expense of
increased computational cost. Another advantage over the subspace methods is the improved robustness
against signal coherence. However, for low SNRs and closely located sources, the relatively high bias
remains an challenging issue for this approach.

3.14.3 Beamforming Methods
609
3.14.3.4 Numerical examples
In this section, the beamforming based methods discussed previously are tested by numerical exper-
iments. In the simulation, a uniform linear array of 12 sensors with inter-element spacings of half a
wavelength is employed. The narrow band signals are generated by P = 2 uncorrelated signals of vari-
ous strengths. The signal to noise ratio of the ﬁrst and second signals are given by [5 0] dB, respectively.
The number of snapshots is N = 200 in each Monte Carlo trial.
Figure 14.2 shows the normalized spectra obtained from conventional beamformer, MVDR beam-
former and sparse data representation over −90◦to 90◦for well separated sources located θ = [20◦40◦]
relative to the broadside. All the three methods exhibit two peaks at the reference locations. For the
second experiment, the reference DOA parameter is given by θ = [20◦30◦], which corresponds to
closely located signals. As shown in Figure 14.3, the conventional beamformer only leads to one max-
imum between the true DOAs and does not recognize the existence of two signals. On the other hand,
the MVDR beamformer and the sparse data representation based approach perform well in resolving
two signals.
In the third experiment, we compare the estimation accuracy of these methods. To avoid resolution
problem, the reference DOA parameter is chosen as θ = [20◦40◦]. Both signals have equal power
with SNR running from −5 dB to 20 dB in a 1 dB step. Figure 14.4 depicts the root mean squared
−80
−60
−40
−20
0
20
40
60
80
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Degrees
Normalized Spectrum
Normalized Spectrum
MVDR
Conventional Beamformer
Sparse Data Rep
FIGURE 14.2
Normalized spectrum for well separated signals. Reference DOA parameter θ = [20◦40◦], SNR = [5 0] dB,
N = 200.

610
CHAPTER 14 DOA Estimation Methods and Algorithms
−80
−60
−40
−20
0
20
40
60
80
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Degrees
Normalized Spectrum
Normalized Spectrum
MVDR
Conventional Beamformer
Sparse Data Rep
FIGURE 14.3
Normalized spectrum for closely located signals. Reference DOA parameter θ = [20◦30◦], SNR = [5 0] dB,
N = 200.
−5
0
5
10
15
20
10
−1
10
0
10
1
SNR(dB)
RMSE (deg)
MVDR
Performance of DOA Estimation
Conventional Beamformer
Sparse Data Rep
FIGURE 14.4
Estimation performance, RMSE vs. SNR. Reference DOA parameter θ = [20◦40◦], equal power, N = 200.

3.14.4 Subspace Methods
611
error (RMSE) obtained from 1000 trials. For all three methods, RMSE decreases with increasing SNR.
The sparse data representation based method has an overall best performance over the entire SNR
range. The MVDR beamformer lies between the other two methods. The gap between these methods
becomes most signiﬁcant at low SNRs. For example, at SNR = −5 dB, the RMSE of conventional
beamformer is 5◦which is more than three times that of the sparse data representation based method with
RMSE = 1.5◦.
From the simulation results, we have observed the resolution limitation of the conventional beam-
former. Improved resolution capability and estimation accuracy can be achieved by the MVDR beam-
former and computationally involved sparse data representation based estimator.
3.14.4 Subspace methods
In an attempt to overcome the resolution limit of conventional beamforming, many spectral-like methods
were introduced in seventies. They exploit the eigenstructure of the spatial correlation matrix (14.18)
to form pseudo spectrum functions. These functions exhibit sharp peaks at the true parameters and lead
to superior performance as compared to the Fourier based analysis. While the early work by Pisarenko
[30] was devoted to harmonic retrieval, the MUSIC (Multiple SIgnal Classiﬁcation) algorithm [2,31]
was developed for array signal processing.
Recall that Rx is a Hermitian symmetric matrix. Therefore, the eigenvectors are orthogonal. From
(14.18), it is apparent that the eigenvalues induced by the signal part differs from the remaining ones
by the noise level. More speciﬁcally, let (λi, ui), (i = 1, . . . , M) denote eigenvalue/eigenvector pairs
of Rx, the spectral decomposition of Rx can be expressed as
Rx =
M

i=1
λiuiuH
i
= UssU H
s + UnnU H
n ,
(14.36)
where s = diag(λ1, . . . , λP), Us = [u1, . . . uP] and n = diag(λP+1, . . . , λM), Un = [uP+1,
. . . , uM].Whenthesignalcovariancematrix Rs isfullrank,i.e., rank(Rs) = P,thematrix A(θ)Rs A(θ)H
has the rank of P. The eigenvalues satisfy the property: λ1 ≥λ2 ≥· · · ≥λP > λP+1 = · · · = λM
= σ 2. The signal eigenvectors corresponding to the P largest eigenvalues span the same subspace as
the steering matrix. The noise eigenvectors corresponding to the remaining (M −P) eigenvalues are
orthogonal to the signal subspace. Mathematically, the signal and noise subspaces are related to the
steering matrix as follows:
sp(Us) = sp(A(θ)),
sp(Un) ⊥sp(A(θ)).
(14.37)
In practice, the analysis is based on the sample covariance matrix 
Rx. The eigenvalues and eigen-
vectors in (14.36) are then replaced by their estimates ˆλi, ˆui. Similarly, the matrices on the right hand
side of (14.36) are substituted by corresponding estimates 	Us, 	Un, 	s and 	n, respectively. For ﬁnite
samples, 	Us ̸= Us and 	Un ̸= Un, the property (14.37) is approximately valid. Many efforts have been
made to ﬁnd the best way of combining the estimated signal and noise eigenvectors to achieve high

612
CHAPTER 14 DOA Estimation Methods and Algorithms
resolution capability and estimation accuracy. In the following, we assume that the number of signals
is known so that the signal and noise subspaces can be separated. Methods for determination of the
number of sources will be discussed separately in Section 3.14.7. In the following, we will present
the well known MUSIC and ESPRIT algorithms in Sections 3.14.4.1 and 3.14.4.2, respectively. The
important issue of signal coherence will be discussed in Section 3.14.4.3.
3.14.4.1 MUSIC
The MUSIC algorithm suggested by Schmidt [2,32], and Bienvenu and Kopp [31] exploits the orthog-
onality between signal and noise subspaces. From (14.37), we know that any vector a(θ) ∈sp(A(θ))
satisﬁes
aH(θ)Un = 0.
(14.38)
Assume the array is unambiguous; that is, any collection of P distinct DOAs {θ1, . . . , θp} forms a
linearly independent set {a(θ1), . . . , a(θp)}. Then the above relation is valid for P distinct columns of
A(θ). Motivated by this observation, the MUSIC spectrum is deﬁned in terms of the estimated noise
eigenvectors as
PMU(θ) =
1
a(θ)H 	Un	U H
n a(θ)
.
(14.39)
For high SNR (or large N) and uncorrelated signal sources, the MUSIC spectrum exhibits high peaks
near the true DOAs. To ﬁnd the DOA estimates, we calculate PMU(θ) over a ﬁne grid of θ and locate
the P largest maxima of PMU(θ). In comparison with the MVDR beamformer (14.29), the MUSIC
spectrum uses the projection matrix 	Un	U H
n rather than 	R−1
x . To get more insight, assume a perfect
spatial correlation matrix. Then, for noise eigenvalues σ 2 = 1 and R−1
s
→0, PMVDR(θ) approaches
P MU(θ). Then MUSIC may be interpreted as a MVDR-like method with a correlation matrix calculated
at inﬁnite SNR. This explains the superior resolution of MUSIC than MVDR [3].
In [33,34], an alternative implementation of MUSIC is suggested to improve estimation accuracy.
The idea behind the sequential MUSIC is to ﬁnd the strongest signal in each iteration and then remove the
estimated signal from the observation for the next iteration. As theoretical analysis and numerical results
in [34] show the advantage of sequential MUSIC over standard MUSIC is signiﬁcant for correlated
signals. The Toeplitz approximation method [35] provides another implementation of MUSIC speciﬁc
to uncorrelated sources with a ULA.
For a uniform linear array, MUSIC has a simple implementation. Let z = e jφ where φ = 2πd sin θ,
the steering vector (14.16) has the form:
a(z) = [1, z, . . . , zM−1]T .
(14.40)
The inverse of the MUSIC spectrum (14.39) becomes
PMU(z) = a(z−1)T 	Un	U H
n a(z).
(14.41)
The root-MUSIC algorithm [36] ﬁnds the roots of the complex polynomial function zM−1PMU(z) rather
than searching for maxima of the MUSIC spectrum. Among the (2M −1) possible candidates, P roots

3.14.4 Subspace Methods
613
ˆzi, i = 1, . . . , P that are closest to the unit circle on the complex plane are selected to obtain DOA
estimates. Since φ = 2πd sin θ, the DOA parameters are given by ˆθi = sin−1[angle(ˆzi)/(2πd)]. It
is known that root-MUSIC has the same asymptotic performance as standard MUSIC. In the ﬁnite
sample case, root-MUSIC has a much better threshold behavior and improved resolution capability
[37]. This is explained by the fact that the radial component of the errors in ˆzi will not affect ˆθi. Since
the search procedure in standard MUSIC is replaced by solving the roots of a polynomial in root-
MUSIC, the computational cost is signiﬁcantly reduced. However, while standard MUSIC is applicable
to arbitrary array geometry, root-MUSIC requires a ULA. When ULAs are not available, one can
apply array interpolation techniques [38] to approximate the array response. For more details on array
interpolation, the reader is referred to Chapter 16 of this book.
The extension of standard MUSIC to the two dimensional case is straightforward. The 2D steering
vector (14.8) is used in the MUSIC spectrum, searching for the P largest maxima over a two dimensional
space. For root-MUSIC, an additional ULA is required to be able to resolve both azimuth and elevation
[39]. More algorithms and results regarding two dimensional DOA estimation are to be found in Chapter
15 of this book.
While the MUSIC algorithm utilizes all noise eigenvectors, the Minimum Norm (Min-Norm) algo-
rithm suggested in [40,41] uses a single vector in the noise space. A comprehensive study on the
resolution capability of MUSIC and the Min-Norm algorithm can be found in [42].
3.14.4.2 ESPRIT
The ESPRIT (Estimation of Signal Parameters via Rotational Invariance Techniques) algorithm pro-
posed by Roy and Kailath [43] exploits the rotational invariance property of two identical subarrays and
solves the eigenvalues of a matrix relating two signal subspaces. A simple way to construct identical
subarrays is to select the ﬁrst (M −1) elements and the second to the Mth elements of a ULA (see
Figure 14.5). The array response matrices of the ﬁrst and second subarrays are then expressed as
A1(θ) = J1 A(θ),
A2(θ) = J2 A(θ),
(14.42)
where J1 and J2 are selection matrices of the ﬁrst and second subarrays. They consist of an (M −1)
× (M −1) identity matrix and an (M −1) × 1 zero vector
J1 = [ I M−1
0 ]
J2 = [ 0
I M−1 ].
(14.43)
Deﬁne z p = e jφp, p = 1, . . . , P. From (14.42), we know that the two subarrays have the same
array response up to a phase shift due to the distance between them. This observation leads to the shift
invariance property
A2(θ) = A1(θ),
(14.44)
where  = diag[z1, . . . , z p]. Note that ESPRIT is applicable for array geometries other than ULAs as
long as the shift invariance property holds, see e.g., [43–45].

614
CHAPTER 14 DOA Estimation Methods and Algorithms
Recall that the signal subspace of the original array and the signal eigenvectors span the same
subspace; therefore, they are related through a nonsingular linear transformation T:
Us = A(θ)T.
(14.45)
Multiplying both sides of (14.45) with J1 and J2,
Us1 = A1(θ)T,
Us2 = A2(θ)T.
(14.46)
Combining (14.44) and (14.46) yields the relation between Us1 and Us2:
Us2 = Us1,
 = T −1T.
(14.47)
Since the matrix  is similar to the diagonal matrix , both matrices have the same eigenvalues,
z1, . . . , z p.
Using estimates 	Us1, 	Us2 in (14.47), one can apply LS (Least Squares) or TLS (Total Least Squares) to
obtain 	 [46]. Finally, DOA estimates are obtained from eigenvalues of 	 by the formula
ˆθi = sin−1[angle(ˆzi)/(2πd)]. The computational burden of the ESPRIT algorithm can be reduced
by using real-valued operations as proposed in [44].
3.14.4.3 Signal coherence
In the development of subspace methods, we have made an important assumption that the rank of the
signal covariance matrix Rs equals the number of signals P so that the signal eigenvectors spans the same
subspace as the column space of the array manifold matrix. However, this condition no longer holds
when two signals are coherent, meaning that the magnitude of the correlation coefﬁcient of the signals
is one. Coherent signals are often encountered in wireless communications as a result of a multipath
propagation effect or smart jamming in radar systems. In the presence of signal coherence, Rs becomes
rank deﬁcient, leading to divergence of signal eigenvectors into the noise subspace. Since the property
(14.38) is not satisﬁed, performance of subspace methods degrades signiﬁcantly. To mitigate the effect
of signal coherence, one could apply forward-backward averaging or spatial smoothing techniques.
The former requires a ULA and can handle two coherent signals. The latter requires arrays with a
translational invariance property and is able to deal with maximally P coherent signals.
Let E denote the exchange matrix comprised of ones on the anti-diagonal and zeros elsewhere. For
a ULA, the steering vector (14.16) has an interesting property:
Ea(θ)∗= e−j(M−1)φa(θ),
(14.48)
which implies
E A(θ)∗= −(M−1) A(θ),
(14.49)
where  = diag[e jφ1, . . . , e jφP ]. The backward covariance is deﬁned as
RB = ER∗
x E.
(14.50)

3.14.4 Subspace Methods
615
FIGURE 14.5
Array and subarrays.
The forward-backward covariance matrix is obtained by averaging of RB and the standard array covari-
ance matrix Rx:
RFB = 1
2(Rx + E R∗
x E) = A(θ) ˜Rs A(θ)H + σ 2I.
(14.51)
Applying the property (14.49), the modiﬁed signal covariance matrix is then given by
Rs = 1
2(Rs + −(M−1)R∗
s (M−1)).
(14.52)
The coherent signals are de-correlated through phase modulation by the diagonal elements of −(M−1).
The forward-backward ESPRIT is equivalent to the unitary ESPRIT [44], because it only uses real
valued components.
In a general case where more than two coherent signals are present, we need a more powerful solution
to restore the rank of the signal covariance matrix. The spatial smoothing technique, ﬁrst proposed in
[47] and extended in [38,48,49], exploits the degrees of freedom of a regular array by splitting it into
several identical subarrays. Let Ms denote the number of sensors of a subarray. For a ULA of M elements,
the maximal number of subarrays is L = (M −Ms + 1). The array response matrix of the lth subarray
is related to A(θ) as
Al(θ) = El A(θ),
(14.53)
where the selection matrix is El = [0Ms×(l−1)I Ms0Ms×(M−Ms−l+1)]. The spatially averaged covariance
matrix is then given by
RSS = 1
L
L

l=1
El Rx ET
l .
(14.54)
In the case of a ULA, one can combine the forward-backward averaging (14.51) with the spatial
smoothing. In [48,50], it was shown that under mild conditions, the signal covariance matrix obtained
from forward-backward averaging and spatial smoothing is nonsingular. Since the subarrays have a
smaller aperture than the original array, the signal coherency is removed at the expense of resolution
capability. The two dimensional extension of spatial smoothing is addressed in [51–53].

616
CHAPTER 14 DOA Estimation Methods and Algorithms
−5
0
5
10
15
20
10−1
100
101
SNR(dB)
MVDR
ESPRIT
MUSIC
R−MUSIC
RMSE (deg)
Performance of DOA Estimation (Uncorrelated Signals)
FIGURE 14.6
RMSE vs. SNR. Uncorrelated signals. Reference DOA parameter θ = [20◦40◦], N = 200.
3.14.4.4 Numerical examples
We demonstrate the performance of the subspace methods presented previously by numerical results.
A uniform linear array of 12 sensors with inter-element spacings of half a wavelength is employed.
In this case, the application of root-MUSIC is straightforward. Narrow band signals are generated by
P = 2 well separated sources of equal strengths located at θ = [20◦40◦]. The number of snapshots is
N = 200. Both signals are equal power with SNR running from −5 dB to 20 dB. The two subarrays
used in ESPRIT are ULAs comprised of 11 elements.
In the ﬁrst experiment, we consider uncorrelated signals. For comparison, the MVDR beamformer is
applied to the same batch of data. The empirical RMSE is obtained from 1000 trials. From Figure 14.6,
one can observe that root-MUSIC, denoted by R-MUSIC, outperforms standard MUSIC and ESPRIT.
All the subspace methods have lower estimation errors than the MVDR beamformer. The performance
difference is most signiﬁcant at low SNRs. For SNR close to 20 dB, all methods behave similarly. The
superior performance of root-MUSIC compared to standard MUSIC is expected as predicted by the
theoretical analysis [37]. The estimation error of ESPRIT is higher than both MUSIC algorithms due
to the reduced aperture.
In the second experiment, two correlated signals are considered with real valued correlation coefﬁ-
cientρ = 0.92.OnecanobservefromFigure14.7thattheperformanceofallmethodsdegraderapidly.At
SNR = −5 dB, the RMSE is more than twice the RMSE in the uncorrelated case. Both MUSIC-based

3.14.5 Parametric Methods
617
−5
0
5
10
15
20
10
−1
10
0
10
1
SNR(dB)
RMSE of the estimated DOA in degrees
MVDR
ESPRIT
MUSIC
R−MUSIC
FB−ESPRIT
FB−MUSIC
FB−R−MUSIC
FIGURE 14.7
RMSE vs. SNR. Correlated signals. Reference DOA parameter θ = [20◦40◦], N = 200.
algorithms have almost identical performance. They are slightly better than ESPRIT. The curve of
ESPRIT almost coincides with that of MVDR. These observations indicate that subspace methods are
very sensitive to signal correlation and can not provide accurate estimates when rank deﬁciency occurs.
If we use the forward-backward averaged sample covariance matrix (14.51) in the subspace methods,
denoted by FB-ESPRIT, FB-MUSIC, and FB-R-MUSIC, respectively, the estimation accuracy improves
signiﬁcantly as the three curves at the bottom show. In comparison with Figure 14.6, the RMSE increases
only slightly when the FB technique is applied. For a detailed discussion on highly correlated signals,
the reader is referred to Chapter 15 of this book.
3.14.5 Parametric methods
The spectral-like methods presented previously treat the direction ﬁnding problem as spatial frequency
estimation. Although subspace methods overcome the resolution limitation of beamforming techniques,
and yield good estimates at reasonable computational cost, the performance degrades dramatically in
the presence of correlated or coherent signals. Parametric methods exploit the data model directly
and are usually statistically well motivated. The well known maximum likelihood (ML) approach is
representative of this class of estimators. Since parametric methods are not dependent on the eigen-
structure of the sample covariance matrix, they provide reasonable results in scenarios involving signal
correlation/coherence, low SNRs and small data samples. The price for the improved robustness

618
CHAPTER 14 DOA Estimation Methods and Algorithms
and accuracy is the increased computational complexity. We will introduce the maximum likelihood
approach and the covariance matching estimation methods in Sections 3.14.5.1 and 3.14.5.4, respec-
tively. Several numerical algorithms for efﬁcient implementation of the ML estimator will be presented
in Section 3.14.5.2. Analytical results on the performance of DOA estimators presented so far will be
discussed in Section 3.14.5.5.
3.14.5.1 The maximum likelihood approach
The maximum likelihood method is a systematic tool for constructing estimators. Based on the statistical
model for data samples, it maximizes the likelihood function over the parameters of interest to derive
estimates. The well known properties of ML estimation include asymptotic normality and efﬁciency
under proper conditions [54]. For DOA estimation, the application is straightforward. Recall the data
model in (14.17)
x(n) = A(θ)s(n) + n(n).
(14.55)
We assume the noise n(n) is temporally independent and complex normally distributed with zero mean
and covariance matrix Rn = σ 2I, i.e., n(n) ∼CN(0, σ 2I). In the array processing literature, two
different interpretations of the source signals lead to the deterministic and the stochastic ML estimators.
3.14.5.1.1
Deterministic maximum likelihood
In the deterministic ML approach, the signal s(n) is viewed as a ﬁxed realization of a stochastic
process; the parameters s(1), s(2), . . . , s(N) are considered to be deterministic and unknown. With the
above noise assumption, the array output x(n) is complex normally distributed with mean A(θ)s(n)
and covariance matrix σ 2I, i.e., x(n) ∼CN(A(θ)s(n), σ 2I). Because the array outputs x(n), n =
1, . . . , N are independent, the joint likelihood function is the product of the likelihood associated with
each snapshot, i.e.,
ld(θ, s(1), . . . , s(N), σ 2) =
N

n=1
ld(θ, s(n), σ 2) =
N

n=1
1
(πσ 2)M exp

−1
σ 2 ∥x(n) −A(θ)s(n)∥2

,
(14.56)
where ∥·∥denotes the Euclidean norm. The log-likelihood function is then given by
Ld(θ, s(1), . . . , s(N), σ 2) = −
N

n=1
M log (πσ 2) + 1
σ 2 ∥x(n) −A(θ)s(n)∥2.
(14.57)
The unknown parameters ϑd = {θ, s(1), . . . , s(N), σ 2} include the DOA parameter and nuisance
parameters. As the number of the signal waveform parameters increases with increasing number of
snapshots, the high dimension of parameter space will make direct optimization of (14.57) infeasible.
It is well known that the likelihood function is separable [55,3], and the likelihood can be concentrated
with respect to the linear parameters. For a ﬁxed, unknown θ, the ML estimate of the signal is given by
ˆs(n) = A♯(θ)x(n),
(14.58)

3.14.5 Parametric Methods
619
where A♯(θ) denotes the Moore-Penrose pseudo inverse. For a full column rank A(θ), it is given by
A♯(θ) = (A(θ)H A(θ))−1 A(θ)H. Replacing s(n) with ˆs(n) in (14.57), and maximizing the resulting
likelihood over σ 2, we obtain the ML estimate
ˆσ 2 = 1
M tr(P⊥(θ)	Rx),
(14.59)
where P⊥(θ) = I −P(θ) is the orthogonal complement of the projection matrix P(θ) = A(θ)A♯(θ).
Replacing σ 2 with ˆσ 2 in the likelihood function again, we obtain the concentrated likelihood function:
Ld(θ) = −log tr(P⊥(θ)	Rx).
(14.60)
Since log (·) is a monotonically increasing function, the ML estimate can be obtained from maxi-
mizing the function Ld(θ), or equivalently,
ˆθDML = arg min
θ
tr(P⊥(θ)	Rx).
(14.61)
The signal waveform and noise parameters can be computed by replacing θ with the estimate ˆθ DML
into (14.58) and (14.59), respectively. Combining the criterion (14.60) and the noise estimate (14.59)
shows that the deterministic ML estimate minimizes the distance between the observation and the model
which is represented by the estimated noise power.
3.14.5.1.2
Stochastic maximum likelihood
In the stochastic ML, the signal s(n) is considered as a complex normal random process with zero mean
and covariance matrix Rs = E[s(n)s(n)H]. Assuming independent, spatially white noise as in the
deterministic case, the array observation x(n) is normally distributed with zero mean and covariance
matrix Rx, i.e., CN(0, Rx) where Rx = A(θ)Rs A(θ)H + σ 2I. The joint log-likelihood function for
the stochastic signal model is given by
ls(θ, S, σ 2) =
N

n=1
1
π M det Rx
exp

−x(n)H R−1
x x(n)

,
(14.62)
where the vector S includes P2 unknown entries in the signal covariance matrix Rs. Taking logarithm
of ls(·) and omitting constants, we obtain
Ls(θ, S, σ 2) = −log det Rx −tr

R−1
x 	Rx

.
(14.63)
The parameter vector ϑs = [θ, S, σ 2] remains the same over the observation interval, unlike the growing
parameter vector in the deterministic case. It was shown in [56,57] that the linear parameters in (14.63)
have a closed form expression for the ML estimates at an unknown ﬁxed nonlinear parameter θ as
follows:
ˆσ 2 =
1
M −P tr

P⊥(θ)	Rx

,
(14.64)
	Rs = A♯(θ)

	Rx −ˆσ 2I

A♯(θ)H.
(14.65)

620
CHAPTER 14 DOA Estimation Methods and Algorithms
Replacing σ 2 and Rs with ˆσ 2 and 	Rs, one obtains the concentrated stochastic likelihood function as
Ls(θ) = −log det

A(θ)	Rs A(θ)H + ˆσ 2I

(14.66)
= −log det

P(θ)	Rx P(θ) +
1
M −P tr

P⊥(θ)	Rx

P⊥(θ)

.
(14.67)
The ML estimate for the DOA parameter is derived by minimizing the negative likelihood function
over θ
ˆθSML = arg min
θ
−Ls(θ).
(14.68)
Once ˆθSML is available, the signal and noise parameters can be computed from (14.64) and (14.65)
by replacing the DOA parameter with its estimate. The criterion (14.66) has a nice interpretation as
the generalized variance minimized by the estimated model parameter [3]. If there is only one signal
source, the projection matrix is given by P(θ) = a(θ)a(θ)H/M, and the criterion Ls(θ) is a monoton-
ically increasing function of a(θ)	Rx a(θ)H. The optimum wave parameter maximizes the conventional
beamforming output and therefore results in the same estimate as the conventional beamformer.
In the above discussion, the spectral covariance 	Rs is not necessarily positive deﬁnite as the opti-
mization was over Hermitian matrices. The positive deﬁniteness of 	Rs is taken into account by imposing
a constraint in the optimization process in [58,59]. Fortunately, 	Rs has full rank with probability 1 for
sufﬁciently large N, provided the true Rs has full rank. The ML estimator for known signal waveforms
was developed in [60–62] under various assumptions. The problem of unknown noise structures was
discussed in [63].
3.14.5.2 Implementation
In the derivation of ML estimators, we have reduced the size of the problem by concentrating the
signal and noise parameters. The resulting objective functions: (14.60) and (14.66) depend only on the
nonlinear parameters. Maximization of both criteria still requires multi-dimensional searches. Hence,
efﬁcient implementation of the ML estimators becomes an important issue. The alternating projection
algorithm [64] is an iterative technique for ﬁnding the maximum of the concentrated likelihood function
(14.60). It performs maximization with respect to a single parameter, while all other parameters are
held ﬁxed. In [65], Newton-type methods are suggested for the large sample case.
In the following, we will present the statistically motivated expectation and maximization (EM)
and space alternating generalized EM (SAGE) algorithm. The multidimensional search in the origi-
nal problem can be replaced by several one dimensional maximizations. Both algorithms assume the
deterministic signal model so that the suggested augmentation scheme is valid. It is possible to derive
EM and SAGE for stochastic ML for uncorrelated signals, see e.g., [66]. When a ULA is available, the
iterative quadratic maximum likelihood (IQML) algorithm can be applied to minimize the deterministic
likelihood function. A common feature of these methods is that a good initial estimate is required for the
convergence to the global maximum. One way to obtain the initial estimate is via other simpler methods
such beamforming techniques or subspace methods. Another approach is to optimize the ML crite-
ria directly by stochastic optimization procedures such as the genetic algorithm (GA) [67], simulated
annealing [68] and particle swarm method [69] prior to the local maximization algorithms.

3.14.5 Parametric Methods
621
3.14.5.2.1
EM algorithm
The expectation and maximization (EM) algorithm [70] is a well known iterative algorithm in statistics
for locating modes of likelihood functions. Because of its simplicity and stability, it has been applied to
many problems since its ﬁrst appearance. The idea behind EM is quite simple: rather than performing
a complicated maximization of the observed data log-likelihood, one augments the observations with
imputed values that simplify the maximization and applies the augmented data to estimate the unknown
parameters. Because the imputed data are unknown, they are estimated from the observed data. This
procedure continues to iterate between the E- and M-steps until no changes occur in the parameter
estimates.
Let X and Y denote the observed and augmented data, respectively. The corresponding density
functions are denoted by fX(x|ϑ) and fY(y|ϑ). The augmented data Y is speciﬁed so that M(Y) = X
is a many-to-one mapping. Starting from an initial guess ϑ[0], each iteration of the EM algorithm consists
of an expectation (E) step and a maximization (M) step. At the (i + 1)st iteration, (i = 0, 1, . . . ), the
E-step evaluates the conditional expectation of the augmented data log-likelihood log fY(y|ϑ) given
the observed data x and the ith iterate ϑ = ϑ[i]:
Q(ϑ, ϑ[i]) = E

log fY(y|ϑ)|x, ϑ[i]
.
(14.69)
For notational simplicity, y is also used to denote a random vector in expressions like (14.69). The
M-step determines ϑ[i+1] by maximizing the expected augmented data log-likelihood
ϑ[i+1] = arg max
ϑ
Q(ϑ, ϑ[i]).
(14.70)
A simple proof based on Jensen’s inequality [71] shows that the observed data likelihood increases
monotonically or never decreases with iterations [70]. As with most optimization techniques, EM is not
guaranteed to always converge to a unique global maximum. In well-behaved problems log fX(x|ϑ) is
unimodel and concave over the entire parameter space, then EM converges to the maximum likelihood
estimate from any starting value [70,72].
For DOA estimation, the observed data consists of the array outputs x(n), n = 1, . . . , N. For the
deterministic signal model, the augmented data y(n) is constructed by decomposing x(n) virtually into
its signal and noise parts [73]:
y(n) =
⎡
⎢⎣
y1(n)
...
yp(n)
⎤
⎥⎦=
⎡
⎢⎣
a(θ1)s1(n)
...
a(θp)sp(n)
⎤
⎥⎦+
⎡
⎢⎣
n1(n)
...
nP(n)
⎤
⎥⎦,
(14.71)
where the M × 1 vectors yp(n), p = 1, . . . , P are independent and complex normally dis-
tributed as CN(a(θp)sp(n), σ 2
p I). The noise parameters are positive and must satisfy the constraint

P
p=1 σ 2
p = σ 2. The total unknown parameter vector is given by ϑ = [ϑ1, ϑ2, . . . , ϑ P], where
ϑ p = [θp, sp(1), . . . , sp(N), σ 2
p]. Through data augmentation, maximization of log fY(y|ϑ) can be
performed over distinct parameter sets ϑ p, p = 1, . . . , P in parallel. For the unknown noise case, the
(i + 1)st iteration proceeds as follows [74].

622
CHAPTER 14 DOA Estimation Methods and Algorithms
E-step:
Calculate the conditional mean ˆyp(n) and correlation matrix 	C yp of yp(n):
ˆyp(n) = a

θ[i]
p

sp(n)[i] + σ 2[i]
p
σ 2[i] (x(n) −A(θ[i])s(n)[i]),
	C yp = 1
N
N

n=1
ˆyp(n)ˆyp(n)H +

σ 2[i]
p
2
σ 2[i]
p
I.
M-step:
Update θp for p = 1, . . . , P
θ[i+1]
p
= arg max
θp a(θp)H	C yp a(θp),
(14.72)
Given the estimate (14.72), the signal parameter sp(n)[i+1] can be obtained from (14.58) by replacing
x(n)with ˆyp(n),using A(θ) = a(θ[i+1]
p
).Similarly,thenoiseparameterσ 2[i+1]
p
isobtainedfrom(14.59)
by replacing 	Rx with 	C yp.
The M-step (14.72) requires only a one dimensional search. The multi-dimensional nonlinear opti-
mization in the original problem is greatly simpliﬁed by data augmentation. The EM algorithms for
the known noise case [73,75] and the stochastic signal model [76] also demonstrate this computational
advantage. A major shortcoming of EM is that it may converge slowly. To address this issue, we will
discuss an implementation based on a more ﬂexible augmentation scheme in the following.
To improve the convergence rate, the space alternating generalized EM (SAGE) algorithm [77] is
derived in [78,79].
3.14.5.2.2
SAGE algorithm
The space alternating generalized EM (SAGE) algorithm [77] generalizes the idea of data augmentation
to simplify computations of the EM algorithm. Instead of estimating all parameters at once, SAGE breaks
up the problem into several smaller problems by conditioning sequentially on a subset of the parameters
and then applies EM to each reduced problem. Because each of the reduced problems considers the
likelihood as a function of a different subset of parameters, it is natural to use a different augmentation
scheme for each of the corresponding EM algorithms [77,80]. In some settings, this attempt turns out
to be very useful for speeding up the algorithm.
Unlike the EM algorithm, each iteration of SAGE consists of several cycles. The parameter subset
associated with the cth cycle ηc is updated by maximizing the conditional expectation of log-likelihood
log fZc(zc|ηc) of the augmented data Zc. The data augmentation schemes are allowed to vary between
cycles. Within one iteration, every element of the parameter vector η must be updated at least once.
Let ˜ηc be the vector containing all parameters of η except the elements of ηc. Then η = (ηc, ˜ηc) is a
partition of the parameter set at the cth cycle. The estimate at the cth cycle, ith iteration is represented
by (·)[i,c]. The output of the last cycle of the ith iteration is used as the input of the (i + 1)st iteration:
η[i+1,0] = η[i,C]. Starting from the initial estimate η[0,0], the (i + 1)st iteration of the SAGE algorithm
proceeds as follows.

3.14.5 Parametric Methods
623
For c = 1, . . . , C
E-step:
Compute
Q[c] 
ηc, η[i+1,c−1]
= E

log fZc(zc|ηc)|x, η[i+1,c−1]
.
(14.73)
M-step:
Update ηc by maximizing Q[c](ηc, η[i+1,c−1]) with respect to ηc
η[i+1,c]
c
= arg max
ηc Q[c] 
ηc, η[i+1,c−1]
,
(14.74)
η[i+1,c] =

η[i+1,c]
c
, ˜η[i+1,c−1]
c

.
(14.75)
Similarly to EM, it can be shown that any sequence generated by the above procedure increases (or
maintains) log fX(x|ϑ) at every cycle [77].
A natural augmentation scheme for DOA estimation is to consider one source at each cycle:
zc(n) = a(θc)sc(n) + n(n).
(14.76)
Compared to the augmentation scheme speciﬁed in (14.71), zc(n) is more noisy since the whole noise
component is fully incorporated in every cycle. The parameter vector associated with the cth cycle is
given by ηc = (θc, sc(1), . . . , sc(N), σ 2). The cth cycle in the (i + 1)st iteration is as follows:
E-step:
Calculate the conditional mean ˆzc(n) and correlation matrix 	C zc.
ˆzc(n) = a

θ[i+1,c−1]
c

sc(n)[i+1,c−1] + x(n) −A

θ[i+1,c−1]
s(n)[i+1,c−1],
(14.77)
	C zc = 1
N
N

n=1
ˆzc(n)ˆzc(n)H.
(14.78)
M-step:
Update θc
θ[i+1,c]
c
= arg max
θc a(θc)H	C zca(θc).
(14.79)
The computational complexity for each iteration of EM and SAGE is almost the same. The total compu-
tational cost is determined by the convergence rate. It has been shown in [74] that the SAGE algorithm
converges faster than the EM algorithm when certain conditions on observed and augmented information
matrices are satisﬁed.
3.14.5.2.3
Iterative quadratic maximum likelihood
The iterative quadratic maximum likelihood (IQML) algorithm [81], also proposed independently in
[82], can trace its root back to system identiﬁcation methods [83]. Unlike EM and SAGE which are
applicable to arbitrary arrays, the IQML algorithm requires a ULA so that the array response matrix
A(θ) has a Vandermonde structure:
A(θ) =
⎛
⎜⎜⎜⎝
1
1
· · ·
1
e jφ1
e jφ2
· · ·
e jφP
...
...
· · ·
...
e j(M−1)φ1 e j(M−1)φ2
e j(M−1)φP
⎞
⎟⎟⎟⎠,
(14.80)

624
CHAPTER 14 DOA Estimation Methods and Algorithms
where φp = 2πd sin θp, p = 1, . . . , P according to (14.15). To re-parameterize the likelihood function
(14.60), one deﬁnes a polynomial with roots z p = e jφp, p = 1, . . . , P as
b(z) = z P + b1z P−1 + · · · + bP =
P

p=1
(z −e jφp).
(14.81)
By construction, the Toeplitz matrix BH
BH =
⎛
⎜⎝
bP
bP−1
· · ·
1
· · · 0
...
...
...
0
0
bP
bP−1
· · · 1
⎞
⎟⎠
(14.82)
is full rank and satisﬁes the following relation:
BH A(θ) = 0.
(14.83)
In other words, the column space of B is orthogonal to that of A(θ). Therefore, the projection matrix
in (14.60) can be reformulated as
P⊥(θ) = B(BH B)−1BH.
(14.84)
Then the likelihood criterion (14.60) can be re-parameterized in terms of the polynomial coefﬁcients
b = [b1, . . . , bP]
LIQML(b) = −tr(B(BH B)−1BH 	Rx).
(14.85)
Maximizing LIQML(b) leads to an estimate for the coefﬁcient vector ˆb. With b replaced by ˆb, the DOA
estimate is computed by ﬁnding the roots of (14.81).
Minimization of the criterion (14.85) is still a complicated optimization problem. However, if the
matrix Q = (BH B)−1 is replaced by a known matrix, the criterion becomes quadratic in b and has
a closed form solution. This observation leads to the iterative algorithm suggested in [81]. Setting the
initial value Q(0) = I and denoting the ith iterate as ˆb
(i), the (i + 1)st iteration of the IQML algorithm
proceeds as follows:
1. Compute Q(i) = (B(i)H B(i))−1.
2. Find ˆb
(i) by solving
ˆb
(i+1) = arg max
b
−tr(B Q(i)BH 	Rx).
(14.86)
The procedure continues until the distance between two consecutive iterates is less than a pre-speciﬁed
smallnumberδ,i.e.,∥b(i+1)−b(i)∥≤δ.Toensuretherootsofthepolynomialwithestimatedcoefﬁcients
lie on the unit circle, constraints on b have been suggested in [81,84]. For example, since b(z) has all
its roots on the unit circle, its coefﬁcients satisfy the conjugate symmetry constraint: bk = b∗
P−k,
k = 0, 1, . . . , P. Similar to EM and SAGE, the IQML algorithm converges to local maxima which
may or may not coincide with global optimal solution. The complexity of IQML algorithm is discussed
in [85]. The asymptotic performance is investigated in [86]. In [87] an efﬁcient implementation is
suggested for the IQML algorithm.

3.14.5 Parametric Methods
625
3.14.5.3 Subspace ﬁtting methods
The maximum likelihood approach exploits the parametric model and statistical distribution of array
observations fully and exhibits excellent performance. The subspace ﬁtting method [88–90] provides a
uniﬁed framework for the deterministic ML estimator and subspace based methods. More speciﬁcally,
it uses a nonlinear least square formulation
{ˆθ, 	T } = arg min
θ,T ∥M −A(θ)T∥2,
(14.87)
where M is a data matrix and T is any matrix of conformable dimension. For ﬁxed A(θ), the mini-
mization with respect with T measures how well the column spaces of M and A(θ) match. Replacing
the closed form solution 	T = A♯(θ)M back into (14.87) results in a concentrated criterion:
ˆθ = arg min
θ
tr(P⊥(θ)M M H).
(14.88)
Clearly, the deterministic ML estimator (14.61) can be obtained by using array observations as the data
matrix M = [x(1), . . . , x(N)].
The subspace ﬁtting criterion is derived when the estimated signal eigenvectors are inserted as data
M = 	Us. The weighted least square ﬁtting solution to (14.87) has the expression:
ˆθSSF = arg min
θ
tr

P⊥(θ)	UsW	U H
s

,
(14.89)
where the weighting matrix W is Hermitian and positive deﬁnite. The analysis in [89,90] shows that the
estimator ˆθSSF is strongly consistent and asymptotically normally distributed. Minimization of the error
covariance matrix of ˆθSSF leads to the optimal weighting matrix Wopt = 2−1
s
where  = s −σ 2I.
Recall that the diagonal matrix s contains P signal eigenvalues and σ 2 denotes the noise eigenvalue. In
practice, both s and σ 2 are estimated from data. The weighted subspace ﬁtting (WSF) algorithm (or the
method of direction estimation (MODE) [91]) is obtained when a consistent estimator 	
Wopt = 	
2	−1
s
is inserted into (14.89):
ˆθWSF = arg min
θ
tr(P⊥(θ)	Us	
2	−1
s 	U H
s ).
(14.90)
The signal subspace ﬁtting formulation (14.89) has certain advantages over the data-domain nonlinear
least square (14.87), in particular when P ≪M. It is then signiﬁcantly cheaper to compute (14.89)
than (14.87).
In addition to the criterion (14.89), a noise subspace ﬁtting formulation is developed in [91]. Although
the resulting criterion is quadratic in the steering matrix A(θ), the noise subspace ﬁtting criterion can
not produce reliable estimates in the presence of signal coherence. The covariance matching estimator
[92] that will be presented shortly can be formulated as (14.87).
The implementation of nonlinear least square type criteria (14.87) has been addressed in several
papers [64,77,93]. A common feature of these methods is similar to the SAGE algorithm in the sense
that instead of maximizing all parameters simultaneously, a subset of parameters, or the parameters
associated with one signal source is computed in one step while keeping other parameters ﬁxed. The
RELAX procedure [93] is similar to the SAGE algorithm (14.77) and (14.79), although it has a simpler

626
CHAPTER 14 DOA Estimation Methods and Algorithms
motivation and interpretation. The WSF (or MODE) criterion (14.90) can be formulated in terms of
polynomial coefﬁcients for ULAs by the expression (14.84) [91]. An iterative implementation, iterative
MODE, similar to IQML is suggested in [84]. Theoretical and numerical results in [84] show that
iterative MODE provides more accurate estimates and is computationally more efﬁcient than IQML.
3.14.5.4 Covariance matching estimation methods
The covariance matching estimation methods are referred to as generalized least squares in the statistical
literature. The application to array processing has led to several interesting algorithms [92,94–97].
Covariance matching can treat temporally correlated data and provides the same large sample properties
as maximum likelihood estimation at often a lower computational cost [92].
Recall that the array output covariance matrix is give by Rx = A(θ)Rs AH(θ) + σ 2I. By stacking
the columns of Rx, one obtains the following expression:
r = vec(Rx) = (θ)μ + 
σ 2 = [(θ)
]
 μ
σ 2

= (θ)α,
(14.91)
where the elements of μ are source signal covariance parameters, αT = [μT σ 2], 
 = vec(I) is a
known matrix, and (θ) is a given function of the unknown parameter vector θ. In general, the DOA
parameter vector θ enters (θ) in a nonlinear fashion. An estimate for r can be obtained from the
sample covariance matrix by ˆr = vec(	Rx). Fitting the data ˆr to the model (14.91) in the weighted least
squares sense leads to the following criterion
(ˆr −r)H 	
W−1(ˆr −r) =
	
W−1
2 ˆr −	
W−1
2 (θ)α

2
,
(14.92)
where the weighting matrix 	
W
=

R∗⊗	R is a consistent estimate of the covariance matrix
E(ˆr −r)(ˆr −r)H. The symbol ⊗denotes the Kronecker matrix product.
The least square criterion is separable in the linear and nonlinear parameters. Minimizing (14.92)
over the linear parameter vector α results in a closed form expression:
ˆα = [(θ)H 	
W−1(θ)]−1(θ)H 	
W−1ˆr.
(14.93)
Substituting (14.93) into (14.92) leads to a concentrated criterion:
ˆθ = arg min
θ
ˆr H 	
W−1
2 (I −P(θ))	
W−1
2 ˆr,
(14.94)
where P(θ) = 	
W−1
2 (θ)[(θ)H 	
W−1(θ)]−1(θ)H 	
W−1
2 denotes a projection matrix onto the
column space of 	
W−1
2 (θ). To apply (14.94), one needs to ﬁnd the matrix (θ) corresponding to
the covariance matrix of the array observations. Based on the extended invariance principle, it was
shown that the covariance matching estimator is a large sample realization of the ML method and
asymptotically efﬁcient [92]. A drawback of the covariance matrix matching based estimation methods
is that they inherently assume a large sample size, and are less suitable to scenarios involving a small
number of observations and high SNRs.

3.14.5 Parametric Methods
627
3.14.5.5 Performance bound
The performance of an estimator is measured by its average distance to the true parameters. In many
cases, one is interested in the following questions: (1) Whether it converges to the true parameter as
the number of data samples approaches inﬁnity. (2) Whether the asymptotic error covariance matrix
attains the Cramér-Rao bound (CRB). These two properties, consistency and efﬁciency, and the error
covariance matrix are major concerns in a performance study. In this section, we will outline several
important results. A comprehensive coverage on performance analysis is given in Chapter 14 in this
book.
It is well known that the estimation error covariance of any unbiased estimator is lower bounded by
the Cramér-Rao bound [54]. The Crámer-Rao bounds for the conditional and unconditional model are
derived in [98–100], respectively. The conditional CRB, denoted by Bc(θ) is given by
Bc(θ) = σ 2
2N
 N

n=1
Re

SH(n)H(θ)S(n)
−1
,
(14.95)
where S(n) = diag(s1(n), . . . , sp(n)), D(θ) = [d(θ1), . . . , d(θM)] contains the ﬁrst derivative of
steering vectors, d(θ) = da(θ)/dθ, and H(θ) = DH(θ)
 
I −A(θ)(AH(θ)A(θ))−1 AH(θ)
!
D(θ).
For N →∞, the conditional CRB tends to the limit
Bas
c (θ) = σ 2
2N
"
Re

H(θ) ⊙RT
s
#−1
.
(14.96)
The unconditional CRB, denoted by Bu(θ), is given by
Bu(θ) = σ 2
2N
"
Re

H(θ) ⊙(Rs A(θ)H R−1
x A(θ)Rs)T #−1
.
(14.97)
From (14.95) and (14.97), we can observe that the CRBs decrease with increasing number of snapshots.
Theoretical analysis and simulation results also show that the CRBs decrease as the number of sensors
or SNRs grow.
3.14.5.5.1
ML methods
The CRBs (14.95) and (14.97) are related as Bu(θ) ≥Bc(θ) in a positive deﬁnite sense. Because the
number of signal parameters s(n) increases with the number of snapshots, the conditional CRB can
not be attained by the conditional ML estimator. Under the unconditional data model, the parameter
vector remains ﬁnite dimensional when N →∞, the unconditional ML estimator is consistent and
achieves the unconditional CRB asymptotically. Let Cc and Cu denote the covariance matrix of the
conditional and unconditional ML estimators, respectively. The following inequality is proved in [100]:
Cc ≥Cu ≥Bu ≥Bc. In summary, the conditional ML estimator is consistent, but not efﬁcient;
whereas the unconditional ML estimator is both consistent and efﬁcient.
3.14.5.5.2
Subspace methods
The subspace methods are derived from signal—and noise eigenvector/eigenvalue estimates. Therefore,
statistical properties of the eigen-analysis of 	Rx [8] play an important role in the performance study.

628
CHAPTER 14 DOA Estimation Methods and Algorithms
The asymptotic distribution derived in [98] shows that the MUSIC algorithm is a consistent estimator.
Its covariance matrix may grow rapidly when some of the signal eigenvalues are close to the noise
eigenvalue. This scenario occurs when two signals are closely located or correlated, leading to an
almost rank deﬁcient A(θ). For uncorrelated signals, the MUSIC estimator exhibits good performance
comparable with the conditional ML estimator. The asymptotic performance of MUSIC is investigated
in [101]. A performance study of root-MUSIC can be found in [36,37]. Asymptotic analysis of ESPRIT
is carried out in [90,102].
3.14.5.6 Numerical examples
In this section, we compare the performance of conditional ML estimator and root-MUSIC algorithm
in a simulated environment. A ULA of 12 elements with half wavelength spacing is employed to
receive two far-ﬁeld narrow band signal sources of equal strengths located at θ = [20◦30◦]. The
sample covariance matrix is estimated from N = 200 snapshots. Each experiment performs 500 Monte
Carlo trials.
The RMSEs for DOA estimates and the conditional CRB (14.95) for uncorrelated and correlated
signals are depicted in Figures 14.8 and 14.9, respectively. For the uncorrelated case, ML performs
slightly better than root-MUSIC; in particular, at low SNR between −5 and 5 dB. In the correlated case
−5
0
5
10
15
20
10−2
10−1
100
SNR(dB)
RMSE(deg)
R−MUSIC
Conditional CRB
DML
Performance of DOA Estimation
FIGURE 14.8
RMSE vs. SNR. Uncorrelated signals. Reference DOA parameter θ = [20◦30◦], N = 200.

3.14.5 Parametric Methods
629
−5
0
5
10
15
20
10
−2
10
−1
10
0
10
1
SNR(dB)
RMSE(deg)
R−MUSIC
FB−R−MUSIC
DML
conditional CRB
Performance of DOA Estimation
FIGURE 14.9
RMSE vs. SNR. Correlated signals. Reference DOA parameter θ = [20◦30◦], N = 200.
with the correlation coefﬁcient ρ = 0.92, while the deterministic ML estimator performs as well as
in the uncorrelated case and close to the CRB, root-MUSIC no longer provides reliable estimates. As
can be observed from Figure 14.9, even for SNR as high as 10 dB, root-MUSIC has RMSE larger than
2◦. The difference between ML and root-MUSIC is most signiﬁcant at low SNRs. In other words, the
ML estimator is more robust than root-MUSIC against signal correlation and low SNRs. Although the
performance of root-MUSIC is improved by forward-backward averaging, the RMSE is still larger than
the ML approach. For SNR below 0 dB, it is twice as much as that of ML.
As mentioned previously, the ML estimator requires multi-dimensional nonlinear optimization. We
compare three different implementations: (1) matlab function fmincon, (2) EM algorithm, (3) SAGE
algorithm. The initial estimates for (1). are found by the genetic algorithm. The initial estimates for EM
and SAGE are ﬁxed at θ(0) = [16◦34◦] to simplify the investigation of their convergence behavior.
Figure 14.10 shows that all three methods ﬁnd ML estimates and achieve the same accuracy. To compare
the convergence behavior of EM and SAGE, we plot the average log-likelihood value vs. iterations in
Figure 14.11. As the convergence analysis in [74] predicted, SAGE converges faster than EM. It requires
only 6 iterations to reach the ﬁnal likelihood value, while EM requires 15 iterations. This is further
conﬁrmed by the average total number of iterations shown in Figure 14.12. As we can observe, at SNR
from −10 dB to 5 dB, EM needs more than twice iterations than SAGE. For moderate to high SNR,
the number of iterations of EM always exceeds that of SAGE by at least six iterations. This suggests

630
CHAPTER 14 DOA Estimation Methods and Algorithms
-5
0
5
10
15
20
10
−1
SNR(dB)
RMSE(deg)
EM
SAGE
ML
EM
Performance of DOA Estimation
FIGURE 14.10
RMSE vs. SNR. EM, SAGE, ML with Newton methods. Uncorrelated signals. Reference DOA parameter
θ = [20◦30◦], SNR = [00] dB, N = 200.
0
5
10
15
20
25
30
0.5
0.55
0.6
0.65
0.7
0.75
0.8
EM
Convergence of log-likelihood versus iterations
Mean of log-likelihoods 
Number of iterations
SAGE
FIGURE 14.11
Log-likelihood vs. iterations. Uncorrelated signals. Reference DOA parameter θ = [20◦30◦], SNR = [0 0] dB,
N = 200.

3.14.6 Wideband DOA Estimation
631
−10
−5
0
5
10
15
20
0
5
10
15
20
25
30
35
40
SNR(dB)
EM
SAGE
Number of iterations
Number of iterations to reach local maxima
FIGURE 14.12
Number of iterations vs. SNR. Uncorrelated signals. Reference DOA parameter θ = [20◦30◦],N = 200.
that EM requires 60% more computational time than SAGE. It should be mentioned that the genetic
algorithm [67] requires more than 10 times as long computational time compared to SAGE.
3.14.6 Wideband DOA estimation
The DOA estimation methods presented previously are suitable for narrow band signals that often occur
in communications and radar systems. In applications like sonar or seismic monitoring, the signals are
often broadband. The important issue for the wideband case is how to combine multiple frequencies
in an optimal way. For the maximum likelihood approach, the extension is straightforward because of
the asymptotic properties of the Fourier transform [3,76,103]. Since the signal subspace is different for
various frequencies, subspace methods require a pre-processing procedure to form a coherent averaging
of the signal subspace as suggested in [104,105]. Another approach is to evaluate the spectral matrix
and derive estimates from each frequency and then combine these estimates in some appropriate way
[106]. Numerical results show that the former coherent approach provides better estimates than the latter
one. In the following, we will describe the wideband version of the ML estimators and then discuss the
coherent signal subspace method.

632
CHAPTER 14 DOA Estimation Methods and Algorithms
3.14.6.1 Wideband maximum likelihood estimation
In Section 3.14.2.2.1, the data model (14.10) was developed for a continuous temporal array output
x(t). In practice, the array outputs are temporally sampled at a properly chosen frequency. The data
within an observation interval x(1), . . . , x(N) is divided into K non-overlapping snapshots of length
N ′ = N/K and Fourier-transformed. For large number of samples, the frequency domain data Xk(ω)
can be modeled by (14.10). Under some regularity conditions including stationarity of array outputs,
the following asymptotic properties hold [107]:
1. X1(ω), . . . , X K (ω) are independent, identically complex normally distributed with zero mean and
covariance matrix RX(ω) = A(ω, θ)Rs(ω)A(ω, θ)H + Rn(ω).
2. For 0 < ω1, . . . , < ωJ < π, Xk(ω1), . . . , Xk(ωJ) are stochastically independent.
3. Given the signal vector Sk(ω) = [Sk
1(ω), . . . , Sk
p(ω)]T , Xk(ω) is complex normally distributed with
mean A(ω, θ)Sk(ω) and covariance matrix Rn(ω).
In the following, we assume that Rn(ω) = σ 2(ω)I. Because of the independency between differ-
ent frequency bins, the likelihood function is a product of those associated with various frequencies.
For the deterministic data model, the log-likelihood function is given by
Lw,d(θ, Sw,d, σ 2w,d) = −
J

j=1
K

k=1

N log π + N log σ 2(ω j)
+
1
σ 2(ω j)
Xk(ω j) −A(ω j, θ)Sk(ω j)

2
,
(14.98)
where the signal vector Sw,d and noise vector σ 2
w,d contain signal and noise parameters of J frequencies.
Similar to the narrow band case, the likelihood function can be concentrated with respect to the signal
and noise parameters, leading to the concentrated likelihood function
Lw,d(θ) = −
J

j=1
log tr

P⊥(ω j, θ)	Rx(ω j)

,
(14.99)
where the sample covariance matrix 	Rx(ω j) =
1
K

K
k=1 Xk(ω j)Xk(ωk)H and P⊥(ω j, θ) is the
orthogonal complement of the projection matrix P(ω j, θ) = A(ω j, θ)A#(ω j, θ). Note that the sum-
mand in (14.99) has the same form as the narrow band likelihood function (14.61). The broadband
criterion can be considered as an arithmetic average of narrow band likelihood functions over fre-
quencies. The deterministic ML estimate is computed by maximizing this criterion or minimizing the
negative log-likelihood:
ˆθ W,DML = arg min
θ
−Lw,d(θ).
(14.100)
For the stochastic signal model, the log-likelihood function is given by
Lw,s(θ, Sw,s, σ w,d) = −K
J

j=1

M log π + log det Rx(ω j) + tr(Rx(ω j)−1	Rx(ω j))

,
(14.101)

3.14.6 Wideband DOA Estimation
633
where Sw,s contains signal spectral parameters of all frequencies and σ w,d includes noise power
parameters. Similar to the narrow band case, the stochastic likelihood function can be simpliﬁed by
substituting ML estimates of signal and noise parameters into (14.101), leading to the concentrated
criterion:
Lw,s(θ) = −
J

j=1
log det

P(ω j, θ)	Rx(ω j)P(ω j, θ) + ˆσ 2(ω j)P⊥(ω j, θ)

.
(14.102)
where ˆσ 2(ω j) =
1
N−M tr(P⊥(ω j, θ)	Rx(ω j)) is an estimate for the noise parameter. Similar to the deter-
ministic case, (14.102) is an average of the narrow band likelihood criterion (14.61) over frequencies.
The stochastic ML estimator is then obtained by maximizing this criterion or minimizing the negative
likelihood:
ˆθ W,SML = arg min
θ
−Lw,s(θ).
(14.103)
The performance analysis in [66] shows that under regularity conditions, ˆθ W,SML is an asymptot-
ically consistent, efﬁcient estimator for θ. The deterministic ML estimator ˆθ W,DML is asymptotically
consistent, but not efﬁcient. The computation complexity can be also simpliﬁed by the EM or EM-like
algorithms [74,76].
3.14.6.2 Coherent signal subspace methods
The coherent signal subspace methods proposed in [105] combine the broadband data by multiplying
each frequency with the focusing matrix T(ω j) satisfying the following property
T(ω j)A(ω j, θ) = A(ω0, θ),
(14.104)
where ω0 is a selected reference frequency. The coherently averaged covariance matrix Ry is given by
Ry =
J

j=1
T(ω j)Rx(ω j)T(ω j)H =
J

j=1
T(ω j)Rs(ω j)T(ω j)H + ˜σ 2Rn,
(14.105)
where ˜σ 2 is the sum of noise level over frequencies and Rn = 
J
j=1
σ 2(ω j)
˜σ 2
T(ω j)T(ω j)H. Given the
known noise structure Rn, the eigenvalue/eigenvector pairs of Ry satisfy the same properties (14.36),
(14.37) as in the narrow band case. Hence, the subspace methods introduced previously can be applied
to the new matrix (14.105).
The design of (14.104) requires a rough estimate of the DOA parameter, which can be obtained from
the narrow band MVDR or conventional beamformer. In [104], the rotational signal subspace focusing
matrix is developed by solving the constrained optimization problem:
min
T(ω j) ∥A(ω0, θ) −T(ω j)A(ω j, θ)∥F,
j = 1, . . . , J
(14.106)
subject to
T(ω j)H T(ω j) = I.
(14.107)

634
CHAPTER 14 DOA Estimation Methods and Algorithms
The solution to (14.106) is given by T(ω j) = V(ω j)U(ω j)H, where the columns of V(ω j) and
U(ω j) are left and right singular vectors of A(ω0, θ)A(ω j, θ)H. The selection of reference frequency
and accuracy improvement are discussed in detail in [104,105]. Within the class of signal subspace
transformation matrices, the rotational subspace transformation matrix is well known for their optimality
in preserving SNR after focusing [108]. In practice, the spatial correlation matrix Rx is replaced by
the sample covariance matrix 	Rx. By (14.105), we compute the coherently averaged sample covariance
matrix 	Ry and construct coherent signal/noise subspaces from 	Ry. Then standard subspace methods
are applied with ω0 as the reference frequency for DOA estimation.
In [109], coherent subspace averaging is achieved by using weighted signal subspaces
Us(ωi)Pi P H
i Us(ωi)H instead of the array correlation matrix Rx(ω j) in (14.105), where Us(ωi) con-
tains signal eigenvectors at frequency ωi and Pi is a weighting matrix. While the aforementioned
methods concentrates on the design of the best coherently averaged signal subspaces and ﬁnding the
DOA estimates by standard narrow band eigenstructure based algorithms such as MUSIC, the test
of orthogonality of projected subspaces (TOPS) algorithm proposed in [110] utilizes the property of
transformed signal subspaces and test whether the hypothesized subspaces and the noise subspaces are
orthogonal. A signiﬁcant advantage of this approach is that it does not require initial DOA estimates.
Simulation results in [110] show that TOPS performs better than the aforementioned methods in mid
SNR ranges, while the coherent methods work best at low SNR and incoherent methods work best at
high SNR.
3.14.7 Signal detection
Estimation of the number of signals is fundamental to array processing algorithms. It is usually the
ﬁrst step in the application of direction ﬁnding algorithms. In the previous discussion, we assumed
that the number of signals, P, is known a priori. In practice, the number of signals needs to be esti-
mated from measurements as well. Popular approaches for determining the number of signals can be
classiﬁed as nonparametric or parametric methods. The former utilizes the eigenstructure of the array
correlation matrix (14.13) and estimates the dimension of the signal subspace by employing the infor-
mation theoretic criteria [10,111–113] or hypothesis tests [63,114,115]. Parametric methods exploit
the array output model (14.12) and jointly estimate the parameter and number of signals [65,116–118].
The nonparametric approach is computationally simple but sensitive to signal coherence and small
data samples. The parametric approach requires more time for parameter estimation, but performs
signiﬁcantly better than the nonparametric one in critical scenarios. In the following, we will describe
the ideas behind the aforementioned methods brieﬂy and give more related references.
3.14.7.1 Nonparametric methods
We have learned in subspace methods that the array correlation matrix (14.13) has the eigen-
decomposition Rx = UssU H
s + UnnU H
n where the diagonal matrix s consists of the P largest
eigenvalues and Us contains corresponding eigenvectors. The remaining M −P eigenvalues/vectors
are included in n and Un in a similar way. When the signal covariance matrix Rs is full rank, the

3.14.7 Signal Detection
635
eigenvalues satisfy the property
λ1 ≥λ2 ≥· · · ≥λP > λP+1 = · · · = λM = σ 2.
(14.108)
The smallest (M −P) noise eigenvalues are equal to σ 2. This observation suggests that the number of
signals can be determined from the multiplicity of the smallest eigenvalue. In practice, the correlation
matrix Rx is unknown and the eigenvalues are estimated from the sample covariance matrix 	Rx. The
ordered sample eigenvalues ˆλi, i = 1, . . . , M are distinct with probability one [8].
The sphericity test, originating from the statistical literature [119], is modiﬁed for detection purpose
in [115]. Therein, a series of nested hypothesis tests is formulated to test the equality of (M −i),
i = 0, . . . , M −1 eigenvalues, i.e.,
Hi : λ1 ≥λ2 ≥· · · ≥λi > λi+1 = · · · = λM,
(14.109)
Ai : λ1 ≥λ2 ≥· · · ≥λi > λi+1 > λM,
where Hi and Ai denote the null hypothesis and alternative, respectively. Starting from i = 0, the test
proceeds to the next hypothesis if Hi is rejected. Upon acceptance of Hi, the test stops, implying all
remaining tests are true and leading to the estimate 	P = i. For non-Gaussian distribution and small
samples case, the test statistic does not have a closed form expression for null distribution. To overcome
this problem, a procedure using bootstrap techniques are developed in [114]. The test for unknown noise
ﬁelds is suggested in [120]. Recently, due to the development of random matrix theory, the eigenvalue
based multiple test is re-visited for the small sample case in [121,122] and the references therein.
Theinformationtheoreticcriteriabasedapproachviewssignaldetectionasmodelorderselection.The
Akaike’s information criterion (AIC) and Rissanen’s minimum description length (MDL) was derived
for signal detection in [111]. In the derivation, the data set {x(1), . . . , x(N)} is parameterized by the
eigenvalues and eigenvectors of correlation matrix Rx, rather than the DOA parameter. Maximization
of the log-likelihood function leads to the AIC criterion
AIC(i) = −N log
⎡
⎢⎣
M
l=i+1ˆλl

1
M−i

M
l=i+1 ˆλl
M−i
⎤
⎥⎦+ i(2M −i),
(14.110)
and the MDL criterion
MDL(i) = −N log
⎡
⎢⎣
M
l=i+1ˆλl

1
M−i

M
l=i+1 ˆλl
M−i
⎤
⎥⎦+ 1
2i(2M −i) log N.
(14.111)
The number of signals 	P is determined as the minimizing value i ∈{0, 1, . . . , Pmax} of AIC or MDL,
where Pmax ( ≤M −1) denotes the maximal number of signals. Eqs. (14.110) and (14.111) show that
both criteria has the ﬁrst term in common, which is a ratio between geometric mean and arithmetic
mean of the smallest (M −i) eigenvalues. The penalty term of AIC depends only on the number
of free adjustable parameters, while the penalty term of MDL depends also on the data length N. In
general, AIC tends to overestimate the number of signals while MDL is consistent as the number of

636
CHAPTER 14 DOA Estimation Methods and Algorithms
samples approaches inﬁnity [111,123]. Various improvement strategies for MDL for situations involving
fully correlated signals, correlated noise and small samples have been suggested in [112,124–127] and
references therein.
3.14.7.2 Parametric methods
In parametric methods, the DOA parameter in the model (14.12) enters the algorithms directly. Deter-
mination of the number of signals can be formulated as a multiple hypothesis test. In the multiple
hypothesis test approach, we consider a series of nested hypotheses.
Hi : x(n) = Ai−1(θi−1)si−1(t) + n(n) (data contains at most (i−1) signals),
Ai : x(n) = Ai(θi)si(n) + n(n)
(data contains at least i signals).
(14.112)
The subscripts (i −1) and i are used to emphasize the dimension of the steering matrix and the signal
vector under the null hypothesis Hi and the alternative Ai, respectively. Here, the signal vectors are
considered as unknown and deterministic.
In [116,118,128], a sequential test procedure is developed to detect the signal one after another.
Starting from noise only case, i = 0, Hi is tested against Ai. If Hi is rejected, a new signal is declared
as detected and the test procedure proceeds to the next hypothesis Hi+1. It stops when the null hypothesis
is accepted, implying that no further signal can be detected. The number of signals is then estimated by
the dimension of the signal vector under the accepted null hypothesis. The test statistics are constructed
by the generalized likelihood ratio principle. In the narrow band case, it leads to an F-test similar to
that suggested in [129]. For broadband data, a closed form expression for the null distribution is not
available. In this case, bootstrap techniques or Edgeworth expansions can be applied to approximate
the signiﬁcance level or test threshold. The global signiﬁcance level in the sequential test procedure is
usuallycontrolledbyBonferroni-typeprocedures. As eachtest is conductedat amuchlower level, results
may be conservative when the size of the problem increases. A more powerful test procedure based on
the false discovery rate criterion is developed in [117]. A joint estimation and detection procedure was
also investigated in [65].
Simulation shows that the multiple hypothesis approach has superior performance than information
theoretic approach [117]. In particular, signal coherence has little impact on the performance. Due to ML
estimates required in the test, parametric methods are computationally more expensive than eigenvalue
based methods.
3.14.7.3 Additional issues
When the estimated number of signals, 	P, provided by detection algorithms is accurate, the performance
of DOA estimation is well studied in the literature. In the low SNR region and small sample case, the
number of signals may be over- or underestimated. In the presence of overestimated signals, the true
DOA parameters are included in the oversized parameter vector with increased variance for the true
parameters. In the case of under estimation, the inaccuracy in signal numbers will lead to bias and
increased mean squared errors [130]. Robust algorithms have been suggested in [131,132] to retrieve
information when the number of signals is unknown.

3.14.8 Special Topics
637
3.14.8 Special topics
We have presented DOA estimation algorithms assuming far-ﬁeld propagation and static sources. In
practice, these conditions may change and require modiﬁcation to standard algorithms. In the following,
we will discuss several interesting issues and provide related references.
3.14.8.1 Tracking
Localization of moving sources is essential to many applications. In the classical tracking problem, the
DOA estimates obtained from array data are considered as input data for track estimation. The main task
is to match DOA estimates and to contacts, and many solutions have been developed to solve the data
association problem [133,134]. An alternative approach incorporates target motion into the likelihood
function and estimates the DOA parameter, and velocity directly from data [135–137]. In [138,139],
the EM algorithm is suggested to reduce the computational cost for maximizing the likelihood function.
To further simplify the implementation, the recursive EM algorithm is developed in [128,140]. The
recursive EM algorithm is a stochastic approximation procedure for ﬁnding ML estimates [141]. With
a specialized gain matrix derived from the EM algorithm, it has a simple implementation and leads to
asymptotic normality and consistency. With a proper formulation, it can also be used for estimating
time varying DOA parameters.
Forsubspacemethods,howtocomputethetime-varyingsignalornoisesubspacesefﬁcientlybecomes
the most important step. In early works, classical batch Eigenvalue Decomposition/SVD techniques
have been modiﬁed for the use in adaptive processing. Fast computation methods based on subspace
averaging were proposed in [142–144]. Another class of algorithms considers ED/SVD as a constrained
or unconstrained optimization problem [145–149]. For example, in [149], it is shown that the signal
subspace can be computed by solving the following unconstrained optimization problem:
min E

∥x(n) −WW H x(n)∥2
,
(14.113)
where W ∈CM×r denotes the matrix argument and r is the number of signal eigenvectors. The aim of
subspace tracking is to compute W efﬁciently at the time instant n from the subspace estimate at time
instant (n −1). For time-varying subspaces, the expectation in (14.113) is replaced by an exponentially
weighted sum of snapshots to ensure the samples in the distant past is down weighted. In addition to low
computational complexity, fast convergence and numerical stability are also desired properties in the
implementation of subspace tracking techniques. Once the subspace estimates are updated, the DOA
estimates are computed by subspace methods presented previously.
3.14.8.2 Signals with known structures
In some applications, the source signals exhibit speciﬁc structures and can be exploited for DOA estima-
tion. For example, in communication systems, modulated signals are characterized by cyclostationarity,
which is referred to as being periodically correlated. This property allows estimation of DOAs of only
those signals having speciﬁed cycle frequency. Also, the noise can have unknown spatial characteristics
as long as it is cyclically independent from signals of interest. Several direction ﬁnding algorithms were
suggested and analyzed in [150–154].

638
CHAPTER 14 DOA Estimation Methods and Algorithms
In standard array processing methods, array data are assumed to be Gaussian and completely char-
acterized by second order statistics. In the presence of non-Gaussian signals, higher order statistics
can be exploited to the advantage of Gaussian noise suppression and increased aperture [155–158].
A common feature of both types of methods is the requirement of large amount of data samples to
achieve comparable results as standard algorithms.
3.14.8.3 Spatially correlated noise ﬁelds
Most existing array processing methods assume that the background noise is spatially white, i.e., the
covariance matrix is proportional to the identity matrix. This assumption is often violated in practical
situations [159]. If the noise covariance matrix is known or estimated from signal-free measurements,
the data can be pre-whitened. In the absence of this knowledge, the quality of DOA estimates degrade
dramatically at low SNR [160,161].
Methods that take small errors in the assumed noise covariance into account are proposed in [63,
162,163]. These algorithms are not applicable when the noise covariance is completely unknown,
unless SNR is very high. Another approach considers parametric noise models and estimates DOA
and noise parameters simultaneously [56,164,165]. In this approach, the additional noise parameters
require extra computational time and increase variances of DOA estimates. In [166–168], the effect
of unknown correlated noise is alleviated by the covariance differencing technique. The instrumental
variables based approach is proposed in [169,170]. This technique relies on the assumption that the
emitter signals are temporally correlated with correlation time signiﬁcantly longer than that of the noise.
Other solutions include exploitation of prior knowledge of signals [171] or speciﬁc array conﬁgurations
[172]. In [171], the signal waveform is expressed as a linear combination of known basis functions. This
assumption is reasonable in applications like radar and active sonar. The algorithm developed therein is
a good example showing that knowledge of the spatially colored noise can be traded against alternative
a priori information about signals.
3.14.8.4 Beamspace processing
The computational complexity for DOA estimation grows rapidly with data dimension, i.e., the number
of sensors. In many applications like radar, arrays may have thousands of elements [4,173]. Methods
for reducing the data dimension without loss of information are important to these scenarios. Motivated
by the idea of beamforming, the beamspace processing employs a linear transformation to the outputs
of the full sensors of the array
z(n) = T H x(n),
(14.114)
where T is an orthonormal M × R, (R < M) transformation matrix. The columns of T correspond
to beamformers within a narrow DOA sector. The design of the transformation matrix is achieved by
maximizing the average signal-to-noise ratio [174], selection of spatial sector [175] or minimizing
error variances [176]. The beamspace processing may improve estimation performance by ﬁltering out
interferences outside the sector of interest and relax the assumption of white noise to local whiteness. As
indicated in [177,178], the resolution threshold of the MUSIC algorithm can be lowered in beamspace.
With prior knowledge on the true DOA parameter, it is possible to theoretically attain the Crámer-Rao
bound by proper choice of the transformation matrix [176].

3.14.8 Special Topics
639
The adoption of beamspace processing into MUSIC and ESPRIT algorithms is addressed in [179]
and references therein. It is interesting to observe that the array response vector becomes T H a(θ) after
the transformation (14.114). This allows a simpler expression of array manifold vector and facilitates
the application of root-MUSIC and ESPRIT in the 2D case [180]. As pointed out in [180], beamspace
transformation has a close link to array interpolation. The interpolated array scheme proposed by
Friedlander and Weiss [38] employs a linear transformation to map the manifold vectors for an arbitrary
array onto ULA-type response vectors. The ﬁeld of view of the array is divided into L sectors, deﬁned
by [θ(1)
l
, θ(2)
l
](l = 1, . . . , L). Then a set of angles is selected for each sector,
l =

θ(1)
l
, θ(1)
l
+ 	θ, θ(1)
l
+ 2	θ, . . . , θ(2)
l

.
(14.115)
Let A(l) and A(l) denote the array response matrix of the real array and the virtual array with desired
response, respectively. An interpolation matrix is computed for each sector as the least square solution
such that ∥Bl Al −¯Al∥F is minimized. One may use a weighted least square formulation to improve
interpolation accuracy. In [181], an MSE design criterion is suggested to reduce DOA estimation bias
caused by array interpolation. An interesting observation is the duality between array interpolation and
coherent signal space averaging introduced in Section 3.14.6.2. The former designs the mapping matrix
based on the spatially sampled frequencies, while the latter based on samples in the temporal frequency
domain. Both techniques are useful for increasing applicability of computationally efﬁcient subspace
methods.
3.14.8.5 Distributed sources
In several array processing applications, such as radio communications, underwater acoustics and radar,
physical measurements show that the effects of angle spread should be taken into account in the mod-
eling. This appears in wireless communications, for example, an elevated base station experiences the
received signal as distributed in space due to local scattering around the mobile [182,183]. The array
output in distributed source modeling can be expressed as x(n) = 
P
i=1 si(n) + n(t), where si(n)
describes the contribution of the ith signal to the array output. Unlike in the point source modeling
where si(n) = si(n)a(θi), the source energy is spread over some angular volume and is written as
[184–186]
si(n) =
$
θ∈
˜si(θ, ψi, n)a(θ)dθ,
(14.116)
where ˜si(θ, ψi, n) is the angular signal density of the ith source, ψi contains location parameters of
the ith source and  is the angular ﬁeld of view. Examples for ψi are the two bounds of a uniformly
distributed source or mean and standard deviation of source with Gaussian angular distribution. The
problem of interest here is to estimate the unknown parameter vector ψi.
Forsmallangularspread,thedistributedsourcemodeling(14.116)usuallyleadstoasignalcovariance
matrix of the form
Rsi = a(θ0)a(θ0)H ⊙B,
(14.117)
where the matrix B is a fully occupied matrix with elements depending on the array shape and sig-
nal distribution. As a result, the rank of the signal covariance matrix Rs = 
P
i=1 Rsi is equal to the

640
CHAPTER 14 DOA Estimation Methods and Algorithms
number of sensors M. This implies that a separation between signal subspace and noise subspace is not
possible. To overcome this difﬁculty, a number of approaches based on subspace methods have been
suggested. In [187], the signal subspace is approximated by eigenvectors associated with dominant
eigenvalues. In [185,186], a generalized subspace in Hilbert space is deﬁned to preserve the eigenstruc-
ture as in the point source modeling. Based on an approximation of the signal covariance matrix, a
root-MUSIC algorithm is derived in [188]. In [189], the property of the inverse of the covariance matrix
is exploited to establish the orthogonality between signal and noise subspace. Performance bounds and
analysis of subspace methods in the context of distributed sources are considered in [190,191].
Note that the distributed source modeling also affects the design of the adaptive beamformer as the
distortionless constraint (14.27) no longer holds. In [185], a generalized minimum variance beamformer
is proposed by considering total distributed energy of the signal. The resolution of [185] is found
superior to [186–188] in simulation. While the above mentioned methods are mostly semiparametric,
parametric methods based on ML approach and covariance matching techniques are derived in [97] and
[94], respectively. Through the application of the extended invariance principle, the high computational
complexity often encountered by the parametric approach is signiﬁcantly lowered in [94].
3.14.8.6 Polarization sensitivity
Most direction ﬁnding algorithms presented before consider sensor arrays in which the output of each
sensor is a scalar response to, for example, acoustic pressure or one component of the electric or magnetic
ﬁelds. As the array manifold depends only on the direction of arrival, one is able to retrieve the spatial
signature of the emitting signals without estimating polarization parameters. Polarization is an important
property of electromagnetic waves. In wireless communications, polarization diversity has played a key
in antenna design [192]. The transverse components of the electric or magnetic ﬁelds are related through
polarization parameters. Due to this additional information, the DOA estimation performance can be
improved by polarization sensitive antenna arrays. In [193], an extension of MUSIC is suggested for
polarization sensitive arrays. The subspace ﬁtting method, ML based approach and ESPRIT algorithm
were developed for diversely polarized signals [61,194–199], respectively. A performance study can be
found in [200,201].
A complete data model for vector sensors that characterizes all six components of the electromag-
netic ﬁelds is suggested in [202]. Therein, it is shown that in contrast to scalar sensor arrays, DOA
estimation is possible using only one single vector sensor. Identiﬁability and uniqueness issues related
to vector sensors have been investigated in [203,204]. Other interesting applications including seismic
localization, acoustics, and biomedical engineering have been discussed in [205–208].
3.14.9 Discussion
The problem of estimating the direction of arrival using an array of sensors has been discussed in detail
in this contribution. Starting with the beamforming approach, we have presented eigenstructure based
subspace methods and parametric methods. The spectral analysis based beamforming techniques are
essentially spatial ﬁlters and requires least computational effort. Subspace methods achieve high reso-
lution and estimation accuracy at an affordable computational cost. Parametric methods exploit the data
model fully, and are characterized by excellent statistical properties and robustness in critical scenarios

References
641
at the expense of increased computations. Selection of suitable algorithms depends on the underlying
propagation environment, required accuracy and processing speed, available software and hardware.
For simplicity, the essential DOA estimators are presented in the context of narrow band data. Tech-
niques for processing broadband data are treated separately. Methods for signal detection are included
in a separate section. Despite the richness of theoretical and experimental results in array processing,
technological innovation and theoretical advances have shifted the research focus to application spe-
ciﬁc methods. To reﬂect this trend, we selected several topics including tracking, structured signals,
correlated noise ﬁeld, beamspace processing, distributed sources, and vector sensors for discussion.
The materials covered in this article are presented in a tutorial style, trying to serve the ﬁrst exposure
and as a tour guide into this exciting area. References listed here are by no means complete, but in the
hope to assist interested readers for further study. More specialized aspects of array processing will be
treated in detail by other contributing authors of this series. Their works are particularly valuable to
ﬁll the gap between this rather introductory review and in-depth knowledge. Finally, we feel extremely
grateful to all researchers that have enriched the area of array processing and made this article possible.
Acknowledgments
The authors would like to thank Prof. Johann F. Böhme and Prof. Jean-Pierre Delmas for their valuable comments
and suggestions that signiﬁcantly improve this paper.
Relevant Theory: Statistical Signal Processing and Signal Processing
See Vol. 1, Chapter 4 Random Signals and Stochastic Processes
See Vol. 1, Chapter 11 Parametric Estimation
See this Volume, Chapter 2 Model Order Selection
See this Volume, Chapter 8 Performance Analysis and Bounds
References
[1] J. Capon, High resolution frequency wave number spectrum analysis, Proc. IEEE 57 (1969)
1408–1418.
[2] R.O. Schmidt, Multiple emitter location and signal parameter estimation, IEEE Trans. Antennas Propag. 34
(3) (1986) 276–280.
[3] J.F. Böhme, Array processing, in: S. Haykin (Ed.), Advances in Spectrum Analysis and Array Processing,
Prentice Hall, Englewood Cliffs, NJ, 1991, pp. 1–63.
[4] H. Krim, M. Viberg, Two decades of array signal processing research: the parametric approach, IEEE Signal
Process. Mag. 13 (4) (1996) 67–94.
[5] B.D. Van Veen, K.M. Buckley, Beamforming: a versatile approach to spatial ﬁltering, IEEE Acoust. Speech
Signal Process. Mag. (1988) 4–24.
[6] D.H. Johnson, D.E. Dugeon, Array Signal Processing: Concepts and Techniques, Prentice Hall, 1993.
[7] H.L. Van Trees, Optimum Array Processing (Detection, Estimation, and Modulation Theory, Part IV), Wiley,
New York, 2002.
[8] T.W. Anderson, An Introduction to Multivariate Statistical Analysis, third ed., Wiley, 2003.
[9] Y. Bresler, A. Macovski, On the number of signals resolvable by a uniform linear array, IEEE Trans. Acoust.
Speech Signal Process. ASSP-34 (1986) 1361–1375.

642
CHAPTER 14 DOA Estimation Methods and Algorithms
[10] M. Wax, I. Ziskind, On unique localization of multiple sources by passive sensor arrays, IEEE Trans. Acoust.
Speech Signal Process. 37 (7) (1989) 996–1000.
[11] R.T. Lacoss, Data adaptive spectral analysis methods, Geophysics 36 (71) 661–675.
[12] J. Li, P. Stoica, Z. Wang, On robust Capon beamforming and diagonal loading, IEEE Trans. Signal Process.
51 (7) (2003) 1702–1715.
[13] G. Borgiotti, L. Kaplan, Superresolution of uncorrelated intereference sources by using adaptive array tech-
niques, IEEE Trans. Antennas Propag. 27 (3) (1979) 842–845.
[14] M-X Huang, J.J. Shih, R.R. Lee, D.L. Harrington, R.J. Thoma M.P. Weisend, F. Hanlon, K.M. Paulson,
T. Li, K. Martin, G.A. Miller, J.M.Canive, Commonalities and differences among vectorized beamformers
in electromagnetic source imaging, Brain Topogr. 16 (2004) 139–158.
[15] C. Vaidyanathan, K.M. Buckley, Performance analysis of the MVDR spatial spectrum estimator, IEEE Trans.
Signal Process. 43 (6) (1995) 1427–1437.
[16] A. Luthra, A solution to the adaptive nulling problem with a look-direction constraint in the presence of
coherent jammers, IEEE Trans. Antennas Propag. 34 (5) (1986) 702–710.
[17] N.L.
Owsley,
An
overview
of
optimum
adaptive
control
in
sonar
array
processing,
in:
K.S. Nardendra, R.V. Monopoli (Eds.), Applications of Adaptive Control, Academic Press, New York,
1980, pp. 131–164.
[18] V. Reddy, A. Paulraj, T. Kailath, Performance analysis of the optimum beamformer in the presence of
correlated sources and its behavior under spatial smoothing, IEEE Trans. Acoust. Speech Signal Process. 35
(7) (1987) 927–936.
[19] T.J. Shan, T. Kailath, Adaptive beamforming for coherent signals and interference, IEEE Trans. Acoust.
Speech Signal Process. 33 (3) (1985) 527–536.
[20] C.-J. Tsai, J.-F. Yang, T.-H. Shiu, Performance analyses of beamformers using effective SINR on array
parameters, IEEE Trans. Signal Process. 43 (1) (1995) 300–303.
[21] M.D. Zoltowski, On the performance analysis of the MVDR beamformer in the presence of correlated
interference, IEEE Trans. Acoust. Speech Signal Process. 36 (6) (1988) 945–947.
[22] C.D. Richmond, Response of sample covariance based MVDR beamformer to imperfect look and inhomo-
geneities, IEEE Signal Process. Lett. 5 (12) (1998) 325–327.
[23] S.A. Vorobyov, A.B. Gershman, Z.-Q Luo, Robust adaptive beamforming using worst-case performance
optimization: a solution to the signal mismatch problem, IEEE Trans. Signal Process. 51 (2) (2003)
313–324.
[24] J.-J. Fuchs, On the application of the global matched ﬁlter to DOA estimation with uniform circular arrays,
IEEE Trans. Signal Process. 49 (4) (2001) 702–709.
[25] D. Malioutov, M. Cetin, A.S. Willsky, A sparse signal reconstruction perspective for source localization with
sensor arrays, IEEE Trans. Signal Process. 53 (8) (2005) 3010–3022.
[26] J.A. Tropp, Just relax: convex programming methods for identifying sparse signals in noise, IEEE Trans.
Info. Theory 52 (3) (2006) 1030–1051.
[27] M.M. Hyder, K. Mahata, Direction-of-arrival estimation using a mixed l2 norm approximation, IEEE Trans.
Signal Process. 58 (9) (2010) 4646–4655.
[28] J. Yin, T. Chen, Direction-of-arrival estimation using a sparse representation of array covariance vectors,
IEEE Trans. Signal Process. 59 (9) (2011) 4489–4493.
[29] A. Panahi, M. Viberg, On the resolution of the Lasso-based Doa estimation method, in: International ITG
Workshop on Smart Antennas (WSA 2011), Aachen, Germany, IEEE, 2011.
[30] V.F. Pisarenko, The retrieval of harmonics from a covariance function, Geophys. J. Roy. Astron. Soc. 33
(1973) 347–366.
[31] G. Bienvenu, L. Kopp, Principle de la goniometrie passive adaptive, in: Proceedings of the 7’eme Colloque
GRESIT, Nice, France, 1979, pp. 106/1–106/10.

References
643
[32] R.O. Schmidt, Multiple emitter location and signal parameter estimation, in: Proceedings of the RADC
Spectrum Estimation Workshop, Rome, NY, 1979, pp. 243–258.
[33] S.K. Oh, C.K. Un, A sequential estimation approach for performance improvement of eigen-structure based
methods in array processing, IEEE Trans. Signal Process. 1 (41) (1993) 457–463.
[34] P. Stoica, P. Handel, A. Nehoral, Improved sequential MUSIC, IEEE Trans. Aerosp. Electron. Syst. 31 (4)
(1995) 1230–1239.
[35] S.Y.Kung,K.S.Arun,D.V.BhaskarRao,State-spaceandsingular-valuedecomposition-basedapproximation
methods for the harmonic retrieval problem, J. Opt. Soc. Am. 73 (12) (1983) 1799–1811.
[36] A.J. Barabell, Improving the resolution performance of eigenstructure-based direction-ﬁnding algorithms,
in: Proceedings of the ICASSP 83, Boston, MA, 1983, pp. 336–339.
[37] B.D. Rao, K.V.S. Hari, Performance analysis of root-MUSIC, IEEE Trans. Acoust. Speech Signal Process.
ASSP-37 (12) (1989) 1939–1949.
[38] B. Friedlander, A.J. Weiss, Direction ﬁnding using spatial smoothing with interpolated arrays, IEEE Trans.
Aerosp. Electron. Syst. 28 (2) (1992) 574–587.
[39] D.V. Sidorovich, A.B. Gershman, Two-dimensional wideband interpolated root-MUSIC applied to measured
seismic data, IEEE Trans. Signal Process. 46 (8) (1998) 2263–2267.
[40] R. Kumaresan, D.W. Tufts, Estimating the angles of arrival of multiple plane waves, IEEE Trans. Aerosp.
Electron. Syst. AES-19 (1983) 134–139.
[41] S.S. Reddi, Multiple source location—a digital approach, IEEE Trans. Aerospace Electron. Syst. 15 (1979)
95–105.
[42] M. Kaveh, A.J. Barabell, The statistical performance of the MUSIC and the minimum-norm algorithms in
resolving plane waves innoise, IEEE Trans. Acoust. Speech Signal Process. ASSP-34 (1986) 331–341.
[43] R. Roy, T. Kailath, ESPRIT—Estimation of signal parameters via rotational invariance techniques, IEEE
Trans. Acoust. Speech Signal Process. 37 (7) (1989) 984–995.
[44] M. Haardt, J. Nossek, Unitary ESPRIT: how to obtain increased estimation accuracy with a reduced com-
putational burden, IEEE Trans. Signal Process. 43 (5) (1995) 1232–1242.
[45] B.D. Rao, K.V.S. Hari, Performance analysis of ESPRIT and TAM in determining the direction of arrival of
plane waves in noise, IEEE Trans. Acoust. Speech Signal Process. ASSP-37 (12) (1989) 1990–1995.
[46] G.H. Golub, C.F. Van Loan, Matrix Computations, third ed., John Hopkins University Press, Baltimore,
1996.
[47] J.E. Evans, J.R. Johnson, D.F. Sun, Application of advanced signal processing techqniues to angle of arrival
estimation in ATC navigation and surveillance systems, Technical Report, MIT Lincoln Laboratory, June
1982.
[48] S.U. Pillai, B.H. Kwon, Forward/backward spatial smoothing techniques for coherent signal identiﬁcation,
IEEE Trans. Acoust. Speech Signal Process. 37 (1) (1989) 8–15.
[49] T.J. Shan, M. Wax, T. Kailath, On spatial smoothing for direction-of-arrival estimation of coherent signals,
IEEE Trans. Acoust. Speech Signal Process. 33 (1985) 806–811.
[50] R.T. Willimas, S. Prasad, A.K. Mahalanabis, L.H. Sibul, An improved spatial smoothing technique for
bearing estimation in a multipath environment, IEEE Trans. Acoust. Speech Signal Process. 36 (4) (1988)
425–431.
[51] J. Fuhl, J.P. Rossi, E. Bonek, High resolution 3-D direction of arrival determination for urban mobile radio,
IEEE Trans. Antennas Propag. 45 (4) (1997) 672.
[52] M. Haardt, M.D. Zoltowski, C.P. Mathews, J.A. Nossek 2-D unitary ESPRIT for efﬁcient 2-D parameter
estimation, in: Proceedings of the ICASSP, Detroit, vol. 4, IEEE, May 1995, pp. 2096–2099.
[53] M.D. Zoltowski, C.P. Mathews, M. Haardt, Closed-form 2D angle estimation with rectangular arrays in
element space or beamspace via unitary ESPRIT, IEEE Trans. Signal Process. 44 (2) (1996) 316–328.
[54] E.L. Lehmann, G. Casella, Theory of Point Estimation, second ed., Springer, New York, 1998.

644
CHAPTER 14 DOA Estimation Methods and Algorithms
[55] J.F. Böhme, Estimation of source parameters by maximum likelihood and nonlinear regression, in: Proceed-
ings of the ICASSP 84, vol. 9, 1984, pp. 271–274.
[56] J.F. Böhme. Estimation of spectral parameters of correlated signals in waveﬁelds, Signal Process. 11 (1986)
329–337.
[57] J.F. Böhme. Separated estimation of wave parameters and spectral parameters by maximum likelihood,
in: Proceedings of the ICASSP 86, Tokyo, Japan, 1986, pp. 2818–2822.
[58] Y. Bresler, Maximum likelihood estimation of linearly structured covariance with application to antenna array
processing, in: Proceedings of the 4th ASSP Workshop on Spectrum Estimation and Modeling, Minneapolis,
MN, August 1988, pp. 172–175.
[59] Y. Bresler, V.U. Reddy, T. Kailath, Optimum beamforming for coherent signal and interferences, IEEE Trans.
Acoust. Speech Signal Process. 36 (6) (1988) 833–843.
[60] M. Cedervall, R.L. Moses, Efﬁcient maximum likelihood doa estimation for signals with known waveforms
in the presence of multipath, IEEE Trans. Signal Process. 45 (3) (1997) 808–811.
[61] J. Li, R.T. Compton, Maximum likelihood angle estimation for signals with known waveforms, IEEE Trans.
Signal Process. 41 (1993) 2850–2862.
[62] J. Li, B. Halder, P. Stoica, M. Viberg, Computationally efﬁcient angle estimation for signals with known
waveforms, IEEE Trans. Signal Process. 43 (1995) 2154–2163.
[63] K.M. Wong, J.P. Reilly, Q. Wu, S. Qiao, Estimation of the directions of arrival of signals in unknown
correlated noise, Parts i and ii, IEEE Trans. Signal Process. 40 (1992) 2007–2028.
[64] I. Ziskind, M. Wax, Maximum likelihood localization of multiple sources by alternating projection, IEEE
Trans. Acoust. Speech Signal Process. 36 (10) (1988) 1553–1560.
[65] B.Ottersten,M.Viberg,P.Stoica,A.Nehorai,ExactandlargesampleMLtechniquesforparameterestimation
and detection in array processing, in: S. Haykin, J. Litva, T.J. Shepherd (Eds.), Radar Array Processing,
Springer Verlag, Berlin, 1993, pp. 99–151.
[66] D. Kraus, Approximative Maximum-Likelihood-Schätzung und verwandte Verfahren zur Ortung und
Signalschätzung mit Sensorgruppen, Dr.-Ing. Dissertation, Faculty of Electrical Engineering, Ruhr–
UniversitätBochum, Shaker Verlag, Aachen, 1993.
[67] D.E. Goldberg, Genetic Algorithms in Search, Optimization and Machine Learning, Addison-Wesley, 1988.
[68] S. Kirkpatrick, C.D. Gelatt, M.P. Vecchi, Optimization by simulated annealing, Science 220 (4598) (1983)
671–680.
[69] R.C. Eberhart, J. Kennedy, A new optimizer using particle swarm theory, in: Proceedings of
the Sixth International Symposium on Micromachine and Human Science, Nagoya, Japan, 1995,
pp. 39–43.
[70] A.P. Dempster, N. Laird, D.B. Rubin, Maximum likelihood from incomplete data via the EM algorithm, J.
Roy. Stat. Soc. Ser. B 39 (1977) 1–38.
[71] C.R. Rao, Linear Statistical Inference and its Application, Wiley, New York, 1973.
[72] C.F.J. Wu, On the convergence properties of the EM algorithm, Ann. Stat. 11 (1983) 95–103.
[73] M. Feder, E. Weinstein, Parameter estimation of superimposed signals using the EM algorithm, IEEE Trans.
Acoust. Speech Signal Process. 36 (4) (1988) 477–489.
[74] P.-J. Chung, J.F. Böhme, Comparative convergence analysis of EM and SAGE algorithms in DOA estimation,
IEEE Trans. Signal Process. 49 (12) (2001) 2940–2949.
[75] Michael I. Miller, Daniel R. Fuhrmann, Maximum-Likelihood narrow-band direction ﬁnding and the EM
algorithm, IEEE Trans. Acoust. Speech Signal Process. 38 (9) (1990) 1560–1577.
[76] D. Kraus, J.F. Böhme, Maximum likelihood location estimation of wideband sources using the em-algorithm,
in: Proceedings of the IFAC/ACASP Symposium on Adaptive Systems in Control and Signal Processing,
Grenoble, 1992.

References
645
[77] Jeffrey A. Fessler, Alfred O. Hero, Space-alternating generalized expectation-maximization algorithm, IEEE
Trans. Signal Process. 42 (10) (1994) 2664–2677.
[78] Nail Cadalli, Orhan Arikan, Wideband maximum likelihood direction ﬁnding and signal parameter estimation
by using tree-structured EM algorithm, IEEE Trans. Signal Process. 47 (1) (1999) 201–206.
[79] P.-J. Chung, J.F. Böhme, DOA estimation using fast EM and SAGE algorithms, Signal Process. 82 (11)
(2002) 1753–1762.
[80] X.L. Meng, D. van Dyk. The EM algorithm—an old folk song sung to the fast tune, J. Roy. Stat. Soc. Ser.
B 59 (1997) 511–567.
[81] Y. Bresler, A. Macovski, Exact maximum likelihood parameter estimation of superimposed exponential
signals in noise, IEEE Trans. Acoust. Speech Signal Process. 34 (5) (1986) 1081–1089.
[82] R. Kumaresan, L. Scharf, A. Shaw, An algorithm for pole-zero modeling and spectral analysis, IEEE Trans.
Acoust. Speech Signal Process. 34 (3) (1986) 637–640.
[83] K. Steiglitz, L. McBride, A technique for identiﬁcation of linear systems, IEEE Trans. Autom. Control. 10
(1965) 461–464.
[84] J. Li, P. Stoica, Z.-S. Liu, Comparative study of IQML and MODE direction-of-arrival estimators, IEEE
Trans. Signal Process. 46 (1) (1998) 149–160.
[85] M.P. Clark, L.L. Scharf, On the complexity of IQML algorithms, IEEE Trans. Acoust. Speech Signal Process.
40 (7) (1992) 1811–1813.
[86] P. Stoica, J. Li, T. Soderstrom, On the inconsistency of IQML, Signal Process. 56 (1997)
185–190.
[87] Y. Hua, The most efﬁcient implementation of IQML algorithm, IEEE Trans. Signal Process. 42 (8) (1994)
2203–2204.
[88] B. Ottersten, M. Viberg, T. Kailath, Analysis of subspace ﬁtting and ML techniques for parameter estimation
from sensor array data, IEEE Trans. Signal Process. 40 (1992) 590–600.
[89] M. Viberg, B. Ottersten, Sensor array processing based on subspace ﬁtting, IEEE Trans. Signal Process. 39
(5) (1991) 1110–1121.
[90] M. Viberg, B. Ottersten, T. Kailath, Detection and estimation in sensor arrays using weighted subspace
ﬁtting, IEEE Trans. Signal Process. 39 (11) (1991) 2436–2449.
[91] P. Stoica, K. Sharman, Maximum likelihood methods for direction-of-arrival estimation, IEEE Trans. Acoust.
Speech Signal Process. ASSP-38 (1990) 1132–1143.
[92] B. Ottersten, P. Stoica, R. Roy, Covariance matching estimation techniques for array signal processing
applications, Digital Signal Process. 8 (3) (1998) 185–210.
[93] J. Li, D. Zheng, P. Stoica, Angle and waveform estimation via RELAX, IEEE Trans. Aerospace Electron.
Syst. 33 (3) (1997) 1077–1087.
[94] O. Besson, P. Stoica, Decoupled estimation of doa and angular spread for a spatially distributed source, IEEE
Trans. Signal Process. 48 (7) (2000) 1872–1882.
[95] A.B. Gershman, F.F. Mecklenbräuker, J.F. Böhme, Matrix ﬁtting approach to direction of arrival estimation
with imperfect spatial coherence of wavefronts, IEEE Trans. Signal Process. 45 (7) (1997) 1894–1899.
[96] D. Kraus, J.F. Böhme, Asymptotic and empirical results on approximate maximum likelihood and least
squares methods for array processing, in: Proceedings of the ICASSP, Albuquerque, NM, USA, IEEE, 1990,
pp. 2795–2798.
[97] T. Trump, B. Ottersten, Estimation of nominal direction of arrival and angular spread using and array of
sensors, Signal Process. 50 (1–2) (1996) 57–70.
[98] P. Stoica, A. Nehorai, Music, maximum likelihood and Cramér-Rao bound, IEEE Trans. Acoust. Speech
Signal Process. ASSP-37 (1989) 720–741.
[99] P. Stoica, A. Nehorai, Music, maximum likelihood and Cramér-Rao bound: Further results and comparisons,
IEEE Trans. Acoust. Speech Signal Process. ASSP-38 (1990) 2140–2150.

646
CHAPTER 14 DOA Estimation Methods and Algorithms
[100] P. Stoica, A. Nehorai, Performance study of conditional and unconditional direction-of-arrival estimation,
IEEE Trans. Acoust. Speech Signal Process. 38 (1990) 1783–1795.
[101] X.L. Xu, K.M. Buckly, Bias analysis of the MUSIC location estimator, IEEE Trans. Acoust. Speech Signal
Process. 40 (10) (1992) 2559–2569.
[102] B. Ottersten, M. Viberg, T. Kailath, Performance analysis of the total least squares ESPRIT algorithm, IEEE
Trans. Signal Process. SP-39 (1991) 1122–1135.
[103] D.Kraus,J.F.Böhme,EMdualmaximumlikelihoodestimationforwidebandsourcelocation,in:Proceedings
of the IEEE ICASSP, Minneapolis,1993.
[104] H. Hung, M. Kaveh, Focussing matrices for coherent signal-subspace processing, IEEE Trans. Acoust.
Speech Signal Process. 36 (8) (1988) 1272–1281.
[105] H. Wang, M. Kaveh, Coherent signal-subspace processing for the detection and estimation of angles of arrival
of multiple wide-band sources, IEEE Trans. Acoust. Speech Signal Process. 33 (4) (1985) 823–831.
[106] G. Su, M. Morf, The signal subspace approach for multiple wideband emitter location, IEEE Trans. Acoust.
Speech Signal Process. ASSP-31 (6) (1983) 1502–1522
[107] D.R. Brillinger, Time Series: Data Analysis and Theory, Holden-Day, San Francisco, 1981.
[108] M.A. Doron, A.J. Weiss, On focusing matrices for wide-band array processing, IEEE Trans. Signal Process.
40 (6) (1992) 1295–1302.
[109] E.D. di Claudio, R. Parisi, WAVES: weighted average of signal subspaces for robust wideband direction
ﬁnding, IEEE Trans. Signal Process. 49 (10) (2001) 2179–2191.
[110] Y.-S. Yoon, L.M. Kaplan, J.H. McClellan, TOPS: new DOA estimator for wideband signals, IEEE Trans.
Signal Process. 54 (6) (2006) 1977–1989.
[111] M. Wax, T. Kailath, Detection of signals by information theoretic criteria, IEEE Trans. Acoust. Speech Signal
Process. ASSP-33 (2) (1985) 387–392.
[112] M. Wax, I. Ziskind, Detection of the number of coherent signals by the MDL principle, IEEE Trans. Acoust.
Speech Signal Process. 37 (8) (1989) 1190–1196.
[113] L.C. Zhao, P.R. Krishnaiah, Z.D. Bai, On detection of the number of signals in presence of white noise, J.
Multivariate Anal. 20 (1) (1986) 1–25.
[114] Ramon F. Brcich, Abdelhak M. Zoubir, Per Pelin, Detection of sources using bootstrap techniques, IEEE
Trans. Signal Process. 50 (2) (2002) 206–215.
[115] D. Williams, D. Johnson, Using the sphericity test for narrow-band passive arrays, IEEE Trans. Acoust.
Speech Signal Process. 38 (1990) 2008–2014.
[116] J.F. Böhme, Statistical array signal processing of measured sonar and seismic data, in: Proceedings of the
SPIE 2563 Advanced Signal Processing Algorithms, San Diego, July 1995, pp. 2–20.
[117] P.-J. Chung, J.F. Böhme, C.F. Mecklenbräuker, A.O. Hero, Detection of the number of signals using the
Benjamini-Hochberg procedure, IEEE Trans. Signal Process. 55 (6) (2007) 2497–2508.
[118] D. Maiwald, J.F. Böhme, Multiple testing for seismic data using bootstrap, in: Proceedings of IEEE Inter-
national Conference on Acoustics, Speech, and Signal Processing, Adelaide, vol. VI, 1994, pp. 89–92.
[119] D.N. Lawley, Tests of signiﬁcance of the latent roots of the covariance and correlation matrices, Biometrika
43 (1956) 128–136.
[120] Q. Wu, K.M. Wong, Determination of the number of signals in uknown noise environments-PARADE, IEEE
Trans. Signal Process. 43 (1) (1995) 362–365.
[121] S. Kritchman, B. Nadler, Non-parametric detection of the number of signals: hypothesis testing and random
matrix theory, IEEE Trans. Signal Process. 57 (10) (2009) 3930–3941.
[122] P.O. Perry, P.J. Wolfe, Minimax rank estimation for subspace tracking, IEEE J. Sel. Top. Signal Process. 4
(3) (2010) 504–513.
[123] L.C. Zhao, P.R. Krishnaiah, Z.D. Bai, Remarks on certain criteria for detection of number of signals, IEEE
Trans. Acoust. Speech Signal Process. 35 (2) (1987) 129–132.

References
647
[124] E. Fishler, H. Messer, Order statistics approach for determining the number of sources using an array of
sensors, IEEE Signal Process. Lett. 6 (7) (1999) 179–182.
[125] R.R. Nadakuditi, A. Edelman, Sample eigenvalue based detection of high-dimensional signals in white noise
using relatively few samples, IEEE Trans. Signal Process. 56 (7) (2008) 2625–2638.
[126] M. Wong, Q.T. Zou, J.P. Reilly, On information theoretic criterion for determining the number of signals in
high resolution array processing, IEEE Trans. Acoust. Speech Signal Process. 38 (11) (1990) 1959–1971.
[127] C. Xu, S. Kay, Source enumeration via the EEF criterion, IEEE Signal Process. Lett. 15 (2008) 569–572.
[128] D. Maiwald, Breitbandverfahren zur Signalentdeckung und -ortung mit Sensorgruppen in Seismik- und
Sonaranwendungen, Dr.-Ing. Dissertation, Department of Electrical Engineering, Ruhr-UniversitätBochum,
Shaker Verlag, Aachen, 1995.
[129] R.H. Shumway, Replicated time-series regression: an approach to signal estimation and detection, in:
D.R. Brillinger, P.R. Krishnaiah (Eds.), Handbook of Statistics, vol. 3, Elsevier Science Publishers B.V.,
1983, pp. 383–408.
[130] P.-J. Chung, Stochastic maximum likelihood estimation under misspeciﬁed numbers of signals, IEEE Trans.
Signal Process. 55 (9) (2007) 4726–4731.
[131] R. Badeau, B. David, G. Richard, A new perturbation analysis for signal enumeratio in rotational invariance
techniques, IEEE Trans. Signal Process. 54 (2) (2006) 450–458.
[132] P.-J. Chung, M. Viberg, C.F. Mecklenbräuker, Broadband ML estimation under model order uncertainty,
Signal Process. 90 (5) (2010) 1350–1356.
[133] Y. Bar-Shalom, X.R. Li, T. Kirubarajan, Estimation with Applications to Tracking and Navigation, ﬁrst ed.,
Wiley, New York, 2001.
[134] M. Orton, W. Fitzgerald, A bayesian approach to tracking multiple targets using sensor arrays and particle
ﬁlters, IEEE Trans. Signal Process. 50 (2) (2002) 216–223.
[135] V. Katkovnik, A.B. Gershman, A local polynomial approximation based beamforming for source localization
and tracking in nonstationary environments, IEEE Signal Process. Lett. 7 (1) (2000) 3–5.
[136] C.R. Rao, C.R. Sastry, B. Zhou, Tracking the direction of arrival of multiple moving targets, IEEE Trans.
Signal Process. 42 (5) (1994) 1133–1144.
[137] Y. Zhou, P.C. Yip, H. Leung, Tracking the direction-of-arrival of multiple moving targets by passive arrays:
algorithm, IEEE Trans. Signal Process. 47 (10) (1999) 2655–2666.
[138] L. Frenkel, M. Feder, Recursive expectation and maximization (em) algorithms for time-varying parameters
with application to multiple target tracking, IEEE Trans. Signal Process. 47 (2) (1999) 306–320.
[139] R.E. Zarnich, K.L. Bell, H.L. Van Trees, A uniﬁed method for measurement and tracking of contacts from
an array of sensors, IEEE Trans. Signal Process. 49 (12) (2001) 2950–2961.
[140] P.-J. Chung, J.F. Böhme, A.O. Hero, Tracking of multiple moving sources using recursive EM algorithm,
EURASIP J. Appl. Signal Process. 2005 (2005) 50–60.
[141] D.M. Titterington, Recursive parameter estimation using incomplete data, J. Roy. Stat. Soc. Ser. B 46 (2)
(1984) 257–267.
[142] R. DeGroat, Noniterative subspace tracking, IEEE Trans. Signal Process. 40 (3) (1992) 571–577.
[143] I. Karasalo, Estimating the covariance matrix by signal subspace averaging, IEEE Trans. Acoust. Speech
Signal Process. ASSP-34 (1) (1986) 8–12.
[144] S. Ouyang, Y. Hua, Bi-iterative least-square method for subspace tracking, IEEE Trans. Signal Process. 53
(8) (2005) 2984–2996.
[145] K. Abed-Meraim, A. Chkeif, Y. Hua, Fast orthonormal PAST algorithm, IEEE Signal Process. Lett. 7 (3)
(2000) 60–62.
[146] R. Badeau, G. Richard, B. David, Fast and stable yast algorithm for principal and minor subspace tracking,
IEEE Trans. Signal Process. 56 (8) (2008) 3437–3446.

648
CHAPTER 14 DOA Estimation Methods and Algorithms
[147] C.E. Davila, Efﬁcient, high performance, subspace tracking for time-domain data, IEEE Trans. Signal Pro-
cess. 48 (12) (2000) 3307–3315.
[148] J. Xin, A. Sano, Efﬁcient subspace-based algorithm for adaptive bearing estimation and tracking, IEEE Trans.
Signal Process. 53 (12) (2005) 4485–4505
[149] B. Yang, Projection approximation subspace tracking, IEEE Trans. Signal Process. 43 (1) (1995) 95–107.
[150] W.A. Gardner, Simpliﬁcation of MUSIC and ESPRIT by exploitation of cyclostationarity, Proc. IEEE 76
(1988) 845–847.
[151] S.V. Schell, Performance analysis of the cyclic MUSIC method of direction estimation for cyclostationary
signals, IEEE Trans. Signal Process. 42 (11) (1994) 3043–3050.
[152] Q. Wu, K.M. Wong, Blind adaptive beam forming for cyclostationary signals, IEEE Trans. Signal Process.
44 (11) (1996) 2757–2767.
[153] G. Xu, T. Kailath, Direction-of-arrival estimation via exploitation of cyclostationary—a com-
bination
of
temporal
and
spatial
processing,
IEEE
Trans.
Signal
Process.
40
(7)
(1992)
1775–1786.
[154] H. Yan, H.H. Fan, Doa estimation for wideband cyclostationary signals under multipath environment, in:
IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004, Proceedings (ICASSP
’04), vol. 2, May 2004, pp. ii-77–ii-80.
[155] P. Chevalier, L. Albera, A. Ferreol, P. Comon, On the virtual array concept for higher order array processing,
IEEE Trans. Signal Process. 53 (4) (2005) 1254–1271.
[156] M.C. Dogan, J.M. Mendel, Cumulant-based blind optimum beamforming, IEEE Trans. Aerosp. Electron.
Syst. 30 (3) (1994) 722–741.
[157] M.C. Dogan, J.M. Mendel, Applications of cumulants to array processing. I. Aperture extension and array
calibration, IEEE Trans. Signal Process. 43 (5) (1995) 1200–1216.
[158] B. Porat, B. Friedlander, Direction ﬁnding algorithms based on high-order statistics, IEEE Trans. Signal
Process. 39 (9) (1991) 2016–2024.
[159] B.F. Cron, C.H. Sherman, Spatial correlation functions for various noise models, J. Acoust. Soc. Am. 34
(1962) 1732–1736
[160] F. Li, R.J. Vaccaro, Performance degradation of DOA estimators due to unknown noise ﬁelds, IEEE Trans.
Signal Process. 40 (3) (1992) 686–690.
[161] M. Viberg, Sensitivity of parametric direction ﬁnding to colored noise ﬁelds and undermodeling, Signal
Process. 34 (2) (1993) 207–222.
[162] M. Viberg, A.L. Swindlehurst, Analysis of the combined effects of ﬁnite samples and model errors on array
processing performance, IEEE Trans. Signal Process. 42 (1994) 3073–3083.
[163] M. Wax, Detection and localization of multiple sources in noise with unknown covariance, IEEE Trans.
Signal Process. 40 (1) (1992) 245–249.
[164] J.F. Böhme, D. Kraus, On least squares methods for direction of arrival estimation in the presence of unknown
noise ﬁelds, in: Proceedings of the ICASSP 88, New York, NY, 1988, pp. 2833–2836.
[165] V. Nagesha, S. Kay, Maximum likelihood estimation for array processing in colored noise, in: IEEE Inter-
national Conference on Acoustics, Speech, and Signal Processing, ICASSP-93, 1993, vol. 4, April 1993,
pp. 240–243.
[166] A. Paulraj, T. Kailath, Direction-of-arrival estimation by eigenstructure methods with unknown
sensor
gain
and
phase,
in:
Proceedings
of
the
IEEE
ICASSP,
Tampa,
FL,
March
1985,
pp. 17.7.1–17.7.4.
[167] S. Prasad, R.T. Williams, A.K. Mahalanabis, L.H. Sibul, A transform-based covariance differencing approach
for some classes of parameter estimation problems, IEEE Trans. Acoust. Speech Signal Process. 36 (5) (1988)
631–641.

References
649
[168] F. Tuteur, Y. Rockah, A new method for detection and estimation using the eigenstructure of
the covariance difference, in: Proceedings of the ICASSP 86 Conference, Tokyo, Japan, 1986,
pp. 2811–2814.
[169] R.L. Moses, A.A. Beex, Instrumental variable adaptive array processing, IEEE Trans. Aerosp. Electron. Syst.
24 (2) (1988) 192–202.
[170] M. Viberg, P. Stoica, B. Ottersten, Array processing in correlated noise ﬁelds based on instrumental variables
and subspace ﬁtting, IEEE Trans. Signal Process. 43 (5) (1995) 1187–1199.
[171] M. Viberg, P. Stoica, B. Ottersten, Maximum likelihood array processing in spatially correlated noise ﬁelds
using parameterized signals, IEEE Trans. Signal Process. 45 (4) (1997) 996–1004.
[172] S.A. Vorobyov, A.B. Gershman, K.M. Wong, Maximum likelihood direction-of-arrival estimation in
unknown noise ﬁelds using sparse sensor arrays, IEEE Trans. Signal Process. 53 (1) (2005) 34–43.
[173] X.L. Xu, K. Buckley, An analysis of beam-space source localization, IEEE Trans. Signal Process. 41 (1)
(1993) 501.
[174] B.D. Van Veen, B.G. Williams, Dimensionality reduction in high resolution direction of arrival estima-
tion, in: Twenty-Second Asilomar Conference on Signals, Systems and Computers, 1988, vol. 2, 1988,
pp. 588–592.
[175] P. Forster, G. Vezzosi, Application of spheroidal sequences to array processing, in: IEEE International
Conference on Acoustics, Speech, and Signal Processing, ICASSP ’87, vol. 12, April 1987, pp. 2268–2271.
[176] S. Anderson, On optimal dimension reduction for sensor, array signal processing, Signal Process. 30 (2)
(1993) 245–256.
[177] H.B. Lee, M.S. Wengrovitz, Resolution threshold of beamspace MUSIC for two closely spaced emitters,
IEEE Trans. Acoust. Speech Signal Process. 38 (9) (1990) 1545–1559.
[178] X.L. Xu, K. Buckley, A comparison of element and beam space spatial-spectrum estimation for multiple
source clusters, in: Proceedings of the ICASSP 90, Albuquerque, NM, April 1990.
[179] M.D. Zoltowski, G.M. Kautz, S.D. Silverstein, Beamspace root-mUSIC, IEEE Trans. Signal Process. 41 (1)
(1993) 344.
[180] C.P. Mathews, M.D. Zoltowski, Eigenstructure techniques for 2-D angle estimation with uniform circular
arrays, IEEE Trans. Signal Process. 42 (9) (1994) 2395–2407.
[181] P. Hyberg, M. Jansson, B. Ottersten, Array interpolation and DOA MSE reduction, IEEE Trans. Signal
Process. 53 (12) (2005) 4464–4471.
[182] K.I. Pedersen, P.E. Mogensen, B.H. Fleury, A stochastic model of the temporal and azimuthal dispersion seen
at the base station in outdoor propagation environments, IEEE Trans. Veh. Technol. 49 (2) (2000) 437–447.
[183] M. Tapio, On the use of beamforming for estimation of spatially distributed signals, in: Proceedings of the
IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003 (ICASSP ’03), vol. 5,
April 2003, pp. V-369–V-372.
[184] A. Hassanien, S. Shahbazpanahi, A.B. Gershman, A generalized capon estimator for localization of multiple
spread sources, IEEE Trans. Signal Process. 52 (1) (2004) 280–283.
[185] S. Shahbazpanahi, S. Valaee, M.H. Bastani, Distributed source localization using ESPRIT algorithm, IEEE
Trans. Signal Process. 49 (10) (2001) 2169–2178.
[186] S. Valaee, B. Champagne, P. Kabal, Parametric localization of distributed sources, IEEE Trans. Signal
Process. 43 (9) (1995) 2144–2153.
[187] Y. Meng, P. Stoica, K.M. Wong, Estimation of the directions of arrival of spatially dispersed signals in array
processing, IEE Proc.—Radar Sonar Navig. 143 (1) (1996) 1–9.
[188] M. Bengtsson, B. Ottersten, Low-complexity estimators for distributed sources, IEEE Trans. Signal Process.
48 (8) (2000) 2185–2194.
[189] A. Zoubir, Y. Wang, P. Charge, Efﬁcient subspace-based estimator for localization of multiple incoherently
distributed sources, IEEE Trans. Signal Process. 56 (2) (2008) 532–542.

650
CHAPTER 14 DOA Estimation Methods and Algorithms
[190] D. Astely, B. Ottersten, The effects of local scattering on direction of arrival estimation with MUSIC, IEEE
Trans. Signal Process. 47 (12) (1999) 3220–3234.
[191] R. Raich, J. Goldberg, H. Messer, Bearing estimation for a distributed source: modeling, inherent accuracy
limitations and algorithms, IEEE Trans. Signal Process. 48 (2) (2000) 429–441.
[192] C.B. Dietrich, K. Dietze, J.R. Nealy, W.L. Stutzman, Spatial, polarization, and pattern diversity for wireless
handheld terminals, IEEE Trans. Antennas Propag. 49 (9) (2001) 1271–1281.
[193] E. Ferrara Jr., T. Parks, Direction ﬁnding with an array of antennas having diverse polarizations, IEEE Trans.
Antennas Propag. 31 (2) (1983) 231–236.
[194] J. Li, R.T. Compton, Angle and polarization estimation using ESPRIT with a polarization sensitive array,
IEEE Trans. Antennas Propag. 39 (9) (1991) 1376–1383.
[195] J. Li, P. Stoica, Efﬁcient parameter estimation of partially polarized electromagnetic waves, IEEE Trans.
Signal Process. 42 (11) (1994) 3114–3125.
[196] D.Rahamim,J.Tabrikian,R.Shavit,Sourcelocalizationusingvector sensor arrayinamultipathenvironment,
IEEE Trans. Signal Process. 52 (11) (2004) 3096–3103.
[197] A. Swindlehurst, M. Viberg, Subspace ﬁtting with diversely polarized antenna arrays, IEEE Trans. Antennas
Propag. 41 (12) (1993) 1687–1694.
[198] I. Ziskind, M. Wax, Maximum likelihood localization of diversely polarized sources by simulated annealing,
IEEE Trans. Antennas Propag. 38 (7) (1990) 1111–1114.
[199] M.D. Zoltowski, K.T. Wong, ESPRIT-based 2-D direction ﬁnding with a sparse uniform array of electro-
magnetic vector sensors, IEEE Trans. Signal Process. 48 (8) (2000) 2195–2204.
[200] Q. Cheng, Y. Hua, Performance analysis of the MUSIC and Pencil-MUSIC algorithms for diversely polarized
array, IEEE Trans. Signal Process. 42 (11) (1994) 3150–3165.
[201] A.J. Weiss, B. Friedlander, Performance analysis of diversely polarized antenna arrays, IEEE Trans. Signal
Process. 39 (7) (1991) 1589–1603.
[202] A. Nehorai, E. Paldi, Vector-sensor array processing for electromagnetic source localization, IEEE Trans.
Signal Process. 42 (2) (1994) 376–398.
[203] K.-C. Ho, K.-C. Tan, W. Ser, Investigation on number of signals whose direction of arrival are uniquely
determinable with an electromagnetic sensor, Signal Process. 47 (1995) 41–54.
[204] B. Hochwald, A. Nehorai, Identiﬁability in array processing models with vector-sensor applications, IEEE
Trans. Signal Process. 44 (1) (1996) 83–95.
[205] M. Akcakaya, C.H. Muravchik, A. Nehorai, Biologically inspired coupled antenna array for direction-of-
arrival estimation, IEEE Trans. Signal Process. 59 (10) (2011) 4795–4808.
[206] D. Donno, A. Nehorai, U. Spagnolini, Seismic velocity and polarization estimation for waveﬁeld separation,
IEEE Trans. Signal Process. 56 (10) (2008) 4794–4809.
[207] M. Hawkes, A. Nehorai, Wideband source localization using a distributed acoustic vector-sensor array, IEEE
Trans. Signal Process. 51 (6) (2003) 1479–1491.
[208] B. Hochwald, A. Nehorai, Magnetoencephalography with diversely oriented and multicomponent sensors,
IEEE Trans. Biomed. Eng. 44 (1) (1997) 40–50.

15
CHAPTER
Subspace Methods and
Exploitation of Special
Array Structures
Martin Haardt*, Marius Pesavento†, Florian Roemer*, and Mohammed Nabil El Korso‡
*Communications Research Laboratory, Ilmenau University of Technology, Ilmenau, Germany
†Communication Systems Group, Darmstadt University of Technology, Darmstadt, Germany
‡Waves Material and Systems Group, Energetic Mechanic Electromagnetic Lab (LEME, EA-4416), University
Paris-Ouest Nanterre-La Defense, Ville d’Avray, France
3.15.1 Introduction
Several important applications (including radar, wireless channel sounding, sonar, and seismology)
require the estimation of the directions of arrival of several propagating waves from noise-corrupted
measurements taken by an array of sensors. Modern subspace based high-resolution frequency or
direction of arrival (DOA) estimation schemes [1] provide a resolution that exceeds the traditional
Rayleigh resolution limit.1 They can be classiﬁed according to their numerical procedure [2] into
•
extrema-searching techniques, e.g., spectral MUSIC [3], spectral RARE,
•
polynomial-rooting techniques, e.g., Pisarenko’s harmonic decomposition [4], Min-Norm [5], root-
MUSIC [6,7], MODE, or root-RARE, and
•
matrix-shifting techniques, e.g., Standard ESPRIT [8], state space methods (direct data approach or
Toeplitz approximation method) [9,10], matrix pencil methods [11–13], optimally weighted ESPRIT
[14], or Unitary ESPRIT [15].
Notice that matrix-shifting techniques utilize estimates of the signal subspace whereas extrema-
searching techniques and most polynomial-rooting techniques use estimates of its orthogonal com-
plement, often referred to as noise subspace.
Due to its simplicity and high-resolution capability, ESPRIT (Estimation of Signal Parameters via
Rotational Invariance Techniques) [8] has become one of the most popular signal subspace based DOA
or spatial frequency estimation schemes. Here, the spatial frequency estimates are obtained without
nonlinear optimization and without the computation or search of any spectral measure. ESPRIT is
explicitly premised on a point source model for the sources and is restricted to use with array geometries
that exhibit so-called invariances [8]. This requirement, however, is not very restrictive as many of the
common array geometries used in practice exhibit these invariances, or their output can be transformed
to effect these invariances. ESPRIT may be viewed as a complement to the MUSIC (MUltiple SIgnal
1For a uniform linear array of M identical sensors, the Rayleigh criterion for resolution states that two incoherent plane
waves propagating into two slightly different directions can only be resolved if the difference of their spatial frequencies is
at least 2π/M [16]. This resolution is, for instance, provided by the DFT-based periodogram.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00015-1
© 2014 Elsevier Ltd. All rights reserved.
651

652
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
Classiﬁcation) algorithm [3], the forerunner of all subspace based DOA methods, in that it is based on
properties of the signal eigenvectors whereas MUSIC is based on properties of the noise eigenvectors.
It should be noted that ESPRIT may also be used in the dual problem of estimating the frequencies of
multiple sinusoids embedded in additive noise (harmonic retrieval) [8]. In the latter application, ESPRIT
is more generally applicable than MUSIC as it can handle damped sinusoids and provides estimates
of the damping factors as well as the constituent frequencies. There are three primary steps in any
ESPRIT-type algorithm:
1. signal subspace estimation: computation of a basis for the estimated signal subspace,
2. solution of the invariance equation: solution of an (in general) overdetermined system of equations,
the so-called invariance equation, derived from the basis matrix estimated in step 1, and
3. spatial frequency estimation: computation of the eigenvalues of the solution of the invariance
equation formed in step 2.
Extensions of these subspace-based high-resolution parameter estimation to the R-dimensional
(R-D) case are required for a variety of applications, such as estimating the multi-dimensional param-
eters of the dominant multipath components from MIMO channel measurements [17], which may be
used for geometry-based channel modeling. In this case, the dominant multipath components may be
parametrized in terms of their azimuth and elevation angles at the transmitter (directions of departure),
their azimuth and elevation angles at the receiver (directions of arrival), as well as the corresponding
propagation delays and Doppler shifts, leading to an R = 6 dimensional harmonic retrieval problem
[17]. Other applications include radar, wireless communications [18], sonar, seismology, and medical
imaging. Numerous multi-dimensional harmonic retrieval techniques have been developed, ranging
from Fourier-based methods to parametric high resolution techniques, cf. [19] for an overview. Efﬁ-
cient solutions to this problem are given by subspace-based algorithms like ESPRIT- or MUSIC-based
techniques [8] and their multi-dimensional extensions such as 2-D Unitary ESPRIT [20], R-D Unitary
ESPRIT [21], R-D MUSIC [22], R-D MDF (multi-dimensional folding) [23], or R-D RARE (rank
reduction estimator) [24].
In the traditional approaches to subspace-based parameter estimation, the R-D signals are stored in
matrices by means of a stacking operation. Obviously, this representation does not account for the R-D
grid structure inherent in the data. A more natural approach to store and manipulate multi-dimensional
data is given by tensors. Tensors have already been used in parallel factor (PARAFAC) analysis tech-
niques to obtain important identiﬁability results for the multi-dimensional harmonic retrieval problem
[25,26]. Parameter estimates based on the PARAFAC model are often obtained via iterative techniques
such as alternating Least Squares (ALS) [27] that might require many iterations and do not guarantee
convergence to the global optimum [28]. Therefore, it has been proposed to use ESPRIT-type methods
to initialize these iterative techniques [29]. In contrast to existing tensor approaches using PARAFAC
[29], we focus on a direct analogy to the matrix case by using higher-order extensions of the SVD,
i.e., the higher-order SVD (HOSVD) [30], and their low-rank approximations [31]. The HOSVD can
be viewed as a Tucker3 model [32], which has a long history in tensor analysis [27,33,34]. Note that
the COMFAC algorithm [35,36], which is a fast implementation of trilinear ALS, also uses a low-rank
approximation based on the Tucker3 model as a preprocessing step. This “Tucker3 compression” is
used to speed up the iterative Least Squares ﬁtting procedure of the PARAFAC model (without the
Vandermonde structure that is speciﬁc to the harmonic retrieval problem), and thereby avoids a brute
force implementation of ALS in the raw data space.

3.15.1 Introduction
653
In this chapter, we show that the tensor representation allows us to exploit the structure inherent in the
data further. We demonstrate how existing concepts like forward-backward averaging [37] and the map-
ping of complex centro-Hermitian covariance matrices to real-valued matrices of the same size [37,38]
can be generalized to tensors. We also discuss how an HOSVD-based low-rank approximation leads
to an improved estimate of the signal subspace which can be used to improve any multi-dimensional
subspace-based parameter estimation scheme, e.g., R-D Unitary ESPRIT, R-D MUSIC, or R-D RARE.
As examples, we derive the R-D standard Tensor-ESPRIT and the R-D Unitary Tensor-ESPRIT algo-
rithms explicitly.
Table 15.1 summarizes the ESPRIT-type algorithms that are discussed in this chapter together with
a reference where they have ﬁrst been proposed and a reference where a performance analysis for them
has been derived. In this case (open) means that analytical performance results are not available yet.
Tensor-ESPRIT-type algorithms are written in italic letters. Since all ESPRIT-type algorithms can be
combined with different methods to solve the shift invariance equations, Table 15.2 summarizes the
different Least Squares solutions that are available together with the corresponding references.
Table 15.1 Overview of ESPRIT-Type Algorithms and Their Performance Analysis. Tensor-
ESPRIT-Type Algorithms are Written in Italic Letters
Algorithm
Proposed
Performance Analysis
1-D Standard ESPRIT
[39]
[7,40], …
1-D Unitary ESPRIT
[15]
[41]
R-D Standard ESPRIT
(Implicit in [42])
(Implicit in [40])
R-D Unitary ESPRIT
[20] (2-D), [21] (R-D)
[41] (2-D), [43] (R-D)
R-D Standard Tensor -ESPRIT
[42]
[43,44]
R-D Unitary Tensor -ESPRIT
[42]
[43,44]
1-D NC Standard ESPRIT
[45]
( = 1-D NC Unitary ESPRIT)
1-D NC Unitary ESPRIT
[46]
(open)
R-D NC Standard ESPRIT
(Implicit in [46])
(= R-D NC Unitary ESPRIT)
R-D NC Unitary ESPRIT
[46]
(open)
R-D NC Standard Tensor -ESPRIT
[47]
(open)
R-D NC Unitary Tensor -ESPRIT
[47]
(= R-D NC Unitary Tensor-ESPRIT)
Table 15.2 Overview of Least-Squares Algorithms to Solve the Invariance Equations of ESPRIT-
Type Algorithms and Their Performance Analysis
Algorithm
Proposed
Performance Analysis
Least Squares (LS)
[39]
[7,40]
Total Least Squares (TLS)
[48]
[49]
Structured Least Squares (SLS)
[50]
[51] (1-D)
Tensor-Structure SLS
[52]
(open)

654
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
This chapter is organized as follows. After the introduction of the data model in Section 3.15.2,
we discuss matrix- and tensor-based subspace estimation techniques in Section 3.15.3. Based on these
subspace estimation techniques, we provide an overview of important subspace-based parameter esti-
mation techniques in Section 3.15.4, before the main conclusions are summarized in Section 3.15.5.
3.15.2 Data model
3.15.2.1 Notation
In order to facilitate the distinction between scalars, matrices, and tensors, the following notation is
used: Scalars are denoted as italic letters (a, b, . . . , A, B, . . . , α, β, . . .), column vectors as lower-case
bold-face letters (a, b, . . .), matrices as bold-face capitals (A, B, . . .), and tensors are written as bold-
face calligraphic letters (A, B, . . .). Lower-order parts are consistently named: the (i, j)-element of the
matrix A, is denoted as ai, j and the (i, j, k)-element of a third order tensor B as bi, j,k.
We use the superscripts T ,H ,∗,−1 ,+ for transposition, Hermitian transposition, complex conjuga-
tion, matrix inversion, and the Moore-Penrose pseudo inverse of a matrix, respectively. Moreover, the
Kronecker product of two matrices A and B is denoted as A ⊗B and the Khatri-Rao product (column-
wise Kronecker product) as A ♦B. An n-mode vector of an (I1 × I2 × · · · × IN)-dimensional tensor
A is an In-dimensional vector obtained from A by varying the index in and keeping the other indices
ﬁxed. A subtensor of the tensor A, denoted by Ain=k, is obtained by ﬁxing the nth index to some value
k. Moreover, a matrix unfolding of the tensor A along the nth mode is denoted by [A](n) and can be
understood as a matrix containing all the n-mode vectors of the tensor A. The order of the columns is
chosen in accordance with [53].
The outer product of the tensors A ∈CI1×I2×···×IN and B ∈C J1×J2×···×JM is given by
C = A ◦B ∈CI1×···×IN ×J1×···×JM ,
where
ci1,i2,...,iN , j1, j2,..., jM = ai1,i2,...,iN · b j1, j2,..., jM .
(15.1)
Inotherwords,thetensorC containsallpossiblecombinationsofpairwiseproductsbetweentheelements
of A and B. This operator is very closely related to the Kronecker product deﬁned for matrices.
The n-mode product of a tensor A ∈CI1×I2×···×IN and a matrix U ∈C Jn×In along the nth mode is
denoted as B = A ×n U and deﬁned via
B = A ×n U
⇔[B](n) = U · [A](n),
(15.2)
i.e., it may be visualized by multiplying all n-mode vectors of A from the left-hand side by the matrix U.
The higher-order SVD (HOSVD) of a tensor A ∈CI1×I2×···×IN is given by
A = S ×1 U1 ×2 U2 · · · ×N UN,
(15.3)
where S ∈CI1×I2×···×IN is the core tensor which satisﬁes the all-orthogonality conditions [53] and
Un ∈CIn×In, n = 1, 2, . . . , N, are the unitary matrices of n-mode singular vectors.
We also deﬁne the concatenation of two tensors along the nth mode via the operator [A ⊔n B].

3.15.2 Data Model
655
The operations we have deﬁned so far satisfy the following properties that can easily be veriﬁed
A ×1 X1 ×2 X2 = A ×2 X2 ×1 X1,
(15.4)
(A ×1 X1) ×1 Y1 = A ×1 (Y1 · X1),
(15.5)
[A ×1 X1 ×2 X2 · · · ×R X R](n) = Xn · [A](n) · (Xn+1 ⊗Xn+2 · · · ⊗X R
⊗X1 · · · ⊗Xn−1)T ,
(15.6)
[I R,N ×1 F1 · · · ×R FR](p) = Fp · (Fp+1♦· · · ♦FR♦F1♦· · · ♦Fp−1)T ,
(15.7)

A ⊔r B

×pU p = [A ×p U p ⊔r B ×p U p],
where r ̸= p,
(15.8)

A ⊔r B

×r

Ur, Wr

= A×rUr + B×rWr,
(15.9)
A ×r
 Xr
Yr

= [(A ×r Xr) ⊔r (A ×r Yr)],
(15.10)
where r, p ∈{1, 2, . . . , R} and the dimensions of the tensors and matrices are A, B ∈CM1×···×MR, Ur,
Wr ∈CNr×Mr , Vr ∈C Pr×Nr , Xr ∈CNr×Mr , and Yr ∈CQr×Mr . The Euclidean (vector) norm, the
Frobenius (matrix) norm, and the Higher-Order Frobenius (tensor) norm are denoted by ∥a∥2, ∥A∥F,
and ∥A∥H, respectively. All three norms are computed by taking the square-root of the sum of the
squared magnitude of all the elements in their arguments. It is easily veriﬁed that
∥A∥H =
[A](n)

F ,
n = 1, 2, . . . , N.
(15.11)
A p × p matrix Qp is called left--real if p · Q∗
p = Qp, where p is the p × p exchange matrix
with ones on its antidiagonal and zeros elsewhere. The special set of unitary sparse left--real matrices
introduced in [15] is denoted as Q(s)
p . They are given by
Q(s)
2n =
1
√
2
 In
jIn
n
−jn

and Q(s)
2n+1 =
1
√
2
⎡
⎣
In
0n×1
jIn
0T
n×1
√
2
0T
n×1
n
0n×1
−jn
⎤
⎦,
(15.12)
for odd and even order, respectively. Furthermore, a matrix X ∈CM×N is called centro-Hermitian if
M · X∗· N = X. The vector ek denotes the kth column of an identity matrix.
3.15.2.2 General data model
Consider an array with M identical omni-directional sensors distributed in the R-dimensional (R-D)
space with complex gain equal to one (see the introductory chapter for a discussion on beam patterns).
The location of each sensor m (for m = 1, . . . , M) is denoted by ϱm in the R-D space. Depending on
the scenario the array geometry could be fully known or could be divided into many smaller known
subarrays in the case of partially calibrated arrays. Assume that there are d (d < M) far-ﬁeld point
sources emitting narrow-band signals whose baseband model at time t is denoted by s(t). These sources
are assumed to be located at azimuth angles θ1, θ2, . . . , θd and at elevation angles φ1, φ2, . . . , φd (see
Figure 15.1). Estimating these angles, called direction-of-arrivals (DOAs), are the objective of various
estimation techniques. We also assume that N observations or snapshots are available at times tn,

656
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
y
z
x
•
source
φ
θ
FIGURE 15.1
Coordinate system for one source.
i.e., n = 1, 2, . . . , N. Throughout the text, the number of the sources is assumed to be known or can be
estimated using the well-known methods presented in [54–56]. Moreover, the sources are considered
to be uncorrelated. The mth sensor noise for m = 1, 2, . . . , M is modeled as independently identically
distributed (i.i.d.) zero-mean complex white Gaussian additive noise, i.e.,
nm(t) ∼CN(0, σ 2).
(15.13)
Furthermore, the noise vector n(t) can be written as
n(t) = [n1(t) n2(t)
· · ·
nM(t)]T .
(15.14)
The noise is assumed to be both spatially and temporally white, hence
E{n(t1)nH(t2)} =

σ 2IM, t1 = t2,
0,
t1 ̸= t2.
(15.15)
The full observation matrix (also referred to as array output signal) is given by
X = [x(t1) x(t2)
· · ·
x(tN)]
(15.16)
in which the tth snapshot of the array observation vector in the presence of the sensor noise n(t) is
given by
x(t) =
d

l=1
a(θl, φl)sl(t) + n(t),
(15.17)
= A(θ, φ)s(t) + n(t),
(15.18)

3.15.2 Data Model
657
where θ =

θ1 θ2 · · · θd
T and φ =

φ1 φ2 · · · φd
T are, respectively, the azimuth and the elevation
angles of the source DOAs, the vector a(θl, φl) indicates the array response (commonly referred to as
array steering vector) to the lth source,2 and
s(t) =

s1(t) s2(t)
· · ·
sd(t)
T
(15.19)
is the signal waveform vector which is assumed to be stochastic. The matrix A(θ, φ) can be represented
as containing d column-vectors each corresponding to a source such that
A(θ, φ) =

a(θ1, φ1) a(θ2, φ2)
· · ·
a(θd, φd)

.
(15.20)
Thus, the full observation matrix can be written as
X = X0 + N,
(15.21)
where N = [n(t1) n(t2) · · · n(tN)] and the noiseless observation matrix is given by X0 = A(θ, φ)S in
which the source signal matrix S =

s(t1) s(t2) · · · s(tN)

.
Generally, the mth element of the array steering vector [a(θl, φl)](m), i.e., the response of sensor m
to the lth source, can be shown to be [22]
[am(θl, φl)](m) = gm(θl, φl) · e jkT
l ϱm,
(15.22)
where kl is deﬁned as the wavenumber corresponding to plane wave impinging on the array from the
direction of the lth source such that
kl = −2π
λ
⎡
⎣
cos θl sin φl
sin θl sin φl
cos φl
⎤
⎦,
(15.23)
where the azimuth and the elevation angles are deﬁned similar to those in the spherical coordinate
system, i.e., θ is the azimuth angle in the xy-plane from the x-axis and φ is the elevation angle from
positive z-axis (see Figure 15.1). It is customary to assume, without loss of generality, that the ﬁrst
sensor is placed in the origin of the coordinate system. Moreover, the term gm(θl, φl) ∈C in (15.22) is
the complex beam pattern of the antenna array at the azimuth angle θl and the elevation angle φl. In the
special case where the elements are assumed to be isotropic we have gm(θ, φ) = 1, ∀θ, φ.
3.15.2.3 Special array structures
In this part, arrays with special structures are taken into account. The popularity of many of such arrays
is due to their array steering matrix structural feature which can be exploited to develop search-free low
computational complexity DOA estimation algorithms.
3.15.2.3.1
Uniform linear arrays (ULAs)
In a uniform linear array (ULA), all the M sensors lie on a line and the distance between the adjacent
sensors is identical 	 for any two adjacent sensor, see Figure 15.2. Hence, if we assume the ﬁrst sensor
2Depending on the situation and for sake of simplicity, the array steering vectors and/or matrices will be indexed by the
azimuth θ and the elevation φ, or by the spatial frequency μ given, for example, by (15.28) and (15.29) in the 2-D context
using a uniform rectangular array.

658
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
x
Δ
FIGURE 15.2
Uniform linear array geometry with M = 6 sensors.
to be the reference sensor, for a ULA of size M it can be said that
ϱm = (m −1)	,
m = 1, . . . , M.
(15.24)
The ULAs are unable to distinguish between sources with different elevation angles. Hence, ULAs are
incapable of estimating the elevation angles of the source DOA [57], i.e., φ1, . . . , φd. The lth element
of the array steering vector for ULA lying on the x-axis can be written as

a(θl)

(m) = e j 2π
λ (m−1)	 cos θl.
(15.25)
Later we will see that sometimes it is more useful to write the array steering vector of a ULA as a
function of spatial frequency μ rather than as a function of DOAs. The spatial frequency associated
with the lth source is deﬁned as
μl = 2π
λ 	 cos θl.
(15.26)
Then, the ULA steering matrix can be written as follows:
A(μ) =

a(μ1) a(μ2)
· · ·
a(μd)

=
⎡
⎢⎢⎢⎢⎢⎣
1
1
· · ·
1
e jμ1
e jμ2
· · ·
e jμd
e j2μ1
e j2μ2
· · ·
e j2μd
...
...
...
...
e j(M−1)μ1
e j(M−1)μ2
· · · e j(M−1)μd
⎤
⎥⎥⎥⎥⎥⎦
,
(15.27)
where μ =

μ1 · · · μd
T . As it can be observed the obtained array steering matrix for a ULA is a
Vandermonde matrix [7].
3.15.2.3.2
Minimum redundancy linear arrays
In [58] Moffet introduced a class of non-uniform spaced linear arrays in order to achieve best DOA
estimation performance for a given number of sensors. This class is the so-called minimum redundancy
arrays. Let us consider the one dimensional case where the ﬁrst sensor denotes the reference sensor such
that ϱ1 = 0. Let 	g denotes the greatest common divisor of all existing inter-element. The minimum
redundancy array are deﬁned such that:
•
All intermediate distances are present, i.e., one has m	g ∈D, ∀m ∈{1, 2, . . . , M −1} in which D
contains all the existing sensors inter-element.
•
Minimize the number of the redundant lags, i.e., pairs of sensors separated by the same distance.

3.15.2 Data Model
659
x
y
Δ
FIGURE 15.3
Uniform rectangular array geometry with M1 = 6 and M2 = 3 sensors.
3.15.2.3.3
Uniform rectangular arrays (URAs)
In a uniform rectangular array (URA), the sensors lie on uniform grid of a rectangular shape where
the sensor spacing is equal to 	 (see Figure 15.3). We assume that the URA lies on the xy-plane and
it consists of sensors in a grid of size M1 × M2, hence the total number of sensors is M = M1M2.
It should be remarked that unlike ULAs, URAs are capable of estimating both the azimuth and the
elevation angles of the source DOAs. Deﬁning the spatial frequencies associated with azimuth and
elevation angles of the lth source, respectively,
μ(1)
l
= 2π
λ 	 cos θl sin φl,
(15.28)
μ(2)
l
= 2π
λ 	 sin θl sin φl,
(15.29)
it can be shown that the URA steering vector corresponding to the lth source can be formed as
a

μ(1)
l
, μ(2)
l

= a

μ(1)
l

⊗a

μ(2)
l

,
(15.30)
where a

μ(1)
l

and a

μ(2)
l

are equivalent to the ULA steering vectors composed of M1 and M2
sensors, respectively.
3.15.2.3.4
Uniform circular arrays (UCAs)
The uniform circular array (UCA) is a speciﬁc class of planar arrays where all sensors lie in a unique
circle such that the angular separation, ζ, between two successive sensors is the same, see Figure 15.4.
The UCA is generally preferred to the ULA due to the ambiguities introduced by the linear arrays [59].
The steering vectors are given as
[a(θl, φl)](m) = e j 2πr
λ cos (θl−γm) sin (φl),
(15.31)
where r, γm denote the radius of the array and the angle of the mth sensor.
3.15.2.3.5
Centro-symmetric arrays
An array is called centro-symmetric if it can be mirrored around its centroid without changing its
geometry, see, for example, Figure 15.5. Mathematically speaking, its array steering matrix must satisfy

660
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
•
•
•
•
•
•
•
•
x
y
ζ
γm
FIGURE 15.4
Uniform circular array geometry with M = 8.
•
γ 1
γ 1 + π
2
•
•
•
•
•
x
y
FIGURE 15.5
Centro-symmetric circular array geometry with M = 6.
the property
M · A∗= A · .
(15.32)
Here,  is a diagonal matrix containing phase terms which account for the fact that the phase reference
does not necessarily coincide with the array’s centroid, e.g., ULAs or UCAs. Note that for condition
(15.32) to be valid, the array elements do not need to be omnidirectional. We can have an arbitrary
complex beam pattern gm(θ, φ) for the antennas, as long as all elements have identical beam patterns,
i.e., gm(θ, φ) = g(θ, φ) for m = 1, 2, . . . , M.
3.15.2.3.6
Partially calibrated arrays
Although sensor arrays with large aperture size are favorable but these arrays are costly. Moreover, they
are more susceptible to modeling errors (such as sensor mutual coupling, channel mismatches between
subarrays, sensor gain and phase uncertainties, array geometry uncertainties, and time synchronization
issue) and classic subspace-based DOA estimation methods are known to be sensitive to these errors.
To avoid the modeling errors in the process of DOA estimation, the idea of large-aperture sparse sensor

3.15.2 Data Model
661
x
y
subarray 2
subarray 3
subarray 1
η1
η2
η3
FIGURE 15.6
3 Arbitrary known subarrays with arbitrary unknown displacements.
arrays is presented. Sparse sensor arrays is divided into K smaller subarrays that are much easier to
calibrate. Hence, these arrays are referred to as partially calibrated arrays (PCAs), see Figure 15.6.
For this class of arrays, the array steering matrix, which is as always a function of DOAs, is also
a function of new unknown signal-independent parameters which are the modeling errors. This set of
parameters is denoted by η =

η2 η3 · · · ηK
T . For instance, η can indicate the unknown (or uncertain)
displacement vectors η2, η3, . . . , ηK between the ﬁrst (or reference) subarray and the other subarrays,
c.f. Figure 15.6. To estimate the source DOAs, in this case, the array steering matrix is normally
partitioned such that the part which solely depends on the DOAs is separated from other part(s) that
depends on the unknown modeling errors and the DOAs. Hence, the structure of the array steering
matrix (or vector) can be exploited to estimate the DOAs by circumventing the modeling errors in the
steering matrix. The partitioning of the array steering matrix can be done in various ways for different
estimation schemes which will be discussed when those schemes are presented.
3.15.2.3.7
Multidimensional arrays
The ULA and URA conﬁgurations can be generalized to the R-D case by considering R-dimensional
sampling grids. In order to be able to apply R-D algorithms such as R-D matrix-based or tensor-based
ESPRIT, this grid needs to satisfy certain properties.
In particular, an R-dimensional sampling grid is called separable if it can be constructed from
an outer product of R one-dimensional sampling grids. In other words, for each dimension we can
design the sampling freely but then all combinations of sampling points must be present in the sampled
data. Examples of not separable and separable 2-D sampling grids are shown in Figure 15.7a and b,
respectively. Figure 15.7c shows the special case of a 2-D uniform sampling grid which is assumed
for URAs.3
3Hexagonal arrays are another example of non-separable 2-D arrays. Therefore, we cannot apply tensor calculus there, even
though the application of 3-D Unitary ESPRIT is possible, as we have shown in [60,61].

662
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
(a)
(b)
(c) 
(1)
(2)
FIGURE 15.7
Examples of 2-D sampling grids: (a) not a separable 2-D sampling grid; (b) separable 2-D sampling grid
composed of the outer product of two (non-uniform) linear arrays; (c) uniform separable 2-D grid.
FIGURE 15.8
3-D array geometry with M1 = M2 = M3 = 3.
Separable R-D sampling grids lead to array manifolds that are separable with respect to the R
dimensions. To this end, let a

μ(r)
∈CMr×1 be the array manifold in the rth dimension, comprising
Mr sampling points, where μ(r) is the spatial frequency in the rth dimension. Then the array manifold
of the R-D array satisﬁes
a

μ(1), . . . , μ(R)
= a

μ(1)
⊗· · · ⊗a

μ(R)
∈CM×1,
(15.33)
where ⊗represents the Kronecker product and
M =
R

r=1
Mr.
(15.34)
In the special case where a

μ(r)
is chosen uniformly in all dimensions r = 1, 2, . . . , R, the
R-D array is referred to as a uniform R-D sampling grid. Uniform R-D sampling can be seen as the
generalization of ULAs and URAs to R dimensions. Figure 15.8 exempliﬁes such a grid for R = 3.
Note that dimensions are not restricted to spatial dimensions. We can also consider time and frequency
dimensions, for instance.

3.15.2 Data Model
663
Note that for 2-D antenna arrays, the following conditions must be fulﬁlled so that the array manifold
becomes separable:
1. The array elements are placed in a 2-D grid that is separable, i.e., it can be constructed as the outer
product of two 1-D grids.
2. The complex beam patterns gm(θ, φ) are either
a. expressed via a separable function over the direction cosines μ(r) corresponding to the two array
dimensions, cf. (15.28) and (15.29), or
b. equal for all antenna elements, i.e., gm(θ, φ) = g(θ, φ) for m = 1, 2, . . . , M (including their
spatial orientation in the array). In the latter case, separability is not needed.
If the 2-D array does not obey the two assumptions, its two dimensions cannot be separated and we
have to stack the elements in one mode of our measurement tensor.
The Kronecker-structured array manifold shown in (15.33) can be represented via tensors in a very
natural way. Instead of stacking the R dimensions along of the rows of a long array steering vector
a, we can preserve the natural R-D structure by considering an array steering tensor [42]. For the ith
wavefront we can write
Ai = a

μ(1)
i

◦a

μ(2)
i

◦· · · ◦a

μ(R)
i

∈CM1×M2×···×MR,
(15.35)
where ◦represents the outer product and i = 1, 2, . . . , d. Similar to the array steering matrix A ∈
CM×d we can deﬁne an array steering tensor by concatenating the Ai from (15.35) by virtue of the
concatenation operator ⊔n (cf. Section 3.15.2.1)
A =

A1⊔R+1A2⊔R+1 · · · ⊔R+1Ad

.
(15.36)
Likewise,
the
multidimensional
observations
can
be
arranged
into
a
measurement
tensor
X ∈CM1×···×MR×N. Together with (15.36) we may write
X = A ×R+1 ST + N = X 0 + N ,
(15.37)
which is the tensor-based equivalent of (15.21). The relations to the matrix-based model are given by
X = [X]T
(R+1),
A = [A]T
(R+1),
N = [N ]T
(R+1).
(15.38)
3.15.2.3.8
R-D shift invariance structure
For R-D matrix shifting-based algorithms we additional require an R-D shift invariance in the array.
This means that the array can be divided into two subarrays that are identical except for a displacement
in all R dimensions. Since for an R-D harmonic wave, a displacement in the rth mode incurs a phase
offset proportional to the frequency of the wave in the rth mode, frequency estimates are obtained by
estimating the phase offsets for all waves in all R modes.
To estimate the frequencies of an R-D harmonic wave in all dimensions4 in this manner, we require
a shift invariance of the sampling grid in all R dimensions. This can be expressed via tensor calculus in
4If the signal is harmonic only in R′ of the R dimensions (R′ < R), we can apply R′-D ESPRIT in these modes and leave
the others modes untouched. In this case the R −R′ “non-harmonic” dimensions simply provide additional snapshots (which
we collect in mode R + 1 in our data model for simplicity).

664
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
a natural way. Let Ai ∈CM1×M2···×MR be the “array steering tensor” of the ith wavefront as deﬁned in
(15.35). Then, the shift invariance of Ai in the rth mode can be expressed as

Ai ×r J(r)
1

· ej·μ(r)
i
= Ai ×r J(r)
2 ,
r = 1, 2, . . . , R,
(15.39)
where J(r)
1
and J(r)
2
∈RM(sel)
r
×Mr are the selection matrices which select the M(sel)
r
out of Mr indices
belonging to the ﬁrst and the second subarray in the rth mode, respectively. Moreover, μ(r)
i
is the spatial
frequency of the ith wavefront in the rth mode for i = 1, 2, . . . , d and r = 1, 2, . . . , R.
For the special case of an R-D uniform sampling grid introduced above we choose J(r)
1
and J(r)
2
to
J(r)
1
= [IMr−1
0(Mr−1)×1] J(r)
2
= [0(Mr−1)×1
IMr−1],
(15.40)
such that M(sel)
r
= Mr −1, which corresponds to maximally overlapping subarrays.
The shift invariance relation for a single source from (15.39) can be extended to consider all d sources
jointly. We obtain [42]
A ×r J(r)
1
×R+1 (r) = A ×r J(r)
2 ,
(15.41)
where A
=
[A1⊔R+1A2⊔R+1 · · · ⊔R+1Ad]
∈
CM1×M2···×MR×d is the array steering tensor
(cf. (15.36)) and
(r) = diag

[ej·μ(r)
1 , . . . , ej·μ(r)
d ]

∈Cd×d.
(15.42)
Note that a matrix-based equivalent of (15.41) in terms of the array steering matrix A = [A]T
(R+1) is
found by considering the transpose of the (R + 1)-mode unfolding of (15.41). Using (15.6) we obtain
J(r)
1
· A · (r) = J(r)
2
· A,
where
(15.43)
J(r)
n
= (IM1 ⊗· · · ⊗IMr−1) ⊗J(r)
n
⊗(IMr+1 ⊗· · · ⊗IMR),
n = 1, 2,
(15.44)
which coincides with the matrix-based shift invariance equations derived in [21].
Note that in the 1-D case, the shift invariance equation simpliﬁes into
J1 · A ·  = J2 · A.
(15.45)
Figure 15.9 shows the 2-D shift invariance of a 5 × 4 separable 2-D sampling grid. The left-hand
side shows how to choose the selection matrices J(1)
1
and J(1)
2
for the ﬁrst dimension (horizontal) and
the right-hand side shows how to choose the selection matrices J(2)
1
and J(2)
2
for the second dimension
(vertical), i.e.,

3.15.2 Data Model
665
˜
J (1)
1
˜
J (1)
2
˜
J (2)
1
˜
J (2)
2
FIGURE 15.9
2-D shift invariance for a 5×4 separable 2-D sampling grid. Left: subarrays for the ﬁrst (horizontal) dimension,
right: subarrays for the second (vertical) dimension.
J(1)
1
=
⎡
⎣
1 0 0 0 0
0 1 0 0 0
0 0 0 1 0
⎤
⎦,
J(1)
2
=
⎡
⎣
0 1 0 0 0
0 0 1 0 0
0 0 0 0 1
⎤
⎦,
J(2)
1
=
 1 0 0 0
0 0 1 0

,
J(2)
2
=
 0 1 0 0
0 0 0 1

.
Moreover, J(1)
n
= J(1)
n
⊗I4 and J(2)
n
= I5 ⊗J(2)
n
for n = 1, 2.
3.15.2.4 Non-circular data
Up to here we have not made any further assumptions about the amplitudes of the multidimensional
signals which we collect in the matrix S (cf. (15.21)), except for the fact that the rank of S should be equal
to d. However, as we discuss in Sections 3.15.4.2 and 3.15.4.3.3, via simple modiﬁcations of ESPRIT-
type algorithms5 [46,47] we can take advantage of a particular structure in these amplitudes referred
to as second-order non-circularity. This occurs for instance in communication-type scenarios where the
transmitters employ speciﬁc modulation schemes, such as binary phase shift keying (BPSK), amplitude
shift keying (ASK), minimum shift keying (MSK), or Offset Quadrature Phase Shift Keying (OQPSK).
A full statistical description of complex random variables includes not only the individual distribution
of their real and imaginary parts but also the joint distribution since they might be correlated. A simpli-
fying assumption that is often made is to consider second-order circularly symmetric complex random
variables. A zero mean complex random variable Z = X + jY is said to be second-order circularly
symmetric if it satisﬁes E{Z2} = 0, which implies that real part and imaginary part are uncorrelated
5Many other subspace-based parameter estimation schemes have been enhanced to beneﬁt from non-circular sources as well,
e.g., [45,62–64].

666
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
and have the same variance. Consequently, if E{Z2} ̸= 0, the random variable Z is (second-order)
non-circular. We can measure the degree of non-circularity via a scalar parameter ζ referred to as the
“non-circularity rate” [65], “circularity coefﬁcient” [66], or “circularity quotient” [67],
ζ = E{Z2}
E{|Z|2}.
(15.46)
It can be shown that |ζ| ≤1. A random variable with 0 < |ζ| < 1 is called (second-order) weak-
sense non-circular, for |ζ| = 1 we speak of (second-order) strict-sense non-circularity. Strict-sense
non-circular random variables are sometimes also referred to as rectilinear [68]. Note that strict-sense
non-circularity implies a linear dependence between real and imaginary part of Z. We can think of Z
as a real-valued random variable which is rotated by a complex phase term, i.e., Z = W · ejϕ, where
W ∈R is a random variable and ϕ is deterministic (ﬁxed). In a communication system, the amplitudes
si(t) are non-circular random variables if the symbols are drawn from constellations which are not
circularly symmetric. We obtain strict-sense non-circular amplitudes if the transmitters use real-valued
constellations (such as BPSK or ASK), which appear rotated by complex phase terms at the receiver
since each transmitter may have a different transmission delay. Note that OQPSK and MSK symbols
can be transformed into rectilinear amplitudes by applying an appropriate derotation at the receiver [68].
Figure 15.10 shows an example of an I/Q diagram displaying Inphase vs. Quadrature (I/Q) components
Re (si ( t ) )
Im (si ( t ) )
1
2
User 1
User 2
FIGURE 15.10
Example for strict-sense non-circular amplitudes: two users (red, blue) transmit symbols drawn from real-
valued constellations. Since they undergo different phase rotations, the I/Q diagram at the receiver consists
of differently rotated real-valued random variables, i.e., the complex symbols si(t) can be described as strict-
sense non-circular random variables. (For interpretation of the references to color in this ﬁgure legend, the
reader is referred to the web version of this book.)

3.15.3 Subspace Estimation
667
of the received symbols for two users that transmit using a real-valued constellation. Since each user’s
transmission undergoes a different phase rotation (ϕi), the receiver observes rotated real-valued random
variables that satisfy the strict-sense non-circularity property. For the source symbol matrix S ∈Cd×N
this implies the structure [45]
S = 	 · S0,
(15.47)
where S0 ∈Rd×N and 	 = diag([ejϕ1, . . . , ejϕd]).
Non-circular random variables can be exploited in signal processing applications since they carry a
speciﬁc structure. If s[n] is a non-circular random variable in addition to the covariance matrix 
s =
E

s[n] · s[n]H
, the pseudo-covariance matrix 
s = E{s[n] · s[n]T } contains statistical information
about s[n] we can take advantage of. For circular random variables, the pseudo-covariance matrix is
equal to the zero matrix.
3.15.3 Subspace estimation
3.15.3.1 Matrix-based subspace estimation
The covariance matrix of the array output signal is deﬁned as

x ≜E{x(t)xH(t)}
= AE{s(t)sH(t)}AH + E{n(t)nH(t)}
= A
sAH + σ 2IM
(15.48)
in which it is assumed that the noise and the signals are independent and have zero-mean. Moreover, in
(15.48), we deﬁne the signal covariance matrix as

s ≜E{s(t)sH(t)}.
(15.49)
Assuming that the signals are uncorrelated, the d × d matrix 
s becomes diagonal and non-singular
such that

s = diag{σ1, σ2, . . . , σd},
(15.50)
where σl ̸= 0 for l = 1, . . . , d is the signal power of the lth source. Therefore, since the M × d array
steering matrix A is of full-column rank, the M × M matrix A
sAH is rank-deﬁcient and of rank d.
This low-rank property can be exploited in the presence of the sensor noise to construct two subspaces
which are at the foundation of the subspace-based estimation methods. From (15.48) it can be observed
that 
x has M −d eigenvalues equal to the noise power σ 2 and d eigenvalues greater than σ 2. In other
words, if we deﬁne λm as the mth largest eigenvalue of 
x then
λ1 ≥λ2 ≥· · · ≥λd > λd+1 = · · · = λM = σ 2.
(15.51)
Hence the L largest eigenvalues of 
x are called signal eigenvalues and the rest of the M −d eigenvalues
are called noise eigenvalues. After performing the eigen-decomposition on the array output covariance

668
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
matrix 
x we write

x =
M

m=1
λmumuH
m
= UssUH
s + UnnUH
n
= UssUH
s + σ 2UnUH
n ,
(15.52)
where s and n denote, respectively, the d×d and the (M −d)×(M −d) diagonal matrices containing
the signal and the noise eigenvalues
s = diag{λ1, λ2, . . . , λd},
(15.53)
n = σ 2IM−d.
(15.54)
Moreover, the M ×d signal- and the M ×(M −d) noise-eigenvector matrices Us and Un, respectively,
contain the eigenvectors corresponding to the signal and to the noise eigenvalues. We will refer to the
matrices Us and Un as signal subspace matrix and noise subspace matrix, respectively.
It is well-known that assuming both A and 
s to be full column-rank matrices, both the array steering
matrix and the signal-eigenvectors subspace span the same subspace, i.e.,
range{Us} = range{A},
(15.55)
whereas, the columns of Un span its orthogonal complement, i.e., the null space of AH. Consequently,
UsUH
s = A(AHA)−1AH,
(15.56)
UnUH
n = IM −A(AHA)−1AH.
(15.57)
In other words, for some full-rank d × d matrix P, called mixing matrix, the following important
relationship can be formed which will be referred to in the text many times
A = UsP.
(15.58)
Similarly, since P is nonsingular, hence invertible, we can also write
Us = AP−1
= AP′,
(15.59)
where for the simplicity in the notations in the later sections we deﬁne
P′ ≜P−1.
(15.60)
The true array covariance matrix is generally unknown in practice, therefore its ﬁnite sample estimate

x = 1
N
N

t=1
x(t)xH(t),
(15.61)

3.15.3 Subspace Estimation
669
which is the maximum likelihood estimate of the 
x in (15.48) in the case of Gaussian noise is used.
It is assumed that the number of snapshots is larger than the number of sensors, i.e., N ≥M. This
assumption is required so that the rank of the obtained sample covariance matrix 
x (in the presence
of the noise) becomes equal to M; a necessary condition for the subsequent construction of the signal
and noise subspaces for the subspace-based methods which are discussed in next chapter.
Let ˆλm, for m = 1, . . . , M, denote the mth largest eigenvalue of the sample covariance matrix 
x in
(15.61) such that
ˆλ1 ≥ˆλ2 ≥· · · ≥ˆλd ≥ˆ−λd+1 ≥· · · ≥ˆλM.
(15.62)
Similar to the true covariance matrix 
x the eigenvalues can be divided into the signal eigenvalues
containing the d largest eigenvalues, i.e., ˆλ1, . . . , ˆλd, and the noise eigenvalues consisting of M −d
smallest eigenvalues, i.e., ˆλd+1, . . . , ˆλM. Similarly, the eigen-decomposition of the sample covariance
matrix 
x can be written as

x =
M

m=1
ˆλm ˆum ˆuH
m
= Us s U
H
s + Un n U
H
n ,
(15.63)
where s and n denote, respectively, the d×d and the (M −d)×(M −d) diagonal matrices containing
the signal and the noise eigenvalues
s = diag{ˆλ1, ˆλ2, . . . , ˆλd},
(15.64)
n = diag{ˆλd+1, ˆλd+2, . . . , ˆλM}.
(15.65)
The matrices Us and Un are, respectively, the estimates of the M × d signal- and the M × (M −d)
noise-eigenvector matrices consist of the eigenvectors corresponding to the signal and to the noise
eigenvalues.
Note that, instead of performing an eigendecomposition of (15.63) and ﬁnding the d dominant
eigenvectors, one can also compute an SVD of the measurement matrix X directly and obtain Us from
the d dominant left singular vectors. The truncated SVD of X is given by
X ≈Us · 
s · V
H
s ,
(15.66)
where 
s ∈Rd×d and Vs ∈CN×d. We refer to this process as the “direct data approach” to obtain the
subspace.
3.15.3.2 Subspace estimation with a small number of snapshots
In particular applications, the number N of available data snapshots in (15.18) may be insufﬁcient to
span the entire signal subspace. The rank of the sample covariance matrix 
x in (15.61) is however
lower bounded by the number of linearly independent snapshots. Hence, in case that N < d the sample
covariance matrix exhibits a rank smaller than d. In other words, there exist at least M −N > N −d
zero eigenvalues and the signal subspace can no longer be extracted from the d principal eigenvectors as
in the large snapshot case. To overcome these difﬁculties the redundancy in the data snapshots resulting

670
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
from the uniform linear array structure encountered in uniform R-D arrays can be exploited to create
additionally, so-called virtually, snapshots. Consider for simplicity the ULA geometry composed of M
omni-directional sensor as deﬁned in (15.25). A generalization of the spatial smoothing technique to
general uniform linear R-D array structures is then straight forward. The ULA can be decomposed in K
overlapping identical uniform linear subarray of length Msub = M −K + 1 > d such that
asub(μ) ≜

1, e jμ, . . . , e j(Msub−1)μT
= e j(k−1)μJka(μ),
(15.67)
where a(μ) is deﬁned in (15.27) and where
Jk ≜
 0Msub×(k−1)
IMsub
0Msub×(M−k+1)
T
(15.68)
is a Msub × M subarray selection matrix. With the above deﬁnition it can readily be veriﬁed that
xsub(t) ≜Jkx(t) = Asubs(t) + Jkn(t)
= Asubk−1s(t) + Jkn(t)
= Asubsk(t) + nk(t)
(15.69)
for k = 1, . . . , K where sk(t) ≜k−1s(t), nk(t) ≜Jkn(t), Asub = JkA and
 ≜diag{e jμ1, . . . , e jμd}
(15.70)
is deﬁned in accordance to (15.42). We observe from (15.69) that K generally linearly independent
snapshots xsub of size Msub × 1 can be obtained from a single measurement x(t) of size M × 1.
In this case, even from a single snapshot a sample covariance matrix of rank Msub can generally be
computed as

x(t) ≜1
K
K

k=1
xk(t)xH
k (t)
≃Asub

1
K
K

k=1
sk(t)sH
k (t)

AH
sub + 1
K
K

k=1
nk(t)nH
k (t)
= AMsub 
s,K (t)AH
Msub + 
n(t),
(15.71)
where

s,K (t) ≜1
K
K

k=1
sk(t)sH
k (t)
= 1
K
K

k=1
k−1s(t)sH(t)(∗)k−1
(15.72)
and 
n(t) ≜
1
K
K
k=1 nk(t)nH
k (t) denote signal and noise sample covariance matrices, respectively,
corresponding to the tth snapshot. Note that the latter approximation is based on the consideration

3.15.3 Subspace Estimation
671
that due to the independence of the source and noise signals for sufﬁciently large K, the cross terms
can be neglected. The process of averaging overlapping subarray snapshots is generally referred to
as spatial smoothing. Taking statistical expectation on both sides of (15.72) we further observe that
spatial smoothing can also applied in the case of correlated or coherent sources, i.e., when the signal
covariance matrix 
s ≜E{s(t)sH(t)} in (15.49) is rank deﬁcient. Unlike the conventional (estimated)
signal covariance matrix, the spatially smoothed estimate

s,K ≜E{
s,K (t)}
= 1
K
K

k=1
k−1E{s(t)sH(t)}(∗)k−1
= 1
K
K

k=1
k−1
s(∗)k−1
(15.73)
generally exhibits up to K times the rank of 
s, obviously however, without exceeding a rank equal
to the dimension d. Despite the beneﬁts of spatial smoothing in the case of small snapshot numbers
and correlated sources we remark that there is a performance penalty associated with non-coherent
averaging over subarray snapshots, resulting in reduced resolution capability of the DOA estimation
methods due the reduction of the aperture size. Further, we note that due to the reduction of the effective
array size from M to M −K +1, the total number of resolvable sources is reduced in spatial smoothing.
In practice, a compromise between the subspace separation capability of the sample covariance matrix,
the resolution performance of the DOA estimation methods, and the computational complexity needs
to be found [26,69,70].
3.15.3.3 Forward-backward averaging and real-valued subspace estimation
If the array is centro-symmetric, i.e., M · A∗= A ·  (cf. (15.32)), we can apply forward-backward
averaging (FBA) to the data matrix X. FBA uses a symmetry in the data to create an additional set of
N “virtual” snapshots. Moreover, via FBA, two coherent source can be decorrelated. The augmented
measurement matrix X can be written as
X(fba) = [X
M · X∗· N] ∈CM×2N.
(15.74)
Note that X(fba) has 2N columns, i.e., the number of snapshots has been virtually doubled. Since X(fba) is
a centro-symmetric matrix, we can apply the one-to-one mapping between the set of centro-symmetric
matrices and the set of real-valued matrices from [38]. In other words, the matrix
ϕ

X(fba)
= QH
M · X(fba) · Q2N = T

X

(15.75)
is real-valued for unitary matrices QM that are left--real, i.e., they satisfy Q∗
M·M = QM. The notation
T (X) is introduced to simplify the application of both, FBA and the real-valued transformation. Note
that the transformation (15.75) can be efﬁciently implemented by considering sparse unitary left--
real matrices [15] shown in (15.12). The advantage of (15.75) is that since the matrix is real-valued,

672
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
a subspace estimate is obtained by a real-valued SVD, which has a lower computational complexity
compared to the complex-valued counterpart. A real-valued signal subspace estimate Es ∈RM×d is
then obtained by collecting the d dominant left singular vectors of ϕ

X(fba)
into a matrix. Based on
Es, “unitary” versions of many DOA estimation algorithms can be deﬁned, e.g., the Unitary ESPRIT
algorithm discussed in Section 3.15.4.1.
3.15.3.4 Tensor-based subspace estimation
To ﬁnd a subspace estimate that takes the natural tensor structure into account we employ a multi-
dimensional extension of the SVD in form of a suitable tensor decomposition. We choose the higher-
order SVD (HOSVD) since it is easily computed via SVDs of the unfoldings of the tensor. Moreover,
the truncated HOSVD6 allows for multilinear low-rank approximation in a manner similar to the
truncated SVD.
Let X 0 be the noise-free observation, such that X = X 0 + N . Then, the SVD of rth unfolding of
X 0 and X can be expressed as
[X 0](r) =

U[s]
r
U[n]
r

·


[s]
r
0d×(N−d)
0(M−d)×d
0(M−d)×(N−d)

·

V[s]
r
V[n]
r
H
,
(15.76)
[X](r) =

U
[s]
r
U
[n]
r

·


[s]
r
0d×(N−d)
0(M−d)×d

[n]
r

·

V
[s]
r
V
[n]
r
H
,
(15.77)
where U[s]
r
∈CMr×pr and U[n]
r
∈CMr×(Mr−pr) denote the basis for the r-space and its orthogonal
complement, respectively. Here, pr denotes the r-rank7 of X 0. Based on the r-spaces U[s]
r
we can
estimate the core tensor S[s] ∈C p1×···×pR×pR+1 via
S[s] = X 0 ×1 U[s]H
1
· · · ×R U[s]H
R
×R+1U[s]H
R+1,
(15.78)
S
[s] = X×1 U
[s]H
1
· · · ×R U
[s]H
R
×R+1 U
[s]H
R+1.
(15.79)
The truncated HOSVD then reads as
X 0 = S[s] ×1 U[s]
1 · · · ×R U[s]
R ×R+1 U[s]
R+1,
(15.80)
X ≈S
[s] ×1 U
[s]
1 · · · ×R U
[s]
R ×R+1 U
[s]
R+1 = X.
(15.81)
If we compare the truncated HOSVD of X in (15.81) with the truncated SVD in (15.66), we observe
that a unique feature of the HOSVD is that it performs low-rank approximations in all R + 1 modes.
Hence, the multilinear structure is exploited to perform more efﬁcient denoising.
6Note that, unlike the truncated SVD, the truncated HOSVD does not provide the Least-Squares optimal low-rank approx-
imation of the tensor. In [31], an iterative Higher Order Orthogonal Iterations (HOOI) algorithm is proposed for this task.
However, since the improvement of the HOOI solution compared to the truncated HOSVD is only marginal, we propose to
use the truncated HOSVD for signal subspace estimation.
7In practice, we can estimate the r-ranks individually via a model order selection scheme operating on all unfoldings.
Alternatively, we can apply tensor-based model order selection schemes [71] to estimate d and then use pr = min (Mr, d).

3.15.3 Subspace Estimation
673
As a multilinear extension of the subspace estimate Us we introduce the following signal subspace
tensor 8 U
[s] ∈CM1×···×MR×d
U
[s] = S
[s] ×1 U
[s]
1 · · · ×R U
[s]
R ×R+1 
[s]−1
R+1.
(15.82)
A more formal link between U
[s] and U
[s]
s
is given by the following important identity (shown for
R = 2 in [44])

U
[s]T
(R+1) =

T1 ⊗T2 ⊗· · · T R

· Us,
(15.83)
where Tr ∈CMr×Mr represent estimates of the projection matrices onto the r-spaces of X 0, which are
computed via Tr = U
[s]
r U
[s]H
r
.
It is worth pointing out that (15.83) provides some rather interesting insights. Firstly, it shows that the
matrix

U
[s]T
(R+1) ∈CM×d yields an estimate for the signal subspace, which can be used to replace the
matrix Us. Secondly, it demonstrates that an explicit computation of the core tensor of X is actually not
necessary if only the HOSVD-based subspace estimate is needed. Thirdly, it shows that the HOSVD-
based subspace estimate can be seen as the projection of the (unstructured) matrix-based subspace
estimate onto the Kronecker structure inherent in the data and that this projection is achieved by virtue
of the Kronecker product of r-space projection matrices. Since this projection leaves the desired signal
unaltered it affects only the noise, ﬁltering out the part of the noise which does not obey the required
Kronecker structure. This observation provides a different way of understanding the denoising obtained
via multilinear rank reduction. The relation (15.83) also shows that for any mode r where d ≥Mr we
have Tr = Ir and hence no performance improvement can be obtained in this particular mode r. As a
corollary from this we have

U
[s]T
(R+1) = Us if d ≥maxr=1,2,...,R (Mr), i.e., there is no improvement
in terms of the subspace estimation accuracy from the HOSVD-based subspace estimate if the number
of wavefront d is greater then or equal to the number of sensors in all R modes.
Forward-backward averaging (FBA) and the real-valued transformation that are introduced in
Section 3.15.3.3 for the matrix case can also be formulated in terms of tensors. For forward-backward
averaging we can write [42]
X (fba) = [X⊔R+1X ∗×1 M1 · · · ×R MR ×R+1 N].
(15.84)
The subsequent real-valued transformation can be expressed as
T (X) = X (fba) ×1 QH
M1 · · · ×R QH
MR ×R+1 QH
2N.
(15.85)
Note that the spatial smoothing technique described in Section 3.15.3.2 can also be formulated in tensor
notation, as shown in [42]. Moreover, a tensor-based spatial smoothing technique for 1-D damped and
undamped harmonic retrieval with a single snapshot is discussed in [70]. The extension to multiple
snapshots is introduced in [72] and an R-D extension is shown in [73]. A major advantage of [72,73]
is that the performance of the ESPRIT-type parameter estimates is almost independent of the choice of
the subarray size for the spatial smoothing.
8Note that in [42], U
[s] was deﬁned without the multiplication by 
[s]−1
R+1 in the (R + 1)th mode. While this has no impact on
the subspace of interest, we include it here since this deﬁnition simpliﬁes the notation at this point.

674
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
3.15.4 Subspace-based algorithms
Passive source localization by an array of sensors arises in several applications, such as radio astronomy,
sonar, seismology, radar, geophysics and oceanography. Several algorithms has been proposed to solve
the estimation problem of far-ﬁeld narrowband source localization. Among them, the maximum likeli-
hood (ML) approaches have been shown to reach the best accuracy. Nevertheless, the main drawback
of ML schemes is their computationally cost which make them impractical in reality. To overcome this
drawback, several subspace-based algorithms have been developed in the literature. More precisely, the
key idea is to take into account the intrinsic properties of the eigen-structure of the observed covari-
ance matrix. Based on this, a number of computationally simpler high-resolution algorithm have been
proposed. These subspace-based algorithms can be classiﬁed, into a spectral searching techniques and
search free techniques, as follows:
•
Spectral searching techniques, e.g., MUSIC [74] and its variant (weighted MUSIC [75], Min-
Norm [76,77], sequential MUSIC [78], recursively applied and projected MUSIC [79]), RARE
[80], weighted subspace ﬁtting [81].
•
Search free techniques
– Polynomial-rooting techniques, e.g., root-MUSIC [6] and its variant (unitary root-MUSIC [15],
interpolated root-MUSIC [82]), root-RARE [80], MODE [83], manifold separation [84,85],
Fourier domain root-MUSIC [86].
– Matrix-shifting techniques, e.g., ESPRIT [8] and its variant (Unitary ESPRIT [15], weighted
ESPRIT [14]) and matrix pencil methods [11–13].
3.15.4.1 One-dimensional algorithms using matrix-based subspace estimates
This subsection is dedicated to the one-dimensional algorithms. For sake of simplicity, in the following,
steering vectors will be indexed by θ, z or ˘z depending on the situation.
3.15.4.1.1
MUSIC
As it has been noticed in (15.56), the manifold matrix A(θ) spans the same subspace as the signal
eigenvector matrix Us. Therefore, each column of the array steering matrix is orthogonal to the noise
subspace Un, hence
UH
n a(θl) = 0
(15.86)
for θl = θ1, . . . , θd or equivalently
aH(θl)UnUH
n a(θl) = 0.
(15.87)
This is the core idea of the MUSIC estimation method. In practice, in order to estimate the DOAs, the
estimate of the noise subspace matrix Un obtained from the sample covariance matrix 
x in (15.63)
must be used. Therefore, the following “spectral” function is proposed in [74]
fMUSIC(θ) =
1
∥U
H
n a(θ)∥2
=
1
aH(θ)Un U
H
n a(θ)
.
(15.88)

3.15.4 Subspace-Based Algorithms
675
The estimated DOAs ˆθ1, . . . , ˆθd are, then, obtained by the angles θ corresponding to the d maxima of
fMUSIC(θ). The so-called MUSIC pseudo null-spectrum function fN-MUSIC, given as the denominator of
the MUSIC function in (15.88), can be interpreted as the measure of the projection of the array manifold
vector onto the noise subspace Un which ideally for the true DOAs is zero. Then, the estimated DOAs
are the ones that minimize this projection. To ﬁnd the DOAs, a scan over the entire ﬁeld-of-view (FOV)
is required and the function fMUSIC(θ) in (15.88) needs to be evaluated for each θ.
The popularity of the MUSIC DOA estimation method is due to its relative computational simplic-
ity (compared to maximum-likelihood method which requires multidimensional search [22]), its high
resolution capability (compared to traditional beamforming technique and Capon method [87]), and its
asymptotic efﬁciency [88].
Algorithm 1. Summary of the MUSIC algorithm
1. Compute the eigendecomposition of 
x and obtain the matrix Un.
2. Find the d maxima of fMUSIC(θ) in (15.88) by scanning the entire FOV.
3.15.4.1.2
Weighted MUSIC
As it can be observed, in the MUSIC spectral function of (15.88), all the noise eigenvectors are treated
equally. The MUSIC method can be extended to include a speciﬁc weighting matrix for controlling
the effect of each noise eigenvector on the estimates. A proper choice of the weighting matrix will
be particularly useful to improve the performance of the estimators in difﬁcult situations such as low
number of snapshots and low SNR to overcome some of the shortcomings of the MUSIC method [75].
Toward this end, the following spectrum function is deﬁned to take into account the different effects of
the noise eigenvectors
fWMUSIC(θ) =
1
aH(θ)UnWWMUSIC U
H
n a(θ)
.
(15.89)
It is clear that the conventional MUSIC function in (15.88) is a special case of the weighted-MUSIC
function in (15.89) with WWMUSIC = IM−d. This choice of weight matrix is proved to be the optimal
weight matrix in the sense that it yields the best asymptotic performance [83].
A useful choice of the weighting matrix is
WWMUSIC = U
H
n e1eT
1 Un,
(15.90)
where e1 is the ﬁrst column of the M × M identity matrix. The choice of WWMUSIC in (15.89) coincides
with the well-known Min-Norm method [76,77]. In the Min-Norm method, a non-zero vector with
minimum norm in the noise subspace, i.e., a linear combination of the noise eigenvectors, is obtained.
Then, the orthogonality of this minimum length vector and the array manifold vector is measured similar
to the one used for the MUSIC method in (15.88) for the angles in the FOV. The Min-Norm method is
known to yield an improved resolution capability of distinguishing two close sources, as compared to
the MUSIC method in the ULAs [22].

676
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
Algorithm 2. Summary of the weighted MUSIC algorithm
1. Compute the eigendecomposition of 
x and obtain the matrix Un.
2. Chose the weighting matrix WWMUSIC (e.g., WWMUSIC = IM−d for the MUSIC algorithm,
WWMUSIC = U
H
n e1eT
1 Un for the Min-Norm method).
3. Find the d maxima of fWMUSIC(θ) in (15.89) by scanning the entire FOV.
3.15.4.1.3
Root-MUSIC
The root-MUSIC DOA estimation method [6] exploits the Vandermonde structure of the array manifold
vector in the ULAs in (15.24) to estimate the DOAs through a search-free algorithm based on polynomial
rooting. Deﬁning
z = e
2π
λ 	 cos θ
(15.91)
the parametric array manifold vector a(z) becomes
a(z) =

1 z
z2
· · ·
zM−1T
.
(15.92)
Furthermore, it is simple to show that
aH(z) = aT
1
z

.
(15.93)
Then, the MUSIC criteria in (15.87) for the true DOAs transforms into
aT
1
z

UnUH
n a(z) = 0.
(15.94)
From (15.93), it can be seen that if z is a root of the polynomial in (15.94), then its conjugate reciprocate
1/z∗is also a root. Therefore, the polynomial in (15.94), which is of degree 2M −2, has 2M −2 roots
with M −1 roots on/inside the unit-circle and their M −1 conjugate reciprocate pairs on/outside the
unit-circle. In practice, the estimate of the noise subspace matrix, i.e., Un in (15.63), from the sample
covariance matrix 
x in (15.61) is used and the following polynomial is obtained
froot-MUSIC(z) = aT
1
z

Un U
H
n a(z).
(15.95)
Thetruespatialfrequencies,i.e.,theonesassociatedwiththetrueDOAs,areontheunit-circle.Therefore,
to estimate the DOAs from froot-MUSIC(z), the d complex roots of froot-MUSIC(z), namely ˆz1, . . . , ˆzd,
closest to the unit-circle and inside it should be selected and the estimated DOAs can be computed for
l = 1, . . . , d from
ˆθl = cos−1

λ
2π	∡(Zl)
 
,
(15.96)
where ∡(·) denotes the phase of a complex variable. It has been demonstrated [88,89] that both MUSIC
and root-MUSIC have the same asymptotic performances. From (15.96), one can observe that the

3.15.4 Subspace-Based Algorithms
677
estimated DOA ˆθl (for l = 1, . . . , d) depends only on the phase of the root ˆzl of the root-MUSIC
polynomial in (15.95) and not on the magnitude of ˆzl. Hence, any changes in the magnitude has no
effect on the estimated DOAs and the root-MUSIC method is robust to the radial errors of the estimated
roots [90]. Because of this property, the root-MUSIC method enjoys superior performance in comparison
to the MUSIC method in low SNR and low number of snapshots. One can notice that, the root-MUSIC
method is only applicable to the ULAs and also to the uniform circular arrays (UCAs) [59], and not
to any arbitrary array geometry (unlike the MUSIC method). However, there are methods, such as
array interpolation [91] and beamspace methods [92], in which the array manifold of an arbitrary
array geometry can be approximately transformed into the array manifold of a virtual ULA so that the
root-MUSIC method can be implemented.
Algorithm 3. Summary of the root-MUSIC algorithm
1. Compute the eigendecomposition of 
x and obtain the matrix Un.
2. Root the polynomial aT 
1
z

Un U
H
n a(z).
3. Find the DOA estimates using the largest magnitude roots which lie inside the unit circle.
3.15.4.1.4
Unitary root-MUSIC
The computational complexity of the root-MUSIC estimation technique can be further reduced by
using a unitary transformation to reformulate the complex-valued algorithm to the real-valued one
which makes its implementation simpler.
Let Q(s)
M be any unitary, column conjugate symmetric, i.e., M

Q(s)
M
∗
= Q(s)
M see (15.12).
Deﬁne the real-valued sample covariance matrix C ≜

Q(s)
M
H 
FBQ(s)
M where 
FB is the sample
covariance matrix obtained from forward-backward averaging, i.e., 
FB
≜

x + P 
∗
xP.
Thus, it can be easily shown that
C = Re

Q(s)
M
H 
xQ(s)
M
 
.
(15.97)
The eigenvalues and the eigenvectors of the real-valued sample covariance matrix C and the sample
forward-backward matrix 
x are related through the unitary matrix Q(s)
M such that [15]
ˆum,Q(s)
M =

Q(s)
M
H
ˆum,FB,
(15.98)
ˆλm,Q(s)
M = ˆλm,FB,
(15.99)
where ˆum,FB and ˆum,Q(s)
M are the eigenvectors corresponding to the mth largest eigenvalue of 
x and C,
respectively, and λm,FB and λm,Q(s)
M are the mth largest eigenvalues of 
x and C, respectively.

678
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
Writing the root-MUSIC polynomial for the forward-backward averaging and using the property of
Q(s)
M , the Unitary root-MUSIC polynomial is obtained
fFB-RMUSIC(z) = aT
1
z

Un,FB U
H
n,FBa

z

= aT
1
z

Q(s)
M

Q(s)
M
H Un,FB U
H
n,FBQ(s)
M

Q(s)
M
H
a

z

= aT
1
z

Q(s)
M Un,Q(s)
M
U
H
n,Q(s)
M

Q(s)
M
H
a

z

= aT
Q(s)
M
1
z

Un,Q(s)
M
U
H
n,Q(s)
M aQ(s)
M

z

≜fQ-RMUSIC(z),
(15.100)
where the transformed array steering vector is deﬁned as
aQ(s)
M (z) ≜

Q(s)
M
H
a(z).
(15.101)
The d roots inside and closest to the unit-circle can be used as the estimate of z1, . . . , zd and subsequently
to obtain the DOAs in the same way explained for the root-MUSIC method.
The Unitary root-MUSIC enjoys from reduced computational complexity compared to the forward-
backward root-MUSIC. In comparison with the root-MUSIC, its unitary version has the advantage of
better asymptotic performance in the case of correlated sources due to the effect of the forward-backward
matrix on the decorrelation of source pairs.
Algorithm 4. Summary of the Unitary root-MUSIC algorithm
1. Compute the eigendecomposition of C and obtain the matrix Un,Q(s)
M .
2. Root the polynomial fQ-RMUSIC(z) = aT
Q(s)
M

1
z

Un,Q(s)
M
U
H
n,Q(s)
M aQ(s)
M (z).
3. Find the DOA estimates using the d largest magnitude roots which lie inside the unit circle.
3.15.4.1.5
Estimation of Signal Parameters via Rotational Invariance Techniques
(ESPRIT)
The ESPRIT technique [39] is a search-free DOA estimation algorithms applicable to arrays composed
of two identical (possibly unknown) subarrays with known intersubarray displacement. Such arrays
satisfy a shift invariance relation as shown in Section 3.15.2.3, Eq. (15.45), which we restate here for
convenience
J1 · A ·  = J2 · A,
(15.102)
where J1, J2 ∈RM(sel)×M are the selection matrices for the ﬁrst and the second subarray and  =
diag

[ejμ1, . . . , ejμd]

contains the unknown parameters μi, i = 1, 2, . . . , d. To eliminate the unknown
array steering matrix we use (15.58) to replace A by the estimated signal subspace Us. The transformed

3.15.4 Subspace-Based Algorithms
679
shift invariance equation then becomes
J1 · Us · 	 ≈J2 · Us,
(15.103)
where 	 = P ·  · P−1, i.e., the eigenvalues of 	 are given by ejμi . The system of equations in
(15.103) is overdetermined since we have M(sel) ·d equations for d2 unknowns. Consequently, we need
an appropriate Least Squares technique to solve it. The simplest choice is given by the method of Least
Squares which selects the matrix 	 that minimizes the Frobenius norm of the difference of the left-hand
side and the right-hand side in (15.103). The resulting closed-form solution is given by
	LS =

J1 · Us
+
· J2 · Us,
(15.104)
where + denotestheMoore-Penrosepseudoinverse.The1-DStandardESPRITalgorithmissummarized
in Algorithm 5.
Algorithm 5 [39]. Summary of 1-D Standard ESPRIT using Least Squares
1. Estimate the signal subspace Us via the truncated SVD of the observation matrix X ∈CM×N.
2. Solve the overdetermined shift invariance equation
J1 · Us · 	 ≈J2 · Us
(15.105)
for the matrix 	 via the method of Least Squares (LS).
3. Compute the eigenvalues ˆλi for i = 1, 2, . . . , d of 	. Recover the frequencies ˆμi via
ˆμi = arg

ˆλi

.
If the array is centro-symmetric, forward-backward averaging can be applied to the data. Since the
resultingdatamatrixisthencentro-Hermitian,itcanbemappedintothereal-valueddomain,asexplained
in Section 3.15.3.3. This allows to save computational complexity because all preceding calculations
can be carried out in the real domain.
Based on this idea, a “unitary” version of ESPRIT has been proposed in [15]. As shown there, a
real-valued version of the invariance Eqs. (15.103) is given by
K1 · Es · ϒ ≈K2 · Es,
(15.106)
where Es ∈RM×d is the estimated real-valued signal subspace (cf. Section 3.15.3.3), the eigenvalues
of ϒ are given by tan (μi/2), and Kn are the transformed selection matrices given by
K1 = 2 · Re

QH
M(sel) · J2 · QM

,
(15.107)
K2 = 2 · Im

QH
M(sel) · J2 · QM

.
(15.108)
Since (15.103) and (15.106) follow the same algebraic form, the LS solution is given by
ϒLS =

K1 · Es
+
· K2 · Es.
(15.109)
The 1-D Unitary ESPRIT algorithm is summarized in Algorithm 6.

680
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
Algorithm 6 [15]. Summary of 1-D Unitary ESPRIT using Least Squares
1. Estimate the real-valued signal subspace Es via the truncated SVD of the transformed real-valued
observation matrix T (X) = QH
M ·

X
MX∗N

· Q2N ∈RM×2N, where Qp is a unitary p × p
left--real matrix (i.e., p · Q∗
p = Qp).
2. Solve the overdetermined shift invariance equations
K1 · Es · ϒ ≈K2 · Es
(15.110)
for the matrix ϒ via the method of Least Squares (LS).
3. Compute the eigenvalues ˆωi for i = 1, 2, . . . , d of ϒ. Recover the frequencies ˆμi via
ˆμi = 2 · arctan ( ˆωi).
While the LS solution is closed-form and simple to implement, it is in general suboptimal. The
reason for this is that an LS solution to an overdetermined set of equations, say, A · x ≈b can always
be interpreted as ﬁnding a projection of the vector b onto the subspace spanned by the columns of A. In
that respect, one inherently assumes that A is perfectly known and the only error lies on the right-hand
side of the equation, i.e., we ﬁnd an error term 	b such that A · x = b + 	b and ∥	b∥2 is minimized.
However, in the case of a shift invariance equation we have J1 Us	 ≈J2 Us, which we solve for 	.
Consequently, the error clearly lies on both sides of the equation as neither “A” (J1 Us) nor “b” (J2 Us)
are perfectly known.
This observation has inspired the use of the TLS procedure [48] for solving the invariance equation.
TLS allows for errors in all variables, hence one error term for J1 Us and another error term for J2 Us is
explicitly computed with the goal to align their subspaces until an exact solution for 	 exists.
The drawback of TLS is that the error terms for J1 Us and J2 Us are found independently of each
other. However, as long as the two subarrays used for ESPRIT overlap, they have common elements.
This is additional information coming from the particular structure of the array which is ignored by
TLS. In order to take this structure into account, SLS was proposed in [50]. In SLS we model an explicit
error term for Us, accounting for the fact that the true source of error in the shift invariance equation
is the subspace estimation error. Since the resulting cost function represents a quadratic Least Squares
problem, an exact closed-form solution does not exist anymore. However, it is shown in [50] that the
cost function can be solved iteratively by local linearization and that one iteration is typically sufﬁcient.
To this end, the SLS cost function for a 1-D shift invariance equation9 J1 · Us · 	 ≈J2 · Us can be
expressed as
	SLS = 	LS + 		SLS,
where
		SLS = arg min
		,	Us
J1 ·

Us + 	Us

·

	LS + 		

−J2 ·

Us + 	Us

2
F + κ2 ∥	Us∥2
F
.
(15.111)
9The same algorithm applies to R-D shift invariance equations (where Jn is replaced by J(r)
n
for n = 1, 2 and
r = 1, 2, . . . , R) and to the transformed real-valued invariance equations (where J(r)
n , Us, and 	(r) are replaced by K(r)
n , Es,
and ϒ(r), respectively).

3.15.4 Subspace-Based Algorithms
681
Here, 	LS refers to the LS solution given by (15.104). Moreover, κ is a regularization constant con-
trolling the inﬂuence of the regularization term that penalizes too large updates in 	Us. It is given by
κ2 = M(sel)
M·α , where α ∈(0, ∞) controls the amount of regularization: large values of α refer to using
less regularization. Since (15.111) is a quadratic Least Squares problem, it is solved iteratively by local
linearization. In the kth iteration, the updates to 	Us and 		 are calculated via [50]
	Us,k+1 = 	Us,k + 		Us,k
and 		k+1 = 		k + 			k,
where
 vec

			k

vec

		Us,k


= −F+ ·

vec

Rk

κ · vec

	Us,k


with
Rk = J1 ·

Us + 	Us,k

·

	LS + 		k

−J2 ·

Us + 	Us,k

and
F =

Id ⊗(J1

Us + 	Us,k

)

	LS + 		k

⊗J1

−

Id ⊗J2

0
κ · IM·d

,
(15.112)
where the initial values are given by 	Us,0 = 0M×d and 		0 = 0d×d. Even though SLS is derived as
an iterative procedure, Haardt [50] argues that only one iteration is required to achieve a considerable
improvement in estimation accuracy and therefore only a single iteration is needed.
It is important to note that TLS and SLS can be used to replace LS for the solution of the shift
invariance equations in all the LS-based ESPRIT algorithms that are shown in this chapter. Since
they all follow the same three steps (signal subspace estimation, solution of the invariance equations,
extraction of the spatial frequencies), we simply exchange the second step, using SLS instead of LS to
solve the invariance equations.
A tensor-based extension of SLS was introduced in [52] under the name Tensor-Structure SLS (TS-
SLS). TS-SLS is based on the underlying idea in SLS to model an explicit perturbation for the signal
subspace. However, the structure of the subspace tensor is exploited explicitly by modeling individual
perturbation terms for the components it is constructed from. This leads to an improved parameter
estimation accuracy. Note that TS-SLS provides a tensor gain even in scenarios where the HOSVD-
based subspace estimate does not provide a tensor gain, i.e., if d ≥max{M1, . . . , MR}.
3.15.4.1.6
Generalized ESPRIT (GESPRIT)
The generalized ESPRIT approach of [93] has been originally formulated for the array model composed
of two M
2 -sensor non-overlapping subarrays with pairwise sensor calibration such that the displacement
vectors ˜ηm =

xm −xm+ M
2 , ym −ym+ M
2
T
for m = 1, . . . , M
2 between the mth sensor in the ﬁrst
subarray and its corresponding sensor, i.e., the

m + M
2

th sensor in the second subarray, is known.
It is shown in [93] that if d ≤
M
2 , then for any M
2 × d full-rank matrix WGESPRIT, the matrix
W H
GESPRIT

Us,2 −p(θ)Us,1

drops rank where Us,1 and Us,2 are the M
2 × d submatrices from Us
such that
Us =
 Us,1
Us,2

(15.113)

682
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
and the M
2 × M
2 diagonal matrix p(θ) contains the displacement-phase information between the sensor
pairs and the M
2 diagonal entries are deﬁned as
[p(θ)](m,m) ≜e
j

xm−xm+ M
2

sin θ+

ym−ym+ M
2

cos θ
(15.114)
for m = 1, . . . , M
2 . It can be noted that the generalized ESPRIT scheme makes also use of rank dropping
criterion which was used for the RARE algorithm in [80]. The difference is that the generalized ESPRIT
is a ESPRIT-like algorithm, whereas the RARE method is a MUSIC-like technique.
In the ﬁnite sample case, we usually replace Us,1 and Us,2 by their estimates given by Us,1 and Us,2,
respectively. This leads to the following generalized ESPRIT spectrum, for WGESPRIT = Us,1 [93]
fGES1(θ) =
1
!!!det
"
U
H
s,1 Us,2 −U
H
s,1(θ)Us,1
#!!!
,
(15.115)
where the signal DOAs are estimated from the d highest peaks of (15.115).
Another meaningful choice of WGESPRIT is WGESPRIT = Us,2 −p(θ)Us,1 [94]. With the latter
choice, the generalized ESPRIT spectral function becomes
fGES2(θ) =
1
|det{(Us,2 −(θ)Us,1)H(Us,2 −(θ)Us,1)}|
.
(15.116)
3.15.4.1.7
Method of direction of arrival estimation (MODE)
The MODE technique is in fact the rooting version of the weighted subspace ﬁtting (WSF) method for
the ULAs. The cost function of the WSF technique which has to be minimized can be shown to be [83]
fMODE(θ) = Tr

P⊥
A(θ) UsWMODE U
H
s

,
(15.117)
where
P⊥
A(θ) = IM −A(θ)(AH(θ)A(θ))−1AH(θ)
(15.118)
indicates the orthogonal projection matrix of the array steering matrix,
WMODE = (s −ˆσ 2Id)
−1
s
(15.119)
is the asymptotic-optimum weight matrix, and
ˆσ 2 =
1
M −d Tr(n)
(15.120)
Algorithm 7 [93]. Summary of the generalized ESPRIT scheme
1. Compute the eigendecomposition of 
x and obtain the matrix Us,1 and Us,2.
2. Depending on your choice of WGESPRIT, ﬁnd the d maxima of fGESPRIT(θ) in (15.115) in (15.116)
by scanning the entire FOV.

3.15.4 Subspace-Based Algorithms
683
denotes the estimated power of the noise. The objective in MODE is to reformulate the function fMODE
in (15.117) so that the mutlidimensional minimization becomes less computationally costly. Let us
deﬁne a polynomial of degree d which has the spatial frequencies z1, . . . , zd as its roots such that
b(z) = b0zd + b1zd−1 + · · · + bd = b0
d
l=1
(z −zl).
(15.121)
Deﬁning the highly-structured matrix B
BH =
⎡
⎢⎣
bd
· · ·
b1
b0
· · ·
0
...
...
...
0
bd
· · ·
b1
b0
⎤
⎥⎦
(15.122)
it can be clearly seen that
BHA(θ) = 0.
(15.123)
Then, fMODE(θ) in (15.117) can be reformulated as
fMODE(b) = Tr

PB UsWMODE U
H
s

,
(15.124)
where
b =

b0
b1
· · ·
bd
T
(15.125)
and
PB = B(BHB)−1BH.
(15.126)
Algorithm 8. Solving the MODE function
1. Obtain the initial estimate ˆb
(0) of b from the quadratic function
f (0)
MODE(b) = Tr

BH UsWMODE U
H
s B

(15.127)
s.t. Re(b0) = 1,
bk = b∗
d−k,
k = 0, 1, . . . , d
and form B from ˆb
(0).
2. Solve the following quadratic function
f (1)
MODE(b) = Tr

(BB)−1BH UsWMODE U
H
s B

s.t. Re(b0) = 1,
bk = b∗
d−k,
k = 0, 1, . . . , d.
(15.128)
to obtain ˆb and root the polynomial with coefﬁcients ˆb to estimate DOAs.
Consequently, the MODE algorithm is performed by computing the coefﬁcient vector b which
minimizes fMODE(b) in (15.124). The DOAs can then be estimated from the roots of the polynomial

684
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
containing b as its coefﬁcients. In order to guarantee that the roots of the MODE polynomial exhibit
the unit norm property the process of minimizing the function fMODE(b), has to take into account
the conjugate-symmetric constraint w.r.t. the polynomial coefﬁcients. Further, a norm constraint on b,
e.g., ∥b∥2 = 1, needs to be taken into account to remove the trivial solution [95,96]. Another possible
normalizationofbisdescribedinAlgorithm8wheretherealpart(ortheimaginarypart)ofb0 isﬁxedto1.
In contrast to other subspace-based methods like MUSIC, MODE achieves statistical efﬁciency for
both uncorrelated and highly correlated sources through a search-free algorithm based on closed-form
quadratic solutions and polynomial rooting.
3.15.4.1.8
Rank-reduction (RARE) DOA estimation method
The RARE technique has been developed in [80,97,98] for the case of sensor arrays consisting of
multiple fully-calibrated subarrays without any calibration information in-between subarrays. Let us
assume that the array composed of K subarrays and the unknown array geometry-dependent parameter
η consists of the displacement vectors between the subarrays. For this class of arrays, the columns of
the array manifold matrix can be described as
a(θl, η) = LR(θl)hR(θl, η),
(15.129)
where the M × K matrix LR(θ) is deﬁned as
LR(θl) ≜
⎡
⎢⎢⎢⎣
a1(θl)
0
· · ·
0
0
a2(θl) · · ·
0
...
...
...
...
0
0
· · · aK (θl)
⎤
⎥⎥⎥⎦
(15.130)
for θl = θ1, . . . , θd, ak(θl) for k = 1, . . . , K is the lth column of the manifold matrix for the kth
subarray such that the ﬁrst sensor of that subarray is considered as the origin (or reference) sensor, c.f.
Figure15.11,andthe K ×1vector h(θl, η)containsthephaseinformationresultingfromtheuncalibrated
or unknown part of the array such as intersubarray displacement vectors ηk = [αk βk]T for k = 2, . . . , K
such that
hR(θl, η) =

1 φ2,l
· · ·
φK,l
T ,
(15.131)
where
φk(θl) ≜e j(2π/λ)(αk sin θl+βk cos θl)
(15.132)
for k = 2, . . . , K and l = 1, . . . , d. Note, that LR(θ) is solely dependent on the DOAs and the known
or calibrated part of the array. The MUSIC criterion in Section 3.15.4.1.1, i.e., the orthogonality of the
eigenvector matrix of the noise subspace and the array manifold matrix (15.87), can then be used
aH(θl, η)UnUH
n a(θl, η) =
hH
R (θl, η)LR(θl)UnUH
n LH
R (θl)hR(θl, η) =
hH
R (θl, η)FRARE(θl)hR(θl, η) = 0,
(15.133)
where
FRARE(θ) ≜LR(θ)UnUH
n LH
R (θ).
(15.134)

3.15.4 Subspace-Based Algorithms
685
x
y
•
•
•
....
subarray 2
subarray 1
subarray K
η1
η2
ηK
FIGURE 15.11
K arbitrary known subarrays with arbitrary unknown displacements.
The idea in the RARE algorithm is based on the observation that if K ≤M −d and taking into the
account that rank{Un} ≥K, then Eq. (15.133) is true only when the K × K matrix FRARE(θl) drops
rank, i.e., when rank{FRARE(θl)} < K. In the ﬁnite sample case, however, the K × K matrix FRARE(θ)
is given by
FRARE(θ) ≜LR(θ)Un U
H
n LH
R (θ).
(15.135)
Then, in order to estimate the DOAs, the d maxima of the following function in the entire FOV must
be found
fRARE(θ) =
1
|det{FRARE(θ)}|
.
(15.136)
It should be remarked that the spectral-RARE function can be expressed in other ways as well which
yields approximately the same DOA estimation performance (see [80]). It should be remarked that
deﬁning the constant diagonal matrix
 = LR(θ)HLR(θ)
(15.137)
and the scalar r = det{} and applying Schur’s complement, the alternative RARE matrix
FRARE(θ) ≜r

Id −UT
s LH
R (θ)−1LR(θ)Us

(15.138)
and for the ﬁnite sample case
FRARE(θ) ≜r

Id −U
T
s LH
R (θ)−1LR(θ)Us

(15.139)
is obtained that exhibits the same rank properties as the RARE matrix in (15.134) in the sense, that
is yields the same determinant function for all values of θ. The same statement also holds true if the
true signal subspace eigenvector matrix Us in (15.138) is replaced by the corresponding ﬁnite sample
estimates Us. The RARE matrix FRARE(θ) in (15.138) is of dimension d × d, whereas the dimension
of FRARE(θ) in (15.134) is of size K × K. Hence, in the case where the number of subarrays K exceeds

686
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
the number of sources d the use of alternative RARE matrix in the evaluation of the determinant is
preferable from a computational point of view.
For some special geometry of the array where the PCA is composed of identically oriented uni-
form subarrays, a search-free RARE algorithm, known as root-RARE, is also developed [80] which is
described in the next subsection.
Algorithm 9. Summary of the RARE technique
1. Compute the eigendecomposition of 
x and obtain the matrix Un if d ≤K, and Us if K ≤d.
2. If d ≤K, then ﬁnd the d maxima of fRARE(θ) in (15.136) by scanning the entire FOV.
3. Else, use the alternative deﬁnition of the RARE function given in (15.138) and ﬁnd the d maxima
of fRARE(θ) by scanning the entire FOV.
3.15.4.1.9
Root-RARE
Let us consider a PCA composed of K identically oriented uniform subarrays, in which, the kth subarray
consists of mk sensors. Without loss of generality, we assume that all theses subarrays are parallel to the
x-axis. Consequently, the cartesian coordinates of the nth sensor belonging to the kth subarray is given
by (αk +κn	x, βk), where (αk, βk) denotes the unknown coordinate of the ﬁrst sensor belonging to the
kth subarray and κn is the integer multiple of the common baseline 	x, which determines the location
of the nth sensor, c.f. Figure 15.12.
Then, the mk × 1 steering vector of the kth subarray is expressed as
ak(θ, ηk) = bk(z)e j 2π
λ (αk sin (θ)+βk cos (θ))
(15.140)
in which ηk = [αk βk]T and
bk(z) =

1 zκ2
· · ·
zκmk T ,
(15.141)
x
y
•
•
•
•
•
•
•
•
•
•
Δx
η1
ηK
η2
subarray 1
subarray 2
subarray K
....
FIGURE 15.12
K arbitrary known uniform and linear subarrays with arbitrary unknown displacements.

3.15.4 Subspace-Based Algorithms
687
where z = e j 2π
λ 	x cos (θ). From (15.140), one can deduce the steering vector expression of the whole
array:
a(θ, η) =

a1(θ)T
· · ·
aK (θ)T T
= LrR(z)hrR(θ, η)
(15.142)
in which η = [ηT
1 · · · ηT
K ]T and
h(θ, η) =

e j 2π
λ (α1 sin (θ)+β1 cos (θ))
· · · e j 2π
λ (αK sin (θ)+βK cos (θ))T
(15.143)
and
LrR(z) =
⎡
⎢⎢⎢⎣
b1(z)
0m1×1
· · · 0m1×1
0m2×1
b2(z)
· · · 0m2×1
...
...
...
0mK ×1
0mK ×1
bK (z)
⎤
⎥⎥⎥⎦.
(15.144)
Since the noise subspace is orthogonal to the steering vectors of the true DOAs, one obtains
hH
rR(θl, η)LH
rR(zl)UnUH
n BrR(zl)hrR(θl, η) = 0 for l = 1, . . . , d.
(15.145)
From (15.145), one can notice that BH
rR(z)UnUnLrR(z) is rank deﬁcient for z = zl (i.e., θ = θl),
l = 1, . . . , d. Consequently, the rooting polynomial of the so-called root-RARE scheme, in the ﬁnite
sample case, is deﬁned as follows:
froot-RARE = det

LH
rR(z)Un U
HLrR(z)

= det

LT
rR(1/z)Un U
HLrR(z)

.
(15.146)
Similar to the root-MUSIC, the roots of froot-RARE form conjugate reciprocal pairs and the DOAs can
be estimated using the largest magnitude roots which are inside the unit circle.
Algorithm 10. Summary of the root-RARE scheme
1. Compute the eigendecomposition of 
x and obtain the matrix Un.
2. Root the polynomial det

LT
rR(1/z)Un U
HLrR(z)

.
3. Find the d DOA estimates using the largest magnitude roots which lie inside the unit circle.
3.15.4.1.10
Interpolated root-MUSIC
Interpolated scheme uses the principal of a virtual array in order to obtain a search-free algorithm based
on polynomial rooting. More precisely, the main idea is to approximate the true non uniform array by
a virtual ULA using an interpolation matrix V. The true steering vector is then given by the following
approximation [82]:
a(θ) ≃VaV(z)
(15.147)

688
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
in which the MV ×1 vector aV(z) denotes the steering vector of the new virtual ULA. The interpolation
matrix V of dimension M × MV is designed to reduce the interpolation error. Plugging (15.147) into
the MUSIC pseudo null-spectrum function, one obtains the polynomial fV(z) of degree 2MV −2:
fN-MUSIC(θ) ≃fV(z) = aT
V
1
z

V H U
H
n UnVaV(z).
(15.148)
Finally, as in the root-MUSIC scheme, the DOAs are found from the largest-magnitude roots of the
polynomial fV(z) that are located inside the unit circle. For more details on the interpolated root-MUSIC
scheme, the reader can refer to the chapter entitled Array Processing in the face of Nonidealities by
Costa et al.
Algorithm 11. Designing the interpolated array: an off line procedure
1. Divide the ﬁeld of view into S regions and deﬁne a set of angles for each sth sector:
 =

θs,begin
θs,begin + 	θ
· · ·
θs,end

,
(15.149)
where the sth sector is delimited by θs,begin and θs,end.
2. Decide where to place the virtual elements of the new interpolated array corresponding to the sth
sector. The steering matrix of the real array and the virtual array associated with the sth section are
given respectively, by As =

a(θs,begin) · · · a(θs,end)

and AV,s =

aV(θs,begin) · · · aV(θs,end)

.
3. Compute the matrix Vs as the Least Square solution of
VsAs = AV,s,
(15.150)
which can be given by
As =

V H
s Vs
−1 V H
s AV,s
(15.151)
thus, one obtains a set of an interpolation matrices. If the Frobenius norm of AV,s −VsAs is not
sufﬁciently small compared to the norm of AV,s, then, come back to the ﬁrst step and reduce the
sth sector’s size.
3.15.4.1.11
Manifold separation
In [85] Doron and Doron proposed the so-called manifold separation scheme which can be considered
as an other root-MUSIC like approach for arbitrary array geometry. The manifold separation technique
approximates the true steering vector by
a(θ) ≃VMSaMS(˘z)
(15.152)
in which ˘z = e jθ and where the MMS × 1 Vandermonde aMS(˘z) depends only on ˘z such that
aMS(˘z) =

˘z0
· · ·
˘z(MMS−1)T
(15.153)

3.15.4 Subspace-Based Algorithms
689
in which the M × MMS matrix VMS, depends only on the array parameters. Consequently, the MUSIC
pseudo null-spectrum can be approximated by
fN-MUSIC(θ) ≃fMS(˘z) = aT
MS
1
˘z

V H
MS Un U
H
n VMSaMS(˘z).
(15.154)
Finally, as in the root-MUSIC scheme, the DOAs are found from the largest-magnitude roots of the
polynomial fMS(˘z) that are located inside the unit circle.
One can ﬁnd a plethora of methods to design VMS based on the Least Square scheme or on the inverse
discrete Fourier transform of a(θ) taken at different angles [84,85]. It can be noted that the parameter
MMS represents the accuracy of the approximation given in (15.152). Increasing MMS will improve the
latter approximation which leads to a more accurate estimate. In [85], it has been suggested that the
minimal value of MMS leading to an acceptable DOA estimation is equal or greater than 8π q
λ where q
is given as the largest distance between the origin of coordinate system and the array sensors. For more
details on the manifold separation scheme, the reader can refer to the chapter entitled Array Processing
in the face of Nonidealities by Costa et al.
3.15.4.1.12
Fourier domain root-MUSIC
Noting that the MUSIC null-spectrum function, fN-MUSIC(θ), is periodic w.r.t. the DOA with the
period 2π, in [86] the authors introduced the so-called Fourier domain root-MUSIC. More precisely,
fN-MUSIC(θ) can be written using the Fourier series expansion
fN-MUSIC(θ) =
+∞

m=−∞
Fme jmθ
(15.155)
in which the Fourier coefﬁcients are given by
Fm = 1
2π
$ π
−π
fN-MUSIC(θ)e−jmθdθ.
(15.156)
Consequently, using only MFD = 2MFD −1 points in (15.155), one obtains ˆfN-MUSIC(θ), the approx-
imation of fN-MUSIC(θ), given by
ˆfN-MUSIC(θ) =
MFD−1

m=−MFD+1
Fm ˘zm
(15.157)
in which ˘z = e jmθ. In practice, the Fourier coefﬁcients Fm are approximated by Fm using the discrete
Fourier transform
Fm =
1
MFD
MFD−1

m′=−MFD+1
fN-MUSIC
2πm′
MFD

e−j2π m′m
MFD .
(15.158)

690
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
Thus, similar to the way of root-MUSIC, the estimated DOAs can be selected from the largest
magnitude roots of
ˆfFD(˘z) =
MFD−1

m=−MFD+1
Fm ˘zm.
(15.159)
One can observe that ˆfFD(˘z) can be negative. Thus, sign changes of ˆfFD(˘z) means that there are
two roots that lie on the unit circle closely to each other. Furthermore, it has been proved in [86] that
the roots of ˆfFD(˘z) satisfy the conjugate reciprocity property, meaning that the corresponding roots for
which ˆfFD(˘z) is negative, do not form a conjugate reciprocal pair. Consequently, one can obtain two
distinct groups. The ﬁrst one contains pairs of roots lying exactly at the unit circle. The second one
contains the roots which form conjugate reciprocal and do not belong to the unit circle. Based on this
discuss, the proposed algorithm of [86] is explained in the algorithm summary box 12.
Algorithm 12 [86]. Fourier domain root-MUSIC
1. Select the closest root from the unit circle.
2. Identify the class group of the computed root by checking whether its conjugate reciprocal value
is another root.
3. Use the latter root to estimate the DOA if it belongs to the second group, then drop both this root
and its conjugate reciprocal pair. Then, go to step 5.
4. Else, estimate the source DOA from the average of this root and its closest neighbor, and drop
both these roots.
5. Repeat steps 1–4 until d DOAs will be estimated.
3.15.4.2 Multi-dimensional algorithms using matrix-based subspace estimates
3.15.4.2.1
R-D Standard ESPRIT
To solve the R-D shift invariance Eq. (15.43) for the matrices (r), we need to eliminate the unknown
array steering matrix A. This is achieved by observing that the column space of A and Us agree and
hence we can write A = Us ·P for a non-singular square matrix P (cf. (15.58)). In practice, we estimate
Us via an SVD of the noisy measurements X. The estimate Us satisﬁes A ≈Us · P. Inserting this
relation into (15.43), we have
J(r)
1
· Us · P · (r) ≈J(r)
2
· Us · P,
J(r)
1
· Us · P · (r) · P−1
%
&'
(
	(r)
≈J(r)
2
· Us,
(15.160)
which is an overdetermined set of equations for 	(r). An unstructured “Least Squares” solution of
(15.160) for 	(r) is obtained by
	
(r)
LS = arg min
	
J(r)
1
· Us · 	 −J(r)
2
· Us

2
F =

J(r)
1
· Us
+
·J(r)
2
· Us.
(15.161)

3.15.4 Subspace-Based Algorithms
691
Since 	(r) = P · (r) · P−1 represents an EVD, we obtain an estimate of (r) via an EVD of 	
(r)
LS. To
ensure the correct pairing across the dimensions, the matrices 
(r) should be estimated via a joint EVD
of 	
(r)
LS (e.g., via [99]). Algorithm 13 summarized the R-D Standard ESPRIT procedure.
Algorithm 13. Summary of R-D Standard ESPRIT using Least Squares
1. Estimate the signal subspace Us via the truncated SVD of the observation matrix X ∈CM×N.
2. Solve the overdetermined shift invariance equations J(r)
1
· Us · 	(r) ≈J(r)
2
· Us for the matrices
	(r) for r = 1, 2, . . . , R via the method of Least Squares (LS).
3. Compute the eigenvalues ˆλ(r)
i
for i = 1, 2, . . . , d of 	
(r) jointly for all r = 1, 2, . . . , R, e.g., via
the joint diagonalization scheme proposed in [99]. Recover the correctly paired frequencies ˆμ(r)
i
via ˆμ(r)
i
= arg

ˆλ(r)
i

.
3.15.4.2.2
R-D Unitary ESPRIT
R-D Unitary ESPRIT can be applied if the array is centro-symmetric, i.e., its structure is invariant under
mirroring around one centroid (cf. Section 3.15.2.3.5). If the array is centro-symmetric we can exploit
the fact that A and M · A∗span the same column space. Therefore, the measurements X ∈CM×N can
be augmented by M · X∗along the columns without changing the column space. This creates another
set of N “virtual snapshots” (cf. Section 3.15.3.3). Moreover, under certain conditions, this step allows to
decorrelate two coherent sources.10 Finally, the redundancies in the resulting augmented measurement
matrix can be used to transform the complex-valued measurement in the real-valued domain and perform
the entire processing using real-valued additions and multiplications only. The details of the derivation
are found in [15,21]. Here we only provide a summary in Algorithm 14.
3.15.4.2.3
R-D RARE
In this section we extend the RARE algorithm of Section 3.15.4.1.9 that has originally be proposed
for 1-D DOA estimation in partly calibrated arrays to DOA estimation in R-D array structures [80].
The basic idea of the multidimensional extension of the RARE algorithm is to estimate the parameters
along the different baselines separately using the 1-D RARE algorithm. Therefore, the R-D array is
considered as subarray system composed of multiple shifted and identically oriented ULAs for which
the RARE algorithm can be applied to estimate the spatial frequencies along a ULA baseline. The
described estimation procedure can then applied to estimate the DOA parameters along all remaining
baselines of the R-D structure. Such a separate estimation procedure is attractive from a computational
viewpoint, as it allows to decompose a R dimensional estimation problem into R one dimensional
rooting problems. However, if the number of sources is large, the overhead required for associating the
various DOA parameter estimates obtained separately along the different baselines of the array to the
10The decorrelation relies on phase offsets between the sources and hence there are pathological cases were it fails, e.g.,
sources arriving in-phase (which means that their complex correlation coefﬁcient is equal to 1 or −1) at an array where the
phase reference is chosen in the center.

692
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
Algorithm 14 [21]. Summary of R-D Unitary ESPRIT using Least Squares
1. Estimate the real-valued signal subspace Es via the truncated SVD of the transformed real-valued
observation matrix T (X) = QH
M ·

X
MX∗N

· Q2N ∈RM×2N, where Qp is a unitary p × p
left--real matrix (i.e., p · Q∗
p = Qp).
2. Solve the overdetermined shift invariance equations
K(r)
1
· Es · ϒ(r) ≈K(r)
2
· Es
(15.162)
for the matrices ϒ(r) for r = 1, 2, . . . , R via the method of Least Squares (LS), where K(r)
1
and
K(r)
2
are the transformed selection matrices given by
K(r)
1
= 2 · Re

QH
M(sel)
r
·M/Mr ·J(r)
2
· QM

,
(15.163)
K(r)
2
= 2 · Im

QH
M(sel)
r
·M/Mr ·J(r)
2 ·QM

.
(15.164)
3. Compute the eigenvalues ˆω(r)
i
for i = 1, 2, . . . , d of ϒ
(r) jointly for all r = 1, 2, . . . , R, e.g., via
the joint diagonalization scheme proposed in [99] or via the Simultaneous Schur Decomposition
proposed in [21]. Recover the correctly paired frequencies ˆμ(r)
i
via ˆμ(r)
i
= 2 · arctan( ˆω(r)
i ).
individual sources can be signiﬁcant. Exploiting the rich nullspace structure of the RARE polynomial
matrices the R-D RARE algorithm has been developed that entirely avoids the computationally complex
combinatorial parameter association procedure and further enhances the resolution performance of the
1-D RARE estimates [24,97].
In order to derive the multidimensional extension of the root-RARE algorithm, consider the R-D
Kronecker steering vector model (15.33), which for k = 1, . . . , R and in accordance to (15.129) can
also be expressed as
a

μ(1)
l
, . . . , μ(R)
l

= a

μ(1)
l

⊗· · · ⊗a

μ(R)
l

= KR,r

μ(r)
l

hR
"
μ(k)
l
#R
k̸=r

,
(15.165)
where a

μ(r)
is the Mr × 1 steering vector along the baseline d,
LR,r

μ(r)
l

≜IM/Mr ⊗a

μ(r)
l

⊗IM/Mr
(15.166)
and
hR
"
μ(k)
l
#R
k̸=r

= a

μ(1)
l

⊗· · · ⊗a

μ(r−1)
l

⊗a

μ(r+1)
l

⊗· · · ⊗a

μ(R)
l

.
(15.167)
Deﬁning z(r) = e jμ(r) and inserting (15.165) in (15.134) we obtain the RARE matrix
F(r)
RARE

z(r)
≜LT
R,r

1/z(r)
UnUH
n LR,r

z(r)
(15.168)

3.15.4 Subspace-Based Algorithms
693
which represents a (M/Mr) × (M/Mr) matrix polynomial of degree 2Mr −1. Alternatively we can
also consider the RARE matrix as deﬁned in (15.138), which yields the matrix polynomial of dimension
d × d as
F(r)
RARE

z(r)
≜M

Id −1/MrUT
s LT
R,r

1/z(r)
LR,r

z(r)
Us

,
(15.169)
where M is deﬁned in (15.34). In the ﬁnite sample case, replacing the true signal and noise eigenvectors
Us and Un by their respective estimates Us and Un in the matrix polynomials in (15.168) and (15.169)
the parameter estimates of μ(r)
1 , . . . , μ(r)
d
along the rth array baseline can then be obtained from the d
largest roots of the matrix polynomials inside the unit circle.
For the alternative matrix polynomial formulation in (15.169) an interesting property can be derived
that interrelates the matrix polynomials composed along different baselines r = 1, . . . , R. In fact
it was shown in [97], that with z(r)
l
= e jμ(r)
l
the matrix polynomials F(r)
RARE(z(r)) in (15.169) eval-
uated at z(r) = z(r)
l
for r = 1, . . . , R yield matrices with intersecting subspaces. Hence a vector
pl = p(1)
l
= · · · = p(R)
l
can be found such that
F(1)
RARE

z(1)
l

p(r)
l
= · · · = F(R)
RARE

z(R)
l

p(r)
l
= 0d×1.
(15.170)
Furthermore, it can be proven that for unique signal roots z(r)
l
the nullspace vector p(r)
l
is equivalent to
the kth column of the mixing matrix in (15.58). The property (15.170) suggests a sophisticated parameter
association procedure described in Algorithm 15.
Algorithm 15. Summary of the R-D RARE technique
1. Compute the d largest roots ˆz(r)
l
inside the unit circle from the RARE matrix polynomials in
(15.169) with Us replaced by Us for r = 1, . . . , R to form the sets Z(r) = {ˆz(r)
l }l=1d.
2. For each root ˆz(r)
l
∈Z(r) obtained in the previous step compute the unit norm nullspace vector
ˆp(r)
l
and form the unsorted set P(r) ≜
"
ˆp(r)
1 , . . . , ˆp(r)
d
#
. Initialize the iteration counter with i = 1.
3. While i ≤d: Select a root ˆz(r′)
s,i and the baseline r′ among the roots in all sets Z(r) that is located
close to the unit-circle and that is well separated from the remaining roots along that baseline.
Remove the root form the set Z(r) and select ˆps,i as the corresponding normalized nullspace
vector.
4. Determine the root ˆz(r)
i
∈Z(r) along all remaining baselines r ̸= r′ as
ˆz(r)
s,i =
max
ˆz(d)
l
∈Z(d)

ˆp(r′)H
s,i
F(d)
RARE

ˆz(d)
l

ˆp(r′)H
s,i
) F(d)
RARE

ˆz(d)
l

2
F
(15.171)
and remove the corresponding roots from the sets Z(r). Set i = i + 1.
5. Obtain the R-D parameter estimates

ˆμ(1)
l
, . . . , ˆμ(R)
l

=

arg
"
ˆz(1)
s,l
#
, . . . , arg
"
ˆz(R)
s,l
#
for
l = 1, . . . , d.

694
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
The intersecting subspace property (15.170) and the estimated mixing matrix Ps ≜[ps,1, . . . ,ps,d]
computed in Algorithm 15 can further be exploited to enhance DOA estimation performance. Making
use of property (15.58) we can obtain a simple estimate of the R-D steering matrix as
A = UsPs
(15.172)
from which reﬁned source root and spatial frequency estimates can be computed in a straightforward
manner.
3.15.4.2.4
R-D MODE
The Multiple Invariance (MI) MODE algorithm proposed in [100] has been originally developed for
DOA estimation in sensor arrays composed of multiple subarrays. In this section we introduce a simple
extension of this algorithm to the case of DOA estimation in uniform R-D array structures. Consider
the general R-D Kronecker steering vector model in (15.33). The steering matrix A partitions as
A ≜

a

μ(1)
1 , . . . , μ(R)
1

, . . . , a

μ(1)
d , . . . , μ(R)
d

=A

μ(1), . . . , μ(R−1)
♦A

μ(R)
, (15.173)
A

μ(1), . . . , μ(R−1)
≜A

μ(1)
♦· · · ♦A

μ(R−1)
.
(15.174)
Thegeneralideaof theR-DMODEalgorithmissimilartothatoftheconventional1-DMODEalgorithm.
Hence, the weighted subspace ﬁtting criteria (15.117) is minimized. Similarly to the 1-D case of Section
3.15.4.1.7 the noise subspace is modeled by a highly-structured sparse matrix G such that
GHA = 0(M−d)×d.
(15.175)
From the Khatri-Rao structure of the steering matrix in (15.173) it can readily be veriﬁed that G can,
e.g., be chosen as
GH ≜
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
BH
MR
0
0
· · ·
0
C1
J1
0
· · ·
0
0
BH
R
0
· · ·
0
C2
0
J1
· · ·
0
0
0
BH
MR
· · ·
0
...
...
CM/MR
0
0
· · ·
J1
0
0
0
· · · BH
MR,
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
(15.176)
C j ≜
⎡
⎢⎣
cd, j
· · ·
c2, j
c1, j
· · ·
0
...
...
...
0
cd, j
· · ·
c2, j
c1, j
⎤
⎥⎦
(15.177)
with
c j ≜[c1, j, c2, j, . . . , cd, j]T ,
(15.178)

3.15.4 Subspace-Based Algorithms
695
J(r)
1
≜

Id, 0d×M/MR

and the MR ×(MR −d) full rank matrix BMR deﬁned in (15.122). We observe,
that with (15.175) and (15.176) also BH
MRA(μR) = 0(MR−d)×d such that (15.121) is satisﬁed. If we
further choose
eT
1 C jA(μR) = 11×d
then
C jA(μR) = −

J1A(μR)

♦

eT
j+1A(μ(1), . . . , μ(R−1))

(15.179)
for j = 1, . . . , *R−1
r=1 Mr, where e j denotes the jth column of the identity matrix of conformable
dimensions and 11×d is the 1 × d vector containing ones in all entries.
Replacing the orthogonal projector P⊥
A = IM×M −A(AHA)−1AH in (15.117) with
PG ≜G(GHG)−1GH
(15.180)
yields
fWSF(b, c1, . . . , cM/MR) = Tr

PG UsWMODE U
H
s

,
(15.181)
where b and WMODE deﬁned in (15.125) and (15.119), respectively. The R-D MODE algorithm can
then be carried out as summarized in Algorithm 16. It should be noted that for simplicity of notation we
considered the special case in which the signal are separated according to that the spatial frequencies
along Rth baseline, which are estimated ﬁrst. However, by exchanging the indices and rearranging the
received data correspondingly it is straightforward to also exchange the order of the parameter estimation
along the various baselines. We remark that due to the sequential estimation procedure the performance
the R-D MODE technique critically depends on the estimation order. The spatial frequencies along
which the sources are well-separated should therefore be estimated ﬁrst.
Algorithm 16. Solving the R-D MODE function
1. Obtain the initial estimate ˆb
(0), ˆc(0)
1 , . . . , ˆc(0)
M/MR of b, c1, . . . , cM/MR, respectively, from the
quadratic function
f (0)
WSF(b, c1, . . . , cM/MR) = Tr(GH UsWMODE U
H
s G)
(15.182)
and form G from ˆb
(0), ˆc(0)
1 , . . . , ˆc(0)
M/MR.
2. Solve the following quadratic function
f (1)
WSF(b, c1, . . . , cM/MR) = Tr

(GG)−1GH UsWMODE U
H
s G

.
(15.183)
to obtain the vectors ˆb
(1), ˆc(1)
1 , . . . , ˆc(1)
M/MR.
3. Root the polynomial with coefﬁcients ˆb
1 to obtain the estimate ˆμR of the spatial frequencies
along the Rth baseline. Form the estimated steering matrix A( ˆμR) and insert it in (15.179) and
(15.179) along with B
(1) and C
(1)
j , j = 1, . . . , M/MR. Compute the spatial frequencies along the
remaining baselines from the solution of the system of equations.

696
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
3.15.4.2.5
R-D NC Standard ESPRIT
R-D NC Standard ESPRIT is applicable if the source signals si[n] for i = 1, 2, . . . , d, n = 1, 2, . . . , N
represent samples from a strict-sense non-circular distribution, as described in Section 3.15.2.4. This
implies that they can be expressed as si(t) = eϕi · s0,i(t), where s0,i(t) ∈R and ϕi does not change
with time (n). For the matrix of amplitudes S ∈Cd×N we can then write S = 	 · S0, where 	 =
diag

[eϕ1, . . . , eϕd]

and S0 ∈Rd×N.
Based on this assumption we can deﬁne an augmented measurement matrix X(nc) as [46,63]11
X(nc) =

X
M · X∗

.
(15.184)
Inserting X = A · S + N and S = 	 · S0, we can rewrite (15.184) into
X(nc) =

A · S
M · A∗· S∗

+

N
M · N∗

=

A
M · A∗· 	∗· 	∗

· S +

N
M · N∗

= A(nc) · S + N(nc),
(15.185)
since S∗= 	∗· S0 and 	∗· S = S0. Equation (15.185) shows that the desired signal component of
the augmented X(nc) can be factorized into an extended array steering matrix A(nc) ∈C2M×d and the
original matrix of amplitudes S ∈Cd×N. A remarkable property of A(nc) is the following: If the array
steering matrix A is shift-invariant, i.e., J1 · A ·  = J2 · A, where J1 and J2 ∈RM(sel)×M are the
selection matrices for the ﬁrst and the second subarray, then A(nc) satisﬁes
J(nc)
1
· A(nc) ·  = J(nc)
2
· A(nc),
where
(15.186)
J(nc)
1
=
 J1
0
0
M(sel) · J2 · M

and J(nc)
2
=
J2
0
0
M(sel) · J1 · M

∈R2M(sel)×2M.
(15.187)
The shift invariance in (15.186) was already used in [45] and by us in [46] for the special case of a
ULA and the special case of a centro-symmetric array, respectively. Equation (15.186) is more general
since it does need further assumptions about the array except for the shift invariance. Note that (15.187)
implies that via the augmentation we have created a virtual array of 2M sensors with two shift invariant
subarrays containing 2M(sel) sensors. Consequently, this step doubles the number of sources that can
be resolved simultaneously as well. Based on the shift invariance equation shown in (15.186) we can
deﬁne an R-D Standard ESPRIT-type algorithm following the same steps as before. The resulting R-D
NC Standard ESPRIT algorithm is summarized in Algorithm 17.
11Charg et al. [63] deﬁnes X(nc) for root-MUSIC without the matrix M. The formulation in (15.184) we use here was ﬁrst
proposed by us in [46] to facilitate the real-valued implementation for Unitary ESPRIT.

3.15.4 Subspace-Based Algorithms
697
Algorithm 17. Summary of R-D NC Standard ESPRIT using Least Squares
1. Estimate the augmented signal subspace U
(nc)
s
∈C2M×d via the truncated SVD of the augmented
observation matrix X(nc) ∈C2M×N.
2. Solve the overdetermined shift invariance equations
J(nc)(r)
1
· U
(nc)
s
· 	(r) ≈J(nc)(r)
2
· U
(nc)
s
(15.188)
for the matrices 	(r) for r = 1, 2, . . . , R via the method of Least Squares (LS), where J(nc)(r)
1
and J(nc)(r)
2
are deﬁned as (cf. (15.187))
J(nc)(r)
n
= IM1·····Mr−1 ⊗J(nc)(r)
n
⊗IMr+1·····MR,
(15.189)
J(nc)(r)
1
= blkdiag
"
J(r)
1 ,  · J(r)
2
· 
#
,
(15.190)
J(nc)(r)
2
= blkdiag
"
J(r)
2 ,  · J(r)
1
· 
#
.
(15.191)
3. Compute the eigenvalues ˆλ(r)
i
for i = 1, 2, . . . , d of 	
(r) jointly for all r = 1, 2, . . . , R, e.g., via
the joint diagonalization scheme proposed in [99]. Recover the correctly paired frequencies ˆμ(r)
i
via ˆμ(r)
i
= arg

ˆλ(r)
i

.
3.15.4.2.6
R-D NC Unitary ESPRIT
The extension of R-D NC Standard ESPRIT to R-D NC Unitary ESPRIT is again quite straightforward.
There are two remarkable things to note here though. Firstly, while R-D Unitary ESPRIT requires the
original array to be centro-symmetric, this is not required for R-D NC Unitary ESPRIT. The reason
is that even if A is not centro-symmetric, the augmented array steering matrix A(nc) is always centro-
symmetric.12
The second surprising result is that forward-backward averaging has no effect on the performance.
That means if we apply FBA to X(nc) the subspace estimate Us remains unaltered since
X(nc)(fba) ·

X(nc)(fba)H
= 2 · X(nc) ·

X(nc)H
,
(15.192)
where X(nc)(fba) =

X(nc) 2M · X(nc)∗· N

. Note that (15.192) has two important consequences.
Firstly, it shows that the performance of R-D NC Standard ESPRIT and R-D NC Unitary ESPRIT is
identical .13 Secondly, it shows that unlike Unitary ESPRIT, NC Unitary ESPRIT cannot handle two
coherent sources: FBA has no decorrelation effect as shown in (15.192) and the row-wise augmentation
applied for NC ESPRIT has no decorrelation effect either (as evident from (15.185)).
12In the special case where the array is centro-symmetric, we have J2 = M(sel) · J1 · M and hence the augmented selection
matrices simplify into J(nc)
n
= I2 ⊗Jn, n = 1, 2.
13Combining the ﬁrst two observations, it becomes clear that there is actually no need for a “Standard” version of R-D NC
Unitary ESPRIT. It is included in this chapter for the sake of completeness only.

698
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
The third surprising result is that applying forward-backward averaging and the real-valued trans-
formation, the resulting transformed measurement matrix takes the following simple form:
T (X(nc)) = 2 ·
Re

X

0M×N
Im

X

0M×N

,
(15.193)
if the sparse left--real matrices Q(s)
p from (15.12) are used for the real-valued transformation. Since
the zero block matrices and the factor 2 in front can be skipped, we conclude that the signal subspace
can be estimated directly from the matrix where the real part of X and the imaginary part of X are
stacked on top of each other. Based on this observation, an R-D NC Unitary ESPRIT algorithm can be
derived, which is summarized in Algorithm 18.
Algorithm 18 [46]. Summary of R-D NC Unitary ESPRIT using Least Squares
1. Estimate the augmented real-valued signal subspace E
(nc)
s
∈R2M×d via the truncated SVD of the
stacked observation [Re

X
T , Im

X
T ]T ∈R2M×N.
2. Solve the overdetermined shift invariance equations
K(nc)(r)
1
· E
(nc)
s
· ϒ(r) ≈K(nc)(r)
2
· E
(nc)
s
(15.194)
for the matrices ϒ(r) for r = 1, 2, . . . , R via the method of Least Squares (LS), where
K(nc)(r)
1
= 2 · Re

QH
M(sel)
r
·M/Mr ·J(nc)(r)
2
· QM

,
(15.195)
K(nc)(r)
2
= 2 · Im

QH
M(sel)
r
·M/Mr ·J(nc)(r)
2
· QM

,
(15.196)
and J(nc)(r)
n
are deﬁned in Algorithm 17.
3. Compute the eigenvalues ˆω(r)
i
for i = 1, 2, . . . , d of ϒ
(r) jointly for all r = 1, 2, . . . , R, e.g., via
the joint diagonalization scheme proposed in [99] or via the Simultaneous Schur Decomposition
proposed in [21]. Recover the correctly paired frequencies ˆμ(r)
i
via ˆμ(r)
i
= 2 · arctan ( ˆω(r)
i ).
3.15.4.3 Algorithms using tensor-based subspace estimates
3.15.4.3.1
R-D Standard Tensor-ESPRIT
As we have demonstrated in Section 3.15.2.3.8, the use of tensor algebra leads to a simpliﬁed and more
natural formulation of the R-D shift invariance equations, since the artiﬁcial stacking operation and its
consequences (such as the introduction of many Kronecker products) are avoided. Based on this idea,
an R-D Standard ESPRIT algorithm can be formulated entirely in terms of tensors [42]. As we show in
the sequel, this enhances the estimation accuracy due to the improved tensor-based subspace estimate
shown in Section 3.15.3.4. Moreover, it enables us to ﬁnd tensor-based solutions to the overdetermined
shift invariance equations [52].

3.15.4 Subspace-Based Algorithms
699
We ﬁrst eliminate the unknown array steering tensor from the shift invariance equations (15.41) by
virtue of the signal subspace tensor (15.82). This step is facilitated by the following relation between
A and U[s]:
A = U[s] ×R+1 T,
(15.197)
where T ∈Cd×d is a non-singular transform matrix. Essentially, (15.197) shows that the row spaces of
the (R +1)-mode unfoldings of A and U[s] agree. At the same time, if we compute any r-mode unfold-
ing of (15.197) it becomes apparent that all the r-spaces of A and U[s] coincide for r = 1, 2, . . . , R. It
allows to eliminate the unknown array steering tensor from the shift invariance equations, replacing it
by the estimated signal subspace tensor U
[s] via A ≈U
[s]×R+1T. We then obtain
U
[s] ×r J(r)
1
×R+1 	(r) ≈U
[s] ×r J(r)
2 ,
(15.198)
where14 	(r) = T−1 ·(r) ·T, r = 1, 2, . . . , R follows by applying identity (15.5) for repeated n-mode
products. Note that due to (15.5), the order of the matrices in the deﬁnition of 	(r) is reversed compared
to the matrix case shown in (15.160).
The next step is the solution of the overdetermined sets of Eqs. (15.198) to yield the estimates 	
(r).
It is easy to show that the Least Squares solution of the tensor-valued shift invariance equation (15.198)
has the following closed-form solution:
	
(r)
LS = arg min
	
U
[s] ×r J(r)
1
×R+1 	 −U
[s] ×r J(r)
2

2
H
(15.199)
⇒	
(r)T
LS
=

J(r)
1
·

U
[s]T
(R+1)
+
·J(r)
2
·

U
[s]T
(R+1) .
(15.200)
Comparing (15.200) with (15.161) we see that the Least Squares solution of the matrix-based shift
invariance equations for R-D Standard ESPRIT and the tensor-based shift invariance equations for R-D
Standard Tensor-ESPRIT differ only in the choice of the subspace. Contemplating that the remaining
steps (joint eigendecomposition of 	
(r)
LS to recover the frequencies μ(r)
i ) are also the same, we can
conclude that R-D Standard Tensor-ESPRIT is algebraically equivalent to R-D Standard ESPRIT if we
replace the SVD-based subspace estimate Us by the HOSVD-based subspace estimate
U
[s]T
(R+1).
3.15.4.3.2
R-D unitary Tensor-ESPRIT
In the previous section we have seen that tensor calculus allows to derive a tensor-valued version of R-D
Standard ESPRIT and that it is algebraically equivalent to matrix-based R-D Standard ESPRIT except
for using the enhanced HOSVD-based subspace estimate.
We can proceed in a similar manner for R-D Unitary Tensor-ESPRIT. If the array is centro-symmetric,
we can apply forward-backward averaging to the measurement tensor X and then transform the resulting
tensor onto the real-valued domain to lower the computational complexity. We can then estimate the
14Note that this is not exactly the same as the 	(r) deﬁned in Section 3.15.4.2.1, since the matrix of eigenvectors is different.
However, since we are only interested in the eigenvalues, this difference is irrelevant, and hence we use the same variable for
brevity.

700
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
signal subspace tensor via a truncated HOSVD of the transformed tensor T (X) ∈RM1×···×MR×2N
shown in (15.85), i.e.,
T (X) ≈S
[s]
T ×1 E
[s]
1 · · · ×R E
[s]
R ×R+1 E
[s]
R+1
⇒E
[s] = S
[s]
T ×1 E
[s]
1 · · · ×R E
[s]
R ×R+1 
[s]−1
R+1,
(15.201)
where E
[s] ∈RM1×···×MR×d. Applying the real-valued transformation in (15.85) to the shift invariance
Eqs. (15.198) yields the following transformed equations
E
[s] ×r K(r)
1
×R+1 ϒ(r) ≈E
[s] ×r K(r)
2 ,
(15.202)
where K(r)
1
= 2·Re

QH
M(sel)
r
· J(r)
2
· QMr

and K(r)
2
= 2·Im

QH
M(sel)
r
· J(r)
2
· QMr

. The real-valued shift
invariance equations in (15.202) have the same algebraic form as the shift invariance equations for R-D
Standard Tensor-ESPRIT shown in (15.198). Consequently, using similar arguments as in (15.200) we
ﬁnd the closed-form Least Squares solution to (15.202) via
ϒ
(r)T
LS
=

K(r)
1
·

E
[s]T
(R+1)
+
· K(r)
2
·

E
[s]T
(R+1) .
(15.203)
Note that as for R-D Standard Tensor-ESPRIT, for R-D Unitary Tensor-ESPRIT we again obtain a
solution which is algebraically equivalent to the matrix-based R-D Unitary ESPRIT algorithm. A slight
difference is that the transformed selection matrices K(r)
1
and K(r)
2
used in (15.203) are given by
K(r)
n
=

IM1 ⊗· · · ⊗IMr−1

⊗K(r)
n ⊗

IMr+1 ⊗· · · ⊗IMR

,
n = 1, 2,
(15.204)
and hence, they coincide with the matrices K(r)
n deﬁned in Algorithm 14 only if we choose the left--real
matrices QM and QM(sel)
r
·M/Mr according to
QM = QM1 ⊗QM2 ⊗· · · ⊗QMr ⊗· · · ⊗QMR,
(15.205)
QM(sel)
r
·M/Mr = QM1 ⊗QM2 ⊗· · · ⊗QM(sel)
r
⊗· · · ⊗QMR,
(15.206)
where the smaller QMr are arbitrary unitary left--real matrices. Moreover, the matrix QM used in the
transformation T

X

from (15.85) should also be chosen as in (15.205). However, since the partic-
ular choice of the left--real matrices is irrelevant for the performance of R-D Unitary ESPRIT we
again conclude that R-D Unitary ESPRIT and R-D Unitary Tensor-ESPRIT are algebraically equivalent
except for the fact that the SVD-based subspace estimate Es is replaced by the HOSVD-based subspace
estimate E
[s].
3.15.4.3.3
R-D NC standard Tensor-ESPRIT
In Section 3.15.4.3.1 we have shown how we can exploit the multidimensional structure of the R-D
harmonic retrieval problem by virtue of tensor algebra, giving rise to the R-D Tensor-ESPRIT-type

3.15.4 Subspace-Based Algorithms
701
A
M
A
M
A
FIGURE 15.13
Virtually doubled 2-D array after matrix-based augmentation of the measurements. The virtually doubled
3 × 3 URA is augmented by a second URA ﬂipped in both dimensions. The resulting array is not a separable
2-D sampling grid.
algorithms. On the other hand, in Section 3.15.4.2 we have shown how strict-sense non-circularity of
the amplitudes (source symbols) can be exploited by virtue of widely linear signal processing, giving
rise to NC-ESPRIT-type algorithms. This sparks the question whether both approaches can be combined
for the case of R-D harmonic retrieval with strict-sense non-circular amplitudes.
However, combining the two approaches is not a trivial task. In fact, the augmentation that was applied
for R-D NC-ESPRIT-type algorithms destroys the R-D separable sampling grid structure required for
R-D Tensor-ESPRIT-type algorithms. This is exempliﬁed in Figure 15.13, where we show the virtual
18-sensor array which results from performing the augmentation for matrix-based NC-ESPRIT-type
algorithms to a 3 × 3 URA. The additional virtual URA is ﬂipped in both dimensions but neither
augmented vertically nor horizontally. Hence, the resulting array is not a separable 2-D sampling grid,
since we cannot express it as the outer product of 1-D sampling grids.
Consequently, in order to exploit both, the R-D structure and the strict-sense non-circularity at the
same time, a tensor-compliant way of exploiting non-circularity is required. As shown in [47], this
is accomplished by performing the augmentation along the individual modes separately (in the 2-D
example along the rows and along the columns) and exploiting all these augmentations jointly.
To this end, let the r-mode augmented measurement tensor be given by
X (nc,r) =

X⊔r X ∗×1 M1 · · · ×R MR

∈CM1×···×Mr−1×2Mr×Mr+1×···×MR×N.
(15.207)
This tensor admits a factorization similar to (15.185), i.e.,
X (nc,r) = A(nc,r) ×R+1 ST + N (nc,r),
(15.208)
where the r-mode augmented array steering tensor A(nc,r) is given by
A(nc,r) =

A ⊔r A∗×1 M1 · · · ×R MR ×R+1

	∗· 	∗
∈CM1×···×Mr−1×2Mr×Mr+1×···×MR×d.
(15.209)
The R-D NC Tensor-ESPRIT-type algorithms are based on the shift invariance of A(nc,r). It can be
shown that the r-mode augmented array steering tensor A(nc,r) deﬁned in (15.209) obeys the following

702
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
shift invariance equation
A(nc,r) ×r J(nc)(r)
1
×R+1 (r) = A(nc,r) ×r J(nc)(r)
2
(15.210)
for r = 1, 2, . . . R, where J(nc)(r)
1
and J(nc)(r)
2
are deﬁned in (15.190) and (15.191), respectively.
In other words, (15.210) shows that the r-mode augmented array steering tensor is shift invariant
with a “doubled” number of elements in the rth mode.15 Therefore, the idea to exploit non-circularity
and the R-D tensor structure jointly is to use all r-mode augmentations jointly, i.e., to extract estimates
for (r) from the X (nc,r) for r = 1, 2, . . . , R.
In order accomplish this goal, the unknown array steering tensors need to be replaced by estimates
of appropriate signal subspace tensors. To this end, let the truncated HOSVD of the noise-free r-mode
augmented measurement tensor X (nc,r)
0
be given by X (nc,r)
0
= S[s](r) ×1 U[s](r)
1
· · · ×R U[s](r)
R
×R+1
U[s](r)
R+1 . Deﬁne the r-mode augmented signal subspace tensor U[s](r) via
U[s](r) = S[s](r) ×1 U[s](r)
1
· · · ×R U[s](r)
R
×R+1 
[s](r)−1
R+1
(15.211)
be the signal subspace tensor originating from the r-mode augmented measurement tensor X (nc,r).
Then, the following set of shift invariance equations is satisﬁed:
U[s](r) ×r J(nc)(r)
1
×R+1 	(r) = U[s](r) ×r J(nc)(r)
2
,
r = 1, 2, . . . , R,
(15.212)
where 	(r) = T · (r) · T−1, i.e., T is not a function of r.
It is important to note that if the array is not centro-symmetric, the n-ranks of A(nc,r) can exceed d,
which must be taken into account when computing the truncated HOSVD for U[s](r). Since they are
equal to 2d in the worst case, it is safe to truncate the HOSVD to 2d in the ﬁrst R modes (of course, we
still truncate to d in mode R + 1).
A very important aspect of (15.212) is that T is not a function of r, i.e., all 	(r) still have a common
set eigenvectors. This is crucial since the automatic pairing in R-D ESPRIT-type algorithms is based on
this fact.
TheR-DNCStandardTensor-ESPRITfollowsnaturallyfrom(15.212).ItissummarizedinAlgorithm 19.
3.15.4.3.4
R-D NC unitary Tensor-ESPRIT
The extension of R-D NC Standard Tensor-ESPRIT to R-D NC Unitary Tensor-ESPRIT is again quite
straightforward. In fact, many of the results from the matrix case (cf. Section 3.15.4.2.6) carry over
to the tensor case. Firstly, the augmented array steering tensor A(nc,r) is centro-symmetric even if the
original array steering tensor A is not centro-symmetric.16 Secondly, forward-backward averaging has
no effect on the augmented tensor X (nc,r), i.e.,

X (nc,r)(fba)T
(R+1) ·

X (nc,r)(fba)T
(R+1)
H
= 2 ·

X (nc,r)T
(R+1)

X (nc,r)T
(R+1)
H
,
(15.214)
15Note that A(nc,r) is shift invariant in the other modes q = 1, 2, . . . , R, q ̸= r only if the array is centro-symmetric in the
qth mode, i.e., Mq · A(q)∗and A(q) span the same column space. However, this additional shift invariance is not needed for
R-D NC Tensor-ESPRIT type algorithms.
16The condition on centro-symmetry M ·A∗= A· for the matrix case is expressed in tensor notation as A∗×1 1 · · ·×R
MR = A ×R+1 , where  is a unitary diagonal matrix.

3.15.4 Subspace-Based Algorithms
703
Algorithm 19. Summary of R-D NC Standard Tensor-ESPRIT using Least Squares
1. Estimate the augmented signal subspace tensors U
[s](r) ∈CM1×···×2Mr×···×MR×d via the trun-
cated HOSVD of the r-mode augmented observation tensors X (nc,r) following (15.211) for
r = 1, 2, . . . , R.
2. Solve the overdetermined shift invariance equations
U
[s](r) ×r J(nc)(r)
1
×R+1 	
(r) ≈U
[s](r) ×r J(nc)(r)
2
.
(15.213)
for the matrices 	
(r) for r = 1, 2, . . . , R via the method of Least Squares (LS).
3. Compute the eigenvalues ˆλ(r)
i
for i = 1, 2, . . . , d of 	
(r) jointly for all r = 1, 2, . . . , R, e.g., via
the joint diagonalization scheme proposed in [99]. Recover the correctly paired frequencies ˆμ(r)
i
via ˆμ(r)
i
= arg

ˆλ(r)
i

.
where X (nc,r)(fba) =

X (nc,r) ⊔R+1 X (nc,r)∗×1 M1 · · · ×R MR ×R+1 N

. As in the matrix case,
this shows that the performance of R-D NC Standard Tensor-ESPRIT is identical to R-D NC Unitary
Tensor-ESPRIT and hence the latter is clearly preferable due to the lower computational complexity.
Thirdly, in the matrix case, we had the result that the transformed real-valued measurement matrix
has a very simple form (cf. (15.193)). Applying the tensor-based forward-backward averaging and the
corresponding real-valued transformation which was introduced in (15.85) to X (nc,r), we arrive at a
simple direct form of the transformed measurement tensor as well. It is given by
T (X (nc,r)) =

X (nc,r) ⊔R+1 (X (nc,r)∗×1 M1 · · · ×R MR ×R+1 N)

×1QH
M1 · · · ×R QH
MR ×R+1 QH
2N =

2 · Re

X
(r)
⊔r 2 · Im

X(r)
× ⊔R+1 [OM1×···×MR×N⊔r OM1×···×MR×N]

,
where X
(r) = X ×1 QH
M1 · · · ×r−1 QH
Mr−1 ×r+1 QH
Mr+1 · · · ×R QH
MR.
Note that the zero entries in T (X (nc,r)) and the factor 2 can be skipped as they have no inﬂuence on
the signal subspace estimate. Therefore, we can replace T (X (nc,r)) by the following simpliﬁed version
T (X (nc,r)) =

Re

X
(r)
⊔r Im

X
(r)
∈RM1×···×Mr−1×2Mr×Mr+1×···×MR×N.
(15.215)
Based on this result, the R-D NC Unitary Tensor-ESPRIT algorithm follows straightforwardly. It is
summarized in Algorithm 20.
3.15.4.4 Simulation results
3.15.4.4.1
1-D algorithms using matrix-based subspace estimates
In the ﬁrst scenario we consider the 1-D algorithms using matrix-based subspace estimates adapted for a
ULA. More precisely, we compare the performance of the following algorithms : root-MUSIC, MODE

704
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
Algorithm 20 [47]. Summary of R-D NC Unitary Tensor-ESPRIT using Least Squares
1. Estimate the real-valued augmented signal subspace tensors E
[s](r) ∈RM1×···×2Mr×···×MR×d via
the truncated HOSVD of the transformed r-mode augmented observation tensors ¯T (X (nc,r)) ∈
RM1×···×Mr−1×2Mr×Mr+1×···×MR×N shown in (15.215) for r = 1, 2, . . . , R.
2. Solve the overdetermined shift invariance equations
E
[s](r) ×r K(nc)(r)
1
×R+1 ϒ
(r) ≈E
[s](r) ×r K(nc)(r)
2
(15.216)
for the matrices ϒ
(r) for r = 1, 2, . . . , R via the method of Least Squares (LS), where
K(nc)(r)
1
= 2 · Re

QH
M(sel)
r
· J(nc)(r)
2
· QMr

,
(15.217)
K(nc)(r)
2
= 2 · Im

QH
M(sel)
r
· J(nc)(r)
2
· QMr

,
(15.218)
and J(nc)(r)
n
are deﬁned in (15.190) and (15.191).
3. Compute the eigenvalues ˆω(r)
i
for i = 1, 2, . . . , d of ϒ
(r) jointly for all r = 1, 2, . . . , R, e.g., via
the joint diagonalization scheme proposed in [99] or via the Simultaneous Schur Decomposition
proposed in [21]. Recover the correctly paired frequencies ˆμ(r)
i
via ˆμ(r)
i
= 2 · arctan ( ˆω(r)
i ).
(as presented in the summary box 8), Standard ESPRIT (S-ESPRIT), and Unitary ESPRIT (U-ESPRIT)
with the stochastic Cramér-Rao lower bound (CRB) [57]. The array is assumed to be uniform and linear
with M = 8 sensors spaced by half wavelength. The two sources, assumed to be far-ﬁeld narrowband
complex circular Gaussian sequences with zero mean and variance equal to one, impinge on the array
from θ1 = 10◦and θ2 = 15◦. Finally, the simulation results are averaged over 1000 simulation runs
and the ESPRIT-based schemes consider a maximum overlap.
From Figure 15.14 one can notice that the threshold of the root-MUSIC algorithm occurs at a higher
SNR than the MODE and ESPRIT-based algorithms. Furthermore, Figure 15.14 suggests that the MODE
and S-ESPRIT algorithms exhibit the same threshold phenomena, whereas the U-ESPRIT shows the
best breakdown point. Finally, all the listed algorithms above are in a good agreement with the stochastic
CRB in the asymptotic region.
In the second scenario we focus on the 1-D search free schemes using matrix-based subspace esti-
mates adapted for a NULA. More precisely, we compare the performance of the following algorithms:
interpolated root-MUSIC, manifold separation, and Fourier domain root-MUSIC. The stochastic CRB
is plotted as benchmark, the spectral MUSIC and the Min-Norm schemes are also added.
The array is assumed to be non-uniform with M = 8 sensors as represented by Figure 15.15. The two
sources, assumed to be far-ﬁeld narrowband complex circular Gaussian sequences with zero mean and
variance equal to one, impinge on the array from θ1 = 10◦and θ2 = 15◦with N = 15 snapshots. The
simulation results are averaged over 1000 simulation runs and the matrices VV and VMS are derived
using the LS in order to obtain an optimum approximation of the array manifold. The interpolated
root-MUSIC scheme is applied to sectors of width 45◦where MV = MMS = MFD = 21.

3.15.4 Subspace-Based Algorithms
705
FIGURE 15.14
1-D algorithms using matrix-based subspace estimates for 2 uncorrelated sources using a ULA with M = 8.
−1
−0.5
0
0.5
1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
x/λ
y/λ
FIGURE 15.15
Non-uniform array geometry used for the second example.

706
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
5
10
15
20
25
30
35
10−2
10−1
100
101
102
SNR (dB)
RMSE (degrees)
 
 
Array interpolation
Manifold Separation
FD root−MUSIC
Spectral MUSIC
Min−Norm
Stochastic CRB
FIGURE 15.16
1-D algorithms using matrix-based subspace estimates for 2 uncorrelated sources using the non-uniform
array represented in Figure 15.15 with M = 8.
Figure15.16showsthattheinterpolatedroot-MUSIC,themanifoldseparationandtheFourierdomain
root-MUSIC schemes exhibit a saturation in their performance in the asymptotic region. Nevertheless,
it is shown that the Fourier domain root-MUSIC algorithm’s saturation happens for a higher SNR than
for the other methods. This saturation can be attenuated by increasing MV, MMS, and MFD for the
interpolated root-MUSIC, the manifold separation and the Fourier domain root-MUSIC algorithms,
respectively, but in return, this increases the computational cost of these search free methods. Finally,
in comparison with the spectral form of the MUSIC and the Min-Norm techniques, it can be noticed
from Figure 15.16 that the manifold separation and the Fourier domain root-MUSIC show a breakdown
point which occurs in a lower SNR.
3.15.4.4.2
R-D algorithms using matrix-based subspace estimates
In order to compare the multidimensional (matrix-based and tensor-based) algorithms we investigate
multidimensional harmonics sampled on separable R-D sampling grids in the sequel. For simplicity
we assume totally uniform sampling, i.e., the sampling grid is chosen uniformly in all R modes. For
R = 2, this assumption coincides with a uniform rectangular array (URA) of M1 × M2 sensors. The
source amplitudes si(t) are modeled as circularly symmetric complex Gaussian distributed random
variables with zero mean, variance one, and a correlation coefﬁcient given by
!!E

si(t) · s j(t)∗!! =
ρ ∈[0, 1] ∀i ̸= j = 1, 2, . . . , d. Moreover, the noise samples are assumed to be mutually uncorrelated
zero mean circularly symmetric complex Gaussian distributed with common variance σ 2
n . The SNR is
deﬁned as SNR = σ −2
n . The estimation accuracy of the algorithms is measured with respect to a root
mean square estimation error (RMSE) deﬁned as
RMSE =
+
,
,
-E
.
1
d
1
R
d

i=1
R

r=1

μ(r)
i
−ˆμ(r)
i
2
/
.
(15.219)

3.15.4 Subspace-Based Algorithms
707
Table 15.3 Abbreviations Used for R-D the Simulation Results
Abbreviation
Meaning
RMSE
Root mean square error
SNR
Signal to noise ratio
SE
R-D Standard ESPRIT
UE
R-D Unitary ESPRIT
STE
R-D Standard Tensor-ESPRIT
UTE
R-D Unitary Tensor-ESPRIT
NC UE
R-D NC Unitary ESPRIT
NC UTE
R-D NC Unitary Tensor-ESPRIT
CRB
Deterministic Cramér-Rao bound
CRBnc
Deterministic Cramér-Rao bound for strict-sense non-circular sources [101]
LS
Least Squares
SLS
Structured Least Squares
TS-SLS
Tensor-Structure Structured Least Squares
TS-RD-SLS
Tensor-Structure R-D Structured Least Squares
We compare the R-D versions of Standard ESPRIT (SE), Unitary ESPRIT (UE), Standard Tensor-
ESPRIT (STE), Unitary Tensor-ESPRIT, MODE, as well as RARE. Note that for R-D MODE and R-D
RARE, forward-backward averaging is used as a preprocessing step. As a reference, we also display
the corresponding deterministic Cramér-Rao bound (CRB). Table 15.3 summarizes the abbreviations
used in the subsequent ﬁgure captions.
Figures 15.17 and 15.18 compare the performance of the 2-D MODE and the 2-D RARE algorithm
with the 2-D ESPRIT-type algorithms SE, STE, UE, and UTE, all based on LS. We consider a 6 × 6
URA, N = 6 snapshots, and d = 2 correlated sources with ρ = 0.9. For Figure 15.17 we set the
true spatial frequencies to μ(1)
1
= 1, μ(1)
2
= 0.2, μ(2)
1
= 0.2, and μ(2)
2
= 1 and vary the SNR. For
Figure 15.18 we ﬁx the SNR to 20 dB and vary the source positions as a function of the spatial
separation 	μ according to μ(1)
1
= μ(2)
1
= 1 and μ(1)
2
= μ(2)
2
= 1 −	μ. We can clearly see that the
tensor-based algorithms STE and UTE outperform the matrix-based algorithms SE and UE as a result
of the enhanced HOSVD-based subspace estimate. For high SNR and a larger spatial separation, 2-D
MODE outperforms UTE. Note that we do not show UTE combined with SLS in Figures 15.17 and
15.18, which performs better than the UTE with LS shown here.
In Figures 15.19 and 15.20 we investigate the performance of SLS and its tensor-based extension
TS-SLS. For the ﬁrst result shown in Figure 15.19 we consider d = 3 highly correlated sources
(ρ = 0.999) captured by a 3 × 3 URA and use N = 10 snapshots. The true spatial frequencies are
μ(1)
1
= 1, μ(2)
1
= −1, μ(1)
2
= 0, μ(2)
2
= 1, μ(1)
3
= −1, μ(2)
3
= 0. Note that since d = M1 = M2,
this is a scenario where the HOSVD-based subspace estimate coincides with the SVD-based subspace
estimate (cf. Section 3.15.3.4). Consequently, the LS-based Tensor-ESPRIT algorithms coincide with
their matrix based counterparts, as evident from the overlapping curves for SE LS and STE LS in
Figure 15.19. Likewise, UE SLS and UTE SLS coincide. However, using the tensor-based extensions of

708
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
0
5
10
15
20
25
30
10
−3
10
−2
10
−1
10
0
SNR [dB]
RMSE [rad]
SE
UE
STE
UTE
RARE
MODE
CRB
FIGURE 15.17
RMSE vs. SNR for a 6 × 6 URA, N = 6 snapshots, two correlated sources (ρ = 0.9) positioned at μ(1)
1
= 1,
μ(1)
2
= 0.2, μ(2)
1
= 0.2, and μ(2)
2
= 1.
10−1
100
10−3
10−2
10−1
100
Separation Δ μ
RMSE [rad]
SE
UE
STE
UTE
RARE
MODE
CRB
FIGURE 15.18
RMSE vs. the spatial separation 	μ for a 6×6 URA, N = 6 snapshots, an SNR of 20 dB and two correlated
sources (ρ = 0.9) positioned at μ(1)
1
= μ(2)
1
= 1 and μ(1)
2
= μ(2)
2
= 1 −	μ.
SLS we can still beneﬁt from the tensor structure in this scenario. UTE TS-SLS and UTE TS-2D-SLS
clearly outperform UTE SLS.
For Figure 15.20 we switch to a 5 × 7 URA and consider a single snapshot (N = 1) only. The d = 2
sources’ spatial frequencies are given by μ(1)
1
= 1, μ(2)
1
= −1, μ(1)
2
= 0, μ(2)
2
= 1. The ﬁgure shows
that SLS outperforms LS, UTE outperforms UE, and TS-SLS outperforms SLS, as expected.

3.15.4 Subspace-Based Algorithms
709
15
20
25
30
35
40
10
−3
10
−2
10
−1
10
0
SNR [dB]
RMSE [rad]
SE LS
STE LS
UE SLS
UTE SLS
UTE TS−SLS
UTE TS−RD−SLS
CRB
FIGURE 15.19
RMSE vs. SNR for d = 3 correlated sources (ρ = 0.999) on a 3 × 3 URA, N = 10, μ(1)
1
= 1, μ(2)
1
= −1,
μ(1)
2
= 0, μ(2)
2
= 1, μ(1)
3
= −1, μ(2)
3
= 0.
0
5
10
15
20
25
30
10−3
10−2
10−1
SNR [dB]
RMSE [rad]
UE LS
UE SLS
UTE LS
UTE SLS
UTE TS−SLS
UTE TS−RD−SLS
CRB
FIGURE 15.20
RMSE vs. SNR for d = 2 sources on a 5 × 7 URA, single snapshot (N = 1), μ(1)
1
= 1, μ(2)
1
= −1, μ(1)
2
= 0,
μ(2)
2
= 1.
TheﬁnalsetofsimulationsdemonstratestheperformanceofESPRIT-typealgorithmsfornon-circular
sources. For simplicity we only consider Unitary ESPRIT-type algorithms and compare UE and NC
UE with their tensor versions UTE and NC UTE. For comparison we also display the deterministic
Cramér-Rao bound for strict-sense non-circular sources (CRBnc) from [101]. The strict-sense non-
circular source amplitudes are generated according to (15.47), generating S0 from a standard normal
distribution with source correlation
!!E

s0,i(t) · s0, j(t)
!! = ρ.

710
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
20
25
30
35
40
45
50
10−3
10−2
10−1
100
101
SNR [dB]
RMSE [rad]
UE
UTE
CRB
NC UE
NC UTE
CRBnc
FIGURE 15.21
RMSE vs. SNR for d = 3 correlated sources (ρ = 0.99) at ﬁxed positions μ(1)
1
= μ(2)
1
= 1, μ(1)
2
= μ(2)
2
=
0.85, μ(1)
3
= μ(2)
3
= 1.15 with phase angles ϕ1 = 0, ϕ2 = π/2, ϕ3 = π/4. A 5 × 7 URA and N = 10
snapshots.
20
25
30
35
40
10−2
10−1
100
SNR [dB]
RMSE [rad]
UE
UTE
CRB
NC UE
NC UTE
CRBnc
FIGURE 15.22
RMSE vs. SNR for a 6 × 6 URA, N = 10 snapshots, d = 4 uncorrelated sources at ﬁxed positions μ(1)
1
=
μ(2)
1
= 1, μ(1)
2
= μ(2)
2
= 0.9, μ(1)
3
= μ(2)
3
= 0.8, μ(1)
4
= μ(2)
4
= 0.7 with phase angles ϕ1 = 0, ϕ2 =
π/6, ϕ3 = π/3, ϕ4 = π/2.
ForthesimulationresultshowninFigure15.21weconsidera5×7URA, N = 10snapshotsandd = 3
correlated sources (ρ = 0.99). The sources’ phase angles are ﬁxed to ϕ1 = 0, ϕ2 = π/2, ϕ3 = π/4 and
the true spatial frequencies are given by μ(1)
1
= μ(2)
1
= 1, μ(1)
2
= μ(2)
2
= 0.85, μ(1)
3
= μ(2)
3
= 1.15. On
the other hand, for Figure 15.22 we use a 6 × 6 URA and d = 4 uncorrelated sources with phase angles

3.15.5 Conclusions
711
given by ϕ1 = 0, ϕ2 = π/6, ϕ3 = π/3, ϕ4 = π/2. Moreover, thetruespatial frequencies inthis scenario
are μ(1)
1
= μ(2)
1
= 1, μ(1)
2
= μ(2)
2
= 0.9, μ(1)
3
= μ(2)
3
= 0.8, μ(1)
4
= μ(2)
4
= 0.7. Both simulation
results show that NC UE outperforms UE (due to exploiting the noncircularity), UTE outperforms UE
(due to exploiting the R-D structure), and NC UTE outperforms both (by combining both beneﬁts).
3.15.5 Conclusions
In this chapter we have presented a detailed overview of subspace methods adapted for uniform arrays,
non-uniform arrays, and other speciﬁc array structures. The popularity of many of these special array
structures is due to the availability of search-free low computational complexity DOA or spatial fre-
quency estimation algorithms particularly to exploit the structure of the array. Different subspace based
algorithms have been compared using numerical simulations.
These subspace-based algorithms can be classiﬁed, with respect to their numerical procedure into
spectral searching techniques and search-free techniques. The spectral searching techniques include
the well known MUSIC, RARE, weighted subspace ﬁtting schemes, and their variants. Whereas, the
search-free techniques can be partitioned into two subclasses:
•
Polynomial-rooting techniques, e.g., root-MUSIC and its variants for the ULA context: in the non-
uniform array context, the main idea is to use the approximation of the true steering vector by a virtual
steering vector (using, e.g., manifold separation or Fourier transform) in order to obtain a search-free
algorithm based on polynomial rooting. In this chapter, we have presented and compared several
polynomial-rooting techniques with application to non-uniform arrays. It has been noticed that the
interpolated root-MUSIC, the manifold separation and the Fourier domain root-MUSIC schemes
exhibit a saturation in their performance in the asymptotic region. This saturation can be attenuated
by increasing the number of the virtual arrays, but in return, this increases the computational cost.
•
The matrix-shifting techniques, e.g., matrix pencil methods, ESPRIT, and its variants: due to its
simplicity and universal applicability ESPRIT has becomes one of the most popular signal subspace
based spatial frequency estimation methods. ESPRIT is premised on array geometries that exhibit
a shift invariance structure that enables the estimation of the source DOA parameters from the
eigenvalues of an estimated matrix. Numerical simulations have shown that the threshold of the
root-MUSIC algorithm occurs at a higher SNR than ESPRIT-based algorithms, in which the Unitary
ESPRIT scheme performs best among all ESPRIT-based schemes.
For the case of multidimensional parameter estimation, we have introduced R-D matrix-based and
tensor-based algorithms. We have demonstrated that multidimensional signals can be represented by
tensors which provide a natural formulation of the R-dimensional signals and their properties (such
as the R-D shift invariances needed for matrix shifting techniques). Based on this representation, an
improved HOSVD-based signal subspace estimate was deﬁned. We have shown that this subspace
estimate performs a more efﬁcient denoising of the data which leads to a tensor gain in terms of
an enhanced estimation accuracy. This subspace estimate can be combined with arbitrary existing
multidimensional subspace-based parameter estimation schemes.
Then we have discussed the tensor-based schemes R-D Standard Tensor-ESPRIT and R-D Unitary
Tensor-ESPRIT. They outperform the matrix based R-D ESPRIT-type algorithms due to the enhanced

712
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
subspace estimate obtained from the HOSVD. We have also shown that strict-sense non-circular sources
can be exploited to virtually double the number of available sensors by an augmentation of the mea-
surement matrix. Based on this idea, the R-D NC Standard ESPRIT and the R-D NC Unitary ESPRIT
algorithm are derived. As a result, the number of resolvable wavefronts is doubled and the achievable
estimation accuracy is improved. Finally, the family of NC Tensor-ESPRIT-type algorithms has been
introduced to combine both beneﬁts, the strict-sense non-circular source symbols and the multidimen-
sional structure of the signals. This is a non-trivial task, since the augmentation of the measurement
matrix performed for R-D NC Unitary ESPRIT destroys the structure needed for the Tensor-ESPRIT-
type algorithms. It has been solved by deﬁning a mode-wise augmentation of the measurement tensor.
The resulting gain from using tensors and using non-circular sources has been demonstrated in numerical
simulations.
Acknowledgment
This work was partially supported by the European Research Council (ERC) Advanced Investigator Grants program
under Grant 227477-ROSE.
References
[1] A.J. van der Veen, E.F. Deprettere, A.L. Swindlehurst, Subspace-based signal analysis using singular value
decomposition, Proc. IEEE 81 (1993) 1277–1308.
[2] F. Li, R.J. Vaccaro, Uniﬁed analysis for DOA estimation algorithms in array signal processing, Signal Process.
25 (1991) 147–169.
[3] R.O. Schmidt, Multiple emitter location and signal parameter estimation, in: Proceeding of the RADC
Spectrum Estimation Workshop, Grifﬁths AFB, NY, 1979, pp. 243–258 (Reprinted in IEEE Trans. Antennas
Propag. 34 (1986) 276–280).
[4] V.F. Pisarenko, The retrieval of harmonics from a covariance function, Geophys. J. Roy. Astron. Soc. 33
(1973) 347–366.
[5] R. Kumaresan, D.W. Tufts, Estimating the parameters of exponentially damped sinusoids and pole-zero
modeling in noise, IEEE Trans. Acoust. Speech Signal Process. ASSP-30 (1982) 833–840.
[6] A.J. Barabell, Improving the resolution performance of eigenstructure-based direction-ﬁnding algorithms,
in: Proceeding of the IEEE International Conference Acoustics, Speech Signal Processing, Boston, MA,
1983, pp. 336–339.
[7] B.D. Rao, K.V.S. Hari, Performance analysis of root-MUSIC, IEEE Trans. Acoust. Speech Signal Process.
37 (1989) 1939–1948.
[8] R. Roy, T. Kailath, ESPRIT–Estimation of signal parameters via rotational invariance techniques, IEEE
Trans. Acoust. Speech Signal Process. ASSP-37 (1989) 984–995.
[9] S.Y.Kung,K.S.Arun,D.V.BhaskarRao,StatespaceandSVDbasedapproximationmethodsfortheharmonic
retrieval problem, J. Opt. Soc. Am. 73 (1983) 1799–1811.
[10] B.D. Rao, K.S. Arun, Model based processing of signals: a state space approach, Proc. IEEE 80 (1992)
283–309.
[11] Y. Hua, Estimating two-dimensional frequencies by matrix enhancement and matrix pencil, IEEE Trans.
Signal Process. 40 (1992) 2267–2280.

References
713
[12] Y. Hua, A pencil-MUSIC algorithm for ﬁnding two-dimensional angles and polarizations using crossed
dipoles, IEEE Trans. Antennas Propag. 41 (1993) 370–376.
[13] Y. Hua, T.K. Sarkar, On SVD for estimating generalized eigenvalues of singular matrix pencil in noise, IEEE
Trans. Signal Process. 39 (1991) 892–900.
[14] A. Eriksson, P. Stoica, Optimally weighted ESPRIT for direction estimation, Signal Process. 38 (1994)
223–229.
[15] M. Haardt, J.A. Nossek, Unitary ESPRIT: how to obtain increased estimation accuracy with a reduced
computational burden, IEEE Trans. Signal Process. 43 (1995) 1232–1242.
[16] L.L. Scharf, Statistical Signal Processing, Addison-Wesley Publishing Comp., Reading, MA, 1991.
[17] M. Haardt, R.S. Thomä, A. Richter, Multidimensional high-resolution parameter estimation with applica-
tions to channel sounding, in: Y. Hua, A. Gershman, Q. Chen (Eds.), High-Resolution and Robust Signal
Processing, Marcel Dekker, New York, NY, 2004, pp. 255–338 (Chapter 5).
[18] X. Liu, N.D. Sidiropoulos, A. Swami, Blind high-resolution localization and tracking of multiple frequency
hopped signals, IEEE Trans. Signal Process. 50 (2002) 889–901.
[19] X. Liu, N.D. Sidiropoulos, T. Jiang, Multidimensional harmonic retrieval with applications in MIMO wireless
channel sounding, in: A. Gershman, N. Sidiropoulos (Eds.), Space-Time Processing for MIMO Communi-
cations, John Wiley & Sons, Ltd., 2005, pp. 41–75 (Chapter 2).
[20] M.D. Zoltowski, M. Haardt, C.P. Mathews, Closed-form 2D angle estimation with rectangular arrays in
element space or beamspace via Unitary ESPRIT, IEEE Trans. Signal Process. 44 (1996) 316–328.
[21] M. Haardt, J.A. Nossek, Simultaneous schur decomposition of several non-symmetric matrices to achieve
automatic pairing in multidimensional harmonic retrieval problems, IEEE Trans. Signal Process. 46 (1998)
161–169.
[22] H.L. Van Trees, Optimum Array Processing: Detection, Estimation, and Modulation Theory, Part IV, Wiley,
New York, 2002.
[23] K.N.Mokios,N.D.Sidiropoulos,M.Pesavento,C.E.MecklenbrSuker,On3-Dharmonicretrievalforwireless
channel sounding, in: Proceeding of the IEEE International Conference Acoustics, Speech Signal Processing
(ICASSP 2004), 2004, pp. 89–92.
[24] M. Pesavento, C.F. Mecklenbräuker, J.F. Böhme, Multidimensional rank reduction estimator for parametric
MIMO channel models, EURASIP J. Appl. Signal Process. (2004) 1354–1363.
[25] T. Jiang, N.D. Sidiropoulos, J.M.F. ten Berge, Almost sure identiﬁability of multidimensional harmonic
retrieval, IEEE Trans. Signal Process. 49 (2002) 1849–1859.
[26] X. Liu, N.D. Sidiropoulos, Almost sure identiﬁability of constant modulus multidimensional harmonic
retrieval, IEEE Trans. Signal Process. 50 (2002) 2366–2368.
[27] P.M. Kroonenberg, J. de Leeuw, Principal component analysis of three-mode data by means of alternating
least squares algorithms, Psychometrika 45 (1980) 69–97.
[28] M. Rajih, Blind identiﬁcation of underdetermined mixtures based on the characteristic function, Ph.D. Thesis,
Université de Nice á Sophia Antipolis, 2006.
[29] N.D. Sidiropoulos, R. Bro, G.B. Giannakis, Parallel factor analysis in sensor array processing, IEEE Trans.
Signal Process. 48 (2000) 2377–2388.
[30] L. deLathauwer, B. deMoor, J. Vanderwalle, A multilinear singular value decomposition, SIAM J. Matrix
Anal. Appl. (2000) 21.
[31] L. deLathauwer, B. deMoor, J. Vanderwalle, On the best rank-1 and rank-(r1,r2, . . . ,rn) approximation of
higher-order tensors, SIAM J. Matrix Anal. Appl. (2000) 21.
[32] L.R. Tucker, Some mathematical notes on three-mode factor analysis, Psychometrika 31 (1966) 279–311.
[33] H.A.L. Kiers, P.M. Kroonenberg, J.M.F. ten Berge, An efﬁcient algorithm for TUCKALS3 on data with large
numbers of observation units, Psychometrika 57 (1992) 415–422.

714
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
[34] P.M. Kroonenberg, Three-Mode Principle Component Analysis: Theory and Applications, DSWO Press,
Leiden, 1983.
[35] R. Bro, N. Sidiropoulos, G.B. Giannakis, A fast least squares algorithm for separating trilinear mixtures, in:
Proceedings of the International Workshop on Independent Component Analysis for Blind Signal Separation
(ICA 99), 1999, pp. 289–294.
[36] N.D. Sidiropoulos, G.B. Giannakis, R. Bro, Blind PARAFAC receivers for DS-CDMA systems, IEEE Trans.
Signal Process. 48 (2000) 810–823.
[37] D.A. Linebarger, R.D. DeGroat, E.M. Dowling, Efﬁcient direction ﬁnding methods employing forward/
backward averaging, IEEE Trans. Signal Process. 42 (1994) 2136–2145.
[38] A. Lee, Centrohermitian and skew-centrohermitian matrices, Linear Algebra Appl. 29 (1980) 205–210.
[39] R. Roy, A. Paulraj, T. Kailath, ESPRIT - a subspace rotation approach to estimation of parameters of cisoids
in noise, IEEE Trans. Acoust. Speech Signal Process. AASP-34 (1986) 1340–1342.
[40] F. Li, H. Liu, R.J. Vaccaro, Performance analysis for DOA estimation algorithms: uniﬁcation, simpliﬁcations,
and observations, IEEE Trans. Aerosp. Electron. Syst. 29 (1993) 1170–1184.
[41] C.P. Mathews, M. Haardt, M.D. Zoltowski, Performance analysis of closed-form, ESPRIT based 2-D angle
estimator for rectangular arrays, IEEE Signal Process. Lett. 3 (1996) 124–126.
[42] M. Haardt, F. Roemer, G. Del Galdo, Higher-order SVD based subspace estimation to improve the parameter
estimationaccuracyinmulti-dimensionalharmonicretrievalproblems,IEEETrans.SignalProcess.56(2008)
3198–3213.
[43] F. Roemer, H. Becker, M. Haardt, Analytical performance analysis for multi-dimensional Tensor-ESPRIT-
typeparameterestimationalgorithms,in:ProceedingoftheIEEEInternationalConferenceAcoustics,Speech
Signal Processing (ICASSP 2010), Dallas, TX, 2010.
[44] F. Roemer, H. Becker, M. Haardt, M. Weis, Analytical performance evaluation for HOSVD-based parameter
estimation schemes, in: Proceeding of the IEEE International Workshop on Computational Advances in
Multi-Sensor Adaptive Processing (CAMSAP 2009), Aruba, Dutch Antilles, 2009.
[45] A. Zoubir, P. Chargé, Y. Wang, Non circular sources localization with ESPRIT, in: Proceeding of the European
Conference on Wireless Technology (ECWT 2003), Munich, Germany, 2003.
[46] M. Haardt, F. Roemer, Enhancements of Unitary ESPRIT for non-circular sources, in: Proceeding of the IEEE
International Conference Acoustics, Speech Signal Processing (ICASSP 2004), Montreal, Canada, 2004,
pp. 101–104.
[47] F. Roemer, M. Haardt, Multidimensional unitary Tensor-ESPRIT for non-circular sources, in: Proceeding
of the IEEE International Conference Acoustics, Speech Signal Processing (ICASSP 2009), Taipei, Taiwan,
2009.
[48] R. Roy, T. Kailath, Total least-squares ESPRIT, in: Proceedings of the 21st Asilomar Conference Circuits
System Computer, Paciﬁc Grove, CA, 1987.
[49] B. Ottersten, M. Viberg, T. Kailath, Performance analysis of the total least squares ESPRIT algorithm, IEEE
Trans. Signal Process. 39 (1991) 1122–1135.
[50] M. Haardt, Structured least squares to improve the performance of ESPRIT-type algorithms, IEEE Trans.
Signal Process. 45 (1997) 792–799.
[51] F. Roemer, M. Haardt, Analytical performance assessment of 1-D structured least squares, in: Proceeding
of the IEEE International Conference Acoustics, Speech Signal Processing (ICASSP 2011), Prague, Czech
Republic, 2011.
[52] F. Roemer, M. Haardt, Tensor-structure structured least squares (TS-SLS) to improve the performance of
multi-dimensional ESPRIT-type algorithms, in: Proceeding of the IEEE International Conference Acoustics,
Speech Signal Processing (ICASSP 2007), Honolulu, HI, 2007, pp. 893–896.
[53] L. De Lathauwer, B. De Moor, J. Vandewalle, A multilinear singular value decomposition, SIAM J. Matrix
Anal. Appl. 21 (2000) 1253–1278.

References
715
[54] L. Huang, T. Long, S. Wu, Source enumeration for high-resolution array processing using improved
Gerschgorin radii without eigendecomposition, IEEE Trans. Signal Process. 56 (2008) 5916–5925.
[55] M. Wax, T. Kailath, Detection of signals by information theoretic criteria, in: Proceeding of the IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP 1985), Florida, USA, 1985.
[56] M. Wax, I. Ziskind, Detection of the number of coherent signals by the MDL principle, IEEE Trans. Acoust.
Speech Signal Process. 37 (1989) 1190–1196.
[57] P. Stoica, R. Moses, Spectral Analysis of Signals, Prentice Hall, NJ, 2005.
[58] A.T. Moffet, Minimum redundancy linear arrays, IEEE Trans. Antennas Propag. 16 (1968) 172–175.
[59] C.P. Mathews, M.D. Zoltowski, Performance analysis of the UCA-ESPRIT algorithm for circular ring arrays,
IEEE Trans. Signal Process. 42 (1994) 2535–2539.
[60] F. Roemer, M. Haardt, Using 3-D Unitary ESPRIT on a hexagonal shaped ESPAR antenna for 1-D and 2-D
direction of arrival estimation, in: Proceeding of the ITG/IEEE Workshop on Smart Antennas (WSA’05),
Duisburg, Germany, 2005.
[61] F. Roemer, M. Haardt, Efﬁcient 1-D and 2-D DOA estimation for non-circular sources with hexagonal shaped
ESPAR arrays, in: Proceeding of the IEEE International Conference Acoustics, Speech Signal Processing
(ICASSP 2006), Toulouse, France, 2006, pp. 881–884.
[62] H. Abeida, J.-P. Delmas, MUSIC-like estimation of direction of arrival for noncircular sources, IEEE Trans.
Signal Process. 54 (2006) 2678–2690.
[63] P. Charg, Y. Wang, J. Saillard, A non circular sources direction ﬁnding method using polynomial rooting,
Signal Process. (2001) 1765–1770.
[64] A. Liu, G. Liao, Q. Xu, C. Zeng, A circularity-based DOA estimation method under coexistence of noncir-
cular and circular signals, in: Proceeding of the IEEE International Conference Acoustics, Speech Signal
Processing, Kyoto, Japan, 2012.
[65] J.P. Delmas, H. Abeida, Stochastic cramer-rao bound for noncircular signals with application to DOA esti-
mation, IEEE Trans. Signal Process. 52 (2004) 3192–3199.
[66] J. Eriksson, V. Koivunen, Complex random vectors and ICA models: identiﬁability, uniqueness, and separa-
bility, IEEE Trans. Inform. Theory 52 (2006) 1017–1029.
[67] E. Ollila, On the circularity of a complex random variable, IEEE Signal Process. Lett. 15 (2008)
841–844.
[68] P. Chevalier, F. Pipon, New insights into optimal widely linear array receivers for the demodulation of BPSK,
MSK and GMSK signals corrupted by non circular interferences—application to SAIC, IEEE Trans. Signal
Process. 54 (2006) 870–883.
[69] T.-J. Shan, M. Wax, T. Kailath, On spatial smoothing for direction-of-arrival estimation of coherent signals,
IEEE Trans. Acoust. Speech Signal Process. 33 (1985) 806–811.
[70] A. Thakre, M. Haardt, K. Giridhar, Single snapshot spatial smoothing with improved effective array aperture,
IEEE Signal Process. Lett. 16 (2009) 505–509.
[71] J.P.C.L. Da Costa, F. Roemer, M. Haardt, R.T. de Sousa Jr., Multi-dimensional model order selection,
EURASIP J. Adv. Signal Process. 26 (2011) (review article).
[72] A. Thakre, M. Haardt, F. Roemer, K. Giridhar, Tensor-Based spatial smoothing (TB-SS) using multiple
snapshots, IEEE Trans. Signal Process. (2010).
[73] A. Thakre, M. Haardt, K. Giridhar, Single snapshot r-d Unitary ESPRIT using an augmentation of the tensor
order, in: Proceedings of the IEEE International Workshop on Computational Advances in Multi-Sensor
Adaptive Processing (CAMSAP 2009), 2009.
[74] R.O. Schmidt, Multiple emitter location and signal parameter estimation, IEEE Trans. Antennas Propag.
AP-34 (1986) 243–258.
[75] S.S. Reddi, Multiple source location—a digital approach, IEEE Trans. Aerosp. Electron. Syst. 15 (1979)
95–105.

716
CHAPTER 15 Subspace Methods and Exploitation of Special Array Structures
[76] M. Kaveh, A.J. Barabell, The statistical performance of the MUSIC and minimum-norm algorithms in
resolving plane waves in noise, IEEE Trans. Acoust. Speech Signal Process. 34 (1986) 331–341.
[77] H. Krim, P. Forster, J.G. Proakis, Operator approach to performance analysis of root-MUSIC and root Min-
Norm, IEEE Trans. Acoust. Speech Signal Process. 40 (1992) 1687–1688.
[78] P. Stoica, P. Handel, A. Nehoral, Improved sequential MUSIC, IEEE Trans. Aerosp. Electron. Syst. 31 (1995)
1230–1239.
[79] J.C. Mosher, R.M. Leahy, Source localization using recursively applied and projected (RAP) music, IEEE
Trans. Signal Process. 39 (1999) 332–340.
[80] M. Pesavento, A.B. Gershman, K.M. Wong, Direction ﬁnding in partly calibrated sensor arrays composed
of multiple subarrays, IEEE Trans. Signal Process. 50 (2002) 2103–2115.
[81] M. Viberg, B. Ottersten, T. Kailath, Detection and estimation in sensor arrays using weighted subspace
ﬁtting, IEEE Trans. Signal Process. 39 (1991) 2436–2449.
[82] B. Friedlander, A.J. Weiss, Direction ﬁnding using spatial smoothing with interpolated arrays, IEEE Trans.
Aerosp. Electron. Syst. 28 (1992a) 574–587.
[83] H.L. VanTrees, Detection, Estimation and Modulation Theory: Optimum Array Processing, vol. 4, Wiley,
New York, 2002.
[84] F. Belloni, A. Richter, V. Koivunen, DOA estimation via manifold separation for arbitrary array structures,
IEEE Trans. Signal Process. 55 (2007) 4800–4810.
[85] M. Doron, E. Doron, Waveﬁeld modeling and array processing, Part II. Algorithm, IEEE Trans. Signal
Process. 42 (1994) 2571–2580.
[86] M. Rubsamen, A. Gershman, Direction-of-arrival estimation for non-uniform sensor arrays: from manifold
separation to Fourier domain MUSIC methods, IEEE Trans. Signal Process. 57 (2007) 588–599.
[87] H. Krim, M. Viberg, Two decades of array signal processing research: the parametric approach, IEEE Signal
Process. Mag. 13 (1996) 67–94.
[88] P. Stoica, A. Nehorai, MUSIC, maximum likelihood, and Cramer-Rao bound, IEEE Trans. Acoust. Speech
Signal Process. 37 (1989) 720–741.
[89] P. Stoica, A. Nehorai, MUSIC, maximum likelihood and Cramer-Rao bound: further results and comparisons,
IEEE Trans. Acoust. Speech Signal Process. 38 (1990) 2140–2150.
[90] B.D. Rao, K.V.S. Hari, Performance analysis of ESPRIT and TAM in determining the direction of arrival of
plane waves in noise, IEEE Trans. Acoust. Speech Signal Process. AASP-37 (1989) 1990–1995.
[91] B. Friedlander, A.J. Weiss, Direction ﬁnding using spatial smoothing with interpolated arrays, IEEE Trans.
Aerosp. Electron. Syst. 28 (1992b) 574–587.
[92] M.D. Zoltowski, J.M. Kautz, S.D. Silverstein, Beamspace root-music, IEEE Trans. Signal Process. 41 (1996)
344–364.
[93] F. Gao, A.B. Gershman, A generalized ESPRIT approach to direction-of-arrival estimation, IEEE Signal
Process. Lett. 10 (2005) 254–257.
[94] E. Tuncer, B. Friedlander, Classical and Modern Direction-of-Arrival Estimation, Academic Press, Elsevier
Inc., USA, 2009.
[95] J. Li, P. Stoica, Z.-S. Liu, Comparative study of IQML and MODE direction-of-arrival estimators, IEEE
Trans. Signal Process. 46 (1998) 149–160.
[96] P. Stoica, K. Sharman, Maximum likelihood methods for direction of arrival estimation, IEEE Trans. Acoust.
Speech Signal Process. 38 (1990) 1132–1143.
[97] M. Pesavento, Fast algorithms for multidimensional harmonic retrieval, Ph.D. Thesis, Ruhr-University
Bochum, 2005.
[98] C.M.S.See,A.B.Gershman,Direction-of-arrivalestimationinpartlycalibratedsubarray-basedsensorarrays,
IEEE Trans. Signal Process. 52 (2004) 329–338.

References
717
[99] T. Fu, X. Gao, Simultaneous diagonalization with similarity transformation for non-defective matrices, in:
Proceeding of the IEEE International Conference Acoustics, Speech Signal Processing (ICASSP 2006),
Toulouse, France, 2006.
[100] A. Swindlehurst, P. Stoica, M. Jansson, Exploiting arrays with multiple invariances using music and mode,
IEEE Trans. Signal Process. 49 (2001) 2511–2521.
[101] F. Roemer, M. Haardt, Deterministic Cramér-Rao bounds for strict sense non-circular sources, in: Proceeding
of the ITG/IEEE Workshop on Smart Antennas (WSA’07), Vienna, Austria, 2007.

16
CHAPTER
Performance Bounds and
Statistical Analysis of DOA
Estimation
Jean Pierre Delmas
TELECOM SudParis, Département CITI, CNRS UMR 5157, Evry Cedex, France
3.16.1 Introduction
Over the last three decades, many direction of arrival (DOA) estimation and source number detection
methods have been proposed in the literature. Early studies on statistical performance were only based
on extensive Monte Carlo experiments. Analytical performance evaluations, that allow one to evaluate
the expected performance, as pioneering by Kaveh and Barabell [1], have since attracted much excellent
research.
The earlier works were devoted to the statistical performance analysis of subspace-based algorithms.
In particular the celebrated MUSIC algorithm has been extensively investigated (see, e.g., [2–5] among
many others). But curiously, these works were based on ﬁrst-order perturbations of the eigenvectors
and eigenvalues of the sample covariance matrix, and thus involved very complicated derivations.
Subsequently, Krim et al. [6] carried out a performance analysis of two eigenstructure-based DOA
estimation algorithms, using a series expansion of the orthogonal projectors on the signal and noise
subspaces, allowing considerable simpliﬁcation of the previous approaches. Motivated by this point of
view, several uniﬁed analyses of subspace-based algorithms have been presented (see, e.g., [7–9]). In
parallel to these works, a particular attention has been paid to the statistical performance of the exact and
approximative maximum likelihood algorithms (ML), in relation to the celebrated Cramer-Rao bound
(see, e.g., [10,11], and the tutorial [12] with the references therein).
The statistical performance analysis of the difﬁcult and critical problem of the detection of the
number of sources impinging on an array, has been based on principally standard techniques of the
statistical detection literature. In particular, the information theoretical criteria and especially the min-
imum description length (MDL), as popularized in the signal processing literature by [13], have been
analyzed (see, e.g., [14–16]). Related to the DOA estimation accuracy and to the detection of the number
of sources, the resolvability of closely spaced signals in terms of their parameters of interest have been
also extensively studied (see, e.g., [17,18]).
The aim of this chapter is not to give a survey of all performance analysis of DOA estimation
and source detection methods that have appeared in the literature, but rather, to provide a uniﬁed
methodology introduced in [19] and then specialized to second-order in [20] to study the theoretical
statistical performance of arbitrary DOA estimation and source number detection methods and to tackle
the resolvability of closely space sources. To illustrate this framework, several examples are detailed
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00016-3
© 2014 Elsevier Ltd. All rights reserved.
719

720
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
such as the conventional MUSIC algorithm, the MDL criterion and the angular resolution limit based
on the detection theory.
This chapter is organized as follows. Section 3.16.2 presents the mathematical model of the array out-
put and introduce the basic assumptions. General statistical tools for performance bounds and statistical
analysis of DOA estimation algorithms are given in Section 3.16.3 based on a functional approach pro-
viding a common unifying framework. Then, Section 3.16.4 embarks on statistical performance analysis
of beamforming-based, maximum likelihood and second-order algorithms with a particular attention
paid to the subspace-based algorithms. In particular the robustness w.r.t. the Gaussian distribution, the
independence and narrowband assumptions, and array modeling errors are considered. Finally some
elements of statistical performance analysis of high-order algorithms complete this section. A glimpse
into the detection of the number of sources is given in Section 3.16.5 where a performance analysis of
the minimum description length (MDL) criterion is derived. Finally, Section 3.16.6 is devoted to criteria
for resolving two closely spaced sources.
The following notations are used throughout this chapter: o(ϵ) and O(ϵ) denote quantities such that
limϵ→0 o(ϵ)/ϵ = 0 and |O(ϵ)/ϵ| is bounded in the neighborhood of ϵ = 0, respectively.
3.16.2 Models and basic assumption
3.16.2.1 Parametric array model
Consider an array of M sensors arranged in an arbitrary geometry that receives the waveforms generated
by P point sources (electromagnetic or acoustic). The output of each sensor is modeled as the response
of a linear time-invariant bandpass system of bandwidth B. The impulse response of each sensor to a
signal impinging on the array depends on the physical antenna structure, the receiver electronics and
other antennas in the array through mutual coupling. The complex amplitudes sp(t) of these sources
w.r.t. a carrier frequency f0 are assumed to vary very slowly relative to the propagation time across the
array (more precisely, the array aperture measured in wavelength, is much less than the inverse relative
bandwidth f0/B). This so-called narrowband assumption allows the time delays τm,p of the pth source at
the mth sensor, relative to some ﬁxed reference point, to be modeled as a simple phase-shift of the carrier
frequency. If n(t) is the complex envelope of the additive noise, the complex envelope of the signals col-
lected at the output of the sensors is given by applying the superposition principle for linear sensors by:
x(t) =
P

p=1
a(θ p)sp(t) + n(t) = A(θ)s(t) + n(t),
(16.1)
where s(t) def
= [s1(t), . . . , sP(t)]T and θ p may include generally azimuth, elevation, range and polar-
ization of the pth source. However, we will here assume that there is only one parameter per source,
referred as the direction of arrival (DOA) θ. a(θp) is the steering vector associated with the pth source.
The array manifold, deﬁned as the set {a(θ), θ ∈} for some region  in DOA space, is perfectly
known, either analytically or by measuring it in the ﬁeld. It is further required for performance analysis
that a(θ) be continuously twice differentiable w.r.t. θ. A(θ) = [a(θ1), . . . , a(θP)] is the M × P steering
matrix with θ = [θ1, . . . , θP]T .

3.16.2 Models and Basic Assumption
721
To illustrate the parameterization of the steering vector a(θ), assume that the sources are in the far
ﬁeld of the array, and that the medium is non-dispersive, so that the waveforms can be approximated as
planar. In this case, the mth component of a(θ) is simply gm(θ)e−ikT rm where gm(θ) is the directivity
gain of the mth sensor, k def
= 2π f0
c u, c represents the speed of propagation, u is a unit vector pointing in the
direction of propagation and rm is the position of the mth sensor relative the origin of the different delays.
The by far most studied sensor geometry is that of uniform linear array (ULA), where the M sensors
are assumed to be identical and omnidirectional over the DOA range of interest. Referenced w.r.t. the ﬁrst
sensor that is used as the origin, gm(θ) = 1 and kT rm = (m −1) 2π f0
c
d sin (θ) = (m −1) 2πd
λ0 sin (θ),
where λ0 is the wavelength. To avoid any ambiguity, d must be less than or equal to λ0
2 . The standard
ULA has d = λ0
2 that ensures a maximum accuracy on the estimation of θ. In this case
a(θ) = [1, eiπ sin (θ), . . . , ei(M−1)π sin (θ)]T .
(16.2)
3.16.2.2 Signal assumptions and problem formulation
Each vector observation x(t) is called a snapshot of the array output. Let the process x(t) be observed
at N time instants {t1, . . . , tN}. x(t) is often sampled at a slow sampling frequency 1/Ts compared to
the bandwidth of x(t) for which {x(t)}t1,...,tN are independent. Temporal correlation between successive
snapshots is generally not a problem, but implies that a larger number N of snapshots is needed for
the same performance. We will prove in Section 3.16.4.3 that the parameter that ﬁxes the performance
is not N, but the observation interval T = NTs. The signals {sp(t)}p=1,..,P and n(t) are assumed
independent.1 For well calibrated arrays, n(t) is often assumed to be dominated by thermal noise in the
receivers, which can be well modeled as zero-mean temporally and spatially white circular Gaussian
random process. In this case, E[n(ti)nH(t j)] = σ 2
n δi, jI and E[n(ti)nT (t j)] = 0, for which the spatial
covariance and spatial complementary covariance matrices are given by Rn
def
= E[n(t)nH(t)] = σ 2
n I
and Cn
def
= E[n(t)nT (t)] = 0, respectively. A common, alternative model assumes that n(t) is spatially
correlated where Rn is known up to a scalar multiplicative term σ 2
n , i.e., Rn = σ 2
n n where n is a
known deﬁnite positive matrix. In this case, x(t) can be pre-multiplied by an inverse square-root factor
−1/2
n
of n, which renders the resulting noise spatially white and preserves model (16.1) by replacing
the steering vectors a(θ) by −1/2
n
a(θ).
Two kind of assumptions are used for {sp(t)}p=1,..,P. In the ﬁrst one, called stochastic or uncon-
ditional model (see, e.g., [10,11]), {sp(t)}p=1,..,P are assumed to be zero-mean random variables
for which the most commonly used distribution is the circular Gaussian one with spatial covariance
Rs
def
= E[s(t)sH(t)] and spatial complementary covariance Cs
def
= E[s(t)sT (t)] = 0. Rs is nonsingular
for not fully correlated sources (called also noncoherent) or near-singular for highly correlated sources.
In the case of coherent sources (specular multipath or smart jamming, where some signals impinging
on the array of sensors can be sums of scaled and delayed versions of the others), Rs is singular. In this
chapter Rs is usually assumed nonsingular. For these assumptions, the snapshots x(t) are zero-mean
complex circular Gaussian distributed with covariance matrix
1Note that only the uncorrelation assumption is required for second-order based algorithms, in contrast to fourth-order based
algorithms, that require the independent assumption. However, this latter one simpliﬁes the statistical performance analysis.

722
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
Rx = A(θ)RsAH(θ) + σ 2
n I.
(16.3)
ThiscircularGaussianassumptionliesnotonlyinthefactthatcircularGaussiandataareratherfrequently
encountered in applications, but also because optimal detection and estimation algorithms are much
easier to deduce under this assumption. Furthermore, as will be discussed in Section 3.16.4, under
rather general conditions and in large samples [21], the Gaussian CRB is the largest of all CRB matrices
corresponding to different distributions of the sources of identical covariance matrix Rs. This stochastic
model can be extended by assuming that s(t) is arbitrarily distributed with ﬁnite fourth-order moments
[20] including the case where Cs ̸= 0 associated with the second-order noncircular distributions.
A common alternative assumption, called deterministic or conditional model (see, e.g., [10,11]) is
used when the distribution of s(t) is unknown or/and clearly non-Gaussian, for example in radar and
radio communications. Here s(t) is nonrandom, i.e., the sequence {s(t)}t1,...,tN is frozen in all realizations
of the random snapshots {x(t)}t1,...,tN . Consequently, {s(t)}t1,...,tN is considered as a complex unknown
parameter in CN P. For this assumption, the snapshots x(t) are complex circular Gaussian distributed
with mean A(θ)s(t) and covariance matrix σ 2
n I.
With these preliminaries, the main DOA problem can now be formulated as follows: Given the
observations, {x(t)}t1,...,tN and the described model (16.1), detect the number P of incoming sources
and estimate their DOAs {θp}p=1,...,P.
3.16.2.3 Parameter identiﬁability
Once the distribution of the observations {x(t)}t1,...,tN has been ﬁxed, the question of the identiﬁability
of the parameters (including the DOA {θp}p=1,...,P) must be raised. For example, under the assumption
of independent, zero-mean circular Gaussian distributed observations, all information in the measured
data is contained in the covariance matrix Rx (16.3). The question of parameter identiﬁability is thus
reduced to investigating under which conditions Rx determines the unknown parameters. Thus, if no a
priori information on Rs is available, the unknown parameter α of Rx contains the following P + P2 +1
real-valued parameters:
α =

θ1, . . . , θP, [Rs]1,1, . . . , [Rs]P,P, Re([Rs]2,1),
Im([Rs]2,1), . . . , Re([Rs]P,P−1), Im([Rs]P,P−1), σ 2
n
T
(16.4)
and the parameter α is identiﬁable if and only if Rx(α(1)) = Rx(α(2)) ⇒α(1) = α(2). To ensure this
identiﬁability, it is necessary that A(θ) be full column rank for any collection of P, distinct θp ∈.
An array satisfying this assumption is said to be unambiguous. Notice that this requirement is problem-
dependent and, therefore, has to be established for the speciﬁc array under study. For example, due to
the Vandermonde structure of a(θ) in the ULA case (16.2), it is straightforward to prove that the ULA
is unambiguous if  = ( −π/2, +π/2). In the case where the rank of Rs, that is the dimension of the
linear space spanned by s(t) is known and equal to r, different conditions of identiﬁability has been
given in the literature. In particular, the condition
P < M + r
2
(which reduces to P < M when Rs is nonsingular)
(16.5)
has been proved to be sufﬁcient [22] and practically necessary [23].

3.16.3 General Statistical Tools for Performance Analysis of DOA Estimation
723
When s(t) are not circularly Gaussian distributed, the identiﬁability condition is generally much more
involved. For example, when s(t) is noncircularly Gaussian distributed, x(t) is noncircularly Gaussian
distributed as well with complementary covariance
Cx = A(θ)CsAT (θ) ̸= 0
(16.6)
and the distribution of the observations are now characterized by both Rx and Cx. Consequently, the
condition of identiﬁability will be modiﬁed w.r.t. the circular case given in (16.5). This condition has
not been presented in the literature, except for the particular case of uncorrelated and rectilinear (called
also maximally improper) sources impinging on a ULA for which, the augmented covariance matrix
R˜x
def
= E[˜x(t)˜xH(t)] with ˜x(t) def
= [xT (t), xH(t)]T is given by
R˜x =
P

p=1
σ 2
pa(θp, φp)aH(θp, φp) + σ 2
n I,
(16.7)
where a(θp, φp) def
= [aT (θp), e−2iφpaH(θp)]T with φp is the second-order phase of noncircularity
deﬁned by
E[s2
p(t)] = e2iφpE
s2
p(t)
 = e2iφpσ 2
p.
(16.8)
Due to the Vandermonde-like structure of the extended steering matrix A(θ, φ) def
= [a(θ1, φ1), . . . ,
a(θP, φP)], the condition of identiﬁability is now here P < 2M −1.
Note that when s(t) is discrete distributed (for example when sp(t) are symbols sp,k(p) of a digital
modulation taking q different values), the condition of identiﬁability is nontrivial despite the distribution
ofx(t)isamixtureofq P circularGaussiandistributionsofmeanP
p=1 sp,k(p)a(θp)andcovarianceσ 2
n I.
3.16.3 General statistical tools for performance
analysis of DOA estimation
3.16.3.1 Performance analysis of a speciﬁc algorithm
3.16.3.1.1
Functional analysis
To study the statistical performance of any DOA’s estimator (often called an algorithm as a succession
of different steps), it is fruitful to adopt a functional analysis that consists in recognizing that the
whole process of constructing the estimate ˆθ N is equivalent to deﬁning a functional relation linking
this estimate to the measurements from which it is inferred. As generally ˆθ N are functions of some
statistics gN (assumed complex-valued vector in CL) deduced from (x(t))t1,...,tN , we have the following
mapping:
{x(t)}t1,...,tN −→gN
alg
−→ˆθ N.
(16.9)
Many often, the statistics gN are sample moments or cumulants of x(t). The most common ones are
second-order sample moments of x(t) deduced from the sample covariance and complementary covari-
ance matrices Rx,N
def
= 1
N
N
n=1 x(tn)xH(tn) and Cx,N
def
= 1
N
N
n=1 x(tn)xT (tn), respectively. For non-
Gaussian symmetric sources distributions, even sample high-order cumulants of x(t) are also used,

724
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
in particular the fourth-order sample cumulants deduced from the sample quadrivariance matrices
Qx,N,Q′
x,N andQ′′
x,N where[Qx]i+( j−1)M,k+(l−1)M
def
= Cum(xi(t), x∗
j (t), x∗
k (t), xl(t)),[Q′
x]i+( j−1)M,k
+(l−1)M
def
= Cum(xi(t), x∗
j (t), xk(t), xl(t))and[Q′′
x]i+( j−1)M,k+(l−1)M
def
= Cum(xi(t), x j(t), xk(t), xl(t)),
estimated through the associated fourth and second-order sample moments. In these cases, the algo-
rithms are called second-order, high-order and fourth-order algorithms, respectively.
The statistic gN generally satisﬁes two conditions:
i. gN converges almost surely (from the strong law of large numbers) to E(gN) when N tends to
inﬁnity, that is a function of the DOAs and other parameters denoted g(θ).
ii. The DOAs θ are identiﬁable from g(θ), i.e., there exists a mapping g(θ) −→θ.
Furthermore, we assume that the algorithm alg satisﬁes alg[(g(θ)] = θ for all θ ∈. Consequently
the functional dependence ˆθ N = alg(gN) constitutes a particular extension of the mapping g(θ) −→θ
in the neighborhood of g(θ) that characterizes all algorithm based on the statistic gN.
Note that for circular Gaussian stochastic and deterministic models of the sources, the likelihood
functions of the measurements depend on {x(t)}t1,...,tN through only the sample covariance Rx,N, and
therefore the algorithms called respectively stochastic maximum likelihood (SML) and deterministic
maximum likelihood (DML) algorithms are second-order algorithms [12]. The SML algorithm has
been extended to noncircular Gaussian sources, for which the ML algorithm is built from both Rx,N
and Cx,N [24].
However, due to their complexity, many suboptimal algorithms with much lower computational
requirements have been proposed in the literature. Among them, many algorithms are based on the
noise (or signal) orthogonal projector x,N onto the noise (or signal) subspace associated with the
sample covariance Rx,N. These algorithms are called subspace-based algorithms. The most celebrated
is the MUSIC algorithm that offers a good trade-off between performance and computational costs. Its
statistical performance has been thoroughly studied in the literature (see, e.g., [1,3,25,26]). In these
cases, the mapping (16.9) becomes
{x(t)}t1,...,tN −→Rx,N −→x,N
alg
−→ˆθ N,
(16.10)
where the mapping alg characterizes the speciﬁc subspace-based algorithm. Some of these algorithms
have been extended for noncircular sources through subspace-based algorithms based on (x,N, ′
x,N)
or ˜x,N where ′
x,N and ˜x,N are the orthogonal projectors onto the noise subspace associated with the
sample complementary covariance Cx,N and the sample augmented covariance R˜x,N
def
= 1
N
N
n=1 ˜x(tn)
˜xH (tn) with ˜x(tn) def
= (xT (tn), xH(tn))T , respectively [27].
3.16.3.1.2
Asymptotic distribution of statistics
Due to the nonlinearity of model (16.1) w.r.t. the DOA’s parameter, the performance analysis of detectors
for the number of sources and the DOA’s estimation procedures are not possible for a ﬁnite number N
of snapshots. But in many cases, asymptotic performance analyses are available when the number N of
measurements, the signal-to-noise ratio (SNR) (see, e.g., [28]) or the number of sensors M converges
to inﬁnity (see, e.g., [29]). In practice N, SNR and M are naturally ﬁnite and thus available results in

3.16.3 General Statistical Tools for Performance Analysis of DOA Estimation
725
the asymptotic regime are approximations, whose domain of validity are speciﬁed through Monte Carlo
simulations. We will consider in this chapter, only asymptotic properties w.r.t. N and thus, the presented
results will be only valid in practice when N ≫M. When N is of the same order of magnitude than M,
although very large, the approximations given by the asymptotic regime w.r.t. N are generally very bad.
To derive the asymptotic distribution, covariance and bias of estimated DOAs w.r.t. the number N
of measurements, we ﬁrst need to specify the asymptotic distribution of some statistics gN.
For the second-order statistics
gN = vec(Rx,N, Cx,N) = 1
N
N

n=1
x∗(tn) ⊗x(tn)
x(tn) ⊗x(tn)

,
where vec(.) and ⊗denote, respectively, the vectorization operator that turns a matrix into a vector by
stacking the columns of the matrix one below another and the standard Kronecker product of matrices,
closed-form expressions of the covariance E[(gN −g)(gN −g)H] and complementary covariance
E[(gN −g)(gN −g)T ] matrices (where g def
= g(θ) for short), and their asymptotic distributions2 have
been given [30] for independent measurements, fourth-order arbitrary distributed sources and Gaussian
distributed noise:
E
	
(gN −g)(gN −g)H
= 1
N
 RRx
RRx,Cx
RH
Rx,Cx
RCx

,
E
	
(gN −g)(gN −g)T 
= 1
N
 CRx
CRx,Cx
CT
Rx,Cx
CCx

,
√
N

vec(Rx,N, Cx,N) −vec(Rx, Cx)
 L
→NC

0;
 RRx
RRx,Cx
RH
Rx,Cx
RCx

,
 CRx
CRx,Cx
CT
Rx,Cx
CCx

,
(16.11)
with
RRx = R∗
x ⊗Rx + K(Cx ⊗C∗
x) +

A∗⊗A

Qs(AT ⊗AH),
(16.12)
RCx = Rx ⊗Rx + K(Rx ⊗Rx) +

A ⊗A

Q′′′
s (AH ⊗AH),
CRx = RRx K,
CCx = Cx ⊗Cx + K(Cx ⊗Cx) +

A ⊗A

Q′′
s (AT ⊗AT ),
RRx,Cx = C∗
x ⊗Rx + K(Rx ⊗C∗
x) +

A∗⊗A

Q′′′′
s (AH ⊗AH),
CRx,Cx = R∗
x ⊗Cx + K(Cx ⊗R∗
x) +

A∗⊗A

Q′
s(AT ⊗AT ),
where A def
= A(θ) for short and K denotes the vec-permutation matrix which transforms vec(C) to
vec(CT ) for any square matrix C. Qs, Q′
s, and Q′′
s are deﬁned as for x(t) deﬁned previously and
2Throughout this chapter N R(m; R), NC(m; R) and NC(m; R, C) denote the real, circular complex, arbitrary complex
Gaussian distribution, respectively, with mean m, covariance R and complementary covariance C.

726
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
[Q′′′
s ]i+( j−1)P,k+(l−1)P
def
= Cum(si(t), s j(t), s∗
k (t), s∗
l (t)), [Q′′′′
s ]i+( j−1)P,k+(l−1)P
def
= Cum(si(t), s∗
j (t),
s∗
k (t), s∗
l (t)). Note that the asymptotic distribution of Rx,N has been extended to non independent
measurements with arbitrary distributed sources and noise of ﬁnite fourth-order moments with Rn
arbitrarily structured in [20,31].
Consider now the noise orthogonal projector gN = vec(x,N). Its asymptotic distribution is deduced
from the standard ﬁrst-order perturbation for orthogonal projectors [32] (see also [6]):
δ(x,N) = −xδ(Rx,N)S# −S#δ(Rx,N)x + o

δ(Rx,N)

,
(16.13)
where δ(x,N) def
= x,N −x, δ(Rx,N) def
= Rx,N −Rx and S# is the Moore-Penrose inverse of S =
A(θ)RsAH(θ). The remainder in (16.13) is a standard o

δ(Rx,N)

for a realization of the random
matrix Rx,N, but an op

δ(Rx,N)

if Rx,N is considered as random. The relation (16.13) proves that gN
is differentiable w.r.t. vec(Rx,N) in the neighborhood of vec(Rx) and its differential matrix (called also
Jacobian matrix) evaluated at vec(Rx) is
DRx,x = −

S∗# ⊗x + ∗
x ⊗S#
.
(16.14)
Then using the standard theorem of continuity (see, e.g., [33, Theorem B, p. 124]) on regular functions
of asymptotically Gaussian statistics, the asymptotic behaviors of x,N and Rx,N are directly related:
√
N

vec(x,N) −vec(x)
 L
→NC

0; Rx , Rx K

,
(16.15)
where Rx is given for independent measurements, fourth-order arbitrary distributed sources and
Gaussian distributed noise, using (16.12) by
Rx = DRx,x RRx DH
Rx,x = ∗
x ⊗U + U∗⊗x,
(16.16)
with U = σ 2
n S#RxS#. We see that Rx does not depend on Cs and the quadrivariances of the sources.
Consequently, all subspace-based algorithms are robust to the distribution and to the noncircularity of
the sources; i.e., the asymptotic performances are those of the standard complex circular Gaussian case.
Note that the asymptotic distribution of (x,N, ′
x,N) and ˜x,N have also been derived under the same
assumptions in [27], where it is proved that they do not depend on the quadrivariances of the sources,
as well. The asymptotic distributions of x,N, (x,N, ′
x,N) and ˜x,N will allow us to derive the
statistical performance of arbitrary subspace-based algorithms based on these orthogonal projectors in
Section 3.16.4.4.
Note that the second-order expansion of x,N w.r.t. Rx,N has been used in [6] to analyze the behavior
of the root-MUSIC and root-min-norm algorithms dedicated to ULA, but is useless as far as we are
concerned by the asymptotic distribution of the DOAs alone, as it has been speciﬁed in [27], where an
extension of the root-MUSIC algorithm to noncircular sources has been proposed.
Finally, consider now the asymptotic distribution of the signal eigenvalues of Rx,N that is useful for
the statistical performance analysis of information theoretic criteria (whose MDL criterion popularized
by Wax and Kailath [13] is one of the most successful), for the detection of the number P of sources. Let
λ1, . . . , λP, λP+1 = σ 2
n , . . . , λM = σ 2
n denote the eigenvalues of Rx, ordered in decreasing order and

3.16.3 General Statistical Tools for Performance Analysis of DOA Estimation
727
v1, . . . , vP the associated eigenvectors (deﬁned up to a multiplicative unit modulus complex number)
of the signal subspace. Then, suppose that for a “small enough” perturbation Rx,N −Rx, the largest
P associated eigenvalues of the sample covariance Rx,N are λ1,N > · · · > λP,N. It is proved in [14],
extending the work by Kaveh and Barabell [1] to arbitrary distributed independent measurements (16.1)
with ﬁnite fourth-order moment, not necessarily circular and Gaussian, the following convergence in
distribution:
√
N(λN −λ) L
→NR(0; Rλ),
(16.17)
with λN = [λ1,N, . . . , λP,N]T , λ = [λ1, . . . , λP]T , and [Rλ]i, j = λ2
i δi, j + |λi, j|2 + λi,i, j, j for
i, j = 1, . . . P, δi, j is the Kronecker delta, λi, j
def
= vH
i Cxv∗
j and λi, j,k,l
def
= (vT
i ⊗vH
j )Qx(v∗
k ⊗vl).
In contrast to the circular Gaussian distribution [1], we see that the estimated eigenvalues {λi,N}i=1,...,P
are no longer asymptotically mutually independent. Furthermore, it is proved in [14] that for i, j =
1, . . . , P:
E[λi,N] = λi + 1
N

1≤k̸=i≤M
λiλk + |λi,k|2 + λi,k,i,k
λi −λk
+ o
 1
N

,
(16.18)
Cov[λi,N, λ j,N] = 1
N (λ2
i δi, j + |λi, j|2 + λi,i, j, j) + o
 1
N

.
(16.19)
We note that these results are also valid for the augmented covariance matrix R˜x,N where M and P are
replaced by 2M and the rank of R˜x,N −σ 2
n I, respectively.
3.16.3.1.3
Asymptotic distribution of estimated DOA
In the following, we consider arbitrary DOA algorithms that are in practice “regular” enough.3 More
speciﬁcally, we assume that the mapping alg is R-differentiable w.r.t. gN ∈CL in the neighborhood of
g(θ), i.e.,
ˆθ N = alg(gN) = alg(g) + Dalg
g,θ(gN −g) + Dalg *
g,θ (gN −g)∗+ o∥gN −g∥,
(16.20)
with alg(g) = θ and P × L matrix Dalg
g,θ is the R-differential matrix (Jacobian) of the mapping
gN
alg
−→ˆθ N evaluated at g(θ). In practice, this matrix is derived from the chain rule by decomposing
the algorithm as successive simpler mappings, and in each of these mapping, this matrix is simply
deduced from ﬁrst-order expansions. Then, applying a simple extension of the standard theorem of
continuity [33, Theorem B, p. 124] (also called -method), it is straightforwardly proved the following
convergence in distribution:
√
N(ˆθ N −θ) L
→NR(0; Rθ) with Rθ = 2

Dalg
g,θRg

Dalg
g,θ
H
+ Re

Dalg
g,θCg

Dalg
g,θ
T 
, (16.21)
where Rg and Cg are the covariance and the complementary covariance matrices of the asymptotic
distribution of the statistics gN. We note that for subspace-based algorithms and second-order algorithms
3This is the case, for example when ˆθ N maximizes w.r.t. α, a real-valued function f (α, gN) that is twice-R differentiable
w.r.t. α and gN.

728
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
based on Rx,N or R˜x,N, g∗
N = KgN (because the orthogonal projector matrices and the covariance
matrices are Hermitian structured), and generally for statistics gN that contain all conjugate of its
components, the mapping alg is C-differentiable w.r.t. gN in the neighborhood of g(θ) and (16.20) and
(16.21) become respectively:
ˆθ N = alg(gN) = alg(g) + Dalg
g,θ(gN −g) + o∥gN −g∥,
(16.22)
where now, Dalg
g,θ is the C-differential matrix of the mapping gN
alg
−→ˆθ N evaluated at g(θ) and
√
N(ˆθ N −θ) L
→NR(0; Rθ) with Rθ = Dalg
g,θRg

Dalg
g,θ
H
.
(16.23)
3.16.3.1.4
Asymptotic covariance and bias
Under additional regularities of the algorithm alg, that are generally satisﬁed, the covariance of ˆθ N is
given by
Cov(ˆθ N) = 1
N Rθ + o
 1
N

.
(16.24)
Using a second-order expansion of alg(gN) and CR-calculus, where alg is assumed to be twice-R-
differentiable, the bias is given by
E(ˆθ N) −θ =
1
2N
⎡
⎢⎢⎢⎣
Tr

R ˜gHalg
˜g,θ,1

...
Tr

R ˜gHalg
˜g,θ,P

⎤
⎥⎥⎥⎦+ o
 1
N

,
(16.25)
where Halg
˜g,θ,k =
∂
∂˜g

∂alg
∂˜g
H
=

H(1)
g,θ,k H(2)g,θ,k
H(2)∗
g,θ,k
H(1)∗
g,θ,k

is the complex augmented Hessian matrix [34,
A2.3] of the kth component of the function alg at point g(θ) and R ˜g =
Rg Cg
C∗
g R∗
g

is the augmented
covariance of the asymptotic distribution of gN. In the particular case where alg is twice-C-differentiable
(see, e.g., the examples given for C-differentiable algorithms (16.22)), i.e.,
ˆθ N = alg(gN) = alg(g) + Dalg
g,θ(gN −g) + 1
2[IP ⊗(gN −g)H]
⎡
⎢⎢⎣
Halg
g,θ,1
...
Halg
g,θ,P
⎤
⎥⎥⎦[gN −g] + o∥gN −g∥2,
(16.26)
(16.25) reduces to
E(ˆθ N) −θ =
1
2N
⎡
⎢⎢⎢⎣
Tr

RgHalg
g,θ,1

...
Tr

RgHalg
g,θ,P

⎤
⎥⎥⎥⎦+ o
 1
N

.
(16.27)

3.16.3 General Statistical Tools for Performance Analysis of DOA Estimation
729
We note that relations (16.24), (16.25) and (16.27) are implicitly used in the signal processing lit-
erature by simple ﬁrst and second-order expansions of the estimate ˆθ N w.r.t. the involved statistics
without checking any necessary mathematical conditions concerning the remainder terms of the ﬁrst
and second-order expansions. In fact these conditions are very difﬁcult to prove for the involved map-
pings gN
alg
−→ˆθ N. For example, the following necessary conditions are given in [35, Theorem 4.2.2] for
second-order algorithms: (i) the measurements {x(t)}t1,...,tN are independent with ﬁnite eighth moments,
(ii) the mapping gN
alg
−→ˆθ N is four times R-differentiable, (iii) the fourth derivative of this mapping
and those of its square are bounded. These assumptions that do not depend on the distribution of the
measurements are very strong, but fortunately (16.24), (16.25) and (16.27) continue to hold in many
cases in which these assumptions are not satisﬁed, in particular for Gaussian distributed data (see, e.g.,
[35, Example 4.2.2]).
In practice, (16.24), (16.25), and (16.27) show that the mean square error (MSE)
E∥ˆθ N −θ∥2 = ∥E(ˆθ N) −θ∥2 + Tr[Cov(ˆθ N)]
(16.28)
is then also of order 1/N. Its main contribution comes from the variance term, since the square of
the bias is of order 1/N 2. But as empirically observed, this bias contribution may be signiﬁcant when
SNR or N is not sufﬁciently large. However, there are very few contributions in the literature, that have
derived closed-form bias expressions. Among them, Xu and Cave [36] has considered the bias of the
MUSIC algorithm, whose derivation ought to be simpliﬁed by using the asymptotic distribution of the
orthogonal projector x,N, rather than those of the sample signal eigenvectors (e1,N, . . . , eP,N).
3.16.3.2 Cramer-Rao bounds (CRB)
The accuracy measures of performance in terms of covariance and bias of any algorithm, described
in the previous section may be of limited interest, unless one has an idea of what the best possible
performance is. An important measure of how well a particular DOA ﬁnding algorithm performs is
the mean square error (MSE) matrix E[(ˆθ −θ)(ˆθ −θ)T ] of the estimation error ˆθ N −θ. Among the
lower bounds on this matrix, the celebrated Cramer-Rao bound (CRB) is by far the most commonly
used. We note that this CRB is indeed deduced from the CRB on the complete unknown parameter
α of the parametrized DOA model, for example, given by (16.4) for the circular Gaussian stochastic
model. Furthermore, rigorously speaking, this CRB ought to be only used for unbiased estimators and
under sufﬁciently regular distributions of the measurements. Fortunately, these technical conditions are
satisﬁed in practice and due to the property that the bias contribution is often weak w.r.t. the variance term
in the mean square error (16.28) for N ≫1, the CRB that lower bounds the covariance matrix of any
unbiased estimators is used to lower bound the MSE matrix of any asymptotically unbiased estimator4
E[(ˆα −α)(ˆα −α)T ] ≥CRB(α)
(16.29)
with CRB(α) is given under weak regularity conditions by:
CRB(α) = FIM−1(α),
(16.30)
4Note that for for ﬁnite N, the estimator ˆα is always biased and (16.29) does not apply. Additionally, biased estimators may
exist whose MSE matrices are smaller than the CRB (see, e.g., [37]).

730
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
where FIM(α) is the Fisher information matrix (FIM) given elementwise by
[FIM(α)]k,l = −E
∂2 log p(x; α)
∂αkαl

(16.31)
associatedwiththeprobabilitydensityfunction p(x; α)ofthemeasurementsx = [xT (t1), . . . , xT (tN)]T .
The main reason for the interest of this CRB is that it is often asymptotically (when the amount N of
data is large) tight, i.e., there exist algorithms, such that the stochastic maximum likelihood (ML) esti-
mator (see 3.16.4.2), whose covariance matrices asymptotically achieve this bound. Such estimators are
said to be asymptotically efﬁcient. However, at low SNR and/or at low number N of snapshots, the CRB
is not achieved and is overly optimistic. This is due to the fact that estimators are generally biased in such
non-asymptotic cases. For these reasons, other lower bounds are available in the literature, that are more
relevant to lower bound the MSE matrices. But unfortunately, their closed-form expressions are much
morecomplextoderiveandaregenerallynoninterpretable(see,e.g.,theWeiss-Weinsteinboundin[38]).
In practice, closed-form expressions of the FIM (16.31) are difﬁcult to obtain for arbitrary distribu-
tions of the sources and noise. In general, the involved integrations of (16.31) are solved numerically
by replacing the expectations by arithmetical averages over a large number of computer generated mea-
surements. But for Gaussian distributions, there are a plethora of closed-form expressions of CRB(θ)
in the literature. And the reason of the popularity of this CRB is the simplicity of the FIM for Gaussian
distributions of x.
3.16.3.2.1
Gaussian stochastic case
On way to derive closed-form expressions of CRB(θ) is to use the extended Slepian-Bangs [39,40]
formula, where the FIM (16.31) is given elementwise by
[FIM(α)]k,l = 2Re
∂mx
∂αk
H
R−1
x
∂mx
∂αl

+ Tr
∂Rx
∂αk
R−1
x
∂Rx
∂αl
R−1
x

(16.32)
for a circular5 Gaussian NC(mx; Rx) distribution of x.But there are generally difﬁculties to derive
compact matrix expressions of the CRB for DOA parameters alone given by
CRB(θ) = [FIM−1(α)](1:P,1:P)
with α = (θ T , βT )T where β gathers all the nuisance parameters (in many applications, only the DOAs
are of interest). Another way, based on the asymptotic efﬁciency of the ML estimator (under certain regu-
larity conditions) has been used to indirectly derive the CRB on the DOA parameter alone (see 3.16.4.2).
For the circular Gaussian stochastic model of the sources introduced in Section 3.16.2.2, compact
matrix expressions of CRB(θ) have been given in the literature, when no a priori information is available
on the structure of the spatial covariance Rs of the sources. For example, Stoica et al. [41] have derived
5Note that this Slepian-Bangs formula has been extended to noncircular Gaussian NC(mx; Rx, Cx) distribution in [42] where
(16.32) becomes [FIM(α)]k,l =

∂m˜x
∂αk
H
R−1
˜x
∂m˜x
∂αl + 1
2Tr

∂R˜x
∂αk R−1
˜x
∂R˜x
∂αl R−1
˜x

with m˜x
def
= (mT
x , mH
x )T and R˜x
def
=
Rx Cx
C∗
x R∗
x

.

3.16.3 General Statistical Tools for Performance Analysis of DOA Estimation
731
the following expression for one parameter per source and uniform white noise (i.e., Rn = σ 2
n I)
CRBCG(θ) = σ 2
n
2N

Re

(DHxD) ⊙

RsAHR−1
x ARs
T −1
,
(16.33)
where ⊙denotes the Hadamard product (i.e., element-wise multiplication), x is the orthogonal pro-
jector on the noise subspace, i.e., x = ⊥
A
def
= I −A(AHA)−1AH and D def
=

da(θ1)
dθ1 , . . . , da(θP)
dθP

. We
note the surprising fact that when the sources are known to be coherent (i.e., Rs singular), the associated
Gaussian CRB CRBCG(θ) that includes this prior, keeps the same expression (16.33) [43].
As is well known, the importance of this Gaussian CRB formula lies in the fact that circular Gaussian
data are rather frequently encountered in applications. Another important point is that under rather
general conditions that will be speciﬁed in Section 3.16.4.2, the circular complex Gaussian CRB matrix
(16.33) is the largest of all CRB matrices among the class of arbitrary complex distributions of the
sources with given covariance matrix Rx (see, e.g., [21, p. 293]). Note that many extensions of (16.33)
have been given. For example this formula has been extended to several parameters per source (see,
e.g., [44, Appendix D]), to nonuniform white noise (i.e., Rn = Diag[σ 2
1 , . . . , σ 2
M]) and unknown
parameterized noise ﬁeld (i.e., Rn = (σ)) in [45–47], respectively. Due to the domination of the
Gaussian distribution, these bounds have often been denoted in the literature as stochastic CRB (e.g.,
in [10]) or unconditional CRB (e.g., in [11]), without specifying the involved distribution.
Furthermore, all these closed-form expressions of the CRB have been extended to the noncircular
Gaussian stochastic model of the sources in [42,44,48, Appendix D], given associated CRBNCG(θ)
expressions satisfying
CRBNCG(θ) ≤CRBCG(θ)
corresponding to the same covariance matrix Rs. For example, for a single source, with one parameter θ1,
CRBNCG(θ1) decreases monotonically as the second-order noncircularity rate γ1 (deﬁned by E|s2
1(t)| =
γ1e2iφ1E[s2
1(t)] and satisfying 0 ≤γ1 ≤1) increases from 0 to 1, for which we have, respectively,
CRBCG(θ1) = 1
N

1
h1

σ 2
n
σ 2
1
+
1
∥a(θ1)∥2
σ 4
n
σ 4
1

,
CRBNCG(θ1) = 1
N

1
h 1

σ 2
n
σ 2
1
+
1
2∥a(θ1)∥2
σ 4
n
σ 4
1

,
(16.34)
where h1 is the purely geometrical factor 2 daH (θ1)
dθ1
⊥
a1
da(θ1)
dθ1
with ⊥
a1
def
= IM −a(θ1)aH (θ1)
∥a(θ1)∥2 .
If the source covariance Rs is constrained to have a speciﬁc structure, (i.e., if a prior on Rs is taken into
account), a speciﬁc expression of CRBCG(θ), which integrates this prior ought to be derived, to assess
the performance of an algorithm that uses this prior. But unfortunately, the derivation of CRBCG(θ) is
very involved and lacks any engineering insight. For example, when it is known that the sources are
uncorrelated, the expression given in [49, Theorem 1] of CRBCG(θ) includes a matrix B, deﬁned as any
matrix, whose columns span the null space of [a∗(θ1) ⊗a(θ1), . . . , a∗(θP) ⊗a(θP)]H. And to the best
of our knowledge no closed-form expression of CRBCG(θ) has been published in the important case of
coherent sources, when the rank of Rs is ﬁxed strictly smaller than P.

732
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
Finally, note that the scalar ﬁeld modeling one component of electromagnetic ﬁeld or acoustic
pressure (16.1) has been extended to vector ﬁelds with vector sensors, where associated stochastic
CRBs for the DOA (azimuth and elevation) alone have been derived and analyzed for a single source. In
particular, the electromagnetic (six electric and magnetic ﬁeld components) and acoustic (three velocity
components and pressure) ﬁelds have been considered in [50,51], respectively.
3.16.3.2.2
Gaussian deterministic case
For the deterministic model of the sources introduced in Section 3.16.2.2, the unknown parameter α of
Rx is now
α =

θ1, . . . , θP,

Re[sT (tn)], Im[sT (tn)]

n=1,...,N , σ 2
n
T
.
(16.35)
ApplyingtheextendedSlepian-Bangsformula(16.32)tothecircularGaussianNC
⎛
⎜⎝
⎡
⎢⎣
As(t1)
...
As(tN)
⎤
⎥⎦; σ 2
n IN M
⎞
⎟⎠
distribution of x, Stoica and Nehorai [11] have obtained the following CRB for the DOA alone:
CRBDet(θ) = σ 2
n
2N
%
Re
	
DHxD ⊙Rs,N

&−1, where Rs,N
def
= 1
N
N
n=1 s(tn)sH(tn). Furthermore, it was
proved in [3] that CRBDet(θ) decreases monotonically with increasing N (and M). This implies, that
if the sources s(tn) are second-order ergodic sequences, Rs,N has a limit Rs when N tends to inﬁnity,
and we obtain for large N, the following expression denoted in the literature as deterministic CRB or
conditional CRB (e.g., in [11])
CRBDet(θ) ≈σ 2
n
2N

Re

(DHxD) ⊙Rs
−1
.
(16.36)
Finally, we remark that the CRB for near-ﬁeld DOA localization has been much less studied than the
far-ﬁeld one. To the best of our knowledge, only papers [52–54] have given and analyzed closed-form
expressions of the stochastic and deterministic CRB, and furthermore in the particular case of a single
source for speciﬁc arrays. For a ULA where the DOA parameters are the azimuth θ and the range r,
based on the DOA algorithms, the steering vector (16.2) has been approximated in [53] by
[a(θ,r)]m=1,...,M = ei(ω(m−1)+φ(m−1)2),
where ω and φ are the so-called electric angles connected to the physical parameters θ and r by
ω = 2π d
λ0 sin(θ) and φ = π d2
λ0r cos2(θ). Then in [52], the exact propagation model
[a(θ,r)]m=1,...,M = e
i 2πr
λ0
'
1+ 2(m−1)d sin (θ)
r
+ (m−1)2d2
r2
−1

,
has been used, that has revealed interesting features and interpretations not shown in [53]. Very recently,
the uniform circular array (UCA) has been investigated in [54] in which the exact propagation model
is now:

3.16.3 General Statistical Tools for Performance Analysis of DOA Estimation
733
[a(θ, φ,r)]m=1,...,M = e
i 2πr
λ0

1−
'
1−2 r0
r cos

θ−2π(m−1)
M

sin (φ)+
r2
0
r2

,
where r0, θ and φ denote the radius of the UCA, the azimuth and the elevation of the source. Note that
in contrast to the closed-form expressions given in [53] and [52], the ones given in [54] relate the near
and far-ﬁeld CRB on the azimuth and elevation by very simple expressions.
3.16.3.2.3
Non Gaussian case
The stochastic CRB for the DOA appears to be prohibitive to compute for non-Gaussian sources. To
cope with this difﬁculty, the deterministic model for the sources has been proposed for its simplicity.
But in contrast to the stochastic ML estimator, the corresponding deterministic (or conditional) ML
method does not asymptotically achieve this deterministic CRB, because the deterministic likelihood
function does not meet the required regularity conditions (see Section 3.16.4.2). Consequently, this
deterministic CRB is only a nonattainable lower bound on the covariance of any unbiased DOA estimator
for arbitrary non-Gaussian distributions of the sources. So, it is useful to have explicit expressions of
the stochastic CRB under non-Gaussian distributions.
To the best of our knowledge, such stochastic CRBs have only been given in the case of binary
phase-shift keying (BPSK), quaternary phase-shift keying (QPSK) signal waveforms [55] and then,
to arbitrary L-ary square QAM constellation [56], and for a single source only. In these works, it is
assumed Nyquist shaping and ideal sample timing apply so that the intersymbol interference at each
symbol spaced sampling instance can be ignored. In the absence of frequency offset but with possible
phase offset, the signals at the output of the matched ﬁlter can be represented as s1(t) = σ 2
1 eiφ1ϵ1(t),
where {ϵ1(t)}t1,...,tN are independent identically distributed random symbols taking values ±1 for BPSK
symbols and {±(2k −1)a ± i(2l −1)a}l,k=1,..2q−1 with L = 22q for L-ary square QAM symbols,
where 2a is the intersymbol distance in the I/Q plane, which is adjusted such that E|ϵ1(t)|2 = 1. For
these discrete sources, the unknown parameter of this stochastic model is
α =

θ1, φ1, σ 2
1 , σ 2
n
T
andithasbeenprovedin[55,56]thattheparameters(θ1, φ1)and(σ 2
1 , σ 2
n )aredecoupledintheassociated
FIM. This allows one to derive closed-form expressions of the so called non-data-aided (NDA) CRBs
on the parameter θ1 alone. In particular, it has been proved [55] that for a BPSK and QPSK source, that
is respectively rectilinear and second-order circular, we have
CRBBPSK(θ1)
CRBNCG(θ1) =
1
(1 −g(ρ))

1 + 1
2ρ

and
CRBQPSK(θ1)
CRBCG(θ1)
=
1

1 −g
 ρ
2
 
1 + 1
ρ
,
(16.37)
where CRBNCG(θ1) and CRBCG(θ1) are given by (16.34) and with ρ def
= Mσ 2
1
σ 2n
and g is the following
decreasing function of ρ: g(ρ) def
= e−ρ
√
2π
( +∞
−∞
e−u2
2
cosh(u√2ρ) du. Equation (16.37) is illustrated in Figure
16.1 for a ULA of M sensors spaced a half-wavelength apart. We see from this ﬁgure that the CRBs
under the non-circular [resp. circular] complex Gaussian distribution are tight upper bounds on the

734
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
−10
−5
0
5
10
15
20
25
30
0.85
0.9
0.95
1
ρ (dB)
r1(θ1)
QPSK
BPSK
FIGURE 16.1
Ratios r1(θ1) def
= CRBBPSK(θ1)
CRBNCG(θ1) and r1(θ1) def
= CRBQPSK(θ1)
CRBCG(θ1)
as a function of ρ def
=
Mσ 2
1
σ 2n .
CRBs under the BPSK [resp. QPSK] distribution at very low and very high SNRs only. Finally, note
that among the numerous results of [55,56], these stochastic NDA CRBs have been compared with
those obtained with different a priori knowledge. In particular, it has been proved that in the presence
of any unknown phase offset (i.e., non-coherent estimation), the ultimate achievable performance on
the NDA DOA estimates holds almost the same irrespectively of the modulation order L. However, the
NDA CRBs obtained in the absence of phase offset (i.e., coherent estimation) vary, in the high SNR
region, from one modulation order to another.
Finally note that the ML estimation of the DOAs of these discrete sources has been proposed [57],
where the maximization of the ML criterion (which is rather involved) is iteratively carried out by the
expectation maximization (EM) algorithm. Adapted to the distribution of these sources, this approach
allows one to account for any arbitrary noise covariance Rn as soon as n(t) is Gaussian distributed.
3.16.3.3 Asymptotically minimum variance bounds (AMVB)
To assess the performance of an algorithm based on a speciﬁc statistic gN built on {x(t)}t1,...,tN , it is
interesting to compare the asymptotic covariance Rθ (16.21) or (16.23) to an attainable lower bound
that depends on the statistic gN only. The asymptotically minimum variance bound (AMVB) is such
a bound. Furthermore, we note that the CRB appears to be prohibitive to compute for non-Gaussian
sources and noise, except in simple cases and consequently this AMVB can be used as an useful
benchmark against which potential estimates ˆθ N are tested. To extend the derivations of Porat and
Friedlander [58] concerning this AMVB to complex-valued measurements, two additional conditions
to those introduced in Section 3.16.3.1.1 must be satisﬁed:

3.16.3 General Statistical Tools for Performance Analysis of DOA Estimation
735
iii. The involved function alg that deﬁnes the considered algorithm must be C-differentiable, i.e.,
must satisfy (16.22). In practice, it is sufﬁcient to add conjugate components to all complex-valued
components of g, as in example (16.41);
iv. The covariance Rg of the asymptotic distribution of gN must be nonsingular. To satisfy this lat-
ter condition, the components of gN that are random variables, must be asymptotically linearly
independent. Consequently the redundancies in gN must be withdrawn.
Under these four conditions, the covariance matrix Rθ of the asymptotic distribution of any estimator
ˆθ N built on the statistics gN is bounded below by (GH(θ)R−1
g G(θ))−1:
Rθ = Dalg
g,θRg

Dalg
g,θ
H
≥

GH(θ)R−1
g G(θ)
−1
,
(16.38)
where G(θ) is the L × P matrix dg(θ)
dθ .
Furthermore, this lowest bound AMVBgN (θ) def
= (GH(θ)R−1
g G(θ))−1 is asymptotically tight, i.e.,
there exists an algorithm alg whose covariance of its asymptotic distribution satisﬁes (16.38) with
equality. The following nonlinear least square algorithm is an AMV second-order algorithm:
ˆθ N = arg min
α∈P[gN −g(α)]HR−1
g (α)[gN −g(α)],
(16.39)
where we have emphasized here the dependence of Rg on the unknown DOA α. In practice, it is
difﬁcult to optimize the nonlinear function (16.39), where it involves the computation of R−1
g (α). Porat
and Friedlander proved for the real case in [59] that the lowest bound (16.38) is also obtained if an
arbitrary weakly consistent estimate Rg,N of Rg(α) is used in (16.39), giving the simplest algorithm:
ˆθ N = arg min
α∈P[gN −g(α)]HRg,N[gN −g(α)].
(16.40)
This property has been extended to the complex case in [60].
This AMVB and AMV algorithm have been applied to second-order algorithms that exploit both
Rx,N and Cx,N in [24]. In this case, to fulﬁll the previously mentioned conditions (i)–(iv), the second-
order statistics gN are given by
gN =
⎡
⎣
vec(Rx,N)
v(Cx,N)
v(C∗
x,N)
⎤
⎦,
(16.41)
where v(·) denotes the operator obtained from vec( · ) by eliminating all supradiagonal elements of a
matrix. Finally, note that these AMVB and AMV DOA ﬁnding algorithm have been also derived for
fourth-order statistics by splitting the measurements and statistics gN into its real and imaginary parts
in [60].
3.16.3.4 Relations between AMVB and CRB: projector statistics
The AMVB based on any statistics is generally lower bounded by the CRB because this later bound
concerns arbitrary functions of the measurements {x(t)}t1,...,tN . But it has been proved in [44], that the
AMVB associated with the different estimated projectors x,N, (x,N, ′
x,N) and ˜x,N introduced

736
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
in Section 3.16.3.1.2, which are functions of the second-order statistics of the measurements, attains
the stochastic CRB in the case of circular or noncircular Gaussian signals. Consequently, there always
exist asymptotically efﬁcient subspace-based DOA algorithms in the Gaussian context.
To prove this asymptotic efﬁciency, i.e.,
AMVBvec(x,N )(θ) = CRBCG(θ)
(16.42)
and
AMVBvec(x,N ,′
x,N )(θ) = AMVBvec(˜x,N )(θ) = CRBNCG(θ),
(16.43)
the condition (iv) of Section 3.16.3.3 that is not satisﬁed [61] for these statistics ought to be extended
and consequently the results (16.38) and (16.39) must be modiﬁed as well, because here Rg is singular.
In this singular case, it has been proved [61] that if the condition (iv) in the necessary conditions
(i)–(iv) is replaced by the new condition Span(G(θ)) ⊂Span(Rg(θ)), (16.38) and (16.39) becomes
respectively
Rθ = Dalg
g,θRg

Dalg
g,θ
H
≥

GH(θ)R#
gG(θ)
−1
(16.44)
and
ˆθ N = arg min
α∈P[gN −g(α)]HR#
g(α)[gN −g(α)].
(16.45)
And it is proved that the three statistics vec(x,N), vec(x,N, ′
x,N), and vec(˜x,N) satisfy the con-
ditions (i)–(iii) and (v) and thus satisfy results (16.44) and (16.45).
Finally, note that this efﬁciency property of the orthogonal projectors extends to the model of spatially
correlated noise, for which Rn = σ 2
n n where n is a known positive deﬁnite matrix. In this case, for
example, the orthogonal projector xw,N deﬁned after whitening
{x(t)}t1,...,tN −→{xw(t)}t1,...,tN
def
= {−1/2
n
x(t)}t1,...,tN −→Rxw,N
= 1
N
N

n=1
xw(tn)xH
w (tn) −→xw,N
satisﬁes
AMVBvec(xw,N )(θ) = CRBw
CG(θ) = σ 2
n
2N

Re

(DHxwD) ⊙

RsAHR−1
x ARs
T −1
,
where xw
def
= −1
n
−−1
n A(AH−1
n A)−1−H
n
AH is insensitive to the choice of the square root 1/2
n
of n, and is no longer a projection matrix.
3.16.4 Asymptotic distribution of estimated DOA
We are now specifying in this section the asymptotic statistical performances of the main DOA algo-
rithms that may be classiﬁed into three main categories, namely beamforming-based, maximum like-
lihood and moments-based algorithms.

3.16.4 Asymptotic Distribution of Estimated DOA
737
3.16.4.1 Beamforming-based algorithms
Among the so-called beamforming-based algorithms, also referred to as low-resolution, compared to
the parametric algorithms, the conventional (Bartlett) beamforming and Capon beamforming are the
most referenced representatives of this family. These algorithms do not make any assumption on the
covariance structure of the data, but the functional form of the steering vector a(θ) is assumed perfectly
known. These estimators ˆθ N are given by the P highest (supposed isolated) maximizer and minimizer
in α of the respective following criteria:
aH(α))Rxa(α) and aH(α)
R−1
x a(α),
(16.46)
where )Rx is the unbiased sample estimate Rx,N and 
R−1
x
is either the biased estimate R−1
x,N or the
unbiased estimate [(N −M)/N]R−1
x,N (that both give the same estimate ˆθ N). Note that these algorithms
extend to d parameters per source, where α is replaced by α = (α1, . . . , αd) in (16.46).
For arbitrary noise ﬁeld (i.e., arbitrary noise covariance Rn) and/or an arbitrary number P of sources,
the estimate ˆθ N given by these two algorithms are non-consistent, i.e.,
lim
N→∞
ˆθ N ̸= θ
and asymptotically biased. The asymptotic bias AsBias(θ) can be straightforwardly derived by a second-
order expansion of the criterion aH(α)Rϵ
xa(α) around each true values (θp)p=1,...,P (with ϵ = +1 [resp.,
ϵ = −1] for the conventional [resp. Capon] algorithm), but noting that limN→∞E( ˆθp,N) is a maximizer
or minimizer ¯θp of aH(α)Rxa(α) or aH(α)R−1
x a(α), respectively. The following value is obtained [62]
AsBias(θp) def
= lim
N→∞E( ˆθp,N) −θp = −
Re[a′H(θp)Rϵ
xa(θp)]
a′H(θp)Rϵxa′(θp) + Re[aH(θp)Rϵxa′′(θp)],
(16.47)
with a′(θp) def
= daH (θp)
dθp
and a′′(θp) def
= d2aH (θp)
dθ2p
.
Following the methodology of Section 3.16.3.1.2, the additional bias for ﬁnite value of N, that is of
order 1/N can be derived, which gives
E( ˆθp,N) −θp = AsBias(θp) + bp
N + o
 1
N

,
see, e.g., the involved expression of bp for the Capon algorithm [62, rel. (35)].
In the same way, the covariance E[(ˆθ N −E(ˆθ N))(ˆθ N −E(ˆθ N))T ] which is of order 1/N can be
derived. It is obtained with ¯θ def
=[ ¯θ1, . . . , ¯θP]T
E[(ˆθ N −E(ˆθ N))(ˆθ N −E(ˆθ N))T ] = E[(ˆθ N −¯θ)(ˆθ N −¯θ)T ] + o
 1
N

= Rθ
N + o
 1
N

,
see, e.g., the involved expression [50, rel. (24)] of Rθ associated with a source for several parameters
per source. The relative values of the asymptotic bias, additional bias and standard deviation depend

738
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
on the SNR, M and N, but in practice the standard deviation is typically dominant over the asymptotic
bias and additional bias (see examples given in [62]).
Finally, note that in the particular case of a single source, uniform white noise (Rn = σ 2
n I) and an
arbitrary number d of parameters of the source (here θ = (θ1, . . . , θd)T ), it has been proved [63], that
ˆθ N given by these two beamforming-based algorithms is asymptotically unbiased (AsBias(θp) given
by (16.47) is zero), if and only if ∥a(θ)∥is constant. Furthermore, based on the general expressions
(16.48) of the FIM6
FIM(θ) =
2Nσ 4
s
σ 2n (σ 2n + ∥a(θ)∥2σ 2s )Re

∥a(θ)∥2D(θ)HD(θ)−D(θ)Ha(θ)aH(θ)D(θ)

,
(16.48)
where D(θ) is deﬁned here by [∂a(θ)/∂θ1, . . . , ∂a(θ)/∂θd], for d parameters associated with a single
source, and expression [50, rel. (24)] of Rθ specialized to Rn = σ 2
n I, it has been proved that 1
N Rθ =
FIM−1(θ), i.e., the conventional and Capon algorithms are asymptotically efﬁcient, if and only if ∥a(θ)∥
is constant.
3.16.4.2 Maximum likelihood algorithms
3.16.4.2.1
Stochastic and deterministic ML algorithms
As discussed in Section 3.16.2.2, the two main models for the sensor array problem in Gaussian noise,
corresponding to stochastic and deterministic modeling of the source signals lead to two different
Gaussiandistributionsofthemeasurements{x(t)}t1,...,tN ,andconsequentlytotwodifferentlog-likelihoods
l(α) = ln p(x; α), where the unknown parameter α is respectively given by (16.4) and (16.35).
With some algebraic effort, the stochastic ML criterion l(α) can be concentrated w.r.t. Rs and σ 2
n
(see, e.g., [64,65]), thus reducing the dimension of the required numerical maximization to the required
P DOAs (θ1, . . . , θP) and giving the following optimization problem:
ˆθ
SML
N
= arg min
θ∈P JSML[θ, Rx,N],
(16.49)
with
JSML[θ, Rx,N] = ln[det (A(θ)Rs,N(θ)AH(θ) + σ 2
n,N(θ)I)],
(16.50)
where
Rs,N(θ) = A#(θ)[Rx,N −σ 2
n,N(θ)I]A#H(θ) and σ 2
n,N(θ) =
1
M −P Tr[⊥
A(θ)Rx,N],
(16.51)
where ⊥
A(θ) = I −A(θ)A#(θ) is the orthogonal projector onto the null space of AH. Despite its
reduction of the parameter space, JSML[θ, Rx,N] is a complicated nonlinear expression in θ, that cannot
been analytically minimized. Consequently, numerical optimization procedures are required.
Remark that in this modeling, the obvious a priori information that Rs is positive semi-deﬁnite has
not been taken into account. This knowledge, and more generally, the prior that Rs is positive semi-
deﬁnite of rank r smaller or equal than P can be included in the modeling by the parametrization
6For one parameter (d = 1) or ∥a(θ)∥constant, (16.48) can be simpliﬁed by withdrawing the real operator [2, rel. (49)].

3.16.4 Asymptotic Distribution of Estimated DOA
739
Rs = LLH, where L is a P × r lower triangular matrix. But this modiﬁcation will have no effect for
“large enough N” since )Rs given by (16.51) is a weakly consistent estimate of Rs [12]. And since this
new parametrization leads to signiﬁcantly more involved optimization, the unrestricted parametrization
of Rs used in (16.50) appears to be preferable.
Due to the quadratic dependence of the deterministic ML criterionl(α) in the parameters {s(t)}t1,...,tN ,
its concentration w.r.t. {s(t)}t1,...,tN and σ 2
N is much more simpler than for the stochastic ML criterion.
It gives the following new ML estimator:
ˆθ
DML
N
= arg min
θ∈P JDML[θ, Rx,N],
(16.52)
with
JDML[θ, Rx,N] = Tr[⊥
A(θ)Rx,N].
(16.53)
Comparing (16.53) and (16.50), we see that the dependence in θ of the DML criterion is simpler than
for the SML criterion. But both criteria require nonlinear Pth-dimensional minimizations with a large
number of local minima that give two different estimates θ, except for a single source for which the
minimization of (16.53) and (16.50) reduce to the maximization of the common criteria
aH(θ)Rx,Na(θ)
∥a(θ)∥2
.
This implies that when the norm of the steering vector a(θ) is constant (which is generally assumed), the
conventional and Capon beamforming, SML and DML algorithms coincide and thus conventional and
Capon beamforming and DML algorithms inherit the asymptotical efﬁciency of the SML algorithm.
Note that this property extends to several parameters per source.
3.16.4.2.2
Asymptotic properties of ML algorithms
We consider in this Subsection, the asymptotic properties of DML or SML algorithms used under the
respectively, deterministic and circular Gaussian stochastic modeling of the sources. In the ﬁeld of
asymptotic performance characterization of DML or SML algorithms, asymptotic generally refers to
either the number N of snapshots or the SNR value.
First,considertheasymptoticpropertiesw.r.t. N,thatarethemostknown.Underregularityconditions
that are satisﬁed by the SML algorithm, the general properties of ML estimation states that ˆθ
SML
N
is
consistent and asymptotically efﬁcient and Gaussian distributed, more precisely
√
N

ˆθ
SML
N
−θ
 L
→NR(0; RSML
θ
) with RSML
θ
= NCRBCG(θ),
(16.54)
where CRBCG(θ) is given by (16.33). This property of the SML algorithm extends to nonuniform white
and unknown parameterized noise ﬁeld in [45,46], respectively, and to general noncircular Gaussian
stochastic modeling of the sources with the associated CRBNCG(θ) [42,48]. Note that to circumvent
the difﬁculty to extract the “θ corner” from the inverse of FIM(α), a matrix closed-form expression of
CRBCG(θ) has been ﬁrst obtained in an indirect manner by an asymptotic analysis of the SML estimator
[10,11]. Then, only 10 years later, this CRB has been obtained directly from the extended Slepian-Bangs
formula [41,45].

740
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
As for the DML algorithm, since the signal waveforms themselves are regarded as unknown param-
eters, it follows that the number of unknown parameters α (16.35) in the modeling, grows without limit
with increasing N, the general asymptotic properties of the ML no longer apply. More precisely, the
DML estimate of θ is weakly consistent, whereas the DML estimate of {s(tn)}n=1,...,N is inconsistent.
The asymptotic distribution of ˆθ
DML
N
has been derived in [4,66]
√
N

ˆθ
DML
N
−θ
 L
→NR

0; RDML
θ

(16.55)
with
RDML
θ
= NCRBDet(θ) + 2N 2CRBDet(θ)Re

(DHxD) ⊙(AHA)−T 
CRBDet(θ),
(16.56)
where CRBDet(θ) is given by (16.36). Note that the inequality 1
N RDML
θ
≤CRBDet(θ) in (16.56) does
not follow from the Cramer-Rao inequality theory directly, because the Cramer-Rao inequality requires
that the number of unknown parameters be ﬁnite. As the number of real-valued parameters in α (16.35)
is P + 2N P + 1, it increases with N and the Cramer-Rao inequality does not apply here. Note that the
DML estimates of {s(tn)}n=1,...,N are indeed asymptotically unbiased, despite being non-consistent.
Furthermore, it has been proved in [4], that if the DML algorithm is used under the circular Gaussian
stochastic modeling of the sources, the asymptotic distribution (16.54) of ˆθ
DML
N
is preserved. But under
this assumption on the sources, the DML algorithm is suboptimal, and thus 1
N RDML
θ
≥CRBCG(θ).
Finally comparing directly the expressions (16.33) and (16.36) of the Cramer-Rao bound by applying
the matrix inversion lemma, it is straightforward to prove that CRBCG(θ) ≥CRBDet(θ). This allows
one to relate RDML
θ
, RSML
θ
, CRBCG(θ), and CRBDet(θ) by the following relation:
1
N RDML
θ
≥1
N RSML
θ
= CRBCG(θ) ≥CRBDet(θ).
(16.57)
In particular, for a single source with q parameters, we have
CRBCG(θ) =

1 +
σ 2
n
∥a(θ)∥2σ 2s

CRBDet(θ),
(16.58)
with CRBCG(θ) = FIM−1(θ), where FIM(θ) is given by (16.48).
Finally, note an asymptotic robustness property [10,11] of the SML and DML algorithms that states
that the asymptotic distribution of ˆθ
SML
N
and ˆθ
DML
N
is preserved whatever the modeling of the source:
circular Gaussian distributed with E[s(t)sH(t)] = Rs or modeled by arbitrary second-order ergodic
signals with Rs = limN→∞1
N
N
n=1 s(tn)sH(tn). We will present a more general asymptotic robustness
property that applies to a large category of second-order algorithms in Section 3.16.4.3. The fact that
the SML algorithm always outperforms (for P > 1) the DML algorithm, provides strong justiﬁcations
for the appropriateness of the stochastic modeling of sources for the DOA estimation problem.
Consider now, the asymptotic properties of the SML and DML algorithms w.r.t. SNR, used under
their respective source model assumptions. It has been proved in [28], that under the circular Gaus-
sian assumption of the sources, the SML estimates ˆθ
SML
N
is asymptotically (w.r.t. SNR) non-Gaussian

3.16.4 Asymptotic Distribution of Estimated DOA
741
distributed and non-efﬁcient, i.e., ˜θσn
def
= 1
σn (ˆθ
SML
N
−θ) converges in distribution to a non-Gaussian dis-
tribution, when σn tends to zero, with N ﬁxed, with limσn→0 E[˜θσn ˜θ
T
σn] ≥limσn→0 1
σ 2n CRBCG(θ). In
practice, ˆθ
SML
N
is non-Gaussian distributed and non-efﬁcient at high SNR, only for a very small number
N of snapshots.7 For example, for a single source, using (16.37), it is proved in [28] that
lim
σn→0 E[˜θσn ˜θ
T
σn] =
N
N −1 lim
σn→0
1
σ 2n
CRBCG(θ) =
N
N −1

1
Nh1σ 2
1

,
(see (16.34) for the second equality), where h1 is deﬁned just after (16.34). These properties contrast
with the DML algorithm used under the deterministic modeling of the sources, which is proved [67] to be
asymptotically
(w.r.t.
SNR)
Gaussian
distributed
and
efﬁcient,
i.e.,
1
σn (ˆθ
DML
N
−θ) L
→
NR(0;
1
2N {Re[(DHxD) ⊙Rs]}−1) when σn tends to zero, with N arbitrary ﬁxed. These results
are consistent with those of [11]. In practice for very high SNR and “not too small” N, (16.57) becomes
1
N RDML
θ
≈1
N RSML
θ
= CRBCG(θ) ≈CRBDet(θ).
(16.59)
Furthermore, it has been proved in [11], that (16.59) is also valid for M ≫1. The asymptotic distribution
of the DOA estimate w.r.t. M (for ﬁnite data) of the SML and DML algorithms has been studied in [68].
The strong consistency has been proved for both ML algorithms. Furthermore, unlike the previously
studied large sample case, the asymptotic covariance matrices of the DOA estimates coincide with the
deterministic CRB (16.36) for the SML and DML algorithms. The asymptotic distribution of the DOA
estimates given by subspace-based algorithms has been studied in [29], when M, N →∞, whereas
M/N converges to a strictly positive constant. In this asymptotic regime, it is proved, in particular, that
these traditional DOA estimates are not consistent. The threshold and the so-called subspace swap of the
SML and MUSIC algorithms have been studied w.r.t. N, M and SNR (see, e.g., [69]). Furthermore, a new
consistent subspace-based estimate has been proposed, which outperforms the standard subspace-based
methods for values of M and N of the same order of magnitude [29].
3.16.4.2.3
Large sample ML approximations
Since the SML and DML algorithms are often deemed exceedingly complex, suboptimal algorithms
are of interest. Many such algorithms have been proposed in the literature and surprisingly, some of
them are asymptotically as accurate as the ML algorithms, but with a reduced computational cost. These
algorithms have been derived, either by approximations of the ML criteria by neglecting terms that do
not affect the asymptotic properties of the estimates, or by using a purely geometrical point of view. We
present this latter approach that allows one to unify a large number of algorithms [12]. These algorithms
rely on the geometrical properties of the spectral decomposition of the covariance matrix Rx:
Rx = Es
sEH
s + σ 2
n EnEH
n
7In practice the approximate covariances deduced from the asymptotic analysis w.r.t. the number of snapshots are also valid
for high SNR with ﬁxed “not too small number” of snapshots for the second-order DOA algorithms. But note that there is no
theoretical result on the asymptotic distribution of the sample projector w.r.t. the SNR.

742
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
with Es = [e1, . . . , er], 
s = Diag(λ1, . . . , λr), and En = [er+1, . . . , eM] where r is the rank of Rs,
associated with the consistent estimates
Rx,N
def
= 1
N
N

n=1
x(tn)xH(tn) = Es,N
s,NEH
s,N + σ 2
n,NEn,NEH
n,N.
(16.60)
These algorithms can be classiﬁed as signal subspace-based and noise subspace-based ﬁtting algorithms.
The former algorithms based on Span(Es) ⊆Span(A(θ)) are given by the following optimization:
ˆθ
SSF
N
= arg min
θ∈P Tr

⊥
A(θ)Es,NWEH
s,N

,
(16.61)
where W is a weighting r × r positive deﬁnite matrix to be speciﬁed. And the latter algorithms based
on EH
n A(θ) = 0, that is valid only if the source covariance matrix is nonsingular (r = P), are given by
ˆθ
NSF
N
= arg min
θ∈P Tr[UAH(θ)En,NEH
n,NA(θ)],
(16.62)
where U is a weighting P × P positive deﬁnite matrix to be speciﬁed.
Introduced from a purely geometrical point of view, these two classes of algorithms present unex-
pected relations with the previously described ML algorithms. First, for arbitrary positive deﬁnite
weighting matrices W and U, the estimates ˆθ
SSF
N
and ˆθ
NSF
N
given respectively by (16.61) and (16.62),
are weakly consistent. Second, for the weighting matrices that give the lowest covariance matrix of the
asymptotic distribution of ˆθ
SSF
N
and ˆθ
NSF
N
, that are respectively given [12] by
Wopt = (
s −σ 2
n I)2
−1
s
and Uopt = A#(θ0)EsWoptEH
s A#H(θ0),
where θ0 denotes here the true value of the DOAs, the associated estimates ˆθ
SSF
N
and ˆθ
NSF
N
are asymp-
totically equivalent to ˆθ
SML
N
(i.e.,
√
N(ˆθ
SSF
N
−ˆθ
SML
N
) →0 and
√
N(ˆθ
NSF
N
−ˆθ
SML
N
) →0 in probability
as N →∞) and thus have the same asymptotic distribution that the SML algorithm. Furthermore and
fortunately, this property extends for any weakly consistent estimates WN and UN of respectively Wopt
and Uopt, e.g., derived from the spectral decomposition of the sample covariance matrix Rx,N (16.60)
with σ 2
n,N is the average of M −r smallest eigenvalues of Rx,N and with θ0 is replaced by a weakly
consistent estimates of θ. This implies a two steps procedure to run the optimal noise subspace-based
ﬁtting algorithm. Due to this drawback, the signal subspace-based ﬁtting algorithm with the weighting
WN = (
s,N −σ 2
n,NI)2
−1
s,N, denoted weighted subspace ﬁtting (WSF) algorithm, is preferred to the
noise subspace-based ﬁtting algorithms.
Finally, note that this algorithm is based on eigenvalues and eigenvectors of the sample covariance
matrix Rx,N. This contrasts with the subspace-based algorithms whose asymptotic statistical properties
will be studied in Section 3.16.4.4 that are based on the noise or signal orthogonal projector x,N asso-
ciated with Rx,N only. Note that general properties of subspace-based estimators focused on asymptotic
invariance of these estimators have been given in [70].

3.16.4 Asymptotic Distribution of Estimated DOA
743
3.16.4.3 Second-order algorithms
Most of the narrowband DOA algorithms presented in the literature are second-order algorithms, i.e., are
based on the sample covariance Rx,N
def
= 1
N
N
n=1 x(tn)xH(tn) or more generally on R˜x,N
def
= 1
N
N
n=1
˜x(tn)˜xH(tn). To prove common properties of this class of algorithm, it is useful to use the functional
analysis presented in Section 3.16.3.1.1
{x(t)}t1,...,tN −→Rx,N
alg
−→ˆθ N,
(16.63)
in which any second-order algorithm is a mapping alg that generally satisﬁes
alg

A(θ)RsAH(θ) + σ 2
n I

= θ
for any θ ∈P,
(16.64)
but not necessarily for all P × P Hermitian positive semi-deﬁnite matrix Rs. Depending on the a
priori knowledge about Rs, that is required by the second-order algorithms alg, different constraints are
satisﬁed by the C-differential matrix Dalg
Rx,θ of the algorithm at the point Rx (16.22). In particular, it has
been proved the following main two constraints [20]:
Dalg
Rx,θ

A(θ) ⊗A(θ)

= 0 for Rs unstructured
(16.65)
Dalg
Rx,θ

a(θp) ⊗a(θp)

= 0,
p = 1, . . . , P for Rs structured diagonal.
(16.66)
Using these constraints, the general expression RRx of the covariance of the asymptotic distribution of
the sample covariance Rx,N [31] obtained under mild conditions for non independent measurements
with arbitrary distributed sources and noise of ﬁnite fourth-order moments, and the general relation
(16.23), that links RRx and Dalg
Rx,θ to the covariance Rθ of the asymptotic distribution of ˆθ N, allows one
to prove the following two results, that extend a robustness property presented in [71]:
•
For any second-order algorithms based on Rx,N, that do not require the sources spatially uncorrelated
and when the noise signals {n(t)}t1,...,tN are temporally uncorrelated, Rθ is invariant to the distribu-
tion, the second-order noncircularity and the temporal distribution of the sources, but depends on
the distribution of the noise through its second-order and fourth-order moments. In particular for
circular Gaussian noise, the asymptotic distribution of ˆθ N are those of the standard complex circular
Gaussian case.
•
For any second-order algorithms based on Rx,N that require the sources spatially uncorrelated and/or
when the noise signals {n(t)}t1,...,tN are temporally correlated, Rθ is sensitive to the distribution, the
second-order noncircularity and the temporal distribution of the sources.
Note that the majority of the second-order algorithms (e.g., the beamforming, ML, MUSIC, Min Norm,
ESPRIT algorithms) does not require spatially uncorrelated sources. In contrast, second-order tech-
niques based on state-space realizations (e.g., the Toeplitz approximation method (TAM), see [8]) and
Toeplitzation or augmentation with ULA or uniform rectangular arrays, require this uncorrelation, and
thus the asymptotic distribution of ˆθ N will be generally (except for a single source, for which the con-
straint (16.66) reduces to (16.65)) sensitive to the distribution, the second-order noncircularity or the
temporal distribution of the sources, even when the noise is temporally uncorrelated.

744
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
−10
−5
0
5
10
15
20
25
30
10−7
10−6
10−5
10−4
10−3
10−2
SNR(dB)
MSE
FIGURE 16.2
Theoretical and estimated MSE (with 500 Monte Carlo runs) of θ1 versus the SNR, for respectively white (◦),
colored (+) and harmonic (*) signals for N = 100 after Toeplitzation (—) and without Toeplitzation (- - -).
To illustrate this sensitivity to the source distribution when the noise is temporally uncorrelated, we
consider in Figure 16.2, the case of two equipowered and spatially uncorrelated sources impinging on
a ULA of 10 sensors, θ1 = 20◦and θ2 = 30◦, where the DOAs are estimated by the standard MUSIC
algorithm after Toeplization. The sources are either white Gaussian, ARMA Gaussian (generated by
a (10, 10) Butterworth ﬁlter driven by a white circular Gaussian noise, where the bandwidth is ﬁxed
to 0.5) or harmonic. The centered frequencies of the ARMA and the frequencies of the harmonics are
−0.25 and 0.25. Figure 16.2 shows that the Toeplization improves the performance for very weak SNR
only, whereas is very sensitive to the distribution of the sources for high SNR.
Usually, performance analyses are evaluated as a function of the number N of observed snapshots
without taking the sampling rate into account. In fact, depending on the value of this sampling rate, the
collected samples x(tn) are more or less temporally correlated and performance is affected. Thus, the
interesting question arises as to how the asymptotic covariance of the DOA estimators (denoted here
ˆθ T ) varies with this sampling rate 1
Ts for a ﬁxed observation interval T = NTs. This question has been
investigated in [20], in which the continuous-time noise envelope n(t) is spatially white and temporally
white in the bandwidth [−B
2 , + B
2 ]. It has been proved:
•
If the signals x(t) are oversampled ( 1
Ts > B)
E[(ˆθ T −θ)(ˆθ T −θ)T ] ≈
1
BT Rθ > 1
N Rθ
for N ≫1,
irrespective of the sample rate 1/Ts.

3.16.4 Asymptotic Distribution of Estimated DOA
745
•
If the signals x(t) are subsampled ( 1
Ts < B)
E[(ˆθ T −θ)(ˆθ T −θ)T ] ≈Ts
T Rθ = 1
N Rθ >
1
BT Rθ
for N ≫1 and BTs ≫1.
Consequently the array must be temporally oversampled, and the parameter of interest that characterizes
performance ought not to be the number N of snapshots, but rather the observation interval T .
3.16.4.4 Subspace-based algorithms
We concentrate now on the family of second-order algorithms based on the orthogonal noise8 projector
x,N (16.10). These algorithms estimate θ, either by extrema-searching approaches (MUSIC, Min-
Norm, etc.), by polynomial rooting approaches (Pisarenko, root MUSIC, and root Min-Norm for ULA),
or by matrix shifting approaches (ESPRIT, TAM, Matrix pencil method). The most celebrated of these
algorithms is the MUSIC algorithm, where θ is estimated as the P deepest minima in a d-dimensional
(for d parameters per source) of the following localization function JMUSIC[θ, x,N]:
JMUSIC[θ, x,N] = aH(θ)x,Na(θ),
(16.67)
of the so-called spatial null spectrum (or equivalently as the P highest peaks (maxima) of its inverse).
This algorithm has given a plethora of variants. For example, in the particular case of the ULA, this
standard MUSIC algorithm have been favorably replaced by the root MUSIC algorithm. Using the
general methodology presented in Section 3.16.3.1.2, the asymptotic distribution of ˆθ N given by any
subspace-based algorithms alg is simply derived from the expression of the C-differential matrix Dalg
x,θ
of the mapping x,N
alg
−→ˆθ N evaluated at x(θ). For example, for the standard MUSIC algorithm,
DMUSIC
x,θ
is straightforwardly obtained from the ﬁrst-order expansion of
 ∂JMUSIC(θ,x,N )
∂θ

θ=θp+δθp,N
= 0
that gives for one parameter per source
DMUSIC
x,θ
=
⎡
⎢⎣
dT
1...
dT
P
⎤
⎥⎦with dT
p = −1
h p

a′T (θp) ⊗aH(θp)

+

aT (θp) ⊗a′H(θp)

, p = 1, .., P,
(16.68)
with a′(θp) def
= da(θp)
dθp
and h p
def
= 2a′H(θp)xa′(θp). Using (16.68) with (16.16) and (16.23) allow one to
directly prove that the sequences
√
N(ˆθ N −θ) converges in distribution to the zero-mean Gaussian distri-
bution of covariance matrix given elementwise by

RMUSIC
θ

k,l =
2
hkhl Re((aH(θl)Ua(θk))(a′H(θk)x
a′(θl))) and compactly by
RMUSIC
θ
= 2

H ⊙I
−1 Re

H ⊙(AHUA)T  
H ⊙I
−1 ,
(16.69)
8Note that since x + ⊥
x = I and x,N + ⊥
x,N = I, all algorithm based on the orthogonal signal projector comes down
to an algorithm based on the orthogonal noise projector.

746
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
where (H)p,p
def
= h p and U has been deﬁned in Section 3.16.3.1.2. Note that these expressions have
been derived in [3] by much more involved derivations based on the asymptotic distribution of the
eigenvectors of the sample covariance matrix Rx,N. Finally, note that if the sample orthogonal noise
projector x,N is replaced by an adaptive estimator x,γ of x, where γ is the step-size of an arbitrary
constant step-size recursive stochastic algorithm (see e.g., [72,73]), it has been proved in [72] that
√γ (ˆθγ −θ) converges in distribution to the zero-mean Gaussian distribution of covariance matrix
given also by RMUSIC
θ
, where ˆθγ is an adaptive estimate of θ given by the MUSIC algorithm based
on the speciﬁc adaptive estimate x,γ of x studied in [72]. Using a similar approach [26], it has
been proved that the Root MUSIC algorithm associated with the ULA, presents the same asymptotic
distribution, but slightly outperforms the standard MUSIC algorithm outside the asymptotic regime.
This analysis has been extended to MUSIC-like algorithms applied to the orthogonal noise projectors
′
x,N [resp. ˜x,N] associated with the complementary sample covariance Cx,N [the augmented sample
covariance R˜x,N] matrices for the DOA estimation of arbitrary noncircular [resp. rectilinear] sources
[27]. Finally, note that with our general methodology, all the expressions of the covariance RMUSIC
θ
can
be straightforward extended for several parameter per source.
The expression of the covariance (16.69) of the asymptotic distribution of ˆθ N given the standard
MUSIC algorithm has been analyzed in detail (see, e.g., [2,3]). In particular it has been proved that the
MUSIC algorithm is asymptotically efﬁcient for a single source, an arbitrary number of parameters per
source and ∥a(θ1)∥depending on θ1, e.g., for one parameter per source
1
N RMUSIC
θ1
= CRBCG(θ1) = 1
N

1
h1

σ 2
n
σ 2
1
+
1
∥a(θ1)∥2
σ 4
n
σ 4
1

.
For several sources, the MUSIC algorithm is in general asymptotically inefﬁcient, in particular for
correlated sources for which the efﬁciency degrades when the correlation between the sources increases.
The degradation of performances are considerable for highly correlated sources for any value of the
SNRs. In contrast, for uncorrelated sources, the MUSIC algorithm is asymptotically efﬁcient when
σ 2
n tends to zero, in the following sense limσ 2n →0
	 1
N RMUSIC
θ

[CRBCG(θ)]−1 = I. So, in practice,
for uncorrelated sources, the MUSIC algorithm is asymptotically efﬁcient for high SNRs of all the
sources.
It is of utmost importance to investigate in what region of N and SNR, the asymptotic theoretical
results can predict actual performance. But unfortunately, only Monte Carlo simulations can specify
this region. We illustrate in the following the SNR threshold region for the SML, DML, and MUSIC
algorithm.
Consider two zero-mean circular Gaussian sources impinging on an ULA (16.2) with M = 6 (for
whichthe3 dBbandwidthisabout8◦)andaspatiallyuniformwhitenoise(16.3).Thesources1(t)consist
of a strong direct path at θ1 = 0◦relative to array broadside and a weaker (multipath at θ2 = 4◦at −3 dB
w.r.t. s1(t). The correlation between s1(t) and s2(t) is 0.99 giving thus the source covariance matrix
Rs =
 1 0.7
0.7 0.5

. Figure 16.3 shows the root mean square error (RMSE) of the estimated DOA ˆθ1 by the
MUSIC algorithm w.r.t. the SNR deﬁned by σ 2
1 /σ 2
n , compared with the theoretical standard deviation
(TSD)
*
1
N (RMUSIC
θ
)1,1 and the square root of the stochastic CRB √CRBCG(θ1). We see from this ﬁgure

3.16.4 Asymptotic Distribution of Estimated DOA
747
100
10-1
25
30
35
40
RMSEMUSIC (  1)
STDMUSIC (  1)
CRBCG (  1)
STD
θ
θ
θ
SNR (dB)
FIGURE 16.3
RMSE of ˆθ1 estimated by the MUSIC algorithm (averaged on 1000 runs) compared with the theoretical
standard deviation and the square root of the stochastic CRB, as a function of the SNR for N = 1000.
that the MUSIC algorithm is not efﬁcient at all for highly correlated sources. Furthermore, the domain
of validity of the asymptotic regime is here very limited, i.e., for N = 1000, SNR > 30 dB is required.
With the same parameters, Figure 16.4 shows the RMSE of the estimated DOA ˆθ1 by the SML and
DML algorithms which are compared with the TSD
*
1
N (RSML
θ
)1,1 and
*
1
N (RDML
θ
)1,1 and the square
roots of the CRBs √CRBCG(θ1) and √CRBDET(θ1). We see from this ﬁgure that the numerical values
of the four expressions of (16.57) are very close and the performance of the two ML algorithms are very
similar except for the SNR threshold region for which the SML algorithm is efﬁcient for SNR > 0 dB
with N = 1000. Finally, comparing Figures 16.3 and 16.4, we see that both ML algorithms largely
outperform the MUSIC algorithm for highly correlated sources.
3.16.4.5 Robustness of algorithms
We distinguish in this subsection, the robustness of the DOA estimation algorithms w.r.t. the narrowband
assumption and to array modeling errors, because for the array modeling errors, the model (16.1) remains
valid with a modiﬁed steering matrix, in contrast to the violation of narrowband assumption, for which
(16.1) must be modiﬁed.
3.16.4.5.1
Robustness w.r.t. the narrowband assumption
As the wideband assumption generally requires an increased computational complexity compared to the
narrowbandones,itisofinteresttoexamineifthenarrowbandmethodscanbeusedforasufﬁcientlywide
bandwidth without sacriﬁcing performance. Some responses to this question have been given in [74]
for symmetric spectra w.r.t. the demodulation frequency and in [75] for non-symmetric spectra and/or
offset of the centered value of the spectra w.r.t. the demodulation frequency f0. In these assumptions,

748
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
RMSEDML (  1)
RMSESML (  1)
TSDCG (  1)
TSDDet (  1)
θ
θ
θ
θ
SNR(dB)
STD
100
10
10
12
14
16
18
20
22
24
26
28
30
-1
FIGURE 16.4
RMSE of ˆθ1 estimated by the SML and DML algorithms (averaged on 1000 runs) compared with the theo-
retical standard deviations and the square root of the stochastic and deterministic CRBs, as a function of
the SNR for N = 1000.
the model (16.1) of the complex envelope of the measurements becomes
x(t) =
P

p=1
+ +B/2
−B/2
a(θp, f0 + f )ei2π f t dμp( f ) + n(t),
(16.70)
where a(θp, ν) def
= [ei2πντ1,p, . . . , ei2πντM,p]T (with a(θp, f0) = a(θp)) and μp( f ) is the spectral mea-
sure of the pth source. Using the general methodology explained in Section 3.16.3.1, based on a
ﬁrst-order expansion of the DOA estimate ˆθ N = alg(x,N) in the neighborhood of x (where x,N
and x are the orthogonal projectors onto the noise subspace associated with the covariance of (16.70)
and (16.1), respectively), general closed-form expressions of the asymptotic (w.r.t. the number of snap-
shots and source bandwidth) for arbitrary subspace-based algorithm have been derived in [75]. It is found
that the behavior of these DOA estimators strongly depends on the symmetry of the source spectra w.r.t.
their centered value and on the offset of this centered value w.r.t. f0. It is showed that the narrowband
SOS-based algorithms are much more sensitive to the frequency offset than to the bandwidth.
In particular for source spectra Ss( f ) symmetric w.r.t. the demodulation frequency f0, it is proved
that the estimated DOAs given by any narrowband subpace-based algorithm are asymptotically unbiased
w.r.t. the number of snapshots and signal bandwidth. More precisely
E(ˆθ N) −θ =

f 2
σ
f 2
0

balg + O

f 4
σ
f 4
0

+ O
 1
N

,

3.16.4 Asymptotic Distribution of Estimated DOA
749
where fσ
def
=
( B
−B Ss( f ) f 2d f /
( B
−B Ss( f )d f
1/2
is the deﬁnition used for the bandwidth. Furthermore,
for a single source, Rx = Rs1 ⊙a(θ1)aH(θ1) + σ 2
n I, where the nuisance parameters are now the terms
of the Hermitian matrix Rs1 and σ 2
n . This new parameterization allows to derive the circular Gaussian
stochastic CRB issued from a non-zero bandwidth CRBNZB
CG (θ1). It is related to the standard CRBCG(θ1)
by the relation
CRBNZB
CG (θ1) = CRBCG(θ1)

1 + c

f 2
σ
f 2
0

+ O

f 4
σ
f 4
0

,
where the expression of c is given in [75].
3.16.4.5.2
Robustness to array modeling errors
Imprecise knowledge of the gain and phase characteristics of the array sensors, and of the sensor
locations and possible mutual coupling, can seriously degrade the theoretical performance of the DOA
estimation algorithms. Experimental systems attempt to eliminate or minimize these errors by careful
calibrations. But even when initial calibration is possible, system parameters may change over time and
thus the array modeling errors cannot be completely eliminated. Consequently, it is useful to qualify
the sensitivity of the DOA estimator algorithms to these modeling errors, i.e., to study the effect of
difference between the true and assumed array manifold {a(θ), θ ∈} caused by modeling errors, on
DOA estimator algorithms. This analysis has received relatively little attention in the literature.
In these studies, to simplify the analysis, the covariance matrix Rx is assumed perfectly known,
i.e., the effects of a ﬁnite number of samples is assumed negligible. Let γ gather the array parameters
which are the subject of the sensitivity analysis. For example, γ may contain the sensors gain, phases
or location, or other parameters such as the mutual coupling coefﬁcients of the array sensors. A DOA
estimation algorithm uses the steering matrix A(θ, γ 0) = [a(θ1, γ 0), . . . , a(θP, γ 0)], corresponding
to a nominal value γ 0 of the array parameters that differs from the true steering matrix A(θ, γ ), where
γ is slightly different from γ 0 (see particular parameterizations studied in [76,77]). We refer to the
difference between the true and assumed array parameters as a modeling error. The sensitivity study
of a particular DOA estimation algorithm consists to provide a relation between δθ = θγ −θ and the
modeling error δγ = γ −γ 0 in the mapping
Rx(γ ) = A(θ, γ )RsAH(θ, γ ) + σ 2
n I
alg(γ 0)
−→θγ ,
(16.71)
where naturally Rx(γ 0)
alg(γ 0)
−→θ, if alg(γ 0) denotes an arbitrary second-order algorithm based on the
nominal array. Using a ﬁrst order perturbation of (16.71) in the neighborhood of γ 0, through those of the
orthogonal projector on the noise subspace x(γ ), a relation δθ = h(δγ )+o(δγ ) where h is linear has
been given for the MUSIC and DML algorithms in [77–79], respectively. These works model the errors
δγ by zero-mean independent random variables (δγ = σγ u where u is a random vector whose elements
are zero-mean unit variance random variables). They lead to estimates that are approximatively unbiased
(i.e., E(θγ ) −θ = o(σγ )) and where their approximative variances depend only on the second-order
statistics of the modeling errors (more precisely Var(θp,γ ) = cpσ 2
γ + o(σ 2
γ ), p = 1, . . . , P). However,
by confronting these theoretical results with numerical experiments, one notices that the MUSIC and
DML algorithms are biased in the presence of multiple sources and these theoretic and experimental

750
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
variances do not agree with larger modeling errors. More precisely, these theoretical results are valid
only up to the point where the probability of resolution is close to one (see [25]).
To take into account these larger modeling errors, a more accurate relation between δθ and δγ , based
on a second-order expansion of x(γ ) around γ 0 (provided by a recursive nth order expansion of δx
w.r.t. δRx [6]) as been given in [25,80] for analyzing the sensitivity of the MUSIC and DML algorithms
to larger modeling errors. Modeling the errors δγ as previously, an approximation of the bias E(θγ )−θ
that depends on the second-order statistics of the modeling errors, and of the variance that now depends
on the fourth-order statistics of the modeling errors, are given. These reﬁned closed-form expressions
can predict the actual performance observed by numerical experiments for larger modeling errors, in
particular in the threshold regions of the MUSIC and DML algorithms.
Note that the sensitivity of DOA estimators to modeling errors of the noise covariance matrix, that
includes the presence of undetected weak signals, has also been studied in the literature (see, e.g.,
[81]). Finally, note that the combined effects of random array modeling errors and ﬁnite samples have
been analyzed for the class of so-called signal subspace ﬁtting (SSF) algorithms in [82]. In addition to
deriving the ﬁrst-order asymptotic expressions for the covariance of the estimation error, an additional
weighting matrix has been introduced in (16.61) that has been optimized for any particular random
array modeling errors.
3.16.4.6 High-order algorithms
When the sources are non Gaussian distributed, they convey valuable statistical information in their
moments of order greater than two (this is in particular true when considering communications
signals). In these circumstances, it makes sense to consider DOA estimation techniques using this
higher order information. Of particular interest are the algorithms based on higher order cumulants of
the measurements {x(t)}t1,...,tN due to their additivity property in the sums of independent components.
Furthermore, these cumulants show the distinctive property of being in a certain sense, insensitive to
additive Gaussian noise, making it possible to devise consistent DOA estimates without it being nec-
essary to know, to model or to estimate the noise covariance Rn. As generally, the distributions of the
sources are even, their odd order moments are zero and thus to cope with these signals, only the even
high-order cumulants of the measurements are used.
Computational considerations dictate using mainly fourth-order cumulants. To use these approaches,
we consider the assumptions of Section 3.16.2.2, in which we add that the sources {sp(t)}p=1,...,P have
nonvanishing fourth-order cumulants. Furthermore, we assume that their moments are ﬁnite up to the
eighth-order, to study the statistical performance of these algorithms.
Of course, there are many more quadruples than pairs of indices, and consequently a very large num-
ber of cumulants Cum(xi(t), x∗
j (t), x∗
k (t), xl(t)), i, j, k,l = 1, . . . , M for circular sources (and more,
Cum(xi(t), x∗
j (t), xk(t), xl(t)) and Cum(xi(t), x j(t), xk(t), xl(t)), i, j, k,l = 1, . . . , M for noncircu-
lar sources) can be exploited despite their redundancies, to identify the DOA parameters with unknown
noise covariance. For example, for circular signals, the maximum set of nonredundant cumulants is
Cum

xi(t), x∗
j (t), x∗
k (t), xl(t)

with 1 ≤i ≤M, 1 ≤l ≤i, 1 ≤j ≤i
and 1 ≤k ≤j.
The asymptotically minimum variance (AMV) algorithm (see Section 3.16.3.3) based on a subset of
fourth-order cumulants that can identify the DOA parameters, is the nonlinear least square algorithm

3.16.4 Asymptotic Distribution of Estimated DOA
751
(16.40) in which gN gathers the involved cumulants. To implement this AMV algorithm, one has to
decide which cumulants should be included in gN. The best estimate would be obtained when all
nonredundant cumulants are selected. This, however, may require excessive computations if M is large.
However it is sufﬁcient to deal with a reduced set of cumulants, although there do not seem to be any
simple guidelines in this matter [60]. In practice, a good tradeoff between computational complexity
and accuracy is to devise suboptimal algorithms that require an overall computational effort similar
to the second-order algorithms, while retaining a fourth-order cumulants subset, sufﬁcient for DOA
indentiﬁcation. Such algorithms have been proposed in the literature such as the diagonal slice (DS), the
contracted quadricovariance (CQ) and the so called 4-MUSIC [60] algorithms. The ﬁrst two algorithms
are fourth-order subspace-based algorithms built on the following rank defective M × M matrices:

QDS
x

i, j = Cum

xi(t), x∗
j (t), x∗
j (t), x j(t)

,

QCQ
x

i, j =
M

m=1
Cum

xi(t), x∗
j (t), x∗
m(t), xm(t)

.
They require P < M sources and their statistical performance has been analyzed in [19] with the general
framework explained in Section 3.16.3.1. In particular, it is has been proved that for a single source and a
ULA in spatially uniform white noise, these two fourth-order algorithms have similar performance to the
MUSIC algorithm, except for low SNR, for which the MUSIC algorithm outperforms both fourth-order
algorithms. The 4-MUSIC algorithm is built from the rank defective M2 × M2 matrix

Q4-MUSIC
x

i+( j−1)M,k+(l−1)M = Cum

xi(t), x∗
j (t), x∗
k (t), xl(t)

.
It is proved in [60] that
Q4-MUSIC
x
= [A∗(θ) ⊗A(θ)]Qs[A∗(θ) ⊗A(θ)]H,
where (Qs)i+( j−1)P,k+(l−1)P = Cum(si(t), s∗
j (t), s∗
k (t), sl(t)), i, j, k,l = 1, . . . , P. Q4-MUSIC
x
is
indeﬁnite in general and its rank is G
g=1 r2
g where the P sources are divided in G groups, with rg
in the gth group. The sources in each group are assumed to be dependent, while sources belonging to
different groups are assumed independent. Because the vectors a∗(θp) ⊗a(θp), p = 1, . . . , P are P
columns of A∗(θ) ⊗A(θ), the 4-MUSIC algorithm is obtained by searching the P deepest minima of
the following localization function J4-MUSIC[θ, x,N]:
J4-MUSIC[θ, x,N] = [a∗(θ) ⊗a(θ)]Hx,N[a∗(θ) ⊗a(θ)],
(16.72)
where x,N is now, the orthogonal projector onto the noise subspace of the sample estimate Q4-MUSIC
x,N
of Q4-MUSIC
x
. In practice the statistical dependence of the sources are unknown. Porat and Fiedlander
[60] has proposed to retain only M2 −P2, rather M2 −G
g=1 r2
g eigenvectors corresponding to the
smallest singular values of Q4-MUSIC
x,N
. We note that, to the best of our knowledge, no complete statistical
performance analysis of this algorithm has yet appeared in the literature. Despite its higher variance
(w.r.t. the MUSIC algorithm under the assumption of spatially uniform white noise), this fourth-order

752
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
algorithm presents some advantages, aside from its capacity to deal with unknown Gaussian noise ﬁelds.
Using the concept of virtual array, it is proved in [83] that this algorithm can identify up to M2 −M
sources when the sensors are identical and up to M2 −1 sources for different sensors. Furthermore, it
is shown that its resolution for closely spaced sources and robustness to modeling errors is improved
with respect to the MUSIC algorithm. To increase even more its number of sources to be processed,
resolution and robustness to modeling errors, extensions of this 4-MUSIC algorithms, giving rise to the
2q-MUSIC (with q > 2) has been proposed [84].
3.16.5 Detection of number of sources
One of the more difﬁcult and critical problems facing passive sensor arrays systems is the detection of
the number P of sources impinging on the array. This is a key step in most of the parametric estimation
techniques that were brieﬂy described in Section 3.16.4. The eigendecomposition based techniques
require in addition, information on the dimension r of the signal subspace. If the source covariance Rs
has full rank, i.e., there are no coherent sources present, P and r are identical. Moreover, the solution of
the detection problem has, in many cases, value of its own, regardless of the DOA estimation problem.
A natural scheme for detecting the number P of sources is to formulate a likelihood ratio test based
on the SML estimator (16.49). Such a test is often referred to as a generalized likelihood ratio test
(GLRT). This test can be implemented by a sequential test procedure (see, e.g., [12, Sec. 4.7.1]). For
each hypothesis, the likelihood ratio statistic is computed and compared to a threshold. The accepted
hypothesis is the ﬁrst one for which the threshold is crossed. The problem with this method is the
subjective judgment required for deciding on the threshold levels or the associated probabilities of false
alarm related by the asymptotic distribution of the normalized likelihood ratio.
Another important approach to the detection problem is the application of the information theoretic
criteria for model selection. Unlike the conventional hypothesis testing based approaches, these criteria
do not require any subjective threshold setting. Among them, the minimum description length (MDL)
criterion introduced by Rissanen [85] is the most widely used because of its consistency. This technique
has been used for detecting the signal subspace dimension r [13], and also for detecting the number of
sources P [86]. We concentrate now on the detection of r.
3.16.5.1 MDL criterion
The information theoretic criteria approach is a general method for detecting the order r of a statistical
model. That is, given a parameterized probability density function p(x; α(r)) for various order r, detect
ˆr such that ˆr = arg minr{−ln[p(x; ˆα(r)
ML)] + g(r)}, where ˆα(r)
ML is the ML estimate of α(r) and g(r) is a
penalty function. For the MDL criterion which is based on a particular penalty function, ˆr is given for
N independent identically distributed measurements x(tn), by
ˆr = arg min
r

−ln

p

x; ˆα(r)
ML

+ 1
2card(α(r)) ln (N)

,
(16.73)

3.16.5 Detection of Number of Sources
753
where card(α(r)) denotes the number of free real-valued parameters in α(r). Depending on the distribu-
tion of the measurements x and its parametrization α, different implementations of the MDL criterion
have been proposed.
The most often used assumption, is the zero-mean circular Gaussian distribution associated with the
parametrization (16.1) in which all the elements of the steering matrix A are assumed unknown with
the only restriction that A has full column rank with M > P. For this modeling, the measurements can
be parameterized by the parameter
α(r) =

vT
1 , . . . , vT
r , λ1, . . . , λr, σ 2
n
T
,
where λ1 ≥· · · ≥λr > σ 2
n = . . . , σ 2
n are the eigenvalues of Rx and v1,…,vr, the eigenvectors
associated with the largest r eigenvalues, and the general MDL criterion (16.73), which is referred to
as the Gaussian MDL (GMDL), becomes [13]
ˆr = Arg min
r
r
with r
def
= N(M −r) ln
 ˆar
ˆgr

+ 1
2r(2M −r) ln N,
(16.74)
with ˆar
def
=
1
M−r
M
i=r+1 ˆλi and ˆgr
def
= ,M
i=r+1 ˆλ1/(M−r)
i
, where ˆλ1 > ˆλ2 > · · · > ˆλM are the eigenvalues
of the sample covariance matrix 1
N
N
n=1 x(tn)xH(tn), denoted here by )Rx.
3.16.5.2 Performance analysis of MDL criterion
This GMDL criterion has been analyzed in [16], and it has been shown to be a consistent estimator of
the rank r, i.e., the probability of error decreases to zero as the number N of measurements increases
to inﬁnity. Moreover, under mild regularity conditions, like ﬁnite second moments, it is a consistent
estimator of the rank r, even if the measurements are non-Gaussian. This property contrasts with the
Akaike information criterion (AIC) that yields an inconsistent estimate of that tends, asymptotically, to
overestimate r [13].
The GMDL criterion has been further analyzed by considering the events ˆr < r and ˆr > r, called
underestimation and overestimation, respectively. Since (r)r=0,...,M−1 are functions of the eigenvalues
(ˆλi)i=1,...,M of )Rx, the derivation of the probabilities P(ˆr > r) and P(ˆr < r) needs the joint exact
or asymptotic distribution of (ˆλi)i=1,...,M. This asymptotic distribution is available for circular com-
plex Gaussian distribution [87] and more generally for arbitrary distributions with ﬁnite fourth-order
moments [14], but unfortunately, the functional (r)r=0,...,M−1 (16.74) is too complicated to infer its
asymptotically distribution. Therefore, for simplifying the derivation of these probabilities, it has been
argued [36,88,89] by extended Monte Carlo experiments (essentially for r = 1 and r = 2) that
P(ˆr > r) ≈P(ˆr = r + 1) ≈P(r+1 < r) and
P(ˆr < r) ≈P(ˆr = r −1) ≈P(r−1 < r).
(16.75)
As the probability of overestimation is concerned, exact and approximate asymptotic upper bound of
this probability have been derived in [36] showing that generally P(ˆr > r) ≪1. Therefore, only the

754
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
probability of underestimation has been analyzed by many authors. In particular, using the reﬁnement
introduced by [90]
E(ˆar) =
1
M −r

Tr(Rx) −
r

i=1
E(ˆλi)

= σ 2
n +
1
M −r
r

i=1

λi −E(ˆλi)

of the classical approximation E(ˆar) ≈σ 2
n and the asymptotic bias (16.18) and covariance (16.19),
a closed-form expression of the probability of underestimation given by the GMDL criterion, used
under arbitrary distributions with ﬁnite fourth-order moments, has been given in [14]. This expression
has been analyzed for P = r = 1 and P = r = 2 for different distributions of the sources in [14].
Figure 16.5 illustrates the robustness of the MDL criterion to the distribution of the sources. We see
from this ﬁgure that the probability of underestimation is sensitive to the distribution of the source,
particularly for sources of large kurtosis and for weak values of the number N of snapshots.
The general MDL criterion has been studied in [15], where using the approximation (16.75), a
general analytical expression of P(ˆr < r) has been given. This expression allows one to prove the
consistency of the general MDL criterion when the number of snapshots tends to inﬁnite and has been
specialized to particular parameterized distributions. Among them, the Gaussian assumption associated
with a parameterized steering matrix A(θ) has been studied and some numerical illustrations show that
the use of this prior information about the array geometry enables an improvement in performance of
about 2 dB. Finally, note that the MDL criterion generally fails when the sample size is smaller than
the number of sensors. In this situation a sample eigenvalue based detector has been proposed in [91].
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.1
−16
−14
−12
SNR (dB)
N=1000
N=200
circ.Gauss. (th)
circ.Gauss. (est)
BPSK  (th)
BPSK  (est)
Impulse p=10 (th)
Impulse p=10 (est)
Impulse p=20 (th)
Impulse p=20 (est)
Probability  of underestimation
−10
−8
−6
−4
−2
0.2
FIGURE 16.5
P(ˆr = 0/r = 1) as a function of the SNR for four distributions of the source (the impulsive takes the values
{−1,0, + 1} with P(s(tn) = −1) = P(s(tn) = +1) =
1
2p and two values of the number N of snapshots, for
an ULA with ﬁve sensors.

3.16.6 Resolution of Two Closely Spaced Sources
755
3.16.6 Resolution of two closely spaced sources
An important measure to quantify the statistical performance for the DOA estimation problem is the
resolvability of closely spaced signals in terms of their parameters of interest. The principal question
to characterize this resolvability is to ﬁnd the minimum SNR (denoted threshold array SNR (ASNR))
required for a sensor array to correctly resolve two closely spaced signals for a given DOA distance
θ def
= |θ2 −θ1| (called angular resolution limit (ARL) or statistical resolution limit) between them.
Generally in the literature they are three different ways to describe this resolution limit. The ﬁrst one
is based on the mean null spectrum concerning a speciﬁc algorithm. The second one is based on the
estimation accuracy, more precisely on the Cramer-Rao Bound. The last one is based on the detection
theory using the hypothesis test formulation.
3.16.6.1 Angular resolution limit based on mean null spectra
Based on the array beam-pattern G(θ0, θ) = |aH(θ0)a(θ)|, different resolution criteria have been
deﬁned from its main lobe w.r.t. a look direction θ0, as the celebrated Rayleigh resolutions such as the
half power beamwidth or the null to null beamwidth that depends solely on the antenna geometry, and
consequently have the serious shortcoming of being independent of the SNR.
For speciﬁc so-called high resolution algorithms, such as different MUSIC-like algorithms, based
on the search for two local minima of sample null spectra JAlg(θ, x,N), two main criteria based on
the mean null spectrum E[JAlg(θ, x,N)] have been deﬁned. These criteria are justiﬁed by the property
that the standard deviation -Var(JAlg(θ, x,N)) of the sample null spectrum associated with the con-
ventional MUSIC and Min-Norm algorithms is small compared to its mean value E[JAlg(θ, x,N)] in
the vicinity of the true DOAs for N ≫M for arbitrary SNR [1].
For the ﬁrst criterion, introduced by Cox [92], two sources are resolved if the midpoint mean null
spectrum is greater than the mean null spectrum in the two true source DOAs:
E[JAlg(θm, x,N)] ≥1
2

E[JAlg(θ1, x,N)] + E[JAlg(θ2, x,N)]

with θm
def
= 1
2(θ1 + θ2).
This criterion was ﬁrst studied by Kaveh and Barabell [1] and Kaveh and Wang [93] in the resolution
analysis of the conventional MUSIC and Min-Norm algorithms for two uncorrelated equal-powered
sources and a ULA. This analysis has been extended to more general classes of situations, e.g., for two
correlated or coherent equal-powered sources with the smoothed MUSIC algorithm [94], then for two
unequal-powered sources impinging on an arbitrary array with the conventional and beamspace MUSIC
algorithm [95]. A subsequent paper by Zhou et al. [96] developed a resolution measure based on the
mean null spectrum and compared their results to Kaveh and Barabell’s work.
For the second criterion, introduced by Sharman and Durrani [97] and then studied by Forster and
Villier [26] in the context of the conventional MUSIC and Min-Norm algorithms for two uncorrelated
equal-powered sources and a ULA, two sources are resolved if the second derivative of the mean null
spectrum at the midpoint is negative
d2E[JAlg(θ, x,N)]
dθ2
|θ=θm
≤0.

756
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
Resorting to an analysis based on perturbations of the noise projector x,N [6], instead of those of the
eigenvectors (e.g., [1,95]), these two criteria have been studied for arbitrary distributions of the sources,
for the conventional MUSIC algorithm. The following closed-form expressions of the approximation
of the threshold ASNR given by these two criteria have been obtained in [27]:
ASNR1 ≈2
N
αM
(θ)4
⎛
⎝1 +
.
1 + N(θ)2
2βM
⎞
⎠and
ASNR2 ≈1
N
αM
(θ)4
⎛
⎝1 +
.
1 + N(θ)2
βM
⎞
⎠,
(16.76)
where αM and βM are fractional expressions in M speciﬁed in [27] for ULAs. These expressions (16.76)
have been extended in [27] to a noncircular MUSIC algorithm adapted to rectilinear signals, introduced
and analyzed in [98], for which (16.76) becomes
ASNR1 ≈2
N αθ,φ
M

1 +
.
1 +
N
2βθ,φ
M

and
ASNR2 ≈1
N αθ,φ
M

1 +
.
1 +
N
βθ,φ
M

,
(16.77)
where φ def
= φ2 −φ1 is the second-order noncircularity phase separation (16.8) and where now αθ,φ
M
and βθ,φ
M
are expansions of 1/(θ)2 without constant term, whose coefﬁcients depend on M, φ
and the array conﬁguration. Closed-form expressions of αθ,φ
M
and βθ,φ
M
are given in [27] for weak
and large second-order noncircularity phase separations and ULAs, where it is proved that ASNR1 and
ASNR2 are decreasing functions of φ and thus are minimum for φ = π/2.
Figure 16.6 illustrates these two threshold ASNRs for two independent equal-powered BPSK mod-
ulated signals impinging on a ULA with M = 10 and T = 500. We clearly see in this ﬁgure that the
noncircular MUSIC algorithm outperforms the conventional MUSIC algorithm except for very weak
second-order noncircularity phase separations or which the ASNR thresholds of these two algorithms
are very similar. Furthermore, we note that the behaviors of the ASNR threshold given by the two
criteria are very similar although the ASNR thresholds are slightly weaker for the Sharman and Durrani
criterion than for the Cox criterion.
Moreover, several authors have considered (e.g., [99–101]) the probability of resolution or an approx-
imation of it, based on the Cox criterion applied to the null sample spectrum to circumvent the possible
misleading results given by these two criteria. Finally note that the resolution capability of the conven-
tional and Capon beamforming algorithms have been thoroughly analyzed (see, e.g., [102]). Thanks to
the simple expression of their spatial null spectra (16.46), it is possible to derive an approximation of
the probability of resolution deﬁned as the probability that the dip in midway between the two sources
is at least 3-dB less than the peak of either source as a function of the SNR and DOA separation.
Thus, ﬁxing a speciﬁc high conﬁdence level, this allows one to predict the SNR required to resolve
two closely spaced sources. The superiority of the Capon algorithm is proved in [102], as the resolving

3.16.6 Resolution of Two Closely Spaced Sources
757
10
−4
10
−3
10
−2
10
−1
10
−4
10
−3
10
−2
10
−1
20
40
60
80
100
120
140
160
20
40
60
80
100
120
140
160
DOA separation Δθ (rd)
DOA separation Δθ (rd)
threshold ASNR (dB)
threshold ASNR (dB)
Δφ =0
Δφ =π/6
Δφ =π/2
Δφ =0
Δφ=π/6
Δφ=π/2
(a)
(b)
FIGURE 16.6
Comparison of the threshold ASNRs given by the Cox (a) and Sharman and Durrani (b) criteria as a function
of the DOA separation θ associated with the conventional MUSIC (—) and noncircular MUSIC algorithms
(- -) for three values of the second-order noncircularity phase separation φ.
power increases with SNR; in contrast, the Bartlett algorithm cannot exceed the Fourier/Rayleigh limit
no matter how strong the signals.
3.16.6.2 Angular resolution limit based on the CRB
Array resolution has been studied independently of any algorithm by using the CRB. Based on the
observation that the standard MUSIC algorithm is unlikely to resolve closely spaced signals if the stan-
dard deviation of the DOA estimates exceed θ/8 [3], Lee [103] has proposed to deﬁne the resolution
limit as the DOA separation θ for which
max
-
CRB(θ1),
-
CRB(θ2)

= cθ,
(16.78)
for the two closely spaced sources, where c is somewhat arbitrarily chosen. This criterion ignores the
coupling between the estimates ˆθ1 and ˆθ2. To overcome these drawbacks, Smith has proposed [18] to
deﬁne the resolution limit as the source separation that equals the square root of its own CRB, i.e.,
-
CRB(θ) = cθ,
(16.79)
withc = 1.9 ThismeansthattheangularresolutionlimitorthethresholdASNRareobtainedbyresolving
the implicit equations (16.78) and (16.79). This latter criterion has been applied to the deterministic
modeling of the sources in [18] and then extended to multiple parameters per source in [104]. For the
stochastic modeling of the sources, the circular Gaussian distribution has been compared to the discrete
9Note that this translation factor c is somewhat arbitrarily chosen (see different values cited in [17]).

758
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
one in [105]. In particular it has been proved that the threshold ASNR is inversely proportional to the
number N of snapshots and to the square of θ for the Gaussian case, in contrast to BPSK, MSK and
QPSK case, for which it is inversely proportional to the fourth power of θ.
3.16.6.3 Angular resolution limit based on the detection theory
The previous two approaches to characterize the angular resolution have in fact two different purposes.
The ﬁrst one studies the capability of a speciﬁc algorithm to estimate the DOAs of two closely spaced
sources when the number of sources is known. In contrast, the second one is aiming to deﬁne an absolute
limit on resolution that depends only of the array conﬁguration and parameters of interest as the number
M of sensors and SNR. But this latter approach based on the ad hoc relationships (16.78) and (16.79),
essentially makes sense because the CRB indicates the parameter estimation accuracy and intuitively
should be related to the resolution limit. But it suffers from two drawbacks. First, the resolution limit
deﬁned by this approach is not rigorously grounded in a statistical setting. Second, if the resolution
limit is expressible by (16.78) or (16.79), can the translation factor c, be analytically determined?
To solve these two problems, Liu and Nehorai have proposed to use a hypothesis test formulation
[17]. This approach has been introduced in a 3D reference frame, but to be consistent with the notations
of this section, it is brieﬂy summarized in the following in the 2D framework, where the DOA of a
source is the parameter θ. As the source localization accuracy may vary at different DOAs, consider the
resolution limit at a speciﬁc DOA of interest. More precisely, assume there exists a source at a known
DOA θ1 and we are interested in the minimum angular separation θ that the array can resolve between
this source at θ1 and another source at a direction θ2 close to θ1. Quite naturally, the resolution of the
two sources can be achieved through the binary composite hypothesis test
H0: θ = 0,
one source is present,
H1: θ > 0,
two sources are present.
To rigorously deﬁne the resolution limit θ, we ﬁx the values of PFA and PD for this test. Otherwise,
θ could be arbitrary low, while the result of the test may be meaningless. Let α = [θ, βT ]T be the
unknown parameter of our statistical model, where θ is the parameter of interest and β gathers all
the unknown nuisance parameters. To conduct this test, the GLRT is considered due to the unknown
nuisance parameters:
LG(x, N) = p(x; )θ, ˆβ1, H1)
p(x; ˆβ0, H0)
H1 > γ ′,
(16.80)
where p(x; θ, β, H1) and p(x; β, H0) denote the probability density function of the measurement
x = [xT (t1), . . . , xT (tN)]T under the hypothesis H1 and H0, respectively. ˆ
θ and ˆβ1 are respectively
the ML estimate of θ and β under H1, and ˆβ0 is the ML estimate of β under H0. The distribution of this
GLRT LG(x, N) is generally very involved to derive, but hopefully, approximations of the distribution
of 2 ln LG(x, N) for large values of N are available under H0 and H1. First, under H0, Wilk’s theorem
with nuisance parameters (see, e.g., [106, p. 132]) can be applied without having to know the exact form
of LG(x, N). This theorem states the following convergence in distribution when N tends to ∞:
2 ln LG(x, N) L
→χ2(1) under
H0,
(16.81)

3.16.6 Resolution of Two Closely Spaced Sources
759
where χ2(1) denotes the central chi-square distribution with one degree of freedom (associated with
the single parameter θ). Under H1, the derivation of the asymptotic distribution of 2 ln LG(x, N) is
much more involved. Using a theoretical result by Stroud [107], Stuart et al. [108, Chapter 14.7] have
stated that when θ can take values10 near 0, 2 ln LG(x, N) is approximately distributed11 as
2 ln LG(x, N)
a∼χ2(1, λN) under
H1,
(16.82)
where χ2(1, λN) denotes the noncentral chi-squared distribution with one degree of freedom and non-
centrality parameter λN given by (see [109, Section 6.5])
λN = (θ −0)([FIM−1(α)]1,1)−1(θ −0),
(16.83)
whose dependence on N in the FIM of α is emphasized, and where [FIM−1(α)]1,1 denotes the (1,1) th
entry of FIM−1(α). It is further shown [109, Appendix 6C] that as N is large, (16.83) is approximated
by
λN ≈(θ)2([FIM−1(α)]1,1|θ=0)−1 = CRB−1(θ)|θ=0.
(16.84)
Based on these limit and approximate distributions of 2 ln LG(x, N) under H0 and H1 for which the
GLRT in (16.81) can be rewritten as
2 ln LG(x, N)
H1
> γ def
= 2 ln γ ′,
(16.85)
the angular resolution limit (ARL) has been computed in [17] by using the two constraints
PFA = Qχ2(1)(γ ) and
PD = Qχ2(1,λN )(γ ),
where the values of PFA and PD are ﬁxed and where Qχ2(1) and Qχ2(1,λN ) denote the right tail probability
of the χ2(1) and χ2(1, λN) distributions, respectively. It assumes the form
θ =
-
λK
-
CRB(θ)|θ=0,
where the factor √λK is analytically determined by the preassigned values of PFA and PD. Note that the
SNR is embedded in the expression of CRB(θ) that is proportional to K. The dependence on the SNR
of the CRB may vary according to the distribution of the sources. For example, Delmas and Abeida
[105] proves that the CRB of the DOA separation of discrete sources is very different from those of
Gaussian sources.
10The following more formal condition is given in [107], θ is embedded in an adequate sequence indexed by N
that converges to zero at the rate N −1/2 or faster, i.e., ∥θ∥= O(1/N 1/2). Note the simpliﬁed condition given
by Kay [109, A. 6A]: ∥θ∥= c/
√
N for some constant c, that is reduced to the rough assumption of weak SNR
[109, Section 6.5].
11The accurate formulation is limN→∞
%
P

2 ln LG(x, N)] < t

−P(VN < t)
&
= 0 ∀t, where VN has a noncentral chi-
squared distribution with one degree of freedom and noncentrality parameter μN that depends on the data length N.

760
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
Relevant Theory: Statistical Signal Processing
See this Volume, Chapter 1 Introduction: Statistical Signal Processing
See this Volume, Chapter 2 Model Selection
See this Volume, Chapter 8 Performance Analysis and Bounds
References
[1] M. Kaveh, A.J. Barabell, The statistical performance of the MUSIC and the Minimum-Norm algorithms in
resolving plane waves in noise, IEEE Trans. ASSP 34 (2) (1986) 331–341.
[2] B. Porat, B. Friedlander, Analysis of the asymptotic relative efﬁciency of the MUSIC algorithm, IEEE Trans.
ASSP 36 (4) (1988) 532–544.
[3] P. Stoica, A. Nehorai, MUSIC, maximum likelihood, and Cramer-Rao bound, IEEE Trans. ASSP 37 (5)
(1989) 720–741.
[4] P.Stoica,A.Nehorai,MUSIC,maximumlikelihood,andCramer-Raobound:furtherresultsandcomparisons,
IEEE Trans. ASSP 38 (12) (1990) 2140–2150.
[5] W. Xu, K.M. Buckley, Bias analysis of the MUSIC location estimator, IEEE Trans. Signal Process. 40 (10)
(1992) 2559–2569.
[6] H. Krim, P. Forster, G. Proakis, Operator approach to performance analysis of root-MUSIC and root-min-
norm, IEEE Trans. Signal Process. 40 (7) (1992) 1687–1696.
[7] A. Gorokhov, Y. Abramovich, J.F. Böhme, Uniﬁed analysis of DOA estimation algorithms for covariance
matrix transforms, Signal Process. 55 (1996) 107–115.
[8] F. Li, R.J. Vaccaro, Uniﬁed analysis for DOA estimation algorithms in array signal processing, Signal Process.
25 (2) (1991) 147–169.
[9] F. Li, H. Liu, R.J. Vaccaro, Performance analysis for DOA estimation algorithms: uniﬁcation, simpliﬁcation,
and observations, IEEE Trans. Aerosp. Electron. Syst. 29 (4) (1993) 1170–1184.
[10] B. Ottersten, M. Viberg, T. Kailath, Analysis of subspace ﬁtting and ML techniques for parameter estimation
from sensor array data, IEEE Trans. Signal Process. 40 (3) (1992) 590–599.
[11] P. Stoica, A. Nehorai, Performance study of conditional and unconditional direction of arrival estimation,
IEEE Trans. ASSP 38 (10) (1990) 1783–1795.
[12] B. Ottersten, M. Viberg, P. Stoica, A. Nehorai, Exact and large sample maximum likelihood techniques for
parameter estimation and detection in array processing, in: S. Haykin, J. Litva, T.J. Shepherd (Eds.), Radar
Array Processing, Springer-Verlag, Berlin, 1993, pp. 99–151.
[13] M. Wax, T. Kailath, Detection of signals by information theoretic criteria, IEEE Trans. ASSP 33 (2) (1985)
387–392.
[14] J.P. Delmas, Y. Meurisse, On the second-order statistics of the EVD of sample covariance matrices—
application to the detection of noncircular or/and nonGaussian components, IEEE Trans. Signal Process. 59
(8) (2011) 4017–4023.
[15] E. Fishler, M. Grosmann, H. Messer, Detection of signals by information theoretic criteria: general asymptotic
performance analysis, IEEE Trans. Signal Process. 50 (5) (2002) 1027–1036.
[16] L.C. Zhao, P.R. Krishnaiah, Z.D. Bai, On detection of the number of signals in the presence of white noise,
J. Multivariate Anal. 20 (1) (1986) 1–20.
[17] Z. Liu, A. Nehorai, Statistical angular resolution limit for point sources, IEEE Trans. Signal Process. 55 (11)
(2007) 5521–5527.
[18] S.T. Smith, Statistical resolution limits and the complexiﬁed Cramer-Rao bound, IEEE Trans. Signal Process.
53 (5) (2005) 1597–1609.

References
761
[19] J.F. Cardoso, E. Moulines, Asymptotic performance analysis of direction-ﬁnding algorithms based on fourth-
order cumulants, IEEE Trans. Signal Process. 43 (1) (1995) 214–224.
[20] J.P. Delmas, Asymptotic performance of second-order algorithms, IEEE Trans. Signal Process. 50 (1) (2002)
49–57.
[21] P. Stoica, R. Moses, Introduction to Spectral Analysis, Prentice Hall, Inc., 1997.
[22] M. Wax, I. Ziskind, On unique localization of multiple sources by passive sensor arrays, IEEE Trans. ASSP
37 (7) (1989) 996–1000.
[23] A. Nehorai, D. Starer, P. Stoica, Direction of arrival estimation with multipath and few snapshots, Circ. Syst.
Signal Process. 10 (3) (1991) 327–342.
[24] J.P. Delmas, Asymptotically minimum variance second-order estimation for non-circular signals with appli-
cation to DOA estimation, IEEE Trans. Signal Process. 52 (5) (2004) 1235–1241.
[25] A. Ferreol, P. Larzabal, M. Viberg, On the resolution probability of MUSIC in presence of modeling errors,
IEEE Trans. Signal Process. 56 (5) (2008) 1945–1953.
[26] P. Forster, E. Villier, Simpliﬁed formulas for performance analysis of MUSIC and Min Norm, in: Proceedings
of Ocean Conference, September 1998.
[27] H. Abeida, J.P. Delmas, MUSIC-like estimation of direction of arrival for non-circular sources, IEEE Trans.
Signal Process. 54 (7) (2006) 2678–2690.
[28] A. Renaux, P. Forster, E. Boyer, P. Larzabal, Unconditional maximum likelihood performance at ﬁnite number
of samples and high signal to noise ratio, IEEE Trans. Signal Process. 55 (5) (2007) 2358–2364.
[29] P. Vallet, P. Loubaton, X. Mestre, Improved subspace estimation for multivariate observations of high dimen-
sion: the deterministic signal case, IEEE Trans. Inform. Theory 58 (2) (2012) 1002–3234.
[30] J.P. Delmas, H. Abeida, Asymptotic distribution of circularity coefﬁcients estimate of complex random
variables, Signal Process. 89 (2009) 2670–2675.
[31] J.P. Delmas, Y. Meurisse, Asymptotic performance analysis of DOA algorithms with temporally correlated
narrow-band signals, IEEE Trans. Signal Process. 48 (9) (2000) 2669–2674.
[32] T. Kato, Perturbation Theory for Linear Operators, Springer-Verlag, Berlin, 1995.
[33] R.J. Serﬂing, Approximation Theorems of Mathematical Statistics, John Wiley and Sons, 1980.
[34] P.J. Schreier, L.L. Scharf, Statistical Signal Processing of Complex-Valued Data—The Theory of Improper
and Noncircular Signals, Cambridge University Press, 2010.
[35] E.L. Lehmann, Elements of Large-Sample Theory, Springer-Verlag, New-York, 1999.
[36] W. Xu, M. Kaveh, Analysis of the performance and sensitivity of eigendecomposition-based detectors, IEEE
Trans. Signal Process. 43 (6) (1995) 1413–1426.
[37] P. Stoica, R.L. Moses, On biased estimators and the unbiased Cramer-Rao lower bound, Signal Process. 21
(1990) 349–350.
[38] D.T. Vu, A. Renaux, R. Boyer, S. Marcos, Closed-form expression of the Weiss-Weinstein bound for 3D
source localization: the conditional case, in: Proceedings of SAM, Jerusalem, Israel, October 2010.
[39] W.J. Bangs, Array processing with generalized beamformers, Ph.D. Thesis, Yale University, New Haven,
CT, 1971.
[40] D. Slepian, Estimation of signal parameters in the presence of noise, Trans. IRE Prof. Group Inform. Theory
PG IT-3, 1954, pp. 68–89.
[41] P. Stoica, A.G. Larsson, A.B. Gershman, The stochastic CRB for array processing: a textbook derivation,
IEEE Signal Process. Lett. 8 (5) (2001) 148–150.
[42] J.P. Delmas, H. Abeida, Stochastic Cramer-Rao bound for non-circular signals with application to DOA
estimation, IEEE Trans. Signal Process. 52 (11) (2004) 3192–3199.
[43] P. Stoica, B. Ottersten, M. Viberg, R.L. Moses, Maximum likelihood array processing for stochastic coherent
sources, IEEE Trans. Signal Process. 44 (1) (1996) 96–105.

762
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
[44] H. Abeida, J.P. Delmas, Efﬁciency of subspace-based DOA estimators, Signal Process. 87 (9) (2007) 2075–
2084.
[45] A.B. Gershman, P. Stoica, M. Pesavento, E.G. Larsson, Stochastic Cramer-Rao bound for direction estimation
in unknown noise ﬁelds, IEE Proc—Radar Sonar Navig. 149 (1) (2002) 2–8.
[46] M. Pesavento, A.B. Gershman, Maximum-likelihood direction of arrival estimation in the presence of
unknown nonuniform noise, IEEE Trans. Signal Process. 49 (7) (2001) 1310–1324.
[47] H. Ye, R.D. Degroat, Maximum likelihood DOA estimation and asymptotic Cramer-Rao bounds for additive
unknown colored noise, IEEE Trans. Signal Process. 43 (4) (1995) 938–949.
[48] H. Abeida, J.P. Delmas, Cramer-Rao bound for direction estimation of non-circular signals in unknown noise
ﬁelds, IEEE Trans. Signal Process. 53 (12) (2005) 4610–4618.
[49] M. Jansson, B. Göransson, B. Ottersten, Subspace method for direction of arrival estimation of uncorrelated
emitter signals, IEEE Trans. Signal Process. 47 (4) (1999) 945–956.
[50] M. Hawkes, A. Nehorai, Acoustic vector-sensor beamforming and Capon direction estimation, IEEE Trans.
Signal Process. 46 (9) (1998) 2291–2304.
[51] A. Nehorai, E. Paldi, Vector-sensor array processing for electromagnetic source localization, IEEE Trans.
Signal Process. 42 (2) (1994) 376–398.
[52] Y. Begriche, M. Thameri, K. Abed-Meraim, Exact Cramer-Rao bound for near ﬁeld source localization, in:
International Conference on ISSPA, Montreal, July 2012.
[53] M.N. El Korso, R. Boyer, A. Renaux, S. Marcos, Conditional and unconditional Cramer-Rao bounds for
near-ﬁeld source localization, IEEE Trans. Signal Process. 58 (5) (2010) 2901–2907.
[54] J.P. Delmas, H. Gazzah, Analysis of near-ﬁeld source localization using uniform circular arrays, in: Inter-
national Conference on Acoustics, Speech and Signal Processing (ICASSP 2013), Vancouver, Canada, May
2013.
[55] J.P. Delmas, H. Abeida, Cramer-Rao bounds of DOA estimates for BPSK and QPSK modulated signals,
IEEE Trans. Signal Process. 54 (1) (2006) 117–126.
[56] F. Bellili, S.B. Hassen, S. Affes, A. Stephenne, Cramer-Rao lower bounds of DOA estimates from square
QAM-modulated signals, IEEE Trans. Commun. 59 (6) (2011) 1675–1685.
[57] M. Lavielle, E. Moulines, J.F. Cardoso, A maximum likelihood solution to DOA estimation for discrete
sources, in: Proceedings of Seventh IEEE Workshop on SP, 1994, pp. 349–353.
[58] B. Porat, B. Friedlander, Performance analysis of parameter estimation algorithms based on high-order
moments, Int. J. Adapt. Control Signal Process. 3 (1989) 191–229.
[59] B. Friedlander, B. Porat, Asymptotically optimal estimation of MA and ARMA parameters of non-Gaussian
processes from high-order moments, IEEE Trans. Automat. Control 35 (1990) 27–35.
[60] B. Porat, B. Friedlander, Direction ﬁnding algorithms based on higher order statistics, IEEE Trans. Signal
Process. 39 (9) (1991) 2016–2024.
[61] H. Abeida, J.P. Delmas, Asymptotically minimum variance estimator in the singular case, in: Proceedings
of EUSIPCO, Antalya, September 2005.
[62] C. Vaidyanathan, K.M. Buckley, Performance analysis of the MVDR spatial spectrum estimator, IEEE
Trans. Signal Process. 43 (6) (1995) 1427–1437.
[63] H. Gazzah, J.P. Delmas, Spectral efﬁciency of beamforming-based parameter estimation in the single source
case, in: SSP 2011, Nice, June 2011.
[64] A.G. Jaffer, Maximum likelihood direction ﬁnding of stochastic sources: a separable solution, in: Proceedings
of ICASSP, New York, April 11–14 1988, pp. 2893–2896.
[65] P. Stoica, N. Nehorai, On the concentrated stochastic likelihood function in array processing, Circ. Syst.
Signal Process. 14 (1995) 669–674.
[66] M. Viberg, B. Ottersten, Sensor array signal processing based on subspace ﬁtting, IEEE Trans. ASSP
39 (5) (1991) 1110–1121.

References
763
[67] A. Renaux, P. Forster, E. Chaumette, P. Larzabal, On the high SNR conditional maximum likelihood
estimator full statistical characterization, IEEE Trans. Signal Process. 54 (12) (2006) 4840–4843.
[68] M. Viberg, B. Ottersten, A. Nehorai, Performance analysis of direction ﬁnding with large arrays and ﬁnite
data, IEEE Trans. Signal Process. 43 (2) (1995) 469–477.
[69] B.A. Johnson, Y.I. Abramovich, X. Mestre, MUSIC, G-MUSIC, and maximum-likelihood performance
breakdown, IEEE Trans. Signal Process. 56 (8) (2008) 3944–3958.
[70] J.F. Cardoso, E. Moulines, Invariance of subspace based estimator, IEEE Trans. Signal Process. 48 (9)
(2000) 2495–2505.
[71] J.F. Cardoso, E. Moulines, A robustness property of DOA estimators based on covariance, IEEE Trans.
Signal Process. 42 (11) (1994) 3285–3287.
[72] J.P. Delmas, J.F. Cardoso, Performance analysis of an adaptive algorithm for tracking dominant subspace,
IEEE Trans. Signal Process. 46 (11) (1998) 3045–3057.
[73] J.P. Delmas, J.F. Cardoso, Asymptotic distributions associated to Oja’s learning equation for Neural
Networks, IEEE Trans. Neural Networks 9 (6) (1998) 1246–1257.
[74] J. Sorelius, R.L. Moses, T. Söderström, A.L. Swindlehurst, Effects of nonzero bandwidth on direction of
arrival estimators in array processing, IEE Proc.—Radar Sonar Navig. 145 (6) (1998) 317–324.
[75] J.P. Delmas, Y. Meurisse, Robustness of narrowband DOA algorithms with respect to signal bandwidth,
Signal Process. 83 (3) (2003) 493–510.
[76] A. Ferreol, P. Larzabal, M. Viberg, On the asymptotic performance analysis of subspace DOA estimation in
the presence of modeling errors: case of MUSIC, IEEE Trans. Signal Process. 54 (3) (2006) 907–920.
[77] B. Friedlander, A sensitivity analysis of the MUSIC algorithm, IEEE Trans. ASSP 38 (10) (1990) 1740–1751.
[78] B. Friedlander, A sensitivity analysis of the maximum likelihood direction-ﬁnding algorithm, IEEE Trans.
Aerosp. Electron. Syst. 26 (11) (1990) 953–958.
[79] A.L. Swindlehurst, T. Kailath, A performance analysis of subspace-based methods in the presence of model
errors. Part I: The MUSIC algorithm, IEEE Trans. Signal Process. 40 (7) (1992) 1758–1773.
[80] A. Ferreol, P. Larzabal, M. Viberg, Performance prediction of maximum likelihood direction of arrival
estimation in the presence of modeling error, IEEE Trans. Signal Process. 56 (10) (2008) 4785–4793.
[81] M. Viberg, Sensitivity of parametric direction ﬁnding to colored noise ﬁelds and undermodeling, Signal
Process. 34 (2) (1993) 207–222.
[82] M. Viberg, A.L. Swindlehurst, Analysis of the combined effects of ﬁnite samples and model errors on array
processing performance, IEEE Trans. Signal Process. 42 (11) (1994) 3073–3083.
[83] P. Chevalier, A. Ferreol, On the virtual array concept for the fourth-order direction ﬁnding problem, IEEE
Trans. Signal Process. 47 (9) (1999) 2592–2595.
[84] P. Chevalier, A. Ferreol, L. Albera, High resolution direction ﬁnding from higher order statistics; the
2q-MUSIC algorithm, IEEE Trans. Signal Process. 54 (8) (2006) 2986–2997.
[85] J. Rissanen, Modeling by shortest data description, Automatica 14 (1978) 465–471.
[86] M. Wax, I. Ziskind, Detection of the number of coherent signals by the MDL principle, IEEE Trans. ASSP
37 (8) (1989) 1190–1196.
[87] T.W. Anderson, Asymptotic theory for principal component analysis, Ann. Math. Stat. 34 (1963) 122–148.
[88] M. Kaveh, H. Wang, H. Hung, On the theoretic performance of a class of estimators of the number of
narrow-band sources, IEEE Trans. ASSP 35 (9) (1987) 1350–1352.
[89] H. Wang, M. Kaveh, On the performance of signal subspace processing—Part I: Narrow-band systems,
IEEE Trans. ASSP 34 (5) (1986) 1201–1209.
[90] F.
Haddadi,
M.M.
Mohammadi,
M.M.
Nayebi,
M.R.
Aref,
Statistical
performance
analysis
of MDL source enumeration in array processing, IEEE Trans. Signal Process. 58 (1) (2010)
452–457.

764
CHAPTER 16 Performance Bounds and Statistical Analysis of DOA Estimation
[91] R.R.
Nadakuditi,
A.
Edelman,
Sample
eigenvalue
based
detection
of
high-dimensional
sig-
nals in white noise using relatively few samples, IEEE Trans. Signal Process. 56 (17) (2008)
2625–2638.
[92] H. Cox, Resolving power and sensitivity to mismatch of optimum array processors, J. Acoust. Soc. Am. 54
(3) (1973) 771–785.
[93] M. Kaveh, H. Wang, Threshold properties of narrowband signal subspace array processing methods, in:
S. Haykin (Ed.), Advances in Spectrum Analysis and Array Processing, vol. 2, Prentice-Hall, pp. 173–220.
[94] S.U. Pillai, G.H. Kwon, Performance analysis of MUSIC-type high resolution estimators for direction
ﬁnding in correlated and coherent scenes, IEEE Trans. ASSP 37 (8) (1989) 1176–1189.
[95] H.B. Lee, M.S. Wengrovitz, Resolution threshold of beamspace MUSIC for two closely spaced emitters,
IEEE Trans. ASSP 38 (9) (1990) 1445–1559.
[96] C. Zhou, F. Haber, D.L. Jaggard, A resolution measure for the MUSIC algorithm and its application to plane
wave arrivals contaminated by coherent interference, IEEE Trans. Signal Process. 39 (2) (1991) 454–463.
[97] K.C. Sharman, S.T. Durrani, Resolving power of signal subspace methods for ﬁnite data lengths, in:
Proceedings of ICASSP, Tampa, Florida, April 1985.
[98] H. Abeida, J.P. Delmas, Statistical performance of MUSIC-like algorithms in resolving noncircular sources,
IEEE Trans. Signal Process. 56 (9) (2008) 4317–4329.
[99] H.B. Lee, M.S. Wengrovitz, Statistical characterization of the MUSIC algorithm null spectrum, IEEE Trans.
Signal Process. 39 (6) (1991) 1333–1347.
[100] Q.T. Zhang, Probability of resolution of the MUSIC algorithm, IEEE Trans. Signal Process. 43 (4) (1995)
978–987.
[101] Q.T. Zhang, A statistical resolution theory of the beamformer-based spatial spectrum for determining the
directions of signals in white noise, IEEE Trans. ASSP 43 (8) (1995) 1867–1873.
[102] C.D. Richmond, Capon algorithm mean-squared error threshold SNR prediction and probability of
resolution, IEEE Trans. Signal Process. 53 (8) (2005) 2748–2764.
[103] H.B. Lee, The Cramer-Rao bound on frequency estimates of signals closely spaced in frequency, IEEE
Trans. Signal Process. 40 (6) (1992) 1508–1517.
[104] M.N. El Korso, R. Boyer, A. Renaux, S. Marcos, Statistical resolution limit for multiple parameters of
interest and for multiple signals, in: Proceedings of ICASSP, Dallas, May 2010.
[105] J.P. Delmas, H. Abeida, Statistical resolution limits of DOA for discrete sources, in: Proceedings of ICASSP,
Toulouse, May 2006.
[106] G.A. Young, R.L. Smith, Essentials of Statistical Inference, Cambridge Series in Statistical and Probabilistic
Mathematics, 2005.
[107] T.W.F. Stroud, Fixed alternatives and Wald’s formulation of the noncentral asymptotic behavior of the
likelihood ratio statistics, Ann. Math. Stat. 43 (2) (1972) 447–454.
[108] A. Stuart, J.K. Ord, Advanced Theory of Statistics, ﬁfth ed., vol. 2, Edward Arnold, 1991.
[109] S.M. Kay, Fundamentals of Statistical Signal Processing, Detection Theory, vol. II, Prentice-Hall, 1998.

17
CHAPTER
DOA Estimation of Nonstationary
Signals
Moeness G. Amin and Yimin D. Zhang
Center for Advanced Communications, Villanova University, Villanova, PA, USA
3.17.1 Introduction
For many decades, time-frequency (t-f) signal representations, such as the Wigner-Ville distribution
(WVD) and spectrograms, were only applied to analyze nonstationary signals incident on single-
sensor receivers. The objective is to characterize the data observations in the t-f domain, leading to
proper signal detection and characterization, separation, classiﬁcation, and cancelation. These offerings
were subsequently enhanced by introducing reduced interference quadratic time-frequency distribu-
tions (TFDs) which have led to improved multi-component signal power localizations in the t-f domain.
With sensor arrays being ubiquitous in many application areas of signal processing, such as commu-
nications, radar, acoustic, and biomedical, it has become important to consider TFDs in the context
of array processing. This is successfully achieved within the framework of spatial time-frequency
distribution (STFD) [1–6].
This chapter discusses the direction-of-arrival (DOA) estimation of far-ﬁeld sources producing non-
stationary signals, particularly those in the form of frequency modulated (FM) waveforms. We use
DOA estimation methods based on the quadratic (bilinear) STFD framework. Nonstationary signals
are encountered in various passive and active arrays using different sensing modalities. For example,
many modern radar systems use linear FM (LFM) signals to achieve pulse compression (LFM sig-
nals are also referred to as chirp signals). Alternatively, accelerating, rotating, or maneuvering targets
generate time-varying Doppler frequencies, with well deﬁned Doppler-frequency signatures [7,8]. Fur-
ther, FM signals can be easily generated and, as such, they are considered the preferred waveforms for
smart jammers, and have proven effective in hindering and compromising communications and radar
receivers [9].
The STFD framework was ﬁrst developed by Belouchrani and Amin for the blind separation of
narrowband nonstationary signals [4]. It was shown that the STFD matrix is related to the source
TFD matrix by the spatial mixing matrix in a manner similar to the commonly used expression, in
narrowband array processing problems, relating the sensor spatial covariance matrix to the source
covariance matrix. The same STFD framework was then used for direction ﬁnding of nonstation-
ary signals using t-f based DOA estimation approaches, such as t-f MUSIC, t-f root-MUSIC, t-f
maximum likelihood (t-f ML), and t-f ESPRIT [5,10–15]. These techniques, when applied to the
source t-f signatures, have shown improved performance, compared to conventional DOA estimation
approaches. The latter, which directly operate on the data or its covariance matrix, do not account for,
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00017-5
© 2014 Elsevier Ltd. All rights reserved.
765

766
CHAPTER 17 DOA Estimation of Nonstationary Signals
or properly utilize, the instantaneous frequency (IF) characterizations of the source signals. Compre-
hensive analyses, supporting STFD-based DOA estimations and demonstrating the robustness of the
signal and noise subspaces associated with the STFD matrices, were provided by Zhang et al. [6]. It
was shown that, signal-to-noise ratio (SNR) enhancement can be obtained from constructing the STFD
matrix incorporating signal power concentration regions in the time-frequency domain. This, in turn,
leads to robustness of the signal and noise subspace estimates compared to their counterparts, which are
obtained using the data covariance matrix. In addition, masking and ﬁltering of the source t-f signatures
allow separation and, subsequently, the consideration of individual, or a subgroup of, sources in the ﬁeld
of view. With such source discriminatory capability, the receiver can handle and process more signals
than sensors. Reduction of sources further increases SNR and lowers the mutual interference between
the signals, improving signal and noise subspace estimations. In some applications, particularly when
acoustic signals are involved, the TFD of multiple signals can be approximately disjoint or orthogonal,
i.e., only one signal is present at a given t-f point. With a single source considered at a time, the source
DOA can be estimated using only two receivers [16]. In essence, DOA estimation for nonstationary
signals, which are well separated in the t-f domain, should be performed using t-f methods.
It is recognized that the advantages of t-f based DOA estimation can only be materialized if appropri-
ate t-f points are selected in the formulation of the STFD matrices. While in some scenarios, the selection
of t-f points of peak power may be relatively simple, the problem may become challenging in other
situations, e.g., when the signals are highly contaminated by noise. Different approches for t-f point
selection are summarized in [17] and references therein. Utilization of the spatial degrees-of-freedom,
or spatial diversity, embedded in the STFD matrix, can reduce noise and enhance the t-f signatures of the
signals of interest without the need of using robust t-f kernels [18]. A simple example for achieving this
task is through an average of the TFDs over all receive sensors [19]. Insights into the characteristics of
TFDs corresponding to different sensors can also assist in the identiﬁcation of auto-term and cross-term
points [20,21]. It is worthnoting that the separation of the auto-term t-f points from cross-term t-f points
in general is less of an issue in DOA estimation than in blind source separation applications. This is
because, in performing DOA estimation, STFD matrices only need to meet the full rank requirement
[10]. This requirement can be satisﬁed with the inclusion of cross-terms. Nevertheless, the capability
of separating auto-term points from cross-term points allows the selection of t-f regions corresponding
to a subset of sources for proper source discrimination.
This chapter focuses on the DOA estimation approaches of nonstationary signals based on the STFD
framework. An analogous framework can be provided using linear transforms, such as the short-time
Fourier transform (STFT) and wavelet transform, both can achieve power localization and SNR enhance-
ment. However, multi-resolution analysis is not most effective when dealing with signals characterized
by their IF laws, which is the assumption made throughout this chapter. The STFT, on the other hand,
has a well known shortcoming, trading off temporal and spectral resolutions, and its magnitude square
is already considered within the STFD framework. Nevertheless, recent advances on the exploitation
of fractional Fourier transform (FrFT) and signal stationarization for DOA estimations are considered
in this chapter.
In addition to STFDs, we also review relevant recent approaches for nonstationary signal DOA esti-
mations. One of these approaches is the exploitation of spatial joint-variable distributions (SJVD), such
as spatial ambiguity function (SAF). The latter employs the Doppler and time-lag variables, in lieu of
the time and frequency variables [22]. Another important extension of the STFD and SJVD based DOA

3.17.2 Nonstationary Signals and Time-Frequency Representations
767
estimation methods is the consideration of wideband signals where the narrowband assumption does
not hold, i.e., the steering vector varies with the frequency within the signal bandwidth [11,23,24].
The latest application of STFD to multiple-input multiple-output (MIMO) radar systems for joint
direction-of-departure (DOD) and DOA estimations [25] is also introduced.
The following notations are used in this chapter. A lower (upper) case bold letter denotes a vector
(matrix). E[·] represents statistical mean operation. (·)∗, (·)T and (·)H respectively denote complex
conjugation, transpose, and conjugate transpose (Hermitian) operations. Re(·) represents the real part
operation of a complex variable, vector or matrix. ⊙denotes the Hadamard product, ⊗is the Kronecker
product, and ♦denotes the Khatri-Rao product. In expresses the n ×n identity matrix. Diag(x) denotes
a diagonal matrix using the elements of x as its diagonal elements, diag(X) a vector consisting of the
diagonal elements of matrix X, and vec(X) a vectorized result of matrix X. det(·) and tr(·) respectively
denote the determinant and trace of a matrix. In addition, CN×M denotes the complete set of N × M
complex entries, [a]n denotes the nth element of vector a, and [A]m,n denotes the (m,n)th element of
matrix A. δi,l is the Kronecker delta function which equals to 1 when i = l and 0 otherwise.
3.17.2 Nonstationary signals and time-frequency representations
3.17.2.1 Nonstationary signals
A large class of signal processing techniques deal with deterministic or stochastic time-domain signals
that are stationary. A deterministic signal is said to be stationary if it can be written as a discrete sum of
sinusoids, whereas in the random case, a signal x(t) is said to be wide-sense stationary (or stationary up to
the second order) if its expectation is independent of time, and its autocorrelation function E[x(t1)x∗(t2)]
depends only on the time difference t2 −t1 [26]. For stationary signals, parameters such as the mean
and variance, if they exist, also do not change over time or space. For this type of signals, the Fourier
transform is widely used to extract the frequency-domain information from the time-domain signals
and also as a pre-processing step for various temporal, spatial, and spatio-temporal processing methods.
Many real-world signals, however, are nonstationary. A signal is referred to as nonstationary if one
of the fundamental assumptions of stationary signals is no longer valid. For example, a ﬁnite duration
signal, in particular a transient signal (for which the length is short compared to the observation dura-
tion), is nonstationary. Also, many nonstationary signals have their frequency contents and properties
change with time. Signals with time-varying spectra include: the impulse response of a wireless com-
munication channel, radar and sonar acoustic waves, seismic acoustic waves, biomedical signals, such
as electrocardiogram (ECG) or neonatal seizures, biological signals, such as bat or dolphin echolocation
sounds, vocals in speech, notes in music, engine noise, shock waves in fault structures and jamming
signals [27].
3.17.2.2 Cohen’s class of time-frequency representations
There are a number of ways one can perform t-f analysis for nonstationary signals, most of which fall
into the following two classes: linear t-f analysis and bilinear t-f analysis. Short-time Fourier transform
(STFT), fractional Fourier transform (FrFT) and wavelet transform are commonly used techniques
to perform linear t-f analysis [26,28]. In contrast with linear t-f representations, which decompose
the signal to basis functions, or elementary components (the atoms), the bilinear t-f representations,

768
CHAPTER 17 DOA Estimation of Nonstationary Signals
introduced in the following subsection, distribute the signal power over two description variables: time
and frequency.
The Cohen’s class of TFDs is the foundation of the STFD framework for direction ﬁnding as shown
in Sections 3.17.3 and 3.17.4. The Cohen’s class of auto-term TFDs of a narrowband signal x(t) is
deﬁned as [29,30],
Dxx(t, f ) =
 ∞
−∞
 ∞
−∞
φ(t −u, τ)x

u + τ
2

x∗
u −τ
2

e−j2πfτ du dτ,
(17.1)
where t and f represent the time and frequency indexes, respectively, φ(t, τ) is the t-f kernel, and τ is
the time-lag variable.
The cross-term TFD of two signals xi(t) and xk(t) is deﬁned as
Dxi xk(t, f ) =
 ∞
−∞
 ∞
−∞
φ(t −u, τ)xi

u + τ
2

x∗
k

u −τ
2

e−j2πfτ du dτ.
(17.2)
In practice, TFDs are often evaluated using their discrete-time forms [31]. To use integer time delay
τ, we rewrite (17.1) as
Dxx(t, f ) = 2
 ∞
−∞
 ∞
−∞
φ(t −u, 2τ)x(u + τ)x∗
u −τ

e−j4πfτ du dτ.
(17.3)
The discrete form of the auto-term TFD corresponding to (17.3) is typically expressed as
Dxx(t, f ) =
∞

u=−∞
∞

τ=−∞
φ(t −u, τ)x(u + τ)x∗(u −τ)e−j4πfτ,
(17.4)
which excludes the constant of two and a scaling factor in τ for expressional convenience. Similarly,
the discrete-form of the cross-term TFD corresponding to (17.2) is given by
Dxi xk(t, f ) =
∞

u=−∞
∞

τ=−∞
φ(t −u, τ)xi(u + τ)x∗
k (u −τ)e−j4πfτ.
(17.5)
It is clear from the above equations that the TFD maps one-dimensional (1-D) signals in the time
domain into two-dimensional (2-D) signal representations in the t-f domain. The fundamental TFD
property of concentrating the input signal energy around its IF, while spreading the noise energy over
the entire t-f domain, is crucial in DOA estimation, as it increases the effective SNR. For a single-
component LFM signal, pseudo Wigner-Ville distribution (PWVD) can achieve SNR improvement
up to the window length [6]. The SNR enhancement is dominantly determined by the window size,
but is less sensitive to the type of t-f kernels [32]. When all the t-f points are selected within a 3-dB
bandwidth from the peaks, the SNR improvement remains proportional to the window length [33].
Such observations are valid for a general class of signals, provided that the third-order derivative of the
waveform phase is negligible or, equivalently, the waveforms can be approximated by an LFM within
each sliding window interval.
The properties of a TFD can be characterized by simple constraints on the kernel. Different kernels
can be designed and used to generate TFDs with prescribed, desirable properties. WVD is often regarded
as the basic or prototype quadratic TFDs, since the other quadratic TFDs can be described as ﬁltered
version of the WVD. WVD is known to provide the best t-f resolution for single-component LFM

3.17.2 Nonstationary Signals and Time-Frequency Representations
769
Table 17.1 Example of Time-Frequency Kernels
Distribution
Kernel φ(t, τ)
Wiger-Ville
δ(t)
Pseudo Wigner-Ville
δ(t)w(τ)
Choi-Williams [34]
√πσ
|τ| exp

−π2σt 2
τ 2

Zhao-Atlas-Marks [35]
w(τ)rect

t
2τ/a

signals, but it yields high cross-terms when the frequency law is nonlinear or when a multi-component
signal is considered. Various reduced interference kernels have been developed to reduce the cross-term
interference. Table 17.1 shows some commonly used kernel functions [7], where δ(t) is a Dirac delta
function, rect(t) is a rectangular window function, w(t) is an arbitrary window function, and σ and a are
scalars. TFD examples that use these kernels are illustrated in the following two examples. In addition to
these kernels that assume ﬁxed parameters, some kernels, such as the adaptive optimal kernel, provide
signal-adaptive ﬁltering capability [36].
3.17.2.2.1
Examples
Figures 17.1a and 17.1b show the real- and imaginary-parts of an analytic LFM signal, expressed as
x(t) = exp[ j2π(0.1t +0.001176t2), t = 0, . . . , 255. The start and end frequencies of the LFM signals
are, respectively, 0.1 and 0.4. Performing Fourier transform of the signal yields a spectrum spreading
over the normalized frequency band [0.1, 0.4], as shown in Figure 17.1c. The WVD of the waveform,
shown in Figure 17.1d, depicts high energy concentration of the instantaneous narrowband signal with
a linearly time-varying IF signature.
Figure 17.2 shows the t-f representations of two time-limited parallel LFM signals using different
kernels. The WVD provides sharp auto-term signatures, whereas the cross-terms are evidently present
in the middle of the two auto-term signatures. By using PWVD, the cross-terms in the time-domain
are mitigated, whereas the frequency-domain cross-terms remain. Both the Choi-Williams distribution
and Zhao-Atlas-Marks distribution provide much reduced cross-term presence. The three non-WVD
distributions yield much wider auto-term signatures in the t-f domain.
3.17.2.3 Wigner-Radon transform and fractional Fourier transform
for LFM signals
The IFs of LFM (chirp) signals vary linearly with time. The WVD auto-terms of a chirp signal represent
themselves in the t-f plane as a straight line with positive values. The time-varying frequency behavior
of each LFM component can be described in the t-f domain by the slope (chirp rate) and the initial
frequency. This property enables signal parameter estimation and characterizations. The Wigner-Radon
transform and fractional Fourier transform (FrFT) are well known techniques that utilize these LFM
signal properties. These techniques can be used for DOA estimation of LFM signals. FrFT-based DOA
estimation is discussed in Section 3.17.4.4.

770
CHAPTER 17 DOA Estimation of Nonstationary Signals
0
50
100
150
200
250
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
Time
Real−part waveform
0
50
100
150
200
250
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
Time
Imaginary−part waveform
(a)
(b)
(c)
(d)
0
0.1
0.2
0.3
0.4
0.5
0
10
20
30
40
50
60
70
Frequency
FFT magnitude
Time
Frequency
0
50
100
150
200
250
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
50
100
150
200
FIGURE 17.1
Waveform and Wigner-Ville distribution of an LFM signal. (a) Real-part of the waveform. (b) Imaginary-part
of waveform. (c) FFT magnitude. (d) Wigner-Ville distribution.
For an LFM signal x(t), whose IF is expressed as f (t) = f0 + βt, integrating the WVD Dxx(t, f )
over the t-f line segments yields high peak values, and thus allows estimation of the chirp rate β and
the initial frequency f0, which uniquely describe the signature of the LFM signal. The following line
integration,
L( f0, β) =

Dxx(t, f0 + βt)dt
(17.6)

3.17.2 Nonstationary Signals and Time-Frequency Representations
771
Time
Frequency
0
50
100
150
200
250
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
0
50
100
150
200
250
Time
Frequency
0
50
100
150
200
250
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
10
20
30
40
50
60
70
80
90
100
Time
Frequency
0
50
100
150
200
250
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
0
5
10
15
20
Time
Frequency
0
50
100
150
200
250
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
20
40
60
80
100
120
140
160
180
200
(a)
(b)
(c)
(d)
FIGURE 17.2
TFDs of two LFM signals corresponding to different kernels. (a) Wigner-Ville distribution. (b) Pseudo Wigner-
Ville distribution. (c) Choi-Williams distribution. (d) Zhao-Atlas-Marks distribution.
is referred to as the Wigner-Radon transform. The above integration is equivalent to dechirping, i.e.,
signal multiplication with the conjugation of the LFM signal, followed by power spectral calculation
of the product [37,38]. For multi-component LFM signals, the Wigner-Radon transform yields peaks
in the respective ( f0, β) positions in the time-frequency plane, whereas the cross-terms are effectively
mitigated due to their positive-negative oscillating behavior.
The FrFT, on the other hand, is a generalization of the classical Fourier transform. The FrFT was
ﬁrst developed for quantum mechanics [39], but has found broad applications since it was introduced to
the signal processing community [28]. Ref. [28] also analyzed the relationship between the FrFT and

772
CHAPTER 17 DOA Estimation of Nonstationary Signals
FIGURE 17.3
Illustration of rotation in the time-frequency domain through FrFT.
the WVD. FrFT is, in essence, a rotation of the signal representation in the t-f domain (Figure 17.3).
The FrFT deﬁnes an operator, denoted as Rα, that performs counterclockwise rotation of the signal by
an angle of α in the t-f plane. In this sense, the classical Fourier transform becomes a speciﬁc case by
setting α = π/2.
The FrFT is deﬁned by the following transformation kernel:
Kα(t, u) =
⎧
⎪⎨
⎪⎩

1−j cot α
2π
e j t2+u2
2
cot α−jut csc α, if α is not a multiple of π,
δ(t −u),
if α is a multiple of 2π,
δ(t + u),
if α + π is a multiple of 2π,
(17.7)
where u is the axis of the transformed domain. The FrFT of a signal x(t) is then expressed as
Xα(u) = Rαx(t) =
 ∞
−∞
x(t)Kα(t, u)dt
=
⎧
⎪⎪⎨
⎪⎪⎩

1−j cot α
2π
e j u2
2 cot α
 ∞
−∞
x(t)e j t2
2 cot α−jut csc αdt, if α is not a multiple of π,
x(t),
if α is a multiple of 2π,
x(−t),
if α + π is a multiple of 2π.
(17.8)
By properly choosing the rotating angle, an LFM signal would be well localized in the transformed
domain. Readers interested in this subject can refer to [40] for additional information about FrFT.
3.17.2.4 Polynomial phase signals and parameter estimations
A polynomial phase signal (PPS) is an extension of LFM signals which include higher phase orders. The
parameter estimation of PPS signals can be used for DOA estimation through signal stationarization,
as described in Section 3.17.4.4.

3.17.2 Nonstationary Signals and Time-Frequency Representations
773
Mathematically, a PPS can be expressed as
x(t) = Ae jφ(t) = Ae
j
K
k=0
aktk
,
(17.9)
where K is the polynomial order of the phase φ(t), {a0, . . . , aK } are the polynomial coefﬁcients, and
A is the signal amplitude.
Several techniques have been developed to estimate PPS parameters. Commonly used parametric
methods estimate the IF through polynomial phase transform, Hough transform, and high-order ambi-
guity function (HAF) [41–43].
The HAF is deﬁned as the Fourier transform of the high-order instantaneous moment (HIM) which
is given, for a signal s(t), by the following relation:
HIMK [s(t); τ] =
K−1

q=0
[s(∗q)(t −qτ)]
 K−1
q

,
(17.10)
where K is the HIM order, τ is the lag, and (·)(∗q) is an operator deﬁned as
s(∗q)(t) =
 s(t), if q is even,
s∗(t), if q is odd.
(17.11)
The Nth order HIM of a PPS given in (17.9) is reduced to a constant amplitude harmonic [44,45]
HIMN[s(t); τ] = A2N−1 e j( ˜ωN t+ ˜φN ),
(17.12)
where
˜ωN = N!τ N−1aN,
˜φN = (N −1)!τ N−1aN−1 −0.5N!(N −1)τ NaN.
(17.13)
A natural way to take advantage of this property is to compute the Fourier transform of the Nth-order
HIM, which leads to the HAF deﬁnition:
HAFN[s; ω, τ] =
 ∞
−∞
HIMN[s(t); τ]e−jωt dt.
(17.14)
The Nth order polynomial coefﬁcient can be estimated via
ˆaN =
1
N!τ N−1 arg max
ω {|HAFN(s; ω, τ)|}.
(17.15)
Using this estimate, the effect of the phase term of the Nth order can be removed:
s(N−1)(t) = s(t)e−j ˆaN t N .
(17.16)
This process can be repeated to obtain lower order coefﬁcients.

774
CHAPTER 17 DOA Estimation of Nonstationary Signals
It was pointed out in [45,46] that the classical procedure for polynomial phase modeling based on
HAF method is challenged by the noise robustness and the cross-terms presence. To overcome these
problems, the multilag HAF (mlHAF) concept, which is a generalization of the HIM, was proposed in
[46]. Consider that the Kth-order HIM as the second-order HIM of the (K−1)th-order HIM,
HIMK (s(t); τ] = HIM2[HIMK−1[s(t); τ]; τ].
(17.17)
In mlHAF based technique, the HIM is replaced by the multilag HIM (mlHIM), which is expressed as
mlHIMK (s(t); τ K−1] = mlHIMK−1[s(t+τK−1); τ K−2]×mlHIM∗
K−1[s(t−τK−1); τ K−2], (17.18)
where τ N = [τ1, τ2, . . . , τK ] is the set of lags. The mlHAF is deﬁned as the Fourier transform of mlHIM
in a manner similar to HAF. The performance of HAF-based parameter estimation of multi-component
PPS signals are provided in, e.g., [47].
When a nonstationary signal, which is characterized by its IF, is considered over a substantial time
period, it may become difﬁcult to use a PPS to model the entire waveform. Rather, it is more practical
to partition the waveform into multiple segments, each represents a PPS signal. The segments can be
nonoverlapping or partially overlapping. The PPS coefﬁcients are estimated over each segment and
then merged together to achieve the global phase behavior of the entire FM signal [44,48–50]. In
this case, multiple PPS parameter estimates can be made in each segment, and the phase continuity
over neighboring segments can be utilized as additional constraint for the selection of the most likely
parameter set [44,48].
3.17.3 Spatial time-frequency distribution
In this section, we ﬁrst introduce the concept of STFD. Analysis of the subspace estimates based on
STFD matrices is then provided. The robustness of these estimates compared to those corresponding
to the covariance matrices is the main motivation of using the STFD platform for direction ﬁnding of
nonstationary signals.
3.17.3.1 Spatial time-frequency distribution
Consider n narrowband nonstationary signals impinging on an array consisting of m sensors. By
narrowband signals, we mean that the steering vector does not change with frequency within the
signal bandwidth. For simplicity, we assume a 1-D DOA estimation problem (e.g., only the azimuth
angle is considered), but the extension to a 2-D problem (i.e., both the azimuth and elevation angles are
considered) is straightforward. The m × 1 received data vector x(t) and the n × 1 source signal vector
d(t) are related by
x(t) = A(θ)d(t) + n(t),
(17.19)
where A(θ) = [a(θ1), a(θ2), . . . , a(θn)] is the m × n mixing matrix that holds the steering vectors
of the n signals, θ = [θ1, θ2, . . . , θn], and a(θq) is the steering vector for the qth source, who sig-
nal dq(t) arrives from direction θq. Each element of d(t) = [d1(t), d2(t), . . . , dn(t)]T is assumed to be

3.17.3 Spatial Time-Frequency Distribution
775
a mono-component signal. Due to the signal mixing occurring at each sensor, the elements of x(t)
become multi-component signals. n(t) is an m × 1 additive noise vector that consists of independent
and identically distributed (i.i.d.) zero-mean, white and complex Gaussian distributed processes with
variance σ 2
n . The noise elements are assumed to be independent of the signals, which are assumed to
be deterministic.
The STFD matrix of vector x(t) is expressed as [4]
Dxx(t, f ) =
 ∞
−∞
 ∞
−∞
φ(t −u, τ)x

u + τ
2

xH 
u −τ
2

e−j2πfτ du dτ,
(17.20)
where the (i, k)th element of Dxx(t, f ) is given in (17.2) for i, k = 1, 2, . . . , m. The noise-free STFD
matrix is obtained by substituting (17.19) into (17.20), resulting in
Dxx(t, f ) = A(θ)Ddd(t, f )AH(θ),
(17.21)
where Ddd(t, f )is the TFD matrix of d(t) which consists of auto-source TFDs as its diagonal elements
and cross-source TFDs as its off-diagonal elements. With the presence of noise, the expected value of
Dxx(t, f ) becomes
E[Dxx(t, f )] = A(θ)Ddd(t, f )AH(θ) + σ 2
n Im.
(17.22)
Equation (17.22) relates the STFD matrix to the source TFD matrix in a manner similar to the formula
that is commonly used in narrowband array processing problems, relating the source covariance matrix to
the sensor spatial covariance matrix. It is clear, therefore, that the two subspaces spanned by the principle
eigenvectors of Dxx(t, f ) and the columns of A(θ) are identical. As discussed below, the construction
of the STFD matrix from the t-f points of highly localized signal energy allows the corresponding signal
and noise subspace estimates to become more robust to noise than their counterparts obtained using the
data covariance matrix [4,6]. Further, source elimination, rendered through the selection of speciﬁc t-f
regions, improves DOA estimations [6].
3.17.3.2 SNR enhancement
To provide insights into the properties of STFDs, we consider the case of frequency modulated (FM)
signals and the simplest form of TFD, namely, the pseudo Wigner-Ville distribution (PWVD) [6]. The
consideration of FM signals is motivated by the fact that these signals are uniquely characterized by
their IFs, and therefore, they have clear t-f signatures that can be utilized by the STFD approach. Also,
FM the signals have constant amplitudes. The FM signals can be modeled as
d(t) = [d1(t), . . . , dn(t)]T =

D1e jψ1(t), . . . , Dne jψn(t)T
,
(17.23)
where Di and ψi(t) are the ﬁxed amplitude and time-varying phase of ith source signal. For each
sampling time t, di(t) has an IF of fi(t) = dψi(t)/(2πdt). For the simplicity of the analysis, we
further assume that the third-order derivative of the phase is negligible over the window length L.
The discrete form of PWVD of a signal x(t), using a rectangular window of odd length L, is
given by
Dxx(t, f ) =
(L−1)/2

τ=−(L−1)/2
x(t + τ)x∗(t −τ)e−j4πfτ.
(17.24)

776
CHAPTER 17 DOA Estimation of Nonstationary Signals
Similarly, the spatial pseudo Wigner-Ville distribution (SPWVD) matrix is obtained as
Dxx(t, f ) =
(L−1)/2

τ=−(L−1)/2
x(t + τ)xH(t −τ)e−j4πfτ.
(17.25)
The ith diagonal element of PWVD matrix Ddd(t, f ) is given by
Ddidi (t, f ) =
(L−1)/2

τ=−(L−1)/2
D2
i e j[ψi(t+τ)−ψi(t−τ)]−j4π f τ.
(17.26)
Assume that the third-order derivative of the phase is negligible over the window length L, then along
the true t-f points of the ith signal, fi(t) = dψi(t)/(2πdt), and ψi(t + τ) −ψi(t −τ) −4π fi(t)τ = 0.
Accordingly, for (L −1)/2 ≤t ≤N −(L −1)/2,
Ddidi (t, fi(t)) =
(L−1)/2

τ=−(L−1)/2
D2
i = L D2
i .
(17.27)
Similarly, the noise SPWVD matrix Dnn(t, f ) is
Dnn(t, f ) =
(L−1)/2

τ=−(L−1)/2
n(t + τ)nH(t −τ)e−j4πfτ,
(17.28)
whose statistical expectation is E[Dnn(t, f )] = σ 2
n Im. Therefore, when we select the t-f points along
the t-f signature or the IF of the ith FM signal, the SNR in the STFD matrix E[Dxx(t, f )] becomes
L D2
i /σ 2
n , which has an improved factor L over the covariance matrix Rxx = E[x(t)xH(t)].
The PWVD of each FM source has a constant value over the observation period, providing that we
leave out the rising and falling power distributions at both ends of the data record. For convenience, we
select those N ′ = N −L + 1 t-f points of constant distribution value for each source signal. In the case
where the STFD matrices no sources, i.e., a total of noN ′ t-f points, the result is given by
D =
1
noN ′
no

q=1
N′

i=1
Dxx(ti, fq,i(ti)),
(17.29)
where fq,i(ti) is the IF of the qth signal at the ith time sample. The expectation of the averaged STFD
matrix is
D = 1
no
no

q=1

L D2
qaqaH
q + σ 2
n I

= L
no
AoRo
dd(Ao)H + σ 2
n I,
(17.30)
where Ro
dd = Diag[D2
i , i = 1, 2, . . . , no] and Ao = [a1, a2, . . . , ano] represent the signal correlation
matrix and the mixing matrix formulated by considering no signals out of the total number of n signal
arrivals, respectively.

3.17.3 Spatial Time-Frequency Distribution
777
It is clear from (17.30) that the SNR improvement G = L/no (we assume L > no) is inversely
proportional to the number of sources contributing to matrix D. Therefore, from the SNR perspective,
it is best to set no = 1, i.e., to select the sets of N ′ t-f points that belong to individual signals one set at
a time, and then separately evaluate the respective STFD matrices.
This procedure is made possible by the fact that STFD-based array processing is, in essence, a dis-
criminatory technique in the sense that it does not require simultaneous localization and extraction of
all unknown signals received by the array. Array processing can be performed using STFDs of a sub-
class of the impinging signals with speciﬁc t-f signatures. In this respect, the t-f based direction ﬁnding
techniques have implicit spatial ﬁltering, removing the undesired signals from consideration. It is also
important to note that with the ability to construct the STFD matrix from one or few signal arrivals, the
well known m > n condition on source localization using arrays can be relaxed to m > no, i.e., we
can perform direction ﬁnding or source separation with the number of array sensors smaller than the
number of impinging signals. Further, from the angular resolution perspective, closely spaced sources
with different t-f signatures can be resolved by constructing two separate STFDs, each corresponding
to one source, and then proceed with subspace decomposition for each STFD matrix, followed by an
appropriate source localization method (MUSIC, for example). The drawback using different STFD
matrices separately is of course the need for repeated computations. Relevant work for noise analysis
and SNR enhancement in the t-f domain can be found in [51–54].
3.17.3.3 Subspace analysis
Analysis of the eigendecomposition of the STFD matrix is closely related to the analysis of subspace
decomposition of the covariance matrix [55]. Before elaborating on this relationship, we present the
case of FM signals using the conventional covariance matrix approach.
In Eq. (17.19), it is assumed that the number of sensors is greater than the number of sources,
i.e., m > n. Further, matrix A is full column rank. We further assume that the correlation matrix
Rxx = E[x(t)xH(t)] is nonsingular, and the observation period consists of N snapshots with N > m.
Under the above assumptions, the correlation matrix is given by
Rxx = E[x(t)xH(t)] = ARddAH + σ 2
n Im,
(17.31)
where Rdd = E[d(t)dH(t)] is the source correlation matrix.
Let λ1 > λ2 > · · · > λn > λn+1 = λn+2 = · · · = λm = σ 2
n denote the eigenvalues of Rxx.
It is assumed that λi, i = 1, . . . , n, are distinct. The unit-norm eigenvectors associated with λ1, . . . , λn
constitutethecolumnsofmatrixS = [s1, . . . , sn]thatspansthesignalsubspace,andthosecorresponding
to λn+1, . . . , λm make up matrix G = [g1, . . . , gm−n] that spans the noise subspace. Since the columns
of A and S span the same subspace, then AHG = 0.
In practice, Rxx is unknown, and therefore should be estimated from the available data samples (snap-
shots) x(i), i = 1, 2, . . . , N. The estimated correlation matrix is given by Rxx = 1
N
N
i=1 x(i)xH(i).
Let {ˆs1, . . . , ˆsn, ˆg1, . . . , ˆgm−n} denote the unit-norm eigenvectors of Rxx, arranged in the descending
order of the associated eigenvalues, and let S = [ˆs1, . . . , ˆsn] and G = [ˆg1, . . . , ˆgm−n].
We assume that the transmitted signals propagate in a stationary environment and are mutually
uncorrelated over the observation period 1 ≤t ≤N, i.e.,
1
N
N
k=1di(k)d∗
l (k) = 0, for i ̸= l, i,

778
CHAPTER 17 DOA Estimation of Nonstationary Signals
l = 1, . . . , n. In this case, the signal correlation matrix is
Rdd = lim
T →∞
1
T
T

t=1
d(t)dH(t) = Diag

D2
1, . . . , D2
n

.
(17.32)
Lemma 1 [6].
For uncorrelated FM signals with additive white Gaussian noise, the orthogonal pro-
jections of {ˆgi} onto the column space of S are asymptotically (for large N) jointly Gaussian distributed
with zero means and covariance matrices given by
E

SSH ˆgi
 
SSH ˆg j
H
= σ 2
n
N
 n

k=1
λk
(σ 2n −λk)2 sksH
k

δi, j ≜1
N Uδi, j,
(17.33)
E

SSH ˆgi
 
SSH ˆg j
T 
= 0 for all i, j.
(17.34)
The following Lemma provides the relationship between the eigendecompositions of the STFD matrices
and the data covariance matrices used in conventional array processing.
Lemma 2 [6].
Let λo
1 > λo
2 > · · · > λo
no > λo
no+1 = λo
no+2 = · · · = λo
m = σ 2
n denote the eigenvalues
of Ro
xx = AoRo
dd(Ao)H + σ 2
n Im, which is deﬁned from a data record of a mixture of the no selected
FM signals. Denote the unit-norm eigenvectors associated with λo
1, . . . , λo
no by the columns of So =
[so
1, . . . , so
no] , and those corresponding to λo
no+1, . . . , λo
m by the columns of Go = [go
1, . . . , go
m−no].
We also denote λt f
1 > λt f
2 > · · · > λt f
no > λt f
no+1 = λt f
no+2 = · · · = λt f
m = (σ t f
n )2 as the eigenvalues
of D deﬁned in (17.30). The superscript t f denotes that the associated term is derived from the STFD
matrix D. The unit-norm eigenvectors associated with λt f
1 , . . . , λt f
no are represented by the columns of
St f = [st f
1 , . . . , st f
no] , and those corresponding to λt f
no+1, . . . , λt f
m are represented by the columns of
Gt f = [gt f
1 , . . . , gt f
m−no]. Then,
a.
The signal and noise subspaces of St f and Gt f are the same as So and Go, respectively.
b.
The eigenvalues have the following relationship:
λt f
i
=
⎧
⎨
⎩
L
no

λo
i −σ 2
n

+ σ 2
n = L
no λo
i +

1 −L
no

σ 2
n , i ≤no,

σ t f
n
2
= σ 2
n ,
no < i ≤m.
(17.35)
An important conclusion from Lemma 2 is that, the largest no eigenvalues are ampliﬁed using STFD
analysis. This improves detection of the number of the impinging signals on the array, as it widens the
separation between dominant and noise-level eigenvalues. Determination of the number of signals is
key to establishing the proper signal and noise subspaces, and subsequently plays a fundamental role in
subspace-based applications. When the input SNR is low, or the signals are closely spaced, the number
of signals may often be underdetermined. When the STFD is applied, the SNR threshold level and/or
angle separation necessary for the correct determination of the number of signals are greatly reduced.
Next we consider the signal and noise subspace estimates from a ﬁnite number of data samples. We
form the STFD matrix based on the true (t, f ) points along the IF of the no FM signals.

3.17.4 DOA Estimation Techniques
779
Lemma 3 [15,6].
If the third-order derivative of the phase of the FM signals is negligible over the
time-period [t −L + 1, t + L −1], then the orthogonal projections of {ˆgt f
i } onto the column space
of St f are asymptotically (for N ≫L) jointly Gaussian distributed with zero means and covariance
matrices given by
E

St f (St f )H ˆgt f
i
 
St f (St f )Hˆgt f
j
H
= σ 2
n L
noN ′
 no

k=1
λt f
k
(σ 2n −λt f
k )2 st f
k

st f
k
H

δi, j
= σ 2
n
N′
 no

k=1
(λo
k −σ 2
n ) + no
L σ 2
n
(σ 2n −λo
k)2
so
k

so
k
H

δi, j
≜1
N ′ Ut f δi, j,
(17.36)
E

St f (St f )H ˆgt f
i
 
St f (St f )H ˆgt f
j
T
= 0 for all i, j.
(17.37)
From (17.36) and (17.37), two important observations are in order. First, if the signals are both
localizable and separable in the t-f domain, then the reduction of the number of signals from n to
no greatly reduces the estimation error, speciﬁcally when the signals are closely spaced. The second
observation relates to SNR enhancements. The above equations show that error reductions using STFDs
are more pronounced for the cases of low SNR and/or closely spaced signals. It is clear from (17.36) and
(17.37) that, when λo
k ≫σ 2
n for all k = 1, 2, . . . , no, the results are almost independent of L (suppose
N ≫L so that N ′ = N −L + 1 ≃N), and therefore there would be no obvious improvement in using
the STFD over conventional array processing. On the other hand, when some of the eigenvalues are
close to σ 2
n (λo
k ≃σ 2
n , for some k = 1, 2, . . . , no), which is the case of weak or closely spaced signals,
all the results of above three equations are reduced by a factor of up to G = L/no, respectively. This
factor represents, in essence, the gain achieved from using STFD processing.
3.17.4 DOA estimation techniques
In this section, we ﬁrst introduce the STFD-based DOA estimation techniques under the narrowband
signal model. T-f MUSIC and t-f maximum likelihood (ML) are used as examples. These techniques
demonstrate the advantages of the STFD framework, as described in the previous section. The t-f
MUSIC is relatively simple, whereas t-f ML is more computationally demanding, but allows high-
resolution DOA estimation of coherent signals. We address the effect of t-f cross-terms on direction
ﬁnding performance. We then introduce the DOA estimation techniques based on parametric models of
nonstationary signals. Depending on the characteristics of the nonstationary signals, different techniques
can be used. Fractional transform is discussed for LFM signals, whereas techniques based on signal
stationarizationallowshigh-resolutionDOAestimationsofhigher-orderpolynomialphasesignals.DOA
estimation based on spatial joint-variable domain distributions, such as the spatial ambiguity function
(SAF), is also introduced. Finally, STFD-based DOA estimation of wideband signals is discussed.

780
CHAPTER 17 DOA Estimation of Nonstationary Signals
3.17.4.1 Time-frequency MUSIC
Without loss of generality, we consider 1-D direction ﬁnding where the DOAs are described by θ. First,
recall that the DOAs are estimated in the MUSIC technique by determining the n values of θ for which
the following spatial spectrum is maximized [56],
fMU(θ) =

aH(θ)GGHa(θ)
−1
=

aH(θ)(I −SSH)a(θ)
−1
,
(17.38)
where a(θ) is the steering vector corresponds to θ. The variance of those estimates in the MUSIC
technique, assuming white noise processes, is given by Stoica and Nehorai [55]
E

ˆωi −ωi
2 =
1
2N
aH(θi)Ua(θi)
h(θi)
,
(17.39)
where ωi = (2πd/λ) sin θi is the spatial frequency associated with DOA θi, d is the interelement
spacing, and λ is the wavelength. ˆωi is the estimate of ω obtained from the MUSIC. Moreover, U is
deﬁned in (17.33), and
h(θi) = dH(θi)GGHd(θi),
with d(θi) = da(θi)/dω.
(17.40)
Similarly, for t-f MUSIC with no signals selected, the DOAs are determined by locating the no peaks
of the spatial spectrum deﬁned from the no signals’ t-f regions,
f t f
MU(θ) =

aH(θ)Gt f (Gt f )Ha(θ)
−1
=

aH(θ)

I −St f (St f )H
a(θ)
−1
.
(17.41)
Gt f and St f can be obtained by using either joint block diagonalization (JBD) [5] or t-f averaging.
When the t-f averaging is used, the variance of the DOA estimates based on t-f MUSIC is obtained,
from the results of Lemmas 2 and 3, as [6],
E

ˆωt f
i
−ωi
2
=
1
2N ′
aH(θi)Ut f a(θi)
ht f (θi)
,
(17.42)
where ˆωt f
i
is the estimate of ωi, Ut f is deﬁned in (17.36), and
ht f (θi) = dH(θi)Gt f (Gt f )Hd(θi).
(17.43)
Note that ht f (θ) = h(θi) if no = n.
3.17.4.1.1
Examples
Consider a uniform linear array of eight sensors spaced by half a wavelength, and an observation period
of 1024 samples. Two chirp signals emitted from two sources positioned at angles θ1 and θ2. The start
and end frequencies of the signal source at θ1 are ωs1 = 0 and ωe1 = π, while the corresponding two
frequencies for the other source at θ2 are ωs2 = π and ωe2 = 0, respectively.

3.17.4 DOA Estimation Techniques
781
−30
−25
−20
−15
−10
−5
0
5
10
10
−2
10
−1
10
0
10
1
SNR (dB)
Standard Deviation (deg)
MUSIC
MUSIC (exp)
L= 33
L= 33 (exp)
L=129
L=129 (exp)
CRB
FIGURE 17.4
Variance of DOA estimation versus input SNR.
Figure 17.4 displays the variance of the estimated DOA ˆθ1 versus SNR for the case (θ1, θ2) =
(−10◦, 10◦). The curves in this ﬁgure show the theoretical and simulation results of the conventional
MUSIC and t-f MUSIC (for L = 33 and 129). The Cramer-Rao bound (CRB) is also shown in Figure
17.4 for comparison. Both signals were selected when performing t-f MUSIC (no = n = 2). Simulation
results were averaged over 100 independent Monte-Carlo runs. The advantages of t-f MUSIC in low
SNR cases are evident from this ﬁgure. The simulation results deviate from the theoretical results for
low SNR. This is due to considering only the lowest coefﬁcient order of the perturbation expansion
in deriving the theoretical results [6]. Figure 17.5 shows estimated spatial spectra at SNR = −20 dB
based on t-f MUSIC (L = 129) and the conventional MUSIC. The t-f MUSIC spectral peaks are clearly
resolved.
Figure 17.6 shows examples of the estimated spatial spectrum based on t-f MUSIC (L = 129) and
the conventional MUSIC where the angle separation is small (θ1 = −2.5◦, θ2 = 2.5◦). The input SNR
is −5 dB. Two t-f MUSIC algorithms are performed using two sets of t-f points, each set belongs to
the t-f signature of one source (no = 1). It is evident that the two signals cannot be resolved when the
conventional MUSIC is applied, whereas by utilizing the signals’ distinct t-f signatures and applying
t-f MUSIC separately for each signal, the two signals become clearly separated and a reasonable DOA
estimation is achieved. It is noted that there is a small bias in the estimates of t-f MUSIC due to the
imperfect separation of the two signals in the t-f domain.

782
CHAPTER 17 DOA Estimation of Nonstationary Signals
−40
−10
10
40
10−2
10−1
100
t−f MUSIC
Magnitude
−40
−10
10
40
10−2
10−1
100
MUSIC
θ (deg)
Magnitude
FIGURE 17.5
Estimated spatial spectra of MUSIC and t-f MUSIC.
3.17.4.2 Time-frequency maximum likelihood method
In this section, we introduce the time-frequency maximum likelihood (t-f ML) method that can deal
with coherent nonstationary sources [15,57]. For conventional ML methods, the joint density function
of the sampled data vectors x(1), x(2), . . . , x(N), is given by Ziskind [58]
f (x(1), . . . , x(N)) =
N

i=1
1
πmdet[σ 2n I]exp

−1
σ 2n
[x(i) −Ad(i)]H[x(i) −Ad(i)]

.
(17.44)
It follows from (17.44) that the log-likelihood function of the observations x(1), x(2), . . . , x(N), is
given by
L = −mNlnσ 2
n −1
σ 2n
N

i=1

x(i) −Ad(i)
H 
x(i) −Ad(i)

.
(17.45)
To carry out this minimization, we ﬁx A and minimize (17.45) with respect to d. This yields the
well-known solution
ˆd(i) =

AHA
−1
AHx(i).
(17.46)
We can obtain the concentrated likelihood function as [58]
FML(θ) = tr

Im −A(AHA)−1AH
Rxx

.
(17.47)

3.17.4 DOA Estimation Techniques
783
−40
−2.5 2.5
40
10−5
100
t−f MUSIC
Magnitude
−40
−2.5 2.5
40
10−5
100
MUSIC
θ (deg)
Magnitude
FIGURE 17.6
Estimated spatial spectra of MUSIC and t-f MUSIC for closely spaced signals.
The ML estimate of θ is obtained as the minimizer of (17.47). Let ωi and ˆωi, respectively, denote
the spatial frequency and its ML estimate associated with θi, then the estimation error ( ˆωi −ωi)
are asymptotically (for large N) jointly Gaussian distributed with zero means and the covariance
matrix [55]
E

ˆωi −ωi
2
=
1
2N

Re

H ⊙RT
dd
−1
· Re

H ⊙

RddAHUARdd
T  
Re

H ⊙RT
dd
−1
,
(17.48)
where U is deﬁned in (17.33). Moreover,
H = CH 
I −A(AHA)−1AH
C,
with C = dA/dω.
(17.49)
Next we consider the t-f ML method. As we discussed in the previous section, we select no ≤n
signals in the t-f domain. The concentrated likelihood function deﬁned from the STFD matrix is similar
to (17.47) and is obtained by replacing Rxx by D,
Ft f
ML(θ) = tr

I −Ao 
(Ao)HAo−1
(Ao)H

D

.
(17.50)

784
CHAPTER 17 DOA Estimation of Nonstationary Signals
Therefore, the estimation error ( ˆωt f
i
−ωi) associated with the t-f ML method are asymptotically
(for N ≫L) jointly Gaussian distributed with zero means and the covariance matrix [15]
E

ˆωt f
i
−ωi
2
= σ 2
n
2N ′

Re

Ho ⊙DT
dd
−1
· Re

Ho ⊙

Ddd(Ao)HUt f AoDdd
T 
×

Re

Ho ⊙DT
dd
−1
= σ 2
n
2N ′

Re

Ho ⊙(Ro
dd)T −1
· Re

Ho ⊙

Ro
dd(Ao)HUt f AoRo
dd
T 
×

Re

(Ho ⊙Ro
dd)T −1
,
(17.51)
where Ut f is deﬁned in (17.36), and
Ho = (Co)H

I −Ao 
(Ao)HAo−1
(Ao)H

Co,
with Co = dAo/dω.
(17.52)
In the case of no = n, then Ho = H, and Co = C.
The signal localization in the t-f domain enables us to select fewer signal arrivals. This fact is not only
important in improving the estimation performance, particularly when the signals are closely spaced, but
also reduces the dimension of the optimization problem solved by the maximum likelihood algorithm,
and subsequently reduces the computational requirement.
3.17.4.2.1
Examples
To demonstrate the advantages of t-f ML over both the conventional ML and the t-f MUSIC, consider
a uniform linear array of eight sensors separated by half a wavelength. Two FM signals arrive from
(θ1, θ2) = (−10◦, 10◦) with the IFs f1(t) = 0.2 + 0.1t/N + 0.2 sin (2πt/N) and f2(t) = 0.2 +
0.1t/N + 0.2 sin (2πt/N + π/2), t = 1, . . . , N. The SNR of both signals is −20 dB, and the number
of snapshots used in the simulation is N = 1024. We use L = 129 for t-f ML. Figure 17.7 shows (θ1, θ2)
that yield the minimum values of the likelihood function of the t-f ML and the ML methods for 20
independent trials. It is evident that the t-f ML provides much improved DOA estimation over the
conventional ML.
In the next example, the t-f ML and the t-f MUSIC are compared for coherent sources. The two
coherent FM signals have common IFs f1,2(t) = 0.2 + 0.1t/N + 0.2 sin (2πt/N), t = 1, . . . , N, with
a π/2 phase difference. The signals arrive at (θ1, θ2) = (−2◦, 2◦). The SNR of both signals is 5 dB and
the number of snapshots is 1024. Figure 17.8 shows the contour plots of the likelihood function of the
t-f ML and the estimated spectra of t-f MUSIC for three independent trials. It is clear that the t-f ML
can separate the two signals, whereas the t-f MUSIC fails.
3.17.4.3 Effect of cross-terms
Auto-term and cross-term t-f points have different roles and contribute differently in DOA estimation.
This section considers the behavior of cross-terms in DOA estimation and addresses the proper selection
of auto-term and cross-term points.

3.17.4 DOA Estimation Techniques
785
0
10
20
−20
−10
0
θ2 (deg)
θ1 (deg)
FIGURE 17.7
(θ1, θ2) which minimize the t-f ML (“x”) and ML (“·”) likelihood functions.
As we discussed in Section 3.17.2, cross-terms are a by-product of the TFD due to its bilinearity.
Although different kernels have different ways of mitigating cross-terms [30,59], complete removal of
cross-terms, nevertheless, is in general difﬁcult to achieve.
There are two types of cross-terms in the underlying DOA estimation problems. The ﬁrst type is due
to the interactions between the components of the same source signal. These cross-terms always reside,
along with the auto-terms, on the main diagonal of the source TFD matrix. This type of cross-terms
shares the same steering vector as the auto-terms and thus can be similarly treated. The other type of
cross-terms is those generated from the interactions between two signal components belonging to two
different sources. These cross-terms are associated with cross-TFD of the source signals and, at any
given t-f point, they constitute the off-diagonal entries of the source TFD matrices. Here we consider
the second type of cross-terms.
To understand the role of cross-terms in DOA estimation, it is important to compare the cross-terms
to the cross-correlation between signals in conventional array processing, whose properties are well
studied. The source TFD matrix takes the following general form:
Ddd(t, f ) =
⎡
⎢⎢⎢⎣
Dd1d1(t, f )
Dd1d2(t, f ) · · ·
Dd1dn(t, f )
Dd2d1(t, f )
Dd2d2(t, f ) · · ·
Dd2dn(t, f )
...
...
...
...
Ddnd1(t, f )
Ddnd2(t, f ) · · ·
Ddndn(t, f )
⎤
⎥⎥⎥⎦.
(17.53)

786
CHAPTER 17 DOA Estimation of Nonstationary Signals
0
2
4
−4
−2
0
t−f ML
θ1 (deg)
−30
−2
2
30
10
−1
100
t−f MUSIC
θ (deg)
Magnitude
FIGURE 17.8
Contour plots of t-f ML likelihood function (upper) and spatial spectra of t-f MUSIC (lower).
On the other hand, the covariance matrix of correlated source signals is given at the form
Rdd =
⎡
⎢⎢⎢⎣
Rd1d1
Rd1d2
· · ·
Rd1dn
Rd2d1
Rd2d2
· · ·
Rd2dn
...
...
...
...
Rdnd1
Rdnd2
· · ·
Rdndn
⎤
⎥⎥⎥⎦,
(17.54)

3.17.4 DOA Estimation Techniques
787
where the off-diagonal element Rdid j = E[di(t)d∗
j (t)] represents the correlation between source signals
di and d j. Direction ﬁnding problems can usually be solved when the signals are partially correlated,
however, full rank property of the source covariance matrix Rdd is a necessary condition.
Comparing Eqs. (17.53) and (17.54), it is clear that the cross-correlation terms and the cross-terms
have analogous forms. When cross-terms are present at the selected t-f point, these cross-terms appear
as off-diagonal elements in the source TFD matrix. On the other hand, when signals are correlated,
the off-diagonal elements of the covariance matrix of the source signals represent the cross-correlation
between two source signals. DOA estimation problems can usually be solved when the signals are
partially correlated, provided that the full rank property of the covariance matrix of the source signals is
maintained. The cross-correlation terms and the cross-term TFDs have an analogous form and similar
function. That is, cross-term TFDs can be exploited in the DOA estimation as long as the full rank
subspace of the STFD matrix is achievable [10]. It is noted that the covariance matrix is obtained as a
results of statistical or ensemble averages, whereas the STFD matrix is deﬁned at a (t, f ) point and its
value usually varies with respect to time t and frequency f. When multiple (t, f ) points are incorporated,
the effect of a cross-term may be reduced, since the cross-term usually oscillates with respect to time.
3.17.4.4 DOA estimation based on signal stationarization
As we discussed in Section 3.17.2.3, FrFT can “rotate” LFM signals in the t-f domain and become
sinusoidal signals in a transformed coordinate system. For narrowband LFM signals, the t-f signatures
of the signals are identical for different array sensors, thus the same rotating operation stationarizes
a signal component at all array sensors. Further, mask operations can be applied in the transformed
domain to remove the effects of other components, whether they correspond to LFM or nonlinear FM
signals. As such, the DOA estimation problem of LFM signals becomes equivalent to that of a single
sinusoidal signal [60].
In general, for FM signals that are characterized by PPS or other time-varying IFs, their parameters
can be estimated, as discussed in Section 3.17.2.4. The signal stationarization process converts an FM
signal into a sinusoid or DC signal and, as such, allows a similar treatment [49]. The DOA estimation
technique based on signal stationarization is proposed in [61].
For receiver array signals
x(t) = A(θ)d(t) + n(t) =
n

i=1
aidi(t) + n(t),
(17.55)
where di(t) = Di e jφi(t), stationarization is performed by multiplying x(t) with the conjugation of the
kth signal component [61],
x[k](t) = x(t)e−jφk(t) = ak Dk +
n

i=1,i̸=k
aie j(φi(t)−φk(t))
i
(t) + n(t).
(17.56)
This operation transforms the selected kth signal from an FM signal to a DC signal. Other signal
components, shown as the second term at the right-hand side of the above equation, will likely to have
nonzero frequencies whenever the corresponding frequencies satisfy dφi(t)/dt ̸= dφk(t)/dt for i ̸= k.

788
CHAPTER 17 DOA Estimation of Nonstationary Signals
As such, even with some perturbations induced due to imperfect stationarization, a mask around the
DC region can be applied to only keep the kth signal, which is subsequently used for DOA estimation.
In [62], the signal stationarization is applied for the direction ﬁnding problem of multipath signals
in an over-the-horizon radar (OTHR) system. It is shown that the stationarization operation allows
separation of multipath signals, which have both closely separated Doppler signatures and close angular
separation. This enables DOA estimations of individual components which are otherwise difﬁcult to
perform without pre-processing.
3.17.4.5 DOA estimation based on spatial joint-variable domain distributions
So far, we have considered the TFD which transforms a 1-D (time-domain) signal into a 2-D represen-
tation in the joint t-f domain. It is known that a nonstationary signal can be also represented in other
joint-variable domains, such as the joint domain of time-lag and Doppler (frequency-lag), time and
time-lag, and frequency and Doppler (frequency-lag) [7].
The ambiguity function of a signal x(t) is deﬁned as
Bxx(ν, τ) =
 ∞
−∞
x

u + τ
2

x∗
u −τ
2

e−jντ du,
(17.57)
where ν and τ are the frequency lag and the time lag, respectively.
For the signal observed at an sensor array, we deﬁne the spatial ambiguity function (SAF) matrix of
a signal vector x(t) in a similar way to the STFD as [22]
Bxx(ν, τ) =
 ∞
−∞
x

u + τ
2

xH 
u −τ
2

e−jντ du.
(17.58)
In a noise-free environment, x(t) = Ad(t), the SAF is related to the source ambiguity matrix
Bdd(ν, τ) by
Bxx(ν, τ) = ABdd(ν, τ)AH.
(17.59)
Equations (17.58) and (17.59) are similar to the STFD matrix and thus the SAF inherits the properties
of the STFD.
The SAFs have the following two important offerings that distinguish them from other array spatial
functions. (1) The cross-terms in between source signals reside on the off-diagonal entries of source
ambiguity matrix Bdd(ν, τ). In the ambiguity domain, the signal auto-terms are positioned near and
at the origin, making it easier to leave out cross-terms from matrix construction. (2) In the ambiguity
domain, the auto-terms of all narrowband signals, regardless of their frequencies and phases, fall on the
time-lag axis (ν = 0), while those of the wideband signals fall on a different (ν, τ) region or spread
over the entire ambiguity domain. Therefore, the SAF is a natural choice for recovering and spatially
localizing narrowband sources in broadband signal platforms.
3.17.4.6 DOA estimation of wideband nonstationary signals
The discussion so far has been focused on the DOA estimation of narrowband nonstationary signals.
In many applications, the signals are rather wideband. In this case, the DOA estimator should consider
the fact that the steering vector is now frequency-dependent.

3.17.5 Joint DOD/DOA Estimation in MIMO Radar Systems
789
In order to estimate the DOA for a general class of wideband signals, the conventional techniques
usually use Fourier transform to decompose the wideband signals into a set of narrowband components.
The narrowband signals can then be processed either incoherently or coherently. The incoherent-based
approaches are relatively simple and estimate the DOA from the average of the spatial spectra corre-
sponding to different frequency bins. However, coherent approaches are often preferred due to their
superior performance compared to incoherent ones. A popularly used technique, namely, the coherent
signal-subspace (CSS) processing technique, was proposed by Wang and Kaveh [63] and was further
developed in several papers (see [64] and references therein). The fundamental concept of the CSS
techniques is to use a set of focusing matrices that map the steering vector at different frequencies into
that at a reference frequency prior to coherent combining.
Several t-f and ambiguity domain based DOA estimation methods have been developed for the
estimation of wideband LFM signals [11,23,65]. Wang and Xia [65] employs the t-f analysis to estimate
the chirp rates and compensates the signal chirp structure in an iterative manner. A good estimate of the
signal DOAs is required to initialize the iterative processing. By assuming that the wideband signals
are separable in the t-f domain and their IFs do not rapidly change, [11] uses a sufﬁciently short sliding
window to construct the STFD matrices so as to preserve the narrowband structure of the array manifold.
The focusing matrices are then applied to the STFD matrices at selected t-f points corresponding to
the source t-f signatures. Ma and Goh [23] considers the ambiguity domain for the DOA estimation of
wideband LFM signals whose chirp rates are assumed to be known. Multiple chirps with identical chirp
rates are allowed in this technique. Performance of incoherent and coherent processing techniques is
also compared in [23].
In essence, STFD framework permits wideband DOA estimation methods incorporating the CSS
approaches for nonstationary signals. The nature of the LFM signals and the offering of t-f signal
representations may be utilized in several aspects. (i) The decomposition of the LFM signals into a
spectrum of frequency bins is inherently performed in the t-f analysis. (ii) For LFM signals that have
distinct characteristics in the t-f domain, DOA estimation can be performed on individual sources.
(iii) LFM signals are instantaneous narrowband, allowing the focusing matrices to be applied to t-f
points.
3.17.5 Joint DOD/DOA estimation in MIMO radar systems
In this section, we discuss the STFD framework in the context of joint direction-of-departure
(DOD)/direction-of-arrival (DOA) estimation in multiple-input multiple-output (MIMO) radar con-
ﬁgurations [25]. MIMO radar is an emerging technology that has attracted much interest in the radar
community [66,67]. By emitting orthogonal waveforms from the transmit array antennas and utilizing
matched ﬁlterbanks in the receivers to extract the orthogonal waveform components, MIMO radar sys-
tems can exploit the spatial diversity and the higher number of degrees of freedom to improve resolution,
clutter mitigation, and classiﬁcation performance. In particular, a monostatic MIMO radar system can
provide effective array designs to achieve an extended virtual array, which is the sum coarray of the
transmit array and the receive arrays [67,68]. A bistatic MIMO radar, on the other hand, is capable
to jointly estimate the DOD and DOA of targets for enhanced target localization [69–72]. Bistatic
radars, in which the transmitters and receivers are separated by a considerable distance, have received

790
CHAPTER 17 DOA Estimation of Nonstationary Signals
increasing attentions because of many potential advantages, such as detection of stealthy targets, covert
receivers for safe operation, and increased coverage [73]. The DOD and DOA information obtained
from a bistatic radar system is particularly important in narrowband radar systems, such as over-the-
horizon radar, which do not have a high range resolution [25,74]. It is shown in [75] that nonstationary
processing in a MIMO radar platform also yields improved estimation of motion parameters whose
Doppler law is characterized by PPS models.
3.17.5.1 Signal model
Consider a bistatic MIMO radar system consisting of Nt closely spaced transmit antennas and Nr
closely spaced receive antennas. Denote S ∈CNt×T as the narrowband waveform matrix which contains
orthogonal waveforms to be transmitted from Nt antennas over a pulse-repetition period of T fast-time
samples. We assume that the waveform orthogonality is achieved in the fast-time domain. That is, by
denoting si as the ith row of matrix S, si and sl are orthogonal for any i ̸= l with different delays, and
si is orthogonal to the delayed version of itself. We also assume that si has a unit norm, i.e., SSH = INt .
Consider a far-ﬁeld range cell where L point targets are present with DOD θl and DOA φl, where
l = 1, . . . , L. Then, the signal data received at the receive array corresponding to the range cell is
expressed as the following Nr × 1 complex vector,
X(t) = Ar(t)AH
t S + N(t),
(17.60)
where t is the slow time index, Ar = [ar(φ1), . . . , ar(φL)] and At = [at(θ1), . . . , at(θL)], with ar(φl)
∈CNr×1 and at(θl) ∈CNt×1 respectively denoting the receive steering vector corresponding to DOA φl
and the transmit steering vector corresponding to DOD θl. In addition, (t) = Diag[γ1(t), . . . , γL(t)]
where γl(t) = ρle j2πβ( fD,l(t),t) denotes the complex reﬂection coefﬁcient of the lth target during the
tth pulse repetition period. The complex reﬂection coefﬁcient is a function of the radar cross section
(RCS), represented by ρl, and the phase term, denoted as β( fD,l(t), t), which depends on the Doppler
frequency fD,l(t) of the slow time index t. Moreover, N(t) ∈CNr×T is an additive noise matrix, whose
elements are assumed to be i.i.d. complex Gaussian random variables with zero mean and variance σ 2
n .
To qualify expression (17.60), it is assumed that the steering vectors remain unchanged during the entire
slow-time processing period, which is often the case for far-ﬁeld targets. The nonstationary signatures
result from the maneuvering ﬂights of targets, represented by the Doppler frequency fD,l(t).
By post-multiplying (17.60) by SH and utilizing the orthogonality of the transmitted waveforms, we
obtain Y(t) ∈CNt×Nr as
Y(t) = Ar(t)AH
t + Z(t),
(17.61)
where Z(t) = N(t)SH. Vectorizing Y(t) in (17.61) yields the following Nt Nr × 1 vector
y(t) = w(t) + z(t) = Aγ (t) + z(t),
(17.62)
where w(t) = Aγ (t) is the noise-free portion of the signal vector,
A = At ♦Ar =

a[t]
1 ⊗a[r]
1 , . . . , a[t]
L ⊗a[r]
L

,
(17.63)
with a[t]
l
and a[r]
l
denoting the lth column of At and Ar, respectively. In addition, γ (t) = diag((t)) =
[γ1(t), · · · , γL(t)]T , and z(t) = vec(Z(t)).

3.17.5 Joint DOD/DOA Estimation in MIMO Radar Systems
791
The noise component corresponding to the mth transmit waveform and the nth receive antenna is
given by zn,m(t) = [z(t)](m−1)Nr+n = ˜nn(t)˜sH
m , where ˜nn(t) is the nth row of the receive noise matrix
N(t), and ˜sm is the mth row of waveform matrix S, m = 1, . . . , Nt and n = 1, . . . , Nr. Notice that we
used ˜() to emphasize a row vector. It is clear that vector z(t) has a zero mean, spatially white across the
virtual sensors, and its covariance matrix can be shown to be σ 2
n INt Nr because
E

zn1,m1(t)z∗
n2,m2(t)

= E

˜nn1(t)˜sH
m1

˜nn2(t)˜sH
m2
∗
= E

˜sm2 ˜nH
n2(t)˜nn1(t)˜sH
m1

= σ 2
n δn1,n2δm1,m2.
(17.64)
3.17.5.2 Joint DOD/DOA estimations
In bistatic radars, the DOD and DOA information can be synthesized to locate targets. For multiple
targets, the combination of estimated DOD and DOA yields paring ambiguity. Several techniques have
been developed to void or to automatically obtain pairing operation [69,72]. These approaches, based
on ESPRIT [76], or combined ESPRIT-MUSIC, can be extended to the t-f framework. We consider,
as an example, the combined ESPRIT-MUSIC technique developed in [69] which only requires two
decoupled one-dimensional direction ﬁnding operations where the DOD and DOA are automatically
paired. In this section, we extend this technique into the STFD framework. The DODs of the targets are
ﬁrst estimated using t-f ESPRIT [12] and their DOAs are then obtained using t-f MUSIC [5]. To apply
ESPRIT-based method, both arrays are assumed to be uniform and linear, but the interelement spacings
of the two arrays, respectively denoted as dt and dr, may differ.
Consider a t-f region 0 that contains signal returns from L0 ≤L targets. An STFD matrix, denoted
as Dyy(0), can be obtained through weighted average of the STFD matrices across region 0, i.e.,
Dyy(0) =

(t, f )∈0
w(t, f )Dyy(t, f ),
(17.65)
where w(t, f ) is the weighting coefﬁcients, which can be chosen to be identical or proportional to the
TFD magnitude. The signal subspace of matrix Dyy(0) corresponds to the L0 target signals contained
in the selected t-f region 0. In other words, it spans the same subspace as A0, where A0 = A0,t ♦A0,r
is a Nt Nr × L0 submatrix of A that contains the L0 columns of matrix A, corresponding to the L0
signals included in the selected t-f region.
Performing eigendecomposition of Dyy(0) and denote Us,0 as its Nt Nr × L0 signal subspace,
whereas Un,0 as the Nt Nr ×(Nt Nr −L0) noise subspace. Then, Us,0 and A0 are related by an unknown
transformation matrix T as
Us,0 = A0T.
(17.66)
Divide the virtual array into two overlapping subarrays, respectively consisting of the ﬁrst and last
(Nt −1)Nr virtual antennas. Denote A(1)
0,t and A(2)
0,t as the ﬁrst and last Nt −1 rows of A0,t, and let
A(t1)
0
= A(1)
0,t ♦A0,r and A(t2)
0
= A(2)
0,t ♦A0,r. Further, denote the averaged STFD matrices deﬁned in
these subarrays as D(1)
yy (0) and D(2)
yy (0), respectively. Then, their respective signal subspaces relate
to A(t1)
0
and A(t2)
0
through
U(1)
s,0 = A(t1)
0
T,
U(2)
s,0 = A(t2)
0
T.
(17.67)

792
CHAPTER 17 DOA Estimation of Nonstationary Signals
A(t2)
0
and A(t1)
0
differ due to the antenna position and thus are related by
A(t2)
0
= A(t1)
0
[t],
(17.68)
where[t] isadiagonalmatrixwithdiagonalelements[[t]]i,i = exp ( j2πdt sin (θi)/λ), i = 1, . . . , L0.
Similarly, U(1)
s,0 and U(2)
s,0 are related by
U(2)
s,0 = U(1)
s,0[t].
(17.69)
From the above results, [t] can be obtained from U(1)
s,0 and U(2)
s,0. Substituting (17.68) into (17.69), we
obtain
U(1)
s,0 = A(t1)
0
T,
U(2)
s,0 = A(t1)
0
[t]T.
(17.70)
Therefore, it is concluded from (17.69) and (17.70) that [t] and [t] are related by [t] = T−1[t]T,
that is, [t] can be obtained as the eigenvalues of [t]. As such, the DODs θi can be obtained for
i = 1, . . . , L0.
To estimate the DOAs after DODs are obtained, the ESPRIT-MUSIC method is based on the fact that
noise subspace and the steering vector of the virtual array are orthogonal [69]. In the t-f framework, this
leads to a t-f MUSIC based approach for each estimated θi, i = 1, . . . , L0, i.e., estimating the paired
φi by ﬁnding the peaks of the following pseudo spatial spectrum
f (φ) =
1
aH
r (φ)[at(θi) ⊗INr ]HUn,0UH
n,0[at(θi) ⊗INr ]ar(φ).
(17.71)
When the receive array is uniform linear, for which the receive steering vector can be expressed as a
polynomial function of z = exp (−j2πdr sin (φ)/λ), i.e.,
ar(φ) =

1, e−j2πdr
λ
sin (φ), . . . , e−j2π(Nr −1)dr
λ
sin (φ)T
=

1, z, . . . , zNr−1T
,
(17.72)
the paired DOA φi can be solved using the simpler t-f root-MUSIC approach that ﬁnds the root inside
and closest to the unit circle of the following polynomial:
aH
r (φ)[at(θi) ⊗INr ]HUn,0UH
n,0[at(θi) ⊗INr ]ar(φ) = 0.
(17.73)
For the directions of other L −L0 targets, the same procedure can be carried out in different t-f regions
where these signals are included.
By exploiting source selection/discrimination through t-f region selection, signiﬁcant performance
improvement can be achieved. This is particularly true in the challenging situations when multiple
targets are closely spaced in angle but are separable in the time-frequency domain. Speciﬁcally, when a
t-f region corresponding to a single target is identiﬁed, the DOD and DOA can be estimated with simple
phase examinations, and no paring operation is needed.
3.17.5.2.1
Example
Consider a scenario in which two moving targets appear in a speciﬁc range bin of interest. The bistatic
radar consists of a linear transmit array consisting of Nt = 4 antennas and a linear receive array of
Nr = 6 antennas. The transmit and receive arrays are assumed to be distantly separated. Half wavelength

3.17.6 Conclusion
793
−10
−5
0
5
10
15
20
10 −2
10 −1
10 0
10 1
SNR (dB)
RMSE DOD (deg)
non−TF
TF, all targets
TF, first target
−10
−5
0
5
10
15
20
10 −2
10 −1
10 0
10 1
SNR (dB)
RMSE DOA (deg)
non−TF
TF, all targets
TF, first target
(a)
(b)
FIGURE 17.9
Comparison of RMSE performance. (a) DOD estimation. (b) DOA estimation.
interelement spacing is set for both transmit and receive arrays. The waveforms emitted from different
transmit antennas are considered orthogonal, i.e., their crosscorrelations are ignored. The total number
of samples is 256 for each waveform. The two targets have close DODs (10◦and 15◦) and DOAs (5◦
and 20◦). The input SNR of all the return signals are assumed to be identical. The start frequencies
of the two chirp signals are 0.15 and 0.18, and the respective ending frequencies are 0.35 and 0.38.
The increasing Doppler signature of each target indicates the target movement towards the transmit and
receive arrays in a way that the sum two-way slant range decreases over time.
In Figure 17.9, the root-mean-square error (RMSE) of the DOD and DOA estimation results of the
ﬁrst target are compared for three different scenarios, namely, joint ESPRIT-MUSIC without the use of
time-frequency analysis, time-frequency ESPRIT-MUSIC with both signals selected for consideration,
and time-frequency ESPRIT-MUSIC that only considers the signal corresponding to the ﬁrst target.
The results are averaged over 100 independent trials. It is evident that when both signals are selected,
the t-f ESPRIT-MUSIC still beneﬁts from the SNR enhancement over low SNR regions. It is also
clear that the performance of both DOD and DOA estimates is signiﬁcantly improved through target
discrimination by considering only the ﬁrst target. This improvement stems from overcoming the close
angular separation of the targets at both the transmitter and receiver sides using t-f signature selections.
3.17.6 Conclusion
This chapter discussed direction of arrival estimation of nonstationary signals that are characterized by
instantaneous frequency laws. Conventional direction ﬁnding methods, including high resolution tech-
niques, do not properly account for the instantaneous frequency characterization of the signals impinging
on the antenna arrays. We discussed the spatial time-frequency distribution (STFD) framework which

794
CHAPTER 17 DOA Estimation of Nonstationary Signals
permits eigenstructure subspace methods to utilize the signal-to-noise ratio enhancement, brought about
by incorporating the time-frequency regions of high power concentration. The latter are typically found
at and around the signal time-frequency signature. High SNR data enable robustness of DOA estimates.
It was also shown that distinction in the time-frequency signatures of closely spaced sources provides
a discriminatory capability, within the STFD framework, which allows reducing the number of sources
in the ﬁeld of view to a single, or a subgroup of the sources. This permits processing more sources than
sensors and reduces the variance of the source angular estimate. We extended the STFD framework to
include multiple-input multiple-output (MIMO) conﬁgurations and estimated both the source direction-
of-departure and direction-of-arrival. Although the focus of the chapter was on bilinear distributions of
nonstationary signals, we also addressed linear time-frequency methods and their applications to DOA
estimation of polynomial phase sources.
Glossary
Time-frequency distribution
distribution of the signal power over both the time and frequency
variables
Spatial time-frequency distribution
a matrix whose entries are the time-frequency distributions asso-
ciated with the outerproducts of the data observation vectors
measured across a sensor array
Auto-term
a sample in the time-frequency domain which pertains to the
time-frequency distribution of an individual component of the
signal
Cross-term
an artifact in the time-frequency domain which is introduced by
the bilinear product of two components of the input signal
Source discrimination
isolation of individual source signals in single variable or joint-
variables domains, such as time, frequency, space, and time-
frequency domains
Relevant Theory: Statistical Signal Processing
See this Volume, Chapter 1 Introduction: Statistical Signal Processing
See this Volume, Chapter 3 Non-stationary Signal Analysis
References
[1] M.G. Amin, Y. Zhang, Spatial time-frequency distributions and their applications, in: B. Boashash (Ed.),
Time-Frequency Signal Analysis and Processing, Elsevier, Oxford, UK, 2003.
[2] M.G. Amin, Y. Zhang, Spatial time-frequency distributions and DOA estimation, in: E. Tuncer, B. Friedlander
(Eds.), Classical and Modern Direction of Arrival Estimation, Academic Press, Burlington, MA, 2009.
[3] M.G. Amin, Y. Zhang, G.J. Frazer, A.R. Lindsey, Spatial time-frequency distributions: theory and applications,
in: L. Debnath (Ed.), Wavelets and Signal Processing, Birkhauser, Boston, MA, 2003.

References
795
[4] A. Belouchrani, M.G. Amin, Blind source separation based on time-frequency signal representations, IEEE
Trans. Signal Process. 46 (11) (1998) 2888–2897.
[5] A. Belouchrani, M.G. Amin, Time-frequency MUSIC, IEEE Signal Process. Lett. 6 (5) (1999) 109–110.
[6] Y. Zhang, W. Mu, M.G. Amin, Subspace analysis of spatial time-frequency distribution matrices, IEEE Trans.
Signal Process. 49 (4) (2001) 747–759.
[7] B. Boashash, Theory of quadratic TFDs, in: B. Boashash (Ed.), Time-Frequency Signal Analysis and Pro-
cessing, Elsevier, Oxford, UK, 2003.
[8] S. Qian, D. Chen, Joint Time-Frequency Analysis—Methods and Applications, Prentice Hall, Englewood
Cliffs, NJ, 1996.
[9] M.G. Amin, Interference mitigation in spread spectrum communication systems using time-frequency distri-
butions, IEEE Trans. Signal Process. 45 (1) (1997) 90–101.
[10] M.G. Amin, Y. Zhang, Direction ﬁnding based on spatial time-frequency distribution matrices, Digit. Signal
Process. 10 (4) (2000) 325–339.
[11] A. Gershman, M.G. Amin, Wideband direction-of-arrival estimation of multiple chirp signals using spatial
time-frequency distributions, IEEE Signal Process. Lett. 7 (6) (2000) 152–155.
[12] A. Hassanien, A.B. Gershman, M.G. Amin, Time-frequency ESPRIT for direction-of-arrival estimation of
chirp signals, in: Proceedings of the IEEE Sensor Array and Multichannel Signal Processing Workshop,
Rosslyn, VA, August 2002, pp. 337–341.
[13] K. Sekihara, S. Nagarajan, D. Poeppel, Y. Miyashita, Time-frequency MEG-MUSIC algorithm, IEEE Trans.
Med. Imag. 18 (1) (1999) 92–97.
[14] Q. Wang, C. Wu, A high reliability DOA estimation method—TF-ESPRIT method, in: Proceedings of the Int.
Conf. Signal Process., Beijing, China, August 2002, pp. 374–377.
[15] Y. Zhang, W. Mu, M.G. Amin, Time-frequency maximum likelihood methods for direction ﬁnding, J. Franklin
Inst. 337 (4) (2000) 483–497.
[16] S. Rickard, F. Dietrich, DOA estimation of many W-disjoint orthogonal sources from two mixtures using
DUET, in: Proceedings of the IEEE Workshop on Statistical Signal and Array Processing, Pocono, PA,
August 2000, pp. 311–314.
[17] A. Belouchrani, M.G. Amin, N. Thirion-Moreau, Y.D. Zhang, Source separation and localization using time-
frequency distributions, IEEE Signal Process. Mag. (in press).
[18] M.G. Amin, Minimum variance time-frequency distribution kernels for signal in additive noise, IEEE Trans.
Signal Process 44 (9) (1996) 2352–2356.
[19] W. Mu, M.G. Amin, Y. Zhang, Bilinear signal synthesis in array processing, IEEE Trans. Signal Process. 51
(1) (2003) 90–100.
[20] N. Linh-Trung, A. Belouchrani, K. Abed-Meraim, B. Boashash, Separating more sources than sensors using
time-frequency distributions, EURASIP J. Appl. Signal Process. 2005 (17) (2005) 2828–2847.
[21] Y. Zhang, M.G. Amin, Blind separation of nonstationary sources based on spatial time-frequency distributions,
EURASIP J. Appl. Signal Process. 2006 (2006) 13 (Article ID 64785).
[22] M.G. Amin, A. Belouchrani, Y. Zhang, The spatial ambiguity function and its applications, IEEE Signal
Process. Lett. 7 (6) (2000) 138–140.
[23] N. Ma, J.T. Goh, Ambiguity-function-based techniques to estimate DOA of broadband chirp signals, IEEE
Trans. Signal Process. 54 (5) (2006) 1826–1839.
[24] B.A. Obeidat, Y. Zhang, M.G. Amin, DOA and polarization estimation for wideband sources, in: Proceedings
of the Asilomar Conference on Signals, System, Computers, Paciﬁc Grove, CA, November 2004.
[25] Y.D. Zhang, M.G. Amin, B. Himed, Joint DOD/DOA estimation in MIMO radar exploiting time-frequency
signal representations, EURASIP J. Adv. Signal Process. 2012 (1) (2012) 102.
[26] F. Auger, P. Flandrin, P. Gonçalvés, O. Lemoine, Time-frequency toolbox for use with Matlab. <http://tftb.
nongnu.org/tutorial.pdf>.

796
CHAPTER 17 DOA Estimation of Nonstationary Signals
[27] A. Papandreou-Suppappola, Applications in Time-Frequency Signal Processing, CRC Press, Boca Raton, FL,
2003.
[28] L.B. Almeida, The fractional Fourier transform and time-frequency representations, IEEE Trans. Signal
Process. 42 (11) (1994) 3084–3091.
[29] L. Cohen, Time-frequency distributions—a review, Proc. IEEE 77 (7) (1989) 941–981.
[30] L. Cohen, Time-Frequency Analysis, Prentice Hall, Englewood Cliffs, NJ, 1995.
[31] B. Boashash, G.R. Putland, Discrete time-frequency distributions, in: B. Boashash (Ed.), Time-Frequency
Signal Analysis and Processing, Elsevier, Oxford, UK, 2003.
[32] W. Mu, M.G. Amin, SNR analysis of time-frequency distributions, in: Proceedings of the IEEE Int. Conf.
Acoust. Speech Signal Process. Istanbul, Turkey, June 2000, pp. II645–II648.
[33] X-G. Xia, V. Chen, A quantitative SNR analysis for the pseudo Wigner-Ville distribution, IEEE Trans. Signal
Process. 47 (10) (1999) 2891–2894.
[34] H.I. Choi, W.J. Williams, Improved time-frequency representation of multicomponent signals using exponen-
tial kernels, IEEE Trans. Acoust. Speech Signal Process. ASSP-37 (6) (1989) 862–871.
[35] Y. Zhao, L.E. Atlas, R.J. Marks, The use of cone-shaped kernels for generalized time-frequency representations
of non-stationary signals, IEEE Trans. Acoust. Speech Signal Process. ASSP-38 (1990) 1084–1091.
[36] R.G. Baraniuk, D.L. Jones, A signal-dependent time-frequency representation: optimal kernel design, IEEE
Trans. Signal Process. 41 (1993) 1589–1602.
[37] W. Li, Wigner distribution method equivalent to dechirp method for detecting a chirp signal, IEEE Trans.
Acoust. Speech Signal Process. ASSP-35 (1987) 1210–1211.
[38] J.C. Wood, D.T. Barry, Radon transformation of time-frequency distributions for analysis of multicomponent
signals, IEEE Trans. Signal Process. 42 (11) (1994) 3166–3177.
[39] V. Namias, The fractional order Fourier transform and its application to quantum mechanics, J. Inst. Math.
Appl. 25 (1980) 241–265.
[40] S. Das, I. Pan, Fractional Order Signal Processing: Introductory Concepts and Applications, Springer, 2012.
[41] S. Barbarossa, Analysis of multicomponent LFM signals by a combined Wigner-Hough transform, IEEE
Trans. Signal Process. 43 (6) (1995) 1511–1515.
[42] S. Barbarossa, O. Lemoine, Analysis of nonlinear FM signals by pattern recognition of their time-frequency
representation, IEEE Signal Process. Lett. 3 (4) (1996) 112–115.
[43] S. Peleg, B. Porat, Estimation and classiﬁcation of polynomial-phase signals, IEEE Trans. Inform. Theory 37
(1991).
[44] C. Ioana, A. Quinquis, Time-frequency analysis using warped-based high-order phase modeling, EURASIP
J. Applied Signal Process. 2005 (17) (2005) 2856–2873.
[45] B. Porat, Digital Processing of Random Signals: Theory and Methods, Prentice Hall, Englewood Cliffs, NJ,
1993.
[46] S. Barbarossa, A. Scaglione, G.B. Giannakis, Product high-order ambiguity function for multicomponent
polynomial-phase signal modeling, IEEE Trans. Signal Process. 46 (3) (1998) 691–708.
[47] D.S. Pham, A.M. Zoubir, Analysis of multicomponent polynomial phase signals, IEEE Trans. Signal Process.
55 (1) (2007) 56–65.
[48] S. Djukanovi´c, M. Dakovi´c, L. Stankovi´c, Local polynomial Fourier transform receiver for nonstationary
interference excision in DSSS communications, IEEE Trans. Signal Process. 56 (4) (2008) 1627–1636.
[49] C. Ioana, Y.D. Zhang, M.G. Amin, F. Ahmad, B. Himed, Time-frequency analysis of multipath Doppler
signatures of maneuvering targets, in: Proceedings of the IEEE International Conference Acoustics, Speech,
Signal Process, Kyoto, Japan, March 2012.
[50] C. Ioana, Y.D. Zhang, M.G. Amin, F. Ahmad, G. Frazer, B. Himed, Time-frequency characterization of micro-
multipath signals in over-the-horizon radar, in: Proceedings of the IEEE International Radar Conference,
Atlanta, GA, May 2012, pp. 671–675.

References
797
[51] M.G. Amin, Time-frequency spectrum analysis and estimation for nonstationary random processes, in:
B. Boashash (Ed.), Time-Frequency Signal Analysis: Methods and Applications, Longman Cheshire, 1992.
[52] S. Hearon, M.G. Amin, Minimum variance time-frequency distribution kernels, IEEE Trans. Signal Process.
43 (1995) 1258–1262.
[53] L. Stankovic, A time-frequency distribution concentrated along the instantaneous frequency, IEEE Signal
Process. Lett. 3 (3) (1996) 89–91.
[54] L. Stankovic, Analysis of noise in time-frequency distributions, IEEE Signal Process. Lett. 9 (9) (2002)
286–289.
[55] P. Stoica, A. Nehorai, MUSIC, maximum likelihood and Cramer-Rao bound, IEEE Trans. Acoust. Speech
Signal Process. ASSP-37 (5) (1989) 720–741.
[56] R.O. Schmidt, Multiple emitter location and signal parameter estimation, IEEE Trans. Antennas Propagat.
AP-34 (3) (1986) 276–280.
[57] M.G. Amin, Spatial time-frequency distributions for direction ﬁnding and blind source separation, in: Pro-
ceedings of the SPIE Wavelet Conference, Orlando, FL, April 1999.
[58] I. Ziskind, M. Wax, Maximum likelihood localization of multiple sources by alternating projection, IEEE
Trans. Acoust. Speech Signal Process. ASSP-36 (10) (1988) 1553–1560.
[59] J. Jeong, W.J. Williams, Kernel design for reduced interference distributions, IEEE Trans. Signal Process. 42
(1992) 402–412.
[60] H. Qu, R. Wang, W. Qu, P. Zhao, Research on DOA estimation of multi-component LFM signals based on
the FRFT, Wirel. Sens. Network 2009 (3) (2009) 171–181.
[61] Y.D. Zhang, M.G. Amin, B. Himed, Direction-of-arrival estimation of nonstationary signals exploiting sig-
nal characteristics, in: International Conference Information Science Signal Processing Their Applications,
Montreal, Canada, July 2012.
[62] Y.D. Zhang, M.G. Amin, B. Himed, Altitude estimation of maneuvering targets in MIMO over-the-horizon
radar, in: IEEE Sensor Array and Multichannel Signal Processing Workshop, Stevens, NJ, June 2012,
pp. 261–264.
[63] H. Wang, M. Kaveh, Coherent signal-subspace processing for the detection and estimation of angles of arrival
of multiple wideband sources, IEEE Trans. Acoust. Speech Signal Process. ASSP-33 (1985) 823–831.
[64] B. Friedlander, J. Weiss, Direction ﬁnding for wide-band signals using an interpolated array, IEEE Trans.
Signal Process. 41 (1993) 1618–1634.
[65] G. Wang, X.-G. Xia, Iterative algorithm for direction of arrival estimation with wideband chirp signals, IEE
Proc. Radar Sonar Navig. 147 (5) (2000) 233–238.
[66] E. Fisher, A. Haimovich, R. Blum, D. Chizhik, L. Cimini, R. Valenzuela, MIMO radar: an idea whose time
has come, in: Proceedings of the IEEE Radar Conference, April 2004, pp. 71–78.
[67] J. Li, P. Stoica (Eds.), MIMO Radar Signal Processing, Wiley-IEEE Press, New York, NY, 2009.
[68] J. Li, P. Stoica, MIMO radar with colocated antennas, IEEE Signal Process. Mag. 25 (5) (2007) 106–114.
[69] M.L. Bencheikh, Y. Wang, Joint DOD-DOA estimation using combined ESPRIT-MUSIC approach in MIMO
radar, Electron. Lett. 46 (15) (2010).
[70] J. Chen, H. Gu, W. Su, A new method for joint DOD and DOA estimation in bistatic MIMO radar, Signal
Process. 90 (2010) 714–719.
[71] C. Duofang, C. Baixiao, Q. Guodong, Angle estimation using ESPRIT in MIMO radar, Electron. Lett. 44 (12)
(2008).
[72] M. Jin, G. Liao, J. Li, Joint DOD and DOA estimation for bistatic MIMO radar, Signal Process. 89 (2009)
244–251.
[73] N.J. Willis, H.D. Grifﬁths (Eds.), Advances in Bistatic Radar, SciTech Publishing, 2007.
[74] Y. Zhang, G.J. Frazer, M.G. Amin, Concurrent operation of two over-thehorizon radars, IEEE J. Sel. Topics
Signal Process. 1 (1) (2007) 114–123.

798
CHAPTER 17 DOA Estimation of Nonstationary Signals
[75] A. Hassanien, S.A. Vorobyov, A.B. Gershman, Moving target parameters estimation in noncoherent MIMO
radar systems, IEEE Trans. Signal Process. 60 (5) (2012) 2354–2361.
[76] R. Roy, T. Kailath, ESPRIT-estimation of signal parameters via rotational invariance techniques, IEEE Trans.
Acoust. Speech Signal Process. ASSP-37 (7) (1989) 984–995.

18
CHAPTER
Source Localization and Tracking
Yu Hen Hu
Department of Electronics and Communication Engineering, University of Wisconsin-Madison, Madison, WI, USA
3.18.1 Introduction
In this chapter, the task of source localization and tracking will be discussed. The goal of source
localization is to estimate the location of one or more events (e.g., earthquake) or targets based on
signals emitted from these locations and received at one or more sensors. It is often assumed that the
cross section of the target or the event is very small compared to the spread of the sensors and hence
the point source assumption is valid. If source locations move with respect to time, then tracking will
be performed to facilitate accurate forecasting of future target positions. Diverse applications of source
localizations have been found, such as Global Positioning System (GPS) [1,2], sonar [3,4], radar [5,6],
seismic event localization [7–9], brain imaging [10], teleconference [11,12], wireless sensor networks
[13–19], among many others.
The basic approach of source localization is geometric triangulation: Given the distance or angles
between the unknown source location and known reference positions, the coordinates of the source
locationscanbecomputedalgebraically.However,thesedistanceoranglemeasurementsoftenneedtobe
inferredindirectlyfromasignalpropagationmodel thatdescribesthereceivedsourcesignalasafunction
of distance and incidence angle between the source and the sensor. Such a model facilitates statistical
estimation of spatial locations of the sources based on features such as time of arrival, attenuation
of signal intensity, or phase lags. Speciﬁc features that may be exploited are also dependent on the
speciﬁc signal modalities such as acoustic signal, radio waves, seismic vibrations, infra-red light, or
visible light. In this chapter, various source signal propagation models will be reviewed, and statistical
inference methods will be surveyed.
Very often, source localization will be performed consecutively to track a moving source over time.
Using a dynamic model to describe the movement of the source, one may predict the probability distri-
bution function (pdf) of source location using previously received source signals. With this estimated
prior distribution of source location, Bayesian estimation may be applied to update the source location
using current sensory measurements. Thus, source localization and tracking are often intimately related.
In the remaining of this chapter, the basic idea of triangulation will ﬁrst be reviewed. Next, the signal
propagation and channel models will be introduced. Statistical methods that implicitly or explicitly
leveragethetriangulationapproachtoestimatesourcelocationswillthenbepresented.Bayesiantracking
methods such as Kalman ﬁlter will also be brieﬂy surveyed.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00018-7
© 2014 Elsevier Ltd. All rights reserved.
799

800
CHAPTER 18 Source Localization and Tracking
3.18.2 Problem formulation
Assume N sensors are deployed over a sensing ﬁeld with known positions. Speciﬁcally, the position of
thenthsensorisdenotedbyxn. Itisalsoassumedthatthereare Ktargetsinthesensingﬁeldwithunknown
locations {rk; 1 ≤k ≤K}. Each target is emitting a source signal denoted by sk(t) at time t. The nth
sensor will receive a delayed, and sometimes distorted version of the kth source signal yn,k(t). In general,
yn,k(t) is a function of the past source signal up to time t, {sk(t −m); 1 ≤k ≤K, m = 0, 1, . . .}, the
sensor locations xn, the target locations rk, as well as the propagation medium of the signal. This source
signal propagation model will be discussed in a moment. It is noted that prior to target localization, a
target detection task must be performed and the presence of K targets within the sensing ﬁeld must have
been estimated. The issues of target detection and target number estimation will not be included in this
discussion.
We further assume that the measurements at the nth sensor, denoted by yn(t) is a superimposition of
{yn,k(t); 1 ≤k ≤K}. That is,
yn(t) =
K

k=1
yn,k(t) + en(t),
(18.1)
where en(t) is the observation noise at the nth sensor. The objective of source localization is to estimate
the source locations {rk; 1 ≤k ≤K} based on sensor readings {yn(t −ℓ); 1 ≤n ≤N, ℓ= 0, 1, . . .}
given known sensor positions {xn; 1 ≤n ≤N} and the number of targets K.
3.18.3 Triangulation
In a sensor network source localization problem setting, the sensor locations are the reference positions.
Based on signals received at sensors from the sources, two types of measurements may be inferred:
(i) distance between each sensor and each source and (ii) incidence angle of a wavefront of the source
signal impinged upon a sensor relative to an absolute reference direction (e.g., north). In this section,
we will derive three sets of formula that make use of (a) distance only, (b) angle only, and (c) distance
and angle to deduce the source location. For convenience, the single source situation will be used, with
discussions on potential generalization to multiple sources.
3.18.3.1 Distance based triangulation
Denote dn to be the Euclidean distance between the position of the nth sensor xn and the (unknown)
source location r, namely, dn = ∥xn −r∥. dn may be estimated from the sensor observations yn(t) for
certain type of sensors such as laser or infrared light. One may write down N quadratic equations:
d2
n = ∥xn −r∥2 = ∥xn∥2 + ∥r∥2 −2xT
n r,
1 ≤n ≤N.
(18.2)
Subtracting both sides of each pair of successive equations above to eliminate the unknown term ∥r∥2,
it leads to N −1 linear equations
(xn+1 −xn)T r = 1
2

∥xn+1∥2 −∥xn∥2
−

d2
n+1 −d2
n

,
1 ≤n ≤N −1.
(18.3)

3.18.3 Triangulation
801
These N −1 linear systems of equations may be expressed in a matrix form:
Xr = d.
(18.4)
In general, the accuracy of the distance estimate may be compromised by estimation errors. Thus, a
more realistic model should include an estimation noise term:
Xr = d + e,
(18.5)
where e is a zero-mean, uncorrelated random noise vector such that
E{e} = 0,
cov{e} =  = diag

σ 2
1 , . . . , σ 2
N

.
Then r may be estimated using weighted least square method that seeks to minimize a cost function
			
			(Xr −d)T −1(Xr −d)
			
			
2
.
The leads to
ˆrDis,W LS =

XT −1X
−1
XT −1d.
(18.6)
3.18.3.2 Angle based triangulation
Denote θn to be incidence angle from the source into the nth sensor using the north direction as the
reference direction. We further assume that the angle is positive along the clock-wise direction. Referring
to Figure 18.1, it is easily veriﬁed that
0 =

−cos θn sin θn

(xn −r).
(18.7)
FIGURE 18.1
Geometric positions for Triangulation.

802
CHAPTER 18 Source Localization and Tracking
Rearranging terms and collecting all N equations, one has
⎡
⎢⎢⎢⎣
−cos θ1 sin θ1
−cos θ2 sin θ2
...
...
−cos θN sin θN
⎤
⎥⎥⎥⎦



C
· r =
⎡
⎢⎢⎢⎣

−cos θ1 sin θ1

x1

−cos θ2 sin θ2

x2
...

−cos θN sin θN

xN
⎤
⎥⎥⎥⎦



p
.
(18.8)
Or, in matrix formation:
C · r = p.
(18.9)
Similar to Eq. (18.5), the observation p may be contaminated with noise. As such, the source location
may be obtained via a weighted least square estimate. For the sake of notation simplicity, one may use
e to denote the noise vector as in Eq. (18.5). Then, the weighted least square estimation of r becomes:
ˆrAng,W LS =

CT −1C
−1
CT −1p.
(18.10)
3.18.3.3 Triangulation: generalizations
In Sections 3.18.3.1 and 3.18.3.2, single target triangulation localization algorithms for distance mea-
surements and incidence angle measurements have been discussed. Both of these situations lead to an
over-determined linear systems of Eqs. (18.5) and (18.9). Therefore, when both distance measurements
and incidence angle measurements are available, these two equations may be combined and solved
jointly.
When there are two or more sources (targets), a number of issues will need to be addressed. First of
all, when a sensor receives signals emitted from two or more sources simultaneously, it may not be able
to distinguish one signal from another if these signals overlap in time, space and frequency domains.
This is the traditional signal (source) separation problem [20–23]. Secondly, even individual sources
may be separated by individual sensors, which of the signals received by different sensors correspond
to the same source is not always easy to tell. This is the so called data association problem [24,25].
A comprehensive survey of these two issues is beyond the scope of this chapter.
As discussed earlier, while localization may be accomplished via triangulation, the measurements
of sensor to source distance or source to sensor incidence angle must be estimated based on received
signals. The mathematical model of the received source signals, known as the signal propagation model
will be surveyed in the next section.
3.18.4 Signal propagation models
Depending on speciﬁc applications, in many occasions, the source signal may be modeled as a narrow
band signal characterized by a single sinusoid:
sk(t) = Ak exp ( j2π fkt + φk),
(18.11)
where Ak is the amplitude, fk is the frequency, and φk is the phase. While for certain special cases that
all or a portions of these parameters are known, in most applications, they are assumed unknown.

3.18.4 Signal Propagation Models
803
In other occasions, the source signal may be a broad band signal which contains numerous harmonics
and is difﬁcult to be expressed analytically.
Between each source-sensor pair there is a communication channel whose characteristics depend
on speciﬁc medium (air, vacuum, water, etc.). The net effects of the communication channels on the
received signal yn,k(t) can be summarized in the following categories:
Attenuation: The amplitude of the source signal often attenuates rapidly as source to sensor distance
increases. Hence, examining relative attenuation of signal strength provides an indirect way to estimate
source to sensor distance. For a point source, the rate of attenuation is often inversely proportional
to ∥xn −rk∥. The communication channel between the sensor and the source may also be frequency
selective such that the attenuation rates are different from different frequency bands. For example, high
frequency sound often attenuate much faster than low frequency sound. Thus the amplitude waveform
as well as the energy of the source signal at the sensor may be distorted. If the signal propagation is
subject to multi-path distortion, the attenuation rate may also be affected. Yet another factor that affects
the measured amplitude of received signal is the sensor gain. Before the received analog signal is to be
digitized, its magnitude will be ampliﬁed with adaptive gain control to ensure the dynamic range of the
analog-to-digital converter (ADC) is not saturated. Furthermore, the signal strength attenuation may
not be uniform over all directions, and the point source assumption may not be valid at short distance.
Time delay: Denote ν to be the signal propagation speed in the corresponding medium, the time for the
source signal traveling to the sensor can be evaluated as
Dn,k = ∥xn −rk∥/ν.
(18.12)
However, the time delay due to signal propagation may be impacted by non-homogeneous mediums.
The consequence may be refraction or deﬂection of signal propagation and the accuracy of time delay
estimation may be compromised.
Phase distortion: The nonlinear phase distortion due to frequency selective channel property may also
distort the morphology of the signal waveform, making it difﬁcult to estimate any phase difference
between received signals at different sensors.
Noise: While the source signal travels to each sensor, it may suffer from (additive) channel noise or
interferences by other sources. It is often assumed that the background noise observed at each sensor is
a zero-mean, un-correlated, and wide-sense stationary random process, having Gaussian distribution.
Moreover, the background noise processes at different sensors are assumed to be statistically indepen-
dent to each other. Such assumptions may need to be modiﬁed for situations when the background noise
also include high energy impulsive noise or interferences.
A commonly used channel model in wireless communication theory is the convolution model that
models the frequency selective characteristics of the channel as a ﬁnite impulse response digital ﬁlter
{hn,k(m); 0 ≤m ≤M −1}. Thus, using the notation deﬁned in this chapter,
yn,k(t) =
M−1

m=0
hn,k(m)sk(t −m) + ϵn,k(t).
(18.13)
The channel parameters are functions of both the sensor and source locations. For source localization
application, above model is often simpliﬁed to emphasize speciﬁc features.

804
CHAPTER 18 Source Localization and Tracking
3.18.4.0.1
Received signal strength indicator (RSSI)
A popular simpliﬁed model concerns only amplitude attenuation:
yn,k(t) =
gn
∥xn −rk∥· sk(t).
(18.14)
Here the propagation delay, phase distortion, and noise are all ignored. Instead, gn is used to denote the
sensor gain of the nth sensor. Thus, one may write
yn(t) = gn ·
K

k=1
sk(t)
∥xn −rk∥+ en(t).
(18.15)
Averaging over a short time interval centered at the sampling time t, one may express the energy of the
received signal during this short period as
Yn(t) = 1
T
 t+T /2
t−T /2
y2
n(u)du ≃Gn ·
K

k=1
Sk(t)
∥xn −rk∥2 + ζn(t),
(18.16)
where Yn(t) is the received signal energy at time t at sensor n, Gn = g2
n, and
Sk(t) = 1
T
 t+T /2
t−T /2
[sk(u)]2du.
It is assumed that the K source signals are statistically, mutually independent, such that
1
T
 t+T /2
t−T /2
sk(u)s j(u)du ≃0,
k ̸= j.
Moreover, the background noise en(t) is also independent to the signal, besides being i.i.d. random
variables such that
1
T
 t+T /2
t−T /2
sk(u)e j(u)du ≃0,
∀k, j
and
1
T
 t+T /2
t−T /2
ek(u)e j(u)du =
ζn(t) k = j,
0
k ̸= j.
(18.17)
Here ζn(t) is a random variable with a χ2 distribution. However, as discussed in [19], for practical
purposes, ζn(t) can be modeled as a Gaussian random variable with a positive mean value μn > 0 and
variance σ 2
n .
Equations (18.15) or (18.16) are often used in source localization algorithms that are based on
Received Signal Strength Indicator (RSSI) [26,27] to infer the target location.

3.18.4 Signal Propagation Models
805
3.18.4.1 Time delay estimation
Time delay estimation [28,29] has a long history of signal processing applications [30–32]. It is assumed
that
yn,k(t) =
M−1

m=0
hn,k(t)sk(t −m −Dn,k) + ϵn,k(t).
(18.18)
If Dn,k can be estimated accurately, the source to sensor distance may be estimated using Eq. (18.12).
Thus, the key issue is to estimate Dn,k.
If the original source signal sk(t) and the received signal yn,k(t) are both available, then the time
delay may be estimated using a number of approaches.
Assume sk(t) and yn,k(t) are both zero-mean white sense stationary random processes over a time
interval [−T /2, T /2], the cross-correlation between them is deﬁned as
Rs,y(τ) = 1
T
 T /2
−T /2
sk(t)yn,k(t + τ)dt.
(18.19)
Substituting yn,k(t) in Eq. (18.18) into Eq. (18.19), and assume hn,k(t) = 1 if t = 0 and hn,k = 0
otherwise, one has
Rs,y(τ) = 1
T
 T /2
−T /2
sk(t)sk(t −Dn,k + τ)dt + 1
T
 T /2
−T /2
sk(t) · ϵn,k(t)dt



=0
= Rs,s(τ −Dn,k) ≤Rs,s(0) = 1
T
 T /2
−T /2
|sk(t)|2dt.
(18.20)
Therefore, a maximum likelihood estimate of the time delay Dn,k will be
Dn,k = argτ max Rs,y(τ).
(18.21)
There is a fundamental difﬁculty in applying Eq. (18.21) to estimate source to sensor signal prop-
agation delay: sk(t) may not be available at the sensor. This is often the case when the source is
non-cooperative such as an intruder. On the other hand, if the source is cooperative, it may transmit a
signal that consists of a time stamp. If the clocks at the sensor and at the source are synchronized as in
the case of the global positioning system (GPS) [1], the sensor can compare the receiving time stamp
against the sending time stamp and deduce the transit time without using cross correlation.
In some applications, the direction of the source is known but the distance between the source and
the sensor is to be measured. Then, a round trip signal propagation delay may be estimated using cross-
correlation method by emitting a signal sk(t) from the sensor toward the source and bounding back
to the sensor. Then, both the transmitted signal and received signal will be available at the sensor and
above cross-correlation method may be applied to estimate the source to sensor distance.
In general, when sk(t) is unavailable at the sensor, a difference of time of arrival from the same
source at different sensors will allow one to estimate the incidence angle of source signal. This is the
Time Difference of Arrival (TDoA) feature mentioned in literatures [33,34]. With TDoA, a Generalized
Cross Correlation (GCC) [28] may be applied to estimate δm,n(k) = Dm,k −Dn,k, m ̸= n.

806
CHAPTER 18 Source Localization and Tracking
Ideally, one would hope ym,k(t) = hm,k(0)sk(t −Dm,k) and yn,k(t) = hn,k(0)sk(t −Dn,k). As such,
one computes the cross correlation
Rm,n(τ) = 1
T
 T /2
−T /2
ym,k(t)yn,k(t + τ)dt
= 1
T
 T /2
−T /2
sk(t −Dm,k)sk(t −Dn,k + τ)dt
= Rss(τ −(Dn,k −Dm,k)) ≤Rss(0).
(18.22)
Thus,
ˆδm,n(k) = Dm,k −Dn,k = argτ max Rm,n(τ).
(18.23)
With the presence of channel noise ϵn,k(t) and channel model {hn,k(t)}, Knapp and Carter [28] proposed
to pre-ﬁlter ym,k(t) and yn,k(t) to improve the accuracy of the TDOA estimate by enhancing the signal
to noise ratio (SNR) of Rm,n(τ) estimate. Speciﬁcally, denote Ym,k(ω) and Yn,k(ω) respectively as the
Fourier transform of the received signal ym,k(t) and yn,k(t), and also denote Wm,k(ω) and Wn,k(ω)
respectively as the spectrum of the pre-ﬁlters for ym,k(t) and yn,k(t), the GCC is deﬁned as:
RGCC
m,n (τ) =
1
2πT
 T /2
−T /2
Wm,k(ω)W ∗
n,k(ω)Ym,k(ω)Y ∗
n,k(ω) exp ( jωτ)dω.
(18.24)
Once δm,n(k) is estimated, one has the following relation:
δm,n(k) · v = ∥xm −r∥−∥xn −r∥.
(18.25)
Hence TDOA provides a relative distance measure from the source to two different sensors. We note
by passing that Eq. (18.25) deﬁnes a parabolic trajectory for potential target location r.
3.18.4.2 Angle of arrival estimation
For narrow band source signal, if sensors are fully synchronized, phase difference between received
sensor signals may be used to estimate the incidence angle of source signal.
Assume a point source emitting a narrow band (single harmonic) signal described in Eq. (18.11).
Under a far ﬁeld assumption, that is
max
m,n ∥xm −xn∥≪min
n ∥r −xn∥
(18.26)
the waveform of the source signal can be modeled as a plane wave such that the incidence angle of the
source to each of the sensor nodes will be identical. This makes it easier to represent the time difference
of arrival as a steering vector which is a function of the incidence angle and the sensor array geometry.
Again, let north be a reference direction of the incidence angle θ which increases along the clock-
wise direction. Then a unit vector along the incidence angle can be expressed as [−sin θ, −cos θ]T .
The time difference of arrival between sensor nodes m and N can be expressed as:
tm,N(θ) =

xm −xN
T
 −sin θ
−cos θ

ν
(18.27)

3.18.4 Signal Propagation Models
807
Substitute the expression of a narrow band signal as shown in Eq. (18.11) into the expression of received
signal described in Eq. (18.18), one has
ym,k(t) = {hm,k(t)} ∗∗{sk(t −Dm,k)} + ϵm,k(t)
= {hm,k(t)} ∗∗{sk(t −(DN,k + tm,N(θk)))} + ϵm,k(t)
= Hm,k( fk) · Ak exp

j2π fk(t −(DN,k + tm,N(θk))) + φk

+ ϵm,k(t)
= Hk exp

−j2π fktm,N(θk)

· sk(t −DN,k) + ϵm,k(t),
(18.28)
where Hn,k( fk) = Hk is the frequency response of hn,k(t) evaluated at f = fk and is independent of
rk, and xn under the far ﬁeld assumption Eq. (18.26). Assume K = 1, then the received signal of all N
sensors may be represented by
yk(t) = aH
k (θk)sk(t −DN,k) · Hk + ϵk(t),
(18.29)
where
ak(θk) =

exp (−j2π fkt1,N(θk))
· · ·
exp (−j2π fktN−1,N(θk))
1H
is a steering vector with respect to a narrow band source with incidence angle θk using the signal received
at the Nth sensor as a reference. It represents the phase difference of the received sensor signals with
respect to a plane wave traveling at an incidence angle θk. With K narrow band sources, the received
signal vector than may be expressed as:
y(t) =
K

k=1
yk(t) = AH(θ)s(t) + ϵ(t),
(18.30)
where
A(θ) =

a1(θ1) a2(θ2) · · · aK (θK )H ,
s(t) =

s1(t −DN,1)H1
s2(t −DN,2)H2
· · · sK (t −DN,K )HK
H ,
and
ϵ(t) =
K

k=1
ϵk(t).
Equation (18.30) is the basis of many array signal processing algorithms [3,35,36] such as MUSIC
[37]. Speciﬁcally, the covariance matrix of y(t) may be decomposed into two parts:
Ryy = E{yyH} = A(θ)SAH(θ) + σ 2I = Rs + Rn,
(18.31)
where Rs and Rs are the signal and noise covariance matrix respectively. In particular, Rs has a rank
equal to K. In practice, one would estimate the covariance matrix from received signal and perform
eigenvalue decomposition:
Ryy = 1
T
T −1

t=0
y(t)yH(t) = UssUH
s + UnnUH
n ,
(18.32)

808
CHAPTER 18 Source Localization and Tracking
where s = diag{λ1, . . . , λK } are the largest K eigenvalues and columns of Us are corresponding
eigenvectors. The K dimensional subspace spanned by columns of the Us matrix is called the signal
subspace. On the other hand, n = diag{λK+1, . . . , λN} are the remaining N −K eigenvalues. The
N −K dimensional subspace spanned by columns of the Un matrix is called the noise subspace. Deﬁne
vk(θ) =

exp (−j2π fkt1,N(θ)) · · · exp (−j2π fktN−1,N(θ)) 1H
(18.33)
as a generic steering vector, the MUSIC method evaluates the function
PMUSIC(θ) =
∥v(θ)∥2
∥vH(θ)Un∥2 .
(18.34)
This MUSIC spectrum then will show high peaks at θ = θk, 1 ≤k ≤K.
3.18.5 Source localization algorithms
3.18.5.1 Bayesian source localization based on RSSI
For convenience of discussion, let us rewrite Eq. (18.16) here after a linear transformation of the random
variables
Zn(t) = (Yn(t) −μn)/σn
and
˜ζn(t) = (ζn(t) −μn)/σn.
(18.35)
Then,
⎡
⎢⎢⎢⎣
Z1(t)
Z2(t)
...
Z N(t)
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
G1/(σ1 · ∥x1 −r1∥2)
G1/(σ1 · ∥x1 −r2∥2) · · · G1/(σ1 · ∥x1 −rK ∥2)
G2/(σ2 · ∥x2 −r1∥2)
G2/(σ2 · ∥x2 −r2∥2) · · · G2/(σ2 · ∥x2 −rK ∥2)
...
...
...
...
G N/(σN · ∥xN −r1∥2) G N/(σN · ∥xN −r2∥2) · · · G N/(σN · ∥xN −rK ∥2)
⎤
⎥⎥⎥⎦
×
⎡
⎢⎢⎢⎣
S1(t)
S2(t)
...
SK (t)
⎤
⎥⎥⎥⎦+
⎡
⎢⎢⎢⎣
˜ζ1(t)
˜ζ2(t)
...
˜ζN(t)
⎤
⎥⎥⎥⎦
(18.36)
or in matrix notation
z = Hs + ˜ζ.
(18.37)
Since ζ is a normalized Gaussian random vector with zero mean and identity matrix as its covariance,
the likelihood function that z is observed at N sensors, given the K source signal energy and source
locations {rk, Sk(t); 1 ≤k ≤K} can be expressed as:
L(rk, Sk(t); 1 ≤k ≤K) = P{z|rk, Sk(t); 1 ≤k ≤K} ∝exp

−1
2(z −Hs)T (z −Hs)

.
(18.38)

3.18.5 Source Localization Algorithms
809
A maximum likelihood (ML) estimate of {rk, Sk(t); 1 ≤k ≤K} may be obtained by maximizing L or
equivalently, minimizing the negative log likelihood function
ℓ(rk, Sk(t); 1 ≤k ≤K) = −log L = ∥z −Hs∥2.
(18.39)
Setting the gradient of ℓagainst s equal to 0, one may express the estimate of the source signal energy
vector as
ˆs = H†z,
(18.40)
where H† is the pseudo inverse of the H matrix. Substituting Eq. (18.40) into Eq. (18.39), one has
ℓ(rk; 1 ≤k ≤K) = ∥(I −HH†)z∥2.
(18.41)
Equation (18.41) is signiﬁcant in several ways: (a) The number of unknown parameters is reduced from
3K to 2K assuming that the dimension of rk is 2. (b) To minimize ℓ, the source locations should be
chosen such that the (normalized) energy vector z falls within the subspace spanned by columns of the
H matrix as close as possible. In [19], this property is leveraged to derive a multi-resolution projection
method for solving the source locations.
In deriving the ML estimates of source locations, no prior information about source locations is used.
If, as in a tracking scenario, the prior probability of source locations, p(rk; 1 ≤k ≤K) is available,
then the a posterior probability may be expressed as:
P{rk, Sk(t); 1 ≤k ≤K|z} ∝p(rk; 1 ≤k ≤K) · exp

−1
2(z −Hs)T (z −Hs)

.
(18.42)
Maximizing above expression then will lead to the Bayesian estimate of the source locations and
corresponding source emitted energies during [t −T /2, t + T /2].
3.18.5.2 Non-linear least square source localization using RSSI
Assume a scenario of a single source (K = 1). If one ignores the noise energy term, Eq. (18.16) can be
expressed as (using notation in Eq. (18.35))
∥xn −r∥2 = S ·
Gn
σn · Zn(t)
1 ≤n ≤N.
(18.43)
Based on this approximated distance, the source location r and the source energy S may be estimated.
3.18.5.2.1
Nonlinear quadratic optimization
Based on Eq. (18.43), one evaluate the ratio
∥xn −r∥2
∥xm −r∥2 = Gn
Gm
· σm · Zm(t)
σn · Zn(t) = κ2
n,m,
n ̸= m.
(18.44)
After simpliﬁcation, above equation can be simpliﬁed as
∥r −cm,n∥= ρm,n
where cm,n = xn −κ2
m,nxm
1 −κ2m,n
and ρm,n = κm,n∥xn −xm∥
1 −κ2m,n
.
(18.45)

810
CHAPTER 18 Source Localization and Tracking
For convenience, one may set m = n + 1 and writes cn, and κn instead of cm,n, and κm,n. The target
location may be solved by minimizing a nonlinear cost function:
J(r) =
N−1

n=1
(∥r −cn∥−ρn)2.
(18.46)
In Eq. (18.46), it is assumed that κn ̸= 1. It can easily be updated to deal the situation when κn →1.
3.18.5.2.2
Least square solution
If one ignores the background noise, Eq. (18.45) can be seen as a distance measurement of the unknown
source location r. Recall the distance based triangulation method described in Section 3.18.3.1. One may
considersquaringbothsidesofEq.(18.45)usingsensorreadingsofsensorindicesn, n+1,andm, m+1:
∥r −cn,n+1∥2 = ρ2
n,n+1 ⇒∥r∥2 = 2rT cn,n+1 + ρ2
n,n+1 −∥cn,n+1∥2,
∥r −cm,m+1∥2 = ρ2
m,m+1 ⇒∥r∥2 = 2rT cm,m+1 + ρ2
m,m+1 −∥cm,m+1∥2.
After simpliﬁcation, one has
(cn,n+1 −cm,m+1)T r = ρ2
m,m+1 −ρ2
n,n+1 + ∥cn,n+1∥2 −∥cm,m+1∥2.
(18.47)
Combining above equations for different indices of m, n, one may solve for r by solving an over-
determined linear system
C r = h ⇒ˆrLS = C†h.
(18.48)
3.18.5.2.3
Source localization using table look-up
Considerasingletarget(K = 1)scenario.Thenormalizedsensorobservationvectorz(t)canberegarded
as a signature vector of a source at location r. Hence, by collecting the corresponding signature vectors
for all possible locations r in a sensing ﬁeld, the source location may be estimated using table look-up
method. To account for variations of source intensity, the signature vector may be normalized to have
a unity norm.
3.18.5.3 Source localization using time difference of arrival
Denote
dN = ∥xN −r∥.
(18.49)
Substituting Eq. (18.49) into Eq. (18.25) with m = N, one has
∥r −xn∥= δn · v + dN,
n = 1, 2, . . . , N −1.
(18.50)
Squaring both sides of above equation for both indices m and n,
∥r∥2 + ∥xm∥2 −2xT
mr = (δm · v)2 + d2
N + 2dNδmv,
∥r∥2 + ∥xn∥2 −2xT
n r = (δn · v)2 + d2
N + 2dNδnv.

3.18.5 Source Localization Algorithms
811
Subtracting both sides of above equations, it yields (for 1 ≤m, n ≤N −1)
(xn −xm)T r + (δn −δm) · v · dN = 1
2

∥xn∥2 −∥xm∥2 + (δ2
m −δ2
n) · v2
= pn,m.
Restricting m = n + 1, one may express above into a matrix format:
⎡
⎢⎢⎣
(x1 −x2)T
(δ1 −δ2) · v
(x2 −x3)T
(δ2 −δ3) · v
· · ·
· · ·
(xN−1 −xN)T (δN−1 −δN) · v
⎤
⎥⎥⎦
 r
dN

=
⎡
⎢⎢⎢⎣
p1,2
p2,3
...
pN−1,N
⎤
⎥⎥⎥⎦.
(18.51)
The source location r may be solved from above equation using least square estimate subject to the
constraint quadratic equality constraint according to Eq. (18.49):

rT dN

⎡
⎣
1 0 0
0 1 0
0 0 −1
⎤
⎦
 r
dN

+

−2xT
N 0
  r
dN

+ ∥xN∥2 = 0.
(18.52)
3.18.5.4 Source localization using angle of arrival
When there is only a single source in the sensing ﬁeld, the angle based triangulation method discussed
in Section 3.18.3.2 can be applied to estimate the source location. With more than one sources, a data
correspondence problem must be resolved. Such a problem has been addressed in terms of N-Ocular
stereo [38].
Assume that each of the nth sensor detects K distinct incidence angles from the K sources. Thus,
there are N · K incidence angles {θn,k; 1 ≤n ≤N, 1 ≤k ≤K}. If at the nth sensor, it receives a source
signal with incidence angle θn,k, then the source location may be expressed as
rk = xn + α · u(θn,k) = xn + α ·
 sin θn,k
cos θn,k

,
α > 0.
(18.53)
Similarly, for the mth sensor, for the ℓth incidence angle, the source location is at
rℓ= xm + β · u(θm,ℓ) β > 0.
Therefore, if these two sources are the same source (e.g., rk = rℓ), then one must have a valid solution,
namely, α > 0, and β > 0 to the following linear system of equations:
xm −xn = αu(θn,k) −βu(θm,ℓ) =
 sin θn,k sin θm,ℓ
cos θn,k cos θm,ℓ
  α
−β

.
(18.54)
The solution can be represented expressively as:
 α
β

=
 −cos θm,ℓsin θm,ℓ
−cos θn,k sin θn,k

· (xm −xn).
(18.55)
If both α and β are positive, then xn + αu(θn,k) is a potential source location. Since it is derived from
observation of two sensors, it is called a bi-ocular solution. Otherwise, the solution will be discarded.
Substituting the K 2 pairs angles {(θn,k, θm,ℓ); 1 ≤k, ℓ≤K} into Eq. (18.55), one may obtain up to K 2

812
CHAPTER 18 Source Localization and Tracking
valid solutions which are candidates for the K possible source locations, assuming there is no occlusion.
The collection of these solutions will be denoted by P(2) indicating they are consistent with two sensor
observations.
Now for a third sensor at xq with incidence angles {θq,k; 1 ≤k ≤K}, one may test if any of the
potential solutions in P(2), r, lies in any of the K incidence rays originated from xq. This is easily
accomplished by evaluating
uT (θq,k)(r −xq) = uT (θq,k) · {αu(θq,k)} = α.
(18.56)
If the resulting α > 0, then the candidate solution r will be promoted into a tri-ocular solution set
P(3) for being consistent with 3 sensor observations. Repeat above procedure until P(N) is obtained
or when the size of the solution set reduces to K. Then the procedure is terminated and the K source
positions are obtained.
Two issues will need to be addressed when applying above procedures: (a) A false matching solution
may be obtained where many incidence rays intersect but no source exists. Fortunately, each incidence
ray passing through a false matching position should have two or more matching points. Thus, a false
matching solution may be identiﬁed if every incidence rays passing through it have more than one
matching point. (b) The azimuth incidence angle estimates may be inaccurate. Hence the intersections
may not coincide at the same position. Several remedies of this problem have been discussed in [38].
In practice, one may partition the sensing ﬁeld into mesh grids whose size roughly equal to the angle
estimation accuracy. The position of a potential N-ocular solution then will be registered with the
corresponding mesh grid rather than a speciﬁc point. A mesh grid will be included into P(m) if there
are m intersections fall within its range.
3.18.6 Target tracking algorithm
So far, in this chapter, source localization is performed based solely on a single snapshot at time t of
sensor readings at N sensors in the sensing ﬁeld. If past sensor readings about the same sources can be
incorporated, the source location estimates are likely to be much more accurate.
3.18.6.1 Dynamic and observation models
Statistically, tracking is modeled as a sequential Bayesian estimation problem of a dynamic system
whose states obey a Markov model. In the context of source localization and tracking, the dynamic
system that describes a single target moving in a 2D plane has the form
 r(t)
˙r(t)

= z(t) = Fz(t −1) + Gw(t)
(18.57)
=
⎡
⎢⎢⎣
1 0
T0
0
0 1
0
T0
0 0
1
0
0 0
0
1
⎤
⎥⎥⎦
 r(t −1)
˙r(t −1)

+
⎡
⎢⎢⎣
T 2
0 /2
0
T0
0
0
T 2
0 /2
0
T0
⎤
⎥⎥⎦w(t),
where T0 is the time duration between t and t −1, and w(t) is a zero mean Gaussian random number
with variance σ 2
w which models the acceleration.

3.18.6 Target Tracking Algorithm
813
Signal received at N sensors as a function of source location r and source signal s(t) gives the
observation model. Examples of observation model include Eqs. (18.15) and (18.18). These nonlinear
models may be expressed as:
y(t) = h(z(t)) + v(t),
(18.58)
where the observation noise v(t) is a zero mean Gaussian random variable with variance σ 2
v . Sometimes,
intermediate observation model, such as sensor to source distance estimate Eq. (18.12), Eq. (18.25), or
source signal incidence angle estimate such as Eq. (18.53).
In general, the sensor observation y(t), or the intermediate measurements are highly nonlinear equa-
tions of the source position and speed z(t). Alternatively, one may apply methods discussed in this
chapter to estimate z(t) based only on current observation y(t), and express a derived observation
equation as:
y(t) = H · z(t) + v(t) =

 I 0 
z(t) + v(t).
(18.59)
3.18.6.2 Sequential Bayesian estimation
The state transition described in Eqs. (18.57) and (18.58) can be described by a Markov chain model
such that
P{z(t)|z(t −1), . . . , z(0)} = P{z(t)|z(t −1)}
and
P{y(t)|z(t), z(t −1), . . . , z(0)} = P{y(t)|z(t)}.
As such, it is easily veriﬁed that
P{z(t), . . . , z(0); y(t), . . . , y(1)} = P{z(0)} ·
t
m=1
P{y(m)|z(m)} · P{z(m)|z(m −1)}.
(18.60)
Denote Y(t) = {y(t), y(t −1), . . . , y(0)} to be the observations up to time t, and P{z(t)|Y(t)} to be the
conditional probability of z(t) given Y(t). Given the state estimation (location and speed of the source)
at previous time step P{z(t −1)|Y(t −1)}, the dynamic model Eq. (18.57) allows the prediction of the
location and speed of the source at time t:
P{z(t)|Y(t −1)} =

P{z(t)|z(t −1)}P{z(t −1)|Y(t −1)}dz(t −1),
(18.61)
where
P{z(t)|z(t −1)} ∼N

F · z(t −1), σ 2
wGGT 
(18.62)
has a normal distribution. Similarly,
P{y(t)|z(t)} ∼N

h(z(t)), σ 2
v I

.
(18.63)
Applying Bayesian rule, one has
P{z(t)|Y(t)} = P{z(t)|y(t)}P{z(t)|Y(t −1)}
P{y(t)|Y(t −1)}
=
P{z(t)|y(t)}P{z(t)|Y(t −1)}
 
P{y(t)|z(t)}P{z(t)|Y(t −1)}dz(t).
(18.64)

814
CHAPTER 18 Source Localization and Tracking
3.18.6.3 Kalman ﬁlter
Based on the sequential Bayesian formulation, one may deduce the well-known Kalman ﬁlter for the
linear observation model (Eq. (18.59)). Speciﬁcally, the Kalman ﬁlter computes the mean and covariance
matrix of the probability distribution
P{z(t)|Y(t)} ∼N(ˆz(t), P(t)),
where
ˆz(t) = E{P{z(t)|Y(t)} and P(t) = E

(z(t) −ˆz(t))(z(t) −ˆz(t))T 
.
3.18.6.3.1
Prediction phase
Given ˆz(t −1), the dynamic Eq. (18.57) allows one to predict the a priori estimate of the current state:
z(t|t −1) = F · ˆz(t −1).
(18.65)
Hence,
z(t) −z(t|t −1) = F · z(t −1) + w(t) −F · ˆz(t −1) = F(z(t −1) −ˆz(t −1)).
The corresponding prediction error covariance matrix is:
P(t|t −1) = E

(z(t) −z(t|t −1))(z(t) −z(t|t −1))T 
= FP(t −1)FT + σ 2
wI.
(18.66)
Equations (18.65) and (18.66) constitute the prediction phase of a Kalman ﬁlter.
3.18.6.3.2
Update phase
Given the predicted source position and speed z(t|t −1), each sensor may compute an expected received
signal y(t|t −1) = H · z(t|t −1) and the corresponding innovation (prediction error) when compared
to the actual received signal y(t) as
˜y(t) = y(t) −y(t|t −1) = y(t) −H · z(t|t −1).
(18.67)
The corresponding covariance matrix then is
Q(t) = E

˜y(t)˜yT (t)

= HP(t|t −1)HT + σ 2
v I.
(18.68)
Applying least square principle, the optimal Kalman gain matrix may be expressed as:
K(t) = P(t|t −1)HT Q−1(t).
(18.69)
Finally, the update equation of the state estimation is:
ˆz(t) = z(t|t −1) + K(t)˜y(t) = (I −K(t)H)z(t|t −1) + K(t)y(t).
(18.70)
In other words, the optimal estimate of the source location and speed is a linear combination of the pre-
dicted location and speed and a correction term based on sensor observations. Moreover, the covariance
matrix of estimation error will also be updated:
P(t) = (I −K(t)H)P(t|t −1).
(18.71)

References
815
3.18.6.3.3
Nonlinear observation model
TheKalmanﬁltertrackingequationsdevelopedsofarisbasedonthelinearobservationmodelEq.(18.59).
It facilitates the close-form expression of the prediction error covariance matrix Eq. (18.68). However,
as discussed earlier, many practical observation models are non-linear in nature. A number of techniques
have been developed to deal with this challenge.
With an extended Kalman ﬁlter (EKF), the nonlinear observation model will be replaced by an
approximated linear model such that
Q(t) = HP(t|t −1)HT + σ 2
v I,
K(t) = P(t|t −1)HT Q−1(t),
P(t) = (I −K(t)H)P(t|t −1),
where H = ∇zz(t)|z(t|t−1). There are also Unscented Kalman ﬁlter (UKF) [39] that further enhance the
accuracy of the EKF.
For extremely nonlinear models, particle ﬁlter [18,40,41] may be applied to facilitate more accurate,
albeit more computationally intensive, tracking. Brieﬂy speaking, in a particle ﬁlter, the probability
distribution is approximated by a probability mass function (pmf) evaluated at a set of randomly sampled
points (particles). Then, the sequential Bayesian estimation is carried out on individual particles.
3.18.7 Conclusion
In this chapter, source localization algorithms in the context of wireless sensor network are discussed.
A distinct approach of this chapter is to separate the received source signal model from the basic
triangulation algorithms. The development also revealed basic relations among several well studied
families of localization algorithms. The signiﬁcance of tracking algorithm in the localization task is
also discussed and some basic tracking algorithms are reviewed.
Relevant Theory: Signal Processing Theory, Machine Learning Statistical Signal processing, and Array
Signal Processing
See Vol. 1, Chapter 2, Continuous-Time Signals and Systems
See Vol. 1, Chapter 3, Discrete-Time Signals and Systems
See Vol. 1, Chapter 4, Random Signals and Stochastic Processes
See Vol. 1, Chapter 11, Parametric Estimation
See Vol. 1, Chapter 19 A Tutorial Introduction to Monte Carlo Methods
See this volume, Chapter 5, Distributed Signal Detection
See this volume, Chapter 7, Geolocation—Maps, Measurements, Models, and Methods
See this volume, Chapter 19, Array Processing in the Face of Nonidealities
References
[1] P. Daly, Electron. Commun. Eng. J. 5 (1993) 349–357.
[2] B.W. Parkinson, J.J. Spilker (Eds.), Global Positioning System: Theory and Applications, vol. 1, American
Institute of Astronautics and Aeronautics, 1996.

816
CHAPTER 18 Source Localization and Tracking
[3] N.L. Owsley, in: S. Haykin (Ed.), Array Signal Processing, Prentice-Hall, Englewood-Cliffs, NJ, 1991.
[4] S. Zhou, P. Willett, IEEE Trans. Signal Process. 55 (2007) 3104–3115.
[5] P. Valin, A. Jouan, E. Bosse, in: Proc. SPIE-1999 Sensor Fusion: Architectures, Algorithms, and Applications
III, vol. 3719, Society of Photo-Optical Instrumentation Engineers, Bellingham, WA, USA, Orlando, FL,
USA, 1999, pp. 126–138.
[6] G.L. Duckworth, M.L. Frey, C.E. Remer, S. Ritter, G. Vidaver, in: Proc. SPIE, vol. 2344, The International
Society for Optical Engineering, 1995, pp. 16–29.
[7] C. Friedrich, U. Wegler, Geophys. Res. Lett. 32 (2005) L14312.
[8] D. Gajewski, K. Sommer, C. Vanelle, R. Patzig, Geophysics 74 (2009) WB55–WB61.
[9] J. Zhao, Seismic signal processing for near-ﬁeld source localization, Ph.D. Dissertation, University of Cali-
fornia, Los Angeles, 2007.
[10] R.R. Ramirez, Scholarpedia 3 (11) (2008) 1073.
[11] B.C. Basu, S.A. Pentland, in: Proceedings of ICASSP’01, vol. 5, pp. 3361–3364.
[12] P. Aarabi, A. Mahdavi, in: Proceedings of ICASSP’02, IEEE, 2002, pp. 273–276.
[13] J.C. Chen, K. Yao, R.E. Hudson, IEEE Signal Process. Mag. 19 (2002) 30–39.
[14] J. Chen, R.E. Hudson, K. Yao, IEEE Trans. Signal Process. 50 (2002) 1843–1854.
[15] Y.H. Hu, X. Sheng, D. Li, in: IEEE Workshop on Multimedia Signal Processing, IEEE, St. Thomas, Virgin
Island, 2002.
[16] D. Li, Y.H. Hu, EURASIP J. Appl. Signal Process. (2003) 321–337.
[17] X. Sheng, Y.H. Hu, in: Proceedings of the International Symposisum on Information Processing in Sensor
Networks (IPSN’03), Springer-Verlag, Palo Alto, CA, 2003, pp. 285–300.
[18] X. Sheng, Y.H. Hu, in: Proceedings of ICASSP’04, vol. 3, IEEE, Montreal, Canada, 2004, pp. 972–975.
[19] X. Sheng, Y.H. Hu, IEEE Trans. Signal Process. 53 (2005) 44–53.
[20] S. Amari, A. Cichocki, H.H. Yang, in: Proceedings of Advances in Neural Information Processing Systems
(NIPS’96), MIT Press, 1996, pp. 757–763.
[21] J.F. Cardoso, Proc. IEEE 86 (1998) 2009–2025.
[22] S.C. Douglas,in: Y.H. Hu, J.N. Hwang (Eds.), Handbook of Neural Network Signal Processing, CRC Press,
Boca Raton, FL, 2001 (Chapter 7).
[23] G. Gelle, M. Colas, G. Delaunay, Mech. Syst. Signal Process. 14 (2000) 427–442.
[24] K.-C. Chang, C.-Y. Chong, Y. Bar-Shalom, IEEE Trans. Automatic Control 31 (1986) 889–897.
[25] M. Ito, S. Tsujimichi, Y. Kosuge, in: Proceedings of the International Conference on Industrial Electronics,
Control and Instrumentation, New Orleans, LA, vol. 3, pp. 1260–1264.
[26] C. Savarese, J.M. Rabaey, J. Beutel, in: Proceedings of ICASSP’2001, IEEE, Salt Lake City, UT, 2001,
pp. 2676–2679.
[27] V. Seshadri, G. Zaruba, M.A. Huber, in: Proceedings of the International Conference on Pervasive Computing
and Communications (PerCom’05), IEEE, 2005, pp. 75–84.
[28] C.H. Knapp, G.C. Carter, IEEE Trans. Acoust. Speech Signal Process. 24 (1976) 320–327.
[29] G.C. Carter (Ed.), Coherence and Time Delay Estimation, IEEE Press, 1993.
[30] Y.T. Chan, R.V. Hattin, J.B. Plant, IEEE Trans. Acoust. Speech Signal Process. 26 (1978) 217–222.
[31] T.L. Tung, K. Yao, C.W. Reed, R.E. Hudson, D. Chen, J.C. Chen, in: Proceedings of SPIE, vol. 3807, The
International Society for Optical Engineering, 1999, pp. 220–233.
[32] J. Benesty, J. Chen, Y. Huang, IEEE Trans. Speech Audio Process. 1542 (2004) 509–519.
[33] F. Gustafsson, F. Gunnarsson, in: Proceedings of ICASSP’03, vol. 6, IEEE, 2003, pp. 553–556.
[34] L. Yang, K.C. Ho, IEEE Trans. Signal Process. 57 (2009) 4598–4615.
[35] H. Krim, M. Viberg, IEEE Signal Process. Mag. 1583 (1996) 67–94.
[36] E. Tuncer, B. Friedlander (Eds.), Classical and Modern Direction-of-Arrival Estimation, Academic Press,
2010.

References
817
[37] P. Stoica, A. Nehorai, IEEE Trans, Acoust. Speech Signal Process. 37 (1989) 720–741.
[38] T. Sogo, H. Ishiguro, M.M. Trivedi, in: Proceedings of IEEE Workshop Omnidirectional Vision, IEEE, 2000,
pp. 153–160.
[39] S.J. Julier, J.K. Uhlmann, Proc. IEEE 92 (2004) 401–422.
[40] M. Arulampalam, S. Maskell, N. Gordon, T. Clapp, IEEE Trans. Signal Process. 50 (2002) 174–188.
[41] X. Sheng, Y.H. Hu, in: Proceedings of 4th International Symposium on Information Processing in Sensor
Networks (IPSN ’05), IEEE, Los Angeles, CA, 2005.

19
CHAPTER
Array Processing in the Face
of Nonidealities
Mário Costa*, Visa Koivunen*, and Mats Viberg†
*Department of Signal Processing and Acoustics, School of Electrical Engineering,
Aalto University/SMARAD CoE, Finland
†Division of Signal Processing and Antennas, Chalmers University of Technology, Sweden
3.19.1 Introduction
In array signal processing one is typically interested in characterizing, synthesizing, enhancing or atten-
uating certain aspects of propagating waveﬁelds by employing a collection of sensors, known as a sensor
array. Characterizing a propagating waveﬁeld refers to determining its spatial spectrum, i.e., the angular
distribution of energy, so that information regarding the location of the sources generating the waveﬁeld
can be obtained, for example [1]. Synthesizing or producing a waveﬁeld refers to generating a propa-
gating waveﬁeld with a desired spatial spectrum in order to focus the transmitted energy towards certain
locations in space. Finally, attenuating or enhancing a received waveﬁeld based on its spatial spectrum
refers to the ability of canceling interfering sources or improving the signal-to-interference-plus-noise
ratio (SINR) and maximizing the energy received from certain directions. Examples of characterization,
synthesis and enhancement of propagating waveﬁelds include direction-of-arrival (DoA) estimation,
angle spread estimation in channel sounding as well as transmit and receive beamforming [2].
Traditionally, array signal processing has found applications in radar and sonar, defense systems,
signal intelligence (SIGINT), and surveillance as well as imaging and biomedical applications. Radioas-
tronomy also employs many array processing techniques [3]. More recently, it has been used in wireless
communication systems, in particular in basestations that utilize beamforming techniques in control-
ling the interference and enhancing the signal quality. Moreover, creating advanced, measurement-based
models of the radio channels in communication systems such as long-term evolution (LTE) requires
capturing the directional properties of the propagation channel [4]. In global navigation satellite sys-
tems, receive beamforming techniques for anti-jamming purposes are often employed as well as DoA
estimation techniques in indoor navigation systems [5]. See also Chapter 20 “Applications of Array
Signal Processing” in this volume.
The propagating waveﬁeld is typically parameterized by the angular location of sources generating
such a waveﬁeld, their polarization state, bandwidth, delay proﬁle, and Doppler shift. These are called
waveﬁeld parameters and are given in terms of a reference system, which in the case of angular infor-
mation is typically assumed to be the coordinate system common to the sensor array and propagating
waveﬁeld. Such a reference system is typically assumed to be within the physical extent of the sensor
array, known as array aperture, and the angular parameterization of the propagating waveﬁeld refers
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00019-9
© 2014 Elsevier Ltd. All rights reserved.
819

820
CHAPTER 19 Array Processing in the Face of Nonidealities
to the DoAs or directions-of-departure (DoDs), characterizing the spatial spectrum of the waveﬁeld
received or transmitted by the sensor array.
In addition to the propagating waveﬁeld, a model describing the response of the sensor array as a
function of the waveﬁeld parameters, such as the angle-of-arrival or departure, is typically required in
array processing. Such a model is deﬁned in terms of array steering vectors and allows us to estimate the
waveﬁeld parameters from data acquired by the sensor array, and use them to design a beamformer at
the receiver. Similarly, steering vectors are used to synthesize a desired waveﬁeld and employ transmit
beamforming techniques. In order to simplify these signal processing tasks and models, the standard
approach to array signal processing assumes rather idealistic array steering vector models. In particular,
all array elements are typically assumed to have similar omnidirectional gain patterns and the employed
sensor array is assumed to have a regular geometry such as a uniform linear array (ULA), a uniform rect-
angular array (URA), or a uniform circular array (UCA). The resulting array steering vector models have
then a very convenient form for various signal processing tasks; see Section 3.19.2. However, most of
real-world sensor arrays are not well described using such an ideal array model. In fact, elements of real-
world arrays have individual beampatterns, not necessarily omnidirectional, and may be subject to severe
mutual coupling. Phase centers of the elements may not be exactly in the assumed positions. Moreover,
mounting platform reﬂections and cross-polarization effects are also very common in real-world arrays.
In practical array processing applications employing ideal array steering vector models leads to
a performance degradation and typically to loss of optimality for optimal array processors [6]. The
limiting factor in the performance of high-resolution array processing algorithms as well as in the
tightness of related theoretical performance bounds is known to be the accuracy of the employed array
model rather than measurement noise [6,7]. Similarly, misspeciﬁed sensor array models may lead to a
severe performance loss of beamforming techniques. Effects include steering energy towards unwanted
directions, cancelation of the signal of interest (SOI) as well as ampliﬁcation of interfering sources [8].
In this chapter we present techniques that allow the practitioner to acquire a realistic array steer-
ing vector model by taking into account array nonidealities such as mutual coupling, mounting plat-
form reﬂections, cross-polarization effects, errors in element positions as well as individual directional
beampatterns. This facilitates achieving optimal performance in the presence of nonidealities as well as
mitigating problems related to beam-steering, SOI and interference cancellation. We also describe how
the various approaches can be applied in the context of high-resolution direction ﬁnding and beam-
forming. Emphasis is given to the case when the array response, along with its nonidealities, is obtained
from array calibration measurements. However, the methods and techniques discussed in this chapter are
also applicable when the array response is obtained from EM simulation software, or even when ideal
array models are employed. Typically, EM simulation software does not capture manufacturing errors
while calibration measurement noise is unavoidable in array calibration measurements. Techniques for
denoising array calibration measurements are included in this chapter as well. Sensor failure in array
signal processing is not addressed herein, and the interested reader is referred to [9,10] and references
therein. Many of such techniques aim at determining the inoperable sensors’ outputs from the available
array snapshots, and proceed with the array processing tasks as if the sensor array were fully operable.
Then, realistic array steering vector models are still required and the methods discussed herein may
also be useful in such circumstances.
The classiﬁcation used in this chapter for the various techniques capable of dealing with array
nonidealities is given in Figure 19.1. We classify the methods trying to capture the nonidealities as

3.19.2 Ideal Array Signal Models
821
FIGURE 19.1
Classiﬁcation of techniques for array processing in the face of nonidealities.
model-driven and data-driven techniques. Robust methods are a third class of methods that acknowl-
edge that the array model contains errors without trying to characterize such nonidealities. Instead,
robust estimation methods trade-off desirable properties such as high-resolution or optimality for reli-
ability in the face of uncertainties in the array response. In model-driven techniques, the array non-
idealities are described using an explicit formulation for each nonideality. The parameters of such a
formulation may be estimated from array calibration measurements or simultaneously with waveﬁeld
parameters. The latter approach is called auto-calibration technique [7,11–14]. Data-driven techniques
use array calibration data as a starting point and capture the nonidealities implicitly by using basis
function expansion, interpolation, approximation or nonparametric estimation techniques. Data-driven
methods include local interpolation of array calibration data [6], array interpolation technique [15–17],
and manifold separation technique [18,19] which stems from the waveﬁeld modeling principle [20–22].
These techniques do not employ any explicit model for the array nonidealities. In data-driven techniques
the array nonidealities are described by the basis function coefﬁcients, which may be estimated from
array calibration measurements. Hence, they allow the practitioner to develop array processing algo-
rithms that do not require explicit formulation for the nonidealities, are independent of the sensor array,
including its geometry and individual element beampatterns while obtaining close to optimal perfor-
mance. Finally, robust methods try to bound the inﬂuence of modeling errors in the estimation process
instead of trying to capture them.
This chapter is organized as follows. First, conventional array steering vector models and widely
employed techniques in array processing are brieﬂy described in Section 3.19.2. Then, typical explicit
formulations for array nonidealities are described in Section 3.19.3. In Section 3.19.4, array calibra-
tion measurements in controlled environments are brieﬂy described. Section 3.19.5 includes model-
driven techniques that are based on explicit formulations of the array nonidealities. Section 3.19.6
considers data-driven techniques. In Section 3.19.7, robust methods are described. Section 3.19.8
includes extensive array processing examples. Conclusions are given in Section 3.19.9.
3.19.2 Ideal array signal models
The conventional narrowband N-element array output model due to a propagating waveﬁeld, generated
by P ∈N far-ﬁeld sources, is
x(k) = A(θ, φ)s(k) + n(k),
(19.1)

822
CHAPTER 19 Array Processing in the Face of Nonidealities
where A(θ, φ) ∈CN×P, s(k) ∈CP×1, and n(k) ∈CN×1 denote the array steering matrix, transmitted
waveforms, and sensor noise, respectively. The discrete time instant is denoted by k ∈N while θ ∈RP×1
and φ ∈RP×1 represent the co-elevation and azimuth angles of the P sources generating the propagating
waveﬁeld, respectively. Typically, the co-elevation angle (θ ∈[0, π]) is measured down from the z-axis
and the azimuth angle (φ ∈[0, 2π)) is measured counter-clockwise in the xy-plane. In Eq. (19.1),
the N-dimensional observation vector x(k) ∈CN×1 is known as array snapshot. The array steering
matrix A(θ, φ) is composed of P array steering vectors a(θ, φ) ∈CN×1, each representing the array
response to a plane-wave impinging on the sensor array from directions φ1, . . . , φP. In array processing,
the employed sensor array is typically assumed to be unambiguous in the sense that any collection of
P(P < N) steering vectors with different angles forms a linearly independent set.
Assuming that the employed sensor array lies in the xy-plane, and is not subject to nonidealities such
as mutual coupling or cross-polarization effects, the corresponding array steering vector model may be
written as
a(θ, φ) = [g1(θ, φ)ejκ(x1 sin (θ) cos (φ)+y1 sin (θ) sin (φ)), . . . , gN(θ, φ)ejκ(xN sin (θ) cos (φ)+yN sin (θ) sin (φ))],
(19.2)
where gn(θ, φ) ∈R denotes the gain function of the nth element. In (19.2), κ = 2π/λ and λ denote
the angular wavenumber and wavelength, respectively. Moreover, xn, yn ∈R denote the location (in
meters) of the nth element in the xy-plane, relative to the origin of the assumed coordinate system. Note
that other waveﬁeld parameters such as the polarization of the sources may also be included in the array
steering vector model in (19.2). This is brieﬂy discussed in Section 3.19.8.
Typically, in array signal processing the steering vector model in (19.2) is further simpliﬁed by assum-
ing that the array elements are all identical and have omnidirectional gain functions, i.e., gn(θ, φ) = 1,
and are arranged in regular geometries. Commonly used ideal steering vector models include those of
ULAs, UCAs, and URAs:
aULA(φ) = [1, ejκdcos(φ), . . . , ejκd(N−1)cos(φ)]T ,
(19.3a)
aUCA(θ, φ) = [ejκrsin(θ)cos(φ−γ1), . . . , ejκrsin(θ)cos(φ−γN )]T ,
(19.3b)
aURA(θ, φ) = [1, ejκdxsin(θ)cos(φ), . . . , ejκdx(Nx−1)sin(θ)cos(φ)]T
⊗[1, ejκdysin(θ)cos(φ), . . . , ejκdy(Ny−1)sin(θ)sin(φ)]T ,
(19.3c)
where ⊗and d denote the Kronecker product and the inter-element spacing, respectively. In (19.3b),
r ∈R and γn = 2πn/N denote the radius of the circular array and the angular position of the nth
element, respectively.
Assuming waveﬁeld propagation in the xy-plane as well as uncorrelation between transmitted signals
and sensor noise, the array covariance matrix of (19.1) is given by
RX = A(φ)RSA(φ)H + RN,
(19.4)
whereRS ∈CP×P andRN ∈CN×N denotethecovariancematricesofthetransmittedsignalsandsensor
noise, respectively. The signal covariance matrix RS may be rank deﬁcient, with rank P′(P′ ≤P),
due to highly correlated or coherent sources that may be caused by specular multipath propagation,
for example. Sensor noise is typically assumed to be zero-mean complex-circular Gaussian distributed
N C(0, σ 2IN). In practice, the exact covariance matrix in (19.4) is unknown and it is typically estimated

3.19.2 Ideal Array Signal Models
823
from a collection of K(K ≥N) array snapshots as
RX = 1
K
K

k=1
x(k)x(k)H.
(19.5)
Signal models (19.1) and (19.4) are used in most array processing tasks such as beamforming and
direction ﬁnding. In estimation problems, maximum likelihood methods are commonly used to ﬁnd the
optimal parameter estimates whereas beamformers typically target at enhancing the signal by maximiz-
ing the SINR at the array output.
A popular criterion for evaluating the performance of beamformers is the array output SINR [8]:
SINR = σ 2
S|wHa(φS)|2
wHRI+Nw
,
(19.6)
where φS ∈[0, 2π) and σ 2
S ∈R denote the angle from where the SOI impinges on the sensor array and
the corresponding signal power, respectively. Moreover, w ∈CN×1 denotes the beamformer weight
vector and RI+N = A(φ)R IA(φ)H +RN ∈CN×N the covariance matrix due to both interfering signals
RI and sensor noise. The optimal weight vector that maximizes (19.6) is [8]
wOPT = αR−1
I+Na(φS),
(19.7)
where α ∈R may be arbitrary since it does not affect the SINR in (19.6). Choosing α = 1/(a
(φS)HR−1
I+Na(φS)) leads to the well-known minimum variance distortionless response (MVDR) beam-
former, also known as Capon beamformer [8,23]. Note that using the exact RX in place of RI+N in
(19.7) does not affect the array output SINR.
In Section 3.19.1, we have mentioned that the DoAs of the sources generating the propagating
waveﬁeld may be found from its spatial spectrum. The location of the sources are associated with the
angles of the spatial spectrum with larger power. We may therefore view DoA estimation as a spectrum
estimation problem and employ beamforming techniques for estimating the angular distribution of
power of the waveﬁeld received by the sensor array. Such an approach is called nonparametric or
spectral-based approach to DoA estimation since it does not require a parametric model for the sources,
nor the number of sources generating the waveﬁeld. These techniques are versatile but typically have
poor resolution and lead to suboptimal DoA estimates. Informally, resolution refers to the ability of
distinguishing between two closely spaced sources. The resolution of beamforming techniques is limited
by the array aperture, i.e., the physical size of the array in wavelengths, as well as SNR, and does not
improve with increasing number of array snapshots.
One way of improving the resolution limit imposed by the array aperture is by making further
assumptions regarding the sources generating the propagating waveﬁeld. In particular, we ﬁrst assume
that the number of sources P as well as rank of the signal covariance matrix RS are known or have been
correctly estimated from the array output. The radiating sources are also assumed to be located in the
far-ﬁeld of the sensor arrays as well as point-emitters in the sense that the ﬁeld radiated by each source
can be assumed to have originated from a single location in space. Finally, we assume that the number
of sources generating the waveﬁeld is smaller than the number of array elements. Then, the array output

824
CHAPTER 19 Array Processing in the Face of Nonidealities
in (19.1) is known as low-rank signal model and the array covariance matrix in (19.4) can be written as
RX = ESSEH
S + ENNEH
N .
(19.8)
Here, ES ∈CN×P′ and EN ∈CN×(N−P′) contain the eigenvectors of RX spanning the so-called
signal and noise subspaces while S ∈CP′×P′ and N ∈C(N−P′)×(N−P′) contain the corresponding
eigenvalues in their diagonal. Techniques employing the low-rank signal model are called subspace
methods and are a class of high-resolution DoA estimation algorithms [2]. They exploit the fact that
the columns of ES span the same subspace as the columns of the steering matrix A(φ) (in the case of
coherent signals ES is contained in the subspace spanned by the columns of A(φ)), and that both ES
and A(φ) are orthogonal to EN. Unlike beamforming techniques, the resolution of subspace methods
improves with increasing number of array snapshots.
A commonly used lower bound on the estimation error variance of any unbiased estimator is the
Cramér-Rao lower Bound (CRB) [24]. Assuming that both signal and noise are zero-mean complex-
circular Gaussian distributed, the unconditional CRB for azimuth angle estimation is [25]
CRB(φ) = σ 2
2N

ℜ

˙A(φ)H⊥
A ˙A(φ)

⊙

RSA(φ)HR−1
X A(φ)RS
T 	−1
,
(19.9)
where ˙A(φ) =

∂a(φ1)
∂φ1
. . . ∂a(φP)
∂φP

∈CN×P. Moreover, ⊙and ⊥
A ∈CN×N denote the Hadamard-
Schur product and a projection matrix onto the nullspace of A(φ)H, respectively. An estimator with
an error covariance matrix that equals (19.9) is called statistically efﬁcient. In particular, the stochastic
maximum likelihood estimator is asymptotically (K →+∞) statistically efﬁcient, and the azimuth-
angle estimates are obtained as [26]
ˆφ = arg min
φ det

A(φ)RSA(φ)H + ˆσ 2I

.
(19.10)
Here, det{·} denotes the determinant of a matrix. Moreover, RS and ˆσ 2 denote estimates of the signal
covariance matrix and sensor noise, respectively. See [26] and chapter DOA Estimation Methods and
Algorithms of this book for details.
Asymptotically optimal DoA estimation algorithms such as the stochastic maximum likelihood
estimator, and beamforming techniques such as the Capon beamformer, are often very sensitive to
uncertainties in the array steering vector model and sensor noise (and interferers) statistics [6,8]. Under
these scenarios, optimal DoA estimators may be subject to bias and increased variance while optimum
beamformers may suffer from SOI cancellation effect. Uncertainty in noise statistics may be due to
outliers, i.e., highly deviating observations that do not follow the same pattern as the majority of the
data, or incorrect assumptions on the noise environment. For example, man-made interference has
typically a non-Gaussian heavy-tailed distribution, for which (19.5) may no longer be a consistent
estimator of RX [27]. Uncertainties in the steering vector model are often due to misspeciﬁcation or
lack of knowledge of various array nonidealities. These include:
•
Uncertainty in array elements’ beampatterns and positions.
•
Mutual coupling.
•
Mounting platform reﬂections.
•
Cross-polarization effects.

3.19.3 Examples of Array Nonidealities
825
•
Departures from narrowband, far-ﬁeld and point-source assumptions.
•
Errors introduced by the receiver front-end architecture.
•
Effects of nonlinear elements.
In subsequent sections we describe in detail various rigorous and practical approaches for taking the
aforementioned nonidealities of real-world arrays into account by array processing techniques. For
details on array processing under uncertainty in noise statistics the reader is referred to [27].
3.19.3 Examples of array nonidealities
This section describes the main nonidealities experienced in real-world sensor arrays. We discuss their
effects in array processing techniques, and provide explicit formulations describing such array nonide-
alities that can be found in the literature. These models are rather speciﬁc but allow one to understand
the departure from the ideal array model as well as to incorporate such nonidealities into both DoA
estimators and beamforming techniques.
3.19.3.1 Mutual coupling
Mutual coupling (also known as cross-talk) refers to interactions among array elements. The signal
received by an element affects the signals received by the other array elements, and similarly for signal
transmission [28, Chapter 2]. Typically, mutual coupling is inversely proportional to the inter-element
spacing as well as isolation among array elements. Mutual coupling distorts the elements’ radiation
patterns and decreases the efﬁciency of sensor arrays. Mobile wireless terminals equipped with antenna
arrays are a typical example where mutual coupling is signiﬁcant since the whole chassis, along with
its other components, can be considered part of the antenna [5]. Array processing algorithms typically
experience a signiﬁcant loss of performance when the employed array steering vector model does not
account for mutual coupling [6,29].
The steering vector of a sensor array subject to mutual coupling is typically modeled as [6]
a(φ) = Ca0(φ),
(19.11)
where C ∈CN×N denotes the mutual coupling matrix and a0(φ) ∈CN×1 is known as nominal array
steering vector. The C(m, n) element describes the contribution of the nth array element to the output of
the mth sensor. Nominal sensor arrays are typically considered to be ideal uniform arrays with regular
geometries of the form (16.3), and the motivation for their use is based on the assumption that real-world
arrays may be described as a perturbation from an ideal sensor array. For example, if the nominal array
is assumed to be an ideal UCA the mutual coupling matrix takes the form of a circulant matrix [30].
Note that a diagonal matrix C in (19.11) may also describe errors due to the receiver front-end such as
imbalance in the I/Q channels. This is also discussed in Section 3.19.3.5.
In practice, the mutual coupling matrix needs to be determined from array calibration measurements
and a nominal array steering vector should be speciﬁed by the practitioner. Typically, the mutual coupling
matrix is obtained from the measured network parameters of the sensor array, including scattering and
transmission coefﬁcients, which may be a rather tedious task [31,32, Chapter 2]. Moreover, determining
the nominal array steering vector is typically based on trial and error, and rely on visual inspection of
the real-world sensor array.

826
CHAPTER 19 Array Processing in the Face of Nonidealities
3.19.3.2 Uncertainty in array elements’ beampatterns and positions
Often, elements’ beampatterns and positions in real-world arrays are not fully known. This may be
caused by normal variability in the manufacturing process in the sense that each array element has an
individual beampattern or may suffer from manufacturing errors. In fact, elements’ phase centers in
real-world arrays do not typically correspond to their physical locations due to interactions with other
array elements and mounting platform. Misspeciﬁcation of the array element’s beampatterns and phase
centers leads to loss of performance in array processing techniques.
A commonly employed model taking into account individual beampatterns and position errors is
a(φ) = diag

g1(φ)ejκ(˜x1 cos φ+ ˜y1 sin φ), . . . , gN(φ)ejκ(˜xN cos φ+ ˜yN sin φ)
a0(φ),
(19.12)
where ˜xn, ˜yn ∈R, and gn(φ) ∈R denote the error in the nth element’s position, with respect to the
nominal array steering vector, and corresponding directional beampattern. Parameters ˜xn, ˜yn may be
estimated from calibration measurements taken in controlled environments while the gain function
gn(φ) may be measured at a discrete set of points and interpolated using appropriate basis functions
such as splines [6]. The latter approach leads to a technique known as array interpolation and it is
described in Section 3.19.6.
Alternatively, one may specify a parametric model for gn(φ) (i.e., functionally dependent on φ) by
trial and error, and visual inspection. For example, in the case of electrically short (relative to the wave-
length) x-oriented dipoles one can use the following approximation gn(φ) ≈sin φ. However, in the gen-
eral case of electrically large antennas and patch elements, specifying a parametric model for gn(φ) may
be very challenging. An example of two gain functions of a real-world array is illustrated in Figure 19.2b.
90
180
0
270
Element 1
Element 15
(a)
(b)
FIGURE 19.2
(a) Real-world rectangular array with N = 4 × 4 dual-polarized patch elements. (b) Gain patterns of two
elements of the real-world rectangular array. Courtesy of the Department of Radio Science and Technology,
Aalto University, Finland.

3.19.3 Examples of Array Nonidealities
827
3.19.3.3 Cross-polarization effects
Cross-polarization effects refer to “leakage” that, for example, a vertically polarized element suffers
from an horizontally polarized waveﬁeld. They are typically characterized by the cross-polarization
discrimination (XPD), denoting the ratio between the power received by an antenna due to co-polarized
and cross-polarized waveﬁelds. The ratio between the powers received in different polarizations is
commonly expressed in dB scale. XPD deﬁnes quantitatively how well the two received channels
that use different polarization orientations are isolated. Antennas with a large XPD are essentially
insensitive to cross-polarization effects and the power received from cross-polarized waveﬁelds may be
neglected. When mounted on an array the antennas’ XPD may change signiﬁcantly due to complex EM
interactions among the array elements, scatterers, and mounting platform. In such cases, high-resolution
DoA estimators that do not take cross-polarization effects into account typically lead to estimates that
may contain signiﬁcant bias and excess variance [33].
The steering vector of a sensor array that is subject to cross-polarization effects may be described as
a(φ) = aco(φ)αco + across(φ)αcross,
(19.13)
where aco(φ) ∈CN×1 and across(φ) ∈CN×1 denote the array responses due to a co-polarized and cross-
polarized waveﬁelds, respectively. Moreover, αco, αcross ∈C deﬁne the polarization of the waveﬁeld.
For example, for a co-polarized waveﬁeld Eq. (19.13) simpliﬁes to a(φ) = aco(φ) while for a cross-
polarized waveﬁeld we have a(φ) = across(φ).
Parametric modeling of aco(φ) and across(φ) in (19.13) may now be done by employing models
(19.11) and (19.12). However, specifying a nominal array steering vector model for the cross-polarized
component across(φ) is even more challenging than that of the co-polarized component, where one may
approximate the element’s gain function as gn(φ) ≈sin(φ). Typically, visual inspection does not help
much in determining a parametric model for gn(φ). An example of gain functions corresponding to an
horizontally and vertically polarized waveﬁeld is illustrated in Figure 19.3.
90
270
0
180
H−polarization
V−polarization
FIGURE 19.3
Gain functions corresponding to the horizontal and vertical polarization components of an element of the
real-world rectangular array from Figure 19.2a.

828
CHAPTER 19 Array Processing in the Face of Nonidealities
3.19.3.4 Departures from narrowband assumption
The narrowband signal model commonly used in array processing (see Section 3.19.2) assumes that the
time-bandwidth product is “small,” i.e.,
Bsτ ≪1,
(19.14)
where Bs and τ denote the bandwidth of the transmitted signal and the wavefront’s propagation
delay across the array aperture, respectively. A rule of thumb for considering a signal narrowband
is sinc(Bsτ) ≈1 [34]. In practice, the time-bandwidth product may be such that the narrowband
assumption no longer holds true. This is also the case in focusing-based wideband array processing,
where signals’ bandwidth is divided into a set of narrowband channels and narrowband processing is
applied to each narrowband bin or to a focused covariance matrix [35]. Alternatively, genuine space-time
signal processing can be employed as in STAP radar systems [36,37].
Assuming an array with a ﬂat frequency response (with linear phase) over the signals’ bandwidth,
the array covariance matrix may be modeled as [34,38]
RX =
P

p=1

a( f p, φp)aH( f p, φp) ⊙Rp

+ σ 2IN,
(19.15)
where ⊙denotes the element-wise Hadamard-Schur product. Moreover, a( f , φ) ∈CN×1 denotes
the array steering vector with a linear phase response over frequency and Rp ∈RN×N contains the
correlation of the pth signal among the array elements. For signals with small time-bandwidth product
Rp equals a matrix of ones and (19.15) reduces to (19.4). However, when Bsτ is non-negligible the rank
of

a( f p, φp)aH( f p, φp) ⊙Rp

due to a single signal is larger than one, and the low-rank structure
of the array covariance matrix in (19.4) is lost. Thus, high-resolution subspace methods may not be
applicable anymore [34]. The inﬂuence of non-negligible time-bandwidth product on DoA estimators
and beamforming techniques has been addressed in [34,38]. In most cases, the error due to non-
negligible time-bandwidth product can be neglected when compared to ﬁnite sample effects. However,
when sources are closely spaced or have large difference in power, such an error may be signiﬁcant.
3.19.3.5 Errors due to receiver front-end architectures
Receiver architectures are commonly classiﬁed as superheterodyne, low-IF (intermediate frequency)
or direct-conversion receivers. Each front-end architecture is subject to various nonidealities such as
I/Q-imbalance, DC-offset, and interfering image frequencies that impact the performance of array
processors.
Superheterodyne receivers typically consist of two or more IF stages in order to convert the radio-
frequency (RF) signal to baseband. They require image rejection ﬁlters at each downconversion stage,
which may be difﬁcult to integrate on-chip with other components. Power consumption and size may
be signiﬁcant [39]. Low-IF receivers convert the RF signal to baseband in two IF stages, similarly to the
superheterodyne receiver. The need for image rejection ﬁlters is overcome by the use of two mixers, one
for each I/Q channels, in order to cancel the image. In practice, gain and phase imbalances in the I/Q
channels limit the effectiveness of such image cancellation approach. Direct-conversion (or zero-IF)
receivers downconvert the RF signal to baseband in a single stage. There is no need for image rejection

3.19.4 Array Calibration
829
ﬁlters nor image cancellation. However, they typically suffer from DC offset, and I/Q imbalances in the
demodulation process are still present.
I/Q imbalances in the demodulation process are common to all of the aforementioned receivers
and have been studied in the context of array signal processing in [40]. They appear as phase and
amplitude distortions in the I and Q branches of the demodulated signal. Similarly to errors caused
by departures from narrowband assumption, the rank of the covariance matrix due to received signals
increases by two and the noise eigenvalues are no longer identical. The low-rank structure of the array
covariance matrix may be lost and subspace-based array processing methods experience a performance
degradation.
One should note that I/Q imbalances may be signiﬁcantly mitigated by using advanced digital down-
converters, either at intermediate or radio frequencies. The commonly used low-rank model is then a
good approximation of the array covariance matrix, given that a sufﬁcient number of quantization bits
are used [41]. Power consumption and high cost of ADCs operating at GHz and large bandwidths may
be a limiting factor in practice.
We also note that antenna arrays using a single receiver, known as switched or time division multiplex-
ing receivers, are often employed in practice due to their low-power, cost, and size [41,42]. Typically,
switched array receivers suffer from phase errors that need to be estimated and taken into account by
array processing methods.
3.19.3.6 Effects of nonlinear elements
Linearity of the sensor array is among the most common assumptions in the array processing litera-
ture. Linearity, in the sense of superposition principle, essentially means that the array output due to a
propagating waveﬁeld generated by multiple sources equals the sum of array outputs due to a wave-
ﬁeld generated by each source separately. Most sensor arrays can be considered linear systems and
the superposition principle may then be employed [32]. However, active elements such as low-noise
ampliﬁers (LNAs) commonly used in receiver architectures are nonlinear systems and the superpo-
sition principle at the array output (after the RF front-end) may no longer hold true [43]. Typically,
LNAs trade-off linearity for gain and noise ﬁgures. Some waveforms that have large peak to average
power ratio such as OFDM (orthogonal frequency-division multiplexing) are particularly sensitive to
nonlinearities of power ampliﬁers. Digital signal processing techniques for mitigating nonlinear effects
due to RF front-end include pre- as well as post-distortion techniques [44].
3.19.4 Array calibration
The goal of array calibration is to capture the combined effects of sensor positions, their unknown
gain and phase, mutual coupling characteristics as well as cross-polarization effects and mounting
platform reﬂections. In array calibration one typically acquires the so-called array measurement
matrix A(φc) ∈CN×Q. The array measurement matrix is composed of a collection of Q steering vectors
corresponding to the angles contained in the vector φc ∈RQ×1. The standard approach of obtaining
the array measurement matrix is by taking the sensor array into an anechoic chamber and measuring
its response to a source, known as probe, from Q ∈N different known angles. The antenna array is
usually mounted on a mechanical device, called positioner, that rotates the sensor array in azimuth (and

830
CHAPTER 19 Array Processing in the Face of Nonidealities
FIGURE 19.4
Example of the standard array calibration setup. A ULA is rotated in the xy-plane around its center element
while a probe is held ﬁxed in the far-ﬁeld of the ULA.
possibly in elevation) while the probe is held ﬁxed; see Figure 19.4. Note that the coordinate system
employed for DoA estimation is deﬁned by both the positioner and probe.
The array measurement matrix fully describes a given real-world sensor array as well as all its
nonidealities. However, array calibration measurements are typically taken in controlled environments
such as anechoic chambers, and may be subject to various errors including sensor noise, reﬂections
from the anechoic chamber, imperfections of the employed positioner, attenuations and phase-drifts
due to cabling, small distance between the antenna array and probe (i.e., not in far-ﬁeld), and effects
of the probe (e.g., not a point-source). These errors need to be corrected so that array processing
techniques may employ an accurate model of the real-world array response. Approaches for reducing
the aforementioned errors occurring during array calibration measurements can be found in [32,33,45].
Moreover, array calibration measurements do not provide any steering vector model, i.e., an explicit
formulation describing the array response as a function of the waveﬁeld parameters. Such difﬁculties
may be alleviated by employing data-driven techniques described in Section 3.19.6.
Typically, the array measurement matrix contains the array response to angles spanning the whole
angular region, such as φc ∈(0, 2π] in the azimuth-only case. However, in some applications the array
response may only be measured over a small angular sector, and a partial array calibration is obtained.
Examples include applications where the antenna array is deployed on an environment where the sources
are known a priori to be conﬁned to an angular sector or when the array dimensions do not allow a full
calibration. Data-driven techniques described in Section 3.19.6 are also applicable in these cases.
3.19.5 Model-driven techniques
In this section, we describe techniques that assume an explicit model describing each array nonideality.
The array nonidealities may be estimated, by employing such a model, from array calibration measure-
ments or directly from the array output data, simultaneously with the waveﬁeld parameters. The latter

3.19.5 Model-Driven Techniques
831
approach is known as auto-calibration technique. Moreover, the array nonidealities may be assumed to
be unknown deterministic or random parameters with known prior distribution. Hence, methods from
estimation theory may be applied to estimate the array nonidealities.
3.19.5.1 Deterministic approach
ConsideranN-elementplanararraylyinginthexy-planeanddenotetheuncertaintyinthearrayelements’
positions by ρ = [˜x1, ˜y1, . . . , ˜xN, ˜yN]T ∈R2N×1. In this case, the array is not assumed to be subject
to other nonidealities such as cross-polarization effects or individual beampatterns. We may estimate
the sensors’ misplacements ρ from array calibration measurements as [6]
ˆρ = arg min
ρ
A(φc) −A(φc, ρ)
2
F ,
(19.16)
where A(φc, ρ) ∈CN×Q denotes a matrix composed of a collection of array steering vectors describing
ρ in a closed-form, such as in (19.12), and ∥·∥F denotes the Frobenius norm of a matrix. In some cases,
a closed-form solution to (19.16) may be obtained. For example, using the mutual coupling matrix C
in place of ρ in (19.16) yields the following solution:
C = A(φc)A†(φc),
(19.17)
where we have used the array model (19.11) and assumed that A(φc) has full row-rank. Notation (·)†
in (19.17) denotes the Moore-Penrose pseudo-inverse of a matrix. Similarly, by letting ρ denote angle-
independent gain and phase errors such as A(φc, ρ) = diag{ρ}A(φc), we obtain the following solution:
ˆρ = ˜an(φc)aH
n (φc)

an(φc)aH
n (φc)
−1
,
(19.18)
where ˜an(φc) ∈C1×Q and an(φc) ∈C1×Q denote the nth row of A(φc) and A(φc), respectively.
In case one is dealing with electrically large uniform linear arrays, the mutual coupling matrix may be
approximated by a banded matrix. Recall that mutual coupling is typically inversely proportional to
inter-element spacing thus, such an effect may be negligible among sensors located at both ends of the
linear array. A least-squares estimator to such a structured mutual coupling matrix may also be found in
a closed-form. Computationally efﬁcient solutions may employ appropriate LU-factorization and back-
substitution methods [46, Chapter 4]. A summary of model-driven calibration is given in Table 19.1.
Alternatively, we may jointly estimate array nonidealities and waveﬁeld parameters from the output
of the sensor array [11–13]. For example, joint estimation of the nonidealities ρ and azimuth angles
of P sources (φ ∈RP×1) generating a propagating waveﬁeld may be accomplished by employing the
following nonlinear least-squares estimator [12]
{ ˆφ, ˆρ} = arg min
ˆφ,ˆρ
Tr

⊥
A(φ, ρ)RX

.
(19.19)
Typically, criterion in (19.19) is minimized in an alternating manner between the array nonidealities
ρ and the DoAs φ [47]. Since (19.19) is highly nonlinear, and potentially with multiple local minima,

832
CHAPTER 19 Array Processing in the Face of Nonidealities
Table 19.1 Steps of (Deterministic) Model-Driven Calibration
Ofﬂine
Step 1 Acquire the array calibration matrix A(φc) ∈CN×Q
Step 2 Specify an array steering vector model a(φ, ρ) ∈CN×1
describing both array nonidealities and waveﬁeld parameters
Step 3 Estimate the array nonidealities ˆρ
Online
Step 4 Acquire the output of the real array x(k), k = 1, . . . , L
Step 5 Apply DoA estimators and beamforming techniques
using the resulting array steering vector a(φ, ˆρ)
the minimization should be initialized with “good enough” initial values so that the global minimum
can be attained. Note that the array nonidealities ρ are typically nuisance parameters. The statistical
performance of the waveﬁeld parameter estimates may suffer due to the higher dimension of the para-
metric model as well as estimation errors in the nuisance parameters.
The main issue with auto-calibration techniques is that of parameter identiﬁability [6]. In general,
both ρ and φ cannot be uniquely estimated unless a nonlinear sensor array is employed and additional
assumptions regarding sensors’ locations as well as DoAs are made [12,13]. For example, if the array
orientationisunknowntheDoAsmaynotbeuniquelyestimatedsincetheyrepresenttheanglesrelativeto
the orientation of the sensor array. Alternatively, one may assume that the array nonidealities are random
parameters with a known prior distribution, and employ Bayesian estimators. This is discussed next.
3.19.5.2 Bayesian approach
In the previous section we have seen that the identiﬁability problem in auto-calibration techniques could
be alleviated by making additional assumptions regarding the nonidealities or waveﬁeld parameters.
One such an assumption considers the array nonidealities to be random parameters with a known prior
distribution. In addition to alleviating the identiﬁability problem, such an assumption allows one (at least
inprinciple) to“integrateout”thearraynonidealities andfocus onthewaveﬁeldparameters, instead[24].
For example, in mass production of sensor arrays one could model array elements’ misplacements due
to manufacturing errors as bivariate Gaussian distributed and proceed with Bayesian type of estimators
for the waveﬁeld parameters [7,14].
One such an estimator is the generalized weighted subspace ﬁtting (GWSF) algorithm proposed in
[7]. It extends the MODE [48] and WSF [49] by taking into account prior information (ﬁrst and second
moments) of the array nonidealities in an optimal manner. It provides asymptotically efﬁcient estimates
provided the assumption on the prior Gaussian distribution is valid and array parameterization is known.
The DoA estimates obtained by the GWSF are given by [7]
ˆφ = arg min
φ
ˆeH
S ⊥
¯AW⊥
¯A ˆeS,
(19.20)

3.19.5 Model-Driven Techniques
833
Table 19.2 Steps of Auto-Calibration Techniques
Ofﬂine
Step 1
Specify an array steering vector model a(φ, ρ) ∈CN×1
describing both array nonidealities and waveﬁeld parameters
Step 2
Model the array nonidealities ρ either as unknown deterministic
or random parameters with a prior distribution
Online
Step 3
Acquire the output of the real array x(k), k = 1, . . . , L
Step 4
Determine the number of signals generating the received waveﬁeld
Step 5
Estimate waveﬁeld parameters ˆφ by employing a suitable
estimator e.g., the NNLS or GWSF estimator
Step 6 (optional)
Estimate the array nonidealities ˆρ and apply beamforming
techniques using the resulting array steering vector a(φ, ˆρ)
where ˆeH
S = vec
ET
S EH
S
T 
∈C2N P′×1 and ⊥
¯A ∈C2N P′×2N P′ denotes a projection matrix onto the
orthogonal complement of
¯A(φ, ρ) =
 (IP′ ⊗A(φ, ρ))
0
0
(IP′ ⊗Ac(φ, ρ))
	
.
(19.21)
Furthermore, 
W ∈C2N P′×2N P′ in (19.20) denotes a (positive-deﬁnite) weighting matrix that ensures
asymptotically minimum variance unbiased estimates and the superscript (·)c denotes complex-
conjugate. The ﬁrst and second-order moments of the array nonidealities enter criterion (19.20) through

W; see [7] for details. Criterion (19.20) is an asymptotic approximation of the maximum a posteriori
estimator for simultaneous estimation of array and waveﬁeld parameters [14]. It may be implemented
by means of polynomial rooting techniques when the nominal array steering vector has a form similar
to that of an ideal ULA. A summary of auto-calibration techniques is given in Table 19.2.
The main difﬁculty with the Bayesian approach is related to the well-known problem of choosing
appropriate prior distributions.1 Assumed prior knowledge may not exist or it may be difﬁcult to express
in the form of a pdf. Moreover, specifying a parametric model for the array nonidealities may be very
challenging in practice, similarly to the deterministic approach. In case of uncertainties in the array
elements’ locations, the nominal steering vector model may be obtained by visual inspection of the real-
world sensor array [7]. However, when considering cross-polarization effects, sensors with individual
beampatterns and mutual coupling, such a procedure is of little help in determining a nominal array
steering vector.
1This may be alleviated by means of uncertainty sets on the array steering vector, to be discussed in Section 3.19.7. For
example, uncertainties in the array elements’ locations may be bounded by the array aperture, thus avoiding the difﬁculties
that may arise in deriving Bayesian type of estimators with truncated prior distributions.

834
CHAPTER 19 Array Processing in the Face of Nonidealities
In practice, array calibration measurements may be necessary even in auto-calibration techniques.
Hence, it may be worth considering alternative techniques for dealing with array nonidealities that
assume array calibration measurements but do not suffer from the difﬁculties in specifying explicit
formulations for the nonidealities. This is discussed in the next section.
3.19.6 Data-driven techniques
Data-driven techniques take into account all array nonidealities simultaneously through array calibration
measurements or synthesized array response using e.g., electromagnetic simulation software. These
techniques do not require any explicit formulation describing the array nonidealities in a closed-form.
Examples of nonidealities that may be handled with data-driven techniques include mutual coupling,
individual beampatterns, mounting platform reﬂections, and cross-polarization effects. This section
describes the array interpolation technique [15] and waveﬁeld modeling principle [20], also known as
manifold separation technique [18].
In particular, array interpolation technique may be understood as a linear interpolation method that ﬁts
array calibration measurements with some ideal array steering vector model. The manifold separation
techniques stems from the waveﬁeld modeling principle and can be seen as an orthogonal expan-
sion in Fourier basis (in azimuth-angle processing) of each array element. The expansion coefﬁcients
describe the array nonidealities in a combined manner and may be estimated from array calibration
measurements.
3.19.6.1 Local interpolation of the array calibration matrix
The columns of the array calibration matrix A discussed in Section 3.19.4 describe the array response,
with the combined effects due to array nonidealities, to a set of angles. The angular grid employed in
array calibration measurements is typically sparse due to time and cost limitations. Hence, optimal array
processing methods using the array calibration matrix may loose their high-resolution properties and
suffer from SOI cancellation effects. Perhaps the most intuitive approach to overcome such a limitation
consists in interpolating the array calibration matrix using local basis functions such as splines.
Let α(φ) denote a vector composed of local basis functions such as splines or other polynomial func-
tions. The practitioner should choose local basis functions with desirable properties such as smoothness,
differentiability, and minimum energy. Also, let Cn denote a coefﬁcient matrix obtained by interpolating
the array calibration matrix A over an angular sector Cn using α(φ). Cn may correspond to two or more
columns of A. Using local basis as the interpolating functions leads to the following piece-wise estimate
of the real-world array steering vector:
ˆa(φ) =
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
C1α(φ), φ ∈C1,
C2α(φ), φ ∈C2,
...
Cnα(φ), φ ∈Cn.
(19.22)

3.19.6 Data-Driven Techniques
835
Table 19.3 Steps of Local Interpolation Technique
Ofﬂine
Step 1
Acquire the array calibration matrix A(φc) ∈CN×Q
and divide it into L angular sectors {Al ∈CNv×Q/L}L
l=1
Step 2
Specify a nominal array model a0(φ) ∈CN×1
Step 3
Find the L coefﬁcient matrices {Cl (φ) ∈CN×N }L
l=1
Online
Step 4
Acquire the output of the real array x(k), k = 1, . . . , K
Step 5
Apply DoA estimators and beamforming techniques to x(k)
using the nominal array model a0(φ) and coefﬁcient matrices {Cl (φ)}L
l=1
Alternatively, one may use a nominal array steering vector a0(φ) in place of α(φ), and use a local basis
expansion for the coefﬁcients matrices in (19.22), instead. More precisely, we may have [6]:
ˆa(φ) =
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
C1(φ)a0(φ),
φ ∈C1,
C2(φ)a0(φ),
φ ∈C2,
...
Cn(φ)a0(φ), φ ∈Cn,
(19.23)
where the nth matrix Cn(φ) is modeled as
Cn(φ) = diag{Cnα(φ)}.
(19.24)
Here, Cn denotes a local coefﬁcients matrix; see [6] and references therein for details. The rationale
for (19.23) is that Cn(φ) is typically a smoother function of the angles that the array response, thus
allowing for sparser calibration grids than those employed in (19.22). A summary of local interpolation
technique is given in Table 19.3.
Expressions (19.22) and (19.23) may be useful in cases when the sensor array is deployed on an
environment where the sources are known to be conﬁned to an angular sector. If this is not the case,
and the sources may span the whole angular region, using local interpolation techniques may lead
to a signiﬁcant increase on the computationally complexity of array processing methods and may
compromise the convergence rate of gradient-based optimization techniques. For example, using (19.22)
with the root-MUSIC algorithm requires ﬁnding the roots of n different polynomials while the maximum
step-size of gradient-based methods is limited by the size of each angular sector Cn. Hence, waveﬁeld
modeling and manifold separation, discussed later in this section, are generally preferred when a sensor
array is deployed on an environment where the sources may span the whole angular region.

836
CHAPTER 19 Array Processing in the Face of Nonidealities
3.19.6.2 Array interpolation technique
The array interpolation technique was originally proposed in [15] and further studied in, e.g., [16,17,50].
The idea is to linearly transform the real-world array so that its response approximates that of a speci-
ﬁed ideal array, such as an ULA, known as virtual array. The steering vector model of the virtual array
needs to be speciﬁed by the designer, and it is typically based on some array processing technique. For
example, if the virtual array is that of an ULA, one may employ polynomial rooting techniques for DoA
estimation. We note that for UCAs a technique called Beamspace transform may be also employed [51].
However, we do not consider Beamspace transform in this chapter due to the restriction on the array
geometry; see [51] and references therein.
Let A(φc) ∈CN×Q denote the calibration measurement matrix of the real-world array and Av(φc) ∈
CNv×Q a collection of steering vectors of the virtual array. In its simplest form, the array interpolation
technique consists in determining the transformation matrix T ∈CNv×N that minimizes the following
quadratic error:
T = arg min
T
TA(φc) −Av(φc)
2
F.
(19.25)
The solution to (19.25) is well-known to be
T = Av(φc)A†(φc).
(19.26)
Given the output of the real-world array x(k) ∈CN×1, the output of the virtual array y(k) ∈CNv×1
and its sample covariance matrix RY ∈CNv×Nv are found as y(k) = Tx(k) and RY = TRXTH,
respectively. Array processing techniques may then be developed for the virtual array and be employed
to real-world arrays without explicitly modeling their nonidealities. We note that the virtual array should
be designed so that both TH and RY are of full column-rank. In case the condition Nv ≤N does not
lead to a full-rank virtual array covariance matrix, the virtual array should be re-designed. A summary
of array interpolation techniques is given in Table 19.4.
Table 19.4 Steps of Array Interpolation Technique
Ofﬂine
Step 1
Acquire the array calibration matrix A(φc) ∈CN×Q
and divide it into L angular sectors {Al ∈CNv×Q/L}L
l=1
Step 2
Specify L virtual array models {al (φ) ∈CNv×1}L
l=1 and generate the
corresponding virtual array calibration matrices {Av
l ∈CNv×Q/L}L
l=1
Step 3
Find the L transformation matrices {Tl ∈CNv×N}L
l=1
If Tl is ill-conditioned go to Step 2 and design a new virtual array model
Online
Step 4
Acquire the output of the real array x(k), k = 1, . . . , K
Step 5
Obtain L virtual array outputs yl (k) = Tl x(k),l = 1, . . . , L
Step 6
Apply DoA estimators and beamforming techniques to {yl (k)}L
l=1
using the virtual array models {al (φ)}L
l=1

3.19.6 Data-Driven Techniques
837
The array interpolation technique has two important drawbacks. First, the virtual array, including
its conﬁguration, orientation, number of elements, and inter-element spacing, needs to be speciﬁed by
the designer. Even though this offers some versatility for employing low-complexity DoA estimators or
beamforming techniques with arbitrary array conﬁgurations (e.g., root-MUSIC algorithm using virtual
ULAs), designing virtual arrays is always a heuristic and subjective task. For example, suppose one
wants to establish a performance bound such as the widely used Cramér-Rao lower Bound (CBR)
for a speciﬁc real-world array [25]. In order to take into account the array nonidealities it would be
appealing to use array calibration measurements and array interpolation techniques for guaranteeing the
tightness of such a bound. However, the resulting CRB depends on the choice of the user-speciﬁed virtual
array conﬁguration and its parameterization, even though the true physical array remains unmodiﬁed.
Typically, the speciﬁed virtual array employed in array interpolation does not provide insight into the
achievable performance by an array built in practice.
Second, the quadratic error in the mapping (19.25) is typically very large if one considers the
whole range of angles at once, i.e., φc ∈[0, 2π). In order to reduce such an error, array interpolation
technique typically proceed by dividing the visible region of the real-world array into angular sectors and
optimizingatransformationmatrixforeachsector.Incasethesensorarrayisdeployedonanenvironment
where the sources are known a priori to be conﬁned to an angular sector such a requirement of array
interpolation techniques is not a serious limitation. However, in environments where the sources may
span the whole angular region, array interpolation technique require sector-by-sector processing, which
is known to be sensitivity to out-of-sector sources [52]. Moreover, it may also need a prohibitively large
number of sectors in azimuth and elevation processing.
Array interpolation techniques are typically more ﬂexible than local interpolation of the array cali-
bration matrix. For example, one cannot (in general) employ the ESPRIT algorithm with arbitrary array
conﬁgurations using (19.22) simply by choosing a “shift-invariant” local basis vector. Typically, the
approximation a(φ) ≈Cnα(φ) is not shift-invariant. On the other hand, array interpolation techniques
requires more design parameters than local interpolation methods. Finally, array interpolation tech-
niques, and to some extent local interpolation methods, typically interpolate exactly all of the measured
data including calibration measurement noise. Next, we show that waveﬁeld modeling and manifold
separation can be formulated in a model ﬁtting approach in order to minimize the contribution of
calibration measurement noise.
3.19.6.3 Waveﬁeld modeling principle and manifold separation technique
The waveﬁeld modeling principle was proposed in the seminal work of Doron and Doron [20–22]. It
has been further studied and applied to high-resolution direction ﬁnding in [18,19], and extended to
vector-ﬁelds such as completely polarized electromagnetic waveﬁelds in [53].
Let us ﬁrst recall some results regarding propagating waveﬁelds and wave equation. For the sake of
clarity, weconsider scalar-ﬁelds suchas acousticpressureﬁelds, narrowbandsignals, anddropthecarrier
term ejωt. The extension to completely polarized EM waveﬁelds is brieﬂy described in Section 3.19.8.
Let (t, r) ∈C represent a (scalar) waveﬁeld propagating in the xy-plane and r ∈R2×1 denote a point in
2-D Euclidean space. The propagating waveﬁeld takes the form of (t, r) = P
p=1sp(t)e−jrT kp in the
case of P far-ﬁeld point sources or (t, r) = s(t)

S1ϱ(φ)e−jrT kdφ in the case of a (far-ﬁeld) spatially
distributed source. ϱ(φ) ∈C denotes a density function and k ∈R2×1 is known as the direction vector

838
CHAPTER 19 Array Processing in the Face of Nonidealities
sinceitisafunctionofφ.Spatiallydistributedsourcesmaybecausedbyscatteringnearbythetransmitter.
Waveﬁelds of time-harmonic nature, i.e., that have a representation in terms of Fourier integral, may be
written as (t, r) = +∞
m=−∞ψm(t)hm(r), where {hm(r) ∈C}+∞
m=−∞and {ψm(t) ∈C}+∞
m=−∞denote
an orthogonal set of spatial basis functions and the coefﬁcients of the expansion, respectively. An
important outcome of such an expansion is that the coefﬁcients {ψm(t) ∈C}+∞
m=−∞uniquely describe
the spatial characteristics of the propagating waveﬁeld, such as the DoAs of the sources generating the
waveﬁeld, in addition to the transmitted signals. For example, by letting {hm(r) ∈C}+∞
m=−∞denote
circular wave functions, the mth waveﬁeld coefﬁcient is given by ψm(t) = s(t)

S1 ejmφϱ(φ)dφ for a
spatially distributed source and ψm(t) = P
p=1sp(t)ejmφp for P point-sources.
Let us now assume that the employed real-world array satisﬁes the superposition principle (see
Section 3.19.3). Then, the waveﬁeld modeling principle shows that the array output, at a given frequency,
is a linear function of the waveﬁeld coefﬁcients {ψm(t) ∈C}+∞
m=−∞. In particular, after discretization
the narrowband array output in (19.1) can be written as
x(k) = Gψ(k) + n(k),
(19.27a)
= G
P

p=1
d(φp)sp(k) + n(k),
(19.27b)
where G ∈CN×M denotes the so-called array sampling matrix and ψ(k) ∈CM×1 contains the
(discretized) waveﬁeld coefﬁcients {ψm(k) ∈C}+∞
m=−∞. Recall that, due to the circular wave basis
function employed by the spatial decomposition of the propagating waveﬁeld,d(φ) ∈CM×1 in (19.27b)
is a Vandermonde vector composed of Fourier basis. Hence, d(φ) is called basis functions vector. In
case of a spatially distributed source, the sum in (19.27a) is replaced by an integral over the angles,
and weighted by ϱ(φ). The number of coefﬁcients employed in (19.27a and 19.27b) is denoted by
M. Exact equality in (19.27a and 19.27b) is achieved with M = ∞but in practice a (very) accurate
approximation of the array output can be obtained with a relatively small M (see Figure 19.7).
The result in (19.27a and 19.27b) shows that the (noise-free) array output can be decomposed into
two parts. One, represented by the array sampling matrix, characterizes the employed sensor array and it
is independent of the waveﬁeld. The second part, represented by the basis functions vector, characterizes
the propagating waveﬁeld and it is independent of the employed sensor array. In fact, a corollary of the
waveﬁeld modeling principle shows that the array steering vector may be decomposed as
a(φ) = G d(φ).
(19.28)
The result in (19.28) is known as manifold separation technique [18] and reveals an interesting interpre-
tation for the array sampling matrix. It represents the spatial Fourier spectrum of the array steering vector
G =

S1 a(φ) dH(φ) dφ,
(19.29)
where each row of the array sampling matrix contains the spatial Fourier coefﬁcients of each array
element. Hence, the array output (at each frequency) can be seen as the product between the spatial
Fourier spectrum of the array steering vector and that of the propagating waveﬁeld.
The array sampling matrix fully and uniquely characterizes a given sensor array since it contains
the coefﬁcients of an orthogonal spectral decomposition of the corresponding array steering vector.

3.19.6 Data-Driven Techniques
839
For example, G contains information about the array conﬁguration, sensors beampatterns (gain and
phase response), mutual coupling, cross-polarization effects, mounting platform reﬂections, etc. In
short, it contains all the effects that can be represented by the array steering vector a(φ). Closed-form
expressions for the array sampling matrix for some ideal sensor arrays can be found in [20]. However,
G may also be estimated in a non-parametric manner from array calibration measurements, without
explicit formulations for the array nonidealities. In particular, the estimated array sampling matrix G
obtained as
G = A(φc)F,
(19.30a)
G = GS
(19.30b)
is known as effective aperture distribution function (EADF) [18,33]. In (16.30), F ∈CQ×Q denotes
the unitary discrete Fourier transform (DFT) matrix and S ∈NQ×M a selection matrix that optimally
trades-off between complexity and accuracy of the resulting array steering vector model in (19.28). S
may be estimated using state-of-the-art model order estimators [54].
We have mentioned that exact equality in (19.27b, 19.27a) and (19.28) requires that G is composed
of inﬁnitely many columns.2 One may feel that such a requirement makes the waveﬁeld modeling
principle, or manifold separation technique, of theoretical interest only. The crucial property of the
array sampling matrix that makes both waveﬁeld modeling principle and manifold separation technique
practical is known as superexponential decay. In particular, the magnitude of the columns of the sampling
matrix, [G]m, decay faster than exponential (i.e., superexponential) as m →∞beyond |m| = κr. κ
and r denote the angular wavenumber and radius of the smallest sphere enclosing the array structure
(centered at the assumed coordinate system), respectively.
In practice, the superexponential property tells us that (19.27b, 19.27a) and (19.28) are (very) well
approximated by a few columns M of the array sampling matrix since the norm-convergence rate
of the expansion in (19.28) is faster than exponential [18,20]; see Figure 19.7. The superexponential
property may be understood by interpreting sensor arrays as spatial ﬁlters. In fact, G may be seen as the
array’s spatial frequency response, where the passband, stopband, and cutoff frequencies are given by
|m| < κr, |m| > κr, and |m| = κr, respectively. For example, sensor arrays with large aperture have
increased resolution since they sample the propagating waveﬁeld over a large area. This is reﬂected
on the array sampling matrix by an increase of the passband |m| < κr (r increases). This leads to an
increase of the amount of energy received from such a waveﬁeld since a large number of waveﬁeld
coefﬁcients {ψm ∈C}+∞
m=−∞are taken into account by the employed sensor array.
In the following, the main concepts and properties of waveﬁeld modeling principle and manifold
separation technique are illustrated using an ideal ULA. We emphasize that using ULAs does not limit
the generality of the discussion. We employ it for the sake of clarity here. Let us consider the 5-element
ULA from Figure 19.5, where the smallest sphere (a circle in this case) enclosing the array structure is
depicted as well. Figure 19.6 illustrates three rows of the array sampling matrix, i.e., the spatial Fourier
coefﬁcients of the ﬁrst three array elements. The ideal ULA is composed of omnidirectional elements
with an inter-element spacing of λ/2. In Figure 19.7a, the norm of each column of the array sampling
matrix, ∥[G]m∥, is illustrated for two ideal ULAs with inter-element spacings of d = λ/2 and d = λ/4.
2In the limiting case of an inﬁnitely small aperture the array sampling matrix is ﬁnite.

840
CHAPTER 19 Array Processing in the Face of Nonidealities
FIGURE 19.5
Ideal uniform linear array with an inter-element spacing denoted by d. The smallest sphere (a circle in this
case) enclosing the array structure is depicted as well. The concept of smallest sphere provides a measure
of the array aperture, including the mounting platform.
−50
0
50
10
20
30
40
−40
−20
−30
−10
−350
−300
−250
−200
−150
−100
−50
0
Mode Index [m]
Magnitude [dB]
1st element
2nd element
3rd element
FIGURE 19.6
Three ﬁrst rows of the array sampling matrix corresponding to the ﬁrst three elements of the ideal ULA
depicted in Figure 19.5. They represent the spatial Fourier coefﬁcients of the ﬁrst three array elements.
The coefﬁcients of the third array element are zero except at m = 0 whereas that of the outer elements
exhibit the superexponential property.

3.19.6 Data-Driven Techniques
841
−50
0
50
10
20
30
40
−40
−30
−20
−10
−350
−300
−250
−200
−150
−100
−50
0
Mode Index [m]
Magnitude [dB]
ULA with d=λ/2
ULA with d=λ/4
1
11
21
31
41
51
61
71
81
91
101
−300
−250
−200
−150
−100
−50
0
Number of Modes [ M]
Square d-Residual [dB]
ULA with d=λ/2
ULA with d=λ/4
(a)
(b)
FIGURE 19.7
In (a) the norm of each column of the array sampling matrix for two ideal ULAs with different inter-element
spacing. In (b) the average squared-residual of the manifold separation technique as a function of the
number of modes. The saturation ﬂoor observed at ∼−300 dB is due to arithmetic precision of Matlab. The
superexponential property of the array sampling matrix is a consequence of the ﬁnite aperture of sensor arrays.
Finally, Figure 19.7b, illustrates the following (average) squared-residual:
1
2π

S1 ∥a(φ) −
(M−1)/2

m=−(M−1)/2
[G]m[d(φ)]m∥2 dφ,
(19.31)
as a function of M, the number of columns of G.
The simulation results show that the “passband” of the array sampling matrix increases for large
apertures.3 In the limiting case of an inﬁnitely small aperture, such as the omnidirectional array ele-
ment located at the center of the coordinate system in Figure 19.5, the array sampling matrix is ﬁnite
(see Figure 19.6). This is because only the magnitude response of such an array needs to be modeled
(the ﬁrst spatial harmonic in the case of omnidirectional elements) since the relative phase across such
an aperture is zero.
A summary of the waveﬁeld modeling principle/manifold separation technique is given in Table 19.5,
where we assume that array calibration measurements are taken over the whole angular region, i.e.,
φc ∈[0, 2π). We emphasize that such an assumption does not limit the generality of the waveﬁeld
modeling principle/manifold separation technique since it is simply related with the choice of orthogonal
basis functions {hm(r)}+∞
m=−∞, employed for decomposing the propagating waveﬁeld. More precisely,
waveﬁeld modeling principle/manifold separation technique are also applicable when only partial array
calibration measurements are acquired, or when the sources are known a priori to be conﬁned to an
angular sector. The superexponential property of the sampling matrix is also retained in such cases [20].
3The correct term should be electric dimensions since the superexponential property is inversely proportional to the wave-
length, in addition to the relationship with the physical dimension of the array.

842
CHAPTER 19 Array Processing in the Face of Nonidealities
Table 19.5 Steps of Waveﬁeld Modeling Principle/Manifold Separation
Technique
Ofﬂine
Step 1
Acquire the array calibration matrix A(φc) ∈CN×Q, with φc ∈[0, 2π)
Step 2
Find G ∈CN×Q by taking a Q-point FFT of A(φc)
Step 3
Estimate the array sampling matrix G ∈CN×M by employing
state-of-the-art model order estimators such as normalized MDL
Online
Step 4
Acquire the output of the real-world array x(k), k = 1, . . . , K
Step 5
Apply DoA estimators and beamforming techniques to x(k)
using the array model a(φ) = Gd(φ)
The waveﬁeld modeling principle/manifold separation technique may also be employed as a comple-
ment to the auto-calibration techniques from Section 3.19.5 as well as to array interpolation technique
and uncertainty sets (to be discussed in the next section). For example, in the case of uncertainties in
the array elements’ positions, one may parameterize the array sampling matrix using the closed-form
expressions in [20] and employ the auto-calibration techniques described in Section 3.19.5. The advan-
tage of such an approach is the simplicity of using Fourier basis regardless of the conﬁguration of the
real-world array. One may also employ manifold separation technique with array interpolation technique
to determine the conditions under which the real array output can be transformed to that of a virtual
array, up to a speciﬁed mapping error [20]. Such conditions can be found with or without sector-by-
sector processing. Finally, we note that many antenna measurement techniques, including the spherical
near-ﬁeld approach, are based on waveﬁeld modeling [32,33]. This suggests that the waveﬁeld modeling
principle/manifold separation technique may play a fundamental role in any sensor array application.
3.19.7 Robust methods
Robust array processing procedures trade-off optimality to high reliability when the assumptions on the
nominal signal or noise model do not hold [8,55–57]. The derivation of an optimal method is typically
performed using strict assumptions on the sensor array model, propagation environment, source signals,
as well as statistical properties of interference and noise. A shortcoming of the optimal array processing
procedures is that they are extremely sensitive even to small deviations from the assumed model.
In reality the underlying assumptions may not be valid and a signiﬁcant degradation from the optimal
performance is experienced.
Robust methods acknowledge that the assumptions on signal model may not be valid and do not try
to recover the nonidealities from the observed or calibration data. Instead, they aim at bounding the
inﬂuence of array modeling errors so that small departures from the nominal model lead only to small
errors in the array processor output. One robust approach is based on minimax design which protects

3.19.7 Robust Methods
843
against a worst possible scenario, i.e., it is the best in the worst case. Hence, robust methods are also
applicable if the conditions where the calibration was done are very different from the conditions where
the sensor array system is deployed.
One simple approach is to assume that these errors are random, independent, and zero mean. Hence,
they just decrease the SNR by increasing the noise variance. Since the array covariance matrix plays an
important role in most array processing algorithms it is of interest to study how such a quantity behaves
in nonstandard conditions. Assuming random errors, the perturbations may be expressed using the array
covariance matrix as follows [58]:
RX = (I + 	)[(A(φ) + A(φ))RS(A(φ) + A(φ))H + σ 2(I + RN)](I + 	)H,
where matrix 	 ∈CN×N is associated with errors that inﬂuence both the signal and noise components
of the data. Departures from the nominal array response are included in the matrix A(φ) ∈CN×P.
This matrix contains the perturbations in element positions, errors in gain and phase responses of the
sensors and mutual coupling. The term RN describes the deviation of the noise covariance matrix from
the nominal matrix I (noise is commonly assumed to be zero-mean complex-circular white Gaussian
distributed and RN an identity matrix). The effects of the above perturbations to high resolution DoA
estimation as well as signal and noise subspaces may be studied using the ﬁrst-order analysis introduced
in [58] or by using tools from matrix perturbation theory. In the following, we will consider an example
of robust beamforming that is optimized for the worst case scenario. A more detailed discussion can be
found in chapter Adaptive and Robust Beamforming of this book.
3.19.7.1 Robust technique based on worst-case performance
optimization and uncertainty sets
We have seen that steering vectors of real-world arrays are not exactly known in practice and that lack
of knowledge or uncertainties about the array model may lead to a signiﬁcant performance degradation
in most array processors. For example, one may steer energy towards unwanted directions, cancel
the SOI as well as amplify interfering sources or jammers; see Figure 19.8. The waveﬁeld modeling
principle/manifold separation technique aims at optimally describing (in the MSE sense, for example)
nonidealities from array calibration measurements as well as incorporating such nonidealities into DoA
estimators and beamforming techniques. However, real-world arrays may also be subject to nonidealities
that change as a function of time or cannot be measured in controlled environments. For example, random
ﬂuctuations of the array response due to nearby scatterers or motion of the platform where the array
is mounted are not captured in the calibration stage. In addition, imprecise knowledge of the DoAs
may also lead to a performance degradation of beamforming techniques, a problem known as pointing
angle or look direction errors. The idea of worst-case performance optimization techniques [59,60]
employing so-called uncertainty sets [23,61], is to develop array processing techniques that are robust
to general uncertainties in the steering vector of the real-world array.
Let us denote the exact (but unknown) steering vector of the real-world array by a(φ) ∈CN×1. Also,
let ˜a(φ) ∈CN×1 denote the known but imprecise array steering vector, where ˜a(φ) = a(φ) + 	a.
˜a(φ) may be acquired from array calibration measurements, EM simulation software or may represent
an ideal ULA, for example. The vector 	a ∈CN×1 denotes the uncertainty we have about a(φ) and
may be due to errors in pointing angle or imprecise gain of array elements. Worst-case performance

844
CHAPTER 19 Array Processing in the Face of Nonidealities
0
50
100
150
−30
−25
−20
−15
−10
−5
0
5
Azimuth Angles [deg]
Array Beampatter [dB]
Robust Capon Beamformer
Standard Capon Beamformer
FIGURE 19.8
Example of array beampattern of both standard and robust Capon beamformer in case of steering vector
uncertainties. The standard Capon beamformer cancels the SOI, located at φ = 90◦.
optimization techniques proceed by assuming that the norm of the uncertainty vector can be bounded
by a known ϵ > 0 such that ∥	a∥2 ≤ϵ. This is equivalent to assuming that the imprecise steering
vector ˜a(φ) belongs to a known hyper-ellipsoid centered at a(φ) [23,61]:
(˜a(φ) −a(φ))HC−1(˜a(φ) −a(φ)) ≤1.
(19.32)
Here, C ∈CN×N denotes a known positive-deﬁnite matrix that characterizes the shape of the ellipsoid
and deﬁnes the maximum uncertainty we have about a(φ). Ellipsoids of the form of (19.32) are called
nondegenerate ellipsoids. If the uncertainty ellipsoids fall into a lower-dimensional space they are
called ﬂat (or degenerate) ellipsoids [61]. Flat ellipsoids are employed to make the uncertainty set as
tight as possible but require more prior information about the maximum uncertainty than that of the
nondegenerate ellipsoids.
Worst-case performance optimization techniques have been mostly used in the context of robust
minimum variance beamforming [23,59–61]. The resulting robust beamformers can be shown to belong
to the class of diagonal loading approaches. In fact, the optimal diagonal loading value can be found
exactly from C, unlike most of the ad hoc diagonal loading techniques [8]. However, the value of ϵ and
the shape of the uncertainty ellipsoid are typically speciﬁed by the designer. See e.g., [62] for alternative
approaches to ﬁnd the loading factor automatically.
Let us consider the eigenvalue decomposition of the sample covariance matrix RX = E EH, with
{λn ∈R}N
n=1 denoting the corresponding eigenvalues, and assume that C = ϵIN. The array steering

3.19.7 Robust Methods
845
vector found by employing robust techniques based on uncertainty sets is [23]
a(φ) = ˜a(φ) −E(IN + γ (φ))−1EH ˜a(φ),
(19.33)
where γ (φ) ∈R is the solution of [23]
N

n=1
|[z]n|2
(1 + γ (φ)λn)2 = ϵ.
(19.34)
Here, z = EH ˜a(φ) and γ (φ) > 0 can be shown to belong to the following interval [23]
∥˜a(φ)∥−√ϵ
λ1
√ϵ
≤γ (φ) ≤min
⎧
⎨
⎩

1
ϵ
N

n=1
|[z]n|2
λ2n
1/2
, ∥˜a(φ)∥−√ϵ
λN
√ϵ
⎫
⎬
⎭.
(19.35)
We may now use the steering vector model in (19.33) with the Capon beamformer expression from
Section 3.19.2 in order to have a robust approach for both beamforming as well as DoA estimation.
A summary of this robust technique is provided in Table 19.6.
Typically, robust techniques based on uncertainty sets have a prohibitively large computational
complexity. For example, the value γ (φ) in (19.33) needs to be found for every angle and may not be
found ofﬂine since it is a function of E. An exception that is worth mentioning is the robust beamformer
of [60], where the beamformer weights may be updated snapshot-by-snapshot using subspace tracking
techniques. However, such an approach is still not practical in DoA estimation since it requires ﬁnding
a principal eigenvector for each grid point of the spectral search.
Table 19.6 Steps of Robust Technique based on Uncertainty Sets
Ofﬂine
Step 1
Acquire the array calibration matrix 
A(φc) ∈CN×Q
Step 2
Determine the maximum uncertainty ellipsoid
by choosing an appropriate matrix C
Online
Step 3
Acquire the output of the real-world array x(k), k = 1, . . . , k
Step 4
Find the EVD of 
RX = 1/K K
k=1 x(k)x(k)H
Step 5
Determine γ (φ) by solving (19.34)
Step 6
Apply the Capon beamformer to x(k)
using the array model a(φ) = ˜a(φ) −E (IN + γ (φ))−1 EH ˜a(φ)

846
CHAPTER 19 Array Processing in the Face of Nonidealities
3.19.8 Array processing examples
3.19.8.1 DoA estimation using an ideal uniform linear array and manifold
separation technique
Let us consider that a propagating waveﬁeld, generated by two equi-power and uncorrelated point-
sources, impinge on an ideal ULA from φ = [90◦, 85◦], measured from the endﬁre of the array. The
ULA is composed of 5 omnidirectional elements with an inter-element spacing of d = λ/2. We employ
the root-MUSIC [63] and element-space (ES) root-MUSIC [18] algorithms. Since the employed sensor
array is composed of omnidirectional elements the array sampling matrix G may be found in a closed-
form [20]. Figure 19.9 illustrates the performance of both root-MUSIC and ES root-MUSIC algorithms
in terms of root mean-squared error (RMSE). Only the results for φ1 = 90◦are illustrated but similar
results are obtained for φ2 = 85◦. Figure 19.9a illustrates the RMSE as a function of snapshots, with
SNR = 10 dB, while Figure 19.9b illustrates the RMSE as a function of SNR, with K = 20 snapshots.
The number of columns of G employed by the ES root-MUSIC is M = 25. Results show that the
ES root-MUSIC has a performance very close to the root-MUSIC even though the former employs an
approximation of the array steering vector.
The complexity of the ES root-MUSIC is, of course, higher than that of the root-MUSIC algorithm,
and if the employed sensor array is indeed an ideal ULA one should resort to the standard root-MUSIC
algorithm. However, if the task is estimate DoAs using real-world arrays with imperfections, the ES
10
100
1000
5
10
−1
10
0
10
1
10
2
Snapshots
RMSE [degrees]
root−MUSIC
ES root−MUSIC
Stochastic CRB
(a)
0
10
20
30
40
50
10
−2
10
−1
10
0
10
1
10
2
SNR [dB]
RMSE [degrees]
root−MUSIC
ES root−MUSIC
Stochastic CRB
(b)
FIGURE 19.9
Performance of both standard root-MUSIC and ES root-MUSIC algorithms as a function of (a) snapshots and
(b) SNR. A propagating waveﬁeld, generated by two equi-power and uncorrelated sources, impinge on an
ideal ULA from φ = [90◦, 85◦]. Only the results for φ1 = 90◦are illustrated but similar results are obtained
for φ2 = 85◦. The number of columns of G employed by the ES root-MUSIC is M = 25. Results show that
there is practically no loss of performance, even though the ES root-MUSIC employs an approximation of the
array steering vector.

3.19.8 Array Processing Examples
847
root-MUSIC is a very attractive choice. Note that the complexity of the ES root-MUSIC algorithm may
be reduced by means of Schur factorization and Arnoldi iterations [64].
Let us now suppose that the only information we have about a real-world array is by means of its array
measurement matrix A(φc), and the stochastic CRB expression for array processing in (19.9) needs to
be found. One may employ the manifold separation technique in (19.28) with (19.9) in order to ﬁnd
an approximate CRB expression that is tight even for real-world arrays with nonidealities, excluding
the low SNR regime where the CRB is not a tight bound in general. To illustrate this, let us assume
that the array measurement matrix of the 5-element ULA from Figure 19.5 is obtained from Q = 30
points (φc ∈[−π, π)) with SNRcal = 20 dB. The EADF of such an ULA is obtained from the
array measurement matrix using Eq. (16.30). The resulting array steering vector model, Eq. (19.28),
is employed with the CRB expression in (19.9) in order to obtain an approximate CRB expression.
Figure 19.10 illustrates the ratio between the approximate and exact stochastic CRBs as a function of
the number of columns of G. The results have been averaged over φ ∈[−70◦, 70◦] and 100 realizations
of calibration noise. The approximate CRB expression obtained by employing the manifold separation
principle is accurate since the ratio CRBapprox/CRBexact converges to unity. We also note that the
accuracy of the approximate CRB expression is related to the electrical dimension of the employed
5
10
15
20
25
3
29
10−1
100
101
102
Number of Modes [M]
CRBapprox/CRBexact
FIGURE 19.10
Accuracy of the approximate CRB expression obtained by employing the manifold separation technique.
The ratio between the approximate and exact CRBs is illustrated as a function of the number of columns
of the EADF. The approximate CRB expression is accurate since the ratio CRBapprox/CRBexact converges to
one around M = 15, which is a measure of the electrical dimension of the employed sensor array. The
approximate CRB expression obtained by employing the manifold separation technique is tight and very
useful for real-world arrays with imperfections.

848
CHAPTER 19 Array Processing in the Face of Nonidealities
sensor array. In fact, the ratio CRBapprox/CRBexact converges to unity around M = 15 modes which,
as discussed in Section 3.19.6, is the point where the magnitude of the array sampling matrix starts
decaying superexponentially.
3.19.8.2 Robust beamforming using array calibration
Let us consider that a propagating waveﬁeld, generated by three uncorrelated point-sources, impinge
on an ideal ULA that is identical to the one employed in the previous example. The SOI and interfering
sources impinge on the sensor array from φS = 90◦and (φ1 = 30◦, φ2 = 10◦), respectively. The signal
powers of the interferers are σ 2
1 = σ 2
2 = 20 dB. We consider two sources of uncertainty in the
array steering vector a(φS), namely due to array calibration noise and error in the look direction.
In particular, we employ the array measurement matrix A(φc) of the ULA, found with an SNRcal =
20 dB and Q = 181 calibration points. In addition, we consider that there is an error of two degrees
in the DoA of the SOI. We employ the robust Capon beamformer, obtained by using (19.33) in (19.7),
with the imprecise array steering vector ˜a(φS + 2◦) found directly from A(φc), and by employing
the manifold separation technique, i.e., using the EADF G. The uncertainty ellipsoid is ﬁxed with
C = ϵIN, where ϵ = 0.1. Figure 19.11a illustrates the array output SINR as a function of snapshots
with σ 2
S = 10 dB while Figure 19.11b illustrates the array output SINR as a function of the SNR of
the SOI with K = 100 snapshots. Employing the manifold separation technique leads to improved
performance since it attenuates calibration measurement noise [18].
0
100
200
300
400
500
−5
0
5
10
15
17
Snapshots
SINR [dB]
Optimum
Robust Beamformer
Robust Beamformer w/ MST
(a)
−20
−15
−10
−5
0
5
10
15
20
−15
−10
−5
0
5
10
15
20
25
30
SNR [dB]
SINR [dB]
Optimum
Robust Beamformer
Robust Beamformer w/ MST
(b)
FIGURE 19.11
Performance of the robust beamformer based on uncertainty sets in terms of (a) array output SINR as a
function of snapshots and (b) array output SINR as a function of SNR of the SOI. Two sources of uncertainty
in the array steering vector are considered, namely due to array calibration noise and error in the look direc-
tion. Employing the manifold separation technique leads to improved performance since it allows reducing
calibration measurement noise while modeling array nonidealities.

3.19.8 Array Processing Examples
849
3.19.8.3 Polynomial rooting techniques for real-world arrays with nonidealities
Let us now consider DoA estimation algorithms based on polynomial rooting techniques that can be
employed regardless of the array conﬁguration and nonidealities. Assume that a propagating waveﬁeld,
generated by two point-sources, is observed by the real-world array from Figure 19.12 [65]. The sources
are located in the far-ﬁeld of the sensor array and their DoAs are φ = [60◦, 65◦]T . The sources are
assumed to be located in the same plane (xy-plane) as the employed antenna array. Only the array
measurement matrix A(φc) of the real-world array is known. The interpolated root-MUSIC algorithm
[15] as well as the ES root-MUSIC [18] and the Fourier-domain (FD) root-MUSIC [50] are used to
provide the angle estimates as follows.
The interpolated root-MUSIC algorithm is employed by ﬁrst determining 12 array mapping matrices
{Ts}12
s=1, one for each 30◦-sector, from A(φc). Each of the 12 virtual ULAs (one per sector) is located at
the center of the minimum circle enclosing the employed sensor array and oriented so that its broadside
corresponds to the middle of each sector. The virtual ULAs are composed of ﬁve elements with an
inter-element spacing of λ/2, so that the aperture of the virtual ULAs is maximized while guaranteeing
a small condition number of the mapping matrices. The remaining steps of the interpolated root-MUSIC
algorithm are implemented as described in [15].
The ES root-MUSIC algorithm is implemented by ﬁrst determining the EADF, denoted by G as
described in (16.6.9). This includes taking the FFT of the array measurement matrix and determining
the number of columns M by means of a model order estimation technique such as MDL [54]. After
determining the noise subspace EN of the sample covariance matrix RX, the DoA estimates are found
from the phase-angles of the P roots closest to the unit circle (either inside of outside the unit circle) of
(a)
90
270
180
0
Element 1
Element 2
(b)
FIGURE 19.12
(a) Five-element Inverted-F Antenna (IFA) array built for direction-ﬁnding purposes using handheld terminals.
Its dimensions, center frequency and bandwidth are 6 cm × 4 cm, 3.5 GHz, and ∼100 MHz, respectively.
(b) Magnitude of the radiation pattern of two elements of the array. Each antenna has a different radiation
characteristic which is far from the ideal omnidirectional pattern. Courtesy of the Department of Radio
Science and Technology, Aalto University, Finland.

850
CHAPTER 19 Array Processing in the Face of Nonidealities
the following polynomial
c2M−2 z2M−2 + · · · + c1 z + c0 = 0.
(19.36)
Note that the coefﬁcients in (19.36) may be found in a computationally efﬁcient manner using the FFT:
c = FFT
 N−P

n=1
!!!IFFT

GH[EN]n
!!!
2
"
,
(19.37)
where c = [cM . . . c0 c2M−2 . . . cM+1]T ∈C(2M−1)×1.
The FD root-MUSIC algorithm is implemented by ﬁrst determining the sampled MUSIC nullspec-
trum f(φc) ∈CQ×1:
f(φc) = diag

A(φc)HENEH
N A(φc)

.
(19.38)
Then, the coefﬁcients of the FD root-MUSIC polynomial
g2M−2 z2M−2 + · · · + g1 z + g0 = 0
(19.39)
are obtained as
˜g = FFT{f(φc)},
(19.40a)
g = S˜g,
(19.40b)
where g = [gM . . . g0, g2M−2 . . . gM+1]T ∈C(2M−1)×1 and the selection matrix S ∈C(2M−1)×Q
is obtained in a similar fashion as with the ES root-MUSIC.
Figure 19.13 illustrates the performance of the three polynomial rooting approaches in terms of
RMSE as a function of (a) snapshots with SNR = 20 dB and (b) SNR with K = 100 snapshots.
Only the results for φ2 = 65◦are shown but similar results are obtained for φ1 = 60◦. The algorithms
exploit a noise-free array measurement matrix with Q = 180 calibration points. The degree of both
ES root-MUSIC and FD root-MUSIC polynomials are equal with M = 21. Results show that the ES
root-MUSIC as well as the FD root-MUSIC have similar performance and are closed to the stochastic
CRB while the estimates obtained by the interpolated root-MUSIC have large bias and excess variance.
Figure 19.14 illustrates the sensitivity of both ES root-MUSIC and FD root-MUSIC algorithms,
for a ﬁxed M = 21, to (a) calibration SNR (SNRcal) with Q = 31 and (b) calibration points Q with
SNRcal = 30 dB. Two equi-power sources impinge on the 5-element IFA array from φ = [5◦, 15◦]T
with an SNR = 20 dB and K = 100. Only the results for φ1 = 5◦are illustrated but similar results
are obtained for φ2 = 15◦. Results show that the ES root-MUSIC algorithm outperforms the FD
root-MUSIC when the array measurement matrix is corrupted by calibration noise.
3.19.8.4 Azimuth, elevation, and polarization estimation
Let us now consider the general case of estimating both azimuth φ and elevation θ angles of a completely
polarized EM propagating waveﬁeld. Typically, the polarization of the waveﬁeld is unknown and needs
to be estimated along with the DoAs. The narrowband array output model is now given by
x(k) = [Aφ(φ, θ) Aθ(φ, θ)]V(γ , β)s(k) + n(k),
(19.41)

3.19.8 Array Processing Examples
851
10
0
10
1
10
2
10
3
10
−1
10
0
10
1
10
2
10
3
Snapshots
RMSE [degrees]
ES root−MUSIC
FD root−MUSIC
Interpolated root−MUSIC
Stochastic CRB
(a)
0
5
10
15
20
25
30
35
40
10
−2
10
−1
10
0
10
1
10
2
10
3
SNR[dB]
RMSE [degrees]
ES root−MUSIC
FD root−MUSIC
Interpolated root−MUSIC
Stochastic CRB
(b)
FIGURE 19.13
Performance of interpolated root-MUSIC, ES root-MUSIC, and FD root-MUSIC algorithms as a function of
(a) snapshots and (b) SNR. A propagating waveﬁeld, generated by two equi-power and uncorrelated sources
located at φ = [60◦,65◦]T , impinge the sensor array from Figure 19.12. Only the results for φ2 = 65◦
are illustrated but similar results are obtained for φ1 = 60◦. The array calibration matrix is noise-free and
Q = 180 points have been taken. Results show that the ES root-MUSIC as well as the FD root-MUSIC have
similar performance and are closed to the stochastic CRB while the estimates obtained by the interpolated
root-MUSIC have large bias and excess variance.
0
10
20
30
40
50
10
−1
10
0
10
1
10
2
SNRcal [dB]
RMSE [degrees]
ES root−MUSIC
FD root−MUSIC
Stochastic CRB
(a)
10
1
10
2
10
3
10
−1
10
0
10
1
10
2
Calibration Samples [Q]
RMSE [degrees]
ES root−MUSIC
FD root−MUSIC
Stochastic CRB
(b)
FIGURE 19.14
Sensitivity of ES root-MUSIC and FD root-MUSIC algorithms, with a ﬁxed M = 21, to (a) calibration SNR
(SNRcal) with Q = 31 and (b) number of calibration points Q with SNRcal = 30 dB. Two equi-power sources
impinge on the 5-element IFA array from φ = [5◦, 15◦]T with an SNR = 20 dB and K = 100. Results show
that the ES root-MUSIC algorithm outperforms the FD root-MUSIC when the array measurement matrix is
corrupted by calibration noise.

852
CHAPTER 19 Array Processing in the Face of Nonidealities
where Aφ(φ, θ), Aθ(φ, θ) ∈CN×P denote the array steering matrices due to a vertical and horizontal
polarized waveﬁelds, respectively. V(γ , β) = [Vφ(γ ), Vθ(γ , β)]T ∈C2P×P describes the polarization
of the waveﬁeld and it is typically given by
Vφ(γ ) = diag{vφ(γ1), . . . , vφ(γP)},
(19.42a)
Vθ(γ , φ) = diag{vθ(γ1, β1), . . . , vθ(γP, βP)},
(19.42b)
where vφ(γp) = cos (γp) and vθ(γp, βp) = sin (γp)ejβp. The parameters γ and β describe the polariza-
tion ellipse of the received Electric-ﬁeld and take values over 0 ≤γ ≤π/2 and −π ≤β < π, respec-
tively. The techniques described in Sections 3.19.5 and 3.19.6 may now be employed to (19.41) by mod-
eling the array steering vector a(θ, φ, γ, β) ∈CN×1 either in a parametric or non-parametric manner.
In particular, the waveﬁeld modeling principle/manifold separation technique for completely polar-
ized EM waveﬁelds consists in employing so-called vector spherical harmonics, instead of Fourier basis
in (19.27b, 19.27a) and (19.28). The motivation for using vector spherical harmonics follows from the
fact that such basis functions form a complete and orthonormal set on the 2-sphere, similarly to Fourier
basis in azimuth-only processing. However, vector spherical harmonics, which have a rather cumber-
some algebraic form, are less attractive than Fourier basis for the purposes of array processing and may
be subject to numerical instabilities. In fact, a formulation of the waveﬁeld modeling principle/manifold
separation technique involving 2-D Fourier basis may be found in [53], where it is employed the so-
called equivalence matrix [19]. A summary of the waveﬁeld modeling principle/manifold separation
technique for completely polarized EM waveﬁelds is given in Table 19.7.
Let us consider that a propagating EM waveﬁeld, generated by two equi-power far-ﬁeld point-
sources, is received by the 5-element IFA from Figure 19.12. The DoAs and polarization parameters
Table 19.7 Steps of Waveﬁeld Modeling Principle/Manifold Separation
Technique for Completely Polarized EM Waveﬁelds
Ofﬂine
Step 1
Acquire the array calibration matrices 
Aφ(φc, θc), 
Aθ(φc, θc)
with φc ∈[0, 2π) and θc ∈[0, π]
Step 2
Find 
G by taking a discrete vector spherical harmonic transform
of 
Aφ(φc, θc), 
Aθ(φc, θc)
Step 3
Estimate the array sampling matrix 
G by employing
model order estimation techniques
Step 4
Employ the equivalence matrix  and ﬁnd  = 
G
Online
Step 5
Acquire the output of the real array x(k), k = 1, . . . , K
Step 6
Apply DoA estimators and beamforming techniques to x(k)
using the array model ˆa(θ, φ, γ , β) = (I2 ⊗d(θ, φ))v(γ , β),
where d(θ, φ) = d(φ) ⊗d(θ)

3.19.9 Conclusion
853
0
5
10
15
20
25
30
35
40
10
−2
10
−1
10
0
10
1
10
2
SNR [dB]
RMSE [degrees]
θ1 PES MUSIC
θ1 Stochastic CRLB
θ2 PES MUSIC
θ2 Stochastic CRLB
(a)
0
5
10
15
20
25
30
35
40
10
−2
10
−1
10
0
10
1
10
2
10
3
SNR [dB]
RMSE [degrees]
φ1 PES MUSIC
φ1 Stochastic CRLB
φ2 PES MUSIC
φ2 Stochastic CRLB
(b)
FIGURE 19.15
Statistical performance of the PES MUSIC algorithm using the 5-element IFA from Figure 19.12. The DoAs
and polarization parameters are (θ1 = 20◦, θ2 = 40◦), (φ1 = 25◦, φ2 = 60◦) and (γ1 = 10◦, γ2 = 20◦),
(β1 = 10◦, β2 = 50◦), respectively. The PES MUSIC algorithm takes into account array nonidealities and
has a performance close to the stochastic CRB.
are (θ1 = 20◦, θ2 = 40◦), (φ1 = 25◦, φ2 = 60◦), and (γ1 = 10◦, γ2 = 20◦), (β1 = 10◦, β2 = 50◦),
respectively. K = 100 snapshots are acquired at the array output. The array response was obtained
from an EM simulation software; see [65] for details. The manifold separation technique is employed
for determining the array steering vector model along with its nonidealities, as described in Table 19.7.
The polarimetric element-space (PES) MUSIC algorithm [53] is used for estimating both DoAs and
polarization parameters of the sources generating the waveﬁeld.
Figure 19.15 illustrates the statistical performance of the PES MUSIC in terms of RMSE as a
function of SNR. Only the angle estimates are shown but similar results are obtained for the polarization
parameters. Results show that the PES MUSIC algorithm has a performance close to the stochastic CRB
since it takes into account array nonidealities.
3.19.9 Conclusion
In this chapter, array signal processing in face of array nonidealities was addressed. Real-world arrays
are always subject to nonidealities such as mutual coupling, mounting platform reﬂections,
cross-polarization effects, sensors with individual beampatterns as well as sensors’ position errors.
We have seen that such nonidealities typically lead to a signiﬁcant performance degradation as well as
loss of optimality of DoA estimators and beamforming techniques.
Various techniques for dealing with array nonidealities have been described. They are classiﬁed as
model-driven techniques, data-driven, and robust methods. Model-driven techniques use an explicit for-
mulation describing each nonideality, which may be challenging to specify, and include auto-calibration
techniques as well as so-called parametric calibration methods. Data-driven techniques do not assume
any explicit formulation for the nonidealities but employ array calibration measurements. They cap-

854
CHAPTER 19 Array Processing in the Face of Nonidealities
ture the nonidealities implicitly by using basis function expansion, interpolation, approximation or
nonparameteric estimation techniques. Data-driven techniques include local interpolation of the array
calibration matrix, array interpolation as well as manifold separation techniques. Finally, robust meth-
ods try to bound the inﬂuence of nonidealities in the estimation process instead of trying to capture
them. Typically, robust methods trade-off optimality for reliability.
Extensive array processing examples have been included. They explain in detail how array processing
techniques may deal with array nonidealities by employing data-driven techniques as well as robust
methods.
We note that the various techniques for dealing with array nonidealities described in this chapter
have different features and may complement each other. Future research work may thus be based on
combining auto-calibration techniques and robust methods with manifold separation.
Relevant Theory: Signal Processing Theory, Statistical Signal Processing and Array Signal Processing
See Vol. 1, Chapter 11 Parametric Estimation
See this Volume, Chapter 2 Model Order Selection
See this Volume, Chapter 16 Performance Bounds and Statistical Analysis of DOA Estimation
References
[1] P. Stoica, R. Moses, Introduction to Spectral Analysis, Wiley, 1997.
[2] H. Krim, M. Viberg, Two decades of array signal processing, IEEE Signal Process. Mag. (1996) 67–94.
[3] S. Wijnholds, S. van der Tol, R. Nijboer, A. van der Veen, Calibration challenges for future radio telescopes,
IEEE Signal Process. Mag. 27 (1) (2010) 30–42.
[4] D. Gesbert, C. van Rensburg, F. Tosato, F. Kaltenberger, Multiple antenna techniques, in: S. Sesia, I. Touﬁk,
M. Baker (Eds.), LTE—The UMTS Long Term Evolution: From Theory to Practice, John Wiley and Sons,
2009, pp. 243–283 (Chapter 11).
[5] F. Belloni, V. Ranki, A. Kainulainen, A. Richter, Angle-based indoor positioning system for open indoor
environments, in: Workshop on Positioning, Navigation and Communication, 2009, pp. 261–265.
[6] M. Viberg, M. Lanne, A. Lundgren, Calibration in array processing, in: T. Tuncer, B. Friedlander (Eds.),
Classical and Modern Direction-of-Arrival Estimation, Academic Press, Burlington, MA, USA, 2009,
pp. 93–124 (Chapter 3).
[7] M. Jansson, A. Swindlehurst, B. Ottersten, Weighted subspace ﬁtting for general array error models, IEEE
Trans. Signal Process. 46 (9) (1998) 2484–2498.
[8] A. Gershman, Robust adaptive beamforming in sensor arrays, Int. J. Electron. Commun. 53 (6) (1999)
305–314.
[9] R. Mailloux, Array failure correction with a digitally beamformed array, IEEE Trans. Antennas Propag. 44
(12) (1996) 1543–1550.
[10] A. Waters, V. Cevher, Distributed bearing estimation via matrix completion, in: Proceedings of the IEEE
International Conference on Acoustics, Speech, and Signal Processing, 2010, pp. 2590–2593.
[11] A.Weiss,B.Friedlander,Eigenstructuremethodsfordirectionﬁndingwithsensorgainandphaseuncertainties,
Circ. Syst. Signal Process. 9 (3) (1990) 271–300.
[12] A. Weiss, B. Friedlander, Array shape calibration using sources in unknown locations—a maximum likelihood
approach, IEEE Trans. Acoust. Speech Signal Process. 37 (12) (1989) 1958–1966.

References
855
[13] Y. Rockah, P. Schultheiss, Array shape calibration using sources in unknown locations—Part I: far-ﬁeld
sources, IEEE Trans. Acoust. Speech Signal Process. 35 (3) (1987) 286–299.
[14] M. Viberg, A. Swindlehurst, A Bayesian approach to auto-calibration for parametric array signal processing,
IEEE Trans. Signal Process. 42 (12) (1994) 3495–3507.
[15] B. Friedlander, The root-MUSIC algorithm for direction ﬁnding with interpolated arrays, Signal Process. 30
(1993) 15–19.
[16] P. Hyberg, M. Jansson, B. Ottersten, Array interpolation and DOA MSE reduction, IEEE Trans. Signal Process.
53 (12) (2005) 4464–4471.
[17] A.Gershman,J.Böhme,AnoteonmostfavorablearraygeometriesforDOAestimationandarrayinterpolation,
IEEE Signal Process. Lett. 4 (8) (1997) 232–235.
[18] F. Belloni, A. Richter, V. Koivunen, DoA estimation via manifold separation for arbitrary array structures,
IEEE Trans. Signal Process. 55 (10) (2007) 4800–4810.
[19] M. Costa, A. Richter, V. Koivunen, Uniﬁed array manifold decomposition based on spherical harmonics and
2-D Fourier basis, IEEE Trans. Signal Process. 58 (9) (2010) 4634–4645.
[20] M. Doron, E. Doron, Waveﬁeld modeling and array processing, Part I—Spatial sampling, IEEE Trans. Signal
Process. 42 (10) (1994) 2549–2559.
[21] M. Doron, E. Doron, Waveﬁeld modeling and array processing, Part II—Algorithms, IEEE Trans. Signal
Process. 42 (10) (1994) 2560–2570.
[22] M. Doron, E. Doron, Waveﬁeld modeling and array processing, Part III—Resolution capacity, IEEE Trans.
Signal Process. 42 (10) (1994) 2571–2580.
[23] J. Li, P. Stoica, Z. Wang, On robust Capon beamforming and diagonal loading, IEEE Trans. Signal Process.
51 (7) (2003) 1702–1715.
[24] S. Kay, Fundamentals of Statistical Signal Processing: Estimation Theory, Prentice Hall, 1993.
[25] P. Stoica, E. Larsson, A. Gershman, The stochastic CRB for array processing: a textbook derivation, IEEE
Signal Process. Lett. 8 (5) (2001) 148–150.
[26] P. Stoica, B. Ottersten, M. Viberg, R. Moses, Maximum likelihood array processing for stochastic coherent
sources, IEEE Trans. Signal Process. 44 (1) (1996) 96–105.
[27] V. Koivunen, E. Ollila, Direction of arrival estimation under uncertainty, in: S. Chandran (Ed.), Advances in
Direction of Arrival Estimation, Artech House, 2006, pp. 241–258 (Chapter 12).
[28] R. Mailloux, Phased Array Antenna Handbook, second ed., Artech House, 2005.
[29] K. Dandekar, H. Ling, G. Xu, Effect of mutual coupling on direction ﬁnding in smart antenna applications,
Electron. Lett. 36 (22) (2000) 1889–1891.
[30] R. Goossens, H. Rogier, A hybrid UCA-RARE/root-MUSIC approach for 2-D direction of arrival estimation
in uniform circular arrays in the presence of mutual coupling, IEEE Trans. Antennas Propag. 55 (3) (2007)
841–849.
[31] H. Steyskal, J. Herd, Mutual coupling compensation in small array antennas, IEEE Trans. Antennas Propag.
38 (12) (1990) 1971–1975.
[32] J. Hansen (Ed.), Spherical Near-Field Antenna Measurements, Peter Peregrinus Ltd., 1988.
[33] M. Landmann, M. Käske, R. Thomä, Impact of incomplete and inaccurate data models on high resolution
parameter estimation in multidimensional channel sounding, IEEE Trans. Antennas Propag. 60 (2) (2012)
557–573.
[34] M. Zatman, How narrowband is narrowband? IEE Proc. Radar Sonar Navig. 145 (2) (1998) 85–91.
[35] H. Wang, M. Kaveh, Coherent signal-subspace processing for the detection and estimation of angles of arrival
of multiple wide-band sources, IEEE Trans. Acoust. Speech Signal Process. 33 (4) (1985) 823–831.
[36] R. Klemm, Principles of Space-Time Adaptive Processing, The Institution of Electrical Engineers, 2002.
[37] S. Werner, M. With, V. Koivunen, Householder multistage Wiener ﬁlter for space-time navigation receivers,
IEEE Trans. Aerosp. Electron. Syst. 43 (3) (2007) 975–988.

856
CHAPTER 19 Array Processing in the Face of Nonidealities
[38] J. Sorelius, R. Moses, T. Söderström, A. Swindlehurst, Effects of nonzero bandwidth on direction of arrival
estimators in array signal processing, IEE Proc. Radar Sonar Navig. 145 (6) (1998) 317–324.
[39] A. Abidi, Direct-conversion radio transceivers for digital communications, IEEE J. Solid State Circ. 30 (12)
(1995) 1399–1410.
[40] U. Nickel, On the inﬂuence of channel errors on array signal processing methods, Int. J. Electron. Commun.
47 (4) (1993) 209–219.
[41] F. Demmel, Practical aspects of design and application of direction-ﬁnding systems, in: T. Tuncer, B. Fried-
lander (Eds.), Classical and Modern Direction-of-Arrival Estimation, Academic Press, Burlington, MA, USA,
2009, pp. 53–92.
[42] G. Krishnamurthy, K. Gard, Time division multiplexing front-ends for multiantenna integrated wireless
receivers, IEEE Trans. Circ. Syst. I: Regular Papers 57 (6) (2010) 1231–1243.
[43] S. Loyka, The inﬂuence of electromagnetic environment on operation of active array antennas: analysis and
simulation techniques, IEEE Antennas Propag. Mag. 41 (6) (1999) 23–39.
[44] M. Valkama, A. Springer, G. Hueber, Digital signal processing for reducing the effects of RF imperfections in
radio devices—an overview, in: Proceedings of the IEEE International Symposium on Circuits and Systems,
2010, pp. 813–816.
[45] J. Toivanen, T. Laitinen, P. Vainikainen, Modiﬁed test zone ﬁeld compensation for small-antenna measure-
ments, IEEE Trans. Antennas Propag. 58 (11) (2010) 3471–3479.
[46] G. Golub, C. Loan, Matrix Computations, third ed., John Hopkins University Press, 1996.
[47] J. Fessler, A. Hero, Space-alternating generalized expectation-maximization algorithm, IEEE Trans. Signal
Process. 42 (10) (1994) 2664–2677.
[48] P. Stoica, K. Sharman, Maximum likelihood methods for direction-of-arrival estimation, IEEE Trans. Acoust.
Speech Signal Process. 38 (7) (1990) 1132–1143.
[49] M. Viberg, B. Ottersten, Sensor array processing based on subspace ﬁtting, IEEE Trans. Signal Process. 39
(5) (1991) 1110–1121.
[50] M. Rübsamen, A. Gershman, Direction-of-arrival estimation for nonuniform sensor arrays: from manifold
separation to Fourier domain MUSIC methods, IEEE Trans. Signal Process. 57 (2) (2009) 588–599.
[51] C. Mathews, M. Zoltowski, Eigenstructure techniques for 2-D angle estimation with uniform circular arrays,
IEEE Trans. Signal Process. 42 (9) (1994) 2395–2407.
[52] M. Pesavento, A. Gershman, Z. Luo, Robust array interpolation using second-order cone programming, IEEE
Signal Process. Lett. 9 (1) (2002) 8–11.
[53] M. Costa, A. Richter, V. Koivunen, DoA and polarization estimation for arbitrary array conﬁgurations, IEEE
Trans. Signal Process. 60 (5) (2012) 2330–2343.
[54] J. Rissanen, MDL denoising, IEEE Trans. Inform. Theory 46 (7) (2000) 2537–2543.
[55] J. Li, P. Stoica (Eds.), Robust Adaptive Beamforming, John Wiley and Sons, 2006.
[56] A. Zoubir, V. Koivunen, Y. Chakhchoukh, M. Muma, Robust estimation in signal processing, IEEE Signal
Process. Mag. 29 (2012).
[57] E. Ollila, V. Koivunen, Robust estimation techniques for complex-valued random vectors, in: S. Haykin,
T. Adali (Eds.), Adaptive Signal Processing: Next Generation Solutions, Wiley, 2009, pp. 87–142.
[58] A. Swindlehurst, T. Kailath, A performance analysis of subspace-based methods in the presence of model
errors—Part I: the MUSIC algorithm, IEEE Trans. Signal Process. 40 (7) (1992) 1758–1774.
[59] S. Vorobyov, A. Gershman, Z. Luo, Robust adaptive beamforming using worst-case performance optimization:
a solution to the signal mismatch problem, IEEE Trans. Signal Process. 51 (2) (2003) 313–324.
[60] S. Shahbazpanahi, A. Gershman, Z. Luo, K. Wong, Robust adaptive beamforming for general-rank signal
models, IEEE Trans. Signal Process. 51 (9) (2003) 2257–2269.
[61] R. Lorenz, S. Boyd, Robust minimum variance beamforming, IEEE Trans. Signal Process. 53 (5) (2005)
1684–1696.

References
857
[62] L. Du, T. Yardibi, J. Li, P. Stoica, Review of user parameter-free robust adaptive beamforming algorithms,
Digit. Signal Process. 19 (4) (2009) 567–582.
[63] A. Barabell, Improving the resolution performance of the eigenstructure-based direction-ﬁnding algorithms,
in: IEEE International Conference on Acoustics, Speech and Signal Processing, 1983, pp. 336–339.
[64] J. Zhuang, W. Li, A. Manikas, Fast root-MUSIC for arbitrary arrays, Electron. Lett. 46 (2) (2010) 174–176.
[65] A. Azremi, M. Kyro, J. Ilvonen, J. Holopainen, S. Ranvier, C. Icheln, P. Vainikainen, Five-element inverted-F
antenna array for MIMO communications and radio direction ﬁnding on mobile terminal, in: Loughborough
Antennas and Propagation Conference, 2009, pp. 557–560.

20
CHAPTER
Applications of Array Signal
Processing
A. Lee Swindlehurst*, Brian D. Jeffs†, Gonzalo Seco-Granados‡, and Jian Li§
*Department of Electrical Engineering and Computer Science, University of California, Irvine, CA, USA
†Department of Electrical and Computer Engineering, Brigham Young University, Provo, UT, USA
‡Department of Telecommunications and Systems Engineering, Universitat Autònoma de Barcelona,
Bellaterra, Barcelona, Spain
§Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA
3.20.1 Introduction and background
The principles behind obtaining information from measuring an acoustic or electro-magnetic ﬁeld at
differentpointsinspacehavebeenunderstoodformanyyears.Techniquesforlong-baselineopticalinter-
ferometry were known in the mid-19th century, where widely separated telescopes were proposed for
high-resolution astronomical imaging. The idea that direction ﬁnding can be performed with two acous-
tic sensors has been around at least as long as the physiology of human hearing has been understood. The
mathematical duality observed between sampling a signal either uniformly in time or uniformly in space
is ultimately just an elegant expression of Einstein’s theory of relativity. However, most of the technical
advances in array signal processing have occurred in the last 30 years, with the development and prolif-
eration of inexpensive and high-rate analog-to-digital (A/D) converters together with ﬂexible and very
powerful digital signal processors (DSPs). These devices have made the chore of collecting data from
multiple sensors relatively easy, and helped give birth to the use of sensor arrays in many different areas.
Parallel to the advances in hardware that facilitated the construction of sensor array platforms were
breakthroughs in the mathematical tools and models used to exploit sensor array data. Finite impulse
response (FIR) ﬁlter design methods originally developed for time-domain applications were soon
applied to uniform linear arrays in implementing digital beamformers. Powerful data-adaptive beam-
formers with constrained look directions were conceived and applied with great success in applications
where the rejection of strong interference was required. Least-mean square (LMS) and recursive least-
squares (RLS) time-adaptive techniques were developed for time-varying scenarios. So-called “blind”
adaptive beamforming algorithms were devised that exploited known temporal properties of the desired
signal rather than its direction-of-arrival (DOA).
For applications where a sensor array was to be used for locating a signal source, for example
ﬁnding the source’s DOA, one of the key theoretical developments was the parametric vector-space
formulation introduced by Schmidt and others in the 1980s. They popularized a vector space signal
model with a parameterized array manifold that helped connect problems in array signal processing
to advanced estimation theoretic tools such as Maximum Likelihood (ML), Minimum Mean-Square
Estimation (MMSE) the Likelihood Ratio Test (LRT) and the Cramér-Rao Bound (CRB). With these
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-411597-2.00020-5
© 2014 Elsevier Ltd. All rights reserved.
859

860
CHAPTER 20 Applications of Array Signal Processing
tools, one could rigorously deﬁne the meaning of the term “optimal” and performance could be compared
against theoretical bounds. Trade-offs between computation and performance led to the development of
efﬁcient algorithms that exploited certain types of array geometries. Later, concerns about the ﬁdelity
of array manifold models motivated researchers to study more robust designs and to focus on models
that exploited properties of the received signals themselves.
The driving applications for many of the advances in array signal processing mentioned above
have come from military problems involving radar and sonar. For obvious reasons, the military has
great interest in the ability of multi-sensor surveillance systems to locate and track multiple “sources
of interest” with high resolution. Furthermore, the potential to null co-channel interference through
beamforming(orperhapsmoreprecisely,“null-steering”)isacriticaladvantagegainedbyusingmultiple
antennas for sensing and communication. The interference mitigation capabilities of antenna arrays and
information theoretic analyses promising large capacity gains has given rise to a surge of applications for
arrays in multi-input, multi-output (MIMO) wireless communications in the last 15 years. Essentially
all current and planned cellular networks and wireless standards rely on the use of antenna arrays for
extending range, minimizing transmit power, increasing throughput, and reducing interference. From
peering to the edge of the universe with arrays of radio telescopes to probing the structure of the brain
using electrode arrays for electroencephalography (EEG), many other applications have beneﬁted from
advances in array signal processing.
In this chapter, we explore some of the many applications in which array signal processing has
proven to be useful. We place emphasis on the word “some” here, since our discussion will not be
exhaustive. We will discuss several popular applications across a wide variety of disciplines to indicate
the breadth of the ﬁeld, rather than delve deeply into any one or try to list them all. Our emphasis will be
on developing a data model for each application that falls within the common mathematical framework
typically assumed in array processing problems. We will spend little time on algorithms, presuming that
such material is covered elsewhere in this collection; algorithm issues will only be addressed when the
model structure for a given application has unique implications on algorithm choice and implementation.
Since radar and wireless communications problems are discussed in extensive detail elsewhere in the
book, our discussion of these topics will be relatively brief.
3.20.2 Radar applications
We begin with the application area for which array signal processing has had the most long-lasting
impact, dating back to at least World War II. Early radar surveillance systems, and even many still in
use today, obtain high angular resolution by employing a radar dish that is mechanically steered in order
to scan a region of interest. While such slow scanning speeds are suitable for weather or navigation
purposes, they are less tolerable in military applications where split-second decisions must be made
regarding targets (e.g., missiles) that may be moving at several thousand miles per hour. The advent of
electronically scanned phased arrays addressed this problem, and ushered in the era of modern array
signal processing.
Phased arrays are composed of from a few up to several thousand individual antennas laid out in a line,
circle,rectangleorevenrandomly.Directionalityisachievedbytheprocessofbeamforming:multiplying
the output of each antenna by a complex weight with a properly designed phase (hence the term
“phased” array), and then summing these weighted outputs together. The conventional “delay-and-sum”

3.20.2 Radar Applications
861
FIGURE 20.1
A phased array radar enclosed in the nose of a ﬁghter jet.
beamforming scheme involves choosing the weights to phase delay the individual antenna outputs such
that signals from a chosen direction add constructively and those from other directions do not. Since
the weights are applied electronically, they can be rapidly changed in order to focus the array in many
different directions in a very short period of time. Modern phased arrays can scan an entire hemisphere
of directions thousands of times per second. Figures 20.1 and 20.2 show examples of airborne and
ground-based phased array radars.
For scanning phased arrays, a ﬁxed set of beamforming weights is repeatedly applied to the antennas
over and over again, in order to provide coverage of some area of interest. Techniques borrowed from
time-domain ﬁlter design such as windowing or frequency sampling can be used to determine the
beamformer weights, and the primary trade-off is beamwidth/resolution versus sidelobe levels. Adaptive
weight design is required if interference or clutter must be mitigated. In principle, the phased array
beamformer can be implemented with either analog or digital hardware, or a combination of both. For
arrays with a very large number of antennas (e.g., the Patriot radar has in excess of 5000 elements),
analog techniques are often employed due to the hardware and energy expense required in implementing
a separate RF receive chain for each antenna. Hybrid implementations are also used in which analog
beamformingoversubsetsofthearrayisusedtocreateasmallernumberofsignalstreams,whicharethen
processed by a digital beamformer. This is a common approach, for example, in shipborne radar systems,
where the targets of interest (e.g., low altitude cruise missiles) are typically located near the horizon. In
such systems, analog beamforming with vertically-oriented strips of antennas are used to create a set
of narrow azimuthal beams whose outputs can be ﬂexibly combined using digital signal processing.

862
CHAPTER 20 Applications of Array Signal Processing
FIGURE 20.2
The phased array used for targeting the Patriot surface-to-air missile system, composed of over 5000 indi-
vidual elements.
In this section, we will brieﬂy discuss the two radar array applications that have received the most
attention in the signal processing literature: space-time adaptive processing (STAP) and MIMO radar.
Since these are discussed in detail elsewhere in the book, our discussion will not be comprehensive.
While STAP and MIMO radar applications are typically used in active radar systems, arrays are also
useful for passive radars, such as those employed in radio astronomy. We will devote a separate section
to array signal processing for radio astronomy and discuss this application in much more detail, since
it is not addressed elsewhere in the book.
3.20.2.1 Space-time adaptive processing
In many tactical military applications, airborne surveillance radars are tasked with providing location
and tracking information about moving objects both on the ground and in the air. These radars typically

3.20.2 Radar Applications
863
clutter with
positive Doppler
clutter with
negative Doppler
jammer
FIGURE 20.3
Airborne STAP scenario with clutter and jamming.
use pulse-Doppler techniques since measuring the velocity of the objects of interest (or “targets”) is a key
to accurately tracking them. As depicted in Figure 20.3, even when the targets are airborne, the transmit
mainbeam and sidelobes will still illuminate the ground, especially when the radar look-direction is
at a negative elevation angle (the targets may be below the radar platform). This means that the radar
returns will contain signiﬁcant energy from ground reﬂections, referred to as clutter. In addition, since
pulse-Doppler techniques require an active radar, the frequency support of the radar signal is known,
and an adversary can employ strong jamming to further mask the target returns. Often, the target signal
is many tens of dB (e.g., 50 or more) weaker than the combination of jamming and clutter.
The difﬁculty of the situation is revealed by Figure 20.4, which shows the angle-Doppler power
spectrum of data that contains a target together with clutter and jamming at a particular range. The
jamming signal is due to a point source, so it is conﬁned to a single arrival angle, but the jamming signal
extends across the entire bandwidth of the data. The clutter energy lies on a ridge that cuts across the
angle-Doppler space in a direction that is a function of the heading, altitude and velocity of the radar, and
the current range bin of interest. Clutter in front of the radar will have a positive Doppler, and that behind
it will be negative (as seen in Figure 20.3). Compared with the clutter and jamming, the target signal is
weak and cannot be distinguished from the background due to the limited dynamic range of the receiver.
Doppler ﬁltering alone is not sufﬁcient to reveal the target, since the jamming signal cuts across the entire
bandwidth of the signal. On the other hand, using spatial ﬁltering (beamforming) to null the jammer
will still leave most of the clutter untouched. What is needed is a two-dimensional space-time ﬁlter. The
process of designing and applying such a ﬁlter is referred to as space-time adaptive processing (STAP).
To better place STAP in the context of array signal processing problems, consider Figure 20.5 which
depicts how data is organized in an M-antenna pulse-Doppler radar. The radar transmits a series of K

864
CHAPTER 20 Applications of Array Signal Processing
clutter
target
jamming
FIGURE 20.4
Angle-Doppler spectrum with weak target in the presence of clutter and jamming.
Pulse1
Pulse2
PulseK
Pulse1
Pulse2
PulseK
Pulse1
Pulse2
PulseK
Channel 1
Channel 2
Channel M
1 2 3
r
r
r
r
r
r
r
r
r
r
r
r
r
r
r
FIGURE 20.5
Organization of data for range bin r in STAP pulsed-Doppler radar.

3.20.2 Radar Applications
865
pulses separated in time by a ﬁxed pulse repetition interval (PRI). In order to focus sufﬁcient energy to
obtain a measurable return from a target, the transmitted pulse is typically a very spatially focused signal
steered towards a particular azimuth and elevation angle or look direction. However, the mathematical
description of the STAP process can be described independently of this assumption. In between the
pulses, the radar collects the returns from each of the M antennas, which are sampled after the received
data is passed through a pulse-compression matched ﬁlter. Each sample corresponds to the aggregate
contribution of scatterers (clutter and targets, if such exist) at a particular range together with any noise,
jamming or other interference that may be present. The range for a given sample is given by the speed
of light multiplied by half the time interval between transmission of the pulse and the sampling instant.
Suppose we are interested in a particular range bin r. As shown in the ﬁgure, we will let
˜y(t) =
⎡
⎢⎣
˜y1(t)
...
˜yM(t)
⎤
⎥⎦,
(20.1)
Y0 =
 ˜y(1) · · ·
˜y(K)	
(20.2)
represent the M × 1 vector of returns from the array after pulse t and the M × K matrix of returns from
all K pulses for range bin r, respectively.
Alternatively, as shown in Figure 20.6, the data can be viewed as forming a cube over M antennas,
K pulses, and B total range bins. Each range bin corresponds to a different slice of the data cube. Data
from adjacent range bins Yk will be used to counter the effect of clutter and jamming in the range bin of
interest, which we index with k = 0. The time required to collect the data cube for a given look direction
is referred to as a coherent processing interval (CPI). If the radar employs multiple look directions, a
separate CPI is required for each. Assuming the target, clutter and jamming are stationary over different
CPIs, data from these CPIs can be combined to perform target detection and localization. However,
in our discussion here we will assume that data from only a single CPI is available to determine the
presence or absence of a target in range bin r.
K pulses
M channels
FIGURE 20.6
STAP data cube showing slices for range bin of interest (Y0) and secondary range bin (Yk).

866
CHAPTER 20 Applications of Array Signal Processing
If a target is present in the data set Y0, then the received signal can be modeled as
˜y(t) = b0a(θ0, φ0)e jω0t +
Dc

i=1
bia(θi, φi)e jωit +
D j

j=1
a(θ∗
j , φ∗
j )x j(t) + n(t)



˜e(t)
,
(20.3)
where bi is the amplitude of the return from the ith scatterer (i = 0 corresponds to the target), (θi, φi) are
the azimuth and elevation angles of the ith scatterer, ωi is the corresponding Doppler frequency, a(θ, φ)
is the response of the M-element receive array to a signal from direction (θi, φi), x j(t) is the signal
transmitted by the jth jammer, (θ∗
j , φ∗
j ) denote the DOA of the jth jammer signal, Dc represents the
number of distinct clutter sources, D j the number of jammers, and n(t) corresponds to any remaining
background noise and interference. We have also deﬁned ˜e(t) to contain all received signals except that
of the target. Note that the above model assumes the relative velocity of the radar and all scatterers is
constant over the CPI, so that the Doppler effect can be described as a complex sinusoid.
Technically, the amplitude and Doppler terms bi and ωi will also depend on the azimuth and elevation
angles of the ith scatterer since the Doppler frequency is position-dependent and the strength of the
return is a function of the transmit beampattern in addition to the intrinsic radar cross section (RCS)
of the scatterer. This is clear from Figure 20.7, which shows the geometry of the airborne radar with
respect a clutter patch on the ground at some range r. The Doppler frequency for the given clutter patch
at azimuth θ and elevation φ can be determined from the following equations:
sin φ = H
r +
r2 −H2
2r(re + H),
(20.4)
cos α = sin θ cos φ,
(20.5)
ω = 4πV
λ
cos α,
(20.6)
FIGURE 20.7
Geometry for determining the Doppler frequency due to a ground clutter patch at range r.

3.20.2 Radar Applications
867
where re denotes the earth’s radius, H is the altitude of the radar, and α is the angle between the
velocity vector of the radar and the clutter patch. To simplify the notation, we have dropped the explicit
dependence of bi and ωi on θi, φi. While the highest Doppler frequencies obviously occur for small
α (forward- or rear-looking radar), the fact that cos α changes relatively slowly for small α compared
with α near 90◦means that the Doppler spread of the clutter for a forward- or rear-looking radar will
be smaller than that for the side-looking case.
Rather than working with the data matrix Y0, for STAP it is convenient to vectorize the data as
follows:
y0 = vec(Y0) =
⎡
⎢⎣
˜y(1)
...
˜y(K)
⎤
⎥⎦= b0s(θ0, φ0, ω0) + e0,
(20.7)
where e0 is deﬁned similarly to y0 for the clutter and jamming, and where
s(θ0, φ0, ω0) = vec

a(θ0, φ0)

e jω0 e j2ω0 · · · e j Kω0

(20.8)
=
⎡
⎣
e jω0
...
e j Kω0
⎤
⎦⊗a(θ0, φ0).
(20.9)
The MK × 1 vector y0 is the space-time snapshot associated with the given range bin (r) of interest. To
detect whether or not a target signal was present in y0, one may be tempted to use a minimum-variance
distortionless response (MVDR) space-time ﬁlter of the form
w(θ, φ, ω) =
R−1
y0 s(θ, φ, ω)
sH(θ, φ, ω)R−1
y0 s(θ, φ, ω)
,
(20.10)
apply it to y0 for various choices of (θ, φ, ω), which then should lead to a peak in the ﬁlter output
when (θ, φ, ω) corresponds to the parameters of the target. The problem with this approach is that
we will not have enough data available to estimate the covariance Ry0; if the target signal is only
present in this range bin, then with a single CPI we only have a single snapshot that possesses this
covariance.
Fortunately, an alternative approach exists, since it can be shown via the matrix inversion lemma
(MIL) that the optimal MVDR space-time ﬁlter is proportional to another vector that can be more readily
estimated:
w(θ, φ, ω) ∝R−1
e0 s(θ, φ, ω),
(20.11)
which depends on the covariance Re0 of the clutter and jamming. In particular, STAP relies on the
assumption that the statistics of the clutter and jamming in range bins near the one in question are
similar, and can be used to estimate Re0. For example, let S0 = {k1, k2, . . ., kNs} represent a set
containing the indices of Ns target-free range bins near r (since the target signal may leak into range

868
CHAPTER 20 Applications of Array Signal Processing
bins immediately adjacent to bin r, these are typically excluded), then a sample estimate of Re0 may be
formed as
Re0 =

k∈S0
ykyH
k = H,
 =

yk1 . . . ykNs
	
,
(20.12)
where yk is the space-time snapshot from range bin k. The Ns samples that compose  are referred to
as secondary data vectors.
Implementation of the space-time ﬁlter in (20.11) using a covariance estimate such as (20.12) is
referred to as the “fully adaptive” STAP algorithm. The number Ns of secondary data vectors chosen
to estimate Re0 is a critical parameter. If it is too small, a poor estimate will be obtained; if it is too
large, then the assumption of statistical similarity may be strained. Another critical parameter is the
rank of Re0. While in theory Re0 may be full rank, in practice its effective rank ρ is typically much
smaller than its dimension MK, since the clutter and jamming are usually orders of magnitude stronger
than the background noise. According to Brennan’s rule [1], the value of ρ for a uniform linear array
is M + (K −1)β, where β is a factor that depends on the speed of the array platform and the pulse
repetition frequency (PRF), and is usually between 0.5 and 1.5. The rank of Re0 for non-linear array
geometries will be greater, although no concise formula exists in the general case. Factors inﬂuencing
the rank of Re0 include the beamwidth and sidelobes of the transmit pulse (narrower pulses and lower
sidelobes mean smaller ρ), the presence of intrinsic clutter motion (e.g., leaves on trees in a forest)
or clutter discretes (strong specular reﬂectors), and whether the radar is forward- or side-looking (the
Doppler spread of the clutter and hence ρ is much smaller in the forward-looking case).
The rank of Re0 is important in determining the minimum value for Ns required to form a sufﬁciently
accurate sample estimate. A general rule of thumb is that the number of required samples is on the order
of 2ρ–5ρ. Even when these many stationary secondary range bins are available, Ns may still be much
smaller than MK, and Re0 will not be invertible. In such situations, a common remedy is to employ a
diagonal loading factor δ, and use the MIL to simplify calculation of the inverse:
Re0 + δI
−1 =

H + δI
−1
(20.13)
= 1
δ

I −

H + δI
−1
H

.
(20.14)
Another approach is to use a pseudo-inverse based on principal components.
Still, the computation involved in implementing the fully adaptive STAP algorithm is often pro-
hibitive. The dimension MK of Re0 is often in the hundreds, and computational costs add up quickly
when one realizes the STAP ﬁltering must be performed in multiple range bins for each look direction.
Most of the STAP research in recent years has been aimed at reducing the computational load to more
reasonable levels. Two main classes of approaches have been proposed: (1) partially adaptive STAP
and (2) parametric modeling. In the partially adaptive approach, the dimensions of the space–time data
slice are reduced by means of linear transformations in space or time or both:
Y0 →TaY0TH
ω .
(20.15)
Techniques for choosing the transformation matrices include beamspace methods, Doppler binning,
PRI staggering, etc. The classical moving target indicator (MTI) approach can be thought of as falling

3.20.2 Radar Applications
869
in this class of algorithms for the special case where Ta is one-dimensional. The dimension reduction
achieved by partially adaptive methods not only reduces the computational load, but it improves the
numerical conditioning and decreases the required secondary sample support as well.
The parametric approach is based on the observation that in (20.14), as δ →0, we have
lim
δ→0
Re0 + δI
−1∝

I −

H
−1
H

.
(20.16)
Thus, the effect of R−1
e0 is to approximately project the space-time signal vector onto the space orthogonal
to the clutter and jamming. While  could be used to deﬁne this subspace, a more efﬁcient approach has
been proposed based on vector autoregressive (VAR) ﬁltering. To see this, note from (20.3) and (20.7)
that the clutter and jamming vector ek for range bin k over the full CPI can be partitioned into samples
for each individual pulse within the CPI:
ek =
⎡
⎢⎢⎢⎣
nk(1)
nk(2)
...
nk(K)
⎤
⎥⎥⎥⎦.
(20.17)
The VAR approach assumes that the clutter and jamming obey the following model for each pulse t:
H0nk(t) + H1nk(t −1) + · · · + HLnk(t −L + 1) = 0,
(20.18)
where L is typically assumed to be small (e.g., less than 5–7) and each matrix Hi is M′ × M for some
chosen value of M′. The matrix coefﬁcients of the VAR can be estimated for example by solving a
standard least-squares problem of the form
min
H
Ns

k=1
∥Hek∥2
s.t. HHH = I,
(20.19)
where
H =
⎡
⎢⎢⎢⎣
HL
HL−1
· · ·
H0
HL
HL−1
· · ·
H0
...
...
HL
HL−1
· · · H0
⎤
⎥⎥⎥⎦
(20.20)
and the constraint HHH = I is used to prevent a trivial solution. The matrix HH will approximately
span the subspace orthogonal to , and based on (20.16) a suitable space-time ﬁlter would be given by
w = PHH s(θ, φ, ω),
(20.21)
where
PHH = HH
HHH−1
H.
(20.22)

870
CHAPTER 20 Applications of Array Signal Processing
FIGURE 20.8
Angle-Doppler spectra after STAP ﬁltering.
This approach is referred to as the space-time autoregressive (STAR) ﬁlter. An example of the perfor-
mance of the STAR ﬁlter is given in Figure 20.8 for a case with L = 4 and Ns = 7. These results are
for the same data set that generated the unﬁltered angle-Doppler spectrum in Figure 20.4. Note that the
clutter and jamming have been removed, and the target is plainly visible. Similar results were obtained in
this case with the fully adaptive STAP method with diagonal loading, but required a value of Ns near 60.
3.20.2.2 MIMO radar
Multi-input multi-output (MIMO) radar is beginning to attract a signiﬁcant amount of attention from
researchers and practitioners alike due to its potential of advancing the state-of-the-art of modern radar.
Unlike a standard phased-array radar, which transmits scaled versions of a single waveform, a MIMO
radar system can transmit via its antennas multiple probing signals that may be chosen quite freely
(see Figure 20.9). This waveform diversity enables superior capabilities compared with a standard
phased-array radar. For example, the angular diversity offered by widely separated transmit/receive
antenna elements can be exploited for enhanced target detection performance. For collocated transmit
and receive antennas, the MIMO radar paradigm has been shown to offer many advantages including
long virtual array aperture sizes and the ability to untangle multiple paths. Array signal processing plays
critical roles in reaping the beneﬁts afforded by the MIMO radar systems. In our discussion here, we
focus on array signal processing for MIMO radar with collocated transmit and receive antennas.

3.20.2 Radar Applications
871
MIMO Transmit Array
MIMO Receive Array
Combinations of {xm(t)}
Targets
)
(
t
x
M
)
(
1 t
x
(a)
Transmit Phased-Array
Receive Phased-Array
Targets
)
(
2
t
x
b
)
(
1
t
x
w
)
(
1
t
x
b
)
(
t
x
wM
(b)
FIGURE 20.9
(a) MIMO radar and (b) phased-array radar.
An example of a UAV equipped with a MIMO radar system is shown in Figure 20.10, where the
transmit array is sparse and the receive array is a ﬁlled (half-wavelength inter-element spacing) uniform
linear array. When the transmit antennas transmit orthogonal waveforms, the virtual array of the radar
system is a ﬁlled array with an aperture up to M times that of the receive array, where M is the number of
transmit antennas. Many advantages of MIMO radar with collocated antennas result directly from this
signiﬁcantly increased virtual aperture size. For example, for small aerial vehicles (with medium or short
range applications), a conventional phased-array system could be problematic since it usually weighs
too much, consumes too much power, takes up too much space, and is too expensive. In contrast, MIMO
radar offers the advantages of reduced complexity, power consumption, weight and cost by obviating
phase shifts and affording signiﬁcantly increased virtual aperture size.
Some typical examples of array processing in MIMO radar include transmit beampattern synthesis,
transmit and receive array design, and adaptive array processing for diverse MIMO radar applications.
We brieﬂy describe these array processing examples in MIMO radar.
3.20.2.2.1
Flexible transmit beampattern synthesis
The probing waveforms transmitted by a MIMO radar system can be designed to approximate a desired
transmit beampattern and also to minimize the cross-correlation of the signals reﬂected from various
targets of interest—an operation that would hardly be possible for a phased-array radar.
The recently proposed techniques for transmit narrowband beampattern design have focused on the
optimization of the covariance matrix R of the waveforms. Instead of designing R, we might think of
directly designing the probing signals by optimizing a given performance measure with respect to the
matrix X of the signal waveforms. However, compared with optimizing the same performance measure
with respect to the covariance matrix R of the transmitted waveforms, optimizing directly with respect to

872
CHAPTER 20 Applications of Array Signal Processing
0
15
5
10
13
Feet
Rx Antenna
Tx Antenna
5'
10'
FIGURE 20.10
A UAV equipped with a MIMO radar.
X is a more complicated problem. This is so because X has more unknowns than R and the dependence
of various performance measures on X is more intricate than the dependence on R.
There are several recent methods that can be used to efﬁciently compute an optimal covariance
matrix R, with respect to several performance metrics. One of the metrics consists of choosing R, under
a uniform elemental power constraint (i.e., under the constraint that the diagonal elements of R are
equal), to achieve the following goals:
a. Maximize the total spatial power at a number of given target locations, or more generally, match a
desired transmit beampattern.
b. Minimize the cross-correlation between the probing signals at a number of given target locations.
Another beampattern design problem is to choose R, under the uniform elemental power constraint, to
achieve the following goals:
a. Minimize the sidelobe level in a prescribed region.
b. Achieve a predetermined 3 dB main-beam width.

3.20.2 Radar Applications
873
It can be shown that both design problems can be efﬁciently solved in polynomial time as a semi-deﬁnite
quadratic program (SQP).
We comment in passing on the conventional phased-array beampattern design problem in which only
the array weight vector can be adjusted and therefore all antennas transmit the same differently-scaled
waveform. We can readily modify the MIMO beampattern designs for the case of phased-arrays by
adding the constraint that the rank of R is one. However, due to the rank-one constraint, both of these orig-
inallyconvexoptimizationproblemsbecomenon-convex.Thelackofconvexitymakestherank-onecon-
strained problems much harder to solve than the original convex optimization problems. Semi-deﬁnite
relaxation (SDR) is often used to obtain approximate solutions to such rank-constrained optimization
problems. The SDR is obtained by omitting the rank constraint. Hence, interestingly, the MIMO beam-
pattern design problems are the SDRs of the corresponding phased-array beampattern design problems.
We now provide a numerical example below, where we have used a Newton-like algorithm to solve
the rank-one constrained design problems for phased-arrays. This algorithm uses SDR to obtain an
initial solution, which is the exact solution to the corresponding MIMO beampattern design problem.
Although the convergence of the said Newton-like algorithm is not guaranteed, we did not encounter
any apparent problem in our numerical simulations.
Consider the beampattern design problem with M = 10 transmit antennas. The main-beam is
centered at θ0 = 0◦, with a 3 dB width equal to 20◦(θ1 = −10◦, θ2 = 10◦). The sidelobe region
is  = [−90◦, −20◦] ∪[20◦, 90◦]. The minimum-sidelobe beampattern design is shown in Figure
20.11a. Note that the peak sidelobe level achieved by the MIMO design is approximately 18 dB below
the mainlobe peak level. Figure 20.11b shows the corresponding phased-array beampattern obtained
by using the additional constraint rank(R) = 1. The phased-array design fails to provide a proper
mainlobe (it suffers from peak splitting) and its peak sidelobe level is much higher than that of its
−50
0
50
−30
−20
−10
0
10
20
Angle (degree)
Beampattern (dB)
(a)
−50
0
50
−30
−20
−10
0
10
20
Angle (degree)
Beampattern (dB)
(b)
FIGURE 20.11
Minimum sidelobe beampattern designs, under the uniform elemental power constraint, when the 3 dB
main-beam width is 20◦. (a) MIMO and (b) phased-array.

874
CHAPTER 20 Applications of Array Signal Processing
MIMO counterpart. We note that, under the uniform elemental power constraint, the number of degrees
of freedom (DOF) of the phased-array that can be used for beampattern design is equal to only M −1;
consequently, it is difﬁcult for the phased-array to synthesize a proper beampattern. The MIMO design,
on the other hand, can be used to achieve a much better beampattern due to its much larger number of
DOF, viz. M2 −M.
The radar waveforms are generally desired to possess constant modulus and excellent auto- and
cross-correlation properties. Consequently, the probing waveforms can be synthesized in two stages: at
the ﬁrst stage, the covariance matrix R of the transmitted waveforms is optimized, and at the second
stage, a signal waveform matrix X is determined whose covariance matrix is equal or close to the
optimal R, and which also satisﬁes some practically motivated constraints (such as constant modulus
or low peak-to-average-power ratio (PAR) constraints). A cyclic algorithm for example, can be used
for the synthesis of such an X, where the synthesized waveforms are required to have good auto- and
cross-correlation properties in time.
3.20.2.2.2
Array design
For a phased-array radar system, the transmission of coherent waveforms allows for a narrow mainbeam
and, thus, a high signal-to-noise ratio (SNR) upon reception. When the locations of targets in a scene
are unknown, phase shifts can be applied to the transmitting antennas to steer the focal beam across
an angular region of interest. In contrast, MIMO radar systems, by transmitting different, possibly
orthogonal waveforms, can be used to illuminate an extended angular region over a single processing
interval, as we have demonstrated above.
Waveform diversity permits higher degrees of freedom, which enables the MIMO radar system to
achieve increased ﬂexibility for transmit beampattern design. The assumptions used in the discussions
above are that the positions of the transmitting antennas, which also affect the shape of the beampattern,
are ﬁxed prior to the construction of R followed by the synthesis of X. At the receiver, sparse, or thinned,
array design has been the subject of an abundance of literature during the last 50 years. The purpose
of sparse array design has been to reduce the number of antennas (and thus reduce the cost) needed to
produce desirable spatial receiving beampatterns. The ideas behind sparse receive array methodologies
can be extended to that of sparse, MIMO array design. For example, cyclic algorithms can be used to
approximate desired transmit and receive beampatterns via the design of sparse antenna arrays. These
algorithms can be seen as extensions to iterative receive beampattern designs.
3.20.2.2.3
Adaptive array processing at radar receivers
Adaptive array processing plays a vital role at radar receivers, including those of MIMO radar. Conven-
tional data-independent algorithms, such as the delay-and-sum approach for array processing, suffer
from poor resolution and high sidelobe level problems. Data-adaptive algorithms, such as MVDR
(Capon) receivers, have been widely used in radar receivers. These adaptive signal processing algo-
rithms offer much higher resolution and lower sidelobe levels than the data-independent approaches.
However, these algorithms can be sensitive to steering vector errors and also require a substantial
number of snapshots to determine the second-order statistics (covariance matrices). To mitigate these
problems, diagonal loading has been used extensively in practical applications to make adaptive algo-
rithms feasible. However, too much diagonal loading makes the adaptive algorithm degenerate into

3.20.3 Radio Astronomy
875
data-independent methods, and the diagonal loading level may be hard to determine in practice.
Parametric methods tend to be sensitive to data model errors and are not as widely used as the afore-
mentioned data-adaptive algorithms.
In MIMO radar, adaptive array processing is essential, especially because many of the simple tricks
used to achieve the longer virtual arrays, such as randomized antenna switching (also called randomized
time-division multiple access (R-TDMA)) and slow-time code-division multiple access (ST-CDMA),
provide sparse random sampling. Because of such sampling, the high sidelobe level problem suffered by
data-independent approaches are exacerbated. Moreover, most of the radar signal processing problems
encountered in practice do not have multiple snapshots. In fact, in most practical applications, only a
single data measurement snapshot is available for adaptive signal processing. For example, in synthetic
aperture radar (SAR) imaging, just a single phase history matrix is available for SAR image formation.
Moreover the phase history matrix may not be uniformly sampled. In MIMO radar applications, includ-
ing MIMO-radar-based space-time adaptive processing (STAP), synergistic MIMO SAR imaging and
ground moving target indication (GMTI), and untangling multiple paths for diverse radar operations
such as those encountered by MIMO over-the-horizon radar (OTHR), we essentially have just a single
snapshot available at the radar receiver, especially in a heterogeneous clutter environment.
Fortunately, the recent advent of iterative adaptive algorithms, such as the iterative adaptive approach
(IAA) and sparse learning via iterative minimization (SLIM), obviate the need of multiple snapshots and
the uniform sampling requirements but retain desirable properties, including high resolution, low side-
lobe level, and robustness against data model errors, of the conventional adaptive array processing meth-
ods. Moreover, for uniformly sampled data, various fast implementation strategies of these algorithms
have been devised to exploit the Toeplitz matrix structures. These iterative adaptive algorithms are partic-
ularly suited for signal processing at radar receivers. They can also be used in diverse other applications,
such as in sonar, radio astronomy, and channel estimation for underwater acoustic communications.
3.20.3 Radio astronomy
Radio astronomy is the study of our universe by passive observation of extra-terrestrial radio frequency
emissions. Sources of interest for astronomers include (among others) radio galaxies, pulsars, supernova
remnants, synchrotron radiation from excited material in a star’s magnetic ﬁeld, ejection jets from black
holes, narrowband emission and absorption lines from diffuse elemental or chemical compound matter
that can be assayed by their characteristic spectral structure, and continuum thermal black body radiation
emitted by objects ranging from stars to interstellar dust and gasses. The radio universe provides quite
a different and complementary view to that which is visible to more familiar optical telescopes. Radio
astronomy has enabled a much fuller understanding of the structure of our universe than would have
been possible with visible light alone. With Doppler red shifting, the spectrum of interest ranges from
as low as the shortwave regime near 10 MHz, to well over 100 GHz in the millimeter and submillimeter
bands, and there are radio telescopes either in use or under development to cover much of this spectrum.
From the earliest days of radio astronomy, detecting faint deep space sources has pushed available
technology to extreme performance limits. Early progress was driven by improvements in hardware
with relatively straightforward signal processing and detection techniques. With the advent of large

876
CHAPTER 20 Applications of Array Signal Processing
synthesis arrays, signal processing algorithms increased in sophistication. More recently, interest in
phased array feeds (PAFs) has opened a new frontier for array signal processing algorithm development
for radio astronomical observations.
Radio astronomy presents unique challenges as compared to typical applications in communications,
radar, sonar, or remote sensing:
•
Low SNR: Deep space signals are extremely faint. SNRs of −30 to −50 dB are routine.
•
Radiometric detection: A basic observational mode in radio astronomy is “on-source minus off-
source” radiometric detection where the source level is well below the noise ﬂoor and can only be
seen by differencing with a noise only estimate. This requires stable power estimates of (i) system
noise plus weak signal of interest (SOI) and (ii) noise power alone with the sensor steered off the
SOI. The standard deviation of the noise power estimate determines the minimum detectable signal
level, so that long integration times (minutes to hours) are required.
•
Low system temperatures: With cryogenically cooled ﬁrst stage low noise ampliﬁers, system noise
temperatures can be as low as 15 K at L-band, including LNA noise, waveguide ohmic losses,
downstream receiver noise, and spillover noise from warm ground observed beyond the rim of a
dish reﬂector.
•
Stability: System gain ﬂuctuations increase the receiver output variance and place a limit on achiev-
able sensitivity that cannot be overcome with increased integration time. High stability in gain,
phase, noise, and beamshape response over hours is required to enable long term integrations to
tease out detection of the weakest sources.
•
Bandwidth: Some scientiﬁc observations require broad bandwidths of an octave or more. Digital
processing over such large bandwidths poses serious computational burdens.
•
Radio frequency interference (RFI): Observations in RFI environments outside protected frequency
bands are common. Interference levels below the noise ﬂoor may be as problematic as strong interfer-
ers, since they are hard to identify and attenuate. Cancelation approaches also cause pattern rumble
which limits sensitivity.
3.20.3.1 Synthesis imaging
Radio astronomical synthesis imaging uses interferometric techniques and some of the world’s largest
sensor arrays to form high resolution images of the distribution of radio sources in deep space.
Figure 20.12 presents two examples of the beautiful high resolution detail revealed by synthesis imaging
from the Very Large Array (VLA) in New Mexico, and Figure 20.13 shows the VLA with its anten-
nas conﬁgured in a compact central core conﬁguration. The key to this technology is coherent cross-
correlation processing (i.e., interferometry) of RF signals seen by pairs of widely separated antennas
(up to 10s of kilometers and more). Each such antenna typically consists of a high gain dish reﬂector of
12–45 m diameter which serves as a single element in the larger array. At lower frequencies, in order
to avoid difﬁculties of physically steering the large aperture needed for high gain, array elements may
themselves be built up as electronically steered beamforming aperture array “stations” using clusters of
ﬁxed bare antennas without a reﬂector (for example, the LOFAR array). Whether implemented with a
collection of large dish telescopes, or with a beamforming array, these elements of the full imaging array
provide a sparse spatial sampling of the wavefront that would have been observed by a much larger,
imaginary “synthetic” encompassing dish. Though the array cannot match the collecting areas of the

3.20.3 Radio Astronomy
877
FIGURE 20.12
VLA images of radio sources not visible to optical astronomy. (a) An early image of the gas jet structures in
Cygnus A (ejected from the spinning core of the radio galaxy in the constellation Cygnus) seen at 5.0 GHz
1983 by Perley, Carilli, and Dreher. (b) Supernova remnant Cassiopeia A, 1994 composite of 1.4, 4.0, and
8.4 GHz images, by Rudnick, Delaney, Keohane, Koralesky, and Rector.
Credits: National Radio Astronomy Observatory/Associated Universities, Inc./National Science Foundation.
FIGURE 20.13
The central core of the Very Large Array (VLA) in compact conﬁguration.
Credit: Dave Finely, National Radio Astronomy Observatory/Associated Universities, Inc./National Science Foundation.
synthesized aperture, the long “baseline” distances between antennas yield spatial imaging resolution
comparable to that of the encompassing dish aperture which inscribes the baseline vectors. Exploiting
the earth’s rotation over time relative to the distant celestial sky patch being observed ﬁlls in sampling
gaps between sparse array elements.
There are a number of aspects of synthesis imaging arrays that are distinct from many other
array signal processing applications. Due to wide separation there is no mutual coupling and noise

878
CHAPTER 20 Applications of Array Signal Processing
is truly independent across the array. The large scale, long baselines, and critical dependence on phase
relationships require very long coherent signal transport or precision time stamping of data sets using
atomic clock references. Each array element is itself a high gain, highly directive antenna with a sizable
aperture. Precision array calibration is required, but due to large scale hardware this cannot be done in a
laboratory or on an antenna range. Self calibration methods are employed that use known point-source
deep space objects in the ﬁeld of view to properly phase the array. Array geometry is sparse with either
random-like or log-scaled spacing. Extreme stability is required due to the need for coherent integration
over hours, and bandwidths of interest can cover and octave or more.
3.20.3.1.1
The imaging equation
While the signals of interest are broadband, processing typically takes place in frequency subchannels
so that narrowband models can typically be used. Further, since deep space sources are typically seen
through line-of-sight propagation, multipath scattering is limited and occurs only locally as reﬂections
off antenna support structures. Thus the propagation channel can be considered to be memoryless (zero
delay spread). The synthesis imaging equations relate the observed cross correlation between pairs of
array elements to the expected electromagnetic source intensity spatial distribution over a patch of the
T1=0
y1(t)
Tm
ym(t)
φ(s)+Tm
s
s0
u
v
p
w
q
I(s)
rm
r1
Tm
E(s,t)
FIGURE 20.14
Geometry and signal deﬁnitions for the synthesis imaging equations.

3.20.3 Radio Astronomy
879
celestial sphere. Figure 20.14 illustrates the geometry, signal deﬁnitions, and coordinate systems for
one of the baseline pairs of antennas used to develop the imaging equations.
Consider the electric ﬁeld E(s, t) = E(s)e jt observed by the array at frequency  due to a
narrowband plane wave signal arriving from the direction pointed to by the unit length 3-space vector
s. We consider only the quasi monochromatic case where a single radiation frequency  is observed by
subband processing. To simplify discussion, polarization effects are not considered so E(s) is treated
as a scalar rather than vector quantity, though working synthesis arrays typically have dual polarized
antennas and receiver systems to permit studying source polarization. Since distance is indeterminate to
the array, in our model the observed E(s) and its corresponding intensity distribution I(s) = E

|E(s)|2	
are projected without time or phase shifting onto a hypothetical far-ﬁeld celestial sphere that is interior
to the nearest observed object. The goal of synthesis imaging is to estimate I(s) from observations of
sensor array y(t).
Deﬁne the image coordinate axes (p, q) to be ﬁxed on the celestial sphere and centered in the
imaging ﬁeld of view patch. Since s is unit length, we may use these coordinates to express it as
s =

p, q,

1 −p2 −q2

. Let s0 point to the (p = 0, q = 0) origin, thus s0 = (0, 0, 1). For small
values of p and q, such as being contained within a ﬁeld-of-view limited by the narrow beamwidth of
array antennas, s ≈(p, q, 1). Time delays Tm are inserted in the signal paths for receiver outputs ym(t)
to compensate for the differential propagation times of a plane wave originating from the (p, q) origin.
The most distant antenna is arbitrarily designated as the m = 1st element, and T1 = 0. Thus the array
is co-phased for a signal propagating along s0.
Receiver output voltage signal ym(t), 1 ≤m ≤M, is given by the superposition of scaled electric
ﬁeld contributions from across the full celestial sphere surface S, plus local sensor noise:
ym(t) =

S
A(s)E(s)e j

t+φm(s)

ds + nm(t),
(20.23)
where A(s) represents the known antenna element directivity pattern and downstream receiver gain
terms, φm(s) is the phase shift due to differential geometric propagation distances for a source from
s relative to a co-phased source from s0 as shown in Figure 20.14, and nm(t) is the noise seen in the
mth array element. For simple imaging algorithms, it is assumed that all elements (e.g., dish antennas)
have identical spatial response patterns and that each is steered mechanically or electronically to align
its beam mainlobe with s0, so A(s) does not depend on m and sources outside the elemental beams are
strongly attenuated. The beamwidth deﬁned by A(s) determines the maximum imaging ﬁeld of view,
or patch size. Considering the full array, (20.23) can be expressed in vector form as:
y(t) =

S
A(s)E(s)e j(t+φ(s))ds + n(t)
(20.24)
where φ(s) = [φ1(s) · · · φM(s)]T .
Consider the vector distance between two array elements, (rl−rm),l ̸= m, where rm is the location of
the mth antenna. This is known as an interferometric “baseline,” and it plays a critical role in synthesis
imaging. Longer baselines yield higher resolution images by increasing the synthetic array aperture
diameter, and using more antennas provides more distinct baseline vectors which will be shown to
more fully sample the image in the angular spectrum domain. In the following all functions of element

880
CHAPTER 20 Applications of Array Signal Processing
position depend only on such vector differences, so it is convenient to deﬁne a relative coordinate system
(u, v, w) in the vicinity of the array to express the difference as (rl −rm) = (u, v, w). Align (u, v)
with (p, q), and w with s0. Scale these axes so distance is measured in wavelengths, i.e., so that a unit
distance corresponds to one wavelength λ = 2πc
 , where c is the speed of light. In this coordinate system
we have by simple geometry
φm(s) + Tm = −2πs(rm −r1), and Tm = −2π s0(rm −r1).
(20.25)
At array outputs ym(t), after the inserted delays Tm, the effective phase difference between two array
elements is then
φl(s) −φm(s) = −2π(s −s0)T (rl −rm).
(20.26)
Using the signal models of (20.23) and (20.26), the cross correlation of two antenna signals as a
function of their positions is given by:
R(rl, rm) = E

yl(t)y∗
m(t)
	
for l ̸= m
(20.27)
= E

S
A(s)E(s)e j(t+φl(s))ds + nl(t)

×

S
A(s′)E(s′)e j(t+φm(s′))ds′ + nm(t)
∗
(20.28)
=

S
|A(s)|2I(s)e−j2π(s−s0)T (rl−rm)ds
=

S
|A(s)|2I(s)e−j2π(p,q,a−1)T (u,v,w)ds
(20.29)
=
 ∞
−∞
|A(p, q)|2 1
a I(p, q)e−j2π(up+vq+w(a−1))dp dq
(20.30)
≈
 ∞
−∞
|A(p, q)|2I(p, q)e−j2π(up+vq)dp dq = R(u, v) for u, v ̸= 0,
(20.31)
where a =

1 −p2 −q2. We have assumed zero mean spatially independent radiators for E(s) and
nm(t), a narrow ﬁeld of view so a ≈1, and that s0 = (0, 0, 1). The quantity R(u, v) is known by radio
astronomers as a “visibility function” where arguments rl and rm are replaced by u and v since the
ﬁnal expression depends only on these terms. A cursory inspection of (20.31) reveals that it is precisely
a 2-D Fourier transform relationship, so the inversion method to obtain I(s) from visibilities R(u, v)
suggests itself:
I(p, q) =
1
|A(p, q)|2
 ∞
−∞
R(u, v)e j2π(up+vq)du dv,
∀{(p, q)|A(p, q) ≫0}
(20.32)
=
1
|A(p, q)|2 F−1(R(u, v)),
(20.33)
where F−1(·) is the inverse 2-D Fourier transform. This is the well known synthesis imaging equation.
Since only cross correlations between distinct antennas are measured by this imaging interferometer,

3.20.3 Radio Astronomy
881
the self power terms R(rl, rm)|rl=rm = R(0, 0) are not computed or used in the Fourier inverse. The
d.c. level in the image which normally depends on these terms must rather be adjusted to provide a
black, zero valued background.
3.20.3.1.2
Algorithms for solving the imaging equation
The geometry of the imaging problem described in (20.32) and illustrated in Figure 20.14 is continually
changing due to Earth rotation. The ﬁxed ground antenna positions rm rotate relative to the (u, v) axis,
whichremainsalignedtothe(p, q)axisﬁxedonthecelestialsphere.Ononehand,thisisanegativeeffect
because it limits the integration time that can be used to estimate R(u, v) under a stationarity assumption.
On the other hand, rotation produces new baseline vectors (rl −rm) with distinct orientations, ﬁlling
in the Fourier space coverage for R(u, v) and improving image quality. To exploit rotation, imaging
observations are made over long time periods, up to 12 h, to form a single image.
Receiver outputs are sampled as y(i) ≡y(iTs) at frequency fs = 1/Ts, and sample covariance
estimates of the visibility function (assuming zero mean signals) are obtained as
Rk = 1
N
(k+1)N−1

i=kN
y(i)yH(i),
(20.34)
where N is the number of samples in the long term integration (LTI) window over which the imaging
geometry and thus cross correlations may be assumed to be approximately stationary, and k is the
LTI index. (We will later introduce a short term integration window length Nsti over which moving
interference sources appear statistically stationary.)
Since covariance estimates are only available at discrete time intervals (one per LTI index k), and
the antennas have ﬁxed Earth positions, only samples of R(u, v) are available with irregular spacing in
the (u, v) plane, so (20.32) must be solved with discreet approximations. However, noting that due to
Earth rotation, the corresponding antenna position vector orientations rm depend on time through k, a
new set of (u, v) samples with different locations is available at each LTI. Index k is thus added to the
notation to distinguish distinct baseline vectors (rk,l −rk,m) for the same antenna pairs during different
LTIs. So the (l, m)th element of Rk relates to the sampled visibility function as
{Rk}lm = Rk,lm ≈R(uk,lm, vk,lm),
(20.35)
where (uk,lm, vk,lm, wk,lm) = (rk,l −rk,m) and where as in (20.26) and (20.31), due to inserted time
delays Tm we may take wk,lm to be zero. For simplicity we will use a single index κ to represent unique
LTI-antenna index triples {k,lm} to specify vector samples in the (u, v) plane, so (uk,lm, vk,lm) =
(uκ, vκ) and Rk,lm = Rκ. Thus elements of the sequence of matrices Rk provide a non-uniformly
sampled representation of the visibility function, or frequency domain image. Consistent with the
treatment of R(0, 0) in (20.32), diagonal elements in Rκ are set to zero.
Figure 20.15a presents an example of a certain VLA geometry, and Figure 20.15b shows where
the (uκ, vκ) samples would lie, with each point representing a unique sample κ. This plot includes 61
LTIs (i.e., 0 ≤k ≤60) over a 12 h VLA observation for the Cygnus A radio galaxy of Figure 20.12a.
This sample pattern would change for sources with different positions on the celestial sphere (expressed
by astronomers in right ascension and declination).

882
CHAPTER 20 Applications of Array Signal Processing
−6
−4
−2
0
2
4
−4
−2
0
2
4
6
VLA Antenna Positions
x in km
y in km
(a)
−6
−4
−2
0
2
4
6
x 10 4
−6
−4
−2
0
2
4
6
x 10 4
VLA (u,v) sample Coverage with Source RA/dec=300/40.7
u
v
(b)
FIGURE 20.15
(a) An example VLA antenna element geometry with the repositionable 25 m dishes in a compact log spacing
along the arms. Axis units are in kilometers. (b) Corresponding (u, v) sample grid for a 12 h observation of
Cygnus A. Each point represents a (uκ, vκ) sample corresponding to a unique baseline vector where a visibility
estimate Rκ is available. Red crosses denote baselines from a single LTI midway through the observation,
and blue points are additional samples available using Earth rotation, with a new Rk computed every 12 min.
Observation is at 1.61 GHz and axis units are in wavelengths. (For interpretation of the references to color
in this ﬁgure legend, the reader is referred to the web version of this book.)

3.20.3 Radio Astronomy
883
With this frequency domain sampling and including noise effects (20.32) becomes
ID(p, q) =
1
|A(p, q)|2
 ∞
−∞
(u, v)

R(u, v) + R(u, v)

e j2π(up+vq)du dv
(20.36)
=
1
|A(p, q)|2

κ
Rκ e j2π(uκ p+vκq),
(20.37)
where ID(p, q) is known as the “dirty image,” the sampling function (u, v) = 
κδ(u −uκ, v −vκ),
and R(u, v) represents sample estimation error in the covariance/visibility. Since the (u, v) plane is
sparsely sampled, (u, v) introduces a bias in the inverse which must be removed by deconvolution as
described below. This also means that (20.37) is not a true inverse Fourier transform due to the limited
set of basis functions used. It is referred to as the “direct Fourier inverse” solution.
There are two common approaches to solving (20.36) or (20.37) for ID(p, q) given a set of LTI
covariances Rκ. The most straightforward though computationally intensive method is a brute force
evaluation of (20.37) given knowledge of the (uκ, vκ) sample locations (e.g., as in Figure 20.15).
Alternately, the efﬁciencies of a 2-D inverse FFT can be exploited if these samples and corresponding
visibilities Rk are re-sampled on a uniform rectilinear grid in the (u, v) plane. “Cell averaging” assigns
the average of visibility samples contained in a local cell region to the new rectilinear grid point in the
middleofthecell.Otherre-griddingmethodsbasedonhigherorder2-Dinterpolationhavealsobeenused
successfully. When large ﬁelds of view are required, or array elements are not coplanar, then any of these
approaches based on (20.31) will not work and a solution to the more complete expression of (20.30)
must be found. Cornwell has developed the W-Projection method to address these conditions [27].
An alternate “parametric matrix” representation of (20.31) and (20.37) has been developed. This is
particularly convenient because it models the imaging system in a familiar array signal processing form
that lends itself readily to analysis, adaptive array processing and interference canceling, and opens
up additional options for solving the synthesis imaging and image restoration problems. Returning to
the indexing notation of (20.34), note that since (rl −rm) = (rl −r1) −(rm −r1) one may express
(uk,lm, vk,lm) as (uk,l1 −uk,m1, vk,l1 −vk,m1). Let J(p, q) = |A(p, q)|2I(p, q) be the desired image
as scaled (i.e., vignetted) by the antenna beam pattern, and sample it on a regular 2-D grid of pixels
(pd, qd), 1 ≤d ≤D. The conventional visibility Eq. (20.31) then becomes
Rk,lm =
D

d=1
J(pd, qd)e−j2π(uk,lm pd+vk,lmqd) + σ 2
n δ(l −m)
(20.38)
=
D

d=1
e−j2π(uk,l1 pd+vk,l1qd)J(pd, qd)e j2π(uk,m1 pd+vk,m1qd) + σ 2
n δ(l −m),
(20.39)
which in matrix form is
Rk = AkJAH
k + σ 2
n I, where
(20.40)

884
CHAPTER 20 Applications of Array Signal Processing
Ak = [ak,1, . . ., ak,D],
(20.41)
ak,d =

e−j2π(uk,11 pd+vk,11qd), . . ., e−j2π(uk,M1 pd+vk,M1qd)T
,
(20.42)
and where J = Diag([J(p1, qD), . . ., J(pD, qD)]) is the diagonal image matrix representation of sam-
pled J(p, q), M is the total number of array elements, and though noise is independent across antennas,
the self noise terms have been included to allow for the l = m case that contributes to the diagonal of
full matrix Rk. The matrix discrete “direct Fourier inverse” relationship corresponding to (20.37) is
J = 1
K
K

k=1
AH
k RkAk,
(20.43)
where K is the number of available LTIs. Equations (20.40) and (20.43) are well suited to address synthe-
sis imaging as an estimation problem, facilitating use of Maximum Likelihood, maximum a posteriori,
constrained minimum variance, or robust beamforming techniques. Note that (20.43) is not a complete
discrete inverse Fourier transform, indeed, often D > MK so a one-to-one inverse relationship between
Rk and J does not exist andJ is signiﬁcantly blurred.
By the Fourier convolution theorem, the effect of frequency sampling by (u, v) in (20.36) is
to convolve the desired image I(p, q) with the “dirty beam response” ψD(p, q) = F−1((u, v)).
Neglectingtheeffectofindividualantennadirectivitypattern A(p, q), ψD(p, q)canbeinterpretedasthe
point spread function, or synthetic beam pattern of the imaging array for the given observation scenario.
Signiﬁcant reduction of this blurring effect can be achieved by an image restoration/deconvolution step.
The dirty image of (20.36) may be expressed as
ID(p, q) = ψD(p, q) ∗(I(p, q) + I(p, q)),
(20.44)
where I(p, q) = F−1(R(u, v)) is due to sample estimation error in the visibilities. Since antenna
locations in the rotating (u, v) plane are known precisely over the full observation, ψD(p, q) is known
to high accuracy, and with well calibrated dish antennas so is A(p, q). Thus (20.44) may be solved as
I(p, q) = ID(p, q) ∗−1 ψD(p, q),
(20.45)
where “∗−1” denotes deconvolution with respect to the right argument. Due to the spatial lowpass
nature of dirty beam ψD(p, q) this problem is ill conditioned and must be regularized by imposing
some assumptions about the image. The most popular reconstruction methods impose a sparse source
distribution model and use an iterative source subtraction approach related to the original CLEAN
algorithm [32]. The sparse model is justiﬁable for point-source images of star ﬁelds, and works well
even with more complex distributions of gas and nebular structures given that much of the ﬁeld of view
is expected to be dark. Several variants and extensions to CLEAN have been proposed, some applying
source subtraction in the spatial (p, q) domain, and some in the frequency (u, v) domain. Typically
these have performance tuning parameters which astronomers adjust for most pleasing results. Thus the
effective regularization term or mathematical optimization expression is often not known precisely and
the process is a bit ad hoc, but solutions with higher contrast and resolution, and with reduced noise and
reconstruction artifacts are preferred. Maximum entropy reconstruction has also been used effectively.

3.20.3 Radio Astronomy
885
3.20.3.2 Astronomical phased array feeds
A new application for array signal processing in radio astronomy is phased array feeds (PAFs) where the
traditional single large horn antenna feed at the focus of large telescope dish is replaced with a closely
spaced (order of 1/2 wavelength) 2-D planar array of small antennas located at the dish focal plane. The
primary motivation for such a system, as shown in Figure 20.16 is to form multiple simultaneous beams
steered to cover a grid pattern in a ﬁeld of view that is many times larger than the single pixel horn fed
dish. PAFs are ideal for wide-ﬁeld and survey instruments where it is desired to cover large regions of
the sky in the shortest possible time. They provide the ability to capture a small image over the ﬁeld of
view, with one pixel per simultaneously formed beam, using a single snapshot pointing of the dish. Such
systems have been referred to as “radio cameras.” Additional advantages of PAFs include sensitivity
optimization with respect to the noise environment, and spatial interference cancelation capabilities
(see Figure 20.16 and Section 3.20.3.3) albeit at the expense of increased hardware and processing
complexity.
In some ways PAF processing is simply conventional beamforming for an array of microwave
receiving antennas, but there are several unique aspects of the application that provide some challenges.
y(i)
s(i)
z(i)
Radio telescope dish with a phased array feed
FIGURE 20.16
The primary advantage of FPA telescopes is increased ﬁeld of view provided by multiple, simultaneously
formed beams. Spatial cancelation of interfering signals is also possible, but very deep nulls are required.

886
CHAPTER 20 Applications of Array Signal Processing
The following technical hurdles are why PAFs have not been previously adopted in radio astronomy,
but these issues have largely been resolved and working platforms have now been demonstrated.
First, the PAF is not a bare aperture array but operates in conjunction with a very large reﬂector which
for an on-axis far ﬁeld point source focusses a tight Airy pattern spot of energy at the array that spans little
more than a single array element. For off-axis sources the spot moves across the array and undergoes
coma shaped pattern distortion. So, though noise and interference are seen on all elements, only a few
antennas see much of the SOI. The combined dish and PAF can be viewed as a dense array of small but
high gain, highly directive elements, but not all of these have equal SNR. Elements outside the focal spot
must however be used in beamforming to control the illumination pattern on the dish and thus reduce
spillover noise from observing warm ground beyond the edge of the dish. The focal properties of the dish
also limit the achievable ﬁeld of view, even with electronic steering, since deviation from the boresight
axis beyond a few beamwidths leads to defocusing and loss of gain, no matter how large the PAF is.
Second, array calibration is critical to achieve maximum sensitivity (gain over noise power) and
due to the huge sizes of these instruments, must be performed in situ using known deep space objects
as calibration sources of opportunity. Calibrations must be performed periodically (order of weeks) to
account for electronic and structural drift, and must estimate array response vectors in every direction
that a beam is to be steered or a response constraint is to be placed.
Third, beamformer weight calculation is non-trivial. Astronomers want maximum sensitivity and
stable beampatterns on the sky, but these competing requirements are challenging. The variable corre-
lated noise ﬁeld environment of a radio telescope calls for an adaptive approach, but it is difﬁcult to
obtain low error array calibrations at enough points to control beam sidelobe structure. Also, due to
complexity of the antenna structures, it is impossible to design usable beamformer weights from even
a very detailed electromagnetic system simulation.
Fourth, as discussed in Section 3.20.3.3, many of the conventional adaptive canceling beamforming
methods are not very effective for astronomical PAFs. This is because observations are frequently done
when both the SOI and interference power levels are well below the noise ﬂoor. New approaches are
required to form deeper spatial nulls in scenarios where it is difﬁcult to estimate interference parameters.
Fifth, replacing a single horn feed channel with 38, or 200 array elements, as have been proposed for
PAFs, has major implications on the back end processing. Processed bandwidths of 300 MHz or more
per antenna are needed, so a real-time DSP processor with capacity to serve as digital receiver, multiple
beamformer, and array correlator for calibrationm constitutes a major infrastructure investment.
And ﬁnally, in a ﬁeld where cryogenically cooled antennas and LNAs are the norm to reduce receiver
noise, cooling a large array is daunting. Most current development projects have opted for room temper-
ature arrays and trade off the then necessary longer integration times with faster survey speeds possible
with multiple beams.
3.20.3.2.1
Signal model
After analog frequency down conversion, sampling, and complex baseband bandshifting, the array
signal time sample vector of Figure 20.16 is modeled as
y(i) = as(i) +
D

d=1
vd(i) zd(i) + n(i),
(20.46)

3.20.3 Radio Astronomy
887
where a is the array response vector for signal of interest (SOI) s(i), vd(i) is the time varying array
response for the dth independent interfering source zd(i), and n(i) is the noise vector. Source response
a is assumed to be constant, even for observation times on the order of an hour because the dish
mechanically tracks a point in the sky. Even ﬁxed ground interference sources must be modeled as
moving (thus vd(i) depends on i) due to this tracking motion of the dish. Approaches to address man–
made interference are discussed in Section 3.20.3.3. This model for zd(i) can also include natural deep
space sources which are bright enough to overwhelm the SOI even when seen in the beam sidelobe
pattern. Their apparent rotational motion about the SOI is due to Earth rotation. When the corresponding
vd(i) is known accurately, these can be removed through a successive subtraction algorithm known as
peeling. As with synthesis imaging, broadband processing for PAFs is accomplished by FFT based
subband decomposition, often with thousands of frequency bins. So in the following we consider only
a single frequency channel and adopt the standard narrowband array processing model.
Any array signal processing, including beamforming, must take into account the fact that, unlike
synthesis imaging, the PAF noise vector n(i) is correlated across the array. Even with cryogenic cooling,
ﬁrst stage ampliﬁer LNA noise is correlated due to electromagnetic mutual coupling at the elements.
Another major component, spillover noise from warm ground black body radiation as seen by the feed
array, is spatially correlated because it is not isotropic since it stops above the horizon and is blocked
over a large solid angle by the dish.
In a practical PAF scenario the beams are steered in a rectangular or hexagonal grid pattern with
crossover points at the −1 to −3 dB levels. The total number of beams, J, is limited by the maximum
steering angle which is determined by the diameter of the array feed and the focal properties of the dish,
by the acceptable limit for beamshape distortion, and by the available processing capacity for real-time
simultaneous computation of multiple beams. As illustrated in Figure 20.17, the time series output for
+
w1
w3
wM
b(i) = w  y(i) 
H
θ
Space 
signal
of interest
Noise :
Interference
y  (i)
1
y  (i)
2
y  (i)
M
n  (i)
1
n  (i)
M
s(i)
z  (i)
1
FIGURE 20.17
Beamformer architecture. Narrowband operation is assumed and for PAF beamforming, interaction with the
large reﬂector dish is not shown.

888
CHAPTER 20 Applications of Array Signal Processing
a beam steered in the jth direction is given by
b j(i) = wH
j y(i),
(20.47)
where w j is the vector of complex weights for beamformer j, 1 ≤j ≤J. Weights are designed based
on array calibration data and the desired response pattern constraints and optimization as described in
the following two sections. Separate beamformers with their own sets of J distinct weight vectors are
computed for each frequency channel, though we consider only a single channel in this discussion.
3.20.3.2.2
Calibration
Since multiple simultaneous beams are formed with a PAF as shown in Figure 20.16, a calibration for
the signal array response vector a j must be performed for each direction, s j, corresponding to each
formed beam’s boresight direction, and any additional directions where point constraints in the beam
pattern response will be placed. Periodic re-calibration is necessary due to strict beam pattern stability
requirements, to correct for differential electronic phase and gain drift, and to characterize changes in
receiver noise temperatures. Calibration is based on sample array covariance estimates R as described
in (20.34) while observing a dominant bright calibration point source in the sky. For example, in the
northern hemisphere, Cassiopeia A and Cygnus A shown in Figure 20.12 are the brightest continuum
(broadband) sources, and with a typical single dish telescope aperture they are unresolved and appear
as point sources. Both have been used as calibrators.
3.20.3.2.3
Beamformer calculation
Since discovery of the weakest, most distant sources is a primary aim of radio astronomers, it is
paramount to design a dish and feed combination to achieve high sensitivity, which has been derived
for a phased array feed to be
Ae
Tsys
= kbB
Fs
wHRsw
wHRnw
(m2/K),
(20.48)
where Ae (in m2) represents directivity in terms of the effective antenna aperture collecting area, Tsys is
system noise power at the beamformer output expressed as a black body temperature, kb is Boltzmann’s
constant, B is system bandwidth, Fs, (in Watts/m2) is the signal ﬂux density in one polarization, and
Rs and Rn are the signal and noise components of R respectively. Here we have assumed D = 0, i.e.,
that there are no interferers. For a reﬂector antenna with a traditional horn feed, maximizing sensitivity
involves a hardware-only tradeoff between aperture efﬁciency, which determines the received signal
power, andspillover efﬁciency, whichdetermines thespillover noisecontribution. WithaPAF, sensitivity
is determined by the beamforming weights as well as the array and receivers. Adjusting w controls both
the PAF illumination pattern on the dish which affects Ae, and the response to the noise ﬁeld, which
affects Tsys. Noting that all other right hand side terms in (20.48) are constant, sensitivity can be
maximized with the well known maximum signal to noise ratio (SNR) beamformer
wsnr = arg max
w
wHRsw
wHRnw.
(20.49)
To date all hardware demonstrated PAF telescopes have used this maximum sensitivity beamformer.
However, a hybrid beamformer design method for PAFs that parametrically trades off sensitivity max-
imization with constraining mainlobe shape and sidelobe levels has been proposed.

3.20.3 Radio Astronomy
889
Cross Elevation (Degrees)
Elevation (Degrees)
0
0
0
0
0
0
0
0
0
0
0
0
20
20
20
20
20
20
20
20
20
20
20
40
40
40
40
40
40
40
40
40
60
60
60
60
60
60
60
80
80
80
80
80
100
100
100
120
120
140
−4
−2
0
2
4
−4
−3
−2
−1
0
1
2
3
4
0
20
40
60
80
100
120
140
160
(a)
(b)
FIGURE 20.18
(a) Cygnus X region at 1600 MHz. 5×5 mosaic of images using the 19-element prototype PAF on the Green
Bank 20-Meter Telescope. The circle indicates the half-power beamwidth. (b) Canadian Galactic Plane
Survey image [38] convolved to the 20-m effective beamwidth. The center of the map is approximately
20h44m, +42◦(J2000) with north to the upper left.
Credit: Karl Warnick in [33].
3.20.3.2.4
Radio camera results
In 2008, ASTRON and BYU/NRAO independently demonstrated the ﬁrst radio camera images with
a PAF fed dish. Figure 20.18 presents an example of the BYU work as a mosaic image of a com-
plex source distribution in the Cygnus X region. As a comparison, the right image is from the Cana-
dian Galactic Plane Survey image, but blurred by convolution with the equivalent beam pattern of the
20-Meter Telescope to match resolution scales. We expect that the image artifacts caused by discontinu-
ities at mosaic tile boundaries could be eliminated with more sophisticated processing. The Cygnus X
radio camera image contains approximately 3000 pixels. A more practical coarse grid spacing of about
half the HPBW would require about 600 pixels. A single horn feed would require 600 pointings (one
for each pixel) to form such an image, compared to 25 (one for each mosaic tile) for the radio camera.
Thus for equal integration times per pixel, this radio camera provides an imaging speed up of 24 times.
3.20.3.3 Interference mitigation for radio astronomy
From a regulatory and spectrum management point of view, radio astronomy is a passive wireless
service which must co-exist with many other licensed communications activities. Though international
treaties have long been established to protect a few important frequency bands for astronomical use only
(e.g., around 1420 MHz for emission lines of abundant deep space neutral Hydrogen) these precautions

890
CHAPTER 20 Applications of Array Signal Processing
have become wholly inadequate. Astronomers’ current scientiﬁc goals require observing emissions
across the radio spectrum from molecules of more exotic gas compounds, from broad spectrum sources
such as pulsars, and from highly red shifted objects nearing the edge of the observable universe where
Doppler effects dramatically reduce the frequencies. Thus there is virtually no frequency band devoid
of interesting sources to study. Astronomers cannot rely solely on protected bands and must develop
methods to mitigate ubiquitous man-made radio transmission interference.
The problem is further exacerbated because one of the fundamental aims of radio astronomy is to
discover the weakest of sources which are often at signal levels many tens of decibels below the noise
ﬂoor. Successful detection usually requires long integration times on the order of hours to average out
noise induced sample estimation error variance, combined with on-source minus off-source subtraction
to ﬁnd subtile differences in power levels between a noise-only background and noise plus SOI. Thus
even very weak interference levels that would hardly hinder wireless communications can completely
obscure an astronomical source of interest.
There is a long laundry list of troublesome RFI sources for radio astronomy. Examples of man-made
signals encountered at radio observatories for which mitigation strategies have been demonstrated
include: satellite downlink transmissions, radar systems, air navigation aids, wireless communications,
and digital television broadcasts. Even locating instruments in undeveloped areas with regulatory pro-
tection for radio quiet zones does not avoid many man-made sources such as satellite downlinks. Low
frequency synthesis arrays such as LOFAR, PAPER, LWA, and the Murchison Wideﬁeld Array oper-
ate in the heavily used VHF bands (30–300 MHz) to detect highly redshifted emissions, and as such
must contend with very powerful commercial TV and FM radio broadcasts, as well as two-way mobile
communications services.
There are a variety of RFI mitigation methods used in radio astronomy. The major approaches include
avoidance (simply wait until the interference stops or observe in a different frequency band), temporal
excision (blank out only the small percentage of data samples corrupted by impulsive interference),
waveform subtraction (estimate parameters for known structured interference and subtract a synthetic
copy of this signal from the data), anti-coincidence (remove local interference by retaining only signals
common to two distant observing stations), and spatial ﬁltering (adaptive array processing to place
spatial nulls on interference). Since this present article emphasizes array signal processing, we will
address spatial ﬁltering in the following discussion.
Figures 20.16 and 20.19 illustrateinterferencescenarios for aphasedarrayfeedandsynthesis imaging
array respectively. For PAFs the closely packed antennas in the feed enable for the ﬁrst time adaptive
spatial ﬁltering on single dish telescopes. This would also be possible with PAFs on the multiple dishes
of a large imaging array, but even with just typical single horn feeds (as in Figure 20.19) the covariance
matrix used to compute imaging visibilities as in (20.34) and (20.40) can also be used for interference
canceling. Some proposed algorithms use only the main imaging array antennas, while others achieve
improved performance with additional smaller auxiliary antennas trained on the interferers as shown in
the ﬁgure. The various algorithm approaches will be discussed below. Most spatial ﬁltering work to-date
has been at frequencies in L-band (1–2 GHz) and below because this includes important astronomical
sources and because of the abundance of man-made interference in these bands.

3.20.3 Radio Astronomy
891
High gain main antenna array
Low gain auxiliary
antennas
q
p
I(p,q)
s(i)
A(p,q)
u
w
v
r1
r2
rM
Interfering
satellite
Deep-space
object
y (i)
m
y (i)
a
Ground-based
transmitter
z (i)
1
z (i)
2
m
FIGURE 20.19
An RFI scenario at a synthesis imaging array. Two independent interference sources are illustrated: a satellite
downlink and a ground-based broadcast transmitter. The main imaging array consists of typical single feed
dishes (i.e., PAF feeds are not used here). In addition to the main array, a subarray of smaller auxiliary anten-
nas is shown which can be used with some algorithms discussed below to improve cancelation performance.
If tracking information is available, these auxiliaries are steered to the offending sources to provide a high
INR copy of the interference.
3.20.3.3.1
Challenges and solutions to radio astronomical spatial ﬁltering
Many of the well-known adaptive beamforming algorithms appear at ﬁrst glance to be promising
candidates for interference mitigation in astronomical array processing, including maximum SNR,
minimum variance distortionless response (MVDR or Capon), linearly constrained minimum variance
(LCMV), generalized sidelobe canceler (GSC), Wiener ﬁltering, and other algorithms. Robust canceling
beamformers which are less sensitive to calibration error have also been considered for aperture arrays
used as stations in large low frequency imaging arrays like LOFAR. However, due to several challenging
characteristics of the radio astronomical RFI problem, most of these approaches are less successful here

892
CHAPTER 20 Applications of Array Signal Processing
than they would be in typical radar, sonar, wireless communications, or signal intercept applications.
These problems have made many astronomers reluctant to adopt the use of adaptive array processing
methods for regular scientiﬁc observations. We note though that the intrinsic motivations to observe in
RFI corrupted bands are becoming strong enough that rapid progress toward adoption is necessary and
is anticipated by most practitioners. New algorithm adaptations are being introduced which are better
suited for radio astronomical spatial ﬁltering. We consider below some of the signiﬁcant aspects of
radio astronomy that complicate spatial ﬁltering.
The typical astronomical SOI power level is 30 dB or more below the system noise over comparable
bandwidth,evenwhencryogenicallycooledLNAsareusedwithinstrumentslocatedinradioquietzones.
Canceling nulls must therefore be deep enough to drive interference below the SOI level, i.e., below the
on-source minus off-source detection limit, not just down to the system noise level. Most algorithms
require a dominant interferer to form deep nulls because minimum variance methods (MVDR, LCMV,
max SNR, Wiener Filtering, etc.) which balance noise variance with residual interference power cannot
drive a weaker interferer far below the noise ﬂoor. The residual will remain well above the SOI level.
Another promising solution to limited null depth is a zero forcing beamformer like subspace pro-
jection (SP) where the null in the estimated vector subspace for interference is theoretically inﬁnitely
deep. A number of proposed radio astronomical RFI cancelers have adopted the SP approach and some
experimental demonstration results have appeared. Figure 20.20 illustrates the ﬁrst use of subspace
projection RFI mitigation with a PAF as reported in [53]. Data were collected from a 19 element PAF
mounted on the 20-Meter Telescope at the NRAO Green Bank, West Virginia observatory while observ-
ing the deep space Hydroxl Ion (OH) maser radiation source designated in star catalog as “W3OH.” An
FM-modulated RFI source overlapping the W3OH spectral line at 1665 MHz was created artiﬁcially
using a signal generator. The RFI was removed using the subspace projection algorithm. Snapshot
radio camera images (see Section 3.20.3.2) of the source with and without RFI mitigation are shown in
Figure 20.20. The source which was completely obscured by interference is now clearly visible.
Typically interference subspace estimation is poor in SP and all other cancelers without a dominant
RFI signal so null depth suffers at lower INR levels. Short integration times, needed to avoid subspace
Cross Elevation (Degrees)
−1
−0.5
0
0.5
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
−10
−5
0
5
10
15
20
25
30
Elevation (Degrees)
(a) No RFI
Cross Elevation (Degrees)
Elevation (Degrees)
−1
−0.5
0
0.5
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
0
50
100
150
(b) With RFI
Cross Elevation (Degrees)
Elevation (Degrees)
−1
−0.5
0
0.5
1
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
−10
−5
0
5
10
15
20
25
30
(c) RFI Canceled
FIGURE 20.20
W3OH image with and without RFI. The color scale is equivalent antenna temperature (K).

3.20.4 Positioning and Navigation
893
smearing with moving interference, increase covariance sample estimation error which also limits null
depth. To address these issues, an SP canceler using auxiliary antennas as in Figure 20.19 and a new
parametric model-based SP approach for tracking low INR moving interferers have been proposed
which signiﬁcantly improves null depth [50].
Adaptive beamformers must distort the desired quiescent (interference free) beam pattern in order to
place deep nulls on interferers. For astronomy, even modest beamshape distortions can be unacceptable.
A small pointing shift in mainlobe peak response, or coma in the beam mainlobe can corrupt sensitive
calibratedmeasurementsofobjectbrightnessspatialdistribution.Duetostrictgainstabilityrequirements
it has been preferable to lose some observation time and frequency bands to interference rather than
draw false scientiﬁc conclusions from corrupted on-sky beam patterns.
For PAF beamforming a potential solution is to use one of several classical constrained adaptive
beamformers. Due to the inherent tendency for off-axis steered beams with a parabolic dish reﬂector to
develop a mainlobe coma distortion, it would be necessary to employ several mainlobe point constraints
to maintain a consistent symmetric beampattern. It has also been demonstrated that without multiple
mainlobe constraints, RFI canceling nulls in the beampattern sidelobes can cause signiﬁcant distortion
in the mainlobe.
A more subtle undesirable effect for both PAF and synthesis imaging arrays is that variations in
the effective sidelobe patterns due to moving RFI nulling can translate directly to an increase in the
minimum detectable signal level for the radiometer. Weak astronomical sources can only be observed by
integrating the received power for a long period to obtain separate low variance estimates of signal plus
noise power (on source), and noise only (off source). Both signal and noise (including leakage from other
deep space source through beam sidelobe patterns) must be stable to an extreme tolerance requirement
over the full integration time. Even small variations in the sidelobe structure can signiﬁcantly perturb
background source and noise signal levels, causing intolerable time variation. This sidelobe pattern
rumble due to adaptive cancelation increases the “confusion limit” to detection since unstable noise and
background are not fully canceled in the on-source minus off-source subtraction. This occurs even if
the beam pattern mainlobe is held stable using constrained or robust beamformer techniques.
3.20.4 Positioning and navigation
The Global Positioning System (GPS) is the most widely adopted positioning system in the world. It is a
prominent example of what is known as Global Navigation Satellite Systems or GNSS, which represent
any system that provides position information to users equipped with appropriate receivers at any time
and anywhere around the globe based on signals transmitted from satellites. Currently there are two
operating GNSS: GPS (developed by the USA) and Glonass (developed by the former USSR and now by
Russia), while there are a number of systems under deployment, such as Galileo in Europe and Compass
in China. Despite the differences in the satellite constellation, signal parameters, etc., all of these systems
share the same operating principles and use similar types of signals. Therefore, while we will often refer
to the case of GPS, all of what we discuss here is also applicable to the other systems as well.
The GPS constellation is formed by approximately 30 satellites orbiting at a distance of about
26,560 km from earth’s center. Each satellite transmits several Direct-Sequence Spread-Spectrum

894
CHAPTER 20 Applications of Array Signal Processing
(DS-SS) signals, and the main task of a GPS receiver is to measure the distances to the satellites
via the time delay of the signals. In applications requiring high-accuracy positions, the phase of the
received signal is also used as a source of information about the propagation delay of the signal. Once
the receiver has obtained these distances, it can compute its position by solving a geometrical problem.
Apart from the satellites themselves, the core of a GNSS is the ground segment that consists of a set of
ground stations monitoring the satellites and computing their positions.
Unlike communication receivers, where timing and phase synchronization are intermediary steps
to recovering the transmitted information, for positioning receivers it is the synchronization that is
the information. Signiﬁcantly greater synchronization precision is required in a GNSS receiver than
in a communications system. As discussed below, the positioning accuracy of GNSS is degraded by
many effects. Multipath propagation and certain types of interference are very difﬁcult to mitigate with
single-antenna receivers. Spatial processing has proven to be the most effective approach to combat
these sources of degradation, making it possible to obtain in some cases the same accuracy as in a
multipath- and interference-free scenario. The next two sections describe the error sources in GNSS,
with special emphasis on the multipath effects, and an appropriate signal model for spatial process-
ing. They serve as a justiﬁcation of why the use of antenna arrays in the context of GNSS has been
receiving considerable attention since the mid-1990s. The rest of the sections discuss the advantages
and limitations of different approaches for exploiting the spatial degrees of freedom or spatial diversity
in satellite-based navigation systems.
3.20.4.1 Error sources and the beneﬁts of antenna arrays in GNSS
The synchronization accuracy demanded by GPS receivers is very stringent, on the order of a few
nanoseconds, and exceeds by far the levels usually required in communications receivers. The difﬁculties
in achieving such ranging accuracy are due to the presence of different sources of error, which can be
categorized in three groups: (i) the errors due to the ground segment and the satellites, (ii) propagation-
induced errors, and (iii) local errors at the receiver. The ﬁrst category includes the discrepancy between
the estimates of the satellite positions and clocks, which are computed by the ground segment and
broadcast by the satellites themselves, and the actual values. The second category corresponds to the
changes in the propagation delay, phase and amplitude of the signals caused by the atmosphere. Finally,
local errors refer to the effects of thermal noise, interference and multipath components.
The largest contributors to the total error budget are typically the ionospheric delay and local effects.
The size of the errors in the ﬁrst category is progressively decreasing as the ground segment and satellites
are modernized. Moreover, one can also access alternative providers of more accurate satellite coordi-
nates and clocks. Another option is to use differential methods, where the user receiver makes use of
corrections computed by another receiver at a known position, or relative methods, where the position
relative to that second receiver is computed. The use of differential or relative methods virtually elimi-
nates the errors from the ﬁrst category. These methods also help mitigate the propagation-induced errors.
Alternatively, the ionospheric delay can be essentially canceled using measurements at two or more
frequency bands. In short, the errors from the ﬁrst two categories can typically be mitigated at the mea-
surement or system levels, andhencethelocal errors remainas thelimitingfactor intheultimateaccuracy
achievable with GNSS. This is the reason why it is of high interest to use signal processing techniques,
and in particular antenna array-based methods, to combat multipath and interference effects in GNSS.

3.20.4 Positioning and Navigation
895
Diffraction
FIGURE 20.21
Environment with multipath propagation.
As in other systems, interference obviously affects the quality of time delay and phase estimates
in GNSS. On the other hand, the study of multipath effects requires a different treatment to the one
that is typically employed in wireless communications. While multipath components can be useful in
communications systems as a source of diversity or to increase the total received signal power, they are
always a source of error in navigation systems, and can lead to positioning inaccuracies reaching up to
many tens of meters. For the case of a satellite-based transmission, multipath is produced by objects that
are close to the receiver, as depicted in Figure 20.21. The only signal of interest in a navigation receiver
is the line-of-sight (LOS) signal, since it conveys information about the transmitter-receiver distance
through its time delay and phase information. While the multipath in a frequency-ﬂat channel with zero
delay-spread theoretically arrives at the same time as the LOS, the resulting fading can lead to signal
drop-outs and poor localization performance. A second antenna (i.e., forming a small array) can be
used to overcome this difﬁculty. More challenging are multipath signals that arrive with non-zero delay
relative to the LOS, but still within 1–1.5 chip periods of the LOS (for civilian GPS, the chip period
is 1 µs, corresponding to about 300 m). Such signals are commonly referred to as coherent multipath,
and cause biases in the LOS signal time delay and carrier phase estimates. Signal replicas with delays
greater than about 1.5 chip periods can essentially be eliminated via the despreading process.
Narrowband or pulsed interference can be canceled in single antenna receivers using excision ﬁlters or
pulse blanking. Wideband non-pulsed interference cannot be combatted with time-domain processing,
but it is in principle an easy target for array processing. Harmful interference usually stands out clearly

896
CHAPTER 20 Applications of Array Signal Processing
above the noise, and this makes its identiﬁcation and subsequent nulling with a spatial ﬁlter relatively
easy. On the other hand, multipath mitigation is an extremely difﬁcult task in single-antenna receivers
and also a difﬁcult problem when using antenna arrays. In the single-antenna case where time-domain
methods must be used, the problem is ill-conditioned since one is attempting to estimate the parameters
of signal replicas that are very similar to each other. If a reﬂection and the LOS signal differ by a very
small delay (compared to the inverse of the signal bandwidth), they are almost identical and it is very
difﬁcult to accurately measure the exact LOS signal delay. On the other hand, the spatial selectivity
offered by antenna arrays can be used to differentiate the LOS signal from multipath, since the multipath
will arrive from directions different from the LOS (it is very unlikely to have reﬂectors close to the
direct propagation path). The application of spatial processing for multipath mitigation is not without
difﬁculties. The main problem is that the LOS signal and the coherent multipath are strongly correlated,
which causes problems for many array processing techniques.
3.20.4.2 Signal model for positioning applications
The signal received by the antenna array can be written as
y(t) =
D

k=0
αkakx(t −τk)e j2π fkt + n(t).
(20.50)
In particular, in our problem the sources are not different signals, but delayed replicas of a single signal.
EachreplicaisshiftedbyadifferentDopplerfrequency fk,anditscomplexamplitudeisαk.Thesubindex
0isreservedfortheLOSsignal,andthisimpliesthatτi > τ0, ∀i.Thetermn(t)includesthethermalnoise
and any (possibly directional) interference. The key parameters of interest for positioning applications
are τ0 and possibly the argument of α0 (i.e., ∠α0, which is the carrier phase of the LOS signal).
According to the discussion above, we assume that the delays of the replicas are in the range [τ0, τ0+
1.5Tc], where Tc is the chip duration. Each replica may represent a single reﬂection or a cluster of
reﬂections with very similar delays. This leads to different possible parameterizations for the vectors
ak, as listed below:
1. an unstructured spatial signature (i.e., each ak is an arbitrary complex vector). In this case, there is
an inherent ambiguity between the deﬁnition of αk and ak, which can be simply avoided by deﬁning
αkak as the overall spatial signature. One element of the spatial signature is identiﬁed as αk, and
hence the carrier phase of the LOS signal is given by the argument of that element of the spatial
signature.
2. a steering vector (or also referred to as structured spatial signature), which is a function of the DOA.
3. a weighted sum of steering vectors: ak = Dk
l=1 αk,lak,l(θk,l, φk,l), where each term corresponds
to the amplitude and the steering vector of one of the reﬂections of the cluster. In this case, the
ambiguity between αk and ak can be handled in the same way as in the ﬁrst model.
The signal x(t) may represent the GNSS signal itself or the signal after some processing. The
most common case of processing in our context is the despreading operation, which consists in cross-
correlating the received signal with a local replica of the pseudorandom or pseudonoise (PN) sequence.

3.20.4 Positioning and Navigation
897
In this case, the variable t in the signals may be interpreted as the correlation lag. Unlike communications
receivers, a single correlation lag is not sufﬁcient. A single correlation lag may be appropriate for data
detection but in a GNSS receiver, where the timing of the PN sequence has to be measured, several
correlation lags are required. The correlation of the incoming signal with the local sequence is usually
computed as a multiply-integrate-and-dump operation, which is carried out for each lag. However,
the despread signal, depicted in Figure 20.22, can also be interpreted as a portion of the output of
a matched ﬁlter. Figure 20.23 shows how the reception of multiple replicas affects the shape of the
despread signal, and it is clear from there that identifying the components that form the signal is a very
complicated task.
The choice of whether to base the computation of beamformers or other estimation methods on
the pre-despreading (pre-correlation) or post-despreading (post-correlation) signal has a crucial impact
on the performance and limitations of the array processing algorithms. GNSS signals typically have
a Carrier-Power-to-Noise-Spectral-Density (C/N0) of about 45 dB Hz. The chip rate and hence the
bandwidth is greater than 1 MHz, so this results in an SNR on the order of −15 dB or less. This means
that the GNSS signals and also their reﬂections are buried in the background noise. If one computes
the spatial correlation matrix Ryy = E{y(t)yH(t)} in a pre-correlation scheme, only the noise and
interference have a noticeable contribution to the matrix, so in practical terms the “total” correlation
matrix Ryy really only represents the noise-plus-interference correlation matrix.
The situation is completely different in the post-correlation scheme. The SNR of the correlation
maximum is equal to C/N0 times the duration of the local reference. The duration of PN sequences
in GNSS is several milliseconds, so the SNR of the maximum is typically on the order of several tens
of dBs. The average SNR of the signal depends on the length of the portion of the correlation around
the maximum that is taken as the observation window. This length is normally not too large, usually
only a few chips, so the average SNR stays at the level of tens of dBs. In this case, the post-correlation
matrix Ryy includes noticeable contributions from the LOS and reﬂected signals besides the noise and
y(t)
time
T
T
2T c
2T c
2T c
Symbol 1
Symbol 2
Symbol 3
FIGURE 20.22
Qualitative example of the signal at one antenna after the despreading (parameter T is the symbol period:
20 ms in GPS C/A, and Tc is the chip duration: ∼1 µs in GPS C/A.)

898
CHAPTER 20 Applications of Array Signal Processing
y(t)
o
o
bT
+
1
2
y t( )
t
FIGURE 20.23
Qualitative example of the despreaded signal composed of the LOS component and two reﬂections. These
reﬂections are considered as coherent multipath because their contributions overlap with that of the LOS
component.
interference. To conclude, in order to make multipath visible in the spatial correlation matrix, one has
to work with the post-despreading correlation matrix. If one wants to hide multipath from the spatial
correlation matrix, the pre-despreading correlation matrix has to be used.
The location of the beamformer (if any) with respect to the despreader has an impact on computational
complexity, but it does not have an effect on performance since only its position within a set of linear
operations is changed. Note that we are referring here to the placement of the beamformer in the
receive chain, and not to the input data used for its computation, which is a totally different aspect as
explained above. Some examples of the placement of the beamformer as well as the input data used
for its computation are shown in Figures 20.24 and 20.25. Note that all combinations are in principle
possible, although some cases, such as pre-despreading beamforming with weights computed using
the post-despread signals, do not have a clear justiﬁcation. As an example of a typical approach, the
beamforming vector is computed using the pre-despread correlation matrix as w = R−1
yy a0, and applied
to the despread signal to obtain z(t) = wHy(t). In the ﬁrst formula, the symbol y refers to signals before
despreading, whereas in the second formula it refers to the despread signals.
3.20.4.3 Beamforming
The objective is to synthesize an array pattern that attenuates the reﬂections and interference. In the con-
text of GNSS, antenna-array beamformers are customarily referred to as CRPAs (Controlled Reception
Pattern Antennas). Adaptive (or data-dependent) beamforming is appropriate for situations where little
a priori information about the scenario is available, or when the scenario is likely to change with time.

3.20.4 Positioning and Navigation
899
RFE & ADC
RFE & ADC
RFE & ADC
RFE & ADC
Beamformer for one
or several satellites
Generation of several
delayed replicas of the
reference signal
One correlation channel, processing
only one signal for one satellite
To the rest of the
GNSS receiver
Computation of the spatial
correlation matrix, beamformer,
etc., using the signals before the
despreading
w∗
1
w∗
2
w∗
3
w∗
M
I&D
I&D
I&D
FIGURE 20.24
Example of a GNSS receiver using an antenna array where the beamformer is applied before despreading and
it is computed using the pre-despread signals. The output of the beamformer is processed by a conventional
GNSS receiver channel, as if it was the signal coming from a single antenna. Either option is possible: the
beamformer can be the same for all satellites, or different beamformers for different satellites can be used.
The complexity bottleneck is due to the fact that the beamformer weights are applied to high-rate samples
coming from the RF front-end.
This is the typical situation for user receivers. On the other hand, deterministic (or data-independent)
beamforming is more suitable for static and relatively controlled scenarios. This is typically the case
for ground reference stations. These reference stations refer to both the receivers that form part of
the ground segment of the GNSS (i.e., those receivers providing the measurements used to compute
the position of the satellites) and the user receivers that are static and typically used as references in
differential or relative positioning.
3.20.4.3.1
Adaptive beamforming
As outlined below, several different types of adaptive beamforming algorithms have been proposed for
GNSS. Some of these are adaptations of standard algorithms, others have been designed speciﬁcally
for conditions speciﬁc to positioning applications.

900
CHAPTER 20 Applications of Array Signal Processing
RFE & ADC
Correlation channel
Correlation channel
Correlation channel
Correlation channel
RFE & ADC
Optional Spatial Preprocessing
RFE & ADC
RFE & ADC
Computation of the
pre-despreading
spatial correlation
matrix (valid for all
satellites)
Computation of the
post-despreading
spatial correlation
matrix (valid only for
one satellite)
Generation of several
delayed replicas of the
reference signal
Computation of the
beamformer for one
satellite
Signal for time-
delay and 
carrier phase
estimation
I&D
I&D
I&D
w∗
1
w∗
2
w∗
3
w∗
M′
I&D
I&D
I&D
I&D
I&D
I&D
I&D
I&D
I&D
FIGURE 20.25
Example of a GNSS receiver using an antenna array where the beamformer is applied after despreading. The
beamformer vector is calculated using the pre-despreading or the post-despreading spatial correlation matrix.
An optional spatial preprocessing block is included, which can be used to cancel some spatial sectors. The
number of outputs of the preprocessing block, M′, is equal to or smaller than the number of antennas, M.
In this conﬁguration, the application of the beamformer weights do not entail a signiﬁcant computational
load because the correlation channels generate samples at a very low rate. Hence the fact that a different
beamformer is applied for each satellite is not a problem. Here the computational bottleneck comes from
the need to use a correlation channel at each antenna or at each output of the preprocessing block.
Algorithms employing a spatial reference: These approaches are based on knowledge of the steering
vectoroftheLOSsignal,a0.AssumingthisaprioriinformationisreasonableinsomeGNSSapplications
since the satellite position can be known thanks to the navigation message (transmitted by the satellite
itself) or to assistance from ground stations, and a rough estimate of the receiver position may be
available from previous position ﬁxes or from the application of a basic positioning algorithm (e.g.,
using only one antenna and not exploiting the antenna array). Moreover, the accuracy of the satellite
and receiver positions is not important in determining the DOA of the signal; errors of several hundreds

3.20.4 Positioning and Navigation
901
of meters can be tolerated without affecting the satellite DOA estimate, given that the satellite-receiver
distance is more than 20,000 km. However, the assumption of a known a0 relies on the availability of
array calibration and especially on the knowledge of the receiver orientation (also known as attitude in
the GNSS literature). Errors or uncertainty in the array response correspond to the standard calibration
problem found in many applications of antenna arrays, and robust methods developed for generic
applications are also applicable here. On the other hand, the need to know the receiver orientation is a
feature more speciﬁc to GNSS receivers. Assuming that a0 is known, the use of the MVDR beamformer
(and variants) is possible, and it is most appropriate to apply them in a pre-despreading scheme. If these
beamformers are computed with the post-despreading correlation matrix and multipath components are
present, they will suffer from the cancellation of the desired signal.
Algorithms employing a temporal reference: These methods are based on knowledge of the GNSS
signal waveform. Knowledge of the waveform can be exploited to design a beamformer that minimizes
the difference between its output and the reference signal (e.g., as in a Wiener ﬁlter). In practice, the
situation is not that straightforward because even though the shape of the signal is known, the delay
and frequency shift are not, so the beamformer weights and the signal parameters have to be computed
jointly or iteratively. The expression for the beamformer is
wT = R−1
yy ryx

ˆτ0, ˆf0

,
(20.51)
where ryx(ˆτ0, ˆf0) is the cross-correlation between the array output and a local replica of the LOS signal
generated using estimates of its delay and frequency shift, ˆτ0 and ˆf0, respectively. In this case, it only
makes sense to work with correlations computed after the despreading, otherwise the contribution of
the GNSS signals is hardly present in the correlations. This beamformer is able to cancel interference,
but its performance in the presence of multipath is not satisfactory, although not as bad as with spatial-
reference beamformers. The temporal reference beamformer combines the multipath and the LOS signal
in a constructive manner, so as to increase the SNR. This is useful behavior in communications but not
in navigation systems, since the increase in SNR comes at the price of a bias in the estimation of the
delay and phase due to the presence of strong multipath at the beamformer output.
Hybrid beamformers: The opposite behavior of the spatial-reference and temporal-reference beam-
formers suggests that their combination may have good properties. Both of them provide the LOS signal
at the output, but the former changes the phase of the multipath so that it is roughly in counter-phase
with the LOS signal, whereas the later modiﬁes the multipath phase to align it with that of the LOS
signal. Therefore, if the output of both beamformers is added together, the multipath will tend to cancel.
This observation has led to the proposal of a hybrid beamformer that can be expressed as
wH = βwT + γ wS,
(20.52)
where wS is a spatial-reference beamformer, and β and γ are two scalars weighting the contribution
of each beamformer. When wS is chosen as the MVDR beamformer, it can be shown that the optimal
weights are
β = α0,
γ = 1 −α0aH
0 R−1
yy ryx(τ0, f0).
(20.53)

902
CHAPTER 20 Applications of Array Signal Processing
Since the optimal weights depend on the unknown parameters to be estimated, a practical way to proceed
is to use an iterative algorithm where the calculation of the beamformer according to (20.52) is done
using the previous estimates of {α0, τ0, f0}, and next these estimates are updated using the output of
the just computed beamformer.
Blind algorithms: This class of methods refers to techniques that do not exploit a priori knowledge of
the exact signal or the steering vector, and hence are more robust to errors in these assumptions. Examples
of such methods include those based on the constant modulus (CM) assumption, cyclostationarity and
the power inversion approach. The civil GPS signal in current use, referred to as the C/A signal, has
constant modulus because it is formed by almost rectangular chips. Most other GNSS signals also
satisfy the CM property. However, this property cannot be exploited before despreading since the array
cannot provide enough SNR gain to bring the signal above the noise. Therefore, the CM beamformer
has to be applied after despreading, but in order to do so the despread samples corresponding to the LOS
signal have to be CM. This happens when only one sample per integration period is used. However, the
presence of multipath does not alter the constant-modulus property of the signal, so the CM beamformer
is not useful in combating multipath.
GNSS signals are obviously cyclostationary since the repeated use of the PN spreading sequence
introduces periodicity into the statistics of the signal. The fact that several repetitions of the PN code
are present during a bit time (a property sometimes referred to as self-coherence) can also be exploited,
as depicted in Figure 20.26. Interference will not have in general this structure, so it is possible to
design the beamformer by imposing that its output should be as similar as possible to a version of itself
delayed by a time equal to the PN code duration. Because of the same reasons as in the case of the
CM beamformer, this technique should be applied to the despread signals and it will only be effective
against interference and not multipath.
A very simple but rather effective approach is the power inversion beamformer. The weights are
obtained as the beamformer vector that minimizes the total output power subject to a simple constraint
to avoid the null solution. The constraint is chosen without using any information about the signal,
typically forcing a given beamformer coefﬁcient to be equal to one. This method has to be applied
to the signals before despreading and, since the response is independent of the GNSS signals, it may
happen that some nulls of the reception pattern are near to the DOAs of some of the GNSS signals.
However, this situation can often be accepted since it is assumed that many GNSS satellites will be
1 ms
One bit period, 20 ms
PN code 
period
Acts as 
reference for
Acts as 
reference for
FIGURE 20.26
Structure of the GPS signal that allows to implement self-coherence restoration beamforming methods.

3.20.4 Positioning and Navigation
903
visible (around 10 satellites), and if a few of them are lost due to the coincidence of the pattern nulls
with their DOAs, there will still be a sufﬁcient number of satellite signals available (i.e., four or more)
to compute the position. In this method, all satellites are received through the same beamformer, so
it offers the possibility of being deployed as an add-onto existing single-antenna receivers. This is an
important advantage of this method; more sophisticated beamformers that require information provided
the receiver (e.g., the DOA or the delay of the LOS signal) or that generate one beam per satellite
cannot be coupled with existing single-antenna receivers and require the development of a completely
new receiver. The number of antennas used with power inversion should be large enough to cancel
the existing interference sources, but not much larger in order not to increase the number of nulls in
the pattern and thus the probability that a GNSS signal is canceled. The power inversion approach is
popular in military systems where jamming from highly maneuverable sources (ﬁghter jets) is a pivotal
concern. The fast maneuvers of these vehicles makes the use of spatial-reference beamformers virtually
impossible, and therefore a simple and robust method like power inversion, that does not need any
reference or calibration procedure, is an excellent option.
3.20.4.3.2
Deterministic beamforming
Although it is recognized that data-dependent beamformers are more powerful in general than determin-
istic versions, there are some situations where the latter may be advantageous. Deterministic beamform-
ers are clearly more robust against calibration errors and other uncertainties in the signal parameters.
Moreover, if the desired and non-desired signals are known to be conﬁned to distinct spatial regions,
the deterministic design may offer an adequate solution since the problem reduces to designing a spatial
ﬁlter with given pass and stop bands. This a priori spatial separability occurs in several circumstances in
GNSS, particularly in GNSS ground stations. In this case, the interference is normally ground-based, and
the multipath normally arises from ground-based scatterers, so both interference and multipath impinge
on the receiver from relatively low elevation angles. This is contrasted with the satellite signals, which
originate from the entire upper hemisphere. Thus, as illustrated in Figure 20.27, a ﬁxed beamformer can
be designed to minimize reception of signals from these low elevations. The complicating factor here
is that an upwards-facing array typically cannot provide a sharp stop-band to pass-band transition for
directions near end-ﬁre. Another advantage of deterministic beamformers is that they allow an easier
control of the trade-off between array gain (understood here as the increase of the ratio between the
desired signal power and the white noise power) and interference cancellation. In adaptive beamform-
ers, these two characteristics are tightly coupled. For instance, with MVDR, the presence of a strong
interference gives rise to a deep null in the pattern, and this null necessarily increases the beampattern
in other directions, thus degrading the array gain.
3.20.4.4 DOA estimation
DOA estimation algorithms can be used as a processing stage prior to beamforming. If the DOAs
of the LOS and reﬂected signals and interferences can be determined, then it is possible to design a
beamformer that, for instance, attenuates the reﬂections and interferences while maximizing the SNR
of the LOS signal. Given the identiﬁability limitations of DOA estimation methods and their sensitivity
to highly correlated signals, such a method would likely only be suitable in situations where there were
a small number of multipath and interference arrivals in addition to the LOS signal. The DOAs of the

904
CHAPTER 20 Applications of Array Signal Processing
θn
θs
Forbidden sector
Desired sector
Transition sector
FIGURE 20.27
Desired and forbidden regions for the design of deterministic beamformers.
non-desired signals can typically be obtained in two stages; interference sources can be localized prior
to despreading, while the DOAs for multipath sources would have to be found after despreading. Even
when it is not possible to use estimation methods to determine the DOAs of all signals, such methods can
still be useful for detecting scenarios where the LOS signal is obstructed. Such information is critical in
trackingapplications,sincehighlyerroneousestimatesduetonon-LOSmeasurementscanbeeliminated.
3.20.4.5 Array-based parameter estimators
Probably the most rigorous approach to the use of antenna arrays for multipath and interference mitiga-
tion consists not in focusing on the use of the array to synthesize a beam that attenuates those unwanted
signals, but in formulating the measurement of the time delay and carrier phase of the LOS signal as
an estimation problem. The Maximum Likelihood (ML) approach used in many other areas of array
processing can also be used here. There is a large variety of models and assumptions that have been
used to derive ML estimators, as we brieﬂy outline below. Recall the expression of y(t) in (20.50) and
assume that K samples or snapshots are taken from the array, which form the columns of a matrix Y.
This matrix can be expressed as
Y = A(X(τ) ⊙D(f)) + N,
(20.54)
where A = [a0, . . ., aD],  = diag{α} = diag{α0, . . ., αD}, τ = [τ0, . . ., τD], and f = [ f0, . . ., fD].
The (k,n)th components of X and D are: [X(τ)]k,n = x(tn −τk) and [D(f)]k,n = e j2π fktn. Matrix N
contains the snapshots of n(t), which includes all disturbances present in the received signal except for

3.20.4 Positioning and Navigation
905
the multipath components. In particular, as it can include directional interference, it is logical to assume
that N is spatially colored. The spatial correlation matrix is denoted as Q and it is in general assumed to
be unknown. If we further assume for simplicity that N is temporally white, zero-mean and circularly-
symmetric complex Gaussian distributed, the negative log-likelihood function can be expressed as
L(Y, A, α, τ, f) = M ln det(Q)
+ tr

Q−1(Y −A(X(τ) ⊙D(f)))(Y −A(X(τ) ⊙D(f)))H
,
(20.55)
where A can be replaced with the alternative parameterization discussed in Section 3.20.4.2. The ML
estimates of the different parameters can be obtained as the arguments that minimize (20.55). This opti-
mization problem, in its most general form, cannot be easily tackled because it has a large number of
variables and it is highly non-linear (and non-convex). As discussed below, simpliﬁcations are possible
depending on various modeling assumptions and how the problem is parameterized.
Unstructured spatial signatures and spatially white noise: The assumption of spatially white noise
allows determinant in (20.55) to be eliminated, and the ML problem turns into a least squares problem.
Since the resulting problem has the same structure as the estimation of the DOAs of unknown deter-
ministic signals, most DOA estimations algorithms can be adapted to the estimation of time delays and
frequencies in this new setup. A number of algorithms have been developed based on this parallelism
between conventional DOA estimation and time delay estimation with unstructured spatial signatures.
However, all techniques derived under the assumption of spatial whiteness suffer from a lack of interfer-
ence mitigation capability. In addition, the use of unstructured spatial signatures causes the variance of
the estimates to grow when the difference in delay and frequency shift of the replicas becomes smaller
(see Figure 20.28).
Structured spatial signatures and spatially white noise: In this approach, the steering vectors ak are
parameterized by the corresponding DOAs instead of being arbitrary complex vectors. This change
makes the estimation problem more non-linear and hence more complex to solve, but on the other hand
it provides in general more accurate estimates because the model parsimony is improved. The increased
accuracy is largely observed when the signals are very close to each other in the delay and frequency
dimension.
Unstructured spatial signatures and unknown spatial correlation: The ML estimator for this model
involvesthedeterminantofthecorrelationmatrixoftheﬁttingresiduals,andhenceitdoesnotcorrespond
to a least squares problem like the techniques derived under the assumptions of unstructured spatial
signatures and spatial white noise. Consequently, it is not possible to establish a clear parallelism
with DOA estimation algorithms, but techniques have been developed that are robust to directional
interference. In addition, asymptotically equivalent algorithms have been proposed that admit a simple
solution based on polynomial rooting.
Structured spatial signatures and unknown spatial correlation: This constitutes the most detailed
model for the problem at hand, and also the one that leads to the best performance as long as there are
no severe model mismatches with respect to reality. A direct optimization for this model requires a highly
non-linear search in the DOA, time delay and frequency spaces, which cannot be implemented easily
in an efﬁcient manner. This limitation has been recently overcome by applying the Extended Invariance

906
CHAPTER 20 Applications of Array Signal Processing
FIGURE 20.28
Qualitative representation of the behavior achieved with the estimators derived under different models. It is
assumed that the LOS signal and one reﬂection are received. The solid line corresponds to the model with
unstructured spatial signatures. The dashed line corresponds to the model with structured spatial signatures;
the line may be not totally constant, but in any case it shows a much smaller dependence with the delay than
the solid line. When the reﬂection is not mitigated, the errors have the shape depicted by the dash-dotted
line, where the increase in the RMSE is normally not due to an increase of the variance as in the other two
cases, but to the existence of large bias.
Principle (EXIP). The EXIP technique begins with ML estimates corresponding to the model with
unstructured spatial signatures and unknown spatial correlation described above, which can be obtained
with relatively low complexity. Then, these estimates are reﬁned by means of a weighted least-squares
ﬁt, resulting in improved estimates that have the same asymptotic accuracy as the exact ML estimates
directly derived from the model with structured spatial signatures and unknown spatial correlation.
The reﬁnement approach boils down to a DOA estimation problem, and if the antenna array response
has a Vandermonde structure, a polynomial-rooting based DOA estimator can be used. Thus, in the
most difﬁcult case involving DOAs and time delays of several replicas received in noise of unknown
spatial correlation, estimates asymptotically equivalent to the ML ones can be obtained simply rooting
two polynomials.
GNSS-speciﬁc signal models: Although the methods described above rigorously follow the logic of
model-based estimation, they may present limitations in some practical conditions. This is exempliﬁed
by these two cases:
•
The model in (20.54) assumes that the received signal is formed by several replicas of the transmitted
GNSS signal. The real received signal may not be constituted by a few clearly deﬁned reﬂections, but
instead may consist of a large number or even a continuous distribution of components. In principle,
the accurate modeling of this reality would require the use of a very large value for D in the model,
and this would prohibitively increase the number of parameters to estimate and hence the complexity.
One can argue that a reasonable model can be obtained using only a few replicas that capture most
of the contribution of the actual multipath environment. But even if this is true, the estimation of the

3.20.5 Wireless Communications
907
appropriate value of D (large enough to represent well the received signal, but not too large to avoid
overﬁtting of the model and excessive complexity) is an issue that needs to be addressed in any of
the model-based estimators presented above.
•
There are some particular aspects of the GNSS application that are not adequately exploited. For
instance, the above methods provide estimates of all parameters in the model, but this is overkill in
GNSS, where only the parameters of the LOS signal are of interest for positioning. Moreover, there
is some side information that is not employed in the models, such as the a priori knowledge of the
DOA of the LOS signal, and the fact that reﬂections always arrive later than the LOS signal and
usually with smaller amplitudes.
As a consequence, a different way of proceeding consists in abandoning very detailed models attempt-
ing to provide a very precise description of the received signal (and maybe not achieving it because the
signal includes other effects not accounted for in the model), in favor of simpler models that focus on
particular aspects related to the GNSS application, even if they do not necessarily provide a compre-
hensive representation reality. For example, when LOS DOA can be assumed to be known, the vector
a0 can act as a spatial reference to the LOS signal, what makes it possible to approximately model
the reﬂections as part of the noise term with unknown spatial correlation and, hence, the value of D is
simply taken as zero. It can be shown that there is an equivalence between the estimator resulting from
this simpliﬁed model and the hybrid beamformer presented in Section 3.20.4.3.1, while a model with
D > 0 would provide a more accurate representation of reality (at the expense of increased complexity),
results have shown that there is typically not a large penalty in assuming D = 0. Problems will arise in
situations when the delay of the reﬂections are close to that of the LOS signal, in which case the time
delay and carrier phase estimates are biased. However, the degradation in such cases remains bounded.
3.20.5 Wireless communications
The use of antenna arrays in wireless communications provides one or more of the following types of
advantages: diversity gain, array (or beamforming) gain and multiplexing gain. Given that in practice
these gains lead to increases in capacity and spectral efﬁciency as well as improved robustness against
fading, multiple antenna (or MIMO) techniques have been included in recent wireless communication
standards. While the signal models and algorithms for multi-antenna wireless communications have
been studied in detail in other chapters, here we focus on speciﬁc ways in which multiple antennas are
exploited in current wireless standards.
3.20.5.1 Multiple antennas techniques in LTE
MIMO constitutes an essential element of LTE in order to achieve the highly demanding requirements
for transmission rate and spectral efﬁciency. LTE exploits multiple antennas for both diversity and
multiplexing [78,79, Ch.11], and also for both the downlink and uplink portions of the network.
3.20.5.1.1
Diversity schemes
Various sources of diversity are available to average out channel variations due to fading. This includes
time and frequency diversity, as well as transmit and receive diversity. Receive diversity is mandatory

908
CHAPTER 20 Applications of Array Signal Processing
for user handsets, usually referred to as UE’s (User Equipment). It is the baseline receiver functionality
for which performance requirements are deﬁned. The typical method consists in performing maximum
ratio combining (MRC) of the signals received at several antennas. We will focus however on transmit
diversity since many schemes were analyzed in detail during the standardization phase of LTE. Some
of the characteristics sought for the ﬁnal selection of techniques were:
•
Absence of puncturing in the presence of correlated channels. This eliminated the use of Cyclic Delay
Diversity (CDD) and Precoding Vector Switching (PVS) in favor of block-code-based schemes.
•
Low decoding complexity, which eliminated the option of non-orthogonal block codes.
•
Power efﬁciency. Each antenna has an instantaneous power limitation, so the power that is not
employed during one OFDM symbol (referred to as a “resource element” in LTE) cannot be shifted
to the following ones. On the other hand, power can be adaptively allocated in the frequency domain;
power that is not used in some subcarriers can be employed in others. The objective of using the
maximum available power makes it advisable to select schemes where all antennas transmit at all
times, though not necessarily in all subcarriers. This objective takes precedence over achieving a
uniform power distribution in the frequency domain.
•
Robustness to channel estimation errors. Orthogonal block codes lose the orthogonality property
due to channel estimation errors at the receiver. As a certain level of error is unavoidable, it has to
be checked that these errors do not cause large interfering terms. Estimation errors are not the only
source of loss of orthogonality; variations of the channel that violate some design assumptions (such
as the channel is constant across a certain group of subcarriers or during some symbols) may also
create self-interference. It is desired to use techniques that do not make stringent assumptions about
the evolution of the channel in time or frequency. Moreover, the quality of the channel estimation is
not necessarily the same at all antennas. This means that all antennas are not statistically equivalent
on average and a proper balancing of the symbols among them is needed.
•
Good adaptation to the structure of the signals. The signals are mapped to two-dimensional resource
blocks formed by a certain number of symbols and subcarriers. Some codes must be applied over a
number of symbols or subcarriers that is a multiple of a given value (typically two or four). It may
be easier to achieve the structure required by the code in one of the two dimensions. Since there are
many more subcarriers than symbols forming a resource block, it is usually simpler to apply the code
in the frequency domain because selecting a certain number of subcarriers is more manageable than
changing the number of symbols in a block. Furthermore, in LTE the number of available OFDM
symbols in a resource block is often odd.
•
Reduced inter-cell interference. One must consider the impact of diversity techniques on the inter-
ference produced in neighboring cells.
For two-transmit-antenna diversity, the well-known Alamouti code is applied in the frequency
domain, constituting a Space-Frequency Block Code (SFBC). If y(p)(k) denotes the symbols trans-
mitted from the pth antenna on the kth subcarrier, at a given OFDM symbol period, the transmission
strategy of the eNodeB (i.e., the base station in LTE terminology) can be represented as follows:
 y(0)(k)
y(0)(k + 1)
y(1)(k)
y(1)(k + 1)

=

x(n)
x(n + 1)
−x∗(n + 1)
x∗(n)

,
(20.56)

3.20.5 Wireless Communications
909
FIGURE 20.29
Space-Frequency Block Code for four antennas used in LTE.
where x(n) represents the stream of symbols to be transmitted. In the case of four transmit antennas,
the previous code is applied to each pair of antennas. Each pair of antennas uses a different set of
frequencies, and hence the scheme is referred to as SFBC-FSTD, where FSTD stands for Frequency
Shift Transmit Diversity (also known as Frequency Switched Transmit Diversity). This is depicted in
Figure 20.29, and can be expressed as
⎡
⎢⎢⎣
y(0)(k)
y(0)(k + 1)
y(0)(k + 2)
y(0)(k + 3)
y(1)(k)
y(1)(k + 1)
y(1)(k + 2)
y(1)(k + 3)
y(2)(k)
y(2)(k + 1)
y(2)(k + 2)
y(2)(k + 3)
y(3)(k)
y(3)(k + 1)
y(3)(k + 2)
y(3)(k + 3)
⎤
⎥⎥⎦
=
⎡
⎢⎢⎣
x(n)
x(n + 1)
0
0
0
0
x(n + 2)
x(n + 3)
−x∗(n + 1)
x∗(n)
0
0
0
0
−x∗(n + 3)
x∗(n + 2)
⎤
⎥⎥⎦.
(20.57)
This mapping is a full-rate orthogonal code with diversity order equal to two, which is smaller than the
possible maximum of four since full-rate full-diversity orthogonal codes do not exist for four antennas
and complex symbols. Note also that each pair of symbols uses antennas {0, 2} and {1, 3}. This is because
the channel estimates are better in antennas 0 and 1 since more pilot symbols are employed for these
antennas than for antennas 2 and 3. Thus, each pair of symbols makes use of one of the antennas for which
the receiver can obtain better channel estimates and another antenna for which the estimates are worse.
3.20.5.1.2
Multiplexing schemes
LTE supports closed-loop and open-loop MIMO transmission in the downlink using P = 2 or 4 antennas
and a number of multiplexing layers equal to υ = 1, 2, 3, or 4. A layer is a term used in LTE to denote the

910
CHAPTER 20 Applications of Array Signal Processing
different data streams to be transmitted simultaneously using spatial multiplexing. As a consequence, the
number of layers represents the multiplexing gain and cannot exceed the number of transmit antennas;
thus, υ ≤P. The number of layers is also referred to as the rank of the transmission. The mapping of
between codewords (i.e., an independently encoded data block) and layers is also speciﬁed in LTE. For
a transmission rank greater than 1, up to two codewords can be transmitted. In this case, each codeword
is assigned to each layer if υ = 2, one codeword is assigned to one layer and the other codeword is
split between the other two layers if υ = 3, and each codeword is mapped to a different pair of layers
if υ = 4. Multi-codeword transmission allows for the use of the computationally simpler MMSE-SIC
(Minimum Mean Square Error-Successive Interference Cancellation) detector, providing comparable
performance to the more complex ML detector applied to the single-codeword case, which on the other
hand enjoys an advantage in terms of ARQ ACK/NACK signaling.
The relation between the symbols at the antenna ports, y(p)(n), and the symbols in layer l, x(l)(n), is
⎡
⎢⎣
y(0)(n)
...
y(P−1)(n)
⎤
⎥⎦= W(n)
⎡
⎢⎣
x(0)(n)
...
x(υ−1)(n)
⎤
⎥⎦,
P = 1, 2, or 4,
P ≥υ = 1, 2, 3, or 4,
(20.58)
where W(n) is a P × υ precoding matrix. Next we describe the closed- and open-loop approaches to
forming this matrix.
Closed-loop multiplexing schemes: The precoding matrices belong to a codebook. The receiver selects
the best precoding matrix based on its current channel estimates and feeds back an index to the trans-
mitter. For the case of rank-1 transmission with 2 antennas, the precoders are
 1
1

,
 1
−1

,
 1
j

,
 1
−j

.
(20.59)
The elements of the precoders are limited to the QPSK alphabet {±1, ± j} to reduce computational
complexity at the UE by avoiding the use of complex multiplications. Moreover, there are no amplitude
differences between antennas because it is desired to use the maximum available power at each antenna.
These two properties are also valid for the other cases, with the caveat that with four antennas the
elements of the matrices can also belong to the 8-PSK alphabet: {±1, ± j, ( ±1 ± j)/
√
2}.
For the case of rank-2 transmission with 2 antennas, the precoders are
 1 0
0 1

,
1
√
2
 1
1
1 −1

,
1
√
2
1
j
1 −j

.
(20.60)
The codebook for four antenna ports is formed by 16 matrices, which are obtained from 16 generating
vectors, vk, whose components belong to the 8-PSK alphabet by applying the Houselholder matrix
deﬁnition: I −2vkvH
k . The precoders for ranks lower than four are obtained by a selected subset of the
columns of each matrix. This makes it straightforward to fulﬁll the nested property, whereby columns of
lower rank precoders are subsets of the columns of higher rank precoders, which considerably facilitates
the precoder evaluation at the UE. LTE admits both frequency-selective precoding, in which precoding

3.20.5 Wireless Communications
911
weights are selected independently for different sub-bands of bandwidth ranging from 360 kHz to
1.44 MHz, and also wideband precoding, where a single set of single precoding weights are applied to
the entire transmission band.
Note that rank-1 transmission amounts to beamforming. Besides the beamforming case, LTE also
allows for UE-speciﬁc beamforming, which is not based on the feedback of precoding-related informa-
tion, but on channel state information obtained by the eNodeB using for instance DOAs measured from
the uplink signals or exploiting reciprocity in TDD scenarios.
Open-loop multiplexing schemes: The same diversity schemes as described in Section 3.20.5.1.1 are
used for rank-1 open-loop communication. For higher ranks, the general approach is to employ layer
cycling together with precoder cycling. Layer cycling is implemented by means of CDD (Cyclic Delay
Diversity), and the net effect is to circularly change the order of the columns of the precoding matrix.
Speciﬁcally, this type of CDD is called long-delay CDD in LTE terminology. This means each layer is
transmitted using a different column of the precoding matrix at successive OFDM symbols. The precoder
cycling consists simply of changing the precoding matrix after each set of υ resource elements, that
is to say, when a complete circular shift of the current matrix has been done. The logic behind this
approach is that precoder cycling provides a new realization of SINRs across the layers every time the
precoding matrix is changed, and layer cycling makes each codeword experience an SINR that is the
average of the SINRs of the layers because each codeword ends up using all columns of the precoding
matrix.
In order to put the description above in formulas, we can consider for example the case of P = 4
antennasandυ = 3layers.Thedescriptionisalsovalidfortwoorfourlayerswithobviousmodiﬁcations.
The same relation as in (20.58) is valid with the replacement of W(n) with
W
 n
υ

mod 4

D(n)U,
(20.61)
where W(n) represents one of the 16 matrices previously mentioned, matrix D(n) applies CDD in the
frequency domain and U is the υ × υ DFT matrix:
U =
1
√
3
⎡
⎣
1
1
1
1 e−j2π/3
e−j4π/3
1 e−j4π/3
e−j8π/3
⎤
⎦.
(20.62)
The cyclic delay applied to the lth layer is equal to a fraction l/υ of the symbol duration, and then the
CDD matrix is
D(n) =
⎡
⎣
1
0
0
0 e−j2πn/3
0
0
0
e−j4πn/3
⎤
⎦.
(20.63)
The set of possible precoding matrices contains four elements (for any number of layers), and the index
(⌊n
υ ⌋mod 4) selects another matrix every time a given matrix has been used for υ symbols. The important

912
CHAPTER 20 Applications of Array Signal Processing
fact is that the combined effect of the CDD and the DFT matrices is
D(3m)U =
1
√
3
⎡
⎣
1
1
1
1 e−j2π/3
e−j4π/3
1 e−j4π/3
e−j8π/3
⎤
⎦,
D(3m + 1)U =
1
√
3
⎡
⎣
1
1
1
e−j2π/3
e−j4π/3
1
e−j4π/3
e−j8π/3
1
⎤
⎦,
(20.64)
D(3m + 2)U =
1
√
3
⎡
⎣
1
1
1
e−j4π/3
1 e−j2π/3
e−j8π/3
1 e−j4π/3
⎤
⎦,
which means that columns of the resulting matrix are shifted for successive symbols.
The case for two antennas is simpler because the precoding matrix W(n) is always the identity matrix
(so no precoder cycling is applied) and
D(n) =
 1
0
0 (−1)n

.
(20.65)
This implies that
D(2m)U =
1
√
2
1
1
1 −1

,
D(2m + 1)U =
1
√
2
 1
1
−1 1

,
(20.66)
which simply represents a swap of the columns between the two layers for consecutive symbols.
3.20.5.1.3
Multiple user MIMO (MU-MIMO)
The previous description is based on Release 8 of the LTE standard and has considered only Single-
User MIMO (SU-MIMO). That release includes a rather minimal MU-MIMO transmission scheme. It
is based on codebook feedback and uses the same codebooks as SU-MIMO. Actually, only the rank-1
precoders are employed because only one layer is utilized by each UE. The performance of this MU-
MIMO scheme is limited by the coarse codebook quantization and the lack of support for cross-talk
suppression at the UE. As a consequence, MU-MIMO only offers marginal gain with respect to SU-
MIMO. The shortcomings of this simple MU-MIMO approach are ﬁxed in the subsequent releases
[80–82]. The set of new features included in Release 10 of the standard has made it possible to reach
spectral efﬁciencies of 30 bits/s/Hz in the downlink and 15 bits/s/Hz in the uplink [83, Section 7.3].
Release 9 allows for beamforming for up to four UEs. The beamformers are constructed by exploit-
ing channel reciprocity. It also includes the option of rank-2 transmissions to two UEs. Release 10
(also known as LTE-A or LTE-Advanced) supports conﬁgurations with up to 8 × 8 MIMO with eight
transmission layers, and as a consequence the set of precoding codebooks has also been extended using
the dual-codebook approach. That is, the precoding matrix is obtained as the multiplication of two
matrices, W1 and W2, where W1 is a block diagonal matrix matching the spatial covariance matrix of

3.20.5 Wireless Communications
913
the dual-polarized antenna setup, and W2 is the antenna selection and cophasing matrix. The LTE-A
UEs have to provide feedback information for both W1 and W2. When only two or four antennas are
used at the eNodeB, W1 is the identity matrix and backwards compatibility with Releases 8 and 9 is
achieved. For the 8-transmit antenna conﬁguration, W1 is obtained from the coefﬁcients of the DFT.
An important contribution in LTE-A is the inclusion of Coordinated Multipoint transmission (CoMP),
whereby multiple eNodeBs can cooperate to determine the scheduling, transmission parameters, and
transmit antenna weights for a speciﬁc UE [84,85]. The objective is to reduce interference at the UEs,
making universal frequency reuse possible and, hence improving cell-edge throughput as well as average
sector throughput with little complexity increase at the receiver. Two major types of CoMP transmission
are identiﬁed for the downlink (DL) of LTE-A:
•
Coordinated beamforming/coordinated scheduling (CB/CS) refers to techniques that do not required
data sharing between cells. However, CSI may be shared among cells. This family of techniques
includes coordinated beamforming/scheduling, adaptive fractional frequency reuse, interference
alignment, PMI (Precoding Matrix Indicators) coordinations, etc.
•
Joint processing is characterized by the fact that data are shared, and it includes techniques such as
dynamic cell selection and joint transmission (network MIMO).
The CoMP concept can also be employed in the uplink by coordinating multiple cells to perform
joint reception of the transmitted signal at multiple receiving eNodeBs and/or by taking coordinated
scheduling decisions. Nevertheless, CoMP transmission/reception is an active area of research and
further studies are needed to reliably evaluate the gains of CoMP in LTE.
3.20.5.1.4
Uplink MIMO
In Release 8, only one antenna of the UE can be used for transmission, so it is possible to achieve
transmit diversity using an antenna selection mechanism, but single-user spatial multiplexing is not
feasible. However, the uplink (UL) can support MU-MIMO transparently with 2–6 UEs (although in
practice only two UEs are considered in order to limit receiver complexity). The number of UEs that can
share a resource block is determined by the number of orthogonal reference signals that can be assigned
to the UEs. The different reference signals are used by the eNodeB to estimate the channels of each
UE, from which a multiuser detector (e.g., using the MMSE criterion) is derived. In Release 10, spatial
multiplexingwith1,2,or4transmitantennasattheUEanduptofourlayersisintroduced.Open-loopand
closed-loop spatial multiplexing as well as transmit diversity are supported. Closed-loop multiplexing
relies on codebook-based precoding, and the codebooks are optimized to maintain a low PAPR.
To sum up, the evolution of MIMO techniques in the different releases of the standard is summarized
in Table 20.1.
3.20.5.2 Multiple antennas techniques in WiMAX
The IEEE 802.16m standard is the core technology for WiMAX Release 2 (WiMAX-2 in short), and it
contains the addition of several MIMO technologies to the ones included in IEEE 802.16e (which was
the basis of WiMAX Release 1) [86]. MIMO plays an essential role in WiMAX-2, as well as in LTE-A, in
ordertomeettheIMT-Advanced4Grequirements.AlthoughterminologiesintheIEEE802.16and3GPP
LTE standards differ and the comparison may be confusing, the MIMO techniques used in both WiMAX-
2 and LTE-A, while different in various details, share in general the same fundamental approaches.

914
CHAPTER 20 Applications of Array Signal Processing
Table 20.1 Evolution of the Support of MIMO Techniques in LTE
LTE (Rel-8)
LTE (Rel-9)
LTE-A (Rel-10)
Downlink
• Codebook-based
• Non-codebook-based
SU- & MU-MIMO
precoding for eight layers
• Transmit diversity
• Dual-stream beamforming
• Enhanced MU-MIMO
• Dedicated reference
• Inclusion of CoMP
signal-based beamforming
Uplink
• MU-MIMO
• Spatial multiplexing with
codebook-based precoding
• Antenna selection
• Transmit diversity
FIGURE 20.30
WiMAX DL MIMO architecture (as shown in [89]).
Therefore, rather than describing the details of MIMO techniques in WiMAX-2, for which an excellent
review can be found in [87, Ch.10], we will focus on the similarities between LTE-A and WiMAX (a
compared overview can be found in [88]), and comment on some speciﬁcs aspects of the latter.
Both 802.16m and LTE-A support MIMO implementations with the same sets of antennas: 2, 4,
or 8 transmit antennas and a minimum of 2 receive antennas in the DL; 1, 2, or 4 transmit antennas
and a minimum of 2 receive antennas in the UL. The two systems also specify schemes for: open-
loop transmit diversity, open- and closed-loop spatial multiplexing, and MU-MIMO both in the UL
and DL. The WiMAX downlink architecture is represented in Figure 20.30. For open-loop transmit
diversity, WiMAX employs SFBC encoding combined with precoder cycling, whereas LTE employs
either SFBC or SFBC-FSTD. As far as open-loop spatial multiplexing is concerned, both systems
propose precoder cycling, but WiMAX does not include layer permutation with CDD. Closed-loop
spatial multiplexing relies on codebook-based precoding, and WiMAX has three feedback mechanisms:
base mode, transformation mode, and differential mode.
Codebook adaptation is deﬁned in 802.16m, and it consists in changing the codeword distribution
according to long-term channel statistics. Each vector codeword of the rank-1 base codebook is linearly

3.20.5 Wireless Communications
915
transformed and normalized to create a codeword in the new codebook. As a result, more codewords are
steered towards the ideal beamformer vectors and the codebook quantization error is reduced. Moreover,
codebook adaptation is also useful in achieving robustness against calibration errors in the antenna array
and transceiver chains. The derivation of the adaptive precoding matrix is speciﬁc to the implementation
and is not included in the standard. The case where the columns of the precoding matrix are orthogonal
to each other is called unitary precoding. Otherwise, it is deﬁned as non-unitary precoding. Non-
unitary precoding is only allowed with closed-loop MU-MIMO. Advanced beamforming is also enabled
by this precoding mechanism. Besides the closed-loop MU-MIMO scheme, which is also present in
LTE, WiMAX-2 allows for open-loop MU-MIMO, where each terminal selects the preferred column
from a unitary matrix that has been preset for each frequency-domain resource. Each terminal reports
the channel quality indicator (not the spatial correlation matrix, which is the reason why the scheme
is considered to be open-loop), and the technique shows good performance with limited feedback
in uncorrelated and semi-correlated channels typically corresponding to urban areas with high user
density and no line-of-sight. A summary of the MIMO modes proposed for the downlink and uplink of
WiMAX-2 are summarized in Tables 20.2 and 20.3.
3.20.5.3 Multiple Antenna Techniques in IEEE 802.11
MIMO techniques play an essential role in the signiﬁcant increase (54–600 Mbits) in the maximum
data rate provided by the IEEE 802.11n amendment to the IEEE 802.11-2007 standard. The single
largest contributor to the rate increment comes from the use of multiple antennas, which has the effect
of a fourfold increase. A factor of 2 can be attributed to the widening of the channels from 20 MHz to
Table 20.2 Downlink MIMO Modes
Mode index
Description
MIMO Encoding Format
MIMO Precoding
0
Open-loop single-user
Alamouti encoding in
Non-adaptive
(transmit diversity)
space-frequency
1
Open-loop single-user
Transparent encoding
Non-adaptive
(spatial multiplexing)
2
Closed-loop single-user
Transparent encoding
Adaptive
(spatial multiplexing)
3
Open-loop multiple-user
Multi-layer encoding
Non-adaptive
(spatial multiplexing)
4
Closed-loop multiple-user
Multi-layer encoding
Adaptive
(spatial multiplexing)
5
Open-loop single-user
Conjugate data repetition
Non-adaptive
(transmit diversity)

916
CHAPTER 20 Applications of Array Signal Processing
Table 20.3 Uplink MIMO Modes
Mode index
Description
MIMO Encoding Format
MIMO Precoding
0
Open-loop single-user
Alamouti encoding in
Non-adaptive
(transmit diversity)
space-frequency
1
Open-loop single-user
Transparent encoding
Non-adaptive
(spatial multiplexing)
2
Closed-loop single-user
Transparent encoding
Adaptive
(spatial multiplexing)
3
Open-loop multiple-user
Transparent encoding
Non-adaptive
(collaborative spatial multiplexing)
4
Closed-loop multiple-user
Transparent encoding
Adaptive
(collaborative spatial multiplexing)
40 MHz; and the rest of the improvement (roughly about 40%) to reducing the overhead in the signal
[90]. IEEE 802.11a/g allowed only for a very basic exploitation of multiple antennas. Its method for
obtaining diversity was simple antenna selection, while IEEE 802.11n allows for the use of Space-Time
Block Codes (STBC), spatial multiplexing and transmit beamforming. Any number of transmit and
receive antennas with a maximum number of 4 at each side is permitted, and up to four data streams
can be multiplexed.
Two processing blocks are sequentially applied to the spatial streams to obtain the data streams to
be transmitted from each antenna [91,92]:
•
STBC encoder: Spreads constellation points from NSS spatial streams into NSTS space-time streams
using a space-time block code. The STBC encoder is used only when NSS < NSTS, otherwise it is
a transparent block. If NSS = 1 and NSTS = 2, the Alamouti code is employed; if NSS = 2 and
NSTS = 3, one spatial stream is encoded by the Alamouti approach and the other stream is directly
mapped to the third space-time stream; if NSS = 2 and NSTS = 4, two disjoint pairs of space-time
streams are obtained by applying the Alamouti code to each spatial stream; and ﬁnally if NSS = 3
and NSTS = 4, one spatial stream is coded with the Alamouti code and the other two streams are
directly mapped to the output. The cases for a single spatial stream NSS = 1 with three or four
antennas are handled through the use of spatial expansion, which is mentioned below.
•
Spatial mapper: Maps the NSTS space-time streams to the NTX antennas (where NTX ≥NSTS)
by multiplying the space-time streams by a matrix, which is then passed along to each transmit
chain. Different matrices can be used for different subcarriers. Some examples of spatial mapping
are presented below, but other alternatives are possible and the standard does not restricts the imple-
mentation to these instances.
– Direct mapping: Each space-time stream is directly assigned to each antenna (only possible
when NTX = NSTS), possibly after multiplication by a complex exponential in order to
implement CDD.

3.20.6 Biomedical
917
– Indirect mapping: The two sets of streams are related by a square unitary matrix such as the
Hadamard matrix or the Fourier matrix.
– Spatial expansion: The standard proposes several binary-valued (ones and zeros) matrices
covering the different combinations of the values of NTX and NSTS. The effect of these
matrices is simply to translate each of the NSTS streams to one or several antennas. For
instance, if NSTS = 1 and NTX = 3, the following matrix (vector, in this case) is proposed:
D = 1/
√
3[1 1 1]T , which implies that the same symbols are transmitted simultaneously
from the three antennas.
– Beamforming matrix: Represents any matrix that improves the reception based on some
knowledge of the channel between the transmitter and the receiver. Two mechanisms are
considered in the standard to obtain CSI at the transmit side. The ﬁrst is called implicit feed-
back, which relies on reciprocity in the TDD operation mode to estimate the channel based
on a reference signal transmitted by the device that will act as receiver in the subsequent
communication. In the second mechanism, denoted as explicit feedback, the receiver sends
to the transmitter either the measured channel response or a beamforming matrix that it
has computed based on the measured channel. In the latter case, there are two possibilities,
namely, to simply transmit the coefﬁcients of the beamforming matrix (called noncom-
pressed beamforming feedback matrix) or a set of angles and phases that parameterize that
matrix (called compressed beamforming feedback matrix).
As a ﬁnal remark, it is worth mentioning that a cyclic shift can also be applied to the signal in each
antenna to prevent unintentional beamforming. The shift can be inserted either in the frequency or in
the time domain (i.e., before or after the IDFT).
3.20.6 Biomedical
There is an immense interest in processing the electrical, magnetic and acoustic signals that originate
from physiological processes, and extracting information that is useful for diagnosis and treatment.
Examples of such signals include those obtained via electrocardiography, measurements of the elec-
trical behavior of the heart; electroencephalography and magnetoencephalography, which measure the
electrical and magnetic activity of the brain; electromyography, observations of electrical signals in
muscle tissue, and so on. In addition, active measurement approaches exist that collect the response of
the body to magnetic or acoustic stimulation, as in magnetic resonance or ultrasonic imaging systems.
Arrays of sensors are used in many of these applications, primarily for localizing the source of the
signals in passive measurement systems, or for non-invasively imaging the internal structure of the
body in active systems.
In this section, we will brieﬂy discuss three biomedical applications of array signal processing that
are widely employed in both clinical or research settings. These are by no means exhaustive; a notable
omission is magnetic resonance imaging (MRI), which uses a large array of coils to detect the precession
of molecules in response to applied external magnetic ﬁelds. However, these examples serve to illustrate
the important role array signal processing has in biomedicine.

918
CHAPTER 20 Applications of Array Signal Processing
3.20.6.1 Ultrasonic imaging
Ultrasonic arrays for biomedical imaging are in widespread clinical use today, most commonly for
monitoring fetal development and for real-time imaging of heart valve operation and related blood ﬂow.
Ultrasound imaging is relatively inexpensive compared with other imaging modalities, and the array and
associated equipment is relatively compact and portable. Ultrasonic images can achieve sub-millimeter
resolution, but the imaging process is more susceptible to noise and unpredictable propagation effects
than, say, MRI.
Ultrasound imaging is based on pulse-echo signal processing, much like an active radar. An array of
from many tens to a few hundred piezoelectric transducers transmits baseband signals with bandwidths
up to tens of MHz and then receives the resulting echoes. Broadband signals are usually employed for
imaging human tissue, while narrowband CW signals are employed for Doppler measurements of blood
ﬂow velocities. An ultrasonic array is relatively compact, with an aperture of 50 mm or less, and can be
condensed to ﬁt in a handheld wand that is manually placed on the body and oriented in some direction
of interest. The speed of sound in human tissue is approximately 1500 m/s, so the resulting wavelength
is typically much less than 1 mm. Consequently, near-ﬁeld modeling of the acoustic wavefronts is often
necessary. The array typically has a slight inward curve to create a larger “fan-beam” image.
Traditionally, ultrasonic imagers have employed delay-and-sum beamforming to focus both the
transmit and receive signals, although with improvements in computational power, systems are now
being designed with adaptive (e.g., MVDR) beamforming to improve resolution and eliminate artifacts
due to interference entering through sidelobes. An important difference compared to radar is the severe
range-dependent attenuation the ultrasonic signal undergoes—with signal intensity decreasing by a
factor of two at 5 MHz for approximately every cm of distance the signal travels. This necessitates the
use of gain compensation on receive and leads to low SNRs at longer ranges. As focus moves towards
higher frequencies for better resolution, the attenuation problem increases.
3.20.6.2 EEG and MEG signal processing
Electroencephalography (EEG) and magnetoencephalography (MEG) are widely used in both clinical
practice and research since they provide direct measurement of cerebral activity with much higher
temporal resolution than other non-invasive methods such as functional MRI (fMRI). The analysis
of EEG/MEG signals is used for detecting and diagnosing neurological disorders such as epileptic
seizures, monitoring brain activity during sleep or anesthesia, analyzing the extent of brain damage
due to stroke or traumatic injury, etc. Such signals are also currently being investigated as a tool for
brain-computer interface applications that would allow individuals with sensory-motor impairments
(e.g., a paraplegic) to control a wheelchair, prosthetic limb or a computer input device via focused
cognitive activity. Although EEG/MEG techniques have lower spatial resolution than, for example,
fMRI, relatively high-resolution techniques for locating sources of cerebral activity have been proposed
to cope with this issue.
To obtain high spatial precision, EEG/MEG localization requires a large array of sensors or electrodes
(an example of a typical EEG array is shown in Figure 20.31), which leads to a high-dimensional inverse
problem that in general does not have a unique solution. Thus, in practice, a “forward” propagation
model for the brain, skull and scalp is adopted, and one attempts to estimate the parameters of the
model corresponding to the source activity. A common approach is to model the signal source in a

3.20.6 Biomedical
919
FIGURE 20.31
Cap with electrodes for collecting EEG data.
small region of the brain as originating from an equivalent current dipole, treating the dipole location,
the orientation and magnitude of the dipole moment as dipole parameters to be estimated. Figure 20.32
depicts the equivalent dipole model, where the charge difference along a neuron (or neuron cluster)
causes a ﬂow of current whose resulting electric or magnetic ﬁeld can be measured by a sensor. While
EEG caps like the one in Figure 20.31 are used to place the sensor as close to the brain as possible, there
is increasing interest in and use of intracranial EEG measurements, or electrocorticography (ECoG),
where the electrode is placed beneath the skull immediately adjacent to the neural area of interest. ECoG
signals avoid the attenuation of the skull and scalp and provide a much higher SNR, but at the expensive
of an invasive implantation. In the next section, we describe the mathematical model that results from the
equivalent dipole assumption to illustrate its connection with other array signal processing applications.
3.20.6.2.1
Uniﬁed dipole model for EEG/MEG/ECoG measurements
Assume a current dipole located at position r ∈R3×1 and an electric or magnetic sensor located at
s ∈R3×1. In the following, we derive expressions for the electric or magnetic ﬁeld y(t) at s due to the
dipole at r for the three measurement modalities EEG, MEG, and ECoG. We will see that all three lead
to expressions with a similar structure that allows us to formulate a unifying model for the output of
arrays of such sensors.

920
CHAPTER 20 Applications of Array Signal Processing
skin
skull
brain
equivalent
dipole
propagating
currents
EEG or MEG sensor
FIGURE 20.32
Equivalent current dipole model for EEG measurements.
EEG: The electric potential at s caused by a current density JS at location r under a quasistatic
assumption (i.e., setting all time derivatives in Maxwell’s equations equal to zero) can be expressed as
y(t) = −
1
4πσ

V
∇JS(r, t)
∥s −r∥dr,
(20.67)
where ∇is the divergence operator and V is the volume of interest. A current dipole can be idealized
as a source and sink with equal magnitude, denoted by I0(t), and separated by a very small distance d,
which leads to
∇JS = −I0(t)[δ(s −r+) −δ(s −r−)],
(20.68)
where δ is the Dirac delta function, and r+ (r−) is the source (sink) location. The dipole location r is
assumed to be at the midpoint between r+ and r−, and the orientation of the dipole is in the direction
of d = r+ −r−= 1
2(r+ −r) = 1
2(r −r−). Substituting (20.68) into (20.67), the potential generated
by the ideal dipole source becomes
y(t) =
I0(t)
4πσ∥s −r+∥−
I0(t)
4πσ∥s −r−∥.
(20.69)
Assuming that ∥s −r+∥≫d, and similarly for r−, then
1
∥s −r+∥≈
1
∥s −r∥+ (s −r)T d
2∥s −r∥3 ,
1
∥s −r−∥≈
1
∥s −r∥−(s −r)T d
2∥s −r∥3 .

3.20.6 Biomedical
921
Substituting this approximation into (20.69), the potential received at r becomes
y(t) = I0(t)
4πσ

1
∥s −r∥+ (s −r)T d
2∥s −r∥3 −

1
∥s −r∥−(s −r)T d
2∥s −r∥3

=
1
4πσ
(s −r)T
∥s −r∥3 m(t),
(20.70)
where the dipole moment is deﬁned as m(t) = dI0(t). In the sequel, we will write m(t) = φs(t), where
φ = d/∥d∥is the unit-magnitude dipole orientation, and s(t) = I0(t)∥d∥is the moment magnitude.
MEG: Extracranial magnetic ﬁelds produced by neuronal activity within the brain can be calculated
using Biot-Savart’s law. A dipole source at r with dipole moment m(t) will generate a magnetic ﬁeld
y(t) at sensor location s given by
y(t) = μ0(m(t) × (s −r))T
4π∥s −r∥3
t = μ0((s −r) × t)T
4π∥s −r∥3
m(t),
(20.71)
where × denotes the vector cross product and t is a unit vector deﬁning the orientation of the sensor. As
in the case of EEG, we will write m(t) = φs(t) with φ deﬁning the orientation of the dipole moment.
Note that a dipole inside a spherically symmetric conductor with φ aligned with the sphere’s radius will
produce no external magnetic ﬁeld. Consequently, for MEG applications, the orientation φ (and hence
the moment m(t)) is often expressed using only two rather than three coordinates.
ECoG: More involved models have been developed for ECoG settings due to the presence of local
currents and higher SNR. For a sensor inside the skull on the surface of the brain at position s, the
measured potential y(t) due to a dipole source at r with moment m(t) in a homogeneous conducting
sphere is given by
y(t) =
1
4πσ

2r −s
rd3
+
1
∥r∥2rd

r +
r∥s∥cos θ −∥r∥s
∥r∥+ rd −∥s∥cos θ
T
m(t),
(20.72)
where σ is the conductivity value for the brain, θ denotes the angle between r and s and rd = ∥r −s∥.
General multi-source multi-sensor model: In all three cases discussed above, the equation for the
electric or magnetic ﬁeld has the same general form. In particular, for an array of M sensors at positions
si, i = 1, . . ., M, the ﬁeld can be represented as
yi(t) = g(si, r)T m(t),
(20.73)
where the gain vector depends on which measurement system is employed:
EEG:
g(si, r) =
1
4πσ
si −r
∥si −r∥3 ,
(20.74)
MEG:
g(si, r) = μ0(si −r) × ti
4π∥si −r∥3 ,
(20.75)
ECoG:
g(si, r) =
1
4πσ
 
2r −si
r3
d,i
+
1
∥r∥2rd,i

r +
r∥si∥cos θi −∥r∥si
∥r∥+ rd,i −∥si∥cos θi
!
,
(20.76)

922
CHAPTER 20 Applications of Array Signal Processing
where all variables are as deﬁned above, with the subscript i referencing sensor i. Thus, for all three
models, stacking the outputs of the M sensors together in the vector y(t) yields the same general equation:
y(t) =
⎡
⎢⎣
gT (s1, r)
...
gT (sM, r)
⎤
⎥⎦m(t) = G(r)m(t) = a(r, φ)s(t),
(20.77)
where G(r) is M × 3 (or possibly M × 2 in the case of MEG data), and where the steering vector for
the source depends on its location and dipole orientation:
a(r, φ) = G(r)φ.
(20.78)
The steering vector model in (20.78) has the same form as in RF applications with diversely polarized
signals. Finally, augmenting the model with the superposition of N sources as well as background
interference n(t), we end up with the standard array processing equation:
y(t) =

a(r1, φ1) · · · a(rN, φN)
	
⎡
⎢⎣
s1(t)
...
sN(t)
⎤
⎥⎦+ n(t) = A(θ)s(t) + n(t),
(20.79)
where the vector θ contains the source location and dipole orientation parameters.
The fact that the steering or array manifold vectors depend linearly on the dipole orientations, and
that these vectors are assumed to satisfy φT
k φk = 1, lead to special types of solutions when estimating
the parameters. For example, a direct implementation of the MUSIC algorithm leads to
ˆr, ˆφ = arg min
r,φ
φT GT (r)EnET
n G(r)φ
φT GT(r)G(r)φ
s.t. φT φ = 1,
(20.80)
where En are the noise subspace eigenvectors of the covariance of y(t). It is straightforward to show that
minimizing the MUSIC criterion is equivalent to solving the following generalized eigenvalue problem
as a function of r:
ˆr = arg min
r λmin(r),
(20.81)
GT (ˆr)EnET
n G(ˆr) ˆφ = λmin(ˆr)GT (ˆr)G(ˆr) ˆφ,
(20.82)
where λmin(r) is the smallest generalized eigenvalue for a given r. The position estimates ˆr are found
by searching for the value of r for which λmin(r) is minimized, and the dipole orientation estimate is
then given by the generalized eigenvector associated with λmin(ˆr).
3.20.6.2.2
Interference mitigation
For EEG and MEG measurements, where the sensors are separated from the brain by the skull and scalp,
the signals of interest are very weak, and embedded in strong, spatially correlated noise and interference
due primarily to background brain activity not related to the stimulus of interest. If standard source

3.20.6 Biomedical
923
localization algorithms are applied without some attempt at mitigating this interference, the results are
typically very poor. A common strategy in such situations is to design experiments with dual conditions,
one (control state) prior to application of the stimulus and one (activity state) after the stimulus has
been applied. In principle, the control state data will contain only background interference and sensor
noise, while the activity state data will contain statistically similar noise and interference as well as the
event-related signals. Prewhitening approaches are typically applied in dual-condition experiments like
these. In these approaches, the control state data are ﬁrst used to estimate the spatial covariance matrix
of the interference plus noise using, for example, the following sample average:
RC = 1
nC
nC

t=1
yC(t)yT
C(t),
(20.83)
where nC is the number of control state samples. The activity state data, yA(t), is then prewhitened in
an attempt to eliminate the inﬂuence of the interference and noise as follows:
y′
A(t) = R−1/2
C
yA(t).
(20.84)
A drawback to the use of prewhitening is that it requires that the spatial and temporal statistics of
the interference and noise during the control state be identical to those during the activity state. If the
assumption of stationarity between these two states is violated, then methods based on prewhitening
can suffer a signiﬁcant performance degradation. An alternative is to use projection-based methods that
estimate a spatial-only subspace in which the bulk of the interference energy lies during the control
state, and then project away this subspace in the activity state data. This method eliminates the need
for temporal stationarity, and relies only on the assumption that the locations of the interference in the
controlandactivitystatesremainunchanged.Thisisareasonableassumptionsinceany“new”sourcethat
appears during the activity state is considered to be related to the stimulus, and is thus a source of interest.
As an example, we present here the results of an experimental study with real EEG data. Experiments
with an auditory stimulus applied to the left ear were conducted with a single human subject to elicit
auditory-evoked potentials. MUSIC and LCMV were applied to the resulting data using both prewhiten-
ing (PW) and the projection (NP) technique and assuming the number of sources was one. Figures 20.33
and 20.34 show the spatial spectra of the four algorithm combinations. The projection-based methods
provide an activity map that closely corresponds to what one would expect, with energy conﬁned to the
auditory cortex. On the other hand, the prewhitening-based methods contain a number of apparently
unrelated artifacts, and the PW-LCMV method does not even show any energy near the auditory cortex.
3.20.6.3 Multi-sensor extracellular probes
Direct measurement of neural action potentials (APs) using electrodes inserted directly into biological
tissue has become an important neurological research and diagnostic tool. The goal is to record the
APs of individual neurons, often referred to as “single-unit activity,” in order to obtain a more precise
view of the underlying neurophysiology. Information from these recordings are potentially useful in the
development of artiﬁcial prostheses and in the diagnosis and treatment of paralysis and brain disorders
such as epilepsy and memory loss. Even though the electrodes are small and can be inserted with high
accuracy to target a speciﬁc location, they will typically record the superposition of the activity from

924
CHAPTER 20 Applications of Array Signal Processing
FIGURE 20.33
Spatial spectra of four algorithm combinations using experimental data (top view).
FIGURE 20.34
Same as previous ﬁgure (side view).

3.20.6 Biomedical
925
FIGURE 20.35
Automated procedures for AP sorting.
several neurons. The process of separating out the single-unit activity of individual neurons from the
multi-unit activity in the noisy electrode measurements is often referred to as AP or “spike” sorting.
In practice, manual sorting of APs in large volumes of experimental data is prohibitively time-
consuming,andautomatedproceduresforAPsortinghavebecomeessential.AsdepictedinFigure 20.35,
an automated AP sorting algorithm can be divided into three main steps: (1) AP detection and time align-
ment: determining the locations of the APs in the electrode time series and arranging the isolated AP
waveforms so that they “line up” in time, (2) feature extraction: extracting a low-dimensional set of
parameters for each detected AP that can be used to discriminate between different sources, and (3) clus-
tering: grouping the extracted features into clusters in order to associate them with individual neurons.
The feature extraction step is crucial since it reduces the effect of noise and removes redundant informa-
tion in the input data so that clustering algorithms can work efﬁciently. The three most common feature
categories discussed in the literature are: (1) AP shape-related features, such as AP height, width, peak-
to-peak amplitude, inter-AP interval, and ﬁrst-order derivative, (2) wavelet coefﬁcients, and (3) principal
components (PCs). One common characteristic of these features is that they only capture “temporal”
information since they are obtained by processing single-sensor measurements. However, AP sorting
based only on temporal features is challenging since neurons with similar geometries located at roughly
equal distances to the electrode can generate very similar AP waveforms and therefore similar features.
To overcome this problem, multi-sensor extracellular probes (e.g., tetrodes) that record a time-aligned
multi-channel data set have been suggested. The simplest way to use the data from multi-sensor probes
is to apply standard feature extraction techniques to all of the channels individually, and then combine
all the extracted features as inputs for clustering. Other approaches use the availability of spatially
distinct channel measurements to obtain neuron location estimates or independent components as feature
vectors for clustering. Independent component analysis (ICA) is a computational method for separating a
multivariate signal into additive subcomponents. While ICA can potentially resolve overlapping spikes,

926
CHAPTER 20 Applications of Array Signal Processing
it requires strong assumptions regarding the non-Gaussianity and independence of the APs, and a
separate feature extraction step is still required to identify the source of the recovered AP waveform.
Matched subspace (MS) techniques attempt to detect the presence of a signal that lies in an a priori
unknown low-dimensional subspace of the data. Unlike multi-sensor principal component analysis and
algorithms based on location estimates, which respectively allow only temporal or spatial information
to be extracted, the MS approach provides a joint spatio-temporal feature vector that is more effective
for differentiating between individual neurons. Furthermore, the spatial information obtained by MS
techniques is achieved without the need for a forward propagation model as required by location-based
methods.
3.20.6.3.1
Data model
Assume that the APs have been accurately detected in a previous step using existing approaches. A block
of samples around each detected AP peak is isolated, and it is time-aligned with data blocks obtained for
other detected APs. Assuming M electrodes and N samples per block, the data for the ith detected AP will
consist of an M × N matrix Yi, which is referred to as an AP “bundle.” Assuming that each bundle con-
sists of an AP from a single neuron, and assuming that the AP signal results in an instantaneous mixture
at the electrode array (i.e., a rank-one signal component), an appropriate mathematical model for Yi is:
Yi = Si + Wi = aivT
i + Wi,
(20.85)
where Si ∈RM×N represents the noise-free multi-sensor signal corresponding to the AP, Wi is com-
posed of zero-mean background neural and sensor noise, ai ∈RM×1 is the spatial signature of the target
neuron, and vi ∈RN×1 corresponds to the sampled AP waveform.
By vectorizing the data matrix, we obtain
yi = si + wi = vi ⊗ai + wi
= ci ⊗ai + wi
(20.86)
= ( ⊗ai)ci + wi,
(20.87)
where ⊗denotes the Kronecker product and yi, si, and wi are M N × 1 vectors formed from Yi, Si,
and Wi, respectively. The term vi = ci models the AP in the absence of any speciﬁc information
about the waveform, with matrix  ∈RN×p (p ≤N) representing a chosen orthonormal basis and
c ∈Rp×1 representing the corresponding coefﬁcient vector. Modeling the AP signal in this way not
only provides the possibility of a compact representation for the AP but also eliminates the need for AP
templates, which enables unsupervised spike sorting. Although  can be any orthonormal basis, one
with a compact support such as the wavelet basis is preferred in general since APs tend to be pulse-like.
3.20.6.3.2
Multi-sensor feature extraction
In the discussion that follows, we brieﬂy describe several popular algorithms for feature extraction from
a given M N × 1 AP bundle yi. In some cases, the methods either assume a single sensor (M = 1) or
they operate on each sensor independently. We will use the notation y(k)
i
= yi(k : M : M(N −1) + k)
to represent the data from the kth sensor, where the indexing k : M : M(N −1) + k indicates we select
every Mth sample from yi starting with sample k. The variable p will be used to denote the dimension
of the extracted feature vector.

3.20.6 Biomedical
927
Discrete wavelet transform: The wavelet transform is a popular choice for feature extraction in the
spike sorting application since it offers simultaneous interpretation of the signal in both time and scale
(frequency), which allows local, transient or intermittent components to be elucidated. It has advantages
over the traditional Fourier transform in analyzing physical signals since it can provide a compact signal
representation in both the time and scale domains. The discrete wavelet transform (DWT) decomposes
the data from a single sensor as follows:
y(k)
i
= wc(k)
i
,
(20.88)
where w ∈RN×N is a basis matrix that deﬁnes the DWT, and c(k)
i
∈RN×1 represents the DWT
coefﬁcient vector. The DWT basis is typically assumed to be orthonormal, so the coefﬁcient vector is
found by simply computing c(k)
i
= T
wy(k)
i
. The feature vector ˆc(k)
i
∈Rp×1 is determined by choosing
a subset of p of the coefﬁcients in the full DWT vector c(k)
i
. The choice of which p coefﬁcients to use
can in principle be different for each sensor k, but must be the same for each AP bundle. For example,
feature reduction for the DWT can be achieved by selecting the p coefﬁcients that have the largest
average magnitudes. Once a reduced-dimension set of features is chosen for each sensor, the complete
feature vector is formed by stacking them all together:
ˆcw = vec

ˆc(1)
w
· · · ˆc(m)
w

.
(20.89)
Principal component analysis: A difﬁculty associated with the DWT approach is there is no systematic
way to choose the wavelet basis so that it is somehow optimized for the signals at hand. Principal
component analysis (PCA) addresses this issue by calculating a data-dependent basis that corresponds
to the principle subspace where most of the signal energy resides. This is most commonly achieved by
performing the singular value decomposition (SVD) on a subset of n > p of the AP bundles
UkkVT
k =

y(k)
i1 y(k)
i2
. . . y(k)
in

,
(20.90)
where i1, i2, . . ., in are the indices corresponding to the n AP bundles chosen for the analysis. The PCA
basis (k)
p
∈RN×p is then taken to be the ﬁrst p columns of Uk, and the PCA feature vector (sometimes
referred to as the “score” vector) is calculated as ˆc(k)
i
= (k)T
p
y(k)
i
. In most applications of PCA to this
problem, p is chosen to be between two to three. Alternatively, a single basis for all k can be found by
including AP bundles from all sensors in the SVD of (20.90). As in the DWT approach, once features
are extracted for each k, the complete feature vector is found by stacking them together as in (20.89).
Matched Subspace Detector: The Matched Subspace Detector (MSD) can be thought of as a general-
ization of the well-known matched ﬁlter from signal processing, where a noisy signal yi is correlated
with a parameterized version of the signal of interest s to produce the output sT yi. The parameters are
chosen as those that maximize the resulting correlation. The single-sensor versions of the DWT and
PCA algorithms described in the previous section, where s = c, can be thought of as implementing a
simple matched ﬁlter:
ˆci = arg max
c
∥sT yi∥2 = arg max
c
∥cT T yi∥2
s.t. ∥c∥= ∥yi∥= αi,
(20.91)

928
CHAPTER 20 Applications of Array Signal Processing
where the constraint on c is used to maintain energy equivalence. The solution to (20.91) is the same as
that given earlier for DWT and PCA: ˆci = T yi.
The general MSD approach can be viewed as a natural multi-sensor extension of the single-sensor
DWTorPCAapproaches. Insteadofthesingle-sensorparameterization s = c,themulti-sensorparam-
eterization in (20.87) is used. In particular, MSD solves the following generalized version of (20.91):
ˆai, ˆci = arg max
a,c
"""sT yi
"""
2
= arg max
a,c
"""(c ⊗a)T yi
"""
2
s.t. ∥a∥= 1, ∥c∥= ∥yi∥= αi,
(20.92)
where the constraints match those used in the model to ensure identiﬁability. It is straightforward to
ﬁnd a closed form solution for both ˆai, ˆci.
The MSD algorithm can be used in conjunction with either the DWT or PCA, or any other choice
of the temporal basis matrix . The number of features produced by the MSD algorithm will be the M
spatial features from the elements of ˆai, plus however many temporal features are provided by ˆci, which
in turn depends on the dimension of . For the case of PCA, where  ∈RN×p and typically p ≪N, the
temporal feature vector ˆci will have p elements. For the DWT, where  is N ×N, ˆci will have N elements.
Note that in this case, ˆai can be found from the SVD of X′
i rather than X′
i, since both matrices have the
same set of left singular vectors. Whether the total number of space-time features obtained by MSD is
M + N or M + P, it is often desirable to reduce the number of features to a more manageable number.
3.20.7 Sonar
In the context of naval warfare, sonar is used to detect, locate, track and identify surface and submerged
vehicles. This is one of the classical early applications of digital array signal processing. Since required
bandwidths are often small and operating frequencies are low (10s of Hz to about 30 kHz) due to
propagation limitations at higher frequencies in the ocean environment, corresponding sample and data
rates are low enough to have been accommodated by ADCs and signal processing computers available
in the 1970s and 1980s. The well funded military applications spurred rapid development in that era, and
the transition from analog to digital systems enabled signiﬁcant capability enhancements and increased
processing complexity. Many of the classical array processing and statistically optimal beamforming
algorithms were ﬁrst demonstrated in sonar applications.
We will address two major classes of sonar: active and passive. Active sonar has much in common
with radar systems in that a pulse, or sequence of pulses, is transmitted and the return echo signal is
analyzed to detect vehicle range, direction, and range rate (radial velocity). This can be viewed as an
non-cooperative digital wireless communications problem where the transmitted pulse corresponds to
communications symbol, and two-way propagation effects including reﬂection from the target corre-
spond to the communications channel.
Passivesonarisa“listenonly”modeusedwhenstealthyoperationisimportantsoasnottorevealone’s
own position with a transmitted pulse. Acoustic radiation is detected from the target’s turning propeller,
internal machinery, occupants, or ﬂow turbulence as it moves through the water. Passive systems can
typically estimate target direction, and can classify the source as to speed, vehicle type, or even speciﬁc
hull number by comparing the signal spectrum to previously obtained acoustic signature data bases.

3.20.7 Sonar
929
The primary use of sensor and transmitting arrays in sonar is to exploit spatial information in the
channel, including estimating directions of arrival, improving gain, and mitigating against noise and
other interfering sources. We will also discuss in Section 3.20.7.3 how array processing combined with
good acoustic propagation models can be used in passive sonar to estimate range and depth at a distance,
without access to two-way propagation time-of-ﬂight information.
3.20.7.1 Sonar arrays
The sensors used in sonar arrays are hydrophones that act as underwater microphones and acoustic
drivers. Most hydrophones are constructed of ceramic piezoelectric transducer material, which operates
effectively over the range of a few Hz to tens of kHz. In active sonar the same hydrophone elements
are used for both transmit and receive. The total instantaneous array output power for long range sonar
systems can be many tens of kilowatts. At very low frequencies some systems use electromagnetic lin-
ear motors (like speaker driver coils) or hydraulic actuators. Infrasonic pulses have also been generated
using explosive charges.
Depending on the intended application and the supporting platform, sonar arrays are found in a variety
of physical forms. Spherical or cylindrical arrays as seen in Figure 20.36 are housed in the bulbous bow
protrusions below the water line of many military surface ships, and encased in the streamlined bow of
submarines. These typically operate in the 1–6 kHz range and are capable of steering pencil beams in
both azimuth and depression angle. An example of a spherical array is the US Navy AN/BSY-2 sonar
on the Sea Wolf submarine.
FIGURE 20.36
An illustration of the spherical array in the Virginia III class of submarines.
Credit: Defense Industry Daily.

930
CHAPTER 20 Applications of Array Signal Processing
Conformal arrays use a thinly layered grid of hydrophones mounted on the nose or sides of vessels so
as to blend smoothly with the contours of the hull design. Though this may be a less than ideal geometry
for acoustic beamforming, it has the beneﬁt of maintaining a streamlined structure for reduced drag and
ﬂow noise turbulence while allowing a larger aperture than is practical with a spherical array.
Long tubular towed array lines are pulled behind surface ships, submarines, and barges. Many
hydrophones are spaced regularly inside a garden-hose-like tube that can be thousands of feet long.
Depth is controlled either by adjusting the payout of the tow cable, or with an actively controlled
tow body at the end of the array or at the tow cable attachment point. This enables steering to, and
maintaining a desired depth (see Figure 20.37). Because of their length, towed arrays offer very large
apertures for increased bearing resolution, narrow beams, high sensitivity due to many sensors and
separation from ship self noise, and lower frequency operation as compared to hull mounted arrays.
One drawback with the towed array is its one-dimensional linear geometry which leads to annularly
symmetric (donut shaped) formed beampatterns. This yields no directivity in the vertical dimension,
and a left-right ambiguity that requires the support ship to make turn maneuvers to resolve. The
low frequency, long range, barge-towed US Navy SURTASS system is an example of a towed array
sonar.
When mobility is essential or when submarine detection is needed at the far perimeter of the sonar
reach from a naval battle group, then helicopter-borne dipping sonar is highly effective. A sonar array is
reeled down to great depth from a hovering helicopter. Figure 20.38 shows a 1980s era system that is still
in service, the US Navy AN/AQS-13 sonar. More recent developments like the US Navy AN/AQS-22
ALFS dipping sonar include extendable hydrophone support arms which increase aperture and permit
lower frequency operation.
Modern torpedoes like the US Navy Mk 48 ADCAP shown in Figure 20.39 are quite autonomous.
They are able to search out, detect, track, and target surface ships and submarines without the necessity
FIGURE 20.37
A French type F70 frigate (the Motte-Picquet) ﬁtted with VDS (Variable Depth Sonar) type DUBV43 or
DUBV43C towed array sonars. The array reeling mechanism and tow depth control body can be seen.
Credit: Used by permission, NetMarine. Photographer: Jean-Michel Roche.

3.20.7 Sonar
931
FIGURE 20.38
A US Navy 1980s era Sikorsky SH-3H Sea King helicopter lowers its AN/AQS-13 dipping sonar.
Credit: US DefenseImagery (www.defenseimagery.mil), PH1 R.O. Overholt, USN.
FIGURE 20.39
Maintenance on an early development model of the US Navy Mk 48 ADCAP torpedo. The sonar hydrophone
array lies behind the rubber shielded ﬂat front nose plate.
Credit: US DefenseImagery ( www.defenseimagery.mil).
of guidance and control from the launching boat. These tasks are performed using a nose-mounted
planar array and on-board signal processing. The Mk 48 array is a nose-mounted grid of piezoelectric
hydrophones which steer pencil beams for detection and direction ﬁnding.

932
CHAPTER 20 Applications of Array Signal Processing
Other sonar arrays are not mobile, but are permanently moored to the ocean ﬂoor. We will discuss
in Section 3.20.7.3 how a ﬁxed vertical line array can be used in matched ﬁeld processing to estimate
source range and depth using only passive observations. There are a number of very large and widely
dispersed bottom-afﬁxed passive sensor arrays used for surveillance in strategic ocean regions, including
the US Navy’s SOSUS network.
3.20.7.2 The undersea acoustic channel
Effective sonar signal processing requires an understanding of the challenging characteristics of sound
propagation in an the ocean environment. In many ways sonar propagation is more complex and variable
than the radio frequency channel encountered in wireless communications, radio astronomy, or radar.
Fortunately though, propagation in the deep ocean is well understood, can be modeled accurately, and
coherent processing across a large sensor array is possible even for distant sources.
3.20.7.2.1
Propagation models
Sound velocity in salt water is nominally 5000 ft per second, but this varies signiﬁcantly with depth,
sea temperature, and local salinity. Figure 20.40 illustrates a representative depth-dependent sound
velocity proﬁle c(z) and the resulting ray propagation characteristics. The increasing velocity near the
sea ﬂoor is due to greatly increased pressure in the deep isothermal layer below about 3000 ft. Velocity
also increases as depth decreases between the deep sound channel and the surface duct due to rising
temperature as depth decreases in the main thermocline layer. The cross-over between these two effects
leads to a velocity minimum that focuses acoustic energy in the stable deep sound channel which can
propagate great distances and maintain coherency across the ray paths.
Propagation effects near the surface are much more variable and depend on diurnal heating and
cooling, surface mixing due to wind and wave action, latitude, and formation of seasonal thermocline
layers. A relatively shallow surface layer duct often forms which traps energy near the surface, allowing
sonar propagation and detection with shallow arrays. This may be the only possibility if the source also
lies in the duct. However, due to sea roughness and losses at the sea-air interface, transmission loss is
greater in this layer and rays die out more rapidly than in the deep sound channel.
Another important propagation effect not illustrated in Figure 20.40 is the convergence zone. Rays
of higher angular incidence (at the sensor array or source) will periodically extend beyond the deep
sound channel and intersect the surface. This forms a ring on the surface at a ﬁxed range from the sonar
array of convergent ray paths that enable surface ship detection at great distances. The radial separation
between the successive convergence zones is typically on the order or 20 miles.
Optimal placement of sensor arrays (in depth), identifying convergence zones, and estimating range
require speciﬁc knowledge of c(z) to enable numerical ray path modeling of the sound channel. This
information is obtained to great depths by bathythermograph and velocimeter sounders which are
dropped overboard from surface ships or non-retrievably deployed from helicopters or other naval sup-
port ﬁxed wing aircraft (e.g., the PC-3 Orion). When there are multiple vessels in the operational theater
it is possible to collect these environmental data periodically over a large area. In situ measurements
are supplemented with historical data, seasonal and weather models, and ocean bottom topography data
to provide quite accurate sound velocity proﬁle results. These enable useful acoustic channel ray trace
modeling.

3.20.7 Sonar
933
z
c(z)
zs
FIGURE 20.40
Acoustic propagation model for a horizontally stratiﬁed ocean. The convex-to-the left sound velocity function
c(z) forms long distance propagating modes (or acoustic ray paths) in the deep sound channel. The complex
wavefront seen at the hydrophone array depends on source depth z and range, enabling estimation of these
source parameters using MFP.
3.20.7.2.2
Transmission loss
Signal loss in the undersea acoustic channel is due to physical wavefront spreading, volume absorption,
and leakage and scattering at the surface and bottom. One would expect near-ﬁeld propagation to follow
a spherical spreading law with loss proportional to 1/r2, and long distance propagation conﬁned by the
ocean surface and sea bottom to a planar disc to have cylindrical spreading loss proportional to 1/r,
where r is range to the source. However extensive ﬁeld measurements suggest that due to scattering
and leakage, spherical spreading with 1/r2 loss is a better match over a wide range of conditions.
A commonly used model for sonar transmission loss in dB is
TL ≈(20 log10 r) + αr × 10−3,
(20.93)
α = 16π2
3ρc3

μs + 3
4μv

f 2,
(20.94)

934
CHAPTER 20 Applications of Array Signal Processing
where α is deﬁned in units of decibels loss per thousand yards, r is (following sonar convention) in yards,
and f is frequency in Hz. The ﬁrst term in (20.93) is due to spherical spreading. Other parameters for
pure distilled water are density ρ ≈1 gm/cm3, sound velocity c ≈1.5×105 cm/s, shear viscosity μs ≈
0.01 poises, and volume viscosity μv ≈0.0281 poises. Below about 100 Hz the effective α in sea water
increases (as compared to distilled water) by a factor of 30 due primarily to dissolved magnesium sulfate.
The fact that attenuation in dB is proportional to f 2 suggests that for long range detection it will
be highly advantageous to use low frequencies. This is born out in practice where short range and
targeting sonars with small arrays typically operate at tens of kHz, medium range hull mounted arrays
and helicopter dipping sonars are at 1–6 kHz, and long range towed array sonars cover 10 Hz to a
few 100 Hz. Even at low frequencies, spreading losses are signiﬁcant at long ranges so in order to put
sufﬁcient energy into the water, active sonar systems typically use very long transmit pulses on the order
of several seconds. Fortunately the sound channel is stable over such long pulse periods and coherent
matched ﬁlter detection processing of echoes is possible.
3.20.7.2.3
Noise and reverberation
Sonar systems must detect weak signals in an inherently very noisy environment. Noise sources are
many and varied, but we will mention approximate average levels for some signiﬁcant sources in deep
water conditions.
•
Between 1 Hz and 10 Hz there are a variety of sources that contribute to an average level of approx-
imately 105 dB rel 1 µPa at 1 Hz, which declines with a slope of −30 dB per decade of frequency
increase.
•
Between about 10 Hz and 150 Hz, the dominant source is mechanical and turbulence noise from
distant surface shipping. Acoustic levels range from 60 to 85 dB rel 1 µPa for light to heavy shipping
trafﬁc conditions, respectively.
•
Between about 100 Hz and 100 kHz The dominant source is surface noise from wind and wave
action. Levels decline with increased frequency with a slope of about −20 dB per decade. At 1 kHz
surface noise levels range from 44 to 70 dB rel 1 µPa for sea state 0–6, respectively.
Additional external noise sources include biologics such as shrimp (one of the loudest) and marine
mammals. Self-generated noise from the platform vehicle is of course very local and potentially strong.
It includes ﬂow noise due to turbulence across the hydrophone surfaces for a moving platform, and
propulsion, machinery and other noise associated with the support vehicle.
Flow noise is very local to each hydrophone and is thus well modeled as statistically independent
per sensor, and often i.i.d. Surface sea state noise is typically quite widespread and can often be approx-
imately modeled as isotropic within a horizontal plane containing the array. Shipping noise can be
directional (spatially colored) since it is concentrated in well traveled shipping lanes. Biologic sources
include very direction-dependent and distant marine mammals and more local swarms of shrimp-like
noise makers. Beamforming algorithms which place nulls on the nearby directional noise sources can
be very effective in improving SNR in this environment.
Detection processing in active sonar must deal with signiﬁcant reverberation. There are three main
sources: volume reverberation, surface reﬂections, and bottom backscatter from rough clutter topgraphic
features. Volume reﬂection is due to widely distributed particulate matter and marine life in the path
of the transmit beam. It is strongest during the early portion of the pulse period. The initial surface

3.20.7 Sonar
935
reﬂection arrives from directly above the array, with additional backscatter occurring as ray paths
intersect the surface during rough sea-air interface conditions due to higher sea state. Multiple bottom-
surface reﬂections lead to a nearly periodic structure for reverberation peaks within an exponentially
decaying envelope. Reverberation can be reduced by extending the vertical array aperture to narrow the
transmit and receive beampatterns in the vertical dimension. A time-dependent automatic gain control
is also used in the receiver to avoid signal clipping during strong reverberation early in the pulse period.
When the target of interest is moving, Doppler gating can also be used to reject reverberation from
stationary clutter and to highlight the frequency-shifted target echo return.
3.20.7.3 Matched ﬁeld processing
Matched ﬁeld processing (MFP) is an interesting passive sonar application where modeled ray propaga-
tion is compared with the signal spatial structure at the receive array to estimate parameters of interest.
The classical MFP application is to estimate source (target) range and depth at great distances, though
it is theoretically possible to use the technique to identify environmental parameters such as ocean ﬂoor
geography, propagation medium inhomogeneities, and even global undersea tomography. Unlike active
sonar where two-way time of ﬂight is used to directly measure range, and depth is not usually observable,
in passive MFP it is possible to infer these parameters from the spatial phase and amplitude structure
of the wavefront at the sensor array. Source localization can be viewed as an acoustic channel inversion
problem exploiting sufﬁcient complexity in the spatial signal distribution across a sensor array and a
well-modeled channel transfer function between any candidate source position and each array sensor.
This is not simple wavefront curvature estimation which can only be used effectively at shorter ranges
within the Fresnel limits of the array. Success depends on the ability to accurately model the ducted,
wave-guided acoustic propagation from source to sensor in a planar channel constrained by the ocean
surface above, sea ﬂoor below, and a thermal-gradient-induced refractive deep-sound channel which
directs (bends) acoustic rays with shallow incidence angles back toward the channel center. As illustrated
in Figure 20.40, signals arrive at the array as a ﬁnite set of multipath rays, or acoustic modes, which are
the discrete solutions to the frequency domain wave Eq. (20.95) and whose angular and depth distribu-
tion, or spatial spectrum, depends on the channel structure and source and sensor element positions.
To solve the channel inversion problem, source position parameters are varied within a propagation
model for an optimization search to ﬁnd the best “match” between the predicted and observed acoustic
“ﬁeld” at the sensor array. MFP relies on accurate full wave parametric modeling of acoustic waveguide
propagation between the source and the array of hydrophone sensors, typically constructed as a vertical
line array. Model mismatch of course impairs localization performance, but at low frequencies (10–
100s of Hz) the sea channel maintains remarkable phase coherency across propagation modes and
ray paths and existing models are sufﬁciently accurate. The MFP approach has been successfully
demonstrated over ranges of hundreds of kilometers. Externally provided environmental parameters
needed in the model include the sound velocity proﬁle, bottom composition, and bottom topography.
Contemporary measurements are obtained within a few hours of the MFP observations by deploying
sounding instruments overboard to record sound velocity to great depths.
In this section we will follow in part the development found in [131]. Assuming waveguided propa-
gation and a distant source, surface and bottom scattered signal components are attenuated to the point
where they are negligible relative to modal components. These modes represent the multiple ray paths in

936
CHAPTER 20 Applications of Array Signal Processing
the deep sound channel between the source and individual array elements, and are the discrete solutions
to the temporal frequency domain wave equation

∇2 + K 2(v)

g(v, vs) = −δ(v −vs),
(20.95)
where v = [x, y, z]T is a position vector for an arbitrary point in the ocean channel, g(v)is the nor-
malized (assuming a unit amplitude source) velocity potential or pressure, ∇2 is the spatial Laplacian
operator, K(v) =

c(v) is the position dependent medium wave number,  is the radian frequency of the
narrowband acoustic source, c(v) is the local sound velocity, vs is the source position, and δ(·) is the
3D delta function. Since the source is modeled as a ﬁxed point radiator, solutions g(v) are interpreted
as the Green’s function for the propagation channel between vs and v.
It is often possible to model the acoustic channel with a horizontally stratiﬁed ocean as shown in
Figure 20.40, where sound speed c(v) = c(z) is a function of depth only and surface and bottom act
as partially reﬂecting parallel plates. At greater distances this model is more accurate since only rays
conﬁned in the deep sound channel have survived surface and bottom scattering and attenuation. In this
case we may separate out dependence on z in (20.95) and simplify by centering the (x, y) coordinate
system on the source so g(v, vs) may be re-parameterized as g(¯v, z, zs) where ¯v = [x −xs, y −ys]T .
The 2-D inverse spatial Fourier transform relationship with respect to only x and y is then
g(¯v, z, zs) =
1
4π2
 ∞
−∞
G(k, z, zs)e jkT ¯v dk,
(20.96)
where k = [kx, ky]T is the 2-D horizontal wavenumber vector. Note that the medium wavenumber is
given by K 2 = k2
x +k2
y +k2
z . Acoustic pressure g(¯v, z, zs) is interpreted as that seen by a hydrophone at
depth z and 2D range ¯v relative to the source, which is at depth zs. The wave equation is then expressed
in the 2-D spatial frequency domain by substituting (20.96) into (20.95)
1
4π2
 ∞
−∞

∇2 + K 2(z)

G(k, z, zs)e jkT ¯v dk = −1
4π2
 ∞
−∞
δ(z −zs)e jkT ¯v dk,
(20.97)
 ∂2
∂z2 + K 2(z) −|k|2

G(k, z, zs) = −δ(z −zs),
(20.98)
where in (20.97) we have used δ(v −vs) = δ(¯v)δ(z −zs) and −1
4π2
# ∞
−∞e jkT ¯v dk = δ(¯v).
Equation (20.98) follows by matching the Fourier transform arguments, noting that G(k, z, zs) does not
depend on x or y, and that the vertical wave number is given by k2
z = K 2 −|k|2. Solutions G(k, z, zs)
to (20.98) are known as the depth dependent Green’s functions.
In general these solutions span a continuous range of k corresponding to the different directions of
arrival for the wave fronts at z. But in the horizontally stratiﬁed, waveguided case we are considering,
only discrete values of k for distinct ray paths represent propagation modes with signiﬁcant energy, and
these directions of arrival at (¯v, z) are conﬁned to the vertical plane containing the source and sensor.
Thus G(k, z, zs) typically consists of a series of complex-amplitude-scaled delta functions at discrete
wavenumbers kn corresponding to the nth propagation ray. The inverse transform of (20.96) then takes
the form
g(¯v, z, zs) =
1
4π2

n
G(kn, z, zs)e jkT
n ¯v.
(20.99)

3.20.7 Sonar
937
A central component of every MFP algorithm is a numerical simulation for the forward propagation
model. Given a sound velocity proﬁle c(z), the simulation solves (20.98) for the discrete rays and uses
(20.99) to compute g(¯v, z, zs) as a function of all ¯v and zs values in the search range and for every z
corresponding to a sensor array element depth. The fundamental MFP strategy is to solve the inverse
propagation problem with an exhaustive search for the best match with respect to ¯v and zs between the
forwardmodeledresponsesandthemeasuredsensorarrayresponsestructureseeninoutputsamplesy(i).
Assuming a vertical line array of M elements and an MFP search in range and depth, the sampled
data vector at the array is
y(i) = a(¯v, zs)s(i) + n(i),
(20.100)
where the parametric array spatial response vector is given by
a(¯v, zs) =
⎡
⎢⎣
g(¯v, z1, zs)
...
g(¯v, zM, zs)
⎤
⎥⎦
(20.101)
and where zm, 1 ≤m ≤M, is the depth of the mth array hydrophone sensor, s(i) is a zero-mean
Gaussian random source process with variance σ 2
s and n(i) is the noise sample vector including ﬂow
noise, surface winds and shipping, biologics, etc. Assuming wide sense stationarity, the covariance
matrix is
R = E[y(i)yH(i)] = σ 2
s a(¯v, zs)aH(¯v, zs) + Rn = Rs(¯v, zs) + Rn.
(20.102)
As an MPF performance metric one can quantify how unique the array spatial response is for distinct
values of the parameters ¯v and zs, since this is related to the invertibility of the channel. To this end, a
very useful measure is the ambiguity function deﬁned as
φ(¯v1, z1; ¯v2, z2) =
$$$$
aH(¯v1, z1)
∥a(¯v1, z1)∥·
a(¯v2, z2)
∥a(¯v2, z2)∥
$$$$
2
.
(20.103)
If φ(¯v1, z1; ¯v2, z2) has multiple equally large peaks, then the MFP solution is ambiguous. Ideally it
would have a single narrow peak at (¯v1 = ¯v2; z1 = z2) for all ¯v1, z1, which would yield high resolution
unique solutions, but signiﬁcant sidelobe patterns are common. Array length and depth and the sound
velocity proﬁle c(z) affect the shape of the ambiguity function and thus channel invertibility.
3.20.7.4 Acoustic vector sensors
As we transition to microphone arrays for aeroacoustical applications, we brieﬂy mention here a rela-
tively new type of acoustical vector sensor (AVS), which essentially amounts to an “array on a sensor.”
An AVS can measure the vector-valued acoustic particle velocity in addition to the scalar-valued sound
pressure, and such sensors have been manufactured for acoustic measurements in both air and water.
An example of an aeroacoustic vector sensor is shown in Figure 20.41. The output of a general AVS in
free space can be represented as
y(t) =

1
u(θ, φ)

x(t) + n(t),
(20.104)

938
CHAPTER 20 Applications of Array Signal Processing
FIGURE 20.41
A vector acoustic sensor manufactured by Microﬂown Technologies, The Netherlands.
where x(t) represents the sound pressure, n(t) noise and interference, and
uT (θ, φ) = [cos (θ) cos (φ)
sin (θ) cos (φ) sin (φ)]T
is a unit vector at the sensor pointing towards the source at azimuth angle θ and elevation angle φ. If
the sensor is located near a reﬂecting surface (e.g., a wall or the ocean ﬂoor), then a reﬂection term is
added to (20.104) to account for the source image.
The key distinguishing feature of an AVS is the fact that it produces a four-dimensional measurement
at essentially a single point in space. A single AVS can be used to localize two separate sources, and
additional resolving power can be obtained by an array of AVS within a relatively small aperture.
AVS provide an interesting alternative to standard hydrophones or microphones in acoustic source
localization and signal recovery.
3.20.8 Microphone arrays
The processing of acoustic signals in the air using arrays of microphones has received signiﬁcant atten-
tion, although considerably less than for underwater acoustics due to the ubiquitous use of sonar in naval
operations. While the use of microphone arrays has also been proposed for military applications, such as
localization or identiﬁcation of vehicles, helicopters, sniper ﬁre, etc., such arrays have perhaps enjoyed
more success in commercial settings, particulary those related to speech recovery or enhancement. For
example, the ability of microphone arrays to locate an acoustic source such as a speaker, extract an
acoustic signal in a noisy and reverberant environment, and synthesize arbitrary sound ﬁelds has led to

3.20.8 Microphone Arrays
939
FIGURE 20.42
4 × 4 microphone array manufactured by iSEMcon GmbH, Germany.
their use in advanced video-conferencing systems, “hands-free” communication systems, surveillance
of criminal activity and simulation of concert hall acoustics in high-end audio systems. Figure 20.42
shows a 4 × 4 array used for sound ﬁeld mapping and source localization. A simple array typical of
those used for teleconferencing applications is shown in Figure 20.43.
Similar to underwater acoustics, signal processing with microphone arrays relies on wideband data
models, where the propagation time across the array is usually much greater than the inverse bandwidth.
For example, it takes about 6 ms for sound to travel one half meter (a typical array aperture), while
the inverse bandwidth of a speech signal is around 0.2–0.5 ms. On the other hand, since the speed of
sound in air is over four times slower than in water, and since the frequencies of interest for aero-
acoustics are usually higher than in sonar, microphone arrays can be much more compact. At 1 kHz,
the wavelength of sound is about 30 cm, so arrays with apertures under a few meters are common.
Consequently, plane-wave propagation models are typically assumed, at least locally, in the vicinity of
the array. Propagation in outdoor environments is complicated by wind and temperature gradients that
make precise localization difﬁcult over long ranges. Even in situations where straight-line propagation
can be assumed, random ﬂuctuations in the air and temperature will cause a transmitted and received
acoustic signal to lose temporal coherence if the signal travels a large distance. Indoors, the main obstacle
to overcome is reverberation due to reﬂections of the sound from ﬂoors, walls, ceilings, furniture, etc.

940
CHAPTER 20 Applications of Array Signal Processing
FIGURE 20.43
Microphone array used in video-conferencing applications. Manufactured by Polycom, Inc., San Jose, CA.
Consequently, the focus of most microphone array applications in outdoor settings is source localization,
while indoors the most common problem is reconstruction of a desired acoustic source in the presence
of noise and multipath. We brieﬂy discuss aspects of these two problems below.
3.20.8.1 Aeroacoustic source localization
The term “acoustic camera” is often used to refer to microphone arrays that are used to characterize
sound ﬁelds and locate sources of acoustic energy. Since the aeroacoustic signals used for localization
are typically wideband, models for the problem tend to be formulated in the frequency domain. Let
y(t) = [y1(t) · · · yM(t)]T denote the output of an M-microphone array. Assuming zero-mean wide-
sense stationary signals, the array output is characterized by its cross-correlation matrix
Ry(τ) = E{y(t + τ)y(t)T }
(20.105)
and the corresponding cross spectral density (CSD) matrix Gy(ω) whose i, jth element is deﬁned as
Gy,i j(ω) =
 ∞
−∞
Ry,i j(τ)e−jωτdτ,
(20.106)
where Ry,i j(τ) is element i, j of Ry(τ).
In general, the elements of the CSD may be expressed as
Gy,i j(ω) = e−jωτi j(p)Gs,i j(ω) + σ 2δi j(ω),
(20.107)
where σ 2(ω) is the CSD of the noise (assumed to be uncorrelated at each microphone), τi j(p) is the
propagation delay between the two microphones, which is a function of the location of the source p, and
Gs,i j(ω) = γs,i j(ω)[Gs,i(ω)Gs, j(ω)]1/2,
(20.108)

3.20.8 Microphone Arrays
941
where γs,i j(ω) is the spectral coherence function for the two sensors satisfying 0 ≤|γs,i j(ω)| ≤1, and
Gs,i(ω) represents the CSD of the source at microphone i. In general, Gs,i(ω) ̸= Gs, j(ω) when i ̸= j
due to propagation inhomogeneities that occur as the signal travels between the two microphones. If
microphones i and j are close enough together such that one can assume spatially coherent planewave
propagation between them, then γs,i j(ω) = 1 and Gs,i(ω) = Gs, j(ω).
A convenient and very general approach is to assume an array-of-arrays situation, where several (say,
K) arrays of closely-spaced microphones with locally coherent propagation are distributed over a larger
area and separated by distances over which coherent propagation cannot generally be assumed. This
model subsumes the two cases discussed above. If the vector outputs of each array yk(t) are stacked
on top of each other to form the super-vector y(t) = [y1(t)T · · · yK (t)T ]T , then the MK × MK CSD
matrix will be given by
Gy(ω, p) =
⎡
⎢⎣
a1(ω, p)aH
1 (ω, p)Gs,1(ω)
· · · a1(ω, p)aH
K (ω, p)e−jωτ1K (p)Gs,1K (ω)
· · ·
...
· · ·
aK (ω, p)aH
1 (ω, p)e−jωτK1(p)Gs,K1(ω) · · ·
aK (ω, p)aH
K (ω, p)Gs,K (ω)
⎤
⎥⎦
+ σ 2(ω)I,
(20.109)
where I is an MK × MK identity matrix (assuming for simplicity that the noise CSD is the same at
each array),
ak(ω, p) =
⎡
⎢⎣
e−jωτk,11(p)
...
e−jωτk,1Mk (p)
⎤
⎥⎦,
(20.110)
and where τk,i j(p) represents the propagation delay between microphones i and j for array k with Mk
elements.
If one has access to the outputs of all K of the arrays and the various source CSDs Gs,i j(ω) are
known, a procedure for estimating the source location p based on samples of Gy(ω, p) at different
frequencies can easily be formulated. Such an approach would require the arrays to share all their data
with a fusion center, which incurs a large communication overhead. In addition, knowledge of Gs,i(ω)
implies that the arrays can somehow obtain time-aligned measurements of the source CSD, which is
problematic without knowledge of the source location. The latter issue can be resolved by absorbing
the time-delay terms e−jωτkl(p) between arrays k and l into Gs,kl(ω), and basing the estimate of p on
just the intra-array phase shifts. An alternative approach is to estimate the direction-of-arrival (DOA) of
the source signal at each array using only the locally calculated CSD matrix ak(ω, p)aH
k (ω, p)Gs,k(ω)
(the location of the source is not identiﬁable at each array individually, only the source DOA). Each
array would then forward only its estimated DOA to the fusion center, which would then estimate
p via triangulation. Various studies of the Cramér-Rao Bound have been conducted to determine the
difference in achievable performance for these approaches.
3.20.8.2 Wideband adaptive beamforming
As mentioned above, in many microphone array applications, locating an acoustic source is less impor-
tant than extracting its waveform in a reverberant and noisy environment. In relatively short-range

942
CHAPTER 20 Applications of Array Signal Processing
indoor settings where factors that inﬂuence acoustic propagation (temperature, pressure, wind, etc.) are
uniform, Doppler and dispersion effects can be ignored, and to a very good approximation the array will
simply receive scaled and delayed versions of the source via a (potentially large) number of reverberant
paths. In particular, at microphone m, the received acoustic signal can be represented as
ym(t) =
N

i=1
αi,ms(t −τi,m) + nm(t),
(20.111)
where s(t) is the desired source, N denotes the number of multipath echoes from the source to the
microphone, {αi,m, τi,m} are the amplitude and the delay corresponding to path i at microphone m, and
nm(t) is due to all other background noise and interference.
The most common approach to extracting s(t) from the M-element microphone array output is via
a wideband beamformer:
ˆs(t −t0) =
M

m=1
L

l=0
wml ym(t −lTs),
(20.112)
where Ts is the sampling period of the array, wml is the beamformer weight for microphone m at sample
l, and t0 is an arbitrary delay. This essentially amounts to a space-time equalizer similar to what might
be employed in a frequency-selective wireless RF channel. The difference in the microphone array
application is that one typically does not have access to periodic “training” data from the source to
facilitate updates of the beamformer/equalizer weights, either in time via the LMS or RLS algorithms,
or using a data-adaptive approach like MVDR beamforming. Instead, other factors must be exploited
to adapt the weights. For example, one may know or be able to estimate the approximate location or
DOA of the source, as in automobile voice-enhancement or video conferencing systems where the
speaker(s) are conﬁned to certain positions. Likewise, knowledge of the location of strong sources of
acoustic interference (e.g., TVs, air conditioners, windows, etc.) can also be taken advantage of to help
the ﬁlter focus on the source of interest. Adaptive noise canceling approaches are possible if reference
waveforms are available for the interference, obtained for example by placing a microphone near the
interfering source. One can also exploit situations where the source or interference is known to have
strong components at certain frequencies, although in this case it is advantageous to implement the ﬁlter
in the frequency domain:
S(ωk) =
M

m=1
Wm(ωk)Ym(ωk).
(20.113)
Important factors to consider when implementing a wideband beamformer in microphone array
applications are the sampling period Ts and the length L of the equalizer, which in many situations can
be quite large for the required value of Ts. For example, to reconstruct a speech signal with a 3 kHz
bandwidth in a room where the path lengths of the echos may vary by 5 m could require a value of L
on the order of 300–400. For this reason, in computationally constrained scenarios, one may be forced
to settle for a space-only beamformer followed by an adaptive echo canceler.

3.20.9 Chemical Sensor Arrays
943
3.20.9 Chemical sensor arrays
In recent years, the use of model-based signal processing with chemical sensor arrays has received
signiﬁcant interest. Driving this interest has been important applications such as enironmental monitor-
ing of air and water quality, chemical spills, detection and localization of air- or waterborne chemical
weapons and even landmines. The ability to quickly discover and accurately locate sources of toxic
chemicals is obviously a critical factor in mitigating their negative impact. The term “model-based” is
used here to contrast against classical methods that simply use arrays of sensors to improve coverage
or increase the probability of detecting a chemical event. While these are clearly important, our focus
below will be on approaches that employ parametric models to describe chemical ﬂow across the sen-
sors, and as such can be used to locate and quantify other properties of the source(s) in addition to
simply detecting their presence.
The key differentiating feature of applications involving chemical sensor arrays compared with others
considered in this chapter is the fact that the signals of interest propagate according to diffusion rather
than wave equations. Additional complications such as imprecisely known wind/currents, turbulence,
eddys, vortices and boundary effects make it difﬁcult to obtain an accurate mathematical model except in
fairly simple circumstances. Nevertheless, results obtained from simpliﬁed models of the environment
can serve as valuable approximations that provide useful information. Furthermore, they can be used to
focus the local implementation of more complicated numerical operations that would be too involved
to perform globally.
To illustrate the application of sensor arrays in localizing a diffusing chemical source, we will
consider a simple example involving a point source in an open environment (all surfaces and other
boundaries are far enough removed from the source and array so that their effects can be neglected) with
homogeneous diffusivity in all directions. Assume the source is located at position r0 = [x0, y0, z0]T
and at time t0 begins emitting the chemical substance at a constant rate of μ kg/s. Assume also that a
wind/current is present with constant velocity vector v. For this case, the diffusion equation that governs
the concentration c(r, t) of the substance at some position r at time t > t0 is given by
∂c(r, t)
∂t
= κ∇2c(r, t) −∇c · v,
(20.114)
where κ measured in m2/s is the diffusivity of the medium, which in the above expression is assumed
to be incompressible. The solution to (20.114) is given by c(r, t) = μa(r, t), where
a(r, t) =
1
8πκ∥r −r0∥exp
%(r −r0)T v
2κ
&
×
'
exp
%∥r −r0∥∥v∥
2κ
&
erfc
 
∥r −r0∥
2√κ(t −t0) + ∥v∥
(
t −t0
4κ
!
(20.115)
× exp
%−∥r −r0∥∥v∥
2κ
&
erfc
 
∥r −r0∥
2√κ(t −t0) −∥v∥
(
t −t0
4κ
!)
,
(20.116)

944
CHAPTER 20 Applications of Array Signal Processing
where erfc(x) = 2
π
# ∞
x e−y2 dy is the complementary error function. While technically the above model
is appropriate for molecular diffusion, it can be applied to larger scale scenarios involving convective
diffusion by adjusting the value of the diffusivity κ.
To characterize the chemical concentration at any point in space or time, one would need to know
μ, the “strength” of the source, as well as the parameters in the vector θ = [rT
0 κ t0]T , which include
the location of the source and the time it became active. The diffusivity κ is also treated as an unknown
constant, since it will depend on environmental factors (temperature, humidity, etc.) in a complicated
way. To determine these unknowns, an array of sensors that measure the concentration of the chemical
can be deployed. For example, a given sensor located at position ri would observe the following
concentration at some speciﬁc time tk:
yi(tk) = a(ri, θ, tk)μ + ni(tk),
where ni(t) represents noise or modeling errors, and a is written as an explicit function of θ to emphasize
its dependence on the parameters of interest. If the observations from M sensors taken at K distinct time
samples are stacked into a single observation vector y, where element p of y is indexed according to
p = M(k −1)+i for k = 1, . . ., K and i = 1, . . ., M, the standard array processing model is obtained:
y =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
a(r1, θ, t1)
...
a(rM, θ, t1)
a(r1, θ, t2)
...
a(rM, θ, tK )
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
μ + n = a(θ)μ + n,
(20.117)
where the vector of noise samples n is organized like y, and element p = M(k −1)+i of the “steering”
vector a(θ) is given by a(ri, θ, tk). With the model of (20.117) in hand, one can apply standard array
processing techniques to estimate μ and θ, provided that (20.117) is identiﬁable. In principle, unique
identiﬁcation of the three location parameters in θ, namely r0, requires that M ≥4, and of course we
require that the total number of observations MK exceed the number of free parameters (six in this
model). In practice, of course, MK will likely need to be much larger than six in order to combat the
effects of noise.
Whilethediscussionabovewasforthesimplecaseofaninﬁniteopenenvironment,asimilarapproach
can be taken for more complicated scenarios provided that the diffusion equation can be solved. Cases of
particular interest that have been addressed include a semi-inﬁnite medium (e.g., a source on the ocean
ﬂoor) and a large room of known dimensions. Boundary conditions play an important role in such
cases, and different results are obtained depending on whether or not the boundaries are permeable to
the chemical of interest. Source models different from the step function model assumed above can also
be employed, such as impulse or pulsed waveforms. In settings involving very complicated geometries
(e.g., urban canyons, buildings with ofﬁces and hallways, etc.), moving sources or sensors, or when more
realistic propagation effects are taken into account (e.g., turbulence, eddys, inhomogeneous diffusivity,
etc.), numerical methods are required to evaluate the response of the array to the chemical source. Details
for these different modeling assumptions can be found in the references at the end of the chapter.

3.20.10 Conclusion
945
3.20.10 Conclusion
As we have seen above, the applications of array signal processing stretch from locating the sources
of electrical energy from tiny neurons in the brain to astronomical objects millions of light-years away
to submarines deep below the surface of the ocean. Remarkably, all of these applications share a very
consistent underlying mathematical model that often allows techniques developed for one problem
to apply to others in different ﬁelds. For this reason, we see similar methods appearing in journals
related to radar, sonar, neurophysiology, acoustics, radio astronomy, medical imaging, seismology,
and navigation, although explained in many cases with different terminology or emphases. Superﬁcial
differences in language aside, while the methods in the literature of these different areas are similar,
they are not identical; each application has its own peculiarities that warrant special attention. Thus,
in addition to showing what is common among the problems considered, our goal has also been to
highlight the unique features of each application, and hence to provide motivation for the particular
methodologies researchers and practitioners have adopted for these applications. Clearly, our discussion
has only scratched the surface, and many details have been glossed over. It is our hope that we have
piqued the reader’s interest enough to pursue some of these details in the reference list (which is itself
a small subset of what is available).
Relevant Theory: Signal Processing Theory, Machine Learning, and Statistical Signal Processing
See Vol. 1, Chapter 2 Continuous-Time Signals and Systems
See Vol. 1, Chapter 3 Discrete-Time Signals and Systems
See Vol. 1, Chapter 4 Random Signals and Stochastic Processes
See Vol. 1, Chapter 5 Sampling and Quantization
See Vol. 1, Chapter 6 Digital Filter Structures and Their Implementation
See Vol. 1, Chapter 7 Multirate Signal Processing for Software Radio Architectures
See Vol. 1, Chapter 8 Modern Transform Design for Practical Audio/Image/Video Coding Applications
See Vol. 1, Chapter 9 Discrete Multi-Scale Transforms in Signal Processing
See Vol. 1, Chapter 10 Frames in Signal Processing
See Vol. 1, Chapter 11 Parametric Estimation
See Vol. 1, Chapter 12 Adaptive Filters
See Vol. 1, Chapter 20 Clustering
See Vol. 1, Chapter 21 Unsupervised Learning Algorithms
See Vol. 1, Chapter 25 A Tutorial on Model Selection
See this Volume, Chapter 2 Model Order Selection
See this Volume, Chapter 7 Geolocation—Maps, Measurements, Models, and Methods
See this Volume, Chapter 8 Performance Analysis and Bounds
References and Further Reading
Space-time adaptive processing
[1] L. Brennan, F. Staudaher, Subclutter Visibility Demonstration, Adaptive Sensors, Inc., Technical Report
RL-TR-92-21, 1992.

946
CHAPTER 20 Applications of Array Signal Processing
[2] I.S. Reed, J.D. Mallett, L.E. Brennan, Rapid convergence rate in adaptive arrays, IEEE Trans. Aerosp.
Electron. Syst. AES-10 (1974) 853–862.
[3] B.D. Carlson, Covariance matrix estimation errors and diagonal loading in adaptive arrays, IEEE Trans.
Aerosp. Electron. Syst. 24 (3) (1988) 397–401.
[4] I. Kirsteins, D. Tufts, Adaptive detection using low rank approximation to a data matrix, IEEE Trans. Aerosp.
Electron. Syst. AES-30 (1) (1994) 55–67.
[5] P. Parker, A. Swindlehurst, space-time autoregressive ﬁltering for matched subspace STAP, IEEE Trans.
Aerosp. Electron. Syst. AES-39 (2) (2003) 510–520.
[6] J. Guerci, J. Goldstein, I. Reed, Optimal and adaptive reduced-rank STAP, IEEE Trans. Aerosp. Electron.
Syst. 36 (2) (2000) 647–663.
[7] J. Guerci, Space-Time Adaptive Processing for Radar, Artech House, 2003.
[8] R. Klemm, Space-Time Adaptive Processing: Principles and Applications, IEE Press, 1998.
[9] J. Ward, Space-Time Adaptive Processing for Airborne Radar, MIT Lincoln Labs, Technical Report TR-1015,
1994.
MIMO radar
[10] J. Li, P. Stoica (Eds.), MIMO Radar Signal Processing, John Wiley & Sons, Inc., Hoboken, NJ, 2009.
[11] E. Fishler, A. Haimovich, R. Blum, D. Chizhik, L. Cimini, R. Valenzuela, MIMO radar: an idea whose time
has come, in: Proceedings of the IEEE Radar Conference, April 2004, pp. 71–78.
[12] E. Fishler, A. Haimovich, R. Blum, L. Cimini, D. Chizhik, R. Valenzuela, Spatial diversity in radars—models
and detection performance, IEEE Trans. Signal Process. 54 (3) (2006) 823–838.
[13] I. Bekkerman, J. Tabrikian, Target detection and localization using MIMO radars and sonars, IEEE Trans.
Signal Process. 54 (2006) 3873–3883.
[14] P. Stoica, J. Li, Y. Xie, On probing signal design for MIMO radar, IEEE Trans. Signal Process. 55 (8) (2007)
4151–4161.
[15] J. Li, P. Stoica, MIMO radar with colocated antennas: review of some recent work, IEEE Signal Process.
Mag. 24 (5) (2007) 106–114.
[16] L. Xu, J. Li, P. Stoica, Target detection and parameter estimation for MIMO radar systems, IEEE Trans.
Aerosp. Electron. Syst. 44 (3) (2008) 927–939.
[17] A.H. Haimovich, R.S. Blum, L.J. Cimini, MIMO radar with widely separated antennas, IEEE Signal Process.
Mag. 25 (1) (2008) 116–129.
[18] H. He, P. Stoica, J. Li, Designing unimodular sequence sets with good correlations—including an application
to MIMO radar, IEEE Trans. Signal Process. 57 (11) (2009) 4391–4405.
[19] H. He, J. Li, P. Stoica, Waveform Design for Active Sensing Systems—A Computational Approach, Cam-
bridge University Press, 2012.
[20] W. Roberts, P. Stoica, J. Li, T. Yardibi, F.A. Sadjadi, Iterative adaptive approaches to MIMO radar imaging,
IEEE J. Sel. Top. Signal Process. 4 (1) (2010) 5–20.
[21] X. Tan, W. Roberts, J. Li, P. Stoica, Sparse learning via iterative minimization with application to MIMO
radar imaging, IEEE Trans. Signal Process. (2011) 1088–1101.
Radio astronomy
[22] D. John, Kraus, Radio Astronomy, second ed., Cygnus-Quasar Books, Powell, Ohio, 1986.
[23] A.R. Thompson, J.M. Moran, G.W. Swenson Jr., Interferometry and Synthesis in Radio Astronomy, second
ed., Wiley-Interscience, New York, 2001.

References and Further Reading
947
[24] B.D. Jeffs, K.F. Warnick, J. Landon, J. Waldron, J.R. Fisher D. Jones, R.D. Norrod, Signal processing for
phased array feeds in radio astronomical telescopes, IEEE J. Sel. Top. Signal Process. 2 (5) (2008) 635–646.
[25] P.J. Napier, A.R. Thompson, R.D. Ekers, The very large array: design and performance of a modern synthesis
radio telescope, Proc. IEEE 71 (1983) 1295–1320.
[26] R. Levanda, A. Leshem, Synthetic aperture radio telescopes, IEEE Signal Process. Mag. 27 (1) (2010) 14–29.
[27] R.J. Cornwell, K. Golap, S. Bhatnagear, The noncoplanar baselines effect in radio interferometry: the W-
projection algorithm, IEEE J. Sel. Top. Signal Process. 2 (5) (2008) 647–657.
[28] A. Leshem, A.-J. van der Veen, A.-J. Boonstra, Multichannel interference mitigation techniques in radio
astronomy, Astrophys. J. Suppl. 131 (1) (2000) 355–374.
[29] A. Leshem, A.-J. van der Veen, Radio-astronomical imaging in the presence of strong radio interference,
IEEE Trans. Inform. Theory 46 (5) (2000) 1730–1747.
[30] J.A. Högbom, Aperture synthesis with a nonregular distribution of interferometer baselines, Astron. Astro-
phys. Suppl. 15 (1974) 417–426.
[31] F.R. Schwab, Relaxing the isoplanatism assumption in self-calibration: application to low-frequency radio
interferometry, Astron. J. 131 (6) (1984) 646–659 (pt. F).
[32] R.J.Cornwell,MultiscaleCLEANdeconvolutionsofradiosynthesisimages,IEEEJ.Sel.Top.SignalProcess.
2 (5) (2008) 793–801.
[33] J. Landon, M. Elmer, D. Jones, A. Stemmons, B.D. Jeffs, K.F. Warnick, J.R. Fisher, R.D. Norrod, Phased
array feed calibration, beamforming, and imaging, Astron. J. 139 (3) (2010) 1154–1167.
[34] K.F. Warnick, M.A. Jensen, Effects of mutual coupling on interference mitigation with a focal plane array,
IEEE Trans. Antennas Propag. 53 (8) (2005) 2490–2498.
[35] M. Elmer, B.D. Jeffs, K.F. Warnick, J.R. Fisher, R. Norrod, Beamformer design methods for radio astro-
nomical phased array feeds, IEEE Trans. Antennas Propag. 60 (2) (2012) 903–914.
[36] S. van der Tol, B.D. Jeffs, A.-J. van der Veen, Self calibration for the LOFAR radio astronomical array, IEEE
Trans. Signal Process. 55 (9) (2007) 4497–4510.
[37] K.F. Warnick, B.D. Jeffs, Gain and aperture efﬁciency for a reﬂector antenna with an array feed, IEEE
Antennas Propag. Lett. 5 (2006) 499–502.
[38] A.R. Taylor, S.J. Gibson, M. Peracaula, P.G. Martin, T.L. Landecker, C.M. Brunt, P.E. Dewdney, S.M.
Dougherty, A.D. Gray, L.A. Higgs, C.R. Derton, L.B.G. Knee, R. Kothes, C.R. Purton, B. Uyaniker, B.J.
Wallace, A.G. Willis, D. Durand, The Canadian galactic plane survey, Astron. J. 125 (2003) 3145–3164.
[39] Y. Bhattacharjee, Radio astronomers take arms against a sea of signals, Science 330 (6003) (2010) 444–445.
[40] J.F.Bell,S.W.Ellingson,J.Bunton,RemovaloftheGLONASSC/AsignalfromOHspectrallineobservations
using a parametric modeling technique, Astrophys. J. Suppl. 135 (2001) 87–93.
[41] A.J. Poulsen, B.D. Jeffs, K.F. Warnick, J.R. Fisher, Programmable real-time cancellation of GLONASS
interference with the Green Bank telescope, Astron. J. 130 (6) (2005) 2916–2927.
[42] W. Dong, B.D. Jeffs, J.R. Fisher, Radar interference blanking in radio astronomy using a Kalman tracker,
Radio Sci. 40 (5) (2005).
[43] B.D. Jeffs, W. Lazarte, J.R. Fisher, Bayesian detection of radar interference in radio astronomy, Radio Sci.
41 (2006).
[44] S.W. Ellingson, G.A. Hampson, Mitigation of radar interfernece in L-band radio astronomy, Astrophys. J.
Suppl. 147 (2003) 167–176.
[45] Q. Zhang, Y. Zheng, S.G. Wilson, J.R. Fisher, R. Bradley, Combating pulsed radar interference in radio
astronomy, Astron. J. 126 (2003) 1588–1594.
[46] Q. Zhang, Y. Zheng, S.G. Wilson, J.R. Fisher, R. Bradley, Excision of distance measuring equipment inter-
ference from radio astronomy signals, Astron. J. 129 (6) (2005) 2933–2939.
[47] J.R. Fisher, Q. Zhang, S.G. Wilson, Y. Zheng, R. Bradley, Mitigation of pulsed interference to redshifted HI
and OH observations between 960 and 1215 megahertz, Astron. J. 129 (6) (2005) 2940–2949.

948
CHAPTER 20 Applications of Array Signal Processing
[48] P.A. Fridman, W.A. Baan, RFI mitigation methods in radio astronomy, Astron. Astrophys. 378 (2001) 327–
344.
[49] C. Barnbaum, R.F. Bradley, A new approach to interference excision in radio astronomy: real-time adaptive
cancellation, Astron. J. 116 (1998) 2598–2614.
[50] B.D. Jeffs, L. Li, K.F. Wanick, Auxiliary antenna assisted interference mitigation for radio astronomy arrays,
IEEE Trans. Signal Process. 53 (2) (2005) 439–451.
[51] S.W. Ellingson, G.A. Hampson, A subspace-tracking approach to interference nulling for phased array-based
radio telescopes, IEEE Trans. Antennas Propag. 50 (1) (2002) 25–30.
[52] C.K. Hansen, K.F. Warnick, B.D. Jeffs, R. Bradley, Interferene mitigation using a focal plane array, Radio
Sci. 40 (2005).
[53] J.R. Nagel, K.F. Warnick, B.D. Jeffs, J.R. Fisher, R. Bradley, Experimental veriﬁcation of radio frequency
interference mitigation with a focal plane array feed, Radio Sci. 42 (2007).
[54] J. Raza, A.-J. Boonstra, A.-J. van der Veen, Spatial ﬁltering of RF interference in radio astronomy, IEEE
Signal Process. Lett. 9 (2) (2002) 64–67.
Positioning and navigation
[55] E.D. Kaplan, C. Hegarty (Eds.), Understanding GPS: Principles and Applications, second ed., Artech House,
2005.
[56] Y.-H. Chen, J.-C.J.D.S.D. Lorenzo, J. Seo, S. Lo, P. Enge, D.M. Akos, Real-time software receiver for GPS
controlled reception pattern antenna array processing, in: ION GNSS Conference, 2010.
[57] R.G. Lorenz, S.P. Boyd, Robust beamforming in GPS arrays, in: ION National Technical Meeting, 2002.
[58] S. Backén, On dynamic array processing for GNSS software receivers, Lulea University of Technology,
Ph.D. Dissertation, 2011.
[59] G. Seco-Granados, J. Fernandez-Rubio, C. Fernandez-Prades, ML estimator and hybrid beamformer for
multipath and interference mitigation in GNSS receivers, IEEE Trans. Signal Process. 53 (3) (2005) 1194–
1208.
[60] M. Amin, W. Sun, A novel interference suppression scheme for global navigation satellite systems using
antenna array, IEEE J. Sel. Areas Commun. 23 (5) (2005) 999–1012.
[61] D. Lu, Q. Feng, R. Wu, Survey on interference mitigation via adaptive array processing in GPS, PIERS
Online 2 (4) (2006) 357–362.
[62] R. Fante, J. Vaccaro, Wideband cancellation of interference in a GPS receive array, IEEE Trans. Aerosp.
Electron. Syst. 36 (2) (2000) 549–564.
[63] S.-J. Kim, R. Iltis, STAP for GPS receiver synchronization, IEEE Trans. Aerosp. Electron. Syst. 40 (1) (2004)
132–144.
[64] M. Amin, L. Zhao, A. Lindsey, Subspace array processing for the suppression of FM jamming in GPS
receivers, IEEE Trans. Aerosp. Electron. Syst. 40 (1) (2004) 80–92.
[65] M.T. Brenneman, Y.T. Morton, Q. Zhou, GPS multipath detection with ANOVA for adaptive arrays, IEEE
Trans. Aerosp. Electron. Syst. 46 (3) (2010) 1171–1184.
[66] J. Soubielle, I. Frijalkow, P. Duvaut, A. Bibaut, GPS positioning in a multipath environment, IEEE Trans.
Signal Process. 50 (1) (2002) 141–150.
[67] A. Swindlehurst, Time delay and spatial signature estimation using known asynchronous signals, IEEE Trans.
Signal Process. 46 (2) (1998) 449–462.
[68] A. Jakobsson, A. Swindlehurst, P. Stoica, subspace-based estimation of time delays and Doppler shifts, IEEE
Trans. Signal Process. 46 (9) (1998) 2472–2483.
[69] M. Wax, A. Leshem, Joint estimation of time delays and directions of arrival of multiple reﬂections of a
known signal, IEEE Trans. Signal Process. 45 (10) (1997) 2477–2484.

References and Further Reading
949
[70] H. Amindavar, A. Reza, A new simultaneous estimation of directions of arrival and channel parameters in a
multipath environment, IEEE Trans. Signal Process. 53 (2) (2005) 471–483.
[71] M. Vanderveen, A.-J. van der Veen, A. Paulraj, Estimation of multipath parameters in wireless communica-
tions, IEEE Trans. Signal Process. 46 (3) (1998) 682–690.
[72] F. Antreich,
J. Nossek, W.
Utschick,
Maximum likelihood
delay estimation in a navigation
receiver
for
aeronautical
applications,
Aero.
Sci.
Technol.
12
(3)
(2008)
256–267
(online).
<http://www.sciencedirect.com/science/article/pii/S1270963807000843>.
[73] G. Seco, A.L. Swindlehurst, D. Astély, Exploiting antenna arrays for synchronization, in: G.B. Giannakis, Y.
Hua, P. Stoica, L. Tong (Eds.), Signal Processing Advances in Wireless Communications, Trends in Single-
and Multi-User Systems, vol. II, Prentice-Hall, 2000, pp. 403–430 (Chapter 10).
[74] F. Antreich, J.A. Nossek, G. Seco-Granados, A.L. Swindlehurst, The extended invariance principle for signal
parameter estimation in an unknown spatial ﬁeld, IEEE Trans. Signal Process. 59 (7) (2011) 3213–3225.
[75] J.-C.Juang,G.-S.Huang,DevelopmentofGPS-basedattitudedeterminationalgorithms,IEEETrans.Aerosp.
Electron. Syst. 33 (3) (1997) 968–976.
[76] J.K. Ray, M.E. Cannon, P.C. Fenton, Mitigation of static carrier-phase multipath effects using multiple closely
spaced antennas, Navigation: J. Inst. Navigation (ION) 46 (3) (1999) 193–201.
[77] J. Ray, M. Cannon, P. Fenton, GPS code and carrier multipath mitigation using a multiantenna system, IEEE
Trans. Aerosp. Electron. Syst. 37 (1) (2001) 183–195.
Wireless communications
[78] F. Khan, LTE for 4G Mobile Broadband—Air Interface Technologies and Performance, Cambridge Univer-
sity Press, 2009.
[79] S. Sesia, I. Touﬁk, M. Baker (Eds.), LTE—The UMTS Long Term Evolution: From Theory to Practice,
Wiley, 2009.
[80] J. Lee, J.-K. Han, J.C. Zhang, MIMO technologies in 3GPP LTE and LTE-advanced, EURASIP J. Wireless
Commun. Network. (2009) (online). <http://dx.doi.org/10.1155/2009/302092>.
[81] A. Ghosh, R. Ratasuk, B. Mondal, N. Mangalvedhe, T. Thomas, LTE-advanced: next-generation wireless
broadband technology (invited paper), IEEE Wireless Commun. 17 (3) (2010) 10–22.
[82] J. Duplicy, B. Badic, R. Balraj, P.H. Rizwan Ghaffar, F. Kaltenberger, R. Knopp, I.Z. Kovács, H.T. Nguyen,
D. Tandur, G.Vivier, MU-MIMO in LTE systems, EURASIP J. Wireless Commun. Network. (2011).
[83] E. Dahlman, S. Parkvall, J. Skold, 4G: LTE/LTE-Advanced for Mobile Broadband, Academic Press, 2011.
[84] H. Taoka, S. Nagata, K. Takeda, Y. Kakishima, X. She, K. Kusume, MIMO and CoMP in LTE-advanced,
NTT DOCOMO Techn. J. 12 (2) (2010) 20–28.
[85] E. Hossain, D.I. Kim, V.K. Bhargava, Cooperative Cellular Wireless Networks, Cambridge University Press,
2011.
[86] Q. Li, X. Lin, J. Zhang, W. Roh, Advancement of MIMO technology in WiMAX: from IEEE 802.16d/e/j to
802.16m, IEEE Commun. Mag. 47 (6) (2009) 100–107.
[87] S. Ahmadi, Mobile WiMAX: A Systems Approach to Understanding IEEE 802.16m Radio Access Tech-
nology, Academic Press, 2010.
[88] Q. Li, G. Li, W. Lee, M. il Lee, D. Mazzarese, B. Clerckx, Z. Li, MIMO techniques in WiMAX and LTE: a
feature overview, IEEE Commun. Mag. 48 (5) (2010) 86–92.
[89] IEEE Std 802.16, IEEE Standard for Local and metropolitan area networks Part 16: Air Interface for Broad-
band Wireless Access Systems Amendment 3: Advanced Air Interface, IEEE Std 802.16m-2011(Amendment
to IEEE Std 802.16-2009), 2011.
[90] D.Halperin,W.Hu,A.Sheth,D.Wetherall,802.11withmultipleantennasfordummies,SIGCOMMComput.
Commun. Rev. 40 (2010) 19–25 (online). <http://doi.acm.org/10.1145/1672308.1672313>.

950
CHAPTER 20 Applications of Array Signal Processing
[91] E. Perahia, R. Stacey, Next Generation Wireless LANs: Throughput, Robustness, and Reliability in 802.11n,
Cambridge University Press, 2008.
[92] IEEE802.11n, IEEE Standard for Information technology—Telecommunications information exchange
between systems—Local and metropolitan area networks—Speciﬁc requirements Part 11: Wireless LAN
Medium Access Control (MAC) and Physical Layer (PHY) Speciﬁcations Amendment 5: Enhancements
for Higher Throughput, IEEE Std 802.11n-2009 (Amendment to IEEE Std 802.11-2007 as amended by
IEEE Std 802.11k-2008, IEEE Std 802.11r-2008, IEEE Std 802.11y-2008, and IEEE Std 802.11w-2009),
2009.
Biomedical applications
[93] T. Szabo, Diagnostic Ultrasound Imaging: Inside Out, Elsevier Academic Press, 2004.
[94] B. Steinberg, Digital beamforming in ultrasound, IEEE Trans. Ultrasonics, Ferr. Freq. Cont. 39 (6) (1992)
716–721.
[95] J. Lu, H. Zou, J. Greenleaf, Biomedical ultrasound beamforming, Ultrasound Med. Biol. 20 (5) (1994)
403–428.
[96] J. Quistgaard, Signal acquisition and processing in medical diagnostic ultrasound, IEEE Signal Process.
Mag. 14 (1) (1997) 67–74.
[97] Z. Wang, J. Li, R. Wu, Time-delay- and time-reversal-based robust Capon beamformers for ultrasound
imaging, IEEE Trans. Med. Imag. 24 (2005) 1308–1322.
[98] S. Sanei, J. Chambers, EEG Signal Processing, Wiley & Sons, Ltd., West Sussex, England, 2007.
[99] P. Nunez, R. Srinivasan, Electric Fields of the Brain: The Neurophysis of EEG, Oxford University Press,
2006.
[100] T. Handy (Ed.), Brain Signal Analysis, Advances in Neuroelectric and Neuromagnetic Methods, MIT Press,
2009.
[101] Y. Salu, L.G. Cohen, D. Rose, S. Sato, C. Kufta, M. Hallett, An improved method for localizing electric
brain dipoles, IEEE Trans. Biomed. Eng. 37 (7) (1990) 699–705.
[102] J.C. de Munck, The estimation of time varying dipoles on the basis of evoked potentials, Electroencephalogr.
Clin. Neurophysiol. 77 (1990) 156–160.
[103] J. Mosher, P. Lewis, R. Leahy, Multiple dipole modeling and localization from spatio-temporal MEG data,
IEEE Trans. Biomed. Eng. 39 (6) (1992) 541–557.
[104] J.W. Phillips, R.M. Leahy, J.C. Mosher, MEG-based imaging of focal neuronal current sources, IEEE Trans.
Med. Imag. 16 (3) (1997) 338–348.
[105] B. van Veen, W. van Drongelen, M. Yuchtman, A. Suzuki, Localization of brain electrical activity
via linearly constrained minimum variance spatial ﬁltering, IEEE Trans. Biomed. Eng. 44 (9) (1997)
867–880.
[106] B. Lutkenhoner, Dipole source localization by means of maximum likelihood estimation: theory and simu-
lations, Electroencephalogr. Clin. Neurophysiol. 106 (1998) 314–321.
[107] B. Cufﬁn, EEG dipole source localization, IEEE Eng. Med. Bio. Mag. 17 (5) (1998) 118–122.
[108] Z. Koles, Trends in EEG source localizatoin, Electroencephalogr. Clin. Neurophysiol. 106 (1998) 127–137.
[109] L. Zhukov, D. Weinstein, C. Johnson, Independent component analysis for EEG source localization, IEEE
Eng. Med. Bio. Mag. 19 (3) (2000) 87–96.
[110] D. Yao, Electric potential produced by a dipole in a homogeneous conducting sphere, IEEE Trans. Biomed.
Eng. 47 (7) (2000) 964–966.
[111] S. Baillet, J.C. Mosher, R.M. Leahy, Electromagnetic brain mapping, IEEE Signal Process. Mag. 18 (6)
(2001) 14–30.

References and Further Reading
951
[112] J.C. de Munck, H.M. Huizenga, L.J. Waldorp, R.A. Heethaar, Estimating stationary dipoles from MEG/EEG
data contaminated with spatially and temporally correlated background noise, IEEE Trans. Signal Process.
50 (7) (2002) 1565–1572.
[113] C. Michela, M. Murraya, G. Lantza, S. Gonzaleza, L. Spinellib, R.G. de Peralta, EEG source imaging, Clin.
Neurophysiol. 115 (2004) 2195–2222.
[114] K. Sekihara, K. Hild, S. Nagarajan, A novel adaptive beamformer for MEG source reconstruction effective
when large background brain activities exist, IEEE Trans. Biomed. Eng. 53 (9) (2006) 1755–1764.
[115] T. Ferree, P. Nunez, Primer on electroencephalography for functional connectivity, in: V. Jirsa, A. McIntosh
(Eds.), Handbook of Brain Connectivity, Springer-Verlag, 2007, pp. 169–200.
[116] K. Sekihara, K. Hild, S.S. Dalal, S. Nagarajan, Performance of prewhitening beamforming in MEG dual
experimental conditions, IEEE Trans. Biomed. Eng. 55 (3) (2008) 1112–1121.
[117] S.C. Wu, A.L. Swindlehurst, P.T. Wang, Z. Nenadic, Projection vs. prewhitening for EEG interference
suppression, IEEE Trans. Biomed. Eng. 59 (5) (2012) 1329–1338.
[118] S.C. Wu, A.L. Swindlehurst, P.T. Wang, Z. Nenadic, Efﬁcient dipole parameter estimation in EEG systems
with near-ML performance, IEEE Trans. Biomed. Eng. 59 (5) (2012) 1339–1348.
[119] S. Gibson, J.W. Judy, D. Markovic, Spike sorting: the ﬁrst step in decoding the brain, IEEE Signal Process.
Mag. 29 (1) (2012) 124–143.
[120] C.M. Gray, P.E. Maldonado, M. Wilson, B. McNaughton, Tetrodes markedly improve the reliability and
yield of multiple single-unit isolation from multi-unit recordings in cat striate cortex, J. Neurosci. Methods
63 (1995) 43–54.
[121] S. Takahashi, Y. Sakurai, M. Tsukada, Y. Anzai, Classifcation of neuronal activities from tetrode recordings
using independent component analysis, Neurocomputing 49 (2002) 289–298.
[122] S. Takahashi, Y. Anzai, Y. Sakurai, A new approach to spike sorting for multi-neuronal activities recorded
with a tetrode: how ICA can be practical, Neurosci. Res. 46 (2003) 265–272.
[123] M.I. Chelaru, M.S. Jog, Spike source localization with tetrodes, J. Neurosci. Meth. 142 (2005) 305–315.
[124] S. Micera, L. Citi, J. Rigosa, J. Carpaneto, S. Raspopovic, G.D. Pino, L. Rossini, K. Yoshida, L. Denaro,
P. Dario, P.M. Rossini, Decoding information from neural signals recorded using intraneural electrodes:
toward the development of a neurocontrolled hand prosthesis, Proc. IEEE 98 (3) (2010) 407–417.
Sonar
[125] W.C. Knight, R.G. Pridham, S.M. Kay, Digital signal processing for sonar, IEEE Proc. 69 (11) (1981)
1451–1506.
[126] R.J. Urick, Principles of Underwater Sound, third ed., John Wiley & Sons, West Sussex, England, 1983.
[127] R.G. Fizell, S.C. Wales, Source localization in range and depth in an arctic environment, J. Acoust. Soc. Am.
Suppl. 78 (1985) p. S57.
[128] N.L. Owsley, Array Signal Processing, Prentice Hall, 1985.
[129] L. Brekhovskikh, Y. Lysanov, Fundamentals of Ocean Acoustics, Springer-Verlag, New York, 1991.
[130] Special issue on detection and estimation in matched—ﬁeld processing, IEEE J. Ocean. Eng. 18 (3) (1993)
156–270.
[131] A.B. Baggeroer, W.A. Kuperman, P.N. Mikhalevsky, An overview of matched ﬁeld methods in ocean acous-
tics, IEEE J. Ocean. Eng. 18 (4) (1993) 401–424.
[132] A. Tolstoy, Matched Field Processing for Underwater Acoustics, World Scientiﬁc, Singapore, 1993.
[133] A. Nehorai, E. Paldi, Acoustic vector-sensor array processing, IEEE Trans. Signal Process. 42 (9) (1994)
2481–2491.
[134] D.W. Tufts, J.P. Ianniello, I. Lourtie, J.C. Preisig, J.M.F. Moura, The past, present, and future of underwater
acoustic signal processing, IEEE Signal Process. Mag. 15 (4) (1998) 21–51.

952
CHAPTER 20 Applications of Array Signal Processing
[135] M. Hawkes, A. Nehorai, Effects of sensor placement on acoustic vector-sensor array performance, IEEE J.
Oceanic Eng. 24 (1999) 33–40.
[136] A.D. Waite, Sonar for Practising Engineers, third ed., West Sussex, England, 2002.
[137] M. Hawkes, A. Nehorai, Wideband source localization using a distributed acoustic vector-sensor array, IEEE
Trans. Signal Process. 51 (6) (2003) 1479–1491.
[138] W. Xu, A.B. Baggeroer, C.D. Richmond, Bayesian bounds for matched—ﬁeld parameter estimation, IEEE
Trans. Signal Process. 52 (12) (2004) 3293–3305.
Microphone arrays
[139] J. Flanagan, J. Johnston, R. Zahn, G. Elko, Computer-steered microphone arrays for sound transduction in
large rooms, J. Acoust. Soc. Am. 78 (5) (1985) 1508–1518.
[140] Y. Kaneda, J. Ohga, Adaptive microphone-array system for noise reduction, IEEE Trans. Acoust. Speech
Signal Process. ASSP-34 (6) (1986) 1391–1400.
[141] Y. Grenier, A microphone array for car environments, Speech Commun. 12 (1993) 25–39.
[142] B. Ferguson, B. Quinn, Application of the short-time Fourier transform and the Wigner-Ville distribution to
the acoustic localization of aircraft, J. Acoust. Soc. Am. 96 (1994) 821–827.
[143] M. Hoffman, K. Buckley, Robust time-domain processing of broadband microphone array data, IEEE Trans.
Speech Audio Process. 3 (3) (1995) 193–203.
[144] S.Fischer,K.Simmer,Beamformingmicrophonearraysforspeechacquisitioninnoisyenvironments,Speech
Commun. 20 (1996) 215–227.
[145] G. Elko, Microphone array systems for hands-free telecommunication, Speech Commun. 20 (1996) 229–240.
[146] S. Affes, Y. Grenier, A signal subspace tracking algorithm for microphone array processing of speech, IEEE
Trans. Speech Audio Process. 5 (5) (1997) 425–437.
[147] B. Ferguson, Time-delay estimation techniques applied to the acoustic detection of jet aircraft transits,
J. Acoust. Soc. Am. 106 (1) (1999) 255–264.
[148] M. Dahl, I. Claesson, Acoustic noise and echo canceling with microphone array, IEEE Trans. Veh. Tech. 48
(5) (1999) 1518–1526.
[149] J. Benesty, Adaptive eigenvalue decomposition algorithm for passive acoustic source localization, J. Acoust.
Soc. Am. 107 (1) (2000) 384–391.
[150] Y. Huang, J. Benesty, G. Elko, M. Mersereau, Real-time passive source localization: a practical linear-
correction least-squares approach, IEEE Trans. Speech Audio Process. 9 (8) (2001) 943–956.
[151] J. Chen, L. Yip, J. Elson, H. Wang, D. Maniezzo, R. Hudson, K. Yao, D. Estrin, Coherent acoustic array
processing and localization on wireless sensor networks, Proc. IEEE 91 (8) (2003) 1154–1162.
[152] T. Gustafsson, B. Rao, M. Trivedi, Source localization in reverberant environments: modeling and statistical
analysis, IEEE Trans. Speech Audio Process. 11 (6) (2003) 791–803.
[153] R. Kozick, B. Sadler, Source localization with distributed sensor arrays and partial spatial coherence, IEEE
Trans. Signal Process. 52 (3) (2004) 601–616.
[154] Z. Li, R. Duraiswami, Flexible and optimal design of spherical microphone arrays for beamforming, IEEE
Trans. Audio Speech Lang. Process. 15 (2) (2007) 702–714.
[155] J. Benesty, J. Chen, Y. Huang, J. Dmochowski, On microphone-array beamforming from a MIMO acoustic
signal processing perspective, IEEE Trans. Audio Speech Lang. Process. 15 (3) (2007) 1053–1065.
[156] X. Zhao, Z. Ou, Closely coupled array processing and model-based compensation for microphone array
speech recognition, IEEE Trans. Audio Speech Lang. Process. 15 (3) (2007) 1114–1122.
[157] J. Benesty, J, Chen, Y. Huang, Microphone Array Signal Processing, Springer Verlag, 2008.
[158] M. Brandstein, D. Ward (Eds.), Microphone Arrays—Signal Processing Techniques and Applications,
Springer Verlag, 2010.

References and Further Reading
953
Chemical sensor arrays
[159] A. Nehorai, B. Porat, E. Paldi, Detection and localization of vapor-emitting sources, IEEE Trans. Signal
Process. 43 (1) (1995) 243–253.
[160] A. Gershman, V. Turchin, Nonwave ﬁeld processing using sensor array approach, Signal Process. 44 (1995)
197–210.
[161] B. Porat, A. Nehorai, Localizing vapor-emitting sources by moving sensors, IEEE Trans. Signal Process.
44 (4) (1996) 1018–1021.
[162] A. Jerémic, A. Nehorai, Design of chemical sensor arrays for monitoring disposal sites on the ocean ﬂoor,
IEEE J. Ocean. Eng. 23 (4) (1998) 334–343.
[163] Y. Nievergelt, Solution to an inverse problem in diffusion, SIAM Rev. 40 (1) (1998) 74–80.
[164] A. Jerémic, A. Nehorai, Landmine detection and localization using chemical sensor array processing, IEEE
Trans. Signal Process. 48 (5) (2000) 1295–1305.
[165] J. Matthes, L. Gröll, H. Keller, Source localization based on pointwise concentration measurements, Sensor.
Actuat. A: Phys. 115 (2004) 32–37.
[166] J. Matthes, L. Gröll, H. Keller, Source localization by spatially distributed electronic noses for advection and
diffusion, IEEE Trans. Signal Process. 53 (5) (2005) 1711–1719.
[167] T. Zhao, A. Nehorai, Detecting and estimating biochemical dispersion of a moving source in a semi-inﬁnite
medium, IEEE Trans. Signal Process. 54 (6) (2006) 2213–2225.
[168] S. Vijayakumaran, Y. Levinbook, T. Wong, Maximum likelihood localization of a diffusive point source
using binary observations, IEEE Trans. Signal Process. 55 (2) (2007) 665–676.
[169] M. Ortner, A. Nehorai, A. Jerémic, Biochemical transport modeling and Bayesian source estimation in
realistic environments, IEEE Trans. Signal Process. 55 (6) (2007) 2520–2532.

955
A
Acoustic signal processing
chemical sensor arrays, 943
microphone arrays, 938, 940
Adaptive ATC strategy, 394
Adaptive beamforming algorithms, 482, 508
algorithms employing
spatial reference, 900
temporal reference, 901
basic principles, 508
blind algorithms, 902
general-rank source, 513
gradient adaptive beamforming algorithms, 513
hybrid beamformers, 901
MVDR beamforming with data covariance matrix, 512
optimal SINR, 512
projection adaptive beamforming methods, 515
reduced complexity approaches to adaptive  
beamforming, 516
sample matrix inversion adaptive beamformer, 514
wideband adaptive beamforming, 519
Adaptive broadband beamforming, 584
Adaptive combination weights, 401, 412
Adaptive CTA strategy, 393
Adaptive diffusion strategies with smoothing mechanisms, 415
Adapt-then-combine (ATC) diffusion strategy, 353
Aeroacoustic source localization, 940–941
Affine transforms, 53–54
AIC. See Akaike information criterion (AIC)
Airborne fast vehicles, 278
Airborne slow vehicles, 280
Akaike information criterion (AIC), 12, 17, 635
Algorithms using tensor-based subspace estimates, 698
R-D NC standard tensor-ESPRIT, 700
R-D NC unitary tensor-ESPRIT, 702–703
R-D standard tensor-ESPRIT, 698–699
R-D unitary tensor-ESPRIT, 699
Ambiguity function, 77
Angle-Doppler spectra, 870
Aperture theory, 556
Array aperture, 819–820
Array-based parameter estimators, 904–905
GNSS-specific signal models, 906
structured spatial signatures and spatially white noise, 905
structured spatial signatures and unknown spatial  
correlation, 905
unstructured spatial signatures and spatially white noise, 905
unstructured spatial signatures and unknown spatial  
correlation, 905
Array calibration, 829–830
robust beamforming using, 848
Array geometries, 557
Array interpolation technique, 836
Array nonidealities, 825
array elements’ beampatterns and positions, 826
cross-polarization effects, 827
mutual coupling, 825
narrowband signal model, 828
nonlinear elements, effects of, 829
receiver front-end architectures, 828
Array processing
beam forming and signal detection, 480
adaptive beamforming, 482
signal detection, 485
spatial filter design, 480
direction-of-arrival estimation, 486
beamforming methods, 487
modeling errors and array calibration, 492
parametric methods, 489
subspace methods, 488
geometric data model, 465
ideal data model, 466
non-ideal data models, 470
wave propagation, 465
non-Coherent array applications, 493
microwave and ultrasound imaging, 497
sensor networks, source localization in, 497
spread sources, 493
time series modeling, 495
spatial filtering and beam patterns, 471
one-dimensional arrays, 472
spatial filtering, 471
two-dimensional arrays, 475
wideband array response, 477
Array signal processing
adaptive and robust beamforming, 458
applications of, 460
array processing, 458
azimuth, elevation, and polarization estimation, 850, 852
biomedical applications, 917
broadband beamforming and optimization, 458
classification of techniques, 821
DOA estimation, 846–848
methods and algorithms, 458
Index

956
Index
of nonstationary signals, 459
performance bounds and statistical analysis of, 459
examples, 846
face of non idealities, 460
history, 457
ideal array signal models, 821
multi-input multi-output (MIMO) radar, 870–871
nonstationary signals, 459
outlook, 461
polynomial rooting techniques, 849
positioning and navigation, 893–894
radar applications, 860–862
radio astronomy, 875–876
robust beamforming using array calibration, 848
robust methods, 842–843
sonar, 928–929
source localization and tracking, 460
special array structures, subspace methods and  
exploitation of, 459
wireless communications, 907
Array steering vectors, 820
Astronomical phased array feeds, 885
beamformer calculation, 888
calibration, 888
radio camera results, 889
signal model, 886–888
Asymptotic analysis
and central limit theorem, 313
and parametric models, 315
Asymptotic distribution
estimated DOA, 736
beamforming-based algorithms, 737–738
high-order algorithms, 750
maximum likelihood algorithms, 738
robustness of algorithms, 747
second-order algorithms, 743–744
subspace-based algorithms, 745
of statistics, 724
Asymptotic regime, 194
Attenuation, 803
Autoregressive (AR) modeling, 328
cooperative adaptation through diffusion, 334
linear model, 328
non-cooperative adaptive solution, 331
non-cooperative mean-square-error solution, 330
B
Bandwidth, 876
Bayesian computational methods, 5
computational methods, 161
expectation-maximization (EM), for MAP  
estimation, 162
Markov chain Monte Carlo (MCMC), 163
parameter estimation, 143
Bayesian inference, 147
Bayesian model averaging, 161
linear Gaussian model, 144
maximum likelihood (ML) estimation, 146
model uncertainty and Bayesian decision theory, 158
model uncertainty, structures for, 161
particle filtering and auxiliary sampling, 169
marginalized particle filters, 171
particle filters, 177
probability densities and integrals, 178
gamma density, 180
inverse Wishart distribution, 182
inverted-gamma distribution, 180
multivariate Gaussian, 178
normal-inverted-gamma distribution, 181
univariate Gaussian, 178
Wishart distribution, 181
state-space models and sequential inference, 164
linear Gaussian state-space models, 164
prediction error decomposition, 166
sequential Monte Carlo (SMC), 167
Bayesian formulation, 190, 210
Bayesian i.i.d. setting, 217
Bayesian inference, 147
covariance matrices, priors on, 157
G-prior, 157
hyperparameters and marginalization, of unwanted  
parameters, 152
linear Gaussian model, hyperparameters for, 153
linear Gaussian model, parameters in, 151
Marginal likelihood, 152
normal-inverted-gamma prior, 154
posterior inference and Bayesian cost functions, 149
Bayesian information criterion (BIC), 14
Bayesian model averaging, 161
Bayesian quickest change detection, 217
Bayesian source localization, 808–809
Beamformer architecture, 887
Beam forming and signal detection, 480
Beamforming-based algorithms, 737–738
Beamforming methods, 487
Beamforming process, 860, 898
adaptive beamforming algorithms, 899
deterministic, 903
Beamspace processing, 638
BIC. See Bayesian information criterion (BIC)
Binary hypothesis testing problem, 188
Binary RSS measurements, 289
Biomedical applications, array signal processing, 917
electroencephalography (EEG), 918
magnetoencephalography (MEG) signal processing, 918
Array signal processing (Continued)

957
Index
multi-sensor extracellular probes, 923, 925–926
ultrasound imaging, 918
Biomedical signal analysis, 137
Blackman window, 32
Block maximum norm, 435
Bootstrap methods, 12
Bootstrapping, 14
Born-Jordan distribution, 83
Broadband beamformer, 574
Broadband beamforming and optimization
adaptive broadband beamforming, 584
common signal modeling, 584
frequency domain, generalized sidelobe canceler in, 589
frequency domain Wiener filter, 591
generalized sidelobe canceler (GSC), 587
LCMV in frequency domain, 586
linearly constrained minimum variance (LCMV)  
beamforming, 584
Wiener filter, 590
design in element space, 558
broadband beamformer, 574
Chebyshev design, 563
design examples, 568
model and robust formulation, 563
robust Chebyshev design, 567
robust total least squares design, 567
robust WLS design, 566
steerable broadband beamformer, 571
total least squares design and Eigen-filters, 562
weighted least square (WLS) design, 561
design using wave equation, 574
design examples, 582
spherical broadband beamformer, 581
wave equation, 579
environment and channel modeling, 556
aperture theory, 556
array geometries, 557
examples for optimal beamformers, 593
optimal near-field signal-to-noise plus interference  
beamformer (SNIB), 591
frequency domain formulation, 593
time domain formulation, 591
Butterworth distribution, 83
C
Capon beamformer. See Minimum variance distortionless 
response (MVDR) beamformer
Car engine signal analysis, 137
Cellular phones, 285
binary RSS measurements, 289
continuous RSS measurements, 286
Chair-Varshney fusion rule, 200
Channel aware distributed detection, 197
Chebyshev design, 563
Chemical sensor arrays, 943
Chirplet transform, 53–54
Closed-loop multiplexing schemes, 910–911
Closely spaced sources, resolution of, 755
CRB, angular resolution limit, 757–758
detection theory, angular resolution limit, 758–759
mean null spectra, angular resolution limit, 755
Cognitive radio, 250
Cohen class of distributions, 80
auto-terms form, 87
reduced interference distributions, 83
Coherent processing interval (CPI), 865
Collaborative spectral sensing, 341
Combination weights, 396
Combine-then-adapt (CTA) diffusion strategy, 355
Common signal modeling, 584
Complex argument distribution, 114
Computational methods, 161
Computer network security, 250
Conditional independence assumption, 190
asymptotic regime, 194
Bayesian formulation, 190
decision fusion problem, 192
Neyman-Pearson formulation, 191
Consensus recursion, 442
Consensus strategies, comparison with, 442
Constant combination weights, 397
Constrained Cramér-Rao bound (CCRB), 308
Constrained maximum-likelihood estimation (CMLE), 310
Continuous RSS measurements, 286
Controlled Reception Pattern Antennas (CRPAs), 898
Conventional beamformer, 605
Convergence behavior, 368
Convergence in mean, 409
Cooperative adaptation through diffusion, 334
Coordinated Multipoint transmission (CoMP), 913
Copula theory, 199
Covariance matching estimation methods, 626
Covariance matrices, priors on, 157
CPI. See Coherent processing interval
Cramér-Rao bounds (CRB), 9, 303, 729
bias-informed, 301
Gaussian deterministic case, 732
Gaussian stochastic case, 730
general CRB expression, 301
non Gaussian case, 733–734
on parameter estimation, 299
properties, 302
transformations, 301
Cramer-Rao Lower Bound (CRLB), 263, 824, 837
Biomedical applications (Continued)

958
Index
CRB. See Cramér-Rao bounds (CRB)
CRLB. See Cramer-Rao Lower Bound (CRLB)
Cross-polarization discrimination (XPD), 827
Cross-polarization effects, 827
Cross-validation (CV), 12
CRPAs. See Controlled Reception Pattern Antennas
CuSum procedure, 211
CV. See Cross-validation (CV)
D
Data and beamforming models, 504
narrowband case, 505
general-rank source, 506
point source, 505
wideband case, 507
Data association problem, 802
Data-driven techniques, 834
array calibration matrix, local interpolation of, 834–835
array interpolation technique, 836
manifold separation technique, 837, 842
wavefield modeling principle, 837, 842
Data-efficient quickest change detection, 244
Data model, 374, 654
general data model, 655, 657
non-circular data, 665, 667
notation, 654
special array structures, 657
Dead-reckoning model, 259, 272
dynamical models, 273
inertial models, 273
marginalization of speed, 273
odometric models, 272
Decision fusion problem, 192
Degrees of freedom (DOF), 16–17
DE-Shiryaev algorithm, 245
Design using wave equation, 574
Diagonally loaded SMI beamformer, 522
Diffusion adaptation over networks, 5
adaptive diffusion strategies, 359, 374
convergence in mean, 379
data model, 374
error recursions, 377
mean-square performance, of individual nodes, 387
mean-square stability, 381
network mean-square performance, 386
performance measures, 375
transient mean-square performance, 390
uniform data profile, 389
Block maximum norm, 435
combination weights, 396
adaptive combination weights, 401
constant combination weights, 397
optimizing combination weights, 398
consensus recursion, 442
consensus strategies, comparison with, 442
cooperative strategies, 391
ATC and CTA strategies, 392
information exchange, 393
non-cooperative strategy, 394
distributed optimization via diffusion strategies, 345
adapt-then-combine (ATC) diffusion strategy, 353
combine-then-adapt (CTA) diffusion strategy, 355
global cost to neighborhood costs, 347
properties of diffusion strategies, 357
steepest-descent iterations, 351
error recursion, 443
extensions and variations, 414
adaptive diffusion strategies with smoothing  
mechanisms, 415
diffusion distributed optimization, 426
diffusion Kalman filtering, 423
diffusion recursive least-squares, 419
graph laplacian and network connectivity, 430
mean-square-error estimation, 327
autoregressive modeling, 328
collaborative spectral sensing, 341
tapped-delay-line models, 334
target localization, 336
motivation, 323
cooperation among agents, 326
networks and neighborhoods, 324
notation, 326
noisy information exchanges, 403
adaptive combination weights, 412
convergence in mean, 409
error recursion, 405
mean-square convergence, 410
noise sources over exchange links, 404
properties of Kronecker products, 430
steepest-descent diffusion strategies, 364
convergence behavior, 368
error recursions, 366
general diffusion model, 364
stochastic matrices, 433
Diffusion distributed optimization, 426
noiseless updates, 427
updates with gradient noise, 428
Diffusion Kalman filtering, 423
Diffusion recursive least-squares, 419
Direction of arrival (DOA), 823–824, 832
estimation techniques, 463, 486, 779
effect of cross-terms, 784
signal stationarization, 787–788

959
Index
spatial joint-variable domain distributions, 788
time-frequency maximum likelihood method, 782–784
time-frequency MUSIC, 780
wideband nonstationary signals, 788–789
Discrete pseudo Wigner distribution, 75
Discrete S-method, 91
Discrete STFT, signal reconstruction form, 44
Discrete wavelet transform, 927
Distributed sensor systems, 247
Distributed signal detection, 4
with dependent observations, 198
with independent observations
channel aware distributed detection, 197
conditional independence assumption, 190
energy efficient distributed detection, 197
multi-objective optimization, 197
network topologies, 194
nonparametric rules, in distributed detection, 196
DOA. See Direction of arrival (DOA)
DOA estimation methods and algorithms
background, 599
beamforming methods, 604
conventional beamformer, 605
minimum variance distortionless response (MVDR)  
beamformer, 606
numerical examples, 609
sparse data representation based approach, 607
beamspace processing, 638
data model, 600
frequency domain description, 601
uniqueness, 604
wave propagation, 600
distributed sources, 639
parametric methods, 617
covariance matching estimation methods, 626
implementation, 620
maximum likelihood approach, 618
numerical examples, 628
performance bound, 627
subspace fitting methods, 625
polarization sensitivity, 640
signal detection, 634
additional issues, 636
nonparametric methods, 634
parametric methods, 636
signals with known structures, 637
spatially correlated noise fields, 638
subspace methods, 610
estimation of signal parameters via rotational invariance 
techniques (ESPRIT) algorithm, 613
MUSIC algorithm, 612
numerical examples, 616
signal coherence, 614
tracking, 637
wideband DOA estimation, 631
coherent signal subspace methods, 633
wideband maximum likelihood estimation, 632
DOF. See Degrees of freedom (DOF)
Doob’s optional stopping theorem, 213
Doppler velocity log, 282
Doubly constrained robust adaptive beamforming, 539
Dynamical models, 273
E
EADF. See Effective aperture distribution function
ECoG measurements
unified dipole model, 919
EEG and MEG signal processing, 918
interference mitigation, 922–923
unified dipole model, 919
Effective aperture distribution function (EADF), 838–839
Eigen-filters, 562
Eigenspace-based beamformer, 537
Eigenvalue beamforming using multi-rank MVDR  
beamformer, 541
EKF. See Extended Kalman filter
Electroencephalography (EEG) signal processing, 918
Energy efficient distributed detection, 197
Environment and channel modeling, 556
Error recursion, 405, 443
comparison with diffusion strategies, 447
convergence conditions, 443
rate of convergence, 445
Error recursions, 366, 377
ESPRIT algorithm. See Estimation of signal parameters via 
rotational invariance techniques (ESPRIT) algorithm
Estimation of signal parameters via rotational invariance  
techniques (ESPRIT) algorithm, 613, 678
Expectation-maximization (EM) algorithm, 5
for MAP estimation, 162
Extended Invariance Principle (EXIP), 905
Extended Kalman filter (EKF), 264, 815
F
False alarm, 209–211
False discovery rate (FDR), 196
Far-field assumption, 601
Fast Fourier Transform (FFT), 3, 519
FDR. See False discovery rate (FDR)
Filter bank STFT implementation, 38
Finite impulse response digital filter, 803
Finite Impulse Response (FIR) filtering, 463
Direction of arrival (Continued)

960
Index
Fourier domain root-MUSIC, 689–690
Fourier transform, 315, 602
Fractional Fourier Transform, 769–772
Frequency domain description, 601
general model, 602
narrow band data, 603
Frequency domain formulation, 593
Frequency domain, generalized sidelobe canceler in, 589
Frequency domain Wiener filter, 591
Frequency Shift Transmit Diversity (FSTD), 908
FSTD. See Frequency Shift Transmit Diversity
Functional analysis, 723
G
Gabor transform, 45
Gamma density, 180
Gaussian case, 311
Gaussian deterministic case, 732
Gaussian model, 5
Gaussian stochastic case, 730
Gaussian window, 32
General asymptotic Bayesian theory, 221
General asymptotic minimax theory, 237
General diffusion model, 364
Generalized CuSum algorithm, 238
Generalized ESPRIT (GESPRIT), 681–682
Generalized likelihood ratio test (GLRT), 193, 196
Generalized likelihood ratio test (GLRT-) based sequential 
hypothesis testing, 10, 16
Generalized sidelobe canceler (GSC), 527, 587
Generalized weighted subspace fitting (GWSF) algorithm, 832
GeneralizedWigner Distribution (GWD), 60
Generalmaximumlikelihood theory, 16
General-rank signal model, 545
General statistical tools, DOA estimation, 723
AMVB and CRB, relationship, 735–736
asymptotically minimum variance bounds (AMVB), 
734–735
Cramer-Rao bounds (CRB), 729–730
specific algorithm, performance analysis of, 723
Geographical information system (GIS), 258
Geolocation, 6
Geolocation–maps
estimation methods, 260
extended Kalman filter, 264
mathematical framework, 260–261
nonlinear filtering, 261
nonlinear filter theory, 261
particle filter (PF), 267
unscented Kalman filter (UKF), 265
mapping in practice, 292
maps and applications, 276
airborne fast vehicles, 278
airborne slow vehicles, 280
cellular phones, 285
road-bound vehicles, 276
small migrating animals, 290
surface vessels, 283
underwater vessels, 282
motion models, 270
dead-reckoning model, 272
kinematic model, 274
theory, 259
Geometric data model, 465
Geometric triangulation, 799
Global cost to neighborhood costs, 347
Global Navigation Satellite Systems (GNSS), 893–894
beamforming, 898
error sources and benefits of antenna arrays, 894–896
Global Positioning System (GPS), 893
GLRT-based sequential hypothesis testing. See Generalized 
likelihood ratio test (GLRT-) based sequential  
hypothesis testing
GNSS. See Global Navigation Satellite Systems
G-prior, 157
Gradient adaptive beamforming algorithms, 513
Graph laplacian and network connectivity, 430
GWSF algorithm. See Generalized weighted subspace fitting 
algorithm
H
Hann(ing) window, 32
Heuristic approach, 9
Higher order time-frequency representations, 107
Hybrid time and frequency varying  
windows, 41
I
Ideal array signal models, 821
Ideal data model, 466
i.i.d. model with geometric prior, 225
Inertial models, 273
Information and coding theory based methods, 17
Inner interferences in Wigner distribution, 72
Instantaneous bandwidth, 65
Instantaneous frequency (IF)
distribution concentrated, 61
interpretation, 48
Inverse Wishart distribution, 182
Inverted-gamma distribution, 180
I/Q imbalances, 828–829

961
Index
K
Kaiser window, 32
Kalman filter, 814
nonlinear observation model, 815
prediction phase, 814
update phase, 814
Kalman gain, 175–176
Kernel constraint, 82
Kernel decomposition method, 88
Kernel transformations, 85
Kinematic model, 274
K-L divergence. See Kullback-Leibler (K-L) divergence
Kronecker products, properties of, 430
Kullback-Leibler (K-L) divergence, 10, 17–19, 218
L
LCMV in frequency domain, 586
Leaky Integrate-and-Fire model, 250
Least squares estimation, 316
Linear coordinate transforms, of Wigner distribution, 69
Linear Gaussian model, 144
hyperparameters for, 153
parameters in, 151
Linear Gaussian state-space models, 164
Linearly constrained minimum variance (LCMV)  
beamforming, 584
Linear model, 328
Linear signal transforms, 28
Local polynomial Fourier transform (LPFT), 50
Log posterior density, 14
Look direction mismatch (pointing error) problem, 523
Lorden’s problem, 230
Low system temperatures, 876
LSMI adaptive beamformers, 538
L-statistics in time-frequency, 131
L-Wigner distribution realization, 117
M
Magnetoencephalography (MEG) signal processing, 918
Manifold separation technique, 837, 842
Marginalization of speed, 275
Marginalized particle filters, 171
Marginal likelihood, 152
calculation of, 159
Markov chain Monte Carlo (MCMC), 5, 163
Markov transition matrix, 176
Martingales, 212
Matched field processing (MFP), 935
Matched subspace detector (MSD), 927–928
Mathematical framework, 260–261
Mathematical preliminaries, 212
Matrix-based subspace estimation, 667
Matrix perturbations, 307
Maximum likelihood algorithms, 738
asymptotic properties, 739
large sample ML approximations, 741–742
stochastic and deterministic algorithms, 738–739
Maximum likelihood approach, 618
deterministic maximum likelihood, 618
stochastic maximum likelihood, 619
Maximum likelihood (ML) estimation, 146
Maximum likelihood estimation (MLE), 303
MCMC. See Markov chain Monte Carlo (MCMC)
MDL. See Minimum description length (MDL)
Mean-square convergence, 410
Mean-square error bound, 305
Mean-square-error estimation, 327
Mean-square performance, of individual nodes, 387
Mean-square stability, 381
Method of direction of arrival estimation (MODE), 682, 684
Microphone arrays, 938–940
aeroacoustic source localization, 940–941
wideband adaptive beamforming, 941–942
Microwave and ultrasound imaging, 497
MIMO. See Multiple-input multiple-output (MIMO)
Minimax algorithms, optimality properties of, 234
Minimax approach, 211
Minimax quickest change detection, 228
Minimum description length (MDL), 10–19
Minimum variance distortionless response (MVDR)  
beamformer, 606, 823
Minimum-variance distortionless response (MVDR)  
space-time filter, 867–868
Mixture Kalman filter, 171
ML estimation. See Maximum likelihood (ML) estimation
MODE. See Method of direction of arrival estimation
Model and robust formulation, 563
Model-driven techniques, 830–831
Bayesian approach, 832–834
deterministic approach, 831–832
Modeling errors and array calibration, 492
Model order selection, 6
information and coding theory based methods, 17
Akaike information criterion (AIC), 17
minimum description length, 19
regression, variable selection in, 11
AIC and stepwise regression, 12
bootstrap methods, 12
cross-validation (CV), 12
statistical inference paradigms
Bayesian information criterion (BIC), 14
GLRT-based sequential hypothesis testing, 16
subspace methods, signals in, 21

962
Index
Model uncertainty
and Bayesian decision theory, 158
structures for, 161
Monte Carlo method (MCM), 317
Multi-dimensional algorithms, 690
R-D MODE, 694–695
R-D NC standard ESPRIT, 696
R-D NC unitary ESPRIT, 697–698
R-D RARE, 691–694
R-D standard ESPRIT, 690–691
R-D unitary ESPRIT, 691
Multi-objective optimization, 197
Multiple antennas techniques
IEEE 802.11, 915–916
LTE
diversity schemes, 907–908,
multiple user MIMO (MU-MIMO), 912–913
multiplexing schemes, 909–910
uplink MIMO, 913
WiMAX, 913–914
Multiple-input multiple-output (MIMO), 870–871
adaptive array processing at radar receivers, 874–875
direction-of-departure (DOD)/direction-of-arrival (DOA) 
estimation, 789–790
example, 792–793
flexible transmit beampattern synthesis, 871
joint DOD/DOA estimations, 791
signal model, 790
UAV equipped with, 872
Multiple signal classification (MUSIC) algorithm,  
612, 674–675
Fourier domain root-MUSIC, 689–690
interpolated root-MUSIC, 687–688
root-MUSIC, 676
unitary root-MUSIC, 677
weighted MUSIC, 675
Multiplicative and additive noise model, 310
Multi-sensor extracellular probes, 923, 925–926
data model, 926
multi-sensor feature extraction, 926
Multi-sensor feature extraction, 926
discrete wavelet transform, 927
matched subspace detector (MSD), 927–928
principal component analysis, 927
Multi-time Wigner higher order distribution (MTWD), 110
Multivariate Gaussian, 178
MUSIC. See Multiple signal classification
MVDR beamformer. See Minimum variance distortionless 
response beamformer
MVDR beamforming with data covariance matrix, 512
MVDR robust adaptive beamforming design, 536
N
Network mean-square performance, 386
Networks and neighborhoods, 324
Network topologies, 194
Neuroscience, 250
Neyman-Pearson formulation, 191
Noise, 803
Noise eigenvectors, 610
Noise sources over exchange links, 404
Noise subspace, 807–808
Noise vector, 11
Noisy information exchanges, 403
adaptive combination weights, 412
convergence in mean, 409
error recursion, 405
mean-square convergence, 410
noise sources over exchange links, 404
Non-coherent array applications, 493
Non-cooperative adaptive solution, 331
Non-cooperative mean-square-error solution, 330
Non-cooperative strategy, 394
Non Gaussian case, 733–734
Non-Gaussian case, 311
Non-ideal data models, 470
Nonlinear filtering, 261
Nonlinear filter theory, 261
Bayes optimal filter, 261
covariance bound, 263
Kalman filter, 264
mean and covariance, 263
Non-linear least square source localization, 809
least square solution, 810
nonlinear quadratic optimization, 809
source localization using table look-up, 810
Nonlinear observation model, 815
Nonlinear renewal theory, 216
Nonparametric rules, in distributed detection, 196
Non-stationary signal analysis, 5
Non-stationary signal analysis time-frequency approach
higher order time-frequency representations, 107
signal phase derivative and distributions definitions, 112
Wigner bispectrum, 107
Wigner higher order spectra, 108
Wigner multi-time distribution, 110
linear signal transforms, 28
discrete form and realizations of STFT, 36
Gabor transform, 45
generalization, 56
local polynomial Fourier transform, 50
short-time Fourier transform, 28
stationary phase method, 46
STFT and continuous wavelet transform, 52

963
Index
quadratic time-frequency distributions, 58
ambiguity function, 77
Cohen class of distributions, 80
Kernel decomposition method, 88
Rihaczek distribution, 58
S-method, 89
time-frequency, reassignment in, 99
time-frequency representations, affine class of, 104
Wigner distribution, 60
sparse signals in time-frequency, 124
compressive sensing, 131
concentration measures, 124
L-statistics in time-frequency, 131
sparse signals, 126
time-frequency analysis applications, 135
biomedical signal analysis, 137
car engine signal analysis, 137
seismic signal analysis, 137
spread spectrum systems, interference rejection in, 139
time-frequency radar signal processing, 135
time-variant filtering, 138
video sequence, velocities of moving objects, 138
watermarking, in space/spatial-frequency domain, 140
Nonstationary signals, 767
and time-frequency representations, 767
Normal-inverted-gamma distribution, 181
Normal-inverted-gamma prior, 154
Normalized maximum likelihood approach, 19
Notation, 326
Number of sources, detection of, 752
MDL criterion, 752–753
O
Odometric models, 272
One-dimensional algorithms, 674
Estimation of Signal Parameters via Rotational Invariance 
Techniques (ESPRIT), 678
Fourier domain root-MUSIC, 689–690
generalized ESPRIT (GESPRIT), 681–682
interpolated root-MUSIC, 687–688
manifold separation scheme, 688–689
method of direction of arrival estimation (MODE), 682, 684
MUSIC, 674–675
rank-reduction (RARE) DOA estimation method, 684, 686
root-MUSIC, 676
root-RARE, 686
unitary root-MUSIC, 677
weighted MUSIC, 675
One-dimensional arrays, 472
On-source minus off-source radiometric detection, 876
Open-loop multiplexing schemes, 911–912
Optimal near-field signal-to-noise plus interference  
beamformer (SNIB), 591
Optimal SINR, 512
Optimizing combination weights, 398
Orthogonal matching pursuit, 12
P
Parallel configuration, 189
Parallel factor (PARAFAC) analysis, 652
Parameter estimations, 772
Parameter identifiability, 722–723
Parametric array model, 720–721
Parametric methods, 489
Parametric statistical models, 298
Parsimony, principle of, 12
Particle filter (PF) illustration, 267, 269
Particle filtering and auxiliary sampling, 169
Path integration, 259
Performance analysis, 6
Performance analysis and bounds
asymptotic analysis and central limit theorem, 313
asymptotic analysis and parametric models, 315
Fourier transform, 315
least squares estimation, 316
asymptotic normality and MLE, 304
confidence intervals, 318
constrained Cramér-Rao bound and constrained MLE, 308
comments and properties of CCRB, 309
constrained CRB, 308
constrained MLE, 310
Cramér-Rao bound, 299
maximum likelihood estimation and CRB, 303
mean-square error bound, 305
Monte Carlo method (MCM), 317
approximate an expectation, 318
computing CRB via Monte Carlo, 318
multiplicative and non-Gaussian noise, 310
Gaussian case, 311
multiplicative and additive noise model, 310
Non-Gaussian case, 311
parametric statistical models, 298
perturbation methods, 306
matrix perturbations, 307
perturbation analysis of MLE, 308
perturbations and statistical analysis, 306
Performance bound, 627
ML methods, 627
subspace methods, 627
Performance measures, 375
Perturbation methods, 306
Phase distortion, 803
Non-stationary signal analysis (Continued)

964
Index
Polarization sensitivity, 640
Pollak’s problem, 231
Polynomial phase signal (PPS), 772
Polynomial Wigner-Ville distribution, 114, 118
Positioning and navigation, 893–894
array-based parameter estimators, 904–905
beamforming, 898
DOA estimation algorithms, 903
signal model, 896
Posterior inference and Bayesian cost functions, 149
Prediction error decomposition, 166
Predictor-corrector formulation, 169
Probability densities and integrals, 178
Probability distribution function (PDF), 799
Probability mass function (PMF), 815
Problem formulation, 721–722
Product higher order ambiguity function (PHAF), 124
Projection adaptive beamforming methods, 515
Pseudo and smoothed Wigner distribution, 73
Pseudo quantum signal representation, 64
Q
Q-factor transform, 53–54
Quadratic time-frequency distributions, 58
Quickest change detection, 4
applications of, 250
Bayesian quickest change detection, 217
Bayesian i.i.d. setting, 217
general asymptotic Bayesian theory, 221
independent and identically distributed model with  
geometric prior, 225
mathematical preliminaries, 212
martingales, 212
renewal and nonlinear renewal theory, 214
stopping times, 213
minimax quickest change detection, 228
general asymptotic minimax theory, 237
minimax algorithms, optimality properties of, 234
Shiryaev algorithm, minimax algorithms based on, 232
models, 240
variants and generalizations of the quickest change detection 
problem, 241
data-efficient quickest change detection, 244
distributed sensor systems, 247
with unknown pre- or post-change distributions, 241
variants of quickest change detection problem, 249
R
Radar applications, 860–862
space-time adaptive processing, 862
Radio astronomy, 875–876
astronomical phased array feeds, 885
challenges and solutions to, 891
synthesis imaging, 877–878
Radio frequency interference (RFI), 876
Rao-Blackwellized particle filter, 171
Real time distributions, 116
Received signal strength (RSS), 259
Received signal strength indicator (RSSI), 804
Rectangular window function, 30
Redundancy averaging, 622–623
Renewal and nonlinear renewal theory, 214
RFI. See Radio frequency interference
Rihaczek distribution, 58
Rissanen’s minimum description length (MDL), 635
Road-bound vehicles, 276
Robust adaptive beamforming, 521
comparison by simulation, 544
diagonally loaded SMI beamformer, 522
doubly constrained robust adaptive beamforming, 539
eigenspace-based beamformer, 537
eigenvalue beamforming using multi-rank MVDR  
beamformer, 541
forward-backward averaging and spatial smoothing, 533
generalized sidelobe canceler, 527
general-rank signal model, 545
look direction mismatch (pointing error) problem, 523
LSMI adaptive beamformers, 538
motivations, 521
MVDR robust adaptive beamforming design, 536
probabilistically constrained robust adaptive  
beamforming, 540
rapidly moving interferences, 535
sequential quadratic programming-based robust adaptive 
beamforming, 540
SOI and interferences, 529
steering vector estimation, 542
wideband robust adaptive beamforming, 546
worst-case-based robust adaptive beamforming, 538
Robust Chebyshev design, 567
Robust methods, 842–843
worst-case performance/optimization/uncertainty sets,  
843, 845
Robustness of algorithms, 747
robustness to array modeling errors, 749–750
robustness w.r.t. narrowband assumption, 747
Robust total least squares design, 567
Robust WLS design, 566
Role of adaptation, localization application, 340
S
Sample covariance matrix (SCM), 22
Sample matrix inversion adaptive beamformer, 514

965
Index
Scalogram, 53–54
SCM. See Sample covariance matrix (SCM)
Second-order algorithms, 743
Seismic signal analysis, 137
Semi-definite relaxation (SDR), 873
Sensor array, 819
Sensor networks, 250
Sensor networks, source localization in, 497
Sequential Monte Carlo (SMC), 167
Sequential quadratic programming-based robust adaptive 
beamforming, 540
Serial configuration, 195
Shiryaev algorithm, minimax algorithms based on, 232
Shiryaev-Roberts algorithm, 211
Shiryaev-Roberts-Pollak (SRP) algorithm, 232
Shiryaev-Roberts-r (SR-r) algorithm, 232
Shiryaev’s formulation, 210
Shiryaev statistic evolution, 209
Short-time Fourier transform (STFT), 28
continuous STFT inversion, 34
duration measures and uncertainty principle, 32
of multi-component signals, 35
windows, 30
Sigma points, 266
Signal assumptions, 721–722
Signal detection, 485, 634
Signal eigenvectors, 610
Signal intelligence (SIGINT), 819
Signal phase derivative and distributions definitions, 112
Signal propagation models, 802
angle of arrival estimation, 806–808
received signal strength indicator (RSSI), 804
time delay estimation, 805
Signal reconstruction, 62
Signal (source) separation problem, 802
Signal subspace, 807–808
Signal-to-noise ratio (SNR), 603
Signal to noise ratio (SNR) beamformer, 888
Simulation results, 703
1-D algorithms using matrix-based subspace estimates, 703, 
705–706
R-D algorithms using matrix-based subspace estimates, 706
Simultaneous localization and mapping (SLAM), 292
Sinc distribution, 83
SINR, 823
SLAM. See Simultaneous localization and mapping (SLAM)
Small migrating animals, 290
SMC. See Sequential Monte Carlo (SMC)
S-method, 89
discrete S-method, 91
multi-component signals, decomposition of, 97
versus smoothed spectrogram, 96
Soft-thresholding function, 249
Sonar, 928–929
acoustic vector sensors, 937–938
arrays, 929
matched field processing (MFP), 935
undersea acoustic channel, 932
Sound velocity, 932
Source localization algorithms, 808
Bayesian source localization, 808–809
non-linear least square source localization, 809
source localization using angle of arrival, 811–812
source localization using time difference of arrival, 810
Source localization and tracking
problem formulation, 800
signal propagation models, 802
source localization algorithms, 808
target tracking algorithm, 812
triangulation, 800
Source signal propagation model, 800
Space-time adaptive processing (STAP), 862, 602
Sparse data representation based approach, 607
Sparse signals in time-frequency, 124
Spatial filter design, 480
Spatial filtering, 471
Spatial filtering and beam patterns, 471
Spatial time-frequency distribution (STFD), 774
SNR enhancement, 775
subspace analysis, 777
SPC. See Statistical process control (SPC)
Special array structures, 657
centro-symmetric arrays, 659–660
minimum redundancy linear arrays, 658
multidimensional arrays, 661
partially calibrated arrays, 660–661
R-D shift invariance structure, 663
uniform circular array (UCA), 659–660
uniform linear arrays (ULAs), 657–658
uniform rectangular arrays (URAs), 659
Specific algorithm, performance analysis of, 723
asymptotic covariance and bias, 728–729
asymptotic distribution of estimated DOA, 727–728
asymptotic distribution of statistics, 724
functional analysis, 723
Spherical broadband beamformer, 581
Spread sources, 493
Spread spectrum systems, interference rejection in, 139
State-space models and sequential inference, 164
Stationary phase method, 46
Statistical process control (SPC), 250
Statistical signal processing
content, 3
contributions, 4
Bayesian computational methods, 5
bounds, 6

966
Index
diffusion adaptation over networks, 5
distributed signal detection, 4
geolocation, 6
model order selection, 6
non-stationary signal analysis, 5
performance analysis, 6
quickest change detection, 4
time-frequency approach, 5
historical recount, 3
Steepest-descent iterations, 351
Steerable broadband beamformer, 571
Steering vector estimation, 542
Steering vector model, 821–822
Stepwise regression, 12
STFD. See Spatial time-frequency distribution
STFT and continuous wavelet transform, 52
STFT, realizations of, 36
Stochastic complexity, concept of, 19
Stochastic matrices, 433
Stopping times, 213
Subspace-based algorithms, 674, 745
algorithms using tensor-based subspace estimates, 698
multi-dimensional algorithms, 690
one-dimensional algorithms, 674
simulation results, 703
Subspace estimation, 667
forward-backward averaging and real-valued, 671–672
matrix-based subspace estimation, 667
with small number of snapshots, 669
tensor-based subspace estimation, 672
Subspace fitting methods, 625
Subspace methods, 488
Synchronization issues, 252
Synthesis imaging, 876–878
algorithms for solving the imaging equation, 881
geometry and signal definitions, 878
The imaging equation, 878
T
Tapped-delay-line models, 334
Target localization, 336
Target tracking algorithm, 812
dynamic and observation models, 812–813
Kalman filter, 814
sequential Bayesian estimation, 813
TDoA. See Time Difference of Arrival
Tensor-based subspace estimation, 672
Time and frequency varying windows, 41
Time delay, 803
Time Difference of Arrival (TDoA), 805–806
Time domain formulation, 591
Time-frequency analysis applications, 135
Time-frequency approach, 5
Time-frequency maximum likelihood method, 782–784
examples, 784
Time-frequency MUSIC, 780
examples, 780–781
Time-frequency radar signal processing, 135
Time-frequency representations
Cohen’s class of, 767
examples, 769
Time-frequency representations, affine class of, 104
Time series modeling, 495
Time-variant filtering, 138
Time varying window, 41
Total least squares design and Eigen-filters, 562
Transient change detection, 251
Transient mean-square performance, 390
Triangulation, 800
angle based triangulation, 801–802
distance based triangulation, 800
generalizations, 802
geometric positions for, 801
Two-dimensional arrays, 475
U
UCA. See Uniform circular array
UKF. See Unscented Kalman filter
ULAs. See Uniform linear arrays
Uncertainty principle and Wigner distribution, 63
Undersea acoustic channel, 932
noise and reverberation, 934
propagation models, 932
transmission loss, 933–934
Uniform circular array (UCA), 659–660
Uniform data profile, 389
Uniform linear arrays (ULAs), 657–658
Uniform rectangular arrays (URAs), 659
Univariate Gaussian, 178
Unscented Kalman filter (UKF), 265, 815
URAs. See Uniform rectangular arrays
V
Variants and generalizations of the quickest change detection 
problem, 241
Variants of quickest change detection problem, 249
Video sequence, velocities of moving objects, 138
W
Wald’s identity, 213
Watermarking, in space/spatial-frequency domain, 140
Wave equation, 579
Wavefield modeling principle, 837, 842
Statistical signal processing (Continued)

967
Index
Wavefield parameters, 819–820
Wave propagation, 465, 600
Weighted least square (WLS) design, 561
Wideband adaptive beamforming, 519, 941–942
Wideband array response, 477
Wideband DOA estimation, 631
Wideband maximum likelihood estimation, 632
Wideband robust adaptive beamforming, 546
Wiener filter (WF), 482, 590
Wigner bispectrum, 107
Wigner distribution, 60
auto-terms and cross-terms, 70
based inversion and synthesis, 76
discrete pseudo, 75
inner interferences in, 72
instantaneous bandwidth, 65
instantaneous frequency, distribution concentrated, 61
linear coordinate transforms of, 69
properties of, 67
pseudo and smoothed, 73
pseudo quantum signal representation, 64
signal reconstruction, 62
uncertainty principle and, 63
Wigner higher order spectra, 108
Wigner multi-time distribution, 110
Wigner-Radon transform, 769–772
Wireless communications, 907
multiple antennas techniques, LTE, 907
Wishart distribution, 181
Worst-case-based robust adaptive beamforming, 538
Z
Zhao-Atlas-Marks distribution, 83

