Sylvain Duquesne
Svetla Petkova-Nikova (Eds.)
 123
LNCS 10064
6th International Workshop, WAIFI 2016
Ghent, Belgium, July 13–15, 2016
Revised Selected Papers
Arithmetic of Finite Fields

Lecture Notes in Computer Science
10064
Commenced Publication in 1973
Founding and Former Series Editors:
Gerhard Goos, Juris Hartmanis, and Jan van Leeuwen
Editorial Board
David Hutchison
Lancaster University, Lancaster, UK
Takeo Kanade
Carnegie Mellon University, Pittsburgh, PA, USA
Josef Kittler
University of Surrey, Guildford, UK
Jon M. Kleinberg
Cornell University, Ithaca, NY, USA
Friedemann Mattern
ETH Zurich, Zurich, Switzerland
John C. Mitchell
Stanford University, Stanford, CA, USA
Moni Naor
Weizmann Institute of Science, Rehovot, Israel
C. Pandu Rangan
Indian Institute of Technology, Madras, India
Bernhard Steffen
TU Dortmund University, Dortmund, Germany
Demetri Terzopoulos
University of California, Los Angeles, CA, USA
Doug Tygar
University of California, Berkeley, CA, USA
Gerhard Weikum
Max Planck Institute for Informatics, Saarbrücken, Germany

More information about this series at http://www.springer.com/series/7407

Sylvain Duquesne
• Svetla Petkova-Nikova (Eds.)
Arithmetic of Finite Fields
6th International Workshop, WAIFI 2016
Ghent, Belgium, July 13–15, 2016
Revised Selected Papers
123

Editors
Sylvain Duquesne
University of Rennes
Rennes
France
Svetla Petkova-Nikova
KU Leuven
Leuven
Belgium
ISSN 0302-9743
ISSN 1611-3349
(electronic)
Lecture Notes in Computer Science
ISBN 978-3-319-55226-2
ISBN 978-3-319-55227-9
(eBook)
DOI 10.1007/978-3-319-55227-9
Library of Congress Control Number: 2017933869
LNCS Sublibrary: SL1 – Theoretical Computer Science and General Issues
© Springer International Publishing AG 2016
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the
material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now
known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book are
believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors
give a warranty, express or implied, with respect to the material contained herein or for any errors or
omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in
published maps and institutional afﬁliations.
Printed on acid-free paper
This Springer imprint is published by Springer Nature
The registered company is Springer International Publishing AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Preface
These are the proceedings of WAIFI 2016, the 6th International Workshop on the
Arithmetic of Finite Fields, held in Ghent, Belgium, during July 13–15, 2016. The ﬁve
previous editions of this workshop were held in Madrid, Spain (WAIFI 2007), Siena,
Italy (WAIFI 2008), Istanbul, Turkey (WAIFI 2010), Bochum, Germany (WAIFI
2012), and Gebze, Turkey (WAIFI 2014). Springer has published all previous volumes
of the WAIFI proceedings in the LNCS series.
Since 2008, WAIFI has been held every even year, bringing together mathemati-
cians, computer scientists, engineers, and physicists who conduct research in different
areas of ﬁnite ﬁeld arithmetic.
The program consisted of three invited talks and 17 contributed papers. The invited
speakers were Swastik Kopparty (Rutgers University, USA), Simeon Ball (Universitat
Politècnica de Catalunya, Spain) and Razvan Barbulescu (CNRS, Paris 6 and 7,
France). The papers supporting the two last invited talks were also included in the
proceedings. The contributed talks were selected from 38 submissions, each of which
was assigned to at least three committee members or external reviewers chosen by the
members. Additionally, the Program Committee had a signiﬁcant online discussion
phase for several days. Three additional presentations were made during the workshop
but are not part of these proceedings.
We are very grateful to the members of the Program Committee for their dedication,
professionalism, and careful work with the review and selection process. We also
sincerely thank the external reviewers who contributed with their special expertise to
review papers for this workshop.
We deeply thank the general co-chairs, Vincent Rijmen and Leo Storme, for their
support of the Program Committee and their hard work in leading the overall organization
of the workshop helped by the Organizing Committee. We would also like to sincerely
thank members of the Steering Committee of the workshop series for their constant
support and encouragement in our efforts to create a stimulating scientiﬁc program leading
to this volume. Furthermore, we thank Jean-Jacques Quisquater for his valuable help in
publicity and we are also very grateful to José Luis Imaña and Jan de Beule for diligently
maintaining the workshop website. As with the previous volumes, Springer agreed to
publish the revised and expanded versions of the WAIFI 2016 papers as an LNCS volume.
We thank Alfred Hoffman and Anna Kramer from Springer for making this possible.
The submission and selection of papers were done using the EasyChair conference
management system. Hence, thank you EasyChair! We would also like to acknowledge
the Foundation Compositio Mathematica and FWO for being sponsors of the workshop.
Finally, but most importantly, we deeply thank all the authors who submitted their
papers to the workshop and the participants all over the world who chose to honor us
with their attendance.
February 2017
Sylvain Duquesne
Svetla Petkova-Nikova

Organization
Steering Committee
Berk Sunar
Worcester Polytechnic Institute, USA
Anwar Hasan
University of Waterloo, Canada
Çetin Kaya Koç
University of California Santa Barbara, USA
Jean-Jacques Quisquater
Université Catholique de Louvain, Belgium
Christof Paar
Ruhr-Universität Bochum, Germany
Gustavo Sutter
Autonomous University of Madrid, Spain
José Luis Imaña
Complutense University of Madrid, Spain
Francisco
Rodriguez-Henriquez
CINVESTAV-IPN, Mexico
Ferruh Ozbudak
Middle East Technical University, Turkey
Sihem Mesnager
University of Paris 8, France
Erkay Savaş
Sabanci University, Turkey
Claude Carlet
University of Paris 8, France
General Co-chairs
Vincent Rijmen
KU Leuven, Belgium
Leo Storme
Ghent University, Belgium
Local Organizing Committee
Daniele Bartoli
Ghent University, Belgium
Wouter Castryck
Ghent University, Belgium
Maarten De Boeck
Ghent University, Belgium
John Sheekey
Ghent University, Belgium
Leo Storme
Ghent University, Belgium
Peter Vandendriessche
Ghent University, Belgium
Geertrui Van de Voorde
Ghent University, Belgium
Jan De Beule
Vrije Universiteit Brussel, Belgium
Vincent Rijmen
KU Leuven, Belgium
Bart Preneel
KU Leuven, Belgium
Jan Tuitman
KU Leuven, Belgium
Jean-Jacques Quisquater
Université Catholique de Louvain, Belgium
Joost Vercruysse
Université Libre de Bruxelles, Belgium
Program Co-chairs
Sylvain Duquesne
University of Rennes 1, France
Svetla Petkova-Nikova
KU Leuven, Belgium

Publicity Chair
Jean-Jacques Quisquater
Université Catholique de Louvain, Belgium
Program Committee
Tsonka Baicheva
Bulgarian Academy of Sciences, Bulgaria
Jean-Claude Bajard
University Pierre et Marie Curie, France
Josep Balasch
KU Leuven, Belgium
Anne Canteaut
Inria Rocquencourt, France
Claude Carlet
University of Paris 8, France
Luca De Feo
University of Versailles-Saint Quentin, France
Sylvain Duquesne
University Rennes 1, France
Tor Helleseth
University of Bergen, Norway
Sophie Huczynska
University of St. Andrews, UK
Alexander Kholosha
University of Bergen, Norway
Miroslav Knezevic
KU Leuven and NXP Semiconductors, Belgium
Gohar Kyureghyan
University of Magdeburg, Germany
Ivan Landzhev
New Bulgarian University, Bulgaria
Gregor Leander
Ruhr University Bochum, Germany
Sihem Mesnager
University of Paris 8, France
Amir Moradi
Ruhr University Bochum, Germany
Gary Mullen
Penn State University, USA
Svetla Petkova-Nikova
KU Leuven, Belgium
Daniel Panario
Carleton University, Canada
Ruud Pellikaan
Technical University Eindhoven, The Netherlands
Alexander Pott
Otto von Guericke University, Germany
Christophe Ritzenthaler
University of Rennes 1, France
Leo Storme
Ghent University, Belgium
Arnaud Tisserand
CNRS, University of Rennes 1, France
Frederik Vercauteren
KU Leuven, Belgium
Paul Zimmermann
Inria Nancy - Grand Est, France
Additional Reviewers
Domingo Gomez
University of Cantabria, Spain
Sujoy Sinha Roy
KU Leuven, Belgium
Valentin Suder
University of Versailles Saint-Quentin, France
Nicolas Estibals
University of Rennes 1, France
Kanat Abdukhalikov
United Arab Emirates University, UAE
Alina Ostafe
University of New South Wales, Australia
Karim Bigou
University of Brest, France
Wilfried Meidl
Sabanci University, Turkey
Yi Lu
University of Bergen, Norway
Omran Ahmadi
Institute for Research in Fundamental Sciences, Iran
Zhixiong Chen
Mercy College, USA
VIII
Organization

Wouter Castryck
Ghent University, Belgium
Qiang Wang
Carleton University, Canada
Aurore Guillevic
Inria Nancy, Grand Est, France
Audrey Lucas
University of Rennes 1, France
Ayoub Otmani
University of Rouen, France
Ayça ÇeŞmelioglu
Istanbul Kemerburgaz University, Turkey
Nicolas Sendrier
Inria Paris, France
Gregoire Lecerf
Ecole Polytechnique, France
Gabriel Gallin
University of Rennes 1, France
Arthur Beckers
KU Leuven, Belgium
Tobias Oder
Ruhr-Universität Bochum, Germany
Organization
IX

Contents
Invited Talk I
A Brief History of Pairings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
Razvan Barbulescu
Elliptic Curves
Differential Addition on Binary Elliptic Curves. . . . . . . . . . . . . . . . . . . . . .
21
Reza Rezaeian Farashahi and Seyed Gholamhossein Hosseini
Adequate Elliptic Curves for Computing the Product of n Pairings . . . . . . . .
36
Loubna Ghammam and Emmanuel Fouotsa
On Pseudorandom Properties of Certain Sequences of Points
on Elliptic Curve. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
54
László Mérai
Applications
Linear Complexity and Expansion Complexity of Some Number
Theoretic Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
67
Richard Hofer and Arne Winterhof
Irreducible Polynomials
On Sets of Irreducible Polynomials Closed by Composition . . . . . . . . . . . . .
77
Andrea Ferraguti, Giacomo Micheli, and Reto Schnyder
A Note on the Brawley-Carlitz Theorem on Irreducibility of Composed
Products of Polynomials over Finite Fields. . . . . . . . . . . . . . . . . . . . . . . . .
84
Akihiro Munemasa and Hiroko Nakamura
Invited Talk II
On Arcs and Quadrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
Simeon Ball
Applications to Cryptography
A Generalised Successive Resultants Algorithm . . . . . . . . . . . . . . . . . . . . .
105
James H. Davenport, Christophe Petit, and Benjamin Pring

Distribution and Polynomial Interpolation of the Dodis-Yampolskiy
Pseudo-Random Function. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
125
Thierry Mefenza and Damien Vergnaud
Boolean Functions
A Conjecture About Gauss Sums and Bentness of Binomial
Boolean Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
143
Jean-Pierre Flori
Generalized Bent Functions and Their Gray Images. . . . . . . . . . . . . . . . . . .
160
Thor Martinsen, Wilfried Meidl, and Pantelimon Stănică
Cryptography
Enhanced Digital Signature Using RNS Digit Exponent Representation . . . . .
177
Thomas Plantard and Jean-Marc Robert
Efficient Finite Field Multiplication for Isogeny Based Post
Quantum Cryptography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
193
Angshuman Karmakar, Sujoy Sinha Roy, Frederik Vercauteren,
and Ingrid Verbauwhede
A Search Strategy to Optimize the Affine Variant Properties of S-Boxes . . . .
208
Stjepan Picek, Bohan Yang, and Nele Mentens
Cryptography and Boolean Functions
A Super-Set of Patterson-Wiedemann Functions – Upper Bounds
and Possible Nonlinearities. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
227
Selçuk Kavut, Subhamoy Maitra, and Ferruh Özbudak
A Correction and Improvements of Some Recent Results on Walsh
Transforms of Gold Type and Kasami-Welch Type Functions . . . . . . . . . . .
243
Ayhan Coşgun and Ferruh Özbudak
A Practical Group Signature Scheme Based on Rank Metric. . . . . . . . . . . . .
258
Quentin Alamélou, Olivier Blazy, Stéphane Cauchie,
and Philippe Gaborit
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
277
XII
Contents

Invited Talk I

A Brief History of Pairings
Razvan Barbulescu(B)
CNRS, Univ. Paris 6, Univ. Paris 7, Paris, France
razvan.barbulescu@imj-prg.fr
Abstract. Pairings are a relatively new tool in cryptography. Recent
progress on the attack algorithms have changed the security estimations.
We make a list of pairing families and explain their advantages but also
their weaknesses.
1
Introduction
Pairings are a mathematical tool which has been known to cryptographers for a
long time and which switched sides during its history. If in the early 90’s it was
on the attacker’s side, it is now used to create secure cryptologic protocols.
Let E be an elliptic curve deﬁned over a ﬁnite ﬁeld Fq, r an integer number,
P a point of order r and μ an rth root of unity in the algebraic closure Fq. The
Weil pairing (restricted to the subgroup generated by P) is the map
e : Z/rZP × Z/rZP →μZ/rZ
∀(a, b) ∈(Z/rZ)2
([a]P, [b]P)
→μab.
(1)
Two properties of the Weil pairing are direct:
– bilinearity: for all a, a′, b, b′ we have
e([a + a′]P, [b]P) = e([a]P, [b]P) · e([a′]P, [b]P)
e([a]P, [b + b′]P) = e([a]P, [b]P) · e([a]P, [b′]P)
– non-degeneracy: for all a ̸= 0 there exists b so that
e([a]P, [b]P) ̸= 1,
and similarly with the roles of a and b exchanged.
The Weil pairing owes its name to Andr´e Weil who gave an equivalent deﬁ-
nition in 1940 [Wei40]. More precisely, Weil deﬁned the map
eW (S, T) = g(X + S)
g(X)
,
(2)
where g is a function so that div(g) = rT −rOE and X ∈E\E[r2]. This map is
bilinear and non-degenerate (see Proposition III.8.1 in [Sil07]) and, since there
is a unique map with these two properties (up to a multiplicative constant),
c
⃝Springer International Publishing AG 2016
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 3–17, 2016.
DOI: 10.1007/978-3-319-55227-9 1

4
R. Barbulescu
we conclude that Eqs. (2) and (1) are alternative deﬁnitions of the same object.
In 1985 Miller [Mil04] invented an algorithm based on this equivalent deﬁnition
to compute e in polynomial time with respect to the bit sizes of q and r. Frey
and R¨uck [FR94] created an alternative manner to compute Weil pairings using
results of Tate and Lichtenbaum.
From attacker’s point of view, pairings are a tool to reduce hard problems
to easier ones. Given a cyclic group G of known order, a generator P of G and
an other point [a]P for a ∈{0, 1, . . . , #G −1}, the discrete logarithm problem
(DLP) consists in ﬁnding a. In 1992 Menezes, Okamoto and Vanstone [MOV93]
showed that the Weil pairing associated to an elliptic curve over Fq, an integer
r, a point P of order r and an rth root of unity in Fq allows to reduce the DLP
on E to the DLP in the multiplicative group of Fq(μ), the smallest subﬁeld of
Fq which contains μ. The embedding degree of E with respect to r is the degree
of Fq(μ).
From a constructive point of view, pairings are a tool to combine two
encrypted secrets into a common encrypted secret, without decrypting them
at any time. In 2001 Joux [Jou00] proposed a three-party Diﬃe-Hellman key
exchange which requires only one round of communications. If Alice, Bob and
Carol want to agree on a common key they need to agree on an elliptic curve
and on a point P of order r. Then they proceed in two steps
1. each participant generates a random integer, raises P to that power and
broadcasts the result:
– Alice generates a and computes [a]P and broadcasts it,
– Bob generates b and computes [b]P and broadcasts it,
– Carol generates c and computes [c]P and broadcasts it;
2 each participant computes the Weil pairing of the received points and raises
it to its own secret number:
– Alice computes e([b]P, [c]P)a,
– Bob computes e([c]P, [a]P)b,
– Carol computes e([a]P, [b]P)c.
Due to Eq. (1) all participants have computed μabc.
This protocol has inspired alternative solutions which are based on lattices
and therefore belong to the exponential cryptography [GGH13].
The three party Diﬃe-Hellman protocol can be broken by solving the DLP
in the subgroup of E generated by P or by solving the DLP in the multiplicative
group of Fqk. This is true for other applications of pairings but we stick to this
example for simplicity.
2
Known Attacks Against Pairings
2.1
Attacks on the Curve Side
Pollard Rho. In the three-party Diﬃe-Hellman protocol an attacker can compute
the discrete logarithm of [a]P and obtain the secret information a. The state-
of-the-art algorithm to solve DLP in elliptic curves over prime ﬁelds is Pollard’s

A Brief History of Pairings
5
rho [Pol78] which has a cost of O(√r) operations. Hence, for a given security
level one has to set log2 r = 2s and therefore log2 #E(Fq) ≥2s. Due to Hasse’s
theorem, q and #E(Fq) have the same bit size up to an error of 3 bits, so we
have log2 q ≥log2 r = 2s.
Faults on the Twist Curve. Biehl, Meyer and M¨uller [BMM00] explained that,
since some implementations of the scalar multiplication use only the x coordinate
of the points on the elliptic curve E : y2 = x3 +ax+b, by error injection one can
transfer the DLP from E to its twisted curve E′ : ϵy2 = x3 + ax + b, where ϵ is a
non-square of Fq. As a counter-measure we require that the elliptic curves used
in cryptography are twist-safe, i.e. that both #E(Fq) and 2(q + 1) −#E(Fq)
have large prime factors.
Faults in Miller’s Algorithm. Page and Vercauteren [PV06] studied the fault
attacks which concern precisely the evaluation of the pairings and are indepen-
dent on the protocol in which this primitive is used.
2.2
Attacks on the Finite Field Side
In the three-party Diﬃe-Hellman protocol an attacker, who has access to the
public information [a]P, can compute μa = e([a]P, P) using solely public infor-
mation. By solving the DLP in the group generated by μ one can obtain the
secret information a. Hence a safe pairing requires that the DLP in the multi-
plicative group of Fqk is hard.
The best algorithms to solve DLP in ﬁnite ﬁelds inherited the main traits
from Index Calculus [Adl79] and have a complexity inferior to any exponential
function. A suitable notation to express their complexity is
LQ(α, c) = exp((c + o(1))(log Q)α(log log Q)1−α),
where Q is the cardinality of the target ﬁnite ﬁeld and α and c are two constants
such that 0 < α < 1. When the constant c is not important we simply write
LQ(α). By extension we use a similar notation when α is a function.
The state-of-the-art algorithms depend on the size of the characteristic p
with respect to Q = pn (we switch notations from qk to pn to show that p is not
necessarily prime). When p = LQ(lp, cp) we have the following complexities:
– LQ( 1
3,
3
64
9 ) when the ﬁeld has large characteristic, i.e. if lp > 2
3, [JLSV06];
– LQ( 1
3, c) with c ∈[ 3
48
9 ,
3
96
9 ] in the boundary case, i.e. if lp = 2
3; the constant
c =
3
48
9 is obtained when cp = 12
1
3 , [SS16];
– LQ( 1
3,
3
48
9 ) when the ﬁeld has medium characteristic, i.e. if 1
3 < lp < 2
3, and
n has a factor of size 12−1
3 (
log Q
log log Q)
1
3 ; and LQ( 1
3,
3
96
9 ) if n has no factor of
the suitable size (e.g. if n is prime) [BGGM15b];

6
R. Barbulescu
– LQ( 1
3, c) with c ∈[ 3
8
9,
3
96
9 ] when the ﬁeld has a characteristic at the bound-
ary between medium and small, i.e. if lp =
1
3; the complexity c =
3
8
9 is
obtained when cp = 3−1
3 [Jou13]; one has a better complexity in the case of
Kummer extensions;
– LQ(lp +o(1)) when the ﬁeld has small characteristic, i.e. lp < 1
3; the best com-
plexity corresponds to exp(O(1)(log log Q)2) = LQ(o(1)) when p = (log Q)O(1)
[BGJT14].
When the characteristic is non-small, i.e. lp ≥1/3, the best complexities are
all obtained with the same algorithm, presented below.
Number Field Sieve (NFS). The main steps of NFS [JL03] are similar to
those of Index calculus and the key ingredient is smoothness: an integer is B-
smooth if all its prime factors are less than B.
Polynomial Selection. One selects two polynomials f and g with integer coeﬃ-
cients which, when seen as elements of Fp[x], have a common factor ϕ which has
degree n and is irreducible. The performance of the algorithm depends strongly
on the degrees of the two polynomials as well as on their norms, i.e. larges
coeﬃcient in absolute value.
Relation Collection. Given two polynomials f = deg f
i=0 fixi and g = deg g
i=0 gixi
we collect all the pairs (a, b) of integers (or equivalently linear polynomials a −
bx ∈Z[x]) such that max(|a|, |b|) ≤E for a parameter E, gcd(a, b) = 1 and the
two norms Nf(a, b) = deg f
i=0 fiaibdeg f−i and Ng(a, b) = deg g
i=0 giaibdeg g−i are
B-smooth. This stage is usually done using a technique called sieve.
Linear Algebra. For each pair (a, b) yielded by the sieve one can write a linear
equation whose unknowns are in bijection with set of prime ideals of degree one
in the number ﬁelds of f and g of norm less than B. The square matrix has less
than B unknowns and less than log2 pn non-zero entry per row so that one can
use sparse-matrix algorithms like Wiedemann [Wie86].
Individual Logarithm. The unknowns obtained after the linear algebra stage,
called virtual logarithms, allow to compute any discrete logarithm. This stage
takes a negligible amount of time compared to the other stages.
When p has a special form, e.g. a low Hamming weight, a variant of NFS has
a better asymptotic complexity.
The Special Number Field Sieve (SNFS). Given an integer d, an integer p
is d-SNFS if there exists a polynomial P ∈Z[x] and an integer u so that ∥P∥≤50
(or other absolute constant) and p = P(u). Semaev [Sem02] proved that the DLP
is easier in prime ﬁnite ﬁelds Fp when p is d-SNFS with d = ( 9
2)
1
3 (
log p
log log p)
1
3 . One
doesn’t have to change anything in the NFS algorithm except for the choice of

A Brief History of Pairings
7
polynomials: f = P(x) and g = x −u. In practice d is the value of deg f in
the record computations using NFS and goes from 5 for ﬁelds of about 500 bits
to 8 for ﬁelds of about 1200 bits. Experiments conducted with SNFS in the
case of discrete logarithm [HT11] as well as of factorization [KBL14] conﬁrm the
eﬃciency of the algorithm for d-SNFS numbers with d ≥3.
2.3
The LogJam Attack
A simple remark about the algorithms of the Index Calculus family is that they
have two types of input data: a group G and a generator g of G which are used
in the costly stages of the algorithm, relation collection and linear algebra, and
an element h of G which isn’t used before the individual logarithm stage. An
attacker can therefore perform the expensive computations which depend on G
and g once for all and use then to compute many secrete keys by solving many
instances of individual logarithm with respect to that group.
Adrian et al. [ABD+15] conducted real life attacks in this manner. They
estimated that 82% of the scanned servers use the same group and therefore
can be attacked with one stone. One can easily imagine a situation where this
is unacceptable: 80 bits of security are enough to protect bits of one minute for
a pay-TV channel whereas it might be unacceptable for the whole program.
Consequences. Whenever the security of a cryptosystem is measured using Index
Calculus attacks, as NFS, one is vulnerable to the LogJam attack. In this case
one might either use a stronger level of security or generate on-the-ﬂy the group
used in the cryptosystem. For example in the case of pairings one should be able
to generate on-the-ﬂy pairing-friendly curves. However in the case of hardware
implementation of cryptosystems, where parameters have to be hard-coded, the
only option is to use larger key sizes.
3
Recent Progress of the NFS Attack
The ﬁrst estimations of security of pairings have been done at a time when NFS
could only be used for prime ﬁelds, and one had to make the hypothesis that
the DLP in the general case is as hard as in prime ﬁelds [Len01]. Since then the
NFS was adapted to the case Fpn of non-small characteristic and in some cases
the complexity is smaller than in the prime case, as we present below.
3.1
New Methods of Polynomial Selection
The ﬁrst manner to go from Fp to Fpn is to create new methods of polynomial
selection whose result is a pair (f, g) ∈Z[x] not necessarily irreducible which
have a common irreducible factor ϕ in Fp[x].
For any pair (p, ϕ) formed of a prime p and a monic polynomial with integer
coeﬃcients ϕ which is irreducible in Fp[x] and any parameter D ≥deg ϕ one
deﬁnes the lattice

8
R. Barbulescu
L(p, ϕ, D) = {(a0, . . . , aD) ∈ZD+1 |
D

i=0
aixi ∈pZ[x] + ϕZ[x])}.
A naive method of polynomial selection would be to pick a random monic irre-
ducible ϕ ∈Fp[x] of degree n and to make f and g from the shortest two vectors
b1 and b2 in an LLL-reduced basis of L(p, ϕ, D). By the Lenstra-Lenstra-Lovasz
theorem [LLL82] we know that ∥b1∥2 ≤c1Vol(L)
1
dim L where c1 = 2
dim L
4
. Heuris-
tically we expect b1 and b2 to have no non-zero coordinates (random vectors) so
that deg f = deg g = D and ∥b1∥≈∥b2∥≈Vol(L)
1
dim L .
JLSV2. In [JLSV06] Joux, Lercier, Smart and Vercauteren take ϕ of degree
n < D such that ∥ϕ∥2 = 1 + c1Vol(L)
1
dim L . Then one can make f from the
coordinates of the shortest vector of L(p, ϕ, D) and set g = ϕ. By the Lenstra-
Lenstra-Lovasz theorem ∥f∥≤c1Vol(L)
1
dim L < ∥g∥so the two polynomials are
distinct. The advantage is that deg g = n which is smaller than D whereas deg f,
∥f∥and ∥g∥are the same as in the naive method.
GJL. In [JL03] Joux and Lercier proposed a method of polynomial for Fp
which was generalized [Mat06,BGGM15b] to Fpn with n > 1 (generalized Joux
Lercier). One takes f to be a polynomial of degree D + 1 with ∥f∥= 1 which
has an irreducible factor ϕ ∈Fp[x] of degree n, and then one makes g from the
shortest vector of L(p, ϕ, D). The advantage in this case is that f has coeﬃcients
of size O(1) instead of c1(pn)
1
D+1 for the small cost of increasing the degree of f
from D to D + 1.
JLSV1. Also in [JLSV06] Joux, Lercier, Smart and Vercauteren proposed to take
f equal to a polynomial of degree n which is irreducible in Fp[x] with ∥f∥≤1
and to set g = f + p. An additional improvement, which doesn’t change the
asymptotic complexity, consists in selecting polynomials such that deg f = deg g
and ∥f∥= ∥g∥. We can obtain this if we apply the JLSV2 method with D = 2n,
when ∥f∥≈∥g∥≈c1(pn)
1
2n = c1√p. However, one can obtain polynomials
of the same characteristics by reducing a lattice of dimension 2 instead of 2n.
Indeed one takes two polynomials f0, f1 ∈Z[x] of degree n respectively ≤n−1 so
that, for all integers a, f0 + af1 has degree n. Next one LLL-reduces the lattice
generated by M(a, p) =
0 p
1 a

and obtains a vector (u, v) of norm ≤2
1
4 √p.
Finally one sets f = f0 + af1 and set g = vf0 + uf1, which is a multiple of f in
Fp[x].
Conjugation Method. This method, presented in [BGGM15b], is similar to
JLSV1. First we select f0 and f1 so that, for all integer a, f0 + af1 has degree n.
Next we select m as small as possible so that x2 −m has a root a ∈Z modulo p
and f0 + af1 is irreducible in Fp[x]. We ﬁnish as in JLSV1 by reducing M(a, p)
and setting g = vf0 + uf1.
At this point one would like to set f = f0 + √mf1 but this polynomial
belongs to Z[√m][x] instead of Z[x]. We overcome this diﬃculty by setting f =

A Brief History of Pairings
9
(f0 + √mf1)(f0 −√mf1) = f 2
0 −mf 2
1 which has integer coeﬃcients and is a
multiple of g in Fp[x].
Methods for Composite n. Sarkar and Singh [SS16] proposed a method which
improves the asymptotic complexity of NFS when p = LQ(2/3, cp) with cp ∈
[1.12, 1.45] [3.15, 20.91]. The authors made a precise estimation of eﬃciency in
the case of ﬁnite ﬁelds of cryptographic sizes n = 4 and n = 6.
Practical Eﬃciency of the New Methods. The new methods have been
tested in practice and one concluded that the DLP in non-prime ﬁnite ﬁelds
can be easier than in the prime case. In Table 1 we compare the cases n = 2
and n = 3 using the Conjugation method (Conj) to the prime case (n = 1).
For this we converted the computation time into GIPS years (1GIPS year = the
number of instructions done in one year by a CPU core of 1GHz) and made the
convention that 1 GPU hour = 10 CPU hours.
Table 1. Time of discrete logarithms computations in Fpn measured in GIPS years.
Bit size of pn 160 dd (≈532 bits) 180 dd (≈600 bits)
n = 1
55.5 [Kle07]
260 [BGI+14]
n = 2 (Conj)
0.5 [BGGM14]
1 [BGGM15b]
n = 3 (Conj)
34 [BGGM15a]
46 [GGM16]
3.2
The Tower Number Field Sieve
A second method to go from Fp to Fpn with n > 1 has been proposed by
Schirokauer [Sch00] and revised in [BGK15]. One selects h ∈Z[x] of degree n
which is irreducible in Fp[x] and call ι a root of h in its number ﬁeld. Then one
selects f and g in Z[x] which have a common root in Fp using one of the methods
for Fp and calls αf (resp. αg) a root of f (resp. g) in its number ﬁeld and set
Kf = Q(ι, αf) (resp. Kg = Q(ι, αg)) and compute θf (resp. θg) a primitive
element of Kf (resp. Kg).
One sets the parameters E, B and d at the same value as when computing
discrete logarithms in a prime ﬁeld of same bit size as Fpn. The factor base is
formed of the prime ideals of Kf and Kg whose norm is less than B and whose
inertia degree over Q(ι) is one, together with all the prime ideals dividing the
leading coeﬃcients of f and g. The algorithm continues as follows.
1. Enumerate all pairs a, b ∈Z[t] of degree n−1 with ∥a∥, ∥b∥≤E
1
n and collect
those such that Rest(F(a, b), h(t)) and Rest(G(a, b), h(t)) are B-smooth.
2. Consider each element a(ι) + αfb(ι) (resp. a(ι) + αgb(ι)) and compute the
corresponding linear equations, as in the case of the classical version of NFS.
Then solve the linear system to obtain the virtual logarithms of the factor
base.

10
R. Barbulescu
3. Compute the desired discrete logarithm in a similar manner to the classical
case.
The practical eﬃciency of the TNFS has not been tested. Indeed, the relation
collection consists of sieving on pairs (a, b) ∈Z[t] of degree less than n which
is equivalent to sieving on pairs of 2n-tuples of integers. Several teams [Zaj10,
HAKT15,GGV16] made experiments in the case of 3-tuples and concluded that
this does not represent a major practical obstacle. This might be a starting point
for future experiments in the case of 4-tuples so that TNFS in Fp2 can be tested.
3.3
The Extended Tower Number Field Sieve
The extended number ﬁeld sieve (exTNFS), presented in [KB16], consists in
combining the two ideas of the previous sections: new methods of polynomial
selection and tower number ﬁelds. One writes n = ηκ with η, κ ∈Z but not
necessarily diﬀerent from 1 and n and selects polynomials:
1. f and g as in Sect. 3.1 with κ instead of n;
2. h as in Sect. 3.2 with η instead of n.
When η = 1 we obtain the variant of NFS in Sect. 3.1, when η = n we obtain
TNFS (Sect. 3.2), but when n is composite and η is a proper factor of n we
obtain a new algorithm. When gcd(η, κ) ̸= 1 one has to use a special method of
polynomial selection which is due to Jeong and Kim [JK16]. The advantage of
exTNFS is that, in a similar manner in which in TNFS one has the same size of
norms as in classical NFS, in exTNFS one has the same size of the norms when
attacking Fpηκ as when attacking FP κ for a prime P of the same bit size as pη.
The Case of General Primes. In order to analyze the eﬃciency of exTNFS
we estimate the bit size of the norms product. Using Lemma 1 in [KB16] we ﬁnd
that, when the Conjugation method is used to select f and g, the two upper
bound on the norms bit size is:
norms bit size(exTNFS-Conj) ≤3κ log2 E + 1
2κ log2 Q + o(1).
(3)
where o(1) is a negligible term when log2 Q goes to inﬁnity. The o(1) term is
indeed negligible in cryptographic examples, e.g. Example 1 in [KB16]. Hence
exTNFS has the same eﬃciency as NFS with the diﬀerence that now we can
tune the parameter κ and make it equal to any factor of n.
The right hand member of Eq. (3) has its minimum when κ ≈

log2 Q
6 log2 E .
Although the bit size of the parameter E depends on the size of the norms it
doesn’t vary of more than a factor 2 among variants of NFS when one attacks
the same size of ﬁnite ﬁelds. In [KDL+16] one has log2 Q = 768 and log2 E ≈43
so that the optimal value of κ ≈1.72. We conclude that if one selects f and
g using the Conjugation method then for target ﬁelds of approximatively 1000
bits with n ≤24 composite the best options are κ = 2 if n is even and κ = 3 if
n is odd. This would allow to obtain similar practical results as in Table 1.

A Brief History of Pairings
11
The Case of Primes of Special Form. The exTNFS variant for SNFS num-
bers, abbreviated SexTNFS, consists in writing n = ηκ for two integers κ and
η not necessarily diﬀerent from 1 and n, in selecting h as in Sect. 3.2 with η
instead of n and in selecting f and g using the Joux-Pierrot method [JP13], that
we describe below, with κ instead of n.
One selects a monic polynomial S ∈Z[x] of degree n such that f = P(S(x))
is irreducible in Fp[x] and then sets g = S(x) −u. The method is correct due to
the following equation:
f(x) −p = P(S(x)) −P(u) ≡0 mod (S(x) −u) in Fp[x].
Once again we evaluate the practical eﬃciency using the estimation of the
bit size of the norms product, which from [KB16, Sect. 5.2] is:
norms bit size(SexTNFS) ≤(d + 1)κ log2 E + 1
κd log2 Q + o(1),
where o(1) is negligible when Q goes to inﬁnity. The advantage of SexTNFS is
that we have the possibility to set κ equal to any divisors of n.
4
Pairings Families and Their Security
In the light of the recent progress, a perfect pairing family needs to contain a
large number of curves for each security level that can be rapidly generated. Each
curve of a perfect family has an embedding degree k which can be set as desired
to any prime of desired size. The characteristic p is large and is not d-SNFS with
d ≥3. Finally for eﬃciency reasons the parameter r has the same bit size as q.
Freeman, Scott and Teske [FST10] made a taxonomy of known pairing-
friendly families of elliptic curves. Given a bit size and an embedding degree
k, most of them are constructed in two steps:
(i) one selects a prime power q of prescribed bit size and an integer t so that any
elliptic curve over Fq of trace t has embedding degree k and its cardinality
has a large prime factor r;
(ii) one uses the CM method [Mor91,AM93], which, given a prime power q and
an integer t, allows to construct elliptic curves over Fq of trace t.
The CM method has complexity O(D1+ϵ) where D is the unique integer so that
(4q −t2)/D is a perfect square. This imposes that we ﬁx D in advance: it will be
either small or will have common factors with q. By deﬁnition #E(Fq) = q+1−t
so we ask the existence of a prime r so that q + 1 −t ≡0 mod r. Finally, the
property that k is the embedding degree of the curve is equivalent to Φk(q) ≡0
(mod r). We summarize the conditions on the output of the ﬁrst step as follows:
CM-1. Φk(t −1) ≡0 (mod r)
CM-2. q + 1 −t ≡0 (mod r)
CM-3. ∃y, 4q = Dy2 + t2

12
R. Barbulescu
4.1
Supersingular Curves
When k = 2 there is a value of D for which the system is easy to solve. Indeed
we set t = 0 so that we have Φ2(t −1) = 0 and therefore the ﬁrst equation is
satisﬁed independently on r. In Equation CM-3, we take D = q and y = 2 so
that there is no condition on q. Finally Equation CM-2, states that q + 1 has a
prime factor r which is easy to fulﬁll by enumerating primes q. Br¨oker [Br¨o06]
presented the CM method in the case D = q, which is fast although D is large.
A natural question is whether this method can be extended to other values
of k. The answer is given by the following classical result.
Proposition 1. If p ≥5 is a prime then any supersingular elliptic curve over
Fp has embedding degree k = 2.
Proof. By the deﬁnition of supersingular curves we have gcd(t, p) ̸= 1 so p divides
t and therefore t = 0 or |t| ≥p. By Hasse’s theorem |t| ≤2√p which is less than
p and therefore t = 0. Then q ≡t −1 ≡−1 (mod r) and q2 ≡1 (mod r) which
shows that k = ordr(q) = 2.
Drawback. Due to the quasi-polynomial algorithm the cases p = 2 and p = 3 are
forbidden. When p ≥5 the embedding degree k = 2 is ﬁxed to a value which
is far from the optimal value and has made the object of recent computation
records which were faster than the prime case.
4.2
Pinch-Cocks [CP01]
One starts by replacing Equation CM-2, with
CM-2′.
Dy2 + (t −2)2 ≡0
(mod r)
so that we obtain an equivalent system. Then we select r so that r ≡1 mod k
and ( −D
r ) = 1. Then Equation CM-2’, is factorized into
(
√
−Dy + (t −2))(
√
−Dy −(t −2)) ≡0
(mod r).
The choice of r allows to set t equal to a root of the polynomial Φk(X −1) ∈
Fr[X]. The same choice allows to solve this Equation CM-2′, for y: y = (t −
2)/
√
−D (mod r). Finally q is set to (Dy2 + t2)/4. Heuristically this is integer
in a constant proportion of the cases and has the same probability to be prime
as a random integer of the same size, i.e. one succeeds on average after O(log q)
trials.
Drawback. With high probability the integer y has the same bit size as r so that
log2 q ≈2 log2 r which aﬀects the eﬃciency of pairings.

A Brief History of Pairings
13
4.3
Dupont-Enge-Morain [DEM05]
Once again we start by replacing Equation CM-2, by Equation CM-2′. Then
we see Equations CM-1 and CM-2′ as a system which has to be solved with
y, t ∈Fr:
Φk(t −1) = 0
Dy2 + (t −2)2 = 0.
We solve the system (for a given D and bit size b of q) as follows:
1: R(y) ←Rest(Φk(t −2), Dy2 + (t −2)2);
2: for y ≤2
b
2ϕ(k) do
3:
r ←the largest prime factor of R(y)
4:
t = 2 +
	
−Dy2 (if it exists)
5:
q ←q = (Dy2 + t2)/4
6:
q′ ←q + 1 + t (cardinality of the twisted curve to be tested)
7:
if q and q′ are integer primes and log2 r ≥b/2 then return y
8:
end if
9: end for
For example we ran the algorithm for the bit size b = 256, embedding degree
k = 16 and the parameter D = 3. The output list was: y ∈{39193, 61815}.
Drawback. The total number of curves which can be constructed for crypto-
graphic sizes is very small if we restrict to twist-safe curves so that this family
is vulnerable to the LogJam attack.
4.4
Sparse Families (e.g. MNT [MNT01])
The following construction is possible for all integers k so that ϕ(k) = 2, i.e.
k = 3, 4 and 6, but for simplicity we present only the case k = 3. We set
r = Φk(t −1) so that Equation CM-1 is satisﬁed. Next we set q = r + t −1,
which satisﬁes CM-2. The method was generalized by Freeman when ϕ(k) but
cannot be generalized further.
Proposition 2. If ϕ(k) > 4 then the system CM-1, 2, 3 has a ﬁnite set of solu-
tions.
Proof. When we set r = Φk(t −1) Equation CM-3 becomes
y2 = f(t) where f(t) = 1
D(4q −t2) = 1
D(4(Φk(t −1) + t −1) −t2).
By the Riemann-Hurwitz formula the genus of the curve is ⌊deg f−1
2
⌋=
⌊ϕ(k)−1
2
⌋≥2. By Faltings’ theorem the equation has a ﬁnitely many solutions
in Q.
The integer solutions obtained when setting t equal to a linear polynomial in
an additional variable are a subset of the rational solutions, so we have a ﬁnite
number in total.

14
R. Barbulescu
Drawback. The embedding degree k has a very small set of possibilities all of
which are divisible by 2 or 3.
4.5
Complete Families (e.g. BN [BN05])
Once again we replace Equation CM-2 by CM-2′. Then we set r equal to a
polynomial r(x) whose number ﬁeld contains Q(
√
−D, ζk) for a kth root of unity
ζk. This translates into
1. Φk is totally split modulo r(x);
2. x2 + D is totally split modulo r(x).
Next we take t to be a polynomial t(x) so that Φk(t(x)) ≡0 mod r(x). Since
Equation CM-2′ factors we can set y(x) = t(x)· t(x)
√−D where
1
√−D is a polynomial
z(x) in Q(x] so that Dz2+1 ≡0 mod r(x). Finally set q(x) = 1
4(Dy(x)2+t(x)2).
The advantage of this method is that pairing-friendly curves can be generated
on the ﬂy by evaluating r and q at integer values x.
Drawback. The primes constructed by this method are 2ϕ(k)-SNFS and therefore
the NFS attacks have a smaller asymptotic complexity.
4.6
Menezes-K¨oblitz [KM05]
Not all the pairing constructions are obtained using the CM method. Menezes
and K¨oblitz proposed a family which is not aﬀected by the recent progress: p is
not d-SNFS with d ≥3 so that the SNFS attack has no consequences and k = 1
so that the security on the ﬁnite ﬁeld side is the same as that of DSA.
Drawback. The embedding degree k cannot be tuned as desired.
5
Conclusion
We have identiﬁed a list of properties that a perfect pairing family should have
and, by a thorough examination, concluded that in the present state of the art
there is no perfect pairing family. In particular there is no clear champion because
the Barreto-Naehrig family, long believed to be perfect for 128 bits of security,
has a characteristic of a special form and is target to the SNFS attack.
Pairings are subject to two contradictory trends. On the one hand they
require more time before being standardized because no perfect family has been
proposed. On the other hand, time is running against pairings as they are sub-
ject to the NFS attack and therefore belong to the sub-exponential cryptography
as RSA and DSA whereas there exist alternative primitives which are based on
lattices and belong to the exponential cryptography.

A Brief History of Pairings
15
References
[ABD+15] Adrian, D., Bhargavan, K., Durumeric, Z., Gaudry, P., Green, M., Halder-
man, J.A., Heninger, N., Springall, D., Thom´e, E., Valenta, L., Vander-
Sloot, B., Wustrow, E., Zanella-B´eguelin, S., Zimmermann, P.: Imperfect
forward secrecy: how Diﬃe-Hellman fails in practice. In: Proceedings of
the 22nd ACM SIGSAC Conference on Computer and Communications
Security-CCS 2015, pp. 5–17. ACM, New York (2015)
[Adl79] Adleman, L.M.: A subexponential algorithm for the discrete logarithm
problem with applications to cryptography. In: 20th Annual Symposium
on Foundations of Computer Science, pp. 55–60. IEEE (1979)
[AM93] Oliver, A., Atkin, L., Morain, F.: Elliptic curves and primality proving.
Math. Comput. 61(203), 29–68 (1993)
[BGGM14] Barbulescu, R., Gaudry, P., Guillevic, A., Morain, F.: Discrete loga-
rithms in GF(p2) – 160 digits (2014). Announcement available at the
NMBRTHRY archives, item 004706
[BGGM15a] Barbulescu, R., Gaudry, P., Guillevic, A., Morain, F.: New record in Fp3
(2015). https://webusers.imj-prg.fr/∼razvan.barbaud/p3dd52.pdf
[BGGM15b] Barbulescu, R., Gaudry, P., Guillevic, A., Morain, F.: Improving NFS for
the discrete logarithm problem in non-prime ﬁnite ﬁelds. In: Oswald, E.,
Fischlin, M. (eds.) EUROCRYPT 2015. LNCS, vol. 9056, pp. 129–155.
Springer, Heidelberg (2015). doi:10.1007/978-3-662-46800-5 6
[BGI+14] Bouvier, C., Gaudry, P., Imbert, L., Jeljeli, H., Thom´e, E.: Discrete log-
arithms in GF(p) – 180 digits (2014). Announcement available at the
NMBRTHRY archives, item 004703
[BGJT14] Barbulescu, R., Gaudry, P., Joux, A., Thom´e, E.: A heuristic quasi-
polynomial algorithm for discrete logarithm in ﬁnite ﬁelds of small
characteristic. In: Nguyen, P.Q., Oswald, E. (eds.) EUROCRYPT 2014.
LNCS, vol. 8441, pp. 1–16. Springer, Heidelberg (2014). doi:10.1007/
978-3-642-55220-5 1
[BGK15] Barbulescu, R., Gaudry, P., Kleinjung, T.: The tower number ﬁeld sieve.
In: Iwata, T., Cheon, J.H. (eds.) ASIACRYPT 2015. LNCS, vol. 9453,
pp. 31–55. Springer, Heidelberg (2015). doi:10.1007/978-3-662-48800-3 2
[BMM00] Biehl, I., Meyer, B., M¨uller, V.: Diﬀerential fault attacks on elliptic curve
cryptosystems. In: Bellare, M. (ed.) CRYPTO 2000. LNCS, vol. 1880, pp.
131–146. Springer, Heidelberg (2000). doi:10.1007/3-540-44598-6 8
[BN05] Barreto, P.S.L.M., Naehrig, M.: Pairing-friendly elliptic curves of prime
order. In: Preneel, B., Tavares, S. (eds.) SAC 2005. LNCS, vol. 3897, pp.
319–331. Springer, Heidelberg (2006). doi:10.1007/11693383 22
[Br¨o06] Br¨oker, R.: Constructing elliptic curves of prescribed order. Ph.D. the-
sis, Leiden University (2006). http://www.math.leidenuniv.nl/∼reinier/
thesis.pdf
[CP01] Cocks, C., Pinch, R.G.E.: Identity-based cryptosystems based on the Weil
pairing. Unpublished manuscript, 170 (2001)
[DEM05] Dupont, R., Enge, A., Morain, F.: Building curves with arbitrary small
mov degree over ﬁnite prime ﬁelds. J. Cryptol. 18(2), 79–89 (2005)
[FR94] Frey, G., R¨uck, H.-G.: A remark concerning m-divisibility and the discrete
logarithm in the divisor class group of curves. Math. Comput. 62(206),
865–874 (1994)

16
R. Barbulescu
[FST10] Freeman, D., Scott, M., Teske, E.: A taxonomy of pairing-friendly elliptic
curves. J. Cryptol. 23(2), 224–280 (2010)
[GGH13] Garg, S., Gentry, C., Halevi, S.: Candidate multilinear maps from ideal
lattices. In: Johansson, T., Nguyen, P.Q. (eds.) EUROCRYPT 2013.
LNCS, vol. 7881, pp. 1–17. Springer, Heidelberg (2013). doi:10.1007/
978-3-642-38348-9 1
[GGM16] Gaudry, P., Guillevic, A., Morain, F.: Discrete logarithm record in GF(p3)
of 592 bits (180 decimal digits) (2016). Announcement available at the
NMBRTHRY archives, item 004706
[GGV16] Gaudry, P., Gr´emy, L., Videau, M.: Collecting relations for the num-
ber ﬁeld sieve in GF(p6) (2016). Accepted for publication at ANTS-XII,
Kaiserslautern
[HAKT15] Hayasaka, K., Aoki, K., Kobayashi, T., Takagi, T.: A construction of 3-
dimensional lattice sieve for number ﬁeld sieve over GF(pn). Cryptology
ePrint Archive, Report 2015/1179 (2015). http://eprint.iacr.org/2014/
300
[HT11] Hayasaka, K., Takagi, T.: An experiment of number ﬁeld sieve over
GF(p) of low hamming weight characteristic. In: Chee, Y.M., Guo, Z.,
Ling, S., Shao, F., Tang, Y., Wang, H., Xing, C. (eds.) IWCC 2011.
LNCS, vol. 6639, pp. 191–200. Springer, Heidelberg (2011). doi:10.1007/
978-3-642-20901-7 11
[JK16] Jeong, J., Kim, T.: Extended tower number ﬁeld sieve with application
to ﬁnite ﬁelds of arbitrary composite extension degree. Cryptology ePrint
Archive, Report 2016/526 (2016). http://eprint.iacr.org/2016/526
[JL03] Joux, A., Lercier, R.: Improvements to the general number ﬁeld for dis-
crete logarithms in prime ﬁelds. Math. Comput. 72(242), 953–967 (2003)
[JLSV06] Joux, A., Lercier, R., Smart, N., Vercauteren, F.: The number ﬁeld sieve
in the medium prime case. In: Dwork, C. (ed.) CRYPTO 2006. LNCS, vol.
4117, pp. 326–344. Springer, Heidelberg (2006). doi:10.1007/11818175 19
[Jou00] Joux, A.: A one round protocol for tripartite Diﬃe–Hellman. In: Bosma,
W. (ed.) ANTS 2000. LNCS, vol. 1838, pp. 385–393. Springer, Heidelberg
(2000). doi:10.1007/10722028 23
[Jou13] Joux, A.: Faster index calculus for the medium prime case application to
1175-bit and 1425-bit ﬁnite ﬁelds. In: Johansson, T., Nguyen, P.Q. (eds.)
EUROCRYPT 2013. LNCS, vol. 7881, pp. 177–193. Springer, Heidelberg
(2013). doi:10.1007/978-3-642-38348-9 11
[JP13] Joux, A., Pierrot, C.: The special number ﬁeld sieve in Fpn - application
to pairing-friendly constructions. In: Cao, Z., Zhang, F. (eds.) Pairing
2013. LNCS, vol. 8365, pp. 45–61. Springer, Heidelberg (2014). doi:10.
1007/978-3-319-04873-4 3
[KB16] Kim, T., Barbulescu, R.: Extended tower number ﬁeld sieve: a new com-
plexity for the medium prime case. In: Robshaw, M., Katz, J. (eds.)
CRYPTO 2016. LNCS, vol. 9814, pp. 543–571. Springer, Heidelberg
(2016). doi:10.1007/978-3-662-53018-4 20
[KBL14] Kleinjung, T., Bos, J.W., Lenstra, A.K.: Mersenne factorization factory.
In: Sarkar, P., Iwata, T. (eds.) ASIACRYPT 2014. LNCS, vol. 8873, pp.
358–377. Springer, Heidelberg (2014). doi:10.1007/978-3-662-45611-8 19
[KDL+16] Kleinjung, T., Diem, C., Lenstra, A.K., Priplata, C., Stahlke, C.: Discrete
logarithms in GF(p) – 768 bits (2016). Announcement available at the
NMBRTHRY archives, item 004917

A Brief History of Pairings
17
[Kle07] Kleinjung, T.: Discrete logarithms in GF(p) – 160 digits (2007).
Announcement available at the NMBRTHRY archives, item 003269
[KM05] Koblitz, N., Menezes, A.: Pairing-based cryptography at high security
levels. In: Smart, N.P. (ed.) Cryptography and Coding 2005. LNCS, vol.
3796, pp. 13–36. Springer, Heidelberg (2005). doi:10.1007/11586821 2
[Len01] Lenstra, A.K.: Unbelievable security matching AES security using public
key systems. In: Boyd, C. (ed.) ASIACRYPT 2001. LNCS, vol. 2248, pp.
67–86. Springer, Heidelberg (2001). doi:10.1007/3-540-45682-1 5
[LLL82] Lenstra, A.K., Lenstra, H.W., Lov´asz, L.: Factoring polynomials with
rational coeﬃcients. Math. Ann. 261(4), 515–534 (1982)
[Mat06] Matyukhin, D.: Eﬀective version of the number ﬁeld sieve for discrete
logarithms in the ﬁeld GF(pk). Trudy po Discretnoi Matematike 9, 121–
151 (2006). (in Russian)
[Mil04] Miller, V.S.: The weil pairing, and its eﬃcient calculation. J. Cryptol.
17(4), 235–261 (2004)
[MNT01] Miyaji, A., Nakabayashi, M., Takano, S.: New explicit conditions of ellip-
tic curve traces for FR-reduction. IEICE Trans. Fundam. Electron. Com-
mun. Comput. Sci. 84(5), 1234–1243 (2001)
[Mor91] Morain, F.: Building cyclic elliptic curves modulo large primes. In: Davies,
D.W. (ed.) EUROCRYPT 1991. LNCS, vol. 547, pp. 328–336. Springer,
Heidelberg (1991). doi:10.1007/3-540-46416-6 28
[MOV93] Menezes, A.J., Okamoto, T., Vanstone, S.A.: Reducing elliptic curve log-
arithms to logarithms in a ﬁnite ﬁeld. IEEE Trans. Inf. Theory 39(5),
1639–1646 (1993)
[Pol78] Pollard, J.: Monte carlo methods for index computation (mod p). Math.
Comput. 32(143), 918–924 (1978)
[PV06] Page, D., Vercauteren, F.: A fault attack on pairing-based cryptography.
IEEE Trans. Comput. 55(9), 1075–1080 (2006)
[Sch00] Schirokauer, O.: Using number ﬁelds to compute logarithms in ﬁnite
ﬁelds. Math. Comput. 69(231), 1267–1283 (2000)
[Sem02] Semaev, I.: Special prime numbers and discrete logs in ﬁnite prime ﬁelds.
Math. Comput. 71(237), 363–377 (2002)
[Sil07] Silverman, J.H.: The Arithmetic of Dynamical Systems, vol. 241. Springer
Science & Business Media, Heidelberg (2007)
[SS16] Sarkar, P., Singh, S.: New complexity trade-oﬀs for the (multiple) num-
ber ﬁeld sieve algorithm in non-prime ﬁelds. In: Fischlin, M., Coron, J.-S.
(eds.) EUROCRYPT 2016. LNCS, vol. 9665, pp. 429–458. Springer, Hei-
delberg (2016). doi:10.1007/978-3-662-49890-3 17
[Wei40] Weil, A.: Sur les fonctions alg´ebriquesa corps de constantes ﬁni. CR Acad.
Sci. Paris 210(1940), 592–594 (1940)
[Wie86] Wiedemann, D.: Solving sparse linear equations over ﬁnite ﬁelds. IEEE
Trans. Inform. Theory 32(1), 54–62 (1986)
[Zaj10] Zajac, P.: On the use of the lattice sieve in the 3D NFS. Tatra Mt. Math.
Publ. 45(1), 161–172 (2010)

Elliptic Curves

Diﬀerential Addition on Binary
Elliptic Curves
Reza Rezaeian Farashahi1,2(B) and Seyed Gholamhossein Hosseini1
1 Department of Mathematical Sciences, Isfahan University of Technology,
Isfahan 84156-83111, Iran
farashahi@cc.iut.ac.ir, g.hoseini@math.iut.ac.ir
2 School of Mathematics, Institute for Research in Fundamental Sciences (IPM),
P.O. Box 19395-5746, Tehran, Iran
Abstract. This paper presents extremely fast diﬀerential addition (i.e.,
the addition of two points with the known diﬀerence) and doubling for-
mulas, as the core step in Montgomery scalar multiplication, for various
forms of elliptic curves over binary ﬁelds. The formulas are provided for
binary Edwards, binary Hessian and binary Huﬀelliptic curves with cost
of 5M + 4S + 1D when the given diﬀerence point is in aﬃne form. Here,
M, S, D denote the costs of a ﬁeld multiplication, a ﬁeld squaring and a
ﬁeld multiplication by a constant, respectively. This paper also presents,
new complete diﬀerential addition formulas for binary Edwards curves
with cost of 5M + 4S + 2D.
Keywords: Elliptic curves · Binary Edwards curves · Hessian curves ·
Binary Huﬀcurves · Diﬀerential addition
1
Introduction
An elliptic curve E over a ﬁeld F can be given by the Weiersrasß equation
y2 + a1xy + a3y = x3 + a2x2 + a4x + a6
where coeﬃcients a1, a2, a3, a4 and a6 are in F. There are many other ways
to represent elliptic curves such as Legendre equation, cubic equations, quartic
equations and intersection of two quadratic surfaces [18]. The use of elliptic
curves over ﬁnite ﬁelds based on their ﬁnite groups in cryptography (ECC)
was independently proposed in the mid 1980s by Koblitz [11] and Miler [14].
Since the introduction of elliptic curve cryptography many proposals have been
made to speed up the group arithmetic. Eﬃcient arithmetic (addition, doubling,
tripling and scalar multiplication) on elliptic curves over ﬁnite ﬁelds is the core
requirement of elliptic curve cryptography. Several forms of elliptic curves over
ﬁnite ﬁelds with several coordinate systems have been studied to improve the
eﬃciency and the speed of the arithmetic on the group law.
c
⃝Springer International Publishing AG 2016
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 21–35, 2016.
DOI: 10.1007/978-3-319-55227-9 2

22
R. Rezaeian Farashahi and S.G. Hosseini
Elliptic curves over binary ﬁnite ﬁelds are interesting particularly for hard-
ware implementations. Every ordinary elliptic curve over the binary ﬁnite ﬁled
F2m can be represented in the Weierstraß form
y2 + xy = x3 + ax2 + b,
where a, b ∈F2m and b ̸= 0. There are alternative ways to represent binary
elliptic curves such as binary Hessian [1,5,6,17], binary Edwards [3], binary
Huﬀcurves [9] and binary μ4-normal forms [12].
The scalar multiplication is the most important operation of elliptic curve
cryptography. That is to compute kP for a given point P on elliptic curve E
deﬁned over a ﬁnite ﬁeld Fq and a given integer k. The scalar multiplication can
be performed by a sequence of point additions and point doublings. Speed and
eﬃciency are the main factors to be considered in the correct implementing of
scalar multiplication. Moreover, the implementations should be performed in a
way to be resistant against passive and active side channel attacks. There are
several mathematical countermeasures proposed for preventing these attacks.
Simple side-channel attacks get information from a single scalar multiplication
when the power trace reveal distinctive key dependent patterns. The main idea
of the countermeasure against simple side-channel attacks is to make the com-
putation uniform. And the main solutions are making indistinguishable point
addition and point doubling, using double and add always method, using win-
dow method or applying the Montgomery technique.
The Montgomery method [15,16] is introduced for scalar multiplication of
points for a special type of curve in large characteristic. This method has been
extended to other form of elliptic curves and to binary elliptic curves [8]. The
Montgomery scalar multiplication is known also as Montgomery ladder. In the
Montgomery ladder, for each bit of the scalar both doubling and addition are
performed, so this prevents the computation secure against simple power analy-
sis. Also this method is not subject to fault attacks.
The countermeasures for some other passive or active attacks are to insert
suitable randomness to the key and also to the base point of the scalar multipli-
cation. Therefore, here the scalar key may be larger than the order of the base
point, which makes some exceptional cases like the point at inﬁnity in the com-
putation of the Montgomery ladder. Thus, obtaining complete or almost complete
formulas for addition and doubling makes the ladder performs completely.
In this paper we present fast explicit formulas for diﬀerential additions and
doublings on well known binary elliptic curves such as binary Edwards, binary
Hessian and binary Huﬀcurves.
2
Diﬀerential Addition
A Montgomery curve over a ﬁeld F of characteristic diﬀerent from 2 is given by
the equation
bY 2Z = X3 + aX2Z + XZ2,

Diﬀerential Addition on Binary Elliptic Curves
23
where a, b are elements of F with b(a2 −4) ̸= 0. The Montgomery ladder for
scalar multiplication is performed by a sequence of simultaneous point addition
and doubling, which makes this method interesting against side-channel attacks.
In Montgomery curves, the basic computation in a each step is done without
the Y coordinate, i.e., the technique involves special formulas for addition and
doubling that relies on only the X and Z coordinates of a point in projective
form. Also, the Y coordinate of the output point can be derived from the X and
Z coordinates.
In general, the basic computation in a each step of the Montgomery ladder
is diﬀerential addition and doubling. That is for given points P1, P2 and P1 −P2
on elliptic curve E over Fq to compute P1 + P2 and 2P1. The idea is extended
by a suitable rational function on the elliptic curve. Suppose w is a rational
function deﬁned over an elliptic curve E over a ﬁnite ﬁeld Fq. The function w is
given by fraction of polynomials in the coordinate ring of E over Fq. Let w(P) =
w(−P) for any point P on E(Fq). Then the w-coordinate diﬀerential addition
and doubling means to compute w(2P1) and w(P1+P2) from given values w(P1),
w(P2) and w(P1−P2), where P1, P2 are points on E(Fq). For Montgomery curves
the function w is x, where w(P) equals the x-coordinate of the point P. Since
ﬁeld inversion is costly, practically computations are performed where points are
represented in projective coordinates. Therefore, when w is regular at the point
P then w(P) is represented by (w(P) : 1) in the projective line P(Fq). Otherwise,
it is represented by (1 : 0). The projective w-coordinate diﬀerential addition and
doubling (dADD) algorithm is given in Algorithm 1. Notice, in Algorithm 1, the
given input values w(P1), w(P2) and w(P0) = w(P1 −P2) are represented by
Wi/Zi where i = 1, 2, 0 respectively. Then w(P1 + P2), i.e. the w-coordinate
diﬀerential addition, is given by fa
ga with some homogenous polynomials fa and
ga in variables Wi, Zi, where i = 0, 1, 2. Also, w(2P1) is given by fd
gd , where fd
and gd are homogenous polynomials with variables W1, Z1.
Algorithm 1. Projective w-coordinate dADD
Input : E/Fq, w : E(Fq) →P(Fq),
▷The elliptic curve E over Fq
(Wi : Zi) = w(Pi), i = 0, 1, 2.
▷w(P0) = w(P1 −P2)
Output : (Wi : Zi) = w(Pi), i = 3, 4.
▷w(P3) = w(P1 + P2), w(P4) = w(2P1)
1: function dADD((W0 : Z0), (W1 : Z1), (W2 : Z2))
2:
W3 = fa(W0, Z0, W1, Z1, W2, Z2)
▷Diﬀerential addition computation
3:
Z3 = ga(W0, Z0, W1, Z1, W2, Z2)
4:
W4 = fd(W1, Z1)
▷Doubling computation
5:
Z4 = gd(W1, Z1)
6:
return ((W4 : Z4), (W3 : Z3))
▷The diﬀerential addition and doubling
7: end function
The Montgomery scalar multiplication based on a projective w-coordinate
dADD is given in Algorithm 2. Notice, the base point P can be considered such
that one of the coordinates of w(P) equals 1, which makes less ﬁeld operation
computation in each step of the ladder.

24
R. Rezaeian Farashahi and S.G. Hosseini
Algorithm 2. The Montgomery scalar multiplication
Input : E/Fq, w : E(Fq) →P(Fq),
▷The elliptic curve E over Fq
Projective w-coordinate dADD funtion,
P ∈E(Fq), k = (km−1, · · · , k1, k0)
▷k is a positive
integer, km−1 = 1
(W0 : Z0) := w(P), (W1 : Z1) := w(P), (W2 : Z2) := w(2P).
Output : w(kP)
1: for i := m −2 down to 0 do
2:
if ki = 0 then
3:
((W1 : Z1), (W2 : Z2)) := dADD((W0 : Z0), (W1 : Z1), (W2 : Z2))
4:
else
5:
((W2 : Z2), (W1 : Z1)) := dADD((W0 : Z0), (W2 : Z2), (W1 : Z1))
6:
end if
7: end for
8: return (W1 : Z1), (W2 : Z2)
▷The diﬀerential addition and doubling
Note that if there are some exceptional points where the function dADD is
not computed correctly, then the Montgomery ladder does not work properly.
We say that the diﬀerential w-coordinate is complete if the Algorithm 1 works
for any input without any exception. We also say that the function dADD is
almost complete if the Algorithm 1 works for all inputs except for the case where
w(P0) equals w(O), where O is the neutral element of the group of points E(Fq).
Therefore, for the complete function dADD the Montgomery ladder is performed
without any problem for any input. Moreover, for the almost complete function
dADD the Montgomery ladder works for any base point P except for the points
where w(P) equals w(O). Notice, the almost complete function is also suitable
for cryptographic application.
In this paper, we concentrate on diﬀerential addition on binary elliptic curves.
Let E be a binary elliptic curve over F2m in Weiersrasß form
y2 + xy = x3 + ax2 + b,
where a, b are in F2m. Lopez and Dahab [13] presented the projective formu-
las for the addition and doubling of points on E. And, they generalized the
Montgomery’s idea to binary curves. Algorithm 3 provides the Lopez and Dahab
diﬀerential x-coordinate on elliptic curve E over F2m.
If we assume Z0 = 1, then the Lopez and Dahab formulas are computed
using 5M + 4S + 1D. Here, a multiplication in Fq costs one M and a squaring
costs one S. Also the cost of ﬁeld multiplication by a parameter (as a constant)
is denoted by D.
We note, that the point at inﬁnity on the binary elliptic curve E over F2m
is O = (0 : 1 : 0) and x(O) is represented by (1 : 0). One can easily check that
the projective x-coordinate formulas work for all inputs if Z0 ̸= 0, that is where
P0 ̸= O. In other words the formulas are almost complete and the Montgomery
ladder works for all inputs if the base point is not the point at inﬁnity. So, the

Diﬀerential Addition on Binary Elliptic Curves
25
Algorithm 3. Lopez and Dahab projective x-coordinate dADD
Input : E/Fq : y2 + xy = x3 + ax2 + b
▷The elliptic curve E over F2m
(Xi : Zi) = x(Pi), i = 0, 1, 2.
▷x(P0) = x(P1 −P2)
Output : (Xi : Zi) = x(Pi), i = 3, 4.
▷x(P3) = x(P1 + P2), x(P4) = x(2P1)
1: function dADD((X0 : Z0), (X1 : Z1), (X2 : Z2))
2:
X3 = X0 (X1Z2 + X2Z1)2 + Z0 (X1Z1X2Z2)
3:
Z3 = Z0 (X1Z2 + X2Z1)2
4:
X4 = (X4
1 + bZ4
1)
5:
Z4 = X2
1 Z2
1
6:
return ((X4 : Z4), (X3 : Z3))
▷The diﬀerential addition and doubling
7: end function
Montgomery ladder can be modiﬁed as Algorithm 4. Here there is no need to
assume that the bit km−1 of the integer k is equal to ‘1’. Also, there is no need to
precompute 2P from the base point P. Moreover, the ladder works properly even
if the integer k is bigger than the order of the base point P. So, for Lopez and
Dahab formulas, one can use random scalar k as a countermeasure to protect
against diﬀerential power analysis attack.
Algorithm 4. The modiﬁed Montgomery scalar multiplication
Input : E/Fq : y2 + xy = x3 + ax2 + b
▷The elliptic curve E over Fq
P = (x : y : z) ∈E(Fq)
▷P ̸= O = (0 : 1 : 0)
k = (km−1, · · · , k1, k0)
▷0 ≤k ∈Z
(X0 : Z0) := (x : z), (X1 : Z1) := (1 : 0), (X2 : Z2) := (x : z).
Output : w(kP)
1: for i := m −1 down to 0 do
2:
if ki = 0 then
3:
((X1 : Z1), (X2 : Z2)) := dADD((X0 : Z0), (X1 : Z1), (X2 : Z2))
4:
else
5:
((X2 : Z2), (X1 : Z1)) := dADD((X0 : Z0), (X2 : Z2), (X1 : Z1))
6:
end if
7: end for
8: return (X1 : Z1), (X2 : Z2)
▷The diﬀerential addition and doubling
3
Binary Edwards Curves
In this section we review the Binary Edwards curve [3] and propose new diﬀer-
ential addition and doubling formulas.
Let d1, d2 be elements of F2m such that d1 ̸= 0 and d2 ̸= d1(d1 + 1). The
binary Edwards curve with parameters d1 and d2 is given by the equation
EB,d1,d2 : d1(x + y) + d2(x + y)2 = xy(x + 1)(y + 1).
(1)

26
R. Rezaeian Farashahi and S.G. Hosseini
The curve is symmetric in x, y and the negation of (x, y) is (y, x). This curve
has two points (0, 0) and (1, 1) which are invariant under the negation law. The
point (0, 0) is the neutral element of the addition law and the point (1, 1) has
order 2. We denote the point (0, 0) by O.
The binary Edwards curve EB,d1,d2 is birationally equivalent to the ordinary
elliptic curve in Weierstraß form
v2 + uv = u3 + au2 + b,
where a, b are in F2m with b ̸= 0. The map (x, y) −→(u, v) deﬁned by
u = ((d3
1 + d2
1 + d1d2)(x + y))/(xy + d1(x + y))
v = (d3
1 + d2
1 + d1d2)(d1 + 1 + x/(xy + d1(x + y))
is a birational equivalence form EB,d1,d2 to the elliptic curve
v2 + uv = u3 + (d2
1 + d2)u2 + d4
1(d4
1 + d12 + d2).
Aﬃne Addition. The sum of two points (x1, y1) and (x2, y2) on EB,d1,d2 is the
point (x3, y3) deﬁned as follows:
x3 = d1(x1 + x2) + d2(x1 + y1)(x2 + y2) + (x1 + x2
1)(x2(y1 + y2 + 1) + y1y2)
d1 + (x1 + x2
1)(x2 + y2)
,
(2)
y3 = d1(y1 + y2) + d2(x1 + y1)(x2 + y2) + (y1 + y2
1)(y2(x1 + x2 + 1) + x1x2)
d1 + (y1 + y2
1)(x2 + y2)
.
Aﬃne Doubling. The doubling of point (x1, y1) is the point (x4, y4) deﬁned
as follows:
x4 = 1 +
d1 + d2(x2
1 + y2
1) + y2
1 + y4
1
d1 + (x2
1 + y2
1) + d2/d1(x4
1 + y4
1),
(3)
y4 = 1 +
d1 + d2(x2
1 + y2
1) + x2
1 + x4
1
d1 + (x2
1 + y2
1) + d2/d1(x4
1 + y4
1).
Diﬀerential Addition. Bernstein, Lange and Farashahi in [3] proposed the
diﬀerential addition and doubling formulas for binary Edwards curve. Assume
that P = (x1, y1), Q = (x2, y2) are points on EB,d1,d2 and Q−P = (x0, y0), Q+
P = (x3, y3) and 2P = (x4, y4). They considered w-function as w(xi, yi) = xi+yi
and obtained the following complete formulas for diﬀerential addition:
w4 =
w2
1 + w4
1
d1 + w2
1 + (d2/d1)w4
1
,
w3 + w0 =
d1w1w2(1 + w1)(1 + w2)
d2
1 + w1w2(d1(1 + w1 + w2) + d2(w1w2)),
w3w0 =
d2
1(w2
1 + w2
2)
d2
1 + w1w2(d1(1 + w1 + w2) + d2(w1w2)).

Diﬀerential Addition on Binary Elliptic Curves
27
Assume that w0 is given as a ﬁeld element, and w1, w2 are given as fractions
W1/Z1, W2/Z2 and w4, w3 are outputs as fractions W4/Z4 and W3/Z3. Then,
the mixed projective w-coordinate diﬀerential addition and doubling formulas
are given as follows.
A = W1(W1 + Z1),
B = W2(W2 + Z2),
C = Z1Z2,
D=W1W2,
E =AB,
F = E + (

d1C +

d2/d1 + 1D)2,
W4 = A2,
Z4 = W4 + ((
4
d1Z1 +
4
d2/d1 + 1W1)2)2,
Z3 = F, W3 = E + w0F.
From above formulas, for the general case d1 ̸= d2, the cost of diﬀerential
addition is 6M+1S+2D and the cost of doubling is 1M+3S+2D. And the total
cost is 6M + 4S + 4D. If d1 = d2 the total cost is 5M + 4S + 2D. Recently Kim,
Lee and Negre [10] for the case d1 = d2, by using the co-Z trick improved the
diﬀerential addition formulas by 1D and obtained almost complete diﬀerential
addition formulas with cost of 5M + 4S + 1D.
New Diﬀerential Addition. In this section, we consider binary Edwards curves
in general form and present two new w-coordinates diﬀerential formulas where
one of this formulas is complete and the other is almost complete.
Let deﬁne the rational function w by w(x, y) = (x + y)/(d1(x + y + 1)).
The function is well computed for all aﬃne points on a binary Edwards curve
except for the points (x, y) where x + y = 1. Since −(x, y) = (y, x), for all
points P on the curve, we have w(P) = w(−P). Also, we have w(O) = 0.
As before, for i = 0, 1, 2, 3, 4, let wi = w(Pi), where Pi ∈EB,d1,d2(F2m) with
w(P0) = w(P1 −P2), w(P3) = w(P1 + P2) and w(P4) = w(2P1). From the
addition formula (2), with a straightforward calculation, we obtain the following
diﬀerential addition formulas.
w3 + w0 =
w1w2
d2
1(d2
1 + d1 + d2)w2
1w2
2 + 1 ,
(4)
w3w0 =
w2
1 + w2
2
d2
1(d2
1 + d1 + d2)w2
1w2
2 + 1.
(5)
Also, from the doubling formula (3) and some calculations we obtain
w4 =
w2
1
d2
1(d2
1 + d1 + d2)w4
1 + 1.
(6)
We recall [3] that the binary Edwards curve EB,d1,d2 over F2m is complete if
Tr(d2) = 1. Here Tr is the trace function from F2m to F2. Moreover, if Tr(d1) = 0
then there is no point (x, y) on the curve with x + y + 1 = 0. Since, if there is
a point (x, y) with x + y + 1 = 0 on the curve EB,d1,d2 with Tr(d2) = 1 and
Tr(d1) = 0, then by the curve Eq. (1), we have x4 + x2 + d1 + d2 = 0. Then,
Tr(0) = Tr(x4 + x2 + d1 + d2)
= Tr(x4) + Tr(x2) + Tr(d1) + Tr(d2)
= Tr(x2) + Tr(x2) + 0 + 1 = 1,

28
R. Rezaeian Farashahi and S.G. Hosseini
which is a contradiction. Therefore, the function w is well deﬁned for all aﬃne
points on the complete binary Edwards curve EB,d1,d2 with Tr(d1) = 0.
Notice, the set of aﬃne F2m-rational points of the complete binary Edwards
curve EB,d1,d2 is an abelian group. And, with the condition Tr(d1) = 0, for any
point P = (x, y) on the curve, the value w(P) is well computed and belongs to
F2m. By the Eqs. (4) and (6) we have
(w3 + w0)(d2
1(d2
1 + d1 + d2)w2
1w2
2 + 1) = w1w2 ,
w4(d2
1(d2
1 + d1 + d2)w4
1 + 1) = w2
1.
So, we see that if Tr(d1) = 0 then the denominators of Eqs. (4) and (6)
never equal zero. In other words, above w-coordinates diﬀerential addition
and doubling formulas for complete binary Edwards curve are complete where
Tr(d1) = 0.
For further speedup, we can divide the Eq. (4) by Eq. (5) and obtain the
following faster formula.
1
w3
+ 1
w0
=
w1w2
(w1 + w2)2 .
(7)
Cost of Projective w-Coordinates. Using Eqs. (4) and (6), we obtained new
and complete diﬀerential addition formulas for general binary Edwards curves
with the total cost of 5M + 4S + 2D where the diﬀerence of input points is
aﬃne. Then, by using the Eqs. (6) and (7) we obtain, new and fast, but almost
complete, diﬀerential addition formulas in mixed projective coordinates with
the total cost of 5M + 4S + 1D. Thus, the total cost of diﬀerential addition and
doubling in general binary Edwards curves is reduced from 6M + 4S + 4D to
5M + 4S + 1D.
As before assume that w0 is given as a ﬁeld element, and w1, w2 are given
as fractions W1/Z1, W2/Z2 and w4, w3 are to be output as fraction W4/Z4 and
W3/Z3. From Eq. (6) the explicit doubling formula is given by
W4
Z4
=
W 2
1 Z2
1
(d4
1 + d3
1 + d2
1d2)W 4
1 + Z4
1
(8)
and from Eq. (4) the explicit addition formula is given by
W3
Z3
= W0((d4
1 + d3
1 + d2
1d2) W 2
1 W 2
2 + Z2
1Z2
2) + Z0(W1W2Z1Z2)
Z0((d4
1 + d3
1 + d2
1d2) W 2
1 W 2
2 + Z2
1Z2
2))
.
(9)
So, from the Eqs. (8) and (9), the cost of projective w-coordinates is 7M +
4S + 2D. If we set Z0 = 1, then the mixed projective w-coordinates diﬀerential
addition and doubling formulas have the total cost 5M + 4S + 2D as follows.
A = W1Z1,
B = W1W2,
C = Z1Z2,
W4 = A2,
Z4 = (
4
(d4
1 + d3
1 + d2
1d2)W1 + Z1)4,
(10)
Z3 = (

(d4
1 + d3
1 + d2
1d2)B + C)2,
W3 = BC + w0Z3.

Diﬀerential Addition on Binary Elliptic Curves
29
From Eq. (7), we also obtain the following explicit projective diﬀerential addi-
tion formulas.
Z3
W3
= Z0(W1Z2 + W2Z1)2 + W0(W1Z2W2Z1)
W0(W1Z2 + W2Z1)2
.
(11)
Thus, by Eqs. (8) and (11), the cost of projective w-coordinates is 7M+4S+
2D. If we set W0 = 1 and using the mixed projective coordinates we have the
following formulas for computing diﬀerential addition.
A = W1Z1,
B = W1Z2,
C = W2Z1,
W4 = A2,
Z4 = (
4
(d4
1 + d3
1 + d2
1d2)W1 + Z1)4,
(12)
W3 = (B + C)2,
Z3 = BC + z0W3.
From diﬀerential addition and doubling formulas (12), the costs of diﬀerential
addition and doubling are 4M + 1S, 1M + 3S + 1D respectively. And, the total
cost is 5M + 4S + 1D.
The binary Edwards curve EB,d1,d2, has the neutral element O represented
by w-coordinate as (0 : 1). For the complete binary Edwards curve EB,d1,d2 with
Tr(d1) = 0, any point P on the curve can be represented by (w(P) : 1). In other
words, for any w-coordinate representation of the point P by (W : Z) we have
Z ̸= 0. So, from the completeness of the aﬃne w-coordinates diﬀerential addition
and doubling formulas for complete binary Edwards curve with Tr(d1) = 0,
we deduce that the projective w-coordinates diﬀerential addition and doubling
formulas (8) and (9) are also complete. The mixed projective formulas (10) have
the cost of 5M+4S+2D. Furthermore, the projective w-coordinates diﬀerential
addition and doubling formulas (8) and (11) are almost complete; the exceptional
cases are points P0 where w(P0) = w(O). The mixed projective formulas (12)
have the cost of 5M + 4S + 1D.
4
Binary Hessian Curve
A Hessian curve over a ﬁeld F2m is given by the cubic equation
Hd : x3 + y3 + 1 + dxy = 0 ,
for some d ∈F2m with d3 ̸= 27 [5]. The family is extended to the family of
generalized Hessian [5] or twisted Hessian curves [1]. A generalized Hessian curve
Hc,d over F2m is deﬁned by the equation
Hc,d : x3 + y3 + c + dxy = 0,
where c, d are elements of F2m such that c ̸= 0 and d3 ̸= 27c. The projective
closure of the curve Hc,d is
Hc,d : X3 + Y 3 + cZ3 = dXY Z.

30
R. Rezaeian Farashahi and S.G. Hosseini
It has the points (1 : ω : 0) with ω3 = 1 at inﬁnity. The neutral element of
the group of F2m-rational points of Hc,d is the point at inﬁnity (1 : 1 : 0) that is
denoted by O. And, the negation of point (X : Y : Z) is (Y : X : Z).
Aﬃne Addition. The sum of two diﬀerent points (x1, y1), (x2, y2) on Hc,d is
the point (x3, y3) given by
x3 = y12x2 + y22x1
x2y2 + x1y1
and
y3 = x12y2 + x22y1
x2y2 + x1y1
.
Aﬃne Doubling. The doubling of the point (x1, y1) on Hc,d is the point (x4, y4)
given by
x4 = y1(c + x13)
x13 + y13
and
y4 = x1(c + y13)
x13 + y13 .
Diﬀerential Addition. Farashahi and Joye in [5] adapted diﬀerential addition
formulas for the binary curve Hc,d. They deﬁned the rational function w(x, y) =
x3 + y3. As before, for i = 0, 1, 2, 3, 4, let wi = w(Pi), where Pi are points of
Hc,d(F2m) with w(P0) = w(P1 −P2), w(P3) = w(P1 + P2) and w(P4) = w(2P1).
From [5], we have
w4 = w14 + c3(d3 + c)
d3w12
,
(13)
w0 + w3 =
d3w1w2
(w1 + w2)2
and
w0w3 = w12w22 + c3(d3 + c)
(w1 + w2)2
.
(14)
To have mixed projective formulas, wi are given by the fractions Wi/Zi for
i = 0, 1, 2, 3 where Z0 = 1. The following explicit formulas give the output w3
deﬁned by W3/Z3:
A = W1Z2, B = W2Z1, C = AB, U = d3C, V = (A + B)2,
Z3 = V, W3 = U + w0V.
Moreover, we write w4 by the fraction W4/Z4. Then, the explicit doubling
formulas is
A = W1
2, B = Z1
2, C = A +

c3(d3 + c)B, D = d3B,
W4 = C2, Z4 = AD.
The cost of these mixed w-coordinates is 4M + 1S + 1D for addition and
1M + 3S + 2D for doubling and the total cost is 5M + 4S + 2D.
New Diﬀerential Addition. In this section we present two new diﬀerential
addition formulas for generalized Hessian curve over binary ﬁeld F2m with total
cost of 5M + 4S + 1D for both doubling and addition.
We modify the deﬁnition of the above rational function w, [5], and consider
w(x, y) = x3+y3
d3
. Using the diﬀerential addition formulas (14), by a straightfor-
ward calculations, we obtain the following formulas in aﬃne coordinates.
w3 + w0 =
w1w2
w2
1 + w2
2
,
(15)

Diﬀerential Addition on Binary Elliptic Curves
31
w3w0 = w2
1w2
2 + (c4 + c3d3)/(d12)
w2
1 + w2
2
.
(16)
Also, from the doubling formula (13), the following doubling formula is
obtained.
w4 = w4
1 + (c4 + c3d3)/(d12)
w2
1
.
(17)
Cost of Projective w-Coordinates. To obtain the projective formulas, assume
that wi are given by the fractions Wi/Zi for i = 0, 1, 2, 3, 4. From Eq. (15) the
following explicit formulas give W3/Z3 by
W3
Z3
= W0(W1Z2 + W2Z1)2 + Z0(W1Z2W2Z1)
Z0(W1Z2 + W2Z1)2
.
(18)
Also, from Eq. (17), the doubling is given by
W4
Z4
= W 4
1 + (c4 + c3d3)/(d12) Z4
1
W 2
1 Z2
1
.
(19)
The cost of projective w-coordinates diﬀerential addition and doubling is
7M+4S+1D; see Eqs. (18) and (19). If we set Z0 = 1 then we have the following
mixed projective coordinates formulas with the total cost 5M + 4S + 1D.
A = W1Z1,
B = W1Z2,
C = W2Z1
W4 = (W1 +
4
(c4 + c3d3)/d12 Z1)4,
Z4 = A2,
Z3 = (B + C)2,
W3 = BC + w0Z3.
Here, the diﬀerential addition formulas use 4M + 1S and doubling formulas
use 1M+3S+1D and the total cost is 5M+4S+1D. So the computation of 1D
is saved. Notice, the projective w-coordinate diﬀerential addition and doubling
formulas (18) and (19) are almost complete; the exceptional points are 3 torsion
points P0 where w(P0) = w(O) = (1 : 0).
5
Binary HuﬀCurves
Huﬀmodel at ﬁrst introduced by Huﬀ[7] in 1948 to study a diophantine prob-
lem. Huﬀmodel are extended over ﬁelds of odd characteristic. Joye et al. [9],
extended the Huﬀmodel and also introduced the binary partner for Huﬀcurve.
In 2011 Devigen and Joye [4] described the addition law for Binary Huﬀcurve
and compute formulas for addition, doubling and diﬀerential addition which the
cost of their diﬀerential addition and doubling is 5M+5S+1D. Here, we improve
their results to the cost of 5M + 4S + 1D.
The binary Huﬀcurve is given by the equation
HFa,b : ax(y2 + y + 1) = by(x2 + x + 1),
(20)

32
R. Rezaeian Farashahi and S.G. Hosseini
where a, b are in F2m such that a, b ̸= 0 and a ̸= b. This curve have three points
at inﬁnity, namely (a : b : 0), (1 : 0 : 0) and (0 : 1 : 0). Binary Huﬀcurve is
birationally equivalent to the Weierstrasß elliptic curve
v2 + uv = u3 + (a2 + b2)u2 + a2b2u
via the map (x, y) −→(u, v) deﬁned by
u = ab
xy ,
v = ab(axy + b)
x2y
with the inverse map
x = b(u + a2)
v
,
y =
a(u + b2)
v + (a + b)u.
The neutral element of binary Huﬀcurve is the point (0, 0). The negation of the
point (x, y) is (˜x, ˜y) where
˜x = y(b + axy)
a + bxy
,
˜y = x(a + bxy)
b + axy
.
Aﬃne Addition. The sum of two points (x1, y1) and (x2, y2) on HFa,b is the
point (x3, y3) deﬁned as follows:
x3 = (x1y1 + x2y2)(1 + y1y2)
(y1 + y2)(1 + x1x2y1y2),
y3 = (x1y1 + x2y2)(1 + x1x2)
(x1 + x2)(1 + x1x2y1y2).
(21)
Aﬃne Doubling. The doubling of point (x1, y1) is the point (x4, y4) deﬁned
as follows:
x4 =
(a + b)x2
1(1 + y2
1)
b(1 + x2
1)(1 + x2
1y2
1),
y4 =
(a + b)y2
1(1 + x2
1)
a(1 + y2
1)(1 + x2
1y2
1).
(22)
As b ̸= 0 we can divide the Eq. (20) by b and for simplicity we can assume
b = 1. So, we consider the binary Huﬀcurve with the equation
ax(y2 + y + 1) = y(x2 + x + 1)
where a ̸= 0, 1.
Diﬀerential Addition. Devigen and Joye, [4], proposed the rational function
w(x, y) = xy for the binary Huﬀcurves. They obtained the following aﬃne
w-coordinates formulas
w4 = (a2 + 1)/aw2
1
1 + w4
1
,
w3 =
(w1 + w2)2
w0(1 + w1w2)2 .
The projective coordinates of the formulas are
W4 = (a2 + 1)/a(W1Z1)2,
Z4 = (W1 + Z1)4,
W3 = w0(W1Z2 + W2Z1)2,
Z3 = (W1W2 + Z1Z2)2.

Diﬀerential Addition on Binary Elliptic Curves
33
The cost of this w-coordinates in one step of the Montgomery ladder is 5M+
5S + 1D.
New Diﬀerential Addition. Here, we modify the rational function w(x, y) =
xy on binary Huﬀcurve by scaling to w(x, y) =
(a2+1)
a
xy. This new rational
function reduces the cost of diﬀerential addition by 1S. As before, we use the
same notation for diﬀerential addition and doubling. From addition formulas
(21), we obtain the following formulas in aﬃne coordinates.
w3 + w0 =
w1w2
(a/(a2 + 1))4w2
1w2
2 + 1,
(23)
w3w0 =
w2
1 + w2
2
(a/(a2 + 1))4w2
1w2
2 + 1.
(24)
The doubling formula (22) provides the following aﬃne doubling formula.
w4 =
w2
1
(a/(a2 + 1))4w4
1 + 1.
(25)
Then, by Eqs. (23) and (24) we have
1
w3
+ 1
w0
=
w1w2
(w1 + w2)2 .
(26)
Cost of Projective w-Coordinates. Assume that wi are given by the fractions
Wi/Zi for i = 0, 1, 2, 3, 4. By Eq. (26) the following explicit formulas give the
output W3/Z3 by
Z3
W3
= Z0(W1Z2 + W2Z1)2 + W0(W1Z2W2Z1)
W0(W1Z2 + W2Z1)2
.
(27)
Also, from Eq. (25) the explicit doubling formulas is obtained.
W4
Z4
=
W 2
1 Z2
1
W 4
1 + (a/(a2 + 1))4 Z4
1
.
(28)
So, the cost of projective w-coordinates diﬀerential addition and doubling is
7M+4S+1D; see Eqs. (27) and (28). Let assume W0 = 1. Then using the mixed
projective coordinates, we have the following formulas for diﬀerential addition:
A = W1Z1,
B = W1Z2,
C = W2Z1,
Z4 = (W1 + (a/(a2 + 1))Z1)4,
W4 = A2,
W3 = (B + C)2,
Z3 = BC + z0Z3.
Here, the addition formulas use 4M + 1S and doubling formulas use 1M +
3S + 1D. The total cost is 5M + 4S + 1D and one S is saved. Moreover the
projective w-coordinates diﬀerential addition and doubling formulas (27) and
(28) are almost complete.

34
R. Rezaeian Farashahi and S.G. Hosseini
6
Comparison with Previous Works
In Table 1, we compare our new diﬀerential addition formulas with other models
of binary elliptic curves. The addition formulas for all binary elliptic are complete
or almost complete which makes the Montgomery ladder work perfectly in cryp-
tographic applications. The cost of almost complete formulas is 5M + 4S + 1D
that is the best known record. We believe this record may be obtained for any
form of binary elliptic curve by a suitable rational function. The proposed for-
mulas for general binary Edwards are improved in terms of eﬃciency and speed.
The complete formulas for binary Edwards curves are the only known complete
formulas for binary elliptic curves with the cost of 5M + 4S + 2D.
Table 1. Cost of diﬀerential addition and doubling for families of binary elliptic curves
Model
Projective diﬀerential Mixed diﬀerential Completeness
Short Weierstraß [2] 7M + 4S + 1D
5M + 4S + 1D
Almost
Binary Edwards
(general) [3]
8M + 4S + 4D
6M + 4S + 4D
Yes
(d1 = d2) [3]
7M + 4S + 2D
5M + 4S + 2D
Yes
(d1 = d2) [10]
7M + 4S + 2D
5M + 4S + 1D
Almost
(general) this work
7M + 4S + 2D
5M + 4S + 2D
Yes
(general) this work
7M + 4S + 1D
5M + 4S + 1D
Almost
Binary Hessian [5]
7M + 4S + 2D
5M + 4S + 2D
Almost
This work
7M + 4S + 1D
5M + 4S + 1D
Almost
Binary Huﬀ[4]
6M + 4S + 2D
5M + 5S + 1D
Almost
This work
7M + 4S + 1D
5M + 4S + 1D
Almost
Acknowledgment. The authors would like to thank anonymous reviewers for their
useful comments. This research was in part supported by a grant from IPM (No.
93050416).
References
1. Bernstein, D.J., Chuengsatiansup, C., Kohel, D., Lange, T.: Twisted Hessian
curves. In: Lauter, K., Rodr´ıguez-Henr´ıquez, F. (eds.) LATINCRYPT 2015.
LNCS,
vol.
9230,
pp.
269–294.
Springer,
Heidelberg
(2015).
doi:10.1007/
978-3-319-22174-8 15
2. Bernstein, D., Lange, T.: Explicit-formulas database. http://www.hyperelliptic.
org/EFD/
3. Bernstein, D.J., Lange, T., Rezaeian Farashahi, R.: Binary Edwards curves. In:
Oswald, E., Rohatgi, P. (eds.) CHES 2008. LNCS, vol. 5154, pp. 244–265. Springer,
Heidelberg (2008). doi:10.1007/978-3-540-85053-3 16

Diﬀerential Addition on Binary Elliptic Curves
35
4. Devigne, J., Joye, M.: Binary Huﬀcurves. In: Kiayias, A. (ed.) CT-RSA
2011. LNCS, vol. 6558, pp. 340–355. Springer, Heidelberg (2011). doi:10.1007/
978-3-642-19074-2 22
5. Farashahi, R.R., Joye, M.: Eﬃcient arithmetic on Hessian curves. In: Nguyen,
P.Q., Pointcheval, D. (eds.) PKC 2010. LNCS, vol. 6056, pp. 243–260. Springer,
Heidelberg (2010). doi:10.1007/978-3-642-13013-7 15
6. Gaudry, P., Lubicz, D.: The arithmetic of characteristic 2 Kummer surface. Finite
Fields Appl. 246–260 (2009)
7. Huﬀ, G.B.: Diophantine problems in geometryand elliptic ternary forms. Duke
Math. J. 15, 246–260 (1948)
8. Joye, M., Quisquater, J.-J.: Hessian elliptic curves and side-channel attacks. In:
Ko¸c, C¸.K., Naccache, D., Paar, C. (eds.) CHES 2001. LNCS, vol. 2162, pp. 402–
410. Springer, Heidelberg (2001). doi:10.1007/3-540-44709-1 33
9. Joye, M., Tibouchi, M., Vergnaud, D.: Huﬀ’s model for elliptic curves. In: Han-
rot, G., Morain, F., Thom´e, E. (eds.) ANTS 2010. LNCS, vol. 6197, pp. 234–250.
Springer, Heidelberg (2010). doi:10.1007/978-3-642-14518-6 20
10. Kim, K.H., Lee, C.O., Negre, C.: Binary Edwards curves revisited. In: Meier,
W., Mukhopadhyay, D. (eds.) INDOCRYPT 2014. LNCS, vol. 8885, pp. 393–408.
Springer, Heidelberg (2014). doi:10.1007/978-3-319-13039-2 23
11. Koblitz, N.: Elliptic curves cryptosystem. Math. Comput. 48, 203–209 (1987)
12. Kohel, D.: Eﬃcient arithmetic on elliptic curves in characteristic 2. In: Galbraith,
S., Nandi, M. (eds.) INDOCRYPT 2012. LNCS, vol. 7668, pp. 378–398. Springer,
Heidelberg (2012). doi:10.1007/978-3-642-34931-7 22
13. Lopez, J., Dahab, R.: Improved algorithms for elliptic curve arithmetic in GF(2n)
without precomputation. CHES, 220–254 (1999)
14. Miller, V.S.: Use of elliptic curves in cryptography. In: Williams, H.C. (ed.)
CRYPTO 1985. LNCS, vol. 218, pp. 417–426. Springer, Heidelberg (1986). doi:10.
1007/3-540-39799-X 31
15. Montgomery, P.L.: Speeding the polard and elliptic curves methods of factorization.
Math. Comput. 48, 243–264 (1987)
16. Montgomery, P.L.: Modular multiplication without trial division. Math. Comput.
48, 243–264 (1987)
17. Smart, N.P.: The Hessian form of an elliptic curve. In: Ko¸c, C¸.K., Naccache, D.,
Paar, C. (eds.) CHES 2001. LNCS, vol. 2162, pp. 118–125. Springer, Heidelberg
(2001). doi:10.1007/3-540-44709-1 11
18. Washington, L.C.: Elliptic Curves Number Theory and Cryptography. CRC Press,
Boca Raton (2008)

Adequate Elliptic Curves for Computing
the Product of n Pairings
Loubna Ghammam1,2(B) and Emmanuel Fouotsa3,4
1 IRMAR, UMR CNRS 6625, Universit´e Rennes 1,
Campus de Beaulieu, 35042 Rennes Cedex, France
ghammam.loubna@yahoo.fr
2 Laboratoire d’´electronique et de micro´electronique,
FSM Monastir Universit´e de Monastir, Monastir, Tunisia
3 LMNO, UMR CNRS 5139 Universit´e de Caen, Campus 2,
14032 Caen Cedex, France
emmanuelfouotsa@yahoo.fr
4 Higher Teacher Training College, University of Bamenda,
P.O. Box 39, Bambili, Cameroon
Abstract. Many pairing-based protocols require the computation of the
product and/or of a quotient of n pairings where n > 1 is a natural inte-
ger. Zhang et al. [1] recently showed that the Kachisa-Schafer and Scott
family of elliptic curves with embedding degree 16 denoted KSS16 at the
192-bit security level is suitable for such protocols comparatively to the
Baretto-Lynn and Scott family of elliptic curves of embedding degree 12
(BLS12). In this work, we provide important corrections and improve-
ments to their work based on the computation of the optimal Ate pairing.
We focus on the computation of the ﬁnal exponentiation which represent
an important part of the overall computation of this pairing. Our results
improve by 864 multiplications in Fp the computations of Zhang et al.
[1]. We prove that for computing the product or the quotient of 2 pair-
ings, BLS12 curves are the best solution. In other cases, especially when
n > 2 as mentioned in [1], KSS16 curves are recommended for computing
product of n pairings. Furthermore, we prove that the curve presented
by Zhang et al. [1] is not resistant against small subgroup attacks. We
provide an example of KSS16 curve protected against such attacks.
Keywords: BN curves · KSS16 curves · BLS curves · Optimal Ate
pairing · Product of n pairings · Subgroup attacks
1
Introduction
Pairing-based cryptography is another way of building cryptographic protocols.
Thanks to the various and steady improvements for the computation of pairings
This work was supported in part by French ANR projects PEACE and ANR-12-
INSE-0014 SIMPATIC, LIRIMA MACISA project and centre Henri Lebesgue, The
Simons Foundations through Pole of Research in Mathematics with applications to
Information Security, Subsaharan Africa.
c
⃝Springer International Publishing AG 2016
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 36–53, 2016.
DOI: 10.1007/978-3-319-55227-9 3

Adequate Elliptic Curves for Computing the Product of n Pairings
37
on elliptic curves together with their implementation, several protocols have been
published [2–6]. The BN [7] family of elliptic curves are the most suitable for
implementing pairing-based cryptography at the 128-bit security level. At the
high security level, the BLS12 [8] curves are recommended for computing the
optimal Ate pairing according to the results presented in [9,10].
Many pairing-based protocols require the computation of products or quo-
tients of pairings. Some of them require the computation of two pairings [11],
others require three pairings [12] and even more than three pairings as in [13,14].
The few works that studied an eﬃcient computation of products of pairings are
those of Granger and Smart [1,15]. In particular, Zhang et al. [1] have recently
shown that the KSS16 [16] elliptic curves are more suitable when computing
products or quotients of optimal Ate pairings at the 192-bit security level. In
their work they gave explicit formulas and cost evaluation for the Miller loop
and developed interesting ways of computing the hard part of the ﬁnal exponen-
tiation. Unfortunately their results contain several forgotten operations costing
1332 multiplications in the base ﬁeld Fp. In this work we study the computation
of the optimal Ate pairing on KSS16 curves. We present also a new multiple
of the hard part of the ﬁnal exponentiation of the optimal Ate pairing. This
new multiple enabled us to improve the cost of the computation of the hard
part of the ﬁnal exponentiation with respect to the work of Zhang et al. [1]. We
also compare the eﬃciency of KSS16 curves when computing product of pairings
with respect to other common curves at the same security level. We also ana-
lyzed the resistance of the KSS16 curves to the small subgroup attack following
the approach described in [17]. More precisely, the contribution of this work is
as follows:
1. We ﬁrst pointed out ignored operations in the computation of the optimal
Ate pairing (ﬁnal exponentiation) on KSS16 curves by Zhang et al. [1] and
give detailed cost of operations with a magma code to verify the formulas
[18]. Despite the improvement we obtained for the computation of the ﬁnal
exponentiation in this case and based on the fastest known result to date to
our knowledge, we show that BLS12 curves are suitable for the computation
of products of two pairings at the high security level and not KSS16 curves
as recommended in [1]. We also proved that for computing n pairings where
n > 2 then KSS16 curves are the best solution.
2. In [17], Barreto et al. recently studied the resistance of BN, BLS and KSS18
curves to small subgroup attacks. We extend the same analysis to KSS16
curves. In particular we show that the parameters used in [1] do not ensure
protection of these curves to such attacks and we provide an example of
KSS16 curve resistant to this attack.
The rest of this work is organized as follows: Sect. 2 recalls results from [1] on
optimal Ate pairing on KSS16 curves. We point out the forgotten operations
and bring corrections and improvements in the computation of the ﬁnal expo-
nentiation. In Sect. 3, we present our new multiple of the hard part of the ﬁnal
exponentiation d′. We prove that by using the new vector we saved 864M with
respect to the corrected work of Zhang et al. in the computation of the optimal

38
L. Ghammam and E. Fouotsa
Ate pairing over KSS16 curves. Section 4 deﬁnes products of pairings and their
eﬃcient computation. Detailed costs of the calculation and comparison are then
done with commonly pairing-friendly curves at the high security level. The Sect. 5
concerns the resistance of the KSS16 curves against small subgroup attacks. We
show that the curve used in [1] is not protected against small subgroup attack
and provide an adequate example. We conclude our work in Sect. 6.
Notations: In this paper we denote by:
– Mk a multiplication in Fpk.
– Sk a squaring in Fpk.
– Fk a Frobenius map in Fpk.
– Ik an inversion in Fpk.
– Sc a cyclotomic squaring in Fp16.
– Cc a cyclotomic cube in Fp16.
A multiplication, a square and an inversion in Fp are denoted respectively by M,
S and I.
2
Pairings at High Security Level
The 192-bit security level is one of the highest security level recommended when
implementing cryptographic protocols based on pairings. Aranha et al. [9] rec-
ommended the implementation of optimal Ate pairing at this security level over
BLS12 curves. Their results on BLS12 curves have been improved by Ghammam
and Fouotsa in [10] and still conﬁrm that BLS12 curves are a better solution for
implementation at the 192-bit security level. Recently, Zhang et al. [1] consid-
ered the computation of the optimal Ate pairing over KSS16 curves at the same
security level. They proved in particular that this family of curves is suitable for
computing products or quotients of pairings generally involved in many pairing-
based protocols. In this section we review their computation of the optimal Ate
pairing and in particular we bring corrections to shortcomings in their work and
give improvements in the computation of the hard part of the ﬁnal exponenti-
ation. The previous data on costs of computing optimal Ate pairing from the
literature at the 192-security level are given in Table 1.
Table 1. Latest best costs of optimal Ate pairing at the 192-bit security level.
Elliptic curves
Size of p
(bit)
Complexity of
Miller loop
Complexity of the
ﬁnal exponentiation
BLS12 Curves [10] 640
10785M
8116M+6I
BLS24 Curves [10] 480
14574M
23864M+10I
BN Curves [9]
640
16553M
7218M+4I
KSS18 Curves [9]
480
13168M
23821M+8I

Adequate Elliptic Curves for Computing the Product of n Pairings
39
Remark 1. Recently, Kim presented in [19] improvements in discrete logarithm
computation in ﬁnite ﬁelds of the form Fp12. Then Jeong and Kim generalized
it in [20]. They proved the same result for any composite extension degree n
when the prime p is of a special form which is the case of BN, BLS and KSS
curves which we studied in this paper. Therefore, these curves no longer provide
a 192-bit security level. However, they still present a high security level since it
is more than the 128-bit security level.
2.1
The KSS16 Family of Elliptic Curves and Optimal Ate Pairing
Kachisa et al. proposed in [16] a family of pairing-friendly elliptic curves of
embedding degree k ∈{16, 18, 32, 36, 40}. The main idea of their construction
of these families of curves is to use the minimal polynomial of the elements of
the cyclotomic ﬁeld rather than the cyclotomic polynomial φk(x) to deﬁne the
cyclotomic ﬁeld.
The family of curve with k = 16 which is called KSS16 curves is parameterised
as follows:
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
t =1/35

2u5 + 41u + 35

r =u8 + 48u4 + 625
p = 1
980(u10 + 2u9 + 5u8 + 48u6 + 152u5 + 240u4 + 625u2+
2398u + 3125)
(1)
and the equation of the elliptic curve deﬁned over Fp is of the form
y2 = x3 + ax
where t is the trace of the Frobenius endomorphism on E, p is the ﬁeld size and
r presents the order the pairing-friendly subgroup. Let G1 = E(Fp)[r] be the
r-torsion subgroup of E(Fp) and G2 = E′(Fp4)[r]∩Ker(πp −[p]) where E′ is
the quartic twist of E. The subgroup of F⋆
p16 consisting of r-th roots of unity
is denoted by G3 = μr. Consider the function fu,Q with divisor Div(fu,Q) =
u(Q) −([u]Q) −(u −1)(O) and ℓR,S the straight line passing through the points
R and S of the elliptic curve.
Proposition 2. [1] The optimal Ate pairing on the KSS16 curves is the bilinear
and non degenerated map:
eopt : G1 × G2 →G3
(P, Q) −→

(fu,Q(P)l[u]Q,[p]Q(P))p3lQ,Q(P)
	 p16−1
r
The parameter u proposed by Zhang et al. [1] is
u = 249 + 226 + 215 −27 −1
which is a 49-bit integer of Hamming weight equal to 5 so that r has a prime
factor of 377 bits and p is a prime integer of 481 bits. The computation of pairing
involves two main steps: the Miller loop and the ﬁnal exponentiation.

40
L. Ghammam and E. Fouotsa
2.2
The Miller Loop
In our case, to compute the optimal Ate pairing in Proposition 2, the Miller loop
consists of the computation of (fu,Q(P)·l[u]Q,[p]Q(P))p3 ·lQ,Q(P). Let u = un2n+
· · · + u12 + u0 with ui ∈{−1, 0, 1}. The computation of the function fu,Q(P) is
done thanks to the algorithm in Table 2 known as the Miller algorithm [21]. The
Miller loop consists of computing fu,Q(P), l[u]Q,[p]Q(P), lQ,Q(P) and two sparse
multiplications in Fp16 to multiply terms together and one p3-Frobenius.
Table 2. Miller algorithm.
Miller algorithm: Input: u = (un, un−1, . . . , u0),P,Q,
Output:(fu,Q(P) · l[u]Q,[p]Q(P))p3 · lQ,Q(P)
1: Set f1 ←1 and R ←Q
2: For i = n −1 down to 0 do
3:
f1 ←f 2
1 · ℓR,R(P),
R ←2R
Doubling step
5:
if ui = 1 then
6:
f1 ←f1 · ℓR,Q(P)
R ←R + Q, end if
Addition step
7:
if ui = −1 then
8:
f1 ←f1 · ℓR,−Q(P)
R ←R −Q, end if
Addition step
9: end For
10: return f1 = fu,Q(P)
The computation of fu,Q(P) costs 49 doubling steps with associated line eval-
uation, 4 addition steps with line evaluations, 48 squarings in Fp16 and 52 sparse
multiplications in Fp16. We then need an extra 2p-Frobenius maps for comput-
ing [p]Q and [u]Q is obtained through the computation of fu,Q(P). Thus we have
to perform 8 multiplications in Fp, a multiplication in Fp4 and one squaring in
Fp4 plus 2p-Frobenius to compute l[u]Q,[p]Q(P). We need also 8 multiplications
in Fp, 4 multiplications in Fp4, and one squaring in Fp4 to compute lQ,Q(P) (see
[1] for formulas and complete details on the costs).
Therefore, the overall cost of the computation of the Miller loop, as mentioned
in [1], is 49 doubling steps with associated line evaluations, 4 addition steps with
line evaluations, 48 squarings in Fp16, 54 sparse multiplications in Fp16, 2p, p3
Frobenius maps in Fp16, 16 multiplications in Fp, 5 multiplications in Fp4 and
one squaring in Fp4. From Table 4 of [1], the Miller loop of the optimal Ate
pairing on KSS16 curve costs about 10208 multiplications in Fp.
2.3
The Final Exponentiation
The second step in computing the optimal Ate pairing is the ﬁnal exponentiation
which consists of raising the result f1 of
the Miller loop to the power p16−1
r
.
Thanks to the cyclotomic polynomial, this expression is simpliﬁed and presented
as follows:
f
p16−1
r
1
= (f p8−1
1
)
p8+1
r
.

Adequate Elliptic Curves for Computing the Product of n Pairings
41
First we have to compute f = f p8−1
1
which is called the simple part of the ﬁnal
exponentiation. This costs one p8–Frobenius, an inversion and a multiplication
in Fp16. Raising f to the power p8+1
r
is called the hard part of the ﬁnal expo-
nentiation. In [1], Zhang et al. considered a multiple of the second part of the
ﬁnal exponentiation. So instead of computing f d they computed f 857500d where
d = p8+1
r
. This choice enables them to only have integer coeﬃcients in the rep-
resentation of d1 = 857500d in base p which is a simple way for computing this
hard part of the ﬁnal exponentiation.
p8 + 1
r
=
φ(16)−1

i=0
cipi = c0 + c1p + c2p2 + · · · + c7p7
Where:
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
c0 = −11u9 −22u8 −55u7 −278u5 −1172u4 −1390u3 + 1372
c1 = 15u8 + 30u7 + 75u6 + 220u4 + 1280u3 + 1100u2
c2 = 25u7 + 50u6 + 125u5 + 950u3 + 3300u2 + 4750u
c3 = −125u6 −250u5 −625u4 −3000u2 −13000u −15000
c4 = −2u9 −4u8 −10u7 + 29u5 −54u4 + 154u3 + 4704
c5 = −20u8 −40u7 −100u6 −585u4 −2290u3 −2925u2
c6 = 50u7 + 100u6 + 250u5 + 1025u3 + 4850u2 + 5125u
c7 = 875u2 + 1750u + 4375
(2)
Then Zhang et al. presented a very nice decomposition of ci where i ∈
{0, 1, 2, 3, 4, 5, 6, 7}. This representation enabled them to quickly compute the
hard part of the ﬁnal exponentiation. Let
A = u3.B + 56 and B = (u + 1)2 + 4, then
⎧
⎪
⎪
⎨
⎪
⎪
⎩
c0 = −11(u4A + 27u3B + 28) + 19A; c4 = −(2u4A + 55u3B) + 84A
c1 = 5(3u3A + 44u2B) = 5c′
1;
c5 = −5(4u3A + 117u2B) = −5c′
5
c2 = 25(u2A + 38uB) = 25c′
2;
c6 = 25(2u2A + 41uB) = 25c′
6
c3 = −125(uA + 24B) = −125c′
3;
c7 = 125.7B = 125c′
7
The problem with this representation is that when we recomputed these expres-
sions we discovered that there is a missing term in the expression of c0. In fact

c0 = −11u9 −22u8 −55u7 −278u5 −1172u4 −1390u3 + 1372
= −11(u4A + 27u3B + 28) + 19A + 616
(3)
We veriﬁed also the algorithm presented in Appendix A of [1] where the term
f 616 is missing in the computation of the ﬁnal exponentiation. Fortunately, the
expression of c0 do not inﬂuence the rest of the expressions ci with 0 < i < 8.
Therefore, we have to add this term to the ﬁnal result of the hard part of the

42
L. Ghammam and E. Fouotsa
ﬁnal exponentiation of the optimal Ate pairing. Using the square-and-multiply
algorithm, the additional step f 616 costs 8 squarings and 3 multiplications in
Fp16 but we will not add this cost because they are terms precomputed in the
algorithm of Zhang et al. We will add to their algorithm these operations after
the ﬁrst term of the original algorithm:
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
A0 ←T38
A1 ←A0 · T3
A2 ←A1 · T2
A3 ←T12
A2 ←A3 · A2
(4)
By adding these operations we got in A2 the missing term f 616. At the end of
the algorithm presented by Zhang et al. we have to add this term to the ﬁnal
result costing an extra multiplication. So the additional cost is 4 multiplications
and 4 squarings in Fp16.
Other shortcomings with their algorithm that computed the hard part of the
ﬁnal exponentiation concern the computation of c′
5, c′
0 and c′
4. In fact, in the
expression of c′
0, the output of their algorithm is −11(u4A + 55u3B + 28) + 35A
instead of the result −11(u4A + 55u3B + 28) + 19A. Also, the expression of c′
4
computed in their algorithm is −(2u4A + 55u3B) + 148A not as mentioned in
the development which is −(2u4A + 55u3B) + 84A.
The expression of c′
5 is deduced by multiplying the term stocked in the tem-
porary variable T11 by the term stocked in F14 and not by the one recorded in
F25. Also in the computation of c′
7 we must perform the operation F5.T4 instead
of F5.T6.
Therefore we must perform some modiﬁcations in the original algorithm to
have the coherent result at the end. We presented the corrected algorithm in
Appendix A, Table 9, and a magma code for the veriﬁcation of formulas is avail-
able in [18]. The additional corrections cost 4 multiplications and 3 squarings in
Fp16 instead of 3 multiplications and 4 squarings which is the cost of the oper-
ations before our modiﬁcations. Furthermore Zhang et al. claimed that in the
ﬁnal algorithm they used only 16 squarings, but it is not the case because by a
simple count we found that one is forced to perform 38 squarings in Fp16.
As a consequence to compute the ﬁnal exponentiation we have to perform 7
exponentiations by u, 2 exponentiations by (u + 1), one inversion, 44 cyclotomic
squarings in Gφ2(p8), 38 multiplications in Fp16, 2 cyclotomic cubings in Fp16 and
p, p2, p3, p4, p5, p6, p6, p7, p8-Frobenius maps.
In Table 3 we present the new cost of the ﬁnal exponentiation of the optimal
Ate pairing after our correction of the result of the work in [1]. Hence, by adding
some modiﬁcations to the original result the overall cost of the optimal Ate
pairing on KSS16 curve is 33870M+I. So we have extra 1332 multiplications in
Fp than the cost presented in [1].

Adequate Elliptic Curves for Computing the Product of n Pairings
43
Table 3. Complexity of the optimal Ate pairing.
The method
Complexity of
Miller loop
Complexity of the
ﬁnal exponentiation
Method of [1]
10208 M
22330M+I
Our correction 10208 M
23662M+I
3
A New Multiple of the Hard Part of the Final
Exponentiation
An eﬃcient method to compute the hard part is described by Scott et al. [22].
They suggested to write d = φk(p)
r
in base p as d = d0+d1p+· · ·+dφ(k)−1pφ(k)−1
and ﬁnd a short vector addition chain to compute f d much more eﬃciently than
the naive method. In [23], based on the fact that a ﬁxed power of a pairing is
still a pairing, Fuentes et al. [23] suggested to apply Scott et al.’s method with
a power of any multiple d′ of d with r not dividing d′. This could lead to a more
eﬃcient exponentiation than a direct computation of f d. Their idea of ﬁnding
the polynomial d′(x) is to apply the LLL-algorithm to the matrix formed by Q-
linear combinations of the elements d(x), xd(x), . . . , xdegr−1d(x). In this paper
we tried to ﬁnd a new multiple of d1 = 857500 · d (with r not dividing d). We
use a lattice-based method to ﬁnd d′ such that f d′ can be computed in a more
eﬃcient way than computing f 857500·d.
Thanks to the LLL algorithm [24], the best vector that we found is given by:
d′(u) = m0 + m1p + m2p2 + m3p3 + m4p4 + m5p5 + m6p6 + m7p7 = s(u)d1
where
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
s(u) = u3/125
m0 = 2u8 + 4u7 + 10u6 + 55u4 + 222u3 + 275u2
m1 = −4u7 −8u6 −20u5 −75u3 −374u2 −375u
m2 = −2u6 −4u5 −10u4 −125u2 −362u −625
m3 = −u9 −2u8 −5u7 −24u5 −104u4 −120u3 + 196
m4 = u8 + 2u7 + 5u6 + 10u4 + 76u3 + 50u2
m5 = 3u7 + 6u6 + 15u5 + 100u3 + 368u2 + 500u
m6 = −11u6 −22u5 −55u4 −250u2 −1116u −1250
m7 = 7u5 + 14u4 + 35u3 + 392
(5)
Our aim in this section by presenting the new vector d′ is to reduce the com-
plexity of computing the hard part of the ﬁnal exponentiation for the optimal
Ate pairing in KSS16 curves and then the complexity of computing the product
of n pairings. Let

A = u3B + 56
B = (u + 1)2 + 4

44
L. Ghammam and E. Fouotsa
then we can write the expressions of mi where 0 < i < 8 more simply as follows:
⎧
⎪
⎪
⎨
⎪
⎪
⎩
m0 = 2u3A + 55u2B;
m4 = u3A + 10u2B
m1 = −4u2A −75uB;
m5 = 3u2A + 100uB
m2 = −2uA −125B;
m6 = −11uA −250B
m3 = −u4A −24u3B + 196; m7 = 7A
These new expressions enabled us to be faster than Zhang et al. in the computa-
tion of the hard part of the ﬁnal exponentiation. We detailed the computation of
the ﬁnal exponentiation in the algorithm presented in Appendix A, Table 8, and
a magma code for the veriﬁcation of formulas is available in [18]. The overall cost
of this algorithm is then 7 exponentiations by u, 2 exponentiations by (u+1), 34
cyclotomic squarings in Gφ2(p8), 32 multiplications in Fp16, 3 cyclotomic cubings
in Fp16 and p, p2, p3, p4, p5, p6, p6, p7, p8-Frobenius maps.
Table 4. Comparison between Zhang et al. and our new development.
Method
Algorithm Complexity
Sc
M16 F16 Cc
Zhang et al.
1
44
37
8
1
Our development 2
34 32
8
3
Our result of computing the hard par of the ﬁnal exponentiation is compared
with the corrected result presented in Sect. 2.3 in Table 4. For a full comparison,
we consider the example presented in [1]. The extension tower is built as follows:
– Fp4 = Fp[v]/

v4 + 3)

– Fp8 = Fp4[w]/

w2 −v

– Fp16 = Fp8[z]/

z2 −w

The cost of operations for computing the optimal Ate pairing on KSS16 curve
are presented in Table 4 of [1].
Table 5. Comparison between the two vectors d and d′.
The result
Complexity of
algorithm
Complexity of the hard part
the ﬁnal exponentiation
Corrected result of [1] See cost in Table 8 23537M
Our new algorithm
See cost in Table 9 22673M
In Table 5 we compared the complexity in Fp of our result using a new mul-
tiple of the hard part of the ﬁnal exponentiation and the corrected one of Zhang
et al. In this table we remark that our computations are faster than those pre-
sented in [1] for computing the hard part of the ﬁnal exponentiation. We saved
about 864 multiplications in Fp which is an interesting result if one is inter-
ested in hardware or software implementations of the optimal Ate pairing at the
192-security level.

Adequate Elliptic Curves for Computing the Product of n Pairings
45
4
On Computing Products of n Pairings
In some protocols, for example in the BBG HIBE scheme [25], the BLS short
group signature scheme [5], ABE scheme due to Waters [14], the non interactive
proof systems proposed by Groth and Sahai [26] and others [11,13], it is necessary
to compute the product or the quotient of two or more pairings. Scott in [27] and
Granger et al. in [15] investigated the computation of the product of n pairings.
Let
e : G1 × G2 →G3
a bilinear non-degenerated map from two additive groups G1 and G2 to G3 a
multiplicative group. The evaluation of a product of n pairings is of the form
en =
n

i=1
e(Pi, Qi)
In this section we are interested by the computation of n pairings. We give a
comparison of this computation for diﬀerent category of curves at the 192-bit
security level. For this security level it is recommended by Aranha et al. in [9]
to use the BLS12 curves to compute the optimal Ate pairing. In this section and
in the case where one computes the product of n optimal Ate pairings, we will
prove that this category of curves are not a solution for all n specially where
n > 2. We prove also that the KSS16 curves, proposed as the best solution for
computing the product of n pairings by Zhang et al. in [1] are not the best
for n = 2. We First recall in Table 6 the diﬀerent formulas for the optimal Ate
pairing over common families of pairing-friendly curves such as KSS16, KSS18,
BN, BLS12 and BLS24 curves. For computing the optimal Ate pairing we have
two steps: The Miller loop and the ﬁnal exponentiation. The computation of the
product of n pairings consists only of the computation of the product of n Miller
loops followed by the evaluation of the result of the ﬁnal exponentiation. Recall
that in the Miller loop (see the algorithm in Table 2) we have to compute the
following step:
f ←f 2l(Q)
(6)
Table 6. Optimal Ate pairing on elliptic curves.
Curve
Optimal Ate pairing: (P, Q) →
KSS16 [1]

(fu,Q(P)l[u]Q,[p]Q(P))p3lQ,Q(P)
 p16−1
r
KSS18 [9]

fu,Q(P)f p
3,Ql[u]Q,[3p]Q(P)
 p18−1
r
BN [9]

(f6u+2,Q(P)l[6u+2]Q,[p]Q(P)l[6u+2]Q,[−p2]Q(P))
 p12−1
r
BLS12 [9] (fu,Q(P))
p12−1
r
BLS24 [9] (fu,Q(P))
p24−1
r

46
L. Ghammam and E. Fouotsa
where l is the tangent to the curve at a point depending on Q and depending
on the loop iteration in Miller’s algorithm. To compute the product of Eq. (6),
each doubling function-evaluation step becomes
f ←f 2 n
i=1 li(Qi)
(7)
Therefore one needs only to calculate a single squaring in the extension ﬁeld per
doubling rather than n squarings using the naive method of the computation of
the product of n pairings.
So to evaluate the cost of the computation of the product of n optimal Ate
pairings we have to compute at ﬁrst:
– Cost1: Full squarings in the Miller loop (squarings in Eq. 7).
– Cost2: Other operations in the Miller loop (point operations and line evalu-
ation).
– Cost3: Final exponentiation.
Then we have to sum Cost1, nCost2 and Cost3 to ﬁnd the overall cost of the
product of n pairings.
Table 7. Costs comparison of product of n pairings at the 192-bit security levels.
Costs
KSS16 Zhang KSS16
BLS12 [10]
BN [9]
KSS18 [9]
Full squarings
for DBL
2592M
2592M
5892M
8837M
4158M
Others in
Miller loop
7616M
7616M
10760M
16720M
9544M
Final
exponentiation
23662M+I
22888M +I 12574M+6I 11145M+6I
23821M+8I
Total cost for
n = 1
33870M+I
33096M+I
29226M+6I 36702M+6I
37523M+8I
Total cost for
n = 2
41486M+I
40712M+I
39986M+6I 53422M+6I
47067M+8I
Total cost for
n = 3
49102M+I
48328M+I
50746M+6I 64567M+6I
56611M+8I
Total cost for
n = 7
79656M+I
78792M+I
93786M+6I 109147M+6I 94784M +8I
In Table 7, we present the costs for computing the product of n pairings
considering common curves in Table 6. From Table 7, we can deduce that for
n = 2, meaning when we would like to compute the product of two parings, it
is better to use BLS12 curves. In the case of n > 2 as mentioned in [1] KSS16
curves can give the fastest computations of products or quotients of n pairings.
Security of Cryptographic protocols is important in practice. That’s why,
when we compute optimal Ate pairing on KSS16 curves we have to verify the

Adequate Elliptic Curves for Computing the Product of n Pairings
47
security of the parameters of the elliptic curve. In the next section we will present
a detailed study of the security of the computation of the optimal Ate pairing
and more precisely the resistance against the subgroup attacks.
5
Subgroup Security for KSS16 Pairing-Friendly Curves
A detailed study on subgroup security for pairing-friendly curves was recently
studied by Baretto et al. [17]. They focus on common families of elliptic curves
having twists of order six such as BN, BL12, BLS24 and KSS18 curves. In par-
ticular they provided parameters that enable the aforementioned curves to be
resistant against subgroups attacks. In this section, we extend the same analysis
to the KSS family of elliptic curves having quartic twists and of embedding degree
16. We ﬁrst recall the deﬁnition of subgroup secure curves concept from [17] The
subgroup security concept explicitly described on pairing-friendly curves by Bar-
reto et al. [17], is a property that strengthens the resistance of pairing-friendly
curves against subgroup attacks. Let E be an elliptic curve of embedding degree
k and parameterised by p(u), t(u), r(u) ∈Q[u]. Let d be the degree of the twist
of the elliptic curve E and let E′(Fpk/d) its twists. Let h1(u) = | E(Fp)(u) |
r(u)
,
h2(u) = | E′(Fpk/d)(u) |
r(u)
and hT = | Gφk(p(u)) |
r(u)
be the indices of the three
groups on which a pairing is deﬁned.
Deﬁnition 3. [17] The curve E is subgroup secure if all Q[u]-irreducible factors
of h1(u), h2(u), hT (u) that represent primes and that have degree at least the
degree of r(u), contain no prime factor smaller than r(u0) ∈Z when evaluated
at u = u0.
In the case of KSS16, the indices are given in the following proposition:
Proposition 4. Let p(u), t(u), r(u) ∈Q[u] be the parameters of the KSS16
pairing-friendly elliptic curve. The indice hT = p(u)8 + 1
r(u)
is a polynomial in
u of degree 72. Also h1(u) = (125/2)(u2 + 2u + 5) and the order of the quar-
tic twist E′(Fp4) is | E′(Fp4) |= h2(u) · r(u) where h2(u) = (1/15059072)(u32 +
8u31 + 44u30 + 152u29 + 550u28 + 2136u27 + 8780u26 + 28936u25 + 83108u24 +
236072u23 + 754020u22 + 2287480u21 + 5986066u20 + 14139064u19 + 35932740u18 +
97017000u17 + 237924870u16 + 498534968u15 + 1023955620u14 + 2353482920u13 +
5383092978u12+10357467880u11+17391227652u10+31819075896u9+65442538660u8+
117077934360u7
+
162104974700u6
+
208762740168u5
+
338870825094u4
+
552745197960u3 + 632358687500u2 + 414961135000u + 126854087873).
Proof. The order of the group E(Fp4) is | E(Fp4) |= p4 + 1 −t4 where t4 =
t4 −4pt2 + 2p2 (see [28, Theorem 4.12]). The order of the correct quartic twist
E′(Fp4) is given by | E′(Fp4) |= p4 + 1 + v4 where v2
4 = 4p4 −t2
4 (see [29,
Proposition 2]). A direct calculation gives the cofactor as h2(u) = p4+1+v4
r(u)
.

48
L. Ghammam and E. Fouotsa
Remark 5. The value used in [1] for the computation of optimal pairing on
KSS16 curves is u0 = 249 +226 +215 −27 −1. With this value we see that h2(u0)
has the factorisation 2·1249·366593·c1515 where c1515 is still a composite integer
of 1515 bits. This means that the corresponding curve fails to satisfy the small
subgroup attack property. In the following section we search for a parameter u
to avoid subgroup attack on this curve.
For the 192-bit security level, the u0 which gives corresponding sizes of r and p
must be an integer of bit size at least 49. Also, the good u0 must be such that
p(u0), r(u0), h2(u0) and hT (u0) are simultaneously prime. Since u ≡±25 mod 70
(for p to represent integers) one can easily see that h2(u) ≡0 mod 2 and hT (u) ≡
0 mod 2. We will therefore search for u0 such that p(u0), r(u0), h2(u0)/2 and
hT (u0)/2 are simultaneously prime. One can have a chance to obtain such a
u0 if and only if those polynomials satisfy the Bunyakovsky’s property. A quick
veriﬁcation enables to see that the prime number 17 divides these polynomials
when evaluated at n ∈N. Therefore it is enough to search for prime numbers with
2 and/or 17 as factors. The Batemann-Horn conjecture then ensures that they
are approximately 24500 values of u0 ∈[249, 253] with p(u0), r′(u0), h′
2(u0) and
h′
T (u0) simultaneously prime, where r(u) = 17n1 · r′(u), h2(u) = 2 · 17n2 · h′
2(u)
and hT = 2 · 17n3 · h′
T (u) for some positive or zero integers n1, n2 and n3.
A careful search enabled us, after several long tries starting with x0 of Hamming
weight 5, to obtain the following value
u0 = 250 + 247 −238 + 232 + 225 −215 −25 −1
which gives a prime p of 492 bits, r(u0) = r′(u0) prime of 386 bits, h2(u0) =
2·17·h′
2(u0) and hT = 2·17·h′
T (u0) where h′
2(u0) and h′
T (u0) are prime numbers
of 3544 bits and 1577 bits respectively. For the value of p obtained the extension
ﬁeld Fp16 is built using the following tower of extensions:
– Fp2 = Fp[α]/(α2 −11)
– Fp4 = Fp2[β]/

β2 −α)

– Fp8 = Fp4[γ]/

γ2 −β

– Fp16 = Fp8[θ]/

θ2 −γ

An example of elliptic curve E over Fp that satisﬁes |E(Fp)| = p + 1 −t has the
equation E : y2 = x3 + 17x. The corresponding quartic twist E′ over Fp4 with
order |E′(Fp4)| = 2 · 17 · h′
2(u0) · r(u0) is the curve E′ : y2 = x3 + 17/βx.
6
Conclusion
In many pairing-based protocols the evaluation of the product or the quotient of
many pairings is required. In this paper we were interested in the computation
of the product of n optimal Ate pairings at the high security level.
This problem was ﬁrst considered by Zhang et al. [1]. They suggested the
KSS16 curves as a best choice for computing n pairings. We checked their results

Adequate Elliptic Curves for Computing the Product of n Pairings
49
on the computation of the hard part of the ﬁnal exponentiation of the optimal
Ate pairing. We found that they missed 1332 multiplications in Fp in their com-
plexity calculation. We corrected their algorithm and we presented a new algo-
rithm for the computation of the ﬁnal exponentiation based on a new multiple of
the hard part of the ﬁnal exponentiation. With this new vector we saved about
864 multiplications in the basic ﬁeld which is an important result if one thinks
about hardware or software implementations. We implemented our new algo-
rithms in Magma to verify their correctness [18]. We computed also the product
of n pairings. We proved that for n = 2 it is better to use BLS12 curves and for
n > 2 KSS16 curves are the best solution. Finally we proposed a new parame-
ter u for the KSS16 curves to ensure the resistance against the small subgroup
attacks.
A
Algorithms
In these tables and to have the same expressions as Zhang et al. we denote by
f the result of Miller loop and by M the result of the ﬁrst part of the ﬁnal
exponentiation.
Table 8. Final exponentiation with a new exponent. See [18] for the magma code for
the veriﬁcation.
Operations
Terms computed
Cost
E1 = f p8E2 = E1 · f −1
M = f p8−1
T0 = M 2; T1 = T02
M 2; M 4
2S16
T2 = M u+1; T3 = T2u+1
M u+1; M (u+1)2
2Eu
T4 = T3 · T1
M (u+1)2+4 = M B
1M16
T5 = T4u; T6 = T45
M uB; M 5B
1Eu + 1M16 + 2S16
T7 = T18; T8 = T72
M 32; M 64
4S16
T9 = T7 · T1−1; T10 = T92 M 28; M 56
1M16 + 1S16
T11 = T5u; T12 = T11u
M u2B; M u3B
2Eu
T01 = T12 · T10
M u3B+56 = M A
1M16
T14 = T01u; T13 = T14−2
M uA; M −2uA
1Eu + 1S16
T00 = T65; T15 = T005
M 25B; M 125B
2M16 + 4S16
T0 = T13 · T15−1
M −2uA−125B = M c2
1M16
T16 = T02; T17 = T134
M 2c2; M −8uA
3S16
T18 = T17 · T14
M −7uA
1M16
T2 = T16 · T18
M 2c2−7uA = M c6
1M16
T19 = T14u; T20 = T19u
M u2A; M u3A
2Eu
T21 = T20u; T22 = T192
M u4; M 2u2A
1Eu + 1S16
T23 = T55; T24 = T235
M 5uB; M 25uB
2M16 + 4S16

50
L. Ghammam and E. Fouotsa
Table 8. (continued)
Operations
Terms computed
Cost
T25 = T243; T26 = T24 · T25
M 75uB; M 100uB
1C16 + 1M16
T27 = T222
M 4u2A
1S16
T37 = (T27 · T25)−1
M −4u2A−75uB = M c1
1M16
T28 = T27 · T19−1
M 3u2A
1M16
T3 = T28 · T26
M 3u2A+100xB = M c5
1M16
T29 = T115; T30 = T292
M 5u2B; M 10u2B
1M16 + 3S16
T4 = T20 · T30
M u3A+10u2B = M c4
1M16
S0 = T202; S1 = T305
M 2u3A; M 50u2B
1M16 + 3S16
S2 = S1 · T29; S3 = S0 · S2
M 55u2B; M 2u3A−55u2B = M c0
2M16
T31 = T1224
M 24u3B
1C16 + 3S16
T5 = T21−1 · T31−1
M −u4A−24u3B
1M16
T6 = T83 · T1
M 196
1M16 + 1C16
T7 = T5 · T6
M −u4A−24u3B+196 = M c3
1M16
T8 = T17
M 7A = M c7
2M16 + 2S16
T32 = T37p · T7p3 · T3p5 · T8p7
M c1p+c3p3+c5p5+c7p7
3M16 + 4(15M)
T33 = T0p2 · T2p6
M c2p2+c6p6
1M16 + 2(12M)
T = S3 · T32 · T33 · T4p4
M
p8+1
r
3M16 + 1(8M)
Table 9. Corrected version of the ﬁnal exponentiation in [1]. See [18] for the magma
code for the veriﬁcation.
Operations
Terms computed Cost
E1 = f p8E2 = E1 · f −1
M = f p8−1
T1 = E24; T2 = T18; T3 = T22
6S16
A0 = T38; A1 = A0 · T3
1M16 + 3S16
A2 = A1 · T2; A3 = T12
1M16 + 1S16
A2 = A3 · A2
1M16
F1 = T2 · T1−1; F2 = F12
1M16 + 1S16
F3 = E2u+1; F4 = F3u+1
2Eu+1
F5 = F4 · T1; T4 = F58
F5 = M B
1M16 + 3S16
F6 = F5u; F7 = F5−1 · T4
F7 = M c
′
7
1Eu + 1M16
F8 = T43; T5 = F68
1C16 + 3S16
F9 = F6u; F10 = T5 · F6−1
1Eu + 1M16
F11 = F102; T6 = F98
4S16
F12 = F9u; F13 = T6 · F9−1
1Eu + 1M16
F14 = F132; F15 = F12 · F2
F15 = M A
1S16 + 1M16

Adequate Elliptic Curves for Computing the Product of n Pairings
51
Table 9. (continued)
Operations
Terms computed Cost
T7 = F152; T8 = T74
3S16
S1 = T82; S2 = T72
2S16
S3 = S2 · S1; S4 = S3 · F15−1
2M16
T9 = S14; S5 = S3 · T9
1M16 + 2S16
S6 = F142; F16 = F15u
1Eu + 1S16
F22 = F16 · F8
F22 = M c′
3
1M16
F23 = F22u; F24 = F23 · F11
F24 = M c′
2
1Eu + 1M16
T10 = F232; F25 = F23u
1Eu + 1S16
F26 = T10 · F10−1; T11 = F254
F26 = M c′
6
1M16 + 2S16
F27 = F25u; F28 = T11 · F25−1
1Eu + 1M16
F29 = F13 · F14; F30 = T11 · F29
F30 = M c′
5
2M16
F31 = F28 · S6−1; F32 = F122
1M16 + 1S16
F33 = F32 · F12; F34 = F27 · F33
2M16
F35 = F342; F36 = F35 · F12
1M16 + 1S16
F37 = F36−1 · S5; F38 = F34 · F1
F37 = M c′
4
2M16
F39 = F382; F40 = F392
2S16
F41 = F402; F42 = F39 · F38
1M16 + 1S16
F43 = F41 · F42; F44 = F43−1 · S4
2M16
H1 = F7p7; H2 = F22p3
2(14M)
H3 = F24p2; H4 = F26p6
2(12M)
H5 = F30p5; H6 = F31p
2(14M)
H7 = F37p4; H8 = H1 · H2−1
1M16 + 1(8M)
H9 = H82; H10 = H92
2S16
H11 = H10 · H8; H12 = H11 · H3
2M16
H13 = H12 · H4; H14 = H132
1M16 + 1S16
H15 = H142; H16 = H15 · H13
1M16 + 1S16
H17 = H16 · H6; H18 = H17 · H5−1
2M16
H19 = H182; H20 = H192
2S16
H21 = H20 · H18; H22 = H21 · H7
2M16
H23 = H22 · F44
H23 = M d′
1M16
References
1. Zhang, X., Lin, D.: Analysis of optimum pairing products at high security levels. In:
Galbraith, S., Nandi, M. (eds.) INDOCRYPT 2012. LNCS, vol. 7668, pp. 412–430.
Springer, Heidelberg (2012). doi:10.1007/978-3-642-34931-7 24
2. Boneh, D., Franklin, M.: Identity-based encryption from the Weil pairing. In:
Kilian, J. (ed.) CRYPTO 2001. LNCS, vol. 2139, pp. 213–229. Springer, Heidelberg
(2001). doi:10.1007/3-540-44647-8 13

52
L. Ghammam and E. Fouotsa
3. Cocks, C.: An identity based encryption scheme based on quadratic residues. In:
Honary, B. (ed.) Cryptography and Coding 2001. LNCS, vol. 2260, pp. 360–363.
Springer, Heidelberg (2001). doi:10.1007/3-540-45325-3 32
4. Libert, B., Quisquater, J.-J.: Identity based undeniable signatures. In: Okamoto, T.
(ed.) CT-RSA 2004. LNCS, vol. 2964, pp. 112–125. Springer, Heidelberg (2004).
doi:10.1007/978-3-540-24660-2 9
5. Boneh, D., Lynn, B., Shacham, H.: Short signatures from the Weil pairing. J.
Cryptol. 17(4), 297–319 (2004)
6. Goyal, V., Pandey, O., Sahai, A., Waters, B.: Attribute-based encryption for
ﬁne-grained access control of encrypted data. In: Linawati, Mahendra, M.S.,
Neuhold, E.J., Tjoa, A.M., You, I. (eds.) ICT-EurAsia 2014. LNCS, vol. 8407,
pp. 89–98. Springer, Heidelberg (2006). doi:10.1007/978-3-642-55032-4 60
7. Barreto, P.S.L.M., Naehrig, M.: Pairing-friendly elliptic curves of prime order. In:
Preneel, B., Tavares, S. (eds.) SAC 2005. LNCS, vol. 3897, pp. 319–331. Springer,
Heidelberg (2006). doi:10.1007/11693383 22
8. Barreto, P.S.L.M., Lynn, B., Scott, M.: Constructing elliptic curves with prescribed
embedding degrees. In: Cimato, S., Persiano, G., Galdi, C. (eds.) SCN 2002. LNCS,
vol. 2576, pp. 257–267. Springer, Heidelberg (2003). doi:10.1007/3-540-36413-7 19
9. Aranha, D.F., Fuentes-Casta˜neda, L., Knapp, E., Menezes, A., Rodr´ıguez-
Henr´ıquez, F.: Implementing pairings at the 192-bit security level. In: Abdalla, M.,
Lange, T. (eds.) Pairing 2012. LNCS, vol. 7708, pp. 177–195. Springer, Heidelberg
(2013). doi:10.1007/978-3-642-36334-4 11
10. Ghammam, L., Fouotsa, E.: On the computation of the optimal ate pairing at the
192-bit security level. IACR Cryptology ePrint Archive, 2016:130 (2016)
11. Chen, L., Cheng, Z., Smart, N.P.: A built-in decisional function and security
proof of id-based key agreement protocols from pairings. IACR Cryptology ePrint
Archive, 2006:160 (2006)
12. Boneh, D., Boyen, X., Shacham, H.: Short group signatures. In: Franklin, M. (ed.)
CRYPTO 2004. LNCS, vol. 3152, pp. 41–55. Springer, Heidelberg (2004). doi:10.
1007/978-3-540-28628-8 3
13. Abdalla, M., Catalano, D., Dent, A.W., Malone-Lee, J., Neven, G., Smart, N.P.:
Identity-based encryption gone wild. In: Bugliesi, M., Preneel, B., Sassone, V.,
Wegener, I. (eds.) ICALP 2006. LNCS, vol. 4052, pp. 300–311. Springer, Heidelberg
(2006). doi:10.1007/11787006 26
14. Waters, B.: Eﬃcient identity-based encryption without random oracles. In:
Cramer, R. (ed.) EUROCRYPT 2005. LNCS, vol. 3494, pp. 114–127. Springer,
Heidelberg (2005). doi:10.1007/11426639 7
15. Granger, R., Smart, N.P.: On computing products of pairings. IACR Cryptology
ePrint Archive, 2006:172 (2006)
16. Kachisa, E.J., Schaefer, E.F., Scott, M.: Constructing Brezing-Weng pairing
friendly elliptic curves using elements in the cyclotomic ﬁeld. IACR Cryptology
ePrint Archive 2007:452 (2007)
17. Barreto, P.S.L.M., Costello, C., Misoczki, R., Naehrig, M., Pereira, G.C.C.F.,
Zanon, G.: Subgroup security in pairing-based cryptography. In: Lauter, K.,
Rodr´ıguez-Henr´ıquez, F. (eds.) LATINCRYPT 2015. LNCS, vol. 9230, pp. 245–
265. Springer, Cham (2015). doi:10.1007/978-3-319-22174-8 14
18. Fouotsa, E., Ghammam, L.: http://www.camercrypt.org/KSS16-ﬁnalexponen
tiation
19. Kim, T.: Extended tower number ﬁeld sieve: a new complexity for medium prime
case. IACR Cryptology ePrint Archive, 2015:1027 (2015)

Adequate Elliptic Curves for Computing the Product of n Pairings
53
20. Jeong, J., Kim, T.: Extended tower number ﬁeld sieve with application to ﬁnite
ﬁelds of arbitrary composite extension degree. IACR Cryptology ePrint Archive,
2016:526 (2016)
21. Miller, V.S.: The Weil pairing, and its eﬃcient calculation. J. Cryptol. 17(4), 235–
261 (2004)
22. Scott, M., Benger, N., Charlemagne, M., Dominguez Perez, L.J., Kachisa, E.J.:
On the ﬁnal exponentiation for calculating pairings on ordinary elliptic curves. In:
Shacham, H., Waters, B. (eds.) Pairing 2009. LNCS, vol. 5671, pp. 78–88. Springer,
Heidelberg (2009). doi:10.1007/978-3-642-03298-1 6
23. Fuentes-Casta˜neda, L., Knapp, E., Rodr´ıguez-Henr´ıquez, F.: Faster hashing to G2.
In: Miri, A., Vaudenay, S. (eds.) SAC 2011. LNCS, vol. 7118, pp. 412–430. Springer,
Heidelberg (2012). doi:10.1007/978-3-642-28496-0 25
24. Smeets, I., Lenstra, A.K., Lenstra, H., Lov´asz, L., van Emde Boas, P.: The history
of the LLL-algorithm. In: Nguyen, P.Q., Vall´ee, B. (eds.) The LLL Algorithm -
Survey and Applications, pp. 1–17. Springer, Heidelberg (2010)
25. Boneh, D., Boyen, X., Goh, E.-J.: Hierarchical identity based encryption with
constant size ciphertext. In: Cramer, R. (ed.) EUROCRYPT 2005. LNCS, vol.
3494, pp. 440–456. Springer, Heidelberg (2005). doi:10.1007/11426639 26
26. Groth, J., Sahai, A.: Eﬃcient non-interactive proof systems for bilinear groups.
In: Smart, N. (ed.) EUROCRYPT 2008. LNCS, vol. 4965, pp. 415–432. Springer,
Heidelberg (2008). doi:10.1007/978-3-540-78967-3 24
27. Scott,
M.:
Computing
the
tate
pairing.
In:
Menezes,
A.
(ed.)
CT-RSA
2005. LNCS, vol. 3376, pp. 293–304. Springer, Heidelberg (2005). doi:10.1007/
978-3-540-30574-3 20
28. Washington, L.C.: Elliptic Curves Number Theory and Cryptography. Discrete
Mathematics and Its Applications. Chapman and Hall, London (2008)
29. Hesse, F., Smart, N.P., Vercauteren, F.: The eta pairing revisited. IEEE Trans.
Inf. Theory 52(10), 4595–4602 (2006)

On Pseudorandom Properties of Certain
Sequences of Points on Elliptic Curve
L´aszl´o M´erai(B)
Johann Radon Institute for Computational and Applied Mathematics,
Austrian Academy of Sciences, Altenbergerstr. 69, 4040 Linz, Austria
laszlo.merai@oeaw.ac.at
Abstract. In this paper we study the pseudorandom properties of
sequences of points on elliptic curves. These sequences are constructed
by taking linear combinations with small coeﬃcients (e.g. −1, 0, +1) of
the orbit elements of a point with respect to a given endomorphism of
the curve. We investigate the linear complexity and the distribution of
these sequences. The result on the linear complexity answers a question
of Igor Shparlinski.
1
Introduction
For a prime power q = pn we denote by Fq the ﬁeld of q elements. Let E be a
non-singular elliptic curve over Fq deﬁned by
E : Y 2 + (a1X + a3)Y = X3 + a2X2 + a4X + a6,
with some a1, . . . , a6 ∈Fq (see [12]). We recall that the Fq-rational points E(Fq)
of the curve E with the usual addition ⊕form an Abelian group with the point
at inﬁnity O as a neutral element. We write every point P ̸= O on E as P =
(x(P), y(P)).
Every integer m ̸= 0 has a unique non-adjacent binary expansion, also called
binary NAF, for some length k:
m =
k−1

j=0
μj2j,
with (μ0, . . . , μk−1) ∈Mk,
(1)
where Mk is the set of k-tuples with components 0, ±1 such that there are no
two consecutive non-zero components:
Mk = {(μ0, . . . , μk−1) ∈{0, ±1}k | μjμj+1 = 0}.
This expansion provides a faster scalar multiplication compared to the double
and add algorithm as the number of additions is reduced and the number of
doublings is kept constant, as additions and subtractions of points cost about
the same. We remark that the Hamming weight of this representation of m is
c
⃝Springer International Publishing AG 2016
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 54–63, 2016.
DOI: 10.1007/978-3-319-55227-9 4

On Pseudorandom Properties of Certain Sequences of Points
55
minimal among all signed-digit representations of m. It is not hard to show (see
[2]) that for k ≥2
#Mk = 4
32k + O(1).
We also remark that given an integer m (in binary form) one can eﬃciently
computes its NAF representation.
This concept is generalized from the endomorphism doubling δ to arbitrary
endomorphisms by Lange and Shparlinski [8]. Given an Fq-rational point P ∈
E(Fq) and an endomorphism σ on E we consider the set of points
Pσ,m =
k−1

j=0
μjσj(P),
m = (μ0, . . . , μk−1) ∈Mk.
The endomorphism doubling δ(P) = 2P is deﬁned for any elliptic curve over
any ﬁnite ﬁeld. In this case we have
Pδ,m = mP,
where m is the NAF representation (1) of m.
Two further examples of endomorphisms were also considered in [8]. For
a ∈F2 we deﬁne the Koblitz curve Ea over F2 by the Weierstrass equation
Ea : Y 2 + XY = X3 + aX2 + 1
introduced in [5]. We deﬁne the Frobenius endomorphism ϕ which acts on an
F2n-rational point P = (x, y) as
ϕ(P) = (x2, y2).
Finally, we also consider one of the GLV curves introduced by Gallant, Lam-
bert and Vanstone [4]. Let p > 3 be a prime number such that −7 is a quadratic
residue modulo p (that is, p ≡1, 2, 4 (mod 7)). Deﬁne the elliptic curve EGLV
over Fp as
EGLV : Y 2 = X3 −3
4X2 −2X −1.
If b = (1 + √−7)/2 and c = (b −3)/4, then the map ψ deﬁned as
ψ(P) =
 x2 −b
b2(x −c), y(x2 −2cx + b)
b3(x −c)2

for P = (x, y) ∈EGLV is an endomorphism of EGLV.
The behavior of the point set Pσ,m (m ∈Mk) was studied by Lange and
Shaprlinski [7,8]. First they gave an upper bound on the number of collisions of
these points.
Proposition 1. Let P ∈E(Fq) be of prime order ℓand let Nk(Q) be the number
of representations
Pσ,m = Q,
m ∈Mk.
If σ is one of the following endomorphisms:

56
L. M´erai
– δ for an arbitrary curve E,
– ϕ for a Koblitz curve E = Ea, a = 0, 1,
– ψ for the GLV curve E = EGLV,
then for any integer r with 1 ≤r ≤k and 2r ≤ℓ/8 we have Nk(Q) ≤#Mk−r.
In particular, the bound of Proposition 1 implies that if 2k < ℓ/8, then the
points Pσ,m are all distinct. For larger k choosing r = ⌊log2 ℓ⌋−3 we obtain
Nk(Q) = O(2kℓ−1).
Next, Lange and Shaprlinski [8] also studied the distribution of the points
Pσ,m (m ∈Mk). For a non-trivial additive character χ, they proved that

m∈Mk
χ(x(Pσ,m)) ≪#Mk

q1/4νℓ−1/2ν + 2−k/2νq(ν+1)/4ν2
(2)
holds with any ﬁxed integer ν ≥log q/2k where σ is one of the endomorphisms
in Proposition 1. From the bound (2) they proved that the set of points Pσ,m
(m ∈Mk) has good uniformity of distribution properties.
In this paper we study the sequence of points Pσ,m arranged in a sequence by
ordering the vectors m ∈Mk lexicographically. First, we give a lower bound to
the linear complexity of the coordinate-sequence x (Pσ,m) in Sect. 2. This result
gives an answer to a question of Igor Shparlinki (Question 31 in [11]).
Next, in Sect. 3 we extend the result (2). For a vector m ∈Mk, let τ(m) ∈
Mk be the successor of m with respect to the lexicographic ordering. Then we
study the distribution of vectors

x (Pσ,m) , x

Pσ,τ(m)

, . . . , x

Pσ,τ s−1(m)

,
m ∈Mk : τ s−1(m) ∈Mk. (3)
First we give an upper bound to the character sum
Sσ,k,s(χ) =
max
(a0,...,as−1)̸=(0,...,0)

n∈M∗
k
χ
	s−1

i=0
aix

Pσ,τ i(n)


,
where in the sum we exclude the last s −2-many elements of Mk and χ is a
non-trivial additive character. We apply this result to show that the vectors (3)
have good uniformity of distribution properties.
2
Linear Complexity
The linear complexity of a sequence (sn) of length M over a ring R is the length
L of a shortest linear recurrence relation
sn+L = cL−1sn+L−1 + · · · + c1sn+1 + c0sn,
n = 0, . . . , M −L −1
for some c0, . . . , cL−1 ∈R, that (sn) satisﬁes.
The linear complexity measures the unpredictability of a sequence and thus
its suitability in cryptography. For more details see [9,10,13].

On Pseudorandom Properties of Certain Sequences of Points
57
Theorem 1. Let P ∈E(Fq) be of prime order ℓ. Then for any k ≥1 the linear
complexity of (x (Pσ,m))m∈Mk satisﬁes
L(x (Pσ,m)) ≫min

#M⌈k/2⌉, ℓ

.
The following lemma is a crucial step in the proof.
Lemma 1. If P has prime order ℓand ℓdoes not divide the constant term of
the characteristic polynomial of σ, then σ(P) ̸= O. It happens if ℓ> 2 and σ is
one of the selected endomorphism.
Proof. Let χσ = aT 2 + bT + c ∈Fq[T] be the characteristic polynomial of σ. If
σ(P) = O, then O = −aσ2(P) −bσ(P) = cP, thus the order ℓof P divides c.
Finally, we remark, that if σ is one of the endomorphism in Proposition 1, then
the constant term of χσ is 2 (see [8]).
⊓⊔
Proof (Theorem 1). For k = 1, 2 the result is trivial, so we may assume that
k ≥3. Put r = ⌊k/2⌋and consider the set of vectors
n = (ν0, . . . , νk−r−2, 0, νk−r, . . . , νk−1) ∈Mk.
Clearly, n can be written as n = (u, 0, v) with u ∈Mk−r−1, v ∈Mr.
Let L be the linear complexity of the sequence x (Pσ,m) and N be the
number of distinct points Pσ,v, v ∈Mr. By Proposition 1, we have N ≥
#Mr/ maxQ Nr(Q) ≥#Mr/ max{1, #Mr−⌊log2 ℓ⌋+3} ≫min{#Mr, ℓ}. If N ≤
L, then the theorem holds, otherwise there are vectors d0, . . . , dL ∈Mr, such
that the points Pσ,d0, . . . , Pσ,dL are all distinct. Fix these vectors and for each
j = 0, . . . , L deﬁne the sequence
xj(s) = x

Pσ,(s,0,dj)

,
s ∈Mk−r−1,
where again the elements xj(s) arranged in a sequence by ordering the vectors
s lexicographically. The sequences xj(s) are subsequences of x (Pσ,m), thus they
satisfy the same linear recurrence relation of order L. Then these sequences are
in a vector space of dimension at most L so they are linearly dependent, i.e.
there are constants c0, . . . , cL ∈Fq, not all of them are zero, such that
c0x

Pσ,(s,0,d0)

+ · · · + cLx

Pσ,(s,0,dL)

= 0,
s ∈Mk−r−1,
i.e.,
c0x

Pσ,s + σk−r (Pσ,d0)

+ · · · + cLx

Pσ,s + σk−r (Pσ,dL)

= 0,
s ∈Mk−r−1.
By Lemma 1 the points σk−r (Pσ,d0) , . . . , σk−r (Pσ,dL) are pairwise distinct so
the function
F(Q) = c0x

Q + σk−r (Pσ,d0)

+ · · · + cLx

Q + σk−r (Pσ,dL)

has L + 1 poles and the points Pσ,s, s ∈Mk−r−1 are all zeros of it.

58
L. M´erai
Since there are at least
#Mk−r−1/ max
Q Nk−r−1(Q) ≥#Mk−r−1/ max{1, #Mk−r−1−⌊log2 ℓ⌋+3}
≫min{#Mr, ℓ}
distinct points among them, we get the result comparing the number of poles
and zeros of F.
⊓⊔
3
Distribution
In this section we ﬁrst prove a bound on a character sum. This bound immedi-
ately implies results about pseudorandomness of the points Pσ,m.
Theorem 2. Let P ∈E(Fq) be of prime order ℓand χ be a non-trivial additive
character of Fq. Then for any k ≥1 and s ≥2 we have that
Sσ,k,s(χ) ≪#Mk s

q1/4νℓ−1/2ν + 2−k/2νq(ν+1)/4ν2
holds with any ﬁxed integer
ν >
log q
min{2k, 2(log ℓ−3)}
if σ is one of the endomorphisms in Proposition 1.
The proof of the theorem is based on the following character sum estimate
[1]. Let Fq(E) be the function ﬁeld of the curve E. If f ∈Fq(E) and χ is an
additive character, write χ(f(Q)) = 0 whenever Q is a pole of f.
Lemma 2. Let E be an elliptic curve deﬁned over Fq. Let f ∈Fq(E) and sup-
pose that f ̸= zp −z for all z ∈Fq(E). Let χ be a non-trivial additive character
of Fq. Then the bound


Q∈E(Fq)
χ (f(Q))

≤2 deg fq1/2
holds.
Proof (Theorem 2). Let us ﬁx some positive integer r < min{k, log ℓ−3}.
For j = 0, 1 we deﬁne Uj to be the subset of vectors u = (u0, . . . , ur−1) ∈Mr
with ur−1 = ±j. To form a vector in Mk, a vector from U0 can be appended by
any vector from V0 = Mk−r, while a vector from U1 requires the following digit
to be zero. Hence, we put
V1 = {(0, w) : w ∈Mk−r−1}.

On Pseudorandom Properties of Certain Sequences of Points
59
We have

m∈M∗
k
χ
	s−1

i=0
aix

Pσ,τ i(m)


= Rσ,0 + Rσ,1,
where
Rσ,j =

u∈Uj

v∈Vj
(u,v)∈M∗
k
χ
	s−1

i=0
aix

Pσ,τ i((u,v))


=

u∈U∗
j

v∈Vj
χ
	s−1

i=0
aix

Pσ,τ i(u) + σr (Pσ,v)


+ O (s · #Vj) ,
where the asterisks indicates that we exclude the last s −1 elements on Uj.
For j = 0 we have by the H¨older inequality that
⎛
⎝
v∈V0


u∈U∗
0
χ
	s−1

i=0
aix

Pσ,τ i(u) + σr (Pσ,v)



⎞
⎠
2ν
≤#V2ν−1
0

v∈V0


u∈U∗
0
χ
	s−1

i=0
aix

Pσ,τ i(u) + σr (Pσ,v)



2ν
.
(4)
Now #V0 = #Mk−r = O(2k−r). Then by Proposition 1 and Lemma 1 we have
that every point Q is represented by σr(Pσ,v) (v ∈V0) in at most O(2k−rℓ−1+1)
times. So (4) is
≪2(k−r)(2ν−1)(2k−rℓ−1 + 1)

Q∈E(Fp)


u∈U∗
0
χ
	s−1

i=0
aix

Pσ,τ i(u) + Q



2ν
.
As for every complex number z we have |z|2 = zz and for any u ∈Fq we
have χ(u) = χ(−u), we get

Q∈E(Fp)


u∈U∗
0
χ
	s−1

i=0
aix

Pσ,τ i(u) + Q



2ν
=

u1,...,u2ν∈U∗
0

Q∈E(Fp)
χ
	 ν

h=1
s−1

i=0
ai

x

Pσ,τ i(uh) + Q

−x

Pσ,τ i(uh+ν) + Q


.
(5)
If all the values of u1, . . . , u2ν occur more than once in (u1, . . . , u2ν), we
estimate the sum trivially by #E(Fq) ≪q. It happens at most (ν ·#U∗
0 )ν times.
If there is at least one unique value in (u1, . . . , u2ν), we show that the function

60
L. M´erai
F(Q) =
ν

h=1
s−1

i=0
ai

x

Pσ,τ i(uh) + Q

−x

Pσ,τ i(uh+ν) + Q

cannot have the form zp −z with z ∈Fq(E).
Let u be the least value in (u1, . . . , u2ν) with respect to the lexicographic
ordering, such that

1≤h≤ν
uh=u
x (Pσ,uh + Q) ̸=

ν+1≤h≤2ν
uh=u
x (Pσ,uh + Q) .
(6)
Since there is at least one unique value in (u1, . . . , u2ν), there exists such a u.
Since 2r < ℓ/8, we get from Proposition 1, that Pσ,u′ ̸= Pσ,u′′ for any u′ ̸= u′′,
u′, u′′ ∈U∗
0 ⊂Mr. Let <l denote the lexicographic ordering in Mr. As τ i(u) <l
τ j(u′) if i < j or u′ ̸= u is a vector satisfying (6), we have Pσ,τ i(u) ̸= Pσ,τ j(u′)
with the same conditions on i, j and u, u′. Thus if i is the least index such that
ai ̸= 0, then the term x

Pσ,τ i(u) + Q

does not vanish in F by the choice of u,
and −Pσ,τ i(u) is not a pole of any other term of F, thus F cannot have the form
zp −z. Then from Lemma 2 we get that (5) is

u1,...,u2ν∈U∗
0

Q∈E(Fq)
χ (F(Q)) ≪#U2ν
0 sq1/2 + #Uν
0 q.
Since #U0 ≤#Mr = O(2r), we have that
R2ν
σ,0 ≪2(k−r)(2ν−1)(2k−rℓ−1 + 1)(22rνsq1/2 + 2rνq) + s2ν2(k−r)2ν.
Using the same argument one can also obtain
R2ν
σ,1 ≪2(k−r−1)(2ν−1)(2k−r−1ℓ−1 + 1)(22rνsq1/2 + 2rνq) + s2ν2(k−r−1)2ν.
Thus
|Sσ,k,s(χ)|2ν ≪2(k−r)(2ν−1)(2k−rℓ−1 + 1)(22rνsq1/2 + 2rνq) + s2ν2(k−r)2ν.
Choosing
r =
log q
2ν

< k
we get that the terms 22rνq1/2 and 2rνq are O(q3/2). Hence
|Sσ,k,s(χ)|2ν ≪s2(k−r)2νℓ−1q3/2 + 2(k−r)(2ν−1)q3/2 + s2ν2(k−r)2ν
≪s22νk+log q/2ℓ−1 + 22νk−k+(ν+1) log q/2ν + s2ν22νk−log q
which proves the result.
⊓⊔
The most interesting case is when the E(Fq) has a cyclic group structure
with prime order ℓ. Then by the Hasse-Weil theorem, we have that ℓ= q1+o(1).
If k = (1 + o(1)) log q, then choosing ν = 2, Theorem 2 implies
Sσ,k,s(χ) ≪#Mk sq−1/16.

On Pseudorandom Properties of Certain Sequences of Points
61
As an application of Theorem 2, we get results about pseudorandomness of
the vectors (3).
Let β1, . . . , βn be a ﬁxed basis of Fpn over Fp. For a ﬁxed subset J ⊂
{1, . . . , n}, and ﬁxed elements ci,j ∈Fq, i ∈{0, 1, . . . , s −1}, j ∈I, put
N

J, (ci,j)

= #

m ∈Mk : x

Pσ,τ i(m)

j = ci,j, i ∈{0, 1 . . . , s −1}, j ∈J

.
Using the standard techniques (see e.g. [8]) to express the deviation of
N

J, (ci,j)

from its expected value Mk/p#J·s by character sums we get from
Theorem 2.
Corollary 1. Let p be a prime number and let P ∈E(Fpn) be of prime order ℓ.
Then for any integers k, s ≥1 the bound
max
J,(ci,j)
N

J, (ci,j)

−#Mk
p#J·s
 ≪#Mk s

q1/4νℓ−1/2ν + 2−k/2νq(ν+1)/4ν2
holds with any ﬁxed integer
ν >
log q
min{2k, 2(log ℓ−3)},
where σ is one of the following endomorphisms:
– δ for an arbitrary curve E,
– ϕ for a Koblitz curve E = Ea, a = 0, 1.
If again ℓ= q1+o(1) and k = ⌊log q⌋, then choosing ν = 2, Corollary 1 implies
that for any α < 1/16 the components of (3) on any #J ≤αn positions are
uniformity distributed.
If the point P is Fp-rational, then the sequence x(Pσ,m) is a sequence in a
prime ﬁeld Fp. In this case we can study the discrepancy of this sequence. More
precisely, let Dψ,k,s be the discrepancy of the vectors
	
x (Pψ,m)
p
, x

Pψ,τ(m)

p
, . . . , x

Pψ,τ s−1(m)

p

,
m ∈Mk,
(7)
in the s-dimensional unite cube. That is
Dψ,k,s =
sup
I⊂[0,1)s

T(I)
#Mk
−|I|
 ,
where T(I) is the number of points (7) which hit the s-dimensional interval
I = [α1, β1) × · · · × [αs, βs) of size |I| = (β1α1) · · · (βs −αs).
Using the Erd˝os-Tur´an inequality, see [3,6], relating the discrepancy and
exponential sums we immediately derive:

62
L. M´erai
Corollary 2. Let p be a prime number and let P ∈E(Fp) be of prime order ℓ.
Then for any integers k, s ≥1 the bound
Dψ,k,s ≪#Mk s

q1/4νℓ−1/2ν + 2−k/2νq(ν+1)/4ν2
holds with any ﬁxed integer
ν >
log q
min{2k, 2(log ℓ−3)}.
where σ is one of the following endomorphisms:
– δ for an arbitrary curve E,
– ψ for the GLV curve E = EGLV.
Acknowledgements. The author is partially supported by the Austrian Science Fund
FWF Project F5511-N26 which is part of the Special Research Program “Quasi-Monte
Carlo Methods: Theory and Applications” and by Hungarian National Foundation for
Scientiﬁc Research, Grant No. K100291.
References
1. Beelen, P.H.T., Doumen, J.M.: Pseudorandom sequences from elliptic curves. In:
Mullen, G.L., Stichtenoth, H., Tapia-Recillas, H. (eds.) Finite Fields with Appli-
cations to Coding Theory, Cryptography and Related Areas (Oaxaca, 2001), pp.
37–52. Springer, Berlin (2002). doi:10.1007/978-3-642-59435-9 3
2. Bosma, W.: Signed bits and fast exponentiation. J. Th´eor. Nombres Bordx. 13(1),
27–41 (2001). 21st Journ´ees Arithm´etiques (Rome, 2001)
3. Drmota, M., Tichy, R.: Sequences, Discrepancies and Applications. Springer, Berlin
(1997)
4. Gallant, R.P., Lambert, R.J., Vanstone, S.A.: Faster point multiplication on elliptic
curves with eﬃcient endomorphisms. In: Kilian, J. (ed.) CRYPTO 2001. LNCS,
vol. 2139, pp. 190–200. Springer, Heidelberg (2001). doi:10.1007/3-540-44647-8 11
5. Koblitz, N.: CM-curves with good cryptographic properties. In: Feigenbaum, J.
(ed.) CRYPTO 1991. LNCS, vol. 576, pp. 279–287. Springer, Heidelberg (1992).
doi:10.1007/3-540-46766-1 22
6. Kuipers, L., Niederreiter, H.: Uniform Distribution of Sequences. John Wiley,
New York (1974)
7. Lange, T., Shparlinski, I.E.: Collisions in fast generation of ideal classes and points
on hyperelliptic and elliptic curves. Appl. Algebra Eng. Commun. Comput. 15,
329–337 (2005)
8. Lange, T., Shparlinski, I.E.: Distribution of some sequences of points on elliptic
curves. J. Math. Cryptol. 1(1), 1–11 (2007)
9. Meidl, W., Winterhof, A.: Linear complexity of sequences and multisequences. In:
Mullen, G., Panario, D. (eds.) Handbook of Finite Fields, pp. 324–336. Chapman
& Hall, London (2013)
10. Niederreiter, H.: Linear complexity and related complexity measures for sequences.
In: Johansson, T., Maitra, S. (eds.) INDOCRYPT 2003. LNCS, vol. 2904, pp. 1–17.
Springer, Heidelberg (2003). doi:10.1007/978-3-540-24582-7 1

On Pseudorandom Properties of Certain Sequences of Points
63
11. Shparlinski, I.E.: Pseudorandom number generators from elliptic curves. Recent
Trends Cryptogr. Contemp. Math. 477, 121–141 (2009). American Mathematical
Society, Providence, RI
12. Silverman, J.H.: The Arithmetic of Elliptic Curves. Springer, Berlin (1995)
13. Winterhof, A.: Linear complexity and related complexity measures. In: Selected
Topics in Information and Coding Theory, pp. 3–40. World Scientiﬁc, Singapore
(2010)

Applications

Linear Complexity and Expansion Complexity
of Some Number Theoretic Sequences
Richard Hofer(B) and Arne Winterhof
Johann Radon Institute for Computational and Applied Mathematics,
Austrian Academy of Sciences, Altenberger Str. 69, 4040 Linz, Austria
{richard.hofer,arne.winterhof}@oeaw.ac.at
Abstract. We study the predictability of some number theoretic
sequences over ﬁnite ﬁelds and thus their suitability in cryptography.
First we analyze the non-periodic binary sequence T = (tn)n≥0 with
tn = 1 whenever n is the sum of three integer squares. We show that it
has a large Nth linear complexity, which is necessary but not suﬃcient
for unpredictability. However, it also has a very small expansion com-
plexity and thus is rather predictable.
Next we prove that some linear combinations of p-periodic sequences
of binomial coeﬃcients modulo a prime p have a very small expansion
complexity and are predictable despite of a high linear complexity.
Finally, we consider the Legendre sequence and verify that it does not
belong to this class of predictable sequences.
Keywords: Expansion complexity · Linear complexity · Generating
function · Three-square theorem · Automatic sequence · Linear recur-
rence sequence · Binomial coeﬃcients · Legendre sequence
1
Introduction
The expansion complexity for sequences over ﬁnite ﬁelds Fq was introduced by
Diem in [7]. For a sequence S = (sn)n≥0 over Fq the generating function G(x)
of S is
G(x) =
∞

n=0
snxn.
For a positive integer N, the Nth expansion complexity EN(S) of S is deﬁned
by EN(S) = 0 if sn = 0 for 0 ≤n ≤N −1 and otherwise as the least total
degree of a nonzero polynomial h(x, y) ∈Fq[x, y] with
h(x, G(x)) ≡0 mod xN.
By a famous result of Christol [5,6] the expansion complexity
E(S) = sup
N≥1
EN(S)
c
⃝Springer International Publishing AG 2016
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 67–74, 2016.
DOI: 10.1007/978-3-319-55227-9 5

68
R. Hofer and A. Winterhof
is ﬁnite, that is G(x) is algebraic, if and only if S can be generated by a ﬁnite
automaton and S is called automatic. For more details on automatic sequences
we refer to the monograph of Allouche and Shallit [1].
The Nth linear complexity LN(S) of S over Fq is deﬁned by LN(S) = 0 if
sn = 0 for 0 ≤n ≤N −1, LN(S) = N if sn = 0 ̸= sN−1 for 0 ≤n ≤N −2 and
otherwise as the length of a shortest linear recurrence
sn+LN(S) +
LN (S)−1

ℓ=0
cℓsn+ℓ= 0,
0 ≤n ≤N −LN(S) −1,
for some cℓ∈Fq, which is satisﬁed by the ﬁrst N terms of the sequence.
The linear complexity L(S) is
L(S) = sup
N≥1
LN(S).
It is well-known, see for example [9, Chap. 8], that L(S) is ﬁnite if and only
if S is ultimately periodic, that is, S is a linear recurring sequence. See also the
surveys about linear complexity and related measures [10,13–15].
Expansion complexity and linear complexity are both measures for the unpre-
dictability of a sequence.
First we study the non-periodic automatic sequence T = (tn)n≥0 over F2
deﬁned by
tn =

1 if n = u2 + v2 + w2 for some integers u, v, w,
0 otherwise.
By the Three-Square Theorem this is equivalent to
tn =
⎧
⎨
⎩
0 if there exist non-negative integers a, k
such that n = 4a(8k + 7),
1 otherwise.
(1)
We show in Sect. 2 that
E(T ) ≤12
(2)
and
LN(T ) ≥(N −7)/4
for N ≥1.
(3)
Note that lower bounds on the Nth linear complexity of many other
automatic sequences including the Thue-Morse sequence, the Rudin-Shapiro
sequence, and the regular paper-folding sequence were obtained in [11]. Roughly
speaking, for the class of non-periodic automatic sequences the linear complex-
ity is a much weaker measure for the unpredictability of a sequence than the
expansion complexity.
Next we study periodic sequences. M´erai, Niederreiter and the second author
[12] recently proved that
EN(S) ≤E(S) = L(S) + 1,
N ≥1,

Linear Complexity and Expansion Complexity
69
for any purely periodic sequence S over Fq. We will provide examples of p-
periodic sequences over Fp with large linear complexity but small Ep(S). More
precisely, for the sequences Au,v = (an)n≥0 of the form
an =
v

k=u
λk
n + k
k

mod p,
n ≥0,
(4)
with λuλv ̸= 0, λk ∈Fp and 0 ≤u < v ≤p −1 we prove in Sect. 3
Ep(Au,v) ≤min

(u + 1)

p
v + 1
	
+ (v −u)
p
v + 1, v + 2
	
=: B(Au,v),
(5)
where {x} = x −⌊x⌋is the fractional part of x. On the one hand the bound can
be very small if v is large with respect to p and v −u is small. For the case u = v
see [12]. On the other hand we have L(Au,v) = v + 1 by [3, Theorem 8]. Hence,
there are many p-periodic sequences over Fp of large linear complexity but small
pth expansion complexity and we have the following hierarchy of complexity
measures for p-periodic sequences
Ep(Au,v) ≤B(Au,v) ≤L(Au,v) + 1 = v + 2,
where B is deﬁned in (5).
Note that any p-periodic sequence can be written in the form (4). More
precisely, any p-periodic sequence S = (sn)n≥0 over Fp can be deﬁned by sn =
f(n), n ≥0, with a unique polynomial f(x) over Fp of degree at most p −1.
Now the polynomials
fk(x) = (k!)−1(x + k)(x + k −1) · · · (x + 1) =
x + k
k

,
k = 0, . . . , p −1,
of degree k are a basis of the linear space of polynomials over Fp of degree at
most p −1. Hence, the sequences

n+k
k

n≥0, k = 0, . . . , p −1, are a basis of
the linear space of p-periodic sequences over Fp and any p-periodic sequence is
a linear combination of these basis sequences.
Further, we consider the Legendre sequence L = (ℓn)n≥0 over Fp of period p
deﬁned by
ℓn =
1 if n is a quadratic residue mod p,
0 otherwise,
or equivalently
ℓn = np−1 + n
p−1
2
2
mod p.
The Legendre sequence has many desirable features of pseudorandomness,
see for example [8,14]. Unfortunately, a lower bound on Ep(L) seems to be out
of reach. However, we prove
B(L) = p + O

p
1
4√e +ε
for any ε > 0
(6)
in Sect. 4.

70
R. Hofer and A. Winterhof
2
The Characteristic Sequence of the Set of Sums
of Three Squares
In this section we prove (2) and (3) for the sequence T over F2 deﬁned by (1).
The generating function G(x) of T is given by
G(x) =
∞

n=0
tnxn =
∞

n=0
xn +
∞

a=0
∞

k=0
x4a(8k+7)
=
1
x + 1 +
∞

a=0

x7
∞

k=0
x8k
4a
=
1
x + 1 +
∞

a=0

x7
(x + 1)8
4a
.
It holds
G(x) + G(x)4 =
1
x + 1 +
1
(x + 1)4 +
x7
(x + 1)8
and therefore we get the equation
(x + 1)8(G(x) + G(x)4) + x6 + x5 + x3 + x2 + x = 0.
(7)
Thus we have found a nonzero polynomial h(x, y) ∈F2[x, y], namely h(x, y) =
(x + 1)8(y + y4) + x6 + x5 + x3 + x2 + x such that h(x, G(x)) = 0. Hence,
E(T ) ≤deg(h) = 12.
Assume G(x) is a rational function, that is
G(x) = f(x)
g(x) ,
f, g ∈F2[x], g ̸= 0,
with gcd(f, g) = 1. Then from (7) we get
(x + 1)8(fg3 + f 4) + (x6 + x5 + x3 + x2 + x)g4 = 0.
Hence (x + 1)8 | g4, that is (x + 1)2 | g. Also g3 | (x + 1)8 since gcd(f, g) = 1.
This is only possible if g(x) = x2+1. Now (x2+1)G(x) = f(x) implies tn+2 = tn
for n ≥deg(f). However, if n ≡7 mod 8 and thus n + 2 ≡1 mod 8, we have
1 = tn+2 ̸= tn = 0. Consequently, G(x) is not rational. Moreover, the four zeros
of h(x, y) are obviously y = G(x) + α with α ∈F4 and none of them is rational.
Put LN = LN(T ) and let
LN

ℓ=0
cℓtn+ℓ= 0,
0 ≤n ≤N −LN −1,
cLN = 1,
be a shortest linear recurrence satisﬁed by the ﬁrst N elements of T . Then
with
g(x) =
LN

ℓ=0
cLN−ℓxℓ

Linear Complexity and Expansion Complexity
71
we get
g(x)G(x) ≡f(x) mod xN
for some polynomial f(x) of degree at most LN −1. Then
(x + 1)8(fg3 + f 4) + (x6 + x5 + x3 + x2 + x)g4 = K(x)xN
with K(x) ̸= 0 since h(x, y) has no rational zero. Comparing the degrees of both
sides gives 4LN + 7 ≥N, that is LN ≥(N −7)/4.
3
Expansion Complexity of p-periodic Sequences over Fp
In this section we prove the bound (5) on Ep(Au,v). Note that any p-periodic
sequence can be uniquely written as some Au,v.
Lemma 1. The generating function of the sequence Au,v = (an)n≥0 deﬁned by
(4) is
G(x) =
v

k=u
λk
(1 −x)k+1 .
Proof. For u = v = k and λk = 1 we have (cf. proof of [12, Lemma 2])
(1 −x)pG(x) = (1 −xp)G(x) =
p−1

n=0
anxn =
p−1−k

n=0
n + k
k

xn
=
p−1−k

n=0
p −1 −k
n

(−x)n = (1 −x)p−1−k
since
p −1 −k
n

(−1)n ≡
n

j=1
k + j
j
≡
n + k
n

≡
n + k
k

mod p.
The generating function of Au,v is the linear combination of the generating
functions of Ak,k with k = u, . . . , v.
⊓⊔
Theorem 1. The p-th expansion complexity of Au,v = (an)n≥0, u < v, of the
form (4) can be bounded by
min

p
v + 2

, v + 2
	
≤Ep(Au,v)
≤min

(u + 1)

p
v + 1
	
+ (v −u)
p
v + 1, v + 2
	
.

72
R. Hofer and A. Winterhof
Proof. The bound
min

p
v + 2

, v + 2
	
≤Ep(Au,v) ≤v + 2
follows from [12, Theorem 1] and [3, Theorem 8].
By Lemma 1 we have
G(x) =
v

k=u
λk
(1 −x)k+1 =
1
(1 −x)v+1
v

k=u
λk(1 −x)v−k.
Put
d =

p
v + 1

and take
h(x, y) = yd −
 v

k=u
λk(1 −x)v−k
d
(1 −x)p−d(v+1).
Then
h(x, G(x)) =
 v
k=u
λk(1 −x)v−k
d
−
 v
k=u
λk(1 −x)v−k
d
(1 −x)p
(1 −x)d(v+1)
=
 v
k=u
λk(1 −x)v−k
d
xp
(1 −x)d(v+1)
≡0 mod xp
since gcd(x, (1 −x)) = 1. Hence
Ep(Au,v) ≤deg(h) = max{d, d(v −u) + p −d(v + 1)}
= max{d, p −d(u + 1)} = p −d(u + 1)
and the result follows.
4
The Legendre Sequence
In this section we prove (6).
Assume L = Au,v. Then we need v = p −1.
If p ≡1 mod 4, then p −1 is a quadratic residue mod p, thus ℓp−1 = 1, and
hence we must have u = 0 since otherwise ℓp−1 = ap−1 = 0.
If p ≡3 mod 4, then p −1 is not a quadratic residue mod p and also p −
u, . . . , p −1 must be quadratic non-residues mod p since ℓn = an = 0 for n =

Linear Complexity and Expansion Complexity
73
p −u, . . . , p −1. This simply means that 1, . . . , u are quadratic residues mod p
since the product of two quadratic non-residues is a quadratic residue. Thus
u = O

p
1
4√e +ε
for any ε > 0,
by the Burgess bound [4, Theorem 2]. Assuming the Extended Riemann Hypoth-
esis we get the better result u = O((log p)2) by Ankeny’s theorem [2].
Hence, the Legendre sequence does not belong to the class of sequences for
which the bound (5) is small.
5
Final Remarks and Open Problems
– Find lower bounds on EN(L) for the Legendre sequence both considered over
Fp and over F2.
– Find lower bounds on EN for other interesting sequences of high linear com-
plexity proﬁle such as inversive pseudorandom number generators or Sidel-
nikov sequences, see [10,14,15].
– Find classes of t-periodic sequences S over Fpr with gcd(t, p) = 1 and Et(S)
of smaller order of magnitude than L(S).
– A relation between Nth expansion complexity and Nth linear complexity is
stated in [12, Theorem 3].
Acknowledgements. The authors are partially supported by the Austrian Science
Fund FWF Project 5511-N26 which is part of the Special Research Program “Quasi-
Monte Carlo Methods: Theory and Applications”.
References
1. Allouche, J.P., Shallit, J.: Automatic Sequences: Theory, Applications, Generaliza-
tions. Cambridge University Press, Cambridge (2003)
2. Ankeny, N.C.: The least quadratic non residue. Ann. Math. 2(55), 65–72 (1952)
3. Blackburn, S.R., Etzion, T., Paterson, K.G.: Permutation polynomials, de Bruijn
sequences, and linear complexity. J. Comb. Theory Ser. A 76(1), 55–82 (1996)
4. Burgess, D.A.: The distribution of quadratic residues and non-residues. Mathe-
matika 4, 106–112 (1957)
5. Christol, G.: Ensembles presque periodiques k-reconnaissables. Theor. Comput.
Sci. 9(1), 141–145 (1979)
6. Christol, G., Kamae, T., Mend´es-France, M., Rauzy, G.: Suites alg´ebriques, auto-
mates et substitutions. Bull. Soc. Math. Fr. 108(4), 401–419 (1980)
7. Diem, C.: On the use of expansion series for stream ciphers. LMS J. Comput.
Math. 15, 326–340 (2012)
8. Hofer, R., Winterhof, A.: On the arithmetic autocorrelation of the Legendre
sequence. Adv. Math. Commun. 11(1), 237–244 (2017)
9. Lidl, R., Niederreiter, H.: Finite ﬁelds. In: Encyclopedia of Mathematics and Its
Applications, vol. 20. Addison-Wesley Publishing Company, Advanced Book Pro-
gram, Reading (1983)

74
R. Hofer and A. Winterhof
10. Meidl, W., Winterhof, A.: Linear complexity of sequences and multisequences. In:
Handbook of Finite Fields. Discrete Mathematics and its Applications, pp. 324–
336. CRC Press, Boca Raton (2013)
11. M´erai, L., Winterhof, A.: On the Nth linear complexity of p-automatic sequences
over Fp (2016, preprint)
12. M´erai, L., Niederreiter, H., Winterhof, A.: Expansion complexity and linear com-
plexity of sequences over ﬁnite ﬁelds. Cryptogr. Commun. 1–9 (2016)
13. Niederreiter, H.: Linear complexity and related complexity measures for sequences.
In: Johansson, T., Maitra, S. (eds.) INDOCRYPT 2003. LNCS, vol. 2904, pp. 1–17.
Springer, Heidelberg (2003). doi:10.1007/978-3-540-24582-7 1
14. Topuzo˘glu,
A.,
Winterhof,
A.:
Pseudorandom
sequences.
In:
Garcia,
A.,
Stichtenoth, H. (eds.) Topics in Seometry Coding Theory and Cryptography. Alge-
bra and Applications, vol. 6, pp. 135–166. Springer, Dordrecht (2007)
15. Winterhof, A.: Linear complexity and related complexity measures. Selected topics
in information and coding theory. Coding Theory and Cryptology, vol. 7, pp. 3–40.
World Scientiﬁc Publishing, Hackensack (2010)

Irreducible Polynomials

On Sets of Irreducible Polynomials Closed
by Composition
Andrea Ferraguti1, Giacomo Micheli2(B), and Reto Schnyder3
1 DPMMS, Centre for Mathematical Sciences, University of Cambridge,
Wilbeforce Rd, Cambridge CB3 0WB, UK
af612@cam.ac.uk
2 Mathematical Institute, University of Oxford,
Woodstock Rd, Oxford OX2 6GG, UK
giacomo.micheli@maths.ox.ac.uk
3 Institute of Mathematics, University of Zurich,
Winterthurerstrasse 190, Zurich 8057, Switzerland
reto.schnyder@math.uzh.ch
Abstract. Let S be a set of monic degree 2 polynomials over a ﬁnite ﬁeld
and let C be the compositional semigroup generated by S. In this paper
we establish a necessary and suﬃcient condition for C to be consisting
entirely of irreducible polynomials. The condition we deduce depends on
the ﬁnite data encoded in a certain graph uniquely determined by the
generating set S. Using this machinery we are able both to show exam-
ples of semigroups of irreducible polynomials generated by two degree 2
polynomials and to give some non-existence results for some of these sets
in inﬁnitely many prime ﬁelds satisfying certain arithmetic conditions.
Keywords: Finite ﬁelds · Irreducible polynomials · Semigroups ·
Graphs
1
Introduction
Since irreducible polynomials play a fundamental role in applications and in the
whole theory of ﬁnite ﬁelds (see for example [2,4,13–16]), related questions have a
long history (see for example [3,8,9,11,12,17,18]). In this paper we specialize on
irreducibility questions regarding compositional semigroups of polynomials. This
kind of question has been addressed in the speciﬁc case of semigroups generated
by a single quadratic polynomial, see for example in [1,2,10–12,15], for analogous
results related to additive polynomials, see [5,6]. It is worth mentioning that one
of these results [12, Lemma 2.5] has been recently used in [7] by the ﬁrst and the
second author of the present paper to prove [3, Conjecture 1.2].
Throughout the paper, q will be an odd prime power, Fq[x] the univariate
polynomial ring over the ﬁnite ﬁeld Fq and Irr(Fq[x]) the set of irreducible poly-
nomials in Fq[x]. Let us give an example which motivates this paper. For a
prime q congruent to 1 modulo 4, we can ﬁx in Fq[x] two quadratic polynomials
c
⃝Springer International Publishing AG 2016
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 77–83, 2016.
DOI: 10.1007/978-3-319-55227-9 6

78
A. Ferraguti et al.
f = (x −a)2 + a and g = (x −a −1)2 + a such that both a and a + 1 are
non-squares in Fq. One can experimentally check that any possible composition
of a sequence of f’s and g’s is irreducible (for a concrete example, take q = 13,
(x −5)2 + 5 and g = (x −6)2 + 5). Let us denote the set of such compositions
by C. A couple of observations are now necessary:
– In principle, it is unclear whether a ﬁnite number of irreducibility checks will
ensure that C is a subset of Irr(Fq[x]).
– The fact that C ⊆Irr(Fq[x]) is indeed pretty unlikely to happen by chance,
as the density of degree 2n monic irreducible polynomials over Fq is roughly
1/2n. Thus, if C satisﬁes this property, one reasonably expects that there must
be an algebraic reason for that.
We address these issues by giving a necessary and suﬃcient condition for the
semigroup C ⊂Fq[x] to be contained in Irr(Fq[x]). In addition, this condition is
algebraic and can be checked by performing only a ﬁnite amount of computation
over Fq, answering both points above.
In Sect. 2 we describe the criterion (Theorem 2.4 and Corollary 2.5) and pro-
vide a non-trivial example (Example 2.7) of a compositional semigroup in Fq[x]
contained in Irr(Fq[x]) and generated by two polynomials.
In Sect. 3 we show the non-existence of such C whenever q is a prime con-
gruent to 3 modulo 4 and the generating polynomials are of a certain form
(Proposition 3.2). Example 3.3 shows that these conditions are indeed sharp.
2
A General Criterion
In order to state our main result, we ﬁrst need the following deﬁnition, which
describes how to build a ﬁnite graph encoding only the useful (to our purposes)
information contained in the generating set of the semigroup.
Deﬁnition 2.1. Let q be an odd prime power, Fq the ﬁnite ﬁeld of order q and
S a subset of Fq[x]. We denote by GS the directed multigraph deﬁned as follows:
– the set of nodes of GS is Fq;
– for any node a ∈Fq and any polynomial f ∈S, there is a directed edge
a →f(a). We label that edge with f.
Before stating the next deﬁnition, we recall that for any monic polynomial f
of degree 2 there exists a unique pair (af, bf) ∈F2
q such that f = (x −af)2 −bf.
Deﬁnition 2.2. Let S be a subset of Fq[x] consisting of monic polynomials of
degree 2. We call the set DS = {−bf | f ∈S} ⊆Fq, the S-distinguished set
of Fq.
The following result is just an inductive extension of the classical Capelli’s
Lemma.

On Sets of Irreducible Polynomials Closed by Composition
79
Lemma 2.3 (Recursive Capelli’s Lemma). Let K be a ﬁeld and f1, . . . , fℓ
be a set of irreducible polynomials in K[X]. The polynomial f1(f2(· · · (fℓ) · · · ))
is irreducible if and only if the following conditions are satisﬁed:
• f1 is irreducible over K[X],
• f2 −α1 is irreducible over K(α1)[X] for a root α1 of f1,
• f3 −α2 is irreducible over K(α1, α2)[X] for a root α2 of f2 −α1,
· · ·
• fℓ−αℓ−1 is irreducible over K(α1, . . . , αℓ−1)[X] for a root αℓ−1 of fℓ−1−αℓ−2.
Proof. Given Capelli’s Lemma [12, Lemma 2.4], the proof is straightforward by
induction.
⊓⊔
We are now ready to state and prove the main theorem.
Theorem 2.4. Let S be a set of generators for a compositional semigroup C ⊆
Fq[x]. Suppose that S consists of polynomials of degree 2. Then we have that
C ⊆Irr(Fq[x]) if and only if no element of −DS = {bf | f ∈S} ⊆Fq is a square
and in GS there is no path of positive length from a node of DS to a square
of Fq.
Proof. It is clear that C contains a reducible polynomial of degree 2 if and only
if one element of −DS is a square. Thus we can assume that S consists only of
irreducible polynomials.
We now show that in GS there is a path of positive length from a node of DS
to a square if and only if C contains a reducible polynomial of degree greater or
equal than 4.
First, suppose that the composition f1f2 · · · fℓ+1 is a reducible polynomial
of minimal degree, with fi ∈S and fi = (x −ai)2 −bi, for i ∈{1, . . . , ℓ+ 1}
and ℓ≥1. Whenever β is not a square in Fq, we denote by √β a root of the
polynomial T 2 −β in the algebraic closure of Fq. By Capelli’s Lemma applied to
the composition of f1 · · · fℓand by the minimality of the degree of f1f2 · · · fℓ+1,
we have that the following elements are not squares in their ﬁeld of deﬁnition:
β0 = b1 ∈Fq
β1 = b2 + a1 +

β0 ∈Fq2
β2 = b3 + a2 +

β1 ∈Fq22
. . .
βℓ−1 = bℓ+ aℓ−1 +

βℓ−2 ∈Fq2ℓ−1.
(1)
To see this, note that f1 has the root α1 = a1 +√β0, so f2 −α1 = (x−a2)2 −β1
is irreducible if and only if β1 is nonsquare; and so on. On the other hand,
βℓ= bℓ+1 +aℓ+

βℓ−1 ∈Fq2ℓis necessarily a square. For j < i, let us denote by
N j
i : Fq2i →Fq2j the usual norm map. We claim that the Fq-norm N 0
ℓ: Fq2ℓ→Fq
maps βℓto f1(· · · fℓ(−bℓ+1) · · · ), and this deﬁnes a path in GS from −bℓto a
square. This can be easily seen by ﬁrst decomposing N 1
ℓ:
N 1
ℓ= N 1
2 ◦N 2
3 ◦. . . N ℓ−1
ℓ
(2)

80
A. Ferraguti et al.
and then by directly computing N 1
2 ◦N 2
3 ◦. . . N ℓ−1
ℓ
(βℓ). It is important indeed
that β0, β1, . . . , βℓ−1 are not squares, as the computation above only gives the
desired result when (√βi)q2i
= −√βi.
Conversely, suppose that in GS there is a path to a square s. Choose such a
path of minimal length, starting at some −bf in the distinguished set, for some
f ∈S. Consider now the composition associated to this path: if
s = f1f2 · · · fℓ(−bf),
(3)
set fℓ+1 = f and let g = f1f2 · · · fℓ+1 ∈Fq[x]. One can construct the βi’s as
before, i.e. β0 = b1 and for i ∈{1, . . . , ℓ}, βi = bi+1+ai+

βi−1. We can suppose
that the βi’s for i < ℓare all non-squares as otherwise, by taking the smallest d
such that βd is square, we ﬁnd a composition f1f2 · · · fd+1 that is reducible by
Recursive Capelli’s Lemma, and then we are done.
As all the βi’s, for i < ℓ, can be supposed to be non-squares, we have as
above that N 0
ℓ(βℓ) = f1f2 · · · fℓ(−bℓ+1) = s, which we have assumed to be a
square. Now, recall that an element of a ﬁnite ﬁeld is a square if and only if its
norm is a square: this shows that g is reducible by Recursive Capelli’s Lemma.
⊓⊔
The reader should observe that this theorem generalizes [12, Proposition 2.3],
as the condition given by our graph is the same as the stability condition in
[12, Proposition 2.3] whenever the semigroup we are considering has only one
generator. It is useful to mention the following corollary, which is immediate.
Corollary 2.5. Let S be a set of irreducible degree two polynomials and C
deﬁned as in Theorem 2.4. Then C ⊆Irr(Fq[x]) if and only if there is no path of
positive length from a node of DS to a square of Fq.
Proof. It is enough to observe that whenever S ⊆Irr(Fq[x]) then −DS consists
of non-squares.
⊓⊔
Remark 2.6. Given that C is generated by degree 2 polynomials, it is easy to
observe that the datum of S is equivalent to the datum of C.
The following example shows a way to ﬁnd examples of semigroups contained in
Irr(Fq[x]) when q ≡1 mod 4.
Example 2.7. Let q ≡1 mod 4 be a prime power, and let a ∈Fq such that both
a and b = a + 1 are non-squares. Deﬁne f = (x −a)2 + a and g = (x −b)2 + a.
In this situation, we have DS = {a}, and by assumption, −a, a and b are all
non-squares. Since f(a) = g(b) = a and f(b) = g(a) = b, all paths in GS starting
from a end in a non-square, and the conditions of Theorem 2.4 are satisﬁed.
Figure 1 shows the relevant part of the graph GS. The reader should observe
that this is indeed the example mentioned in the introduction.
a
b
g
g
f
f
Fig. 1. The nodes of GS reachable from DS.

On Sets of Irreducible Polynomials Closed by Composition
81
3
The Case p ≡3 mod 4
Whenever q = p is a prime congruent to 3 modulo 4, we have the following
non-existence results for polynomials without a linear term.
Proposition 3.1. Let p ≡−1 mod 8 be a prime, and let f = x2 −b be a
polynomial in Fp[x]. Let C be the semigroup generated by f. Then C contains a
reducible polynomial.
Proof. Assume for contradiction that C ⊂Irr(Fp[x]). First note that if b is a
square, then f is reducible, so we can assume that b is not a square, and thus
−b is a square. Consider the set of iterates T = {f(−b), f 2(−b), . . .} ⊆Fp. By
Corollary 2.5, C contains only irreducible polynomials if and only if T contains
only nonsquares. So assume that this condition holds. Since T is ﬁnite, there
exist k < m ∈N>0 such that f m(−b) = f k(−b). Choose k to be minimal. Now
there are two cases: if k > 1, then there exist two distinct elements u, v ∈T
such that u2 −b = v2 −b. Thus, u = −v, which implies that one between u
and v is a square, a contradiction. If on the other hand k = 1, then we have
f m(−b) = f(−b) = b2−b, and so f m−1(−b) is either −b or b. It can’t be −b, since
that is a square, so we must have f m−1(−b) = b ∈T. Setting u = f m−2(−b),
we get that u2 −b = b and so u2 = 2b, which is a contradiction because 2 is a
square in Fp and consequently 2b is not.
⊓⊔
Proposition 3.2. Let p ≡3 mod 4 be a prime. Let f = x2 −bf and g = x2 −bg
be polynomials in Fp[x] with bf, bg distinct non-squares. Let S = {f, g} and let
C be the semigroup generated by S. Then C contains a reducible polynomial.
Proof. Let GS be the graph attached to S as in Deﬁnition 2.1. Let G′
S be the
induced subgraph consisting of all nodes of GS that are reachable by some path
of positive length starting from −bf or −bg. That is, the edges of G′
S are just
the edges of GS starting and ending at a node in G′
S. From now on, when we
speak of nodes and edges, we will always be referring to nodes and edges in G′
S.
We call an edge from u to v an f-edge if it comes from the relation f(u) = v,
while we call it a g-edge if it comes from g(u) = v. Since bf and bg are assumed
nonsquare, we have by Corollary 2.5 that C contains a reducible polynomial if
and only if at least one of the nodes of G′
S is a square. In the following, we
assume for contradiction that G′
S consists only of non-squares.
Let us observe the following: suppose that there exists a node v of G′
S which is
the target of two f-edges. By deﬁnition, this means that there exist two distinct
nodes u, u′ ∈G′
S such that u2 −bf = u′2 −bf = v. This implies that u′ = −u,
and thus one between u and u′ is a square, since −1 is not a square in Fp. This
contradicts our assumption. By symmetry, the same applies to g-edges.
By the argument above, we see that every node is the target of at most
one f-edge and one g-edge, and by counting edges that it is indeed exactly one
of each.

82
A. Ferraguti et al.
Now, consider the sum

v∈G′
S
(f(v) −g(v)).
(4)
On one hand, each node u ∈G′
S appears exactly once as f(v) and once as g(v′)
for some v, v′ ∈G′
S, so the sum is zero. On the other hand, it clearly holds that
f(v) −g(v) = bg −bf for all v. Letting n be the number of nodes in G′
S, we get
the equation
0 = n(bg −bf) in Fp.
(5)
Since bf ̸= bg by hypothesis, we must have p | n. This is impossible however,
since G′
S is not empty and consists only of nonsquares, so 1 ≤n ≤p−1
2 .
⊓⊔
The fact that the polynomials of Proposition 3.2 don’t have a linear term is of
crucial importance. Let us see why by giving an explicit example of a semigroup
of irreducible polynomials in Fp[x] for which Proposition 3.2 does not apply (but
p ≡3 mod 4).
Example 3.3. Let us ﬁx p = 7 and
f = (x −1)2 −5 = x2 + 5x + 3 ∈F7[x]
g = (x −4)2 −5 = x2 + 6x + 4 ∈F7[x].
(6)
The set S = {f, g} has distinguished set DS = {−5} and graph as in Fig. 2.
Since 5 is not a square, and we only look at paths of positive length, the ﬁnal
claim follows by checking that 3 and −1 are not squares modulo 7.
−5
3
−1
f
g
f
g
f
g
Fig. 2. The nodes of GS reachable from −5.
Acknowledgements. The ﬁrst author was supported by the Swiss National Science
Foundation grant number 168459. The second author was supported by Swiss National
Science Foundation grant number 161757. The third author was supported in part by
Swiss National Science Foundation grant number 149716 and Armasuisse.

On Sets of Irreducible Polynomials Closed by Composition
83
References
1. Ahmadi, O.: A note on stable quadratic polynomials over ﬁelds of characteristic
two. arXiv preprint arXiv:0910.4556 (2009)
2. Ahmadi, O., Luca, F., Ostafe, A., Shparlinski, I.E.: On stable quadratic polyno-
mials. Glasg. Math. J. 54(02), 359–369 (2012)
3. Andrade, J., Miller, S.J., Pratt, K., Trinh, M.T.: Special sets of primes in function
ﬁelds. arXiv preprint arXiv:1309.5597 (2013)
4. Barbulescu, R., Gaudry, P., Joux, A., Thom´e, E.: A heuristic quasi-polynomial
algorithm for discrete logarithm in ﬁnite ﬁelds of small characteristic. In: Nguyen,
P.Q., Oswald, E. (eds.) EUROCRYPT 2014. LNCS, vol. 8441, pp. 1–16. Springer,
Heidelberg (2014). doi:10.1007/978-3-642-55220-5 1
5. Batra, A., Morton, P.: Algebraic dynamics of polynomial maps on the algebraic
closure of a ﬁnite ﬁeld, I. Rocky Mt. J. Math. 24(2), 453–481 (1994)
6. Batra, A., Morton, P.: Algebraic dynamics of polynomial maps on the algebraic
closure of a ﬁnite ﬁeld, II. Rocky Mt. J. Math. 24(3), 905–932 (1994)
7. Ferraguti, A., Micheli, G.: On the existence of inﬁnite, non-trivial F-sets. J. Num-
ber Theory (2016, to appear)
8. Gao, S., Howell, J., Panario, D.: Irreducible polynomials of given forms. Contemp.
Math. 225, 43–54 (1999)
9. Gao, S., Panario, D.: Tests and constructions of irreducible polynomials over ﬁnite
ﬁelds. In: Cucker, F., Shub, M. (eds.) Foundations of Computational Mathematics,
pp. 346–361. Springer, Heidelberg (1997)
10. Gomez, D., Nicol´as, A.P.: An estimate on the number of stable quadratic polyno-
mials. Finite Fields Appl. 16(6), 401–405 (2010)
11. Jones, R.: An iterative construction of irreducible polynomials reducible modulo
every prime. J. Algebra 369, 114–128 (2012)
12. Jones, R., Boston, N.: Settled polynomials over ﬁnite ﬁelds. Proc. Am. Math. Soc.
140(6), 1849–1863 (2012)
13. Lidl, R., Niederreiter, H.: Finite Fields, vol. 20. Cambridge University Press,
Cambridge (1997)
14. Mullen, G.L., Panario, D.: Handbook of Finite Fields. CRC Press, Boca Raton
(2013)
15. Ostafe, A., Shparlinski, I.E.: On the length of critical orbits of stable quadratic
polynomials. Proc. Am. Math. Soc. 138(8), 2653–2656 (2010)
16. Rabin, M.O., et al.: Fingerprinting by random polynomials. Center for Research
in Computing Techn., Aiken Computation Laboratory, Univ. (1981)
17. Shoup, V.: New algorithms for ﬁnding irreducible polynomials over ﬁnite ﬁelds.
Math. Comp. 54(189), 435–447 (1990)
18. von ZurGathen, J.: Irreducible trinomials over ﬁnite ﬁelds. Math. Comp. 72(244),
1987–2000 (2003)

A Note on the Brawley-Carlitz Theorem
on Irreducibility of Composed Products
of Polynomials over Finite Fields
Akihiro Munemasa(B) and Hiroko Nakamura
Research Center for Pure and Applied Mathematics,
Graduate School of Information Sciences, Tohoku University, Sendai, Japan
munemasa@math.is.tohoku.ac.jp, nakamu@ims.is.tohoku.ac.jp
Abstract. We give a new proof of the Brawley-Carlitz theorem on irre-
ducibility of the composed products of irreducible polynomials. Our proof
shows that associativity of the binary operation for the composed prod-
uct is not necessary. We then investigate binary operations deﬁned by
polynomial functions, and give a suﬃcient condition in terms of degrees
for the requirement in the Brawley-Carlitz theorem.
Keywords: Finite ﬁeld · Composed product · Irreducible polynomial
1
Introduction
For a prime power q, we denote by Fq a ﬁnite ﬁeld with q elements. If m and n
are relatively prime positive integers, then the composite ﬁeld of Fqm and Fqn is
Fqmn. In fact, if Fqm = Fq(α) and Fqn = Fq(β), then Fqmn = Fq(α+β) = Fq(αβ).
In other words, both α + β and αβ have minimal polynomial of degree mn
over Fq. Brawley and Carlitz generalized this fact by introducing the method of
composed products in order to construct irreducible polynomials of large degree
from polynomials of lower degree. A basic material of their construction is a
binary operation on a subset of Fq having certain properties, where Fq is the
algebraic closure of Fq. Let G be a non-empty subset of Fq, which is invariant
under the Frobenius map α →αq. A binary operation ⋄: G × G →G is called
a diamond product on G if
σ(α ⋄β) = σ(α) ⋄σ(β)
(1)
holds for all α, β ∈G. Let MG[q, x] denote the set of all monic polynomials f
in Fq[x] such that deg f ≥1, and all of the roots of f lie in G. Let f(x) =
m
i=1(x −αi) and g(x) = n
i=1(x −βi) be in polynomials in MG[q, x], where
α1, . . . , αm, β1, . . . , βn ∈G. We deﬁne the composed product f ⋄g as
(f ⋄g)(x) =
m

i=1
n

j=1
(x −αi ⋄βj).
A. Munemasa—The work of this author is partially supported by JSPS KAKENHI
Grant Number 26400003.
c
⃝Springer International Publishing AG 2016
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 84–92, 2016.
DOI: 10.1007/978-3-319-55227-9 7

A Note on the Brawley-Carlitz Theorem on Irreducibility
85
Theorem 1 ([1, Theorem 2]). Let ⋄be a diamond product on a non-empty sub-
set G of Fq. Suppose that (G, ⋄) is a group and let f, g be polynomials in MG[q, x]
with deg f = m and deg g = n. Then the composed product f ⋄g is irreducible if
and only if f and g are both irreducible with gcd(m, n) = 1.
The purpose of this paper is to give a new proof of Theorem 1 with weaker
hypotheses. In order to explain the weakened hypothesis, we need a deﬁnition.
For a positive integer m, let
Fm(q) = {α ∈Fqm | Fq(α) = Fqm}.
Clearly,
Fkl(q) ⊂Fl(qk)
(2)
for positive integers k, l.
Deﬁnition 2. Let ⋄be a diamond product on a subset G ⊂Fq containing
Fm(q) ∪Fn(q). We say that ⋄satisﬁes weak cancellation on Fm(q) × Fn(q), if
α ⋄β = α ⋄β′ =⇒β = β′,
(3)
α ⋄β = α′ ⋄β =⇒α = α′
(4)
for all α, α′ ∈Fm(q) and β, β′ ∈Fn(q).
We will show in Sect. 2 that the conclusion of Theorem 1 holds if ⋄satisﬁes
weak cancellation on Fm(q)×Fn(q). In other words, associativity of the product ⋄
is unnecessary. In Sect. 3, we consider a diamond product deﬁned by a polynomial
function, and show that such a diamond product satisﬁes weak cancellation if
the degree is small (see Theorem 9 for details). In Sect. 4, the optimality of the
degree bound for weak cancellation is investigated. This leads us to a conjecture
on the existence of irreducible polynomials all of whose coeﬃcients except the
constant term belong to the prime ﬁeld.
2
The Brawley-Carlitz Theorem
Throughout this paper, we let q be a prime power, and σ : Fq →Fq denote the
Frobenius map α →αq. For positive integers k and r, we denote by ordk(r) the
multiplicative order of r modulo k. For a nonzero α ∈Fq, we denote by |α| the
multiplicative order of α. Then (see, for example, [3, Corollary 2.15]), we have,
for m > 1,
Fm(q) = {α ∈Fqm | α, σ(α), . . . , σm−1(α) : pairwise distinct}
= {α ∈Fqm | {l ∈Z | σl(α) = α} = mZ}
= {α ∈Fqm | α ̸= 0, ord|α|(q) = m}.
Our proof of the Brawley-Carlitz theorem relies on the following lemma in group
theory.

86
A. Munemasa and H. Nakamura
Lemma 3. Let Γ be a ﬁnite group of order mn having subgroups M and N of
order m and n, respectively. Assume Γ = M × N and (m, n) = 1. If K is a
subgroup of Γ, then K = (K ∩M)(K ∩N).
Proof. Since (m, n) = 1, there exist integers r, s such that rm + sn = 1. Let
z ∈K. Since Γ = M × N, there exist x ∈M and y ∈N such that z = xy. Then
z = zsnzrm with zsn = xsn ∈K ∩M, zrm = yrm ∈K ∩N. Since z ∈K was
arbitrary, we conclude K ⊂(K ∩M)(K ∩N). Since the reverse containment is
obvious, we obtain the desired result.
Theorem 4. Suppose G is a non-empty subset of Fq. Let ⋄be a diamond prod-
uct on G satisfying (3) and (4). Let f, g ∈MG[q, x], deg f = m and deg g = n.
Then the following are equivalent:
(i) f ⋄g is irreducible in Fq[x],
(ii) f and g are irreducible in Fq[x], and gcd(m, n) = 1.
Proof. (i) =⇒(ii). Since (f ⋄g)(x) is irreducible, clearly f(x) and g(x) are
irreducible. Let α and β be roots of f(x) and g(x), respectively. Then α ⋄β
is a root of (f ⋄g)(x) which is an irreducible polynomial of degree mn. This
implies ord|α⋄β|(q) = mn. Let ℓbe the least common multiple of m and n. Then
σℓ(α⋄β) = σℓ(α)⋄σℓ(β) = α⋄β. Thus ord|α⋄β|(q) divides ℓ, and hence, ℓ= mn.
This implies gcd(m, n) = 1.
(ii) =⇒(i) Let α ∈Fm(q) and β ∈Fn(q) be roots of f and g, respectively.
The Frobenius automorphism σ generates the group F = ⟨σ⟩of order mn acting
on Fqmn. Moreover, setting
M = ⟨σn⟩= {h ∈F | h(β) = β},
(5)
N = ⟨σm⟩= {h ∈F | h(α) = α},
(6)
we have |M| = m and |N| = n, so F = M × N. Let
K = {h ∈F | h(α ⋄β) = α ⋄β}.
Then
|F · (α ⋄β)| = |F : K|.
(7)
We claim K ∩M = K ∩N = 1. Indeed, if h ∈K ∩M, then
α ⋄β = h(α ⋄β)
= h(α) ⋄h(β)
(by (1))
= h(α) ⋄β,
so α = h(α) by (4). This implies h ∈N. Since h ∈M and M ∩N = 1, we
conclude h = 1. This proves K ∩M = 1. Similarly, we can prove K ∩N = 1
using (3).
Now, by Lemma 3, we obtain K = 1. This implies |F · (α ⋄β)| = |F| by (7).
Therefore, the degree of the minimal polynomial of α ⋄β over Fq is |F| = mn.
Since deg(f ⋄g) = mn and (f ⋄g)(α ⋄β) = 0, we conclude that f ⋄g is the
minimal polynomial of α ⋄β over Fq, and hence irreducible in Fq[x].

A Note on the Brawley-Carlitz Theorem on Irreducibility
87
3
Diamond Products Deﬁned by Polynomial Functions
Stichtenoth [5] classiﬁed associative diamond products deﬁned by a polynomial
function, under a certain condition. As we have seen in the previous section,
associativity is irrelevant for the Brawley-Carlitz theorem. This prompts us to
classify diamond products satisfying weak cancellation instead. In this section,
we consider diamond products deﬁned by a polynomial function, and give a
suﬃcient condition in terms of degrees in order that the associated diamond
product satisﬁes weak cancellation. It turns out that, in general, a wider class
of polynomials than those classiﬁed in [5] can be used as a diamond product.
Let m be a positive integer, and let ψ : Fm(q) →Fm(q) be a function. We
say that ψ satisﬁes the restricted injectivity on Fm(q) if, for all α ∈Fm(q) and
k ∈Z,
ψ(α) = ψ(σk(α)) =⇒α = σk(α).
(8)
If ψ : Fm(q) →Fq is a function taking values in Fqm such that ψ commutes with
σ, then ψ(σk(α)) = σk(ψ(α)). Thus, (8) is equivalent to
ψ(α) ∈Fm(q).
(9)
In particular, this equivalence holds when ψ is a polynomial function with coef-
ﬁcients in Fq.
Lemma 5. Let ψ(x) ∈Fq[x] be a polynomial with deg ψ ≥1. Then for α ∈Fq,
deg ψ ≥[Fq(α) : Fq(ψ(α))].
Proof. Let ψ0(x) = ψ(x)−ψ(α) ∈Fq(ψ(α))[x]. Then ψ0(α) = 0, so ψ0 is divisible
by the minimal polynomial of α over Fq(ψ(α)). This implies
[Fq(α) : Fq(ψ(α))] ≤deg ψ0
= deg ψ.
Lemma 6. Let m > 1 be an integer, and let m1 be the smallest prime divisor
of m. If ψ(x) ∈Fq[x] is a monic polynomial with 0 < deg ψ < m1, then the
function deﬁned by ψ satisﬁes the restricted injectivity on Fm(q).
Proof. For α ∈Fm(q), we have
m1 > deg ψ
≥[Fq(α) : Fq(ψ(α))]
(by Lemma 5)
= [Fqm : Fq(ψ(α))].
Since [Fqm : Fq(ψ(α))] is a divisor of m and m1 is the smallest prime divisor
of m, we conclude that [Fqm : Fq(ψ(α))] = 1, that is, Fq(ψ(α)) = Fqm. This
implies (9).

88
A. Munemasa and H. Nakamura
Lemma 7. Let m1 be the smallest prime divisor of a positive integer m > 1,
and let k be an integer not divisible by m. Then for α ∈Fm(q), α −σk(α), α2 −
σk(α2), . . . , αm1−1 −σk(αm1−1) are linearly independent over Fq.
Proof. Suppose α −σk(α), α2 −σk(α2), . . . , αm1−1 −σk(αm1−1) are linearly
dependent. Then there exist a1, . . . , am1−1 ∈Fq, (a1, . . . , am1−1) ̸= (0, . . . , 0),
and
m1−1

i=1
ai(αi −σk(αi)) = 0.
Let
a0 =
m1−1

i=1
aiαi ∈Fqm,
f(x) =
m1−1

i=1
aixi −a0 ∈Fq(a0)[x].
Then σk(a0) = a0, so f ∈Fqgcd(k,m)[x]. Since f(α) = 0, f is divisible by the
minimal polynomial of α over Fqgcd(k,m). This implies
m1 > deg f
≥[Fqgcd(k,m)(α) : Fqgcd(k,m)]
= [Fqm : Fqgcd(k,m)]
=
m
gcd(k, m).
Since m1 is the smallest prime divisor of m, we obtain gcd(k, m) = m, that is,
m | k. This is a contradiction.
Lemma 8. If m and n are relatively prime positive integers, then Fn(q) ⊂
Fn(qm). In particular, if α ∈Fm(q), β ∈Fn(q), k ∈Z and
ϕ(x, y) =
n−1

i=0
ψi(x)yi ∈Fq[x, y]
satisfy ϕ(σk(α), β) = ϕ(α, β), then ψi(σk(α)) = ψi(α) for 0 ≤i ≤n −1.
Proof. The ﬁrst part is immediate from [3, Corollary 3.47]. Since ϕ(σk(α), β) =
ϕ(α, β), we have
n−1

i=0
(ψi(σk(α)) −ψi(α))βi = 0.
Since β ∈Fn(q) ⊂Fn(qm) and ψi(σk(α)) −ψi(α) ∈Fqm, linear independence
of 1, β, . . . , βn−1 over Fqm shows ψi(σk(α)) = ψi(α) for 0 ≤i ≤n −1.

A Note on the Brawley-Carlitz Theorem on Irreducibility
89
Theorem 9. Let q be a prime power, and let m, n > 1 be relatively prime posi-
tive integers. Suppose m1 is the smallest prime divisor of m, n1 is the smallest
prime divisor of n. Let ϕ(x, y) ∈Fq[x, y] be a polynomial with 0 < degx ϕ < m1
and 0 < degy ϕ < n1. Then the diamond product on Fq deﬁned by ϕ satisﬁes
weak cancellation on Fm(q) × Fn(q).
Proof. We need to show
ϕ(α, β) = ϕ(σk(α), β) =⇒α = σk(α),
(10)
ϕ(α, β) = ϕ(α, σk(β)) =⇒β = σk(β).
(11)
It suﬃces to show only (10), as the proof of (11) is similar. Suppose α ∈Fm(q),
β ∈Fn(q), k ∈Z. Let
ϕ(x, y) =
n1−1

i=0
ψi(x)yi,
(12)
ψi(x) =
m1−1

j=0
aijxj
(0 ≤i ≤n1 −1).
(13)
If ϕ(α, β) = ϕ(σk(α), β), then, by Lemma 8, ψi(α) −ψi(σk(α)) = 0 for 0 ≤i ≤
n1 −1. This implies
m1−1

j=1
aij(αj −σk(αj)) = 0
(0 ≤i ≤n1 −1).
If α ̸= σk(α), then k is not divisible by m. Then by Lemma 7, we obtain aij = 0
for 0 ≤i ≤n1−1 and 1 ≤j ≤m1−1. This implies degx ϕ = 0, which contradicts
the assumption. Therefore, α = σk(α).
4
Irreducible Polynomials All of Whose Coeﬃcients
Except the Constant Term Belong to the Prime Field
In this section, we show that the hypotheses degx ϕ < m1 and degy ϕ < n1 in
Theorem 9 are necessary. We believe that these upper bounds cannot be relaxed
for any prime power q and relatively prime positive integers m and n. This
leads to a conjecture on the existence of irreducible polynomials all of whose
coeﬃcients except the constant term belong to the prime ﬁeld.
Proposition 10. Let m and n be relatively prime integers with m, n > 1. Let
m1 and n1 be the smallest prime divisor of m and n, respectively. Then the
following are equivalent:
(i) there exists a polynomial ϕ(x, y) ∈Fq[x, y] with degx ϕ = m1, 0 < degy ϕ <
n1, such that σk(α) ̸= α and ϕ(σk(α), β) = ϕ(α, β) for some α ∈Fm(q)
and β ∈Fn(q),

90
A. Munemasa and H. Nakamura
(ii) there exists a polynomial ψ(x) ∈Fq[x] with deg ψ = m1 which fails to satisfy
the restricted injectivity on Fm(q),
(iii) Fm/m1(q) ∩{αm1 + m1−1
i=1
ciαi | α ∈Fm(q), c1, . . . , cm1−1 ∈Fq} ̸= ∅,
(iv) there exists a monic irreducible polynomial f(x) ∈Fqm/m1[x] of degree m1
such that f(x) −f(0) ∈Fq[x] and f(0) ∈Fm/m1(q).
Proof. (i) =⇒(ii). Let ϕ(x, y) be as in (12), where ψi(x) ∈Fq[x] for 0 ≤i ≤
n1 −1. Then by Lemma 8, ψi(σk(α)) = ψi(α) for 0 ≤i ≤n1 −1. By the
assumption, there exists i ∈{0, 1, . . . , n1 −1} such that deg ψi = m1, and this
ψi fails to satisfy the restricted injectivity on Fm(q).
(ii) =⇒(iii). We may assume without loss of generality that ψ is monic.
Replacing ψ(x) by ψ(x) −ψ(0), we may further assume that ψ(0) = 0. By
the assumption, there exists α ∈Fm(q) and k ∈Z such that σk(α) ̸= α and
ψ(σk(α)) = ψ(α). Since ψ(x) ∈Fq[x], the latter implies σk(ψ(α)) = ψ(α). Thus
ψ(α) ∈Fqgcd(k,m). Since σk(α) ̸= α, k is not a multiple of m. This implies that
Fqgcd(k,m) is a proper subﬁeld of Fqm. Therefore, there exists a divisor d > 1 of
m such that ψ(α) ∈Fqm/d. By Lemma 5, we have
m1 ≥[Fq(α) : Fq(ψ(α))]
≥[Fqm : Fqm/d]
= d.
Since m1 is the smallest prime divisor of m, we obtain m1 = d. This forces
Fq(ψ(α)) = Fqm/m1 , and hence ψ(α) ∈Fm/m1(q).
(iii) =⇒(iv). Suppose α ∈Fm(q), c1, . . . , cm1−1 ∈Fq, and
c0 = αm1 +
m1−1

i=1
ciαi ∈Fm/m1(q).
Deﬁne
f(x) = xm1 +
m1−1

i=1
cixi −c0 ∈Fqm/m1[x].
Then f(x) −f(0) ∈Fq[x] and f(0) = −c0 ∈Fm/m1(q). We claim f(x) is irre-
ducible in Fqm/m1[x]. Indeed, since f(α) = 0, f(x) is divisible by the min-
imal polynomial of α over Fqm/m1. On the other hand, since Fqm/m1(α) ⊃
Fq(α) = Fqm, the minimal polynomial of α over Fqm/m1 has degree at least
[Fqm : Fqm/m1] = m1 = deg f. Therefore, f(x) is the minimal polynomial of α
over Fqm/m1, and hence is irreducible Fqm/m1[x].
(iv) =⇒(i). Deﬁne
k = m
m1
,
ϕ(x, y) = (f(x) −f(0))y ∈Fq[x, y].

A Note on the Brawley-Carlitz Theorem on Irreducibility
91
Then, degx ϕ = m1, degy ϕ = 1. Let α be a root of f(x). Since f(0) = −(f(α) −
f(0)) ∈Fq(α), we have Fq(α) = Fq(f(0), α) = Fqm/m1(α) = Fqm. Thus α ∈
Fm(q). Moreover, for an arbitrary β ∈Fn(q), we have
ϕ(σk(α), β) = σk(f(α) −f(0))β
= −σk(f(0))β
= −f(0)β
= (f(α) −f(0))β
= ϕ(α, β).
Proposition 10 shows that hypotheses 0 < degx ϕ < m1 and 0 < degy ϕ <
n1 in Theorem 9 are best possible, provided that any of the four equivalent
conditions are satisﬁed. We conjecture that this is always the case.
Conjecture 1. Let q be a prime power, and let k, l be positive integers. Then
there exists a monic irreducible polynomial f(x) ∈Fqk[x] of degree l such that
f(x) −f(0) ∈Fq[x] and f(0) ∈Fk(q).
Note that Conjecture 1 is slightly stronger than Proposition 10(iv) in the sense
that l is not necessarily the smallest prime divisor of kl.
Conjecture 2. Let p be a prime, and let k, l be positive integers. Then there
exists a monic irreducible polynomial f(x) ∈Fpk[x] of degree l such that f(x) −
f(0) ∈Fp[x] and f(0) ∈Fk(p).
Clearly, validity of Conjecture 1 for all prime power q implies that of Con-
jecture 2. Conversely, suppose that Conjecture 2 is true. Let q = pr, where p is a
prime. Then there exists a monic irreducible polynomial f(x) ∈Fprk[x] of degree
l such that f(x)−f(0) ∈Fp[x] and f(0) ∈Frk(p). In particular, f(x) is a monic
irreducible polynomial in Fqk[x] of degree l such that f(x) −f(0) ∈Fq[x] and
f(0) ∈Fk(q) by (2). Therefore, the two conjectures are equivalent.
The existence problem of a monic irreducible polynomial of two prescribed
coeﬃcients dates back to Carlitz [2]. See [4, Part II, Sect. 3.5] for more recent
work. Conjecture 2 is a similar but diﬀerent problem, in the sense that all coef-
ﬁcients except the constant term are required to be in the prime ﬁeld.
Conjecture 2 is trivially true for l = 1 or k = 1. Moreover, it is true for the
following special cases:
Proposition 11. Conjecture 2 is true if l = p.
Proof. It is known (see for example [2]) that there exists a ∈Fk(p) such that
TrFpk (a) = 1. Then, by [3, Corollary 3.79], xl −x −a is irreducible in Fpk[x].
Proposition 12. Let l be a positive integer each of whose prime factor divides
pk−1. Assume further that, pk ≡1 (mod 4) if l ≡0 (mod 4). Then Conjecture 2
is true.

92
A. Munemasa and H. Nakamura
Proof. Let a be a primitive element of Fpk. Then xl −a is irreducible in Fpk[x]
by [3, Theorem 3.75].
By Propositions 11 and 12, Conjecture 2 is true for l = 2, or l = 3 and k even.
We have veriﬁed Conjecture 2 for pkl ≤1020 by computer.
References
1. Brawley, J.V., Carlitz, L.: Irreducibles and the composed product for polynomials
over a ﬁnite ﬁeld. Discret. Math. 65, 115–139 (1987)
2. Carlitz, L.: A theorem of Dickson on irreducible polynomials. Proc. Am. Math. Soc.
3, 693–700 (1952)
3. Lidl, R., Niederreiter, H.: Finite Fields. Cambridge University Press, Cambridge
(1997)
4. Mullen, G.L., Panario, D.: Handbook of Finite Fields. CRC Press, Boca Raton
(2013)
5. Stichtenoth, H.: A note on composed products of polynomials over ﬁnite ﬁelds. Des.
Codes Cryptogr. 73, 27–32 (2014)

Invited Talk II

On Arcs and Quadrics
Simeon Ball(B)
Departament de Matem`atiques, Universitat Polit`ecnica de Catalunya,
Jordi Girona 1-3, M`odul C3, Campus Nord, 08034 Barcelona, Spain
simeon@ma4.upc.edu
Abstract. An arc is a set of points of the (k−1)-dimensional projective
space over the ﬁnite ﬁeld with q elements Fq, in which every k-subset
spans the space. In this article, we ﬁrstly review Glynn’s construction of
large arcs which are contained in the intersection of quadrics. Then, for
q odd, we construct a series of matrices Fn, where n is a non-negative
integer and n ⩽|G| −k −1, which depend on a small arc G. We prove
that if G can be extended to a large arc S of size q + 2k −|G| + n −2
then, for each vector v of weight three in the column space of Fn, there
is a quadric ψv containing S \ G. This theorem is then used to deduce
conditions for the existence of quadrics containing all the vectors of S.
2010 Mathematics Subject Classiﬁcation: 51E21 · 15A03 · 94B05 ·
05B35
1
Introduction
Let PGk−1(Fq) denote the (k −1)-dimensional projective space over Fq, the
ﬁnite ﬁeld with q elements. For any homogeneous polynomials f1, . . . , fr in k
variables, let V (f1, . . . , fr) denote the points of PGk−1(Fq) which are zeros of
all the polynomials f1, . . . , fr.
An arc of PGk−1(Fq) is a set S of points of PGk−1(Fq) with the property that
every k-subset spans PGk−1(Fq). The set of columns of a generator matrix of
a k-dimensional linear maximum distance separable (MDS) code over Fq (when
viewed as points in the corresponding projective space) is an arc of PGk−1(Fq)
and vice-versa, so arcs and linear MDS codes are equivalent objects.
In [3], the author recently detailed a possible method to construct large arcs
from small arcs. An alternative method to construct large arcs from small arcs as
the intersection of the quadrics containing the small arc, was proposed by Glynn
in [7]. In this note we ﬁrstly review Glynn’s construction, then try and prove
some kind of converse of Glynn’s construction. We will construct a matrix from a
small arc and show that for each vector of weight three in the column space of the
matrix, there is a quadric containing the large arc to which the small arc extends.
The author acknowledges the support of the project MTM2014-54745-P of the Span-
ish Ministerio de Econom´ıa y Competitividad.
This article is for the proceedings of the International Workshop on the Arithmetic
of Finite Fields WAIFI 2016, held in Ghent, Belgium, July 13–15, 2016.
c
⃝Springer International Publishing AG 2016
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 95–102, 2016.
DOI: 10.1007/978-3-319-55227-9 8

96
S. Ball
The largest known arcs are of size q + 1, unless k ⩾q + 1, in which case the
largest arcs have size k + 1, or k = 3 or q −1 and q is even, in which case they
have size q + 2. Moreover, if k ⩽3 or k ⩾q −1 then it is a simple matter to
prove that there are no arcs larger than these largest known arcs.
The MDS conjecture, proposed as a question by Segre [9], is the following.
Conjecture 1.1. If 4 ⩽k ⩽q −2 then an arc of PGk−1(Fq) has size at most
q + 1.
The MDS conjecture was proven for q prime in [1]. For q non-prime and k ⩽
2p −2, where p is the prime for which q is a p-th power, the MDS conjecture
was proven in [2]. As a consequence of these results and Tables 3.1, 3.2, 3.3, 3.4
and 3.7 from [8], we have that the MDS conjecture is true for all q ⩽27 and for
all k ⩽7, with the possible exceptions of (k, q) = (6, 81) and (k, q) = (7, 81).
For q odd and k ⩽q, the largest known arcs have size q + 1.
The normal rational curve,
S = {(1, t, . . . , tk−1) | t ∈Fq} ∪{(0, . . . , 0, 1)}
is an arc of size q + 1 in PGk−1(Fq), for all k ⩽q.
Observe that S is contained the intersection of quadrics V (φij), where
φij(x) = xixj −xi+1xj−1,
and 1 ⩽i ⩽j−2 and 3 ⩽j ⩽k. These quadratic forms span a
k−1
2

-dimensional
subspace of the vector space P2, whose non-zero elements are the homogeneous
polynomials of degree two.
The Glynn arc [6],
S = {(1, t, t2 + ηt6, t3, t4) | t ∈Fq} ∪{(0, . . . , 0, 1)}
is an arc of size 10 in PG4(F9), where η is ﬁxed and satisﬁes η4 = −1.
As observed in [7], S is contained the intersection of quadrics,
ηx2
2 + x2
4 −x3x5,
x3x4 −ηx1x2 −x2x5,
x2x4 −x1x5,
x2x3 −x1x4 −ηx4x5,
x2
2 + ηx2
4 −x1x3.
These quadrics span a 5-dimensional subspace of the vector space P2.
2
Glynn’s Construction of Arcs as Intersection
of Quadrics
Recall that P2 denotes the vector space whose non-zero elements are the homoge-
neous polynomials in k variables of degree 2. The space P2 is a
k+1
2

-dimensional
vector space over Fq and a typical element of P2 is
ψ(x) = a1x2
1 + · · · + akx2
k +

i,j
bijxixj,
where the sum runs over i and j such that 1 ⩽i < j ⩽k.

On Arcs and Quadrics
97
For any subspace U of P2, we denote by V (U) the set of points of PGk−1(Fq)
which are zeros of ψ, for all ψ ∈U.
As we have seen in the introduction, the normal rational curve is contained
(in fact equal to) V (U) for some
k−1
2

-dimensional subspace U in which every
polynomial is irreducible. The following theorem is Theorem 3.1 from [6] and is
a partial converse of this. Glynn goes on to conjecture that not only is V (U) an
arc, under the hypothesis, but is in fact a normal rational curve.
Theorem 2.1. Let U be a
k−1
2

-dimensional subspace of P2. If every polyno-
mial in U is irreducible and V (U) spans PGk−1(Fq) then V (U) is an arc of
PGk−1(Fq).
Proof. Suppose that V (U) is not an arc. Then there is a point u of V (U) which
is dependent on r ⩽k −1 points of V (U), say e1, . . . , er. Since V (U) spans the
space, there are points er+1, . . . , ek of V (U) such that e1, . . . , ek span PGk−1(Fq).
With respect to a suitable basis we can assume that ei are the unit vectors, for
i = 1, . . . , k and u = (u1, . . . , uk−1, 0), where uiuj ̸= 0 for some i ̸= j.
Let π be the hyperplane of PGk−1(Fq) spanned by e1, . . . , ek−1. The vector
space of quadrics restricted to the hyperplane π has dimension
k
2

and the
subspace of this vector space of the quadrics which contains e1, . . . , ek−1 and
u has dimension
k
2

−k =
1
2k(k −3). Since U has dimension
1
2k(k −3) + 1
there must be two quadrics ψ1 and ψ2 in U whose restriction to π is the same.
Therefore, ψ1 −ψ2 factorises into two linear forms, one of whose kernels is π, a
contradiction.
⊓⊔
Given an arc G of PGk−1(Fq), we deﬁne
QS(G) = {ψ ∈P2 | ψ(x) = 0, for all x ∈G},
a subspace of P2.
The following theorem is Theorem 3.2(i) from [7].
Theorem 2.2. If G is an arc of PGk−1(Fq) of size 2k −1 then V (QS(G)) is
arc of PGk−1(Fq) containing G.
Proof. With respect to a suitable basis we can assume that G contains the unit
vectors e1, . . . , ek and the points (1, yℓ2, . . . , yℓk) for ℓ= 1, . . . , k −1. Quadrics
in the subspace QS(G) are of the form
ψ(x) =

i,j
bijxixj,
where
(yℓ2, . . . , yℓk, yℓ2yℓ3, . . . , yℓ,k−2yℓ,k−1) · (b12, . . . , b1k, b23, . . . , bk−1,k) = 0.
for all ℓ= 1, . . . , k −2. Here, · denotes the standard inner product of vectors.
Since G is an arc, this system of equations has rank k−2 and so the dimension of
QS(G) is
k+1
2

−(2k −1) =
k−1
2

. Since G ⊆V (QS(G)), the points V (QS(G))
span PGk−1(Fq), so Theorem 2.1 applies.
⊓⊔

98
S. Ball
The following theorem is Theorem 3.2(ii) from [7].
Theorem 2.3. If G is an arc of PGk−1(Fq) of size at most 2k −2 then G does
not extend to a larger arc within V (QS(G)).
Proof. As in the proof of Theorem 2.2, each point of G imposes a condition
on the quadrics in QS(G). Hence, the dimension of QS(G) is
k+1
2

−|G|. Any
point of V (QS(G)) \ G which extends G to a larger arc would impose a further
condition on QS(G), thus implying that its dimension is smaller than it is.
⊓⊔
Observe that if we take a larger arc G, of size 2k or 2k + 1 say, then QS(G)
will, in general, get smaller and then V (QS(G)) larger. We will not then have
that V (QS(G)) is necessarily an arc. However, we should be able to ﬁnd a larger
arc extending G within V (QS(G)). Alternatively, we can take a subspace U of
QS(G). Although Theorem 2.1 will not apply, so we cannot conclude that V (U)
is an arc, it may be that there is a large arc containing G contained in V (U). This
is precisely what happens if we take 9 points G of Glynn arc, as described in the
previous section. The subspace of quadrics QS(G) is a 6-dimensional subspace
and it contains a ﬁve dimensional subspace U such that the Glynn arc of size 10
is contained in V (U). Observe that for the subspace U spanned the ﬁve quadrics
detailed in the previous section, V (U) also contains the point (0, 0, 1, 0, 0), so is
not an arc itself.
3
Small Arcs Which Extend to Large Arcs
Although Theorem 3.4, Theorem 3.5 and Theorem 3.6 have not explicitly
appeared before, the results in this section are based on the articles [3–5].
Let Vk(Fq) denote the k-dimensional vector space over Fq.
Let det(v1, . . . , vk) denote the determinant of the matrix whose i-th row is
vi, a vector of Vk(Fq). If C = {p1, . . . , pk−1} is an ordered set of k −1 vectors
then we write
det(u, C) = det(u, p1, . . . , pk−1),
where we evaluate the determinant with respect to a ﬁxed canonical basis.
Throughout this section S will be an arbitrarily ordered arc of size q+k−1−t
of Vk(Fq). In other words, we will consider S as a set of vectors of Vk(Fq), as
opposed to a set of points of PGk−1(Fq).
For each (k −1)-subset C of S, there is a non-zero element αC ∈Fq, such
that the following lemma holds, see [4, Lemma 2.2].
Lemma 3.1. Suppose that q is odd. Let E be a subset of S of size k +t−1. For
any subset D of E of size k −3,

αC

z∈(E∪{x})\C
det(z, C)−1 = 0,
where the sum runs over the subsets C of E of size k −1 containing D, for all
x ∈S \ E.

On Arcs and Quadrics
99
Let G be an arc of Vk(Fq) and let n ⩽|G| + 1 −k be a non-negative integer.
We deﬁne a matrix Fn whose rows are indexed by the (k −1)-subsets of G. The
columns of Fn are indexed by pairs (D, E), where D is a subset of E of size k−3
and E is a subset of G of size |G| −n. The (C, (D, E)) entry of Fn is

u∈G\E
det(u, C),
if D ⊂C ⊂E and zero otherwise.
Let v(x) be the row vector whose coordinates are indexed by the (k −1)-
subsets C of G and whose C entry is
αC det(x, C)−1

z∈G\C
det(z, C)−1.
Note that all the coordinates in v(x) are non-zero.
Lemma 3.2. If G extends to an arc S of size q+2k+n−|G|−2 then v(x)Fn = 0
for all x ∈S \ G.
Proof. The (D, E) coordinate in the vector v(x)Fn is

αC det(x, C)−1

z∈G\C
det(z, C)−1

u∈G\E
det(u, C),
where the sum runs over the (k−1)-subsets C with the property that D ⊂C ⊂E.
By Lemma 3.1, this sum is zero.
⊓⊔
Lemma 3.2 allows us to prove various theorems depending on vectors appearing
in the column space of Fn.
Theorem 3.3. If there is a vector w of weight one in the column space of Fn
then G cannot be extended to an arc of size q + 2k + n −|G| −2.
Proof. Suppose G extends to an arc of size q + 2k + n −|G| −2. By Lemma 3.2,
v(x) · w = 0, where · denotes the standard inner product of vectors. Since w
has weight one, this equation implies that one of the coordinates of v(x) is zero,
which it is not.
⊓⊔
Theorem 3.4. If there is a vector w of weight two in the column space of Fn and
|G| < 1
2(q+k+n−1) then G cannot be extended to an arc of size q+2k+n−|G|−2.
Proof. Suppose G extends to an arc S of size q+2k+n−|G|−2. By Lemma 3.2,
v(x) · w = 0, where · denotes the standard inner product of vectors. Since w has
weight two, there are two (k −1)-subsets C1 and C2 of G such that
β1 det(x, C1)−1 + β2 det(x, C2)−1 = 0,

100
S. Ball
for some β1, β2 ∈Fq, for all x ∈S \ G. This implies that all the vectors of S \ G
are in the kernel of the linear form
α(x) = β1 det(x, C2) + β2 det(x, C1).
Note that α is not zero since C1 and C2 do not span the same hyperplane
of Vk(Fq). Since the kernel of a linear form is a hyperplane and a hyperplane
of Vk(Fq) contains at most k −1 vectors of an arc of Vk(Fq), we have that
|S \ G| ⩽k −1. Therefore,
q + 2k + n −|G| −2 −|G| ⩽k −1,
contradicting the hypothesis on the size of G.
⊓⊔
Theorem 3.5. Suppose G can be extended to an arc S of size q+2k+n−|G|−2.
For each vector w of weight three in the column space of Fn there is a quadratic
form ψw such that S \ G ⊆V (ψw).
Proof. By Lemma 3.2, v(x) · w = 0, where · denotes the standard inner product
of vectors. Since w has weight three, there are three (k −1)-subsets C1, C2 and
C3 of G such that
β1 det(x, C1)−1 + β2 det(x, C2)−1 + β3 det(x, C3)−1 = 0,
for some β1, β2, β3 ∈Fq, for all x ∈S \ G.
This implies that
S \ G ⊆V (ψw),
where
ψw(x) = β1 det(x, C2) det(x, C3) + β2 det(x, C1) det(x, C3) + β3 det(x, C1) det(x, C2).
⊓⊔
Theorem 3.6. Let S be an arc of Vk(Fq) of size q + k −t −1 and suppose
that C1, C2, C3 are (k −1)-subsets of S with the property that no element of
C1 ∪C2 ∪C3 is in exactly one of the Ci, for some i = 1, 2, 3. Suppose that there
is a 2-subset T of S such that for each x ∈S \ (T ∪C1 ∪C2 ∪C3), there is a
subset G of S \ (T ∪{x}) with the property that there is a vector with support
{C1, C2, C3} in the column space of Fn(G), where n = |G| −k −t + 1. Then
S ⊆V (ψ),
for some quadratic form
ψ(x)=β1 det(x, C2) det(x, C3)+β2 det(x, C1) det(x, C3)+β3 det(x, C1) det(x, C2),
where β1, β2, β3 are non-zero elements of Fq.

On Arcs and Quadrics
101
Proof. For each x ∈S \(T ∪C1 ∪C2 ∪C3), there is, by hypothesis, a subset G of
S \ (T ∪{x}) such that Theorem 3.5 implies the existence of non-zero elements
β1, β2, β3 of Fq (possibly dependent on G which is dependent on x) such that
T ∪{x} ⊆V (ψ),
where
ψ(X) = β1 det(X, C2) det(X, C3)+β2 det(X, C1) det(X, C3)+β3 det(X, C1) det(X, C2).
Since ψ(a) = 0 and ψ(b) = 0 where T = {a, b}, the elements β1, β2, β3 are
determined (up to scalar factor) by T. Therefore, they do not depend on x and
we have that S \ (C1 ∪C2 ∪C3) ⊆V (ψ).
By hypothesis, C1, C2, C3 are (k −1)-subsets of S with the property that no
element of C1 ∪C2 ∪C3 is in exactly one of the Ci, for some i = 1, 2, 3. Hence,
C1 ∪C2 ∪C3 ⊆V (ψ).
⊓⊔
The following example is essentially what is used to classify arcs of Vk(Fq) of
size q + 1, for k ⩽p and k ⩽1
2(q −1) in [1]. Recall, p is the prime for which q is
a p-th power.
Example 3.7. Let S be an arc of Vk(Fq) of size q + 1, where k ⩽p and k ⩽
1
2(q −1). Let K be a subset of S of size k and suppose Ci = K \ {ei}, for
i = 1, 2, 3, for any e1, e2, e3 ∈K. Then F1(G) contains a vector with support
{C1, C2, C3}, for all (2k−2)-subsets G of S containing K. Since 2k−2 ⩽|S|−3,
we can ﬁx a 2-subset T of S and choose G to be a subset of S \ (T ∪{x}). Then
Theorem 3.6 implies that
S ⊆V (ψ),
where, with respect to the basis K of Vk(Fq),
ψ(x) = β1x2x3 + β2x1x3 + β3x1x2,
for some β1, β2, β3, non-zero elements of Fq. As proven in [1], this is suﬃcient to
prove that S (when viewed as points in the corresponding projective space) is a
normal rational curve.
References
1. Ball, S.: On sets of vectors of a ﬁnite vector space in which every subset of basis
size is a basis. J. Eur. Math. Soc. 14, 733–748 (2012)
2. Ball, S., De Beule, J.: On sets of vectors of a ﬁnite vector space in which every
subset of basis size is a basis II. Des. Codes Cryptogr. 65, 5–14 (2012)
3. Ball, S.: Extending small arcs to large arcs. arXiv:1603.05795 (2016)
4. Ball, S., De Beule, J.: On subsets of the normal rational curve. arXiv:1603.06714
(2016)
5. Chowdhury, A.: Inclusion matrices and the MDS conjecture. arXiv:1511.03623v2
(2015)

102
S. Ball
6. Glynn, D.G.: The non-classical 10-arc of PG(4, 9). Discret. Math. 59, 43–51 (1986)
7. Glynn, D.G.: On the construction of arcs using quadrics. Austral. J. Combin. 9,
3–19 (1994)
8. Hirschfeld, J.W.P., Storme, L.: The packing problem in statistics, coding theory and
ﬁnite projective spaces: update 2001. In: Blokhuis, A., Hirschfeld, J.W.P., Jung-
nickel, D., Thas, J.A. (eds.) Finite Geometries. Developments in Mathematics, vol.
3, pp. 201–246. Springer, Heidelberg (2001). doi:10.1007/978-1-4613-0283-4 13
9. Segre, B.: Introduction to Galois geometries. Atti Accad. Naz. Lincei Mem. 8, 133–
236 (1967)

Applications to Cryptography

A Generalised Successive Resultants Algorithm
James H. Davenport1, Christophe Petit2, and Benjamin Pring1(B)
1 University of Bath, Bath BA2 7AY, UK
{J.H.Davenport,b.i.pring}@bath.ac.uk
2 University of Oxford, Oxford OX2 6GG, UK
Christophe.Petit@maths.ox.ac.uk
Abstract. The Successive Resultants Algorithm (SRA) is a root-ﬁnding
algorithm for polynomials over Fpn and was introduced at ANTS in
2014 [19]. The algorithm is eﬃcient when the characteristic p is small and
n > 1. In this paper, we abstract the core SRA algorithm to arbitrary
ﬁnite ﬁelds and present three instantiations of our general algorithm,
one of which is novel and makes use of a series of isogenies derived from
elliptic curves with suﬃciently smooth order.
Keywords: Root ﬁnding · Finite ﬁelds · Algorithms · Elliptic curves
1
Introduction
The factorization of polynomials over ﬁnite ﬁelds is an important problem in
computer algebra, both from theoretical and practical points of view [11]. An
important subcase of this problem is the root-ﬁnding problem, which given a
polynomial over a ﬁnite ﬁeld, asks for one, several or all roots of this polynomial
over the ﬁeld. It is well-known that factoring polynomials is deterministically
reducible to root-ﬁnding [3], so in this paper we will mostly focus on the root-
ﬁnding problem.
1.1
Finding Roots of Polynomials over Finite Fields
From now on in this paper, let Fpn be a ﬁnite ﬁeld of size pn and f a polynomial
of degree d with coeﬃcients in Fpn. As it is often the case in the literature, we
will assume that f is entirely split over Fpn and that it has no repeated roots.
One can reduce the general case to this one by computing gcd(f(x), xqn −x),
for example using a variant of the square and multiply algorithm [10]. We allow
the notation x and f(x) to denote the variable and polynomial in Fpn[x] with
ˆx ∈Fpn and f(ˆx) to represent the evaluation of the polynomial f at ˆx.
Since the seminal work of Berlekamp in the seventies [3], the root-ﬁnding
problem can be solved in probabilistic polynomial time (in the degree of f and in
n log p). Signiﬁcant practical and theoretical improvements have been made since
then, with the current best probabilistic algorithm for the general factorization
of a polynomial being due to Kedlaya and Umans [16]. In practice, one will often
c
⃝Springer International Publishing AG 2016
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 105–124, 2016.
DOI: 10.1007/978-3-319-55227-9 9

106
J.H. Davenport et al.
use either Berlekamp’s trace algorithm [3] or Cantor-Zassenhaus algorithm [5],
depending on the parameters.
Berlekamp’s trace algorithm in fact provides a polynomial time reduction
from the root-ﬁnding problem over Fpn to the root-ﬁnding problem over Fp. The
reduction can be made deterministic, leading to a polynomial time deterministic
algorithm for ﬁelds of small characteristic.
In contrast, Shoup’s algorithm [23] is still the best unconditional determinis-
tic algorithm over Fp today, with a complexity in ˜O(d2√p). Designing a deter-
ministic polynomial time algorithm in that setting is an important open prob-
lem, even in the case of degree 2 polynomials. Evdokimov has provided a quasi-
polynomial time algorithm when a quadratic non-residue is provided together
with the ﬁeld as an input to the algorithm [8]. Under the Generalised Riemann
Hypothesis (GRH), this element can be computed in polynomial time, removing
the need for an extra input. Polynomial time algorithms have also been suggested
under additional assumptions on the polynomial [21], other conjectures [1,9] or
for speciﬁc families of primes [2,21,24], still under GRH.
In 2014, Petit introduced a new algorithm in the small characteristic case,
called the Successive Resultants Algorithm [19].
1.2
Our Contributions
In this paper, we introduce a generalisation of the Successive Resultants Algo-
rithm to arbitrary ﬁnite ﬁelds. Our generalisation covers both the original SRA
algorithm for ﬁnite ﬁelds Fpn with small characteristic and the generalised Gra-
eﬀe transform approach of Grenet et al. [12] when pn −1 is smooth. We also
present a third instance using an elliptic curve with smooth order over Fpn,
leading to a new algorithm of independent interest.
Our initial observation is that the linearized polynomials used in SRA can
be replaced by any set of polynomials, and in fact even rational maps Ki, such
that the image of the composed map Kt ◦Kt−1 ◦. . . ◦K2 ◦K1 under a restricted
domain is suﬃciently small. Similar generalisations were made in diﬀerent con-
texts in [20].
Like the original SRA, our generalisation reduces the root-ﬁnding problem for
large degree polynomials to the same problem for “small” degree polynomials.
The original SRA has two stages, a resultant stage and a gcd stage. We show
how to adapt both stages to the case of arbitrary rational maps, and how to
overcome the technical diﬃculties introduced by the denominators of the maps.
Recently, De Feo, Petit and Quisquater showed that the Successive Resul-
tants Algorithm and Berlekamp’s celebrated Trace Algorithm (BTA) [3] are in
a certain sense dual of each other [18]. We remark that the generalised Graeﬀe
transform algorithm mentioned above can similarly be seen as a dual of Shoup’s
algorithm when p −1 is smooth [24], and our new algorithm as a dual of a slight
variant of an algorithm due to Ronyai [21, Sect. 7] (See Table 1).
In the algorithm of Sect. 3.3, we have used Icart’s embeddings [15] to map
Fp elements to the x-coordinates of Fp-rational points of a smooth order elliptic
curve over Fp, where Ronyai’s algorithm would map them to a smooth curve

A Generalised Successive Resultants Algorithm
107
Table 1. Special instances of SRA and corresponding “dual” algorithms
p small pn −1 smooth Elliptic curves
Resultant-based [19]
[12]
Section 3
GCD-based
[3]
[24]
[21, Sect. 4]
over Fp2. Our approach has some eﬃciency advantages and more importantly it
leads to a larger set of suitable parameters in the algorithm.
We remark that all our algorithms can be made deterministic for certain
parameters after some precomputation dependent upon the ﬁeld and assuming
the Generalised Riemann Hypothesis. These deterministic versions can be seen in
the continuity of [2,21,24], providing polynomial time deterministic algorithms
under GRH for special ﬁelds.
Proof of concept code in SageMath [7] for all three instantiations may be
found at https://www.github.com/bip20/SRA.
2
A Generalised Form of the Successive Resultants
Algorithm
The Successive Resultants Algorithm (SRA) is a root ﬁnding algorithm which
exploits the properties of an ordered set of rational mappings in order to extract
roots by computing the roots of polynomials of small degree. As explained in
the introduction, we will be considering the problem of ﬁnding the roots of a
polynomial f ∈Fpn[x] whose splitting ﬁeld is Fpn.
The generation of the rational maps is a key factor in the eﬃciency and
utility of the SRA algorithm. These maps may be considered as input to the
algorithm and the existence of a useful set of maps currently depends upon the
structure of Fpn. We note that the rational maps are independent of f and may
be performed as precomputation.
Given a polynomial f of degree d and a sequence of rational maps K1, . . . , Kt
the SRA algorithm involves computing ﬁnite sequences of length j ≤t + 1
obtained by successively transforming the roots of f by application of the rational
maps. In other words, the sequences (x1, . . . , xj) of length 1 to t + 1 fulﬁlling

f(x1)
= 0
Ki(xi) = ai(xi)
bi(xi)
= xi+1
for i = 1, . . . , j
(1)
where Ki : Fpn \ Ni →Fpn, Ni := {xi ∈Fpn : bi(xi) = 0} and ai, bi ∈Fpn[X]
such that gcd(ai(xi), bi(xi)) is trivial.
We deﬁne the composed map
K[j](x1) : Fpn \ N [j] →Fpn
(2)
K[j](x1) = Kj ◦. . . ◦K0(x1)

108
J.H. Davenport et al.
where N [j] := {x1 ∈Fpn : ∀i ∈{1, . . . , j} Ki ◦. . .◦K1(x1) /∈Ni}. For notation
purposes, we take K[0] to be the identity map IdFpn : Fpn →Fpn and N [0] = ∅.
Ideally, we will want a minimal number of rational maps of small degree with
the property that Image(K[t]) is small. These points will improve the eﬃciency
of the algorithm, as will become clear later in the paper.
The SRA algorithm consists of two separate stages, the Resultant Stage
and
the
GCD
stage.
In
the
Resultant
stage,
a
series
of
polynomials
f (1)(x1), . . . , f (t)(xt) are computed with f (i+1)(xi+1) relying on f (i)(xi) and
Ki(xi). The roots of f (i)(xi) lying in Fpn correspond to the existence of a
sequence (x1, . . . , xj) with the root as the ith value in the sequence. In the GCD
stage, roots of f (i+1)(xi+1) are used to ﬁnd the roots of f (i)(xi) by computing
roots of polynomials whose degree is constrained by the Ki maps.
Theorem 1. Given the maps Ki : Fpn \ Ni →Fpn for i = 1, . . . , t we have
that each distinct root of f (1)(x1) produces a unique sequence (x1, . . . , xj) where
j ≤t + 1, obtained by computing Ki(xi) := xi+1 while xi /∈Ni.
Proof. This may be seen by successively applying the maps Ki to each root. If
for some j ∈{1, . . . , t} we have that Kj−1 ◦. . .◦K0(x1) ∈Nj, then the sequence
is of length j. Otherwise the sequence is of length t + 1. The sequence is unique
for any distinct root of f (1)(x1) by the fact that the root is the ﬁrst value in any
sequence.
⊓⊔
2.1
The Resultant Stage
We will use the basic result that the resultant possesses the property that for
f, g ∈Fpn[x] we have that Resx(f(x), g(x)) = 0 if and only if the polynomials
f(x) and g(x) share a common factor in Fpn[x]. The resultant of two polyno-
mials f, g ∈Fpn[x] may be calculated via naively taking the determinant of the
Sylvester matrix of f and g or a more specialised method depending upon the
structure of the Kj maps. We will use the standard result [17, Deﬁnition 1.93]
that
Resx(f, g) = lc(f)deg(g)

x:f(x)=0
g(x)
(3)
where the roots are taken over the splitting ﬁeld of f and lc(f) is the leading
coeﬃcient of f.
We will use the resultant on polynomials in two variables xi, xi+1, with
respect to the xi variable to create a series of univariate polynomials,
f (i+1)(xi+1), whose roots correspond to a non-empty subset of roots of f (i)(xi).
In the Resultant stage we clear the denominator of the Ki rational function
representation of the map and successively compute resultants of the result-
ing equation and the previously computed polynomial with respect to the vari-
able xi, deﬁning f (1)(x1) := f(x1) as the ﬁrst such polynomial. This results
in the generation of an ordered list of polynomials f (1)(x1), . . . , f (t)(xt) via the
procedure

A Generalised Successive Resultants Algorithm
109

f (1)(x1)
:= f(x1)
f (i+1)(xi+1)
:= Resxi(f (j)(xi), ai(xi) −bi(xi) · xi+1) for i = 1, . . . , t −1
(4)
The roots of the resulting sequence of polynomials f (1), . . . , f (t) encode the
potential values any xi may take for the sequences described in Theorem 1.
Theorem 2. The polynomials f (1), . . . , f (t) have the following properties:
(i) If f (1) splits over Fpn then all f (i) split over Fpn.
(ii) The degree of any f (i+1) is less than or equal to the degree of f (i).
(iii) The degree of f (i+1) is strictly less than the degree of f (i) if and only if the
gcd of f (i) and bi is non-trivial.
Proof. We have that by formula (3), that
f (i+1)(xi+1) = Resxi(f (i)(xi), ai(xi) −bi(xi) · xi+1)
(5)
= lc(f (i))deg(ai(xi)−bi(xi)·xi+1)

xi:f (i)(xi)=0
(ai(xi) −bi(xi) · xi+1)
For (i) we note that for any polynomials ai, bi ∈Fpn[x] and ˆxi ∈Fpn we have
that ai(ˆxi), bi(ˆxi) ∈Fpn. For (ii) & (iii) as f (i) splits over Fpn it is clear that
the degree of f (i+1)(xi+1) ≤d with equality holding if and only if bi(xi) and
f (i)(xi) share no roots in Fpn.
⊓⊔
We note that in the case of polynomial maps, we have that deg(f (i)) = d as
bi(xi) = 1 and therefore possesses no roots.
Theorem 3. If f (1)(x1) splits over Fpn then the union of all ith values for valid
sequences (x1, . . . , xj) as produced in Theorem 1 is equal to the set of roots of
each f (i)(xi).
Proof. We use induction to prove the result. As f (1) splits over Fpn, we have
that the roots of f (1)(x1) comprise exactly the ﬁrst values of the sequences as
we have deﬁned f (1)(x1) := f(x1). Assuming that the set of roots of f (i) is equal
to the set of possible xi sequence values, we have that, by the computation of
the resultant and Eq. (5), the roots of f (i+1)(xi+1) are those values such that
f (i)(xi) = 0 and ai(xi) −bi(xi) · xi+1 = 0. If xi ∈Ni then by the product
equation of the resultant as in (5) we have that if bi(xi) = 0, there is no root of
f (i+1)(xi+1) corresponding to a solution of ai(xi) −bi(xi) · xi+1 = 0. If xi /∈Ni,
we have that bi(xi) ̸= 0 and so the root xi+1 satisﬁes both f (i)(xi) = 0 and
ai(xi)
bi(xi) = xi+1 and is therefore the corresponding point in a sequence.
⊓⊔
We note that if some f (i) does not split over Fpn then if xi is a root of an
irreducible factor of f (i) in the splitting ﬁeld of f (i) we have the potential for
f (i)(xi) = 0 and ai(xi) −bi(xi) · xi+1 = 0 with xi+1 ∈Fpn. This would lead to
sequences of the form (xi+1, . . . , xj), but as we assume that f (i) splits over Fpn
we have that all f (i) split over Fpn by Theorem 1.

110
J.H. Davenport et al.
Theorem 4. The roots of f (i) lie in the image of K[i−1].
Proof. By the property of the resultant, the roots of f (i)(xi) possess the property
that ai−1(xi−1)
bi−1(xi−1) = xi. This successively constrains the potential values that the
roots of each f (i)(xi) may take.
⊓⊔
By Theorem 4, we have that by sensible choice of the Ki maps, we may obtain
a small set which contains our potential xt+1 values. This will be useful in the
GCD stage.
It is clear that as the roots are successively constrained by Theorem 4, the
sequences may be considered as a series of trees of depth j ≤t + 1 with the ˆxj
forming the root nodes and the distinct subsets of the roots of f corresponding to
sequences of length j forming the leaves. The SRA algorithm may be considered
as a means of generating this tree with relation to the Ki rational maps by ﬁrst
encoding the information concerning the nodes at each level with the Resultant
stage and then computing the root and children nodes with the GCD stage.
2.2
The GCD Stage
In the GCD stage, the f (1), . . . , f (t) polynomials computed by the Resultant
stage to are used to locate the ﬁnal values of all sequences (x1, . . . , xj) as created
by the procedure in Theorem 1. Once we have the ﬁnal value, we recursively
determine the sequence by application of the gcd algorithm and by iteratively
computing roots of polynomials, whose degree is bounded by the degree of the
Ki maps. Once we have obtained the ﬁrst value in all sequences, we naturally
have found the roots of f (1)(x1) = f(x1).
Theorem 5. Given any ˆxi+1 ∈Fpn which forms part of a sequence as computed
by successive application of the Ki maps on the roots of f, we may compute all
ith values of sequences which possess ˆxi+1 as the i + 1th value.
Proof. If ˆxi+1 ∈Fpn is such that there exists a sequence (x1, . . . , xi, ˆxi+1, . . . , ˆxj)
we have that all values of xi such that Ki(xi) = ai(xi)
bi(xi) = ˆxi+1 are contained in
the roots of f (i)(xi) by Theorem 3. As Resxi(f (i)(xi), ai(xi) −bi(xi) · ˆxi+1) = 0,
we have that
g(i)
ˆxi+1(xi) := gcd(f (i)(xi), ai(xi) −bi(xi) · ˆxi+1)
(6)
is non-trivial and as f (i)(xi) is split over Fpn, we have that (6) is a product of
linear factors whose roots are exactly those such that f (i)(xi) = 0 and Ki(xi) =
ai(xi)
bi(xi) = ˆxi+1. We may therefore extract all xi values whose next value in the
sequence is ˆxi+1 by ﬁnding the roots of a split polynomial of degree bounded by
deg g(i)
ˆxi+1 ≤max{deg ai, deg bi}.
⊓⊔

A Generalised Successive Resultants Algorithm
111
Theorem 6. (i) We may detect that there exists a sequence (ˆx1, . . . , ˆxj) of
length j < t + 1 and may compute ˆxj ∈Fpn by computing the roots of a
polynomial of degree no larger than deg bj.
(ii) Given Image(K[t]) we may detect that there exists a sequence (ˆx1, . . . , ˆxt+1)
of length t + 1 and its ﬁnal value ˆxt+1 ∈Fpn by computing the roots of
|Image(K[t])| polynomials of degree no larger than max{deg at, deg bt}.
Proof. (i) If a sequence is of length j < t + 1, then xj ∈Nj. If this is the case,
then it is detected by observing that deg f (j+1) < deg f (j) as in Theorem 2. As
xj ∈Nj, we have that bj(xj) = 0 and f (j)(xj) = 0, so we may compute
g(j)(xj) := gcd(f (j)(xj), bj(xj))
(7)
whose degree is ≤deg bj and whose roots are the ﬁnal values of all sequences of
length j. For sequences of length t there will be no indication of degree drop and
so we must compute g(t)(xt). For (ii), in the case where a sequence of length
t+1 exists, we have by Theorem 4 that the potential values of xt lie in the roots
of f (t)(xt) and that bt(xt) ̸= 0. The xt for which Kt(xt) = at(xt)
bt(xt) = ˆxt+1 may
therefore be extracted by computing the roots of
g(t)
ˆxt+1(xt) := gcd(f (t)(xt), at(xt) −bt(xt) · ˆxt+1)
(8)
for each ˆxt+1 ∈Image(K[t]). In the case where no such sequence exists for a
chosen ˆxi+1 then by Theorem 4 we have that (8) is trivial.
⊓⊔
Taken together with a sensible choice of mappings to constrain each
|Image(K[i])| for i = 1, . . . , t, Theorems 4, 5 and 6 allow us to ﬁnd the length
and ﬁnal value of all sequences. For sequences of length j < t + 1, we may use
Theorem 4, whilst for sequences of length t+1 Theorem 5 constrains the possible
values which xt+1 may take. Ideally, we will wish Image(K[t]) to contain only
one element.
We note that SRA may also be used to explicity extract roots possessing
certain properties. The algorithm may speciﬁcally pick out only roots corre-
sponding to sequences of speciﬁc length or roots which intersect with K[j]−1(B)
for B ⊆Image(K[j]).
Together the Resultant stage and the GCD stage give us the generalised
SRA.
2.3
Generic Complexity Analysis
We allow the notation that h(n) is O(g(n)) if there exists some C ∈R and N ∈N
such that for all n ≥N we have that |h(n)| ≤C|g(n)|. We also make use of the
notation that h(n) is ˜O(g(n)) if h(n) is O(g(n) logc g(n)). Complexity is given
in terms of basic operations in Fp. The cost of these operations is O(log p) for
addition, O((log p)2) for multiplication and inversion with classical arithmetic
or ˜O(log p) for addition, multiplication and ˜O((log p)2) for exponentiation with
fast FFT-style arithmetic, such as via the Sch¨onhage-Strassen algorithm [10].

112
J.H. Davenport et al.
Algorithm 1. The generalised Successive Resultants Algorithm
Data: f ∈Fpn[x]
– the polynomial whose roots we wish to ﬁnd
a1
b1 , . . . , at
bt
– a set of rational maps
B ⊆Fpn
– a set of points contained in Image(K[t])
ParSeq ∈{T, F}
– whether to extract roots not in K[t]−1(Fpn)
Result:
The roots of f in K[t]−1(B) and optionally all roots not in K[t]−1(Fpn).
begin
f (1)(x1) ←−f(x1)
for i = 1, . . . , t −1 do
f (i+1)(xi+1) ←−Resultantxi(f (i)(xi), ai(xi) −bi(xi) · xi+1)
CandidateRoots ←−B
for i = t, . . . , 1 do
TempRoots ←−{}
for y ∈CandidateRoots do
gy(xi) ←−gcd(f (t)(xi), ai(xi) −bi(xi) · y)
TempRoots ←−TempRoots ∪Roots(gy(xi))
if PartialSeq and (i < t and deg(f (i+1)) < deg(f (i)) or i == t) then
gb(xi) ←−gcd(f (i)(xi), bi(xi))
TempRoots ←−TempRoots ∪Roots(gb(xi))
CandidateRoots ←−TempRoots
return CandidateRoots
We write a(n) and m(n) to represent the cost of addition and multiplica-
tion over Fpn. We let A(d), M(d) and G(d) respectively represent the cost of
performing the addition, multiplication and taking the gcd of two polynomials
of degree d in Fpn[x]. We allow R(d) to be the cost of computing the resultant
of two polynomials in Fpn[y][x] with respect to x where the maximum degree of
either polynomials in x is d and the maximum degree of y is 1. We represent the
cost of ﬁnding the roots in Fpn of a degree d polynomial to be P(d).
The following table summarises the cost of performing these with regard
to Fpn in terms of basic operations over Fp [10]. We provide a cost for P(d)
in terms of the Berlekamp Trace Algorithm, though other methods including
standard formulae for quadratics, cubics and quartics may be used (Table 2).
Table 2. Cost of operations over Fpn in terms of basic operations over Fp.
a(n)
m(n)
A(d)
M(d)
G(d)
R(d)
P(d)
Classical O(n) O(n2) O(dn) O(d2n2) O(d2n2 log d) O(d3n2 log d) O(d2n3)
Fast
O(n)
˜O(n)
O(dn)
˜O(dn)
˜O(dn)
˜O(d2n))
˜O(dn2)
We assume that we are attempting to ﬁnd the roots of the polynomial
f ∈Fpn[x] of degree d such that f possesses d distinct roots, all deﬁned over

A Generalised Successive Resultants Algorithm
113
Fpn. Whilst the complexity of the SRA algorithm depends upon the choice of
Ki rational maps, we may assume there are t maps and that these have been
provided by a precomputation. We assume that the maximum degree of any
ai, bi ∈Fpn[x] is B, that |Image(K[t])| = L and that d ≥max{B, L}. Comput-
ing purely the linear factors of a polynomial of degree d may be done at a cost
of O(m(n)M(d) log d log(pnd)) operations in Fp [10]. We also assume that the
maps Ki have been precomputed and exclude this cost.
We have that the resultant stage will consist of taking t resultants of bivariate
polynomials where the maximum degree of x is d and the degree of y is always 1.
After noting if deg f (i) < deg f (i+1), we may compute the square-free part by a
cost bounded by O(M(n) log d) - this cost is overwhelmed by the computation
of the ﬁrst resultant. We therefore have that the resultant stage generically costs
O(td3n2 log d) with classical arithmetic or ˜O(td2n) with fast arithmetic.
Each of the t steps in the GCD consists of taking a maximum of d gcds
of maximum degree d resulting in polynomials of degree bounded by B which
require solving. At any stage, at most
d
2 of these will be of degree ≥2 and
will require solving. This results in a total cost of O(td3n2 log d + tdP(B)) for
classical arithmetic and ˜O(td2n + tdP(B)) for fast arithmetic.
We therefore have the generic cost of SRA is O(td3n2 log d + tdP(B)) with
classical arithmetic or ˜O(td2n + tdP(B)) with fast arithmetic. As the f (i) are
square-free, we may obtain the linear factors by using equal-degree splitting
for a cost of O(m(n)M(B) log d log(pnB)). This gives us a total complexity
cost of ˜O(td3n2 + tBd3n5) for classical arithmetic or ˜O(td2n + tBd2n3) with
fast arithmetic. We note that optimized versions of the separate stages may be
constructed by exploiting the structure of the Ki maps for speciﬁc instantiations
of SRA [13,19].
3
Instantiations of SRA
In this section we present three instantiations of our generalised SRA algorithm.
We ﬁrst show how the original SRA algorithm ﬁts into our generalised version.
We then present an algorithm for eﬃciently determining the roots of a polyno-
mial f ∈Fp[x] when p −1 is smooth; this algorithm is equivalent to the one
in [12]. We conclude with a description of a method to transform polynomials
with roots in F∗
p into a polynomial whose roots correspond to x-coordinates of an
elliptic curve deﬁned over Fp when p = 2 mod 3. This method demonstrates a
procedure with which we can exploit the structure of Fp to generate the required
rational maps. Proof of concept code written in SageMath [7] for all three cases
may be found at https://github.com/bip20/SRA.
3.1
SRA over Fpn with p Small
In this section we show how the original SRA algorithm ﬁts into the framework
of our generalised algorithm. The original SRA algorithm was designed for exten-
sion ﬁelds Fpn. It uses n polynomial maps Ki of degree p, hence the algorithm

114
J.H. Davenport et al.
is only eﬃcient for small characteristic ﬁelds. The polynomials Ki are chosen
as follows. For any {v1, . . . , vn} a basis of Fpn over Fp, we deﬁne the system of
linearized polynomials

L0(z)
= z
Li(z)
= 
i∈Fp Li−1(z −ivi)
for i = 1, . . . , n
(9)
The system
Ki(xi) = xp
i −cixi = xi+1
for i = 1, . . . , n
(10)
may be derived from system (9) by means of the setting xi = Li(z) and the ci
may be precomputed for a cost of O(n4) with classical arithmetic or ˜O(n3) with
fast arithmetic.
From system (9) it may be deduced that Image(K[n]) = {0} ⊂Fpn and we
may call the SRA algorithm as described in Algorithm 2 with the precomputed
Ki polynomials and B = {0}. As the maps are polynomials, all sequences will
be of full length, so there is no need to check for partial sequences.
A straight forward application of the SRA algorithm as described in Sect. 2
would lead to a cost of ˜O(d3n3 + pd3n6) with classical arithmetic and ˜O(d2n2 +
pd2n4) for fast arithmetic. The algorithm possesses several optimizations for
both the Resultant stage and the GCD stage which utilise the structure of the
polynomial maps (10), fast arithmetic, multipoint evaluation and reuse calcula-
tions. This leads to a cost of O(d2n3) with classical arithmetic or ˜O(dn2) with
fast arithmetic excluding the precomputation of the ci values [19]. These opti-
mizations have allowed it outperform traditional algorithms such as Berlekamp’s
Trace Algorithm for certain parameters [19].
3.2
SRA Maps for F∗
p of Smooth Order
In this section we explore the use of SRA in the ﬁeld Fp where |F∗
p| is smooth. This
algorithm is equivalent to one based on Generalised Graeﬀe transforms [12,13].
Deﬁnition 1. For any integer n we will denote the smoothness function
S : N −→N by S(n) = max{p : p is a prime factor of n}.
We say that an integer n ∈N is B-smooth if S(n) ≤B.
We will assume that f ∈Fp[x] is of degree d and that f splits over Fp and is
square-free. From Fermat’s little theorem we have that xp−1 −1 = 0 for x ∈F∗
p.
As we have that p−1 = n1 · · · nt we exploit this structure to create the following
system of maps
Ki(xi) = xni
i
= xi+1
for i = 1, . . . , t
(11)
with K[t](x1) = Kt ◦· · · ◦K1(x1) = xn1···nt
1
= xp−1
1
and Image(K[t]) = {0, 1}.
We may therefore use the Ki maps and {0, 1} as input to the SRA algorithm.
As with the original SRA, the maps are polynomials and so all sequences will
be of length t + 1.

A Generalised Successive Resultants Algorithm
115
An Optimized Resultant Stage. We may assume that t ≤log p and that
B = S(p−1). A straightforward adaptation of the algorithm would cost O(Bd3)
with classical arithmetic or ˜O(Bd2) with fast arithmetic.
After checking whether 0 is a root of f, we may use an improved method of
computing the resultant which requires the precomputation of a root of unity.
Full details of procedure is described in [13, Sect. 2.5]. This method replaces
taking each resultant and is based upon the result that
f (i+1)(xi+1) : = Resxi(f (i)(xi), xni
i
−xi+1)
(12)
f (i+1)(xni
i+1) =

k∈{1,...,ni}
f (i)(ζk
nixi+1)
where ζni is an nith root of unity. After computing f (i+1)(xni
i+1) this way and
shifting the coeﬃcients to obtain f (i+1)(xi+1) the total cost of taking each resul-
tant costs O(d log p log B) with fast arithmetic. The optimisation proposed in
[13, Sect. 2.5] results in a total cost for the Resultant stage of ˜O(d log2 p log B)
with fast arithmetic.
Complexity Analysis. We assume that we wish to ﬁnd the roots of a polyno-
mial f ∈Fp[x] of degree d lying in Fp and that S(p−1) = B. Using the standard
GCD stage and the optimized resultant gives us a complexity of ˜O(d2B2 +Bd3)
with classical arithmetic and ˜O(d log2 p + d log2 pB) with fast arithmetic and
the improvements from [13]. We note that the algorithm of [13] also utilises an
improved equivalent to the GCD stage and their algorithm is more eﬃcient, with
a total complexity ˜O(B
1
2 d log2 p) for certain parameters.
3.3
SRA Map in Conjunction with Hashing to an Elliptic Curve
We now generalise the previous instance by working with the group of ratio-
nal points of an elliptic curve over Fp instead of the multiplicative group F∗
p.
This generalisation is analogous to Lenstra’s generalisation of Pollard’s p −1
factorization method as the elliptic curve factorization method.
We assume that the ﬁeld Fp is provided with an elliptic curve Ea,b (in reduced
Weierstass coordinates Y 2 = X2 + aX + b) of smooth order N = t
i=1 ni over
Fp and a sequence of isogenies ϕi : Ei →Ei+1, where E1 = Ea,b and ϕi has
degree ni. It is well-known that ϕi can be deﬁned as ϕi(x, y) =

ξi(x)
ψ2
i (x), y ωi(x)
ψ3
i (x)

where ξi, ωi, ψi are polynomials [28]. From this data we deﬁne the rational maps
Ki : Fp →Fp : x →ξi(x)
ψ2
i (x). The composition map K[t](x) = Kt ◦. . . ◦K1 clearly
maps to inﬁnity all Fp elements that are the x-coordinate of some P ∈Ea,b(Fp).
By Hasse’s theorem, this set covers roughly half of the elements in Fp [25].
Applying the SRA algorithm with those maps on f, we would not be able to
separate roots that are not the x-coordinates of a point in E. At this point, one
could try to split the remaining factor g by applying SRA again on g(x −α), for
α randomly chosen in Fp. This algorithm, somehow reminiscent of Berlekamp’s
trace algorithm, would probably work well in practice but it is not clear how it

116
J.H. Davenport et al.
could be rigorously analyzed. An alternative approach would be to assume that
E has a smooth order over Fp2 instead of a smooth order over Fp. This approach
would be more satisfactory from a theoretical point of view but it would also
put more severe restrictions on the set of parameters, requiring that the curve
order is smooth over Fp2 instead of Fp. This is essentially the approach taken by
Ronyai [21] for a diﬀerent algorithm.
In this paper, we use recent progress on hashing into elliptic curves [15]
to solve this problem in a diﬀerent way, which moreover ﬁts nicely within our
generalised SRA framework. We ﬁrst recall the following results from Icart [15].
Lemma 1 [15]. Let p = 2 mod 3 be an odd prime. For any z ∈Fp, there is a
unique cube root of z deﬁned over Fp, which we write z1/3. For any a, b ∈Fp
let Ea,b be the elliptic curve deﬁned by the equation y2 = x3 + ax + b. The map
fa,b : Fp →Ea,b sending 0 to the point at inﬁnity and u ∈F∗
p to (x, y) ∈Ea,b(Fp)
where
x =

v2 −b −u6
27
 1
3 + u6
3 ,
y = ux + v,
v = 3a −u4
6u
,
(13)
is a well-deﬁned surjective map. Reciprocally, if P = (x, y) is a point on the curve
Ea,b, then the solutions us of fa,b(us) = P are the solutions of the polynomial
equation u4 −6u2x + 6uy −3a = 0.
The map fa,b deﬁned in Lemma 1 is in fact an algebraic map as z1/3 = z(2p−1)/3.
Let Ka,b : Fp →Fp, where
u →

v2 −b −u6
27
 1
3 + u6
3
(14)
be the composition of fa,b with a projection on the x-coordinate of the curve.
Lemma 1 implies that the modiﬁed composition map K′(x) = Kt ◦. . .◦K1 ◦Ka,b
maps all Fp elements to inﬁnity. However, the degree of Ka,b is prohibitively
large to run SRA eﬃciently. We therefore modify our algorithm as follows.
In the ﬁrst resultant step instead of computing Resu(f(u), x −Ka,b(u)), we
compute
f (1)(x) = Resu(f(u), ˜Ka,b(u, x))
where
˜Ka,b(u, x) := (u4 −6u2x −3a)2 −36u2(x3 + ax + b).
Note that deg f (1) = 3 deg f as ˜Ka,b has degree 3 with respect to variable x. In
fact, for every root u of f the three values
ξi
v2 −b −u6
27
 1
3 + u6
3 ,
i = 1, 2, 3,
where ξ is a primitive cube root of unity, are roots of the polynomial f (1).
Since only one value in each triple is deﬁned over Fp, one can eliminate the
other “parasitic” roots by replacing f (1)(x) by gcd(f (1)(x), xp −x) at this stage.

A Generalised Successive Resultants Algorithm
117
Alternatively, one can just ignore this issue and work with bigger polynomials,
and eventually the SRA algorithm will only produce Fp roots anyway. The choice
of computing a gcd or not may depend on the parameters; we will not explore
this further here.
After this conversion is completed we may call the original SRA algorithm
to ﬁnd the roots of f (1)(x) via the rational maps derived from the isogenies.
As we know that the composed map of isogenies maps all elements in Ea,b(Fp)
to the point at inﬁnity, we know that all roots of f (1)(x) will result in partial
sequences. Therefore we do not have to calculate or supply SRA with the set of
points in the image of K[t]. Once the roots are returned from the SRA algorithm,
we compute the potential corresponding y coordinates on Ea,b(Fp) for each root
x and use the ﬁnal equation from Lemma 1 to recover the roots by taking gcds
with our original polynomial.
We conclude the section with a comment on the existence and computation
of suitable parameters for this variant of SRA. The existence of a curve of order
N over Fp is equivalent to the existence of an integer solution to the equation
(N + 1 −p)2 −Df 2 = 4N
with D < 0 (see [4, Eq. 4.3]). Once this solution is known, the curve can be
constructed using the complex multiplication algorithm [4, p. 30] provided that
the reduced discriminant D is small enough. Finally, computing small degree
isogenies can be done eﬃciently with V´elu’s formulae [27]. In order to ﬁnd suit-
able parameters for the algorithm of this section, one can therefore for example
ﬁrst ﬁx D small, then choose N randomly among a set of numbers of the desired
smoothness, and ﬁnally solve the above equation for p and f using Cornacchia’s
algorithm [6].
Algorithm 2. SRA in conjunction with Icart’s map
Data:
f ∈Fp[u]
– the polynomial whose roots we wish to ﬁnd
M := { a1
b1 , . . . , at
bt }
– rational map representation of the isogenies
a, b ∈Fp
– description the smooth order curve Ea,b
Result: The roots of f
begin
f (1)(x1) ←−Resu(f(u), (u4 −6u2x1 −3a)2 −36u2(x3
1 + ax1 + b))
f (1)(x1) ←−gcd(f (1)(x1), xp
1 −x1)
UnconvertedRoots ←−SRA(f (1)(x1), M, {}, True)
Roots ←−{}
for x1 ∈UnconvertedRoots do
y1 ←−Sqrt(x3
1 + ax + b)
y2 ←−−y1
Roots ←−Roots ∪gcd(f(u), u4 −6u2x1 + 6uy1 −3a)
Roots ←−Roots ∪gcd(f(u), u4 −6u2x1 + 6uy2 −3a)
return Roots

118
J.H. Davenport et al.
Complexity Analysis. The ﬁrst step requires that we take one resultant of
two bivariate polynomials, where the degree of u is d and the degree of x1 is
3. We must then normalise the resulting polynomial f (1)(x1) by removing the
irreducible factors. This step costs O(dM(d) log d + M(d) log p) to compute the
resultant and take the gcd using a square-and-multiply algorithm. SRA is called
with f (1) and the rational maps derived from the isogenies. There will be a max-
imum of ⌈log p⌉rational maps with their degree bounded by the smoothness of
|Ea,b| and denoted B. Finally the roots must be converted back, costing O(G(d)).
We therefore have the total complexity of the algorithm is ˜O(d2 log p+Bd3) with
classical arithmetic and ˜O(d log p + Bd2) with fast arithmetic.
4
Conclusions and Open Problems
In this paper, we provided a framework to extend the Successive Resultants
Algorithm of [19] to arbitrary ﬁnite ﬁelds. As it stands we have three sets of
maps for which the SRA algorithm works in an eﬃcient manner. The maps for
SRA in the p = 2 mod 3 case exploit the structure of the rational map frame-
work introduced in Sect. 2 and additionally require Icart’s map to transform the
polynomial before converting our solutions back into roots of our original poly-
nomial. We believe that the creation of suitable maps for speciﬁc ﬁnite ﬁelds
exploiting the structure of the rational map framework remains an interesting
open problem.
We remark that the SRA algorithm may be used to solve the problem
of deterministic root ﬁnding for polynomials in Fp[x] under the Generalised
Riemann Hypothesis (GRH), which gives us the result that ﬁnding a genera-
tor of may be done in time O(ln6 p). Provided with such a generator, we may
use deterministic algorithms to ﬁnd square roots [22,26] and cubic roots [14]
allowing us to exploit the standard formula for ﬁnding roots of quadratic, cubic
and quartic equations. As long as max{deg ai, deg bi} ≤4, we may therefore use
SRA in a deterministic manner.
Given the various ways that the algorithm may operate, in terms of choosing
either to include elements which produce partial sequences or not and restriction
of the input B ⊆Image(K[t]) to contain speciﬁc elements, there also exists the
possibility of using SRA to extract only roots with speciﬁc properties as deﬁned
by the Ki maps.
Acknowledgements. Christophe Petit is supported by a GCHQ research grant and
Benjamin Pring is supported by an EPSRC doctoral research grant. The authors would
like to thank the anonymous reviewers both for their time and for their helpful advice,
much of which was incorporated into the ﬁnal paper.
A
Example of SRA with |F∗
p| Smooth
We demonstrate the p −1 instantiation of SRA with a toy example. We use the
ﬁnite ﬁeld F37, where 36 = 2 · 2 · 3 · 3 is 3-smooth. Precomputation for F37 gives
us the series of rational maps (in fact polynomials)

A Generalised Successive Resultants Algorithm
119
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
K1(x1)
= x2
1 = x2
K2(x2)
= x2
2 = x3
K3(x3)
= x3
3 = x4
K4(x4)
= x3
4 = x5
(15)
The composed map is K[4](x1) = x36
1 , which gives us B = Image(K[t]) = {0, 1}.
We wish to ﬁnd the roots of
f(x) = x10 + 21x9 + 22x8 + 7x7 + 12x6 + 25x5 + 35x4 + 4x3 + 25x
(16)
We ﬁrst compute f (i+1)(xi+1) = Resxi(f (xi), xni
i
−xi+1) with f (1)(x1) = f(x1).
f (1)(x1) = x10
1 + 19x9
1 + 25x8
1 + 6x7
1 + 22x6
1 + 32x5
1 + 13x4
1 + 32x3
1 + 6x2
1 + 24x1
f (2)(x2) = x10
2 + 22x9
2 + 34x8
2 + 22x7
2 + 27x6
2 + 32x5
2 + 21x4
2 + x3
2 + 17x2
2 + 16x2
f (3)(x3) = x10
3 + 28x9
3 + 20x8
3 + 23x7
3 + 36x6
3 + 36x4
3 + 22x3
3 + 35x2
3 + 3x3
f (4)(x4) = x10
4 + 28x9
4 + 28x8
4 + 25x7
4 + 18x6
4 + 18x5
4 + 21x4
4 + 28x3
4 + 28x2
4 + 27x4
We then compute g(i)(xi) = gcd(f (i)(xi), xni
i
−ˆxi+1) for i = 4, 3, 2, 1, where
ˆx5 ∈B for i = 4 and ˆxi+1 is a root of g(i+1)(xi) for i = 3, 2, 1.
We will note the solutions of these polynomials to the right of each equation.
g(4)(x4) = gcd(f (4)(x4), x3
4 −0)
= x4
{0}
g(4)(x4) = gcd(f (4)(x4), x3
4 −1)
= x3
4 + 36
{1, 10, 26}
giving us the values for ˆx4 : {0, 1, 10, 26}. We use these roots to calculate
g(3)(x3) = gcd(f (3)(x3), x3
3 −0)
= x3,
{0}
g(3)(x3) = gcd(f (3)(x3), x3
3 −1)
= x3
3 −1,
{10}
g(3)(x3) = gcd(f (3)(x3), x3
3 −10)
= x2
3 + 9x3 + 7,
{7, 33, 34}
g(3)(x3) = gcd(f (3)(x3), x3
3 −26)
= x2
3 + 16x3 + 34,
{9, 12}
giving us the values for ˆx3 : {0, 7, 9, 10, 12, 33, 34}. We use these roots to calculate
g(2)(x2) = gcd(f (2)(x2), x2
2 −0)
= x2,
{0}
g(2)(x2) = gcd(f (2)(x2), x2
2 −7)
= x2 + 28,
{9}
g(2)(x2) = gcd(f (2)(x2), x2
2 −9)
= x2 + 34,
{3}
g(2)(x2) = gcd(f (2)(x2), x2
2 −10)
= x2 + 26,
{11}

120
J.H. Davenport et al.
g(2)(x2) = gcd(f (2)(x2), x2
2 −12)
= x2 + 30,
{7}
g(2)(x2) = gcd(f (2)(x2), x2
2 −33)
= x2 + 25,
{12}
g(2)(x2) = gcd(f (2)(x2), x2
2 −34)
= x2 + 16,
{21}
giving us the values for ˆx2 : {0, 3, 7, 9, 11, 12, 21}. We use these roots to calculate
g(1)(x1) = gcd(f (1), x2
1 −0)
= x1,
{0}
g(1)(x1) = gcd(f (1), x2
1 −3)
= x2
1 + 34,
{15, 22}
g(1)(x1) = gcd(f (1), x2
1 −7)
= x1 + 9,
{28}
g(1)(x1) = gcd(f (1), x2
1 −9)
= x1 + 34,
{3}
g(1)(x1) = gcd(f (1), x2
1 −11)
= x2
1 + 26,
{14, 23}
g(1)(x1) = gcd(f (1), x2
1 −12)
= x2
1 + 25,
{7, 30}
g(1)(x1) = gcd(f (1), x2
1 −21)
= x1 + 13,
{24}
whose union is the set of roots ˆx1 : {0, 3, 7, 14, 15, 22, 23, 24, 28, 30} which are the
roots of of our original polynomial f(x).
B
Example of SRA with p = 2 mod 3
We provide the toy example for the case of ﬁnding solutions for h(u) ∈F41[x],
which fulﬁls our initial condition that p = 41 = 2 mod 3.
We ﬁrst perform the precomputation stage for the given p. A value of N is
computed so that a large enough proportion of N is smooth and allows a suitable
curve to be constructed. We ﬁnd that N = 32 is a such a value and compute the
auxiliary curve
E1,0(F41) := {(x, y) ∈F41 × F41 : y2 = x3 + x}
(17)
whose rational points we will convert our points in F41 to via Icart’s map [15]
as in Eq. 18,
K0 : F41[u, x] →E1,0(F41)
(u, x) →−8u8 + 14u6x −u4x2 + u2x3 + 7u4 + 10
(18)
The ﬁnal step of the precomputation is to compute suitable elliptic curves and
successive isogenies between them such that their degree is bounded by our
smoothness bound. We will only use the rational map representations of the x-
coordinate for these maps. The following series of isogenies with their rational-
map representations of the mappings from x-coordinate to x-coordinates give
rise to the following system of equations

A Generalised Successive Resultants Algorithm
121
K1(x) : E1,0(Fp) →E37,0(Fp),
x2
1 + 1
x1
= x2
K2(x) : E37,0(Fp) →E38,11(Fp)
x2
2 −2x2 + 8
x2 −2
= x3
K3(x) : E38,11(Fp) →E25,8(Fp)
x2
3 + 12x3 + 19
x3 + 12
= x4
(19)
K4(x) : E25,8(Fp) →E34,7(Fp)
x2
4 + 17x4 −10
x4 + 17
= x5
K5(x) : E34,7(Fp) →E1,0(Fp)
x2
5 + 16x5 −18
x5 + 16
= x6
After this precomputation is completed, we may begin the process of calculating
the roots of h(u). We seek to ﬁnd the roots of the polynomial
h(u) = u5 + 19u4 + 6u3 + 37u2 + 38u + 30
(20)
We ﬁrst use the Icart map K0 to create our polynomial f (1)(x1), whose roots
represent solutions of both h(u) and K0(u, x) by means of taking the resultant
with regards to u.
f(x) = Resu(h(u), −8u8 + 14u6x −u4x2 + u2x3 + 7u4 + 10)
= 39x15 + x14 + 22x13 + 30x12 + 4x11 + 33x10 + 33x9
+ 32x8 + 9x7 + 4x6 + 33x5 + 40x4 + 12x3 + x + 2
(21)
we note that we now have a polynomial three times the degree of our original
one, but we are only interested in linear factors hence we may obtain
f(x) = gcd(xp −x, f (1)(x))
f(x) = x4 −15x3 −5x2 + 14x + 14
(22)
which is of degree bounded by deg(h). We then compute the roots of f using
the SRA algorithm with the maps M = {Ki}5
i=1, the set B = ∅and the ﬂag
ParSeq = True.
As described in the generic case of SRA, we now apply the resultant stage to
obtain our f (2)(x2), f (3)(x3), f (4)(x4), f (5)(x5) polynomials using the map struc-
ture we have derived from the rational maps of the isogenies as described in
system 19. To do this we successively compute
f (i+1)(x) = Resu(f (i)(xi), ai(xi) −x4 + 17 · xi+1)
for i = 1, . . . , t −1. (23)
This results in the series of polynomials
f (1)(x1) = x4
1 −15x3
1 −5x2
1 + 14x1 + 14
f (2)(x2) = 14x4
2 + 9x3
2 −13x2
2 −5x2 + 11
f (3)(x3) = −14x4
3 −4x3
3 −16x2
3 −13x3 −16
(24)
f (4)(x4) = −3x4
4 + 7x3
4 −x2
4 −11x4 + 11
f (5)(x5) = −2x4
5 −5x3
5 + 3x2
5 −9x5 + 5

122
J.H. Davenport et al.
We may then begin the gcd stage of the algorithm. We note that at each stage we
must repeatedly extract those values in the kernel as these values are not picked
up by the root merging process. Our ﬁrst set of roots is therefore calculated via
g(5)(x5) = gcd(−2x4
5 −5x3
5 + 3x2
5 −9x5 + 5, x5 + 16)
giving us the candidate roots ˆx5: {25}. We use this to compute the polynomial
g(4)(x4) = gcd(−3x4
4 + 7x3
4 −x2
4 −11x4 + 11, x2
4 + 17x4 −10 −(x4 + 17) · 25)
= x2
4 + 33x4 + 16
These give us ˆx4 : {4}. We perform the same procedure to compute
g(3)(x3) = gcd(−14x4
3 −4x3
3 −16x2
3 −13x3 −16, x2
3 + 12x3 + 19 −(x3 + 12) · 4)
= x2
3 + 8x3 + 12
Giving us the candidate solutions ˆx3 : {35, 39}. We perform the same procedure
to compute
g(2)(x2) = gcd(14x4
2 + 9x3
2 −13x2
2 −5x2 + 11, x2
2 −2x2 + 8 −(x2 −2) · 35)
= x2 + 9
g(2)(x2) = gcd(14x4
2 + 9x3
2 −13x2
2 −5x2 + 11, x2
2 −2x2 + 8 −(x2 −2) · 39)
= x2
2 + 4
Giving us the candidate solutions {32} and {18, 23} respectively. Finally we
compute
g(1)(x1) = gcd(x4
1 −15x3
1 −5x2
1 + 14x1 + 14, x2
1 + 1 −(x1) · 18))
= x1 + 21
g(1)(x1) = gcd(x4
1 −15x3
1 −5x2
1 + 14x1 + 14, x2
1 + 1 −(x1) · 23))
= x2
1 + 18x1 + 1
g(1)(x1) = gcd(x4
1 −15x3
1 −5x2
1 + 14x1 + 14, x2
1 + 1 −(x1) · 32))
= x1 + 28
Solving these provides us with solutions {20}, {2, 21}, {13} for f(x).
We then must convert these back into solutions for h(u). We now possess x-
coordinate solutions and may retrieve the corresponding y-coordinates via sub-
stitution of x into the auxiliary curve and taking square roots. These lead to the
solutions
(13, 18), (13, 23), (21, 4), (21, 37), (2, 16), (2, 25), (20, 5), (20, 36)
each of which we substitute into the precomputed map L(x, y) = u4 −6xu2 +
6uy −3 and take the gcd with h(u) to obtain the list of equations whose roots
are precisely those of h(u) (excluding 0, which may be specially checked for).

A Generalised Successive Resultants Algorithm
123
(13, 18)
1
{}
(13, 23)
u + 17
{24}
(21, 4)
1
{}
(21, 37)
u2 + 22u + 23
{34, 26}
(2, 16)
1
{}
(2, 25)
u + 1
{40}
(20, 5)
u + 20
{21}
(20, 36)
1
{}
The roots of h(u) are therefore {21, 24, 26, 34, 40}.
References
1. Arora, M., Ivanyos, G., Karpinski, M., Saxena, N.: Deterministic polynomial factor-
ing and association schemes. Electron. Colloq. Computat. Complex. 19, 68 (2012)
2. Bach, E., von zur Gathen, J., Lenstra, H.: Deterministic factorization of polynomi-
als over special ﬁnite ﬁelds. University of Wisconsin-Madison, Computer Sciences
Department (1988)
3. Berlekamp, E.: Factoring polynomials over large ﬁnite ﬁelds. Math. Comput. 111,
713–735 (1970)
4. Br¨oker, R.: Constructing elliptic curves of prescribed order. Ph.D. thesis, University
of Leiden (2006)
5. Cantor, D.G., Zassenhaus, H.: A new algorithm for factoring polynomials over
ﬁnite ﬁelds. Math. Comput. 36(154), 587–592 (1981)
6. Cornacchia, G.: Su di un metodo per la risoluzione in numeri interi dell’ equazione
n
h=0 chxn−hyh = p. Giornale di Matematiche di Battaglini 46, 33–90 (1903)
7. The Sage Developers: SageMath, the Sage Mathematics Software System (Version
6.8) (2015). http://www.sagemath.org
8. Evdokimov, S.: Factorization of polynomials over ﬁnite ﬁelds in subexponential
time under GRH. In: Adleman, L.M., Huang, M.-D. (eds.) ANTS 1994. LNCS,
vol. 877, pp. 209–219. Springer, Heidelberg (1994). doi:10.1007/3-540-58691-1 58
9. Gao, S.: On the deterministic complexity of factoring polynomials. J. Symb. Com-
put. 31, 19–36 (2001)
10. von zur Gathen, J., Gerhard, J.: Modern Computer Algebra. Cambridge University
Press, Cambridge (2013)
11. von zur Gathen, J., Panario, D.: Factoring polynomials over ﬁnite ﬁelds: a survey.
J. Symb. Comput. 31(1/2), 3–17 (2001)
12. Grenet, B., van der Hoeven, J., Lecerf, G.: Randomized root ﬁnding over ﬁnite
FFT-ﬁelds using tangent Graeﬀe transforms. In: Proceedings of ISSAC, pp. 197–
204. ACM (2015)
13. Grenet, B., van der Hoeven, J., Lecerf, G.: Deterministic root ﬁnding over ﬁnite
ﬁelds using Graeﬀe transforms. Appl. Algebra Eng. Commun. Comput. 27(3), 237–
257 (2016)
14. Harasawa, R., Sueyoshi, Y., Aichi, K.: Root computation in ﬁnite ﬁelds. IEICE
Trans. Fundam. Electron. Commun. Comput. Sci. 96(6), 1081–1087 (2013)

124
J.H. Davenport et al.
15. Icart, T.: How to hash into elliptic curves. In: Halevi, S. (ed.) CRYPTO
2009. LNCS, vol. 5677, pp. 303–316. Springer, Heidelberg (2009). doi:10.1007/
978-3-642-03356-8 18
16. Kedlaya, K.S., Umans, C.: Fast polynomial factorization and modular composition.
SIAM J. Comput. 40(6), 1767–1802 (2011)
17. Lidl, R., Niederreiter, H.: Finite Fields, vol. 20. Cambridge University Press,
Cambridge (1997)
18. De Feo, L., Petit, C., Quisquater, M.: Application of the aﬃne geometry of GF(qn)
to root ﬁnding. Poster presented at International Symposium on Symbolic and
Algebraic Computation (2015)
19. Petit, C.: Finding roots in GF(pn) with the successive resultant algorithm. LMS
J. Comput. Math. (Spec. Issue ANTS XI) 17A, 203–217 (2014)
20. Petit, C., Kosters, M., Messeng, A.: Algebraic approaches for the elliptic curve
discrete logarithm problem over prime ﬁelds. In: Cheng, C.-M., Chung, K.-M.,
Persiano, G., Yang, B.-Y. (eds.) PKC 2016. LNCS, vol. 9615, pp. 3–18. Springer,
Heidelberg (2016). doi:10.1007/978-3-662-49387-8 1
21. R´onyai, L.: Galois groups and factoring polynomials over ﬁnite ﬁelds. SIAM J.
Disc. Math. 5(3), 345–365 (1992)
22. Shanks, D.: Five number-theoretic algorithms. In: Proceedings of the Second Man-
itoba Conference on Numerical Mathematics, pp. 51–70 (1972)
23. Shoup, V.: On the deterministic complexity of factoring polynomials over ﬁnite
ﬁelds. Inf. Process. Lett. 33(5), 261–267 (1990)
24. Shoup, V.: Smoothness and factoring polynomials over ﬁnite ﬁelds. Inf. Process.
Lett. 38(1), 39–42 (1991)
25. Silverman, J.H.: Heights and elliptic curves. In: Cornell, G., Silverman, J.H. (eds.)
Arithmetic Geometry, pp. 253–265. Springer, Heidelberg (1986)
26. Tonelli, A.: Bemerkung ¨uber die Auﬂ¨osung quadratischer Congruenzen. Nachrichten
von der K¨onigl. Gesellschaft der Wissenschaften und der Georg-Augusts-Universit¨at
zu G¨ottingen 1891, pp. 344–346 (1891)
27. V´elu, J.: Isog´enies entre courbes elliptiques. Communications de l’Acad´emie royale
des Sciences de Paris. CR Acad. Sci. Paris S´er. AB 273, A238–A241 (1971)
28. Washington, L.C.: Elliptic Curves: Number Theory and Cryptography. CRC Press,
Boca Raton (2008)

Distribution and Polynomial Interpolation
of the Dodis-Yampolskiy Pseudo-Random
Function
Thierry Mefenza1,2(B) and Damien Vergnaud1
1 ENS, CNRS, INRIA, and PSL, Paris, France
mefenza@di.ens.fr
2 Department of Mathematics, University of Yaounde 1, Yaounde, Cameroon
Abstract. We give some theoretical support to the security of the cryp-
tographic pseudo-random function proposed by Dodis and Yampolskiy
in 2005. We study the distribution of the function values over general
ﬁnite ﬁelds and over elliptic curves deﬁned over prime ﬁnite ﬁelds. We
also prove lower bounds on the degree of polynomials interpolating the
values of these functions in these two settings.
Keywords: Dodis-Yampolskiy pseudo-random function · Discrepancy ·
Polynomial interpolation · Finite ﬁelds · Elliptic curves
1
Introduction
A cryptographic pseudo-random function family is a collection of functions
that can be evaluated in polynomial-time using a secret key but for which no
polynomial-time algorithm can distinguish (with signiﬁcant advantage) between
a function chosen randomly from the family and a truly random function (i.e.
whose outputs are sampled uniformly and independently at random). In 2005,
Dodis and Yampolskiy [DY05] proposed an eﬃcient pseudo-random function
family which takes inputs in {1, . . . , d} (for some parameter d ∈N) and outputs
an element in a group G (multiplicatively written) of prime order t with gen-
erator g. The secret key is a scalar x ∈Z∗
t and the pseudo-random function is
deﬁned by:
Vx : {1, . . . , d} −→G
m −→Vx(m) = g
1
x+m
if x + m ̸= 0 mod t and 1G otherwise.
The Dodis-Yampolskiy pseudo-random function family has found numerous
applications in cryptography (e.g., for compact e-cash [CHL05] or anonymous
authentication [CHK+06]). Dodis and Yampolskiy showed that their construc-
tion has some very attractive security properties, provided that some assumption
about the hardness of breaking the so-called Decision Diﬃe-Hellman Inversion
problem holds in G [DY05]. This assumption is non-standard and Cheon [Che10]
proved that it is stronger than the classical discrete logarithm assumption in G.
c
⃝Springer International Publishing AG 2016
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 125–140, 2016.
DOI: 10.1007/978-3-319-55227-9 10

126
T. Mefenza and D. Vergnaud
In practice, two interesting choices for the group G are a subgroup of the
multiplicative group of any ﬁnite ﬁeld (in particular, for the so-called veriﬁable
Dodis-Yampolskiy pseudo-random function in groups equipped with a bilin-
ear map [DY05]) or a subgroup of points of an elliptic curve deﬁned over a
prime ﬁnite ﬁeld. Very few results supporting the Decision Diﬃe-Hellman Inver-
sion assumption hardness were proven in these settings (contrary to the Naor-
Reingold pseudo-random function family [NR04] for which numerous results
are known, e.g. distribution [LSW14], linear complexity [GGI11] and non-linear
complexity [BGLS00]). This paper deals with the distribution of the Dodis-
Yampolskiy pseudo-random function over ﬁnite ﬁelds and over elliptic curves
and proves lower bounds on the degree of polynomials which interpolate these
functions.
Contributions of the Paper. As a ﬁrst contribution, we prove that for almost
all values of parameters, the Dodis-Yampolskiy pseudo-random function pro-
duces a uniformly distributed sequence. This simple result is based on some
recent bounds on character sums with exponential functions. Shparlinski [Shp11]
has obtained in 2011 an explicit bound for exponential sums with consecutive
modular roots over a prime ﬁnite ﬁeld. Ostafe and Shparlinski [OS11] obtained
an analoguous result for exponential sums over multiples of a point on an elliptic
curve deﬁned over a prime ﬁnite ﬁeld. Following the method from [Shp11], we
obtain readily a bound for such sums over any extension of a prime ﬁnite ﬁeld
(Proposition 1). This new bound allows us to give results on the distribution of
the Dodis-Yampolskiy pseudo-random functions over ﬁnite ﬁelds (Theorem 1).
We use the bounds from [OS11] to give results on the distribution of the Dodis-
Yampolskiy pseudo-random functions over elliptic curves (Theorem 2).
In order to break the security of the Dodis-Yampolskiy pseudo-random func-
tion, it would be suﬃcient to have a polynomial over a ﬁnite ﬁeld of low degree
which reveals information on the function values. From the known lower bounds
on the polynomial interpolation on the discrete logarithm in ﬁnite ﬁelds and
elliptic curves (e.g. [CS00,LW02,KW06]), one can prove that a low-degree uni-
variate polynomial cannot reveal the secret key x when evaluated at Vx(m) (for
some integer m ∈{1, . . . , d}) for all x. However, the security of the Dodis-
Yampolskiy pseudo-random function would also be broken if such low-degree
polynomial revealing a value Vx(m′) were proved to exist (for some integer
m′ ∈{1, . . . , d} \ {m} and many diﬀerent keys x). Our main contribution is
to prove lower bounds on the degree of polynomials interpolating the values of
these functions over ﬁnite ﬁelds (Theorem 3) and elliptic curves (Theorem 4 and
Theorem 5). These results can be regarded as ﬁrst complexity lower bounds on
the pseudo-randomness of the Dodis-Yampolskiy function families.
Both contributions are motivated by earlier results of the same ﬂavour on
the Naor-Reingold pseudo-random function family.
2
Auxiliary Results
In this section, we collect some statements about ﬁnite ﬁelds, exponential
sums over ﬁnite ﬁelds and elliptic curves. We provide explicit upper-bounds

Distribution and Polynomial Interpolation
127
for exponential sums with consecutive modular roots over a ﬁnite ﬁeld and for
analogous exponential sums over elliptic curves [Shp11,OS11]. The bound for
exponential sums with consecutive modular roots over a general ﬁnite ﬁeld is
easily derived from [Shp11] and may be of independent interest.
2.1
Finite Fields and Exponential Sums
Let p be an odd prime number. We denote Fq = Fpr the ﬁnite ﬁeld with q = pr
elements (r ≥1). For an integer t, denote by Zt the residue ring modulo t and by
Z∗
t the group of units of Zt. For an integer m > 0, we put em(z) = exp(2πiz/m).
Let g ∈F∗
pr of order t (with t | pr −1), and ψ be a non-trivial character of Fpr.
For a ∈F∗
pr and b ∈Zt, we deﬁne the sum:
Sa,b =

n∈Z∗
t
ψ(ag1/n)et(bn).
Throughout the paper, the notation U ≪V is equivalent to the inequality
|U| ≤cV with some constant c>0. In the following lemmas, the implied constants
in the symbols “≪” may occasionally depend on the integer parameters k, ℓand
are absolute otherwise.
In [BS08] Bourgain and Shparlinski proved, when r = 1, that for any ε >
0, there exists δ > 0 such that for t ≥pε, we have the bound Sa,b ≪t1−δ.
Shparlinski [Shp11] (Theorem 3.1) gave an explicit form of this result (again
when r = 1) for relatively large values of t; in the case t = p1+o(1), it takes the
form Sa,b ≪t127/128+o(1). Using Shparlinski’s methods, we generalize this bound
on Sa,b for any r ≥1 (see Appendix A for a proof which follows [Shp11]):
Proposition 1. For any integers k ≥2, ℓ≥1 we have for t ≥q1/2(log q)2:
Sa,b ≤t1−αk,ℓqβk,ℓ+o(1),
where αk,ℓ=
1
2(2k+ℓ) −
1
4kℓ
and
βk,ℓ=
1
4(2k+ℓ).
2.2
Elliptic Curves and Exponential Sums
We will also consider the setting of an elliptic curve E deﬁned over Fp (where p
is a prime number), that is a rational curve given by the following Weierstrass
equation y2 = x3+Ax+B with A, B ∈Fp and 4A3+27B2 ̸= 0. The set E(Fp) of
the points of the curve deﬁned over Fp (including the special point O at inﬁnity)
has a group structure (denoted additively) with an appropriate composition rule
where O is the neutral element. Given P a point of the curve E with prime
order ℓ(with ℓ| |E(Fp)|), we denote [n]P the scalar multiplication, i.e. in fact
the adding of the point P to itself n times (for n ≥0).
Let E be an elliptic curve and G ∈E(Fp) be a point of order t ≥1. For
a ∈F∗
p and b ∈Zt, we deﬁne the sum:
ˆSa,b =

n∈Z∗
t
ep

aX
 1
n

G

et(bn),
where X(P) denotes the abscissa of a point P ∈E(Fp).

128
T. Mefenza and D. Vergnaud
In [OS11, Theorem 6], Ostafe and Shparlinski obtained an upper-bound on
ˆSa,b (with H(X) = X−1 following the notation from [OS11]):
Proposition 2 [OS11]. For any integers k ≥2, ℓ≥1 we have for t ≥
q1/2(log q)2:
ˆSa,b ≤t1−αk,ℓpβk,ℓ+o(1),
where αk,ℓ=
1
2(4k+ℓ) −
1
4kℓ
and
βk,ℓ=
1
4(4k+ℓ).
2.3
Division Polynomials Over Elliptic Curves
In this section, we recall some basic facts on division polynomials of elliptic curves
(see [Was08,BSS99]). The division polynomials ψm(X, Y ) ∈Fp[X, Y ]/(Y 2−X3−
AX −B), m ≥0, are recursively deﬁned by:
ψ0 = 0
ψ1 = 1
ψ2 = 2Y
ψ3 = 3X4 + 6AX2 + 12BX −A2
ψ4 = 4Y (X6 + 5AX4 + 20BX3 −5A2X2 −4ABX −8B2 −A3)
ψ2m+1 = ψm + 2ψ3
m −ψm−1ψ3
m+1,
m ≥2
ψ2m = ψm(ψm+2ψ2
m−1 −ψm−2ψ2
m+1)/ψ2,
m ≥3,
where ψm is an abbreviation for ψm(X, Y ). If m is odd, then ψm(X, Y ) ∈Fp[X]
is univariate and if m is even then ψm(X, Y ) ∈2Y Fp[X]. Therefore, we have
ψ2
m(X, Y ) ∈Fp[X] and ψm−1(X, Y )ψm+1(X, Y ) ∈Fp[X]. In particular, we may
write ψ2m+1(X) and ψ2
m(X).
The division polynomials can be used to calculate multiples of a point on
the elliptic curve E. Let P = (x, y) ∈E with P ̸= O, then the abscissa of [m]P
is given by θm(x)/ψ2
m(x) where θm(X) = Xψ2
m −ψm−1ψm+1. The zeros of the
denominator ψ2
m(X) are exactly the ﬁrst coordinates of the non-trivial m-torsion
points, i.e., the points Q = (x, y) ∈Fp
2 \ {O} on E with [m]Q = O. Note, that
these points occur in pairs Q = (x, y) and −Q = (x, −y), which coincide only if
2Q = O, i.e., if x is a zero of ψ2
2(X).
We recall that the group of m-torsion points E[m], for an elliptic curve E
deﬁned over a ﬁeld of characteristic p, is isomorphic to (Z/mZ)2 if p ∤m and
to a proper subgroup of (Z/mZ)2 if p | m. If m is a power of p then E[m] is
either isomorphic to (Z/mZ) or to {O}. Accordingly, the degree of ψ2
m(X) is
m2 −1 if p ∤m and strictly less than m2 −1 otherwise. In particular, for p = 2
and m a power of 2 we have deg(ψ2
m) = m −1 if E is not supersingular and
deg(ψ2
m) = 0 otherwise. By induction one can show that θm(X) ∈Fp[X] is monic
of degree m2.

Distribution and Polynomial Interpolation
129
3
Distribution of the Dodis-Yampolskiy Pseudo-Random
Functions
For a real z, we use the notation e(z) = exp(2πiz). For a sequence of N points
Γ = (γ0,n, . . . , γs−1,n)n∈{1,...,N} in the s-dimensional unit cube, we denote its
discrepancy by DΓ :
DΓ =
sup
B⊆[0,1)s

TΓ (B)
N
−|B|
 ,
where TΓ (B) denotes the number of points of the sequence Γ in a box B (i.e. a
polyhedron [α0, β0)×· · ·×[αs−1, βs−1) ⊆[0, 1)s) of volume |B| and the supremum
is taken over all such boxes. For an integer vector a = (a0, . . . , as−1) ∈Zs, we
deﬁne |a| = maxν∈{0,...,s−1}|aν| and r(a) = s−1
ν=0 max{|aν|, 1}.
In order to show that a sequence Γ is uniformly distributed, we need to show
that its discrepancy DΓ is very small (i.e. tends to 0). The following lemma
is our main tool for ﬁnding non-trivial upper bound for the discrepancy. It is a
slightly weaker form of the Koksma-Sz¨usz inequality [DT97, Theorem 1.21]. The
implied constant in the symbol “≪” depends on the integer s.
Lemma 1. For any integer L > 1 and any sequence Γ of N points, we have
DΓ ≪1
L + 1
N

0<|a|<L
1
r(a)

N

n=1
e
	s−1

ν=0
aνγν,n

 ,
where the sum is taken over all integer vectors a ∈Zs with 0 < |a| < L.
We also need the well-known orthogonality relation:
m−1

η=0
em(ηλ) =

0 if λ ̸= 0 mod m
m otherwise
(1)
and the inequality [[IK04], Bound (8.6)] (which holds for any integers m and M
with 1 ≤M ≤m):
m−1

η=0

M

λ=1
em(ηλ)
 ≪m log m.
(2)
3.1
Distribution of the Dodis-Yampolskiy Pseudo-Random Function
Over Finite Fields
Let q = pr be a prime power for some integer r > 1, let g ∈F∗
q be an element
of prime order t. For x ∈Zt and d ≤t, we denote by Dx(d) the discrepancy of
the points (Vx,1(n)/p, . . . , Vx,r(n)/p) for1 ≤n ≤d, where Vx(n) = g
1
x+n ∈Fpr
and Vx(n) = Vx,1(n)β1 + · · · + Vx,r(n)βr, where {β1, . . . , βr} is an ordered basis
of Fpr over Fp. We identify Fp with the set of integers {0, 1, . . . , p −1}.

130
T. Mefenza and D. Vergnaud
Theorem 1. For any x ∈Zt, any integers k ≥2, ℓ≥1 and 1 ≤d ≤t, we have:
Dx(d) ≤t1−αk,lqβk,l+o(1)
d
,
where αk,l =
1
2(2k+l) −
1
4kl
and
βk,l =
1
4(2k+l).
Proof. From Lemma 1, we derive
Dx(d) ≪1
p + 1
d

0<|a|<p
1
r(a)

d

n=1
ep
⎛
⎝
r

j=1
ajVx,j(n)
⎞
⎠

,
where a = (a1, . . . , ar). Set
Sd(a) =
d

n=1
ep(
r

j=1
ajVx,j(n)).
Let {δ1, . . . , δr} be the dual basis of the given ordered basis {β1, . . . , βr}.
For j ∈{1, . . . , r} and n ∈{1, . . . , d}, we have Vx,j(n) = Tr(δjVx(n)), where Tr
denotes the trace of Fpr over Fp (namely Tr(x) = x+xp+· · ·+xpr−1). Therefore,
Sd(a) =
d

n=1
ep
⎛
⎝Tr
⎛
⎝
r

j=1
ajδjVx(n)
⎞
⎠
⎞
⎠=
d

n=1
ep(Tr(αaVx(n)))
where αa = r
j=1 ajδj ∈Fpr.
Let χ be deﬁned by χ(z) = ep(Tr(z)). Then χ is a non trivial additive
character on Fpr. Since there exists j ∈{1, . . . , r} such that aj ̸= 0, then αa ̸= 0.
We have:
Sd(a) =
d

n=1
χ(αaVx(n)) with αa ̸= 0.
We have
Sd(a) =
x+d

n=x+1
n∈Z∗
t
χ(αag1/n) = 1
t

n∈Z∗
t
χ(αag1/n) ×
t−1

c=0
x+d

v=x+1
v∈Z∗
t
et(c(n −v))
= 1
t
t−1

c=0
⎛
⎝
n∈Z∗
t
χ

αag1/n
et(cn)
⎞
⎠×
x+d

v=x+1
v∈Z∗
t
et(−cv).
By applying Proposition 1 and (2), we obtain
Sd(a) ≤1
t
t−1

c=0

x+d

v=x+1
v∈Z∗
t
et(−cv)

× t1−αk,ℓqβk,ℓ+o(1) ≤t1−αk,ℓqβk,ℓ+o(1).

Distribution and Polynomial Interpolation
131
By applying this bound to Dx(d), we have
Dx(d) ≪1
p + t1−αk,lqβk,ℓ+o(1)
d

0<|a|<p
1
r(a) ≪1
p + t1−αk,ℓqβk,ℓ+o(1)
d
logr p
≤t1−αk,ℓqβk,ℓ+o(1)
d
⊓⊔
With the choice k = 4, l = 8, t = q1+o(1) and d = t
127
128 +ε, we obtain
Dx(d) ≤pr(−ε+o(1)) = q−ε+o(1).
3.2
Distribution of the Dodis-Yampolskiy Pseudo-Random Function
Over Elliptic Curves
Let E : y2 = x3 + Ax + B, be an elliptic curve over Fp. For P ∈E(Fp) of prime
order t, for x ∈Zt, and for 1 ≤d ≤t we denote by Dx(d) the discrepancy of the
points (X(Vx(n))/p) for n ∈{1, . . . , d} where Vx(n) =

1
x+n

P ∈E(Fp). We
obtain the following theorem.
Theorem 2. For any x ∈Zt, any integers k ≥2, l ≥1 and 1 ≤d ≤t, we have:
Dx(d) ≤t1−αk,ℓpβk,ℓ+o(1)
d
,
where αk,ℓ=
1
2(4k+ℓ) −
1
4kℓ
and
βk,ℓ=
1
4(4k+ℓ).
Proof. From Lemma 1, we derive
Dx(d) ≪1
p + 1
d

0<|a|<p
1
|a|

d

n=1
ep (aX(Wx(n)))
 ,
where a is an integer. Set Sd(a) = d
n=1 ep(aX(Wx(n))), we have
Sd(a) =
x+d

n=x+1
n∈Z∗
t
ep

aX
 1
n

P

= 1
t

n∈Z∗
t
ep

aX
 1
n

P

×
t−1

c=0
x+d

v=x+1
v∈Z∗
t
et (c(n −v))
= 1
t
t−1

c=0
⎛
⎝
n∈Z∗
t
ep

aX
 1
n

P

et(cn)
⎞
⎠×
x+d

v=x+1
v∈Z∗
t
et(−cv)

132
T. Mefenza and D. Vergnaud
By applying Lemma 6 and (3), we obtain
Sd(a) ≤1
t
t−1

c=0

x+d

v=x+1
v∈Z∗
t
et(−cv)

× t1−αk,ℓpβk,ℓ+o(1)
≤t1−αk,ℓpβk,ℓ+o(1)
By applying this bound to Dx(d), we have
Dx(d) ≪1
p + t1−αk,ℓpβk,ℓ+o(1) × 1
d

0<|a|<p
1
|a|
≪1
p + t1−αk,ℓpβk,l+o(1) × 1
d log p
≤t1−αk,ℓpβk,ℓ+o(1) × 1
d
⊓⊔
With the choice k = 4, ℓ= 16, t = p1+o(1) and d = t
255
256 +ε, we obtain Dx(d) ≪
p−ε+o(1).
4
Polynomial Interpolation of the Dodis-Yampolskiy
Pseudo-Random Function Over Finite Fields
Let g ∈F∗
pr for some integer r > 1, be an element of prime order t | pr −1.
In this section, we prove a lower bound on the degree of univariate polyno-
mial interpolation of the Dodis-Yampolskiy pseudo-random function over ﬁnite
ﬁelds. We consider polynomials that interpolates values of the Dodis-Yampolskiy
pseudo-random function for a ﬁxed secret key x ∈F∗
t . The values considered are
evaluation of the function at integers n ∈{1, . . . , d} for some integer 1 ≤d ≤t
and translates of these values by some ﬁxed constants λ ∈N. This setting is
interesting for applications in cryptography [CHL05,CHK+06]. Note that if one
value n is larger than d then, the Dodis-Yampolskiy function is not necessarily
deﬁned at n + λ. In the following, we consider simple sets where all translates
belong to the function domain but our method can be adapted to other settings.
Theorem 3. Let λ be a ﬁxed integer and let A ⊆{1, . . . , d}. For some x ∈F∗
t ,
let F(X) ∈Fp[X] be such that F(g
1
x+n ) = g
1
x+n+λ for all n ∈A. We have
deg(F) ≥t −2s
4
and
w(F) ≥
 t
4s
1/2
where ♯A = t −s.
In the proof of Theorem 3, we use the following lemma [LW02] where the
weight w(F) (or sparsity) of a polynomial F(X) ∈Fp[X] is the number of its
non-zero coeﬃcients.

Distribution and Polynomial Interpolation
133
Lemma 2 [LW02]. Let γ ∈Fp be an element of order ℓand F(X) ∈Fp[X] be
a non-zero polynomial of degree at most ℓ−1 with at least b zeros of the form
γx with 0 ≤x ≤ℓ−1. The weight of F(X) satisﬁes w(F) ≥ℓ/(ℓ−b).
Proof (Theorem 3). Let R = {(n + x) mod t : n ∈A}. Then R ⊆Ft and ♯R =
t −s. We have F(g
1
n ) = g
1
n+λ for all n ∈R. Noticing that
1
n+λ = 1
λ(1 −
1
λ
n +1),
we obtain F(g
u
λ ) = g
1
λ (1−
1
u+1 ) for all u = λ
n, n ∈R.
Let R0 = {u = λ
n : n ∈R \ {0}} and T = {u ∈R0 : 2u + 1 ∈R0}. Since
♯R0 = t −s, we have ♯T ≥t −2s. Then
F

g
2u+1
λ

= g
1
λ (1−
1
2u+2 ) = g
1
λ ( 1
2 + 1
2 (1−
1
u+1 )) = g
1
2λ × g
1
2λ (1−
1
u+1 )
for all u ∈T. We thus have
F 2 
g
2u+1
λ

= g
1
λ × g
1
λ (1−
1
u+1 ) = g
1
λ × F(g
u
λ ),
for all u ∈T.
Let H(X) = F 2(g
1
λ X2) −g
1
λ F(X). The polynomial H(X) is a non-zero poly-
nomial and deg(H) ≤4 deg(F). Since H(X) has at least ♯T = t −2s zeros, we
have 4 deg(F) ≥t −2s and then deg(F) ≥t−2s
4 . Moreover, if deg(H) ≤t −1,
since the zeros of H are the powers of g
1
λ , then we have by Lemma 2, w(H) ≥
t/(t −(t −2s)), and since w(H) ≤2(w(F))2, it follows that w(F) ≥(t/4s)1/2.
⊓⊔
Remark 1. Theorem 3 is non-trivial only when ♯A > t/2. It remains an open
question to obtain non-trivial lowers bounds for smaller sets A.
5
Polynomial Interpolation of the Dodis-Yampolskiy
Pseudo-Random Function Over Elliptic Curves
In this section, p is an odd prime number, E is an elliptic curve deﬁned over Fp
and P is a point of the curve E(Fp) with prime order t. We prove lower bounds on
the degree of polynomial interpolation of the Dodis-Yampolskiy pseudo-random
function over elliptic curves deﬁned by Vx(n) = X

1
x+n

P

for a secret key
x ∈F∗
t and an integer n ∈{1, . . . , d}, with 1 ≤d ≤t.
Theorem 4. Let S ⊆{1, . . . , d}, ♯S = t −s. We suppose X(P) ̸= 0. For some
x ∈F∗
t , let F(X) ∈Fp[X] be such that ψ2
2(F(X(P))) ̸= 0 and F (Vx(n)) =
Vx(n + 1) for all n ∈S. We have
deg(F) ≥t −2s
176 .
Proof. Let R = {(n + x) mod t : n ∈S} ⊆Ft. We have ♯R = t −s. Let us
denote xk = X([k]P) and R0 = { 1
n : n ∈R}, then we have F(xu) = x1−
1
1+u for
all u ∈R0. We consider the set T = {u ∈R0 : 2u + 1 ∈R0}, then ♯T ≥t −2s.
For all u ∈T, we have:

134
T. Mefenza and D. Vergnaud
F(x2u+1) = x1−
1
2(u+1) = x1/2+1/2(1−1/(u+1))
and
F(xu) = x1−1/(u+1)
(3)
Using division polynomials (see Sect. 2.3), we can write:
x1+1−
1
(u+1) = θ2(F(x2u+1))
ψ2
2(F(x2u+1))
(4)
Using the elliptic curve addition law, we have
x1+α = a(xα) −2y1yα
(xα −x1)2
where a(X) = x1X2 + (x2
1 + A)X + Ax1 + 2B,
and for any polynomial G of degree m ≥1, we have
G(x1+α) = u(xα) −yαv(xα)
(xα −x1)2m
and lc(u) = G(x1)
with uniquely determined polynomialsu(X) andv(X) with deg(u)≤2m (deg(u) =
2m if G(x1) ̸= 0) and deg(v) ≤2m −2 and where lc(u) is the leading coeﬃcient
of the polynomial u(X). Since F(xu) = x1−
1
u+1 , we can rewrite (4) as:
a(F(xu)) −y1y1−
1
u+1
(F(xu) −x1)2
= θ2(F(x2u+1))
ψ2
2(F(x2u+1)).
Since the point (x1−
1
u+1 , y1−
1
u+1 ) ∈E(Fp) and F(xu) = x1−
1
u+1 , the poly-
nomial y2
1(F(xu)3 + A · F(xu) + B)ψ4
2(F(x2u+1)) is equal to the polynomial
[(F(xu) −x1)2θ2(F(x2u+1)) −a(F(xu))ψ2
2(F(x2u+1))]2. We thus obtain
y2
1(F(xu)3 + A · F(xu) + B) × p1(x2u) −y2up2(x2u)
(x2u −x1)12d0
= Q(xu, x2u, y2u),
where d0 = deg(F) and Q(xu, x2u, y2u) denotes a polynomial of the form

(F(xu) −x1)2 p3(x2u) −y2up4(x2u)
(x2u −x1)8d0
−a(F(xu))p5(x2u) −y2up6(x2u)
(x2u −x1)6d0
2
such that deg(p1) ≤6d0, deg(p2) ≤6d0 −2, deg(p3) ≤4d0, deg(p4) ≤4d0 −2,
deg(p5) ≤3d0 and deg(p6) ≤3d0 −2. We obtain:
y2
1(F(xu)3 + AF(xu) + B)(x2u −x1)4d0(p1(x2u) −y2up2(x2u))=P(xu, x2u, y2u),
where P(xu, x2u, y2u) = [(F(xu) −x1)2p3(x2u) −a(F(xu))(x2u −x1)2d0p5(x2u)
−y2u((F(xu) −x1)2p4(x2u) −a(F(xu))(x2u −x1)2d0p6(x2u))]2.
We then proceed as previously by trying to eliminate y2u. We obtain an
expression in function of xu and x2u and we replace x2u by
θ2(xu)
ψ2
2(xu). We ﬁnally
obtain a rational function in xu of the form:
Q(xu)
ψ40d0
2
(xu)
= 0, where Q(X) ∈Fp[X] and deg(Q) ≤88d0.
Claim. Q(X) ̸= 0 if ψ2
2(F(x1)) ̸= 0 and x1 ̸= 0.
Proof (Claim). We have deg(P5) = 3d0 iﬀψ2
2(F(x1)) ̸= 0. If deg(P5) = 3d0,
One can then verify that the leading coeﬃcient of Q is the leading coeﬃcient of

Distribution and Polynomial Interpolation
135
the numerator of the rational function obtained from [(F(xu) −x1)2p3(x2u) −
a(F(xu))(x2u −x1)2d0p5(x2u)]4 after replacing x2u by θ2(xu)
ψ2
2(xu).
Therefore, if deg(P5) = 3d0, then the leading coeﬃcient of Q is (f 2 × x1 ×
ψ2
2(F(x1)))4 which is non zero if x1 ̸= 0 since deg(P5) = 3d0 iﬀψ2
2(F(x1)) ̸= 0,
where f is the leading coeﬃcient of F. Then if ψ2
2(F(x1)) ̸= 0 and x1 ̸= 0, Q(X)
is a non-zero polynomial.
⊓⊔
If ψ2
2(F(x1)) ̸= 0 and x1 ̸= 0, Q(X) is a non-zero polynomial with at least
♯T/2 diﬀerent zeros. We thus have 88d0 ≥(t −2s)/2 and the claimed result. ⊓⊔
The condition X(P) ̸= 0 in the statement of Theorem 4 holds obviously for
almost all point P. The lower bound then holds if the group order ♯E(Fp) is odd
since in this case, the technical condition ψ2
2(F(X(P))) ̸= 0 is always satisﬁed.
However, we obtain a weaker lower bound for the polynomial degree which holds
for every curve E.
Theorem 5. Let 1 ≤d ≤t be a ﬁxed integer and let A ⊆{1, . . . , d}, ♯A = t−s.
For some x ∈F∗
t , let F(X) ∈Fp[X] such that F (Vx(n)) = Vx(n + 1) for all
x ∈A. We have deg(F) ≥(t −3s)1/2/6.
In the proof of Theorem 5, we use the following simple lemma:
Lemma 3. Let E : y2 = x3 + Ax + B be an elliptic curve over Fp with A ̸= 0
and B ̸= 0. Let F(X) ∈Fp[X] be a non-constant polynomial with F(X) ̸= X.
Then there exists α ∈Fp such that ψ2
2(F(α)) = 0 and ψ2
2(α) ̸= 0.
Proof. There are exactly three distinct zeros α1, α2, α3 ∈Fp of ψ2
2(X). For all
index i ∈{1, 2, 3}, there exists at least one βi ∈Fp such that F(βi) = αi,
because F is not a constant polynomial. Since for all i, j ∈{1, 2, 3}, i ̸= j, we
have αi ̸= αj, then the system F(X) = αi and F(X) = αj has no solution. It
follows that the polynomial ψ2
2(F(X)) has at least three diﬀerent zeros.
Let d denote the degree of F and let us suppose that there does not exist
α ∈Fp such that ψ2
2(F(α)) = 0 and ψ2
2(α) ̸= 0. Then we have that ψ2
2(F(X))
has exactly three zeros which are the zeros of ψ2
2(X). If d = 1, then it will
imply that F(X) = X which is impossible. If d ≥2, for all i ∈{1, 2, 3}, the
equation F(X) = αi has exactly one solution γi of multiplicity d which is one
of {α1, α2, α3}. Then γ1 and γ2 are the zeros of the (d −1)-derivative of F(X)
which is of degree 1 and this is impossible because γ1 ̸= γ2. Hence in all cases,
we obtain a contradiction. So there exists α ∈Fp such that: ψ2
2(F(α)) = 0 and
ψ2
2(α) ̸= 0.
Proof (Theorem). Let R = {(n+x) mod t : n ∈A}. Then R ⊆Ft and ♯R = t−s.
The equation F (Vx(n)) = Vx(n + 1) then becomes:
F

X
 1
n

P

= X

1
n + 1

P

,
for all n ∈R. Denoting xk = X([k]P) = X([k mod t]P) and considering the set
T = {n ∈R/n/2, n + 1 ∈R}, we have

136
T. Mefenza and D. Vergnaud
F

x 2
n

= F

x
1
n/2

= x
1
n/2+1 = x
2
n+2 =
θ2(x
1
n+2 )
ψ2
2(x
1
n+2 )
=
θ2(F(x
1
n+1 ))
ψ2
2(F(x
1
n+1 ))
=
θ2(F(F(x 1
n )))
ψ2
2(F(F(x 1
n ))),
hence we have
F
	
θ2(x 1
n )
ψ2
2(x 1
n )

=
θ2(F(F(x 1
n )))
ψ2
2(F(F(x 1
n ))), for all n ∈T.
Finally, we consider the polynomial
H(X) = ψ2d0
2
(X)ψ2
2(F(F(X)))

F
 θ2(X)
ψ2
2(X)

−θ2(F(F(X)))
ψ2
2(F(F(X)))

.
The polynomial H(X) has at least ♯T/2 zeros. We have F(F(X)) ̸= X and
by Lemma 3, it will imply that there exists α ∈Fp such that ψ2
2(F(F(α))) = 0
and ψ2
2(α) ̸= 0. Hence, we have H(α) = −θ2(F(F(α)))ψ2d0
2
(α) ̸= 0, since θ2(X)
and ψ2
2(X) have no common zeros. Therefore, H(X) is a non-zero polynomial
and deg(H) ≤9d2
0. Then we get that 9d2
0 ≥♯R/2 and the result follows.
⊓⊔
6
Conclusion
We studied the distribution of the Dodis-Yampolskiy pseudo-random function
values over ﬁnite ﬁelds and over elliptic curves. We also proved lower bounds
on the degree of polynomials interpolating the values of these functions in this
two settings of practical interest. As future works, it would be interesting to
study the distribution of k-tuples (Vx(m), . . . , Vx(m + k))m and to study the
linear complexity and minimal polynomials of the sequence generated by the
Dodis-Yampolskiy functions over ﬁnite ﬁelds and over elliptic curves.
Acknowledgments. The authors would like to thank the reviewers for their detailed
comments and suggestions for the manuscript. The authors were supported in part by
the French ANR JCJC ROMAnTIC project (ANR-12-JS02-0004) and by the Simons
foundation Pole PRMAIS.
A
Proof of Proposition 1
The classical Weil bound for exponential sums can be found in [Wei48,NW00].
Lemma 4. Let F(x) be a non constant polynomial in Fq[x] such that F(x) ̸=
h(x)p −h(x) for any h(x) ∈Fq(x). We have


x∈Fq
ψ(F(x))

≤(deg(F) −1)q1/2

Distribution and Polynomial Interpolation
137
We deduce the following simple lemma:
Lemma 5. For any pairwise distinct positive integers 1 ≤r1, . . . , rυ ≤R, we
have
max
(a1,...,aυ)∈Fυ
pr
(a1,...,aυ)̸=(0,...,0)

t

n=1
ψ
	 υ

i=1
aigrin

 ≤Rq1/2.
Proof. Let s = (q −1)/t. We have g = θs, where θ is a primitive root in Fq and
t

n=1
ψ
	 υ

i=1
aigrin

=
t

n=1
ψ
	 υ

i=1
aiθsrin

= 1
s
q−1

n=1
ψ
	 υ

i=1
aiθsrin

= 1
s
⎛
⎝
x∈Fq
ψ
	 υ

i=1
aixsri

−1
⎞
⎠
Applying Lemma 4, we obtain:
max
(a1,...,aυ)∈Fυ
pr
(a1,...,aυ)̸=(0,...,0)

t

n=1
ψ
	 υ

i=1
aigrin

 ≤1
s((Rs −1)q1/2 + 1) ≤Rq1/2.
⊓⊔
Proof (Proposition 1). For any integer k ≥2, we have
Sa,b
k =

n1,...,nk∈Z∗
t
ψ
⎛
⎝a
k

j=1
g1/nj
⎞
⎠et
⎛
⎝b
k

j=1
nj
⎞
⎠.
For m ∈Zt, we collect together the terms with n1 +· · ·+nk ≡m mod t, getting:
|Sa,b|k ≤

m∈Zt


n1,...,nk∈Z∗
t
n1+···+nk≡m mod t
ψ
⎛
⎝a
k

j=1
g1/nj
⎞
⎠

.
By the Cauchy inequality, we can upper-bound |Sa,b|2k by
t

m∈Zt


n1,...,nk∈Z∗
t
n1+···+nk≡m mod t
ψ

a
k

j=1
g1/nj


2
= t

(n1,...,n2k)∈Nk
ψ

a
2k

j=1
(−1)jg1/nj

where the outside summation is taken over the set of vectors
Nk = {(n1, . . . , n2k) ∈(Z∗
t )2k : n1 + · · · + n2k−1 ≡n2 + n4 + · · · + n2k mod t)}.

138
T. Mefenza and D. Vergnaud
One can see that for any m ∈N with gcd(m, t) = 1, we have

(n1,...,n2k)∈Nk
ψ
⎛
⎝a
2k

j=1
(−1)jg1/nj
⎞
⎠=

(n1,...,n2k)∈Nk
ψ
⎛
⎝a
2k

j=1
(−1)jgm/nj
⎞
⎠.
Let us ﬁx some parameter Q with Q ≥2 log t. Let Q be the set of primes m ≤Q
with gcd(m, t) = 1. Averaging over all m ∈Q, we obtain
|Sa,b|2k ≤
t
♯Q

m∈Q

(n1,...,n2k)∈Nk
ψ
⎛
⎝a
2k

j=1
(−1)jgm/nj
⎞
⎠.
The number w(t) of prime divisors of t satisﬁes w(t) ≤(1+o(1))(log t)/(log log t)
(which can be seen from the trivial inequality w(t)! ≤t and the Stirling formula).
By the prime number theorem, we have (since Q ≥2 log t):
♯Q ≥(1 + o(1))
Q
log Q −(1 + o(1))
log t
log(log t) ≥0.5
Q
log Q,
provided that t is large enough. We have ♯Nk ≤t2k−1. Using the H¨older inequal-
ity and then extending the region of summation, we obtain that for any integer
ℓ≥1, we have:
|Sa,b|4kℓ≤
t2ℓ
♯Q2ℓ(♯Nk)2ℓ−1

n1,...,n2k∈Z∗
t


m∈Q
ψ
⎛
⎝a
2k

j=1
(−1)jgm/nj
⎞
⎠

2ℓ
≪t4kℓ−2k+1 log2ℓQ
Q2ℓ
t

n1,...,n2k=1


m∈Q
ψ
⎛
⎝a
2k

j=1
(−1)jgmnj
⎞
⎠

2ℓ
= t4kℓ−2k+1 log2ℓQ
Q2l
t

n1,...,n2k=1

m1,...,m2ℓ∈Q
ψ
⎛
⎝a
2k

j=1
2ℓ

h=1
(−1)j+hgmhnj
⎞
⎠
= t4kℓ−2k+1 log2ℓQ
Q2ℓ

m1,...,m2ℓ∈Q

t

n=1
ψ
	
a
2ℓ

h=1
(−1)hgmhn


2k
.
For O(♯Qℓ)=O(Qℓlog−ℓQ) tuples (m1, . . . , m2ℓ) ∈Q2ℓsuch that the tuple of the
elements on the odd positions (m1, . . . , m2ℓ−1) is a permutation of the elements
on the even positions (m2, . . . , m2ℓ), we estimate the inner sum trivially as t.
For the remaining O((♯Q)2ℓ) = O(Q2ℓ(log Q)−2ℓ) tuples, we use the bound
of Lemma 5. Therefore,
|Sa,b|4kℓ≪t4kℓ−2k+1 log2ℓQ
Q2l
(Qℓlog−ℓQt2k + Q2ℓlog−2ℓQ(Qq1/2)2k)
= t4kℓ−2k+1(Q−ℓlogℓQt2k + Q2kqk).

Distribution and Polynomial Interpolation
139
Taking Q = 2t2k/(2k+ℓ)q−k/(2k+ℓ)(log q)ℓ/(2k+ℓ) and if t ≥q1/2(log q)2, one can
see that Q ≥2 log t and we obtain
|Sa,b|4kℓ≪t4kℓ−(2kℓ−2k−ℓ)/(2k+ℓ)qkℓ/(2k+ℓ)(log q)ℓ/(2k+ℓ)
and the result follows.
⊓⊔
References
[BGLS00] Banks, W.D., Griﬃn, F., Lieman, D., Shparlinski, I.E.: Non-linear com-
plexity of the naor–reingold pseudo-random function. In: Song, J.S. (ed.)
ICISC 1999. LNCS, vol. 1787, pp. 53–59. Springer, Heidelberg (2000).
doi:10.1007/10719994 5
[BS08] Bourgain, J., Shparlinski, I.E.: Distribution of consecutive modular roots
of an integer. Acta Arith. 134(1), 83–91 (2008)
[BSS99] Blake, I.F., Seroussi, G., Smart, N.P.: Elliptic Curves in Cryptography.
Cambridge University Press, Cambridge (1999)
[Che10] Cheon, J.H.: Discrete logarithm problems with auxiliary inputs. J. Cryptol.
23(3), 457–476 (2010)
[CHK+06] Camenisch,
J.,
Hohenberger,
S.,
Kohlweiss,
M.,
Lysyanskaya,
A.,
Meyerovich, M.: How to win the clonewars: eﬃcient periodic n-times
anonymous authentication. In: ACM CCS 2006: 13th Conference on
Computer and Communications Security, Alexandria, Virginia, USA, 30
October–3 November 2006, pp. 201–210. ACM Press (2006)
[CHL05] Camenisch, J., Hohenberger, S., Lysyanskaya, A.: Compact e-cash. In:
Cramer, R. (ed.) EUROCRYPT 2005. LNCS, vol. 3494, pp. 302–321.
Springer, Heidelberg (2005). doi:10.1007/11426639 18
[CS00] Coppersmith, D., Shparlinski, I.: On polynomial approximation of the dis-
crete logarithm and the Diﬃe-Hellman mapping. J. Cryptol. 13(3), 339–
360 (2000)
[DT97] Drmota, M., Tichy, R.: Discrepancies and Applications. Springer, Berlin
(1997)
[DY05] Dodis, Y., Yampolskiy, A.: A veriﬁable random function with short proofs
and keys. In: Vaudenay, S. (ed.) PKC 2005. LNCS, vol. 3386, pp. 416–431.
Springer, Heidelberg (2005). doi:10.1007/978-3-540-30580-4 28
[GGI11] G´omez, D., Gutierrez, J., Ibeas, A.: On the linear complexity of the
Naor-Reingold sequence. Inf. Process. Lett. 111(17), 854–856 (2011)
[IK04] Iwaniec, H., Kowalski, E.: Analytic Number Theory. American Mathemat-
ical Society, Providence (2004)
[KW06] Kiltz, E., Winterhof, A.: Polynomial interpolation of cryptographic func-
tions related to Diﬃe-Hellman and discrete logarithm problem. Discrete
Appl. Math. 154(2), 326–336 (2006)
[LSW14] Ling, S., Shparlinski, I.E., Wang, H.: On the multidimensional distribution
of the Naor-Reingold pseudo-random function. Math. Comput. 83(289),
2429–2434 (2014)
[LW02] Lange, T., Winterhof, A.: Polynomial interpolation of the elliptic curve
and XTR discrete logarithm. In: Ibarra, O.H., Zhang, L. (eds.) COCOON
2002. LNCS, vol. 2387, pp. 137–143. Springer, Heidelberg (2002). doi:10.
1007/3-540-45655-4 16

140
T. Mefenza and D. Vergnaud
[NR04] Naor, M., Reingold, O.: Number-theoretic constructions of eﬃcient pseudo-
random functions. J. ACM 51(2), 231–262 (2004)
[NW00] Niederreiter, H., Winterhof, A.: Incomplete exponential sums over ﬁnite
ﬁelds and their applications to new inversive pseudorandom number gen-
erators. Acta Arith. 93(4), 387–399 (2000)
[OS11] Ostafe, A., Shparlinski, I.E.: Twisted exponential sums over points of ellip-
tic curves. Acta Arith. 148(1), 77–92 (2011)
[Shp11] Shparlinski, I.E.: Exponential sums with consecutive modular roots of an
integer. Q. J. Math. 62(1), 207–213 (2011)
[Was08] Washington, L.C.: Elliptic Curves: Number Theory and Cryptography, 2nd
edn. Chapman and Hall/CRC, Boca Raton (2008)
[Wei48] Weil, A.: On some exponential sums. Proc. Natl. Acad. Sci. U.S.A. 34,
204–207 (1948)

Boolean Functions

A Conjecture About Gauss Sums and Bentness
of Binomial Boolean Functions
Jean-Pierre Flori(B)
Agence nationale de la s´ecurit´e des syst`emes d’information,
51 boulevard de La Tour-Maubourg, 75700 Paris 07 SP, France
jean-pierre.flori@ssi.gouv.fr
Abstract. In this note, the polar decomposition of binary ﬁelds of even
extension degree is used to reduce the evaluation of the Walsh trans-
form of binomial Boolean functions to that of Gauss sums. In the case
of extensions of degree four times an odd number, an explicit formula
involving a Kloosterman sum is conjectured, proved with further restric-
tions, and supported by extensive experimental data in the general case.
In particular, the validity of this formula is shown to be equivalent to a
simple and eﬃcient characterization for bentness previously conjectured
by Mesnager.
Keywords: Boolean functions · Bent functions · Walsh spectrum ·
Exponential sums · Gauss sums · Kloosterman sums
1
Introduction
Bent functions are Boolean functions deﬁned over an extension of even degree
and achieving optimal non-linearity. They are of both combinatorial and crypto-
graphic interest. Unfortunately, characterizing bentness of an arbitrary Boolean
function is a diﬃcult problem, and even the less general question of provid-
ing simple and eﬃcient criteria within inﬁnite families of functions in a speciﬁc
polynomial form is still challenging.
For a Boolean function f deﬁned over F2n with n = 2m and given in polyno-
mial form, a classical characterization for bentness is that its Walsh transform 
χf
values are only 2±m. Nevertheless, such a characterization is neither concise nor
eﬃcient: the best algorithm to compute the full Walsh spectrum has complexity
O(n2n), which is asymptotically optimal. Whence the need to restrict to func-
tions in a given form and to look for more eﬃcient criteria. Unfortunately, only
a few inﬁnite families of Boolean functions with a simple and eﬃcient criterion
for bentness are known.
The most classical family is due to Dillon [7] and is made of monomial
functions:
fa(x) = Tr n
1

axr(2m−1)
,
where n = 2m, a ∈F∗
2n and r is co-prime with 2m + 1. Such functions are
bent (and even hyper-bent: for any r coprime with (2n −1) the function fa(xr)
c
⃝Springer International Publishing AG 2016
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 143–159, 2016.
DOI: 10.1007/978-3-319-55227-9 11

144
J.-P. Flori
is also bent) if and only if the Kloosterman sum Km(a) associated with a is
equal to zero [3,7,15]. Not only does such a criterion gives a concise and elegant
characterization for bentness, but using the connection between Kloosterman
sums and elliptic curves [13,14] it also allows to check for bentness in polynomial
time [1,16]. Further results on Kloosterman sums involving p-adic arithmetic
[10,11,20] lead to even faster generation of zeros of Kloosterman sums and so of
(hyper-)bent functions.
Mesnager [18,19] proved a similar criterion for a family Boolean functions in
binomial form:
fa,b(x) = Tr n
1

axr(2m−1)
+ Tr 2
1

bx
2n−1
3

,
where n = 2m, a ∈F∗
2n, b ∈F∗
4 and r is co-prime with 2m + 1 (but also r = 3
which divides 2m +1 [17]). When the extension degree n is twice an odd number,
that is when m is odd, fa,b is (hyper-)bent if and only if Km(a) = 4. Moreover,
(hyper-)bent functions in this family can be quickly generated as techniques used
to generate zeros of Kloosterman sums can be transposed to the value 4 [9].
Unfortunately, the proof of the aforementioned characterization does not
extend to the case where m is even. Nevertheless, it is easy to show that Km(a) =
4 is still a necessary condition for fa,b to be bent in this latter case (but note
that fa,b can no longer be hyper-bent). Further experimental evidence gathered
by Flori et al. [9] supported the conjecture that it should also be a suﬃcient
condition: for m up to 16, fa,b is bent if and only if Km(a) = 4.
In this note, the polar decomposition of ﬁelds of even extension degree n =
2νm with m odd is used to reduce the evaluation of the Walsh transform of fa,b
at ω ∈F∗
2n to that of a Gauss sum of the form

u∈U
ψn (bTr n
m (ωu)) χ

Tr n
1

au22ν−1m−1

,
(1)
where F∗
2n is decomposed as F∗
2n ≃U×F∗
2m, ψn is a cubic multiplicative character
and χ a quadratic additive character.
In the case of extensions of degree four times an odd number, that is when n
is four times an odd number m, an explicit formula involving the Kloosterman
sum Kn/2(a) is proved for ω lying in the subﬁeld F2n/2, and conjectured and
supported by extensive experimental evidence when ω ∈F2n. In particular, the
validity of this formula would prove the following conjecture for extensions of
degree four times an odd number (and give hope to prove the conjecture for n
of any 2-adic valuation):
Conjecture 1. Let n = 4m with m odd, a ∈F∗
2n/2 and b ∈F∗
4. The function fa,b
is bent if and only if Kn/2(a) = 4.
2
Notation
2.1
Field Trace
Deﬁnition 1 (Field trace). For extension degrees m and n such that m divides
n, the ﬁeld trace from F2n down to F2m is denoted by Tr n
m (x).

A Conjecture About Gauss Sums and Bentness
145
2.2
Polar Decomposition
Deﬁnition 2 (Extension degrees). Let n ≥2 be an even integer and ν ≥1
denote its 2-adic valuation. We denote by mi for 0 ≤i ≤ν the integer n/2i, e.g.
m0 = n and mν = m in the introduction.
For 0 ≤i < ν, the multiplicative group F∗
2mi can be split using the so-called
polar decomposition
F∗
2mi ≃Ui+1 × F∗
2mi+1,
where Ui+1 ⊂F∗
2mi is the subgroup of (2mi+1 + 1)-th roots of unity and F∗
2mi+1
the subgroup of (2mi+1 −1)-th roots of unity. Repeating this construction yields
the following decomposition.
Lemma 1 (Polar decomposition). Let ν ≥1 and denote by U denote the
image of U1 × · · · × Uν within F∗
2m0 . Then F∗
2m0 decomposes as
F∗
2m0 ≃U1 × · · · × Uν × F∗
2mν
≃U × F∗
2mν .
2.3
Hilbert’s Theorem 90
Deﬁnition 3. For 1 ≤i ≤ν and j ∈F2, let T j
mi be the set
T j
mi =

x ∈F2mi , Tr mi
1
	
x−1
= j

of elements of F2mi whose inverses have trace j (deﬁning 0−1 to be 0).
Hilbert’s Theorem 90 [8] implies that the function x →x + x−1 is 2-to-1
from Ui\ {1} to T 1
mi and from F∗
2mi \ {1} to T 0
mi\ {0} (and both 0 and 1 are sent
onto 0).
2.4
Dickson Polynomials
Deﬁnition 4. We denote by D3 the third Dickson polynomial of the ﬁrst kind
D3(x) = x3 + x.
A notable property of D3 is that D3(x + x−1) = x3 + x−3. It implies in
particular that D3 induces a permutation of T 0
m1 when m1 is odd and of T 1
m1
when m1 is even [8, Propositions 5, 6 and Theorem 7].
2.5
Characters
Deﬁnition 5 (Additive character). Denote by χ the non-principal quadratic
additive character of F2.
Together with the ﬁeld trace, χ can be used to construct all quadratic additive
characters of F2mi for any 0 ≤i ≤ν.

146
J.-P. Flori
Deﬁnition 6 (Multiplicative character). The non-principal cubic multi-
plicative character ψmi of F2mi for any 0≤i < ν is deﬁned for x∈F2mi as
ψmi (x) = x
2mi −1
3
.
Note that if x lies in a subextension, that is x ∈F2mi+j with 0 ≤i + j < ν,
then
ψmi (x) = ψmi+j (x)2j
.
Remark that 3 divides 2mν + 1 and is coprime with 2mν −1 and 2mi + 1 for
0 ≤i < ν. Therefore the function x →x3 is a permutation of F∗
2mν and Ui for
1 ≤i < ν, and 3-to-1 on Uν. In particular, the multiplicative character ψm0 is
trivial everywhere on F∗
2m0 but on Uν.
2.6
Walsh Transform
Deﬁnition 7. The Walsh transform of a Boolean function f at ω ∈F2m0 is

χf(ω) =

x∈F2m0
χ (f(x) + Tr m0
1
(ωx)) .
It is well-known that a Boolean function f is bent if and only if its Walsh
transform only takes the values 2±m1.
2.7
Kloosterman Sums
Deﬁnition 8. For a ∈F2m1 , the Kloosterman sum Km1(a) is
Km1(a) =

x∈F2m1
χ
	
Tr m1
1
	
ax + x−1

.
The following identities (proved using the map from Sect. 2.3) are well-known:

u1∈U1
χ (Tr m0
1
(au1)) = 1 + 2

t∈T 1
m1
χ (Tr m1
1
(at))
= 1 −2

t∈T 0
m1
χ (Tr m1
1
(at))
= 1 −Km1(a).
2.8
Cubic Sums
Deﬁnition 9. For a, b ∈F2m1 , the cubic sum Cm1(a, b) is
Cm1(a, b) =

x∈F2m1
χ
	
Tr m1
1
	
ax3 + bx


.

A Conjecture About Gauss Sums and Bentness
147
The possible values of Cm1(a, b) were determined by Carlitz [2] together with
simple criteria involving a and b.
The most important consequence of Carlitz’s results in our context is that
Cm1(a, a) = 
x∈F2m1 χ (Tr m1
1
(aD3(x))) = 0 if and only if
– Tr m1
1
(α) = 0 for α ∈F∗
2m1 such that a = α3 when m1 is odd (in that case a
is always a cube),
– and when there exists α ∈F∗
2m1 such that a = α3 (that is a is a cube or
equivalently ψm1 (a) = 1) and Tr m1
2
(α) ̸= 0 (that is the cube root’s half-trace
is non zero) when m1 is even.
Charpin et al. later deduced that both in the odd case [4] and in the even
case [5,6] these conditions are equivalent to Km1(a) ≡1 (mod 3).
For completeness, the other possible values for Cm1(a, a) when m1 is even
follow:
– When a is a cube and Tr m1
2
(α) = 0, then Cm1(a, a) = 2m2+1χ
	
Tr m1
1
	
u3
0


,
where u0 is any solution to u4 + u = α4, that is u0 = (m2−3)/2
i=0
α42∗i+2 + γ
for any γ ∈F4.
– When a is not a cube, then Cm1(a, a) = −2m2χ
	
Tr m1
1
	
au3
0


, where u0 is the
unique solution to u4 + u/a = 1, that is u0 = ψm1 (a) m2−1
i=0
a4ia(4i−1)/3.
Finally, Carlitz also proved the following result on Cm1(a, 0) when m1 = 2m2
is even:
Cm1(a, 0) =
(−1)m2+12m2+1 if ψm1 (a) = 1,
(−1)m22m2
if ψm1 (a) ̸= 1.
2.9
Binomial Functions
The binomial Boolean functions fa,b studied in this note are deﬁned over F2m0 .
Deﬁnition 10. For ν ≥1, a ∈F∗
2m0 and b ∈F∗
4, we denote by fa,b the binomial
function
fa,b(x) = Tr m0
1

ax2m1−1
+ Tr 2
1 (bψm0 (x)) .
(2)
We also deﬁne fa = fa,0 (corresponding to Dillon’s monomial) and gb(x) =
Tr 2
1 (bψm0 (x)).
3
Preliminaries
3.1
Field of Deﬁnition of the Coeﬃcients
First notice that it is enough to know how to evaluate the Walsh transform of
functions fa,b for a ∈F∗
2m1 .
Lemma 2. Let a ∈F∗
2m0 be written as a = α˜a with α ∈U1 and ˜a ∈F∗
2m1 using
the polar decomposition of F∗
2m0 . Let ˜α ∈U1 be a square root of α and β ∈F∗
4
be β = ψm0 (α)−1. Then

χfa,b(ω) = 
χf˜a,βb(˜αω).

148
J.-P. Flori
Proof. Indeed, x →˜αx induces a permutation of F2m0 , ˜α2m1−1 = ˜α−2 = α−1,
and ψm0 (˜α) = ψm0 (α)−1, so that

χfa,b(ω) =

x∈F2m0
χ (fa,b(x) + Tr m0
1
(ωx))
=

x∈F2m0
χ (fa,b(˜αx) + Tr m0
1
(ω˜αx))
=

x∈F2m0
χ (f˜a,βb(x) + Tr m0
1
(ω˜αx))
= 
χf˜a,βb(˜αω).
From now on we can suppose that a ∈F∗
2m1 without loss of generality.
3.2
Polar Decomposition
The polar decomposition yields the following expression for fa,b.
Lemma 3. For ν ≥1, a ∈F∗
2m0 and b ∈F∗
4, and x ∈F∗
2m0 , fa,b(x) is
fa,b(x) = fa,b(u) = fa(u1) + gb(uν).
(3)
Proof. Notice that fa,b(x) = fa(x) + gb(x). Moreover fa is trivial on F∗
2m1 and
gb is trivial everywhere but on Uν as noted in Sect. 2.5.
We now split the sum expressing the Walsh transform of fa,b at ω ∈F2m0
using the polar decomposition of F∗
2m0 as F∗
2m0 ≃U × F∗
2mν . We write x ∈F∗
2m0
as x = uy for u ∈U, and y ∈F∗
2mν .
Lemma 4. For ν ≥1, a ∈F∗
2m1 and b ∈F∗
4, the Walsh transform of fa,b at
ω ∈F2m0 is, for ω = 0:

χfa,b(0) = 1 + (2mν −1)

u∈U
χ (fa,b(u)) ,
(4)
and for ω ̸= 0:

χfa,b(ω) = 1 −

u∈U
χ (fa,b(u)) + 2mν

u∈U,Tr m0
mν (ωu)=0
χ (fa,b(u)) .
(5)
Proof. Using the polar decomposition, the Walsh transform of fa,b at ω ∈F2m0
can indeed be written

χfa,b(ω) =

x∈F2m0
χ (fa,b(x) + Tr m0
1
(ωx))
= 1 +

x∈F∗
2m0
χ (fa,b(x) + Tr m0
1
(ωx))
= 1 +

(u,y)∈U×F∗
2mν
χ (fa,b(uy)) χ (Tr m0
1
(ωuy)) .

A Conjecture About Gauss Sums and Bentness
149
Note that 3 divides 2mν +1 so that 2m0−1
3
= (2mν −1) 2mν +1
3
ν−1
i=1 (2mi +1) and
fa,b(uy) = fa,b(u). Therefore

χfa,b(ω) = 1 +

u∈U
χ (fa,b(u))

y∈F∗
2mν
χ
	
Tr mν
1
	
Tr m0
mν (ωu) y


.
The sum ranging over F∗
2mν is equal to −1 when Tr m0
mν (ωu) ̸= 0 and 2m1 −1
when Tr m0
mν (ωu) = 0. In particular, when ω = 0, the trace is 0 for all u ∈U.
To go further, the cases ν = 1 and ν > 1 have to be dealt with separately.
4
Odd Case
In this section, it is supposed that ν = 1, i.e. m1 is odd and U = U1, which is
the case that Mesnager settled [18,19] with the following proposition. We recall
the main ingredients and results of her work as similar ideas will be used for the
even case.
Proposition 1 [18,19]. For ν = 1, a ∈F∗
2m1 and b ∈F∗
4, the Walsh transform
of fa,b at ω ∈F2m0 is, for ω = 0:

χfa,b(0) =
1 + 2m1−1
3
(1 −Km1(a) −4Cm1(a, a)) if b = 1,
1 + 2m1−1
3
(1 −Km1(a) + 2Cm1(a, a)) if b ̸= 1,
(6)
and for ω ̸= 0:

χfa,b(ω) =
 1 + 2m1χ

fa,b(w−1
1 )

+ 1
3 (1 −Km1(a) −4Cm1(a, a)) if b = 1,
1 + 2m1χ

fa,b(w−1
1 )

+ 1
3 (1 −Km1(a) + 2Cm1(a, a)) if b ̸= 1.
(7)
Proof. For ω ̸= 0, Tr m0
m1 (ωu1) = 0 if and only if u1 = w−1
1 , so that

u1∈U1,Tr m0
m1(ωu1)=0
χ (fa,b(u1)) = χ
	
fa,b(w−1
1 )

.
The only diﬃculty lies in the computation of 
u1∈U1 χ (fa,b(u1)) which can
be done by splitting the sum on U1 according to the value of ψm1 (u1):

u1∈U1
χ (fa,b(u1)) =

u1∈U1
χ (fa(u1)) χ (gb(u1))
=

u1∈U1,bψm0(u1)=1
χ (fa(u1)) −

u1∈U1,bψm0(u1)̸=1
χ (fa(u1))
= 2

u1∈U1,bψm0(u1)=1
χ (fa(u1)) −

u1∈U1
χ (fa(u1)) .
As noted in Sect. 2.7 the second sum is

u1∈U1
χ (fa(u1)) = 1 −Km1(a).

150
J.-P. Flori
As far as the ﬁrst one is concerned, let us denote it S1(a, b, ω). As m1 is odd,
using properties of the Dickson polynomial D3 given in Sect. 2.4, one can show
that for b = 1:
S1(a, b, ω) = 1
3 (1 −Km1(a) + 2Cm1(a, a)) .
As S1(a, b, ω) takes the same value for both b ̸= 1, one deduces that for b ̸= 1:
S1(a, b, ω) = 1
3 (1 −Km1(a) −Cm1(a, a)) .
Results of Carlitz [2] on Cm1(a, a) when m1 is odd yield a concise and easy
to compute the Walsh transform of fa,b at any ω ∈F2m0 .
Together with Charpin et al. results [5,6] and the Hasse–Weil bound on
Km1(a), these formulae prove that fa,b is (hyper-)bent if and only if Km1(a) = 4
as was noted by Mesnager [18,19].
Theorem 1 [18,19]. For ν = 1, a ∈F∗
2m and b ∈F∗
4, the function fa,b is bent
if and only if Km1(a) = 4.
5
Even Case
5.1
General Extension Degree
In this section, it is supposed that ν > 1, i.e. both m0 and m1 are even. The
main diﬀerence with the case ν = 1 is that 3 does now divide 2m1 −1 (in fact
2mν + 1) rather than 2m1 + 1, and ψm0 (u) does not depend on the value of u1
(but only on that of uν).
In particular, the computation of 
u∈U fa,b(u) becomes straightforward.
Lemma 5. For ν > 1, a ∈F∗
2m1 and b ∈F∗
4,

u∈U
χ (fa,b(u)) = −22ν−1mν −1
3 (2mν −1) (1 −Km1(a)) .
(8)
Proof. Splitting U as U ≃U1 × · · · × Uν, the sum can be rewritten:

u∈U
χ (fa,b(u)) =
ν−1

j=2
(2mj + 1)

u1∈U1
χ (fa(u1))

uν∈Uν
χ (gb(uν))
=
ν−1

j=2
(2mj + 1) 2mν + 1
3
(1 −Km1(a))

c∈F∗
4
χ
	
Tr 2
1 (bc)

= −
ν−1

j=2
(2mj + 1) 2mν + 1
3
(1 −Km1(a)) .

A Conjecture About Gauss Sums and Bentness
151
Finally, using the identity

22jmν + 1
 
22jmν −1

=

22j+1mν −1

, the prod-
uct of the (2mj + 1)’s is
ν

j=2
(2mj + 1) =
ν

j=2

22ν−jmν + 1

= 22ν−1mν −1
2mν −1
.
The value of the Walsh transform at ω = 0 given by Eq. (4) can now be
simpliﬁed.
Lemma 6. For ν > 1, a ∈F∗
2m1 and b ∈F∗
4, the Walsh transform of fa,b at
ω = 0 is

χfa,b(0) = 1 −2m1 −1
3
(1 −Km1(a)) .
(9)
As noted by Mesnager [18,19], the Hasse–Weil bound on Km1(a) implies
that, if fa,b is bent, then 
χfa,b(0) = 2m1 and Km1(a) = 4.
Proposition 2 [18,19]. For ν > 1, a ∈F∗
2m1 and b ∈F∗
4, if the function fa,b is
bent, then Km1(a) = 4.
Finally, the value of the Walsh transform at ω ̸= 0 given by Eq. (5) is simpli-
ﬁed as follows.
Lemma 7. For ν > 1, a ∈F∗
2m1 and b ∈F∗
4, the Walsh transform of fa,b at
ω ∈F∗
2m0 is

χfa,b(ω) = 1 + 22ν−1mν −1
3 (2mν −1) (1 −Km1(a)) + 2mν

u∈U,Tr m0
mν (ωu)=0
χ (fa,b(u)) .
(10)
5.2
Descending to an Odd Degree Extension
To simplify further Eq. (10), the sum over u ∈U can be split into smaller sums
according to the extension F2mi (with 1 ≤i ≤ν) where Tr m0
mi (uω) becomes 0,
giving the following expression.
Proposition 3. For ν > 1, a ∈F∗
2m1 and b ∈F∗
4, and ω ∈F∗
2m0 , denote by
Sν(a, b, ω) the sum
Sν(a, b, ω) =

Tr m0
mν−1(uω)̸=0,Tr m0
mν (uω)=0,bψm0(uν)=1
χ (fa(u1)) .
(11)
The Walsh transform of fa,b at ω ̸= 0 is

χfa,b(ω) = 1 −2 · 2(2ν−1−1)mν −1
3
(1 −Km1(a))
−2 · 2(2ν−1−1)mν 	
2mν−1 −1

3
χ (fa(w1))
+ 2mν+1Sν(a, b, ω).
(12)

152
J.-P. Flori
Proof. The
sum
over
U
can
be
divided
into
subsums
σi
over
Ui:

u∈U,Tr m0
mν (ωu)=0 χ (fa,b(u)) = ν
i=1 σi with
σi =

Tr m0
mi−1(u1···ui−1w1···wi−1)̸=0,
Tr m0
mi (u1···uiw1···wi)=0,
ui+1∈Ui+1,...,uν∈Uν
χ (fa(u1)) χ (gb(uν)) .
The ﬁrst sum σ1 can be simpliﬁed as Eq. (8):
σ1 =
ν−1

j=2
(2mj + 1) χ
	
fa(w−1
1 )

 
uν∈Uν
χ (gb(uν))
= −
ν−1

j=2
(2mj + 1) 2mν + 1
3
χ
	
fa(w−1
1 )

= −22ν−1mν −1
3 (2mν −1) χ
	
fa(w−1
1 )

.
(13)
The last sum σν can be split according to the value of ψm0 (uν) as in Sect. 4:
σν = 2

Tr m0
mν−1(uω)̸=0,
Tr m0
mν (uω)=0,
bψm0(uν)=1
χ (fa(u1)) −

Tr m0
mν−1(uω)̸=0,
Tr m0
mν (uω)=0
χ (fa(u1)) ,
(14)
where the ﬁrst term is 2Sν(a, b, ω) and the second term is
−

Tr m0
mν−1 (uω)̸=0,
Tr m0
mν (uω)=0
χ (fa(u1)) = −
ν−1

j=2
2mj

u1̸=w−1
1
χ (fa(u1))
= −
ν−1

j=2
2mj 
1 −χ

fa(w−1
1 )

−Km1(a)

= −22(2ν−2−1)mν 
1 −χ

fa(w−1
1 )

−Km1(a)

,
(15)
as the product of the 2mj’s is
ν−1

j=2
2mj =
ν−1

j=2
22ν−jmν = 22ν−2 ν−3
j=0 2−jmν = 22ν−22(1−2−ν+2)mν.
(16)
For ν > 2, the intermediate sums σi for 2 < i < ν are:
σi =
i−1

j=2
2mj
ν−1

j=i+1
(2mj + 1)

u1̸=w−1
1
χ (fa(u1))

uν∈Uν
χ (gb(uν))
= −
i−1

j=2
2mj
ν−1

j=i+1
(2mj + 1) 2mν + 1
3
	
1 −χ
	
fa(w−1
1 )

−Km1(a)

.

A Conjecture About Gauss Sums and Bentness
153
Fortunately, a simpler expression for the sum of the products of 2mj’s and
(2mj + 1)’s for 1 < j < ν can be devised. Indeed, for k ≥3 and any rational
number m, the sum that we denote by Σ(m, k) is
Σ(m, k) =
k−1

i=2
⎛
⎝
i−1

j=2
22k−jm
k

j=i+1

22k−jm + 1

⎞
⎠= 22(2k−2−1)m −1
2m −1
.
(17)
The proof goes by induction on k. For k = 3, the identity states 2m +1 = 22m−1
2m−1 .
Let us now suppose that Eq. (17) is veriﬁed up to some k ≥3 for all rational
numbers m’s. The sum for k + 1 is
Σ(m, k + 1) = (2m + 1) Σ(2m, k) + (2m + 1)
k−1

j=2
22k−j(2m)
By induction and a variation of Eq. (16), the identity is proved for k + 1:
Σ(m, k + 1) = (2m + 1) 22(2k−2−1)(2m) −1
22m −1
+ (2m + 1) 24(2k−2−1)m
= 24(2k−2−1)m −1
2m −1
+
	
22m −1

24(2k−2−1)m
2m −1
= 22(2k−1−1)m −1
2m −1
.
Setting k = ν and m = mν in Eq. (17) yields
ν−1

i=2
σi = −22(2ν−2−1)mν −1
3 (2mν −1)
	
1 −χ
	
fa(w−1
1 )

−Km1(a)

.
(18)
Note that for ν = 2, both sides of the above equality are zero. Therefore, for
any ν > 1, Eqs. (13), (14), (15) and (18), lead to the following expression for the
Walsh transform at ω ̸= 0:

χfa,b(ω) = 1 + 22ν−1mν −1
3 (2mν −1) (1 −Km1(a))
−2mν 22ν−1mν −1
3 (2mν −1) χ
	
fa(w−1
1 )

−2mν 22(2ν−2−1)mν −1
3 (2mν −1)
	
1 −χ
	
fa(w−1
1 )

−Km1(a)

−2mν22(2ν−2−1)mν 	
1 −χ
	
fa(w−1
1 )

−Km1(a)

+ 2mν+1Sν(a, b, ω),
which gives the announced expression by gathering independently the terms in
χ
	
fa(w−1
1 )

and (1 −Km1(a)).

154
J.-P. Flori
Unfortunately, making the remaining sum Sν(a, b, ω) explicit is a hard prob-
lem. Doing so is equivalent to evaluating a Gauss sum as in Eq. (1): an expo-
nential sum involving a multiplicative character and an additive character. In
the next section, we manage to tackle the case ν = 2 when ω ∈F∗
2m1 (that is
w1 = 1) and conjecture a partial formula when ω ̸∈F∗
2m1 .
5.3
Four Times an Odd Number
From now on, it is supposed that ν = 2, i.e. m0 is four times the odd number m2.
For Tr m0
m2 (uω) to be zero with u1 ̸= w−1
1 , u2 must be the polar part of
	
ω2Tr m0
m1 (u1ω1)

−1 so that the sum of Eq. (11) becomes
S2(a, b, ω) =

u1̸=w−1
1
,ψm0(w2Tr m0
m1(u1w1))=b
χ
	
Tr m0
1
	
au−2
1


.
(19)
The Subﬁeld Case. We now restrict to the case w1 = 1, that is ω ∈F∗
2m1
rather than ω ∈F∗
2m0 .
Lemma 8. For a ∈F∗
2m1 and b ∈F∗
4, and ω ∈F∗
2m1 , deﬁne γ ∈F∗
4 by γ =
bψm1 (w2). Then
S2(a, b, ω) = 2

t∈T 1
m1,ψm1(t)=γ
χ (Tr m1
1
(at)) .
(20)
Proof. As w1 = 1, both the multiplicative and additive characters act on the
same inputs so that we can use the function u1 →u1 + u−1
1
to transform the
sum over U1 of Eq. (19) into a sum over T 1
m1:
S2(a, b, ω) =

u1̸=1,ψm1(u2
1+u−2
1 )=bψm1(w2)
χ
	
Tr m1
1
	
a
	
u−2
1
+ u2
1



=

u1̸=1,ψm1(u1+u−1
1 )=bψm1(w2)
χ
	
Tr m1
1
	
a
	
u1 + u−1
1



= 2

t∈T 1
m1,ψm1(t)=bψm1(w2)
χ (Tr m1
1
(at)) .
Remark that the sum in Eq. (20) can be seen as a ﬁrst step toward gener-
alizing the sum computed in Sect. 4 in the odd case: rather than involving u1
directly, it involves its trace t = Tr m0
m1 (u1).
As is customary, the sum over T 1
m1 can be evaluated using sums over all
of F2m1 :
S2(a, b, ω) =

x∈F∗
2m1 ,ψm1 (x)=γ
χ (Tr m1
1
(ax)) −

x∈F∗
2m1 ,ψm1 (x)=γ
χ

Tr m1
1

ax + x−1
.
(21)

A Conjecture About Gauss Sums and Bentness
155
The ﬁrst sum is easily seen to be a cubic sum whereas the computation of the
second sum is more involved.
Proposition 4. For ν = 2, a ∈F∗
2m1 and γ ∈F∗
4. Deﬁne α ∈F∗
4 by α =
ψm1 (a). The following equality holds:

x∈F∗
2m1 ,ψm1(x)=γ
χ (Tr m1
1
(ax)) =
 2m2+1−1
3
if γ = α−1,
−2m2−1
3
if γ ̸= α−1.
(22)
Proof. Let c ∈F∗
2m1 be such that ψm1 (c) = γ. We make the change of variables
x = cx to transform the sum into a cubic sum:

x∈F∗
2m1 ,ψm1(x)=γ
χ (Tr m1
1
(ax)) =

x∈F∗
2m1 ,ψm1(x)=ψm1(c)
χ (Tr m1
1
(ax))
=

x∈F∗
2m1 ,ψm1(x)=1
χ (Tr m1
1
(acx))
= 1
3

x∈F∗
2m1
χ
	
Tr m1
1
	
acx3

= 1
3 (Cm1(ac, 0) −1) .
Carlitz’s results [2] give explicit values for this cubic sum when m1 is even and
m2 is odd.
Proposition 5. For ν = 2, a ∈F∗
2m1 and γ ∈F∗
4. Deﬁne α ∈F∗
4 by α =
ψm1 (a). The following equality holds:

x∈F∗
2m1 ,ψm1 (x)=γ
χ

Tr m1
1

ax + x−1
=
 1
3 (2Cm1(a, a) + Km1(a) −1) if γ = α,
1
3 (−Cm1(a, a) + Km1(a) −1) if γ ̸= α.
(23)
Proof. First remark that summing over the three possible values of γ yields

x∈F∗
2m1
χ
	
Tr m1
1
	
ax + x−1

= Km1(a) −1.
Moreover, making the change of variable x = (ax)−1 shows that the sum takes
the same value for γ and α−1γ−1. In particular, it takes the same value for αβ
and αβ2, where β ∈F∗
4 is a primitive third root of unity, that is for the elements
of F∗
4 diﬀerent from α, and this value can be deduced from the value for γ = α
which we now compute.

156
J.-P. Flori
Denote by r a square root of a. The change of variable x = rx and properties
of the Dickson polynomial D3 when m1 is even show that for γ = α = ψm1
	
r−1
:

x∈F∗
2m1 ,ψm1 (x)=α
χ

Tr m1
1

ax + x−1
=

x∈F∗
2m1 ,ψm1 (x)=1
χ

Tr m1
1

r

x + x−1
= 1
3

x∈F∗
2m1
χ

Tr m1
1

r

x3 + x−3
= 1
3

x∈F∗
2m1
χ

Tr m1
1

rD3(x + x−1)

= 1
3
⎛
⎜
⎝2

t∈T 0
m1
χ (Tr m1
1
(rD3(t))) −1
⎞
⎟
⎠
= 1
3
⎛
⎜
⎝2Cm1(r, r) −2

t∈T 1
m1
χ (Tr m1
1
(rt)) −1
⎞
⎟
⎠
= 1
3 (2Cm1(r, r) + Km1(r) −1)
= 1
3 (2Cm1(a, a) + Km1(a) −1) .
Equations (22) and (23) give the following expression for S2(a, b, ω).
Theorem 2. For ν = 2, a ∈F∗
2m1 and b ∈F∗
4, and ω ∈F∗
2m1 , let γ = bψm1 (w2).
Then the sum S2(a, b, ω) is
S2(a, b, ω) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
1
3
	
2m2+1 −2Cm1(a, a) −Km1(a)

if γ = α and γ = α−1,
1
3 (−2m2 −2Cm1(a, a) −Km1(a)) if γ = α and γ ̸= α−1,
1
3
	
2m2+1 + Cm1(a, a) −Km1(a)

if γ ̸= α and γ = α−1,
1
3 (−2m2 + Cm1(a, a) −Km1(a))
if γ ̸= α and γ ̸= α−1.
(24)
Carlitz’s results [2] recalled in Sect. 2.8 can be used to make the cubic sum
Cm1(a, a) explicit. In the particular case where Km1(a) ≡1 (mod 3), which is
equivalent to Cm1(a, a) = 0 and implies that a is a cube, the expression for
S2(a, b, ω) gets very concise, as does Eq. (12) for the Walsh transform.
Corollary 1. For ν = 2, a ∈F∗
2m1 with Km1(a) ≡1 (mod 3) and b ∈F∗
4, and
ω ∈F∗
2m1 , let γ = bψm1 (w2). Then the sum S2(a, b, ω) is
S2(a, b, ω) = 2m2+1 −Km1(a)
3
−Tr 2
1 (γ) 2m2.
(25)
and the Walsh transform at ω ̸= 0 is

χfa,b(ω) = χ
	
Tr 2
1 (γ)

2m1 + 4 −Km1(a)
3
.
(26)

A Conjecture About Gauss Sums and Bentness
157
Note that Corollary 1 shows that for ω ∈F∗
2m1 the Walsh transform of fa,b at ω
is that of a bent function if and only if Km1(a) = 4.
5.4
A Conjectural General Formula
The techniques used in the previous section do not apply to the general case
where w1 ̸= 1, i.e. ω ∈F∗
2m0 . The main reason being that the multiplicative
and additive characters of F2m1 act on diﬀerent values, e.g. r = Tr m0
m1 (w1u1),
or s = Tr m0
m1
	
w−1
1 u1

, for one of them, and t = Tr m0
m1 (u1) for the other one.
Considering v = Tr m0
m1 (w1), these values are related by r + s = vt. Moreover,
the sum S2(a, b, ω) takes the same value for w1 and w−1
1 , so there is hope to
introduce enough symmetry to reduce the case w1 ̸= 1 to the case w1 = 1.
Unfortunately, we could not devise a way to do so.
Yet, experimental evidence presented in more details in Sect. 5.5 suggests
that the following conjecture, which relates the value of S2(a, b, ω) for w1 = 1
and w1 ̸= 1, is true.
Conjecture 2. For ν = 2, a ∈F∗
2m1 with Km1(a) ≡1 (mod 3) and b ∈F∗
4, and
ω ∈F∗
2m0 , let γ = bψm1 (w2). There exists a Boolean function ha,b(ω) such that
the sum S2(a, b, ω) is
S2(a, b, ω) = 2m2+1 −Km1(a)
3
−2fa(w−1
1 )2m2+1 −1
3
−ha,b(ω)χ

fa(w−1
1 )

2m2.
(27)
The Walsh transform at ω ̸= 0 is then

χfa,b(ω) = χ
	
ha,b(ω)fa(w−1
1 )

2m1 + 4 −Km1(a)
3
.
(28)
In particular, this conjecture implies Conjecture 1: if Km1(a) = 4, then fa,b is
bent. (And Corollary 1 already does so when ω ∈F∗
2m1 .)
5.5
Experimental Data
The computation of S2(a, b, ω) was implemented in C and assembly1, using AVX
extensions for the arithmetic of F∗
2m0 , PARI/GP [21] to compute the Klooster-
man sums Km1(a), and Pthreads [12] for parallelization.
The computational cost of verifying Conjecture 2 can be somewhat leveraged
using elementary properties of S2(a, b, ω):
– it only depends on the cyclotomic class of a ∈F∗
2m1 ,
– it is the same for w1 and w−1
1 ,
– the inner value can be computed at the same time for u1 and u−1
1 .
1 The source code is available at https://github.com/jpﬂori/expsums.

158
J.-P. Flori
Whatsoever, there are:
– 3 values of γ ∈F∗
4,
– ˜O(2m1) values of a ∈F∗
2m1 ,
– 2m1−1 values of w1 ∈U1\ {1},
– ˜O(2m1) operations in F2m0 for each triple (γ, a, w1).
Therefore, checking the conjectured formula for S2(a, b, ω) over F2m0 has time
complexity ˜O(23m1) which quickly becomes overcostly (and is comparable to
that of computing the Walsh spectrum for every cyclotomic class of a ∈F∗
2m1
which has time complexity ˜O(23m1) as well but space complexity ˜O(2m1)).
Still, we checked Conjecture 2:
– completely for m2 = 3, 5, 7, 9,
– for i up to 3405 where a = zi and z is a primitive element of F2m1 for m2 = 11.
Finally, assuming Km1(a) ≡1 (mod 3) and Conjecture 2 is correct, Parse-
val’s equality yields the following relation:

x∈F∗
2m0
χ
	
ha,b(ω)fa(w−1
1 )

= 2m1 −1
3
(Km1(a) −1)
= 
χfa,b(0) −1.
This is supported by experimental evidence that there are exactly 2m1−1 +
(5/6) (Km1(a) −4)+3 (respectively 2m1−1 −(1/6) (Km1(a) −4)) values of w1 ∈
U1 such that ha,b(ω)fa(w−1
1 ) is zero when γ = 1 (respectively γ ̸= 1).
6
Further Research and Open Problems
Hopefully, Conjecture 2 can be proved using similar techniques as the ones used
by Mesnager [18,19] and in this note. Otherwise, more involved techniques could
be tried, e.g. considering a whole family of sums as a whole and their geometric
structure. Another possibility would be to directly treat the general Gauss sums
of Eqs. (1) and (11) without focussing on the case ν = 2.
References
1. Ahmadi, O., Granger, R.: An eﬃcient deterministic test for Kloosterman sum zeros.
CoRR abs/1104.3882 (2011)
2. Carlitz, L.: Explicit evaluation of certain exponential sums. Math. Scand. 44(1),
5–16 (1979)
3. Charpin, P., Gong, G.: Hyperbent functions, Kloosterman sums, and Dickson poly-
nomials. IEEE Trans. Inf. Theory 54(9), 4230–4238 (2008)
4. Charpin, P., Helleseth, T., Zinoviev, V.: The divisibility modulo 24 of Klooster-
man sums on GF(2m), m odd. J. Comb. Theory Ser. A 114(2), 322–338 (2007).
http://dx.doi.org/10.1016/j.jcta.2006.06.002

A Conjecture About Gauss Sums and Bentness
159
5. Charpin, P., Helleseth, T., Zinoviev, V.: Divisibility properties of Kloosterman
sums over ﬁnite ﬁelds of characteristic two. In: IEEE International Symposium on
Information Theory, ISIT 2008, pp. 2608–2612 (2008)
6. Charpin, P., Helleseth, T., Zinoviev, V.: Divisibility properties of classical binary
Kloosterman sums. Discret. Math. 309(12), 3975–3984 (2009)
7. Dillon, J.F.: Elementary Hadamard Diﬀerence Sets. ProQuest LLC, Ann Arbor,
MI
(1974).
http://gateway.proquest.com/openurl?url ver=Z39.88-2004&rft val
fmt=info:oﬁ/fmt:kev:mtx:dissertation&res dat=xri:pqdiss&rft dat=xri:pqdiss:
7501799, thesis (Ph.D.)–University of Maryland, College Park
8. Dillon, J.F., Dobbertin, H.: New cyclic diﬀerence sets with Singer parameters.
Finite Fields Appl. 10(3), 342–389 (2004)
9. Flori, J.-P., Mesnager, S., Cohen, G.: Binary Kloosterman sums with value 4. In:
Chen, L. (ed.) IMACC 2011. LNCS, vol. 7089, pp. 61–78. Springer, Heidelberg
(2011). doi:10.1007/978-3-642-25516-8 5
10. G¨olo˘glu, F., Lisonˇek, P., McGuire, G., Moloney, R.: Binary Kloosterman sums
modulo 256 and coeﬃcients of the characteristic polynomial. IEEE Trans. Inf.
Theory PP(99), 1 (2012)
11. G¨olo˘glu, F., McGuire, G., Moloney, R.: Binary Kloosterman sums using Stick-
elberger’s theorem and the Gross-Koblitz formula. Acta Arith. 148(3), 269–279
(2011). http://dx.doi.org/10.4064/aa148-3-4
12. Austin Group: Standard for Information Technology: Portable Operating System
Interface (POSIX(R)) Base Speciﬁcations, Issue 7. IEEE Std 1003.1, 2013 Edition
(incorporates IEEE Std 1003.1-2008, and IEEE Std 1003.1-2008/Cor 1-2013), pp.
1–3906, April 2013
13. Katz, N., Livn´e, R.: Sommes de Kloosterman et courbes elliptiques universelles en
caract´eristiques 2 et 3. C. R. Acad. Sci. Paris S´er. I Math. 309(11), 723–726 (1989)
14. Lachaud, G., Wolfmann, J.: Sommes de Kloosterman, courbes elliptiques et codes
cycliques en caract´eristique 2. C. R. Acad. Sci. Paris S´er. I Math. 305(20), 881–883
(1987)
15. Leander, G.: Monomial bent functions. IEEE Trans. Inf. Theory 52(2), 738–743
(2006)
16. Lisonˇek, P.: On the connection between Kloosterman sums and elliptic curves. In:
Golomb, S.W., Parker, M.G., Pott, A., Winterhof, A. (eds.) SETA 2008. LNCS, vol.
5203, pp. 182–187. Springer, Heidelberg (2008). doi:10.1007/978-3-540-85912-3 17
17. Mesnager, S.: A new family of hyper-bent Boolean functions in polynomial form.
In: Parker, M.G. (ed.) IMACC 2009. LNCS, vol. 5921, pp. 402–417. Springer,
Heidelberg (2009). doi:10.1007/978-3-642-10868-6 24
18. Mesnager, S.: Bent and hyper-bent functions in polynomial form and their link
with some exponential sums and Dickson polynomials. IEEE Trans. Inf. Theory
57(9), 5996–6009 (2011)
19. Mesnager, S.: A new class of bent and hyper-bent Boolean functions in polynomial
forms. Des. Codes Cryptogr. 59(1–3), 265–279 (2011)
20. Moloney, R.: Divisibility properties of Kloosterman sums and division polynomials
for Edward curves. Ph.D. thesis, University College Dublin (2011)
21. The PARI Group, Bordeaux: PARI/GP, version 2.7.0 (2014). http://pari.math.
u-bordeaux.fr/

Generalized Bent Functions and Their Gray
Images
Thor Martinsen1, Wilfried Meidl2, and Pantelimon St˘anic˘a1(B)
1 Department of Applied Mathematics, Naval Postgraduate School,
Monterey, CA 93943–5216, USA
{tmartins,pstanica}@nps.edu
2 Johann Radon Institute for Computational and Applied Mathematics,
Austrian Academy of Sciences, Altenbergerstrasse 69, 4040 Linz, Austria
meidlwilfried@gmail.com
Abstract. In this paper we prove that generalized bent (gbent) func-
tions deﬁned on Fn
2 with values in Z2k are regular, and show connections
between the (generalized) Walsh spectrum of these functions and their
components. Moreover we analyze generalized bent and semibent func-
tions with values in Z16 in detail, extending earlier results on gbent
functions with values in Z4 and Z8.
1
Introduction
Let Vn be an n-dimensional vector space over F2 and for an integer q, let Zq be
the ring of integers modulo q. For a generalized Boolean function f from Vn to
Zq the generalized Walsh-Hadamard transform is the complex valued function
H(q)
f (u) =

x∈Vn
ζf(x)
q
(−1)⟨u,x⟩,
ζq = e
2πi
q ,
where ⟨u, x⟩denotes a (nondegenerate) inner product on Vn (we shall use ζ,
Hf, instead of ζq, respectively, H(q)
f , when q is ﬁxed). Throughout, we identify
Vn with the vector space Fn
2 of n-tuples over F2, and we use the regular scalar
(inner) product ⟨u, x⟩= u · x. We denote the set of all generalized Boolean
functions by GBq
n and when q = 2, by Bn.
We recall that for q = 2, where the generalized Walsh-Hadamard transform
of f reduces to the conventional Walsh-Hadamard transform
Wf(u) =

x∈Vn
(−1)f(x)(−1)u·x,
a function f for which |Wf(u)| = 2n/2 for all u ∈Vn is called a bent function.
Similarly, we say that function f : Vn →Zq is a generalized bent (gbent) if
The rights of this work are transferred to the extent transferable according to title
17 §105 U.S.C.
c
⃝Springer International Publishing AG 2016 (outside the US)
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 160–173, 2016.
DOI: 10.1007/978-3-319-55227-9 12

Generalized Bent Functions and Their Gray Images
161
|Hf(u)| = 2n/2 for all u ∈Vn. Further recall that f ∈Bn is called plateaued if
|Wf(u)| ∈{0, 2(n+s)/2} for all u ∈Vn for a ﬁxed integer s depending on f (we
also call f then s-plateaued). If s = 1 (n must then be odd), or s = 2 (n must
then be even), we call f semibent. With this notation, a semibent function is an
s-plateaued Boolean function with smallest possible s > 0. Accordingly we call
a function f ∈GBq
n, with q = 2k, k > 1, generalized semibent (gsemibent, for
short) if |Hf(u)| ∈{0, 2(n+1)/2} for all u ∈Vn, and more general, generalized
s-plateaued if |Hf(u)| ∈{0, 2(n+s)/2} for all u ∈Vn.
Let f : Vm →Zq. If 2k−1 < q ≤2k, we associate a unique sequence of
Boolean functions ai : Vm →F2, 1 ≤i ≤k, such that (the addition below is
in Zq)
f(x) = a1(x) + · · · + 2k−1ak(x), for all x ∈Vm.
If q = 2k, following Carlet [1], we further deﬁne the generalized Gray map ψ(f) :
GBq
n →Bn+k−1 by ψ(f)(x, y1, . . . , yk−1) = k−1
i=1 ai(x)yi ⊕ak(x).
Generalized bent functions were introduced in [7] in connection with appli-
cations in CDMA systems, and lately have attracted increasing attention, see
e.g. [2,3,8,9].
In [8,9] gbent functions f(x) = a1(x) + 2a2(x) in GB4
n and f = a1(x) +
2a2(x) + 22a3(x) in GB8
n were completely characterized in terms of properties
of the Boolean functions ai(x). In particular, relations between gbentness of f
and bentness of associated Boolean functions have been investigated. In [9] it
was moreover shown that f ∈GB4
n, with f(x) = a1 + 2a2(x), a1, a2 ∈Bn, is
gbent if and only if the Gray image ψ(f) is bent if n is odd, or semibent and
the associated a2 and a1 ⊕a2 have complementary autocorrelation if n is even
(see [9] for the details). Currently one observes a lot of research activities on
gbent functions for general k, and we expect that many more general results
will be discovered in the near future. Our generalizations in Sect. 2, where we
analyze gbent functions in terms of their components, are some ﬁrst results.
In particular we show that a gbent function in even dimension is an aﬃne
space of bent functions and we decompose a gbent function in GB2k
n
into two
gbent functions in GB2k−1
n
. In Sect. 3 we analyze gbent functions in GB16
n
in
detail.
2
Gbent Functions and Their Components
In accordance with the terminology for bent functions, we call a gbent function
f ∈GBq
n regular, if Hf(u) = 2n/2ζf ∗(u)
q
for some function f ∗∈GBq
n. We start
with a theorem about the regularity of gbent functions, which is also of indepen-
dent interest. We prove the result by modifying a method of Kumar et al. [6].
Theorem 1. All gbent functions f ∈GB2k
n
are regular, except for n odd and
k = 2, in which case we have H4
f(u) = 2
n−1
2 (±1 ± i).
Proof. If k = 1, the result is known, as we are dealing with classical bent func-
tions. Let k ≥2. Let ζ = e
2πi
2k be a 2k-primitive root of unity. It is known that

162
T. Martinsen et al.
Z[ζ] is the ring of algebraic integers in the cyclotomic ﬁeld Q(ζ). We recall some
facts from [6] (we change the notations slightly). The decomposition for the ideal
generated by 2 in Z[ζ] has the form ⟨2⟩= P 2k−1, where P = ⟨1 −ζ⟩is a prime
ideal in Z[ζ]. The decomposition group
G2 = {σ in the Galois group of Q(ζ)/Q | σ(P) = P}
contains also the conjugation isomorphism σ∗(z) = z−1 (Proposition 2 in [6]).
Observe that H(2k)
f
(u)H(2k)
f
(u) = 2n. Now, as in Property 7 of [6], observing
that our generalized Walsh transform is simply S(f, 2k−1u) (in the notations of
Kumar et al. [6]; u is a binary vector in our case), then H(2k)
f
(u) and H(2k)
f
(u)
will generate the same ideal in Z[ζ] and so, 2−n(H(2k)
f
(u))2 is a unit, and conse-
quently, 2−n/2H(2k)
f
(u) is an algebraic integer. Therefore, by Proposition 1 of [6]
(which, in fact, is an old result of Kronecker from 1857), 2−n/2H(2k)
f
(u) must be
a root of unity. That alone would still not be enough to show regularity since
this root of unity may be in a cyclotomic ﬁeld outside Q(ζ), however, that is
not the case here, since the Gauss quadratic sum G(2k) =
2k−1

i=0
ζi2 = 2k/2(1 + i)
and so,
√
2 ∈Q(ζ), unless k = 2 (since then 1 + i ̸∈Q(ζ)). The ﬁrst assertion is
shown for n even, as well as for n odd with k ≥3.
When n is odd and k = 2, then H(4)
f (u) = 
u∈Vn if(u)(−1)u·x = a + bi, for
some integers a, b. Since f is gbent, with |H(4)
f (u)|2 = 2n we get the diophantine
equation a2 + b2 = 2n. If n is even, the only solutions are (a, b) = (±2n/2, 0), or
(0, ±2n/2). If n is odd, the solutions are (a, b) = (±2⌊n/2⌋, ±2⌊n/2⌋) (independent
choices of signs). The theorem is shown.
From the deﬁnition of a Boolean bent function via the Walsh-Hadamard
transform we immediately obtain the following equivalent deﬁnition, where we
denote the support of a Boolean function f by supp(f) := {x ∈Vn : f(x) = 1}:
A Boolean function f : Vn →F2 is bent if and only if for every u ∈Vn the
function fu(x) := f(x)⊕u·x satisﬁes |supp(fu)| = 2n−1 ±2n/2. Our next target
is to show an analog description for gbent functions. We use the following lemma.
Lemma 1. Let q = 2k, k > 1, ζ = e2πi/q. If ρl ∈Q, 0 ≤l ≤q −1 and
q−1
l=0 ρlζl = r is rational, then ρj = ρ2k−1+j, for 1 ≤j ≤2k−1 −1.
Proof. Since ζ2k−1+l = −ζl for 0 ≤l ≤2k−1 −1, we can write every element z
of the cyclotomic ﬁeld Q(ζ) as
z =
2k−1−1

l=0
λlζl, λl ∈Q, 0 ≤l ≤2k−1 −1.

Generalized Bent Functions and Their Gray Images
163
As [Q(ζ) : Q] = ϕ(q) = 2k−1 (ϕ is Euler’s totient function), the set {1, ζ, . . . ,
ζ2k−1−1} is a basis of Q(ζ). Since
0 =
q−1

l=0
ρlζl −r = (ρ0 −ρ2k−1 −r) +
2k−1−1

l=1
(ρj −ρ2k−1+j)ζl,
the assertion of the lemma follows.
Proposition 1. Let n = 2m be even, and for a function f : Vn →Z2k and
u ∈Vn, let fu(x) = f(x) + 2k−1(u · x), and let b(u)
j
= |x ∈Vn : fu(x) = j}|,
0 ≤j ≤2k −1. Then f is gbent if and only if for all u ∈Vn there exists an
integer ρu, 0 ≤ρu ≤2k−1 −1, such that
b(u)
2k−1+ρu = b(u)
ρu ± 2m and b(u)
2k−1+j = b(u)
j
, for 0 ≤j ≤2k−1 −1, j ̸= ρu.
Proof. First suppose that f is gbent. Then by Theorem 1, f is a regular gbent
function. Hence
Hf(u) =

x∈Vn
ζf(x)(−1)u·x =

x∈Vn
ζf(x)+2k−1(u·x) = Hfu(0) =
2k−1

j=0
b(u)
j
ζj = 2mζr
for some 0 ≤r ≤2k −1. With ρu = r if 0 ≤r ≤2k−1 −1, and ρu = r −2k−1
otherwise, the claim follows from Lemma 1.
The converse statement is veriﬁed in a straightforward manner.
We now can present connections between gbent functions and their compo-
nents for the general case of gbent functions in GB2k
n , k > 1. This generalizes
the corresponding results for k = 2 and k = 3 in [8] and in [9].
Theorem 2. Let n be even, and let f(x) be a gbent function in GB2k
n , k > 1,
(uniquely) given as
f(x) = a1(x) + 2a2(x) + · · · + 2k−2ak−1(x) + 2k−1ak(x),
ai ∈Bn, 1 ≤i ≤k. Then all Boolean functions of the form
gc(x) = c1a1(x) ⊕c2a2(x) ⊕· · · ⊕ck−1ak−1(x) ⊕ak(x),
c = (c1, c2, . . . , ck−1) ∈Fk−1
2
, are bent functions.
Proof. As in Proposition 1, for the gbent function f we denote by fu the function
fu(x) = a1(x) + · · · + 2k−2ak−1(x) + 2k−1(ak(x) + u · x) in GB2k
n . Again, the
integer b(u)
r
, 0 ≤r ≤2k −1, is deﬁned as b(u)
r
= |{x ∈Vn : fu(x) = r}|. By
Proposition 1, b(u)
r+2k−1 = b(u)
r
for all 0 ≤r ≤2k−1 −1, except for one element
ρu ∈{0, . . . , 2k−1 −1} depending on u, for which b(u)
ρu+2k−1 = b(u)
ρu ± 2n/2.
Since it is somewhat easier to follow, we ﬁrst show the bentness of ak(x) =
g0(x). In the second step we show the general case.

164
T. Martinsen et al.
For r ̸= ρu, 0 ≤r ≤2k−1 −1, consider all x ∈Vn for which a1(x) + · · · +
2k−2ak−1(x) = r. Since b(u)
r+2k−1 = b(u)
r
, for exactly half of these x we have
ak(x) + u · x = 0 (note that the number of these x must be even). Among
all x ∈Vn for which a1(x) + · · · + 2k−2ak−1(x) = ρu, there are b(u)
ρu for which
ak(x)+u·x = 0, and there are b(u)
ρu+2k−1 = b(u)
ρu ±2n/2 for which ak(x)+u·x = 1.
Hence for the Walsh-Hadamard transform of ak we get
Wak(u) =

x∈Vn
(−1)ak(x)⊕u·x = ±2n/2,
which shows that ak is bent.
To show that gc is bent for every c ∈Fk−1
2
, we write fu(x), u ∈Vn, as
fu(x) = c1a1(x) + · · · + ck−12k−2ak−1(x) + ¯c1a1(x) + · · · + ¯ck−12k−2ak−1(x)
+ 2k−1(ak(x) + u · x) := h(x) + ¯h(x) + 2k−1(ak(x) + u · x),
where ¯c = c ⊕1. Note that every 0 ≤r ≤2k−1 −1 in the value set of a1(x) +
· · · + 2k−2ak−2(x) has then a unique representation as h(x) + ¯h(x). Consider x
for which h(x) + ¯h(x) = r + s ̸= ρu. Again from b(u)
r+2k−1 = b(u)
r
we infer that for
half of those x we have ak(x) ⊕u · x = 0. Hence also
gc(x) ⊕u · x = c1a1(x) ⊕· · · ⊕ck−1ak−1(x) ⊕ak(x) ⊕u · x = 0
for exactly half of those x. (Observe that h(x1) = h(x2) = r implies c1a1(x1) ⊕
· · · ⊕ck−1ak−1(x1) = c1a1(x2) ⊕· · · ⊕ck−1ak−1(x2).) Similarly as above, among
all x ∈Vn for which h(x)+¯h(x) = ρu, there are b(u)
ρu for which ak(x)⊕u·x = 0,
and there are b(u)
ρu+2k−1 = b(u)
ρu ± 2n/2 for which ak(x) ⊕u · x = 1. From this we
conclude that |{x ∈Vn
:
h(x) + ¯h(x) = ρu and fu(x) = 1}| −|{x ∈Vn
:
h(x) + ¯h(x) = ρu and fu(x) = 0}| = ±2n/2. Therefore
Wgc(u) =

x∈Vn
(−1)gc(x)+u·x = ±2n/2,
and gc is bent.
We remark that the necessary conditions in Theorem 2 are not suﬃcient when
k > 2. The additional conditions on the Walsh spectra for k = 3 given in [9,
Theorem 19] and for k = 4 given in our Theorem 7 are required, as one can easily
conﬁrm with examples employing vectorial Maiorana-McFarland bent functions.
The next result on the decomposition of a gbent function in GB2k
n into two
gbent functions in GB2k−1
n
reveals an inductive approach to the study of gbent
functions in GB2k
n . Note that for k = 2 we recover the result in [9] on the
decomposition of a gbent function in GB4
n into two bent functions.

Generalized Bent Functions and Their Gray Images
165
Theorem 3. Let f ∈GB2k
n with f(x) = g(x) + 2h(x), g ∈Bn, h ∈GB2k−1
n
. If n
is even, then the following statements are equivalent.
(i) f is gbent in GB2k
n ;
(ii) h and h + 2k−2g are both gbent in GB2k−1
n
with Hh+2k−2g(u) = ±Hh(u), for
all u ∈Vn.
If n is odd, then (ii) implies (i).
Proof. We ﬁrst show that for n even, h and h+2k−2g are gbent in GB2k−1
n
if f is
gbent in GB2k
n . In a second step, we show that if h and h+2k−2g are both gbent
in GB2k−1
n
, then f is gbent in GB2k
n if and only if H(2k−1)
h
(u) = ±H(2k−1)
h+2k−2g(u),
for all u ∈Vn. This will conclude the proof for both, n even and n odd.
Let u ∈Vn, and for e ∈{0, 1} and r ∈{0, . . . , 2k−1 −1}, let
S(u)(e, r) = {x ∈Vn : g(x) = e and h(x) + 2k−2(u · x) = r}.
With the notations of Proposition 1, we have fu(x) = f(x)+2k−1(u·x) = g(x)+
2(h(x) + 2k−2(u · x)), and |S(u)(e, r)| = b(u)
e+2r. If f is gbent, by Proposition 1,
there exist ϵ ∈{0, 1} and 0 ≤ρu ≤2k−2 −1, for which |S(u)(ϵ, ρu + 2k−2)| =
|S(u)(ϵ, ρu)| ± 2n/2. For (e, r) ̸= (ϵ, ρu), we have |S(u)(e, r + 2k−2)| = |S(u)(e, r)|.
Observing that {x ∈Vn : h(x) + 2k−2(u · x) = r} = S(u)(0, r) ∪S(u)(1, r), we
obtain
H(2k−1)
h
(u) =

x∈Vn
ζh(x)
2k−1(−1)u·x =

x∈Vn
ζh(x)+2k−2(u·x)
2k−1
= ±ζρu
2k−12n/2.
Consequently, h is gbent in GB2k−1
n
. For h + 2k−2g ∈GB2k−1
n
we have
H(2k−1)
h+2k−2g(u) =

x∈Vn
ζh(x)+2k−2(u·x)+2k−2gx
2k−1
=

e∈F2
r∈Z2k−1

x∈S(u)(e,r)
ζr+2k−2e
2k−1
=

e∈F2
r∈Z2k−1
|S(u)(e, r)|ζr+2k−2e
2k−1
= ±ζρu+2k−2ϵ
2k−1
2n/2,
which implies that also h + 2k−2g is gbent in GB2k−1
n
.
To show the condition H(2k−1)
h
(u) = ±H(2k−1)
h+2k−2g(u), we ﬁrst observe that
2H(2k)
f
(u) = 2

x∈Fn
2
ζg(x)
2k
ζh(x)
2k−1(−1)u·x
=

x∈Fn
2

1 + (−1)g(x) + (1 −(−1)g(x))ζ2k

ζh(x)
2k−1(−1)u·x
= (1 + ζ2k)H(2k−1)
h
(u) + (1 −ζ2k)H(2k−1)
h+2k−2g(u).
(1)

166
T. Martinsen et al.
Writing ζ2k = x + yi, H(2k−1)
h
(u) = a + bi and H(2k−1)
h+2k−2g(u) = c + di, from
Eq. (1), taking the complex norm, squaring and rearranging terms (recall that
|ζ2k|2 = x2 + y2 = 1), we get
2|H(2k)
f
(u)|2 = 1
2(a2 + b2)(1 + 2x + x2 + y2) + 1
2(c2 + d2)(1 −2x + x2 + y2)
−(ac + bd)(x2 + y2 −1) + 2(ad −bc)y
= |H(2k−1)
h
(u)|2(1 + x) + |H(2k−1)
h+2k−2g(u)|2(1 −x)
+ 2y ℑ

H(2k−1)
h
(u)H(2k−1)
h+2k−2g(u)

.
(2)
If h, h+2k−2g are gbent, i.e. |H(2k−1)
h
(u)|2 = |H(2k−1)
h+2k−2g(u)|2 = 2n for all u ∈Vn,
then we immediately see that |H(2k)
f
(u)|2 = 2n for all u ∈Vn, and hence f is
gbent if and only if ℑ

H(2k−1)
h
(u)H(2k−1)
h+2k−2g(u)

= 0, for all u ∈Vn.
We now argue that the condition ℑ

H(2k−1)
h
(u)H(2k−1)
h+2k−2g(u)

= 0 is equiv-
alent to Hh+2k−2g(u) = ±Hh(u). For easy writing, let f0, f1 be the gbent
functions in the indices above. By the regularity of gbent functions (when n
is even or k ≥3), Hf0(u) = 2n/2ζi
2k−1, Hf1(u) = 2n/2ζj
2k−1 for some integers
0 ≤i, j ≤2k −1. Hence Hf0(u) Hf1(u) is real if and only if ζj−i
2k
= ±1, i.e. i = j
or i = j + 2k−1 (modulo 2k). Equivalently, Hf1(u) = ±Hf0(u). If n is odd and
k = 2, then Hf(u) = 2n/2ζi
8, i ∈{1, 3, 5, 7}, and the same argument works.
We close this section with some remarks on relations between gbent functions
in GB2k
n , n even, and relative diﬀerence sets. First note that the characters of Vn×
Z2k are χu,a(x, z) = ζaz
2k (−1)⟨u,x⟩, u ∈Vn, a ∈Z2k. Recall that if |χu,a(D)| =
2n/2 for all nonzero a ∈Z2k and all u ∈Vn, then the graph D = {(x, f(x)) : x ∈
Vn} of f forms a relative diﬀerence set in Vn × Z2k (see for instance Sect. 2.4. in
[10]). Equivalently, if af is gbent for all nonzero a, then D is a relative diﬀerence
set. As easily seen, it is suﬃcient that 2tf is gbent for all 0 ≤t ≤k −1. Using
Theorem 2, it is not hard to show that F(x) = (a0(x), . . . , ak−1(x)) is then
a vectorial bent function, hence also a relative diﬀerence set in an elementary
abelian group. Such gbent functions, which seem quite rare, may be of particular
interest for future research. For an example of a class of such gbent functions
obtained from partial spreads we refer to [5].
3
Complete Characterization of Generalized Bent
and Semibent Functions in GB16
n
We write f ∈GB16
n as
f(x) = a1(x) + 2a2(x) + 22a3(x) + 23a4(x)
= b1(x) + 22b2(x) = a1(x) + 2d(x),

Generalized Bent Functions and Their Gray Images
167
where ai(x) ∈Bn, i = 1, 2, 3, 4, b1(x) = a1(x) + 2a2(x), b2(x) = a3(x) + 2a4(x)
are in GB4
n, and d(x) = a2(x) + 2a3(x) + 22a4(x) ∈GB8
n.
Our objective is to show necessary and suﬃcient conditions on the compo-
nents a1, a2, a3, a4, b1, b2, d for the gbentness of f. For the conditions on a1 and
d for the gbentness of a1(x) + 2d(x) when n is even, we can apply Theorem 3:
f(x) = a1(x) + 2d(x) is gbent if and only if d and d + 4a1 are gbent in GB8
n and
H(8)
d (u) = ±H(8)
d+4a1(u) for all u ∈Vn.
We start with a complete characterization of gbent functions in GB16
n in terms
of a1, a2, a3, a4. By this we extend results in [8,9] on gbent functions in GB4
n and
GB8
n. We then also will characterize gsemibent functions f ∈GB16
n in terms of
a1, a2, a3, a4.
Theorem 4. Suppose that f(x) = a1(x) + 2a2(x) + 22a3(x) + 23a4(x), ai ∈Bn,
1 ≤i ≤4. Then f is gbent in GB16
n if and only if the conditions (i) (if n is
even), or (ii) (if n is odd) hold:
(i) For all ci ∈F2, i = 1, 2, 3, the Boolean function c1a1 ⊕c2a2 ⊕c3a3 ⊕a4 is
bent, and for all u ∈Vn we have
Wa4(u)Wa2⊕a4(u) = Wa3⊕a4(u)Wa2⊕a3⊕a4(u)
= Wa1⊕a4(u)Wa1⊕a2⊕a4(u) = Wa1⊕a3⊕a4(u)Wa1⊕a2⊕a3⊕a4(u), and
Wa4(u)Wa3⊕a4(u) = Wa1⊕a4(u)Wa1⊕a3⊕a4(u).
(ii) For all ci ∈F2, i = 1, 2, 3, the Boolean function c1a1 ⊕c2a2 ⊕c3a3 ⊕a4 is
semibent, and for all u ∈Vn we either have
Wa4(u)Wa2⊕a4(u) = Wa1⊕a4(u)Wa1⊕a2⊕a4(u) = ±2n+1 and
Wa3⊕a4(u) = Wa2⊕a3⊕a4(u) = Wa1⊕a3⊕a4(u) = Wa1⊕a2⊕a3⊕a4(u) = 0,
or
Wa2⊕a4(u) = Wa4(u) = Wa1⊕a4(u) = Wa1⊕a2⊕a4(u) = 0 and
Wa3⊕a4(u)Wa2⊕a3⊕a4(u) = Wa1⊕a3⊕a4(u)Wa1⊕a2⊕a3⊕a4(u) = ±2n+1.
Our proof for Theorem 4 is quite technical and in parts computer-assisted. Hence
we omit is here and present it in the appendix.
The result on the semibentness of functions in GB16
n is obtained with the
same approach. For the proof we again refer to the appendix.
Theorem 5. Let f ∈GB16
n
be given as f(x) = a1(x) + 2a2(x) + 22a3(x) +
23a4(x), ai ∈Bn, 1 ≤i ≤4. Then f is gsemibent when n is odd, and generalized
2-plateaued when n is even, if and only if the Boolean function c1a1 ⊕c2a2 ⊕
c3a3 ⊕a4 is semibent for all ci ∈F2, i = 1, 2, 3, such that for all u ∈Vn their
Walsh-Hadamard transforms are either all zero, or they satisfy
Wa4(u)Wa2+a4(u) = Wa3+a4(u)Wa2+a3+a4(u)
= Wa1+a4(u)Wa1+a2+a4(u) = Wa1+a3+a4(u)Wa1+a2+a3+a4(u), and
Wa4(u)Wa3+a4(u) = Wa1+a4(u)Wa1+a3+a4(u).

168
T. Martinsen et al.
In the light of Theorem 4, one may expect that with a similar approach one
can also show relations between gbentness in GB16
n and in GB4
n. We here only
state the theorem. For the proof we refer to our eprint [4].
Theorem 6. Let f ∈GB16
n with f(x) = a1(x) + 2a2(x) + 22a3(x) + 23a4(x) =
b1(x) + 22b2(x), where b1 = a1 + 2a2, b2 = a3 + 2a4 ∈GB4
n. The function f is
gbent in GB16
n if and only if b2, b1+b2, 2b1+b2, 3b1+b2 are gbent in GB4
n with their
generalized Walsh-Hadamard transforms satisfying the following conditions, (i)
for n even, respectively, (ii) for n odd, for all u ∈Vn:
(i) 2−n/2(H3b1+b2(u), Hb1+b2(u), H2b1+b2(u), Hb2(u)) belongs to one of (ϵ, ϵ, ϵ, ϵ),
(ϵ, ϵ, −ϵ, −ϵ), (ϵ, −ϵ, ϵi, −ϵi), (ϵ −ϵ, −ϵi, ϵi), (ϵi, ϵi, ϵi, ϵi), (ϵi, ϵi, −ϵi, −ϵi),
(ϵi, −ϵi, ϵ, −ϵ), (−ϵi, ϵi, −ϵ, ϵ), where ϵ ∈{±1}.
(ii) 2−(n−1)/2(H3b1+b2(u), Hb1+b2(u), H2b1+b2(u), Hb2(u)) belongs to one of (ϵ+
μi, ϵ + μi, ϵ + μi, ϵ + μi), (ϵ + μi, ϵ + μi, −ϵ −μi, −ϵ −μi), (ϵ + μi, −ϵ −μi, ϵ −
μi, −ϵ + μi), (ϵ + μi, −ϵ −μi, −ϵ + μi, ϵ −μi), for ϵ, μ ∈{±1}.
We close this section with some results on the Gray image ψ(f) of gbent
functions f in GB8
n and GB16
n , extending the corresponding results in [9].
Lemma 2. Let n, k ≥2 be positive integers and ψ : Vn+k−1 →F2 be deﬁned
by ψ(x, y1, y2, . . . , yk−1) = ak(x) ⊕k−1
i=1 yiai(x), where ai ∈Bn, 1 ≤i ≤k.
Denote by a(x) the vectorial Boolean function a(x) = (a1(x), . . . , ak−1(x)) and
let u ∈Vn and v = (v1, . . . , vk−1) ∈Vk−1. The Walsh-Hadamard transform of
ψ at (u, v) is then
Wψ(u, v1, . . . , vk−1) =

α∈Vk−1
(−1)α·vWak⊕α·a(u).
Proof. We will show our claim by induction on k. For k = 2 we have
Wψ(u, v1) =

x∈Vn
y1∈F2
(−1)y1a1(x)⊕a2(x)(−1)v1y1⊕u·x
=

x∈Vn
(−1)a2(x)(−1)u·x +

x∈Vn
(−1)a1(x)⊕a2(x)(−1)v1⊕u·x
= Wa2(u) + (−1)v1Wa1⊕a2(u).
Now let
ψ(x, y1, . . . , yk) = ψ1(x, y1, . . . , yk−1) ⊕ykak(x), where
ψ1(x, y1, . . . , yk−1) = ak+1(x) ⊕
k−1
	
i=1
yiai(x).
Then Wψ(u, v, vk) = Wψ1(u, v) + (−1)vkWψ1⊕ak+1(u, v), which implies our
claim by the induction assumption.

Generalized Bent Functions and Their Gray Images
169
Theorem 7. We have:
(i) Let f(x) = a1(x) + 2a2(x) + 22a3(x) ∈GB8
n be gbent. Then its Gray image
ψ(f) is semibent in Bn+2.
(ii) Let f = a1(x) + 2a2(x) + 22a3(x) + 23a4(x) ∈GB16
n be gbent. Then ψ(f) is
semibent in Bn+3 if n is odd, and 3-plateaued in Bn+3 if n is even.
Proof. (i) By Lemma 2, for ψ(f)(x, y1, y2) = a1(x)y1 + a2(x)y2 + a3(x),
Wψ(f)(u, v1, v2) =Wa3(u) + (−1)v1Wa3⊕a1(u)
+ (−1)v2Wa3⊕a2(u) + (−1)v1+v2Wa3⊕a2⊕a1(u).
(3)
Assume ﬁrst that n is even. Since f is gbent, by [9, Theorem 19], for the
bent components we have Wa3(u)Wa1⊕a2⊕a3(u) = Wa1⊕a3(u)Wa2⊕a3(u), for
all u ∈Vn. Take Wa3(u) = μ1(u)2n/2, Wa3⊕a1(u) = μ2(u)2n/2, Wa3⊕a2(u) =
μ3(u)2n/2, Wa3⊕a2⊕a1(u) = μ4(u)2n/2, for some μi ∈{−1, 1}, 1 ≤i ≤4. Thus,
μ1(u)μ4(u) = μ2(u)μ3(u). Using these in Eq. (3), we obtain
2−n/2Wψ(f)(u, v1, v2) = μ1(u) + (−1)v1μ2(u) + (−1)v2μ3(u) + (−1)v1⊕v2μ4(u).
For (μ1(u), μ2(u), μ3(u), μ4(u)) with values in the set
(−1, −1, −1, −1), (1, 1, −1, −1), (−1, −1, 1, 1), (−1, 1, −1, 1),
(1, −1, −1, 1), (−1, 1, 1, −1), (1, −1, 1, −1), (1, 1, 1, 1),
2−n/2Wψ(f)(u, v1, v2) takes one of the following values
(−1)v1⊕v2⊕1 + (−1)v1⊕1 + (−1)v2⊕1 −1, (−1)v1⊕v2 + (−1)v1⊕1 + (−1)v2 −1,
(−1)v1⊕v2 + (−1)v1 + (−1)v2⊕1 −1, (−1)v1⊕v2⊕1 + (−1)v1 + (−1)v2 −1,
(−1)v1⊕v2 + (−1)v1⊕1 + (−1)v2⊕1 + 1, (−1)v1⊕v2⊕1 + (−1)v1⊕1 + (−1)v2 + 1,
(−1)v1⊕v2⊕1 + (−1)v1 + (−1)v2⊕1 + 1, (−1)v1⊕v2 + (−1)v1 + (−1)v2 + 1.
Therefore, Wψ(f) attains the values 0, ±2(n+4)/2, thus ψ(f) is semibent.
We now consider the case of odd n. Then, by [9, Theorem 19], a3, a1 ⊕
a3, a2 ⊕a3, a1 ⊕a2 ⊕a3 are all semibent and, Wa3(u) = Wa1⊕a3(u) = 0
and |Wa1⊕a2⊕a3(u)| = |Wa2⊕a3(u)| = 2(n+1)/2, or |Wa3(u)| = |Wa1⊕a3(u)| =
2(n+1)/2 and Wa1⊕a2⊕a3(u) = Wa2⊕a3(u) = 0.
Case 1. Let Wa3(u) = Wa1⊕a3(u) = 0, Wa1⊕a2⊕a3(u) = ϵ1(u)2(n+1)/2, Wa2⊕a3
(u) = ϵ2(u)2(n+1)/2, with ϵ1, ϵ2 ∈{−1, 1}. With (3),
Wψ(f)(u, v1, v2) = (−1)v22(n+1)/2 (ϵ1(u) + (−1)v1ϵ2(u)) ,
from which we infer that Wψ(f)(u, v1, v2) ∈{0, ±2(n+3)/2}, for all combina-
tions of ϵi(u) and vi, i = 1, 2. Therefore ψ(f) is semibent.

170
T. Martinsen et al.
Case 2. Let Wa3(u) = ϵ1(u)2(n+1)/2, Wa1⊕a3(u) = ϵ2(u)2(n+1)/2, Wa1⊕a2⊕a3
(u) = Wa2⊕a3(u) = 0, with ϵ1, ϵ2 ∈{−1, 1}. As before, from (3) we obtain
Wψ(f)(u, v1, v2) = 2(n+1)/2 (ϵ1(u) + (−1)v1ϵ2(u)) ,
from which we infer that Wψ(f)(u, v1, v2) ∈{0, ±2(n+3)/2} and therefore ψ(f)
is semibent.
(ii) By Lemma 2, for ψ(f)(x, y1, y2, y3) = a4(x) 3
i=1 yiai(x),
Wψ(f)(u, v1, v2, v3) = Wa4(u) + (−1)v1Wa4⊕a1(u)
+ (−1)v2Wa4⊕a2(u) + (−1)v3Wa4⊕a3(u)
+ (−1)v1⊕v2Wa4⊕a2⊕a1(u) + (−1)v1⊕v3Wa4⊕a3⊕a1(u)
+ (−1)v2⊕v3Wa4⊕a3⊕a2(u) + (−1)v1⊕v2⊕v3Wa4⊕a3⊕a2⊕a1(u).
By going through the 32 cases of Theorem 4 for the Walsh-Hadamard transforms
in the expression above (16 for n even and 16 for n odd), we obtain that the
Walsh-Hadamard spectrum is {0, ±23+n/2} (for n even) and {0, ±22+(n+1)/2}
(for n odd), hence the claim.
Acknowledgements. Work by P.S. started during a very enjoyable visit at RICAM.
Both the second and third named author thank the institution for the excellent working
conditions. The second author is supported by the Austrian Science Fund (FWF)
Project no. M 1767-N26.
A
Appendix
Proof of Theorem 4: Let u ∈Vn. Eq. (2) for k = 4 implies
16
√
2|H(16)
f
(u)|2 = (2 +

2 +
√
2)4
√
2|H(8)
d (u)|2 + (2 −

2 +
√
2)4
√
2|H(8)
d+4a1(u)|2
+ 8

4 −2
√
2 ℑ

H(8)
d (u)H(8)
d+4a1(u)

.
(4)
We denote by A, C, D, W the Walsh-Hadamard transforms Wa4(u), Wa2⊕a4(u),
Wa3⊕a4(u), Wa2⊕a3⊕a4(u) (in that order). We denote by B, X, Y, Z the Walsh-
Hadamard transforms Wa1⊕a4(u), Wa1⊕a2⊕a4(u), Wa1⊕a3⊕a4(u), Wa1⊕a2⊕a3⊕a4
(u) (in that order). By [9, Lemma 17], we know that the generalized Walsh-
Hadamard transform of any function in GB8
n, say d and d + 4a1 with d = a2 +
2a3 + 22a4, is of the form
4H(8)
d (u) = α0A+α1C +α2D +α3W,
4H(8)
d+4a1(u) = α0B +α1X +α2Y +α3Z,
where α0 = 1 + (1 +
√
2)i, α1 = 1 + (1 −
√
2)i, α2 = 1 +
√
2 −i, α3 = 1 −
√
2 −i,
and moreover that (see also [9, Corollary 18]),
4
√
2|H(8)
d (u)|2 = A2 −C2 + 2CD + D2 −2AW −W 2 +
√
2(A2 + C2 + D2 + W 2)
(5)
4
√
2|H(8)
d+4a1(u)|2 = B2 −X2 + 2XY + Y 2 −2BZ −Z2 +
√
2(B2 + X2 + Y 2 + Z2).

Generalized Bent Functions and Their Gray Images
171
Furthermore, with straightforward computations we get
8

4 −2
√
2 ℑ

H(8)
b (u)H(8)
b+4a1(u)

= 2

2 −
√
2 (BC + BD −AX −WX −AY + WY + CZ −DZ)
+ 2

4 −2
√
2 (BD + WX −AY −CZ).
(6)
Using (5) and (6) in Eq. (4) we obtain
16
√
2|H(16)
f
(u)|2
= 2(A2 + B2 −C2 + 2CD + D2 −2AW −W 2 −X2 + 2XY + Y 2 −2BZ −Z2)
+ 2
√
2(A2 + B2 + C2 + D2 + W 2 + X2 + Y 2 + Z2)
+

2 −
√
2 (A2 −B2 + 2BC + C2 + D2 + W 2 −2AX −4WX −X2
(7)
+ 2WY −Y 2 + 4CZ −2DZ −Z2)
+ 2

2 +
√
2 (A2 −B2 + BD + CD + D2 −AW + WX −AY −XY
−Y 2 + BZ −CZ).
If f is gbent in GB16
n , i.e., |H(16)
f
(u)|2 = 2n, by the linear independence of
{1,
√
2,

2 −
√
2,

2 +
√
2} (as easily shown, the set forms a basis of Q(
√
2,

2 −
√
2)), we arrive at the following system of equations with solutions in Z,
A2 + B2 + C2 + D2 + W 2 + X2 + Y 2 + Z2 = 2n+3
A2 + B2 −C2 + 2CD + D2 −2AW −W 2 −X2 + 2XY + Y 2 −2BZ −Z2 = 0
A2 −B2 + 2BC + C2 + D2 + W 2 −2AX −4WX −X2
+ 2WY −Y 2 + 4CZ −2DZ −Z2 = 0
A2 −B2 + BD + CD + D2 −AW + WX −AY −XY −Y 2 + BZ −CZ = 0.
(8)
Let 2t be the largest power of 2 which divides all, A, B, C, D, X, Y, Z and
W, i.e., A = 2tA1, etc., with at least one of the A1, B1, . . . being odd. First, if
n is even and t > n
2 , then t = n
2 + 1 only. Dividing by 22t, the ﬁrst equation
of (8) becomes A2
1 + B2
1 + C2
1 + D2
1 + W 2
1 + X2
1 + Y 2
1 + Z2
1 = 2, which gives the
solution (±1, ±1, 0, 0, 0, 0, 0, 0) (and permutations of these values). However, a
simple computation reveals that none of these possibilities also satisﬁes the last
three equations of (8). If n is odd and t > n+1
2 , then t = n+3
2 , but this implies
that only one value out of A, B, . . . is nonzero. Again, that is impossible to sat-
isfy the last three equations of (8). Assume now that t < n
2 . The ﬁrst equation
of (8) becomes A2
1 + B2
1 + C2
1 + D2
1 + W 2
1 + X2
1 + Y 2
1 + Z2
1 = 2n+3−2t, which is
divisible by 25 (when n is even, since t ≤n−2
2 ), respectively 24 (when n is odd,
since t ≤n−1
2 ). If n is even, this can only happen if A1, B1, . . . , are all even, that
is, ≡0, 2, 4, 6 (mod 8), but that contradicts our assumption that t is the largest
power of 2 dividing A, B, . . .. If n is odd and t ≤n−3
2 , the previous argument
would work, and if t = n−1
2 , then A2
1+B2
1+C2
1 +D2
1+W 2
1 +X2
1 +Y 2
1 +Z2
1 = 16. By

172
T. Martinsen et al.
considering every residues for A1, B1, . . . , modulo 4 and imposing the condition
that the 2nd, 3rd, 4th equations of our system also must be 0 modulo 16, we
only get possibilities (0, 0, 2, 2, 0, 0, 2, 2), (0, 2, 0, 2, 0, 2, 0, 2), (0, 2, 2, 0, 0, 2, 2, 0),
(2, 0, 0, 2, 2, 0, 0, 2), (2, 0, 2, 0, 2, 0, 2, 0), (2, 2, 0, 0, 2, 2, 0, 0) for (A1, B1, . . .) mod-
ulo 4, but that implies that all A1, B1, . . . are even, contradicting our assump-
tion on t. This shows that the only possibility is 2t = 2n/2 if n is even, and
2t = 2(n+1)/2 if n is odd.
Thus, one needs to ﬁnd integer solutions for the equation A2
1+B2
1 +C2
1 +D2
1+
W2
1 +X2
1 +Y 2
1 +Z2
1 = 8, for n even, or A2
1+B2
1 +C2
1 +D2
1+W2
1 +X2
1 +Y 2
1 +Z2
1 = 4
for n odd, which also satisfy the last three equations in (8). Mathematica renders
the following: if n is even, then 2−n
2 (A, C, D, W, B, X, Y, Z) (note the order) is
one of
± (−1, −1, −1, −1, −1, −1, −1, −1),
±(−1, 1, −1, 1, −1, 1, −1, 1),
± (−1, −1, −1, −1, 1, 1, 1, 1),
±(−1, 1, −1, 1, 1, −1, 1, −1),
± (1, −1, −1, 1, −1, 1, 1, −1),
±(1, 1, −1, −1, −1, −1, 1, 1),
(9)
± (1, −1, −1, 1, 1, −1, −1, 1),
±(1, 1, −1, −1, 1, 1, −1, −1),
and, if n is odd, then 2−n+1
2 (A, C, D, W, B, X, Y, Z) is one of
± (−1, 1, 0, 0, −1, 1, 0, 0),
±(−1, 1, 0, 0, 1, −1, 0, 0),
± (0, 0, −1, 1, 0, 0, −1, 1),
±(0, 0, −1, 1, 0, 0, 1, −1),
± (0, 0, 1, 1, 0, 0, −1, −1),
±(0, 0, 1, 1, 0, 0, 1, 1),
± (1, 1, 0, 0, −1, −1, 0, 0),
±(1, 1, 0, 0, 1, 1, 0, 0).
We see that in both cases, if f is gbent, then the conditions of the theorem
are satisﬁed. The converse follows with straightforward calculations.
2
Proof of Theorem 5: Assume that f is gsemibent in GB16
n when n is odd, respec-
tively generalized 2-plateaued when n is even. Then |H(16)
f
(u)| ∈{0, ±2(n+1)/2}
for n odd, respectively, |H(16)
f
(u)| ∈{0, ±2(n+2)/2} for n even. Using the nota-
tions of Theorem 4, from Eq. (7), we immediately get A = B = C = D = X =
Y = W = Z = 0 if H(16)
f
(u) = 0. If |H(16)
f
(u)| = 2(n+1)/2 (for n odd), respec-
tively, |H(16)
f
(u)| = 2(n+2)/2 (for n even), then (7) again yields the system of
Eq. (8) with the one diﬀerence that in the ﬁrst equation the power of 2 on the
right side is 2n+4, respectively, 2n+5. With the same argument as in the proof
of Theorem 4 we see that for such u, 2−n+1
2 (A, C, D, W, B, X, Y, Z) (for n odd),
respectively, 2−n+2
2 (A, C, D, W, B, X, Y, Z) (for n even) can only take the values
from Eq. (9).
Straightforwardly, one conﬁrms that the converse is also true, and the theo-
rem is shown.
2

Generalized Bent Functions and Their Gray Images
173
References
1. Carlet, C.: Z2k-linear codes. IEEE Trans. Inf. Theory 44(4), 1543–1547 (1998)
2. Hod˘zi´c, S., Pasalic, E.: Generalized bent functions-some general construction meth-
ods and related necessary and suﬃcient conditions. Crypt. Commun. 7, 469–483
(2015)
3. Liu, H., Feng, K., Feng, R.: Nonexistence of generalized bent functions from Zn
2 to
Zm. Des. Codes Crypt. 82, 647–662 (2017)
4. Martinsen, T., Meidl, W., St˘anic˘a, P.: Generalized bent functions and their Gray
images. http://arxiv.org/pdf/1511.01438
5. Martinsen, T., Meidl, W., St˘anic˘a, P.: Partial spread and vectorial generalized bent
functions. Des.Codes Crypt. (2017, to appear)
6. Kumar, P.V., Scholtz, R.A., Welch, L.R.: Generalized bent functions and their
properties. J. Comb. Theory - Ser. A 40, 90–107 (1985)
7. Schmidt, K.U.: Quaternary constant-amplitude codes for multicode CDMA. IEEE
Trans. Inform. Theory 55(4), 1824–1832 (2009)
8. Sol´e, P., Tokareva, N.: Connections between quaternary and binary bent functions.
Prikl. Diskr. Mat. 1, 16–18 (2009). http://eprint.iacr.org/2009/544.pdf
9. St˘anic˘a, P., Martinsen, T., Gangopadhyay, S., Singh, B.K.: Bent and generalized
bent Boolean functions. Des. Codes Crypt. 69, 77–94 (2013)
10. Tan, Y., Pott, A., Feng, T.: Strongly regular graphs associated with ternary bent
functions. J. Comb. Theory - Ser. A 117, 668–682 (2010)

Cryptography

Enhanced Digital Signature Using RNS Digit
Exponent Representation
Thomas Plantard1 and Jean-Marc Robert2,3(B)
1 CCISR, SCIT, University of Wollongong, Wollongong, Australia
2 Team DALI, Universit´e de Perpignan Via Domitia, Perpignan, France
jean-marc.robert@univ-perp.fr
3 LIRMM, UMR 5506, Universit´e Montpellier and CNRS, Montpellier, France
Abstract. Digital Signature Algorithm (DSA) involves modular expo-
nentiation, of a public and known base by a random one-time exponent.
In order to speed-up this operation, well-known methods take advantage
of the memorization of base powers. However, due to the cost of the mem-
ory, to its small size and to the latency of access, previous research sought
for minimization of the storage. In this paper, taking into account the
modern processor features and the growing size of the cache memory, we
improve the storage/eﬃciency trade-oﬀ, by using a RNS Digit exponent
representation. We then propose algorithms for modular exponentiation.
The storage is lower for equivalent complexities for modular exponenti-
ation computation. The implementation performances show signiﬁcant
memory saving, up to 3 times for the largest NIST standardized key sizes
compared to state of the art approaches.
Keywords: RNS · Digital signature · Modular exponentiation · Mem-
ory storage · Eﬃcient software implementation
1
Introduction
In the DSS (Digital Signature Standard), DSA (Digital Signature Algorithm)
is a popular authentication protocol. According to the NIST standard (see [3]),
the public parameters are p, q and g. The parameter g is a generator of the
multiplicative group Z/pZ of order q, which is a prime of size corresponding to
the required security level. Therefore, p is a prime chosen such that q divides p−1.
The recommended security levels in the standard are 80–256 bits, corresponding
to 160–512 bit sizes for the prime q. When a server needs to sign a batch of
documents or authentications, the main operations are modular exponentiations
gk mod p (one per signature), where k is a one time random parameter. Taking
advantage of the ﬁxed public parameter g is a natural way to speed-up the
signature protocol, by storing well chosen powers of g. The main known methods
of the state of the art are the one presented by Gordon in [6], which stores the
gRi mod p values, and also the Fixed-base Comb, which is presented by Lim
and Lee in [10]. While improving the complexity, and therefore, lowering the
c
⃝Springer International Publishing AG 2016
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 177–192, 2016.
DOI: 10.1007/978-3-319-55227-9 13

178
T. Plantard and J.-M. Robert
computation time, these methods require some storage. The trade-oﬀbetween
the eﬃciency and the storage amount is the comparison criteria between these
diﬀerent approaches.
All the protocols derived from the DSA can use these diﬀerent approaches,
since they all need an exponentiation of a known base by a random exponent.
Blind signature and E-voting are examples of protocols using ﬁxed-base modular
exponentiation [11]. Moreover, El-Gamal encryption and signature also use a
public generator g to the power of a randomly chosen exponent (see [4]). However,
the decryption uses the result of this operation, and the idea does not apply in
this case.
On the arithmetic side, the Residue Number System (RNS), based on the
Chinese Remainder Theorem, is a classical way to speed-up and/or parallelize
arithmetic computations and was ﬁrst presented by Svoboda in [14] and by
Garner in [5]. One can ﬁnd a complete classical presentation of the RNS in
Knuth [9].
Contributions: In this paper, we propose to use the memorization of base pow-
ers with numeration scales in radix R = m0 · m1 and the RNS representation
of each digit using the base B = {m0, m1}. We study the recoding algorithm
and apply it to the exponent in modular exponentiation. We propose a modular
exponentiation algorithm using this recoding of the exponent and memoriza-
tion. We called this algorithm the m0m1 exponentiation method. We studied
the corresponding complexities and storage amounts, and compared the results
with the Fixed-base Comb and Radix-R methods. We showed that our m0m1
exponentiation method has better storage/complexity trade-oﬀthat the afore-
mentioned methods, for the NIST recommended ﬁeld sizes and a large range of
storage amount. We then made software implementations of our algorithms and
performed tests in order to validate the storage/timing trade-oﬀ. The speed-up
comparison shows the beneﬁts. This approach provides also a fair ﬂexibility in
terms of required storage amount: one can choose the storage amount according
to the device resources available and compatible to the global computation load
of the system.
This paper is organized as follows: Sect. 2, we review the main classical ﬁxed-
base exponentiation algorithms, taking advantage of storage and give their com-
plexities and storage requirements; Sect. 3, we present our approach for the
m0m1 recoding; Sect. 4, we then show the application on modular exponenti-
ation; Sect. 5 shows the implementation strategies and results in terms of per-
formances we got in this work; ﬁnally Sect. 6, we give some concluding remarks
and perspectives.
2
State of the Art Review
In this section, we review the state of the art classical approaches for ﬁxed-base
modular exponentiation.

Enhanced Digital Signature Using RNS Digit Exponent Representation
179
When a server needs to sign a document or a message, the computation
consists of several operations, the main one being a modular exponentiation
gk mod p, with k being a one-time random exponent. This computation can
use the classical Square-and-Multiply algorithm (see Algorithm 1). In terms of
complexity, given the exponent length t (that is, the size of the prime q), the
number of modular squaring is t −1 and the number of modular multiplications
to be computed is t/2 on average, half of this length, for a randomly chosen
exponent. There is no storage in this case.
The method presented by Gordon in [6] ﬁrst suggests to store the t successive
squarings of g (that is the sequence of g2i). In terms of complexity, given the
exponent length t (again, the size of the prime q), one has now no squarings and
the number of modular multiplications to be computed is half of this length on
average as in the previous case, for a randomly chosen exponent. The storage
amount is t values in Z/pZ as mentioned above. Gordon in [6] mentions the
generalization of this idea into a radix R method, which consists of the memo-
rization of the values gi·Rj, with i ∈[1, ..., R −1] and 0 ≤j < ℓwhere ℓis the
radix R length of the exponent, which we denote by w = log2(R) (ℓ= ⌈t/w⌉). In
this case, the complexity is ℓ−1 modular multiplications, for a storage amount
of ℓ·(R−1) values in Z/pZ. In the sequel, we will call this approach the Radix-R
Exponentiation Method (see Algorithm 2).
Algorithm 1. Left-to-Right Square-and-Multiply Modular Exponentiation
Require: k = (kt−1, . . . , k0), the DSA modulus p, g a generator of Z/pZ of order q.
Ensure: X = gk mod p
1: X ←1
2: for i from t −1 downto 0 do
3:
X ←X2 mod p
4:
if ki = 1 then
5:
X ←X · g mod p
6:
end if
7: end for
8: return (X)
Algorithm 2. Radix-R Exponentiation Method
Require: k = (kℓ−1, . . . , k0)R, the DSA modulus p, g a generator of Z/pZ of order q.
Ensure: X = gk mod p
1: Precomputation. Store Gi,j ←gi·Rj, with i ∈[1, ..., R −1] and 0 ≤j < ℓ.
2: X ←1
3: for i from ℓ−1 downto 0 do
4:
X ←X · Gki,i mod p
5: end for
6: return (X)

180
T. Plantard and J.-M. Robert
Algorithm 3. Fixed-base Comb Exponentiation Method
Require: k = (kt−1, . . . , k1, k0)2, the DSA modulus p, g a generator of Z/pZ of order
q, window width w, d = ⌈t/w⌉.
Ensure: X = gk mod p
1: Precomputation. Compute and store g[aw−1,...,a0] mod p,
∀(aw−1, . . . , a0) ∈Zw
2 .
2: By padding k on the left by 0’s if necessary, write k = Kw−1∥. . . ∥K1∥K0, where
each Kj is a bit string of length d. Let Kj
i denote the ith bit of Kj.
3: X ←1
4: for i from d −1 downto 0 do
5:
X ←X2 mod p
6:
X ←X · g[Kw−1
i
,...,K1
i ,K0
i ] mod p
7: end for
8: return (X)
Another classical method is the so called Fixed-base Comb method. In [8],
Hankerson et al. present this method proposed by Lim and Lee in [10]. The
window width w is the number of comb-teeth, and d = ⌈t/w⌉is the distance
in bits between two teeth. This method is shown in Algorithm 3, in which we
denote [aw−1, . . . , a1, a0] = aw−12(w−1)d+. . .+a222d+a12d+a0. The complexity
of this approach is d −1 modular squarings and d multiplications, for a storage
amount of 2w −1 values in Z/pZ. One drawback of this method is the lack of
ﬂexibility for the storage amount, which increases exponentially with respect to
the window width w.
Table 1, we give the complexities and the storage amounts of all these
approaches.
Table 1. Complexities and storage amounts of state of the art methods, average case,
binary exponent length t. #MM denotes the number of modular multiplications, #MS
the number of modular squarings.
#MM
#MS Storage (# values ∈Z/pZ)
Square-and-multiply, Algorithm 1 t/2
t −1
-
Radix-R method, Algorithm 2
⌈t/w⌉
-
⌈t/w⌉· (R −1)
Fixed-base Comb, Algorithm 3
d = ⌈t/w⌉d −1 2w −1
3
m0m1 Recoding
In this section, we present our approach for the m0m1 recoding. Our goal is
to use this representation in a modular exponentiation computation. The RNS
digit representation with two moduli splits the digits in two parts. The ﬁrst
part will be used to select the precomputed values and the second part for ﬁnal
computation of the modular exponentiation, with the best possible trade-oﬀ.

Enhanced Digital Signature Using RNS Digit Exponent Representation
181
3.1
Algorithm
We ﬁrst remind the RNS representation with RNS base B = {m0, m1} of two
moduli. Let R = m0 · m1 and x ∈Z such that 0 ≤x < R. Let us also assume
m0 is prime, since this allows us to invert all integers <m0 modulo m0, and we
choose m1 < m0. In the sequel, we denote |x|m = x mod m.
One represents x with the residues

x(0) = |x|m0
x(1) = |x|m1
and x can be retrieved using the Chinese Remainder Theorem as follows:
x =
x(0) · m1 · |m−1
1 |m0 + x(1) · m0 · |m−1
0 |m1

R .
We now present our recoding approach. Our idea here is to use an exponent
k recoding in radix R = m0 ·m1. We represent every radix-R digits in RNS with
RNS base B = {m0, m1}. Let ki be the digits of k in radix-R, and let us denote
(k(0)
i
, k(1)
i
) their RNS representations in base B. Thus, one has:
k = ℓ−1
i=0 kiRi, with ℓ= ⌈t/ log2(R)⌉,
and

k(0)
i
= |ki|m0,
k(1)
i
= |ki|m1.
Let us denote (when k(1)
i
̸= 0)
m′
0 = m1 · |m−1
1 |m0,
m′
1 = m0 · |m−1
0 |m1,
k′
i = |k(0)
i
· (k(1)
i
)−1|m0.
One keeps κi ←(k′
i, k(1)
i
) as a representation of ki and this leads to ki =
k(1)
i
|k′
i · m′
0 + m′
1|R

R . We handle the modular reduction mod R as follows:
ki = k(1)
i
|k′
i · m′
0 + m′
1|R −⌊k(1)
i
· |k′
i · m′
0 + m′
1|R/R⌋· R.
Let us denote C = ⌊k(1)
i
· (k′
i · m′
0 + m′
1)/R⌋. By noticing that 0 ≤C < m1, we
now consider C as a carry that one can subtract to ki+1. We then compute
if ki+1 ≥C then ki+1 ←ki+1 −C, C ←0, else ki+1 ←ki+1 + R −C, C ←1,
and one gets ki+1 ≥0.
When k(1)
i
= 0, we handle this by slightly rewriting κi as follows: κi =
(|k(0)
i
+ 1|m0 · m′
0 −m′
0), thus keeping κi ←(|k(0)
i
+ 1|m0, 0) as a representation
of ki in this case. In addition, one notices that the carry C is not modiﬁed here
(it is either 0 or 1 and has been previously settled).
The sequence of the κi ←(k′
i, k(1)
i
) is the m0m1 recoding of k we can use to
compute a modular exponentiation.
One notices it might be necessary to process a last carry C, with a ﬁnal
correction. The recoding algorithm is shown in Algorithm 4.

182
T. Plantard and J.-M. Robert
Algorithm 4. m0m1 Recoding
Require: {m0, m1} RNS base with R = m0 · m1, k = ℓ−1
i=0 kiRi.
Ensure: {κi, 0 ≤i < ℓ, (C)}, m0m1 recoding of scalar k.
1: C ←0
2: for i from 0 to ℓ−1 do
3:
ki ←ki −C, C ←0
4:
if ki < 0 then
5:
ki ←ki + R, C ←1
6:
end if
7:
k(0)
i
= |ki|m0, k(1)
i
= |ki|m1.
8:
if k(1)
i
= 0 then
9:
κi ←(|k(0)
i
+ 1|m0, 0)
10:
else
11:
k′
i ←|k(0)
i
· (k(1)
i
)−1|m0
12:
C ←C + ⌊k(1)
i
· |k′
i · m′
0 + m′
1|R/R⌋
13:
κi ←(k′
i, k(1)
i
)
14:
end if
15: end for
16: return {κi, 0 ≤i < ℓ, (−C)}
3.2
Example
We present here an example of m0m1 recoding with an exponent size t of 20 bits
(0 < k < 220), and B = {11, 8} (i.e. m0 = 11, m1 = 8). Thus, in this case, one
has the radix R = m0 · m1 = 88, ℓ= ⌈20/ log2(88)⌉= 4, and therefore
m′
0 = 8 · |8−1|11 = 56,
m′
1 = 11 · |11−1|8 = 33.
Let us take k = 93619210, the random exponent. By rewriting k in radix-R, one
has
k = 48 + 78 · 88 + 32 · 882 + 1 · 883.
We now use Algorithm 4, which consists of a for loop, steps 2 to 15.
– In the ﬁrst iteration (i = 0), one has k0 = 48.
• One has C ←0 and one skips the if-test steps 4 to 6 since k0 ≥0.
• Step 7, one computes the RNS representation in base B of k0 = 48:
k(0)
0
= |k0|11 = 4, k(1)
0
= |k0|8 = 0.
• Steps 6 and 7, since k(1)
0
= 0, one sets
κ0 ←(|k(0)
0
+ 1|11, 0) = (5, 0)
– In the second iteration (i = 1), one has k1 = 78.
• One has C ←0 and one skips the if-test steps 4 to 6 since k1 ≥0.

Enhanced Digital Signature Using RNS Digit Exponent Representation
183
• Step 7, one computes the RNS representation in base B of k1 = 78:
k(0)
1
= |k1|11 = 1, k(1)
1
= |k1|8 = 6.
• Steps 11 and 12, since k(1)
1
̸= 0, one has
|(k(1)
1 )−1|11
←2
k′
1 = |k(0)
1
· (k(1)
1 )−1|11
←2
C ←⌊(k(1)
1
· |k′
1 · 56 + 33|88)/88⌋←3
and ﬁnally
κ1 ←(2, 6)
– In the third iteration (i = 2), one has now k2 ←k2 −C = 29.
• The RNS representation in base B of k2 is k(0)
2
= 7, k(1)
2
= 5.
• The computation steps 11–12 gives C ←2, and
κ2 ←(8, 5).
Without providing all the details, one ﬁnally gives the values returned by the
algorithm:
κ = ((5, 0), (2, 6), (8, 5), (3, 7)), and C = −2.
4
m0m1 Modular Exponentiation
4.1
Algorithm
We now present the use of our recoding in the modular exponentiation. One
wants to compute
gk mod p = g
ℓ−1
i=0 ki·Ri mod p
= g
ℓ−1
i=0 κi·Ri · gC·Rℓmod p
= gC·Rℓ· ℓ−1
i=0 gκi·Ri mod p
with
gκi·Ri mod p = gκ(1)
1
·Ri·|κ′
i·m′
0+m′
1|R mod p, when κ(1)
1
̸= 0
and
gκi·Ri mod p = gRi·|κ′
i·m′
0+m′
1|R · g−Ri·|m′
0+m′
1|R mod p, when κ(1)
1
= 0.
In order to compute the ﬁxed-base modular exponentiation gk mod p, with
p prime, one stores the following values:
Gi,j = gRi·|j·m′
0+m′
1|R mod p, with 0 ≤i ≤ℓ−1, 0 ≤j < m0
and Gℓ,1 = gRℓ·|m′
0+m′
1|R mod p.

184
T. Plantard and J.-M. Robert
The ﬁeld inversion is very costly over Z/pZ, therefore, one also stores the fol-
lowing inverses:
Gi,−1 = g−|m′
0+m′
1|R·Ri mod p avec 0 ≤i ≤ℓ
One uses one value Kj per possible values of 1 ≤κ(1)
i
< m1, that is m1
points. Thus, one now has
Kj =
⎛
⎜
⎝

for all κ(1)
i
=j
Gi,κ(0)
i
⎞
⎟
⎠×

Gℓ,sign(C)1

|C|=j mod p
and
K0 =

for all κ(1)
i
=0
Gi,κ(0)
i
× Gi,−1 mod p.
This leads to
gk
mod p = K0 ×
m1

j=1
Kj
j .
Every single individual modular exponentiation Kj
j is performed with a
square-and-multiply approach, which is more eﬃcient than performing j −1
modular multiplications, even for small m1.
One may notice that the amount of storage is now (m0 + 1) × ℓ+ 1 points.
This approach is depicted in Algorithm 5.
4.2
Example
We now go back to our previous example in Sect. 3.2 page 6. One considers again
the same values and parameters:
– an exponent size t of 20 bits (0 < k < 220), and B = {11, 8}
(i.e. m0 = 11, m1 = 8);
– radix R = m0 · m1 = 88 (ℓ= 4);
– one has k = 93619210;
– and we use the m0m1 recoding previously computed:
κ = ((5, 0), (2, 6), (8, 5), (3, 7)), and C = −2.
We present the computation of gk mod p using Algorithm 5. In terms of storage,
one computes the values
Gi,j = gRi·|j·m′
0+m′
1|R
mod p with 0 ≤i ≤ℓ−1.
One has the following values of |j · m′
0 + m′
1|R for 0 ≤j < 11:
{33, 1, 57, 25, 81, 49, 17, 73, 41, 9, 65}

Enhanced Digital Signature Using RNS Digit Exponent Representation
185
Algorithm 5. Fixed-base m0m1 method modular exponentiation
Require: {m0, m1} RNS base with R = m0m1, k = ℓ−1
i=0 kiRi and κ = {κi, 0 ≤i <
ℓ, (C)} the m0m1 recoding of k, p, the DSA modulus, g ∈Z/pZ, public generator
of order q.
Ensure: X = gk mod p
1: Precomputation. Store Gi,j ←gRi·|j·m′
0+m′
1|R with 0 ≤i < ℓ−1, 0 ≤j <
m0, Gℓ,1 ←gRℓ·|m′
0+m′
1|R, Gi,−1 ←g−Ri·|m′
0+m′
1|R, 0 ≤i ≤ℓ
2: A ←1, Kj ←1 for 0 ≤j < m1
3: for i from 0 to ℓ−1 do
4:
if κ(1)
i
= 0 then
5:
K0 ←K0 × Gi,κ(0)
i
× Gi,−1
6:
else
7:
Kκ(1)
i
←Kκ(1)
i
× Gi,κ(0)
i
8:
end if
9: end for
10: K|C| ←K|C| × Gℓ,sign(C)1
11: W ←size of m1 in bits
12: for i from W downto 0 do
13:
A ←A2
14:
for j from m1 −1 downto 1 do
15:
if bit i of j is non zero then
16:
A ←A × Kj
17:
end if
18:
end for
19: end for
20: return (A × K0)
In our case, with the chosen parameters, this brings us to store the following
values in Z/pZ:
Gi = {g88i·33, g88i, g88i·57, g88i·25, g88i·81, g88i·49, g88i·17, g88i·73, g88i·41, g88i·9, g88i·65}.
We now use κ in Algorithm 5.
– the ﬁrst steps are a for loop (steps 3 to 9):
• in the ﬁrst iteration, one has κ(1)
0
= 0 (and κ(0)
0
= 5), and this gives
K0 ←G0,κ(0)
0
× G0,−1 = g49 × g−1 = g48.
• in the second iteration, one has κ(1)
1
= 6 (and κ(0)
1
= 2), and this gives
K6 ←G1,κ(0)
1
= g88·57 = g5016.
• in the third iteration, one has κ(1)
2
= 5 (and κ(0)
2
= 8), and this gives
K5 ←G1,κ(0)
2
= g882·41 = g317504.

186
T. Plantard and J.-M. Robert
• in the fourth and last iteration, one has κ(1)
2
= 7 (and κ(0)
2
= 3), and this
gives
K7 ←G1,κ(0)
2
= g883·25 = g17036800.
– the last carry C = −2 is now processed (step 10):
K2 ←G4,−1 = g884·(−1) = g−59969536.
– the reconstruction in the second for loop (steps 12 to 16) provides the ﬁnal
result by computing
gk mod p = K0 × m1
j=1 Kj
j mod p
= g48+2·(−59969536)+5·317504+6·5016+7·17036800 mod p
= g936192 mod p,
which is the desired result.
4.3
Complexity
The complexity of Algorithm 5 is evaluated step by step in Table 2 for the average
case. The number of ﬁeld multiplications (MM) is evaluated as follows:
– the MMs in step 5 are performed only in case of K0 ̸= 1, instead, it is only an
instantiation of K0;
– the MMs in step 7 are performed only in case of Kκ(1)
i
̸= 1, instead, it is only
an instantiation of Kκ(1)
i ;
– the same applies for step 10;
This saves on average m1 MMs, and this is taken into account in the Total line
in Table 2 (it explains the −m1 term). The number of operations in the ﬁnal
reconstruction is evaluated as follows:
Table 2. m0m1 modular exponentiation complexity and storage, average case.
Complexity
Step
Operation
Complexity
ℓ/m1 × step 5
K0 ←K0 × Gi,|κ(0)
i
+1|m0 × Gi,−1 2 MM
ℓm1−1
m1
× step 7
Kκ(1)
i
←Kκ(1)
i
× Gi,κ(0)
i
1 MM
1 × step 10
K|C| ←K|C| × Gsign(C)
ℓ,1
1 MM
(W −1) × step 13
A ←A2
1 MS
(H −1) × steps 15 A ←A × Kj
1 MM
1 × step 18
(A × K0)
1 MM
Total
(ℓm1+1
m1
−m1 + H) MM + (W −1) MS
Total storage
(m0 + 1) × ℓ+ m1 + 2 elements of Z/pZ

Enhanced Digital Signature Using RNS Digit Exponent Representation
187
– the modular squaring in step 13 is performed only in case of A ̸= 1;
– the MMs in step 15 and 18 are performed only in case of Kj ̸= 1;
For the sake of simplicity, we denote by H the sum of the j Hamming weights
for each j from m1 −1 downto 1 (foreach loop step 14). The value of H is as
follows for the diﬀerent values of m1:
m1 2 3 4 5 6 7 8
9
H
1 2 4 5 7 9 12 13
We now discuss the complexity comparison of the considered methods (Fixed-
base Comb Algorithm 3, Radix-R Algorithm 2 and m0m1 Algorithm 3). Since the
parameters are very diﬀerent between these three methods, a formal comparison
is diﬃcult. Therefore, we present a comparison based on numerical application,
for NIST recommended sizes. In the sequel of this section, we then provide com-
plexity evaluations in terms of ﬁeld multiplications MM, under the assumption
of squaring MS = 0.86 MM, which is the average value of our implementations
for the NIST DSA recommended ﬁeld sizes.
Figure 1 gives the general behavior of the three algorithms in terms of storage
with respect to the complexity. One can see that the Fixed-base Comb method
is the best for small storage amount. Our m0m1 approach is better for larger
amount of storage, however, the Radix-R method is the best when the storage is
increasing. In the ﬁgure, the ﬁeld size is the largest of the ones recommended in
the NIST standards (see [13]). Thus, the storage amount for such size is very big.
Nevertheless, the behavior is roughly the same for smaller sizes, although the
Fig. 1. Complexity comparison, Fixed base modular exponentiation NIST DSA, key
size 512 bits (ﬁeld size 15360 bits).

188
T. Plantard and J.-M. Robert
beneﬁt of our approach is lower. The NIST provides recommended key sizes and
corresponding ﬁeld size (respectively the size of the primes q and p, see NIST
SP800-57 [13]). This standardized sizes are as follows:
Key size (bits)
160
224
256
384
512
Field size (bits) 1024 2048 3072 7680 15360
For these sizes, Table 3 shows the complexity comparison between the Fixed-
base Comb Algorithm 3, the Radix-R Method Algorithm 2 and our m0m1-
Recoding approach Algorithm 5. For an equivalent number of MMs, we provide
the minimum amount of storage.
We now provide a few comments about this table.
– For all sizes, we do not provide the results for small amount of storage (values
of w < 8). For such storage, the Fixed-base Comb method is the best. One may
notice that the Radix-R approach needs the greatest storage at this complexity
level.
– For intermediate values of complexity, our proposed m0m1 approach shows
the best storage/complexity trade-oﬀ. However, the beneﬁts are greater for
the larger key sizes.
Table 3. Storage amount comparison, Fixed-base Comb method and m0m1 modular
exponentiation ﬁxed-base, average case, NIST recommended exponent sizes.
Key size t = 224 bits
Key size t = 256 bits
#MM
Fixed-base C.
Radix-R
m0m1
#MM
Fixed-base C.
Radix-R
m0m1
45
127.5 kB
345 kB
108 kB
46
383 kB
845 kB
241 kB
w = 9
R = 31
m0 = 11; m1 = 9
w = 10
R = 47
m0 = 17; m1 = 11
37
511.5 kB
594 kB
242 kB
39
1535 kB
1454 kB
579 kB
w = 11
R = 61
31; 7
w = 12
R = 97
47; 7
30
4095.5 kB
1386 kB
770 kB
32
12287 kB
3179 kB
2070 kB
w = 14
R = 179
127; 7
w = 15
R = 257
211; 6
24
32767.5 kB
4230 kB
4173 kB
26
98303 kB
9486 kB
9642 kB
w = 17
R = 677
877; 7
w = 18
R = 937
1223; 6
19
524287.5 kB
27084 kB
50409 kB
20
1572863 kB
66676 kB
225482 kB
w = 21
R = 5417
13441; 5
w = 22
R = 8467
37579; 5
Key size t = 384 bits
Key size t = 512 bits
#MM
Fixed-base C.
Radix-R
m0m1
#MM
Fixed-base C.
Radix-R
m0m1
63
1918 kB
4081 kB
969 kB
86
3836 kB
9841 kB
1940 kB
w = 11
R = 67
m0 = 19; m1 = 11
w = 11
R = 59
m0 = 13; m1 = 11
50
15358 kB
10087 kB
3742 kB
73
15356 kB
17855 kB
4747 kB
w = 14
R = 191
101; 11
w = 13
R = 127
41; 10
41
122878 kB
26655 kB
17284 kB
60
122876 kB
46775 kB
16224 kB
w = 17
R = 677
541; 6
w = 16
R = 409
179; 11
35
983038 kB
80357 kB
64768 kB
52
491516 kB
93110 kB
54680 kB
w = 20
R = 2381
2381; 6
w = 18
R = 937
677; 7
30
7864318 kB
246070 kB
315053 kB
48
983036 kB
156091 kB
106185 kB
w = 23
R = 8467
13441; 5
w = 19
R = 1699
1489; 10
26
62914558 kB
951217 kB
3256278 kB
41
7864316 kB
489112 kB
355573 kB
w = 26
R = 37579
165397; 5
w = 22
R = 6211
5417; 7
24
503316478 kB
1750756 kB
- kB
35
62914556 kB
2048419 kB
2113890 kB
w = 29
R = 74699
−
w = 25
R = 30347
37579; 7

Enhanced Digital Signature Using RNS Digit Exponent Representation
189
• t = 224, the best gain of our m0m1 approach is for #MM ≈24, with a
storage 5 to 8 times smaller than the storage required for the Fixed-base
Comb method, respectively for #MM = 30 and #MM = 24, and 35%
less than the one of the Radix-R method. However, below #MM ≈24,
the Radix-R approach is better.
• t = 256, the best gain of our m0m1 approach is for #MM ≈32, with a
storage about 6 times smaller than the storage required for the Fixed-base
Comb method, and 44% less than the one of the Radix-R method. Again,
with decreasing values of #MM (below 26), the Radix-R approach is
better.
• t = 384, the best gain of our m0m1 approach is for #MM ≈35, with a
storage about 15 times smaller than the storage required for the Fixed-
base Comb method, and 19% less than the one of the Radix-R method.
Again, with decreasing values of #MM (below 33), the Radix-R approach
is better.
• t = 512, the best gain of our m0m1 approach is for #MM ≈41, with a
storage about 22 times smaller than the storage required for the Fixed-
base Comb method, and 27% less than the one of the Radix-R method.
Again, with decreasing values of #MM (below 38), the Radix-R approach
is better.
However, one may notice that the bigger memory storage sizes exceed the
common values of Random Access Memory, and also the maximum allowed for
the malloc function of the standard C library for memory allocation. Neverthe-
less, the storage savings proposed by our method and the Radix-R ones allow to
keep the level under the limit for lower complexities.
As a conclusion, our m0m1 approach shows lower storage amount for inter-
mediate values of storage, whatever the standardized key size.
5
Implementation Results
5.1
Implementation Strategies
We review hereafter the main implementation strategies and test process. This
applies for the three considered exponentiation algorithms. The algorithms were
coded in C, compiled with gcc 4.8.3 and run on the same platform.
Multiprecision Multiplication and Squaring: We used the low level functions per-
forming multi-precision multiplication and squaring of the GMP library as building
blocks of our codes (GMP 6.0.0, see GMP library [1]). According to the GMP
documentation, the classical schoolbook algorithm is used for small sizes, and
Karatsuba and Toom-Cook sub quadratic methods for size ≥2048 bits.
Modular Reduction: This operation implements the Montgomery representation
and modular reduction method, which avoid multi-precision division in the com-
putation of the modular reduction. This approach has been presented by Mont-
gomery in [12]. More speciﬁcally, we used the block Montgomery algorithm sug-
gested by Bosselaers et al. in [2]. In this algorithm, the multi-precision operations

190
T. Plantard and J.-M. Robert
combine full size operand with one word operand and are also available in the
GMP library [1]. Although the complexity is the same, the implementation is
more computer friendly.
m0m1 Recoding: The conversion in radix-R needs multi-precision divisions.
These operations are implemented using the GMP library [1]. The size of these
operations is decreasing along the algorithm, and this is managed through GMP.
The other operations are classical long integer operations. Steps 9 and 21 in
Algorithm 4, an inversion modulo m0 is required (|(k(1)
i
)−1|m0). This operation
is performed using the Extended Euclidean Algorithm, over long integer data.
For the considered exponent sizes, the cost of the recoding is negligible. This is
explained by the small size of the exponent in comparison with the size of the
data processed during the modular exponentiation (see the key sizes given page
11). The timings given in the next Section include this recoding.
Test Processing: The tests involve a few hundred dataset, which consists of ran-
dom exponent inputs and an exponentiation base with the precomputed val-
Table 4. Synthesis of implementation results, clock cycles and storage (kB). Test
performed on an Intel XEON E5-2650 (Ivy bridge), gcc 4.8.3, CENTOS 7.0.1406.
Modular exponentiation
State of the art methods
Fixed-base Comb
Radix R
m0, m1 rec
Ratio
#CC storage
#CC storage
#CC storage
m0, m1/
Best S.o.A.
Key size 224 bits, ﬁeld size 2048 bits (level of security: 112 bits)
221108
1023.5 kB (w = 12)
227838
829 kB (R = 91)
219864
580 kB (m0 = 89, m1 = 6)
×0.994
×0.700
210074
2047.5 kB (w = 13)
206888
1324 kB (R = 163)
207072
766 kB (m0 = 127, m1 = 7)
×0.985
×0.579
149690
65535 kB (w = 18)
147877
7289kB (R = 1223)
146156
21599 kB (m0 = 5417, m1 = 6)
×0.988
×2.96
Key size 256 bits, ﬁeld size 3072 bits (level of security: 128 bits)
524539
1535 kB (w = 12)
502981
1411 kB (R = 91)
501466
897 kB (m0 = 79, m1 = 6)
×0.997
×0.636
449397
6143 kB (w = 14)
445871
2251 kB (R = 163)
446444
2056 kB (m0 = 211, m1 = 6)
×1.001
×0.913
356892
98303 kB (w = 18)
354640
6414 kB (R = 571)
354071
12843 kB (m0 = 1721, m1 = 7)
×0.998
×2.002
Key size 384 bits, ﬁeld size 7680 bits (level of security: 192 bits)
4442590
1918 kB (w = 11)
4492191
3430 kB (R = 53)
4409584
1134 kB (m0 = 23, m1 = 10)
×0.993
×0.467
3554339
15358 kB (w = 14)
3524896
8290 kB (R = 163)
3551437
4164 kB (m0 = 113, m1 = 10)
×1.008
×0.502
2736341
245758 kB (w = 18)
2543480
45221 kB (R = 1223)
2743399
29961 kB (m0 = 1031, m1 = 7)
×1.079
×0.662
Key size 512 bits, ﬁeld size 15360 bits (level of security: 256 bits)
18632429
15536 kB (w = 13)
19260731
13765 kB (R = 91)
18550238
4745 kB (m0 = 41, m1 = 10)
×0.996
×0.345
14848261
122876 kB (w = 16)
15401002
34418 kB (R = 163)
14813453
22109 kB (m0 = 257, m1 = 11)
×0.998
×0.642
12477816
983036 kB (w = 19)
12193232
119061 kB (R = 1223)
12499600
102820 kB (m0 = 1381, m1 = 7)
×1.025
×0.863

Enhanced Digital Signature Using RNS Digit Exponent Representation
191
ues stored. We compute 2000 times the corresponding exponentiation for each
dataset and keep the minimum number of clock cycles. This avoids the cold-cache
eﬀect and system issues. The timings are obtained by averaging the timings of
all dataset.
5.2
Tests Results and Comparison
The three considered exponentiation algorithms were coded in C, compiled with
gcc 4.8.3 and run on the following platform: the CPU is an Intel XEON®
E5-2650 (Ivy bridge), and the operating system is CENTOS 7.0.1406. On this
platform, the Random Access Memory is 12.6 GBytes. One notices that the
performance results include the recoding in the radix-R and m0, m1 cases. The
implementation results conﬁrm the complexity evaluation, for key sizes of 224,
256, 384, and 512 bits. However, the better results are for 384 and 512 bits.
In Table 4, we provide the most signiﬁcant results. The gains shown are
roughly in the same order of magnitude as the one of the complexity evalua-
tion. In particular, for the largest key size (512 bits), the storage of our m0, m1
approach is nearly ten times less than the one required with the Fixed-base Comb
method, and nearly 14% less than the one required for the Radix-R method, for
the same computation timing, about 12.5 × 106#CC.
6
Conclusion and Future Work
In this paper, we have presented a new method for ﬁxed-base exponentiation
using a radix-R conversion with RNS representation of every radix-R digits,
using an RNS base with two moduli B = {m0, m1}. We have designed a recod-
ing algorithm, which computes our m0m1 representation of the exponent, and
we have used it in a modular exponentiation algorithm which provides memory
storage savings or improve the performance in terms of clock cycles per modular
exponentiation, while oﬀering a total ﬂexibility in terms of storage amount. We
have provided a complexity evaluation, which shows that our approach improves
signiﬁcantly the complexity/storage trade-oﬀ. We have then implemented this
approach in order to check the performance beneﬁts. We have compared our
approach with two other classical approaches, the Fixed-base Comb and the
Radix-R, and have conﬁrmed the complexity results, showing the better stor-
age/performance trade-oﬀof our approach.
Two issues remain opened:
– Side-channel analysis is also a major threat, even in case of software implemen-
tation. For example, Gueron in [7] mentions the cache attack. In the present
paper, we did not take this threat into account in the memorization process.
However, by using a storage pattern spreading the data in memory, we could
ensure the resistance against cache-attacks in the same way as the one used
by Gueron without penalty. This needs to be implemented in all algorithms
for fair comparison.

192
T. Plantard and J.-M. Robert
– Our approach can be applied to Elliptic Curve Cryptography, particularly to
the ECDSA signature protocol. In this case, one needs to compute Elliptic
Curve Scalar Multiplication. However, the relatively cheap doubling of point
operation in comparison with point addition for the NIST recommended curves
makes the beneﬁts of our approach not as good as the one in the modular
exponentiation case. Therefore, this approach needs to be implemented in
relevant curves. For example, the twisted Edwards curve is an example of
curve with relatively equivalent doubling and addition in terms of complexity.
References
1. The GNU Multiple Precision Arithmetic Library (GMP). http://gmplib.org/
2. Bosselaers, A., Govaerts, R., Vandewalle, J.: Comparison of three modular reduc-
tion functions. In: Stinson, D.R. (ed.) CRYPTO 1993. LNCS, vol. 773, pp. 175–186.
Springer, Heidelberg (1994). doi:10.1007/3-540-48329-2 16
3. Acting Secretary Cameron Kerry and USST/Director Patrick Gallagher: Digital
Signature Standard (DSS). In: Federal Information Processing Standards Publica-
tions, FIPS PUB 186-4. NIST (2013)
4. ElGamal, T.: A public key cryptosystem and a signature scheme based on discrete
logarithms. In: Blakley, G.R., Chaum, D. (eds.) CRYPTO 1984. LNCS, vol. 196,
pp. 10–18. Springer, Heidelberg (1985). doi:10.1007/3-540-39568-7 2
5. Garner, H.L.: The residue number system. In: Proceedings of the Western Joint
Computer Conference, pp. 146–153 (1959)
6. Gordon, D.M.: A survey of fast exponentiation methods. J. Algorithms 27(1),
129–146 (1998)
7. Gueron, S.: Eﬃcient software implementations of modular exponentiation. J. Cryp-
togr. Eng. 2(1), 31–43 (2012)
8. Hankerson, D., Hernandez, J., Menezes, A.: Software implementation of ellip-
tic curve cryptography over binary ﬁelds. In: Ko¸c, C¸.K., Paar, C. (eds.) CHES
2000. LNCS, vol. 1965, pp. 1–24. Springer, Heidelberg (2000). doi:10.1007/
3-540-44499-8 1
9. Knuth, D.E.: The Art of Computer Programming, Volume II: Seminumerical Algo-
rithms, 3rd edn. Addison-Wesley, Boston (1998)
10. Lim, C.H., Lee, P.J.: More ﬂexible exponentiation with precomputation. In:
Desmedt, Y.G. (ed.) CRYPTO 1994. LNCS, vol. 839, pp. 95–107. Springer,
Heidelberg (1994). doi:10.1007/3-540-48658-5 11
11. L´opez-Garc´ıa, L., Dominguez Perez, L.J., Francisco Rodr´ıguez-Henr´ıquez, F.: A
pairing-based blind signature e-voting scheme. Comput. J. 57(10), 1460–1471
(2014)
12. Montgomery, P.: Modular multiplication without trial division. Math. Comput.
44(170), 519–521 (1985)
13. U.S.D.C. Rebecca Blank and USST/Director Patrick Gallagher: Recommendation
for key management. In: Computer Security, Part 1, Rev 3. NIST Special Publi-
cation 800-7, pp. 62–64. NIST (2012)
14. Svoboda, A.: The numerical system of residual classes in mathematical machines.
In: IFIP Congress, pp. 419–421 (1959)

Eﬃcient Finite Field Multiplication for Isogeny
Based Post Quantum Cryptography
Angshuman Karmakar1(B), Sujoy Sinha Roy1, Frederik Vercauteren1,2,
and Ingrid Verbauwhede1
1 KU Leuven ESAT/COSIC and iMinds, Kasteelpark Arenberg 10 bus 2452,
3001 Leuven-Heverlee, Belgium
{Angshuman.Karmakar,sujoy.sinharoy,Ingrid.Verbauwhede}@esat.kuleuven.be,
frederik.vercauteren@gmail.com
2 Open Security Research, Fangda 704, Kejinan-12th, Nanshan,
518000 Shenzhen, China
Abstract. Isogeny based post-quantum cryptography is one of the most
recent addition to the family of quantum resistant cryptosystems. In
this paper we propose an eﬃcient modular multiplication algorithm for
primes of the form p = 2 · 2a3b −1 with b even, typically used in such
cryptosystem. Our modular multiplication algorithm exploits the spe-
cial structure present in such primes. We compare the eﬃciency of our
technique with Barrett reduction and Montgomery multiplication. Our
C implementation shows that our algorithm is approximately 3 times
faster than the normal Barrett reduction.
Keywords: Modular multiplication · Isogeny · Post-quantum
cryptography
1
Introduction
The rapid development in the ﬁeld of quantum computing has increased the pos-
sibility of practical quantum computer arriving within a few decades [17]. Using
a powerful quantum computer, Shor’s [2] algorithm can factor integers and can
compute discrete logarithm in polynomial time. This has rendered cryptosystems
such as RSA and those using elliptic curve cryptography highly vulnerable.
Due to these developments, research in post-quantum cryptography has seen
a ﬂurry of activity that resulted in many novel post-quantum cryptosystems.
Though the cryptosystems based on learning with errors or LWE has gained
the most interest, there exist other cryptosystems such as the McEliece cryp-
tosystem [18], cryptosystems based on isogeny between elliptic curves [1,13], the
multivariate cryptosystem [19] etc. Many cryptographic schemes based on these
primitives have been proposed which are analogous to their classical counterparts
and hopefully will replace them in the near future.
A cryptosystem based on the computation of isogenies between elliptic curves
was ﬁrst proposed by Anton Stolbunov [13]. The security of this cryptosys-
tem was based on the hardness of computing isogenies between ordinary elliptic
c
⃝Springer International Publishing AG 2016
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 193–207, 2016.
DOI: 10.1007/978-3-319-55227-9 14

194
A. Karmakar et al.
curves. The best known classical algorithm to solve this problem has exponen-
tial [11] complexity. But the work of Childs et al. [8] has shown that this problem
has sub-exponential complexity on a quantum computer. Also their system was
slow for practical purposes.
The isogeny based post quantum cryptosystem proposed by De Feo et al. [1]
uses supersingular elliptic curves instead of ordinary elliptic curves. The authors
in [1] have argued that the problem of computing isogenies between supersingular
elliptic curves is quantum secure. They have also shown that their cryptosystem
is many times faster than the previous system and oﬀers post-quantum security
for practical parameter sizes.
2
Motivation
The isogeny based post-quantum cryptosystem proposed by De Feo et al. [1]
is based on the diﬃculty of computing isogenies between supersingular elliptic
curves. Computing isogenies and applying them to the points of elliptic curves
ultimately boils down to arithmetic operations in a ﬁnite ﬁeld over which the
supersingular curve is deﬁned. In isogeny based cryptography the prime p is of
the form p = f · 2a3b −1 where f is a small number. Such a special structure
of the prime is essential for the scheme. Like many other cryptosystems, isogeny
based cryptosystem rely heavily on modular multiplication.
Montgomery multiplication [3] and Barrett reduction [7] are two ingenious
methods to replace computationally costly divisions used in modular reduction
with additional multiplications, additions, bit shifts etc. These methods tackle
the costly modular multiplication quite eﬃciently and they can be applied for
any general prime. So they are unable to exploit any special structure of the
prime for even faster reduction.
Mersenne primes [5] and Pseudo-Mersenne primes [6] oﬀer very fast reduction
due to their special structure. Also the NIST-curves [20] which are used in elliptic
curve cryptography frequently use ﬁelds over generalized Mersenne primes [4] for
the advantage of extremely fast modular reduction. Even though the primes we
discuss cannot be categorized as a Mersenne prime, generalized Mersenne prime
or Pseudo-Mersenne prime, the possibility of exploiting the special structure of
the prime for an eﬃcient modular multiplication calculation is highly intriguing.
The parameters a and b for the prime p = 2 · 2a · 3b −1 in the isogeny based
post-quantum protocol are chosen in such a way that log2(2a) ≈log2(3b). For
example, the 771-bit prime p = 2 · 23863242 −1 is used in [1] for 128-bit security.
Our Contribution. In this work we describe a fast modular multiplication
algorithm for the primes used in isogeny based post-quantum cryptosystems. Our
algorithm is inspired by the Barrett reduction [7] and leverages special structures
of the primes used in such cryptosystems. While there are several techniques for
performing eﬃcient arithmetic in ﬁelds whose characteristic is a Mersenne prime
or a Pseudo-Mersenne prime [4], we are not aware of any techniques that could

Eﬃcient Finite Field Multiplication
195
accelerate modular arithmetic in ﬁnite ﬁelds of characteristic p = f · 2a3b −1
where f is a small number. In this paper we propose an eﬃcient algorithm to
perform fast modular arithmetic with primes of the form p = 2 · 2a3b −1 with
b even. Besides the new algorithm, we list a number of such primes for diﬀerent
security levels. These primes are listed in Appendix C.
3
Mathematical Background
In this section we will brieﬂy describe the isogeny based key exchange protocol
and then focus on eﬃcient modular multiplication techniques. For a detailed
description of isogeny based key exchange interested readers may follow [1].
3.1
Isogenies of Elliptic Curves
An isogeny φ : E1 →E2 is a basepoint preserving, i.e. φ(O) →O, morphism
between two elliptic curves E1 and E2 deﬁned over Fq (Sect. III.4 in [12]). Two
elliptic curves are said to be isogenous if there exists an isogeny between them.
This is an equivalence relation and symmetry is given by the existence of a dual
isogeny. As mentioned in [1], an isogeny class is an equivalence class under the
above equivalence relation. Inside the same isogeny class the curves are either
all supersingular or all ordinary curves. The post-quantum key exchange scheme
by De Feo et al. in [1] uses supersingular curves.
In this key-exchange scheme the public parameters are a supersingular curve
E0 deﬁned over a ﬁeld Fp2 with p = f · 2a3b ± 1, and bases {Pa, Qa} and
{Pb, Qb} which generate the torsion groups E0[2a] and E0[3b] respectively. Alice
chooses ma, na ∈R
Z/2aZ and computes the isogeny φa : E0 →Ea, Ea =
E0/⟨[ma]Pa+[na]Qa⟩. Alice also computes φa(Pb) and φa(Qb) under this isogeny
and sends Ea, φa(Pb), and φa(Qb) to Bob. Similarly Bob chooses mb, nb ∈R
Z/3bZ computes the isogeny φb : E0 →Eb, Eb = E0/⟨[mb]Pb + [nb]Qb⟩and
sends Eb, φa(Pb), and φa(Qb) to Alice. After this Alice calculates the isogeny φ′
a :
Ea →Eab, Eab = Ea/⟨[ma]φb(Pa) + [na]φb(Qa)⟩and similarly Bob calculates
φ′
b : Eb →Eba. Bob and Alice then use their common j-invariant j( Eab)=j( Eba)
as their shared key.
The diﬃculty of the key-exchange scheme is based on the hardness of com-
puting isogenies between supersingular elliptic curves. The authors in [1] have
argued that the complexity of the best known algorithm [16] for solving this
problem is
4√p using classical computers and
6√p using a quantum computer,
where p is the characteristic of the ﬁeld over which the curves are deﬁned (more
details in Sect. 5 and 6 of [1]). The authors have described post quantum pro-
tocols for zero knowledge proof, key-exchange and public key cryptosystem in
their paper [1]. Hash functions [15] and digital signature schemes [14] based on
the isogenies have also been proposed.

196
A. Karmakar et al.
Alice
Bob
ma, na ∈R Z/2aZ
φa : E0 →
E0/ [ma]Pa + [na]Qa
mb, nb ∈R Z/3bZ
φb : E0 →
E0/ [mb]Pb + [nb]Qb
Send φa(Pb), φa(Qb)Ea
Send φb(Pa), φb(Qa)Eb
φa : Ea →
Ea/ [ma]φb(Pa) +
[na]φb(Qa)
Output : j(Eab)
φb : Eb →
Eb/ [mb]φa(Pb) +
[nb]φa(Qb)
Output : j(Eba)
Isogeny based key-exchange protocol
3.2
Eﬃcient Modular Arithmetic
In this section we describe two famous algorithms for eﬃcient modular reduc-
tions: the Barrett reduction, and the Montgomery reduction.
Barrett Reduction: Euclid’s division lemma tells us that for any two positive
integers a and b there exist q and r such that a = q · b + r, r ∈[0, b −1]. Here
of course, a = r (mod b), but ﬁnding such q and r requires division of a by b.
There exist fast methods for division by small constants [9], but in general for
practical cryptographic settings, division is a computationally costly operation.
For constant divisors, Barrett’s reduction is a clever trick. It estimates 1/b
to substitute division by a few multiplications and bit shifts. The 1/b in Barrett
reduction is approximated as,
1/b =
(2k)/b
b · 2k/b = (2k)/b
2k
≈
x
2k
Usually the value of x is taken as x = ⌊2k/b⌋where the parameter k depends
on a. The error e of the approximation of 1/b is e = 1/b−x/2k. Hence, the error
in approximating the quotient q is ae. As q ∈Z+, for a correct result we require
that the error in approximating q is smaller than 1. This condition is satisﬁed
when k = log2(a). The Barrett reduction algorithm is shown in Algorithm 1.

Eﬃcient Finite Field Multiplication
197
Input: Two numbers a and b, parameter k, x =
2k
b

Output: a (mod b)
1 q ←(a × x) >> k;
2 r ←a −q × b;
3 if r ≥b then
4
r ←r −b
5 end
6 return r
Algorithm 1. Barrett’s Reduction Algorithm
Montgomery Multiplication: Montgomery multiplication [3] is another tech-
nique used to remove the necessity of performing modular reduction after each
multiplication of the ﬁeld elements. To use Montgomery’s technique we need a
number r co-prime to the modulus p or equivalently r·r′+p·p′ = 1. The values r′
and p′ can be calculated by the extended Euclidean algorithm [10]. Montgomery
multiplication ﬁrst converts the operands a and b to the Montgomery domain as
aM = a · r (mod p), bM = b · r (mod p), the multiplication algorithm described
in Algorithm 2 ensures that the product also stays in the Montgomery domain
as aM × bM = cM (mod p) = a · b · r (mod p). Also the result of addition and
subtraction between operands in the Montgomery domain stays in the Mont-
gomery domain. As the conversion to and from the Montgomery domain is a
costly procedure, this technique is useful where we need many multiplications,
additions or subtractions in close succession.
Input: Two numbers aM = a · r (mod p) and bM = b · r (mod p)
Output: cM = a · b · r (mod p)
1 t ←aM · bM;
2 cM ←

t + (t · p′ (mod r)) · p)/r;
3 if cM ≥p then
4
cM ←cM −p
5 end
6 return cM
Algorithm 2. Montogomery Multiplication
As mentioned before, the above two methods do not utilize the special struc-
ture of the primes for faster modular multiplication. In the next section we are
going to describe our modular multiplication algorithm which exploits the special
structure of the prime for eﬃcient modular multiplication.
4
New Modular Multiplication Algorithm
In our method, the representation of ﬁeld elements plays an important role in
the eﬃciency of the method. We represent a ﬁeld element, let’s say A ∈Fp,

198
A. Karmakar et al.
where p = 2 · 2a3b −1, as
A = a1 · 2a3b + a2 · 2a/23b/2 + a3,
a1 ∈[0, 1], a2, a3 ∈[0, 2a/23b/2)
(1)
In the above representation we have assumed that a is even. However it is not
mandatory. If a is odd we can write p = 4 · 2a−13b −1. This change in the value
of the cofactor (from 2 to 4) does not aﬀect the performance of the algorithm.
During the course of our modular multiplication algorithm the only signiﬁcance
of the value of the cofactor is to determine the value of the coeﬃcient a1, where
we need to divide some numbers by the cofactor. As division by 4 is almost
as easy as division by 2 in binary representation, the change of value of the
cofactor from 2 to 4 has little impact on the performance. In case a is odd the
range of a1 will change to [0, 3]. Here we want to note that we could have written
p = 2a+13b −1 instead of p = 4 · 2a−13b −1 with the cofactor equal to one, both
of these representations of p have no major impact on the performance and can be
switched between one another trivially by simple mathematical manipulations.
Using the same argument as above we need b to be even else it will impact the
performance signiﬁcantly, as division by 6 or 12 is not as easy as division by
2 or 4.
We note that this conversion from normal integer representation to this spe-
cial representation and vice versa is a costly procedure. But we explain at the
end of this section that this conversion and reconversion are one-time proce-
dures that we need to perform at the beginning and the end of the key-exchange
algorithm.
4.1
Multiplication Algorithm
Let’s suppose we have two numbers A, B ∈Fp as represented in Eq. (1). After
multiplying them we get the result C as per the equation shown below:
C = a1b1 · 22a32b + (a1b2 + a2b1)23a/233b/2 + (a1b3 + a2b2 + a3b1)2a3b
+(a2b3 + a3b2)2a/23b/2 + a3b3.
(2)
Since the prime p is of the form 2 · 2a3b −1, we can replace 2a3b in Eq. (2) by
2−1(mod p). Hence a1b1 · 22a32b gets replaced by 0 or 2−2 (mod p) as a1, b1 ∈
{0, 1} and a1b1 ∈{0, 1}. Note that for a ﬁxed prime we can precompute the
value of 2−2 (mod p) and use that for the above replacement in Eq. (2).
We can replace (a1b3 + a2b2 + a3b1)2a3b as follows. If (a1b3 + a2b2 + a3b1) is
even, we can write (a1b3 + a2b2 + a3b1)2a3b = (a1b3 + a2b2 + a3b1)/2 (mod p).
Otherwise we can write (a1b3 + a2b2 + a3b1)2a3b = ((a1b3 + a2b2 + a3b1−1)/2)
(mod p) + (a1b3 + a2b2 + a3b1) (mod 2) · 2a3b. Considering both the even and
odd cases we can write the following equation:
(a1b3 + a2b2 + a3b1)2a3b
=⇒

⌊(a1b3 + a2b2 + a3b1)/2⌋

+

(a1b3 + a2b2 + a3b1)
mod 2

2a3b.

Eﬃcient Finite Field Multiplication
199
Similarly,

a1b2 + a2b1

· 23a/233b/2
=⇒

⌊(a1b2 + a2b1)/2⌋

· 2a/23b/2 +

(a1b2 + a2b1)
mod 2

· 2a/2−13b/2.
Rewriting Eq. (2) by replacing the coeﬃcients we get the following equation:
A × B =

2−2
(mod p)



replacing22a32b
a1b1 + a3b3 + ((a1b2 + a2b1)
(mod 2))2a/2−13b/2+
⌊(a1b3 + a2b2 + a3b1)/2)⌋



replacing(a1b3+a2b2+a3b1)2a3b

+

⌊(a1b2 + a2b1)/2⌋



replacing
(a1b2+a2b1)23a/233b/2
+(a2b3 + a3b2)

2a/23b/2
+

(a1b3 + a2b2 + a3b1)
(mod 2)

2a3b.
The algorithm is described in Algorithm 4. To compute the above expression
we have to perform four smaller multiplications: a2b2, a2b3, a3b2 a3b3, as the
other terms which are multiplied with a1, b1 ∈{0, 1}.
Now we have the product as A×B = C = C1·2a3b + C2·2a/23b/2 + C3, but
in this expression the coeﬃcients C2 and C3 lie in the range [0, 2a3b), which is
not consistent with our representation where C2 and C3 should lie in the range
[0, 2a/23b/2). Hence we need to split them further so that they ﬁt according to
our representation scheme. This splitting involves divisions of the coeﬃcients Ci
for i = 2 and 3 by 2a/23b/2. In the next section we are going to explain how we
can do this division eﬃciently.
4.2
Eﬃcient Division
Our purpose is to divide a number Ci ∈[0, 2a3b) by 2a/23b/2 and calculate the
quotient q and remainder r in an eﬃcient way. We note that division by two is
a simple right shift operation. Hence we perform the division by 2a/23b/2 using
the steps shown below.
1. Extract the a/2 least signiﬁcant bits of Ci and store them in a variable r1.
2. Right shift Ci by a/2 bits to obtain C′
i.
3. Divide C′
i by 3b/2 to get the quotient q and the remainder r2.
Hence we have Ci = q · 2a/23b/2 + (r2 · 2a/2 + r1) = q · 2a/23b/2 + r.
The division operation by 3b/2 in Step 3 is not as easy as the division by
2a/2. However since b is a ﬁxed integer, the division can be performed using
multiplications similar to the Barrett reduction technique [7] as described in
Algorithm1 in Sect. 3.
Obtaining the quotients and remainders after dividing C2 and C3 by 2a/23b/2,
it is trivial to write C in the desired representation of a ﬁnite ﬁeld element.

200
A. Karmakar et al.
Input: 2 numbers Q ∈[0, 2a3b) and P = 2a/23b/2 and log2 Q ≈2 · log2 P.
P ′ = P/2a/2 precomputed x = 2k/P ′, k is as described in Sect. 3.2
Output: q and r such that Q = q · P + r
1 t ←⌊Q/2a/2⌋, s = Q (mod 2a/2);
2 q ←t × x >> k;
3 r ←t −P ′ × q;
4 r ←r × 2a/2 + s;
5 if r > P then
6
r ←r −P;
7
q ←q + 1
8 end
9 return q, r
Algorithm 3. Our Division Algorithm
In the next part of this section we will compare the cost of our modular
reduction technique with the original Barrett reduction technique. Note that
the parameters a and b in the prime p = 2 · 2a · 3b −1 are chosen in such a way
that log2(2a) ≈log2(3b). For convenience let us take log2(2a) ≈log2(3b) ≈N.
So the prime is of size 2N bits.
Comparison with Barrett Reduction: In the Barrett reduction technique
in Algorithm 1 the result of an integer multiplication that is of size ≤4N bits is
reduced by a prime of size 2N bits. For correct computation k is of size 4N bits.
In this scenario we have to perform one 4N × 2N bit multiplication to compute
the quotient (line 1 in Algorithm 1) and one 2N × 2N bit multiplication to com-
pute the remainder (line 2 in Algorithm 1). Thus using a quadratic complexity
multiplier, the Barrett reduction technique has a cost of 12N 2. In our modu-
lar reduction technique we perform divisions of two numbers C2 and C3 of size
≤2N by an N bit number 2a/23b/2. Since division by a power of two is almost
free, the cost of each division reduces to the cost of dividing a number of size
≤3N/2 bits by a N/2 bit number. To perform the divisions correctly we need
to ﬁx the value of k to 3N/2. Hence each of the two division operations perform
a 3N/2 × N bit multiplication and an N × N/2 bit multiplication (lines 2 and
3 in Algorithm 3). Thus using a quadratic complexity multiplier, our reduction
technique has a cost of 4N 2.
Comparison with Montogomery Multiplication: In this section we pro-
vide a comparison of the computational cost of Montgomery multiplication with
our technique. As deﬁned in Sect. 4.2 our prime is of size 2·N bits. For executing
a single round of Montgomery multiplication we need two 2N × 2N bit multi-
plications. And a relatively easier multiplication of t · p′ (mod r) where only the
last 2 · N bits of the result are required. In our case we need only four N × N
bit multiplications for the ﬁrst part of our algorithm and two 3N/2 × N bit and
N × N/2 bit multiplications for the ﬁnal reduction.

Eﬃcient Finite Field Multiplication
201
Input: A, B ∈Fp , A = a1 · 2a3b + a2 · 2(a/2)3(b/2) + a3 and
B = b1 · 2a3b + b2 · 2(a/2)3(b/2) + b3; 2−2 (mod p) precalculated
Output: C = A × B (mod p) ,C = C1 · 2a3b + C2 · 2(a/2)3(b/2) + C3
1 C1 = 0; C2 = 0; C3 = 0;
2 Multiply a2 × b2, a2 × b3, a3 × b2, a3 × b3;
// ∈[0, 2a3b)
3 Multiply a1 × b1, a1 × b2, a1 × b3, b1 × a2 b1 × a3;
// ∈[0, 2a/23b/2)
4 C3 ←a1b1 · 2−2 (mod p) + a3b3;
5 C2 ←a2b3 + a3b2;
6 t ←(a1b2 + a2b1) ;
// replacing (a1b2 + a2b1)23a/233b/2
7 if isEven(t) then
8
C2 ←C2 + t/2
9 else
10
t ←t −1;
11
C2 ←C2 + t/2;
12
C3 ←C3 + 2a/2−13b/2
13 end
14 t ←(a1b3 + a2b2 + a3b1) ;
// replacing (a1b3 + a2b2 + a3b1)2a3b
15 if isEven(t) then
16
C3 ←C3 + t/2;
17
C1 ←0
18 else
19
t ←t −1;
20
C3 ←C3 + t/2;
21
C1 ←1
22 end
/* End of first part C = C12a3b + C22a/23b/2 + C3, reduce
C2, C3 = O(2a3b) further by Barrett division
*/
23 q, r ←BarrettDivision(C3);
24 C3 ←r;
25 C2 ←C2 + q;
26 q, r ←BarrettDivision(C2);
27 C2 ←r;
28 C1 ←C1 + q;
29 if isEven(C1) then
30
C3 ←C3 + C1/2;
31
C1 ←0
32 else
33
C3 ←C3 + (C1 −1)/2;
34
C1 ←1
35 end
36 if C3 overﬂows i.e. C3 > 2a/23b/2, then C3 ←C3 −2a/23b/2, C2 ←C2 + 1 if C2
also overﬂows C1 ←C1 + 1 and repeat steps 29 to 35, this situation occurs
rarely and also then we have to perform this step at most once;
37 return (C1 · 2a3b + C2 · 2a/23b/2 + C3)
Algorithm 4. Multiplication Algorithm

202
A. Karmakar et al.
Here we want to mention that the two Barrett Divisions performed in the
reduction stage (23 and 26) of Algorithm 4 can be run in parallel, eﬀectively
reducing the computing time by half (Fig. 1).
C3
Barrett Division
Barrett Division
r
C3
+
C2
q
C2
r
q’
’
(a) Serial Execution
3
Barrett Division
Barrett Division
C
C2
C3
r
q
q’,r’
q=q−mod
r’=r’+q
q’=q’+1
yes
no
r’=r’+q
r’>mod
q>mod
q’,r’
q’,r’
r’=r’−mod
q’=q’+1 yes
no
C2
2
C
(b) Parallel Execution
Fig. 1. Serial and Parallel execution for the reduction part of Algorithm 4
5
Software Implementation
For a comparison of the eﬀective speedup of our algorithm we implemented
our algorithm using C in a 32 bit multi-precision format for a security level
of 128 bits. We also implemented a normal Barrett reduction using the same
multi-precision format. The cost of multiplication when multiplying two input
numbers in both of the algorithms is expected to remain the same. Therefore we
used normal schoolbook multiplication. Upon running multiple instances of both
the algorithms on a computer with CentOS on a core i5 CPU and averaging the
running times we obtain the results as given in Table 1. As we can see from the
table, we achieve an approximate 62% speed-up in reduction and 43% speed-up
for modular multiplication (multiplication + reduction) with our method against
the normal Barrett reduction. This result is consistent with our prediction in
Sect. 4.2.
Table 1. Comparison of our algorithm with normal Barrett reduction algorithm
Operation
Running time (µ s)
Barrett reduction
50.547
Normal multiplication 67.097
Our reduction
19.565
Our multiplication
38.490

Eﬃcient Finite Field Multiplication
203
6
Hardware Implementation
To check the performance of the new modular multiplication scheme, we have
designed a hardware architecture that performs modular multiplications follow-
ing Algorithm 4. The arithmetic unit of the architecture consists of a combina-
tional multiplier of input size N/2 and an addition/subtraction circuit of input
size N. The operands are stored as arrays of N/2 bit words in a register ﬁle
that contains 52 registers in total and of which 16 registers were used to store
the pre-computed values as required by the Algorithm 4. Since the proposed
algorithm performs arithmetic operations on two operands, we kept two out-
put ports and one input port in the register ﬁle. During a multiplication, the
multiplier performs multiplications of words and the adder helps to accumu-
late the result in the accumulator register ACC. For performing multi-precision
additions and subtractions, only the lower half (i.e. the N/2 bits) of the addi-
tion/subtraction circuit is used. The control signals are generated by a hierarchy
of ﬁnite state machines for multi-precision addition, subtraction, shifting and
multiplication. On the top of the hierarchy, a ﬁnite state machine executes the
operations required for the modular multiplication operation (Fig. 2).
We have compiled the hardware architecture using the Xilinx ISE 14.4 tool
targetting the Virtex 6 FPGA (xc6vcx240t-2ﬀ784). For this evaluation, we chose
the ﬁeld generated by the prime 2 · 23863242 −1 (hence N is 385 bits). After
user data
user_en
user_en
user_data _en
dout_en
 X
>> 1
>>N/2
>>N/2
N/2
N/2
N
+
N
ACC
ACC
d_out
d_in1
d_in2
carry_in
0
lsb
lsb_rst
0
1
0
0
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1
1
user data
user_en
user_en
user_data _en
dout_en
 X
>> 1
>>N/2
>>N/2
N/2
N/2
N
+
N
ACC
ACC
d_out
d_in1
d_in2
carry_in
0
lsb
lsb_rst
0
1
0
0
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1
1
Fig. 2. Hardware architecture

204
A. Karmakar et al.
place and route operation, the architecture consumes 11, 924 registers and 12, 790
look-up-tables, accounting to 3% and 8% of the resources available in the FPGA.
The operating frequency of the architecture is 31 MHz. One modular multipli-
cation (integer multiplication + modular reduction) takes 236 cycles and hence
7.61 μs.
7
Conclusion
We presented a fast modular multiplication algorithm that exploits the spe-
cial structure of primes of the form p = 2 · 2a3b −1, used in isogeny based
post-quantum cryptography. To our knowledge there is no other algorithm that
exploits the structure of such primes for fast reduction. We have shown that
our algorithm is more eﬃcient than Montgomery multiplication and Barrett
reduction. We believe that with our algorithm will signiﬁcantly decrease the
time required to calculate isogenies between supersingular elliptic curves, which
will strengthen the potential of isogeny based post-quantum cryptography as a
practical post-quantum cryptosystem.
Acknowlegments. A. Karmakar and S. Sinha Roy were supported by Erasmus
Mundus PhD Scholarship. This work was supported in part by the Research Coun-
cil KU Leuven: C16/15/058. In addition, this work was supported in part by iMinds,
the Flemish Government, FWO G.0550.12N, G.00130.13N and FWO G.0876.14N, by
the Hercules Foundation AKUL/11/19, and by the European Commission through the
Horizon 2020 research and innovation programme under contract No. H2020-ICT-2014-
644371 WITDOM, and H2020-ICT-2014-644209 HEAT, and H2020-ICT-2014-645622
PQCRYPTO.
We would also like to thank Carl Bootland for his help in proof checking the
manuscript.
A
An Example
In this section we provide a small example of the method described in the paper.
Let a = 22,and b = 16 so that the prime is p = 2·2a·3b−1 = 361102068154367,
n = 2a · 3b = 180551034077184, √n = 13436928
A = 128965951662196 = 0 ∗n + 9597874 ∗√n + 971124, and
B = 230338429880123 = 1 ∗n + 3705266 ∗√n + 334009
After executing the ﬁrst stage of the multiplication algorithm, we reached
A × B = C = C1n + C2
√n + C3 with C1 = 0, C2 = 68262390904455, C3 =
50417786320088. We have to reduce C2 and C3 further by dividing them using
√n. Using our Barrett division algorithm we found C3 = 3752181∗√n+380120,
we set the remainder 380120 to C3 and add the quotient with C2. We again
divide C2 with √n
C2 = 68262390904455 + 3752181 = 68262394656636
C2 = 5080208 ∗√n + 5535612, we set the remainder to C2 and add the quotient
with C1 to get C1 = 5080208.

Eﬃcient Finite Field Multiplication
205
As C1 (mod 2) = 0, we add C1/2 = 2540104 to C3 to get C3 = 380120 +
2540104 = 2920224.
Here C3 is smaller than √n and there is no overﬂow. So we stop our algorithm
here. Finally, we get the result as C = 0 ∗n + 5535612 ∗√n + 2920224 =
74381622800160, which is indeed A × B (mod p).
B
Application in Isogeny Based Post-quantum Key
Exchange Protocol
The isogeny based post-quantum protocol, described in Sect. 3 works by comput-
ing and applying isogenies over supersingular elliptic curve groups. These opera-
tions are fundamentally ﬁeld arithmetic operations over the ﬁeld Fp2, where the
curve is deﬁned.
Here we want to mention that modular addition and subtraction is also easy
in our representation. Let’s say we want to add two numbers A, B ∈Fp to get
the sum C = (a1 + b1) · n + (a2 + b2) · √n + (a3 + b3) = C1 · n + C2 · √n + c3
for convenience we have assumed n = 2a3b. Here again, similar to multiplication
algorithm, C1, C2 and C3 may not be consistent with our representation as given
in Eq. (1). To make C consistent with our representation we follow steps 23 to
36 of Algorithm 4. But here we do not have to use the division Algorithm 3, only
a subtraction by 2a/23b/2 will suﬃce. For subtraction we ﬁrst negate a number
B ∈Fp as −B = p−b = (1−b1)·n+(√n−1−b1)·√n + (√n −1 −b3) followed
by an addition.
To apply our method to the isogeny based key exchange algorithm as men-
tioned in Sect. 3.1, we changed the representation of the public parameters in
the beginning of the algorithm and executed the algorithm. In the last step we
changed the representation back to the original form and matched both Alice
and Bob’s j-invariant.
To further test the correctness of the algorithm we ran an instance of the
unmodiﬁed algorithm with same parameter set and numbers m and n. We veri-
ﬁed that both executions produce identical results.
C
List of Primes
In this section we list values for a and b for security level of around 256 bit
and 512 bit. We found these values by a simple brute-force search using a C
implementation. As mentioned before the prime is p = 2 · 2a3b + k, with the
value of log2(3b) close to a. The primality has been tested using GMP [21]
and PARI/GP [22]. Also we should mention that this list is not exhaustive
(Tables 2 and 3).

206
A. Karmakar et al.
Table 2. Table for primes with around 256 bit PQ security
# a
b
k
#
a
b
k
#
a
b
k
1
738 514 +1 10 760 490 −1 19 814 538 −1
2
741 510 +1 11 764 484 −1 20 819 552 +1
3
747 468 +1 12 768 518 +1 21 826 528 +1
4
748 468 −1 13 772 478 −1 22 826 538 −1
5
750 482 −1 14 774 476 −1 23 829 458 +1
6
750 490 +1 15 778 484 +1 24 830 512 +1
7
752 542 −1 16 784 496 +1 25 832 470 +1
8
756 468 −1 17 792 480 +1 26 834 488 −1
9
758 514 −1 18 798 526 +1
Table 3. Table for primes with around 512 bit PQ security
# a
b
k
# a
b
k
1
1538
946
+1 5
1556
958
+1
2
1541
982
+1 6
1569
966
+1
3
1550 1018
−1 7
1570
942
−1
4
1551
964
+1 8
1598 1034
+1
References
1. De Feo, L., Jao, D., Plˆut, J.: Towards quantum-resistant cryptosystems from super-
singular elliptic curve isogenies. https://eprint.iacr.org/2011/506.pdf
2. Shor, P.W.: Polynomial-time algorithms for prime factorization and discrete log-
arithms on a quantum computer. SIAM J. Comput. 26(5), 1484–1509 (1997).
arXiv:quant-ph/9508027v2
3. Montgomery, P.: Modular multiplication without trial division 44, 519–521 (1985)
http://www.ams.org/journals/mcom/1985-44-170/S0025-5718-1985-0777282-X/
home.html
4. Solinas, J.A.: Generalized Mersenne prime. In: van Tilborg, H.C.A., Jajodia, S.
(eds.) Encyclopedia of Cryptography and Security, pp. 509–510. Springer US,
New York City (2011)
5. Solinas, J.A.: Mersenne prime. In: van Tilborg, H.C.A. (ed.) Encyclopedia of Cryp-
tography and Security, pp. 774–775. Springer, US, New York City (2011)
6. Solinas, J.A.: Pseudo-Mersenne prime. In: van Tilborg, H.C.A., Jajodia, S. (eds.)
Encyclopedia of Cryptography and Security, pp. 992–992. Springer US, New York
City (2011)
7. Barrett, P.: Implementing the rivest shamir and adleman public key encryption
algorithm on a standard digital signal processor. In: Odlyzko, A.M. (ed.) CRYPTO
1986. LNCS, vol. 263, pp. 311–323. Springer, Heidelberg (1987). doi:10.1007/
3-540-47721-7 24
8. Childs, A., Jao, D., Soukharev, V.: Constructing elliptic curve isogenies in quantum
subexponential time (2010). http://arxiv.org/abs/1012.4019/

Eﬃcient Finite Field Multiplication
207
9. Dinechin, F., Didier, L.-S.: Table-based division by small integer constants. In:
Choy, O.C.S., Cheung, R.C.C., Athanas, P., Sano, K. (eds.) ARC 2012. LNCS, vol.
7199, pp. 53–63. Springer, Heidelberg (2012). doi:10.1007/978-3-642-28365-9 5
10. Donald, K.: The Art of Computer Programming, vol. 2. Addison-Wesley, Boston.
Chapter 4
11. Galbraith, S., Stolbunov, A.: Improved algorithm for the isogeny problem for ordi-
nary elliptic curves. Appl. Algebra Eng. Commun. Comput. 24(2), 107–137 (2013)
12. Silverman, J.H.: The Arithmetic of Elliptic Curves. Graduate Texts in Mathemat-
ics, vol. 106. Springer, New York (2009)
13. Stolbunov, A.: Constructing public-key cryptographic schemes based on class group
action on a set of isogenous elliptic curves. Adv. Math. Commun. 4(2), 215–235
(2010)
14. Jao, D., Soukharev, V.: Isogeny-based quantum-resistant undeniable signatures.
In: Mosca, M. (ed.) PQCrypto 2014. LNCS, vol. 8772, pp. 160–179. Springer,
Heidelberg (2014). doi:10.1007/978-3-319-11659-4 10
15. Charles, D.X., Lauter, K.E., Goren, E.Z.: Cryptographic hash functions from
expander graphs. J. Cryptol. 22(1), 93–113 (2009)
16. Tani, S.: Claw Finding Algorithms Using Quantum Walk, March 2008. http://
arxiv.org/abs/0708.2584
17. Microsoft predicts practical quantum computers within 10 years. http://www.
ibtimes.co.uk/microsoft-predicts-practical-quantum-computers-within-10-years-15
24268
18. McEliece, R.J.: A public-key cryptosystem based on algebraic coding theory. DSN
Prog. Rep. 44, 114–116 (1978)
19. Ding, J., Schmidt, D.: Rainbow, a new multivariable polynomial signature scheme.
In: Ioannidis, J., Keromytis, A., Yung, M. (eds.) ACNS 2005. LNCS, vol. 3531, pp.
164–175. Springer, Heidelberg (2005). doi:10.1007/11496137 12
20. Recommended elliptic curves for federal government use. http://csrc.nist.gov/
groups/ST/toolkit/documents/dss/NISTReCur.pdf
21. The GNU multiple precision arithmetic library. https://gmplib.org/
22. The PARI/GP computer algebra system. http://pari.math.u-bordeaux.fr/

A Search Strategy to Optimize the Aﬃne
Variant Properties of S-Boxes
Stjepan Picek(B), Bohan Yang, and Nele Mentens
KU Leuven ESAT/COSIC and IMinds,
Kasteelpark Arenberg 10, 3001 Leuven-Heverlee, Belgium
stjepan@computer.org
Abstract. Aﬃne transformations are an often used tool in symmetric
key cryptography. They are mostly known as a way of removing ﬁxed
points in S-boxes, as for instance in the AES S-box. In general, aﬃne
transformations do not have an inﬂuence on most cryptographic prop-
erties, since those properties are aﬃne invariant; aﬃne transformations
only change the representation of the S-box. Because of that, there is not
much research on what would be the best aﬃne transformation in terms
of usability in practical scenarios. With this research, we try to close
that gap; we concentrate on several cryptographic properties and one
implementation property that are variable under various aﬃne transfor-
mations. To provide experimental validations, we concentrate on aﬃne
transformations in S-boxes of three sizes, namely, 4 × 4, 5 × 5, and 8 × 8.
Our results indicate that it is possible to optimize one or more of the con-
sidered properties. Finally, although we experiment with only a handful
of properties, our methodology is of a general nature and could be used
for other cryptographic properties that are aﬃne variant.
1
Introduction
In the process of designing a symmetric key cipher, one often uses some form
of aﬃne transformation. The easiest example is to consider the AES S-box,
where an exclusive OR (XOR) operation with a constant was added after the
matrix multiplication to remove a ﬁxed point at the ﬁrst position [1]. In fact,
this can be regarded as a representative example of the use of aﬃne transforma-
tions in cipher design. When Leander and Poschmann deﬁned optimal 4-bit S-
boxes, they presented them through canonical representatives, i.e. those that are
ﬁrst in the lexicographical order, where all other optimal S-boxes are obtained
via aﬃne transformations of those canonical representatives [2]. Furthermore,
the authors of the PRINCE cipher gave eight class representatives of suitable
S-boxes where one can choose any S-box that is aﬃne equivalent to one of those
This work has been supported in part by Croatian Science Foundation under
the project IP-2014-09-4882. In addition, this work was supported in part by
the Research Council KU Leuven (C16/15/058) and IOF project EDA-DSE
(HB/13/020).
c
⃝Springer International Publishing AG 2016
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 208–223, 2016.
DOI: 10.1007/978-3-319-55227-9 15

A Search Strategy to Optimize the Aﬃne Variant Properties
209
eight S-boxes [3]. One more example is the Ascon cipher [4], for which the S-box
is an aﬃne transformation of the Keccak S-box [5].
The biggest advantage of using aﬃne transformations lies in the fact that
most of the cryptographic properties will not change, but only the representa-
tion of the S-box changes. Therefore, it may seem that aﬃne transformations
do not deserve a more thorough analysis. However, today we know of a number
of properties that can change under various aﬃne transformations (i.e. prop-
erties that are aﬃne variant) such as the transparency order [6], the modiﬁed
transparency order [7], the branch number [8], and the confusion coeﬃcient [9].
Besides those cryptographic properties, it is straightforward to investigate that
implementation properties such as power and area also change under aﬃne trans-
formations.
In this paper, we consider the selection of aﬃne transformations in order to
optimize certain properties of S-boxes while retaining other properties. Naturally,
not all properties considered in this work are relevant for all designs. Therefore,
we want to stress that our focus is on the methodology for ﬁnding a suitable
aﬃne transformation. One can say that, since we are experimenting with the
4 × 4 size, it is possible to conduct an exhaustive search to ﬁnd the best possible
aﬃne transformation. Indeed, that would be possible, at least when the consid-
ered cryptographic properties allow a fast evaluation. Nevertheless, we extend
our experiments and show that our approach is also working for the sizes 5 × 5
and 8 × 8. Therefore, we conduct aﬃne transformations on the S-boxes used in
PRESENT [10], Keccak [5], and AES [1].
Our Contributions. In this paper, we present two main contributions. The
ﬁrst one is a general methodology for generating aﬃne transformations that
improve several aﬃne variant properties. Naturally, this technique has merits
for all S-box sizes, but it is particularly useful for S-box sizes that are too large
for exhaustive search (i.e. bigger than 4 × 4). The second contribution is a novel
way of reducing the search space size. As presented here, some properties change
only under certain transformations and our methodology can ﬁnd exactly those
transformations.
Outline. The rest of this paper is organized as follows. In Sect. 2, we discuss a
number of relevant cryptographic properties for S-boxes. In Sect. 3, we enumerate
related work on the deﬁnition of the aﬃne equivalence of S-boxes. Section 4
presents our experimental setup, the methods we use and the results. Next, in
Sect. 5, we discuss the obtained results and oﬀer several possible future research
avenues. Finally, in Sect. 6, we give a short conclusion.
2
Cryptographic Properties of S-Boxes
The addition modulo 2 (XOR) is denoted as “⊕”. The inner product of the
vectors ¯a and ¯b is denoted as ¯a · ¯b and equals ¯a · ¯b = ⊕n
i=1aibi. The Hamming
weight HW of a vector ¯v, where ¯v ∈Fn
2, is the number of non-zero positions in
the vector. An (n, m)-function is any mapping F from Fn
2 to Fm
2 . In this paper,
we are interested only in cases where n = m.

210
S. Picek et al.
As already stated, aﬃne transformations cannot change many cryptographic
properties. Three properties that are aﬃne invariant, yet highly signiﬁcant for
the rest of this paper are the nonlinearity, the bijectivity, and the δ-uniformity
of an S-box.
An S-box is called bijective (balanced) if it takes every value of Fm
2 the same
number of times, namely 2n−m [11].
The nonlinearity NF of an S-box F is equal to the minimum nonlinearity of
all non-zero linear combinations of its coordinate functions [11].
NF = 2n−1 −1
2
max
¯a∈Fn
2 ,¯v∈Fm∗
2
|WF (¯a, ¯v)|.
(1)
WF (¯a, ¯v) represents the Walsh-Hadamard transform of F:
WF (¯a, ¯v) =

¯x∈Fn
2
(−1)¯v·F (¯x)⊕¯a·¯x.
(2)
Let F be a function from Fn
2 into Fn
2 and a, b ∈Fn
2. We denote:
D(a, b) = |{x ∈Fn
2 : F(x + a) + F(x) = b}|.
(3)
The entry at the position (a, b) corresponds to the cardinality of D(a, b) and is
denoted as δ(a, b). The δ-uniformity δF is then deﬁned as [12,13]:
δF = max
a̸=0,b δ(a, b).
(4)
The results for the aforesaid invariant properties of the PRESENT, Keccak,
and AES S-box are given in Table 1. We note that those S-boxes are bijective.
For the PRESENT and AES case we have S-boxes that are the best possible (or
believed to be in the case of AES and its nonlinearity value) with regards to those
properties. However, when considering the Keccak S-box, both nonlinearity and
δ-uniformity are not optimal (cf. with e.g. the Almost Bent (AB) function in
the PRIMATEs S-box that has nonlinearity 12 and δ-uniformity 2 [14]). Fur-
thermore, the Keccak S-box has two ﬁxed points and a branch number equal to
two, while its aﬃne equivalent S-box as used in Ascon has zero ﬁxed points and
a branch number equal to 3 [4].
Table 1. The values of the considered aﬃne invariant properties.
S-box
Size
NF
δF
PRESENT 4 × 4
4
4
Keccak
5 × 5
8
8
AES
8 × 8 112
4
We use the aforesaid properties to establish informal equivalence classes con-
sidering aﬃne variant properties. When considering the 4×4 S-box size, Leander

A Search Strategy to Optimize the Aﬃne Variant Properties
211
and Poschmann deﬁned optimal S-boxes as those being bijective, with maximal
nonlinearity (equal to 4), and minimal δ-uniformity (again equal to 4). Therefore,
all resulting S-boxes in our experiments (those that were obtained with aﬃne
transformations) are still optimal S-boxes and we do not report those properties.
Naturally, to ensure there are no mistakes, in our design process we still check
them and consider S-boxes valid only if those properties do not change. Simi-
larly, for sizes 5 × 5 and 8 × 8 we do not report the values of the aﬃne invariant
properties, but we check them in our analysis.
We emphasize that we are only interested in the design of S-boxes and not
in the design of a whole cipher, and therefore we do not presume our S-boxes
can replace the ones that are currently used in existing ciphers. Rather, in the
process of the design of new ciphers, we believe our methodology can play a
role. Therefore, since we do not aim to replace the original S-boxes, we do not
conduct any cryptanalysis on complete ciphers. We concentrate only on the
aﬃne equivalence notion. Two S-boxes S1 and S2 of dimension n × n are aﬃne
equivalent if the following equation holds [2]:
S1(x) = B(S2(A(x) ⊕a)) ⊕b,
(5)
where A and B are invertible n × n matrices in GF(2) and a, b ∈Fn
2.
We are also interested in the following cryptographic properties that change
under aﬃne transformations: the number of ﬁxed points, the modiﬁed trans-
parency order (MTF ) property, and the branch number (bF ).
An S-box has no ﬁxed points if the following equation holds [1]:
S(a) ⊕a ̸= 0, ∀a.
(6)
Although ﬁxed points are generally considered as not desired [1], there are still
a number of block ciphers that use S-boxes with ﬁxed points, e.g. Noekeon [15],
Midori [16], etc.
After the design of the transparency order property [6], Chakraborty et al.
found some errors in the deﬁnition and consequently they suggested the modiﬁed
transparency order property that is deﬁned as [7]:
MTF = max
¯β∈Fm
2
(m−
1
22n −2n

¯a∈Fn∗
2
m

j=1
|AFj(a)+
m

i=1,i̸=j
(−1)βi⊕βjCFi,Fj(a)|), (7)
where AFj(a) represents the autocorrelation function of F and CFi,Fj(a) repre-
sents the crosscorrelation function. The crosscorrelation CFi,Fj(a) between func-
tions Fi and Fj equals:
CFi,Fj(a) =

x∈{0,1}n
(−1)Fi(x)⊕Fj(x⊕a).
(8)
The modiﬁed transparency order property was intended to show the level of
resilience of S-boxes against side-channel attacks (SCA). However, we emphasize
that it has been shown that it cannot serve as a deﬁnitive measure for a better

212
S. Picek et al.
side-channel resistance [17]. Nevertheless, the property has some merits since S-
boxes with smaller modiﬁed transparency order indeed possess somewhat better
SCA resilience. Here, the smaller the value of the modiﬁed transparency order,
the better the resilience against SCA.
The branch number bF can be deﬁned as [8]:
bF = min
a,b̸=a(HW(a ⊕b) + HW(S(a) ⊕S(b))).
(9)
A bijective S-box must have a branch number equal to at least two [18]. Note
that this deﬁnition of the branch number diﬀers from the deﬁnition given in [1]
and is suitable for evaluating a single S-box. The branch number describes the
diﬀusion capabilities of an S-box; the higher the value, the better it is.
Search
strategy
Fitness
Function
S-box
specification
LUT based
HDL code
Generation
S-box.v
NANGATE
45nm LIB
Logic
Synthesis
Netlist File
(.v)
Area
Estimates
Fig. 1. Simulation setup for the generation/evaluation of S-boxes.
It is straightforward to experimentally verify that properties like area, power,
and latency are aﬃne variant, and here we consider area as a case study for aﬃne
variant implementation properties. The area cost of S-boxes is estimated by
means of simulation before placement and routing. Figure 1 shows our simulation
setup. In the ﬁrst step, an aﬃne transformation of an S-box is generated by the
search strategy. The 4×4, 5×5, and 8×8 S-boxes are generated in the style of a
lookup table (LUT). A Matlab (R2014b) script is then used to generate the HDL
(Hardware Description Language) description of the S-box (Verilog ﬁle S-box.v)
and to control the simulation ﬂow and Synopsys Design Compiler (I-2013.12)
to produce the gate-level netlist. All S-boxes are synthesized to the NANGATE
45 open cell library (PDKv1 3 v2010 12). The area consumption of the S-box is
estimated by the Synopsys tool chain and represented with the unit GE, which
stands for Gate Equivalent, i.e. the number of equivalent NAND gates in the
speciﬁed technology.
3
Related Work
When designing the Rijndael cipher, Daemen and Rijmen constructed the S-box
as a sequence of a function g and an invertible aﬃne transformation f [1]. As the
authors stated, the aﬃne transformation has no impact on the nonlinearity prop-
erty of the S-box, but enables the S-box to have a complex algebraic expression

A Search Strategy to Optimize the Aﬃne Variant Properties
213
and no ﬁxed or opposite ﬁxed points [1]. They used an aﬃne transformation
that consists of a matrix multiplication followed by an XOR with a constant
value. Osvik used a search algorithm with heuristics to ﬁnd eﬃcient instruc-
tion sequences for the Serpent S-boxes. In this work, the S-boxes are ﬁxed and
only the implementation changes [19]. Leander and Poschmann deﬁned optimal
4-bit S-boxes as those having nonlinearity and δ-uniformity equal to 4 and being
bijective [2]. Furthermore, they were able to ﬁnd that there are only 16 optimal
4 × 4 S-boxes up to the aﬃne equivalence. Saarinen conducted an exhaustive
search of all 16! bijective 4 × 4 S-boxes [18]. The author investigated two types
of equivalence, namely, the linear equivalence (LE) and the permutation-XOR
equivalence (PE). The exhaustive search is conducted over all 4 × 4 S-boxes and
they are classiﬁed into 142 090 700 diﬀerent PE classes. Furthermore, the author
deﬁned Golden S-boxes and found that all Golden S-boxes belong to only four
PE classes. Golden S-boxes are all S-boxes that have the following properties:
S-boxes and their inverses satisfy a diﬀerential probability p ≤1/4, a bias of
linear approximation η ≤1/4, and a branch number of 3. Further, all output
bits have algebraic degree 3 and are dependent on all input bits in a nonlinear
fashion. The Ph.D. thesis of de Canni`ere conducted the exhaustive analysis of
all aﬃne equivalence classes for 4 × 4 S-boxes [20]. In total, he found 302 aﬃne
equivalence classes. Biryukov et al. presented two algorithms for solving linear
and aﬃne equivalence problems for arbitrary S-boxes [21]. With this tool, the
authors are able to ﬁnd a number of new equivalent representations for a number
of ciphers. Carlet et al. deﬁned a more general version of an equivalence called
the CCZ (Carlet, Charpin, Zinoviev) equivalence [22]. Two S-boxes F, G of size
n × n are CCZ equivalent if there exists a linear permutation on Fn
2 × Fn
2 such
that the graph of F is mapped to the graph of G. Ullrich et al. introduced an
iterative deepening depth ﬁrst search strategy to ﬁnd the most eﬃcient bitsliced
implementations of S-boxes. The authors classify 4 × 4 S-boxes on the basis
of some aﬃne invariant properties and then ﬁnd the most eﬃcient S-box per
class [8]. Berghoﬀet al. deﬁned eight suitable classes to select an S-box when
using the PRINCE cipher [3]. To be acceptable for PRINCE, the S-box needs
to fulﬁll the following criteria: the maximal probability of a diﬀerential is 1/4
and there are exactly 15 such diﬀerentials, the maximal absolute bias of a lin-
ear approximation is 1/4 and there are exactly 30 of such approximations, and
each of the 15 non-zero component functions has an algebraic degree of three.
Picek et al. made a classiﬁcation of 4 × 4 S-boxes where the best S-boxes are
those that are optimal (i.e. belong to one of the 16 optimal classes), but also
with an increased side-channel resistance (S-boxes with the lowest value of the
transparency order property) [23]. We note that the transparency order prop-
erty was shown to be ﬂawed, which makes this classiﬁcation relatively useless in
practice. Sarkar et al. discussed how to choose an S-box in the (extended) aﬃne
equivalence class based on diﬀerential power analysis using a Hamming weight
model [24]. Zhang et al. made a new classiﬁcation of 4 × 4 S-boxes in which
all S-boxes are classiﬁed under 183 categories out of which three are platinum
categories (which are a subset of optimal S-boxes) [25]. The authors found that

214
S. Picek et al.
for the PRESENT, RECTANGLE [26], and SPONGENT [27] ciphers, one can
get potentially better S-boxes by choosing from those three platinum categories.
Canteaut and Rou´e investigated the eﬀect of the S-box aﬃne transformations
on the maximal expected diﬀerential probability MEDP and linear potential
MELP over two rounds of a substitution permutation network [28].
4
Experimental Setting and Results
In this section, we ﬁrst brieﬂy discuss the diﬃculty of ﬁnding the best possible
aﬃne transformation and then we present our search strategy. Next, we show
the obtained results through two case studies. Finally, we discuss how our search
strategy can be used to reduce the search space size when considering certain
aﬃne variant properties.
4.1
The Number of Aﬃne Transformations
Here, we discuss the number of possible aﬃne transformations. Recall from
Eq. (5) that the matrices A and B need to be invertible in GF(2). The number
of n×n invertible binary matrices is the order of the General Linear Group over
GF(2) [29]:
GL(n) =
n−1

i=0
(2n −2i).
(10)
It is easy to calculate that for n = 4 there are in total 20 160 invertible
matrices. However, since there are two matrices and additionally two constants
a, b ∈Fn
2, the total number of combinations is ≈236. Although this is a huge
number, it is still within reasonable computation time if we consider certain
properties that can be calculated eﬃciently (e.g. the nonlinearity property).
However, if we consider implementation properties like power or area, then the
time necessary to calculate the respective property for a single 4 × 4 S-box is in
the order of magnitude of 10 s. Therefore, it is impossible to run an exhaustive
search. Furthermore, for the 4×4 size, there are 16 optimal classes, which means
that we need to run such a search 16 times. Already for the 5 × 5 size, there
are 9 999 360 invertible matrices and therefore, the total number of combinations
equals ≈256. Based on the aforesaid, we see that an exhaustive search is often
not a realistic option. Therefore, we need a faster way to obtain good results.
To that end, we experiment with a heuristic search technique.
4.2
Heuristic Search Strategy
For heuristics, we use a genetic algorithm (GA); we utilize the simplest version
of the algorithm we could design for this problem. Individuals (solutions) are
encoded as a set of genotypes of bitstring values. Each genotype represents one
matrix or a constant as given in Eq. (5). Each individual consists of four geno-
types where the ﬁrst two represent the matrices A and B and the third and the

A Search Strategy to Optimize the Aﬃne Variant Properties
215
fourth genotypes represent the constants a and b. The ﬁrst two genotypes can
be considered as row vectors of size n2, where the transformation to a matrix is
done by splitting the vector in n rows of size n. We use the tournament selection
mechanism in order to avoid the need to tune the crossover rate parameter. We
work with the 3-tournament selection which is the option that oﬀers the fastest
convergence [30]. In that selection mechanism, three solutions are selected ran-
domly and the worst one is discarded. Then, from the remaining two solutions,
one oﬀspring is created by the crossover operator. For variation operators, we use
the Simple mutation and the One-point crossover [30]. In the One-point cross-
over, a random crossover point is selected and all bits before that point are taken
from the ﬁrst solution and the remaining bits are taken from the second solution.
In the Simple mutation, a randomly selected bit is inverted with a probability
pm per individual (i.e. each individual will mutate with a probability equal to
pm where the mutation operator is executed only once on a given individual).
We set the mutation probability to 0.8. In all experiments, we use a population
size of 100 individuals. The algorithm starts with a random initial population,
where we do not impose any criteria on the starting population (e.g. we do not
require that the matrices A and B are invertible). As a termination criterion,
we use the number of evaluations without improvement, which is in our case 50
generations.
Next, we give a description of one generation of our heuristics for the 4 × 4
S-box size. First, the algorithm creates 100 random individuals where every
individual consists of 4 bitstring vectors. Two bitstring vectors represent the
matrices A and B and have a length of 16, and two bitstring vectors represent the
constants a and b of size 4. Then, then algorithm randomly selects 3 individuals
and calculates their ﬁtness (i.e. when setting the values of the matrices and
the constants to Eq. (5) it calculates for instance the modiﬁed transparency
order). Then, the worst individual is discarded and from the two better ones, an
oﬀspring is created with the One-point crossover. This process repeats N times
to ensure that most of the population is evaluated and improved. Afterwards,
the mutation is done on a number of individuals and ﬁnally, all individuals are
evaluated again and their ﬁtness value is updated. This procedure runs until the
stopping criterion is met and at that moment, the evolution is ﬁnished.
Regarding the speed of the algorithm, on average one generation (100 indi-
viduals) needs around 1 s to evolve. In that estimation we include the cost of the
evaluation of the cryptographic properties, but not the cost of the evaluation of
the implementation properties. To calculate the area estimate of a single S-box,
we require a processing time in the order of magnitude of 10 s, which means one
generation lasts for around 1 000 s in total. We note that although here we work
with GA, our methodology is not exclusive for that algorithm, but it could work
with any other heuristics that supports the bitstring representation. Naturally,
it is to be expected that in such case one could also need to change the ﬁtness
function and the stopping criterion. For further details about genetic algorithms,
we refer readers to [30].

216
S. Picek et al.
4.3
The Obtained Results
Next, we give the results for two cryptographic properties as the ﬁrst case study
and then for the implementation property as the second case study. In all tables
we display in the Original column the value that denotes the initial value of the
S-boxes we investigate and in the New column the value that denotes the value
of the property after the aﬃne transformation.
The Modiﬁed Transparency Order. When looking for S-boxes with a mini-
mal modiﬁed transparency order value, we aim to minimize the following equa-
tion, since the smaller the value of MTF the better:
objective = MTF + fixed.
(11)
However, it has been shown that the minimal necessary aﬃne transformation
(minimal in a sense that it consists of the smallest number of terms) needed to
change the modiﬁed transparency order property is of the form [17]:
S2(x) = B(S1(x)).
(12)
Therefore, we can simplify our potential solutions (aﬃne transformations) such
that they consist of only a single matrix (B), which is what we do in the next
set of experiments. Note that now the search space is rather small for sizes 4 × 4
and 5 × 5. Since we also want to avoid ﬁxed points, we include this goal in
the objective function. The results obtained with the GA approach are given
in Table 2. Column Matrix B presents examples of values one should use for
the matrix B to obtain the reported MTF values. There, one can see that our
approach ﬁnds the minimal modiﬁed transparency value that is possible for the
PRESENT class (G1). Since there are no previous results for the Keccak S-box
(or any S-box of size 5 × 5) and the modiﬁed transparency order, we report
the diﬀerence between the original S-box and the transformed one where we see
that the diﬀerence is signiﬁcant. Furthermore, for the 8 × 8 size, our approach
yields a marginally better value than the previously known one that equals
6.89 [17]. Although the diﬀerence is negligible, it assures us that our technique is
a viable choice. This is especially apparent since the modiﬁed transparency order
is computationally expensive (when compared to other cryptographic properties)
so by following our approach one requires less time compared to random search
or running heuristics with the goal of ﬁnding new S-boxes.
Branch Number Results. Here, our objective function equals:
objective = bF + (2n −fixed),
(13)
where the goal is to maximize the bF value. Note that here we subtract the
number of ﬁxed points from the theoretical maximal number of ﬁxed points since
we require to increase the branch number, but without adding ﬁxed points. When
considering the branch number property, we do not know what is the smallest
aﬃne transformation we need to use to change that property. Therefore, we work
with Eq. (5) and report our results in Table 3.

A Search Strategy to Optimize the Aﬃne Variant Properties
217
Table 2. Results for MTF , Eq. (12).
S-box
MTF
Matrix B
Original New
PRESENT 2.467
1.9
[4, 2, 7, 8]
Keccak
3.871
2.645 [4, 25, 1, 16, 6]
AES
6.916
6.88
[35, 242, 8, 80, 64, 184, 138, 52]
Table 3. Results for GA, Eq. (13).
S-box
bF
Original New
PRESENT 3
3
Keccak
2
3
AES
2
2
For the PRESENT S-box, we could not improve the original value of the
branch number property (since 3 is also the maximal possible value), but we
notice the property is quite sensitive to changes and it is easy to degrade the
value to 2.
Area Results. In order to ﬁnd S-boxes that have minimal area, we use the
following simple objective function, with the goal to minimize the value:
objective = area + fixed.
(14)
The results for the area are given in Table 4. Note that again here we do not
allow that our transformed S-boxes have ﬁxed points. Here, we omit the AES
S-box case since we believe it is unrealistic to expect that S-box of such a size
would be implemented in a lookup table fashion. The results are given in gate
equivalence (GE) unit.
Table 4. Results for GA, Eq. (14).
S-box
Area [GE]
Original New
PRESENT 26
13.3
Keccak
17
20.33
To put those results into a better perspective, we give area results for lookup
table base implementations of several more relevant S-boxes. For the 4 × 4 size,
Piccolo [31] has 17.33 GE, Prince [3] has 17 GE, Rectangle [26] has 24 GE, and
Midori [16] S-boxes Sb0 and Sb1 have 13.67 and 15.33 GE, respectively. For the
5 × 5 size, Ascon [4] has 30.67 GE and PRIMATEs [14] has 36 GE.

218
S. Picek et al.
4.4
Reducing the Search Space Size
In the previous section we showed that heuristics can be used to ﬁnd improved S-
boxes when considering aﬃne variant properties. However, still the search space
is large and a natural question is whether there is a way to reduce it. It turns
out that is possible when considering certain properties as shown next.
Imagine a scenario where one does not know the minimal necessary aﬃne
transformation needed to ﬁnd the optimal value of a property (here, we consider
the modiﬁed transparency order property). Then, one would need to run all
possible combinations of aﬃne transformations in order to ﬁnd the minimal one.
The question is whether this approach can be simpliﬁed and automated. In the
next experiment we change the objective function to the following one:
objective = MTF ∗100 + HW(X),
(15)
where HW(X) represents the Hamming weight of all matrices and constants in
the aﬃne transformation as in Eq. (5). Therefore, with this objective function,
we aim to minimize not only the value of the modiﬁed transparency order prop-
erty, but also the number of ones in the matrices and constants from Eq. (5).
Note that the main gain in the search space reduction is for the cases in which
one or both of the matrices are not necessary (i.e. identity matrix). We add
a weight factor to the objective function, since optimizing the modiﬁed trans-
parency order is our primary objective. Therefore, a solution that has a good
MTF value and a relatively large HW(X) value will not be replaced with a
solution that has a worse MTF value, but a better HW(X) value. The tuning
procedure for the weight factor is based on the observation that if we multiply
MTF with a multiplicand that is higher than the worse case value of HW(X),
the results do not change; the only diﬀerence is the number of necessary itera-
tions of the algorithm. For S-boxes of size 4 × 4, the HW is equal to 40 when
every matrix and constant consist of all ones. Note that we disregard that the
matrices must be invertible; therefore the worst case is an all-ones matrix.
The results for the new objective are given in Table 5. In column Aﬃne
transformation we give examples of matrix and constant values one needs to use
to obtain an S-box with the reported value of the modiﬁed transparency order.
We denote the identity matrix of dimension n with In.
Table 5. Results for GA, Eq. (15).
S-box
MTF
Aﬃne transformation
PRESENT 1.9
A = I4, B = [1, 4, 13, 2], a = b = 0
Keccak
2.645 A = I5, B = [11, 1, 2, 20, 4], a = b = 0
AES
6.88
A = I8, B = [2, 32, 8, 4, 64, 48, 128, 3], a = b = 0

A Search Strategy to Optimize the Aﬃne Variant Properties
219
5
Discussion
When considering the results for the modiﬁed transparency order, we see that
our approach manages to ﬁnd S-boxes that outperform the original ones. For the
4 × 4 and 5 × 5 sizes that diﬀerence is a rather signiﬁcant one. Furthermore, for
the 4 × 4 size, we can conﬁrm that our method reaches the best possible value
compared to previously reported results [17,32]. When looking at the results for
8 × 8, one can consider them somewhat disappointing since we see only a mar-
ginal improvement over the original AES S-box and an even smaller improvement
over previously known results. However, we emphasize that here we did not con-
centrate on the modiﬁed transparency property, but on a method to ﬁnd aﬃne
transformations that result in improved properties. Furthermore, it is unknown
what is the best possible value of the modiﬁed transparency order for the 8 × 8
S-box having the same cryptographic properties as the AES S-box, so this result
could be better than it seems.
When considering the branch number results, for the Keccak case the value
is improved, while for the PRESENT and the AES case our method could not
ﬁnd any improved S-boxes. However, we note that it easily ﬁnds equivalent S-
boxes with the same branch number value, which is quite diﬃcult to do if one
would for instance use aﬃne transformations with random values (that still give
invertible matrices).
Besides those results, we want to emphasize the results obtained in Table 5.
With those experiments we started with an aﬃne transformation of the form
given in Eq. (5). The algorithm itself reduced it to an aﬃne transformation as
given in Eq. (12). Although we experimented here with a property for which
we a priori know the minimal aﬃne transformation, we can easily imagine a
scenario where one does not know the minimal transformation. In such a case,
our approach can be used for faster evaluation. Indeed, if one observes that
the same aﬃne transformation is used in three diﬀerent S-box sizes, it is a
reasonable assumption that that transformation is also the minimal necessary
transformation to change a certain aﬃne variant property. Even when it is not
the minimal necessary transformation, it will still have a smaller number of terms
and therefore the search space size will be reduced. We note that we are not sure
whether this approach can be used in cases when there exist only a few possible
property values to reach. There, one could improve the objective function to
diﬀerentiate between matrices A and B, i.e. to ﬁrst try to minimize the ﬁrst one,
and only then the second one.
When considering the area results, our method is again successful. For smaller
sizes it ﬁnishes in a short period of time with signiﬁcantly better area results,
as evident from the 4 × 4 scenario. For the 5 × 5 size, our best obtained S-box
is somewhat worse than the Keccak S-box. Since the size of the Keccak S-box is
already quite small, it would be unrealistic to expect a big diﬀerence. However,
we note that our 5 × 5 S-box does not have ﬁxed points. A ﬁxed point in the
Keccak S-box is also the reason why our heuristics could not output the original
S-box (i.e. with constants a and b equal to zero and matrices A and B set as
identity matrices), since it can evolve only aﬃne transformations that result in

220
S. Picek et al.
S-boxes without ﬁxed points. Note that for instance the Ascon S-box (which is
an aﬃne transformation of the Keccak S-box, without ﬁxed points and with a
branch number equal to 3) has an area of 30.67 GE, which is 30% worse than our
S-box. Additionally, since there are usually several clock frequencies of interest,
one would need to repeat the experiments for each frequency. With the heuristic
approach, one could even combine the search for several frequencies and aim
to ﬁnd one S-box that is good for all settings. Besides optimizing only for the
implementation properties, one could at the same time optimize for some aﬃne
variant cryptographic properties like the branch number, for example.
On a more general level, we see two possible drawbacks of our approach.
The ﬁrst one is the relevance of the properties we investigate here. However,
we believe our approach should be regarded as a more general methodology
that works for other properties as well. The second possible drawback is the
heuristic nature of our approach where there is no guarantee that the optimal
solution is found. However, our results show that the method is quite reliable and
consistently producing good solutions. Finally, because of its heuristic nature,
our algorithm works well on bigger sizes, which is usually not the case with
deterministic algorithms [8,33]. Finally, we believe this approach is substantially
better than for instance using heuristics to ﬁnd completely new S-boxes. This
is because already for the 5 × 5 size it is not easy to ﬁnd S-boxes with the
best possible values for the invariant cryptographic properties (e.g., nonlinearity
and δ-uniformity). As already noted, our methodology makes sense only when
designing new ciphers and should not be considered as a source of S-boxes that
can replace existing ones in ciphers. Indeed, to fully utilize the advantages of this
method, one should ﬁrst ﬁnd an S-box that is in accordance with his criteria.
Only after that, the linear layer can be designed so the design goals of a cipher
are met.
In all our experiments, we see that we are interested in more than one prop-
erty, i.e. we always minimize the number of ﬁxed points alongside some other
cryptographic or implementation property. However, the question is whether can
we combine even more properties and still obtain good results. To that end, we
evolved S-boxes of size 4 × 4 that are without ﬁxed points, with an as high as
possible branch number, and an as low as possible modiﬁed transparency order
(therefore, our objective functions consists of three parts). As could be expected,
our methodology works, but there is no guarantee that it can ﬁnd S-boxes with
all optimal values. Indeed, on the one hand we found S-boxes without ﬁxed
points, with branch number 3, and a modiﬁed transparency order equal to 2.13.
On the other hand, we found S-boxes without ﬁxed points, with branch number
2, and a modiﬁed transparency order of 1.9. This shows us a scenario with con-
ﬂicting objectives, which means it is not possible to obtain a single S-box with
all optimal properties.
In future work, we plan to investigate other cryptographic properties as well
as the implementation properties of S-boxes of various sizes. Recently, the energy
eﬃcient cipher Midori was presented for which the S-box is an involution that
is designed with small energy consumption as a goal [16]. However, that S-box

A Search Strategy to Optimize the Aﬃne Variant Properties
221
has four ﬁxed points which, combined with some other factors, lead in the end
to a successful attack on full Midori64 cipher [34]. It would be interesting to see
whether it is possible to use our search method in order to obtain involutions
that have a smaller number of ﬁxed points, and yet are optimal (with regards to
invariant properties). If we consider the 4 × 4 case, not all optimal classes have
involutions, which is only possible when the inverse S-box is a member of the
same class as the S-box. Therefore, this helps us to limit our search to only a
subset of optimal classes. Accordingly, our search strategy seems to lend itself
naturally for that case because it allows us to search only in the relevant classes
and to do that much faster than with an exhaustive search method.
6
Conclusions
In this work, we investigate how to ﬁnd appropriate aﬃne transformations when
considering S-box properties that are aﬃne variant. We conduct the analysis
for three popular S-box sizes to show our approach scales well even for larger
S-boxes. The results show it is possible to eﬃciently ﬁnd aﬃne transformations
that oﬀer better properties. We also discuss one more possible usage of our
methodology, which is the selection of the minimal appropriate aﬃne transfor-
mation form. This way, we do not only ﬁnd better S-boxes (with regards to
aﬃne variant cryptographic properties), but also transformations that are easier
to enumerate since they consist of a smaller number of terms.
References
1. Daemen, J., Rijmen, V.: The Design of Rijndael. Springer-Verlag New York Inc.,
Secaucus (2002)
2. Leander, G., Poschmann, A.: On the classiﬁcation of 4 bit S-boxes. In: Carlet, C.,
Sunar, B. (eds.) WAIFI 2007. LNCS, vol. 4547, pp. 159–176. Springer, Heidelberg
(2007). doi:10.1007/978-3-540-73074-3 13
3. Borghoﬀ, J., et al.: PRINCE – a low-latency block cipher for pervasive computing
applications. In: Wang, X., Sako, K. (eds.) ASIACRYPT 2012. LNCS, vol. 7658,
pp. 208–225. Springer, Heidelberg (2012). doi:10.1007/978-3-642-34961-4 14
4. Dobraunig, C., Eichlseder, M., Mendel, F., Schl¨aﬀer, M.: Ascon. AESAR Submis-
sion (2014). http://ascon.iaik.tugraz.at/
5. Bertoni, G., Daemen, J., Peeters, M., Assche, G.: Keccak. In: Johansson, T.,
Nguyen, P.Q. (eds.) EUROCRYPT 2013. LNCS, vol. 7881, pp. 313–314. Springer,
Heidelberg (2013). doi:10.1007/978-3-642-38348-9 19
6. Prouﬀ, E.: DPA attacks and S-boxes. In: Gilbert, H., Handschuh, H. (eds.) FSE
2005. LNCS, vol. 3557, pp. 424–441. Springer, Heidelberg (2005). doi:10.1007/
11502760 29
7. Chakraborty, K., Sarkar, S., Maitra, S., Mazumdar, B., Mukhopadhyay, D., Prouﬀ,
E.: Redeﬁning the transparency order. In: Coding and Cryptography, International
Workshop, WCC 2015, Paris, France, 13–17 April 2015 (2015)
8. Ullrich, M., De Canni`ere, C., Indesteege, S., K¨u¸c¨uk, ¨O., Mouha, N., Preneel, B.:
Finding optimal bitsliced implementations of 4 × 4-bit S-boxes (2011)

222
S. Picek et al.
9. Fei, Y., Luo, Q., Ding, A.A.: A statistical model for DPA with novel algorithmic
confusion analysis. In: Prouﬀ, E., Schaumont, P. (eds.) CHES 2012. LNCS, vol.
7428, pp. 233–250. Springer, Heidelberg (2012). doi:10.1007/978-3-642-33027-8 14
10. Bogdanov, A., Knudsen, L.R., Leander, G., Paar, C., Poschmann, A., Robshaw,
M.J.B., Seurin, Y., Vikkelsoe, C.: PRESENT: an ultra-lightweight block cipher.
In: Paillier, P., Verbauwhede, I. (eds.) CHES 2007. LNCS, vol. 4727, pp. 450–466.
Springer, Heidelberg (2007). doi:10.1007/978-3-540-74735-2 31
11. Carlet, C.: Vectorial Boolean functions for cryptography. In: Crama, Y., Hammer,
P.L. (eds.) Boolean Models and Methods in Mathematics, Computer Science, and
Engineering, 1st edn, pp. 398–469. Cambridge University Press, New York (2010)
12. Biham, E., Shamir, A.: Diﬀerential cryptanalysis of DES-like cryptosystems. In:
Menezes, A.J., Vanstone, S.A. (eds.) CRYPTO 1990. LNCS, vol. 537, pp. 2–21.
Springer, Heidelberg (1991). doi:10.1007/3-540-38424-3 1
13. Nyberg, K.: Perfect nonlinear S-boxes. In: Davies, D.W. (ed.) EUROCRYPT
1991. LNCS, vol. 547, pp. 378–386. Springer, Heidelberg (1991). doi:10.1007/
3-540-46416-6 32
14. Andreeva, E., Bilgin, B., Bogdanov, A., Luykx, A., Mendel, F., Mennink, B.,
Mouha, N., Wang, Q., Yasuda, K.: Primates v1 submission to the CAESAR com-
petition (2014). http://competitions.cr.yp.to/round1/primatesv1.pdf
15. Daemen, J., Peeters, M., Assche, G.V., Rijmen, V.: Nessie proposal: the block
cipher Noekeon. Nessie submission (2000) http://gro.noekeon.org/
16. Banik, S., Bogdanov, A., Isobe, T., Shibutani, K., Hiwatari, H., Akishita, T.,
Regazzoni, F.: Midori: a block cipher for low energy (extended version). Cryp-
tology ePrint Archive, Report 2015/1142 (2015) http://eprint.iacr.org/
17. Picek, S., Mazumdar, B., Mukhopadhyay, D., Batina, L.: Modiﬁed transparency
order property: solution or just another attempt. In: Chakraborty, R.S., Schwabe, P.,
Solworth, J. (eds.) SPACE 2015. LNCS, vol. 9354, pp. 210–227. Springer, Heidel-
berg (2015). doi:10.1007/978-3-319-24126-5 13
18. Saarinen, M.-J.O.: Cryptographic analysis of all 4 × 4-bit S-boxes. In: Miri, A.,
Vaudenay, S. (eds.) SAC 2011. LNCS, vol. 7118, pp. 118–133. Springer, Heidelberg
(2012). doi:10.1007/978-3-642-28496-0 7
19. Osvik, D.A.: Speeding up serpent. In: AES Candidate Conference, pp. 317–329
(2000)
20. de Canni`ere, C.: Analysis and Design of Symmetric Encryption Algorithms. Ph.D.
thesis, Katholieke Universiteit Leuven (2007)
21. Biryukov, A., Canni`ere, C., Braeken, A., Preneel, B.: A toolbox for cryptanaly-
sis: linear and aﬃne equivalence algorithms. In: Biham, E. (ed.) EUROCRYPT
2003. LNCS, vol. 2656, pp. 33–50. Springer, Heidelberg (2003). doi:10.1007/
3-540-39200-9 3
22. Carlet, C., Charpin, P., Zinoviev, V.: Codes, bent functions and permutations
suitable for DES-like cryptosystems. Des. Codes Crypt. 15(2), 125–156 (1998)
23. Picek, S., Ege, B., Papagiannopoulos, K., Batina, L., Jakobovic, D.: Optimality
and beyond: the case of 4 × 4 S-boxes. In: IEEE International Symposium on
Hardware-Oriented Security and Trust, HOST 2014, Arlington, VA, USA, 6–7
May 2014. IEEE Computer Society, pp. 80–83 (2014)
24. Sarkar, S., Maitra, S., Chakraborty, K.: Diﬀerential power analysis in hamming
weight model: how to choose among (extended) aﬃne equivalent S-boxes. In: Meier,
W., Mukhopadhyay, D. (eds.) INDOCRYPT 2014. LNCS, vol. 8885, pp. 360–373.
Springer, Heidelberg (2014). doi:10.1007/978-3-319-13039-2 21

A Search Strategy to Optimize the Aﬃne Variant Properties
223
25. Zhang, W., Bao, Z., Rijmen, V., Liu, M.: A new classiﬁcation of 4-bit optimal
S-boxes and its application to PRESENT, RECTANGLE and SPONGENT. In:
Leander, G. (ed.) FSE 2015. LNCS, vol. 9054, pp. 494–515. Springer, Heidelberg
(2015). doi:10.1007/978-3-662-48116-5 24
26. Zhang, W., Bao, Z., Lin, D., Rijmen, V., Yang, B., Verbauwhede, I.: RECTANGLE:
a bit-slice ultra-lightweight block cipher suitable for multiple platforms. IACR
Cryptology ePrint Archive 2014, 84 (2014)
27. Bogdanov, A., Kneˇzevi´c, M., Leander, G., Toz, D., Varıcı, K., Verbauwhede, I.:
spongent: a lightweight hash function. In: Preneel, B., Takagi, T. (eds.) CHES
2011. LNCS, vol. 6917, pp. 312–325. Springer, Heidelberg (2011). doi:10.1007/
978-3-642-23951-9 21
28. Canteaut, A., Rou´e, J.: On the behaviors of aﬃne equivalent Sboxes regard-
ing diﬀerential and linear attacks. In: Oswald, E., Fischlin, M. (eds.) EURO-
CRYPT 2015. LNCS, vol. 9056, pp. 45–74. Springer, Heidelberg (2015). doi:10.
1007/978-3-662-46800-5 3
29. Rotman, J.: An Introduction to the Theory of Groups. Springer, New York (1995)
30. Eiben, A.E., Smith, J.E.: Introduction to Evolutionary Computing. Springer,
Heidelberg (2003)
31. Shibutani, K., Isobe, T., Hiwatari, H., Mitsuda, A., Akishita, T., Shirai, T.: Pic-
colo: an ultra-lightweight blockcipher. In: Preneel, B., Takagi, T. (eds.) CHES
2011. LNCS, vol. 6917, pp. 342–357. Springer, Heidelberg (2011). doi:10.1007/
978-3-642-23951-9 23
32. Evci, M.A., Kavut, S.: DPA resilience of rotation-symmetric S-boxes. In: Yoshida,
M., Mouri, K. (eds.) IWSEC 2014. LNCS, vol. 8639, pp. 146–157. Springer,
Heidelberg (2014). doi:10.1007/978-3-319-09843-2 12
33. Courtois, N.T., Hulme, D., Mourouzis, T.: Solving circuit optimisation problems
in cryptography and cryptanalysis. Cryptology ePrint Archive, Report 2011/475
(2011). http://eprint.iacr.org/
34. Guo, J., Jean, J., Nikoli´c, I., Qiao, K., Sasaki, Y., Sim, S.M.: Invariant Sub-
space Attack Against Full Midori64. Cryptology ePrint Archive, Report 2015/1189
(2015). http://eprint.iacr.org/

Cryptography and Boolean Functions

A Super-Set of Patterson-Wiedemann Functions
– Upper Bounds and Possible Nonlinearities
Sel¸cuk Kavut1(B), Subhamoy Maitra2, and Ferruh ¨Ozbudak3,4
1 Department of Computer Engineering, Balıkesir University,
10145 Balıkesir, Turkey
skavut@balikesir.edu.tr
2 Applied Statistics Unit, Indian Statistical Institute,
203 B. T. Road, Kolkata 700108, India
subho@isical.ac.in
3 Department of Mathematics and Institute of Applied Mathematics,
Middle East Technical University, 06800 Ankara, Turkey
ozbudak@metu.edu.tr
4 Department of Mathematical Sciences,
Aalborg University, Aalborg, Denmark
Abstract. Constructing Boolean functions on odd number of variables
with nonlinearity exceeding the bent concatenation bound is one of the
most diﬃcult combinatorial problems in the domain of Boolean func-
tions and it has deep implications to coding theory and cryptology. After
demonstration of such functions by Patterson and Wiedemann in 1983,
for more than three decades the eﬀorts have been channelized in obtain-
ing the instances only. For the ﬁrst time, in this paper, we try to explore
non-trivial upper bounds on nonlinearity of such functions which are
invariant under several group actions. In fact, we consider much larger
sets of functions than what have been considered so far and obtain tight
upper bounds on the nonlinearity in several cases. To support our claims,
we present computational results for functions on n variables where n
is an odd composite integer, 9 ≤n ≤39. In particular, our results for
n = 15 and 21 are of immediate interest given recent research results in
this domain. Not only the upper bounds, we also identify what are the
nonlinearities that can actually be achieved above the bent concatenation
bound for such class of functions.
Keywords: Nonlinearity bound · Patterson-Wiedemann type
functions · Covering radius · First order Reed-Muller code
1
Introduction
The maximum achievable nonlinearity of an n-variable Boolean function for
n odd and n > 7 is a long standing open problem. The problem is directly
connected to coding theory, since it corresponds to the covering radius of the
c
⃝Springer International Publishing AG 2016
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 227–242, 2016.
DOI: 10.1007/978-3-319-55227-9 16

228
S. Kavut et al.
ﬁrst order Reed-Muller codes of block length 2n. High nonlinearity is an impor-
tant property for the Boolean functions used in cryptographic primitives for
resisting linear cryptanalysis [10] as well as correlation and fast correlation
attacks [11,15] and hence this issue is related to cryptology also. For n even,
the functions with provably maximum nonlinearity 2n−1 −2
n
2 −1 exist and such
functions are called bent, though the complete characterization of such func-
tions is not yet known for n ≥8. Let us consider an n-variable function f
constructed by concatenating two (n −1)-variable bent functions g and h,
i.e., f(x0, x1, . . . , xn−1) = x0g(x1, . . . , xn−1) ⊕(x0 ⊕1)h(x1, . . . , xn−1) for all
(x0, x1, . . . , xn−1) ∈Fn
2. One can then easily check that the nonlinearity of f
is 2n−1 −2
n−1
2 . This is called the bent concatenation bound, which had been
conjectured [4] to be the maximum attainable nonlinearity until disproved [13]
in 1983.
Solving the question for small number of variables dates back to 1972 when
it was shown [1] that the nonlinearity of a 5-variable function is at most 12
which is in fact the bent concatenation bound. Almost a decade later, in 1980,
the problem was solved [12] for 7-variable functions noting that the maximum
nonlinearity here is also equal to the bent concatenation bound which is 56. The
existence of functions on odd number of variables having nonlinearity greater
than the bent concatenation bound had remained unknown till Patterson and
Wiedemann demonstrated [13] in 1983 two functions on 15 variables achieving
nonlinearity 215−1 −2
15−1
2
+ 20 = 16276. Both these functions are obtained
in a very small class consisting of merely 211 functions that are idempotent
(a function f is called idempotent if it is invariant under the action of the
group of Frobenius automorphisms, i.e., such a function satisﬁes the condition
f(α) = f(α2) for all α ∈F2n) and invariant under the action of F∗
25 · F∗
23. Over
two decades later, in 2006, the 9-variable functions having nonlinearity 241 were
found [8] in the class of idempotent functions and shortly after that this result
was improved [7] to 242 by deﬁning a generalized class of idempotent functions,
in which a function f satisﬁes the condition f(α) = f(α2k) for all α ∈F2n where
k is a ﬁxed divisor of n.
Consider an n-variable function (n odd) f having nonlinearity 2n−1 −2
n−1
2 +
μn (μn > 0, integer, i.e., nonlinearity more than the bent concatenation bound)
and an m-variable bent function (m even) g. If f and g are functions on diﬀerent
input variables, f ⊕g (known as direct sum) is an (n + m)-variable Boolean
function having nonlinearity 2n+m−1−2
n+m−1
2
+μn·2
m
2 . Thus, if one starts with a
9-variable function with nonlinearity 29−1−2
9−1
2 +2 = 242 [7], then it is possible
to construct functions of 9+m variables having nonlinearity 29+m−1−2
9+m−1
2
+2·
2
m
2 . For example, by this method, we will have functions on 9 + 6 = 15 variables
with nonlinearity 215−1 −2
15−1
2
+ 2 · 2
15−9
2
= 16256 + 16 = 16272. However, one
should note that the functions identiﬁed by Patterson and Wiedemann [13] are
of nonlinearity 215−1 −2
15−1
2
+ 20 = 16256 + 16 = 16276 > 16272. Thus for
odd n > 15, one should start the construction from such 15-variable functions
as available from [13] in direct sum construction with bent functions to have the

A Super-Set of Patterson-Wiedemann Functions
229
highest achievable nonlinearity known so far. Thus, we like to motivate the term
μn
2
n−1
2
= μn · 2−n−1
2
in such case. As long as we obtain some construction with
maximum known nonlinearity beating the bent concatenation bound, we should
look at this term. For n = 9 [7], this term is 2 · 2−4 = 1
8 and for n = 15, this is
20 · 2−7 =
5
32 [13] which is greater than 1
8. Naturally, till date the best known
μn · 2−n−1
2
is for n = 15 [13].
Now let us get into the details of the Patterson-Wiedemann functions [13],
which we will refer to as PW functions in this document. Let φ2 ∈GLF2(F2n)
be the Frobenius automorphism of F2n, which is given by φ2(α) = α2 for all
α ∈F2n. As aforementioned, the class containing only 211 functions considered
in [13] is formed by imposing the constraint of being invariant under the action
of F∗
25 · F∗
23 and the group of Frobenius automorphisms ⟨φ2⟩. In fact, it is easy
to determine, by performing an exhaustive search, the nonlinearities attained
in this class are 16268, 16269, 16275, and 16276. There are quite a few open
questions here.
– Can we decide what nonlinearities are possible to achieve without performing
the exhaustive search? This question is pertinent as one may like to relax the
constraints and try to search a larger class in the hope of better nonlinearity.
– What are the possible nonlinearities above the bent concatenation bound when
we consider the action of F∗
25 · F∗
23 only and not of the group of Frobenius
automorphisms ⟨φ2⟩? For this, the search complexity becomes 2151 for 15-
variable functions.
– Further, we may consider an even larger class when we consider the action of
F∗
25 only. This makes the search space incredibly huge containing 21057 func-
tions. How can one obtain the possible nonlinearities greater than the bent
concatenation bound in such a large class that cannot be searched exhaus-
tively?
We could answer all these questions for 15-variable PW functions and show
that for all these larger classes, the maximum nonlinearity is 16276, that had
been achieved long back in [13] in a very small class of 211 functions. This is
an important negative result that would save a lot of unsuccessful search in
those larger classes had our result been known. There are further implications
of our results. Until recently, the PW functions beating the bent concatenation
bound were known only for n = 15 = 5·3. The next possible candidate had been
n = 21 = 7·3 and such functions could be found [6] after a long gap of more than
three decades. Each function obtained in [6] are of nonlinearity 221−1−2
21−1
2
+61
and the authors left the open question whether there can be functions having
higher nonlinearity. Our method shows that the upper bound of nonlinearity
in this case could be as high as 221−1 −2
21−1
2
+ 196 considering the action of
F∗
27 · F∗
23 and further the upper bound slightly increases to 221−1 −2
21−1
2
+ 199
considering the action of F∗
27 only. Thus, this is a result in the positive direction
that shows one may indeed put further search eﬀort with the expectation of
obtaining instances of 21-variable functions with higher nonlinearity values.

230
S. Kavut et al.
Thus, in general framework, we consider n-variable functions1, where n = p·q
such that p and q are distinct odd primes with p > q. Then we try to obtain the
possible nonlinearity values greater than the bent concatenation bound for the
functions which are
– invariant under the action of F∗
2p · F∗
2q and also
– invariant under the action of either F∗
2p or F∗
2q.
We present techniques that involve basic combinatorics and elementary num-
ber theoretic techniques. Numerical results are presented for the odd composite
integers n where 9 ≤n ≤39. To the best of our knowledge, no such result
on upper bound of nonlinearity in these larger classes could be explored since
the construction of 15-variable PW functions [13] that dates back to 1983. The
generic upper bound on nonlinearity for functions on odd number of variables n
is 2⌊2n−2 −2
n
2 −2⌋[5]. Our results show nontrivial upper bounds for the class of
functions we consider here and that is indeed less than the generic upper bound
provided in [5]. Next we provide necessary background by reviewing the PW
type functions.
2
Background
Let f : F2n→F2 be a Boolean function. For any ω ∈F2n, the Walsh-Hadamard
transform Wf(ω) of f is deﬁned as Wf(ω) = 
α∈F2n(−1)T rn
1 (ωα)+f(α), where
Trn
1 (α) = α + α2 + α22 + . . . + α2n−1 for all α ∈F2n. From this, the non-
linearity nl(f) can be expressed as nl(f) = 2n−1 −1
2 maxω∈F2n |Wf(ω)|. The
distance d(g, h) between g and h is deﬁned as the Hamming distance between
2n length vectors (g(α0), g(α1), . . . , g(α2n−1)) and (h(α0), h(α1), . . . , h(α2n−1)),
where {α0, α1, . . . , α2n−1} are the elements of F2n. Let lω(α) = Trn
1 (ωα) and
hω(α) = lω(α) + 1. Then the nonlinearity nl(f) can be equivalently deﬁned
as the minimum distance of f from all aﬃne functions {lω, hω | ω ∈F2n} as
nl(f) = minω∈F2n{d(f, lω), d(f, hω)}.
In the following, we brieﬂy revisit the PW construction mostly following [2,
13]. Let n = p · q such that p and q are two distinct odd primes and consider an
n-variable Boolean function f having the support Supp(f) = {α ∈F2n | f(α) =
1} = ∪ℓ
i=1αiF∗
2p, where αi’s lie in the diﬀerent cosets of F∗
2p in F∗
2n. Then it is
clear that
d(f, 0) = ℓ(2p −1),
d(f, 1) = 2n −ℓ(2p −1),
(1)
where 0 and 1 are the all-zero and all-one vectors of length 2n, respectively. Let
us deﬁne Hω = Supp(hω) = {α ∈F2n | Trn
1 (ωα) = 0}, which is a hyperplane
in Fn
2 when considered as a vector space over F2. Further, let Hω↾αiF∗
2p be the
1 In fact we also consider the cases where n is an odd composite integer such as n = 9,
25, or 27.

A Super-Set of Patterson-Wiedemann Functions
231
restriction of Hω to the coset αiF∗
2p. It can be shown [2,13] that
Hω↾αiF∗
2p
 is
either 2p−1 −1 or 2p −1 and the number of those having cardinality 2p−1 −1
is 2n−p. Suppose t(ω) = |{αiF∗
2p | αiF∗
2p ⊆Supp(f) ∩Hω}|, or equivalently t(ω)
is the number of αi’s for which Trp
1(ωαi) = 0 ∀ω ∈F∗
2p. Then the number of
cosets of F∗
2p for which both
Hω↾αiF∗
2p
 = 2p−1 −1 and
Supp(f)↾αiF∗
2p
 = 2p −1
is found to be ℓ−t(ω). Following this argument, one can get
d(f, hω) = (ℓ−t(ω)) · 2p−1 +

2n−p −ℓ+ t(ω)

· (2p−1 −1)
+
2n −1
2p −1 −2n−p −t(ω)

· (2p −1) + 1,
= 2n−1 −2p · t(ω) + ℓ.
(2)
Similarly we have
d(f, lω) = 2n−1 + 2p · t(ω) −ℓ.
(3)
As a consequence, from (1)–(3) nl(f) can be rewritten as follows:
nl(f) = min
ω∈F∗
2n{ℓ(2p −1), 2n −ℓ(2p −1), 2n−1 −2p · t(ω) + ℓ, 2n−1 + 2p · t(ω) −ℓ},
which implies that if nl(f) > 2n−1 −2
n−1
2
then the following conditions have to
be satisﬁed:
2n−1 −2(n−1)/2
2p −1
< ℓ< 2n−1 + 2(n−1)/2
2p −1
,
(4)
1
2p
2n−1 −2(n−1)/2
2p −1
−2(n−1)/2

< t(ω) < 1
2p
2n−1 + 2(n−1)/2
2p −1
+ 2(n−1)/2

.
(5)
The condition given by (4) is called the weight condition, as ℓis the number of
cosets in the support of f. In [13], it was computationally shown that there is
no function for n = 3 · 3 satisfying these two conditions. On the other hand, for
n = 5 · 3, there are 1057 cosets of F∗
25 in F∗
215, which makes an exhaustive search
impossible (in the subsequent section we prove that the maximum nonlinearity
in this case is 16276). Hence, an additional constraint of being invariant under
the action of F∗
23 and the group of Frobenius automorphism is imposed [13] on
f, which provides a very small class of functions leaving only 211 options to
search (in fact using the weight condition the number of options can be reduced
to
10
5

= 252 as noticed in [13]). Finally, two functions with nonlinearity 16276
are obtained [13] in this class.
At this point, let us recall a more general deﬁnition [6] of the aforementioned
PW construction:
Deﬁnition 1. Let n = p · q, where p, q > 2 are prime numbers such that p > q.
Let the product R = F2p∗·F2q ∗be the cyclic group of cardinality r = (2p−1)(2q−
1) in F2n. Let ⟨φ2⟩be the group of Frobenius automorphisms where φ2 : F2n →
F2n is deﬁned by α →α2. The function f is called PW type if it is invariant
under the action of R and ⟨φ2⟩.

232
S. Kavut et al.
For simplicity, one can view [2] a PW type function as an interleaved sequence [3]
which is deﬁned as follows:
Deﬁnition 2. Let m = dr, where d, r > 1 are integers. The (d, r)-interleaved
sequence Ad,r corresponding to the binary sequence A = {a0, a1, a2, . . . , am−1} is
deﬁned as the matrix whose (i, j)th entry is equal to ai.d+j, where i = 0, 1, . . . , r−
1 and j = 0, 1, . . . , d −1.
Suppose m = 2n −1. An interleaved sequence Ad,r can be associated with the
ordered sequence {f(1), f(ζ), f(ζ2), . . . , f(ζ2n−2)} such that ai·d+j = f(ζi·d+j),
where ζ is a primitive element in F2n. We call this interleaved sequence the
(d, r)-interleaved sequence corresponding to f with respect to ζ. Let d = (2p −
1)(2q −1). Then it follows from Deﬁnition 1 that the (d, r)-interleaved sequence
of an n-variable PW type function consists of either all 0 or all 1 columns, since
the corresponding function f is invariant under the action of R. Further, the
invariance under the action of ⟨φ2⟩implies that f is an idempotent function and
the ith column has the same value as the jth column if i ≡j2s mod d for some
non-negative integer s. This equivalence relation, denoted by ρd, is given as:
i ρd j ⇔there exists an integer s > 0 such that i ≡j2s mod d.
(6)
For n = 15, the PW construction can be represented by the (151, 217)-interleaved
sequence. Using the equivalence relation ρ151, one obtains 11 groups, among
which there are 10 groups of size 15 and 1 group of size 1. Notice that any
element in a group determines 217 positions in the truth table of f. Since the
weight condition gives 524.3871 < ℓ< 532.6452, i.e., 525 ≤ℓ≤532, we have
to choose 5 groups among the 10 groups of size 15 and we may or may not
choose the remaining 1 group of size 1 (observe that ℓcan be either 5 · 15 · 7 =
525 or 5 · 15 · 7 + 1 = 526). There are 8 functions with nonlinearities 16268,
16269, 16275, and 16276 exceeding the bent concatenation bound 214 −27 =
16256 in the corresponding search space. One half of these functions are obtained
from the other half by complementing the truth tables except their ﬁrst bits.
Hence, the nonlinearity 16276 (resp., 16268) is obtained from the function with
nonlinearity 16275 (resp., 16269) in this way, and vice versa (in the following
section, without using an exhaustive search, we show that these nonlinearities
are the only possible ones that can be attained by the PW construction and in
a much broader class).
3
Nonlinearity of the Functions on n = p · q Variables
Invariant Under the Action of F∗
2p · F∗
2q
In this section, we determine all possible nonlinearities of the PW type func-
tions and their variants for which n = p · q where p, q are odd primes and
p > q. The functions we consider are invariant under the action of F∗
2p ·F∗
2q. This
class is much larger than the class considered in [13] where the action of Frobe-
nius automorphism was considered. In most of the cases, we obtain nonlinearity

A Super-Set of Patterson-Wiedemann Functions
233
bounds strictly less than the generic upper bound in [5] that provides the impor-
tance of our result. We provide detailed examples with n = 15, 21 that answers
several open questions that remained unanswered for the 15-variable [13] and
21-variable [6] functions.
In the following theorem we show what are the possible nonlinearities greater
than the bent concatenation bound when we consider the action of F∗
2p ·F∗
2q. This
is a larger class than what was considered in [13] as we do not consider the action
of Frobenius automorphism here.
Theorem 1. Let f be an n-variable function with nl(f) = 2n−1 −2
n−1
2
+ μn
which is invariant under the action of F∗
2p · F∗
2q, where μn ∈Z+ and n = p · q
such that p, q are two distinct odd primes with p > q. Then at least one of the
values in the following two sets is an integer:
(i)

2n−1−2
n−1
2
+μn
(2p−1)(2q−1) , 2n−1+2
n−1
2
−μn
(2p−1)(2q−1)
	
,
(ii)

ℓ(2q−1)−2
n−1
2
+μn
2p
| ℓ∈Lμn
	
∪

ℓ(2q−1)+2
n−1
2
−μn
2p
| ℓ∈Lμn
	
,
where 1 ≤μn ≤2

2n−2 −2
n
2 −2
−

2n−1 −2
n−1
2

and
Lμn =

ℓ∈Z+ | 2n−1 −2
n−1
2
+ μn
(2p −1)(2q −1)
≤ℓ≤2n−1 + 2
n−1
2
−μn
(2p −1)(2q −1)

.
Proof. In the following, we consider two cases: either the nonlinearity equals
d(f, 0) or d(f, 1), and then at least one of the values displayed in (i) is an
integer, or (non-exclusively) the nonlinearity equals d(f, hω) or d(f, lω) and at
least one of the values displayed in (ii) is an integer.
(i) Since f is invariant under the action of F∗
2p·F∗
2q, its support can be written as
Supp(f) = ∪ℓ
i=1αi(F∗
2p ·F∗
2q), where αi’s lie in the diﬀerent cosets of F∗
2p ·F∗
2q
in F∗
2n. Then it is clear that
d(f, 0) = ℓ(2p −1)(2q −1),
d(f, 1) = 2n −ℓ(2p −1)(2q −1).
(7)
Note that if nl(f) = 2n−1 −2
n−1
2
+ μn, then either d(f, 0) or d(f, 1) can be
equal to 2n−1 −2
n−1
2
+ μn, which gives the possible values of ℓin part (i).
Finally, recall that the generic upper bound [5] on nonlinearity for functions
on odd number of variables n is 2⌊2n−2 −2
n
2 −2⌋, from which we get the
values of μn used to compute ℓ(and t(ω)).
(ii) Clearly, (7) is also obtained from (1) by substituting ℓ(2q −1) for ℓ, due to
the fact that each coset of F∗
2p · F∗
2q consists of 2q −1 distinct cosets of F∗
2p
in F∗
2n. Following the same argument, one can get the distances below:
d(f, hω) = 2n−1 −2p · t(ω) + ℓ(2q −1),
d(f, lω) = 2n−1 + 2p · t(ω) −ℓ(2q −1),
(8)

234
S. Kavut et al.
which is obtained from (2) and (3) by using the same substitution, where
lω(α) = Trn
1 (ωα), hω(α) = lω(α) + 1, and t(ω) is the number of cosets
of F∗
2p totally contained in Supp(hω) ∩Supp(f). Next, as in the proof of
part (i), it follows from the deﬁnition of nonlinearity that t(ω) can be either
ℓ(2q−1)−2
n−1
2
+μn
2p
or ℓ(2q−1)+2
n−1
2
−μn
2p
. However, note that d(f, 0), d(f, 1) ≥
nl(f) = 2n−1 −2
n−1
2
+ μn. This gives, 2n−1−2
n−1
2
+μn
(2p−1)(2q−1)
≤ℓ≤2n−1+2
n−1
2
−μn
(2p−1)(2q−1) .
Thus, we get all the possible values of t(ω) in part (ii).
⊓⊔
3.1
Case n = 15
The 15-variable PW functions are the most important in the domain of nonlin-
earity of Boolean functions as for the ﬁrst time the bent concatenation bound has
been defeated in this scenario [13]. There has been eﬀorts to obtain Boolean func-
tions with good cryptographic properties by modifying the PW functions [13]
as evident from [9,14]. The search space for 15-variable PW functions [13], con-
sidering invariance under F∗
25 · F∗
23 as well as Frobenius automorphism, was as
little as 211 and thus it was very easy to search and obtain the functions with
nonlinearity as high as 16276. However, when we do not consider the Frobenius
automorphism, the class becomes much larger. In this case
215−1
(25−1)(23−1) = 151
and hence the search space is as large as 2151. Exhaustive search here is not
feasible. However, our result below shows that the maximum nonlinearity in this
larger class is again 16276. We present the proof in details and then discuss the
step by step description of Theorem 1 in this direction.
Corollary 1. Consider a 15-variable function f that is invariant under the
action of F∗
25 · F∗
23. Then nl(f) ≤16276 = 215−1 −2
15−1
2
+ 20.
Proof. We have Supp(f) = ∪ℓ
i=1αi(F∗
2p · F∗
2q). One can write Supp(f) in terms
of the cosets F∗
2p in F∗
2n as ∪ℓ′
i=1βiF∗
2p, where ℓ′ = ℓ(2q −1). Hence the weight
condition (4) can be rewritten as
2n−1 −2(n−1)/2
2p −1
< ℓ(2q −1) < 2n−1 + 2(n−1)/2
2p −1
.
(9)
Notice that in our case n = 15, p = 5, and q = 3. Substituting these values in (9),
we get 74.9124 < ℓ< 76.0922, and thus, we have 75 ≤ℓ≤76. Now suppose there
exists a 15-variable function f with nl(f) = 215−1 −2
15−1
2
+ 20 + c = 16276 + c,
where c is a positive integer. Then one can get the corresponding weight condition
for the existence of f as
215−1 −2
15−1
2
+ 20
25 −1
+
c
25 −1 ≤ℓ(23 −1) ≤215−1 + 2
15−1
2
−20
25 −1
−
c
25 −1,
from which, to have nonlinearity 16276 + c, we get
75.0046 +
c
7(25−1) ≤ℓ≤76 −
c
7(25−1), and thus, there is no solution for ℓ. ⊓⊔

A Super-Set of Patterson-Wiedemann Functions
235
To clarify it further, let us consider the following weight condition to have non-
linearity 215−1 −2
15−1
2
+ 19 = 16275:
215−1 −2
15−1
2
+ 19
7(25 −1)
= 75 ≤ℓ≤76.0046 = 215−1 + 2
15−1
2
−19
7(25 −1)
.
Note that the lower bound is exactly 75 and it exceeds this value if we replace
19 by 20, which provides nonlinearity 16276. In this case the upper bound is
exactly 76, which leaves 76 as the only option for ℓ. However, observe that if
we instead replace 19 by 21, then the upper bound becomes less than 76 for
which there is no ℓsatisfying the weight condition. Recall from [2,13] that the
PW constructions with nonlinearity 16276 belong to a class of very small size
in which there exist only 211 functions that are idempotent and invariant under
the action of F∗
25 · F∗
23. On the other hand, the above corollary shows that there
is no function with nonlinearity >16276 in a much larger class of size 2151 which
is formed by lifting the condition of being idempotent.
We ﬁnally discuss what are the possible values of μn in the case of n = 15.
From the above arguments, we deduce that the possible values of μ15 are 19
and 20, when we take the integer values of ℓinto account. In other words, if we
consider only part (i) of Theorem 1, then the following values of ℓbecomes an
integer for μ15 = 19 and 20:
ℓ∈

215−1 −2
15−1
2
+ μ15
(25 −1)(23 −1)
, 215−1 + 2
15−1
2
−μ15
(25 −1)(23 −1)

,
which yields the nonlinearities 215−1 −2
15−1
2
+ 19 = 16275 and 215−1 −2
15−1
2
+
20 = 16276 respectively. To obtain the other possible values of μ15 (and the
corresponding nonlinearities), let us consider part (ii) of Theorem 1. It is easy to
check that 75 ≤ℓ≤76 (i.e., Lμ15 = {75, 76}) for all 1 ≤μ15 ≤18. Hence, one
of the following values of t(ω) must be an integer to have nonlinearity nl(f) =
215−1 −2
15−1
2
+ μ15:
t(ω) ∈

ℓ(23 −1) −2
15−1
2
+ μ15
25
, ℓ(23 −1) + 2
15−1
2
−μ15
25

,
where ℓ∈Lμ15 and 1 ≤μ15 ≤18. One can computationally ﬁnd that t(ω) is
an integer for μ15 = 12 and 13, from which we get the nonlinearities 215−1 −
2
15−1
2
+ 12 = 16268 and 215−1 −2
15−1
2
+ 13 = 16269 respectively.
Thus, with these values, we completely solve why such nonlinearities are
obtained for the PW functions [13], which could never be answered before. Note
that the consideration of Frobenius automorphism does not aﬀect the possible
nonlinearity values. As we know, functions invariant under the action of Frobe-
nius automorphism (also called idempotents) are actually rotation symmetric
Boolean functions [8,14]. Considering this restriction reduces the search space,
but at the same time this space provides a good sample of highly nonlinear
functions. It was indeed quite judicious to study this small search space [13],

236
S. Kavut et al.
however, why such nonlinearity values could be obtained was not known earlier
that we answer here. With our result, now we know that the nonlinearity 16276
is the maximum possible value in a much larger class of size 2151, which was
attained in a much smaller sample space of only 211 in [13].
3.2
Case n = 21
Now we consider the case n = p · q = 7 · 3 = 21. The constraints for 15-
variable functions was such that one had to satisfy 11 inequalities for 11 binary
variables and it could be done easily by exhaustive search. The situation is
not as simple for 21 or more variables. In [13], the choice of orbits for general
case could not be explained and also in [2] it has been commented that such
search might be infeasible. In a very recent result [6], by heuristic search, the
existence of PW functions could be demonstrated for n = 21. The nonlinearity
of such functions are 221−1 −2
21−1
2
+ 61, i.e., μ21 = 61 and one may easily note
that 61 · 2−21−1
2
< 20 · 2−15−1
2 . Thus, even after the discovery of 21-variable
PW functions having nonlinearity more than bent concatenation bound, the old
maximum achievable nonlinearity using the 15-variable PW functions could not
be beaten. Thus, the most natural question is: Can there be the existence of
21-variable functions such that μ21 > 20·2
21−15
2
= 160? Our analysis shows that
the non-trivial upper bound here corresponds to μ21 = 196 and thus there is a
hope for improved result with further search eﬀort.
Let us ﬁrst proceed as in the analysis for the 15-variable case. Here we con-
sider the class of 21-variable functions that are invariant under the action of
F∗
27 · F∗
23. There are 2359 cosets and hence the search space is of size 22359. We
obtain the following inequality from (9):
221−1 −2
21−1
2
27 −1
< ℓ(23 −1) < 221−1 + 2
21−1
2
27 −1
,
and thus, we get 1178.3487 < ℓ< 1180.6524, i.e., 1179 ≤ℓ≤1180. Suppose
there exists a function f with nl(f) = 221−1 −2
21−1
2
+ μ21. Then, to achieve this
nonlinearity, the following condition has to be satisﬁed:
221−1 −2
21−1
2
27 −1
+
μ21
27 −1 ≤7ℓ≤221−1 + 2
21−1
2
27 −1
−
μ21
27 −1,
and thus, we have 1178.3487 +
μ21
7(27−1) ≤ℓ≤1180.6524 −
μ21
7(27−1). This inequal-
ity has no solution for ℓonly if μ21 > 580. However, the gap between the bent
concatenation nonlinearity (1047552 = 221−1 −2
21−1
2 ) and the generic upper
bound [5] (1047850 = 2⌊221−2 −2
21
2 −2⌋) on the nonlinearity of 21-variable func-
tions is 298 (<580). Thus, what we have obtained so far does not provide any
non-trivial upper bound for this class. However, with more detailed analysis we
obtain the following non-trivial upper bound.
Corollary 2. Let us consider a 21-variable function f which is invariant under
the action of F∗
27 · F∗
23. Then nl(f) ≤1047748 = 221−1 −2
21−1
2
+ 196.

A Super-Set of Patterson-Wiedemann Functions
237
Proof. It follows from Theorem 1. Let us consider part (i) of Theorem 1. Then
there can be the existence of 21-variable PW functions with nl(f) = 221−1 −
2
21−1
2
+ μ21 if one of the following values of ℓis an integer:
ℓ∈

221−1 −2
21−1
2
+ μ21
(27 −1)(23 −1)
, 221−1 + 2
21−1
2
−μ21
(27 −1)(23 −1)

,
where 1 ≤μ21 ≤298

= 2

221−2 −2
21
2 −2
−

221−1 −2
21−1
2

. However, it can
be computationally checked that no value of μ21 makes ℓan integer.
Next, consider part (ii) of Theorem 1. From the earlier discussion, it is evident
that Lμ21 = {1179, 1180} (i.e., 1179 ≤ℓ≤1180) for all 1 ≤μ21 ≤298. Then at
least one of the following values of t(ω) must be an integer to have nonlinearity
nl(f) = 221−1 −2
21−1
2
+ μ21:
t(ω) ∈

ℓ(23 −1) −2
21−1
2
+ μ21
27
, ℓ(23 −1) + 2
21−1
2
−μ21
27

,
where ℓ∈Lμ21 and 1 ≤μ21 ≤298. We ﬁnd that only the 8 values of μ21 make
t(ω) an integer: μ21 ∈{60, 61, 67, 68, 188, 189, 195, 196}. Hence, the maximum
possible nonlinearity is 1047748 = 220 −210 + 196.
⊓⊔
Note from the above proof that one of the possible values of μ21 is 61, which
corresponds to the nonlinearity 1047613 = 220 −210 +61 achieved in [6] as afore-
mentioned. However, there can be the existence of μ21 ∈{188, 189, 195, 196},
which provides μ21 · 2−21−1
2
> 20 · 2−15−1
2 , yielding the best known nonlinearity
till date.
3.3
The Algorithm and Numerical Results
Considering Theorem 1, we devise Algorithm 1 to ﬁnd all possible nonlinearities
greater than the bent concatenation bound for the functions on odd number
n = p·q of variables that are invariant under the action of F∗
2p ·F∗
2q, where p and
q are distinct odd primes such that p > q. In this algorithm, for each value of
ℓ∈

ℓ∈Z+ |
2n−1 −2
n−1
2
(2p −1)(2q −1) = lb < ℓ< ub =
2n−1 + 2
n−1
2
(2p −1)(2q −1)

,
(10)
we store the possible nonlinearities 2n−1 −2
n−1
2
+ μn in the array NL when-
ever the condition given by Theorem 1 is satisﬁed given the value of μn ∈
{1, 2, . . . , μmax
n
}, where μmax
n
(computed using the generic upper bound in [5])
is the maximum possible value of μn for odd number n of variables.
We have performed Algorithm 1 and give the maximum values μmax
p·q (≤μmax
n
)
of μn achievable by the n-variable functions that are invariant under the action
of F∗
2p · F∗
2q in Table 1 for 15 ≤n = p · q ≤39, where p and q are distinct odd
primes such that p > q. From Table 1, it is seen that μmax
p·q
= μmax
n
for only
n = 35 and μmax
p·q
< μmax
n
for all the remaining values of n.

238
S. Kavut et al.
Algorithm 1: Computation of all possible nonlinearities > 2n−1 −2
n−1
2 .
input : n, p, where n = p · q such that p and q are odd primes with p > q.
output: Nonlinearities given by the array NL.
k ←0;
1
μmax
n
←2

2n−2 −2
n
2 −2
−

2n−1 −2
n−1
2

;
2
lb ←
2n−1−2
n−1
2
(2p−1)(2q−1);
3
ub ←
2n−1+2
n−1
2
(2p−1)(2q−1);
4
for ℓ←lb to ub do
5
for μn ←1 to μmax
n
do
6
lbn ←2n−1−2
n−1
2
+μn
(2p−1)(2q−1)
;
7
ubn ←2n−1+2
n−1
2
−μn
(2p−1)(2q−1)
;
8
if lbn ≤ℓ≤ubn then
9
tl ←ℓ(2q−1)−2
n−1
2
+μn
2p
;
10
tu ←ℓ(2q−1)+2
n−1
2
−μn
2p
;
11
κ ←{lbn, lbu, tl, tu};
12
if any value in κ is an integer then
13
nl ←2n−1 −2
n−1
2
+ μn;
14
if nl is not in NL then
15
NL[k] ←nl;
16
k ←k + 1;
17
return NL;
18
3.4
Idempotents, i.e., Functions Invariant Under the Action of ⟨φ2⟩
Next we consider the class of functions that are invariant under the action of
F∗
2p · F∗
2q and ⟨φ2⟩as well. In this case, we need to take only some combinations
of the groups (obtained by the equivalence relation (6)) satisfying the weight
condition in (10) into account, which reduces the number of possible values of
ℓin Algorithm 1. Thus, modifying Algorithm 1 accordingly, we have computed
(see Table 1) the maximum values μmax
p·q,⟨φ2⟩of μn which are achievable in this
class. In Table 1, ℓp·q denotes the values of ℓgiven by (10) and ℓp·q,⟨φ2⟩denotes
those of ℓp·q obtained by considering also the action of ⟨φ2⟩. Comparing the
values of μmax
p·q,⟨φ2⟩with μmax
n
in Table 1, we ﬁnd that μmax
p·q,⟨φ2⟩< μmax
n
for all
15 ≤n ≤39 whereas μmax
p·q,⟨φ2⟩< μmax
p·q
for n = 33 and 35 only. Note that the
achievable nonlinearities for n = 15 and 21, given in the previous subsections,
remain the same even after imposing the constraint of being invariant under the
action of ⟨φ2⟩, since the values of ℓp·q are the same as those of ℓp·q,⟨φ2⟩in both
cases.

A Super-Set of Patterson-Wiedemann Functions
239
Table 1. The values of μmax
p·q
and μmax
p·q,⟨φ2⟩together with those of ℓp·q and ℓp·q,⟨φ2⟩for
15 ≤n ≤39, where n = p · q such that p and q are two distinct odd primes with p > q.
n
ℓp·q
ℓp·q,⟨φ2⟩
μmax
p·q
μmax
p·q,⟨φ2⟩μmax
n
15 [75, 76]
{75, 76}
20
20
36
21 [1179, 1180]
{1179, 1180}
196
196
298
33 [299735, 299744]
{299739, 299740}
17426
17412
19194
35 [4363663, 4363728] {4363695, 4363696}
38390
38352
38390
39 [4794067, 4794084] {4794075, 4794076} 151598 151598
153560
4
Functions Invariant Under the Action of F∗
2p
We start with the following corollary of Theorem 1.
Corollary 3. Let f be an n-variable function with nl(f) = 2n−1 −2
n−1
2
+ μn
which is invariant under the action of F∗
2p, where 1 < p|n, n is odd, and μn ∈Z+.
Then at least one of the values in the following two sets is an integer:
(i)

2n−1−2
n−1
2
+μn
2p−1
, 2n−1+2
n−1
2
−μn
2p−1
	
,
(ii)

ℓ−2
n−1
2
+μn
2p
| ℓ∈Lμn
	
∪

ℓ+2
n−1
2
−μn
2p
| ℓ∈Lμn
	
,
where 1 ≤μn ≤2

2n−2 −2
n
2 −2
−

2n−1 −2
n−1
2

and
Lμn =

ℓ∈Z+ | 2n−1 −2
n−1
2
+ μn
2p −1
≤ℓ≤2n−1 + 2
n−1
2
−μn
2p −1

.
Proof. At least one of the following distances have to be equal to nl(f) = 2n−1 −
2
n−1
2
+ μn: d(f, 0) = ℓ(2p −1), d(f, 1) = 2n −ℓ(2p −1), d(f, hω) = 2n−1 −2p ·
t(ω)+ℓ′, d(f, lω) = 2n−1+2p·t(ω)−ℓ′, where ℓ′ ∈Lμn. Thus, one or more values
given by (i) and (ii) have to be an integer. Recall that the upper bound [5] gives
nl(f) ≤2

2n−2 −2
n
2 −2
. Hence the proof.
⊓⊔
Using this corollary, we modify Algorithm 1 to ﬁnd all possible nonlinearities
greater than 2n−1 −2
n−1
2
that can be achieved in the class of functions that
are invariant under the action of F∗
2p, where n is an odd composite integer and
1 < p|n. More speciﬁcally, in the modiﬁed version of Algorithm 1, we replace
ℓ(2q −1) in the numerators of tl and tu (given by lines 10 and 11 of Algorithm 1
respectively) with ℓand remove the term (2q −1) from the denominators of
lb, ub, lbn, and ubn (given by lines 3, 4, 7, and 8 of Algorithm 1 respectively).
Performing the modiﬁed version, we present in Table 2 the maximum values
μmax
n,p (≤μmax
n
) of μn attainable in the corresponding classes for the composite
integers n, where 9 ≤n ≤39 and 1 < p|n. We have also given the values of

240
S. Kavut et al.
Table 2. The values of μmax
n,p

= μmax
n,p,⟨φ2⟩
	
together with those of ℓn,p for 9 ≤n ≤39,
where n is an odd composite integer and 1 < p|n.
(n, p)
ℓn,p
μmax
n,p

= μmax
n,p,⟨φ2⟩
	
μmax
n
(9, 3)
[35, 38]
4
4
(15, 3)
[2323, 2358]
36
36
(15, 5)
[525, 532]
20
(21, 3)
[149651, 149942]
298
298
(21, 7)
[8249, 8264]
199
(25, 5)
[541069, 541332]
1198
1198
(27, 3)
[9585811, 9588150]
2398
2398
(27, 9)
[131313, 131344]
2316
(33, 3)
[613557395, 613576118]
19194
19194
(33, 11) [2098145, 2098208]
17432
(35, 5)
[554185101, 554193556]
38390
38390
(35, 7)
[135273529, 135275592]
38390
(39, 3)
[39268197523, 39268347318] 153560
153560
(39, 13) [33558465, 33558592]
151598
ℓ(referred to as ℓn,p) used in the same algorithm. It is found that the generic
upper bound 2n−1 −2
n−1
2
+ μmax
n
remains the same, i.e., μmax
n,p
= μmax
n
, for all
p ≤n
p . However, except for n = 35, it provides noticeably lower nonlinearities
than the generic upper bound for all p >
n
p . Note that only for n = 35, we
have μmax
n
= μmax
n,p
= μmax
n,q . We see from Table 2 that μmax
15,5 = 20. This means
nl(f) ≤215−1 −2
15−1
2
+ 20 = 16276 in the class of functions that are invariant
under the action of F∗
25 for which the search space becomes 21057 as there are
215−1
25−1 = 1057 cosets of F∗
25 in F∗
215. On the other hand, we observe from Table 2
that μmax
21,7 = 199 whereas μmax
7·3
= μmax
7·3,⟨φ2⟩= 196 (see Table 1). Keeping in mind
that there are 115 groups under the equivalence relation ρ
221−1
(27−1)(23−1) = ρ2359
and 221−1
27−1 = 16513 cosets of F∗
27 in F∗
221, this implies that if we increase the
search space from 2115 to 216513, the nonlinearity bound slightly increases from
221−1−2
21−1
2
+196 to 221−1−2
21−1
2
+199. For n = 9, 15, and 21, all the achievable
values μn,p of μn are given in Table 3.
Let us now consider the class of functions that are invariant under the action
of F∗
2p and ⟨φ2⟩. As in the previous section, we expect that some of the possible
values of ℓcomputed in the aforementioned version of Algorithm 1 are eliminated.
Hence, by suitably adapting it, we have computed the maximum values μmax
n,p,⟨φ2⟩
of μn which are attainable in the corresponding classes; however, we ﬁnd that,
as shown in Table 2, the values of μmax
n,p,⟨φ2⟩are the same as those of μmax
n,p .
In Table 3, all the possible values μn,p,⟨φ2⟩of μn are also given for n = 9, 15,
and 21. We note that the values of μn,p,⟨φ2⟩do not cover all those of μn,p for
(n, p) = (9, 3) and (21, 7), although μmax
n,p,⟨φ2⟩= μmax
n,p
for all the values of (n, p)
in Table 2.

A Super-Set of Patterson-Wiedemann Functions
241
Table 3. The values of μn,p and μn,p,⟨φ2⟩for n = 9, 15, and 21.
(n, p)
μn,p
μn,p,⟨φ2⟩
μmax
n
(9, 3)
[2, 4]
[3, 4]
4
(15, 3) [1, 36]
[1, 36]
36
(15, 5) [12, 20]
[12, 20]
(21, 3) [1, 298]
[1, 298]
298
(21, 7) [56, 72] ∪[185, 199] [60, 68] ∪[71, 72] ∪[188, 196] ∪[198, 199]
5
Conclusion
We have presented non-trivial upper bounds on the nonlinearity of PW type
functions and their super-sets. Our method can be applied algorithmically for
any n-variable function, where n is odd and not prime. It also identiﬁes all the
attainable nonlinearities higher than the bent concatenation bounds. Computa-
tional results are presented for functions on n-variables where n is odd composite
and 9 ≤n ≤39. We particularly explain the issues for n = 15 and 21 in detail
as these are the cases that received serious attention recently. We also provide
numerical results for larger variables and more research in this area is necessary
to explore the situation further. The results obtained in this paper related to
upper bound of nonlinearity couldn’t be achieved for more than three decades
even after substantial eﬀorts as evident from literature. Towards further research,
one may study the Walsh spectra of such functions in more details and apply
our strategy for prime n ≥11 considering the factors of 2n −1.
References
1. Berlekamp, E.R., Welch, L.R.: Weight distributions of the cosets of the (32, 6)
Reed-Muller code. IEEE Trans. Inf. Theory 18(1), 203–207 (1972)
2. Gangopadhyay, S., Keskar, P.H., Maitra, S.: Patterson-Wiedemann construction
revisited. Discret. Math. 306(14), 1540–1556 (2006)
3. Gong, G.: Theory and applications of q-ary interleaved sequences. IEEE Trans.
Inf. Theory 41(2), 400–411 (1995)
4. Helleseth, T., Kløve, T., Mvkkeltveit, J.: On the covering radius of binary codes.
IEEE Trans. Inf. Theory 24(5), 627–628 (1978)
5. Hou, X.-D.: On the norm and covering radius of ﬁrst-order Reed-Muller codes.
IEEE Trans. Inf. Theory 43(3), 1025–1027 (1997)
6. Kavut, S., Maitra, S.: Patterson-Wiedemann type functions on 21 variables with
nonlinearity greater than bent concatenation bound. IEEE Trans. Inf. Theory
62(4), 2277–2282 (2016)
7. Kavut, S., Y¨ucel, M.D.: 9-variable Boolean functions with nonlinearity 242 in the
generalized rotation symmetric class. Inf. Comput. 208(4), 341–350 (2010)
8. Kavut, S., Maitra, S., Y¨ucel, M.D.: Search for Boolean functions with excellent
proﬁles in the rotation symmetric class. IEEE Trans. Inf. Theory 53(5), 1743–
1751 (2007)

242
S. Kavut et al.
9. Maitra, S., Sarkar, P.: Modiﬁcations of Patterson-Wiedemann functions for cryp-
tographic applications. IEEE Trans. Inf. Theory 48(1), 278–284 (2002)
10. Matsui, M.: Linear cryptanalysis method for DES cipher. In: Helleseth, T. (ed.)
EUROCRYPT 1993. LNCS, vol. 765, pp. 386–397. Springer, Heidelberg (1994).
doi:10.1007/3-540-48285-7 33
11. Meier, W., Staﬀelbach, O.: Fast correlation attacks on stream ciphers. In:
Barstow, D., Brauer, W., Brinch Hansen, P., Gries, D., Luckham, D., Moler, C.,
Pnueli, A., Seegm¨uller, G., Stoer, J., Wirth, N., G¨unther, C.G. (eds.) EURO-
CRYPT 1988. LNCS, vol. 330, pp. 301–314. Springer, Heidelberg (1988). doi:10.
1007/3-540-45961-8 28
12. Mykkeltveit, J.J.: The covering radius of the (128, 8) Reed-Muller code is 56. IEEE
Trans. Inf. Theory 26(3), 358–362 (1983)
13. Patterson, N.J., Wiedemann, D.H.: The covering radius of the (215, 16) Reed-
Muller code is at least 16276. IEEE Trans. Inf. Theory IT–29(3), 354–356 (1983).
See also correction: IEEE Trans. Inf. Theory IT-36(2), 443 (1990)
14. Sarkar, S., Maitra, S.: Idempotents in the neighbourhood of Patterson-Wiedemann
functions having Walsh spectra zeros. Des. Codes Crypt. 49(1–3), 95–103 (2008)
15. Siegenthaler, T.: Decrypting a class of stream ciphers using ciphertext only. IEEE
Trans. Comput. C–34(1), 81–85 (1985)

A Correction and Improvements of Some Recent
Results on Walsh Transforms of Gold Type
and Kasami-Welch Type Functions
Ayhan Co¸sgun1(B) and Ferruh ¨Ozbudak2,3
1 Department of Mathematics, Middle East Technical University,
Dumlupınar Bul., No:1, 06800 Ankara, Turkey
cosgun@metu.edu.tr
2 Department of Mathematics and Institute of Applied Mathematics,
Middle East Technical University, Dumlupınar Bul.,
No:1, 06800 Ankara, Turkey
ozbudak@metu.edu.tr
3 Department of Mathematical Sciences, Aalborg University,
Aalborg, Denmark
Abstract. We give explicit evaluations of Walsh transforms of Gold
type functions f(x)
=
TrK

x2a+1 + x2b+1
, 0
≤
a
<
b when
gcd (b −a, k) = gcd (b + a, k) and Kasami-Welch type functions f(x) =
TrK

x
2ta+1
2a+1

, when t is odd, gcd

2k −1, 2a + 1

= 1, k is even. There-
fore we correct a recent result of Roy’2012, we solve an open prob-
lem stated in Roy’2012 and we improve and generalize some results of
Roy’2012 and Lahtonen-McGuire-Ward’2007.
Keywords: Finite ﬁelds · Gold type functions · Kasami-Welch type
functions · Walsh transform
1
Introduction
Let K = F2k denote the ﬁnite ﬁeld of 2k elements. We will denote the absolute
trace map from a ﬁnite ﬁeld F to F2 with TrF .
Let f be a Boolean function f : Vk −→F2, where Vk is a k-dimensional vector
space over F2. The Walsh transform of f at α is the function f W : Vk −→Z
deﬁned by
f W (α) =

x∈Vk
(−1)f(x)+⟨α,x⟩
(1)
where ⟨α, x⟩denotes an (non-degenerate) inner product on Vk. When Vk = K,
a natural choice for ⟨α, x⟩is TrK(αx). We refer, for example, to [1] for more
details on Walsh transform for Boolean functions. Then Eq. (1) becomes
f W (α) =

x∈K
(−1)f(x)+TrK(αx).
(2)
c
⃝Springer International Publishing AG 2016
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 243–257, 2016.
DOI: 10.1007/978-3-319-55227-9 17

244
A. Co¸sgun and F. ¨Ozbudak
The Walsh spectrum of a Boolean function f : K −→F2 is deﬁned to be the
set

f W (α) : α ∈K

.
When the spectrum is precisely

±2
k
2

, f is called bent function. For an integer
0 ≤r ≤k, a function f : K −→F2 is called r-plateaued (r-partially bent) if its
Walsh spectrum is

0, ±2
1
2 (k+r)
. Bent functions have signiﬁcance due to their
applications in cryptography and r-plateaued functions gain interest as they can
be used to construct bent functions (see [8,11] for instance).
Among the most famous examples of functions having 3-valued Walsh spec-
trum, we have Gold functions [4] f(x) = TrK

x2a+1
, with a is relatively prime
to k and k is odd. Gold [4] determined f W (α) in terms of f W (1) and f W (1) is
evaluated ﬁrst in [2] and then in [8]. Furthermore, more general Gold functions
are studied in the appendix of [2].
The other famous examples are Kasami-Welch functions [7] (see also [3])
f(x) = TrK

x4a−2a+1
. With the same hypothesis that a is relatively prime
to k and k is odd, both Gold and Kasami-Welch functions have the spectrum

0, ±2
(k+1)
2

(i.e. they are 1-plateaued with the given hypothesis).
In this paper we deal with the Walsh transforms of Gold type and Kasami-
Welch type functions. By a Gold type function we mean
f(x) = TrK
	
x2a+1 + x2b+1
, 0 ≤a < b,
and by a Kasami-Welch type function we mean
f(x) = TrK

x
2ta+1
2a+1

, t odd.
Gold type functions were studied by various authors in literature. For
instance, in [8], Lahtonen, McGuire and Ward give f W (0) for f(x)
=
TrK
	
x2a+1 + x2b+1
, where 0 ≤a < b, gcd (b −a, k) = gcd (b + a, k) = 1 and k
odd. Then, using the results of Fitzgerald in [6], Roy [11] evaluated f W (α)
– for any α ∈K with k odd,
– for α ∈K with TrK(α) = 0 and k even,
and stated that the case
– TrK(α) = 1 with k even
is open. However, we observed that Roy’s result for the case
– α ∈K with TrK(α) = 0 and k even
does not hold for some α’s. We give a counterexample for such an α in Example 1
below in Sect. 3. In Corollary 1 in Sect. 3, we will complete the evaluation of

Walsh Transforms of Gold Type and Kasami-Welch Type Functions
245
f W (α) by ﬁxing the problem in the result of Roy and giving f W (α) for the
remaining open case TrK(α) = 1 with k even.
Furthermore, in our main result Theorem 1, we consider a more general func-
tion f(x) = TrK
	
x2a+1 + x2b+1
, 0 ≤a < b with the assumption gcd (b −a, k)
= gcd (b + a, k). For any positive integer n, let v2(n) denote the highest non-
negative exponent v such that 2v divides n. Two cases occur for the evaluation
of f W (α):
– when “v2(b −a) = v2(b + a) = v2(k) −1” does not hold,
we completed the evaluation.
– When v2(b −a) = v2(b + a) = v2(k) −1
we computed f W (α) up to its sign, and determined its sign exactly under some
extra assumptions (see Theorem 2).
By means of Theorem 1, we will determine the Walsh spectrum of f(x) =
TrK
	
x2a+1 + x2b+1
, 0 ≤a < b and gcd (b −a, k) = gcd (b + a, k) in Corollary 2
in Sect. 3. We observe that the Walsh spectrum is more complicated than the
special case obtained in [11] (see the paragraph before [11, Theorem 7]).
Kasami-Welch type functions, f(x) = TrK (xe) where e = 2ta+1
2a+1 and t is odd,
were studied by Niho in his thesis [10]. In [8], Lahtonen, McGuire and Ward
evaluated f W (1) under certain conditions and then Roy in [11] generalized their
result up to k odd. We also give generalization of Roy’s result for k even with
Theorem 3 in Sect. 3 below.
The rest of the paper is organized as follows. We give some background in
Sect. 2. We present our results in Sect. 3.
2
Preliminaries
In this section we introduce our notation and present some facts about quadratic
forms and linearized polynomials that we use when proving our main results in
Sect. 3.
Let n be an arbitrary positive integer. Throughout the paper v2(n) will denote
the highest non-negative exponent v such that 2v divides n (that is, the 2-adic
valuation) and
 a
n

will denote the Jacobi symbol of a modulo n. For ﬁnite ﬁelds
F and E, we will write TrE/F for the relative trace from E to F. We also intro-
duce the notation χE(x) for (−1)TrE(x) for any ﬁnite ﬁeld E of characteristic 2.
Let
R(x) =
h

i=0
aix2i + α,
where ai, α ∈K. Let Q : K −→F2 be the quadratic form given by
Q(x) = TrK (xR(x)) .

246
A. Co¸sgun and F. ¨Ozbudak
Then we have

x∈K
(−1)Q(x) = Λ (Q) 2
1
2 (k+r(Q)).
(3)
Here r (Q) = dim rad (Q) is the dimension of the radical. By rad (Q) we mean
the radical of the corresponding bilinear form
BQ(x, y) = Q(x + y) + Q(x) + Q(y)
for x, y ∈K.
More precisely,
rad (Q) = {y ∈K|BQ(x, y) = 0 for all x ∈K} .
Moreover, it is well-known that the invariant Λ (Q) of the quadratic form Q
takes values in the set {−1, 0, +1}. We refer to [9] for further details.
Combining deﬁnition (2) and Eq. (3) above, we have that if f(x)
=
TrK
	
x
	h
i=0 aix2i

, then
f W (α) = Λ (Q) 2
1
2 (k+r(Q))
(4)
where R(x) =
h

i=0
aix2i +α. Therefore, in order to evaluate f W (α) it is enough to
determine Λ (Q) and r (Q). Furthermore, quadratic functions are r (Q)-plateaued
by Eq. (4).
The following is an another well-known fact and employed in many papers:
rad (Q) = log2

deg
	
gcd
	
R∗(x), x2k + x



where
R∗(x) =
h

i=0
ai
	
x2h+i + x2h−i
is the radical polynomial of R(x).
It is easy to observe that rad (Q) is independent of the aﬃne part of Q, and
this yields:
Lemma 1. Deﬁne Qα(x) = TrK (xRα(x)) and Qβ(x) = TrK (xRβ(x)) where
Rα(x) =
h

i=0
aix2i + α ∈K[x] and Rβ(x) =
h

i=0
aix2i + β ∈K[x]. Then
r (Qα) = r (Qβ) .
Lemma 1 shows that the relation between f W (0) and f W (α) depends only
on the relation between the invariants Λ (Q0) and Λ (Qα).

Walsh Transforms of Gold Type and Kasami-Welch Type Functions
247
A polynomial of the form
L(x) =
h

i=0
aixqi ∈Fqm[x]
is called a linearized polynomial over Fqm. Its q-associate is deﬁned as l(t) =
h

i=0
aiti ∈Fqm[t] and L(x) is called the inverse q-associate of l(t).
Let A(x), B(x) ∈Fqm[x] be linearized polynomials and a(t), b(t) ∈Fqm[t] be
their q-associates. Then we deﬁne the right division “|r” in Fqm[x] by
A(x)|rB(x)
if and only if
B(x) = C(x) ◦A(x)
for some linearized polynomial C(x) ∈Fqm[x]
When, m = 1, in particular, it is a well-known fact that
– q-associate of A(x) ◦B(x) is a(t)b(t) and
– A(x)|rB(x)
if and only if
A(x) divides B(x) in ordinary sense.
We will use the following well-known fact about linearized polynomials in
the proof of Lemma 3 below in Sect. 3. We provide a proof for completeness (see
also [9]).
Proposition 1. Suppose L1(x), L2(x) ∈Fq[x] are two linearized polynomials
over Fq, and their q-associates are l1(t), l2(t) ∈Fq[t] respectively. Then
gcd (L1(x), L2(x)) = the inverse q-associate of gcd (l1(t), l2(t))
where gcd (L1(x), L2(x)) is the greatest common divisor of two polynomials L1(x)
and L2(x) for Euclidean division.
Proof. Let gcd (L1(x), L2(x)) = A(x), gcd (l1(t), l2(t)) = b(t) and B(x) be the
inverse q-associate of b(t). Then we will show that A(x) = B(x).
– B(x) divides A(x):
Let l1(t) = c1(t)b(t) and l2(t) = c2(t)b(t) for some c1(t) and c2(t) in Fq[t]. Then
their inverse q-associates are L1(x) = C1(x) ◦B(x) and L2(x) = C2(x) ◦B(x)
where C1(x), C2(x) are inverse q-associates of c1(t) and c2(t), respectively. So
B(x)| gcd (L1(x), L2(x)) = A(x).
– A(x) divides B(x):
As gcd (L1(x), L2(x)) = A(x), we have L1(x) = D1(x) ◦A(x) and L2(x) =
D2(x) ◦A(x) for some linearized polynomials D1(x), D2(x) ∈Fq[x]. Then their
q-associates are l1(t) = d1(t)a(t) and l2(t) = d2(t)a(t) where d1(t), d2(t) are
q-associates of D1(x) and D2(x), respectively. So a(t)| gcd (l1(t), l2(t)) = b(t).
That is, A(x)|B(x).
⊓⊔

248
A. Co¸sgun and F. ¨Ozbudak
3
Main Results
In this section, we will give a counterexample to the result in [11] and then
present our main result in Theorem 1. Moreover, Theorem 2 and Corollary 1
solves an open problem of [11] and Theorem 3 generalizes a result of [11].
In the example below, we will see that the result in [11, Theorem 11] does
not hold for some α ∈K.
Example 1. Let k = 2, so K = F4. Also let f(x) = TrK
	
x20+1 + x21+1
. So,
a = 0, b = 1 and gcd (b −a, k) = gcd (b + a, k) = 1. Then, by [6, Theorem 2.1]
we have f W (0) = 0. Therefore, we would have f W (α) = 0 for all α ∈K with
TrK(α) = 0 according to [11, Theorem 11].
Now, let γ ∈K = F4 be the element such that γ2 = γ+1 (Note that x2+x+1
is irreducible over F2). Then F4 = {0, 1, γ, γ + 1}.
For α = 1 (so TrK(1) = 1 + 12 = 0) we have
f W (1) =

x∈K
(−1)TrK(x2+x3+x)
= (−1)TrK(02+03+0) + (−1)TrK(12+13+1)
+ (−1)TrK(γ2+γ3+γ) + (−1)TrK((γ+1)2+(γ+1)3+(γ+1))
= (−1)TrK(0) + (−1)TrK(1) + (−1)TrK(0) + (−1)TrK(0) = 4
and so f W (1) ̸= 0.
The problem in the proof of [11, Theorem 11] is about the image Im(L) of L
where L(x) = x2a + x2−a + x2b + x2−b. In [11, Theorem 7] it is shown that when
gcd (b −a, k) = gcd (b + a, k) = 1 and k is odd, we have Im(L) = K0 where K0
is the set of elements of K with absolute trace 0. The equality “Im(L) = K0”
is assumed also in the proof of [11, Theorem 11], when k is even. However, the
equality is not true for even k.
For any integer n dividing k, deﬁne the set
Sn =

x ∈K : TrK/F2n(x) = 0

from now on. In fact, we will see below in Lemma 3 that
Im(L) =
Sd,
if k/d is odd,
S2d, if k/d is even.
Therefore, [11, Theorem 11] (where d = 1 and k is even) does not necessarily
hold for an α ∈K such that TrK/F22(α) = 1 as in the Example 1, although we
have still TrK(α) = 0.
Before proving Lemma 3 we will present the following observation which will
play a central role in its proof.
Lemma 2. Assume gcd (b −a, k) = gcd (b + a, k). Put d = gcd (b −a, k) (= gcd
(b + a, k)) and let δ = gcd(2d, k). Then we have δ ∈{d, 2d} and

Walsh Transforms of Gold Type and Kasami-Welch Type Functions
249
(i) δ = d ⇐⇒k/d is odd ⇐⇒δ|(b −a) and δ|(b + a),
(ii) δ = 2d ⇐⇒k/d is even ⇐⇒δ ̸ |(b −a), δ ̸ |(b + a) and δ|2a, δ|2b.
Proof. We have δ = gcd(2d, k) =
d,
if k/d is odd,
2d, if k/d is even.
If δ = d, then δ|(b −a) and δ|(b + a) by assumption. So (i) is proved.
Assume δ = 2d. So k/d is even and v2(k) > v2(d). Then we get v2(b −a) =
v2(b + a) = v2(d). Hence, δ ̸ |(b −a) and δ ̸ |(b + a).
Furthermore, v2(2b) > v2(d) and v2(2a) > v2(d) and this yields v2(2b) −
v2(d) = v2 (2b/d) ≥1 and v2(2a) −v2(d) = v2 (2a/d) ≥1. Then, both 2b/d and
2a/d are even (note that d divides both 2b and 2a). That is, δ = 2d divides both
2b and 2a.
⊓⊔
Now we are ready for the next lemma.
Lemma 3. Let L : K −→K where L(x) = x2a + x2−a + x2b + x2−b. Under the
notation of Lemma 2 we have
Im(L) = Sδ.
Proof. Clearly L : K −→K is linear. We claim:
(1) Im(L) ⊆Sδ.
(2) Ker(L) = F2δ.
Proof of (1): We will show that TrK/F2δ (L(x)) = 0 for all x ∈K.
TrK/F2δ (L(x)) = TrK/F2δ
	
x2a + x2−a + x2b + x2−b
= TrK/F2δ
	
x2a + x2k−a + x2b + x2k−b
.
Case (i): If δ = d, δ|(b −a) by Lemma 2. Then

x2a(2δ)
k+b−a
δ
= x2a+k+b−a = x2k+b = x2b
and

x2k−a(2δ)
k−(b−a)
δ
= x2k−b
similarly. That is, TrK/F2δ

x2a
= TrK/F2δ
	
x2b
and TrK/F2δ
	
x2k−a
=
TrK/F2δ
	
x2k−b
.
Case (ii): If δ = 2d, δ|2b and δ|2a by Lemma 2. Then

x2a(2δ)
k−2a
δ
= x2k−a and

x2b(2δ)
k−2b
δ
= x2k−b.

250
A. Co¸sgun and F. ¨Ozbudak
Thus, TrK/F2δ

x2a
= TrK/F2δ
	
x2k−a
and TrK/F2δ
	
x2b
= TrK/F2δ
	
x2k−b
.
Therefore, in both cases we get TrK/F2δ (L(x)) = 0 for all x ∈K.
Proof of (2):
L(x) = x2a + x2−a + x2b + x2−b = 0 if and only if x2a+b + x2b−a + x22b + x = 0.
It will be suﬃcient to show that
gcd
	
x2a+b + x2b−a + x22b + x, x2k + x

= x2δ + x.
The linearized polynomial x2a+b + x2b−a + x22b + x ∈F2[x] has the 2-associate
xa+b + xb−a + x2b + 1 which has the following factorization
xa+b + xb−a + x2b + 1 =

xa+b + 1
 
xb−a + 1

.
Since gcd (b −a, k) = gcd (b + a, k) = d, we have
gcd

xa+b + 1, xk + 1

= xd + 1 and gcd

xb−a + 1, xk + 1

= xd + 1.
Then
gcd

xa+b + xb−a + x2b + 1, xk + 1

=
xd + 1,
if k/d is odd,
x2d + 1, if k/d is even
= xδ + 1
and the result follows by Proposition 1.
Hence, K/Ker(L) ∼= Im(L) implies |Im(L)| = 2k−δ and then Im(L) = Sδ as
|Sδ| = 2k−δ.
⊓⊔
Now we present the main result of the paper. The evaluation of f W (0) is
already completed in [6]. We ﬁnd f W (α) in terms of f W (0) in some cases of our
main result, and we give f W (0) in absolute value only.
Theorem 1. Assume that gcd (b −a, k) = gcd (b + a, k) with 0 ≤a < b and put
d = gcd (b −a, k) (= gcd (b + a, k)). Let K = F2k, E = F2δ where δ = gcd(2d, k),
and f(x) = TrK
	
x2a+1 + x2b+1
.
Case 1: “v2(b −a) = v2(b + a) = v2(k) −1” does not hold:
If TrK/E (α) = 0, then we choose β ∈K such that β2a+β2−a+β2b+β2−b = α
(see Lemma 3 for existence of such β). Then,
f W (α) =
⎧
⎪
⎨
⎪
⎩
(−1)
TrK

β2a+1+β2b+1+αβ

f W (0), if TrK/E(α) = 0,
0,
otherwise,
where |f W (0)| = 2
1
2 (k+δ).

Walsh Transforms of Gold Type and Kasami-Welch Type Functions
251
Case 2: If v2(b −a) = v2(b + a) = v2(k) −1:
In this case [K : E] is odd. Put τ = TrK/E (α). Then TrK/E (α + τ) = 0 and
hence we choose β ∈K such that β2a + β2−a + β2b + β2−b = α + τ (see Lemma 3
for existence of such β). Then,
f W (α) = (−1)
TrK

β2a+1+β2b+1+αβ

f W (τ).
Furthermore,
f W (τ) = Λ (g) 2
1
2 (k+2d)
where g is the quadratic form g(x) = TrE
	
x2a+1 + x2b+1 + xτ

and Λ (g)
denotes its invariant.
Remark 1. To avoid a very long and complicated statement in Theorem 1, we
will continue the evaluation of Λ (g) separately in Theorem 2.
Proof. Firstly,
f W (0) =

x∈K
(−1)f(x) = Λ (f) 2
1
2 (k+r)
where
r = deg

gcd

xa+b + xb−a + x2b + 1, xk + 1

= deg

xδ + 1

= δ
by Proposition 1 and proof of Lemma 3. As the dimension of the radical does not
depend on α, we have f W (α) = 0 or |f W (α)| = 2
1
2 (k+δ). So it is left to determine
the sign of f W (α).
By [6, Theorem 2.1],
invariant of f = Λ (f) = 0
if and only if
v2(b −a) = v2(b + a) = v2(k) −1
Thus,
f W (0) = 0
if and only if
v2(b −a) = v2(b + a) = v2(k) −1
where χK(x) = (−1)f(x).
Case 1: When “v2(b −a) = v2(b + a) = v2(k) −1” does not hold.
In this case we are sure that f W (0) ̸= 0. Then, by [5, Proposition 3.2],
f W (α) =
⎧
⎨
⎩
(−1)f(x0)f W (0), if R∗(x) = α2b has a solution x0 ∈K,
0,
otherwise,
where R∗(x)=x2b+a+x2b−a+x22b+x is the radical polynomial of R(x) = x2a+x2b.

252
A. Co¸sgun and F. ¨Ozbudak
We have
R∗(x) = α2b for some x0 ∈K if and only if L (x0) = α for the same x0 ∈K
if and only if TrK/E(α) = τ = 0
by Lemma 3.
When τ = 0, let β ∈K be such that α = β2a + β2−a + β2b + β2−b
and observe that TrK (αβ) = TrK
	
β2a+1 + β2−a+1 + β2b+1 + β2−b+1
= 0 as
	
β2−t+1
2t
= β2t+1 for all integers t. Hence, f(β) = TrK
	
β2a+1 + β2b+1
=
TrK
	
β2a+1 + β2b+1 + αβ

and
f W (α) =
⎧
⎪
⎨
⎪
⎩
(−1)
TrK

β2a+1+β2b+1+αβ

f W (0), if τ = 0,
0,
otherwise.
Case 2: v2(b −a) = v2(b + a) = v2(k) −1.
This is the case when v2 (k/d) = 1. So we have δ = 2d.
We will use a similar idea as Roy used in [11]. For any element β of K, we
have
f W (α) = χK
	
β2a+1 + β2b+1 + αβ

 
x∈K
χK
	
x2a+1 + x2b+1 + x (L(β) + α)

where L(β) = β2a + β2−a + β2b + β2−b.
Now, let τ = TrK/E(α) ∈E. Then we have
TrK/E (α + τ) = TrK/E(α) + τTrK/E(1).
The extension degree k/δ is odd in this case, and then TrK/E(1) = 1. So,
TrK/E (α + τ) = τ + τ = 0
Then, by Lemma 3 there exists β ∈K such that L(β) = α + τ. That is,
L(β) + α = τ.
Therefore,
f W (α) = χK
	
β2a+1 + β2b+1 + αβ

 
x∈K
χK
	
x2a+1 + x2b+1 + xτ

= (−1)
TrK

β2a+1+β2b+1+αβ

f W (τ)
where β ∈K such that α + τ = β2a + β2−a + β2b + β2−b.
Let Λ (hτ) denote the invariant of the quadratic form
hτ(x) = TrK
	
x2a+1 + x2b+1 + xτ

.

Walsh Transforms of Gold Type and Kasami-Welch Type Functions
253
So,
f W (τ) = Λ (hτ) 2
1
2 (k+2d).
It is left to show Λ (hτ) = Λ (g). The equality can be observed by a result
in [5].
Apply [5, Theorem 4.2] with n = 2d and k = 2dp1p2...ps (Note that v2(k) =
v2(2d)). Then, by means of [6, Theorem 1.5] we have
r

QFi
τ

= r
	
QFi
0

= r
	
QFi−1
0

= r

QFi−1
τ

= 2d
for all 1 ≤i ≤s where QFi
τ (x) = TrFi
	
x2a+1 + x2b+1 + xτ

and Fi =
F2(p1p2...pin). This yields
2
1
2

r

Q
Fi
τ

−r

Q
Fi−1
τ

= 2
1
2 (0) = 20 = 1 ≡(−1)0(
mod pi)
for all 1 ≤i ≤s. Also we have

2
p1...ps
n
= 1
as n = 2d is even. Hence,
Λ (hτ) = (−1)0

2
p1...ps
n
Λ (g) = Λ (g) .
This completes the proof of Theorem 1.
⊓⊔
For the case v2(b −a) = v2(b + a) = v2(k) −1, the evaluation of f W (α)
depends on the evaluation of Λ (g) according to Theorem 1.
Next we evaluate Λ (g) when v2(b −a) = v2(b + a) = v2(k) −1, τ ∈F22 and
d is odd.
Theorem 2. Under the notation of Theorem 1, assume v2(b −a) = v2(b + a) =
v2(k) −1, τ ∈F22 and d is odd. Then
Λ (g) =

+1, if τ = 1,
0,
otherwise.
Proof. By the assumptions we have 0 = v2(d) = v2(b−a) = v2(b+a) = v2(k)−1
and δ = 2d. Also observe that v2(2d) = 1 = v2(2). Applying [6, Theorem 1.5]
and [5, Theorem 4.2] together, as in the proof of Theorem 1, we get
Λ (g) = Λ (hτ)
where Λ (hτ) denotes the invariant of the quadratic form
hτ(x) = TrF4
	
x2a+1 + x2b+1 + xτ

.

254
A. Co¸sgun and F. ¨Ozbudak
Now, we will focus on Λ (hτ). By Eq. (3),
Λ (hτ) 2
1
2 (2+r(hτ )) =

x∈F4
(−1)hτ (x).
As F4 = {0, 1, γ, γ + 1} where γ2 = γ + 1, we are left to deal with 4 cases
for τ.
(1) τ = 0:
As v2(b −a) = v2(b + a) = v2(2) −1, we have Λ (hτ) = Λ (h0) = 0 by [6,
Theorem 2.1].
(2) τ = 1:
– hτ(0) = TrF4 (0) = 0,
– hτ(1) = TrF4 (1) = 0,
– hτ(γ) = TrF4
	
γ2a+1 + γ2b+1 + γ

= TrF4
	
γ2a+1 + γ2b+1
+ 1,
– and
hτ(γ + 1) = TrF4
	
(γ + 1)2a+1 + (γ + 1)2b+1 + (γ + 1)

= TrF4
	
γ2a+1 + γ2b+1 + γ2a + γ2b + (γ + 1)

= TrF4
	
γ2a+1 + γ2b+1
+ TrF4 (γ) + TrF4 (γ) + TrF4 (γ + 1)
= TrF4
	
γ2a+1 + γ2b+1
+ 1.
Thus,

x∈F4
(−1)hτ (x) = 2 −2(−1)
TrF4

γ2a+1+γ2b+1
.
As γ2 = γ + 1, we have
γt =
⎧
⎨
⎩
1
if t ≡0
mod 3,
γ
if t ≡1
mod 3,
γ + 1
if t ≡2
mod 3.
Thus,
TrF4
	
γ2t+1
=
0
if t is odd,
1
if t is even.
In our case, we have v2(b + a) = v2(d) = 0 and so b + a is odd. Then, one of
a and b is odd and the other one is even. That is,
TrF4
	
γ2a+1 + γ2b+1
= 1
(5)
for all such a and b. Finally we deduce that

x∈F4
(−1)hτ (x) = 4 and Λ (hτ) = +1
for τ = 1.

Walsh Transforms of Gold Type and Kasami-Welch Type Functions
255
(3) τ = γ:
– hτ(0) = TrF4 (0) = 0,
– hτ(1) = TrF4 (γ) = 1,
– hτ(γ) = TrF4
	
γ2a+1 + γ2b+1 + (γ + 1)

= 1 + 1 = 0,
– and
hτ(γ + 1) = TrF4
	
(γ + 1)2a+1 + (γ + 1)2b+1 + (γ + 1)γ

= TrF4
	
γ2a+1 + γ2b+1 + γ2a + γ2b + 1

= 1,
using Eq. (5). Then,

x∈F4
(−1)hτ (x) = 0 and Λ (hτ) = 0 for τ = γ.
(4) τ = γ + 1:
– hτ(0) = TrF4 (0) = 0,
– hτ(1) = TrF4 (γ + 1) = 1,
– hτ(γ) = TrF4
	
γ2a+1 + γ2b+1 + γ(γ + 1)

= 1 + 0 = 1,
– and
hτ(γ + 1) = TrF4
	
(γ + 1)2a+1 + (γ + 1)2b+1 + (γ + 1)2
= TrF4
	
γ2a+1 + γ2b+1 + γ2a + γ2b + γ

= 0,
using Eq. (5). Then,

x∈F4
(−1)hτ (x) = 0 and Λ (hτ) = 0 for τ = γ + 1.
⊓⊔
As a consequence, we can complete the evaluation of f W (α) where f is as
given in [11, Theorem 11]. The following corollary completely solves the open
problem stated in [11] (see pages 901–903 of [11]), in particular in the paragraph
before [11, Theorem 9] and in the Remark in page 903.
Corollary 1. Under the notation of Theorem 1, with k even and d = 1, we have
Case 1: v2(k) > 1
f W (α) =
⎧
⎪
⎨
⎪
⎩
(−1)
TrK

β2a+1+β2b+1+αβ

f W (0), if τ = 0,
0,
otherwise,
where |f W (0)| = 2
1
2 (k+2).
Case 2: v2(k) = 1
f W (α) =
⎧
⎪
⎨
⎪
⎩
(−1)
TrK

β2a+1+β2b+1+αβ

2
1
2 (k+2), if τ = 1,
0,
otherwise.

256
A. Co¸sgun and F. ¨Ozbudak
Furthermore, we are able to determine the Walsh spectrum of f which satis-
ﬁes the assumptions of Theorem 1.
Corollary 2. Under the notation of Theorem 1 for f, the Walsh spectrum of f
is precisely
⎧
⎪
⎪
⎨
⎪
⎪
⎩

0, ±2
1
2 (k+d)
,
if k/d is odd,

0, ±2
1
2 (k+2d)
, if k/d is even.
Proof. This corollary follows easily from Theorem 1.
⊓⊔
We note that in Corollary 2, the Walsh spectrum of f has two diﬀerent forms
depending on the parity of k/d.
The following is a related but a diﬀerent result. It gives a generalization of
one of the main results of [11] (see [11, Theorem 7]) for k even.
Theorem 3. Let K = F2k, k even, a be such that gcd

2k −1, 2a + 1

= 1. Let
t be odd and e = 2ta+1
2a+1 with a is a positive integer. If f(x) = TrK (xe) on the
ﬁeld K, then
f W (1) = 2
1
2 (k+r(k))
where r(k) = gcd ((t −1)a, k) + gcd ((t + 1)a, k) −gcd (2a, k).
Proof. Since gcd

2k −1, 2a + 1

= 1, we have
f W (1) =

x∈K
χK

x
2ta+1
2a+1 + x

=

x∈K
χK
	
x2ta+1 + x2a+1
= Λ (Q) 2
1
2 (k+r(Q))
where Q(x) = TrK
	
x2ta+1 + x2a+1
. Denote r (Q) by r(k). Then
gcd

2k −1, 21 + 1

= 1
if and only if
v2(k) ≤v2(a)
(see [5, Lemma 5.3]). So
v2(k) ≤v2(a) ≤v2(ta + a)
and
v2(k) ≤v2(a) ≤v2(ta −a)
as t is odd. Then, by [6, Theorem 1.5] we have
r(k) = gcd (ta −a, k) + gcd (ta + a, k) −gcd (s, k)
where s = gcd (ta + a, ta −a) = 2a.
Now, it is left to determine Λ(Q). Combining [6, Theorem 3.7] and [6, The-
orem 4.9] we obtain Λ(Q) = 1.
⊓⊔
Acknowledgements. We would like to thank the anonymous reviewers for their
insightful and helpful comments that improved the presentation of this paper.

Walsh Transforms of Gold Type and Kasami-Welch Type Functions
257
References
1. Carlet, C.: Boolean functions for cryptography and error correcting codes (chap.
8). In: Crama, Y., Hammer, P.L. (eds.) Boolean Models and Methods in Math-
ematics, Computer Science, and Engineering. Encyclopedia of Mathematics and
Its Applications, vol. 134, pp. 257–397. Cambridge University Press, Cambridge
(2010)
2. Dillon, J.F., Dobbertin, H.: New cyclic diﬀerence sets with Singer parameters.
Finite Fields Appl. 10, 342–389 (2004)
3. Dobbertin, H.: Another proof of Kasami’s theorem. Des. Codes Cryptogr. 17, 177–
180 (1999)
4. Gold, R.: Maximal recursive sequences with 3-valued recursive cross-correlation
functions. IEEE Trans. Inform. Theory 14, 154–156 (1968)
5. Hou, X.D.: Explicit evaluation of certain exponential sums of binary quadratic
functions. Finite Fields Appl. 13, 843–868 (2007)
6. Fitzgerald, R.: Invariants of trace forms over ﬁnite ﬁelds of characteristic two.
Finite Fields Appl. 15, 261–275 (2009)
7. Kasami, T.: The weight enumerators for several classes of subcodes of the second
order binary Reed-Muller codes. Inf. Control 18, 369–394 (1971)
8. Lahtonen, J., McGuire, G., Ward, H.N.: Gold and Kasami-Welch functions,
quadratic forms, and bent functions. Adv. Math. Commun. 1(2), 243–250 (2007)
9. Lidl, R., Niederreiter, H.: Finite Fields. Encyclopedia of Mathematics and its Appli-
cations, vol. 20, 2nd edn. Cambridge University Press, Cambridge (1997)
10. Niho, Y.: Multi-valued cross-correlation functions between two maximal linear
recursive sequences. Ph.D. thesis, University of Southern California, Los Angeles
(1972)
11. Roy, S.: Generalization of some results on Gold and Kasami-Welch functions. Finite
Fields Appl. 18, 894–903 (2012)

A Practical Group Signature Scheme
Based on Rank Metric
Quentin Alam´elou1,2(B), Olivier Blazy1, St´ephane Cauchie2,
and Philippe Gaborit1
1 Universit´e de Limoges, XLIM-DMI, Limoges, France
{quentin.alamelou,olivier.blazy,philippe.gaborit}@xlim.fr
2 R&D Department, Worldline, Seclin, France
{quentin.alamelou,stephane.cauchie}@worldline.com
Abstract. In this work, we propose the ﬁrst rank-based group signa-
ture. Our construction enjoys two major advantages compared to con-
current post-quantum schemes since it is both practicably instantiated
with public key and signature sizes logarithmic in the number of group
members, and dynamic in a relaxation of the reference BSZ model. For
such a result, we introduce a new rank-based tool, referred as the Rank
Concatenated Stern’s protocol, enabling to link diﬀerent users to a com-
mon syndrome. This protocol, which could be of independent interest,
can be seen as a Stern-like protocol with an additional property that
permits a veriﬁer to check the weight of each part of a split secret. Along
with this work, we also deﬁne two rank-based adaptations of Hamming-
based problems, referred as the One More Rank Syndrome Decoding and
the Decision Rank Syndrome Decoding problems for which we discuss
the security. Embedded into Fiat-Shamir paradigm, our authentication
protocol leads to a group signature scheme secure in the Random Oracle
Model assuming the security of rank-based systems (namely RankSign
and LRPC codes) and the newly introduced problems. For a 100 bits
security level, we give an example of parameters which lead to a signa-
ture size of 550 kB and 5 kB for the public key.
Keywords: Group signature · Post-quantum cryptography · Rank
metric · Zero-knowledge
1
Introduction
A group signature scheme allows members of a group to anonymously issue
signatures on behalf of the group while an opener may revoke anonymity. It
turned out to be very useful in real-life applications such as, for instance, e-voting
or company access policy. While current practical group signatures schemes are
still based on number theory, it is worth looking for constructions facing the
quantum computer.
Related Work. Since its introduction in [1], group signature has been exten-
sively studied and two main formalization works [2,3] have been proposed (BMW
and BSZ models). In the latter case, Bellare et al. consider the case where new
c
⃝Springer International Publishing AG 2016
S. Duquesne and S. Petkova-Nikova (Eds.): WAIFI 2016, LNCS 10064, pp. 258–275, 2016.
DOI: 10.1007/978-3-319-55227-9 18

A Practical Group Signature Scheme Based on Rank Metric
259
users can be added during the lifetime of the group. Numerous eﬃcient pairing-
based group signatures have tended to ﬁt or extend these aforesaid models among
which the following non-exhaustive works [4–9]. To address the quantum threat,
Gordon et al. designed the ﬁrst lattice-based group signature scheme [10] and
in spite of recent progress in this area [11–16] or even in code-based cryptog-
raphy [17,18], post quantum schemes still suﬀer parameters ineﬃciency and/or
lack of properties compared to number-theoretic based constructions previously
mentioned. In parallel to this strong attention for group signature and its sub-
sequent improvements, the ﬁeld of rank-based cryptography has also gained a
lot of interest due to, notably, the recent design of eﬃcient and post quantum
cryptosystems [19,20] with strong security reductions [21].
Our Contributions. Our rank-based construction constitutes the ﬁrst post
quantum group signature scheme to both enable enrollment of new users and
enjoy practical parameters. Indeed, our scheme beneﬁts from public keys sizes
logarithmic in the number of group members, leading to an instantiation with
signatures and public key, respectively of sizes 550 kB and 5 kB for a 100 bits
security level. For such a purpose, we propose a novel approach while designing
a (rank-based) Stern-like authentication protocol, referred as the Rank Concate-
nated Stern’s Protocol. The key idea is to enable a veriﬁer to check the weights
of both parts of a split secret. This protocol is then turned into a group signa-
ture via Fiat-Shamir (FS) paradigm [22] to constitute a new tool in the growth
of rank-based cryptography. We describe a generic scheme that we instantiate
with the LRPC cryptosystem and RankSign scheme so that the practical secu-
rity of our scheme relies on these aforesaid schemes and the two rank-based
problems introduced along with this work, referred as the One More Rank Syn-
drome Decoding (OMSD) and the Decision Rank Syndrome Decoding (D-RSD)
problems.
Road Map. In the following, Sects. 2 and 3 are respectively concerned with
preliminaries, notably about rank based cryptography, and our group signature
model. Section 4 introduces our new ZK authentication protocol while Sect. 5
describes the ensuing group signature scheme. Finally, Sect. 6 provides a security
analysis and Sect. 7 gives parameters for instantiating our scheme.
2
Preliminaries
We ﬁrst deﬁne notation and then give some basic background.
2.1
Notation
All through this work, we use the following notation.
h denote a random oracle. λ denotes a security parameter; Hλ denotes a
random oracle whose output depends on λ. Given a prover-veriﬁer protocol, lλ
denotes the number of rounds to run to achieve security related to λ. Except
stated otherwise, log denotes the binary logarithm. We denote by n the set
{0, . . . , n}. A(z; O) denotes that entity A has knowledge of z and access to
oracle O.

260
Q. Alam´elou et al.
Rank Metric. Let q be a power of a prime p, m an integer and let Vn be
an n dimensional vector space over a ﬁnite ﬁeld GF(qm). Let β denote a basis
(β1, . . . , βm) of GF(qm) over GF(q). Let Fi be the map from GF(qm) to GF(q)
where Fi(x) is the i−th coordinate of x in the basis β. To any v = (v1, . . . , vn) ∈
Vn, we associate v ∈Mm,n(GF(q)) deﬁned by vi,j = Fi(vj). For a basis β, we
denote ψβ the inverse of the application Vn →Mm,n(GF(q)) : x →x computed
with the basis β.
2.2
Background on Rank Metric and Cryptography
Rank Metric Codes. We ﬁrst recall some deﬁnitions.
Deﬁnition 1 (Matrix Code). A linear matrix code C of length m × n over
GF(q) is a subspace of matrices space of size m × n over GF(q). If C is of
dimension K, we say that C is a [m×n, K]q matrix code, or [m×n, K]q if there
is no ambiguity.
The diﬀerence between such a [m × n, K]q matrix code and a code of length
mn and of dimension K is that we can deﬁne a natural metric through the
matrix rank function.
Deﬁnition 2. For any v ∈Vn, the rank weight of v, denoted ωt(v), is deﬁned as
the rank of the associated matrix v. We can now deﬁne the rank metric between
two vectors x and y such as dr(x, y) := ωt(x −y) = rank (x −y). From now,
B(S, ω) := {v ∈S : ωt(v) = ω}.
Deﬁnition 3 (Linear Rank Code). A [n, k]qm rank code C of length n and
dimension k over GF(qm) is a linear subspace of dimension k of GF(qm)n viewed
as a rank metric space. Each word c = (c1, . . . , cn) of C can be associated to a
m × n matrix over GF(q) by representing each coordinate ci by a column vector
with respect to a basis β.
Deﬁned as the rank of its associate matrix x, the weight of a word x does
not depend on the choice of the basis β.
Deﬁnition 4. Let x = (x1, . . . , xn) ∈GF(qm)n be a vector of rank ω. We
denote E the GF(q)-subvector space of GF(qm) generated by x1, x2, . . . , xn. The
vector space E is called the support of x.
Remark 1. The notion of support of a codeword for the Hamming metric and
for the rank metric are diﬀerent but share a common principle: in both cases,
given a syndrome s for which it exists a low weight vector x such that H.xt = s,
then, if the support of x is known, it is possible to recover all the coordinates
values of x by solving a linear system.
Deﬁnition 5. Let e be an error vector of rank r and error support space E.
We denote by generalized erasure of dimension t of an error e, a subspace T of
dimension t of its error support E.
Similarly to the Hamming case where an erasure corresponds to knowing the
position of an error, this rank erasure notion is the knowledge of a subspace T
of the error support E.

A Practical Group Signature Scheme Based on Rank Metric
261
Rank-Based Cryptography. The main interest of rank-based cryptography is
that for hard problems with same size of parameters, the computational complex-
ity is higher than problems based on Hamming metric. It is then possible to gen-
erate instances of problems, with high computational complexity and with small
size of keys (a few thousand bits) when such sizes are only reached with additional
structure (like cyclicity) for Hamming (code-based cryptography) or Euclidean
(lattice-based cryptography) distances. We now recall Syndrome Decoding prob-
lem and Gilbert-Varshamov bound analogues in rank metric. For more details,
we refer the reader to [23,24] and references therein.
Syndrome Decoding Problem (RSD). As in the Hamming case, the problem
consists in ﬁnding a weighted constrained antecedent to a random syndrome by
a dual matrix.
Deﬁnition 6 (Rank Syndrome Decoding). Let H be a (n −k) × n matrix
over GF(qm) (k < n), s ∈GF(qm)n−k and ω an integer. The RSD problem
consists in ﬁnding a vector x ∈GF(qm)n verifying H.xT = s and ωt(x) ≤ω.
The hardness of this problem was proven in [21] while the complexity of the
best known attacks can be found in [25]. The RSD problem can be seen as a rank
adaptation of the well-known Syndrome Decoding (SD) problem which relies on
Hamming metric and was proven to be NP-complete in [26].
Gilbert-Varshamov Bound (GVR). The number of elements S(m, q, ω) of a
sphere of radius ω in GF(qm)n, is equal to the number of m × n q-ary matrices
of rank weight t. For t = 0, S0 = 1 and for ω ≥1, we have (see [23]):
S(n, m, q, ω) =
ω−1

j=0
(qn −qj)(qm −qj)
qt −qj
From this, we then deduce the volume of a ball B(n, m, q, ω) of radius t in
GF(qm) to be:
B(n, m, q, ω) =
ω

i=0
S(n, m, q, i)
In the (frequent) linear case, the rank Gilbert-Varshamov bound GVR(n, k, m, q)
for a linear code [k, n]qm is then deﬁned as the smallest integer ω such as
B(n, m, q, ω) ≥qm(n−k) where B(n, m, q, ω) denotes a ball of radius ω in in
GF(qm).
For a rank code C with dual matrix H, the GVR bound is the smallest rank
weight ω for which, for any syndrome s, there exists on average one word x
solving the RSD instance (H, s, ω).
Rank Stern-like Protocol. Introduced by Goldwasser, Micali and Rackoﬀ[27],
Zero-Knowledge (ZK) protocols fast aroused interest. Stern then ﬁrst proposed
such a scheme based on coding theory [28]. Fixing the attempt of Chen [29],

262
Q. Alam´elou et al.
Gaborit et al. designed a 3-pass prover-veriﬁer protocol constituting a rank alter-
native to Stern’s protocol [30]. To fulﬁll such a goal, they had to deﬁne, in rank
metric, an equivalent notion of permutation used in the Hamming metric setting.
More precisely, they came up with an operation that, without leaking any infor-
mation about its support, can associate any word of rank ω to any particular
word of same rank ω. We now recall this operation.
Deﬁnition 7. Let Q ∈GLm(q), v ∈Vn and a basis β. We deﬁne the product
Q ∗v such that Q ∗v := ψβ(Qv).
For any x, y ∈Vn such that rk(x) = rk(y), it is possible to ﬁnd P ∈GLn(q)
and Q ∈GLm(q) such that x = Q ∗yP.
New Rank-Based Problems. We now introduce two rank-based problems
referred as the One-More Rank Syndrome (OMRSD) Decoding problem and the
Decision Rank Syndrome Decoding (D-RSD) problem. We prove that the D-
RSD problem is a hard problem and we justify the very likely diﬃculty of the
OMRSD problem.
One More Rank Syndrome Decoding Problem. We ﬁrst discuss the situation
where one is given some solutions of a RSD instance and is asked to ﬁnd a new
one.
Deﬁnition 8 (OMRSD Problem). Given an RSD instance sd = (H, s, ω)
and l solutions to sd, denoted x1, . . . , xl, the OMRSD(sd, x1, . . . , xl) problem
consists in ﬁnding xl+1 solution of sd such as : ∀i = 1 . . . l, xi ̸= xl+1.
Assumption 1: the OMRSD problem is hard.
Discussion on assumption 1: There is no known reduction to the RSD prob-
lem for the OMRSD problem. This problem is an adaptation in a coding context
of a similar problem which exists for classical cryptography. At the diﬀerence of
the classical RSD problem where an attacker knows only a syndrome and wants
to ﬁnd a small weight vector, in that case the attacker knows l small weight
vectors of weight ω and search for a new one. It is of course possible to consider
linear combinations of small weight vectors to ﬁnd another small weight vector,
meanwhile because of the properties of the metric, adding two random small
weight vectors of weight ω leads in general to a vector of weight close to 2ω
which is of no use for our problem. In particular in the case of rank metric, if
ω is greater than the rank Gilbert-Varshamov bound (which has to be the case
in general, if more than one preimage of a syndrome does exist), the problem of
ﬁnding a pre-image of weight more than twice the GVR bound is always easy.
Hence this means that using linear combinations of known solutions is not likely
to be of any help. This type of result is not true for instance for Hamming met-
ric or for Euclidean norm, for which in some cases ﬁnding preimage of weight
twice the Gilbert-Varshamov bound can be diﬃcult. Moreover the number of lin-
ear independent such solutions is upper bounded by the dimension of the code.
Overall, although there is no known reduction for this problem, the problem is

A Practical Group Signature Scheme Based on Rank Metric
263
considered diﬃcult by the communauty and no attack exploiting the l known
vectors are known, so that the best attack for the problem consists in directly
attacking the RSD problem.
Decision Rank Syndrome Decoding Problem. We now deﬁne the D-RSD problem
which consists in distinguishing a random syndrome from a syndrome issued from
a small weight vector.
Deﬁnition 9 (D-RSD Problem). Given a random H ∈Mn−k,n(GF(qm)), a
word x ∈B(GF(qm)n, ω > 0) a random syndrome s ∈GF(qm)n−k, is it possible
to distinguish H.xT from s?
Once again, this problem can be seen as a rank adaptation of the Decision
Syndrome Decoding problem deﬁned in Hamming-based cryptography.
Proposition 1. The D-RSD problem is hard.
Proof. Decision problems are very important in cryptography; in the case of
Hamming-based cryptography, the Decision Syndrome Decoding problem has
been proven equivalent to the search problem in Theorem 2 [31], based on the
Goldreich-Levin theorem. The result is presented in term of indistinguishability
of a pseudo-random generator based on the SD problem. Recently a transfor-
mation from a binary code to a q-ary code was proposed in [21] which permits
to obtain a randomized reduction from the SD problem to the RSD problem.
This transformation was used in [32] to adapt the result of Fisher-Stern [31]
for rank metric, but with a reduction to the computational SD problem. These
results hence show that there is a randomized reduction from the binary compu-
tational SD problem to the D-RSD problem, and hence that the D-RSD problem
is hard. In practice the best attacks for this problem are attacks towards the RSD
problem.
2.3
LRPC Codes and Related Cryptosystems
We now introduce LRPC codes [19] and ensuing cryptosystems.
Deﬁnition 10. A Low Rank Parity Check (LRPC) code of rank d, length n and
dimension k over GF(qm) is a code deﬁned by a (n −k) × n parity check matrix
H = (hi,j), such that all its coordinates hi,j belong to the same GF(q)-subspace
of dimension d of GF(qm). We denote by {F1, F2, . . . , Fd} a basis of F.
An eﬃcient decoding algorithm was provided in a way close to the classical
decoding procedure of BCH. Indeed, the general idea for decoding a word y is
as follows: when the parity matrix H has rank weight small enough, the space
generated by the coordinates of a syndrome s = H.yT enables to recover the
product space P = ⟨E.F⟩. Then, knowledge of both P and F enables to deduce
E the support of the error e and ﬁnally the error e contained in y by solving a
linear system.

264
Q. Alam´elou et al.
LRPC Cryptosystem. Contrary to Gabidulin codes [33], LRPC codes enjoy a
poor structure so that they end up to be a well-suited candidate for rank-
based cryptography. When embedded into either McEliece or Niederreiter cryp-
tographic setting, they enable the design of an LRPC-based encryption scheme.
In Sect. 7), we will focus on the Niederreiter setting to instantiate our scheme.
RankSign or Decoding a Random Syndrome Beyond GVR. LRPC codes cannot
decode up to the GVR bound so to circumvent the impossibility of applying
the CFS methodology, Gaborit et al. [20] then proposed to decode random syn-
dromes above GVR. Given a syndrome, the idea is to randomly ﬁx some subspace
of the error support (Deﬁnition 4) which leads to increasing the size of decod-
ing balls. The RankSign signature scheme was then deduced from this result
applying a methodology close to CFS where, given a secret key, one is then able
to output a small weight vector solving an RSD instance relatively to a public
matrix. The RankSign public key can then be seen as a trapdoor matrix.
3
Deﬁnition and Security Model
3.1
Deﬁnition
Under the existence of a PKI for exchanges between users and authorities, we
propose the following deﬁnition where two authorities, a group manager (also
called issuer) and an opener, are involved.
Deﬁnition 11. A group signature GS scheme is a sequence of protocols
(KeyGen, Join, Sign, Verif , Open) such as:
– KeyGen(1λ): it generates the group public key gpk and the private keys: the
group manager secret key gmsk and the opener secret key skO containing
some tracing table tr which could be publicly revealed;
– Join(Ui, gmsk, gpk): interactive protocol between a user Ui and the group man-
ager. In the end, the user gets a secret key usk[i] and the issuer contacts the
opener to update tr;
– Sign(usk[i], gpk, m; μ): to sign a message m, the user uses his secret key usk[i]
and some randomness μ to output a signature σ valid under the group public
key;
– V erif(gpk, m, σ): anybody can check the validity of a signature σ on the mes-
sage m with respect to gpk. It outputs 1 if the signature is valid, and 0 other-
wise;
– Open(skO, gpk, m, σ): for a valid signature σ with respect to gpk, the opener
can provide signer’s identity: it thus outputs the user Ui when it succeeds and
0 otherwise.

A Practical Group Signature Scheme Based on Rank Metric
265
3.2
Security Model
Compared to classic BMW related static models, our scheme enjoys the possi-
bility of adding group members (protocol Join) during lifetime of the group but
does not fulﬁll the non-frameability security property required by the dynamic
BSZ model.
Remark 2. Informally, non-frameability guarantees that, even if both the group
manager and the opener are corrupted, no honest user could be accused of having
generated a signature if he did not. Even if non-frameability appears as a nice
property, many real life applications, such as authentication systems, assume
issuer integrity so that the interest of our model does hold in numerous contexts.
We then require our scheme to fulﬁll properties of correctness, anonymity
and traceability.
Correctness. This guarantees that honest users should be able to generate
valid signatures, and the opener should then be able to revoke anonymity of the
signers.
In the following experiments, we denote the set of corrupted users by CU ,
made of users for which an adversary A knows their secret keys in opposition to
honest users referred as the set HU . A is granted some oracles:
– Ojoin(Ui), a new user Ui is added to HU;
– Osign(Ui, m), if Ui ∈HU , returns Sign(gmsk, sk[i], m) and adds i to S[m], the
list of users for which a signature on message m exists;
– Ocorrupt(Ui), if Ui ∈HU , provides user’s secret key usk[i] and moves Ui to
CU ;
– Oopen(m, σ), returns Open(skO, gpk, m, σ).
Anonymity and Traceability. Informally, the anonymity notion requires that
signatures issued by two users are computationally indistinguishable to an adver-
sary A. Traceability ensures that no group member or coalition of group members
and the opener can produce a valid signature that cannot be opened or for which
the opening process might accuse an honest user.
Anonymity. The anonymity security game (Fig. 1(a)) consists in a challenger
randomly choosing a bit b ∈{0, 1} while the adversary A is asked to guess this
value. More precisely, A targets two users i0 and i1 and the challenger issues a
signature on behalf of ib. Granted aforesaid oracles, the adversary wins the game
if it outputs b′ = b.
Traceability. Concerning traceability (Fig. 1(b)), the adversary aims at produc-
ing a valid signature for which the opening procedure either fails or accuses an
honest user. More precisely, algorithm Verif must output 1 on inputs a cople
(m, σ) generated by the adversary and gpk while procedure Open should not

266
Q. Alam´elou et al.
output the identity of a corrupted user because it would simply mean that A
signed m with a secret key he already knew. On the contrary, if A is able to
produce a valid signature that cannot be opened or that traces back to an honest
user, we consider that he has succeeded in attacking the security of the scheme.
(a) Experiment Expanon−b
GS,A
(λ)
1. (gpk, gmsk) ←KeyGen(1λ)
2. (m, i0, i1) ←A(gpk, tr : Ojoin, Ocorrupt, Osign, Oopen)
3. σb ←Sign(usk[ib], gpk, m; μ)
4. b′ ←A(gpk, σb : Ojoin, Ocorrupt, Osign, Oopen)
5. If i0 /∈HU or i1 /∈HU , Return 0.
6. Return b′.
Adv anon
GS,A(λ) = Pr[Expanon−1
GS,A
(λ) = 1] −Pr[Expanon−0
GS,A
(λ) = 1]
(b) Experiment Exptr
GS,A(λ)
1. (gpk, gmsk, skO) ←KeyGen(1λ)
2. (m, σ) ←A(gpk, skO : Ojoin, OCorrupt, Osign)
3. If Verif (gpk, m, σ) = 0, Return 0.
4. If Open(skO, gpk, m, σ) = ⊥, Return 1.
5. If ∃j ̸∈CU ∪S[m],
Open(skO, gpk, m, σ) = j, Return 1.
6.Else Return 0.
Advtr
GS,A(λ) = Pr[Exptr
GS,A(λ) = 1]
Fig. 1. Security notions
Deﬁnition 12. A group signature scheme fulﬁlling correctness and for which
advantages related to anonymity and traceability (Fig. 1) are negligible, is said
to be dynamic.
4
Rank Concatenated Stern’s Protocol
For H a public matrix, x a small weight vector of weight wx, and the syndrome
s = H.xT , Stern’s authentication protocol [28] permits a prover to convince a
veriﬁer that he knows a small weight vector of weight wx, such that H.xT = s.
Stern’s authentication protocol and its variations have been widely used to
design group signatures through FS paradigm. A rank-based alternative was ﬁrst
proposed by [29] that was later broken and repaired by Gaborit et al. in [30].
We rely on this latter, referred as the Rank Stern’s protocol to propose a new
rank-based ZK authentication protocol.
4.1
Problematic and Overview of Our Protocol
The problematic is to design an authentication protocol enabling a veriﬁer to
check the weight of each part of a split secret. More precisely, let us consider
k × n and k × n′ random matrices Q and R over GF(qm), a syndrome s, some
weights ωx and ωy leading to the SD instance depicted in Fig. 2.

A Practical Group Signature Scheme Based on Rank Metric
267

Q | R

.
x
y

= s.
Fig. 2. High level overview
While (Rank) Stern’s protocol only allows to prove knowledge of a secret z
of weight ωx +ωy, our goal is to prove knowledge of a split secret z = (x, y) such
as ωt(x) = ωx and ωt(y) = ωy.
4.2
Rank Concatenated Stern’s Protocol
Similarly to [17], Fig. 3 introduces our authentication protocol, from now referred
as Rank Concatenated Stern’s Protocol (RCSP), whose goal is to prove knowl-
edge of a secret (x, y) with weight constraints on both x and y. The idea is some-
what to run, in parallel, 2 instances of Rank Stern’s protocol on x and y while
linking these two values through commitments. We denote here Vn = GF(qm)n
and Vn′ = GF(qm)n′.
RSD instance ((Q|R), s, ωQ, ωR)
P’s secret: (x, y) ∈Vn × Vn′ such as (Q|R).(x, y)T = s with ωt(x) = ωx and ωt(y) = ωy
1. [Commitment step] P chooses (v1, v2)
$←∈Vn × Vn′, r1, r2, r3
$←1λ,
(P1, P2)
$←GLn(GF(q)) × GLn′(GF(q)) and Q1, Q2
$←GLm(q) and
He then sends c1, c2, c3 where:
c1 = h(Q1|P1|QvT
1 + RvT
2 |Q2|P2|r1),
c2 = h(Q1 ∗v1P1|Q2 ∗v2P2|r2),
c3 = h(Q1 ∗(v1 + x)P1|(Q2 ∗(v2 + y)P2|r3)
2. [Challenge step] V sends ch
$←{0, 1, 2} to P.
3. [Response step] There are three possibilities:
ch = 0: P responds v1, (Q1|P1), v2, (Q2|P2), r1, r2.
ch = 1: P responds v1 + x, (Q1|P1), v2 + y, (Q2|P2), r1, r3.
ch = 2: P responds Q1 ∗v1P1, Q1 ∗xP1, Q2 ∗v2P2, Q2 ∗yP2, r2, r3.
4. [Veriﬁcation step] There are three possibilities:
ch = 0: V checks c1, c2.
ch = 1: V checks c1, c3.
ch = 2: V checks c2, c3 and
ωt(Q1 ∗xP1) = ωx, ωt(Q2 ∗yP2) = ωy.
5. [Final step] V outputs Accept if all checks passed,
⊥otherwise.
Fig. 3. Rank Concatenated Stern’s Protocol (RCSP).

268
Q. Alam´elou et al.
Remark 3. As pointed out in [17], original version of Stern’s authentication pro-
tocol [28] (in both Hamming and Rank cases) suﬀers a witness distinguishability.
A simple randomization (roles of seeds r1, r2, r3) addresses this issue to ensure
ZK property.
Theorem 1. RCSP (Fig. 3) is an honest prover veriﬁer ZK protocol with cheat-
ing probability 2/3 thus verifying properties of completeness, soundness and zero-
knowledge.
Proof. Lying on rank version of Stern’s protocol [30], the proof is straightfor-
ward. Completeness property is straightforward and we only stress out that
in the case where ch = 1, the veriﬁer can check validity of c1 by computing
h(Q1|P1|(Q(v1 + x)T + R(v2 + y)T −s|Q2|P2|r1). Soundness and ZK properties
directly come from those (of the randomized) Rank Stern’s protocol.
5
Our Rank-Based Group Signature Scheme
Before going into details, we introduce matrices Hs and Hc, indistinguishable
from random ones, verifying:
– Hs is a public trapdoor matrix i.e. given a (trapdoor) secret key sk s, a random
syndrome s and an integer ωs, one can output y solving the RSD instance
(Hs, s, ωs);
– Hc is the public key of a Rank-based Public Key Cryptosystem (R-PKC) with
associated secret key sk c.
5.1
High Level Overview of Our Scheme
The main idea is to instantiate RCSP with particular matrices Q and R so that
a user will be given a small weight split secret (x, yi) such as:
– yi is user’s signing key committed into a group public syndrome s relatively
to Hs;
– x is a random vector committed through a R-PKC ciphertext c enabling to
further revoke anonymity.
These secrets are then linked via a syndrome r, leading to the situation depicted
in Fig. 4, where A and B are random matrices, Hs is a trapdoor matrix and Hc,
a R-PKC public matrix.
To sign a message, Ui then makes a proof of knowledge on (x, yi) through
Rank Concatenated Stern’s protocol (Fig. 3). When the opener, given the R-
PKC secret key, wants to revoke anonymity, he ﬁrst recovers x from c and then
computes r −AxT . This value must appear in its tracing table tr containing all
the B.yT
i s from which he can ﬁnally deduce signer’s identity.

A Practical Group Signature Scheme Based on Rank Metric
269
⎡
⎣
A | B
0 | Hs
Hc | 0
⎤
⎦.
x
yi

=
⎛
⎝
r
s
c
⎞
⎠.
Fig. 4. A particular instantiation of RCSP.
5.2
Algorithms KeyGen, Join and Sign
To begin, the algorithm KeyGen, according to λ, generates the following data:
– a RSD instance (Hs, s, ωs) where Hs is a trapdoor matrix with associated
secret key sk s given to the group manager;
– a R-PKC key pair (Hc, sk c) with sk c given to the opener;
– an integer ω and two random matrices A, B.
When contacted by user Ui, the group manager uses its trapdoor key sk s to
compute user’s secret key usk[i] = yi as a solution of the aforesaid RSD instance.
The opener is then given the syndrome B.yT
i to update tr.
Now, to authenticate himself, Ui ﬁrst chooses a random x of weight ω and
computes the syndromes r = A.xT + B.yT
i
and c = Hc.xT . By instantiating
Q =
 A
0
Hc

and R =
 B
Hs
0

, he makes, through RCSP, a ZK proof on the secret
(x, yi) with ωt(x) = ω and ωt(yi) = ωs, solving the RSD instance depicted in
Fig. 4.
(a) KeyGen(1λ)
1. According to λ, generate:
1.1. a RSD instance rsd = (Hs, s, ωs):
−Hs a trapdoor matrix;
−sk s its related secret key.
1.2. a R-PKC instance:
−Hc the public matrix key;
−skc its related secret key.
1.3. two random matrices A and B
and an integer ω.
4. gpk := (Hs, Hc, A, B, s, ωs, ω).
5. gmsk := sk s, skO := (sk c, tr = [ ]).
6. Return (gpk, gmsk, skO).
(b) Join(Ui, gmsk = sks, gpk)
1. Use the trapdoor sks on Hs to
output yi solving rsd.
2. If ∃j ≤i −1,
yi = usk[j] ∨B.yT
i = tr[j],
go to 1.
3. Return usk[i] = yi, tr[i] = B.yT
i .
(c) Sign(usk[j] = yi, gpk, m; μ)
1. Choose a random x
such as ωt(x) = ω.
1.1. r := A.xT + B.yT
i .
1.2. c := Hc.xT .
2. For l = 1 . . . lλ
2.1. Set c1, c2, c3, d1, d2, d3
according to Figure 3, step 1.
2.2. cmt[l] := {c1, c2, . . . , d3}.
3. ch := Hλ(m, cmt, r, c) ∈2 lλ.
4. For i = 1 . . . lλ
Generate rsp[l] according to
ch[l] and Figure 3, step 3.
5. Set Π = (cmt, ch, resp).
6. Return σ = (Π, (r, c)).
Fig. 5. KeyGen, Join, Sign algorithms

270
Q. Alam´elou et al.
Finally, by turning this process non-interactive through FS paradigm, we
get the signing algorithm. Algorithms KeyGen, Join and Sign are described in
Fig. 5.
5.3
Algorithms Verif and Open
The veriﬁcation algorithm relies on the veriﬁcation step of RCSP (Fig. 3).
To revoke anonymity, the opener uses skc to recover x from the R-PKC
ciphertext c = Hc.xT . He can then computes A.xT and subtracts this value to
r transmitted in the signature along with c. The result r −A.xT must be equal
to some tr[i], from which the signer’s identity is learnt. These two algorithms
appear in Fig. 6.
(a) Verif (gpk, m, σ)
1. Parse σ = (Π, (r, c))
2. Parse Π = (cmt, ch, rsp)
3. ˜ch := Hλ(m, cmt, r, c) ∈2 lλ.
If ( ˜ch ̸= ch), Return 0.
4. For l = 1 . . . lλ
3.1. Check rsp[l] according to
cmt[l], ch[l] and Figure 3.
3.2. If a veriﬁcation fails,
Return 0.
5. Return 1.
(b) Open(skO, gpk, m, σ)
1. If (Verif (gpk, m, σ) = 0)
Return ⊥.
2. Parse σ = (Π, (r, c))
3. Parse skO = (sk c, tr).
4. Use skc to recover x from c.
5. Set z = r −AxT
6. For i = 1 . . . N
If (tr[i] = z)
Return Ui.
7. Return ⊥.
Fig. 6. Verif and Open algorithms
6
Security Analysis
Since correctness directly comes from RCSP, we focus on anonymity and trace-
ability requirements deﬁned in Fig. 1. We begin with the anonymity property.
Theorem 2. If there exists an adversary A that can break the anonymity prop-
erty of the scheme, then there exists an adversary B that can either break the
Zero-Knowledge property of RCSP or the Decision Rank Syndrome Decoding
(D-RSD) problem.
Proof. Through a sequence of games, we will exhibit that an adversary against
our anonymity property would be able to either break the ZK property of our
scheme or the D-RSD problem.
G0 B runs KeyGen(1λ) and acts honestly as described in Fig. 1(a).
G1 Now, to answer the opening query, the simulator uses the ROM observability
to extract some y, and then compares the value to the B.yT
i contained in tr.
Under the ZK soundness, this is similar to the previous game.
G2 The simulator now supersedes part of the KeyGen by setting

A
Hc

= C. This
game is identical to the previous one.

A Practical Group Signature Scheme Based on Rank Metric
271
G3 The simulator now simulates the proof when answering the challenge queries,
by not using the value x, yi. This game is identical to the previous one under
the ZK property.
G4 Now, he sends randoms c = s1, r = s2 +B.yT
i . This game is indistinguishable
from the previous one under the D-RSD problem. (This is seen, by splitting
the challenge s in s1, s2 as it was done for the matrix C)
G5 This last game only displays random values, hence the adversary has no
advantage, which terminates the proof.
Concerning traceability, we have the following theorem.
Theorem 3. If there exists an adversary A that can break the traceability of
the scheme, then there exists an adversary B that can break either break the
Soundness of the Zero-Knowledge proof or the OMRSD problem.
Proof. The proof is straightforward, the simulator starts by simulating the ZK
proofs on every honest signing queries. Then, he picks an identity at random
expecting it to be the targeted honest user (this happens with non-negligible
probability) and sets his tracing key B.y⊤
∗as s, for the other identities the
simulator sends a request to the RSD oracle, and forwards the answer.
Receiving the adversary answers, the simulator uses the ROM, to extract the
value y∗solution to the challenge.
7
Instantiation
Our scheme is generic and can be used with any trapdoor matrix and public
key encryption scheme. In our rank-based context, RankSign and LRPC embed-
ded into Niederreiter setting (see Sect. 2) constitute well-suited candidates for
respectively instantiating matrices Hs and Hc introduced in Sect. 5.
According to Sects. 5 and 6, correctness and security of our scheme generi-
cally rely on matrices Hs and Hc meant to be indistinguishable from random
ones. With such an instantiation, the security is maintained through the puta-
tive indistinguashibilty of LRPC and RankSign public matrices with random
matrices [19].
Parameters. As it will exhibited below, it is suﬃcient in practice to consider
matrices A and B with only one row and then according to previous section, the
security of the protocol relies on the D-RSD problem or the OMRSD problem
associated to matrices Hs and Hc. We now give parameters to obtain an overall
security of 2100.
Following [20], we can consider parameters n′ = 23, k′ = 10, t = 3, m = 24
and q = 28 to design a RankSign public matrix Hs of dimension (n′ −k′) ×
(n′ +t) with coordinates lying in GF(qm). In particular, t denotes the number of
generalized erasures handled by such an instantiation. The size of the group then
consists in the number of potential antecedents to a common public syndrome
s; namely it corresponds to the number of possibilities to form t independent

272
Q. Alam´elou et al.
vectors lying over GF(qm) which roughly leads to qtm users (28×24 here). We
refer the reader to [20] for more details on this point. On the other hand, the
matrix Hc can be instantiated with the cyclic LRPC cryptosystem embedded
in Niederreiter setting; following [19], we consider parameters n = 74, k = 37,
q = 28 and the working ﬁeld GF(qm). Now, matrices A and B are only used to
diﬀerentiate the B.yT
i (procedure Open) and since q = 28 and m = 24, there are
2192 possibilities for B.yT
i by simply taking A and B with one row. Finally, with
A and B made of one row and Hc cyclic, the size of the public key is mainly due
to Hs. By considering the systematic form with aforesaid parameters, it leads to
Hs of size (n′ −k′) × (n′ + t −n′ + k′) = (23 −10) × (10 + 3) over GF(28×24).
Adding contributions of A, B and one line of Hc, it ﬁnally leads to a public key
of around 5 kB.
The signature size depends both on the security level and the length of a
proof of knowledge in RCSP (Fig. 3). Let us ﬁrst notice that random matrices
involved in the protocol can be sent through seeds from which they could be
regenerated. Hence, the preponderant data sent during the protocol consists in
the vectors belonging to Vn and Vn′: thus we get on average 4/3 elements of the
ambient space GF(qm)n+n′ representing 4/3 × (74 + 23) × 8 × 24 bits. When
targeting a 100 bits security level for which 100/log2(3/2) repetitions of the
protocol are required, this leads to a signature of 550 kB. One should notice
that these parameters are versatile and it would be easy to ﬁnd parameters to
ﬁt another security level.
Asymptotic Complexity. To study the asymptotic complexity, we ﬁrst recall
that:
– the number of users N is roughly qmt = 2mtlog(q);
– in practice and as exhibited above, parameters t, k′ and m are set to O(n′) so
that the public key is approximated by O(n′3 × log(q)).
For a given security level, it is possible to increase the number of users by
increasing the size of q. In that case we consider all parameters except q as ﬁxed.
From the previous recalls, the number of users is then N = 2O(log(q)) when the
size of parameters is in O(log(q)) = O(log(N)).
Finally, in terms of computation time, the protocol is very eﬃcient since in
themselves the LRPC and RankSign cryptosystems are very fast (a few millisec-
onds for encryption/decryption or signature).
Concurrent Works. Our dynamic scheme compares very well with code-based
concurrent works such as [17,18]. Indeed, it features public key and signature
sizes logarithmic in N while those of the static scheme presented in [18] are
linear in N. Furthermore, when considering at maximum 224 users, the latter
one leads to a public key of size 1.16 GB with the advantage of only relying
on the SD-problem. Even if dynamic and with public key and signature sizes
in N 1/√
log(N), the group signature of [17] leads to signatures of size 20 MB

A Practical Group Signature Scheme Based on Rank Metric
273
and a public key of 2.5 MB. In parallel, despite recent progress and satisfying
asymptotic performances [11,13–16] (public keys and signatures logarithmic in
the number of group members), lattice-based constructions still suﬀer great sizes
of parameters. Indeed, the most eﬃcient one due to [16], improving works of
[13,14], proposes signatures and a public key respectively of size 61.5 MB and
4.9 MB for a group made of only 1024 users and an overall security of 280.
8
Conclusion
This work proposes the ﬁrst rank-based group signature scheme that is dynamic
in a relaxation of the BSZ model and compares very well with concurrent post-
quantum schemes. By introducing a rank-based ZK authentication protocol,
which could be of independent interest, we obtain a signature scheme via Fiat-
Shamir paradigm. Its security in the ROM, relies on LRPC related cryptosystems
(RankSign and Niederreiter), the RSD problem, and rank-based computational
problems introduced along with this work (OMRSD and D-RSD problems). With
an asymptotic complexity better than code-based constructions and similar to
best lattice-based results, our scheme features public key and signature sizes
logarithmic in the number of group members. Last but not least, with well cho-
sen parameters, we obtain an instantiation with public key and signature sizes
respectively of 550 kB and 5 kB so that our scheme appears fairly practical and
as the most eﬃcient post-quantum group signature protocol up to date.
References
1. Chaum, D., Heyst, E.: Group signatures. In: Davies, D.W. (ed.) EUROCRYPT
1991. LNCS, vol. 547, pp. 257–265. Springer, Heidelberg (1991). doi:10.1007/
3-540-46416-6 22
2. Bellare, M., Micciancio, D., Warinschi, B.: Foundations of group signatures: formal
deﬁnitions, simpliﬁed requirements, and a construction based on general assump-
tions. In: Biham, E. (ed.) EUROCRYPT 2003. LNCS, vol. 2656, pp. 614–629.
Springer, Heidelberg (2003). doi:10.1007/3-540-39200-9 38
3. Bellare, M., Shi, H., Zhang, C.: Foundations of group signatures: the case of
dynamic groups. In: Menezes, A. (ed.) CT-RSA 2005. LNCS, vol. 3376, pp. 136–
153. Springer, Heidelberg (2005). doi:10.1007/978-3-540-30574-3 11
4. Boneh, D., Boyen, X., Shacham, H.: Short group signatures. In: Franklin, M. (ed.)
CRYPTO 2004. LNCS, vol. 3152, pp. 41–55. Springer, Heidelberg (2004). doi:10.
1007/978-3-540-28628-8 3
5. Camenisch, J., Lysyanskaya, A.: Signature schemes and anonymous credentials
from bilinear maps. In: Franklin, M. (ed.) CRYPTO 2004. LNCS, vol. 3152, pp.
56–72. Springer, Heidelberg (2004). doi:10.1007/978-3-540-28628-8 4
6. Boneh, D., Shacham, H.: Group signatures with veriﬁer-local revocation. In: Pro-
ceedings of CCS 2004, pp. 168–177. ACM Press (2004)
7. Kiayias, A., Tsiounis, Y., Yung, M.: Traceable signatures. In: Cachin, C.,
Camenisch, J.L. (eds.) EUROCRYPT 2004. LNCS, vol. 3027, pp. 571–589.
Springer, Heidelberg (2004). doi:10.1007/978-3-540-24676-3 34

274
Q. Alam´elou et al.
8. Groth, J.: Fully anonymous group signatures without random oracles. In: Kuro-
sawa, K. (ed.) ASIACRYPT 2007. LNCS, vol. 4833, pp. 164–180. Springer,
Heidelberg (2007). doi:10.1007/978-3-540-76900-2 10
9. Libert, B., Yung, M.: Eﬃcient traceable signatures in the standard model. In:
Shacham, H., Waters, B. (eds.) Pairing 2009. LNCS, vol. 5671, pp. 187–205.
Springer, Heidelberg (2009). doi:10.1007/978-3-642-03298-1 13
10. Gordon, S.D., Katz, J., Vaikuntanathan, V.: A group signature scheme from lattice
assumptions. In: Abe, M. (ed.) ASIACRYPT 2010. LNCS, vol. 6477, pp. 395–412.
Springer, Heidelberg (2010). doi:10.1007/978-3-642-17373-8 23
11. Laguillaumie, F., Langlois, A., Libert, B., Stehl´e, D.: Lattice-based group sig-
natures with logarithmic signature size. In: Sako, K., Sarkar, P. (eds.) ASI-
ACRYPT 2013. LNCS, vol. 8270, pp. 41–61. Springer, Heidelberg (2013). doi:10.
1007/978-3-642-42045-0 3
12. Langlois, A., Ling, S., Nguyen, K., Wang, H.: Lattice-based group signature scheme
with veriﬁer-local revocation. In: Krawczyk, H. (ed.) PKC 2014. LNCS, vol. 8383,
pp. 345–361. Springer, Heidelberg (2014). doi:10.1007/978-3-642-54631-0 20
13. Ling, S., Nguyen, K., Wang, H.: Group signatures from lattices: simpler, tighter,
shorter, ring-based. In: Katz, J. (ed.) PKC 2015. LNCS, vol. 9020, pp. 427–449.
Springer, Heidelberg (2015). doi:10.1007/978-3-662-46447-2 19
14. Nguyen, P.Q., Zhang, J., Zhang, Z.: Simpler eﬃcient group signatures from lattices.
In: Katz, J. (ed.) PKC 2015. LNCS, vol. 9020, pp. 401–426. Springer, Heidelberg
(2015). doi:10.1007/978-3-662-46447-2 18
15. Libert, B., Mouhartem, F., Nguyen, K.: A lattice-based group signature scheme
with message-dependent opening. In: Manulis, M., Sadeghi, A.-R., Schneider, S.
(eds.) ACNS 2016. LNCS, vol. 9696, pp. 137–155. Springer, Cham (2016). doi:10.
1007/978-3-319-39555-5 8
16. Libert, B., Ling, S., Nguyen, K., Wang, H.: Zero-knowledge arguments for lattice-
based accumulators: logarithmic-size ring signatures and group signatures without
trapdoors. In: Fischlin, M., Coron, J.-S. (eds.) EUROCRYPT 2016. LNCS, vol.
9666, pp. 1–31. Springer, Heidelberg (2016). doi:10.1007/978-3-662-49896-5 1
17. Alam´elou, Q., Blazy, O., Cauchie, S., Gaborit, P.: A code-based group signature
scheme. In: Charpin, J.-P.T.P., Sendrier, N. (eds.) Proceedings of the 9th Inter-
national Workshop on Coding and Cryptography 2015, WCC2015, France, Paris
(2015)
18. Ezerman, M.F., Lee, H.T., Ling, S., Nguyen, K., Wang, H.: A provably secure group
signature scheme from code-based assumptions. In: Iwata, T., Cheon, J.H. (eds.)
ASIACRYPT 2015. LNCS, vol. 9452, pp. 260–285. Springer, Heidelberg (2015).
doi:10.1007/978-3-662-48797-6 12
19. Gaborit, P., Murat, G., Ruatta, O., Z´emor, G.: Low Rank Parity Check codes and
their application to cryptography. In: WCC 2013, Bergen, Norway, April 2013
20. Gaborit, P., Ruatta, O., Schrek, J., Z´emor, G.: RankSign: an eﬃcient signature
algorithm based on the rank metric. In: Mosca, M. (ed.) PQCrypto 2014. LNCS,
vol. 8772, pp. 88–107. Springer, Cham (2014). doi:10.1007/978-3-319-11659-4 6
21. Gaborit, P., Z´emor, G.: On the hardness of the decoding and the minimum distance
problems for rank codes. CoRR, abs/1404.3482 (2014)
22. Fiat, A., Shamir, A.: How to prove yourself: practical solutions to identiﬁcation
and signature problems. In: Odlyzko, A.M. (ed.) CRYPTO 1986. LNCS, vol. 263,
pp. 186–194. Springer, Heidelberg (1987). doi:10.1007/3-540-47721-7 12
23. Loidreau, P.: Properties of codes in rank metric. CoRR, abs/cs/0610057 (2006)

A Practical Group Signature Scheme Based on Rank Metric
275
24. Gaborit, P., Ruatta, O., Schrek, J., Z´emor, G.: New results for rank-based cryp-
tography. In: Pointcheval, D., Vergnaud, D. (eds.) AFRICACRYPT 2014. LNCS,
vol. 8469, pp. 1–12. Springer, Cham (2014). doi:10.1007/978-3-319-06734-6 1
25. Gaborit, P., Ruatta, O., Schrek, J.: On the complexity of the rank syndrome decod-
ing problem. IEEE Trans. Inf. Theory 62(2), 1006–1019 (2016)
26. Berlekamp, E., McEliece, R.J., Van Tilborg, H.C.A.: On the inherent intractability
of certain coding problems (corresp.). IEEE Trans. Inf. Theory 24(3), 384–386
(1978)
27. Goldwasser, S., Micali, S., Rackoﬀ, C.: The knowledge complexity of interactive
proof systems. SIAM J. Comput. 18(1), 186–208 (1989)
28. Stern, J.: A new identiﬁcation scheme based on syndrome decoding. In: Stinson,
D.R. (ed.) CRYPTO 1993. LNCS, vol. 773, pp. 13–21. Springer, Heidelberg (1994).
doi:10.1007/3-540-48329-2 2
29. Chen, K.: A new identiﬁcation algorithm. In: Dawson, E., Goli´c, J. (eds.) CPA
1995. LNCS, vol. 1029, pp. 244–249. Springer, Heidelberg (1996). doi:10.1007/
BFb0032363
30. Gaborit, P., Schrek, J., Z´emor, G.: Full cryptanalysis of the chen identiﬁcation pro-
tocol. In: Yang, B.-Y. (ed.) PQCrypto 2011. LNCS, vol. 7071, pp. 35–50. Springer,
Heidelberg (2011). doi:10.1007/978-3-642-25405-5 3
31. Fischer, J.-B., Stern, J.: An eﬃcient pseudo-random generator provably as secure
as syndrome decoding. In: Maurer, U. (ed.) EUROCRYPT 1996. LNCS, vol. 1070,
pp. 245–255. Springer, Heidelberg (1996). doi:10.1007/3-540-68339-9 22
32. Gaborit, P., Hauteville, A., Tillich, J.-P.: RankSynd a PRNG based on rank metric.
In: Takagi, T. (ed.) PQCrypto 2016. LNCS, vol. 9606, pp. 18–28. Springer, Cham
(2016). doi:10.1007/978-3-319-29360-8 2
33. Ernst, M.: Gabidulin: theory of codes with maximum rank distance. Probl.
Peredachi Inf. 21(1), 3–16 (1985)

Author Index
Alamélou, Quentin
258
Ball, Simeon
95
Barbulescu, Razvan
3
Blazy, Olivier
258
Cauchie, Stéphane
258
Coşgun, Ayhan
243
Davenport, James H.
105
Ferraguti, Andrea
77
Flori, Jean-Pierre
143
Fouotsa, Emmanuel
36
Gaborit, Philippe
258
Ghammam, Loubna
36
Hofer, Richard
67
Hosseini, Seyed Gholamhossein
21
Karmakar, Angshuman
193
Kavut, Selçuk
227
Maitra, Subhamoy
227
Martinsen, Thor
160
Mefenza, Thierry
125
Meidl, Wilfried
160
Mentens, Nele
208
Mérai, László
54
Micheli, Giacomo
77
Munemasa, Akihiro
84
Nakamura, Hiroko
84
Özbudak, Ferruh
227, 243
Petit, Christophe
105
Picek, Stjepan
208
Plantard, Thomas
177
Pring, Benjamin
105
Rezaeian Farashahi, Reza
21
Robert, Jean-Marc
177
Roy, Sujoy Sinha
193
Schnyder, Reto
77
Stănică, Pantelimon
160
Verbauwhede, Ingrid
193
Vercauteren, Frederik
193
Vergnaud, Damien
125
Winterhof, Arne
67
Yang, Bohan
208

