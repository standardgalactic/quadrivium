Applied Control Systems Design

Magdi S. Mahmoud r Yuanqing Xia
Applied Control
Systems Design

Magdi S. Mahmoud
Department of Systems Engineering
King Fahad Univ. of Petroleum & Minerals
Dhahran, Saudi Arabia
Prof. Yuanqing Xia
Dept. Automatic Control
Beijing Institute of Technology
Beijing, China, People’s Republic
ISBN 978-1-4471-2878-6
e-ISBN 978-1-4471-2879-3
DOI 10.1007/978-1-4471-2879-3
Springer London Dordrecht Heidelberg New York
British Library Cataloguing in Publication Data
A catalogue record for this book is available from the British Library
Library of Congress Control Number: 2012936365
© Springer-Verlag London Limited 2012
Apart from any fair dealing for the purposes of research or private study, or criticism or review, as per-
mitted under the Copyright, Designs and Patents Act 1988, this publication may only be reproduced,
stored or transmitted, in any form or by any means, with the prior permission in writing of the publish-
ers, or in the case of reprographic reproduction in accordance with the terms of licenses issued by the
Copyright Licensing Agency. Enquiries concerning reproduction outside those terms should be sent to
the publishers.
The use of registered names, trademarks, etc., in this publication does not imply, even in the absence of a
speciﬁc statement, that such names are exempt from the relevant laws and regulations and therefore free
for general use.
The publisher makes no representation, express or implied, with regard to the accuracy of the information
contained in this book and cannot accept any legal responsibility or liability for any errors or omissions
that may be made.
Printed on acid-free paper
Springer is part of Springer Science+Business Media (www.springer.com)

Preface
An integral part of control systems engineering is the development of controller
design methods to achieve some prescribed performance criteria. It has been one of
the most active research areas in the past decades. A common denominator of these
methods is the availability of a mathematical model that is derived from physical
laws, practical consideration or identiﬁcation of real data. Several important issues
arises including the quality and nature of the model, the performance criteria and
control design approach.
This book provides a guided tour of applied control system design. The starting
point is the construction of system models based on real experimental data. These
models will be evaluated and tested using standard signals. A wide spectrum of con-
trol design methods will be applied to these models. Closed-loop system responses
will be obtained and compared. The end result is to provide an experience-based
recipe that can serve as check-list for researchers or control designers. In this re-
gard, the book uniﬁes the methods for developing feedback controllers and ﬁlters
for a wide class of dynamical systems and reports on the recent advances in design
methodologies. Throughout the book, the use of MATLAB is the vehicle for all
methods of analysis and design.
After an introductory chapter, the book is divided into eight self-contained chap-
ters with each chapter being equipped with illustrative examples, problems and
questions. The book will be supplemented by some design problems, appropriate
appendices and index.
It is planned while organizing the material that this book would be appropriate
for use either as graduate-level textbook in applied mathematics as well as different
engineering disciplines (electrical, mechanical, civil, chemical, systems), a good
volume for independent study or a reference for practicing engineers, interested
readers, researchers and students.
Magdi S. Mahmoud
Yuanqing Xia
KFUPM, Saudi Arabia
BIT, China
v

Acknowledgements
Although the material contained in this volume is an outgrowth of our academic
teaching and research activities over the past several years, the idea of writing the
book arose and developed during Summer 2010 when Magdi Mahmoud was visiting
BIT based on an invitation from Yuanqing Xia.
In writing this book, we took the approach of referring within the text to papers
and/or books which we believed taught us some ideas and methods. We then com-
plement this by adding some notes and questions at the end of each chapter to shed
some light on other related results. We apologize in advance in case we committed
injustice and assure our colleagues that any mistake was not made in purpose.
We are immensely pleased for many stimulating discussions with colleagues, stu-
dents and friends throughout our technical careers which have deﬁnitely enriched
our knowledge and experience. In particular, we owe a measure of gratitude to Pro-
fessor Michael A. Johnson, University of Strathclyde, for his unfailing guidance,
critical review and constructive criticism on earlier draft of the manuscript. We
gratefully acknowledge helpful suggestions and assistance by Oliver Jackson and
Charlotte Cross at Springer-London.
It is a great pleasure to acknowledge the ﬁnancial funding afforded by the dean-
ship of scientiﬁc research (DSR) through project No. IN101024 and for provid-
ing superb competitive environment and overall support of research activities at
KFUPM. Magdi Mahmoud owe a measure of gratitude to KFUPM management for
the continuous encouragements and facilitating all sources of help.
Magdi Mahmoud had the privilege of teaching various graduate courses at
KFUPM (Saudi Arabia). The course notes, updated and organized, were instrumen-
tal in generating different chapters of this book and valuable comments and/or sug-
gestions by graduate students were greatly helpful, particularly those attended the
courses SE 507, SE 513 and SE 514 offered at the Systems Engineering Department
over the period 2007–2011.
Most of all however, we would wholeheartedly like to thank all the members of
our families. Without their constant love, incredible amount of patience and (mostly)
enthusiastic support this volume would not have been ﬁnished.
Magdi S. Mahmoud
Yuanqing Xia
vii

Contents
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
Modern Automation Structure . . . . . . . . . . . . . . . . . . . .
2
1.3
Systems Identiﬁcation . . . . . . . . . . . . . . . . . . . . . . . .
4
1.4
Control Design . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.5
Outline of the Book . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.5.1
Methodology . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.5.2
Chapter Organization
. . . . . . . . . . . . . . . . . . . .
6
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
2
Some Industrial Systems . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.2
Steam Generation Unit . . . . . . . . . . . . . . . . . . . . . . . .
12
2.2.1
System Dynamics . . . . . . . . . . . . . . . . . . . . . .
12
2.3
Small-Power Wind Turbine . . . . . . . . . . . . . . . . . . . . .
15
2.3.1
Wind Turbine Basics . . . . . . . . . . . . . . . . . . . . .
15
2.4
Unmanned Surface Marine Vehicle . . . . . . . . . . . . . . . . .
17
2.4.1
Dynamic Model . . . . . . . . . . . . . . . . . . . . . . .
18
2.5
Industrial Evaporation Unit . . . . . . . . . . . . . . . . . . . . .
19
2.5.1
Mathematical Models . . . . . . . . . . . . . . . . . . . .
19
2.5.2
Multistage Evaporator System . . . . . . . . . . . . . . . .
20
2.6
Distillation Tower . . . . . . . . . . . . . . . . . . . . . . . . . .
21
2.6.1
A Particular Tower . . . . . . . . . . . . . . . . . . . . . .
21
2.7
Falling Film Evaporator . . . . . . . . . . . . . . . . . . . . . . .
22
2.7.1
A Single Effect Evaporator
. . . . . . . . . . . . . . . . .
23
2.8
Vapor Compression Cycle Systems . . . . . . . . . . . . . . . . .
25
2.8.1
A Typical System
. . . . . . . . . . . . . . . . . . . . . .
26
2.9
Flutter of an Aircraft F-18 . . . . . . . . . . . . . . . . . . . . . .
27
2.9.1
Flutter Input and Output Data . . . . . . . . . . . . . . . .
27
2.10 A Hydraulic Pumping System . . . . . . . . . . . . . . . . . . . .
28
2.10.1 Hydraulic Process and the Data . . . . . . . . . . . . . . .
29
ix

x
Contents
2.10.2 Static Behavior . . . . . . . . . . . . . . . . . . . . . . . .
30
2.11 Notes and References . . . . . . . . . . . . . . . . . . . . . . . .
30
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
3
System Identiﬁcation Methods
. . . . . . . . . . . . . . . . . . . . .
35
3.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
3.2
Parameter Estimation Approach . . . . . . . . . . . . . . . . . . .
36
3.2.1
Estimation Algorithms . . . . . . . . . . . . . . . . . . . .
39
3.2.2
Gradient Algorithm . . . . . . . . . . . . . . . . . . . . .
41
3.2.3
Least Squares Algorithm
. . . . . . . . . . . . . . . . . .
45
3.2.4
Choice of the Adaptation Gain
. . . . . . . . . . . . . . .
51
3.3
Transfer-Function Methods . . . . . . . . . . . . . . . . . . . . .
54
3.3.1
Prediction Error Method (PEM) . . . . . . . . . . . . . . .
54
3.4
Subspace Identiﬁcation Method . . . . . . . . . . . . . . . . . . .
56
3.4.1
State Space Models
. . . . . . . . . . . . . . . . . . . . .
56
3.4.2
Block Hankel Matrices and State Sequences . . . . . . . .
59
3.4.3
Model Matrices
. . . . . . . . . . . . . . . . . . . . . . .
60
3.4.4
Orthogonal Projections
. . . . . . . . . . . . . . . . . . .
60
3.4.5
Oblique Projections . . . . . . . . . . . . . . . . . . . . .
61
3.4.6
Deterministic Subspace Identiﬁcation . . . . . . . . . . . .
63
3.4.7
Stochastic Subspace Identiﬁcation
. . . . . . . . . . . . .
65
3.4.8
Combined Deterministic-Stochastic Algorithm . . . . . . .
68
3.4.9
Variations
. . . . . . . . . . . . . . . . . . . . . . . . . .
72
3.5
Output-Error Parametric Model Identiﬁcation . . . . . . . . . . . .
73
3.5.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . .
73
3.5.2
Problems in Estimating Parameters . . . . . . . . . . . . .
74
3.5.3
Identiﬁcation Example 3.1 . . . . . . . . . . . . . . . . . .
76
3.5.4
Parameterizing a MIMO Model . . . . . . . . . . . . . . .
77
3.5.5
Identiﬁcation Example 3.2 . . . . . . . . . . . . . . . . . .
78
3.5.6
Identiﬁcation Example 3.3 . . . . . . . . . . . . . . . . . .
80
3.5.7
Identiﬁcation Example 3.4 . . . . . . . . . . . . . . . . . .
81
3.5.8
The Output Normal Form . . . . . . . . . . . . . . . . . .
82
3.5.9
Identiﬁcation Example 3.5 . . . . . . . . . . . . . . . . . .
86
3.5.10 The Tridiagonal Form . . . . . . . . . . . . . . . . . . . .
88
3.5.11 The Output-Error Cost Function . . . . . . . . . . . . . . .
89
3.5.12 Identiﬁcation Example 3.6 . . . . . . . . . . . . . . . . . .
90
3.5.13 Numerical Parameter Estimation
. . . . . . . . . . . . . .
92
3.5.14 The Gauss–Newton Method . . . . . . . . . . . . . . . . .
94
3.5.15 Identiﬁcation Example 3.7 . . . . . . . . . . . . . . . . . .
95
3.5.16 Regularization in the Gauss–Newton Method . . . . . . . .
97
3.5.17 The Steepest Descent Method . . . . . . . . . . . . . . . .
97
3.5.18 Gradient Projection
. . . . . . . . . . . . . . . . . . . . .
99
3.5.19 Analyzing the Accuracy of the Estimates . . . . . . . . . . 101
3.5.20 Dealing with Colored Measurement Noise . . . . . . . . . 104
3.5.21 Identiﬁcation Example 3.8 . . . . . . . . . . . . . . . . . . 104
3.5.22 Weighted Least Squares . . . . . . . . . . . . . . . . . . . 105

Contents
xi
3.5.23 Prediction-Error Methods . . . . . . . . . . . . . . . . . . 106
3.6
Prediction-Error Parametric Model Estimation . . . . . . . . . . . 107
3.6.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . 107
3.6.2
Prediction-Error Methods . . . . . . . . . . . . . . . . . . 108
3.6.3
Parameterizing an Innovation State-Space Model . . . . . . 109
3.6.4
The Prediction-Error Cost Function . . . . . . . . . . . . . 111
3.6.5
Numerical Parameter Estimation
. . . . . . . . . . . . . . 114
3.6.6
Analyzing the Accuracy of the Estimates . . . . . . . . . . 115
3.6.7
Some Model Parameterizations for SISO Systems . . . . . 116
3.6.8
The ARMAX and ARX Model Structures
. . . . . . . . . 116
3.6.9
Identiﬁcation Example 3.9 . . . . . . . . . . . . . . . . . . 120
3.6.10 Identiﬁcation Example 3.10 . . . . . . . . . . . . . . . . . 120
3.6.11 The Box–Jenkins and Output-Error Model Structures
. . . 121
3.6.12 Qualitative Analysis of the Model Bias . . . . . . . . . . . 124
3.6.13 Identiﬁcation Example 3.11 . . . . . . . . . . . . . . . . . 127
3.6.14 Identiﬁcation Example 3.12 . . . . . . . . . . . . . . . . . 129
3.6.15 Estimation Problems in Closed-Loop Systems . . . . . . . 131
3.6.16 Identiﬁcation Example 3.13 . . . . . . . . . . . . . . . . . 131
3.6.17 Identiﬁcation Example 3.14 . . . . . . . . . . . . . . . . . 132
3.6.18 Software . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
3.7
Questions
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
3.8
Notes and References . . . . . . . . . . . . . . . . . . . . . . . . 140
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
4
Applications I . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
4.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
4.2
Distillation Unit . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
4.2.1
Data Analysis
. . . . . . . . . . . . . . . . . . . . . . . . 149
4.2.2
Validation and Model Fitness . . . . . . . . . . . . . . . . 151
4.3
Steam Generation Unit . . . . . . . . . . . . . . . . . . . . . . . . 152
4.3.1
MIMO ARX Model . . . . . . . . . . . . . . . . . . . . . 153
4.3.2
MIMO State-Space Model . . . . . . . . . . . . . . . . . . 153
4.3.3
Comparison of MIMO Models
. . . . . . . . . . . . . . . 154
4.4
Falling Film Evaporator . . . . . . . . . . . . . . . . . . . . . . . 155
4.4.1
Identiﬁcation Results
. . . . . . . . . . . . . . . . . . . . 156
4.5
Vapor Compression Cycle Systems . . . . . . . . . . . . . . . . . 156
4.5.1
Identiﬁcation Results
. . . . . . . . . . . . . . . . . . . . 158
4.6
Unmanned Marine Vehicle
. . . . . . . . . . . . . . . . . . . . . 159
4.6.1
Identiﬁcation Results
. . . . . . . . . . . . . . . . . . . . 160
4.6.2
ARMAX Model . . . . . . . . . . . . . . . . . . . . . . . 165
4.6.3
State Space Model . . . . . . . . . . . . . . . . . . . . . . 166
4.6.4
KID Model . . . . . . . . . . . . . . . . . . . . . . . . . . 170
4.6.5
Result of Comparisons . . . . . . . . . . . . . . . . . . . . 172
4.6.6
State-Space Order Determinations
. . . . . . . . . . . . . 175
4.7
Industrial Evaporation Unit . . . . . . . . . . . . . . . . . . . . . 176
4.7.1
Continuous-Time Model . . . . . . . . . . . . . . . . . . . 177

xii
Contents
4.7.2
Discrete-Time Model
. . . . . . . . . . . . . . . . . . . . 177
4.7.3
Disturbances . . . . . . . . . . . . . . . . . . . . . . . . . 177
4.7.4
The Prediction Error Method (PEM) Method . . . . . . . . 178
4.7.5
Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . 179
4.7.6
Modiﬁcations
. . . . . . . . . . . . . . . . . . . . . . . . 182
4.7.7
Estimation Using ARX Model . . . . . . . . . . . . . . . . 184
4.7.8
The Multivariable ARX Case . . . . . . . . . . . . . . . . 185
4.7.9
Estimated State Space Using N4SID Model
. . . . . . . . 187
4.7.10 Numerical Results . . . . . . . . . . . . . . . . . . . . . . 190
4.8
A Hydraulic Pumping System . . . . . . . . . . . . . . . . . . . . 193
4.8.1
Dynamical Data . . . . . . . . . . . . . . . . . . . . . . . 197
4.8.2
ARX Modeling
. . . . . . . . . . . . . . . . . . . . . . . 200
4.8.3
ARMAX Modeling
. . . . . . . . . . . . . . . . . . . . . 203
4.8.4
Box–Jenkins Model . . . . . . . . . . . . . . . . . . . . . 203
4.8.5
State Space Model . . . . . . . . . . . . . . . . . . . . . . 204
4.8.6
Linear Identiﬁcation Results . . . . . . . . . . . . . . . . . 206
4.9
Flutter for F-18: Estimation and Validation . . . . . . . . . . . . . 207
4.9.1
PEM Method . . . . . . . . . . . . . . . . . . . . . . . . . 207
4.9.2
ARX Method
. . . . . . . . . . . . . . . . . . . . . . . . 207
4.9.3
ARMAX Method
. . . . . . . . . . . . . . . . . . . . . . 208
4.9.4
BJ Method . . . . . . . . . . . . . . . . . . . . . . . . . . 208
4.9.5
Output Equation Method
. . . . . . . . . . . . . . . . . . 209
4.9.6
N4SID Method . . . . . . . . . . . . . . . . . . . . . . . . 210
4.10 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . 211
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213
5
Nominal Control Design . . . . . . . . . . . . . . . . . . . . . . . . . 215
5.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215
5.1.1
Basic Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . 216
5.1.2
Feedback Control Systems
. . . . . . . . . . . . . . . . . 217
5.1.3
Open-Loop Control Systems
. . . . . . . . . . . . . . . . 218
5.1.4
Closed-Loop Control Systems . . . . . . . . . . . . . . . . 218
5.1.5
Control Systems Design . . . . . . . . . . . . . . . . . . . 218
5.1.6
Standard Representations . . . . . . . . . . . . . . . . . . 220
5.2
Basic Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
5.2.1
Stability
. . . . . . . . . . . . . . . . . . . . . . . . . . . 221
5.2.2
Controllability . . . . . . . . . . . . . . . . . . . . . . . . 222
5.2.3
Control Example 5.1 . . . . . . . . . . . . . . . . . . . . . 223
5.2.4
Observability . . . . . . . . . . . . . . . . . . . . . . . . . 223
5.2.5
Control Example 5.2 . . . . . . . . . . . . . . . . . . . . . 224
5.2.6
Control Example 5.3 . . . . . . . . . . . . . . . . . . . . . 224
5.2.7
Important Notes . . . . . . . . . . . . . . . . . . . . . . . 224
5.3
State Feedback . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
5.3.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . 226
5.3.2
Control Example 5.4 . . . . . . . . . . . . . . . . . . . . . 227
5.3.3
Control Example 5.5 . . . . . . . . . . . . . . . . . . . . . 228

Contents
xiii
5.3.4
Control Example 5.6 . . . . . . . . . . . . . . . . . . . . . 229
5.3.5
Control Example 5.7 . . . . . . . . . . . . . . . . . . . . . 231
5.3.6
Control Example 5.8 . . . . . . . . . . . . . . . . . . . . . 234
5.3.7
Control Example 5.9 . . . . . . . . . . . . . . . . . . . . . 237
5.3.8
State-Feedback in MATLAB
. . . . . . . . . . . . . . . . 242
5.4
Observer-Based Feedback . . . . . . . . . . . . . . . . . . . . . . 242
5.4.1
Basics
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 242
5.4.2
Control Example 5.10 . . . . . . . . . . . . . . . . . . . . 244
5.4.3
Control Example 5.11 . . . . . . . . . . . . . . . . . . . . 245
5.5
Classiﬁcations of Industrial Controllers . . . . . . . . . . . . . . . 248
5.5.1
Two-Position Control Action
. . . . . . . . . . . . . . . . 249
5.5.2
P-Control Action . . . . . . . . . . . . . . . . . . . . . . . 250
5.5.3
Integral Control Action
. . . . . . . . . . . . . . . . . . . 251
5.5.4
PI Control Action . . . . . . . . . . . . . . . . . . . . . . 251
5.5.5
PD Control Action . . . . . . . . . . . . . . . . . . . . . . 251
5.5.6
PID Control Action
. . . . . . . . . . . . . . . . . . . . . 252
5.6
Closed-Loop System Subjected to a Disturbance . . . . . . . . . . 252
5.6.1
Main Issues
. . . . . . . . . . . . . . . . . . . . . . . . . 253
5.6.2
P-Control of Systems
. . . . . . . . . . . . . . . . . . . . 254
5.6.3
I-Control of Systems . . . . . . . . . . . . . . . . . . . . . 256
5.7
Response to Torque Disturbances . . . . . . . . . . . . . . . . . . 256
5.7.1
P-Control . . . . . . . . . . . . . . . . . . . . . . . . . . . 257
5.7.2
PI-Control . . . . . . . . . . . . . . . . . . . . . . . . . . 257
5.7.3
D-Control Action
. . . . . . . . . . . . . . . . . . . . . . 259
5.7.4
P-Control of Systems with Inertia Load . . . . . . . . . . . 259
5.7.5
PD-Control of a System with Inertia Load
. . . . . . . . . 260
5.7.6
PD-Control of Second-Order Systems . . . . . . . . . . . . 261
5.7.7
Control Example 5.12 . . . . . . . . . . . . . . . . . . . . 261
5.8
Linear Optimal Control: Continuous-Time . . . . . . . . . . . . . 264
5.8.1
Important Special Case
. . . . . . . . . . . . . . . . . . . 266
5.8.2
Control Example 5.13 . . . . . . . . . . . . . . . . . . . . 267
5.8.3
Control Example 5.14 . . . . . . . . . . . . . . . . . . . . 267
5.8.4
Optimal Set-Point Control . . . . . . . . . . . . . . . . . . 270
5.8.5
An LMI Formulation
. . . . . . . . . . . . . . . . . . . . 272
5.9
Linear Optimal Control: Discrete-Time . . . . . . . . . . . . . . . 273
5.9.1
An LMI Formulation
. . . . . . . . . . . . . . . . . . . . 276
5.9.2
Direct Driven Inverted Pendulum . . . . . . . . . . . . . . 277
5.9.3
Modeling of dDIP . . . . . . . . . . . . . . . . . . . . . . 279
5.9.4
Optimal Control of Turbo-Generator System . . . . . . . . 280
5.10 Digital Control of Uninterruptible Power Supplies . . . . . . . . . 282
5.10.1 Plant Description
. . . . . . . . . . . . . . . . . . . . . . 283
5.10.2 LQR Design . . . . . . . . . . . . . . . . . . . . . . . . . 283
5.10.3 Recursive Least-Squares Estimator . . . . . . . . . . . . . 286
5.10.4 Kalman Filter
. . . . . . . . . . . . . . . . . . . . . . . . 287
5.10.5 Simulation Results . . . . . . . . . . . . . . . . . . . . . . 288

xiv
Contents
5.11 Model Predictive Control Method . . . . . . . . . . . . . . . . . . 289
5.11.1 Predictive Control Formulation . . . . . . . . . . . . . . . 291
5.11.2 NPC Algorithm
. . . . . . . . . . . . . . . . . . . . . . . 294
5.11.3 RPC Algorithm
. . . . . . . . . . . . . . . . . . . . . . . 295
5.11.4 Implementation Details . . . . . . . . . . . . . . . . . . . 295
5.12 LQGR Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296
5.12.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . 297
5.12.2 Kalman Filter
. . . . . . . . . . . . . . . . . . . . . . . . 298
5.12.3 Solution of the Stochastic Linear Regulator Problem . . . . 300
5.13 MATLAB Hints . . . . . . . . . . . . . . . . . . . . . . . . . . . 302
5.13.1 LQR in MATLAB . . . . . . . . . . . . . . . . . . . . . . 302
5.14 Questions and MATLAB Problems . . . . . . . . . . . . . . . . . 302
5.14.1 Questions
. . . . . . . . . . . . . . . . . . . . . . . . . . 302
5.14.2 MATLAB Problems . . . . . . . . . . . . . . . . . . . . . 303
5.15 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . 305
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
6
Applications II
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
6.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
6.2
Control of Shaping Process of Automobile Belt
. . . . . . . . . . 309
6.2.1
System Model . . . . . . . . . . . . . . . . . . . . . . . . 311
6.2.2
State-Feedback and LQR Control . . . . . . . . . . . . . . 313
6.2.3
Pole Placement . . . . . . . . . . . . . . . . . . . . . . . . 313
6.2.4
LQR Optimal Control . . . . . . . . . . . . . . . . . . . . 313
6.2.5
Disturbance Rejection . . . . . . . . . . . . . . . . . . . . 315
6.2.6
Observer-Based Feedback . . . . . . . . . . . . . . . . . . 316
6.2.7
Reduced-Order Observer
. . . . . . . . . . . . . . . . . . 318
6.3
An Unmanned Helicopter . . . . . . . . . . . . . . . . . . . . . . 321
6.3.1
Linearized Model
. . . . . . . . . . . . . . . . . . . . . . 321
6.3.2
Stabilization Schemes . . . . . . . . . . . . . . . . . . . . 322
6.4
Reverse Osmosis Desalination Plant . . . . . . . . . . . . . . . . . 322
6.4.1
Reverse Osmosis Modeling . . . . . . . . . . . . . . . . . 324
6.4.2
Linear Discrete Model . . . . . . . . . . . . . . . . . . . . 325
6.5
Turbocharged Diesel Engine . . . . . . . . . . . . . . . . . . . . . 326
6.5.1
Dynamic Modeling
. . . . . . . . . . . . . . . . . . . . . 330
6.6
A Rotational Hydraulic Drive . . . . . . . . . . . . . . . . . . . . 331
6.6.1
System Model . . . . . . . . . . . . . . . . . . . . . . . . 333
6.6.2
LQR: Continuous and Discrete Control . . . . . . . . . . . 335
6.7
The Falling Film Evaporator . . . . . . . . . . . . . . . . . . . . . 338
6.7.1
State Feedback Design . . . . . . . . . . . . . . . . . . . . 339
6.7.2
Observer Feedback Design
. . . . . . . . . . . . . . . . . 342
6.7.3
LQR Designs
. . . . . . . . . . . . . . . . . . . . . . . . 342
6.7.4
Tracking Control . . . . . . . . . . . . . . . . . . . . . . . 347
6.8
Vapor Compression Cycle Systems . . . . . . . . . . . . . . . . . 347
6.8.1
Model with Two Output Pressures . . . . . . . . . . . . . . 347
6.8.2
Model with Four Output Temperatures . . . . . . . . . . . 349

Contents
xv
6.8.3
LQR Simulation Results: Continuous Case . . . . . . . . . 350
6.8.4
LQR Simulation Results: Discrete Case . . . . . . . . . . . 352
6.9
Stabilization of F-8 Fly-by-Wire Aircraft . . . . . . . . . . . . . . 353
6.9.1
Linearized Model
. . . . . . . . . . . . . . . . . . . . . . 354
6.9.2
Simulation Results . . . . . . . . . . . . . . . . . . . . . . 355
6.10 Air Conditioning System
. . . . . . . . . . . . . . . . . . . . . . 356
6.10.1 State-Feedback . . . . . . . . . . . . . . . . . . . . . . . . 358
6.10.2 Observer-Based Feedback . . . . . . . . . . . . . . . . . . 359
6.10.3 Tracking Control . . . . . . . . . . . . . . . . . . . . . . . 359
6.11 Three-Degree-of-Freedom Helicopter Model . . . . . . . . . . . . 361
6.11.1 Linearized Model
. . . . . . . . . . . . . . . . . . . . . . 361
6.12 PID Control of a Quadrotor Unmanned Air Vehicle
. . . . . . . . 363
6.12.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . 365
6.12.2 Dynamic Modeling
. . . . . . . . . . . . . . . . . . . . . 366
6.12.3 PID Control Design . . . . . . . . . . . . . . . . . . . . . 369
6.12.4 Simulation Results . . . . . . . . . . . . . . . . . . . . . . 370
6.13 Design of an Aircraft Controller . . . . . . . . . . . . . . . . . . . 372
6.13.1 Linearized Model
. . . . . . . . . . . . . . . . . . . . . . 373
6.13.2 Simulation Results . . . . . . . . . . . . . . . . . . . . . . 374
6.14 Motion Control Design of Liquid Container
. . . . . . . . . . . . 375
6.14.1 Dynamic Model . . . . . . . . . . . . . . . . . . . . . . . 378
6.14.2 State Feedback Design . . . . . . . . . . . . . . . . . . . . 380
6.14.3 Observer-Based Feedback Design . . . . . . . . . . . . . . 381
6.14.4 LQR Design . . . . . . . . . . . . . . . . . . . . . . . . . 381
6.14.5 Tracking Control Design
. . . . . . . . . . . . . . . . . . 382
6.15 Vertical Motion Control of Marine Vehicles . . . . . . . . . . . . . 383
6.15.1 Dynamic Model . . . . . . . . . . . . . . . . . . . . . . . 383
6.15.2 LQR Design . . . . . . . . . . . . . . . . . . . . . . . . . 384
6.15.3 LQGR Design . . . . . . . . . . . . . . . . . . . . . . . . 385
6.16 Pitch Control of Wind Turbines . . . . . . . . . . . . . . . . . . . 387
6.16.1 Simulation of Wind Turbine . . . . . . . . . . . . . . . . . 388
6.16.2 Pitch Control of Wind Turbine
. . . . . . . . . . . . . . . 390
6.17 LQR in MATLAB . . . . . . . . . . . . . . . . . . . . . . . . . . 395
6.18 Questions
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 395
6.18.1 MATLAB Problems . . . . . . . . . . . . . . . . . . . . . 395
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 402
7
Robust Control Design . . . . . . . . . . . . . . . . . . . . . . . . . . 405
7.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 405
7.1.1
Norm Measures of Signals . . . . . . . . . . . . . . . . . . 406
7.1.2
Norm Measures of Systems . . . . . . . . . . . . . . . . . 406
7.1.3
Signiﬁcance of H2-Norm . . . . . . . . . . . . . . . . . . 408
7.1.4
Signiﬁcance of H∞-Norm . . . . . . . . . . . . . . . . . . 409
7.2
H2 Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 411
7.2.1
Control Example 7.1 . . . . . . . . . . . . . . . . . . . . . 412
7.2.2
H2 Optimization . . . . . . . . . . . . . . . . . . . . . . . 413

xvi
Contents
7.2.3
The Standard H2 Problem . . . . . . . . . . . . . . . . . . 414
7.2.4
Control Example 7.2 . . . . . . . . . . . . . . . . . . . . . 416
7.2.5
Control Example 7.3 . . . . . . . . . . . . . . . . . . . . . 418
7.2.6
Control Example 7.4 . . . . . . . . . . . . . . . . . . . . . 420
7.3
H∞Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 421
7.3.1
Two Hamiltonians . . . . . . . . . . . . . . . . . . . . . . 421
7.3.2
LMI Framework . . . . . . . . . . . . . . . . . . . . . . . 422
7.3.3
H2 Design . . . . . . . . . . . . . . . . . . . . . . . . . . 423
7.3.4
H∞Design
. . . . . . . . . . . . . . . . . . . . . . . . . 424
7.3.5
Mixed H2–H∞Synthesis . . . . . . . . . . . . . . . . . . 424
7.4
Control Design of Hydraulic Pumping System . . . . . . . . . . . 425
7.4.1
LQGR Control . . . . . . . . . . . . . . . . . . . . . . . . 426
7.4.2
H2 Optimal Control . . . . . . . . . . . . . . . . . . . . . 426
7.4.3
H∞Control . . . . . . . . . . . . . . . . . . . . . . . . . 428
7.5
Vapor Compression Cycle Systems . . . . . . . . . . . . . . . . . 428
7.5.1
H2 Results . . . . . . . . . . . . . . . . . . . . . . . . . . 429
7.5.2
H∞Results
. . . . . . . . . . . . . . . . . . . . . . . . . 430
7.5.3
LQGR Results . . . . . . . . . . . . . . . . . . . . . . . . 430
7.5.4
A Comparative Study . . . . . . . . . . . . . . . . . . . . 431
7.6
Robust Control of Turbo Diesel Engine . . . . . . . . . . . . . . . 433
7.6.1
Robust Simulation Results . . . . . . . . . . . . . . . . . . 434
7.6.2
Kalman Filter
. . . . . . . . . . . . . . . . . . . . . . . . 436
7.6.3
LQGR Control . . . . . . . . . . . . . . . . . . . . . . . . 437
7.7
The Falling Film Evaporator . . . . . . . . . . . . . . . . . . . . . 440
7.7.1
H2 Control . . . . . . . . . . . . . . . . . . . . . . . . . . 440
7.7.2
H∞Control . . . . . . . . . . . . . . . . . . . . . . . . . 440
7.8
Integral Control and Robust Tracking . . . . . . . . . . . . . . . . 440
7.8.1
Integral Control . . . . . . . . . . . . . . . . . . . . . . . 441
7.8.2
Control Example 7.4 . . . . . . . . . . . . . . . . . . . . . 443
7.8.3
The Error-Space Approach
. . . . . . . . . . . . . . . . . 446
7.8.4
Control Example 7.5 . . . . . . . . . . . . . . . . . . . . . 450
7.8.5
Control Example 7.6 . . . . . . . . . . . . . . . . . . . . . 454
7.8.6
The Extended Estimator . . . . . . . . . . . . . . . . . . . 456
7.8.7
Control Example 7.7 . . . . . . . . . . . . . . . . . . . . . 459
7.9
Questions
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 460
7.10 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . 460
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 461
8
Adaptive Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 463
8.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 463
8.2
Preliminary Examples . . . . . . . . . . . . . . . . . . . . . . . . 463
8.2.1
Example 8.1 . . . . . . . . . . . . . . . . . . . . . . . . . 464
8.2.2
Example 8.2 . . . . . . . . . . . . . . . . . . . . . . . . . 464
8.2.3
Example 8.3 . . . . . . . . . . . . . . . . . . . . . . . . . 465
8.3
Adaptive Control Approaches . . . . . . . . . . . . . . . . . . . . 466
8.3.1
Indirect Adaptive Control Approach
. . . . . . . . . . . . 466

Contents
xvii
8.3.2
Direct Adaptive Control Approach
. . . . . . . . . . . . . 467
8.3.3
Comparisons . . . . . . . . . . . . . . . . . . . . . . . . . 469
8.4
Non-identiﬁer-Based Adaptive Schemes
. . . . . . . . . . . . . . 469
8.4.1
Gain Scheduling . . . . . . . . . . . . . . . . . . . . . . . 469
8.4.2
Multiple Models and Search Methods . . . . . . . . . . . . 471
8.5
A Class of Parametric Models . . . . . . . . . . . . . . . . . . . . 472
8.5.1
Static Parametric Model . . . . . . . . . . . . . . . . . . . 472
8.5.2
Dynamic Parametric Model . . . . . . . . . . . . . . . . . 473
8.5.3
Bilinear Parametric Models . . . . . . . . . . . . . . . . . 473
8.5.4
Example 8.4 . . . . . . . . . . . . . . . . . . . . . . . . . 475
8.5.5
Example 8.5 . . . . . . . . . . . . . . . . . . . . . . . . . 476
8.5.6
Example 8.6 . . . . . . . . . . . . . . . . . . . . . . . . . 478
8.6
Parameter Identiﬁcation . . . . . . . . . . . . . . . . . . . . . . . 478
8.6.1
One-Parameter Case . . . . . . . . . . . . . . . . . . . . . 479
8.6.2
Two-Parameters Case . . . . . . . . . . . . . . . . . . . . 483
8.7
Gradient Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . 485
8.7.1
Gradient Algorithm with Instantaneous Cost Function . . . 486
8.7.2
Example 8.7 . . . . . . . . . . . . . . . . . . . . . . . . . 487
8.7.3
Gradient Algorithm with Integral Cost Function . . . . . . 488
8.8
Least-Squares Algorithms . . . . . . . . . . . . . . . . . . . . . . 489
8.8.1
Recursive LS Algorithm with Forgetting Factor
. . . . . . 491
8.8.2
Pure LS Algorithm . . . . . . . . . . . . . . . . . . . . . . 492
8.8.3
Example 8.8 . . . . . . . . . . . . . . . . . . . . . . . . . 492
8.8.4
Modiﬁed LS Algorithms . . . . . . . . . . . . . . . . . . . 493
8.8.5
Parameter Identiﬁcation Based on DPM
. . . . . . . . . . 494
8.8.6
Parameter Identiﬁcation Based on B-SPM
. . . . . . . . . 496
8.9
Parameter Projection . . . . . . . . . . . . . . . . . . . . . . . . . 498
8.9.1
Example 8.9 . . . . . . . . . . . . . . . . . . . . . . . . . 499
8.9.2
Example 8.10
. . . . . . . . . . . . . . . . . . . . . . . . 500
8.10 Robust Parameter Identiﬁcation . . . . . . . . . . . . . . . . . . . 500
8.10.1 Example 8.11
. . . . . . . . . . . . . . . . . . . . . . . . 501
8.10.2 Example 8.12
. . . . . . . . . . . . . . . . . . . . . . . . 501
8.10.3 Dominantly Rich Excitation . . . . . . . . . . . . . . . . . 502
8.11 State-Space Identiﬁers . . . . . . . . . . . . . . . . . . . . . . . . 504
8.11.1 Example 8.13
. . . . . . . . . . . . . . . . . . . . . . . . 506
8.12 Adaptive Observers
. . . . . . . . . . . . . . . . . . . . . . . . . 506
8.13 A Single Bottleneck Link Computer Network . . . . . . . . . . . . 509
8.14 MATLAB Hints . . . . . . . . . . . . . . . . . . . . . . . . . . . 510
8.15 Questions
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 511
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 519
9
Appendix
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 521
9.1
Important Facts in Linear Algebra . . . . . . . . . . . . . . . . . . 521
9.1.1
Basic Notions
. . . . . . . . . . . . . . . . . . . . . . . . 521
9.1.2
Inner Product and Orthogonality
. . . . . . . . . . . . . . 524
9.1.3
Kronecker Product and Stack of Matrices . . . . . . . . . . 525

xviii
Contents
9.2
Linear Transformations and Matrix Groups . . . . . . . . . . . . . 526
9.3
Matrix Algebra . . . . . . . . . . . . . . . . . . . . . . . . . . . . 529
9.3.1
Inverse of Block Matrices . . . . . . . . . . . . . . . . . . 530
9.3.2
Matrix Inversion Lemma
. . . . . . . . . . . . . . . . . . 531
9.4
Range, Kernel, Rank and Eigenvectors of a Matrix . . . . . . . . . 531
9.5
Symmetric and Skew-Symmetric Matrices . . . . . . . . . . . . . 534
9.6
Singular Value Decomposition
. . . . . . . . . . . . . . . . . . . 536
9.6.1
Geometric Interpretation . . . . . . . . . . . . . . . . . . . 538
9.6.2
Example A.1 . . . . . . . . . . . . . . . . . . . . . . . . . 539
9.6.3
Some Properties of the SVD . . . . . . . . . . . . . . . . . 539
9.7
Gram–Schmidt and the QR Decomposition . . . . . . . . . . . . . 542
9.8
Useful Formulae . . . . . . . . . . . . . . . . . . . . . . . . . . . 543
9.8.1
Ackermann’s Formula for Eigenvalue Assignment . . . . . 543
9.8.2
Parseval Formula . . . . . . . . . . . . . . . . . . . . . . . 544
9.8.3
Frobenius Formula . . . . . . . . . . . . . . . . . . . . . . 545
9.9
Inequalities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 545
9.9.1
Inequality 1
. . . . . . . . . . . . . . . . . . . . . . . . . 545
9.9.2
Inequality 2
. . . . . . . . . . . . . . . . . . . . . . . . . 545
9.9.3
Inequality 3
. . . . . . . . . . . . . . . . . . . . . . . . . 546
9.9.4
Inequality 4 (Schur Complements)
. . . . . . . . . . . . . 546
9.9.5
Inequality 5
. . . . . . . . . . . . . . . . . . . . . . . . . 548
9.10 Lemmas
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 548
9.11 Linear Matrix Inequalities . . . . . . . . . . . . . . . . . . . . . . 551
9.11.1 Basics
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 551
9.11.2 Some Standard Problems
. . . . . . . . . . . . . . . . . . 552
9.11.3 The S-Procedure . . . . . . . . . . . . . . . . . . . . . . . 553
9.12 Lyapunov Map and Lyapunov Equation . . . . . . . . . . . . . . . 554
9.13 Persistence of Excitation and Sufﬁciently Rich Inputs
. . . . . . . 555
9.14 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . 558
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 558
Index
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 559

List of Notations1
List of Symbols
I +
The set of positive integers
ℜ
The set of real numbers
ℜ+
The set of non-negative real numbers
ℜn
The set of all n-dimensional real vectors
ℜn×m
The set of n × m-dimensional real matrices
C−
The open right-half complex plane
C+
The closed right-half complex plane
∈
Belong to or element of
⊂
Subset of

Union

Intersection
≫
Much greater than
≪
Much less than
At
The transpose of matrix A
A−1
The inverse of matrix A
I
An identity matrix of arbitrary order
Is
The identity matrix of dimension s × s
ej
The jth column of matrix I
xt or At
The transpose of vector x or matrix A
λ(A)
An eigenvalue of matrix A
ϱ(A)
The spectral radius of matrix A
λj(A)
The jth eigenvalue of matrix A
λm(A)
The minimum eigenvalue of matrix A, where λ(A) are real
λM(A)
The maximum eigenvalue of matrix A, where λ(A) are real
1Throughout this book, the following terminologies, conventions and notations have been adopted.
All of them are quite standard in the scientiﬁc media and only vary in form or character. Matrices,
if their dimensions are not explicitly stated, are assumed to be compatible for algebraic operations.
In symmetric block matrices or complex matrix expressions, we use the symbol • to represent a
term that is induced by symmetry.
xix

xx
List of Notations
A−1
The inverse of matrix A
A†
The Moore–Penrose-inverse of matrix A
P > 0
Matrix P is real symmetric and positive-deﬁnite
P ≥0
Matrix P is real symmetric and positive semi-deﬁnite
P < 0
Matrix P is real symmetric and negative-deﬁnite
P ≤0
Matrix P is real symmetric and negative semi-deﬁnite
A(i,j),Aij
The ijth element of matrix A
det(A)
The determinant of matrix A
trace(A)
The trace of matrix A
rank(A)
The rank of matrix A
L2(−∞,∞)
Space of time domain square integrable functions
L2[0,∞)
Subspace of L2(−∞,∞) with functions zero for t > 0
L2(−∞,0]
Subspace of L2(−∞,∞) with functions zero for t < 0
L2(jℜ)
Square integrable functions on C0 including at ∞
H2
Subspace of L2(jℜ) with functions analytic in Re(s) > 0
L∞(jℜ)
Subspace of functions bounded on Re(s) = 0 including at ∞
H∞
The set of L∞(jℜ) functions analytic in Re(s) > 0
|a|
The absolute value of scalar a
∥x∥
The Euclidean norm of vector x
∥A∥
The induced Euclidean norm of matrix A
∥x∥p
The ℓp norm of vector x
∥A∥p
The induced ℓp norm of matrix A
Im(A)
The image of operator/matrix A
Ker(A)
The kernel of operator/matrix A
maxD
The maximum element of set D
minD
The minimum element of set D
supD
The smallest number that is larger than or equal to each element
of set D
infD
The largest number that is smaller than or equal to each element
of set D
argmaxD
The index of maximum element of ordered set S
argminD
The index of minimum element of ordered set S
Br
The ball centered at the origin with radius r
Rr
The sphere centered at the origin with radius r
N
The ﬁxed index set {1,2,...,N}
[a,b)
The real number set {t ∈ℜ: a ≤t < b}
[a,b]
The real number set {t ∈ℜ: a ≤t ≤b}
S
The set of modes {1,2,...,s}
iff
If and only if
⊗
The Kronecker product
O(.)
Order of (.)
diag(...)A
Diagonal matrix with given diagonal elements
spec(A)
The set of eigenvalues of matrix A (spectrum)
min-poly(A)(s) The minimal polynomial of matrix A

List of Notations
xxi
List of Abbreviations
ARE
Algebraic Riccati equation
LMI
Linear matrix inequality
SISO
Single-input single-output
MIMO
Multi-input multi-output
BIBS
Bounded-input bounded-state
iISS
Integral-input-to-state stable
UGAS
Uniformly globally asymptotically stable
OLD
Overlapping decomposition
SVD
Singular value decomposition
LBD
Lyapunov-based design
DTS
Discrete-time systems
LQC
Linear quadratic control
LMCR
Liquid-metal cooled reactor
DSMP
Decentralized servomechanism problem
DIP
Distributed information processing
CIP
Centralized information processing
N4SID
Numerical algorithms for subspace state-space system
identiﬁcation

Chapter 1
Introduction
1.1 Overview
In this introductory chapter, we brieﬂy review the basic concepts behind identi-
fying linear time-invariant (LTI) systems, or systems identiﬁcation (SI). We then
proceed to shed some lights about control design (CD) as applied to multivariable
dynamic systems. In general, dynamic models for prediction and control include
transfer functions, state space models, time-series models, which are parametrized
in terms of ﬁnite number of parameters. Hence, these dynamic models are referred
to as parametric models. There are also non-parametric models such as impulse re-
sponses, and frequency responses, spectral density functions, etc. In this book, we
focus on the parametric models with the main thrust evolve around integrating sys-
tem identiﬁcation and control design in one pool toward developing effective tools
for researchers and designers. In what follows, some brief accounts of common
terms are provided.
System: A system is a collection of objects arranged in an ordered form to serve
some purpose. Everything not belonging to the system is part of the environment.
One may characterize the system by input–output (cause and effect) relations. What
constitutes a system depends on the point of view of the observer. The system may
be, for example, an ampliﬁer consisting of electronic components, or a control loop
including that ampliﬁer as one of its parts, or a chemical processing unit having
many such loops, or a plant consisting of a number of units or a number of plants
operating together as a system in the environment of a global economy.
Process: A process is a processing plant that serves to manufacture homoge-
neous material or energy products. Industries that use such processing plants are
called process industries. The common process industries are oil, chemicals, electri-
cal power, paper, glass, mining, metals, cement, drugs, food and beverages. A com-
mon characteristic of process industries is that their products can be made to ﬂow.
From a control point of view, different kinds of variables in a process interact and
produce observable variables. The observable variables of interest to us are usually
called outputs. The process is also affected by external variables. External variables
that can be manipulated by us are inputs of the process. Other external variables are
M.S. Mahmoud, Y. Xia, Applied Control Systems Design,
DOI 10.1007/978-1-4471-2879-3_1, © Springer-Verlag London Limited 2012
1

2
1
Introduction
called disturbances. Disturbances can be divided into two kinds: the measured dis-
turbances which can be directly measured, and the unmeasured disturbances which
are only observed through their inﬂuence on the outputs. A process is said to be
dynamic when the current output value depends not only on the current external
stimuli but also on their earlier values.
Model: A model is a representation of the essential aspects of a system (process)
which presents knowledge of that system (process) in a usable form.
For the application of modern systems and control theory, it is necessary to use
mathematical models that describe the relationships among the system variables in
terms of difference or differential equations.
Within the major topics of this book, identiﬁcation is about how to obtain math-
ematical models of systems (processes) from observations and measurements and
use these models in designing controllers to achieve prescribed criteria.
The input–output data are usually collected from an identiﬁcation test or exper-
iment that is designed to make the measured data maximally informative about the
system properties that are of interest to the user.
A set of candidate models is obtained by specifying their common properties; a
suitable model is searched for within this set. This is the most theoretical part of the
system identiﬁcation procedure. It is here that a priori knowledge and engineering
intuition and insight have to be combined with the formal (mathematical) proper-
ties of models. In this book, we will use linear/nonlinear, time-invariant and ﬁnite
dimensional models of multi-input multi-output (MIMO) systems that are suitable
for modeling a large class of industrial processes.
When the data are available and the model set is determined, the next step is
to ﬁnd the best model in this set. For model parameter estimation, an error crite-
rion (loss function) is speciﬁed. Often the sum of the squares of some error signals
(residuals) is used as the criterion. The values of the parameters are determined by
minimizing the loss function.
When a model is identiﬁed, the next step is model validation. This step is to test
whether the estimated model is sufﬁciently good for the intended use of the model.
First of all, a check to see if the model is in agreement with the a priori knowledge
of the system. Then a check if the model can ﬁt the test or experimental data well,
preferably using a data sequence that has not been used in model estimation. The
ﬁnal validation of the model is the application of the model.
1.2 Modern Automation Structure
The process industries include the following major sectors: food, textiles, paper,
chemicals, petroleum, rubber and plastics, glass, metal and electricity. Due to
world-wide competition, shortage of natural resources and environmental pollution,
the present process industries face very dynamic and unpredictable market condi-
tions and have to produce under very strict national and international regulations.
Computer-based automation systems have been developed in process industries in
order to increase the production safety, quality and ﬂexibility, and to reduce energy

1.2
Modern Automation Structure
3
and material consumption as well as environmental pollution. Some process indus-
tries, such as the reﬁnery and petrochemical industry, recognize plant automation
more and more as a cost effective way of responding to changes of market condi-
tions and production regulations. A modern automation system in process industries
can be depicted as a pyramid and consists of the following layers.
• Instrumentation and primary control: This layer is usually a distributed control
system (DCS) which gathers process measurements and performs simple mon-
itoring of the measurements. The measurements include basic process variables
such as temperature, ﬂow, pressure, level and valve position. A DCS also per-
forms PID based controls on some of the process variables. Usually one controller
only takes care of a single primary variable such as ﬂow or temperature.
• Advanced process control (APC): This part of the system performs multivariable
model based control that will ensure stable unit operation and push the process
to its operational limits for maximum economic beneﬁt. Here one APC controller
can control a whole process such as a distillation column, a reactor. In general,
identiﬁed dynamic models (most often linear) are used for APC controllers. This
layer is usually present in a computer.
• Diagnosis and supervision: This part of the system is to improve the safety and
reliability of the unit operation. A diagnosis system performs fault detection and
classiﬁcation and gives suggestions for maintenance and remedies. Early methods
are mainly based on limit value checking of easily measurable signals and their
derivatives; a recent trend is to use process models for more accurate and quicker
diagnosis. The system can also evaluate the performance of the controllers at
different levels. This layer is usually present in a minicomputer.
• Optimization: An optimization system manipulates the process degrees of free-
dom that are left after meeting the requirements of a safe and stable operation, to
meet the unit economic objectives such as saving energy and expensive material
and/or increasing throughput. The optimizer determines the best set points for
APC controllers. Usually the optimization is carried out based on rigorous (ﬁrst
principle) nonlinear static models. Sometimes identiﬁed models are also used for
optimization, because the cost of using and maintaining a rigorous model can
be too high. Usually the optimizer is executed at a slow rate such that the APC
controls are at steady state with respect to the previous set point change. The
optimization can be performed for a single process as well as a combination of
processes. An optimizer is usually located in a minicomputer.
• Planning and scheduling: This part may cover many units of processes and it pro-
vides decision support in production planning, allocation of raw materials and
scheduling of plant operation for realizing the company’s program and for maxi-
mizing proﬁts. It is used to respond to the market changes as well as production
regulation changes. This part can be located in a minicomputer or a main frame
computer.
Each layer plays an unique and complementary role in the total automation system
and that allows the company to react rapidly to changes. At present, most process
industries have instrumentation and primary control. Only some capital intensive

4
1
Introduction
sectors use higher level layers such as APC, optimization and scheduling. To our
knowledge, reﬁnery and petrochemical industries take the lead in applying computer
automation systems. Due to the availability of affordable and reliable computers and
to development of computing and control sciences, the time is coming that more
process industries can beneﬁt from this multi-disciplinary technology.
1.3 Systems Identiﬁcation
Fundamental to most physical sciences is the concept of a mathematical model. For
example, models are essential for prediction and control purposes. The type and
accuracy of the model depends upon the application in mind, including models for
aerospace applications which usually need to be very precise, whereas models for
industrial processes, such as blast furnaces, can often be very crude. Models can
be obtained from physical reasoning or by analyzing experimental data from the
system. In the latter case, our ability to obtain an accurate model is limited by the
presence of random ﬂuctuations such as unmeasured disturbances and measurement
errors. The problem of obtaining mathematical models of physical systems from real
experimental data constitutes a major part of this book. In particular, we study the
problem of estimation of the parameters within models of dynamic systems. We also
investigate the effects of various experimental conditions upon model accuracy, see
[1–48].
In the majority of practical situations, it is necessary to implement a methodology
for direct identiﬁcation of these dynamic (control) models from experimental data.
We note that there are two types of dynamic models:
1. Non-parametric models (example: frequency response, step response).
2. Parametric models (example: transfer function, differential or difference equa-
tion).
Henceforward, we will be concerned with the identiﬁcation of parametric dynamic
models. In this regard, system identiﬁcation is an experimental approach for deter-
mining the dynamic model of a system. It includes four steps:
1. Input/output data acquisition under an experimentation protocol.
2. Selection or estimation of the “model” structure (complexity).
3. Estimation of the model parameters.
4. Validation of the identiﬁed model (structure and values of the parameters).
A complete identiﬁcation operation must necessarily comprise the four stages indi-
cated above. The speciﬁc methods used at each stage depend on the type of model
desired (parametric or non-parametric, continuous-time or discrete-time) and on the
experimental conditions (for example, hypothesis on the noise, open loop or closed
loop identiﬁcation). The validation is the mandatory step to decide if the identiﬁed
model is acceptable or not.
In what follows, we adopt the approach that ﬁltering and system identiﬁcation are
powerful techniques for building models of complex systems in communications,
signal processing, control, and other engineering disciplines.

1.4
Control Design
5
1.4 Control Design
System theory, in particular, automatic control and system identiﬁcation have expe-
rienced a fast evolution in the past decades. New methods have been developed, per-
formance requirements in traditional engineering areas have signiﬁcantly increased
and in addition, numerous demanding applications in other areas of engineering and
science have appeared. On one hand, the use of the so-called “practical” examples
has been a dominant feature of many textbooks. On the other hand, other books fo-
cus directly on the practical issues involved, leaving the theory out. However, there
is still an important gap between practical model building and the control design
tools.
The extraordinary development of digital computing devices including micro-
processors and micro controllers and their extensive use in control systems in all
ﬁelds of applications has brought about important changes in the design of con-
trol systems. Their performance and low cost make them quite suitable for use
in control systems of various types which, in turn, places a demand for better
capabilities and performances than those provided by analog controllers. From a
practical standpoint, to take advantage of the capabilities of microprocessors, it
is not enough to reproduce the behavior of analog controllers. One really needs
to implement speciﬁc and high-performance model based-control techniques de-
veloped for computer-controlled systems. In this context, identiﬁcation of a plant
dynamic model from data is a fundamental step in the design of the control sys-
tem.
It is increasingly apparent that the association of books with software and on-line
material is radically changing the teaching methods of the control engineering ﬁeld.
Computer-aided control design software requires the understanding of a number
of concepts in order to be used efﬁciently. The use of software for illustrating the
various concepts and algorithms helps understanding and rapidly gives a feeling
of the various phenomena. Details concerning effective implementation and on-site
optimization of the control systems designed have been provided.
1.5 Outline of the Book
The chief objective of this book is to provide a complete description of the ap-
plication of linear system identiﬁcation and linear control design to practical sys-
tems. Thus, this book brings together advanced methods of modern, robust and
resilient control on one hand and applied system identiﬁcation methods on the
other hand. The starting point is a set of real experimental data of some indus-
trial processes. For generality in exposition, the main focus is on merits and demer-
its of different control and identiﬁcation methods. Through extensive simulation
studies, several conclusions will be drawn and useful design toolkit will be delin-
eated.

6
1
Introduction
1.5.1 Methodology
Throughout the textbook, our methodology is composed of ﬁve-steps:
• Mathematical Modeling in which we focus on the use of system identiﬁcation
techniques to generate transfer-function and/or state-space models based on real-
data and subsequently discuss the main ingredients of the derived models under
consideration.
• Deﬁnitions and/or Assumptions here we introduce the deﬁnitions and/or con-
straints on the model variables then proceed to methods of system analysis.
• Examples and Illustrations this represent the backbone of the book around which
the material of the different sections and subsections evolve. This material in-
cludes some solved examples based on MATLAB environment to demonstrate
the effectiveness of the various algorithms and techniques.
• Remarks which are given to shed some light of the relevance of the developed
results vis-a-vis published work. These also help in identifying pertinent features
and properties.
• Methods which are provided most of the time in the form of algorithms and/or
MATLAB procedures.
In the sequel, deﬁnitions (assumptions, remarks) are keyed to chapters and stated
in roman font with bold titles, for example, Deﬁnition 2.3 means Deﬁnition 3 in
Chap. 2 and so on. For convenience, we have added references and problems at the
end of each chapter. Relevant notes and issues are offered as well at the end of each
chapter for the purpose of stimulating the reader.
1.5.2 Chapter Organization
The material covered is divided into nine chapters whereby continuous-time results
go in parallel with discrete-time results. Every chapter includes the corresponding
MATLAB hints, ﬁle names along with some pertinent statements which illustrate
how the algorithms can be used in simulation, computation and implementation.
A problem section for practice of the design is included as well. All the developed
results are conveniently expressed in MATLAB-based procedures.
In Chap. 2, we start our guided tour through the book by presenting several
processes that are commonly used in industrial applications. These processes in-
clude:
1. Steam Generation Unit.
2. Small-Power Wind Turbine.
3. Unmanned Marine Vehicles.
4. Industrial Evaporation Unit.
5. Distillation Column.
6. Falling Film Evaporator.

1.5
Outline of the Book
7
7. Vapor Compression Cycle Systems.
8. Flutter of an Aircraft F-18.
9. A Hydraulic Pumping System.
The purpose is to provide a wide pool of information about practical systems and to
acquaint the reader with the properties of the processes.
The objective of Chap. 3 is to establish a solid foundation of system identiﬁcation
methods that will be used and experimented in the subsequent chapters. The material
covered is subdivided as follows:
1. Parameter estimation approach: with focus on estimation algorithms, gradient
algorithm, least squares algorithm, choice of the adaptation gain.
2. Transfer-function methods: these include autoregressive (AR) method, ARX
method, autoregressive moving average (ARMAX) method, Box–Jenkins method,
prediction error method (PEM).
3. Subspace identiﬁcation method: attention is paid to state space models, block
Hankel matrices and state sequences, model matrices, geometric tools, or-
thogonal and oblique projections. Deterministic, stochastic and combined
deterministic-stochastic subspace identiﬁcation schemes are presented.
Chapter 4 contains detailed computer experiments and MATLAB simulation re-
sults of applying the identiﬁcation methods of Chap. 3 to the industrial processes of
Chap. 2. Focus is placed on data analysis, validation and model ﬁtness. State-space
order determinations and comparison of MIMO models are prime factors. In addi-
tion, conclusions drawn from comparisons among these methods are delineated.
The core techniques in the design of linear control methods are described in
Chap. 5. In preparation, some basic deﬁnitions and features of feedback control sys-
tems (open-loop versus closed-loop control systems, standard representations)are
introduced. Next, the main structural properties of stability, controllability and
observability are established. Feedback control methods (state-feedback, output-
feedback, observer-based feedback) are developed and applied to several practical
systems. We then provides classiﬁcations of industrial controllers and emphasize on
the control actions (P-control, I-control, PI-control, PD control and PID control).
Discussions are given to closed-loop system subjected to a disturbance. Methods of
linear optimal control (continuous-time and discrete-time), model predictive con-
trol, the Kalman ﬁlter and linear quadratic Gaussian regulator design are analysis in
detailed and demonstrated on typical systems examples.
Applications of the linear control design methods are detailed in Chap. 6 and
implemented on:
1. Shaping Process of Automobile Belt.
2. An Unmanned Helicopter.
3. Reverse Osmosis Desalination Plant.
4. Turbocharged Diesel Engine.
5. A Rotational Hydraulic Drive.
6. The Falling Film Evaporator.
7. Vapor Compression Cycle Systems.

8
1
Introduction
8. Control of Quadrotor Unmanned Air Vehicle.
9. Stabilization of F-8 Fly-by-Wire Aircraft.
10. Air Conditioning System.
11. Three-Degree-of-Freedom Helicopter Model.
12. Design of Aircraft Controller.
Chapter 7 introduces an introductory material to advanced control design meth-
ods including H2, H∞and mixed H2/H∞performance criteria. It paves the way
by deﬁning norm measures of signals and systems to construct the problems un-
der consideration. In addition, it discusses integral control for robust tracking. Both
optimal and stabilizing solutions are given along with some examples.
Adaptive methods in the form of control design algorithms are illustrated in
Chap. 8.
Throughout the book, MATLAB implementation and simulation results are em-
phasized. Each chapter includes some selected solved examples and/or case studies
and is supplemented by relevant questions and problems. An Appendix containing
some relevant mathematical tools and basic results is provided as Chap. 9.
References
1. Abdelazim, T., Malik, O.: Identiﬁcation of nonlinear systems by Takagi-Sugeno fuzzy logic
grey box modeling for real-time control. Control Eng. Pract. 13(12), 1489–1498 (2005)
2. Aguirre, L.A.: A nonlinear correlation function for selecting the delay time in dynamical re-
constructions. Phys. Lett. 203A(2–3, 88–94 (1995)
3. Aguirre, L.A., Donoso-Garcia, P.F., Santos-Filho, R.: Use of a priori information in the iden-
tiﬁcation of global nonlinear models—A case study using a buck converter. IEEE Trans. Cir-
cuits Syst. I, Regul. Pap. 47(7), 1081–1085 (2000)
4. Aguirre, L.A., Barroso, M.F.S., Saldanha, R.R., Mendes, E.M.A.M.: Imposing steady-state
performance on identiﬁed nonlinear polynomial models by means of constrained parameter
estimation. IEE Proc. Part D. Control Theory Appl. 151(2), 174–179 (2004)
5. Aguirre, L.A., Coelho, M.C.S., Corrêa, M.V.: On the interpretation and practice of dynamical
differences between Hammerstein and Wiener models. IEE Proc. Part D. Control Theory Appl.
152(4), 349–356 (2005)
6. Astrom, K.J., Eykhoff, P.: System identiﬁcation—A survey. Automatica 7(2), 123–162 (1971)
7. Baker, J.E.: Reducing bias and inefﬁciency in the selection algorithm. In: Proc. 2nd Int. Conf.
Genetic Algorithms Genetic Algorithms Their Appl., Mahwah, N.J., pp. 14–21 (1987)
8. Bakker, H.H.C., Marsh, C., Paramalingam, S., Chen, H.: Cascade controller design for con-
centration in a falling ﬁlm evaporators. Food Control 17(5), 325–330 (2006)
9. Barbosa, B.H.: Instrumentation, modelling, control and supervision of a hydraulic pumping
system and turbine–generator module (in Portuguese). Master’s thesis, Sch. Elect. Eng., Fed-
eral Univ. Minas Gerais, Belo Horizonte, Brazil (2006)
10. Barroso, M.S.F., Takahashi, R.H.C., Aguirre, L.A.: Multi-objective parameter estimation via
minimal correlation criterion. J. Process Control 17(4), 321–332 (2007)
11. Billings, S.A., Voon, W.S.F.: Least squares parameter estimation algorithms for nonlinear sys-
tems. Int. J. Syst. Sci. 15(6), 601–615 (1984)
12. Billings, S.A., Chen, S., Korenberg, M.J.: Identiﬁcation of MIMO nonlinear systems using a
forward-regression orthogonal estimator. Int. J. Control 49(6), 2157–2189 (1989)
13. Bingulac, S., Sinha, N.K.: On the identiﬁcation of continuous-time systems from the samples
of input–output data. In: Proc. Seventh Int. Conf. on Mathematical and Computer Modeling,
Chicago, IL, pp. 231–239 (1989)

References
9
14. Bucharles, A., Cassan, H., Roubertier, J.: Advanced parameter identiﬁcation techniques for
near real = time ﬂight ﬂutter test analysis. AIAA, Paper 90-1275, May 1990
15. Burl, J.B.: Linear Optimal Control, 3rd edn. Prentice Hall, New York (1998)
16. Chankong, V., Haimes, Y.Y.: Multiobjective Decision Making: Theory and Methodology.
North-Holland (Elsevier), New York (1983)
17. Chen, S., Billings, S.A., Luo, W.: Orthogonal least squares methods and their application to
nonlinear system identiﬁcation. Int. J. Control 50(5), 1873–1896 (1989)
18. Connally, P., Li, K., Irwing, G.W.: Prediction and simulation error based perceptron training:
Solution space analysis and a novel combined training scheme. Neurocomputing 70, 819–827
(2007)
19. Cooper, J.: Parameter estimation methods for the ﬂight ﬂutter testing. In: Proc. the 80th
AGARD Structures and Materials Panel, CP-566, AGARD, Rotterdam, The Netherlands,
1995
20. Correa, M.V., Aguirre, L.A., Saldanha, R.R.: Using steady-state prior knowledge to constrain
parameter estimates in nonlinear system identiﬁcation. IEEE Trans. Circuits Syst. I, Regul.
Pap. 49(9), 1376–1381 (2002)
21. Cunningham, P., Canty, N., O’Mahony, T., O’Connor, B., O’Callagham, D.: System identiﬁ-
cation of a falling ﬁlm evaporator in the dairy industry. In: Proc. of SYSID’94, Copenhagen,
Denmark, vol. 1, 234–239 (1994)
22. Ghiaus, C., Chicinas, A., Inard, C.: Grey-box identiﬁcation of air-handling unit elements.
Control Eng. Pract. 15(4), 421–433 (2007)
23. Goldberg, D.E.: Genetic Algorithms in Search, Optimization and Machine Learning. Addison-
Wesley, New York (1989)
24. Hsia, T.C.: On sampled-data approach to parameter identiﬁcation of continuous-time linear
systems. IEEE Trans. Autom. Control AC-17, 247–249 (1972)
25. Hsia, T.: System Identiﬁcation: Least-Squares Methods. Lexington Books, Lexington (1977)
26. Jakubek, S., Hametner, C., Keuth, N.: Total least squares in fuzzy system identiﬁcation: An
application to an industrial engine. Eng. Appl. Artif. Intell. 21, 1277–1288 (2008)
27. Karimi, M., Jahanmiri, A.: Nonlinear modeling and cascade control design for multieffect
falling ﬁlm evaporator. Iran. J. Chem. Eng. 3(2) (2006)
28. Kehoe, M.W.: A historical overview of ﬂight ﬂutter testing, NASA TR 4720, Oct. 1995
29. Leontaritis, I.J., Billings, S.A.: Input–output parametric models for nonlinear systems. Part II:
Deterministic nonlinear system. Int. J. Control 41(2), 329–344 (1985)
30. Miranda, V., Simpson, R.: Modelling and simulation of an industrial multiple-effect evapora-
tor: Tomato concentrate. J. Food Eng. 66, 203–210 (2005)
31. Neilsen, K.M., Pedersen, T.S., Nielsen, J.F.D.: Simulation and control of multieffect evapora-
tor
32. Nepomuceno, E.G., Takahashi, R.H.C., Aguirre, L.A.: Multiobjective parameter estimation:
Afﬁne information and least-squares formulation. Int. J. Control 80(6), 863–871 (2007)
33. Norgaard, M.: Neural network based system identiﬁcation—TOOLBOX, Tech. Univ. Den-
mark, Lyngby, Tech. Rep. 97-E-851 (1997)
34. Ogata, K.: MATLAB for Control Engineers. Prentice-Hall, New York (2008)
35. Pan, Y., Lee, J.H.: Modiﬁed subspace identiﬁcation for long-range prediction model for infer-
ential control. Control Eng. Pract. 16(12), 1487–1500 (2008)
36. Piroddi, L.: Simulation error minimization methods for NARX model identiﬁcation. Int. J.
Model. Identif. Control 3(4), 392–403 (2008)
37. Piroddi, L., Spinelli, W.: An identiﬁcation algorithm for polynomial NARX-models based on
simulation error minimization. Int. J. Control 76(17), 1767–1781 (2003)
38. Quaak, P., van Wijck, M.P.C.M., van Haren, J.J.: Comparison of process identiﬁcation and
physical modeling for falling ﬁlm evaporators. Food Control 5(2), 73–82 (1994)
39. Rangaiah, G., Saha, P., Tade, M.: Nonlinear model predictive control of an industrial four-
stage evaporator system via simulation. Chem. Eng. J. 87, 285–299 (2002)
40. Roffel, B., Betlem, B.: Process Dynamics and Control. Wiley, London (2006)
41. Sinha, N.K.: Estimation of transfer function of continuous-time systems from samples of
input–output data. Proc. Inst. Electr. Eng. 119, 612–614 (1972)

10
1
Introduction
42. Sinha, N.K., Kuszta, B.: Modelling and Identiﬁcation of Dynamic Systems. Von-Nostrand
Reinhold, New York (1983)
43. Sinha, N.K., Rao, G.P. (eds.): Identiﬁcation of Continuous-Time Systems. Kluwer Academic,
Dordrecht (1991)
44. Sjoberg, J., Zhang, Q., Ljung, L., Beneviste, A., Delyon, B., Glorennec, P., Hjalmarsson, H.,
Juditsky, A.: Non-linear black-box modeling in system identiﬁcation: A uniﬁed overview.
Automatica 31, 31–1961 (1995)
45. Soderstrom, T., Stoica, P.: System Identiﬁcation. Prentice-Hall, New York (1989)
46. Stefanov, Z., Hoo, K.A.: Control of a multiple-effect falling-ﬁlm evaporator plant. Ind. Eng.
Chem. Res. 44, 3146–3158 (2005)
47. Van Wijck, M.P., Quaak, P., van Haren, J.J.: Multivariable supervisory control of a four-effect
falling ﬁlm evaporator. Food Control 5(2), 234–243 (1994)
48. Zwillinger, D.: Standard Mathematical Tables and Formulae, 31st edn. Chapman & Hall/CRC,
Boca Raton (2002)

Chapter 2
Some Industrial Systems
2.1 Introduction
Identiﬁcation of process parameters for control purposes must often be done using
a digital computer, from samples of input–output observations. On the other hand,
the process is usually of continuous-time nature, and its dynamical model is most
aptly described in terms of differential equations. Thus, our problem may be stated
as determining a continuous-time model from samples of input–output data.
During the past few decades, several approaches have been developed [30, 46–
48]. For the sake of simplicity, these can be classiﬁed as
• direct methods,
• indirect methods.
Methods belonging to the ﬁrst type attempt to estimate the parameters of a
continuous-time model directly from the samples of the observations, mostly us-
ing some type of numerical integration. In methods of the latter group, the problem
is conveniently divided into two subproblems:
The ﬁrst subproblem consists of estimating the parameters of a discrete-time
model from the samples of the input–output observations.
The second subproblem, on the other hand, consists of determining a suitable
continuous-time model that is equivalent to the discrete-time model obtained for a
given sampling interval.
Generally speaking, the problem of system identiﬁcation may now be stated as
the estimation of the elements of the matrices A, B, C, D associated with the linear
time-invariant system
˙x(t) = Ax(t) + Bu(t),
y(t) = Cx(t) + Du(t)
(2.1)
from a record of the samples of the input output data

u(kT ),y(kT )

,
for k = 0;1;2;...;N
where N is a suitable large number.
M.S. Mahmoud, Y. Xia, Applied Control Systems Design,
DOI 10.1007/978-1-4471-2879-3_2, © Springer-Verlag London Limited 2012
11

12
2
Some Industrial Systems
It may be noted that the matrix D represents direct coupling between the in-
put and the output, and will be zero for strictly proper transfer functions. Without
any loss of generality and unless otherwise stated, this will be assumed to be the
case throughout this book. It should be noted that none of the matrices A, B, C in
(2.1) are unique for a system with a given input–output description. Given a spe-
cial canonical form for the system state equations in either the continuous-time or
the equivalent discrete time models overcomes this problem and also minimizes the
number of parameters to be estimated. It should also be noted that it is tacitly as-
sumed that the order of the linear state space model is known, and that the sampling
interval has been suitably selected. In practice, both of these are important, and have
been subjects of considerable research [24, 25, 48].
In fact, the problem is further complicated by the fact that the available data are
usually contaminated with random noise that are produced either by disturbances or
introduced in data acquisition and measurement. The literature on system identiﬁ-
cation abounds in papers devoted to methods for estimating the parameters in the
presence of noise, see [47] for a detailed list of references.
2.2 Steam Generation Unit
There are two types of conﬁgurations in the electricity generation using drum boilers
and steam turbines:
1. A single boiler is used to generate steam that is directly fed to a single turbine.
This conﬁguration is usually referred to as a boiler–turbine unit.
2. A header is used to accommodate all the steam produced from several boilers,
and the steam is then distributed to several turbines through the header. The steam
can be used to generate electricity as well as other purposes. This conﬁguration
is commonly used in industrial utility plants.
Boiler–turbine units are nowadays preferred over header systems, because they can
achieve quick response to electricity demands from a power grid or network. It
is generally accepted that a boiler–turbine unit is a highly nonlinear and strongly
coupled complex system. However, there is no deﬁnite quantiﬁcation of the com-
plexity of a unit. Speciﬁcally, how nonlinear is it? Can a linear controller be used to
cover the whole operating range? These are fundamental issues in the control system
design for a boiler–turbine unit. Without a thorough understanding, modeling and
identiﬁcation of the system, the operating range and performance of a linear con-
troller cannot be guaranteed. Figure 2.1 shows the schematic diagram of the steam
generator model.
2.2.1 System Dynamics
For the system considered here, the input/output experimental data has been ob-
tained from [20] in which the modeling of a steam generator at Abbot power plant

2.2
Steam Generation Unit
13
Fig. 2.1 Steam generating unit
in Champaign IL is considered. The data comes from a model of this steam genera-
tor. The inputs are listed as follows:
• U1: Fuel scaled 0–1,
• U2: Air scaled 0–1,
• U3: Reference level,
• U4: Disturbance deﬁned by the load level.
The outputs are
• Y1: Drum pressure,
• Y2: Excess oxygen in exhaust gases,
• Y3: Level of oxygen in the drum,
• Y4: Steam ﬂow.
The data values are presented in Fig. 2.2.
The simulation data constitutes 9600 samples at a sampling rate of 3 s, which
characterizes a MIMO process. In implementation, a set of 4000 samples (5000 :
9000) are used for testing, another set of 4000 samples (2500 : 6500) for validation
purpose. The important statistical parameters of all inputs and outputs are listed in
Table 2.1.

14
2
Some Industrial Systems
Fig. 2.2 Statistical data pattern
Table 2.1 Statistical data
Input/output
Type
Mean
Standard deviation
Min
Max
I1
Fuel scaled 0–1
0.504
0.229
0.000
1.07
I2
Air scaled 0–1
0.528
0.295
0.000
1.07
I3
Reference level
0.554
2.460
−4.00
4.53
I4
Disturbance
0.004
0.010
−0.015
0.023
O1
Drum pressure
329.4
85.94
154
534
O2
Excess oxygen in air
4.544
6.157
−0.069
21
O3
Drum oxygen level
0.552
2.849
−9.55
12.3
O4
Steam ﬂow
14.85
7.571
1.99
34.6

2.3
Small-Power Wind Turbine
15
2.3 Small-Power Wind Turbine
Wind energy is a fast-growing interdisciplinary ﬁeld that encompasses many dif-
ferent branches of engineering and science. Despite the amazing growth in the in-
stalled capacity of wind turbines in recent years, engineering and science challenges
still exist. Because larger wind turbines have power capture and economical advan-
tages, the typical size of utility-scale wind turbines has grown dramatically over the
last three decades. Modern wind turbines are large, ﬂexible structures operating in
uncertain environments and lend themselves nicely to advanced control solutions.
Advanced controllers can help achieve the overall goal of decreasing the cost of
wind energy by increasing the efﬁciency, and thus the energy capture, or by reduc-
ing structural loading and increasing the lifetimes of the components and turbine
structures. In what follows, our goal is to introduce control engineers to the techni-
cal challenges that exist in the wind energy industry and to encourage new control
systems research in this area.
2.3.1 Wind Turbine Basics
The main components of a horizontal-axis wind turbine that are visible from the
ground are its tower, nacelle, and rotor. The nacelle houses the generator, which
is driven by the high-speed shaft. The high speed shaft is in turn usually driven
by a gear box, which steps up the rotational speed from the low-speed shaft. The
low-speed shaft is connected to the rotor, which includes the airfoil-shaped blades.
These blades capture the kinetic energy in the wind and transforms it into the rota-
tional kinetic energy of the wind turbine. The description of the wind turbine system
depends on the designs of the wind turbine either horizontal-axis or vertical axis, see
Fig. 2.3.
Vertical-axis wind turbines (VAWTs) are pretty rare and the only one currently in
commercial production is the Darrieus turbine, which looks kind of like an egg ﬁg-
ure. In a VAWT, the shaft is mounted on a vertical axis, perpendicular to the ground.
VAWTs are always aligned with the wind, unlike their horizontal-axis counterparts,
so there’s no adjustment necessary when the wind direction changes. On the other
hand, a VAWT is not normally self starting, it needs energy from its electrical sys-
tem to get started. Instead of a tower, it typically uses wires for support, so the rotor
elevation is lower. Lower elevation means slower wind due to ground interference,
so VAWTs are generally less efﬁcient than horizontal-axis wind turbines (HAWTs).
On the upside, all equipment is at ground level for easy installation and servicing,
but that means a larger footprint for the turbine, which is a big negative in farming
areas. VAWTs may be used for small-scale turbines and for pumping water in rural
areas, but all commercially produced, utility-scale wind turbines are (HAWTs), see
Figs. 2.4–2.5.
From its name, the HAWT shaft is mounted horizontally, parallel to the ground.
HAWT needs to continuously align itself with the wind speed by using a yaw-
adjustment mechanism. The yaw system typically consists of electric motors and

16
2
Some Industrial Systems
Fig. 2.3 VAWT and HAWT
Fig. 2.4 The main
components of HAWT
gearboxes which move the whole rotor left or right in small increments to hold the
higher speed. The turbine’s electronic controller reads the position of a wind vane
device either mechanical or electronic and adjusts the position of the rotor to cap-
ture the most wind energy available [26]. HAWTs use a tower to lift the turbine
components to an optimum elevation for wind speed and so the blades can take up
very little ground space since wind velocities increase at higher altitudes due to sur-
face aerodynamic drag and the viscosity of the air. Horizontal-axis wind turbines
have the main rotor shaft and electrical generator at the top of a tower and must be
pointed into the wind. Small turbines are pointed by a simple wind vane, while large
turbines generally use a wind sensor coupled with a servo motor. Most of HAWTs
have a gearbox which turns the slow rotation of the blades into a quicker rotation
that is more appropriate to drive an electrical generator. The main components of

2.4
Unmanned Surface Marine Vehicle
17
Fig. 2.5 Parts inside the
wind turbine
HAWTs are Rotor blades which capture wind’s energy and convert it to rotational
energy of low speed shaft and Shaft that transfers rotational energy into generator.
Also, Nacelle casing that holds Gearbox which increases speed of shaft between
rotor hub and generator, Generator that uses rotational energy of shaft to generate
electricity using electromagnetism and usually an induction generator that produces
AC electricity is used. Moreover, Electronic control unit that monitors system and
starts up the machine at wind speeds of about 3–8 m/s and shuts down the machine
at about 20 m/s which turbines do not operate at wind speeds above about 20 m/s
because they might be damaged by the high winds, Yaw controller is used to keep
the rotor facing into the wind as the wind direction changes, and Brakes that stop
rotation of shaft in case of power overload or system failure.
In addition to these components, the tower that used to support rotor and nacelle
and lifts entire setup to higher elevation where blades can safely clear the ground
and towers are made from tubular steel, concrete, or steel lattice. Wind speed in-
creases with height and this mean, taller tower enable turbines to capture more en-
ergy and generate more electricity. The electrical equipment that is used to transmit
electricity from generator down through tower and controls many safety elements
of turbine, and anemometer that measures the wind speed and transmits these read-
ings to the controller. The most commonly activated safety system in a turbine is the
braking system, which is triggered by above-threshold wind speeds. These setups
use a power-control system that essentially hits the brakes when wind speeds get
too high and then release the brakes when the wind is coming back.
2.4 Unmanned Surface Marine Vehicle
The Atlantis is assumed to be traveling upon a straight line, conveniently assumed
to be coincident with the x-axis, through water at a constant velocity, Vx. The dis-

18
2
Some Industrial Systems
Fig. 2.6 A schematic model
of the assumed path of the
Atlantis
tance along that line is X (meters), the perpendicular distance to the line is Y (me-
ters), the cross-track error, and the angle that the center-line of the Atlantis makes
with the x-axis is Ψ , the angular error (radians). Figure 2.6 illustrates a schematic
model of the assumed path of the Atlantis. The coordinate frame can always be
rotated to have the x-axis aligned to the desired path of the Atlantis, and so the
assumption that the Atlantis travels down the x-axis is a good one. The assump-
tion of constant velocity, however, is not appropriate since velocity is a function
of the wind speed. Wind speed, of course, cannot be controlled and is highly vari-
able.
2.4.1 Dynamic Model
The continuous-time state-space equations for the kinematic model can be repre-
sented as
⎡
⎣
˙Y
˙Ψ
˙δ
⎤
⎦=
⎡
⎣
0
Vx
0
0
0
Vx
L
0
0
0
⎤
⎦
⎡
⎣
Y
Ψ
δ
⎤
⎦+
⎡
⎣
0
0
1
⎤
⎦u
(2.2)
where δ is the angle of the rudders with respect to the hull center-line (radians). The
distance L is from the boat center of mass to the center of pressure of the rudders
(in meters), and the input, u, is the slew rate of the rudders (in radians/second). This
kinematic model assumes that the boat is running on constant Vx. This assumption
is known to be poor, since unless the wind can be controlled, the velocity will always
be dependent on the speed of the wind. Azimuth and cross-track error in fact do not
integrate with time, but rather with distance traveled upon the line. This has great
implications, since this is exactly the cause of instability with increasing velocity
present in the simple kinematic model. By introducing two new variable,
˜Y ≡Y
Vx
,
˜Ψ ≡Ψ
Vx
.
(2.3)

2.5
Industrial Evaporation Unit
19
Substituting (2.3) back into (2.2), the kinematic model can be rewritten in the fol-
lowing velocity-invariant form:
⎡
⎢⎣
˙˜Y
˙˜Ψ
˙δ
⎤
⎥⎦=
⎡
⎣
0
1
0
0
0
1
L
0
0
0
⎤
⎦
⎡
⎣
˜Y
˜Ψ
δ
⎤
⎦+
⎡
⎣
0
0
1
⎤
⎦u.
(2.4)
2.5 Industrial Evaporation Unit
An identiﬁcation experiment is performed by exciting the system with appropriate
signals and observing its input and output over a time interval. These signals are
normally recorded in a computer mass storage for subsequent information process-
ing. Then one proceeds to ﬁt a parametric model of the process from the recorded
input and output sequences. The ﬁrst step is to determine an appropriate form of
the model (typically a linear difference equation of a certain order). As a second
step some statistically based method is used to estimate the unknown parameters
of the model (such as the coefﬁcients in the difference equation). In practice, the
estimations of structure and parameters are often done iteratively. This means that
a tentative structure is chosen and the corresponding parameters are estimated. The
model obtained is then tested to see whether it is an appropriate representation of the
system. If this is not the case, some more complex model structure must be consid-
ered, its parameters estimated, the new model validated, etc. Note that the ‘restart’
after the model validation gives an iterative scheme.
2.5.1 Mathematical Models
Models and/or systems can be roughly divided into classes such as linear and non-
linear time invariant or time varying discrete time or continuous time with lumped
or with distributed parameters etc. While at ﬁrst sight the class of linear time in-
variant models with lumped parameters seems to be rather restricted it turns out in
practice that many real life input output behaviors of practical industrial processes
can be approximated very well by such a model.
Mathematical models of dynamical systems are used for analysis simulation pre-
diction optimization monitoring fault detection training and control. There are sev-
eral approaches to generate a model of a system. One could for instance start from
ﬁrst principles such as writing down the basic physical or chemical laws that gener-
ate the behavior of the system. This so called white box approach works for simple
examples but its complexity increases rapidly for real world systems. In some cases
the systems equations are known up to within some unknown parameters, which are
estimated using some parameter estimation method gray-box modeling.
Another approach is provided by system identiﬁcation in which ﬁrst measure-
ments or observations are collected from the system which are then modeled using

20
2
Some Industrial Systems
a so-called black-box identiﬁcation approach. Such an approach basically consists
of ﬁrst deﬁning a parameterization of the model, and then determining the model
parameters in such a way that the measurements are explained as accurately as pos-
sible by the model. Typically, this is done by formulating the identiﬁcation problem
as an optimization problem in which the variables are the unknown parameters of
the model the constraints are the model equations and the objective function a mea-
sure of the deviation between the observations and the predictions or simulations
obtained from the model.
The ﬁeld of linear system identiﬁcation is certainly not new although we can
safely say that it only started to blossom in the 1970s. Yet, 20-years of research
have generated a lot of results and practical hands on experience. Among the key
references of identiﬁcation are [6, 20, 31, 49].
In what follows, we use data for industrial evaporator from [27].
2.5.2 Multistage Evaporator System
The selected evaporator system is the ﬁrst step in the liquor burning process as-
sociated with the Bayer process for alumina production at the Wager up alumina
reﬁnery in western Australia. It consists of one falling ﬁlm, three forced-circulation
and a super-concentration evaporators in series [44].
The main components of each stage are a ﬂash tank (FT), a ﬂash pot and a
heater (HT). A simpliﬁed schematic of the evaporator system is depicted in Fig. 2.7.
Flash pots are not shown in this ﬁgure for simplicity of the schematic. Spent liquor,
which is recovered after precipitation of the alumina from its solution, is fed to the
Fig. 2.7 A simpliﬁed schematic of the evaporator system

2.6
Distillation Tower
21
falling ﬁlm stage (FT #1). The volatile component, water in this case, is removed
under high recycle rate and the product is further concentrated through the three
forced-circulation stages (FT #2–4). The super-concentration stage (FT #5) is used
to remove the residual ‘ﬂashing’ of the concentrated liquor without recycle. In each
of the forced-circulation and super-concentration stages, the spent liquor is heated
through a shell and tube heat exchanger (heater) and water is removed as vapor at
lower pressure in the FT. The vapor given off is used as the heating medium in the
heaters upstream. The ﬂashed vapor from FT #3 and 4 are combined and used in HT
#2 while the vapor from FT #2 is used in HT #1. The ﬂashed vapor from FT #5 is
sent directly to the condenser, C in Fig. 2.6. The steam condensates from the heaters
are collected in the ﬂash pots. Live steam is used as the heating medium for HT #3,
4 and 5. Live steam to HT #3 is set in ratio to the amount of live steam entering
HT #4, while the amount of live steam to HT #5 is set depending on the amount of
residual ‘ﬂashing’ to be removed. The cooling water ﬂow to the contact condenser,
C is set such that all remaining ﬂashed vapor is condensed. The evaporator system
is crucial in the aluminum reﬁnery operation and is difﬁcult to control due to recycle
streams, strong process interactions and nonlinearities.
2.6 Distillation Tower
Distillation towers are widely used in the chemical process industries where large
quantities of liquids have to be distilled. Industrial distillation towers are usually
operated at a continuous steady state. From a practical viewpoint, the most important
manipulated variables are the bottom supply energy, the top energy removal, the
reﬂux ratio, which inﬂuence the tower operating pressure, the tray load and degree
of separation. Concerning the system outputs, a distinction must be made between
the controlled and the uncontrolled variables. If the underlying task is to produce a
required product quality, then the top and bottom qualities are the most important
controlled variables. At a tray only the temperature can be continuously measured
and this yields a good indication of the condition of the tower.
There are several assumptions that are commonly made in order not to complicate
matters unnecessarily. These assumptions include that the vapor mass at a tray is
negligible compared to the liquid mass and the energy content of the vapor mass at
a tray is neglected.
2.6.1 A Particular Tower
In this section, we focus our study on a class of distillation towers commonly used in
natural gas plants, an example of which is in Aramco-Saudi Arabia. It must be noted
for this class that unless disturbed by changes in feed, heat, ambient temperature, or
condensing, the amount of feed being added normally equals the amount of product
being removed. A typical physical layout of distillation tower (DT) is portrayed in
Fig. 2.8.

22
2
Some Industrial Systems
Fig. 2.8 Distillation unit
For simplicity in exposition, the identiﬁcation studies carried out in the subse-
quent chapter are based on one input and one output data set each of 10080 samples
with a sampling period of 60 s:
• Input: Feed inlet temperature in F°.
• Output: Tower outlet compound of C2 in mol %.
2.7 Falling Film Evaporator
The most common used evaporator in the dairy industry is the falling ﬁlm evapo-
rator, for the concentration of products like milk, skimmed milk and whey. A four
stage evaporator is used to reduce the water content of the product, that is, milk. The
data was taken from [21]. The identiﬁcation scheme used for the data is the N4SID
subspace based identiﬁcation. The data consists of 6305 samples with three inputs,
feed ﬂow, vapor ﬂow to the ﬁrst evaporator stage and cooling water ﬂow and three
outputs, dry matter content, the ﬂow and the temperature of the out coming product.
The solution containing the desired product is fed to the evaporator and passes a
heat source. The applied heat converts the water in the solution to vapor. The vapor
is removed from the rest of the solution and is condensed while the now concen-
trated solution is either fed into the second evaporator is removed. The evaporator
generally as a machine consists of four sections. The heating section consists of the
heating medium. Steam is fed into this section. The concentrating and separating
section removes the vapor being produced from the solution. The condenser con-
densates the separated vapor, then the vacuum or pump provides pressure to increase
the circulation.
Evaporation is used basically in the dairy industry for the concentration of prod-
ucts like milk, skimmed milk etc. Concentration involves the removal of water from

2.7
Falling Film Evaporator
23
the product. To minimize the cost, evaporation is usually performed in multiple ef-
fect evaporators where two or more effects operate at progressively lower boiling
points. In this type of arrangement, the vapor produced in the previous effect can
be used as the heating medium in the next. The evaporator considered here is a four
falling ﬁlm effects and has a water evaporation capacity of 800 kg/h. The evapora-
tors most commonly are used in the split effect mode, where only the third effect
and the ﬁnishing effect are used.
2.7.1 A Single Effect Evaporator
In what follows, for simplicity, we will consider a single effect falling ﬁlm evapora-
tor to outline the operating principles.
A single effect evaporator consists of a balance tank, a condenser, a preheater, an
evaporator calandria, a separator and a vacuum pump, see Fig. 2.9. The process can
Fig. 2.9 Schematic diagram of evaporator in split effect

24
2
Some Industrial Systems
Fig. 2.10 Block diagram of
single effect falling ﬁlm
evaporator
be decomposed into a product route (steps Pa–Pf), a steam route (steps Sa–Sc) and
a product vapor route (steps Va–Vd). Firstly, we will consider the path the product
takes through the evaporator, see Fig. 2.10.
Pa From the balance tank, the concentrate ﬂows through the condenser where it
gets its ﬁrst injection of heat—see (Vc) overleaf.
Pb The product then ﬂows through the preheater where it gets a second injection of
heat (see Sc).
Pc The product is then pasteurized via the Direct Steam Injection (DSI) pasteuriza-
tion unit and passes through the holding tubes.
Pd From the DSI, the product enters the evaporator calandria. A nozzle and
spreader plate form a distribution system at the top of the evaporator that en-
sures a uniform product distribution.
Pe Upon leaving the distribution plate, the product ﬂows through stainless steel
tubes. The product forms a thin ﬁlm on the inside of the tube while the outside
of the tube is surrounded by steam.
Pf The product from the tubes reaches the bottom of the calandria where it is col-
lected along with product from the separator (see Va).
Next, consider the steam’s path through the process, see Fig. 2.11.
Sa Typically, but not always, the steam enters the calandria at the bottom and sur-
rounds the tubes through which the product is ﬂowing.
Sb Heat is then transferred from the steam to the product. This transfer of heat
causes the water in the product to boil and produce vapor inside the tubes.

2.8
Vapor Compression Cycle Systems
25
Fig. 2.11 Four-effect falling ﬁlm evaporator
Sc Some steam from the calandria shell enters the preheater and is used as the
heating medium in the preheater (see Pb).
Finally, consider the route of the product vapor through the process.
Va The product vapor exits the bottom of the calandria and enters the separator
where product is removed from the vapor and returned to the product stream.
Vb The vapor then enters the condenser.
Vc In the condenser, the vapor acts as a heating medium for the product (see Pa).
Vd The vapor then passes the cold water pipes and condenses.
2.8 Vapor Compression Cycle Systems
In vapor compression cycle systems, it is desirable to effectively control the thermo-
dynamic cycle by controlling the thermodynamic states of the refrigerant. By con-
trolling the thermodynamic states with an inner loop, supervisory algorithms can
manage critical functions and objectives such as maintaining superheat and maxi-
mizing the coefﬁcient of performance.
The primary goal of any air-conditioning or refrigeration system is to move en-
ergy from one location to another. An idealized vapor compression cycle (VCC) sys-
tem, as shown in Fig. 2.12, is a thermodynamic system driven by the phase charac-
teristics of the refrigerant that is ﬂowing through it. Therefore, it is useful to describe
the system in terms of the state of its refrigerant, as shown on a pressure-enthalpy
(P –H) diagram, see Fig. 2.13.

26
2
Some Industrial Systems
Fig. 2.12 Schematic diagram
of VCC system
Fig. 2.13 P –H cycle
diagram
2.8.1 A Typical System
An ideal VCC system assumes isentropic compression, isenthalpic expansion, and
isobaric condensation and evaporation. The basic control objectives of a VCC sys-
tem can be conceptualized visually via Fig. 2.13. For example, the difference be-
tween and represents the increase in enthalpy across the evaporator, that is, the
amount of energy removed from the cooled space. This is a measure of evapora-
tor capacity. The difference between and represents the increase in enthalpy across
the compressor, that is, the amount of work done by the compressor to increase the
pressure of the refrigerant vapor. The system coefﬁcient of performance (COP), a
measure of system efﬁciency, is deﬁned as the ratio between these two changes in
enthalpy.
The focus of this study is to present a comprehensive controller design approach,
that is, one that covers displacement and velocity control, addresses the nonlineari-
ties present in the vapor compression system and considers practical issues such as
transient response and real-time implementation.

2.9
Flutter of an Aircraft F-18
27
Fig. 2.14 F-18 sensor
conﬁguration
2.9 Flutter of an Aircraft F-18
The Flutter is a self-feeding and potentially destructive vibration where aerody-
namic forces on an object couple with a structure’s natural mode of vibration to
produce rapid periodic motion [14]. Flutter can occur in any object within a strong
ﬂuid ﬂow, under the conditions that a positive feedback occurs between the struc-
ture’s natural vibration and the aerodynamic forces, see Fig. 2.14. That is, that the
vibration movement of the object increases an aerodynamic loads which in turn
drives the object to move further [17, 34]. If the energy during the period of aero-
dynamic excitation is larger than the natural damping of the system, the level of vi-
bration will increase, resulting in self-exciting oscillation. The vibration levels can
thus build up and are only limited when the aerodynamic or mechanical damping
of the object match the energy input, this often results in large amplitudes and can
lead to rapid failure. Because of this, structures exposed to aerodynamic forces—
including wings, aerofoil, but also chimneys and bridges—are designed carefully
within known parameters to avoid ﬂutter. It is however not always a destructive
force; recent progress has been made in small-scale wind generators for under
served communities in developing countries, designed speciﬁcally to take advan-
tage of this effect.
2.9.1 Flutter Input and Output Data
The data comprises of one input and one output which has a sampling time of 1 s,
the number of samples in the data are 1024, see Fig. 2.15. In this section, the date
in subdivided into the estimation and validation data parts, each part is comprised

28
2
Some Industrial Systems
Fig. 2.15 Flutter input and
output data
of 512 samples. As we shall see in later chapters, applications of the identiﬁcation
techniques are employed on the estimation data and then the estimated models are
evaluated on the validation data.
2.10 A Hydraulic Pumping System
It is often desirable to ﬁnd parsimonious models with good static and dynamical
responses [32]. The estimation of nonlinear models with such features is quite hard
mainly because static and dynamic information are not equally weighed in a single
set of data. In this respect, static and dynamic information can be thought of as be-
ing conﬂicting. Flexible black-box structures are able to accurately ﬁt a single piece
of data. However, there are two main drawbacks with most of such structures. First,
once such models are estimated, the static information (e.g., static nonlinearity) is
not readily available analytically. Second, not all such model structures and algo-
rithms have been adapted to permit the effective use of static information during
training (parameter estimation). It should be noticed that black-box identiﬁcation
does not necessarily guarantee correct steady-state performance when the model is
nonlinear [3].
When the data sets are conﬂicting in some way, it is advisable to use multi-
objective approaches which yield a set of optimal solutions called the Pareto set.
Bi-objective algorithms have proved to be quite useful in combining both static and
dynamic data during model identiﬁcation [10].
In what follows, we aim to identify models of a 15 kW hydraulic pumping sys-
tem. There has been a clear increase of variable frequency drives as the ﬁnal control
element for such systems. This has enabled the implementation of fast and automatic
control systems. Models of such systems are highly desirable for characterization
and control. Such models should, ideally, represent the system accurately both in
transient and steady-state regimes over a wide range of operating conditions. This
requires, more often than not, the use of nonlinear models.

2.10
A Hydraulic Pumping System
29
We focus in this book to obtain models that perform well both in transient
and steady-state regimes, different identiﬁcation approaches were implemented to
“guarantee” a good balance between such features. In order to improve the model
steady-state performance, the measured static curve of the pumping system was
used as auxiliary information. Such information was used in different intensities,
depending on the model representation used. An improved bi-objective identiﬁca-
tion approach is presented and a new decision-maker is deﬁned. In this brief, we
used and compared polynomial and neural nonlinear autoregressive with moving
average and exogenous variables (NARMAX) models.
2.10.1 Hydraulic Process and the Data
In a full-scale hydroelectric power plant (over 80% of Brazilian electrical energy
is produced in such plants), the water head can be considered constant over rea-
sonably long periods of time. At testing plants, however, the turbines are fed by
powerful hydraulic systems and not by a water head. Because of the characteristics
of the centrifugal pumps used in such plants, the pressure on the turbine decreases
as the water ﬂow increases. Therefore, in realistic testing plants, pressure must be
controlled over a wide range of operating conditions. Mathematical models are de-
sired to simulate and to design the closed-loop control of the real pumping system,
where the models output is the system pressure and the models input is the pumps
reference speed.
The hydraulic plant described in this section is composed by two centrifugal
pumps that feed a hydraulic turbine. The hydraulic plant should be seen by the
turbine as a water head. The static and dynamic data used in this brief were measured
from this plant, composed by two centrifugal pumps coupled to induction motors of
7.5 kW and variable speed drive systems (see Fig. 2.16). The pumps can be operated
alone, in parallel or in a series conﬁguration, always at the same speed. In this work,
the pumps were set in a parallel conﬁguration working at the same instantaneous
speed with a Francis turbine as load [9].
Fig. 2.16 Hydraulic
pumping system

30
2
Some Industrial Systems
Fig. 2.17 Static curve of the
hydraulic pumping system
and its approximation
The modeling data presented in this work were collected from a data acquisition
system. The piezo-resistive pressure transmitter error is ±0.175 mlc (meter of liquid
column).
2.10.2 Static Behavior
The static curve of the system was measured by:
1. Setting the turbine distributor blade to 50% and
2. Maintaining the pumps speed ﬁxed at the chosen values—the speed references
of both pumps were maintained the same during this procedure. After transients
died out, the output pressure was recorded for each reference speed.
During this test, the pumps speed was varied from 750 to 1650 r/min. The static
curve is shown in Fig. 2.17 as well as the second-order polynomial approxima-
tion
H(¯u) = β ¯u2 + α ¯u + κ
(2.5)
with β = 7.2652 × 10−6, α = 1.4933 × 10−3, κ = −1.3312, and where is the pres-
sure in the output pipe and is the steady-state pump speed. This static curve will be
useful during the gray-box modeling and will also be used to evaluate the identiﬁed
models.
In Chap. 4, we will perform identiﬁcation methods to generate appropriate mod-
els.
2.11 Notes and References
In this introductory chapter, some representative system applications were presented
to help in motivating the readers to the upcoming topics. It must be emphasized that
the target goal is to launch an information-based approach to control system design.

References
31
Being an applied design approach, we start by examining some industrial systems
and shed light into their input/output variables. Indeed, there are many similar sys-
tems in practice and hence we encourage the readers to look at these systems and
apply the methods of this book. We will make every effort to produce the subsequent
chapters as a self-contained examination of the background and methods of indus-
trial dynamical systems. For a good introduction to the subject matter, the reader is
referred to [1, 2, 4, 5, 7, 8, 11–13, 15–19, 22, 23, 28, 29, 33–41]. For a MATLAB
tool box, it is advisable to consult [40, 42, 43].
References
1. Abdelazim, T., Malik, O.: Identiﬁcation of nonlinear systems by Takagi–Sugeno fuzzy logic
grey box modeling for real-time control. Control Eng. Pract. 13(12), 1489–1498 (2005)
2. Aguirre, L.A.: A nonlinear correlation function for selecting the delay time in dynamical re-
constructions. Phys. Lett. 203A(2–3), 88–94 (1995)
3. Aguirre, L.A., Donoso-Garcia, P.F., Santos-Filho, R.: Use of a priori information in the iden-
tiﬁcation of global nonlinear models—A case study using a buck converter. IEEE Trans. Cir-
cuits Syst. I, Regul. Pap. 47(7), 1081–1085 (2000)
4. Aguirre, L.A., Barroso, M.F.S., Saldanha, R.R., Mendes, E.M.A.M.: Imposing steady-state
performance on identiﬁed nonlinear polynomial models by means of constrained parameter
estimation. IEE Proc. Part D. Control Theory Appl. 151(2), 174–179 (2004)
5. Aguirre, L.A., Coelho, M.C.S., Corrêa, M.V.: On the interpretation and practice of dynamical
differences between Hammerstein and Wiener models. IEE Proc. Part D. Control Theory Appl.
152(4), 349–356 (2005)
6. Astrom, K.J., Eykhoff, P.: System identiﬁcation—A survey. Automatica 7(2), 123–162 (1971)
7. Baker, J.E.: Reducing bias and inefﬁciency in the selection algorithm. In: Proc. 2nd Int. Conf.
Genetic Algorithms Genetic Algorithms Their Appl., Mahwah, N.J., pp. 14–21 (1987)
8. Bakker, H.H.C., Marsh, C., Paramalingam, S., Chen, H.: Cascade controller design for con-
centration in a falling ﬁlm evaporators. Food Control 17(5), 325–330 (2006)
9. Barbosa, B.H.: Instrumentation, modelling, control and supervision of a hydraulic pumping
system and turbine–generator module (in Portuguese). Master’s thesis, Sch. Elect. Eng., Fed-
eral Univ. Minas Gerais, Belo Horizonte, Brazil (2006)
10. Barroso, M.S.F., Takahashi, R.H.C., Aguirre, L.A.: Multi-objective parameter estimation via
minimal correlation criterion. J. Process Control 17(4), 321–332 (2007)
11. Billings, S.A., Voon, W.S.F.: Least squares parameter estimation algorithms for nonlinear sys-
tems. Int. J. Syst. Sci. 15(6), 601–615 (1984)
12. Billings, S.A., Chen, S., Korenberg, M.J.: Identiﬁcation of MIMO nonlinear systems using a
forward-regression orthogonal estimator. Int. J. Control 49(6), 2157–2189 (1989)
13. Bingulac, S., Sinha, N.K.: On the identiﬁcation of continuous-time systems from the samples
of input–output data. In: Proc. Seventh Int. Conf. on Mathematical and Computer Modeling,
Chicago, IL, pp. 231–239 (1989)
14. Bucharles, A., Cassan, H., Roubertier, J.: Advanced parameter identiﬁcation techniques for
near real-time ﬂight ﬂutter test analysis. AIAA, Paper 90-1275, May 1990
15. Chen, S., Billings, S.A., Luo, W.: Orthogonal least squares methods and their application to
nonlinear system identiﬁcation. Int. J. Control 50(5), 1873–1896 (1989)
16. Connally, P., Li, K., Irwing, G.W.: Prediction and simulation error based perceptron training:
Solution space analysis and a novel combined training scheme. Neurocomputing 70, 819–827
(2007)
17. Cooper, J.: Parameter estimation methods for the ﬂight ﬂutter testing. In: Proc. the 80th
AGARD Structures and Materials Panel, CP-566, AGARD, Rotterdam, The Netherlands
(1995)

32
2
Some Industrial Systems
18. Correa, M.V., Aguirre, L.A., Saldanha, R.R.: Using steady-state prior knowledge to constrain
parameter estimates in nonlinear system identiﬁcation. IEEE Trans. Circuits Syst. I, Regul.
Pap. 49(9), 1376–1381 (2002)
19. Cunningham, P., Canty, N., O’Mahony, T., O’Connor, B., O’Callagham, D.: System identiﬁ-
cation of a falling ﬁlm evaporator in the dairy industry. In: Proc. of SYSID’94, Copenhagen,
Denmark, vol. 1, pp. 234–239 (1994)
20. De Moor, B.L.R. (ed.): DaISy: Database for the Identiﬁcation of Systems. Depart-
ment of Electrical Engineering, ESAT/SISTA, K.U.Leuven, Belgium. http://www.esat.
kuleuven.ac.be/sista/daisy
21. De Moor, B.L.R., Ljung, L., Zhu, Y., Van Overschee, P.: Comparison of three classes of iden-
tiﬁcation methods. In: Proc. of SYSID’94, Copenhagen, Denmark, vol. 1, 175–180 (1994)
22. Draper, N.R., Smith, H.: Applied Regression Analysis, 3rd edn. Wiley, New York (1998)
23. Ekawati, E., Bahri, P.A.: Controllability analysis of a ﬁve effects evaporator system. In: Proc.
Foundations of Computer-Aided Process Operations, FOCAPO2003, pp. 417–420 (2003)
24. El-Sherief, H., Sinha, N.K.: Identiﬁcation and modelling for linear multivariable discrete-time
systems: A survey. J. Cybern. 9, 43–71 (1979)
25. El-Sherief, H., Sinha, N.K.: Determination of the structure of a canonical model for the iden-
tiﬁcation of linear multivariable systems. IEEE Trans. Syst. Man Cybern. SMC-12, 668–673
(1982)
26. Energy Efﬁciency and Renewable Energy, U.S. Department of Energy. www.energy.gov
27. Favoreel, W., De Moor, B.L.R., Van Overschee, P.: Subspace state-space system identiﬁcation
for industrial processes. J. Process Control 10(2–3), 149–155 (2000)
28. Ghiaus, C., Chicinas, A., Inard, C.: Grey-box identiﬁcation of air-handling unit elements.
Control Eng. Pract. 15(4), 421–433 (2007)
29. Goldberg, D.E.: Genetic Algorithms in Search, Optimization and Machine Learning. Addison-
Wesley, New York (1989)
30. Hsia, T.C.: On sampled-data approach to parameter identiﬁcation of continuous-time linear
systems. IEEE Trans. Autom. Control AC-17, 247–249 (1972)
31. Hsia, T.: System Identiﬁcation: Least-Squares Methods. Lexington Books, Lexington (1977)
32. Jakubek, S., Hametner, C., Keuth, N.: Total least squares in fuzzy system identiﬁcation: An
application to an industrial engine. Eng. Appl. Artif. Intell. 21, 1277–1288 (2008)
33. Karimi, M., Jahanmiri, A.: Nonlinear modeling and cascade control design for multieffect
falling ﬁlm evaporator. Iran. J. Chem. Eng. 3(2) (2006)
34. Kehoe, M.W.: A historical overview of ﬂight ﬂutter testing, NASA TR 4720, Oct. 1995
35. Leontaritis, I.J., Billings, S.A.: Input–output parametric models for nonlinear systems. Part II:
Deterministic nonlinear system. Int. J. Control 41(2), 329–344 (1985)
36. Miranda, V., Simpson, R.: Modelling and simulation of an industrial multiple-effect evapora-
tor: Tomato concentrate. J. Food Eng. 66, 203–210 (2005)
37. Neilsen, K.M., Pedersen, T.S., Nielsen, J.F.D.: Simulation and control of multieffect evapora-
tor
38. Nepomuceno, E.G., Takahashi, R.H.C., Aguirre, L.A.: Multiobjective parameter estimation:
Afﬁne information and least-squares formulation. Int. J. Control 80(6), 863–871 (2007)
39. Norgaard, M.: Neural network based system identiﬁcation—TOOLBOX, Tech. Univ. Den-
mark, Lyngby, Tech. Rep. 97-E-851 (1997)
40. Ogata, K.: MATLAB for Control Engineers. Prentice-Hall, New York (2008)
41. Pan, Y., Lee, J.H.: Modiﬁed subspace identiﬁcation for long-range prediction model for infer-
ential control. Control Eng. Pract. 16(12), 1487–1500 (2008)
42. Piroddi, L.: Simulation error minimization methods for NARX model identiﬁcation. Int. J.
Model. Identif. Control 3(4), 392–403 (2008)
43. Piroddi, L., Spinelli, W.: An identiﬁcation algorithm for polynomial NARX-models based on
simulation error minimization. Int. J. Control 76(17), 1767–1781 (2003)
44. Rangaiah, G., Saha, P., Tade, M.: Nonlinear model predictive control of an industrial four-
stage evaporator system via simulation. Chem. Eng. J. 87, 285–299 (2002)
45. Roffel, B., Betlem, B.: Process Dynamics and Control. Wiley, London (2006)

References
33
46. Sinha, N.K.: Estimation of transfer function of continuous-time systems from samples of
input–output data. Proc. Inst. Electr. Eng. 119, 612–614 (1972)
47. Sinha, N.K., Kuszta, B.: Modelling and Identiﬁcation of Dynamic Systems. Von-Nostrand
Reinhold, New York (1983)
48. Sinha, N.K., Rao, G.P. (eds.): Identiﬁcation of Continuous-Time Systems. Kluwer Academic,
Dordrecht (1991)
49. Soderstrom, T., Stoica, P.: System Identiﬁcation. Prentice-Hall, New York (1989)

Chapter 3
System Identiﬁcation Methods
3.1 Introduction
System identiﬁcation is concerned with the estimation of a system on the basis of
observed data. This involves speciﬁcation of the model structure, estimation of the
unknown model parameters, and validation of the resulting model. Least squares
and maximum likelihood methods are discussed, for stationary processes (without
inputs) and for input–output systems.
In most practical applications, the system is not known and has to be estimated
from the available information. This is called the identiﬁcation problem. The iden-
tiﬁcation method will depend on the intended model use, as this determines what
aspects of the system are of relevance. The three main choices in system identiﬁca-
tion are the following.
1. Data: In some situations, it is possible to generate a large amount of reliable data
by carefully designed experiments. In other situations, the possibilities to obtain
data are much more limited and it is not possible to control for external fac-
tors that inﬂuence the outcomes. That is, the magnitude of outside disturbances
(‘noise’) may differ widely from one application to another.
2. Model Class: A model describes relations between the observed variables. For
practical purposes, the less important aspects are neglected to obtain sufﬁciently
simple models. The identiﬁed model should be validated to test whether the im-
posed simpliﬁcations are acceptable.
3. Criterion: The criterion reﬂects the objectives of the modeler. It expresses the
usefulness of models in representing the observed data.
Generally speaking, system identiﬁcation should be then considered as an iterative
procedure as illustrated in Fig. 3.1. The “classic” identiﬁcation methodology used
to obtain parametric models based on non-parametric models of the type “step re-
sponse” is illustrated in Fig. 3.2. This methodology, initially used to obtain continu-
ous time parametric models, has been extended to the identiﬁcation of discrete-time
models.
From the shape of the plant step response, one selects a type of model and the
parameters of this model are graphically determined. As the sampling frequency
M.S. Mahmoud, Y. Xia, Applied Control Systems Design,
DOI 10.1007/978-1-4471-2879-3_3, © Springer-Verlag London Limited 2012
35

36
3
System Identiﬁcation Methods
Fig. 3.1 System
identiﬁcation methodology
is known, one can obtain the corresponding discrete time model from conversion
tables.
This methodology has several disadvantages:
• Test signals with large magnitude (seldom acceptable in the industrial systems).
• Reduced accuracy.
• Bad inﬂuence of disturbances.
• Models for disturbances are not available.
• Lengthy procedure.
• Absence of model validation.
3.2 Parameter Estimation Approach
The availability of a digital computer permits the implementation of algorithms that
automatically estimate the parameters of the discrete time models. It should be em-
phasized that the identiﬁcation of the parametric discrete time models allows to
obtain (by simulation) non-parametric models of the step-response or frequency-
response type, with a far higher degree of accuracy with respect to a direct ap-
proach, and using extremely weak excitation signals. The identiﬁcation of paramet-
ric sampled data models leads to models of a very general use and offers several
advantages over the other approaches.
High performance identiﬁcation algorithms, which have a recursive formulation
tailored to real-time identiﬁcation problems and to their implementation on micro-
computer, have been developed. The fact that these identiﬁcation methods can op-

3.2
Parameter Estimation Approach
37
Fig. 3.2 “Classic”
identiﬁcation methodology
erate with extremely weak excitation signals is a very much appreciated quality in
practical situations.
The parameter estimation principle for discrete time models is illustrated in
Fig. 3.3. A sampled input sequence u(t) (where t is the discrete time) is applied to
the physical system (the cascade actuator–plant–transducer) by means of a digital-
to-analog converter (DAC) followed by a zero-order hold block (ZOH). The mea-
sured sampled plant output y(t) is obtained by means of an analog-to-digital con-
verter (ADC).
A discrete-time model with adjustable parameters is implemented on the com-
puter. The error between the system output y(t) at instant t, and the output y(t)
predicted by the model (known as the prediction error) is used by a parameter adap-
tation algorithm that, at each sampling instant, will modify the model parameters in
order to minimize this error on the basis of a chosen criterion.
The input is, in general, a very low level pseudo-random binary sequence gener-
ated by the computer (sequence of rectangular pulses with randomly variable dura-
tion). Once the model is obtained, an objective validation can be made by carrying
out statistical tests on the prediction error ε(t) and the predicted output ˆy(t). The

38
3
System Identiﬁcation Methods
Fig. 3.3 Principle of model
parameter estimation
validation test enables the best model to be chosen (for a given plant), that is the
best structure and the best algorithm for the estimation of the parameters.
Finally, by computing and graphically representing the step responses and the
frequency response of the identiﬁed model, the characteristics of the continuous-
time model (step response or frequency response) can be extracted.
This modern approach to system model identiﬁcation avoids all the problems
related to the previously mentioned “classical” methods and also offers other possi-
bilities such as:
• Tracking of the variations of the system parameters in real time allowing returning
of controllers during operation.
• Identiﬁcation of disturbances models.
• Modeling of the transducer noises in view of their elimination.
• Detection and measurement of vibration frequencies.
• Spectral analysis of the signals.
One of the key elements for implementing this system model identiﬁcation ap-
proach is the parameter adaptation algorithm (PAA) that drives the parameters of
the adjustable prediction model from the data collected on the system at each sam-
pling instant. This algorithm has a “recursive” structure, that is, the new value of the
estimated parameters is equal to the previous value plus a correction term that will
depend on the most recent measurements.
A “parameter vector” is deﬁned, in general, as the vector of the different pa-
rameters that must be identiﬁed. All the parameter adaptation algorithms have the
following structure:
New parameters
estimation
(vector)

=
Old parameters
estimation
(vector)

+
Adaptation
gain
(matrix)

×
Measurement
function
(vector)

×
Error prediction
function
(scalar)

.
The measurement function vector is also known as the “observation vector”.

3.2
Parameter Estimation Approach
39
Note that nonrecursive parametric identiﬁcation algorithms also exist (which pro-
cess as a one block the input/output data ﬁles obtained over a certain time horizon).
Recursive identiﬁcation offers the following advantages with respect to these non-
recursive techniques:
• Obtaining an estimated model as the system evolves.
• Considerable data compression, since the recursive algorithms process at each
instant only one input/output pair instead of the whole input/output data set.
• Much lower requirements in terms of memory and central-processing unit (CPU)
power.
• Easy implementation on microcomputers.
• Possibility to implement real-time identiﬁcation systems.
• Possibility to track the parameters of time variable systems.
Section 3.2 introduces the main types of parameter estimation (identiﬁcation) algo-
rithms in their recursive form. The effect of the noise on the parameter estimation
algorithms will be discussed in Sect. 3.4.
Model Validation
Different points of view can be considered for the choice of a
model validation procedure. The goal is to verify that the output model excited by
the same input applied to the plant reproduce the variations of the output caused by
the variations of the input regardless the effect of the noise.
3.2.1 Estimation Algorithms
We will illustrate the principles of parametric identiﬁcation presented in Fig. 3.3 by
an example. Consider the discrete-time model of a plant described by
y(t + l) = −a1y(t) + b1(t)u(t)
:= θtφ(t)
(3.1)
where a1 and b1 are the unknown parameters.
The model output can be also written under the form of a scalar product between
the unknown parameter vector
θt = [a1,b1]
(3.2)
and the vector of measures termed measurement vector or plant model regressor
vector
φt(t) =

−y(t),u(t)

.
(3.3)
This vector representation is extremely useful since it allows easy consideration of
models of any order.
Following the diagram given in Fig. 3.3, one should construct an adjustable pre-
diction model, which will have the same structure as the discrete-time model of the
plant given in (3.1):
ˆyo(t + 1) = ˆy

t + 1| ˆθ(t)

= −ˆa1(t)y(t) + ˆb1(t)u(t) = ˆθ(t)tφ(t)
(3.4)

40
3
System Identiﬁcation Methods
where ˆyo(t + 1) is the predicted output at the instant t based on the knowledge
of the parameters estimated at time t(ˆa1(t), ˆb1(t)). ˆyo(t + 1) is called the a priori
prediction. Note in (3.4) that
θ(t)t =

ˆa1(t), ˆb1(t)

(3.5)
is the vector of estimated parameters at time t.
One can deﬁne now the prediction error (a priori) as in Fig. 3.4:
εo(t + 1) = y(t + 1) −ˆyo(t + l) = εo
t + 1, ˆθ(t)

.
(3.6)
The term ˆyo(t +1) is effectively computed between the sampling instants t and t +1
once ˆθ(t) is available, εo(t + 1) is computed at the instant t + 1 after the acquisition
of y(t + 1) (between t + 1 and t + 2). Note that εo(t + 1) depends on ˆθ(t).
Now it will be necessary to deﬁne a criterion in terms of the prediction error,
which will be minimized by an appropriate evolution of the parameters of the ad-
justable prediction model, driven by the parameter adaptation algorithm. Since the
objective is to minimize the magnitude of the prediction error independently of its
sign, the choice of a quadratic criterion is natural. A ﬁrst approach can be the synthe-
sis of a parameter adaptation algorithm which at each instant minimizes the square
of the a priori prediction error. This can be expressed as ﬁnding an expression for
ˆθ(t) such that at each sampling one minimizes
J(t + 1) =

εo(t + 1)
2 =

εo
t + 1, ˆθ(t)
2.
(3.7)
The structure of the parameter adaptation algorithm will be of the form
ˆθ(t + 1) = ˆθ + Δ ˆθ(t + 1)
= ˆθ(t) + f
 ˆθ(t),φ(t),εo(i + 1)

.
(3.8)
The correction term f ( ˆθ(t),φ(t),εo(i + 1)) should only depend upon the informa-
tion available at the instant t + 1 (last measurement y(t + 1), parameter vector ˆθ(t)
and a ﬁnite number of measurements or information at t,t −1,...,t −n). The so-
lution to this problem will be given in Sect. 3.2.2. A recursive adaptation algorithm
will be derived enabling both on-line and off-line implementation.
The criterion in (3.7) is not the only one step ahead criterion which can be con-
sidered and this aspect will also be discussed in Sect. 3.2.2.
When a set of input/output measurements over a time horizon t (i = l,2,...,t) is
available, and we are looking for an off line identiﬁcation, one may ask how to use
this set of data optimally. The objective will be to search for a vector of parameters
ˆθ(t) using the available data up to instant t and that minimizes a criterion of the
form
J(t + 1) =
t
i=1

εo
i, ˆθ(t)

(3.9)
that means the minimization of the sum of the squares of the prediction errors over
the time horizon t. This point of view will lead to the least squares algorithm which
will be presented in Sect. 3.2.3 (under the non-recursive and recursive form).

3.2
Parameter Estimation Approach
41
3.2.2 Gradient Algorithm
The aim of the gradient parameter adaptation algorithm is to minimize a one step
quadratic criterion in terms of the prediction error (one-step ahead).
Consider the same example as in Sect. 3.2.1. The discrete time model of the plant
is expressed by
y(t + 1) = −a1y(t) + b1u(t)
= θtφ(t)
(3.10)
where
θt = [a1,b1]
(3.11)
is the parameter vector and
φ(t)t =

−y(t),u(t)

(3.12)
is the vector of measures (pant model regressor vector).
The adjustable prediction model (a priori) is described by
ˆyo(t + 1) = ˆy

t + 1| ˆθ(t)

= −ˆa1y(t) + ˆb1(t)u(t)
= ˆθ(t)tφ(t)
(3.13)
where ˆyo(t + 1) represents the a priori prediction depending on the values of the
parameters estimated at instant t and
ˆθ(t)t =

ˆa1(t), ˆb1(t)

(3.14)
is the estimated parameter vector.1
The a priori prediction error is given by
εo(t + 1) = y(t + 1) −ˆyo(t + 1).
(3.15)
To evaluate the quality of the new estimated parameter vector ˆθ(t + 1), which
will be provided by the parameter adaptation algorithm, it is useful to deﬁne the
a posteriori output of the adjustable predictor, which corresponds to re-computing
(3.15) with the new values of the parameters estimated at t + 1.
The a posteriori predictor output is deﬁned by
ˆy(t + 1) = ˆy

t + 1| ˆθ(t + 1)

= −a1(t + 1)y(t) + ˆb1(t + 1)u(t)
= ˆθ(t + 1)tφ(t).
(3.16)
One also deﬁnes an a posteriori prediction error:
ε(t + 1) = y(t + 1) −ˆy(t + 1).
(3.17)
1In this case, the predictor regressor vector is identical to the measurement vector.

42
3
System Identiﬁcation Methods
Fig. 3.4 Principle of gradient
method
A recursive parametric adaptation algorithm with memory is desired. The structure
of such an algorithm is2
ˆθ(t + 1) = ˆθ(t) + Δ ˆθ(t + 1)
= ˆθ(t) + f
 ˆθ(t),φ(t),εo(t + 1)

.
(3.18)
The correction term f ( ˆθ(t),φ(t),εo(t +1)) must only depend upon the information
available at instant t + 1 (last measure y(t + 1), parameters of ˆθ(t) and eventually a
ﬁnite number of information at instants t,t −1,t −2,...,n). The correction term
should allow one to minimize at each step the a priori prediction error with respect
to the criterion
min
ˆθ(t)
J(t + 1) =

εo(t + l)
2.
(3.19)
If one represents the criterion J and the parameters ˆa1 and ˆb1 in three-dimensional
space, one gets the form represented in Fig. 3.5 (a reversed conic surface). The
optimum of the criterion will correspond to the bottom of the cone and the pro-
jection of this point on the plane ˆa1, ˆb1 will give us the optimal values of the
plant parameters: a1 and b1. It is obvious that, in order to reach as quickly as pos-
sible this point (the optimum of the criterion), it will be advantageous to go down
along the steepest descent. This solution is analytically given by the gradient tech-
nique.
The horizontal sections of the surface correspond to curves along which the cri-
terion has a constant value (isocriterion curves). If one represents the projection of
the isocriterion curves (J = const) in the plane of the parameters ˆa1, ˆb1, one obtains
concentric closed curves around the point a1, b1 (the parameters of the plant model)
which minimizes the criterion. As the value of the criterion J(= const) increases,
the isocriterion curves move further and further away from the minimum. This is
illustrated in Fig. 3.5.
In order to minimize the value of the criterion, one moves in the direction of the
steepest descent that, see Fig. 3.4, corresponds to move in the opposite direction
2Effectively, if the correction term is null, one holds the previous value of the estimated parameters.

3.2
Parameter Estimation Approach
43
Fig. 3.5 Geometric
interpretation of the gradient
adaptation algorithm
of the gradient associated to the isocriterion curve. This will lead us to a curve
corresponding to J = const of a smaller value, as shown in Fig. 3.4.
The corresponding parametric adaptation algorithm will have the form
ˆθ(t + 1) = ˆθ(t) −F ∂J(t + 1)
∂ˆθ(t)
(3.20)
where F = αI (α >0) is the adaptation matrix gain (I—identity matrix) and ∂J(t +
1)/∂ˆθ(t) is the gradient of the criterion of (3.20) with respect to ˆθ(t).
From (3.20), one gets
1
2
∂J(t + 1)
∂ˆθ(t)
= ∂εo(t + 1)
∂ˆθ(t)
εo(t + 1).
(3.21)
Since
εo(t + 1) = y(t + l) −ˆyo(t + 1)
= y(t + 1) −ˆθ(t)tφ(t)
(3.22)
and then
∂εo(t + 1)
∂ˆθ(t)
= −φ(t).
(3.23)
Substituting (3.23) into (3.20), the parametric adaptation algorithm of (3.20) be-
comes
ˆθ(t + 1) = ˆθ(t) + Fφ(t)εo(t + l)
(3.24)
where F is the adaptation matrix gain.3 Two choices are possible:
1. F = αI; α > 0.
2. F > 0 (positive deﬁnite matrix).4
The geometric interpretation of the parametric adaptation algorithm expressed by
(3.24) is given in Fig. 3.5.
3In equations of the form of (3.24) the vector φ is generally called the observation vector. In this
particular case, it corresponds to the measurement vector.
4A positive deﬁnite matrix is characterized by: (i) each diagonal term is positive; (ii) the matrix is
symmetric; (iii) the determinants of all principal matrix minors are positive. See the Appendix.

44
3
System Identiﬁcation Methods
The parametric adaptation algorithm given by (3.24) presents some instability
possibilities if the adaptation gain (respectively, α) is large (this can be well under-
stood with the support of Fig. 3.4).
Let consider (3.17) of the a posteriori error. By using (3.13) and (3.13), it can be
re-written as
ε(t + 1) = y(t + 1) −ˆy(t + 1)
= y(t + 1) −ˆθ(t)T φ(t) +
 ˆθ(t) −ˆθ(t + 1)
tφ(t).
(3.25)
From (3.24) it yields
ˆθ(t) −ˆθ(t + 1) = −Fφ(t)εo(t + 1)
(3.26)
and by also taking into account (3.15), (3.25) becomes
ε(t + 1) = εo(t + 1) −φ(t)tFφ(t)εo(t + 1).
(3.27)
In case that F = αI, it becomes:
ε(t + 1) =

1 −αφ(t)tφ(t)

εo(t + 1).
(3.28)
If ˆθ(t + 1) is a better estimation than ˆθ(t) (which means that the estimation of the
parameters goes in the good sense) one should get ε(t + l)2 < εo(t + 1)2. There-
fore, it results from (3.28) that the adaptation gain α should satisfy the (necessary)
condition
α < 2/φ(t)tφ(t).
(3.29)
In this algorithm, in other words, the adaptation gain must be chosen as a function
of the magnitude of the signals.5
In order to avoid the possible instabilities, and the dependence of the adaptation
gain with respect to the magnitude of the measured signals, one uses the same gradi-
ent approach but with a different criterion, which has as objective the minimization
of the a posteriori prediction error at each step according to
min
ˆθ(t+1)
J(t + 1) =

ε(t + 1)
2.
(3.30)
Thus, one gets:
1
2
∂J(t + 1)
∂ˆθ(t + 1)
= ∂ε(t + 1)
∂ˆθ(t + 1)
ε(t + 1).
(3.31)
From (3.16) and (3.17), it follows that
ε(t + 1) = y(t + 1) −ˆy(t + 1) = y(t + 1) −ˆθ(t + 1)tφ(t)
(3.32)
and respectively, that
∂ε(t + 1)
∂ˆθ(t + 1)
= −φ(t).
(3.33)
5One can derives from (3.28) that an optimal value for α is α ≈1/φ(t)tφ(t).

3.2
Parameter Estimation Approach
45
Substituting (3.33) into (3.31), the parameter adaptation algorithm of (3.20) be-
comes
ˆθ(t + 1) = ˆθ(t) + Fφ(t)ε(t + 1).
(3.34)
This algorithm depends on ε(t + 1), which is a function ˆθ(t + 1). In order to
implement this algorithm, it is necessary to express ε(t + 1) as a function of
εo(t + 1) : (ε(t + 1) = f ( ˆθ(t),φ(t),εo(t + 1))).
Observe that (3.32) can be rewritten as
ε(t + 1) = y(t + 1) −ˆθ(t)tφ(t) −
 ˆθ(t + 1) −ˆθ(t)
tφ(t).
(3.35)
The ﬁrst two terms of the right side correspond to εo(t + 1) and, from (3.34), one
gets
ˆθ(t + 1) −ˆθ(t) = Fφ(t)ε(t + 1)
(3.36)
which allows one to write (3.35) in the form
ε(t + 1) = εo(t + 1) −φ(t)tFφ(t)ε(t + 1)
(3.37)
from which one derives the desired relation between ε(t + 1) and εo(t + 1)
ε(t + 1) =
εo(t + 1)
1 + φ(t)tFφ(t)
(3.38)
and the algorithm of (3.34) becomes
ˆθ(t + 1) = ˆθ + Fφ(t)εo(t + 1)
1 + φ(t)tFφ(t)
(3.39)
that is a stable algorithm regardless of the gain F (positive deﬁnite matrix). The
division by 1 + φ(t)tFφ(t) introduces a normalization that reduces the sensitivity
of the algorithm with respect to F and φ(t).
The sequence of operation corresponding to the recursive estimation algorithms
can be summarized as follows:
1. Before t + 1: u(t),u(t −1),...,y(t),y(t −1),...,φ(t), ˆθ(t),F are available.
2. Before t + 1 one computes:
Fφ(t)
1+φ(t)tFφ(t) and yo(t + 1) (given by (3.13)).
3. At instant t + 1 y(t + 1) is acquired and u(t + 1) is applied.
4. The parametric adaptation algorithm is implemented.
a. One computes εo(t + 1) by using (3.15).
b. One computes ˆθ(t + 1) from (3.39).
c. (Optionally) one computes ε(t + 1).
5. Return to step 1.
3.2.3 Least Squares Algorithm
By using the gradient algorithm, at each step ε2(t + 1) is minimized or, more pre-
cisely, one moves in the steepest decreasing direction of the criterion, with a step

46
3
System Identiﬁcation Methods
Fig. 3.6 Evolution of an
adaptation algorithm of the
gradient type
update depending on F . The minimization of εa2(t + 1) at each step does not nec-
essarily lead to the minimization of
t
i=1
ε2(i)
on a t-steps time horizon, as illustrated in Fig. 3.6. In fact, in the proximity of
the optimum, if the gain is not small enough, oscillations may occur around the
minimum. On the other hand, in order to obtain a satisfactory convergence speed at
the beginning, when the current estimation is theoretically far from the optimum, a
high adaptation gain is preferable. The least squares algorithm offers, in fact, such a
variation proﬁle for the adaptation gain.
The same equations, as in the gradient algorithm, are considered for the plant,
the prediction model and the prediction errors, namely (3.15) to (3.22).
The aim is to ﬁnd a recursive algorithm of the form of (3.18) that minimizes the
“least squares” criterion
min
ˆθ(t)
J(t) = 1
t
t
i=1

y(i) −ˆθ(t)tφ(i −1)
2
= 1
t
t
i=1
ε2
i, ˆθ(t)

.
(3.40)
The term ˆθ(t)tφ(i −1) corresponds to
ˆθ(t)φ(i −1) = −ˆa1(t)y(i −1) + ˆb1(t)u(i −l)
= ˆy| ˆθ(t).
(3.41)
This is the prediction of the output at instant i (i ≤t) based on the parameter es-
timate at instant t obtained using t measurements. The objective is therefore the
minimization of the sum of the squares of the prediction errors.
First, a parameter ˆθ must be estimated at instant t, so that it minimizes the sum
of the squares of the differences between the output of the plant and the output
of the prediction model over a horizon of t measurements. The value of ˆθ(t) that

3.2
Parameter Estimation Approach
47
minimizes the criterion of (3.40) is obtained by looking for the value that cancels
∂J(t)/∂θ(t):6
∂J(t)
∂ˆθ(t)
= −2
t
i−1

y(i) −ˆθ(t)tφ(i −1)

φ(i −1)
= 0.
(3.42)
From (3.42), taking into account that
 ˆθ(t)tφ(i −1)

φ(i −1) = φ(i −1)φ(i −1)t ˆθ(t)
one readily obtains
 t
i=1
φ(i −1)φ(i −1)t

ˆθ(t) =
t
i=1
y(i)φ(i −1).
Multiplying the left both terms of this equation by
 t
i=1
φ(i −1)φ(i −1)t
−1
it results in
ˆθ(t) =
 t
i=1
φ(i −1)φ(i −1)t
−1
t
i=1
y(i)φ(i −1)
= F(t)
t
i=1
y(i)φ(i −1)
(3.43)
where
F(t)−1 =
t
i=1
φ(i −1)φ(i −1)t.
(3.44)
Observed that this estimation algorithm is not recursive. In order to obtain a recur-
sive algorithm, the estimation of ˆθ(t + 1) is ﬁrst considered:
ˆθ(t + 1) = F(t + 1)
t+1

i=1
y(i)φ(i −1),
(3.45)
F(t + 1)−1 =
t+1

i=1
φ(i −1)φ(i −1)t
= F(t)−1 + φ(t)φ(t)t.
(3.46)
6This is the real minimum with the condition that the second derivative of the criterion, with respect
to ˆθ(t) is positive, that is ∂2J(t)
∂ˆθ(t)2 = 2	t
i=1 φ(i −1)φ(i −1)t > 0, as it is in general the case for
t ≥dimθ (see also Sect. 3.3).

48
3
System Identiﬁcation Methods
Next, one should express it as a function of ˆθ(t):
ˆθ(t + 1) = ˆθ(t) + Δ ˆθ(t + 1).
(3.47)
From (3.45), adding and subtracting φ(t)φ(t)t ˆθ(t)), one gets
t+1

i=1
y(i)φ(i −1) =
t
i=1
y(i)φ(i −1) + y(t + 1)φ(t)
= φ(t)φ(t)t ˆθ(t).
(3.48)
Taking into account (3.43), (3.45) and (3.46), then (3.48) can be rewritten as
t+1

i=1
y(i)φ(i −1)
= F(t + 1)−1 ˆθ(t + 1)
= F(t)−1 ˆθ(t) + φ(t)φ(t)t ˆθ(t) + φ(t)

y(t + 1) −ˆθ(t)tφ(t)

.
(3.49)
On the other hand, on the basis of (3.15) and (3.46), one obtains
F(t + 1)−1 ˆθ(t + 1) = F(t + 1)−1 ˆθ(t) + φ(t)εo(t + 1).
(3.50)
Multiplying on the left by F(t + 1), one gets
ˆθ(t + 1) = ˆθ(t) + F(t + 1)φ(t)εo(t + 1).
(3.51)
The adaptation algorithm of (3.51) has a recursive form similar to the gradient algo-
rithm given in (3.24), with the difference that the gain matrix F(t + 1) is now time
varying since it depends on the measurements (it automatically corrects the gradient
direction and the step length).
A recursive formula for F(t + 1) remains to be provided starting from the recur-
sive formula for F −1(t + 1) given in (3.46). This is obtained by using the matrix
inversion lemma (given below in a simpliﬁed form, see the Appendix for a general
form).
Lemma 3.1 Let F be a regular matrix of dimension (n × n) and φ a vector of
dimension n; then

F −1 + φφt−1 = F −FφφtF
1 + φtFφ .
(3.52)
Observe that to verify the inversion formula, one can simply multiply both terms
by F −1 + φφt.
From (3.46) and (3.52), one gets
F(t + 1) = F(t) −F(t)φ(t)φ(t)tF(t)
1 + φ(t)tF(t)φ(t)
(3.53)
and, regrouping the different equations, a ﬁrst formulation of the recursive least
squares (RLS) parameter adaptation algorithm (PAA) is given by

3.2
Parameter Estimation Approach
49
ˆθ(t + 1) = ˆθ(t) + F(t + 1)φ(t)εo(t + 1),
(3.54)
F(t + 1) = F(t) −
F(t)φ(t)tF(t)
1 + φ(t)tF(t)φ(t),
(3.55)
εo(t + 1) = y(t + 1) −ˆθtφ(t).
(3.56)
An equivalent form of this algorithm is obtained by substituting the expression of
F(t + 1) given by (3.55) into (3.54). It yields
 ˆθ(t + 1) ˆθ(t)

= F(t + 1)φ(t)εo(t + 1) = F(t)φ(t)
εo(t + 1)
1 + φ(t)tF(t)φ(t).
(3.57)
On the other hand from (3.15)–(3.17) and (3.57), one obtains:
ε(t + 1) = y(t + 1) −ˆθ(t + 1)φ(t)
= y(t + 1) −ˆθ(t)φ(t) −
 ˆθ(t + 1) −ˆθ(t)
tφ(t)
= εo(t + 1) −φ(t)tF(t)φ(t)
εo(t + 1)
1 + φ(t)tF(t)φ(t)
=
εo(t + 1)
1 + φ(t)tF(t)φ(t).
(3.58)
This expresses the relation between the a posteriori prediction error and the a priori
prediction error. Using this relation in (3.57), an equivalent form of the parameter
adaptation algorithm for the recursive least squares is obtained7
ˆθ(t + 1) = ˆθ(t) + F(t)φ(t)ε(t + 1),
(3.59)
F(t + 1)−1 = F(t)−1 + φ(t)φ(t)t,
(3.60)
F(t + 1) = F(t) −
F(t)φ(t)φ(t)tF(t)
1 + φ(t)tφ(t)F(t)φ(t),
(3.61)
ε(t + 1) = y(t + 1) −ˆθ(t)tφ(t)
1 + φ(t)tF(t)φ(t) .
(3.62)
For the recursive least squares algorithm to be exactly equivalent to the nonre-
cursive least squares algorithm, it must be started at instant t0 = dimφ(t), since
normally F(t)−1 given by (3.44) becomes non-singular for t = t0.
In practice, the algorithm is initialized at t = 0 by choosing
F(0) = 1
δ I = (GI)I;
0 < δ < 1
(3.63)
a typical value being δ = 0.001 (GI = 1000). It can be observed, from the expres-
sion of F(t + 1)−1 given by (3.60) that the inﬂuence of this initial error decreases
with time. A rigorous analysis (based on the stability theory—see [49]) shows nev-
ertheless that for any positive deﬁnite matrix F(0) (F(0) > 0),
lim
t→0ε(t + 1) = 0.
7This equivalent form is particularly useful in analyzing and understanding the algorithm.

50
3
System Identiﬁcation Methods
The recursive least squares algorithm is an algorithm with a decreasing adaptation
gain. This is clearly seen if the estimation of a single parameter is considered. In
this case F(t) and φ(t) are scalars, then (3.61) becomes
F(t + 1) =
F(t)
1 + φ(t)2F(t) ≤F(t).
The recursive least squares algorithm gives, in fact, less and less weight to the new
prediction errors, and thus to the new measurements.
It can be readily seen that this type of variation of the adaptation gain is not
suitable for the estimation of time varying parameters, and other variation proﬁles
must therefore be considered for the adaptation gain.
One must emphasize that he least squares algorithm, presented up to now for θ(t)
and φ(t) of dimension 2, may be generalized to the n-dimensional case on the basis
of the description of discrete-time systems of the form
y(t) = q−dB(q−1)
A(q−1)
u(t)
(3.64)
where
A

q−1
= 1 + a1q−1 + ··· + anAq−nA,
(3.65)
B

q−1
= b1q−1 + ··· + bnBq−nB
(3.66)
which can further be rewritten as
y(t + 1) = −
nA

i=1
ai(t + 1 −i) +
nB

i=1
biu(t −d −i + 1) = θtφ(t)
(3.67)
where
θt = [a1,...,anA,b1,...,bnB],
(3.68)
φ(t)t =

−y(t),...,−y(t −nA + 1),
u(t −d),...,u(t −d −nB + 1)

.
(3.69)
The a priori adjustable predictor is given in the general case by
ˆyo(t + 1) = −
nA

i=1
ˆaiy(t + 1 −i) +
nB

i=1
ˆbiu(t −d −i + 1) = ˆθtφ(t)
(3.70)
where
ˆθ(t)t =

ˆa1(t),..., ˆanA(t), ˆb1(t),..., ˆbnB(t)

(3.71)
and, for the estimation of ˆθ(t), the algorithm given in (3.54)–(3.56) is used with the
appropriate dimension for ˆθ(t), φ(t) and F(t).

3.2
Parameter Estimation Approach
51
3.2.4 Choice of the Adaptation Gain
The recursive formula for the inverse of the adaptation gain F(t + 1)−1 given by
(3.46) or (3.60) is generalized by introducing two weighting sequences λ1(t)and
λ2(t), as indicated below:
F(t + 1)−1 = λ1(t)F(t)−1 + λ2(t)φ(t)φ(t)t,
0 < λ1(t) ≤1;
0 ≤λ2(t) < 2;
F(0) > 0.
(3.72)
Note that λ1(t) and λ2(t) in (3.72) have the opposite effect: λ1(t) < 1 tends to in-
crease the adaptation gain (the gain inverse decreases), λ2(t) > 0 tends to decrease
the adaptation gain (the gain inverse increases). For each choice of sequences λ1(t)
and λ2(t), a different variation proﬁle of the adaptation gain is found and, conse-
quently, an interpretation in terms of the error criterion that is minimized by the
PAA. Using the matrix inversion lemma given by (3.52), one obtains from (3.72):
F(t + 1) =
1
λ1(t)

F(t) −
F(t)φ(t)φ(t)tF(t)
λ1(t)
λ2(t) + φ(t)tF(t)φ(t)

.
(3.73)
Next a selection of choices for λ1(t) and λ2(t) and their interpretations will be
given.
1. Decreasing Gain (RLS)
In this case,
λ1(t) = λ1 = 1,
λ2(t) = 1
(3.74)
and F(t + 1)−1 is given by (3.60) which leads to a decreasing adaptation gain.
The minimized criterion is expressed by (3.40).
This type of proﬁle is suited for the identiﬁcation of stationary systems (with
constant parameters).
2. Constant Forgetting Factor
In this case,
λ1(t) = λ1 = 1,
0 < λ1 < 1,
λ2(t) = λ2 = 1.
(3.75)
Typical values for λ1 are: λ1 = 0.95,...,0.99.
The criterion to be minimized will be
J(t) =
t
i=1
λt−i
1

y(i) −ˆθ(t)tφ(i −1)
2.
(3.76)
The effect of λ1 < 1 is to introduce a decreasing weighting on the past data
(i < t). This is why λ1 is known as the forgetting factor. The maximum weight is
given to the most recent error. This type of proﬁle is suited for the identiﬁcation
of slowly time varying systems.
Remark 3.2 Note that F(t + 1)−1 given by (3.72) can be interpreted as the out-
put of a ﬁlter characterized b the pulse transfer operator H(q−1) = λ2(t)/(1 −

52
3
System Identiﬁcation Methods
λ1(t)q−1) whose input is φφt. In addition, when an excitation is not pro-
vided (φ(t)φ(t)t = 0), F(t + 1)−1 goes towards zero (because in this case
F(t + 1)−1 = λ1F(t)−1, λ1 < 1, leading to very high adaptation gains, a sit-
uation that should be avoided.
3. Variable Forgetting Factor
In this case
λ2(t) = λ2 = 1
(3.77)
and the forgetting factor λ1 is given by
λ1t = λ0λ1(t −1) + 1 −λ0;
0 < λ0 < 1
(3.78)
typical values being: λ1(0) = 0.95,...,0.99; λ0 = 0.95,...,0.99.
Observe that (3.78) leads to a forgetting factor that asymptotically tends to-
wards 1. The criterion minimized will be
J(t) =
t
i=1
t−1

j=1
λ1(j −i)


y(i) −ˆθ(t)tφ(i −1)
2.
(3.79)
As λ1(t) tends towards 1 for large i, only the initial data are forgotten (the adap-
tation gain tends towards a decreasing gain). This type of proﬁle is highly rec-
ommended for the identiﬁcation of stationary systems, since it avoids a too rapid
decrease of the adaptation gain, thus generally resulting in an acceleration of the
convergence (by maintaining a high gain at the beginning when the estimates are
far from the optimum).
4. Constant Trace
In this case, λ1(t) and λ2(t) are automatically chosen at each step in order
to ensure a constant trace of the gain matrix (constant sum of the diagonal
terms)
TrF(t + 1) = TrF(t) = TrF(0) = nGi
(3.80)
in which n is the number of parameters and Gi the initial gain (typical values:
GI = 0,1...,4), the matrix F(0) having the form
F(0) =
⎡
⎢⎣
Gi
0
...
0
Gi
⎤
⎥⎦.
(3.81)
The minimized criterion is of the form
J(t) =
t
i=1
f (t,i)

y(i) −ˆθ(t)tφ(i −1)
2
(3.82)
in which f (t,i) represents the forgetting proﬁle.
Using this technique, at each step there is a movement in the optimal direction
of the RLS but the gain is maintained approximately constant (reinﬂation of the
RLS gain).

3.2
Parameter Estimation Approach
53
The values of λ1(t) and λ2(t) are determined from
TrF(t + 1) =
1
λ1(t) tr

F(t) −
F(t)φ(t)φ(t)tF(t)
α(t) + φ(t)tF(t)φ(t)

= TrF(t).
(3.83)
It is easy to see that by imposing the ratio α(t) = λ1(t)/λ2(t), (3.83) is obtained
from (3.73). This type of proﬁle is suited for the identiﬁcation of systems with
time varying parameters.
5. Decreasing Gain + Constant Trace
In this case, there is a switch from A1 to A4 when
TrF(t) ≤nG,
G = 0.1 →4
(3.84)
where G is ﬁxed at the beginning. This proﬁle is suited for the identiﬁcation
of time variable systems in the absence of initial information on the parame-
ters.
6. Variable Forgetting Factor + Constant Trace
In this case, there is a switch from A3 to A4 when
TrF(t) ≤nG.
(3.85)
The domain of application is the same as for item 5.
7. Constant Gain (Improved Gradient Algorithm)
In this case,
λ1(t) = λ1 = 1;
λ2(t) = λ2 = 0
(3.86)
and thus from (3.83), it results that
F(t + 1) = F(t) = F(0).
(3.87)
The improved gradient adaptation algorithm given by (3.34) or (3.39) is thus
obtained.
This algorithm can be used to identify stationary or time varying sys-
tems with few parameters (≤3), and in the presence of a reduced noise
level.
This type of adaptation gain results in performances which are inferior to those
provided by proﬁles 1 through 4, but it is simpler to implement.
Choice of the Initial Adaptation Gain F(0)
The initial adaptation gain F(0) is of
the form given by (3.63), respectively (3.81).
In the absence of initial information, upon the parameters to be estimated (a
typical choice is to set the initial estimation to zero), a high initial gain (Gi) is
chosen for reasons that have been explained by (3.63) in Sect. 3.2.3. A typical value
is Gi = 1000.
On the other hand, if an initial parameter estimation is available (resulting for
example from a previous identiﬁcation), a low initial gain is chosen. In general, in
this case Gi ≤1.

54
3
System Identiﬁcation Methods
Since the adaptation gain decreases as the correct model parameter estimations
are approached (a signiﬁcant index is its trace), the adaptation gain may be inter-
preted as an index of the accuracy of the estimation (or prediction). This explains
the choices of F(0) proposed above. Note that, under certain hypotheses, F(0) is
effectively an index of the quality of the estimation because it represents the co-
variance of the parameter error vector ˜θ(t) = ˆθ(t) −θ. This property can give some
information on the evolution of an estimation procedure. If the trace of F(t) is
not signiﬁcantly decreasing, the parameter estimation, in general, is bad. This phe-
nomenon occurs, for example, when the amplitude and the type of the input used are
not suited for the identiﬁcation. The importance of the nature of the identiﬁcation
signal will be discussed in the following section.
3.3 Transfer-Function Methods
Fundamental to most physical sciences is the concept of a mathematical model.
Models are essential for prediction and control purposes. The type and accuracy of
the model depends upon the application in mind. For example, models for aerospace
applications usually need to be very precise, whereas models for industrial pro-
cesses, such as blast furnaces, can often be very crude. Models can be obtained
from physical reasoning or by analyzing experimental data from the system. In the
latter case, our ability to obtain an accurate model is limited by the presence of
random ﬂuctuations such as unmeasured disturbances and measurement errors. The
problem of obtaining mathematical models of physical systems from noisy obser-
vations is the subject of this book. In particular, we study the problem of estimation
of the parameters within models of dynamic systems. We also investigate the effects
of various experimental conditions upon model accuracy.
In the terminology of system identiﬁcation, parametric models include transfer
function, differential or difference equation. Henceforward, we will be concerned
with the identiﬁcation of parametric dynamic models, which are the most suitable
for the design and tuning of applied industrial control systems. Basic methods in-
clude AutoRegressive (AR) method, AutoRegressive with eXogenous input (ARX)
method, AutoRegressive Moving Average (ARMA) method, AutoRegressive Mov-
ing Average with eXogenous input (ARMAX) method, the Box–Jenkins method
and prediction error method (PEM). We initially focus on the latter method leaving
the remaining methods to later sections.
3.3.1 Prediction Error Method (PEM)
The prediction error method (PEM) is sometimes called the generalized least
squares (GLS) method, although GLS originally was associated with a certain nu-
merical minimization procedure [95]. This method was proposed in [17], where he
extended the equation error model and assumed that the true process is given by
Ao(q)y(t) = Bo(q)u(t) +
1
Do(q)e(t)
(3.88)

3.3
Transfer-Function Methods
55
or
y(t) = Bo(q)
Ao(q)u(t) +
1
Ao(q)Do(q)e(t)
(3.89)
where
Ao(q) = 1 + ao
1q−1 + ao
2q−2 + ··· + ao
naq−na,
Bo(q) = bo
1q−1 + bo
2q−2 + ··· + bo
nbq−nb,
Do(q) = 1 + do
1q−1 + do
2q−2 + ··· + do
ndq−nd
and e(t) is white noise with zero mean and variance λ.
So the equation disturbance is assumed to be an AR (autoregressive) process.
Then, (3.88) can be written as
Do(q)Ao(q)y(t) = Do(q)Bo(q)u(t) + e(t).
(3.90)
This enlarged equation has a white noise disturbance e(t). From the study of the
least-squares method, we know that consistent and efﬁcient estimates of ai, bi, di
can be obtained by minimizing the loss function
VPEM = 1
N
N

t=1
ε2(t)
= 1
N
N

t=1

D(q)

A(q)y(t) −B(q)u(t)
2.
(3.91)
This implies that, in the identiﬁcation a model should be used which has the same
structure as the true process
D(q)A(q)y(t) = D(q)B(q)u(t) + ε(t)
(3.92)
where ε(t) is the residual; see Sect. 3.4.2. When D(t) = I, then (3.92) can be written
using ϕ(t) and θ,
y(t) = ϕ∗(t)θ + ε(t)
(3.93)
where
ϕ∗(t) =

−y(t −1)··· −y(t −na)u(t −1)···u(t −nb)

θ = (a1 ···ana b1 ···bna)∗
and for computing ˆθ
ˆθ =

1
N
N

t=1
ϕ(t)ϕ∗(t)
−1
1
N
N

t=1
ϕ(t)y(t)

.
(3.94)
Note that all the discussions about algorithms for computing ˆθ will remain valid.
The results derived there depend only on the ‘algebraic structure’ of the esti-
mate (3.94). For the statistical properties, though, it is of crucial importance whether

56
3
System Identiﬁcation Methods
ϕ(t) is an a priori given quantity, or whether it is a realization of a stochastic pro-
cess. The reason why this difference is important is that for the dynamic models,
when taking expectations of various quantities, it is no longer possible to treat Φ as
a constant matrix.
3.4 Subspace Identiﬁcation Method
This section contains a description of the central ideas pertaining to subspace iden-
tiﬁcation method. First, we describe state space models, which is the type of models
that is delivered by subspace identiﬁcation algorithms. Then we explain how sub-
space identiﬁcation algorithms work.
3.4.1 State Space Models
Models in the sequel are lumped, discrete time, linear, time-invariant, state space
models. It is interesting to observe that many industrial processes can be described
very accurately by this type of models, especially locally in the neighborhood of
a working point. Moreover, there is a large number of control system design tools
available to build controllers for such systems and models. These models are de-
scribed mathematically by the following set of difference equations:
xk+1 = Axk + Buk + wi,
yk = Cxk + Duk + vk,
(3.95)
with
E


wp
vp
wt
q
vt
q

=

 Q
S
St
R

δpq ≥0
(3.96)
where E denotes the expected value operator and δpq the Kronecker delta. In this
model, we denote by the vectors uk ∈ℜm and yk ∈ℜℓthe observations at time
instant k of respectively, the m inputs and ℓoutputs of the process. The vector
xk ∈ℜn is the state vector of the process at discrete time instant k and contains the
numerical values of n states. vk ∈ℜℓand wk ∈ℜn are unobserved vector signals,
usually called the measurement, respectively, process noise. It is assumed that they
are zero mean, stationary, white noise vector sequences. (The Kronecker delta in
(3.96) means δpq = 0 if p ̸= q, and δpq = 1 if p = q, The effect of the process wk
is different from that of vk : wk as an input will have a dynamic effect on the state
xk and output yk, while vk only affects the output yk directly and therefore is called
a measurement noise.)
In addition, A ∈ℜn×n is called the system matrix. It describes the dynamics
of the system (as characterized by its eigenvalues), B ∈ℜn×m is the input matrix,
which represents the linear transformation by which the deterministic inputs inﬂu-
ence the next state and C ∈ℜℓ×n is the output matrix, which describes how the in-
ternal state is transferred to the outside world in the observations yk. The term with

3.4
Subspace Identiﬁcation Method
57
Fig. 3.7 Discrete system under consideration
the matrix D ∈ℜl×m is called the direct feed through term. The matrices Q ∈ℜn×n,
S ∈ℜn×ℓand R ∈ℜℓ×ℓare the covariance matrices of the noise sequences wk and
vk. The block matrix in (3.96) is assumed to be positive deﬁnite, as is indicated by
the inequality sign. The matrix pair {A,C} is assumed to be observable, which im-
plies that all modes in the system can be observed in the output yk and can thus be
identiﬁed. The matrix pair {A,[BQ1/2]} is assumed to be controllable, which in its
turn implies that all modes of the system can be excited by either the deterministic
input uk and/or the stochastic input wk.
A graphical representation of the system can be found in Fig. 3.7.
The main mathematical problem here is phrased as follows: Given s consecutive
input and output observations uo,...,us−1, and yo,...,ys−1. Find an appropriate
order n and the system matrices A, B, C, D, Q, R, S.
Subspace identiﬁcation algorithms are based on concepts from system theory,
numerical linear algebra and statistics. The main concepts in subspace identiﬁcation
algorithms are:
1. The state sequence of the dynamical system is determined ﬁrst, directly from
input/output observations, without knowing the model. That this is possible for
the model class (3.95) is one of the main contributions of subspace algorithms,
as compared to “classical” approaches that are based on an input–output frame-
work. The difference is illustrated in Fig. 3.8. So an important achievement of
the research in subspace identiﬁcation was to demonstrate how the Kalman ﬁl-
ter states can be obtained directly from input–output data using linear algebra
tools (QR and singular value decomposition) without knowing the mathemati-
cal model. An important consequence is that, once these states are known, the
identiﬁcation problem becomes a linear least squares problem in the unknown
system matrices, and the process and measurement noise covariance matrices
follow from the least squares residuals, as is easy to see from (3.95):

xi+1
xi+2
···
xi+j
yi
yi+1
···
yi+j−1




known
=

A
B
C
D

xi
xi+1
···
xi+j−1
ui
ui+1
···
ui+j−1




known
+

wi
wi+1
···
wi+j−1
vi
vi+1
···
vi+j−1

.
(3.97)

58
3
System Identiﬁcation Methods
Fig. 3.8 Subspace and
identiﬁcation classical
approaches
The meaning of the parameters i and j will become clear henceforth. Even
though the state sequence can be determined explicitly, in most variants and im-
plementations, this is not done explicitly but rather implicitly. Putting it differ-
ently, the set of linear equations above can be solved ‘implicitly’ as will become
clear below, without an explicit calculation of the state sequence itself. Of course,
when needed, the state sequence can be computed explicitly.
The two main steps that are taken in subspace algorithms are the following:
a. Determine the model order n and a state sequence ˆxi, ˆxi+1,..., ˆxi+j (esti-
mates are denoted by a ˆ·). They are typically found by ﬁrst projecting row
spaces of data block Hankel matrices, and then applying a singular value de-
composition (see Sects. 3.4.6, 3.4.7, 3.4.8).
b. Solve a least squares problem to obtain the state space matrices:

ˆA
ˆB
ˆC
ˆD

=
min
A,B,C,D


 ˆxi+1
ˆxi+2
···
ˆxi+j
ˆyi
ˆyi+1
···
ˆyi+j−1

−

A
B
C
D
 
 ˆxi
ˆxi+1
···
ˆxi+j−1
ˆui
ˆui+1
···
ˆui+j−1

2
F
,
(3.98)
where ∥· ∥F denotes the Frobenius-norm of a matrix. The estimates of the
noise covariance matrices follow from

ˆQ
ˆS
ˆSt
ˆR

= 1
j

ρwi
ρwi+1
···
ρwi+j−1
ρvi
ρvi+1
···
ρvi+j−1

ρwi
ρwi+1
···
ρwi+j−1
ρvi
ρvi+1
···
ρvi+j−1
t
,
(3.99)
where
ρwk = ˆxk+1 −ˆAˆxk −ˆBuk,
ρvk = yk −ˆC ˆxk −ˆDuk
(k = i,...,i + j −1)
are the least squares residuals.
2. Subspace system identiﬁcation algorithms make full use of the well developed
body of concepts and algorithms from numerical linear algebra. Numerical ro-
bustness is guaranteed because of the well-understood algorithms, such as the

3.4
Subspace Identiﬁcation Method
59
QR-decomposition, the singular value decomposition and its generalizations.
Therefore, they are very well suited for large data sets (s →∞) and large scale
systems (m, ℓ, n large). Moreover, subspace algorithms are not iterative. Hence,
there are no convergence problems. When carefully implemented, they are com-
putationally very efﬁcient, especially for large datasets.
3. The conceptual layout of subspace identiﬁcation algorithms translates into user
friendly software implementations. Recall that there is no explicit need for pa-
rameterizations in the geometric framework of subspace identiﬁcation. Thus, the
user is not confronted with highly technical and theoretical issues such as canoni-
cal parameterizations. The number of user choices is greatly reduced when using
subspace algorithms because we use full state space models and the only parame-
ter to be speciﬁed by the user, is the order of the system, which can be determined
by inspection of certain singular values.
3.4.2 Block Hankel Matrices and State Sequences
Block Hankel matrices with output and/or input data play an important role in sub-
space identiﬁcation algorithms. These matrices can be easily constructed from the
given input–output data. Input block Hankel matrices are deﬁned as
U0|2i−1 =:
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
u0
u1
u2
···
uj−1
u1
u2
u3
···
uj
...
...
...
···
...
ui−1
ui
ui+1
···
ui+j−2
ui
ui+1
ui+2
···
ui+j−1
ui+1
ui+2
ui+3
···
ui+j
...
...
...
···
...
u2i−1
u2i
u2i+1 ··· u2i+j−2
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
=

 U0|i−1
Ui|2i−1

=

Up
Uf

(3.100)
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
u0
u1
u2
···
uj−1
u1
u2
u3
···
uj
...
...
...
···
...
ui−1
ui
ui+1
···
ui+j−2
ui
ui+1
ui+2
···
ui+j−1
ui+1
ui+2
ui+3
···
ui+j
...
...
...
···
...
u2i−1
u2i
u2i+1 ··· u2i+j−2
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
=

U0|i
Ui+1|2i−1

=

U+
p
U−
f

(3.101)
where:
• The number of block rows (i) is a user-deﬁned index which is large enough, that
is, it should at least be larger than the maximum order of the system one wants to

60
3
System Identiﬁcation Methods
identify. Note that, since each block row contains in (number of inputs) rows, the
matrix U0|2i−1 consists of 2mi rows.
• The number of columns (j) is typically equal to s −2i + 1, which implies that
all s available data samples are used. In any case, j should be larger than 2i −1.
Throughout the paper, for statistical reasons, we will often assume that j,s →∞.
For deterministic (noiseless) models, that is, where vk ≡0 and wk ≡0, this will
however not be needed.
• The subscripts of U0|2i−1, U0|i−1, U0|i, Ui|2i−1, etc., denote the subscript of the
ﬁrst and last element of the ﬁrst column in the block Hankel matrix. The sub-
script “p” stands for “past” and the subscript “f ” for “future”. The matrices Uρ
(the past inputs) and Uf (the future inputs) are deﬁned by splitting U0|2i−1 in
two equal parts of i block rows. The matrices U+
p and U−
f on the other hand are
deﬁned by shifting the border between past and future one block row down. They
are deﬁned as U+
p = U0|i and U−
f = Ui+1|2i−1, where the superscript “+” stands
for “add one block row” while the superscript “−” stands for “delete one block
row”. The output block Hankel matrices Y0|2i−1, Yρ, Yf , Y +
ρ , Y −
f are deﬁned in
a similar way. State sequences play an important role in the derivation and inter-
pretation of subspace identiﬁcation algorithms. The state sequence Xi is deﬁned
as:
Xi := (xi
xi+1
···
xi+j−2
xi+j−1) ∈ℜn×j,
(3.102)
where the subscript i denotes the subscript of the ﬁrst element of the state se-
quence.
3.4.3 Model Matrices
Subspace identiﬁcation algorithms make extensive use of the observability and of
its structure. The extended (i > n) observability matrix Γi (where the subscript i
denotes the number of block rows) is deﬁned as:
Γi :=
⎡
⎢⎢⎢⎢⎢⎣
C
CA
CA2
...
CAi−1
⎤
⎥⎥⎥⎥⎥⎦
∈ℜℓi×n.
(3.103)
We assume henceforth that the pair {A,C} to be observable, which implies that the
rank of Γi is equal to n.
3.4.4 Orthogonal Projections
In the following sections, we introduce the main geometric tools used to reveal some
system characteristics. They are described from a linear algebra point of view, inde-
pendently of the subspace identiﬁcation framework. For simplicity in exposition, we

3.4
Subspace Identiﬁcation Method
61
assume that the matrices A ∈ℜρ×j, B ∈ℜq×j and C ∈ℜr×J are given and are of
local use in this section. We also assume that j ≥max(p,q,r), which will always
be the case in the identiﬁcation algorithms.
Recall that the orthogonal projection of the row space of A into the row space of
B is denoted by A/B and its matrix representation is
A/B := ABt
BBt†B,
(3.104)
where † denotes the Moore–Penrose pseudo-inverse of the matrix and A/B⊥is
the projection of the row space of A into B⊥, the orthogonal complement of the
row space of B, for which we have A/B⊥= A −A/B = A(Ij −B(BBt)†B). The
projections ΠB and ΠB† decompose a matrix A into two matrices, the row spaces
of which are orthogonal:
A = AΠB + AΠB⊥.
(3.105)
The matrix representations of these projections can be easily computed via the LQ
decomposition of

B
A

which is the numerical matrix version of the Gram–Schmidt orthogonalization pro-
cedure.
Let A and B be matrices of full row rank and let the LQ decomposition of
 B
A

be denoted by

B
A

= LQt =

L11
0
L21
L22

Qt
1
Qt
2

,
(3.106)
where L ∈ℜ(p+q)×(p+q) is lower triangular, with L11 ∈ℜq×q, L21 ∈ℜp×q, L22 ∈
ℜp×p and Q ∈ℜj×(p+q) is orthogonal, that is,
QtQ =

Qt
1
Qt
2
Q1
Q2

=

Iq
0
0
Ip

.
Then, the matrix representations of the orthogonal projections can be written as
A/B = L21Qt
1,
(3.107)
A/B⊥= L22Qt
2.
(3.108)
3.4.5 Oblique Projections
Instead of decomposing the rows of A as in (3.105) as a linear combination of the
rows of two orthogonal matrices (ΠB and ΠB†), they can also be decomposed as
a linear combination of the rows of two non-orthogonal matrices B and C and of
the orthogonal complement of B and C. This can be written as A = LBB + LcC +

62
3
System Identiﬁcation Methods
Fig. 3.9 Interpretation of
oblique projection in the
j-dimensional space (j = 3)
LB⊥,C⊥
 B
C
⊥. The matrix LCC is deﬁned as the oblique projection of the row space
of A along the row space of B into the row space of C:
A/BC := LCC.
(3.109)
Note that LB and Lc are only unique when B and C are of full row rank and when
the intersection of the row spaces of B and C is {0}, said in other words, rank
 B
C

=
rank(B) + rank(C) = q + r. The oblique projection can also be interpreted through
the following recipe: project the row space of A orthogonally into the joint row
space of B and C and decompose the result along the row space of B and C. This
is illustrated in Fig. 3.9 for j = 3 and p = q = r = 1, where A/
 B
C

denotes the
orthogonal projection of the row space of A into the joint row space of B and C,
A/BC is the oblique projection of A along B into C and A/CB is the oblique
projection of A along C into B.
Let the LQ decomposition of
 B
C
A

be given by
⎡
⎣
B
C
A
⎤
⎦=
⎡
⎣
L11
0
0
L21
L22
0
L31
L32
L33
⎤
⎦
⎡
⎢⎣
Qt
1
Qt
2
Qt
3
⎤
⎥⎦.
Then, the matrix representation of the orthogonal projection of the row space of A
into the joint row space of B and C is equal to:
A/

B
C

=
L31
L32

Qt
1
Qt
2

.
(3.110)
It is obvious that the orthogonal projection of A into
 B
C

can also be written as a
linear combination of the rows of B and C:
A/

B
C

= LBB + LCC =
LB
LC

L11
0
L21
L22

Qt
1
Qt
2

.
(3.111)
Equating (3.110) and (3.111) leads to
LB
LC

L11
0
L21
L22

=
L31
L32

.
(3.112)
The oblique projection of the row space of A along the row space of B into the row
space of C can thus be computed as

3.4
Subspace Identiﬁcation Method
63
A/BC = LCC = L32L−1
22
L21
L22

Qt
1
Qt
2

.
(3.113)
Note that when B = 0 or when the row space of B is orthogonal to the row space
of C(BCt = 0) the oblique projection reduces to an orthogonal projection, in which
case A/BC = A/C.
3.4.6 Deterministic Subspace Identiﬁcation
In what follows, we treat subspace identiﬁcation of purely time- invariant deter-
ministic systems, with no measurement nor process noise (vk ≡0 and wk ≡0 in
Fig. 3.7).
Calculation of a State Sequence
The state sequence of a deterministic system can be found by computing the inter-
section of the past input and output and the future input and output spaces. This can
be seen as follows. Consider wk and vk in (3.95) to be identically 0, and derive the
following matrix input–output equations:
Y0|i−1 = ΓiXi + HiU0|i−1,
(3.114)
Yi|2i−1 = ΓiX2i + HiUi|2i−1,
(3.115)
in which Hi is an li × mi lower block Triangular Toeplitz matrix with the so-called
Markov parameters of the system:
Hi =
⎡
⎢⎢⎢⎢⎢⎣
D
0
0
···
0
CB
D
0
···
0
CAB
CB
D
···
0
...
...
...
...
...
CAi−2B
CAi−3B
···
···
D
⎤
⎥⎥⎥⎥⎥⎦
.
From this, we ﬁnd that

 Y0|i−1
U0|i−1

=

Γi
Hi
0
Imi

Xi
U0|i−1

,
(3.116)
from which we get
rank

 Y0|i−1
U0|i−1

= rank

Xi
U0|i−1

.

64
3
System Identiﬁcation Methods
Hence,
rank

 Y0|i−1
U0|i−1

= mi + n
provided that U0|i−1 is of full row rank. In the sequel, we assume throughout that
j ≫mi, that there is no intersection between the row spaces of Xi and that of U0|i−1
and that the state sequence is of full row rank as well ‘full state space excited’. These
are experimental conditions that are generically satisﬁed and that can be considered
as ‘persistency-of-excitation’ requirements for subspace algorithms to work.
A similar derivation under similar conditions can be done for
rank

 Yi|2i−1
Ui|2i−1

= mi + n,
rank

 Y0|2i−1
U0|2i−1

= 2mi + n.
We can also relate X2i to Xi as
X2i = AiXi + Δr
i U0|i−1,
(3.117)
in which Δr
i = (Ai−1BAi−2B ···ABB) is a reversed extended controllability ma-
trix. Assuming that the model is observable and that i ≥n, we ﬁnd from (3.115)
that
X2i =

−Γ †
i Hi
Γ †
i

Ui|2i−1
Yi|2i−1

,
which implies that the row space of X2i is contained within the row space of

Uf
Yf

.
Similarly, from (3.117) and (3.114) we ﬁnd that
X2i = Ai
Γ †
i Y0|i−1
−Γ †
i HiU0|i−1

+ Δr
i U0|i−1
=

Δr
i −AiΓ †
i Hi
AiΓ †
i

U0|i−1
Y0|i−1

,
which implies that the row space of X2i is equally contained within the row space
of

Up
Yp

.
Let’s now apply Grassmann’s dimension theorem (under the generic assumptions
on persistency of excitation)
dim

row space

Up
Yp

∩row space

Uf
Yf

rank

Up
Yp

(3.118)
+rank

Uf
Yf

−rank
⎡
⎢⎢⎣
Up
Yp
Uf
Yf
⎤
⎥⎥⎦
(3.119)
= (mi + n) + (mi + n) −(2mi + n) = n.
(3.120)

3.4
Subspace Identiﬁcation Method
65
Indeed, above we have shown that any basis for the intersection between ‘past’ and
‘future’ represents a valid state sequence Xi. The state sequence Xi+1 can be ob-
tained analogously. Different ways to compute the intersection have been proposed.
A ﬁrst way, is by making use of a singular value decomposition of a concatenated
Hankel matrix

U0|2i−1
Y0|2i−1

.
This allows to estimate the model order n and to calculate the linear combination of
the rows of

Up
Yp

or equivalently of

Uf
Yf

that generate the intersection. A second way is by taking as a basis for the intersec-
tion the principal directions between the row space of the past inputs and outputs
and the row space of the future inputs and outputs. A nonempty intersection between
two subspaces is characterized by a number of principal angles equal to zero, and
the principal directions corresponding to these zero angles form a basis for the row
space of the intersection.
Computing the System Matrices
As soon as the order of the model and the state sequences X, and Xi+1 are known,
the state space matrices A, B, C, D can be solved from

xi+1
yi|i

  
known
=

A
B
C
D

 xi
Ui|i

  
known
,
(3.121)
where Ui|i, Yi|i are block Hankel matrices with only one block row of inputs respec-
tively outputs, namely Ui|i = (ui ui+1 ··· ui+j−1) and similarly for Yi|i. This set
of equations can be solved. As there is no noise, it is consistent.
3.4.7 Stochastic Subspace Identiﬁcation
In this section, we treat subspace identiﬁcation of linear time-invariant stochastic
systems with no external input (uk ≡0). The stochastic identiﬁcation problem thus
consists of estimating the stochastic system matrices A, C, Q, S, R from given
output data only. We show how this can be done using geometric operations. In the
next part, we show how a state sequence can be found and in the following part the
system matrices are computed.

66
3
System Identiﬁcation Methods
Calculation of a State Sequence
The state sequence of a stochastic model can be obtained in two steps: ﬁrst, the
future output space is projected orthogonally into the past output space and next, a
singular value decomposition is carried out.
1. Orthogonal Projection: As explained in Sect. 3.4.4, we will use the LQ decom-
position to compute the orthogonal projection. Let Y0|2i−1 be the 2ℓi × j output
block Hankel matrix. Then, we partition the LQ decomposition of Y0|2i−1 as fol-
lows
⎡
⎣
Y0|i−1
Yi|i
Yi+1|2i−1
⎤
⎦=
⎡
⎣
L11
0
0
L21
L22
0
L31
L32
L33
⎤
⎦
⎡
⎢⎣
Qt
1
Qt
2
Qt
3
⎤
⎥⎦
(3.122)
where Y0|i−1 ∈ℜℓi, Yi|i ∈ℜℓ, Yi+1|2i−1 ∈ℜℓ(i−1), L11 ∈ℜℓi×ℓi, L21 ∈ℜℓ×ℓi,
L22 ∈ℜℓ×ℓ, L31 ∈ℜℓ(i−1)×ℓi, L32 ∈ℜℓ(i−1)×ℓ, L33 ∈ℜℓ(i−1)×ℓ(i−1).
At this stage, we need two projections. The orthogonal projection Yf /Yp of
the future output space into the past output space, which is denoted by Oi, and the
orthogonal projection Y −
f /Y +
p of Y −
f into Y +
p , denoted by Oi−1, see Sect. 3.4.2
for the deﬁnitions of Yp, Yf , Y +
p and Y −
f . Now, applying (3.107) leads to
Oi = Yf /Yp =

L21
L31

Qt
1,
Oi−1 = Y −
f /Y +
p =
L31
L32

Qt
1
Qt
2

.
(3.123)
It can be shown that the matrix Oi, is equal to the product of the extended ob-
servability matrix and a matrix ˆXi, which contains certain Kalman ﬁlter states.
Thus,
Oi = Γi ˆXi,
(3.124)
where Γi is the li × n observability matrix, see (3.103) and
ˆXi =

ˆx[0]
i
ˆx[1]
i
···
ˆx[j−1]
i

.
Similarly, Oi−1 is equal to
Oi−1 = Γi−1 ˆXi+1,
(3.125)
where ˆXi+1 = [ ˆx[0]
i+1 ˆx[1]
i+1 ··· ˆx[j−1]
i+1
].
2. Singular Value Decomposition: The singular value decomposition of 0i, allows
us to ﬁnd the order of the model (the rank of Oi), and the matrices Γi and ˆXi.
Let the singular value decomposition of
 L21
L31

be equal to

L21
L31

=
U1
U2

S1
0
0
0

V t
1
V t
2

= U1S1V t
1,
(3.126)

3.4
Subspace Identiﬁcation Method
67
ˆX0 =

0
···
0
···
0

ˆP0 = 0
Kalman Filter
y0
↓
yq
↓
yj−1
↓
Yp
...
↓
...
↓
...
↓
yi−1
↓
yi+q−1
↓
yi+j−2
↓
ˆXi =

ˆx[0]
i
···
ˆx[q]
i
···
ˆx[j−1]
i

Fig. 3.10 Interpretation of the sequence ˆXi
where U1 ∈ℜli×n, S1 ∈ℜn×n, and V1 ∈ℜli×n. Then, we can choose Γi =
U1S1/2
1
and ˆXi = S1/2
1
V t
1Qt
1. This state sequence is generated by a bank of non-
steady state Kalman ﬁlters working in parallel on each of the columns of the
block Hankel matrix of past outputs Yp. The j Kalman ﬁlters run in a vertical di-
rection (over the columns). It should be noted that each of these j Kalman ﬁlters
only uses partial output information. The qth Kalman ﬁlter (q = 0,...,j −1)
ˆx[q]
k+1 = (A −KkC)ˆx[q]
k
+ Kkyk+q,
(3.127)
runs over the data in the qth column of Yp, for k = 0,1,...,i −1.
The “shifted” state sequence ˆXi+1, on the other hand, can be obtained as
ˆXi+1 = ( ˆΓi)†Oi−1,
(3.128)
where ˆΓi = Γi−1 denotes the matrix Γi without the last ℓrows, which is also
equal to ˆU1S1/2
1
. In Fig. 3.10, an interpretation of the sequence ˆXi as a sequence
of nonsteady state Kalman ﬁlter estimates based upon i observations of yk is
given. When the system matrices A, C, Q, R, S were known, the state ˆx[q]
i
could be determined from a non-steady state Kalman ﬁlter as follows: Start the
ﬁlter at time q, with an initial state estimate 0. Next, iterating the nonsteady
state Kalman ﬁlter over i time steps (as indicated by the vertical arrow down).
The Kalman ﬁlter will then return a state estimate ˆx[q]
i
. This procedure could
be repeated for each of the j columns, and thus we speak about a bank of non-
steady state Kalman ﬁlters. The major observation in subspace algorithms is that
the system matrices A, C, Q, R, S do not have to be known to determine the state
sequence ˆXi. It can be determined directly from output data through geometric
manipulations.
Computing the System Matrices
At this moment, we have calculated ˆXi and ˆXi+1, using geometrical and numerical
operations on output data only. We can now form the following set of equations:

 ˆXi+1
Yi|i

  
known
=

A
C

[ ˆXi ]

known
+

ρw
ρv

  
residuals
,
(3.129)

68
3
System Identiﬁcation Methods
where Yi|i is a block Hankel matrix with only one block row of outputs. This set of
equations can be easily solved for A, C. Since the Kalman ﬁlter residuals ρw, ρv,
(the innovations) are uncorrelated with ˆXi, solving this set of equations in a least
squares sense (since the least squares residuals are orthogonal and thus uncorrelated
with the regressors ˆXi) results in an asymptotically (as j →∞) unbiased estimate
ˆA, ˆC of A, C as

 ˆA
ˆC

=

 ˆXi+1
Yi|i

ˆX†
i .
An estimate ˆQi, ˆSi, ˆRi of the noise covariance matrices Q, S and R can be obtained
from the residuals:

ˆQi
ˆSi
ˆSt
i
ˆRi

= 1
j

ρw
ρv
ρt
w ρt
v

where the subscript i indicates that the estimated covariances are biased, with how-
ever an exponentially decreasing bias as i →∞.
By making the following substitutions:
ˆXi = Γ †
i Oi = S1/2
1
V t
1Qt
1,
(3.130)
ˆXi+1 = Γ †
i−1Oi−1 = ( ˆΓi)†Oi−1 =
 ˆU1S1/2
1
†(L31
L32)

Qt
1
Qt
2

,
(3.131)
Yi|i = (L21
L22)

Qt
1
Qt
2

(3.132)
the least squares solution reduces to

 ˆA
ˆC

=

[ ˆU1S1/2
1
]†L31
L21

V1S−1/2
1
,
(3.133)
and the noise covariances are equal to

ˆQi
ˆSi
ˆSt
i
ˆRi

= 1
j

[ ˆU1S1/2
1
]†L31
[ ˆU1S1/2
1
]†L32
L21
L22

I −V1V t
1
0
0
I

×

Lt
31[S1/2
1
( ˆU1)t]†
Lt
21
Lt
32[S1/2
1
( ˆU1)t]†
Lt
22

.
(3.134)
Note that the Q-matrices of the LQ factorization cancel out of the least-squares
solution and the noise covariances. This implies that in the ﬁrst step, the Q-matrix
should never be calculated explicitly. Since typically j ≫2mi, this reduces the com-
putational complexity and memory requirements signiﬁcantly.
3.4.8 Combined Deterministic-Stochastic Algorithm
Hereafter, we give one variant of subspace algorithms, for the identiﬁcation of
A, B, C, D, Q, R, S.

3.4
Subspace Identiﬁcation Method
69
Other variants can be found in the literature. The algorithm works in two main steps.
First, the row space of a Kalman ﬁller state sequence is obtained directly from the
input–output data, without any knowledge of the system matrices. In the second
step, the system matrices are extracted from the state sequence via a least squares
problem.
Calculation of a State Sequence
The state sequence of a combined deterministic-stochastic model can again be ob-
tained from input output data in two steps. First, the future output row space is
projected along the future input row space into the joint row space of past input and
past output. A singular value decomposition is carried out to obtain the model order,
the observability matrix and a state sequence, which has a very precise and speciﬁc
interpretation.
1. Oblique projection: We will use the LQ decomposition to compute the oblique
projection Yf /Uf
 Up
Yp

. Let U0|2i−1 be the 2mi × j and Y0|2i−1 the 2li × j block
Hankel matrices of the input and output observations. Then, we partition the LQ
decomposition of
 U
Y

as follows
⎡
⎢⎢⎢⎢⎢⎢⎣
U0|i−1
Ui|i
Ui+1|2i−1
Y0|i−1
Yi|i
Yi+1|2i−1
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
L11
0
0
0
0
0
L21
L22
0
0
0
0
L31
L32
L33
0
0
0
L41
L42
L43
L44
0
0
L51
L52
L53
L54
L55
0
L61
L62
L63
L64
L65
L66
⎤
⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
Qt
1
Qt
2
Qt
3
Qt
4
Qt
5
Qt
6
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
.
(3.135)
The matrix representation of the oblique projection Yf /Uf
 Up
Yp

of the future out-
put row space along the future input row space into the joint space of past input
and past output is denoted by Oi. Analogously to the derivation in Sect. 3.4.5,
the oblique projection can be obtained as
Oi = Yf /Uf

Up
Yp

= LUpL11Qt
1 + LYp
L41
L42
L43
L44

⎡
⎢⎢⎢⎣
Qt
1
Qt
2
Qt
3
Qt
4
⎤
⎥⎥⎥⎦,
(3.136)
where
LUp
LUf
LYp

⎡
⎢⎢⎣
L11
0
0
0
L21 L22
0
0
L31 L32
L33
0
L41 L42
L43 L44
⎤
⎥⎥⎦=

L51 L52
L53 L54
L61 L62
L63 L64

(3.137)

70
3
System Identiﬁcation Methods
from which LUp, LUf and LYp can be calculated. On the other hand, the oblique
projection
Y −
f /U−
f

U+
p
Y +
p

denoted by Oi−1, is equal to
Oi = LU+
p

L11
0
L21
L22

Qt
1
Qt
2

+ LY +
p

L41
L42
L43
L44
0
L51
L52
L53
L54
L55

⎡
⎢⎢⎢⎢⎢⎣
Qt
1
Qt
2
Qt
3
Qt
4
Qt
5
⎤
⎥⎥⎥⎥⎥⎦
,
(3.138)
where
LU+
p
LU−
f
LY +
p

⎡
⎢⎢⎢⎢⎣
L11
0
0
0
0
L21 L22
0
0
0
L31 L32 L33
0
0
L41 L42 L43 L44
0
L51 L52 L53 L54 L55
⎤
⎥⎥⎥⎥⎦
=
L61 L62 L63 L64 L65

.
(3.139)
Under the assumptions that
a. the process noise Wk and measurement noise vk are uncorrelated with the
input uk,
b. the input uk is persistently exciting of order 2i, that is, the input block Hankel
matrix U0|2i−1 is of full row rank,
c. the sample size goes to inﬁnity: j →∞,
d. the process noise wk and the measurement noise vk are not identically zero,
one can show that the oblique projection Oi is equal to the product of the ex-
tended observability matrix Γi and a sequence of Kalman ﬁlter states, obtained
from a bank of nonsteady state Kalman ﬁlters, in essence the same as in Fig. 3.10:
Oi = Γi ˜Xi.
(3.140)
Similarly, the oblique projection Oi−1 is equal to
Oi−1 = Γi−1 ˜Xi+1.
(3.141)
2. Singular value decomposition: Let the singular value decomposition of
LUp
L11
0
0
0
+ LYp
L41
L42
L43
L44

be equal to
LUp
L11
0
0
0
+ LYp
L41
L42
L43
L44

=
U1
U2

S1
0
0
0

V t
1
V t
2

(3.142)
= U1S1V t
1.
(3.143)

3.4
Subspace Identiﬁcation Method
71
Then, the order of the system (3.95) is equal to the number of singular values in
(3.142) different from zero. The extended observability matrix Γi can be taken
to be
Γi = U1S1/2
1
,
(3.144)
and the state sequence ˜Xi is equal to
˜Xi = Γ †
i Oi = S1/2
1
V t
1
⎡
⎢⎢⎢⎣
Qt
1
Qt
2
Qt
3
Qt
4
⎤
⎥⎥⎥⎦.
(3.145)
The “shifted” state sequence ˜Xi+1, on the other hand, can be obtained as
˜Xi+1 = ( ˜Γi)†Oi−1,
(3.146)
where ˜Γi = Γi−1 denotes the matrix Γi without the last l rows.
There is an important observation to be made. Corresponding columns of ˜Xi and
of ˜Xi+1 are state estimates of Xi and Xi+1 respectively, obtained from the same
Kalman ﬁlters at two consecutive time instants, but with different initial conditions.
This is in contrast to the stochastic identiﬁcation algorithm, where the initial states
are equal to 0, see Fig. 3.10.
Computing the System Matrices
From Sect. 3.4.8, we ﬁnd that:
• The order of the system from inspection of the singular values of (3.142).
• The extended observability matrix Γi; from (3.144) and the matrix Γi−1 as ˜Γi,
where ˜Γi denotes the matrix Γi without the last ℓrows.
• The state sequences ˜Xi and ˜Xi+1.
The state space matrices A, B, C and D can now be found by solving a set of
over-determined equations in a least squares sense:

˜Xi+1
˜Yi|i

=

 ˆA
ˆB
ˆC
ˆD

 ˜Xi
Ui|i

+

ρw
ρv

,
(3.147)
where ρw and ρv are residual matrices. The estimates of the covariances of the
process and measurement noise are obtained from the residuals ρw and ρv of (3.147)
as:
 ˆQi
ˆSi
ˆSt
i
ˆRi

= 1
j

ρw
ρv
ρt
w
ρt
v

,
(3.148)
where i again indicates that the estimated covariances are biased, with an exponen-
tially decreasing bias as i →∞. As in the stochastic identiﬁcation algorithm, the

72
3
System Identiﬁcation Methods
Q-matrices of the LQ factorization cancel out in the least-squares solution and the
computation of the noise covariances. This implies that the Q-matrix of the LQ fac-
torization should never be calculated explicitly. Note however, that corresponding
columns of ˜Xi and of ˜Xi+1 are state estimates of Xi and Xi+1 respectively, obtained
with different initial conditions. As a consequence, the set of relations (3.147) is not
theoretically consistent, which means that the estimates of the system matrices are
slightly biased. It can however be proven that the estimates of A, B, C and D are
unbiased if at least one of the following conditions is satisﬁed:
• i →∞,
• the system is purely deterministic, that is, vk = wk = 0, ∀k,
• the deterministic input uk is white noise.
If none of the above conditions is satisﬁed, one obtains biased estimates. However,
there exist more involved algorithms that provide consistent estimates of A, B, C
and D, even if none of the above conditions is satisﬁed, for which we refer to the
literature.
3.4.9 Variations
Several variants on the algorithm that was explained above, exist. First, we note that
the oblique projection Oi can be weighted left and right by user deﬁned weighting
matrices W1 ∈ℜli×li and W2 ∈ℜj×j respectively, which should satisfy the follow-
ing conditions: W1 should be of full rank and the rank of

Up
Yp

W2
should be equal to the rank of

Up
Yp

.
Furthermore, one can distinguish between two classes of subspace identiﬁcation
algorithms. The ﬁrst class uses the state estimates ˜Xi (the right singular vectors
of W1O1W2) to ﬁnd the system matrices. The algorithm in Sect. 3.146 belongs to
this class. The second class of algorithms uses the extended observability matrix Γi
(the left singular vectors of W1OiW2) to ﬁrst determine estimates of A and C and
subsequently of B, D and Q, S, R.
Remark 3.3 It can be shown that three subspace algorithms that have been described
in the literature (N4SID, MOESP and CVA) all start from W1OiW2 with for each
of the algorithms a speciﬁc choice of weighting matrices Wl and W2. The results
are summarized in Table 3.1. From this table, it is clear that the algorithm de-
scribed above is the N4SID algorithm (W1 = Ili and W2 = Ij). The acronym N4SID
stands for “Numerical algorithms for Subspace State Space System IDentiﬁcation”,
MOESP for “Multivariable Output-Error State sPace” and CVA is the acronym of
“Canonical Variate Analysis”.

3.5
Output-Error Parametric Model Identiﬁcation
73
Table 3.1 Interpretations of
different existing subspace
identiﬁcation algorithms
Acronym
W1
W2
N4SID
Ili
Ij
CVA
(limj→∞[(Yf /U⊥
f )(Yf /U⊥
f )t])−1/2
ΠU⊥
f
MOESP
Ili
ΠU⊥
f
Remark 3.4 In Table 3.1, we give interpretations of different existing subspace iden-
tiﬁcation algorithms in a unifying framework. All these algorithms ﬁrst calculate an
oblique projection Oi followed by an SVD of the weighted matrix W1OiW2. The
ﬁrst two algorithms, N4SID and CVA, use the state estimates ˜Xi (the right singular
vectors) to ﬁnd the system matrices, while MOESP is based on the extended observ-
ability matrix Γi (the left singular vectors). The matrix U⊥
f in the weights of CVA
and MOESP represents the orthogonal complement of the row space of Uf .
3.5 Output-Error Parametric Model Identiﬁcation
After studying this chapter, you will be able to
• describe the output-error model-estimation problem;
• parameterize the system matrices of a MIMO LTI state-space model of ﬁxed and
known order such that all stable models of that order are presented;
• formulate the estimation of the parameters of a given system parameterization as
a nonlinear optimization problem;
• numerically solve a nonlinear optimization problem using gradient-type algo-
rithms;
• evaluate the accuracy of the obtained parameter estimates via their asymptotic
variance under the assumption that the signal-generating system belongs to the
class of parameterized state space models; and
• describe two ways for dealing with a nonwhite noise acting on the output of an
LTI system when estimating its parameters.
3.5.1 Introduction
Hereafter, we move another step forward in our exploration of how to retrieve in-
formation about linear time-invariant (LTI) systems from input and output mea-
surements. The step forward is taken by analyzing how we can estimate (part of) the
system matrices of the signal-generating model from acquired input and output data.
We ﬁrst tackle this problem as a complicated estimation problem by attempting to
estimate both the state vector and the system matrices.
This section presents an introduction to estimating the parameters in a user-
deﬁned LTI model. In this chapter, we start with the determination of a model to

74
3
System Identiﬁcation Methods
approximate the deterministic relation between measurable input and output se-
quences. The uncertainties due to noises acting on the system are assumed to be
lumped together as an additive perturbation at the output. Therefore, the estimation
methods presented in this chapter are referred to as the output-error methods. In
Chap. 8, we deal with the approximation of both the deterministic and the stochas-
tic parts of the system’s response, using an innovation model.
The reason for dealing with output-error methods for the analysis of estimating
the parameters of a parametric model of an LTI system is twofold. First, in a num-
ber of applications, only the deterministic transfer from the measurable input to the
output is of interest. An example is identiﬁcation-based fault diagnosis, in which the
estimated parameters of the deterministic part of the model are compared with their
nominal “fault-free” values. Second, the restriction to the deterministic part simpli-
ﬁes the discussion and allows us to highlight how the estimation of parameters in an
LTI model can be approached systematically. This systematic approach. which lies
at the heart of many identiﬁcation methods, is introduced in Sect. 3.5.2 and consists
of the following four steps. The ﬁrst step is parameterizing the model; that is, the
selection of which parameters to estimate in the model. For MIMO LTI state-space
models, some parameterizations and their properties are discussed in Sect. 3.5.3.
Step two consists of formulating the estimation of the model parameters as an op-
timization problem. Section 3.5.4 presents such an optimization problem with the
widely used least-squares cost function. Step three is the selection of a numerical
procedure to solve the optimization problem iteratively. Methods for minimizing a
least-squares cost function are presented in Sect. 3.5.5. The ﬁnal step is evaluation
of the accuracy of the obtained estimates via the covariance matrix of the estimates.
This is discussed in Sect. 3.5.6. In these four steps, it is assumed that the additive
error to the output is a zero-mean white noise. Section 3.5.7 discusses the treatment
of colored additive noise.
3.5.2 Problems in Estimating Parameters
Consider the signal-generating LTI system to be identiﬁed, given by
y(k) = G(q)u(k) + v(k),
(3.149)
where v(k) represents measurement noise that is statistically independent from the
input u(k). Then a general formulation of the output-error (OE) model-estimation
problem is as follows.
Given a ﬁnite number of samples of the input signal u(k) and the output signal
y(k) and the order of the following predictor,
ˆx(k + 1) = Aˆx(k) + Bu(k),
(3.150)
ˆy(k) = C ˆx(k) + Du(k)
(3.151)
the goal is to estimate a set of system matrices A, B, C, and D in this predictor such
that the output
ˆ
y(k) approximates the output of the system (3.149).

3.5
Output-Error Parametric Model Identiﬁcation
75
First, we consider the case in which v(k) is a white-noise sequence. In Sect. 3.5.7,
we then consider the more general case in which v(k) is colored noise.
A common way to approach this problem is to assume that the entries of the sys-
tem matrices depend on a parameter vector θ and to estimate this parameter vector.
The parameterized predictor model based on the system (3.150)–(3.151) becomes
ˆx(k + 1,θ) = A(θ)ˆx(k,θ) + B(θ)u(k),
(3.152)
ˆy(k,θ) = C(θ)ˆx(k,θ) + D(θ)u(k).
(3.153)
Note that the output data ˆy(k,θ) depends not only on the input and the parameters θ
used to parameterize the system matrices A(θ), B(θ), C(θ), and D(θ), but also
on the initial state ˆx(0) of the model (3.152)–(3.153). Therefore, the initial state is
often also regarded as a parameter and added to the parameter vector θ. The notation
ˆx(0,θ) is used to denote the treatment of the initial state as a part of the parameter
vector θ.
The problem of estimating the parameter vector θ can be divided into four parts.
1. This concerns the determination of a parameterization. A parameterization of
the system (3.152)–(3.153) is the speciﬁcation of the dependence of the system
matrices on the parameter vector θ. One widely used approach to parameterize
systems is to use unknown physical constants in a mathematical model derived
from the laws of physics, such as Newton’s or Kirchoff’s laws. An example of
such a parameterization is given below in identiﬁcation example 3.1.
2. This concerns the selection of a criterion to judge the quality of a particular value
of θ. In the foregoing sections, we consider a quadratic error criterion of the form
1
N
N−1

k=0
y(k) −ˆy(k,θ)
2
2,
(3.154)
with ˆy(k,θ) given by (7.4) and (7.5). For each particular value of the param-
eter vector θ, this criterion has a positive value. The optimality may therefore
be expressed by selecting that parameter value that yields the minimal value of
(3.154). Though such a strategy is a good starting point, a more detailed consid-
eration is generally necessary in order to ﬁnd the most appropriate model for a
particular application.
3. This concerns the numerical minimization of the criterion (3.154). Let the “op-
timal” parameter vector ˆθN be the argument θ of the cost function (3.154) that
minimizes this cost function; this is denoted by
ˆθN = argmin 1
N
N−1

k=0
y(k) −ˆy(k,θ)
2
2.
(3.155)
As indicated by (3.152)–(3.153), the prediction ˆy(k,θ) of the output is a ﬁl-
tered version of the input u(k) only. A method that minimizes a criterion of the
form (3.154), where ˆy(k,θ) is based on the input only, belongs to the class of
output-error methods [54]. The Kalman ﬁlter discussed in Chap. 5 determines a
prediction of the output by ﬁltering both the input u(k) and the output y(k). A
speciﬁc interpretation of the criterion (3.155) will be given in due course.

76
3
System Identiﬁcation Methods
Fig. 3.11 The output-error
model-estimation method
4. This concerns the analysis of the accuracy of the estimate θN. Since the mea-
surements y(k) are assumed to be stochastic processes, the derived parameter
estimate ˆθN obtained via optimizing (3.154) will be a random variable. There-
fore, a measure of its accuracy could be its bias and covariance.
The above four problems, which are analyzed in the listed order in Sects. 3.5.3–
3.5.6, aim, loosely speaking, at determining the “best” predictor such that the dif-
ference between the measured and predicted output is made “as small as possible.”
The output-error approach is illustrated in Fig. 3.11.
3.5.3 Identiﬁcation Example 3.1
The electrical-mechanical equations describing a permanent-magnet synchronous
motor (PMSM) were derived in [72]. These equations are used to obtain a model
of a PRISM and summarized below, Fig. 3.12 shows a schematic drawing of the
PMSM, The magnet, marked with its north and south poles, is turning and along
with it is the rotor reference frame indicated by the d-axis and q-axis. In the model,
the following physical quantities are used:
• (id,iq) are the currents and (vd,vq) are the voltages with respect to the rotor
reference frame;
• α is the rotor position and ω its velocity;
• TL represents the external load;
• N is the number of magnetic pole pairs in the motor;
• R is the phase resistance;
• Ld and Lq are the direct- and quadrature-axis inductances, respectively;
• φa is the permanent magnetic constant; and
• J is the rotor inertia.
On the basis of these deﬁnitions the physical equations describing a PMSM are [72]
˙id = −R
Ld
id + NωLq
Ld
iq + 1
Ld
vd,
(3.156)

3.5
Output-Error Parametric Model Identiﬁcation
77
Fig. 3.12 A schematic
representation of the
permanent-magnet
synchronous motor
˙iq = −R
Lq
iq −NωLd
Lq
id −Nφa
Lq
ω + 1
Lq
vq,
(3.157)
˙ω = Nφa
J
iq −1
J TL,
(3.158)
˙α = Nω.
(3.159)
The state of this system equals [id iq ω α ]t. The parameters that would allow us
to simulate this state, given the (input) sequences TL, vd, and vq, are
{N,R,Ld,φa,J}.
Hence, a parameterization of the PMSM model (3.156)–(3.159) corresponds to the
mapping from the parameter set {N,R,Ld,φa,J} to the model description (3.156)–
(3.159). Note that a discrete-time model of the PMSM can be obtained by approxi-
mating the derivatives in (3.156)–(3.159) by ﬁnite differences.
In this chapter, we assume that the order of the LTI system, that is, the dimension
of the state vector, is known. In practice, this is often not the case. Estimating the
order from measurements is discussed in Chap. 8, together with some relevant issues
that arise in the practical application of system identiﬁcation.
3.5.4 Parameterizing a MIMO Model
Finding a model to relate input and output data sequences in the presence of mea-
surement errors and with lack of knowledge about the physical phenomena that
relate these data is a highly nonunique, nontrivial problem. To address this prob-
lem one specializes to speciﬁc models, model sets, and parameterizations. These
notions are deﬁned below for MIMO state-space models of ﬁnite order given by
(3.152)–(3.153).
Let p be the dimension of the parameter vector θ. The set Ω ⊂ℜp that con-
strains the parameter vector, in order to guarantee that the parameterized models
comply with prior knowledge about the system, such as the system’s stability or the
positiveness of its DC gain, is called the parameter set. By taking different values
of θ from the set Ω, we get state-space models of the form (3.152)–(3.153) with

78
3
System Identiﬁcation Methods
different system matrices. A state-space model set is a collection or enumeration of
state-space models of the form given by (3.152)–(3.153).
The transfer function of the nth-order system (3.152)–(3.153) is of the form
G(q,θ) = D(θ) + C(θ)

qIn −A(θ)
−1B(θ).
(3.160)
Thus, for each particular value of θ we get a certain transfer function. From
Sect. 3.4.4, we know that this transfer function is an l × m proper rational func-
tion with a degree of at most n. We use Rl×m
n
to denote the set of all l × m proper
rational transfer functions with real coefﬁcients and a degree of at most n.
A parameterization of the nth-order state-space model (3.152)–(3.153) is a map-
ping from the parameter set Ω ∈ℜp to the space of rational transfer functions
Rl×m
n
. This mapping is called the state-space model structure and is denoted by
M : Ω →Rl×m
n
, thus G(q,θ) = M(θ). Since the structure of the transfer function
is ﬁxed and given by (7.12), the parameterization deﬁned in this way is nothing but a
prescription of how the elements of the system matrices A, B, C, and D are formed
from the parameter vector θ.
Before we continue, we recall some properties of a mapping The map f : X →Y
maps the set X onto the set Y. The set X is called the domain of f and Y is called the
range of f . The map f is called surjective if for every y ∈Y there exists an x ∈X
such that f (x) = y. In other words, to every point in its range there corresponds at
least one point in its domain. It is important to realize that the surjective property
of a map depends on the deﬁnitions of its domain X and its range Y. The map f
is called injective if f (x1) = f (x2) implies x1 = x2, that is, to every point in its
range there corresponds at most one point in its domain. Finally, if the map f is
both surjective and injective, it is called bijective.
Since a similarity transformation of the state vector does not alter the transfer
function, not all parameterizations need to be injective. A parameterization that is
not injective gives rise to a nonunique correspondence between the parameter vector
and the transfer function. This is illustrated in the following example.
3.5.5 Identiﬁcation Example 3.2
Consider the LTI system
x(k + 1) =

 1.5
1
−0.7
0

x(k) +

 1
0.5

u(k),
y(k) =
1
0
x(k).
We parameterize this system using all the entries of the system matrices; this results
in the following parametric model with θ ∈ℜ8:
˜x(k + 1) =

θ(1)
θ(2)
θ(3)
θ(4)

˜x(k) +

θ(5)
θ(6)

u(k),
y(k) =
θ(7)
θ(8)
˜x(k).

3.5
Output-Error Parametric Model Identiﬁcation
79
However, this parameterization is not injective. since we can ﬁnd more than one
parameter vector θ that results in the same transfer function between the input u(k)
and the output y(k). For example, the following two values of the parameter vector
θ give rise to the same transfer function:
θt
1 =
0
−0.7
1
1.5
0.5
1
0
1
,
θt
2 =
2.9
6.8
−0.7
−1.4
0
0.5
1
2
.
The reason for this nonuniqueness is that the transfer function from input to output
remains unchanged when a similarity transformation is applied to the state vector
x(k). To obtain the parameter values θ1, the following similarity transformation of
the state vector was used:
x(k) =

0
1
1
0

˜x(k);
and for θ2 we made use of
x(k) =

1
−2
0
1

˜x(k).
To be able to identify uniquely a model from input and output data requires an
injective parameterization. However, often the main objective is to ﬁnd a state-space
model that describes the input and output data, and uniqueness is not needed. In a
system identiﬁcation context, it is much more important that each transfer function
with an order of at most n given by (3.160) can be represented by at least one point
in the parameter space Ω. In other words, we need to have a parameterization with
domain Ω ⊂ℜp and range Rl×m
n
that is surjective. An example of a surjective
parameterization results on taking all entries of the system matrices A, B, C, and D
as elements of the parameter vector θ as in identiﬁcation example 3.1. This vector
then has dimension p equal to
p = n2 + n(l + m) + ml.
Since this number quickly grows with the state dimension n, alternative parameteri-
zation have been developed. For example, for multiple-input, single-output systems,
the observable canonical form can be used; it is given by [54].
ˆx(k + 1) =
⎡
⎢⎢⎢⎢⎢⎣
0
0
···
0
−a0
1
0
···
0
−a1
0
1
···
0
−a2
...
...
...
...
...
0
0
···
1
−an−1
⎤
⎥⎥⎥⎥⎥⎦
ˆx(k) +
⎡
⎢⎢⎢⎣
b11
···
b1m
b21
···
b2m
...
...
...
bn1
···
bnm
⎤
⎥⎥⎥⎦u(k),
(3.161)
ˆy(k) =
0
0
0
···
1
ˆx(k) +
d11
···
d1m

u(k).
(3.162)
The parameter vector (without incorporating the initial state) is given by
θt =
a0
···
an−1
···
b11
···
bnm
d11
···
d1m

.
The size of θ is
p = n + nm + m.

80
3
System Identiﬁcation Methods
This parameterization M : Ω →R1×m is surjective, the reason for this being that,
although the observer canonical form is always observable, it can be not reachable.
When it is not reachable, it is not minimal and the state dimension can be reduced,
the order of the system becomes less than n. For a SISO transfer function it means
that roots of the numerator polynomial (the zeros of the system) cancel out those of
the denominator (the poles of the system). Different pole zero cancellations corre-
spond to different parameter values that represent the same transfer function, hence
the conclusion that the parameterization is surjective.
Apart from the size of the parameter vector θ and the surjective and/or injective
property of the mapping M(θ), the consequences of selecting a parameterization
on the numerical calculations performed with the model need to be considered as
well. Some examples of the numerical implications of a parameterization are the
following.
1. In estimating the parameter vector θ by solving the optimization problem indi-
cated in (3.155), it may be required that the mapping is differentiable, such that
the Jacobian
∂y(k,θ)
∂θ
exists on a subset in ℜp.
2. In case the mapping is surjective, the parameter optimization (3.155) may suffer
from numerical problems due to the redundancy in the entries of the parameter
vector. A way to avoid such numerical problems is regularization [57], which is
discussed in Sect. 3.5.4.
3. Restrictions on the set of transfer functions M(θ) need to be translated into con-
straints on the parameter set in ℜp. For example, requiring asymptotic stability
of the model leads to restrictions on the parameter set. In this respect it may be
more difﬁcult to impose such restrictions on one chosen parameterization than
on another. Let Ω denote this constraint region in the parameter space, that is,
Ω ⊂ℜp; then we can formally denote the model set M as
M =

M(θ)|θ ∈Ω

.
(3.163)
An example of constraining the parameter space is given below.
4. The numerical sensitivity of the model structure M(θ) with respect to the pa-
rameter vector may vary dramatically between parameterizations. An example
of numerical sensitivity is given later on in identiﬁcation example 3.4.
3.5.6 Identiﬁcation Example 3.3
Consider the transfer function
G(p) =
q + 2
q2 + a1q + a0
(3.164)

3.5
Output-Error Parametric Model Identiﬁcation
81
Fig. 3.13 Imposing stability on the second-order transfer function
parameterized by θ = [a0,a1]t. To impose stability on the transfer function G(q),
we need to ﬁnd a set Ω such that θ ∈Ω results in a stable transfer function of
the form (3.164). In other words, we need to determine a suitable domain for the
mapping M : Ω →U, with U the set of all stable transfer functions of the form
(3.164). For this particular second-order example, the determination of the set Ω is
not that difﬁcult and is requested later on in the problems. The set Ω is mapped onto
the set U of all stable second-order transfer functions of the form (3.164). The set V
is the set of all stable second-order transfer functions. On the right are the impulse
responses for the three indicated points in the parameter space Ω. Figure 3.13 shows
the set Ω. Every point in the set Ω corresponds uniquely to a point in the set U, and
thus the parameterization is injective. The parameterization is bijective with respect
to the set U (with the particular choice of zeros in (3.164), no pole-zero cancellation
can occur for stable poles), but not with respect to the set V that consists of all stable
second-order transfer functions.
Note that Fig. 3.13 shows impulse responses of three systems that correspond to
three different choices of the parameter θ from the set Ω. These impulse responses
are quite different. which illustrates the richness of the set of systems described
by Ω.
3.5.7 Identiﬁcation Example 3.4
The system matrix A in the observer canonical form (3.161)–(3.162) is called a
companion matrix [34]. A companion matrix is a numerically sensitive representa-
tion of the system dynamics; its eigenvalues are very sensitive to small changes in
the coefﬁcients a0,a2,...,an−1.
We use the observer canonical form (3.161)–(3.162) to represent a system with
transfer function
G(q) =
1
q4 + a3q3 + a2q2 + a1q + a0
.

82
3
System Identiﬁcation Methods
Fig. 3.14 Impulse responses of the stable (left) and the unstable system (right)
In this case, the parameter vector is equal to
θt =
a0
a1
a2
a3

.
If we take the parameter vector equal to
θt =
0.915
−2.1
3.11
−2.2
,
the matrix A has two eigenvalues with a magnitude equal to 0.9889 up to four digits
and two eigenvalues with a magnitude equal to 0.9673 up to four digits. Figure 3.14
shows the impulse response of the system G(q) for this choice of θ.
If we change the parameter θ(3) = a2 into 3.12, the properties of the system
become very different. For this slightly different choice of parameters, the matrix
A has two eigenvalues with a magnitude equal to 1.0026 up to four digits and two
eigenvalues with a magnitude equal to 0.9541 up to four digits. Hence, even only a
small change in the parameter a2 makes the system unstable. The impulse response
of the system with a2 = 3.12 is also shown in Fig. 3.14. We clearly see that the
impulse response has changed dramatically. It should be remarked that, for systems
of larger order, results similar to those illustrated in the example can be obtained
with perturbations of magnitude the order of the machine precision of the computer.
In the following subsections, we present two particular parameterizations that are
useful for system identiﬁcation, namely the output normal form and the tridiagonal
form.
3.5.8 The Output Normal Form
The output-normal form parameterization was ﬁrst introduced for continuous-time
state-space models by Hanzon and Ober [35, 36], and later extended for MIMO
discrete-time state-space models [37, 38]. A big advantage of the output normal
form is that the parameterized model is guaranteed to be asymptotically stable with-
out the need for additional constraints on the parameter space. A deﬁnition of the
output normal parameterization of the pair (A,C) in the case of a state-space model
determined by the system matrices A, B, C, and D is as follows.

3.5
Output-Error Parametric Model Identiﬁcation
83
Deﬁnition 3.5 The output-normal-form parameterization of the pair (A,C) with
A ∈ℜl×n is given as

C(θ)
A(θ)

= T1

θ(1)

T2

θ(1)

···Tnl

θ(nl)

 0
In

(3.165)
where θ ∈ℜnl is the parameter vector with entries in the interval [−1,1], and where
the matrices TI(θ(i)) are based on the 2 × 2 matrix
U(α) =

−α
√
1 −α2
√
1 −α2
α

with α ∈ℜin the interval [−1,1]; the matrices Ti(θ(i)) ∈ℜ(n+ℓ)×(n+ℓ) are given
by
Ti

θ(1)

=
⎡
⎣
In−1
0
0
0
U(θ(1))
0
0
0
Il−1
⎤
⎦,
...
Tl

θ(l)

=

In+l−2
0
0
U(θ(l))

,
Tl+1

θ(l + 1)

=
⎡
⎣
In−2
0
0
0
U(θ(l + 1))
0
0
0
1
⎤
⎦,
...
T2l

θ(2ℓ)

=
⎡
⎣
In+l−3
0
0
0
U(θ(2l))
0
0
0
1
⎤
⎦,
...
T(n−1)l+1

θ

(n −1)ℓ+ 1

=

U(θ((n −1)l + 1))
0
0
In+l−2

,
...
Tnl

θ(nℓ)

=
⎡
⎣
Il−1
0
0
0
U(θ(nl))
0
0
0
In−1
⎤
⎦.
The next lemma shows that the parameterized pair of matrices in Deﬁnition 3.5
has the identity matrix as observability Grammian.
Lemma 3.6 Let an asymptotically stable state-space model be given by
x(k + 1) = Ax(k) + Bu(k),
y(k) = Cx(k) + Du(k),

84
3
System Identiﬁcation Methods
with the pair (A,C) given by the output-normal-form parameterization (3.165) of
Deﬁnition 3.5, then the observability Grammian Q, deﬁned as the solution of
AtQA + CtC = Q,
is the identity matrix.
The proof follows from the fact that the matrices U(α) satisfy U(α)tU(α) = I2.
The output-normal-form parameterization of the pair (A,C) can be used to pa-
rameterize any stable state-space model, as shown in the following lemma.
Lemma 3.7 Let an asymptotically stable and observable state-space model be
given as
ˆx(k + 1) = Aˆx(k) + Bu(k),
(3.166)
ˆy(k) = C ˆx(k) + Du(k)
(3.167)
then a surjective parameterization is obtained by parameterizing the pair (A,C) in
the output normal form given in Deﬁnition 3.5 with the parameter vector θAC ∈ℜnl
and parameterizing the pair of matrices (B,D) with the parameter vector θBD ∈
ℜm(n+l) that contains all the entries of the matrices B and D.
Proof The proof is constructive and consists of showing that any stable, observable
state-space system of the form (3.166)–(3.167) can be transformed via a similarity
transformation to the proposed parameterization.
Since A is asymptotically stable and since the pair (A,C) is observable, the
solution Q to the Lyapunov equation
AtQA + CtC = Q,
is positive-deﬁnite. Therefore, a Cholesky factorization can be carried out:
Q = TqT t
q.
The matrix Tt = T −t
q
is the required similarity transformation. Note that Tt exists,
because Q is positive-deﬁnite. The equivalent matrix pair (T −1
t
ATt,CTt) then sat-
isﬁes
At
tAt + Ct
t Ct = In.
In other words, the columns of the matrix

Ct
At

are orthogonal. To preserve this relationship under a second similarity transforma-
tion on the matrices At and Ct, this transformation needs to be orthogonal. As re-
vealed by solving identiﬁcation example 3.1, for any pair (At,Ct) there always
exists an orthogonal similarity transformation Th, such the pair (T −1
h AtTh,CtTh) is
in the so-called observer Hessenberg form [82]. The observer Hessenberg form has

3.5
Output-Error Parametric Model Identiﬁcation
85
a particular pattern of nonzero entries, which is illustrated below for the ease n = 5,
l = 2

CtTh
T −1
h AtTh

=

Ch
Ah

=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
⋆
0
0
0
0
⋆
⋆
0
0
0
⋆
⋆
⋆
0
0
⋆
⋆
⋆
⋆
0
⋆
⋆
⋆
⋆
⋆
⋆
⋆
⋆
⋆
⋆
⋆
⋆
⋆
⋆
⋆
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
with ⋆denoting a possibly nonzero matrix entry.
The pair (Ah,Ch) in observer Hessenberg form can always be represented by a
series of real numbers θ(i) ∈G[−1,1] for i = 1,2,...,nl that deﬁne an output-
normal-form parameterization as in Deﬁnition 3.5. This is illustrated for the case
n = 2 and l = 2. From (3.165) it follows that we need to show that the pair (Ah,Ch)
satisﬁes
T t
nl

θ(nl)

···T t
2

θ(2)

T t
1

θ(1)

Ch
Ah

=

 0
In

.
The ﬁrst transformation, T t
1(θ(1)), is applied as
⎡
⎣
1
0
0
0
Ut(θ(1))
0
0
0
1
⎤
⎦

Ch
Ah

=
⎡
⎣
1
0
0
0
Ut(θ(1))
0
0
0
1
⎤
⎦
⎡
⎢⎢⎣
x11
0
x21
x22
x31
x32
x41
x42
⎤
⎥⎥⎦
=
⎡
⎢⎢⎣
x11
0
x′
21
0
x′
31
x′
32
x41
x42
⎤
⎥⎥⎦,
with U(θ(1)) such that
Ut
θ(1)

x22
x32

=

 0
x′
32

and primes denoting modiﬁed entries, The second transformation, T t
2(θ(2)), yields

I2
0
0
Ut(θ(2))

⎡
⎢⎢⎣
x11
0
x′
21
0
x′
31
x′
32
x41
x42
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
x11
0
x′
21
0
x′′
31
0
x′′
41
x′′
42
⎤
⎥⎥⎦,

86
3
System Identiﬁcation Methods
with double primes denoting modiﬁed entries. Since the matrices U(θ(1)) and
U(θ(2)) are orthogonal, and the pair (Ah,Ch) satisﬁes At
hAh + Ct
hCh = In, we
have

x11
x′
21
x′′
31
x′′
41
0
0
0
x′′
42

⎡
⎢⎢⎢⎣
x11
0
x′
21
0
x′′
31
0
x′′
41
x′′
42
⎤
⎥⎥⎥⎦= I2.
This implies x′′
41 = 0 and (x′′
42)2 = 1. The value of x′′
42 can thus be taken as −1
or 1; in the sequel, the positive value is used. We see that the rightmost column and
bottom row of the transformed matrix are already in the correct form. Subsequently,
the ﬁrst column is transformed into the correct form by annihilating the entries x11
and x′
21. This is done using the orthogonal Givens rotations U(θ(3)) and U(θ(4)).
We obtain
⎡
⎣
1
0
0
0
Ut(θ(4))
0
0
0
1
⎤
⎦

Ut(θ(3))
0
0
I2

I2
0
0
Ut(θ(2))

×
⎡
⎣
1
0
0
0
Ut(θ(1))
0
0
0
1
⎤
⎦
⎡
⎢⎢⎣
x11
0
x21
x22
x31
x32
x41
x42
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
0
0
0
0
1
0
0
1
⎤
⎥⎥⎦.
To complete the parameterization of the state-space system (3.166)–(3.167), the ma-
trices (Bh,D) = (T −1
h T −1
t
B,D) of the transformed state-space system are param-
eterized by all their entries. This completes the proof.
□
The total number of parameters for the output normal parameterization of the
state-space model (3.166)–(3.167) is
p = nℓ+ nm + mℓ.
3.5.9 Identiﬁcation Example 3.5
Consider a second-order state-space model with system matrices
A =

1.5
−0.7
1
0

,
B =

1
0

,
C =
1
0.5
,
D = 0.
Since A is asymptotically stable and the pair (A,C) is observable, we can apply
Lemma 7.2. We start by ﬁnding a similarity transformation Tt such that the trans-
formed pair (T −1
t
ATt,CTt) = (At,Ct) satisﬁes At
tAt + Ct
t Ct = I. Since the pair
(A,C) is observable and the system matrix A is asymptotically stable, the solution
Q of the Lyapunov equation
AtQA + CtC = Q

3.5
Output-Error Parametric Model Identiﬁcation
87
is positive-deﬁnite. Therefore, the matrix Q has a Cholesky factorization TqT t
q that
deﬁnes the necessary similarity transformation Tt = T −t
q
Tq =

 4.3451
0
−2.6161
1.6302

,
Tt =

0.2301
0.3693
0
0.6134

.
By applying the transformation Tt to the quartet of system matrices we obtain a
similarly equivalent quartet. The pair (At,Ct) of this quartet reads

Ct
At

=
⎡
⎣
0.2301
0.6760
0.8979
−0.4248
0.3752
0.6021
⎤
⎦.
This pair (At,Ct) already satisﬁes At
tAt + Ct
t Ct = I2. However, to obtain the fac-
torization in (3.165), we have to perform a number of additional transformations.
First, we perform an orthogonal similarity transformation Th, such that

Ct
CtAt

Th
is lower triangular. This transformation can be derived from the Q factor of the RQ
factorization of the matrix

Ct
CtAt

.
It follows that
Th =

0.3233
0.9466
0.9466
−0.3233

.
Applying the similarity transformation Th yields the following transformed pair:

Ch
Ah

=
⎡
⎣
0.7141
0
0.6176
0.4706
−0.3294
0.8824
⎤
⎦.
To yield the factorization (3.165), we search for a transformation T1 such that
T t
1

Ch
Ah

=
⎡
⎣
⋆
0
⋆
0
0
1
⎤
⎦,
where the ⋆indicate a number not of interest in this particular step. The required
transformation T1 is based on the rotation U(α) in Deﬁnition 3.5 that transforms
the lower-right elements [0.4706,0.8823]t into [0,1]t, and is given by
T1 =
⎡
⎣
1
0
0
0
−0.8824
0.4706
0
0.4706
0.8824
⎤
⎦.

88
3
System Identiﬁcation Methods
Finally, the matrix T t
2 transforms the upper-left elements [0.7141,−0.7]t into [0,1]t
and again is based on a Givens rotation. The transformation T2 is given by
⎡
⎣
0.7
0.7141
0
0.7141
−0.7
0
0
0
1
⎤
⎦,
deﬁning θ(2) equal to −0.7.
The parameter vector θAC = 0 to parameterize the transformed pair (A,C) then
equals

0.8824
−0.7

.
To complete the parameterization in output normal form, the vector θBD is deﬁned
equal to
θBD =

T −1
h T −1
t
0

=
⎡
⎣
1.4003
4.1133
0
⎤
⎦.
3.5.10 The Tridiagonal Form
The tridiagonal parameterization exploits the numerical property that for every
square matrix A there exists a (nonsingular) similarity transformation T , such that
T −1AT is a tridiagonal matrix [34]. A tridiagonal matrix has nonzero entries only
on the diagonal and one layer above and below the diagonal. An illustration of the
form is given for n = 4:
A(θ) =
⎡
⎢⎢⎣
θ(1)
θ(2)
0
0
θ(3)
θ(4)
θ(5)
0
0
θ6
σ
θ
0
0
θ9
θ(10)
⎤
⎥⎥⎦.
To complete the parameterization of the LTI system (3.152)–(3.153), we add the
entries of the matrices B, C, and D. The total number of parameters equals in this
case
p = 32n −2 + n(m + ℓ) + mℓ,
which is an excess of 3n −2 parameters compared with the number of parameters
required before. The surjective property of this parameterization requires that spe-
cial care is taken during the numerical search for the parameter vector θ [57]. This
special care is called regularization and will be discussed later on.

3.5
Output-Error Parametric Model Identiﬁcation
89
3.5.11 The Output-Error Cost Function
As stated earlier, in order to estimate a state-space model of the form (3.152)–
(3.153) from input and output data we consider the quadratic cost function
JN(θ) = 1
N
N−1

k=0
y(k) −ˆy(k,θ)
2
2
(3.168)
where y(k) is the measured output signal, and ˆy(k,θ) is the output signal of the
model (3.152)–(3.153). The cost function JN(θ) is scalar-valued and depends on the
parameter vector θ. In mathematical terms it is a functional [65]. Taking the con-
straints on the parameter vector θ into account, we denote the optimization problem
as
min
θ JN(θ) subject to θ ∈Ω ⊂ℜp and (3.152)–(3.153).
(3.169)
Properties such as convexity of the functional JN(θ) have a great inﬂuence on the
numerical way of ﬁnding the optimum of (3.168). In general, we are able to ﬁnd
only a local minimum and ﬁnding the global minimum, when it exists, requires
either special properties of JN(θ) or an immense computational burden.
For state-space models, a more speciﬁc form of JN(θ), including the effect of
the initial state, is given in the following theorem.
Theorem 3.8 For the state-space model (3.152)–(3.153), the functional JN(θ) can
be written as
JN(θAC,θBD) = 1
N
N−1

k=0
y(k) −φ(k,θAC)θBD
2
2
(3.170)
with θAC the parameters necessary to parameterize the pair (A,C) and
θBD =
⎡
⎣
ˆx(0)
vec(B)
vec(D)
⎤
⎦.
The matrix φ(k,θAC) ∈ℜℓ×(n+m(ℓ+n)) is explicitly given as
φ(k,θAC) =

C(θAC)k,
k−1

τ=0
uτ(τ) ⊗C(θAC)A(θAC)k−1−τ,ut(k) ⊗Il

.
Proof The parameterized state-space model (3.152)–(3.153) is given by
ˆx(k + 1,θAC,θBD) = A(θAC)ˆx(k,θAC,θBD) + B(θBD)u(k),
ˆy(k,θAC,θBD) = C(θAC)ˆx(k,θAC,θBD) + D(θBD)u(k).
The output of this state-space model can explicitly be written in terms of the input
and the initial state ˆx(0,θBD) as (see Sect. 3.4.2)

90
3
System Identiﬁcation Methods
ˆy(k,θAC,θBD) = C(θAC)A(θAC)k ˆx(0,θBD)
+
k−1

τ=0
C(θAC)A(θAC)k−1−τB(θBD)u(τ)D(θBD)u(k).
Application of the property that vec(XYZ) = (Zt ⊗X)vec(Y) and writing down
the resulting equation for k = 1,2,...,N completes the proof.
The parameter vector θ in the original state-space model (3.152)–(3.153) could
be constructed by simply stacking the vectors θAC and θBD of Theorem 3.8 as
θ =

 θAC
θBD

.
The output normal form presented in Lemma 3.7 will give rise to the formulation of
the functional as expressed in Theorem 3.8. If the parameters θAC are ﬁxed, the cost
function (7.22) is linear in the parameters θBD. This fact can be exploited by apply-
ing the principle of separable least squares [33] in the search for the minimum of the
cost function. Separable least squares ﬁrst eliminates the parameters θBD from the
cost function and searches for a minimum with respect to the parameters θAC only.
Once the optimal value of the parameter vector θAC has been found, the parameter
values θBDG are derived by simply solving a linear least-squares problem. The crit-
ical requirement is that there are no parameters in common between those contained
in θAC and θBD. This is the case for the output normal form, deﬁned in Sect. 3.5.2
but not for the tridiagonal form of Sect. 3.5.3. The application of separable least
squares for the identiﬁcation of LTI state-space models is dismissed by Bruls et al.
[11] and Haverkamp [39].
□
The inﬂuence of the choice of the parameterization on the shape of the cost func-
tion JN(θ). and therefore on the numerical optimization process (3.170), is illus-
trated in the example below.
3.5.12 Identiﬁcation Example 3.6
Consider the state-space system from identiﬁcation example 3.4. We demonstrate
that the shape of the cost function JN(θ) depends on the parameterization of the
state-space system. We consider three cases.
• The system is converted into observer canonical form. For this particular system,
we just have to switch the two states to arrive at
A =

0
−a0
0
−a1

,
B =

0.5
1

,
C =
0
1
where a0 = 0.7 and a1 = −1.5. We parameterize the system with the parameter
vector θ = [a0,a1]t.
Figure 3.15 shows how the cost function varies with the parameter vector θ.
The minimum value of the cost function occurs for θ = [0.7,−1.5]. This function
is clearly nonlinear, it has several local minima.

3.5
Output-Error Parametric Model Identiﬁcation
91
Fig. 3.15 The cost JN(θ) as
a function of the parameters
θ(1), θ(2): case 1
Fig. 3.16 The cost JN(θ) as
a function of the parameters
θ(1), θ(2): case 2
• We take again the observer canonical form, but now take the parameter vector θ
equal to [a0/a1,a1]t. This means that we parameterize the A matrix as follows:
A =

0
θ(1)θ(2)
1
−θ(2)

.
Figure 3.16 shows how the cost function varies with the parameter vector θ. The
minimum value of the cost function occurs for θ ≈[0.47,−1.5].
• The system is converted to the output normal form, as explained in identiﬁcation
example 3.5. We vary the two parameters that parameterize the matrices A and
C. The minimum value of the cost function occurs for θ ≈[0.8824,−0.7]. The
cost function is displayed in Fig. 3.17. Again, we see that the cost function is
nonlinear. Unlike in the previous cases, it always remains bounded, since with the
output-normal parameterization the system can never become unstable. However,
we still observe that the cost function is nonconvex.

92
3
System Identiﬁcation Methods
Fig. 3.17 The cost JN(θ) as
a function of the parameters
θ(1), θ(2): case 3
3.5.13 Numerical Parameter Estimation
To determine a numerical solution to the parameter-optimization problem (3.170) of
the previous section, the cost function JN(θ) is expanded in a Taylor series around a
given point θ(i) in the parameter space Ω. This point θ(i) may be the starting point
of the optimization process or an intermediate estimate obtained during the search
for the minimum of JN(θ). The Taylor-series expansion is given by
JN(θ) = JN

θ(i)
+

J ′
N

θ(i)t
θ −θ(i)
+ 1
2

θ −θ(i)tJ ′′
N

θ(i)
θ −θ(i)
+ higher-order terms,
where J ′
N(θ(i)) is Jacobian and J ′′
N(θ(i)) the Hessian of the functional JN(θ) at θ(i),
given by
J ′
N(θ) = ∂JN(θ)
∂θ
=
⎡
⎢⎢⎢⎢⎣
∂JN(θ)
∂θ(1)
∂JN(θ)
∂θ(2)
...
∂JN(θ)
∂θ(p)
⎤
⎥⎥⎥⎥⎦
,
J ′′
N(θ) = ∂2JN(θ)
∂θ∂θt
=
⎡
⎢⎢⎢⎢⎣
∂JN(θ)
∂θ(1)∂θ(1)
∂JN(θ)
∂θ(1)∂θ(2)
···
∂JN(θ)
∂θ(1)∂θ(p)
∂JN(θ)
∂θ(2)∂θ(1)
∂JN(θ)
∂θ(2)∂θ(2)
···
∂JN(θ)
∂θ(2)∂θ(p)
...
...
...
...
∂JN(θ)
∂θ(p)∂θ(1)
∂JN(θ)
∂θ(p)∂θ(2)
···
∂JN(θ)
∂θ(p)∂θ(p)
⎤
⎥⎥⎥⎥⎦
.
We approximate JN(θ) as

3.5
Output-Error Parametric Model Identiﬁcation
93
JN(θ) ≈JN

θ(i)
+

J ′
N

θ(i)t
θ −θ(i)
+ 1
2

θ −θ(i)tJ ′′
N

θ(i)
θ −θ(i)
.
(3.171)
The necessary condition for minimizing this approximation of JN(θ) becomes
J ′
N

θ(i)
+ J ′′
N

θ(i)
θ −θ(i)
= 0.
Therefore, provided that the Hessian at θ(i) is invertible, we can update the param-
eter vector θ(i) to θ by the update equation
θ = θ(i) −J ′′
N

θ(i)−1J ′
N

θ(i)
.
(3.172)
This type of parameter update is called the Newton method. To arrive at explicit
expressions for J ′
N(θ) and J ′′
N(θ), we introduce the error vector
EN(θ) =
⎡
⎢⎢⎢⎣
ϵ(0,θ)
ϵ(1,θ)
...
ϵ(N −1,θ)
⎤
⎥⎥⎥⎦,
with ϵ(k,θ) = y(k) −¯y(k,θ). We can denote the cost function JN(θ) as
JN(θ) = 1
N
N−1

k=0
y(k) −ˆy(k,θ)
2
2
= 1
N Et
N(θ)EN(θ).
(3.173)
Using the calculus of differentiating functionals outlined in [10], and using the no-
tation
ΨN(θ) = ∂EN(θ)
∂θt
(3.174)
the Jacobian and Hessian of JN(θ) can be expressed as
J ′
N(θ) = 1
N
∂Et
N(θ)
∂θ
EN(θ) + 1
N

Ip ⊗Et
N(θ)
∂EN(θ)
∂θ
= 2
N
∂Et
N(θ)
∂θ
EN(θ)
= 2
N
∂EN(θ)
∂θt
t
EN(θ)
= 2
N Ψ t
N(θ)EN(θ),
(3.175)
J ′′
N(θ) = 2
N
∂2Et
N(θ)
∂θt∂θ

Ip ⊗EN(θ)

+ 2
N
∂Et
N(θ)
∂θ
∂EN(θ)
∂θt
= 2
N
∂2Et
N(θ)
∂θt∂θ

Ip ⊗EN(θ)

+ 2
N
∂EN(θ)
∂θt
t ∂EN(θ)
∂θt
= 2
N
∂2Et
N(θ)
∂θt∂θ

Ip ⊗EN(θ)

+ 2
N Ψ t
N(θ)ΨN(θ).
(3.176)

94
3
System Identiﬁcation Methods
3.5.14 The Gauss–Newton Method
The Gauss–Newton method consists of approximating the Hessian J ′′
N(θ(i)) by the
matrix HN(θ(i)):
HN(θ(i) = 2
N Ψ t
N(θ)ΨN(θ).
Such an approximation of the Hessian holds in the neighborhood of the optimum
where the second derivative of the error and the error itself are weakly correlated.
In that case, the ﬁrst term of (3.176) can be neglected. This results in considerable
computational savings. When the matrix HN(θ(i)) is invertible, we can write the
parameter update equation for the Gauss–Newton method as
θ(i+1) = θ(i) −HN

θ(i)−1J ′
N

θ(i)
.
(3.177)
A different way to derive this update equation is by using a Taylor-series expansion
on EN(θ) in the neighborhood of θ(i) as follows:
JN

θ(i) + δθ(i)
= 1
N
EN

θ(i) + δθ
2
2
≈1
N
EN

θ(i)
+ ΨN

θ(i)
δθ(i)2
2
(3.178)
where Ψ t
N(θ) is given by (3.174). The parameter update δθ(i) = θ(i+1) −θ(i) follows
on solving the ‘following linear least-squares problem:
min
δθ(i)
EN

θ(i)
+ ΨN

θ(i)
δθ(i)2
2,
and we get
θ(i+1) = θ(i) −

ΨN

θ(i)tΨN

θ(i)−1ΨN

θ(i)tEN

θ(i)
= θ(i) −HN

θ(i)−1J ′
N

θ(i)
(3.179)
which equals (3.177).
According to (3.177), at every iteration we need to calculate the approximate
Hessian HN(θ(i)) and the Jacobian J ′
N(θ(i)). To ease the computational burden, it is
important to have an efﬁcient way of calculating these quantities. Note that (3.175)
and (3.176) show that in fact we need calculate only EN(θ) and ΨN(θ). To compute
EN(θ), we need to compute ˆy(k,θ) for k = 1,2,...,N. This can be done efﬁciently
by simulating the following system:
ˆx(k + 1,θ) = A(θ)ˆx(k,θ) + B(θ)u(k),
(3.180)
ˆy(k,θ) = C(θ)ˆx(k,θ) + D(θ)u(k).
(3.181)

3.5
Output-Error Parametric Model Identiﬁcation
95
This will also yield the signal ˆx(k,θ) which we need to compute ΨN(θ), as ex-
plained below. Note that ΨN(θ) is given by
ΨN(θ) =
⎡
⎢⎢⎢⎢⎣
∂ϵ(0,θ)
∂t
∂ϵ(1,θ)
∂t
...
∂ϵ(N−1,θ)
∂t
⎤
⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎣
−
∂ˆy(0,θ)
∂θt
∂ˆy(1,θ)
∂θt
...
∂ˆy(N−1,θ)
∂θt
⎤
⎥⎥⎥⎥⎦
,
and that
∂ˆy(k,θ)
∂θt
=

 ∂ˆy(k,θ)
∂θ(1)
∂ˆy(k,θ)
∂θ(2)
···
∂ˆy(k,θ)
∂θ(p)

,
where θ(i) denotes the ith entry of the vector θ. It is easy to see that for every
parameter θ(i) we have
∂ˆx(k + 1,θ)
∂θ(i)
= A(θ)∂ˆx(k,θ)
θ(i)
+ ∂A(θ)
∂θ(i) ˆx(k,θ) + ∂B(θ)
∂θ(i) u(k),
∂ˆy(k,θ)
∂θ(i)
= C(θ)∂ˆx(k,θ)
θ(i)
+ ∂C(θ)
∂θ(i) ˆx(k,θ) + ∂D(θ)
∂θ(i) u(k).
On taking Xi(k,θ) = ∂ˆx(k,θ)/∂θ(i), this becomes
Xi(k + 1,θ) = A(θ)Xi(k,θ) + ∂A(θ)
∂θ(i) ˆx(k,θ) + ∂B(θ)
∂θ(i) u(k),
(3.182)
∂ˆy(k,θ)
∂θ(i)
= C(θ)Xi(k,θ) + ∂C(θ)
∂θ(i) ˆx(k,θ) + ∂D(θ)
∂θ(i) u(k).
(3.183)
The previous two equations show that the derivative of ˆy(k,θ) with respect to θ(i)
can be obtained by simulating a linear system with state Xi(k,θ) and inputs ˆx(k,θ)
and u(k). Note that the matrices
∂A(θ)
∂θ(i) ,
∂B(θ)
∂θ(i) ,
∂C(θ)
∂θ(i) ,
∂D(θ)
∂θ(i)
are ﬁxed and depend only on the particular parameterization that is used to describe
the system. We conclude that the calculation of ΨN(θ) boils down to simulating a
linear system for every element of the parameter vector θ. Therefore, if θ contains
p parameters, we need to simulate p + 1 linear systems in order to compute both
EN(θ) and ΨN(θ).
3.5.15 Identiﬁcation Example 3.7
Let the model output be given by ˆy(k,θ) = φ(k)tθ, with y(k) ∈ℜand φ(k) ∈ℜp;
then the cost function JN(θ) is
JN(θ) = 1
N
N−1

k=0

y(k) −φ(k)tθ
2
(3.184)

96
3
System Identiﬁcation Methods
and the vector EN(θ) is
EN(θ) =
⎡
⎢⎢⎢⎣
y(0) −φ(0)tθ
y(1) −φ(1)tθ
...
y(N −1) −φ(N −1)tθ
⎤
⎥⎥⎥⎦.
Let φi(j) denote the ith entry of the vector φ(j), then
∂Et
N(θ)
∂θ(i)
= −
−φi(0)
φi(1)
···
φi(N −1)
.
Hence,
ΨN(θ)t = −
φ(0)
φ(1)
···
φ(N −1)
,

∂EN(θ)
∂θt
t
EN(θ) = −
φ(0)
φ(1)
···
φ(N −1)
×
⎡
⎢⎢⎢⎣
y(0) −φ(0)tθ
y(1) −φ(1)tθ
...
y(N −1) −φ(N −1)tθ
⎤
⎥⎥⎥⎦
= −Φt
N(YN −ΦNθ),
with
YN =
y(0)
y(1)
···
y(N −1)t ,
ΦN =
φ(0)
φ(1)
···
φ(N −1)t .
Assuming that the matrix Φt
NΦN/N is invertible, we can write the parameter update
(3.179) as
θ(i+1) = θ(i) +
 1
N Φt
NΦN
−1 1
N Φt
N

YN −ΦNθ(i)
=
 1
N Φt
NΦN
−1 1
N Φt
NYN.
(3.185)
The assumed invertibility condition depends on the vector time sequence φ(k). A
systematic framework has been developed to relate this invertibility condition to the
notion of persistency of excitation of the time sequence [54].
The updated parameter vector θ(i+1) becomes independent from the initial one
θ(i). Therefore, the iterative parameter-update rule (3.185) can be stopped after one
iteration (one cycle) and the estimate becomes
ˆθN =
 1
N Φt
NΦN
−1 1
N Φt
NYN.
(3.186)

3.5
Output-Error Parametric Model Identiﬁcation
97
The underlying reason for this is that the functional (3.185) is quadratic in θ. The
latter is a consequence of the model output φ(k)tθ being linear in the unknown
parameter vector θ.
Note that the derived solution of the quadratic cost function (3.186) equals the
one obtained by solving the normal equations for a linear least-squares problem, see
Sect. 2.6.
3.5.16 Regularization in the Gauss–Newton Method
The matrix HN(θ(i) used in the Gauss–Newton update equation (3.177) to approxi-
mate the Hessian may be singular. This will, for example, be the ease when the pa-
rameterization selected is non-injective; different sets of parameters yield the same
value of the cost function JN(θ) and thus the θ that minimizes JN(θ) no longer need
be unique. One possible means of rescue to cope with this singularity is via regular-
ization, which leads to a numerically more attractive variant of the Gauss–Newton
method. In regularization, a penalty term is added to the cost function to overcome
the nonuniqueness of the minimizing θ. Instead of just minimizing JN(θ), the min-
imization problem becomes
min
θ JN(θ) + λ∥θ∥2
2.
The real number λ is positive and has to be selected by the user. Using the same ap-
proximation of the cost function JN(θ) as in (3.178), the regularized Gauss–Newton
update can be derived as
θ(i+1) = θ(i) −

HN

θ(i)
+ λIp
−1J ′
N

θ(i)
.
By adding λIp to HN(θ(i)), the matrix HN(θ(i)) + λIp is made nonsingular for
λ > 0. However, the selection of the regularization parameter λ is far from trivial.
A systematic approach that is widely used is known as the Levenberg–Marquardt
method [61].
3.5.17 The Steepest Descent Method
The steepest-descent method does not compute or approximate the Hessian, it just
changes the parameters into the direction of the largest decrease of the cost func-
tion. This direction is, of course, given by the Jacobian. Hence, the steepest-descent
algorithm updates the parameters as follows:
θ(i+1)(μ) = θ(i) −μJ ′
N

θ(i)
(3.187)
where an additional step size μ ∈[0,1] is introduced. This step size is usually de-
termined via the additional scalar optimization problem,
ˆθ(i+1) = arg min
μ∈[0,1]JN

θ(i+1)(μ)

.

98
3
System Identiﬁcation Methods
In general, the iteration process of the steepest-descent algorithm has a lower con-
vergence speed than that of the iteration in the Gauss–Newton method. However, the
steepest-descent algorithm results in considerable computational savings in each in-
dividual iteration step. This is due to the fact that, to compute J ′
N(θ), we compute the
product Ψ t
N(θ)EN(θ) directly, without computing ΨN(θ) separately. This requires
only two simulations of an nth-order system, as explained below. Recall that
Ψ t
N(θ)EN(θ) =
N−1

k=0

−∂ˆy(k,θ)
∂θ
t
ϵ(k,θ).
Using (3.183), we can write the right-hand side as
N−1

k=0
∂ˆy(k,θ)
∂θ(i)
t
ϵ(k,θ) =
N−1

k=0
Xi(k,θ)C(θ)tϵ(k,θ)
+
N−1

k=0
ˆx(k,θ)t
∂C(θ)
θ(i)
t
ϵ(k,θ)
+
N−1

k=0
u(k)t
∂D(θ)
∂θ(i)
t
ϵ(k,θ).
To obtain ˆx(k,θ), one simulation of the state equation (3.180) is required. From
the discussion in Sect. 3.5.1, it follows that, to compute Xi(k,θ), the p systems
deﬁned by (3.182) and (3.183) need to be simulated. However, for the steepest-
descent method Xi(k,θ) is not needed; only the sum
N−1

k=0
Xi(k,θ)tC(θ)tϵ(k,θ)
is needed. This sum can be computed by just one (backward) simulation of the
system
¯X(k −1,θ) = A(θ)t ¯X(k,θ) + C(θ)tϵ(k,θ)
(3.188)
involving the adjoint state ¯X(k,θ), because
N−1

k=0
Xi(k,θ)tC(θ)tϵ(k,θ) =
N−1

k=0
Wi(k,θ)t ¯X(k,θ)
(3.189)
where
Wi(k,θ) = ∂A(θ)
∂θ(i) ˆx(k,θ) + ∂B(θ)
∂θ(i) u(k).
The equality (3.189) can be derived by writing (3.182) as
Xi(k + 1,θ) = A(θ)Xi(k,θ) + Wi(k,θ).

3.5
Output-Error Parametric Model Identiﬁcation
99
Taking Xi(0,θ) = 0, we can write
⎡
⎢⎢⎢⎢⎢⎣
Xi(0,θ)
Xi(1,θ)
Xi(2,θ)
...
Xi(N −1,θ)
⎤
⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎣
0
0
···
···
0
In
0
···
···
0
A
In
0
···
0
...
...
...
...
...
AN−2
···
A
In
In
⎤
⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎣
Wi(0,θ)
Wi(1,θ)
Wi(2,θ)
...
Wi(N −1,θ)
⎤
⎥⎥⎥⎥⎥⎦
.
(3.190)
For the adjoint state ¯X(N −1,θ) = 0, we have
⎡
⎢⎢⎢⎢⎢⎣
¯Xi(0,θ)
¯Xi(1,θ)
¯Xi(2,θ)
...
¯X(N −1,θ)
⎤
⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
0
In
At
···
(At)N−2
0
0
In
···
...
...
...
0
...
...
...
...
...
...
In
0
0
0
···
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎣
C(θ)tϵ(0,θ)
C(θ)tϵ(1,θ)
C(θ)tϵ(2,θ)
...
C(θ)tϵ(N −1,θ)
⎤
⎥⎥⎥⎥⎥⎦
.
(3.191)
On combining (3.190) and (3.191), it is easy to see that (3.189) holds. We can con-
clude that only two simulations of an nth-order system are required for the steepest-
descent method, instead of p + 1 simulations.
3.5.18 Gradient Projection
When a chosen parameterization is non-injective, the Hessian needs to be regular-
ized as discussed in Sect. 3.5.2. For the special case when the surjective parame-
terization consists of taking all entries of the system matrices A, B, C, and D, the
singularity of the Hessian due to similarity transformations of the state-space sys-
tem can be dealt with in another way. This parameterization that has all the entries
of the system matrices in the parameter vector θ is called the full parameterization.
Consider the system given by the matrices ¯A, ¯B, ¯C, and ¯D obtained by applying
a similarity transformation T ∈ℜn×n to the matrices A, B, C, and D as

 ¯A
¯B
¯C
¯D

=

T −1AT
T −1B
CT
D

.
(3.192)
The system given by ¯A, ¯B, ¯C, and ¯D has the same transfer function, and thus the
same input–output behavior, as the system deﬁned by A, B, C, and D.
By taking all possible nonsingular similarity transformations T , we obtain a set
of systems that have the same input–output behavior, and can thus not be distin-
guished on the basis of input and output data. This set of similar systems forms a
manifold M in the parameter space θ, as pictured schematically in Fig. 3.18. By
changing the parameters along the manifold M, we do not change the input–output
behavior of the system and we therefore do not change the value of the cost function
JN(θ).

100
3
System Identiﬁcation Methods
Fig. 3.18 A schematic
representation of the manifold
M of similar systems
To avoid problems with the numerical parameter update in minimizing JN(θ),
we should avoid modifying the parameters such that they stay on this manifold. This
idea has been put forward by McKelvey and Helmersson [59] and by Lee and Poolla
[51]. At a certain point θ on the manifold M we can determine the tangent plane
(see Fig. 3.18). The tangent plane contains the directions in the parameter space
along which an update of the parameters does not change the cost function JN(θ).
The tangent plane of the manifold is determined by considering similar systems for
small perturbations of the similarity transformation around the identity matrix, that
is T = In + ΔT . A ﬁrst-order approximation of similarly equivalent systems is then
given by

 ¯A
¯B
¯C
¯D

=

T −1AT
T −1B
CT
D

≈

A
B
C
D

+

AΔT −ΔT A
−ΔT B
CΔT
0

.
(3.193)
If the entries of the system matrices are stacked in column vectors as
θ =
⎡
⎢⎢⎣
vec(A)
vec(B)
vec(C)
vec(D)
⎤
⎥⎥⎦,
ˆθ =
⎡
⎢⎢⎣
vec( ¯A)
vec( ¯B)
vec( ¯C)
vec( ¯D)
⎤
⎥⎥⎦
applying the vec operator to (3.193) and using the relation vec(XYZ) = (Zt ⊗
X)vec(Y) (see the Appendix) shows that the parameters of the similar systems are
related as
¯θ = θ + Q(θ)vec(ΔT )
(3.194)
with the matrix Q(θ) deﬁned by
Q(θ) =
⎡
⎢⎢⎣
In ⊗A −At ⊗In
−Bt ⊗In
In⊗
0
⎤
⎥⎥⎦.
The matrix Q depends on θ, since θ contains the entries of the system matrices A,
B, C, and D. Note that (3.194) shows that the columns of the matrix Q(θ) span
the tangent plane at the point θ on the manifold of similar systems. If we update
the parameters θ along the directions of the orthogonal complement of the matrix

3.5
Output-Error Parametric Model Identiﬁcation
101
Q(θ), we will avoid the criterion that we do not change the cost function JN(θ).
The orthogonal complement of Q(θ) follows from an SVD of the matrix Q(θ):
Q(θ) =
U(θ)
U⊥(θ)
Σ(θ)
0
0
0

V (θ)t
V (θ)t

,
with Σ(θ) > 0 and U⊥(θ) ∈ℜp×p−r, with p = n2 + n(l + m) + lm and r =
rank(Q(θ)). The columns of the matrix U(θ) form a basis for the column space
of Q(θ); the columns of the matrix U⊥(θ) form a basis for the orthogonal comple-
ment of the column space of Q(θ). The matrices U(θ) and U⊥(θ) can be used to
decompose the parameter vector θ into two components:
θ = U(θ)U(θ)tθ + U⊥(θ)U⊥(θ)tθ
(3.195)
where the ﬁrst component corresponds to directions that do not inﬂuence the cost
function (the column space of Q) and the second component to the directions that
change the value of the cost function (the orthogonal complement of the column
space of Q).
In solving the optimization problem (3.169), the parameters θ are updated ac-
cording to the rule
θ(i+1) = θ(i) + δθ(i),
where δθ(i) is the update. For the steepest-descent method (3.187), this update
equals δθ(i) = −μJ ′
N(θ(i)). Preventing an update of the parameters in directions
that do not change the cost function is achieved by decomposing δθ(i) similarly to
in (3.195) and discarding the ﬁrst component. On the basis of this observation, the
parameter update of the steepest-descent method (3.187) becomes
θ(i+1) = θ(i) −μU⊥

θ(i)
U⊥

θ(i)tJ ′
M

θ(i)
,
and the update of the Gauss–Newton method (3.177), which is implemented by
imposing an update in the direction of the range space of U⊥(θ(i)) only, is given by
θ(i+1) = θ(i) −μU⊥

θ(i)
U⊥

θ(i)tHN

θ(i)
U⊥

θ(i)−1
× U⊥

θ(i)tJ ′
N

θ(i)
.
This insight can be obtained by solving problem 3.10.
3.5.19 Analyzing the Accuracy of the Estimates
The result of the numerical optimization procedure described in the previous section
is
ˆθN = argmin 1
N
N−1

k=0
y(k) −ˆy(k,θ)
2
2.
A possible way to characterize the accuracy of the estimate ˆθN is via an expression
for its mean and covariance matrix. In this section, we derive this covariance matrix

102
3
System Identiﬁcation Methods
for the case that the system to be identiﬁed belongs to the model class. This means
that G(q) of the system
y(k) = G(q)u(k) + v(k)
belongs to the parameterized model set M(θ).
The Gauss–Newton optimization method approximates the cost function as in
(3.171). This approximation holds exactly in the special case of a model output that
is linear in the parameters as treated in identiﬁcation example 3.7. Therefore, we
study the asymptotic variance ﬁrst for the special case when JN(θ) is given by
JN(θ) = 1
N
N−1

k=0

y(k) −θ(k)tθ
2.
(3.196)
We assume that the system is in the model class, thus the measured output y(k) is
assumed to be generated by the system
y(k) = θ(k)tθ0 + e(k)
(3.197)
where θ0 are the true parameter values, and e(k) is a zero-mean white-noise se-
quence with variance σ 2
e that is statistically independent from φ(k).
Expanding the cost function (3.196) and using the expression for y(k) yields
JN(θ) = 1
N
N−1

k=0
e(k)2 + 1
N
N−1

k=0
e(k)φ(k)(θ0 −θ)
+ 1
N
N−1

k=0
(θ0 −θ)tφ(k)φ(k)t(θ0 −θ),
which is exactly the right-hand side of (3.171). The parameter vector ˆθN that mini-
mizes this criterion for μ = 1 was derived in identiﬁcation example 3.7 and equals
ˆθN =
 1
N Φt
NΦN
−1 1
N ΦNYN
×

1
N
N−1

k=0
φ(k)φ(k)t
−1
1
N
N−1

k=0
φ(k)y(k)

.
Again using the expression for y(k), we get
ˆθN −θ0 =

1
N
N−1

k=0
φ(k)φ(k)t
−1
1
N
N−1

k=0
φ(k)e(k)

.
Since e(k) and φ(k) are independent, E[ ˆθN −θ0] = 0 and thus the estimated param-
eters ˆθN are unbiased. The covariance matrix of ˆθN −θ0 equals
E

[ ˆθN −θ0][ ˆθN −θ0]t

3.5
Output-Error Parametric Model Identiﬁcation
103
=

1
N
N−1

k=0
φ(k)φ(k)t
−1
E

1
N2
N−1

k=0
φ(k)e(k)
N−1

j=0
φ(j)te(j)

×

1
N
N−1

k=0
φ(k)φ(k)t
−1
=

1
N
N−1

k=0
φ(k)φ(k)t
−1 1
N2
N−1

k=0
φ(k)φ(k)tσ 2
e ×

1
N
N−1

k=0
φ(k)φ(k)t
−1
= σ 2
e
N

1
N
N−1

k=0
φ(k)φ(k)t
−1
,
when the matrix

1
N
N−1

k=0
φ(k)φ(k)t
−1
converges to a constant bounded matrix Σφ, the last equation shows that the covari-
ance matrix of ˆθN goes to zero asymptotically (as N →∞). In this case the estimate
is called consistent. The fact that y(k) is given by (3.197) indicates that the system
used in optimizing (3.196) is in the model set. In this case the output-error method
is able to ﬁnd the unbiased and consistent estimates of the parameter vector θ.
Now, we take a look at the more general case in which the cost function is given
by
JN(θAC,θBD) = 1
N
N−1

k=0
y(k) −φ(k,θAC)θBD
2
2,
as in Theorem 3.8. We assume again that the system to be identiﬁed is in the model
class; that is, the system to be identiﬁed can be described by the parameters θAC,0,
and θBD,0 such that the measured output satisﬁes
y(k) = φ(k,θAC,0)θBD,0 + e(k),
where e(k) is a zero-mean white-noise sequence with variance σ 2
e that is statistically
independent from φ(k,θAC). Denoting the true parameters by
θ0 =

 θAC,0
θBD,0

,
and the estimated parameters obtained from the output-error method by ˆθN, it can
again be shown that E[ ˆθN −θ0]t = 0 [54] and thus the estimated parameters ˆθN are
unbiased. The covariance matrix of this unbiased estimate is [54]
E[ ˆθN −θ0][ ˆθN −θ0]t = σ 2
e
N

J ′′(θ0)
−1
and it can be approximated as
E[ ˆθN].
(3.198)

104
3
System Identiﬁcation Methods
The approximation of the covariance matrix of the estimated parameters holds only
asymptotically in N. This needs to be taken into account when using the approxi-
mation to describe the model error.
3.5.20 Dealing with Colored Measurement Noise
At the beginning of this chapter, we considered the signal model
y(k) = G(q)u(k) + v(k)
(3.199)
where v(k) is a white-noise sequence. In this section, we investigate the more gen-
eral case in which v(k) is nonwhite noise. Consider the cost function
JNθ = 1
N
N−1

k=0
y(k) −ˆy(k,θ)
2
2
= 1
N
N−1

k=0
ϵ(k,θ)
2
2
= 1
N Et
NEN.
(3.200)
If vk is a white-noise sequence, the residual vector ϵ(k,θ) will also be a white-noise
sequence if the following two conditions are satisﬁed:
1. The transfer function G(q) of (3.199) belongs to the parameterized model set
M(θ); and
2. The estimate ˆθ is the global minimizing argument of (3.200) in the limit N →∞.
In this case, all temporal information has been modeled; there is no correlation be-
tween different samples of error ϵ(k,θ). If the output measurements are perturbed
by colored noise, the error ϵ(k,θ) can never become a white-noise sequence. The
consequence is that, although the estimated parameter θ can still be unbiased, it no
longer has minimum variance. This is illustrated in the following example.
3.5.21 Identiﬁcation Example 3.8
Consider the quadratic cost function of Example 3.7 given by
JN(θ) = 1
N
N−1

k=0

y(k) −φ(k)θ2.
(3.201)
We assume that the system is in the model class, thus the measured output y(k) is
assumed to be generated by the system
y(k) = φ(k)tθ0 + v(k)
(3.202)

3.5
Output-Error Parametric Model Identiﬁcation
105
where θ0 are the true parameter values, and v(k) is a zero-mean random sequence
that is statistically independent from φ(k).
Adopting the notation of identiﬁcation example 3.7, we can write the minimiza-
tion of JN(θ) as the least-squares problem
min
θ V t
NV N
subject to YN = ΦNθ + VN
(3.203)
where
VN =
v(0)
v(1)
···
v(N −1)t .
We learn before that, to obtain a minimum-variance estimate of θ, we have to solve
the weighted least-squares problem
min
θ Et
NEN
subject to YN = ΦNθ + LEN,
where E(ENEt
N) = IN. On comparing this with (3.203), we see that, to obtain a
minimum-variance estimate, we need to have LEN = VN with L = Σ1/2
v
such that
E(VNV t
N) = Σv. If no information about v(k) is available, this is not possible. It
follows that simply setting L = I will lead to a minimum-variance estimate only if
v(k) is white noise; for colored noise v(k) the minimum variance is obtained for
L = Σ1/2
v
.
3.5.22 Weighted Least Squares
One way to obtain a minimum-variance parameter estimate when the additive noise
v(k) at the output in (3.150) is nonwhite requires that we know its covariance matrix.
Let the required covariance matrix be denoted by Σv and equal to
Σv = E
⎡
⎢⎢⎢⎣
v(0)
v(1)
...
v(N −1)
⎤
⎥⎥⎥⎦
v(0)
v(1)
···
v(N −1)
.
Then, if we assume that Σv > 0, we adapt the cost function (3.173) to the following
weighted least-squares sum:
JN(θ,Σv) = 1
N Et
NΣ−1
v EN = 1
N

Σ−T/2
v
EN
t
Σ−T/2
v
EN

.
(3.204)
The numerical methods outlined in Sect. 3.5 can be adapted in a straightforward
manner by replacing EN by Σ−T/2
v
EN and ΨN by Σ−T/2
v
ΨN.
In general, the covariance matrix is a full Nl×Nl matrix, and, therefore, for large
N its formation and inversion requires a prohibitive amount of memory. However,
recent work by David [20] provides a way to circumvent this problem, by employing
an analytic and sparse expression for the inverse covariance matrix based on the

106
3
System Identiﬁcation Methods
Gohberg-Heinig inversion theorem. This sparsity can be taken into account to derive
computationally efﬁcient methods [8].
A practical procedure for applying the weighting discussed above is the follow-
ing.
1. Minimize the output-error cost function (3.200) and compute the corresponding
residual vector EN for the optimum.
2. Use the residual vector from the previous step to estimate a multivariable AR
model of the noise, and use that model to compute the Cholesky factor of the
inverse covariance matrix as described by David [20].
3. Minimize the weighted cost function (3.204).
After step 3, again the residual vector EN can be computed, and steps 2 and 3 can
be repeated. This can be done several times, but in our experience two iterations
are usually sufﬁcient, which corresponds to the observations made by David and
Bastin [21].
3.5.23 Prediction-Error Methods
Another way to improve the accuracy of the estimates of a parametric model of G(q)
in (3.199) when the perturbation v(k) is nonwhite noise consists of incorporating
a model of this noise into the estimation procedure. We assume that v(k) can be
described by a ﬁltered white-noise sequence e(k), such that
y(k) = G(q)u(k) + H(q)e(k).
Prediction-error methods (PEM) aim at ﬁnding parameters of a model that models
both of the transfer functions G(q) and H(q). Making use of the Kalman-ﬁlter
theory of Sect. 3.5, the above transfer-function model can be described together
with the following innovation state-space model:
ˆx(k + 1) = Aˆx(k) + Bu(k) + Ke(k),
y(k) = C ˆx(k) + Du(k) + e(k),
where e(k) is a white-noise sequence. Note that, in general, the dimension of the
state vector can be larger than the order n of the transfer function G(q), to incorpo-
rate the dynamics of H(q); the dimension equals n only in the special case in which
G(q) and H(q) have the same system poles.
We recall the one-step-ahead predictor of the innovation representation,
ˆx(k + 1|k) = (A −KC)x(k|k −1) + (B −KD)u(k) + Ky(k),
ˆy(k|k −1) = Cx(k|k −1) + Du(k).

3.6
Prediction-Error Parametric Model Estimation
107
If we can parameterize this predictor by the parameter vector, we are able to use a
number of the instruments outlined in this chapter to estimate these parameters by
means of minimizing a cost function based on the one-step-ahead prediction error
JN(θ) = 1
N
N−1

k=0
y(k) −ˆy(k|k −1,θ)
2
2.
The resulting prediction-error methods are widely used and so important that we
will devote the next chapter to them.
3.6 Prediction-Error Parametric Model Estimation
In this section, we are going to
• describe the prediction-error model-estimation problem;
• parameterize the system matrices of a Kalman ﬁlter of ﬁxed and known order
such that all stable MIMO Kalman ﬁlters of that order are presented;
• formulate the estimation of the parameters of a given Kalman ﬁlter parameteriza-
tion via the solution of a nonlinear optimization problem;
• evaluate qualitatively the bias in parameter estimation for speciﬁc SISO paramet-
ric models, such as ARX, ARMAX, output-error, and Box–Jenkins models, under
the assumption that the signal-generating system does not belong to the class of
parameterized Kalman ﬁlters; and
• describe the problems that may occur in parameter estimation, when using data
generated in closed-loop operation of the signal-generating system.
3.6.1 Introduction
This section continues the discussion started in Sect. 3.5, on estimating the param-
eters in an LTI state-space model. It addresses the determination of a model of both
the deterministic and the stochastic part of an LTI model.
The objective is to determine, from a ﬁnite number of measurements of the input
and output sequences, a one-step-ahead predictor given by the stationary Kalman
ﬁlter without using knowledge of the system and covariance matrices of the stochas-
tic disturbances. In fact, these system and covariance matrices (or alternatively the
Kalman gain) need to be estimated from the input and output measurements. The
restriction imposed on the derivation of a Kalman ﬁlter from the data is the assump-
tion of a stationary one-step-ahead predictor of a known order. The estimation of a
Kalman ﬁlter from input and output data is of interest in problems where predictions
of the output or the state of the system into the future are needed. Such predictions
are necessary in model-based control methodologies such as predictive control [18,
31, 70]. Predictions can be made from state-space models or from transfer function

108
3
System Identiﬁcation Methods
models. The estimation problems related to both model classes are treated in this
chapter.
We start in Sect. 3.6.2 with the estimation of the parameters in a state-space
model of the one-step-ahead predictor given by a stationary Kalman ﬁlter. As in
Sect. 3.5, we address the four steps of the systematic approach to estimating the
parameters in a state-space model, but now for the case in which this state-space
model is a Kalman ﬁlter. Although the output-error model can be considered as a
special case of the Kalman ﬁlter, it will be shown that a lot of insight about param-
eterizations, numerical optimization, and analysis of the accuracy of the estimates
acquired in Sect. 3.5 can be reused here.
In Sect. 3.6.3 speciﬁc and widely used SISO transfer-function models, such as
ARMAX, ARX, output-error, and Box–Jenkins, are introduced as special parame-
terizations of the innovation state-space model. This relationship with the Kalman-
ﬁlter theory is used to derive the one-step-ahead predictors for each of these speciﬁc
classical transfer-function models.
When the signal-generating system does not belong to the class of parameterized
models, the predicted output has a systematic error or bias even when the number
of observations goes to inﬁnity. Section 3.6.4 presents, for several speciﬁc SISO
parameterizations of the Kalman ﬁlter given in Sect. 3.6.3, a qualitative analysis of
this bias. A typical example of a case in which the signal-generating system does
not belong to the model class is when the signal-generating system is of higher order
than the parameterized model. The bias analysis presented here is based on the work
of Ljung [53] and Wahlberg and Ljung [92].
We conclude this chapter in Sect. 3.6.5 by illustrating points of caution when
using output-error or prediction-error methods with input and output measurements
recorded in a feedback experiment. Such closed-loop data experiments in general
require additional algorithmic operations to get consistent estimates, compared with
the case in which the data are recorded in open-loop mode. The characteristics of a
number of situations advocate the need to conduct parameter estimation with data
acquired in a feedback experiment. An example is the identiﬁcation of an F-16
ﬁghter aircraft that is unstable without a feedback control system. In addition to this
imposed need for closed-loop system identiﬁcation, it has been shown that models
identiﬁed with closed-loop data may result in improved feedback controller designs
[22, 32, 73]. The dominant plant dynamics in closed-loop mode are more relevant
to designing an improved controller than the open-loop dynamics are.
3.6.2 Prediction-Error Methods
In Sect. 3.5.7, we brieﬂy introduced prediction-error methods. When the output of
an LTI system is disturbed by additive colored measurement noise, the estimates
of the parameters describing the system obtained by an output-error method do not
have minimum variance. The second alternative presented in that section as a means
by which to obtain minimum-variance estimates was the use of prediction-error
methods.

3.6
Prediction-Error Parametric Model Estimation
109
The signal-generating system that is considered in this chapter represents the
colored-noise perturbation as a ﬁltered white-noise sequence. Thus, the input–
output data to be used for identiﬁcation are assumed to be generated in the following
way:
y(k) = G(q)u(k) + H(q)e(k)
(3.205)
where e(k) is a zero-mean white-noise sequence that is statistically independent
from u(k), and G(q) represents the deterministic part and H(q) the stochastic part
of the system. If we assume a set of input–output data sequences on a ﬁnite time in-
terval, then a general formulation of the prediction-error model-estimation problem
is as follows.
Given a ﬁnite number of samples of the input signal u(k) and the output signal
y(k), and the order of the predictor
ˆx(k + 1) = Aˆx(k) + Bu(k) + K

y(k) −C ˆx(k) −Du(k)

,
(3.206)
ˆy(k) = C ˆx(k) + Du(k)
(3.207)
the goal is to estimate the system matrices A, B, C, D, and K in this predictor such
that the output ˆy(k) approximates the output of (3.205).
Recall that the postulated model (3.206)–(3.207) represents a stationary Kalman
ﬁlter. If we assume that the entries of the system matrices of this ﬁlter depend on
the parameter vector θ, then we can deﬁne the underlying innovation model as
ˆx(k + 1|k,θ) = A(θ)ˆx(k|k −1,θ) + B(θ)u(k) + K(θ)ϵ(k),
(3.208)
y(k) = C(θ)ˆx(k|k −1,θ) + D(θ)u(k) + ϵ(k).
(3.209)
If we denote this innovation model by means of transfer functions, then, in analogy
with the signal-generating system (3.205), we get the following parameterizations
of the deterministic and stochastic part:
G(q,θ) = D(θ) + C(θ)

qI −A(θ)
−1B(θ),
H(q,θ) = I + C(θ)

qI −A(θ)
−1K(θ).
Note that the matrix A appears both in G(q) and in H(q), therefore it characterizes
the dynamics both of the deterministic and of the stochastic part of (3.205).
The four problems involved in estimating the parameters of a model deﬁned in
Sect. 3.5.2 will be addressed in the following subsections for the prediction-error
problem. The prediction-error approach is illustrated in Fig. 3.19. In this ﬁgure,
ˆy(k,θ) is derived from (3.209) as C(θ)ˆx(k|k −1,θ) + D(θ)u(k).
3.6.3 Parameterizing an Innovation State-Space Model
Corresponding to the innovation state-space model (3.208)–(3.209), we could rep-
resent conceptually the following parameterization of the one-step-ahead predictor:

110
3
System Identiﬁcation Methods
Fig. 3.19 The prediction-error model-estimation method
ˆx(k + 1|k,θ) =

A(θ) −K(θ)C(θ)

ˆx(k|k −1,θ)
+

B(θ) −K(θ)D(θ)

u(k) + K(θ)y(k),
(3.210)
ˆy(k|k −1,θ) = C(θ)ˆx(k|k −1,θ) + D(θ)u(k).
(3.211)
Various choices of parameterization for this predictor exist. The parameterization
introduced in Sect. 3.5.3 for the output-error case can be used for the prediction-
error case if the “A” matrix is taken as A−KC and the “B” matrix as [B −KD,K]
and we use [u(k),y(k)]t as the input to the system.
On making the evident assumption that the model derived from input–output
data is reachable and observable, Theorem 3.4 may be used to impose on the sys-
tem matrix A−KC the additional constraint of asymptotic stability. This constraint
then leads to the deﬁnition of the set Ω in the model structure M(θ) in (3.163).
Depending on the parameterization selected, the additional constraints in the pa-
rameter space on the one hand may be cumbersome to determine and on the other
may complicate the numerical parameter search. In identiﬁcation example 3.3, it
was illustrated how challenging it is to construct the constraints on the parame-
ter set while restricting the parameterization to yield a stable model. Furthermore,
extending the example to third- or fourth-order systems indicates that the analysis
needs to be performed individually for each dedicated model parameterization. For
such models of higher than second order, the parameter set Ω becomes nonconvex.
This increases the complexity of the optimization problem involved in estimating
the parameters. The advantage of the output normal form is that it inherently guar-
antees the asymptotic stability of the system matrix A −KC of the one-step-ahead
predictor as detailed in the following lemma.
Lemma 3.9 Let a predictor of the innovation model be given by

3.6
Prediction-Error Parametric Model Estimation
111
ˆx(k + 1) = (A −KC)ˆx(k) + (B −KD)u(k) + Ky(k),
(3.212)
ˆy(k) = C ˆx(k) + Du(k)
(3.213)
with the matrix ¯A = A −KC asymptotically stable and the pair (A,C) observable,
then a surjective parameterization is obtained by parameterizing the pair (A,C)
in the output normal form given in Deﬁnition 3.5 with the parameter vector θ ¯AC ∈
ℜnl and parameterizing the triple of matrices ( ¯B,D,K) with the parameter vector
θ ¯BDK ∈ℜ(m+l)+ml that contains all the entries of the matrices ¯B, D, and K, with
B = B −KD.
The proof goes along the same lines as the proof of Lemma 3.7.
To complete the parameter vector parameterizing (3.212)–(3.213) including the
initial state conditions ˆx(0), we simply extend θ ¯AC and θ ¯BDK in the above lemma
with these initial conditions to yield the parameter vector θ as
θ =
⎡
⎣
ˆx(0)
θ ¯AC
θ ¯BDK
⎤
⎦.
The total number of parameters in this case is p = n(2l + m) + ml + n.
3.6.4 The Prediction-Error Cost Function
The primary use of the innovation model structure (3.212)–(3.213) is to predict the
output (or state) by making use of a particular value of the parameter vector θ and of
the available input–output data sequences. To allow for on-line use of the predictor,
the predictor needs to be causal. In off-line applications, we may also operate with
mixed causal, anticausal predictors, such as the Wiener optimal ﬁlter [40] and the
Kalman-ﬁlter/smoothing combination. In what follows, we restrict the discussion to
the causal multi-step-ahead prediction.
Deﬁnition 3.10 For the innovation state-space model structure (3.210)–(3.211), the
Np multi-step-ahead prediction of the output is a prediction of the output at a time
instant k + Np making use of the input measurements u(l), l ≤k + Np and the
output measurements y(l), l ≤k. This estimate is denoted by
ˆy(k + Np|k,θ).
The deﬁnition does not give a procedure for computing a multi-step-ahead pre-
diction. The following lemma gives such a procedure based on the Kalman ﬁlter.
Lemma 3.11 Given the model structure (3.210)–(3.211) and the quantities ˆx(k|k −
1,θ), u(k), and y(k) at time instant k, then the one-step-ahead prediction at time
instant k is given as

112
3
System Identiﬁcation Methods
ˆx(k + 1|k,θ) =

A(θ) −K(θ)C(θ)

ˆx(k|k −1,θ)
+

B(θ) −K(θ)D(θ)

u(k) + K(θ)y(k),
(3.214)
ˆy(k + 1|k,θ) = C(θ)ˆx(k + 1,k,θ) + D(θ)u(k)
(3.215)
and, on the basis of this one-step-ahead prediction, the multi-step-ahead prediction
for Np > 1 is given as
ˆx(k + Np|k,θ) = A(θ)Np−1 ˆx(k + 1|k,θ)
+
Np−2

i=0
A(θ)Np−i−2B(θ)u(k + i + 1),
(3.216)
ˆy(k + Np|k,θ) = C(θ)ˆx(k + Np|k,θ) + D(θ)u(k + Np).
(3.217)
The one-step-ahead prediction model (3.216)–(3.217) in this lemma directly fol-
lows from the parameterized innovation model (3.210)–(3.211). On the basis of this
estimate, the multi-step-ahead prediction can be found by computing the response
to the system,
z(k + j,θ) = A(θ)z(k + j −1,θ) + B(θ)u(k + j −1),
for j > 1 with initial condition z(k + 1,θ) = ˆx(k + 1|k,θ). The multi-step-ahead
prediction is then obtained by setting ˆx(k + Np|k,θ) = z(k + Np,θ). Thus, the
multi-step-ahead prediction is obtained by iterating the system using the one-step-
ahead predicted state as initial condition. It can be proven that the multi-step-ahead
predictor in the lemma is the optimal predictor, in the sense that it solves the so-
called Wiener problem. The interested reader is referred to the book of Hayes [40,
Chapter 7].
Given a ﬁnite number of measurements N of the input and output sequences
of the data-generating system, we can estimate the parameters θ of the multi-step-
ahead predictor (3.216)–(3.217) by minimizing a least-squares cost function
min
θ JN(θ,Np) = min
θ
1
N
N−1

k=0
y(k) −ˆy(k|k −Np,θ)
2
2.
(3.218)
This least-squares criterion is inspired by the minimum-variance state-reconstruction
property of the Kalman ﬁlter. To reveal this link, consider the data-generating sys-
tem in innovation form for the case Np = 1,
ˆx(k + 1,θ) = A(θ)θ(k,θ) + B(θ)u(k) + K(θ)e(k),
y(k) = C(θ)ˆx(k,θ) + e(k),
with ˆx(0,θ) given and with K(θ) derived from the solution of the discrete algebraic
Riccati equation (DARE) about which we will learn more in Chap. 5. From this
innovation representation, we can directly derive the Kalman ﬁlter as
ˆx(k + 1,θ0) = A(θ0)ˆx(k,θ) + B(θ0)u(k) + K(θ)
+

y(k) −C(θ0)ˆx(k,θ0)

,
ˆy(k,θ) = C(θ)ˆx(k,θ).

3.6
Prediction-Error Parametric Model Estimation
113
The minimum-variance property of the estimates obtained by use of the Kalman
ﬁlter means that the variance of the prediction error y(k) −ˆy(k,θ0) is minimized.
Therefore, if we denote ˆy(k,θ) as the output of a Kalman ﬁlter as above but deter-
mined by the parameter vector θ instead of by θ0, then the latter satisﬁes
θ0 = argminTrE

y(k) −ˆy(k,θ)

y(k) −ˆy(k,θ)
t
.
Generally, it was shown that the Kalman ﬁlter is time-varying and, therefore,
that the variance of the prediction error will change over time. However, if we make
the assumption that the variance is constant and the prediction error is an ergodic
sequence, an estimate of θ0 may be obtained by means of the following optimization
problem:
ˆθ0 = argmin lim
N→∞
1
N
N−1

k=0
y(k) −ˆy(k|k −1,θ)
2
2.
The foregoing parameter-optimization problem will be referred to as the prediction-
error estimation problem. It forms a small part of the complete procedure of system
identiﬁcation, since it implicitly assumes the order of the state-space model (n) and
the parameterization to be given.
Henceforth, we will concentrate on the one-step-ahead prediction error, and thus
consider the optimization problem
min
θ JN(θ) = min
θ
N−1

k=0
y(k) −ˆy(k|k −1,θ)
2
2.
(3.219)
For innovation models and recalling Lemma 3.9, for the innovation model (3.212)–
(3.213), a more speciﬁc form of JN(θ) is given in the following theorem:
Theorem 3.12 The functional JN(θ) can be written as
JN(θ ¯AC,θ ¯BDK) = 1
N
N−1

k=0
y(k) −φ(k,θ ˆAC)θ ˆBDK
2
2
(3.220)
with θ ˆAC the parameters necessary to parameterize the pair ( ¯A,C) with ¯A = A −
KC and
⎡
⎢⎢⎣
ˆx(0)
vec( ¯B)
vec(K)
vec(D)
⎤
⎥⎥⎦,
with ¯B = B −KD. The matrix φ(k,θ ¯AC) ∈ℜl×(n+m(l+n)+nl) is explicitly given as
φ(k,θ ¯AC) =

C(θ ¯AC) ¯A(θ ¯AC)k
k−1

τ=0
ut(τ) ⊗C(θ ¯AC) ¯A(θ ¯AC)k=1−τ
k−1

τ=0
yt(τ) ⊗C(θ ¯AC) ¯A(θ ¯AC)k−1−τ
ut(k) ⊗Il

.

114
3
System Identiﬁcation Methods
Proof The one-step-ahead predictor related to the parameterized innovation model
(3.212)–(3.213) is
ˆx(k + 1,θ ¯AC,θ ¯BD) = ¯A(θ ¯AC)ˆx(k,θ ¯BDK) + ¯B(θ ¯BDK)u(k) + K(θ ¯BDK)y(k),
ˆy(k,θ ¯AC,θ ¯BDK) = C(θ ¯AC)ˆx(k,θ ¯AC,θBDK) + D(θ ¯BDK)u(k),
with an initial state ˆx(0,θ ¯BDK). The output of this state-space model can explicitly
be written in terms of the input, output, and initial state ˆx(0,θ ¯BDK) as:
ˆy(k,θ ¯AC,θ ¯BDK) = C(θ ¯AC) ¯A(θ ¯AC)k ˆx(0.θ ¯BDK)
+
k−1

τ=0
C(θ ¯AC) ¯A(θ ¯AC)k−1−τB(θ ¯BDK)u(τ)
+ D(θ ¯BDK)u(k)
+
k−1

τ=0
C(θ ¯AC) ¯A(θ ¯AC)k−1−τK(θ ¯BDK)y(τ).
Application of the property that vec(XYZ) = (Zt ⊗X)vec(Y) completes the
proof.
□
The parameter vector θ in the original innovation model (3.212)–(3.213) could
be constructed by simply stacking the vectors θ ¯AC and θ ¯BDK of Lemma 3.9 as
θ =

 θ ¯AC
θ ¯BDK

.
The output normal form presented in Lemma 3.11 can be used to parameterize the
formulation of the functional as expressed in Lemma 3.9.
3.6.5 Numerical Parameter Estimation
To solve the prediction-error problem, the iterative methods can be generally used.
Of course, some minor adjustments are necessary. For example, if the one-step-
ahead prediction is used, the cost function is computed by simulating the predictor
given by the system (3.212)–(3.213), and the dynamic system (3.182)–(3.82) that
needs to be simulated to obtain the Jacobian in the Gauss–Newton method becomes
Xi(k + 1,θ) = ¯A(θ)Xi(k,θ) + ∂¯A(θ)
∂θ(i) ˆx(k,θ) + ∂¯B(θ)
∂θ(i) u(k)
+ ∂K(θ)
∂θ(i) y(k),
∂¯y(k,θ)
∂θ(i)
= C(θ)Xi(k,θ) + ∂C(θ)
∂θi
ˆx(k,θ) + ∂D(θ)
∂θ(i) u(k),
with

3.6
Prediction-Error Parametric Model Estimation
115
¯A(θ) = A(θ) −K(θ)C(θ),
¯B(θ) = B(θ) −K(θ)D(θ).
Similar straightforward adjustments are needed in the other numerical methods dis-
cussed in Sect. 3.5.5.
3.6.6 Analyzing the Accuracy of the Estimates
To analyze the accuracy of the estimates obtained, the covariance matrix of the
solution ˆθN to the prediction-error optimization problem can be used. The theory
presented in Sect. 3.5.6 for the output-error methods applies also to the prediction-
error methods. Using the covariance matrix to analyze the accuracy of the estimated
model is done under the assumption that the system to be identiﬁed belongs to the
assumed model set M(θ) (3.163). Generally, in practice this assumption does not
hold and the model parameters will be biased.
Using an output-error or prediction-error method, the estimates of the model pa-
rameters are obtained from a ﬁnite number of input and output measurements as
ˆθN = argminJN(θ).
The best possible model θ⋆within a given model structure is given by the minimiz-
ing parameter vector of the cost function
θ⋆= argmin lim
N→∞JN(θ) = argmin ¯J(θ).
The quality of an estimated model ˆθN can now be measured using [54, 68]
E ¯J( ˆθN)
(3.221)
where the expectation E is with respect to the model ¯θN. The measure (3.221) de-
scribes the expected ﬁt of the model to the true system, when the model is applied to
a new set of input and output measurements that have the same properties (distribu-
tions) as the measurements used to determine ˆθN. This measure can be decomposed
as follows [54, 68]:
E ¯J( ¯θN) ≈E
y(k) −y0(k,θ0)
2
2



noise
+E
y0(k,θ0) −ˆy(k,θ⋆)
2
2



bias
+E
 ˆy(k,θ⋆) −
ˆ
k, ˆθN
2
2



variance
,
where y0(k,θ0) is the output of the predictor based on the true model, that is,
y(k) = y0(k,θ) + e(k), with e(k) white-noise residuals. The three parts in this de-
composition will now be discussed.
• Noise part: The variance of the error between the measured output and a predictor
based on the true model 0. This error is a white-noise sequence.

116
3
System Identiﬁcation Methods
• Bias part: The model structures of the true predictor y0(k,θ0) and of the model
class adopted can be different. The bias error expresses the difference between
the true predictor and the best possible approximation of the true predictor within
the model class adopted.
• Variance part: The use of a ﬁnite number of samples N to determine the model
ˆθN results in a difference from the best possible model (within the model class
adopted) θ⋆based on an inﬁnite number of samples.
3.6.7 Some Model Parameterizations for SISO Systems
For identiﬁcation of SISO systems, various parameterizations of the innovation rep-
resentation (3.212)–(3.213) are in use [9, 44, 54, 69]. It is shown in this section that
these more-classical model parameterizations can be treated as special cases of the
MIMO innovation model parameterization discussed in Sect. 3.6.2. We adopt the
common practice of presenting these special SISO parameterizations in a transfer-
function setting.
3.6.8 The ARMAX and ARX Model Structures
The ARMAX, standing for Auto-Regressive Moving Average with eXogenous input,
model structure considers the following speciﬁc case of the general input–output
description (3.205):
y(k) =
b1q−1 + ··· + bnq−n
1 + a1q−1 + ··· + anq−n u(k) + 1 + c1q−1 + ··· + cnq−n
1 + a1q−1 + ··· + anq−n e(k)
(3.222)
where e(k) ∈ℜis again a zero-mean white-noise sequence that is independent from
u(k) ∈ℜand ai, bi, and ci (i = 1,2,...,n) are real-valued scalars. It is common
practice to use negative powers of q in the description of the ARMAX model.
A more general ARMAX representation exists, in which the order of the numer-
ators and denominators may be different, and the transfer from u(k) to y(k) may
contain an additional dead-time. To keep the notation simple, these ﬁne-tunings are
not addressed in this book. When the order n is known, we can deﬁne an estima-
tion problem to estimate the parameters ai, bi, and ci (i = 1,2,...,n) from a ﬁnite
number of input–output measurements. The formulation and the solution of such an
estimation problem is discussed next and is addressed by establishing a one-to-one
correspondence between the ARMAX transfer-function description (3.222) and a
particular minimal parameterization of the state-space system (3.212)–(3.213), as
summarized in the following lemma.
Lemma 3.13 There is a one-to-one correspondence between the ARMAX model
given by (3.222) and the following parameterization of a SISO state-space system
in innovation form:

3.6
Prediction-Error Parametric Model Estimation
117
x(k + 1) =
⎡
⎢⎢⎢⎢⎢⎣
−a1
1
0
···
0
−a2
0
1
···
0
...
...
...
...
...
−an−1
0
···
···
1
−an
0
···
···
0
⎤
⎥⎥⎥⎥⎥⎦
x(k) +
⎡
⎢⎢⎢⎢⎢⎣
b1
b2
...
bn−1
bn
⎤
⎥⎥⎥⎥⎥⎦
u(k)
+
⎡
⎢⎢⎢⎢⎢⎣
c1 −a1
c2 −a2
...
cn−1 −an−1
cn −an
⎤
⎥⎥⎥⎥⎥⎦
e(k),
(3.223)
y(k) =
1
0
0
···
0
x(k) + e(k).
(3.224)
Proof The proof follows on showing that from the parameterization (3.223)–(3.224)
we can obtain in a unique manner the difference equation (3.222). Let xi(k) denote
the ith component of the vector x(k), then (3.223) is equivalent to the following set
of equations:
x1(k + 1) = −a1x1(k) + x2(k) + b1u(k) + (c1 −a1)e(k),
x2(k + 1) = −a2x1(k) + x3(k) + b2u(k) + (c2 −a2)e(k),
...
xn(k + 1) = −anx1(k) + bnu(k) + (cn −an)e(k).
Making the substitution y(k) = x1(k) + e(k) yields
x1(k + 1) = −a1y(k) + x2(k) + b1u(k) + c1e(k),
⋆
x2(k + 1) = −a2y(k) + x3(k) + b2u(k) + c2e(k),
⋆
...
xn−1(k + 1) = −an−1y(k) + xn(k) + bn−1u(k) + cn−1e(k),
⋆
xn(k + 1) = −any(k) + bnu(k) + cne(k).
Increasing the time index of all the equations indicated by a star (⋆) and subse-
quently replacing xn(k + 1) by the right-hand side of the last equation yields the
following expressions for the indicated equations:
x1(k + 2) = −a1y(k + 1) + x2(k + 1) + b1u(k + 1) + c1e(k + 1),
x2(k + 2) = −a2y(k + 1) + x3(k + 1) + b2u(k + 1) + c2e(k + 1),
...
xn−2(k + 2) = −an−2y(k + 1) + xn−1(k + 1) + bn−2u(k + 1)
+ cn−2e(k + 1),
xn−1(k + 2) = −an−1y(k + 1) −any(k) + bnu(k) + cne(k) + bn−1u(k + 1)
+ cn−1e(k + 1).

118
3
System Identiﬁcation Methods
Implementing the above recipe n −2 times yields the single equation
x1(k + n) = −a1y(k + n −1) −a2y(k + n −2) −··· −any(k)
+ b1u(k + n −1) + b2u(k + n −2) + ··· + bnu(k)
+ c1e(k + n −1) + c2e(k + n −2) + ··· + ane(k).
By making use of the output equation (3.114), we ﬁnally obtain
y(k + n) = −a1y(k + n −1) −a2y(k + n −2) −··· −any(k)
+ b1u(k + n −1) + b2u(k + n −2) + ··· + bnu(k)
+ e(k + n) + c1e(k + n −1) + c2e(k + n −2) + ··· + ane(k).
This is the difference equation of (3.222).
□
The ARMAX model is closely related to the observer canonical form in linear
system theory. The ARMAX model can be converted into the observer canonical
form and vice versa by turning the state-vector upside down. The one-step-ahead
predictor for the ARMAX model is summarized in the next lemma.
Lemma 3.14 Let the differences ci −ai be denoted by ki for i = 1,2,...,n, then
the one-step ahead predictor for the ARMAX model (3.222) is given by
ˆy(k|l −1) =
b1q−1 + ··· + bnq−n
1 + c1q−1 + ··· + cnq−n u(k)
+
k1q−1 + ··· + knq−n
1 + c1q−1 + ··· + cnq−n y(k).
(3.225)
Proof Making use of the state-space parameterization of the ARMAX model given
by (3.223) and (3.224), the one-step-ahead prediction based on (3.216) and (3.217)
equals
ˆx(k + 1|k) =
⎛
⎜⎜⎜⎜⎜⎝
⎡
⎢⎢⎢⎢⎢⎣
−a1
1
0
···
0
−a2
0
1
···
0
...
...
...
...
...
−an−1
0
···
···
1
−an
0
···
···
0
⎤
⎥⎥⎥⎥⎥⎦
−
⎡
⎢⎢⎢⎢⎢⎣
k1
k2
...
kn−1
kn
⎤
⎥⎥⎥⎥⎥⎦
1
0
···
0
0
⎞
⎟⎟⎟⎟⎟⎠
× ˆx(k|k −1)
+
⎡
⎢⎢⎢⎢⎢⎣
b1
b2
...
bn−1
bn
⎤
⎥⎥⎥⎥⎥⎦
u(k) +
⎡
⎢⎢⎢⎢⎢⎣
k1
k2
...
kn−1
kn
⎤
⎥⎥⎥⎥⎥⎦
y(k),
ˆy(k|k −1) =
1
0
0
···
0
ˆx(k|k −1);

3.6
Prediction-Error Parametric Model Estimation
119
with ci = ki + ai, this equals
ˆx(k + 1|k) =
⎡
⎢⎢⎢⎢⎢⎣
−c1
1
0
···
0
−c2
0
1
···
0
...
...
...
...
...
−cn−1
0
···
···
1
−cn
0
···
···
0
⎤
⎥⎥⎥⎥⎥⎦
ˆx(k|k −1) +
⎡
⎢⎢⎢⎢⎢⎣
b1
b2
...
bn−1
bn
⎤
⎥⎥⎥⎥⎥⎦
u(k)
+
⎡
⎢⎢⎢⎢⎢⎣
k1
k2
...
kn−1
kn
⎤
⎥⎥⎥⎥⎥⎦
y(k),
ˆy(k|k −1) =
1
0
0
···
0
ˆx(k|k −1).
Following the proof of Lemma 3.11, the transfer-function representation of this
state-space model equals (3.225).
□
Now on introducing the following polynomials in the shift operator q,
A(q) = 1 + a1q−1 + ··· + anq−n,
B(q) = b1q−1 + ··· + bnq−n,
C(q) = 1 + c1q−1 + ··· + cnq−n,
the ARMAX model can be denoted by
y(k) = B(q)
A(q)u(k) + C(q)
A(q)e(k).
(3.226)
The one-step-ahead predictor is denoted by
ˆy(k|k −1) = B(q)
C(q)u(k) + C(q −A(q))
C(q)
y(k).
(3.227)
This is a stable predictor, provided that the polynomial C(q) has all its roots within
the unit circle.
The Auto-Regressive with eXogenous input (ARX) model is a special case of
the ARMAX model structure constraining the parameters ci = 0 for i = 1,2,...,n,
and thus C(q) = 1. Therefore, the ARX model is given by
y(k) = B(q)
A(q)u(k) +
1
A(q)e(k),
and the associated predictor equals
ˆy(k|k −1) = B(q)u(k) +

1 −A(q)

y(k).
(3.228)
To identify a model in the ARMAX or ARX structure, we minimize the
prediction-error cost function JN(θ) described in Sect. 3.6.2. The methods for min-
imizing this cost function were described in Sects. 3.5.5 and 3.6.2. They require

120
3
System Identiﬁcation Methods
the evaluation of the cost function and its Jacobian. This evaluation depends on the
particular parameterization of the state-space innovation model. As pointed out in
Sect. 3.6.2, the choice of a speciﬁc parameterization changes only the following
matrices in the evaluation of the Jacobian:
∂¯A
∂θ(1),
∂B
∂θ(1),
∂C
∂θ(1),
∂D
∂θ(1),
∂K
∂θ(1)
for i = 1,2,...,p. The following example shows that these quantities are easy to
compute.
3.6.9 Identiﬁcation Example 3.9
Given an ARMAX model, with matrices
A =

−θ1
1
−θ2
0

,
B =

θ3
θ4

,
C =
1
0
,
K =

θ5
θ6

it is easy to see that
¯A = A −KC =

−θ1 −θ5
1
−θ2 −θ6
0

,
and therefore
∂¯A
∂θi
=

−1
0
0
0

,
i = 1,2,
∂¯A
∂θi
=

 0
0
−1
0

,
i = 1,5,
∂¯A
∂θi
=

0
0
0
0

,
i = 3,4.
The following example illustrates that, for an ARX model, minimization of the
prediction-error cost function JN(θ) described in Sect. 3.6.2 leads to a linear least-
squares problem.
3.6.10 Identiﬁcation Example 3.10
The ARX predictor is given by (3.228). Taking
A(q) = 1 + a1q−1 + ··· + anq−n,
B(q) = b1q−1 + ··· + bnq−n,

3.6
Prediction-Error Parametric Model Estimation
121
we can write
ˆy(k|k −1) = φ(k)tθ,
with
θ =
−a1
−a2
···
−an|b1
b2
···
bn
t ,
φ(k) =
y(k −1)
···
y(k −1)|u(k −1)
···
u(k −n)
.
Thus, the prediction-error cost function is given by
JN(θ) = 1
N
N−1

k=0

y(k) −φ(k)tθ
2.
Identiﬁcation example 3.10 shows that this form of the cost function leads to a linear
least-squares problem.
3.6.11 The Box–Jenkins and Output-Error Model Structures
The Box–Jenkins (BJ) [9] model structure parameterizes the input–output relation-
ship (3.205) as
y(k) =
b1q−1 + ··· + bnq−n
1 + a1q−1 + ··· + anq−n u(k) + 1 + c1q−1 + ··· + cnq−n
1 + d1q−1 + ··· + dnq−n e(k). (3.229)
On introducing the polynomials
A(q) = 1 + a1q−1 + ··· + anq−n,
(3.230)
B(q) = b1q−1 + ··· + bnq−n,
(3.231)
C(q) = 1 + c1q−1 + ··· + cnq−n,
(3.232)
D(q) = 1 + d1q−1 + ··· + dnq−n
(3.233)
the BJ model can be denoted by
y(k) = B(q)
A(q)u(k) + C(q)
D(q)e(k).
(3.234)
A similar result to that in Lemma 3.11, but now for the BJ model, is given
next.
Lemma 3.15 There is a one-to-one correspondence between the BJ model given by
(3.229) and the following parameterization of a SISO state-space system in innova-
tion form:

122
3
System Identiﬁcation Methods
x(k + 1) =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
−a1
1
0
···
0
0
0
0
···
0
−a2
0
1
···
0
0
0
0
···
0
...
...
...
...
...
...
...
...
...
...
−an−1
0
0
···
1
0
0
0
···
0
−an
0
0
···
0
0
0
0
···
0
0
0
0
···
0
−d1
1
0
···
0
0
0
0
···
0
−d2
0
1
···
0
...
...
...
...
...
...
...
...
...
...
0
0
0
···
0 −dn−1
0
0
···
1
0
0
0
···
0
−dn
0
0
···
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
x(k)
+
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
b1
b2
...
bn−1
bn
0
0
...
0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
u(k) +
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
0
...
0
0
c1 −d1
c2 −d2
...
cn−1 −dn−1
cn −dn
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
e(k),
(3.235)
y(k) =
1
0
0
···
0 1
0
0
···
0
x(k) + e(k).
(3.236)
The proof is similar to the one given for Lemma 3.11.
On embedding the speciﬁc BJ model into the general state-space model consid-
ered earlier, we draw the conclusion that the asymptotic stability of the one-step-
ahead predictor requires the roots of the deterministic polynomial A(q) to be within
the unit circle. This condition is necessary in order to make the pair (A,Q1/2) of the
BJ model (3.235)–(3.236) corresponding to the state-space model being stabilizable.
The following lemma shows that the one-step-ahead predictor of the BJ model
equals
ˆy(k|k −1) = D(q)
C(q)
D(q)
A(q) u(k) + C(q) −D(q)
C(q)
y(k).
Lemma 3.16 The one-step-ahead predictor for the BJ model (3.234) is given by
ˆy(k|k −1) = D(q)
C(q)
B(q)
A(q)u(k) + C(q) −D(q)
C(q)
y(k)
(3.237)
where the polynomials A(q), B(q), C(q), and D(q) are given by (3.229)–(3.233).
Proof Making use of the state-space parameterization of the BJ model given by
(3.234)–(3.235) and the deﬁnition ki = ci −di, the one-step-ahead prediction based
on (3.216)–(3.217) equals

3.6
Prediction-Error Parametric Model Estimation
123
ˆx(k + 1|k) =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
−a1
1
0
···
0
0
0
0
···
0
−a2
0
1
···
0
0
0
0
···
0
...
...
...
...
...
...
...
...
...
...
−an−1
0
0
···
1
0
0
0
···
0
−an
0
0
···
0
0
0
0
···
0
−k1
0
0
···
0
−d1 −k1
1
0
···
0
−k2
0
0
···
0
−d2 −k2
0
1
···
0
...
...
...
...
...
...
...
...
...
...
−kn−1
0
0
···
0 −dn−1 −kn−1
0
0
···
1
−kn
0
0
···
0
−dn −kn
0
0
···
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
× ˆx(k|k −1) +
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
b1
b2
...
bn−1
bn
0
0
...
0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
u(k) +
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
0
...
0
0
k1
k2
...
kn−1
kn
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
y(k),
ˆy(k|k −1) =
1
0
0
···
0 1
0
0
···
0
ˆx(k|k −1).
This system is denoted brieﬂy by
ˆx(k + 1|k) =

A11
0
A21 A22

ˆx(k|k −1) +

B
0

u(k) +

0
K

y(k),
ˆy(k|k −1) = [C1|C2]ˆx(k|k −1).
Since A21 = −KC1, we can write the one-step-ahead prediction of the output as
ˆy(k|k −1) = [C1|C2]

qI −

 A11
0
−KC1 A22
−1 $
B
0

u(k) +

0
K

y(k)
%
= [C1|C2]

qI −A11
0
KC1
qI −A22
−1 $
B
0

u(k) +

0
K

y(k)
%
=

C1(qI −A11)−1B −C2(qI −A22)−1KC1(qI −A11)−1B

u(k)
+ C2(qI −AA22)−1Ky(k)
=

I −C2(qI −A22)−1K)

C1(qI −A11)−1B

u(k)
+ C2(qI −A22)−1Ky(k).
(3.238)

124
3
System Identiﬁcation Methods
Since
A22 + KC2 =
⎡
⎢⎢⎢⎢⎢⎣
−d1
1
0
···
0
−d2
0
1
···
0
...
...
...
...
...
−dn−1
0
0
···
1
−dn
0
0
···
0
⎤
⎥⎥⎥⎥⎥⎦
,
and ki = ci −di, it follows from Lemma 3.11 that
I −C2(qI −A22)−1K =

C(q)
D(q)
−1
.
Therefore, (3.238) can be written in terms of the deﬁned polynomials as (3.237).
On putting the parameters ci and di for i = 1,2,...,n into the BJ model struc-
ture, we obtain a model and predictor that ﬁt within the output-error model. The
resulting speciﬁc transfer-function parameterization has classically been referred to
as the output-error (OE) model. In polynomial form, it reads as
y(k) = B(q)
A(q)u(k) + e(k),
and the associated predictor is given by
ˆy(k|k −1) = B(q)
A(q)u(k).
(3.239)
Thus, if the OE model is stable, then also its predictor is stable.
□
3.6.12 Qualitative Analysis of the Model Bias
The asymptotic variance analyzed in Sects. 3.5.6 and 3.6.2 can be used as an in-
dication of the accuracy of the estimated parameters if the system that generated
the input–output data set belongs to the model set M(θ). The latter hypothesis
generally does not hold. Examples are when the underlying system has a very
large state dimension, whereas for designing a controller one is interested in a low-
dimensionality model.
Therefore, in addition to the variance, also the bias in the estimated parameters
needs to be considered. In this section, we will analyze the bias for some speciﬁc
SISO systems. We ﬁrst introduce some notation. Let θ⋆be the minimizing parameter
vector of the cost function JN(θ) for N →∞
θ⋆= argmin lim
N→∞JN(θ) = argmin ¯J(θ),
and let the system by which the input–output data were generated be described as

3.6
Prediction-Error Parametric Model Estimation
125
y(k) = B0(q)
A0(q)u(k) + v(k)
=
b0
1q−1 + b0
2q−2 + ··· + b0
nq−n
1 + a0
1q−1 + a0
2q−2 + ··· + a0nq−n u(k) + v(k)
(3.240)
with n the order of the system and with v(k) a stochastic perturbation that is in-
dependent from u(k). Under these notions the bias is the difference between com-
parable quantities derived from the estimated model and from the true system that
persists on taking the limit for N →∞. One such comparable quantity is the trans-
fer function, which can, for example, be presented as a Bode plot.
To quantify the variance in the estimate ˆθN given by
ˆθN = argminJN(θ),
we should then analyze
E

[ ˆθN −θ⋆][ ˆθN −θ⋆]t
,
instead of E[[ ˆθN −θ0][ ˆθN −θ0]] as was done in Sect. 3.5.6.
The bias of the estimated model is analyzed under the assumption that the time
sequences are ergodic. In that case, the following limit holds:
lim
N→∞
1
N
N−1

k=0

y(k) −ˆy(k|k −1)
2 = E

y(k) −ˆy(k|k −1)
2
.
When the prediction of the output depends on the parameter vector θ, the above
equation can be written
lim
N→∞
1
N
N−1

k=0

y(k) −ˆy(k|k −1,θ)
2 = ¯J(θ)
(3.241)
establishing the link with the cost function ¯J(θ). This cost function is now ana-
lyzed for the ARMAX and BJ model structures that were introduced in the previous
section.
Lemma 3.17 [54] Let the LTI system that generates the output y(k) for a given
input sequence u(k), k = 0,1,2,...,N −1, with spectrum Φu(ω) be denoted by
y(k) = G0(q)u(k) + v(k),
where v(k) is a stochastic perturbation independent from u(k) with spectrum
Φv(ω), and let the time sequences v(k), u(k), and y(k) be ergodic and let the pa-
rameters ai, bi, and ci of an ARMAX model be stored in the parameter vector θ,
then the parameter vector θ⋆minimizing the cost function
¯J(θ) = lim
N→∞
1
N
N−1

k=0

y(k) −ˆy(k|k −1,θ)
2
satisﬁes

126
3
System Identiﬁcation Methods
θ⋆= argmin 1
2π
& π
−π
''''G0

ejω
−B(ejω,θ)
A(ejω,θ)
''''
2''''
A(ejω,θ)
C(ejω,θ)
''''
2
Φu(ω)
+
''''
A(ejω,θ)
C(ejω,θ)
''''
2
Φv(ω)dω.
(3.242)
Proof The one-step-ahead predictor related to the ARMAX model structure is given
by (3.227). Hence, the one-step-ahead prediction error ϵ(k|k −1) = y(k)−ˆy(k|k −
1) is given by
ϵ(k|k −1) = A(q,θ)
C(q,θ)y(k) −B(q,θ)
C(q,θ)u(k).
To express ϵ(k|k −1) as the sum of two statistically independent time sequences,
simplifying the calculation of the spectrum of ϵ(k|k −1), we substitute into the
above expression the model of the system that generated the sequence y(k). This
yields
ϵ(k|k −1) = A(q,θ)
C(q,θ)

G0(q) −B(q,θ)
A(q,θ)

u(k) + A(q,θ)
C(q,θ)v(k).
By virtue of the ergodic assumption,
¯J(θ) = E

ϵ(k|k −1)2
.
Using Parseval’s identity, see the Appendix, (assuming a sample time T = 1), this
can be written as
E

ϵ(k|k −1)2
= 1
2π
& π
−π
Φϵ(ω)dω.
(3.243)
An expression for Φϵ(ω) can be derived by exploiting the independence between
u(k) and v(k):
Φϵ(ω) =
''''G0

ejω
−B(ejω,θ)
A(ejω,θ)
''''
2''''
A(ejω,θ)
C(ejω,θ)
''''
2
Φu(ω) +
''''
A(ejω,θ)
C(ejω,θ)
''''
2
Φv(ω).
Substitution into (3.243) results in (3.242) as desired.
□
Since the ARX model structure is a special case of the ARMAX model struc-
ture, we can, with a redeﬁnition of the parameter vector θ, immediately derive the
expression for the parameter vector θ⋆minimizing ¯J(θ) in (3.241) as
θ⋆= argmin 1
2π
& π
−π
''''G0

ejω
−B(ejω,θ)
A(ejω,θ)
''''
2''A

ejω,θ
''2Φu(ω)
+
''A

ejω,θ
''2Φv(ω)dω.
(3.244)
The use of Lemma 3.17 in qualitatively analyzing the bias in the estimate ob-
tained with the ARX model structure is highlighted in the following example.

3.6
Prediction-Error Parametric Model Estimation
127
Fig. 3.20 A schematic representation of an acoustical duct
3.6.13 Identiﬁcation Example 3.11
The system to be modeled is an acoustical duct, depicted in Fig. 3.20, which is used
for active-noise-control experiments. At the left-hand end of the duct is mounted a
loudspeaker that produces an undesired noise. The goal is to drive the secondary
loudspeaker mounted just before the other end of the duct such that at the far-right
end of the duct a region of silence is created. Most control algorithms used in ac-
tive noise control need a model of the transfer from the secondary loudspeaker to
the error microphone. A high-order approximation of the acoustical relationship be-
tween the speaker activated with the signal u, and the microphone producing the
measurements y, is given by the following transfer function:
G(q) =
	19
j=0 bjq−j
	19
j=0 ajq−j
with aj and bj listed in Table 3.2.
The magnitude of the Bode plot of the transfer function G(ejω) is depicted by
the thick line in the top part of Fig. 3.21. The input sequence u(k) is taken to be
a zero-mean unit-variance white-noise sequence of length 10000. With this input
sequence, an output sequence y(k) is generated using the high-order transfer func-
tion G(q). These input and output sequences are then used to estimate a sixth-order
ARX model via the use of a QR factorization to solve the related linear least-squares
problem, see identiﬁcation example 3.7. The estimated transfer function ˆG(ejω) is
depicted by the thin line in the top part of Fig. 3.21. We observe that, according
to (3.241) with Φv(ω) = 0, the estimated low-order model accurately matches the
high-order model for those frequency values for which |A(ejω)| is large. From the
graph of |A(ejω)| in the lower part of Fig. 3.21, we observe that this holds in the
high-frequency region above 100 Hz.
The following lemma gives a result similar to Lemma 3.17, but for the BJ model.
Lemma 3.18 [54] Let the LTI system that generates the output y(k) for a given
input sequence u(k), k = 0,1,2,...,N −1, with spectrum Φu(ω) be denoted by
y(k) = G0(q)u(k) + v(k),
where v(k) is a stochastic perturbation independent from u(k) with spectrum
Φv(ω), let the time sequences v(k), u(k), and y(k) be ergodic, and let the param-

128
3
System Identiﬁcation Methods
Table 3.2 Coefﬁcients of the transfer function between u and y in the model of the acoustical duct
θ
Value
θ
Value
a0
1
b0
0
a1
−1.8937219532483E-0
b1
−5.6534330123106E-6
a2
9.2020408176247E-1
b2
5.6870704280702E-6
a3
8.4317527635808E-13
b3
7.7870811926239E-3
a4
−6.9870644340972E-13
b4
1.3389477125431E-3
a5
3.2703011891141E-13
b5
−9.1260667240191E-3
a6
−2.8053825784320E-14
b6
1.4435759589218E-8
a7
−4.8518619047975E-13
b7
−1.2021568096247E-8
a8
9.0515016323085E-13
b8
−2.2746529807395E-9
a9
−8.9573340462955E-13
b9
6.3067990166664E-9
a10
6.2104932381850E-13
b10
9.1305924779895E-10
a11
−4.0655443037130E-13
b11
−7.5200613526843E-9
a12
3.8448359402553E-13
b12
1.9549739577695E-9
a13
−4.9321540807220E-13
b13
1.3891832078608E-8
a14
5.3571245452629E-13
b14
−1.6372496840947E-8
a15
−6.7043859898372E-13
b15
9.0003511972213E-3
a16
6.5050860651120E-13
b16
−1.9333235975678E-3
a17
6.6499999999978E-1
b17
−7.0669966879457E-3
a18
−1.2593250989101E-0
b18
−3.7850561971775E-6
a19
6.1193571437226E-1
b19
3.7590122810601E-6
In the above values, E-0 means ×100, E-6 means ×10−6, etc.
Fig. 3.21 Top: A magnitude
plot of the transfer function
between u(k) and y(k) of the
true (thick line) and the
estimated ARX model (thin
line). Bottom: The weighting
function |A(ejω)|
eters ai, bi, ci, and di of a BJ model be stored in the parameter vector θ, then the
parameter vector θ⋆minimizing the cost function
¯J(θ) = lim
N→∞
1
N
N−1

k=0

y(k) −ˆy(k|k −1,θ)
2

3.6
Prediction-Error Parametric Model Estimation
129
satisﬁes
θ⋆= argmin 1
N
& π
−π
''''G0

ejω
−B(ejω,θ)
A(ejω,θ)
''''
2''''
D(ejω,θ)
C(ejω,θ)
''''
2
Φu(ω)
+
''''
D(ejω,θ)
C(ejω,θ)
''''
2
Φv(ω)dω.
(3.245)
The proof is similar to the proof of Lemma 3.17 using the predictor related to the
BJ model structure as given by (3.237).
Since the OE model structure is a special case of the BJ model structure, we can
with a redeﬁnition of the parameter vector θ immediately derive an expression for
the parameter vector θ⋆of an OE model minimizing the cost function ¯J(θ):
θ⋆= argmin 1
N
& π
−π
''''G0

ejω
−B(ejω,θ)
A(ejω,θ)
''''
2
Φu(ω) + Φv(ω)dω.
(3.246)
The use of Lemma 3.18 in qualitatively analyzing the bias in the estimate ob-
tained with the OE model structure is highlighted with a continuation of identiﬁca-
tion example 3.11.
3.6.14 Identiﬁcation Example 3.12
Making use of the same acoustical model of the duct as analyzed in identiﬁcation
example 3.11, we now attempt to estimate a sixth-order output-error model. By gen-
erating several realizations of the input and output data sequences with the same sta-
tistical properties as outlined in identiﬁcation example 3.11, a series of sixth-order
output-error models was estimated using the tools from the MATLAB System Iden-
tiﬁcation toolbox [56]. Because of the nonquadratic nature of the cost function to be
optimized by the output-error method, the numerical search discussed in Sect. 3.6.2
“got stuck” in a local minimum a number of times. The best result obtained out of
30 trials is presented below.
A Bode plot of the transfer function G(ejω) is depicted by the thick line in
Fig. 3.22. The transfer function ˆG(ejω) of one estimated sixth-order OE model is
also depicted in Fig. 3.22. Clearly, the most dominant peak around 25 Hz is com-
pletely captured. According to the theoretical qualitative analysis summarized by
(3.246) for Ψ v(ω) = 0, it would be expected that the second most dominant peak
around 90 Hz would be matched. However, this conclusion assumes that the global
minimum of the cost function ¯J(θ) optimized by the output-error method has been
found. The fact that the peak around 200 Hz is matched subsequently instead of the
one around 90 Hz indicates that the global optimum still is not being found.
The BJ model structure allows us to estimate the parameters ai and bi for
i = 1,2,...,n unbiasedly, irrespective of the values of the parameters ci, di, for
i = 1,2,...,n, provided that they generate a stable predictor, and provided that n

130
3
System Identiﬁcation Methods
Fig. 3.22 Top: A magnitude
plot of the transfer function
between u(k) and y(k) of the
true (thick line) and the
estimated OE model (thin
line). Bottom: The weighting
function of the error on the
transfer function estimate
corresponds to the true order of the data-generating system. Let the data-generating
system be represented as
y(k) = B0(q)
A0(q)u(k) + v(k),
with v(k) a stochastic zero-mean perturbation that is independent from u(k). The
BJ model structure has the ability to estimate the deterministic part,
B(q)
A(q)u(k),
correctly even if the noise part,
C(q)
D(q)e(k),
does not correspond to that in the underlying signal-generating system. To see this,
let θab denote the vector containing the quantities ai, bi, i = 1,2,...,n, and let θcd
denote the vector containing the quantities ci, di, i = 1,2,...,n. Consider the noise
part of the BJ model to be ﬁxed at some value ¯θcd, then we can denote the criterion
JN(θ) as
JN(θab, ¯θcd) = 1
N

y(k) −ˆy(k|k −1)
2
= 1
N
N−1

k=0

D(q, ¯θcd)
C(q, ¯θcd)
B0(q)
A0(q)u(k) + v(k) −B(q,θab)
A(q,θab)u(k)
2
.
When we take the limit N →∞and assume ergodicity of the time sequences, then,
by Parseval’s identity (9.55) on p. 544, the prediction-error methods will perform
the following minimization:
min
θab
1
2π
& π
−π
''''
D(ejω, ¯θcd)
C(ejω, ¯θcd)
''''
2 ''''
B0(ejω)
A0(ejω) −B(ejω,θab)
A(ejω,θab)
''''
2



Φu(ω)
+
''''
D(ejω, ¯θcd)
C(ejω, ¯θcd)
''''
2
Φv(ω)dω.

3.6
Prediction-Error Parametric Model Estimation
131
When n is correctly speciﬁed, or, more generally, when the orders of the polyno-
mials A0(q) and B0(q) correspond exactly to the orders of the polynomials A(q)
and B(q), respectively, the minimum that corresponds to the underbraced term is
zero. Therefore, if the global optimum of the above criterion ¯J(θab) is found, the
true values of the polynomials A0(q) and B0(q) are estimated.
3.6.15 Estimation Problems in Closed-Loop Systems
This section brieﬂy highlights some of the complications that arise on using the
prediction-error method with input and output samples recorded during a closed-
loop experiment. We consider the closed-loop conﬁguration of an LTI system P and
an LTI controller C as depicted in Fig. 3.23. In general, system identiﬁcation is much
more difﬁcult in closed-loop identiﬁcation experiments. This will be illustrated by
means of a few examples to highlight that, when identifying innovation models, it is
necessary to parameterize both the deterministic and the stochastic part of the model
exactly equal to the corresponding parts of the signal-generating system. The ﬁrst
example assumes only a correct parameterization of the deterministic part, whereas
in the second example both the stochastic and the deterministic part are correctly
parameterized.
3.6.16 Identiﬁcation Example 3.13
Consider the feedback conﬁguration in Fig. 3.23 driven by the external reference
signal r(k), with the system P given as
y(k) = b0
1u(k −1) + b0
2u(k −2) + v(k)
(3.247)
where v(k) is a zero-mean stochastic sequence that is independent from the external
reference r(k). The controller C is a simple proportional controller [27], of the form
u(k) = K

r(k) −y(k)

.
(3.248)
If we were to use an OE model structure with a correctly parameterized determin-
istic part corresponding to that of the system P , the one-step-ahead prediction error
would be
ϵ(k|k −1) = y(k) −
u(k −1)
u(k −2)
b1
b2

,
and with a prediction-error method we would solve the following least-squares prob-
lem:
min
b1,b2
1
N
N−1

k=0

y(k) −
u(k −1)
u(k −2)
b1
b2
2
.

132
3
System Identiﬁcation Methods
Fig. 3.23 A block scheme of an LTI system P in a closed-loop conﬁguration with a controller C
If we substitute for y(k) the expression given in (3.244), this problem can be written
as
min
β
1
N
N−1

k=0
u(k −1)
u(k −2)
β + v(k)
2 ,
subject to
β =

b0
1 −b1
b0
2 −b2

.
We assume the recorded time sequences to be ergodic. If the above least-squares
problem has a unique solution in the limit of N →∞, this solution is zero (β = 0),
provided that the following conditions are satisﬁed:
E

u(k −1)v(k)

= 0,
E

u(k −2)v(k)

= 0.
(3.249)
However, substituting (3.247) into (3.248) yields
u(k) =
K
1 + Kb0
1q−1 + Kb0
2q−2 r(k) −
K
1 + Kb0
1q−1 + Kb0
2q−2 v(k),
which clearly shows that, for K ̸= 0, the input u(k) is not independent from the
noise v(k). For K ̸= 0, the conditions (3.249) are satisﬁed only if v(k) is a white-
noise sequence. This corresponds to the correct parameterization of the stochastic
part of the output-error model. If v(k) were colored noise, biased estimates would
result. This is in contrast to the open-loop case, for which the assumption that u(k)
and v(k) are independent is sufﬁcient to obtain unbiased estimates.
The ﬁnal example in this section illustrates the necessity that the model set M(θ)
(3.163) encompasses both the deterministic and the stochastic part of the signal-
generating system.
3.6.17 Identiﬁcation Example 3.14
Consider the feedback conﬁguration in Fig. 3.23 driven by the external reference
signal r(k), with the system P given as
y(k) = a0y(k −1) + b0u(k −1) + e(k)
(3.250)

3.6
Prediction-Error Parametric Model Estimation
133
where e(k) is a zero-mean white-noise sequence. The controller C has the following
dynamic form:
u(k) = f u(k.1) + g

r(k) −y(k)

(3.251)
with f,g ∈ℜ. If we were to use an ARX model structure with correctly parameter-
ized deterministic and stochastic parts for the system P , the one-step-ahead predic-
tion error would be
ϵ(k|k −1) = y(k) −
y(k −1)
u(k −1)
a
b

.
Following identiﬁcation example 3.12, the conditions for consistency become
E

y(k −1)e(k)

= 0,
E

u(k −1)e(k)

= 0.
(3.252)
These conditions hold since
u(k) =
g(1 −a0q−1)
1 −(f + a0 −gb0)q−1 + f a0q−2 r(k)
−
g
1 −(f + a0 −gb0)q−1 + f a0q−2 e(k),
y(k) =
gb0q−1
1 −(f + a0 −gb0)q−1 + f a0q−2 r(k)
+
1 −f q−1
1 −(f + a0 −gb0)q−1 + f a0q−2 e(k),
and e(k) is a white-noise sequence.
The consistency that is obtained in identiﬁcation example 3.13 with a correctly
parameterized ARX model of a system operating in closed-loop mode can be gen-
eralized for the class of MIMO innovation model structures (3.212)–(3.213) when
the signal-generating system belongs to the model set.
3.6.18 Software
The described basis algorithms and variants have been implemented utilizing the
commercial software standards: for system identiﬁcation:
• The System Identiﬁcation Toolbox in MATLAB, developed by L. Ljung, Linkop-
ing, Sweden: http://www.mathworks.com/products/sysid/.
• The system identiﬁcation package ADAPTx of Adaptics, Inc, developed by
W.E. Larimore: http://www.adaptics.com/.
• The ISID-module in Xmath, developed by P. Van Overschee and Prof. B. De Moor
and in license sold to ISI Inc. (now Wind River), USA: http://www.windriver.com.
• The software packages RaPID and INCA of IPCOS International: http://www.
ipcos.be.
• The package MACEC, developed at the department of Civil Engineering of the
K. U. Leuven in Belgium: http://www.kuleuven.ac.be/bwm/macec/.

134
3
System Identiﬁcation Methods
• Products of LMS International: http://www.lms-international.com.
Additionally, public domain software, as
• SLICOT: http://www.win.tue.nl/niconet/NIC2/slicot.html.
• The SMI toolbox of the Control Laboratory at the T. U. Delft: http://lcewww.et.
tudelft.nl/-verdult/smi/.
• The Cambridge University System Identiﬁcation Toolbox http://www-control.
eng.cam.ac.uk/jmm/cuedsid/.
• The website http://www.esat.kuleuven.ac.be/sista-cosic-docarch/ contains sub-
space identiﬁcation algorithms.
3.7 Questions
1. For a given vector y ∈ℜn, there always exists an orthogonal Householder trans-
formation Q such that
Qy =
⎡
⎢⎢⎣
ξ
0
...
0
⎤
⎥⎥⎦,
with ξ = ±∥y∥2. Use this transformation to show that, for any pair of matrices
A ∈ℜn×n and C ∈ℜl×n, there exists an orthogonal transformation Th such that
the entries above the main diagonal of the matrix

CTh
T −1
h ATh

are zero.
2. Consider a parameterized model with parameters a0, a1, b0, and b1; and a trans-
fer function given by
H(q,a0,a1,b0,b1) =
b1q + b0
q2 + a1q + a0
.
For which values of the parameters a0 and a1 is this transfer function stable?
3. Consider the following single-input, multiple-output system:
y(k) =
⎡
⎣
1+aq−1
(1+aq−1)(1+bq−1)
1+bq−1
(1+aq−1)(1+bq−1)
⎤
⎦u(k).
a. Determine a state-space model of this system such that the C matrix of this
state-space model equals the identity matrix.
b. Denote the state-space model derived above by
x(k + 1) = Ax(k) + Bu(k),
y(k) = x(k).

3.7
Questions
135
Show that the matrices A and B of this state-space model can be determined
from a ﬁnite number of input and output measurements by solving a linear
least-squares problem.
4. Consider the predictor model
ˆy(k,θ) =
b−1
q
+ b2q−2
1 + a1q−1 + a2q−2 u(k)
for k ≥2, with unknown initial conditions ˆy(0) and ˆy(1). Show that, for

−a1
1
−a2
0

,
C =
1
0
,
the predictor can be written in the following form:
ˆy(k,θ) = φ(k,a1,a2)
⎡
⎢⎢⎣
ˆy(0)
ˆy(1)
b1
b2
⎤
⎥⎥⎦,
with φ(k,a1,a2) given by
φ(k,a1,a2) =

CAk

 1
0
a1
1
 k−1

τ=0
CAk−1−τ

1
0

u(τ)
k−1−τ

τ=0

0
1

u(τ)

,
for k ≥2.
5. Consider the predictor model
ˆx(k + 1,θ) = A(θ)ˆx(k,θ) + B(θ)u(k),
ˆy(k,θ) = C(θ)ˆx(k,θ) + D(θ)u(k),
in observer canonical form with system matrices
A =

0
−a0
1
−a1

,
B =

b0
b1

,
C =
0
1
,
D = 0,
so that the parameter vector equals
θ =
a0
a1
b0
b1

.
a. Determine for this parameterization the system matrices
∂A(θ)
∂θ(i) ,
∂B(θ)
∂θ(i) ,
∂C(θ)
∂θ(i) ,
∂D(θ)
∂θ(i) ,
for i = 1,2,3,4, which are needed to compute the Jacobian of the output-
error cost function using (3.182) and (3.183).
b. Determine the conditions on the parameter vector θ such that the combi-
nation of the above predictor model with the dynamic model (3.182) and
(3.183) is asymptotically stable.

136
3
System Identiﬁcation Methods
6. Consider the predictor model
ˆx(k + 1,θ) = A(θ)ˆx(k,θ) + B(θ)u(k),
ˆy(k,θ) = C(θ)ˆx(k,θ) + D(θ)u(k),
with system matrices
A =
⎡
⎢⎢⎢⎣
0
1
0
···
0
0
0
1
···
0
...
...
...
...
...
0
0
0
···
0
⎤
⎥⎥⎥⎦,
B =
⎡
⎢⎢⎢⎣
b1
b2
...
bn
⎤
⎥⎥⎥⎦,
C =
1
0
0
···
0
,
D = 0,
and parameter vector θ = [b1,...,bn].
a. Show that the predictor model can be written as
ˆy(k,θ) =

b1q−1 + b2q−2 + ···bnq−n
u(k).
b. Show that the gradients
∂ˆy(k,θ)
∂θi
,
i = 1,2,...,n,
are equal to their ﬁnite-difference approximations given by
y(k,θ −y(k,θ + Δei))
Δ
,
i = 1,2,...,n,
with Δ ∈ℜand ei ∈ℜn a vector with the ith entry equal to 1 and the other
entries equal to zero.
c. Determine the adjoint state-space equation (3.188) and evaluate (3.189).
7. We are given the system described by
y(k) =

b0 + b1q−1
u(k) + e(k),
with u(k) and e(k) ergodic, zero-mean, and statistically independent stochastic
sequences. The sequence u(k) satisﬁes
E

u(k)2
= σ 2
u,
E

u(k)u(k −1)

= Γ
where Γ ∈ℜand e(k) is a white-noise sequence with variance σ 2
e . Using input–
output measurements of this system, we attempt to estimate the unknown coef-
ﬁcient b of the output predictor given by
ˆy(k,b) = bu(k −1).
a. Determine a closed-form expression for the prediction error criterion for N ∈
∞, given by
¯J(b) = lim
N→∞
1
N
N−1

k=0

y(k) −ˆy(k)
2,
in terms of the unknown parameter b.

3.7
Questions
137
b. Determine the parameter value of ˆb that satisﬁes
ˆb = argmin ¯J(b).
c. Use the expression derived for ˆb to determine conditions on the input u(k)
such that ˆb = b1.
8. Show that, for X ∈ℜn×n,
(In + X)−1 = In −X + X2 −X3 + ··· + (−1)nXn(In + X)−1,
and thus that a ﬁrst-order approximation of (In + X)−1 equals In −X.
9. Given the matrices
A =

 1.5
1
−0.7
0

,
¯A =

1.5
1
−α2 + 1.5α −0.7
α

,
with α ∈ℜ,
a. Determine a similarity transformation such that ¯A = T −1AT .
b. Approximate the similarity transformation as In +ΔT and determine ΔT as
in Sect. 3.5.5.
10. Consider the constrained least-squares problem
min
θ∈range(U)∥Y −Φθ∥2
2
(3.253)
with the matrices Φ ∈ℜN×n(n < N), Y ∈ℜN, and θ ∈ℜn, and with the matrix
U ∈ℜn×p(p < n) of full column rank. Show that, if the product ΦU has full
column rank, the solution to (3.253) satisﬁes
ˆθ = U

UtΦtΦU
−1UtΦtY.
11. Consider the transfer function
M(z) =
D
0
+ C

zI −(A −KC)
−1 B
K 
,
with arbitrary system matrices A ∈ℜn×n, B ∈ℜn×m, C ∈ℜl×n, D ∈ℜl×m,
and K ∈ℜn×l.
a. Let a(z) be a scalar polynomial of order n given by
a(z) = zn + a1zn−1 + ··· + an.
Let B(z) and K(z) be polynomial matrices with polynomial entries of order
n −1 given as
B(z) =
⎡
⎢⎣
b11(z)
···
b1m(z)
...
...
...
bl1(z)
···
blm(z)
⎤
⎥⎦,
K(z) =
⎡
⎢⎣
k11(z)
···
k1l(z)
...
...
...
kl1(z)
···
kll(z)
⎤
⎥⎦.
Show that the transfer function M(z) can be expressed as
D
0
+ [B(z)
K(z)]
a(z)
.

138
3
System Identiﬁcation Methods
b. For the special case l = 1 show that the observable canonical form (3.160)
and (3.161) is a surjective parameterization of the transfer function M(z).
12. Consider the one-step-ahead predictor for a second-order (n = 2) ARMAX
model as given in Lemma 3.13. Let ci = ai + ki (i = 1,2). The parameters
in the one-step-ahead prediction will be estimated using N measurements of
the input u(k) and the output y(k) of the system:
y(k) =
q−1 + 0.5q−2
1 −1.5q−1 + 0.7q−2 u(k) + v(k),
with u(k) and v(k) zero-mean, statistically independent white-noise sequences
of unit variance.
a. Determine an expression for the matrix Φ(c1,c2) such that the prediction-
error criterion JN(c1,c2,θbk) can be written as
JN(c1,c2,θbk) = 1
N
Y −Φ(c1,c2)θbk
2
2,
with
θbk =
 ˆx(0)t
k1
k2
b1
b2
t ,
Y =
y(0)
y(1)
···
y(N −1)t .
b. If the coefﬁcient c2 is ﬁxed to its true value 0.7, derive the condition on c1
such that the ARMAX predictor is asymptotically stable.
c. Write a MATLAB program that calculates the matrix Φ(c1,c2), and takes
as input arguments the vector c = [c1 c2 ], the output sequence Y, and the
input sequence stored in the vector U = [u(1) u(2) ··· u(N)]t.
d. Let δS denote the interval on the real axis for which the ARMAX predic-
tor with c2 = 0.7 is asymptotically stable. Plot the prediction-error criterion
JN(c1,0.7,θbk) as a function of c1 ∈δS. Does the minimal value of this cri-
terion indicate the correct value of c1?
13. Consider the ARX predictor given by (3.228). Using the measurements u(k)
and y(k) acquired in the closed-loop conﬁguration with an LTI controller with
transfer function C(ejω) as depicted in Fig. 3.23, the task is to estimate an
ARX model for the unknown plant P . Show that, in the limit of N →∞, the
prediction-error method attempts to ﬁnd the following estimate:
θ⋆= argmin 1
2π
& π
−π
''''P

ejω
−B(ejω,θ)
A(ejω,θ)
''''
2
×
''''
A(ejω,θ)C(ejω,θ)
1 + P(ejω)C(ejω)
''''
2
Φr(ω)
+
''''
1 + B(ejω,θ)
A(ejω,θ)C(ejω)
1 + P(ejω)C(ejω)
''''
2''A

ejω,θ
''2Φv(ω)dω.
14. Let the following state-space model be given:
x(k + 1) = Ax(k) + Bu(k),
y(k) = Cx(k) + u(k).

3.7
Questions
139
a. Show that the transfer function describing the transfer from u(k) to y(k) is
given as
y(k) =

I + C(qI −A)−1B

u(k).
b. Show that the transfer function describing the transfer from y(k) to u(k) is
given as
u(k) =

I −C

qI −(A −BC)
−1B

y(k).
15. Consider the OE predictor given by (3.239). Using the measurements u(k) and
y(k) acquired in the closed-loop conﬁguration with the LTI controller with
transfer function C(ejω) as depicted in Fig. 8.5 on p. 471, the task is to es-
timate an OE model for the unknown plant P :
a. Show that, in the limit of N →∞, the prediction-error method attempts to
ﬁnd the following estimate:
θ⋆= argmin 1
2π
& π
−π
''''P

ejω
−B(ejω,θ)
A(ejω,θ)
''''
2
×
''''
C(ejω)
1 + P(ejω)C(ejω)
''''
2
Φ2(ω)
+
''''
1 + B(ejω,θ)
A(ejω,θ)C(ejω)
1 + P(ejω)C(ejω)
''''
2
Φv(ω)dω.
b. Show that, for v(k) = 0, the model given by
B(ejω,θ)
A(ejω,θ)
approximates the system P(ejω) accurately in the so-called cross-over-
frequency region, that is, the frequency region in which the loop gain
P(ejω)C(ejω) ≈−1.
16. Adapted from [54]. We are given the system described by
y(k) =
b0q−1
1 + a0q−1 u(k) + 1 + c0q−1
1 + a0q−1 e(k),
with u(k) and e(k) ergodic, zero-mean and statistically independent white-noise
sequences with variances σ 2
u and σ 2
e , respectively. Using N measurements of
the input and the output of this system, we attempt to estimate the two unknown
coefﬁcients a and b in a ﬁrst-order ARX model.
a. Show that, in the limit of N →∞,
E

y2(k)

= b2
0σ 2
u + (c0(c0 −a0) −a0c0 + 1)σ 2
e
1 −a2
0
.
b. Show that, in the limit of N →∞, the prediction-error criterion ¯J(a,b) that
is minimized by the ARX method is given as
¯J(a,b) = E

y2(k)

1 + a2 −2aa0

+

b2 −2bb0

σ 2
u + 2ac0σ 2
e .

140
3
System Identiﬁcation Methods
c. Show that, in the limit of N →∞, the optimal parameter values for a and b
that minimize the above criterion are
ˆa = a0 −
c0
E[y2(k)]σ 2
e ,
ˆb = b0.
d. Show by explicitly evaluating the criterion values ¯J(ˆa, ˆb) and ¯J(a0,b0) that,
in the limit of N →∞, the following relationship holds:
¯J(ˆa, ˆb) < ¯J(a0,b0).
3.8 Notes and References
In this section, we brieﬂy comment on the relation with other identiﬁcation methods
for linear systems, we elaborate on some important open problems and brieﬂy dis-
cuss several extensions. For further elaboration and wide scope, the reader is advised
to look up Refs. [1–4, 23–26, 28, 41, 46–48, 60, 62, 67, 81, 94].
As we have shown in Fig. 3.8, the so-called classical identiﬁcation methods ﬁrst
determine a model (and if needed then proceed via a Kalman ﬁlter to estimate a state
sequence). A good introduction to these methods including such as least squares
methods, instrumental variables, prediction error methods (PEM), and others can
be found in this Encyclopedia under Identiﬁcation of linear Systems in Time Do-
main. Obviously, subspace identiﬁcation algorithms are just one (important) group
of methods for identifying linear systems. But many users of system identiﬁcation
prefer to start from linear input–output models, parametrized by numerator and de-
nominator polynomials and then use maximum likelihood or instrumental variables
based techniques. The at ﬁrst sight apparent advantage of having an input–output
parametrization however often turns out to be a disadvantage, as the theory of pa-
rameterizations of multivariable systems is certainly not easy nor straightforward
and therefore complicates the required optimization algorithms (for example, there
is not one single parametrization for a multiple-output system).
In many implementations of PEM-identiﬁcation, a model obtained by subspace
identiﬁcation typically serves as a good initial guess. Recall that PEMs require a
nonlinear nonconvex optimization problem to be solved, for which a good initial
guess if required.
Another often mentioned disadvantage of subspace methods is the fact that it
does not optimize a certain cost function. The reason for this is that, contrary to
input–output models (transfer matrices), we can not (as of this moment) formulate
a likelihood function for the identiﬁcation of the state space model, that also leads
to an amenable optimization problem. So, in a certain sense, subspace identiﬁcation
algorithms provide (often surprisingly good) ‘approximations’ of the linear model,
but there is still a lot of ongoing research on how the identiﬁed model relates to a
maximum likelihood formulation of the problem. In particular, it is also not straight-
forward at all to derive expressions for the error covariances on the estimates, nor the
quantify exactly in what sense the obtained state sequence is an approximation to the

3.8
Notes and References
141
‘real’ (theoretical) Kalman ﬁlter state sequence, if some of the assumptions we made
are not satisﬁed and/or the block dimensions i and/or j are not inﬁnite (which they
never are in practice). Yet, it is our experience that subspace algorithms often tend to
give very good linear models for industrial data sets. By now, in the literature, many
successful implementations and cases have been reported in mechanical engineer-
ing (modal and vibrational analysis of mechanical structures such as cars, bridges
(civil engineering), airplane wings (ﬂutter analysis), missiles (ESA’s Ariane), etc.),
process industries (chemical, steel, paper and pulp, ...), data assimilation methods
(in which large systems of PDEs are discretized and reconciliated with observations
using large scale Kalman ﬁlters and subspace identiﬁcation methods are used in an
‘error correction’ mode), dynamic texture (reduction of sequences of images that are
highly correlated in both space (within one image) and time (over several images).
Since the introduction of subspace identiﬁcation algorithms, the basic ideas
have been extended to other system classes, such as closed-loop systems, linear
parameter-varying state-space systems, bilinear systems, continuous-time systems,
descriptor systems, periodic systems. We refer the reader to the bibliography for
more information. Furthermore, efforts have been made to ﬁne-tune the algorithms
as presented in this paper. For example, several algorithms have been proposed to
ensure stability of the identiﬁed model. For stochastic models, the positive-realness
property should hold, which is not guaranteed by the raw subspace algorithms for
certain data sets. Also for this problem, extensions have been made.
In this chapter, we discussed the identiﬁcation of an LTI state-space model based
on a ﬁnite number of input and output measurements. We assume that the order of
the system is given and that the disturbances can be modeled as an additive white-
noise signal to the output. The ﬁrst step in estimating the parameters is the deter-
mination of a parameterization of the LTI state-space system. A parameterization
is a mapping from the space of parameters to the space of rational transfer func-
tions that describe the LTI system. We discuss injective, surjective, and bijective
properties of parameterizations and highlight the numerical sensitivity of certain
parameterizations. We describe the output-normal parameterization and the tridiag-
onal parameterization in detail.
For the estimation of the parameters, we need a criterion to judge the quality
of a particular value of the parameters. We introduce the output-error cost function
for this purpose and show that the properties of this cost function depend on the
particular parameterization that is used. For most parameterizations considered in
this chapter, the cost function is non-convex and has multiple local minima.
To obtain the optimal values of the parameters with respect to the output-error
cost function, we numerically minimize this cost function. We discuss the Gauss–
Newton, regularized Gauss–Newton, and steepest-descent methods. In addition, we
present an alternative approach called the gradient-projection method that can be
used to deal with full parameterizations. These numerical procedures are guaranteed
only to ﬁnd local minima of the cost function.
To analyze the accuracy of the estimates obtained by minimizing the output-
error cost function, we derived an expression for the covariance matrix of the error
between the true and the estimated parameters.
If the additive disturbance to the output is a colored, nonwhite noise, then the
output-error method does not yield the minimum-variance estimates of the param-

142
3
System Identiﬁcation Methods
eters. To deal with this problem, we discussed two approaches. The ﬁrst approach
is to apply a weighting with the inverse of the covariance matrix of the additive
disturbance in the output-error cost function. The second approach is to optimize
the prediction error instead of the output error. The prediction-error methods will be
discussed in greater detail in the next chapter.
In [5], the question of estimating the order in the context of subspace methods
is addressed. Three different approaches are presented and the asymptotic proper-
ties thereof derived. Two of these methods are based on the information contained
in the estimated singular values, while the third method is based on the estimated
innovation variance.
Bauer et al. [7] presented states asymptotic normality of subspace estimates. In
addition, a consistency result for the system matrix estimates is given. An algorithm
to compute the asymptotic variances of the estimates is presented.
The effect of some weighting matrices on the asymptotic variance of the esti-
mates of linear discrete time state space systems estimated using subspace methods
was investigated in [6]. The analysis deals with systems with white or without ob-
served inputs and refers to the Larimore type of subspace procedures. The main
result expresses the asymptotic variance of the system matrix estimates in canonical
form as a function of some of the user choices, clarifying the question on how to
choose them optimally. It is shown that the CCA weighting scheme leads to optimal
accuracy.
A new structure for subspace identiﬁcation algorithms is proposed in [12] to help
ﬁxing problems when certain experimental conditions cause ill-conditioning.
The major costs in the identiﬁcation of state-space models still remain because
of the need for the singular value (or sometimes QR) decomposition. It turns out
that proper exploitation, using results from the theory of displacement structure,
of the Toeplitz-like nature of several matrices arising in the procedure reduces the
computational effort [13].
In many on-line identiﬁcation scenarios with slowly time-varying systems, it is
desirable to update the model as time goes on with the minimal computational bur-
den. In [14], the results of the batch processing algorithm are extended to allow
updating of the identiﬁed state space model with few ﬂops.
The problem of identifying multivariable ﬁnite dimensional linear time-invariant
systems from noisy input/output measurements was considered in [15]. Apart from
the fact that both the measured input and output are corrupted by additive white
noise, the output may also be contaminated by a term which is caused by a white in-
put process noise; furthermore, all these noise processes are allowed to be correlated
with each other.
In [16], algorithms were presented to ﬁnd stable approximants to a least-squares
problem, which are then applied to subspace methods to ensure stability of the iden-
tiﬁed model.
It is known that certain popular stochastic subspace identiﬁcation methods may
fail for theoretical reasons related to positive realness. In [19], the authors describe
how to generate data for which the methods do not ﬁnd a model.
The paper [24] describes the modiﬁcation of the family of MOESP subspace
algorithms when identifying mixed causal and anti-causal systems.

3.8
Notes and References
143
In [86], two subspace algorithms are presented to realize a ﬁnite dimensional,
linear time-invariant state-space model from input–output data. Both schemes are
versions of the MIMO Output-Error State Space model identiﬁcation (MOESP) ap-
proach.
The elementary MOESP algorithm is analyzed in [85] It is shown that the
MOESP implementation yields asymptotically unbiased estimates. Furthermore, the
model reduction capabilities of the elementary MOESP schemes are analyzed when
the observations are error-free. On the other hand, the ordinary MOESP algorithm is
analyzed and extended in [87]. The extension of the ordinary MOESP scheme with
instrumental variables increases the applicability of this scheme. Moreover, in [88],
the extension of the MOESP family of subspace model identiﬁcation schemes to the
Hammerstein type of nonlinear system is outlined.
In [89], subspace model identiﬁcation algorithms that allow the identiﬁcation
of a linear, time-varying state space model from an ensemble set of input–output
measurements are presented.
An overview of existing subspace-based techniques for system identiﬁcation was
given in [90]. The methods are grouped into the classes of realization-based and
direct techniques. Similarities between different algorithms were pointed out, and
their applicability is commented upon.
The paper [91] gave a statistical investigation of subspace-based system identiﬁ-
cation techniques. Explicit expressions for the asymptotic estimation error variances
of the corresponding pole estimates were given.
In [93], it is shown that the MOESP class of subspace identiﬁcation schemes
can be extended to identify Wiener systems, a series connection of a linear dynamic
system followed by a static nonlinearity.
A simulation study, in which the performances of the subspace and the trans-
fer function approaches are compared [71], shows that the latter can provide more
accurate models than the former at a lower computational cost.
The paper [74] shows how one can impose stability to the model that is identiﬁed
with a subspace algorithm. The method proposed is based on regularization.
In [75], a subspace algorithm is derived to consistently identify stochastic state
space models from given output data. Two subspace algorithms for the identiﬁca-
tion of mixed deterministic-stochastic systems are derived [76]. Similarities between
three different subspace algorithms for the identiﬁcation of combined deterministic-
stochastic systems are presented in [77]. It is shown that all three algorithms are
special cases of one unifying scheme. In the book [78], the theory of subspace
identiﬁcation algorithms is presented in detail. A subspace identiﬁcation method
is discussed [80] that deals with multivariable linear parameter varying state-space
systems with afﬁne parameter dependence. A general overview [30] of subspace
system identiﬁcation methods is given. A comparison between subspace identiﬁca-
tion and prediction error methods is made on the basis of computational complex-
ity and precision of the methods by applying them on 10 industrial data sets. The
class of existing linear subspace identiﬁcation techniques is generalized to subspace
identiﬁcation algorithms for bilinear systems [29]. In [63], four subspace algorithms
which are based on an initial estimate of the state are considered. For the algorithms

144
3
System Identiﬁcation Methods
considered, a consistency result is proved. In a simulation study, the relative (statis-
tical) efﬁciency of these algorithms in relation to the maximum likelihood algorithm
is investigated
The identiﬁcation of discrete-time bilinear state space systems with multiple in-
puts and multiple outputs is discussed [79]. The subspace algorithm is modiﬁed such
that it reduces the dimension of the matrices involved.
In [83], the identiﬁcation of linear time-invariant (LTI) systems operating in a
closed-loop with an LTI compensator is reformulated to an open-loop multi -input-
multi-output (MIMO) (state space model) identiﬁcation problem, followed by a
model reduction step. The open-loop identiﬁcation problem is solved by the MOESP
(MIMO output-error state space model) identiﬁcation technique. Two algorithms to
identify a linear, time-invariant, ﬁnite dimensional state space model from input–
output data are described [84]. The system to be identiﬁed is assumed to be excited
by a measurable input and an unknown process noise and the measurements are
disturbed by unknown measurement noise. Both noise sequences are discrete zero-
mean white noise.
The Kullback information is developed as the natural measure of the error in
model approximation for general model selection methods including the selection
of model state order in large as well as small samples [50]. It also plays a central
role in developing statistical decision procedures for the optimal selection of model
order as well as structure based on the observed data. The optimality of the canonical
variate analysis (CVA) method is demonstrated for both an open and closed-loop
multivariable system with stochastic disturbances.
In [52], the authors analyze a class of state space identiﬁcation algorithms for
time-series, based on canonical correlation analysis, in the light of recent results on
stochastic systems theory. In this paper, the statistical problem of stochastic model-
ing from estimated covariances is phrased in the geometric language of stochastic
realization theory.
The problem of MIMO recursive identiﬁcation is analyzed [55] within the frame-
work of subspace model identiﬁcation and the use of recent signal processing algo-
rithms for the recursive update of the singular value decomposition is proposed.
An identiﬁcation algorithm which identiﬁes low complexity models of inﬁnite-
dimensional systems from equidistant frequency-response data is presented [58].
The new algorithm is a combination of the Fourier transform technique with sub-
space techniques.
In [64], the stochastic realization of stationary processes with exogenous inputs
in the absence of feedback is studied, and its application to identiﬁcation is brieﬂy
discussed.
A method of identiﬁcation of linear input–output models using canonical variate
analysis (CVA) is developed [66] for application to chemical processes identiﬁcation
and compares it with the traditional prediction error methods. The authors present
several comparisons between prediction error methods and subspace methods, in-
cluding comparisons of accuracy and computational effort.
In [42], one shows that state-space subspace system identiﬁcation (4SID) can be
viewed as a linear regression multistep-ahead prediction error method with certain
rank constraints.

References
145
In [43], the consistency of a large class of methods for estimating the extended
observability matrix is analyzed. Persistence of excitation conditions on the input
signal are given which guarantee consistent estimates for systems with only mea-
surement noise. For systems with process noise, it is shown that a persistence of
excitation condition on the input is not sufﬁcient. More precisely, an example for
which the subspace methods fail to give a consistent estimate of the transfer func-
tion is given. This failure occurs even if the input is persistently exciting of any
order. It is also shown that this problem can be eliminated if stronger conditions on
the input signal are imposed.
The Tennessee Eastman challenge process is a realistic simulation of a chemical
process that has been widely used in process control studies [45]. In this case study,
several identiﬁcation methods are examined and used to develop MIMO models that
contain seven inputs and ten outputs. For a variety of reasons, the only successful
models are the state-space models produced by two popular subspace algorithms,
N4SID and canonical variate analysis (CVA). The CVA model is the most accurate.
References
1. Akaike, H.: Stochastic theory of minimal realization. IEEE Trans. Autom. Control 19, 667–
674 (1974)
2. Akaike, H.: Markovian representation of stochastic processes by canonical variables. SIAM J.
Control 13(1), 162–173 (1977)
3. Aoki, M.: State Space Modeling of Time Series. Springer-Verlag, Berlin (1987)
4. Astrom, K.J., Eykhoff, P.: System identiﬁcation—A survey. Automatica 7(2), 123–162 (1971)
5. Bauer, D.: Order estimation for subspace methods. Automatica 37, 1561–1573 (2001)
6. Bauer, D., Ljung, L.: Some facts about the choice of the weighting matrices in Larimore type
of subspace algorithms. Automatica 38(5), 763–773 (2002)
7. Bauer, D., Deistler, M., Scherrer, W.: Consistency and asymptotic normality of some subspace
algorithms for systems without observed inputs. Automatica 35, 1243–1254 (1999)
8. Bergboer, N., Verdult, V., Verhaegen, M.: An efﬁcient implementation of maximum likeli-
hood identiﬁcation of LTI state-space models by local gradient search. In: Proc. 41st IEEE
Conference on Decision and Control, Las Vegas, Nevada, pp. 616–621. IEEE Press, Piscat-
away (2002)
9. Box, G.E.P., Jenkins, G.M.: Time Series Analysis, Forecasting and Control. Holden-Day, San
Francisco (1970)
10. Brewer, J.W.: Kronecker products and matrix calculus in system theory. IEEE Trans. Circuits
Syst. 25(9), 772–781 (1978)
11. Bruls, J., Chou, C.T., Haverkamp, B., Verhaegen, M.: Linear and non-linear system identiﬁ-
cation using separable least-squares. Eur. J. Control 5(1), 116–128 (1999)
12. Chiuso, A., Picci, G.: Some algorithmic aspects of subspace identiﬁcation with inputs. Int. J.
Appl. Math. Comput. Sci. 11(1), 55–75 (2001)
13. Cho, Y., Xu, G., Kailath, T.: Fast identiﬁcation of state space models via exploitation of dis-
placement structure. IEEE Trans. Autom. Control AC-39(10), 2004–2017 (1994)
14. Cho, Y., Xu, G., Kailath, T.: Fast recursive identiﬁcation of state space models via exploitation
of displacement structure. Automatica 30(1), 45–59 (1994)
15. Chou, C.T., Verhaegen, M.: Subspace algorithms for the identiﬁcation of multivariable dy-
namic errors-in-variables models. Automatica 33(10), 1857–1869 (1997)
16. Chui, N.L.C., Maciejowski, J.M.: Realization of stable models with subspace methods. Auto-
matica 32(11), 1587–1595 (1996)
17. Clarke, D.: Generalized least squares estimation of parameters of a dynamic model. In: Proc.
First IFAC Symposium on Identiﬁcation in Automatic Control Systems, pp. 3–17 (1967)

146
3
System Identiﬁcation Methods
18. Clarke, D.W., Mohtadi, C., Tuffs, P.S.: Generalized predictive control part I: The basic algo-
rithm. Automatica 23(2), 137–148 (1987)
19. Dahlen, A., Lindquist, A., Mari, J.: Experimental evidence showing that stochastic subspace
identiﬁcation methods may fail. Syst. Control. Lett. 34, 303–312 (1998)
20. David, B.: Parameter estimation in nonlinear dynamical systems with correlated noise. Ph D
thesis, Universite Catholique de Louvain, Louvain LaNeuve, Belgium (2001)
21. David, B., Bastin, G.: An estimator of the inverse covariance matrix and its application to ML
parameter estimation in dynamical systems. Automatica 37(1), 99–106 (2001)
22. De Bruyne, F., Gevers, M.: Identiﬁcation for control: Can the optimal restricted complexity
model always be indentiﬁed. In: Proc. of the 33rd IEEE Conference on Decision and Control,
Orlando, Florida, pp. 3912–3917. IEEE Press, Piscataway (1994)
23. De Moor, B., Van Overschee, P.: Graphical User Interface Software for System Identiﬁcation.
Tech. Rep. Report 94-06I, ESAT-SISTA, Department of Electrical Engineering, Katholieke
Universiteit Leuven, Belgium (1994)
24. De Moor, B., Van Overschee, P., Favoreel, W.: Algorithms for subspace state-space system
identiﬁcation: An overview. Appl. Comput. Control Signals Circuits. 1, 247–311 (1999)
25. Desai, U.B., Pal, D.: A transformation approach to stochastic model reduction. IEEE Trans.
Autom. Control AC-29(12), 1097–1100 (1984)
26. Desai, U.B., Kirkpatrick, R.D., Pal, D.: A realization approach to stochastic model reduction.
Int. J. Control 42(2), 821–838 (1985)
27. Dorf, R., Bishop, R.: Modern Control Systems, 8th edn. Addison-Wesley, New York (1998)
28. Faure, P.: Stochastic realization algorithms. In: Mehra, R., Lainiotis, D. (eds.) System Identi-
ﬁcation: Advances and Case Studies. Academic Press, San Diego (1976)
29. Favoreel, W., De Moor, B., Van Overschee, P.: Subspace identiﬁcation of bilinear systems
subject to white inputs. IEEE Trans. Autom. Control 44(6), 1157–1165 (1999)
30. Favoreel, W., De Moor, B., Van Overschee, P.: Subspace state space system identiﬁcation for
industrial processes. J. Process Control 10, 149–155 (2000)
31. Garcia, C.E., Prett, D.M., Morari, M.: Model predictive control: Theory and practice – a sur-
vey. Automatica 25(3), 335–348 (1989)
32. Gevers, M.: Towards a joint design of identiﬁcation and control. In: Trentelman, H.L.,
Willems, J.C. (eds.) Essays on Control: Perspectives in the Theory and Its Applications, pp.
111–151. Birkhauser, Boston (1993)
33. Golub, G.H., Pereyra, V.: The differentiation of pseudo-inverses and nonlinear least squares
problems whose variables separate. SIAM J. Numer. Anal. 10(2), 413–432 (1973)
34. Golub, G.H., Van Loan, C.F.: Matrix Computations, 3rd edn. The Johns Hopkins University
Press, Baltimore (1996)
35. Hanzon, B., Ober, R.J.: Overlapping block-balanced canonical forms and parametrizations:
The stable SISO case. SIAM J. Control Optim. 35(1), 228–242 (1997)
36. Hanzon, B., Ober, R.J.: Overlapping block-balanced canonical forms for various classes of
linear systems. Linear Algebra Appl. 281, 171–225 (1998)
37. Hanzon, B., Peeters, R.L.M.: Balanced parameterizations of stable SISO all-pass systems in
discrete time. Math. Control Signals Syst. 13(3), 240–276 (2000)
38. Hanzon, B., Peeters, R., Olivi, M.: Balanced parameterizations of discrete-time stable all-pass
systems and the tangential Schur algorithm. In: Proc. of the European Control Conference,
Karlsruhe, 1999. Duisburg: Universitat Duisburg (CD Info: http://www.uniduisburg.de/euca/
ecc99/proceedi.htm)
39. Haverkamp, B.: Subspace method identiﬁcation, theory and practice. Ph D Thesis, Delft Uni-
versity of Technology, Delft, The Netherlands (2000)
40. Hayes, M.H.: Statistical Digital Signal Processing and Modeling. John Wiley and Sons, New
York (1996)
41. Ho, B.L., Kalman, R.E.: Effective construction of linear state-variable models from in-
put/output functions. Regelungstechnik 14(12), 545–548 (1966)
42. Jansson, M., Wahlberg, B.: A linear regression approach to state-space subspace system iden-
tiﬁcation. Signal Process. 52(2), 103–129 (1996)

References
147
43. Jansson, M., Wahlberg, B.: On consistency of subspace methods for system identiﬁcation.
Automatica 34(12), 1507–1519 (1998)
44. Johansson, R.: System Modeling and Identiﬁcation. Prentice-Hall, Englewood Cliffs (1993)
45. Juricek, B.C., Seborg, D.E., Larimore, W.E.: Identiﬁcation of the Tennessee Eastman chal-
lenge process with subspace methods. Control Engineering Practice 9(12), 1337–1351 (2001)
46. Kalman, R.E.: A new approach to linear ﬁltering and prediction problems. Trans. Am. Soc.
Mech. Eng., J. Basic Eng. 83(1), 35–45 (1960)
47. Kalman, R.E.: Mathematical description of linear dynamical systems. SIAM J. Control 1,
152–192 (1963)
48. Kung, S.Y.: A new identiﬁcation method and model reduction algorithm via singular value de-
composition. In: Proc. the 12th Asilomar Conference on Circuits, Systems and Computations,
pp. 705–714 (1978)
49. Landau, Y.D.: Adaptive Control: The Model Reference Approach. Marcel Dekker, New York
(1979)
50. Larimore, W.E.: Statistical optimality and canonical variate analysis system identiﬁcation.
Signal Process. 52(2), 131–144 (1996)
51. Lee, L.H., Poolla, K.: Identiﬁcation of linear parameter-varying systems using nonlinear pro-
gramming. J. Dyn. Syst. Meas. Control 121(1), 71–78 (1999)
52. Lindquist, A., Picci, G.: Canonical correlation analysis, approximate covariance extension,
and identiﬁcation of stationary time series. Automatica 32(4), 709–733 (1996)
53. Ljung, L.: Convergence analysis of parametric identiﬁcation methods. IEEE Trans. Autom.
Control 23(5), 770–783 (1978)
54. Ljung, J.: System Identiﬁcation: Theory for the User, 2nd edn. Prentice Hall, New Jersey
(1999)
55. Lovera, M., Gustafsson, T., Verhaegen, M.: Recursive subspace identiﬁcation of linear and
non-linear wiener state-space models, Automatica 36(8), 1639–1650 (2000)
56. Mathworks, System identiﬁcation toolbox 7.4, available at http://www.mathworks.com/
products/sysid.
57. McKelvey, T.: Identiﬁcation of state-space model from time and frequency data. PhD thesis,
Linkoping University, Linkoping, Sweden (1995)
58. McKelvey, T., Akcay, H., Ljung, L.: Subspace-based identiﬁcation of inﬁnite-dimensional
multivariable systems from frequency-response data. Automatica 32(6), 885–902 (1996)
59. McKelvey, T., Helmersson, A.: System identiﬁcation using overparametrized model class –
improving the optimization algorithm. In: Proc. 36th IEEE Conference on Decision and Con-
trol, San Diego, Piscataway, pp. 2984–2989. IEEE Press, New Jersey (1997)
60. Moonen, M., De Moor, B., Vandenberghe, L., Vandewalle, J.: On- and off-line identiﬁcation
of linear state-space models. Int. J. Control 49(1), 219–232 (1989)
61. More, J.J.: The Levenberg–Marquardt algorithm: Implementation and theory. In: Wat-
son, G.A. (ed.) Numerical Analysis. Lecture Notes in Mathematics, vol. 630, pp. 106–116.
Springer-Verlag, Berlin (1978)
62. Overschee, P.V., De Moor, Bart: N4SID: Subspace algorithms for the identiﬁcation of com-
bined deterministic-stochastic systems. Automatica 30(1), 75–93 (1994)
63. Peternell, K., Scherrer, W., Deistler, M.: Statistical analysis of novel subspace identiﬁcation
methods. Signal Process. 52(2), 161–177 (1996)
64. Picci, G., Katayama, T.: Stochastic realization with exogenous inputs and subspace-methods
identiﬁcation. Signal Process. 52(2), 145–160 (1996)
65. Rudin, W.: Real and Complex Analysis, 3rd edn. McGraw-Hill, New York (1986)
66. Schaper, C.D., Larimore, W.E., Seborg, D.E., Mellichamp, D.A.: Identiﬁcation of chemical
processes using canonical variate analysis. Comput. Chem. Eng. 18(1), 55–69 (1994)
67. Silverman, L.: Realization of linear dynamical systems. IEEE Trans. Autom. Control AC-16,
554–567 (1971)
68. Sjoberg, J., Zhang, Q., Ljung, L., Benveniste, A., Delyon, B., Glorennec, P.Y., Hjalmars-
son, H., Juditsky, A.: Nonlinear black-box modeling in system identiﬁcation: A uniﬁed
overview. Automatica 31(12), 1691–1724 (1995)
69. Soderstrom, T., Stoica, P.: System Identiﬁcation. Prentice-Hall, New York (1989)

148
3
System Identiﬁcation Methods
70. Soeterboek, R.: Predictive Control: A Uniﬁed Approach. Prentice-Hall, New York (1992)
71. Stoica, P., Jansson, M.: MIMO system identiﬁcation: State-space and subspace approxima-
tions versus transfer function and instrumental variables. IEEE Trans. Signal Process. 48(11),
3087–3099 (2001)
72. Tatematsu, K., Hamada, D., Uchida, K., Wakao, S., Onuki, T.: New approaches with sensorless
drives. IEEE Ind. Appl. Mag. 6(4), 44–50 (2000)
73. Van den Hof, P.M.J., Schrama, R.J.P.: Identiﬁcation and control – closed loop issues. In:
Preprints of the IFAC Symposium on System Identiﬁcation, Copenhagen, Denmark, pp. 1–
13. Elsevier Science Ltd, Oxford (1994)
74. Van Gestel, T., Suykens, J., Van Dooren, P., De Moor, B.: Identiﬁcation of stable models in
subspace identiﬁcation by using regularization. IEEE Trans. Autom. Control 46(9), 1416–
1420 (2001)
75. Van Overschee, P., De Moor, B.: Subspace algorithms for the stochastic identiﬁcation problem.
Automatica 29, 649–660 (1993)
76. Van Overschee, P., De Moor, B.: N4SID-subspace algorithms for the identiﬁcation of com-
bined deterministic-stochastic systems. Automatica 30(1), 75–94 (1994)
77. Van Overschee, P., De Moor, B.: A unifying theorem for three subspace system identiﬁcation
algorithms. Automatica 31(12), 1853–1864 (1995)
78. Van Overschee, P., De Moor, B.: Subspace Identiﬁcation for Linear Systems: Theory, Im-
plementation and Applications. Kluwer Academic Publishers, Dordrecht, The Netherlands
(1996)
79. Verdult, V., Verhaege, M.: Identiﬁcation of multivariable bilinear state space systems based on
subspace techniques and separable least squares optimization. Int. J. Control 74(18), 1824–
1836 (2001)
80. Verdult, V., Verhaege, M.: Subspace identiﬁcation of multivariable linear parameter-varying
systems. Automatica 38(5), 805–814 (2002)
81. Verhaegen, M.: Realization of covariance sequences. In: Proc. the Toeplitz Memorial Confer-
ence, Tel Aviv, Israel (1981)
82. Verhaegen, M.: A new class of algorithms in linear system theory. PhD thesis, KU Leuven,
Leuven, Belgium (1985)
83. Verhaegen, M.: Application of a subspace model identiﬁcation technique to identify LTI sys-
tems operating in closed-loop. Automatica 29(4), 1027–1040 (1993)
84. Verhaegen, M.: Identiﬁcation of the deterministic part of MIMO state space models given in
innovations form from input–output data. Automatica 30(1), 61–74 (1994)
85. Verhaegen, M., Dewilde, P.: Subspace model identiﬁcation Part 2: Analysis of the elemen-
tary output-error state-space model identiﬁcation algorithm. Int. J. Control 56(5), 1211–1241
(1992)
86. Verhaegen, M., Dewilde, P.: Subspace model identiﬁcation Part 1: The output-error state-space
model identiﬁcation class of algorithms. Int. J. Control 56(5), 1187–1210 (1992)
87. Verhaegen, M., Dewilde, P.: Subspace model identiﬁcation Part 3: Analysis of the ordinary
output-error state-space model identiﬁcation algorithm. Int. J. Control 56(3), 555–586 (1993)
88. Verhaegen, M., Westwick, D.: Identifying MIMO Hammerstein systems in the context of sub-
space model identiﬁcation methods. Int. J. Control 63(2), 331–349 (1996)
89. Verhaegen, M., Yu, X.: A class of subspace model identiﬁcation algorithms to identify peri-
odically and arbitrarily time-varying systems. Automatica 31(2), 201–216 (1995)
90. Viberg, M.: Subspace-based methods for the identiﬁcation of linear time-invariant systems.
Automatica 31(12), 1835–1851 (1995)
91. Viberg, M., Wahlberg, B., Ottersten, B.: Analysis of state-space system identiﬁcation methods
based on instrumental variables and subspace ﬁtting. Automatica 33(9), 1603–1616 (1997)
92. Wahlberg, B., Ljung, L.: Design variables for bias distribution in transfer function estimation.
IEEE Trans. Autom. Control 31(2), 134–144 (1986)
93. Westwick, D., Verhaegen, M.: Identifying MIMO Wiener systems using subspace model iden-
tiﬁcation methods. Signal Process. 52, 235–258 (1996)
94. Zeiger, H., McEwen, A.: Approximate linear realization of given dimension via Ho’s algo-
rithm. IEEE Trans. Autom. Control 19, 153–154 (1974)
95. Zhu, Y.: Multivariable System Identiﬁcation for Process Control. Pergamon, Lexington (2001)

Chapter 4
Applications I
4.1 Introduction
The importance of system models in the contemporary paradigm of advanced con-
trol design cannot be overestimated. There are numerous volumes and survey pa-
pers testify to the pervasive use of system models in different aspects of control
engineering and in different application areas. This growth in the use of models to
accomplish different objectives in the design of industrial control systems has been
accompanied by a similar growth in the science of system identiﬁcation.
System identiﬁcation is often classed as a white-box problem or a black-box
problem, but when the designer is allowed to introduce a priori system knowledge
into the process then more pragmatic grey-box methods emerge. A mainstay of the
control system modeling paradigm are continuous-time models because they arise
naturally when describing the physical phenomena of systems and processes. These
models of physical systems usually involve differential equations that stem from the
application of physical and chemical laws. However, the widespread use of digital
computing technology and the concomitant sampled data led to an emphasis on
the use of discrete system models, discrete control designs and sampled-data-based
system identiﬁcation algorithms. For a wider scope of related technical materials,
the reader is advised to consult the reference [3–6, 18, 19].
4.2 Distillation Unit
Distillation columns are widely used in the chemical process industries where large
quantities of liquids have to be distilled. Industrial distillation towers are usually
operated at a continuous steady state.
4.2.1 Data Analysis
Start by plotting input signal and output signal with respect to time Fig. 4.1. It is
clear that the input and output signals are affected by an offset that need to be re-
M.S. Mahmoud, Y. Xia, Applied Control Systems Design,
DOI 10.1007/978-1-4471-2879-3_4, © Springer-Verlag London Limited 2012
149

150
4
Applications I
Fig. 4.1 Input and output
signals vs. time
Fig. 4.2 Input and output
signals vs. time: zero mean
moved to see how changes in the input give changes in output Fig. 4.2. As mentioned
in the foregoing chapter, the available data set consist of 10080 sample the ﬁrst half
(that is, 5040 sample) of which will be used for estimation purpose and the second
half is for validation purpose.
The correlation analysis estimate, 4th order ARX model, and state space model
are computed and plotted to see the transient response agreement Fig. 4.3.

4.2
Distillation Unit
151
Fig. 4.3 Transient response
agreement between ARX and
state space
Fig. 4.4 Validation plot for ARX: state-space against measured output
4.2.2 Validation and Model Fitness
The measured validation data output (that is, samples between 5040 to 10080) is
compared against the simulated output of the ARX and state space validation model
as depicted in Fig. 4.4.
In order to ﬁnd the closest model structure that represent the on-line real data, a
comparison based on the ﬁtness criteria and residual analysis is performed among
different model structures. Table 4.1 shows this comparison based on the ﬁrst data
set and an appropriate plot is depicted in Fig. 4.5.
By repeating the above procedure with different data set, we can conclude that
BJ model is the best model that represents the highest ﬁt, see Table 4.2 and Fig. 4.6.

152
4
Applications I
Table 4.1 Best ﬁt for the
selected model structure
Model
Order
Fitness
ARX
[4 4 1]
−2470
ARMAX
[2 2 2 1]
−2471
BJ
[2 2 2 2 1]
−2743
Fig. 4.5 Model outputs of
ARX, ARMAX and BJ
Table 4.2 ARX, ARMAX, and BJ model output
Data set
Samples
ARX best ﬁt
ARMAX best ﬁt
BJ best ﬁt
1
5040
−2743
−2744
−2743
2
1000
−5737
−5711
−5449
3
2200
−3189
−3122
−3071
4
2800
−1528
−1644
−1787
5
1810
−2540
−2533
−2627
6
800
−3182
−3165
−3426
7
1470
−2195
−2200
−1795
4.3 Steam Generation Unit
We learned from the previous chapter that the model of steam generation unit is
a typical multivariable system. In identiﬁcation system terminology, multivariable
systems are often more challenging to model since the underlying systems with
several outputs might be difﬁcult. A basic reason for the difﬁculties is that the cou-
pling between several inputs and outputs eventually leads to more complex models.
The structures involved are richer and more parameters will be required to obtain a
good ﬁt. However, models for prediction and control will be able to produce better
results if constructed for all outputs simultaneously. In this section, the complete
steam generation unit is modeled using MIMO ARX model and MIMO State Space
model.

4.3
Steam Generation Unit
153
Fig. 4.6 Simulation results: MIMO ARX
4.3.1 MIMO ARX Model
For simulation experiments using the MIMO ARX model, all the four inputs and
outputs of the system were considered. The order of the system was speciﬁed as
na = 8 × ones(4,4),
nb = 6 × ones(4,4),
nc = 3 × ones(4,4).
The coefﬁcients na, nb and nc were selected on trial and error basis to yield the
best ﬁtness levels. The delay coefﬁcients were however not considered as optimum
results were available without introducing delay in the system. The model was con-
structed using samples from 5000–9000. The validation of the model so obtained
was carried out on samples from 2500–6500. The results of the simulation have
been plotted. The percentage ﬁtness of the various modeled outputs with respect to
the measured outputs for the MIMO ARX model is shown in Fig. 4.6.
4.3.2 MIMO State-Space Model
A state space model of order 6 was found to yield optimum results. Further increase
in the order yielded only a negligible increase in the ﬁtness of the models. With
the model order equal to 9, lower ﬁtness levels were obtained, but it showed better
results in the residual analysis. Therefore, to strike a balance between the complexity
of the model, the ﬁtness and residuals the order of the state space model was selected
as 6. Just as in the previous case, the model was constructed using samples from

154
4
Applications I
Fig. 4.7 Simulation results: MIMO state-space
5000–9000. The ﬁnal prediction error (FPE) was found to be 0.00292292 and the
loss function was found to be 0.00286093. The results of the simulation have been
plotted. The percentage ﬁtness of the various outputs for the State Space Model is
shown in Fig. 4.7.
4.3.3 Comparison of MIMO Models
The plot of comparative ﬁtness percentages between the ARX model and the State
Space Model can be shown in Table 4.3. Generally speaking, it is found convenient
to work with state space models in the multivariable case, since the model structure
complexity is easier to deal with. It is essentially a matter of choosing the model
order. State-space model also provides a more complete representation of the system
than polynomial models. However, when the model order is high, it is better to use
an ARX model because the algorithm involved in the estimation is fast and efﬁcient
when the number of data points is very large. The state-space model estimation with
a large number of data points is slow and requires a large amount of memory and the
ﬁtness of the model is also hampered consecutively. Therefore, we observe that the
ﬁtness levels for the MIMO ARX model are relatively greater than the state space
model. The ARX model therefore is preferable, especially when the model order is
high, see Fig. 4.8.

4.4
Falling Film Evaporator
155
Table 4.3 Comparison of
model ﬁtness
Output
MIMO ARX model
State space model
y1
82.27
81.79
y2
49.59
49.93
y3
84.54
66.1
y4
88.21
87.7
Fig. 4.8 Comparison of
MIMO model ﬁtness
4.4 Falling Film Evaporator
The most common used evaporator in the dairy industry is the falling ﬁlm evapo-
rator, for the concentration of products like milk, skimmed milk and whey. A four
stage evaporator is used to reduce the water content of the product, that is, milk.
The data was taken from [13]. The identiﬁcation scheme used for the data is the
N4SID subspace based identiﬁcation. The data consists of 6305 samples with three
inputs, feed ﬂow, vapor ﬂow to the ﬁrst evaporator stage and cooling water ﬂow and
three outputs, dry matter content, the ﬂow and the temperature of the out coming
product.
The solution containing the desired product is fed to the evaporator and passes a
heat source. The applied heat converts the water in the solution to vapor. The vapor
is removed from the rest of the solution and is condensed while the now concen-
trated solution is either fed into the second evaporator is removed. The evaporator
generally as a machine consists of four sections. The heating section consists of the
heating medium. Steam is fed into this section. The concentrating and separating
section removes the vapor being produced from the solution. The condenser con-
densates the separated vapor, then the vacuum or pump provides pressure to increase
the circulation.

156
4
Applications I
Fig. 4.9 The estimated data
4.4.1 Identiﬁcation Results
The data for the industrial evaporator is taken into account and the System Identi-
ﬁcation was done for the same using MATLAB. The N4SID method of identiﬁca-
tion was performed on the data and the results are shown below for the estimation
and validation of the data. The loss function was 0.000414667 and the FPE was
0.000431254 using the N4SID technique and results, shown in Figs. 4.9 and 4.10,
are extracted.
4.5 Vapor Compression Cycle Systems
Accurate dynamic models of vapor compression systems play a signiﬁcant role
in the efﬁcient design of systems with optimal component sizes and conﬁgura-
tions, and in the development of control strategies to manage these systems. The
framework of the dynamic modeling approach is selected through careful con-
sideration of external constraints that limit the usefulness of a particular frame-
work with regard to system design or control development. In the system design
phase, the model should accurately predict the performance and behavior of a par-
ticular system conﬁguration. The emphasis on accuracy in the design phase has
lead to the use of complex models that provide the ﬂexibility to capture the in-
tricate behavior of the ﬂuid ﬂow and heat transfer phenomena common to va-
por compression systems. In contrast, the model that is most beneﬁcial for con-
trol design is the least complex model that still retains sufﬁcient accuracy to cap-

4.5
Vapor Compression Cycle Systems
157
Fig. 4.10 The validated data
ture the gross dynamic behavior of the system. For control design, it is criti-
cal to strike a delicate balance between dynamic complexity and accuracy in the
model.
With reference to Chap. 2, a representative system model is required to under-
stand which aspects of the thermodynamic cycle are best controlled by which input
parameter. In this section, the dynamic response of a VCC system is identiﬁed us-
ing a time-domain-system identiﬁcation procedure. Three controllable inputs for a
variable-speed VCC are considered: expansion valve opening u1, compressor speed
u2, and evaporator airﬂow rate u3. The condenser airﬂow rate is considered a dis-
turbance to the system because, in some applications, for example, automotive sys-
tems, the condenser airﬂow rate is a function of vehicle speed and, therefore, is not
controlled.
The output measurements consist of six thermodynamic states: two pressures
and four temperatures. Recall that, for an idealized cycle, there are two system pres-
sures: P2 = P3 and P1 = P4. These correspond to the pressure inside the condenser
and the pressure inside the evaporator, respectively. There are four system refrig-
erant temperatures: T1, T2, T3 and T4. Again, assuming an idealized cycle with a
saturated refrigerant leaving the condenser, these represent evaporator outlet tem-
perature, condenser inlet temperature, condenser saturation temperature, and evap-
orator saturation temperature, respectively. The output responses to random Gaus-
sian combinations of all three inputs (see Fig. 4.11) around a set of nominal op-
erating conditions, were collected on an air-conditioning and refrigeration experi-
mental test stand. For a more detailed description of the experimental system, [13,
14].

158
4
Applications I
Fig. 4.11 Random Gaussian input signals
4.5.1 Identiﬁcation Results
A standard prediction error/maximum likelihood system identiﬁcation algorithm
from the MATLAB System Identiﬁcation Toolbox was used to identify the fre-
quency response between each input and output pair. The identiﬁed models were
compared with models obtained using polynomial modeling techniques such as
MIMO ARX modeling etc. Parameter estimation in polynomial modeling tech-
niques was carried out using recursive least squares approach. With respect to the
Complexity of the model, the ﬁtness levels and the residual analysis it was con-
cluded that the Subspace system identiﬁcation using prediction error method yielded
most accurate models. Because system identiﬁcation is sensitive to scaling, two
models were identiﬁed, wherein the output parameters within each model shared
the same inputs. This means that the ﬁrst model was identiﬁed with all three excited
inputs and the two pressure measurements as outputs (P2 = P3 and P1 = P4), and
a second model was identiﬁed with the same inputs and the four temperature mea-
surements as outputs (T1, T2, T3 and T4). The complete state-space representation
of each identiﬁed model is included in the Appendix. Note that using instead of
provided a better ﬁt with respect to the system identiﬁcation.
For each identiﬁed output, the open-loop system response is compared against
the response as predicted by the identiﬁed model, Figs. 4.12 and 4.13 show the
identiﬁed model compared against the data used for the identiﬁcation. The identi-
ﬁed models were then cross-validated using data collected on a different day with a
different ambient temperature and humidity level. The ﬁt percentages for each out-

4.6
Unmanned Marine Vehicle
159
Fig. 4.12 System ID results for P1; P2−1
put characterizing predictive capability of the models are included in each of the
ﬁgures.
It was noted that the ﬁtness percentages of the identiﬁed model were very low for
the model considering the four temperatures T1, T2, T3 and T4, whereas the ﬁtness
percentages for the model considering the pressures P1 and P2−1 were found to be
reasonably good that is, approx 65% in each case.
4.6 Unmanned Marine Vehicle
System identiﬁcation is the art and science of building mathematical models of dy-
namic systems from observed input–output data. It can be seen as the interface be-
tween the real world of applications and the mathematical world of control theory
and model abstractions. Identiﬁcation is a very large topic, with different techniques
that depend on the character of the models to be estimated: linear, non linear, hy-
brid, non parametric etc. Model structure selection is a key step in the identiﬁcation
process. The model structure determines the set in which the model estimation is
performed. The complexity of the model structure, of course, affects the accuracy
with which the model can approximate the real process. The choice of model struc-
ture depends on the noise sequence: how well is it possible to estimate the noise?

160
4
Applications I
Fig. 4.13 System ID results for T1; T2; T3; T4
It is not at all necessary that a model with more parameters or more freedom (more
polynomials) is better. Finding the best model is a matter of choosing a suitable
structure in combination with the number of parameters.
4.6.1 Identiﬁcation Results
Generally speaking, it is preferable to work with state-space models in the multi-
variable case, since the model structure complexity is easier to deal with. It is es-
sentially just a matter of choosing the model order. It is observed that the ﬁt gets
better when more inputs are included and often gets worse when more outputs are
included. To understand the latter fact, realize that a model that has to explain the
behavior of several outputs has a tougher job than one that must just account for a
single output. Difﬁculties obtaining good models for a multi-output system might
be a sign to model one output at a time, to ﬁnd out which are the difﬁcult ones to
handle.
Models that are just to be used for simulations could very well be built up from
single-output models, for one output at a time. However, models for prediction and
control will be able to produce better results if constructed for all outputs simul-
taneously. This follows from the fact that knowing the set of all previous output
channels gives a better basis for prediction than just knowing the past outputs in

4.6
Unmanned Marine Vehicle
161
one channel. Also, for systems where the different outputs reﬂect similar dynamics,
using several outputs simultaneously will help estimating the dynamics. Here, some
of identiﬁcation methods used in this paper is reviewed.
ARMAX
There are several elaborations of the basic ARX model, where different noise mod-
els are introduced; ARMAX is one of them. The basic disadvantage with the ARX
model is the lack of adequate freedom in describing the properties of the distur-
bance term. ARMAX takes care of this deﬁciency by describing the equation error
as a moving average of white noise. This gives the model:
y(t) + a1y(t −1) + ··· + anay(t −na)
= b1u(t −1) + ··· + bnbu(t −nb)
+ e(t) + c1e(t −1) + ··· + cnce(t −nc),
C(q) = 1 + c1q−1 + ··· + cncq−nc
it can be rewritten as
A(q)y(t) = B(q)u(t) + C(q)e(t)
(4.1)
with
G(q,θ) = B(q)
A(q),
H(q,θ) = C(q)
A(q)
where now
θ = [a1 ··· ana
b1 ··· bnb
c1 ··· cnc]T .
(4.2)
The ARMAX model has become a standard tool in control and econometrics for
both system description and control design. It is a signiﬁcant tool in controls and
simulation purposes but drawing this technique to practical conclusions over the
other methods is not relevant.
State Space Models-Based Identiﬁcations
In the state space form the relationship between the input, noise, and output signal is
written as a system of ﬁrst order differential equation using an auxiliary vector x(t).
For beginning it’s easier to construct model in continuous time. Given state space
model equations,
˙x = A(θ)x(t) + B(θ)u(t)
(4.3)
with A and B are matrices of appropriate dimensions for n states, and m inputs.
θ is a vector of parameters, typically correspond to unknown values of physical
coefﬁcients. For system identiﬁcation process, the data available to construct model
parameter obviously discrete. Let the measurement result obtained from sensor be

162
4
Applications I
the output of state space model corrupted with noise, next called measurement noise,
and let process noise be the noise acting on the state, then next state and measured
output can be represented as,
x(t + 1) = A(θ)x(t) + B(θ)u(t) + K(θ)e(t),
(4.4)
y(t) = C(θ)x(t) + e(t).
(4.5)
Next, input output relation can be written in series of polynomial series using shift
operator q [15],
y(t) = G(q,θ)u(t) + H(q,θ)e(t),
(4.6)
G(q,θ) = C(θ)

qI −A(θ)
−1B(θ),
(4.7)
H(q,θ) = C(θ)

qI −A(θ)
−1K(θ) + I.
(4.8)
Solving θ for both G and H now can be treated like similar problem in SISO by
least square technique. Multiple-output ARMAX and OE models are covered via
state-space representations: ARMAX corresponds to estimating the K matrix, while
OE corresponds to ﬁxing K to zero. State Space model parameters are computed
using iterative Prediction-Error Minimization. Once the model structure has been
deﬁned, and a data set ZN has been collected the estimation of the parameter θ is
conceptually simple: Minimize the distance between the predicted output (according
to parameter θ) and the measured outputs,
ˆθN = argmin
θ VN(θ),
(4.9)
VN(θ) =
N

t=1
l

¯y(t) −y(t)

.
(4.10)
Here ¯y is the measurement output, and l is suitable distance measure, such as l(ε) =
∥ε∥2. The connection to the celebrated maximum likelihood method is obtained by
particular choice of norm. Assume that the data is produced by mechanism
¯y = f

Zt−1,θ

+ e(t)
(4.11)
where {e(t)} is a sequence of independent random variables with probability den-
sity function p(x), this make ˆθN equal to the maximum likelihood estimate. The
actual calculation of the minimizing argument is complicated, and possibly a com-
plex search over function with several local minima. The numerical search typically
carried out using the damped Gauss–Newton method. See [15] for more detail on
numerical minimization issue.
Kalman Filter Identiﬁcations
Kalman ﬁlter identiﬁcation (KID) is another system identiﬁcation technique that
uses state space modeling to approach the state space problem not from polynomial
series of transfer functions, but directly from time domain representations. Kalman

4.6
Unmanned Marine Vehicle
163
ﬁlter identiﬁcation (KID) is an algorithm developed by NASA Langley to model
large ﬂexible structures [12]. In this regard, KID is a reﬁned algorithm based on
eigen-systems realizations algorithm developed in [12]. Consider a discrete multi-
variable linear system,
x(t + 1) = Ax(t) + Bu(t),
y(t) = Cx(t) + Du(t).
(4.12)
Assuming initial conditions, x(0) = 0, the set of this equations for a sequence of
t can be written as
y = YU
(4.13)
where
Y =

D
CB
CAB
···
CAl−2B

,
(4.14)
U =
⎡
⎢⎢⎢⎢⎢⎣
u(0)
u(1)
u(2)
···
u(l −1)
u(0)
u(1)
···
u(l −2)
u(0)
···
u(l −3)
...
...
u(0)
⎤
⎥⎥⎥⎥⎥⎦
.
(4.15)
Equation (4.13) is a matrix representation of the relationship between input and
output histories. The matrix y is a q × l output data matrix where q is the number
of outputs and l is the number f data samples. The Y, of dimension q × ml with
m is the number of inputs, contains all the Markov parameters D, CB, CAB, ...,
CAl−2B to be determined. The U matrix is an ml × l upper block triangular input
matrix. It is square in the case of a single input system, and otherwise has more rows
than columns.
For asymptotically stable system, there is a p such as Ap ≈0, so the Y and U
can be truncated. Unfortunately, for lightly damped system, p required to make the
approximation of (4.14) and (4.15), is impractically large, in the sense that matrix U
is too large to solve for its pseudo inverse U+ numerically. Dealing with this, a kind
of observer feedback loop had been suggested to be added to make the system as
stable as desired. Consider
x(t + 1) = Ax(t) + Bu(t) + My(t) −My(t)
= (A + MC)x(t) + (B + MD)u(t) −My(t)
= ¯Ax(t) + ¯Bv(t)
(4.16)
where
v(t) =
u(t)
y(t)

.
(4.17)
When using real data including noise, the eigenvalue of ¯A are in fact placed such that
C ¯Ai ¯B ≈0 for i ≤p where p is sufﬁciently large integer. Using the same approach,
y = ¯Y ¯V
(4.18)

164
4
Applications I
where
¯Y =
 ¯D
¯C ¯B
¯C ¯A ¯B
···
¯C ¯Ap−1 ¯B

,
¯V =
⎡
⎢⎢⎢⎢⎢⎣
u(0)
u(1)
u(2)
···
u(p)
···
u(l −1)
v(0)
v(1)
···
v(p −1)
···
v(l −1)
v(0)
···
v(p −2)
···
v(l −2)
...
...
...
...
v(0)
···
v(l −p −1)
⎤
⎥⎥⎥⎥⎥⎦
.
(4.19)
Solving the problem of observer Markov parameters ¯Y using least square algorithm,
original Markov parameters Y can be recovered. The system Markov parameters can
then be assembled to form the generalized Hankel matrix. The Hankel matrix can
be decomposed into the Observability matrix, a state transition matrix, and the Con-
trollability matrix. The Hankel matrix (which must always be of full rank) can then
be truncated using singular value decomposition (SVD) at an order that sufﬁciently
describes the system. The truncated Hankel matrix is then used to reconstruct A, B,
and C using a minimum balanced realization algorithm that ensures that the con-
trollability and observability Gramians are equal. This is known as the eigen-system
realization algorithm (ERA) and a modiﬁed version with data correlation (ERA/DC)
can also be used [10].
One of the advantages using KID [12] is that it produces a pseudo Kalman state
estimator, which is very useful in control applications. Let (4.12) be extended to
include process and measurement noise as
x(t + 1) = Ax(t) + Bu(t) + w(t),
y(t) = Cx(t) + v(t).
(4.20)
It can be shown that any observer satisfying (4.18) can produce the same input
output map as a Kalman ﬁlter does if the data length is sufﬁciently long and the
order of the observer is sufﬁciently large so that the truncation error is negligible.
Then Kalman steady state gain is given by
L = −A−1M.
(4.21)
The data run available for identiﬁcation purpose comprises of 14 sets. The
longest data run, run 5 will be selected as estimation data, see Fig. 4.14. Validation
data selected here, are run 6, run 7, run 9, and run 10. First, best model parameter
for each method will be computed from estimation data. Fitness of each model to
estimation data then presented. Residual analysis also presented here. At the end,
ﬁtness of each model obtained to validation data set will be presented as well.
Fitness are deﬁned as,
ﬁtness (%) = 100

1 −
∥y −ˆy∥
∥y −E(y)∥

.
(4.22)
Residual deﬁned as
e(t) = H −1(q)

y(t) −G(q)u(t)

,
y(t) = G(q,θ)u(t) + H(q,θ)e(t).
(4.23)

4.6
Unmanned Marine Vehicle
165
Fig. 4.14 Typical input–output set
Ideally residual should be white and independent of the input signals, this can be
examined from autocorrelation plot of residual.
4.6.2 ARMAX Model
The ARMAX identiﬁcation model describes the equation error as a moving model
of white noise. As far as the structuring of the model from the data set is concerned,
the model generated for the outputs y1 and y3 from the input have a pleasing ﬁt
unlike the model for the output y2. The third order estimation model for y1, second
order estimation model for y2 and ﬁfth order estimate for y3 give a satisfactory
proﬁle. During validation using run 7, the fourth order model gives the best ﬁt for
the output channel u1–y1 with a relatively higher amplitude, see Fig. 4.15. Though
lower orders give a satisfactory ﬁt as well but do not follow up the proﬁle clearly. For
the output channel u1–y2, the ﬁt is not high owing to the properties of the output
which depend on the speed of the wind. u1–y3 channel has a high ﬁtness for the
ﬁfth order model upon validation. Upon using run 9, the error in ﬁtness was high
showing that the amplitude of the estimated models was higher than the validation
data run. Run 10 gives a measure ﬁt for output y1, for output y2 the error obtained
upon validation is high and for output y3 the ﬁt was decent enough. The third order
model for the ﬁrst output gives the best results upon validation compared to the

166
4
Applications I
Fig. 4.15 ARMAX model ﬁtness to data runs #6–#10
other orders, see Fig. 4.16. The second order model for the second output is the best
choice and the third order model for the third output.
4.6.3 State Space Model
State space model identiﬁcation will estimate A, B, C, K, and initial state X0. To
determine how many order is sufﬁcient for Atlantis data model, modal singular value
will be computed ﬁrst here, as shown in Fig. 4.17. From this ﬁgure, although there
was sudden drop between order 4 and order 5, that not big than one in logarithmic
scale, but this drop is not adequate to make four order describe behavior of the
system. For comparison, here, several model order is selected, 3 as the Atlantis
model is built in third order state space model, 4, 10, and 20. For state space model
order determination, see Sect. 4.6.6.
Computed state space parameter with state order 20 end up with ill-condition co-
variance matrix. Trying for order 15 also end up with the same result. This probably
come from non linear output error minimization using in PEM technique. However,
with the remaining successful identiﬁed model, comparison between ﬁtness of state
space model to validation data is carried and can be seen in Fig. 4.17.

4.6
Unmanned Marine Vehicle
167
Fig. 4.16 ARMAX model
simulated output comparison
using data run #7
Model Fitness with Estimation Data
PEM estimation give inconsistent ﬁtness
improvement as the order number getting higher, this can be seen in output number
one, that output estimation using order 3 is better than order 4, also in output number
two, estimation using order 4 is better than order 10.
Now, it is clear that state space model built using PEM with order three and four
are far from appropriate selection, that because autocorrelation of residual error still
have relatively high in sample lag k ̸= 0. State space model built using PEM order
ten, however have residual error near to white noise autocorrelation. It is perhaps

168
4
Applications I
Fig. 4.17 State-space model
identiﬁcation using PEM
technique
Table 4.4 Estimation data
ﬁtness comparison using
PEM
Order 3
Order 4
Order 10
Output 1
18.2981
−55.0245
77.2154
Output 2
−30.6765
45.9034
44.3733
Output 3
40.1334
69.9786
73.8384
order ten is a good selection. This fact also corresponding to ﬁtness of each model
to estimation data, as can be seen in Table 4.4.
Simulation with Validation Data
From simulation using four set validation data,
state space model obtained using PEM with order three fails to identify all outputs.
Fitness to validation data 6, is only 15.826%, −24.589% and 34.253% for output

4.6
Unmanned Marine Vehicle
169
Fig. 4.18 PEM model ﬁtness to validation data
one, two and three. Fitness less than zero is a result of unmatched oscillation period
of estimation output, this makes ∥( ˆy) −y∥greater than ∥y −E(y)∥, see deﬁnition
of ﬁtness in (4.22). Nearly the same ﬁtness results are obtained for validation data
7, 9 and 10.
For state space model obtained using PEM with order four, ﬁtness of estima-
tion output to validation data is better than order three for output two, and output
three. Fitness of output estimation to validation output one is awful, it reach below
−100%, in validation data 6, and also below −50% in validation data 7, 9, and 10.
For state space model obtained using PEM with order ten, ﬁtness of estimation
output to validation data is better than the preceding two models. Fitness of this
model is always more than zero, that signiﬁes, the ability of the model to track the
output in the correct oscillation time, although it may not have correct amplitude. In
estimation of validation data 6, this model has the highest ﬁtness result. For valida-
tion data 7, 8, and 9, ﬁtness of this model is lower than the ﬁtness of model order
4, at output three and two. Indeed for validation data 9 and 10, ﬁtness to output
three is only 16.595% and 16.498%. See Fig. 4.18 and Tables 4.5–4.6 for complete
comparison.
Generally, using state space model of order 10 obtained using PEM model, does
not give much ﬁtness improvement to validation data.

170
4
Applications I
Table 4.5 Validation data ﬁtness comparison using PEM: runs #6, #7
Val. data
Data 6
Data 7
Order
3
4
10
3
4
10
Output 1
15.826
−111.800
37.125
33.015
−72.799
33.844
Output 2
−24.589
48.575
54.072
−16.948
49.485
54.652
Output 3
34.253
82.333
61.715
34.691
80.262
69.342
Table 4.6 Validation data ﬁtness comparison using PEM: runs #9, #10
Val. data
Data 9
Data 10
Order
3
4
10
3
4
10
Output 1
28.951
−172.400
12.316
5.175
−66.977
10.195
Output 2
−53.848
37.059
27.568
−3.338
11.317
9.223
Output 3
28.121
61.787
16.595
27.226
28.922
16.498
4.6.4 KID Model
First thing required in the KID method is to choose p, which determines the number
of observer Markov parameters to be identiﬁed from a given set of input and output
data. In general, p will be sufﬁciently larger than the effective order of the system,
at least four or ﬁve times, here p is selected to be 20. Using data run #5, it was
difﬁcult to determine effective order of the system, as there was no sudden drop in
Hankel singular value matrix. Adding order number also makes a slow improvement
in Model Descriptions of the data, as deﬁned as summations of singular value of
selected modes divided by summations singular value of all modes in Hankel matrix.
Here, several model orders are selected, 3, 4, 10, and 20. For simulation of KID
model, Kalman ﬁlter gain given by (4.21) will be incorporated, and each simulation
time increment is separated by two step a priori phase and a posteriori phase, as
below
a priori
¯x(t + 1) = Aˆx(t) + Bu(t),
¯y(t + 1) = C ¯x(t + 1) + Du(t + 1);
a posteriori
¯e(t + 1) = y(t + 1) −¯y(t + 1),
ˆx(t + 1) = ¯x(t + 1) + L¯e(t + 1),
ˆy(t + 1) = C ˆx(t + 1) + Du(t + 1),
e(t + 1) = y(t + 1) −ˆy(t + 1).
(4.24)
Model Fitness with Estimation Data
KID estimation, see Fig. 4.19, gives nearly
consistent ﬁtness improvement as the order increases, except that for output 2 and

4.6
Unmanned Marine Vehicle
171
Fig. 4.19 KID system
identiﬁcation

172
4
Applications I
Table 4.7 Estimation data
ﬁtness comparison using KID
Order 3
Order 4
Order 10
Order 20
Output 1
34.209
61.320
68.289
86.773
Output 2
40.388
48.963
33.067
52.154
Output 3
24.060
88.162
85.769
91.016
3, order 10 ﬁtness is less than order 4. Consistency in model ﬁtness seems to be a
result from the fact that model obtained from OKID technique is in modal balanced
realizations [9, 11]. This means that error truncated in the model is smaller than
modes that were included in state space realizations. It can be seen that order 4 is
nearly adequate for describing dynamic characteristics of system. It is due to the
perfect tracking in fact may not be desirable. Consider for instance output number
2, that has high noise, generating a model that tracks perfectly is not helpful from a
control standpoint.
Residual Analysis
Using the same equation in Sect. 4.6.4, autocorrelation of each
output residual error from each model were carried out. It is found, with regards to
the estimation data ﬁtness Table 4.7, that the model that have more ﬁtness, tend to
have less autocorrelation magnitude. From four models obtained, none of them are
giving autocorrelation plot close to white noise.
Simulation with Validation Data
Validation data output estimation using four
KID models obtained have shown several interesting facts. For data run 6, all the
models are able to track all outputs in correct oscillation time. Model order 3 gives
10.003%, 50.0971%, and 22.29% ﬁtness. Model order four gives nearly the same
ﬁtness, except for output three it gives 80.570% ﬁtness. Best ﬁtness is achieved using
model order 20. Nearly the same result can also be examined for data runs 7 and 10.
Indeed, for these data runs, KID order four model gives 41.227% and 56.269%
ﬁtness for output one. One exception occurs in data run 9, that KID order three,
four and ten models give ﬁtness below zero for output one, that means they fail to
track the output at the correct oscillation period. Generally, KID model tend to have
consistent ﬁtness improvement as order model gets higher. Also, from simulation of
these KID models using validation data, it can be said that KID order four, is fair
enough to describe dynamics of the system. See Fig. 4.20 and Tables 4.8–4.9 for
complete comparison.
4.6.5 Result of Comparisons
Fitness comparison of all models obtained before can be seen in Fig. 4.21. ARMAX
models have the highest ﬁtness for validation data run 6, KID models also have a
good ﬁtness here, except that for output one, low order have small ﬁtness. PEM
model’s have the smallest ﬁtness level. Nearly the same result are correct for data

4.6
Unmanned Marine Vehicle
173
Fig. 4.20 KID model ﬁtness to validation data
Table 4.8 Validation data ﬁtness comparison using OKID: runs #6, #7
Val. data
Data 6
Data 7
Order
3
4
10
20
3
4
10
20
Output 1
10.003
6.263
21.322
65.703
20.047
30.116
41.227
75.942
Output 2
50.971
46.822
42.512
53.405
50.077
44.210
43.315
52.123
Output 3
22.249
80.570
75.497
84.064
22.804
81.633
76.822
85.977
Table 4.9 Validation data ﬁtness comparison using OKID: runs #9, #10
Val. data
Data 9
Data 10
Order
3
4
10
20
3
4
10
20
Output 1
−31.229
−51.026
−25.650
36.793
13.984
56.269
61.665
78.635
Output 2
24.776
38.402
36.873
14.031
12.282
11.649
9.856
33.337
Output 3
23.991
79.626
73.734
80.894
26.206
82.706
82.706
85.750

174
4
Applications I
Fig. 4.21 Fitness
comparison of techniques to
validation data

4.6
Unmanned Marine Vehicle
175
run 7, except for this data run, KID ﬁtness on output one is better than data run 6.
For data run 9, all ARMAX models fail to make estimation, as the ﬁtness runs away
very far in all outputs. PEM models have better ﬁtness here, but it still is very small,
ten order model of PEM only reaches 12.3% of ﬁtness in output one. KID model is
the best here, it has the best ﬁtness value for outputs two and three, except that for
output one, model order three, four and ten have ﬁtness below zeros.
For data run 10, KID provides the best ﬁtness, for ﬁrst output, model order four
give 56.3% and order 20 give 78.6%. Fitness for output two is slightly smaller than
output two, and ﬁtness of OKID model for output three is high, four order give
86.2%, and 20 order give 85.7%.
As a comparison, Elkaim identiﬁcation using KID technique on Atlantis boat,
with different data set have reconciled that model with order four have enough ﬁt-
ness level [9]. The data run that he used using pseudo random input.
4.6.6 State-Space Order Determinations
This additional section will explain how to determine effective model order of state
space model. A realization is computation of triplet A, B, C from Markov parameter
in (4.14) from which the discrete model in (4.12) is satisﬁed. It can be shown that
any system have an inﬁnite number of realizations which will predict the identical
response for any particular output [11]. It’s now desired to determine the minimal
realizations of model, that means possible smallest state space dimension. System
realization begins by forming generalized αm × βq Hankel matrix from Markov
parameters from (4.14), where α and β are greater than expected order of minimal
realizations,
H(k −1) =
⎡
⎢⎢⎢⎣
Yk
Yk+1
···
Yk+β−1
Yk+1
Yk+2
···
Yk+β
...
...
...
...
Yk+α−1
Yk+α
···
Yk+α+β−2
⎤
⎥⎥⎥⎦
(4.25)
for case k = 1,
H(0) =
⎡
⎢⎢⎢⎣
Y1
Y2
···
Yβ
Y2
Y3
···
Yβ
...
...
...
...
Yα
Y1+α
···
Yα+β−1
⎤
⎥⎥⎥⎦.
(4.26)
It can be shown that H(k −1) can be decomposed into three matrices, yield,
H(k −1) = PαAk−1Qβ
(4.27)

176
4
Applications I
where,
Pα =
⎡
⎢⎢⎢⎣
C
CA
...
CAα−1
⎤
⎥⎥⎥⎦,
Qβ =

B
AB
···
Aβ−1B

.
(4.28)
Here, Pα is observability matrix, whereas Qβ is the controllability matrix. If the
realization are minimum, the system will be both controllable and observable, then
Qβ, Pα are of rank n, also Hankel matrix will be rank of n, therefore minimum
realizations of the system will be n number of states.
In noisy input output data however, Hankel matrix always full rank, however, to
determine the true state from noise state, one can determine it from singular value
decomposition of Hankel matrix. Sudden drop in one diagonal value of rectangu-
lar matrix in singular value decomposition can be sign number of system order.
There also another two approach to distinguish between true modes from noise
modes, called Modal Amplitude Coherence and Modal Singular Values, for more
detail see [11].
4.7 Industrial Evaporation Unit
We have learned from the foregoing section that system identiﬁcation is a complex
ﬁeld that can be presented in many deferent ways. In what follows, we provide sim-
ulation studies on an industrial evaporation unit, a schematic description of which
was given in Chap. 2. The input and output patterns are depicted in Fig. 4.22.
Fig. 4.22 Input and output signals

4.7
Industrial Evaporation Unit
177
4.7.1 Continuous-Time Model
For many physical systems, it is natural to work with continuous-time representa-
tions, since most basic relationships are expressed in terms of differential equations.
It is well known that a linear time invariant, causal system can be described by its
impulse response as follows:
y(t) =
 ∞
τ=0
g(τ)u(t −τ)dτ.
(4.29)
The impulse response g(τ) gives a complete characterization of the system; Know-
ing the input signal u(t) at interval [0;t] we can compute the output signal y(t) at
interval [0;t].
For continuous systems, we can also use the notation of transfer functions. The
result of applying the Laplace transform yields:
Y(s) = G(s)U(s).
(4.30)
4.7.2 Discrete-Time Model
In system identiﬁcation, we will almost exclusively deal with observations of inputs
and outputs in discrete time, since this is the typical data-acquisition mode.
We assume output y(k) and u(k) to be observed at the sampling instants k = nT ,
n = 1,2,3,... . The interval T will be called the sampling interval.
Equally, we can derive an impulse response notation for the sampled data system.
For ease of notation, we assume that T is one time unit;
y(k) =
∞

n=0
g(n)u(k −n).
(4.31)
4.7.3 Disturbances
According to relation (4.31), we assume that the output can be calculated exactly
once the input is known. In most cases, this is unrealistic. There are always (un-
known) disturbances affecting the system. In our linear framework, we assume that
these disturbances enter the system additively to the output.
y(k) =
∞

n=0
g(n)u(k −n) + v(k).
(4.32)
Generally, system identiﬁcation is chosen to represent the noise term v(k) as a ﬁl-
tered white noise. The white noise e(k) emphasizes the unknown (stochastic) nature
of the disturbance. By varying the white noise characteristics and choosing different
impulse responses h(k), all kinds of disturbances can be represented. Although this
description does not give a complete characterization of all possible disturbances, it
is good enough for most practical purposes.

178
4
Applications I
v(k) =
∞

n=0
h(n)e(k −n).
(4.33)
Similar to transfer function description in the continuous time domain, we can use
transfer functions in the discrete time domain.
The use of z-transformation offers an elegant method for describing transfer
functions in the discrete time domain. z-transformation plays a similar role for dis-
crete processes as Laplace transformation does for continuous processes.
The z-transformation is deﬁned as:
G(z) =
∞

k=0
g(k)z−k
(4.34)
hence,
y(k) = G(z)u(k)
(4.35)
where G(z) can be called the transfer function of a discrete system.
In some identiﬁcation studies, the operators z and q are used interchangeably to
denote the forward (backward) shift operator, that is, shifting a signal one sampling
interval ahead in time. In the same way, z−1 and q−1 are used interchangeably to
denote the backward shift operator, shifting the signal one interval backward in time.
Using the transfer function description, we can deﬁne our basic description for a
linear system with additive disturbance.
y(k) = G(q)u(k) + H(q)e(k).
(4.36)
4.7.4 The Prediction Error Method (PEM) Method
The prediction error method (PEM) is sometimes called the generalized least
squares (GLS) method, although GLS originally was associated with a certain nu-
merical minimization procedure by extending the equation error model and assum-
ing that the true process is given by
Ao(q)y(t) = Bo(q)u(t) +
1
Do(q)e(t)
(4.37)
or
y(t) = Bo(q)
Ao(q)u(t) +
1
Ao(q)Do(q)e(t)
where
Ao(q) = 1 + ao
1q−1 + ao
2q−2 + ··· + ao
naq−na,
Bo(q) = bo
1q−1 + bo
2q−2 + ··· + bo
nbq−nb,
Do(q) = 1 + do
1q−1 + do
2q−2 + ··· + do
ndq−nd
and e(t) is white noise with zero mean and variance λ.

4.7
Industrial Evaporation Unit
179
So the equation disturbance is assumed to be an AR (autoregressive) process.
Then, (3.88) can be written as
Do(q)Ao(q)y(t) = Do(q)Bo(q)u(t) + e(t).
(4.38)
This enlarged equation has a white noise disturbance e(t). Prom the study of the
least-squares method, we know that consistent and efﬁcient estimates of ai, bi, di
can be obtained by minimizing the loss function
VPEM = 1
N
N

t=1
ε2(t)
= 1
N
N

t=1

D(q)

A(q)y(t) −B(q)u(t)
2.
(4.39)
This implies that, in the identiﬁcation a model should be used which has the same
structure as the true process
D(q)A(q)y(t) = D(q)B(q)u(t) + ε(t)
(4.40)
where ε(t) is the residual. When D(t) = I, (3.92) can be written using ϕ(t) and θ,
y(t) = ϕ∗(t)θ + ε(t)
(4.41)
where
ϕ∗(t) =

−y(t −1)
···
−y(t −na)
u(t −1)
···
u(t −nb)

,
θ = (a1
···
ana
b1
···
bna)∗
and for computing ˆθ
ˆθ =

1
N
N

t=1
ϕ(t)ϕ∗(t)
−1
1
N
N

t=1
ϕ(t)y(t)

.
(4.42)
Note that all the discussions about algorithms for computing ˆθ will remain valid.
The results derived there depend only on the ‘algebraic structure’ of the esti-
mate (4.42). For the statistical properties, though, it is of crucial importance whether
ϕ(t) is an a priori given quantity, or whether it is a realization of a stochastic pro-
cess. The reason why this difference is important is that for the dynamic models,
when taking expectations of various quantities, it is no longer possible to treat Φ as
a constant matrix.
4.7.5 Analysis
Consider the least squares estimate (4.42) applied to the model (3.93). Assume that
the data obey
Ao(q)y(t) = Bo(q)u(t) + v(t)
(4.43)

180
4
Applications I
or equivalently
y(t) = ϕ∗(t)θo + v(t).
(4.44)
Here, θo is called the true parameter vector and v(t) is a stationary stochastic process
that is independent of the input signal. If the estimate ˆθ in (4.42) is ‘good’, it should
be close to the true parameter vector θo. To examine if this is the case, an expression
is derived for the estimation error
ˆθ −θo =

1
N
N

t=1
ϕ(t)ϕ∗(t)
−1
·

1
N
N

t=1
ϕ(t)y(t) −

1
N
N

t=1
ϕ(t)ϕ∗(t)

θo

=

1
N
N

t=1
ϕ(t)ϕ∗(t)
−1
1
N
N

t=1
ϕ(t)v(t)

.
(4.45)
The minimization of the loss function (3.91) has no analytical solution because
the error ε(t) is nonlinear in the parameters. We note, however, that the error ε(t)
of (3.92) has a bilinear feature. For given D(q) it is linear in A(q) and B(q), and
vice versa. The bilinear property can be exploited to obtain a simple algorithm for
minimizing the loss function (3.91). Speciﬁcally, the algorithm consists of repeating
the following two steps until convergence.
At iteration k + 1:
Step Procedure
• For given ˆDk(q) deﬁne the residual
εk+1
1
(t) = ˆDk(q)A(q)y(t) −ˆDk(q)B(q)u(t).
The error εk+1
1
(t) is linear in A(q) and B(q), hence we can determine ˆAk+1(q)
and ˆBk+1(q) by solving an LS problem where the loss function
V1 = 1
N
N

t=1
εk+1
1
(t)2
= 1
N
N

t=1
 ˆDk(q)

A(q)y(t) −B(q)u(t)
2
is minimized.
• For given ˆAk+1(q) and ˆBk+1(q) deﬁne the residual as
εk+1
2
(t) = D(q) ˆAk+1(q)y(t) −D(q) ˆBk+1(q)u(t).

4.7
Industrial Evaporation Unit
181
Fig. 4.23 Error generation of the GLS algorithm
Then determine ˆDk+1(q) by minimizing
V2 = 1
N
N

t=1
εk+1
2
(t)2
= 1
N
N

t=1

D(q)
 ˆAk+1(q)y(t) −ˆBk+1(q)u(t)
2.
This is again an LS problem.
Thus each step of the algorithm solves an LS problem. This is perhaps why the
name generalized least-squares (GLS) is given to the algorithm. The iteration can be
started with a normal LS estimation. Figure 4.23 shows the block diagram of error
generation for the GLS algorithm.
A question to be answered is whether the alternative minimization of V1 and
V2 will minimize the original loss function VGLS in (3.91). The intuitive answer of
the reader may be positive. This is indeed true. The iteration procedure is a special
case of the so called separable least-squares problem. Under the persistent excita-
tion condition of the test signal, they can show that, if the iteration converges, it will
reach a local minimum of the original loss function VGLS in (3.91). Thus, the itera-
tion is a minimization procedure. Note, however, that the convergence to the global
minimum is not guaranteed here.

182
4
Applications I
4.7.6 Modiﬁcations
The least squares method is certainly simple to use. As shown above, it gives con-
sistent parameter estimates only under rather restrictive conditions. In some cases,
the lack of consistency may be tolerable. If the signal-to-noise ratio is large, the bias
will be small. If a regulator design is to be based on the identiﬁed model, some bias
can in general be acceptable. This is because a reasonable regulator should make
the closed loop system insensitive to parameter variations in the open loop part. In
other situations, however, it can be of considerable importance to have consistent
parameter estimates. In this and the following chapter, two different ways are given
of modifying the LS method so that consistent estimates can be obtained under less
restrictive conditions.
It is appropriate here to comment on the prediction error approach and why the
LS method is a special case of this approach. Neglecting the equation error ε(t) in
the model (3.93), one can predict the output at time t as
ˆy(t) = −a1y(t −1) −··· −anay(t −na)
+ b1u(t −1) + ··· + bnbu(t −nb)
= ϕ∗(t)θo.
(4.46)
Hence,
ε(t) = y(t) −ˆy(t)
(4.47)
can be interpreted as a prediction error. Therefore, the LS method determines the
parameter vector which makes the sum of squared prediction errors as small as
possible. Note that the predictor (4.46) is constructed in a rather ad hoe manner. It
is not claimed to have any generally valid statistical properties, such as mean square
optimality.
There are several ways to modify the GLS algorithm in order to simplify the
computation or to speed up the convergence rate. The main idea of these modiﬁ-
cations is ﬁrst to apply the LS method on the model (3.92) with order na + nd in
order to obtain consistent estimates of polynomials D(q)A(q) and D(q)B(q), then
to perform some kind of model reduction to retrieve A(q), B(q) and D(q). For the
problem of model order selection, one can still use the output error criterion. Now,
however, there is another possibility. Because the GLS method aims at obtaining
white noise residuals, a natural way to order selection is to check the whiteness of
residuals for increasing orders. The sample autocorrelation function of the residuals
can be used for this test. Note that we have to select both the process order and the
order of the disturbance ﬁlter. To simplify the procedure, we can let them be equal,
i.e., n = nd. More discussions on order selection will be given in a later section.
To see why the GLS method can be called a prediction error method, rewrite the
true process (3.88) as
y(t) = Bo(q)
Ao(q)u(t) +
1
Ao(q)Do(q)e(t)

4.7
Industrial Evaporation Unit
183
= Bo(q)
Ao(q)u(t) +

1
Ao(q)Do(q) −1

e(t) + e(t).
(4.48)
Because the coefﬁcients of the highest degree terms of Ao(q) and Do(q) are 1
(monic polynomials), their product will also have this property:
F o(q) = Ao(q)Do(q) = 1 + f1q−1 + ··· + f2nq−1.
Thus, the ﬁlter

1
Ao(q)Do(q) −1

= −f1q−1 −··· −f2nq−1
Ao(q)Do(q)
has one unit delay. This means that the second term in (4.48) is a signal that only
depends on the past data up to time t −1. When expressing this signal in terms of
u(t) and y(t) we have
y(t) = Bo(q)
Ao(q)u(t) +

1
Ao(q)Do(q) −1

Ao(q)Do(q)
·

y(t) −Bo(q)
Ao(q)u(t)

+ e(t)
= Bo(q)Do(q)u(t) +

1 −Ao(q)Do(q)

y(t) + e(t)
= z(t)e(t)
(4.49)
where
z(t) = Bo(q)Do(q)u(t) +

1 −Ao(q)Do(q)

y(t).
Note that z(t) and e(t) are uncorrelated. If z(t) is used as the one step ahead predic-
tion of the output y(t), the prediction error e(t) is white noise. One would expect
that this predictor is the best one in some sense, because when the prediction error
is white noise, it contains no useful information at all. Indeed, this can be shown
more formally. Let y∗(t) be an arbitrary predictor of y(t). Then the variance of the
prediction error is
E

y(t) −y∗(t)
2 = E

z(t) + e(t) −y∗(t)
2
= E

z(t) −y∗(t)
2 + Ee2(t)
≥Ee2(t) = E

y(t) −z(t)
2.
(4.50)
Thus, z(t) is the optimal predictor in the sense of minimum variance. In iden-
tiﬁcation, we will write down the optimal ﬁlter in terms of unknown polynomials
as
y(t|θ) = B(q)D(q)u(t) +

1 −A(q)D(q)

y(t)
(4.51)
and determine the parameters by minimizing the sum of the squares of the prediction
errors

184
4
Applications I
V = 1
N
N

t=1

y(t) −y∗(t)
2
= 1
N
N

t=1

D(q)

A(q)y(t) −B(q)u(t)
2.
(4.52)
Again this is the loss function of the GLS method (3.91). The model struc-
ture (3.88) is one way to model the equation error noise. Other model structures
can also be used. Next, consider optimal prediction for systems given in the state
space form
x(t + 1) = A(θ)x(t) + B(θ)u(t) + v(t),
y(t) = C(θ)x(t) + e(t)
(4.53)
where v(t) and e(t) are mutually uncorrelated white noise sequences with zero
means and covariance matrices λ1(θ) and λ2(θ), respectively. The optimal one-step
predictor of y(t) is given by the Kalman ﬁlter,
ˆx(t + 1|t) = A(θ)ˆx(t|t −1)
+ B(θ)u(t) + K(θ)

y(t) −C(θ)ˆx(t|t −1)

,
(4.54)
ˆy(t|t −1) = C(θ)ˆx(t|t −1)
where the gain K(θ) is given by
K(θ) = A(θ)P(θ)C∗(θ)

C(θ)P(θ)C∗(θ) + λ2(θ)
−1
and where P(θ) is the solution of the following algebraic Riccati equation:
P(θ) = A(θ)P(θ)A∗(θ) + λ1(θ) −K(θ)C(θ)P(θ)A∗(θ).
This predictor is mean square optimal if the disturbances are Gaussian distributed.
For other distributions, it is the optimal linear predictor.
4.7.7 Estimation Using ARX Model
The ARX model is the simplest model incorporating the stimulus signal. The esti-
mation of the ARX model is the most efﬁcient of the polynomial estimation meth-
ods because it is the result of solving linear regression equations in analytic form.
Moreover, the solution always satisﬁes the global minimum of the loss function.
The ARX model therefore is preferable, especially when the model order is high.
The disadvantage of the ARX model is that disturbances are part of the system dy-
namics.
The parameters of the ARX model structure can be described by a linear differ-
ence equation:
y(t) + a1y(t −1) + a2y(t −2) + ··· + anay(t −na)
= b1u(t −1) + b2u(t −2) + ··· + bnbu(t −nb) + e(t).
(4.55)

4.7
Industrial Evaporation Unit
185
The adjustable parameters can be lumped in vector θ
θ =

a1
a2
···
ana
b1
b2
···
bnb
T .
Deﬁning the orders and delay of the ARX model. Speciﬁcally, in discrete time q
here working as backward shift operator; this means
A(q) = 1 + a1q−1 + a2q−2 + ··· + anaq−na,
B(q) = b1q−1 + b2q−2 + ··· + bnbq−nb
deﬁne
G(q) = B(q)
A(q),
H(q) =
1
A(q)
then
y(t) = B(q)
A(q)u(t) +
1
A(q)e(t)
or
A(q)y(t) = B(q)u(t) + e(t).
We call this model the ARX model, where AR refers to the autoregressive part
A(q)y(t) and X to the extra input B(q)u(t). The white noise e(t) is assumed to
go through the denominator dynamics of the system. From a physical point of view,
this is probably not the most natural way of representation, but this makes it possible
to deﬁne the predictor as a hear regression model.
Let us introduce vector ϕ(t)
ϕ∗(t) =

−y(t −1)
···
−y(t −na)
u(t −1)
···
u(t −nb)

.
(4.56)
With vectors ϕ(t) and θ, (4.55) can be rewritten as:
y(t) = ϕ∗(t)θ + e(t).
(4.57)
If the term e(t) is considered to be very small, which may be the case in a lot of
practical situations, then according to (4.57) prediction for y(t) depending on the
parameter vector θ, can be written as:
y(t|θ) = ϕ∗(t)θ.
(4.58)
The predictor is a scalar product of the known (regression) vector ϕ(t) and the pa-
rameter vector θ. This is called a hear regression model. With this linear model,
simple estimation methods can be applied for the determination of the parameter
vector θ.
4.7.8 The Multivariable ARX Case
If we consider the case where input u(t) is an m-dimensional vector and output y(t)
is an n-dimensional vector, we obtain for the ARX description:

186
4
Applications I
y(t) + A1y(t −1) + A2y(t −2) + ··· + Anay(t −na)
= B1u(t −1) + B2u(t −2) + ··· + Bnbu(t −nb) + e(t).
(4.59)
For a system with nu inputs and ny outputs, A(q) is an ny × ny matrix. A(q) can
be represented as a polynomial in the shift operator q−1:
A(q) = Iny + A1q−1 + ··· + Anaq−na
=
⎡
⎢⎢⎢⎣
a11(q)
a12(q)
···
a1ny(q)
a21(q)
a22(q)
···
a2ny(q)
...
...
...
...
any1(q)
any2(q)
···
anyny(q)
⎤
⎥⎥⎥⎦
where the entries akj are polynomials in the delay operator q−1,
akj(q) = δkj + a1
kjq−1 + a2
kjq−2 + ··· + a
nakj
kj
q−nakj .
This polynomial describes how old values of output number jth are affected by the
kth output. Here δkj is the Kronecker-delta; it equals 1 when k = j. The kth row
of A(q) represents the contribution of the past output values for predict the current
value of the kth output.
B(q) is an ny × ny matrix and can be represented as a polynomial in the shift
operator q−1:
B(q) = B0 + B1q−1 + ··· + Bnbq−nb
=
⎡
⎢⎢⎢⎣
b11(q)
b12(q)
···
b1nu(q)
b21(q)
b22(q)
···
b2nu(q)
...
...
...
...
bny1(q)
bny2(q)
···
bnynu(q)
⎤
⎥⎥⎥⎦
where the matrix element bkj is a polynomial in the shift operator q−1
bkj(q) = b1
kjq−nbkj + ··· + b
nkkj
kj q−nkkj −nbkj +1
where nkkj is the delay from the jth input to the kth output. B(q) represents the
contributions of inputs to predicting all output values. The simulation results are
given by
A0 =
⎡
⎣
1
0
0
0
1
0
0
0
1
⎤
⎦,
A1 =
⎡
⎣
−0.516 + 0.012i
0.104 + 0.006i
−0.008 + 0.037i
0.069 + 0.021i
−0.706 + 0.012i
−0.158 + 0.068i
−0.010 + 0.007i
−0.010 + 0.004i
−0.868 + 0.022i
⎤
⎦,
A2 =
⎡
⎣
−0.385 + 0.011i
0.0192 + 0.006i
0.015 + 0.036i
−0.103 + 0.021i
−0.1595 + 0.012i
0.126 + 0.067i
−0.015 + 0.007i
−0.0060 + 0.004i
−0.101 + 0.022i
⎤
⎦,

4.7
Industrial Evaporation Unit
187
Fig. 4.24 N4S1D approach
versus the classical approach
Fig. 4.25 Block diagram of
the prediction error method
B0 =
⎡
⎣
0
0
0
0
0
0
0
0
0
⎤
⎦,
B1 =
⎡
⎣
−0.006 + 0.003i
0.006 + 0.003i
0.104 + 0.006i
0.064 + 0.006i
−0.045 + 0.006i
−0.048 + 0.011i
0.004 + 0.002i
−0.001 + 0.002i
−0.124 + 0.004i
⎤
⎦,
B2 =
⎡
⎣
−0.019 + 0.003i
0.020 + 0.003i
0.063 + 0.005i
0.148 + 0.006i
−0.053 + 0.006i
0.207 + 0.010i
0.006 + 0.002i
−0.004 + 0.002i
−0.020 + 0.003i
⎤
⎦.
4.7.9 Estimated State Space Using N4SID Model
In what follows, we will use N4SID Algorithm 1 and N4SID Algorithm 2 to identify
mixed deterministic-stochastic systems. Both algorithms determine state sequences

188
4
Applications I
through the projection of input and output data. As we learned from the foregoing
sections, the major portion the systems identiﬁcation literature is concerned with
computing polynomial models, which are however known to typically give rise to
numerically ill-conditioned mathematical problems, especially for MIMO (Multi-
Input Multi-Output) systems. Numerical algorithms for subspace state space system
identiﬁcation (N4SID) are then viewed as the better alternatives. This is especially
true for high-order multivariable systems, for which it is not trivial to ﬁnd a use-
ful parameterizations among all possible parameterizations. This parametrization is
needed to start up the classical identiﬁcation algorithms, which means that a pri-
ori knowledge of the order and of the observability (or controllability) indices is
required.
With N4SID algorithms, most of this a priori parametrization can be avoided.
Only the order of the system is needed and it can be determined through inspection
of the dominant singular values of a matrix that is calculated during the identiﬁ-
cation. The state space matrices are not calculated in their canonical forms (with
a minimal number of parameters), but as full state space matrices in a certain, al-
most optimally conditioned basis (this basis is uniquely determined, so that there is
no problem of identiﬁability). This implies that the observability (or controllability)
indices do not have to be known in advance.
Another major advantage is that N4SID algorithms are non-iterative, with
no non-linear optimization part involved. For classical identiﬁcation, an extra
parametrization of the initial state is needed when estimating a state space system
from data measured on a plant with a nonzero initial condition. A ﬁnal advantage
of the N4SID algorithms, is that there is no difference between zero and nonzero
initial states.
In the sequel, we deal with LTI systems subject to input and measurement noises
of the type:
x(t + T s) = Ax(t) + Bu(t) + Ke(t),
y(t) = Cx(t) + Du(t) + e,
E
wk
υk
wt
i
υt
i

=
 Qs
Ss
(Ss)t
Rs

δki ≥02.
(4.60)
System (4.60) can be cast into the standard form
xk+1 = Axk + Buk + wk,
yk = Cxk + Duk + νk
where a four-stage evaporator system, the three inputs are
• u1, feed ﬂow,
• u2, vapor ﬂow to the ﬁrst evaporator stage,
• u3, cooling water ﬂow,
and three outputs

4.7
Industrial Evaporation Unit
189
Fig. 4.26 The zero-mean
sample 250–350 for u1–y1
Fig. 4.27 The zero-mean
sample 250–350 for u2–y2
• y1, the dry matter content,
• y2, the ﬂow,
• y3, the temperature of the out-coming product,
and the number of samples are 6305. From this data, nine different combi-
nation can be appeared, namely: (u1,y1); (u1,y2); (u1,y3); (u2,y1); (u2,y2);
(u2,y3);(u3,y1); (u3,y2) and (u3,y3). Figure 4.26 shows input (u1) and output
(y1) data for sample period between 250–350 after removing the constant levels
and making zero-mean data. Where input (u2), output (y2) and input (u3), output
(y3) are shown on Figs. 4.27 and 4.28, respectively.

190
4
Applications I
Fig. 4.28 The zero-mean
sample 250–350 for u3–y3
The model matrices are given below
A =
⎡
⎢⎢⎣
0.96
−0.00
0.018
0.0139
−0.000
0.98
0.060
−0.076
−0.006
−0.10
0.93
−0.18
−0.035
0.075
0.24
0.69
⎤
⎥⎥⎦,
B =
⎡
⎢⎢⎣
−4.2e-5
1.587e-6
0.2
−0.001
0.00
0.0004
−0.003
0.001
−0.0007
0.005
−0.0007
0.0004
⎤
⎥⎥⎦,
C =
⎡
⎣
28.93
67.402
−21.66
0.50
−8.32
−50.44
−47.416
−32.04
−77.91
1.90
−2.45
−0.58
⎤
⎦,
D =
⎡
⎣
0
0
0
0
0
0
0
0
0
⎤
⎦,
K =
⎡
⎢⎢⎣
0.000
−0.000
−0.007
0.004
−0.001
0.001
−0.000
−0.001
−0.001
−0.000
−0.001
−0.000
⎤
⎥⎥⎦,
X(0) =
⎡
⎢⎢⎣
−8.792e-5
−0.00576
−0.0004
−0.014
⎤
⎥⎥⎦.
(4.61)
4.7.10 Numerical Results
PEM method has been used to check performance of this identiﬁcation. The data
samples period from 1 to 3000 have been used to ﬁnd out parameters of state space

4.7
Industrial Evaporation Unit
191
Fig. 4.29 A comparison between original and estimated data using iterative prediction-error min-
imization method, order 5
equation (4.60), Fig. 4.29. In this case, we use order 5 (4.62) but in Fig. 4.30 order
7 have been used.
A =
⎡
⎢⎢⎢⎢⎣
0.963
0.003
−0.017
−0.008
−0.008
0.001
0.926
−0.058
−0.140
0.007
0.013
0.138
0.960
0.099
0.057
0.008
0.200
−0.166
0.698
−0.227
−0.167
−0.068
0.047
−0.187
−0.251
⎤
⎥⎥⎥⎥⎦
,
B =
⎡
⎢⎢⎢⎢⎣
−0.0001
0.0000
0.0025
−0.0055
0.0015
0.0004
0.0041
−0.0005
−0.0001
0.0085
−0.0003
0.0017
−0.0002
−0.0025
0.0217
⎤
⎥⎥⎥⎥⎦
,
C =
⎡
⎣
18.72
27.71
36.25
−1.94
1.74
−6.32
−46.72
7.25
−22.34
−2.15
−52.37
0.31
0.17
−0.49
0.8006
⎤
⎦,
D =
⎡
⎣
0
0
0
0
0
0
0
0
0
⎤
⎦,
K =
⎡
⎢⎢⎢⎢⎣
−0.0003
−0.0003
−0.0167
0.0030
−0.0043
0.0079
0.0049
0.0019
−0.0014
−0.0029
0.0003
−0.0059
−0.0037
−0.0171
0.0046
⎤
⎥⎥⎥⎥⎦
,
X(0) =
0
0
0
0
0T .
(4.62)

192
4
Applications I
Fig. 4.30 A comparison between original and sampled estimated data using iterative prediction-er-
ror minimization method, order 7
Fig. 4.31 A comparison between original and sampled estimated data using iterative prediction-er-
ror minimization method, order 10
From Figs. 4.29–4.46, we observe that for each method with different order we
have different ﬁtness the goodness of chosen order depend on singular value. From
Fig. 4.34, we observe PEM method is the best for output 1 and 2 where ARX is the
best of output 3.

4.8
A Hydraulic Pumping System
193
Fig. 4.32 A comparison between original and sampled estimated data using iterative prediction-er-
ror minimization method, order 15
Fig. 4.33 A comparison between original and estimated data using iterative prediction-error min-
imization method
4.8 A Hydraulic Pumping System
Modeling techniques of industrial processes can be classiﬁed into the following
three categories [17].

194
4
Applications I
Fig. 4.34 A comparison between three types of system identiﬁcations: set 1
Fig. 4.35 A comparison between three types of system identiﬁcations: set 2
1) White-Box Modeling: the model is obtained taking into account physical equa-
tions that govern the process. In this class, a deep knowledge of the system is
necessary.
2) Gray-Box Modeling: Prior or auxiliary knowledge of the system is used. Such
auxiliary knowledge may be available in the form of steady-state data.

4.8
A Hydraulic Pumping System
195
Fig. 4.36 A different comparison between original and estimated data using iterative predic-
tion-error minimization method
Fig. 4.37 A different comparison between original and sampled estimated data using iterative
prediction-error minimization method, order 7
3) Black-Box Modeling: The model is identiﬁed only using the data set acquired
from the process during a dynamical test. In this case, no other source of knowl-
edge is used.

196
4
Applications I
Fig. 4.38 A different comparison between original and sampled estimated data using iterative
prediction-error minimization method, order 10
Fig. 4.39 An alternative comparison between original and sampled estimated data using iterative
prediction-error minimization method, order 10
In this section, we are concerned with black and gray-box procedures using dif-
ferent model classes.

4.8
A Hydraulic Pumping System
197
Fig. 4.40 An alternative comparison between original and sampled estimated data using iterative
prediction-error minimization method, order 15
Fig. 4.41 An alternative comparison between original and sampled estimated data using N4SID
method, order 15
4.8.1 Dynamical Data
One important task that has to be developed during the identiﬁcation process is the
input signal selection as it can inﬂuence not only parameter estimation, but also
structure selection in the case of nonlinear systems [16].

198
4
Applications I
Fig. 4.42 An alternative comparison between original and sampled estimated data using N4SID
method, order 10
Fig. 4.43 An alternative comparison between original and sampled estimated data using N4SID
method, order 5
Since the presence of a “variable time-constant” in the pumping system dynamics
was veriﬁed in an earlier work [7], the input signal was chosen to excite the system at
different operating points using different step sizes. The sampling time Ts = 50 ms
was selected according to the criterion deﬁned in [1]. Examples of input–output data

4.8
A Hydraulic Pumping System
199
Fig. 4.44 Compare between original data (sample 5000 to 5100) and estimated data from (sample
data 1 to 3000) using ARX method, na = [9 9 9; 9 9 9; 9 9 9], nb = [9 9 9; 9 9 9; 9 9 9],
nk = [0 0 1; 1 0 0; 0 1 0]
Fig. 4.45 Compare between original data (sample 5000 to 5100) and estimated data from (sample
data 1 to 3000) using ARX method, na = [5 5 5; 5 5 5; 5 5 5], nb = [3 3 3; 3 3 3; 3 3 3],
nk = [0 0 1; 1 0 0; 0 1 0]
are shown in Fig. 4.47. In this work, N = 3200 data points from the dynamical data
set were used for model identiﬁcation and N = 800 were used for validation.

200
4
Applications I
Fig. 4.46 Compare between original data (sample 5000 to 5100) and estimated data from (sample
data 1 to 3000) using ARX method, na = [3 3 3; 3 3 3; 3 3 3], nb = [5 5 5; 5 5 5; 5 5 5],
nk = [0 0 1; 1 0 0; 0 1 0]
Parametric models describe systems in terms of differential equations and trans-
fer functions. This provides insight into the system physics and a compact model
structure. Generally, you can describe a system using an equation, which is known
as the general-linear polynomial model or the general-linear model Fig. 4.48. The
linear model structure provides ﬂexibility for both the system dynamics and stochas-
tic dynamics. However, a nonlinear optimization method computes the estimation
of the general-linear model. This method requires intensive computation with no
guarantee of global convergence.
Simpler models that are a subset of the General Linear model structure shown
in Fig. 4.48 are possible. By setting one or more of A(q), B(q), C(q) or D(q)
polynomials equal to 1, you can create these simpler models such as AR, ARX,
ARMAX, Box–Jenkins, and output-error structures.
4.8.2 ARX Modeling
The essential characteristic of the linear regression model is that a residual compo-
nent e is deﬁned which is a linear function of the unknown model coefﬁcients. In
the SISO (single input single output) situation, we can write:
y(t) + a1y(t −1) + ··· + anay(t −na)
= b1u(t −1) + ··· + bnbu(t −nb) + e(t)
(4.63)

4.8
A Hydraulic Pumping System
201
Fig. 4.47 Dynamical data: (top) pumps speed reference and (bottom) system output pressure
Fig. 4.48 General
polynomial model

202
4
Applications I
Fig. 4.49 ARX modeled data (- - -) v/s actual data (—)
with y(t) the output signal, and u(t) the input signal of the model, and a1,a2,...,
ana, b1,b2,...,bnb unknown parameters. The use of these kinds of models in esti-
mation and identiﬁcation problems is essentially based on the argument that a least
squares identiﬁcation criterion is an optimization problem that is analytically solv-
able.
Since the white noise term e(t) here enters as a direct error in the difference equa-
tion, the model is often called an equation error model. The adjustable parameters
in this case are:
θ =

a1
···
ana
b1
···
bnb

.
If we introduce
A(q) = 1 + a1q−1 + ··· + anaq−na,
B(q) = 1 + b1q−1 + ··· + bnbq−nb,
we see that the model corresponds to
G(q,θ) = B(q)
A(q);
H(q,θ) =
1
A(q).
Computing the predictor for the system above, we get
ˆy(t|θ) = B(q)u(t) +

1 −A(q)

y(t).
(4.64)
Now, we introduce the vector
ϕ(t) =

−y(t −1)
···
−y(t −na)
u(t −1)
···
u(t −nb)

.
Then we can write the above equation in the following form
ˆy(t|θ) = θt.ϕ(t) = ϕT (t).θ.
(4.65)
The predictor is a scalar product between a known data vector ϕ(t) and a parameter
vector θ. Such a model is called a linear regression in statistics and the vector ϕ(t) is
called regression vector. See Fig. 4.49 for a comparison of the ARX modeled versus
actual data.

4.8
A Hydraulic Pumping System
203
4.8.3 ARMAX Modeling
The basic problem with the ARX model is the lack of adequate freedom in de-
scribing the properties of the disturbance term. We could add ﬂexibility to that by
describing the equation error as a moving average of white noise. This gives the
model:
y(t) + a1y(t −1) + ··· + anay(t −na)
= b1u(t −1) + ··· + bnbu(t −nb)
+ e(t) + c1e(t −1) + ··· + cnce(t −nc).
(4.66)
It can be rewritten as
A(q)y(t) = B(q)u(t) + C(q)e(t)
where
C(q) = 1 + c1q−1 + ··· + cncq−nc
and
G(q,θ) = B(q)
A(q);
H(q,θ) = C(q)
A(q).
The predictor for the ARMAX model can be obtained as
ˆy(t|θ) = B(q)u(t) +

1 −A(q)

y(t)
+

C(q) −1

ε(t,θ)
(4.67)
where
ε(t,θ) = y(t) −ˆy(t|θ).
In this case, our regression vector would be
ϕ(t) =

−y(t −1)
···
−y(t −na)
u(t −1)
···
u(t −nb)
ε(t −1,θ)
···
ε(t −nc,θ)

.
See Fig. 4.50 for a comparison of the ARMAX modeled versus actual data.
4.8.4 Box–Jenkins Model
A natural development of the output error model is to further the properties of the
output error. This can be done by assuming that the true process is
y(t) = B(q)
F(q)u(t) + C(q)
D(q)e(t)
(4.68)
where

204
4
Applications I
Fig. 4.50 ARMAX modeled data (- - -) v/s Actual data (—)
Fig. 4.51 BJ modeled data (- - -) v/s Actual data (—)
F(q) = 1 + f1q−1 + ··· + fnf q−nf ,
D(q) = 1 + d1q−1 + ··· + dndq−nd.
In a sense, this is the most natural ﬁnite-dimensional parameterization and the trans-
fer functions G and H are independently parameterized as rational functions. This
model was suggested and treated in [8]. In this case, the parameter vector is given
by
θ =

b1 ··· bnb
f1 ··· fnf
c1 ··· cnc
d1 ··· dnd

.
See Fig. 4.51 for a comparison of the BJ modeled versus actual data.
4.8.5 State Space Model
In state-space form, the relationship between the input, noise and output signals
is written as a system of ﬁrst order differential or difference equations using an
auxiliary state vector x(t). For most physical systems, it is easier to construct models
with physical insight in continuous time than in discrete time, simply because most
laws of physics are expressed in continuous time. This means that the modeling

4.8
A Hydraulic Pumping System
205
normally leads to a representation
˙x(t) = F(θ)x(t) + G(θ)u(t).
(4.69)
Here F and G are matrices of appropriate dimensions (n × n and n × m, respec-
tively for an n-dimensional system and an m-dimensional input). Moreover, θ is a
vector of parameters that correspond to the unknown values of physical coefﬁcients,
material constants, and the like.
Let η(t) be the measurements that would be obtained with ideal, noise-free sen-
sors:
η(t) = Hx(t).
Using p as the differential operator, the above state representation can be written as

pI −F(θ)

x(t) = G(θ)u(t).
Which means that the transfer function from u to η is
η(t) = Gc(p,θ)u(t),
Gc(p,θ) = H

pI −F(θ)
−1G(θ).
Let the measurements be sampled at the time instants t = kT , k = 1,2,... and
the disturbance effects at those time instants be vT (kT ). Hence, the measured output
is
y(kT ) = Gc(p,θ)u(t) + vT (kT ).
There are several ways of transporting Gc(p,θ) to a representation that is explicitly
discrete time. Suppose that the input is constant over the sampling interval T
u(t) = uk = u(kT ),
kT ≤t < (k + 1)T.
Then (4.69) can be solved from t = kT to t = kT + T , yielding
x(kT + T ) = AT (θ)x(kT ) + BT (θ)u(kT )
where
AT (θ) = eF(θ)T ,
BT (θ) =
 T
τ=0
eF(θ)τG(θ)dτ.
The model identiﬁed using state space modeling is represented in the form of
matrices as follows:
A =
1.0324
−0.1613
0.1567
0.7600

,
B =
−0.0136
−0.1191

,
Ct =
199.8214
−7.0361

.
(4.70)
See Fig. 4.52 for a comparison of the state-space modeled versus actual data.

206
4
Applications I
Fig. 4.52 State-space modeled data (- - -) v/s Actual data (—)
Fig. 4.53 Comparison of
ﬁtness percentages using
various parametric model
structures
4.8.6 Linear Identiﬁcation Results
The ﬁtness level of the ARMAX modeled data was found to be the best as shown
in Fig. 4.53. One possible reason is the inﬂuence of disturbance. Unlike the ARX
model, the ARMAX model structure includes disturbance dynamics. ARMAX mod-
els are useful when you have dominating disturbances that enter early in the process,
such as at the input. The ARMAX model has more ﬂexibility in the handling of dis-
turbance modeling than the ARX model. The Box–Jenkins (BJ) structure provides
a complete model with disturbance properties modeled separately from system dy-
namics. The Box–Jenkins model is useful when you have disturbances that enter
late in the process. For example, measurement noise on the output is a disturbance
late in the process.
As we have discussed, there are a variety of parametric model structures avail-
able to assist in modeling a system. The choice of model structure is based upon

4.9
Flutter for F-18: Estimation and Validation
207
an understanding of the system identiﬁcation method and insight and understanding
into the system undergoing identiﬁcation. The characteristics of both system and
disturbance dynamics play a role is the proper model selection. These system iden-
tiﬁcation methods can handle a wide range of system dynamics without knowledge
of the actual system physics, thereby reducing the engineering effort required to de-
velop models. With respect to the Complexity of the model, the ﬁtness levels and
the residual analysis it is concluded that the ARMAX model suits the given system
best for the data history provided.
4.9 Flutter for F-18: Estimation and Validation
In what follows, the simulation of different identiﬁcation techniques used for the
ﬂutter of an aircraft F-18 is presented. The parametric methods like ARX, ARMAX,
PEM, OE and BJ are used for identiﬁcation. The non-parametric method used is the
N4SID subspace method. All of these methods are estimated and validated for the
data for the ﬂutter of an aircraft F-18.
4.9.1 PEM Method
With sampling interval = 1 s, the generated model is given by
A(q)y(t) =

B(q)/F(q)

u(t) +

C(q)/D(q)

e(t),
A(q) = 1 −2.552q−1 + 2.351q−2 −0.7877q−3,
B(q) = 0.01881 −0.04905q−1,
C(q) = 1 + 1.988q−1 + 0.992q−2,
D(q) = 1 −1.791q−1 + 0.9382q−2,
F(q) = 1 −1.05q−1 + 1.02q−2
and the associated simulation results are summarized in Fig. 4.54, for the estimation
and validation data.
4.9.2 ARX Method
With sampling interval = 1 s, the generated model is given by
A(q)y(t) = B(q)u(t) + e(t),
A(q) = 1 −2.498q−1 + 2.206q−2 −0.6675q−3,
B(q) = −0.3968q−4 + 0.7111q−5 −0.3645q−6
and the associated simulation results are summarized in Fig. 4.55, for the estimation
and validation data.

208
4
Applications I
Fig. 4.54 Estimation of PEM
method: Estimation (top) data
and validation data (bottom)
4.9.3 ARMAX Method
With sampling interval = 1 s, the generated model is given by
A(q)y(t) = B(q)u(t) + C(q)e(t),
A(q) = 1 −1.842q−1 + 0.972q−2,
B(q) = −0.2457q−1 + 1.487q−2 −2.743q−3 + 1.106q−4 + 1.266q−5
−0.9713q−6,
C(q) = 1 + 3.163q−1 + 3.818q−2 + 2.138q−3 + 0.4837q−4
and the associated simulation results are summarized in Fig. 4.56, for the estimation
and validation.
4.9.4 BJ Method
With sampling interval = 1 s, the generated model is given by

4.9
Flutter for F-18: Estimation and Validation
209
Fig. 4.55 Estimation of
ARX method: Estimation
(top) and validation (bottom)
y(t) =

B(q)/F(q)

u(t) +

C(q)/D(q)

e(t),
B(q) = 0.7822 −1.623q−1 + 0.8608q−2,
C(q) = 1 + 2.59q−1 + 2.578q−2 + 0.9919q−3,
D(q) = 1 −2.706q−1 + 2.591q−2 −0.8684q−3,
F(q) = 1 −1.762q−1 + 0.8845q−2 −0.07037q−3
and the associated simulation results are summarized in Fig. 4.57, for the estimation
and validation.
4.9.5 Output Equation Method
With sampling interval = 1 s, the generated model is given by
y(t) =

B(q)/F(q)

u(t) + e(t),
B(q) = 2.447q−1 −9.462q−2 + 14.05q−3 −9.491q−4 + 2.464q−5,
F(q) = 1 −2.448q−1 + 1.175q−2 + 1.737q−3 −2.083q−4 + 0.6412q−5

210
4
Applications I
Fig. 4.56 Estimation of
ARMAX method: Estimation
(top) and validation (bottom)
and the associated simulation results are summarized in Fig. 4.58, for the estimation
and validation.
4.9.6 N4SID Method
With sampling interval = 1 s, the generated model is given by
x(t + 1) = Ax(t) + Bu(t) + Ke(t),
y(t) = Cx(t) + Du(t) + e(t),
A =
 0.78366
0.45662
−0.19106
0.88406

,
B =
0.007195
0.023348

,
Ct =
 −6.8573
−0.75961

,
K =
 −0.13446
−0.091591

,
x(0) =
0.00084913
0.00099388

and the associated simulation results are summarized in Fig. 4.59, for the estimation
and validation.

4.10
Notes and References
211
Fig. 4.57 Estimation of
ARX method: Estimation
(left) and validation (right)
Table 4.10 Comparisons of ﬂutter models
Model
Loss function
FPE
% Estimation
% Validation
PEM
2.41673 × 10−7
2.59285 × 10−7
73.53
52.2
ARX
0.000137359
0.000140617
72.05
55.78
ARMAX
1.97461 × 10−5
2.07252 × 10−5
69.58
62.04
BJ
1.90325 × 10−6
1.99762 × 10−6
75.52
70.49
OE
0.0282611
0.029417
87.01
50.82
N4SID
0.00880892
0.00908857
59.44
43.69
4.10 Notes and References
The use of a priori information to identify nonlinear systems is usually justiﬁed
when the system is not well represented in all operating points by the available dy-
namical data sets, which often occurs in practical situations. For instance, [2] show
that information about the static curve of a system can be useful during the dynamic
model identiﬁcation process when this information is not completely available in
the dynamic data.

212
4
Applications I
Fig. 4.58 Estimation of OE
method: Estimation (top) and
validation (bottom)
Nevertheless, measured static curves and dynamic data were used even though
the dynamic data set might supply by itself enough information to arrive at models
with good approximation of the static curve of the system. Thus, these data sets
could be seen as carrying redundant information.
This brief addressed the problem of identiﬁcation of nonlinear systems using
different methods that use auxiliary information in various degrees. Using data from
a 15 kW pumping plant, it was shown that steady-state information and free-run
simulation error criteria can be useful during the identiﬁcation process.
In this brief a novel multi-objective approach to system identiﬁcation was pro-
posed: it uses the static curve as the additional source of information and the simula-
tion error criterion instead of the prediction error criterion. Besides, a new decision-
maker that takes into account the measurement uncertainty was also introduced.
This approach arrived at models with better static curve and dynamic response, be-
ing possible to ﬁnd a model that outperformed the black-box counterpart in the
dynamic and static performance criteria.
As far as the simulation error bi-objective approach is concerned, it would be
interesting to develop an algorithm to ﬁnd the Pareto set without having to use the
free-run simulation which is very computationally demanding. In spite of its high
computational cost, it is also desired in future work to apply the simulation error
criterion to detect the model structure of the process studied in this work as in [16].

References
213
Fig. 4.59 Estimation of
N4SID method: Estimation
(top) and validation (bottom)
The greatly different orders of magnitude of the estimated parameters deserves a
remark. It must be realized that the parameters multiply regressors variables which,
in this case, are usually nonlinear. A large average value of a variable that appears to
the cubic power will require a much smaller parameter value to compensate. For all
the models in this brief, the contribution of each term multiplied by the respective
parameter is of the same order of magnitude. One way of avoiding this situation
is to normalize the data. This was not done in this brief in order to maintain the
engineering units and therefore to facilitate a physical interpretation of the simulated
data.
References
1. Aguirre, L.A.: A nonlinear correlation function for selecting the delay time in dynamical re-
constructions. Phys. Lett. 203A(2, 3), 88–94 (1995)
2. Aguirre, L.A., Donoso-Garcia, P.F., Santos-Filho, R.: Use of a priori information in the iden-
tiﬁcation of global nonlinear models—A case study using a buck converter. IEEE Trans. Cir-
cuits Syst. I, Reg. Pap. 47(7), 1081–1085 (2000)
3. Aguirre, L.A., Barroso, M.F.S., Saldanha, R.R., Mendes, E.M.A.M.: Imposing steady-state
performance on identiﬁed nonlinear polynomial models by means of constrained parameter
estimation. Proc. IEE Part D: Control Theory Appl. 151(2), 174–179 (2004)

214
4
Applications I
4. Aguirre, L.A., Coelho, M.C.S., Corrêa, M.V.: On the interpretation and practice of dynami-
cal differences between Hammerstein and Wiener models. Proc. IEE Part D: Control Theory
Appl. 152(4), 349–356 (2005)
5. Astrom, K.J., Eykhoff, P.: System identiﬁcation—A survey. Automatica 7(2), 123–162 (1971)
6. Baker, J.E.: Reducing bias and inefﬁciency in the selection algorithm. In: Proc. 2nd Int. Conf.
Genetic Algorithms Genetic Algorithms Their Appl., Mahwah, NJ, pp. 14–21. Lawrence Erl-
baum Associates, Inc. (1987)
7. Barbosa, B.H.: Instrumentation, modelling, control and supervision of a hydraulic pumping
system and turbine–generator module (in Portuguese). Master’s thesis, Sch. Elect. Eng., Fed-
eral Univ. Minas Gerais, Belo Horizonte, Brazil (2006)
8. Box, G.E.P., Jenkins, G.M.: Time Series Analysis, Forecasting and Control. Holden-Day, San
Francisco (1970)
9. Elkaim, G.H.: System identiﬁcation for precision control of a wing-sailed GPS-guided cata-
maran. Ph.D. dissertation, Stanford University (December 2001)
10. Evans, J., Elkaim, G., Lo, S., Parkinson, B.: System identiﬁcation of an autonomous aircraft
using GPS. In: ION Global Positioning System Conference, pp. 1065–1074 (1997)
11. Juang, J.N.: Applied System Identiﬁcation. Prentice Hall, New York (1994)
12. Juang, J.N., Phan, M., Horta, L.G., Longman, R.W.: Identiﬁcation of Observer/Kalman ﬁlter
Markov parameters: Theory and experiments. In: NASA Technical Memorandum, June 1991
13. Keir, M.C.: Dynamic Modeling, Control and Fault Detection in Vapor Compression Systems,
M. Sc. Thesis, Dept. Mech. Eng., Univ. Illinois. Urbana-Champaign, Urbana, IL, 2006
14. Keir, M.C., Alleyne, A.: Feedback structures for vapor compression cycle systems. In: Proc.
American Control Conference, New York, pp. 5052–5058 (2007)
15. Ljung, L.: Systems Identiﬁcation: Theory for the User. Prentice Hall, New York (1999)
16. Piroddi, L., Spinelli, W.: An identiﬁcation algorithm for polynomial NARX models based on
simulation error minimization. Int. J. Control 76(17), 1767–1781 (2003)
17. Sjoberg, J., Zhang, Q., Ljung, L., Beneviste, A., Delyon, B., Glorennec, P., Hjalmarsson, H.,
Juditsky, A.: Nonlinear black-box modeling in system identiﬁcation: A uniﬁed overview. Au-
tomatica 31, 31–1961 (1995)
18. Skogestad, S., Postlethwaite, I.: Multivariable Feedback Control. Wiley, New York (1996)
19. Zhu, Y.: Multivariable System Identiﬁcation for Process Control. Pergamon, Lexington (2001)

Chapter 5
Nominal Control Design
5.1 Introduction
It is increasing apparent that the application of control engineering concepts and
techniques has resulted in numerous beneﬁts which manifest our life. This include,
but not restricted to, improved product/life quality, minimized waste materials, re-
duced pollution, increased safety, reduced energy consumption, to name a few. One
can observe that the notions of feedback and control play signiﬁcance roles in most
societal and technological aspects. Nowadays, it is becoming widely accepted that
control is more engineering than science, but it certainly requires a concrete theoret-
ical underpinning for it to be successfully applied to ever more challenging projects.
This will gradually help in bridging the so-called theory/practice gap.
The development of efﬁcient computer software for control has provided many
beneﬁts for teaching, research, and the development of control systems design in
industry. MATLAB and Simulink are considered the dominant software platforms
for control system analysis and design, with numerous off-the-shelf toolboxes ded-
icated to control systems and related topics. It is clear that MATLAB provides a
suitable implement for control engineering.
Feedback and control are almost everywhere. One can virtually link the power-
ful word control to almost anything, such as diet control, ﬁnancial control, motor
control, pest control, and robot control, to name a few. One can additionally say
that power is nothing without control, which is believed to be correct in both social
and technological contexts. Feedback is an intuitive means for control. For example,
when you feel cold (sensing), you add one more layer of cloth (decision and then
control action) to keep yourself warm and comfortable (objective). This is biologi-
cal feedback due to a change in the environment. In technological systems, the loop
sensing-feedback-decision-control is implemented to change the system behavior
into a desirable one. In most cases in this book, we shall focus on the “feedback
control” for a given system described by ordinary differential equations (ODEs)
with a single input–single output (SISO). More speciﬁcally, we will mainly concen-
trate on analytical and simulation methods for linear feedback control systems and a
few aspects of simulation for nonlinear systems. For multiple input–multiple output
(MIMO) linear systems, good references are [2, 3, 6, 7, 10, 11, 16, 39].
M.S. Mahmoud, Y. Xia, Applied Control Systems Design,
DOI 10.1007/978-1-4471-2879-3_5, © Springer-Verlag London Limited 2012
215

216
5
Nominal Control Design
Fig. 5.1 Standard
representation
Fig. 5.2 Linear feedback
system
Figure 5.1 shows a typical feedback control structure with three blocks, namely,
the plant block, the controller block, and the feedback block. In this typical feedback
control structure, the plant and the controller blocks form the forward path and the
feedback path normally includes the sensor and, possibly, signal conditioning. This
system structure is quite commonly seen in process control and other control ap-
plications. For simplicity, throughout the book only the paths with negative actions
will be labeled in the block diagram, and the ones with positive actions will have the
plus sign omitted by default, as in Fig. 5.1. If all three blocks are linear, the feedback
control structure can be redrawn, as shown in Fig. 5.2. This model structure will be
extensively used in the book.
In control systems, the concept of “feedback” is very important. If we assume
that there is no feedback path, the system will be driven solely by the input signal,
and after the effect of the control block, the output signal of the system will be gen-
erated. This kind of system structure is usually referred to as an open-loop control
structure. Under ideal circumstances, an open-loop control strategy will work, but
this is based on having an accurate plant model, which never exists in practice due to
modeling errors and system disturbances. Thus, for accurate control a closed-loop
system structure must be used instead. Closed-loop systems are often referred to as
feedback control systems.
5.1.1 Basic Deﬁnitions
Among the prevailing trends is that engineering is concerned with understanding
and controlling the materials and forces of nature for the beneﬁt of humankind. In
our way to address control systems, we provide in the following some essential
deﬁnitions:
Systems: A system is a combination of components that act together and perform
a prescribed objective. It must be noted that a system is not limited to physical ones,
rather the concept of system can be equally applied to abstract, dynamic phenomena
such as those encountered in economics, biology and the like.

5.1
Introduction
217
Control Systems: A control system is an interconnection of components form-
ing a system conﬁguration that will provide a desired system response. It must be
recorded that the basis for analysis of a system is the foundation provided by lin-
ear system theory, which emerges from the representation of individual elements
as a cause-effect relationship. This asserts the notion that a system transforms or
processes the input signal to provide an output signal.
Systems: A system is a combination of components that act together and perform
a prescribed objective. It must be noted that a system is not limited to physical ones,
rather the concept of system can be equally applied to abstract, dynamic phenomena
such as those encountered in economics, biology and the like.
Control Systems: A control system is an interconnection of components form-
ing a system conﬁguration that will provide a desired system response. It must be
recorded that the basis for analysis of a system is the foundation provided by lin-
ear system theory, which emerges from the representation of individual elements
as a cause-effect relationship. This asserts the notion that a system transforms or
processes the input signal to provide an output signal.
Plants: A plant may be a piece of equipment or any physical object, perhaps just
a set of machine parts connecting together, the purpose of which is to perform a
particular operation. An alternative phrase to the plant is process.
For the purpose of this book, a component or process to be controlled can be
represented by a single block, as shown in Fig. 5.2.
Controlled Variable: The controlled variable is a quantity or condition that is
measured and controlled. Normally, the controlled variable is the output of the sys-
tem.
Manipulated Variable: The manipulated variable is a quantity or condition that
is varied by the controller so as to affect the value of controlled variable.
Disturbances: A disturbance is a signal that tends to adversely affect the value of
the output of the system. If a disturbance is generated within the system, it is called
internal, while an external disturbance is generated outside the system and hence,
treated as an additional input.
Feedback Control: Feedback control refers to an operation that, in the presence
of disturbances, tends to reduce the difference between the output of a system some
reference input.
In what follows, we discuss some of the basic conﬁgurations usually encountered
in control systems.
5.1.2 Feedback Control Systems
Simply stated, a feedback control system refers to a conﬁguration that maintains
a prescribed relationship between the output and the reference input by comparing
them and using the difference in generating a control. Typically in room-temperature
system, the actual room temperature is measured and compared with the desired
(reference) temperature. Based on the temperature difference, the thermostat turns
the heating or cooling equipment on or off so as to keep the room temperature at a
comfortable level irrespective of the surrounding conditions.

218
5
Nominal Control Design
Fig. 5.3 Open-loop system
Fig. 5.4 Closed-loop system
5.1.3 Open-Loop Control Systems
An open-loop control system utilizes a controller and an actuator to control the
process and obtain the desired response without feedback, see Fig. 5.3. Obviously,
the use of open-loop control systems is severely limited in practice.
5.1.4 Closed-Loop Control Systems
In contrast to open-loop control system, a closed-loop control system depicted in
Fig. 5.4 uses an additional measure (feedback signal) of the actual output in order to
compare the actual output with the desired output response (reference or command).
For obvious reasons, a closed-loop control system is frequently labeled as feedback
control system. Thus, a feedback control system tends to maintain a prescribed re-
lationship of a system variable to another variable by comparing functions of these
variables and utilizing the difference as a means of control.
It is fair to admit feedback control is nowadays a fundamental fact of modern
industry and society. Several numerous examples in textbooks [2, 6, 9–11, 16, 39]
emphasize this fact and illuminate the properties of feedback control systems.
5.1.5 Control Systems Design
Engineering design is the central task of the engineer. It is a complex process in
which both creativity and analysis play major roles. Design is the process of con-
ceiving or inventing the forms, parts, and details of a system to achieve a speciﬁed

5.1
Introduction
219
purpose. Design activity can be thought of as planning for the emergence of a partic-
ular product or system. Design is an innovative act whereby the engineer creatively
uses knowledge and materials to specify the shape, function, and material content
of a system.
An important factor in realistic design is the limitation of time. Design takes
place under imposed schedules, and we eventually settle for a design that may be
less than ideal but considered “good enough.” In many cases, time-is the only com-
petitive advantage. A major challenge for the designer is writing the speciﬁcations
for the technical product. Speciﬁcations are statements that explicitly state what the
device or product is to be and do. The design of technical systems aims to pro-
vide appropriate design speciﬁcations and rests on four characteristics: complexity,
trade-offs, design gaps, and risk. Complexity, trade-off, gaps, and risk are inherent
in designing new systems and devices. Although they can be minimized by consid-
ering all the effects of a given design, they are always present in the design process.
Design is a process that may proceed in many directions before the desired one
is found. It is a deliberate process by which a designer creates something new in
response to a recognized need while recognizing realistic constraints. The design
process is inherently iterative-we must start somewhere! Successful engineers learn
to simplify complex systems appropriately for design and analysis purposes. A gap
between the complex physical system and the design model is inevitable. Design
gaps are intrinsic in the progression from the initial concept to the ﬁnal product.
We know intuitively that it is easier to improve an initial concept incrementally than
to try to create a ﬁnal design at the start. In this respect, engineering design is not
a linear process. It is an iterative, nonlinear, creative process. The design process
consists of [10, 11, 30]:
1. establishing the system goals,
2. identifying the variables that we desire to control,
3. writing the speciﬁcations in terms of the accuracy we must attain, like good reg-
ulation against disturbances, desirable responses to commands, realistic actuator
signals, low sensitivities, and robustness.
Brieﬂy stated, the controller design problem is as follows: Given a model of the
system to be controlled (including its sensors and actuators) and a set of design
goals, ﬁnd a suitable controller, or determine that none exists. As with most of
engineering design, the design of a feedback control system is an iterative and non-
linear process. A successful designer must consider the underlying physics of the
plant under control, the control design strategy, the controller design architecture.
In practice, solving a control problem generally involves
• Choosing sensors to measure the plant output.
• Choosing actuators to drive the plant.
• Developing the plant, actuator, and sensor equations (models).
• Designing the controller based on the models developed and the control criteria.
• Evaluating the design analytically, by simulation, and ﬁnally, by testing the phys-
ical system.
• If the physical tests are unsatisfactory, iterating the foregoing steps.

220
5
Nominal Control Design
5.1.6 Standard Representations
Broadly speaking, for systems control there are three major steps, that is, modeling,
analysis and design, also known as the mad process. If one is given a system to
control, one probably has to go through this “mad” process or loop to achieve a
satisfactory control performance. The structure of this book follows a similar mad
process. For a systematic analysis and design of a control system, mathematical
models of the components are usually required. For linear system models (both
continuous-time and discrete-time), there are usually four kinds of mathematical
models, namely, the transfer function model, the zero-pole-gain model, the block
diagram model and more generally the state space model which will be the central
theme of this book.
For a class of linear time-invariant (LTI) systems, the state space model is de-
scribed by
˙x(t) = Ax(t) + Bu(t),
y(t) = Cx(t) + Du(t)
(5.1)
for continuous-time case with t being the continuous-time instant and
˙x(k + 1) = Ax(k) + Bu(k),
y(k) = Cx(k) + Du(k)
(5.2)
for discrete-time case with k being the discrete-time instant. In (5.1) and (5.2),
x(.) ∈ℜn, u(.) ∈ℜm and y(.) ∈ℜp are the state, the input and the output vectors,
respectively. The corresponding transfer function matrix T (.) from u to y, obtained
by Laplace transform of (5.1)–(5.2) at zero-initial condition, is given by
T (r) = C(rI −A)−1B + D
(5.3)
where r = s in the continuous-time case and r = z in the discrete-time case. One
possible phrase to both (5.1)–(5.3) is the realization {A,B,C,D}. An alternative
short notation is
⎡
⎢⎣
A
···
B
...
...
...
C
···
D
⎤
⎥⎦= C(sI −A)−1B + D.
(5.4)
5.2 Basic Properties
Before embarking on the different methods for feedback control design, the goal of
this section is to consider the basic structural properties of linear MIMO systems
and explore how the feedback action affects them. For more elaborate mathematical
treatment, the reader is advised to consult [16, 44, 47, 52, 54].

5.2
Basic Properties
221
5.2.1 Stability
Consider the continuous system (5.1) with u ≡0, it is easy to show that
x(t) = eA(t−to)x(to)
= Φ(t,to)x(to)
(5.5)
where to is the initial time and Φ(t,to) is often called the continuous state-transition
matrix. For the discrete system (5.2) with u ≡0, it is easy to show that
x(k) = Ak−kox(ko)
= Φ(k,ko)x(ko)
(5.6)
where ko is the initial discrete-instant and Φ(k,ko) is often called the discrete state-
transition matrix.
By virtue of the Cayley–Hamilton theorem, see the Appendix, that Φ(t,to) or
Φ(k,ko) can be expressed as polynomial in A. Then by Frobenius’ theorem, see the
Appendix, the eigenvalue αi of Φ(.,.) are related to the eigenvalues λi of matrix A
by
αi =
eλi(t−to)
Continuous-time,
λk
i
Discrete-time
(5.7)
for the continuous-time and discrete-time cases, respectively. Letting the eigenvalue
λi = βi ± jωi, it is a simple task to express the stability criteria for linear constant
systems as follows:
Continuous-time: ˙x(t) = Ax(t)
• If βi > 0 for any simple root or βi ≥0 for any repeated root,
• If βi ≤0 for all simple roots and βi < 0 for all repeated root,
• If βi < 0 for all roots.
Discrete-time: x(k + 1) = Ax(k)
• If |λi| > 1 for any simple root or |λi| ≥1 for any repeated root,
• If |λi| ≤1 for all simple roots and |λi| < 1 for all repeated root,
• If |λi| < 1 for all roots.
On the other hand, it is readily seen that the origin 0 is an equilibrium point since
˙x ≡0, or x(k + 1) = x(k) yields xe = 0.
In case of MIMO systems, Lyapunov stability theory provides a powerful tool
for system analysis and design. The basic theory makes use of a Lyapunov function
V (x). This scalar function of the state x may be thought of as a generalized en-
ergy. A single-valued function V (x) which is continuous and has continuous partial
derivatives is said to be positive deﬁnite is some region Ω about the origin of the
state space if
1. V (0) = 0,
2. V (x) > 0 for all nonzero x ∈Ω.

222
5
Nominal Control Design
If condition 2) is relaxed to V (x) ≥0 for all nonzero x ∈Ω, then V (x) is said to be
positive semideﬁnite. The Lyapunov function V (x) is not unique; rather, many dif-
ferent Lyapunov functions may be found for a given system. Likewise, the inability
to ﬁnd a satisfactory Lyapunov function does not mean that the system is unstable.
The basic Lyapunov stability theory is phrased as follows:
Theorem 5.1 If a positive-deﬁnite function V (x) can be found such that
1. V (x) > 0, ∀x ̸= 0 and V (0) = 0,
2. Either ˙V (x) < 0 ∀x ̸= 0 for the continuous-time case and
3. ΔV (x) < 0 ∀x ̸= 0 for the discrete-time case
then the origin 0 is asymptotically stable.
5.2.2 Controllability
Controllability is a property of the coupling between the input and the state, and
thus involves the matrices A and B.
Deﬁnition 5.2 A linear system is said to be controllable at time to if it is possible to
ﬁnd some input function (or sequence in the discrete case) u(t) deﬁned over t ∈ℑ,
which will transfer the initial state x(to) to the origin at some ﬁnite time t1 ∈ℑ,
T1 > to. That is there is some input u[to,t1], which gives x(t1) = 0 at a ﬁnite t1 ∈ℑ. If
this is true for all initial time to and all initial states x(to), the system is completely
controllable.
As we see later, the full signiﬁcance of controllability is realized in the course
of feedback design. It will be seen there that if a linear system is controllable, it
is possible to design a linear state feedback control law that will give arbitrarily
speciﬁed closed-loop eigenvalues. Thus, an unstable system can be stabilized, a
slow system can be speeded up, the natural frequencies can be changed, and so on,
if the system is controllable. The existence of solutions to certain optimal control
problems can be assured if the system is controllable.
A controllability criterion is stated below.
Deﬁnition 5.3 A linear time-invariant (LTI) system with realization A, B, C, D is
completely controllable if and only if the n × nm matrix
Pc :=
	
B ... AB ... A2B ... ··· ··· ... An−1B

has rank n.
The form of the foregoing condition is exactly the same for both continuous and
discrete-time systems.

5.2
Basic Properties
223
5.2.3 Control Example 5.1
Consider the continuous system
A =
⎡
⎣
−2
−2
0
0
0
1
0
−3
−4
⎤
⎦,
B =
⎡
⎣
1
0
−0
1
−1
1
⎤
⎦.
Simple computations yield
Pc =
⎡
⎢⎢⎢⎣
−1
0
...
−2
−2
...
2
2
0
1
...
1
1
...
−4
−7
1
1
...
−4
−7
...
13
25
⎤
⎥⎥⎥⎦.
Since the determinant of the ﬁrst three columns is nonzero (= −3), it means that the
rank of Pc is 3. Therefore, this system is completely controllable.
5.2.4 Observability
Observability is a property of the coupling between the state and the output and thus
involves the matrices A and C.
Deﬁnition 5.4 A linear system is said to be observable at time to if x(to) can be
determined from the output function y[to,t1] (or output sequence) for to ∈ℑ, to ≤t1,
where t1 is some ﬁnite time belonging to ℑ. If this is true for all initial time to and
all initial states x(to), the system is completely controllable.
Clearly the observability of a system will be a major requirement in ﬁltering and
state estimation or reconstruction problems. In many feedback control problems, the
controller must use output variables y rather than the state vector x in forming the
feedback signals. If the system is observable, then y contains sufﬁcient information
about the internal states so that most of the power of state feedback can still be
realized.
An observability criterion is stated below.
Deﬁnition 5.5 A linear time-invariant (LTI) system with realization A, B, C, D is
completely observable if and only if the n × np matrix
Po :=
	
Ct ... AtCt ... A2tCt ... ··· ··· ... An−1tCt
has rank n.
The form of the foregoing condition is exactly the same for both continuous and
discrete-time systems.

224
5
Nominal Control Design
5.2.5 Control Example 5.2
Consider the continuous system
A =
0
1
8
−2

,
C =
	4
1
.
Simple computations yield
Po =
⎡
⎣4
...
8
1
...
2
⎤
⎦.
Since the second column is twice the ﬁrst, rank of Po is 1 < 2, it implies that this
system is not completely observable.
5.2.6 Control Example 5.3
The roll-angle dynamics of an aircraft is described by the state model
˙x =
⎡
⎣
˙θ
˙ω
˙τ
⎤
⎦=
⎡
⎣
0
1
0
0
−0.875
−20
0
0
−50
⎤
⎦
⎡
⎣
θ
ω
τ
⎤
⎦+
⎡
⎣
0
0
50
⎤
⎦u,
y =
1
0
0
0
1
0
⎡
⎣
θ
ω
τ
⎤
⎦.
Simple computations yield
Pc =
⎡
⎣
0
0
−1000
0
−1000
50875
50
−2500
125000
⎤
⎦,
Po =
⎡
⎢⎢⎢⎢⎢⎢⎣
1
0
0
0
1
0
0
1
0
0
−0.875
−20
0
−0.875
−20
0
0.7656
1017.5
⎤
⎥⎥⎥⎥⎥⎥⎦
.
Both matrices have rank 3 so the system is both completely controllable and observ-
able. Note that the eigenvalues of the A matrix are {0,−0.875,−50} so the system
is not asymptotically stable.
5.2.7 Important Notes
One primary reason for feedback control systems design is to stabilize systems that
may be unstable. Although our earlier results show that a reachable but unstable
system can have its state controlled by appropriate choice of control input, these
results were obtained under some critical assumptions:

5.3
State Feedback
225
1. the control must be unrestricted (as our reachability results assumed the control
could be chosen freely);
2. the system must be accurately described (that is, we must have an accurate model
of it);
3. the initial state must be accurately known.
The trouble with unstable systems is that they are unforgiving when assumptions
such as the above do not hold. Even if the ﬁrst assumption above is assumed to hold,
there will undoubtedly be modeling errors, such as improperly modeled dynamics
or incompletely modeled disturbances (thus, violating the second assumption). And
even if we assume that the dynamics are accurately modeled, the initial state of the
system is unlikely to be known precisely (violating the third assumption). It is thus
clear that we need ongoing feedback of information about the state of the system, in
order to have a hope of stabilizing an unstable system. Feedback can also improve
the performance of a stable system. We shall come to understand these issues better
over the remaining sections. How, then, can we design feedback controllers that
stabilize a given system (or plant—the word used to describe the system that we
are interested in controlling)? To answer this, we have to address the issues of what
kind of feedback variables are available for our controller. There are, in general, two
types of feedback:
• state feedback;
• output feedback.
With state feedback, all of the state variables (for example, x) of a system are
available for use by the controller, whereas with output feedback, a set of output are
available y. The state feedback problem is easier than the output feedback one, and
richer in the sense that we can do more with control. In the following section, we
examine eigenvalue placement by state feedback. All our discussion here will be for
the case of a known LTI plant. The issue of uncertainty and unmodeled dynamics
should be dealt with in previous subsequent chapters; namely. Our development in
this section will use the notation of continuous-time (CT) systems—but there is no
essential difference for the discrete-time (DT) case.
5.3 State Feedback
In the case of state feedback in Fig. 5.5, we measure all of the state variables. Thus
the plant speciﬁcation is (A;B;I;0) we omit the direct-feed through matrix, D,
for simplicity, because including it would introduce only notational complications,
without changing any conclusions. Our plant speciﬁcation implies that the output
equation is simply y = x. In many applications, direct measurement of all system
state variables is either impossible or impractical. We address the important topic of
output feedback a little later in this section.

226
5
Nominal Control Design
Fig. 5.5 Block diagram of state feedback
5.3.1 Introduction
For now, let us examine state feedback in further detail. Let our control, u, be spec-
iﬁed by u = Kx + v, where K is a constant matrix, and v is an external input. This
corresponds to LTI state feedback. Combining this control law with the state-space
description for our nth-order plant, namely,
δx = Ax + Bu,
y = C
(5.8)
we ﬁnd that the closed-loop dynamics are described by
δx = (A + BK)x + Bv
(5.9)
where we adopt the notation
δx =
 ˙x
for CT systems,
x(k + 1)
for DT systems.
(5.10)
As is apparent from (5.9), the closed-loop system is stable if and only if the eigen-
values of A + BK are all in the stable region. In other words, K stabilizes this
system if and only if
λ(A + BK) ⊂
open left half of the complex plane in continuous-time,
open unit disc in discrete-time,
(5.11)
where λ(A+BK) is the spectrum (set of eigenvalues) of (A+BK). It is interesting
to ask: Can K be chosen so that the eigenvalues of (A+ BK) are placed at arbitrary
desired locations? The answer is provided by the following theorem.
Theorem 5.6 (Eigenvalue placement) There exists a matrix K such that
det

λI −[A + BK]

=
n

i=1
(λ −μi)
(5.12)
for any arbitrary self-conjugate set of complex numbers μ1,...,μn ∈C if and only
if (A;B) is reachable.
The proof of this theorem can be found in [30].

5.3
State Feedback
227
5.3.2 Control Example 5.4
In what follows, we consider the case of constant input disturbances and integral
feedback. Suppose that in our model we have a constant, but unknown, disturbance
vector w,
˙x(t) = Ax(t) + Bu(t) + w,
x(0) = x0,
y(t) = Cx(t).
If we use state feedback, u(t) = −Kx(t), to stabilize the original system, then the
presence of w will yield a nonzero steady-state value. This can be reduced by in-
creasing K, but this has limits, because of saturation and noise effects.
A reasonable approach might be to attempt to at least estimate the unknown w in
some fashion and use this estimate to cancel out the disturbance. Here we may note
that the effects of constant disturbance vectors can often be eliminated by using the
so-called integral-error feedback. Thus, introduce an additional state variable
˙q(t) = y(t)
and use the feedback
u(t) = −Kx(t) −Kqq(t).
The augmented closed-loop system is
 ˙x(t)
˙q(t)

=
A −BK
−BKq
C
0
x(t)
q(t)

+
w
0

and if {K,Kq} are chosen to make this system stable, then the steady-state value of
y(·) will be zero, since the second equation gives 0 = Cx(∞) = y(∞).
It is worth noting that the steady-state error (or bias) has been brought to zero
without any knowledge of the disturbance w. We should note that by using a com-
mand input vd in addition to integral feedback we can obtain a desired nonzero set
point [that is, a desired value of y(∞)].
Some remarks are in order.
Remark 5.7 Suppose {A,b} is controllable and we make a change of state variables
such that T −1b = b = [b1 0 ··· 0]′, say and T −1AT = ¯A, where
¯A =
A11
A12
A21
A22

and A11 is a scalar. It can be veriﬁed that {A22,A21} is controllable.
Remark 5.8 It can be shown that the relative order of a linear system, which is
deﬁned as the difference between the degrees of the denominator and numerator
polynomials of its transfer function, is not affected by state-variable feedback.
Remark 5.9 Let b(s)/a(s) be an irreducible transfer function, and write a(s)ξ(s) =
u(s), y(s) = b(s)ξ(s).

228
5
Nominal Control Design
• The knowledge of ξ(·) and its derivatives completely determines the state vari-
ables of any minimal realization of b(s)/a(s). Therefore, ξ(s) is often called the
partial state of the system.
• A constant state-feedback corresponds to polynomial feedback of the partial state
ξ(·) : v(s) = u(s) −g(s)ξ(s) for some polynomial g(s) of degree less than or
equal to n −1. Such feedback the new transfer function is b(s)/[a(s) + g(s)].
Let us now consider an illustrative example.
5.3.3 Control Example 5.5
As a typical example, consider the act of balancing, say, a pointer on your ﬁngertip
as in Fig. 5.6. Let us assume that the bottom end of the pointer is moving along
the x axis, with your input u(t) being the acceleration of this point: u(t) = ξ(t).
The length of the stick is L; assume that its mass m is concentrated at the top end.
Suppose ϕ is small (so that sin ϕ ≈ϕ and cosϕ ≈1). A force from your ﬁngertip
can be applied only in the direction of the stick. Therefore, by equating the forces
acting, vertically (no acceleration along the vertical axis), we get mg = F , and the
force component acting in the x direction is
mgϕ(t) = Fx(t) = m¨x(t)
while the center of gravity has the x coordinate given by
x(t) = ξ(t) + Lϕ(t).
Considering the balancing as a dynamical system with input u(.) (the acceleration
of ﬁngertip in the x direction) and output y(t) = ϕ(t) (the angle of the stick to the
vertical).
To proceed further, we introduce z1 = ϕ(t), z2 = ˙ϕ(t) as state variables. It is not
difﬁcult to show that gϕ(t) = ¨ξ(t) + L ¨ϕ(t), which in turn yields the state model
˙z(t)A =
 0
1
g/L
0

+
 0
−1
 ¨ξ
L,
y(t) =
	1
0
z(t).
Let
u =
¨ξ
L
be the normalized input. It is easy to see that the characteristic polynomial is
a(s) = s2 −g
L
and the associated transfer function
H(s) =
−1
(s2 −g
L).

5.3
State Feedback
229
Fig. 5.6 Balancing a pointer
Checking the structural properties, it is found that
Pc =
 0
−1
−1
0

,
Po =
1
0
0
1

so the system is controllable and observable. The system eigenvalues are at ±

g
L
so the system is unstable.
Introducing
u(t) = −Ky(t) =
	−K
0
z(t)
we get a new system that has eigenvalues at ±

1 + g
L. However, there is a positive
eigenvalue and the system remains understandable under constant output feedback.
Alternatively, setting K = [K1 K2] and seek to position the closed-loop eigen-
values at −1,−1. A straightforward application of Ackermann yields
K1 = g
L −1,
K2 = −2.
The following example provides an interesting extension of the foregoing
paradigm.
5.3.4 Control Example 5.6
For a system driven by a constant unknown disturbance w, design an observer to
estimate w, and use this to compensate for the disturbance. We have
˙x = Ax + bu + bw,
˙w = 0,
y = cx
where u is the control input and y the observed output. The constant disturbance
w is modeled as the output of an undriven integrator. We then have the augmented
system shown in Fig. 5.7. If now we had an estimate ˆw of w, we could set u = −ˆw
to attempt to cancel out the disturbance. This motivates us to set up an observer to
estimate w.

230
5
Nominal Control Design
Fig. 5.7 Augmented system
Fig. 5.8 Integral feedback
An observer for the augmented system is given by
 ˙ˆx
˙ˆw

=
A
b
0
0
 ˆx
ˆw

+
b
0

u + l(y −c ˆx),
ˆx(0) = 0,
ˆw(0) = 0
where l is an (n + 1) × 1 vector. Partitioning l as [l′
1 l′
2]′, with l2 a scalar, we get
 ˙ˆx
˙ˆw

=
A −l1c
b
−l2c
0
 ˆx
ˆw

+
b
0

u +
l1
l2

y.
The observer structure is then as shown in Fig. 5.8. Now if the augmented system
is observable, we can choose l so as to obtain arbitrary error decay modes and thus
ensure that ˆw approaches w asymptotically. Let us temporarily ignore the question
of observability
We also make a particular choice of ℓas [0 →ℓ2], which will simplify the ob-
server design considerably; for the moment we shall not worry about whether this
can still ensure that the error-decay modes are stable. Now, on setting u = −ˆw, our
observer equation reduces to
 ˙ˆx
˙ˆw

=
 A
0
−l2c
0
 ˆx
ˆw

+
 0
ℓ2

y,
ˆx(0) = 0,
ˆw(0) = 0.

5.3
State Feedback
231
Fig. 5.9 Observer-based
feedback controller
Since the equation for ˆx is undriven and the initial condition is zero, we have ˆx ≡0,
and our observer is simply
˙ˆw = ℓ2y,
ˆw(0) = 0.
The resulting overall compensation scheme is shown in Fig. 5.9 (where the dashed
lines indicate parts that drop out of the compensator).
The result of the above procedure is thus precisely the technique that was pre-
sented earlier for compensation of constant unknown disturbances, namely integral
feedback, see Fig. 5.8. It arises here in a more natural and motivated manner. The
question we have so far avoided is whether proper choice of ℓ2 can ensure that ˆw
approaches w.
Our earlier observer equation shows that the observer error behavior is deter-
mined by the roots of
α(s) = det
sI −A
−b
l2c
s

= det(sI −A) = det
	
s + l2c(sI −A)−b

= sa(s) + l2b(s) = 0.
We assume now that the original system {A,b,c} was stable (or stabilized) and
hence that a(s) is stable, i.e., has roots with strictly negative real parts. It can then
be shown that proper choice of ℓ2 can give stable α(s) if and only if b(s) has no
root at origin.
5.3.5 Control Example 5.7
A passive feedback control system does not use any external power source for sens-
ing, error detection, ampliﬁcation, or actuation. Only the energy available in the

232
5
Nominal Control Design
Fig. 5.10 Liquid-level regulator system
input to each and every component of the system is used to produce its output. A
conceptual design of a passive mechanical-feedback system for regulating the liq-
uid level in a tank is shown in Fig. 5.10. Here, q1e, q2e and he are the constant
equilibrium values. Let q1, q2, and h denote the deviations from their equilibrium
values and qd be a disturbance ﬂow. In steady-state equilibrium, q1e = q2e, qd = 0,
and he is a constant. The control system is a regulator whose purpose is to main-
tain the head of the liquid equal to its desired or reference value he when there is a
disturbance ﬂow qd Obtain its linear mathematical model. A change h in the liquid
level is sensed by a ﬂoat that is connected by a mechanical lever to a control valve.
A turn screw in the ﬂoat-lever mechanism is used to change the length L when a
change hr in the set point corresponding to the desired level he is required. Here,
we assume that hr = 0, that is, there is no change in the desired value of he. If the
head increases by h, the valve moves an amount z and reduces the ﬂow to the tank
and vice versa. For small displacements, the valve displacement z is related to the
ﬂoat displacement h by
z = a
b h
(5.13)
where a and b are the lever lengths shown in Fig. 5.10. For a small deviation, the
linearized equation for the ﬂow control valve is given by
q1 = −c1z
(5.14)
where c1 > 0. The negative sign in (5.14) indicates that when z increases, the ﬂow
q1 decreases and vice versa. The continuity equation for the tank yields
q1 + qd −q2 = Adh
dt
(5.15)

5.3
State Feedback
233
where A is the tank cross-sectional area and the outﬂow q2 is obtained as q2 =
(ρg/R)h. Here, R is the hydraulic resistance of the outlet oriﬁce. Deﬁning a time
constant τ1 = AR/ρg, then (5.15) becomes
q1 + qd = ρg
R (τ1s + 1)h.
(5.16)
The block diagram is obtained from (5.12), (5.14), and (5.16) and shown in
Fig. 5.11(top). Letting k1 = ac1/b, the block diagram of Fig. 5.11(top) can be ex-
pressed as shown in Fig. 5.11(bottom), where hr which is the reference or desired
change in the liquid level, has been set to zero and −h becomes the error. When
modeling a regulator, we can represent all variables as deviations from the equilib-
rium state that is required to be maintained in the presence of disturbances. When
the set point is not changed, the reference input is then set to zero.
For this system, which is of ﬁrst order, we choose one state variable x = h. From
Fig. 5.11, we obtain
(τ1s + 1)x = R
ρg (q1 + qd)
i.e.,
˙x = −
 1
τ1

x +
 R
ρgτ1

q1 +
 R
ρgτ1

qd
(5.17)
and
q1 = −k1x.
(5.18)
We note that (5.17) can also be obtained directly from (5.16) and (5.18) from (5.13)
and (5.14) with k1 as deﬁned in the preceding. On comparing (5.17) and (5.18) to
the generic equations (5.1)–(5.3), we note that x = h, u = q1, v = qd, r = hr = 0,
and y = h. Also, A, B, B1K, and C are scalars and are given by
A = −1/τ1,
B = R/ρgτ1,
B1 = R/ρgτ1,
K = k1,
C = 1.
The state equation for the closed-loop system is obtained by substituting for the
control law from (5.18) in (5.17) as
˙x = −1
τ1

1 + Rk1
ρg

x +
 R
ρgτ1

qd
(5.19)
where the scalar A −BK of (5.9) becomes
A −BK = −1
τ1

1 + Rk1
ρg

.
(5.20)
In case the set point is changed, that is, the desired change in the liquid level hr
is not zero, the control law becomes q1 = k1(hr −h) and (5.19) is modiﬁed to
˙x = −1
τ1

1 + Rk
ρg

x +
 Rk1
ρgτ1

hr +
 R
ρgr1

qd.
(5.21)
It will be seen later on that this control law, where q1 is proportional to the error,
does not possess a good disturbance-rejection property. The closed-loop transfer

234
5
Nominal Control Design
Fig. 5.11 (Top) Block diagram, and (bottom) standard block diagram
functions relating the output h(s) to the command input hr(s) and the disturbance
qd can be obtained as:
H(s) =

k1R/ρg
τ1s + 1 + k1R/ρg

hr(s) +

R/ρg
τ1s + 1 + k1R/ρg

qd(s).
(5.22)
5.3.6 Control Example 5.8
In a class of mechanical, passive, feedback control systems, a boom is modeled as
a uniform beam of length L and is held in a bearing at its lower end. A passive
regulator is to be designed to maintain the boom in its vertical, unstable equilibrium
position. The conceptual design uses a spring as a sensor and actuator as shown
in Fig. 5.12(bottom). Obtain its linear mathematical model. A freebody diagram of
the system is shown in Fig. 5.12(bottom). It is assumed that for small θ, the spring
displacement is Lθ, the spring constant is k, that there is a viscous friction torque at
the bearing with coefﬁcient c, and Td is the disturbance torque. The mass moment
of inertia of the beam about the bearing is (l/3)mL2. Taking moments about the
bearing, we obtain
Td + mg L
2 sin(θ) −c ˙θ −kL2θ = 1
3mL2 ¨θ.
(5.23)
For small θ, sin(θ) ≈θ and it follows from (5.23) that
1
3mL2s2 + cs −1
2mgL

θ = −kL2θ + Td.
(5.24)
Note that the left-hand side of (5.24) represents the system to be controlled and on
the right-hand side, u = −kL2θ, is the control law produced by the spring. Fig-
ure 5.13 depicts a block diagram of (5.24) where θr is the command or desired
change in the angular position. It is set to zero and thus −θ represents the error.

5.3
State Feedback
235
Fig. 5.12 (Top) A passive
regulator, and (bottom) its
freebody diagram
Fig. 5.13 Block diagram of the control system
Choosing x1 = θ and x2 = ˙θ as the state variables, we represent (5.24) in the
form
˙x1 = x2,
(5.25)
˙x2 = 3g
2Lx1 −3c
mL2 x2 +
3
mL2 u +
3
mL2 Td,
u = −kL2θ,
(5.26)
y = x1

236
5
Nominal Control Design
which has the standard state model with
A =
 0
1
3g
2L
−3c
mL2

,
B =
 0
3
mL2

,
E =
 0
3
mL2

,
K =
	
KL2
0

,
C =
	
1
0

.
(5.27)
Hence, the closed-loop matrix is given by
A −BK =

0
1
3g
2L −3K
m
−3c
mL2

,
det[sI −A + BK] = s2 +
 3c
mL2

s −3g
2L + 3K
m
(5.28)
and the associated transfer function relating the output θ to the disturbance torque
Td is given by
Gd(s) =
3
mL2
s2 + ( 3c
mL2 )s −3g
2L + 3K
m
.
(5.29)
Some relevant comments are:
1. In the case that the pair (A;B) is not reachable, then the reachable modes, and
only these, can be changed by state feedback.
2. The pair (A;B) is said to be stabilizable if its unreachable modes are all stable,
because in this case, and only in this case, K can be selected to change the
location of all unstable modes to stable locations.
3. Despite what the theorem says we can do, there are good practical reasons why
one might temper the application of the theorem. Attempting to make the closed-
loop dynamics very fast generally requires large K, and hence large control
effort—but in practice there are limits to how much control can be exercised.
Furthermore, unmodeled dynamics could lead to instability if we got too ambi-
tious with our feedback.
As we shall see later, the linear-quadratic regulator or LQR formulation of the
controller problem for linear systems uses an integral-square (that is quadratic)
cost criterion to pose a compromise between the desire to bring the state to zero
and the desire to limit control effort. In the LTI case, and with the integral extend-
ing over an inﬁnite time interval, the optimal control turns out to be precisely an
LTI state feedback. The solution of the LQR problem for this case enables com-
putation of the optimal feedback gain matrix K∗(most commonly through the
solution of an algebraic Riccati equation).
4. State feedback cannot change reachability, but it can affect observability—either
destroying it or creating it.
5. State feedback can change the poles of an LTI system, but does not affect the
zeros (unless the feedback happens to induce unobservability, in which case what
has occurred is that a pole has been shifted to exactly cancel a zero). Note that, if
the open-loop and closed-loop descriptions are minimal, then their transmission

5.3
State Feedback
237
zeros are precisely the values of s where their respective system matrices drop
rank. These system matrices are related by a nonsingular transformation
sI −(A + BK)
−B
C
0

=
sI −A
−B
C
0
 I
0
K
I

.
(5.30)
Hence, the closed-loop and open-loop zeros are identical.
The main purpose of state feedback is to relocate the open loop eigenvalues to
pre-determined locations in the s-plane by using some pole placement methods. In
control design, placing poles is desirable objective subject to the controllability of
the pair (A,B) because the location of the poles (equivalently the eigenvalues of
the system) has some effective relations to the characteristics of the response of the
system.
Then the poles of the open loop system are the roots of the characteristic equation
given by
|sI −A| = 0.
Full state feedback is utilized by expressing the input vector u in the linear form
u = Kx.
Substituting into the state space model, we get the closed-loop system
˙x = [A −B ∗K]x,
y = [A −D ∗K]x.
(5.31)
The closed-loop eigenvalues system are the roots of the characteristic equation,
det
	
sI −(A −BK)

= 0.
(5.32)
Comparing the terms of (5.32) with those of the desired characteristic equation
yields the elements of the feedback matrix K which force the closed-loop eigen-
values to the pole locations speciﬁed by the desired characteristic equation.
5.3.7 Control Example 5.9
A cart of mass M slides on a frictionless surface. The cart is pulled by a force u(t).
On the cart a pendulum of mass m is attached via a frictionless hinge, as shown in
Fig. 5.14. The pendulum’s center of mass is located at a distance l from either end.
The moment of inertia of the pendulum about its center of mass is denoted by I. The
position of the center of mass of the cart is at a distance s(t) from a reference point.
The angle θ(t) is the angle that the pendulum makes with respect to the vertical axis
which is assumed to increase clockwise.
First, we write the equations of motion that result from the free-body diagram of
the cart. The vertical forces P , R and Mg balance out. For the horizontal forces, we
have the following equation
M ¨s = u −N.
(5.33)

238
5
Nominal Control Design
Fig. 5.14 Inverted pendulum
From the free-body diagram of the pendulum, the balance of forces in the hori-
zontal direction gives the equation
m d2
dt2

s + ℓsin(θ)

= N,
m d
dt

˙s + ℓcos(θ) ˙θ

= N,
(5.34)
m

¨s −l sin(θ)( ˙θ)2 + ℓcos(θ) ¨θ

= N
and the balance of forces in the vertical direction gives the equation
m d2
dt2

ℓcos(θ)

= P −mg,
m d
dt

−ℓsin(θ) ˙θ

= P −mg,
(5.35)
m

−l cos(θ)( ˙θ)2 −ℓsin(θ) ¨θ

= P −mg.
Finally by balancing the moments around the center of mass, we get
I ¨θ = Pℓsin(θ) −Nℓcos(θ).
(5.36)
From (5.33) and (5.34), we can eliminate the force N to obtain
(M + m)¨s + m

ℓcos(θ) ¨θ −ℓsin(θ)( ˙θ)2
= u.
(5.37)
Substituting (5.34) and (5.35) into (5.36) gives us
I ¨θ = ℓ

mg −mℓcos(θ)( ˙θ)2 −mℓsin(θ) ¨θ

sin(θ)
−ℓ

m¨s −mℓsin(θ)( ˙θ)2 + mℓcos(θ) ¨θ

cos(θ).

5.3
State Feedback
239
Simplifying the above expression yields

I + mℓ2 ¨θ = mgℓsin(θ) −mℓ¨s cos(θ).
(5.38)
The equations that describe the system are (5.37) and (5.38). We can have a further
simpliﬁcation of the system of equations by removing the term ¨θ from (5.37), and
the term ¨s from (5.38). Deﬁne the constants
Mt = M + m,
L = I + mℓ2
mℓ
.
Substituting ¨θ from (5.38) into (5.37), we get

1 −mℓ
MtL cos(θ)2

¨s + mℓ
MtLg sin(θ)cos(θ) −mℓ
MtL sin(θ)( ˙θ)2 = 1
Mt
u.
(5.39)
Similarly we can substitute ¨s from (5.37) into (5.38) to get

1 −mℓ
MtL cos(θ)2

¨θ −g
L sin(θ) + mℓ
MtL sin(θ)cos(θ)( ˙θ)2 = −
1
MtL cos(θ)u.
(5.40)
These are nonlinear equations due to the presence of the terms sin(θ), cos(θ), and
( ˙θ)2. We can linearize these equations around θ = 0 and ˙θ = 0, by assuming that
θ(t) and ˙θ(t) remain small. Recall that for small θ
sin(θ) ≈θ −1
6θ3,
cos(θ) ≈1 −1
2θ2,
and using these relations we can linearize (5.39) and (5.40). The linearized system
of equations take the form

1 −mℓ
MtL

¨s + mℓ
MtL
g
Lθ = 1
Mt
u,

1 −mℓ
MtL

¨θ −g
Lθ = −
1
MtLu.
Choose the following state variables x = [s ˙s θ ˙θ ]t, to write a state space model
for the invert ed pendulum. Using these state variables, the following state space
model can be easily obtained
d
dt
⎡
⎢⎢⎣
x1
x2
x3
x4
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
0
1
0
0
0
0
−α mℓ
MtLg
0
0
0
0
1
0
0
α g
L
0
⎤
⎥⎥⎦
⎡
⎢⎢⎣
x1
x2
x3
x4
⎤
⎥⎥⎦+
⎡
⎢⎢⎣
0
α
Mt
0
−
α
LMt
⎤
⎥⎥⎦u,
y =
	1
0
0
x,
where the constant α is given by
α =
1
(1 −mℓ
MtL)
.

240
5
Nominal Control Design
Intuitively it is clear that the equilibrium point [s = const, ˙s = 0, θ = 0, ˙θ = 0] is an
unstable equilibrium point. To verify this, we compute the eigenvalues of the matrix
A by solving the equation det(λI −A). The eigenvalues are

0
0
αq
L
−
αq
L

.
Therefore we have two eigenvalues at the jω axis and one eigenvalue in the open
right half of the complex plane, which indicates instability.
Consider the case where M = 2 kg, m = 0.1 kg, l = 0.5 m, I = 0.025 kg m2, and
of course g = 9.8 m/s2. Assume that we can directly measure the state variables, s,
˙s, θ and ˙θ. We want to design a feedback control law u = F ˆx + r to stabilize this
system. In order to do that, we will choose a feedback matrix F to place the poles
of the closed-loop system at {−1,−1,−3,−3}. Using Ackermann’s formula
F = −
	
0
0
0
1

R−1
n αd(A)
where αd(λ) = (λ + 1)(λ + 1)(λ + 3)(λ + 3) which is the polynomial whose roots
are the desired new pole locations, and Rn is the reachability matrix. In speciﬁc
using the parameters of the problem, we have
F = −[0
0
0
1]
⎡
⎢⎢⎣
0
0.4878
0
0.1166
0.4878
0
0.1166
0
0
−0.4878
0
−4.8971
0.4878
0
−4.8971
0
⎤
⎥⎥⎦
−1
×
⎡
⎢⎢⎣
9.0
24.0
−7.7
−1.9
0
9.0
−24.9
−7.7
0
0
330.6
104.3
0
0
1047.2
330.6
⎤
⎥⎥⎦
=
	1.8827
5.0204
67.5627
21.4204
.
The closed-loop system is given by
d
dt
⎡
⎢⎢⎣
x1
x2
x3
x4
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
0
1.0
0
0
0.9184
2.449
32.7184
10.449
0
0
0
1.0
−0.9184
−2.4490
−22.9184
−10.4490
⎤
⎥⎥⎦
⎡
⎢⎢⎣
x1
x2
x3
x4
⎤
⎥⎥⎦
+
⎡
⎢⎢⎣
0
0.4878
0
−0.4878
⎤
⎥⎥⎦r.
In Fig. 5.15, we show the time trajectories of the closed-loop linearized system when
the reference input r(t) is identically zero and the initial angular displacement of
the pendulum is 1.0 radians. In this simulation, the initial conditions on all the other
state variables are zero.

5.3
State Feedback
241
Fig. 5.15 Plot of state variables of the closed-loop linearized system
We can also look at the performance of this controller if it is applied to the nonlin-
ear system. In this case, we should simulate the dynamics of the following nonlinear
system of equations
d
dt
⎡
⎢⎢⎣
x1
x2
x3
x4
⎤
⎥⎥⎦=
⎡
⎢⎢⎢⎣
x2
−mlg
MtL
1
α(x3) sin(x3)cos(x3) + ml
Mt
1
α(x3) sin(x3)(x4)2
x4
q
L
1
α(x3) sin(x3) −
ml
MtL
1
α(x3) sin(x3)cos(x3)(x4)2
⎤
⎥⎥⎥⎦
+
⎡
⎢⎢⎣
0
1
Mt
1
α(x3)
0
1
MtL
cos(x3)
α(x3)
⎤
⎥⎥⎦u,
u =
	1.8827
5.0204
67.5627
21.4204
⎡
⎢⎢⎣
x1
x2
x3
x4
⎤
⎥⎥⎦+ r,
where α(x3) is deﬁned as
α(x3) =

1 −ml
MtL cos(x3)2

.
In Fig. 5.16, we show the time trajectories of the nonlinear closed-loop system when
the reference input r(t) is identically zero and the initial angular displacement of

242
5
Nominal Control Design
Fig. 5.16 Plot of state variables of the nonlinear closed-loop system
the pendulum is 1.0 radians. In this simulation, the initial conditions on all the other
state variables are zero.
5.3.8 State-Feedback in MATLAB
Invoking the MATLAB software, we could apply the command
K = place(A,B,V )
to determine the feedback matrix gain K where V is the set of desired eigenvalues.
5.4 Observer-Based Feedback
When some or all of the state-variables are not accessible for measurements, we
use an alternative method based on estimating the states. Thus, in observer-based
feedback it is required to construct a device or system that generates a good replica
of the state, see Fig. 5.17.
5.4.1 Basics
Considering the plant itself, the close-loop dynamics is expressed as
˙x = Ax + Bu = Ax + B(K ˆx + υ) = Ax + BK ˆx + Bυ.

5.4
Observer-Based Feedback
243
Fig. 5.17 Block diagram of observer-based feedback
In addition, the observer equation is
˙ˆx = (A −LC)ˆx + (B −LD)u + Ly
= (A −LC)ˆx + (B −LD)(K ˆx + υ) + L(Cx + Du)
=
	
A −LC + (B −LD)K

ˆx + (B −LD)υ + LCx + LD(K ˆx + υ)
=
	
A −LC + (B −LD)K + LDK

ˆx + LCx + [B −LD + LD]υ
= [A −LC + BK]ˆx + LCx + Bυ.
The two systems together are written in augmented state space form as:
 ˙x
˙ˆx

=
 A
BK
LC
A −LC + BK
x
ˆx

+
B
B

υ.
(5.41)
Now to design a controller, we consider a state space system of the form
˙x = Ax + Bu,
y = Cx + Du.
Let us choose V1 as it was in the state feedback case, and V2 as the desired eigen-
values for the observer. Subject to the structural properties (controllability of the
pair (A,B) and observability of the pair (A,C)), the separation theorem holds, and
therefore we could apply the foregoing MATLAB command in two separate stages:
K = place(A,B,V1),
L = place

At,Ct,V2

.

244
5
Nominal Control Design
5.4.2 Control Example 5.10
The longitudinal motion of a ﬂexible bombor aircraft [1] is conventionally modeled
as a second-order short-period mode, a second-order fuselage bending mode, and
two ﬁrst-order control control-surface actuators. The sixth-order system is described
by the following LTI representation:
A =
⎡
⎢⎢⎢⎢⎢⎢⎣
0.4158
1.025
−0.00267
−0.0001106
−0.08021
0
−5.5
−0.8302
−0.06549
−0.0039
−5.115
0.809
0
0
0
1.0
0
0
−1040
−78.35
−34.83
−0.6214
−865.6
−631
0
0
0
0
−75
0
0
0
0
0
0
−100
⎤
⎥⎥⎥⎥⎥⎥⎦
,
B =
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
0
0
0
0
75
0
0
100
⎤
⎥⎥⎥⎥⎥⎥⎦
,
Ct =
⎡
⎢⎢⎢⎢⎢⎢⎣
−1491
0
−146.43
1
140.2
0
−0.9412
0
−1285
0
−564.66
0
⎤
⎥⎥⎥⎥⎥⎥⎦
.
The inputs are the desired elevator deﬂection (rad), u1(t), and the desired canard de-
ﬂection (rad), u2(t), while the outputs are the sensor location’s normal acceleration
m/s2, y1(t), and the pitch-rate (rad/s), y2(t).
Testing the system controllability and observability using MATLAB indicates
that the system is fully controllable and fully observable. This means that it is easy
to place any of it’s eigenvalues into new desired position. Using MATLAB code
place, the desired poles of the system will placed to three different desired position.
The parameter γ will be used to multiply the location of the poles. The desired poles
deﬁned as:
P = γ ∗
	−1 + 1i
−1 −1i
−2 + 2i
−2 −2i
−3
−4
.
(5.42)
The parameter γ will be selected as 10, 20, and 30. More far the location of the poles
to the left side will yields different response of the system. From Fig. 5.18, it can be
seen that desired poles with large magnitude yields more stable and nonoscillatory
closed-loop system.
An observer-based state feedback controller will now be considered. The state-
feedback gain K obtained from the foregoing pole-placement method. Once again,
three sets of pole positions will be selected. The parameters that is used for this
selection is the multiplier α.
Pobs = α ∗
	−1 + 1i
−1 −1i
−2 + 2i
−2 −2i
−3
−4
.
(5.43)
The step response of the closed-loop system is shown in Figs. 5.19–5.22, which is
the response is very different between the selected poles position. The more far the
poles located, the system faster to become stable, but the overshoot is become very
large.

5.4
Observer-Based Feedback
245
Fig. 5.18 Pole-placement state feedback with different γ
Fig. 5.19 Observer-based
controller (Input 1–Output 1)
with different α
5.4.3 Control Example 5.11
A linearized mathematical model for a direct expansion (DX) A/C system was de-
scribed in [48], where it is shown that the physical system consists of six states, two
inputs and two outputs. The model was developed to be able to capture the transient
characteristics of the DX A/C system. A simpliﬁed schematic of the model is shown
in Fig. 5.23. The system matrices A, B, C are as follows:

246
5
Nominal Control Design
Fig. 5.20 Observer-based
controller (Input 1–Output 2)
with different α
Fig. 5.21 Observer-based
controller (Input 2–Output 1)
with different α
A =
⎡
⎢⎢⎢⎢⎢⎢⎣
−2.731
0
0.0756
1.1883
0.5287
5.287
0.0045
−0.0045
0
0
0
0
0
2.6577
−1.692
2.0346
0
0
0.0139
0.067
0.0206
−0.0412
0
0
0.016
0
0
0
0
0
0
0
0
0
0.0145
−0.045
⎤
⎥⎥⎥⎥⎥⎥⎦
,
B =
⎡
⎢⎢⎢⎢⎢⎢⎣
0.035
0
−0.098
0
2.5
0
0
−1.931
0
0
−0.3
0
⎤
⎥⎥⎥⎥⎥⎥⎦
,
Ct =
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
1
0
0
0
0
0
0
0
0
1
⎤
⎥⎥⎥⎥⎥⎥⎦
.
We initially observe that the A/C system is controllable and observable. For the
purpose of designing observer-based controller, we select one eigenvalue set at

5.4
Observer-Based Feedback
247
Fig. 5.22 Observer-based
controller (Input 2–Output 2)
with different α
Fig. 5.23 Air-conditioning block-diagram
V 1 = [−0.05
−0.26
−0.28
−0.3
−1.6
−2.8] and using the MATLAB
command K = place(A,B,V 1) to yield the state-gain matrix
K =
−0.0236
2.1293
−0.3942
0.5250
−2.2973
−0.8044
−0.0280
15.3401
0.2643
−0.8959
−17.7654
−6.3900

.
Then selecting another eigenvalue set at V 2 = [−0.15 −0.8 −1.3 −2.9 −3.6 −4.8]
and using the MATLAB command L = place(At,Ct,V 2) to yield the observer-gain
matrix
L =
 49.6
4.6
−379.52
497.6
86.2
8
307.5
7
1084.7
478.1
193.8
4.5

.

248
5
Nominal Control Design
Fig. 5.24 State trajectories under observer-based control
The resulting state trajectories under observer-based feedback control are plotted in
Fig. 5.24.
5.5 Classiﬁcations of Industrial Controllers
Industrial controllers may be classiﬁed according to their control actions as:
• Two-position or on off controllers.
• Proportional controllers.
• Integral controllers.
• Proportional-plus-integral controllers.
• Proportional-plus-derivative controllers.
• Proportional-plus-integral-plus-derivative controllers.
Most industrial controllers [1, 8, 19, 24, 27, 35, 59] use electricity or pressurized
ﬂuid such as oil or air as power sources. Consequently, controllers may also be clas-
siﬁed according to the kind of power employed in the operation, such as pneumatic
controllers, hydraulic controllers, or electronic controllers. What kind of controller
to use must be decided based on the nature of the plant and the operating condi-
tions, including such considerations as safety, cost, availability, reliability, accuracy,
weight, and size.

5.5
Classiﬁcations of Industrial Controllers
249
Fig. 5.25 (Top) Block
diagram of an on–off
controller; (Bottom) Block
diagram of an on–off
controller with differential
gap
5.5.1 Two-Position Control Action
In a two-position (on–off) control system, the actuating element has only two ﬁxed
positions, which are, in many cases, simply on and off. Two-position or on–off con-
trol is relatively simple and inexpensive and, for this reason, is very widely used in
both industrial and domestic control systems.
Let the output signal from the controller be u(t) and the actuating error signal be
e(t). In two-position control, the signal u(t) remains at either a maximum or mini-
mum value, depending on whether the actuating error signal is positive or negative,
so that
u(t) = U1,
for e(t) > 0,
= U2,
for e(t) < 0
where U1 and U2 are constants. The minimum value U2 is usually either zero
or −U1. Two-position controllers are generally electrical devices, and an electric
solenoid-operated valve is widely used in such controllers. Pneumatic proportional
controllers with very high gains act as two-position controllers and are sometimes
called pneumatic two-position controllers.
Figures 5.25(top) and 5.25(bottom) show the block diagrams for two-position or
on–off controllers. The range through which the actuating error signal must move
before the switching occurs is called the differential gap. A differential gap is in-
dicated in Figs. 5.25(bottom). Such a differential gap causes the controller output
u(t) to maintain its present value until the actuating error signal has moved slightly
beyond the zero value. In some cases, the differential gap is a result of unintentional
friction and lost motion; however, quite often it is intentionally provided in order to
prevent too frequent operation of the on–off mechanism.
Consider the liquid-level control system shown in Fig. 5.26(top), where the elec-
tromagnetic valve shown in Fig. 5.26(bottom) is used for controlling the inﬂow rate.
This valve is either open or closed. With this two-position control, the water inﬂow
rate is either a positive constant or zero. As shown in Fig. 5.27, the output signal
continuously moves between the two limits required to cause the actuating element
to move from one ﬁxed position to the other. Notice that the output curve follows
one of two exponential curves, one corresponding to the ﬁlling curve and the other to

250
5
Nominal Control Design
Fig. 5.26 (Top) Liquid-level
control system;
(Bottom) Electromagnetic
valve
Fig. 5.27 Level h(t) versus ℓ
curve
the emptying curve. Such output oscillation between two limits is atypical response
characteristic of a system under two position control.
From Fig. 5.27, we notice that the amplitude of the output oscillation can be re-
duced by decreasing the differential gap. The decrease in the differential gap, how-
ever, increases the number of on–off switchings per minute and reduces the useful
life of the component 2% be magnitude of the differential gap must be determined
from such considerations as the accuracy required and the life of the component.
5.5.2 P-Control Action
For a controller with proportional (P) control action, the relationship between the
output of the controller u(t) and the actuating error signal e(t) is

5.5
Classiﬁcations of Industrial Controllers
251
u(t) = Kpe(t)
or, in Laplace-transformed quantities,
U(s)
E(s) = Kp
where Kp is termed the proportional gain.
5.5.3 Integral Control Action
In a controller with integral control action, the value of the controller output u(t) is
changed at a rate proportional to the actuating error signal e(t). That is,
du(t)
dt
= Kie(t)
or
u(t) = Ki
 t
0
e(t)dt
where Ki is an adjustable constant. The transfer function of the integral controller
is
U(s)
E(s) = Ki
s .
5.5.4 PI Control Action
The control action of a proportional-plus-integral (PI) controller is deﬁned by
u(t) = Kpe(t) + Kp
T1
 t
0
e(t)dt
or the transfer function of the controller is
U(s)
E(s) = Kp

1 + 1
T1s

where T1 is called the integral time.
5.5.5 PD Control Action
The control action of a proportional-plus-derivative (PD) controller is deﬁned by
u(t) = Kpe(t) + KpTd
de(t)
dt

252
5
Nominal Control Design
Fig. 5.28 Block diagram of a
PID controller
and the transfer function is
U(s)
E(s) = Kp(1 + Tds)
where Td is called the derivative time.
5.5.6 PID Control Action
The combination of proportional (P) control action, integral (I) control action, and
derivative (D) control action is termed proportional-plus-integral-plus-derivative
(PID) control action. This combined action has the advantages of each of the three
individual control actions. The equation of a controller with this combined action is
given by
u(t) = Kpe(t) + Kp
T1
 t
0
e(t)dt + KpTd
de(t)
dt
or the transfer function is
U(s)
E(s) = Kp

1 + 1
T1s + Tds

where Kp is the proportional gain, T1 is the integral time, and Td is the derivative
time. The block diagram of a proportional-plus-integral-plus-derivative controller is
shown in Fig. 5.28.
5.6 Closed-Loop System Subjected to a Disturbance
In what follows, we discuss the performance of control system when subjected to
external disturbances. Reference is made to Fig. 5.29 where a closed-loop system
subjected to a disturbance is shown.
When two inputs (the reference input and disturbance) are present in a linear
system, each input can be treated independently of the other; and the outputs cor-
responding to each input alone can be added to give the complete output. The way
each input is introduced into the system is shown at the summing point by either a
plus or minus sign.

5.6
Closed-Loop System Subjected to a Disturbance
253
Fig. 5.29 Closed-loop system subjected to a disturbance
5.6.1 Main Issues
Consider the system shown in Fig. 5.29. In examining the effect of the disturbance
D(s), we may assume that the reference input is zero; we may then calculate the
response CD(s) to the disturbance only. This response can be found from
CD(s)
D(s) =
G2(s)
1 + G1(s)G2(s)H(s).
On the other hand, in considering the response to the reference input R(s), we may
assume that the disturbance is zero. Then the response CR(s) to the reference input
R(s) can be obtained from
CR(s)
R(s) =
G1(s)G2(s)
1 + G1(s)G2(s)H(s).
The response to the simultaneous application of the reference input and disturbance
can be obtained by adding the two individual responses. In other words, the response
C(s) due to the simultaneous application of the reference input R(s) and disturbance
D(s) is given by
C(s) = CR(s) + CD(s)
=
G2(s)
1 + G1(s)G2(s)H(s)
	
G1(s)R(s) + D(s)

.
Consider now the case where |G1(s)H(s)| ≫1 and |G1(s)G2(s)H(s)| ≫1. In this
case, the closed-loop transfer function CD(s)/D(s) becomes almost zero, and the
effect of the disturbance is suppressed. This is an advantage of the closed-loop sys-
tem.
On the other hand, the closed-loop transfer function CR(s)/R(s) approaches
1/H(s)
as
the
gain
of
G1(s)G2(s)H(s)
increases.
This
means
that
if
|G1(s)G2(s)H(s)| ≫1 then the closed-loop transfer function CR(s)/R(s) becomes
independent of G1(s) and G2(s) and becomes inversely proportional to H(s) so that
the variations of G1(s) and G2(s) do not affect the closed-loop transfer function
CR(s)/R(s). This is another advantage of the closed-loop system. It can easily be
seen that any closed-loop system with unity feedback, H(s) = 1, tends to equalize
the input and output.

254
5
Nominal Control Design
Next, we examine the important cases of control action. This includes propor-
tional-plus-integral (PI), proportional-plus-derivative (PD) and proportional-plus-
integral-plus-derivative (PID). Whatever the actual mechanism may be and what-
ever the form of the operating power, the proportional controller is essentially an
ampliﬁer with an adjustable gain.
In the proportional control of a plant whose transfer function docs not possess
an integrator 1/s, there is a steady-state error, or offset, in the response to a step
input. Such an offset can be eliminated if the integral control action is included in
the controller.
In the integral control of a plant, the control signal, the output signal from the
controller, at any instant is the area under the actuating error signal curve up to that
instant. The control signal u(t) can have a nonzero value when the actuating error
signal e(t) is zero, as shown in Fig. 5.30(top). This is impossible in the case of the
proportional controller since a nonzero control signal requires a nonzero actuating
error signal. (A nonzero actuating error signal at steady state means that there is au
offset.) Figure 5.30(bottom) shows the curve e(t) versus t and the corresponding
curve u(t) versus t when the controller is of the proportional type.
Note that integral control action, while removing offset or steady-state error, may
lead to oscillatory response of slowly decreasing amplitude or even increasing am-
plitude, both of which arc usually undesirable.
5.6.2 P-Control of Systems
In what follows, we will show that the proportional control of a system without an
integrator will result in a steady-state error with a step input. We shall then show
that such an error can be eliminated if integral control action is included in the
controller.
Consider the system shown in Fig. 5.31. Let us obtain the steady-state error in
the unit-step response of the system. Deﬁne
G(s) =
K
T s + 1.
Since
E(s)
R(s) = R(s) −C(s)
R(s)
= 1 −C(s)
R(s) =
1
1 + G(s)
the error E(s) is given by
E(s) =
1
1 + G(s)R(s) =
1
1 +
K
T s+1
R(s).
For the unit-step input R(s) = 1/s, we have
E(s) =
T s + 1
T s + 1 + Ks
1
s .

5.6
Closed-Loop System Subjected to a Disturbance
255
Fig. 5.30 Plots of e(t) and
u(t) curves: (Top) integral
control; (Bottom)
proportional control
Fig. 5.31 Control system with a torque disturbance
The steady-state error is
ess = lim
t→∞e(t) = lim
s→0E(s) = lim
s→0
T s + 1
T s + 1 + K =
1
K + 1.
Such a system without an integrator in the feedforward path always has a steady-
state error in the step response. Such a steady-state error is called an offset. Fig-
ure 5.32 shows the unit-step response and the offset.

256
5
Nominal Control Design
Fig. 5.32 Unit-step response
and offset
Fig. 5.33 Integral control
system
5.6.3 I-Control of Systems
Consider the system shown in Fig. 5.33. The controller is an integral controller. The
closed-loop transfer function of the system is
C(s)
R(s) =
K
s(T s + 1) + k .
Hence,
E(s)
R(s) = R(s) −C(s)
R(s)
=
s(T s + 1)
s(T s + 1) + k .
Since the system is stable, the steady-state error for the unit-step response can be
obtained by applying the ﬁnal-value theorem, as follows:
ess = lim
s→0E(s)
= lim
s→0
s2(T s + 1)1
T s2 + s + Ks
1
s
= 0.
Integral control of the system thus eliminates the steady-state error in the response
to the step input. This is an important improvement over the proportional control
alone, which gives offset.
5.7 Response to Torque Disturbances
Let us investigate the effect of a torque disturbance occurring at the load element
and for this purpose, consider the system shown in Fig. 5.34.

5.7
Response to Torque Disturbances
257
Fig. 5.34 PI control system
with a torque disturbance
5.7.1 P-Control
The proportional controller delivers torque T to position the load element, which
consists of moment of inertia and viscous friction. Torque disturbance is denoted
by D. Assuming that the reference input is zero or R(s) = 0, the transfer function
between C(s) and D(s) is given by
C(s)
D(s) =
1
Js2 + bs + Kp
.
Hence,
E(s)
D(s) = −C(s)
D(s) =
1
Js2 + bs + Kp
.
The steady-state error due to a step disturbance torque of magnitude Td is given
by
ess = lim
s→0E(s)
= lim
s→0
−s
Js2 + bs + Kp
Td
s
= −Td
Kp
.
At steady state, the proportional controller provides the torque −Td, which is equal
in magnitude but opposite in sign to the disturbance torque Td. The steady-state
output due to the step disturbance torque is
ess = −ess −Td
Kp
.
111e steady-state error can be reduced by increasing the value of the gain Kp. In-
creasing this value, however, will cause the system response to be more oscillatory.
5.7.2 PI-Control
To eliminate offset due to torque disturbance, the proportional controller may be
replaced by a proportional-plus-integral (PI) controller. If integral control action is
added to the controller, then, as long as there is an error signal, a torque is developed
by the controller to reduce this error, provided the control system is a stable one.

258
5
Nominal Control Design
Fig. 5.35 PI control of a load element
Figure 5.35 shows the PI control of the load element, consisting of moment of inertia
and viscous friction.
The closed-loop transfer function between C(s) and D(s) is
C(s)
D(s) =
s
Js3 + bs2 + Kps + Kp
Ti
.
In the absence of the reference input, or r(t) = 0, the error signal is obtained from
E(s) =
s
Js3 + bs2 + Kps + Kp
Ti
D(s).
If this control system is stable, that is, if the roots of the characteristic equation
Js3 + bs2 + Kps + Kp
Ti
= 0
have negative real parts, then the steady-state error in the response to a unit-step
disturbance torque can be obtained by applying the ﬁnal-value theorem as follows:
ess = lim
s→0E(s)
= lim
s→0
−s2
Js3 + bs2 + Kps + Kp
Ri
1
s
= 0.
Thus steady-state error to the step disturbance torque can be eliminated if the con-
troller is of the proportional-plus-integral type.
Note that the integral control action added to the proportional controller has con-
verted the originally second-order system to a third-order one. Hence, the control
system may become unstable for a large value of Kp since the roots of the charac-
teristic equation may have positive real parts. (The second-order system is always
stable if the coefﬁcients in the system differential equation are all positive.)
It is important to point out that if the controller were an integral controller, as
in Fig. 5.36, then the system always becomes unstable because the characteristic
equation
Js3 + bs2 + K = 0

5.7
Response to Torque Disturbances
259
Fig. 5.36 Integral control of a load element
will have roots with positive real parts. Such an unstable system cannot be used in
practice.
Note that in the system of Fig. 5.34 the proportional control action tends to stabi-
lize the system, while the integral control action tends to eliminate or reduce steady-
state error in response to various inputs.
5.7.3 D-Control Action
Derivative control action, when added to a proportional controller, provides a means
of obtaining a controller with high sensitivity. An advantage of using derivative
control action is that it responds to the rate of change of the actuating error and
can produce a signiﬁcant correction before the magnitude of the actuating error
becomes too large. Derivative control thus anticipates the actuating error, initiates
an early corrective action, and tends to increase the stability of the system.
Although derivative control does not affect the steady-state error directly, it adds
damping to the system and thus permits the use of a larger value of the gain K,
which will result in an improvement in the steady-state accuracy.
Because derivative control operates on the rate of change of the actuating error
and not the actuating error itself, this mode is never used alone. It is always used in
combination with proportional or proportional-plus-integral control action.
5.7.4 P-Control of Systems with Inertia Load
Before we discuss the effect of derivative control action on system performance, it
is convenient to consider the proportional control of an inertia load.
Consider the system shown in Fig. 5.37(top). The closed-loop transfer function
is obtained as
C(s)
R(s) =
Kp
Js2 + Kp
.
Since the roots of the characteristic equation

260
5
Nominal Control Design
Fig. 5.37 (Top) Proportional
control of a system with
inertia load; (Bottom)
Response to a unit-step input
Fig. 5.38 (Top) PD control
of a system with inertia load;
(Bottom) Response to a
unit-step input
Js2 + Kp = 0
are imaginary, the response to a unit-step input continues to oscillate indeﬁnitely, as
shown in Fig. 5.38(bottom).
Control systems exhibiting such response characteristics arc not desirable. We
will note in the sequel that the addition of derivative control will stabilize the system.
5.7.5 PD-Control of a System with Inertia Load
Let us modify the proportional controller to a proportional-plus-derivative controller
whose transfer function is Kp(1 + Tds). The torque developed by the controller is
proportional to Kp(e+Td ˙e). Derivative control is essentially anticipatory, measures
the instantaneous error velocity, and predicts the large overshoot ahead of time and
produces an appropriate counteraction before too large an overshoot occurs.
Consider the system shown in Fig. 5.38(top). The closed-loop transfer function
is given by
C(s)
R(s) =
Kp(1 + Tf s)
Js2 + KpTds + Kp
.
The characteristic equation
Js2 + KpTds + Kp = 0

5.7
Response to Torque Disturbances
261
Fig. 5.39 A control system
now has two roots with negative real parts for positive values of J , Kp, and Td.
Thus, derivative control introduces a damping effect. A typical response curve c(t)
to a unit-step input is shown in Fig. 5.38(bottom). Clearly, the response curve shows
a marked improvement over the original response curve shown in Fig. 5.38(bottom).
5.7.6 PD-Control of Second-Order Systems
A compromise between acceptable transient-response behavior and acceptable
steady-state behavior may be achieved by use of proportional-plus-derivative con-
trol action.
Consider the system shown in Fig. 5.39. The closed-loop transfer function is
C(s)
R(s) =
Kp + Kds
Js2 + (B + Kd)s + Kp
.
The steady-state error for a unit-ramp input is
ess = B
Kp
.
The characteristic equation is
Js2 + (B + Kd)s + Kp = 0.
The effective damping coefﬁcient of this system is thus B +Kd rather than B. Since
the damping ratio ζ of this system is
ζ = B + Kd
2KpJ .
5.7.7 Control Example 5.12
We consider a mechanical liquid-level control system which incorporates a hy-
dromechanical controller that implements a PID control law, for more detailed tech-
nical discussions the reader is advised to consult [1, 19, 24, 25, 27, 29, 35, 38, 46,
48, 59]. This system is shown in Fig. 5.40. The displacement z1 is related to h by
z1 = (a1/b)h
(5.44)
and the displacement z2 of the spool valve by
z2 = (a2/b)h.
(5.45)

262
5
Nominal Control Design
Fig. 5.40 PID controller for a liquid-level control system
The load on the actuator is negligible and hence, we obtain
z6 = (k1/s)z2
and using (5.45),
z6 =
k1a2
b
 1
D

h.
(5.46)
Equating the damper force to the spring force, we get
c(˙z3 −˙z4) = kz4
or
z4 =

cs
cs + k

z3
=

τs
τs + 1
a3
b

h
(5.47)
where τ = c/k and z3 = (a3/b)h. The valve movement z is obtained as
z =

d4
d3 + d4

z5 +

d3
d3 + d4

z6
(5.48)
where
z5 =

d1
d1 + d2

z1 +

d2
d1 + d2

z4.
(5.49)

5.7
Response to Torque Disturbances
263
Fig. 5.41 Block diagram of a liquid level control system
Substituting for z5 in (5.49) from (5.49) and then using (5.44), (5.46), and (5.47),
we obtain
z =

d4
d3 + d4

d1
d1 + d2
a1
b

h +

d3
d3 + d4
k1a2
b
 1
D h
+

d4
d3 + d4

d2
d1 + d3
τa3
b

D
τD + 1

h.
(5.50)
This equation can be expressed as
z = kph
k1
D

h + kd

D
τD + 1

h
(5.51)
where the gains kp, k1 and kd are obtained by comparing the corresponding terms
in (5.50) and (5.51). The linearized equation for the ﬂow-control valve is
q1 = −cz
(5.52)
and the mathematical model of the tank has been obtained in Example 3.1. The
block diagram may now be completed as shown in Fig. 5.41.
Thus, the hydromechanical controller implements a PID control law. The time
constant T must be chosen to be small to extend the frequency range of the derivative
mode. After summing up the three control actions, we can see that the system is now
type 1. The ﬁrst order of the original system of Example 3.1 has now been raised
to the third order. Hence, two additional state variables must be deﬁned as shown in
Fig. 5.41 for the state-variables representation.
Noting that the set point has not been changed, that is, hr = 0, we obtain the state
equations as follows.
˙x1 = −
 1
τ1

x1 +
 Rc1
τ1ρg

u +
 R
τ1ρg

qd,
˙x2 = −k1x1,
˙x3 = −
 1
τ1

x3 −
kd
τ

˙x1
= −
 kd
ττ1

x1 −
1
τ

x3 −
kdRc1
ττ1ρg

u −
 kdR
ττ1ρg

qd
(5.53)
where in the last equation, we have substituted for ˙x1 from the ﬁrst equation.

264
5
Nominal Control Design
We also have
u = −kpx1 + x2 + x3.
The preceding equations can be expressed in the standard form
˙x = Ax + Bu + B1v,
u = −Kx
where
A =
⎡
⎣
−1/τ1
0
0
−k1
0
0
kd/ττ1
0
−1/τ
⎤
⎦,
B =
⎡
⎣
Rc1/τ1ρg
0
kdR/ττ1ρg
⎤
⎦.
(5.54)
The closed-loop system can now be expressed as
˙x = (A −BK)x + B1u
and its characteristic equation is given by
det|sI −A + BK| = 0.
5.8 Linear Optimal Control: Continuous-Time
In Fig. 5.42, the feedback conﬁguration for the linear quadratic regulation (LQR) is
shown where we note the negative feedback and the absence of a reference signal.
The process is assumed to be a continuous-time LTI system of the form
˙x(t) = Ax(t) + Bu(t),
x(0) = xo,
y(t) = Cx(t),
(5.55)
z(t) = Gx(t) + Hu(t),
where x(t) ∈ℜn, u(t) ∈ℜm, y(t) ∈ℜp, z(t) ∈ℜq, and it has two distinct outputs.
1. The measured output y(t) corresponds to the signal(s) that can be measured and
are therefore available for control.
2. The controlled output z(t) corresponds to the signal(s) that one would like to
make as small as possible in the shortest possible time.
Sometimes z(t) = y(t), which means that our control objective is simply to make
the measured output very small. At other times one may have
z =
y
˙y

,
(5.56)
which means that we want to make both the measured output y(t) and its deriva-
tive ˙y(t) very small. Many other options are possible. The optimal LQR problem
consists of ﬁnding the control input u(t) that minimizes
Jc =
 ∞
0
zt(t)Qz(t) + ϱut(t)Ru(t)dt,
(5.57)

5.8
Linear Optimal Control: Continuous-Time
265
Fig. 5.42 LQR conﬁguration
where Q ∈ℜq×q, R ∈ℜm×m are symmetric positive-deﬁnite matrices and ϱ is a
positive constant. The term
 ∞
0
zt(t)Qz(t)dt
corresponds to the energy of the controlled output and the term
 ∞
0
ut(t)Ru(t)dt
corresponds to the energy of the control signal. Normally in LQR one seeks a con-
troller that minimizes both energies. However, decreasing the energy of the con-
trolled output will require a large control signal, and a small control signal will lead
to large controlled outputs. The role of the constant ϱ is to establish a trade-off
between these conﬂicting goals [2, 3, 6, 7].
1. Choosing ϱ very large, the most effective way to decrease Jc is to employ a small
control input, at the expense of a large controlled output.
2. Choosing ϱ very small, the most effective way to decrease Jc is to obtain a very
small controlled output, even if this is achieved at the expense of employing a
large control input.
The most general form for a quadratic criteria is expressed by
Jo =
 ∞
0
	
xt(t)Qx(t) + ut(t)Ru(t) + 2xt(t)Nu(t)

dt.
(5.58)
It is readily seen on using z(t) = Gx(t) + Hu(t) from (5.55) that (5.57) is a special
case of (5.58) with
Q = GtQG,
R = H tQH + ϱR,
N = GtQH.
Associated with system (5.55) a functional
H

x(.);u(.)

:= −
 ∞
0
	
Ax(t) + Bu(t)

tPx(t) + xt(t)P
	
Ax(t) + Bu(t)

dt,
which when computed along a solution of the system, its value depends only on the
initial condition xo as long as
lim
t→∞x(t) = 0
where Pt = P. This implies that H(x(.);u(.)) is feedback invariant for system
(5.55). To make use of this basic property, we express (5.58) in the form

266
5
Nominal Control Design
Jo = H

x(.);u(.)

+
 ∞
0
xt(t)Qx(t) + ut(t)Ru(t) + 2xt(t)Nu(t)
+
	
Ax(t) + Bu(t)

tPx(t) + xt(t)P
	
Ax(t) + Bu(t)

dt
= H

x(.);u(.)

+
 ∞
0
xt(t)
	
PA + AtP + Q

x(t)
+ ut(t)Ru(t) + 2ut(t)
	
BtP + N t
x(t)dt.
(5.59)
By completing the squares, we have
	
u(t) + Kx(t)

tR
	
u(t) + Kx(t)

= ut(t)Ru(t) + [PB + N]R−1	
BtP + N t
x(t)
+ 2ut(t)
	
BtP + N t
x(t),
K := R−1	
BtP + N t
,
(5.60)
and therefore we express Jo into the form
Jo = H

x(.);u(.)

+
 ∞
0
xt(t)

PA + AtP + Q −[PB + N]R−1	
BtP + N t

x(t)
(5.61)
+
	
u(t) + Kx(t)

tR
	
u(t) + Kx(t)

dt.
On selecting the matrix P such that
PA + AtP + Q −[PB + N]R−1	
BtP + N t
= 0
(5.62)
the minimum of Jo is attained at
u∗(t) = −Kx(t),
K := R−1	
BtP + N t
(5.63)
for which the closed-loop system
˙x(t) =

A −BR−1	
BtP + N t

x(t)
(5.64)
is asymptotically stable and the minimum cost is J ∗
o = xt
oPxo. It must be noted that
(5.62) is called the algebraic Riccati equation (ARE).
5.8.1 Important Special Case
An important special case of the quadratic criteria (5.58) occurs when N ≡0. In
this case, the optimal gain and the associated ARE are given by

5.8
Linear Optimal Control: Continuous-Time
267
Fig. 5.43 State trajectories under LQR
K := R−1BtP,
PA + AtP + Q −PBR−1BtP = 0.
5.8.2 Control Example 5.13
The model of the longitudinal motion of a ﬂexible bomber aircraft considered ear-
lier is considered hereafter using LQR design. The design is based on MATLAB
function lqr(A,B,Q,R). Using this command, we will get feedback gain K and
the solution for Algebraic Riccati Equation. In this simulation, three different sets
of weighting matrices will be selected and the corresponding of close-loop response
will be compared. The parameter will be used to multiply the weighting of the states
is ρ, that is, Q = ρ ∗I5×5 and R = I2×2.
From Fig. 5.43, it is readily seen that the more weight we put on the states, the
states will become more damped and faster to become stable.
5.8.3 Control Example 5.14
The problem of controlling the patient blood gases with the objective of maintain-
ing these blood gases in their physiological ranges during a stable extracorporeal
circulation process is of particular interest [42]. An appropriate block diagram is
depicted in Fig. 5.44 in which the model set-up is portrayed. In terms of the state
and input variables:
• x1 is the ﬂow rate of oxygen,
• x2 is the ﬂow rate of carbon dioxide,

268
5
Nominal Control Design
Fig. 5.44 A proposed block
diagram
• x3 is the arterial partial pressure of oxygen,
• x4 is the arterial partial pressure of carbon dioxide,
• u1 is the commanded oxygen ﬂow rate and
• u2 is the commanded carbon dioxide ﬂow rate,
we consider a continuous-time state space model of the form
˙X(t) = f

X(t),U(t)

,
Y(t) = g

X(t),U(t)

(5.65)
where X(t) ∈ℜ4, U(t) ∈ℜ2, Y(t) ∈ℜ2 are the state, the control input and the
measured output vectors. Let (Xe,Ue) be the reference level of the state and control
vectors and introduce
x(t) = X(t) −Xe,
u(t) = u(t) −Ue
as the corresponding incremental variations. Applying a standard linearization pro-
cedure of (5.65) results in a linearized model that can conveniently cast into the
format
˙x(t) = Ax(t) + Bu(t),
y(t) = Cx(t)
(5.66)
where x(t) ∈ℜ4, u(t) ∈ℜ2, and y(t) ∈ℜ2 are the state, the control input and the
measured output vectors. The matrices A ∈ℜ4×4, B ∈ℜ4×2, C ∈ℜ2×4 are real
constant and describe the dynamics of blood gases during a stable extracorporeal
circulation process. In particular, the coefﬁcients of the matrices
A = ∂f (.,.)
∂X

X=Xe,U=Ue
,
B = ∂f (.,.)
∂U

X=Xe,U=Ue
depend on the conditions of the patient and their nominal values could be evalu-
ated and stored whenever needed. Using reasonable nominal data [42], the model
matrices in (5.66) are given by
A =
⎡
⎢⎢⎣
−10.045
0.002
0.003
0.001
0.001
−9.989
0.001
0.001
6.045
−3.002
−4.997
0.001
0.002
0.505
0.001
−5.002
⎤
⎥⎥⎦,
B =
⎡
⎢⎢⎣
10
0
0
10
0
0
0
0
⎤
⎥⎥⎦,
C =
0
0
0
1
0
0
1
0

.

5.8
Linear Optimal Control: Continuous-Time
269
Fig. 5.45 Response of arterial partial pressure of oxygen and carbon dioxide
Fig. 5.46 Input and output
response for p = 2
Thus the variables of main concern are x3 and x4. At start, we examined the re-
sponse of the blood gases model to initial impact in the arterial partial pressure of
oxygen and carbon dioxide. The result is plotted in Fig. 5.45. In order to illustrate
the application of LQR theory, we use the weighting matrices
Q = Blockdiag
	0
0
1
1
,
R = Blockdiag
	p
p
for three distinct cases: 1) p = 2, 2) p = 0.02 and 3) p = 200. The ensuing input–
output simulation results are depicted in Figs. 5.46–5.48, from which we conclude
the input and output variable settles quickly when p is small corresponding to high
feedback gain.

270
5
Nominal Control Design
Fig. 5.47 Input and output
response for p = 0.02
Fig. 5.48 Input and output
response for p = 200
5.8.4 Optimal Set-Point Control
A practical version of the LQR is the optimal set-point control, which is described
hereafter. Consider the continuous-time LTI process
˙x(t) = Ax(t) + Bu(t),
x(0) = xo,
z(t) = Gx(t) + Hu(t)
(5.67)
where x(t) ∈ℜn, u(t) ∈ℜm, z(t) ∈ℜq. We wish the controlled output z to converge
as fast as possible to a given nonzero constant set point value r, corresponding to
an equilibrium point (xe,ue) of (5.67) for which z = r. In light of the foregoing
sections, this eventually amounts to an LQR criterion of the form [18]
Js =
 ∞
0
˜zt(t) ˜Q˜z(t) + ϱ ˜ut(t) ˜R˜u(t)dt,
(5.68)
where ˜Q ∈ℜq×q, ˜R ∈ℜm×m are symmetric positive-deﬁnite matrices and ϱ is a
positive constant. In addition, ˜z := z−r, ˜u := u−ue. The equilibrium point (xe,ue)
satisﬁes
0 = Axe + Bue,
r = Gxe + Hue

5.8
Linear Optimal Control: Continuous-Time
271
which can be written compactly as
 −A
B
−G
H
−xe
ue

=
0
r

(5.69)
where the block matrix on the left has dimension (n+q)×(n+q). It must be when
the number of inputs m is strictly smaller than the number of controlled outputs q,
we have an underactuated system. In this case, the system of equations (5.69) gen-
erally does not have a solution, because it presents more equations than unknowns.
On the other hand, when the number of inputs m is equal to the number of controlled
outputs q, (5.69) always has a solution as long as the matrix
R(s) :=
sI −A
B
−G
H

is nonsingular for s = 0. R(s) is known as Rosenbrock’s system matrix [30]. A con-
sequence of this is that s = 0 should not be an invariant zero of the system (recall
that a transmission zero of a transfer matrix is always an invariant zero of its state-
space realizations), and therefore it cannot also be a transmission zero of the transfer
matrix T (s) = G(sI −A)−1B + H. One should expect problems when s = 0 is an
invariant zero of the system, since as the state x(t) converges to an equilibrium point,
the control input u(t) must converge to a constant. By the zero-blocking property,
one should then expect the controlled output z(t) to converge to zero and not to r.
It is obvious that when the number of inputs m is strictly larger than the number
of controlled outputs q, we have an overactuated system, and (5.69) generally has
multiple solutions.
Proceeding further, the optimal set point problem can be reduced to that of opti-
mal regulation by considering an auxiliary system with state ˜x := x −xe. Making
use of (5.69) with some manipulations, the dynamics of auxiliary system are ex-
pressed by
˙˜x(t) = A˜x(t) + B ˜u(t),
˜z(t) = G˜x(t) + H ˜x(t).
(5.70)
At this stage, we can regard (5.68) and (5.70) as an optimal regulation problem
for which the optimal solution is given by
˜u(t) = −K ˜x(t).
Translating this result to the original input and state variables u and x, we conclude
that the optimal control for the set-point deﬁned by (5.67) and (5.68) takes the form
u(t) = −K
	
x(t) −xe

+ ue,
t ≥0.
(5.71)
Recall that the solution of (5.69) can be expressed as
xe = Mr,
ue = Nr
for appropriately deﬁned matrices M and N, the control scheme for optimal set-
point control is depicted in Fig. 5.49.

272
5
Nominal Control Design
Fig. 5.49 Linear quadratic set point control with state-feedback
5.8.5 An LMI Formulation
With focus on the LQR design, the associated quadratic cost function is
J =
 ∞
0
	
yt(t)Qy(t) + ut(t)Ru(t)

dt
(5.72)
where 0 < Q, 0 < R are output error and control weighting matrices, which are se-
lected in the course of simulation by observing several sets of criteria of the closed
loop-system. In what follows, we present an LMI-based formulation to the LQ con-
trol of system (5.66) while minimizing the quadratic cost (5.72). We proceed to
determine a linear optimal state-feedback control u = Lx that achieves this goal.
Assume that V (x) has the form V (x) = xtK+x, K+ > 0 and satisﬁes
˙V (x) ≤−
	
xtCtQCx + utRu

.
(5.73)
Then, the linear system controlled by u is asymptotically stable and J∞≤V (xo).
With u = Lx, inequality (5.73) is equivalently expressed as
xt	
K+(A + BL) + (A + BL)tKt
+

x ≤−xt	
CtQC + LtRL

x.
(5.74)
From (5.74), it is evident that (5.73) is satisﬁed if there exists L and K+ such that
K+(A + BL) + (A + BL)tKt
+ +
	
CtQC + LtRL

≤0.
(5.75)
Moreover, instead of directly minimizing the cost xt
oK+xo, we proceed to minimize
its upper bound. Therefore, we assume that there exists γ+ > 0 such that
xt
oK+xo ≤γ+.
(5.76)
In effect, the linear optimal control problem under consideration for given γ+ can
be cast into the format
min
γ+,K+,Lγ+
subject to (5.75)–(5.76).
(5.77)
To convexify the above problem, we ﬁrst express (5.75) as
Φ = K+(A + BL) + (A + BL)tKt
+,
Π =
⎡
⎣
Φ
Ct
Lt
•
−Q−1
0
•
•
−R−1
⎤
⎦≤0.
(5.78)

5.9
Linear Optimal Control: Discrete-Time
273
Pre- and post-multiply (5.78) by diag{K−1
∗,I,I} and using Y = K−1
+ , S = LK−1
+ it
follows that (5.78) is equivalent to
⎡
⎣
(AY + BS) + (AY + BS)t
YCt
YLt
•
−R−1
0
•
•
−Q−1
⎤
⎦≤0.
(5.79)
Additionally, inequality (5.76) can be expressed as
γ+
xt
o
•
K−1
+

≥0
⇐⇒
γ+
xt
o
•
Y

≥0.
(5.80)
The minimization problem (5.77) is cast into the form
min
γ+,Y,S γ+
subject to (5.79)–(5.80).
(5.81)
When a feasible solution of problem (5.81) is attained, we get L = SY −1, K+ =
Y −1.
5.9 Linear Optimal Control: Discrete-Time
In what follows, we direct attention to the class of processes which is assumed to be
a discrete-time LTI system of the form
x(k + 1) = Ax(k) + Bu(k),
x(ko) = xo,
(5.82)
and the performance index
L(xo,u,k) =
k

j=ko+1
	
xt(j)Q(j)x(j) + ut(j −1)R(j)u(j −1)

,
(5.83)
where x(k) ∈ℜn, u(k) ∈ℜm are the state and control vectors, respectively. The
plant (5.82) is initially—that is, at time ko—in state x(ko), and the aim is to return
the plant state to the origin, or a state close to the origin. To do this, we set up a per-
formance index (5.83), in which Q(j) and R(j) are nonnegative deﬁnite symmetric
matrices. The performance index has the property that “large” values of the state
will tend to make the performance index large. Therefore, by choosing the control
sequence {u(ko),u(ko + 1),...}, which minimizes the performance index, we can
expect to achieve the desired regulator effect.
We shall ﬁrst solve the optimization problem for the case of ﬁnite horizon T .
With additional assumptions, we shall then cover the inﬁnite T case, with special
reference to time-invariant plants.
The route to a derivation of the optimal control is via the Principle of Optimality
[2]. Thus, if until time m optimal controls z{u(ko),u(ko + 1),...,u(m −1)} have
been applied, leading to a state x(m), then the remaining terms in the optimal control
sequence, {u(m),u(m + 1),...,u(T −1)} must also be optimal in the sense of
minimizing L(xo,u,k).

274
5
Nominal Control Design
Now let L∗denote the optimal performance index associated with an initial state
x(t) at time t. Then, by the Principle of Optimality
L∗
x(k),k

= min
u(k)
	
Ax(k) + Bu(k)

tQ(j + 1)x(j)
	
Ax(k) + Bu(k)

+ ut(j)R(j + 1)u(j) + L∗
Ax(k) + Bu(k),k + 1

,
= min
u(k)

ut(j)
	
BtQ(j + 1)B + R(j + 1)

u(j)
+ 2xt(j)AtQ(j + 1)Bu(j) + xt(j)AtQ(j + 1)Ax(j)
+ L∗
Ax(k) + Bu(k),k + 1

.
(5.84)
Bearing in mind the foregoing continuous-time results, it would be reasonable to
guess that L∗(x(k),k) would be of the form xt(j)P(j)x(j). Since it proves con-
venient to make use of this result almost immediately, we build into the following
argument an inductive proof of the result. For this purpose, it is required that
	
BtQ(j + 1)B + R(j)

> 0
∀j.
Proceeding further, we have
L

x(T −1),u(.),T −1

= xt(T )Q(T )x(T ) + ut(T −1)R(T )u(T −1).
(5.85)
On using (5.82), we manipulate (5.85) to reach
L

x(T −1),u(.),T −1

= xt(T −1)AtQ(T )Ax(T −1)
+ 2xt(T −1)AtQ(T )Bu(T −1)
+ ut(T −1)
	
BtQ(T )B + R(T )

u(T −1). (5.86)
It is quite evident that the control u∗(T −1) that minimizes this performance index
is a linear function of x(T −1)—that is,
u∗(T −1) = K(T −1)x(T −1),
K(T −1) = −
	
BtQ(T )B + R(T )

−1BtQ(T )A.
(5.87)
Moreover, the resulting optimal index L ∗(x(T −l),T −1) becomes quadratic in
x(T −1)—that is,
L∗
x(T −I),T −1

= xt(T −1)P(T −l)x(T −1),
P(T −1) = At
Q(T ) −Q(T )B
	
BtQ(T )B
(5.88)
+ R(T )

−1BtQ(T )

A.
Our goal is to compute expressions of the matrices K(j), determining the optimal
control law, and P(j), determining the optimal performance index, for arbitrary
values of j. Building on the foregoing results, we assume that L∗(x(j+),j + 1) =

5.9
Linear Optimal Control: Discrete-Time
275
xt(j + 1)P(j + 1)x(j + 1) for a certain matrix P(j + 1). Applying the inductive
hypothesis to (5.84), we have
L∗
x(k),k

= min
u(k)

ut(j)
	
BtQ(j + 1)B + R(j + 1)

u(j)
+ 2xt(j)AtQ(j + 1)Bu(j) + xt(j)AtQ(j + 1)Ax(j)
+ xt(j)AtP(j + 1)Ax(j) + 2xt(j)AtQP(j + 1)Bu(j)
+ ut(j)BtP(j + 1)Bu(j)

.
(5.89)
Again, the minimizing u(j), which is the optimal control at time j, is a linear func-
tion of x(j),
u∗(j) = Kx(j)
(5.90)
and the optimal performance index L∗(x(j),j), resulting from use of u ∗(j), is
quadratic in x(j)—that is,
L∗
x(j),j

= xt(j)P(j)x(j).
The expression for K(j) is given by
K(j) = −
	
Bt ˆQ(j)B + R(j)

−1Bt ˆQ(j)A,
ˆQ(j) = Q(j) + P(j).
(5.91)
The expression for P(j) is
P(j) = At ˆQ(j) −ˆQ(j)B
	
Bt ˆQ(j)B + R(j)

−1Bt ˆQ(j)

A.
(5.92)
To guarantee that the optimal performance index is ﬁnite, we shall require that the
pair A, B is controllable. Recall that the forgoing equations have to be solved recur-
sively.
For inﬁnite horizon, the time-varying matrices reach steady state values leading
to the following expressions:
P+ = At	
Q+ + P+
−

Q+ + P+
B
	
Bt
Q+ + P+
B + R+
−1Bt
Q+ + P+
A,
(5.93)
K+ = −
	
Bt
Q+ + P+
B + R+
−1Bt
Q+ + P+
A
where Q+, +R+ are the steady state (constant) values of the weighting matrices
Q(j), R(j). An assumption guaranteeing asymptotic stability of the closed-loop
system
x(k + 1) =
	
A + BK+
x(k)
is that the pair (A,D) is observable where DDt = Q.

276
5
Nominal Control Design
5.9.1 An LMI Formulation
For a discrete-time LQR the linear system under consideration is described by
xk+1 = Axk + Buk,
yk = Cxk
(5.94)
where matrices A, B, C are derived from A, B, C via appropriate discretization
scheme [45]. With a performance index given by
J =
∞

k=0

xt
kQxk + ut
kRuk

.
(5.95)
In what follows, we present an LMI-based formulation to the LQ control of sys-
tem (5.94) while minimizing the quadratic cost (5.95). Our approach is basically a
discrete-version of the foregoing section. We proceed to determine a linear optimal
state-feedback control uk = Hxk that achieves this goal. Assume that V (x(k)) has
the form
V

x(k)

= xt
kK∗xk,
K∗> 0
and satisﬁes
V

x(k + 1)

−V

x(k)

≤−
	
xt
kQxk + ut
kRuk

.
(5.96)
Then, the linear system controlled by uk is asymptotically stable and J∞≤V (xo).
With uk = Hxk, inequality (5.96) is equivalently expressed as
xt
k(A + BH)tK∗(A + BH)x(k) −xt
kK∗xk ≤−xt
k
	
Q + H tRH

xk.
(5.97)
From (5.97), it is evident that (5.96) is satisﬁed if there exists H and K∗such that
(A + BH)tK∗(A + BH) −K∗+
	
Q + H tRH

≤0.
(5.98)
Moreover, instead of directly minimizing the cost xt
oK∗xo, we proceed to minimize
its upper bound. Therefore, we assume that there exists γ∗> 0 such that
xt
oK∗xo ≤γ∗.
(5.99)
In effect, the linear optimal control problem under consideration for given γ∗can be
cast into the format
min
γ∗,K∗,H γ∗
subject to (5.98)–(5.99).
(5.100)
To convexify the above problem, we ﬁrst express (5.98) as
−K∗+ tΠ−1 ≤0,
(5.101)
 =
	
(A + BH)tH tI

,
(5.102)
Π =
⎡
⎣
K−1
∗
0
0
•
R−1
0
•
•
Q−1
⎤
⎦.

5.9
Linear Optimal Control: Discrete-Time
277
By Schur complements, inequality (5.101) using (5.102) is equivalent to
⎡
⎢⎢⎣
−K∗
(A + BH)t
H t
I
•
−K−1
∗
0
0
•
•
−R−1
0
•
•
•
−Q−1
⎤
⎥⎥⎦≤0.
(5.103)
Pre- and post-multiply (5.103) by diag{K−1
∗,I,I,I} and using X = K−1
∗, Z =
HK−1
∗, it follows that (5.103) is equivalent to
⎡
⎢⎢⎣
−X
(AX + BZ)t
Zt
X
•
−X
0
0
•
•
−R−1
0
•
•
•
−Q−1
⎤
⎥⎥⎦≤0.
(5.104)
Additionally, inequality (5.99) can be expressed as
γ∗
xt
o
•
K−1
∗

≥0
⇐⇒
γ∗
xt
o
•
X

≥0.
(5.105)
The minimization problem (5.100) is cast into the form
min
γ∗,X,Z γ∗
subject to (5.104)–(5.105).
(5.106)
When a feasible solution of the convex minimization problem (5.106) is attained,
then we get
H = ZX−1,
K∗= X−1.
5.9.2 Direct Driven Inverted Pendulum
The inverted pendulum system is a standard problem in the area of control systems
and has two equilibria, one of which is stable while the other is unstable. The stable
equilibrium corresponds to a state in which the pendulum is pointing downwards,
see Fig. 5.50. In the absence of any control force, the system will naturally return to
this state. The stable equilibrium requires no control input to be achieved and, thus,
is uninteresting from a control perspective. The unstable equilibrium corresponds to
a state in which the pendulum points strictly upwards and, thus, requires a control
force to maintain this position.
The basic control objective of the inverted pendulum problem is to maintain the
unstable equilibrium position when the pendulum initially starts in an upright po-
sition. Traditionally, an inverted pendulum was driven by a rotating servo motor
which drove the cart via transfer mechanism to keep the balance of the system. The
ﬂaw of this conﬁguration was the inclusion of the transmission friction and gap in
the system. Transmission by ﬂexible belt would also produce vibration, extension,
and delay, and make the control system unpredictable. To overcome the defect of

278
5
Nominal Control Design
Fig. 5.50 Physical model of
single inverted pendulum
Fig. 5.51 Linear
synchronous motor
the inverted pendulum driven by a rotating machine, a new scheme is proposed and
named the direct driven inverted pendulum (dDIP).
The dDIP consists of a linear motor, a pendulum, a pedestal and a rotary encoder,
as shown in Fig. 5.51. The cart for inverted pendulum is attached to the mover of
the linear motor by rigid connection. In this way, the mover can directly drive the
cart to achieve linear motion without transfer mechanism.
Linear motor is a new type of driving device which can directly transform electri-
cal energy to mechanical linear motion and is called “direct transmission” or “zero
clearance transmission”. It has the advantages of high velocity, high acceleration,
high accuracy, and no maximal travel length restriction. Linear motor can be used
in industry, commercial, military and any other ﬁeld where linear motion is needed.
Linear motor can be classiﬁed into linear induction motor, linear synchronous mo-
tor etc. The motor used in our system is an ironless permanent magnet linear syn-
chronous motor. Its maximal velocity is 5 m/s; maximal acceleration is 100 m/s2;
rated thrust force is 98 N; the peak thrust force is 280 N and the stage’s resolution
is 5 µ m.
The assumptions for the modeling are as follows: (1) the pendulum and the
pedestal are both rigid bodies. (2) air resistance and friction force between pen-

5.9
Linear Optimal Control: Discrete-Time
279
dulum and the bearing are ignored. (3) the direction of the arrowhead is positive
direction of the vector.
Analyzing the physical model of the single IP, we can obtain the mathematical
expression of IP as follows:
(M + m)¨x + ml ¨θ cosθ + ml ˙θ2 sinθ = F,

I + ml2 ¨θ + ml ¨x cosθ = mgl sinθ.
While the IP is running, normally θ (radian) hardly changes at the equilibrium
point and nears zero. Therefore, small angle approximation can be made: cosθ ≈1,
sinθ ≈θ, ( dθ
dt )2 ≈0. With u representing the input force F , the expressions () can
be simpliﬁed as follows:
(M + m)¨x + mℓ¨θ = u,

I + mℓ2 ¨θ + mℓ¨x = mgℓθ.
The frequency response of the linear motor is measured by using a dynamic
signal analyzer Agilent 35670A. Agilent 35670A is a FFT type frequency spec-
trum/network analyzer with 4 channels. This standard apparatus can measure fre-
quency spectrum, network, time domain and amplitude domain in the range of 0–
100 KHz and can analyze frequency response, octave, harmonic distortion and or-
der spectrum. Agilent 35670A requires that the input is an analog signal, but the
displacement of the linear motor’s mover given by a linear encoder which has a res-
olution of 5 µ m is digital. So a TMS320F2812 DSP is used to decode and count
the digital count value into analog voltage through DAC7731. In this way, Agilent
35670A can sweep sine to the linear motor.
The pedestal of the IP was mounted on the linear motor’s mover without the
pendulum while the sweeping process was in progress thus the mass M ( including
the mass of the angle encoder) of the pedestal is taken into account. The result of
the measurement is the motor’s frequency response within 1–100 Hz. Using ﬁtting
function of MATLAB, the transfer function of the linear motor was obtained; where
the input is voltage u and the output was displacement x.
G(s) = X(s)
U(s) =
1.869
s2 + 12.32s + 0.4582.
(5.107)
Applying inverse Laplace transformation to () and the result can be expressed as:
1.869u = ¨x + 12.32˙x + 0.4582x.
(5.108)
5.9.3 Modeling of dDIP
According to (5.108), we can get:
¨x = −12.32˙x −0.4582x + 1.869u.
(5.109)

280
5
Nominal Control Design
Combining (5.106) and (5.109) we can obtain the following equation:
¨θ = 0.4582ml
I + ml2 x + 12.32ml
I + ml2 ˙x +
mgl
I + ml2 θ −1.869ml
I + ml2 u.
(5.110)
Four state variables are chosen as follows:
x1 = x,
x2 = ˙x,
x3 = θ,
x4 = ˙θ.
So the state vector is,
X =
⎡
⎢⎢⎣
x
˙x
θ
˙θ
⎤
⎥⎥⎦
(5.111)
and the state space description of the dDIP is
˙X = Ax + Bu
=
⎡
⎢⎢⎣
0
1
0
0
−0.4582
−12.32
0
0
0
0
0
1
a
b
c
0
⎤
⎥⎥⎦
⎡
⎢⎢⎣
x
˙x
θ
˙θ
⎤
⎥⎥⎦+
⎡
⎢⎢⎣
0
1.869
0
d
⎤
⎥⎥⎦u,
(5.112)
where
a = 0.4582ml
I + ml2 ,
b = 12.32ml
I + ml2 ,
c =
mgl
I + ml2 ,
d = −1.869ml
I + ml2 .
The parameters are m = 0.1 kg, l = 0.2415 m and g = 9.8 m/s2.
Choosing the outputs as follows:
y1 = x,
y2 = ˙x,
y3 = θ,
y4 = ˙θ.
So the output vector is:
Y = CX =
⎡
⎢⎢⎣
1
0
0
0
0
1
0
0
0
0
1
0
0
0
0
1
⎤
⎥⎥⎦
⎡
⎢⎢⎣
x
˙x
θ
˙θ
⎤
⎥⎥⎦.
(5.113)
5.9.4 Optimal Control of Turbo-Generator System
A basic element in power generation is the turbo-generator, that is shown in
Fig. 5.52, the dynamic model of which has six states, two inputs and two outputs
[15, 17, 21, 28].
Using appropriate data, the system matrices are given by

5.9
Linear Optimal Control: Discrete-Time
281
Fig. 5.52 Turbo-generator system: Physical and block-diagram
A =
⎡
⎢⎢⎢⎢⎢⎢⎣
−18.4456
4.2263
−2.2830
0.2260
0.4220
−0.0951
−4.0977
−6.0706
5.6825
−0.6966
−1.2246
0.2873
1.4449
1.4336
−2.6477
0.6092
0.8979
−0.2300
−0.0093
0.2302
−0.5002
−0.1764
−6.3152
0.1350
−0.0464
−0.3489
0.7238
6.3117
−0.6886
0.3645
−0.0602
−0.2361
0.2300
0.0915
−0.3214
−0.2087
⎤
⎥⎥⎥⎥⎥⎥⎦
,
B =
⎡
⎢⎢⎢⎢⎢⎢⎣
−0.2748
3.1463
−0.0501
−9.3737
−0.1550
7.4296
0.0716
−4.9176
−0.0814
−10.2648
0.0244
13.7943
⎤
⎥⎥⎥⎥⎥⎥⎦
,
Ct =
⎡
⎢⎢⎢⎢⎢⎢⎣
0.5971
3.1013
−0.7697
9.3422
4.8850
−5.6000
4.8608
−0.7490
−9.8177
2.9974
−8.8610
10.5719
⎤
⎥⎥⎥⎥⎥⎥⎦
.
The eigenvalues of the system are computed using MATLAB command line eig(A)
are given by −15.8730, −10.3872, −0.3493 ± j6.3444, −1.0444, −0.2346. All
system poles are to the left-hand side of imaginary axis of the complex plane, hence,
the system is stable.
Using the MATLAB command line: lqr(A,B,Q,R) with Q = I6, R = I2, the
optimal state-feedback gain is:
K =
−0.0077
−0.0280
−0.0916
0.0269
−0.0344
0.0261
−0.0037
−0.0597
0.1593
0.6495
−1.0641
1.0248

resulting in the closed-loop eigenvalues as
−19.5001 ± j1.8608,
−7.1847,
−2.3323 ± j5.6329,
−1.0094.
The optimal output trajectories are plotted in Fig. 5.53.

282
5
Nominal Control Design
Fig. 5.53 Optimal output trajectories
5.10 Digital Control of Uninterruptible Power Supplies
The ultimate goal of uninterruptible power supplies (UPS) system is to supply con-
stant amplitude sinusoidal voltage and constant frequency to load without any in-
terruption in case of a main power failure [8, 22, 23, 26]. The quality of the UPS
output voltage is deﬁned by the total harmonic distortion (THD). The most com-
mon UPS conﬁguration consists of a battery bank and a static rectiﬁer-inverter-ﬁlter
that produce a low total harmonic distortion sinusoidal output voltage that supplies
the critical load. For such application, system performances are usually measured in
terms of transient response and waveform distortions under sudden changes in load
parameters [23, 33].
With the cost reduction of microcontrollers and digital signal processors (DSP),
the use of digital control technique in power converter has increased. However, high
power converters are usually operated at low switching frequencies in order to re-
duce switching losses. Therefore, advanced control strategies are required to over-
come these complications [22, 32, 43].
To design the closed loop control, the model of the system has an important task
in the conception of the controller. Some linear models for single phase PWM in-
verter system have been reported in literature [22, 33]. The output voltage and its
derivative, that is proportional to the capacitor current, can be used as the state vari-
ables, as well as the output voltage and the inductor current. However, modelling
errors and unmodeled dynamics are quite common. They may be a result of simpli-
ﬁcations on the model, which can degrade the performance of the system [43].

5.10
Digital Control of Uninterruptible Power Supplies
283
Many discrete time controllers used to control a single phase inverters in UPS
applications were reported in literature, such as predictive control [8, 13], repetitive
control [25, 53], optimal state feedback [50] and selective harmonic compensation
[26, 40]. Even if most of these schemes offered high performance feedback con-
trol results, they still relay on high switching frequencies and involve considerable
computational over heads. In this paper, a single phase UPS with a low switching
frequency is proposed in order to minimize switching losses and improve system
efﬁciency. An adaptive linear quadratic regulator for single-phase UPS application
is proposed. The regulator is a useful tool in modern optimal control design. For
the proposed controller, a recursive least square estimator identiﬁes the plant pa-
rameters which are used to compute the regulator gains periodically. The quadratic
cost function parameter is chosen in order to reduce the energy of the control signal.
Only the output voltage can be measured and the inductor current is not measurable.
As a result, an observer is used to estimate the inductor current. Using a suitable ﬁl-
ter, the effect of disturbances on the response of the system will be decreased. The
simulations were carried out using MATLAB Simulink.
5.10.1 Plant Description
The single-phase PWM inverter is shown in Fig. 5.54, the LC ﬁlter and the resistive
load R are considered to be the plant of the system.
The inverter is controlled by the unipolar PWM. The power switches are turned
on and off at the carrier frequency. The plant can be modeled by the state space
variable vC and iL:
˙
vc
iL

=
 −1
RC
1
C
−1
L
0
vc
iL

+
 0
1
L

u,
y =
	1
0
vc
iL

,
(5.114)
or
˙x = Ax + Bu,
y = Cx.
(5.115)
Then, a discrete time model of the plant obtained by the forward method and sample
time Ts is given by:
x(k + 1) = Adx(k) + Bdu(k),
y(k) = Cdx(k),
(5.116)
where
x(k) =
	
vc(k)
ˆ˙iL(k)

T ,
Ad = I + TsA,
Bd = T sB.
(5.117)
5.10.2 LQR Design
The adaptive linear quadratic regulator controller has the objective of tracking the
discrete sinusoidal r(k) reference in each sample instant.

284
5
Nominal Control Design
Fig. 5.54 Inverter, ﬁlter and
load
Fig. 5.55 Block diagram of the control system
The system output y(k) is the capacitor voltage in the discrete form vc(k). The
state variables used in the (LQR) are the measured output voltage vc(k), the esti-
mated inductor current ˆiL(k), the integrated tracking error v(k); all with a feedback
action and the discrete reference r(k) and its derivative ˙r(k) with a feed forward ac-
tion. Each state variable has weighting Ki tuned according to θ(k), which contains
the plant parameters identiﬁed by the RLS estimator. The control system shown in
Fig. 5.55 is therefore proposed. Then, in the proposed system, the state vector z(k)
is deﬁned as:
z(k) =
	
vc(k)
ˆ˙iL(k)
v(k)
r(k)
˙r(k)

T ,
(5.118)
and the LQR control signal is given by
uLQR(k) = −Kz(k).
(5.119)
To design the optimal gains K1,K2,...,K5, the system must be represented in the
form:
z(k + 1) = Gz(k) + HuLQR(k),
(5.120)

5.10
Digital Control of Uninterruptible Power Supplies
285
where each state variable is calculated by a difference equation. The two ﬁrst vari-
ables of vector z(k) are obtained by (5.116). The signal v(k) is:
v(k + 1) = e(k + 1) + v(k),
(5.121)
where the error is given by:
e(k) = r(k) −y(k).
(5.122)
From (5.116), (5.121) and (5.122) results the difference equation for
v(k + 1) = v(k) + r(k) + Ts ˙r(k) −CdAdx(k)
−CdBduLQR(k).
(5.123)
The continuous time reference variables are:
˙
r(t)
˙r(t)

=

0
1
−ω2
0
r(t)
˙r(t)

,
˙r = Rr.
(5.124)
This system generates a sinusoidal reference when initiated with initial values:
r(0) = 0,
˙r(0) = wVp,
where VP is the sine wave amplitude and w is the angular frequency.
In the discrete form, using a sample period TS, the subsystem (5.124) is given
by:
n(k + 1) = Rdn(k),
(5.125)
where
n(k) =
	r(k)
˙r(k)
,
(5.126)
Rd = I + TsR.
(5.127)
Then, using the state equations (5.116), (5.123) and (5.125), the closed-loop system
representation becomes:
⎡
⎣
x(k + 1)
v(k + 1)
n(k + 1)
⎤
⎦=
⎡
⎣
Ad
0
0
−CdAd
1
CdRd
0
0
Rd
⎤
⎦
⎡
⎣
x(k)
v(k)
n(k)
⎤
⎦
+
⎡
⎣
Bd
−CdBd
0
⎤
⎦uLQR(k),
(5.128)
y(k) =
	Cd
0
0
	x(k)
v(k)
n(k)
T .
The optimal gains of the control law (3.100) are those that minimize the following
cost function:
J = 1
2
∞

k=0

zT (k)Qz(k) + uT (k)Ruu(k)

,
(5.129)

286
5
Nominal Control Design
where Q and Ru are chosen as positive deﬁnite matrixes that set the weighting of
states and the control signal respectively.
The K gains can be obtained through the evaluating the Riccati equations [44],
as follows:
S(k) = GT S(k + 1)G + Q −
	
H T S(k + 1)G

T
×
	
Ru + H T S(k + 1)H

−1	
H T S(k + 1)G

,
(5.130)
K(k) = R−1
u H T 
GT −1
S(k) −Q

.
(5.131)
A good ﬂexibility in the design of the controller is provided by the selection of Q
and Ru matrixes.
5.10.3 Recursive Least-Squares Estimator
To estimate the plant parameters when the load conditions are variable, a RLS algo-
rithm is used [3]. The discrete plant model with a zero order hold is given by:
y(z)
u(z) =
θ
z2 + θ1z + θ2
.
(5.132)
The difference equation of the estimated output is:
y(k) = −θ1y(k −1) −θ2y(k −2) + θ3u(k −2),
(5.133)
or
ˆy(k) = θT (k)Ψ (k −1),
(5.134)
where
θ(k) =
	θ1
θ2
θ3

,
(5.135)
and
Ψ (k) =
	−y(k −1)
−y(k −2)
u(k −2)
.
(5.136)
The RLS gains are calculated using:
L(k) =
p(k −1)Ψ (k)
1 + Ψ T kp(k −1)Ψ (k).
(5.137)
The RLS covariance matrix is given by:
p(k) = p(k −1) −p(k −1)Ψ (k)Ψ T (k)p(k −1)
1 + Ψ T (k)p(k −1)Ψ (k)
,
(5.138)
and the plant parameters θ are recursively obtained by:
ˆθ(k) = ˆθ(k −1) + L(k)
	
y(k) −Ψ T ˆθ(k −1)

,
(5.139)

5.10
Digital Control of Uninterruptible Power Supplies
287
where:
ˆAd =
0
−ˆθ2
1
−ˆθ1

,
ˆBd =
 ˆθ3
0

,
Cd =
	0
1
.
(5.140)
Then, it is possible to identify the plant parameters to a range of different loads
through the substitution of matrixes (5.140) into system (5.128) and proceed there
often with the LQR gains design in real time.
5.10.4 Kalman Filter
Since only the output voltage is measured, a Kalman ﬁlter [44, 55] is used to esti-
mate the inductor current state.
x(k + 1) = Adx(k) + Bdu(k) + w(k),
y(k) = Cdx(k) + v(k).
(5.141)
The random variables w(k) and v(k) represent the process and measurement noise
respectively. They are assumed to be independent of each other and with normal
probability distributions such that:
E
	
w(k)T
w(k)

= Rw > 0,
E
	
v(k)T
v(k)

= Rv > 0,
(5.142)
E
	
w(k)T
v(k)

= 0.
In practice, the process noise covariance and measurement noise covariance matri-
ces might change with each time step or measurement. However, here, it is assumed
that they are presented below [55].
The Kalman gains are given by:
KG(k) =

M(k)CT
d

CdM(k)CT
d + Rv
−1,
(5.143)
and the estimated variable, the inductor current, is
iL = ˆx2(k) =
	
0
1

ˆx(k).
(5.144)
The following recursive equations are used:
PK(k) = M(k) −KG(k)CdM(k),
(5.145)
and
M(k) =

AdPK(k)AT
d

+

BdRwBT
d

.
(5.146)
After each time and measurement update pair, the process is repeated with the pre-
vious posterior estimates used to project or predict the new a priori estimates.

288
5
Nominal Control Design
Fig. 5.56 System Simulink blockdiagram
5.10.5 Simulation Results
The simulation work is carried out according to the proposed block diagram pre-
sented in Fig. 5.56. The inverter system controlled by linear quadratic regulator
algorithm is realized in order to study the output voltage (V c) performance under
linear and nonlinear loads. The plant controller parameters, algorithm constants and
other system speciﬁcations are presented in Table 5.1.
For a linear load, the input and output voltage waveforms, estimated and mea-
sured inductor currents as well as estimated parameters are shown in Figs. 5.57, 5.58
and 5.59, respectively.
A linear load output voltage and current with values of R and K (gains) taken
from Table 5.1 are illustrated in Fig. 5.60 and the output voltage frequency spectrum
is presented in Fig. 5.61. From this spectrum, the THD is calculated and the obtained
value is 1.12% showing a high quality output voltage.
For a nonlinear load, the output voltage, the output current and the output volt-
age frequency spectrum are shown in Figs. 5.62 and 5.63, respectively. The THD
obtained from the voltage spectrum is equal to 1.61% proving a high quality output
voltage. Figure 5.64 depicts the transient response of the output voltage compared to
the reference. One notices that the dynamic time vanishes in brief time. Figure 5.65
shows the output voltage tracking the reference voltage efﬁciently in the case of lin-
ear load disturbance. From this ﬁgure, it is clear that the proposed LQR regulator is
efﬁcient.

5.11
Model Predictive Control Method
289
Table 5.1 System parameters
DC input voltage
E = 400 V
Reference voltage
Vref = 320 V (peak), 60 Hz
Sample time
Ts = 1/I8000 s
States weightings
Q = diag[50 100 150 1 1]
Control weighting
Ru = 100
For linear load:
Filter inductance
L = 5.3 mH
Filter capacitance
C = 80 µF
Linear load
R = 6 
LQR gains K = [8.0177 36.0875 1.0127 −10.0251 −0.0031]
For nonlinear load:
Nonlinear load rated resistive load phase commutated at angle 45°
Filter inductance
L = 0.5 mH
Filter capacitance
C = 1000 µF
LQR gains K = [9.0097 3.4099 −1.0096 −10.8201 −0.0036]
Switching frequency
f = 1500 Hz
Fig. 5.57 Input and output
voltage for a linear load
5.11 Model Predictive Control Method
The control techniques known collectively as MPC (Model Predictive Control) es-
sentially consist of applying the ﬁrst element of the control sequence obtained as the
solution of an optimal control problem which is solved at each sampling time. Due
to its ability to deal with multivariable systems and transport delays, and to handle
constraints by explicit including them in the optimization problem [49], MPC strate-
gies have become widely employed in industry. Stability requirements for predictive
control laws have already been established when no uncertainties or disturbances are
present [41]. However, predictive controllers may suffer from infeasibility problems

290
5
Nominal Control Design
Fig. 5.58 Measured and
estimated inductor current for
a linear load
Fig. 5.59 The estimated
parameters for a linear load
in the presence of disturbances, possibly leading to violation of system constraints
and system instability, even if the controller stabilizes the system in the nominal
case [12].
Among the possible approaches proposed to deal with this problem, one could
cite min–max optimization [37, 51], and constraint restriction [12, 20]. Badgwell [4]
points out that min–max MPC has an increased computational burden associated
with the usual optimization problem solved by MPC at each sampling time. This
does not occur with the restricted constraint formulation, as the nominal optimiza-
tion problem is solved considering modiﬁed constraints, which can be obtained
off-line. In this section, a robust predictive state regulator is designed for a non-
linear, sixth-order model of a three-degree-of-freedom (3DOF) helicopter subject
to bounded disturbances and physical restrictions on its maneuvering space. Con-
straints are assumed to be convex polyhedral sets and the robustness is achieved by
the use of the restricted constraints formulation presented in [12], which ensures fea-

5.11
Model Predictive Control Method
291
Fig. 5.60 Output voltage and
current for a linear load
Fig. 5.61 Spectral analysis
of the output voltage for a
linear load
sibility and constraint fulﬁllment in spite of the existence of unknown but bounded
disturbances. The computer routines used to calculate the modiﬁed restrictions were
based on algorithms provided in [34] and employed some operations on polyhedra
already implemented in the Multi-Parametric Toolbox (MPT) for MATLAB [36].
For comparison purposes, a nominal predictive control law is also considered. Sim-
ulations results are provided to illustrate that, in the presence of disturbances, while
the robust predictive control law effectively guarantees that none of the system con-
straints is violated, the nominal predictive control law fails to do so.
5.11.1 Predictive Control Formulation
The robust predictive control formulation adopted herein was proposed in [12]. It
concerns the regulation of time-invariant discrete-time linear systems subject to a
disturbance input. The disturbance is assumed to be unknown but must belong to a
compact set:

292
5
Nominal Control Design
Fig. 5.62 Output voltage and
current for a non-linear load
Fig. 5.63 Spectral analysis
of the output voltage for a
non-linear load
x(k + 1) = Ax(k) + Bu(k) + Ew(k),
(5.147)
x(k) ∈X ⊂ℜn,
∀k ≥0,
(5.148)
u(k) ∈U ⊂ℜp,
∀k ≥0,
(5.149)
w(k) ∈W ⊂ℜm,
∀k ≥0.
(5.150)
It is also assumed that the pair (A,B) is stabilizable, U is compact and X , U, W
contain the origin as an interior point. In this section, two predictive control laws
were considered: NPC (nominal predictive control) and RPC (robust predictive con-
trol). It must be noted that the NPC algorithm does not take into account the effects
of the disturbances affecting the system. On the other hand, the RPC algorithm per-
forms a nominal optimization but modiﬁes the original constraints to ensure their
fulﬁllment in spite of the unknown disturbances [12]. These modiﬁcations involve
the use of the following set operations. Let
A,B ⊂ℜn,
F ⊂ℜp,
M ∈ℜp×n,

5.11
Model Predictive Control Method
293
Fig. 5.64 Transient response
of the output voltage for a
linear load
Fig. 5.65 Reference voltage,
output voltage and current
with linear load disturbance
(from R = 6  to R = 3 )
then
A B :=

a ∈ℜn|a + b ∈A,∀b ∈B

,
A ⊕B :=

a + b ∈ℜn|a ∈A,b ∈B

,
LM(M,A) :=

Ma ∈ℜp|a ∈A

,
LM−1(M,F) :=

a ∈ℜp|Ma ∈F

.
Next, we summarize the NPC algorithm.

294
5
Nominal Control Design
5.11.2 NPC Algorithm
Let x(k + j|k) represent the predicted system state at instant k + j, computed at
instant k, based on the actual state x(k) and on the future control moves. Deﬁne the
cost function
J

C[k]

= J

C(k)

=
N−1

j=0
ct(k + j|k)Ψ c(k + j|k).
(5.151)
The nominal predictive control algorithm can be described by the following
steps:
Step 1: Minimize the cost function (5.151), with 0 < Ψ = Ψ t by considering the
control sequence
C(k) =
	
ct(k|k)
···
ct(k + N −1|k)

t
subject to the constraints deﬁned in Eqs. (5.147) to (5.150).
x(k + j + 1|k) = Ax(k + j|k) + Bu(k + j|k),
x(k|k) = x(k),
(5.152)
u(k + j|k) = Kx(k + j|k) + c(k + j|k),
(5.153)
c(k + j|k) = 0,
∀j ≥N
x(k + j|k) ∈Xj,
0 ≤j ≤N,
(5.154)
x(k + j|k) ∈Uj,
0 ≤j ≤N −1
Xj ∈X,
0 ≤j ≤N −1,
XN = ℑh
∞,
(5.155)
Uj ∈U,
0 ≤j ≤N −1.
Step 2: Let
C∗(k) =
	
c∗t(k|k)
···
c∗t(k + N −1|k)

t
be the optimal control sequence resulting from the optimization in Step 1. Apply
u(k) = Kx(k) + c∗(k|k)
to the plant.
Step 3: Set k →k + 1 and return to Step 3.
Remark 5.10 The set ℑh
∞is the maximal positively invariant subset of
X h = X ∩LM−1(K,U)
for the system under the nominal linear feedback, that is, the set of all states which
satisfy state and control constraints (under nominal linear feedback) and for which
the next state remains in such set. In the way, the set ˜ℑh
∞is the maximal robust
positively invariant subset of
X h = X ∩LM−1(K,U)
for the system under the nominal linear feedback, that is, the set of all states which
satisfy state and control constraints (under nominal linear feedback) and for which

5.11
Model Predictive Control Method
295
the next state remains in such set, for all admissible disturbances. It can be arbitrarily
select the gain matrix K deﬁnes a nominal linear state feedback u(k) = Kx(k) as
long as the resulting closed-loop system is stable. If K is taken as the unconstrained
LQR gain minimizing the cost
∞

j=0
xt(k)Qx(k) + ut(k)Ru(k),
0 ≤Qt = Q, 0 < Rt = R
(5.156)
and selecting the weight matrix Ψ = R + BtPB where 0 < Pt = P is the unique
solution of the discrete ARE associated with the LQR problem, then it can be shown
[12] that the minimization of (5.151) subject to (5.152)–(5.155) is equivalent to the
minimization of (5.156) subject to the same constraints.
5.11.3 RPC Algorithm
The robust predictive control algorithm is identical to the NPC algorithm, except by
the replacement of constraints (5.155) by
X0 = X,
XN = ℑh
∞≈RN,
U0 = U,
(5.157)
Xj = X ≈Rj,
0 ≤j ≤N −1,
Uj = U ≈LM(K,Rj),
0 ≤j ≤N −1,
(5.158)
Rj =
j−1

m=0
LM

(A + BK)mE,W

,
∀j ≥1.
The main property of the RPC algorithm, see [12], is that, if the optimization
problem has a solution for the initial state x(0), then it will be feasible for all time,
all state and control constraints will be fulﬁlled, the nonlinear predictive control
law asymptotically approaches the nominal linear control law u(k) = Kx(k), and
the system state is asymptotically steered to a neighborhood of the origin R∞=
limj→∞Rj for all admissible disturbances.
5.11.4 Implementation Details
If the constraints are deﬁned by convex polyhedral sets, optimization problem
(5.151)–(5.155) reduces to a quadratic programming format. To describe this for-
mat, we let the state and control constraints are deﬁned by
Xj : Sx[k+j]x[k + j|k] ≤rx[k+j],
Uj : Su[k+j]x[k + j|k] ≤ru[k+j]
and compute the following matrices

296
5
Nominal Control Design
S =
SXHx(A + BK,B)
SUHu(A + BK,B)

,
r =
rX
rU

−
 SXFx(A + BK)
SUFu(K,A + BK)

x[k|k],
SX = blockdiag
	Sx[k+1]
Sx[k+2]
···
Sx[k+N]

,
SU = blockdiag
	Su[k]
Su[k+1]
···
Su[k+N−1]

,
Hx(Φ,B) =
⎡
⎢⎢⎢⎣
B
0
···
0
Φ
B
···
0
...
...
...
...
ΦN−1B
ΦN−1B
···
B
⎤
⎥⎥⎥⎦,
rX =
⎡
⎢⎢⎢⎣
rx[k+1]
rx[k+2]
...
rx[k+N]
⎤
⎥⎥⎥⎦,
rU =
⎡
⎢⎢⎢⎣
rx[k]
rx[k+1]
...
rx[k+N−1]
⎤
⎥⎥⎥⎦,
Hu(K,Φ,B) =
⎡
⎢⎢⎢⎢⎢⎣
I
···
0
0
KB
···
0
0
...
...
...
...
KΦN−3B
···
I
0
KΦN−2B
···
KB
I
⎤
⎥⎥⎥⎥⎥⎦
,
Fx(Φ) =
⎡
⎢⎢⎢⎣
Φ
Φ2
...
ΦN
⎤
⎥⎥⎥⎦,
Fu(K,Φ) =
⎡
⎢⎢⎢⎣
K
KΦ
...
KΦN−1
⎤
⎥⎥⎥⎦.
Then the quadratic programming problem can be expressed as
C∗(k) = argmin
C[k]

Ct[k] ˆΨ C[k]

subject to
SC[k] ≤r,
ˆΨ = diagN{Ψ }.
(5.159)
5.12 LQGR Design
In this section, we review what is known as Linear Quadratic Gaussian theory or
LQG theory for brevity. By including Gaussian white noise in the LQ paradigm
linear optimal feedback systems based on output feedback rather than state feedback
may be found.

5.12
LQGR Design
297
Fig. 5.66 LQG feedback
5.12.1 Introduction
In what follows, we consider the system
˙x(t) = Ax(t) + Bu(t) + Γ v(t),
z(t) = Gx(t) + Du(t),
(5.160)
y(t) = Cx(t) + w(t).
The measured output y(t) is available for feedback and z(t) is the controlled output.
The signals v and w are zero-mean Gaussian plant and measurement white noise
processes with
Ev(t)vt(t) = Vδ(t −s)
Ev(t)wt(t) = 0
Ew(t)wt(t) = Wδ(t −s)
⎫
⎬
⎭
∀t,s ∈ℜ
(5.161)
where the power spectrum matrices 0 ≤Vt = V, 0 ≤Rt = W, are sometimes referred
to as the intensity matrices of the two white noise processes, respectively.
We do not go into the theory of stochastic processes in general and that of white
noise in particular, but refer to texts such as [5, 56]. The initial state x(0) is assumed
to be a random vector. The various assumptions deﬁne the state x(t), t ∈ℜ, and the
controlled output z(t), t ∈ℜ, as random processes. As a result, also the quadratic
error expression
zt(t)Qz(t) + ut(t)Ru(t),
t ≥0
(5.162)
is a random process. The problem of controlling the system such that the integrated
expected value
 T
0
E
	
zt(t)Qz(t) + ut(t)Ru(t)

dt,
(5.163)
is minimal is the stochastic linear regulator problem. The time interval [0;T ] at this
point is taken to be ﬁnite but eventually we consider the case that T →∞. At any
time t the entire past measurement signal y(s), s ≤t, is assumed to be available for
feedback. Figure 5.66 clariﬁes the situation.

298
5
Nominal Control Design
5.12.2 Kalman Filter
A fundamental limitation of LQR is imposed by the need to measure the entire state.
In many applications some states are not measurable, that is, there are no currently
available sensors capable of measuring these states. In many other applications, the
cost of including sensors for measuring the entire state is prohibitive or undesir-
able. Therefore, a methodology is needed for designing controllers when only par-
tial state measurements are available. The Kalman ﬁlter is an optimal estimator of
state, where optimal is deﬁned in terms of minimizing the mean square estimation
error. The Kalman ﬁlter estimates the state of a system given a set of known inputs
and a set of measurements.
We learned before that the dynamical system
˙ˆx(t) = Aˆx(t) + Bu(t) + L
	
y(t) −Cˆx(t)

,
t ∈ℜ
(5.164)
can act as an observer for system (5.160) under the nominal conditions (v(t) ≡0
and w(t) ≡0) and hence reproduce the state x asymptotically, that is ˆx
t→∞
−→x. The
matrix L is the observer gain. We take advantage of this salient feature and connect
the observer (5.164) to the noisy system (5.160). Differentiation of
e(t) = ˆx(t) −x(t)
leads to the error differential equation
˙e(t) = (A −LC)Ae(t) −Γ v(t) + Lw(t),
t ∈ℜ.
(5.165)
Owing to the two noise terms on the right-hand side the error now no longer con-
verges to zero, even if the error system is stable. Suppose that the error system is
stable. It is well known [58] that as t →∞, the error covariance matrix
E
	
et(t)e(t)

converges to a constant steady-state value Y that satisﬁes the linear Lyapunov matrix
equation
(A −LC)Y + Y(A −LC)t + Γ VΓ t + LYLt = 0.
(5.166)
It is an easy task following arguments from Lyapunov theory that as a function of the
gain matrix L the steady-state error covariance matrix Y is minimal if L is chosen
as
L = YCtW−1.
(5.167)
It should be noted that minimal means here that if ˆY is the steady-state error covari-
ance matrix corresponding to any other observer gain ˆL then ˆY ≥Y. This inequality
is to be taken in the sense that ˆY −Y ≥0.
A consequence of this result is that the gain (5.167) minimizes the steady-state
mean square state reconstruction error
lim
t→∞E
	
et(t)e(t)

.

5.12
LQGR Design
299
Actually, the gain minimizes the weighted mean square construction error
lim
t→∞E
	
et(t)Wee(t)

for any nonnegative-deﬁnite weighting matrix We.
Substitution of the optimal gain matrix (5.167) into the Lyapunov equation
(5.166) yields
AY + YAt + Γ VΓ t −YCtW−1CY = 0.
(5.168)
This is another algebraic matrix Riccati equation or the Dual Riccati. The ob-
server (5.160) with the gain chosen as in (5.167) and the covariance matrix Y the
nonnegative-deﬁnite solution of the Riccati equation (5.168) is the famous Kalman
ﬁlter [31].
Remark 5.11 A signiﬁcant result is system theory is that the optimal regulator and
the Kalman ﬁlter are dual in the following sense. Given the regulator problem of
Chap. 5, replace A with At, B with Ct, D with Γ t, Q with V, and R with W. Then
the regulator Riccati equation (5.16) becomes the observer Riccati equation (5.168),
its solution X becomes Y, the state feedback gain K is the transpose of the observer
gain L, and the closed-loop system matrix A −BK is the transpose of the error
system matrix A −LC. By matching substitutions the observer problem may be
transposed to a regulator problem.
Next we review several properties of the Kalman ﬁlter.
1. Assume that the system
˙x(t) = Ax(t) + Γ v(t),
y(t) = Cx(t)
(5.169)
is stabilizable and detectable and the noise intensity matrices V and W are
positive-deﬁnite. By duality to the regulator, the algebraic Riccati equation
(5.168) has a unique nonnegative-deﬁnite symmetric solution Y. If the system
(5.169) is controllable rather than just stabilizable then Y is positive-deﬁnite. It
is important to note that if the system (5.169) is not detectable then no observer
with a stable error system exists. If the system is not stabilizable (with d as in-
put) then there exist observers that are not stable but are immune to the state
noise d. Hence, stability of the error system is not guaranteed. Matrix W needs
to be positive-deﬁnite to prevent the Kalman ﬁlter from having inﬁnite gain. If V
is not positive-deﬁnite, then there may be unstable modes that are not excited by
the state noise and, hence, are not stabilized in the error system.
2. The minimal value of the steady-state weighted mean-square state reconstruction
error
lim
t→∞E
	
et(t)Wee(t)

= Tr[YWe].
3. The minimal value of the mean square reconstruction error is achieved by the
observer gain matrix
L = YCtW−1.

300
5
Nominal Control Design
4. The error system
˙e(t) = (A −LC)Ae(t),
t ∈ℜ
(5.170)
is stable, that is, all the eigenvalues of the matrix A −LC have strictly negative
real parts. As a consequence also the observer
˙ˆx(t) = Aˆx(t) + Bu(t) + L
	
y(t) −Cˆx(t)

,
t ∈ℜ
(5.171)
is stable.
5. Note that the implementation of Kalman ﬁlter requires a system noise spectral
density matrix, a measurement noise spectral density matrix, an initial condition
on the state estimate, and an initial estimation error covariance matrix.
5.12.3 Solution of the Stochastic Linear Regulator Problem
We consider the stochastic linear regulator problem that consists of minimizing
 T
0
E
	
zt(t)Qz(t) + ut(t)Ru(t)

dt,
(5.172)
for the system
˙x(t) = Ax(t) + Bu(t) + Γ v(t),
z(t) = Gx(t),
(5.173)
y(t) = Cx(t) + w(t)
and discuss several versions:
1. Noise-free state: When the noise signal v(t) is absent and the state x(t) may be
directly measurable, then for T →∞the performance index is minimized by the
control law
u(t) = −Kx(t) = −R−1BtXx(t)
(5.174)
where the symmetric n × n matrix X is the nonnegative-deﬁnite solution of the
algebraic matrix Riccati equation (ARE)
XA + AtX + GtQG −XBR−1BtX = 0.
(5.175)
2. State feedback: If white noise signal v(t) is present, then obviously the state and
input cannot be driven to 0, and the integrated generalized square error (5.172)
does not converge to a ﬁnite number as T →∞. It is proved [6, 7, 55] that the
state feedback law (5.174) minimizes the rate at which (5.172) approaches ∞,
that is, it minimizes
lim
T →∞
 T
0
E
	
zt(t)Qz(t) + ut(t)Ru(t)

dt.
(5.176)
This limit equals the steady-state mean square error index steady-state mean
square error

5.12
LQGR Design
301
Fig. 5.67 Estimator-based
feedback control
lim
t→∞E
	
zt(t)Qz(t) + ut(t)Ru(t)

.
(5.177)
Hence, the state feedback law minimizes the steady-state mean square error.
3. Output feedback: The interesting situation is that the state cannot be accessed
for measurement. The state may be optimally estimated, however, with the help
of the Kalman ﬁlter. Then the solution of the stochastic linear regulator problem
with output feedback (rather than state feedback) is to replace the state x(t) in
the state feedback law (5.174) with the estimated state ˆx(t). Thus, the optimal
controller is given by
˙ˆx(t) = Aˆx(t) + Bu(t) + L
	
y(t) −Cˆx(t)

,
t ∈ℜ,
u(t) = −K ˆx(t).
(5.178)
The controller minimizes the steady-state mean square error (5.177) under output
feedback. The feedback gain K and the observer gain L follow from the forego-
ing analysis, respectively. Figure 5.67 shows the arrangement of the closed-loop
system.
Using the estimated state as if it were the actual state is known as certainty
equivalence. It splits state estimation and control input selection thereby lead-
ing to the idea frequently referred to as the separation principle. It follows that
the closed-loop system that results from interconnecting the plant (5.173) with
the feedback controller (5.178) is stable—under the stabilizability-detectability
assumptions. To clarify this, we substitute of u(t) = −K ˆx(t) into (5.173) yields
with the further substitution ˆx(t) = x(t) −e(t)
˙x(t) = (A −BK)Ax(t) −BKe(t) + Γ Lv(t)
(5.179)
which together with (5.165) yields
 ˙x(t)
˙e(t)

=
A −BK
−BK
0
A −LC
x(t)
e(t)

+

Γ v(t)
−Γ v(t) + Lw(t)

.
(5.180)
It is a straightforward task to show that the eigenvalues of this system are the
eigenvalues of the closed-loop system. Simple inspection shows that these eigen-
values consist of the eigenvalues of A −BK (the regulator poles) together with
the eigenvalues of A −LC (the observer poles). If the plant (5.173) has order n
then the feedback controller also has order n). Hence, there are 2n closed-loop
poles.

302
5
Nominal Control Design
5.13 MATLAB Hints
5.13.1 LQR in MATLAB
The command [K,P,E] = lqr(A,B,Q,R,N) solves the ARE (5.62) and computes
the optimal state-feedback gain matrix K given in (5.60) that minimizes the LQR
criteria (5.58) for the continuous-time system (5.55). It also returns the poles E of
the closed-loop system (5.64).
5.14 Questions and MATLAB Problems
5.14.1 Questions
Q5.1 Suppose that P1 and P2 are two symmetric positive-deﬁnite solutions to the
ARE (5.62). Show that P1 and P2 satisfy (A −BR−1BtP2)(P1 −P2) +
(P1 −P2)(A −BR−1BtP2) = 0 and argue that P1 = P2.
Q5.2 Derive a solution to the optimal control problem involving a performance in-
dex Jα =
! ∞
0 e2αt[xt(t)Qz(t)+ut(t)Ru(t)]dt, and show that the associated
closed-loop eigenvalues have real parts less than −α.
Q5.3 Let (sI −A)−1b = [Pn−l(s) ··· P0(s)]′/a(s). Show that the common roots
of the n + 1 polynomials {Pn−l(s),...,P0(s),a(s)} specify exactly the un-
controllable natural frequencies of {A,b}.
Q5.4 A linear time-invariant system is described by
A =
⎡
⎣
1
0
0
0
2
0
0
0
−1
⎤
⎦,
B =
⎡
⎣
1
1
0
⎤
⎦,
Ct =
⎡
⎣
1
0
1
⎤
⎦.
Evaluate the eigenvalues of the system and examine their structural proper-
ties. Compute the controllability and observability matrices. Apply a linear
state-feedback with auxiliary input and discuss the effect of feedback on the
controllability, observability and closed-loop eigenvalues. Repeat the forego-
ing effort for the case of constant output feedback with auxiliary input.
Q5.5 Consider a linear time-invariant system
˙x = Ax + Bu,
y = Cx.
The problem of interest is to choose u = −Kx + v such that y →yd as t →
∞where yd is a constant set point. Give a detailed analysis of the problem
and establish the required conditions.
Q5.6 Given the system
˙x = Ax + Bu + Ew,
y = Cx

5.14
Questions and MATLAB Problems
303
where w is a constant disturbance. The objective is to regulate the system
output (to the origin) in spite of the disturbance w using the integral error
feedback
˙η = y(t),
u(t) = −K1x −K2η.
Establish the conditions to fulﬁll the objective.
5.14.2 MATLAB Problems
P5.1 For the linearized model of the Reverse osmosis (RO) plant discussed in
Sect. 5.4, design and evaluate an observer-based feedback controller by se-
lecting the observer eigenvalues distinctly different from the controller eigen-
values. Plot the state responses for different cases and comment on the results.
P5.2 For the linearized model of the Reverse osmosis (RO) plant discussed in
Sect. 5.4, design and evaluate an optimal linear quadratic regulator with equal
weighting for the state and input. Plot the output responses to unit step input
and compare on the same graph the open-loop and the closed-loop responses.
P5.3 A linearized model of a vertical takeoff and landing (VTOL) aircraft [Dorf]
has the matrices
A =
⎡
⎢⎢⎣
−0.0389
0.0271
0.0188
−0.4555
0.0482
−1.0100
0.0019
−4.0208
0.1024
0.3681
−0.7070
1.4200
0
0
1
0
⎤
⎥⎥⎦,
B =
⎡
⎢⎢⎣
0.4422
0.1291
3.5446
−7.5922
−6.0214
4.4900
0
0
⎤
⎥⎥⎦,
Ct =
⎡
⎢⎢⎣
1
0
0
0
0
0
0
1
⎤
⎥⎥⎦.
Evaluate the structural properties of the system. Design stabilizing state-
feedback, observer-based feedback and LQR controllers and compare among
the three cases.
P5.4 Consider the turbo-generator system treated in Example 5.5. Design stabiliz-
ing observer-based feedback controller and plot the input–output trajectories.
Compare the results of both design cases.
P5.5 A helicopter is a twin rotor aircraft that is lifted and propelled by one or
more horizontal rotors, each rotor consisting of two or more rotor blades.
Helicopters are classiﬁed as rotorcraft or rotary-wing aircraft to distinguish
them from ﬁxed-wing aircraft because the helicopter achieves lift with the
rotor blades which rotate around a mast. Hover is the operating state in which
the lifting rotor has no velocity relative to the air, either vertical or horizon-
tal. Equations of motion of the helicopter during hovering conditions are ob-
tained using the momentum theory which applies the basic theory of ﬂuid
mechanics, conservation of mass, momentum and energy. General vertical

304
5
Nominal Control Design
ﬂight involves axial ﬂow with respect to the rotor. Vertical ﬂight implies axial
symmetry of the rotor and hence that the velocities and loads on the rotor are
independent of the azimuth position. Axial symmetry greatly simpliﬁes the
dynamics and aerodynamics of the helicopter rotor. The following eight-order
linear system models the small-perturbation rigid body motion of a helicopter
about the hover condition [14]:
˙x = Ax + Bu,
y = Cx
where
x :=
Pitch attitude (rad)
Roll attitude (rad)
Body roll rate (rad s−1)
Body pitch rate (rad s−1)
Body yaw rate (rad s−1)
Forward velocity (ft s−1)
Lateral velocity (ft s−1)
Normal velocity (ft s−1)
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
θ
φ
p
q
r
u
v
w
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
A =
	A1
A2

,
A1 =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
0
0
0.9986
0
0
1.0000
−0.0032
0
0
−11.5705
−2.5446
0
0
0.4394
−1.9982
0
0
−2.0409
−0.4590
−32.1036
0
−0.5034
2.2970
0.1022
32.0578
−2.3470
−0.5036
−1.9110
1.7138
−0.0040
−0.0574
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
A2 =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
0.0534
0
0
0
0.0595
0
0
0
−0.0636
0.1068
−0.0949
0.0071
0
0.0167
0.0185
−0.0012
−0.7350
0.0193
−0.0046
0.0021
0
−0.0212
−0.0212
0.0158
0.8349
0.0212
−0.0379
0.0004
0
0.0140
−0.0009
−0.2905
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
B =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
0000
0.1243
0.0828
−2.7525
−0.0179
−0.0364
0.4751
0.0143
0
0.3045
0.0150
−0.4965
−0.2067
0.2877
−0.5445
−0.0164
0
−0.0191
0.0164
−0.5445
0.2348
−4.8206
−0.0004
0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,

5.15
Notes and References
305
with inputs
u : =
⎡
⎢⎢⎣
θod
θls
θlc
θot
⎤
⎥⎥⎦=
Main rotor collective (deg)
Longitudinal cyclic (deg)
Lateral cyclic (deg)
Tail rotor cyclic (deg)
(5.181)
C =
	C1
C2

,
C1 =
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
1
0
0
0
0
1
0
0
0
0
0
0.535
0
0
1
0
0
0
0
1
⎤
⎥⎥⎥⎥⎥⎥⎦
,
C2 =
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0.0595
0.0533
−0.9968
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
and outputs
y =
⎡
⎢⎢⎢⎢⎢⎢⎣
˙h
θ
φ
˙ψ
q
p
⎤
⎥⎥⎥⎥⎥⎥⎦
=
Heave velocity (ft s−1)
Pitch attituded (rad)
Roll attitude (rad)
Heading rate (ft s−1)
Body pitch rate (rad s−1)
Body roll rate (rad s−1)
(5.182)
Develop state-feedback controllers based pole assignment and optimal con-
trol and compare their closed-loop behavior. Comment on the result.
5.15 Notes and References
The analysis presented in this chapter made extensive use of the standard textbooks
[2, 6, 7, 10, 16, 39, 47, 52, 54, 57].
References
1. Anderson, W.: Controlling Electrohydraulic Systems. Dekker, New York (1988)
2. Anderson, B.O.D., Moore, J.B.: Linear Optimal Control—Linear Quadratic Methods.
Prentice-Hall, Englewood Cliffs (1990)
3. Astrom, K.J., Wittenmark, V.E.: Adaptive Control, 2nd edn. Prentice-Hall, New York (1995)
4. Badgwell, T.A.: Robust model predictive control. Int. J. Control 68, 797–818 (1997)
5. Bagchi, A.: Optimal Control of Stochastic Systems. Prentice Hall International, Englewood
Cliffs (1993)
6. Brockett, R.W.: Finite Dimensional Linear Systems. John Wiley and Sons, New York (1970)
7. Burl, J.B.: Linear Optimal Control, 3rd edn. Prentice-Hall, New York (1998)
8. Buso, S., Fasolo, S., Mattavelli, P.: Uninterruptible power supply multiloop control employing
digital predictive voltage and current regulators. In: Proc. IEEE APEC, pp. 907–913 (2001)
9. Byeongil, K., Chang, Y., Lee, M.H.: System identiﬁcation and 6-DOF controller design of
unmanned model helicopter. JSME Int. J. Ser. C 49(4), 1048–1057 (2006)

306
5
Nominal Control Design
10. Callier, F.M., Desoer, C.A.: Multivariable Feedback Systems. Springer-Verlag, New York
(1982)
11. Chen, C.-T.: Introduction to Linear Systems Theory. Holt, Rinehart and Winston, New York
(1970)
12. Chisci, L., Rossiter, J.A., Zappa, C.: Systems with persistent disturbances: Predictive control
with restricted constraints. Automatica 37, 1019–1028 (2001)
13. Cho, J., Lee, S., Mok, H., Choe, G.: Modiﬁed deadbleat controller for UPS with 3-phase PWM
inverter. In: Conf. Rec. IEEE-IAS Annu. Meeting, pp. 2208–2215 (1999)
14. Edwards, C., Spurgeon, S.K.: Sliding mode stabilization of uncertain systems using only out-
put information. Int. J. Control 62(5), 1129–1144 (1995)
15. Fredriksson, J., Egardt, B.: Backstepping control with local LQ performance applied to a tur-
bocharged diesel engine. In: Proc. 40th IEEE Conference on Decision and Control, vol. 1,
pp. 111–116 (2001)
16. Freudenberg, J.S., Looze, D.P.: Frequency Domain Properties of Scalar and Multivariable
Feedback Systems. Springer-Verlag, Berlin (1988)
17. Friedrich, I., Liu, C.S., Oehlerking, D.: Coordinated EGR-rate model-based controls of tur-
bocharged diesel engines via an intake throttle and an EGR valve. In: IEEE Conference on
Vehicle Power and Propulsion, VPPC ’09, 7–10 Sept. 2009, pp. 340–347
18. Fukushima, N., Arslan, M.S., Hagiwara, I.: An optimal control method based on the energy
ﬂow equation. IEEE Trans. Control Syst. Technol. 17(4), 866–875 (2009)
19. Ghazy, M.A.: Variable Structure Control for Electrohydraulic Position Servo System. In: Proc.
Industrial Electronics Conference, IECON, vol. 1, pp. 2194–2198 (2001)
20. Gossner, J.R., Kouvaritakis, B., Rossiter, J.A.: Stable generalized predictive control with con-
straints and bounded disturbances. Automatica 33, 551–568 (1997)
21. Haiyan, W.: Control oriented dynamic modeling of a turbocharged diesel engine. In: Sixth Int.
Conference on Intelligent Systems Design and Applications—ISDA ’06, vol. 2, 16–18 Oct.
2006, pp. 142–145
22. Haneyoshi, T., Kawamura, A.: Waveform compensation of PWM inverter with cyclic ﬂuctu-
ating loads. IEEE Trans. Industrial Application 24(4), 582–589 (1988)
23. IEEE recommended practice for emergency and standby power systems for industrial and
commercial applications. IEEE-446-1995, 1995
24. Jaho Seo, J., Venugopala, R., Kenne, J.-P.: Feedback linearization based control of a rotational
hydraulic drive. Control Eng. Pract. 15, 2007 pp.
25. Jensen, U.B., Enjeti, P.N., Blaabjerg, F.: A new space vector based control method for UPS
systems powering a nonlinear performance programmable AC power source with low har-
monic distortion using DSP-based repetitive control technique. IEEE Trans. Power Electron.
12, 715–725 (1997)
26. Jouanne, A.V., Enjeti, P.N., Lucas, D.J.: DSP control of high power UPS systems feeding
nonlinear loads. IEEE Trans. Industrial Electronics 43, 121–125 (1996)
27. Jovanovic, M.: Nonlinear control of an electrohydraulic velocity servosystem. Proc. Am. Con-
trol Conf. 1, 588–593 (2002)
28. Jung, M., Glover, K., Christen, U.: Comparison of uncertainty parameterisations for robust
control of turbocharged diesel engines. Control Eng. Pract. 13(1), 15–25 (2005)
29. Kaddissi, C., Kenne, J.-P., Saad, M.: Identiﬁcation and real-time control of an electrohydraulic
servo system based on nonlinear backstepping. IEEE/ASME Trans. Mechatron. 12, 12–22
(2007)
30. Kaliath, T.: Linear Systems. Prentice-Hall, New York (1980)
31. Kalman, R.E., Bucy, R.S.: New results in linear ﬁltering and prediction theory. J. Basic Engi-
neering, Trans. ASME Series D 83, 95–108 (1961)
32. Karam, S., Mahdi, J.K.: Application of adaptive LQR with repetitive control for UPS systems.
In: Proc. the 2003 IEEE Industry Applications Conference, pp. 1124–1129
33. Kawamura, A., Yokoyama, T.: Comparison of ﬁve control methods for digitally feedback con-
trolled PWM inverters. In: Proc. the 1991 EPE Conference, pp. 035–040
34. Kerrigan, E.C.: Robust constraint satisfaction: Invariant sets and predictive control, PhD the-
sis, St. John’s College, Cambridge, UK (2000)

References
307
35. Kim, N., Cha, S., Peng, H.: Optimal control of hybrid electric vehicles based on Pontryagin’s
minimum principle. IEEE Trans. Control Syst. Technol. 18, 1–12 (2010)
36. Kvasnica, M., Grieder, P., Baoti´c, M.: Multi-parametric toolbox (MPT), http://control.ee.
ethz.ch/~mpt/ (2004)
37. Lee, J.H., Yu, Z.: Worst case formulations of model predictive control for systems with
bounded parameters. Automatica 33, 763–781 (1997)
38. Liao, H.H., Roelle, M.J., Chen, J.S., Park, S., Gerdes, J.C.: Implementation and analysis of a
repetitive controller for an electro-hydraulic engine valve system. IEEE Trans. Control Syst.
Technol. 18, 1–12 (2010)
39. Maciejowski, J.M.: Multivariable Feedback Design. Addison-Wesley, England (1989)
40. Mattavelli, P.: Synchronous-frame harmonic control for high performance power supplies.
IEEE Trans. Industrial Application 37, 864–872 (2001)
41. Mayne, D.Q., Rawlings, J.B., Rao, C.V., Scokaert, P.O.M.: Constrained model predictive con-
trol: Stability and optimality. Automatica 36(6), 789–814 (2000)
42. Misgeld, B.J.E., Werner, J., Hexamer, M.: Robust and self-tuning blood ﬂow control during
extracorporeal circulation in the presence of system parameter uncertainties. Med. Biol. Eng.
Comput. 43(5), 589–598 (2005)
43. Montagner, V.F., Carati, E.G.: An adaptive linear quadratic regulator with repetitive controller
applied to uninterruptible power supplies. In: Proc. the 2000 IEEE Industry Applications Con-
ference, pp. 2231–2236
44. Ogata, K.: Discrete-Time Control Systems. Prentice-Hall, New York (1987)
45. Ogata, K.: MATLAB for Control Engineers. Prentice-Hall, New York (2008)
46. Pipeleers, G., Demeulenaere, B., Al-Bender, F., Schutter, J., Swevers, J.: Optimal performance
tradeoffs in repetitive control: Experimental validation on an active air bearing setup. IEEE
Trans. Control Syst. Technol. 17(4), 970–979 (2009)
47. Postlethwaite, I., MacFarlane, A.G.J.: A Complex Variable Approach to the Analysis of Linear
Multivariable Feedback Systems. Springer-Verlag, Berlin (1979)
48. Qi, Q., Deng, S.: Multivariable control-oriented modeling of a direct expansion (DX) air con-
ditioning (A/C) system. Int. J. Refrig. 31(5), 841–849 (2008)
49. Rossiter, J.A.: Model-Based Predictive Control: A Practical Approach. CRC Press, Boca Ra-
ton (2003)
50. Ryan, M.J., Brunsicle, W.E., Lorenz, R.D.: Control topology option for a single-phase UPS
inverters. IEEE Trans. Industrial Application 33(4), 493–501 (1997)
51. Scokaert, P.O.M., Mayne, D.Q.: Min-max feedback model predictive control for constrained
linear systems. IEEE Trans. Autom. Control 43, 1136–1142 (1998)
52. Skogestad, S., Postlethwaite, I.: Multivariable Feedback Control: Analysis and Design. John
Wiley & Sons, Chichester, England (1996)
53. Tzou, Y.Y., Ou, R.S., Jung, S.L., Chang, M.Y.: High performance programmable AC power
source with low harmonic distortion using DSP-based repetitive control technique. IEEE
Trans. Power Electron. 12, 715–725 (1997)
54. Vardulakis, A.I.G.: Linear Multivariable Control—Algebraic Analysis and Synthesis Meth-
ods. John Wiley & Sons, Chichester, England (1991)
55. Welch, G., Bishop, G.: An Introduction to the Kalman Filter. University of North Carolina at
Chapel Hill, Chapel Hill, pp. 2759–3175 (2003)
56. Wong, E.: Introduction to Random Processes. Springer-Verlag, New York (1983)
57. Wonham, W.M.: Linear Multivariable Control—A Geometric Approach. Springer-Verlag,
Berlin (1974)
58. Yano, K., Higashikawa, S., Terashima, K.: Motion control of liquid container considering an
inclined transfer path. Control Eng. Pract. 10, 465–472 (2002)
59. Yuan, Q.H., Li, P.Y.: Robust optimal design of unstable valves. IEEE Trans. Control Syst.
Technol. 15(6), 1065–1074 (2007)

Chapter 6
Applications II
6.1 Introduction
Feedback control has played a vital role in the advance of engineering and science.
In addition to its extreme importance in space-vehicle systems, missile-guidance
systems, robotic systems, and the like, automatic control has become an important
and integral part of modern manufacturing and industrial processes. For example,
automatic control is essential in the numerical control of machine tools in the man-
ufacturing industries, in the design of autopilot systems in the aerospace industries,
and in the design of cars and trucks in the automobile industries. It is also essential
in such industrial operations as controlling pressure, temperature, humidity, viscos-
ity, and ﬂow in the process industries. Since advances in the theory and practice of
automatic control provide the means for attaining optimal performance of dynamic
systems, improving productivity, relieving the drudgery of many routine repetitive
manual operations, and more, most engineers and scientists must now have a good
understanding of this ﬁeld, see [15, 16, 29] for different technical views.
6.2 Control of Shaping Process of Automobile Belt
To maintain stable tension and uniform distribution for winding string during the
winding shaping process of automobile belt, a computer control system is proposed.
In this system, the string tension can be measured by a tension sensor and regulated
by a magnetic powder brake. Simultaneously, the velocity of the shaping model
shaft that is driven by a DC motor can be measured by an opto-coder. For realizing
optimal performance, the observer-based LQR controller is applied to this system.
The feedback is determined by minimizing the cost function on the LQR rule, while
a full order or a reduced-order observer is used to estimate system states besides be
measurable states: shaft velocity and the string tension. Simulation results are given
for these control strategies, and the disturbance rejection ability is examined.
The computer control system for the winding shaping process is shown in
Fig. 6.1. When the system is started, the shaft of the shaping model turns. The
M.S. Mahmoud, Y. Xia, Applied Control Systems Design,
DOI 10.1007/978-1-4471-2879-3_6, © Springer-Verlag London Limited 2012
309

310
6
Applications II
Fig. 6.1 Winding shaping system for automobile belt
string from a line tube is winded around the gum sheet which is mounted outside
of the model shaft, and its moving step is controlled by a stepper motor [24]. The
string tension is adjusted by the voltage of the magnetic powder brake with a feed-
back signal from the tension sensor. At the same time, the shaft is driven by a DC
motor whose velocity is measured by an opto-coder. All the operations including
string tension and shaft velocity, are controlled by an industrial PC computer. The
design goal of the system is to maintain stable and uniform string tension and shaft
velocity during whole winding process, and to quickly reach the demanded states
after starting.
It is known that the tension regulation is not easy because it is sensitive to the ve-
locity variation and the surrounding interferences, so proper control strategy should
be found. There are some researches are related to tension control. In [48], some
ideas of tension control are applied to a web machine. The torque and velocity con-
trol were used to rewinding roller to get desired results. A tension control system is
proposed in [31] using an active dancer roller, which is suitable for the production
of wire and sheet materials. Modeling and controller design with tension feedback,
output feedback and state feedback with an observer were discussed. In [42], a mod-
eling method is proposed for web tension proﬁle in a paper machine, which could be
built based on string model, 2D-connection model and ﬁnite element model. Fault-
tolerant control is used in [39] for winding machine in processes such as sheet and
ﬁlm processes of steel industry. A modeling and control method of winding sys-
tems is presented in [30] for elastic webs. Robust H∞and linear parameter varying
control were used to get the desired result.
It was shown in [24] that a PID controller can work smoothly, but took time
to be stable. So the control algorithms should be further improved. Along similar
lines, the H2-optimal digital control [11, 25] yielded good responses simulation
studies despite it demands too large controls for the DC motor and magnetic powder
brake.
In this section, the model of the winding system of the automobile belt is intro-
duced, and a feedback control system is designed to minimize the cost function on

6.2
Control of Shaping Process of Automobile Belt
311
the LQR rule. The full-order and reduced-order observer are used to estimate system
states besides the measurable states: shaft velocity and the string tension. Simula-
tion results are given for the optimal feedback control based on the full-order and
reduced-order observer, and the disturbance rejection ability is examined.
6.2.1 System Model
In the sequel, we provide deﬁnition of the related variables.
Parameters
Constant: Jr—combined inertia of shaping model and the motor (3.2 kg m2);
β1—viscous friction of main shaft (0.2 N m/s); K1—motor torque constant
(0.15 N m/A); L—motor armature inductance (3.6 mH); R—motor arma-
ture resistance (1 ); Ke—motor velocity constant (1.2 V s); Kg—gear ratio
(20 : 1); J2—inertia of string tube (0.4 kg m2); β2—viscous friction of string
tube (0.02 N m/s); Ks—damping constant of magnetic brake (0.08 V s/(N–m));
KF —torque constant of magnetic brake (1.2 V/(N–m)); KL—spring constant of
winding string (8 × 104 N/m); r1—radius of shaping model (0.3 m); r2—radius
of string tube (0.2 m).
Differential Equations
For the main shaft velocity ωt, it relates to, motor torque (KgKII, where I is arma-
ture current) and string tension T :
J1
dω1
dt + β1ω1 = KgK1I −T r1.
(6.1)
And the armature current I conforms to:
Ldl
dt + R.I + KeKgω1 = UM
(6.2)
where UM is the motor control voltage.
The velocity ω2 of the string tube is related to the string tension T and the mag-
netic brake friction torque F . We have
J2
dω2
dt + β2ω2 = T r2 −F.
(6.3)
The magnetic brake friction torque is adjusted by the control voltage UF :
Ks
dF
dt + KF F = UF .
(6.4)

312
6
Applications II
Let x1 be the position on the winding model, and x2 be position on the string tube.
Then string tension T is related to the string deformation x1 −x2 and spring constant
KL of the winding string [6]:
T = KL(x1 −x2),
(6.5)
dx1
dt = r1ω1,
dx2
dt = r2ω2,
(6.6)
dT
dt = KL
dx1
dt −dx2
dt

= KL(r1ω1 −r2ω2).
State Space Model
Let x1 = ω1, x2 = I, x3 = ω2, x4 = F , x5 = T , and outputs are y1 = ω1, y2 = T .
From (3.95)–(3.100), we get
⎡
⎢⎢⎢⎢⎣
˙x1
˙x2
˙x3
˙x4
˙x5
⎤
⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
−β1
J1
KgK1
J1
0
0
−r1
J1
−KeKg
L
−R
L
0
0
0
0
0
−β2
J2
1
J2
r2
J2
0
0
0
−KF
Ks
0
KLr1
0
−KLr2
0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎣
x1
x2
x3
x4
x5
⎤
⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎣
0
0
1
L
0
0
0
0
1
Ks
0
0
⎤
⎥⎥⎥⎥⎦

UM
UF

,
(6.7)

y1
y2

=

x1
x5

=

1
0
0
0
0
0
0
0
0
1

X.
Substitute all parameters, A and B matrices become
A =
⎡
⎢⎢⎢⎢⎣
−0.0625
0.9375
0
0
−0.09375
−3333.3
−277.78
0
0
0
0
0
−0.05
−2.5
0.5
0
0
0
−12
0
24000
0
−16000
0
0
⎤
⎥⎥⎥⎥⎦
,
B =
⎡
⎢⎢⎢⎢⎣
0
0
277.78
0
0
0
0
10
0
0
⎤
⎥⎥⎥⎥⎦
,
C =

1
0
0
0
0
0
0
0
0
1

.
By checking the rank of [B AB A2B A3B A4B] and [C CA CA2 CA3 CA4],
the system is controllable and observable.
Open-Loop Step Response
The open-loop tension and velocity step responses are showed in Fig. 6.2. We can
see that velocity reach stable stale very quickly, but tension has much oscillation
and takes time to be stable. This response is consistent to that of real system.

6.2
Control of Shaping Process of Automobile Belt
313
Fig. 6.2 Open-loop step responses
6.2.2 State-Feedback and LQR Control
State feedback is applied in control
u = −Kx + Pr,
(6.8)
where K is a feedback matrix and P is the feed forward for tracking. We want to
design a state feedback to achieve good tracking and disturbance rejection ability.
6.2.3 Pole Placement
For ˙x = Ax + Bu and u = −Kx + Pr, we have
˙x = (A −BK)x + BPr.
(6.9)
Now we should properly choose the eigenvalues of A−BK so that the system is sta-
ble and can quickly reach the stable values. Although we can place the eigenvalues
at any places on the left hand of the polar plane because the system is controllable,
the outputs of the resulted controller may be too large to be realized in real system.
An optimal design method is to use LQR optimal control to get the feedback K.
6.2.4 LQR Optimal Control
The controller can be designed using MATLAB function “lqr”, which calculates
the optimal gain matrix K such that the state-feedback law u = −Kx minimizes the
cost function
J =
 ∞
0

xtqx + utru

dt.
(6.10)

314
6
Applications II
Fig. 6.3 Responses for both
step inputs under LQR
control
Choose
q =
⎡
⎢⎢⎢⎢⎣
1
0
0
0
0
0
10
0
0
0
0
0
10
0
0
0
0
0
10
0
0
0
0
0
1500
⎤
⎥⎥⎥⎥⎦
,
r =

1
0
0
1

.
Using MATLAB, this leads to
K =

 3263
4.737
−2183
9.477
36.06
398.2
0.3412
−274
6.456
2.495

.
With the simulation model in MATLAB “simulink” environment, we get the system
responses (shown in Fig. 6.3) for both step inputs of velocity and tension. The steady
values of the responses are adjusted by the feedforward P (3500 and 0.5) so that
they are between 60 N to 70 N for tension, and 16 to 22 radls (l5 Q∼2 IOrpm)
for velocity. From the ﬁgure, the responses seem to be pretty fast and stable, but the
controls have large initial negative values. For the control of magnetic powder brake,
no negative voltage is allowed. For DC motor source, it is better to use positive
voltage. So saturation elements were added in front of the controls to the system.
But the system becomes unstable with this saturation, as shown in Fig. 6.4. An
improved method is to use ramp velocity input with upper bounded. With trial-and-
error method for choosing the LQR parameters, batter results are gotten with
q =
⎡
⎢⎢⎢⎢⎣
0.05
0
0
0
0
0
10
0
0
0
0
0
10
0
0
0
0
0
10
0
0
0
0
0
1000
⎤
⎥⎥⎥⎥⎦
,
r =

1
0
0
100

,
K =

 5986
6.170
−3999
12.52
96.74
5.810
0.0045
−4.708
0.325
0.060


6.2
Control of Shaping Process of Automobile Belt
315
Fig. 6.4 Responses with
saturation
Fig. 6.5 System responses under ramp velocity input
and P are chosen with 6500 and 0.1. Figure 6.5 shows the results with these param-
eters. We can see that responses are pretty good and the controls have no negative
values.
6.2.5 Disturbance Rejection
To examine the disturbance rejection ability, some pulses are added to the velocity
input with amplitude 1 tenth of the upper value of the velocity input, as shown
in Fig. 6.6. Also some white noises are added to the controls Um and Uf to the
system. The system still has good ability to remove them as shown in Fig. 6.7, even
with large noise. We can see that the tension has also some jump noise, but returns
to original values very quickly. So it has fast regulation speed, but the control Um
has much larger value.

316
6
Applications II
Fig. 6.6 Disturbance (pulses and noise) testing
Fig. 6.7 Results of disturbance testing
6.2.6 Observer-Based Feedback
Figure 6.8 shows an observer-based state feedback control system. The full-order
observer takes it form as
˙ˆx = (A −GC)ˆx

B
G

u
y
t ,
(6.11)
ˆy = C ˙ˆx.
(6.12)
The system is observable so that the eigenvalues of the error dynamic matrix A −
GC could be assigned negatively. Normally we choose these eigenvalues with real
parts 3–5 times larger than the real parts of eigenvalues of P = A −BK. After
getting the estimated states ˆx, the state feedback control is realized. Figure 6.9 shows
the system step responses with real parts of eigenvalues of (A −GC) equal to 2
times of real parts of eigenvalues of (A −BK). Figure 6.10 shows the estimated
errors of the observer. We found that negative real part of eigenvalues of (A −GC)
should be properly selected, since too high negative real part of these eigenvalues
may cause the controls to oscillate. In this case, we found that 2 times of real parts
of eigenvalues of (A −BK) are appropriate.

6.2
Control of Shaping Process of Automobile Belt
317
Fig. 6.8 Observer-based state feedback
Fig. 6.9 Responses with full-order observer-based state feedback
Fig. 6.10 Estimated errors of full-order observer

318
6
Applications II
6.2.7 Reduced-Order Observer
Two states of the, system, x1 (velocity) and x5 (tension) can be directly measured
through the sensors so that we only need to estimate three other states. Therefore,
the reduced-order observer is applied and designed as following steps.
1) Consider the change of state coordinate: Z = Px. Let p =
 C
R

, C =
 1
0
0
0
0
0
0
0
0
1

and R can be chosen arbitrarily so that P 1 exists. Here we choose
R =
0
1
0
0
0
0
0
1
0
0
0
0
0
1
0

,
P =
⎡
⎢⎢⎢⎣
1
0
0
0
0
0
0
0
0
1
0
1
0
0
0
0
0
1
0
0
0
0
0
1
0
⎤
⎥⎥⎥⎦.
2) After changing the state coordinate, we have
˙Z = PAP −1Z + PBu = ¯AZ + ¯Bu,
(6.13)
y = CP −1Z = ¯CZ.
(6.14)
3) Now we partition ¯A and ¯B
¯A =

A11
A12
¯A21
¯A22

,
¯A11 =

−0.0625
−0.0938
24000
0

,
¯A12 =

0.938
0
0
0
−16000
0

,
¯A21 =
−3333
0
0
0.5
0
0

,
¯A22 =
−2.778
0
0
0
−0.05
−2.5
0
0
−12

,
¯B =

 ¯B1
¯B2

,
¯B1 =

0
0
0
0

,
¯B2 =
277.8
0
0
0
0
100

.
4) Then the reduced-order observer takes form of
˙V = ( ¯A22 −G ¯A12)V +

( ¯A22 −G ¯A12)G + ¯A21 −G ¯A11

y
+ ( ¯B2 −G ¯B1)u,
(6.15)
ˆZ =

 ˆZ1
ˆZ2

=

y
V + Gy

.
(6.16)
5) Finally, we get the estimated states
ˆx = P −1Z = Z.
(6.17)
The same as that in full-order observer, state feedback, control can be realized
by using ˆx. That is to place the eigenvalues of ¯A22 −G ¯Al2 at desired positions.
Figure 6.12 shows the results with the real part of eigenvalues of ¯A22 −G ¯A12
(3-element vector) equals to 5 times of real part of eigenvalues of {A −BK(2 : 4)}

6.2
Control of Shaping Process of Automobile Belt
319
Fig. 6.11 Reduced-order observer-based state feedback

320
6
Applications II
Fig. 6.12 Response of reduced-order observer-based state feedback
Fig. 6.13 Response of state-feedback system
(the 2nd, 3rd and 4th eigenvalues of the A −BK). Figure 6.13 shows the esti-
mated errors. We can see that the system responses are good, but the controls have
some noise, especially with the larger values of negative real parts of eigenvalues of
( ¯A22 −G ¯A12).
It was observed that there is less oscillation in the tension and velocity responses
when the negative eigenvalues of ( ¯A22 −G ¯A12) are chosen farther away from the
imaginary axis. However, when the eigenvalues are too far away from the imaginary
axis, the system may cause another problem: small high-frequency oscillation. And
it will even be unstable. So the real part of eigenvalues of ( ¯A22 −G ¯A12) should be
properly chosen.

6.3
An Unmanned Helicopter
321
6.3 An Unmanned Helicopter
An unmanned aerial vehicle (UAV) is an aircraft that ﬂies without a human crew
on board the aircraft. These vehicles have wide applications in remote sensing and
explorations. To distinguish UAVs from missiles, a UAV is deﬁned as a reusable, un-
crewed vehicle capable of controlled, sustained, level ﬂight and powered by a jet or
reciprocating engine. Therefore, cruise missiles are not considered UAVs, because,
like many other guided missiles, the vehicle itself is a weapon that is not reused,
even though it is also unmanned and in some cases remotely guided.
There are a wide variety of UAV shapes, sizes, conﬁgurations, and character-
istics. Historically, UAVs were simple drones (remotely piloted aircraft), but au-
tonomous control is increasingly being employed in UAVs. UAVs come in two va-
rieties: some are controlled from a remote location, and others ﬂy autonomously
based on pre-programmed ﬂight plans using more complex dynamic automation
systems.
Currently, military UAVs perform reconnaissance as well as attack missions [50].
While many successful drone attacks on militants have been reported, they are also
prone to collateral damage and/or erroneous targeting, as with many other weapon
types [50]. UAVs are also used in a small but growing number of civil applications,
such as ﬁreﬁghting or nonmilitary security work, such as surveillance of pipelines.
UAVs are often preferred for missions that are too “dull, dirty, or dangerous” for
manned aircraft.
6.3.1 Linearized Model
The numerical values of a linearized state-space model are given by [50]:
A =

A1
A2
A3
A4

,
A1 =
⎡
⎢⎢⎢⎢⎢⎢⎣
−0.126
0
0
0
0
−32.2
0
−0.425
0
0
32.2
0
−0.168
0.087
0
0
0
0
−0.082
−0.052
0
0
0
0
0
0
1
0
0
0
0
0
0
1
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
,
A2 =
⎡
⎢⎢⎢⎢⎢⎢⎣
−32.2
0
0
0
0
0
32.2
0
0
0
36.71
161.11
0
0
0
63.58
−19.49
0
0
0
0
0
0
0
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
,
A3 =
⎡
⎢⎢⎢⎢⎣
0
0
0
−1
0
0
0
0
−1
0
0
0
0
0
0
0
0
0
0
−1.33
0
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎦
,
A4 =
⎡
⎢⎢⎢⎢⎣
−3.444
0.829
0
0
0
0.361
−3.444
0
0
0
0
9.64
−0.76
8.42
0
0
0
0.057
−5.51
−44.873
0
0
0
1.816
−11.02
⎤
⎥⎥⎥⎥⎦
,

322
6
Applications II
B =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
−0.8417
2.8231
0
0
−2.4090
−0.3511
0
0
0
0
70.5041
0
0
0
23.6260
44.8734
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
Ct =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
1
0
0
0
0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
0
0
0
0
1
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
The open-loop eigenvalues are
−1.5725 ± 12.2567j,
−8.2845 ± 8.5844j,
−1.8659 ± 8.2757j,
0.2458 ± 0.0277j,
−0.5262 ± 0.0754j,
−0.7223
which means that the system is unstable.
6.3.2 Stabilization Schemes
To stabilize the system, one way is to employ a state-feedback controller, the gain of
which can be determined by using the pole-placement technique through MATLAB
software. With the desired eigenvalues being
−8.4, −8.3, −0.3, −0.6, −0.9, −1, −1.1, −1.9, −1.8, −1.7, −1.6
the gain matrix is given by
K = 10−3
×
⎡
⎢⎢⎣
3.9
−2.5
3.41
61.9
−38.4 −7.5 −544.8 −3045
0
−0.1
0.8
−5.6 12.8 127.5 −192.2
11
126
2695.5 −467.9
0
−0.5
2.7
−2.5
0.8
51.7
52.1
74.9
101.7
467.3
1061.4 12.1
92.1
144.9
1
0.8
−33.1 −64.5 −25.3 −91.9 −567.9
978.7
−5.2 −350.4 36.6
⎤
⎥⎥⎦.
The corresponding trajectories of the closed-loop state-feedback control system are
plotted in Fig. 6.13, which show that the stabilizing behavior.
6.4 Reverse Osmosis Desalination Plant
The production of fresh water for drinking, domestic, agricultural, landscape and
industrial uses by desalination of sea and brackish waters has become a major issue
in the regions suffering from the scarcity of natural fresh water supplies [18]. This
has resulted in a demand for the desalination systems. In the last years, signiﬁcant
advances in the membrane technology have allowed an essential improvement in
the ﬁltering quality and simultaneously a general reduction of costs such that Re-
verse Osmosis plants have today lower energy consumption, investment cost, space

6.4
Reverse Osmosis Desalination Plant
323
requirements and maintenance than other desalination methods such as distillation,
ion exchange and solar humidiﬁcation.
Reverse Osmosis (RO) is a process used for demineralization of water to clean
brackish water or to desalt seawater. When we try to separate pure water and a salt
solution through a semi permeable membrane, the pure water diffuses through the
membrane and dilutes the salt solution. The membrane rejects most of the dissolved
salts, while allowing the water to permeate. This phenomenon is known as natu-
ral osmosis. As water passes through the membrane, the pressure on the dilute side
drops, and the pressure of the concentrated solution rises. The osmotic ﬂux contin-
ues until equilibrium is reached, where the net water ﬂux through the membrane
becomes zero at equilibrium; the liquid level in the saline water will be higher than
that on the waterside. The amount of water passing in either direction will be equal.
The hydrostatic pressure difference achieved is equal to the effective driving force
causing the ﬂow, called osmotic pressure. This pressure is a strong function of the
solute concentration and the temperature, and depends on the type of ionic species
present. Applying a pressure in excess of the osmotic pressure to the saline water
section slows down the osmotic ﬂow, and forces the water to ﬂow from the salt solu-
tion into the waterside. Therefore, the direction of ﬂow is reversed, and that is why
this separation process is called reverse osmosis.
The process consists in recovering water from a saline solution pressurized by
pumping it into a closed vessel to a point greater than the osmotic pressure of the
solution. Thus, the solution is pressed against a membrane so that it is separated
from the solutes (the dissolved material). The portion of water that passes through
the membrane reducing strongly the solute concentration is called permeate. The
remaining water (re tented) is discharged with a high salt concentration.
Reverse osmosis (RO) plant is described in detail in [1, 2, 18]. It is shown that the
RO plant is modeled and a description about the modeling is given. In what follows,
a linear state space model proposed in [18] is utilized to design a control system.
Most of the RO plants includes a pre-treatment unit, where the salt concentration
of permeate (or also permeate conductivity) is controlled by adjusting the pH value
of the feed. However, plants for drink water puriﬁcation do not include pH control
and permeate conductivity is a non-controlled variable. In order to be able to adjust
the permeate conductivity, a bypass valve, which allows mixing a small amount of
feed water with permeate is included. This construction leads to a different system
topology, which has not been studied much.
With the increasing energy awareness and scarcity, it is becoming more desirable
to operate plants very close to target. That is over production and over puriﬁcation is
not economically justiﬁable if the plant can be operated closer to speciﬁcation. For
this purpose, controllers must be adapted in order to continuously and automatically
adjust operating conditions to meet variable demand. The performance of RO plants
is quite sensitive to the quality of the feed and plant operating conditions. This
means that a RO plant requires a very efﬁcient pretreatment process and an accurate
control system to maintain its operation close to the optimum conditions, which
results in increased productivity and prolongs the life of the membranes due to the
reduction of membrane fouling.

324
6
Applications II
6.4.1 Reverse Osmosis Modeling
A basic RO system normally consists of four main subsystems: pretreatment, high-
pressure pump, membrane assembly (RO unit) and post-treatment (see Fig. 6.14).
Salty feed water is ﬁrst pretreated to avoid membrane fouling. It then passes through
ﬁlter cartridges (a safety device) and is sent through the membrane modules (per-
meators) by a high-pressure pump. Because of the high pressure, pure water per-
meates through the membranes and the salty water becomes concentrated (retained
or brine). The water product ﬂows directly from the permeators into the post treat-
ment unit, and the retentate (at high pressure) is discharged, usually, after passing
through an energy recovery system. Pretreatment is important in RO plants because
suspended particles must be removed in order to maintain the membrane surfaces
continuously clean. Thus, pretreatment consists of ﬁne ﬁltration and the addition of
chemicals to inhibit precipitation and the growth of microorganisms. The pH value
of the feed water is also adjusted in this unit. The high-pressure pump supplies the
pressure needed to enable the water to pass through the membrane and have the salts
rejected. This pressure range is from 15 to 25 bars for drinking and brackish water
and from 54 to 80 bars for seawater. The membrane assembly consists of a pressure
vessel and several membrane units such that feed water is pressurized against the
membrane. The membrane must be able to resist the entire pressure drop across it.
The semi-permeable membranes vary in their ability to pass fresh water and reject
the passage of salts. Finally, the post-treatment consists of stabilizing the water and
preparing it for distribution. This post-treatment might consist of the removing gases
such as hydrogen sulﬁde, adding minerals and adjusting the pH value.
In a typical RO desalination plant, there are basically four variables of interest:
(1) ﬂow rate of permeate, (2) salt content of permeate, (3) trans-membrane pressure,
and (4) pH of feed water. The ﬁrst two outputs are obviously important because they
are production targets. Trans-membrane pressure must not be allowed to exceed an
upper limit since that could cause membrane rupture and the pH of feed water should
be within bounds to extend membrane life. Therefore, only the ﬁrst two variables are
selected as outputs as they are important. In the case of small plants, pretreatment
Fig. 6.14 Schematic of RO plant

6.4
Reverse Osmosis Desalination Plant
325
Fig. 6.15 Blockdiagram of
RO system
units are very simple and normally pH control of feed water is not implemented.
Permeate conductivity can be modiﬁed by using a bypass pipeline, which allows the
mix of a small amount of feed water with the product, if the quality requirements for
the product that allows for by recycling a small amount of retentate. The input/output
representation with feed water bypass is illustrated in Fig. 6.15.
The plant under consideration has a capacity in nominal operation of about
900 l/h (that is, 0.25 l/s) for an inlet of 0.625 l/s. The ﬂow rate of concentrate in
0.375 l/s, that is, 60% retentate and 40% permeate. The bypass ﬂow rate is about
8% of the feed water, that is, 0.04 l/s for the nominal operation. The range for per-
meate ﬂow rate is given by 0.021 l/s < qp < 0.433 l/s for a valve opening varying
between 100% < áp < 10%. Notice that this valve may not be close in order that
the plant works at all. The maximum water purity is obtained by a closed bypass
valve and a valve in the retentate stream closed up to 90% (10% valve opening).
The normal operating point is 50% valve opening for both valves. Under these con-
ditions, the permeate ﬂow rate is 0.250 l/s, the retentate 0.375 l/s and the permeate
conductivity 425 µS/cm (283 ppm). In order to put the set point, for example, at
0.20 l/s it is necessary to open the retentate valve up to 60%. Once the valve is ﬁxed
to this value it is not possible to modify this ﬂow rate by using the bypass valve. On
the contrary, modifying the bypass valve, the conductivity can be adjusted to other
reference value.
6.4.2 Linear Discrete Model
In terms of the system variables
Inputs:
• Retentate valve opening u1.
• Bypass valve opening as u2.
Outputs:
• Permeate ﬂow rate y1.
• Permeate conductivity as y2.
State variables:
• Temperature of feed water.
• Salinity of feed water.
• Pressure of retentate.
• Temperature of permeate.
• pH of feed water.

326
6
Applications II
• Pressure of permeate.
• Temperature of retentate.
• Salinity of retentate.
• pH of retentate.
A discrete-time state space linear model was obtained from sampled-data for a
sampling time of 0.15 s at the operating point mentioned above. The general equa-
tions are given by,
A =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
0.201
0.01
0
0
0
0
0
2e-4 −0.001
−3.301 −0.129
0
0
0
0
0
0.001
0.001
0
0
0.757
0
0
0
0
0
0.113
0
0
0
0.955
0.116
0
0
0.01 −0.062
0
0
0
−0.545 0.573
0
0
0.11 −0.606
0
0
0
0
0
0.859
0.056
0
0.004
0
0
0
0
0
−1.833 0.043
0
0.024
0
0
0
0
0
0
0
0.905
0
0
0
0
0
0
0
0
0
0.286
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
Bt =

−8.02e-5 −0.001
0
−0.002 −0.041
0
0
−0.632
0
−8.42e-5 −0.001 0.009 −0.002 −0.041 1.7e4 0.002
0
0.057

,
C =

222.53 12.46 0.668
0
0
0
0
0 0
0
0
0
−21.784 −7.624 1209.53 3705.56 0 0

.
The open-loop eigenvalues λ(A) are given by
0.0360 ± j0.0761, 0.7570, 0.7640 ± 0.1639j, 0.7535, 0.1485, 0.9050, 0.2860
which indicate that the discrete-time model is stable since all eigenvalues lies within
the unit disc in the complex plane. Moreover, the model is both controllable and
observable.
For the state-feedback control design, we employ MATLAB ﬁle place to compute
the gain matrix. By repeated application, we select the gain of least norm. This is
expressed by
K =

−10.089 0.330 −15.436 −0.237 −2.154
4.625
0.357
−1.398 −0.065
2.172
14.076
19.32
−1.511
0.261
−5.773 −0.436
0.169
3.133

,
and the associated closed-loop eigenvalues
0.036
0.1481
0.357
0.264
0.764
0.7535
0.35
0.2
0.276
.
The corresponding state trajectories are displayed in Figs. 6.16–6.20.
6.5 Turbocharged Diesel Engine
In recent years more stringent requirements on performance, fuel conservation and
low emissions have paved way for increased complicated engine performance.
Strategies like exhaust gas recirculation and turbo charging have been devised to

6.5
Turbocharged Diesel Engine
327
Fig. 6.16 Feedback
trajectories of states x1 and x2
Fig. 6.17 Feedback
trajectories of states x3 and x4
cope up with the requirements. These give us a great bit of freedom to control the
behavior of the engine. Previous practices used these in a suboptimal way since
the devices used to control these features affect many different parts of the engine

328
6
Applications II
Fig. 6.18 Feedback
trajectories of states x5 and x6
Fig. 6.19 Feedback
trajectories of states x7 and x8
through the cross-couplings in the system. The development of an optimal coordi-
nated strategy often takes more time than available in a production cycle. In order
to fully extract the potential of these devices, we consider this as a multivariable

6.5
Turbocharged Diesel Engine
329
Fig. 6.20 Feedback
trajectory of state x9
Fig. 6.21 Schematic diagram of the TDE model
control problem. A multivariable approach to this will yield a better performance.
Turbochargers mainly ﬁnd their applications in racing cars,automobiles, aircrafts
and gas turbines. Diesel (compression ignition) engines hold a signiﬁcant advan-
tage over spark ignited (gasoline) engines in fuel economy. Moreover, diesel engines
have lower feed-gas emissions of the regulated exhaust gases, but the after-treatment
devices for diesel engines are far less efﬁcient than the conventional three way cat-
alysts for spark ignition engines.
In this section, the plant to be controlled is a turbocharged passenger car diesel
engine equipped with exhaust gas recirculation and a variable geometry turbine as
shown in Fig. 6.21. Turbocharger increases the power density of the engine by forc-

330
6
Applications II
ing air into the cylinders, which allows injection of additional fuel without reaching
the smoke limit. The turbine, which is driven by the energy in the exhaust gas, has
a variable geometry that allows the adaptation of the turbine efﬁciency based on the
engine operating point. The second feedback path from the exhaust to the intake
manifold is due to the EGR, which is controlled by the EGR valve. The recirculated
exhaust gas replaces oxygen in the inlet charge, thereby reducing the temperature
proﬁle of the combustion and hence the emissions of oxides and nitrogen.
6.5.1 Dynamic Modeling
In terms of the data
A =

A1
A2
A3
A4

,
A1 =
⎡
⎣
−0.4125
−0.0248
0.0741
101.5873
−7.2651
2.7608
0.0704
0.0085
−0.0741
⎤
⎦,
A2 =
⎡
⎣
0.0089
0
0
2.8608
0
0
−0.0089
0
0.0200
⎤
⎦,
A3 =
⎡
⎣
0.0878
0.2672
0
−1.8414
0.0990
0
0
0
0
⎤
⎦,
A4 =
⎡
⎣
−0.3674
0.0044
0.3962
0
−0.0343
−0.0330
−359
187.5364
−87.0316
⎤
⎦,
B =
⎡
⎢⎢⎢⎢⎢⎢⎣
−0.0042
0.0064
−1.0360
1.5894
0.0042
0
0.1261
0
0
−0.0168
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
,
C =

0
0
0
0
0
3.6
0
0
0
1
0
0

.
Numerical simulation of the control designs using the linear-quadratic regulator
(LQR) and linear-quadratic Gaussian regulator (LQGR) are summarized in terms
of the feedback gains and the associated bounds:
Lℓqr =

−0.8195
−0.1731
−0.1973
1.1521
−0.9907
−0.0028
5.14277
0.3250
0.3654
0.7437
0.1943
0.0025

,
∥Lℓqr∥= 5.2748,
γ+ = 6.3472,
Lℓqgr =

−0.341
−0.0628
−0.0950
0.4114
−0.3772
−0.0009
1.9763
0.1176
0.1655
0.2696
0.0982
0.0009

,
∥Lℓqgr∥= 2.0334,
γ+ = 6.3472.
The numerical clearly suggests that the control design based on the mixed
H2/H∞yields the best compromise. However, it requires, excessive computations
compared with LQR, H2 and H∞. The corresponding state trajectories are plotted
in Figs. 6.22–6.27.

6.6
A Rotational Hydraulic Drive
331
Fig. 6.22 Response of state 1
Fig. 6.23 Response of state 2
Fig. 6.24 Response of state 3
6.6 A Rotational Hydraulic Drive
Modern internal combustion engines equipped with variable valve actuation systems
are proven to achieve better combustion characteristics. By appropriately varying
the valve timing, one can increase fuel economy, boost power output and reduce

332
6
Applications II
Fig. 6.25 Response of state 4
Fig. 6.26 Response of state 5
Fig. 6.27 Response of state 6
emissions [43]. Related studies are reported in [38, 51]. In particular, the problem
of optimizing plug-in hybrid electric vehicle (PHEV) power management is studied
in [38] by using stochastic dynamic over a distribution of drive cycles, rather than
a single cycle and explicitly trades off fuel and electricity usage. Linear feedback
controllers are developed in [33] for an electro-hydraulic valve system (EHVS) and

6.6
A Rotational Hydraulic Drive
333
a repetitive feed-forward controller is added to improve the tracking performance.
The problem of power management of hybrid electric vehicles (HEVs) is treated
in [28] via the Pontryagin’s minimum principle as a viable real-time strategy. By
employing performance index including fuel consumption, exhaust emission, or ac-
celeration performance over the whole driving-cycle information, global optimal
results are reported in [34]. Application of robust control design for the physical
geometric design of electrohydraulic valves is reported in [53], where it is shown
that viscosity effect is exclusively utilized in the nominal optimal design, whereas
both the viscosity effect and the non oriﬁce ﬂux effect are needed in the robust op-
timal design. In [12], two-controller structure is proposed for a generic EPS system
addressing motor torque and steering motion, by applying H2 and H∞design meth-
ods, respectively. An improved optimal control method based on the energy equation
of the controlled system is presented in [16]. The work [44] experimentally demon-
strates the implications of this trade off by applying a recently developed repetitive
controller design approach to reduce the error motion of the spindle’s axis of rotation
on an active air bearing setup. In [51], the problem of inventory control is studied
using high gain (sliding mode) adaptive control to handle the system uncertainties
caused by modeling errors and unmeasured disturbances.
On another research direction pertinent to the present paper, electro-hydraulic
servo-systems (EHSS) ﬁnd extensive industrial applications ranging from hydraulic
stamping, injection molding presses to aerospace ﬂight-control actuators. EHSSs
serve as highly efﬁcient drive systems because they posses a high power/mass ratio,
quick response, high stiffness and high load capabilities. To maximize the advan-
tages of hydraulic systems and to meet increasingly precise performance with high
accuracy and fast response, high performance servo controllers are required. How-
ever, traditional linear controllers have performance limitations due to the presence
of nonlinear dynamics in EHSS, speciﬁcally, a square-root relationship between the
differential pressure that drives the ﬂow of the hydraulic ﬂuid, and the ﬂow rate. To
achieve near-optimality, keep the methodology simple.
6.6.1 System Model
The system under consideration for this study is a rotational hydraulic drive and
the set-up is generic and allows for ample extension of the results herewith to
other electro-hydraulic systems including double-acting cylinders [8]. Referring to
Fig. 6.28, a DC electric motor drives a pump, which delivers oil at a constant supply
pressure from the oil tank to each component of the system. The oil is used for the
operation of the hydraulic actuator and is returned through the servo-valve to the oil
tank at atmospheric pressure. An accumulator and a relief valve are used to main-
tain a constant supply pressure from the output of the pump. The electro-hydraulic
system includes two Moog Series 73 servo-valves which control the movement of
the rotary actuator and the load torque of the system. These servo valves are oper-
ated by voltage signals generated by an Opal-RT real-time digital control system.
The actuator and load are both hydraulic motors connected by a common shaft. One
servo-valve regulates the ﬂow of hydraulic ﬂuid to the actuator and the other reg-

334
6
Applications II
Fig. 6.28 Functional diagram
ulates the ﬂow to the load. The actuator operates in a closed-loop while the load
operates open-loop, with the load torque being proportional to the command volt-
age to the load servo-valve. While the actuator and load chosen for this study are
rotary drives, the exact same set-up could be used with a linear actuator and load,
and thus, they are represented as generic components in Fig. 6.28.
Using the angular displacement, angular velocity, differential pressure P1 and
differential pressure P2 as the system states, the signals from servo valves 1, 2 as
the control inputs whereas the angular velocity and angular displacement as the
outputs, a linearized model of an electro-hydraulic system about the origin (x1 = 0,
x2 = 0, x3 = 0, x4 = 0) can be cast into the form
˙x = Ax + Bu,
(6.18)
y = Cx,
A =
⎡
⎢⎢⎣
0
ωM
0
0
0
−γ Ωh/α
Ωh/α
0
0
−αΩh
−ΩhcL
αΩh
0
0
0
−1/τv
⎤
⎥⎥⎦,
(6.19)
B =
⎡
⎢⎢⎣
0
0
0
−Ωh/α
0
0
1/τv
0
⎤
⎥⎥⎦,
Ct =
⎡
⎢⎢⎣
0
1
ωM
1
0
1
0
1
⎤
⎥⎥⎦.
Using typical data [26, 40], the different parameters are τv = 0.01 s, ωM =
173.45 r/s, α = 4.7408 s, cL = 0.077, γ = 0.5432, ωh = 138.68 r/s. By evaluat-
ing the model matrices given by (4.70), it is readily seen that the linearized system
is unstable as it has eigenvalue at the origin and has internal oscillations due to a
pair of complex.

6.6
A Rotational Hydraulic Drive
335
6.6.2 LQR: Continuous and Discrete Control
With Q = 10 × I4, R = I2, the output response is depicted in Fig. 6.29. Typical
simulation results are plotted in Figs. 6.30–6.33 for three sets of Q matrix with
R = I2. With respect to the norm of the gain matrix and the time taken by the states
to settle to steady state, it is concluded that the case (ii) has yielded optimum results.
In case (i), the number of oscillations in the states are more. Whereas, moving from
case (ii) to case (iii), there is no signiﬁcant reduction in the number of oscillations.
There is a decrease in the settling time of the states, but the gain K is increasing
signiﬁcantly. In the step response of the system, we observe that in each case the
second output of the system, that is, the angular velocity settles to zero after a ﬁnite
interval of time despite the input being at unit step. This is because the signal from
the two servo valves is treated as a positioning input. This means that if any constant
input is applied at either of the inputs of the system, the actuator shaft moves to a
distinct position and stops. Its angular position remains at that ﬁnite value while the
angular velocity reduces to zero when the actuator shaft has stopped moving.
Fig. 6.29 Output response
Fig. 6.30 Comparison of
state x1

336
6
Applications II
Fig. 6.31 Comparison of
state x2
Fig. 6.32 Comparison of
state x3
Fig. 6.33 Comparison of
state x4
Turning now to the discrete LQR. The continuous system matrices were sampled
at a rate of 0.01 seconds to obtain the discrete model. Simulation was carried out
such that the weight on the inputs was kept constant and the weight on the states was
varied to study the behavior of the system in three different cases. Optimum results

6.6
A Rotational Hydraulic Drive
337
Fig. 6.34 Step response of
system using DLQR
Fig. 6.35 Comparison of
state x1 trajectories
were found using the following weighting matrices: Q = 10 ∗I4×4, R = I2×2, the
output response is depicted in Fig. 6.34.
Of all the 3 cases simulated above, it is noted that the controller gain K is the
largest in the third case, while the settling time is the least in the third case. Hence,
as we increase the controller gain, the settling time decreases. The response of the
DLQR regulator is similar to the LQR regulator, the only difference being the control
that is applied at discrete instants equal to the sampling time of the system model.
Just as in the continuous LQR all the have been weighted equally in each case while
implementing the discrete regulator. In the above simulation, the matrix R was used
to weight the control input applied. The matrix Q was used to weight the states of
the system. Typical simulation results are plotted in Figs. 6.35–6.38 for three sets of
Q matrix with R = I2.

338
6
Applications II
Fig. 6.36 Comparison of
state x2 trajectories
Fig. 6.37 Comparison of
state x3 trajectories
6.7 The Falling Film Evaporator
Based on the system description in the foregoing chapter, the numerical values of
the system matrices are given by:
A =
⎡
⎢⎢⎢⎢⎢⎢⎣
0.9704
0.0043
−0.0170
0.0003
0.0532
−0.0197
−0.0026
0.9415
−0.0719
0.1236
0.0009
0.0520
0.0110
0.1548
0.9501
−0.0793
−0.0004
0.0078
−0.0045
−0.1885
0.1947
0.8364
−0.0154
−0.3347
−0.1001
−0.0280
0.0252
−0.0889
0.8270
0.1096
0.0730
−0.0335
0.0432
−0.0503
0.2329
0.0905
⎤
⎥⎥⎥⎥⎥⎥⎦
, (6.20)

6.7
The Falling Film Evaporator
339
Fig. 6.38 Comparison of
state x4 trajectories
B =
⎡
⎢⎢⎢⎢⎢⎢⎣
−0.0001
0.0001
0.0028
−0.0050
0.0015
0.0001
0.0049
−0.0005
0.0009
−0.0062
0.0001
0.0005
−0.0034
−0.0015
0.0025
−0.0030
0.0005
−0.0084
⎤
⎥⎥⎥⎥⎥⎥⎦
,
(6.21)
C =
⎡
⎣
18.4197
28.9777
34.3101
5.3853
2.0093
0.9821
−6.2863
−46.2754
7.2586
21.0611
0.0672
15.1997
−52.2695
0.3603
−0.1112
0.7214
0.6543
−0.0106
⎤
⎦. (6.22)
6.7.1 State Feedback Design
In what follows, we provide the simulation results of state-feedback design. We start
with the continuous case:
A. Continuous Case: The pole placement method was used for the design of state
feedback using MATLAB along with the desired eigenvalues as
v =
−1
−2
−3
−2.5
−1.5
−5
.
(6.23)
This yields the feedback gain matrix as
K = 103
⎡
⎣
−0.7351
0.0164
0.7176
0.5049
−0.3379
−0.2327
−2.9280
4.7762
6.1816
0.6691
1.0067
0.2010
0.2584
0.5098
0.6744
−0.0169
0.2578
0.0672
⎤
⎦.
(6.24)
The ensuing state trajectories of the closed-loop system are depicted in Figs. 6.39,
6.40, 6.41.
B. Discrete Case: Using a sampling period of 0.1 s, and performing similar MAT-
LAB simulation, the obtained results are plotted in Figs. 6.42, 6.43, 6.44.

340
6
Applications II
Fig. 6.39 Trajectory of state variables x1 (left) and x2 (right): Continuous-case
Fig. 6.40 Trajectory of state variables x3 (left) and x4 (right): Continuous-case
Fig. 6.41 Trajectory of state variables x5 (left) and x6 (right): Continuous-case

6.7
The Falling Film Evaporator
341
Fig. 6.42 Trajectory of state variables x1 (left) and x2 (right): Discrete-case
Fig. 6.43 Trajectory of state variables x3 (left) and x4 (right): Discrete-case
Fig. 6.44 Trajectory of state variables x5 (left) and x6 (right): Discrete-case

342
6
Applications II
Fig. 6.45 Trajectory of state variables x1 (left) and x2 (right): Continuous observer-based
6.7.2 Observer Feedback Design
Now, we provide the simulation results of observer-based feedback design and start
with the continuous case:
A. Continuous Case: In addition to the state-feedback design results, the eigenval-
ues for the observer is taken as
v2 =
−1
−2
−3
−2.5
−1.5
−5
.
(6.25)
This yields the observer gain matrix as,
L =
⎡
⎢⎢⎢⎢⎢⎢⎣
−0.0083
−0.0412
−0.1470
0.4337
−0.8842
0.3158
−0.3959
1.0391
−0.1852
1.6329
−2.3090
1.5799
−1.4840
0.4975
−3.8431
−0.8085
0.6047
−1.1962
⎤
⎥⎥⎥⎥⎥⎥⎦
.
(6.26)
The associated simulation results of the continuous case are plotted in Figs. 6.45,
6.46, 6.47.
B. Discrete Case: In what follows, we present the simulation results of the discrete
case, see Figs. 6.48, 6.49, 6.50.
6.7.3 LQR Designs
A. Continuous Case: In what follows, we present the simulation results of the con-
tinuous case, see Figs. 6.51–6.54.
B. Discrete Case: In what follows, we present the simulation results of the discrete
case, see Figs. 6.55–6.58.

6.7
The Falling Film Evaporator
343
Fig. 6.46 Trajectory of state variables x3 (left) and x4 (right): Continuous observer-based
Fig. 6.47 Trajectory of state variables x5 (left) and x6 (right): Continuous observer-based
Fig. 6.48 Trajectory of state variables x1 (left) and x2 (right): Discrete observer-based

344
6
Applications II
Fig. 6.49 Trajectory of state variables x3 (left) and x4 (right): Discrete observer-based
Fig. 6.50 Trajectory of state variables x5 (left) and x6 (right): Discrete observer-based
Fig. 6.51 Trajectories of input u1 (left) and input u2 (right): Continuous LQR

6.7
The Falling Film Evaporator
345
Fig. 6.52 Trajectory of
input u3: Continuous LQR
Fig. 6.53 Trajectory of output y1 (left) and output y2 (right): Continuous LQR
Fig. 6.54 Trajectory of
output y3: Continuous LQR

346
6
Applications II
Fig. 6.55 Trajectories of input u1 (left) and input u2 (right): Discrete LQR
Fig. 6.56 Trajectory of
input u3: Discrete LQR
Fig. 6.57 Trajectories of output y1 (left) and output y2 (right): Discrete LQR

6.8
Vapor Compression Cycle Systems
347
Fig. 6.58 Trajectory of
output y3: Discrete LQR
Fig. 6.59 Trajectories of input u1 (left) and input u2 (right): Tracking control
6.7.4 Tracking Control
The simulation results are depicted in Figs. 6.59–6.63.
6.8 Vapor Compression Cycle Systems
In what follows, the identiﬁed state-space models [A,B,C,D] based on two distinct
cases: a) two output pressures and b) four output temperatures.
6.8.1 Model with Two Output Pressures
The state-space model based on two output pressures are given below. We note that
the differential pressure, rather than actual pressures P2 was used for identiﬁcation.

348
6
Applications II
Fig. 6.60 Trajectory of
input u3: Tracking control
Fig. 6.61 Trajectories of output y1 (left) and output y2 (right): Tracking control
A =

A1
A2
A3
A4

,
A1 =
⎡
⎣
0.9284
0.0352
0.2495
−0.0029
0.5362
−0.3899
0.2765
−0.2607
−0.1668
⎤
⎦,
A2 =
⎡
⎣
0.0821
0.2620
0.0920
0.5040
0.0600
−0.3541
−0.1809
−0.1152
−0.5602
⎤
⎦,
A3 =
⎡
⎣
0.1730
0.5656
−0.1452
−0.0759
−0.2315
0.1099
−0.0635
0.1477
0.3053
⎤
⎦,
A4 =
⎡
⎣
−0.0886
−0.6043
0.0872
0.3524
−0.8646
−0.0532
−0.0822
−0.0022
−0.7786
⎤
⎦,

6.8
Vapor Compression Cycle Systems
349
Fig. 6.62 Trajectory of
output y3: Tracking control
B =
⎡
⎢⎢⎢⎢⎢⎢⎣
−0.0101
−0.0001
0.0377
0.0094
−0.0000
0.0313
0.0500
0.0004
−0.6057
0.0242
0.0003
−0.3703
−0.0143
−0.0002
1.1068
0.0288
0.0004
0.1241
⎤
⎥⎥⎥⎥⎥⎥⎦
,
C =
C1
C2

,
C1 =

267.7117
88.6283
19.3981
88.3195
−236.8275
61.0602

,
C2 =

 54.6803
26.2659
2.4993
−73.9526
−30.2428
37.3458

,
D =

0
0
0
0
0
0

.
6.8.2 Model with Four Output Temperatures
In this case, the identiﬁed state-space [A,B,C,D] system model is based on four
output temperatures and is given below.
A =
⎡
⎢⎢⎣
0.9953
0.0002
0.0024
0.0004
−0.0024
0.9955
0.0003
−0.0096
−0.0032
−0.0087
0.9705
0.0131
−0.0093
−0.0262
−0.0137
0.8923
⎤
⎥⎥⎦,
B =
⎡
⎢⎢⎣
−0.0003
−0.0000
0.0273
−0.0002
0.0000
0.0260
−0.0007
0.0000
−0.1399
−0.0018
0.0001
0.1591
⎤
⎥⎥⎦,

350
6
Applications II
Fig. 6.63 State trajectories of system using LQR
C =
⎡
⎢⎣
71.4946
9.8191
−6.6912
1.7531
−14.0400
31.8341
−4.8913
0.8771
−12.8821
−0.9395
−3.9774
7.0485
−22.2656
−10.7576
−11.4903
−1.8273
⎤
⎥⎦.
In the following, we present the results of simulating the closed-loop system with
two output pressures using different controllers. The corresponding results for the
case with four output temperatures are left as an exercise for the reader.
6.8.3 LQR Simulation Results: Continuous Case
For the simulation, we selected the weighting matrix R was kept constant and the
matrix Q was varied in three different cases. The optimum results were obtained at
Q = 10×I4×4, R = I2×2, which yields ∥K∥= 1.1889×104, Tr(P) =7.1017 ×107.
In our system, the six states have the same amount of signiﬁcance. Hence, they
have been weighted equally in each case. In the above simulation, the matrix R was
used to weight the control input applied. The matrix Q was used to weight the states
of the system. Simulation was carried out such that the weight on the inputs was kept
constant and the weight on the states was varied to obtain the optimum results.
With respect to the norm of the gain matrix and the time taken by the states to
settle to steady state, it is concluded that the case (iii) has yielded optimum results.
In case (i), the number of oscillations in the states are more. Whereas, moving from
case (ii) to case (iii) there is signiﬁcant reduction in the number of oscillations.
There is a decrease in the settling time of the states, but the gain K is increasing

6.8
Vapor Compression Cycle Systems
351
Fig. 6.64 Comparison of
state x1
Fig. 6.65 Comparison of
state x2
Fig. 6.66 Comparison of
state x3
correspondingly. However, keeping in mind the stability of the system, case (iii) was
found to be most suitable. The corresponding plots of state trajectories are presented
in Figs. 6.64–6.69.

352
6
Applications II
Fig. 6.67 Comparison of
state x4
Fig. 6.68 Comparison of
state x5
Fig. 6.69 Comparison of
state x6
6.8.4 LQR Simulation Results: Discrete Case
Simulation was carried out such that the weight on the inputs was kept constant and
the weight on the states was varied to study the behavior of the system in three dif-
ferent cases. Optimum results were found using the weighting matrices Q = I4×4,
R = I2×2. It is found that ∥K∥= 1.1294 × 104, Tr(P) = 7.1082 × 107.

6.9
Stabilization of F-8 Fly-by-Wire Aircraft
353
Fig. 6.70 State trajectories of system using DLQR
Of all the three cases simulated above, it is noted that the controller gain K is
the largest in the third case, while the settling time is also the least in the third case.
Hence, as we increase the controller gain, the settling time decreases. The response
of the DLQR regulator is similar to the LQR regulator, the only difference being the
control that is applied at discrete instants equal to the sampling time of the system
model.
Just as in the continuous LQR all the have been weighted equally in each case
while implementing the discrete regulator. In the above simulation, the matrix R
was used to weight the control input applied. The matrix Q was used to weight the
states of the system.
6.9 Stabilization of F-8 Fly-by-Wire Aircraft
NASA has been conducting research in digital ﬂy-by-wire technology in a program
called the NASA F-8 Digital Fly-By-Wire Program (DFBW). The broad objective of
this program is to provide the technology required for implementation of advanced,
reliable, DFBW ﬂight control systems which will permit greater operational capa-
bility and increased performance of future aircraft. This program is being conducted
jointly by the Dryden Flight Research Center, Edwards, CA, and the Langley Re-
search Center, Hampton, VA. The program makes use of a test aircraft, an F-8 Cru-
sade naval ﬁghter aircraft, which has been modiﬁed by removal of the mechanical
ﬂight control system and its replacement with an electronic ﬂight control system. In
this modiﬁcation, the pilot’s mechanical linkages to primary actuator slide valves on
the aircraft’s control surfaces were replaced by electrical connections to secondary
electro-hydraulic actuators which are then used to operate the primary actuator slide

354
6
Applications II
valves. The program has been conducted in two phases. In Phase I [I], pilot accept-
ability and technical feasibility of digital ﬂy-by-wire were explored using a single
channel digital system constructed from components previously developed for the
Apollo Space Program. The objectives of Phase I1 are to establish a design base for
practical multiple channel DFBW systems using a triplex digital system designed
around three state-of-the-art, off-the-shelf digital ﬂight computers, to ﬂight test the
system and certain selected space shuttle ﬂight control system concepts, and to con-
duct research into and evaluate advanced control law concepts suitable for digital
implementation. A triplex analog ﬂy-by-wire backup control system has been used
in both phases to provide increased reliability and safety of ﬂight. Phase I ﬂights
were completed in the fall of 1973. Phase I1 ﬂights commenced in August 1976 and
will continue for about two years. The role of Langley Research Center in this pro-
gram, which will be discussed herein, has been to investigate and promote advanced
control laws for possible ﬂight experimentation. This work is motivated by the much
greater ﬂexibility and logic capability of digital systems as compared to analog sys-
tems and by the increased complexity and sophistication expected of future aircraft
ﬂight control systems. Future control systems are expected to provide active control
for modes of motion that are today either accomplished passively or not at all. For
example, active controls for control conﬁgured vehicles (CCV) are being proposed
to provide control over aircraft which are statically unstable aerodynamically, to
modify span-wise wing lift distribution to reduce drag or provide structural load re-
lief during high g maneuvering ﬂight, to provide lower acceleration levels for pilot
and passengers during wind turbulence, to provide ﬂutter mode control, etc. Lan-
gley has promoted the integration of such concepts into an advanced control law
package suitable for ﬂight test. Flight tests of such a package, described in 121, will
be conducted early in the Phase I1 program. Langley has also promoted advanced
control concepts based on adaptation of the control system to the changing external
environment of the airplane or to the failure of control system components internal
to the aircraft. The purpose of this paper is to provide background material for the
adaptive control law study papers that follow.
6.9.1 Linearized Model
We have relied on references [5, 19] for the following nonlinear model for the F8
aircraft longitudinal ﬂight dynamics. The desired operating point corresponds to
an altitude of 30,000 ft, again as in the references [5, 19]. The lift coefﬁcients are
complicated nonlinear functions of the angles of attack and elevator angle. For sim-
plicity, we have again followed references [5, 19].
The F-8 is an “old-fashioned” aircraft that has been used by NASA as part of their
digital “ﬂy-by-wire” research program. We have modiﬁed the equations of motion
by including a large “ﬂaperon” on the wing so as to obtain two control variables in
the longitudinal dynamics of the F-8. This ﬂaperon does not exist in the F-8 aircraft.
However, such surfaces exist in other recent aircraft, for example, the X-29, and
provide some additional ﬂexibility for precision maneuvers.

6.9
Stabilization of F-8 Fly-by-Wire Aircraft
355
It has been assumed that the aircraft is ﬂying at a constant altitude in equilib-
rium ﬂight allows us to linearize the nonlinear equations of motion. In doing so, the
longitudinal dynamics decouple from the lateral dynamics. The variables needed to
characterize the longitudinal motion are as follows:
• Horizontal velocity v(t),
• Pitch angle ϑ,
• Pitch rate, q = ˙ϑ,
• Angle of attack α,
• Flight path angle β = ϑ −α,
• Elevators δe(t), and
• Flaperons δf (t).
The measurements are the pitch and ﬂight path angles, y(t) = [ϑ β]. The effect of
wind gust disturbances, which primarily corrupt the angle of attack, is modeled as
the output of a shaping ﬁlter driven with unit intensity white noise, d(t).
The stabilization of the nonlinear airplane could be achieved in principle also by
using linear feedback. The linearized, longitudinal equations of the F-8 aircraft are
as follows:
˙x(t) = Ax(t) + Bu(t) + Ld(t),
y(t) = Cx(t) + v(t),
where
A =
⎡
⎢⎢⎢⎢⎣
0.0
0.0
1.0
0.0
0.0
1.50
−1.50
0.0
0.0057
1.50
−12.0
12.0
−0.60
−0.0344
−12.0
−0.852
0.290
0.0
−0.0140
−0.290
0.0
0.0
0.0
0.0
−0.730
⎤
⎥⎥⎥⎥⎦
,
B =
⎡
⎢⎢⎢⎢⎣
0.00
0.00
0.16
0.80
−19.0
−3.0
−0.0115
−0.0087
0.00
0.00
⎤
⎥⎥⎥⎥⎦
,
Ct =
⎡
⎢⎢⎢⎢⎣
1
0
0
1
0
0
0
0
0
0
⎤
⎥⎥⎥⎥⎦
,
L =
⎡
⎢⎢⎢⎢⎣
0.00
0.00
0.00
0.00
1.1459
⎤
⎥⎥⎥⎥⎦
,
x(t) =
⎡
⎢⎢⎢⎢⎣
ϑ(t)
β(t)
q(t)
ν(t)
xd(t)
⎤
⎥⎥⎥⎥⎦
and v(t) is white noise with an Intensity of μ = 0.01 deg2/s.
6.9.2 Simulation Results
The following are the MATLAB simulation results of the control techniques ap-
plied for the “f-8 ﬂy-by-wire” aircraft stabilization. Each set of seven graphs in-

356
6
Applications II
Fig. 6.71 LQR results
cludes graphs of the ﬁve states and two graphs of the controller inputs. Simulation
results have been shown for the linear quadratic regulator control (LQR) and linear
quadratic Gaussian control (LQGR).
It can be observe that the two control schemes are stabilizing the aircraft, however
the LQG control has yielded the most suitable path with long period. On the other
hand, depending upon the tolerance level of the state variables, the LQR Control
seems to be the most unsuitable method of stabilizing the aircraft with a high over-
shoot factor which can lead the aircraft to a stall region. The corresponding state
trajectories are plotted for LQR in Fig. 6.71 and LQGR in Fig. 6.72.
6.10 Air Conditioning System
A linearized dynamic model for a direct expansion (DX) A/C system was utilized.
The physical system consists of six states, two inputs and two outputs. The model
was developed to be able to capture the transient characteristics of the DX A/C sys-
tem. This paper represents the work of designing different types of controllers such
as State-feedback, Observer-based feedback, tracking control and integral control.
The simpliﬁed schematic of the model is shown in Fig. 6.73.
The dynamic model, written in state-space representation which was suitable
for designing multivariable control, was linearized at steady state operating points.
The linearized model has been validated by comparing the model simulation results
with the experimental data obtained from an experimental DX A/C system. The
developed model was used in designing different multi-input multi-output (MIMO)
controllers to simultaneously control indoor air temperature and humidity in a space
served by a DX A/C system.

6.10
Air Conditioning System
357
Fig. 6.72 LQGR results
Fig. 6.73 The schematic diagram of the experimental DX A/C system
The system matrices A, B and C are as follows:
A =
⎡
⎢⎢⎢⎢⎢⎢⎣
−5.731
0
0.0756
4.1883
−5287
5287
0.0045
−0.0045
0
0
0
0
0
4.6577
−12.692
8.0346
0
0
0.0139
0.0067
0.0206
−0.0412
0
0
0.00016
0
0
0
0
0
0
0
0
0
0.0045
−0.0045
⎤
⎥⎥⎥⎥⎥⎥⎦
,

358
6
Applications II
B =
⎡
⎢⎢⎢⎢⎢⎢⎣
55.035
0
−0.098
0
172.5
0
0
−5.931
0
0
−0.00003
0
⎤
⎥⎥⎥⎥⎥⎥⎦
,
C =

0
1
0
0
0
0
0
0
0
0
0
1

.
All the eigenvalues of the system have the negative real parts, so that the DX A/C
system represented by the linearized model was asymptotically stable.
λ =
⎡
⎢⎢⎢⎢⎢⎢⎣
−12.7050
−5.5902
−0.1436
−0.0299
−4.6144e-16
−0.0045
⎤
⎥⎥⎥⎥⎥⎥⎦
.
(6.27)
The system is fully controllable with rank 6. Also, it is observable with rank 6.
6.10.1 State-Feedback
With state space design, we remain in the time domain and thus work directly with
the differential equation model of our plant. It is important to realize that whether
we work with transfer functions or with differential equations in state space form,
the mathematics describes the same thing and the forms can be interchanged. The
major advantage however of working with a state space model of a system is that
the internal system state is explicitly maintained over time, where as with a transfer
function, only the input output relationship is maintained.
We would like to design a controller such that the closed loop poles are at certain
desired locations. So we deﬁne the desired pole locations. Using MATLAB, we got
the gain matrix K. The closed state feedback response to step change is shown in
Fig. 6.74. The characteristic polynomial for this closed-loop system is the determi-
nant of (sI −(A −BK)). Since the matrices A and B ∗K are both 6 by 6 matrices,
there will be 6 poles for the system. By using full-state feedback, we can place the
poles anywhere we want. We could use the MATLAB function place to ﬁnd the
control matrix, K, which will give the desired poles.
K has as many elements (degrees of freedom) as there are poles. This means that
we can place the closed loop poles anywhere as long as the system is controllable
from the input. Calculating the feedback gain matrix K and then converting the gain
back so that it is applicable to the original state vector. It uses the extra degrees of
freedom provided by these inputs to not only place the eigenvalues of the closed
loop system but to also ‘shape’ the eigenvectors such that the closed loop system is
‘well-conditioned’.

6.10
Air Conditioning System
359
Fig. 6.74 Output trajectories
by state-feedback controller
6.10.2 Observer-Based Feedback
Previously, we designed controllers using full state feedback. The state however is
not usually directly available through measurements. The idea behind the estimator
is to place a model of the plant in parallel with the actual plant and to drive them
both with the same input. If the model’s initial state vector is set equal to the plant’s
initial state vector then the state estimate (generated by the model) will track the
actual state vector. However, there are always uncertainties in the plant model and
in practice, without feedback, the state estimate would diverge from the true state.
The solution is to use the measurement y(t) and to compare it with the model’s
predicted measurement and use the difference between the two to modify the state
estimate in such a way that it converges to the true state vector. We can build an
observer to estimate them, while measuring only the output y(t) = Cx(t).
The observer is basically a copy of the plant; it has the same input and almost
the same differential equation. An extra term compares the actual measured output
y(t) to the estimated output; this will cause the estimated states ˆx(t) to approach the
values of the actual states x(t). The error dynamics of the observer are given by the
poles of (A −L ∗C).
First, we need to choose the observer gain L. Since we want the dynamics of
the observer to be much faster than the system itself, we need to place the poles
at least ﬁve times farther to the left than the dominant poles of the system. If we
want to use place, we need to put the three observer poles at different locations. The
corresponding state trajectories are plotted in Fig. 6.75.
6.10.3 Tracking Control
Recall the state space feedback, we don’t compare the output to the reference; in-
stead we measure all the states, multiply by the gain vector K, and then subtract this
result from the reference. There is no reason to expect that K ∗x(t) will be equal

360
6
Applications II
Fig. 6.75 State trajectories by observer-based controller
Fig. 6.76 Output trajectories
by tracking controller
to the desired output. To eliminate this problem, we can scale the reference input to
make it equal to K ∗x(t) steady state. This scale factor is often called Nbar. If we
want to ﬁnd the response of the system under state feedback with this introduction
of the reference, we simply note the fact that the input is multiplied by this new
factor, Nbar. Now a step can be tracked reasonably well. The corresponding state
trajectories are plotted in Fig. 6.76.

6.11
Three-Degree-of-Freedom Helicopter Model
361
6.11 Three-Degree-of-Freedom Helicopter Model
Predictive control strategies have been widely used in industry for their ability to
handle operational constraints. It is known that the presence of disturbances may
cause predictive controllers to lose feasibility and to violate system constraints. This
section addresses the implementation of a state-space predictive control law with
restricted constraints to ensure feasibility and constraint fulﬁllment in spite of the
existence of unknown but bounded disturbances.
6.11.1 Linearized Model
In the sequel, we consider a nonlinear, sixth order, three-degree-of-freedom (3DOF)
helicopter model, see Fig. 6.77. Our objective is to achieve state regulation subject
to bounded disturbances as well as state and control polyhedral constraints. The
constraints on the maneuvering space are assumed to be convex polyhedral sets. As
illustrated in [35, 36], the model is composed by the helicopter body, which is a
small arm with one propeller at each end, and the helicopter arm, which connects
the body to a ﬁxed base. Although the system cannot exhibit translational motion, as
it is ﬁxed in a support, it can rotate freely about three axes. The helicopter position
is characterized by the pitch, travel and elevation angles. The pitch movement cor-
responds to the rotation of the helicopter body about the helicopter arm, the travel
movement corresponds to the rotation of the helicopter arm about the vertical axis
and the elevation movement corresponds to the rotation of the helicopter arm about
the horizontal axis. The control variables are the input voltages to the power ampli-
ﬁers that drive each one of the two DC motors connected to the helicopter propellers.
The maximum input voltage to the ampliﬁers is 5 V. Three digital encoders provide
measurements of the helicopter angles. Encoder resolution is about 0.044° for travel
Fig. 6.77 Quanser 3DOF helicopter

362
6
Applications II
Fig. 6.78 Trajectories of
pitch angle
Fig. 6.79 Trajectories of
pitch rate
angle and 0.088° for pitch and elevation angles. The original nonlinear model has
x1 is the pitch angle (in rad), x2 is the pitch rate (in rad/s), x3 is the elevation angle
(in rad), x4 is the elevation rate (in rad/s), x5 is the travel angle (in rad), x6 is the
travel rate (in rad/s), u1 is the front motor ampliﬁer input voltage (in V), and u2 is
the back motor ampliﬁer input voltage (in V).
An approximate linear model obtained by applying a ﬁrst-order Taylor series
expansion around a given equilibrium point ¯x = [0 0
−0 : 122 0 0 0]t, ¯u =
[2.804,2.804]t, which corresponds to helicopter hovering seven degrees below the
horizontal, can be expressed as:
˙ˆx =
⎡
⎢⎢⎢⎢⎢⎢⎣
0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
1
0
0
0
0
−1.192
0
0
0
0
1
0
0
0
1
−1.257
0
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
ˆx +
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
2.806
−2.806
0
0
0.395
0.395
0
0
0
0
⎤
⎥⎥⎥⎥⎥⎥⎦
ˆu.
The corresponding state trajectories are plotted in Figs. 6.78–6.83 for different
cases.

6.12
PID Control of a Quadrotor Unmanned Air Vehicle
363
Fig. 6.80 Trajectories of
elevation angle
Fig. 6.81 Trajectories of
elevation rate
Fig. 6.82 Trajectories of
travel angle
6.12 PID Control of a Quadrotor Unmanned Air Vehicle
A Quadrotor, also called a Quadrotor helicopter or Quadrocopter, is an aircraft that
is lifted and propelled by four rotors, see Fig. 6.84. Quadrotors are classiﬁed as
rotorcraft, as opposed to ﬁxed-wing aircraft, because their lift is derived from four

364
6
Applications II
Fig. 6.83 Trajectories of
travel rate
Fig. 6.84 Quadrotor model
rotors. They can also be classiﬁed as helicopters, though unlike standard helicopters,
Quadrotors use ﬁxed-pitch blades, whose rotor pitch does not vary as the blades ro-
tate. Control of vehicle motion can be achieved by varying the relative speed of
each rotor to change the thrust and torque produced by each. There are two genera-
tions of Quadrotor designs. The ﬁrst generation Quadrotors were designed to carry
one or more passengers. These vehicles were among the ﬁrst successful heavier-
than-airvertical takeoff and landing (VTOL) vehicles. However, early prototypes
suffered from poor performance, and latter prototypes required too much pilot work
load, due to poor stability augmentation. The more recent generation of Quadrotors
are commonly designed to be unmanned aerial vehicles (UAVs). These vehicles use
an electronic control system and electronic sensors to stabilize the aircraft. With
their small size and agile maneuverability, these Quadrotors can be ﬂown indoors as
well as outdoors. There are a lot of advantages of the current generation of Quadro-
tors, versus comparably scale helicopters. For instance, Quadrotors do not require
mechanical linkages to vary the rotor blade pitch angle as they spin. This simpli-
ﬁes the design of the vehicle, and reduces maintenance time and cost. Moreover,

6.12
PID Control of a Quadrotor Unmanned Air Vehicle
365
the use of four rotors allows each individual rotor to have a smaller diameter than
the equivalent helicopter rotor, for a given vehicle size, allowing them to store less
kinetic energy during ﬂight. This reduces the damage caused should the rotors hit
any objects. For small scale UAVs, this makes the vehicles safer to interact with in
close proximity.
Unmanned Aerial Vehicles (UAVs) are deﬁned as aircrafts without the onboard
presence of pilots [50]. UAVs have been used to perform intelligence, surveillance,
and reconnaissance missions. The technological promise of UAVs is to serve across
the full range of missions. UAVs have several basic advantages over manned sys-
tems including increased maneuverability, reduced cost, reduced radar signatures,
longer endurance, and less risk to crews. Vertical take-off and landing type UAVs
exhibit even further maneuverability features. Such vehicles are to require little hu-
man intervention from take-off to landing. UAVs have potential for fulﬁlling many
civil and military applications including surveillance, intervention in hostile envi-
ronments, air pollution monitoring, and area mapping [10].
Unmanned aerial vehicles (UAV) have shown a growing interest thanks to recent
technological projections, especially those related to instrumentation. They made
possible the design of powerful systems (mini drones) endowed with real capacities
of autonomous navigation at reasonable cost.
6.12.1 Introduction
In this section, we are studying the behavior of the quadrotor. This ﬂying robot
presents the main advantage of having quite simple dynamic features. Indeed, the
quadrotor is a small vehicle with four propellers placed around a main body. The
main body includes power source and control hardware. The four rotors are used
to controlling the vehicle. The rotational speeds of the four rotors are independent.
Thanks to this independence, it’s possible to control the pitch, roll and yaw attitude
of the vehicle. Then, its displacement is produced by the total thrust of the four rotors
whose direction varies according to the attitude of the quadrotor. The vehicle motion
can thus be controlled. There have been numerous projects involving quadrotors to
date, with the ﬁrst known hover reported in [32]. Recent interest in the quadrotor
concept has been sparked by commercial remote control versions, such as the Dra-
ganFlyer IV [14]. Many groups [4, 9, 21, 45] have seen signiﬁcant success in devel-
oping autonomous quadrotor vehicles. Nowadays, the mini-drones invade several
application domains [20]: safety (monitoring of the airspace, urban and interurban
trafﬁc); natural risk management (monitoring of volcano activities); environmen-
tal protection (measurement of air pollution and forest monitoring); intervention in
hostile sites (radioactive workspace and mine clearance), management of the large
infrastructures (dams, high-tension lines and pipelines), agriculture and ﬁlm pro-
duction (aerial shooting).
In contrast to terrestrial mobile robots, for which it is often possible to limit the
model to kinematics, the control of aerial robots (quadrotor) requires dynamics in
order to account for gravity effects and aerodynamic forces [3].

366
6
Applications II
In general, existing quadrotor dynamic models are developed on the hypothesis
of a unique rigid body which is a restrictive hypothesis that does not account for
the fact that the system is composed of ﬁve rigid bodies: four rotors and a crossing
body frame. This makes the explanation of several aspects, like gyroscopic effects,
very difﬁcult. Additionally, simpliﬁcation hypotheses are generally introduced early
in the model development and leads in general to misleading interpretations.
6.12.2 Dynamic Modeling
A quadrotor is an under actuated aircraft with ﬁxed pitch angle four rotors as shown
in Fig. 6.85. Modeling a vehicle such as a quadrotor is not an easy task because of
its complex structure. The aim is to develop a model of the vehicle as realistically
as possible. In the quadrotor, there are four rotors with ﬁxed angles which represent
four input forces that are basically the thrust generated by each propeller as shown
in Fig. 6.85. The collective input (u1) is the sum of the thrusts of each motor. Pitch
movement is obtained by increasing (reducing) the speed of the rear motor while
reducing (increasing) the speed of the front motor. The roll movement is obtained
similarly by increasing (reducing) the speed of the right motor while reducing (in-
creasing) the speed of the left motor. The yaw movement is obtained by increasing
(decreasing) the speed of the front and rear motors together while decreasing (in-
creasing) the speed of the lateral motors together. This should be done while keeping
the total thrust constant.
Each of the controller inputs affects certain side of the quadrotor model, u2 here
affects the rotation in the roll angle while u3 affect the pitch angle and u4 control
the yaw angle during the ﬂying process and u1 affect the altitude (z-axis) for this
model. Each rotor produces moments as well as vertical forces. These moments
have been experimentally observed to be linearly dependent on the forces for low
Fig. 6.85 The quadrotor schematic

6.12
PID Control of a Quadrotor Unmanned Air Vehicle
367
speeds. There are four input forces and six output states (x,y,z,θ,ψ,φ) therefore
the quadrotor is an under-actuated system. The rotation direction of two of the rotors
are clockwise while the other two are counterclockwise, in order to balance the
moments and produce yaw motions as needed.
The compensation of this torque in the center of gravity is established thanks to
the use of contra rotating rotors 1–3 and 2–4. Recall that rotors 2 and 4 turn coun-
terclockwise while rotors 1 and 3 turn clockwise. In order to move the quadrotor
model from the earth to a ﬁxed point in the space, the mathematical design should
depend on the direction cosine matrix as follows:
Rzky =
⎡
⎣
CϕCθ
CϕSθSψ −SϕCψ
CϕSθCψ + SϕSψ
CϕSθ
SϕSθSψ + CϕCψ
SϕSθCψ −CϕSψ
−Sθ
CθSψ
CϕCψ
⎤
⎦
(6.28)
where
• Sφ = sinφ, Cψ = cosψ, etc.
• R is the matrix transformation.
• ϕ is the Roll angle.
• θ is the Pitch angle.
• ψ is the Yaw angle.
The dynamic model of the quadrotor helicopter can be obtained via a Lagrange
approach and a simpliﬁed model is given as follow [5].
The equations of motion can be written using the force and moment balance.
¨x = u1(cosφ sinθ cosψ + sinφ sinψ) −K1 ˙x/m,
¨y = u1(sinφ sinθ cosψ + cosφ sinψ) −K2 ˙y/m,
¨z = u1(cosφ cosψ) −g −K3˙z/m,
(6.29)
where
• x: Forward position in earth axes.
• y: Lateral position in earth axes.
• z: Vertical position in earth axes.
• Ki: The Drag Coefﬁcients for the system.
The Ki’s given above are the drag coefﬁcients. In the following we assume the
drag is zero, since drag is negligible at low speeds. The center of gravity is assumed
to be at the middle of the connecting link. As the center of gravity moves up (or
down) d units, then the angular acceleration becomes less sensitive to the forces,
therefore stability is increased. Stability can also be increased by tilting the rotor
forces towards the center. This will decrease the roll and pitch moments as well as
the total vertical thrust.
For convenience, we will deﬁne the inputs to be:
U1 = (Th1 + Th2 + Th3 + Th4)/m,
U2 = l(−Th1 −Th2 + Th3 + Th4)/I1,
U3 = l(−Th1 + Th2 + Th3 −Th4)/I2,
U4 = C(Th1 + Th2 + Th3 + Th4)/I3,
(6.30)

368
6
Applications II
where
• u1: Vertical thrust generated by the four rotors.
• u2: Pitching moment.
• u3: Yawing moment.
• u4: Rolling moment.
• Thi: The thrusts generated by four rotors.
• Ii: The moments of inertia with respect to the axes,
where Thi’s are thrusts generated by four rotors and can be considered as the real
control inputs to the system, and C the force to moment scaling factor. And Ii’s are
the moment of inertia with respect to the axes. Therefore, the equations of Euler
angles become:
¨θ = u2 −lK4 ˙θ/I1,
¨ψ = u3 −lK5 ˙ψ/I2,
¨ϕ = u4 −K6 ˙ϕ/I3,
(6.31)
where (x,y,z) are three positions; (θ,ϕ,ψ) three Euler angles, representing pitch,
roll and yaw, respectively; g the acceleration of gravity; l the half length of the he-
licopter; m the total mass of the helicopter; Ii’s the moments of inertia with respect
to the axes; Ki’s the drag coefﬁcients.
This quadrotor helicopter model has six outputs (x,y,z,θ,ψ,ϕ) while it only
has four independent inputs, therefore the quadrotor is an under-actuated system.
We are not able to control all of the states at the same time. A possible combination
of controlled outputs can be x, y, z and ϕ in order to track the desired positions,
move to an arbitrary heading and stabilize the other two angles, which introduces
stable zero dynamics into the system [3, 45]. A good controller should be able to
reach a desired position and a desired yaw angle while keeping the pitch and roll
angles constant.
By applying Pythagoras theorem and implementing some assumptions and can-
cellations as follows:
1. The quadrotor structure is symmetrical and rigid.
2. The Inertia matrix (I) of the vehicle is very small and to be neglected.
3. The center of mass is placed at the origin o.
4. The propellers are rigid.
5. Thrust and drag are proportional to the square of the propellers speed.
These above equations have been established assuming that the structure is rigid
and the gyroscopic effect resulting from the propellers rotation has been neglected.
The ϕ and ψ can be extracted in the following expressions:
ϕd = tan−1
yd −y
xd −x

,
ψd = tan−1

zd −z

(xd −x)2 + (yd −y)2

,
(6.32)

6.12
PID Control of a Quadrotor Unmanned Air Vehicle
369
Fig. 6.86 The quadrotor
angles movements
where
• ϕ is the desired yaw angle.
• ψ is the desired roll angle.
By supplying the four motors with the required voltage, the system will be on, the
thrust here is directly proportional with these voltages, whenever increasing the volt-
age, the thrust for the motor increase and vice versa. The proﬁle of quadrotor angle
movements is depicted in Fig. 6.86.
6.12.3 PID Control Design
The PID design are pointed out in many references, such as [17], that PID controllers
can be used only for plants with relatively small time delay for high performance
devices like the quadrotor. This controller takes many structures but the most im-
portant one as in the following form:
u(t) = Kp

e(t) + 1
Ti
 t
0
e(τ)dτ + Td
de(t)
dt

(6.33)
where u(t) is the input signal to the plant model, the error signal e(t) is deﬁned as
e(t) = r(t) −y(t)
(6.34)
and r(t) is the reference input signal.
In this section, the PID controller for the quadrotor is developed based on the fast
response. Using this approach as a recursive algorithm for the control-laws synthe-
sis, all the calculation stages concerning the tracking errors are simpliﬁed.
One other aspect of the controller selection depends on the method of control of
the UAV. It can be mode-based or non-mode based. For the mode based controller,

370
6
Applications II
independent controllers for each state are needed, and a higher level controller de-
cides how these interact. On the other hand for a non-mode based controller, a single
controller controls all of the states together.
However, the adopted control strategy is summarized in the control of two sub-
systems; the ﬁrst relates to the position control while the second is that of the attitude
control.
The quadrotor model above can be divided into two subsystems: a fully-actuated
subsystem S1 that provides the dynamics of the vertical position z and the yaw angle
(z and ψ).

 ¨z
¨φ

=

u1 cos(φ)cos(ψ) −g
u4

+

 −K3˙z/m
−K6 ˙φ/I3

.
(6.35)
An under-actuated subsystem S2 representing the under-actuated subsystem which
gives the dynamic relation of the horizontal positions (x,y) with the pitch and roll
angles.

 ¨x
¨y

=

u1 cosφ
u1 sinφ
u1 sinφ
−u1 cosφ

sinφ cosψ
sinψ

+

−K1 ˙x/m
−K2 ˙y/m

(6.36)
and

 ¨θ
¨ψ

=

u2
u3

+

 −lK4 ˙θ/I1
−lK5 ˙ψ/I2

.
(6.37)
Since drag is very small at low speeds, the drag terms in the above equations can
be considered as small disturbances to the system.
The PID control is applied to the equations above with inputs u1, u2, u3, u4
and outputs φ, θ, ψ and Zd. Though these methods were rather successful in local
analysis of nonlinear systems afﬁne in control they usually fail to work for a global
analysis and nonlinear systems that are nonafﬁne in control [41].
For the fully-actuated subsystem, we can construct a rate bounded PID con-
trollers to move states z and φ, θ, ψ to their desired values.
6.12.4 Simulation Results
The nominal parameters and the initial conditions of the quadrotor for simulation
are:
I1 = I2 = 1.25 Ns2/rad,
I3 = 2.5 Ns,
K1 = K2 = K3 = 0.010 Ns/m,
K4 = K5 = K6 = 0.010 Ns/m,
m = 2 kg,
l = 0.2 m,
g = 9.8 m/s2.
The proposed control algorithm shown in Fig. 6.87 which is composed of all con-
trollers, inputs, speed reference and the inner relationships of the thrust, the quadro-

6.12
PID Control of a Quadrotor Unmanned Air Vehicle
371
Fig. 6.87 Simulation model with PID controllers for the quadrotor
Fig. 6.88 The z-axis moving
to the desired z-point
tor system is supplied by a step function for the altitude and (z-axis) which is sub-
ject to the three step inputs at (3,10,20) and the response yields as can be seen in
Fig. 6.88 which is contains some transient overshot and another for the Yaw angle
(ψ) which is subjected to step input after 5 second as shown in Fig. 6.90 and the
roll angle (f) which is respond after 3 second as it can be seen in Fig. 6.89, the pitch
angle response is shown in Fig. 6.91 which 5% overshot when subjected to step in-
put these transient perturbation are due to many reasons such as a certain of some
mechanical parameters in the design and the simpliﬁcation of controller design.
The simulation results show that the PID controllers are able to robustly stabilize
the quadrotor helicopter and move it to a desired position with a desired yaw angle

372
6
Applications II
Fig. 6.89 Roll (φ) angle
after 3 seconds to start
moving to the desired point
Fig. 6.90 Yaw (ψ) angle
after 5 seconds to start
moving to the desired point
Fig. 6.91 Pitch (θ) angle
start moving to the desired
point
while keeping the pitch and the roll angles zero. And here in this design, its easy
and with a fast response time, can get the pitch angle (θ) to its desired value.
The reason of using the PID controllers in this system is to control z, which
is sensitive to the changes for the other parameters, by using the proposed PID
controller method strategy. The good performance can be shown from the speed
of response of the quadrotor; although the overshoot in the altitude response was
removed, the transient response of the system became faster. The same speed of
response can be also seen in the yaw, pitch and roll angles control of Figs. 6.88,
6.89, 6.90.
6.13 Design of an Aircraft Controller
The Lockheed L-1011 TriStar, commonly referred to as just L-1011 (pronounced
“ell-ten-eleven”) or TriStar, is a medium-to-long range, three-engine, wide body
passenger jet airliner, see Fig. 6.92. It was the third wide-body airliner to enter
commercial operations, following the Boeing 747 and the McDonnell Douglas DC-

6.13
Design of an Aircraft Controller
373
Fig. 6.92 L-1011 tristar
structure
10. Between 1968 and 1984, Lockheed manufactured a total of 250 TriStars. The
design featured a twin-aisle interior with a maximum of 400 passengers, a three en-
gine layout, low noise emissions (in the early 1970s, Eastern Air Lines nicknamed
the L-1011 “The WhisperLiner”), improved reliability, and efﬁcient operation. The
L-1011 featured a highly advanced autopilot system and was the ﬁrst wide-body
to receive FAA certiﬁcation for Cat-IIIc auto-landing, which approved the TriStar
for completely blind landings in zero-visibility weather performed by the aircraft’s
autopilot. The L-1011 used an Inertial Navigation System (INS) to operate its nav-
igation needs. This included aligning the navigation system by entering current co-
ordinates of longitude and latitude. It also had a unique Direct Lift Control (DLC)
system, which allowed for smooth approaches when landing. DLC helps maintain
the descending glide slope on ﬁnal approach by automatically deploying spoiler
panels on the wings. Thus, rather than maintaining the descent by adjusting pitch,
DLC helps control the descent while maintaining a more consistent pitch angle,
using four redundant hydraulic systems.
6.13.1 Linearized Model
A sixth order model of an aircraft is hereafter selected for the purpose of control
design. A linearized model of the Lockheed L1011 TriStar aircraft at a cruise ﬂight
condition has the system matrices:
A =
⎡
⎢⎢⎢⎢⎢⎢⎣
−20
0
0
0
0
0
0.337
−1
0
0.249
−1.12
−5.2
0
1
0
0
1
0
−0.744
−0.032
0
−0.154
−0.0042
1.54
0
0
0
0
−25
0
0.02
0
0.0386
−0.996
−0.00029
−0.117
⎤
⎥⎥⎥⎥⎥⎥⎦
,

374
6
Applications II
Fig. 6.93 State trajectories without input
B =
⎡
⎢⎢⎢⎢⎢⎣
20
0
0
0
0
0
0
0
0
25
0
0
⎤
⎥⎥⎥⎥⎥⎦
,
C =

0
0
1
0
0
0
0
0
0
0
0
1

where the state variables are ∂r = rudder deﬂection, ∂a = aileron deﬂection, ϕ =
bank angle (rad), r = yaw rate (rad/s), p = roll rate (rad/s) and β = sideslip angle
(rad). The input variables are ∂rc = rudder command (rad), ∂ac = rudder command
(rad) and the output measured variables are ϕ = bank angle (rad) and β = sideslip
angle (rad). The eigenvalues of the A matrix were found to be
−0.0882 ± +1.2695j,
−1.0855,
−0.0092,
−20.00,
−25.000.
Two of the eigenvalues have complex parts which cause oscillations in the system
response, see Fig. 6.93.
6.13.2 Simulation Results
In what follows, we present the simulation results of feedback control design. This
is subsumed of state-feedback, observed-based feedback, tracking control and LQR
design. The corresponding state trajectories are plotted in Fig. 6.94 under state-
feedback.
The corresponding output trajectories are plotted in Fig. 6.95 under state-
feedback. In Fig. 6.96, the corresponding state trajectories are plotted under
observer-based feedback. The output trajectories under observer-based feedback are
shown in Fig. 6.97 and a comparison of state trajectories is provided in Fig. 6.98.

6.14
Motion Control Design of Liquid Container
375
Fig. 6.94 State trajectories with state-feedback
Fig. 6.95 Output trajectories with state-feedback
The corresponding state trajectories with tracking control, integral control and
LQR are plotted in Figs. 6.99–6.101, respectively.
6.14 Motion Control Design of Liquid Container
In the casting and steel industry, containers with melted metal are transferred over
long distances from the furnace. To achieve higher degrees of automatic operation,
optimal motion control is always considered. It is important to shorten the trans-

376
6
Applications II
Fig. 6.96 State trajectories with observer-based feedback
Fig. 6.97 Output trajectories with observer-based feedback
portation time in order to increase productivity. However, transfer at high speed
causes molten metal to slosh in both the ladle and the molds. This sloshing phe-
nomenon deteriorates the quality of the mold due to impurity and excessive cooling
of the molten metal. Besides that, it can be dangerous as overﬂow can happen as
well [52]. Many papers have been published about control of the sloshing in liquids.
One of the studies considered it as a problem of suppressing liquid oscillations [49].
Another used the idea of jerk reduction to decrease the sloshing due to jerk move-

6.14
Motion Control Design of Liquid Container
377
Fig. 6.98 A comparison of state trajectories
Fig. 6.99 State trajectories with tracking control
ments by optimal control [23]. Different control approaches are also applied. PID
control and observer based control have been applied with great success in 2009 [7].
Not many studies have applied control to both the motion of the liquid container as
well as the sloshing phenomenon at the same time [52]. In 2002 however, Yano et al.
applied robust control to both the sloshing as well as the motion of the liquid con-
tainer [52]. In this study, a similar model to Yano’s will be used and several control
techniques will be applied to study their effect on the system.

378
6
Applications II
Fig. 6.100 State trajectories with integral control
Fig. 6.101 State trajectories with LQR control
6.14.1 Dynamic Model
In our model, we assume that the transfer path is a straight line, see Fig. 6.102. Thus,
as long as there are no sudden changes in the acceleration we can model the three-
dimensional container as a two dimensional container. Therefore, the given sloshing
model is described as a pendulum-type sloshing model [52]. Adding the rotational

6.14
Motion Control Design of Liquid Container
379
Fig. 6.102 A sloshing model
motion to the pendulum-type sloshing model gives a new model that describes both
the transfer of the container as well as the rotation that causes the sloshing [52]. The
following diagram shows the container with all the variables that affect the model.
The rotational motion of the system around point O is given by
J d2θ
dt2 = −cℓd(θ −η)
dt
ℓcos2 θ −mgℓsinθ + m¨xℓcosφ cosθ
−m¨xℓsinφ sinθ −mℓD d2η
dt2 cosθ
where J = mℓ2 is the moment of inertia. A linearization about θ ≈0, with some
simpliﬁcation [52] yields
¨θ = −c
m( ˙θ −˙η) −g
ℓθ + 1
ℓ¨x cosφ.
(6.38)
The motor used is a DC servo-motor where the input is voltage and the output is
velocity, which in turn applied to the contrainer transfer function. The model is
described by
Gm(s) =
Km
τm + 1
where Km and τm are the motor gain and time-constant, respectively. The container
rotation is described by the transfer function
Gr(s) =
Krω2
n
s2 + 2ξωns + ω2n
.
Taking x = [θ, ˙θ,η, ˙η, ¨η,x, ˙x]t, Y = [h,x]t and u = [u1,u2]t as the state, output
and control input, respectively, along with the parameter values as
Km = 0.0912,
τm = 0.0227,
Kr = 0.5807,
ξ = 0.3778,
ωn = 41.446,
hs = 0.14,
φ = 5.0,
ℓ= 0.0442,
c = 1.88,
m = 2.744,
D = 0.02

380
6
Applications II
we obtain the linearized model
˙x =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
1
0
0
0
0
0
−221.72
−0.6851
0
0.6851
0
0
−992.878
0
0
0
1
0
0
0
0
0
0
0
1
0
0
0
0
0
−1717.77
−31.3166
0
0
0
0
0
0
0
0
1
0
0
0
0
0
07
−44.053
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
x
+
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
0
90.55
0
0
0
0
0
0
−997.51
0
0
4.0176
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
ˆu,
y =

0.25
0
−0.25
0
0
0
0
0
0
0
0
0
1
0

x.
When a liquid container is transferred on an inclined transfer path, a transferring
machine with one degree of freedom may cause overﬂow and contamination of the
molten metal in terms of only acceleration control for linear container transfer. Eval-
uation of the structural properties of the linearized model shows that the model is
both controllable and observable, however is unstable with internal oscillations since
the eigenvalues are 0,0,−0.3426 ± 14.8863,−15.6583 ± 28.3743,−44.0530. In
the following sections, we examine the feedback control design and simulation of
different schemes.
6.14.2 State Feedback Design
The design objective is to stabilize the linearized sloshing model and remove the
internal oscillations. With the aid of MATLAB, we place the closed-loop poles at
[−1,−2,−3,−5,−6,−8,−11] to obtain the state-feedback controller gain as
K =

−1.2297
0.1821
0.2100
0.1332
0.0149
0.2149
−10.6701
−0.0627
−0.0035
−0.1145
1.6334
0.0137
−0.0323
−0.0270

.
The ensuing state-trajectories are plotted in Fig. 6.103. The nonzero values of x3
and x6 are justiﬁed by the application of the ﬁnal value theorem (see the Appendix)
which yields
xss = −(A + BK)−1Br
=

0
0
1.8120
0
0
6.4231
0
0
0
12.0565
0
0
11.7794
0
t
.

6.14
Motion Control Design of Liquid Container
381
Fig. 6.103 State trajectories: Input 1 (left), Input 2 (right)
Fig. 6.104 Observeration errors (left), a comparison of state x1 (right)
6.14.3 Observer-Based Feedback Design
Relying on the measured states and build an observer. Using MATLAB, placing
the poles at [−5,−60,−15,−105,−3,−40,−5.5], which sufﬁciently high than the
controller poles, gives the observer gain as
L = 103

0.4
−3.2
−0.5
−15.7
1239.1
−0.0002
0.0001
0.0003 −0.0004 0.0001 −0.0002 −0.0008
0.0001
−0.0005
t
.
In Figs. 6.104, 6.105, the observation error as well as a comparison between state-
feedback and observer-based feedback are plotted.
6.14.4 LQR Design
Seeking to optimize the performance, we considered the LQR design with different
weighting matrices. The simulation results of the closed-loop step response for two
distinct cases:
• Cheap control: Q = 0.1 ∗I7, R = I2,
• Expensive control: Q = diag([10 250 10 10 10 110 10]), R = I2,
are presented in Fig. 6.106.

382
6
Applications II
Fig. 6.105 A comparison of state x3 (left), a comparison of state x5 (right)
Fig. 6.106 Closed-loop response: expensive LQ control (left), cheap LQ control (right)
Fig. 6.107 A Simulink sloshing model
6.14.5 Tracking Control Design
There are two types of tracking control, one in which a signal is set to track zero
(regulator) and the other case is when the signal is set to track a reference signal or
trajectory. In both cases, the difference between the reference signal and the output
is the error that is used to drive the system. The error is integrated before being used
as a control signal in order to eliminate steady state errors. A Simulink model was
created to track a reference signal, see Fig. 6.107.
The outputs shown below, Fig. 6.108 include the measured outputs of the system,
the reference trajectory and the control inputs.

6.15
Vertical Motion Control of Marine Vehicles
383
Fig. 6.108 Tracking
trajectories of input and
output
6.15 Vertical Motion Control of Marine Vehicles
Marine vehicles are designed to operate with adequate reliability and stability, and
in order to accomplish this, it is essential to control the motion of the submarine.
This control task consists in making the submarine to follow, as closely as possible,
a desired trajectory, which can be deﬁned in terms of submarine’s depth, velocity,
pitch angle and pitch rate. In most submarine’s operational conditions, the desired
trajectory is slowly varying due to the motion induced by the waves. The desired
trajectory can be achieved in the face of uncertainty of the system to be controlled
even in the presence of the uncontrollable external disturbances acting on the system
in the form of waves, wind and current in the water. From the control system design
perspective, the characterization of the disturbances acting on the submarine is es-
sential to design good performance submarine motion controllers and to understand
limitations that may prevent the design achieving the performance speciﬁcations.
In this section, we apply optimal control techniques and simulations represent the
achievement of stability.
The vertical dynamics of a submarine traveling a few meters below the surface
of a sea are considered here. The purpose here is to control the depth and pitch of
the submarine by the use of optimal control. Figure 6.109 illustrates the model of
the submarine and its related parameters.
6.15.1 Dynamic Model
The vertical plane behavior of the submarine is modeled by the simpliﬁed linear
time-invariant equations:
˙x =
⎡
⎣
6.5 × 10−4
−0.2502
−0.008
−0.0014
0
1
0
0
0
0
−3.25
0
⎤
⎦x

384
6
Applications II
Fig. 6.109 A submarine
model
+
⎡
⎢⎢⎣
−0.0348
−0.0686
0.0369
−0.0109
0
0
0
0
⎤
⎥⎥⎦ˆu +
⎡
⎢⎢⎣
1
0
0
1
0
0
0
0
⎤
⎥⎥⎦ˆw,
y =

0
0
1
0
0
0
0
1

x + v
where x = [W q θ h]t and u = [δb δs]t are the state and control input respectively,
and
• W = downwards velocity at right angles to the submarine main axis (m/s).
• q = pitch rate (rad/s).
• θ = pitch (rad).
• h = depth wrt the datum depth (hd) below the main sea level (m).
• δb = bow control plane angle (rad).
• δs = stern control plane angle (rad).
• y = [θ h]t is the output.
• ˆw = process noise of the sea.
• vˆv = measurement noise of the sea.
The open loop model of submarine used here is unstable since λ(A) = {−0.2074 ±
0.0927i,−0.0647,0.1074}. In order to stabilize the system, optimal control methods
are used in he sequel.
6.15.2 LQR Design
After several experimentations, it is found that using Q = 0.0125 ∗I4, R = 104I2,
the MATLAB command lqr gives the feedback gain matrix
K =

 0.0165
3.5451
1.4563
−0.0462
−0.0049
−1.0482
−0.4306
0.0137

and the associated closed-loop eigenvalues as
λ(A + BK) = {−0.0647,−0.1076,−0.2073 ± 0.0927i}.

6.15
Vertical Motion Control of Marine Vehicles
385
Fig. 6.110 State trajectories under LQR
Fig. 6.111 State trajectories
under LQR
The resulting optimal state and the optimal control input trajectories are depicted in
Figs. 6.110, 6.111.
6.15.3 LQGR Design
In most of the practical systems, all the states of the system are not available for
feedback. LQ Gaussian control is a method of designing feedback control laws for
linear systems with additive Gaussian processes that minimize a given quadratic
cost function. This is achieved through the application of separation principle con-

386
6
Applications II
Fig. 6.112 LQGR block
diagram
Fig. 6.113 LQGR state and state estimates
sisting of solving a LQR problem and the optimal linear state estimator (Kalman
ﬁlter) which gives the estimate ˆx of the state x, refer to Fig. 6.112 for details. In
Kalman ﬁlter, the two free parameters to be selected are known as process noise and
measurement noise. The Kalman ﬁlter should be designed such that the resulting
LQG controller is very close to that of full state feedback control. The LQG control
scheme is implemented in MATLAB by invoking the separation principle as it guar-
antees that the closed loop poles of the estimator will not appear in the closed loop
poles of the system under control thereby ﬁnding the LQR solution using the MAT-
LAB command lqr function and state estimates using the Kalman ﬁlter function
MATLAB command kalman.
This yields the Kalman gain matrix as
L =
⎡
⎢⎢⎣
0.0331
−0.0247
0.0046
−0.0024
0.0324
−0.0286
0.2859
0.4218
⎤
⎥⎥⎦
and the corresponding trajectories of state and state-estimates are depicted in
Fig. 6.113 which clearly indicate nice asymptotic behavior in reproducing the states.

6.16
Pitch Control of Wind Turbines
387
Fig. 6.114 LQGR control
input
Fig. 6.115 LQR and LQGR
state trajectories
The control input trajectories of the LQGR scheme are shown in Fig. 6.114.
For the purpose of comparison, we provide in Figs. 6.115 and 6.116 the optimal
state and input trajectories based on LQR and LQGR.
6.16 Pitch Control of Wind Turbines
Since the 1990s, the wind energy industry has been growing rapidly. The wind
power generation technology had developed from stall-controlled to variable speed
pitch regulated. And wind turbine has demanded better performance of con-
troller [22, 46, 47].
With the increasing of capacity of wind turbines, pitch-control technique of large
wind turbine has become a key technique of wind energy. Pitch-control can not
only output power steadily, but also make wind turbine have better starting and
braking performance. Additionally, using optimized control algorithm can lower

388
6
Applications II
Fig. 6.116 LQR and LQGR
input trajectories
Fig. 6.117 Wind turbine
model
load and torque ripple of wind turbine, extending the life of wind turbine. At present,
in China most wind turbine is controlled by PID algorithm, which cannot have a
satisfy effect. Abroad researchers have proposed many advanced control theory and
strategy about pitch-control. Senjyu et al. had applied GPC control method to pitch-
control [47]. This is wind speed predict model based on average wind speed and
standard deviation, having pitch controlled according to predicted wind speed.
6.16.1 Simulation of Wind Turbine
The equivalent model of wind turbine is shown in Fig. 6.117. The aerodynamic
torque gained by blade from wind energy [13]:
Tr = 1
2
πρR2Cp(β,λ)
λ
V 2
(6.39)

6.16
Pitch Control of Wind Turbines
389
in which, ρ is the density of air (kg/m3), R is the radius of rotor (m), V is the wind
speed (m/s), β is the pitch angle (degree), λ is tip speed ratio, λ = ΩR/V , Ω is
the rotor speed, Cp is power conversion coefﬁcient, which indicates wind turbine’s
efﬁciency of converting wind energy to usable mechanism power. Cp is function of
tip speed ratio λ and blade pitch angle β. Cp can be written as [13, 27]:
CP (λ,β) = 0.22
116
λi
−0.4β −5

· e −22.5
λi
(6.40)
in which λi satisﬁes:
1
λi
=
1
λ + 0.08 · β −0.035
β2 + 1.
Although wind turbine is a nonlinear model, at some point near by it can be treated
as linear model. Linearizing torque Tr at point (V0,Ω0,β0) nearby:
Tr = Tr(V0,Ω0,β0) + αΔV + γ ΔΩ + ζΔβ.
(6.41)
In which, ΔΩ = Ω −Ω0, ΔV = V −V0, Δβ = β −β0
α = ∂Tr
∂V

(V0,Ω0,β0)
,
γ = ∂Tr
∂Ω

(V0,Ω0,β0)
,
ζ = ∂Tr
∂β

(V0,Ω0,β0)
.
Let state variable q1 and q2 are blade angle and rotor angle respectively (calculated
in low speed shaft. Tshaft is the reaction torque on the shaft. Then:
Tshaft = Kd(q1 −q2) + Cd(˙q1 −˙q2),
(6.42)
ΔTshaft = Kd(Δq1 −Δq2) + Cd(Δ˙q1 −Δ˙q2),
(6.43)
Jrot ¨q1 = Tr −Tshaft −Kf rotΩ,
(6.44)
JgenΔ˙q2 = ΔTshaft −ΔTgen −Kf genΔωgen.
(6.45)
Above, Kd is elastic coefﬁcient of propeller shaft, Cd is damping coefﬁcient on
propeller shaft, Jrot and Jgen are rotation inera of low speed side and generator (cal-
culated in low speed side), Kf rot, Kf rot are friction coefﬁcient of low speed side and
high speed side respectively. Tshaft0 is counter torque at working point (V0,Ω0,β0).
The speed acceleration is 0, so:
Tr(V0,Ω0,β0) = Tshaft0 + Kf rotΩ0.
(6.46)
Then:
Jrot ¨q1 = ΔTr −ΔTshaft −Kf rotΔΩ.
(6.47)
Let
x1 = Δ˙q1,
x2 = Kd(Δq1 −Δq2),
x3 = Δ˙q2.

390
6
Applications II
Then:
Jrot ˙x1 = (γ −Cd −Kf rot)x1 −x2 + Cdx3 + ζΔβ + αΔV,
(6.48)
˙x2 = Kd(x1 −x3).
(6.49)
According to the torque equation of generation:
Jgen ˙x3 = Cdx1 + x2 −(Cd + Kf gen)x3 −ΔTgen.
(6.50)
In state equation form:
 ˙x = Ax + Bu + Γ uD
y = Cx + Du
(6.51)
where,
A =
⎡
⎢⎢⎣
(γ −Cd−Kf rot)
Jrot
−1
Jrot
Cd
Jrot
Kd
0
−Kd
Cd
Jgen
1
Jgen
−Cd−Kfgen
Jgen
⎤
⎥⎥⎦,
B =
⎡
⎢⎣
ζ
Jrot
0
0
0
0
−1
Jgen
⎤
⎥⎦,
Γ =
⎡
⎢⎣
α
Jrot
0
0
⎤
⎥⎦,
C =
0
0
1
,
D = 0
input u = ⌊Δβ,ΔTgen⌋, disturbance quantity uD = ΔV .
At present pitch actuator has hydraulic and electric two forms. For simplicity,
pitch actuator can be simpliﬁed to a ﬁrst-order inertia model, no matter it is hydraulic
or electric actuator. The pitch actuator transmission function is:
Act(s) =
1
τβs + 1.
(6.52)
6.16.2 Pitch Control of Wind Turbine
After connected to the grid, wind turbine can work in two modes: one mode is
when wind speed is slower that rated wind speed, another is when faster. When
wind speed is slow, wind turbine output power is smaller than rated power. So the
pitch angle is set to 0° and wind turbine runs in optimal tip speed by controlling
generator speed, in order to absorb as much wind energy as possible. While wind
speed is faster than rated speed, the output power will excess rated power. Because
the electrical and mechanical limitation of wind turbine, the rotator speed and output
power cannot excess rated value. So, when output power is larger than rated power,
pitch angle should be increased to smaller wind energy utilization efﬁciency. When
output power is smaller than rated power, pitch angle will be decreased to maintain
the output power at about rated power nearby.

6.16
Pitch Control of Wind Turbines
391
Nowadays variance speed pitch-control wind turbine always has its electromag-
netic torque given value constant, maintaining output power by regulating generator
speed. The most common method is adopting PI control to regulate generator speed.
This method is simple and easily applied in engineering. However, PI control may
have overshoot problems, which makes pitch actuator complicated and easily fa-
tigued.
LQR is linear quadrics regular, whose control object is linear system given by
state space form in modern control theory. And its object function is object states
and quadrics function which controls input. LQR optimal control is designing state
feedback controller G. In order to minimize the quadrics object function J , and
also G is decided only by weight matrix Q and R, the selection of Q and R
is very important. LQR theory is a relatively mature theory in modern control
theory. It provided an efﬁcient analysis method for multi-variable feedback sys-
tem. Object function J included state variable and input variable, which requires
state variable and input variable to be small. In the pitch-control system, input
value is the error of pitch angle. Because of large inertia of blade, rapid pitch-
control would damage pitch regulated mechanism and aggravate the friction of
pitch-control shaft. So, having some limitation to input energy will be reasonable.
Additionally, choosing torque variation as state variable can suppress torque ripple
as much as possible in LQR optimal control. Then the life of wind turbine can be
extended.
The linear state model is given by

˙x = Ax + Bu + Γ uD
y = Cx
(6.53)
and the objective function is
J = 1
2
 tf
t0

xt(t)Qx(t) + ut(t)Ru(t)

dt
(6.54)
where Q is positive semideﬁnite matrix, R is positive deﬁnite matrix, Q and R
are weighted matrix for state variable and input variable, respectively. x(t) is n-
dimension state variable, u(t) is m-dimension input variable. According to control
theory, in order to minimize object function, optimal control is:
u(t) = Gx(t),
G = −R−1BtP,
where P is Riccati function:
−PA −AtP + PBR−1BtP −Q = 0.
(6.55)
Positive deﬁnite symmetric solution. The LQR control diagram is shown as
Fig. 6.118. In engineering application, state variable cannot be measured usually.
So it needs to design a state observer to estimate state variable value. Figure 6.118
is the diagram used in actual application. Because there is a disturbance variable
ud in wind turbine model, only using LQR control cannot regulate generator speed
very well. And the disturbance from disturbance variable should be minimized as
much as possible. Disturbance Accommodating Control (DAC) is a good method

392
6
Applications II
Fig. 6.118 LQR diagram
Fig. 6.119 Disturbance correction control diagram
to solve this problem. DAC control is a reconstructed disturbance model method
based on state observer. The disturbance variable is reconstructed and is part of
state feedback, can decrease or neutralize the disturbance effect. This paper adopted
LQR method with DAC, which means that through LQR optimal control having a
optimal feedback matrix G, then using DAC method to estimate disturbance vari-
able and eliminating the disturbance from disturbance variable. DAC diagram is
shown as Fig. 6.119. Using state observer to estimate state variable and disturbance
variable, disturbance can be eliminated. Presume the disturbance variable has forms
as below:

ud = ΘzD(t),
˙zD(t) = FzD(t);
zD(0) = z0D
(6.56)
z0D is unknown, presume Θ and F is already known. According to DAC control
theory, state feedback should contain the feedback of disturbance:
u(t) = Gx(t) + GDzD(t).
(6.57)
Replace u(t) in the state function with the up function, we have:
˙x(t) = (A + BG)x(t) + (BGD + Γ Θ)zD(t).
(6.58)

6.16
Pitch Control of Wind Turbines
393
To eliminate the disturbance, it requires BGD + Γ Θ = 0, then it can be considered
as a system without disturbance. If the system cannot satisfy BGD + Γ Θ = 0, then
choosing GD to make ∥BGD + Γ Θ∥minimum.
Because state variable x(t) and zD(t) cannot be measured directly, designing
state observer is needed to predict state variable and disturbance variable. Wind
turbine’s state observer’s math model:
 ˙ˆx = Aˆx(t) + Bu(t) + Γ ˆud(t) + Kx(y(t) −ˆy(t)),
ˆy = C ˆx(t);
ˆx(0) = 0.
(6.59)
Disturbance observer: ˙ˆxD = F ˆzD(t) + KD(y(t) −ˆy(t)),
ˆuD = Θ ˆzD(t).
(6.60)
Designing appropriate Kx and KD can let:
lim
t→∞ex(t) = lim
t→∞

x(t) −ˆx(t)

= 0,
(6.61)
lim
t→∞eD(t) = lim
t→∞

zD(t) −ˆzD(t)

= 0.
Disturbance state function can be written as:
˙e(t) = ( ¯A −¯K ¯C)e(t).
(6.62)
Where, e(t) = [ et
x
et
D ]t, ¯A =
 A
Γ Θ
0
F

, ¯C = [ C
0], ¯K =
 Kx
KD

.
According to the formula above, error’s expression can be solved:
e(t) = e( ¯A−¯K ¯C)te(0).
(6.63)
If system ( ¯A
¯C) is measurable, then ( ¯A −¯K ¯C) can have any poles conﬁguration,
letting e(t) damping to 0 rapidly. Feedback control principal became:
u(t) = Gˆx(t) + GD ˆzD(t).
(6.64)
To verify the control performance of LQR algorithm based on disturbance cor-
relation, a numeric simulation was performed on MATLAB Simulink. The wind
turbine model parameter is: rated power 650 kW, rotor diameter 43 m, gear box
transmission ratio 43.16, rotor rated speed 42 rpm. LQR algorithm based on distur-
bance correction and PI regulation method were simulated.
Choosing work point at V0 = 17 m/s, Ω0 = 42 rpm, β0 = 13.35 in LQR algo-
rithm and linearizing at this point. Then wind turbine’s state function is function
(6.51), where:
A =
⎡
⎣
−0.198
−3.108 × 10−6
−3.108 × 10−5
2.69 × 107
0
−2.69 × 107
1.56 × 10−4
1.56 × 10−5
−0.0624
⎤
⎦,
B =
⎡
⎣
−7.5 × 10−3
0
0
⎤
⎦,

394
6
Applications II
Fig. 6.120 Simulation
waveform of LQR algorithm
choosing R = 1, Q =

 1
0
0
0
1×10−12
0
0
0
50

. From matrix A,B,Q and R, state feedback
matrix: K = [2.2219 1.6905 × 10−8 −1.3289].
In the simulation, wind speed stepped from 17 m/s to 18 m/s at t = 0 moment. In
PI regulation, Kp = 8, KI = 1.5, simulation result is shown as Fig. 6.120. From the
simulation we can tell, PI regulation method has a lager overshoot, while LQR algo-
rithm has a much smaller one. In Fig. 6.120, LQR algorithm can decrease the elastic
force on drive link. In Fig. 6.120, after adopting LQR algorithm, the overshoot can
be very small, which can reduce the action of pitch actuator. While PI regulation has
a larger overshoot, pitch angle ﬂuctuated for a moment, which is harmful for pitch
actuator.

6.17
LQR in MATLAB
395
6.17 LQR in MATLAB
The command [K,P,E] = lqr(A,B,Q,R,N) solves the ARE (5.62) and computes
the optimal state-feedback gain matrix K given in (5.60) that minimizes the LQR
criteria (5.58) for the continuous-time system (5.55). It also returns the poles E of
the closed-loop system (5.64).
6.18 Questions
Q5.1 Suppose that P1 and P2 are two symmetric positive-deﬁnite solutions to the
ARE (5.62). Show that P1 and P2 satisfy (A −BR−1BtP2)(P1 −P2) +
(P1 −P2)(A −BR−1BtP2) = 0 and argue that P1 = P2.
Q5.2 Derive a solution to the optimal control problem involving a performance in-
dex Jα =
 ∞
0 e2αt[xt(t)Qz(t) + ut(t)Ru(t)]dt, and show that the associated
closed-loop eigenvalues have real parts less than −α.
6.18.1 MATLAB Problems
1. For the linearized model of the Reverse osmosis (RO) plant discussed in
Sect. 5.4, design and evaluate an observer-based feedback controller by selecting
the observer eigenvalues distinctly different from the controller eigenvalues. Plot
the state responses for different cases and comment on the results.
2. For the linearized model of the Reverse osmosis (RO) plant discussed in
Sect. 5.4, design and evaluate an optimal linear quadratic regulator with equal
weighting for the state and input. Plot the output responses to unit step input and
compare on the same graph the open-loop and the closed-loop responses.
3. Consider a quadruple-tank process, depicted in Fig. 6.121, which consists of
four interconnected water tanks and two pumps. Its manipulated variables are
voltages to the pumps and the controlled variables are the water levels in the
two lower tanks. The quadruple tank system presents a typical multi-input-multi-
output (MIMO) system that is widely used in control system labs. An appropriate
state-space model is given by:
dh1
dt = −a1
A1

2gh1 + a3
A1

2gh3 + γ1k1
A1
ν1 + d
A1
,
dh2
dt = −a2
A2

2gh2 + a4
A2

2gh4 + γ2k2
A2
ν2 −d
A2
,
dh3
dt = −a3
A3

2gh3 + (1 −γ2)k2
A3
ν2,
dh4
dt = −a4
A4

2gh4 + (1 −γ1)k1
A4
ν1,

396
6
Applications II
Fig. 6.121 Four tank model
Fig. 6.122 A twin-rotor
helicopter when going
upward along z-axis
dν1
dt = −ν1
τ1
+ 1
τ1
u1,
dν2
dt = −ν2
τ2
+ 2
τ2
u2.
By linearizing the model around the point ho = [11.4 11.6 5.3 4.0]t, vo =
[0.5 0.5]t. The remaining data is ai = [2.10,2.14,2.2,2.3], cm2 Ai = 730, γ1 =
0.30, γ2 = 0.35, kj = [7.45,7.30], g = 9.81, τi = [2.0,2.1].
It is desired to undertake control studies using alternative control strategies.
Provide simulations to compare among various controllers.
4. A twin-rotor helicopter when going upward along z-axis is depicted in Fig. 6.122.
The objective is to control the azimuth and elevation angles and the height. The
system is underactuated because it has two actuators and three degrees of free-
dom. The model has two inputs and three outputs. The outputs of the system
include azimuth angle φ (position plane about the vertical axis), the elevation
angle θ (position in the vertical plane about horizontal axis) and the height h
(position along the vertical axis (z-axis)). The voltages u1 and u2 to the main
and tail rotors served as inputs to the system.

6.18
Questions
397
The complete set of equations describing the helicopter process during its
motion along z-axis is given by
dφ
dt = ˙φ,
dφ
dt = [JA + JL]−1[2JL cosθ sinθ ˙θ ˙φ + τφ],
dθ
dt = ˙θ,
d ˙θ
dt = 1
|d|

−d22

τθ −JL cosθ sinθ ˙φ2 −mlcg cosθ

−d12

τh + mlc sinθ ˙θ2 −m −Kms

,
dh
dt = ˙h,
d ˙h
dt = 1
|d|

−d12

τθ −JL cosθ sinθ ˙φ2 −mlcg cosθ

×

τh + mlc sinθ ˙θ2 −m −Kms

,
dω1
dt = −1
T ω1 +
1
k1T1
u1,
dω2
dt = −1
T ω2 +
1
k2T2
u2
here K = 2
3, k = 3
4 and φ = azimuth angle, ˙φ = rate of change of azimuth angle,
θ = elevation angle, ˙θ = rate of change of elevation angle, h = height, ˙h =
rate of change of height, ω1 = angular velocity of the mail rotor, ω2 = angular
velocity of the tail rotor. By linearizing the above model around the equilibrium
point φ0 = 0.1 rad, θ0 = 0 rad, h0 = 0.05 m, u1,0 = 0.7788 V, u2,0 = 1.2548 V
and taking
x = [φ
˙φ
θ
˙θ
h
˙h
ω1
ω2]t,
u = [u1
u2]t,
y = [φ
θ
h]t
as the state, input and output vectors, a linearized model has the following ma-
trices
A =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
1
0
0
0
0
0
0
0
0
157.55
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
0
2.9741
−0.218
0
0
0
0
0
1
0
0
0
0
0
0
0
0
0.0418
0.5115
0
0
0
0
0
0
−0.2
0
0
0
0
0
0
0
0
−0.4
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
B =

0
0
0
0
0
0
3.6364
0
0
0
157.55
0
0
0
0
9.0909
t
,

398
6
Applications II
Fig. 6.123 Single machine
and inﬁnite bus system
Fig. 6.124 Block diagram of SMIB with exciter and AVR
Fig. 6.125 Power system
representation
Ct =
⎡
⎣
1
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
0
1
0
0
0
⎤
⎦.
It is desired to undertake control studies using alternative control strategies. Pro-
vide simulations to compare among various controllers.
5. Consider the problem of designing power system stabilizer (PSS) for a single
machine and inﬁnite bus (SMIB) system based on linear control techniques.
A schematic representation of this system is shown in Fig. 6.123.
A standard block diagram including the effect of excitation is given in
Fig. 6.124. As a typical case, consider the following case in Fig. 6.125 along
with data values
(i) Post fault system condition
P = 0.9,
Q = 0.3,
Et = 1.0∠36°,
EB = 0.995∠0°,
f = 60,

6.18
Questions
399
Fig. 6.126 Single phase
representation of UPQC
(ii) Generator parameters
H = 3.5 MWs/MVA,
Ld = 1.81,
Xd = 1.81,
Lq = 1.76,
Xq = 1.76,
Lℓ= 0.15,
X′
d = 0.3,
L′
d = 0.3,
Xℓ= 0.16,
L′
q = 1.81,
Xd = 1.81,
Lq = 1.76,
T ′
do = 1.76,
Ld = 0.65,
Ra = 0.003,
L′′
d = 0.23,
T ′
do = 8.0 s,
L′′
q = 0.25,
KD = 0,
T ′
qo = 1.0 s,
T ′′
do = 0.03 s,
T ′′
qo = 0.07 s,
(iii) IEEE type-1 excitation system
KA = 50,
TA = 0.05,
KE = −0.05.0,
TE = 0.5,
KF = 0.05,
TF = 0.5,
(iv) Constants
K1 = 0.84982,
K2 = 1.0286,
K3 = 0.38618,
K4 = 1.55310,
K5 = −0.1315,
K6 = 0.49934.
6. In recent years, the increasing use of power electronic devices has led to the dete-
rioration of power quality (PQ) due to harmonic generations. On the other hand,
a stable supply voltage has always been desired for smooth operations of many
industrial power plants. Recent research has shown that the uniﬁed power qual-
ity conditioners (UPQCs), an integration of series and shunt active ﬁlters, can be
utilized to solve most PQ problems simultaneously. This motivates us to develop
comprehensive and cost-effective controllers that cannot only be implemented
easily but also fully utilize the UPQC to solve a wide range of PQ problems. Dif-
ferent control approaches for the UPQC have been proposed. The most common
approach focuses on extracting and injecting distorted components, that is, har-
monics (from sampled supply voltage and load current), into the network. This
aims to make the load voltage and supply current undistorted. A single-phase
representation of UPQC is shown in Fig. 6.126.

400
6
Applications II
Fig. 6.127 Vehicle suspension system
Apply basic electrical circuit laws to develop an appropriate state-space model
and explore the structural properties. Design suitable state and observer-based
feedback controllers to improve the system behavior.
7. The study of ride quality evaluates the passenger’s response to road/terrain ir-
regularities with the objective of improving comfort and road isolation while
maintaining wheel/ground contact. Ride problems mainly arise from vehicle vi-
brations, which may be induced by variety of sources including external factors,
such as roadway roughness or aerodynamic forces, or they may be internally
generated forces produced by vehicle subsystems, such as the engine, power-
train, or the suspension mechanisms. Usually the surface irregularity acts as a
major source that excites the vibration of the vehicle. Passenger comfort in a
road vehicle depends on a combination of vertical motion (heave) and angular
motion (pitch). Suspension elements between the wheels and the vehicle body
generate vertical forces which excite both heave and pitch motions. Suspension
system designs are mostly based on ride analysis. Vehicle suspensions using var-
ious types of springs, dampers, and linkages with tailored ﬂexibility in various
directions have been developed over the last century since the beginning of the
automobile age. Active suspensions, with proper control design, can give an im-
proved overall suspension performance. A schematic diagram of the vehicle with
an active suspension system is shown in Fig. 6.127.
In the modeling process, rigid bodies of masses mf and mR represent respec-
tively the front and rear equivalent mass of the wheel assembly, upper control
arm, lower control arm and the associated linkages. The front and rear tire stiff-
ness are denoted by KuF and KuR, respectively. The frame and body structure of
the vehicle is characterized by the mass ms and the pitch moment of inertia Jp
(about a body-ﬁxed coordinate system, centered at the vehicle’s centre of grav-
ity). The state variables of this model are: x1 = front suspension deﬂection, x2 =

6.18
Questions
401
Fig. 6.128 One-quarter car
model
rear suspension deﬂection, x3 = vertical velocity of the sprung mass, x4 = pitch
rate of the sprung mass, x5 = front tire deﬂection, x6 = vertical velocity of the
front unsprung mass, x7 = rear tire deﬂection and x8 = vertical velocity of the
rear unsprung mass. Two actuators are placed in between the sprung mass ms
and the unsprung masses mR and mF . The active control forces of the front and
rear actuators are denoted by uF and uR, respectively. Only the ﬁrst and second
states can be measured.
Develop an appropriate state-space model and examine the structural prop-
erties. Design suitable state, observer-based feedback controllers and linear-
quadratic regulator to improve the system behavior.
8. Figure 6.128 shows a simpliﬁed linear quarter car model. Develop a state-space
model in terms of x1, ˙x1, x2, ˙x2 as the state vector and u1, u2 as the force inputs
to masses m1, m2.
Examine the structural properties of the model and design linear feedback
controllers using m1 = 60 kg, m2 = 375 kg, k1 = 200 kN m−1, k2 = 15 kN m−1,
c1 = 7 Ns m−1 and c2 = 1425 Ns m−1. Moreover, a good-quality road with
length L = 100 m is considered for a vehicle speed range 40 →180 km h−1.
9. The longitudinal motion of a ﬂexible bomber aircraft is modeled as a second
order short-period mode, a second-order fuselage bending mode, and two ﬁrst-
order control-surface actuators. The sixth order system is described by the fol-
lowing linear, time-invariant, state-space representation
A =
⎡
⎢⎢⎢⎢⎢⎢⎣
0.4158
1.025
−0.00267
−0.0001106
−0.08021
0
−5.5
−0.8302
−0.06549
−0.0039
−5.115
0.809
0
0
0
1
0
0
−1040
−78.35
−34.83
−0.6214
−865.6
−631
0
0
0
0
−75
0
0
0
0
0
0
−100
⎤
⎥⎥⎥⎥⎥⎥⎦
,

402
6
Applications II
B =
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
0
0
0
0
0
0
75
0
0
100
⎤
⎥⎥⎥⎥⎥⎥⎦
,
C =

−1491
−146.43
−40.2
−0.9412
−1285
564.66
0
1.0
0
0
0
0

,
D =

0
0
0
0

.
The inputs are the desired elevator deﬂection (rad), u1(t), and the desired canard
deﬂection (rad), u2(t), while the outputs are the sensor location’s normal accel-
eration m/s2, y1(t), and the pitch-rate (rad/s), y2(t). Test the structural properties
of the system. Then proceed to design feedback controllers and compare the cor-
responding closed-loop state trajectories.
References
1. Al-Bastaki, N.M., Abbas, A.: Modeling an industrial reverse osmosis unit. Desalination 126,
33–39 (1999)
2. Alatiqi, I., Ettouney, H., El-Dessouky, H.: Process control in water desalination industry: An
overview. Desalination 126, 15–32 (1999)
3. Altug, E., Ostrowski, J.P., Mahony, R.: Control of a quadrotor helicopter using visual feed-
back. In: Proc. 2002 IEEE Int. Conference on Robotics and Automation, vol. 1, pp. 72–77
(2002)
4. Altug, E., Ostrowski, J.P., Taylor, C.J.: Quadrotor control using dual camera visual feedback,
In: ICRA, Taipei, September 2003
5. Anderson, W.: Controlling Electrohydraulic Systems. Dekker, New York (1988)
6. Bagchi, A.: Optimal Control of Stochastic Systems. Prentice Hall International, Englewood
Cliffs (1993)
7. Bandyopadhyay, B., Ghandi, P.S., Kurodo, S.: Sliding mode observer based sliding mode
controller for slosh free motion through PID scheme. IEEE Trans. Ind. Electron. 56(9), 3432–
3442 (2009)
8. Burl, J.B.: Linear Optimal Control, 3rd edn. Prentice-Hall, New York (1998)
9. Castillo, P., Dzul, A., Lozano, R.: Real-time stabilization and tracking of a four-rotor mini
rotorcraft. IEEE Trans. Control Syst. Technol. 12(4), 510–516 (2004)
10. Castillo, P., Lozano, R., Dzul, A.: Stabilization of a mini rotorcraft with four rotors. IEEE
Control Syst. Mag. 25, 45–50 (2005)
11. Chen, T., Francis, B.A.: Optimal Sampled-Data Control Systems. Springer, London (1995)
12. Chen, X., Yang, T., Chen, X., Zhou, K.: A generic model-based advanced control of electric
power-assisted steering systems. IEEE Trans. Control Syst. Technol. 16(6), 1289–1300 (2008)
13. Datta, R., Ranganathan, V.T.: Variable-speed wind power generation using doubly fed wound
rotor induction machine. A comparison with alternative schemes[J]. IEEE Trans. Energy Con-
vers. 17, 414–421 (2002)
14. Dragan Fly-Innovations, www.rctoys.com (2003)
15. Franklin, G.F., Powell, J.D., Naeini, A.E.: Feedback Control of Dynamic Systems, 4th edn.
Prentice-Hall, New York (2002)
16. Fukushima, N., Arslan, M.S., Hagiwara, I.: An optimal control method based on the energy
ﬂow equation. IEEE Trans. Control Syst. Technol. 17(4), 866–875 (2009)

References
403
17. Gaeid, K.S., Mohamed, H.A.F., Ping, H.W., Hassan, L.H.: PID controller for induction motors
with faults, University of Malaya & University of Nottingham Malaysia Campus, In: The 2nd
International Conference on Control, Instrumentation & Mechatronic, CIM-2009
18. Gambier, A., Krasnik, A., Badreddin, E.: Dynamic modelling of a small reverse osmosis de-
salination plants for advanced control purposes. In: Proc. of the 2007 American Control Con-
ference. New York, July 11–13, pp. 4854–4859 (2007)
19. Ghazy, M.A.: Variable structure control for electrohydraulic position servo system. In: Proc.
Industrial Electronics Conference, IECON, vol. 1, pp. 2194–2198 (2001)
20. Guenard, N., Hamel, T., Moreau, V.: Modélisation et élaboration de commande de stabilisation
de vitesse et de correction d’assiette pour un drone. In: CIFA, 2004
21. Hamel, T., Mahoney, R., Lozano, R., Ostrowski, E.: Dynamic modelling and conﬁguration
stabilization for an X4-ﬂyer. In: The 15éme IFAC World Congress, Barcelona, Spain, 2002
22. Hangzhi, Y.: Control Technology of Wind Turbine, Mechanics Industry Press, Beijing (2002)
23. Hoshijima, K., Ikeda, M.: Vibration suppression control for mechanical transfer systems by
jerk reduction. Int. J. Control. Autom. Syst. 5(6), 614–620 (2007)
24. Hu, C., Cheng, X.: Electric drive system for winding shaper of automobile belt, In: Proc. IEEE
Conf. on Electric Machines and Systems, Shengyyang, China, 2001
25. Hu, C., Meng, M., Liu, P.X., Wang, X.: Optimal digital control system design for winding
shaping process of automobile belt. In: IEEE Canadian Conference on Electrical and Com-
puter Engineering, Montreal, pp. 1763–1766 (2003)
26. Jaho Seo, J., Venugopala, R., Kenne, J.-P.: Feedback linearization based control of a rotational
hydraulic drive. Control Eng. Pract. 15, 235–241 (2007)
27. Kanellos, F.D., Hatziargyriou, N.D.: A new control scheme for variable speed wind turbines
using neural networks[C]. In: Power Engineering Society Winter Meeting, 2002, vol. 1. IEEE,
pp. 260–365 (2002)
28. Kim, N., Cha, S., Peng, H.: Optimal control of hybrid electric vehicles based on Pontryagin’s
minimum principle. IEEE Trans. Control Syst. Technol. 21, 73–82 (2010)
29. Ko, H.S., Lee, K.Y., Kim, H.C.: An intelligent based LQR controller design to power system
stabilization. Electr. Power Syst. Res. 71, 1–9 (2004)
30. Koc, H., Knittel, D., de Mathelin, M., Abba, G.: Modeling and robust control of winding
systems for elastic webs. IEEE Trans. Control Syst. Technol. 10(2), 197–208 (2002)
31. Kuribayashi, K., Nakajima, K.: Active dancer roller system for tension control of wine and
sheet. In: Proc. IFAC Power Systems, vol. 4, pp. 1747–1752 (1985)
32. Lambermont, P.: Helicopters and Autogyros of the World (1958)
33. Liao, H.H., Roelle, M.J., Chen, J.S., Park, S., Gerdes, J.C.: Implementation and analysis of a
repetitive controller for an electro-hydraulic engine valve system. IEEE Trans. Control Syst.
Technol. 21, 12–22 (2010)
34. Lin, C.C., Peng, H., Grizzle, J.W., Kang, J.: Power management strategy for a parallel hybrid
electric truck. IEEE Trans. Control Syst. Technol. 11(6), 839–849 (2003)
35. Lopes, R.V., Galvão, R.K.H., Milhan, A.P., Becerra, V.M., Yoneyama, T.: Modelling and con-
strained predictive control of a 3DOF helicopter. In: XVI Congresso Brasileiro de Automática,
Salvador, Brazil, paper 123, vol. 1, pp. 429–434 (2006)
36. Maia, M.H., Galvão, R.K.H.: Robust constrained predictive control of a 3DOF helicopter
model with external disturbances. In: ABCM Symposium Series in Mechatronics, vol. 3, pp.
19–26 (2008)
37. Mayne, D.Q., Rawlings, J.B., Rao, C.V., Scokaert, P.O.M.: Constrained model predictive con-
trol: Stability and optimality. Automatica 36(6), 789–814 (2000)
38. Moura, S.J., Fathy, H.K., Callaway, D.S., Stein, J.L.: A stochastic optimal control approach
for power management in plug-in hybrid electric vehicles. IEEE Trans. Control Syst. Technol.
21, 1–11 (2010)
39. Noura, H., Sauter, D., Hamelin, F., Theilliol, D.: Fault-tolerant control in dynamic systems:
Application to a winding machine. IEEE Control Syst. Mag. 7, 33–49 (2000)
40. Ogata, K.: MATLAB for Control Engineers. Prentice-Hall, New York (2008)

404
6
Applications II
41. Olfati-Saber, R.: Nonlinear control of underactuated mechanical systems with application to
robotics and aerospace vehicles. Ph.D. thesis in Electrical Engineering and Computer Science,
Massachusetts Institute of Technology (February 2001)
42. Parola, M., Vuorinen, S., Linna, H., Kaljunen, T., Beletski, N.: Modelling the web tension
proﬁle in a paper machine, http://www.vtt.ﬁ/tte/informationcarriers/Oxford2001.pdf (2001)
43. Peterson, K.S., Stefanopoulou, A.G.: Rendering the electromechanical valve actuator globally
asymptotically stable. In: Proc. IEEE Conf. Decision Control, pp. 1753–1758 (2003)
44. Pipeleers, G., Demeulenaere, B., Al-Bender, F., Schutter, J., Swevers, J.: Optimal performance
tradeoffs in repetitive control: Experimental validation on an active air bearing setup. IEEE
Trans. Control Syst. Technol. 17(4), 970–979 (2009)
45. Pounds, P., Mahony, R., Hynes, P., Roberts, J.: Design of a fourrotor aerial robot. In: Australian
Conference on Robotics and Automation, Auckland, November 2002
46. Sakamoto, R., Senjyu, T., Kinjo, T.: Output power leveling of wind turbine generator for all
operating regions by pitch angle control. In: Power Engineering Society General Meeting,
vol. 1, pp. 45–52 (2005)
47. Senjyu, T., Sakamoto, R., Urasaki, N., Funabashi, T.: Output power leveling of wind turbine
generator for all operating regions by pitch angle control. IEEE Trans. Energy Convers. 21,
467–475 (2006)
48. Shelton, J.J.: Dynamics of web tension control with velocity or torque control. In: Proc. Amer-
ican Control Conference, New York, pp. 1423–1427 (1986)
49. Terashima, K., Schmidt, G.: Motion control of a cart-based container considering suppression
of liquid oscillations. In: Int. Symposium on Industrial Electronics, 25–27 May, pp. 275–280
(1994)
50. UAVs, New world vistas: Air and space for the 21st century. Human Systems and Biotechnol-
ogy Systems 7, 17–18 (1997)
51. Wang, J., Ydstie, E.B.: Robust inventory control system. IEEE Trans. Control Syst. Technol.
15(4), 768–774 (2007)
52. Yano, K., Higashikawa, S., Terashima, K.: Motion control of liquid container considering an
inclined transfer path. Control Eng. Pract. 10, 465–472 (2002)
53. Yuan, Q.H., Li, P.Y.: Robust optimal design of unstable valves. IEEE Trans. Control Syst.
Technol. 15(6), 1065–1074 (2007)

Chapter 7
Robust Control Design
7.1 Introduction
It is commonly agreed practice that a successfully designed control system should
be always able to maintain stability and performance level in spite of uncertainties
in system dynamics and/or in the working environment to a reasonable degree [3,
25]. Design requirements such as gain margin and phase margin in using conven-
tional frequency-domain techniques are solely for the purpose of robustness [4].
During the period of 1960s and 1970s when system models could be much more
accurately described and design methods were mainly mathematical optimizations
in time-domain, the robustness issue was not that prominently considered. However,
due to its importance the research on robust design has been going on all the time.
A breakthrough came in the late 1970s and early 1980s with the pioneering work of
[23, 24] on the theory, now known as the H∞optimal control theory. The H∞opti-
mization approach and μ-synthesis/analysis method are well developed and elegant.
They provide systematic design procedures of robust controllers for linear systems,
though the extension into nonlinear cases is being actively researched. Many books
have since been published on H∞and related theories and methods [2, 6, 7, 10, 11,
21, 22, 25, 26].
On a parallel development, the application of optimal control theory to the prac-
tical design of multivariable control systems attracted much attention during the
period 1960–1980. This theory considers linear ﬁnite-dimensional systems repre-
sented in state space form, with quadratic performance criteria. The system may be
affected by disturbances and measurement noise represented as stochastic processes,
in particular, by Gaussian white noise. The theoretical results obtained for this class
of design methods are known under the general name of LQG theory [1, 15]. The
deterministic part is called LQ theory which was discussed in Chap. 5. Since 1980
the theory has been further reﬁned under the name of H2 theory [5], in the wake of
the attention for the so-called H∞control theory.
In the present chapter, we present a short overview of a number of results of H2
and H∞theories with an eye to using them for control system design. Since robust-
ness of a feedback control system is very important in control engineering practice.
M.S. Mahmoud, Y. Xia, Applied Control Systems Design,
DOI 10.1007/978-1-4471-2879-3_7, © Springer-Verlag London Limited 2012
405

406
7
Robust Control Design
In actual control problems, there are always disturbances due to the environment
and uncertainties due to the imperfect model used in the controller design. Clearly,
it is desirable for the controlled system to have certain robustness against these dis-
turbances and uncertainties. To assess the robustness, ﬁrst of all, a proper measure
is needed. Norm measures to signals and systems are introduced, which can be re-
garded as the basis of robust control. In what follows, the symbols L and H are due
to Lebesgue and Hardy, respectively.
7.1.1 Norm Measures of Signals
The size of a signal f (t) is usually measured in its Lp-norm deﬁned as
f (t)

p =
 ∞
−∞
f (t)
p dt

(7.1)
where p is a positive integer. Three key properties of a norm:
1. ∥f (t)∥p ≥0 and ∥f (t)∥p = 0, iff u = 0.
2. α∥f (t)∥p = |α|∥f (t)∥p, ∀scalars α.
3. ∥f (t) + g(t)∥p ≤∥f (t)∥p + ∥g(t)∥p.
The following norms are commonly used:
1. The L1-norm: ∥f (t)∥1 =
 ∞
−∞|f (t)|dt.
2. L2-norm, the measure of signal power: ∥f (t)∥2 =
 ∞
−∞f 2(t)dt.
3. L∞-norm, the least upper bound of |f (t)|: ∥f (t)∥∞= supt |f (t)|.
Observe that in case of vector signal x(t), which is a function of time t ≥0, the
L2-norm becomes
x(t)

2 =
	 ∞
0
xt(t)x(t)dt.
7.1.2 Norm Measures of Systems
The size of a system in a transfer function form is usually measured by its H2-
and H∞-norms. Hereafter, we consider a transfer function matrix G(s) with each
element being strictly proper and stable transfer function.
1. H2-norm is deﬁned by
G(s)

2 =
	
1
2πj
 j∞
−j∞
G(jω)
2 dω.
(7.2)
Standard algebraic manipulations lead to

7.1
Introduction
407
G(s)

2 =
	
1
2π Tr
 +∞
−∞
G(jω)G∗(jω)dω
=
	
Tr
 +∞
0
G(t)Gt(t)dt
(7.3)
where G∗(jω) is the complex conjugate transpose of G(jω) and G(t) is the in-
verse Laplace transform of G(s). The H2-norm is in fact a measure of the square
root of the integral squared value of the output when the input is an impulse sig-
nal. In stochastic system terminology, the H2-norm is the root mean square value
of the output signal when the input is white noise.
2. H∞-norm is generally deﬁned by
G(s)

∞= sup
u(t)̸=0
∥y(t)∥2
∥u(t)∥2
(7.4)
where u(t) and y(t) are the input and output of the system, respectively, and sup
denotes supremum, the least upper bound. For stable systems, the H∞-norm of
the system can be computed from
G(s)

∞= sup
ω
G(jω)
.
(7.5)
It is readily seen that the H∞-norm is in fact the peak value of the magnitude of
the frequency response.
It is well-known that the condition
G(s)
H∞≤γ
is satisﬁed if and only if there exists a matrix P = P t ≥0 that meets the following
criteria:
1. It is a solution of
PA + AtP + CtC + γ −2PBBtP = 0.
(7.6)
2. The matrix
A + γ −2BBtP
(7.7)
is stable.
The above result is frequently known as the Bounded Real Lemma [9]. An inter-
pretation of ∥G(s)∥H∞is that it is the energy gain from the input u to the output y,
that is
G(s)
H∞:= max
u(t)̸=0
 ∞
0 yt(t)y(t)dt
 ∞
0 ut(t)u(t)dt .
(7.8)
This implies that ∥G(s)∥H∞achieves the maximum gain using a worst case input
signal that is essentially a sinusoid at frequency ω∗with input direction that yields
supω σM(G(jω∗)) as the ampliﬁcation.

408
7
Robust Control Design
The following properties of norms are given without proofs.
1. ∥y(t)∥2 ≤∥G(s)∥∞∥u(t)∥2.
2. ∥y(t)∥∞≤∥G(s)∥2∥u(t)∥∞.
3. ∥G1(s)G2(s)∥∞≤∥G1(s)∥∞∥G2(s)∥∞.
7.1.3 Signiﬁcance of H2-Norm
Consider a MIMO system described by
Y(s) = G(s)U(s)
(7.9)
where U(s) ∈ℜm and Y(s) ∈ℜp are the input and output vectors in the s-domain.
Let us apply a unit impulse, δ(t), in input channel i at a time. The output vector
becomes
Yi(s) = G(s)Ei,
Ei =

0
···
0
1
0
···
0
t.
(7.10)
Thus,
yi(t)
2
2 =
 +∞
0
Tr

yi(t)yt
i (t)

dt.
(7.11)
By virtue of Parseval’s theorem (see the Appendix), we have
yi(t)
2
2 = 1
2π
 +∞
−∞
Tr

yi(jω)y∗
i (jω)

dω.
(7.12)
On using (7.9), we obtain
yi(t)
2
2 = 1
2π
 +∞
−∞
Tr

G(jω)EiEt
iG∗(jω)

dω
= 1
2π
 +∞
−∞

Gi1(jω)
2 + ··· +
Gip(jω)
2
dω.
(7.13)
Manipulating
m

i=1
yi(t)
2
2 = 1
2π
 +∞
−∞

G(jω)
 m

i=1
EiEt
i

G∗(jω)

dω.
(7.14)
Since it can be shown that
m
i=1 EiEt
i

Im, it follows from (7.14) that
m

i=1
yi(t)
2
2 = 1
2π
 +∞
−∞

G(jω)G∗(jω)

dω
=
G(s)
2
2.
(7.15)
In brief, minimizing the H2-norm of the transfer function matrix is equivalent o
minimizing the sum of squares of L2-norm of outputs due to unit impulse in each
input channel.

7.1
Introduction
409
In what follows, we provide a connection to the root-mean squares (RMS) re-
sponse. In the time-domain,
y(t) =
 t
0
G(t −τ)u(τ)dτ.
(7.16)
Let each input be an independent zero-mean white noise with unit intensity, that is,
E

u(t)ut(τ)

= Iδ(t −τ).
(7.17)
The mean square response can be written as
E

yt(t)y(t)

= E

Tr

y(t)yt(t)

.
(7.18)
A little algebra yields
E

yt(t)y(t)

= E

Tr
 t
0
G(t −τ)u(τ)dτ
 t
0
ut(α)Gt(t −α)dα

= Tr
 t
0
 t
0
G(t −τ)Eu(τ)ut(α)Gt(t −α)dτ dα

= Tr
 t
0
 t
0
G(t −τ)Gt(t −α)δ(τ −α)dτ dα

= Tr
 t
0
G(t −α)Gt(t −α)dα

.
(7.19)
Letting ν = t −α, we get
E

yt(t)y(t)

=
 t
0
Tr

G(ν)Gt(ν)

dν
(7.20)
and therefore
lim
t→∞E

yt(t)y(t)

=
 ∞
0
Tr

G(ν)Gt(ν)

dν.
(7.21)
Using Parseval’s theorem (see the Appendix)
lim
t→∞E

yt(t)y(t)

= 1
2π
 ∞
−∞
Tr

G(jω)G∗(ω)

dω
=
G(s)
2
H2.
(7.22)
In brief, minimizing the H2-norm of the transfer function matrix is equivalent
to minimizing the RMS of outputs in the statistical steady-state due to independent
zero-mean white-noise inputs.
7.1.4 Signiﬁcance of H∞-Norm
Let us deﬁne the input as
u(t) = auejωt,
au =

au1
au2
···
aum
t.
(7.23)

410
7
Robust Control Design
In steady state, we have
y(t) = ayejωt,
ay =

ay1
ay2
···
ayp
t
(7.24)
where au, ay are in general complex vectors. Thus,
ay = G(jω)au.
(7.25)
Using the deﬁnition of the maximum singular value
∥ay∥2
∥au∥2
≤
G(jω)
H∞
⇒
sup
au
∥ay∥2
∥au∥2
= σM

G(jω)

≤
G(s)
H∞
(7.26)
which provides an alternative statement of (7.4).
Following a different route to express the H∞-norm starts by recalling
y(t)
2
L2 = 1
2π
 ∞
−∞
y∗(jω)y(jω)dω
= 1
2π
 ∞
−∞
y(jω)
2
2 dω.
(7.27)
Since y(jω) = G(jω)u(jω), then for zero initial conditions of inputs and outputs
y(jω)

2 ≤σM

G(jω)
u(jω)

2
≤
G(jω)
H∞
u(jω)

2.
(7.28)
The substitution of (7.28) into (7.27) yields
y(t)
2
L2 ≤1
2π
 ∞
−∞
G(jω)
H∞
u(jω)
2
2 dω
=
G(jω)
H∞
1
2π
 ∞
−∞
u(jω)
2
2 dω.
(7.29)
Using Parseval’s theorem again,
y(t)
L2 ≤
G(jω)
H∞
u(t)
L2.
(7.30)
This means that if
G(jω)
H∞≤γ
(7.31)
then
∥y(t)∥L2
∥u(t)∥L2
≤γ
(7.32)
which is often used in the sequel as
y(t)
2
L2 −γ 2u(t)
2
L2 < 0
∀u(t) ∈L2.
(7.33)
In the next sections, we proceed to solve the H2 and H∞control problems.

7.2
H2 Control
411
7.2 H2 Control
Recall that we introduced the linear quadratic Gaussian (LQG) problem in Chap. 5.
In this section we cast the LQG problem as a special case of a larger class of prob-
lems, which lately has become known as H2 optimization. It must be emphasized
that this approach allows to remove the stochastic ingredient of the LQG formula-
tion. In many applications, it is difﬁcult to establish the precise stochastic properties
of disturbances and noise signals. Very often in the application of the LQG prob-
lem to control system design the noise intensities V and W play the role of design
parameters rather than that they model reality.
Hereafter, the stochastic element is eliminated by recognizing that the perfor-
mance index for the LQG problem may be represented as a system norm—the H2-
norm. To introduce this point of view, we consider the stable system
˙x(t) = Ax(t) + Γ v(t),
y(t) = Cx(t),
t ∈ℜ,
(7.34)
and the associated transfer function G(s) = C(sI −A)−1Γ . In (7.34), the distur-
bance signal v(t) is white noise with covariance function E[v(t)vt(s)] = V δ(t −s).
Thus, the output y of the system is a stationary stochastic process with spectral
density matrix
Sy(f ) = G(j2πf )V Gt(−j2πf ),
f ∈ℜ.
It follows that the mean square output is given by
E

yt(t)y(t)

= Tr
 ∞
−∞
Sy(f )df

= Tr
 ∞
−∞
G(j2πf )V Gt(−j2πf )df

.
(7.35)
Recall that the quantity
∥G∥2
2 = Tr
 ∞
−∞
G(j2πf )V Gt(−j2πf )df

(7.36)
is called earlier H2-norm of system (7.34). If the disturbance v has unit intensity
(V = I) then the mean square output E[yt(t)y(t)] equals precisely the square of the
H2-norm of system.
The impulse response matrix (inverse Laplace transform of G(s)) of system
(7.34) is given by
g(t) = CeAtΓ.
Obviously, if A is not a stability matrix them g(t) is unbounded, hence the H2-norm
is inﬁnite. So consider in the sequel that A is a stability matrix. Therefore,
∥G∥2
H2 = Tr
 ∞
−∞
gt(t)g(t)dt


412
7
Robust Control Design
= Tr
 ∞
0
Γ teAttCtCeAtΓ dt

= Tr

Γ t
 ∞
0
eAttCtCeAt dt Γ

= Tr

Γ tYΓ

.
(7.37)
The matrix Y obviously satisﬁes
AtY + YA =
 ∞
0

AteAttCtCeAt + eAttCtCeAtA

dt
=

eAttCtCeAtt=∞
t=0
= CtC.
(7.38)
That is, Y satisﬁes the Lyapunov equation
AtY + YA + CtC = 0
and as A is a stability matrix, the solution of (7.38) is well-known to be unique.
7.2.1 Control Example 7.1
Consider the following LTI system
˙x =
⎡
⎣
0
1
0
0
0
1
−2
−5
−1
⎤
⎦x +
⎡
⎣
0
0
1
⎤
⎦u,
y = x.
Simple computations give the transfer function G(s) as
G(s) =
⎡
⎣
(s3 + s2 + 5s + 2)−1
(s3 + s2 + 5s + 2)−1
(s3 + s2 + 5s + 2)−1
⎤
⎦.
To compute ∥G∥2, we ﬁrst solve
AtY + YA + CtC = 0
to yield
Y =
⎡
⎣
2.4167
2.4167
0.2500
•
5.7500
0.5833
•
•
1.0833
⎤
⎦.
Thus
∥G∥2 =

Tr

BtYB

= 1.0408.
Incidently, invoking the m-ﬁle h2norm of MATLAB we ﬁnd ∥G∥2 = 1.041.

7.2
H2 Control
413
Fig. 7.1 Feedback system
with stochastic inputs and
outputs
7.2.2 H2 Optimization
Proceeding further, we provide strong link between the LQG and H2 optimization
problems. For this purpose, we rewrite the time-domain LQG problem into an equiv-
alent frequency-domain H2 optimization problem. While the LQG problem requires
state space realizations, the H2-optimization problem is in terms of transfer matri-
ces. To simplify the expressions to come we assume that Q = I and R = I, that is,
the LQG performance index is
lim
t→∞E

zt(t)z(t) + ut(t)u(t)

.
(7.39)
This situation should not cause any loss of generality since by scaling and transfor-
mation of variables z(t), u(t), the performance index may always be brought into
this form. For the open-loop system
˙x(t) = Ax(t) + Bu(t) + Γ v(t),
z(t) = Gx(t),
(7.40)
y(t) = Cx(t) + w(t)
we solve for z(t) and y(t) in terms of v(t), w(t) and u(t), to get
z(t) = G(sI −A)−1Γ v(t) + G(sI −A)−1Bu(t)
= P11(s)v(t) + P12(s)u(t),
(7.41)
y(t) = C(sI −A)−1Γ v(t) + C(sI −A)−1Bu(t) + w(t)
= P21(s)v(t) + P22(s)u(t).
(7.42)
In Fig. 7.1, the interconnection of feedback system with compensator K subject to
stochastic inputs and outputs is shown, from which we have
u(t) = −Ky(t)
⇒
u(t) = −

I + K(P22)−1
KP21v(t) −

I + K(P22)−1
Kw(t)
(7.43)
= H21(s)v(t) + H22(s)w(t).
From (7.41), we get
z(t) = P11 −P12

I + K(P22)−1
KP21v(t) −P12

I + K(P22)−1
Kw(t)
= H11(s)v(t) + H12(s)w(t).
(7.44)

414
7
Robust Control Design
Written compactly, we have
 z(t)
u(t)

=
H11(s)
H12(s)
H21(s)
H22(s)
 v(t)
w(t)

= H(s)
 v(t)
w(t)

.
(7.45)
Evaluating the mean square error, we get
lim
t→∞E

zt(t)z(t) + ut(t)u(t)

= lim
t→∞E
 z(t)
u(t)
t  z(t)
u(t)

= Tr
 ∞
−∞
G(j2πf )Gt(−j2πf )df

= ∥H∥2
2.
(7.46)
This leads to the basic result that solving the LQG problem amounts to minimizing
the H2 norm of the closed-loop system with (v,w) input and (z,u) as output.
It is interesting to recast the LQG problem using a generalized plant in state-
space form as follows:
˙x(t) = Ax(t) + [Γ
0]
 v(t)
w(t)

+ Bu(t),
⎡
⎣
z(t)
u(t)
y(t)
⎤
⎦=
⎡
⎣
G
0
C
⎤
⎦x(t) +
⎡
⎣
0
0
0
0
0
I
⎤
⎦
 v(t)
w(t)

+
⎡
⎣
0
I
0
⎤
⎦u(t).
(7.47)
7.2.3 The Standard H2 Problem
The performance of a feedback system can be quantiﬁed in terms of the closed-
loop gain from the disturbance inputs to the reference outputs. The system 2-norm
represents an average gain and can be used as a performance function for an optimal
control problem.
In what follows, the standard H2 control is described by the block diagram in
Fig. 7.2 where the objective is that of selecting the controller K such that it
1. stabilizes the resulting closed-loop system, and
2. minimizes the H2-norm of the closed-loop system (with w as input and z as
output),
where G(s) is the transfer function of the form:
G(s) =
⎡
⎣
A
B1
B2
C1
0
D12
C2
D21
0
⎤
⎦.
(7.48)
For convenience, we consider the partition of G(s) according to
 z
y

=
G11
G12
G21
G22
w
u

.
(7.49)

7.2
H2 Control
415
Fig. 7.2 The standard H2
problem
The closed-loop system
z = F(G,K)w
has the transfer function F(G,K) given by
F(G,K) = G11 + G12(I −KG22)−1KG21.
The H2-optimal control problem consists of ﬁnding a causal controller K which
stabilizes the plant G(s) while minimizing the cost function
J2(K) =
F(G,K)
2
2
which is a standard convex optimization problem.
Adopting the state-space framework, the underlying H2-optimal problem is most
conveniently solved in the time-domain. We will assume that G(s) can be cast into
the generalized state-space representation [5]:
˙x(t) = Ax(t) + B1w(t) + B2u(t),
z(t) = C1x(t) + D11w(t) + D12u(t),
y(t) = C2x(t) + D21w(t) + D22u(t).
The H2-optimal problem may be solved by reducing it to an LQG problem. The
derivation necessitates the introduction of some assumptions, which are listed in the
summary that follows. They are natural assumptions for LQG problems. To proceed
for the solution, we consider the generalized plant has the following model
˙x(t) = Ax(t) + B1w(t) + B2u(t),
z(t) = C1x(t) + D12u(t),
(7.50)
y(t) = C2x(t) + D21w(t) + D22u(t)
for which we assume that the following conditions hold:
• The system
˙x(t) = Ax(t) + B2u(t),
z(t) = C1x(t)
is stabilizable and detectable.
• The system
˙x(t) = Ax(t) + B1w(t),
y(t) = C2x(t)
is stabilizable and detectable.

416
7
Robust Control Design
• The matrix
A −sI
B1
C2
D21

has full row rank for every s = jω and D21 has full row rank.
• The matrix
A −sI
B2
C1
D12

has full column rank for every s = jω and D12 has full column rank.
Under the foregoing assumptions, the optimal dynamic output (observer-based)
feedback controller is
˙ˆx(t) = Aˆx(t) + B2u(t) + L

y(t) −C2 ˆx −D22u(t)

,
u(t) = −K ˆx(t).
(7.51)
The observer and state-feedback gain matrices are given by
L =

YCt
2 + B1Dt
21

D21Dt
21
−1,
K =

D12Dt
12
−1
Bt
2X + Dt
12C1

(7.52)
where the matrices X and Y are the unique, symmetric positive-deﬁnite solutions of
the algebraic Riccati equations
AtX + XA + Ct
1C1 −

XB2 + Ct
1D12

D12Dt
12
−1
Bt
2X + Dt
12C1

= 0,
(7.53)
AY + YAt + B1Bt
1 −

YCt
2 + B1Dt
21

D21Dt
21
−1
C2Y + D21Bt
1

= 0.
(7.54)
It should be noted that the condition that D12 has full column rank means that there
is direct feedthrough from the input u to the error signal z. Likewise, the condition
that D21 has full row rank means that the noise w is directly fed through to the
observed output y.
The H2 optimization problem and its solution are discussed at length in [20, 26].
7.2.4 Control Example 7.2
Consider the system of the form (7.50) with the following data
A =
1
1
0
1

,
B1 =
σ
0
σ
0

,
B2 =
0
1

C1 =
β
β
0
0

,
D12 =
0
1

,
C2 =

1
0
,
D21 =

0
1
.
It is noted that D11 = 0, D22 = 0, Dt
12C1 = 0, (D12Dt
12)−1 = I and therefore there
are no cross-terms in the control Riccati equation (7.54), which is
AtX + XA + Ct
1C1 −XB2Bt
2X = 0.

7.2
H2 Control
417
The stabilizing solution is easily veriﬁed to be
X = α
2
1
1
1

,
α =

2 +

4 + β2 
leading to K = α[1 1]. Similarly, since B1Dt
21 = 0, the measurement and process
noise are uncorrelated and the Kalman ﬁlter Riccati equation is
AY + YAt + B1Bt
1 −YCt
2C2Y = 0.
It is easy to check that the stabilizing solution is
Y = ν
1
1
1
2

,
ν =

2 +

4 + σ 2 
leading to L = ν

 1
1

. Thus, the optimal observer-based feedback controller (7.51)
can be cast as
K(s) =
A −B2K −LC2
L
−K
0

.
Since
A −B2K −LC2 =

1 −ν
1
−(α + ν)
1 −α

simple computations yield
K(s) =
αν(1 −2s)
s2 + (α + ν −2)s + αν .
The optimal cost is given by

Tr

Bt
1XB1

+ Tr

KYKt
=

5α

σ 2 + αν

.
The optimal cost is monotonically increasing in both β and σ.
Seeking to a proper real rational transfer function K(s), an alternative procedure
can derived for the solution of the H2 control problem of the plant
˙x(t) = Ax(t) + B1w(t) + B2u(t),
z(t) = C1x(t) + D12u(t),
(7.55)
y(t) = C2x(t) + D21w(t)
under the following conditions:
• The system
˙x(t) = Ax(t) + B2u(t),
y(t) = C2x(t)
is stabilizable and detectable.
• Dt
12D12 > 0 and D21Dt
21 > 0.

418
7
Robust Control Design
• For all ω
rank
A −jωI
B2
C1
D12

= number of columns,
(7.56)
rank
A −jωI
B1
C2
D21

= number of rows.
(7.57)
The solution consists of two steps: First, we solve the two algebraic Riccati equa-
tions

A −B2

D12Dt
12
−1Dt
12C1
tS + S

A −B2

D12Dt
12
−1Dt
12C1

−SB2

D12Dt
12
−1Bt
2S + Ct
1

I −D12

D12Dt
12
−1Dt
12

C1 = 0,

A −B1Dt
21

Dt
21D21
−1C2

Z + Z

A −B1Dt
21

Dt
21D21
−1C2
t
−ZCt
2

Dt
21D21
−1C2Z + B1

I −Dt
21

Dt
21D21
−1D21

Bt
1 = 0.
(7.58)
Second, the optimal transfer function K(s) is given by
K(s) = −N1(sI −A −B2N1 −N2C2)−1N2,
N1 = −

Dt
12D12
−1
Bt
2S + Dt
12C1

,
N2 = −

ZCt
2 + B1Dt
21

Dt
21D21
−1.
7.2.5 Control Example 7.3
Consider the system of the form (7.50) with the following data
A =
⎡
⎣
−5
2
−4
0
−3
0
0
7
−1
⎤
⎦,
B1 =
⎡
⎣
7
−3
1
⎤
⎦,
B2 =
⎡
⎣
6
8
−5
⎤
⎦,
C1 =
⎡
⎣
−2
9
4
⎤
⎦,
D12 = 1,
D11 = 0,
C2 =
⎡
⎣
6
3
−1
⎤
⎦,
D21 = 2,
D22 = 0.
Expressing the transfer function G(s) as:
G(s) =
⎡
⎣
A
B1
B2
C1
0
D12
C2
D21
0
⎤
⎦:=
G11(s)
G12(s)
G21(s)
G22(s)


7.2
H2 Control
419
we compute the respective elements as
G11(s) = −37s2 −2509s −669
s3 + 9s2 + 23s + 15 ,
G12(s) = s3 + 49s2 + 339s + 1455
s3 + 9s2 + 23s + 15
,
G21(s) = 2s3 + 50s2 + 113s + 597
s3 + 9s2 + 23s + 15
,
G22(s) = 65s2 + 488s −865
s3 + 9s2 + 23s + 15.
(7.59)
Since λA = {−1,−3,−5} so A is stable, we can take N1 = 0 and N2 = 0. There-
fore, the matrix
M(s) =
⎡
⎣
A
0
B2
0
0
1
−C2
1
0
⎤
⎦:=
M11(s)
M12(s)
M21(s)
M22(s)

from which we compute
M11(s) = 0,
M12(s) = 0,
M21(s) = 0,
M22(s) = −65s2 −488s + 865
s3 + 9s2 + 23s + 15 .
It follows for a proper real rational transfer function Q(s) that the controller K(s)
can be written as
K(s) = M11(s) + M12(s)Q(s)

I −M22(s)Q(s)
−1M21(s)
= Q(s)

I −M22(s)Q(s)
−1
= Q(s)

I −−65s2 −488s + 865
s3 + 9s2 + 23s + 15 Q(s)
−1
=
(s3 + 9s2 + 23s + 15)Q(s)
s3 + 9s2 + 23s + 15 + (65s2 + 488s −865)Q(s).
(7.60)
From (7.59) and (7.60), we compute the controlled system as
T(s) = G11(s) + G12(s)K(s)

I −G22(s)K(s)
−1G21(s),
= −37s2 −2509s −669
s3 + 9s2 + 23s + 15 + s3 + 49s2 + 339s + 1455
s3 + 9s2 + 23s + 15
× Q(s)2s3 + 50s2 + 113s + 597
s3 + 9s2 + 23s + 15
.
(7.61)
Control example illuminates the fact that the transfer function of the controlled
systems can be written in as speciﬁc form. It turns out that using the controller
K(s) = M11(s) + M12(s)Q(s)

I −M22(s)Q(s)
−1M21(s)
the transfer function of the controlled system can be cast into the form
T(s) = Φ11(s) + Φ12(s)Q(s)Φ21(s)
(7.62)
where Φij(s) is given by

420
7
Robust Control Design
Φ11(s)
Φ12(s)
Φ21(s)
Φ22(s)

=
⎡
⎢⎢⎣
A + B2N1
−B2N1
B1
B2
0
A + N2C2
B1 + N2D21
0
C1 + D12N1
−D12N1
D11
D12
0
C2
D21
0
⎤
⎥⎥⎦.
7.2.6 Control Example 7.4
We reexamine the system previously treated in Example 7.3. We learned before
that A is stable. It is not difﬁcult to see that the pairs (A,B2) and (A,C2) are
stabilizable and detectable, respectively. Also, by default, Dt
12D12 = 1 > 0 and
D21Dt
21 = 4 > 0. Simple computation shows for all ω that
rank
A −jωI
B2
C1
D12

= rank
⎡
⎢⎢⎣
−5 −jω
2
−4
6
0
−3 −jω
0
8
0
7
−1 −jω
−5
−2
9
4
1
⎤
⎥⎥⎦= 4,
rank
A −jωI
B1
C2
D21

= rank
⎡
⎢⎢⎣
−5 −jω
2
−4
7
0
−3 −jω
0
−3
0
7
−1 −jω
1
6
3
−1
1
⎤
⎥⎥⎦= 4.
Therefore, the assumptions in (7.57) are satisﬁed. Proceeding to look at the Riccati
equations (7.58), we ﬁrst see that
Ct
1

I −D12

D12Dt
12
−1Dt
12

C1 = Ct
1(1 −1)C1 = 0,
B1

I −Dt
21

Dt
21D21
−1D21

Bt
1 = B1(1 −1)Bt
1 = 0.
Hence, the solutions of (7.58) are S = 0 and Z = 0. This is turn leads to
N1 = −

Dt
12D12
−1
Bt
2S + Dt
12C1

= −

Dt
12D12
−1Dt
12C1
= −C1 =

−2
−9
4

,
N2 = −

ZCt
2 + B1Dt
21

Dt
21D21
−1 = −B1Dt
21

Dt
21D21
−1
= −B1/2 =

−3.5
1.5
−0.5
t.
The optimal transfer function K(s) is given by
K(s) = −N1(sI −A −B2N1 −N2C2)−1N2
=
18.5s2 + 12.5s + 334.5
s3 + 65s2 + 2275s + 9665
which can be realized by the state-space model
ξ(t) =
⎡
⎣
−14
−62
−24.5
25
−70.5
−33.5
−13
50.5
19.5
⎤
⎦ξ(t) +
⎡
⎣
−3.5
1.5
−0.5
⎤
⎦y(t),
u(t) =

−2
−9
4
ξ(t).
(7.63)
Next, we address the H∞control problem.

7.3
H∞Control
421
7.3 H∞Control
In this section, we introduce what is known as H∞-optimization as a design tool for
linear multivariable control systems. H∞-optimization amounts to the minimization
of the ∞-norm of a relevant frequency response function. The name derives from
the fact that mathematically the problem may be set in the space H∞(the Hardy
space), which consists of all bounded functions that are analytic in the right-half
complex plane. We do not go to this length, however. H∞-optimization resembles
H2-optimization, where the criterion is the 2-norm. Because the 2- and ∞-norms
have different properties the results naturally are not quite the same. An important
aspect of H∞optimization is that it allows to include robustness constraints explic-
itly in the criterion.
In the sequel, we let the controller K and plant G(s) be real, rational and proper.
We assume that the state space models of K and G(s) are available and that their
realizations are assumed to be stabilizable and detectable. In this regard, the optimal
H∞control problem [22, 25] is to ﬁnd all the admissible controllers K such that Tzv
is minimized. It should be noted that the optimal H∞controllers are generally not
unique for MIMO systems. Furthermore, ﬁnding the optimal H∞controller is often
both theoretically and numerically complicated. This is certainly in contrast with the
standard H2 theory, in which the optimal controller is unique and can be obtained
by solving two Riccati equations without iterations. Knowing the achievable optimal
(minimum) H∞norm may be useful theoretically since it sets a limit on what we
can achieve.
7.3.1 Two Hamiltonians
In practice however, it is often not necessary and sometimes even undesirable to de-
sign an optimal controller and it is usually much cheaper to obtain controllers that
are very close in norm sense to the optimal ones, which will be called suboptimal
controllers. A suboptimal controller may have some other properties which are bet-
ter than the optimal controller (for example, lower bandwidth). The realization of
the transfer matrix G(s) is taken to be of the form
G(s) =
⎡
⎣
A
B1
B2
C1
0
D12
C2
D21
0
⎤
⎦.
(7.64)
The following standard assumptions are considered hold: The matrix block D22 is
assumed to be zero so that G22 is strictly proper, also D11 is assumed to be zero in
order to guarantee that H2 control problem is properly posed. We also assume that
(A,B1) is controllable and (C1,A) is observable and that (A,B2) is stabilizable and
(C2,A) is detectable.
It is known that the H∞solution involves the following two Hamiltonian matri-
ces [20, 21, 25]:

422
7
Robust Control Design
H∞=

A
γ −2B1B∗
1 −B2B∗
2
−C1C∗
1
−A∗

,
(7.65)
J∞=

A∗
γ −2C1C∗
1 −C2C∗
2
−B1B∗
1
−A

.
(7.66)
Now it is clear that if the performance level γ approaches inﬁnity, then these two
Hamiltonian matrices become similar to the H2 Hamiltonian matrices. The transfer
function from v to z can be written as
Tzv =
⎡
⎣
A
B2F∞
B1
−Z∞L∞C2
ˆA∞
−Z∞L∞D21
C1
D12F∞
0
⎤
⎦.
(7.67)
7.3.2 LMI Framework
In this section, we provide an LMI-formulation of the H2 and H∞control design.
We direct attention to alternative techniques for computing the state-feedback con-
troller u = Lx. The closed-loop system is described by
˙xs(t) = Asxs(t) + Γ w(t),
(7.68)
z(t) = Gsxs(t) + Φw(t),
As = A + BL,
Gs = G + DL.
(7.69)
Designing an H2 controller is approached via convex analysis. Suppose a Lya-
punov function for the closed-loop system (7.68) is selected as
V (xs) = xt
sPxs(t),
0 < Pt = P ∈ℜn×n.
(7.70)
Along the solutions of the closed-loop system (7.68) with w(t) ≡0, we obtain
˙V (xs) = xt
s

PAs + At
sP

xs.
(7.71)
From the Lyapunov theorem, the closed-loop system (7.68) is internally asymptoti-
cally stable if
At
sP + PAs < 0
(7.72)
is satisﬁed. The objective of this paper is to develop LMI-based characterization of
the two optimization problems:
A) The H2-norm optimization in which it is required to ﬁnd the state-feedback gain
L that ensures the stability of closed-loop system (7.68) and keeps the H2-norm
of the transfer function Tzw(s) from w to z as small as possible.
B) The H∞-norm optimization in which it is required to ﬁnd the state-feedback
gain L that ensures the stability of closed-loop system (7.68) and keeps the
∥z∥2 < γ ∥w∥2 for a prescribed attenuation level γ > 0.

7.3
H∞Control
423
7.3.3 H2 Design
Provided matrix As is Hurwitz for given L with Φ ≡0, Ψ ≡0, the square of the
H2-norm of the transfer function Hzw(s) can be expressed in terms of the solution of
a Lyapunov equation (controllability Grammian) such that the corresponding mini-
mization problem with respect L is given by
min

Tr

Ct
sPsCs

: AsPs + PsAt
s + Γ Γ t = 0

(7.73)
where Tr[.] denotes the trace operator. Since Ps < P for any P satisfying
AsP + PAt
s + Γ Γ t < 0
(7.74)
it is readily veriﬁed that ∥Hzw(s)∥2
2 = Tr[Ct
sPCs] < ν if and only if there exists
P > 0 satisfying (7.74) and Tr[Ct
sPCs] < ν. Introducing an auxiliary parameter W,
and in line of [16] the following analytical result is obtained.
Theorem 7.1 Matrix As is stable and ∥Hzw(s)∥2
2 < ν for a prescribed ν if and only
if there exist matrices ˆP, W such that
Tr(W) < ν,
(7.75)

At
s ˆP + ˆPAs
ˆPΓ
•
−I

< 0,
(7.76)
 ˆP
Ct
s
•
W

> 0.
The main design result is summarized by the following theorem.
Theorem 7.2 System (7.68)–(7.69) is stable with ∥Hzw(s)∥2
2 < ν for a prescribed
ν if and only if there exist matrices 0 < X , 0 < Y and W such that
Tr(W) < ν,
(7.77)
AX + XAt + BY + YtBt
Γ
•
−I

< 0,
(7.78)
X
XGt + YtDt
•
W

> 0.
(7.79)
Moreover, the controller gain is L = YX −1.
Proof A congruent transformation [16–18] via diag[X
I], X = ˆP−1 on (7.76)
yields (7.79).
□

424
7
Robust Control Design
7.3.4 H∞Design
In what follows, we consider the H∞-norm optimization problem. It follows from
robust control theory [25] that the solution of this problem corresponds to determin-
ing the controller parameters that guarantees the feasibility of
˙V (xs) + ztz −γ 2wtw < 0.
(7.80)
The design result is summarized by the following theorem.
Theorem 7.3 System (7.68) is asymptotically stable with γ -disturbance attenuation
if there exist matrices 0 < X , 0 < Y, and scalar γ > 0 satisfying the following LMI
⎡
⎣
Πo
Γ
Πc
•
−γ 2I
Φt
•
•
−I
⎤
⎦< 0,
(7.81)
Πo = AX + XAt + BY + YtBt,
(7.82)
Πc = XGt + YtDt.
Moreover, the controller gain is L = YX −1.
Proof With the aid of (7.71), we express inequality (7.80) in the form
xt
s

PAs + At
sP

xs + [Csxs + Φw]t[Csxs + Φw]
+ 2xt
sPΓ −γ 2wtw < 0.
(7.83)
Inequality (7.83), by Schur complements, is equivalent to
⎡
⎣
PAs + At
sP
PBs
Ct
s
•
−γ 2I
Dt
s
•
•
−I
⎤
⎦< 0
(7.84)
for any [xs,w] ̸= 0. Applying the congruent transformation diag[XI], X = ˆP−1 to
(7.84) and using LX = Y, we readily obtain LMI (7.81) subject to (7.82), which
concludes the proof.
□
7.3.5 Mixed H2–H∞Synthesis
Considering system (7.85), the mixed H2–H∞synthesis problem deals with the
problem of ﬁnding the state-feedback controller which minimizes the H2 norm
of the transfer function Tzw(s) and subject to the H∞-norm constrained by the
bound γ .

7.4
Control Design of Hydraulic Pumping System
425
Fig. 7.3 State trajectories
using LQR
7.4 Control Design of Hydraulic Pumping System
The ﬁrst design method is the linear quadratic regulator discussed earlier in Chap. 6.
For the simulation, we selected the weighting matrix R was kept constant and the
matrix Q was varied in three different cases. The optimum results were obtained at.
Q = 0.1 × I2×2,
R = 1.
In our system, the two states have the same amount of signiﬁcance. Hence, they
have been weighted equally in each case. In the above simulation, the matrix R was
used to weight the control input applied. The matrix Q was used to weight the states
of the system. Simulation was carried out such that the weight on the inputs was kept
constant and the weight on the states was varied to obtain the optimum results. With
respect to the Norm of the Gain matrix and the time taken by the states to settle to
steady state, it is concluded that the case shown in Fig. 7.3 has yielded optimum
results.
Turning to the discrete-time LQR, the simulation was carried out such that the
weight on the inputs was kept constant and the weight on the states was varied to
study the behavior of the system in three different cases. Optimum results were
found using the following weighting matrices:
Q = I2×2,
R = 1.
Of all the cases simulated, it is noted that the controller gain K is the largest in
the case shown in Fig. 7.4, while the settling time is also the least in the third case.
Hence, as we increase the controller gain, the settling time decreases. The response
of the DLQR regulator is similar to the LQR regulator, the only difference being the
control that is applied at discrete instants equal to the sampling time of the system
model.
Just as in the continuous LQR all the have been weighted equally in each case
while implementing the discrete regulator. In the above simulation, the matrix R
was used to weight the control input applied. The matrix Q was used to weight the
states of the system.

426
7
Robust Control Design
Fig. 7.4 States of the system
using DLQR
Fig. 7.5 State trajectories
using LQGR
7.4.1 LQGR Control
The simulation of the (LQG) as carried out using a combination of the Linear
Quadratic Regulator and a Kalman state estimator. The noises in consideration were
the input noise and the plant noise. The LQG regulator was designed for three dif-
ferent cases by varying the LQR gains. The state trajectories are plotted in Fig. 7.5.
The weighting matrix R was kept constant and the and the matrix Q was varied
in three different cases. There were considerable oscillations observed in the states
before they settle to steady state in the ﬁrst case, they were reduced in the second
case and found to be minimum in the third case. The controller gain K required to
control the system was also found to be minimum in the third case.
7.4.2 H2 Optimal Control
The performance of a feedback system can be quantiﬁed in terms of the closed-
loop gain from the disturbance inputs to the reference outputs. The system 2-norm

7.4
Control Design of Hydraulic Pumping System
427
Fig. 7.6 Comparison of state
trajectories using different
controllers
Fig. 7.7 State trajectories
using H2 control
represents an average gain and can be used as a performance function for an opti-
mal control problem. In what follows, the simulation for various values of D12 and
D21 the value of gain matrix K for the most optimal controller was found to be at
D12 = 0, D21 = 20 × I2×2. The state trajectories are plotted in Fig. 7.7.

428
7
Robust Control Design
7.4.3 H∞Control
It is known that the H∞solution involves the following two Hamiltonian matrices
[20, 21, 25]:
H∞=

A
γ −2B1B∗
1 −B2B∗
2
−C1C∗
1
−A∗

,
J∞=

A∗
γ −2C1C∗
1 −C2C∗
2
−B1B∗
1
−A

.
Now it is clear that if the performance level γ approaches inﬁnity, then these two
Hamiltonian matrices become similar to the H2 Hamiltonian matrices. The transfer
function from v to z can be written as
Tzv =
⎡
⎣
A
B2F∞
B1
−Z∞L∞C2
ˆA∞
−Z∞L∞D21
C1
D12F∞
0
⎤
⎦.
The H∞solution involves the following two Hamiltonian matrices:
H∞=

A
γ −2B1B∗
1 −B2B∗
2
−C1C∗
1
−A∗

,
J∞=

A∗
γ −2C1C∗
1 −C2C∗
2
−B1B∗
1
−A

.
Now it is clear that if γ approaches inﬁnity, then these two Hamiltonian matrices
become similar to the H2 Hamiltonian matrices. The transfer function from v to z
can be written as
Tzv =
⎡
⎣
A
B2F∞
B1
−Z∞L∞C2
ˆA∞
−Z∞L∞D21
C1
D12F∞
0
⎤
⎦.
On simulation using MATLAB, for various values of D12, the value of gain ma-
trix K for the most appropriate controller was found to be at
D12 = 20,
D21 = 0.02 × I3×3.
The state trajectories are plotted in Fig. 7.8. A comparison of the state trajectories
are plotted in Fig. 7.6.
7.5 Vapor Compression Cycle Systems
In Chap. 6, we provided identiﬁed state-space models [A, B, C, D] based on two dis-
tinct output cases and presented typical control design and simulation results using
LQR methods in the continuous-domain and discrete-domain. Here, we present the
simulation results based on H2, H∞and LQGR designs. Then we compare between
the controlled states arising from these designs.

7.5
Vapor Compression Cycle Systems
429
Fig. 7.8 State trajectories
using H∞control
Fig. 7.9 State trajectories of
system at D21 = 20 × I2×2
7.5.1 H2 Results
On simulation, for various values of D12 and D21 the value of gain matrix K for the
most optimal controller was found to be
D12 = 0,
D21 = 20 × I2×2
we get Norm(K) = 5.1796 × 105. The corresponding state trajectories are plotted
in Fig. 7.9.
In H2 control, we have carried out the simulation of the system considering the
matrix D12 to be zero and the values of the matrix D21 have been varied. The system
has been studied in ﬁve different cases assuming the values of D21 to be 0.002 ×
I2×2, 0.02 × I2×2, 0.2 × I2×2, 2 × I2×2 and 20 × I2×2. Comparing the results of
the cases above, we observe that the feedback gain required in the ﬁrst four cases is
very high. With respect to the response of the system and the control input required,
it is concluded that the we get the best response at D12 = 0, D21 = 20 × I2×2. The
corresponding state trajectories are plotted in Fig. 7.10.

430
7
Robust Control Design
Fig. 7.10 States of system at
D12 = 20 × I2×2
7.5.2 H∞Results
On simulation using MATLAB, for various values of D12, the value of gain matrix
K for the most appropriate controller was found to be:
At D12 = 20, D21 = 0.02 × I3×3, we get Norm(K) = 1.0115 × 105.
In H∞control, we have carried out the simulation of the system considering the
matrix D21 to be constant at 0.02×I3×3 and the values of the matrix D12 have been
varied. The system has been studied in four different cases assuming the values of
D12 to be 0.02, 0.2, 2, 20. Comparing the results of the cases above, we observe that
the feedback gain required in the ﬁrst case is very high. The last 3 cases do not have
much difference in the gain K. But it is observed that the number of oscillations
have been drastically reduced in the last case. Therefore, based on the response of
the system and the control input required, it is concluded that the we get the best
response at D12 = 20, D21 = 0.02 × I3×3.
7.5.3 LQGR Results
The simulation of the Linear Quadratic Gaussian regulator was carried out using a
combination of the Linear Quadratic Regulator and a Kalman state estimator. The
noises in consideration were the input noise and the plant noise. The LQG regulator
was designed for three different cases by varying the LQR gains. The weighting
matrix R was kept constant and the and the matrix Q was varied in three different
cases. There were considerable oscillations observed in the states before they settle
to steady state in the ﬁrst case, they were reduced in the second case and found to
be minimum in the third case. The controller gain K required to control the system
was also found to be minimum in the third case. The corresponding state trajectories
are plotted in Fig. 7.11.

7.5
Vapor Compression Cycle Systems
431
Fig. 7.11 States of system
at Q3
Fig. 7.12 Comparison of
state x1
7.5.4 A Comparative Study
The controller gain in the three cases is 1.1889 × 104 for LQR, 5.1796 × 105 for
H2 control and 1.0115 × 105 for Hinf control. It is noted that the gain requirements
for H2 and H∞control techniques do not vary much but are ten times the gain
required by LQR controller. Therefore, it is concluded that the H∞controller is best
suited for the control of the Vapor compression system though its gain requirement
is higher than that of LQR. The corresponding state trajectories for different methods
put together are plotted in Figs. 7.12–7.17.
The Kalman Filter was used on the system to ﬁlter out the noises acting on the
system at the inputs, on the states and at the output. The Kalman Filer was im-
plemented along with the Linear Quadratic Regulator to form a Linear Quadratic
Gaussian Regulator. The LQG regulator is a more complex version of the LQR reg-
ulator that can be used for a system with Gaussian noises acting on it.

432
7
Robust Control Design
Fig. 7.13 Comparison of
state x2
Fig. 7.14 Comparison of
state x3
Fig. 7.15 Comparison of
state x4

7.6
Robust Control of Turbo Diesel Engine
433
Fig. 7.16 Comparison of
state x5
Fig. 7.17 Comparison of
state x6
7.6 Robust Control of Turbo Diesel Engine
Modern diesel engines are typically equipped with the VGT and EGR and both in-
troduce feedback loops from exhaust to intake manifold. The recirculated exhaust
gas is cooled down in the EGR cooler and its mass ﬂow is controlled via the EGR
valve. Both the EGR valve and the VGT are pneumatically actuated and ﬁtted with
position sensors. An intercooler reduces the temperature of the compressed air com-
ing from the compressor. In addition to the standard production type sensors, for
mass air ﬂow (MAF) and manifold absolute pressure (MAP), the engine is equipped
with various temperature and pressure sensors as well as with a turbocharger speed
and inline shaft torque sensor. Exhaust gas recirculation (EGR) combined with the
variable geometry turbocharging provides an important avenue for NOx emission
reduction.
Reference is made Sect. 6.5 where we discussed a class of turbo diesel engines.
In what follows, we consider a typical turbocharger consisting of an exhaust gas
driven turbine that, by means of a mechanical shaft, is able to transfer its kinetic
energy to the compressor impeller. The impeller imparts this energy to the air, which
is turned into density increase in the compressor diffuser. The variable geometry

434
7
Robust Control Design
turbocharging is accomplished by a turbine that has a system of movable guide vanes
located on the turbine stator. By adjusting the guide vanes, the exhaust gas energy to
the turbocharger can be regulated, thus controlling the compressor mass airﬂow and
exhaust manifold pressure. The variable geometry turbocharger (VGT) actuator is
typically used to control the intake manifold absolute pressure (MAP) and the EGR
valve controls the mass air ﬂow (MAF) into the engine. Both the EGR and VGT
paths are driven by the exhaust gas and hence constitute an inherently multivariable
control problem. Recall that the effect of the EGR and VGT actuators is coupled
through the pressure in the exhaust manifold, therefore a co-ordinated approach
will yield a better performance than the control strategies using SISO techniques.
An appropriate linearized model that can be conveniently cast into the format
˙x(t) = Ax(t) + Bu(t) + Γ w(t),
z(t) = Gx(t) + Du(t) + Φw(t),
(7.85)
y(t) = Cx(t) + Ψ w(t),
where x(t) ∈ℜn, u(t) ∈ℜm, y(t) ∈ℜp, z(t) ∈ℜq and w(t) ∈ℜq are the state, the
control input, the measured output, the controlled output and the external distur-
bance vectors. The matrices A, B, C, G, D, F , Φ, Ψ are real constants, the numer-
ical values of which are given in the simulation section. In system (7.85), the states
components are mx = mass at the exhaust manifold, px = pressure at the exhaust
manifold, mi = mass at the intake manifold, pi = pressure at the exhaust manifold,
Nt = turbocharger shaft speed and Wci = compressor mass ﬂow. The system inputs
are u1 = exhaust gas recirculation (EGR) actuator position and u2 = variable ge-
ometry turbocharger (VGT) actuator (vanes) position, whereas the system outputs
which are y1 = intake manifold absolute pressure (MAP) and y2 = intake mass air
ﬂow (MAF).
7.6.1 Robust Simulation Results
Modern internal combustion engines equipped with variable valve actuation systems
are proven to achieve better combustion characteristics. By appropriately varying
the valve timing, one can increase fuel economy, boost power output and reduce
emissions [19]. In particular, the problem of optimizing plug-in hybrid electric ve-
hicle (PHEV) power management is studied in [12] by using stochastic dynamic
over a distribution of drive cycles, rather than a single cycle and explicitly trades
off fuel and electricity usage. Linear feedback controllers are developed in [13] for
an electro-hydraulic valve system (EHVS) and a repetitive feed-forward controller
is added to improve the tracking performance. The problem of power management
of hybrid electric vehicles (HEVs) is treated in [14] via the Pontryagin’s minimum
principle as a viable real-time strategy. By employing performance index including
fuel consumption, exhaust emission, or acceleration performance over the whole
driving-cycle information, global optimal results are reported in [19].

7.6
Robust Control of Turbo Diesel Engine
435
Fig. 7.18 States of system at
D21 = 20 × I2×2
Using typical data [19], the different parameters are τv = 0.01 s, ωM =
173.45 r/s, α = 4.7408 s, cL = 0.077, γ = 0.5432, ωh = 138.68 r/s. By evaluat-
ing the model matrices given by (4.70), it is readily seen that the linearized system
is unstable as it has eigenvalue at the origin and has internal oscillations due to a
pair of complex.
H2 Control
On simulation, for various values of D12 and D21 the value of gain matrix K for the
most optimal controller was found to be at D12 = 0, D21 = 20 × I2×2, we get
K =
−0.0009
−4.7608
−0.9451
−2.3892
0.0500
−0.8939
0.9765
1.3927

,
∥K∥= 5.409.
(7.86)
The corresponding state trajectories are plotted in Fig. 7.18.
In H2 control we have carried out the simulation of the system considering the
matrix D12 to be zero and the values of the matrix D21 have been varied. The system
has been studied in ﬁve different cases assuming the values of D21 to be 0.002 ×
I2×2, 0.02 × I2×2, 0.2 × I2×2, 2 × I2×2 and 20 × I2×2. Comparing the results of
the cases above, we observe that the feedback gain required in the ﬁrst four cases is
very high. With respect to the response of the system and the control input required,
it is concluded that the we get the best response at D12 = 0, D21 = 20 × I2×2.
H∞Control
On simulation using MATLAB, for various values of D12, the value of gain matrix
K for the most appropriate controller was found to be:
At D12 = 20, D21 = 0.02 × I3×3, we get
K =
−0.0000
0.0000
−0.0499
−0.0000
0.9199
1.9248
−0.3750
−0.9967

,
∥K∥= 2.384.
(7.87)

436
7
Robust Control Design
Fig. 7.19 States of system at
D12 = 20 × I2×2
In H∞control we have carried out the simulation of the system considering the
matrix D21 to be constant at 0.02×I3×3 and the values of the matrix D12 have been
varied. The system has been studied in four different cases assuming the values of
D12 to be 0.02, 0.2, 2, 20. Comparing the results of the cases above, we observe that
the feedback gain required in the ﬁrst case is very high. The last 3 cases do not have
much difference in the gain K. But it is observed that the number of oscillations
have been drastically reduced in the last case. Therefore, based on the response of
the system and the control input required, it is concluded that the we get the best
response at D12 = 20, D21 = 0.02 × I3×3, see the corresponding state trajectories
as plotted in Fig. 7.19.
7.6.2 Kalman Filter
The Kalman gains and estimation error variances are generated for this system with
various values for the plant noise spectral density matrix, the measurement noise
spectral density matrix and the initial estimation error covariance matrix. In ad-
dition, the system is simulated and the simulated measurements are put into the
Kalman ﬁlter to yield the estimated states, which are then compared with the actual
states. The estimates approach the actual states as shown in the plots.
The plant states depart from a predictable pattern more rapidly when the plant
noise spectral density is increased. As a consequence, the steady-state estimation
errors increase, since less averaging can be performed on the measurements. The
variation in measurement efﬁciency is more visible in the output y2. The Kalman
ﬁlter simulation was carried out taking into consideration the system noise and mea-
surement noise. The initial estimation error covariance matrix Bv was deﬁned as
Bv =
⎡
⎢⎢⎣
1
1
0
0
1
1
10
0
⎤
⎥⎥⎦.

7.6
Robust Control of Turbo Diesel Engine
437
Fig. 7.20 Estimation error
of y1
Fig. 7.21 Estimation error
of y2
The spectral density of the plant noise Sw and the measurement noise Sv was se-
lected as 1 each. The random noise was generated and supplied to the system while
the response of the system was studied. The real and estimated states of the sys-
tem were plotted for comparison. The measurement error and estimation error at the
two inputs were also plotted. The estimation output error trajectories are plotted in
Figs. 7.20, 7.21.
7.6.3 LQGR Control
The simulation of the Linear Quadratic Gaussian regulator was carried out using a
combination of the Linear Quadratic Regulator and a Kalman state estimator. The
noises in consideration were the input noise and the plant noise. The LQG regulator
was designed for three different cases by varying the LQR gains. The weighting
matrix R was kept constant and the and the matrix Q was varied in three different
cases. There were considerable oscillations observed in the states before they settle
to steady state in the ﬁrst case, they were reduced in the second case and found to

438
7
Robust Control Design
Fig. 7.22 Real versus
estimated states
Fig. 7.23 States of system at
Q = 10 ∗I4×4
be minimum in the third case. The controller gain K required to control the system
was also found to be minimum in the third case. A comparison between the real and
estimated state trajectories are plotted in Fig. 7.22.
The corresponding state, output and controlled input trajectories are plotted in
Figs. 7.23–7.25.
Comparisons
The above system of a Electro-Hydraulic actuator was studied structurally and vari-
ous optimal control techniques were applied to it. The system response in each case
was studied with respect to its time requirement and the control energy required
while implementing each strategy.
The comparative results of the three techniques namely, LQR, H2 and H∞have
been plotted as shown in Fig. 7.26.
The dashed line represents the response of the LQR regulated system. The dot-
dashed line represents the response of the H2 regulated system and the solid line

7.6
Robust Control of Turbo Diesel Engine
439
Fig. 7.24 Outputs of the
system
Fig. 7.25 Inputs of the
system
Fig. 7.26 Comparison of
state responses
represents the response of the H∞regulated system. The controller gain in the three
cases is 3.4045 for LQR, 5.409 for H2 control and 2.384 for Hinf control. It is noted
that the gain requirements for the control techniques do not vary much.

440
7
Robust Control Design
However with respect to the speed of response it is noted that LQR has the
quickest response of the three techniques compared above. The hydraulic actuator
is commonly used in operations such as tilting of the ailerons or horizontal stabi-
lizers of the aircraft or in other applications where the time factor is very critical.
Therefore, it is desirable that the controller has a fast response with less oscillations
and minimum control gain. Therefore, it is concluded that the LQR controller is best
suited for the control of the Electro-Hydraulic actuator.
The Kalman Filter was used on the system to ﬁlter out the noises acting on the
system at the inputs, on the states and at the output. The Kalman Filer was im-
plemented along with the Linear Quadratic Regulator to form a Linear Quadratic
Gaussian Regulator. The LQG regulator is a more complex version of the LQR reg-
ulator that can be used for a system with Gaussian noises acting on it. The MPC
control was implemented on the system. It was found that MPC control is not feasi-
ble for the given system bearing in mind the system characteristics and the control
requirements of the system.
7.7 The Falling Film Evaporator
Evaporation is used basically in the dairy industry for the concentration of products
like milk, skimmed milk etc. Concentration involves the removal of water from the
product. To minimize the cost evaporation is usually performed in multiple effect
evaporators where two or more effects operate at progressively lower boiling points.
In this type of arrangement, the vapor produced in the previous effect can be used
as the heating medium in the next. The evaporator considered here is a four falling
ﬁlm effects and has a water evaporation capacity of 800 kg/h. The evaporators most
commonly are used in the split effect mode, where only the third effect and the
ﬁnishing effect are used.
7.7.1 H2 Control
The simulation results using H2 control are plotted in Figs. 7.27–7.32.
7.7.2 H∞Control
The simulation results using H∞control are plotted in Figs. 7.33–7.38.
7.8 Integral Control and Robust Tracking
In the state-space design methods discussed so far, no mention has been made of
integral control, and no design examples have produced a compensation containing

7.8
Integral Control and Robust Tracking
441
Fig. 7.27 The ﬁrth state
trajectory using H2 control
Fig. 7.28 The second state
trajectory using H2 control
an integral term. In the sequel, we show how integral control can be introduced by a
direct method of adding the integral of the system error to the equations of motion.
Integral control is a special case of tracking a signal that does not go to zero in
the steady-state. Then we introduce a general method for robust tracking that will
present the internal model principle. This solves an entire class of tracking problems
and disturbance-rejection controls.
7.8.1 Integral Control
Reference is made to Fig. 7.39. We start with a rudimentary solution to integral
control by augmenting the state vector with the desired dynamics. For the system
˙x = Fx + Gu + G1w,
y = Hx,
(7.88)

442
7
Robust Control Design
Fig. 7.29 The third state
trajectory using H2 control
Fig. 7.30 The fourth state
trajectory using H2 control
we can feed back the integral of the error, e = y −r, as well as the state of the plant,
x, by augmenting the plant state with the extra (integral) state xI , which obeys the
differential equation
˙xI = Hx −r(= e),
which leads to
xI =
 t
e dt.
The augmented state equations become
 ˙xI
˙x

=
0
H
0
F
xI
x

+
 0
G

u −
1
0

r +
 0
G1

w,
(7.89)
and the feedback law is
u = −

K1
K0
xI
x

= −K
xI
x

.

7.8
Integral Control and Robust Tracking
443
Fig. 7.31 The ﬁfth state
trajectory using H2 control
Fig. 7.32 The sixth state
trajectory using H2 control
With this revised deﬁnition of the system, we can apply the design techniques
from Chap. 5 in a similar fashion; they will result in the control structure shown
in Fig. 7.39.
7.8.2 Control Example 7.4
Consider the motor speed system described by
u = −K
xI
x

that is, F = −3, G = 1, and H = 1. Design the system to have integral control and
two poles at s = −5. It is required to design an estimator with pole at s = −10. The
disturbance enters at the same place as the control. Then we evaluate the tracking
and disturbance rejection responses.

444
7
Robust Control Design
Fig. 7.33 The ﬁrst state
trajectory using H∞control
Fig. 7.34 The second state
trajectory using H∞control
We proceed by noting that the pole-placement requirement is equivalent to
pc = [−5;−5].
The augmented system description including the disturbance w is
 ˙xI
˙x

=
0
1
0
−3
xI
x

+
0
1

(u + w) −
1
0

r.
Therefore, we can ﬁnd K from
det

sI −
0
1
0
−3

+
0
1

K

= s2 + 10s + 25.
A little algebra gives
s2 + (3 + K0)s + K1 = s2 + 10s + 25
which yields
K =

K1
K0

=

25
7
.

7.8
Integral Control and Robust Tracking
445
Fig. 7.35 The third state
trajectory using H∞control
Fig. 7.36 The fourth state
trajectory using H∞control
The system is shown with feedbacks in Fig. 7.40 along with a disturbance input
w. On the other hand, the estimator gain L = 7 is obtained from
αe(s) = s + 10 = s + 3 + L.
The estimator equation is of the form
˙ˆx = (F −LH)ˆx + Gu + Ly
= −10ˆx + u + 7y
and
u = −K0 ˆx = −7ˆx.
The step response y1 due to a step reference input r, and the output disturbance
response y2 due to a step disturbance input w are shown in Fig. 7.41(a) and the
associated control efforts (u1 and u2) are shown in Fig. 7.41(b). As noted, the system
tracks the step reference input and rejects the step disturbance asymptotically.

446
7
Robust Control Design
Fig. 7.37 The ﬁfth state
trajectory using H∞control
Fig. 7.38 The sixth state
trajectory using H∞control
Fig. 7.39 Integral control structure
7.8.3 The Error-Space Approach
In what follows, we present a more analytical approach to giving a control system
the ability to track (with zero steady-state error) a nondecaying input and to reject
(with zero steady-state error) a nondecaying disturbance such as a step, ramp, or

7.8
Integral Control and Robust Tracking
447
Fig. 7.40 Integral control example
Fig. 7.41 Transient response
for motor speed system:
(a) Step responses,
(b) Control efforts
sinusoidal input. The method is based on including the equations satisﬁed by these
external signals as part of the problem formulation and solving the problem of con-

448
7
Robust Control Design
trol in an error space so we are assured that the error approaches zero even if the
output is following a nondecaying, or even a growing, command (such as a ramp
signal) and even if some parameters change (the robustness property). Although
the method is illustrated in detail for signals that satisfy second-order differential
equations, but the extension to more complex signals is not difﬁcult.
Consider the system state model
ˆx = Fx + Gu + G1w,
y = Hx
(7.90)
and a reference signal that is known to satisfy a speciﬁc differential equation. The
initial conditions on the equation generating the input are unknown. For example,
the input could be a ramp whose slope and initial value are unknown. Plant distur-
bances of the same class may also be present. We wish to design a controller for
this system so that the closed-loop system will have speciﬁed poles and will have
the ability to track input command signals and to reject disturbances of the type de-
scribed without steady-state error. We will develop the results only for second-order
differential equations. Deﬁne the reference input to satisfy the relation
¨r + α1˙r + α2r = 0
(7.91)
and the disturbance to satisfy exactly the same equation:
¨w + α1 ˙w + α2w = 0.
(7.92)
The (tracking) error is deﬁned as
e = y −r.
(7.93)
The problem of tracking r and rejecting w can be seen as an exercise in designing
a control law to provide regulation of the error, which is to say that the error e tends
to zero as time gets large. The control must also be structurally stable or robust, in
the sense that regulation of e to zero in the steady-state occurs even in the presence
of “small” perturbations of the original system parameters. Note that in practice we
never have a perfect model of the plant and the values of parameters are virtually
always subject to some change, so robustness is always very important.
We know that the command input satisﬁes (7.90), and we would like to eliminate
the reference from the equations in favor of the error. We begin by replacing r in
(7.91) with the error in (7.93). When we do this, the reference cancels because of
(7.90), and we have the formula for the error in terms of the state
¨e + α1 ˙e + α2e = ¨y + α1 ˙y + α2y
= H¨x + α1H˙x + α2Hx.
(7.94)
Replacing the plant state vector with the error-space state deﬁned by
ξ := ¨x + α1˙x + α2x
(7.95)
and similarly, we replace the control with the control in error space, deﬁned as
μ := ¨u + α1 ˙u + α2u.
(7.96)

7.8
Integral Control and Robust Tracking
449
With these deﬁnitions we can replace (7.94) with
¨e + α1 ˙e + α2e = Hξ.
(7.97)
The state equation for ξ is given by
˙ξ = d3
dt3 x + α1¨x + α2˙x = Fξ + Gμ.
(7.98)
Notice that the disturbance as well as the reference cancels from (7.98). Note that
(7.97) and (7.98) now describe the overall system in an error space. In standard
state-variable form, the equations are
˙z = Az + Bμ,
(7.99)
where
z =

e
˙e
ξt t
(7.100)
and
A =
⎡
⎣
0
1
0
−α2
−α1
H
0
0
F
⎤
⎦,
B =
⎡
⎣
0
0
G
⎤
⎦.
(7.101)
The error system (A,B) can be given arbitrary dynamics by state feedback if it is
controllable. If the plant (F,G) is controllable and does not have a zero at any of
the roots of the reference-signal characteristic equation
αr(s) = s2 + α1s + α2,
then the error system (A,B) is controllable. Therefore, there exists a control law of
the form
μ = −

K2
K1
K0

⎡
⎣
e
˙e
ξ
⎤
⎦= −Kz,
(7.102)
such that the error system has arbitrary dynamics by pole placement. We now need
to express this control law in terms of the actual process state x and the actual
control. We combine (7.95), (7.96), and (7.102) to get the control law in terms of u
and x (we write u(2) to mean d2u/dt2):
(u + K0x)(2) +
2

i=1
αi(u + K0x)(2−i) = −
2

i=1
Kie(2−i).
(7.103)
The structure for implementing (7.103) is very simple for tracking constant inputs.
In that case the equation for the reference input is ˙r = 0. In terms of u and x, the
control law (7.103) reduces to
˙u + K0˙x = −K1e.
(7.104)
Here, we only need to integrate to reveal the control law and the action of integral
control:
u = −K1
 t
e dτ −K0x.
(7.105)

450
7
Robust Control Design
Fig. 7.42 Integral control using the internal model approach
A block diagram of the system, shown in Fig. 7.42, clearly shows the presence of a
pure integrator in the controller. In this case, the only difference between the internal
model method of Fig. 7.42 and the ad hoc method of Fig. 7.39 is the relative location
of the integrator and the gain.
A more complex problem that clearly shows the power of the error-space ap-
proach to robust tracking is posed by requiring that a sinusoid be tracked with zero
steady-state error. The problem arises, for instance, in the control of a mass-storage
disk-head assembly.
7.8.4 Control Example 7.5
A simple normalized model of a computer disk-drive servomechanism [8] is given
by the equations
F =
0
1
0
−1

;
G =
0
1

;
G1 =
0
1

;
H =

1
0
;
J = 0.
Because the data on the disk is not exactly on a centered circle, the servo must follow
a sinusoid of radian frequency ω0. determined by the spindle speed. It is required to
give the structure of a controller for this system that will follow the given reference
input with zero steady-state error. Then, setting ω0 = 1, consider that the desired
closed-loop poles are at −1 ±
√
3 and −
√
3 ± j1. Finally, demonstrate the tracking
and disturbance rejection properties of the system using MATLAB or Simulink.
We attend to the problem in steps. Initially, the reference input satisﬁes the dif-
ferential equation ¨r = −ω2
0r so that α1 = 0 and α2 = ω2
0. With these values the
error-state matrices according to (7.101) are
A =
⎡
⎢⎢⎣
0
1
0
0
−ω2
0
0
1
0
0
0
0
1
0
0
0
−1
⎤
⎥⎥⎦,
B =
⎡
⎢⎢⎣
0
0
0
1
⎤
⎥⎥⎦.

7.8
Integral Control and Robust Tracking
451
Fig. 7.43 Structure of the tracking compensator for the servomechanism
Simple calculations show that the characteristic equation of A −BK is
s4 + (1 + K02)s3 +

ω2
0 + K01

s2 +

K1 + ω2
0(1 + K02)

s + K01ω2
0K2 = 0
from which the gain may be selected by pole assignment. The compensator imple-
mentation from (7.103) has the structure shown in Fig. 7.43, which clearly shows
the presence of the oscillator with frequency ω0 (known as the internal model of
the input generator) in the controller. This is a particular case of the internal model
principle, which requires that a model of the external or exogenous signal be in the
controller for robust tracking and disturbance rejection [8].
Next, we assume that ω0 = 1 rad/s and the desired closed-loop poles are as given
above. If
pc = [−1 + j
√
3;−1 −j√r;−
√
3 + j;−
√
3 −j]
then the feedback gain is
K =

K2
K1 : K0

=

2.0718
16.3923 : 13.9282
4.4641
which results in the controller
˙xc = Acxc + Bce,
u = Ccxc
with
Ac =
 0
1
−1
0

,
Bc =
−16.323
−2.0718

,
Cc =

1
0
.
The controller frequency response is shown in Fig. 7.44 and shows a gain of
inﬁnity at the rotation frequency of ω0 = 1 rad/s. The frequency response from r
to e, that is, the sensitivity function S(s), is shown in Fig. 7.45 and shows a sharp

452
7
Robust Control Design
Fig. 7.44 Controller
frequency response
Fig. 7.45 Sensitivity function frequency response
notch at the rotation frequency ω0 = 1 rad/s. The same notch is also present in the
frequency response of the transfer function from w to y. In Fig. 7.46, a Simulink
simulation diagram for the system is shown. Although the simulations can also he
clone in MATLAB, it is more instructive to use the interactive graphical environ-
ment of Simulink. Simulink also provides the capability to add nonlinearities and
carry out robustness studies efﬁciently. The tracking properties of the system are
shown in Fig. 7.47 showing asymptotic tracking property of the system. The dis-
turbance rejection properties of the system are illustrated in Fig. 7.48 depicting
asymptotic disturbance rejection of sinusoidal disturbance input. The closed-loop
frequency response, that is, the complementary transfer function T (s), for the ro-
bust servomechanism is shown in Fig. 7.49. As seen from the ﬁgure, the frequency
response from r to y is unity at ω0 = 1 rad/s as expected.
The zeros of the system from r to e are located at ±j, −2.7321 ± j2.5425. The
robust tracking properties are due to the presence of the blocking zeros at ±j. The
zeros from w to y, both blocking zeros, are located at ±j. The robust disturbance
rejection properties are due to the presence of these blocking zeros.

7.8
Integral Control and Robust Tracking
453
Fig. 7.46 Simulink block diagram for robust servomechanism
Fig. 7.47 Tracking
properties for robust
servomechanism
Fig. 7.48 Disturbance
rejection properties for robust
servomechanism
From the nature of the pole-placement problem, the state z in (7.100). will tend
toward zero for all perturbations in the system parameters as long as A−BK remains
stable. Notice that the signals that are rejected are those that satisfy the equations

454
7
Robust Control Design
Fig. 7.49 Closed-loop frequency response for robust servomechanism
with the values of α1 actually implemented in the model of the external signals. The
method assumes that these are known and implemented exactly. If the implemented
values are in error, then a steady-state error will result.
7.8.5 Control Example 7.6
Consider the system
H(s) =
1
s + 3
which has the state-variable description
F = −3,
G = 1,
H = 1.
It is desired to construct a controller with poles at s = −5 to track an input that
satisﬁes ˙r = 0.
We proceed as follows. The error system is
 ˙e
˙z

=
0
1
0
−3
0
1

μ
and the desired characteristic equation has the form
αc(s) = s2 + 10s + 25,
(7.106)
then the pole-placement equation for K is
det[sI −A + BK] = αc(s).
(7.107)
By (7.106) and (7.107), we have
s2 + (3 + K0)s + K1 = s2 + 10s + 25,

7.8
Integral Control and Robust Tracking
455
Fig. 7.50 Example of internal model with feedforward
which gives
K =

25
7
=

K1
K0

,
and the system is implemented as shown in Fig. 7.50. The transfer function from r
to e for this system, the sensitivity function,
E(s)
R(s) = S(s) = −
s(s + 10)
s2 + 10s + 25
shows a blocking zero at s = 0, which prevents the constant input from affecting
the error. The closed-loop transfer function, that is, the complementary sensitivity
function is
Y(s)
R(s) = T =
5
s2 + 10s + 25.
The structure of Fig. 7.50 permits us to add a feedforward of the reference input,
which provides one extra degree of freedom in zero assignment. If we add a term
proportional to r in (7.104), then
u = −K1
 t
e(τ)dτ −K0x + Nr.
(7.108)
This relationship has the effect of creating a zero at −K1/N. The location of this
zero can he chosen to improve the transient response of the system. For actual im-
plementation, we can rewrite (7.108) in terms of e to get
u = −K1
 t
e(τ)dτ −K0x + N(y −e).
(7.109)
The block diagram for the system is shown in (7.108). It is easy to see that the
overall transfer function becomes
Y(s)
R(s) =
Ns + 25
s2 + 10s + 25.
Notice that the DC gain is unity for any value of N and that through our choice of N
we can place the zero at any real value to improve the dynamic response. A natural
strategy for locating the zero is to have it cancel one of the system poles, in this case

456
7
Robust Control Design
Fig. 7.51 Internal model as integral control with feedforward
Fig. 7.52 Step responses
with integral control and
feedforward
at s = −5. The step response of the system is shown in Fig. 7.52 for N = 5, as well
as for N = 0 and 8. With the understanding that one pole can be canceled in integral
control designs, we make sure to choose one of the desired control poles such that
it is both real and able to be canceled through the proper choice of N.
7.8.6 The Extended Estimator
Recall that the discussion of robust control so far has used a control based on full-
state feedback. If the state is not available, then as in the regular case, the full-state
feedback, Kx, can be replaced by the estimates, Kˆx, where the estimator is built as
before. As a ﬁnal look at ways to design control with external inputs, in this section
we develop a method for tracking a reference input and rejecting disturbances. The
method is based on augmenting the estimator to include estimates from external
signals in a way that permits us to cancel out their effects on the system error.
Suppose the plant is described by the equations
˙x = Fx + Gu + Gw,
y = Hx,
(7.110)
e = Hx −r.

7.8
Integral Control and Robust Tracking
457
Fig. 7.53 Block diagram of a
system for tracking and
disturbance rejection with
extended estimator:
Equivalent disturbance
Fig. 7.54 Block diagram of a
system for tracking and
disturbance rejection with
extended estimator: Block
diagram for design
Fig. 7.55 Block diagram of a
system for tracking and
disturbance rejection with
extended estimator: Block
diagram for implementation
Furthermore, assume that both the reference r and the disturbance w are known to
satisfy the equations1
αw(s)w = αρ(s)w = 0,
(7.111)
αr(s)r = αρ(s)r = 0,
(7.112)
where
αρ(s) = s2 + α1s + α2
corresponding to polynomials αw(s) and αr(s) in Fig. 7.53. In general, we would
select the equivalent disturbance polynomial αρ(s) in Fig. 7.54 to be the least com-
mon multiple of αw(s) and αr(s). The ﬁrst step is to recognize that, as far as the
1Again we develop the results for a second-order equation in the external signals; the discussion
can be extended to higher-order equations.

458
7
Robust Control Design
steady-state response of the output is concerned, there is an input-equivalent signal
ρ that satisﬁes the same equation as r and w and enters the system at the same place
as the control signal as shown in Fig. 7.54. As before, we must assume that the plant
does not have a zero at any of the roots of (7.111). For our purposes here, we can
replace (7.111) with
˙x = Fx + G(u + ρ),
e = Hx.
(7.113)
If we can estimate this equivalent input, we can add to the control a term −ˆρ that
will cancel out the effects of the real disturbance and reference and cause the output
to track r in the steady-state. To do this, we combine (7.111) and (7.113) into a state
description to get
˙z = Az + Bu,
e = Cz,
(7.114)
where z = [ρ ˙ρ xT ]T . The matrices are
A =
⎡
⎣
0
1
0
−α2
−α1
0
G
0
F
⎤
⎦,
B =
⎡
⎣
0
0
G
⎤
⎦,
C =

0
0
H
.
(7.115)
The system given by (7.115) is not controllable since we cannot inﬂuence ρ from u.
However, if F and H are observable and if the system (F,G,H) does not have a zero
that is also a root of (7.111), then the system of (7.115) will be observable, and we
can construct an observer that will compute estimates of both the state of the plant
and of ρ. The estimator equations are standard, but the control is not:
˙ˆz = Aˆz + Bu + L(e −Cˆz),
u = −Kˆx −ˆρ.
(7.116)
In terms of the original variables, the estimator equations are
⎡
⎣
˙ˆρ
¨ˆρ
˙ˆx
⎤
⎦=
⎡
⎣
0
1
0
−α2
−α1
0
G
0
F
⎤
⎦
⎡
⎣
ˆρ
˙ˆρ
ˆx
⎤
⎦+
⎡
⎣
0
0
G
⎤
⎦u +
⎡
⎣
l1
l2
L3
⎤
⎦[e −Hˆx].
(7.117)
The overall block diagram of the system for design is shown in Fig. 7.54. If we write
out the last equation for ˆx in (7.117) and substitute (7.116), a simpliﬁcation of sorts
results because a term in ˆρ cancels out:
˙ˆx = G ˆρ + Fˆx + G(−Kˆx −ˆρ) + L3(e −Hˆx)
= Fˆx + G(−Kˆx) + L3(e −Hˆx)
= Fˆx + G¯u + L3(e −Hˆx).
With the estimator of (7.117) and the control of (7.116), the state model is
˙x = Fx + G(−Kˆx −ˆρ) + Gρ.
(7.118)

7.8
Integral Control and Robust Tracking
459
In terms of the estimate errors, (7.230) can be rewritten as
˙x = (F −GK)x + GK˜x + G ˜ρ.
(7.119)
Because we designed the estimator to be stable, the values of ˜ρ and ˜x go to zero in
the steady-state, and the ﬁnal value of the state is not affected by the external input.
The block diagram of the system for implementation is drawn in Fig. 7.54. The steps
involved in this process will now be illustrated.
7.8.7 Control Example 7.7
Construct an estimator to controlling the state [8] and canceling a constant bias at
the output and track a constant reference in the motor speed system described by
˙x = −3x + u,
y = x + w,
˙w = 0,
˙r = 0.
(7.120)
Place the control pole at s = −5 and the two extended estimator poles at s = −15.
To begin, we design the control law by ignoring the equivalent disturbance.
Rather, we notice by inspection that a gain of −2 will move the single pole from −3
to the desired −5. Therefore, K = 2. The system augmented with equivalent exter-
nal input ρ, which replaces the actual disturbance w and the reference r, is given
by
˙ρ = 0;
˙x = −3x + u + ρ,
e = x.
The extended estimator equations are
˙ˆρ = li(e −ˆx),
˙ˆx = −3ˆx + u + ˆρ + l2(e −ˆx).
The estimator error gain is found to be L = [225 27]t from the characteristic equa-
tion
det
s
l1
1
s + 3 + l2

= s2 + 30s + 225.
A block diagram of the system is given in Fig. 7.56(top), and the step responses to
input at the command r (applied at t = 0 s) and at the disturbance w (applied at
t = 0.5 s) are shown in Fig. 7.56.

460
7
Robust Control Design
Fig. 7.56 Motor speed
system with extended
estimator: (top) Block
diagram; (bottom) Command
step response and disturbance
step response
7.9 Questions
Q7.1 For the following linear time-invariant system
˙x = Ax + Bd,
e = Cx
consider the optimization problem
sup
d
J(d) = sup
d
 ∞
0

ete −γ 2dtd

dt < ∞.
Show that the solution of this optimization problem leads to relationships identi-
cal to those for the bounded real lemma.
7.10 Notes and References
The H2 optimal control problem is the modern version of what is commonly known
as the linear quadratic Gaussian (LQG) problem. As indicated in the foregoing sec-
tions, minimization of the H2-norm of the closed loop transfer matrix can be given
the stochastic interpretation of minimizing the expected value of the squared norm
of the output, in case that the disturbance input is a standard white noise process. It
is exactly the minimization of this expected value that the classical formulation of
the LQG-problem deals with.

References
461
References
1. Anderson, B.O.D., Moore, J.B.: Linear Optimal Control—Linear Quadratic Methods.
Prentice-Hall, Englewood Cliffs (1990)
2. Bosgra, O.H., Kwakernaak, H.: Design Methods for Control Systems. Dutch Institute of Sys-
tems and Control (2001)
3. Boyd, S.P., Barratt, C.H.: Linear Controller Design: Limits of Performance. Prentice-Hall,
Englewood Cliffs (1991)
4. Doyle, J.C., Stein, G.: Multivariable feedback design: Concepts for a classical/modern syn-
thesis. IEEE Trans. Autom. Control 26, 4–16 (1981)
5. Doyle, J.C., Glover, K., Khargonekar, P.P., Francis, B.A.: State-space solutions to standard H2
and H∞control problems. IEEE Trans. Autom. Control 34, 831–847 (1989)
6. Doyle, J.C., Francis, B.A., Tannenbaum, A.R.: Feedback Control Theory. Macmillan, New
York (1992)
7. Francis, B.A.: A Course in H∞Control Theory. Springer-Verlag, Berlin (1987)
8. Franklin, G.F., Powell, J.D., Naeini, A.E.: Feedback Control of Dynamic Systems, 4th edn.
Prentice-Hall, Englewood Cliffs (2002)
9. Green, M., Limebeer, D.J.N.: Linear Robust Control. Wiley, New York (1999)
10. Gu, Da-Wei, Petkov, P.H., Konstantinov, M.M.: Robust Control Design with MATLAB.
Springer, London (2003)
11. Helton, J.W., Merino, O.: Classical Control Using H∞Methods. Society for Industrial and
Applied Mathematics, Philadelphia (1998)
12. Hu, c., Meng, M.Q., Liu, P.X.: Observer based LQR control of shaping process of automobile
belt. In: Proc. the 5th World Congress on Intelligent Control, China, June, pp. 3310–3314
(2004)
13. Jovanovic, M.: Nonlinear control of an electrohydraulic velocity servosystem. Proc. Am. Con-
trol Conf. 1, 588–593 (2002)
14. Kaddissi, C., Kenne, J.-P., Saad, M.: Identiﬁcation and real-time control of an electrohydraulic
servo system based on nonlinear backstepping. IEEE/ASME Trans. Mechatron. 12, 12–22
(2007)
15. Kwakernaak, H., Sivan, R.: Linear Optimal Control Systems. Wiley, New York (1972)
16. Mahmoud, M.S.: Resilient L2–L∞ﬁltering of polytopic systems with state-delays. IET Con-
trol Theory Appl. 1(1), 141–154 (2007)
17. Mahmoud, M.S., Al-Rayyah, A.Y.: Efﬁcient parameterization to stability and feedback syn-
thesis of linear time-delay systems. IET Control Theory Appl. 3(8), 1107–1118 (2009)
18. Mahmoud, M.S., Xia, Y.: Robust ﬁlter design for piecewise discrete-time systems with time-
varying delays. Int. J. Robust Nonlinear Control 20, 540–560 (2010)
19. Moura, S.J., Fathy, H.K., Callaway, D.S., Stein, J.L.: A stochastic optimal control approach
for power management in plug-in hybrid electric vehicles. IEEE Trans. Control Syst. Technol.
21, 1–11 (2010)
20. Saberi, A., Sannuti, P., Chen, B.M.: H∞Optimal Control. Prentice-Hall, Englewood Cliffs
(1995)
21. Sanchez-Pena, R.S., Sznaier, M.: Robust Systems. Theory and Applications. John Wiley and
Sons, New York (1998)
22. Stoorvogel, A.A.: The H∞Control Problem: A State Space Approach. Prentice-Hall, Engle-
wood Cliffs (1992)
23. Zames, G.: Feedback and optimal sensitivity: Model reference transformations, multiplicative
seminorms and approximate inverses. IEEE Trans. Autom. Control 26, 301–320 (1981)
24. Zames, G., Francis, B.A.: Feedback, minimax sensitivity, and optimal robustness. IEEE Trans.
Autom. Control 28, 585–600 (1983)
25. Zhou, K., Doyle, J.C.: Essentials of Robust Control. Prentice-Hall, Englewood Cliffs (1998)
26. Zhou, K., Doyle, J.C., Glover, K.: Robust and Optimal Control. Prentice-Hall, Upper Saddle
River (1995)

Chapter 8
Adaptive Control
8.1 Introduction
In this chapter, we adopt the deﬁnition of adaptive control as the combination of
a parameter estimator, which generates parameter estimates online, with a control
law in order to control classes of plants whose parameters are completely unknown
and/or could change with time in an unpredictable manner. The choice of the param-
eter estimator, the choice of the control law, and the way they are combined leads
to different classes of adaptive control schemes. Adaptive control as deﬁned above
has also been referred to as identiﬁer-based adaptive control in order to distinguish
it from other approaches referred to as non-identiﬁer-based, where similar control
problems are solved without the use of an online parameter estimator.
The choice of adaptive control as a solution to a particular control problem in-
volves understanding of the plant properties as well as of the performance require-
ments. Research in adaptive control has a long history of intense activities that in-
volved debates about the precise deﬁnition of adaptive control, examples of instabil-
ities, stability and robustness proofs, and applications. The material contained in this
chapter relies on the basic references [8, 9, 19]. Adaptive control involves learning,
and learning requires data which carry sufﬁcient information about the unknown
parameters. For such information to be available in the measured data, the plant has
to be excited, and this may lead to transients which, depending on the problem un-
der consideration, may not be desirable. Furthermore, in many applications there is
sufﬁcient information about the parameters, and online learning is not required. In
such cases, linear robust control techniques may be more appropriate.
8.2 Preliminary Examples
In what follows, we present some typical examples to illustrate the notions of adap-
tive control schemes. The following two simple examples illustrate situations where
adaptive control is superior to the traditional linear control.
M.S. Mahmoud, Y. Xia, Applied Control Systems Design,
DOI 10.1007/978-1-4471-2879-3_8, © Springer-Verlag London Limited 2012
463

464
8
Adaptive Control
8.2.1 Example 8.1
Consider the scalar plant
˙x = ax + u,
where u is the control input and x the scalar state of the plant. The parameter a is
unknown. We want to choose the input u so that the state x is bounded and driven
to zero with time. If a is a known parameter, then the linear control law
u = −kx,
k > |a|,
can meet the control objective. In fact if an upper bound ¯a ≥|a| is known, the above
linear control law with k > ¯a can also meet the control objective. On the other hand,
if a changes so that a > k > 0, then the closed-loop plant will be unstable.
The conclusion is that in the absence of an upper bound for the plant parameter
no linear controller could stabilize the plant and drive the state to zero. The adaptive
control law
u = −kx,
˙k = x2,
guarantees that all signals are bounded and x converges to zero no matter what the
value of the parameter a is. This simple example demonstrates that adaptive control
is a potential approach to use in situations where linear controllers cannot handle
the parametric uncertainty.
8.2.2 Example 8.2
As another example, consider the same example, Example 8.1, but with an external
bounded disturbance d:
˙x = ax + u + d.
The disturbance is unknown but can be approximated as
d =
N

i=1
θ∗
i φi(t,x),
where φi(t,x) are known functions and θ∗
i are unknown constant parameters. In this
case if we use the linear control law
u = −kx
with k > ¯a ≥|a|, we can establish that |x| is bounded and at steady state
|x| ≤
d0
k −a ,
where do is an upper bound for |d|. It is clear that by increasing the value of the
controller gain k, we can make the steady-state value of x as small as we like. This

8.2
Preliminary Examples
465
will lead to a high gain controller, however, which is undesirable especially in the
presence of high-frequency unmodeled dynamics. In principle, however, we cannot
guarantee that x will be driven to zero for any ﬁnite control gain in the presence
of nonzero disturbance d. The adaptive control approach is to estimate online the
disturbance d and cancel its effect via feedback. The following adaptive control law
can be shown to guarantee signal boundedness and convergence of the state x to
zero with time:
u = −kx −ˆd,
ˆd =
N

i=1
θiφi(t,x),
˙θi = xφi(t,x),
where k > ¯a ≥|a|, assuming of course that ¯a is known; otherwise k has to be esti-
mated, too.
It is readily seen that, in addition to stability, adaptive control techniques could be
used to improve performance in a wide variety of situations where linear techniques
would fail to meet the performance characteristics. This by no means implies that
adaptive control is the most appropriate approach to use in every control problem.
8.2.3 Example 8.3
The design of autopilots for high-performance aircraft was one of the primary mo-
tivations for active research in adaptive control. Aircrafts operate over a wide range
of speeds and altitudes, and their dynamics are nonlinear and conceptually time-
varying. For a given operating point, the complex aircraft dynamics can be approx-
imated by a linear model. For example, for an operating point i, the longitudinal
dynamics of an aircraft model may be described by a linear system of the form
[14–16]:
˙x = Aix + Biu,
x(t0) = x0,
y = Ct
i x + DiU,
(8.1)
where the matrices Ai, Bi, Ci, Di are functions of the operating point i; x is the
state; u is the input; and y is the measured outputs. As the aircraft goes through dif-
ferent ﬂight conditions, the operating point changes, leading to different values for
Ai, Bi, Ci, Di. Because the measured outputs carry information about the state x
and parameters, one may argue that, in principle, a sophisticated feedback controller
could learn the parameter changes, by processing the outputs y(t), and use the ap-
propriate adjustments to accommodate them. This argument led to a feedback con-
trol structure on which adaptive control is based. The controller structure consists
of a feedback loop and a controller with adjustable gains, as shown in Fig. 8.1. The
way of adjusting the controller characteristics in response to changes in the plant
and disturbance dynamics distinguishes one scheme from another.

466
8
Adaptive Control
Fig. 8.1 General adaptive control structure for aircraft control
8.3 Adaptive Control Approaches
The class of adaptive control schemes studied in this chapter is characterized by
the combination of an online parameter estimator, which provides estimates of the
unknown parameters at each instant of time, with a control law that is motivated
from the known parameter case. The way the parameter estimator, also referred to
as adaptive law in the chapter, is combined with the control law gives rise to two
different approaches. In the ﬁrst approach, referred to as indirect adaptive control,
the plant parameters are estimated online and used to calculate the controller pa-
rameters. Typically, at each time t, the estimated plant is formed and treated as if
it is the true plant in calculating the controller parameters. This approach has also
been referred to as explicit adaptive control, because the controller design is based
on an explicit plant model. In the second approach, referred to as direct adaptive
control, the plant model is parameterized in terms of the desired controller pa-
rameters, which are then estimated directly without intermediate calculations in-
volving plant parameter estimates. This approach has also been referred to as im-
plicit adaptive control because the design is based on the estimation of an implicit
plant model. In [1–3, 5–7, 10–18, 20–23], pertinent issues have been thoroughly
discussed.
8.3.1 Indirect Adaptive Control Approach
The basic structure of indirect adaptive control is shown in Fig. 8.2. The plant
model G(θ∗) is parameterized with respect to some unknown parameter vec-
tor θ∗.
For example, for a linear time-invariant (LTI) single-input single-output (SISO)
plant model, θ∗is a vector with the unknown coefﬁcients of the numerator and
denominator of the plant model transfer function. An online parameter estimator
generates the estimate θ(t) of θ∗at each time t by processing the plant input u
and output y. The parameter estimate θ(t) speciﬁes an estimated plant model char-
acterized by G(θ(t)), which for control design purposes is treated as the “true”

8.3
Adaptive Control Approaches
467
Fig. 8.2 Indirect adaptive control structure
plant model and is used to calculate the controller parameter or gain vector θc by
solving a certain algebraic equation, θc(t) = F(θ(t)), that relates the plant param-
eters with the controller parameters at each time t. The form of the control law
C(θc,(t)) and algebraic equation θc(t) = F(θ(t)) is chosen to be the same as that
of the control law C(θ∗
c ) and equation θ∗
c = F(θ∗), which could be used to meet
the performance requirements for the plant model G(θ∗) if θ∗was known. It is,
therefore, clear that with this approach, C(θc(t)) is designed at each time t to sat-
isfy the performance requirements for the estimated plant model G(θ(t)) rather
than for the actual plant G(θ∗). Therefore, the main problem in indirect adaptive
control is to choose the class of control laws C(θc) and the class of parameter es-
timators that generate θ(t), as well as the algebraic equation θc = F(θ), so that
C(θc) meets the performance requirements for the plant model G(θ∗) with un-
known θ∗.
8.3.2 Direct Adaptive Control Approach
Figure 8.3 shows the structure of direct adaptive control. In this case, the plant
model G(θ∗) is parameterized in terms of the unknown controller parameter
vector θ∗
c , for which C(θ∗
c ) meets the performance requirements, to obtain the
plant model Gc(θ∗
c ) with exactly the same input/output (I/O) characteristics as
G(θ∗).
The online parameter estimator is designed based on Gc(θ∗
c ) instead of G(θ∗) to
provide the direct online estimate θc(t) of θ∗
c at each time t, by processing the plant
input u and output y. The estimate θc(t) is then used in the control law without in-
termediate calculations. The choice of the class of control laws C(θc) and parameter
estimators that generate θc(t) so that the closed-loop plant meets the performance
requirements is the fundamental problem in direct adaptive control. The properties

468
8
Adaptive Control
Fig. 8.3 Direct adaptive control structure
of the plant model G(θ∗) are crucial in obtaining the parameterized plant model
Gc(θ∗
c ) that is convenient for online estimation. As a result, direct adaptive control
is restricted to certain classes of plant models. In general, not every plant can be
expressed in a parameterized form involving only the controller parameters, which
is also a suitable form for online estimation. As we show in Chap. 5, a class of plant
models that is suitable for direct adaptive control for a particular control objective
consists of all SISO LTI plant models that are minimum phase; that is, their zeros
are located in Re[s] < 0.
In general, the ability to parameterize the plant model with respect to the desired
controller parameters is what gives us the choice to use the direct adaptive control
approach. Note that Figs. 8.2 and 8.3 can be considered as having the exact same
structure if in Fig. 8.3 we add the calculation block θc(t) = F(θc(t)) = θc(t). This
identical-in-structure interpretation is often used in the literature of adaptive control
to argue that the separation of adaptive control into direct and indirect is artiﬁcial and
is used simply for historical reasons. In general, direct adaptive control is applicable
to SISO linear plants which are minimum phase, since for this class of plants the
parameterization of the plant with respect to the controller parameters for some con-
troller structures is possible. Indirect adaptive control can be applied to a wider class
of plants with different controller structures, but it suffers from a problem known as
the stabilizability problem explained as follows: As shown in Fig. 8.2, the controller
parameters are calculated at each time t based on the estimated plant. Such calcula-
tions are possible, provided that the estimated plant is controllable and observable or
at least stabilizable and detectable. Since these properties cannot be guaranteed by
the online estimator in general, the calculation of the controller parameters may not
be possible at some points in time, or it may lead to unacceptable large controller
gains. As we explain in Chap. 6, solutions to this stabilizability problem are pos-
sible at the expense of additional complexity. Efforts to relax the minimum-phase
assumption in direct adaptive control and resolve the stabilizability problem in indi-
rect adaptive control led to adaptive control schemes where both the controller and
plant parameters are estimated online, leading to combined direct/indirect schemes
that are usually more complex [6].

8.4
Non-identiﬁer-Based Adaptive Schemes
469
8.3.3 Comparisons
The principle behind the design of direct and indirect adaptive control shown in
Figs. 8.2 and 8.3 is conceptually simple. The form of the control law is the same
as the one used in the case of known plant parameters. In the case of indirect
adaptive control the unknown controller parameters are calculated at each time t
using the estimated plant parameters generated by the online estimator, whereas
in the direct adaptive control case the controller parameters are generated directly
by the online estimator. In both cases the estimated parameters are treated as the
true parameters for control design purposes. This design approach is called cer-
tainty equivalence (CE) and can be used to generate a wide class of adaptive
control schemes by combining different online parameter estimators with differ-
ent control laws. The idea behind the CE approach is that as the parameter es-
timates θc(t) converge to the true ones θ∗
c , the performance of the adaptive con-
troller C(θc) tends to that of C(θ∗
c ) used in the case of known parameters. In some
approaches, the control law is modiﬁed to include nonlinear terms, and this ap-
proach deviates somewhat from the CE approach. The principal philosophy, how-
ever, that as the estimated parameters converge to the unknown constant parameters
the control law converges to that used in the known parameter case, remains the
same.
8.4 Non-identiﬁer-Based Adaptive Schemes
Another class of schemes that ﬁt the generic structure given in Fig. 8.1 but do not
involve online parameter estimators is referred to as non-identiﬁer-based adaptive
control schemes. In this class of schemes, the online parameter estimator is replaced
with search methods for ﬁnding the controller parameters in the space of possible
parameters, or it involves switching between different ﬁxed controllers, assuming
that at least one is stabilizing or uses multiple ﬁxed models for the plant covering
all possible parametric uncertainties or consists of a combination of these methods.
We brieﬂy describe the main features, advantages, and limitations of these non-
identiﬁer-based adaptive control schemes in the following subsections. Since some
of these approaches are relatively recent and research is still going on, we will not
discuss them further in the rest of the chapter.
8.4.1 Gain Scheduling
Let us consider the aircraft model (8.1), where for each operating point i =
1,2,...,N the parameters Ai, Bi, Ci, Di are known. For each operating point i, a
feedback controller with constant gains, say Ki, can be designed to meet the perfor-

470
8
Adaptive Control
Fig. 8.4 Gain scheduling structure
mance requirements for the corresponding linear model. This leads to a controller,
say C(Ki), with a set of gains K1,K2,...,KN covering N operating points. Once
the operating point, say i, is detected the controller gains can be changed to the
appropriate value of Ki obtained from the precomputed gain set. Transitions be-
tween different operating points that lead to signiﬁcant parameter changes may be
handled by interpolation or by increasing the number of operating points. The two
elements that are essential in implementing this approach are a lookup table to store
the values of Ki and the plant measurements that correlate well with the changes
in the operating points. The approach is called gain scheduling and is illustrated in
Fig. 8.4.
The gain scheduler consists of a lookup table and the appropriate logic for de-
tecting the operating point and choosing the corresponding value of Ki from the
lookup table. With this approach, plant parameter variations can be compensated
by changing the controller gains as functions of the input, output, and auxiliary
measurements. The advantage of gain scheduling is that the controller gains can be
changed as quickly as the auxiliary measurements respond to parameter changes.
Frequent and rapid changes of the controller gains, however, may lead to instabil-
ity [2]; therefore, there is a limit to how often and how fast the controller gains
can be changed. One of the disadvantages of gain scheduling is that the adjustment
mechanism of the controller gains is precomputed ofﬂine and, therefore, provides
no feedback to compensate for incorrect schedules. A careful design of the con-
trollers at each operating point to meet certain robustness and performance mea-
sures can accommodate some uncertainties in the values of the plant parameters
Ai, Bi, Ci, Di. Large unpredictable changes in the plant parameters, however,
due to failures or other effects may lead to deterioration of performance or even
to complete failure. Despite its limitations, gain scheduling is a popular method
for handling parameter variations in ﬂight control [9, 12] and other systems [17,
20, 23]. While gain scheduling falls into the generic deﬁnition of adaptive con-
trol, we do not classify it as adaptive control in this chapter due to the lack of
online parameter estimation which could track unpredictable changes in the plant
parameters.

8.4
Non-identiﬁer-Based Adaptive Schemes
471
Fig. 8.5 Multiple models adaptive control with switching
8.4.2 Multiple Models and Search Methods
A class of non-identiﬁer-based adaptive control schemes emerged over the years
which do not explicitly rely on online parameter estimation [1, 3–5, 7, 10, 11, 13–
16, 18]. These schemes are based on search methods in the controller parameter
space [20] until the stabilizing controller is found or the search method is restricted
to a ﬁnite set of controllers, one of which is assumed to be stabilizing [4, 7]. In some
approaches, after a satisfactory controller is found it can be tuned locally using
online parameter estimation for better performance [20, 22, 23]. Since the plant
parameters are unknown, the parameter space is parameterized with respect to a set
of plant models which is used to design a ﬁnite set of controllers so that each plant
model from the set can be stabilized by at least one controller from the controller set.
A switching approach is then developed so that the stabilizing controller is selected
online based on the I/O data measurements. Without going into speciﬁc details, the
general structure of this multiple model adaptive control with switching, as it is
often called, is shown in Fig. 8.5.
In Fig. 8.5, N controllers are used to control a plant whose parameters θ∗
p are
unknown or could change with time. In some approaches an a priori knowledge of
where the elements of θ∗
p are located, such as lower and upper bounds, is used to pa-
rameterize the plant and generate a ﬁnite set of controllers so that for each possible
plant there exists at least one stabilizing controller from the set of the N controllers.
This by itself could be a difﬁcult task in some practical situations where the plant
parameters are unknown or change in an unpredictable manner. Furthermore, since
there is an inﬁnite number of plants within any given bound of parametric uncer-
tainty, ﬁnding controllers to cover all possible parametric uncertainties may also
be challenging. In other approaches [4, 7], it is assumed that the set of controllers
with the property that at least one of them is stabilizing is available. Once the set of
controllers with the stabilizing property is available the problem of ﬁnding the stabi-
lizing one using I/O data has to be resolved. This is achieved by the use of a switch-
ing logic that differs in detail from one approach to another. While these methods
provide another set of tools for dealing with plants with unknown parameters, they

472
8
Adaptive Control
cannot replace the identiﬁer-based adaptive control schemes where no assumptions
are made about the location of the plant parameters. One advantage, however, is that
once the switching is over, the closed-loop system is LTI, and it is much easier to
analyze its robustness and performance properties. This LTI nature of the closed-
loop system, at least between switches, allows the use of the well-established and
powerful robust control tools for LTI systems [6] for controller design. These ap-
proaches are still at their infancy and it is not clear how they affect performance, as
switching may generate bad transients with adverse effects on performance. Switch-
ing may also increase the controller bandwidth and lead to instability in the presence
of high-frequency unmodeled dynamics. Guided by data that do not carry sufﬁcient
information about the plant model, the wrong controllers could be switched on over
periods of time, leading to internal excitation and bad transients before the switch-
ing process settles to the right controller. Some of these issues may also exist in
classes of identiﬁer-based adaptive control, as such phenomena are independent of
the approach used.
8.5 A Class of Parametric Models
Let us consider the ﬁrst-order system
˙x = −x + ax + bu,
where x, u are the scalar state and input, respectively, and a, b are the unknown
constants we want to identify online using the measurements of x, u.
8.5.1 Static Parametric Model
The ﬁrst step in the design of online parameter identiﬁcation (PI) algorithms is to
lump the unknown parameters in a vector and separate them from known signals,
transfer functions, and other known parameters in an equation that is convenient for
parameter estimation. For the above example, one such suitable parametric repre-
sentation is obtained by expressing the above system as
x =
1
s + 1(ax + bu) = a
1
s + 1x + b
1
s + 1u,
and in the compact algebraic form
x = θ∗tφ,
where
θ∗= [a,b]t,
φ =

1
s + 1x,
1
s + 1u
t
.
In the general case, this class of parameterizations is of the form
z = θ∗tφ,
(8.2)

8.5
A Class of Parametric Models
473
where θ∗∈ℜn is the vector with all the unknown parameters and z ∈R,φ ∈ℜn are
signals available for measurement. We refer to (8.2) as the linear “static” parametric
model (SPM). The SPM may represent a dynamic, static, linear, or nonlinear system.
Any linear or nonlinear dynamics in the original system are hidden in the signals z, φ
that usually consist of the I/O measurements of the system and their ﬁltered values.
8.5.2 Dynamic Parametric Model
Another parameterization of the above scalar plant is
x =
1
s + 1[a,b]
x
u

=
1
s + 1θ∗tφ,
θ∗= [a,b]t,
φ = [x,u]t.
In the general case, the above parametric model is of the form
z = W(q)

θ∗t
,
(8.3)
where z ∈R, φ ∈ℜn are signals available for measurement and W(q) is a known
stable proper transfer function, where q is either the shift operator in discrete time
(i.e., q = z) or the differential operator (q = s) in continuous time. We refer to (8.3)
as the linear “dynamic” parametric model (DPM). The importance of the SPM and
DPM as compared to other possible parameterizations is that the unknown parame-
ter vector θ∗appears linearly. For this reason, we refer to (8.2) and (8.3) as linear in
the parameters parameterizations.
As we will show later, this property is signiﬁcant in designing online PI algo-
rithms whose global convergence properties can be established analytically.
We can derive (8.2) from (8.3) if we use the fact that θ∗is a constant vector and
redeﬁne φ to obtain
z = θ∗tϕ,
ϕ = W(q)φ.
In a similar manner, we can ﬁlter each side of (8.2) or (8.3) using a stable proper
ﬁlter and still maintain the linear in the parameters property and the form of SPM,
DPM. This shows that there exist an inﬁnite number of different parametric models
in the form of SPM, DPM for the same parameter vector θ∗.
8.5.3 Bilinear Parametric Models
In some cases, the unknown parameters cannot be expressed in the form of the linear
in the parameters models. In such cases, the PI algorithms based on such models
cannot be shown to converge globally. A special case of nonlinear in the parameters
models for which convergence results exist is when the unknown parameters appear
in the special bilinear form
z = ρ∗
θ∗φ + z1

(8.4)

474
8
Adaptive Control
or
z = W(q)ρ∗
θ∗φ + z1

,
(8.5)
where z ∈R, φ ∈ℜn, z1 ∈R are signals available for measurement at each time t,
and ρ∗∈ℜn, θ∗∈ℜn are the unknown parameters. The transfer function W(q) is
a known stable transfer function. We refer to (8.4) and (8.5) as the bilinear static
parametric model (B-SPM) and bilinear dynamic parametric model (B-DPM), re-
spectively.
In some applications of parameter identiﬁcation or adaptive control of plants of
the form
˙x = Ax + Bu,
whose state x is available for measurement, the following parametric model may be
used:
˙x = Amx + (A −Am)x + Bu,
where Am is a stable design matrix; A, B are the unknown matrices; and x, u are
signal vectors available for measurement. The model may be also expressed in the
form
˙x = Amx + Θ∗tΦ,
where Θ∗t = [A−Am,B], Φ = [xt,ut]t. We refer to this class of parametric models
as state-space parametric models (SSPM). It is clear that the SSPM can be expressed
in the form of the DPM and SPM. Another class of state-space models that appear
in adaptive control is of the form
˙x = Amx + BΘ∗tΦ,
where B is also unknown but is positive deﬁnite, is negative deﬁnite, or the sign
of each of its elements is known. We refer to this class of parametric models as
bilinear state-space parametric models (B-SSPM). The B-SSPM model can be easily
expressed as a set of scalar B-SPM or B-DPM.
The PI problem can now be stated as follows:
• For the SPM and DPM: Given the measurements z(t), φ(t), generate θ(t), the
estimate of the unknown vector θ∗, at each time t. The PI algorithm updates θ(t)
with time so that as time evolves, θ(t) approaches or converges to θ∗. Since we
are dealing with online PI, we would also expect that if θ∗changes, then the PI
algorithm will react to such changes and update the estimate θ(t) to match the
new value of θ∗.
• For the B-SPM and B-DPM: Given the measurements of z, z1, and φ, generate
the estimates θ(t), ρ(t) of θ∗, ρ∗, respectively, at each time t the same way as in
the case of SPM and DPM.
• For the SSPM: Given the measurements of x, u, that is, Φ, generate the estimate
Θ of θ∗(and hence the estimates ˆA(t), ˆB(t) of A, B, respectively) at each time t
the same way as in the case of SPM and DPM.

8.5
A Class of Parametric Models
475
The online PI algorithms generate estimates at each time t, by using the past and
current measurements of signals. Convergence is achieved asymptotically as time
evolves. For this reason they are referred to as recursive PI algorithms to be distin-
guished from the nonrecursive ones, in which all the measurements are collected a
priori over large intervals of time and are processed ofﬂine to generate the estimates
of the unknown parameters.
Generating the parametric models (8.2)–(8.5) is a signiﬁcant step in the design
of the appropriate PI algorithms. Below, we present several examples that demon-
strate how to express the unknown parameters in the form of the parametric models
presented above.
8.5.4 Example 8.4
Consider the mass-spring-dashpot system shown in Fig. 8.6, where k is the spring
constant, f is the viscous-friction or damping coefﬁcient, M is the mass of the
system, u is the forcing input, and x is the displacement of the mass M.
If we assume that the spring is “linear,” that is, the force acting on the spring
is proportional to the displacement, and the friction force is proportional to the ve-
locity ˙x, using Newton’s law we obtain the differential equation that describes the
dynamics of the system as
M ¨x = u −kx −f ˙x.
(8.6)
Let us assume that M, f , k are the constant unknown parameters that we want to
estimate online. We can easily express (8.6) in the form of SPM by deﬁning
θ∗= [M,f,k]t,
z = u,
φ = [¨x, ˙x,x]t.
However, in this formulation we are making the assumption that the vector φ =
[¨x, ˙x,x]t is available for measurement, which is true, provided that x and its ﬁrst two
derivatives are available for measurement. If not, the parametric model associated
with φ = [¨x, ˙x,x]t cannot be used for developing PI algorithms because φ is not
available for measurement. Let us assume that only x, the displacement of the mass,
is available for measurement. In this case, in order to express (8.6) in the form
of the SPM, we ﬁlter both sides of (8.6) with the stable ﬁlter
1
Λ(s) where Λ(s) =
(s + λ)2 and λ > 0 is a constant design parameter we can choose arbitrarily, to
obtain
Ms2 + f s + k
Λ(s)
=
1
Λ(s)u.
(8.7)
Using (8.7), we can express the unknown parameters in the form of (8.2) as fol-
lows:
z = θ∗tφ,

476
8
Adaptive Control
Fig. 8.6
Mass-spring-dashpot system
where
z =
1
Λ(s)u,
φ =
 s2
Λ(s)x,
s
Λ(s)x,
1
Λ(s)x
t
,
θ∗= [M,f,k]t.
In this case z, φ are available for measurement since they can be generated by ﬁl-
tering the measurements u and x, respectively. Another possible parametric model
is
z = θ∗tφ,
where
z =
s2
Λ(s)x,
φ =

1
Λ(s)u,
s
Λ(s)x,−
1
Λ(s)x
t
,
θ∗=

1
M , f
M , k
M
t
.
In this model, the unknown parameters are rearranged to a different vector θ∗.
8.5.5 Example 8.5
Consider the cart with two inverted pendulums shown in Fig. 8.7, where M is the
mass of the cart, m1 and m2 are the masses of the bobs, and l1 and l2 are the lengths
of the pendulums, respectively. Using Newton’s law and assuming small angular
deviations of |α1|, |α2|, the equations of motion are given by

8.5
A Class of Parametric Models
477
Fig. 8.7 Cart with two
inverted pendulums
M ˙v = −m1gα1 −m2gα2 + u,
m1(˙v + l1 ¨α1) = m1gα1,
m2(˙v + l2 ¨α2) = m2gα2,
where v is the velocity of the cart, u is an external force, and g is the acceleration
due to gravity. Letting α1 be the output, i.e., y = α1, the system can be described by
the differential equation
y(4) + a2y(2) + a0y = b2u(2) + b0u,
where
a2 = −g
M
	M + m1
l1
+ M + m2
l2

,
a0 = (M + m1 + m2)g2
Ml1l2
,
b2 =
1
Ml1
,
b0 =
g
Ml1l2
.
The above equation can be rewritten as
y(4) = θ∗tY0,
where
Y0 =

u(2),u,−y(2),−t
t,
θ∗= [b2,b0,a2,a0]t.
In order to avoid the use of differentiators, we ﬁlter each side with fourth-order
stable ﬁlter
1
Λ(s), e.g., Λ(a) = (s + λ)4, λ > 0, to obtain the SPM model
z = θ∗tφ,
where
z =
s4
(s + λ)4 y,
φ =

s2
(s + λ)4 u,
1
(s + λ)4 u,−
s2
(s + λ)4 y,−
1
(s + λ)4 y
t
,
θ∗= [b2,b0,a2,a0]t.

478
8
Adaptive Control
If in the above model we know that a0 is nonzero, redeﬁning the constant parameters
as ¯b2 = b2
a0 , ¯b0 = b0
a0 , ¯a1 = a1
a0 , we obtain the following B-SPM:
z = ρ∗
θ∗tφ + z1

,
where
z =
s4
(s + λ)4 y,
z1 =
1
(s + λ)4 y,
φ =

s2
(s + λ)4 u,
1
(s + λ)4 u,−
s2
(s + λ)4 y
t
,
θ∗= [¯b2, ¯b0, ¯a2]t,
ρ∗= a0.
8.5.6 Example 8.6
Consider the second-order plant
˙x = Ax + Bu,
where x = [x1,x2]t, u = [u1,u2]t, and
A =
a11
a12
a21
a22

,
B =
b11
b12
b21
b22

are matrices with unknown elements. The SSPM is generated as
˙x =
−am
0
0
−am

x +
a11 + am
a12
a21
a22 + am

x +
b11
b12
b21
b22

u,
where am > 0 is a design constant. The model may be also expressed as
˙x =
−am
0
0
−am

x + Θ∗tΦ,
where
Θ∗t =
a11 + am, a12, b11, b12
a21, a22 + am, b21, b22

,
Φ = [x1,x2,u1,u2]t.
8.6 Parameter Identiﬁcation
The purpose of this section is to present the design, analysis, and simulation of
a wide class of algorithms that can be used for online parameter identiﬁcation of
continuous-time plants. The online identiﬁcation procedure involves the following
three steps.
1. Lump the unknown parameters in a vector θ∗and express them in the form of
the parametric model SPM, DPM, B-SPM, or B-DPM.

8.6
Parameter Identiﬁcation
479
2. Use the estimate θ of θ∗to set up the estimation model that has the same form
as the parametric model. The difference between the outputs of the estimation
and parametric models, referred to as the estimation error, reﬂects the distance
of the estimated parameters θ(t) from the unknown parameters θ∗weighted by
some signal vector. The estimation error is used to drive the adaptive law that
generates θ(t) online. The adaptive law is a differential equation of the form
˙θ = H(t)ε,
where ε is the estimation error that reﬂects the difference between θ(t) and θ∗
and H(t) is a time-varying gain vector that depends on measured signals. A wide
class of adaptive laws with different H(t) and ε may be developed using opti-
mization techniques and Lyapunov-type stability arguments.
3. Establish conditions that guarantee that θ(t) converges to θ∗with time. This step
involves the design of the plant input so that the signal vector φ(t) in the para-
metric model is persistently exciting (a notion to be deﬁned later on), i.e., it has
certain properties that guarantee that the measured signals that drive the adaptive
law carry sufﬁcient information about the unknown parameters. For example, for
φ(t) = 0, we have z = θ∗tφ = 0, and the measured signals φ, z carry no infor-
mation about θ∗. Similar arguments could be made for φ that is orthogonal to θ∗
leading to z = 0 even though θ ̸= θ∗, etc.
We demonstrate the three design steps using the following example of a scalar
plant.
8.6.1 One-Parameter Case
Consider the ﬁrst-order plant model
y =
a
s + 2u,
(8.8)
where a is the only unknown parameter and y and u are the measured output and
input of the system, respectively.
1. Parametric Model: We write (8.8) as
y = a
1
s + 2u = auf ,
(8.9)
where uf =
1
s+2u. Since u is available for measurement, uf is also available for
measurement. Therefore, (8.9) is in the form of the SPM
z = θ∗φ,
(8.10)
where θ∗= a and z = y, φ = uf are available for measurement.
2. Parameter Identiﬁcation Algorithm: This step involves the development of an
estimation model and an estimation error used to drive the adaptive law that
generates the parameter estimates.

480
8
Adaptive Control
Estimation Model and Estimation Error: The estimation model has the same
form as the SPM with the exception that the unknown parameter θ∗is replaced
with its estimate at time t, denoted by θ(t), i.e.,
ˆz = θ(t)φ,
(8.11)
where ˆz is the estimate of z based on the parameter estimate θ(t) at time t. It is
obvious that the difference between z and ˆz is due to the difference between θ(t)
and θ∗. As θ(t) approaches θ∗with time we would expect that ˆz would approach
z at the same time. Note that the reverse is not true, i.e., ˆz(t) = z(t) does not
imply that θ(t) = θ∗. Since θ∗is unknown, the difference ˜θ = θ(t) −θ∗is not
available for measurement. Therefore, the only signal that we can generate, using
available measurements, that reﬂects the difference between θ(t) and θ∗is the
error signal
ε = z −ˆz
m2s
,
(8.12)
which we refer to as the estimation error. m2
s ≥1 is a normalization signal1 de-
signed to guarantee that
φ
ms is bounded. This property of ms is used to establish
the boundedness of ms the estimated parameters even when φ is not guaranteed
to be bounded. A straightforward choice for ms in this example is m2
s = 1+αφ2,
α > 0. If φ is bounded, we can take α = 0, that is, m2
s = 1. Using (8.11) in
(8.12), we can express the estimation error as a function of the parameter error
˜θ = θ(t) −θ∗, i.e.,
ε =
˜θφ
m2s
.
(8.13)
Equation (8.13) shows the relationship between the estimation error ε and the
parameter error ˜θ. It should be noted that ε cannot be generated using (8.13)
because the parameter error ˜θ is not available for measurement. Consequently,
(8.13) can be used only for analysis.
Adaptive Law: A wide class of adaptive laws or parameter estimators for gen-
erating θ(t), the estimate of θ∗, can be developed using (8.11)–(8.13). The sim-
plest one is obtained by using the SPM (8.10) and the fact that φ is scalar to
write
θ(t) = z(t)
φ(t),
(8.14)
provided φ(t) ̸= 0. In practice, however, the effect of noise on the measurements
of φ(t), especially when φ(t) is close to zero, may lead to erroneous parameter
estimates. Another approach is to update θ(t) in a direction that minimizes a
certain cost of the estimation error ε. With this approach, θ(t) is adjusted in a
1Note that any m2
s ≥nonzero constant is adequate. The use of a lower bound 1 is without loss of
generality.

8.6
Parameter Identiﬁcation
481
direction that makes |ε| smaller and smaller until a minimum is reached at which
|ε| = 0 and updating is terminated.
Now, consider the cost criterion
J(θ) = ε2m2
s
2
= (z −θφ)2
2m2s
,
(8.15)
which we minimize with respect to θ using the gradient method to obtain
˙θ = −γ dJ(θ)
dθ
,
(8.16)
where γ > 0 is a scaling constant or step size which we refer to as the adaptive
gain and where dJ(θ)
dθ
is the gradient of J with respect to θ. In this scalar case,
dJ(θ)
dθ
= dJ
dθ = −(z −θφ)
m2s
φ = −εφ,
which leads to the adaptive law
˙θ = γ εφ,
θ(0) = θ0.
(8.17)
3. Stability and Parameter Convergence: The adaptive law should guarantee that
the parameter estimate θ(t) and the speed of adaptation ¯θ are bounded and that
the estimation error ε gets smaller and smaller with time. These conditions still
do not imply that θ(t) will get closer and closer to θ∗with time unless some
conditions are imposed on the vector φ(t), referred to as the regressor vector.
Let us start by using (8.13) and the fact that ˙˜θ = ˙θ −˙θ∗= ˙θ (due to θ∗being
constant) to express (8.17) as
˙˜θ = −γ φ2
m2s
˜θ,
˜θ(0) = ˜θ0.
(8.18)
This is a scalar linear time-varying differential equation whose solution is
˜θ(t) = e
−γ
 t
0
φ2(τ)
m2s (τ) dτ ˜θ0,
(8.19)
which implies that for
 t
0
φ2(τ)
m2s(τ)dτ ≥α0t
(8.20)
and some α0 > 0, ˜θ(t) converges to zero exponentially fast, which in turn im-
plies that θ(t) →θ∗exponentially fast. It follows from (8.19) that θ(t) is always
bounded for any φ(t) and from (8.18) that ˙θ(t) = ˙˜θ(t) is bounded due to
φ(t)
ms(t)
being bounded.
Another way to analyze (8.18) is to use a Lyapunov-like approach as follows:
We consider the function
V =
˜θ2
2γ .

482
8
Adaptive Control
Then
˙V =
˜θ
γ
d ˜θ
dt = −φ2
m2s
˜θ2 ≤0
or, using (8.13),
˙V = −φ2
m2s
˜θ2 = −ε2m2
s ≤0.
(8.21)
We should note that ˙V = −ε2m2
s ≤0 implies that ˙V is a negative semideﬁnite
function in the space of ˜θ. ˙V in this case is not negative deﬁnite in the space of ˜θ
because it can be equal to zero when ˜θ is not zero. Consequently, if we apply the
stability results of the Appendix, we can conclude that the equilibrium ¯θe = 0
of (8.18) is uniformly stable (u.s.) and that the solution of (8.18) is uniformly
bounded (u.b.). These results are not as useful, as our objective is asymptotic
stability, which implies that the parameter error converges to zero. We can use
the properties of V, ˙V , however, to obtain additional properties for the solution
of (8.18) as follows.
Since V > 0 and ˙V ≤0, it follows that (see the Appendix) V is bounded,
which implies that
˜θ is bounded and V
converges to a constant, i.e.,
limt→∞V (t) = V∞. Let us now integrate both sides of (8.21). We have
 t
0
˙V (τ)dτ = −
 t
0
ε2(τ)m2
s(τ)dτ
or
V (t) −V (0) = −
 t
0
ε2(τ)m2
s(τ)dτ.
(8.22)
Since V (t) converges to the limit V∞as t →∞, it follows from (8.22) that
 ∞
0
ε2(τ)m2
s(τ)dτ = V (0) −V∞< ∞,
i.e., εms is square integrable or εms ∈L2. Since m2
s ≥1, we have ε2 ≤ε2m2
s,
which implies ε ∈L2. From (8.13), we conclude that
¯θφ
ms ∈L2 due to εms ∈L2.
Using (8.17), we write
˙θ = γ εms
φ
ms
.
Since φ
ms is bounded and εms ∈L2∩L∞, it follows (see Problem 2) that ˙θ ∈L2∩
L∞. In summary, we have established that the adaptive law (8.17) guarantees
that (i) θ ∈L∞and (ii) ε,εms, ˙θ ∈L2 ∩L∞independent of the boundedness of
φ. The L2 property of ε, εms, and ˙θ indicates that the estimation error and the
speed of adaptation ˙θ are bounded in the L2 sense, which in turn implies that
their average value tends to zero with time.
It is desirable to also establish that ε, εms, and ˙θ go to zero as t →∞, as
such a property will indicate the end of adaptation and the completion of learn-
ing. Such a property can be easily established when the input u is bounded (see
Problem 3).

8.6
Parameter Identiﬁcation
483
The above properties still do not guarantee that θ(t) →θ∗as t →∞. In order
to establish that θ(t) →θ∗as t →∞exponentially fast, we need to restrict
φ
ms
to be persistently exciting (PE), i.e., to satisfy
1
T
 t+T
t
φ2(τ)
m2s
dτ ≥α0 > 0
(8.23)
∀t ≥0 and some constants T , α0 > 0. The PE property of
φ
ms is guaranteed by
choosing the input u appropriately. Appropriate choices of u for this particular
example include (i) u = c > 0, (ii) u = sinωt for any ω ̸= 0 and any bounded
input u that is not vanishing with time. The condition (8.23) is necessary and
sufﬁcient for exponential convergence of θ(t) →θ∗.
4. The PI algorithm for estimating the constant a in the plant (8.8) can now be
summarized as
˙θ = γ εφ,
θ(0) = θ0,
ε = (z −ˆz)
m2s
,
ˆz = θφ,
z = y,
φ =
1
s + 2u,
m2
s = 1 + φ2,
where θ(t) is the estimate of the constant a in (8.8).
The above analysis for the scalar example carries over to the vector case with-
out any signiﬁcant modiﬁcations, as demonstrated in the next section. One im-
portant difference, however, is that in the case of a single parameter, convergence
of the Lyapunov-like function V to a constant implies that the estimated param-
eter converges to a constant. Such a result cannot be established in the case of
more than one parameter for the gradient algorithm.
8.6.2 Two-Parameters Case
Consider the plant model
y =
b
s + a u,
(8.24)
where a, b are unknown constants. Let us assume that y, ˙y, u are available for
measurement. We would like to generate online estimates for the parameters a, b.
1. Parametric Model: Since y, ˙y are available for measurement, we can express
(8.24) in the SPM form
z = θ∗tφ,
where z = ˙y, θ∗= [b,a]t, φ = [u,−y]t, and z, φ are available for measurement.

484
8
Adaptive Control
2. Parameter Identiﬁcation Algorithm: It consists of:
Estimation Model:
ˆz = θtφ,
where θ(t) is the estimate of θ∗at time t.
Estimation Error:
ε = z −ˆz
m2s
= z −θtφ
m2s
,
(8.25)
where ms is the normalizing signal such that φ
ms ∈L∞. A straightforward choice
for ms is m2
s = 1 + αφtφ for any α > 0.
Adaptive Law: We use the gradient method to minimize the cost,
J(θ) = ε2m2
s
2
= (z −θtφ)2
2m2s
= (z −θ1φ1 −θ2φ2)2
2m2s
,
where φ1 = u, φ2 = −y, and set
˙θ = −Γ dJ(θ)
dθ
,
where
dJ(θ)
dθ
=
 ∂J
∂θ1
, ∂J
∂θ2
t
,
Γ = Γ t > 0 is the adaptive gain, and θ1, θ2 are the elements of θ = [θ1,θ2]t.
Since
∂J
∂θ1
= −(z −θtφ)
m2s
φ1 = −εφ1,
∂J
∂θ2
= −(z −θtφ)
m2s
φ2 = −εφ2,
we have
˙θ = Γ εφ,
θ(0) = θ0,
(8.26)
which is the adaptive law for updating θ(t) starting from some initial condition
θ(0) = θ0.
3. Stability and Parameter Convergence: As in the previous example, the equation
for the parameter error ˜θ = θ −θ∗is obtained from (8.25), (8.26) by noting that
ε = z −θtφ
m2s
= θ∗tφ −θtφ
m2s
= −
˜θtφ
m2s
= −φt ˜θ
m2s
(8.27)
and ˙˜θ = ˙θ, i.e.,
˙˜θ = Γ φε = −Γ φφt
m2s
˜θ.
(8.28)
It is clear from (8.28) that the stability of the equilibrium ˜θe = 0 will very much
depend on the properties of the time-varying matrix −Γ φφt
m2s , which in turn de-
pends on the properties of φ. For simplicity, let us assume that the plant is stable,

8.7
Gradient Algorithms
485
i.e., a > 0. If we choose m2
s = 1, Γ = γ I for some γ > 0 and a constant input
u = co > 0, then at steady state y = c1 := c0b
a ̸= 0 and φ = [co,−c1]t, giving
−Γ φφt
m2s
= −γ

c2
0
−c0c1
−c0c1
c2
1

:= A,
i.e.,
˙˜θ = A ˜θ,
where A is a constant matrix with eigenvalues 0, −γ (c2
0 + c2
1), which implies
that the equilibrium θe = 0 is only marginally stable; i.e., ˜θ is bounded but does
not necessarily converge to 0 as t →∞. The question that arises in this case
is what properties of φ guarantee that the equilibrium ˜θe = 0 is exponentially
stable. Given that
φ = H(s)u,
where for this example H(s) = [1,−b
s+a ]t, the next question that comes up is
how to choose u to guarantee that φ has the appropriate properties that imply
exponential stability for the equilibrium ˜θe = 0 of (8.28). Exponential stability
for the equilibrium point ˜θe = 0 of (8.28) in turn implies that θ(t) converges to
θ∗exponentially fast. As demonstrated above for the two-parameter example, a
constant input u = co > 0 does not guarantee exponential stability. We answer
the above questions in the following section.
8.7 Gradient Algorithms
The gradient algorithm is developed by using the gradient method to minimize some
appropriate functional J(θ). Different choices for J(θ) lead to different algorithms.
As in the scalar case, we start by deﬁning the estimation model and estimation error
for the SPM.
The estimate ˆz of z is generated by the estimation model
ˆz = θtφ,
(8.29)
where θ(t) is the estimate of θ∗at time t. The estimation error is constructed as
ε = z −ˆz
m2s
= z −θtφ
m2s
,
(8.30)
where m2
s ≥1 is the normalizing signal designed to bound φ from above. The nor-
malizing signal often has the form m2
s = 1 + n2
s, where ns ≥0 is referred to as
the static normalizing signal designed to guarantee that
φ
ms is bounded from above.
Some straightforward choices m, for ns include
n2
s = αφtφ,
α > 0,

486
8
Adaptive Control
or
n2
s = φtPφ,
P = P t > 0,
where α is a scalar and P is a matrix selected by the designer.
The estimation error (8.30) and the estimation model (8.29) are common to sev-
eral algorithms that are generated in the following sections.
8.7.1 Gradient Algorithm with Instantaneous Cost Function
The cost function J(θ) is chosen as
J(θ) = ε2m2
s
2
= (z −θtφ)2
2m2s
,
(8.31)
where ms is the normalizing signal given by (8.30). At each time t, J(θ) is a convex
function of θ and therefore has a global minimum. The gradient algorithm takes the
form
˙θ = −Γ dJ
dθ ,
(8.32)
where Γ = Γ t > 0 is a design matrix referred to as the adaptive gain. Since dJ
dθ =
−(z−θtφ)φ
m2s
= −εφ, we have
˙θ = Γ εφ.
(8.33)
The adaptive law (8.33) together with the estimation model (8.29), the estimation
error (8.30), and ﬁltered signals z, φ constitute the gradient parameter identiﬁcation
algorithm based on the instantaneous cost function.
Theorem 8.1 The gradient algorithm (8.33) guarantees the following:
1. ε,εms, ˙θ ∈L2 ∩L∞and θ ∈L∞.
2. If
φ
ms is PE, i.e.,
 t+T0
t
φφt
m2s dτ > α0T0I ∀t ≥0 and for some T0,α0 > 0, then
θ(t) →θ∗exponentially fast. In addition,

θ(t) −θ∗tΓ −1
θ(t) −θ∗
≤(1 −γ1)n
θ(0) −θ∗tΓ −1
θ(0) −θ∗
,
where 0 ≤t ≤nT0, n = 0,1,2,..., and
γ1 =
2α0T0λmin(Γ )
2 + β4λ2max(Γ )T 2
0
,
β = sup
t

φ
ms
.
3. If the plant model has stable poles and no zero-pole cancellations and the input
u is sufﬁciently rich of order n + m + 1, i.e., it consists of at least n+m+1
2
distinct
frequencies, then φ, φ
ms are PE. Furthermore, |θ(t) −θ∗|, ε, εms, ˙θ converge to
zero exponentially fast.

8.7
Gradient Algorithms
487
8.7.2 Example 8.7
Consider the dynamics of a hard-disk drive servo system [8] given by
y = kp
s2 (u + d),
where y is the position error of the head relative to the center of the track, kp is a
known constant, and
d = A1 sin(ω1t + ϕ1) + A2 sin(ω2t + ϕ2)
is a disturbance that is due to higher-order harmonics that arise during rotation of the
disk drive. In this case, ω1, ω2 are the known harmonics that have a dominant effect
and Ai, ϕi, i = 1,2, are the unknown amplitudes and phases. We want to estimate
d in an effort to nullify its effect using the control input u.
Using sin(a + b) = sina cosb + cosa sinb, we can express d as
d = θ∗
1 sinω1t + θ∗
2 cosω1t + θ∗
3 sinω2t + θ∗
4 cosω2t,
where
θ∗
1 = A1 cosϕ1,
θ∗
2 = A1 sinϕ1,
θ∗
3 = A2 cosϕ2,
θ∗
4 = A2 sinϕ2
(8.34)
are the unknown parameters. We ﬁrst obtain a parametric model for
θ∗=

θ∗
1 ,θ∗
2 ,θ∗
3 ,θ∗
4
t.
We have
s2y = kpu + kpθ∗tψ,
where
ψ(t) = [sinω1t,cosω1t,sinω2t,cosω2t]t.
Filtering each side with
1
Λ(s) where Λ(s) = (s + λ1)(s + λ2) and λ1,λ2 > 0 are
design constants, we obtain the SPM
z = θ∗tφ,
where
z =
s2
Λ(s)y −kp
1
Λ(s)u,
φ = kp
1
Λ(s)ψ(t) = kp
1
Λ(s)[sinω1t,cosω1t,sinω2t,cosω2t]t.
Therefore, the adaptive law
˙θ = Γ εφ,
ε = z −θtφ
m2s
,
m2
s = 1 + n2
s,
n2
s = αφtφ,

488
8
Adaptive Control
where Γ = Γ t > 0 is a 4 × 4 constant matrix, may be used to generate θ(t), the
online estimate of θ∗. In this case, φ ∈L∞and therefore we can take α = 0, i.e.,
m2
s = 1. For ω1 ̸= ω2, we can establish that φ is PE and therefore θ(t) →θ∗ex-
ponentially fast. The online estimate of the amplitude and phase can be computed
using (8.34) as follows:
tan ˆϕ1(t) = θ2(t)
θ1(t),
tan ˆϕ2(t) = θ4(t)
θ3(t),
ˆA1(t) =

θ2
1(t) + θ2
2(t),
ˆA2(t) =

θ2
3(t) + θ2
4(t),
provided of course that θ1(t) ̸= 0, θ3(t) ̸= 0. The estimated disturbance
ˆd(t) = ˆA1(t)sin

ω1(t) + ˆϕ1(t)

+ ˆA2(t)sin

ω2(t) + ˆϕ2(t)

can then be generated and used by the controller to cancel the effect of the actual
disturbance d.
8.7.3 Gradient Algorithm with Integral Cost Function
The cost function J(θ) is chosen as
J(θ) = 1
2
 t
0
e−β(t−τ)ε2(t,τ)m2
s(τ)dτ,
where β > 0 is a design constant acting as a forgetting factor and
ε(t,τ) = z(τ) −θt(t)φ(τ)
m2s(τ)
,
ε(t,t) = ε,
τ ≤t,
is the estimation error that depends on the estimate of θ at time t and on the values
of the signals at τ ≤t. The cost penalizes all past errors between z(τ) and ˆz(τ) =
θt(t)φ(τ), τ ≤t, obtained by using the current estimate of θ at time t with past
measurements of z(τ) and φ(τ). The forgetting factor e−β(t−τ) is used to put more
weight on recent data by discounting the earlier ones. It is clear that J(θ) is a convex
function of θ at each time t and therefore has a global minimum. Since θ(t) does
not depend on τ, the gradient of J with respect to θ is easy to calculate despite the
presence of the integral. Applying the gradient method, we have
˙θ = −Γ dJ
dθ ,
where
dJ
dθ = −
 t
0
e−β(t−τ) z(τ) −θt(t)φ(τ)
m2s(τ)
φ(τ)dτ.
This can be implemented as

8.8
Least-Squares Algorithms
489
˙θ = −Γ

R(t)θ + Q(t)

,
θ(0) = θ0,
˙R = −βR + φφt
m2s
,
R(0) = 0,
˙Q = −βQ −zφ
m2s
,
Q(0) = 0,
where R ∈ℜn×n, Q ∈ℜn×1; Γ = Γ t > 0 is the adaptive gain; n is the dimension
of the vector θ∗; and ms is the normalizing signal deﬁned in (8.30).
Theorem 8.2 The gradient algorithm with integral cost function guarantees that
1. ε,εms, ˙θ ∈L2 ∩L∞and θ ∈L∞.
2. limt→∞| ˙θ(t)| = 0.
3. If φ
ms is PE, then θ(t) →θ∗exponentially fast. Furthermore,for Γ = γ I, the rate
of convergence increases with γ .
4. If u is sufﬁciently rich of order n + m + 1, i.e., it consists of at least n+m+1
2
distinct frequencies, and the plant is stable and has no zero-pole cancellations,
then φ, φ
ms are PE and θ(t) →θ∗exponentially fast.
Theorem 8.2 indicates that the rate of parameter convergence increases with in-
creasing adaptive gain. Simulations demonstrate that the gradient algorithm based
on the integral cost gives better convergence properties than the gradient algorithm
based on the instantaneous cost. The gradient algorithm based on the integral cost
has similarities with the least-squares (LS) algorithms to be developed in the next
section.
8.8 Least-Squares Algorithms
The LS method dates back to the eighteenth century, when Gauss used it to de-
termine the orbits of planets. The basic idea behind LS is ﬁtting a mathematical
model to a sequence of observed data by minimizing the sum of the squares of the
difference between the observed and computed data. In doing so, any noise or inac-
curacies in the observed data are expected to have less effect on the accuracy of the
mathematical model. The method is simple to apply and analyze in the case where
the unknown parameters appear in a linear form, such as in the linear SPM
z = θ∗tφ.
(8.35)
We illustrate the use and properties of LS by considering the simple scalar example
z = θ∗φ + dn,
where z,θ∗,φ ∈R,φ ∈L∞, and dn is a noise disturbance whose average value goes
to zero as t →∞, i.e.,
lim
t→∞
1
t
 t
0
dn(τ)dτ = 0.

490
8
Adaptive Control
In practice, dn may be due to sensor noise or external sources, etc. We examine the
following estimation problem: Given the measurements of z(τ), φ(τ) for 0 ≤τ < t,
ﬁnd a “good” estimate θ(t) of θ∗at time t. One possible solution is to calculate θ(t)
as
θ(t) = z(τ)
φ(τ) = θ∗+ dn(τ)
φ(τ)
(8.36)
by using the measurements of z(τ), φ(τ) at some τ < t for which φ(r) ̸= 0. Because
of the noise disturbance, however, such an estimate may be far off from θ∗. For
example, at the particular time τ at which we measured z and φ, the effect of dn(τ)
may be signiﬁcant, leading to an erroneous estimate for θ(t) generated by (8.36).
A more appropriate approach is to choose the estimate θ(t) at time t to be the
one that minimizes the square of all the errors that result from the mismatch of
z(τ) −θ(t)φ(τ) for 0 ≤τ ≤t. Hence, the estimation problem above becomes the
following LS problem: Minimize the cost
J(θ) = 1
2
 t
0
z(τ) −θ(t)φ(τ)
2 dτ
(8.37)
w.r.t. θ(t) at any given time t. The cost J(θ) penalizes all the past errors from τ = 0
to t that are due to θ(t) ̸= θ∗. Since J(θ) is a convex function over R at each time
t, its minimum satisﬁes
dJ
dθ (θ) = −
 t
0
z(τ)φ(τ)dτ + θ(t)
 t
0
φ2(τ)dτ = 0,
which gives the LS estimate
θ(t) =
	 t
0
φ2(τ)dτ

−1  t
0
z(τ)φ(τ)dτ,
provided of course that the inverse exists. The LS method considers all past data in
an effort to provide a good estimate for θ∗in the presence of noise dn. For example,
when φ(t) = 1, ∀t ≥0, we have
lim
t→∞θ(t) = lim
t→∞
1
t
 t
0
z(τ)dτ = θ∗+ lim
t→∞
1
t
 t
0
dn(τ)dτ = θ∗;
i.e., θ(t) converges to the exact parameter value despite the presence of the noise
disturbance dn.
Let us now extend this problem to the linear model (8.35). As in Sect. 8.7, the
estimate ˆz of z and the normalized estimation are generated as
ˆz = θtφ,
e = z −ˆz
m2s
= z −θtφ
m2s
,
where θ(t) is the estimate of θ∗at time t, and m2
s = 1 + n2
s is designed to guar-
antee
φ
ms ∈L∞. Below we present different versions of the LS algorithm, which
correspond to different choices of the LS cost J(θ).

8.8
Least-Squares Algorithms
491
8.8.1 Recursive LS Algorithm with Forgetting Factor
Consider the function
J(θ) = 1
2
 t
0
e−β(t−τ) [z(τ) −θt(t)φ(τ)]2
m2s(τ)
dτ + 1
2e−βt(θ −θ0)tQ0(θ −θ0),
(8.38)
where Q0 = Qt
0 > 0, β ≥0 are design constants and θ0 = θ(0) is the initial pa-
rameter estimate. This cost function is a generalization of (8.37) to include possible
discounting of past data and a penalty on the initial error between the estimate θ0
and θ∗. Since
z
ms , φ
ms ∈L∞, J(θ) is a convex function of θ over ℜn at each time t.
Hence, any local minimum is also global and satisﬁes
dJ
dθ (θ(t)) = 0
∀t ≥0.
The LS algorithm for generating θ(t), the estimate of θ∗, in (8.35) is therefore ob-
tained by solving
dJ
dθ (θ) = e−βtQ0

θ(t) −θ0

−
 t
0
e−β(t−τ) z(τ) −θt(t)φ(τ)
m2s(τ)
φ(τ)dτ = 0
(8.39)
for θ(t), which yields the nonrecursive LS algorithm
θ(t) = P(t)

e−βtQ0θ0 +
 t
0
e−β(t−τ) z(τ)φ(τ)
m2s(τ)
dτ

,
(8.40)
where
P(t) =

e−βtQ0 +
 t
0
e−β(t−τ) z(τ)φt(τ)
m2s(τ)
dτ
−1
,
(8.41)
is the so-called covariance matrix. Because Q0 = Qt
0 > 0 and φφt is positive
semideﬁnite, P(t) exists at each time t. Using the identity
d
dt PP −1 = ˙PP −1 + P d
dt P −1 = 0
and εm2
s = z −θtφ, and differentiating θ(t) w.r.t. t, we obtain the recursive LS
algorithm with forgetting factor
˙θ = Pεφ,
θ(0) = θ0,
˙P = βP −P φφt
m2s
P,
P(0) = P0 = Q−1
0 .
(8.42)
The stability properties of (8.42) depend on the value of the forgetting factor β, as
discussed in the following sections. If β = 0, the algorithm becomes the pure LS
algorithm discussed and analyzed in Sect. 8.8.2. When β > 0, stability cannot be
established unless
φ
ms is PE. In this case (8.42) is modiﬁed, leading to a different
algorithm.
The following theorem establishes the stability and convergence of θ to θ∗of the
algorithm (8.42) in the case where φ
ms is persistently excited (PE), see the Appendix.

492
8
Adaptive Control
Theorem 8.3 If
φ
ms is PE, then the recursive LS algorithm with forgetting factor
(8.42) guarantees that P,P −1 ∈L∞and that θ(t) →θ∗as t →∞. The conver-
gence of θ(t) →θ∗is exponential when β > 0.
Since the adaptive law (8.42) could be used in adaptive control where the PE
property of
φ
ms cannot be guaranteed, it is of interest to examine the properties of
(8.42) in the absence of PE. In this case, (8.42) is modiﬁed in order to avoid certain
undesirable phenomena, as discussed in the following sections.
8.8.2 Pure LS Algorithm
When β = 0 in (8.38), the algorithm (8.42) reduces to
˙θ = Pεφ,
θ(0) = θ0,
˙P = −P φφt
m2s
P,
P(0) = P0,
(8.43)
which is referred to as the pure LS algorithm.
Theorem 8.4 The pure LS algorithm (8.43) guarantees that
1. ε,εms, ˙θ ∈L2 ∩L∞and θ,P ∈L∞.
2. limt→∞θ(t) = ¯θ, where ¯θ is a constant vector.
3. If φ
ms is PE, then θ(t) →θ∗as t →∞.
4. If (8.35) is the SPM for the plant
y(n) + an−1y(n−1) + ··· + a1 ˙y + a0y
= bmu(m) + ··· + b1 ˙u + b0u
(8.44)
with stable poles and no zero-pole cancellations, and u is sufﬁciently rich of
order n + m + 1, i.e., consists of at least n+m+1
2
distinct frequencies, then φ, φ
ms
are PE and therefore θ(t) →θ∗as t →∞.
8.8.3 Example 8.8
In order to get some understanding of the properties of the pure LS algorithm, let us
consider the scalar SPM
z = θ∗φ,
where z, θ∗, φ ∈R. Let us assume that φ ∈L∞. Then the pure LS algorithm is given
by

8.8
Least-Squares Algorithms
493
˙θ = pεφ,
θ(0) = θ0,
˙P = −p2φ2,
p(0) = p0 > 0,
ε = z −θφ = −˜θφ.
Let us also take φ = 1, which is PE, for this example. Then we can show by solving
the differential equation via integration that
p(t) =
p0
1 + p0t
and ˜θ(t) =
˜θ(0)
1+p0t , i.e.,
θ(t) = θ∗+ θ(0) −θ∗
1 + p0t .
It is clear that as t →∞, p(t) →0, leading to the so-called covariance wind-up
problem. Since φ = 1 is PE, however, θ(t) →θ∗as t →∞, with a rate of 1
t (not
exponential) as predicted by Theorem 8.4. Even though θ(t) →θ∗, the covariance
windup problem may still pose a problem in the case where θ∗changes to some
other value after some time. If at that instance p(t) ∼= 0, leading to ˙θ ∼= 0, no adap-
tation will take place and θ(t) may not reach the new θ∗.
For the same example, consider φ(t) =
1
1+t which is not PE since
 t+T
t
φ2(τ)dτ =
 t+T
t
1
(1 + τ)2 dτ =
1
1 + t −
1
1 + t + T
goes to zero as t →∞, i.e., it has zero level of excitation. In this case, we can show
that
p(t) =
p0(1 + t)
1 + (1 + p0)t ,
θ(t) = θ∗+

θ(0) −θ∗
1 + t
1 + (1 + p0)t
by solving the differential equations above. It is clear that p(t) →
p0
1+p0 and θ(t) →
p0θ∗+θ(0)
1+p0
as t →∞; i.e., θ(t) converges to a constant but not to θ∗due to lack of
PE. In this case, po converges to a constant and no covariance wind-up problem
arises.
8.8.4 Modiﬁed LS Algorithms
One way to avoid the covariance wind-up problem is to modify the pure LS algo-
rithm using a covariance resetting modiﬁcation to obtain
˙θ = Pεφ,
θ(0) = θ0,
˙P = −P φφt
m2s
P,
P

t+
r

= P0 = ρ0I,
(8.45)
m2
s = 1 + n2
s,
n2
s = αφtφ,
α > 0,

494
8
Adaptive Control
where t+
r is the time at which λmin(P(t) ≤ρ1 and ρ0 > ρ1 > 0 are some design
scalars. Due to covariance resetting, P(t) ≥ρ1I ∀t ≥0. Therefore, P is guaranteed
to be positive deﬁnite for all t ≥0. In fact, the pure LS algorithm with covariance
resetting can be viewed as a gradient algorithm with time-varying adaptive gain P ,
and its properties are very similar to those of a gradient algorithm analyzed in the
previous section. They are summarized by Theorem 8.5 in this section.
When β > 0, the covariance wind-up problem, i.e., P(t) becoming arbitrarily
small, does not exist. In this case, P(t) may grow without bound. In order to avoid
this phenomenon, the following modiﬁed LS algorithm with forgetting factor is
used:
˙θ = Pεφ,
˙P =

βP −PφφtP
m2s
if ∥P(t)∥≤R0,
0
otherwise,
(8.46)
where P(0) = P0 = P t
0 > 0, ∥P0∥≤R0, R0 is a constant that serves as an upper
bound for ∥P∥, and m2
s = 1+n2
s is the normalizing signal which satisﬁes φ
ms ∈L∞.
The following theorem summarizes the stability properties of the two modiﬁed
LS algorithms.
Theorem 8.5 The pure LS algorithm with covariance resetting (8.45) and the mod-
iﬁed LS algorithm with forgetting factor (8.46) guarantee that
1. ε,εms, ˙θ ∈L2 ∩L∞and ˙θ ∈L∞.
2. If φ
ms is PE, then θ(t) →θ∗as t →∞exponentially fast.
3. If (8.35) is the SPM for the plant (8.44) with stable poles and no zero-pole can-
cellations, and u is sufﬁciently rich of order n+m+1, then φ, φ
ms are PE, which
guarantees that θ(t) →θ∗as t →∞exponentially fast.
8.8.5 Parameter Identiﬁcation Based on DPM
Let us consider the DPM
z = W(s)

θ∗tψ

.
This model may be obtained from z = θ∗tφ by ﬁltering each side with W(s) and
redeﬁning the signals z, φ. Since θ∗is a constant vector, the DPM may be written
as
z = W(s)L(s)

θ∗tφ

,
(8.47)
where φ = L−1(s)ψ, L(s) is chosen so that L−1(s) is a proper stable transfer func-
tion, and W(s)L(s) is a proper strictly positive real (SPR) transfer function.
ˆz = W(s)L(s)

θtφ

.

8.8
Least-Squares Algorithms
495
We form the normalized estimation error
ε = z −ˆz −W(s)L(s)

εn2
s

,
(8.48)
where the static normalizing signal ns is designed so that φ
ms ∈L∞for m2
s = 1+n2
s.
If W(s)L(s) = 1, then (8.48) has the same expression as in the case of the gradient
algorithm. Substituting for z in (8.48), we express ε in terms of the parameter error
˜θ = θ −θ∗:
ε = W(s)L(s)

−˜θtφ −εn2
s

.
(8.49)
For simplicity, let us assume that W(s)L(s) is strictly proper and rewrite (8.49) in
the minimum state-space representation form
˙e = Ace + bc

−˜θtφ −εn2
s

,
ε = ct
ce,
(8.50)
where W(s)L(s) = ct
c(sI −Ac)−1bc. Since W(s)L(s) is SPR, it follows that (see
the Appendix) there exist matrices Pc = ℜt
c > 0, Lc = Lt
c > 0, a vector q, and a
scalar ν > 0 such that
PcAc + At
cPc = −qqt −νLc,
Pcbc = cc.
(8.51)
The adaptive law for θ is generated using the Lyapunov-like function
V = etPce
2
+
˜θtΓ −1 ˜θ
2
,
where Γ = Γ t > 0. The time derivative ˙V of V along the solution of (8.50) is given
by
˙V = −1
2etqqte −ν
2etLce + etPcbc

−˜θtφ −εn2
s

+ ˜θtΓ −1 ˙˜θ.
Since etPcbc = etcc = ε, it follows that by choosing ˙˜θ = ˙θ as
˙θ = Γ εφ,
(8.52)
we get
˙V = −1
2etqqte −ν
2etLce −εn2
s ≤0.
As before, from the properties of V, ˙V we conclude that e, ε, θ ∈L∞and
e,ε,εns ∈L2. These properties in turn imply that ˙θ ∈L2. Note that without the
use of the second equation in (8.51), we are not able to choose ˙˜θ = ˙θ using signals
available for measurement to make ˙V ≤0. This is because the state e in (8.50) can-
not be generated since it depends on the unknown input ˜θtφ. Equation (8.50) is used
only for analysis.
The stability properties of the adaptive law (8.52) are summarized by the follow-
ing theorem.

496
8
Adaptive Control
Theorem 8.6 The adaptive law (8.52) guarantees that
1. ε,θ ∈L∞and ε,εns, ˙θ ∈L2.
2. If ns,φ, ˙φ ∈L∞and φ is PE, then θ(t) →θ∗exponentially fast.
The adaptive law (8.52) is referred to as the adaptive law based on the SPR–
Lyapunov synthesis approach.
Remark 8.7 The adaptive law (8.52) has the same form as the gradient algorithm
even though it is developed using a Lyapunov approach and the SPR property. In
fact, for W(s)L(s) = 1, (8.52) is identical to the gradient algorithm.
8.8.6 Parameter Identiﬁcation Based on B-SPM
Consider the bilinear SPM described by
z = ρ∗
θ∗tφ + Z0

,
(8.53)
where z, z0 are known scalar signals at each time t and ρ∗, θ∗are the scalar and
vector unknown parameters, respectively. The estimation error is generated as
ˆz = ρ

θtφ + z0

,
ε = z −ˆz
m2s
,
where ρ(t), θ(t) are the estimates of ρ∗, θ∗, respectively, at time t and where ms
is designed to bound φ, z0 from above. An example of ms with this property is
m2
s = 1 + φtφ + z2
0.
Let us consider the cost
J(ρ,θ) = ε2m2
s
2
= (z −ρ∗θtφ −ρξ + ρ∗ξ −ρ∗z0)
2m2s
,
where
ξ = θtφ + z0
is available for measurement. Applying the gradient method we obtain
˙θ = −Γ1
dJ
dθ θ = Γ1ερ∗φ,
˙ρ = −γ dJ
dθ ρ = γ1εξ,
where Γ1 = Γ t
1 > 0, γ > 0 are the adaptive gains. Since ρ∗is unknown, the adaptive
law for θ cannot be implemented. We bypass this problem by employing the equality
Γ1ρ∗= Γ1
ρ∗sgn

ρ∗
= Γ sgn

ρ∗
,

8.8
Least-Squares Algorithms
497
where Γ1 = Γ1|ρ∗|. Since Γ1 is arbitrary any Γ = Γ t > 0 can be selected without
having to know |ρ∗|. Therefore, the adaptive laws for θ, ρ, may be written as
˙θ = Γ εφ sgn

ρ∗
,
˙ρ = γ εξ,
(8.54)
ε = z −ρξ
m2s
,
ξ = θtφ + z0.
Theorem 8.8 The adaptive law (8.54) guarantees that
1. ε,εms, ˙θ, ˙ρ ∈L2 ∩L∞and θ,ρ ∈L∞.
2. If
ε
ms , then ρ(t) →¯ρ as t →∞, where ¯ρ is a constant.
3. If
ε
ms ∈L2 and φ
ms is PE, then θ(t) converges to θ∗as t →∞.
4. If the plant (8.44) has stable poles with no zero-pole cancellations and u is suf-
ﬁciently rich of order n + m + 1, then φ, φ
ms are PE and θ(t) converges to θ∗as
t →∞.
Proof Consider the Lyapunov-like function
V =
˜θtΓ −1 ˜θ
2
ρ∗ + ˜ρ2
2γ .
Then
˙V = ˜θtφε
ρ∗sgn

ρ∗
+ ˜ρεξ.
Using |ρ∗|sgn(ρ∗) = ρ∗and the expression
εm2
s = ρ∗θ∗tφ + ρ∗z0 −ρθtφ −ρz0
= −˜ρz0 + ρ∗θ∗tφ −ρθtφ + ρ∗θtφ −ρ∗θtφ
= −˜ρ

z0 + θtφ

−ρ∗˜θtφ = −˜ρξ −ρ∗˜θtφ,
we have
˙V = ε

ρ∗˜θtφ + ˜ρξ

= −ε2m2
s ≤0,
which implies that V ∈L∞and therefore ρ,θ ∈L∞. Using similar analysis as
in the case of the gradient algorithms for the SPM, we can establish (i) from the
properties of V , ˙V and the form of the adaptive laws.
(ii) We have
ρ(t) −ρ(0) =
 t
0
˙ρ dτ ≤
 t
0
| ˙ρ|dτ ≤γ
 t
0
|εms| |ξ|
ms
dτ
≤γ
	 t
0
ε2m2
s dτ

1/2	 t
0
|ξ|2
m2s
dτ

1/2
< ∞,
where the last inequality is obtained using the Schwarz inequality (see [6]).
Since εms, ξ
ms ∈L2, the limit as t →∞exists, which implies that ˙ρ ∈L1 and

498
8
Adaptive Control
limt→∞ρ(t) = ¯ρ for some constant ¯ρ. The proof of (iii) is long and is presented in
the web resource [9]. The proof of (iv) is included in the proof of Theorem 8.1.
□
The assumption that the sign of ρ∗is known can be relaxed, leading to an adap-
tive law for θ, ρ with additional nonlinear terms.
8.9 Parameter Projection
In many practical problems, we may have some a priori knowledge of where θ∗
is located in ℜn. This knowledge usually comes in terms of upper and/or lower
bounds for the elements of θ∗or in terms of location in a convex subset of ℜn. If
such a priori information is available, we want to constrain the online estimation to
be within the set where the unknown parameters are located. For this purpose, we
modify the gradient algorithms based on the unconstrained minimization of certain
costs using the gradient projection method presented in Sect. 3.5.18 as follows.
The gradient algorithm with projection is computed by applying the gradient
method to the following minimization problem with constraints:
minJ(θ)
subject to θ ∈S,
where S is a convex subset of ℜn with smooth boundary almost everywhere. Assume
that S is given by
S =

θ ∈ℜn|g(θ) ≤0

,
where g : ℜn →R is a smooth function.
The adaptive laws based on the gradient method can be modiﬁed to guarantee
that θ ∈S by solving the constrained optimization problem given above to obtain
˙θ = Pr
	
−Γ dJ
dθ

=
⎧
⎨
⎩
−Γ dJ
dθ
if θ ∈S0, or θ ∈δ(S) and −(Γ dJ
dθ )t := g ≤0,
−Γ dJ
dθ + Γ
dg
dθ
dgt
dθ
dgt
dθ Γ dg
dθ
Γ dJ
dθ
otherwise,
(8.55)
where δ(S) = {θ ∈ℜn|g(θ) = 0} and S0 = {θ ∈ℜn|g(θ) < 0} denote the boundary
and the interior, respectively, of S and Pr(·) is the projection operator.
The gradient algorithm based on the instantaneous cost function with projection
follows from (8.55) by substituting for dJ
dθ = −εφ to obtain
˙θ = Pr(Γ εφ)
=
⎧
⎨
⎩
Γ εφ
if θ ∈S0, or θ ∈δ(S) and (Γ εφ)t dg
dθ ≤0,
Γ εφ −Γ
dg
dθ
dg
dθ
t
dg
dθ
tΓ dg
dθ
Γ εφ
otherwise,
(8.56)
where θ(0) ∈S.

8.9
Parameter Projection
499
The pure LS algorithm with projection becomes
˙θ = Pr(Pεφ)
=
⎧
⎨
⎩
Pεφ
if θ ∈S0 or θ ∈δ(S) and (Pεφ)t dg
dθ ≤0,
Pεφ −P
dg
dθ
dg
dθ
t
dg
dθ
tP dg
dθ
Pεφ
otherwise,
(8.57)
where θ(0) ∈S,
˙P =

βP −P φφt
m2s P
if θ ∈S0 or θ ∈δ(S) and (Pεφ)t dg
dθ ≤0,
0
otherwise,
and P(0) = P0 = P t
0 > 0.
Theorem 8.9 The gradient adaptive laws of Sect. 8.7 and the LS adaptive laws of
Sect. 8.8 with the projection modiﬁcations given by (8.55) and (8.57), respectively,
retain all the properties that are established in the absence of projection and in
addition guarantee that θ(t) ∈S ∀t ≥0, provided θ(0) ∈S and θ∗∈S.
8.9.1 Example 8.9
Let us consider the plant model
y =
b
s + a u
where a, b are unknown constants that satisfy some known bounds, e.g., b ≥1 and
20 ≥a ≥−2. For simplicity, let us assume that y, ˙y,u are available for measure-
ment so that the SPM is of the form
z = θ∗tφ,
where z = ˙y, θ∗= [b,a]t, φ = [u,−y]t. In the unconstrained case the gradient
adaptive law is given as
˙θ = Γ εφ,
ε = z −θtφ
m2s
,
where m2
s = 1 + φtφ; θ = [ˆb, ˆa]; ˆb, ˆa are the estimates of b, a, respectively. Since
we know that b ≥1 and 20 ≥a ≥−2, we can constrain the estimates ˆb, ˆa to be
within the known bounds by using projection. Deﬁning the sets for projection as
Sb = {ˆb ∈R|1 −ˆb ≤0},
Sl
a = {ˆa ∈R| −2 −ˆa ≤0},
Su
a = {ˆa ∈R| ˆa −20 ≤0}

500
8
Adaptive Control
and applying the projection algorithm (8.55) for each set, we obtain the adaptive
laws
˙ˆb =
γ1εu
if ˆb > 1 or (ˆb = 1 and εu ≥0),
0
if ˆb = 1 and εu < 0,
with ˆb(0) ≥1, and
˙ˆa =
⎧
⎨
⎩
−γ2εy
if 20 > ˆa > −2 or (ˆa = −2 and εy ≤0)
or (ˆa = 20 and εy ≥0),
0
if (ˆa = −2 and εy > 0) or (ˆa = 20 and εy < 0),
with ˆa(0) satisfying 20 ≥ˆa(0) ≥−2.
8.9.2 Example 8.10
Let us consider the gradient adaptive law
˙θ = Γ εφ
with the a priori knowledge that |θ∗| ≤M0 for some known bound M0 > 0. In most
applications, we may have such a priori information. We deﬁne
S =

θ ∈ℜng(θ)
 = θtθ
2 −M2
0
2 ≤0

and use (8.55) together with dg
dθ = θ to obtain the adaptive law with projection
˙θ =
Γ εφ
if |θ| < M0 or (|θ| = M0 and φtΓ θε ≤0),
Γ εφ −Γ
θθt
θtΓ θ Γ εφ
if |θ| = M0 and φtΓ θε > 0
with |θ(0)| ≤M0.
8.10 Robust Parameter Identiﬁcation
In the previous sections, we designed and analyzed a wide class of PI algorithms
based on the parametric models
z = θ∗tφ
or
W(s)θ∗tφ.
These parametric models are developed using a plant model that is assumed to be
free of disturbances, noise, unmodeled dynamics, time delays, and other frequently
encountered uncertainties. In the presence of plant uncertainties, we are no longer
able to express the unknown parameter vector θ∗in the form of the SPM or DPM
where all signals are measured and θ∗is the only unknown term. In this case, the
SPM or DPM takes the form
z = θ∗tφ + η
or
z = W(s)θ∗tφ + η,
(8.58)
where η is an unknown function that represents the modeling error terms. The fol-
lowing examples are used to show how (8.58) arises for different plant uncertainties.

8.10
Robust Parameter Identiﬁcation
501
8.10.1 Example 8.11
Let us consider the plant
y = θ∗
1 + μΔm(s)

u,
(8.59)
where μ is a small constant and Δm(s) is a proper transfer function with poles in the
open left half s-plane. Since μ is small and Δm(s) is proper with stable poles, the
term μΔm(s) can be treated as the modeling error term which can be approximated
with zero. We can express (8.59) in the form of (8.58) as
y = θ∗u + η,
where
η = μθ∗Δm(s)u
is the modeling error term.
For LTI plants, the parametric model with modeling errors is usually of the form
z = θ∗tu + η,
η = Δ1(s)u + Δ2(s)y + d,
(8.60)
where Δ1(s), Δ2 are proper transfer functions with stable poles and d is a bounded
disturbance. The principal question that arises is how the stability properties of the
adaptive laws that are developed for parametric models with no modeling errors are
affected when applied to the actual parametric models with uncertainties.
8.10.2 Example 8.12
The following example demonstrates that the adaptive laws of the previous sections
that are developed using parametric models that are free of modeling errors cannot
guarantee the same properties in the presence of modeling errors. Furthermore, it
often takes only a small disturbance to drive the estimated parameters unbounded.
Consider the scalar constant gain system
y = θ∗u + d,
where d is a bounded unknown disturbance and u ∈L∞. The adaptive law for esti-
mating θ∗derived for d = 0 is given by
˙θ = γ εu,
ε = y −θu,
(8.61)
where γ > 0 and the normalizing signal is taken to be 1. If d = 0 and u, ˙u ∈L∞
then we can establish that (i) ˙θ,θ,ε ∈L∞, (ii) ε(t) →0 as t →∞by analyzing the
parameter error equation
˙˜θ = −γ u2 ˜θ,

502
8
Adaptive Control
which is a linear time-varying differential equation. When d ̸= 0, we have
˙˜θ = −γ u2 ˜θ + γ du.
(8.62)
In this case, we cannot guarantee that the parameter estimate θ(t) is bounded for
any bounded input u and disturbance d. In fact, for θ∗= 2, γ = 1,
u = (1 + t)−1/2,
d(t) = (1 + t)−1/4
	5
4 −2(1 + t)−1/4

→0
as t →∞,
we have
y(t) = 5
4(1 + t)−1/4 →0
as t →∞,
ε(t) = 1
4(1 + t)−1/4 →0
as t →∞,
θ(t) = (1 + t)−1/4 →∞
as t →∞;
that is, the estimated parameter drifts to inﬁnity with time even though the distur-
bance d(t) disappears with time. This instability phenomenon is known as param-
eter drift. It is mainly due to the pure integral action of the adaptive law, which, in
addition to integrating the “good” signals, integrates the disturbance term as well,
leading to the parameter drift phenomenon.
Another interpretation of the above instability is that, for u = (1 + t)−1/2, the
homogeneous part of (8.62), that is, ˙˜θ = −γ u2 ˜θ, is only uniformly stable, which
is not sufﬁcient to guarantee that the bounded input γ du will produce a bounded
state ˜θ. If u is persistently exciting, i.e.,
 t+T0
t
u2(τ)dτ ≥α0T0 for some α0,T0 > 0
and ∀t ≥0, then the homogeneous part of (8.62) is e.s. and the bounded input γ du
produces a bounded state ˜θ.
If the objective is parameter convergence, then parameter drift can be prevented
by making sure the regressor vector is PE with a level of excitation higher than
the level of the modeling error. In this case, the plant input in addition to being
sufﬁciently rich is also required to guarantee a level of excitation for the regressor
that is higher than the level of the modeling error. This class of inputs is referred to
as dominantly rich and is discussed in the following section.
8.10.3 Dominantly Rich Excitation
Let us revisit the example in Sect. 8.10.2 and analyze (8.62), that is,
˙˜θ = −γ u2 ˜θ + γ du,
(8.63)
when u is PE with level α0 > 0. The PE property of u implies that the homogeneous
part of (8.63) is e.s., which in turn implies that
 ˜θ(t)
 ≤e−γ α1t ˜θ(0)
 + 1
α1

1 −e−γ α1t
sup
τ≤t
u(τ)d(τ)


8.10
Robust Parameter Identiﬁcation
503
for some α1 > 0 which depends on α0. Therefore, we have
lim
t→∞sup
τ≥t
 ˜θ(τ)
 ≤1
α1
lim
t→∞sup
τ≥t
u(τ)d(τ)
 = 1
α1
sup
τ
u(τ)d(τ)
.
(8.64)
The bound (8.64) indicates that the PI error at steady state is of the order of the
disturbance; i.e., as d →0 the parameter error also reduces to zero. For this simple
example, it is clear that if we choose u = u0, where u0 is a constant different from
zero, then α1 = α0 = u2
0; therefore, the bound for | ˜θ| is sup1
|d(t)|
u0 . Thus, the larger
the value of u0 is, the smaller the parameter error. Large u0 relative to |d| implies
large signal-to-noise ratio and therefore better accuracy of identiﬁcation.
Deﬁnition 8.10 A sufﬁciently rich input u of order n + m + 1 for the dominant part
of the plant
y = G0(s)u + Δ(μs)u + d
(8.65)
is called dominantly rich of order n + m + 1 if it achieves its richness with fre-
quencies ωi, i = 1,2,...,N, where N ≥n+m+1
2
, |ωi| < O( 1
μ),2 |ωi −ωj| > O(μ),
i ̸= j, and |u| > O(μ) + O(d).
Lemma 8.11 Let H0(s), H1(μs,s) satisfy the following assumptions:
1. The vectors H0(jω1),H0(jω2),...,H0(jω¯n) are linearly independent on Cn for
all possible ω1,ω2,...,ω¯n ∈R, where ¯n := n + m + 1 and ω1 ̸= ωk for i ̸= k.
2. For any set {ω1,ω2,...,ω¯n} satisfying |ωi −ωk| > O(μ) for i ̸= k and
|ωi| < O( 1
μ), we have |det( ¯H)| > O(μ), where ¯H := [H0(jω1),H0(jω2),...,
H0(jω¯n)].
3. |H1(jμω,jω)| ≤c for some constant c independent of μ and ∀ω ∈R.
Then there exists a μ∗> 0 such that for μ ∈[0,μ∗), φ is PE of order n + m + 1
with level of excitation α1 > O(μ), provided that the input signal u is dominantly
rich of order n + m + 1 for the plant (8.65).
Consider the plant
y =
b
s + a
	
1 + 2μ(s −1)
(μs + 1)2

u,
where a, b are the unknown parameters and μ = 0.001. The plant may be modeled
as
y =
b
s + a u
by approximating μ = 0.001 ∼= 0. The input u = sinω0t with 1 ≪ω0 ≪1000
would be a dominantly rich input of order 2. Frequencies such as ω0 = 0.006 rad/s
or ω0 = 900 rad/s would imply that u is not dominantly rich even though u is sufﬁ-
ciently rich of order 2.
2A function f (x) is of O(μ) ∀x ∈ if there exists a constant c ≥0 such that ∥f (x)∥≤c|μ|
∀x ∈.

504
8
Adaptive Control
8.11 State-Space Identiﬁers
Let us consider the state-space plant model
˙x = Apx + Bpu,
(8.66)
where x ∈ℜn is the state, u ∈ℜm is the input vector, and Ap ∈ℜn×n, Bp ∈ℜn×m
are unknown constant matrices. We assume that x,u are available for measurement.
One way to estimate the elements of Ap, Bp online is to express (8.66) as a set of n
scalar differential equations and then generate n parametric models with scalar out-
puts and apply the parameter estimation techniques covered in the previous sections.
Another more compact way of estimating Ap, Bp is to develop online estimators
based on an SSPM model for (8.66) as follows.
We express (8.66) in the form of the SSPM:
˙x = Amx + (Ap −Am)x + Bpu,
where Am is an arbitrary stable matrix. The estimation model is then formed as
˙ˆx = Am ˆx + ( ˆAp −Am)x + ˆBpu = Am(ˆx −x) + ˆApx + ˆBpu
where ˆAp(t), ˆBp(t) are the estimates of Ap, Bp at time t, respectively. The above
estimation model has been referred to as the series-parallel model in the literature
[8, 9, 12]. The estimation error vector is deﬁned as
ε = x −ˆx −(sI −Am)−1εn2
s
or
ε = x −ˆx −w,
˙w = Amw + εn2
s,
w(0) = 0,
where n2
s is the static normalizing signal designed to guarantee
x
√
1+n2s
,
u
√
1+n2s
∈
L∞. A straightforward choice for ns is n2
s = xtx + utu. It is clear that if the plant
model (8.66) is stable and the input u is bounded, then ns can be taken to be equal
to zero.
It follows that the estimation error satisﬁes
˙ε = Amε −˜Apx −˜Bpu −εn2
s,
where ˜Ap := ˆAp −Ap, ˜Bp := ˆBp −Bp are the parameter errors.
The adaptive law for generating ˆAp, ˆBp is developed by considering the Lya-
punov function
V (ε, ˜Ap, ˜Bp) = εtPε + tr
	 ˜At
pP ˜Ap
γ1

+ tr
	 ˜Bt
pP ˜Bp
γ2

,
(8.67)
where tr(A) denotes the trace of matrix A; γ1,γ2 > 0 are constant scalars; and P =
pt > 0 is chosen as the solution of the Lyapunov equation
PAm + AmP t = −Q
(8.68)

8.11
State-Space Identiﬁers
505
for some Q = Qt > 0, whose solution is guaranteed by the stability of Am (see the
Appendix). The time derivative ˙V is given by
˙V = ˙εtPε + εtP ˙ε + Tr
	 ˙˜At
pP ˜Ap
γ1
+
˜At
pP ˙˜Ap
γ1

+ Tr
	 ˙˜Bt
pP ˜Bp
γ2
+
˜Bt
pP ˙˜Bp
γ2

.
Substituting for ˙ε, using (8.68), and employing the equalities Tr(A + B) = Tr(A) +
Tr(B) and Tr(At) = Tr(A) for square matrices A, B of the same dimension, we
obtain
˙V = −εtQε −2εtP ˜Apx −2εtP ˜Bpu + 2tr
	 ˜At
pP ˙˜Ap
γ1
+
˜Bt
pP ˙˜Bp
γ2

−2εtPεn2
s.
(8.69)
Using the equality vty = tr(vyt)for vectors v, y of the same dimension, we rewrite
(8.69) as
˙V = −εtQε + 2Tr
	 ˜At
pP ˙˜Ap
γ1
−˜At
pPεxt +
˜Bt
pP ˙˜Bp
γ2
−˜Bt
pPεut

−2εtPεn2
s.
(8.70)
The obvious choice for ˙ˆAp = ˙˜Ap, ˙ˆBp = ˙˜Bp to make ˙V negative is
˙ˆAp = γ1εxt,
˙ˆBp = γ2εut,
(8.71)
which gives us
˙V = −εtQε −2εtPεn2
s ≤0.
This implies that V , ˆAp, ˆBp, ε are bounded. We can also write
˙V ≤−|ε|2λmin(Q) −2|εns|2λmin(P) ≤0
and use similar arguments as in the previous sections to establish that ε,εns ∈L2.
From (8.71), we have that
∥˙ˆAp∥≤γ1|εms||xt|
ms
,
∥˙ˆBp∥≤γ2|εms||ut|
ms
,
where m2
s = 1 + n2
s. Since |x|
ms , |u|
ms ∈L∞and |εms| ∈L2, we can also conclude that
∥˙ˆAp∥,∥˙ˆBp∥∈L2.
We have, therefore, established that independent of the stability of the plant and
boundedness of the input u, the adaptive law (8.71) guarantees that
• ∥ˆAp∥,∥ˆBp∥,ε ∈L∞,
• ∥˙ˆAp∥,∥˙ˆBp∥,ε,εns ∈L2.
These properties are important for adaptive control where the adaptive law is used
as part of the controller and no a priori assumptions are made about the stability
of the plant and boundedness of the input. If the objective, however, is parameter
estimation, then we have to assume that the plant is stable and the input u is designed
to be bounded and sufﬁciently rich for the plant model (8.66). In this case, we can
take n2
s = 0.

506
8
Adaptive Control
Theorem 8.12 Consider the plant model (8.66) and assume that (Ap,Bp) is con-
trollable and Ap is a stable matrix. If each element ui, i = 1,2,...,m, of vector u
is bounded, sufﬁciently rich of order n + 1, and uncorrelated, i.e., each ui contains
different frequencies, then ˆAp(t), ˆBp(t) generated by (8.71) (where ns can be taken
to be zero) converge to Ap, Bp, respectively, exponentially fast.
8.11.1 Example 8.13
Consider the second-order plant
˙x = Ax + Bu,
where x = [x1,x2], u = [u1,u2]t is a bounded input vector, the matrices A, B are
unknown, and A is a stable matrix. The estimation model is generated as
˙ˆx =
−am
0
0
−am

(ˆx ⊢x) +
 ˆa11
ˆa12
ˆa21
ˆa22

x +
 ˆb11
ˆb12
ˆb21
ˆb22

u,
where ˆx = [ˆx1, ˆx2]t and am > 0. The estimation error is given by
ε = x −ˆx,
where ns = 0 due to the stability of A and boundedness of u. The adaptive law
(8.71) can be written as
˙ˆaij = γ1εixj,
˙ˆbij = γ2εiuj
for i = 1,2, j = 1,2, and adaptive gains γ1, γ2. An example of a sufﬁciently rich
input for this plant is
u1 = c1 sin2.5t + c2 sin4.6t,
u2 = c3 sin7.2t + c4 sin11.7t
for some nonzero constants ci, i = 1,2,3,4.
The class of plants described by (8.66) can be expanded to include more realistic
plants with modeling errors. The adaptive laws in this case can be made robust by
using exactly the same techniques as in the case of SISO plants described in previous
sections, and this is left as an exercise for the reader.
8.12 Adaptive Observers
Consider the LTI SISO plant
˙x = Ax + Bu,
x(0) = x0,
y = Ctx,
(8.72)

8.12
Adaptive Observers
507
where x ∈ℜn. We assume that u is a piecewise continuous bounded function of time
and that A is a stable matrix. In addition, we assume that the plant is completely
controllable and completely observable. The problem is to construct a scheme that
estimates both the plant parameters, i.e., A, B, C, as well as the state vector x using
only I/O measurements. We refer to such a scheme as the adaptive observer.
A good starting point for designing an adaptive observer is the Luenberger ob-
server used in the case where A, B, C are known. The Luenberger observer is of the
form
˙ˆx = Aˆx + Bu + K(y −ˆy),
ˆx(0) = ˆx0,
ˆy = Ct ˆx,
(8.73)
where K is chosen so that A −KCt is a stable matrix, and guarantees that ˆx →x
exponentially fast for any initial condition x0 and any input u. For A −KCt to be
stable, the existence of K is guaranteed by the observability of (A,C).
A straightforward procedure for choosing the structure of the adaptive observer is
to use the same equation as the Luenberger observer (8.73), but replace the unknown
parameters A, B, C with their estimates A, B, C, respectively, generated by some
adaptive law. The problem we face with this procedure is the inability to estimate
uniquely the n2 + 2n parameters of A, B, C from the I/O data. The best we can do
in this case is to estimate the parameters of the plant transfer function and use them
to calculate ˆA, ˆB, ˆC. These calculations, however, are not always possible because
the mapping of the 2n estimated parameters of the transfer function to the n2 + 2n
parameters of ˆA, ˆB, ˆC is not unique unless (A,B,C) satisﬁes certain structural
constraints. One such constraint is that (A,B,C) is in the observer form, i.e., the
plant is represented as
˙xα =

−ap
In−1
0

xα + bpu,
y = [1,0,...,0]xα,
(8.74)
where ap = [an−1,an−2,...,a0]t and bp = [bn−1,bn−2,...,b0]t are vectors of di-
mension n, and In−1 ∈ℜ(n−1)×(n−1) is the identity matrix. The elements of ap and
bp are the coefﬁcients of the denominator and numerator, respectively, of the trans-
fer function
y(s)
u(s) =
bn−1sn−1 + bn−2sn−2 + ··· + b0s
sn + an−1sn−1 + an−2sn−2 + ··· + a0s
(8.75)
and can be estimated online from I/O data using the techniques presented in the
previous sections.
Since both (8.72) and (8.74) represent the same plant, we can focus on the plant
representation (8.74) and estimate xα instead of x. The disadvantage is that in a
practical situation x may represent some physical variables of interest, whereas xα
may be an artiﬁcial state vector.
The adaptive observer for estimating the state xα of (8.74) is motivated from the
Luenberger observer structure (8.73) and is given by
˙ˆx = ˆA(t)ˆx + ˆbp(t)u + K(t)(y −ˆy),
ˆx(0) = ˆx0,
ˆy = [1,0,...,0]ˆx,
(8.76)

508
8
Adaptive Control
where ˆx is the estimate of xα,
ˆA(t) =

−ˆap(t)
In−1
0

,
K(t) = a∗−ˆap(t),
ˆap(t) and ˆbp(t) are the estimates of the vectors ap and bp, respectively, at time t,
and a∗∈ℜn is chosen so that
A∗=

−a∗
In−1
0

.
(8.77)
is a stable matrix that contains the eigenvalues of the observer.
A wide class of adaptive laws may be used to generate ˆap(t) and ˆbp(t) online.
As in Chap. 2, the parametric model
z = θ∗tφ
(8.78)
may be developed using (8.75), where
θ∗=

bt
p,at
p
t
and z, φ are available signals, and used to design a wide class of adaptive laws
to generate θ(t) = [ˆbt
p(t),at
p(t)]t, the estimate of θ∗. As an example, consider the
gradient algorithm
˙θ = Γ εφ,
ε = z −θtφ
m2s
,
(8.79)
where m2
s = I + αφtφ and α ≥0.
Theorem 8.13 The adaptive observer described by (8.76)–(8.79) guarantees the
following properties:
1. All signals are bounded.
2. If u is sufﬁciently rich of order 2n, then the state observation error |ˆx −xa| and
the parameter error |θ −θ∗| converge to zero exponentially fast.
Proof (i) Since A is stable and u is bounded, we have xa,y,φ ∈L∞and hence
m2
s = 1 + αφtφ ∈L∞. The adaptive law (8.79) guarantees that θ ∈L∞and
ε,εms, ˙θ ∈L2 ∩L∞.
The observer equation may be written as
˙ˆx = A∗ˆx + ˆbp(t)u +
 ˆA(t) −A∗
xα.
Since A∗is a stable matrix and ˆbp, ˆA, u, xα are bounded, it follows that ˆx ∈L∞,
which in turn implies that all signals are bounded.
(ii) The state observation error ˜x = ˆx −xα satisﬁes
˙˜x = A∗˜x + ˜bpu −˜apy,
(8.80)
where ˜bp = ˆbp −bp, ˜ap = ˆap −ap are the parameter errors. Since for u sufﬁciently
rich we have that θ(t) →θ∗as t →∞exponentially fast, it follows that ˜bp, ˜ap →0
exponentially fast. Since u,y ∈L∞, the error equation consists of a homogeneous
part that is exponentially stable and an input that is decaying to zero. This implies
that ˜x = ˆx −xa →0 as t →∞exponentially fast.
□

8.13
A Single Bottleneck Link Computer Network
509
Fig. 8.8 Network topology
8.13 A Single Bottleneck Link Computer Network
The congestion control problem in computer networks has been identiﬁed as a feed-
back control problem. The network users adjust their sending data rates, in response
to congestion signals they receive from the network, in an effort to avoid congestion
and converge to a stable equilibrium that satisﬁes certain requirements: high net-
work utilization, small queue sizes, small delays, fairness among users, etc. Many
of the proposed congestion control schemes require that at each link the number of
ﬂows, N say, utilizing the link is known. Since the number of users varies with time,
N is an unknown time-varying parameter, which needs to be estimated online. Es-
timation algorithms, which have been proposed in the literature, are based on point
wise time division, which is known to lack robustness and may lead to erroneous
estimates. In this study, we consider a simple estimation algorithm, which is based
on online parameter identiﬁcation.
We consider the single bottleneck link network shown in Fig. 8.8. It consists of N
users which share a common bottleneck link through high bandwidth access links.
At the bottleneck link, we assume that there exists a buffer, which accommodates
the incoming packets. The rate of data entering the buffer is denoted by y, the queue
size is denoted by q, and the output capacity is denoted by C. At the bottleneck
link, we implement a signal processor, which calculates the desired sending rate p.
This information is communicated to the network users, which set their sending rate
equal to p. The desired sending rate p is updated according to the following control
law:
˙p =
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
1
ˆN [ki(C −y) −kqq]
if 1 < p < C,
1
ˆN [ki(C −y) −kqq]
if p = 1, 1
ˆN [ki(C −y) −kqq] > 0,
1
ˆN [ki(C −y) −kqq]
if p = C, 1
ˆN [ki(C −y) −kqq] < 0,
0
otherwise,
(8.81)
where ˆN is an estimate of N which is calculated online and ki, kq are design param-
eters. Since N is changing with time, its estimate ˆN has to be updated accordingly.
In this study, we use online parameter estimation to generate ˆN. Since the sending
rate of all users is equal to p, it follows that
y = Np.
(8.82)

510
8
Adaptive Control
Fig. 8.9 Time response of
the estimate of the number of
ﬂows
Since y and p are measured at the bottleneck link, (8.82) is in the form of an SPM
with N as the unknown parameter. We also know that N cannot be less than 1. Using
the results of the chapter, we propose the following online parameter estimator:
˙ˆN =

γ εp
if ˆN > 1 or ˆN = 1 and εp ≥0,
0
otherwise,
ε = y −ˆNp
1 + p2 ,
(8.83)
where ˆN(0) ≥1. We demonstrate the effectiveness of the proposed algorithm using
simulations, which we conduct on the packet-level simulator ns −2. We consider
the network topology of Fig. 8.8 in our simulations. The bandwidth of the bottleneck
link is set to 155 Mb/s, and the propagation delay of each link is set to 20 ms. The
design parameters are chosen as follows: γ = 0.1, ki = 0.16, kq = 0.32. Initially
30 users utilize the network. The estimator starting with an initial estimate of 10
converges to 30. After t = 30 seconds 20 of these users stop sending data, while an
additional 20 users enter the network at t = 45 s. The output of the estimator at the
bottleneck link is shown in Fig. 8.9. We observe that the estimator accurately tracks
the number of ﬂows utilizing the network. In addition, we observe good transient
behavior as the responses are characterized by fast convergence and no overshoots.
The estimator results are obtained in the presence of noise and delays which were
not included in the simple model (8.82). Since the number of parameters to be es-
timated is 1, the PE property is satisﬁed for p ̸= 0, which is always the case in this
example.
8.14 MATLAB Hints
A fundamental software toolkit is the Adaptive Control Toolbox for MATLAB and
Simulink. It aims at designing, implementing, and analyzing parameter identiﬁca-

8.15
Questions
511
Table 8.1 A short account of some of the MATLAB functions
ucgrad, ucgradbk
On-line continuous-time parameter estimation using generalized gradient
method (including SPR-Lyapunov approach)
udgrad
On-line discrete-time parameter estimation using generalized gradient
method (including SPR–Lyapunov approach)
ucrls
On-line continuous-time parameter estimation using least-squares method
udproj
On-line parameter estimation using projection algorithm
mrcpoly
MRC/MRAC design based on polynomial approach
udmracdr
Discrete-time direct MRAC
udmracidr
Discrete-time indirect MRAC
dmpc
Minimum prediction error control (MPE) design
umpcdrl
Direct MPEC for linear parametric models
umpcidr
Indirect MPEC
tion and adaptive control schemes. It is of interest to stress that the design and imple-
mentation can be performed for both continuous-time and discrete-time plants. This
extensive toolbox includes most of the widely-accepted algorithms in the adaptive
control literature. These include various gradient and least squares based parameter
identiﬁcation routines, model reference and pole placement adaptive control laws,
parameter projection and robust modiﬁcation algorithms. In Table 8.1 we provide a
short account of some of the MATLAB functions [4].
8.15 Questions
1. Consider the third-order plant
y = G(s)u,
where
G(s) =
b2s2 + b1s + b0
s3 + a2s2 + a1s + a0
.
a) Obtain parametric models for the plant in the form of SPM and DPM when
θ∗= [b2,b1,b0,a2,a1,a0]t.
b) If a0, a1, and a2 are known, i.e., a0 = 2, a1 = 1, and a2 = 3, obtain a para-
metric model for the plant in terms of θ∗= [b2,b1,b0]t.
c) If b0, b1, and b2 are known, i.e., b0 = 2, b1 = b2 = 0, obtain a parametric
model in terms of θ∗= [a2,a1,a0]t.
2. Consider the mass-spring-dashpot system of Fig. 8.6 described by (8.6) with
x, u as the only signals available for measurement. Let us assume that M =
100 kg and f , k are the unknown constant parameters that we want to estimate
online. Develop a parametric model for estimating the unknown parameters
f , k. Specify any arbitrary parameters or ﬁlters used.

512
8
Adaptive Control
3. Consider the second-order ARMA model
y(k) = −1.3y(k −1) −a2y(k −2) + b1u(k −1) + u(k −2),
where the parameters a2, b1 are unknown constants. Express the unknown pa-
rameters in the form of a linear parametric model. Assume that u(k), y(k), and
their past values are available for measurement.
4. Consider the fourth-order ARMA model
y(k + 4) = a1y(k + 3) −a2y(k) + b1u(k) + u(k + 2),
where a1, a2, b1 are unknown constants. Express the unknown parameters in the
form of a linear parametric model. Assume that only the current and the past
four values of the signals u and y, i.e., u(k),...,u(k −4),y(k),...,y(k −4),
are available for measurement.
5. Consider the nonlinear system
¨x + 2˙x + x = a1f1(x) + a2f2(x) + b1g1(x)u + b2g2(x)u,
where a1, a2, b1, b2 are unknown constants and x, f1(x), f2(x), g1(x), g2(x),
u are available for measurement. Express the unknown parameters in the form
of
a) the linear SPM,
b) the linear DPM.
6. Consider the following system described in the I/O form
y = Kp
s + b
s2 + as + cu,
where b, a, c, Kp are unknown constants. In addition, we know that Kp > 0 and
only u and y are available for measurement. Express the unknown parameters
in the form of the
a) B-SPM,
b) B-DPM,
c) linear SPM,
d) linear DPM.
7. Consider the nonlinear system
˙x = f (x) + g(x)u,
where the state x and the input u are available for measurement and f (x), g(x)
are smooth but unknown functions of x. In addition, it is known that g(x) > 0
∀x. We want to estimate the unknown functions f , g online using neural net-
work approximation techniques. It is known that there exist constant parameters
W ∗
f , W ∗
g , referred to as weights, such that
f (x) ≈
m

i=1
W ∗
f iϕf i(x),
g(x) ≈
n

i=1
W ∗
giϕgi(x),

8.15
Questions
513
where ϕf i(·), ϕgi(·) are some basis functions that are known and n, m are
known integers representing the number of nodes of the neural network. Ob-
tain a parameterization of the system in the form of SPM that can be used to
identify the weights W ∗
f i, W ∗
gi online.
8. Consider the mass-spring-dashpot system of Fig. 8.6 described by (8.6) and the
SPM with θ∗= [M,j,k]t presented in Example 8.4.
a) Generate the signals z, φ of the parametric model using the Adaptive
Control Toolbox for M = 100 kg, f = 0.15 kg/s, k = 7 kg/s2, u(t) =
1 + cos( π
3 t), and 0 ≤t ≤25 s.
b) The SPM in (a) is based on the assumption that M, f , k are unknown.
Assume that M is known. Use the Adaptive Control Toolbox to generate
the signals of the reduced SPM for the same values of M, f , k, u(t) =
1 + cos( π
3 t), and 0 ≤t ≤25 s.
c) Consider the SPM
z = θ∗tφ
and the estimation model
ˆz = θt(t)φ.
Find values for θ(t), φ(t) such that z = ˆz but θ(t) ̸= θ∗.
d) Consider the adaptive law
˙θ = γ εφ,
where θ, φ ∈ℜn,
φ
ms ∈L∞, εms ∈L2 ∩L∞, and ms ≥1. Show that ˙θ ∈
L2 ∩L∞.
e) Show that if u ∈L∞in (8.8), then the adaptive law (8.17) with m2
s = 1 +
αφ2,α ≥0, guarantees that ε,εms, ˙θ ∈L2 ∩L∞and that ε(t),ε(t)ms(t),
˙θ(t) →0 as t →∞.
f) (a) Show that (8.23) is a necessary and sufﬁcient condition for θ(t) in the
adaptive law (8.17) to converge to θ∗exponentially fast.
(b) Establish which of the following choices for u guarantee that φ in
(8.17) is PE:
(i) u = c0 ̸= 0, c0 is a constant.
(ii) u = sint.
(iii) u = sint + cos2t.
(iv) u =
1
1+t .
(v) u = e−t.
(vi) u =
1
(1+t)1/2 .
(c) In (b), is there a choice for u that guarantees that θ(t) converges to θ∗
but does not guarantee that φ is PE?
9. Use the plant model (8.53) to develop the bilinear parametric model. Show all
the steps.
10. In Theorem 8.1, assume that φ, ˙φ ∈L∞. Show that the adaptive law (8.33) with
m2
s = 1 + n2
s, n2
s = αφtφ, and α ≥0 guarantees that ε(t), ε(t)ms(t), ˙θ(t) →0
as t →∞.

514
8
Adaptive Control
11. Consider the SPM z = θ∗tφ and the cost function
J(θ) = 1
2
 t
0
e−β(t−τ) (z(τ) −θt(t)φ(τ))2
m2s(τ)
dτ,
where m2
s = 1 + φtφ and θ(t) is the estimate of θ∗at time t.
i. Show that the minimization of J(θ) w.r.t. θ using the gradient method leads
to the adaptive law
˙θ(t) = Γ
 t
0
e−β(t−τ) z(τ) −θt(t)φ(τ)
m2s(τ)
φ(τ)dτ,
θ(0) = θ0.
ii. Show that the adaptive law in part (a) can be implemented as
˙θ(t) = −Γ

R(T )θ(t) + Q(t)

,
θ(0) = θ0,
˙R(t) = −βR(t) + φ(t)φt(t)
m2s(t)
,
R(0) = 0,
˙Q(t) = −βQ(t) −z(t)φ(t)
m2s(t) ,
Q(0) = 0,
which is referred to as the integral adaptive law.
12. Consider the second-order stable system
˙x =
a11
a12
a21
0

x +
b1
b2

u,
where x, u are available for measurement, u ∈L∞and a11, a12, a21, b1, b2
are unknown parameters. Design an online estimator to estimate the unknown
parameters. Simulate your scheme using a11 = −0.25, a12 = 3, a21 = −5,
b1 = 1, b2 = 2.2, and u = 10sin2t. Repeat the simulation when u = 10sin2t +
7cos3.6t. Comment on your results.
13. Consider the nonlinear system
˙x = a1f1(x) + a2f2(x) + b1g1(x)u + b2g2(x)u,
where u,x ∈R; fi, gi are known nonlinear functions of x; and ai, bi are un-
known constant parameters and i = 1,2. The system is such that u ∈L∞im-
plies x ∈L∞. Assuming that x,u can be measured at each time t, design an
estimation scheme for estimating the unknown parameters online.
14. Design and analyze an online estimation scheme for estimating θ∗in (8.47)
when L(s) is chosen so that W(s)L(s) is biproper and SPR.
15. Design an online estimation scheme to estimate the coefﬁcients of the numera-
tor polynomial
Z(s) = bn−1sn−1 + bn−2sn−2 + ··· + b1s + b0
of the plant
y = Z(s)
R(s)u
when the coefﬁcients of R(s) = sn + an−1sn−1 + ··· + a1s + a0 are known.
Repeat the same problem when Z(s) is known and R(s) is unknown.

8.15
Questions
515
Fig. 8.10 The
mass-spring-damper system
for Problem 17
Fig. 8.11 The
mass-spring-damper system
for Problem 16
16. Consider the mass-spring-damper system shown in Fig. 8.10, where β is the
damping coefﬁcient, k is the spring constant, u is the external force, and y(t) is
the displacement of the mass m resulting from the force u.
i. Verify that the equations of motion that describe the dynamic behavior of
the system under small displacements are
m ¨y + β ˙y + ky = u.
ii. Design a gradient algorithm to estimate the constants m, β, k when y, u can
be measured at each time t.
iii. Repeat (b) for an LS algorithm.
iv. Simulate your algorithms in (b) and (c) assuming m = 20 kg, β = 0.1 kg/s,
k = 5 kg/s2, and inputs u of your choice.
v. Repeat (d) when m = 20 kg for 0 ≤t ≤20 s and m = 20(2−e−0.01(r−20)) kg
for t ≥20 s.
17. Consider the mass-spring-damper system shown in Fig. 8.11.
i. Verify that the equations of motion are given by
k(y1 −y2) = u,
k(y1 −y2) = m ¨y2 + β ˙y2.
ii. If y1, y2, u can be measured at each time t, design an online parameter
estimator to estimate the constants k, m, and β.
iii. We have the a priori knowledge that 0 ≤β ≤1, k ≥0.1, and m ≥10. Mod-
ify your estimator in (b) to take advantage of this a priori knowledge.
iv. Simulate your algorithm in (b) and (c) when β = 0.2 kg/s, m = 15 kg,
k = 2 kg/s2, and u = 5sin2t + 10.5 kg m/s2.
18. Consider the block diagram of a steer-by-wire system of an automobile shown
in Fig. 8.12, where r is the steering command in degrees, θp is the pinion angle
in degrees, and ˙θ is the yaw rate in degree/s. The transfer functions G0(s),
G1(s) are of the form
G0(s) =
k0ω2
0
s2 + 2ξ0ω0s + ω2
0(1 −k0),

516
8
Adaptive Control
Fig. 8.12 Block diagram of a
steer-by-wire system for
Problem 18
Table 8.2 The values of the
parameters at different speeds
Speed V
k0
ω0
ξ0
k1
ω1
ξ1
30 mph
0.81
19.75
0.31
0.064
14.0
0.365
60 mph
0.77
19.0
0.27
0.09
13.5
0.505
G1(s) =
k1ω2
1
s2 + 2ξ1ω1s + ω2
1
,
where k0, ω0, ξ0, k1, ω1, ξ1 are functions of the speed of the vehicle. Assuming
that r, θp, ˙θ can be measured at each time t, do the following:
i. Design an online parameter estimator to estimate ki, ωi, ξi, i = 0,1, using
the measurements of θp, ˙θ, r.
ii. Consider the values of the parameters shown in Table 8.2 at different speeds:
Assume that between speeds the parameters vary linearly. Use these values
to simulate and test your algorithm in (a) when
A. r = 10sin0.2t + 8 degrees and V = 20 mph.
B. r = 5 degrees and the vehicle speeds up from V = 30 mph to V =
60 mph in 40 seconds with constant acceleration and remains at 60 mph
for 10 seconds.
19. Consider the equation of the motion of the mass-spring-damper system given
in Problem 16, i.e.,
m ¨y + β ˙y + ky = u.
This system may be written in the form
y = ρ∗(u −m ¨y −β ˙y),
where ρ∗= 1
k appears in a bilinear form with the other unknown parameters m,
β. Use the adaptive law based on the bilinear parametric model to estimate ρ∗,
m, β when u, y are the only signals available for measurement. Since k > 0,
the sign of ρ∗may be assumed to be known. Simulate your adaptive law using
the numerical values given in (d) and (e) of Problem 8.
20. The effect of initial conditions on the SPM can be modeled as
z = θ∗tφ + η0,
˙ω = Λω0,
η0 = Ctω0,
where Λ is a transfer matrix with all poles in R[s] < 0 and ω0 ∈ℜn, η0 ∈R.
Show that the properties of an adaptive law (gradient, LS, etc.) with η0 = 0 are
the same as those for the SPM with η0 ̸= 0.

8.15
Questions
517
21. Consider the system
y = e−τs
b
(s −a)(μs + 1)u,
where 0 < τ ≪1, 0 < μ ≪1, and a, b, τ, μ are unknown constants. We want
to estimate a, b online.
i. Obtain a parametric model that can be used to design an adaptive law to
estimate a,b.
ii. Design a robust adaptive law of your choice to estimate a,b online.
iii. Simulate your scheme for a = −5, b = 100, τ = 0.0, μ = 0.001, and dif-
ferent choices of the input signal u. Comment on your results.
22. The dynamics of a hard-disk drive servo system are given by
y = kp
s2
6

i=1
b1is + b0i
s2 + 2ζiωis + ω2
i
u,
where ωi, i = 1,...,6, are the resonant frequencies which are large, i.e., ω1 =
11.2π × 103 rad/s, ω2 = 15.5π × 103 rad/s, ω3 = 16.6π × 103 rad/s, ω4 =
18π × 103 rad/s, ω5 = 20π × 103 rad/s, ω6 = 23.8π × 103 rad/s. The unknown
constants b1i are of the order of 104, b0i are of the order of 108, and kp is of the
order of 107. The damping coefﬁcients ζi are of the order of 10−2.
i. Derive a low-order model for the servo system. (Hint: Take
α
ωi ∼= 0 and
hence α2
ω2
i
∼= 0 for α of the order of less than 103.)
ii. Assume that the full-order system parameters are given as follows:
bl6 = −5.2 × 104,
b01 = 1.2 × 109,
b02 = 5.4 × 108,
b03 = −7.7 × 108,
b04 = −1.6 × 108,
b05 = −1.9 × 108,
b06 = 1.2 × 109,
kp = 3.4 × 107,
ζ1 = 2.6 × 10−2,
ζ2 = 4.4 × 10−3,
ζ3 = 1.2 × 10−2,
ζ4 = 2.4 × 10−3,
ζ5 = 6.8 × 10−3,
ζ6 = 1.5 × 10−2.
Obtain a Bode plot for the full-order and reduced-order models.
iii. Use the reduced-order model in (a) to obtain a parametric model for the
unknown parameters. Design a robust adaptive law to estimate the unknown
parameters online.
23. Consider the time-varying plant
˙x = −a(t)x + b(t)u,
where a(t), b(t) are slowly varying unknown parameters; i.e., |˙a|, |˙b| are very
small.
i. Obtain a parametric model for estimating a, b.
ii. Design and analyze a robust adaptive law that generates the estimates ˆa(t),
ˆb(t) of a(t), b(t), respectively.
iii. Simulate your scheme for a plant with a(t) = 5+sinμt, b(t) = 8+cos2μt
for μ = 0,0.01,0.1,1,5. Comment on your results.

518
8
Adaptive Control
24. Consider the parameter error differential equation (8.62), i.e.,
˙˜θ = −γ u2 ˜θ + γ du.
Show that if the equilibrium ˜θe = 0 of the homogeneous equation
˙˜θ = −γ u2 ˜θ
is exponentially stable, then the bounded input γ du will lead to a bounded
solution ˜θ(t). Obtain an upper bound for | ˜θ(t)| as a function of the upper bound
of the disturbance term γ du.
25. Consider the system
y = θ∗u + η
η = Δ(s)u,
where y, u are available for measurement, θ∗is the unknown constant to be
estimated, and η is a modeling error signal with Δ(s) being proper and analytic
in R[s] ≥−0.5.
The input u is piecewise continuous.
i. Design an adaptive law with a switching σ-modiﬁcation to estimate θ∗.
ii. Repeat (a) using projection.
iii. Simulate the adaptive laws in (a), (b) using the following values:
θ∗= 5 + sin0.1t,
Δ(s) = 10μ μs −1
(μs + 1)2
for μ = 0,0.1,0.01 and u = constant, u = sinω0t, where ω0 = 1,10,100.
Comment on your results.
26. The linearized dynamics of a throttle angle θ to vehicle speed V subsystem are
given by the third-order system
V =
bp1p2
(s + a)(s + p1)(s + p2)θ + d,
where p1, p2 > 20, 1 ≥a > 0, and d is a load disturbance.
(a) Obtain a parametric model for the parameters of the dominant part of the
system.
(b) Design a robust adaptive law for estimating these parameters online.
(c) Simulate your estimation scheme when a = 0.1, b = 1, p1 = 50, p2 = 100,
and d = 0.02sin5t, for different constant and time-varying throttle angle
settings θ of your choice.
27. Consider the parametric model
z = θ∗tφ + η,
where
η = Δu(s)u + Δy(s)y
and Δu, Δy are proper transfer functions analytic in R[s] ≥−δ0
2 for some
known δ0 > 0.

References
519
a) Design a normalizing signal ms that guarantees
η
ms ∈L∞when (i) Δu, Δy
are biproper, (ii) Δu, Δy are strictly proper. In each case specify the upper
bound for |η|
ms .
b) Calculate the bound for
η
ms when
i. Δu(s) = eτs−1
(s+1)2 , Δy(s) = μ
s2
(s+1)2 ,
ii. Δu(s) =
μs
μs+2, Δy(s) =
μs
μs+1, where 0 < μ ≪1 and 0 < τ ≪1.
c) Design and simulate a robust adaptive law to estimate θ∗for the following
example:
θ∗= [1,0.1]t,
φ = [u,y]t,
z =
s
s + 5y,
Δu(s) = e−τs −1
s + 2
,
Δy(s) = μ(s −1)
(μs + 1)2 ,
where τ = 0.01, μ = 0.01.
References
1. Anderson, B.O.D., Brinsmead, T., Liberson, D., Morse, A.S.: Multiple model adaptive control
with safe switching. Int. J. Adapt. Control Signal Process. 15, 445–470 (2001)
2. Astrom, K.J.: Theory and applications of adaptive control: A survey. Automatica 19, 471–486
(1983)
3. Astrom, K.J., Wittenmark, B.: Adaptive Control. Addison-Wesley, Reading (1989)
4. Fidan, B., Ioannou, P.A.: Adaptive Control Toolbox: User’s Guide. The Mathworks, Boston
(2005)
5. Fu, M., Barmish, B.R.: Adaptive stabilization of linear systems via switching control. IEEE
Trans. Autom. Control 31, 1097–1103 (1986)
6. Goodwin, G.C., Sin, K.S.: Adaptive Filtering Prediction and Control. Prentice-Hall, Engle-
wood Cliffs (1984)
7. Gupta, M.M. (ed.): Adaptive Methods for Control System Design. IEEE Press, Piscataway
(1986)
8. Ioannou, P.A., Fidan, B.: Adaptive Control Tutorial, SIAM’s Advances in Design and Control
(2006)
9. Ioannou, P.A., Sun, J.: Robust Adaptive Control. Prentice-Hall, Englewood Cliffs (1996); also
available online from http://www-rcf.usc.edu/~ioannou/Robust_Adaptive_Control.htm
10. Kanellakopoulos, I., Kokotovis, P.V., Morse, A.S.: Systematic design of adaptive controllers
for feedback linearizable systems. IEEE Trans. Autom. Control 36, 1241–1253 (1991)
11. Kreisselmier, G.: An indirect adaptive controller with a self-excitation capability. IEEE Trans.
Autom. Control 34, 524–528 (1989)
12. Landau, I.D.: Adaptive Control: The Model Reference Approach. Marcel Dekker, New York
(1979)
13. Miller, D.E., Davison, E.J.: An adaptive controller which provides an arbitrarily good transient
and steady-state response. IEEE Trans. Autom. Control 36, 68–81 (1991)
14. Narendra, K.S., Balakrishnan, J.: Improving transient response of adaptive control systems
using multiple models and switching. IEEE Trans. Autom. Control 39, 1861–1866 (1994)

520
8
Adaptive Control
15. Narendra, K.S., Balakrishnan, J.: Adaptation and learning using multiple models, switching,
and tuning. IEEE Control Syst. Mag. 15, 37–51 (1995)
16. Narendra, K.S., Balakrishnan, J.: Adaptive control using multiple models. IEEE Trans. Autom.
Control 42, 171–187 (1997)
17. Narendra, K.S., Monopoli, R.V. (eds.): Applications of Adaptive Control. Academic Press,
New York (1980)
18. Paul, A., Safonov, M.G.: Model reference adaptive control using multiple controllers and
switching. In: Proc. the 42nd IEEE Conference on Decision and Control, vol. 4, pp. 3256–
3261. IEEE Press, New York (2003)
19. Poularikas, A.D., Ramadan, Z.M.: Adaptive Filtering Primer with MATLAB. Taylor and Fran-
cis, New York (2006)
20. Stein, G.: Adaptive ﬂight control: A pragmatic view. In: Narendra, K.S., Monopoli, R.V. (eds.)
Applications of Adaptive Control. Academic Press, New York (1980)
21. Tsakalis, K.S., Ioannou, P.A.: A new indirect adaptive control scheme for time-varying plants.
IEEE Trans. Autom. Control 35, 697–705 (1990)
22. Tsakalis, K.S., Ioannou, P.A.: Linear Time Varying Systems: Control and Adaptation.
Prentice-Hall, Englewood Cliffs (1993)
23. Wang, R., Safonov, M.G.: Stability of unfalsiﬁed adaptive control using multiple controllers.
In: Proc. the American Control Conference, pp. 3162–3167 (2005)

Chapter 9
Appendix
9.1 Important Facts in Linear Algebra
We assume that the reader already has basic training in linear algebra and for a more
complete introduction, the reader should resort to a book such as Strang [6]. Some
familiarity with the numerical software MATLAB is also encouraged. In this book,
we deal mostly with ﬁnite-dimensional linear spaces, which are also often called lin-
ear vector spaces. For generality, we consider the linear space to be n-dimensional.
A linear space is typically denoted by the letter V (for “vector space”). Although
most of the time we will deal with vectors of real numbers ℜ, occasionally, we will
encounter vectors of complex numbers C. As a reminder, for instance, the eigen-
values or eigenvectors of a real matrix could be complex. For simplicity, our review
will be conducted for linear spaces over the ﬁeld of real numbers ℜwith the under-
standing that most deﬁnitions and results generalize to the complex case with little
change.
9.1.1 Basic Notions
Deﬁnition 9.1 (A linear space or a vector space) A set (of vectors) V is considered
a linear space over the ﬁeld ℜif its elements, called vectors, are closed under two
basic operations: scalar multiplication and vector summation “+”. That is, given
any two vectors v1,v2 ∈V and any two scalars α,β ∈ℜ, the linear combination
v = αv1 + βv2 is also a vector in V . Furthermore, the addition is commutative and
associative, it has an identity 0, and each element has an inverse, “−v”, such that
v +(−v) = 0. The scalar multiplication respects the structure of ℜ, that is, α(β)v =
(αβ)v, 1v = v and 0v = 0. The addition and scalar multiplication are related by the
distributive laws: (α + β)v = αv + βv and α(v + u) = αv + αu.
For example, ℜn is a linear space over the ﬁeld of real numbers ℜ. To be consis-
tent, we always use a column to represent a vector:
M.S. Mahmoud, Y. Xia, Applied Control Systems Design,
DOI 10.1007/978-1-4471-2879-3_9, © Springer-Verlag London Limited 2012
521

522
9
Appendix
x1
x2
···
xn
t =
⎡
⎢⎢⎢⎣
x1
x2
...
xn
⎤
⎥⎥⎥⎦∈ℜn
(9.1)
where [x1 x2 ··· xn ]t means “the (row) vector [x1 x2 ··· xn ] transposed.”
Given two scalars α,β ∈ℜand two vectors x = [x1 x2 ··· xn ]t ∈ℜn and
y = [y1 y2 ··· yn ]t ∈ℜn, their linear combination is a componentwise summa-
tion weighted by α and β:
αx + βy = α
x1
x2
···
xn
t + β
y1
y2
···
yn
t
=
αx1 + βy1
αx2 + βy2
···
αxn + βyn
t .
(9.2)
We will now provide a brief review of basic notions and frequently used notation
associated with a linear vector space V (that is, ℜn).
Deﬁnition 9.2 (Subspace) A subset W of a linear space is called a subspace if the
zero vector 0 is in W and w = αw1 + βw2 ∈W for all α,β ∈ℜand w1,w2 ∈W.
Deﬁnition 9.3 (Spanned subspace) Given a set of vectors S = {νi}m
i=1, the sub-
space spanned by S is the set of all ﬁnite linear combinations 
m
i=1 αiνi for all
[α1 α2 ··· αn ]t. This subspace is usually denoted by Span(S).
For example, the two vectors v1 = [1 0 0]t and v2 = [1 1 0]t span a subspace
of ℜ3 whose vectors are of the general form v = [x y 0]t.
Deﬁnition 9.4 (Linear independence) A set of vectors S = {νi}m
i=1 is linearly inde-
pendent if
[α1ν1 + α2ν2 + ··· + αmνm] = 0
implies
α1 = α2 = ··· = αm = 0.
On the other hand, a set of vectors {νi}m
i=1 is said to be linearly dependent if there
exist [α1 α2 ··· αn ] ∈ℜnot all zero such that
[α1ν1 + α2ν2 + ··· + αmνm] = 0.
Deﬁnition 9.5 (Basis) A set of vectors B = {bi}n
i=1 of a linear space V is said to
be a basis if B is a linearly independent set and B spans the entire space V ; that is,
V = span(B).
Properties of a basis: Suppose B and B′ are two bases for a linear space V .
Then:
1. B and B′ contain exactly the same number of linearly independent vectors. This
number, say n, is the dimension of the linear space V .

9.1
Important Facts in Linear Algebra
523
2. Let B = {bi}n
i=1 and B′ = {b′
i}n
i=1. Then each basis vector of B can be expressed
as a linear combination of those in B′; that is,
bj = a1jb′
1 + a2jb′
2 + ··· + anjb′
n =
n

i=1
aijb′
i,
(9.3)
for some aij ∈R,i,j = 1,2,...,n.
3. Any vector v ∈V can be written as a linear combination of vectors in either of
the bases:
v = x1b1 + x2b2 + ··· + xnbn = xnbn = x′
1b′
1 + x′
2b′
2 + ··· + x′
nb′
n,
(9.4)
where the coefﬁcients {xi ∈R}n
i=1 and {x′
i ∈R}n
i=1 are uniquely determined and
are called the coordinates of v with respect to each basis.
In particular, if B and B′ are two bases for the linear space Rn, we may put the basis
vectors as columns of two n × n matrices and also call them B and B′, respectively:
B .= [b1,b2,...,bn],
B′ .=

b′
1,b′
2,...,b′
n

∈Rn×n.
(9.5)
Then we can express the relationship between them in the matrix form B = B′A as
[b1,b2,...,bn] =

b′
1,b′
2,...,b′
n

⎡
⎢⎢⎢⎣
a11
a12
···
a1n
a21
a22
···
a2n
...
...
...
...
an1
an2
···
ann
⎤
⎥⎥⎥⎦.
(9.6)
The role of the n × n matrix is to transform one basis (B′) to the other (B). Since
such a transformation can go the opposite way, the matrix A must be invertible. So
we can also write B′ = BA−1.
If v is a vector in V , it can be expressed in terms of linear combinations of either
basis as
v = x1b1 + x2b2 + ··· + xnbn = xt
1bt
1 + xt
2bt
2 + ··· + xt
nbt
n.
(9.7)
Thus, we have
v = [b1,b2,...,bn]
⎡
⎢⎢⎢⎣
x1
x2
...
xn
⎤
⎥⎥⎥⎦=

bt
1,bt
2,...,bt
n

⎡
⎢⎢⎢⎣
a11
a12
···
a1n
a21
a22
···
a2n
...
...
...
...
an1
an2
···
ann
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
x1
x2
...
xn
⎤
⎥⎥⎥⎦.
Since the coordinates of v with respect to Bt are unique, we obtain the following
transformation of coordinates of a vector from one basis to the other:
⎡
⎢⎢⎢⎣
xt
1
xt
2...
xt
n
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
a11
a12
···
a1n
a21
a22
···
a2n
...
...
...
...
an1
an2
···
ann
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
x1
x2
...
xn
⎤
⎥⎥⎥⎦.
(9.8)

524
9
Appendix
Let x = [x1,x2,...,xn]t ∈Rn and xt = [xt
1,xt
2,...,xt
n]t ∈Rn denote the two co-
ordinate vectors. We may summarize in matrix form the relationships between two
bases and coordinates with respect to the bases as
Bt = BA−1,
xt = Ax.
(9.9)
Be aware of the difference in transforming bases from transforming coordinates!
9.1.2 Inner Product and Orthogonality
Deﬁnition 9.6 (Inner product) A function is an inner product1 if
1. ⟨u,αv + βw⟩= α⟨u,v⟩+ β⟨u,w⟩, Rn × Rn →R,
2. ⟨u,v⟩= ⟨v,u⟩,
3. ⟨v,v⟩≥0, and ⟨v,v⟩= 0 ⇔v = 0.
For each vector v,√⟨v,v⟩is called its norm.
The inner product is also called a metric, since it can be used to measure length
and angles.
For simplicity, a standard basis is often chosen for the vector space Rn as the set
of vectors
e1 = [1,0,0,...,0]t,
e2 = [0,1,0,...,0]t,
en = [0,0,0,...,0,1]t.
(9.10)
The matrix I = [e1,e2,...,en] with these vectors as columns is exactly the n × n
identity matrix.
Deﬁnition 9.7 (Canonical inner product on Rn) Given any two vectors x =
[x1,x2,...,xn]t and y = [y1,y2,...,yn]t in Rn, we deﬁne the canonical inner prod-
uct to be
⟨x,y⟩.= xty = x1y1 + x2y2 + ··· + xnyn.
(9.11)
This inner product induces the standard 2-norm, or Euclidean norm, ∥· ∥2, which
measures the length of each vector as
∥x∥2
.=
√
xtx =

x2
1 + x2
2 + ··· + x2n.
(9.12)
Notice that if we choose another basis Bt related to the above standard basis I
as I = BtA, then the coordinates of the vectors x,y related to the new basis are
xt and yt, respectively, and they relate to x,y by xt = Ax and yt = Ay. The inner
product in terms of the new coordinates becomes
⟨x,y⟩= xty =

A−1xtt
A−1yt
=

xt
A−tA−1
yt
.
(9.13)
1In some literature, an inner product is also called a dot product, denoted by u · v. However, in this
book, we will not use that name.

9.1
Important Facts in Linear Algebra
525
We denote this expression of the inner product with respect to the new basis by

xt,yt
A−tA−1
.=

xttA−tA−1
yt
.
(9.14)
This is called an induced inner product from the matrix A. Knowing the matrix
A−tA−1, we can compute the canonical inner product directly using coordinates
with respect to the nonstandard basis Bt.
Deﬁnition 9.8 (Orthogonality) Two vectors x,y are said to be orthogonal if their
inner product is zero: ⟨x,y⟩= 0. This is often indicated as x ⊥y.
9.1.3 Kronecker Product and Stack of Matrices
Deﬁnition 9.9 (Kronecker product of two matrices) Given two matrices A ∈Rm×n
and B ∈Rk×l, their Kronecker product, denoted by A ⊗B, is a new matrix
A ⊗B .=
⎡
⎢⎢⎢⎣
a11B
a12B
···
a1nB
a21B
a22B
···
a2nB
...
...
...
...
an1B
an2B
···
amnB
⎤
⎥⎥⎥⎦∈Rmk×nl.
(9.15)
If A and B are two vectors, that is, n = l = 1, the product A ⊗B is also a vector but
of dimension mk.
In MATLAB, one can easily compute the Kronecker product by using the com-
mand C = kron(A,B).
Deﬁnition 9.10 (Stack of a matrix) Given an m × n matrix A ∈Rm×n the stack of
the matrix A is a vector, denoted by As, in Rmn obtained by stacking its n column
vectors, say a1,a2,...,an ∈Rm, in order
As .=
⎡
⎢⎢⎢⎣
a1
a2
...
an
⎤
⎥⎥⎥⎦∈Rmn.
(9.16)
As mutually inverse operations, As is called A “stacked,” and A is called As “un-
stacked.”
The Kronecker product and stack of matrices together allow us to rewrite al-
gebraic equations that involve multiple vectors and matrices in many different but
equivalent ways. For instance, the equation
utAv = 0
(9.17)
for two vectors u, v and a matrix A of proper dimensions can be rewritten as
(v ⊗u)tAs = 0.
(9.18)
The second equation is particularly useful when A is the only unknown in the equa-
tion.

526
9
Appendix
9.2 Linear Transformations and Matrix Groups
Linear algebra studies the properties of the linear transformations, or linear maps,
between different linear spaces. Since such transformations can be represented as
matrices, linear algebra to a large extent studies the properties of matrices.
Deﬁnition 9.11 (Linear transformation) A linear transformation from a linear (vec-
tor) space Rn to Rm is deﬁned as a map L : Rn →Rm such that
• L(x + y) = L(x) + L(y), ∀x,y ∈Rn;
• L(αx) = αL(x), ∀x ∈Rn, α ∈R.
With respect to the standard bases of Rn and Rm, the map L can be represented by
a matrix A ∈Rm×n such that
L(x) = Ax,
∀x ∈ℜn.
(9.19)
The ith column of the matrix A is then nothing but the image of the standard
basis vector ei ∈ℜn under the map L; that is,
A =

L(e1),L(e2),...,L(en)

∈ℜm×n.
The set of all (real) m×n matrices is denoted by M(m,n). When viewed as a linear
space, M(m,n) can be identiﬁed as the space ℜmn. When there is little ambigu-
ity, we refer to a linear map L by its matrix representation A. If n = m, the set
M(n,n) .= M(n) forms an algebraic structure called a ring (over the ﬁeld R). That
is, matrices in M(n) are closed under both matrix multiplication and summation: If
A,B are two n × n matrices, so are C = AB and D = A + B.
Linear maps or matrices that we encounter in computer vision often have a spe-
cial algebraic structure called a group.
Deﬁnition 9.12 A group is a set G with an operation “◦” on the elements of G that:
• is closed: if g1,g2 ∈G, then also g1 ◦g2 ∈G;
• is associative: (g1 ◦g2) ◦g3 = g1 ◦(g2 ◦g3), for all g1,g2,g3 ∈G;
• has a unit element e : e ◦g = g ◦e = g, for all g ∈G;
• is invertible: For every element g ∈G, there exists an element g−1 ∈G such that
g ◦g−1 = g−1 = g−1 ◦g = e.
Deﬁnition 9.13 (The general linear group GL(n)) The set of all n × n nonsingular
(real) matrices with matrix multiplication forms a group. Such a group of matrices
is usually called the general linear group and denoted by GL(n).
Deﬁnition 9.14 (Matrix representation of a group) A group G has a matrix repre-
sentation or can be realized as a matrix group if there exists an injective map
R : G →GL(n);
g →R(g).
Note that a map f (·) is called injective if f (x) ̸= f (y) as long as x ̸= y, which
preserves the group structure of G. That is, the inverse and composition of elements

9.2
Linear Transformations and Matrix Groups
527
in G are preserved by the map in the following way: Such a map is called a group
homomorphism in algebra.
R(e) = In×n,
R(g ◦h) = R(g)R(h),
∀g,h ∈G.
(9.20)
Below, we identify a few important subsets of M(n) that have special algebraic
structures (as examples of matrix groups) and nice properties.
The group GL(n) itself can be identiﬁed as the set of all invertible linear trans-
formations from ℜn to ℜn in the sense that for every A ∈GL(n), we obtain a linear
map
L : ℜn →ℜn;
x →Ax.
(9.21)
Notice that if A ∈GL(n), then so is its inverse: A−1 ∈GL(n). We know that an
matrix is invertible if and only if its determinant is nonzero. Therefore, we have
det(A) ̸= 0,
∀A ∈GL(n).
(9.22)
The general linear group, when matrices are considered to be known only up to a
scalar factor, GL(n)/R, is referred to as the projective transformation group, whose
elements are called projective matrices or homographies.
Matrices in GL(n) of determinant +1 forming subgroup called the special linear
group, denoted by SL(n). That is, det(A) = +1 for all A ∈SL(n). It is easy to verify
that if A ∈SL(n), then so is A−1, since detA−1 = detA−1.
Deﬁnition 9.15 (The afﬁne group A(n)) An afﬁne transformation L from ℜn to ℜn
is deﬁned jointly by a matrix A ∈GL(n) and a vector b ∈ℜn such that
L : ℜn →ℜn;
x →Ax + b.
(9.23)
The set of all such afﬁne transformations is called the afﬁne group of dimension and
is denoted by A(n).
Notice that the map L so-deﬁned is not a linear map from ℜn to ℜn unless b = 0.
Nevertheless, we may “embed” this map into a space one dimension higher so that
we can still represent it by a single matrix. If we identify an element a ∈ℜn with
 x
1

∈ℜn+1, then L becomes a map from ℜn+1 to ℜn+1 in the following sense:
Observe that this is the so-called homogeneous representation of x. Notice that
this identiﬁcation does not preserve the vector structure of ℜn.
L : ℜn+1 →ℜn+1;
x
1

→
A
b
0
1
x
1

.
(9.24)
Thus, a matrix of the form
A
b
0
1

∈ℜ(n+1×n+1),
A ∈GL(n), b ∈ℜn,
(9.25)
fully describes an afﬁne map, and we call it an afﬁne matrix. This matrix is an
element in the general linear group GL(n + 1). In this way, A(n) is identiﬁed as

528
9
Appendix
a subset (and in fact a subgroup) of GL(n + 1). The multiplication of two afﬁne
matrices in the set A(n) is
A1
b1
0
1
A2
b2
0
1

=
A1A2
A1b2 + b1
0
1

∈ℜ(n+1×n+1),
(9.26)
which is also an afﬁne matrix in A(n) and represents the composition of two afﬁne
transformations.
Given ℜn and its standard inner product structure, ⟨x,y⟩= xty, ∀x,y ∈ℜn, let
us consider the set of linear transformations (or matrices) that preserve the inner
product.
Deﬁnition 9.16 (The orthogonal group O(n)) An n × n matrix A (representing a
linear map from ℜn to itself) is called orthogonal if it preserves the inner product,
that is,
⟨Ax,Ay⟩= ⟨x,y⟩,
∀x,y ∈ℜn.
(9.27)
The set of all n × n orthogonal matrices forms the orthogonal group of dimension,
and it is denoted by O(n).
Obviously, O(n) is a subset (and in fact a subgroup) of GL(n). If R is an orthog-
onal matrix, we must have ℜtR = Rℜt = I. Therefore, the orthogonal group O(n)
can be characterized as
O(n) =

R ∈GL(n)|ℜtR = I

.
(9.28)
The determinant det(R) of an orthogonal matrix R can be either +1 or −1. The
subgroup of O(n) with determinant +1 is called the special orthogonal group and is
denoted by SO(n). That is, for any R ∈SO(n), we have det(R) = +1. Equivalently,
one may deﬁne SO(n) as the intersection SO(n) = O(n) ∩SL(n). In the case n = 3,
the special orthogonal matrices are exactly the 3 × 3 rotation matrices.
The afﬁne version of the orthogonal group gives the Euclidean (transformation)
group.
Deﬁnition 9.17 (The Euclidean group E(n)) A Euclidean transformation L from
ℜn to ℜn is deﬁned jointly by a matrix R ∈O(n) and a vector T ∈ℜn such that
L : ℜn →ℜn;
x →Rx + T.
(9.29)
The set of all such transformations is called the Euclidean group of dimension and
is denoted by E(n).
Obviously, E(n) is a subgroup of A(n). Therefore, it can also be embedded into
a space one-dimension higher and has a matrix representation
R
T
0
1

∈ℜ(n+1×n+1),
R ∈O(n), T ∈ℜn.
(9.30)
If R further belongs to SO(n), such transformations form the special Euclidean
group, which is traditionally denoted by SE(n). When n = 3, SE(3), represents the
conventional rigid-body motion in ℜ3, where R is the rotation of a rigid body and
T is the translation (with respect to a chosen reference coordinate frame).

9.3
Matrix Algebra
529
Since all the transformation groups introduced so far have natural matrix repre-
sentations, they are matrix groups. To summarize their relationships, we have
SO(n) ⊂O(n) ⊂GL(n),
SE(n) ⊂A(n) ⊂GL(n + 1).
(9.31)
Since these groups themselves admit a differential structure, they belong to the
Lie groups.
9.3 Matrix Algebra
In what follows, we let A ∈Cn×n and denote its conjugate transpose ¯At := A∗. Sup-
pose A has p distinct eigenvalues, λ1,...,λp, with the ith one being of multiplicity
mi. The sep of all eigenvalues of A is called spectrum, denoted by σ(A). Let the
characteristic polynomial of A be
ΔA(λ) := det(λI −A) = λn + cn−1λn−1 + ··· + c0.
(9.32)
Then we have the following:
1. det(A) = (−1)nc0 = p
i=1 λmi
i . Furthermore,
det(A) = det

At
,
det(AB) = det(A)det(B),
∀A,B ∈Cn×n.
2. Trace(A) = 
p
i=1 aii = 
p
i=1 miλi = (−1)n−1cn−1. Moreover,
Trace(A + B) = Trace(A) + Trace(B).
3. If λ is an eigenvalue of A, its complex conjugate ¯λ is an eigenvalue of A∗.
4. If A is real, so are ci’s. Therefore, if λ is an eigenvalue, so is ¯λ.
5. If A is both real and symmetric, σ(A) is real.
6. In general, A is called Hermitian if A = A∗. For real matrix, this is synonymous
to being symmetric. For a Hermitian matrix A, σ(A) is real, and it admits a com-
plete set of n orthogonal eigenvectors (even if the eigenvalues are not distinct).
Denote the normalized versions of these eigenvectors by x1,...,xn where xi
corresponds to the eigenvalue λi where we allow the possibility for λi = λj for
i ̸= j. Then we can rewrite A as:
A =
n

i=1
λixix∗
i ,
which is known as the spectral representation of A.
7. If A is not Hermitian, but semisimple (that is, has a set of n linearly independent
eigenvectors xi’s), it still admits a spectral representation, this time of the form
A =
n

i=1
λixiy∗
i ,
where y∗
i is the ith row of M−1, with M = [x1,...,xn]. This is known as the
eigenvector dyadic expansion of A.

530
9
Appendix
8. If a Hermitian matrix A has only positive (respectively, nonnegative) eigenval-
ues, it is called a positive deﬁnite (respectively, nonnegative deﬁnite) matrix, and
this property is symbolically displayed as A > 0 (respectively, A ≥0). A is said
to be negative deﬁnite (respectively, nonpositive deﬁnite) if −A > 0 (respec-
tively, −A ≥0). A positive deﬁnite matrix A has the property that x∗Ax > 0
for all x ∈Cn which is not zero.
9.3.1 Inverse of Block Matrices
Let A be a square matrix of appropriate dimension and partitioned in the form
A =
A1
A2
A3
A4

(9.33)
where both A1 and A4 are square matrices. If A1 is invertible, then
Δ1 = A4 −A3A−1
1 A2
is called the Schur complement of A1. Alternatively, if A4 is invertible, then
Δ4 = A1 −A2A−1
4 A3
is called the Schur complement of A4.
It is well-known that matrix A is invertible if and only if either
A1
and
Δ1
are invertible,
or
A4
and
Δ4
are invertible.
Speciﬁcally, we have the following equivalent expressions
A1
A2
A3
A4
−1
=

Υ1
−A−1
1 A2Δ−1
1
−Δ−1
1 A3A−1
1
Δ−1
1

(9.34)
or
A1
A2
A3
A4
−1
=

Δ−1
4
−Δ−1
4 A2A−1
4
−A−1
4 A3Δ−1
4
Υ4

(9.35)
where
Υ1 = A−1
1
+ A−1
1 A2Δ−1
1 A3A−1
1 ,
(9.36)
Υ4 = A−1
4
+ A−1
4 A3Δ−1
4 A2A−1
4 .
Important special cases are
A1
0
A3
A4
−1
=

A−1
1
0
−A−1
4 A3A−1
1
A−1
4

(9.37)
and
A1
A2
0
A4
−1
=
A−1
1
−A−1
1 A2A−1
4
0
A−1
4

.
(9.38)

9.4
Range, Kernel, Rank and Eigenvectors of a Matrix
531
9.3.2 Matrix Inversion Lemma
Let A ∈Rn×n and C ∈Rm×m be nonsingular matrices. By using the deﬁnition of
matrix inverse, it can be easily veriﬁed that
[A + BCD]−1 = A−1 −A−1B

DA−1B + C−1−1DA−1.
(9.39)
9.4 Range, Kernel, Rank and Eigenvectors of a Matrix
Let A be a general m× n matrix that also conveniently represents a linear map from
the vector space ℜn to ℜn.
Deﬁnition 9.18 (Range, span, null space, and kernel) Deﬁne the range or span of A,
denoted by range(A) or span(A), to be the subspace of ℜm such that y ∈range(A)
if and only if y = Ax for some x ∈ℜn. Deﬁne the null space of A, denoted by
null(A), to be the subspace of ℜn such that x ∈null(A) if and only if Ax = 0. When
A is viewed as an abstract linear map, null(A) is also referred to as the kernel of the
map, denoted by ker(A).
Notice that the range of a matrix A is exactly the span of all its column vectors;
the null space of a matrix A is exactly the set of vectors which are orthogonal to
all its row vectors (for a deﬁnition of orthogonal vectors see Deﬁnition 9.8). The
notion of range or null space is useful whenever the solution to a linear equation of
the form Ax = b is considered. In terms of range and null space, this equation will
have a solution if b ∈range(A) and will have a unique solution only if null(A) = ∅
(the empty set).
In MATLAB, the null space of a matrix can be computed using the command
>>
Z = null(A).
Deﬁnition 9.19 (Rank of a matrix)
The rank of a matrix is the dimension of its
range:
rank(A) .= dim

range(A)

.
(9.40)
Properties of matrix rank: For an arbitrary m × n matrix A, its rank has the
following properties:
• rank(A) = n −dim(null(A)).
• 0 ≤rank(A) ≤min{m,n}.
• rank(A) is equal to the maximum number of linearly independent column (or
row) vectors of A.
• rank(A) is the highest order of a nonzero minor of A.
• Sylvester’s inequality: Let B be an n×k matrix. Then AB is an m×k matrix and
rank(A) + rank(B) −n ≤rank(AB) ≤min

rank(A),rank(B)

.
(9.41)

532
9
Appendix
• For any nonsingular matrices C ∈ℜm×m and D ∈ℜn×n, we have
rank(A) = rank(CAD).
(9.42)
In MATLAB, the rank of a matrix A is just
>>
rank(A).
It should be noted that a minor of order k is the determinant of a k × k submatrix
of A.
Deﬁnition 9.20 (Orthogonal complement to a subspace) Given a subspace S of ℜn,
we deﬁne its orthogonal complement to be the subspace S⊥⊆ℜn such that x ∈S⊥
if and only if xty = 0 for all y ∈S. We write ℜn = S ⊕S⊥.
The notion of orthogonal complement is used in this book to deﬁne the “coim-
age” of an image of a point or a line. Also, with respect to any linear map A from
ℜn to ℜm, the space ℜn can be decomposed as a direct sum of two subspaces,
ℜn = null(A) ⊕null(A)⊥,
and ℜm can be decomposed similarly as
ℜm = range(A) ⊕range(A)⊥.
We also have the following not so obvious relationships.
Theorem 9.21 Let be a linear map from ℜn to ℜm. Then:
(a) null(A)⊥= range(At),
(b) range(A)⊥= null(At),
(c) null(At) = null(AAt),
(d) range(A) = range(AAt),
Proof To prove part c: null(AAt) = null(At), we have
• AAtx = 0 ⇒⟨x,AAtx⟩= ∥Atx∥2 = 0 ⇒Atx = 0, hence null(AAt) ⊆null(At).
• Atx = 0 ⇒AAtx = 0; hence null(AAt) ⊇null(At).
To prove part (d), range(AAt) = range(A), we ﬁrst need to prove that ℜn is a direct
sum of range(At) and null(A), that is, part (a) of the theorem. Part (b) can then be
proved similarly. We prove this by showing that a vector x is in null(A) if and only
if it is orthogonal to range(At) : x ∈null(A) ⇔⟨Ax,y⟩= 0, ∀y ⇔⟨x,Aty⟩= 0,
∀y. Hence, null(A) is exactly the subspace that is the orthogonal complement to
range(At) (denoted by range(At)⊥). Therefore, ℜn is a direct sum of range(At)
and null(A). Now to complete our proof of part (d), let ImgA(S) denote the im-
age of a subspace S under the map A. Then we have range(A) = ImgA(ℜn) =
ImgA(range(At)) = range(AAt) (in the second equality we used the fact that ℜn
is a direct sum of range(At) and null(A)). These relations are depicted by Fig. 9.1.
In fact, the same result holds even if the domain of the linear map is replaced by
an inﬁnite-dimensional linear space with an inner product (i.e., ℜn is replaced by

9.4
Range, Kernel, Rank and Eigenvectors of a Matrix
533
Fig. 9.1 The orthogonal
decomposition of the domain
and codomain of a linear
map A
a Hilbert space). In that case, this theorem is also known as the ﬁnite-rank operator
fundamental lemma [5]. We will later use this result to prove the singular value
decomposition. But already it implies a result that is extremely useful in the study
of multiple-view geometry.
□
Lemma 9.22 (Rank reduction lemma) Let A ∈ℜn×n be a matrix and let W be a
matrix of the form
W =
 M
0
AB
AAt

∈ℜ(m+n)×(k+n)
(9.43)
for some matrices M ∈ℜm×k and B ∈ℜn×k. Then, regardless of what B is, we
always have
rank(M) = rank(W) −rank(A).
(9.44)
The proof is easy using the fact range(AB) ⊆range(A) = range(AAt) with the
second identity from the previous theorem, and we leave the rest of the proof to the
reader as an exercise.
A linear map from ℜn to itself is represented by a square n × n matrix A. For
such a map, we sometimes are interested in subspaces of ℜn that are “invariant”
under the map.This notion turns out to be closely related to the eigenvectors of the
matrix A. More rigorously speaking, a subspace S ⊂ℜn is invariant if A(S) ⊆S.
Deﬁnition 9.23 (Eigenvalues and eigenvectors of a matrix) Let A be an n × n com-
plex matrix in Cn×n. A nonzero vector v ∈Cn is said to be its (right) eigenvector
if
Av = λv
(9.45)
for some scalar λ ∈C; λ is called an eigenvalue of A. Similarly, a nonzero row
vector ηt ∈Cn is called a left eigenvector of A if ηtA = ληt for some λ ∈C.
Although A will mostly be a real matrix in this book, to talk about its eigenvec-
tors, it is more convenient to think of it as a complex matrix (with all entries that
happen to be real).

534
9
Appendix
Unless otherwise stated, an eigenvector by default means a right eigenvector.
The set of all eigenvalues of a matrix A is called its spectrum, denoted by σ(A).
The MATLAB command
[V,D] = eig(A)
produces a diagonal matrix D of eigenvalues and a full-rank matrix V whose
columns are the corresponding eigenvectors, so that AV = V D.
We give the following facts about eigenvalues and eigenvectors of a matrix with-
out a proof.
Properties of eigenvalues and eigenvectors: Given a matrix A ∈ℜn×n, we have:
1. If Av = λv, then for the same eigenvalue λ, there also exists a left eigenvector ηt
such that ηtA = ληt and vice versa. Hence, σ(A) = σ(At).
2. The eigenvectors of A associated with different eigenvalues are linearly indepen-
dent.
3. All its eigenvalues σ(A) are the roots of the (characteristic) polynomial equation
det(λI −A) = 0. Hence, det(A) is equal to the product of all eigenvalues of A.
4. If B = PAP −1 for some nonsingular matrix P , then σ(B) = σ(A).
5. If A is a real matrix, then λ ∈C is an eigenvalue implies that its conjugate λ is
also an eigenvalue. Simply put, σ(A) = ¯σ(A) for real matrices.
9.5 Symmetric and Skew-Symmetric Matrices
Deﬁnition 9.24 (Symmetric matrix) A matrix S ∈ℜn×n is called symmetric if
St = S. A symmetric matrix S is called positive (semi-)deﬁnite, if xtSx > 0 (or
xtSx ≥0) for all x ∈ℜn, denoted by S > 0 (or S ≥0).
Properties of symmetric matrices: If S is a real symmetric matrix, then:
1. All eigenvalues of S must be real, that is, σ(S) ⊂R.
2. Let (λ,v) be an eigenvalue-eigenvector pair. If λi ̸= λj, then vi ⊥vj; that is,
eigenvectors corresponding to distinct eigenvalues are orthogonal.
3. There always exist n orthonormal eigenvectors of S, which form a basis for ℜn.
4. S > 0 (S ≥0) if λi > 0 (λi ≥0) ∀i = 1,2,...,n; i.e. S is positive (semi-)deﬁnite
if all eigenvalues are positive (nonnegative).
5. S ≥0 and λ1 ≥λ2 ≥··· ≥λn; then max∥x∥2=1⟨x,Sx⟩= λ1 and min∥x∥2=1⟨x,
Sx⟩= λn.
From point 3, we see that if V = [v1,v2,...,vn] ∈ℜn×n is the matrix of all the
eigenvectors, and λ = diag{λ1,λ2,...,λn} is the diagonal matrix of the correspond-
ing eigenvalues, then we can write
S = V ΛV t,
where V is an orthogonal matrix. In fact, V can be further chosen to be in
SO(n) (that is, of determinant +1) if n is odd, since V ΛV t = (−V )Λ(−V )t and
det(−V ) = (−1)n det(V ).

9.5
Symmetric and Skew-Symmetric Matrices
535
Deﬁnition 9.25 (Induced 2-norm of a matrix) Let A ∈ℜm×n. We deﬁne the induced
2-norm of A (as a linear map from ℜn to ℜm) as
∥A∥2
.= max
∥x∥2=1∥A∥2 = max
∥x∥2=1

x,AtAx

.
Similarly, other induced operator norms on A can be deﬁned starting from dif-
ferent norms on the domain and codomain spaces on which A operates.
Let A be as above. Then AtA ∈ℜn×n is clearly symmetric and positive semidef-
inite, so it can be diagonalized by a orthogonal matrix V . The eigenvalues, being
nonnegative, can be written as σ 2
i . By ordering the columns of V so that the eigen-
value matrix Λ has decreasing eigenvalues on the diagonal, we see, from point 5 of
the preceding fact, that AtA = V diag{σ 2
1 ,σ 2
2 ,...,σ 2
n}V t and
∥A∥2 = σ1.
The induced 2-norm of a matrix A ∈ℜm×n is different from the “2-norm” of A
viewed as a vector in ℜmn. To distinguish them, the latter one is conventionally
called the Frobenius norm of A, precisely deﬁned as ∥A∥f =

i,j a2
ij. Notice
that 
i,j a2
ij is nothing but the trace of AtA (or AAt). Thus, we have
∥A∥f =

trace

AtA

=

σ 2
1 ,σ 2
2 ,...,σ 2n.
The inverse problem of retrieving from the symmetric matrix S = AtA is usu-
ally solved by Cholesky factorization. For the given S, its eigenvalues must be
nonnegative. Thus, we have S = V ΛV t = AtA for A = Λ( 1
2 )V t, where Λ( 1
2 ) =
diag{σ1,σ2,...,σn} is the “square root” of the diagonal matrix λ. Since ℜtR = I
for any orthogonal matrix, the solution for A is not unique: RA is also a solu-
tion. Cholesky factorization then restricts the solution to be an upper triangular ma-
trix (exactly what we need for camera calibration in Chap. 6). In MATLAB, the
Cholesky factorization is given by the command A = chol(S).
Deﬁnition 9.26 (Skew-symmetric matrix)
A matrix A ∈ℜn×n is called skew-
symmetric (or antisymmetric) if At = −A.
Properties of a skew-symmetric matrix: If A is a real skew-symmetric matrix,
then:
1. All eigenvalues of A are either zero or purely imaginary, that is, of the form iω
for i =
√
−1 and some ω ∈R.
2. There exists an orthogonal matrix V such that
A = V ΛV t,
(9.46)
where Λ is a block-diagonal matrix Λ = diag{Ai,...,Am,0,...,0}, where each
Ai is a 2 × 2 real skew-symmetric matrix of the form
Ai =
 0
ai
−ai
0

∈ℜ2×2,
i = 1,2,...,m.
(9.47)

536
9
Appendix
From point 2, we conclude that the rank of any skew-symmetric matrix must be
even. A commonly used skew-symmetric matrix in computer vision is associated
with a vector u ∈ℜ3, denoted by
ˆu =
⎡
⎣
0
−u3
u2
u3
0
−u1
−u2
u1
0
⎤
⎦∈ℜ3×3.
(9.48)
The reason for such a deﬁnition is that ˆuv is equal to the conventional cross
product u × v of two vectors in ℜ3. Then we have rank(ˆu) = 2 if u ̸= 0 and the
(left and right) null space of ˆu is exactly spanned by the vector u itself. That
is, ˆuu = 0 and ut ˆu = 0. In other words, columns and rows of the matrix ˆu are
always orthogonal to u.
Obviously, At ˆuA is also a skew-symmetric matrix. Then At ˆuA = ˆv for some
v ∈ℜ3. We want to know what the relationship between v and A, u is.
Hat operator: If A is a 3 × 3 matrix of determinant 1, then we have
At ˆuA = 
A−1u.
(9.49)
This is an extremely useful fact, which will be extensively used in our book. For
example, this property allows us to “push” a matrix through a skew-symmetric ma-
trix in the following way: ˆuA = A−t ˆuA = A−t 
A−1u. We leave to the reader as an
exercise to think about how this result needs to be modiﬁed when the determinant
of A is not !, or when A is not even invertible.
9.6 Singular Value Decomposition
The singular value decomposition (SVD) is a useful tool to capture essential features
of a matrix (that represents a linear map), such as its rank, range space, null space,
and induced norm, as well as to “generalize” the concept of “eigenvalue– eigenvec-
tor” pair to non-square matrices. The computation of the SVD is numerically well
conditioned, making it extremely useful for solving many linear-algebraic problems
such as matrix inversion, calculation of the rank, linear least-squares estimate, pro-
jections, and ﬁxed-rank approximations.
We give hereafter a complete description and proof for the singular value de-
composition (SVD) theorem. Recall ﬁrst that the inner product deﬁned on Cn is
⟨x,y⟩= x∗y, ∀x,y ∈Cn. We now introduce the following important lemma.
Lemma 9.27 Let A ∈Cm×n and A∗be its conjugate transpose. We then always
have:
N

AA∗
= N

A∗
,
R

AA∗
= R(A).
Proof To prove N(AA∗) = N(A∗), we have:

9.6
Singular Value Decomposition
537
1. AA∗x = θ ⇒⟨x,AA∗x⟩= ∥A∗x∥2 = 0 ⇒A∗x = θ. Hence N(AA∗) ⊆
N(A∗).
2. A∗x = θ ⇒AA∗x = θ. Hence N(AA∗) ⊇N(A∗).
To prove R(AA∗) = R(A), we need to prove that Cn is a direct sum of R(A∗)
and N(A). We prove this by showing that a vector x is in N(A) if and only if it is
orthogonal to R(A∗):
x ∈N(A)
⇒

A∗x,y

= 0,
∀y ∈R

A∗
⇒
⟨x,Ay⟩= 0,
∀y.
Hence N(A) is exactly the subspace which is orthogonal supplementary to R(A∗)
(sometimes denoted as R(A∗)⊥). Therefore, Cn is a direct sum of R(A∗) and
N(A). Let ℑA(S) denote the image of a subspace S under the map A. Then we
have:
R(A) = ℑA

Cn
= ℑAR

A∗
= R

AA∗
where in the second equality we used the fact that Cn is a direct sum of R(A∗)
and N(A).
□
We are now ready to give a complete proof for the singular value decomposition
theorem which is the following.
Theorem 9.28 (Singular value decomposition) Let F = ℜor C. Let A ∈Fn×n be
a matrix of rank r. Then there exist matrices U ∈Fm×m and V ∈Fn×n, and Σ1 ∈
ℜn×n such that:
1. V = [V1 : V2],V1 ∈Fn×r, satisﬁes:
V is unitary, that is, V ∗V = In×n,
R(V1) = R(A∗), the columns of V1 form an orthonormal basis of R(A∗),
R(V2) = N(A), the columns of V2 form an orthonormal basis of N(A),
The columns of V form a complete orthonormal basis of eigenvectors of A∗A.
2. U = [U1 : V U2],U1 ∈Fm×r, satisﬁes:
U is unitary, that is, U∗U = Im×m,
R(U1) = R(A∗), the columns of U1 form an orthonormal basis of R(A),
R(U2) = N(A), the columns of U2 form an orthonormal basis of N(A∗),
The columns of U form a complete orthonormal basis of eigenvectors of AA∗.
3. Σ1 = diag(σ1,...,σr) ∈ℜr×r such that σ1 ≥σ2 ···σr > 0. A ∈Fm×n has
dyadic expansion
A = U1Σ1V ∗
1
⇒
A =
r

i=1
σiuiv∗
i
where ui, vi are the columns of U1 and V1, respectively.
4. A ∈Fm×n has a singular value decomposition (SVD)
A = UΣV ∗,
Σ =
Σ1
0
0
0

.

538
9
Appendix
Proof
1. A ∈Fm×n has rank r, hence the nonnegative (or, equivalently, positive semidef-
inite) Hermitian matrix AA∗has rank r according to Lemma 9.27. It has n non-
negative eigenvalues σ 2
i ordered as
σ 2
1 ≥σ 2
2 ≥··· ≥σ 2
r > 0 = σ 2
r+1 = ··· = σ 2
n
to which corresponds a complete orthonormal eigenvector basis (ν)2
i=1 of AA∗.
This family of vectors (∈Fm) form the columns of a unitary n×n matrix, say, V .
From Lemma 9.27, R(AA∗) = R(A∗) and N(AA∗) = N(A), the properties
listed in 1 follow.
2. Deﬁne a diagonal matrix Σ1 = diag(σ1,σ2,...,σr) ∈ℜr×r. When then have
AA∗V1 = V1Σ2
1, hence

AV1Σ−1
1
∗
AV1Σ−1
1

= Ir×r.
This deﬁnes an m × r matrix:
U1 = AV1Σ−1
1 .
It follows that U∗
1 U1 = Ir×r. Since A∗A and AA∗both have exactly r nonzero
eigenvalues, it follows that the columns of U1 form an orthonormal basis for
R(AA∗) and R(A). Thus, the properties of U1 listed in 2 hold. Now deﬁne
an m × (m −r) matrix U2 with orthonormal columns which are orthogonal
to columns of U1. Then U = [U1 : U2] is clearly an unitary matrix. From the
proof of Lemma 9.27, columns of U2 form an orthonormal basis of N(A∗) or
N(AA∗). Therefore, columns of U2 are all the eigenvectors corresponding to
the zero eigenvalue. Hence, columns of U form a complete orthonormal basis of
eigenvectors of AA∗. List 2 is then fully proven.
3. Since U1 = AV1Σ−1
1 , we have
A = U1Σ1V ∗
1 .
The dyadic expansion directly follows.
4. The singular value decomposition follows because
A[V1 : V2] = [U1Σ1 : 0] = [U1 : U2]Σ
⇒
A = UΣV ∗.
□
9.6.1 Geometric Interpretation
Notice that in the SVD of a square matrix A = UΣV t ∈ℜn×n, columns of U =
[u1,u2,...,un] and columns of V = [v1,v2,...,vn] form orthonormal bases for
ℜn. The SVD essentially states that if A (as a linear map) maps a point x to y,
then coordinates of with respect to the basis U are related to coordinates of x with
respect to the basis V by the diagonal matrix Σ that scales each coordinate by the
corresponding singular value.

9.6
Singular Value Decomposition
539
Fig. 9.2 The image of a unit
sphere on the left under a
nonsingular map A ∈ℜ2×2 is
an ellipsoid on the right
Theorem 9.29 Let A ∈ℜn×n = UΣV t be a square matrix. Then A maps the unit
sphere Sn−1 .= {x ∈ℜn : ∥x∥2 = 1} to an ellipsoid with semi-axes σiui, where ui is
the ith column of U.
Proof Let x,y be such that Ax = y. The set {ui}n
i=1 is an orthonormal basis for ℜn.
With respect to such a basis x has coordinates
[α1,α2,...,αn]t =

⟨v1,x⟩,⟨v2,x⟩,...,⟨vn,x⟩
t.
That is, x = 
n
i=1 αivi. With respect to the basis {ui}n
i=1, has coordinates
[β1,β2,...,βn]t =

⟨u1,y⟩,⟨u2,y⟩,...,⟨un,y⟩
t.
We also have y = 
n
i=1 βiui = Ax = 
n
i=1 σiuivt
ix = 
n
i=1 σi⟨vi,x⟩ui. Hence
σiαi = βi. Now ∥x∥2
2 = 
i=1 α2
i = 1, ∀x ∈Sn−1, and so we have 
n
i=1 β2
i /σ 2
i = 1,
which implies that the point y satisﬁes the equation of an ellipsoid with semi-axes
of length σi. This is illustrated in Fig. 9.2 for the case n = 2.
□
9.6.2 Example A.1
The singular value decomposition of matrix
A =
⎡
⎣
0
3
4
⎤
⎦
is A = UΣV ∗where
U =
⎡
⎣
0
−0.6
−0.8
0.6
0.64
−0.84
0.8
−0.48
0.36
⎤
⎦,
Σ =
⎡
⎣
5
0
0
⎤
⎦,
V = 1.
Since matrix A has rank = 1, it has a single nonzero singular value. Therefore, the
spectral norm of A is σM(A) = 5.
9.6.3 Some Properties of the SVD
Let A = UΣV ∗be the singular value decomposition of the n × m matrix A, with
singular values σ1,σ2,...,σr, r = min(n,m). Denote the columns of the n × n

540
9
Appendix
unitary matrix U as ui, i = 1,2,...,n, and those of the m × m unitary matrix V
as vi, i = 1,2,...,m. The following statements hold true:
1. For i = 1,2,...,min(n,m), the column vector ui is an eigenvector of AA∗cor-
responding to the eigenvalue σ 2
i . Any remaining columns are eigenvectors cor-
responding to the eigenvalue 0.
2. Similarly, for i = 1,2,...,min(n,m), the column vector vi is an eigenvector of
A∗A corresponding to the eigenvalue σ 2
i . Any remaining columns are eigenvec-
tors corresponding to the eigenvalue 0.
3. For i = 1,2,...,min(n,m), the vectors ui and vi satisfy
Avi = σiui,
A∗ui = σivi.
4. Given a square n × n matrix A, the following properties hold [5]:
σM(A) = max
x∈Cn
∥Ax∥2
∥x∥2
,
σm(A) = min
x∈Cn
∥Ax∥2
∥x∥2
,
σm(A) ≤
λi(A)
 ≤σM(A),
where λi(A) is the ith eigenvalue of A,
σm(A) =
1
σM(A−1),
σM(A) =
1
σm(A−1),
if A−1 exists,
σM(αA) = |α|σM(A),
with α any complex number,
σM(A + B) ≤σM(A) + σM(B),
σM(AB) ≤σM(A)σM(B),
σm(A) −σM(B) ≤σm(A + B) ≤σm(A) + σM(B),
max

σM(A),σM(B)

≤σM

[AB]

≤
√
2max

σM(A),σM(B)

,
max
i,j |Aij| ≤σM(A) ≤nmax
i,j |Aij|,
with Aij the (i,j) element of A,
n

i=1
σ 2
i (A) = Tr

A∗A

.
Problems involving orthogonal projections onto invariant subspaces of C, such
as the linear least-squares (LLS) problem, can be easily solved using the SVD.
Deﬁnition 9.30 (Generalized (Moore–Penrose) inverse) Given a matrix A ∈ℜm×n
of rank r with its SVD A = UΣV t, we then deﬁne the generalized inverse of A
to be
A⊥= V Σ⊥Ut,
Σ⊥=

Σ−1
1
0
0
0

n×m
.
The generalized inverse is sometimes also called the pseudo-inverse.

9.6
Singular Value Decomposition
541
In MATLAB, the pseudo-inverse of a matrix is computed by the command X =
pinv(A).
Properties of generalized inverse:
• AA⊥A = A, A⊥AA⊥= A⊥.
The generalized inverse can then be used to solve linear equations in general.
Proposition 9.31 (Least-squares solution of a linear systems) Consider the problem
Ax = b with A ∈ℜm×n of rank r ≤min(m,n). The solution x∗that minimizes
∥Ax −b∥2 is given by x∗= A⊥b.
The following two results have something to do with the sensitivity of solving
linear equations of the form Ax = b.
Proposition 9.32 (Perturbations) Consider a nonsingular matrix A ∈ℜn×n. Let δA
be a full-rank perturbation. Then
• |σk(A + δA) −σk(A)| ≤σ1(δA), ∀k = 1,2,...,n.
• σn(AδA) ≥σn(A)σn(δA),
• σ1(A−1) =
1
σn(A),
where σi denotes the ith singular value.
Proposition 9.33 (Condition number) Consider the problem Ax = b, and consider
a “perturbed” full-rank problem (A + δA)(x + δx) = b. Since Ax = b, then to
ﬁrst-order approximation, δx = −A†δAx. Hence, ∥δx∥2 ≤∥A†∥2∥δA∥2∥x∥2, from
which
∥δx∥2
∥x∥2
≤
A†
2∥A∥2
∥δA∥2
∥A∥2
.= k(A)∥δA∥2
∥A∥2
,
where k(A) = ∥A†∥2∥A∥2 is called the condition number of A. It easy to see that
k(A) = σ1/σn if A is invertible.
Last but not the least, one of the most important properties of the SVD is related
to a ﬁxed-rank approximation of a given matrix. Given a matrix A of rank r, we
want to ﬁnd a matrix B such that it has ﬁxed rank p < r and the Frobenius norm of
the difference ∥A −B∥f is minimal. The solution to this problem is given simply by
setting all but the ﬁrst p singular values to zero
B .= UΣ(p)V t,
where Σ(p) denotes the matrix obtained from Σ by setting to zero its elements on
the diagonal after the pth entry. The matrix B has exactly the same induced 2-norm
of, that is, σ1(A) = σ1(B), and satisﬁes the requirement on the rank.
Proposition 9.34 (Fixed rank approximation) Let A, B be deﬁned as above. Then
∥A−B∥2
f = σ 2
p+1 +···+σ 2
r . Furthermore, such a norm is the minimum achievable.
The proof is an easy exercise that follows directly from the properties of orthog-
onal projection and the properties of the SVD given above.

542
9
Appendix
After we have gone through all the trouble proving this theorem, you must know
that SVD has become a numerical routine available in many computational soft-
wares such as MATLAB. Within MATLAB, to compute the SVD of a given m × n
matrix A, simply use the command
>>
[U,S,V ] = SVD(A)
which returns matrices U, S, V satisfying A = USV ∗(where S represents Σ as
deﬁned above).
9.7 Gram–Schmidt and the QR Decomposition
A matrix in GL(n) has n independent rows (or columns). A matrix in O(n) has
orthonormal rows (or columns). The Gram–Schmidt procedure can be viewed as a
map from GL(n) to O(n), for it transforms a nonsingular matrix into an orthogonal
one. Call L+(n) the subset of GL(n) consisting of lower triangular matrices with
positive elements along the diagonal. Such matrices form a subgroup of GL(n).
Theorem 9.35 (Gram–Schmidt procedure) For every A ∈GL(n), there exists a
lower triangular matrix L ∈ℜn×n and an orthogonal matrix E ∈O(n) such that
A = LE.
(9.50)
Proof Contrary to the convention of the book, for simplicity in this proof all vectors
indicate row vectors. That is, if v is an n-dimensional row vector, it is of the form:
v = [v1,v2,...,vn] ∈ℜn. Denote the ith row vector of the given matrix A by ai for
i = 1,2,...,n. The proof consists in constructing L and E iteratively from the row
vectors ai:
l1
.= a1
→e1
.= l1/∥l1∥2,
l2
.= a2 −(a2,ϵ1)ϵ1
→e2
.= l2/∥l2∥2,
...
...
...
...
...
ln
.= an −
n−1

i=1
⟨ai+1,ei⟩ei →en
.= ln/∥ln∥2.
Then E = [et
1,...,et
n]t, and the matrix L is obtained as
L =
⎡
⎢⎢⎢⎣
∥l1∥2
0
···
0
⟨a2,e1⟩
∥l2∥2
···
0
...
...
...
...
⟨a2,e1⟩
···
⟨an,en−1⟩
∥ln∥2
⎤
⎥⎥⎥⎦.
By construction is orthogonal; that is, EEt = EtE = I.
□

9.8
Useful Formulae
543
Remark 9.36 The Gram–Schmidt’s procedure has the peculiarity of being causal, in
the sense that the ith row of the transformed matrix E depends only upon rows with
index J ≤i of the original matrix A. The choice of the name E for the orthogonal
matrix above is not accidental.
There are a few useful variations to Gram–Schmidt procedure. By transposing
A = LE, we get At = EtLt
.= QR. Notice that R = Lt is an upper triangular ma-
trix. Thus, by applying Gram–Schmidt procedure to the transpose of a matrix, we
can also decompose it into the form QR where Q is an orthogonal matrix and R
an upper triangular matrix. Such a decomposition is called the QR decomposition.
In MATLAB, this can be done by the command [Q,R] = qr(A). Furthermore, by
inverting At = EtLt, we get A−t = L−tE .= KE. Notice that K = L−t is still an
upper triangular matrix. Thus, we can also decompose any matrix into the form of
an upper triangular matrix followed by an orthogonal There are a few useful varia-
tions to Gram–Schmidt procedure. By transposing, we get. Notice that is an upper
triangular matrix. Thus, by applying Gram–Schmidt procedure to the transpose of a
matrix, we can also decompose it into the form where is an orthogonal one. The lat-
ter one is the kind of “QR decomposition” we use in Chap. 6 for camera calibration.
9.8 Useful Formulae
In what follows, some standard formulae that are of common use in the book are
presented.
9.8.1 Ackermann’s Formula for Eigenvalue Assignment
In [1], a formula is provided to compute the feedback gain matrix K such that a set
of eigenvalues of the linear system
˙x(t) = Ax(t) + Bu(t)
at desired locations. The formula emerges by organizing a three-step procedure of
converting the system matrices into controller canonical form, solving for the gain
and converting the gain back. It has the form:
K = [0,...,0,1]Pcαc(A),
Pc =

B,AB,A2B,...,An−1B

,
αc(A) = An + α1An−1 + α2An−2 + ··· + αnI
where αj are the coefﬁcients of the desired characteristic polynomial
αc(s) = (s −s1)(s −s2)···(s −sn)
= sn + α1sn−1 + α2sn−2 + ··· + αn
and s1,...,sn are the desired eigenvalues.

544
9
Appendix
9.8.2 Parseval Formula
Let f (t) be a continuous-time signal over the time-interval [t1,t2]. Then the
continuous-time signal energy over the length L = t2 −t1] is deﬁned by
EL =
 t2
t1
f (t)
2 dt
whereas the total continuous-time signal energy is given by
E∞=
 ∞
−∞
f (t)
2 dt.
(9.51)
From Laplace transform methods [Gajic], we recall the frequency domain convolu-
tion which states that the Frequency transform of a product of two signals in time is
proportional to the convolution of their convolution of their Fourier transforms in
the frequency domain, that is for two continuous-time signals x1(t) and x2(t), we
have
F

x1(t)x2(t)

= 1
2π X1(jω) ∗X2(jω)
= 1
2π
 ∞
−∞
X1

j(ω −λ)

∗X2(jλ)dλ
(9.52)
where F[x] is the Fourier transform of x and ∗stands for the convolution operation.
Based thereon, we can now establish the relationship between signal energy in the
time and frequency domains. Rewriting (9.52) as
F

x1(t)x2(t)

=
 ∞
−∞
x1(t)x2(t)e−jωt dt.
(9.53)
Since (9.53) is valid for any ω, it must be valid for ω = 0. In view of (9.51)–(9.53),
we have
 ∞
−∞
x1(t)x2(t)e−jωt dt = 1
2π
 ∞
−∞
X1

j(ω −λ)

∗X2(jλ)dλ.
(9.54)
Letting x1(t) = x2(t) = x(t) with x(t) being a real function such that |x(t)|2 =
x2(t), it follows that
E∞=
 ∞
−∞
x2(t)dt = 1
2π
 ∞
−∞
X(jλ)X(jλ)dλ
= 1
2π
 ∞
−∞
X(jλ)
2 dλ =
 ∞
−∞
X(jf )
2 df.
(9.55)
Note that λ = 2πf , is a dummy variable of integration, plays the role of the angu-
lar frequency. The quantity |X(jf )|2 is known as the energy spectrum. The result
established in (9.55) is known as Parseval theorem which has great importance in
signal processing and communications.

9.9
Inequalities
545
9.8.3 Frobenius Formula
Let λ1,λ2,...,λn are the eigenvalues of the n × n matrix A and let f (x) be a
function which is analytic inside a circle in the complex plane that contains all
the λi. Then f (λ1),f (λ2),...,f (λn) are the eigenvalues of the matrix function
f (A). For example, the state transition matrix Φ(t,to) = eA(t−to) has eigenvalues
γi = eλi(t−to). It can be veriﬁed that the eigenvectors of A and Φ(t,to) are the same.
9.9 Inequalities
All mathematical inequalities are proved for completeness. They are termed facts
due to their high frequency of usage in the analytical developments.
9.9.1 Inequality 1
For any real matrices Σ1, Σ2 and Σ3 with appropriate dimensions and Σt
3Σ3 ≤I,
it follows that
Σ1Σ3Σ2 + Σt
2Σt
3Σt
1 ≤αΣ1Σt
1 + α−1Σt
2Σ2,
∀α > 0.
Proof This inequality can be proved as follows. Since ΦtΦ ≥0 holds for any ma-
trix Φ, then take Φ as
Φ =

α1/2Σ1 −α−1/2Σ2

.
Expansion of ΦtΦ ≥0 gives ∀α > 0
αΣ1Σt
1 + α−1Σt
2Σ2 −Σt
1Σ2 −Σt
2Σ1 ≥0
which by simple arrangement yields the desired result.
□
9.9.2 Inequality 2
Let Σ1, Σ2, Σ3 and 0 < R = Rt be real constant matrices of compatible dimensions
and H(t) be a real matrix function satisfying H t(t)H(t) ≤I. Then for any ρ > 0
satisfying ρΣt
2Σ2 < R, the following matrix inequality holds:

Σ3 +Σ1H(t)Σ2

R−1
Σt
3 + Σt
2H t(t)Σt
1

≤ρ−1Σ1Σt
1 + Σ3

R −ρΣt
2Σ2
−1Σt
3.
Proof The proof of this inequality proceeds like the previous one by considering
that
Φ =

ρ−1Σ2Σt
2
−1/2Σ2R−1Σt
3 −

ρ−1Σ2Σt
2
−1/2H t(t)Σt
1

.

546
9
Appendix
Recall the following results
ρΣt
2Σ2 < R,

R −ρΣt
2Σ2
−1 =

R−1 + R−1Σt
2

ρ−1I −Σ2R−1Σt
2
−1Σ2R−1
Σ2
and
H t(t)H(t) ≤I
⇒
H(t)H t(t) ≤I.
Expansion of ΦtΦ ≥0 under the condition ρΣt
2Σ2 < R with standard matrix ma-
nipulations gives
Σ3R−1Σt
2H t(t)Σt
1 + Σ1H(t)Σ2R−1Σt
3 + Σ1H(t)Σ2Σt
2H t(t)Σt
1
≤ρ−1Σ1H(t)H t(t)Σt
1 + Σt
3R−1Σ2

ρ−1IΣ2Σt
2
−1Σ2R−1Σt
3
⇒

Σ3 + Σ1H(t)Σ2

R−1
Σt
3 + Σt
2H t(t)Σt
1

−Σ3R−1Σt
3
≤ρ−1Σ1H(t)H t(t)Σt
1 + Σt
3R−1Σ2

ρ−1I −Σ2Σt
2
−1Σ2R−1Σt
3
⇒

Σ3 + Σ1H(t)Σ2

R−1
Σt
3 + Σt
2H t(t)Σt
1

≤Σ3

R−1 + Σ2

ρ−1I −Σ2Σt
2
−1Σ2R−1
Σt
3 + ρ−1Σ1H(t)H t(t)Σt
1
= ρ−1Σ1H(t)H t(t)Σt
1 + Σ3

R −ρΣt
2Σ2
−1Σt
3
which completes the proof.
□
9.9.3 Inequality 3
For any real vectors β, ρ and any matrix Qt = Q > 0 with appropriate dimensions,
it follows that
−2ρtβ ≤ρtQρ + βtQ−1β.
Proof Starting from the fact that

ρ + Q−1β
tQ

ρ + Q−1β

≥0,
Q > 0
which when expanded and arranged yields the desired result.
□
9.9.4 Inequality 4 (Schur Complements)
Given a matrix Ω composed of constant matrices Ω1, Ω2, Ω3 where Ω1 = Ωt
1 and
0 < Ω2 = Ωt
2 as follows
Ω =
Ω1
Ω3
Ωt
3
Ω2

.
We have the following results

9.9
Inequalities
547
(A) Ω ≥0 if and only if either
⎧
⎨
⎩
Ω2 ≥0,
Π = Υ Ω2,
Ω1 −Υ Ω2Υ t ≥0
(9.56)
or
⎧
⎨
⎩
Ω1 ≥0,
Π = Ω1Λ,
Ω2 −ΛtΩ1Λ ≥0
(9.57)
hold where Λ, Υ are some matrices of compatible dimensions.
(B) Ω > 0 if and only if either
Ω2 > 0,
Ω1 −Ω3Ω−1
2 Ωt
3 > 0
or
Ω1 ≥0,
Ω2 −Ωt
3Ω−1
1 Ω3 > 0
hold where Λ, Υ are some matrices of compatible dimensions.
In this regard, matrix Ω3Ω−1
2 Ωt
3 is often called the Schur complement Ω1(Ω2)
in Ω.
Proof (A) To prove (9.56), we ﬁrst note that Ω2 ≥0 is necessary. Let zt = [zt
1 zt
2]
be a vector partitioned in accordance with Ω. Thus, we have
ztΩz = zt
1Ω1z1 + 2zt
1Ω3z2 + zt
2Ω2z2.
(9.58)
Select z2 such that Ω2z2 = 0. If Ω3z2 ̸= 0, let z1 = −πΩ3z2, π > 0. Then it follows
that
ztΩz = π2zt
2Ωt
3Ω1Ω3z2 −2πzt
2Ωt
3Ω3z2
which is negative for a sufﬁciently small π > 0. We thus conclude Ω1z2 = 0 which
then leads to Ω3z2 = 0, ∀z2 and consequently
Ω3 = Υ Ω2
(9.59)
for some Υ .
Since Ω ≥0, the quadratic term ztΩz possesses a minimum over z2 for any z1.
By differentiating ztΩz from (9.58) wrt zt
2, we get
∂(ztΩz)
∂zt
2
= 2Ωt
3z1 + 2Ω2z2 = 2Ω2Υ tz1 + 2Ω2z2.
Setting the derivative to zero yields
Ω2Υ z1 = −Ω2z2.
(9.60)

548
9
Appendix
Using (9.59) and (9.60) in (9.58), it follows that the minimum of ztΩz over z2 for
any z1 is given by
min
z2 ztΩz = zt
1

Ω1 −Υ Ω2Υ t
z1
which prove the necessity of Ω1 −Υ Ω2Υ t ≥0.
On the other hand, we note that the conditions (9.56) are necessary for Ω ≥0
and since together they imply that the minimum of ztΩz over z2 for any z1 is non-
negative, they are also sufﬁcient.
Using similar argument, conditions (9.57) can be derived as those of (9.56) by
starting with Ω1.
The proof of (B) follows as direct corollary of (A).
□
9.9.5 Inequality 5
For any quantities u and v of equal dimensions and for all ηt = i ∈S, it follows that
the following inequality holds
∥u + v∥2 ≤

1 + β−1
∥u∥2 + [1 + β]∥v∥2
(9.61)
for any scalar β > 0, i ∈S.
Proof Since
[u + v]t[u + v] = utu + vtv + 2utv.
(9.62)
It follows by taking norm of both sides of (9.62) for all i ∈S that
∥u + v∥2 ≤∥u∥2 + ∥v∥2 + 2
utv
.
(9.63)
We know from the triangle inequality that
2
utv
 ≤β−1∥u∥2 + β∥v∥2.
(9.64)
On substituting (9.64) into (9.63), it yields (9.61).
□
9.10 Lemmas
The basic tools and standard results that are utilized in robustness analysis and re-
silience design in the different chapters are collected hereafter.
Lemma 9.37 The matrix inequality
−Λ + SΩ−1St < 0
(9.65)
holds for some 0 < Ω = Ωt ∈ℜn×n, if and only if

9.10
Lemmas
549
−Λ
SX
•
−X −X t + Z

< 0
(9.66)
holds for some matrices X ∈ℜn×n and Z ∈ℜn×n.
Proof (⇒) By Schur complements, inequality (9.65) is equivalent to
−Λ
SΩ−1
•
−Ω−1

< 0.
(9.67)
Setting X = X t = Z = Ω−1, we readily obtain inequality (9.66).
(⇐) Since the matrix [I S] is of full rank, we obtain
 I
St
t −Λ
SX
•
−X −X t + Z
 I
St

< 0
⇐⇒
−Λ + SZSt < 0
⇐⇒
−Λ + SΩ−1St < 0,
Z = Ω−1
(9.68)
which completes the proof.
□
Lemma 9.38 The matrix inequality
AP + PAt + DtR−1D + M < 0
(9.69)
holds for some 0 < P = Pt ∈ℜn×n, if and only if
⎡
⎣
AV + VtAt + M
P + AW −V
DtR
•
−W −Wt
0
•
•
−R
⎤
⎦< 0
(9.70)
holds for some V ∈ℜn×n and W ∈ℜn×n.
Proof (⇒) By Schur complements, inequality (9.69) is equivalent to
AP + PAt + M
DtR
•
−R

< 0.
(9.71)
Setting V = Vt = P, W = Wt = R, it follows from Lemma 9.37 with Schur com-
plements that there exists P > 0, V, W such that inequality (9.70) holds.
(⇐) In a similar way, Schur complements to inequality (9.70) imply that:
⎡
⎣
AV + VtAt + M
P + AW −V
DtR
•
−W −Wt
0
•
•
−R
⎤
⎦< 0
⇐⇒
 I
A

AV + VtAt + M + DtR−1D
P + AW −V
•
−W −Wt
 I
A
t
< 0
⇐⇒
AP + PAt + DtR−1D + M < 0,
V = Vt
(9.72)
which completes the proof.
□

550
9
Appendix
Lemma 9.39 Given any x ∈ℜn:
max

xtRHΔGx
2 : Δ ∈ℜ

= xtRHH tRxxtGtGx.
Lemma 9.40 Given matrices 0 ≤X = Xt ∈ℜp×p, Y = Y t < 0 ∈ℜp×p, 0 ≤Z =
Zt ∈ℜp×p, such that

ξtYξ
2 −4

ξtXξ
ξtZξ
2 > 0
for all 0 ̸= ξ ∈ℜp is satisﬁed. Then there exists a constant α > 0 such that
α2X + αY + Z < 0.
Lemma 9.41 For a given two vectors α ∈Rn, β ∈Rm and matrix N ∈Rn×m deﬁned
over a prescribed interval Ω, it follows for any matrices X ∈Rn×n, Y ∈Rn×m, and
Z ∈Rm×m, the following inequality holds
−2

Ω
αt(s)Nβ(s)ds ≤

Ω
α(s)
β(s)
t 
X
Y −N
Y t −Nt
Z
α(s)
β(s)

ds
where
 X
Y
Y t
Z

≥0.
An algebraic version of Lemma 9.41 is stated below
Lemma 9.42 For a given two vectors α ∈Rn, β ∈Rm and matrix N ∈Rn×m deﬁned
over a prescribed interval Ω, it follows for any matrices X ∈Rn×n, Y ∈Rn×m, and
Z ∈Rm×m, the following inequality holds
−2αtNβ ≤
α
β
t 
X
Y −N
Y t −Nt
Z
α
β

= αtXα + βt
Y t −Nt
α + αt(Y −N)β + βtZβ
subject to
 X
Y
Y t
Z

≥0.
Lemma 9.43 Let 0 < Y = Y t and M, N be given matrices with appropriate dimen-
sions. Then it follows that
Y + MΔN + NtΔtMt < 0,
∀ΔtΔ ≤I
holds if and only if there exists a scalar ε > 0 such that
Y + εMMt + ε−1NtN < 0.
In the following lemma, we let X(z) ∈Rn×p be a matrix function of the
variable z. A matrix X∗(z) is called the orthogonal complement of X(z) if
Xt(z)X∗(z) = 0 and X(z)X∗(z) is nonsingular (of maximum rank).

9.11
Linear Matrix Inequalities
551
Lemma 9.44 Let 0 < L = Lt and X, Y be given matrices with appropriate dimen-
sions. Then it follows that the inequality
L(z) + X(z)PY(z) + Y t(z)P tXt(z) > 0
(9.73)
holds for some P and z = zo if and only if the following inequalities
Xt
∗(z)L(z)X∗(z) > 0,
Y t
∗(z)L(z)Y∗(z) > 0
(9.74)
hold with z = zo.
It is signiﬁcant to observe that feasibility of matrix inequality (9.73) with vari-
ables P and z is equivalent to the feasibility of (9.74) with variable z and thus the
matrix variable P has been eliminated from (9.73) to form (9.74). Using Finsler’s
lemma, we can express (9.74) in the form
L(z) −βX(z)Xt(z) > 0,
L(z) −βY(z)Y t(z) > 0
(9.75)
for some β ∈R.
The following is a statement of the reciprocal projection lemma.
Lemma 9.45 Let P > 0 be a given matrix. The following statements are equiva-
lent:
(i) M + Z + Zt < 0,
(ii) the LMI problem
M + P −(V + V t)
V t + Zt
V + Z
−P

< 0
is feasible with respect to the general matrix V .
9.11 Linear Matrix Inequalities
It has been shown that a wide variety of problem arising in system and control the-
ory can conveniently reduced to a few standard convex or quasiconvex optimization
problems involving linear matrix inequalities (LMIs). The resulting optimization
problems can then be solved numerically very efﬁciently using commercially avail-
able interior-point methods.
9.11.1 Basics
One of the earliest LMIs arises in Lyapunov theory. It is well-known that the differ-
ential equation
˙x(t) = Ax(t)
(9.76)

552
9
Appendix
has all of its trajectories converge to zero (stable) id and only if there exists a matrix
P > 0 such that
AtP + AP < 0.
(9.77)
This leads to the LMI formulation of stability, that is, a linear time-invariant system
is asymptotically stable if and only if there exists a matrix 0 < P = P t satisfying the
LMIs
AtP + AP < 0,
P > 0.
Given a vector variable x ∈Rn and a set of matrices 0 < Gj = Gt
j ∈Rn×n, j =
0,...,p, then a basic compact formulation of a linear matrix inequality is
G(x) Δ= G0 +
p

j=1
xjGj > 0.
(9.78)
Notice that (9.78) implies that vtG(x)v > 0 ∀0 ̸= v ∈Rn. More importantly, the set
{x|G(x) > 0} is convex. Nonlinear (convex) inequalities are converted to LMI form
using Schur complements in the sense that
Q(x)
S(x)
•
R(x)

> 0
(9.79)
where Q(x) = Qt(x), R(x) = Rt(x), S(x) depend afﬁnely on x, is equivalent to
R(x) > 0,
Q(x) −S(x)R−1(x)St(x) > 0.
(9.80)
More generally, the constraint
Tr

St(x)P −1(x)S(x)

< 1,
P(x) > 0
where P(x) = P t(x) ∈Rn×n, S(x) ∈Rn×p depend afﬁnely on x, is handled by
introducing a new (slack) matrix variable Y(x) = Y t(x) ∈Rp×p and the LMI (in x
and Y):
TrY < 1,
Y
S(x)
•
P(x)

> 0.
(9.81)
Most of the time, our LMI variables are matrices. It should clear from the foregoing
discussions that a quadratic matrix inequality (QMI) in the variable P can be readily
expressed as linear matrix inequality (LMI) in the same variable.
9.11.2 Some Standard Problems
Here we provide some common convex problems that we encountered throughout
the monograph. Given an LMI G(x) > 0, the corresponding LMI problem (LMIP)
is to
ﬁnd a feasible x ≡xf such that G(xf ) > 0, or determine that the LMI is infeasible.

9.11
Linear Matrix Inequalities
553
It is obvious that this is a convex feasibility problem. The generalized eigenvalue
problem (GEVP) is to minimize the maximum generalized eigenvalue of a pair of
matrices that depend afﬁnely on a variable, subject to an LMI constraint. GEVP has
the general form
minimize
λ,
subject to
λB(x) −A(x) > 0,
B(x) > 0,
C(x) > 0
(9.82)
where A, B, C are symmetric matrices that are afﬁne functions of x. Equivalently
stated
minimize
λM

A(x),B(x)

,
subject to
B(x) > 0,
C(x) > 0
(9.83)
where λM[X,Y] denotes the largest generalized eigenvalue of the pencil λY −X
with Y > 0. This is problem is quasiconvex optimization problem since the con-
straint is convex and the objective ,λM[A(x),B(x)], is quasiconvex. The eigenvalue
problem (EVP) is to minimize the maximum eigenvalue of a matrix that depend
afﬁnely on a variable, subject to an LMI constraint. EVP has the general form
minimize
λ,
subject to
λI −A(x) > 0,
B(x) > 0
(9.84)
where A, B are symmetric matrices that are afﬁne functions of the optimization
variable x. This is problem is convex optimization problem.
EVPs can appear in the equivalent form of minimizing a linear function subject
to an LMI, that is
minimize
ctx,
subject to
G(x) > 0
(9.85)
where G(x) is an afﬁne function of x. Examples of G(x) include
PA + AtP + CtC + γ −1PBBtP < 0,
P > 0.
It should be stressed that the standard problems (LMIPs, GEVPs, EVPs) are
tractable, from both theoretical and practical viewpoints:
They can be solved in polynomial-time.
They can solved in practice very efﬁciently using commercial software.
9.11.3 The S-Procedure
In some design applications, we faced the constraint that some quadratic function
be negative whenever some other quadratic function is negative. In such cases, this
constraint can be expressed as an LMI in the data variables deﬁning the quadratic
functions. Let G0,...,Gp be quadratic functions of the variable ξ ∈Rn:
Gj(ξ) Δ= ξtRjξ + 2ut
jξ + vj,
j = 0,...,p, Rj = Rt
j.

554
9
Appendix
We consider the following condition on G0,...,Gp:
G0(ξ) ≤0
∀ξ
such that Gj(ξ) ≥0, j = 0,...,p.
(9.86)
It is readily evident that if there exist scalars ω1 ≥0,...,ωp ≥0 such that
∀ξ,
G0(ξ) −
p

j=1
ωjGj(ξ) ≥0
(9.87)
then inequality (9.86) holds. Observe that if the functions G0,...,Gp are afﬁne,
then Farkas lemma state that (9.86) and (9.87) are equivalent. Interestingly enough,
inequality (9.87) can written as
R0
u0
•
v0

−
p

j=1
ωj
Rj
uj
•
vj

≥0.
(9.88)
The foregoing discussions were stated for non strict inequalities. In case of strict
inequality, we let R0,...,Rp ∈Rn×n be symmetric matrices with the following
qualiﬁcations
ξtR0ξ > 0
∀ξ
such that ξtGjξ ≥0, j = 0,...,p.
(9.89)
Once again, it is obvious that there exist scalars ω1 ≥0,...,ωp ≥0 such that
∀ξ,
G0(ξ) −
p

j=1
ωjGj(ξ) > 0
(9.90)
then inequality (9.89) holds. Observe that (9.90) is an LMI in the variables
R0,ω1,...,ωp. It should be remarked that the S-procedure deals with non strict
inequalities allows the inclusion of constant and linear terms. In the strict version,
only quadratic functions can be used.
9.12 Lyapunov Map and Lyapunov Equation
An important type of linear equation that we will encounter in our book is of Lya-
punov type:2 ﬁnd a matrix X ∈Cn×n that satisﬁes the equation
AX + XB = 0
(9.91)
for a given pair of matrices A,B ∈Cn×n. Although solutions to this type of equa-
tion can be difﬁcult in general, simple solutions exist when both A and B have n
independent eigenvectors. Suppose {ui ∈Cn}n
i=1 are the n right eigenvectors of A,
and {vj ∈Cn}n
j=1 are the n left eigenvectors of B; that is,
Aui = λiui;
v∗
j B = ηjv∗
j
(9.92)
for eigenvalues λi, ηj for each i, j. Here v∗means the complex-conjugate and
transpose of v, since v can be complex.
2It is also called Sylvester equation in some literature.

9.13
Persistence of Excitation and Sufﬁciently Rich Inputs
555
Lyapunov map: For the above matrix A and B, the n2 eigenvectors of the Lya-
punov map
L : X →AX + XB
(9.93)
are exactly Xij = uiv∗
j ∈Cn×n, and the corresponding eigenvalues are λi + ηj ∈C,
i,j = 1,2,...,n.
Proof The n2 matrices {Xij}n
i,j=1 are linearly independent, and they must be all the
eigenvectors of L.
□
Due to this fact, any matrix X that satisﬁes the Lyapunov equation AX+XB = 0
must be in the subspace spanned by eigenvectors Xij that have zero eigenvalues:
λi +ηj = 0. In MATLAB, the command X = lyap(A,B,C) solves the more general
Lyapunov equation AX + XB = −C.
In this book, we often look for solutions X with extra requirements on its struc-
ture. For instance, X needs to be real and symmetric (Chap. 6), or X has to be a
rotation matrix (Chap. 8). If so, we have only to take the intersection of the space of
solutions to the Lyapunov equation with the space of symmetric matrices or rotation
matrices.
9.13 Persistence of Excitation and Sufﬁciently Rich Inputs
We start with the following deﬁnition.
Deﬁnition 9.46 The vector φ ∈Rn is persistently excited (PE) with level α0 if it
satisﬁes
 t+T0
t
φ(τ)φt(τ)dτ ≥α0T0I
(9.94)
for some α0 > 0, T0 > 0 and ∀t ≥0.
Since φφt is always positive semideﬁnite, the PE condition requires that its inte-
gral over any interval of time of length T0 is a positive deﬁnite matrix.
Deﬁnition 9.47 The signal u ∈R is called sufﬁciently rich of order n if it contains
at least n
2 distinct nonzero frequencies.
For example, u = 
10
i=1 sinωit, where ωi ̸= ωj for i ̸= j is sufﬁciently rich of
order 20. A more general deﬁnition of sufﬁciently rich signals and associated prop-
erties may be found in [4].
Let us consider the signal vector φ ∈Rn generated as
φ = H(s)u,
(9.95)
where u ∈R and H(s) is a vector whose elements are transfer functions that are
strictly proper with stable poles.

556
9
Appendix
Theorem 9.48 Consider (9.95) and assume that the complex vectors
H(jω1),...,H(jωn)
are linearly independent on the complex space
Cn
∀ω1,ω2,...,ωn ∈R,
ωi ̸= ωj, i ̸= j.
Then φ is PE if and only if u is sufﬁciently rich of order n.
Proof The proof of Theorem 9.48 can be found in [3, 4].
□
We demonstrate the use of Theorem 9.48 for the Example 8.3, where
φ = H(s)u
and
H(s) =

1
−b
s+u

.
In this case n = 2 and
H(jω1) =

1
−
b
jω1+a

,
H(jω2) =

1
−
b
jω2+a

.
We can show that the matrix [H(jω1),H(jω2)] is nonsingular, which implies that
H(jω1), H(jω2) are linearly independent for any ω1, ω2 different than zero and
ω1 ̸= ω2.
Let us choose
u = sinω0t
for some ω0 ̸= 0 which is sufﬁciently rich of order 2. According to Theorem 9.48,
this input should guarantee that φ is PE for the Example 8.3. Ignoring the transient
terms that converge to zero exponentially fast, we can show that at steady state
φ =

sinω0t
c0 sin(ω0t + ϕ0)

,
where
c0 =
|b|

ω2
0 + a2
,
ϕ0 = arg

−b
jω0 + a

.
Now
φφt =

sin2 ω0t
c0 sinω0t sin(ω0t + ϕ0)
c0 sinω0t sin(ω0t + ϕ0)
c2
0 sin2(ω0t + ϕ)

and
 t+T0
t
φ(τ)φt(τ)dτ =
a11
a12
a12
a22

,

9.13
Persistence of Excitation and Sufﬁciently Rich Inputs
557
where
a11 = T0
2 −sin2ω0(t + T0) −sin2ω0t
4ω0
,
a12 = c0
T0
2 cosϕ0 + c0
sinϕ0
4ω0

cos2ω0t −cos2ω0(t + T0)

,
a22 = c2
0
T0
2 −c2
0
sin2(ω0(t + T0) + ϕ0) −sin2(ω0t + ϕ0)
4ω0
.
Choosing T0 = π
ω0 it follows that
a11 = T0
2 ,
a12 = T0c0
2
cosϕ0,
a22 = T0
2 c2
0
and
 t+T0
t
φ(τ)φt(τ)dτ = T0
2

1
c0 cosϕ0
c0 cosϕ0
c2
0

,
which is a positive deﬁnite matrix. We can verify that for α0 = 1
2
(1−cos2 ϕ0)c2
0
1+c2
0
> 0,
 t+T0
t
φ(τ)φt(τ)dτ ≥T0α0I,
which implies that φ is PE.
Let us consider the plant model
y = b(s2 + 4)
(s + 5)3 u,
where b is the only unknown parameter. A suitable parametric model for estimating
b is
z = θ∗φ,
where
z = y,
θ∗= b,
φ = s2 + 4
(s + 5)3 u.
In this case φ ∈R and H(s) =
s2+4
(s+5)3 ; i.e., n = 1 in Theorem 9.48. Let us use
Theorem 9.48 to choose a sufﬁciently rich signal u that guarantees φ to be PE. In
this case, according to the linear independence condition of Theorem 9.48 for the
case of n = 1, we should have
H(jω0)
 =
4 −ω2
0
(25 + ω2
0)3/2 ̸= 0
for any ω0 ̸= 0. This condition is clearly violated for ω0 = 2, and therefore a suf-
ﬁciently rich input of order 1 may not guarantee φ to be PE. Indeed, the input
u = sin2t leads to y = 0,φ = 0 at steady state, which imply that the output y and

558
9
Appendix
regressor φ carry no information about the unknown parameter b. For this example
u = sinω0t will guarantee φ to be PE, provided ω0 ̸= 2. Also, u = constant ̸= 0
and u = 
m
i=1 sinωit, m ≥2, will guarantee that φ is PE. In general, for each two
unknown parameters we need at least a single nonzero frequency to guarantee PE,
provided of course that H(s) does not lose its linear independence as demonstrated
by the above example.
The two-parameter case leads to the differential equation (8.28), which has ex-
actly the same form as in the case of an arbitrary number of parameters. In the
following section, we consider the case where θ∗, φ are of arbitrary dimension and
analyze the convergence properties of equations of the form (8.28).
9.14 Notes and References
The analysis presented in this chapter made extensive use of the standard texts in-
cluding [5].
References
1. Ackermann, J.: Der Entwurf Linearer Regelungssysteme im Zustandsraum, Regelungstech,
Prozess-Datenverarb. 7, 297–300 (1972)
2. Chiang, R.Y., Safonov, M.G.: User’s Guide, Robust Control Toolbox. The Math Works, Natick,
USA (1992)
3. Goodwin, G.C., Sin, K.S.: Adaptive Filtering Prediction and Control. Prentice-Hall, Englewood
Cliffs (1984)
4. Ioannou, P.A., Fidan, B.: Adaptive Control Tutorial, SIAM’s Advances in Design and Control
(2006)
5. Noble, B., Daniel, J.: Applied Linear Algebra, 3rd edn. Prentice-Hall, New York (1988)
6. Strange, G., Introduction to Applied Mathematics. Wellesley, Cambridge (1986)

Index
A
Ackerman formula, 543
Adaptive control, 463
Adaptive control schemes, 463
Autopilots, 465
B
Bilinear parametric models, 473
Block Hankel matrices, 59
C
Cart with two inverted pendulums, 476
Certainty equivalence, 301
Closed-loop control system, 218
Combined deterministic-stochastic algorithm,
68
Continuous state-transition matrix, 221
Control design, 215
Control system, 217
Controllability, 222
D
Deterministic subspace identiﬁcation, 63
Direct adaptive control, 466
Discrete state-transition matrix, 221
Disturbance rejection, 315
Dynamic model of a liquid container,
378
Dynamic model of marine vehicles, 383
Dynamic parametric model, 473
E
Eigenvalues and eigenvectors, 534
F
Feedback design of liquid container, 380
Frobenius formula, 545
G
Gain scheduling, 469
Generalized least squares (GLS) method, 54
Gradient algorithm, 41, 485
Gradient projection, 99
H
H2-norm, 406
H2-norm: signiﬁcance, 408
H2 optimization, 413
H∞control, 421
H∞-norm, 407
H∞-norm: signiﬁcance, 409
Hydraulic process, 29
Hydraulic pumping system, 28, 193
I
Indirect adaptive control, 466
Industrial controllers, 248
Industrial evaporation unit, 19
Inequalities, 545
Integral control, 440
Integral control action, 251, 254
K
Kernel of a matrix, 531
L
L1-norm, 406
L2-norm, 406
L∞-norm, 406
Least squares algorithm, 45, 489
Linear matrix inequalities, 551
Linear optimal control: continuous-time,
264
Liquid container, 375
Lyapunov function, 221
Lyapunov stability theory, 222
M.S. Mahmoud, Y. Xia, Applied Control Systems Design,
DOI 10.1007/978-1-4471-2879-3, © Springer-Verlag London Limited 2012
559

560
Index
M
Marine vehicles, 383
Mass-spring-dashpot system, 475
Matrix inverse, 530
Matrix inversion lemma, 531
N
Norm measures of signals, 406
Norm measures of systems, 406
Null space, 531
O
Observability, 223
On–off control action, 249
Online parameter estimator, 467
Open-loop control system, 218
Optimal set-point control, 270
Output-error parametric identiﬁcation, 73
Output-normal form, 82
P
Parameter adaptation algorithm, 38
Parameter estimation, 36
Parameter projection, 498
Parametric models, 472
Parseval formula, 544
PD control action, 251
PI control action, 251
PID control action, 252
Plant, 217
Prediction error method (PEM), 54
Proportional control action, 250
Q
QR decomposition, 542
Qualitative analysis of bias, 124
R
Range of a matrix, 531
Rank of a matrix, 531
Recursive estimation algorithms, 45
Robust parameter identiﬁcation, 500
S
Separation principle, 301
Shaping process of automobile belt,
309
Singular value decomposition (SVD),
536
Skew-symmetric matrix, 534, 535
Stability, 221
State feedback, 225
State-space identiﬁers, 504
Static parametric model, 472
Steepest-descent method, 97
Stochastic subspace identiﬁcation, 65
Subspace identiﬁcation method, 56
Symmetric matrices, 534
System, 216, 217
System identiﬁcation, 35
T
Transfer-function methods, 54
U
Unmanned surface marine vehicle, 17
W
Weighted least squares, 105
Wind turbine, 15, 387
Winding shaping process, 309

