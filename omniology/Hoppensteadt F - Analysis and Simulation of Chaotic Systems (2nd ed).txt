Analysis and Simulation
of Chaotic Systems,
Second Edition
Frank C. Hoppensteadt
Springer





Acknowledgments
I thank all of the teachers and students whom I have encountered, and I
thank my parents, children, and pets for the many insights into life and
mathematics that they have given me—often unsolicited. I have published
parts of this book in the context of research or expository papers done
with co-authors, and I thank them for the opportunity to have worked
with them. The work presented here was mostly derived by others, al-
though parts of it I was fortunate enough to uncover for the ﬁrst time. My
work has been supported by various agencies and institutions including the
University of Wisconsin, New York University and the Courant Institute of
Mathematical Sciences, the University of Utah, Michigan State University,
Arizona State University, the National Science Foundation, ARO, ONR,
and the AFOSR. This investment in me has been greatly appreciated, and
the work in this book describes some outcomes of that investment. I thank
these institutions for their support.
The preparation of this second edition was made possible through the
help of Linda Arneson and Tatyana Izhikevich. My thanks to them for their
help.

Contents
Acknowledgments
v
Introduction
xiii
1
Linear Systems
1
1.1
Examples of Linear Oscillators . . . . . . . . . . . . . . .
1
1.1.1
Voltage-Controlled Oscillators . . . . . . . . . . .
2
1.1.2
Filters
. . . . . . . . . . . . . . . . . . . . . . . .
3
1.1.3
Pendulum with Variable Support Point . . . . . .
4
1.2
Time-Invariant Linear Systems . . . . . . . . . . . . . . .
5
1.2.1
Functions of Matrices . . . . . . . . . . . . . . . .
6
1.2.2
exp(At)
. . . . . . . . . . . . . . . . . . . . . . .
7
1.2.3
Laplace Transforms of Linear Systems
. . . . . .
9
1.3
Forced Linear Systems with Constant Coeﬃcients . . . .
10
1.4
Linear Systems with Periodic Coeﬃcients . . . . . . . . .
12
1.4.1
Hill’s Equation
. . . . . . . . . . . . . . . . . . .
14
1.4.2
Mathieu’s Equation . . . . . . . . . . . . . . . . .
15
1.5
Fourier Methods . . . . . . . . . . . . . . . . . . . . . . .
18
1.5.1
Almost-Periodic Functions
. . . . . . . . . . . .
18
1.5.2
Linear Systems with Periodic Forcing . . . . . . .
21
1.5.3
Linear Systems with Quasiperiodic Forcing . . . .
22
1.6
Linear Systems with Variable Coeﬃcients: Variation of
Constants Formula
. . . . . . . . . . . . . . . . . . . . .
23
1.7
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . .
24

viii
Contents
2
Dynamical Systems
27
2.1
Systems of Two Equations . . . . . . . . . . . . . . . . .
28
2.1.1
Linear Systems
. . . . . . . . . . . . . . . . . . .
28
2.1.2
Poincar´e and Bendixson’s Theory . . . . . . . . .
29
2.1.3
x′′ + f(x)x′ + g(x) = 0 . . . . . . . . . . . . . . .
32
2.2
Angular Phase Equations . . . . . . . . . . . . . . . . . .
35
2.2.1
A Simple Clock: A Phase Equation on T 1
. . . .
37
2.2.2
A Toroidal Clock: Denjoy’s Theory . . . . . . . .
38
2.2.3
Systems of N (Angular) Phase Equations
. . . .
40
2.2.4
Equations on a Cylinder: PLL . . . . . . . . . . .
40
2.3
Conservative Systems . . . . . . . . . . . . . . . . . . . .
42
2.3.1
Lagrangian Mechanics
. . . . . . . . . . . . . . .
42
2.3.2
Plotting Phase Portraits Using Potential Energy .
43
2.3.3
Oscillation Period of x′′ + Ux(x) = 0
. . . . . . .
46
2.3.4
Active Transmission Line . . . . . . . . . . . . . .
47
2.3.5
Phase-Amplitude (Angle-Action) Coordinates . .
49
2.3.6
Conservative Systems with N Degrees of Freedom
52
2.3.7
Hamilton–Jacobi Theory . . . . . . . . . . . . . .
53
2.3.8
Liouville’s Theorem . . . . . . . . . . . . . . . . .
56
2.4
Dissipative Systems . . . . . . . . . . . . . . . . . . . . .
57
2.4.1
van der Pol’s Equation . . . . . . . . . . . . . . .
57
2.4.2
Phase Locked Loop . . . . . . . . . . . . . . . . .
57
2.4.3
Gradient Systems and the Cusp Catastrophe . . .
62
2.5
Stroboscopic Methods . . . . . . . . . . . . . . . . . . . .
65
2.5.1
Chaotic Interval Mappings . . . . . . . . . . . . .
66
2.5.2
Circle Mappings . . . . . . . . . . . . . . . . . . .
71
2.5.3
Annulus Mappings
. . . . . . . . . . . . . . . . .
74
2.5.4
Hadamard’s Mappings of the Plane . . . . . . . .
75
2.6
Oscillations of Equations with a Time Delay . . . . . . .
78
2.6.1
Linear Spline Approximations . . . . . . . . . . .
80
2.6.2
Special Periodic Solutions
. . . . . . . . . . . . .
81
2.7
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . .
83
3
Stability Methods for Nonlinear Systems
91
3.1
Desirable Stability Properties of Nonlinear Systems . . .
92
3.2
Linear Stability Theorem . . . . . . . . . . . . . . . . . .
94
3.2.1
Gronwall’s Inequality . . . . . . . . . . . . . . . .
95
3.2.2
Proof of the Linear Stability Theorem
. . . . . .
96
3.2.3
Stable and Unstable Manifolds . . . . . . . . . . .
97
3.3
Liapunov’s Stability Theory . . . . . . . . . . . . . . . .
99
3.3.1
Liapunov’s Functions . . . . . . . . . . . . . . . .
99
3.3.2
UAS of Time-Invariant Systems . . . . . . . . . .
100
3.3.3
Gradient Systems . . . . . . . . . . . . . . . . . .
101
3.3.4
Linear Time-Varying Systems . . . . . . . . . . .
102
3.3.5
Stable Invariant Sets . . . . . . . . . . . . . . . .
103

Contents
ix
3.4
Stability Under Persistent Disturbances . . . . . . . . . .
106
3.5
Orbital Stability of Free Oscillations
. . . . . . . . . . .
108
3.5.1
Deﬁnitions of Orbital Stability . . . . . . . . . . .
109
3.5.2
Examples of Orbital Stability
. . . . . . . . . . .
110
3.5.3
Orbital Stability Under Persistent Disturbances .
111
3.5.4
Poincar´e’s Return Mapping
. . . . . . . . . . . .
111
3.6
Angular Phase Stability
. . . . . . . . . . . . . . . . . .
114
3.6.1
Rotation Vector Method . . . . . . . . . . . . . .
114
3.6.2
Huygen’s Problem . . . . . . . . . . . . . . . . . .
116
3.7
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . .
118
4
Bifurcation and Topological Methods
121
4.1
Implicit Function Theorems
. . . . . . . . . . . . . . . .
121
4.1.1
Fredholm’s Alternative for Linear Problems
. . .
122
4.1.2
Nonlinear Problems: The Invertible Case . . . . .
126
4.1.3
Nonlinear Problems: The Noninvertible Case . . .
128
4.2
Solving Some Bifurcation Equations . . . . . . . . . . . .
129
4.2.1
q = 1: Newton’s Polygons
. . . . . . . . . . . . .
130
4.3
Examples of Bifurcations . . . . . . . . . . . . . . . . . .
132
4.3.1
Exchange of Stabilities . . . . . . . . . . . . . . .
132
4.3.2
Andronov–Hopf Bifurcation
. . . . . . . . . . . .
133
4.3.3
Saddle-Node on Limit Cycle Bifurcation
. . . . .
134
4.3.4
Cusp Bifurcation Revisited . . . . . . . . . . . . .
134
4.3.5
Canonical Models and Bifurcations . . . . . . . .
135
4.4
Fixed-Point Theorems
. . . . . . . . . . . . . . . . . . .
136
4.4.1
Contraction Mapping Principle
. . . . . . . . . .
136
4.4.2
Wazewski’s Method . . . . . . . . . . . . . . . . .
138
4.4.3
Sperner’s Method . . . . . . . . . . . . . . . . . .
141
4.4.4
Measure-Preserving Mappings . . . . . . . . . . .
142
4.5
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . .
142
5
Regular Perturbation Methods
145
5.1
Perturbation Expansions . . . . . . . . . . . . . . . . . .
147
5.1.1
Gauge Functions: The Story of o, O . . . . . . . .
147
5.1.2
Taylor’s Formula
. . . . . . . . . . . . . . . . . .
148
5.1.3
Pad´e’s Approximations
. . . . . . . . . . . . . .
148
5.1.4
Laplace’s Methods
. . . . . . . . . . . . . . . . .
150
5.2
Regular Perturbations of Initial Value Problems . . . . .
152
5.2.1
Regular Perturbation Theorem
. . . . . . . . . .
152
5.2.2
Proof of the Regular Perturbation Theorem
. . .
153
5.2.3
Example of the Regular Perturbation Theorem
.
155
5.2.4
Regular Perturbations for 0 ≤t < ∞. . . . . . .
155
5.3
Modiﬁed Perturbation Methods for Static States . . . . .
157
5.3.1
Nondegenerate Static-State Problems Revisited .
158
5.3.2
Modiﬁed Perturbation Theorem . . . . . . . . . .
158

x
Contents
5.3.3
Example: q = 1 . . . . . . . . . . . . . . . . . . .
160
5.4
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . .
161
6
Iterations and Perturbations
163
6.1
Resonance . . . . . . . . . . . . . . . . . . . . . . . . . .
164
6.1.1
Formal Perturbation Expansion of Forced Oscilla-
tions . . . . . . . . . . . . . . . . . . . . . . . . .
166
6.1.2
Nonresonant Forcing . . . . . . . . . . . . . . . .
167
6.1.3
Resonant Forcing . . . . . . . . . . . . . . . . . .
170
6.1.4
Modiﬁed Perturbation Method for Forced Oscilla-
tions . . . . . . . . . . . . . . . . . . . . . . . . .
172
6.1.5
Justiﬁcation of the Modiﬁed Perturbation Method
173
6.2
Duﬃng’s Equation
. . . . . . . . . . . . . . . . . . . . .
174
6.2.1
Modiﬁed Perturbation Method . . . . . . . . . . .
175
6.2.2
Duﬃng’s Iterative Method . . . . . . . . . . . . .
176
6.2.3
Poincar´e–Linstedt Method . . . . . . . . . . . . .
177
6.2.4
Frequency-Response Surface . . . . . . . . . . . .
178
6.2.5
Subharmonic Responses of Duﬃng’s Equation . .
179
6.2.6
Damped Duﬃng’s Equation . . . . . . . . . . . .
181
6.2.7
Duﬃng’s Equation with Subresonant Forcing
. .
182
6.2.8
Computer Simulation of Duﬃng’s Equation
. . .
184
6.3
Boundaries of Basins of Attraction
. . . . . . . . . . . .
186
6.3.1
Newton’s Method and Chaos . . . . . . . . . . . .
187
6.3.2
Computer Examples
. . . . . . . . . . . . . . . .
188
6.3.3
Fractal Measures
. . . . . . . . . . . . . . . . . .
190
6.3.4
Simulation of Fractal Curves . . . . . . . . . . . .
191
6.4
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . .
194
7
Methods of Averaging
195
7.1
Averaging Nonlinear Systems
. . . . . . . . . . . . . . .
199
7.1.1
The Nonlinear Averaging Theorem . . . . . . . .
200
7.1.2
Averaging Theorem for Mean-Stable Systems
. .
202
7.1.3
A Two-Time Scale Method for the Full Problem .
203
7.2
Highly Oscillatory Linear Systems . . . . . . . . . . . . .
204
7.2.1
dx/dt = εB(t)x . . . . . . . . . . . . . . . . . . .
205
7.2.2
Linear Feedback System . . . . . . . . . . . . . .
206
7.2.3
Averaging and Laplace’s Method
. . . . . . . . .
207
7.3
Averaging Rapidly Oscillating Diﬀerence Equations . . .
207
7.3.1
Linear Diﬀerence Schemes . . . . . . . . . . . . .
210
7.4
Almost Harmonic Systems . . . . . . . . . . . . . . . . .
214
7.4.1
Phase-Amplitude Coordinates . . . . . . . . . . .
215
7.4.2
Free Oscillations . . . . . . . . . . . . . . . . . . .
216
7.4.3
Conservative Systems . . . . . . . . . . . . . . . .
219
7.5
Angular Phase Equations . . . . . . . . . . . . . . . . . .
223
7.5.1
Rotation Vector Method . . . . . . . . . . . . . .
224

Contents
xi
7.5.2
Rotation Numbers and Period Doubling Bifurca-
tions . . . . . . . . . . . . . . . . . . . . . . . . .
227
7.5.3
Euler’s Forward Method for Numerical Simulation
227
7.5.4
Computer Simulation of Rotation Vectors
. . . .
229
7.5.5
Near Identity Flows on S1 × S1 . . . . . . . . . .
231
7.5.6
KAM Theory
. . . . . . . . . . . . . . . . . . . .
233
7.6
Homogenization . . . . . . . . . . . . . . . . . . . . . . .
234
7.7
Computational Aspects of Averaging . . . . . . . . . . .
235
7.7.1
Direct Calculation of Averages . . . . . . . . . . .
236
7.7.2
Extrapolation . . . . . . . . . . . . . . . . . . . .
237
7.8
Averaging Systems with Random Noise . . . . . . . . . .
238
7.8.1
Axioms of Probability Theory . . . . . . . . . . .
238
7.8.2
Random Perturbations . . . . . . . . . . . . . . .
241
7.8.3
Example of a Randomly Perturbed System . . . .
242
7.9
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . .
243
8
Quasistatic-State Approximations
249
8.1
Some Geometrical Examples of Singular Perturbation
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . .
254
8.2
Quasistatic-State Analysis of a Linear Problem
. . . . .
257
8.2.1
Quasistatic Problem
. . . . . . . . . . . . . . . .
258
8.2.2
Initial Transient Problem . . . . . . . . . . . . . .
261
8.2.3
Composite Solution . . . . . . . . . . . . . . . . .
263
8.2.4
Volterra Integral Operators with Kernels Near δ .
264
8.3
Quasistatic-State Approximation for Nonlinear Initial Value
Problems . . . . . . . . . . . . . . . . . . . . . . . . . . .
264
8.3.1
Quasistatic Manifolds . . . . . . . . . . . . . . . .
265
8.3.2
Matched Asymptotic Expansions
. . . . . . . . .
268
8.3.3
Construction of QSSA
. . . . . . . . . . . . . . .
270
8.3.4
The Case T = ∞. . . . . . . . . . . . . . . . . .
271
8.4
Singular Perturbations of Oscillations . . . . . . . . . . .
273
8.4.1
Quasistatic Oscillations . . . . . . . . . . . . . . .
274
8.4.2
Nearly Discontinuous Oscillations . . . . . . . . .
279
8.5
Boundary Value Problems . . . . . . . . . . . . . . . . .
281
8.6
Nonlinear Stability Analysis near Bifurcations . . . . . .
284
8.6.1
Bifurcating Static States . . . . . . . . . . . . . .
284
8.6.2
Nonlinear Stability Analysis of Nonlinear Oscilla-
tions . . . . . . . . . . . . . . . . . . . . . . . . .
287
8.7
Explosion Mode Analysis of Rapid Chemical Reactions .
289
8.8
Computational Schemes Based on QSSA . . . . . . . . .
292
8.8.1
Direct Calculation of x0(h), y0(h) . . . . . . . . .
293
8.8.2
Extrapolation Method
. . . . . . . . . . . . . . .
294
8.9
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . .
295
Supplementary Exercises
301

xii
Contents
References
303
Index
311

Introduction
This book describes aspects of mathematical modeling, analysis, computer
simulation, and visualization that are widely used in the mathematical
sciences and engineering.
Scientists often use ordinary language models to describe observations
of physical and biological phenomena. These are precise where data are
known and appropriately imprecise otherwise. Ordinary language modelers
carve away chunks of the unknown as they collect more data. On the other
hand, mathematical modelers formulate minimal models that produce re-
sults similar to what is observed. This is the Ockham’s razor approach,
where simpler is better, with the caution from Einstein that “Everything
should be made as simple as possible, but not simpler.”
The success of mathematical models is diﬃcult to explain. The same
tractable mathematical model describes such diverse phenomena as when
an epidemic will occur in a population or when chemical reactants will
begin an explosive chain-branched reaction, and another model describes
the motion of pendulums, the dynamics of cryogenic electronic devices, and
the dynamics of muscle contractions during childbirth.
Ordinary language models are necessary for the accumulation of experi-
mental knowledge, and mathematical models organize this information, test
logical consistency, predict numerical outcomes, and identify mechanisms
and parameters that characterize them.
Often mathematical models are quite complicated, but simple approx-
imations can be used to extract important information from them. For
example, the mechanisms of enzyme reactions are complex, but they can
be described by a single diﬀerential equation (the Michaelis–Menten equa-

xiv
Introduction
tion [14]) that identiﬁes two useful parameters (the saturation constant and
uptake velocity) that are used to characterize reactions. So this modeling
and analysis identiﬁes what are the critical data to collect. Another example
is Semenov’s theory of explosion limits [128], in which a single diﬀerential
equation can be extracted from over twenty chemical rate equations model-
ing chain-branched reactions to describe threshold combinations of pressure
and temperature that will result in an explosion.
Mathematical analysis includes geometrical forms, such as hyperbolic
structures, phase planes, and isoclines, and analytical methods that derive
from calculus and involve iterations, perturbations, and integral transforms.
Geometrical methods are elegant and help us visualize dynamical processes,
but analytical methods can deal with a broader range of problems, for ex-
ample, those including random perturbations and forcing over unbounded
time horizons. Analytical methods enable us to calculate precisely how
solutions depend on data in the model.
As humans, we occupy regions in space and time that are between very
small and very large and very slow and very fast. These intermediate
space and time scales are perceptible to us, but mathematical analysis
has helped us to perceive scales that are beyond our senses. For example,
it is very diﬃcult to “understand” electric and magnetic ﬁelds. Instead,
our intuition is based on solutions to Maxwell’s equations. Fluid ﬂows are
quite complicated and usually not accessible to experimental observations,
but our knowledge is shaped by the solutions of the Navier–Stokes equa-
tions. We can combine these multiple time and space scales together with
mathematical methods to unravel such complex dynamics. While realistic
mathematical models of physical or biological phenomena can be highly
complicated, there are mathematical methods that extract simpliﬁcations
to highlight and elucidate the underlying process. In some cases, engineers
use these representations to design novel and useful things.
We also live with varying levels of logical rigor in the mathematical
sciences that range from complete detailed proofs in sharply deﬁned math-
ematical structures to using mathematics to probe other structures where
its validity is not known.
The mathematical methods presented and used here grew from several
diﬀerent scientiﬁc sources. Work of Newton and Leibniz was partly rigor-
ous and partly speculative. The G¨ottingen school of Gauss, Klein, Hilbert,
and Courant was carried forward in the U.S. by Fritz John, James Stoker,
and Kurt Friedrichs, and they and their students developed many impor-
tant ideas that reached beyond rigorous diﬀerential equation models and
studied important problems in continuum mechanics and wave propaga-
tion. Russian and Ukrainian workers led by Liapunov, Bogoliubov, Krylov,
and Kolmogorov developed novel approaches to problems of bifurcation
and stability theory, statistical physics, random processes, and celestial
mechanics. Fourier’s and Poincar´e’s work on mathematical physics and dy-
namical systems continues to provide new directions for us, and the U.S.

Introduction
xv
mathematicians G. D. Birkhoﬀand N. Wiener and their students have con-
tributed to these topics as well. Analytical and geometrical perturbation
and iteration methods were important to all of this work, and all involved
diﬀerent levels of rigor.
Computer simulations have enabled us to study models beyond the reach
of mathematical analysis. For example, mathematical methods can provide
a language for modeling and some information, such as existence, unique-
ness, and stability, about their solutions. And then well executed computer
algorithms and visualizations provide further qualitative and quantitative
information about solutions. The computer simulations presented here de-
scribe and illustrate several critical computer experiments that produced
important and interesting results.
Analysis and computer simulations of mathematical models are im-
portant parts of understanding physical and biological phenomena. The
knowledge created in modeling, analysis, simulation, and visualization
contributes to revealing the secrets they embody.
The ﬁrst two chapters present background material for later topics in
the book, and they are not intended to be complete presentations of Linear
Systems (Chapter 1) and Dynamical Systems (Chapter 2). There are many
excellent texts and research monographs dealing with these topics in great
detail, and the reader is referred to them for rigorous developments and
interesting applications. In fact, to keep this book to a reasonable size
while still covering the wide variety of topics presented here, detailed proofs
are not usually given, except in cases where there are minimal notational
investments and the proofs give readily accessible insight into the meaning
of the theorem. For example, I see no reason to present the details of proofs
for the Implicit Function Theorem or for the main results of Liapunov’s
stability theory. Still, these results are central to this book. On the other
hand, the complete proofs of some results, like the Averaging Theorem for
Diﬀerence Equations, are presented in detail.
The remaining chapters of this book present a variety of mathematical
methods for solving problems that are sorted by behavior (e.g., bifurca-
tion, stability, resonance, rapid oscillations, and fast transients). However,
interwoven throughout the book are topics that reappear in many diﬀer-
ent, often surprising, incarnations. For example, the cusp singularity and
the property of stability under persistent disturbances arise often. The
following list describes cross-cutting mathematical topics in this book.
1. Perturbations. Even the words used here cause some problems. For
example, perturb means to throw into confusion, but its purpose here is
to relate to a simpler situation. While the perturbed problem is confused,
the unperturbed problem should be understandable. Perturbations usually
involve the identiﬁcation of parameters, which unfortunately is often mis-
understood by students to be perimeters from their studies of geometry.
Done right, parameters should be dimensionless numbers that result from
the model, such as ratios of eigenvalues of linear problems. Parameter iden-

xvi
Introduction
tiﬁcation in problems might involve diﬃcult mathematical preprocessing in
applications. However, once this is done, basic perturbation methods can
be used to understand the perturbed problem in terms of solutions to the
unperturbed problem. Basic perturbation methods used here are Taylor’s
method for approximating a smooth function by a polynomial and Laplace’s
method for the approximation of integral formulas. These lead to the im-
plicit function theorem and variants of it, and to matching, averaging, and
central-limit theorems. Adaptations of these methods to various other prob-
lems are described here. Two particularly useful perturbation methods are
the method of averaging and the quasistatic-state approximation. These
are dealt with in detail in Chapters 7 and 8, respectively.
2. Iterations. Iterations are mathematical procedures that begin with a
state vector and change it according to some rule. The same rule is applied
to the new state, and so on, and a sequence of iterates of the rule results.
Fra Fibonacci in 1202 introduced a famous iteration that describes the
dynamics of an age-structured population. In Fibonacci’s case, a population
was studied, geometric growth was deduced, and the results were used to
describe the compounding of interest on investments.
Several iterations are studied here. First, Newton’s method, which con-
tinues to be the paradigm for iteration methods, is studied. Next, we study
Duﬃng’s iterative method and compare the results with similar ones de-
rived using perturbation methods. Finally, we study chaotic behavior that
often occurs when quite simple functions are iterated. There has been a
controversy of sorts between iterationists and perturbationists; each has its
advocates and each approach is useful.
3. Chaos. The term was introduced in its present connotation by Yorke
and Li in 1976 [101, 48]. It is not a precisely deﬁned concept, but it occurs in
various physical and religious settings. For example, Boltzmann used it in a
sense that eventually resulted in ergodic theories for dynamical systems and
random processes, and Poincar´e had a clear image of the chaotic behavior
of dynamical systems that occurs when stable and unstable manifolds cross.
The book of Genesis begins with chaos, and philosophical discussions about
it and randomness continue to this day. For the most part, the word chaos
is used here to indicate behavior of solutions to mathematical models that
is highly irregular and usually unexpected. We study several problems that
are known to exhibit chaotic behavior and present methods for uncovering
and describing this behavior. Related to chaotic systems are the following:
a. Almost periodic functions and generalized Fourier analysis [11, 140].
b. Poincar´e’s stroboscopic mappings, which are based on snapshots of
a solution at ﬁxed time intervals—“Chaos, illumined by ﬂashes of
lightning” [from Oscar Wilde in another context] [111].

Introduction
xvii
c. Fractals, which are space ﬁlling curves that have been studied since
Weierstrass, Hausdorﬀ, Richardson, and Peano a century ago and
more recently by Mandelbrodt [107].
d. Catastrophes, which were introduced by Ren´e Thom [133] in the
1960s.
e. Fluid turbulence that occurs in convective instabilities described by
Lorenz and Keller [104].
f. Irregular ecological dynamics studied by Ricker and May [48].
g. Random processes, including the Law of Large Numbers and ergodic
and other limit theorems [82].
These and many other useful and interesting aspects of chaos are described
here.
4. Oscillations. Oscillators play fundamental roles in our lives—
“discontented pendulums that we are” [R.W. Emerson]. For example, most
of the cells in our bodies live an oscillatory life in an oscillating chemical
environment. The study of pendulums gives great insight into oscillators,
and we focus a signiﬁcant eﬀort here in studying pendulums and similar
physical and electronic devices.
One of the most interesting aspects of oscillators is their tendency to syn-
chronize with other nearby oscillators. This had been observed by musicians
dating back at least to the time of Aristotle, and eventually it was addressed
as a mathematical problem by Huygens in the 17th century and Korteweg
around 1900 [142]. This phenomenon is referred to as phase locking, and
it now serves as a fundamental ingredient in the design of communications
and computer-timing circuits. Phase locking is studied here for a variety of
diﬀerent oscillator populations using the rotation vector method. For ex-
ample, using the VCON model of a nerve cell, we model neural networks as
being ﬂows on high-dimensional tori. Phase locking occurs when the ﬂow
reduces to a knot on the torus for the original and all nearby systems.
5. Stability. The stability of physical systems is often described using
energy methods. These methods have been adapted to more general dy-
namical systems by Liapunov and others. Although we do study linear and
Liapunov stability properties of systems here, the most important stability
concept used here is that of stability under persistent disturbances. This
idea explains why mathematical results obtained for minimal models can
often describe behavior of systems that are operating in noisy environ-
ments. For example, think of a metal bowl having a lowest point in it. A
marble placed in the bowl will eventually move to the minimum point. If
the bowl is now dented with many small craters or if small holes are put
in it, the marble will still move to near where the minimum of the original
bowl had been, and the degree of closeness can be determined from the
size of the dents and holes. The dents and the holes introduce irregular

xviii
Introduction
disturbances to the system, but the dynamics of the marble are similar in
both the simple (ideal) bowl and the imperfect (realized) bowl.
Stability under persistent disturbances is sometimes confused with struc-
tural stability. The two are quite diﬀerent. Structural stability is a concept
introduced to describe systems whose behavior does not change when the
system is slightly perturbed. Hyperbolic structures are particularly im-
portant examples of this. However, it is the changes in behavior when a
system is slightly perturbed that are often the only things observable in ex-
periments: Did something change? Stability under persistent disturbances
carries through such changes. For example, the diﬀerential equation
˙x = ax −x3 + εf(t),
where f is bounded and integrable, ε is small, and a is another parameter,
occurs in many models. When ε = 0 and a increases through the value
a = 0, the structure of static state solutions changes dramatically: For
a < 0, there is only one (real) static state, x = 0; but for a > 0 there
are three: x = ±√a are stable static states, and x = 0 is an unstable
one. This problem is important in applications, but it is not structurally
stable at a = 0. Still, there is a Liapunov function for a neighborhood of
x = 0, a = 0, ε = 0, namely, V (x) = x2. So, the system is stable under
persistent disturbances. Stability under persistent disturbances is based on
results of Liapunov, Malkin, and Massera that we study here.
6. Computer simulation. The two major topics studied in this book are
mathematical analysis and computer simulation of mathematical models.
Each has its uses, its strengths, and its deﬁciencies. Our mathematical anal-
ysis builds mostly on perturbation and iteration methods: They are often
diﬃcult to use, but once they are understood, they can provide information
about systems that is not otherwise available. Understanding them for the
examples presented here also lays a basis for one to use computer packages
such as Mathematica, Matlab or Maple to construct perturbation expan-
sions. Analytical methods can explain regular behavior of noisy systems,
they can simplify complicated systems with ﬁdelity to real behavior, and
they can go beyond the edges of practical computability in dealing with
fast processes (e.g., rapid chemical reactions) and small quantities (e.g.,
trace-element calculations).
Computer simulation replaces much of the work formerly done by mathe-
maticians (often as graduate students), and sophisticated software packages
are increasing simulation power. Simulations illustrate solutions of a math-
ematical model by describing a sample trajectory, or sample path, of the
process. Sample paths can be processed in a variety of ways—plotting, cal-
culating ensemble statistics, and so on. Simulations do not describe the
dependence of solutions on model parameters, nor are their stability, ac-
curacy, or reliability always assured. They do not deal well with chaotics
or unexpected catastrophes—irregular or unexpected rapid changes in a
solution—and it is usually diﬃcult to determine when chaos lurks nearby.

Introduction
xix
Mathematical analysis makes possible computer simulations; conversely,
computer simulations can help with mathematical analysis. New computer-
based methods are being derived with parallelization of computations,
simpliﬁcation of models through automatic preprocessing, and so on, and
the future holds great promise for combined work of mathematical and
computer-based analysis. There have been many successes to date, for
example the discovery and analysis of solitons.
The material in this book is not presented in order of increasing diﬃculty.
The ﬁrst two chapters provide background information for the last six chap-
ters, where oscillation, iteration, and perturbation techniques and examples
are developed. We begin with three examples that are useful throughout
the rest of the book. These are electrical circuits and pendulums. Next,
we describe linear systems and spectral decomposition methods for solv-
ing them. These involve ﬁnding eigenvalues of matrices and deducing how
they are involved in the solution of a problem. In the second chapter we
study dynamical systems, beginning with descriptions of how periodic or
almost periodic solutions can be found in nonlinear dynamical systems
using methods ranging from Poincar´e and Bendixson’s method for two dif-
ferential equations to entropy methods for nonlinear iterations. The third
chapter presents stability methods for studying nonlinear systems. Partic-
ularly important for later work is the method of stability under persistent
disturbances.
The remainder of the book deals with methods of approximation and
simulation. First, some useful algebraic and topological methods are de-
scribed, followed by a study of implicit function theorems and modiﬁcations
and generalizations of them. These are applied to several bifurcation prob-
lems. Then, regular perturbation problems are studied, in which a small
parameter is identiﬁed and the solutions are constructed directly using the
parameter. This is illustrated by several important problems in nonlinear
oscillations, including Duﬃng’s equation and nonlinear resonance.
In Chapter 7 the method of averaging is presented. This is one of the most
interesting techniques in all of mathematics. It is closely related to Fourier
analysis, to the Law of Large Numbers in probability theory, and to the
dynamics of physical and biological systems in oscillatory environments.
We describe here multitime methods, Bogoliubov’s transformation, and
integrable systems methods.
Finally, the method of quasistatic-state approximations is presented.
This method has been around in various useful forms since 1900, and it
has been called by a variety of names—the method of matched asymptotic
expansions being among the most civil. It has been derived in some quite
complicated ways and in some quite simple ones. The approach taken here
is of quasistatic manifolds, which has a clear geometric ﬂavor that can aid
intuition. It combines the geometric approach of Hadamard with the an-

xx
Introduction
alytical methods of Perron to construct stable and unstable manifolds for
systems that might involve irregular external forcing.
In rough terms, averaging applies when a system involves rapid oscilla-
tions that are slowly modulated, and quasistatic-state approximations are
used when solutions decay rapidly to a manifold on which motions are
slower. When problems arise where both kinds of behavior occur, they can
often be unraveled. But there are many important problems where neither
of these methods apply, including diﬀraction by crossed wires in electro-
magnetic theory, stagnation points in ﬂuid ﬂows, ﬂows in domains with
sharp corners, and problems with intermittent rapid time scales.
I have taught courses based on this book in a variety of ways depend-
ing on the time available and the background of the students. When the
material is taught as a full year course for graduate students in mathe-
matics and engineering, I cover the whole book. Other times I have taken
more advanced students who have had a good course in ordinary diﬀerential
equations directly to Chapters 4, 5, 6, 7, and 8. A one quarter course is pos-
sible using, for example, Chapters 1, 7, and 8. For the most part Chapters 1
and 2 are intended as background material for the later chapters, although
they contain some important computer simulations that I like to cover in
all of my presentations of this material. A course in computer simulations
could deal with sections from Chapters 2, 4, 7, and 8. The exercises also
contain several simulations that have been interesting and useful.
The exercises are graded roughly in increasing diﬃculty in each chapter.
Some are quite straightforward illustrations of material in the text, and
others are quite lengthy projects requiring extensive mathematical analysis
or computer simulation. I have tried to warn readers about more diﬃcult
problems with an asterisk where appropriate.
Students must have some degree of familiarity with methods of ordinary
diﬀerential equations, for example, from a course based on Coddington
and Levinson [24], Hale [58], or Hirsch and Smale [68]. They should also be
competent with matrix methods and be able to use a reference text such as
Gantmacher [46]. Some familiarity with Interpretation of Dreams [45] has
also been found to be useful by some students.
Frank C. Hoppensteadt
Paradise Valley, Arizona
June 1999

1
Linear Systems
A linear system of ordinary diﬀerential equations has the form
dx
dt = A(t)x + f(t).
Given an N-dimensional vector f and an N × N matrix A(t) of functions
of t, we seek a solution vector x(t). We write x, f ∈EN and A ∈EN×N
and sometimes x′ = dx/dt or ˙x = dx/dt.
Many design methods in engineering are based on linear systems. Also,
most of the methods used to study nonlinear problems grew out of methods
for linear problems, so mastery of linear problems is essential for under-
standing nonlinear ones. Section 1.1 presents several examples of physical
systems that are analyzed in this book. In Sections 1.2 and 1.3 we study
linear systems where A is a matrix of constants. In Sections 1.4 and 1.5
we study systems where A is a periodic or almost-periodic matrix, and in
Section 1.6 we consider general linear systems.
1.1
Examples of Linear Oscillators
The following examples illustrate typical problems in oscillations and per-
turbations, and they are referred to throughout this book. The ﬁrst two
examples describe electrical circuits and the third a mechanical system.

2
1.
Linear Systems
 V(x)
 V in
 VCO
Figure 1.1. A voltage-controlled oscillator. The controlling voltage Vin is applied
to the circuit, and the output has a ﬁxed periodic waveform (V ) whose phase x
is modulated by Vin.
1.1.1
Voltage-Controlled Oscillators
Modern integrated circuit technology has had a surprising impact on math-
ematical models. Rather than the models becoming more complicated
as the number of transistors on a chip increases, the mathematics in
many cases has become dramatically simpler, usually by design. Voltage-
controlled oscillators (VCOs) illustrate this nicely. A VCO is an electronic
device that puts out a voltage in a ﬁxed waveform, say V , but with a
variable phase x that is controlled by an input voltage Vin. The device is
described by the circuit diagram in Figure 1.1. The voltages in this and
other ﬁgures are measured relative to a common ground that is not shown.
The output waveform V might be a ﬁxed period square wave, a triangular
wave, or a sinusoid, but its phase x is the unknown. VCOs are made up of
many transistors, and a detailed model of the circuit is quite complicated
[83, 65]. However, there is a simple input–output relation for this device:
The input voltage Vin directly modulates the output phase as described by
the equation
dx
dt = ω + Vin,
where the constant ω is called the center frequency. The center frequency
is sustained by a separate (ﬁxed supply) voltage in the device, and it can
be changed by tuning resistances in the VCO. Thus, a simple diﬀerential
equation models this device. The solution for x is found by integrating this
equation:
x(t) = x(0) + ωt +
 t
0
Vin(s)ds.
The voltage V (x) is observable in this circuit, and the higher the input
voltage or the center frequency is, the faster V will oscillate.
Equations like this one for x play a central role in the theory of nonlinear
oscillations. In fact, a primary goal is often to transform a given system
into phase-and-amplitude coordinates, which is usually diﬃcult to carry
out. This model is given in terms of phase and serves as an example of how
systems are studied once they are in phase and amplitude variables.

1.1. Examples of Linear Oscillators
3
 V in
 V
 L
 R
 C
 I
 Ground
Figure 1.2. An RLC circuit.
1.1.2
Filters
Filters are electrical circuits composed of resistors, inductors, and capaci-
tors. Figure 1.2 shows an RLC circuit, in which Vin, R, L, and C are given,
and the unknowns are the output voltage (V ) and the current (I) through
the circuit. The circuit is described by the mathematical equation
C dV
dt
=
I
LdI
dt + RI
=
Vin −V.
The ﬁrst equation describes the accumulation of charge in the capacitor;
the second relates the voltage across the inductor and the voltage across the
resistor (Ohm’s Law) to the total voltage Vin −V . Using the ﬁrst equation
to eliminate I from the model results in a single second-order equation:
LC d2V
dt2 + RC dV
dt + V = Vin.
Thus, the ﬁrst-order system for V and I can be rewritten as a second-order
equation for the scalar V .
The RLC circuit is an example of a ﬁlter. In general, ﬁlters are circuits
whose models have the form
an
dnV
dtn + an−1
dn−1V
dtn−1 + · · · + a0V = bm
dmW
dtm + · · · + b0W,
where W is the input voltage, V is the output voltage, and the constants
{ai} and {bi} characterize various circuit elements. Once W is given, this
equation must be solved for V .
Filters can be described in a concise form: Using the notation p = d/dt,
sometimes referred to as Heaviside’s operator, we can write the ﬁlter
equation as
V = H(p)W,
where the function H is a rational function of p:
H = (bmpm + · · · + b0)
(anpn + · · · + a0) .

4
1.
Linear Systems
This notation is made precise later using Laplace transforms, but for now
it is taken to be a shorthand notation for the input–output relation of the
ﬁlter. The function H is called the ﬁlter’s transfer function.
In summary, ﬁlters are circuits whose models are linear nth-order ordi-
nary diﬀerential equations. They can be written concisely using the transfer
function notation, and they provide many examples later in this book.
1.1.3
Pendulum with Variable Support Point
Simple pendulums are described by equations that appear in a surprising
number of diﬀerent applications in physics and biology. Consider a pen-
dulum of length L supporting a mass m that is suspended from a point
with vertical coordinate V (t) and horizontal coordinate H(t) as shown in
Figure 1.3. The action integral for this mechanical system is deﬁned by
 b
a
mL2
2
dx
dt
2
−
d2V
dt2 + g

mL(1 −cos x) −d2H
dt2 mL sin x

dt,
where g is the acceleration of gravity. Hamilton’s principle [28] shows that
an extremum of this integral is attained by the solution x(t) of the equation
Ld2x
dt2 +
d2V
dt2 + g

sin x + d2H
dt2 cos x = 0,
which is the Euler–Lagrange equation for functions x(t) that make the
action integral stationary.
Furthermore, a pendulum in a resistive medium to which a torque is
applied at the support point is described by
Ld2x
dt2 + f dx
dt +
d2V
dt2 + g

sin x + d2H
dt2 cos x = I,
where f is the coeﬃcient of friction and I is the applied torque.
For x near zero, sin x ≈x and cos x ≈1, so the equation is approximately
linear in x:
Ld2x
dt2 + f dx
dt +
d2V
dt2 + g

x = I −d2H
dt2 .
This linear equation for x(t), whose coeﬃcients vary with t, involves many
diﬃcult problems that must be solved to understand the motion of a pen-
dulum. Many of the methods used in the theory of nonlinear oscillations
grew out of studies of such pendulum problems; they are applicable now to
a wide variety of new problems in physics and biology.

1.2. Time-Invariant Linear Systems
5
 H(t)
 V(t)
 L
 m
 x
Figure 1.3. A pendulum with a moving support point. (H(t), V (t)) gives the
location of the support point at time t. The pendulum is a massless rod of length
L suspending a mass m, and x measures the angular deﬂection of the pendulum
from rest (down).
1.2
Time-Invariant Linear Systems
Systems of linear, time-invariant diﬀerential equations can be studied in
detail. Suppose that the vector of functions x(t) ∈EN satisﬁes the system
of diﬀerential equations
dx
dt = Ax
for a ≤t ≤b, where A ∈EN×N is a matrix of constants.
Systems of this kind occur in many ways. For example, time-invariant
linear nth-order diﬀerential equations can be rewritten in the form of ﬁrst-
order systems of equations: Suppose that y(t) is a scalar function that
satisﬁes the linear equation
any(n) + · · · + a0y = 0.
Let us set x1 = y, x2 = y(1), . . . , xn = y(n−1), and
A =


0
1
0
0
· · ·
0
0
0
0
1
0
· · ·
0
0
0
0
0
1
· · ·
0
0
...
...
...
...
...
...
...
0
0
0
0
· · ·
0
1
b0
b1
b2
b3
· · ·
bn−2
bn−1



6
1.
Linear Systems
where b0 = −a0/an, . . . , bn−1 = −an−1/an. A matrix in this form is called
a companion matrix [40]. With this, the vector x satisﬁes the diﬀerential
equation
dx
dt = Ax.
If this were a scalar equation (i.e., n = 1), the solution would be x(t) =
exp(At)x(0), where x(0) is given. We show next that this formula also
deﬁnes a solution when A is any constant matrix.
1.2.1
Functions of Matrices
Let g(z) be an analytic function of z in some set S of the complex plane.
Suppose that g has a convergent power series expansion
g(z) =
∞

n=0
cnzn
for z in S. If A is an N ×N matrix, then we can make sense of the function
g(A) by deﬁning it to be the power series
g(A) =
∞

n=0
cnAn.
This converges absolutely if the series of scalars  |cn||A|n converges,
where |c| denotes the modulus of a complex number c and |A| denotes
the Euclidean norm of the matrix A [34]:
|A| =

i

j
|ai,j|2.
Here ai,j is the component in the ith row and jth column of A.
If A is a diagonalizable matrix, then it can be written in terms of its
spectral decomposition:
A =
N

j=1
λjPj,
where λ1, . . . , λn are the eigenvalues of A and P1, . . . , Pn are projection
matrices, which satisfy the conditions PiPj = Pi if i = j and PiPj = 0
otherwise. Because of this, we see that for any integer m,
Am =
N

j=1
λm
j Pj.

1.2. Time-Invariant Linear Systems
7
In addition, we have
g(A) =
∞

n=0
cnAn =
N

j=1
∞

n=0
cnλn
j Pj =
N

j=1
g(λj)Pj,
provided that each eigenvalue λj lies in the domain where g is analytic.
Note that the spectral decomposition enables us to calculate functions
of A in terms of powers of the scalars {λj}, rather than powers of A. The
result is that once the eigenvalues and their projection matrices are found,
eﬀort in calculating functions of A is greatly reduced.
However, not every matrix can be diagonalized. The most that can be
said is that any matrix A can be put into Jordan canonical form. That is,
there is a block diagonal matrix J and a transforming matrix T such that
T −1AT = J.
The blocks on the main diagonal of J have the form
λkIk + Zk =


λk
1
0
0
0
0
0
λk
1
· · ·
0
0
0
0
0
λk
0
0
0
...
...
...
0
0
0
λk
1
0
0
0
0
· · ·
0
λk
1
0
0
0
0
0
λk


where Ik is an identity matrix of dimension k for k = 1, . . . , K, where K
is the number of blocks and Z is a matrix of zeros except for some ones on
the superdiagonal (where Zi,j = δi+1,j). Since ZN = 0, Z is referred to as
being a nilpotent matrix. There may also be a diagonalizable term on the
main diagonal of J (see [46]).
1.2.2
exp(At)
Since exp(t) is an entire function, exp(At) can be deﬁned by the series
exp(At) =
∞

n=0
(At)n
n!
,
which converges for all (real and complex) numbers t and for any matrix
A. We see directly from this series that
d exp(At)
dt
= A exp(At).
Therefore, this series deﬁnes a solution of the diﬀerential equation
dx
dt = Ax.

8
1.
Linear Systems
What does exp(At) look like? If A is diagonalizable, then we can interpret
exp(At) easily; namely,
exp(At) =
N

j=1
exp(λjt)Pj,
so that exp(At) is simply a linear combination of matrices whose coeﬃcients
are exponentials of eigenvalues of A. In general, the series expansion of
exp(At) shows that
exp(At) = exp(TJT −1t) = T exp(Jt)T −1.
Moreover, the exponential of a block diagonal matrix is again a block di-
agonal matrix having blocks of the same dimensions. Thus, it is suﬃcient
to consider a typical irreducible block matrix:
exp[(λI + Z)t].
This has the form
exp(λt)

I + tZ + t2Z2
2
+ · · · + tk−1Zk−1
(k −1)!

,
where k is the dimension of this block. Therefore, for any matrix A, the
function exp(At) is a linear combination of matrices whose coeﬃcients are
polynomials in t multiplied by exponentials of eigenvalues of A.
Finally, we note that the spectrum of a matrix A can be split into three
parts: those eigenvalues having negative real parts (S), those having pos-
itive real parts (U), and those that are purely imaginary (O). If A is
diagonalizable, then it can be transformed into a block diagonal matrix
having three blocks: The ﬁrst consists of those eigenvalues in S, the second
of those in O, and the third of those in U. Therefore, we can write
exp(At) =

j in S
exp(λjt)Pj +

j in O
exp(λjt)Pj +

j in U
exp(λjt)Pj.
The ﬁrst sum approaches zero as t →∞, the second one oscillates, and the
third one grows as t →∞. Any solution of the system
dx
dt = Ax
can therefore be written in the form
x(t) =

j in S
exp(λjt)Pjx(0) +

j in O
exp(λjt)Pjx(0) +

j in U
exp(λjt)Pjx(0).
In the ﬁrst sum, x(0) is said to excite stable modes; in the second, oscilla-
tory modes; and in the third, unstable modes. Thus, the matrix A deﬁnes
a partition of the entire space EN into three parts: a stable manifold that
is deﬁned by the span of the projection matrices Pj for j ∈S, an unstable

1.2. Time-Invariant Linear Systems
9
manifold deﬁned by the span of the matrices Pj for j ∈U, and an oscil-
latory, or center manifold, that is spanned by the matrices Pj for j ∈O.
We shall see later that this decomposition carries over to certain nonlinear
systems.
1.2.3
Laplace Transforms of Linear Systems
Suppose that g(t) is a vector of smooth functions that grow no faster than
an exponential as t →∞. We deﬁne the Laplace transform of g to be
g∗(p) =
 ∞
0
exp(−pt)g(t) dt,
where p is a complex number called the transform variable. Because of our
assumption on g, the integrand is dominated by a decreasing exponential
if Re(p) is suﬃciently large, where Re(p) denotes the real part of p. Note
that
dg
dt
∗
= pg∗−g(0).
Therefore, we see that Laplace’s transform converts diﬀerentiation into
multiplication, and it justiﬁes using p as the Heaviside operator described
in Section 1.1.2.
How does one recover g from its transform? If G(p) is a function that is
analytic in a region except for pole singularities, then we deﬁne
g(t) =
1
2πi

C
exp(pt)G(p) dp,
where C is a curve lying in the region and enclosing all of the singularities
of G. With g deﬁned in this way, g∗(p) = G(p). This formula for g is the
Laplace inversion formula, and it shows how to recover the original function
from its transform.
Calculation of the inverse formula uses the method of residues, which is
based on Cauchy’s formula: If F(z) is a function that is analytic in some
region containing a point z0 and if C is a curve lying in this region and
enclosing z0, then we have the formula
F(z0) =
1
2πi

C
F(z)
(z −z0) dz.
This is referred to as the Cauchy integral formula, and the method of
residues is based on it. For example, if G(p) = 1/(p −a), then
g(t) =
1
2πi

C
exp(pt)
(p −a) dp = exp(at)
if C encloses the point z = a.

10
1.
Linear Systems
A low-pass ﬁlter is described in Section 1.1.2 (with inductance L = 0).
Using the notation of that section, we have
V = H(p)W,
where H(p) = (RCp + 1)−1. This formula should be interpreted as one for
the transforms of V and W:
V ∗= H(p)W ∗,
and so V (t) is the inverse Laplace transform of the function H(p)W ∗(p).
It follows that
V (t) = exp

−t
RC

V (0) +
 t
0
exp

−(t −s)
RC

W(s) ds
RC .
Finally, we note that another useful representation of the matrix exp(At)
can be found using Laplace transforms. Namely, we can deﬁne
exp(At) =
1
2πi

C
(pI −A)−1 exp(pt)dp.
This formula is proved by reducing A to its Jordan canonical form and
applying Cauchy’s formula to each term in the matrix, as shown in the
next section.
1.3
Forced Linear Systems with Constant
Coeﬃcients
Now let us consider a system of the form
dx
dt = Ax + f(t).
This describes a linear system to which a forcing function f is applied. We
suppose that f grows no faster than an exponential. Taking the Laplace
transform of this equation gives
(pI −A)x∗(p) = f ∗(p),
or
x∗(p) = (pI −A)−1f ∗(p),
where this inverse matrix is deﬁned except when p is an eigenvalue of A.
Since x∗is the product of two transforms, x(t) is a convolution product;
that is, there is a matrix h(t) such that
x(t) =
 t
0
h(t −s)f(s)ds,
where h∗(p) = (pI −A)−1.

1.3. Forced Linear Systems with Constant Coeﬃcients
11
What is h? If A is diagonalizable, then we can use its spectral
decomposition to evaluate h. Since
A =
N

j=1
λjPj,
we have that
(pI −A)−1 =
N

j=1
1
(p −λj)Pj.
Therefore,
h(t) =
N

j=1
1
2πi

C
exp(pt)
(p −λj)dpPj =
N

j=1
eλjtPj = exp(At).
This motivates the following observation: For any matrix A, we have the
function
y(t) =
 t
0
exp[A(t −s)]f(s)ds,
which satisﬁes
dy
dt −Ay = f(t).
This formula for y gives a particular solution of the equation, and the
general solution has the form
x(t) = y(t) + z(t),
where z solves the homogeneous problem
dz
dt −Az = 0
and
z(0) = x(0),
and so
z(t) = exp(At)x(0).
In summary, if x(t) solves the equation
dx
dt = Ax + f(t),
then
x(t) = exp(At)x(0) +
 t
0
exp[A(t −s)]f(s) ds.
This is the variation of constants formula for x(t), and it might or might
not be useful depending on how easily the matrix exp(At) can be evaluated.
The transfer function notation for this is
x(t) = (pI −A)−1f(t),

12
1.
Linear Systems
so we see that the transfer function notation summarizes a great deal of
work. The general variation of constants formula is described in Section 1.6.
1.4
Linear Systems with Periodic Coeﬃcients
Consider the linear system
dx
dt = A(t)x,
where A is now an N × N matrix of continuous periodic functions, say
A(t + T) = A(t) for all t, −∞< t < ∞, where T is a period of A.
We say that Φ(t) is a fundamental matrix for this system if
dΦ
dt = A(t)Φ
and
Φ(0) is nonsingular.
Note that if d(t) denotes the determinant of Φ(t), then
dd
dt = tr[A(t)]d
and
d(0) ̸= 0
[24]. Therefore,
d(t) = exp
  t
0
tr[A(s)]ds

d(0),
so d(t) ̸= 0 for all t where tr(A) = N
k=1 Ak,k is the trace of A. It follows
that Φ(t) is nonsingular for all t, and therefore the columns of Φ(t) deﬁne
a set of N linearly independent solutions of the system.
The following theorem is very useful for studying periodic systems.
Floquet’s Theorem.Let Φ be as described above. Then there is a
periodic matrix P(t), having period T, and a constant matrix R such that
Φ(t) = P(t) exp(Rt).
Proof of Floquet’s Theorem. If Φ(t) is a fundamental matrix of the problem,
then so is Φ(t + T). Moreover, calculation shows that
d
dtΦ−1 = −Φ−1(t)Φ′(t)Φ−1(t).
Therefore,
d
dt[Φ−1(t)Φ(t + T)] = 0.
It follows that there is a constant nonsingular matrix, namely,
C = Φ−1(0)Φ(t),

1.4. Linear Systems with Periodic Coeﬃcients
13
such that
Φ(t + T) = Φ(t)C
for all t.
This is the key observation on which further developments are based. In
particular, it follows from this formula that for any integer n,
Φ(nT) = Φ(0)Cn.
Therefore, the long-term behavior of solutions can be determined from the
eigenvalues of the matrix C. If we can deﬁne a matrix R by the formula
R = log(C)
T
,
so that exp(RT) = C, then the matrix
P(t) = Φ(t) exp(−Rt)
satisﬁes the identity
P(t + T) = P(t)
for all t. This follows because for all t,
P(t + T) = Φ(t + T) exp(−RT) exp(−Rt) = Φ(t) exp(−Rt) = P(t).
The logarithm of C is well-deﬁned (as shown in [24]), although it might be
a matrix of complex numbers.
This result is especially helpful in determining the behavior of x(t) as
t →∞. For example, if all of the eigenvalues of R have negative real parts,
then x(t) →0 as t →∞. However, this theorem is diﬃcult to apply, since
it is usually diﬃcult to ﬁnd the matrix R.
An interesting consequence of Floquet’s Theorem is that any periodic
system can be transformed into one having constant coeﬃcients. In fact,
the change of variables x = P(t)y takes the problem
dx
dt = A(t)x
into the linear system
dy
dt = Ry.
A very useful example is the system
d
dt

x1
x2

=
 cos ωt
sin ωt
−sin ωt
cos ωt

B
 cos ωt
−sin ωt
sin ωt
cos ωt
  x1
x2

,
where B is any 2 × 2 matrix of constants. Using Floquet’s transformation

y1
y2

=

cos ωt
−sin ωt
sin ωt
cos ωt
 
x1
x2


14
1.
Linear Systems
we convert this system into
d
dt

y1
y2

=

B + ω

0
−1
1
0
 
y1
y2

.
Thus, in this case, Floquet’s transformation is easy to carry out, and R =
B + ωJ, where J is Jacobi’s matrix:
J =

0
−1
1
0

.
1.4.1
Hill’s Equation
The equation
d2x
dt2 + p(t)x = 0,
where p is a continuous periodic function, is known as Hill’s equation.
This equation arises frequently in mathematical physics, for example,
Schr¨odinger’s equation in quantum mechanics and studies of the stability
of periodic solutions by linearization often have this form (see [28, 105]).
Let y1 denote the solution of this equation that satisﬁes the initial con-
ditions y1(0) = 1 and y′
1(0) = 0, and let y2 denote the solution of this
equation that satisﬁes y2(0) = 0, y′
2(0) = 1. Then, if we set x′ = y, we can
rewrite Hill’s equation as a ﬁrst-order system:
dx
dt
=
y
dy
dt
=
−p(t)x,
and the matrix
Φ(t) =
 y1(t)
y2(t)
y′
1(t)
y′
2(t)

deﬁnes a fundamental solution. The matrix Φ is called the Wronskian ma-
trix for this system. In fact, each column of this matrix solves the system,
and Φ(0) = I.
Suppose that the period of p is T, so p(t + T) = p(t) for all t. Floquet’s
Theorem shows that Φ(T) = exp(RT). The eigenvalues of this matrix
are called characteristic multipliers, and if they have modulus equal to
one, then all solutions of Hill’s equation are bounded as t →±∞. The
eigenvalues of RT are called the characteristic exponents of the problem.
On the other hand, a great deal has been determined about the eigen-
values of R for Hill’s equation. For example, the eigenvalues of Φ(T) are
determined from the characteristic equation
λ2 −[y1(T) + y′
2(T)]λ + det Φ(T) = 0,

1.4. Linear Systems with Periodic Coeﬃcients
15
and they have the form
λ = ∆±

∆2 −det[Φ(T)],
where 2∆
=
tr[Φ(T)], the trace of Φ(T), and det[Φ(T)] denotes
its determinant. Note that 2∆
=
y1(T) + y′
2(T), and det[Φ(T)]
=
exp
 T
0 tr[A(s)]ds

= 1.
Therefore, if ∆can be evaluated, then the nature of the eigenvalues of
Φ(T) can be determined. In particular, if |∆| < 1, then the eigenvalues of
Φ(T) are complex conjugates and have modulus 1. In this case, all solutions
of Hill’s equation are bounded on the entire interval −∞< t < ∞. On the
other hand, if ∆> 1, both roots have positive real parts, and if ∆< −1,
then both eigenvalues have negative real parts. In either of these two cases,
no solution of Hill’s equation remains bounded on the whole interval −∞<
t < ∞(see [105]). Finally, if ∆= 1, then there is (at least) one solution
having period T, and if ∆= −1, then there is (at least) one solution having
period 2T. In either case, the other solution can grow no faster than O(t)
as t →∞.
Hill’s equation with damping has the form
d2x
dt2 + rdx
dt + p(t)x = 0,
where r > 0. Setting x = exp(−rt/2)y gives
d2y
dt2 +

p(t) −
r
2
2
y = 0.
This is of the form just considered, and we see that if ∆< 1 for this
equation, then y remains bounded for 0 ≤t < +∞, and consequently
x →0 as t →+∞.
Pr¨ufer introduced polar coordinates to Hill’s equation setting y = dx/dt
and dy/dt = −p(t)x. Then x = r cos θ and y = r sin θ. The result is
dr
dt
=
r[1 −p(t)] cos θ sin θ
dθ
dt
=
−p(t) cos2 θ −sin2 θ.
Note that the angular variable θ is separated from the amplitude variable in
this case! Thus, Hill’s equation is easily put into phase–amplitude variables,
which we study further in Section 2.3.5, and the problem reduces to study
of the ﬁrst-order diﬀerential equation for θ.
1.4.2
Mathieu’s Equation
More can be said about the special case of Hill’s equation when p(t) =
δ + ε cos t, where δ and ε are constants. The result is known as Mathieu’s
equation, and its solutions are either bounded or unbounded, as for Hill’s

16
1.
Linear Systems
ε
δ
|   |>1
|   |<1
∆
∆
Figure 1.4. Stability diagram for Mathieu’s equation. If (δ, ε) lies in one of the
labeled regions, then |∆| < 1 and all solutions of Mathieu’s equation are bounded.
Note that if δ = 0 and ε = 0, then x(t) = at + b for some constants a and b.
equation. Figure 1.4 shows the values of δ and ε for which solutions are
bounded.
Meissner introduced a practice problem, where the term cos t is replaced
by a 2π-periodic square wave q(t), where
q(t) =

1
for 0 ≤t < π,
−1
for π ≤t < 2π.
There is an interesting application of this to the pendulum model de-
scribed in Section 1.1.3. Let H = 0 and V = A cos ωt. Then linearizing
the pendulum equation about x = 0 and replacing t by ωt gives
d2x
dt2 +
 g
Lω2

−A
L cos t

x = 0,
and linearizing about x = π gives
d2x
dt2 −
 g
Lω2

−A
L cos t

x = 0.
We see that if δ = ±(g/Lω2) and ε = ±A/L lie in the overlap region
in Figure 1.5, then both equilibria are stable. Thus, if the support point

1.4. Linear Systems with Periodic Coeﬃcients
17
ε
δ
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xxxxxx
xx
xx
xx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxx
Overlap
Regions
Figure 1.5. Overlap regions. If the data are in the doubly shaded regions, then
both the up and down positions of the pendulum are stable. In this case, a small
perturbation of the pendulum from the straight up position persists, but the
pendulum remains nearly straight up for all future times.
is vibrated vertically with a range of frequencies and amplitudes so that
(g/Lω2) and A/L lie in the doubly shaded region in Figure 1.5, then both
the up and the down positions of the pendulum are stable.
If the pendulum is damped, then the linear equations are
d2x
dt2 + rdx
dt ±
 g
Lω2

−A
L cos t

x = 0,
respectively. Setting x = exp(−rt/2)y in each of these equations gives
d2y
dt2 ±
 g
Lω2

−A
L cos t ∓
r
2
2
y = 0,
respectively. In these cases, we have that
δ = (g/Lω2) −(r/2)2
and
δ = −(g/Lω2) −(r/2)2,
respectively.
Figure 1.5 shows the stability diagram for these two oscillators drawn
together on the same coordinate axes when r = 0. Figure 1.6 shows the
same result for small r. In this case small perturbations of the pendulum
from the straight up position die out, approximately like exp(−rt/2). This

18
1.
Linear Systems
ε
δ
xx
xx
xx
Overlap
Regions
r
-r
Figure 1.6. The stability diagram of the up and down positions when damping
is accounted for (r > 0). In this case, small perturbations of the pendulum from
the straight up position die out, approximately like exp(−rt/2).
shows that an oscillating environment can stabilize a static state that is
unstable without oscillation. This is an important phenomenon found in
many physical and biological systems [1, 87, 127].
1.5
Fourier Methods
No result comparable to Floquet’s Theorem is available for systems having
almost periodic coeﬃcients. However, when these systems do arise in ap-
plications, they can be studied using generalized Fourier methods. Some of
these methods are described in this section.
1.5.1
Almost-Periodic Functions
Almost-periodic functions play important roles in studies of nonlinear os-
cillators. An almost-periodic function, say f(t), is one that comes close to
being periodic in the following sense: For a given tolerance ε there is a
number Tε, called a translation number, such that in any interval of length

1.5. Fourier Methods
19
Tε there is a number T ′ for which
|f(t + T ′) −f(t)| < ε
for all t. The translation number of a periodic function is simply its period.
References [11] and [140] present introductions to almost-periodic functions
and their properties.
If f is almost-periodic, then it has a generalized Fourier expansion:
f(t) ∼
∞

n=1
Cn exp(itλn),
where the amplitudes {Cn} (complex) and the frequencies {λn} (real) char-
acterize the function. The frequencies of f are deﬁned to be the values of
λ for which the average
A(λ) = lim
T →∞
1
T
 T
0
exp(−iλt)f(t)dt
is not zero. It is known that this happens for at most countably many
values of λ, say λ1, λ2, . . . . The amplitudes of the modes are given by the
formulas
Cn = A(λn)
for n = 1, 2, . . . .
An important example of an almost-periodic function is deﬁned by the
series
f(t) =
∞

n=1
exp(it/2n)
n2
.
The nth term in the series has period 2n+1π, so the function is not periodic.
But given a tolerance ε, we can choose N so large that
∞

n=N
1
n2 < ε
2.
Then, setting Tε = 2N+1π, we have
|f(t + Tε) −f(t)| < ε
for all t. This shows that f is almost periodic, but note that the integral
of this series does not converge, and so does not deﬁne an almost-periodic
function.
The class of all almost-periodic functions is larger than needed to study
many nonlinear oscillators, and the smaller class of quasiperiodic functions
is useful. These functions are generated by ﬁnitely many frequencies as
follows. Let ω be a vector of M real numbers,
ω = (ω1, . . . , ωM),

20
1.
Linear Systems
and let ⃗n be a multi-index, that is, ⃗n is a vector of integers such that
⃗n = (n1, . . . , nM).
If the components of ω are rationally related, then the sequence {⃗n · ω} is
equivalent to a sequence of integer multiples of a real number. However,
if the components of ω are not rationally related, then the sequence is
dense in the real numbers. We deﬁne |⃗n| =  ni, and we consider a set
of amplitudes {C⃗n} that satisﬁes some convergence condition, say |C⃗n| ≤
1/|⃗n|2 as |⃗n| →∞. Then the series
∞

|⃗n|=−∞
C⃗n exp(it⃗n · ω)
deﬁnes an almost-periodic function whose frequencies are generated by
a ﬁnite set, namely, the components of ω. Such a function is called a
quasiperiodic function.
Quasiperiodic functions are closely related to periodic functions. For
example, if f is a quasiperiodic function, then there is a function F(s),
s ∈EM, that is periodic in each component of s, such that f(t) = F(ωt).
In particular, if f has the series representation
f(t) =
∞

|⃗n|=−∞
C⃗n exp(it⃗n · ω),
then F is deﬁned by the formula
F(s) =
∞

|⃗n|=−∞
C⃗n exp(i⃗n · s).
On the other hand, let F(s1, . . . , sM) be a diﬀerentiable function that is
2π-periodic in each variable s1, . . . , sM. Such functions have Fourier series,
say
F(s1, . . . , sM) =
∞

|⃗n|=−∞
F⃗n exp(i⃗n · s),
where ⃗n = (n1, . . . , nM) and s = (s1, . . . , sM). With a vector of frequencies
ω = (ω1, . . . , ωM), we can deﬁne a function f by the formula
f(t) = F(ω1t, . . . , ωMt).
This function has a generalized Fourier series, namely,
f(t) =
∞

|⃗n|=−∞
F⃗n exp(it⃗n · ω),
so it is a quasiperiodic function.

1.5. Fourier Methods
21
These remarks show that quasiperiodic functions are essentially multiply
periodic functions that involve more than one frequency.
The following theorem will be used later:
Weak Ergodic Theorem. Let f be a quasiperiodic function with F de-
ﬁned as above. Suppose that the frequencies deﬁning f, say ω, are rationally
independent; that is, n · ω ̸= 0 if n ̸= 0. Then
lim
T →∞
1
T
 T
0
f(t)dt =
 1
2π
M  2π
0
· · ·
 2π
0
F(s1, . . . , sM)ds1 · · · dsM.
In fact, both sides are equal to C0, which proves the theorem. This form
of the ergodic theorem from statistical mechanics is useful in a variety of
numerical computations described in Chapter 7.
1.5.2
Linear Systems with Periodic Forcing
Consider the equation
dx
dt = Ax + g(t),
where A is a constant diagonalizable matrix and g is a continuous, periodic
function, say
g(t) =
∞

m=−∞
Cm exp(imωt),
which has period 2π/ω. The solution x(t) is given by the formula
x(t) = exp(At)x(0) +
 t
0
exp[A(t −s)]g(s)ds.
If the spectral decomposition of A is given by
A =
N

j=1
λjPj,
then the integral in the formula for x(t) becomes
 t
0
N

j=1
∞

m=−∞
Cm exp[λj(t −s) + i(mω)s]dsPj
=
N

j=1
∞

m=−∞
Cm
(eimωt)
(λj −imω) −eλjt Pj
as long as the ratio λj/iω is not an integer m for which Cm ̸= 0. This
condition ensures that the forcing is not resonant.

22
1.
Linear Systems
If the forcing is resonant, that is, if λj/iω = k for some integers k and
j for which Ck ̸= 0, then the corresponding term in the solution has the
form
 t
0
Ck exp[λj(t −s) + ikωs]dsPj = Ckt exp(iωkt)Pj.
The resonance case occurs when the forcing function has a frequency that
matches one of the free frequencies of the problem, that is, one of the
eigenvalues of A. Subresonant forcing occurs when one of the frequencies
of g matches an integer multiple of one of the free frequencies.
1.5.3
Linear Systems with Quasiperiodic Forcing
Now consider the equation
dx
dt = Ax + g(t),
where A is a constant diagonalizable matrix and g is a continuous,
quasiperiodic function generated by two frequencies, say ω and µ:
g(t) =
∞

m,n=−∞
Cm,n exp[i(mω + nµ)t].
We suppose that |Cm,n| ≤K/(m2 + n2) for some constant K.
The solution x(t) is given by the formula
x(t) = exp(At)x(0) +
 t
0
exp[(A(t −s)]g(s)ds.
If the spectral decomposition of A is
A =
N

j=1
λjPj,
then the integral in the formula for x(t) becomes
 t
0
N

j=1
∞

m,n=−∞
Cm,n exp[λj(t −s) + i(mω + nµ)s]Pjds
=
N

j=1
∞

m,n=−∞
Cm,n
exp[i(mω + nµ)t]
i(mω + nµ) −λj
Pj
−
N

j=1
∞

m,n=−∞
Cm,n exp(λjt)
i(mω + nµ) −λj
Pj

1.6. Linear Systems with Variable Coeﬃcients: Variation of Constants Formula
23
if these series converge. The series do converge if the eigenvalues of A
are not purely imaginary. However, if some eigenvalues of A lie on the
imaginary axis and the frequencies µ and ω are rationally independent,
then the series representing x(t) becomes more diﬃcult to evaluate. In
particular, the numbers i{mω + nµ} are dense in the imaginary axis, and
so the denominators i(mω + nµ) −λj become arbitrarily small for large m
and n. This is a small divisor problem, and we will deal with aspects of it
in Section 7.4.3.
1.6
Linear Systems with Variable Coeﬃcients:
Variation of Constants Formula
A general linear system has the form
dx
dt = A(t)x + f(t),
where x, f ∈EN and A is an N × N matrix of continuous functions. Let
Φ(t) denote the solution of the matrix equation
dΦ
dt = A(t)Φ,
Φ(0) = identity.
The matrix Φ is called the fundamental solution for the problem, and
it is determined by solving these N 2 scalar diﬀerential equations for the
components of Φ.
The solution x(t) of the linear problem is given by the variation of
constants formula
x(t) = Φ(t)x(0) +
 t
0
Φ(t)Φ−1(s)f(s) ds.
This formula can be easily derived by setting x = Φ(t)y, since the equation
for y is
dy
dt = Φ−1(t)f(t).
The diﬃculty in using this formula is that Φ is usually not available. If
A is constant, then we have seen that
Φ(t) = exp(At).
If A is periodic, then
Φ(t) = P(t) exp(Rt),
which at least shows the form of Φ even though P and R may be diﬃcult
to ﬁnd. No comparable result is available in cases where A is quasiperiodic

24
1.
Linear Systems
or almost periodic. In the general case, usually
Φ(t) ̸= exp
  t
0
A(s)ds

,
since in general
A(t)
 t
0
A(s)ds ̸=
 t
0
A(s)dsA(t).
1.7
Exercises
1.1. a. Show that the Laplace transform of a convolution
 t
0
h(t −s)f(s)ds
is the product of the transforms of h and f if f and h do not grow
faster than exponential functions as t →∞. Evaluate the Laplace
transform of the derivative dg/dt of a diﬀerentiable function g(t).
b. Use the Laplace transform to solve the diﬀerential equation
d2x
dt2 + dx
dt + bx = f(t),
where a and b are known constants and f(t) is a given function.
c. Show that if
y(t) =
 t
0
exp[A(t −s)]f(s)ds,
where y, f ∈EN and A in EN×N is a constant matrix, then
dy
dt −Ay = f.
Suppose that A is diagonalizable. Use the spectral decomposition of
A and the Laplace transform to relate the solution of this diﬀerential
equation to the eigenvalues of A.
d. Show that any solution of the diﬀerential equation
dy
dt −Ay = f
can be written in the form
y(t) = exp(At)y(0) +
 t
0
exp[A(t −s)]f(s)ds
using the method of Laplace transforms.
1.2. a. Let P(t) = Φ(t) exp(−Rt) as in the proof of Floquet’s Theorem in
Section 1.4. Show that the change of variables x = P(t)y takes the
periodic system
dx
dt = A(t)x

1.7. Exercises
25
into the system
dy
dt = Ry,
where R is a constant matrix. Thus, show that any periodic system
can be transformed in this way into a linear system having constant
coeﬃcients.
b. Find a 2 × 2 matrix of functions, say A(t), such that
A(t)
  t
0
A(s)ds

̸=
  t
0
A(s)ds

A(t).
Show that in this case the matrix Φ(t) = exp[
 t
0 A(s)ds] does not
solve the equation
dΦ/dt = A(t)Φ.
Find such a matrix A(t) that is periodic. Relate this result to
Floquet’s theorem.
c. Show that if Φ(t) is an N × N matrix of functions satisfying the
equation
dΦ
dt = A(t)Φ,
then the function D(t) = det[Φ(t)] satisﬁes the equation
dD
dt = tr[A(t)]D(t),
where tr[A] is the trace of A (i.e., the sum of the elements of A lying
on the main diagonal).
1.3. Let A(t) = U −1(t)CU(t), where C is a constant 2 × 2 matrix and the
components of the 2 × 2 matrix U are
U11 = cos t,
U12 = sin t,
U21 = −sin t,
U22 = cos t.
The eigenvalues of A and C are identical. Apply Floquet’s transforma-
tion to this system. Show by example that the resulting system having
constant coeﬃcients can have a positive eigenvalue even though both
the eigenvalues of C have negative real parts. Conclude that eigen-
values of a periodic coeﬃcient matrix do not determine stability
properties of the linear system.
1.4. Show that if |∆| < 1, then all solutions of Hill’s equation (Sec-
tion 1.4.1) are bounded for −∞< t < ∞. Also, show that if |∆| > 1,
then all solutions (excluding the one that is zero everywhere) are
unbounded on −∞< t < ∞.
1.5. Construct the complete stability diagram for Meissner’s equation in
Section 1.4.2 using numerical simulation.
1.6. Verify the weak ergodic theorem for the function F(s1, s2) = 1 +
cos s1 + cos s2 and ω1 = 1 and ω2 =
√
2 by direct substitution. That
is, show that
(2π)−2
 2π
0
F(s1, s2)ds1ds2 = lim
T →∞
1
T
 T
0
F

t,
√
2t

dt.

2
Dynamical Systems
This chapter contains material intended to provide the reader with some
background in topics of dynamical systems that are used later. There is
a large literature on each topic in this chapter, and the presentation here
provides only an overview of topics relevant to the remainder of the book.
A distinction is usually made between systems that are isolated, known
as free systems, and those that interact with the outside world, known as
forced systems. But this classiﬁcation is not reliable. Often we reduce forced
systems to (apparently) free ones by looking at the system stroboscopically
or by introducing extra variables to describe external inﬂuences. Often
we reduce free problems to ones that appear to be forced because certain
combinations of their variables are time-like. For example, systems in which
energy is conserved can have dissipative components within them such as
hyperbolic equilibria, which can be uncovered by ﬁnding a time-like variable
among the variables of the system and using it to reduce the problem to a
dissipative one of lower order.
The term oscillation usually refers to a periodic or almost-periodic solu-
tion of a system of diﬀerential equations. Free oscillations are oscillatory
solutions to models that are time-invariant. The LC circuit is a typical
free oscillator. Nonlinear oscillations are oscillatory solutions to nonlinear
diﬀerential equations. This chapter begins with a study of free nonlinear
problems in two variables, about which a great deal is known.
Most oscillations studied here can be described by functions of the
form F(x1, . . . , xN) that are 2π-periodic in each of N phase variables
x1, . . . , xN, which themselves vary with time. A convenient mathematical
description of an oscillator is one given in terms of such phase variables,

28
2. Dynamical Systems
and phase equations are studied in Section 2.2. However, most physical
problems are described in terms of physical observables like voltages, cur-
rents, displacements, and so on, and converting such problems to convenient
phase variables is usually diﬃcult. The third and fourth sections investi-
gate general conservative and dissipative systems, respectively. This leads
to a discussion of discrete dynamics and function iterations in Section 2.5.
Finally, some oscillations caused by time delays are described in Section 2.6.
2.1
Systems of Two Equations
It is possible to describe in detail solutions of two linear equations. Much of
this work carries over to nonlinear systems as well, at least near equilibria.
Poincar´e and Bendixson’s theory deals with general nonlinear systems for
two variables. It is derived in Section 2.1.2 and then later applied to study
Lienard’s equation.
2.1.1
Linear Systems
Consider the linear system
dx
dt
=
ax + by
dy
dt
=
cx + dy
where a, b, c, and d are real numbers. The point x = 0, y = 0 is a equilibrium
for this system, and the following analysis shows how all solutions of the
system behave.
We saw in Chapter 1 that the solutions of this system are based on
exponentials of eigenvalues of the coeﬃcient matrix, namely, solutions of
the characteristic equation
λ2 −(a + d)λ + (ad −bc) = 0,
where the coeﬃcient of −λ is tr(A), the trace of the matrix
A =

a
b
c
d

,
and the last term is its determinant, det A. Therefore, this equation has
the form
λ2 −tr(A)λ + det(A) = 0,
and the eigenvalues are
λ = tr(A)
2
±
tr(A)
2
2
−det(A).

2.1. Systems of Two Equations
29
 y
 x
Figure 2.1. A = diagonal (−2, −1). A stable node.
If we suppose that det A ̸= 0, then there are three cases:
1. The roots are real and have the same sign. If the roots are negative,
then all solutions tend to the critical point as t →∞. This is called a
stable node (see Figure 2.1). In the other case, it is an unstable node.
2. The roots are real and have opposite signs. In this case, there is a one-
dimensional stable manifold and a one-dimensional unstable manifold
(see Section 1.2.2). The critical point x = 0, y = 0, is called a saddle
point or hyperbolic point in this case (see Figure 2.2).
3. The roots are complex conjugates. If the real part of the eigenvalues
is negative, then all solutions spiral into the critical point. This is a
stable spiral or a spiral sink (Figure 2.3). If the real part is positive,
solutions spiral away from the critical point. This is an unstable spiral
or a spiral source. If the real parts are zero, then this is a center, and
solutions circle around it (see Figure 2.4).
Much of the behavior depicted in Figures 2.1– 2.4 is also seen in nonlinear
systems. However, nonlinear systems can have more complicated behavior.
2.1.2
Poincar´e and Bendixson’s Theory
Consider a system of two ordinary diﬀerential equations of the form
dx
dt
=
f(x, y)
dy
dt
=
g(x, y),

30
2. Dynamical Systems
 y
 x
Figure 2.2. A = diagonal (−1, 1). A saddle point.
Figure 2.3. A stable spiral.
Figure 2.4. A center.

2.1. Systems of Two Equations
31
where f and g are continuously diﬀerentiable functions of (x, y) over some
compact (i.e., closed and bounded) set D in E2. Given a point (ξ, η) in D
there is a unique solution of this system passing through it. We say that
(ξ, η) is an equilibrium (equivalently, rest point, critical point, or static
state) for the system if f(ξ, η) = g(ξ, η) = 0. Otherwise, we write the
unique solution beginning (t = 0) at (ξ, η) as x = x(t, ξ, η), y = y(t, ξ, η).
Poincar´e and Bendixson’s theory describes what can happen to this solution
if it eventually remains in D.
Poincar´e–Bendixson Theorem. Suppose that D is a closed and
bounded subset of E2 containing at most a ﬁnite number of rest points.
Moreover, suppose that (x(t), y(t)) is a solution of the system
dx
dt
=
f(x, y)
dy
dt
=
g(x, y),
and that for some time t0 it remains in D for all t ≥t0. Then there are
three possibilities:
1. [x(t), y(t)] tends to a critical point as t →∞.
2. [x(t), y(t)] tends to a periodic orbit as t →∞. This means that there
is a periodic solution of the system, say x = p(t) and y = q(t), such
that the solution [x(t), y(t)] approaches the set {[p(τ), q(τ)] : −∞<
τ < ∞} as t →∞.
3. [x(t), y(t)] approaches a set that is homeomorphic to a circle and that
contains critical points and orbits joining them.
Thus, solutions either approach a critical point of the system, an os-
cillation, or they approach a necklace of critical points on a strand of
orbits.
The proof of this result can be found in [24, 58, 68] and it is not presented
here.
This remarkable result rules out a great number of pathologies for two-
dimensional systems that must be dealt with in higher dimensional systems.
Much of the work on diﬀerential equations is restricted to problems that
can be reduced to systems to which this theorem can be applied. A typical
application of the Poincar´e–Bendixson theory is given in Section 2.1.3.
This theorem is not valid in dimensions higher than two. It relies es-
sentially on reducing the system to a single scalar ordinary diﬀerential
equation
dx
dy = f(x, y)
g(x, y)

32
2. Dynamical Systems
and then using special properties of solutions to such equations. Lorenz’s
system of equations provides an important example of three equations
where most solutions do not converge to any of the three options in the
Poincar´e–Bendixson Theorem. Instead, they wander in a structured but
chaotic way for all time. Lorenz’s system is
dx
dt
=
σ(y −x)
dy
dt
=
−xz + αx −y
dz
dt
=
xy −βz,
where α, β, and σ are constants. Chaotic solutions of this system are present
when σ = 10, α = 28, and β = 8/3. Solutions are depicted in Figure 2.5.
2.1.3
x′′ + f(x)x′ + g(x) = 0
Lienard’s equation includes a variety of nonlinear second-order equations
that are used in many applications. It is
d2x
dt2 + f(x)dx
dt + g(x) = 0,
where f and g are continuous functions of x. Two cases of special
importance are van der Pol’s equation
f(x) = ax2 −b
and
g(x) = ω2x
and Duﬃng’s equation
f(x) = 0
and
g(x) = x3 + ax + b
for some constants ω, a, and b. These two cases are studied at several points
throughout this book. However, in this section we study a form of Lienard’s
equation that includes van der Pol’s equation, namely,
d2x
dt2 + f(x)dx
dt + x = 0,
where f is a smooth function. We now derive conditions that ensure that
this equation supports a nonlinear oscillation.
In analogy with mechanical systems we deﬁne the energy of the system
to be the sum of the kinetic and potential energies:
˙x2
2 + x2
2 .
In this case we have
˙x2
2 + x2
2 = C −
 t
0
f(x(s)) ˙x2(s)ds,

2.1. Systems of Two Equations
33
−20
−10
0
10
20
−50
0
50
0
5
10
15
20
25
30
35
40
45
50
x
y
z
−20
−10
0
10
20
−50
0
50
0
5
10
15
20
25
30
35
40
45
50
x
y
z
−20
−15
−10
−5
0
5
10
15
20
−30
−20
−10
0
10
20
30
x
y
Figure 2.5. Top: Cross-eyed stereo depiction of a solution of Lorenz’s system.
Bottom: Projection of the solution into the xy-plane.

34
2. Dynamical Systems
where C is a constant. Thus, if f = 0, energy is conserved; if f(x) > 0,
then energy is taken out of the system; and, if f(x) < 0, then energy is put
into the system.
Integrating the diﬀerential equation once results in an equivalent ﬁrst-
order system:
dx
dt
=
y −F(x)
dy
dt
=
−x,
where
F(x) =
 x
0
f(z)dz.
Hypothesis H.
1. F(−x) = −F(x) for all x.
2. There is a number α > 0 such that F(x) is negative for 0 < x < α.
3. There is a number β ≥α such that F(x) is positive and strictly
increasing for x > β.
4. F(∞) = ∞.
In analogy with the RLC ﬁlter (see Section 1.1.2), the coeﬃcient f(x)
corresponds to a resistance: If f > 0, then there is resistance, and energy is
being taken out of the system. If f < 0, then there is negative resistance,
and energy is being put into it. The fact that F < 0 for x near 0 implies
that x = 0 lies in a negative resistance region. The fact that F > 0 for
large x indicates that the system is resistive for large x. We will see exam-
ples of electronic devices, such as tunnel diodes, that exhibit both positive
and negative resistances later. With Hypothesis H, we have the following
Theorem.
Lienard’s Theorem. Let Hypothesis H be satisﬁed. Then Lienard’s
equation has a (nontrivial) periodic solution.
Proof. Consider a solution of the system starting with x(0) = 0 and
y(0) = y0 > 0. If y0 is large, then there is a solution of the equation that
proceeds clockwise completely around the origin and hits the positive y
axis at a point y1(y0).
We use the following lemma, which we state here without proof (see [58],
pp. 57–60).
Lemma. The mapping y1 : y0 →y1(y0) has the following properties:
1. If α < β, then y1 is deﬁned for large values of y0 and for small values
of y0. In addition, for large values of y0, y1(y0) < y0, and for small
values of y0, y1(y0) > y0.

2.2. Angular Phase Equations
35
2. If α = β, then y1 is deﬁned for all values of y0 on the positive y-axis.
Moreover, y1 is a monotone decreasing function of y0.
The results in the above lemma (1) are illustrated in Figure 2.6. Since
there are no critical points in the annular region described in Figure 2.6, it
follows from the Poincar´e–Bendixson Theorem that any solution starting
on the (upper) line segment [y1(y0), y0] must approach a periodic solution
of the system. This completes the proof of the theorem.
An interesting corollary of this theorem uses the additional condition:
Hypothesis H′. α = β.
With this we have the following theorem.
Theorem. Let conditions H and H′ be satisﬁed. Then Lienard’s equation
has a unique periodic solution. All solutions in the plane approach this orbit
except for the unstable equilibrium x = 0, y = 0.
Proof. The proof follows directly from the above lemma (2). With con-
dition H′ the mapping y0 →y1(y0) is monotone. Since the previous
theorem shows that this mapping has a ﬁxed point, it must be unique.
This completes the proof (see also [24]).
Example of van der Pol’s Equation.
We can use these results to
study van der Pol’s equation
d2x
dt2 + A(x2 −1)dx
dt + x = 0.
In this case, F(x) = A(x3/3−x) and α = β =
√
3. The last theorem shows
that there is a unique periodic solution of van der Pol’s equation for any
choice of the parameter A (A > 0). Therefore, van der Pol’s equation has
a globally stable periodic solution for any A > 0. We study this nonlinear
oscillation when A ≪1 and when A ≫1 in Chapters 7 and 8, respectively.
2.2
Angular Phase Equations
Unfortunately, the term phase equation is used with at least two diﬀerent
meanings. First, phase refers to an angular variable, as in the phase of a
sinusoidal function; second, phase variables are position and momentum
variables in mechanical systems. In this section we study angular phase
variables.
Phase equations give a convenient description of nonlinear oscillators.
In the next section we show how some other models can be transformed
into phase-amplitude coordinates, but in this section we consider systems
of (angular) phase equations. In general, these models are measured by an

36
2. Dynamical Systems
 y
 x
y  (y  )
1     0
y  (y  )
1     0
 large
0
 y
 small
 y0
Figure 2.6. An annular region that is invariant to solutions of Lienard’s equation.
observable, say F(x1, . . . , xN), which is 2π-periodic in each of the phases
x1, . . . , xN. Because of this, we need only consider these variables in a set
T N = {(x1, . . . , xN) : 0 ≤xj < 2π for j = 1, . . . , N}.
The set T N is referred to as the N torus. For N = 1, it can be identiﬁed with
a circle where x is proportional to arc length along the circle (Figure 2.7);
for N = 2, it can be identiﬁed with a torus that is constructed by cutting
a patch out of the x1x2-plane that is length 2π on a side and identifying
the edge x1 = 0 with the edge x1 = 2π by sewing them together to form
a cylinder, and then identifying the edge x2 = 0 with the edge x2 = 2π
by sewing them together (Figure 2.8). The general case is more diﬃcult to
visualize, although one can usefully think of T N being a cube out of EN
with opposite sides identiﬁed.
Where do phase equations come from? First, we will see in Section 2.3.5
that phase–amplitude coordinates can be used eﬀectively to study some
nonlinear oscillators. Two important mechanical cases are perturbed har-
monic oscillators and weakly coupled pendulums where phase variables
describe angular momentum. Second, modern electronic circuits are de-
signed to be modeled directly using phase variables to facilitate their use
in more complicated circuits. This is illustrated by the VCO in Chapter 1.

2.2. Angular Phase Equations
37
 x
Figure 2.7. An angular variable.
2.2.1
A Simple Clock: A Phase Equation on T 1
A single phase is an angular variable describing a circle as shown in
Figure 2.7.
Let us consider a clock having one hand and with its circumference num-
bered from 0 to 2π (counterclockwise). The hand moves at a constant rate
of ω radians per hour, so if x denotes the angle between the hand and 0,
then it satisﬁes the diﬀerential equation
dx
dt = ω
where t is measured in hours. The solution of this equation is x(t) = ωt+x0.
An important example of a single phase equation is the harmonic
oscillator. Consider the equation
u′′ + ω2u = 0.
If we introduce polar coordinates to this equation by setting
u′ + iωu = yeix,
then
y′ = 0
and
x′ = ω,
which is the phase-amplitude version of a harmonic oscillator. Since the
angle equation is uncoupled from the amplitude, we see that the harmonic
oscillator deﬁnes a simple clock. This is a physically important model whose
isochrons, or lines of constant phase, are rays from the origin.
Scalar equations of the form
dx
dt = f(x)
cannot have periodic solutions. In fact, if x(t) is an oscillatory solution of
this equation, then there must be a time when dx/dt = 0, so the solution
must have hit an equilibrium. But since solutions are unique, x(t) must be
an equilibrium. Also, solutions x(t) are monotone between equilibria, since
the sign of f can change only at equilibria.

38
2. Dynamical Systems
Another important example is the ﬁrst-order phase locked loop. This is
an electronic feedback circuit that is based on the VCO in Chapter 1. The
output voltage of the VCO can be taken to be cos x(t). This is fed back
into the VCO as part of its controlling voltage. The mathematical model
for this is
dx
dt = ω + cos x.
If the center frequency ω is greater than 1, then x(t) →∞as t →∞, and
we refer to this as an oscillation, since the voltage cos x(t) oscillates in this
case. We say that there is a periodic solution for x on the circle (i.e., x
modulo 2π).
If the center frequency ω is less than 1, then there is a static state, and
since the solutions of this equation are monotone between static states,
each tends toward a static state as t →∞. In particular, cos x(t) →−ω.
When ω > 1, this equation can be solved by quadrature using the
expression
dt =
dx
ω + cos x.
We have that when x increases by 2π units, t increases by an amount T,
which is the period of oscillation. In particular,
T =
 2π
0
dx
ω + cos x.
2.2.2
A Toroidal Clock: Denjoy’s Theory
Two simple clocks, say with phases x and y, respectively, are modeled by
the equations
dx
dt
=
ω
dy
dt
=
µ.
Telling time on this pair of clocks is like locating a point on T 2, so we refer
to this as a toroidal clock. For example, let t be solar time in days, let x
be the phase of a solar day, and let y be the phase of the moon. Then in
solar time units ω = 2π and µ = 2π/T, since the x variable must complete
a cycle of length 2π each day and the y variable must complete a cycle of
2π every T days (approximately 29 days).
A pair of phase equations has the form
dx
dt
=
f(x, y)
dy
dt
=
g(x, y),

2.2. Angular Phase Equations
39
where f and g are smooth functions that are 2π-periodic in each of x and
y.
Since only values of x and y modulo 2π play a role, we might as well
consider this system to be on the xy-plane reduced modulo 2π. As noted
earlier, this is equivalent to a torus T 2. Therefore, this doubly periodic sys-
tem is often referred to as being a system of ordinary diﬀerential equations
on a torus, which is generated by the two circles labeled x = 0 and y = 0
in Figure 2.8.
Poincar´e and Denjoy studied this problem in some detail [24]. They
deﬁned the rotation number to be the limit
ρ = lim
t→∞
x(t)
y(t).
The limit ρ is a dimensionless number that gives the relative frequency
between x and y, and it has some very interesting and useful features.
They derived the following results [30].
Denjoy’s Theorem. Let f, g be as above. Then the number ρ has the
following properties:
1. ρ exists, and its value is independent of the initial values, x(0) and
y(0), used to compute it.
2. ρ depends continuously on f and g.
3. If ρ is rational, then every solution of this system approaches a peri-
odic solution on the torus, called a torus knot. Moreover, if ρ = p/q
where p and q are integers (lowest common terms), then the solu-
tion rotates in the x direction p times around the torus and in the y
direction q times around the torus each period.
4. If ρ is irrational, then all solutions of the system are dense in the
torus. This is referred to as the ergodic case.
The rotation number is usually diﬃcult to evaluate, but it can be sim-
ulated using a computer, and in that way periodic solutions on the torus
can be detected by simulation.
Figure 2.9 shows a simulation of the rotation number for the system
dx
dt
=
ω + λ sin(x −y) + (1 −λ)[sin(2x −y) −sin(2y −x)]
dy
dt
=
µ.
Denjoy and Poincar´e’s theory leads to a useful numerical method for de-
scribing the behavior of nonlinear oscillators. We will use the theory in
Chapter 7.

40
2. Dynamical Systems
y
x
x
y
Figure 2.8. Toroidal coordinates (x1, x2). The lines x1 ≡x = 0 and x2 ≡y = 0
correspond to the circles shown.
2.2.3
Systems of N (Angular) Phase Equations
Systems of N angular phase equations have the form
dx
dt = ω + f(x),
where x, f, ω ∈EN, and f is a vector of functions that are 2π-periodic in
each component of x. Without loss of generality we assume that
1
2π
 2π
0
f(x)dx = 0,
since we can move a nonzero average of the feedback into ω. These equa-
tions arise in celestial mechanics, statistical mechanics, modern electronic
circuit theory, brain science, and many other applications. Not much can be
said about them in general, although if ωj ≫fj, then averaging methods
can be used, as shown in Chapter 7, to derive the rotation vector method
that partially extends Denjoy and Poincar´e’s theory of rotation numbers
to higher dimensions.
2.2.4
Equations on a Cylinder: PLL
The circuit in Figure 2.10 is a second order phase locked loop [75, 83].
A voltage W comes into a phase detector whose output is V (x)W. This
signal passes through a low-pass ﬁlter, and the result controls the VCO.
The mathematical formulation of a phase locked loop is as follows: The
unknowns in this model are the ﬁlter output voltage z(t) and the VCO
phase x(t) as described in Chapter 1, V (x) is a 2π-periodic function of the
phase x. The model for this circuit is
dx
dt
=
ω + z
τ dz
dt
=
−z + V (x)W.

2.2. Angular Phase Equations
41
0
1
1
0
ρ
0
1
1
0
Frequency
P−map
Figure 2.9. Rotation number simulation for x′ = λ sin(x −t) + (1 −λ) sin(2x −t).
While the transitions between 1/2 and 1, etc., seem to be discontinuous, Denjoy’s
theory ensures that this function is a continuous function of λ. Further simulation
of the rotation number at these “jumps” shows many steps. The function is similar
to Cantor’s function.

42
2. Dynamical Systems
   Voltage
 Controlled 
  Oscillator
     Low
     Pass
    Filter
 z
Diode
 W
 V(x) 
Figure 2.10. A voltage-controlled oscillator neuron (VCON) model.
The ﬁrst equation describes the VCO: ω is the VCO center frequency
and z is its controlling voltage. The second equation describes the output
z of the low-pass ﬁlter where τ is the ﬁlter time constant. This model is
quite similar to the pendulum with an oscillating support point and an
applied torque in Section 1.2 [22] and to the point Josephson junction
in Section 8.5 [98]. The PLL is also the basis for the VCON model in
mathematical neuroscience [75].
If W is constant, this model has one phase variable x and one voltage
variable z. It is convenient to visualize this model geometrically on a cylin-
der as shown in Figure 2.11. A nonlinear oscillation can be a closed curve
that goes around the cylinder, in which case x →∞while the orbit is
closed in this geometry. This model is studied further in Section 2.4.2.
2.3
Conservative Systems
Second-order oscillators are complicated to study. The easiest ones are those
derived from conservation laws, and these are discussed in this section. But
ﬁrst we recall some notations and ideas from mechanics [28].
2.3.1
Lagrangian Mechanics
Consider a mechanical system whose position or state at time t is described
by a scalar function x(t). Let the potential energy of this system be denoted
by U(x), and denote the kinetic energy by m ˙x2/2, where m is mass. The
Lagrangian of this system is deﬁned to be
L = m ˙x2
2 −U(x),
and Hamilton’s principle states that the system moves between any two
times a and b in such a way as to make the action integral
I(x) =
 b
a
L(x, ˙x)dt
stationary. That is, if we perturb x by a continuously diﬀerentiable function
εη(t), where η(a) = η(b) = 0 and where ε is a small positive real number,

2.3. Conservative Systems
43
y
x
Figure 2.11. Cylindrical coordinates.
then we consider the integral
I(x + εη) = I(x) + εI′(x)η + O(ε2),
where
I′(x)η =
 b
a
∂L
∂x η + ∂L
∂˙x ˙η

dt.
The integral is stationary if I′(x)η = 0 for any function η as described
above.
A necessary condition for this is obtained by integrating this formula by
parts and setting the resulting integrand equal to zero:
∂L
∂x −∂
∂t
∂L
∂˙x

= 0.
This is the Euler–Lagrange equation for I(x) [28]. The result in this case is
that
md2x
dt2 + ∂U
∂x = 0.
Multiplying both sides of this equation by ˙x and integrating it gives
m
2
dx
dt
2
+ U(x) = constant.
Thus, the total energy of the system is conserved.
2.3.2
Plotting Phase Portraits Using Potential Energy
Consider the conservation equation
d2x
dt2 + ∂U
∂x = 0,
where the potential function U is a smooth function of x. Maxima of U
correspond to saddle points, and minima correspond to centers in the phase
portrait of solutions to this equation. To see this, suppose that x∗is an

44
2. Dynamical Systems
extremum of U; that is, (∂U/∂x)(x∗) = 0. Linearizing the equation about
this state gives (x = x∗+ u)
¨u + au = 0,
where
a = d2U
dx2 (x∗).
If x∗is a maximum (with a < 0), then the characteristic equation
λ2 + a = 0
has two real roots, one positive and one negative. If x∗is a minimum for
U (with a > 0), then both roots are imaginary.
Solutions can be visualized by thinking of U(x) as describing the proﬁle
of a surface on which a marble is rolling under the force of gravity. The
marble’s potential energy is proportional to its height U(x), and its motion
is described by Newton’s law (F = ma). Obviously, if there is dissipation
in the system (e.g., friction), then the marble will eventually roll to a valley
ﬂoor, which is a (local) minimum of U. A marble starting exactly on a peak
of U will remain there, but starting near a peak, it will roll away. However,
the system studied here does not dissipate energy, and so a marble will not
settle to a valley ﬂoor unless it starts there. It will either oscillate endlessly
back and forth across a valley, be ﬁxed at an extremum for U, or it will
move to ∞.
Solutions can be plotted in the phase plane when we use x and ˙x as
variables. Since energy is conserved, we have
˙x2
2 + U(x) = E,
where E is the initial energy of the system. Figure 2.12 depicts two local
minima of U and the corresponding phase portrait.
Let y = ˙x; then the trajectory with energy E2 lies on the graph of the
function y2 = 2[E2−U(x)]. This curve is deﬁned for an interval A ≤x ≤B.
The quantity y2 measures the distance between the constant E2 and the
potential energy U = U(x). Thus, the orbit is closed and so represents a
periodic solution of the system.
Closed horizontal lines in the graph of U correspond to periodic solutions
in the phase plane, and horizontal lines tangent at a local maximum of
U correspond to separatrices. If such a line is bounded, the separatrix is
homoclinic, that is, it goes from the saddle point and returns to it. If it
is tangent to two maxima, the separatrix is heteroclinic, going from one
saddle to the other.
Example of a Quartic Potential. Consider the quartic potential
U(x) = x4
4 −ax2
2 + bx + c

2.3. Conservative Systems
45
 U(x)
 x
 x
 dx/dt
 E
 E 1
 E 2
 E 1
 E
 E 2
Figure 2.12. Phase portrait derived from the potential function U. Various energy
levels are shown to correspond to various orbits in the phase plane.
for some constants a, b, and c. Figure 2.13 shows U and the correspond-
ing phase portraits in two typical cases. Note that the extrema of U are
determined by a cusp catastrophe (Section 2.4.3).
One special case is Duﬃng’s equation,
¨x + x −x3 = 0,
which arises in many applications. For example, it is an approximation to
a pendulum equation using
sin y ≈y −y3
3
and x = y/
√
3. In this case, U(x) = x2/2 −x4/4, so there are always three
rest points, x = 0 and x = ±1. The ﬁrst is a center and the second two are

46
2. Dynamical Systems
 x
 x
 U
 U
Figure 2.13. Phase portraits for a fourth-order potential. The two other typical
cases are found by the change of variables x →−x, which ﬂips these plots through
the y-axis.
saddle points. It is interesting that the saddle–saddle connections can be
found explicitly in this case. In particular, the function x(t) = tanh(t/
√
2) is
a solution of the equation that satisﬁes the boundary conditions x(±∞) =
±1.
2.3.3
Oscillation Period of x′′ + Ux(x) = 0
Consider the conservation equation
d2x
dt2 + ∂U
∂x (x) = 0.
Suppose that we set an energy level E and that corresponding to it is
an oscillation as shown in Figure 2.14. The energy level E determines the
values of x1 and x2, and solving
1
2
dx
dt
2
+ U(x) = E

2.3. Conservative Systems
47
 dx/dt
 x
 x
 x 2
1
Figure 2.14. Closed orbit for U(x) = E. The upper branch from x2 to x1 is
traversed in the same time as the lower branch from x1 to x2.
on the top half of the orbit gives
dx
dt =

2[E −U(x)].
Integrating this over the top half of an orbit, as shown next, gives
1
√
2
 x2
x1
dx

E −U(x)
= T
2 ,
which is half the period. Thus, the period of the oscillation is
T =
√
2
 x2
x1
dx

E −U(x)
.
2.3.4
Active Transmission Line
Figure 2.15 shows a series of circuits that are coupled by resistors (R). In
each circuit, there is a battery (voltage E) in series with a resistor (R∗).
Each is in parallel with a capacitor (C) and a tunnel diode the current
through which is given by f(V ).
The current coming into the node labeled Vi is Ii−1, and according to
Kirchhoﬀ’s law [83], it is balanced by the total current going out of the
node: Ii + I. In turn, I splits into three components, one for each branch
in the circuit:
I = f(Vi) + (Vi −E)
R∗
+ C dVi
dt .

48
2. Dynamical Systems
 V i
 R *
 I
 C
 R
 E
 f(V)
 I i-1
 V i-1
 R *
 C
 E
 f(V)
 V i+1
 R *
 C
 R
 E
 f(V)
 f(V)
 Ground
Figure 2.15. An active transmission line.
On the other hand,
Ii−1 = Vi−1 −Vi
R
and
Ii = Vi −Vi+1
R
.
Combining these formulas gives
C dVi
dt = Vi−1 −2Vi + Vi+1
R
−f(Vi) −Vi −E
R∗
.
A useful approximation views this as being nearly a continuum of circuits.
We write V (s, t) for the voltage at position s. Thus, Vi(t) = V (iδs, t), where
δs is the distance between circuit nodes. As the distance between nodes is
decreased, the resistance R decreases. We suppose that (δs)2/R ≈D as
δs →0. If δs ≪1, then the model becomes (approximately)
C ∂V
∂t = D∂2V
∂s2 −f(V ) −V −E
R
.
If we look for time-invariant voltage proﬁles, we study the equation
0 = DV ′′ −f(V ) −V −E
R
.
In the case of tunnel diodes, f(V ) is nearly a cubic curve, so this equation
has the form of a conservation law with quartic potential.
For example, consider the equation
V ′′ + A
V 3
3 −V

−V −E
R
= 0,
where here ′ = d/ds. This equation is conservative with potential energy
U(V ) = AV 4
12 −(1/R + A)V 2
2
+ EV
R .
Our earlier work on quartic potential functions enables us to describe the
solutions of this problem.

2.3. Conservative Systems
49
Given boundary conditions, such as V (±∞, t) = 0 for the original trans-
mission line, we determine that a static solution of this is possible only
if V = 0 is a homoclinic saddle point, that is, a saddle point where one
unstable separatrix eventually returns to it along a stable one. There are
many static solutions that are periodic functions of s but do not satisfy
the boundary condition. The structure of solutions of the transmission line
problem and their coordinated behavior as functions of t and s is rich, and
it deserves further study [130].
The dynamics of solutions for V (s, t) of the original model can also be
studied using the phase plane. For example, if for each of a sequence of
times the solution curve V (s, tn) is plotted on the V, V ′ coordinates, then
interesting aspects of the solution can be presented [74].
2.3.5
Phase-Amplitude (Angle-Action) Coordinates
It is often convenient to describe conservation models using the momentum
p = m ˙x rather than the velocity ˙x. At the same time, we change notation
by replacing x by q. We deﬁne the Hamiltonian (total energy) as
H(p, q) = p2
2m + U(q).
The Euler–Lagrange equation can now be written as (see Section 2.3.1)
dq
dt
=
∂H
∂p
dp
dt
=
−∂H
∂q .
This is a Hamiltonian system of equations corresponding to the physical
problem whose energy is H [28].
Note that if G(p, q) is a function that is invariant when evaluated along
solutions of this system, then
0
=
dG
dt = ∂G
∂p ˙p + ∂G
∂q ˙q
=
−∂G
∂p
∂H
∂q + ∂G
∂q
∂H
∂p
≡
[H, G].
The expression [H, G] is called the Poisson bracket, and so we see that any
function that is invariant under the ﬂow of solutions must commute with
H in the sense that the Poisson bracket vanishes, and conversely.
This observation is a starting point for the development of Lie’s algebraic
theory for nonlinear oscillators. Lie’s theory uses the product deﬁned by
the Poisson bracket to deﬁne an algebra. By viewing solutions as being
actions in this algebra, we can accomplish replacing our original nonlinear
problem by a linear one for representations of the Lie algebra [39].

50
2. Dynamical Systems
Hamiltonian systems are integrable, that is, the structure of these equa-
tions often allows us to change variables in a way that produces solvable
equations. This change of variables does not always exist, and even when it
does, it is not usually possible to carry it out. Still, there are two important
cases where the work is straightforward, namely, the harmonic oscillator
and the pendulum.
We ﬁrst introduce a new amplitude variable a by the formula
a = H(p, q),
and we deﬁne a new phase variable ξ and a new frequency ω by solving the
equations
ω
2
dq
dξ
=
∂H
∂p (p, q)
ω
2
dp
dξ
=
−∂H
∂q (p, q),
for p = p(ξ, a), q = q(ξ, a) subject to the constraints that H(p, q) = a. The
frequency ω is chosen so that these solutions p and q have period 2π in ξ.
This can be done near nondegenerate energy levels of the system, that is,
near orbits that represent nontrivial periodic solutions, but this step is the
ﬁrst major hurdle in using the method.
The change of variables
p
=
p(ξ, a)
q
=
q(ξ, a)
is invertible, since the Jacobian is
det


∂p
∂ξ
∂p
∂a
∂q
∂ξ
∂q
∂a

= −2
ω ̸= 0.
Therefore, we can deﬁne inverse variables by
ξ
=
ξ(p, q)
a
=
H(p, q)
[22]. The second problem is ﬁnding these inverse variables in a useful form.
When this can be done, it follows that a and ξ satisfy the equations
da
dt
=
0
dξ
dt
=
ω(a),
which can be integrated directly. Because of this fact, such Hamiltonian
systems are referred to as being integrable systems. Since a is an amplitude

2.3. Conservative Systems
51
and ξ is a phase variable, these are referred to as being phase-amplitude,
or sometimes angle-action, variables.
Example of a Pendulum. Chester’s analysis of the pendulum [22]
begins with the equation
d2x
dt2 + sin x = 0.
This can be converted to a Hamiltonian system by setting q for x and
H(p, q) = p2
2 + 2 sin2 q
2.
Then
dq
dt
=
p
dp
dt
=
−sin q.
We set H(p, q) = 2a2, and we seek functions p = p(ξ, a) and q = q(ξ, a)
and a constant ω(a) such that
ω dq
dξ
=
p
ω dp
dξ
=
−sin q,
where these functions are to have period 2π in ξ. We have

ω ∂q
∂ξ
2
= p2 = 4

a2 −sin2 q
2

,
so we study the two cases a < 1 and a > 1 separately. In the ﬁrst case, the
pendulum oscillates regularly, and in the second, it executes full cycles.
If a < 1, we set sin(q/2) = as, and we get an equivalent integral equation
for s,
ω
 s
0
(1 −σ2)−1/2(1 −a2σ2)−1/2dσ = ξ,
if q = 0 corresponds to ξ = 0. The inverse relation is
s = sin(q/2)
a
= sn
 ξ
ω , a2

,
where sn denotes the elliptic sine function [1].
This function is known to have period 4K(a2) in ξ/ω, where
K(a2) =
 1
0
ds

(1 −s2)(1 −a2s2)
=
 π/2
0
dφ

1 −a2 sin2 φ
.

52
2. Dynamical Systems
In order that the function sn(ξ/ω, a2) have period 2π in ξ, we make the
choice
ω =
π
2K(a2).
Note that as a →0, K(a2) →π/2, so the period of small amplitude
oscillations is 2π.
For a > 1, we deﬁne sin(q/2) = s, so
ω
 s
0
dσ

(1 −σ2)(1 −(σ/a)2)
= aξ
and
s = sin q
2 = sn
aξ
ω , a−2

.
This function has period 4K(a−2) in aξ/ω, or 2π in ξ if
ω =
πa
2K(a−2).
In this case the pendulum is executing full clocking oscillations. In ei-
ther case we have derived ω(a) for the integrable form of the pendulum
equations, as well as the change of variables that takes the pendulum to in-
tegrable form. Explicit formulas for the oscillations can be found by solving
for q in each case.
2.3.6
Conservative Systems with N Degrees of Freedom
A system of N particles will have N position and N momentum co-
ordinates. Say particle i has position qi(t) at time t and (generalized)
momentum pi(t). If the potential energy is
U(q1, . . . , qN),
then the Hamiltonian is given by the formula
H(p, q) =
N

i=1
p2
i
2mi
+ U(q),
and the equations of motion are
dqi
dt
=
∂H
∂pi
dpi
dt
=
−∂H
∂qi
for i = 1, . . . , N. Thus, 2N equations result, which are equivalent to the
N second-order equations
mj ¨qj + ∂U
∂qj
(q) = 0

2.3. Conservative Systems
53
for j = 1, . . . , N.
This is a starting point for many studies in statistical and celestial
mechanics [92, 129]. In addition, these equations arise as characteristic
equations in solving ﬁrst-order nonlinear partial diﬀerential equations.
They also arise in the calculus of variations, where they appear as Euler–
Lagrange equations. Finally, an extensive geometrical theory, a symplectic
geometry that is based on diﬀerential invariants of this system, has evolved.
Because of the central role played by such systems in a wide variety of math-
ematical disciplines and physics, these equations have been and continue to
be extensively studied. We study examples of this general system further
in later chapters. Here we note the following useful connection between
Hamiltonian systems and certain partial diﬀerential equations [28].
2.3.7
Hamilton–Jacobi Theory
Hamiltonian systems are closely related to certain ﬁrst-order partial diﬀer-
ential equations. On one hand, let φ(t, x, a), where x ∈EN, be a smooth
solution of the Hamilton–Jacobi equation
∂φ
∂t + H(x, ∇φ) = 0,
for t ≥0. We suppose that φ contains N parameters a1, . . . , aN such that
det
∂2φ
∂xi∂aj
̸= 0.
Then φ is called a complete integral of the equation. We suppose here
that H(x, p) is a continuously diﬀerentiable function of the 2N variables
x1, . . . , xN, p1, . . . , pN. Then the equations
∂φ
∂aj
= bj,
where b1, . . . , bn are free constants, can be used to determine x as a unique
function of t, a, and b.
Let us deﬁne
pj = ∂φ/∂xj;
then these functions satisfy the ordinary diﬀerential equations
dxj
dt
=
∂H
∂pj
dpj
dt
=
−∂H
∂xj
for j = 1, . . . , N [47]. This shows how solutions of a Hamilton–Jacobi par-
tial diﬀerential equation can deﬁne solutions of an associated Hamiltonian
system.

54
2. Dynamical Systems
On the other hand, a Hamilton–Jacobi equation
∂φ/∂t + H(x, ∇φ) = 0
with initial conditions
φ(0, x) = g(x)
and
∇φ(0, x) = ∇g(x)
for a given smooth function g(x) can be solved in the following way using
the Hamiltonian system. Deﬁne variables
pj = ∂φ
∂xj
for
j = 1, . . . , N,
and for each ξ ∈EN, let x(t, ξ), p(t, ξ) denote solutions of the Hamiltonian
system that satisfy the initial conditions
xj(0) = ξj,
pj(0) = ∂g
∂xj
(ξj).
Finally, let Φ(t, ξ) denote the solution of the equation
dΦ
dt = p(t, ξ) · ∂H
∂p [x(t, ξ), p(t, ξ)] −H
with initial condition Φ(0, ξ) = g(ξ). The change of variables x = x(t, ξ)
can be inverted: say, ξ = ˆξ(t, x). Then we deﬁne
φ(t, x) = Φ[t, ˆξ(t, x)].
This function satisﬁes the Hamilton–Jacobi equation
∂φ
∂t + H(x, ∇φ) = 0
and initial conditions
φ(0, x) = g(x),
∇φ(0, x) = ∇g(x).
We say that the Hamiltonian system forms the set of characteristic
equations for this Hamilton–Jacobi equation.
These two calculations show the relation between a Hamiltonian system
and its associated Hamilton–Jacobi equation. There are other interesting
connections between these systems with interpretations in the calculus of
variations [28]. The following example illustrates Jacobi’s method.
Example of a Two-Body Problem. If bodies of masses m1 and m2
are placed at points x and y ∈E3, respectively, then Newton’s law of
gravitation states that the potential energy of the pair is
U(x, y) = am1m2
r
,

2.3. Conservative Systems
55
where r = |x −y| and a is a constant. The equations of motion of this
system are
m1¨x
=
−∇xU
m2¨y
=
−∇yU.
The motion can be shown to lie in a plane, and for convenience, we place
the second mass at the origin of our coordinate system. The result is a
system of two equations for two of the components of x, say x1 and x2:
m1¨x1 + ∂U
∂x1
=
0
m2¨x2 + ∂U
∂x2
=
0,
where now
U(x1, x2) =
am1m2

x2
1 + x2
2
.
This is equivalent to a Hamiltonian system. Let m1 = m2 = 1. Then
H(x1x2, p1, p2) = p2
1 + p2
2
2
+ U(x1, x2).
The corresponding Hamilton–Jacobi equation is
∂φ
∂t + 1
2
 ∂φ
∂x1
2
+ 1
2
 ∂φ
∂x2
2
=
b

x2
1 + x2
2
,
where b = −a. In polar coordinates, this equation becomes
∂ψ
∂t + 1
2
∂ψ
∂r
2
+
1
2r2
∂ψ
∂θ
2
= b
r,
where ψ(t, r, θ) = φ(t, r cos θ, r sin θ). This equation can be solved as a sum
of functions, one in each variable. The result is that
ψ = a1t + a2θ + g(r, a1, a2),
where
g =
 r
r0

2bˆr−1 −2a1 −a2
2ˆr−2dˆr.
Solving the equations
b1 = ∂ψ/∂a1,
b2 = ∂ψ/∂a2
leads to the formula
r = c[1 −e2 sin(θ −b2)]−1,
which deﬁnes a solution of the two-body problem.

56
2. Dynamical Systems
2.3.8
Liouville’s Theorem
Consider the system of diﬀerential equations
dx
dt = f(x),
x(0) = ξ,
where x, ξ, and f are in EN and f is a smooth function of the components
of x. Let us consider the ensemble of solutions beginning in a volume V (0).
The size of this set after t time units will be given by the integral

V (t)
dx,
where V (t) is a collection of points
{x = x(t, ξ) : ξ ∈V (0)}.
This is the image of V (0) under the ﬂow deﬁned by the solutions of the
diﬀerential equation. If we make the change of variables ξ →x by setting
x = x(t, ξ), then we have from calculus that

V (t)
dx =

V (0)
det
∂x
∂ξ

dξ.
The derivative ∂x/∂ξ can be determined from the original equation by
solving the problem
d
dt
∂x
∂ξ = ∂f
∂x(x)∂x
∂ξ ,
∂x
∂ξ (0) = identity.
Thus, the function y(t) = det(∂x/∂ξ)(t) satisﬁes
˙y = tr[fx(x)]y,
y(0) = 1.
The coeﬃcient of the right-hand side of this equation is the divergence of
f, divf = ∇· f. It follows that

V (t)
dx =

V (0)
exp
  t
0
div f(x(t′, ξ))dt′

dξ.
If div f = 0, then volume V (0) = volume V (t) for any t > 0, since these
measures are deﬁned by the same integral. With these calculations, we have
proved the following useful theorem.
Liouville’s Theorem. Let the conditions listed above on f be satisﬁed.
Then the ﬂow deﬁned by the diﬀerential equation dx/dt = f(x) is volume-
preserving if div f(x) = 0 for all x.
This result shows that Hamiltonian systems deﬁne volume-preserving
ﬂows. In fact, the divergence of the right-hand side of a Hamiltonian system

2.4. Dissipative Systems
57
is zero, since
N

i=1
∂˙q1
∂qi
+
N

i=1
∂˙p1
∂pi
=
N

i=1
∂2H
∂pi∂qi
−
N

i=1
∂2H
∂pi∂qi
= 0.
Therefore, for each t the solutions of a Hamiltonian system deﬁne a mapping
of EN into itself for which the Lebesgue measure is invariant.
2.4
Dissipative Systems
We have seen that conservative systems typically have a rich structure of
oscillatory solutions. Systems that do not conserve energy are diﬀerent. For
example, oscillations of such systems are usually isolated, as for Lienard’s
equation in Section 2.1.3. Two important examples are described in detail
in this section: van der Pol’s equation and the second order phase locked
loop (PLL) model.
2.4.1
van der Pol’s Equation
Recall that van der Pol’s equation is
¨x + A(x2 −1) ˙x + x = 0.
We know from Section 2.1.3 that for any choice of A > 0 there is a unique
periodic solution of this equation, and all other solutions approach it as
t →∞except for the unstable equilibrium at x = 0, ˙x = 0.
It is diﬃcult to estimate the period of this oscillation. After some work
on perturbation methods in Chapter 8 we will see that the period for large
values of A is comparable to A, and for small values of A the period is
comparable to 2π. Figure 2.16 shows the oscillation for two values of A.
2.4.2
Phase Locked Loop
The phase locked loop (Section 2.2.4) is one of the basic circuits of modern
electronics. It is the basis of many important synchronous control systems,
including FM radio, Doppler radar, and computer timing devices [83]. The
voltage-controlled oscillator neuron model (VCON) is a model in mathe-
matical neuroscience that is similar to a phase locked loop [75]. A PLL
comprises a VCO whose output is V (x) = cos x, a phase detector that
multiples V (x) by the input, say W, and a low-pass ﬁlter whose output
controls the VCO. The mathematical model is
dx
dt
=
ω + z
τ dz
dt
=
−z + W cos x.

58
2. Dynamical Systems
−2
−1
0
1
2
−5
−4
−3
−2
−1
0
1
2
3
4
5
a
−2
−1
0
1
2
−5
−4
−3
−2
−1
0
1
2
3
4
5
b
Figure 2.16. (a) A = 10.0, x = x′ = 0 is an unstable node. The underlying
cubic isocline is indicated with dashed lines. The portions of the solution near
this isocline are traversed slowly compared to the rapid jumps away from it. (b)
A = 0.5. The limit cycle is approximately a circle, and its period is nearly 2π. In
this case the solution shown starts at x = 1, x′ = 0, and it slowly winds out to
the limit cycle.
In this section we study the free case of this system when W = A is a
positive constant.
With y = ω + z, the system takes the form
dx
dt
=
y
dy
dt
=
−σy + I + f(x),
where σ = 1/τ and I = ω/τ are constants and f(x) = (A/τ) cos x.
This problem can be analyzed completely. First, all solutions approach
the strip
S = {(x, y) : I −f ∗≤σy ≤I + f ∗},
where f ∗= maxx |f(x)| = A/τ. In fact, we see directly from the second
equation that solutions approach this strip at an exponential rate with time
constant σ. It is appropriate to view this system as being on the cylinder

2.4. Dissipative Systems
59
|y| < ∞, 0 ≤x ≤2π, since the equations are invariant under the translation
x →x + 2π. We consider several cases.
Case |I| > f ∗. When I > f ∗, there are no static states, since the isoclines
dx/dt = 0 and dy/dt = 0 never cross. Using the fact that the strip S is
invariant, we will show that the mapping deﬁned from the cross-section of
this strip at x = 0 to the one at x = 2π has a ﬁxed point in S, and so there
is a periodic solution, say y = Y (x). This periodic solution is a limit cycle
on the cylinder. We prove this in the following theorem [98].
Theorem. If I > f ∗, there is a unique limit cycle on the cylinder, and
all solutions approach it as t →∞.
Proof. First, we need only consider the strip S. Since S is invariant, the
solutions deﬁne a mapping of the cross-section x = 0 of S into the one for
x = 2π. This mapping is also a contraction mapping, which follows from
the following short calculation showing that the mapping has a positive
derivative that is less than one.
Let M(y0) denote the value of y when x = 2π given that y = y0 when
x = 0. We can write y as a function of x, since there are no critical points
in S, and we have
dy
dx = −σy + I + f(x)
y
,
y(0) = y0. The derivative ∂y/∂y0 satisﬁes the linear problem
d
dx
∂y
∂y0
=
−
I + f(x)
y2
 ∂y
∂y0
∂y
∂y0
(0)
=
1.
Therefore,
M ′(y0) = exp

−
 2π
0
I + f(x)
y2
dx

< 1.
It follows that this transformation has a unique ﬁxed point, and it lies on a
limit cycle, say L. The stability of this limit cycle follows from the stability
of S and the fact that L is the largest invariant set in S.
If we denote the limit cycle L by y = Y (x), then the relation between x
and t on this limit cycle can be determined by integrating
dx
Y (x) = dt.
In fact, the period is
T =
 2π
0
dx
Y (x).

60
2. Dynamical Systems
0
2
4
6
8
10
12
−4
−3
−2
−1
0
1
2
3
4
Figure 2.17. In this case, I = 0.5, τ = σ = 1.0, f(x) = cos x, and we see that
all solutions approach stable nodes except for the stable manifolds of the saddle
points. Thus, the VCON output equilibrates to a stable voltage, V (xL). Here
0 ≤x ≤4π shows two sheets of the cylinder. On each the left equilibrium is a
stable node and the right one is a saddle point.
Case |I| < f ∗. In this case there are two equilibria on the cylinder,
namely, when f(x) = −I. The left one is denoted by xL, and for it f ′(xL) <
0. The other is denoted by xR, and f ′(xR) > 0. The linearization of the
system about these states has the form
d2x
dt2 + σ dx
dt −f ′(x∗)x = 0.
The characteristic polynomial is λ2 + σλ −f ′(x∗) = 0, and its roots are
λ = −σ
2 ±

σ2
4 + f ′(x∗).
Thus, we see that x∗= xL is a stable sink. It is a stable spiral point if I
is small, and it is a stable node if I is near f ∗, since f ′(xL) ≈0. Similarly,
we see that xR is a saddle point. The following theorem describes stability
properties of the system when |I| < f ∗.
Theorem. For each value of τ and A, there is a number I∗(A, t) < f ∗
such that

2.4. Dissipative Systems
61
1. If I < I∗, then the sink is globally stable on the cylinder, with the
exception of separatrices.
2. If I∗< I < f ∗, then a stable sink and a stable limit cycle both exist.
The proof of this theorem is given in [98]. It is accomplished by showing
that if I is small, then the stable and unstable manifolds are as in Fig-
ure 2.17, and for I near I = 1 as in Figure 2.18. The number I∗is the value
at which there is a saddle-saddle connection.
0
2
4
6
8
10
12
−4
−3
−2
−1
0
1
2
3
4
Figure 2.18. In this case, I = 0.99, and the other data are as in Figure 2.17.
We see that there is a stable node and a stable periodic solution, y = Y (x), for
this choice of parameters. Y is referred to as being a running periodic solution
or a limit cycle on the cylinder. The running periodic solution corresponds to
repetitive ﬁring by the cell, and the VCON has two stable modes of behavior in
this case.
This system exhibits hysteresis as ω increases from zero to A and back to
zero. For small values of ω, the system equilibrates to a stable node, where
it remains until the saddles and nodes coalesce and disappear (at ω = A).
After this, the limit cycle is reached as shown in Figure 2.19. When ω is
decreased, the system remains on the limit cycle until the saddle-saddle
connection is reached. Below this, the solution equilibrates to a sink.

62
2. Dynamical Systems
0
2
4
6
8
10
12
−4
−3
−2
−1
0
1
2
3
4
Figure 2.19. In this case, I = 1.1, and the other data are as in Figure 2.17. There
are no equilibria, but there is a unique limit cycle, and it is globally stable. The
dots show where the saddle and node collided.
2.4.3
Gradient Systems and the Cusp Catastrophe
Let F(x) denote a real valued mapping from x ∈EN to E1. The gradient
of F, denoted by ∇F(x), is a vector that is normal to the level surface
F(x) = c at the point x. Thus, solutions of the equation
dx
dt = −∇F(x)
are curves in EN that are parallel to these normal vectors. Because of this,
F plays the role of an energylike function. However, the values of F are
not conserved as is energy in a conservative system. Instead, F decreases
along solutions. In fact, if x(t) is a solution of this gradient system, then
dF
dt (x(t)) = ∇F(x) · ˙x = −|∇F(x(t))|2,
which is negative unless x is an equilibrium for the system. We call such a
system dissipative.

2.4. Dissipative Systems
63
 x
 b
 a
Figure 2.20. Bifurcation diagram of the cusp catastrophe.
There can be no periodic solution to a gradient system, since a solution
having a least period T > 0 will satisfy
0 = F[x(T)] −F[x(0)] =
 T
0
dx
dt ∇F(x(t))dt =
 T
0
|∇F(x(t))|2dt,
which implies that ∇F(x) = 0 for all t. Thus, x(t) must be an equilibrium
of the system.
Gradient systems arise in several settings. One interesting source is from
optimization problems: Suppose that we want to ﬁnd proper extrema of the
function F(x). We ﬁnd these among the values of x for which ∇F(x) = 0.
Thus, we solve either of the associated gradient problems
˙x = ±∇F(x)
using an initial guess x(0). If this solution approaches a static state, the
limit will be a candidate for an extremum. We do this for many initial points
and build up a library of possible extrema that must be tested separately
[124].
Example of the Cusp Catastrophe
The cusp catastrophe surface provides a number of interesting examples
of nonlinear oscillations. We saw this with the quartic potential in a conser-
vative system. It also provides interesting examples of dissipative systems.
Consider the quartic polynomial
F(x) = x4
4 −ax2
2 + bx + c,
where a, b, and c are constants. Note that this form includes all quartics,
since the coeﬃcient of x3 is the sum of the roots and by a translation this

64
2. Dynamical Systems
 x
 b
 a
Figure 2.21. van der Pol oscillation on a cusp surface.
can always be made zero. We study the solutions of the gradient system
˙x = −∂F
∂x .
First we ﬁnd the critical values, that is, the values of x for which ∂F/∂x = 0.
To do this, we must solve the equation
x3 −ax + b = 0
in a way that describes all solutions for any choices of a and b.
There are either one or three real roots, and they can be found by solving
for b and plotting the resulting surface:
b = ax −x3.
Extreme values of this function of a and x occur where ∂b/∂x = 0, that is,
a −3x2 = 0. Thus,
b = ±2a3/2
3
√
3 .
The result is depicted in Figure 2.20.
On the other hand, the ax trace of the solution when b = 0 is a parabola
a = x2 and the line x = 0. Combining these facts leads to the surface
plotted in Figure 2.20. This is called the cusp catastrophe surface [133].
The upper and lower branches of this surface are stable equilibria for the
system
˙x = −∂F
∂x .
Interesting oscillators can be generated by allowing a and b to change with
time, and the following examples illustrate two of them.
van der Pol’s Equation.

2.5. Stroboscopic Methods
65
 x
 b
 a
Figure 2.22. Lock-washer oscillation on a cusp surface.
Consider the system
˙x = −∂F
∂x
˙a = 0,
a(0) > 0
˙b = εx,
where ε is a small parameter, ε ≪1. Figure 2.21 shows the solutions of
this system. Since ε ≪1, the solutions equilibrate to the cusp catastrophe
surface faster than b changes. Therefore, the solutions appear to be glued
to this surface except when they cross an edge.
Lock-Washer Oscillator.
Consider the system
˙x
=
−∂F
∂x
˙a
=
−εb
˙b
=
εa.
Now, the point [a(t), b(t)] executes a slow circle in the ab plane, and the x
variable is attracted to the stable branch of the cusp catastrophe surface
lying above or below the circle. Figure 2.22 shows a typical solution of this
problem.
Many other oscillations can be visualized using this surface by adjusting
the dynamics of a and b. This surface occurs in our analysis of various
aspects of nonlinear oscillations.
2.5
Stroboscopic Methods
If we trace an oscillation using a ﬂashing light, then the sequence of points
observed at the ﬂashes deﬁnes a table of values for an iteration of EN into
itself. Little is known about such iterations when N ≥3.

66
2. Dynamical Systems
So, we restrict attention here to examples of interval mappings, circle
mappings, and mappings of the plane. Most of these topics are of inde-
pendent interest, but we restrict our attention in most cases to problems
related directly to oscillations and chaotic dynamics.
2.5.1
Chaotic Interval Mappings
Iterations of a real-valued function can be surprisingly complicated. Even
simple functions can have highly irregular iterates, and similar behavior is
found in solutions of certain nonlinear oscillator problems. We begin with
deﬁnitions and a summary of some relevant work on function iteration.
This is followed by some computer experiments for iterations.
Consider a continuous function g that maps a ﬁnite interval I = (a, b)
into itself. We deﬁne iterates of g by the notation g0(x) = x, g1(x) = g(x),
and gm(x) = g(gm−1(x)) for m = 2, 3, 4 . . . . We say that x∗is a ﬁxed point
of period m if gm(x∗) = x∗, but gj(x∗) is not equal to x∗for j < m. The
orbit of a point y is the set of points
Ω(y) = {gj(y) : j = 0, 1, 2, . . . }.
Finally, we say that x∗is a stable ﬁxed point of g if (1) g(x∗) = x∗and
(2) for every point y near x∗we have that
lim
n→∞gn(y) = x∗.
Sarkovski’s Sequence.
A striking result found by Sarkovski describes interesting things about
ﬁxed points of g [126]. Sarkovski’s sequence is deﬁned by rearranging the
natural numbers as follows:
1, 2, 22, . . . , 2n, . . . # . . . , 9 · 2n, 7 · 2n, 5 · 2n, 3 · 2n, . . . , 9 · 2, 7 · 2, 5 · 2,
3 · 2, . . . , 9, 7, 5, 3.
The symbol # separates powers of 2 (pure harmonics) coming from the left
from partials (odd numbers and their harmonics) coming from the right.
Sarkovski showed that if g has a ﬁxed point of order p, then it has a
ﬁxed point of each order q lying to the left of p in this list. Thus, if there
is a ﬁxed point of period two, then there is also a ﬁxed point; at the other
extreme, the presence of a ﬁxed point of period 3 implies that there are
ﬁxed points of all periods (see also [101]).
In one sense, Sarkovski’s sequence describes the complexity of invariant
sets for g. The farther along g is in the sequence, the richer the collection
of sets that are invariant under it.
An interesting approach to iteration of smooth functions is described by
Ulam [61, 134]. Under certain circumstances there is a function (called a
density function) that is invariant under g. A simple example of this occurs

2.5. Stroboscopic Methods
67
when
g = min(2x, 2 −2x)
and I = [0, 1]. In this case, the inverse image of an interval of length
L is the union of two intervals of total length L. Therefore, the density
function d = 1 is invariant, and we say in this case that Lebesgue measure
is invariant under g. Invariant measures describe for interval mappings the
idea of volume for Hamiltonian ﬂows [see Section 2.3.8].
The ergodic theorem [117] has a useful implication for this simple ex-
ample. It states (roughly) that if Lebesgue measure is invariant, iterates
under g of most initial points move all over the interval. In particular, the
probability of an iterate hitting a given subinterval is proportional to the
length of that subinterval. This is the basis of the work in [76], which is
described next.
Iteration Histogram and Entropy.
The ergodic theorem suggests a method for using a computer to exper-
iment with function iterates. In particular, let us partition the invariant
interval I into M equal parts (cells) and select a point from I at random.
This point is iterated N ∗times under g and the number of the iterates
that hit each cell is recorded. If N ∗and M are suﬃciently large, then in
cases where the ergodic theorem applies (in particular, when there is an
invariant measure that is absolutely continuous with respect to Lebesgue
measure) the histogram that results from the iteration experiment reﬂects
the graph of an invariant density function.
Suppose that the iteration histogram has cell contents c1, . . . , cM. If we
normalize these by setting
pj = cj
 M

k=1
ck,
then (p1, . . . , pM) deﬁnes a probability distribution. The number
H(p) = −
M

j=1
pj log pj
is called the entropy of the distribution described by p.
In the above equation H indicates how spread out are the components
of p. For example, if the components of p were approximately normally
distributed, we would have pj ≈exp[−(j −m)2], and for this H would be a
second moment of the distribution. Therefore, it is related to p’s variance.
If all cells are equally ﬁlled (pj = 1/M), then H(p) = log M, which is the
maximum value of H. If only one cell is ﬁlled (pJ = 1), then H(p) = 0,
which is the minimum value of H.
Rather than plotting a density function’s histogram as in [76], we will
simply indicate which cells are eventually hit by the iteration. Figure 2.23

68
2. Dynamical Systems
2.5
2.8
3.1
3.4
3.7
4.0
1
0.0
400
300
200
100
0
r
Period 22
Period 21
Period 20
Entropy
Iterate Density
Figure 2.23. Iterate density and entropy as computed for g(x) = rx(1 −x).
shows the result of the iteration experiment performed for the function
g(x) = rx(1 −x).
In Figure 2.23, the value g(1/2) is iterated 2,000 times, and the ﬁrst 100
iterates are discarded to suppress transients. The value x = 1/2 is chosen
for the initial point of the iteration because it is known that for any choice
of r the orbit of this point evolves into the invariant set of g that attracts
most initial points. We plot also the entropy of the iteration’s distribution
to quantify its complexity.
In Figure 2.23, the unit interval 0 ≤x ≤1 is partitioned into 300 subin-
tervals. The dark pixels are those subintervals in which some iterates of the
mapping lie. Figure 2.23 illustrates high-resolution computation followed
by pixel truncation imposed by the plotting device. In this, we choose 300
values of r between r = 1 and r = 4, and for each we plot horizontally the
pixels containing at least one iterate of g. We could successively rescale the
viewing window and get successively more reﬁned views of the iteration,
since the computations are of greater accuracy than the plotting device
used here. In Figure 2.23, all cells having at least one iterate are plotted

2.5. Stroboscopic Methods
69
for each of 300 values of r between 1 and 4. We see ﬁrst (1 ≤r ≤3) the
stable ﬁxed point x = (r −1)/r. Beyond r = 3, there is a cascade of new
periodic orbits appearing that correspond to Sarkovski’s sequence lying to
the left of #. The # occurs approximately at r ≈3.57 for this function.
The left and right branches of this diagram come together at r = r∗≈3.68.
The behavior beyond # (r > 3.57) is often referred to as being chaotic,
although r intervals where there are stable 6-, 5-, and 3-period orbits are
clearly visible even at the level of resolution of this experiment. The term
chaotic is not clearly deﬁned, and it is used with diﬀerent meanings in
various contexts. We take it to mean highly irregular behavior.
The experiment described in Figure 2.23 shows that the simulation is
useful when there is a single ﬁxed point of g, a case to which the ergodic
theorem does not apply directly. In such a case there is an invariant measure
whose density function is a Dirac delta function. Still, the iteration experi-
ment produces a quantized approximation to the Dirac function, since the
iterates all accumulate in the cell containing the ﬁxed point. This observa-
tion enables us to uncover Sarkovski’s sequence from function iteration, up
to the resolution of the output device, as shown in Figure 2.23.
Finite Semigroup Approximation.
Some insight into the complicated dynamics described above can be
found by approximating the function g by a pixel approximation. We par-
tition the interval [0, 1] into N equal subintervals, J1 = [x0, x1], J2 =
(x1x2], . . . , JN = (xN−1, xN]. We deﬁne an integer-valued function f by
the table of values
f(i) = j
if g(xi−1) ∈Jj
for i, j = 1, . . . , N.
Thus, f(i) = j if g maps the left endpoint of Ji into Jj, and f deﬁnes a
mapping of the set S = {1, . . . , N} into itself. It also describes the graph
of g when N pixels are used to plot it. The iterates of f deﬁne a ﬁnite
semigroup [95] Figure 2.24 shows the result of performing the iteration
experiment just described for f rather than g.
Markov Chain Approximation to g.
Are iterates of g random? Using f, we can associate with g a Markov
chain. Let us deﬁne the graph matrix G[f] by the formulas
Gj,k =

1
if f(j) = k,
0
otherwise,
for j, k = 1, . . . , N. The matrix G is a stochastic matrix, since each of its
row sums is equal to one, and each of its components is nonnegative. The
graph of f appears in G[f], where it is traced by the ones appearing in that
matrix as shown in Figure 2.24.
The spectrum of G consists of ones, zeros, and some roots of unity.
These eigenvalues are closely related to the dynamics of f. In fact, each
nontrivial root-of-unity eigenvalue corresponds to a periodic orbit of f, and
the corresponding left eigenvector consists of ones lying over a periodic

70
2. Dynamical Systems
1
10
20
30
40
50
60
70
80
90
100
100
90
80
70
60
50
40
30
20
10
1
Figure 2.24. Graph transition matrix for g(x) = 3.98x(1 −x) using 100 pixels.
orbit of f. Similarly, each unit eigenvalue (those not among roots-of-unity
eigenvalues) corresponds to a ﬁxed point of f and each zero eigenvalue
corresponds to a transient state of f. Finally, we can associate with g and
N another Markov chain. We deﬁne Mjk to be the proportion of Jj that
maps into Jk under g. This Markov chain presumably better approximates
g than does f or G[f]. Figure 2.26 shows the results of a Monte Carlo
simulation based on this Markov chain.
The complexity of these iterations can be described using the histogram
entropy. For example, let the eigenpairs for G[f] be denoted by λk, φk for
k = 1, . . . , N. Add up all of the eigenvectors φk for which λk ̸= 0:
φ =

λk̸=0
φk.
Normalize this vector by its length, say q = φ/|φ|, so q = (q1, . . . , qN)
is a probability vector. The entropy H(q) describes the complexity of the

2.5. Stroboscopic Methods
71
2.5
2.75
3
3.25
3.5
3.75
4
1
.5
0
200
150
100
50
0
Entropy
Iterate Density
Figure 2.25. Iteration and entropy of the pixel approximation to g using 100
pixels.
iterates of f and so gives an indication of the dynamics of g. A similar
statistic can be computed for the Markov chain M (see [37]).
2.5.2
Circle Mappings
Consider now a system of diﬀerential equations on a torus as described in
Section 2.2.2:
˙x
=
F(x, y)
˙y
=
G(x, y),
where F and G are diﬀerentiable functions that are doubly periodic, say
F(x + 2π, y) = F(x, y) = F(x, y + 2π)
for all x and y. If G ̸= 0, then we can divide the ﬁrst equation by the second
and replace y by t:
˙x = f(t, x),

72
2. Dynamical Systems
Figure 2.26. Markov chain transition matrix for g(x) using 100 pixels (r = 3.98).
Row sums add to 1.0, and shading indicates the relative density of each compo-
nent. In this example, the values are 0.8 on the original graph and 0.1 in each
cell adjacent to it.
where now f(t, x) = F(t, x)/G(t, x) is a 2π-periodic function of t and x.
Thus, certain systems on the torus are equivalent to periodically forced
scalar problems.
Poincar´e’s mapping of solutions is deﬁned by
φ : x(0) →x(2π) ≡φ[x(0)],
and it corresponds to a mapping of the circle y = 0 on the torus into itself.
Consider a function Y (t) for which
dY
dt = f(t, Y )
and
Y (0) = x(0) + 2π.
Let z = Y (t) −x(t). Then
dz
dt = f(t, z + x) −f(t, x)
and
z(0) = 2π.
But z(t) = 2π is the unique solution of this problem! Therefore, Y (t) =
x(t) + 2π, and so
φ(x + 2π) = φ(x) + 2π
for all x. This is referred to as the circle mapping property.

2.5. Stroboscopic Methods
73
Figure 2.27. Iteration histogram of Markov graph transition matrix.
Iteration of Circle Mappings.
Let xn+1 denote the image of xn under Poincar´e’s mapping:
xn+1 = φ(xn).
In particular, given a point x0, the dynamics of the solution x(t) are de-
scribed by the sequence {xn}, which gives the values of the solution x(t)
each time it crosses the circle t = 0. It is similar to ﬂashing a light on the
solution x(t) mod 2π each time t hits an integer multiple of 2π, and so this
is sometimes referred to as the stroboscopic method [111].
Because of the circle mapping property, it is necessary to consider only
the iterates of φ modulo 2π. In fact, if we deﬁne a sequence yn to be the
residues of the sequence xn modulo 2π (i.e., xn = 2πMn + yn for some
integer Mn, where 0 ≤yn < 2π), then
xn+1 = yn+1 + 2πMn+1 = φ(xn) = φ(yn + 2πMn) = φ(yn) + 2πMn,
and so
yn+1 = φ(yn) mod 2π.
For example, consider the diﬀerential equation
˙x = α,

74
2. Dynamical Systems
where α is a constant. The solutions are
x(t) = αt + x(0).
Therefore,
φ(x) = x + 2πα,
so φ amounts to rotation through 2πα radians. This case is referred to as
the Kronecker ﬂow on the torus [115]. The iterations modulo 2π become
yn+1 = yn + 2πα
(mod 2π).
These are plotted in Figure 2.28.
We see that if α is rational, then every orbit closes, since in that case
yn = y0+2παn = y0 when n is a multiple of the denominator in α. But if α
is irrational, every orbit is dense in the torus, and so all orbits are ergodic.
The rotation number is deﬁned for Poincar´e’s mapping by the formula
ρ = lim
t→∞
x(t)
t
= lim
n→∞
φn(ξ)
2πn ,
where ξ is the initial condition of x(t). Recall that ρ does not depend on
the choice of ξ (see Section 2.2.2).
For dx/dt = α, we have
lim
n→∞
φn(ξ)
2πn = lim
n→∞
2πnα
2πn = α.
Therefore, we have a simple illustration of Denjoy’s theorem.
The next example illustrates a use of the rotation number in computer
simulations of a ﬁrst-order VCON network. Consider the system as
˙x
=
ω + cos x + (1 −cos x)(1 + cos y)
˙y
=
1.
Figure 2.29 shows the rotation number of this equation. We clearly see
intervals where the graph of ρ plateaus, and it is over these that x is
phase-locked to y.
2.5.3
Annulus Mappings
A variety of interesting results were derived by H. Poincar´e and G. D.
Birkhoﬀfor mappings of an annulus into itself [12]. An annular region in the
plane is one that is bounded by two concentric, nonintersecting smooth arcs.
Mappings of an annular region into itself occur naturally when we study the
response of a nonlinear oscillation to periodic forcing. The forced oscillation
often lies near the periodic solution, and so an invariant annular region is
formed. Poincar´e’s Twist Theorem can be applied to prove the existence of
periodic and more complicated oscillations for annulus mappings.

2.5. Stroboscopic Methods
75
0
2
2
n
n+1
π
π
ψ
ψ
Figure 2.28. ψn+1 = ψn + 2πα modulo 2π for α = 3/8.
Poincar´e’s Twist Theorem. Suppose that Φ maps an annular region
A in E2 into itself such that Φ preserves area and leaves the boundaries of
A invariant. Suppose that the outside boundary is rotated one way and the
inside boundary the other way. Then there must be at least one ﬁxed point
for Φ in A.
The proof is not presented here. If the conditions of this theorem are
satisﬁed and if Φ is Poincar´e’s mapping for some dynamical system, then
that system must have a periodic solution whose stroboscopic iterates lie
in A. In fact, the behavior of iterates of Φ are usually much richer, as in
the example of this theorem that is presented in Section 2.6 [86].
2.5.4
Hadamard’s Mappings of the Plane
Let us now consider more general mappings of the plane into itself. We
begin with a linear iteration
xn+1
=
(1 + σ)xn
yn+1
=
(1 −τ)yn,
where σ and τ are real numbers with 0 < 1 −τ < 1 < 1 + σ. Following the
work of Hadamard [56], we begin with a circle of initial data
x2
0 + y2
0 = c2,

76
2. Dynamical Systems
0
1.01
1.18
1.34
1.5
1.1
.82
.55
.28
0
Frequency
ρ
0
1.01
1.18
1.34
1.5
1
.75
.5
.25
0
Frequency
P−map
Figure
2.29.
Rotation
number
and
return
map
simulations
for
˙x
=
ω + cos 8πx + 0.1(1 −cos 8πx) cos 2πt. Note that there is a unique
ﬁxed point for the return mapping when ρ = 1, two points when ρ = 1/2, etc.

2.5. Stroboscopic Methods
77
where c is a constant. Then the nth iterate satisﬁes

xn
(1 + σ)n
2
+

yn
(1 −τ)n
2
= c2,
which is the formula for an ellipse having radius c(1 + σ)n along the x-axis
(its major axis) and radius c(1−τ)n along the y-axis (its minor axis). Thus,
the circle generates a sequence of ellipses that converge to the x-axis.
The point x = 0, y = 0, is an equilibrium for this system. It is a hy-
perbolic (saddle) point, since its characteristic multipliers are 1 + σ > 1 >
1 −τ.
Next, consider a nonlinear mapping
xn+1
=
(1 + σ)xn + f(xn, yn)
yn+1
=
(1 −τ)yn + g(xn, yn),
where f and g are smooth functions having no linear terms in their Taylor
expansions near x = 0, y = 0. We write
(xn+1, yn+1) = Φ(xn, yn)
for this iteration. In analogy with Perron’s Theorem for diﬀerential equa-
tions (Chapter 3), we expect there to be a smooth stable manifold and a
smooth unstable one. This fact will not be proved here. However, we can
see that this is the case near x = 0, y = 0.
First, ﬁnd a function y = Y (x) for x near 0 such that
Y = (1 −τ)Y + g(x, Y )
and Y (0) = 0. This can be done, since the following conditions are satisﬁed:
1. x = 0, Y = 0 is a solution.
2. The function g is smooth near this point.
3. The Jacobian {∂[−τY + g(x, Y )]/∂Y }(0, 0) = −τ ̸= 0.
Therefore, the implicit function theorem ensures that there is a unique
solution of this equation that satisﬁes Y (0) = 0. The solution is smooth,
and it can be expanded in a Taylor polynomial about x = 0.
In fact, the set
U = {(x, y) : y = Y (x)}
is the unstable manifold for this system, and any point beginning on it [say,
y0 = Y (x0)] generates a sequence (xn, yn) that diverges from (0, 0) as n
increases.
Similarly, we can ﬁnd a function x = X(y) that solves the problem
X = (1 + σ)X + f(X, y)
for y near 0. The set S = {(x, y) : x = X(y)} is the stable manifold for this
problem.

78
2. Dynamical Systems
Homoclinic Points.
The stable and unstable manifolds can eventually cross, and when this
happens, the consequences are dramatic. Suppose that there is a point
R = (ξ, η) ∈S ∩U. Then, Φn(R) →(0, 0) as n →±∞. It can also happen
that the manifolds S and U cross transversally at R; that is, the tangents
to these two manifolds at R are not collinear, and we say that R is a
transversal homoclinic point. In this case, the loop in Figure 2.30 on the
manifold U between R and Φ(R) must approach S as n →∞. It becomes
terribly wrapped under iterations of Φ.
In particular, consider the rectangular region R in Figure 2.30. It is
known that R contains an invariant set that has inﬁnitely many periodic
solutions in it, as well as solutions that remain in R but never repeat. These
are aperiodic oscillations. In fact, there are two subsets of R, say labeled 0
and 1, such that given any sequence of ones and zeros, there is a solution
that hits the set 0 and the set 1 in the order speciﬁed by this sequence.
This also occurs in forced oscillators, as is shown later [5].
2.6
Oscillations of Equations with a Time Delay
Equations with time delays can often be analyzed using iteration methods.
Consider a system of diﬀerential-diﬀerence equations
˙x = f[x(t), x(t −σ)]
for x, f ∈EN, and where σ > 0 is a ﬁxed time delay. It is shown in [10]
that if f is a smooth function of its arguments and if x is speciﬁed on some
interval of length σ, say
x(t) = ψ(t)
for −σ ≤t ≤0,
then there is a unique solution of this system on some future interval. In
fact, on the interval 0 ≤t ≤σ, this is just the system of ordinary diﬀerential
equations
dx
dt = f[x(t), ψ(t −σ)],
x(0) = ψ(0),
and all the usual existence and uniqueness theory for ordinary diﬀerential
equations carries over. If a solution exists, the process can be continued by
marching forward in steps of size σ.
The linear delay equation
˙x = −αx(t −1),
x(t) = ψ(t)
for −1 ≤t ≤0
where α is a scalar illustrates several interesting things. First, we can solve
this problem using Laplace transforms. Applying the Laplace transform to

2.6. Oscillations of Equations with a Time Delay
79
xxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxx
S
U
R
Figure 2.30. S and U for a transverse homoclinic point. Inﬁnitely many periodic
orbits hit the rectangle R. In addition, given any sequence of 0’s and 1’s there
are two sets O and I in R and an orbit that hits these two sets in the order listed
in the given sequence [5].
both sides of this equation gives
px∗(p) −x(0) = −α exp(−p)x∗(p) −α
 0
−1
exp[−p(s + 1)]ψ(s)ds.
Therefore, the characteristic equation is
p + α exp(−p) = 0,
since this equation describes the poles of the problem’s transfer function
(see Chapter 1). [10] further shows that there are countably many complex
number solutions to this equation, say {pm}, and that the solution x(t) can
be written as the series
x(t) =
∞

m=0
Bm exp(pmt).

80
2. Dynamical Systems
The complex values for p that solve the characteristic equation have the
form p = ρ + iτ, and so separating real and imaginary parts in the
characteristic equation gives an equivalent system
ρ
=
−αe−ρ cos τ
τ
=
αe−ρ sin τ.
When α = π/2, there are two imaginary characteristic values, namely,
ρ = 0, τ = ±π/2. For that value of α, the equation has periodic solutions.
When α < π/2, then ρ < 0, and so x(t) →0 as t →∞. Finally, when
α > π/2, there is a characteristic root having ρ > 0, so solutions grow as
t →∞.
It is appropriate to think of a diﬀerential-diﬀerence equation as being one
for functions that are in an inﬁnite dimensional space that is spanned by the
functions {exp(pnt)}. This observation leads to mathematical results that
have been eﬀectively used to study nonlinear parabolic partial diﬀerential
equations [131].
Note that setting τ = αt and y(τ) = x(τ/α) changes the example into
the equation
dy
dτ = −y(τ −α).
Therefore, increasing the value of α has the eﬀect of increasing the delay.
The Laplace transform calculations show that oscillations can appear as
the delay increases through α = π/2.
2.6.1
Linear Spline Approximations
A useful technique for approximating diﬀerential-diﬀerence equations of the
form
dx
dt = f[x(t), x(t −σ)]
with the goal of solving them numerically was derived in [7]. This approach
also gives useful insight to solutions of these equations. The idea is to take
the delay interval of length σ and divide it into N equal parts. At each point
of the partition, say tj, we deﬁne x(tj) to be a node of a linear spline. We
will approximate the function x(t) over this interval by taking a piecewise
linear function that agrees with x at the nodes tj. The approximating
function is described by a vector (y0, . . . , yN): Let
yj(t) = x(t −jσ/N)
for the N + 1 nodes j = 0, . . . , N. In particular, yN(t) = x(t −σ). Be-
tween nodes, yj is a linear function as shown in Figure 2.31. We interpret
diﬀerentiation in the equation to be from the right.

2.6. Oscillations of Equations with a Time Delay
81
With this notation, we see that the derivative of yj(t) is approximately
˙yj ≈yj−1 −yj
σ/N
.
Using the linear spline approximation, we obtain the system of ordinary
diﬀerential equations (containing no time delay)
˙y0
=
f(y0, yN)
˙yj
=
N
σ (yj−1 −yj),
for j = 1, . . . , N, for the components of the vector y(t). With this notation,
we have the following theorem.
Theorem on Linear Spline Approximation. Under the conditions
listed above,
x(t) = y0(t) + O(1/N)
as N →∞, uniformly for t on any ﬁnite set over which x(t) exists.
The proof of this result is given in [7].
Example of a Linear Spline Solution. Consider the equation
˙x = −αx(t −1)[1 −x2(t)].
The linear spline approximation method with N = 2 gives
˙y0
=
−αy2(t)[1 −y2
0(t)]
˙y1
=
−2(y1 −y0)
˙y2
=
−2(y2 −y1).
This system has equilibria when y2 = y1 = y0 for y0 = 0 and y0 = ±1. The
last two are hyperbolic. Linearizing about x = 0 gives the same equation
as in the preceding example. For α < π/2 it is stable. For α > π/2 there
appears a nonlinear oscillation.
2.6.2
Special Periodic Solutions
Consider the equation
˙x = h[x(t)]f[x(t −1)],
where f and h are smooth functions. We can transform this equation by a
change of variables x →g(z) into the form
˙z = F(z(t −1)).
In fact,
g′(z) ˙z = f{g[z(t −1)]}h[g(z)],

82
2. Dynamical Systems
 x(t)
 t
 y (t)
j
 t
 y 0
 y N
 y 1
Figure 2.31. (Top) x(t). (Middle) An equal partition of the t-axis on which the
linear spline approximation is based. (Bottom) The linear spline approximation
to x(t).
so if g′ = h(g), we have that F(z) = f[g(z)]. We see that if h(x) = 1 −x2
as in Section 2.6.1, then g = tanh z.
Thus, we consider the equation
˙z = F(z(t −1)),
where F is a smooth function. We look for special periodic solutions of this
equation that satisfy the conditions
z(t + 2) = −z(t),
z(−t) = −z(t).
Setting y(t) = z(t −1) and x = −z gives
˙x
=
−F(y)
˙y
=
F(x).
This Hamiltonian system was derived in [119].
An interesting feature of this system has been pointed out [119]. Suppose
that we try to solve for special periodic solutions using a semi-implicit Euler

2.7. Exercises
83
 F
 z
Figure 2.32. F(z) for the sample iteration.
numerical algorithm, say
yn+1
=
yn + ahF(xn)
xn=1
=
xn −ahF(yn+1).
This deﬁnes a mapping of the xy-plane into itself, say T(xn, yn). The
Jacobian of this system is given by
det

1
ahF ′(xn)
−ahF ′(yn+1)
1 −a2h2F ′(yn+1)F ′(xn)

= 1.
Therefore, T is an area preserving transformation of the plane.
Suppose that F(z) has the form shown in Figure 2.32. Then the equilibria
are determined from the equations
F(x∗) = F(y∗) = 0,
and their stability is determined using the eigenvalues of the matrix

0
−F ′(y∗)
F ′(x∗)
0

.
Moreover, for F as shown in Figure 2.32 this iteration has an invariant
annulus. Figure 2.33 shows a numerical simulation of this iteration.
Poincar´e’s Twist Theorem (Section 2.5.3) shows that there is at least
one ﬁxed point within this annulus. However, the actual behavior of the
iteration is much more complicated.
2.7
Exercises
2.1.
Reproduce the phase plane portraits for the four cases of a two-
dimensional linear system with constant coeﬃcients, as depicted in
Figures 2.1– 2.4.

84
2. Dynamical Systems
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
Figure 2.33. An invariant annulus is shown in iterations of the area preserving
mapping described in the text. Note that there are ﬁve elliptic points and four
hyperbolic (heteroclinic) points.
2.2.
The Poincar´e–Bendixson Theorem indicates that there are three
possible evolutions for a bounded trajectory of a two-dimensional
autonomous system: It approaches a stable equilibrium, a stable pe-
riodic orbit, or a stable necklace. Construct an example of each of
these cases.
2.3. a. The FitzHugh–Nagumo model arises in studies of tunnel diodes and
neurons:
dv
dt
=
w −f(v)
dw
dt
=
v −bw −E,
where f(v) = v(v −1)(v −a) and a, b and E are ﬁxed parameters,
0 ≤a ≤1 and b ≥0. Show that for some values of E, b, and a this
system has a unique periodic solution using the results for Lienard’s
equation.
b∗. Consider the general Lienard equation
d2x
dt2 + g(x)dx
dt + Ux(x) = 0.
Suppose that U and g are smooth functions (at least continuously
diﬀerentiable), that g is an even function of x (that is, g(−x) = g(x)

2.7. Exercises
85
for all x), U is an odd function (that is, U(−x) = −U(x) for all x),
and that U(±∞) = ∞. Also, suppose that there is a number α such
that
G(x) =
 x
0
g(s)ds
is negative for x < α and positive monotone for x > α with G(∞) =
∞. Show that there is a unique nontrivial periodic solution. Moreover,
show that any nontrivial solution approaches this solution as t →∞.
(Hint: Consider the function E(x, dx/dt) = (dx/dt)2/2 + U(x) in the
proof in Section 2.1.3.)
2.4.
Consider the diﬀerential equations
dx
dt = 1,
dy
dt = α
for (x, y) on the torus T = {(x, y) : 0 ≤x, y < 2π}
a. Show that the rotation number of this system is ρ = 1/α. Describe so-
lutions when α is a rational number. What happens to solutions when
α is irrational? Why? Discuss the computability in these two cases
by dividing the torus into small squares for which each is darkened
and remains so when a trajectory hits it. Corroborate your discussion
with a computer simulation illustrating each case.
b. If α = 1/29.6, plot the nonnegative function (cos x(t) cos y(t))+ over
a toroidal patch 0 ≤x, y ≤2π. If t denotes solar time in days, then
the pair (x, y) simultaneously records the solar and lunar times.
c. Use a computer simulation to calculate the rotation number of the
system
dx
dt
=
1 + λ + (1 −λ) sin(2x −y) + λ sin(x −2y)
dy
dt
=
2 −λ,
for 0 ≤λ ≤2. Plot ρ versus λ for each choice you make of λ (see
Figure 2.9).
d. Consider the equations
dx
dt = p,
dy
dt = q,
where p and q are integers and x(0) and y(0) are given, say x(0) = 1.0,
y(0) = 1.0. Show that ρ = p/q. The solution of this system is a
toroidal knot having winding numbers p and q. Plot the solution of
this equation in the four cases
i. p = 1
q = 2
ii. p = 1
q = 3
iii. p = 2
q = 3
iv. p = 5
q = 6.
Deduce that for a general system on the torus as considered by Denjoy
(Section 2.2.2) if the rotation number is rational (so all solutions

86
2. Dynamical Systems
approach a periodic solution whose rotation number is p/q), then
there is a torus knot that is a stable oscillation of the system.
2.5. a. Consider the three diﬀerential equations
dx
dt
=
a + sin(x −y)
dy
dt
=
b + sin(y −z)
dz
dt
=
c + sin(z −x),
where a, b, c > 0 and a + b + c > 3.
Reduce this system to one on a torus using the projection method in
Section 2.2.3. (Hint: x + y + z is a time-like variable.)
What is limt→∞x(t) : y(t) : z(t) if a = 2, b = 2, and c = 2?
b∗. The common ratios in part a can be plotted using areal coordinates:
Let p = x/(x + y + z), q = y/(x + y + z), r = z/(x + y + z). If a > 1,
b > 1, and c > 1, then these three numbers are nonnegative and add
to 1.0. Therefore, the point (p, q, r) can be identiﬁed with one lying
on an equilateral triangle in the positive orthant of E3. Plot these
numbers for t = 100π and for various choices of a, b, and c using
computer simulations (see Figure 7.4).
2.6. a. Plot the phase portrait of solutions to the conservative equation
d2x
dt2 + Ux(x) = 0
corresponding to each of the potential functions
i. U(x)
=
x2/2;
ii. U(x)
=
a(sin x/2)2.
b. Show that in case i, all solutions have period 2π.
c∗. Calculate the period of oscillations in case ii near stable equilibria.
Describe the period of oscillations of bound states as a function of
amplitude by plotting the energy E versus the period of the oscillation
having this energy. Use this calculation to discuss the solution of the
two-point boundary value problem
d2x
dt2 + Ux(x) = 0,
x(0) = 0,
x(τ) = 0.
For what values of τ is this solvable? How many solutions are there?
2.7. a. In Section 2.3.5 we derived the transformation from cartesian co-
ordinates to phase–amplitude coordinates for Hamiltonian systems:
p = p(a, ξ), q = q(a, ξ). Calculate the Jacobian of this transformation.
Carry out the full transformation in the case U(x) = x2/2. Derive the
change of variables and use it to solve the equation
d2x
dt2 + Ux(x) = 0.
b∗. Carry out the same program when U(x) = (sin x/2)2. (Hint: See [22].)
2.8. a. Consider the Hamiltonian H(p, q) = 
k=1,... ,N(p2
k+q2
k)/2+εH1(p, q),
where ε is a small number and H1(p, q) is a smooth (diﬀerentiable)

2.7. Exercises
87
function. Write the resulting Hamiltonian system in phase-amplitude
coordinates. (Hint: Set dqj/dt + iωjqj = yj exp ixj.)
b. A collection of N bodies, say located at points x1, . . . , xN in E3 and
having masses m1, . . . , mN satisfy the equations
mj d2xj
dt2 = −∂U
∂xj
for j = 1, . . . , N, where
U = −

k̸=j
mkmj
|xk −xj|
and the sum is taken over all indices j and k for which j ̸= k. Carefully
write out the resulting Hamiltonian system.
c. The two-body problem results in part b when N = 2. Use a computer
simulation to plot solutions to the two-body problem.
2.9.
Use the Hamilton–Jacobi method to solve the initial value problems
∂φ
∂t + x∂φ
∂x = 0,
φ(0, x) = x,
where −∞< x < ∞
and
∂φ
∂t + x · ∇φ = 0,
φ(0, x) = g(x),
where x is in EN.
2.10.
Let U(x) = x4/4 −ax2/2 + bx + c.
a. Describe the solutions of the diﬀerential equation
d2x
dt2 + Ux(x) = 0
for all choices of a, b, and c, using the methods of Sections 2.3.2 and
2.4.3.
b. Compute and plot the solutions of van der Pol’s equation and the
lock-washer oscillators in Section 2.4.3 for ε = 0.1. Also, identify the
underlying cusp surface.
2.11.
Let f be a single-valued function mapping the set S = {1, . . . , N}
into itself.
a. Show that the iterates of f, say f j, deﬁne a semigroup using the
operation of function composition: That is, show that f if j = f i+j.
b. Show that the spectrum of the graph transition matrix for f consists
of zeros and roots of unity. Relate the corresponding eigenvectors to
the invariant sets of f.
c. Perform a Monte Carlo simulation of the matrix M associated with
the function
g(x) = 3.54x(1.0 −x)
as in Section 2.5.1.

88
2. Dynamical Systems
2.12. a. Show that the function φ deﬁned in Section 2.5.2 deﬁnes a circle
mapping. In particular, show that the solutions x(t) and ξ(t) of the
diﬀerential equation
dx
dt = f(t, x),
where f is doubly periodic and where the initial data satisfy
ξ(0) is arbitrary and x(0) = ξ(0) + 2π
satisfy
x(t) = ξ(t) + 2π
for all t.
b. Show that the residues of x(2πn) modulo 2π satisfy the iteration
yn+1 = φ(yn)
(mod 2π).
Also, show how to use the sequence yn to reconstruct the sequence
xn. (Hint: x0 −y0 = 2πM for some integer multiple M.)
c. Show that if α is rational, then all iterates deﬁned by
yn+1 = yn + 2πα
are periodic. Show that if α is irrational, then all iterates are dense
in the circle 0 ≤y < 2π.
d. Consider the mapping r exp(iθ) →2r exp(2iθ)/(1+r). Show that the
circle r = 1 is invariant for this mapping; in fact, show that all points
in the plane (except r = 0) approach this circle under iterations of
this mapping. Show that there are inﬁnitely many distinct periodic
solutions on the circle. [Hint: The mapping restricted to the circle
r = 1 deﬁnes the circle mapping θn+1 = 2θn (mod 2π).] The set
r = 1 is a strange attractor for this system.
2.13.
Reproduce Figure 2.27.
2.14. a. (Routh–Hurwitz Criterion for Stability.) Show that if all of the coef-
ﬁcients of a polynomial are positive, then all of its roots must have
negative real parts [10].
b∗. The diﬀerential–diﬀerence equation dx/dt = −ax(t−1) can be solved
using Laplace’s transform. Show that the characteristic equation in
this case is p = −ae−p. Consider the roots for p of the function
p + ae−p. Show that sin(πt/2) solves the problem when a = π/2.
Show that for a < π/2 all roots have negative real part. Describe how
the set of roots changes as a increases beyond π/2. (Hint: pep +a = 0.
Let p = σ + iτ, and derive equations relating a, σ, and τ.)
2.15. a. Describe all solutions of the Hamiltonian system
dz
dt
=
−F(y)
dy
dt
=
F(z),
where F(y) = y(1 −y)(y −a) and a is a ﬁxed number 0 < a <
1. (Hint: Show that G(z) + G(y) is constant along solutions, where
G′(z) = F(z).)

2.7. Exercises
89
b. Discretize this model using the semi-implicit method described in Sec-
tion 2.6.2. Show that the transformation T deﬁned by this iteration
satisﬁes det(T) = 1. Show that this implies that the transformation
is area preserving.

3
Stability Methods for Nonlinear
Systems
A mechanical or an electrical device can be fabricated to a level of accuracy
that is restricted by technical or economic constraints. What happens to the
output if the construction is a little oﬀspeciﬁcations? Does output remain
near design values? How sensitive is the design to variations in fabrication
parameters?
Stability theory gives some answers to these and similar questions. The
ultimate concept of stability developed here is stability under persistent
disturbances. Much of our later work in perturbation theory is based on
this idea. However, linear stability theory is the most convenient concept
to apply. It is based on a study of small deviations from a design state,
and so it reduces the problem to a linear problem for small deviations. The
methods of Chapter 1 can be used once this is done.
Sometimes the linear analysis carries little or no useful information. For
example, if large deviations must be considered, then the linear analysis
is unreliable, or the small deviations problem might have neutral stability
properties that do not carry over directly to the full model. In some cases,
the linear problem is unstable but nonlinearities capture growing modes
with the result being that the design output is still stable. In these cases,
other methods based on energy considerations are useful, and Liapunov’s
theory is the one developed and used here.

92
3. Stability Methods for Nonlinear Systems
3.1
Desirable Stability Properties of Nonlinear
Systems
Consider a system of diﬀerential equations of the form
dx
dt = f(t, x),
where x, f ∈EN, the components of f are smooth functions of their argu-
ments, and as before, t is a real variable. Assume throughout this section
that the components of f are at least continuous in t and twice continuously
diﬀerentiable with respect to the components of x.
Suppose that there is a solution of this equation, say x = φ(t), that exists
for all future times, say t0 ≤t < ∞. Deviations from φ are described by
the variable y = x −φ. With this the equation becomes
dy
dt = F(t, y),
where F(t, y) = f[t, y + φ(t)] −f[t, φ(t)]. This new equation has y = 0 as a
solution. In this way, the study of a solution x = φ(t) is reduced to the study
of the static state y = 0 of an associated problem. For the convenience of
notation, we return to the original notation and suppose that f(t, 0) = 0
for all t, t0 ≤t < ∞.
The question asked in this section is: How do solutions beginning near
x = 0 behave? We hope that they stay near x = 0 for all time, or even
approach it as t →∞, and the methods developed in this section provide
some useful ways to determine this.
We begin with a series of deﬁnitions. Let x(t, t0, x0) denote the solution
of the system
dx
dt = f(t, x)
that satisﬁes the initial conditions
x(t0, t0, x0) = x0.
Since f(t, 0) = 0, we see that x(t, t0, 0) ≡0.
1. The solution x ≡0 is said to be stable if given any tolerance ε > 0
and any initial time t0, there is a constraint δ(ε, t0) > 0 such that
|x0| < δ implies that x(t, t0, x0) exists for t0 ≤t < ∞and satisﬁes
|x(t, t0, x0)| < ε
for all t ≥t0. Thus, a solution will stay near x = 0 if it starts nearby.
2. The solution x ≡0 is said to be asymptotically stable if it is stable
and if there is a constraint δ1(ε, t0) > 0 such that |x0| < δ1 implies
that
|x(t, t0, x0)| →0

3.1. Desirable Stability Properties of Nonlinear Systems
93
as t →∞. Thus, x = 0 is stable, and solutions starting near it will
approach it.
3. The solution x ≡0 is said to be uniformly asymptotically stable (UAS)
if it is stable with its constraint δ being independent of t0 and if given
a tolerance ε > 0 there is a number T(ε) such that t −t0 > T(ε)
implies that
|x(t, t0, x0)| < ε.
Thus, x approaches zero as t −t0 →∞, uniformly in t0 and in x0.
4. The solution x ≡0 is said to be exponentially asymptotically stable
(EAS) if there are constants δ, K, and α, all positive, such that
|x0| < δ implies that
|x(t, t0, x0)| ≤Ke−α(t−t0)|x0|
for all t ≥t0.
5. The solution x ≡0 is said to be stable under persistent disturbances
(SPD) if given a tolerance ε there are constraints δ1 and δ2 such that
(a) for any initial state η satisfying |η| < δ1 and (b) for any admissible
perturbing function g(t, x), satisfying |g(t, x)| < δ2 for t0 ≤t < ∞
and for x near x = 0, the solution of the perturbed equation
dy
dt = f(t, y) + g(t, y)
that satisﬁes the initial condition
y(t0) = η
meets the tolerance
|y(t)| < ε
for t0 ≤t < ∞. A perturbation g(t, x) is admissible if it is continu-
ously diﬀerentiable with respect to the components of x and Lebesgue
integrable in t.
Stability under persistent disturbances, sometimes called total stability
[57], plays a central role in perturbation theory, as shown in later chapters.
It states that adding a small, but possibly very erratic, perturbation to the
original system might change the solutions, but it does not change them
much: They still remain near x = 0. The condition that g be measurable
in t is quite a mild one, but it can be relaxed still further [24].
The domain of attraction of an asymptotically stable state is the set of
all initial values x0 such that x(t, t0, x0) approaches the state as t →∞.
These deﬁnitions are used in many contexts. Stability and asymptotic
stability are not strong properties, in the sense that they are not preserved
under small changes in the system. However, EAS, UAS, and SPD are quite

94
3. Stability Methods for Nonlinear Systems
strong ideas and will be developed further in this chapter. Note, though,
that asymptotic stability in a system that is time-invariant or periodic in
t implies UAS. Of course, a solution that is EAS is also UAS [6]. First, we
study systems that are exponentially asymptotically stable.
3.2
Linear Stability Theorem
Taylor’s expansion of f(t, x) about x = 0 can be used to derive a linear
problem for small deviations from x = 0. Since f(t, 0) = 0, expanding f
about x = 0 gives the formula
f(t, x) = A(t)x + G(t, x),
where A is the Jacobian matrix having components
Ai,j(t) = ∂fi
∂xj
(t, 0)
for i, j = 1, . . . , N and G is the remainder in Taylor’s formula, so for each
t there is a constant K1 such that
|G(t, x)| ≤K1|x|2.
We denote this property by writing G(t, x) = O(|x|2) as x →0 for each
t; the notation O(|x|2) is explained fully in Chapter 5. Now, suppose that
this estimate holds uniformly for t0 ≤t < ∞(i.e., K1 does not depend on
t). Of course, if f is a linear function of x, then we have G = 0.
Solutions of the full system near x = 0 can be studied by deriving the
linear problem and ignoring G. We show here that this is valid when the
linear problem is EAS. Let Φ(t) be a fundamental solution of this system:
dΦ
dt = A(t)Φ,
Φ(t0) = identity.
The connection between the linear problem and the full nonlinear problem
can be established using the variation of constants formula and treating G
as though it were known. As in Section 1.6, the result is that the diﬀerential
equation
dx
dt = A(t)x + G(t, x)
is equivalent to the integral equation
x(t) = Φ(t)x(t0) +
 t
t0
Φ(t)Φ−1(s)G[s, x(s)]ds.
This is an important step in many studies of nonlinear problems. The
matrix Φ carries information about the behavior of solutions to the linear
part of the problem, and the function G carries information about the
problem’s nonlinearity.

3.2. Linear Stability Theorem
95
We show next that when the linear problem is exponentially asymptot-
ically stable, then so is the nonlinear problem. Let us suppose that the
linear part of the problem is EAS:
Hypothesis H. There are constants K and α, both positive, such that
|Φ(t)Φ−1(s)| ≤K exp[−α(t −s)]
for all t0 ≤s ≤t < ∞.
For example, this condition is satisﬁed if A is a constant matrix and all
its eigenvalues have negative real parts. There are other linear systems that
satisfy condition H as well (see Sections 1.4 and 3.3.4).
With this condition, we can state and prove the following useful theorem:
Linear Stability Theorem (See [24, 58, 27, 63]). Let condition H hold,
and suppose that G(t, x) = O(|x|2) as |x| →0, uniformly for t0 ≤t < ∞.
Then there is a number δ0 > 0 such that if |x(t0)| < δ0, then the solution
emerging from this initial state exists and is unique, and it approaches
x = 0 as t →∞. In fact, there is a positive constant α0 such that
|x(t)| ≤K|x(t0)| exp[−α0(t −t0)]
for all t ≥t0.
We conclude from this estimate that the solution x = 0 of the full non-
linear problem is exponentially asymptotically stable. The proof of this
theorem rests on Gronwall’s inequality, described below, which is closely
related to mathematical induction.
3.2.1
Gronwall’s Inequality
Let u(t), v(t), and w(t) be continuous (scalar) functions deﬁned for a ≤
t ≤b. Suppose that w(t) > 0 and that u(t) satisﬁes the inequality
u(t) ≤v(t) +
 t
a
w(s)u(s)ds
for all a ≤t ≤b. Then we can estimate u(t) in terms of v and w; namely,
u(t) ≤v(t) +
 t
a
w(s)v(s) exp
  t
s
w(s′)ds′

ds
for all a ≤t ≤b.
Proof. The proof of this result follows from setting
R(t) =
 t
a
w(s)u(s)ds.

96
3. Stability Methods for Nonlinear Systems
Then R′ = wu ≤wv + wR, or
d
dt

R(t) exp

−
 t
a
w(s)ds

≤exp

−
 t
a
w(s)ds

w(t)v(t).
Integrating this gives the result.
3.2.2
Proof of the Linear Stability Theorem
The integral equation
x(t) = Φ(t)Φ−1(t0)x(t0) +
 t
t0
Φ(t)Φ−1(s)G[s, x(s)]ds
has a unique solution on some interval, say t0 ≤t ≤t0 + δ∗, and it can be
continued as long as the solution remains bounded [24]. Taking norms of
both sides of this equation and using condition H gives
|x(t)| ≤K exp[−α(t −t0)]|x(t0)| +
 t
t0
K exp[−α(t −s)]|G[s, x(s)]|ds.
If |x| remains less than δ/K1 over an interval t0 ≤t ≤T and δ is suﬃciently
small, then we have |G(t, x)| ≤δ|x|. Setting u(t) = |x(t)|eαt, we have
u(t) ≤K exp(αt0)|x(t0)| + δK
 t
t0
u(s)ds
for t0 ≤t ≤T. Gronwall’s inequality with v = K exp(αt0)|x(t0)| and
w = δK shows that
u(t) ≤K exp(αt0)|x(t0)| exp[δK(t −t0)].
Therefore,
|x(t)| ≤K|x(t0)| exp[−(α −δK)(t −t0)].
If we choose δ so small that δ < α/K and restrict |x(t0)| so that K|x(t0)| <
δ/K1, then x remains so small on any interval [t0, T] that this estimate is
justiﬁed. We conclude that the theorem is valid for t0 ≤t < ∞with
α0 = α −δK.
This powerful result shows that if the small deviation problem is expo-
nentially asymptotically stable, then the nonlinear problem is also. Thus,
small deviations die out for the full model.
Example. The Linear Stability Theorem shows that the solution x = 0
of the scalar equation
dx
dt = ax −x3

3.2. Linear Stability Theorem
97
 x
 a
x =    a
              EAS
               EAS
x = -   a
x = 0
            unstable
           EAS
x = 0
x = 0
           UAS
Figure 3.1. Pitchfork bifurcation. The static state x = 0 is exponentially asymp-
totically stable for a < 0, uniformly asymptotically stable for a = 0, and unstable
for a > 0. As a increases through a = 0, two new static states bifurcate from
x = 0. Each is exponentially asymptotically stable.
is exponentially asymptotically stable if a < 0. Note that not all solutions
of this equation tend to zero. The static states and their stability are shown
in Figure 3.1.
3.2.3
Stable and Unstable Manifolds
Consider the time-invariant system
dx
dt = Ax + f(x),
where the constant matrix A has all eigenvalues lying oﬀthe imaginary axis.
The eigenvalues then are either stable ones (Re λ < 0) or unstable ones
(Re λ > 0). In this case, we say that A deﬁnes an exponential dichotomy
[109] on the space EN. This was discussed for linear problems in Chapter 1,
and we assume without loss of generality that A has a block diagonal form
A = diag(S, U),
where the matrix S has dimensions m × m and all of its eigenvalues are
stable, and the matrix U has dimensions n × n and all of its eigenvalues
are unstable. Since these account for all eigenvalues of A, m + n = N. We
break the vectors x and f into two vectors, say X and g, and Y and h,

98
3. Stability Methods for Nonlinear Systems
respectively, where X, g ∈Em and Y, h ∈En, and we rewrite the system
as two equations
dX
dt
=
SX + g(X, Y )
dY
dt
=
UY + h(X, Y ).
Perron rewrote this system [121] as a system of integral equations in a
special way using the variation of constants formula. Consider the integral
equation
X(t)
=
exp(St)ξ +
 t
0
exp[S(t −s)]g[X(s), Y (s)]ds
Y (t)
=
−
 ∞
t
exp[U(t −s)]h[X(s), Y (s)]ds.
If ξ is suﬃciently small, then this system of equations has a unique solution,
say X = X(t, ξ), Y = Y (t, ξ), which exists for 0 ≤t < ∞. The proof is
based on successive approximations, quite like those used in proving the
implicit function theorem in Section 4.1.2. The proof is presented in [24].
Gronwall’s inequality applies to this system, and it shows that
[X(t, ξ), Y (t, ξ)] →(0, 0)
as t →∞. Let us deﬁne a set S by
S = {[ξ, Y (0, ξ)] : ξ is small}.
This set deﬁnes an m-dimensional manifold for ξ near zero, and any solution
starting on it solves Perron’s integral equations. Therefore, it approaches
zero at an exponential rate, and S is referred to as being a stable manifold.
It can be shown that any solution starting away from S is repelled from
it at an exponential rate [24]. We summarize these results in the following
theorem:
Perron’s Theorem. Suppose that the eigenvalues of the matrix A sat-
isfy Re(λ) ̸= 0. In particular, suppose that there are m eigenvalues with
Re(λ) < 0 and n with Re(λ) > 0, where m + n = N. Finally, suppose that
f(x) is a smooth function for x near zero and f(0) = 0. Then there is an
m-dimensional stable manifold for the system
dx
dt = Ax + f(x).
Replacing t by −t in this system shows that there is an n-dimensional
stable manifold as t →−∞. We denote this by U, and it is referred to as
an unstable manifold for the full system.
This result shows that the stable and unstable manifolds derived for
linear problems in Chapter 1 can carry over to nonlinear systems. An inter-

3.3. Liapunov’s Stability Theory
99
esting geometrical approach to stable and unstable manifolds was proposed
by Hadamard as described in Section 2.5.4. These results can be extended
to cases where A and f depend explicitly on t, but that is not carried out
here. Finally, if some of the eigenvalues have Re(λ) = 0, then the nonlinear
system can have a manifold of oscillatory or static solutions that is called
a center manifold [68]. This is discussed in Section 1.2.2 and in Chapter 7.
3.3
Liapunov’s Stability Theory
Linear stability theory enables us to determine the stability of critical points
by linearizing the problem near them. However, linear theory is not useful
in many problems. For example, the equation described in Figure 3.1 is
dx
dt = ax −x3.
It has x = 0 as a critical point, and if a < 0, it is asymptotically stable.
However, this also happens when a = 0, that is, when the linear part of
this equation is not exponentially asymptotically stable. Liapunov’s theory
enables us to resolve such problems.
3.3.1
Liapunov’s Functions
Liapunov generalized the idea of a gradient system by observing certain
features that can be mimicked. He derived convenient functions without
reference to the physics of the problem. These are now called Liapunov’s
functions, although sometimes they are still referred to as energy functions
even when they are not related to a physical energy. These are used to
study stability properties of nonlinear systems of diﬀerential equations.
The following deﬁnitions are facilitated by using comparison functions that
are continuous (scalar) functions, say a(u), deﬁned for u ≥0, monotone
increasing, and satisfying a(0) = 0.
A Liapunov function for the static state x = 0 of the system
dx
dt = f(t, x),
f(t, 0) ≡0,
is any smooth scalar-valued function
V (t, x) : [0, ∞) × EN →E1
for which there are comparison functions a, b, and c such that
1. V (t, 0) = 0 for all t ≥0.
2. a(|x|) ≤V (t, x) ≤b(|x|) for t ≥0 and x near 0.
3. ∂V/∂t + ∇V · f(t, x) ≤−c(|x|).

100
3. Stability Methods for Nonlinear Systems
We deﬁne another comparison function d by the formula
d(u) = c[b−1(u)]
for later use.
The ﬁrst condition states that V vanishes at the system’s static state
x = 0. The second comparisons show that if V →0, then |x| →0, and
conversely. The third condition states that V is decreasing along solutions,
since the left-hand side of this inequality is simply the derivative of V along
solutions:
dV [t, x(t)]
dt
= ∂V
∂t + ∇V · f(t, x),
where x(t) is a solution of the system.
The deﬁnition of Liapunov’s function used here is more restrictive than
necessary for many results, but it is convenient for our limited goals. Further
details of these deﬁnitions and applications of them can be found in [57],
but the following examples illustrate the basic arguments of the theory.
3.3.2
UAS of Time-Invariant Systems
Consider the time-invariant system
dx
dt = f(x),
where f(0) = 0 and the components of f are smooth functions of the
components of x for x near zero. We have the following result.
Theorem. If there is a Liapunov function for this system, then the
solution x = 0 is uniformly asymptotically stable.
Proof. This result follows from two simple arguments. First, the
fundamental theorem of calculus states that
V [x(t)] −V [x(s)] =
 t
s
dV [x(t′)]
dt
dt′,
and so
V [x(t)] −V [x(s)] =
 t
s
∇V [x(t′)] · f[x(t′)]dt′ ≤−
 t
s
d(V )dt′ < 0
for 0 ≤s < t < ∞and for any solution with x(0) ̸= 0. Therefore,
a(|x(t)|) ≤V [x(t)] ≤V [x(0)] ≤b[|x(0)|],
and so the solution x = 0 is stable.
If x(t) starts near zero but does not approach zero as t →∞, then the
fact that
dV [x(t)]
dt
≤−d (V [x(t)])

3.3. Liapunov’s Stability Theory
101
leads to the estimate
 V [x(t0)]
V [x(t)]
dV
d(V ) ≥t −t0.
If x(t) does not approach zero, there is a number δ > 0 such that V [x(t)] ≥δ
for all large t. Therefore,
Constant ≥
 V [x(t0)]
V [x(t)]
dV
d(V ) ≥t −t0,
which eventually contradicts itself. This shows that x(t) →0, and it follows
that x = 0 is uniformly asymptotically stable.
Massera’s Theorem ( Section 3.4) shows that the converse of this theorem
is also valid. Because of this, the idea of uniform asymptotic stability is
quite natural for nonlinear systems. The remainder of this section presents
examples of Liapunov’s functions and some of their uses.
3.3.3
Gradient Systems
Gradient systems are important in many applications [124]. These are sys-
tems whose right-hand side is the gradient of a scalar function. For example,
consider the system
dx
dt = −∇F(x),
where x ∈EN and ∇F is the gradient of a smooth scalar valued function
F(x). This is concise notation for the system of equations
dxi
dt = −∂F
∂xi
(x)
for i = 1, . . . , N. One interesting thing about such systems is that an
isolated minimum of F corresponds to an asymptotically stable rest point
for this system. In fact, if x∗is an isolated minimum for F, then the function
V (x) = F(x) −F(x∗)
is a Liapunov function.
This observation is the basis of a numerical algorithm, called the gra-
dient method, used for ﬁnding extrema of functions of several variables.
Candidates for minima are among the values of x for which the gradient
of F is zero: ∇F(x) = 0. We have just seen that these values of x are
asymptotically stable equilibria for the dynamical system
dx
dt = −∇F(x).
Because of this, we can begin with an initial guess, say x0, then solve
this associated gradient system using a convenient computer package and

102
3. Stability Methods for Nonlinear Systems
trace the evolution of the solution. If the solution converges to a point, say
x∗, then we have located a candidate for a minimum of F. The computer
can also be used to test x∗for being a real minimum of F directly or
by calculating a Hessian matrix. Maxima of F are minima of −F, so the
resulting system can be solved for t →−∞to ﬁnd maxima.
Example. Let us consider the entropy function
F(x) = −
N

k=1
xk log xk
for vectors x in the probability simplex
Σp = {x such that x1 + · · · + xN = 1 and x1 > 0, . . . , xN > 0}.
Then the maxima of F can be found by solving the dynamical system
dxj
dt = −log xj −1.
If we use logarithms to base N, then 1 = log N, so this equation is
dxj
dt = −log Nxj.
It follows that Nxj →1 as t →∞, and so x(t) approaches a uniform
distribution, the one expected for maximum entropy.
The function F is called the entropy of the distribution x in Σp, and
this calculation shows that the gradient method moves the entropy toward
its maximum value, which occurs at the barycenter (all xj = 1/N) of the
simplex Σp.
3.3.4
Linear Time-Varying Systems
Liapunov functions can be useful in studying general linear systems. For
example, consider the linear system
dx
dt = A(t)x,
where A is a matrix of smooth and bounded functions. We ask, under what
conditions on A is the function
V (x) = |x|2
a Liapunov function for this system?
The comparison functions are a(u) = b(u) = u2, and it only remains
to evaluate the derivative of V along solutions: Since |x|2 = x⊤x, we have
that
d(x⊤x)
dt
= x⊤(A⊤+ A)x,

3.3. Liapunov’s Stability Theory
103
where A⊤denotes the transpose of A and x⊤denotes the transpose of the
column vector x (so it is a row vector). Since A⊤+A is a symmetric matrix,
it is diagonalizable [46]. Its spectral decomposition shows that if all of its
eigenvalues have negative real parts, then there is a positive number µ such
that
x⊤Ax = x⊤(A + A⊤)x/2 ≤−µx⊤x
for all vectors x. Thus, this function is negative deﬁnite if the eigenvalues
of the symmetric part of A have negative real parts. In this case we would
take c(u) = µu2. The following example illustrates this result.
Example. As in Section 1.4, let
U(t) =

cos ωt
−sin ωt
sin ωt
cos ωt

.
Note that U ⊤is the inverse of U, since U ⊤U = I. Consider the system of
equations
dx
dt = C(t)x,
where x ∈E2, C(t) = U ⊤(t)BU(t), and
B =

a
b
c
d

.
First, C(t) and B have the same eigenvalues. Therefore, the eigenvalues of
C(t) are constants even though C itself varies with t. Second, the derivative
of |x|2 along solutions of the system is
dx⊤x
dt
= (Ux)⊤(B⊤+ B)(Ux) ≤ρ|x|2,
where ρ is any real number that majorizes 2Re λ for all eigenvalues λ
of B⊤+ B. Therefore, if the eigenvalues of the symmetric part of B are
stable, then the solution x = 0 is exponentially asymptotically stable (see
Exercise 1.3).
This important example shows that stability of a linear system with peri-
odic coeﬃcients cannot be determined from the eigenvalues of its coeﬃcient
matrix alone. Chapter 7 shows that if ω is suﬃciently small and B is stable,
then the full system is stable.
3.3.5
Stable Invariant Sets
Liapunov’s functions can also describe the stability of invariant sets. We
say that a set S is invariant with respect to solutions of the system
dx
dt = f(x)

104
3. Stability Methods for Nonlinear Systems
if any solution x(t) of this system with y(t0) ∈S satisﬁes x(t) ∈S for all
t ≥t0.
For example, if x0 is a point for which the solution x = x(t, x0) that
satisﬁes the initial conditions x(0, x0) = x0 remains bounded for t ≥0,
then we deﬁne the ω-limit set of this solution to be the set
ω(x0)
=
{ξ in EN such that there is a sequence {tn}
with tn →∞and x(tn, x0) →ξ}.
Thus, the ω-limit set consists of all points that are approached by some
subsequence of values lying on the orbit starting at x = x0. It is known
that the ω-limit set of a solution is an invariant set; that is, if ξ ∈ω(x0),
then x(t, ξ) ∈ω(x0) for all t ≥0 [24].
Suppose that there is a smooth function V (x) : EN →E1 that has the
following properties:
1. V (x) ≥0.
2. ∇V (x) · f(x) ≤0.
Let S = {x ∈EN such that ∇V (x) · f(x) = 0}. With this notation we
have the following result for this system:
Theorem. If x0 is such that x(t, x0) remains bounded for t ≥0, then
ω(x0) ⊂S. Thus, x(t, x0) →S as t →∞.
Proof. First, since V is bounded below and since it is monotone and
nonincreasing along solutions (V ′ ≤0), limt→∞V [x(t, x0)] exists, say with
value c. Second, V (ξ) = c for all ξ ∈ω(x0). This follows from the fact that
for any such value ξ there is a sequence tn such that x(tn, x0) →ξ and
so V [x(tn, x0)] →V (ξ) = c, since V is a continuous function. Finally, for
ξ ∈ω(x0), the solution x(t, ξ) remains in ω(x0), and since V is constant on
this set, we have that
d
dtV [x(t, ξ)] = dc
dt = 0.
As a result, ∇V (ξ) · f(ξ) = 0. Thus, ξ ∈S. These calculations show that
ω(x0) ⊂S.
As a result of this theorem, we see that the set S is a global attractor
for all solutions.
Example. Lienard’s Equation. Lienard’s equation has the form
x′′ + f(x)x′ + h(x) = 0,
where f and h are smooth functions. We suppose, as in Section 2.1.3, that
h behaves like a restoring force,
xh(x) > 0
for
x ̸= 0,

3.3. Liapunov’s Stability Theory
105
and that
H(x) =
 x
0
h(s)ds
approaches ∞as x →∞. Here we suppose that f(x) > 0 for all values of
|x| ̸= 0.
Theorem. With these conditions on Lienard’s equation, the solution
x = 0 is globally asymptotically stable.
Proof. To prove this, we rewrite the equation as a ﬁrst-order system:
dx
dt
=
y
dy
dt
=
−h(x) −f(x)y,
and we deﬁne a function V by the formula
V (x, y) = y2
2 + H(x).
V has the following properties:
1. It is a smooth function of x and y.
2. V > 0 for (x, y) ̸= 0.
3. dV/dt = −f(x)y2, which is negative for y ̸= 0.
This is not a Liapunov function for Lienard’s equation, since the derivative
of V along solutions of Lienard’s system is not strictly negative (it vanishes
whenever y = 0 for any x.)
Lemma. Every solution of Lienard’s system is bounded and approaches
the largest invariant set M in S = {(x, y) : f(x)y2 = 0}.
Proof. Since V →∞as |x| →∞, observation 3 of the above theorem en-
sures that all solutions are bounded. Moreover, the previous theorem shows
that all solutions approach S. It follows that the solution must approach
the largest invariant set in S. This is because the ω-limit set of any orbit
is an invariant subset of S, and the largest invariant set is the union of all
of the ω-limit sets.
Proof of Theorem (continued). The only invariant set for Lienard’s equa-
tion in S is x = 0, y = 0. Therefore, it is globally asymptotically stable.
This completes the proof of the theorem.
Example. As a ﬁnal illustration of this result, we consider a slight
variant of van der Pol’s equation:
x′′ + x2x′ + x = 0.

106
3. Stability Methods for Nonlinear Systems
We have
dx
dt
=
y
dy
dt
=
−x −x2y,
and
V (x, y) = x2 + y2
2
.
The derivative of this function along solutions is
dV
dt = −x2y2.
The theorem applies to this equation where S is the union of the x- and
y- axes. The only invariant subset of S is (0, 0). Therefore, all solutions
approach x = 0, y = 0 as t →∞.
3.4
Stability Under Persistent Disturbances
Uniform asymptotic stability might seem to be a complicated idea, but the
next theorem shows that it ensures the existence of a Liapunov function.
Consider the system
dx
dt = f(t, x),
where x, f ∈EN, f is a diﬀerentiable function, and f(t, 0) = 0 for all t ≥t0.
Massera [108] proved the following result.
Massera’s Inverse Theorem. Suppose that x = 0 is a uniformly
asymptotically stable solution of this system and that f is a continu-
ously diﬀerentiable function of its arguments for x near x = 0 and for
t0 ≤t < ∞. Then there is a Liapunov function for this system having the
three properties listed in Section 3.3.1.
The proof of this theorem is not presented here. However, the construc-
tion of Liapunov’s function in Massera’s proof involves integration along
trajectories of the equation, and since these are not known, the proof gives
few useful hints about constructing a Liapunov function. This is one of the
major problems in the theory.
Still, this result plays an important role in stability theory: It is about
the only inverse theorem known, and it gives conditions under which we can
detect stability under persistent disturbances. This is a much overlooked,
but very important, result due to Malkin [106].

3.4. Stability Under Persistent Disturbances
107
Consider the system
dx
dt = f(t, x),
(3.1)
where f(t, 0) = 0 for all t and f is continuously diﬀerentiable in t and in the
components of x for x near 0. We refer to this as the unperturbed equation.
A Carath´eodory perturbation of this equation has the form
dy
dt = f(t, y) + g(t, y),
(3.2)
where g is bounded and Lebesgue measurable with respect to t and a con-
tinuously diﬀerentiable function with respect to the components of y. Such
functions g are referred to here as Carath´eodory functions. The general
question studied is: What stability conditions on System (3.1) ensure that
solutions of the perturbed Equation (3.2) lie near y = 0 for any function g
that is not too large?
There are many answers to this question, but Malkin found conditions
on Equation (3.1) that ensure that its static state x = 0 is stable under
persistent disturbances. Recall that the solution x = 0 of Equation (3.1)
is stable under persistent disturbances if given a tolerance ε > 0 there are
numbers δ1 and δ2 such that |g(t, y)| < δ2 for all t and y together with
|y(0)| < δ1 imply that |y(t)| < ε for all t, 0 ≤t < ∞, where x(t) solves
Equation (3.1) and y(t) solves Equation (3.2). Thus, if |g| is small and y
starts near x, then y remains close to x for all t. The following theorem
gives an answer to our question.
Malkin’s Theorem. Suppose that the solution x = 0 is a uniformly
asymptotically stable solution of Equation (3.1). Then it is stable under
persistent disturbances.
The proof of this result involves several steps that we do not present here
in detail. However, the following arguments present the essential ideas of
the proof.
Massera’s theorem shows that there is a Liapunov function for the sys-
tem (3.1), say V (t, x). Let us calculate its derivative along solutions of
Equation (3.2):
dV [t, y(t)]
dt
= ∂V
∂t + ∇V · f(t, y) + ∇V · g(t, y) ≤−c(|y|) + O(δ2).
This is strictly negative for y outside some neighborhood of y = 0. Hence,
by the arguments used in Section 3.3.2, we see that the solutions of Equa-
tion (3.2) approach some neighborhood of y = 0 as t →∞. Specifying the
radius of this neighborhood to be ε, we adjust δ1 and δ2 to make the stable
neighborhood suﬃciently small to meet the tolerance ε. This is shown in
Figure 3.2.
Note that this result does not ensure that Equation (3.2) has a uniformly
asymptotically stable solution, but only that its solutions starting near zero

108
3. Stability Methods for Nonlinear Systems
|x|
a(|x|)
- c(|x|)
(a)
|y|
a(|y|)
- c(|y|)+
(b)
  δ
Figure 3.2. (a) Shown here are lower bounds for V (above) and upper bounds for
dV/dt (below). The result is that when g = 0, x(t) →0 as t →∞. (b) Shown
here are lower bounds for V (above) and upper bounds for dV/dt (below) when
g ̸= 0. Bounds for the values of dV/dt near the origin are not known, but the
result is that y(t) approaches a neighborhood of 0 as t →∞.
stay near zero. We make use of this result in some surprising ways when we
study perturbation methods. Note that the conditions of the linear stability
theorem imply that the solution x = 0 in that case is stable under persistent
disturbances.
We see in Chapter 6 that this form of stability can carry us through
bifurcation points where systems are usually not structurally stable ([55],
p. 259). Bifurcation points are extremely important in applications, since
it is at these places that there is a qualitative change in solution behavior
that is often observable in experiments. Systems are not structurally stable
near bifurcation points.
3.5
Orbital Stability of Free Oscillations
We have studied periodic solutions of conservative systems and of Lienard’s
equation in Chapter 2. In what senses are these solutions stable?
A periodic solution of a time-invariant system cannot be asymptotically
stable. To see this, consider the system
dx
dt = f(x),
where x, f ∈EN, and suppose that it has a (nonconstant) periodic solution,
say x = p(t), having least period T > 0. For any number a, the function
p(t + a) is also a periodic solution of this system. Moreover, if a is small, it
starts very near p(t), but the diﬀerence
p(t) −p(t + a)

3.5. Orbital Stability of Free Oscillations
109
cannot approach zero as t →∞.
Because of this, a new kind of stability must be introduced, namely,
orbital stability. Although a periodic solution of a time-invariant system
cannot be asymptotically stable in the sense of Liapunov (it can be stable),
the orbit deﬁned by the periodic solution can be. In a sense, the periodic
solution can be asymptotically stable in amplitudes, and we can interpret
arc length along the orbit as being analogous to time in nonautonomous
systems.
3.5.1
Deﬁnitions of Orbital Stability
Let p(t) be a solution of least period T(> 0) of the system
dx
dt = f(x).
We deﬁne the orbit of p to be the set
Ω(p) = {x = p(t) : 0 ≤t ≤T}.
Recall that the distance between a point η and a set S is deﬁned to be
d(η, S) = inf{|η −z| : z ∈S}.
We say that p is orbitally stable if given a tolerance ε > 0 there is a
number δ > 0 such that d[x0, Ω(p)] < δ implies that
d[x(t, x0), Ω(p)] < ε
for all t ≥0. Also, p is orbitally asymptotically stable if it is orbitally stable
and solutions that start near the orbit approach it as t →∞. Finally, p
is orbitally stable under persistent disturbances if given a tolerance ε > 0,
there are numbers δ1 and δ2 such that for any Carath´eodory function g(t, y)
with |g(t, y)| < δ2 and any initial point y0 that is near the orbit, say
d[y0, Ω(p)] < δ1, the solution y(t, y0) of
dy
dt = f(y) + g(t, y),
y(0) = y0
satisﬁes
d[y(t), Ω(p)] < ε
for all t ≥0.

110
3. Stability Methods for Nonlinear Systems
3.5.2
Examples of Orbital Stability
A collection of excellent practice problems for studying orbital stability is
presented by λω-systems. Consider the system
dx
dt
=
λ(x, y)x −ω(x, y)y
dy
dt
=
ω(x, y)x + λ(x, y)y,
where λ and ω are arbitrary functions of x and y. Polar coordinates are
introduced by setting r2 = x2 + y2 and θ = tan−1(y/x). The result is that
rr′ = xx′ + yy′ = λ(x, y)r2
and
r2θ′ = xy′ −yx′ = ω(x, y)r2.
Thus, the system becomes
dr
dt
=
λ(r cos θ, r sin θ)r
dθ
dt
=
ω(r cos θ, r sin θ).
For example, if ω = constant and λ = (1−r), then this system has a unique
periodic orbit (r = 1), and it is orbitally asymptotically stable.
Recall the conservation equation
x′′ + Ux(x) = 0,
where the potential function U is a quartic, as shown in Section 2.3.2.
There are many periodic orbits deﬁned by this equation, and all of them
are orbitally stable. However, the separatrices that begin and end at the
saddle point x∗are not. These observations can be proved using the total
energy
x′2
2 + U(x)
as a measure of deviation.
Finally, recall that van der Pol’s equation
x′′ + (x2 −1)x′ + x = 0
satisﬁes the conditions of Section 2.1.3 for Lienard’s equation, so it has
a unique periodic solution (other than x = 0). It follows from the
Poincar´e–Bendixson Theorem [24] that this periodic solution is orbitally
asymptotically stable.

3.5. Orbital Stability of Free Oscillations
111
3.5.3
Orbital Stability Under Persistent Disturbances
The next theorem shows how stability under persistent disturbances can
result for orbits.
Theorem. Let p(t) be an orbitally asymptotically stable solution of the
time-invariant system
dx
dt = f(x),
where f is a smooth function. Then p(t) is orbitally stable under persistent
disturbances.
The proof is not presented here [143]. However, the conditions of the
theorem ensure that the orbit Ω(p) has a Liapunov function. In fact, there
is a function V (t, x) that is periodic in t, V (t, x) > 0, and dV/dt < 0 for x
not in Ω(p). Thus, Ω(p) plays the role of S in the lemma in Section 3.3.5.
The result follows from a straightforward extension of Malkin’s theorem
presented in the last section.
This theorem shows that the stable oscillation of Lienard’s equation in
Section 3.3.5 is orbitally stable under persistent disturbances.
3.5.4
Poincar´e’s Return Mapping
Let x = p(t) ∈EN be a periodic solution having least period T > 0 of
dx
dt = f(x),
where f is a smooth function of the components of the vector x ∈EN. We
study the deviation of solutions from p by setting u = x −p(t). Then u
satisﬁes the equation
du/dt = A(t)u + g[p(t), u],
where A is the Jacobian matrix A(t) = fx[p(t)] and g[p(t), u] = O(|u|2) as
|u| →0 uniformly for 0 ≤t ≤T.
Let vectors q2, . . . , qN be pairwise orthogonal and orthogonal to p′(0).
Thus, the column vectors
p′(0), q2, . . . , qN
span EN. Let Y (t) be the fundamental solution of the linear equation
du
dt = A(t)u
that satisﬁes the initial conditions
Y (0) = [p′(0) q2 · · · qN]

112
3. Stability Methods for Nonlinear Systems
given here in terms of its columns. This equation has a periodic solution,
namely, u = p′(t), and our choice of initial conditions ensures that p′(t) is
the ﬁrst column of Y (t).
Floquet’s Theorem shows that
Y (t) = P(t) exp(Lt),
where P(t) has period T, P(0) = Y (0), and
L = diag(0, Λ),
where Λ is an (N −1) × (N −1) matrix. The eigenvalues of L are called
the characteristic exponents of the system, and the eigenvalues of exp(LT)
are called the characteristic multipliers. Note that at least one of the char-
acteristic multipliers must have a modulus equal to 1, since the function
u = p′(t) is a periodic solution of the linear system. By our choice of initial
conditions for Y , we see that p′(t) is the ﬁrst column of P(t) and L has the
form shown.
The variation of constants formula shows that u satisﬁes the integral
equation
u(t) = Y (t)u(0) +
 t
0
Y (t)Y −1(s)g[p(s), u(s)]ds.
We introduce one more change of variables: Let
w = P −1(0)u.
It follows that w satisﬁes the integral equation
w(t) = P −1(0)Y (t)P(0)w(0) +
 t
0
P −1(0)Y (t)Y −1(s)g[p(s), P(0)w(s)]ds.
We consider solutions of this equation that satisfy initial conditions of the
form
w(0) = col(0, b2, . . . , bN),
and let b be the vector (b ∈EN−1) given by the last N −1 components
of w(0). The notation “col” indicates that w(0) is a column vector having
the given components.
With this, we have from [24] the following lemma.
Lemma. [24] With the above notation and assumptions, for every vector
b near zero there is a unique number T(b) such that the ﬁrst component
of w, say w1(t), satisﬁes
w1[T(b)] = 0
and T(b) is a continuous function of b for b near zero with T(0) = T,
where T is the period of p(t).

3.5. Orbital Stability of Free Oscillations
113
 B k
 x = x(t)
 w  = 0
 B k+1
1
Figure 3.3. The return mapping: w1 = 0 deﬁnes a plane that is transverse to
solutions.
Proof. The solutions of the system near p(t) are depicted in Figure 3.3:
The solutions beginning with w1(0) = 0 lie on a plane that is orthogonal to
p(t) at the point p(0). The fact that solutions depend continuously on initial
data ensures that solutions starting with b near zero (i.e., starting near the
orbit of p) remain near the orbit for 0 ≤t ≤2T. In particular, there are
values of t near T, say t1 and t2 for which w1(t1) < 0 and w1(t2) > 0.
The intermediate value theorem shows that there is a ﬁrst value t, say
t∗, such that t∗is near T and w1(t∗) = 0. We deﬁne T(b) = t∗. The
continuity of T(b) follows from the fact that the solutions of the system
depend continuously on b.
The Return Mapping. T(b) is called the return time to the transversal
plane deﬁned by w1 = 0. Let col(0, Bk) denote a point on this plane. Then
w[T(Bk)] deﬁnes a new point on the plane, say col[0, Bk+1]. The mapping
Bk →Bk+1
is called the return mapping. The fact that the return mapping is well-
deﬁned relies on the plane section being transversal to the ﬂow deﬁned by
the solutions.
If the eigenvalues of the matrix Λ have negative real parts, then it follows
that Bk →0 as k →∞. We summarize these results in the following
theorem:
Theorem. Let p(t) be a periodic solution of the equation
dx
dt = f(x)
having least period T > 0 (in particular, p is not a rest point for the system).
Suppose that f is a smooth function of the components of x. Moreover,

114
3. Stability Methods for Nonlinear Systems
suppose that N −1 characteristic multipliers of the linear system
dx
dt = fx[p(t)]x
have a modulus less than 1. Then p(t) is orbitally asymptotically stable.
The proof of this result follows from the calculations presented above
and the fact that if the vectors Bj approach zero, then the corresponding
solutions of the system, x(t, Bj), approach p(t) uniformly on the interval
0 ≤t ≤T. Important examples of how this result can be used are described
later when we discuss the bifurcation of periodic solutions in Chapter 6.
Unfortunately, this result does not apply in some important cases. For
example, consider the oscillator
x′′ + f(x) = 0,
where x is a scale and f is a smooth function. Suppose that there is a 2π-
periodic solution to this equation, say x = p(t). Linearizing the equation
about this oscillation leads to the equation
u′′ + f ′[p(t)]u = 0,
which is a form of Hill’s equation. In this case, we know that one solution
of this equation is u = p′(t), and by shifting the time variable we can
take p′(2π) = 1. It follows that one of the characteristic multipliers of this
equation has modulus 1, so the other one must also have modulus 1 (see
Section 1.4.1). Thus, the conditions of the theorem are not satisﬁed.
3.6
Angular Phase Stability
The preceding discussion of amplitude stability should not hide the fact
that phase stability is very important, too. In fact, it is surprising that
asymptotic stability of phases can occur in systems in which energy is
conserved. This result is perhaps against intuition, but we illustrate it here
by studying the clock problem formulated by Huygens in the 1600s. But
we ﬁrst describe a useful method for analyzing phase equations.
3.6.1
Rotation Vector Method
Consider a system of diﬀerential equations on an N-dimensional torus,
dx
dt = ω + f(x),
where f is a continuously diﬀerentiable function that is periodic in each
component of x, say with period 2π. Let ω be nearly proportional to a
vector of integers, say
ω = αn + ˜Ω,

3.6. Angular Phase Stability
115
where α is a constant of proportionality, all the components of n are positive
integers (n1, . . . , nN), and ˜Ωis some ﬁxed vector in EN.
We deﬁne new variables
yj
=
xj
αnj
εgj(y)
=
1
αnj
(fj(αn1y1, . . . , αnNyN) + ˜Ωj).
Then
dy/dt = 1 + εg(y),
where 1 is the N-vector of all ones and ε = maxj{1/(αnj)} ≪1.
We are interested in determining conditions that will ensure that
lim
t→∞y1(t) : · · · : yN(t) = 1 : · · · : 1
To do this, we consider the problem in the probability simplex Σp. We
deﬁne the components of the phase distribution vector to be
pj(t) =
xj(t)/nj
N
k=1 xk(t)/nk
.
These ratios all approach 1/N as t →∞if and only if the entropy function
H(p) = −
1
log N
N

j=1
pj log pj
approaches a maximum value (H = 1.0). Equivalently,
x1 : x2 : · · · : xN →n1 : n2 : · · · : nN
as t →∞. Thus, H, which is the entropy of the distribution p, provides a
useful measure of synchronization of the oscillators.
Let v = N
k=1 yk. Then pj = yj/v, and
dv
dt = N(1 + ε¯g(vp)),
where ¯g(y) = (1/N) N
k=1 gk(y). Moreover,
v dpj
dt = 1 −pjN + ε(gj −Npj¯g(vy)).
Next, we set
q = v(Np −1).
With this,
dqj
dt = ˙v(Np −1) + vn ˙p = εN(gj −¯g).

116
3. Stability Methods for Nonlinear Systems
Therefore,
dqj
dv = ε(gj −¯g)
1 + ε¯g
= ε

gj −1
N
N

k=1
gk
  1
N + q
N

+ O(ε2).
We return to this calculation in Chapter 7, where the method of averaging
will be used to ﬁnish the calculation.
The rotation vector method [75] comprises a collection of stability results
about this system. The central idea is that if the functions qj deﬁned by
these equations remain bounded as v →∞and if v →∞as t →∞, then
the formula
qj(t) = v(Npj(t) −1),
in the limit t = ∞, yields that the relative ratios of the components of x
approach those of ω:
x1 : · · · : xN →n1 : · · · : nN
as t →∞. The right-hand side of this limit is referred to as a rotation
vector, in analogy with the rotation number of Denjoy [75, 30].
In later chapters we derive useful conditions under which the system for
q is stable under persistent disturbances. The result that
x1 : · · · : xN →ω1 : · · · : ωN
as t →∞implies that the system is synchronized.
If the system for q is stable under persistent disturbances, then the same
result holds for all nearby systems. This is the phenomenon of phase-locking;
namely, the phases synchronize at the same relative frequencies even though
the system is slightly changed. This is described in speciﬁc examples after
we have discussed the method of averaging in Chapter 7.
3.6.2
Huygen’s Problem
Let us consider a system of N pendulums, where the angular deviation
from rest of the jth pendulum is θj, which we suppose is not large. Then
the system is described by the equations
¨θj + ω2
j sin θj = −εFj(θ, ˙θ),
where Fj describes the force exerted on the jth pendulum by the system
when it is in state θ, ˙θ. This problem has been studied in detail by Korteweg
[142], and we consider here only an illustrative example. When ε = 0, there
is no coupling, and the jth pendulum oscillates with frequency ωj. This
corresponds to each pendulum swinging in isolation from the others. When
the pendulums are coupled, they tend to synchronize. As an example, let
us consider a lattice of oscillators having nearest neighbor interactions. To

3.6. Angular Phase Stability
117
−1
−0.5
0
0.5
1
1.5
2
0
0.5
1
1.5
2
2.5
ω1
ω2
ω3
p1
p2
p3
Figure 3.4. Synchronization for Huygens problem. For each of 25 choices for
(ω1, ω2, ω3) shown on the parabola in the top ﬁgure, the problem for (θ1, θ2, θ3)
was solved using ε
=
0.5 and Ij
=
0.1 up to t
=
100π. The ratios
pj = θj/(θ1 + θ2 + θ3) for j = 1, 2, 3, are plotted in a probability simplex in
the lower ﬁgure. Most of the values are near where p1(t) : p2(t) : p3(t) ≈1 : 1 : 1,
which shows that the oscillators are near synchrony.
ﬁx ideas, we take
Fj(θ, ˙θ) =
∂
∂θj
N

k=1
cos(θk −θk+1) + Ij,
where Ij is the torque applied to the support point, and we take θN+1 = θ1.
In the case of N = 3, we have
¨θ1 + ω2
1 sin θ1
=
εI1 + ε[sin(θ1 −θ2) + sin(θ1 −θ3)]
¨θ2 + ω2
2 sin θ2
=
εI2 + ε[sin(θ2 −θ3) + sin(θ2 −θ1)]
¨θ3 + ω2
3 sin θ3
=
εI3 + ε[sin(θ3 −θ1) + sin(θ3 −θ2)].
We simulate this system using an interesting form of output: Select from
a uniform distribution of values of the vector ω = (ω1, ω2, ω3) in the prob-
ability simplex, and for each calculate the corresponding solution. Then,
normalize these values by setting pj = θj/(θ1 +θ2 +θ3) and plot the results
using a real coordinates.

118
3. Stability Methods for Nonlinear Systems
Figure 3.4 shows the results of simulations of this system. In this case,
we wish to consider the ratio θ1 : θ2 : θ3 as t →∞. These can be plotted
simultaneously using triangular coordinates.
3.7
Exercises
3.1. a. Gronwall’s inequality shows that if u, w, and v are continuous
functions that are nonnegative and if
u(t) ≤v(t) +
 t
0
w(s)u(s)ds,
then
u(t) ≤v(t) +
 t
0
w(s)v(s) exp
  t
s
w(s′)ds′

ds.
Prove this by deﬁning z(t) =
 t
0 w(s)u(s)ds, showing that
dz/dt ≤wv + wz
and integrating this inequality. Simplify the result in the case where
v = constant.
b. The following comparison theorem is quite useful: Let x(t) solve the
integral equation
x(t) = f(t) +
 t
0
k(t −s)x(s)ds,
where f and k are smooth functions, and suppose that z(t) satisﬁes
the inequality
z(t) ≤|f(t)| +
 t
0
|k(t −s)|z(s)ds
and z(0) = |x(0)|. Show that z(t) ≥|x(t)| for all t.
3.2. a. Show that a solution of Perron’s integral equations in Section 3.2.3
deﬁnes a solution of diﬀerential equations in that section.
b∗. Show that Perron’s integral equations have a unique solution, and
that it exists for all 0 ≤t < ∞. Show that the solution of this system
approaches zero as t →∞. (Hint: Use successive approximations and
Gronwall’s inequality.)
3.3.
Suppose that f(t, x) is a vector of N functions having period T in t
and being continuously diﬀerentiable. Suppose that x = 0 is a solution
of the diﬀerential equation
dx
dt = f(t, x).
That is, f(t, 0) = 0 for all t.
Show that if x = 0 is asymptotically stable, then it is uniformly
asymptotically stable.

3.7. Exercises
119
3.4.
Consider the gradient system
dx
dt = −∇F(x).
Suppose that x∗is a local minimum for F. Show that V (x) =
F(x)−F(x∗) deﬁnes a Liapunov function for this system near x = x∗.
Show that this gradient system cannot have a periodic solution. [Hint:
Integrate (dx/dt, dx/dt)(t) around an orbit.]
b. Apply the gradient method to ﬁnd the extrema of the function
F(x, y) = ax2 + bxy + cy2
in each of the three cases
i.
b = 0
ac > 0,
a > 0.
ii.
a = c = 0
b > 0.
iii.
b = 0
ac < 0.
Discuss the general case.
c. Show that the gradient system with potential function
F(x) = −
N

k=1
xk log xk
can be solved using the exponential integral function [1]
Ei(u) =
 u
−∞
ev
v dv.
Show that xj = (1/N) exp[Ei−1(t)], and so show that xj(t) →1/N
as t →∞for each j = 1, . . . , N.
3.5.
Find a matrix A having a positive eigenvalue while the eigenvalues of
the symmetric part of A are negative. Use this example to show that
x⊤x might not deﬁne a Liapunov function for the system dx/dt = Ax.
3.6.
Show that the return mapping in Section 3.5.4 has the form
Bk+1 = exp(ΛT)Bk + o(|Bk|).
Show that if all of the eigenvalues of Λ have negative real parts, then
|Bk| →0 as k →∞. Show how the eigenvalues of Λ are related to
the original system in Section 3.5.4.
3.7.
Show that if p(t) is a periodic solution of the system
dx
dt = f(x),
then the function u =
dp
dt deﬁnes a periodic solution of the linear
problem
du
dt = ∂f
∂x[p(t)]u.
Conclude that at least one characteristic exponent of this system
has real part zero, and so at least one characteristic multiplier has
modulus equal to one.

120
3. Stability Methods for Nonlinear Systems
3.8.
Determine the (angular) phase stability of the system
dx
dt
=
ω + sin(x −y)
dy
dt
=
µ + sin(y −x).
In particular, determine the values of ω and µ for which x/y →1.
3.9.
Consider the linear problem
˙x = Ax,
where A is a stable matrix of constants. Show that
V (x) =
 ∞
0
|eAtx|2dt
deﬁnes a Liapunov function for this system. (This is the essential
argument in proving Massera’s Theorem.)

4
Bifurcation and Topological Methods
It is often possible to reduce stability and oscillation problems for dif-
ferential equations to problems for systems of algebraic or operator
equations, which can be studied using implicit function theorems and ﬁxed
point-methods.
Consider a system of (algebraic) equations
F(u, λ) = 0,
where u ∈EN is a vector of unknowns, λ ∈EK is a vector of parameters,
and F is a vector of smooth functions, taking its values in EN. Suppose
that F has at least M + 1 continuous derivatives with respect to each of
its arguments.
The problem studied in this chapter is to solve this system for u in terms
of the parameters in λ. We ﬁrst derive some implicit function theorems, and
we then describe techniques for solving (nonlinear) bifurcation equations.
These results are illustrated with examples of bifurcations of static and
periodic solutions in systems of diﬀerential equations.
Finally, we consider some geometric methods that are useful for ﬁnding
solutions. Among these are ﬁxed-point theorems from topology.
4.1
Implicit Function Theorems
Linear systems of equations are the easiest to solve, but even they are
usually complicated. Solutions of them are described ﬁrst, followed by non-

122
4. Bifurcation and Topological Methods
linear problems using implicit function methods that are based on solving
linear problems.
4.1.1
Fredholm’s Alternative for Linear Problems
Consider the equation for x ∈EN
Ax = f,
where A ∈EN×N and f ∈EN. The matrix A and the vector f are given,
and we are to determine a vector x that solves this equation.
If the matrix A is invertible, then the solution is given by the formula
x = A−1f.
This formula can be evaluated using the spectral decomposition of A or by
direct numerical evaluation, which may or may not be diﬃcult. However,
if the matrix A is not invertible, then other problems arise. For example,
there may not be a solution.
Suppose for the remainder of this section that A has rank N −q and
that there are q linearly independent vectors, say φ1, . . . , φq, that span the
null space, or the kernel of A, which we denote by ker(A); that is, if v is
a vector for which Av = 0, then there are unique constants b1, . . . , bq such
that
v = b1φ1 + · · · + bqφq.
We denote by ker(A)⊥the collection of all vectors that are orthogonal to
ker(A); that is,
ker(A)⊥= {v ∈EN : v · φj = 0 for j = 1, . . . , q}.
The set ker(A)⊥is called the orthogonal complement of ker(A), or the
cokernel of A. From these deﬁnitions we have that
EN = ker(A) ⊕ker(A)⊥.
This means that any vector v in EN can be written in a unique way as
v = c1φ1 + · · · + cqφq + w,
where w ∈ker(A)⊥and c1, . . . , cq are uniquely deﬁned constants.
We denote by A⊤the transpose of A, and by ker(A⊤) and ker(A⊤)⊥the
kernel of A⊤and its orthogonal complement, respectively.
Fredholm’s Alternative is usually stated in the following way [28].
Fredholm’s Alternative. Either the equation
Ax = f

4.1. Implicit Function Theorems
123
has a unique solution for any choice of the forcing vector f, or the
homogeneous equation
Ax = 0
has a nonzero solution.
However, the alternative has come to mean more in the current literature.
Figure 4.1 describes decompositions of EN that A and A⊤deﬁne, and so
it tells a great deal about solving for x.
Fredholm’s Alternative comprises the following results, summarized in
Figure 4.1.
1. The matrix A maps the set ker(A) into 0, since all of the vectors in
ker(A) are null vectors.
2. A maps the set S = ker(A)⊥one-to-one onto the set T = ker(A⊤)⊥.
That is, if f ⊥ker(A⊤), then there is a unique vector in ker(A)⊥, say
w∗, such that Aw∗= f.
3. In order for there to be a solution to the equation Ax = f, f must
lie in ker(A⊤)⊥. In that case, the general solution has the form
x = c1φ1 + · · · + cqφq + w∗,
where c1, . . . , cq are arbitrary constants, but w∗is uniquely deter-
mined by f.
Therefore, Fredholm’s Alternative establishes a useful decomposition of
EN into the null space of A⊤and its complement. Since A does not map
into any part of ker(A⊤), the equation cannot be solved if part of f lies in
this set. This can be seen simply by ﬁnding vectors ψ1, . . . , ψq that span
ker(A⊤) and observing that if there is a solution (say, Ax = f), then
ψj · f = ψj · Ax = A⊤ψj · x = 0
for j = 1, . . . , q. The equations
ψj · f = 0
for j = 1, . . . , q are called the solvability conditions for this equation. It
is necessary that f satisfy these conditions if there is to be a solution. In
other words, they ensure that f is in ker(A⊤)⊥.
Proof of Fredholms Alternative. Result 1 is obvious, and the ﬁrst part of
result 3 was just proved. It remains to show that A deﬁnes a one-to-one
mapping of S = ker(A)⊥onto T = ker(A⊤)⊥. First, if w and w1 are in S
and if Aw = Aw1, then A(w −w1) = 0, so w −w1 ∈ker(A). Since S is
a linear subspace of EN and since 0 is the only element common to both
ker(A) and S, it must be that w−w1 = 0. Therefore, A deﬁnes a one-to-one
mapping of S into T.

124
4. Bifurcation and Topological Methods
Now suppose that f ∈ker(A⊤)⊥. We must show that there is a vector
w∗∈S such that Aw∗= f. This can be done by actually constructing an
approximate solution for general f.
Least Squares Solution of Ax = f.
We ﬁrst ask for a vector x that minimizes the norm of Ax −f:
η = (Ax −f) · (Ax −f) = |Ax −f|2 = min .
If there is one, it is called the least-squares solution, and we denote it by
xLSQ. The value for xLSQ is to be found among the values for which the
gradient of this norm vanishes. Since η = (A⊤Ax −2A⊤f) · x + f · f, we
see that ∂η/∂xj = 0 for j = 1, . . . , N when
A⊤Ax = A⊤f.
This system has certain advantages over the original one: The matrix on
the left-hand side is now symmetric, so a spectral decomposition of A⊤A
is available and it is useful. Also, the forcing vector A⊤f satisﬁes the
solvability conditions.
The matrix A⊤A is a symmetric matrix of rank N −q and nullity q.
Therefore, there is an orthogonal matrix P(P ⊤P = PP ⊤= I) having the
form
P = (φ1, . . . , φq, ξq+1, . . . , ξN),
where the column vectors φ1, . . . , φq span ker(A) such that P diagonalizes
A⊤A; that is,
P ⊤A⊤AP =
 0
0
0
D

,
(4.1)
where D is a diagonal matrix, say D = diag(dq+1, . . . , dn) [46]. We have
det D ̸= 0, since the rank of D is N −q. Note that the columns of AP are
(0, . . . , 0, Aξq+1, . . . , AξN).
In fact, if we denote the ith column of the matrix AP by (AP)i, then
(AP)i = 0 if i = 1, . . . , q, but (AP)i = Aξi for i = q + 1, . . . , N. Moreover,
from Equation (4.1) we see that
(AP)i · (AP)j = (AP)⊤
i (AP)j = 0
if i ̸= j or if i = j ≤q
and
(AP)j · (AP)j = dj
if j > q.
The vectors (AP)q+1, . . . , (AP)N span ker(A⊤)⊥, since they are N −q
linearly independent elements of that subspace. Note that (ξq+1, . . . , ξN)
are eigenvectors of A corresponding to nonzero eigenvalues.
Next, we deﬁne z = P ⊤x. With this, the equation becomes
P ⊤A⊤APz = P ⊤A⊤f.

4.1. Implicit Function Theorems
125
Hence,
 0
0
0
D

z = (AP)⊤f = (0, . . . , 0, Aξq+1, . . . , AξN)⊤f.
Thus, the ﬁrst q components of the right-hand side are zero, and the last
are given by (Aξj)⊤f for j = q + 1, . . . , N.
The ﬁrst q equations show that z1, . . . , zq are free. The last N −q
equations show that zj = (Aξj) · f/dj. Therefore,
xLSQ =
q

i=1
ziφi +
N

i=q+1
(f · Aξi) ξi
di
.
This vector solves the equation
A⊤AxLSQ = A⊤f.
Next, let
fR = f −
q

j=1
Cjψj,
where Cj = f · ψj. The vector fR is the part of f that lies in ker(A⊤)⊥.
We have the following lemma.
Lemma. AxLSQ = fR.
Proof. The vectors Aξq+1, . . . , AξN, are orthogonal, and they span
ker(A⊤)⊥. Therefore, fR can be expanded in terms of them:
fR =
N

i=q+1
fiAξi,
where fj = fR · Aξj/dj. Since
xLSQ =
q

i=q
ziφi +
N

i=q+1
(f · Aξi) ξi
di
,
we have that
AxLSQ = A
N

i=q+1
(f · Aξi) ξi
di
=
N

i=q+1
(f · Aξi)Aξi
di
= fR.
In summary, we see that the equation
Ax = f

126
4. Bifurcation and Topological Methods
has a solution if and only if f ∈ker(A⊤)⊥. In that case, the solution is
given by the formula
xLSQ =
q

i=1
ziφi +
N

i=q+1
(f · Aξi) ξi
di
,
where z1, . . . , zq are free constants. In particular, if f = fR, then there is
a unique w∗in ker(A)⊥such that Aw∗= f. This completes the proof of
result 2 of Fredholm’s Alternative, and the second part of 3.
It is tempting to use the least-squares method as the basis for a nu-
merical scheme for ﬁnding xLSQ. However, there are signiﬁcant accuracy
problems in this approach, and more sophisticated decomposition methods
are usually used [21].
4.1.2
Nonlinear Problems: The Invertible Case
Suppose that u = u0 (in EN) solves the equation
F(u0, λ0) = 0
for some choice of the parameters λ0 in EK. Without loss of generality, we
can assume that u0 = 0 and λ0 = 0, since a simple translation of variables
(u →u −u0, λ →λ −λ0) gives a new system for which this is true. Thus,
we suppose that
F(0, 0) = 0.
Recall that the components of F are assumed to be at least M + 1 times
continuously diﬀerentiable with respect to the components of u and of λ.
We look only for small solutions of this system for small values of λ; that
is, we seek solutions that are near u = 0 for parameters near λ = 0. We
begin by expanding the equation about this known solution:
F(u, λ) = C(λ) + A(λ)u + G(u, λ),
where C(λ) = F(0, λ), A(λ) = Fu(0, λ) is the Jacobian matrix, and G(u, λ)
is the remainder. There is a constant K such that
|G(u, λ)| ≤K|u|2
for all small values of |u| and |λ|. We consider here the case where A(λ) is
invertible, and, in the next section, the case where it is not.
Hypothesis HI. A(0) is an invertible matrix.
With this we have the following result.
Implicit Function Theorem. Suppose that condition HI and the above
conditions are satisﬁed. Then there is a unique small solution, say u = u(λ),

4.1. Implicit Function Theorems
127
of the equation
F(u, λ) = 0
for λ near zero. In fact, there are functions Uj(λ), homogeneous poly-
nomials in the components of λ of degree j, for j = 1, . . . , M, such
that
u(λ) =
M

i=0
Ui(λ) + O(|λ|M+1).
The functions Uj have the form
Uj(λ) =

k1+···+kK=j
U(j, k1, . . . , kK)λk1
1 · · · λkK
K ,
where the sum is taken over nonnegative indices k1, . . . , kK that satisfy the
constraint.
Proof of the Implicit Function Theorem. The proof is accomplished in
three steps.
Step 1: Determine the functions Uj recursively from the equation. Ob-
viously, U0 = 0, since we are looking for small solutions. Next, U1(λ) =
−A−1Gλ(0, 0)λ, etc. These coeﬃcients give Taylor’s expansion of the
expected solution.
Step 2: Let v = u−M
j=0 Uj(λ), and derive an equation for the remainder
v. The result has the form
v = u −
M

i=0
Ui(λ) =
−
A−1

G

v +
M

i=0
Ui(λ), λ

−G
 M

i=0
Ui(λ), λ

+
O(|λ|M+1).
Thus, the remainder v solves the equation
v = H(v, λ),
where H is a smooth function with
H = O(|v|2) + O

|λ||v|) + O(|λ|M+1
as |v| →0 and |λ| →0.
Step 3: Finally, show that there is a unique solution for v and that v =
O(|λ|M+1) as |λ| →0. This is done by deﬁning a sequence of successive
approximations to v by v0 = 0, and for j = 1, 2, . . . , vj = H(vj−1, λ).
This deﬁnes a Cauchy sequence (see Section 4.4.1), and so it converges
to a solution of the equation. To see that this solution satisﬁes the error
estimate, we note that v1 does, and that each further approximation does.
In fact, we have that each vj satisﬁes
|vj| ≤Kδ|vj−1| + K|λ|M+1

128
4. Bifurcation and Topological Methods
for some constant K, all small λ, and vj−1 satisfying |λ| + |vj−1| ≤δ.
Therefore,
|v1|
≤
K|λ|M+1
|v2|
≤
Kδ|v1| + K|λ|M+1,
and, by a straightforward induction,
|vj| ≤K(1 + r + r2 + · · · + rj−1)|λ|M+1,
where r = Kδ. It follows that v satisﬁes the estimate
|v| ≤K|λ|M+1
1 −r
= O

|λ|M+1
.
4.1.3
Nonlinear Problems: The Noninvertible Case
Now suppose that the linear part of the problem is not invertible.
Speciﬁcally, suppose the following condition:
Hypothesis HNI: A(0)x = 0 has q linearly independent solutions for
x.
With this, ker[A(0)] is spanned by some vectors, φ1, . . . , φq, and
ker[A(0)⊤] is spanned by ψ1, . . . , ψq. We suppose that these are biorthog-
onal sets with
ψj · φk = δj,k
for j, k = 1, . . . , q, where δj,k is Kronecker’s delta function (δj,k = 1 if
k = j, = 0 otherwise).
As in Section 4.1, we let
u = c1φ1 + · · · + cqφq + w,
where c1, . . . , cq are arbitrary constants and w is a vector that is orthogonal
to the null space of A(0), that is, w · φj = 0 for j = 1, . . . , q.
The equations to be solved become
A(0)w
=
H(c1, . . . , cq, w, λ)
≡
−C(λ) −[A(λ) −A(0)]w −G(c1φ1 + · · · + cqφq + w, λ).
Here and below we write A for A(0), and we use the matrix notation Φc =
c1φ1+· · ·+cqφq, where Φ is an N ×q matrix whose columns are the vectors
φ1, . . . , φq and c is the column vector whose components are c1, . . . , cq.
The invertible form of the implicit function theorem can be used to prove
the existence of a unique function w∗(c1, . . . , cq, λ) that solves the equation
A⊤Aw = −A⊤H(c1, . . . , cq, w, λ)

4.2. Solving Some Bifurcation Equations
129
ker(  )
      A
      A
ker(     )
tr
    = ker(  )
 S          A  
T           A  
   = ker(     )
tr
A
Figure 4.1. Diagram of the Fredholm Alternative.
and is orthogonal to the null space of A. This is the least-squares version of
the original equations. The solution w∗is a solution if the original system
of the solvability conditions
ψj · H[c1, . . . , cq, w∗(c, λ), λ] = 0
are satisﬁed for j = 1, . . . , q. This fact is a restatement of Fredholm’s
Alternative. These q equations for the q unknowns c1, . . . , cq, are called
the bifurcation equations. Each small solution of them for small λ gives a
small solution of the original problem, namely,
u = Φc + w∗(c, λ).
This approach has been extended to study quite sophisticated problems
in functional analysis, and it is now referred to as the Liapunov–Schmidt
Method [135].
Figure 4.1 is important to keep in mind, since it describes where w∗
and the bifurcation equations come from. The combinations of c1, . . . , cq
are selected by the solvability conditions to ensure that H lies in T =
ker(AT )⊥. This may or may not be possible. If so, then the invertible form
of the implicit function theorem is used in the portion of EN where A is
invertible to ﬁnd w∗(c, λ) in S = ker(A)⊥. It is straightforward to derive
w∗in practice by iteration, but solving the bifurcation equations is usually
diﬃcult.
4.2
Solving Some Bifurcation Equations
Finding u in the invertible case and w∗in the noninvertible case are usually
straightforward, and the method of iteration described in the proof gives
a reliable iterative scheme for ﬁnding them. However, in the noninvertible
case, the bifurcation equations must be solved as well, and it is at this
point that the hard work begins. There are no known general methods for
doing this, but Newton’s polygons are quite useful for solving a variety of
problems.

130
4. Bifurcation and Topological Methods
4.2.1
q = 1: Newton’s Polygons
When q = 1, the solution takes the form
x = cφ + w∗(c, λ),
and the bifurcation equation becomes the scalar equation
0 = ψ · f[cφ + w∗(c, λ), λ],
which can be expanded in powers of c and λ. Therefore, we consider the
scalar equation
0 = a0,0 + a1,0c + a0,1λ + a2,0c2 + a1,1cλ + a0,2λ2 + · · · ,
which we want to solve for small real solutions c when λ is near 0. Here are
some examples:
1. There may be a unique small solution
0 = c + λc2 + λ2c + λc = c(1 + λc + λ2 + c).
Here c = 0 is the only small solution for λ near zero.
2. There may be more than one solution, and both could be an analytic
function of λ:
0 = λc2 + λ2c = λc(c + λ).
Thus, c = 0 and c = −λ are two small solutions.
3. There may be several solutions, but they are analytic in some
(fractional) power of λ:
0 = λc3 −λ2c = λc(c2 −λ).
Here c = 0, c =
√
λ, and c = −
√
λ are small solutions.
These examples suggest that we look for solutions in the form
c = αλr + higher order terms in λ
for some amplitude α and some base exponent r. Thus,
0
=
a1,0αλr + a0,1λ + a2,0α2λr2 + a1,1αλrλ + a0,2λ2 + · · ·
=
(· · · )λr∗+ · · · ,
where
r∗= min{rj + k = constant: j, k = 0, 1, 2, . . . , for which aj,k ̸= 0}.
Terms that will balance to contribute to the coeﬃcient of λr∗can be deter-
mined by ﬁnding the indices (j, k) of nonzero coeﬃcients for which at least
two lie on the same straight line k = −rj+ constant. This can be done
graphically by plotting k vertically and j horizontally, the points (j, k) for
which aj,k ̸= 0. Then the straight lines bounding this set of (j, k) values

4.2. Solving Some Bifurcation Equations
131
 k(  )
 j(c)
λ
Slope -1/2
Slope -1
Figure 4.2. Newton’s polygon for λ2 + λc −c3 + c4 + λ2c2. There are two relevant
slopes.
from (0, 0) are determined, and the slopes of these lines give the possi-
ble values of −r. Only lines having at least two points are of interest in
obtaining possible equations for α.
For example, consider the equation
0 = λ2 + λc −c3 + c4 + λ2c2.
Figure 4.2 shows the indices and the enclosing straight lines.
From Figure 4.2, we see that the two possible cases are
c ≈λ
and
c ≈
√
λ.
Newton’s polygon method rests on the following theorem, which shows that
corresponding to each of these scalings there is an analytic solution.
Weierstrass Preparation Theorem. Suppose that G(c, λ) is an an-
alytic function of c and λ near c = 0, λ = 0, such that G(0, 0) = 0
and
∂jG
∂cj (0, 0) = 0
for j = 1, . . . , k −1,
but ∂kG
∂ck (0, 0) ̸= 0.
Then there are analytic functions A0(λ), . . . , Ak−1(λ), and B(c, λ) with
B(c, λ) ̸= 0 for c and λ near zero, such that
G(c, λ) = [ck + Ak−1(λ)ck−1 + · · · + A0(λ)]B(c, λ).
We do not prove this result here [66]. If we wish to solve the equation
G(c, λ) = 0

132
4. Bifurcation and Topological Methods
for c as a function of λ, then since B ̸= 0, the roots are determined by
solving the polynomial
ck + Ak−1(λ)ck−1 + · · · + A0(λ) = 0.
There are exactly k solutions of this equation for each value of λ near λ = 0.
Moreover, each root is an analytic function of some (fractional) power of
λ.
If in the example depicted in Figure 4.2 we set
c = α
√
λ + Bλ + · · · .
Then
α −α3
=
0
(1 −3α2)β + (1 + α4)
=
0,
and so on. This shows that α = ±1, 0 are the possible candidates for
starting; thereafter, all coeﬃcients are uniquely determined. We will apply
this method in the next examples.
4.3
Examples of Bifurcations
The examples presented in this section illustrate important bifurcation phe-
nomena that arise in many applications. The ﬁrst is a system that exhibits
the classical cusp bifurcation of static states, and the second illustrates a
Hopf bifurcation of a periodic solution.
4.3.1
Exchange of Stabilities
Consider the system of diﬀerential equations
dx
dt
=
λx −ayx
dy
dt
=
−by + dyx + fx2,
where a, b, d, and f are positive constants. Small static states of these equa-
tions are to be found by solving the equations dx/dt = 0, dy/dt = 0 for x
and y when λ is near zero. In this case the matrix A(λ) = diag(λ, −b), and
when λ = 0, φ = ψ = (1, 0)⊤. Therefore, we seek the solutions of the form
x = c, y = w, in the notation of Section 4.1.3.
The ﬁrst step in using the Liapunov–Schmidt method involves solving
0 = −bw + dwc + fc2 + h.o.t.

4.3. Examples of Bifurcations
133
for w as a function of c and λ, where h.o.t. denotes higher order terms in
c. Obviously,
w = fc2
b
+ h.o.t.
Substituting this result into the ﬁrst equation gives the bifurcation equation
0 = λc −(af/b)c3 + c(h.o.t.).
Using Newton’s polygons, we see that if λ < 0, then c = 0 is the only
(small) real solution. If λ > 0, then there are three possible solutions, c = 0
and c = ±

λb/af + h.o.t.
Therefore, this system has a unique small static state for λ < 0, namely
x = y = 0, and there are three small static states for λ > 0. An interesting
aspect of this example is that the solution x = y = 0 is exponentially stable
for λ < 0, but it is unstable for λ > 0. However, for λ > 0, the two new
(nonzero) solutions are both exponentially stable. This behavior is typical
of many stability problems, and it is referred to as being an exchange of
stabilities. Note that when λ = 0, the solution x = y = 0 is UAS but not
EAS; in fact, the system is stable under persistent disturbances through the
bifurcation, but not structurally stable. This is studied further in Chapter 8
[51, 85].
4.3.2
Andronov–Hopf Bifurcation
The following example shows how an oscillation can bifurcate from a static
state in such a way that its amplitude grows while its frequency remains
approximately constant. Consider the system
dx
dt
=
[λ −(x2 + y2)]x −ωy
dy
dt
=
ωx + [λ −(x2 + y2)]y,
where λ and ω are constants. Setting r2 = x2 + y2 and θ = tan−1(y/x),
this problem becomes
dr
dt
=
r(λ −r2)
dθ
dt
=
ω.
Dividing the ﬁrst equation by the second gives
dr
dθ = r(λ −r2)
ω
.
Thus, the λω-system reduces easily to a scalar diﬀerential equation where
the original angle variable becomes a time-like variable. Static states for this
equation (r = r∗) correspond to periodic solutions of the original system.

134
4. Bifurcation and Topological Methods
We considered the same static state problem in the preceding section. For
λ < 0, there is a unique real static state for r, namely r = 0. For λ > 0
there are three real solutions r = 0 and r = ±
√
λ. The two nonzero static
states for r correspond to periodic solutions, one π out of phase with the
other, so we consider only the positive root. The result for the original
system is that for λ > 0 there is a unique periodic orbit, namely,
x =
√
λ cos(ωt + φ),
y =
√
λ sin(ωt + φ),
where φ is a free constant.
We say that as λ increases through λ = 0, a periodic solution bifurcates
from the static state x = 0, y = 0. Note that this static state is stable for
λ < 0 but unstable for λ > 0; however, the periodic solution is orbitally
exponentially stable for λ > 0. Therefore, an exchange of stabilities can
also occur through the appearance of a periodic solution.
The λω-system provides a good example of a periodic solution bifur-
cation, and it is typical of a class of problems called Hopf bifurcation
problems. We study these later in Chapter 8 [69].
4.3.3
Saddle-Node on Limit Cycle Bifurcation
The example here shows how an oscillation can bifurcate from a static state
in such a way that the amplitude remains approximately constant while the
frequency increases. Consider the system
dx
dt
=
(R2 −x2 −y2)x −(Ω+ x)y
dy
dt
=
(Ω+ x)x + (R2 −x2 −y2)y,
where R and Ωare some constants.
The bifurcation occurs here as Ω/R increases through the value 1:
1. For Ω/R < 1, θ →cos−1 Ωas t →∞.
2. For Ω/R > 1, θ →∞as t →∞.
The oscillation that appears is close to the circle r = R, but the frequency
increases as the bifurcation point is passed. Further study of this model
shows that as Ω/R →1, a stable node and a saddle point coalesce, and as
the bifurcation is passed, they annihilate each other and only the circular
orbit remains.
4.3.4
Cusp Bifurcation Revisited
The appearance and disappearance of two stable static states occurs in
most systems that exhibit hysteresis. The cusp model illustrates this.

4.3. Examples of Bifurcations
135
Consider the scalar equation
dx
dt = −(x3 −ax + b).
The static states of the system are found by solving
x3 −ax + b = 0
for x. There are either one or three real solutions to this equation, as shown
in Figure 2.20, where the real solutions for x are plotted as functions of
(a, b). The lines where multiple static states appear can be found in the
following way.
As shown in Section 2.4.3, the bifurcation curves are
b = ±2a3/2
3
√
3 .
These curves in the ab-plane describe the situation as shown in Figure 2.20.
Between them there are three roots; the top and bottom ones are stable
for the diﬀerential equation. Outside of this region, there is only one real
root, and it is stable.
In the terminology of singularity theory [133], each of the branches of
the bifurcation curve describes a fold bifurcation where the surface folds
over and under itself. The cusp singularity is at the origin a = 0, b = 0,
and it describes the coming together of two folds.
4.3.5
Canonical Models and Bifurcations
One of the reasons that mathematical results are so eﬀective in so many
surprising applications is that there are certain canonical models that arise
in a wide variety of applications. A canonical model is the continuous image
of an entire class of models, and so it represents the class. Any results for
the canonical model carry over in some sense to all models of the class even
though not all of these are known [81].
For example, the neuroscientist Hodgkin observed that nerve cells can
ﬁre in two diﬀerent ways as stronger currents are applied through their
membranes. He classiﬁed these as Class 1 and Class 2 excitations. In the
ﬁrst, an oscillation appears that has approximately constant amplitude but
increasing frequency. In the second case, an oscillation of cell membrane
voltage appears that grows in amplitude but has approximately constant
frequency. The saddle-node on limit cycle and the Andronov–Hopf models
are canonical models for these two phenomena, respectively [81]. These
same models occur in descriptions of a wide variety of other physical and
biological phenomena.
On the other hand, the cusp bifurcation occurs as a canonical model
of a codimension 2 singularity [133]. It arises later in this book in both
Duﬃng’s and van der Pol’s equations, and it signals the appearance of

136
4. Bifurcation and Topological Methods
bistable behavior. The exchange of stabilities example resides within the
cusp surface as well.
4.4
Fixed-Point Theorems
A periodically forced system has the form
dx
dt = f(t, x),
where x and f are in EN, and we suppose that f is a smooth function of
its arguments having (least) period T in t.
A solution starting at a point x(0) evolves into a point x(T) after T
units, and as in Chapter 3, we can deﬁne the return mapping, or Poincar´e’s
mapping, by
P : x(0) →x(T).
Fixed points of this mapping correspond to periodic solutions of the original
system of equations, and a study of P helps us to clarify several important
issues. The following lemma shows this.
Lemma. P has a ﬁxed point if and only if the diﬀerential equation used
to deﬁne it has a solution of period T (not necessarily its least period).
Proof. If Py = y, then let the solution of the deﬁning system with initial
value x(0) = y be denoted by x(t). Let z(t) = x(t + T). Note that z(t)
satisﬁes the same diﬀerential equation as x, and that z(0) = x(T) = y.
Since solutions of this problem are unique, x and z are identical. This
shows that x(t) = x(t + T) for all t. Conversely, if x(t) is a solution having
period T, then x(0) is a ﬁxed point of P.
This lemma shows that a ﬁxed point of the return mapping corresponds
to a periodic solution of the original system. Therefore, we can establish
the existence of periodic solutions to the system of diﬀerential equations
by ﬁnding its ﬁxed points. In this section we describe four methods that
are available for doing this.
4.4.1
Contraction Mapping Principle
Suppose that F is a continuous mapping of a closed subset Ωof EN into
itself such that for some constant λ, 0 ≤λ < 1, we have that
|F(x) −F(y)| ≤λ|x −y|
for all x and y in Ω. Then there is a unique ﬁxed point for F in Ω, and it
is asymptotically stable under iterations of F.

4.4. Fixed-Point Theorems
137
The proof of this result begins with showing that the iteration sequence
{xn}, say starting from x0 and for n = 0, 1, . . . deﬁned by
xn+1 = F(xn),
is a Cauchy sequence. In fact, |xn+1 −xn| ≤λ|xn −xn−1|, so |xn+1 −xn| ≤
λn|x1 −x0|. It follows that for any integers k and n,
|xn+k −xn| ≤
 n+k

j=n
λj

|x1 −x0|.
Since the sum in this estimate approaches zero as n and k →∞, we see
that {xn} is a Cauchy sequence. Therefore, it converges to a limit, say x∗.
Passing to the limit n →∞in the formula
xn+1 = F(xn)
shows that x∗= F(x∗). Obviously, x∗is the only ﬁxed point of F. Finally,
an initial condition, say y0, lying near x0, deﬁnes an iteration sequence
{yn}. Since
|yn −xn| ≤λn|y0 −x0|,
we see that yn →x∗as n →∞. Thus, the equilibrium is asymptotically
stable [32].
Example. A Forced Stable Linear System. The equation
dx
dt = Ax + g(t),
where A is a constant matrix having all eigenvalues in the left half-plane
and g is a vector of smooth functions having period T, has a unique periodic
solution. This can be proved using the contraction mapping principle, as
we show next.
The return mapping is deﬁned for this system as follows: An initial value
x(0) determines a unique solution of this equation, namely,
x(t) = exp(At)x(0) +
 t
0
exp[A(t −s)]g(s)ds.
The return mapping therefore is
P(ξ) = exp(AT)ξ +
 T
0
exp[A(T −s)]g(s)ds,
where we write x(0) = ξ. Since A is a stable matrix, we have
| exp(ATm)| < 1
for suﬃciently large values of m. Therefore, P m is a contraction mapping
for suﬃciently large m. It follows that P m has a unique ﬁxed point, say ξ∗.

138
4. Bifurcation and Topological Methods
Also, ξ∗is a unique ﬁxed point of P, since for any point x(0) we have
P mk[x(0)] →ξ∗
as k →∞, and so
P(ξ∗) = P[P mk(ξ∗)] = P mk[P(ξ∗)] →ξ∗
as k →∞. It must be that
ξ∗= [I −exp(AT)]−1
 T
0
exp[A(T −s)]g(s)ds.
It follows that the diﬀerential equation has a unique periodic solution,
namely,
x(t) = exp(At)ξ∗+
 t
0
exp[A(t −s)]g(s)ds.
4.4.2
Wazewski’s Method
A mapping need not be a contraction to have a ﬁxed point. In fact, recall
from calculus that every continuous function attains all values between its
maximum and minimum values. If f is a continuous function mapping a
ﬁnite interval [a, b] into itself, then the graph of f (i.e., the set {[x, f(x)] :
x ∈[a, b]}) must intersect the one-to-one line {(x, x)}. Such an intersection
deﬁnes a ﬁxed point of f.
This observation is based on the intermediate value theorem of calculus,
and it is possible to extend it to dimensions higher than one. Brouwer’s
ﬁxed-point theorem does this.
Brouwer’s Fixed-Point Theorem. Suppose that F : EN →EN is a
continuous mapping of a closed ball, say Ω⊂EN, into itself. Then F has
a ﬁxed point, say x∗, in Ω.
Note that the ﬁxed point given by this result need not be unique, since
the conditions are satisﬁed by the identity mapping on Ω. This result is
not proved here [32].
Example: Forcing a System That Is Stable Under Persistent
Disturbances. Consider the equation
dx
dt = −x3 + A cos t.
In the tx-plane, we see that ˙x < 0 on the line x = 2A, but on the line x =
−2A, ˙x > 0. Therefore, solutions starting in the interval −2A ≤x ≤2A
remain there for all future times. In particular, this interval is mapped into
itself by the return mapping. It follows from Brouwer’s theorem that the
return mapping has a ﬁxed point, and so there is a periodic solution of this
equation.

4.4. Fixed-Point Theorems
139
 x
 t
 x = -2A
 x = 2A
Figure 4.3. Example of Brouwer’s theorem.
A corollary of Brouwer’s theorem is the No-Retract Theorem.
No-Retract Theorem.
There is no continuous mapping of the unit
ball (or any compact manifold with boundary) in EN onto its boundary that
leaves boundary points ﬁxed.
Proof. If there were such a mapping, say G, of the set
BN = {x ∈EN : |x| ≤1},
called the unit ball in EN, onto its boundary
SN−1 = {x ∈EN : |x| = 1},
then G followed by the antipodal mapping x →−x would deﬁne a con-
tinuous mapping of the unit ball into itself that had no ﬁxed points. This
contradicts Brouwer’s Theorem, and so the No-Retract Theorem is proved.
Another interesting consequence of this theorem is useful in study-
ing nonlinear diﬀerential equations. Consider solutions of a system of N
equations
dx
dt = f(t, x)

140
4. Bifurcation and Topological Methods
that have initial values in a smooth, bounded, and simply connected domain
Ω. Let c denote the cylinder in tx space that is deﬁned by
C = {(t, x) : 0 ≤t < ∞, x in Ω}.
Let ∂C denote the lateral boundary of this cylinder:
∂C = {(t, x) : 0 ≤t < ∞, x in ∂Ω}.
An egress point of C is a point in ∂C at which a solution of the system
leaves the interior of C. A strict egress point, say (t∗, x∗), is one where a
solution of the system lies inside C for t∗−δ < t < t∗and outside C for
t∗< t < t∗+ δ for some small positive number δ. With these deﬁnitions,
we can discuss Wazewski’s result:
Wazewski’s Theorem. Suppose that all egress points of the system are
strict egress points. Then there is a solution of the system that begins in Ω
and remains in C for all t ≥0.
Proof. If such a point did not exist, then every point in Ωdeﬁnes an
orbit that eventually leaves C. We deﬁne a mapping of Ωinto ∂C by the
solutions: If p ∈Ωand x(t, p) is the solution emanating from that point
at t = 0, then the mapping is given by p →q = x(t∗, p), where t∗is the
ﬁrst time this solution hits ∂C. This is a continuous mapping, since egress
points are strict. The mapping p →q followed by the projection
(t∗, x∗) →(0, x∗),
which is called a pull-back mapping, then deﬁnes a continuous mapping of
Ωonto its boundary that leaves boundary points ﬁxed. This contradicts
the No-Retract Theorem and completes the proof of the theorem [32].
The solutions described by this theorem are usually diﬃcult to con-
struct numerically because they are often not stable. Some techniques based
on a related theorem, Sperner’s lemma, have been devised (see [18] and
Section 4.4.3).
Example. A Forced Unstable System. Consider the equation
dx
dt = x + A cos t.
The cylinder {(t, x) : t ≥0, −2A ≤x ≤2A} is bounded (in x) by the lines
x = ±2A. Since every egress point is a strict egress point for this cylinder,
there is a solution, say x = p(t), that remains within these limits for t ≥0.
This must be a periodic solution. Indeed, the general solution is given
by the formula
x(t) = exp(t)x(0) +
 t
0
exp(t −s)A cos s ds.

4.4. Fixed-Point Theorems
141
The return mapping is given by
P(ξ) = exp(2π)ξ +
 2π
0
exp(2π −s)A cos s ds,
and it has a unique ﬁxed point
ξ∗= [1 −exp(2π)]−1
 2π
0
exp(2π −s)A cos s ds.
The solution p(t) is the one with the initial value ξ∗.
4.4.3
Sperner’s Method
Suppose that f is a mapping of the plane E2 into itself. Thus, for each
point x ∈E2, f deﬁnes a vector
f(x) = [f1(x1, x2), f2(x1, x2)].
Consider a triangle T in E2; select one side of T, say S; and trace the vector
f around T, keeping track of the angle it makes with the side S. The total
angle passed through must be 2πN for some integer N. This is called the
index of T relative to f. We denote it by I(f, T). If T is a small triangle,
we see that if f ̸= 0 in T and on its boundary, then I(f, T) = 0.
Next consider two triangles, say T1 and T2, that share a side, say S, and
suppose that I(f, T1) = 0 and I(f, T2) = 0. Let the part of the index of f
that occurs on T2 −S be δ2; then the part on S is −δ2. Similarly, if the
index on T1 −S is δ1, then the index on S is −δ1. It follows that
I(f, T1 ∪T2) = δ1 + δ2 = 0.
Finally, consider an arbitrary triangle T. Suppose that I(f, T) ̸= 0. Then
there must be a point p ∈T such that f(p) = 0. Such a value can be
found by introducing a triangulation of T into subtriangles of size d (i.e.,
the longest side of one of the partitioning triangles is of length d). This
argument shows that for at least one of the triangles in this partition, say
s, we must have I(f, s) ̸= 0, or else f ̸= 0 in every triangle.
The index and this triangulation construction give a method for ﬁnding a
ﬁxed point of f in a triangle T. First, select a mesh size d and a correspond-
ing triangulation of T. Begin on the boundary of T, successively testing
subtriangles around the boundary for their index. Throw away triangles
t for which I(f, t) = 0. This algorithm, referred to as Sperner’s method,
leads us to a subtriangle, say s, for which I(f, s) ̸= 0. This algorithm can
be quite useful for computations [23, 119].

142
4. Bifurcation and Topological Methods
4.4.4
Measure-Preserving Mappings
Consider an externally forced Hamiltonian system
dx
dt = J∇H(x) + g(t),
where x ∈E2N, say x = col(p, q), where each of p, q ∈EN, J is Jacobi’s
matrix
J =

0
−I
I
0

,
and H and g are smooth functions. Since the divergence of the right-hand
side of this system is zero, the ﬂow deﬁnes a volume-preserving transforma-
tion of E2N into itself (see Section 2.3.8). Suppose also that g has period
T. Then the return mapping is deﬁned by
x(0) →x(T),
and it deﬁnes a measure-preserving transformation of E2N into itself. We
have seen in this chapter that ﬁxed points of this mapping deﬁne periodic
solutions of the original system. We have seen in Chapter 2, for exam-
ple from Poincar´e’s Twist Theorem in Section 2.5, that the ﬁxed-point
structure of volume-preserving mappings can be quite complicated. This
problem is the object of intense study [116].
4.5
Exercises
4.1. a. Show that the rank of an N × N matrix A and its transpose A⊤are
the same. Show that if the equation Ax = f is solvable, then f must
be orthogonal to all null vectors of A⊤.
b. Let L = (f −Ax) · (f −Ax). Show that the equations ∂L/∂xj = 0
for j = 1, . . . , N are equivalent to the system of equations
A⊤Ax = A⊤f.
c. Solve the system
2x + y
=
f1
4x + 2y
=
f2,
using the least-squares method described in part b.
d∗. Show that the least-squares method works also when A is in EM×N,
where M ̸= N.
4.2.
Show that the sequence of iterates deﬁned by the iteration in Sec-
tion 4.1.2, say {vj}, deﬁnes a Cauchy sequence, and so that it
converges. Verify that the limit satisﬁes the estimate
v = O(|λ|M+1)
as λ →0.

4.5. Exercises
143
4.3. a. Demonstrate the Weierstrass Preparation Theorem by showing that
the function G deﬁned in Section 4.2.1 can be written in the form
G(c, λ) = (ck + l.o.t.)B(c, λ),
where B(0, 0) ̸= 0. Here l.o.t. denotes lower order terms in powers of
c.
b. Construct all small solutions for c and λ near zero of the equation
c9 −c4λ + cλ2 = 0
using Newton’s polygon method and the Weierstrass Preparation
Theorem.
4.4.
Exchange of Stabilities. Verify the computations done in Sec-
tions 4.3.1 and 4.3.2.
4.5.
Consider the diﬀerential-delay equation
dx
dt = λx(t −1)[1 −x2(t)].
Show that as λ increases through the value λ = π/2, a bifurcation
of a periodic solution occurs. Do this by showing that as λ increases
through the value λ = π/2, a single pair of eigenvalues of the linear
problem
dx
dt = λx(t −1)
crosses the imaginary axis from left to right. Show that for λ =
π/2, the function x = sin πt/2 solves the linear problem. [See
Exercise 2.14.b.]
4.6.
Verify that the formulas for ξ∗in the examples in Sections 4.4.1
and 4.4.2 lead to the deﬁnition of solutions having period T.
4.7.
Verify that the graph of a continuous function f that maps an interval
into itself must cross the one-to-one line at some point. Thus, the
function must have a ﬁxed point.
4.8. a. Solve the equation
dx
dt = −x3 + A cos t
numerically and plot x(2π) versus x(0). Show that there is a unique
periodic solution of this equation and that it is asymptotically stable.
b. Show that the strict egress point mapping in Wazewski’s theorem is
a continuous mapping of the initial set into the boundary.
c. Use Wazewski’s theorem to show that the diﬀerential equation
dx
dt = x3 + A cos t
has a unique periodic solution that starts and remains in the interval
−2A ≤x(t) ≤2A.

5
Regular Perturbation Methods
Four kinds of perturbation problems are studied in the remainder of this
book. They are illustrated by the following examples:
1. Smooth Data and a Finite Interval. The initial value problem
dx
dt = −x3 + εx,
x(0, ε) = ξ0 + εξ1 + O(ε2),
where the right-hand side deﬁnes a smooth function of ε at ε = 0, arises
frequently in bifurcation problems. The solution x = 0 is stable under
persistent disturbances, but not exponentially asymptotically stable. A so-
lution can be constructed using Taylor’s formula: First, when ε = 0, the
solution is
x0(t) =
ξ0

1 + 2tξ2
0
,
and for ε ̸= 0 it has the form
x(t) = x0(t) + εx1(t) + O(ε2),
where x1(t) solves the problem
dx1
dt = (−3x0(t)x1 + 1)x0,
x1(0) = ξ1,
and so on. This is a regular perturbation problem on a ﬁnite interval [0, T],
and the error estimate O(ε2) holds as ε →0 uniformly for 0 ≤t ≤T.
However, since the solution x(t) approaches √ε as t →∞, we cannot
expect Taylor’s formula to be valid uniformly for 0 ≤t < ∞.

146
5. Regular Perturbation Methods
2. Smooth Data and an Inﬁnite Interval. The problem
dx
dt = −x + ε,
x(0, ε) = ξ0 + εξ1 + O(ε2)
has the property that when ε = 0 the solution x = 0 is exponentially
asymptotically stable. The solution of this equation is
x(t) = e−t[ξ(ε) −ε] + ε.
Since this depends smoothly on ε uniformly for 0 ≤t < ∞, the problem is
referred to as a regular perturbation problem on [0, ∞).
3. Highly Oscillatory Data. The coeﬃcient of x in the problem
dx
dt = −cos
 t
ε

x + ε,
x(0, ε) = ξ0 + εξ1 + O(ε2)
is highly oscillatory, having period 2πε. This coeﬃcient has an essential
singularity at ε = 0, and the solution is
x(t) = exp

−
 t
0
cos
s
ε

ds

x(0, ε) + ε
 t
0
exp

−
 t
s
cos
s′
ε

ds′

ds.
It is not apparent at ﬁrst glance how one might extract useful informa-
tion from this explicit formula. However, we will see that the Method of
Averaging (described in Chapter 7) provides for this.
4. Smooth Data—Singular Solutions. Solutions might decay or grow
rapidly over short time intervals. For example, the equation
εdx
dt = −x,
x(0, ε) = ξ0 + εξ1 + O(ε2)
appears to involve a smooth perturbation, but its solution is
x(t) = exp(−t/ε)x(0, ε),
which has an essential singularity at ε = 0. Problems of this kind are
studied in Chapter 8 using quasistatic-state approximation methods.
Examples 1 and 2 are regular perturbation problems, and 3 and 4 are
singular perturbation problems, so called because their solutions depend
regularly or singularly on ε at ε = 0.
Many methods are available for identifying regular perturbation prob-
lems and for constructing their solutions. In this chapter we derive some
methods based on Taylor’s theorem for constructing approximations to
their solutions. Applications of these methods to oscillation problems are
made in Chapter 6. Singular perturbation problems are studied using
averaging and matching methods in Chapters 7 and 8, respectively.
The regular perturbation methods derived here are based on the Im-
plicit Function Theorem. After introducing some other useful ideas, we
derive methods for constructing solutions to initial value problems in what
corresponds to both the invertible and noninvertible cases.

5.1. Perturbation Expansions
147
5.1
Perturbation Expansions
Perturbation methods have played important roles in the development of
mathematics and physics. Most of the problems studied here come from
electrical circuits or mechanical systems, but the methods were developed
for and used in a variety of applications.
In this chapter we deal primarily with problems that can be solved using
Taylor’s formula, but methods using Pad´e approximations are also dis-
cussed. Recall that Taylor’s formula shows how to approximate a smooth
function by a polynomial, and it estimates the error that is made in the
approximation. Pad´e’s method uses rational function approximations made
up of ratios of polynomials. Using rational functions often makes it possible
to uncover information about singularities of a function and so to obtain
approximations far away from where power series converge.
A variety of notation is used to describe these procedures. Gauge func-
tions are described ﬁrst. Next, Taylor’s and Pad´e’s formulas are discussed.
Since solutions of diﬀerential equations can be found using integral formu-
las, like the variation of constants formula, it is important to know Laplace’s
method and the method of stationary phase, which we also describe brieﬂy
in this section.
5.1.1
Gauge Functions: The Story of o, O
Suppose that f and g are smooth functions of ε for ε near zero, say |ε| ≤ε0.
We say that
f(ε) = O(g(ε))
as ε →0
if f(ε)/g(ε) is bounded for all small ε. Thus, there is a constant K and a
constant ε1 such that
|f(ε)| ≤K|g(ε)|
for all |ε| ≤ε1.
We say that
f(ε) = o(g(ε))
as ε →0
if
f(ε)
g(ε) →0
as ε →0.
Thus, given a tolerance η, there is a constraint δ such that |f(ε)| ≤η|g(ε)|
when |ε| ≤δ. These are order-of-magnitude or gauge relations between
functions, and they give some idea of the relative sizes between them for
small values of the parameter ε. We say that
n

n=0
cnfn(ε)

148
5. Regular Perturbation Methods
is an asymptotic expansion of f(ε) at ε = 0 if the following are true:
1. The sequence {fn}, n = 0, . . . , n + 1, is a gauge sequence; that is,
fn(ε) = o(fn−1(ε)) as ε →0 for n = 1, . . . , n + 1, and
2.
f(ε) −
n

n=0
cnfn(ε) = O(fn+1(ε))
as ε →0.
Asymptotic expansions need not converge as n →∞, since convergence
would imply that the function approximated is closely related to an analytic
function. We have no reason to suspect a priori that solutions are that
smooth. Asymptotic expansions do not uniquely determine functions, and
on the other hand, several diﬀerent asymptotic sequences can be used to
approximate a given function [33].
5.1.2
Taylor’s Formula
A function f(ε) that has n + 1 continuous derivatives at ε = 0 can be
approximated by a polynomial of degree n:
f(ε) = f(0) + f ′(0)ε + · · · + f [n](0)εn/n! + O(εn+1).
This is Taylor’s expansion of f about ε = 0, and it gives a very useful
approximation to f near ε = 0. The error is given explicitly by the formula
f [n+1](η)εn+1
(n + 1)!
,
where η is some point near zero, |η| < ε. Here the gauge sequence is fn = εn,
and so on.
5.1.3
Pad´e’s Approximations
Pad´e’s approximations are rational functions that account for pole sin-
gularities, and they are frequently valid in domains larger than those for
power series expansions. It is often useful to construct an approximation to
a function using Taylor’s formula and then derive Pad´e’s approximation to
Taylor’s polynomial. This is obviously successful when we sum a geometric
series. In general, an analytic function’s Taylor series has radius of conver-
gence R that is restricted to the largest circle not enclosing a singularity. If
the singularity is a pole, then Pad´e’s method can be used to continue the
function outside this circle of convergence.
We say that the rational function
Rm,n(ε) = Pm(ε)
Qn(ε) ,

5.1. Perturbation Expansions
149
where Pm is a polynomial of degree m and Qn is one of degree n, is an
[m, n]-Pad´e approximation to f if
f(ε) −Rm,n(ε) = O(εm+n+1)
as ε →0. Constructing Pad´e’s approximation Rm,n begins with a power
series expansion of f about ε = 0, say
f(ε) = f0 + f1ε + · · · + fMεM + O(εM+1).
We specify m and n such that m + n + 1 ≤M, and we seek polynomials
Pm(ε) = a0 + a1ε + · · · + amεm
and
Qn(ε) = b0 + b1ε + · · · + bnεn
such that
f = Pm
Qn
+ O(εm+n+1).
Usually, we take m = n −1, 2n ≤M, and b0 = 1. This last can be done
without loss of generality if Q(0) ̸= 0, since the numerator and denom-
inator can be multiplied by an arbitrary constant. Since we use a ratio
of polynomials of degrees m and n, we cannot expect to achieve greater
accuracy than order m + n + 1, so we cross multiply to get
Qnf −Pm = O(εm+n+1).
Equating coeﬃcients of like powers on both sides gives
order m + n :
b0fm+n
+
· · ·
+
bnfm
= 0
order m + n −1 :
b0fm−1+n
+
· · ·
+
bnfm−1
= 0
· · ·
· · ·
· · ·
· · ·
· · ·
· · ·
order m + 1 :
b0f1+m
+
· · ·
+
bnfm−n+1
= 0,
starting from order m + n. Here we set fj = 0 if j < 0. This is a system of
n equations for the n unknowns b1, . . . , bn. Recall that b0 = 1, so this is a
nonhomogeneous problem.
We assume the following condition:
Hypothesis H1. This system can be solved for b1, . . . , bn.
Once the coeﬃcients of Qn are known, we can easily ﬁnd the coeﬃcients
of Pm:
order 0 :
a0 = f0
order 1 :
a1 = b1f0 + f1
· · ·
order m :
am = m
j=1 bjfm−j + fm.
Thus, once the coeﬃcients of the denominator are known, the coeﬃcients
of the numerator can be found explicitly.

150
5. Regular Perturbation Methods
There are many surprising and useful extensions of this method [20].
Consider the system of diﬀerential equations
dx
dt = A(ε)x + B(ε),
where A and B are matrices that are polynomials in ε, say of degrees m
and n, respectively. A static state of this system must solve the equation
A(ε)x + B(ε) = 0.
If A(0) is invertible, then the unique static state is
x = −A−1(ε)B(ε)
for ε near 0,
which is a matrix of rational functions of ε. Therefore, Taylor’s method is
more restrictive than Pad´e’s, for which a matrix form of Pad´e’s method,
Rm,n(ε), gives the exact solution to this problem.
Two ways to proceed with perturbation problems are as follows:
Method I. Substitute Taylor’s or Pad´e’s expansion into the problem and
equate coeﬃcients of like powers of ε.
Method II. Derive equations for the coeﬃcients in the approximation by
successively diﬀerentiating the problem with respect to ε.
These two methods are used throughout the remainder of this book.
5.1.4
Laplace’s Methods
The system of diﬀerential equations
dx
dt = A(ε)x + f(t)
has the solution
x(t) = eA(ε)tx(0) +
 t
0
eA(ε)(t−s)f(x)ds.
Evaluating this formula can be diﬃcult.
For example, if A(ε) = 1/ε, then the solution becomes large if ε →0+
or if t →+∞. On the other hand, if A(ε) = −1/ε, then the ﬁrst term
on the right-hand side of this equation approaches a discontinuous limit
as ε →0, namely, x(0) if t = 0, but 0 if t > 0. The second term is more
interesting, and the kernel in this integral is closely related to a Dirac delta
function. Finally, if A(ε) = i/ε, then the integral is highly oscillatory, and
the asymptotic evaluation of it is closely related to the Riemann–Lebesgue
Lemma [125].
The ﬁrst case (A = 1/ε) is divergent, and we do not deal with it further.
The second case (A = −1/ε) is treated by using Laplace’s method, and
the third case (A = i/ε) can be evaluated using stationary phase methods.
Since we are dealing primarily with approximations to solutions of diﬀeren-
tial equations, it is important to know these fundamental methods. In fact,

5.1. Perturbation Expansions
151
they form the basis of the matching and averaging results, respectively,
treated in later chapters. We begin with integration by parts, which is
sometimes referred to as the fundamental theorem of applied mathematics.
Integration by Parts.
Consider the function of t and ε deﬁned by the integral formula
 t
0
exp(is/ε)f(s)ds,
where f is a continuously diﬀerentiable function. Integration by parts gives
an easy way to determine how this function behaves as ε →0. In particular,
 t
0
exp
is
ε

f(s)ds = ε
i exp
it
ε

f(t) −ε
i f(0) −ε
i
 t
0
exp
is
ε

f ′(s)ds.
Integration by parts can be used to generate an asymptotic expansion of
this function, but this short calculation shows that the integral is of order
O(ε) (as ε →0) for any ﬁxed value of t.
Laplace’s Integral Formula.
Consider the integral
h(ε) =
 β
α
f(s) exp

−g(s)
ε

ds.
What is the dominant part of this integral as ε →0+? Integration by parts
is usually not useful in answering this question.
We suppose that f(t) is continuous and g(t) is a twice-diﬀerentiable real-
valued function for α ≤t ≤β. The place where g is smallest should give
the fastest growing part of the kernel, so let us ﬁrst suppose that g has a
minimum at a point τ ∈(α, β). Then g′(τ) = 0 and g′′(τ) > 0. As ε →0,
h(ε) ∼
 τ+δ
τ−δ
f(s) exp

−g(τ) + g′′(τ)((s −τ)2/2)
ε

ds.
Setting u2 = g′′(τ)(s −τ)2/2ε gives
h(ε)
∼
2f(τ) exp

−g(τ)
ε

2ε
g′′(τ)
 δ[g′′(τ)/2ε]1/2
0
e−u2du
∼
2f(τ) exp

−g(τ)
ε

2πε
g′′(τ)
as ε →0+.
When the minimum of g is attained at an endpoint of the interval, then
similar calculations show that
h(ε) ∼





f(α) exp[−g(α)/ε]

2πε
g′′(α)
if g′(α) = 0
εf(α) exp[−g(α)/ε]
1
g′(α)
if g′(α) > 0,
if the left endpoint is a local minimum for g. Similarly for τ = β.

152
5. Regular Perturbation Methods
The Method of Stationary Phase.
Consider the integral formula
h(ε) =
 β
α
f(s) exp
iφ(s)
ε

ds,
where |ε| ≪1 and the phase φ is a real-valued function of the real variable
s. Stokes and Kelvin [33] claim that the major contributions to this integral
come from the endpoints α and β and from the vicinity of the points where
φ is stationary, that is, where φ′ = 0, and that to leading order in ε,
the stationary points are more signiﬁcant than the endpoints. This can be
justiﬁed using the method of steepest descent, which we do not present
here [33].
Suppose that φ is stationary at some point τ, say that φ′(τ) = 0 and
φ′′(τ) > 0. We suppose that the major part of the integral comes from near
τ, so we write
h(ε) ∼
 τ+ε
τ−ε
f(t) exp
iφ(t)
ε

dt.
As before,
h(ε) ∼

2πε
φ′′(τ)f(τ) exp
iφ(τ)
ε
+ iπ
4

as ε →0+.
We use these calculations later in Chapter 7.
5.2
Regular Perturbations of Initial Value
Problems
What conditions ensure that a problem is regular; for example, when will
Taylor’s formula be successful in ﬁnding approximate solutions? Several
results in this section answer these questions.
5.2.1
Regular Perturbation Theorem
Given smooth data f and ξ in EN, we consider the initial value problem
dx
dt = f(t, x, ε),
x(0) = ξ(ε).
Suppose the following conditions are satisﬁed:
Hypothesis H2. For ε = 0, this system has a unique solution on some
ﬁnite interval 0 ≤t ≤T. We call this solution x0(t), and it satisﬁes the
equations
dx0
dt = f(t, x0, 0),
x0(0) = ξ(0).

5.2. Regular Perturbations of Initial Value Problems
153
Hypothesis H3. f and ξ(ε) are smooth functions of their variables for
0 ≤t ≤T, x near x0, and ε near zero. Speciﬁcally, we suppose that f and
ξ are n + 1 times continuously diﬀerentiable in all variables, so
ξ(ε) = ξ0 + ξ1ε + · · · .
We have the following theorem:
Regular Perturbation Theorem. Let conditions H2 and H3 be sat-
isﬁed. Then for suﬃciently small ε the perturbed problem has a unique
solution, and it is n + 1 times diﬀerentiable with respect to ε. Moreover,
this solution can be expanded in a Taylor expansion
x(t, ε) = x0(t) + x1(t)ε + · · · + xn(t)εn + O(εn+1),
where the error estimate holds as ε →0 uniformly for 0 ≤t ≤T.
5.2.2
Proof of the Regular Perturbation Theorem
The proof of this result involves three steps. The usual existence theory for
ordinary diﬀerential equations ensures that a unique solution of the prob-
lem exists for 0 ≤t ≤T [24]. Denote this by x(t, ε). Since this solution is
n + 1 times diﬀerentiable with respect to ε, it can be expanded in a Taylor
polynomial up to order O(εn+1). The ﬁrst step involves ﬁnding this expan-
sion. The diﬀerence between the real solution and Taylor’s approximation
is called the remainder. The second step involves deriving an equation for
the remainder, and the third step involves ﬁnding an a priori estimate of
the remainder.
Step 1. We use Method II for ﬁnding the expansion of the solution:
x(t, ε) = x0(t) + x1(t)ε + · · · ,
where
x0(t)
=
x(t, 0)
x1(t)
=
∂x(t, ε)
∂ε

at ε = 0, etc.
Therefore,
dx0
dt = f(t, x0, 0),
x0(0) = ξ0
dx1
dt = fx(t, x0, 0)x1 + fε(t, x0, 0),
x1(0) = ξ1
· · ·
dxm
dt
= fx(t, x0, 0)xm + {· · · }m,
xm(0) = ξm.
Here fx denotes the Jacobian matrix having components (∂fi/∂xj), fε
denotes the partial derivatives of the components of f with respect to

154
5. Regular Perturbation Methods
ε, and the terms {· · · }m denote a combination of terms depending on
x0, . . . , xm−1.
The ﬁrst equation’s solution is given by condition H2. The remaining
equations for m = 1, . . . , M are forced linear equations, and their solu-
tions can be obtained from the variation of constants formulas. Thus, the
expansion of x(t, ε) is uniquely determined.
Step 2. The remainder is deﬁned to be
R(t, ε) = x(t, ε) −E(t, ε, n),
where E denotes the expansion just found for x(t):
E(t, ε, n) =
n

j=0
xj(t)εj.
This function satisﬁes the equation
dR
dt = f(t, R + E, ε) −dE
dt .
An equivalent way to think of E is that it was found by substituting the
form
E(t, ε, n) =
n

j=0
xj(t)εj
into the equation and equating like powers of ε. Thus,
dE
dt = f(t, E, ε) + O(εn+1),
and the equation for R becomes
dR
dt = (fx(t, x0, 0) + O(ε))R + o(R) + O(εn+1),
R(0) = O(εn+1).
The second step involves showing that this equation has a unique solution.
This follows from the method of successive approximations presented in
Chapter 4.
Step 3. Finally, we must estimate |R|. It follows from Gronwall’s in-
equality that R = O(εn+1). This completes the proof of the theorem.
The proof of this result is typical of proofs of expansion approximations.
First, the approximation is constructed on faith. Then the diﬀerence be-
tween it and a real solution of the problem is deﬁned. An equation for this
diﬀerence is then analyzed, usually using contraction mapping arguments.
This establishes the existence of a solution to the remainder equation. Fi-
nally, the solution of the remainder equation is estimated, usually using
Gronwall’s inequality.

5.2. Regular Perturbations of Initial Value Problems
155
5.2.3
Example of the Regular Perturbation Theorem
Consider the equation
dx
dt = −
x
1 + ε,
x(0) = cos ε.
The regular perturbation theorem guarantees that the solution of this prob-
lem is a smooth function of ε at ε = 0. Therefore, it has a Taylor expansion
about ε = 0, say
x(t, ε) = x0(t) + x1(t)ε + · · · + xn(t)εn + O(εn+1).
These coeﬃcients can be determined directly from the equation by suc-
cessively diﬀerentiating it, with the result being a sequence of diﬀerential
equations for the coeﬃcients: (Method II)
dx0
dt
=
−x0,
x0(0) = 1
dx1
dt
=
−x1 + x0,
x1(0) = 0
dx2
dt
=
−x2 + x1 −x0,
x2(0) = −1, etc.
Therefore,
x0(t)
=
exp(−t)
x1(t)
=
t exp(−t)
x2(t)
=
exp(−t)(t2/2 −t −1), etc.
This calculation illustrates the direct Taylor method; of course, Pad´e’s
method would work better for this problem.
5.2.4
Regular Perturbations for 0 ≤t < ∞
Two interesting examples are
dx
dt = −x3 + εx
and
dx
dt = εx.
Both of these are regular perturbation problems for t restricted to a ﬁnite
interval, but the regular perturbation theorem breaks down for each on
inﬁnite time intervals. In the ﬁrst case, x(t) →√ε as t →∞, which is not
a smooth function of ε at ε = 0, even though the equations are smooth.
In the second, x(t, ε) is an entire function of t and ε, but the solution is
exp(εt), which does not converge uniformly for 0 ≤t < ∞as ε →0.

156
5. Regular Perturbation Methods
What conditions ensure that the approximation found in the regular
perturbation theorem is valid uniformly for all 0 ≤t < ∞? Consider the
initial value problem
dx
dt = f(t, x, ε),
x(0) = ξ(ε).
Suppose ﬁrst that the problem has a solution when ε = 0.
Hypothesis H4. The zero-order problem
dx0
dt = f(t, x0, 0),
x0(0) = ξ(0)
has a unique solution for 0 ≤t < ∞.
Next, suppose that the data are smooth near this solution.
Hypothesis H5. ξ and f are smooth functions of their arguments for
ε near zero, 0 ≤t < ∞, and for (t, x) near (t, x0(t)).
Finally, suppose that the linearized problem is exponentially asymptoti-
cally stable (EAS).
Hypothesis H6. The fundamental solution of the linear problem
dY
dt = fx(t, x0(t), 0)Y,
y(s) = I
satisﬁes
|Y (t)| ≤K exp(−α(t −s))
for all 0 ≤t < ∞, where K and α are some positive constants.
With these assumptions, we have the following theorem.
Regular Perturbation Theorem on [0, ∞). Let conditions H4, H5,
and H6 be satisﬁed. Then for suﬃciently small ε, the full problem has a
unique solution, and it exists for 0 ≤t < ∞. Moreover, if
E(t, ε, n) =
n

j=0
xj(t)εj
is the expansion derived in the Regular Perturbation Theorem, then
x(t, ε) −E(t, ε, n) = O(εn+1),
where the error estimate holds uniformly for 0 ≤t < ∞.
The proof of this result proceeds exactly the same as in the ﬁnite-interval
case, except for the last step. In step 3, we must use the estimate provided
by condition H6 in Gronwall’s inequality to realize a uniform bound on
the function (x −E)ε−M−1 that is valid for 0 ≤t < ∞. This is the same

5.3. Modiﬁed Perturbation Methods for Static States
157
argument as used in the Linear Stability Theorem in Chapter 3, and it is
not reproduced here.
Example. Uniformly Valid Regular Perturbation Expansion.
Consider the equation
dx
dt = Ax + εf(x),
x(0) = ξ,
where f(0) = 0 and A is an asymptotically stable matrix (i.e., its
eigenvalues have strictly negative real parts).
Then
x(t, ε) −exp(At)x(0) = O(ε)
as ε →0 uniformly for 0 ≤t < ∞.
5.3
Modiﬁed Perturbation Methods for Static
States
Consider now an autonomous (i.e., time-invariant) system of equations
dx
dt = f(x, ε).
Static states of the problem are determined by solving the equation
f(x, ε) = 0.
We studied this in Chapter 4 using the implicit function theorem.
Recall that we made the following assumptions:
Hypothesis H1. There is a solution for ε = 0, say x∗
0:
f(x∗
0, 0) = 0.
Hypothesis H2. f is a smooth function of x and ε for x near x∗
0 and ε
near zero.
Hypothesis H3. The Jacobian
det(∂f/∂x)(x∗
0, 0) ̸= 0.
Or:
Hypothesis H3′. The Jacobian matrix has rank r < N.
We refer to problems satisfying conditions H3 as being nondegenerate
and those satisfying H3′ as being degenerate.

158
5. Regular Perturbation Methods
5.3.1
Nondegenerate Static-State Problems Revisited
Under conditions H1, H2, and H3, there is a unique solution of the per-
turbed equation near x∗
0, say x∗(ε), for ε near zero. Moreover, this solution
is a smooth function of ε. It follows that x∗(ε) can be expanded in Taylor’s
expansion about ε = 0:
x∗(ε) = x0 + εx1 + · · · + εnxn + O(εn+1).
Since the coeﬃcients in this expansion are derivatives of x∗with respect to
ε, we can derive equations for them directly from the deﬁning equation:
f(x0, 0)
=
0
fx(x0, 0)x1 + fε(x0, 0)
=
0,
and so on. Since x0 is given and the Jacobian condition is satisﬁed, each of
these equations has a unique solution.
5.3.2
Modiﬁed Perturbation Theorem
In Chapter 4 the implicit function theorem was used to study problems
where the linear part is not invertible, but we had to derive and deal with
a complicated set of bifurcation equations. In this section we derive a useful
perturbation technique for constructing the bifurcation equations directly.
Consider the static state problem
f(x, ε) = 0,
where f(0, 0) = 0 and f is a smooth function near (0, 0) in EN+1. Thus,
we suppose that x0 = 0. Further, suppose that
Hypothesis H3′. The Jacobian matrix
A = (∂f/∂x)(0, 0)
has rank r and nullity q = N −r. Moreover, the null space of this matrix
is spanned by vectors {φ1, . . . , φq}, and the null space of its adjoint is
spanned by vectors {ψ1, . . . , ψq}, where
ψj · φk
=
δj,k
φj · φk
=
ψj · ψk = δj,k
for j, k = 1, . . . , q. Here δj,k is Kronecker’s delta function; it is equal to 1
if j = k and is zero otherwise.
Finally, we rewrite the equation as
f(x, ε) = Ax + G(x, ε) = 0,
where G(x, ε) = f(x, ε) −Ax = O(ε + |x|2) for x and ε near zero.
We are now in a position to deﬁne the modiﬁed problem.
Modiﬁed Perturbation Problem.

5.3. Modiﬁed Perturbation Methods for Static States
159
Given small values of c1, . . . , cq and ε, ﬁnd functions λj(c1, . . . , cq, ε) for
j = 1, . . . , q and x(c1, . . . , cq, ε) such that
Ax + G(x, ε) +
q

j=1
λjψj = 0
φk · x = ck
for k = 1, . . . , q.
The following result shows that this system is solvable, and that the bifur-
cation equations derived in Chapter 4 are found by setting λ1 = 0, . . . , λq =
0.
Modiﬁed Perturbation Theorem.
Under conditions H1, H2, and
H3′, the modiﬁed perturbation problem has a unique solution. That is, there
are unique functions λj(c1, . . . , cq, ε) and w(c1, . . . , cq, ε) that are deﬁned
for c1, . . . , cq, ε near zero such that
1. The functions x = q
j=1 cjφj + w and λ1, . . . , λq satisfy the modiﬁed
perturbation problem.
2. These functions have at least n+1 continuous derivatives with respect
to c1, . . . , cq and ε. In particular, these functions can be expanded
using Taylor’s formula:
w
=
wc1c1 + · · · + wcqcq + wεε + h.o.t.
λj
=
λjc1c1 + · · · + λjcqcq + λjεε + h.o.t.
This result is quite useful in studying resonance problems. Of course, it
is a clever restatement of the degenerate Implicit Function Theorem [5.4].
Proof of the Modiﬁed Perturbation Theorem. The proof of this result is
accomplished by showing that the Implicit Function Theorem can be used
to solve the modiﬁed problem. Writing
x =
q

j=1
cjφj + w
we have
Aw + Ψλ = −G(x, ε).
The columns of A span the set ker(A⊤)⊥and the columns of the matrix
Ψ span ker(A⊤). Therefore, the linear part on the left-hand side of this
equation is a matrix having N linearly independent columns, and so it is
invertible. Therefore, the modiﬁed problem can be solved using the nonde-
generate form of the Implicit Function Theorem. In particular, there is a
unique solution for w and λ, which are smooth functions of c1, . . . , cq, and

160
5. Regular Perturbation Methods
ε. In fact, introduce a change of basis
x =
q

j=1
cjφj +
N−q

j=1
wjφj+q,
where the vectors φ1, . . . , φq span ker(A) and the vectors φq+1, . . . , φq+r
complete this set to a basis of EN. Then the modiﬁed problem becomes
λj
=
−ψj · G

q

j=1
cjφj + w, ε

Aw
=
G

q

j=1
cjφj + w, ε

−
q

j=1
λjψj.
Since the linear problem for λ and w has full rank, the Implicit Function
Theorem (nondegenerate form) ensures that these equations can be solved
for small solutions λ and w as functions of c1, . . . , cq, and ε for |c| and |ε|
near zero.
Thus, there is a unique solution for x and λ as functions of c and ε. Once
this is done, the original problem can be solved by requiring that
λj(c, ε) = 0
for j = 1, . . . , q.
These are equivalent to the bifurcation equations derived in Chapter 4.
5.3.3
Example: q = 1
Approximations of the modiﬁed perturbation solution (i.e., x and the func-
tions λj) can be found using Taylor’s formula: We take q = 1 to illustrate
this method. Then
x
=
xεε + xcc + · · ·
λ
=
λεε + λcc + · · · .
The ﬁrst result is
Axε + Gε(0, 0) + λeψ
=
0
xε · φ
=
0.
Thus, λε = −ψ · Gε(0, 0) and
Axε + Gε(0, 0) −(ψ · Gε(0, 0))ψ = 0.
This equation has a unique solution that is orthogonal to φ. Next,
Axc + λcψ
=
0
xc · φ
=
1.
Therefore, λc = 0 and xc = φ.

5.4. Exercises
161
In this way we can continue to construct Taylor’s expansion of each of
these functions. We return to the original problem by forcing the modiﬁed
problem to be the same as the original one:
λ(c, ε) = 0.
This equation can be studied using Newton’s polygons. The modiﬁed
method applies in the exchange of stabilities problem in Chapter 4, and
we use it in constructing nonlinear oscillations in Chapter 6.
5.4
Exercises
5.1.
Show that x and x+exp(−1/x) have the same asymptotic expansions
as x →0+.
5.2.
Show that
1
1 + x
∼
−

(−x)n
∼
−

(x −1)x2n
∼
−

(x2 −x + 1)(−x)3n
as x →∞, where the sums are taken for n = 0, 1, 2, 3, 4, . . . .
5.3. a. Solve the equation
(1 −ε)f(ε) = 1
for f using two diﬀerent methods: Pad´e approximants and Taylor’s
expansions. Compare the answers you obtain in each case.
b. Construct the [1, 1]-Pad´e approximation to the function
f(ε) =
	1 + ε/2
1 + 2ε

−1/2
.
Construct Taylor’s approximation of f up to order 2. Compare your
answers for ε = 1 and for ε = ∞.
5.4.
Calculate an asymptotic approximation to the integral
 1
a
exp
	is2
ε

cos s ds
as ε →0 for the two cases a = 0 and a = −1.
5.5.
Show that R = O(eM+1) in the proof of the regular perturbation
theorem in Section 5.2.2.
5.6.
Use the Ansatz x = exp[P(ε)t/Q(ε)] to solve the problem
dx
dt = −
x
1 + ε,
x(0) = cos ε
in the example in Section 5.2.3 for |ε| ≪1.
5.7.
Apply the modiﬁed perturbation method to the exchange of stabilities
problem in Sections 4.3.1 and 5.3.3.

6
Iterations and Perturbations
Forcing a nonlinear oscillation can have complicated consequences, espe-
cially if the forcing period is near the oscillation’s period. The simplest
question is: Under what conditions will a periodic solution result? The
answers for externally forced systems are quite diﬀerent from those for
feedback systems that are found in Sections 3.5, 7.4, 7.5, and 8.4.
Problems considered in this chapter have the general form
dx
dt = f(t, x, ε),
where x, f ∈EN and f is a smooth function of its variables. The case
where f has least period T > 0, say f(t + T, . . . ) = f(t, . . . ) for all t, is
referred to as an externally (periodically) forced system. When f does not
depend explicitly on t, we refer to it as a feedback system.
We suppose that the unperturbed problem
dx
dt = f(t, x, 0)
has a periodic solution x = p(t), say with period T. Conditions on the
data will be found under which the perturbed problem (ε ̸= 0) will have
a periodic solution that is close to p(t) and has period near T or some
rational multiple of T.

164
6. Iterations and Perturbations
6.1
Resonance
When we try to construct expansions of forced oscillations, we soon dis-
cover diﬃculties if the forcing frequency is near a natural frequency of the
system. Two results, one describing nonresonance and the other applicable
to resonant cases, are presented in the ﬁrst section of this chapter. The
modiﬁed perturbation method is applied to these cases, and the results
are compared to other perturbation and iteration schemes in the case of
Duﬃng’s equation. In the course of this, we discover that chaotic behavior
can occur and that fractals can bound basins of attraction when Duﬃng’s
equation is externally forced.
The equation
d2x
dt2 + µ2x = ε cos t
is useful for introducing some basic ideas. It can be solved explicitly. If
µ2 ̸= 1, then
x(t) = A cos(µt + φ) + ε cos t
µ2 −1,
where A and f are arbitrary constants. The ﬁrst term gives the general
solution of the free problem. If µ2 = 1, then
x(t) = A cos(t + φ) + εt sin t
2
;
the last term is referred to as secular, since it grows very slowly.
Since we are interested in ﬁnding solutions that have the same period
as the forcing function (viz., 2π), we specify that x satisfy the periodicity
conditions
x(t + 2π, ε) = x(t, ε)
for all t ≥0.
There are three cases:
1. The problem is nonresonant, or regular, when µ is not an integer. In
this case, the equation has a unique solution of period 2π, namely,
x(t) = ε cos t
µ2 −1.
2. Subresonance occurs when µ2 = n2 for some integer n2 ̸= 1. In this
case the solution formula shows that both terms in the solution have
period 2π, but the ﬁrst, which corresponds to the general solution of
the homogeneous equation, has least period 2π/n. The second term
is a particular solution of the equation.
3. Resonance occurs when µ2 = 1. In this case, there is no solution of
the equation having period 2π.

6.1. Resonance
165
The situation here is quite similar to Fredholm’s Alternative for solving
systems of linear equations. Recall that when solving the linear system
Lx = f,
where L is a matrix and x and f are vectors, we found that there is a
solution for x if and only if the forcing function f is orthogonal to the null
space of L⊤. We follow the same approach for solving equations where now
L represents a diﬀerential operator and f is a function.
The concept of orthogonality for vectors extends naturally to functions.
Let f and g be two complex valued functions deﬁned on an interval 0 ≤
t ≤T. Let tj = jT/N for j = 0, 1, 2, . . . , N, and fj = f(tj) and gj = g(tj).
The vectors f = (f0, . . . , fN) and g = (g0, . . . , gN) have inner product
f · g =
N

j=0
fjg∗
j ,
where g∗
j denotes the complex conjugate of gj. If N is large, this is
approximately the integral
1
N f · g = 1
T
N

j=0
fjg∗
j
T
N ≈1
T
 T
0
f(s)g∗(s)ds ≡1
T (f, g),
where we deﬁne the inner product of two square integrable functions f(t)
and g(t) to be
(f, g) =
 T
0
f(t)g∗(t)dt.
We say that f and g are orthogonal over [0, T] if (f, g) = 0.
Note that if f is a square-integrable complex-valued function, then (f, f)
exists, and so we can deﬁne
|f| =

(f, f).
This shows that these integral formulas are natural extensions to functions
of geometric ideas for vectors.
For example, taking the inner product (with T = 2π) of both sides of
our diﬀerential equation with the general solution of the unforced problem
(ε = 0), namely with cos(µt + φ), we have

cos(µt + φ), d2x
dt2 + µ2x

= (cos(µt + φ), ε cos t).
Integration by parts shows that the left-hand side of this equation is zero.
Therefore, a necessary condition that this equation have a solution is that
0 = (cos(µt + φ), ε cos t)
for any constant φ. In this example, this condition is also suﬃcient to ensure
solvability.

166
6. Iterations and Perturbations
How can these cases be determined directly from the equation? The
unperturbed, or free, equation is
d2x
dt2 + µ2x = 0.
Since we will be forcing this system with period 2π, solutions of this equa-
tion that have period 2π are the important ones. In the resonance case,
the forcing is among these. In the subresonance case, the forcing function
is orthogonal to these; and in the regular case, there are no such solutions
to the free problem.
In our analogy with Fredholm’s Alternative, the matrix L is replaced by
a diﬀerential operator
Lx = d2x
dt2 + µ2x
deﬁned for all square-integrable functions x(t) for which the second
derivative makes sense and that satisfy the periodicity conditions
x(t) = x(t + 2π)
for all t. This operator is self-adjoint in the sense that (Lx, y) = (x, Ly).
6.1.1
Formal Perturbation Expansion of Forced Oscillations
Let us try to construct the solution of the general problem
dx
dt = f(t, x, ε),
x(t + T) = x(t)
by a regular perturbation expansion beginning with a known periodic solu-
tion when ε = 0, say p(t), without worrying about validity. Let our Ansatz,
or initial guess for the solution, be
x(t) = p(t) + εx1 + ε2x2 + · · · .
This gives
dp
dt
=
f(t, p, 0)
dx1
dt
=
fx(t, p, 0)x1 + fε(t, p, 0),
and so on, where the subscripts denote diﬀerentiations with respect to ε
and the components of x.
The solution for x1 is given by the formula
x1(t) = Q(t) exp(Rt)x1(0) +
 t
0
Q(t) exp[R(t −s)]Q−1(s)fε(s)ds,
where fε(s) ≡fε(s, p(s), 0) and Q(t) exp(Rt) is the fundamental solution
of the linear part given by Floquet’s theory; x1 is periodic if x1(T) = x1(0).

6.1. Resonance
167
Thus, we have a formula for the initial data of periodic solutions:
[I −exp(RT)]x1(0) =
 T
0
exp[R(T −s)]Q−1(s)fε(s)ds.
As before, there are three cases:
1. The matrix I −eRT is invertible (nonresonance).
2. The matrix is not invertible, but the right-hand side is orthogonal to
its adjoint null vectors (subresonance).
3. The matrix I −eRT is not invertible and the right-hand side is not
orthogonal to its adjoint null vectors (resonance).
In case 3 there is no solution for x1(0), and so the formal perturbation
Ansatz breaks down. In case 2 there is a unique particular solution, plus
an arbitrary linear combination of null vectors of the matrix. This requires
the special accounting supplied by the modiﬁed perturbation method. In
the ﬁrst case there is a unique solution for x1(0), hence a unique periodic
solution of the system.
This calculation illustrates the general situation: Speciﬁc results are
described in the sections on nonresonance and resonance, which follow.
6.1.2
Nonresonant Forcing
It is possible to give conditions that ensure nonresonance and to completely
describe perturbation solutions in that case. We refer to this collection of
results as the Nonresonance Theorem.
Consider the forced system
dx
dt = f(t, x, ε),
where f is a vector of smooth functions that are periodic in t, say with
least period T. We suppose the following:
Hypothesis H1. There is a solution x = p(t) of the unperturbed
equation
dx
dt = f(t, x, 0)
that has period T.
Hypothesis H2. x, f ∈EN. f is a smooth function of its variables for
(t, x) near (t, p(t)) and ε suﬃciently small. Moreover, f has least period
T > 0 in t:
f(t + T, x, ε) = f(t, x, ε)
for all t ≥0.

168
6. Iterations and Perturbations
The problem here is to determine solutions of this system that are
periodic having the same period as the forcing
x(t + T, ε) = x(t, ε)
for all t ≥0.
If ψ(t, a, ε) is the solution of the diﬀerential equation that satisﬁes the
initial condition
ψ(0, a, ε) = p(0) + a,
then ﬁxed points of the mapping
p(0) + a →ψ(T, a, ε)
deﬁne periodic solutions of the original problem. Therefore, we consider the
equation
ψ(T, a, ε) −p(0) −a = 0.
We can apply the Implicit Function Theorem to this equation to construct
solutions for a = a(ε), and so eventually construct periodic solutions of the
forced problem.
The Jacobian matrix of this equation for a is
∂ψ
∂a (T, 0, 0) −I,
where I is the N-dimensional identity matrix. If this matrix is nonsingular,
then we can ﬁnd a unique solution for a = a(ε). If the matrix is singular,
then we can use the modiﬁed perturbation method to study solutions.
The Jacobian matrix is usually not easy to determine, because the fol-
lowing calculation must be done. The function u = ∂ψ/∂a is an N × N
matrix that solves the linear problem
du
dt = fx(t, p(t), 0)u(t),
u(0) = I.
Since this is a linear equation having periodic coeﬃcients, Floquet’s theory
shows that u(t) has the form
u(t) = P(t) exp(Rt),
where P(t) has period T in t and R is a constant matrix. Therefore, u(T) =
eRT . Recall that the matrix R is usually diﬃcult to ﬁnd.
It follows that if all eigenvalues of R lie oﬀthe imaginary axis in the
complex plane, then the regular perturbation method works directly. The
result is a uniquely determined function a(ε). This proves the following
theorem.
Nonresonance Theorem. Let conditions H1 and H2 above be satisﬁed.
Further, suppose that x = 0 is the only solution of the linear problem
dx
dt = fx(t, p(t), 0)x,
x(t + T) = x(t);

6.1. Resonance
169
then, for suﬃciently small ε, the full problem has a unique periodic solution
x = x∗(t, ε). If f is M + 1 times diﬀerentiable with respect to its variables,
then x∗can be constructed using a regular perturbation expansion:
x∗(t, ε) = p(t) + x1(t)ε + · · · + xM(t)εM + O(εM+1),
where the coeﬃcients are uniquely determined by a hierarchy of linear
problems, and x∗is determined by the initial conditions
x∗(0, ε) = p(0) + a(ε),
where a is determined in the preceding argument.
Example of a Conservative System with nonresonant forcing.
Here we try to construct a 2π-periodic solution of the equation
d2x
dt2 + µ2x + εf(x) = g(t),
where f is a smooth function, µ is a ﬁxed constant, and ε is a small
parameter. The forcing function g is 2π-periodic and has a Fourier series
g(t) =
∞

m=−∞
gmeimt.
This equation includes Duﬃng’s equation, for which
f(x) = αx + βx3.
We suppose here that µ is not an integer. The unperturbed problem is
obtained by setting ε = 0:
d2x
dt2 + µ2x = g(t),
and it has a unique periodic solution that is given by the Fourier series
p(t) =
∞

m=−∞
gm
eimt
µ2 −m2 .
In this case, according to the Regular Perturbation Theorem, we can ﬁnd
x as a smooth function of ε. Therefore, we try to ﬁnd the solution of the
equation in the form of a Taylor expansion
x(t, ε) = p(t) + εx1(t) + · · · .
We obtain a system of equations for the other coeﬃcients:
d2x1
dt2 + µ2x1
=
−f(x0)
d2x2
dt2 + µ2x2
=
−∂f
∂x(x0)x1,

170
6. Iterations and Perturbations
and so on. These equations are to be solved subject to the periodicity
conditions
xj(t + 2π) = xj(t)
for j = 1, 2, . . .
for all t. Obviously, each of these problems has a unique solution, and the
Fourier series of each can be found.
6.1.3
Resonant Forcing
Problems created by resonant forcing are quite similar to those encountered
in the noninvertible case of the Implicit Function Theorem. We can reduce
the problem to a set of bifurcation equations, but the solutions of these
may be quite diﬃcult to ﬁnd.
We consider here systems in the form
dx
dt = Ax + εG(t, x, ε),
where x, G ∈EN. We say that the forcing function (G) is resonant if it has
period T and if the matrix I −exp(AT) is not invertible. In this case, the
hypotheses of the Nonresonance Theorem are not satisﬁed, since the linear
problem
dx
dt = Ax
has a (nonzero) solution of period T.
The following conditions are used in this section:
Hypothesis H1. G is a smooth function for −∞< t < ∞, with x
near zero and |ε| ≪1, and G(t + T, x, ε) = G(t, x, ε) for all t and some
least T > 0. Moreover, G(t, x, 0) = O(|x|)2 for x near zero uniformly for
0 ≤t ≤T.
Hypothesis H2. The matrix A has the form
A =
 R
0
0
D

,
where R is a K×K diagonal matrix, R = diag(r1, . . . , rK), with exp(RT) =
I, and the matrix D is such that exp(DT) −I is invertible.
This system is not as general as could be considered here (e.g., in general,
R is not diagonalizable), but it enables us to deal with the fundamental
solution exp(At) explicitly. More general equations require evaluation of
the Floquet exponent matrix, which we have discussed earlier.
The existence of periodic solutions can be studied as before: We seek
initial values a such that the solution x = φ(t, a, ε) has period T. As before,
φ(0, a, ε) = a,

6.1. Resonance
171
and we want to solve
φ(T, a, ε) = a
for a.
The function φ solves the equivalent integral equation
φ(t, a, ε) = eAta + ε
 t
0
eA(t−s)G(s, φ, ε)ds.
The periodicity condition becomes
(I −eAT )a = ε
 T
0
eA(T −s)G(s, φ, ε)ds.
Setting ˆa = col(a1, . . . , aK) and ¯a = col(aK+1, . . . , aN), and similarly for
G, say ˆG = (G1, . . . , GK) and ˜G = col(GK+1, . . . , GN), then we have
0
=
 T
0
e−Rs ˆG(s, φ(s, a, ε), ε)ds
(I −eDT )˜a
=
ε
 T
0
eD(T −s) ˜G(s, φ(s, a, ε), ε)ds.
The Implicit Function Theorem guarantees that for each small ε and for
each choice of ˆa near zero there is a unique solution for ˜a, say
˜a = ˜a(ˆa, ε).
Substituting this solution into the ﬁrst K equations gives the bifurcation
equations, which must be solved for ˆa. These results are summarized in the
following theorem.
Resonant Forcing Theorem. Let conditions H1 and H2 hold. Then
for each small ˆa in EK and ε there exists a unique solution ˜a = ˜a(ˆa, ε) in
EN−K of
(I −eDT )˜a = ε
 T
0
eD(T −s) ˜G(s, φ(s, a, ε), ε)ds.
Moreover, for each small solution ˆa of the bifurcation equations
0 =
 T
0
e−Rs ˆG(s, φ(s, ˜a(ˆa, ε), ε), ε)ds
there is a periodic solution
x = φ(t, a, ε)
of the original problem where a = col(ˆa, ˜a(ˆa, ε)).
This result is less satisfactory than the Nonresonance Theorem because
it takes us only to the bifurcation equations, and they are in a form that re-
quires knowledge of φ(t, a, ε). The modiﬁed perturbation method enables us

172
6. Iterations and Perturbations
to construct the bifurcation equations although there may be no solutions
to them or they might not be solvable using available methods.
6.1.4
Modiﬁed Perturbation Method for Forced Oscillations
Suppose that the conditions of the resonant forcing theorem are satisﬁed.
Then we can pursue periodic solutions as we did static states, using the
modiﬁed perturbation method.
First, we augment the problem by introducing K
new variables
λ1, . . . , λK, and K new constraints c1, . . . , cK:
dx
dt = Ax + εG(t, x, ε) + ε
K

j=1
λjerjtej,
where ej is the jth standard basis unit
ej = col(δ1,j, . . . , δN,j)
and rj is the jth eigenvalue of R. Note that because of our choice of basis
in the original problem, the last term can be written as
ε exp(At)λ,
where λ is the vector
λ = col(λ1, . . . , λK, 0, . . . , 0).
Thus, the augmented problem is
dx
dt = Ax + εG(t, x, ε) + ε exp(At)λ.
The K additional constraints are speciﬁed by the projections
(x, exp(rjt)ej) = cj
for j = 1, . . . , K. Finally, we specify that x has period T by requiring that
x(t + T) = x(t)
for all t.
Second, we construct Taylor expansions for x and λ as functions of ε and
c = (c1, . . . , cK), for these quantities near zero. Each of these problems has
a unique solution, and the results are functions
x = x(t, c, ε)
and
λ = λ(c, ε).
The third step gets us back to the original problem. We require that
λ(c, ε) = 0.
These are the bifurcation equations, and when they are satisﬁed, x(t, c, ε)
is a solution of the original problem that has period T.
Rather than present this method as a general algorithm, we consider an
important example in Section 6.2.8.

6.1. Resonance
173
6.1.5
Justiﬁcation of the Modiﬁed Perturbation Method
The program prescribed by the Modiﬁed Perturbation Method has three
steps:
1. Add K variables λ1, . . . , λK and K constraints c1, . . . , cK to the
problem by
dx
dt
=
Ax + εG(t, x, ε) + ε exp(At)λ
cj
=
(x, exp(λjt)ej),
where λ = col(λ1, . . . , λK, 0, . . . , 0) and ej is the jth standard basis
unit (i.e., a vector with 1 in the jth position and 0 elsewhere). Note
that the right-hand side of the diﬀerential equation is T-periodic in t,
and we are to solve this system for x and λ subject to the constraints
and the periodicity condition
x(t + T) = x(t)
for all t.
2. Construct x and λ as power series in ε and the components of
c = col(c1, . . . , cK, 0, . . . , 0). The coeﬃcients in these expansions are
determined uniquely.
3. The equations
λj(c, ε) = 0,
j = 1, . . . , K,
must be solved for c as functions of ε, say c = c(ε). For each such so-
lution the function x(t, c(ε), ε) is a T-periodic solution of the original
problem.
We now show that this approach is equivalent to the one in the previ-
ous section. In fact, let us denote the solution of the modiﬁed diﬀerential
equations that satisﬁes x(0) = b by
y(t, b, ε).
This function satisﬁes the integral equation
y(t, b, ε) = eAtb + ε
 t
0
eA(t−s)G(s, y, ε)ds + εteAtλ.
We observe that y has period T (i.e., y(0) = y(T)) if and only if b satisﬁes
the equation
(I −eAT )b = ε
 T
0
eA(T −s)G(s, y, ε)ds + εTeAT λ.
Note the presence of secular terms in the equation for y(t, b, ε); these are
discussed from another point of view in Section 6.2.3. We write b = col(ˆb,˜b),

174
6. Iterations and Perturbations
where the ﬁrst subvector has K components, etc. For each choice of ˆb near
zero and |ε| ≪1 there is a unique solution for ˜b = ˜b(ˆb, e) of the equations
(I −eDT )˜b = ε
 T
0
eD(T −s) ˜G(s, y, ε)ds.
We now replace b by col(ˆb,˜b(ˆb, ε)). With this, the projection constraints
take the form
cj = (y, exp(rjt)ej) = ˆbj + εHj(ˆb, ε),
where
Hj = 1
T
 T
0
 t
0
e−rjs ˆGjdsdt + T
2 λj
for j = 1, . . . , K. The Implicit Function Theorem guarantees that
c = ˆb + εH(ˆb, ε)
deﬁnes a one-to-one relation between c and ˆb. In particular, we can solve
for ˆb, say with the result
ˆb = c + εh(c, ε).
The functions λj are deﬁned by the formulas
λj(c, ε) = −1
T
 T
0
e−rjs ˆGj ds
which results from direct integration of the diﬀerential equation for y. Fi-
nally, values of c and ε for which λ = 0 result in a solution y that has
period T, but since it now satisﬁes the same equation as φ, we also have
that for such c and ε,
y(t, b(c, ε), ε) = φ(t, a, ε).
Thus, the results of the Resonant Forcing Theorem and the Modiﬁed
Perturbation Method agree.
6.2
Duﬃng’s Equation
The examples in this section illustrate several interesting aspects of reso-
nant forcing. These are all based on Duﬃng’s equation, which is among the
simplest nonlinear conservation equations. Several methods diﬀerent from
the Modiﬁed Perturbation Method have been devised to study resonantly
forced systems. Two particularly important ones are Duﬃng’s iterative
procedure and the Poincar´e–Linstedt perturbation procedure. Rather than
describing these methods in general, we consider an important typical case:
We study the response of Duﬃng’s equation to small resonant forcing where

6.2. Duﬃng’s Equation
175
the modiﬁed perturbation method, Duﬃng’s iteration, and the Poincar´e–
Linstedt methods can all be used. One or another of these methods can
work for many other cases.
We consider in this section the problem
d2x
dt2 + x = ε(−αx −βx3 + C cos ωt).
Resonance occurs when the forcing frequency ω is near 1.
6.2.1
Modiﬁed Perturbation Method
Consider Duﬃng’s equation when the forcing frequency is near resonance,
say
ω2 = 1 + µε + O(ε2).
With the change of variable ωt →t, the equation becomes
(1 + εµ)d2x
dt2 + x = ε(−αx −βx3 + C cos t).
According to the Modiﬁed Perturbation Method, we augment the equation
by introducing λ and η,
(1 + εµ)d2x
dt2 + x = ε(−αx −βx3 + C cos t + λ cos t + η sin t),
and we specify the constraints
(x, cos t) = a
and
(x, sin t) = b.
The Modiﬁed Perturbation Method is quite clumsy in this case. As a short-
cut, we ignore the fact that a and b are small, and we construct x, λ, and
η in powers of ε alone:
d2x0
dt2 + x0 = 0
(x0, cos t) = a
and
(x0, sin t) = b
d2x1
dt2 + x1 = −αx0 −βx3
0 + C cos t −µd2x0
dt2 + λ0 cos t + η0 sin t
(x1, cos t) = 0
and
(x1, sin t) = 0,
and so on. Solving the ﬁrst problem gives
x0(t) = 2a cos t + 2b sin t.
It will turn out that b = 0, so we use this information now to simplify the
calculations. In order that the second problem be solvable for a function

176
6. Iterations and Perturbations
having period 2π, we must have the coeﬃcient of cos t equal to zero on the
right-hand side of the equation:
−αa −3β a3
4 + C + aµ + λ0 = 0;
this formula relates the forcing frequency (ω) to the amplitude of response
(a). For further details see [89, 43].
The bifurcation equation is found by setting λ = 0. To leading order in
ε, this is
3β a3
4 + (α −µ)a −C = 0.
Note that there is a cusp singularity at a = 0, α −µ = 0, C = 0, as shown
in Figure 6.1.
6.2.2
Duﬃng’s Iterative Method
Duﬃng introduced an iterative method [31] for approximating the periodic
solutions of the
d2x
dt2 + x = ε(−αx −βx3 + C cos ωt).
Begin with an initial guess suggested by the forcing, namely,
x0(t) = A cos ωt,
and consider the iteration
d2xn+1
dt2
+ xn+1 = ε(−αxn −βx3
n + C cos ωt)
for n = 0, 1, . . . . The equation for x1 is
d2x1
dt2 + x1 = ε(−αA cos ωt −β(A cos ωt)3 + C cos ωt).
The right-hand side can be simpliﬁed by writing
(cos ωt)3 = 3 cos ωt
4
+ cos 3ωt
4
.
Then
d2x1
dt2 + x1 = ε

−αA −3βA3
4
+ C

cos ωt −A3β
4
cos 3ωt

.
Integrating this (assuming ω ̸= 1) gives
x1 = ε(−αA −3βA3/4 + C)
1 −ω2
cos ωt −
A3β
4(1 −9ω2) cos 3ωt.

6.2. Duﬃng’s Equation
177
Duﬃng’s idea is that if the initial guess is a good one, then the coeﬃcient
of cos ωt in this solution must be close to A. Thus,
(1 −ω2)A = ε

−αA −3βA3
4
+ C

.
If ω2 = 1 + µε, then
3βA3
4
+ (α −µ)A −C = 0.
This is identical to the result obtained in the preceding section using the
Modiﬁed Perturbation Method.
Once A is determined in this way, it follows that the amplitude of cos ωt
in each of the subsequent iterations will also be A.
6.2.3
Poincar´e–Linstedt Method
In the two preceding sections, the forcing frequency ω was given and the
response’s amplitude was determined. It is possible to reverse the procedure
by specifying the amplitude of the response and asking what frequencies
give a 2π-periodic oscillation having this amplitude.
Again, we consider the equation
d2x
dt2 + x = ε(−αx −βx3 + C cos ωt).
We make the change of variables ωt →t with the result
ω2 d2x
dt2 + x = ε(−αx −βx3 + C cos t).
Determine ω and x such that the periodicity condition
x(t + 2π) = x(t)
is satisﬁed as well as the initial conditions
x(0) = A,
x′(0) = 0,
which specify that x has A as a (local) maximum value.
We begin by expanding x and ω in power series:
x
=
x0(t) + x1(t)ε + · · ·
ω
=
ω0 + ω1ε + · · · .
Setting ε = 0 in the problem gives
ω2
0
d2x0
dt2 + x0 = 0
x0(t + 2π) = x0(t)
x0(0) = A,
x′
0(0) = 0.

178
6. Iterations and Perturbations
The periodicity condition requires that
ω0 = 1
and
x0(t) = A cos t.
Diﬀerentiating the equation with respect to ε and setting ε = 0 (Method
II in Section 5.1.3) gives
ω2
0
d2x1
dt2 + x1 = −αA cos t −βA3 cos3 t + C cos t −2ω0ω1
d2x0
dt2 ,
or
d2x1
dt2 + x1 =

C −αA −3βA3
4
+ 2ω1A

cos t −βA3
4
cos 3t.
We choose ω1 to cancel the remaining part of the coeﬃcient of cos t in the
right-hand side:
ω1 = αA + 3βA3/4 −C
2A
.
Therefore, we have
ω = 1 + εαA + 3βA3/4 −C
2A
+ O(ε2).
If we are interested in the frequency near 1, we write
ω = 1 + εµ/2,
which is the expansion of ω2 = 1 + εµ for ε near zero, and we get
3βA3
4
+ (α −µ)A −C + O(ε) = 0.
This relation between forcing frequency and response amplitude agrees with
those derived in the preceding sections.
The Poincar´e–Linstedt method is quite similar to the Modiﬁed Perturba-
tion Method, but its point of view is reversed as noted earlier. The method
is sometimes referred to as the perturbation method, and sometimes it is
called the Method of Suppressing Secular Terms. (Secular terms refer to
nonperiodic solutions that grow slowly.) They can be removed by choosing
constants such that coeﬃcients of terms causing resonance are zero, as we
chose ω1 here. This is very much in the spirit of the Modiﬁed Perturba-
tion Method, and its validity is established in our discussion of Averaging
Methods in Chapter 7.
6.2.4
Frequency-Response Surface
Each of the methods used above leads to a frequency-response relation of
the form
A3 −4(µ −α)A
3β
−4C
3β = 0,

6.2. Duﬃng’s Equation
179
 A
 C
µ−α
Figure 6.1. Cusp frequency-response surface.
although Duﬃng’s iteration method involves the least work in deriving this
formula. This formula deﬁnes a surface in ACµ-space, and it is depicted
in Figure 6.1, where it is assumed that all coeﬃcients in this equation are
positive.
Fixing the forcing amplitude C determines a cross-section of this surface.
Several of these are depicted in Figure 6.2, where we plot the response
amplitude |A|.
The restoring force αx + βx3 is due to the potential energy
U(x) = αx2
2
+ βx4
4 .
In analogy with a mechanical spring, the case where β > 0 is referred to as
that of a hard spring, since increasing extension (x) increases the restoring
force. The case of β < 0 is that of a soft spring, since the restoring force
eventually decreases with increasing extension. These diagrams show that
there is a nonunique response of the system for most parameter values. More
insight into this comes from considering Duﬃng’s equation with damping,
as in Section 6.2.6.
6.2.5
Subharmonic Responses of Duﬃng’s Equation
The periodic solutions found in the preceding section are harmonics of
the forcing; that is, they have the same period as the forcing function.
Many other periodic solutions of Duﬃng’s equation are excited by periodic
forcing. Solutions having least period some integer multiple of the forcing
period are common; these are called subharmonics (lower frequency). Solu-
tions where the least period is the forcing period divided by an integer are

180
6. Iterations and Perturbations
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
0
0.5
1
1.5
 
|A|
Figure 6.2. Frequency-response for hard springs, where β > 0. For the soft spring
where β < 0, the ﬁgure is reversed to the right. C > 0 is ﬁxed.
called higher harmonics, because their frequencies are integer multiples of
the base frequency.
Subharmonics can be found by using Duﬃng’s iterative method and a
suitable initial guess that picks them out. For example, let
x0 = a cos t
3 + A cos t
be our initial guess for the 1/3 harmonic of the equation
ω2 d2x
dt2 = −αx −βx3 + F cos t,
where ω is the forcing frequency. Our guess has a least period of 6π. Iter-
ating beginning with x0 and equating coeﬃcients of the iterate to those of
x0 give
a

α −ω2
9

+ 3β
4 (a3 + a2A + 2aA2)
=
0
A(α −ω2) + β
4 (a3 + 6a2A + 3A3)
=
F.
Let us consider this system in the linear case where β = 0. There are
nonzero solutions for a and A only if ω = √α or ω = 3√α. There are
nearby solutions of these equations if β is near zero and ω is near these two
values.

6.2. Duﬃng’s Equation
181
The important point here is that the linear problem gives the hint of
where to look for subharmonics in the space of all possible parameters (α, β,
and ω) appearing in the problems. If the forcing frequency is a rational
multiple of the free frequency of the linear problem, then we might expect
a comparable oscillation for the nonlinear problem. This may or may not
happen, but it usually gives a starting point.
6.2.6
Damped Duﬃng’s Equation
Now consider the equation
d2x
dt2 + rdx
dt + αx + βx3 = a cos ωt + b sin ωt,
where r > 0 is the damping coeﬃcient. Let us use Duﬃng’s method to
study this equation. We begin with an initial guess
x0 = A cos ωt
and deﬁne the iteration
d2x1
dt2 = −rdx0
dt −αx0 −βx3
0 + a cos ωt + b sin ωt.
Integrating this equation gives
x1(t) = (3βA3/4) + αA −a
ω2
cos ωt −b + ωAr
ω2
sin ωt + h.f.t.,
where h.f.t. denotes higher frequency terms. Setting this equal to the initial
guess gives
b
=
−Aωr
a
=
3βA3
4
+ αA −Aω2.
Let us rewrite the forcing term as an amplitude C and a phase lag φ,
where C2 = a2 + b2 and φ = −tan−1(b/a). With this, a cos ωt + b sin ωt =
C cos(ωt + φ), and
C2 = (ωAr)2 +
3βA3
4
+ (α −ω2)A
2
.
Now the cusp singularity is at C2−(ωAr)2. If r is small, the response shown
in Figure 6.3 is similar to that in Figure 6.2, with the important exception
that there is a unique small amplitude oscillation when |ω2 −a| ≫1.
Figure 6.3 explains some interesting physical behavior of electrical cir-
cuits [64]. If we begin with an oscillator with β > 0, α > ω2, then the
system oscillates with small amplitude when α−ω2 ≈4. As the forcing fre-
quency ω increases, the oscillation remains on the top branch until the fold
is reached. It then jumps to the lower branch, that is, to a small amplitude
oscillation. This kind of discontinuous behavior is observed in what appear

182
6. Iterations and Perturbations
−4
−3
−2
−1
0
1
2
3
4
0
0.5
1
1.5
2
2.5
 
|A|
Figure 6.3. Frequency-response for damped Duﬃng equation, in the hard spring.
For the soft spring the ﬁgure is reversed to the right.
to be very smooth systems. We say that there is a hysteretic response of
the system. For example, after this experiment establishes the oscillation
on the lower branch far to the left of the vertical axis, we can begin to
decrease ω. As we do this, the oscillation remains small in amplitude until
the lower fold is reached near the vertical axis, when the oscillation jumps
to higher amplitude.
6.2.7
Duﬃng’s Equation with Subresonant Forcing
The resonant forcing theorem applies as it did in Section 6.1.3 when we
replace εG by
g(t) + εF(t, x, ε),
where g is subresonant. This is illustrated here with a calculation using the
Modiﬁed Perturbation Method (See Section 6.1.4). Consider the equation
d2x
dx2 + µ2x = C cos t −ε(αx + βx3),
where µ ̸= ±1 is an integer. The forcing function cos t has period 2π, and
the two linearly independent solutions of the homogeneous equation
d2x
dt2 + µ2x = 0

6.2. Duﬃng’s Equation
183
also have period 2π, but the forcing is orthogonal to them.
The modiﬁed perturbation method gives a way to construct periodic so-
lutions of this equation. We introduce new variables λ and η and constraints
a and b as follows:
d2x
dt2 + µ2x = C cos t −ε(αx + βx3) + ελ cos µt + εη sin µt
(x, cos µt) = a
and
(x, sin µt) = b
x(t + 2π) = x(t)
for all t.
We successively diﬀerentiate this problem with respect to ε, a, and b, and so
derive a sequence of problems for expansion coeﬃcients (the subscripts here
denote diﬀerentiations and numbered subscripts denote diﬀerentiations
with respect to ε):
d2x0
dt2 + µ2x0 = C cos t
(x0, cos µt) = 0
and
(x0, sin µt) = 0
d2x1
dt2 + µ2x1 = −αx0 −βx3
0 + λ0 cos µt + η0 sin µt
(x1, cos µt) = 0
and
(x1, sin µt) = 0
d2xa
dt2 + µ2xa = 0
(xa, cos µt) = 1
and
(xa, sin µt) = 0
d2xb
dt2 + µ2xb = 0
(xb, cos µt) = 0
and
(xb, sin µt) = 1
d2xaε
dt2
+ µ2xaε = −(α + 3βx2
0)xa + λa cos µt + ηa sin µt
(xaε, cos µt) = 0
and
(xaε, sin µt) = 0
d2xbε
dt2
+ µ2xbε = −(α + 3βx2
0)xb + λb cos µt + ηb sin µt
(xbε, cos µt) = 0
and
(xbε, sin µt) = 0,
etc.

184
6. Iterations and Perturbations
The solution of the ﬁrst problem is
x0(t) = C cos t
(µ2 −1).
Note that λ0 is zero if µ ̸= 3, but otherwise it is not zero. The other
solutions are
η0 = 0
xa(t)
=
cos µt
xb(t)
=
sin µt
λa
=
α
π +
3βC2
2(µ2 −1)2
ηb
=
α
π +
3βC2
2(µ2 −1)2
λb
=
0
ηa
=
0,
etc.
We have enough here to demonstrate two important points. First, if µ = 3
and C ̸= 0(ε), then λ0 ̸= 0, and we have no hope of solving the bifurcation
equation
λ = 0
for small a, b, and ε. Therefore, the method does not produce a solution
because of interference of higher harmonics. Second, if µ = 3 and C = O(ε)
or if µ ̸= 3, then the Jacobian matrix of the bifurcation equations has
determinant
det∂(λ, η)
∂(a, b) =
α
π +
3βC2
2(µ2 −1)2
2
.
If this quantity is not zero, there are unique functions
a = a(ε)
and
b = b(ε)
that solve the bifurcation equations
λ(a, b, ε)
=
0
η(a, b, ε)
=
0,
and the resulting function x(t, a(ε), b(ε), ε) is a 2π-periodic solution of
Duﬃng’s equation.
6.2.8
Computer Simulation of Duﬃng’s Equation
The behavior described in Figure 6.3 can be illustrated by direct computa-
tion of the solutions to Duﬃng’s equation. Figure 6.4 depicts a portion of

6.2. Duﬃng’s Equation
185
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
1
0.8
0.6
0.4
0.2
0
−.2
−.4
−.6
−.8
−1
Figure 6.4. Fifty iterations of each of 6 initial points along the ˙x = 0 axis. This
shows one small stable response for 0.5¨x + 0.01 ˙x + x −x3 = 0.04 cos t.
the phase plane for (free) Duﬃng’s equation. The center is surrounded by
a continuum of periodic orbits that extend to the separatrices that join the
two saddle points. Plotted are values {(x(2πn), y(2πn))} (where y = x′)
for many choices of n and for many choices of initial conditions x(0), y(0).
Shown in Figure 6.5 is Poincar´e’s mapping for a damped equation that
is externally forced:
0.81d2x
dt2 + 0.05dx
dt + x −x3 = cos t.
This plot is obtained by selecting an initial point, say x(0) = ξ, dx/dt(0) =
η, solving the equation, and plotting the solution point each time t hits an
integer multiple of 2π. The plot is generated by repeating this simulation
for many initial points.
We found here a unique stable periodic solution of period 2π. In Fig-
ure 6.6 we solve the same equation but with weaker damping. In this case
we see two stable periodic solutions, one corresponding to each of the top
and bottom branches in Figure 6.3.
The basins of attraction of these two oscillations are separated by a
fractal curve that is in some sense random. To understand this, we turn to
a discussion in Section 6.3 of fractal curves and chaotic behavior.

186
6. Iterations and Perturbations
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
1
0.8
0.6
0.4
0.2
0
−.2
−.4
−.6
−.8
−1
Figure 6.5. Two stable responses: 0.6¨x + 0.01 ˙x + x −x3 = 0.04 cos t.
6.3
Boundaries of Basins of Attraction
When two stable modes of oscillation coexist, as in the cases shown in Fig-
ures 6.3 and 6.5, where the response curve has doubled back on itself, there
comes an important question. Given an initial point, what will happen to
its solution? There are three possibilities: The solution can approach one
of the two stable oscillations or it can remain on a boundary separating
their basins of attraction. This can be important in meeting design speci-
ﬁcations and in determining stability of a designed system. Unfortunately,
the boundary between two basins of attraction can be quite complicated.
In particular, there can be exquisitely sensitive dependence of solutions on
their initial positions. This fact was known to Poincar´e and others in the
last century, and a number of researchers since then have studied aspects
of this phenomenon. It is closely related to the chaotic behavior described
in Chapter 2.
Newton’s method gives an excellent starting point for a discussion of
basins of attraction. It can exhibit multiple coexisting static states and
complicated boundaries separating their basins of attraction. Next, some
computer simulations are used to illustrate chaotic behavior in Duﬃng’s
and van der Pol’s oscillators. The boundaries between basins of attraction
can be very complicated, and our discussion of fractals provides some in-

6.3. Boundaries of Basins of Attraction
187
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
1
0.8
0.6
0.4
0.2
0
−.2
−.4
−.6
−.8
−1
Figure 6.6. One large, stable response: 0.9¨x + 0.01 ˙x + x −x3 = 0.04 cos t.
sight into such structures. Finally, a computer simulation to estimate the
nature of the boundary in speciﬁc cases is described.
6.3.1
Newton’s Method and Chaos
Newton’s method gives us one of the best available algorithms for ﬁnding
the zeros of a function. It is a recursive scheme whose iterates move in the
space in which solutions lie. It also presents an interesting introduction to
chaos.
Recall that if f(x) is a smooth real-valued function, and if we seek the
values of x for which f(x) = 0, then we can proceed by successive linear
extrapolations. Let us make an initial guess, say x0, and deﬁne a sequence
of approximations {xn} by the algorithm
xn+1 = xn −f(xn)
f ′(xn)
as long as this makes sense. This formula deﬁnes Newton’s method. If
f ′(x∗) ̸= 0, where x∗is the zero near x0, then this sequence will converge
to x∗, and it will usually do so at a quadratic rate. Thus, quite rapid
convergence results when the method works.
Sarkovski studied what happens when the condition f ′(x∗) ̸= 0 is not
satisﬁed [126]. He derived the following interesting results, which were de-

188
6. Iterations and Perturbations
scribed in Section 2.5.1. A computer simulation was designed and carried
out [76] to ﬁnd the zero of the function
f(x) =
|x −r + 1|
x
1/(r−1)
,
where r > 1. This function has a discontinuous derivative at its zero x =
r −1 (i.e., f(r −1) = 0). If we derive Newton’s algorithm for this, we get
for 1 < r ≤4
xn+1 = rxn(1 −xn).
For these values the sequence of iterates lies in the unit interval 0 ≤x ≤1,
which we studied in Section 2.5.1.
6.3.2
Computer Examples
The one-dimensional mappings do not elucidate the basin-of-attraction
boundary problem, but three other examples are presented here to do this.
Consider a mapping of the plane E2 into itself,
F : x = (x, y) →(f(x, y), g(x, y)) = F(x).
Suppose that F has two ﬁxed points, say F(a) = a and F(b) = b. Fur-
thermore, suppose that each of these ﬁxed points is stable. We deﬁne the
basins of attraction of these points to be
B(a) = (x ∈E2 : F n(x) →a as n →∞),
where F n(x) = F(F n−1(x)). We deﬁne B(b) similarly.
The boundary between these two sets might be simple or very compli-
cated. A question of interest is, given a point in E2, does it lie in B(a) or
in B(b)? Points that lie away from the boundary are decidable, but those
that lie on it are not. The following examples illustrate several interesting
facts.
The Roots of z3 −1.
First, let us consider iterates of Newton’s method for the complex valued
function f(z) = z3 −1. There are three zeros of this function, one at each
of the three cubic roots of unity: z = 1, z = −1/2 ± i
√
3/2. Iterates of
this mapping were studied by Fatou, Julia, and Kinney and Pitcher among
many others. It is known that the three domains of attraction, one each
for the three roots, are hopelessly intertwined. In fact, at any point that
bounds any two of these domains there are points of the third domain
arbitrarily close by. The set bounding these three basins of attraction is
now referred to as a Julia set (see Figure 6.7) [36, 93, 107].
Duﬃng’s Equation.
Figure 6.5 shows a case where there is a unique periodic response. In
Figure 6.6 two stable responses coexist. The two basins of attraction in

6.3. Boundaries of Basins of Attraction
189
−1.6
0
2
1.6
0
−2
Figure 6.7. Julia set for the basins of attraction of the third roots of unity using
Newton’s method to solve z3−1 = 0. Each of the three shaded regions is attracted
to one of the roots. The Julia set is in black. These are points on the boundaries
of the three basins of attraction. The real axis points down here. z = 1 is at the
bottom center of this ﬁgure.
this case are separated by a complicated curve. We return later to ﬁnding
out how complicated this curve can be.
van der Pol’s Equation.
van der Pol’s equation has the form
˙x + k(x3/3 −x) + y
=
0
˙y
=
x −B cos t.
If k is large and B = kA, then all of the responses lie in an annulus enclosing
the knee-shaped curve y = k(x −x3/3), |x| ≤
√
3 in Figure 6.8 [132, 98].
The solutions can be described in part by how many times they proceed
around the origin for each oscillation of the forcing function. This measures
the output frequency relative to the input frequency. The resulting ratio is
called the rotation number, and its calculation [38] is shown in Figure 6.9.
We see here that there are overlapping sets where two stable periodic
solutions having diﬀerent periods coexist. Since these two solutions lie in
the annulus described above, their domains of attraction must be very
mixed up (see [64])!

190
6. Iterations and Perturbations
 x
 y
 dx/dt = 0
Figure 6.8. Phase portrait of a forced van der Pol equation.
6.3.3
Fractal Measures
These examples show that quite complicated basin boundaries can occur
in simple problems. It is therefore of some interest to understand “very
wrinkled” curves. Figure 6.10 describes the construction of a sequence of
curves that have common endpoints but become successively more complex;
in particular, they become longer even though they keep a recognizable
shape.
In four steps the curve becomes quite complicated, and as the process
continues, we rapidly lose track of it. We can view each step of this process
as a measurement. For example, at ﬁrst, we use a rod of length 1; second,
one of length 1/4, and so on. Obviously, the process results in some limiting
set, but the lengths of the approximating curves increase without bound.
Apparently, this problem was observed by cartographers trying to measure
the length of England’s coastline (see [107]).
We are interested in how the length of the approximating curve changes
with the length of the measure used. For example, if L(ε) denotes the length
of the approximating line that is based on using a measure ε, then for the
example in Figure 6.10, the length doubles when the measure is quartered:
L(ε/4) = 2L(ε).
This gives a recursion formula between the lengths using diﬀerent measures.
We can solve this recursion using the z transform; that is, we set L(ε) = εα.
Solving for α in the result gives
α = −log 2
log 4 = −1
2.

6.3. Boundaries of Basins of Attraction
191
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxx
xxx
xxx
xxx
xxx
xxx
xxx
xxx
xxx
xx
xx
xx
xx
xxxxx
xxxxx
xxxxx
xxxxx
xxxxx
1/3
1/2
1/5
1/7
5/9
2/3
3/5
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
B
0.01
0.05
0.1
0.15
ε
1/9
1/13
Figure 6.9. Rotation number for van der Pol’s equation (redrawn from [38]).
A trivial example is where we successively partition a straight-line seg-
ment. In this case, the length of the line remains constant no matter what
value of ε we take. For example,
L(ε/2) = 1
for all ε. Thus, α = 0 for a straight-line fractal. However, our intuition is
that a straight-line segment should have dimension 1, so we deﬁne
dc = 1 −α.
Thus, for the straight-line fractal dc = 1, and for the curve in Figure 6.10
dc = 3/2. The notation dc is used to indicate that we have computed
the Kolmogorov capacity of the curve [110]. Figure 6.11 shows some other
examples.
6.3.4
Simulation of Fractal Curves
Now, suppose that two sets A and B make up a set whose area is 1.
Moreover, suppose that these two sets are separated by a fractal curve
having dimension dc.

192
6. Iterations and Perturbations
A
B
L   = 1 
= 1 
ε
A
B
L =
   = 8 / 4 = 2 
= 1 / 4 
ε
A
B
L =
   = 64 / 16 = 4 
= 1 / 16 
ε
A
B
L =
   = 256 / 64 = 16 
= 1 / 64 
ε
Figure 6.10. Complicated basin boundaries. L denotes the length of the curve.
At each step the linear segments are split into four equal parts and rearranged.
ε is the length of the measuring rod at each step.
We now perform calculation in which we place a point in this set and
observe whether it lies in A or B. We suppose that our placement of the
point is accurate only to within some tolerance, say δ. Therefore, our ex-
periment corresponds to placing a disk of radius δ on the diagram. We say
that the experiment is undecidable if the disk intersects the boundary of
A or the boundary of B, and so the relevant thing here is the area of a
δ-neighborhood of the boundaries of these two sets. This area should be the
length of the boundary of A plus the length of the boundary of B multi-
plied by δ. However, a fractal boundary has inﬁnite length. Let L(δ) denote
the length of the common boundary of the two sets using a measuring rod
of length δ. Then the area covered by this approximation is proportional
to
L(δ)δ = δ1+α = δ2−dc.

6.3. Boundaries of Basins of Attraction
193
1. Cantor`s middle thirds set:
     =  log 2 / log 3
d c
2.
     =  log 5 / log 3
d c
3. Peano`s curve
     =  log 9 / log 3 = 2
d c
A
B
A
B
Figure 6.11. Capacities of various fractal curves.
For example, if δ = 1.0 × 10−10 and dc = 1.9, then the area of this “ﬂat-
tened” boundary is comparable to 0.1. Thus, ten orders of magnitude of
precision are lost [35].
Fractals in Higher Dimensions.
Kolmogorov’s capacity is easy to deﬁne for sets in an arbitrary Euclidean
space. Consider a bounded set, say S, in EM. Given a number ε, let N(ε)
denote the number of nonoverlapping (M-dimensional) cubes needed to
cover S. Deﬁne
dc = lim
ε→0+
log N(ε)
log 1/ε .
This limit need not exist, but when it does, this is called the fractal
dimension of S.
Note that for small values of ε
log N(ε) ≈dc log(1/ε).
This suggests a method for approximating dc for a given curve C. Fix ε,
approximate C using measures of length ε, determine N(ε),and plot the
values of N and 1/ε on log–log coordinates. Doing this for several values
of ε gives a straight line whose slope is dc.
Hausdorﬀdeﬁned a measure of complicated sets [117]. Let a set S in E2
be covered by a collection of disks, say Di, which have radii εi, respectively.
We deﬁne a number
∆(d) =
inf
partitions

i
εd
i ,
where the inﬁmum is taken over all possible coverings of S by disks having
radii εi. Hausdorﬀshowed that ∆= ∞when d is large, and ∆= 0 when
d is small. There is a unique value of d for which 0 < ∆(d) < ∞. This
value of d, say dH, is called the Hausdorﬀdimension of S. It is clear that

194
6. Iterations and Perturbations











J
J
J
J
J
J
J
J
J
J
J
J
J
J
J
JJ

















J
J
J
J
J
J
J
J
J
J
J
J
J
J
J
JJ






J
JJ



J
JJ



J
JJ



Figure 6.12. Construction of the Triangle Fractal.
dc ≥dH for any set, since dc is obtained by using a special covering of S.
(See [35] for a further discussion of these topics.)
6.4
Exercises
6.1.
Show that (Lx, y) = (x, Ly) when Lx = x′′ + µ2x, x(t) and y(t)
are functions whose second derivatives are square integrable and the
notation (f, g) is the inner product notation deﬁned in Section 6.1.
Compare this result with the analogous calculation for matrices: De-
termine for which N × N matrices A we have Ax · y = x · Ay for all
N-vectors x and y.
6.2.
Verify that the amplitude A of successive iterates in Duﬃng’s method
solves
3βA3
4
+ (α −µ)A −C = 0
as in Section 6.2.2.
6.3.
Reproduce Poincar´e’s mapping for Duﬃng’s equation in Figures 6.4,
6.5, and 6.6, using computer simulations.
6.4.
Construct the triangle fractal.
On the left in Figure 6.12 is an equilateral triangle of altitude 1.
Begin with the inscribed triangle on the left. What is its length? Next,
inscribe three triangles in the residual space as shown on the right.
What is the total length of the edges of the four inscribed triangles?
Continue this process. What is the capacity dc of the limit set?

7
Methods of Averaging
Regular perturbation methods are based on Taylor’s formula and on im-
plicit function theorems. However, there are many problems to which
Taylor’s formula cannot be applied directly. In these cases perturba-
tion methods based on multiple time or space scales can often be used,
sometimes even for chaotic systems.
Relatively fast and slow scales can occur in many ways. For example,
suppose that A is a 4 × 4 matrix having eigenvalues
λ1 = ρ + iω,
λ2 = ρ −iω,
λ3 = µ,
λ4 = η,
where |ρ| ≪ω and η ≪µ < 0. The spectral decomposition of A is (see
Section 1.2.1)
A =
4

j=1
λjPj,
where Pj, are projection matrices satisfying the conditions
PjPk = 0
if j ̸= k and P 2
k = Pk.
The solution of the initial value problem
dx
dt = Ax,
x(0) is given
can be derived using this notation:
x(t) =
4

j=1
eλjtPjx(0).

196
7. Methods of Averaging
 ρ+  ω
 µ
 η
i
 ρ−  ω
i
Figure 7.1. Spectrum of A with ρ < 0.
The ﬁrst two terms in this sum are modulated at a slower rate than they
oscillate, since their ampliﬁcation rate ρ is smaller than their frequency ω.
The third term is slowly modulated relative to the fourth, which decays
rapidly to zero, since η ≪µ. If we write ε = ρ/ω, then ε ≪1 and the ﬁrst
two terms can be written as
eω(ε+i)tP1x(0) + eω(ε−i)tP2x(0).
We could say that these modes vary on two time scales: ωt (oscillation)
and a slower one, εωt (modulation).
Similarly, setting ε′ = µ/η we can write the last two terms as
e(µt)P3x(0) + e(µt/ε′)P4x(0).
This is a sum of transients that decay on two time scales: µt and a faster
one, µt/ε′.
Plotting the eigenvalues of A can suggest what scales govern the so-
lution’s behavior, as shown in Figure 7.1. Eigenvalues lying near the
imaginary axis give rise to slowly modulated oscillations; eigenvalues ly-
ing near the origin correspond to quasistatic modes; and other eigenvalues
lying near the real axis describe rapidly growing or decaying modes.
This example shows that small parameters can appear in linear systems
as ratios of eigenvalues, and so the system’s solution can include various
scales. There are important implications of this for numerical methods,
since stability and accuracy of numerical schemes depend on step sizes
being appropriate to changes in solutions. Although eigenvalues can be
used to discover various scales in linear problems, they are often diﬃcult
to determine, and there is no reliable method for ﬁnding their analogues
in nonlinear problems. In fact, nonlinear problems typically involve scales

7. Methods of Averaging
197
that change with the system’s state. Some aspects o f this are studied here
and in Chapter 8.
In this chapter we study highly oscillatory problems, and in the next we
study problems with rapid transients. Highly oscillatory systems are studied
using averaging methods; we ﬁrst state and prove a general averaging result
that is used throughout this chapter. The ideas developed here are similar to
those of stability under persistent disturbances(Chapter 3), but in addition
they provide methods for constructing precise approximations to solutions.
A useful approximation shortcut that is based on a multiscale expansion
formalism is also developed in Section 7.1.
The general theory is later specialized and applied to a variety of prob-
lems. First, linear problems are studied in detail in Section 7.2, especially
certain linear feedback problems where detailed computations can be car-
ried out. In Section 7.3 the multiscale methodology is revised and applied
to nearly linear diﬀerence equations. We study a variety of iterations using
those results.
Weakly nonlinear problems are studied in Section 7.4; in particular, we
revisit van der Pol’s and Duﬃng’s equations as well as more general systems
of weakly coupled harmonic oscillators. Special cases of these are problems
for (angular) phase variables. In Section 7.5 three separate approaches to
phase-amplitude systems are derived: the rotation vector method (RVM),
Bogoliubov’s near-identity transformation for diﬀerential equations on a
torus, and the Kolmogorov–Arnol’d–Moser (KAM) theory for quasiperiodic
solutions. Section 7.6 describes how microscopic spatial structure can be
used to derive macroscopic properties of ﬁne periodic structures in space.
This is the method of homogenization. Computational methods that are
based on averaging are described in Section 7.7. Bogoliubov also developed
averaging methods for dynamical systems that are perturbed by random
noise. The chapter ends with a brief discussion of averaging in systems
perturbed by random processes.
Averaging nonlinear conservative systems can be delicate because small
divisors can occur. These arise through nonlinear feedbacks that create
internal resonances. Many important techniques have been developed to
deal with small divisors, culminating (to date) in the RVM and the KAM
theories. These theories show how to deal with oscillatory problems in
which there is no dissipation. When dissipation is present in a system,
the theorem on nonlinear averaging for mean-stable systems is used to
construct solutions.
Problems encountered in highly oscillatory systems are already appar-
ent in linear systems. The following example is quite useful. Consider the
diﬀerential equation
dx
dt = U −1(t)BU(t)x,

198
7. Methods of Averaging
where x is in E2, U is the rotation matrix
U(t) =

cos ωt
−sin ωt
sin ωt
cos ωt

,
and
B =

a
b
c
d

.
This system was studied in Section 1.4. The change of variables y = Ux
takes this system into
dy
dt = (B + ωJ)y,
where J is Jacobi’s matrix
J =

0
−1
1
0

.
The matrix U rotates a vector through an angle ωt, so we refer to the system
for x as being the result of spinning the system for y. The eigenvalues of
this system are given by the solutions of the equation
λ2 −(a + d)λ + ad −bc + ω(c −b) + ω2 = 0.
We consider three interesting examples:
Example 1. Spinning Can Destabilize a Stable Linear System.
Let
B =

−1
b
0
−2

.
Then the eigenvalues of U −1AU are −1 and −2, but the eigenvalues of
B + ωJ are
λ = −3 ±
√
1 + 4bω −4ω2
2
.
The neutral stability condition for this system (viz., Re λ = 0) occurs when
the real part of the eigenvalues are zero: This happens when 4bω−4ω2 = 8.
Therefore, there are two regions, S and U, in the plane such that if (ω, b)
is in S, then y = 0 is a stable spiral node. If (ω, b) is in U, then it is an
unstable node! Thus, spinning the system 4ω(b −ω) > 8 can destabilize
it. W. A. Coppel [27] showed that in general, slow oscillations (|ω| ≪1)
cannot destabilize the system if the eigenvalues of A have negative real
parts.
Example 2. Spinning Can Stabilize a Hyperbolic System. Let
B =
 0
1
1
0

.

7.1. Averaging Nonlinear Systems
199
The eigenvalues of this matrix are ±1, but the eigenvalues of B + ωJ are
±

(1 −ω2). Therefore, if |ω| < 1, then y = 0, and hence x = 0, is a
hyperbolic point (i.e., it is conditionally stable), but if ω2 > 1, it is a stable
node. Thus, spinning can stabilize an unstable node.
Example 3. Rapid Spinning Averages the System. Finally, let us
expand U −1(t)BU(t) in its Fourier series:
U −1(t)BU(t) = B0 + h.f.t.,
where h.f.t. denotes higher frequency terms. In this case, the matrix B0 is
B0 =



a + d
2
−c −b
2
c −b
2
a + d
2


,
whose eigenvalues are λ±
0 = (a + d ± (c −b)i)/2.
The system for x is periodic in t, and so Floquet’s theory, which shows
that such a system can be transformed into a system with constant coeﬃ-
cients, leads to the matrix R of Section 1.4; in this case, R = B + ωJ. The
eigenvalues of B + ωJ for large ω are given by the formulas
λ± = ±iω + (a + d) ± i(c −b)
2
+ O
 1
ω

.
Recall that Floquet’s Theorem states that a fundamental matrix for the
system for x is P(t) exp(Rt). In this case it is
U(t) exp((B + ωJ)t) ≈U(t)eB0t.
In summary, we have seen in these examples that spinning can destabilize
a stable system, and it can stabilize an unstable system. Finally, we have
seen that the average of a highly oscillatory system is closely related (by
Floquet’s theory) to the full problem. We investigate this connection next,
but in a more general setting.
7.1
Averaging Nonlinear Systems
Consider the system of diﬀerential equations
dx
dt = εf(t, εt, x, ε)
or its slow-time equivalent,
dx
dτ = f
τ
ε , τ, x, ε

,

200
7. Methods of Averaging
where x, f ∈EN, ε is a small real parameter, say |ε| ≪1, and the slow
time variable τ = εt is restricted to some ﬁnite interval 0 ≤εt ≤T < ∞.
Suppose the following hypothesis is true.
Hypothesis H1. f(t, τ, x, ε) is a smooth function of its arguments for
0 ≤t ≤T/ε, 0 ≤τ ≤T, for x in some domain G lying in EN, and for
ε near zero. Moreover, suppose that f is an almost periodic function of
t, uniformly in the other variables. Speciﬁcally, we assume that f can be
expanded in a uniformly convergent generalized Fourier series
f(t, τ, x, ε) = f0(τ, x, ε) +
∞

n=1
fn(τ, x, ε)eiωnt
where the frequencies ωn satisfy 0 < ω1 < ω2 < · · · .
The smooth functions fn are the amplitudes of the various modes of rapid
oscillation of f relative to t. When convenient, we write ω0 = 0.
Functions of this kind can be indistinguishable from chaotic ones in prac-
tice, but there are ﬁne points of distinction between chaotic functions, say
ones that have a power spectrum supported by an interval of frequencies,
and functions that have a convergent generalized Fourier expansion. In
particular, we can average the latter functions to good use.
If we attempt to average f with respect to t, we must evaluate the limit
⟨f⟩(τ, x, ε) ≡lim
T →∞
1
T
 T
0
∞

n=0
fneiωntdt = f0(τ, x, ε).
Thus, f0 is the mean value of f with respect to t, provided that the series of
integrals converges. Unfortunately, the series appearing here need not con-
verge. For example, if fn = n−2 and ωn = 2−n, then although the series can
be integrated termwise, the small numbers ωn appear in the denominators
of the integral, and the resulting series does not converge. This illustrates
the small divisor problem that is discussed further in Section 7.5.
7.1.1
The Nonlinear Averaging Theorem
The next condition ensures that the average of f exists.
Hypothesis H2. Let g = f −f0, and suppose that the integral
 t
0
g(t′, τ, x, 0)dt′ =
 t
0
[f(t′, τ, x, 0) −f0(τ, x, 0)]dt′
is bounded uniformly for 0 ≤t ≤T/ε (and so for 0 ≤τ ≤T) and for
x ∈G.
This condition is not the “best possible” one, but it suﬃces for our
purposes here and it is comparable to mixing conditions that arise naturally
in systems perturbed by random noise (see Section 7.8). Condition H2

7.1. Averaging Nonlinear Systems
201
is usually satisﬁed, although it can be diﬃcult to verify in applications.
However, if f is a periodic function of t or if it is a ﬁnite trigonometric
polynomial in t, then this condition is satisﬁed. On the other hand, as we
have seen, if the Fourier series for f is suﬃciently lacunary, say ωn = 2−n,
then this condition might not be satisﬁed. More general conditions for
averaging nonlinear problems are given in [58, 77].
We have the following theorem:
Nonlinear Averaging Theorem. Suppose that conditions H1 and H2
are satisﬁed, and suppose that the averaged system
dX
dτ = f0(τ, X, 0),
X(0) = η
(7.1)
has a unique solution lying in G for 0 ≤τ ≤T. If ε0 is suﬃciently small
and if |ε| ≤ε0, then:
1. There is a unique solution of the problem
dx
dt = εf(t, εt, x, ε),
x(0) = η
(7.2)
for 0 ≤t ≤T/ε.
2. The solution lies in G.
3. There is a constant K depending on T and ε0 such that
|x(t) −X(εt)| ≤K|ε|
for 0 ≤t ≤T/ε.
This result shows that the solution of the averaged equation (7.1) ap-
proximates the solution of the full problem (7.2) having the same initial
data over large (growing) intervals, 0 ≤t ≤T/ε.
Proof of the Nonlinear Averaging Theorem. The theorem is proved in a
more general setting in [77]. The proof here follows from a straightforward
application of Gronwall’s inequality.
Let z = x(t, ε) −X(εt). This function satisﬁes the initial value problem
dz
dt
=
εf(t, εt, z + X, ε) −εf0(εt, X, 0)
=
ε[fx(t, εt, X, 0)z + f(t, εt, X, 0)
−f0(εt, X, 0) + O(ε) + O(|z|2)]
z(0)
=
0,
where fx denotes the Jacobian matrix of the components of f with respect
to the components of x.

202
7. Methods of Averaging
First, we deﬁne the linear problem’s fundamental solution to be U(t, s),
which can be determined from the diﬀerential equation
dU
dt = εfx(t, εt, X(εt), 0)U,
U(s, s) = I.
Using this, we can convert the initial value problem for x into an equivalent
integral equation for z:
z(t) = ε
 t
0
U(t, s)(f(s, εs, X(εs), 0) −f0(εs, X(εs), 0) + O(ε) + O(|z|2))ds.
Let us deﬁne g(s) = f(s, εs, X(εs), 0) −f0(εs, X(εs), 0) and integrate this
formula once by parts. The result is
ε
 t
0
U(t, s)g(s)ds = εU(t, s)
 s
0
g(s′)ds′
&&&&
t
0
−ε
 t
0
dU
dt
 s
0
g(s′)ds′.
This shows that
ε
 t
0
U(t, s)g(s)ds = ε
 t
0
g(s)ds −ε2
 t
0
fxU(t, s)
 x
0
g(s′)ds′.
It follows from condition H2 that for 0 ≤t ≤T/ε, this integral is bounded
by K1ε, where K1 is a constant that depends on ε0 and T. Therefore,
|z(t)| ≤O(ε) + ε
 t
0
|U(t, s)|O(|z|2)ds.
It follows from Gronwall’s inequality (see Section 3.2.1) that |z(t)| = O(ε)
uniformly for 0 ≤t ≤T/ε.
7.1.2
Averaging Theorem for Mean-Stable Systems
Now suppose that T = ∞in conditions H1 and H2. Adding a stability
condition can justify an approximation that is valid on the entire half-line
0 ≤t < ∞. We say that the system is mean stable if condition H3 is true:
Hypothesis H3. The averaged equation
dX
dτ = f0(τ, X, 0)
has a rest point, say X∗, that is exponentially asymptotically stable.
With this additional condition, we have the following theorem.
Averaging Theorem for Mean-Stable Systems. Let f satisfy con-
ditions H1, H2, and H3. Let X denote the solution of the initial value
problem
dX
dτ = f0(τ, X, 0),
X(0) = η

7.1. Averaging Nonlinear Systems
203
for 0 ≤τ < ∞. If η is near X∗and if ε > 0 is suﬃciently small, then the
problem
dx
dt = εf(t, εt, x, ε),
x(0) = η
has a unique solution for 0 ≤t < ∞, and
x(t, ε) = X(εt) + O(ε),
where the error estimate here holds as ε →0+ uniformly for 0 ≤t < ∞.
This result is quite strong, since it gives a valid approximation of the
system’s solution over the entire half-line t ≥0. The stability condition H3
required for the result is quite restrictive, but it can be relaxed somewhat
to stability under persistent disturbances or uniform asymptotic stability
[15]. Note that the sign of ε must be positive in this result to ensure that the
stability estimates hold for t →∞. This result also highlights the duality
between τ →∞and ε →0. The solution can be written as x(τ/ε, ε) =
X(τ) + O(ε), which decomposes x into two components, the behavior as
τ →∞and the behavior as ε →0.
Proof of the Mean Stable Averaging Theorem. The proof of this result
proceeds exactly like that of the last section except that we must extend
the estimate to the entire line t ≥0. First, note that condition H3 ensures
that the fundamental solution U(t, s) satisﬁes an estimate of the form
|U(t, s)| ≤Ke−α(t−s)
for 0 ≤s ≤t < ∞and for some positive constants K and α. Then, we
deﬁne u(t) = |z(t)|eαt as we did in using Gronwall’s Lemma to prove the
linear stability theorem in Section 3.2. It follows that u(t) increases at most
like a slow exponential function if ε is suﬃciently small. Therefore, |z(t)|
decays at an exponential rate with amplitude at most O(ε).
7.1.3
A Two-Time Scale Method for the Full Problem
Based on the last two theorems, we observe that two time scales (t and εt)
appear in the solutions, and it is useful to exploit this fact. To do this, we
write a solution of this equation as
x = u(t, τ, ε),
where t and τ = εt are treated as independent variables (when convenient).
Keep in mind that this guess for the form of a solution must be validated
a posteriori. We suppose that u is a smooth function of ε, so that
u(t, τ, ε) = u0(t, τ) + εu1(t, τ) + ε2u2(t, τ) + · · · ,

204
7. Methods of Averaging
where the coeﬃcients are assumed to be bounded functions for 0 ≤t, τ < ∞
to ensure that this expansion makes sense as ε →0. The problem becomes
∂u
∂t + ε∂u
∂τ = εf(t, τ, u, ε).
We hope that the dependence of x on the two time scales t and τ is correctly
accounted for by this, and we proceed to construct Taylor’s expansion for
u by successively diﬀerentiating the equation with respect to ε:
∂u0
∂t
=
0
∂u1
∂t
=
f(t, τ, u0, 0) −∂u0
∂τ , . . . .
The ﬁrst equation implies that u0 does not depend on t, so we write
u0 = U0(τ).
The second equation can be integrated, and its solution is
u1(t, τ) = U1(τ) +
 t
0
f(t′, τ, U0(τ), 0)dt′ −tdU0
dτ ,
where U1 is an unknown function. Since u1 is to be bounded, we divide
both sides by t and pass to the limit t = ∞. The result is
dU0
dτ
= lim
t→∞
1
t
 t
0
f(t′, τ, U0(τ), 0)dt′ = f0(τ, U0(τ), 0).
The process can be continued to determine more coeﬃcients in the expan-
sion of u. At least we see that U0(τ) = X(τ) as we determined in the
nonlinear averaging theorem.
It is perhaps questionable that we can average over the t variable while
holding the τ variable ﬁxed. Still, the results of this nonrigorous calculation
agree with those in the averaging theorems just proved, and so they produce
the correct equations when the conditions of those theorems are satisﬁed.
The two-time scale scheme provides a good probe to use in studying novel
problems, as we will see in studies of diﬀerence equations in Section 7.3 and
in homogenization problems in Section 7.6.
7.2
Highly Oscillatory Linear Systems
It is useful to go through the steps of the two averaging theorems for linear
systems.

7.2. Highly Oscillatory Linear Systems
205
7.2.1
dx/dt = εB(t)x
Systems of the form
dx
dt = εB(t)x,
x(0, ε) given,
where ε is a small parameter and B(t) is a matrix of smooth quasiperiodic
functions, say ones having uniformly convergent generalized Fourier expan-
sions, are diﬃcult to solve in general. Even if B is a matrix of constants,
calculating values of the exponential eεBt can pose serious computational
challenges [114], and if B(t) is periodic, determination of Floquet’s matrix
(R) is usually diﬃcult. Still, systems in this form are quite useful, and we
study next how they can be analyzed using the method of averaging.
Let us ﬁrst rewrite the equation as
dx
dt = εB0x + ε(B(t) −B0)x,
where B0 denotes the average of B(t):
B0 = lim
T →∞
1
T
 T
0
B(t′)dt′.
Thus, B0 is made up of all of the constant terms in B(t). Note that if B(t)
is a matrix of functions that are 2π-periodic in t, then
B0 = 1
2π
 2π
0
B(t)dt.
The averaged equation is
dX
dt = εB0X,
and its solution is
X(εt) = eεB0tX0.
There are three cases, depending on over what interval we are interested
in approximating. These are summarized in the following theorem:
Averaging Theorem for Linear Systems.
1. 0 ≤t ≤T (< ∞). On this interval,
x(t, ε) = x(0, 0) + O(ε),
where the error estimates hold as ε →0 uniformly for t ∈[0, T].
2. 0 ≤t ≤T/ε. In this case,
x(t, ε) = exp(εB0t)x0 + O(ε),

206
7. Methods of Averaging
where the error estimate holds uniformly for 0 ≤t ≤T/ε. Therefore,
we have that
x(t, ε) = X(tε) + O(ε).
3. 0 ≤t < ∞. Suppose that there are positive constants K and α such
that
|eεB0t| ≤Ke−αεt
for 0 ≤t < ∞. Then x(t, ε) = X(tε)+O(ε), where the error estimate
holds as ε →0+ uniformly in t, 0 ≤t < ∞. (For example, if all
eigenvalues of B0 have negative real parts, then the averaged equation
gives an approximation to x that is accurate for all t.)
These results follow from direct applications of the nonlinear averaging
theorems to the linear problem. The ﬁrst of these three cases is not very
interesting, since no inﬂuence of B is felt to the order of accuracy O(ε) for
0 ≤t ≤T. However, the other two cases are of great interest.
7.2.2
Linear Feedback System
A linear feedback system of the form
dx
dt = (A + εC)x,
where A is an oscillatory matrix (i.e., A is a diagonalizable matrix having
purely imaginary eigenvalues ±iωj), can be analyzed using the averaging
theorems. We spin the system as before: Let
x = exp(At)y.
Then
dy
dt = εe−AtCeAty,
where now the coeﬃcient matrix is a linear combination of oscillatory
functions that can be found using the spectral decomposition of A.
In fact, if A has the form
A =
2N

j=1
iωjPj,
we can calculate B0 directly. Since
B(t) = e−AtCeAt

7.3. Averaging Rapidly Oscillating Diﬀerence Equations
207
is a matrix of trigonometric polynomials, we know that B0 exists, and it is
given by the formula
B0 =

ωj=ωk
PjCPk,
where the sum is taken over all indices j and k for which ωj = ωk.
7.2.3
Averaging and Laplace’s Method
Laplace studied highly oscillatory integrals, and he derived various
asymptotic expansions for them. A particular example was described in
Section 5.1.4. In general, Laplace’s methods are based on the method of
steepest descent, but they take a simpler form in the case we considered in
the last section, where
dy
dτ = e−Aτ/εCeAτ/εy.
Integrating this equation gives an equivalent integral equation for y(τ):
y(τ)
=
y(0) +
 τ
0
e−As/εCeAs/εy(s)ds
=
y(0) + B0
 τ
0
y(s)ds
+
 τ
0
(e−As/εCeAs/ε −B0)y(s)ds.
Integrating the last integral once by parts and using the conditions of the
previous section shows that it is O(ε). In fact, Laplace’s method reduces
to the Riemann–Lebesgue Lemma [125] in this case, since the only terms
surviving in the last integral are those that are oscillatory functions of
s/ε multiplied by y(s). The Riemann–Lebesgue Lemma shows that such
integrals approach zero as ε →0.
7.3
Averaging Rapidly Oscillating Diﬀerence
Equations
The two-time scale formalism can be very useful in studying problems that
fall outside the usual diﬀerential equations systems considered up to this
point. For example, consider the diﬀerence equation
xn+1 = xn + εf(n, xn, ε),
where x, f ∈EN. Given x0, this recursion deﬁnes a unique sequence {xn},
which we refer to as being a solution of the recursion. The question asked

208
7. Methods of Averaging
here is: Can we construct an approximate solution that is valid when |ε| ≪
1?
We can begin to answer this question by using multiple time scales. We
observe that if f is a function of x only, then this recursion is trying hard
to be a diﬀerential equation. In fact, if X(s) is a smooth function such that
X(nε) = xn, then the recursion deﬁnes a forward Euler scheme for the
diﬀerential equation
dX
ds = f(X).
Motivated by this, we make a guess for the solution as a function of the
two time scales n and εn:
xn = u(n, εn, ε) = u0(n, εn) + εu1(n, εn) + ε2u2(n, εn) + · · · .
We write s = εn, and then the recursion takes the form
u(n + 1, s + ε, ε) = u(n, s, ε) + εf(n, u, ε).
Setting ε = 0 in this equation gives
u0(n + 1, s) = u0(n, s).
Diﬀerentiating the equation with respect to ε and setting ε = 0 in the result
gives
u1(n + 1, s) = u1(n, s) + f(n, u0(n, s), 0) −∂u0
∂s ,
and so on.
The ﬁrst equation shows that u0 does not depend on n, and so we write
u0(n, s) = U0(s).
The second equation shows that
u1(n, s) = U1(s) +
n−1

j=0
f(j, U0(s), 0) −ndU0
ds .
If u1 remains bounded as n →∞, then dividing both sides of this equation
by n and passing to the limit n = ∞gives
dU0
ds = lim
n→∞
1
n
n−1

j=0
f(j, U0(s), 0).
We take for initial data here the value
U0(0) = x0.
Hypothesis H4. Suppose that the average
f0(U) = lim
n→∞
1
n
n−1

j=0
f(j, U, 0)

7.3. Averaging Rapidly Oscillating Diﬀerence Equations
209
exists and deﬁnes a smooth function of U. Moreover, suppose that the
diﬀerence
n−1

j=0
[f(j, U, 0) −f0(U)]
remains bounded uniformly in n and U.
With this condition we obtain a useful approximation result for diﬀerence
equations.
Diﬀerence Equation Averaging Theorem. Suppose that condition
H4 is satisﬁed for the recursion
xn+1 = xn + εf(n, xn, ε)
and that each function f(n, x, ε) is a smooth function of its arguments x
(in EN) and ε (near zero) for n = 0, 1, 2, . . . . Let U(s) be determined from
initial value problem
dU
ds = f0(U),
U(0) = x0.
Then
xn = U(εn) + O(ε),
where the error estimate holds (as ε →0) uniformly for n = 0, 1, . . . , n[1/ε].
Here n is any ﬁxed positive integer and [1/ε] denotes the integer part of 1/ε,
that is, the largest integer less than or equal to 1/ε.
Proof of the Diﬀerence Equation Averaging Theorem. The proof is
accomplished by successfully estimating the diﬀerence
δn = xn −U(εn).
We have
δn+1
=
xn+1 −U(εn + ε)
=
xn + εf(n, xn, ε) −U(εn) −εf0(U(εn)) + O(ε2)
=
δn + ε(f(n, δn + U(εn), ε) −f0(U(εn))) + O(ε2)
=
(1 + εfx)δn + ε(f(n, U(εn), ε) −f0(U(εn))) + O(ε2) + εO(|δn|2).
It follows from back substitutions that
δn = O(ε) + ε
n−1

k=0
O(|δk|2).
There is a constant K such that |O(ε)| ≤Kε and O(|δk|2) ≤K|δk|2 for
k = 0, 1, . . . , n −1. Now suppose that |δk| ≤2Kε for k ≤n −1. Then
|δn| ≤K(ε + 4nKε2) ≤2Kε
if 4Knε < 1.

210
7. Methods of Averaging
Therefore, if ε < 1/(4KN), by mathematical induction we have that δn =
O(ε) uniformly for n = 1, . . . , n[1/ε] [78].
If U approaches a rest point of the diﬀerential equation, say U →U ∗,
where f0(U ∗) = 0 and U ∗is exponentially asymptotically stable, then the
results of the averaging theorem hold uniformly for 0 ≤n < ∞. The proof
of this is analogous to the proof of the Mean Stable Averaging Theorem in
Section 7.1.2, and it is not presented here.
7.3.1
Linear Diﬀerence Schemes
As we did for linear diﬀerential equations, we can carry out several
computations in detail for linear recursions. We consider the problem
xn+1 = (A + εB)xn,
x0 given.
Writing xn = Anun gives (if A is invertible)
un+1 = un + εA−n−1BAnun.
Applying the analysis of the preceding section, we might hope to ﬁnd that
un = U(nε) + O(ε),
where U(s) satisﬁes the equation
dU
ds = lim
n→∞
1
n
n−1

j=1
A−j−1BAjU.
If the coeﬃcient matrix has all of its eigenvalues with negative real parts,
then we might hope that the error estimate O(ε) would hold uniformly for
all n.
Therefore, it is of interest to determine the structure of the matrix
B0 = lim
n→∞
1
n
n−1

j=0
A−j−1BAj
if this limit exists. In order to do this, we assume that A is a discrete
oscillatory matrix.
Deﬁnition. A is a discrete oscillatory matrix if it has a spectral
decomposition of the form
A =
N

j=1
λjPj
where the eigenvalues λj lie on the unit circle in the complex plane (|λj| =
1). Therefore, λj = exp(iωj) for some real numbers ωj. We say that A is a

7.3. Averaging Rapidly Oscillating Diﬀerence Equations
211
discrete stable matrix if all eigenvalues λj satisfy
|λj| ≤1
for j = 1, . . . , N, and it is a discrete asymptotically stable matrix if
|λj| < 1
for j = 1, . . . , N.
We can calculate B0 directly when A is a discrete oscillatory matrix. In
fact, then
A−n−1BAn =
N

j=1
N

k=1
λn
kλ−n−1
j
PjBPk.
Moreover, the geometric sum
1
n
n−1

m=0
λm
k λ−m−1
j
=
λ−1
j
n
(λk/λj)n −1
(λk/λj) −1 .
Since the eigenvalues λ lie on the unit circle in the complex plane, this
expression approaches zero as n →∞unless λj = λk, in which case it has
the value 1/λj.
Therefore, we have
B0 = A−1 
λj=λk
PjBPk,
where the sum is taken over all indices j and k for which λj = λk. Thus, B0
contains at least the terms PjBPj. The average of B also exists when the
eigenvalues of A are arbitrary as long as PjBPk = 0 whenever |λk/λj| > 1.
This result is comparable to the Baker–Campbell–Hausdorﬀtheorem [9].
The next theorem follows from the Diﬀerence Equation Averaging
Theorem.
Averaging Theorem for Linear Diﬀerence Equations. Let A be a
discrete oscillatory matrix, and let {xn} be a sequence determined by the
recursion
xn+1 = (A + εB)xn.
Then, for any ﬁxed number n,
xn = An exp(εB0n)x0 + O(ε),
where the error estimate holds as ε →0 uniformly for n = 1, . . . , n[1/ε].
Thus, we can approximate the solution of the recursion using the
fundamental solution of the diﬀerential equation
dU
ds = B0U,
U(0) = I.

212
7. Methods of Averaging
Example of a Discrete Rotational System. We consider a case
where N = 2 and A = J (Jacobi’s matrix),
J =
 0
−1
1
0

.
This matrix has spectral decomposition
J = i
2

1
i
−i
1

−i
2
 1
−i
i
1

≡iP1 + (−i)P2.
Now, consider the diﬀerence equation
xn+1 = (J + εB)xn,
where B is an arbitrary 2 × 2 matrix.
From the calculations above, we see that the relevant average is given by
the formula
B0 = −iP1BP1 + iP2BP2.
The result of the averaging theorem for linear diﬀerence equations shows
that
xn = Jn exp(εnB0)x0 + O(ε)
for n = 1, . . . , n[1/ε] for any ﬁxed number n.
Examples of Perturbations of Markov Chains. The two-time scale
method can be used to study a random processes. A Markov chain describes
the dynamics of a system that can move among a ﬁnite set of states, say
S1, . . . , SN, in a random way [37]. Let pj,n be the probability that the
system is in state Sj at time n, and let Pj,k denote the probability that
the system moves from state Sj to state Sk in one time step. We suppose
that these transition probabilities (Pjk) do not change with time. As a
result, the probability of state j at the sampling time n + 1 is the sum
of all possible states at the previous step weighted by the probability of
transition to state j in one time step. We write this as
pj,n+1 =
N

k=1
pk,nPk,j
for j = 1, . . . , N. The notation can be simpliﬁed by introducing the
probability density (row) vector
pn = (p1,n, . . . , pN,n)
and the transition probability matrix
P = (Pk,j).

7.3. Averaging Rapidly Oscillating Diﬀerence Equations
213
With this, the model becomes
pn+1 = pnP.
The sequence of probability vectors {pn} describes the evolution of the
process.
Two interesting examples of perturbations of cyclic chains are
pn+1 = pn(I + εB),
where I is the identity matrix in EN, and
pn+1 = pn(C + εB),
where C is a cyclic matrix in EN:
C =












0
1
0
0
0
0
· · ·
0
0
...
...
...
0
0
· · ·
0
1
1
0
0
0












.
We suppose in each case that the row sums of B are all equal to zero and
that the matrices in each case I +εB and C +εB have nonnegative entries,
so they are stochastic matrices. In the ﬁrst case, the chain is trivial when
ε = 0, and so any distribution will persist in that case. However, when
ε > 0, we have from the averaging result that
pn = U0(εn) + O(ε),
where
dU0
ds = U0B.
Since I + εB is a stochastic matrix, all of B’s oﬀ-diagonal elements must
be nonnegative. Thus, B = D + ˜D, where D is a diagonal matrix and ˜D is
a matrix of nonnegative elements. It follows that
U0 = p0 exp(εDs)V0,
where V0 has only nonnegative elements.
Since the eigenvalues of a stochastic matrix all lie in or on the unit circle
in the complex plane, the eigenvalues of B must lie at the origin or in the
left half-plane. If B has a single eigenvalue at λ = 0, then all modes of U0
are damped except for the uniform mode. Thus, if ε > 0, the probability
distribution becomes spread out over all possible states.
The second example describes a chain that moves contents regularly from
one state to the next and from state SN to state S1 when ε = 0. If B has a

214
7. Methods of Averaging
single eigenvalue at λ = 0, then the “merry-go-round” chain changes into
one that results in a uniform distribution of the process over the states.
Finally, it is useful to consider a nonstationary Markov chain
pn+1 = pn(I + εBn),
where Bn is a periodic sequence of matrices, say with period n, for which
I + εBn is a stochastic matrix for each n = 0, . . . , n −1. Such chains arise
as models in chronobiology where n denotes weeks and n = 52 is a year, or
n is in minutes and n = 1440 is a day. In this case,
pn = U0(εn) + O(ε),
where
dU0
ds = U0 ¯B
and
¯B = 1
N
N−1

j=0
Bj.
Therefore, the average inﬂuence of the sequence {Bn} is dominant to
leading order. The higher order approximations of this chain using the
multiscale method bring the higher moments of the probability distribu-
tion of the sequence {Bn} into the approximation. Although these results
are not surprising, they are useful, since it is frequently possible to estimate
the small parameter ε from experiments (see, e.g., [118]).
7.4
Almost Harmonic Systems
Problems of the form
dz
dt = Az + εf(t, z, ε),
where A is an oscillatory matrix, ε is a small parameter, and f is a smooth
function of its arguments, are referred to as almost harmonic systems. (Re-
call that A is an oscillatory matrix if it is a diagonalizable real matrix and
all of its eigenvalues are purely imaginary, say ±iω1, . . . , ±iωN.)
We suppose that A is real, and so its dimension is even, say z, f ∈E2N
and A ∈E2N×2N. If f is a smooth function of its variables and is almost
periodic in t, then this system can be converted into one to which the
averaging theory applies directly by using the change of variables
z = exp(At)y.
With this,
dy
dt = εe−Atf(t, eAty, ε).

7.4. Almost Harmonic Systems
215
The new right-hand side has a generalized Fourier expansion in t, and the
averaging theory can be attempted directly as described earlier.
From another point of view, we can introduce a change of variables
that takes the matrix A into its real Jordan canonical form. Since A is
an oscillatory matrix, there is a matrix, say P, such that
P −1AP = diag

0
−ω1
ω1
0

, . . . ,

0
−ωN
ωN
0

.
When ε = 0, the problem reduces to one that is equivalent to a system of
harmonic oscillators, which is why we refer to such systems for z as almost
harmonic.
We can rewrite the system for z as
d2xj
dt2 + ω2
j xj = εFj

t, x, dx
dt , ε

for j = 1, . . . , N. For example, xj can be thought of as the location of the
jth particle in an N-particle array each with momentum dxj/dt. Then this
equation is based on Newton’s law, and it describes the restoring force in
the system (ω2
j xj) and the coupling between particles εFj.
Almost harmonic systems of this form are studied in [59, 111, 96, 13, 116].
We derive a variety of interesting results for them here.
7.4.1
Phase-Amplitude Coordinates
One advantage of studying harmonic oscillators is that they can be easily
transformed into phase-amplitude coordinates (see Section 2.3.5). Let us
deﬁne variables rj and θj by
rjeiθj = dxj
dt + iωjxj.
Therefore,
drj
dt + idθj
dt rj = εe−iθjFj + iωjrj,
and so the new variables rj, θj ∈EN satisfy the equations
drj
dt
=
εfj(t, r, θ, ε)
dθj
dt
=
ωj + εgj(t, r, θ, ε),
where
fj
=
Re(exp(−iθj)Fj)
gj
=
Im(exp(−iθj)Fj)/rj.
The vector of amplitudes r and the vector of phases θ are the unknowns
in this problem. This change of variables converts the original system into

216
7. Methods of Averaging
phase-amplitude coordinates using those for the harmonic oscillator ( ˙r =
0, ˙θ = ω).
The averaging procedures outlined in Section 7.1 can be applied to this
system, which includes a number of interesting examples. Small divisor
problems are common in these systems, but they can be eliminated in many
useful cases. For example, if the averaged system has an asymptotically
stable rest point, then mean stability overcomes small divisors. Also, if the
free frequencies of the system (ωj) satisfy certain nonresonance conditions
as in the KAM theory in Section 7.5.6, then small divisors can be shown
to be manageable.
7.4.2
Free Oscillations
When there is no external forcing in the system, the equations are
drj
dt
=
εfj(r, θ, ε)
dθj
dt
=
ωj + εgj(r, θ, ε).
When N = 1 and there is no external forcing, we can use θ as the new
time variable in the problem,
dr
dθ = ε
f(r, θ, ε)
ω + εg(r, θ, ε),
and treat this using our methods for forced systems. Once this is done, the
additional step of relating θ to t must be taken. If r = r(θ, ε) is known,
then
dθ
dt = ω + εg(r(θ, ε), θ, ε).
The solution is θ = θ(t, ε). For example, if the period of an oscillation that
has period 2π in θ is to be found, we must solve the equation 2π = θ(T, ε)
for the period T. As we have seen before, the period usually changes as ε
does.
When N > 1, since all of the phase variables are timelike (θj ≈ωjt+· · · ),
it is not obvious how perturbation methods can be useful.
One approach is to change the basis in EN using ω = col(ω1, . . . , ωN)
and its orthogonal complement, so ω, W2, . . . , WN, is an orthogonal basis.
Then
d(ω · θ)
dt
=
ω · ω + εω · g(r, θ, ε)
d(Wj · θ)
dt
=
εWj · g(r, θ, ε)
for j = 2, . . . , N. Thus, we see that ω · θ is a timelike variable and all
the other variables in the problem move slowly with respect to it. This

7.4. Almost Harmonic Systems
217
approach is studied in the rotation vector method in Section 7.5.1, and it
is successful if the conditions of the mean-stable averaging theorem are met
by the system
drj
dτ
=
ε
fj
ω · ω + εω · g
dψj
dτ
=
ε
Wj · g
ω · ω + εω · g ,
where ψj = Wj · θ and τ = ω · θ.
On the other hand, if there is no strong stability and the frequencies
ω1, . . . , ωN are incommensurable, little is known (see Section 7.5.6). The
problem in this case can be partly solved if r can be shown to approach an
invariant manifold, say r →R(ψ, ε) as θ →∞, in which case the problem
reduces to one for ψ alone on this manifold, and so to a ﬂow on a torus.
The invariant torus can be stable, but behavior on it might be ergodic.
This is an extension of the ideas of orbital stability (see Section 7.4.3).
If there is an oscillation for this system, then its period probably will
change with ε. We can determine its period, or equivalently its frequency,
as we construct a solution. Similar to our discussion of orbit stability of
free oscillations, we attempt here to construct an orbital and its period,
and we disregard the phase lag of solutions. van der Pol’s equation again
gives a good illustration.
Let us consider the equation
d2x
dt2 + x = ε(1 −x2)dx
dt
from the point of view of two time scales.
We look for the solution of van der Pol’s equation in the form
x = x0(τ, s) + x1(τ, s)ε + x2(τ, s)ε2 + · · · ,
where s (= εt) and τ = ω(ε)t are taken to be independent variables. As
before, we require that the coeﬃcients in this expansion be bounded as
functions of t, and to determine ω(ε) we require that they be 2π-periodic
as functions of τ as well. Now, x satisﬁes the equation
ω2 ∂2x
∂τ 2 + 2εω ∂2x
∂τ∂s + ε2 ∂2x
∂s2 + ε(x2 −1)

ω ∂x
∂τ + ε∂x
∂s

+ x = 0.
Setting ε = 0 in this equation gives
ω2
0
∂2x0
∂τ 2 + x0 = 0.
The general solution of the ﬁrst equation is
x0(τ, s) = A(s) cos(τ/ω0) + B(s) sin(τ/ω0),
where A and B are arbitrary functions of s, and we see from the periodicity
condition that ω0 = 1. It will turn out that we must take ω1 = 0 to ensure

218
7. Methods of Averaging
that x1 is periodic. We use this transformation at this point to simplify our
calculations. Diﬀerentiating with respect to ε and setting ε = 0 gives
∂2x1
∂τ 2 + x1 = −2 ∂2x0
∂τ∂s + (1 −x2
0)∂x0
∂τ .
The equation for x1 becomes
∂2x1
∂τ 2 + x1
=
−2(−A′ sin τ + B′ cos τ)
+ (1 −A2 cos2 τ −AB sin 2τ −B2 sin2 τ)(−A sin τ + B cos τ).
Using the identities
cos3 t
=
(3 cos t)/4 + h.f.t.
sin3 t
=
(3 sin t)/4 + h.f.t.
cos2 t sin t
=
(sin t)/4 + h.f.t.
sin2 t cos t
=
(cos t)/4 + h.f.t.,
we can easily expand the right-hand side of this equation in its Fourier
series.
The functions A and B must be chosen to suppress the resonant terms
in the right-hand side (see Chapter 6). To do this, the coeﬃcients of cos τ
and sin τ are set equal to zero, and the result is
2dA
ds −A

1 −A2
4 −B2
4

=
0
2dB
ds −B

1 −A2
4 −B2
4

=
0.
This system can be solved using polar coordinates: Setting A = R cos ψ
and B = R sin ψ, we have that
2RdR
ds = 2AdA
ds + 2B dB
ds = R2

1 −R2
4

and
R2 dψ
ds = AdB
ds −B dA
ds = 0.
Therefore,
dR2
ds = R2

1 −R2
4

.
We see that R(∞) = 2, so the result of these computations is that as
t →∞,
x →2 cos(ωt + φ) + O(ε),

7.4. Almost Harmonic Systems
219
where ω = 1 + O(ε2) and φ is determined by initial conditions. This ap-
proach to the averaging method is used extensively in [26, 90], which contain
many modern applications.
Almost Harmonic Approximations in Weakly Connected Networks[81].
Systems of van der Pol’s equations have the form
d2xj
dt2 + µj(x2
j −1)dxj
dt + ω2
j xj = εfj

t, x, dx
dt

,
where ε and µj are parameters, and x and dx/dt denote vectors with
components x1, . . . , xN and dx1/dt, . . . , dxN/dt, respectively.
When ε = 0, this system reduces to a system of van der Pol’s equations
with parameters µj and frequencies ωj. We have just shown that if each
0 < µj ≪1, then each oscillator approaches a periodic solution having
amplitude R = 2. Since each equation in this system has a stable periodic
solution, the entire network has a stable invariant torus that is the product
of these orbits. In [141, 81] it is shown that there is a nearby invariant
torus for the full system when 0 < ε ≪1, so this system can eventually be
reduced to a phase model of the form
˙ψj = Ωj + εΨj.
7.4.3
Conservative Systems
Recall that Hamiltonian systems can be (in theory) converted to phase-
amplitude coordinates, where an amplitude variable is the system’s energy
and the phase variables are deﬁned in a complicated way (see Section 2.3.5).
Let us consider a system that has been converted to phase-amplitude
coordinates, say in the form
dr
dt
=
f(r, ψ, ε)
dψ
dt
=
g(r, ψ, ε),
where r is a vector of N amplitude variables, ψ is a vector of N angular
phase variables, and f and g are smooth functions that are 2π-periodic in
each of the components of ψ.
We suppose that r = r∗corresponds to the invariant torus for ε = 0, so
f(r∗, ψ, 0) = 0
for all ψ. Then the set (r∗, ψ) deﬁnes an N torus in E2N as the components
of ψ range over [0, 2π]. Moreover, the equation
dψ
dt = g(r∗, ψ, 0)
deﬁnes a ﬂow of solutions on the surface of the torus. Linearizing the r
equation about r = r∗and replacing r −r∗by εr brings the system into

220
7. Methods of Averaging
the form
dr
dt
=
Sr + O(ε)
dψ
dt
=
g(r∗, ψ, 0) + O(ε).
The special case
g(r∗, ψ, 0) = ω(r∗),
where ω(r∗) is a function of r∗only, is usually the one considered, since
little is known about the general case. For most of our work we take ω to
be constant. Note that this system is of the same form as that derived for
the weakly coupled harmonic system except that r can now respond on the
fast time scale t.
We would like to derive an approximation to solutions of this system that
is valid uniformly for 0 ≤t < ∞. However, we cannot use the mean-stable
averaging theorem, since it would require the ψ variable to equilibrate.
This is usually not the case for ﬂows on a torus, especially if the vector ω
has incommensurable components. The following example illustrates this
problem.
Recall our notation for quasiperiodic functions introduced in Chapter 1.
Let G(x1, . . . , xN) be a smooth function that is 2π-periodic in each of
the variables x1, . . . , xN. Then if the frequencies ω1, . . . , ωN are ratio-
nally independent (κ · ω ̸= for all integer vectors κ ̸= 0), the function
G(ω1t, . . . , ωNt) is a quasiperiodic function as described in Section 1.5.1.
This is a special kind of almost-periodic function that is generated (or de-
ﬁned) by a periodic function of a ﬁnite number of variables. We say that its
frequencies are spanned by ω. In particular, it has an easily derived Fourier
series, and all of its frequencies are linear integer combinations of the ﬁnite
set (ω1, . . . , ωN). The Fourier series of G has the form
G(ω1t, . . . , ωNt) =
∞

|j|=−∞
CjeIj·ωt,
where j is a multi-index of integers, j = (j1, . . . , jN), ω is the vector ω =
(ω1, . . . , ωN), and |j| = j1 + · · · + jN.
Small divisor problems arise even in simple systems of weakly coupled
harmonic oscillators. For example, consider the system
d2x
dt2 + x
=
ε sin(x −y)
d2y
dt2 + 2y
=
ε sin(y −x).
We will attempt to use the iteration method to construct oscillatory
solutions of this system (see Section 6.2.2).

7.4. Almost Harmonic Systems
221
Setting ε = 0 gives
d2x0
dt2 + x0
=
0
d2y0
dt2 + 2y0
=
0.
The solutions are
x0(t)
=
A cos t + B sin t
y0(t)
=
a cos
√
2t + b sin
√
2t
for some constants A, a, B, and b.
Putting these solutions into the right-hand side of the equation gives
d2x1
dt2 + x1
=
sin(x0 −y0)
d2y1
dt2 + 2y1
=
sin(y0 −x0).
Now, the right-hand side is a quasiperiodic function of t, and it has a
generalized Fourier series
sin(x0(t) −y0(t)) =
∞

m,n=−∞
Cm,n exp(imt + i
√
2nt),
where the coeﬃcients Cm,n are not zero for inﬁnitely many values of m and
n.
The solution for x1 is given by the variation of constants formula
x1(t)
=
εeit
 t
0

m,n
Cm,n exp(imt′ + in
√
2t′ −it′)dt′
+ εe−it
 t
0

m,n
Cm,n exp(imt′ + in
√
2t′ + it′)dt′ + αeit + βe−it.
Proceeding as though all sums converge, we have that
x1(t) = ε

m,n
Cm,n
eimt+in
√
2t −eit
im + in
√
2 −i +

m,n
Cm,n
eimt+in
√
2t −e−it
im + in
√
2 + i .
The following lemma [60] highlights a problem with this expansion.
Lemma. The set {1 + m + n
√
2 : m, n integers} is dense in E1.
Because of this fact, we see that the terms deﬁning x1 have arbitrarily
small divisors, and we cannot expect these series to converge. It therefore
appears that the iteration method fails to produce a quasiperiodic solution,
and a subtler approach is needed to resolve this problem of small divisors.

222
7. Methods of Averaging
Since sin(x −y) is a real analytic function of x and y, we do know that
the coeﬃcients Cm,n decay geometrically to zero: Say, for some number ξ,
|Cm,n| ≤|ξ|m+n,
|ξ| < 1
as m+n →∞. Therefore, if the divisors are not too small, then these series
can be shown to converge, and the iteration process can be continued. It
is possible to set conditions on the divisors that ensure that these series
converge. The following deﬁnition is useful for dealing with small divisors .
Condition L. Let (ω1, . . . , ωN) be a set of frequencies. We say that
these frequencies satisfy condition L if there are constants G and γ with
G > 0 and γ > N −1 such that for all multi-indices j = (j1, . . . , jN) with
 |jk| ̸= 0 the estimate
|ω · j| > G|j|−γ
holds.
This condition is named for Liouville, who derived a similar condition.
It is very much like a nonresonance condition (see Section 7.5.6). In fact,
condition L holds for the example of this section [115], and so we see that
the terms in the series deﬁning x1(t) are dominated by those of a convergent
geometric series. Therefore, x1 is determined in the iteration method, and
the process can continue.
When ω is proportional to a vector of integers, the problem is said to
be resonant and condition L is not satisﬁed. This is a case to which the
Rotation Vector Method can be applied as shown in Section 7.5.1.
Bogoliubov [13] introduced a method of near-identity transformations
to analyze this system with condition L. The result is described by the
following steps.
We introduce new variables by the transformation
r
=
εV (u, v, ε)
ψ
=
u + εU(u, v, ε),
where U and V are 2π-periodic in the components of u. This transformation
is to be found so that it takes the system into the simpler system
du/dt
=
ω
dv/dt
=
Sv.
Thus, if the matrix S is asymptotically stable, then the v values equilibrate
to v = 0, and a solution in original variables will be
ψ
=
ωt + c + εU(ωt + c, 0, ε)
r
=
εV (ωt + c, 0, ε).
Therefore, we see that such a solution is a quasiperiodic function of t.

7.5. Angular Phase Equations
223
The idea behind this transformation is to construct an invariant surface
for ε ̸= 0 that is near the invariant torus of the unperturbed system. Be-
cause of this, the method is sometimes referred to as the method of invariant
manifolds [59].
Since the problem is time-invariant, we expect that a modiﬁcation of
frequencies will be required to carry out this plan. Therefore, we introduce
a frequency modiﬁcation λ, and we consider the modiﬁed problem
dr
dt
=
Sr + εf(r, ψ, 0)
dψ
dt
=
ω + λ + εg(r, ψ, 0).
Bogoliubov derived the following theorem for this system.
Bogoliubov’s Averaging Theorem. Suppose that the frequency vec-
tor ω satisﬁes condition L and that S is an asymptotically stable matrix.
Finally, suppose that f and g are analytic functions of their arguments.
Then there exists a smooth function λ = λ(ε) such that the system above
has a quasiperiodic solution of the form
ψ
=
ωt + c + εU(ωt + c, 0, ε)
r
=
εV (ωt + c, 0, ε),
where the phase shift c is an arbitrary vector of constants.
This theorem will be used decisively in Section 7.5.2 to construct intervals
of phase locking. Unfortunately, it is not always easy to verify the conditions
of this theorem.
7.5
Angular Phase Equations
In this section we consider problems that are described in terms of phase
variables alone. For example, these may arise as descriptions of dissipative
or conservative ﬂows on invariant tori or as models of networks of integrated
circuits that are described by phase variables, as we saw for the PLL and
VCON circuits.
The rotation vector method is useful for studying phase-locking behavior
for various systems. Next, we apply Bogoliubov’s near-identity transforma-
tion to study a problem to which Denjoy’s theory applies. This proves
certain other facts about phase locking. Finally, we describe brieﬂy the
KAM theory of ﬂows on tori.

224
7. Methods of Averaging
7.5.1
Rotation Vector Method
An important system of equations is
dx
dt
=
ω + εf(x, y, ε)
(7.3)
dy
dt
=
εg(x, y, ε),
where y and g are M-vectors and x, ω, and f are N-vectors, f and g are
periodic in each of the components of x, and ε is a small parameter. The
functions f and g are assumed to be smooth functions of their arguments.
As in Section 7.4.2, we suppose that ω is proportional to a vector of
nonzero integers, and without loss of generality, we take
ω = col(p1, . . . , pN),
where pk is an integer for each k = 1, . . . , N. This system does not satisfy
condition L, and so Bogoliubov’s averaging result does not apply directly.
However, vectors of integers W2, . . . , WN
can be found that are
orthogonal to ω and pairwise orthogonal:
Wj · Wk = 0
for j ̸= k
and ω·Wj = 0 for j = 2, . . . , N. We introduce new variables to the problem
through a change of basis in EN. Let
x = vω +
N

j=2
ujWj,
where the new coordinates are v, u2, . . . , uN.
This change of variables is similar to Delaunay orbit elements in celestial
mechanics [49]. The diﬀerential equations are easily transformed into these
new coordinates by taking dot products of the system with ω, W2, . . . , WN,
successively. The results are
(ω · ω)dv
dt
=
ω · ω + ω · f
(Wj · Wj)duj
dt
=
εWj · f
dy
dt
=
εg,
for j = 2, . . . , N. We write ω2 = ω · ω. Using v as a timelike variable, we
divide the last M + N −1 equations by the ﬁrst and get
duj
dv
=
ε
Wj · f
ω2 + εω · f
dy
dv
=
ε
g
ω2 + εω · f .

7.5. Angular Phase Equations
225
This form of the system is one to which the Mean Stable Averaging
Theorem can be applied.
We rewrite it as
du
dv
=
εF(v, u, y, ε)
(7.4)
dy
dv
=
εG(v, u, y, ε),
where u denotes the (N −1)-vector (u2, . . . , uN) and F denotes the vector
whose jth component is
Fj(v, u, y, ε) =
Wj · f
ω2 + ω · f .
Since the original function f is periodic in the components of x and the
vectors ω, W2, . . . , WN, have integer coordinates, the function F is periodic
in v and the components of u. Therefore, F has a convergent Fourier series:
F(v, u, y, ε) =
∞

|n|=−∞
Cn(y, ε) exp

i

n1v +
N

j=2
njuj

.
The average of this function over v is given by the Fourier series
⟨F⟩(U, y) =
∞

|n|=−∞
Cn(y, 0) exp

i
N

j=2
njUj

,
where the sum is taken over all multi-indices n for which n1 = 0.
If the original function f has the Fourier series
f(x, y, ε) =
∞

|n|=−∞
fn(y, ε)ein·x,
then the average of f over v is given by the Fourier series
⟨f⟩=
∞

|n|=−∞,n·ω=0
fn(y, 0)ein·x,
where the sum is taken over all multi-indices n for which n · ω = 0. For
such indices, we have that
n · x =
N

j=2
ujn · Wj.
Therefore, the coeﬃcients Cn in the expansion for F can be determined
from f.

226
7. Methods of Averaging
Since the system is periodic in v, a near-identity transformation can be
found such that system 7.4 can be rewritten as
du
dv
=
ε⟨F⟩(u, y) + O(ε2)
(7.5)
dy
dv
=
ε⟨G⟩(u, y) + O(ε2).
We suppose that the following condition is satisﬁed.
Hypothesis H5. The averaged equation
dU
dv
=
ε⟨F⟩(U, Y )
dY
dv
=
ε⟨G⟩(U, Y )
has an exponentially stable rest point, say (U ∗, Y ∗).
This condition ensures that the state (U ∗, Y ∗) is stable under persistent
disturbances. If this condition is satisﬁed, and if u(0) is near U ∗, y(0) is
near Y ∗, and if ε is suﬃciently small, then we have that
u = U + O(ε)
and
y = Y + O(ε)
uniformly for 0 ≤v < ∞for this system and all nearby (Carath´eodory)
systems as described in Section 8.1.
This calculation has an important application. Suppose that condition
H5 is satisﬁed. Then the u components of the system remain bounded, and
we have that
x
v = ω +
N

j=2
uj
v Wj →ω
as v →∞for this system and all nearby ones as above. This can be written
more concisely as
x1 : · · · : xN →ω1 : · · · : ωN,
meaning that the relative ratios of the components of x approach the rel-
ative ratios of frequencies ω. Thus, the output frequency ratios are locked.
The u variables are, in engineering terminology, phase lags. Since they
converge to near u∗, the phase lags also lock.
We say that the system is in phase lock with the frequencies ω, and
ω is called the rotation vector in analogy with the two-dimensional case
described by Denjoy. These results are summarized in the next theorem.
Phase Locking Theorem. Suppose that f and g are smooth functions
that are periodic in the components of x and that condition H5 is satisﬁed.
Then
x1 : · · · : xN →ω1 : · · · : ωN

7.5. Angular Phase Equations
227
as t →∞for system (7.2) and all nearby (Carath´eodory) systems.
Phase-locking occurs in many conservative systems. This is due to
dissipation within Hamiltonian systems. For example, if the system
dx
dt = f(x)
phase locks, say according to the rotation vector method, then H(x, p) =
f(x) · p deﬁnes a Hamiltonian for which the dynamics are described by the
equation
dx
dt
=
∇pH(x, p) = f(x)
dp
dt
=
−∇xH(x, p) = −gradx(f(x) · p).
In this way any system of phase equations can be embedded in a
Hamiltonian system, so there are many conservative systems that have
exponentially stable subsystems.
7.5.2
Rotation Numbers and Period Doubling Bifurcations
Rotation numbers are very useful for describing phase locking within sys-
tems of oscillators. For example, they can describe stability within systems
where none is expected, such as for conservative systems in the preced-
ing section. On the other hand, rotation numbers do not do everything:
For example, recall the parabolic interval mapping in Section 2.5 (namely,
x →rx(1 −x)). We can deﬁne a “rotation number” to be the number of
times an orbit circles around the rest point (r−1)/r as n increases, divided
by n. Equivalently, we could count the number of times iterates move left
in n steps and deﬁne the rotation number to be this number divided by n.
With this deﬁnition, there is rotation number 1/2 for almost all initial
values x0 and for all values of r in the interval, 3 < r < r∗≈3.57 . . . .
This happens even though there is an inﬁnite sequence of period doubling
bifurcations over this interval.
Still, rotation numbers can give useful information, ranging from Den-
joy’s rigorous theory for a ﬂow on a torus to Cartwright and Littlewood’s
[53, 17, 38] use of rotation numbers to study van der Pol’s equation, even
when this number is poorly deﬁned.
7.5.3
Euler’s Forward Method for Numerical Simulation
We begin this section with a useful observation based on our work on
averaging for diﬀerence equations. Namely, we show that for a large class
of problems Euler’s forward diﬀerence method for solving angular phase
equations is stable. In fact, it yields a ﬁrst-order numerical scheme that

228
7. Methods of Averaging
gives the correct value for rotation number of a system that is in phase
lock. We apply this simulation technique to two examples.
The forward Euler algorithm for solving a system of diﬀerential equations
of the form
dx
dt = ω + f(x, t),
where x, ω, f ∈EN, and f is a smooth function that satisﬁes the conditions
of the Nonlinear Averaging Theorem (Section 7.1.1), is given by
xn+1 = xn + h(ω + f(xn, nh)),
where we have used a step size h and replaced t by nh and the solution
x(t) by the sequence xn ≈x(nh). Setting
yn = xn −ωnh
gives the formula
yn+1 = yn + hf(yn + hnω, nh)
and y0 = x0.
The diﬀerence between y(nh) and yn measures the error in using the
algorithm. We say that a scheme is of order p if this diﬀerence error is
O(hp+1). The scheme for yn is a ﬁrst-order algorithm, since
x(h) −x1
=
 h
0
(ω + f(x(s), s))ds −h(ω + f(x0, 0))
=
 h
0
f(x(s), s)ds −hf(x0, 0)
=
O(h2),
so p = 1.
According to the averaging theorem for diﬀerence equations (Section 7.3),
we have
yn = U(hn) + O(h),
where the function U(s) is determined by solving the problem
dU
ds = lim
M→∞
1
M
M−1

j=0
f(U + ωs, s) = f(U + ωs, s)
and U(0) = x0. To study this equation we consider the averaged equation
d ¯U
ds = lim
S→∞
1
S
 S
0
f( ¯U + ωs, s)ds = ¯f( ¯U).
If this system has an exponentially asymtotically stable rest point, then
U and ¯U should remain close and ¯U remains bounded. Therefore, if this

7.5. Angular Phase Equations
229
−.2
−.04
.12
.28
.44
.6
.76
.92
1.08
1.24
1.4
1.4
1.26
1.12
.98
.84
.7
.56
.42
.28
.14
0
Frequency
ρ
Figure 7.2. N = 2 rotation number vs. ω.
happens, then
xn
nh = yn + nhω
nh
→ω
as n →∞. This result agrees with the phase-locking results of Section 7.5.1.
In particular, the condition used here is the same one used in the rotation
vector method to ensure that the system phase-locks onto the rotation vec-
tor ω. Thus, we see that stability of this (doubly) averaged system ensures
that the forward Euler algorithm generates a sequence that converges to
the same rotation number as for the original system of equations.
This fact greatly facilitates our simulations of phase equations, since the
forward Euler scheme involves few computations.
7.5.4
Computer Simulation of Rotation Vectors
Coupled oscillators tend to synchronize—even Hamiltonian systems of
them. This suggests that in addition to orbital stability (i.e., stability in
amplitudes) there is signiﬁcant phase-locking, which is asymptotic stability
in angular phases. In fact, phase stability is the rule, and erratic behavior,

230
7. Methods of Averaging
ω
ω
ω 2
1
3
1:1:1
2:1:2
2:1:1
3:1:1
4:1:1
3:2:1
Figure 7.3. A chart of phase locking relations that are observed in Figure 7.4.
like that described by the KAM theory, is the exception in many physical
systems.
The rotation vector method in Section 7.5.1 gives a rigorous method
for demonstrating phase-locking. To illustrate this phenomenon using
computer experiments we consider two interesting examples.
N = 2. This case falls within the scope of Denjoy’s theory. The rota-
tion number described in Figure 7.2 is calculated using the forward Euler
algorithm for the system
dx
dt
=
ω −ε(sin(x −y) + 2 sin(2x −y))
dy
dt
=
1.0 + ε(sin(x −y) + sin(2x −y)),
where ε = 0.1 and ρ ≈x(50π)/y(50π). This shows plateau regions where
the oscillators are in phase lock. The KAM theory (Section 7.5.6) describes
some of the system’s behavior oﬀthese plateaus.
N = 3. The rotation vector in a system of three oscillators can be de-
scribed using triangular coordinates. In the case of three phase equations,
say
dxj
dt = ωj + εfj(x1, x2, x3)
for j = 1, 2, 3, if phase-locking occurs, the rotation vector will be the limit
lim
t→∞x1(t) : x2(t) : x3(t) = z1 : z2 : z3,
where the vector (z1, z2, z3) is proportional to a vector of integers. We can
represent this vector of integers using triangular coordinates by introducing
numbers
ξj =
zj
z1 + z2 + z3

7.5. Angular Phase Equations
231
−1
−0.5
0
0.5
1
1.5
2
0
0.5
1
1.5
2
2.5
ω1
ω2
ω3
p3
p2
p1
Figure 7.4. Simulation of three oscillators described in the text. This shows that
some oscillators go to a vertex, meaning that only one oscillator dominates, but
most are near one of the 2:1:1 locking rotation vectors.
for j = 1, 2, 3. Since these numbers add to one and they are not negative, we
can depict the point (ξ1, ξ2, ξ3) as being in the intersection of the positive
octant with the plane ξ1 +ξ2 +ξ3 = 1. This is illustrated next for the model
dx1
dt
=
ω1 + ε(cos(x1 −x2) + cos(2x1 −x3))
dx2
dt
=
ω2 + ε(cos(x2 −x3) + cos(2x2 −x1))
dx3
dt
=
ω3 + ε(cos(x3 −x1) + cos(2x3 −x2)).
We plot the results of (ξ1, ξ2, ξ3) on triangular (or areal) coordinates for
each of many choices for 0 < ω1, ω2 < 2.0. This is shown in Figures 7.3
and 7.4.
7.5.5
Near Identity Flows on S1 × S1
Let us return to some work developed in our discussion of ﬂows on a torus.
Consider the equation
dx
dt = ω(ε) + εf(t, x, ε).

232
7. Methods of Averaging
The change of variables y = x −ω(0)t takes this equation into a form to
which the averaging theory applies:
dy
dt = ε(ω1 + ω2ε + · · · + f(t, y + ω(0)t, ε)).
We can analyze this system using Bogoliubov’s near-identity transforma-
tion: Let us try to ﬁnd a change of variables
y = v(t, ξ, ε) = ξ + εv1(t, ξ) + ε2v2(t, ξ) + · · ·
that takes the equation for y into one of the form
dξ
dt = εM1(ξ) + ε2M2(ξ) + · · · .
In this way, we have converted the original problem into one that does not
involve t explicitly, much as the method of averaging converts the problem
into a time-invariant one. In fact, we should ﬁnd that M1 = ¯f.
Substituting these formulas (y = v(t, ξ, ε)) into the problem for y gives
∂v
∂t + ∂v
∂ξ
dξ
dt = ε[ω1 + ω2ε + · · · + f(t, ω0t + v, ε)].
Combining this formula with the ones for dx/dt and dv/dt gives
dξ
dt
+
ε∂v1
∂t + ε2 ∂v2
∂t + · · · + (εM1 + ε2M2 + · · · )

1 + ε∂v1
∂ξ + ε2 ∂v2
∂ξ + · · ·

=
ε(ω1 + ω2ε + · · · + f(t, ω0t + v, ε)).
Equating coeﬃcients of like powers of ε on both sides gives
M1 + ∂v1
∂t = f(t, ξ + ω0t, 0) + ω1,
so if v1(ξ, t) is to be periodic in t, we must have
M1(ξ) = ω1 + 1
2π
 2π
0
f(t, ξ + ω0t, 0)dt ≡ω1 + ¯f(ξ),
and so
v1(ξ, t) = V1(ξ) +
 t
0
[f(t′, ω0t′ + ξ, 0) −¯f(ξ)]dt′,
where V1(ξ) is still not known. Two important points here are that M1 is
indeed the average of f (plus a constant), and the calculation here is quite
similar to the two-time scale expansion method introduced earlier in this
chapter.
This process can continue. For example,
M2 + M1
∂v1
∂ξ + ∂v2
∂t = ∂f
∂v (t, ξ + ω0t, 0)v1(t, ξ) + f1(t, ξ + ω0t) + ω2,
and so on (see [26, 90]).

7.5. Angular Phase Equations
233
7.5.6
KAM Theory
An important extension of Bogoliubov’s Theorem was developed by Kol-
mogorov, Arnold, and Moser [115], which is now known as the KAM theory.
This work signiﬁcantly relaxes the conditions needed by Bogoliubov to es-
tablish the existence of quasiperiodic solutions to the system presented just
above Bogoliubov’s averaging theorem in Section 7.4.3.
Suppose that the matrix S (Section 7.4.3) is diagonalizable and that its
eigenvalues are denoted by σj. Condition L is now replaced by the following
condition.
Condition KAM. Suppose that there are positive constants G and γ,
γ > N −1, such that
|i(j · ω) −σk| > G|j|−γ
and
|i(j · ω) −σk + σk′| > G|j|−γ
for all nonzero multi-indices j as described in condition L and all indices k,
k′ = 1, . . . , m.
The problem is modiﬁed by adding new variables µ, M, and λ as shown
next,
dr
dt
=
Sr + µ(ε) + M(ε)r + εf(r, ψ, ε)
(7.6)
dψ
dt
=
ω + λ(ε) + εg(r, ψ, ε),
and we have the following theorem.
KAM Theorem. Suppose that condition KAM is satisﬁed and that
the functions f and g are analytic. Then there exist functions λ = λ(ε),
µ = µ(ε), and M = M(ε) such that the system (7.6) has a quasiperiodic
solution of the form
ψ
=
ωt + c + εU(ωt + c, ε)
r
=
εV (ωt + c, ε).
This result is useful in establishing the existence of quasiperiodic solu-
tions to Hamiltonian systems. The proof of this result, a description of the
earlier literature, and several interesting examples are described in [116].
If λ, µ, and M in this result are zero, then we have found a quasiperiodic
solution of the original system—in fact, an invariant torus of solutions. In
any case, we see that if the nonresonance Condition KAM is satisﬁed, then
near the original system is one having quasiperiodic solution.

234
7. Methods of Averaging
7.6
Homogenization
We have considered averaging problems where two time scales appear, but
there are many important problems where two space scales or combinations
of time and space scales appear.
The idea here is to study periodic structures in space. Consider a material
in which there is variation of physical parameters on both microscopic
and macroscopic scales. For example, consider a line of bacterial cells that
are ﬁxed in an agar gel and placed at distances that are comparable to
their size (microns). Suppose also that there is a gradient of nutrient that
is established in the gel—its variation is on the macroscopic scale that
is related to the size of the agar gel itself. Let a denote some physical
characteristic, such as the local coeﬃcient of diﬀusivity of nutrients, and
let f be the local uptake rate of nutrients. The data of the system can vary
on the microscopic scale x/ε and the macroscopic scale x, where ε is the
size of an interval containing each bacterial cell. We suppose that diﬀusivity
is periodic with period ε, so we write a(x/ε), where a has period 1.
A model for the static distribution of u is
∂
∂x

a
x
ε
∂u
∂x

+ f

x, x
ε

u = 0,
where a(ξ) and f(x, ξ) are periodic in ξ with period one. Setting
v = a
x
ε
∂u
∂x
gives
∂v
∂x = −f

x, x
ε

u.
This results in the system
∂
∂x

u
v

=

0
b
−f
0
 
u
v

,
where b = 1/a. Using the two-scale method developed in Section 7.1, we
replace ∂/∂x by ε∂/∂x + ∂/∂y, where y = εx. Then the equations become

ε ∂
∂x + ∂
∂y
  u
v

= ε

0
b
−f
0
  u
v

.
Expanding u and v in terms of ε, we have
u
=
u0(x, y) + εu1(x, y) + · · ·
v
=
v0(x, y) + εv1(x, y) + · · · .

7.7. Computational Aspects of Averaging
235
Substituting these into the equation and equating like powers of ε gives
∂
∂y
 u0
v0

= 0,
so
 u0
v0

=
 U0(x)
V0(x)

,
and
∂
∂y
 u1
v1

=

0
b
−f0
0
  u0(x)
v0(x)

−∂
∂x
 u0
v0

.
As a result,
∂
∂x
 U0
V0

=


0
'1
a
(
−f0
0


 U0(x)
V0(x)

,
where
¯b =
'1
a
(
= lim
T →∞
1
T
 T
0
1
a(s)ds =
 1
0
ds
a(s)
and
f0(x) =
 1
0
f(x, s)ds.
Therefore,
 ∂
∂x
'1
a
(−1 ∂
∂x

U0 + f0(x)U0 = 0,
and we see that the “mean diﬀusivity” is the harmonic mean of the mi-
croscopic diﬀusivity of the system (see [103] for a detailed treatment of
homogenization).
7.7
Computational Aspects of Averaging
Let us consider now a highly oscillatory system, say having the form
dx
dt = f
 t
ε, x

,
x(0) = ξ,
where f is a vector of functions that satisfy the conditions of the Nonlinear
Averaging Theorem of Section 7.1. We know from that theorem that the
solution of this problem can be written in the form
x = x0(t) + εx1(t, t/ε) + O(ε2),

236
7. Methods of Averaging
where x0 is determined as being the solution of the equation
dx0
dτ = ¯f(x0) = lim
T →∞
1
T
 T
0
f(τ, x0)dτ,
x0(0) = ξ,
and x1 is given by the formula
x1(t, t/ε) = X1(t) +
 t/ε
0
[f(τ, x0) −¯f(x0)]dτ.
Under the assumptions of the theorem, the integral in this formula is
uniformly bounded, and X1 is (as yet) an undetermined function.
We wish to ﬁnd x(h, ε) at some step 1 ≫h ≫ε. To do this we use and
compare two methods: computation of averages and extrapolation.
7.7.1
Direct Calculation of Averages
First, to take advantage of the averaging formula, we must evaluate x0,
which entails evaluating of the average of f. This can be done in (at least)
three diﬀerent ways.
1. Approximation of the Averaging Limit. Since the average exists, given
a tolerance δ we can ﬁnd a constraint T(δ, x) such that
&&&&
1
T1
 T1
0
fdτ −1
T2
 T2
0
fdτ
&&&& < δ
and
&&&&
1
T1
 T1
0
fdτ −¯f(x)
&&&& < δ
for all T1 and T2 ≥T. If we can ﬁnd such a constraint T(δ, x), then we can
take as an approximation to ⟨f⟩the integral
¯f(x) =
1
T(δ, x)
 T (δ,x)
0
fdτ + O(δ).
The tolerance δ is related to the accuracy of the numerical scheme that we
hope to obtain from this work.
2. Second Diﬀerence Method. Let us deﬁne
V (T, x) =
 T
0
f(τ, x)dτ = ¯f(x)T + p(T, x),
which has the form of the average of f times T plus a function p that is
almost periodic in T and has mean zero.
First, note that if we take the second diﬀerence of V with respect to T,
we get
V (2T, x) −2V (T, x) = p(2T, x) −2p(T, x).

7.7. Computational Aspects of Averaging
237
For any tolerance δ and any value of x, there is a δ translation number
T(δ) for p such that
p(2T, x) −p(T, x) −p(T, x) + p(0, x) = O(δ)
uniformly for x in some domain G. Therefore, if T is such a translation
number, then
V (2T, x) −2V (T, x) = O(δ).
Therefore, by tabulating values of the second diﬀerence of the integral,
V (2T, x) −2V (T, x),
we can ﬁnd candidates for translation numbers. Unfortunately, the fact that
this diﬀerence is small does not necessarily imply that |p(T, x)| is small.
Of course in some cases this method works exactly, for example, if f is
periodic in t. Experience with this method has been good. It fails when f
has an unfortunate set of frequencies. However, the method proposed here
proceeds by tabulating the values of
V (2T, x) −2V (T, x)
and selecting the ﬁrst value of T away from T = 0 for which the tolerance
|V (2T, x) −2V (T, x)| < δ
is met. For this value of T we take
¯f(x) = V (T, x)
T
.
Various tests can be performed to create a sense of security in this estimate,
but it could be undecidable.
3. Ergodic Theorem. If f is a quasiperiodic function, say
f(τ, x) = F(ω1τ, . . . , ωLτ, x)
where F is 2π-periodic in each of its ﬁrst L variables, then we know from
the weak ergodic theorem [117] that
¯f(x) = lim
T →∞
1
T
 T
0
f(τ, x)dτ =
1
(2π)L
 2π
0
· · ·
 2π
0
F(θ1, . . . , θL, x)dθ1 · · · dθL.
Therefore, we could evaluate the L-fold integral wherever needed. This,
however, can turn out to be a major project in itself if L ≥4.
7.7.2
Extrapolation
Once a satisfactory value of T is found, we return to the full problem, where
we set
ε′ = h
T .

238
7. Methods of Averaging
Then
2x

h, ε′
2

−x(h, ε′) = x0(h) + O(δh) + O
 h
T
2
.
On the other hand,
x(h, ε) = x0(h) + O(ε).
Therefore,
x(h, ε) = 2x

h, ε′
2

−x(h, ε′) + O(ε) + O(δh) + O
 h
T
2
.
This formula shows how the extrapolation formula depends on the choice
of δ, T, and ε′. Usually ε′ ≫ε, so solving the problems for x(h, ε′/2) and
x(h, ε′) is usually signiﬁcantly faster than calculating x(h, ε) directly. One
of the interesting features of this approach, as with the QSSA method in
Chapter 8, is that the result improves as the stiﬀness (≈1/ε) increases
[79, 112].
7.8
Averaging Systems with Random Noise
In addition to his development of averaging methods for studying oscil-
latory nonlinear systems, Bogoliubov also introduced methods for dealing
with systems perturbed by random noise. This work and its successors are
described in [82]. We summarize here some relevant parts of that work,
since they form a natural and useful extension of the methods in this chap-
ter. The ideas are very powerful, and they enable us to further explore the
connections between oscillations, chaos, and randomness.
What does “random” mean? What are “random variables”? What are
“random signals”? What are “random perturbations”? Many mathemati-
cians, scientists, and engineers have worked on developing mathematical
structures that make these questions, and their answers, precise enough to
enable us to ﬁnd rigorous results. These results have been used to explain
physical observations, like Brownian motion, and to design devices, like FM
radio, that can perform well in the presence of noise.
In this section we ﬁrst recall some basic ideas from the theory of proba-
bility theory, and then we describe a basic averaging result for dynamical
systems perturbed by random noise.
7.8.1
Axioms of Probability Theory
Probability theory is based on the idea of a probability space. We write
this as (Ω, E, P), where

7.8. Averaging Systems with Random Noise
239
1. Ωis a set, called the sample space, whose elements might correspond
to the possible outcomes of some experiment.
2. E is a collection of subsets of Ω. This is called the collection of events
or observables of Ω. We say event E ∈E occurs if the outcome of an
experiment, say ω, is in E.
3. P is a mapping from E to the interval [0, 1]. For E ∈E, P(E) is the
probability of this event. We interpret this in the sense of frequency:
If the experiment is performed a large number of times, the event E
should occur in proportion P(E).
These entities have certain consistency properties required of them to be
useful:
1. E includes both the whole space Ωand the empty set φ.
2. If a set A is in E, then so is its complement Ac = {ω ∈Ω, ω /∈A}.
3. If a sequence of sets {An} is in E, then so is the union ∪∞
n=1An ∈E.
4. 0 = P(φ) ≤P(A) ≤P(Ω) = 1 for any event A ∈E.
5. P(∪∞
n=1An) = ∞
n=1 P(An) for any sequence of disjoint sets An ∈E.
A random variable can be thought of as being a measurement of a sample
in Ω. Consider a function X : Ω→E1 with the property that if x is in
the range of X, i.e., x ∈X(Ω), then the set {ω ∈Ω|X(ω) = x} = X−1(x)
is an event in E. This ensures that we can determine the probability of a
given measurement: We write P(x) = P(X−1(x)). (In general, X can take
values in any kind of space, which we denote later by Y .)
Using this, we can deﬁne the moments of a random variable, namely,
E(Xn) =

x∈X(Ω)
xnP(x)
for any integer n. In particular, the mean value (also known as the average
or expected value) of X refers to E(X), the variance of X is E(X2)−E(X)2,
and so on.
The distribution function of a random variable X is the function FX(x) =
P(X ≤x). Since this is a nondecreasing function, it has a derivative (almost
everywhere), and we expect that
FX(x) =
 x
−∞
fX(u)du,
where the function fX is referred to as the probability density function
of X. The function fX might be a generalized function, and the rigorous
mathematical theory underlying all of these ideas is quite involved (see
[117, 37] for expositions of this).

240
7. Methods of Averaging
However, in many important cases, the probability density function is
a smooth function. For example, in the case that X is a normal random
variable, we have
fX(x) =
1
√
2πσ2 e−(x−µ)2
2σ2 .
For such a random variable, its mean is µ and its variance is σ2. Moreover,
the meaning of mean and variance can be made clearer by observing that
for a normal random variable 68+% of samples will be within one standard
deviation of the mean (i.e., within µ ± σ), 95+% within 2σ, and 99+%
within 3σ. Thus, the mean locates the values of X, and the variance tells
how spread out they are.
Random Processes.
Of interest to us here are random variables that also depend on time.
We refer to such functions as random processes (or random signals), and we
write them as X(t, ω) : [t0, t1] × Ω→Y , where Y is some set in E1. These
processes might have some smoothness properties with respect to t, but
they have only the properties of random variables with respect to ω. For
example, there is no topology in the probability space, so we cannot speak
of X being continuous over Ω. Usually, ω is not included in the notation
for random processes.
Brownian motion is a good and useful example. We say that a random
process B(t) is Brownian motion if
1. For any sequence of times t0 < t1 < t2 < · · · < tn the diﬀerences
B(t1) −B(t0), B(t2) −B(t1), . . . , B(tn) −B(tn−1) are independent
random variables.
2. The distribution function for the increments is normal with mean
zero and variance t:
P(B(t1) −B(t0) ≤x) =
1

2π(t1 −t0)
 x
−∞
exp

−
u2
2(t1 −t0)

du.
3. B(t) is a continuous function of t for 0 ≤t < ∞.
A notation for stochastic diﬀerential equations has been developed. We
write
dX = σdB,
and this is interpreted in terms of stochastic integrals that are deﬁned so
that in this case the process X is Brownian motion with variance σ2t [82].
An important point for understanding stochastic diﬀerential equation
notation is that the probability density function for X, say p(x, t), satisﬁes
the diﬀusion equation
∂p
∂t = (σ2/2)∇2
xp.

7.8. Averaging Systems with Random Noise
241
More generally, we interpret the solution of the stochastic diﬀerential
equation
dx = f(x)dt + g(x)dB
in terms of the probability density function for x, which in this case is
∂p/∂t = ∇· ((g2/2)∇p −fp).
Such processes are referred to as diﬀusion processes.
We will consider problems involving noise that is described using a
random signal of the form
y(t/ε, ω) : [0, ∞] × Ω→Y,
where ε is a small dimensionless parameter that will describe the ratio of
the noise time scale to the system’s response time scale. We require some
natural technical conditions on y.
First, we suppose that y is ergodic: For any measurable function h(s)
and any t
E(h(y(t/ε, ω))) =

Y
h(y)ρ(dy),
where ρ is a measure on Y called the ergodic measure for y. Essentially this
says that the average of a function along a noise trajectory is the same as
averaging the function over the whole noise space, with weighting allocated
by ρ. Hereafter we omit the ω in this notation and write y(t/ε), and so on.
We also suppose that the noise is mixing, meaning that in a probabilistic
sense not made precise here
 t
0
|p(t′, y, C)dt′ −ρ(C)|dt′ < ∞
for all t, where p(t′, y, C′) is the transition probability density function for
moving from point y to a set C in a time interval of length t′. This is
essentially the same condition that we required in the Nonlinear Averaging
Theorem in Section 7.1. (See [82] details.)
7.8.2
Random Perturbations
Consider a system
˙x = f(y(t/ε), x, t),
where y is an ergodic mixing process. Then it is shown in [82] that
x(t) = ¯x(t) + √εx1 + O(ε),
where ¯x is derived from the averaged system
˙¯x = ¯f(¯x) ≡

Y
f(y, ¯x)ρ(dy)

242
7. Methods of Averaging
and x1 is a diﬀusion process whose drift (f above) and variance (g2 above)
can be calculated.
Therefore, the solution moves like the averaged system, but the error
accumulates. The Law of the Iterated Logarithm states that
lim
t→∞
√εx1(t)
√2t log log t = 1
almost surely. Then if t ≤T/ε, √εx1(t) should be (approximately) bounded
by √ε. Therefore, on an interval up to T/ε, the average system dominates,
but beyond that the noise takes over if there is no other mechanism present
to control it.
7.8.3
Example of a Randomly Perturbed System
Let us consider a random process y(t) that takes values in a ﬁnite set
Y ⊂E1, say {S1, . . . , SM}. We suppose that it is a Markov jump process
with switching times determined from an exponential distribution. That is,
for each sample path there is a sequence of random times
0 = τ0 < τ1 < τ2 < · · · < τK+1
and a sequence of states in Y , say
y0, y1, . . . ,
such that y(t) = yk for τk ≤t < τk+1. Then to ﬁnd the sample path for x,
we solve
˙x = f(yk, x, t), x(ετk) = x(ετ −
k )
for ετk ≤t < ετk+1 and for k = 1, . . . , K, where ετK+1 = T is a ﬁxed
number. We take for the initial condition on this interval the ending value
of x on the preceding interval. This is denoted by x(ετk) = x(ετ −
k ).
We suppose that the distribution of switching times is exponential,
P(τk+1 −τk > t) = exp(−λt),
and that at each switching time, the probability that y jumps from state Si
to state Sj is a given number πi,j. The matrix P = (πi,j) is the transition
probability matrix for this Markov chain. We suppose that this Markov
chain for y is ergodic. That is, 1 is a unique eigenvalue of P; all others
satisfy |λ| < 1; and the corresponding left eigenvector, say ρ, has only
positive entries; i.e., ρj > 0 for j = 1, . . . , M.
Calculating sample paths is expensive if ε is small, since to get to time
T with a sample path for x we must solve the sampled problems on
approximately O(T/ε) time intervals.
On the other hand, the averaging theorem for this ensures that we can
use the averaged problem as an approximation:
˙¯x = ¯f(¯x, t), ¯x(0) = x0,

7.9. Exercises
243
where
¯f(¯x, t) =
M

m=1
f(Sm, ¯x, t)ρm.
This gives a good approximation up to time t = T if ε is small.
Beyond time T, our estimate of the diﬀerence
xε(t) −¯x(t)
diﬀuses away.
This example highlights the fact that y is a fast process: As ε →0 the
switching times for y, ε(τk+1 −τk), get closer to each other, so the jumping
frequency increases. Since y is ergodic, it rapidly visits all states in Y .
How accurate is the approximation? The almost periodic function av-
eraging theory of Bogoliubov for deterministic systems (i.e., nonrandom
ones) creates approximations that are of order ε on a time interval [0, T].
The random perturbations are of order √ε on this interval, and even with
stability properties required of the averaged system they eventually wander
oﬀ: The accuracy diﬀuses away, even if the averaged system is exponentially
stable. So noise will eventually prevail. The random averaging theory is pre-
sented in detail in [82], where the second order approximation is derived
and the meaning of the approximation is studied in detail.
Another interesting example of this is that in which the averaged system
has an energy surface, as if it were a gradient system. Then the potential
wells dominate behavior for certain periods of time, but eventually noise
will (probably) move the solution through all of the wells in a predictable,
but random, way. In fact, most solutions end up visiting all of the potential
wells in a way that is itself described by a Markov chain [42].
7.9
Exercises
7.1. a. Show that if f(t) is a periodic function or a trigonometric polynomial,
then condition H2 in Section 7.1 is satisﬁed. That is, show that
 t
0
[f(t) −⟨f⟩]dt
is bounded for all τ ≥0.
b∗. If ξ(t, ω) is a stationary random process, then its average exists,
lim
T →∞(1/T)
 T
0
E{|ξ(t, ω)|}dt ≡⟨ξ⟩,
and in addition,
lim
T →∞(1/T)
 T
0
{ξ(t, ω) −⟨ξ⟩}dt ≡η(ω)

244
7. Methods of Averaging
is a Gaussian random variable [91]. Find such a process ξ(t, ω) that
does not have a convergent Fourier series, even one having random
coeﬃcients. This example shows that generalized Fourier analysis is
not suﬃcient to describe random processes.
7.2.
Show that if condition H3 in Section 7.1 is replaced by the system
being stable under persistent disturbances, then the mean averaging
theorem still holds.
7.3.
Averaging linear systems: Let A be an oscillatory matrix.
a. Evaluate ⟨B⟩≡⟨e−AtB(t)eAt⟩when B is a matrix of periodic
functions.
b. Show that [⟨B⟩, A] = 0, where [A, C] ≡AC −CA is the commutator,
or Poisson bracket, of A and C.
7.4.
Show that the two-time scale method can be used for linear systems
by carrying out the ﬁrst two steps in solving
dx
dt = εC(t)x,
where C is a periodic function or a trigonometric polynomial of t.
7.5. a. Verify the induction argument used in the proof of the Diﬀerence
Equation Averaging Theorem.
b. Show that if all of the eigenvalues of ⟨B⟩have negative real parts,
then the conclusion of the diﬀerence equation averaging theorem in
Section 7.3 holds uniformly for all n = 1, 2, 3, . . . .
7.6.
Verify the spectral decomposition of the cyclic matrix used in
Section 7.3.
7.7.
Apply the method of averaging to the system
dy
dt = ε exp(−At)f(exp(At)y, ε)
when A is an oscillatory matrix and the components of f(y, ε) are
smooth functions of ε and analytic functions of the y variables. Here
y, f are in EN and A is in EN×N.
7.8. a. Rewrite the equation
u′′ + ω2u = εF(u)
as an equivalent linear system in E2 whose coeﬃcient matrix (when
ε = 0) has eigenvalues ±iω. Convert this system to phase-amplitude
coordinates using polar coordinates (r, θ). Write the result as a ﬁrst-
order equation using θ as the timelike variable.
b. Consider Duﬃng’s equation
x′′ + ax = εbx3.
Describe its solution by using the averaging procedure. Compare your
answers with those obtained for Duﬃng’s equation in Chapter 6 for
similar parameter values.
c. Apply the near-identity transformation to the system in part a.
7.9.
Let z(t) be a complex-valued function that satisﬁes the diﬀerential
equation
dz
dt = iωz + (a −zz∗)z,

7.9. Exercises
245
where z∗denotes the complex conjugate of z. Describe the behavior
of solutions for z(t) when a and ω are real numbers.
7.10.
The gene pool carried by a population of animals that have a genetic
trait (one locus) of one of three possible types (two alleles) can be
described by the diﬀerence equation
gn+1 =
rng2
n + sn(1 −gn)gn
rng2n + 2sngn(1 −gn) + tn(1 −gn)2 .
Suppose that there is slow selection; that is,
rn = 1 + ερn,
sn = 1 + εσn,
and
tn = 1 + ετn,
where ρn, σn, and τn are assumed to be oscillatory functions that
have mean values
⟨ρ⟩= lim
n→∞
1
n
n−1

u=0
ρu,
⟨σ⟩= lim
n→∞
1
n
n−1

u=0
σu,
⟨τ⟩= lim
n→∞
1
n
n−1

u=0
τu.
With this notation, apply the Nonlinear Diﬀerence Averaging The-
orem to analyze this system for small values of ε in the four cases
σ > ρ, τ; σ < ρ, τ; ρ < σ < τ; and τ < σ < ρ.
7.11.
Let f(t, x, ε) = cos(x −ωt) + cos t as in Section 7.5.5. Carry out the
near-identity transformation for the resulting equation. Show that
if ω1 = 0 and ω0 ̸= ±1, then M2 = 0 and, if ω0 = ±1, −M2 =
± sin x/2 + ω2.
7.12∗. Consider the initial value problem
∂u
∂t + b
	x
ε , t
ε, x, t, ε

∂u
∂x = 0,
u(x, 0) = U(x)
for real variables x, t and for 0 < ε ≪1. Let ξ = x/ε and τ = t/ε, and
suppose (i) U(x) and b(ξ, τ, x, t, ε) are smooth (at least C1) functions
of ξ, τ, x, t, and ε and (ii) b(ξ +1, τ, . . . ) = b(ξ, τ +1, . . . ) = b(ξ, τ, . . . )
for all values of ξ, τ, x, t, and ε. That is, b is doubly periodic in ξ and
τ with period 1. Use the multiple-scale formalism to construct an
approximation to the solution of this problem that is valid for small
values of ε: Let
u(x, t) = u0(ξ, τ, x, t) + εu1(ξ, τ, x, t) + · · ·
and determine equations for coeﬃcients, which should be bounded
for all values of ξ, τ.
Show that u0(x, t) solves
∂u0
∂t + ρ(x, t)∂u0
∂x = 0,
u0(x, 0) = U(x).
(Hint: Consider the ordinary diﬀerential equation
dξ
dτ = b0(ξ, τ, x, t)
in which x and t appear as parameters. It is known [30] that for any
choice of initial data τ0, ξ0, the solution, say
ξ = X(τ, τ0, ξ0),

246
7. Methods of Averaging
has the properties that
(i) the limit
lim
τ→∞X(τ, τ0, ξ0)/τ = ρ(x, t)
exists and is independent of (τ0, ξ0);
(ii) ρ is a continuous function of (x, t);
(iii) if ρ is a rational number, then any solution approaches a periodic
solution that is a torus knot;
(iv) if ρ is irrational, then any solution is dense in the torus.)
7.13∗. Consider the problem [122]
du
dt
=
ε(B(t)u + C(t)v)
dv
dt
=
Az + ε(D(t)u + E(t)v),
where each of B(t), C(t), D(t), and E(t) is a ﬁnite sum of periodic
matrices and the matrix A is stable. Suppose that the average
lim
T →∞
1
T
 T
0
B(s)ds
is zero. Show that any solution to this system can be constructed in
the form
u
=
u0(t, εt, ε2t) + O(ε)
v
=
v0(t, εt) + O(ε)
by using the multitime method.
7.14∗. Consider the integro-diﬀerential equation [80]
dx
dt = ε

µ +
 t
0
K(t −τ)(sin(x(τ) + τ) + sin x(τ))dτ

,
where the kernel K satisﬁes |K(τ)| ≤Ae−αt for 0 ≤τ < ∞. Here
|ε| ≪1, 0 < α, and µ is a ﬁxed constant. Use the multitime Ansatz
x = x0(t, s) + εx1(t, s) + · · · ,
where s = εt, to show that x0(t, s) = X0(s), which satisﬁes the
equation
dX0(s)
ds
= µ + K∗sin X0,
where
K∗= lim
T →∞
1
T
 T
0
 t
0
K(t −τ) dτ dt.
7.15∗. Consider the system of nonlinear diﬀusion equations [25]
∂u
∂t
=
D1 ∂2u
∂x2 + ελ(u2 + v2)u −ωv
∂v
∂t
=
D2 ∂2v
∂x2 + ωu + ελ(u2 + v2)v,

7.9. Exercises
247
where D1, D2, and ω are positive constants and λ(r) = 1−r. Identify
slowly modulated periodic waves. (Hint: Introduce polar coordinates
to u and v by R2 = u2 + v2 and tan Θ = u/v, average the problem,
and look for (traveling wave) solutions of the result having the form
R(εx −cε2t), etc., where c is a constant to be determined.)

8
Quasistatic-State Approximations
The appearance of several time scales in a problem can mean that various
components of the system respond at diﬀerent rates. Rapidly responding
components can try to reach some equilibrium, while the other components
change hardly at all. It is not surprising that such perturbation problems
can be studied using stability methods, because both deal with how solu-
tions approach equilibria. These problems diﬀer from those in Chapter 7,
where oscillations occurred on a fast time scale relative to other changes.
In this chapter we study problems that try to equilibrate on a fast time
scale while other components in the system change more slowly.
Gradient systems illustrate many of the methods developed in this
chapter. Consider the system of equations
dy
dt = −∇G(y),
where y is in EN and G maps EN into E1 with
lim
|y|→∞G(y) →∞.
The solutions of this equation either begin and remain at a critical point of
G, say y∗where ∇G(y∗) = 0, or they approach such an equilibrium. Since
along such a solution
dG(y(t))
dt
= −|∇G(y)|2,
the solution must approach a critical point of G(y).

250
8. Quasistatic-State Approximations
An analogous singular perturbation problem is
εdy
dt = −∇G(y).
The parameter ε seems not to be essential, since the change of variables
τ = t/ε removes it from the equation:
dy
dτ = −∇G(y).
(8.1)
Still, in terms of the original time scale t, the variable τ approaches ∞as
ε →0+. Let Y (τ) be a solution of Equation (8.1) for which ∇G(Y (0)) ̸= 0.
Then Y (τ) →y∗as τ →∞, where y∗is a critical point of G : ∇G(y∗) = 0.
In terms of the original time scale, we have y = Y (t/ε). Therefore, for each
t > 0, Y (t/ε) →y∗as ε →0+! This calculation illustrates a duality between
stability and perturbations in quasistatic-state problems. Note that y∗need
not be a minimum of G, but in most applications, we restrict attention to
initial data Y (0) that lie in the basin of attraction of a minimum.
This result is robust: Solutions of the perturbed system
εdy
dt = −∇G(y) + εg(t, y, ε),
where ε is a small positive parameter, behave in a way similar to Equa-
tion (8.1). Suppose that g satisﬁes Carath´eodory’s conditions (g is Lebesgue
integrable with respect to t, continuously diﬀerentiable with respect to the
components of y, continuous as a function of ε, and bounded). Just as in
our discussion of stability under persistent disturbances (see Section 3.4),
we see that the function G(y) is almost a potential function for this system,
but its derivative along solutions is
dG(y(t))
dt
= −1
ε|∇G(y)|2 + ∇G · g(t, y, ε).
This is negative for all values of y except those near ∇G(y) = 0. Therefore,
if y(0) is not near such a point, then y(t) →y∗+O(ε) as t →∞or ε →0+.
It is interesting to note that a similar calculation can work even if g
represents (large deviation) Gaussian noise [91].
Next consider the system of equations
dx
dt
=
f(t, x, y, ε)
(8.2)
εdy
dt
=
−∇G(y) + εg(t, x, y, ε),
where x, f ∈EM. Let us suppose that y∗is a minimum of G(y) and that
y(0) is near y∗. Then as in the preceding paragraph, the values of the solu-
tion y(t) will lie near y∗as well. Suppose also that f satisﬁes Carath´eodory’s
conditions and that the solutions of
dx
dt = f(t, x, y∗, e)

8. Quasistatic-State Approximations
251
beginning in a bounded domain Ωremain there for 0 ≤t ≤T. Then the
manifold Ω× {y = y∗} is referred to as a quasistatic manifold for the
system. It is not invariant with respect to solutions, but solutions of the
full system with y(0) near y∗certainly stay near this manifold for small ε
and 0 ≤t ≤T.
Finally, consider the system
dx
dt
=
−∇F(x) + εf(t, x, y, ε),
x(0) = ξ
(8.3)
εdy
dt
=
−∇G(y) + εg(t, x, y, ε),
y(0) = η.
If y(0) is near y∗(a minimum of G), if x(0) is near x∗(a minimum of F),
and if f and g satisfy Carath´eodory’s conditions for y near y∗and x near x∗
for 0 ≤t < ∞then for small positive values of ε, y quickly equilibrates to a
neighborhood of y∗(a quasistatic manifold) and x eventually equilibrates
to a neighborhood of x∗. In particular, the solution is near
x
=
x∗+ x∗
0(t) + O(ε)
y
=
y∗+ Y (t/ε) + O(ε),
where
dx∗
0
dt = −∇F(x∗+ x∗
0),
x∗
0(0) = ξ −x∗
and
dY
dτ = −∇G(Y ),
Y (0) = η −y∗.
This approximation is valid on the entire interval 0 ≤t < ∞, and we see
that it is a sum of terms: the equilibrium (x∗, y∗) of the reduced problem
(ε = 0 in Equation (8.3)), two transients, one on the slow time scale t
(for x∗
0) and one on the fast time scale τ (for Y ), and a small error. The
expression (x∗+ x∗
0, y∗) is called the quasistatic-state approximation, and
Y is the initial transient.
It is clear that level sets of the potential functions F and G in system
(8.3), say
{(x, y) ∈EM × EN|F(x) = F(x∗) + aε
and
G(y) = G(y∗) + bε},
where a and b are ﬁxed constants, deﬁne a tube in [0, ∞) × Em × En that
is of order o(1) about x∗, y∗. It is “sticky” in the sense that solutions of the
system starting near it are attracted to it and once inside the boundary
stay there.
The ﬁrst example (8.1) describes a duality between perturbations and
stability under persistent disturbances. The next example shows that be-
havior on various time scales can be peeled oﬀ. For example, the dynamics
of the ﬁrst of Equations (8.2) with y = y∗and ε = 0 could be chaotic, but

252
8. Quasistatic-State Approximations
still y is attracted to y∗. Finally, the third example shows how an approxi-
mation can be constructed for 0 ≤t < ∞when the slow and fast auxiliary
problems following the system (8.3) are both stable. These examples are
useful to keep in mind throughout this chapter, where various results are
derived that extend and apply these observations.
The results just described for perturbed gradient systems can be ex-
tended to more general systems. In fact, a Liapunov function centered at
some state is quite similar, at least locally, to a potential function for a
gradient function. For example, consider the system
εdy
dt = G(y),
and suppose that it has a static state, say y = y∗, that is asymptotically
stable. Then from Section 3.4 we know that there is a Liapunov function
W(y) that is continuously diﬀerentiable at and near y∗, W(y∗) = 0, and
there is a comparison function c such that
dW
dt = 1
ε∇W · G(y) ≤−1
εc(|y −y∗|)
for y near y∗. It follows that W(Y (t/ε)) →W(y∗) as ε →0+ for every
t > 0, and so y →y∗if y(0) is near y∗.
Using the idea of stability under persistent disturbances, we can apply
W to study solutions of a nearby (Carath´eodory) system
dy
dt = 1
εG + g(t, y, ε),
in which case y(t, ε) →y∗+ o(1) as ε →0+ for every t > 0 [70]. In
this way Liapunov functions are used later to extend the quasistatic-state
approximation beyond gradient-like systems.
In Chapter 1 we saw that the spectrum of the matrix A determines the
behavior of solutions of the linear system
dx
dt = Ax.
In particular, as in Chapter 7, if the eigenvalues of A are real but widely
separated, then the solution has relatively fast and slow modes. The ratios
of the eigenvalues show what are the fast and slow time scales.
The term “singular-perturbation problem” applies to any problem whose
solution has a near-singular behavior, in the sense of complex function
theory, relative to a perturbation parameter (ε) in the system. Usually,
the solutions have essential singularities at ε = 0. The problems studied in
Chapter 7 are singular perturbation problems, since their solutions involve
terms of the form exp(it/ε). In this chapter we study problems that have
slowly varying parts and rapidly equilibrating parts—typically they include
terms of the form exp(−t/ε). In contrast to the last chapter, we do not study
highly oscillatory problems here, but only problems whose solutions are the

8. Quasistatic-State Approximations
253
sum of a (slow) quasistatic-state approximation (QSSA) and a rapid initial
transient to it.
Linear problems clearly illustrate these results from the analytic point
of view. For example, the equation
dx
dt = 1
εAx + f(t)
has its solution given explicitly by the formula
x(t) = exp
At
ε

x(0) +
 t
0
exp
A(t −s)
ε

f(s)ds.
If the eigenvalues of A are real and negative, and if ε is a small positive
number, then the kernel exp(A(t −s)/ε) behaves like a delta function in
the sense that
x(t) = eAt/ε(x(0) + εA−1f(0)) −εA−1f(t) + O(ε2A−2).
The ﬁrst and last terms are small, so as a useful approximation we write
eAt/ε ≈−εA−1δ(t)
for t ≥0 and ε near zero. This calculation also shows that the solution x(t)
is approximated by the sum of a rapidly decaying exponential (exp(At/ε))
and a slowly varying term (−εA−1f(t)). Integrals of this form are frequently
encountered in proofs of quasistatic-state approximations.
A system of ordinary diﬀerential equations, say
dz
dt = F(t, z)
where z in EM+N, might have two time scales, say t and t/ε. It is often
the case that the parameter ε can be identiﬁed and that the system can be
converted to the form
dx
dt
=
f(t, x, y, ε)
εdy
dt
=
g(t, x, y, ε),
where x, f ∈EM, y, g ∈EN, and ε is a small positive parameter. On
the other hand, it is often neither possible nor desirable to preprocess the
system to get it into this form, since the same system might have diﬀerent
time scales at various points in the state space (z). We describe an example
of this at the end of the chapter. However, we mainly study preprocessed
systems in this chapter, since we have to start somewhere.
It is important to consider only dimensionless parameters ε in these
problems; in fact, trivial changes of units, say from nanometers to meters, in
a model should not change a solution’s behavior. Dimensionless parameters
are also important in models, since they make possible comparison of results
obtained in various experimental settings [19].

254
8. Quasistatic-State Approximations
We begin with a geometric description of fast and slow time scales. This
is followed by an analysis of quasistatic states in a linear feedback sys-
tem that shows how responses on the several time scales can be “peeled
oﬀ” in succession, where behavior on the fastest scale is determined ﬁrst,
then on the next fastest, and so on. Fully nonlinear initial value problems
are studied next. We show that the fastest time response might equili-
brate to a quasistatic manifold. For example, the manifold might contain
quasistatic chaotic dynamics for which no perturbation theory gives ade-
quate approximate solutions. Still, the solutions remain near the quasistatic
manifold. Additional conditions on the manifold dynamics are shown to
ensure convergence of the solution of the perturbed problem on the in-
terval 0 ≤t ≤T ≤∞. It is shown under further conditions that the
solution of the full problem can be approximated using the method of
matched asymptotic expansions. The method of matched asymptotic ex-
pansions (MAE) [71, 120, 136, 26, 90, 132, 44, 137, 139] can be used to
construct a quasistatic-state approximation (QSSA) and its initial tran-
sients for this problem. Extensions of this approach to a variety of other
applications are discussed in later sections.
A theory of singular perturbations of nonlinear oscillations is described in
Section 8.5. This begins with Friedrichs and Wasow’s theory of quasistatic
oscillations and ends with a brief description of nearly discontinuous oscil-
lations. Boundary value problems are described next, and the chapter ends
with a description of nonlinear stability methods for static and stationary
solutions, an analysis of H2–O2 combustion, some computational schemes
based on the QSSA, and some aspects of QSSA, for randomly perturbed
systems.
8.1
Some Geometrical Examples of Singular
Perturbation Problems
It helps to have in mind a few simple pictures of singular perturbation
problems. For example, consider a system of two scalar equations
dx
dt
=
f(x, y),
x(0) = ξ,
εdy
dt
=
g(x, y),
y(0) = η,
where f and g are smooth functions and ε is a small positive parameter.
Setting ε = 0 in this system results in an algebraic equation and a
diﬀerential equation:
dx
dt
=
f(x, y),
x(0) = ξ,
0
=
g(x, y).

8.1. Some Geometrical Examples of Singular Perturbation Problems
255
 y
 x
y  =   (x  )
0
0
φ
Figure 8.1. Solution of the reduced problem.
This problem is called the reduced problem.
Solving the algebraic equation
g(x, y) = 0
may pose signiﬁcant diﬃculties, as we have seen in Chapter 4, but we
assume that there is a unique smooth function y = φ(x) such that
g(x, φ(x)) = 0
for all x. On this branch of solutions, the quasistatic problem becomes
dx
dt = f(x, φ(x)),
x(0) = ξ.
We denote the solution of this problem by x0(t), and we deﬁne y0(t) =
φ(x0(t)). If f < 0, then x0 moves to the left, as depicted in Figure 8.1.
Next, we see that the y component of the solution changes rapidly if g
is not near zero, since then
&&&&
dy
dt
&&&& = |g(x, y)|
ε
≫1.
To investigate this further, we introduce the fast time variable τ = t/ε, and
the problem becomes
dx
dτ
=
εf(x, y),
x(0) = ξ,
dy
dτ
=
g(x, y),
y(0) = η.

256
8. Quasistatic-State Approximations
 y
 x
y =    (x)
φ
(ξ ,η)
Figure 8.2. A nice singular perturbation problem. Arrows indicate the direction
that solutions move in the xy-plane. Double arrows indicate fast motions.
Setting ε = 0 in this system gives
dx
dτ
=
0,
x(0) = ξ,
dy
dτ
=
g(x, y),
y(0) = η.
Equivalently, for ε = 0 and x = ξ, we have
dy
dτ = g(ξ, y),
y(0) = η.
This is called the initial transient (or sometimes boundary layer) problem.
The value y = φ(ξ) is an equilibrium value for this equation, and if it is
stable, then we expect y →φ(ξ) as τ →∞. This happens if
gy(ξ, φ(ξ)) < 0
for all ξ, and then the solution of the full problem behaves as shown in
Figure 8.2, which we refer to as a nice singular perturbation problem.
In this chapter we determine that some problems are nice singular per-
turbation problems, and we construct approximations to their solutions.
The construction involves two steps: First, there is a special solution of the
full problem that lies near (x0(t), y0(t)), called the quasistatic state. It can
be found using the implicit function theorem. Once it is known, the initial
transient can be constructed using a Taylor’s series.
Complications arise if gy vanishes somewhere along the solution of the
reduced problem. Figure 8.3 shows a typical case, and a solution of the full
problem that encounters a fold is indicated. The complication here is that a
fast time response occurs sometime after the initial transient, at which time

8.2. Quasistatic-State Analysis of a Linear Problem
257
 y
 x
y =    (x)
φ
(ξ ,η)
Figure 8.3. A not-nice singular perturbation problem.
the reduced solution falls over a fold, and it is usually diﬃcult to locate in
time when this happens, since it depends on the system’s state. We deal
with one aspect of these problems later in this chapter, but the fact that
slow and fast time scales alternate in these problems poses a major barrier
to constructing approximate solutions.
8.2
Quasistatic-State Analysis of a Linear Problem
The general idea is that the solution of nice problems is the sum of a
slowly varying part and a rapidly dying part, and each of these parts can
be constructed separately. These can be combined to represent the full
solution by matching free constants. The problems described in this section
are ones for which the two parts of a solution can be constructed as power
series in a single small parameter. Proofs are carried out in detail for a
simple problem to indicate what steps are usually involved in validating
QSSAs. Other problems are dealt with in [71, 120, 44, 137, 41].
QSS methods can be illustrated using a linear problem without many
technical complications. In particular, consider the linear problem
dx
dt
=
Ax + By + f(t),
x(0) = ξ,
εdy
dt
=
Dy + g(t),
y(0) = η,
where x, f, ξ ∈EM, and y, g, η ∈EN. The matrices A, B, and D are
constants of appropriate dimensions, A ∈EM×M, B ∈EM×N, and so on.
Finally, we suppose that f and g have n+1 continuous derivatives on some
interval 0 ≤t ≤T.

258
8. Quasistatic-State Approximations
We will show that if a certain condition (H2) is satisﬁed, then the solution
of the original problem can be written as
x
=
x0(t) + O(ε)
y
=
−D−1g(t) + exp
Dt
ε

(η + D−1g(0)) + O(ε),
where the error estimates hold uniformly for 0 ≤t ≤T. The result is valid
for the case where T = ∞if the matrices A and D are stable, that is, if all
of their eigenvalues have negative real parts.
The quasistatic state is constructed using free constants (ξ∗(ε)) that
are chosen at a later stage in the perturbation algorithm to ensure that
matching conditions are met. The calculation of ξ∗shows that using the
initial value ξ of the full problem does not necessarily give the correct
quasistatic state beyond order ε.
8.2.1
Quasistatic Problem
The slowly varying part of the solution can be found by ﬁrst solving the
quasistatic problem and then later determining what initial conditions are
appropriate for it. The quasistatic problem is posed in a curious way: Given
any smooth function
ξ∗(ε) = ξ0 + εξ1 + · · · + εnξn + O(εn+1)
ﬁnd functions x∗and y∗such that
dx∗
dt
=
Ax∗+ By∗+ f(t),
x(0) = ξ∗(ε)
εdy∗
dt
=
Dy∗+ g(t),
and x∗, y∗are smooth function of ε for ε near zero. Note that (x∗, y∗) deﬁnes
a solution of the system of diﬀerential equations, but no initial condition is
speciﬁed for y∗; instead, we require that the solution (x∗, y∗) be expandable
in a power series in ε.
The following calculation gives evidence that this problem is solvable for
any choice of ξ∗. We set
x∗(t, ε)
=
x0 + x1ε + · · ·
y∗(t, ε)
=
y0 + y1ε + · · · ,
and we study the problems that result for the coeﬃcients in this expansion:
dx0
dt
=
Ax0 + By0 + f(t),
x0(0) = ξ0
0
=
Dy0 + g(t),

8.2. Quasistatic-State Analysis of a Linear Problem
259
and
dx1
dt
=
Ax1 + By1,
x1(0) = ξ1
dy0
dt
=
Dy1,
and so on. If D is invertible, each of these problems has a unique solution.
Slightly more is needed to make the whole process valid.
Hypothesis H1. Suppose that the matrix D can be decomposed as
D = DS +
M ′

j=1
iβjPj + DU,
where DS and −DU are stable and βj ̸= 0 for all j = 1, . . . , M ′. There
are M ′ purely imaginary eigenvalues. Moreover, we suppose that this
decomposition is orthogonal. That is, DsDU = DsPj = 0, and so on.
The numbers iβj account for the purely imaginary eigenvalues of D,
and a consequence of condition H1 is that the oscillatory part of D is
diagonalizable. With this assumption
y0 = −D−1g,
and x0 is the unique solution of
dx0
dt = Ax0 + f −BD−1g(t),
x0(0) = ξ0.
Once x0 and y0 are known, x1 and y1 are uniquely determined from the
next two equations, and so on. This calculation is justiﬁed by the following
theorem.
Linear Quasistatic-State Theorem. Suppose that f, g, and ξ∗are
smooth functions having continuous derivatives up to order n + 1 in their
arguments for 0 ≤t ≤T (T < ∞) and for ε near zero. Moreover, suppose
that D satisﬁes condition H1. Then there are functions (x∗, y∗) that solve
the quasistatic problem and
x∗(t, ε)
=
n

j=0
xj(t)εj + O(εn+1)
y∗(t, ε)
=
n

j=0
yj(t)εj + O(εn+1),
where the coeﬃcients in this expansion are determined uniquely using the
algorithm described above. The error estimate holds uniformly for 0 ≤t ≤
T.

260
8. Quasistatic-State Approximations
Proof of the Quasistatic-State Theorem. The remainders
R(t, ε) = x∗(t, ε) −
n

j=0
xj(t)εj
and
Q(t, ε) = y∗(t, ε) −
n

j=0
yj(t)εj
satisfy the equations
dR
dt
=
AR + BQ,
R(0) = O(εn+1)
εdQ
dt
=
DQ + G,
where
G = −Ddyn
dt εn+1 = O(εn+1).
The trick is in ﬁnding correct initial values for Q(0). We use Perron’s ap-
proach to stable and unstable manifolds (See Section 3.2.3). We write
Q in terms of its projection onto the stable and oscillatory modes of
D1 = D −DU (i.e., Q1) and onto the unstable modes DU (i.e., QU):
Q = Q1 + QU.
It is easy to verify that the formulas
Q1(t)
=
exp
D1t
ε

Q1(0) + 1
ε
 t
0
exp
D1(t −s)
ε

G1(s)ds
QU(t)
=
−1
ε
 τ
t
exp
DU(t −s)
ε

GU(s)ds
deﬁne a solution of the remainder system. The function Q1(0) is determined
explicitly by the algorithm, and QU(0) is given explicitly by the last formula
above. Finally, the functions G1 and GU are both of order O(εn+1), and
integrating once by parts shows that
|Q1(t)| ≤K0|Q1(0)| + K0
 t
0
|G1(s)|ds
and
|QU(t)| ≤K1
 T
t
|GU(s)|ds
for some positive constants K0 and K1. Since Q1(0) = O(εn+1), Q(t) =
O(εn+1) uniformly for 0 ≤t ≤T. Note that since Q1(0) is otherwise
arbitrary, the quasistatic problem does not necessarily have a unique
solution.

8.2. Quasistatic-State Analysis of a Linear Problem
261
The solution for R is given by the formula
R(t) = eAtR(0) +
 t
0
eA(t−s)BQ(s)ds = O(εn+1).
In this example the solution of the full problem for the remainders can be
found explicitly.
This result can be extended to the entire half-line 0 ≤t < ∞if A is a
stable matrix. In that case the upper limit in the formula for QU is replaced
by ∞, and the proof proceeds the same way.
8.2.2
Initial Transient Problem
We next derive an algorithm for determining ξ∗so that the diﬀerences
X(τ, ε) = x −x∗,
Y (τ, ε) = y −y∗
are asymptotically equal to zero (up to order n + 1) for any τ > 0, where
τ = t/ε. Moreover, we hope to ﬁnd that X(τ, ε) and Y (τ, ε) are smooth
functions of ε:
X(τ, ε)
=
X0(τ) + εX1(τ) + · · · + Xn(τ)εn + O(εn+1)
Y (τ, ε)
=
Y0(τ) + εY1(τ) + · · · + Yn(τ)εn + O(εn+1),
where the error estimates hold uniformly for 0 ≤t ≤T. The functions X
and Y are referred to as initial transients.
Since τ →∞as ε →0+, X and Y will be asymptotic to zero as ε →0+
for each t > 0 if the conditions
Xj(τ) →0
and
Yj(τ) →0
(exponentially) as τ →∞are met. These are sometimes called the matching
conditions for the problem, since they ensure that the QSS matches the
initial transient.
The functions X and Y satisfy the system
dX
dτ
=
ε(AX + BY ),
X(0) = ξ −ξ∗
dY
dτ
=
DY,
Y (0) = η −y∗(0, ε),
where ξ∗(ε) is still unknown. Therefore,
dX0
dτ
=
0,
X0(0) = ξ −ξ0
dY0
dτ
=
DY0,
Y0(0) = η + D−1g(0).
It follows that X0(∞) = 0 only if ξ0 = ξ. This shows that there is a
unique choice for ξ0. In order that no restriction be placed on ξ and that
Y0(∞) = 0, we require that the following condition holds.

262
8. Quasistatic-State Approximations
Hypothesis H2. D is a stable matrix (i.e., all of its eigenvalues have
negative real parts, so D = DS).
With this condition Y0(∞) = 0 for any choice of (ξ, η). The functions Xj
and Yj solve the problems
dXj
dτ
=
AXj−1 + BYj−1,
Xj(0) = −ξj
dYj
dτ
=
DYj,
Yj(0) = −yj(0)
for j = 1, 2, . . . . Therefore,
Yj(τ) = −exp(Dτ)yj(0)
and
Xj(τ) = −ξj −BD−1(eDτ −I)yj−1(0) + A
 τ
0
Xj−1(s)ds.
To ensure that the matching condition on Xj is satisﬁed, we specify that
ξj = BD−1yj−1(0) + A
 ∞
0
Xj−1(s)ds.
The integral in this formula exists, since Xj−1 approaches zero exponen-
tially. This can be established by a straightforward induction argument,
and so the expansion of ξ∗(ε) is found.
Initial Transient Theorem. Suppose that condition H2 is satisﬁed.
Then there is a function ξ∗(ε), uniquely determined to order O(εn+1) by
ξj, j = 0, . . . , n, such that the solution of
dX
dτ
=
ε(AX + BY ),
X(0) = ξ −ξ∗
dY
dτ
=
DY,
Y (0) = η −y∗(0, ε)
satisﬁes
X(t/ε, ε) = O(εn+1)
and
Y (t/ε, ε) = O(εn+1)
for each 0 < t ≤T as ε →0+ (note that t = 0 is not included here).
Moreover, these functions have uniquely determined Taylor expansions up
to order n + 1, as derived in the last paragraph.

8.2. Quasistatic-State Analysis of a Linear Problem
263
Proof of the Initial Transient Theorem. Let the functions Xj, Yj be
determined from the algorithm of the last paragraph, and let
R(t, ε)
=
X
 t
ε, ε

−
N

j=0
Xj
 t
ε

εj
Q(t, ε)
=
Y
 t
ε, ε

−
n

j=0
Yj
 t
ε

εj.
These functions satisfy the equations
dR
dt
=
AR + BQ
R(0) = O(εn+1)
εdQ
dt
=
DQ
Q(0) = O(εn+1).
Integrating these equations, we have
Q(t) = exp
Dt
ε

O(εn+1)
and
R(t)
=
eAtO(εn+1) +
 t
0
eA(t−s′)BeDs′/εO(εn+1)ds′
=
O(εn+1).
This completes the proof of the Initial Transient Theorem.
Again, note that the result is valid for T = ∞if the matrix A is stable.
8.2.3
Composite Solution
The results of these calculations show that if condition H2 is satisﬁed, then
the solution of the original problem can be written as
x(t, ε)
=
x∗(t, ε) + X(t/ε, ε)
y(t, ε)
=
y∗(t, ε) + Y (t/ε, ε),
where the quasistatic state (x∗, y∗) and the initial transient (X, Y ) can be
expanded in series in ε that are uniquely determined up to order εn+1. In
particular,
x
=
x0(t) + O(ε)
y
=
−D−1g(t) + exp
Dt
ε

(η + D−1g(0)) + O(ε),
where the error estimates hold uniformly for 0 ≤t ≤T. The result is valid
for the case where T = ∞if the matrix A is stable.

264
8. Quasistatic-State Approximations
In summary, the quasistatic state is constructed using free constants
(ξ∗(ε)) that are chosen at a later stage to ensure that the matching con-
ditions are met. The calculation of ξ∗shows that using the initial value ξ
of the full problem is not necessarily the correct choice for the quasistatic
state beyond the ﬁrst term.
8.2.4
Volterra Integral Operators with Kernels Near δ
The calculation in the proof of the Initial Transient Theorem highlights an
important aspect of singular perturbations. Namely, the integrals involved
have kernels that are quite like delta functions. To see this, consider the
Volterra integral formula
g(t) = 1
ε
 t
0
k
t −s
ε

f(s)ds,
where the kernel is k and ε is a small positive parameter. We suppose
that f and f ′ are smooth and bounded functions and that k(t) and K(t) =
 ∞
t
k(s)ds are both integrable functions. Then g can be approximated using
integration by parts:
g(t) = 1
ε
 t
0
k
s
ε

f(t −s)ds = K(0)f(t) +
 t
0
K
s
ε

f ′(t −s)ds,
so
g(t) = K(0)f(t) + o(1)
as ε →0. Thus, we write (1/ε)k((t −s)/ε) ∼K(0)δ(t −s).
8.3
Quasistatic-State Approximation for Nonlinear
Initial Value Problems
Consider the initial value problem
dx
dt
=
f(t, x, y, ε),
x(0) = ξ(ε)
(8.4)
εdy
dt
=
g(t, x, y, ε),
y(0) = η(ε),
where x, f ∈EM, y, g ∈EN, and ε is a small positive parameter.
We consider a domain Ω= I × BR × BR′ × [0, ε0], where I = {t : t0 ≤
t ≤T ≤∞}, BR = {x in EM : |x| ≤R}, BR′ = {y in EN : |y| ≤R′}, and
T and ε0 are some ﬁxed constants. In what follows, the balls BR and BR′
can be replaced by any sets that are diﬀeomorphic to them. We suppose
next that the following condition holds.

8.3. Quasistatic-State Approximation for Nonlinear Initial Value Problems
265
Hypothesis H3. f and g are C2(Ω), and any solution of the system
(8.4) beginning in BR × BR′ remains there for t0 ≤t ≤T.
Setting ε = 0 in this system gives
dx
dt
=
f(t, x, y, 0),
x(0) = ξ(0)
(8.5)
0
=
g(t, x, y, 0),
which we refer to as the reduced problem. In the following subsection we
place successively more restrictive conditions on the system and obtain as
a result more information about solutions.
8.3.1
Quasistatic Manifolds
We begin with the least restrictive result.
Hypothesis H4. Suppose there is a function y = Φ(t, x) such that
g(t, x, Φ(t, x), 0) = 0 for t0 ≤t ≤T and x in BR. Moreover, this function
is smooth, Φ ∈C2(I × BR), and it has no folds, that is, we suppose that
det(Φx(t, x)) ̸= 0 for (t, x) in I × BR.
We deﬁne the manifold
M = {(t, x, Φ(t, x)) : (t, x) in I × BR},
which we refer to as the quasistatic, or reduced, manifold.
Next, we suppose that the quasistatic manifold is stable:
Hypothesis H5. The system of equations
dY
dτ = g(α, β, Y, 0)
has Y = Φ(α, β) as an equilibrium for each (α, β) in I × BR. We suppose
that this equilibrium is asymptotically stable uniformly in the parameters
(α, β) in I × BR. That is, there is a comparison function a; a positive,
monotonically decreasing function d for which d(∞) = 0; and a posi-
tive constant δ such that if |Y (τ0) −Φ(α, β)| < δ, then the corresponding
solution Y (τ, α, β) exists and satisﬁes
|Y (τ, α, β) −Φ(α, β)| ≤a(|Y (τ0) −Φ(α, β)|)d(τ −τ0)
for 0 < τ0 ≤τ < ∞.
With these conditions we have the following lemma:
Lemma. If conditions H3, H4, and H5 are satisﬁed, then there is a
function W(α, β, Y ) such that
1. W is twice continuously diﬀerentiable on I × BR × BR,
2. a(|y −Φ(α, β)|) ≤W(α, β, y) ≤b(|y −Φ(α, β)|),

266
8. Quasistatic-State Approximations
3. g(α, β, y, 0) · ∇yW(α, β, y) ≤−c(|y −Φ(α, β)|),
where a, b, and c are comparison functions that are independent of (α, β)
in I × BR.
This lemma is proved in [70]. The proof is quite similar to that created
by Massera [108] to construct Liapunov functions (see Chapter 3). The
function W is a Liapunov function for the quasistatic manifold, and it
serves as the basis for proving the following theorem:
Quasistatic Manifold Theorem. Suppose that conditions H3, H4, and
H5 are satisﬁed, and let the initial condition be such that η is in the domain
of attraction of Φ(t0, ξ0) for the system in H5 with α = t0 and β = ξ0.
Then for each small ε, there is a unique solution of Equations (8.4) for
t0 ≤t ≤T. Moreover, the solution satisﬁes
dist(y, M) = o(1)
as ε →0+
uniformly on any interval of the form t0 ≤t1 ≤t ≤T, that is, one not in-
cluding the initial time t0. This result holds for any nearby (Carath´eodory)
system as well.
The result is not proved here (see [70]). However, the main idea is to
use the function W to deﬁne a “sticky” layer that encloses the set M. The
derivative of W along a solution of Equations (8.4) is
εdW
dt = ∇W · g + ε∂W
∂t + ε∇W · f.
The argument proceeds as it did for stability under persistent disturbances.
Since the last two terms are O(ε), there is a level set of W that is of diameter
o(1) (for small ε) and that deﬁnes an attractive and invariant layer about
M.
Example. Lorenz’s system of equations [104] comprises three equations
for the amplitudes of dominant modes in the convective ﬂow of a ﬂuid
in a toroidal container that is heated from below. These equations were
extracted from among all possible modes by an assumption that the system
of three amplitude equations is closed. In fact, the system is embedded in
a system of higher dimension, which we illustrate here with the following
system in E4:
dx1
dt
=
x2x3 −bx1 + εf1(t, x, y, ε)
dx2
dt
=
−x1x3 + rx3 −x2 + εf2(t, x, y, ε)
dx3
dt
=
σ(x2 −x3) + εf3(t, x, y, ε)
dy
dt
=
λy −y3 + εg(t, x, y, ε),

8.3. Quasistatic-State Approximation for Nonlinear Initial Value Problems
267
where f1, f2, f3, and g are Carath´eodory functions. The quasistatic mani-
fold (y = O(
√
λ) + O(ε)) can be constructed when λ and ε are near zero.
When ε = 0, the system reduces to Lorenz’s system, which is known to be
chaotic for various choices of b, r, and σ. In this case, if λ is near 0, then
W(y) = y2, and the previous theorem shows that the solutions remain near
the quasistatic manifold for all t > 0. Since the dynamics on the manifold
are chaotic, we cannot expect the solution of the full problem to remain near
any one particular solution of the reduced problem for ﬁxed t as ε →0+.
The same result can be extended to vectors y, even inﬁnite dimensional
ones, using methods derived in [51]. This completes the example.
Let (x0, y0) denote the solution of the reduced problem (8.5) with y0(t) =
Φ(t, x0(t)), and we have the following corollary.
Corollary. If the conditions of the previous theorem are satisﬁed, if T <
∞, and if the solution of the reduced problem (x0(t), y0(t)) exists for t0 ≤
t ≤T, then on any interval of the form t0 < t1 ≤t ≤T, for suﬃciently
small ε, the solution of the full problem (8.4), (x(t), y(t)), exists, and it
satisﬁes
x(t) = x0(t) + o(1),
y(1) = Φ(t, x0(t)) + o(1)
uniformly as ε →0+.
The proof of this result follows from the observation that the the-
orem gets this solution near (x0(t1), y0(t1)), and the solutions depend
continuously on the data to leading order in ε (see [70] for details).
We next place stability conditions on motions in the quasistatic manifold.
Hypothesis H6. Suppose now that the system (8.5) dx0/dt = f(t, x0,
Φ(t, x0), 0) has a solution for t0 ≤t < ∞, say x∗(t), and it is uniformly
asymptotically stable. Furthermore, suppose that ξ0 is in the domain of
attraction of x∗.
With this additional condition, we have the following theorem.
Quasistatic-State Theorem. Let conditions H3, H4, H5, and H6 be
satisﬁed. Then, for suﬃciently small values of ε, the solution of (8.4) exists
for t0 ≤t < ∞, and it satisﬁes
(x, y) = (x0(t), Φ(t, x0(t))) + o(1)
as ε →0+, uniformly on any interval of the form t0 < t1 ≤t < ∞.
Moreover, this result holds for any nearby (Carath´eodory) system.
Sketch of Proof. Condition H6 implies that there is a Liapunov function
V (t, x) for which
1. V (t, x∗(t)) = 0.

268
8. Quasistatic-State Approximations
2. There are comparison functions a1 and b1 such that
a1(|x −x∗|) ≤V (t, x) ≤b1(|x −x∗|)
for x near x∗(t).
3. There is a comparison function c1 such that
∂V
∂t + ∇V (t, x) · f(t, x, Φ(t, x), 0) ≤−c1(|x −x∗(t)|)
for 0 ≤t < ∞and x near x∗(t).
The derivative of V along solutions of (8.4) is
dV
dt = ∂V
∂t + ∇V (t, x) · f(t, x, y, ε).
If y = Φ(t, x) + o(1) (as from the previous theorem), then
dV
dt ≤−c1(|x −x∗(t)|) + o(1).
Proceeding as for stability under persistent disturbances in Section 3.4, we
see that there is a level set of V , having diameter o(1) as ε →0+, that is
attractive and invariant. This combined with the Quasistatic Manifold The-
orem shows that there is a “sticky tube” about (x0(t), Φ(t, x0(t))). Details
of these proofs are given in [70].
As an example of this result we consider the system
dx
dt
=
−x3 + εf(t, x, y, ε)
εdy
dt
=
−y3 + εg(t, x, y, ε),
where f and g are Carath´eodory functions. The functions V = x2 and
W = y2 are the desired Liapunov functions, and so the result applies to
this system, namely,
(x(t), y(t)) = (0, 0) + o(1)
for each t > 0.
8.3.2
Matched Asymptotic Expansions
We turn now to approximating the solutions of system (8.4). For this we
require a condition that is similar to invertibility in the implicit function
theorem.
Denote by gy(t) the Jacobian matrix
gy(t) =
 ∂gi
∂yj
(t, x0(t), y0(t), 0)


8.3. Quasistatic-State Approximation for Nonlinear Initial Value Problems
269
for i, j = 1, . . . , N.
Hypothesis H7. Suppose that system (8.5) has a smooth solution
(x0(t), y0(t)) and all of the eigenvalues of the matrix
gy(t)
satisfy Re λ(t) ≤−δ < 0 on some ﬁnite interval 0 ≤t ≤T.
Next, we suppose that the data are smooth near the solution of the
reduced problem.
Hypothesis H8. The functions f and g have continuous derivatives up
to order n+2 with respect to their arguments in some neighborhood of the
points (t, x0(t), y0(t)), 0 ≤t ≤T, and for 0 ≤ε < ε0. Also, the initial data
(ξ(ε), η(ε)) are smooth functions of ε for 0 ≤ε < ε0.
With these conditions we have the main theorem of this section:
Quasistatic-State Approximation Theorem. Let conditions H3, H4,
H7, and H8 be satisﬁed. Then there is a neighborhood U of (x0(0), y0(0))
such that for each small ε > 0 the problem (8.4) has a unique solution for
0 ≤t ≤T, provided that (ξ, η) ∈U. Moreover, there is a quasistatic state
x∗(t, ε), y∗(t, ε) and an initial transient X(τ, ε), Y (τ, ε) such that
x(t, ε)
=
x∗(t, ε) + X
 t
ε, ε

y(t, ε)
=
y∗(t, ε) + Y
 t
ε, ε

for 0 ≤t ≤T and each small ε > 0. The quasistatic state has the form
x∗(t, ε)
=
n

j=0
xj(t)εj + O(εn+1)
y∗(t, ε)
=
n

j=0
yj(t)εj + O(εn+1),
where the error estimates hold uniformly for 0 ≤t ≤T, and the initial
transient has the form
X
 t
ε, ε

=
n

j=0
Xj
 t
ε

εj + O(εn+1)
Y
 t
ε, ε

=
n

j=0
Yj
 t
ε

εj + O(εn+1),

270
8. Quasistatic-State Approximations
where the error estimates hold uniformly for 0 ≤t ≤T as ε →0. Finally,
there are positive constants K, α, and ε′
0 such that
|X(τ, ε)| + |Y (τ, ε)| ≤K|η(ε) −y∗(0, ε)| exp(−ατ)
for 0 ≤τ ≤T/ε and 0 < ε ≤ε′
0.
The proof of this result is presented in [71], and it is not presented
here. However, the ﬁrst steps in the proof require constructing Taylor’s
expansions listed in the theorem. Once these have been derived, the proof
is completed by obtaining integral equations for the remainders that are
the diﬀerences between the solution of the full problem and the proposed
approximations, and then showing that they have unique solutions that are
of order O(εn+1). This proof was carried out in detail for linear systems in
Section 8.2.
Vasil’eva and O’Malley [120, 137] developed a method of matched asymp-
totic expansions to solve problem (8.4), and it is from their work that the
present approach grew. Their algorithm is described in [137, 138]. Other re-
ﬁnements and extensions of their method were carried out by their students
and colleagues (see [71]). Roughly, their approach entails the construction
of three expansions, an outer one, an inner one, and a third one used to
match these two. The inner and matching expansions are combined here in
the initial transient of the QSS method. The matching approach has proved
to be quite useful in studying a variety of problems, and [120, 26] describe
many features of the method and its origins and uses in ﬂuid mechanics
and elasticity.
8.3.3
Construction of QSSA
The coeﬃcients in the expansion of the quasistatic state are found by
solving problem (8.5) for x0 and y0, and then for j = 1, . . . , n, by solving
dxj
dt
=
fxxj + fyyj + pj(t),
xj(0) = ξ∗
j
dyj−1
dt
=
gxxj + gyyj + qj(t),
where for each j the functions pj and qj depend on the coeﬃcients xk, yk,
for k = 0, . . . , j −1. The initial condition for xj (i.e., ξ∗
j ) is determined
at a later step by the matching conditions. These n problems have unique
solutions.
The expansion of the initial transient is determined by solving for j = 0
dX0
dτ
=
0,
X0(0) = ξ0 −ξ∗
0
dY0
dτ
=
g(0, X0, Y0, 0),
Y0(0) = η0 −y∗(0, 0),

8.3. Quasistatic-State Approximation for Nonlinear Initial Value Problems
271
and for j = 1, . . . , n by solving
dXj
dτ
=
Pj(τ),
Xj(0) = ξj −ξ∗
j
dYj
dτ
=
gxXj + gyYj + Qj(τ),
Yj(0) = ηj −y∗
j (0).
The functions Pj and Qj are determined by the previous coeﬃcients Xk, Yk
for k = 1, . . . , j −1.
The values of ξ∗
j are determined at each step to ensure that the matching
conditions Xj(∞) = 0, Yj(∞) = 0 are satisﬁed. These are given by the
formulas
ξ∗
j =
 ∞
0
Pj(τ ′)dτ ′ + ξj.
Each of these n problems has a unique solution. In this way, the expansions
in the theorem are found.
8.3.4
The Case T = ∞
The results of the QSSA Theorem are valid over the entire half-line 0 ≤
t < ∞if the reduced problem satisﬁes additional stability conditions. We
now assume the following.
Hypothesis H9. The solution of the reduced problem (x0, y0) exists
and remains bounded for all 0 ≤t < ∞, and the linear problem
dx
dt = [fx(t) −fy(t)g−1
y (t)gx(t)]x
has x = 0 as an exponentially asymptotically stable solution.
If condition H9 is added to the hypotheses of the QSSA Theorem with
T = ∞, then the results of that theorem are valid for 0 ≤t < ∞. In
particular, the quasistatic state and the initial transient can be expanded
in powers of ε as indicated there, and the error estimates hold as ε →0+
uniformly for 0 ≤t < ∞. This extension of the QSSA Theorem is proved
in [71].
Example of the Michaelis–Menten Approximation. A simple en-
zyme reaction involves an enzyme E, a substrate S, a complex C, and
a product P. Such reactions were studied by Michaelis and Menton and
by Haldane and Briggs [14]. Their work is widely used in biochemistry.
Schematically, the reaction is
E + S ↔C ↔E + P.
The forward reactions dominate the backward ones. After some prelimi-
nary scaling to remove dimensions from the problem, this reaction can be

272
8. Quasistatic-State Approximations
described by a system of diﬀerential equations for the (normalized) sub-
strate concentration (x) and the (normalized) complex concentration (y)
as
dx
dt
=
−x + (x + k)y,
x(0) = 1
εdy
dt
=
x −(x + K)y,
y(0) = 0,
where ε measures a typical ratio of enzyme to substrate concentration
(O(10−5)) and k and K (k < K) denote normalized (nondimensional)
rate constants.
The QSS method shows that the reduced problem is
dx0
dt = (k −K)x0
(K + x0)
with the initial condition x0(0) = 1, and
y0 = x0/(K + x0).
The rapid transient is determined from the equation
dY0
dτ = −(1 + K)Y0,
Y0(0) = −
1
1 + K .
Moreover, since the equation for x0 is exponentially stable, we conclude
that the approximation
x
=
x0(t) + O(ε)
y
=
y0(t) + Y0(t/ε) + O(ε)
is valid uniformly for 0 ≤t < ∞.
This approximation is known as the Michaelis–Menten approximation.
The equation
dx0
dt = (k −K)x0
K + x0
gives the quasistatic approximation to this reaction, and while the rate
equations are based on the law of mass action, this equation seems to
involve a more complicated rate law. In biochemistry Vmax = K −k is
called the uptake velocity or maximum reaction rate, and K is the reac-
tion’s saturation constant. These two constants are used by biochemists to
characterize enzyme action.

8.4. Singular Perturbations of Oscillations
273
 y
 x2
 x1
    = 0
 g
Figure 8.4. Cusp.
8.4
Singular Perturbations of Oscillations
Let us now consider the time-invariant problem
dx
dt
=
f(x, y, ε)
εdy
dt
=
g(x, y, ε).
A particularly interesting problem arises when the reduced problem
dx0
dt
=
f(x0, y0, 0)
0
=
g(x0, y0, 0)
has a stable oscillation. Two interesting questions in this case are whether
the full problem has a stable oscillation near this reduced one, and whether
the period of this solution is near the reduced oscillation’s period.
It is useful to keep an example in mind, say
dx1
dt
=
f1(x, y, ε)
dx2
dt
=
f2(x, y, ε)
εdy
dt
=
g(x, y, ε),
in E3, where g has the form of a cusp:
g(x, y, ε) = −y3 + x1y −x2 + εG(x, y, ε).
We see that when ε = 0, the solutions of the reduced problem lie on a cusp
surface, as shown in Figure 8.4.

274
8. Quasistatic-State Approximations
 y
 x2
 x1
     =  0
 g 
 Stable oscillation for   = 0
 Reduced oscillation
ε /
Figure 8.5. Quasistatic oscillation.
Two interesting cases are described here. In the ﬁrst, we suppose that
there is a stable oscillation of the reduced problem that does not hit one of
the bifurcation curves (i.e., folds) of the cusp surface. Such an oscillation
is referred to as a quasistatic oscillation, and a typical case is depicted in
Figure 8.5. In the second, we consider an oscillation that is draped over a
fold in the surface, similar to the one shown in Figure 8.6.
8.4.1
Quasistatic Oscillations
There is an interesting class of oscillation problems in which a periodic
solution can be constructed as a quasistatic solution. In the cusp example,
these are solutions that lie near a reduced oscillation that is on one branch
of the cusp surface, as shown in Figure 8.5. Because of this, computation
of approximation solutions is quite transparent.
Consider the system of equations
dx
dt
=
f(x, y, ε)
εdy
dt
=
g(x, y, ε),
where x, f ∈EM and y, g ∈EN. We suppose that f and g are smooth func-
tions of their variables in some region of EM+N, and we restrict attention
to that region.
The results of this section are based on the reduced problem
dx
dt
=
f(x, y, 0)
0
=
g(x, y, 0)

8.4. Singular Perturbations of Oscillations
275
 y
 x2
 x1
    = 0
 g
Figure 8.6. A nearly discontinuous oscillation.
having a periodic solution, say (x0, y0), with period T0. Conditions are
found that ensure the existence of a nearby periodic solution of the full
problem and that it can be constructed. The construction involves only a
quasistatic solution of the problem, and so it is quite straightforward.
As we have seen with other time-invariant problems, we must expect the
perturbed problem to have a periodic solution with period slightly diﬀerent
from T0. Therefore, we introduce an unknown time scaling
t = T(ε)s
into the problem with the result that
dx
ds
=
T(ε)f(x, y, ε)
εdy
ds
=
T(ε)g(x, y, ε).
If the quasistatic solution is periodic, we can construct the oscillation in
the form
x
=
x0(s) + x1(s)ε + x2(s)ε2 + · · ·
y
=
y0(s) + y1(s)ε + y2(s)ε2 + · · · .
In addition to ﬁnding the coeﬃcients in these expansions, we must also show
how the t-period T(ε) is to be chosen. The equations for the coeﬃcients
are
dx0
ds
=
T0f(x0, y0, 0)
0
=
T0g(x0, y0, 0),

276
8. Quasistatic-State Approximations
all of which are known, and for j = 1, 2, . . . ,
dxj
ds
=
Tj
dx0
ds + T0(fxxj + fyyj) + pj
dyj−1
ds
=
T0(gxxj + gyyj) + qj,
where the functions pj and qj depend on xk, yk, and Tk for k = 0, . . . , j−1.
Here the functions gx, and so on, denote Jacobian matrices of derivatives,
(∂gi/∂xk)(x0, y0, 0), and so forth.
Hypothesis H10. Suppose the reduced problem has a periodic solution,
x0, y0 = Φ(x0(t)), say with period T0, and the matrix gy(x, y, 0) is stable
for (x, y) near (x0, y0).
With this assumption we can solve the second equation for yj, and so
the problem reduces to one for xj:
dxj
ds = Tj
dx0
ds + A(s)xj + Pj(s),
where Pj is a one-periodic function of s that depends on terms with index
k, k < j, and the matrix A is periodic of period 1 given by the formula
A(s) = T0(fx −fyg−1
y gx).
Note that dx0/ds is a periodic solution of the linear problem
du
ds = A(s)u.
Therefore, there is a deﬁciency in the number of independent state variables
that is made up for by the presence of the period’s coeﬃcients, similar to
the situation in studying stability and regular perturbations of periodic
solutions to autonomous systems (see Sections 3.5.4 and 6.1.2).
Hypothesis H11. Suppose the linear problem
du
ds = A(s)u
has exactly one characteristic exponent of the form 2πi ˆN for some integer
ˆN.
With this, as before, there is a unique choice of Tj such that each of
the problems for x1, . . . , xn has a periodic solution of period T0. There
remains a free constant in xj that corresponds to the initial phase, but
that can be ﬁxed by taking the ﬁrst component of xj to be zero. With such
a condition, xj is uniquely determined. This calculation is justiﬁed by the
following theorem.
Friedrichs–Wasow Theorem. Suppose that conditions H10 and H11
are satisﬁed and that the functions f and g are smooth near (x0, y0). Then,

8.4. Singular Perturbations of Oscillations
277
for suﬃciently small ε > 0 there is a unique periodic solution of the full
problem with period T(ε) which lies near (x0, y0). Moreover, T(ε) = T0 +
O(ε). This solution is orbitally asymptotically stable if (x0, y0) is also.
The proof of this result follows directly from the construction of the peri-
odic quasistatic state. Again, remainders are deﬁned and integral equations
are derived for them. The proof is presented in [139].
Example of the Friedrichs–Wasow Theorem. The example stud-
ied in this section uses some results from our earlier work on averaging.
Consider the system in E3
du
dt
=
−λv + µ

u −u3
3

+ εf(u, v, y, ε, µ)
dv
dt
=
λu + εF(u, v, y, ε, µ)
εdy
dt
=
−Dy + g(u, v) + εG(u, v, y),
where u and v are scalars, y, g, G ∈EN, λ is a ﬁxed frequency, and µ is
a ﬁxed small (positive) number in this system. We will consider the case
where
0 < ε ≪µ ≪1.
Setting ε = 0 in this system gives
du0
dt
=
−λv0 + µ

u0 −u3
0
3

dv0
dt
=
λu0
Dy0
=
g(u0, v0).
We see that the ﬁrst two equations reduce to van der Pol’s equation, which
we studied in Sections 2.1.3 and 7.4.2. In particular,
u0(t)
=
r(µt) cos λt + O(µ)
v0(t)
=
r(µt) sin λt + O(µ),
where r(∞) = 2. The third equation is easily solved if D is invertible. In
fact, let us suppose that −D is a stable matrix (i.e., all of its eigenvalues
have negative real parts). Then
y0(t) = D−1g(r(µt) cos λt + O(µ), r(µt) sin λt + O(µ)).
This reduced solution is orbitally asymptotically stable, since solutions ap-
proach the quasistatic manifold at an exponential rate determined by the
eigenvalues of −D and solutions in the manifold approach van der Pol’s
oscillation.

278
8. Quasistatic-State Approximations
A periodic quasistatic state can be constructed for this system, but rather
than proceeding with this result, we simply apply the Friedrichs–Wasow
Theorem and obtain an easy approximation to this oscillation by using the
ﬁrst terms of the quasistatic state:
u
=
2 cos(λt) + O(µ) + O(ε)
v
=
2 sin(λt) + O(µ) + O(ε)
y
=
D−1g(2 cos(λt), 2 sin(λt)) + O(µ) + O(ε).
If we wish to include the rapid transients in this approximation, we use the
quasistatic state approximation and write
u(t, ε)
=
r(µt) cos(λt) + O(µ) + O(ε)
v(t, ε)
=
r(µt) sin(λt) + O(µ) + O(ε)
y(t, ε)
=
D−1g(r(µt) cos(λt), r(µt) sin(λt))
+ exp(−Dt/ε)[y(0) −y0(0)] + O(µ) + O(ε).
In this way we quickly derive an approximation to the solution of a quite
complicated system of equations.
It is interesting to pursue a slightly diﬀerent approach to the problem—
one that enables us to calculate the period of the oscillation. Let us return
to the original problem
du
dt
=
−λv + µ

u −u3
3

+ εf(u, v, y, ε, µ)
dv
dt
=
λu + εF(u, v, y, ε, µ)
εdy
dt
=
−Dy + g(u, v) + εG(u, v, y),
and let us introduce polar coordinates in the ﬁrst two equations: Let
√
3u
=
ρ cos φ
√
3v
=
ρ sin φ.
This results in the new system
dρ
dt
=
µρ cos2 φ(1 −ρ2 cos2 φ) + O(ε)
dφ
dt
=
λ −µ sin φ cos φ(1 −ρ2 cos2 φ) + O(ε)
εdy
dt
=
−Dy + ˜g(ρ cos φ, ρ sin φ) + ε ˜G(ρ cos φ, ρ sin φ, y).
Since φ is a timelike variable, we can write
dρ
dφ
=
µρ cos2 φ1 −ρ2 cos2 φ
λ
+ O(µ2) + O(ε)
ε dy
dφ
=
−Dy + ˜g(ρ cos φ, ρ sin φ)
λ
+ O(µ2) + O(ε).

8.4. Singular Perturbations of Oscillations
279
The QSS Theorem can be applied directly to this system to construct its
quasistatic state. Once this is done, we return to compute the period of the
quasistatic state by solving the equation
dφ
λ −µ sin φ cos φ(1 −ρ2 cos2 φ) + O(ε) = dt.
In particular, we have that
dt =
dφ
λ + O(µ, ε),
and so
T(ε, µ) = 2π
λ + O(µ, ε).
The higher order corrections to the period can be calculated directly by
using the corresponding corrections in the integral deﬁning T.
This last calculation clears up the confusion about having one too few
state variables that often results. When a time-invariant system is converted
to phase-amplitude coordinates, the natural time scale for solutions is the
new phase variable, not t, and the period T results from converting from the
period in the phase variable, for example 2π in the case of polar coordinates,
to 2π/λ in t.
8.4.2
Nearly Discontinuous Oscillations
Let us now brieﬂy consider the case where the system
dx
dt
=
f(x, y, 0)
0
=
g(x, y, 0)
has a periodic solution along which condition H1 is not satisﬁed.
Speciﬁcally, we suppose that the following assumption is satisﬁed.
Hypothesis H12. The reduced problem has a discontinuous solution of
period T0, and det(gy(x0(t), y0(t), 0)) ̸= 0 for all but a ﬁnite set of t values.
We suppose that gy(t, x0(t), y0(t), 0) is stable away from these points.
The problem now is similar to that depicted in Figure 8.6, and it is
signiﬁcantly more diﬃcult than the preceding case.
Oscillations of this kind were studied by van der Pol, Cartwright, and Lit-
tlewood [17], Levinson [100], Pontryagin [123], Mishchenko [113], Kevorkian
and Cole [90], Stoker [132], and Grasman [53], among others. They are
often called relaxation oscillations. Unfortunately, there is no result com-
parable to the Friedrichs–Wasow Theorem to ensure the existence of stable
oscillations in this case, except for special cases including the ones cited
above.

280
8. Quasistatic-State Approximations
The t values at which gy vanishes are called turning points, and there is
an extensive theory for constructing solutions near them (see [26, 139, 123,
113]). Rather than pursuing a vague general discussion of these problems,
we turn to a speciﬁc, well-studied example.
van der Pol’s equation has been studied extensively, so it provides a useful
guide to solving other nearly discontinuous oscillation problems. Consider
the equation
εd2x
dt2 + (x2 −1)dx
dt + x = 0,
where ε is a small positive parameter. It is useful to rewrite this equation
as a ﬁrst-order system of equations by integrating it once. The result is
εdx
dt
=
x −x3
3 −y
dy
dt
=
x.
Four questions about this equation that have been answered are as
follows:
1. Does this equation have a periodic solution for small values of ε?
2. If so, what is its period?
3. How can such an oscillation be constructed?
4. What is the response of this oscillator to external periodic forcing?
The ﬁrst question is answered by our work in Section 3.5 on Lienard’s
equation. There is a unique periodic solution to this equation for any choice
of the parameter ε, and it is globally asymptotically stable.
The phase portrait of this solution is shown in Figure 8.7, where ε ≪1.
The isocline dx/dt = 0 has been drawn in this portrait for reference. For
small ε the oscillation remains quite close to the cubic x isocline except at
the jump (or turning) points. The jumps are traversed quite rapidly, in a
time of order ε (double arrow).
The period can be approximated by observing that most of the time is
spent near the cubic curve. This is described by the reduced problem for
this system,
dx0
dt =
x0
(1 −x2
0),
and the part of this solution lying near half of the oscillation occurs for 1 <
x0 < 2. Therefore, the transit time of this branch is given (approximately)
by
T0 = 2
 1
2
1 −x2
x
dx = 3 −2 ln 2.

8.5. Boundary Value Problems
281
 x
 y
 dx/dt = 0
Figure 8.7. Depiction of van der Pol’s relaxation oscillation, ε ≪1. This
shrink-wraps onto the isocline as ε →0+.
It follows that the period is given by
T ≈3 −2 ln 2 + o(1)
as ε →0. In fact, further work (which is not presented here, see [139])
shows that
T = 3 −2 ln 2 + 7.014ε2/3 −0.167ε ln ε −1.325ε + O(ln ε/ε).
The third question is more diﬃcult to answer, and it is not addressed
here, but the details of the construction can be found in [26]. Finally, the
response of this oscillator to external periodic forcing can be chaotic. The
computer simulation in Section 6.3.2 describes the responses. This was
derived in [38], where further references can be found (see also [17, 100, 53]).
8.5
Boundary Value Problems
Singularly perturbed boundary value problems arise in many important
applications. As we have seen, ﬁnding periodic solutions entails solving a
problem with boundary conditions (e.g., x(0) = x(T)). Models for spatial
structure on whose boundaries physical parameters are set, such as tem-
perature, pressure, ﬂow, electrical current, and so on, and many control
problems are boundary value problems (see, e.g., [120]). An understand-
ing of the role played by ε in these problems is helped by understanding
the geometric structure of solutions. Rather than developing a complete
boundary-layer theory here, we study an interesting example that gives

282
8. Quasistatic-State Approximations
the ﬂavor of how the QSS analysis can be used to solve boundary value
problems.
A Josephson junction is a cryogenic device consisting of two supercon-
ductors separated by a thin gap [98]. The electrodynamics of this device
are described in terms of a quantum mechanical wave function that is
quite similar to the phase variable used to describe VCOs. A jump occurs
in the wave function across the gap, and it is denoted by u(x, t), where
x, 0 ≤x ≤1, describes the location along the gap and t is time. The
sine–Gordon equation is satisﬁed by u:
∂2u
∂t2 + σ ∂u
∂t −ε2 ∂2u
∂x2 + sin u = 0
for 0 ≤x ≤1 and t ≥0.
A magnetic ﬁeld of strength proportional to H is applied at both ends,
and the device is driven by a current I applied at the right end. These
conditions are described by the boundary conditions
∂u
∂x(0, t) = H,
∂u
∂x(1, t) = H + I.
The static states of this conﬁguration are found by solving the problem
ε2 d2u
dx2 −sin u = 0
with the boundary conditions
du
dx(0) = H,
du
dx(1) = H + I.
We consider here only the case where ε ≪1.
We rewrite this problem as a ﬁrst-order system of equations
εdu
dx
=
v
εdv
dx
=
sin u,
where now v(0) = εH and v(1) = ε(H + I). We must construct a solution
of this system that lies on the line v = εH at x = 0 and meets the line
v = ε(H + I) when x = 1.
A candidate for a quasistatic solution is u = 0, v = 0. We test this by
trying to construct correcting (transients) at both endpoints (x = 0 and
x = 1) that connect the boundary conditions to this quasistatic state. We
ﬁrst seek a left boundary-layer correction u = εU(x/ε), v = εV (x/ε) such
that
V (0) = H
and
(U(ξ), V (ξ)) →(0, 0)
as ξ →∞.

8.5. Boundary Value Problems
283
 v
 u
 v=  H
ε
Starting
Point
 v
 u
 Terminus
 v=  (H+I)
ε
QSS
   = 0
   = 1
x
x
Figure 8.8. Geometry of solutions to the boundary value problem.
The problem for (U, V ) is
dU
dξ
=
V
dV
dξ
=
1
ε sin εU = U + O(ε).
Figure 8.8 shows the phase portrait of solutions.
U and V can be constructed in power series in ε, U = U0 + εU1, and so
on. We see that there is a unique solution for (U0, V0) that satisﬁes these
two conditions: It is
U0(ξ) = −He−ξ,
V0(ξ) = He−ξ.
This starts at the intersection of the stable manifold for (0, 0) and the
constraint V = H.
Next, we construct the right boundary correction. Let η = (1−x)/ε. Then
η = 0 corresponds to x = 1, and η →+∞corresponds to (1 −x)/ε →∞,
so η represents a fast scale that moves backward from x = 1. The problem
for u = εU(η) and v = εV(η) is
dU
dη = −V
dV
dη = −1
ε sin εU = −U + O(ε)
V(0) = H + I
and
(U(η), V(η)) →(0, 0)
as η →∞.

284
8. Quasistatic-State Approximations
This can be constructed in a power series in ε. As before, we see that there
is a unique solution for U0(η), V0(η):
U0(η) = (H + I)e−η,
V0(η) = (H + I)e−η.
Combining these results, we might expect that an approximate solution of
the problem is
u
=
−He−x/ε + (H + I)e(x−1)/ε + O(ε)
v
=
ε(He−x/ε + (H + I)e(x−1)/ε + O(ε)),
which is the sum of a left boundary-layer correction, a right boundary-layer
correction, and a quasistatic state. There remains an important question:
Is there a solution to this boundary value problem that lies near (within
O(ε)) the approximation that we constructed? The answer lies in a detailed
analysis of trajectories of the equation. If ε is so small that ε(H + I) < 1,
then there is such a solution. The proof is constructed as in other problems:
An integral equation is derived for the remainder, that is, the diﬀerence
between (u, v) and the approximation, and that equation is shown to have
a solution (see [120]).
There are many kinds of boundary value problems involving singular
perturbations that must be studied. The one described here illustrates the
basic geometry involved in many of these problems. However, a survey,
such as [94] should be consulted to get a better feeling for the diversity of
boundary value problems that have been studied.
8.6
Nonlinear Stability Analysis near Bifurcations
The singular perturbation methods described in this chapter are closely
related to stability results, as we have seen repeatedly. Because of this, it is
not surprising that a QSSA can be used to establish stability properties of
various problems. This has been particularly important in problems from
ﬂuid mechanics [51].
8.6.1
Bifurcating Static States
The QSSA method is particularly useful in cases where changing parameter
values results in the appearance of a new static state through bifurcation.
Consider the system
dz
dt = F(z, λ),
where z, F ∈EN and λ is a real parameter. Suppose that there is a static
state, say z = 0, that loses its stability at some value, say λ = λ0. In
particular, assume the following condition.

8.6. Nonlinear Stability Analysis near Bifurcations
285
Hypothesis H13. F(0, λ) = 0 for all λ near λ = λ0. The Jacobian
matrix Fz(0, λ) is assumed to be stable for λ < λ0, it has a single eigenvalue
equal to zero for λ = λ0, and it has a single eigenvalue with positive real
part for λ > λ0. All the other eigenvalues are assumed to have negative
real parts for λ near λ0.
With assumption H13 we can determine whether a new static state
appears for the problem as λ increases through λ0
by using the
Liapunov–Schmidt method described in Chapter 4.
Let φ denote the null eigenvector of Fz(0, λ0) and write
z = cφ + w,
where w · φ = 0. The static state problem
F(z, λ) = 0
becomes
0
=
PF(cφ + w, λ)
0
=
Bw + QF(cφ + w, λ),
where P is the projection of EN onto φ and Q is the complementary pro-
jection. The matrix B is a stable matrix found by projecting the Jacobian
matrix Fz(0, 0) onto the complement of φ.
As shown in Chapter 4, there is a unique solution for w, say w = w∗(c, λ),
for c near zero and λ near λ0, and substituting this into the ﬁrst equation
gives the bifurcation equation
0 = PF(cφ + w∗(c, λ), λ).
If this equation has nontrivial small solutions for c as functions of λ −λ0,
then new static states appear through a simple bifurcation.
A general theory for using the QSSA to test the stability of these
new static states is presented in [51]. We consider here an example that
illustrates typical conditions when the method is useful.
Example of Landau’s Equation for a Canonical Bifurcation
Problem. The problem described in Section 4.3.1 is amenable to nonlinear
stability analysis. Consider the system of equations
dx
dt
=
λx −axy + h.o.t.
dy
dt
=
−by + dx2 + h.o.t.
Here, a, b, and d are ﬁxed positive numbers, and λ is a parameter. We saw
that as λ increases through zero (λ0 = 0 here), a pair of new static states

286
8. Quasistatic-State Approximations
appears given by
(x, y) =

±

bλ
ad, λ
a

+ h.o.t.
The stability of these new states is determined in Section 4.3.1 by linearizing
the problem about them and ﬁnding that these linear problems are stable.
The Linear Stability Theorem then applies to show that these are stable
solutions of the nonlinear problem.
One deﬁciency in using linear stability methods is that they are restricted
to a neighborhood of the static state, possibly to an extent where they do
not accurately describe the domain of attraction of the state. The following
approach based on the QSSA can correct this.
Newton’s polygon analysis in Section 4.1 indicates the appropriate scal-
ing to use in this problem. For λ > 0, we set ε = λ, x = √εu, y = εv, and
s = εt. With these changes of variables, the problem becomes
du
ds
=
u −auv + h.o.t.
εdv
ds
=
−bv + du2 + h.o.t.
Given any initial data (u(0), v(0)), we can determine the behavior of so-
lutions of this system for ε near zero by using the QSSA Theorem. The
reduced problem is
du0
ds
=
u0 −au0v0
0
=
−bv0 + du2
0.
There is a unique solution for v0, and substituting this into the ﬁrst
equation gives
du0
ds = u0

1 −ad
b u2
0

,
u0(0) = u(0).
The solution of this problem exists for all 0 ≤s < ∞, and it approaches
sgn(u(0))

b
ad
as s →∞at an exponential rate.
The initial transient is determined by the equation
dY0
ds = −bY0,
Y0(0) = v(0) −d
b u(0)2.
Therefore, condition H5 of the QSSA Theorem is satisﬁed, and we conclude
that
u
=
u0(s) + O(ε)
v
=
v0(s) + Y0(s/ε) + O(ε),

8.6. Nonlinear Stability Analysis near Bifurcations
287
where the error estimate holds uniformly for 0 ≤s ≤∞.
Returning to the original question, we can now state that if x(0) = O(√ε)
and y(0) = O(ε), say x(0) = √εξ and y(0) = εη where ξ and η are ﬁxed
constants, then
x(t) →sgn(ξ)

bε
ad + O(ε)
as t →∞.
The essential diﬀerence between the nonlinear stability analysis and
the linear stability analysis is that the stability of the quasistatic state
is determined by solving a nonlinear problem. This gives a more realis-
tic description of the domain of attraction of the bifurcated state. Here
there is no further restriction of (x(0), y(0)) other than x(0) = O(√ε) and
y(0) = O(ε), so the nonlinear stability analysis establishes that the un-
stable static state is in the boundary of the domain of attraction of the
new static state. The equation for u0 is referred to as Landau’s equation in
applications to ﬂuid dynamics [19]
8.6.2
Nonlinear Stability Analysis of Nonlinear Oscillations
The Hopf theory of bifurcations that was discussed brieﬂy in Chapter 4
can be studied for stability using the methods of the preceding section. In
fact, consider the problem
dx
dt = f(x, λ),
which we suppose has a static state, say x = φ(λ). Suppose that for λ < λ0,
all of the eigenvalues of the Jacobian matrix
fx(φ(λ), λ)
lie in the left half of the complex plane, but that there are two eigenvalues,
say ρ(λ)±iω(λ), for which ρ(λ0) = 0, ρ′(λ0) > 0, and ω(λ0) > 0. The other
eigenvalues are assumed to remain in the left half-plane for λ near λ0. In this
situation, which was described in Sections 4.3 and 6.1.4, a Hopf bifurcation
might occur from the static state x = φ(λ) resulting in the appearance of
a new oscillation. The stability analysis of this new oscillation can proceed
in the following steps.
1. Project the problem onto the two modes carrying the purely imag-
inary eigenvalues, and their complement, all of which are damped
modes.
2. Determine the manifold of quasiequilibrium values for the damped
modes. Substitute this into the equations for the two oscillatory
modes, which reduces it to a system for two variables.

288
8. Quasistatic-State Approximations
3. Since the problem carried by the oscillatory modes is described by
a perturbation of a harmonic oscillator, introduce polar coordinates
into these equations.
4. Using the phase variable of this system as a timelike variable, reduce
the system to a single scalar equation.
5. Apply the Mean Stable Averaging Theorem to this equation to derive
the analogue of Landau’s equation.
For example, consider the problem
x′′ + εx′ + ω2x
=
εf(x, y, x′, y′, ε)
y′′ + 2ry′ + µ2y
=
εg(x, y, x′, y′, ε),
where f and g are smooth functions, and r, ω, and µ are ﬁxed positive
constants. For ε = 0 there results a linear problem whose spectrum consists
of the four values
±iω,
−r ±

r2 −µ2.
Obviously, the y components will equilibrate on a fast time scale (relative
to εt), so we set y′ = y′′ = 0. The result is that the quasistatic manifold is
deﬁned by
y0 = 0
and so on. Thus, to leading order in ε, we have
x′′ + ω2x = εf(x, 0, x′, 0, 0) −εx′.
Introducing polar coordinates into this system using the formula
dx
dt + iωx = Reiθ
gives
dθ
dt = ω −ε sin θ f −R cos θ
R
,
where f = f[R sin(θ)/ω, 0, R cos(θ), 0, 0]. Using θ as a timelike variable, we
have
dR
dθ =
ε cos θ(f −R cos θ)
ω −ε sin θ(f/R −cos θ) = ε
ω cos θ(f −R cos θ) + O(ε2).
Averaging this equation gives Landau’s equation for the problem; namely,
dR
dθ = −ε
ω
 1
2π
 2π
0
cos T f
R
ω sin T, 0, R cos T, 0, 0

dT −R
2

.
Static states of this equation correspond to periodic solutions of the original
system, and if such a static state is asymptotically stable for the aver-
aged equation, then the oscillation is orbitally asymptotically stable (i.e.,
asymptotically stable in amplitudes).

8.7. Explosion Mode Analysis of Rapid Chemical Reactions
289
Table 8.1. H2–O2 elementary reactions.
Reaction
Rate
Type of Reaction
H2 + O2 →H · +HO2
k0
Initiation
H2 + OH· →H · +H2O
k1
O2 + H· →OH · +O·
k2
H2 + O· →OH · +H·
k3
Propagation
H · +W →
a1
Termination
OH · +W →
a2
Termination
O · +W →
a3
Termination
This nonlinear stability analysis of bifurcating oscillations uses both qua-
sistatic state and averaging methods. The solutions reduce to a quasistatic
manifold, and the highly oscillatory behavior on it can be described us-
ing averaging methods. The reader should carry out the details of this
calculation for the case of van der Pol’s equation where
f(x, 0, x′, 0, ε) = x2x′.
8.7
Explosion Mode Analysis of Rapid Chemical
Reactions
Explosive chemical reactions are diﬃcult to study using the QSSA because
most of the interesting dynamics occur in transients after an initiation
phase, but before the reaction comes to equilibrium. The example treated
in this section illustrates a case where the QSSA theorem does not give
useful information directly, but it provides some guidance in obtaining a
canonical problem whose solution is relatively simple to ﬁnd. The canonical
problem gives an approximate description of the initial transient’s behavior,
where most of the interesting dynamics occur.
The combustion of hydrogen involves a chain-branched reaction that is
described in Table 8.1 [2]. Three types of reactions are involved in this
process: initiation, branching (or propagation), and termination. In these
reactions HO2 is taken to be an inactive particle, and W in the termination
reactions indicates collisions with the container’s wall.
We describe the concentrations of various chemical species by
u = [H2],
v = [O2],
x = [H·],
y = [OH·],
z = [O·],
where the notation H·, O·, etc., denotes highly reactive radicals. Then the
kinetic rate equations can be derived directly from Table 8.1 as H2 −O2
elementary reactions

290
8. Quasistatic-State Approximations
du
dt
=
−(k1y + k3z)u −k0uv,
u(0) = u0
dv
dt
=
−k2xv −k0uv,
v(0) = v0
dx
dt
=
−(k2v + a1)x + k1uy + k3uz + k0uv,
x(0) = 0
dy
dt
=
k2vx −(k1u + a2)y + k3uz,
y(0) = 0
dz
dt
=
k2vx −(k3u + a3)z,
z(0) = 0.
It is convenient to rewrite this system using matrices: Let
B =


−k2v
k1u
k3u
k2v
−k1u
k3u
k2v
0
−k3u


and
T =


a1
0
0
0
a2
0
0
0
a3

.
The matrix B describes the branching reactions, and the matrix T describes
the termination reactions. If X = col(x, y, z), then
dX
dt = (B −T)X + col(k0uv, 0, 0),
where the terms on the right-hand side denote branching, termination, and
initiation, respectively, of the radical concentrations.
Spectral Analysis of B −T. The characteristic polynomial of B −T is
P(λ) = −det(B −T −λI3),
where I3 is the 3 × 3 identity matrix. The roots of this polynomial are the
eigenvalues of B −T, and P has the form
P(λ) = λ3 + σλ2 + νλ −ω(u, v),
where σ = α + β + κ + a1 + a2 + a3 > 0,
ν = α(a2 + a3) + β(κ + a1 + a3) + κ(a1 + a2) + a1a2 + a3a2 + a1a3 > 0,
and
ω(u, v) = 2αβκ −[a1βκ + a1a2κ + a1a3β + a3a2α + a1a2a3],
where α = κ2v, β = k1u, and κ = k3u. Note that
ω(u, v) = det(B −T).

8.7. Explosion Mode Analysis of Rapid Chemical Reactions
291
The sign of ω plays an important role here. First, P is a monotone increasing
function of λ, since its ﬁrst derivative is positive for λ > 0.
Therefore, if P(0) = −ω(u, v) < 0, then there is a unique real, positive
eigenvalue λ∗(u, v). Moreover, if λ1 and λ2 denote the other two eigenvalues,
then either (1) they are real and both negative, or (2) they are imaginary.
In the latter case,
λ∗+ λ2 + λ1 = −σ < 0,
so 2Re λ1 < −λ∗< 0.
Thus, in either case, if ω(u, v) > 0, then B −T has one positive, real
eigenvalue and two other eigenvalues that have negative real parts.
Denote by λ∗(u, v) the eigenvalue of B −T that has the largest real part,
and let φ∗denote the corresponding eigenvector, so (B−T)φ∗= λ∗φ∗. The
vector ψ∗denotes the adjoint eigenvector
(B −T)trψ∗= λ∗ψ∗.
These are normalized so that
ψ∗· φ∗= 1
and
ψ∗· ψ∗= 1.
The eigenvector φ∗is referred to as the explosion mode, and λ∗gives its
ampliﬁcation, or explosion rate. For relevant values of the reaction rates,
φ∗is observed to remain essentially constant throughout the reaction.
The radical components can be rewritten as




x
y
z



= cφ∗+ Ω,
where the vector Ωaccounts for the λ1 and λ2 modes. Since these
modes will be damped, we ignore them and introduce the explosion mode
approximation




x
y
z



= cφ∗.
Substituting this into the model gives
du
dt
=
−(k1φ∗
2 + k3φ∗
3)cu −k0uv
dv
dt
=
−(k2φ∗
1)cv −k0uv
dc
dt
=
λ∗(u, v)c + αk0uv,
where α gives the projection of the initiation vector col(1, 0, 0) onto φ∗.
Since the initiation reaction is negligible throughout most of the reaction,

292
8. Quasistatic-State Approximations
we ignore it:
du
dt
=
−(k1φ∗
2 + k3φ∗
3)cu
dv
dt
=
−(k2φ∗
1)cv
dc
dt
=
λ∗(u, v)c.
This is called the canonical ﬁrst-order branching problem, and it is solvable;
the equation for du/dv can be easily solved:
v = Kuξ,
where ξ =
(k2φ∗
1)
(k1φ∗
2 + k3φ∗
3).
Then the equation for dc/du can be integrated:
c = ¯c −
 u
¯u
λ∗(s, Ksξ)
(k1φ∗
2 + k3φ∗
3)
ds
s ,
where ¯u and ¯c are values after the initiation phase (¯u ≈u0, ¯c ≈0).
As the reaction proceeds, u and v are depleted and λ∗(u, v) moves from
being large and positive to being negative. The values of u and v for which
λ∗= 0 deﬁne the ﬁrst explosion limit of the reaction. If u and v are super-
critical (λ∗> 0), then an explosion will ensue that begins termination only
when λ∗= 0. The values of c at termination can be estimated using the
above formula for c [2, 128].
8.8
Computational Schemes Based on QSSA
The numerical solution of singular perturbation problems can be diﬃcult
for several reasons; for example, it is not unusual in applications that ε =
O(10−10). Solving for the initial transient can be handled by taking a very
small step size for the numerical algorithm to ensure accuracy, but it is
only the ﬁrst problem. The second problem is that any numerical algorithm
constantly makes errors that throw the solution oﬀof the reduced solution,
and small step sizes might be required throughout the calculation to ensure
that the numerical scheme is stable. This last aspect of the computation is
referred to as stiﬀness of the system. Various computer packages have been
designed to circumvent this problem of stiﬀness, such as Gear’s package
and LSODE, but computation remains expensive [67, 112].
QSS methods can be used to formulate a useful numerical scheme that
takes advantage of solution structure to avoid some of the stiﬀness prob-
lems. These can signiﬁcantly reduce the computation time, but they do
require preprocessing the system into a standard form, which may not be
possible in reasonable time.

8.8. Computational Schemes Based on QSSA
293
Consider the initial value problem
dx
dt
=
f(t, x, y, ε),
x(0) = ξ(ε) = ξ0 + O(ε)
εdy
dt
=
g(t, x, y, ε),
y(0) = η(ε) = η0 + O(ε),
where ε is a small, positive parameter. Here x, f, ξ ∈EM and y, g, η ∈EN.
The reduced problem (ε = 0 with the initial y condition canceled) is
dx
dt
=
f(t, x, y, 0),
x(0) = ξ0
0
=
g(t, x, y, 0).
It is assumed to have a smooth solution, x = x0(t), y = y0(t), on some
interval 0 ≤t ≤T. Moreover, the data f, g, ξ, and η are assumed to be
smooth near this solution and for ε near zero. Finally, the Jacobian matrix
gy(t, x0(t), y0(t), 0)
is assumed to be stable (i.e., all of its eigenvalues lie in the left half-plane,
bounded uniformly away from the imaginary axis for all 0 ≤t ≤T).
Under these conditions, the Quasistatic State Approximation Theorem
shows that the solution of the full problem has the form
x(t, ε)
=
x0(t) + x1(t)ε + X(t/ε, ε) + O(ε2)
y(t, ε)
=
y0(t) + y1(t)ε + Y (t/ε, ε) + O(ε2),
where X and Y satisfy
|X(t/ε, ε)| + |Y (t/ε, ε)| ≤Ke−µt/ε
for some positive constants K and µ that are independent of ε. These
estimates hold uniformly for 0 ≤t ≤T.
We wish to determine a numerical approximation of (x(h, ε), y(h, ε)) for
a given step size h ≫ε. Direct evaluation of this quantity by numerical
packages can be expensive if ε is very small, but the QSSA Theorem ensures
that x0(h), y0(h) is a useful approximation.
8.8.1
Direct Calculation of x0(h), y0(h)
Since h/ε ≫1, we can ignore X and Y terms in the approximation, and
x0(h), y0(h) should give an acceptable approximation to x(h, ε), y(h, ε). We
begin with a guess for y0(0) and use Newton’s method to solve the equation
0 = g(0, x(0), y, 0)
for y. This process can be repeated as required up to t = h. Let us next use
a pth-order numerical method for solving the ordinary diﬀerential equation

294
8. Quasistatic-State Approximations
for x0(h). The result is that
x(h, ε)
=
x0(h) + O(ε) + O(hp+1)
y(h, ε)
=
y0(h) + O(ε) + O(hp+1),
where x0(h) and y0(h) are the computed solutions.
8.8.2
Extrapolation Method
It is possible to avoid solving the reduced problem by taking advantage of all
of the information given by the QSSA Theorem. The extrapolation method
described here was derived in [79]. The idea is to identify a value, say ε′, that
is substantially larger than ε, but for which the solution x(h, ε′), y(h, ε′)
approximates x(h, ε), y(h, ε) to the accuracy of the numerical scheme used.
Solving the full problem with a large value of ε can be done with greater
accuracy using less eﬀort.
First, a value T is found such that
K exp(−µT) = O(hp+1),
where µ is usually on the order of the largest negative eigenvalue of gy, and
K depends on the size of gy. Next, the value
ε′ = h
T
is deﬁned, and the full problem is solved using a standard integration
method, say of order p, to determine values x(h, ε′/2), y(h, ε′/2) and
x(h, ε′), y(h, ε′). From the arguments below, it follows that
x(h, ε)
=
2x(h, ε′/2) −x(h, ε′) + O(hp+1) + O(ε′2) + O(ε)
y(h, ε)
=
2y(h, ε′/2) −y(h, ε′) + O(hp+1) + O(ε′2) + O(ε).
These formulas are derived by observing that
2x(h, ε′/2) = 2x0(h) + x1(h)ε′ + 2X(T, ε′/2) + O(ε′2)
and
x(h, ε′) = x0(h) + x1(h)ε′ + X(T, ε′) + O(ε′2).
Subtracting these two expressions gives
2x(h, ε′/2) −x(h, ε′) = x0(h) + O(hp+1) + O(ε′2).
On the other hand,
x(h, ε) = x0(h) + O(ε),

8.9. Exercises
295
so the desired result for x(h, ε) is found. Similarly for y(h, ε). The ﬁnal
result is that
x(h, ε)
=
2x(h, ε′/2) −x(h, ε′) + O(hp+1) + O(ε) + O((h/T)2)
y(h, ε)
=
2y(h, ε′/2) −y(h, ε′) + O(hp+1) + O(ε) + O((h/T)2).
This is referred to as the extrapolation approximation.
In many applications, the number of operations used in these compu-
tations is proportional to 1/ε, for x(h, ε), and so on, and to 1/ε′, for
x(h, ε′), and so on. Therefore, the ratio ε′/ε indicates the relative number
of operations of direct solution compared to the extrapolation solution.
Using the extrapolation approximation can avoid analytical preprocess-
ing of a problem to get it into the form of the full problem for x and y if K
and µ can be estimated. It also avoids having to solve the algebraic equa-
tion g = 0 at each mesh point required for solving the x equation of the
reduced problem. Both preprocessing and solving for the quasistatic state
y can require substantial amounts of time, and a major object of computer
solvers is to avoid preprocessing.
This extrapolation method is based on the QSS perturbation scheme. It
is distinct from straightforward Richardson extrapolation formulas that are
based on Taylor’s formula and that are not appropriate for stiﬀproblems.
It is important to note that this method improves as ε gets smaller.
8.9
Exercises
8.1.
Use the quasistatic state approximation to construct the solution of
the system
dx
dt
=
ax + by + sin t,
x(0) = 1
εdy
dt
=
−y + cos t,
y(0) = 3,
where x and y are scalars and ε is a small positive number. Construct
both the quasistatic state and the initial layer corrections through
order ε2.
8.2.
Show in the Quasistatic State Approximation Theorem that the
initial layer corrections satisfy Xj →0 as τ →∞.
8.3∗.
Problems involving two, or more, small parameters can also be
handled using the QSS method. Consider the system
dx
dt
=
Ax + Bu + Cv + f(t)
εdu
dt
=
Du + Ev + g(t)
ε2 dv
dt
=
Fv + h(t),

296
8. Quasistatic-State Approximations
where x, f are in EM, u, g are in EN, and v, h are in EK. The matrices
A, B, and so on, are of appropriate dimensions. This problem contains
two small parameters ε and ε2. Suppose that the matrices D and F
are stable and that the functions f, g, and h are smooth functions.
Show that this problem has a quasistatic state (x∗, u∗, v∗) and two
transients
	
X
	 t
ε, ε

, U
	 t
ε, ε

, V
	 t
ε, ε


and
	
X∗
	 t
ε2 , ε

, U ∗
	 t
ε2 , ε

, V ∗
	 t
ε2 , ε


that decay at exponential rates. Moreover, show that the solution is
given by the formula
(x, u, v) = (x∗, u∗, v∗) + (X, U, V ) + (X∗, U ∗, V ∗)
and that the terms in this formula can be expanded in a Taylor
expansion about ε = 0.
8.4.
Suppose that the functions f(x, y, ε) and g(x, y, ε) are smooth func-
tions (at least twice continuously diﬀerentiable) for all real numbers
x, y, and ε. Suppose that the system
dx1
dt
=
f1(x, y, 0)
dx2
dt
=
f2(x, y, 0)
0
=
−y3 + x1y −x2
has an oscillation, say x∗
1(t), x∗
2(t), y(t), on which
−3y2 + x1 < 0.
Therefore, the oscillation lies either on the top or bottom branch of
the cusp surface. Let T0 denote the period of this oscillation. The
Friedrichs–Wasow Theorem shows that there is a unique periodic so-
lution of the full problem lying near the orbit of the reduced problem
and having period near T0. Use the quasistatic state method to derive
the ﬁrst-order approximation to the oscillation of the full system.
8.5.
Consider the atoll oscillator, which deﬁnes a ﬂow on a torus having
interesting periodic solutions:
dx
dt
=
5.0(1.05 + cos x −cos y)
dy
dt
=
0.04(1.0 + cos y + 10.0 cos x).
Prove that there is a periodic solution to this system. Simulate
the solution of this system by calculating the solution and plotting
the results on a toroidal patch (x and y modulo 2π) as shown in
Figure 8.10.

8.9. Exercises
297
0
10
20
30
40
50
60
70
80
90
100
−1
−0.5
0
0.5
1
cos x
0
10
20
30
40
50
60
70
80
90
100
−1
−0.5
0
0.5
1
t
cos y
Figure 8.9. The atoll oscillator solutions.
8.6.
Consider the nonlinear stability problem
dx
dt = A(λ)x + f(t, x),
where x, f are in EM and A is a matrix of appropriate dimensions.
Suppose that f is a smooth function that satisﬁes
f(t, x) = o(|x|)
as |x| →0 uniformly for 0 ≤t < ∞. Suppose that a simple eigenvalue
of A passes through the origin from left to right as λ increases through
zero while the remaining eigenvalues remain in the left half plane,
bounded away from the imaginary axis.
Apply the nonlinear stability analysis described in Section 8.6.1 to
describe solutions. Derive Landau’s equation for this problem.
8.7.
Consider the damped conservative system
εu′′ + ru′ + Uu(u) = 0,
where ε is a small dimensionless parameter, r describes the coeﬃcient
of friction, and U(u) describes the system’s potential energy. We wish
to solve this equation subject to the boundary conditions
u(0) = A,
u(1) = B.
Setting ε = 0 in the equation results in the reduced problem
ru′
0 + Uu(u0) = 0.

298
8. Quasistatic-State Approximations
0
1
2
3
4
5
6
0
1
2
3
4
5
6
x
y
Figure 8.10. The atoll oscillator on T 2.
This ﬁrst-order diﬀerential equation’s solution is uniquely determined
by specifying u0 at one point. Therefore, in general the solution
cannot satisfy both boundary conditions.
a. What is the correct value for u0 to approximate the solution of the
full problem?
b. Solve the problem explicitly in the special case where U(u) = u2/2.
8.8.
Show that if the matrix A in the quasistatic state theorem is expo-
nentially stable, then the error estimates in the result hold uniformly
for 0 ≤t < ∞.
8.9∗.
Consider the stochastic diﬀerential equation [91, 42]
dx = 1
ε F ′(x)dt + σdB,
where x(t) is a random variable and dB denotes white noise, as in
Section 7.8. If u(x, t) denotes the probability density function of the
random variable x, then it is known that u solves the Fokker–Planck
equation
∂u
∂t = σ2
2
∂2u
∂x2 −∂
∂x
	
F(x)u
ε

.
a. Find a static state solution of this. (Hint: Set ∂u/∂t = 0 and solve
the resulting equation for u(x).)

8.9. Exercises
299
b. Determine what happens to this distribution as ε and σ2 →0+. In
particular, explain the role played by the maxima of F(x) in the
distribution of x.
8.10.
Let p denote the proportion of a human population’s gene pool that is
carried by a single locus that is of type A, and let q = 1−p denote the
proportion that are of type B. We suppose that there are only these
two types. As a result, the population can be broken down into three
groups AA, AB, and BB, by their genetic type. Let D(t), 2H(t), and
R(t) denote the proportions of the population of these types at time
t. Then p = (D + H), q = (H + R). If selection is slow, then the birth
rates and death rates for all of these genotypes are almost the same.
Suppose that the birth rates are identical and that the death rates
are dAA = d + εd1, dAB = d + εd2, dBB = d + εd3. Then
dD
dt
=
b(p2 −D) + ε(d∗−d1)D
dH
dt
=
b(pq −H) + ε(d∗−d2)H
dR
dt
=
b(q2 −R) + ε(d∗−d3)R,
where b > 0 is the population’s birth rate, and d∗= d1D+2d2H+d3R
[73].
a. Derive a diﬀerential equation for p.
b. Apply the quasistatic state approximation theorem to this system to
obtain the quasistatic state and the initial correction expansions to
ﬁrst order in ε.
c. Plot your results for (D, 2H, R) using triangular coordinates, as shown
in Figure 8.11.
8.11∗. Consider the nonlinear renewal equation [54]
εx(t)
=
 0
−1
{(2ε −1)x(t + s) −x2(t + s)}ds
for t > 0
x(t)
=
εv0(t)
for −1 ≤t < 0,
where 0 < ε ≪1 and where v0 is extended as a periodic function.
Use the multitime algorithm to ﬁnd an approximate solution to this
equation. In particular, let
x = εV (ξ, t, ε) = εV0(ξ, τ) + ε2V1(ξ, τ) + · · · ,
where ξ = (1 −ε)t and τ = ε2t. Show that
∂V0
∂τ + ∂
∂ξ (V0 −V 2
0 ) = 1
2
∂2V0
∂ξ2
V0(ξ, τ) = V0(ξ −1, τ)
and
V0(ξ, 0) = v0(ξ).
8.12∗. Consider the equation [72]
ε∂u
∂t = D ∂2u
∂x2 + u −u3

300
8. Quasistatic-State Approximations
0
0.2
0.4
0.6
0.8
1
1.2
0
0.2
0.4
0.6
0.8
1
D
  H
R
Hardy-Weinberg
Equilibria
2
Figure 8.11. Hardy–Weinberg quasi-equilibrium.
for 0 ≤x ≤1 and the auxiliary boundary conditions
∂u
∂x(0, t) = 0,
∂u
∂x(1, t) = 0.
Suppose that u(x, 0) = U(x) is given. Show that there is a qua-
sistatic state for this problem. Construct it and the transient initial
correction.

Supplementary Exercises
S.1.
Consider the forced pendulum equation
x′′ + α sin x = B cos 2πt.
Calculate the rotation number of the response as a function of forcing
amplitude B and oscillator tuning α by converting the problem to
polar coordinates and calculating the values θ(100π)/(100π).
S.2.
Solve the Michaelis–Menten model in Section 8.3.4 for ε = 0.001
and ε = 0.00001 and using the extrapolation method described in
Section 8.8.
S.3.
Consider a linear array of masses extending from −∞to +∞, say
having masses mj at site j, −∞< j < ∞. Suppose that the location
of the jth mass is xj, and that these masses are connected by springs.
Then the dynamics of the ensemble are described by the equations
dxj
dt = f(xj+1 −xj) −f(xj −xj−1),
where f(u) describes the restoring force of a spring that is deﬂected u
units from rest. Carry out a computer simulation of this system when
f(s) = as, when f(s) = bs + cs3, and when f(s) = e−a|s| where a, b,
and c are ﬁxed positive constants. The ﬁrst case is a simple diﬀusion
problem, the second is referred to as the Fermi–Pasta–Ulam model,
and the third is the Toda lattice.
S.4.
Simulate the twist mapping
rn+1 = rn −h cos(tn + rn),
tn+1 = tn + rn.
S.5.
Using a computer simulation, determine the two basins of attraction
of the stable periodic solutions described in Figure 6.6. (Hint: Given

302
8. Quasistatic-State Approximations
a tolerance ε, calculate the probability that a line segment having
this length and thrown at random hits the boundary. Calculate this
number for several values of ε and extrapolate its value to ε = 0.)
S.6.
Consider the array of VCONs
dxj
dt = ωj + ε tanh
	
A cos xj + Cj cos µt +
100

k=1
Bj,k cos xk

for j = 1, . . . , 100, where the matrix B is a cyclic matrix. Take ωj =
1.0−j0.8/50.0 for j = 1, . . . , 50 and ωj = ω101−j for j = 51, . . . , 100,
A = 5.0, ε = 0.5, Cj = 5.0, Bjj = 0.0.
a. Simulate this system and plot the resulting rotation vector (ρ1, . . . , ρN)
using polar coordinates. (Hint: Deﬁne ρj = xj(100π)/x1(100π) and
plot the points (ρj cos(2πj/100), ρj sin(2πj/100)) for j = 1, . . . , 100.)
b. Experiment with various choices of the connection matrix B. For ex-
ample, let it describe nearest neighbor interactions where it is a cyclic
matrix having center row . . . , 1, −2, 1, . . . , or let B be a permutation
matrix.
S.7.
Consider the semi-implicit scheme
xn+1
=
xn −hf(yn+1)
yn+1
=
yn + hf(xn),
where f(u) = sin u. Simulate the solution of this iteration for various
choices of initial conditions. Plot your answers by plotting the iterates
of this mapping in the xy-plane.
S.8.
Carry out a Monte Carlo simulation of solutions to the stochastic
diﬀerential equation
dy = 1
ε F ′(y)dt + σ
ε dB
by computing sample paths using the discrete model
yn+1 = yn + h
ε (F ′(yn) + σWn),
where Wn is at each step a random variable selected from a nor-
mal distribution and F is a quartic function. Plot your answer as a
histogram of y100. (Hint: Use a random number generator for a uni-
formly distributed random variable on the interval −1 < y < 1 to
select six values. Add them up and divide by
√
6. The result is a
normally distributed variable (see [62]).)

References
[1] M. Abramowitz, I.A. Stegun, Handbook of Mathematical Functions, Dover,
New York, 1972.
[2] P. Alfeld, F.C. Hoppensteadt, Explosion Mode Analysis of H2–O2 Combus-
tion, Chemical Physics Series, Springer-Verlag, New York, 1980.
[3] A.A. Andronov, A.A. Witt, S.E. Chaikin, Theory of Oscillators, Dover, New
York, 1966.
[4] V.I. Arnol’d, Mathematical Methods of Classical Mechanics, Springer-Verlag,
New York, 1978.
[5] V.I. Arnol’d, A. Avez, Ergodic problems in classical mechanics, W.A.
Benjamin, New York, 1968.
[6] H. Antosiewicz, A survey of Liapunov’s second method, in Contributions to
the Theory of Nonlinear Oscillations, S. Lefschetz (ed.), Vol. IV, Princeton,
N.J., 1958.
[7] H.T. Banks, F. Kappel, Spline approximations for functional diﬀerential
equations, J. Diﬀerential Eqns., 34(1979): 496–522.
[8] K.G. Beauchamp, Walsh Functions and their Applications, Academic Press,
New York, 1975.
[9] R. Bellman, Perturbation Theory, Holt-Rhinehardt-Winston, New York,
1964.
[10] R. Bellman, K. Cooke, Diﬀerential-Diﬀerence Equations, Academic Press,
New York, 1963.
[11] A.S. Besicovitch, Almost Periodic Functions, Dover, New York, 1954.
[12] G.D. Birkhoﬀ, Dynamical Systems, Vol. IX., American Mathematical
Society, Providence, RI, 1966.

304
References
[13] N.N. Bogoliuboﬀ, Y.A. Mitropolski, Asymptotic Methods in the Theory of
Nonlinear Oscillations, Gordon-Breach, New York, 1961.
[14] G.E. Briggs, J.B.S. Haldane, A note on the kinetics of enzyme action.
Biochem. J. 19(1925): 338–339.
[15] H. Carrillo, The method of averaging and stability under persistent distur-
bances with applications to phase-locking, Dissertation, University of Utah,
1983.
[16] P.H. Carter, An improvement of the Poincar´e–Birkhoﬀﬁxed point theorem,
Trans. AMS 269(1982): 285–299.
[17] M.A. Cartwright, J.E. Littlewood, Ann. Math. 54(1951): 1–37.
[18] L. Cesari, Asymptotic Behavior and Stability Problems in Ordinary Dif-
ferential Equations, Ergebnisse der Math. New Series, Vol. 16, 1963, 2nd
ed.
[19] S. Chandrasekhar, Hydrodynamic and Hydromagnetic Stability, Oxford
University Press, 1961.
[20] E.W. Cheney, Introduction to Approximation Theory, McGraw-Hill, New
York, 1966.
[21] E.W. Cheney, D. Kincaid, Numerical Mathematics and Computing, Brooks-
Cole, Monterey, CA, 1980.
[22] W. Chester, The forced oscillations of a simple pendulum, J. Inst. Maths.
Appl. 15(1975): 298–306.
[23] S.N. Chow, J.K. Hale, Methods of Bifurcation Theory, Springer-Verlag, New
York, 1982.
[24] E.A. Coddington, N. Levinson, Theory of Ordinary Diﬀerential Equations,
McGraw Hill, New York, 1955.
[25] D.S. Cohen, F.C. Hoppensteadt, R.M. Miura, Slowly modulated oscillations
in nonlinear diﬀusion processes, SIAM J. Appl. Math. 33 (1977):217–229.
[26] J.D. Cole, Perturbation Methods in Applied Mathematics, Blaisdale, Waltham,
MA, 1968.
[27] W.A. Coppel, Stability and Asymptotic Behavior of Diﬀerential Equations,
Heath, Boston, 1965.
[28] R. Courant, D. Hilbert, Methods of Mathematical Physics, Vol. I, Wiley-
Interscience, New York, 1968.
[29] Salvador Dali, The Persistence of Memory. Centre Georges Pompidou, Mus´ee
National d’Art Moderne, Paris, 1980.
[30] A. Denjoy, Sur les courbes d´eﬁnies par les ´equations diﬀ´erentielles a la surface
du tor, J. Math. Pures Appl. 9(1932):333–375.
[31] G. Duﬃng, Erzwungene Schwingungen bie ver¨anderlicher Eigenfrequeng, F.
Vieweg u. Sohn, Braunschweig, 1918.
[32] J. Dugundji, Fixed Point Theory, Panstwowe Wydawnictwo Naukowe,
Warsaw, 1982.
[33] A. Erdelyi, Asymptotic Expansions, Dover, New York, 1956.
[34] D.K. Fadeev, V.N. Fadeeva, Computational Methods in Linear Algebra, W.H.
Freedman, San Francisco, 1963.

References
305
[35] J.D. Farmer, E. Ott, J.A. Yorke, Physica 7D (1983): 153.
[36] P. Fatou, Sur les equations fonctionelles, Bull. Soc. Math. Fr. 47(1919): 161–
211; 48(1920): 33–94, 208–314.
[37] W. Feller, An Introduction to Probability Theory and its Applications, Wiley,
New York, 1968.
[38] J.E. Flaherty, F.C. Hoppensteadt, Frequency entrainment of a forced van
der Pol oscillator, Studies Appl. Math. 58(1978): 5–15.
[39] A.T. Fomenko, Integrable systems on Lie algebras and symmetric spaces,
Gordon and Breach, New York, 1988.
[40] J.S. Frame, Applications of Matrices in Engineering, MSU Lecture Notes,
1965.
[41] L.E. Frankel, On the method of matched asymptotic expansions, Proc.Camb.
Phil. Soc. 65(1969): 209–284.
[42] M.I. Freidlin, A.D. Ventsel, Random Perturbations of Dynamical Systems,
Springer-Verlag, New York, 1984.
[43] K.O. Friedrichs, Lectures on Advanced Ordinary Diﬀerential Equations,
Gordon and Breach, New York, 1965.
[44] K.O. Friedrichs, Asymptotic phenomena in mathematical physics, Bull.
AMS (1955): 485–504.
[45] S. Freud, The Interpretation of Dreams, Allen & Unwin, London, 1954.
[46] F.R. Gantmacher, Applications of the Theory of Matrices, Wiley-Interscience,
New York, 1959.
[47] P.R. Garabedian, Partial Diﬀerential Equations, Wiley, New York, 1964.
[48] J. Glieck, Chaos: Making of a New Science, Viking, 1987.
[49] H. Goldstein, Classical Mechanics, Addison-Wesley, Reading, Mass., 1950.
[50] Preconditioned Conjugate Gradient Methods, Springer-Verlag, New York,
1990.
[51] N. Gordon, F.C. Hoppensteadt, Nonlinear stability analysis of static states
which arise through bifurcation, Comm. Pure Appl. Math. 28(1975): 355–
373.
[52] Jo. Grasman, E.J.M. Velig, G. Willems, Relaxation oscillations governed by
a van der Pol equation, SIAM J. Appl. Math. 31(1976): 667–676.
[53] J. Grasman, E.J.M. Velig, G. Willems, Relaxation oscillations governed by
a van der Pol equation, SIAM J. Appl. Math. 31(1976): 667–676.
[54] J.M. Greenberg, F.C. Hoppensteadt, Asymptotic behavior of solutions to a
population equation, SIAM J. Appl. Math. 17(1975): 662–674.
[55] J. Guckenheimer, P. Holmes, Nonlinear Oscillations, Dynamical Systems
and Bifurcations of Vector Fields, Applied Mathematical Sciences, Vol. 42,
Springer-Verlag, New York, 1983.
[56] J. Hadamard, Sur l’it´eration et les solutions asymptotiques des ´equations
dif´erentielles, Bull. Soc. Math. France 29(1901): 224–228.
[57] W. Hahn, Stability of Motion, Springer-Verlag, New York, 1967.
[58] J.K. Hale, Ordinary Diﬀerential Equations, Wiley-Interscience, New York,
1971.

306
References
[59] J.K. Hale, Oscillations in Nonlinear Systems, McGraw-Hill, New York, 1963.
[60] P.R. Halmos, Measure Theory, Van Nostrand, Princeton, 1950.
[61] P.R. Halmos, Lectures on Ergodic Theory, Chelsea Publishing Co., New
York, 1956.
[62] J.M. Hammersley, D.C. Handscombe, Monte Carlo Methods, Methuen,
London, 1964.
[63] P. Hartmann, Ordinary Diﬀerential Equations, Hartmann, Baltimore, 1973.
[64] C. Hayashi, Nonlinear Oscillations in Physical Systems, Princeton Univer-
sity Press, Princeton, 1985.
[65] R.J. Higgins, Electronics with Digital and Analog Integrated Circuits,
Prentice-Hall, Englewood Cliﬀs, New Jersey, 1983.
[66] E. Hille, Analytic Function Theory, Vol. 1 and 2, Ginn, New York, 1959.
[67] A.C. Hindmarsh, Gear’s ordinary diﬀerential equation solver, UCID-30001
(rev. 3) Lawrence Livermore Lab, Livermore, CA. Dec. 1974.
[68] M. Hirsch, S. Smale, Diﬀerential Equations, Dynamical Systems and Linear
Algebra, Academic Press, New York, 1974.
[69] E. Hopf, Ber. Math. Phys. Sachsische Akad. Wiss. Leipzig, 94(1942): 1–22.
[70] F.C. Hoppensteadt, Singular perturbations on the inﬁnite interval, Trans.
AMS, 123(1966): 521–535.
[71] F.C. Hoppensteadt, Properties of solutions of ordinary diﬀerential equations
with small parameters, Comm. Pure Appl. Math. 24(1971): 807–840.
[72] F.C. Hoppensteadt, On quasi-linear parabolic equations with a small
parameter, Comm. Pure Appl. Math. 24(1971): 17–38.
[73] F.C. Hoppensteadt, Mathematical Theories of Populations, SIAM Publica-
tions, 1975.
[74] F.C. Hoppensteadt, Mathematical Methods of Population Biology, Cam-
bridge University Press, New York, 1982.
[75] F.C. Hoppensteadt, Introduction to the Mathematics of Neurons: Modeling
in the Frequency Domain, 2nd ed., Cambridge University Press, New York,
1997.
[76] F.C. Hoppensteadt, J.M. Hyman, Periodic solutions of a logistic diﬀerence
equation, SIAM J. Appl. Math. 58(1977): 73–81.
[77] F.C. Hoppensteadt, W.L. Miranker, Diﬀerential equations having rapidly
changing solutions: Analytic methods for weakly nonlinear systems, J. Diﬀ.
Eqn. 22 (1976): 237–249.
[78] F.C. Hoppensteadt, W.L. Miranker, Multi-time methods for systems of
diﬀerence equations, Studies Appl. Math. 56(1977): 273–289.
[79] F.C. Hoppensteadt, W.L. Miranker, An extrapolation method for the numer-
ical solution of singular perturbation problems, SIAM J. Sci. Stat. Comp.
4(1983): 612–625.
[80] F.C. Hoppensteadt, A. Schiaﬃno, Stable oscillations of weakly nonlin-
ear Volterra integro-diﬀerential equations, J. reine u. angewandte Math.
353(1984): 1–13.

References
307
[81] F.C. Hoppensteadt, E.M. Izhikevich, Weakly Connected Neural Networks,
Springer-Verlag, new York, 1997.
[82] F.C. Hoppensteadt, H.S. Salehi, A.V. Skorokhod, Randomly Perturbed
Dynamical Systems, in preparation.
[83] P. Horowitz, W. Hill, The Art of Electronics, 2nd ed., Cambridge University
Press, New York, 1989.
[84] E.L. Ince, Ordinary Diﬀerential Equations, Dover, New York, 1956.
[85] G. Iooss, D. Joseph, Nonlinear Dynamics and Turbulence, Pitman, Boston,
1983.
[86] H. Jacobowitz, Corrigendum, The existence of the second ﬁxed point, J.
Diﬀerential Eqns. 25(1977): 148–149.
[87] E. Jahnke, F. Emde, Tables of Functions, Dover, New York, 1945.
[88] G. Julia, Sur l’it´eration des fonctions rationelles, J. Math. Pure Appl.
8(1918): 47–245.
[89] J.B. Keller, Perturbation Theory, Michigan State University, 1968.
[90] J. Kevorkian, J.D. Cole, Perturbation Methods in Applied Mathematics,
Springer-Verlag, New York, 1981.
[91] R.Z. Khas’minskii, Stochastic Stability of Diﬀerential Equations, Sijthoﬀ&
Noordhoﬀ, Rockville, MD, 1980.
[92] A.I. Khinchin, An Introduction to Information Theory, Dover, New York,
1965.
[93] J. Kinney, T. Pitcher, Invariant Measures for Rational Functions. Some con-
nections between ergodic theory and the iteration of polynomials, Ark. Mat.
8(1969): 25–32.
[94] P. Kokotovic, H. Khalil, Singular Perturbation Methods in Control: Analysis
and Design, Academic, London, 1986.
[95] K. Krohn, J.L. Rhodes, Algebraic Theory of Machines (M.A. Arbib, ed.),
Academic Press, New York, 1968.
[96] N. Krylov, N.N. Bogoliuboﬀ, Introduction to Nonlinear Mechanics, Annals of
Mathematics Studies, No. 11, Princeton University Press, Princeton, 1947.
[97] W. Leveque, Elementary Theory of Numbers, Addison-Wesley, Reading,
Mass., 1962.
[98] M. Levi, F.C. Hoppensteadt, W.L. Miranker, Dynamics of the Josephson
junction, Quart. Appl. Math. (July 1978): 167–198.
[99] M. Levi, On van der Pol’s equation, AMS Memoirs, Providence, R.I., 1979.
[100] N. Levinson, A second order diﬀerential equation with singular solutions,
Ann. Math. 50(19): 127–152.
[101] T.Y. Li, J.A. Yorke, Period three implies chaos, Amer. Math. Monthly,
82(1975): 985–992.
[102] W.C. Lindsey, Synchronization Systems in Communication and Control,
Prentice-Hall, Englewood Cliﬀs, N.J., 1972.
[103] J.L. Lions, A. Bensoussan, G. Papanicolaou, Asymptotic analysis for
periodic structures, North-Holland, New York, 1978.

308
References
[104] E.N. Lorenz, Deterministic nonperiodic ﬂow, J. Atoms. Sci. 20(1963): 130–
141.
[105] W. Magnus, S. Winkler, Hill’s Equation, Wiley-Interscience, New York,
1966.
[106] I.G. Malkin, Theorie der Stabilit¨at einer Bewegung, Oldenbourg, Munich,
1959.
[107] B.B. Mandelbrot, The Fractal Geometry of Nature, Updated and Aug-
mented. W.H.Freeman, New York, 1983.
[108] J.L. Massera, Contributions to stability theory, Ann. Math. 64(1956): 182–
206.
[109] J.L. Massera, J.J. Schaﬀer, Linear Diﬀerential Equations and Function
Spaces, Academic Press, New York, 1966.
[110] S.W. McDonald, C. Grebogi, E. Ott, J.A. Yorke, Fractal basin boundaries,
Physica 17D (1985): 125–153.
[111] N.N. Minorsky, Nonlinear Oscillations, Van Nostrand, Princeton, 1962.
[112] W.L. Miranker, Numerical Methods for StiﬀEquations and Singular
Perturbation Problems, D. Reidel, Holland, 1981.
[113] E.F. Mishchenko, Asymptotic calculation of periodic solutions of systems
of diﬀerential equations containing small parameters in the derivatives, AMS
Transl. Ser. 2, 18(1961): 199–230.
[114] C. Moler, On the calculation of exponentials of matrices, SIAM Review,
1980.
[115] J. Moser, On the theory of quasi-periodic motions, SIAM Rev. 8(1966):145–
171.
[116] J. Moser, Stable and Random Motions in Dynamical Systems: With Special
Emphasis on Celestial Mechanics, Princeton University Press, Princeton,
1973.
[117] M.E. Munroe, Introduction to Measure and Integration, Addison-Wesley,
Cambridge, Mss., 1953.
[118] R. Novick, F.C. Hoppensteadt, On plasmid incompatibility, Plasmid
1(1978):421–434.
[119] R.D. Nussbaum, H.O. Peitgen, Special and spurious solutions of dx/dt =
−aF(x(t −1)), Mem. AMS 51(310)1984.
[120] R.E. O’Malley, Introduction to Singular Perturbations, Academic Press,
New York, 1974.
[121] O. Perron, ¨Uber stabilit¨at und asymptotisches verhalten der Integrale von
Diﬀerential-gleichgungensysteme, Math. Zeit. 29(1929): 129–160.
[122] S.C. Persek, F.C. Hoppensteadt, Iterated averaging methods for systems of
ordinary diﬀerential equations with a small parameter, Comm. Pure Appl.
Math. 31(1978): 133–156.
[123] L.S. Pontryagin, Asymptotic behavior of the solutions of systems of dif-
ferential equations with a small parameter in the higher derivatives, AMS
Transl. Ser. 2, 18(1961): 295–320.

References
309
[124] Preconditioned Conjugate Gradient Methods, Springer-Verlag, New York,
1990.
[125] W. Rudin, Real and Complex Analysis, McGraw-Hill, 1966.
[126] A.N. Sarkovski, Ukr. Math. Zh. 16(1964): 61–71. See also P. Stefan, A
theorem of Sarkovskii on the existence of periodic orbits of continuous
endomorphisms of the real line, Comm. Math. Phys. 54(1977): 237–248.
[127] E.E. Sel’kov, Stabilization of energy charge, generation of oscillations
and multiple steady states in energy metabolism as a result of purely
stoichiometric regulation, Eur. J. Biochem. 59(1975)197–220.
[128] N.N. Semenov, Chemical Kinetics and Chain Reactions, Clarendon, Oxford,
1935.
[129] C.L. Siegel, J. Moser, Lectures in Celestial Mechanics, Springer-Verlag, New
York, 1971.
[130] J. Smoller, Shock Waves and Reaction-Diﬀusion Equations, Springer-
Verlag, New York, 1983.
[131] P.E. Sobolevski, Equations of parabolic type in Banach space, AMS
Translation, 49(1966): 1–62.
[132] J.J. Stoker, Nonlinear Vibrations, Wiley, New York, 1950.
[133] R. Thom, Structural Stability and Morphogenesis: An Outline of a General
Theory of Models, W.A. Benjamin, Reading, Mass., 1975.
[134] S. Ulam, A Collection of Mathematical Problems, Wiley-Interscience, New
York, 1960.
[135] M.M. Vainberg, V.A. Trenogin, Theory of Branching of Solutions of
Nonlinear Equations, Noordhoﬀ, Leyden, 1974.
[136] M. van Dyke, Perturbation Methods in Fluid Mechanics, Parabolic Press,
Palo Alto, CA, 1975.
[137] A.B. Vasil’eva, Asymptotic formulae for the solution of a system of ordinary
diﬀerential equations containing parameters of diﬀerent orders of smallness
multiplying the derivatives, Dokl. Akad. Nauk SSSR 128(1959): 1110–1113.
[138] A.B. Vasil’eva, V.F. Butuzov, Asymptotic Expansions of Solutions of
Singularlty Perturbed Equations, Nauka, Moscow, 1973 (in Russian).
[139] W. Wasow, Asymptotic Expansions for Ordinary Diﬀerential Equations,
Interscience, New York, 1965.
[140] N. Wiener, The Fourier Integral and Certain of its Applications, Dover,
New York, 1958.
[141] S. Wiggins, Introduction to Applied Nonlinear Dynamical Systems and
Chaos, Springer-Verlag, New York, 1990.
[142] D.E. Woodward, Phase locking in model neuron networks having group
symmetries, Dissertation, University of Utah, 1988.
[143] T. Yoshizawa, Stability Theory and the Existence of Periodic and Almost
Periodic Solutions, Springer-Verlag, New York, 1975.

Index
λω-system, 110, 133
H2–O2 elementary reactions, 289
ω-limit set, 104
action integral, 4, 42
active transmission line, 48
almost harmonic system, 214
almost-periodic, 18–20, 220
ampliﬁcation rate, 291
angle-action coordinates, 49
angle-action variables, 51
angular phase equations, 40
Approximation of the Averaging
Limit, 236
asymptotic expansion, 148, 161
asymptotically stable, 92, 288
asymptotically stable uniformly in
the parameters, 265
atoll oscillator, 296
Averaging Theorem for Linear
Diﬀerence Equations, 211
Averaging Theorem for Linear
Systems, 205
Averaging Theorem for Mean-Stable
Systems, 202
Baker–Campbell–Hausdorﬀtheorem,
211
bifurcation equations, 129, 184
Bogoliubov’s Averaging Theorem, 223
Bogoliubov’s Theorem, 233
Brouwer’s Fixed-Point Theorem, 138
Brownian motion, 240
canonical models, 135
canonical problem, 289
capacity of the curve, 191
Carath´eodory system, 226, 267
Cauchy’s formula, 9
center frequency, 2
center manifold, 9, 99
chaos, xvi
characteristic equations, 54
characteristic exponent, 14, 112, 276
characteristic multipliers, 14, 112
circle mapping property, 72
col, 112
companion matrix, 6
comparison functions, 99
Condition KAM, 233
Condition L, 222
conservative system, 62
Contraction Mapping Principle, 136

312
Index
cusp, 63, 64, 296
cusp bifurcation, 134
Delaunay orbit elements, 224
delta function, 264
Denjoy’s Theorem, 39, 116
diagonalizable matrix, 6
Diﬀerence Equation Averaging
Theorem, 209
diﬀerential-delay equation, 143
diﬀerential-diﬀerence equations, 78
diﬀusion equation, 240
diﬀusion processes, 241
discrete oscillatory matrix, 210
discrete stable matrix, 211
dissipative system, 62
distribution function, 239
domain of attraction, 93
Duﬃng’s equation, 32, 45, 174, 184,
188
Duﬃng’s Iterative Method, 176, 180
entropy, 67, 70, 102, 115
ergodic Markov chain, 242
ergodic measure, 241
Ergodic Theorem, 237
Euler’s forward diﬀerence method,
227
Euler–Lagrange equation, 4, 43
exchange of stabilities, 133, 161
expected value, 239
explosion rate, 291
exponential dichotomy, 97
exponential distribution, 242
exponential integral function, 119
exponentially asymptotically stable,
93, 228, 271
extrapolation, 237
extrapolation approximation, 295
extrapolation method, 294
Fibonacci sequence, xvi
ﬁlters, 3
ﬁrst explosion limit, 292
ﬁrst-order branching problem, 292
FitzHugh–Nagumo model, 84
ﬁxed point of period m, 66
Floquet’s Theorem, 12, 112
ﬂows on a torus, 231
Fokker–Planck equation, 298
fractal curve, 191
Fredholm’s Alternative, 122, 166
frequency-response relation, 178
Friedrichs–Wasow Theorem, 276
fundamental matrix, 12
fundamental solution, 23
gauge relations, 147
Gaussian random variable, 244
Gear’s package, 292
genetic type, 299
gradient method, 101
gradient systems, 101
Gronwall’s Inequality, 95, 154, 202
Hadamard’s mappings, 75
Hamilton’s principle, 4, 42
Hamilton–Jacobi, 87
Hamilton–Jacobi equation, 53
Hamiltonian system, 49, 53, 82, 87,
219, 227
hard spring, 179
harmonic mean, 235
harmonic oscillator, 37, 215
Hausdorﬀdimension, 193
Heaviside’s operator, 3
heteroclinic, 44
higher harmonics, 180
Hill’s equation, 14, 114
homoclinic, 44
homoclinic points, 78
Homogenization, 234
Hopf bifurcation, 134, 287
Huygen’s Problem, 116
hyperbolic point, 29
hysteresis, 61, 182
Implicit Function Theorem, 126, 171
index, 141
initial transient, 251, 270
Initial Transient Theorem, 262, 264
inner product, 165
integrable systems, 50
integration by parts, 151, 264
invariant torus, 219
isochrons, 37
iteration histogram, 67

Index
313
Jacobi’s matrix, 14
Jacobian, 83
Jordan canonical form, 7
Josephson junction, 282
Julia set, 188
KAM Theorem, 233
KAM theory, 233
kernel, 122
kinetic energy, 42
Kronecker ﬂow, 74
l.o.t., 143
Lagrangian, 42
Landau’s Equation, 285, 287, 297
Laplace inversion formula, 9
Laplace transform, 9
Laplace’s Integral Formulas, 151
Laplace’s method, 207
Law of the Iterated Logarithm, 242
least-squares method, 142
least-squares solution, 124
left boundary-layer correction, 282
Liapunov function, 99, 120, 266
Liapunov–Schmidt Method, 129, 132
Lie’s theory, 49
Lienard’s equation, 104, 110
Linear Quasistatic-State Theorem,
259
linear spline, 80
Linear Stability Theorem, 95, 286
Liouville’s Theorem, 56
lock-washer oscillator, 65
Lorenz’s system, 32, 266
low-pass ﬁlter, 10
Malkin’s Theorem, 107
Markov chain, 69, 212
Markov jump process, 242
Massera’s Inverse Theorem, 106, 120
matching conditions, 264
Mathieu’s equation, 15
mean diﬀusivity, 235
Mean Stable Averaging Theorem,
210, 225, 288
mean value, 239
merry-go-round chain, 214
Method I, 150
Method II, 150
method of invariant manifolds, 223
method of residues, 9
Michaelis–Menten Approximation,
271
modes of rapid oscillation, 200
modiﬁed perturbation method, 172,
173, 175, 178, 182
Modiﬁed Perturbation Theorem, 159
moments, 239
Monte Carlo simulation, 70
multi-index, 20
multitime algorithm, 299
multitime method, 246
near-identity transformations, 222
Newton’s method, 187, 293
Newton’s polygon method, 131, 143
Newton’s polygons, 161
nilpotent matrix, 7
No-Retract Theorem, 139
node, 80
Nonlinear Averaging Theorem, 201
Nonlinear Diﬀerence Equation
Averaging Theorem, 245
nonlinear diﬀusion equation, 246
nonlinear renewal equation, 299
nonresonance, 167
Nonresonance Theorem, 168
nonresonant, 164
normal random variable, 240
Ohm’s Law, 3
orbit, 66, 109
orbital stability, 109
orbitally asymptotically stable, 109,
114, 288
orbitally stable, 109
orbitally stable under persistent
disturbances, 109, 111
order-of-magnitude, 147
ordinary language model, xiii
orthogonal complement, 122
oscillatory matrix, 206, 214
oscillatory modes, 8
Pad´e approximation, 148
pendulum, 51
period, 281
Perron integral equations, 98, 118

314
Index
Perron’s Theorem, 98
phase equation, 35
phase locked loop, 40, 57
Phase Locking Theorem, 226
phase-amplitude coordinates, 2, 87,
215, 219
phase-amplitude variables, 51
pitchfork bifurcation, 97
PLL, 223
Poincar´e’s mapping, 72, 194
Poincar´e’s Twist Theorem, 74, 83,
142
Poincar´e–Bendixson Theorem, 31, 84,
110
Poincar´e–Bendixson’s Theory, 29
Poincar´e–Linstedt method, 178
Poisson bracket, 49
potential energy, 42
probability density function, 239, 240
probability simplex, 102, 115
probability space, 238
projection matrices, 6
pull-back mapping, 140
QSSA, 253
QSSA Theorem with T = ∞, 271
quasiperiodic function, 19, 220
quasistatic manifold, 265, 289
Quasistatic Manifold Theorem, 266
quasistatic oscillation, 274
quasistatic state, 264, 284
quasistatic-state approximation, 251
Quasistatic-State Approximation
Theorem, 269, 293
Quasistatic-State Theorem, 267
random processes, 240
random signals, 240
random variable, 239
reduced oscillation, 273
reduced problem, 265, 280
Regular Perturbation Theorem, 152,
156
resonance, 22, 164, 167
Resonant Forcing Theorem, 171
return mapping, 113, 119
return time, 113
Riemann–Lebesgue Lemma, 207
right boundary-layer correction, 283
RLC circuit, 3
rotation number, 39, 74, 227
rotation vector, 116, 226
rotation vector method, 116, 222
Rotational System, 212
Routh–Hurwitz Criterion, 88
saddle point, 29
saddle-node on limit cycle bifurcation,
134
saddle-saddle connection, 61
Sarkovski sequence, 66, 187
Schr¨odinger’s equation, 14
second diﬀerence method, 236
secular term, 173
self-adjoint, 166
semi-implicit Euler numerical
algorithm, 83
several small parameters, 295
sine–Gordon equation, 282
single locus, 299
slow selection, 299
small divisor problem, 23, 200, 222
soft spring, 179
solvability conditions, 123, 129
spectral decomposition, 6, 103
spiral sink, 29
spiral source, 29
stability under persistent
disturbances, xviii, 93, 107,
133, 138, 197, 203, 250, 251,
266, 268
stable, 92
stable ﬁxed point, 66
stable manifold, 8, 78, 98
stable matrix, 262
stable node, 29
stable spiral, 29
stationary phase, 152
steepest descent, 207
sticky layer, 266
stiﬀness, 292
stochastic diﬀerential equations, 240
stochastic integral, 240
strange attractor, 88
stroboscopic method, 73
structural stability, xviii, 108
subharmonics, 179
subresonance, 164, 167

Index
315
suppressing secular terms, 178
switching times, 242
Taylor’s expansion, 148
Theorem on Linear Spline
Approximation, 81
time delays, 78
toroidal clock, 38
toroidal knot, 86
total stability, 93
trace, 25, 28
transfer function, 4, 79
translation number, 18
transpose, 122
transversal homoclinic point, 78
transversal plane, 113
triangle fractal, 194
triangular coordinates, 299
two time scales, 234
two-body problem, 54
two-time scale method, 204
uniformly asymptotically stable, 93,
100, 106, 203
unstable manifold, 9, 78, 98
unstable node, 29
unstable spiral, 29
van der Pol’s Equation, 35, 57, 64,
189, 217, 280
variance, 239
variation of constants formula, 12, 23,
94
VCO, 38
VCON, 57
voltage-controlled oscillator, 2
volume-preserving mappings, 142
Wazewski’s Theorem, 140, 143
Weak Ergodic Theorem, 21
weakly connected networks, 219
Weierstrass Preparation Theorem,
131, 143
Wronskian matrix, 14



