THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3,1-61
Printed in the United States of America
Rules and representations
Noam Chomsky
Department of Linguistics and Philosophy, Massachusetts Institute of
Technology, Cambridge, Mass. 02139
Abstract: The book from which these sections are excerpted (N. Chomsky, Rules and Representations, Columbia University Press, 1980) is
concerned with the prospects for assimilating the study of human intelligence and its products to the natural sciences through the investigation
of cognitive structures, understood as systems of rules and representations that can be regarded as "mental organs." These mental structufes
serve as the vehicles for the exercise of various capacities. They develop in the mind on the basis of an innate endowment that permits the
growth of rich and highly articulated structures along an intrinsically determined course under the triggering and partially shaping effect of
experience, which fixes parameters in an intricate system of predetermined form. It is argued that the mind is modular in character, with a
diversity of cognitive structures, each with its specific properties and principles. Knowledge of language, of the behavior of objects, and much
else crucially involves these mental structures, and is thus not characterizable in terms of capacities, dispositions, or practical abilities, nor is it
necessarily grounded in experience in the standard sense of this term.
Various types of knowledge and modes of knowledge acquisition are discussed in these terms. Some of the properties of the language faculty
are investigated. The basic cognitive relation is "knowing a grammar"; knowledge of language is derivative and, correspondingly, raises further
problems. Language as commonly understood is not a unitary phenomenon but involves a number of interacting systems: the "computational"
system of grammar, which provides the representations of sound and meaning that permit a rich range of expressive potential, is distinct from a
conceptual system with its own properties; knowledge of language must be distinguished from knowledge of how to use a language; and the
various systems that enter into the knowledge and use of language must be further analyzed into their specific subcomponents.
Keywords: evolution; grammar; knowledge; language; mental structures
1. Mind and body
In this paper I would like to explore a number of issues
relating to human cognitive capacities and the mental struc-
tures that serve as the vehicles for the exercise of these
capacities. Plainly, this formulation of a problem embodies
assumptions that are far from clear and are highly controver-
sial insofar as they are clear. I will try to make them clearer
and, I hope, more plausible as I proceed. In the end, the best
way to clarify and evaluate these assumptions is to construct
specific models guided by them in particular domains, then to
ask how these models fare when interpreted as explanatory
theories. If the leading ideas are appropriate, they will be
sharpened and justified by the success of explanatory theories
that develop them in a specific way. I will not attempt a
systematic presentation of such a model here, but I will
discuss properties of some that are being investigated -
though in technical studies they are not presented in these
terms, which, I want to suggest, are the appropriate terms.
The cognitive domain that will primarily concern me is
human language. The reason for the choice is in part person-
al, relating to limits of my own understanding. I think it is fair
to say, however, that the issues are more easily formulated
and better understood in connection with human language
than other domains of human cognition - which is not to say
that they are clearly formulated or well understood. There
are some who would virtually identify the study of language
and the study of mind (such as Quine, 1975, in terms of
dispositions). This is not my own view.
I would like to think of linguistics as that part of psychology
that focuses its attention on one specific cognitive domain and
one faculty of mind, the language faculty. Psychology, in the
sense of this discussion, is concerned, at the very least, with
human capacities to act and to interpret experience, and with
the mental structures that underlie these capacities and their
exercise; and more deeply, with the second-order capacity to
construct these mental structures (see Chomsky 1975a for
more detail).
The term "capacity" is used with varying degrees of
strictness. When I say that a person has the capacity to do
so-and-so at a particular time, I mean that, as physically and
mentally constituted at that time, he needs no further instruc-
tion, learning, training, or physical development, to do so-
and-so; if placed under appropriate external conditions, he is
able to do it. Thus, a person who does not know how to swim
lacks the capacity to swim, in this sense. Similarly, the
Olympic swimming champion lacks the capacity to swim if
his arms and legs are amputated or broken, but not if he is
tied to a chair or asleep or absorbed in a book. Thus, having
the capacity to do so-and-so is not the same as knowing how to
do so-and-so; in particular, there is a crucial intellectual
component in "knowing how" (Chomsky 1975b). We might
distinguish further between what one is able to do at will and
what falls within one's capacity, though one cannot do it at
will. Thus Babe Ruth had the capacity to hit a home run, but
not at will, whereas he had the capacity to lift a bat at will (cf.
Danto and Morgenbesser 1957).
There is also a second-order sense of "capacity," as when
we say that any normal child has the capacity to swim, or to
run a mile, or to speak Italian, if only given the appropriate
training or opportunities for development. In this sense the
child does not have the capacity to fly, and other (terrestrial)
organisms do not have the capacity to speak Italian. Some-
times the term is used more loosely, as when we speak of
"capacities" in the sense of "mental faculties." The distinc-
tions can be sharpened, but this should be enough for my
purposes here.
To begin with, let us assume that it makes sense to say, as
we normally do, that each person knows his or her language -
that you and I know English, for example - that this knowl-
edge is in part shared among us and represented somehow in
our minds, ultimately in our brains, in structures that we can
Â© 1980 Cambridge University Press
0140-525X/B0/010001-62SA. 00/0

Chomsky: Rules and representations
hope to characterize abstractly, and in principle quite
concretely, in terms of physical mechanisms. When I use
terms such as "mind," "mental representation," "mental
computation," and the like, I am keeping to the level of
abstract characterization of the properties of certain physical
mechanisms, as yet almost entirely unknown. There is no
further ontological import to such references to mind or
mental representations and acts. In the same way, a theory of
human vision might be formulated in concrete terms, refer-
ring, say, to specific cells in the visual cortex and their
properties; or it might be formulated abstractly in terms of
certain modes of representation (say, images or stick-figure
sketches), computations on such representations, organizing
principles that determine the nature of such representations
and rules, and so on. In the latter case the inquiry belongs to
the study of mind in the terminology that I will adopt, though
it need in no sense imply the existence of entities removed
from the physical world.
I am interested, then, in pursuing some aspects of the study
of mind - in particular, such aspects as lend themselves to
inquiry through the construction of abstract explanatory
theories that may involve substantial idealization and will be
justified, if at all, by success in providing insight and explana-
tions. From this point of view, substantial coverage of data is
not a particularly significant result; it can be attained in many
ways, and the result is not very informative as to the correct-
ness of the principles employed. It will be more significant if
we show that certain fairly far-reaching principles interact to
provide an explanation for crucial facts - the crucial nature of
these facts deriving from their relation to proposed explana-
tory theories. It is a mistake to argue, as many do, that by
adopting this point of view one is disregarding data. Data that
remain unexplained by some coherent theory will continue to
be described in whatever descriptive scheme one chooses, but
they will simply not be considered very important for the
moment.
From this point of view we can proceed to approach the
study of the human mind much in the way that we study the
physical structure of the body. In fact, we may think of the
study of mental faculties as actually being a study of the
body - specifically the brain - conducted at a certain level of
abstraction. It may be useful, as a point of departure, to
consider for a moment how we do proceed to study the
human body.
We assume, no doubt correctly, that the human species is
characterized by a certain biological endowment. The
embryo grows ultimately to the adult as its genetic program
unfolds under the triggering and shaping effect of the envi-
ronment. These effects are worth distinguishing. Take the
standard conditioning paradigm, in which a course of behav-
ior is constructed in a step-by-step process by manipulation of
reinforcement contingencies - that is, contingencies that for
some reason change the probability of behavior. This is an
example of a shaping effect of the environment. Or suppose
that there is some domain, however narrow, in which tradi-
tional empiricist psychology is valid; say that a child receives
simultaneously a visual and an auditory impression and
associates them, the residue of the auditory impression serv-
ing as the name of the object taken to have caused the visual
impression. There are notorious problems in working any of
this out - crucially, the problem of how we can have sensory
experience uninformed by conceptual judgement (see, for
example, Williams 1977; Schopenhauer 1974). But suppose
that we put these problems aside. Then the empiricist para-
digm can serve as an example of the shaping effect of the
environment on knowledge, furthermore a case in which
there is some sort of "resemblance" between what is in the
mind and what it perceives.
Suppose, in contrast, that certain environmental conditions
are required to set in operation an intrinsically determined
process, as nutrition is required for cellular growth to take
place in predetermined ways. (It has been reported, for
example, that handling of rats induces lateralization for
spatial and affective processes; Denenberg et al. 1978.) In
such cases the processes that take place are not shaped by the
environment; they do not reflect the course of interchange
with it or somehow "resemble" the stimulus, any more than a
child is a reflection of the food he eats. When external
conditions are necessary for or facilitate the unfolding of an
internally controlled process, we can speak of their "trigger-
ing" effect. If institutionalized children do not learn a
language, the reason may be that a crucial triggering factor
(appropriate social interchange) is lacking, as in the case of
Harlow's deprived monkeys [see Rajecki et al.: "Toward a
General Theory of Infantile Attachment" BBS 1(3) 1978]; but
we would not therefore say that attention, care, and love
shape the growth of language in the sense that a schedule of
reinforcement shapes the behavior of a pigeon. The distinc-
tion between the two kinds of effects of the environment is
not sharp, but it is conceptually useful. My own suspicion is
that a central part of what we call "learning" is actually
better understood as the growth of cognitive structures along
an internally directed course under the triggering and
partially shaping effect of the environment. In the case of
human language, there evidently is a shaping effect; people
speak different languages, which reflect differences in their
verbal environment. But it remains to be seen in what
respects the system that develops is actually shaped by experi-
ence, rather than reflecting intrinsic processes and structures
triggered by experience.
Returning to the analogy to the physical body, we take for
granted that the organism does not learn to grow arms or to
reach puberty - to mention an example of genetically-
determined maturation that takes place long after birth.
Rather, these developments are determined by the genetic
endowment, though the precise manner in which the genetic
plan is realized depends in part on external factors, both
triggering and shaping. For example, nutritional level can
apparently affect the tirne of onset of puberty over a consid-
erable range. As the biological plan unfolds, a system of
interacting organs and structures matures - the heart, the
visual system, and so on, each with its specific structures and
functions, interacting in largely predetermined ways.
Our biological endowment determines both the scope and
limits of physical growth. On the one hand, it permits the
growth of a complex system of highly articulated physical
organs, intrinsically determined in their essential properties.
Were it not for this highly specific innate endowment, each
individual would grow into some kind of an amoeboid crea-
ture, merely reflecting external contingencies, one individual
quite unlike another, each utterly impoverished and lacking
the intricate special structures that make possible a human
existence and that differentiate one species from another. Our
biological endowment permits a vast potential for develop-
ment, roughly uniform for the species. At the same time, it in
fact narrowly limits what each individual can become; the
human embryo presumably cannot become a bird by modifi-
cation of the external environment. Scope and limits of
development are intimately related. Innate factors permit the
organism to transcend experience, reaching a high level of
complexity that does not reflect the limited and degenerate
environment. These very same factors rule out many possible
courses of development and limit drastically the final states
that can be attained in physical growth.
Now all of this should be transparent and hardly controver-
sial. Apparently very little is known about how any of it
happens, but no one really doubts that something of this sort is
roughly true. If it were proposed that we "taught" to pass
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Chomsky: Rules and representations
through puberty, or "learn" to have arms rather than wings,
no one would take the suggestion very seriously, even in the
present state of ignorance concerning the mechanisms
involved. Why is this so? Presumably the reason derives from
the vast qualitative difference between the impoverished and
unstructured environment, on the one hand, and the highly
specific and intricate structures that uniformly develop, on
the other.
When we turn to the mind and its products, the situation is
not qualitatively different from what we find in the case of
the body. Here, too, we find structures of considerable
intricacy, developing quite uniformly, far transcending the
limited environmental factors that trigger and partially shape
their growth. Language is a case in point, though not the only
one. Think, for example, of the capacity to deal with the
number system, common to humans (aside from those with
gross pathology) and, as far as we know, unique to humans,
surely a major factor in the remarkable success of the "Gali-
lean style" in physics. Russell once wrote that we would not
have developed the concept of number had we lived on the
sun. Perhaps the opportunity to employ those faculties of
mind that present us with a world of individual objects
provides a triggering effect for the growth of the "number
faculty," but beyond that, it seems reasonable to suppose that
this faculty is an intrinsic component of the human mind.
One should not be misled by the fact that some birds, for
example, can be taught to pick n elements from an array for
small n - about up to seven (Koehler 1956). The very essence
of the number system is the concept of adding one, indefi-
nitely. The concept of infinity is not just "more" than seven,
just as human language, with its discrete infinity of meaning-
ful expressions, is not just "more" than some finite system of
symbols that can laboriously be imposed on other organisms
(nor, by the same token, just "less" than an essentially
continuous system of communication, like the dance of bees -
(see Cognition and consciousness in nonhuman species, BBS
1(4) 1978). The capacity to deal with the number system or
with abstract properties of space is surely unlearned in its
essentials. Furthermore, it is not specifically "selected"
through evolution, one must assume - even the existence of
the number faculty could not have been known, or the
capacity exercised, until human evolution had essentially
reached its current stage.
We may usefully think of the language faculty, the number
faculty, and others as "mental organs," analogous to the heart
or the visual system or the system of motor coordination and
planning. There appears to be no clear demarcation line
between physical organs, perceptual and motor systems, and
cognitive faculties in the respects in question. In short, there
seems little reason to insist that the brain is unique in the
biological world, in that it is unstructured and undifferen-
tiated, developing on the basis of uniform principles of
growth or learning - say those of some learning theory, or of
some yet-to-be conceived general-purpose learning strategy -
that are common to all domains.
David Hubel, who has pioneered some of the most exciting
work of recent years on the physical basis for mammalian
vision, concludes that
". . . we are led to expect that each region of the central
nervous system has its own special problems that require
different solutions. In vision we are concerned with
contours and directions and depth. With the auditory
system, on the other hand, we can anticipate a galaxy of
problems relating to temporal interactions of sounds of
different frequencies, and it is difficult to imagine that the
same neural apparatus deals with all of these phenomena
... for the major aspects of the brain's operation no master
solution is likely (Hubel 1978)."
There may well be properties common to diverse systems. For
example, experience is necessary for "fine tuning" of the
visual and auditory systems, as it is for other systems that
develop in accordance with fixed genetic instructions. Recent
work on motor coordination in monkeys seems to show "that
many motor programs are part of a primate's genetic endow-
ment. No sensory feedback or spinal reflex loops are necessary
for learning the repertoire of movements . . . though . . .
sensory feedback is necessary for 'fine tuning'. . . ." (Taub
1976). [See also Roland: "Sensory Feedback to the Cerebral
Cortex During Voluntary Movement in Man" BBS 1(1) 1978.]
Perceptual and motor systems are doubtless partly "set ' by
the shaping effect of other aspects of the environment (Blake-
more 1973), but the systems that emerge seem to be highly
specialized and intrinsically programmed in quite different
ways. In short, what is taken for granted without direct
evidence in the case of physical growth on the basis of an
implicit argument from poverty of the stimulus is also being
found in the study of the brain and nervous system - not
surprisingly, one would think.
In the case of cognitive faculties, it is widely assumed that
development is uniform across domains, and that the intrinsic
properties of the initial state are homogeneous and undiffer-
entiated - an assumption found across a spectrum of opinion
reaching from Skinner to Piaget (who differ on much else)
and common in contemporary philosophy as well. Notice that
there are two issues here: the issue of innate structure, and
that of modularity. One might hold that there is rich innate
structure but little or no modularity. But there is a relation
between the views, in part conceptual. Insofar as there is little
in the way of innate structure, what develops in the mind of
an individual will be a homogeneous system derived by the
application to experience of common principles that consti-
tute the innate endowment. Such differentiation as there may
be will reflect differentiation in the environment. Corre-
spondingly, the belief that various systems of mind are
organized along quite different principles leads to the natural
conclusion that these systems are intrinsically determined, not
simply the result of common mechanisms of learning and
growth. It is not surprising, then, to find that opinions
"cluster. " Those who tend toward the assumption of modular-
ity tend also to assume rich innate structure, while those who
assume general multipurpose learning mechanisms tend to
deny modularity.
Once we begin to take seriously the actual states attained in
particular cases, we are, I believe, led to the conclusion that
intrinsic structure is rich (by the argument from poverty of
the stimulus) and diverse (by virtue of the apparent diversity
in fundamental principles of capacities and mental structures
attained). These conclusions are, I think, to be expected in the
case of systems that have any significant function in the life of
an organism. As noted, they are taken for granted without
much thought or evidence in the study of physical develop-
ment; no one doubts that the instructions for a liver and visual
system will be quite different. Insofar as anything is known
about cognitive systems - which is not very far - the related
assumptions of poverty of initial structure and homogeneity
do not seem tenable, and the general line of argument that
keeps analogous assumptions from being considered at all in
the case of physical growth seems applicable. The more we
learn about specific systems, that more applicable it becomes,
and I would hazard a guess that this will continue to be so. In
the case of human conceptual systems, for example, intrinsic
even to such apparently elementary notions as "thing" or
"object," there is a subtle interaction between conditions of
spatiotemporal contiguity, the willed acts of an agent respon-
sible for the object, and other factors (see Chomsky 1975a). It
is difficult to interpret this except in terms of our intrinsic
modes of cognition. When we turn to language, many exam-
ples have been studied of shared knowledge that appears to
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Chomsky: Rules and representations
have no shaping stimulation - knowledge without grounds,
from another point of view - and that seems to be based on
principles with only the most superficial resemblances to
those operative in other cognitive domains.
Let me give some simple examples, in part to illustrate the
point, and in part for later reference. Consider, for example,
the process of forming questions. We select some noun phrase
in a sentence, replace it by an appropriate questionword,
place the latter at the beginning of the sentence, and with
other mechanical operations, form a question. Thus, on the
model of the sentence, "John saw a man," we can form
"Whom did John see?" Or, to take a more complex case, on
the model of the sentence, "The teacher thought that his
assistant had told the class to study the lesson," we can
question "the class" and ask: "Which class did the teacher
think that his assistant had told to study the lesson?" But
consider the following example, of roughly comparable
complexity: "The lesson was harder than the teacher had told
the class that it would be." Here, if we question "the class,"
we derive: "Which class was the lesson harder than the
teacher had told that it would be?" Evidently, this is not a
well-formed question, though its intended sense is clear
enough and perfectly intelligible, with a little thought. It is
difficult to imagine that people capable of these judgments
have all had relevant training or experience to block the
obvious inductive generalization. Rather, it seems that some
specific property of the human language faculty - hence a
general property of language - leads to these consequences, a
property that derives from our modes of cognition.
To take a second case, consider the rule forming reciprocal
expressions such as, "The men saw each other." A child
learning English, or someone learning English as a second
language, must learn that "each other" is a reciprocal expres-
sion - that is, an idiosyncratic fact about English. Given that
it is a reciprocal expression, it must have an antecedent: for
example, "the men" in "The men saw each other," which has
the meaning, roughly: "Each of the men saw the other." The
antecedent can be in a different clause, as in: "The candidates
wanted [each other to win]," where "each other" appears in a
subordinate clause as the subject of "win," whereas its ante-
cedent, "the candidates," appears in the main clause. Some-
times, however, the reciprocal cannot find its antecedent
outside of its clause, as in: "The candidates wanted me to vote
for each other," which is not well-formed with the perfectly
sensible meaning: "Each of the candidates wanted me to vote
for the other." One might assume that the antecedent must be
the "nearest noun phrase," but this is false, as we can see from
such sentences as, "The candidates hurled insults at each
other." While this sentence could mean that the candidates
hurled each insult at the other insults, plainly that is not the
way we normally interpret it.
In this case, too, it can hardly be maintained that children
learning English receive specific instruction about these
matters, or even that they are provided with relevant experi-
ence that informs them that they should not make the obvious
inductive generalization, say, that "each other" takes some
plural antecedent that precedes it. Children make many
errors in language learning, but they do not assume, until
corrected, that "The candidates wanted me to vote for each
other" is a well-formed sentence meaning that each candidate
wanted me to vote for the other. Relevant experience is never
presented for most speakers of English, just as no pedagogic or
traditional grammar, however compendious, would point out
these facts. Somehow, this is information that the children
themselves bring to the process of language acquisition as part
of their mode of cognition.
Some general principle of language applies to permit the
proper choice of antecedent - not an entirely trivial matter,
as these examples suggest. Similarly, some general principle
of language determines which phrases can be questioned.
These principles, which have many ramifications, are among
those that provide a basic framework within which knowl-
edge of language develops as the child progresses to the
mature state of knowledge; they are on a par with the factors
that determine that the child will have binocular vision. As
we consider such principles and their interaction, we begin to
approach the richness of the language faculty - one element
of our biological endowment, and, it appears, a distinctive
element.
It would be surprising indeed if we were to find that the
principles governing these phenomena are operative in other
cognitive systems, although there may be certain loose
analogies, perhaps in terms of figure and ground, or proper-
ties of memory, as we see when the relevant principles are
made explicit. Such examples illustrate two points, in the
present connection: first, that there is good reason to suppose
that the functioning of the language faculty is guided by
special principles specific to this domain; second, that the
argument from poverty of the stimulus provides a useful
device for inquiry into these principles - indeed, at the
moment, the most useful device, I think, for inquiring into
universal grammar.
It seems reasonable to assume that the language faculty -
and, I would guess, other mental organs - develops in the
individual along an intrinsically determined course under the
triggering effect of appropriate social interaction and
partially shaped by the environment - English is not Japa-
nese, just as the distribution of horizontal and vertical recep-
tors in the visual cortex can be modified by early visual
experience. The environment provides the information that
questions are formed by movement of a question word and
that "each other" is a reciprocal expression; in other
languages this is not the case, so that these cannot be proper-
ties of biological endowment in specific detail. Beyond such
information, much of our knowledge reflects our modes of
cognition and is therefore not limited to inductive generaliza-
tion from experience, let alone any training that we may have
received. And just as the visual system of a cat, though
modified by experience, will never be that of a bee or a frog,
so the human language faculty will develop only one of the
human languages, a narrowly constrained set.
A familiar argument against a modular approach to the
study of mind is that it "reduces the possibility of viewing
language as an aspect of the total corpus of behavior" and
"obscures the connections between language and other
aspects of cognition" (Hill and Most 1978, pp. 651-2). By
parity of argument, we should conclude that the belief that
the eye and the ear work on different principles reduces the
possibility of viewing vision as an aspect of behavior and
obscures the relations between vision and hearing. It is a sad
commentary on the field that such arguments can even be
advanced.
Consider again the question whether cognitive functions
are both diverse and determined in considerable detail by a
rich innate endowment. If the answer is positive, for some
organism, that organism is fortunate indeed. It can then live
in a rich and complex world of understanding shared with
others similarly endowed, extending far beyond limited and
varying experience. Were it not for this endowment, individ-
uals would grow into mental amoeboids, unlike one another,
each merely reflecting the limited and impoverished environ-
ment in which he or she develops, lacking entirely the finely
articulated and refined cognitive organs that make possible
the rich and creative mental life that is characteristic of all
individuals not seriously impaired by individual or social
pathology - though, once again, we must bear in mind that
the very same intrinsic factors that permit these achievements
also impose severe limits on the states that can be attained; to
put it differently, that there is an inseparable connection
between the scope and limits of human knowledge.
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Chomsky: Rules and representations
Finally, let me emphasize the limits on the enterprise I
have been outlining. Two individuals with the same genetic
endowment and common experience will attain the same
state - specifically, the same state of knowledge of language
(random elements aside). But this does not preclude the
possibility of diversity in the exercise of this knowledge, in
thought or action. The study of acquisition of knowledge or of
interpretation of experience through the use of acquired
knowledge still leaves open the question of the causation of
behavior and, more broadly, our ability to choose and decide
what we will do.
2. Structures, capacities, and conventions
I began the first section by speaking of human cognitive
capacities and the mental structures that serve as their vehi-
cles; I then went on to consider the legitimacy of studying
such mental structures in the manner of the natural sciences
and the prospects for this study; I ended by expressing some
skepticism as to whether the mind is as uniform and undiffer-
entiated as it is regarded by many modern psychologists and
philosophers. Numerous questions arise at every point along
the way. The questions of initial structure and modularity are
relatively straightforward empirical ones, if we accept the
presuppositions they embody: Is the mind organized into
distinct cognitive faculties with their specific structures and
principles, or are there uniform principles of learning, accom-
modation, assimilation, abstraction, induction, strategy, or
whatever, that simply apply to different stimulus materials to
provide our knowledge of the behavior of objects in physical
space, our knowledge that certain strings of words do or do not
have certain meanings, and so on. It is reasonably clear how to
proceed to settle these issues. As I have already indicated, the
available evidence seems to me to favor a modular approach.
The other questions, while they have an empirical compo-
nent, are nevertheless of a very different order.
To know a language, I am assuming, is to be in a certain
mental state, which persists as a relatively steady component
of transitory mental states. What kind of mental state? I
assume further that to be in such a mental state is to have a
certain mental structure consisting of a system of rules and
principles that generate and relate mental representations of
various types. Alternatively, one might attempt to character-
ize knowledge of language - perhaps knowledge more gener-
ally - as a capacity or ability to do something, as a system of
dispositions of some kind, in which case it is perhaps not
unreasonable to think of behavior as providing a criterion for
the possession of knowledge. In contrast, if such knowledge is
characterized in terms of mental state and structure, then
behavior simply provides evidence for possession of knowl-
edge, as might facts of an entirely different order - electrical
activity of the brain, for example.
The choice between these alternatives cannot be settled by
a priori argument, but only by trying to refine each of them
to the point where we can ask how they fare as theories that
explain some significant range of facts - for example, that
certain sentences do or do not mean such-and-such and that
we know this to be the case. For the moment, at least, there is
no substantive issue. There has been a fair amount of work
sketching theories of rules and representations that have at
least a degree of descriptive and explanatory success. The
proposal that particular items of our knowledge, such as those
given for illustration in the preceding section, can be
explained on the assumption that "the speaker has a number
of abilities" or "has acquired a number of psychological
dispositions" (Kitcher 1978) remains merely a promissory
note. I won't attempt to explore the possibilities of fulfilling
the promise. I suspect that the attraction will dim when it is
recognized how little can be said in terms of "sets of disposi-
tions." Generally the dispositional analysis is put forth on the
grounds that the facts do not compel us to adopt the alterna-
tive, which is true but hardly relevant. Surely it suffices that
the alternative stands as the "best explanation," if that much
is correct. In the absence of a coherent alternative, and with
at least partial successes to show from the study of theories of
rules and representations, I will continue to assume that it is
correct to analyze knowledge of language, and to offer
explanations for particular instances, in terms of mental
structures of rules and representations - to assume, in short,
that our linguistic abilities are based on such mental struc-
tures.
The issue of structure is not a straightforward empirical
one, but it does have an empirical component. In particular,
success in developing a structural theory of mind, knowledge,
and belief would count against the picture of cognition in
terms of capacities without structured vehicles, and would
indicate that the prevailing concern with organization of and
potential for behavior misconceives a certain category of
evidence as criterial.
If, as I am now assuming, to know a language is to be in a
certain mental state comprised of a structure of rules and
principles (comparably, for certain other aspects of cogni-
tion), then in theory one could know a language without
having the capacity to use it. Let's begin by considering this
issue.
Imagine a person who knows English and suffers cerebral
damage that does not affect the language centers at all but
prevents their use in speech, comprehension, or, let us
suppose, even thought. Suppose that the effects of the injury
recede, and, with no further experience or exposure, the
person recovers the original capacity to use the language. In
the intervening period, he had no capacity to speak or
understand English, even in thought, though the mental
(ultimately physical) structures that underlie that capacity
were undamaged. Did the person know English during the
intervening period?
This is reminiscent of the question whether a person who is
in a dreamless sleep can properly be said to know English, or
to know his name. The cognitive property that concerns me
holds of the person who possesses the mental structure, thus of
the aphasic throughout, as we learn from the fact of his
recovery. In this case the fact of his recovery provides
evidence that he had knowledge of English, though none of
his behavior (even his thought) at the time provided any
evidence for possession of this knowledge.
Suppose that there is a second aphasic like the first, but
because of some other and irrelevant problem (say, a circula-
tory disorder) he never recovers speech. Should we say in this
case that the knowledge of English was lost? That would seem
perverse. The first aphasic recovered because he had retained
a certain mental (ultimately physical) state, a certain state of
knowledge - namely, knowledge of English. His recovery
provides evidence for the fact. One can imagine all sorts of
evidence that might indicate that the aphasic who did not
recover was in exactly the same (relevant) state - say, electri-
cal activity of the brain or evidence from autopsy. The
conclusion that the second aphasic retained his knowledge of
English would have to be based on evidence, of course, but
not necessarily evidence from behavior. To deny that the
aphasic who did not recover had knowledge of his language
would seem as odd a move as to deny that the one who did
recover knew his language when he was unable to use this
knowledge.
Both of these aphasics remained in a certain cognitive state
throughout. "Knowing English" seems to me the appropriate
term for designating this state. Were we to identify capacity
and knowledge, we would presumably be led to saying that
the aphasic does not know English when the capacity is
lacking, and we would hence be committed to the belief that
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Chomsky: Rules and representations
full knowledge of English can arise in a mind totally lacking
this knowledge without any relevant experience whatsoever,
as the case of recovery shows. This is plainly not true of the
child's mind and seems an exotic claim. I do not want to argue
terminology, but I will use the term "knows English " with
reference to the person with the appropriate mental structure,
quite apart from his capacity to use the internally represented
knowledge (even in thought) or even to gain access to it. In
these terms, which do not seem to me to strain normal usage,
two individuals might share exactly the same knowledge (e.g.,
of English, of music, of calculus, of geography, etc.) but differ
greatly in their capacity to use it, which also seems a
commonplace; and a person might increase his capacities
while gaining no new knowledge. In the same usage, behavior
is no criterion for knowledge, though it provides evidence for
possession of knowledge, along with much else, in principle.
Similar remarks apply in the case of "knowing how," which
also involves a crucial intellectual component, often ignored.
Consider now a different case: a child learning English.
Suppose that the child is at the stage in which he produces
so-called "telegraphic speech ' â that is, a series of content
words without grammatical elements. Imagine the following
(not entirely hypothetical) sequence of events. At one point
the child produces only telegraphic speech. Shortly after, he
makes correct use of grammatical particles such as "do " and,
let us say, the whole auxiliary system of English, and does so
across the board - that is, in questions, assertions, negations,
and so on. At the earlier stage, the child did not have the
capacity to use such items (so his behavior indicates). Did he
have the knowledge of the appropriate rules and forms? In
the framework that I am suggesting, the answer might be that
he did. That is, it might be that he had fully internalized the
requisite mental structure but for some reason lacked the
capacity to use it; perhaps because he spoke through a filter
that passed only content words, perhaps because of limits on
memory. There is evidence in other domains that changes in
memory or attention can lead to what appears to be change in
the stage of cognitive development (Bryant 1974). I am
assuming this to be a question of fact, for which we might
find varied sorts of evidence. One kind of evidence that the
child did have the knowledge, though without any capacity to
use it, would be that the whole system appeared, full-blown,
in all constructions. This could be explained on the assump-
tion that the knowledge was already internalized, though not
exhibited, because of a filtering effect: a conclusion that
might be supported, for example, if we found evidence for
the lifting of the memory restriction in other domains. Or,
experiment might show that at the earlier stage, the child
understood normal speech better than speech with noncon-
tent words randomly interspersed - a finding that would
again provide evidence that he possessed the knowledge. Or,
in principle, more exotic means might be devised: say, study
of electrical activity of the brain. We cannot enumerate the
kinds of evidence that might bear on the truth of the
hypothesis that the child had the knowledge, any more than
we can in the case of investigation of some other complex
system, the internal elements and working of which we are
trying to determine. But I see no reason to deny that there is a
fact of the matter, however difficult it may be to establish, or
that behavior is only one kind of evidence - sometimes not
the best, and surely no criterion for knowledge.
Suppose that, in contrast to the above sketch, our tests
indicated that the child did not have knowledge of the full
system of relevant rules when he was in the stage of
telegraphic speech. We might then propose a very different
account of his state of knowledge at the time. Here is one
possibility, again not entirely fanciful. Suppose that what we
call "knowing a language" is not a unitary phenomenon, but
must be resolved into several interacting but distinct compo-
nents. One involves the "computational" aspects of
language - that is, the rules that form syntactic constructions
or phonological or semantic patterns of varied sorts, and that
provide the rich expressive power of human language. A
second component involves the system of object-reference
and also such relations as "agent," "goal," "instrument," and
the like - what are sometimes called "thematic relations" or
(misleadingly) "case relations." For want of a better term, let
us call the latter a "conceptual system." We might discover
that the computational aspect of language and the conceptual
system are quite differently represented in the mind and
brain, and perhaps that the latter should not, strictly speaking,
be assigned to the language faculty at all, but rather should be
considered as part of some other faculty that provides "com-
mon-sense understanding" of the world in which we live.
Involved in this system might be what Moravcsik (1975,
1977), in a series of very interesting papers, has called the
"aitiational" structure of our concepts - that is, their analysis,
more or less along Aristotelian lines, in terms of such "genera-
tive factors" as origin, function, material constitution, and the
like - notions that have reentered recent discussion in the
misleading framework of "essences of things" and "identity
across possible worlds" (See Chomsky 1975a, pp. 46f.)
Supposing all of this, let us distinguish a system of "computa-
tional" rules and representations that constitute the language
faculty, strictly speaking, and a system of conceptual struc-
ture organized along the lines just indicated. The two systems
interact. Thus certain expressions of the linguistic system are
linked to elements of the conceptual system, and perhaps
rules of the linguistic system refer to thematic relations. But it
nevertheless might be correct, in a fuller theory of the mind,
to distinguish these systems much as we distinguish the visual
and circulatory system, though of course they interact. The
conceptual system, for example, might have a central role in
all sorts of mental acts and processes in which language plays
no significant part; it might have a different physical basis
and different evolutionary history, and so on.
Tentatively assuming such a framework as this, let us
return to the child in the telegraphic speech stage. Suppose
that his conceptual system in the sense of the preceding
remarks has partly matured, but his linguistic system has not,
apart perhaps from peripheral components that provide
sounds and words. The transition from the telegraphic stage
to the later stage might be behaviorally identical to the first
case we considered, but markedly different in actual charac-
ter. In the first case a peripheral change, say in memory, led
to the capacity to use an already represented system of
knowledge; in the second ease the system of knowledge
changed from one state to a different state. Again, the two
distinct processes could in principle be distinguished by
evidence of various sorts, but the child's behavior occupies no
privileged place and may in fact tell us little or nothing.
Pursuing the matter further, consider again the child in the
second example, with a partially-developed conceptual
system and a minimally-functioning language system - which
we might think of on the analogy of incipient fluttering
motions of a bird before the system of flight has matured. The
child might be able to make sense of much of the adult speech
around him, as we can often make out what is said in a
foreign language when we can identify some of the words,
impose a thematic and aitiational structure, and use contex-
tual cues, even without much knowledge of the grammar.
Actually, normal comprehension under noisy conditions in
our own language is in some ways a similar task. But the
child's success would not lie in his possession of knowledge of
the language that he hears, apart from peripheral aspects.
To evaluate a picture such as this, we might, again, turn to
evidence of various sorts. For example, there might be clinical
evidence. It seems that patients whose left hemispheres have
been surgically removed in infancy do not, as had been
thought previously, develop fully normal language. They
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Chomsky: Rules and representations
show surprising abnormalities in handling very simple struc-
tures that involve a degree of computational facility such as
simple passive sentences; general understanding in normal
life, however, is so good that these abnormalities may go
unnoticed (Dennis and Whitaker 1976; Dennis 1978).
Conceivably, further research may show that while the
conceptual system is intact, certain elements of the language
system are not, and that language use, while superficially
normal, involves rather different mechanisms.
Or, to mention another possible example, consider a recent
study of a child, deprived of language experience until age
13, who showed a degree of apparent language development
in subsequent years under therapy and training, with a fair
degree of comprehension attained (Curtiss 1977). There is
some reason to believe that her knowledge of language does
not involve the normal computational system of language [see
Arbib and Caplan: "Neurolinguistics Must be Computation-
al" BBS 2(3) 1979] but may rather involve the use of a
conceptual system of the type just outlined - a system quite
distinct from language (though it interacts with it) and
perhaps in a sense more "primitive." One might speculate
that higher apes, which apparently lack the capacity to
develop even the rudiments of the computational structure of
human language, may nevertheless command parts of the
conceptual structure just discussed and thus be capable of
elementary forms of symbolic function or symbolic commu-
nication (see Savage-Rumbaugh et al. 1978; and "Cognition
and Consciousness in Nonhuman Species" BBS 1(4) 1978;
Limber 1977; Terrace, forthcoming; Chomsky, forthcoming)
while entirely lacking the human language faculty. Possible
support for such a view derives from work indicating that
humans with severe language deficit - perhaps literal
destruction of the language faculty - can acquire systems
similar to those that have been taught to apes (see Velletri-
Glass et al. 1973; Gardner et al. 1976; Davis and Gardner
1976), as if, to put it very loosely, apes were in this regard like
humans without the language faculty.
These speculations are directed to two points. First, the
approach to the study of mind and language that I have been
outlining leaves open a variety of avenues of inquiry into the
nature and organization of mental structures and the ways in
which they develop. While evidence is meager and research is
barely beginning, there is enough promise, I think, to suggest
that the approach is well worth pursuing, quite apart from
what has been achieved within the narrower frame of linguis-
tic inquiry. Second, we should not exclude the possibility that
what we normally think of as knowledge of language might
consist of quite disparate cognitive systems that interweave in
normal cognitive development. The system of conceptual
structures that involves object-reference with all of its subtle-
ties and complexities, thematic structures, aitiational factors,
and the like, might be distinct from the language faculty,
though related to it. The latter possibility relates in obvious
ways to recent debate in the philosophical literature about the
theory of meaning and belief systems - in part an outgrowth
of Quine's important and influential critique of empiricist
semantics, and in part influenced by Wittgenstein's insights
into use of language against the background of belief, intent,
and so on, among other sources.
How these issues will be resolved, we can only guess. My
own guess is that something along the lines I have just
described may be correct. Let us tentatively assume so and
continue to inquire into the unitary or modular character of
the faculty of language itself. It makes sense, I think, to
analyze the mental state of knowing a language into further
components - in particular, to distinguish what is sometimes
called "grammatical competence" from "pragmatic compe-
tence." The term "competence" entered the technical litera-
ture in an effort to avoid entanglement with the slew of
problems relating to "knowledge," but it is misleading in that
it suggests "ability" - an association that I would like to sever,
for reasons just discussed. By "grammatical competence" I
mean the cognitive state that encompasses all those aspects of
form and meaning and their relation, including underlying
structures that enter into that relation, which are properly
assigned to the specific subsystem of the human mind that
relates representations of form and meaning. A bit mislead-
ingly, perhaps, I will continue to call this subsystem "the
language faculty." Pragmatic competence underlies the abil-
ity to use such knowledge along with the conceptual system to
achieve certain ends or purposes. It might be that pragmatic
competence is characterized by a certain system of constitu-
tive rules represented in the mind, as has been suggested in a
number of studies.
Again, there are empirical assumptions embedded in the
conceptual distinction. For example, I assume that it is
possible in principle for a person to have full grammatical
competence and no pragmatic competence, hence no ability
to use a language appropriately, though its syntax and seman-
tics are intact. To adopt an analogy of Kasher's (1977), this
would be something like the case of a policeman who knows
the syntax of traffic signals (red and green lights and their
sequence, etc.) and their semantics (red means stop, etc.) but
lacks the knowledge of how to use them to direct traffic.
There have, in fact, been some clinical descriptions of
language disability that might reflect such a situation in part
at least (e.g. Blank et al. 1978). The assumptions involved are
by no means innocent. They bear directly on questions about
the "essence of language" that have figured significantly in
contemporary philosophy (see Chomsky 1975a, Chapter 2).
Keeping to grammatical competence, what is to be
included under aspects of form and meaning properly
assigned to the language faculty? If one rejects the modular
approach outlined earlier, the question is meaningless, or
rather, the decision is arbitrary, since there is no language
faculty and the mental state of knowing a language is some
artibrarily-selected subpart of one's total mental state. By
"arbitrary" I do not mean "selected on no basis at all," but
rather selected on no basis having to do with the structure of
the mind. But if one believes the modular approach to have
merit, as I do, the question is a reasonable one. It is on a par
with the question: What is the human visual system, or the
heart, or the circulatory system? Such systems are not physi-
cally isolable. As in the case of a "mental organ," which I am
taking to be an integrated system of rules and principles,
generating representations of various sorts, the question is one
of appropriate idealization at a certain level of theoretical
discussion - a question with empirical content no doubt, but
one that can be fully resolved only in the context of broader
study of a system that incorporates the given idealized
"organ" as a part. It seems to me that no problem of principle
arises in the case of the language faculty that does not arise in
the case of the visual system or some other system convention-
ally isolated for special study. We abstract away from connec-
tions that obviously exist, hoping to be able ultimately to
reconstruct a full picture of the structure and functioning of
the total system - recognizing, at the same time, that even the
"total system," in this case the individual organism, is itself an
idealization reflecting a particular way of looking at things
and processes in the world, which does not come ontologically
prepackaged as a set of individuals with properties (essential
or other) apart from our mode of conception.
In the case of the language faculty, there is a fair consensus
on some of the elements that should be incorporated within it,
along with considerable dispute about others - in particular,
those on what might be called "the periphery," to use a
metaphor that I hope will not be too misleading. It is
conventional, at least since Aristotle, to think of language as
form with a meaning. If so, among the representations
provided by the system of grammatical competence - hence-
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Chomsky: Rules and representations
forth, the grammar - will be representations of form and
representations of meaning. These representations are "pe-
ripheral" in the sense that they may be regarded as the point
of contact between the language faculty and other systems of
the mind - again not a necessary assumption, but a reasonable
one I think. We may think of these representations as the ones
that enter directly into the use of language. What are the
elements of these representations? What is their character?
On the modular assumptions outlined, these are obscure
empirical questions, to be clarified and answered by empiri-
cal inquiry.
To what extent, for example, does the organization of
sound properly belong to the system of language rather than
to other systems? Here there are real and significant empiri-
cal questions concerning perceptual categorization and its
possible special relation to language (Mehler and Bertoncini
1979). Studying the interaction between the perceptual
system and the system of language, with particular attention
to possible specialization for language, we can hope to refine
our understanding of the representation of form provided by
grammar, and thus of the rules that enter into determining
this representation.
Still more debated, perhaps more intractable problems
arise in considering representations of meaning. Do the "se-
mantic rules" of natural language that are alleged to give the
meanings of words belong to the language faculty strictly
speaking, or should they be regarded perhaps as centrally-
embedded parts of a conceptual or belief system, or do they
subdivide in some way? Much of the debate about these
matters has been inconclusive. It turns on dubious intuitions
as to whether we would still call our pets "cats" if we learned
that they are robots controlled by Martians, or whether we
would call the stuff in the Ganges "water" were we to
discover that it differs in chemical composition from what
flows in the Mississippi [see Fodor, this volume]. It is harder, I
think, to make up a story compatible with the assumption that
I persuaded you to leave but at no point did you intend to
leave; quite generally, arguments for analytic connections of
some sort involving properties of the verbal system, with its
network of thematic relations, are more compelling than
those devised for common nouns. Even assuming there to be
certain analytic connections, as I believe to be the case, the
question remains whether these are to be assigned to the
language faculty, hence to appear in some form in its repre-
sentations of meaning, or to a conceptual system of a sort
perhaps organized along the lines already discussed. Similar-
ly, suppose that our notion of a "thing" involves considera-
tions of spatio-temporal contiguity as well as human action, as
discussed in references noted earlier (Chomsky 1975a, pp. 44
f.; 203). If so, have we isolated a "semantic universal" or a
fact about our conceptual systems? Similar questions arise in
connection with more complex semantic properties - for
example, certain possible universals relating to abstract and
concrete interpretation of common nouns (Chomsky 1976;
Jackendoff, forthcoming).
Or consider another question that has been much debated.
Certain discourses are appropriate in a sense in which others
are not. For example, if I say "It was Dickens who wrote
"Moby Dick," - italics indicate heavy stress - you can appro-
priately respond: "No, it was Melville, but not: "No, it was
David Copper field." If you were to give the latter response, I
would understand you to be asserting that David Copperfield
wrote "Moby Dick." The point can be expressed in terms of
focus and presupposition, in one of the senses of these terms,
and relates to the position of main stress. Is this a matter of
semantics or pragmatics? Is it to receive expression in terms of
the representations provided by the grammar or not?
Or, to take a last case, suppose that we agree that some sort
of representation of quantificational structure is to be given
by the grammar at the level of representation of meaning.
Does the notation matter? Should the representation involve
quantifiers or variables, or should it be in a variable-free
notation, or is the question without empirical import?
There are innumerable questions of this sort. How we
proceed to deal with them depends on the point of view we
adopt towards what we are doing. Suppose, for example, that
someone rejects the approach outlined here or is just not
interested in it and is pursuing some other aim - let us say, to
codify logical inference using natural language sentences (e.g.
Katz 1972). Then all properties entering into such inference,
and only these, will appear in his "representations of mean-
ing." For example, suppose it can be shown that pragmatic
rather than logical presupposition is involved in the case of "It
is Dickens who wrote Moby Dick." Then the relevant proper-
ties of this sentence will not be encoded in "representations of
meaning" for the study of logical entailment, no matter what
the character of the rules that govern the phenomenon may
be. Suppose it turns out that presupposition, in the sense
required to account for these cases, is governed by rules that
fall within grammar in a narrow sense - perhaps rules that
enter into determining representations involved in logical
inference in other cases. Then the person who is concerned to
map out the properties of the language faculty will include
these properties in his "representations of meaning," what-
ever the status of the presupposition. There has been much
empty discussion of these questions - though perhaps deeper
issues are masked in it (for example, questions of psychologi-
cal realism and modularity).
If one adopts the point of view that I have been discussing
here, then it is clear how to proceed to answer these questions,
at least in principle. We will try to construct coherent and
integrated systems with explanatory power and see where the
examples fall. If the idealization to the language faculty and
its subcomponents is legitimate - that is, if it corresponds to
some significant aspect of reality - we may be able to find an
answer to these questions. My impression is that at the
moment we often cannot; the available evidence is inade-
quate and the theories not sound enough to bear the weight.
In some cases I think there are possibilities for an answer. For
example, in the matter of stress and presupposition there is
reason to believe that the rules fall within grammatical
competence, so that the properties appear in the representa-
tions of meaning it provides. Were it to be shown that these
matters do not bear on logical inference but only, say, on
conversational implicature, we would then conclude that
representations of meaning generated by the rules of gram-
mar provide materials for conversational implicature, not that
they must exclude these elements. And if some attribute of a
sentence that enters into logical inference turns out not to be
provided by the best theory of grammar that we can devise,
we will conclude that this is not an element of the representa-
tions of meaning provided by grammatical competence.
Proceeding in this way, we will try to identify just what it is
that we have loosely been calling "representations of mean-
ing," much in the way that we will try to determine the
properties of linguistic representations of sound. The fact that
the conclusions may not conform to some a priori scheme or
satisfy some specific need such as codifying inference is,
plainly, irrelevant to this empirical inquiry. I am assuming, in
short, that we are trying to answer a difficult empirical
question, only partially clear, which can become more precise
only in the course of finding some answers to it: namely, what
are the real components of mental states?
Taking a grammar to be a system of rules that provides
representations of sound and meaning (among others), their
specific character to be determined as research progresses,
our task is to discover the representations that appear and the
rules operating on them and relating them; and more impor-
tant, to discover the system of universal grammar that
provides the basis on which they develop. One may think of
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Chomsky: Rules and representations
the genotype as a function that maps a course of experience
into the phenotype. In these terms, universal grammar is an
element of the genotype that maps a course of experience into
a particular grammar that constitutes the system of mature
knowledge of a language - a relatively steady state achieved
at a certain point in normal life.
Thinking about the question we now face in rather general
and qualitative terms, we can make a fair guess as to what we
should discover, if this inquiry succeeds. An investigation of
the final states attained - that is, the grammars - reveals that
the knowledge acquired and to a large extent shared involves
judgments of extraordinary delicacy and detail. The argu-
ment from poverty of the stimulus leaves us no reasonable
alternative but to suppose that these properties are somehow
determined in universal grammar, as part of the genotype.
There is simply no evidence available to the language learner
to fix them, in many crucial cases that have been studied.
Nevertheless, people obviously speak different languages
depending on their limited individual experience.
As translators are well aware, there need be no point-
by-point comparison between languages, and linguistic work
reveals considerable variety. Given these properties of
language, what we should expect to discover is a system of
universal grammar with highly restrictive principles that
narrowly constrain the category of attainable grammars, but
with parameters that remain open to be fixed by experience.
If the system of universal grammar is sufficiently rich, then
limited evidence will suffice for (he development of rich and
complex systems in the mind, and a small change in parame-
ters may lead to what appears to be a radical change in the
resulting system. What we should be seeking, then, is a system
of unifying principles that is fairly rich in deductive struc-
ture, but with parameters to be fixed by experience.
Kndowed with this system and exposed to limited experience,
the mind develops a grammar that consists of a rich and
highly articulated system of rules, not grounded in experience
in the sense of inductive justification, but only in that experi-
ence has fixed the parameters of a complex schematism with
a number of options. The resulting systems, then, may vastly
transcend experience in their specific properties but yet be
radically different from one another, at least on superficial
examination; and they may not be comparable point-by-point
in general.
Keeping to the rather vague level of these qualitative
remarks (which I try to make a bit more precise elsewhere;
see Chomsky 1980, Chapter 4), the problem of accounting for
the growth of different languages, each of which lacks an
inductive grounding in experience, is not unlike the general
problem of growth or, for that matter, speciation. It appears
that the biochemistry of life is rather similar across all living
organisms and that, as Francois Jacob (1978) puts it:
". . . it was not biochemical innovation that caused
diversification of organisms. . . . What accounts for the
difference between a butterfly and a lion, a chicken and a
fly, or a worm and a whale is not their chemical
components, but varying distributions of these
components . . . specialization and diversification called
only for different utilization of the same structural
information. ... It is thanks to complex regulatory circuits,
which either unleash or restrain the various biochemical
activities of the organism, that the genetic program is
implemented. [In related organisms, mammals for
example], the diversification and specialization . . . are the
result of mutations which altered the organism's regulatory
circuits more than its chemical structures. The minor
modification of redistributing the structures in time and
space is enough to profoundly change the shape,
performance, and behavior of the final product." (see also
Jacob 1977)
The logic is rather similar to what I have outlined in the case
of acquisition of knowledge of language. In a system that is
sufficiently intricate in structure, small changes in particular
points can lead to substantial differences in outcome. In the
case of growth of organs, mental organs in our case, small
changes in parameters left open in the general schematism
can lead to what appear to be very different systems.
I think we may now be at the stage where, for the first time
really, we can propose systems of universal grammar that at
least have the right properties. I have no doubt that they are
incorrect, at least in detail, perhaps in general conception. But
they do have the right properties, and that seems to me of
some importance. That is, the systems that are now being
investigated by a number of linguists do have a deductive
structure that permits a range of empirical phenomena to be
derived from some simple and, I think, rather natural princi-
ples, and they also have the property that small changes in the
parameters in some of the general principles lead to quite
different languages. These are the kinds of systems we hope
to find, whether or not the systems of universal grammar
currently being investigated will prove to be on the right
track.
I have been speaking of "knowing English" as a mental
state (or a stable component of mental states), or a property of
a person in a certain mental state, but we may want to
analyze this property in relational terms. What is it that is
known? Ordinary usage would say: a language - and I have so
far been keeping to this usage, speaking of knowing and
learning a language - e.g. English. But it is implicit in what I
have said that this way of talking can be misleading. I think it
has been, and I would now like to explain why. To avoid
terminological confusion, let me introduce a technical term
devised for the purpose - namely "cognize" - with the
following properties. The particular things we know we also
cognize. In the case of English, we know that "The candidates
wanted each other to win" means that each wanted the other
to win, and that "The candidates wanted me to vote for each
other" is not well-formed, with the meaning that each wanted
me to vote for the other. We therefore cognize these facts.
Furthermore, we cognize the system of mentally-represented
rules from which the facts follow. That is, we cognize the
grammar that constitutes the current state of our language
faculty and the rules of this system as well as the principles
that govern their operation. And finally, we cognize the
innate schematism, along with its rules, principles, and condi-
tions.
In fact, I don't think that "cognize" is very far from
"know," where the latter term is moderately clear, but this
seems to me a relatively minor issue, similar to the question
whether the terms "force" and "mass" in physics depart from
their conventional sense. If the person who cognized the
grammar and its rules could miraculously become conscious
of them, we would not hesitate to say that he knows the
grammar and its rules, and that this conscious knowledge is
what constitutes his knowledge of his language. Thus "cogniz-
ing" is tacit or implicit knowledge, a concept that seems to me
unobjectionable. Putting aside the question of "innate knowl-
edge" (see Chomsky 1980, Chapter 3), we note that cognizing
has the structure and character of knowledge but may be, and
in the interesting cases is, inaccessible to consciousness.
Concluding this terminological digression, I will return to the
terms "know" and "knowledge," but I will now use them in
the sense of "cognize" - that is, admit both conscious and
tacit knowledge - and hope that possible confusion will have
been allayed. The fundamental cognitive relation is knowing
a grammar: knowing the language determined by it is deriva-
tive. Correspondingly, it raises additional problems (see
Chomsky 1980, Chapter 3).
I see no reasonable alternative to the position that gram-
mars are internally represented in the mind, and that the
basic reason why knowledge of language comes to be shared
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Chomsky: Rules and representations
in a suitably idealized population (and partially shared in
actual populations) is that its members share a rich initial
state, hence develop similar steady states of knowledge. There
are, obviously, many reasons for skepticism about specific
proposals that are put forth in the effort to characterize these
grammars and the universal grammar from which they
allegedly develop, and about the various idealizations that
enter into them. In the next section I want to consider some
further questions about knowledge of grammar.
3. Knowledge of grammar
In the preceding sections I have been discussing elements of a
theory of human knowledge that is concerned with such
traditional questions as "What is human knowledge?", "How
does it arise in the individual?", "In what respects is it
shared?". Comparable questions arise concerning other
cognitive systems - for example, systems of individual and
shared belief. The discussion has been "mentalistic," but, I
think, in an innocuous sense. It takes no stand on issues of
materialism (in fact, I have expressed some skepticism about
the content of these issues, given that "body" is an open and
evolving concept), but rather it proceeds as an inquiry at a
certain level of abstraction into the nature of certain mecha-
nisms, presumably neural mechanisms, now largely un-
known. The level of abstraction is appropriate insofar as it
enables fundamental properties of these systems to be
isolated, analyzed, and explained; and insofar as results
obtained at this level provide a guide for the study of
mechanisms, much as study of chemical properties provides a
guide for inquiry into atomic theory or a theory of feature
detectors in the auditory system might lay a basis for research
into the neurophysiology of hearing. I am tentatively assum-
ing the mind, to be modular in structure - a system of inter-
acting subsystems that have their own special properties.
What little is known supports this view. The only reasonable
research strategy, so far as I can see, is to study particular
systems and their interaction. If the modular approach is
incorrect, such study will reveal, contrary to what I expect,
that these systems involve the same principles and develop in
the same way from a common basis. I have been attempting
to isolate for special study one of these systems: the faculty of
human language. I have suggested that what we loosely call
"knowledge of language" involves, in the first place, knowl-
edge of grammar - indeed, that language is a derivative and
perhaps not very interesting concept - and beyond that, other
cognitive systems that interact with grammar: conceptual
systems with their specific properties and organizing princi-
ples may be quite different-in character from the "computa-
tional" language faculty; pragmatic competence might be a
distinct cognitive system with a different structure from that
of grammatical competence; these systems may be further
composed of distinct though interacting components. If so, we
should not expect a unitary answer to the question "What is
knowledge of human language and how does it arise?"
Rather, we will find that the question was wrongly put; it
does not identify a natural kind. If this turns out to be correct,
it should occasion no surprise. There is little reason to suppose
that ordinary common-sense notions will prove any more
appropriate for the theory of knowledge than they are for the
study of the physical world (or I should say, other aspects of
the physical world).
I am assuming grammatical competence to be a system of
rules that generate and relate certain mental representations,
including, in particular, representations of form and mean-
ing, the exact character of which is to be discovered, though a
fair amount is known about them. These rules, furthermore,
operate in accordance with certain general principles. I have
informally discussed rules of grammar that, for example,
move a question-word to the front of a sentence or associate
an antecedent with an anaphoric expression such as "each
other." Such rules can be formulated quite precisely within
an explicit theory of rules and representations (along lines
discussed elsewhere). I offered a few linguistic examples to
illustrate certain principles that govern the application of
these rules. I will simply give names to these principles;
further characterization appears elsewhere (Chomsky 1980,
Chapter 4): the movement rule is governed by a principle of
"locality" - elements of mental representation can't be
moved "too far" - and the choice of antecedent is governed
by a principle of "opacity" - variable-like elements can't be
free in certain opaque domains, in a sense specific to the
language faculty.
Certain factors that govern or enter into the adult system of
rules, representations, and principles belong to universal
grammar; that is, they are somehow represented in the
genotype, along with the instructions that determine that we
will grow arms instead of wings, or have a mammalian eye
instead of an insect eye. Among the elements of the genotype,
I am tentatively assuming, are the principles of locality and
opacity, the option of moving question-words and relating a
variable-like expression such as each other (an anaphor) to an
antecedent and, in general, certain basic properties of the
mental representations and the rule systems that generate and
relate them. These will become empirical hypotheses, once
they are stated in more explicit form.
One basic element in what is loosely called "knowledge of a
language," then, is knowledge of grammar, now analyzed in
terms of a certain structure of rules, principles, and represen-
tations in the mind. This grammar generates paired represen-
tations of sound and meaning, along with much else. It thus
provides at least partial knowledge of sound-meaning rela-
tions. A fuller account of knowledge of language will consider
the interactions of grammar and other systems - specifically,
the system of conceptual structures and pragmatic compe-
tence - and perhaps others (for example, systems of knowl-
edge and belief that enter into what we might call "common
sense understanding" of the world). These systems and their
interactions also arise from a primitive basis - part of an
innate endowment that defines "the human essence."
Keeping to knowledge of grammar, I have also been
speaking of knowledge of the rules and principles of gram-
mar, and also knowledge of the innate elements that enter
into this mature knowledge. It is, I feel, a relatively uninter-
esting question whether "knowledge" in the sense of this
discussion is the same concept as that expressed by the English
word "knowledge." If one disagrees, he can replace "know"
wherever I am using it by the technical term "cognize,"
which has just the properties I am assigning to it. In fact, it is
not at all clear that the ordinary concept of "knowledge" is
even coherent, nor would it be particularly important if it
were shown not to be.
Against an approach to the study of knowledge of the sort
that I have been describing, it is commonly argued that it
would not permit us to distinguish properly between, say,
knowing a language and knowing how to ride a bicycle [see
Premack: "Does the Chimpanzee Have a Theory of Mind"
BBS 1(4) 1978]. Thus, in the latter case, too, one might say
that the bicycle rider "cognizes" both "the rules of riding he
can articulate - push with the feet on the pedals - and those
that he cannot, even though his practice is in accord with
them - e.g. lean into a curve. But nothing much of interest
may turn out to have been attributed when we attribute to
him the [cognizing] of a rule of riding." (Donnellan 1977, p.
720) I have discussed similar objections elsewhere, explaining
why I think they are misguided (Chomsky 1975a, pp. 222-3;
1972, p. 87) Let's consider Donnellan's specific case. True,
there would be little point to a concept of "cognizing" that
did not distinguish "cognizing the rules of grammar" from
10
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Chomsky: Rules and representations
the bicycle rider's knowing that he should push the pedals or
lean into a curve, given what we assume to be the facts of the
matter. But it seems easy enough to make the relevant
distinction. In the case of riding a bicycle, there is no reason to
suppose that the rules in question are represented in a
cognitive structure of anything like the sort I have described.
Rather, we take bicycle riding to be a skill, whereas knowl-
edge of language and its concomitants - for example,
knowledge that reciprocal expressions have the properties I
mentioned - is not a skill at all. The skill in question might,
perhaps, be based on certain reflex systems, in which case it
would be incorrect to attribute a cognitive structure in the
sense of this discussion to the person who exercises the skill. In
contrast to the case of language, nothing seems to be
explained by attributing to the bicycle rider a cognitive
structure incorporating the rules with which his practice
accords. But suppose we are wrong, and in fact the bicycle
rider does have a representation of certain physical principles
in his mind and uses them to plan or compute his next act. In
this case we should attribute to him a cognitive structure, and
in fact, it would be quite appropriate to say that he cognizes
these principles as he does the rules of his language. The
question, 1 take it, is basically one of fact.
To help clarify the issue, consider two missile systems, each
of which is designed to send a rocket to the moon. One of
them operates along lines once proposed by B. F. Skinner; it
has several pigeons looking at a screen that depicts what lies
directly ahead, trained to peck when the rocket veers off
course, their pecking restoring the image of the moon to a
focused position on the screen. Consider, in contrast, a system
that incorporates an explicit theory of the motions of the
heavenly bodies and information about its initial position and
velocity and that carries out measurements and computations
using its internalized theory to adjust its course as it proceeds.
This rocket might hit the very same spot as the servomecha-
nism with the pigeons, but it would do so in a very different
way. Mere investigation of behavior might tell us little,
perhaps nothing. A deeper look might be required to distin-
guish the two systems. In the second case, but not the first,
inquiry might lead us to attribute to the missile something
like a "mental state " [see Griffin: "Prospects for a Cognitive
â¢Ethology" BBS 1(4) 1978]. That is, it might lead us to
formulate an abstract characterization of perhaps unknown
mechanisms, postulating a system that involves the cognizing
of certain principles and representations. In the first case,
such an account would be factually wrong. I think that the
two cases fall on opposite sides of an important divide, and
that the second - the cognizing missile - shares properties
with human knowledge. It also lacks crucial properties; for
example, it is a task-oriented device, whereas knowledge of
language, for example, is not.
No doubt one can construct other cases that are not so
readily distinguished. This would be a valuable exercise,
which might contribute to an understanding of just what
distinguishes knowledge (cognizing), in the sense of this
discussion, from skill and ability. But the many examples of
the sort just mentioned that appear in the literature do not
seem to me very helpful in this regard because they are too
easily handled. Nor do they suggest any problem in the course
I have been pursuing, so far as I can see.
A recurrent theme throughout this discussion has been the
question whether it is legitimate to adopt the standard "real-
ist" assumptions of the natural sciences in studying
language - and cognition more generally. I have been assum-
ing that the questions I have been raising are (rather obscure)
questions of fact. Thus, it is a question of fact whether
knowledge of grammar is represented in the mind along the
lines I have been suggesting, or in other ways, or not at all; or
whether such knowledge arises from some sort of learning or
differential response to stimuli or in some other way, perhaps
through the unfolding of a fairly detailed genetic program
under the triggering and partially shaping effect of experi-
ence; or whether my knowledge that the typewriter before
me will not suddenly fly away is grounded in experience with
similar objects or derives in significant part from a conceptual
system that has its roots in human biological endowment and
is only modified and sharpened in certain ways by experi-
ence - clearly a very different picture, which is susceptible to
considerable further refinement. I am taking these to be
empirical questions, so that we cannot specify in advance
what categories of evidence may be relevant to advancing our
understanding of them or settling them. Is it correct to regard
these questions as empirical?
In the natural sciences, when a theory is devised in some
idealized domain, we ask whether the theory is true and try to
answer the question in various ways. Of course, we expect
that the theory is probably false, and even if on the road to
truth, that it does no more than describe at some appropriate
level of abstraction properties alleged to be true of whatever
the real elements of the world may be when considered at this
level of description; it has, in short, some of the properties of
so-called "functionalist" theories in psychology. There is a
familiar morass of problems about just what is meant when
we take a theory to be true: What is the status of its theoretical
entities, its principles, its idealizations? How have the facts
been recast through the medium of the experimental situation
or our perceptual and cognitive faculties? I am not now
concerned with these questions but rather with some special
and additional ones that are held to arise, beyond these, when
we turn to psychology.
Presumably these problems arise somewhere on the bound-
ary between physiology and psychology. Consider again the
study of vision. Suppose that some series of experiments leads
to the conclusion that particular cells are sensitive to lines
with certain orientations. In this case no special problems are
held to arise, though of course the conclusion is underdeter-
mined by evidence, the cell is abstracted from its environ-
ment, nothing is said (at this level) about the mechanisms that
might be responsible for what the cell is alleged to be doing,
the results are obtained under highly idealized conditions
built into the experimental situation and apparatus, and so on.
Suppose next that it is proposed that identification of objects
involves analysis into stick-figures or geometrical structures,
though nothing is said or known about neural mechanisms
that might carry out such analysis. Is the situation fundamen-
tally different in some way, apart from the fact that the
theory abstracts still further from the physical and chemical
properties of the brain? It is not clear why one should assume
so. That is, in this case there seems no reason to refrain from
taking the theory to be true, then seeking evidence to verify,
disconfirm, or sharpen it, proceeding to search for mecha-
nisms with the properties postulated, and so on.
Let us turn now to the problem that seems to many people
to be more disturbing. Consider the elements postulated to
account for the facts used for illustration earlier: the rule of
movement, the principles of opacity and locality, the repre-
sentations postulated, and so on. Suppose that all of this can be
made as precise as one pleases and that the system meets some
very high level of success in explaining such facts as those
mentioned over a substantial range. Suppose further that by
assuming elements of this system to be innate we can go on to
explain how it is that children presented with some informa-
tion - say, that "each other" is a reciprocal expression rather
than the name of a tree - reach the conclusions they do about
such facts as those mentioned. Are we permitted to regard the
theories of particular and universal grammar so constructed
as true, respectively, of the steady state attained in language
acquisition and of the initial state common to the species, so
that we then proceed to test, refine, and extend them, search
for mechanisms with the properties they codify, and so on? It
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
11

Chomsky: Rules and representations
is this step that gives rise to various qualms and objections. It
is commonly felt to be unwarranted, requiring different sorts
of evidence, or even to be without sense (as advocates of
"indeterminacy" would maintain). The question is, what
boundary have we crossed that requires us to abandon normal
scientific practice, with all of its familiar pitfalls and obscuri-
ties?
What is commonly said is that theories of grammar or
universal grammar, whatever their merits, have not been
shown to have a mysterious property called "psychological
reality," What is this property? Presumably, it is to be
understood on the model of "physical reality." But in the
natural sciences one is not accustomed to ask whether the best
theory we can devise in some idealized domain has the
property of "physical reality," apart from the context of
metaphysics and epistemology, which I have here put aside,
since I am interested in some new and special problem that is
held to arise in the domain of psychology. The question is:
what is "psychological reality," as distinct from "truth, in a
certain domain"?
As has been evident throughout, I am not convinced that
there is any such distinction. I see no reason not to take our
theories tentatively to be true at the level of description at
which we are working, then proceeding to refine and evalu-
ate them and to relate them to other levels of description,
hoping ultimately to find neural and biochemical systems
with the properties expressed in these theories. Perhaps we
can gain some insight into the question, if there is one, by
asking how it arose.
The first discussion of "psychological reality" that I know
of in this connection was in the classic paper of Edward
Sapir's (1933) on "the psychological reality of the phoneme."
We can reconstruct Sapir's argument â unfairly to him,
though in accord with subsequent interpretation - as
proceeding in essentials as follows. Considering first what is
often called "linguistic evidence," Sapir arrived at a phono-
logical analysis for a certain language: an abstract system of
rules and underlying representations that offered a plausible
account of the linguistic data. The phonological analysis was
not empirically vacuous over the domain of "linguistic
evidence." It had some predictive power in the language for
which it was offered (e.g., with regard to previously unana-
lyzed forms) and also had indirect empirical content in that
the principles on which it was based could be tested for
validity in other languages, or in study of language change,
and so on. In our terms, his principles of phonological analysis
can be regarded as elements of universal grammar, and one
should then ask whether they yield, in each language, the best
account of phonetic organization for this language, with the
proper predictive consequences, the most far-reaching gener-
alizations, and so forth. So far, what Sapir was doing was
standard linguistics, though unusually well-conceived.
But he then proceeded to raise a new question: do the
phonemes he postulated have "psychological reality"? To
answer this question he turned to other kinds of data (what is
sometimes called "psychological evidence") - that is, percep-
tual tests of various kinds that we need not go into here. The
outcome of these tests convinced him that his theoretical
constructions had "psychological reality. "
Sapir was sharply criticized in subsequent years (e.g. by
Twaddell 1935) for venturing to claim that his constructions
had "psychological reality" instead of putting them forth
merely as fictions convenient for some purpose. But another
question arises: Why didn't the "linguistic evidence" suffice
to establish "psychological reality?" Perhaps the answer is
that it was too weak; after all, phonology is a finite system
with limited predictive content. But that does not seem to be
the right answer. In fact, in this case the "linguistic evidence"
may well be more persuasive than Sapir's "psychological
evidence." Furthermore, it is clear from the ensuing debate
up to the present that no matter how powerful the "linguistic
evidence" might have been, it would not have sufficed to
establish "psychological reality." Some new category of
evidence is required, and this, however weak and inconclu-
sive, could support a claim to "psychological reality."
In short, the evidence available in principle falls into two
epistemological categories: some is labeled "evidence for
psychological reality," and some merely counts as evidence
for a good theory. Surely this position makes absolutely no
sense, but it remains implicit in discussion of the matter by
psychologists and linguists to the present (see, for example,
Chomsky 1980, Chapter 5). I suspect that something of the
sort also may lie behind the wariness about inner mechanisms
or "the psychological form in which competence exists"
expressed by many philosophers concerned with language
and mind - for example, those discussed in Chomsky 1980,
Chapters 2 and 3.
What we should say, in all these cases, is that any theory of
language, grammar, or whatever, carries a truth claim if it is
serious - though the supporting argument is, and must be,
inconclusive. We will always search for more evidence and
for deeper understanding of given evidence, which also may
lead to change of theory. What the best evidence is depends
on the state of the field. The best evidence may be provided
by as yet unexplained facts drawn from the language being
studied, or from similar facts about other languages, or from
psycholinguistic experiment, or from clinical studies of
language disability, or from neurology, or from innumerable
other sources. We should always be on the lookout for new
kinds of evidence, and we cannot know in advance what they
will be. But there is no distinction of epistemological catego-
ry. In each case we have evidence - good or bad, convincing
or not â as to the truth of the theories we are constructing; or,
if one prefers, as to their "psychological reality," though this
term is best abandoned, as seriously misleading.
There are two final points on which I would like to
comment briefly in connection with the notion "knowledge
of grammar." The first has to do with consciousness, the
second with learning.
As I am using the term, knowledge may be unconscious and
not accessible to consciousness. It may be "implicit" or
"tacit." No amount of introspection could tell us that we
know, or cognize, or use certain rules or principles of gram-
mar, or that use of language involves mental representations
formed by these rules and principles. We have no privileged
access to such rules and representations.
I have already indicated why I think it is reasonable to
suppose that the rules of grammar are mentally represented
and used in thought and behavior, much as in the case of the
"cognizing missile" discussed earlier (but also with crucial
differences). Furthermore, this approach to knowledge and
understanding has not simply been proposed as a possibility,
but explored in some detail with, I think, a considerable
measure of success. To the best of my knowledge it is unique
in this respect. I know of no other account that even attempts
to deal with the fact that our judgments and behavior accord
with and are in part explained by certain rule systems (or to
be more accurate, are explained in part by theories that
attribute mental representations of rule systems). Unless some
principled objection to this approach can be discovered, to
reject it out of hand in the absence of any coherent alternative
is simply a variety of dogmatism, deserving of no comment.
The critic's task is to show some fundamental flaw in princi-
ple or defect in execution, or to provide a different and
preferable account of how it is that what speakers do is in
accordance with certain rules, or is described by these rules -
an account that does not attribute to them mental representa-
tion of a system of rules (rules which in fact appear to be
beyond the level of consciousness). If someone can offer such
an account of how it is that we know what we do know, say,
12
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Chomsky: Rules and representations
about reciprocals, or judge as we do judge, and so on, there
will be something to discuss. Since no such account has been
forthcoming, even in the most primitive or rudimentary
form, there really is nothing to discuss.
The issue is not simply whether we should use the word
"knowledge" in connection with knowing rules. The issue is
whether this is a permissible approach to developing a theory
that will account for parts of what everyone agrees to be
knowledge, or, if one wants to drop the term, that will
account for what is taken to be in the domain of knowledge,
thought, language, action, and behavior.
Searle (1976) remarks correctly that speakers of English do
not recognize the rules of grammar as being those they follow,
and also that the rules proposed are "abstract and compli-
cated" and "are a long way from having the intuitive plausi-
bility that ordinary grammar-book rules have." Let us
consider the merit of these objections - they are offered as
objections - to an approach of the sort I have been outlining.
Since the rules are not recognized by speakers as being
those they follow, and in fact appear to be inaccessible to
consciousness or introspections, Searle concludes that "for the
most part the rules remain mere hypotheses." With the
conclusion I of course agree, apart from the words "mere"
and "for the most part." What he should have said, simply, is
that "the rules are hypotheses," or that theories attributing
mental representations of these rules offer hypotheses. That is
to say, the theories in question have empirical content, not a
criticism, in my book at least. The words "mere" and "for the
most part" suggest that Searle has seriously misunderstood the
work on which he is commenting, apparently taking it to be
an attempt at some sort of conceptual analysis.
There is a further problem. Note that Searle argues that
"for the most part the rules remain mere hypotheses" on the
grounds that speakers do not recognize them as being rules
they follow. As already noted, this is no argument at all. But
suppose that someone were able to construct an alternative
theory involving rules accessible to consciousness that had
something like the coverage or explanatory force of theories
involving inaccessible rules. That would certainly be an
interesting result, though it obviously would not move us
beyond the domain of "mere hypotheses" - that is, beyond
the domain of statements with empirical content. A person's
judgments about what he does have no uniquely privileged
status; they simply constitute evidence to be set alongside
other evidence. But again, the question is academic. So far as
I know, explanatory principles with any merit bearing on the
domain of facts of the sort that I have been considering are, in
general, inaccessible to consciousness, and there is no reason
to expect otherwise. The doctrine of accessibility in any of its
traditional or contemporary forms seems to me entirely
without antecedent plausibility, and without empirical
support.
As for the fact that the rules do not have the intuitive
plausibility of those of ordinary grammar books, that is true
and surely to be expected, for reasons that have been
discussed many times. Ordinary grammar books are
concerned with a domain of facts that is virtually comple-
mentary to what is most significant for the project I have been
discussing. That is, ordinary grammar books, quite properly
for their purposes, tacitly assume a principled grammar
(generally without awareness) and deal with idiosyncracies,
with the kinds of things that could not be known without
experience or instruction. For example, no grammar book
devised, say, for teaching English, would, or should, deal with
the simple properties of questions or of reciprocals that I have
mentioned. Rather, it should deal with basic facts of word
order and inflection, or with the fact that "each other" is a
reciprocal in contemporary English as distinct from
languages that do not formally distinguish reflexive and
reciprocal, and so on. Such comments on the language no
doubt have great intuitive plausibility, but there is surely no
reason to expect that this will remain true when we consider
such principles as locality or opacity in an attempt to explain
facts many of which any ordinary grammar book simply
disregards, as it should, insofar as these facts and the princi-
ples that underlie them can be assumed to be available to the
person using the grammar, once the idiosyncracies are
presented.
To conclude these remarks, I would like to turn briefly to
the notion of "learning." I have been suggesting that knowl-
edge of grammar, hence of language, develops in the child
through the interplay of genetically determined principles
and a course of experience. Informally, we speak of this
process as "language learning." It makes sense to ask whether
we misdescribe the process when we call it "learning." The
question merits some thought, I believe. Without attempting
to inquire into too many subtleties or to settle the question, I
would like to suggest that in certain fundamental respects we
do not really learn language; rather, grammar grows in the
mind.
When the heart, or the visual system, or other organs of the
body develop to their mature form, we speak of growth rather
than of learning. Are there fundamental properties distin-
guishing the development of physical organs and of language
that should lead us to distinguish growth, in the one case,
from learning, in the other? Perhaps, but it is not obvious. In
both cases, it seems, the final structure attained, and its
integration into a complex system of organs, is largely prede-
termined by our genetic program, which provides a highly
restrictive schematism that is Deshed-out and articulated
through interaction with the environment (embryological or
postnatal). There are certain processes that one thinks of in
connection with learning: association, induction, condition-
ing, hypothesis-formation and confirmation, abstraction and
generalization, and so on. It is not clear that these processes
play a significant role in the acquisition of language. There-
fore, if learning is characterized in terms of its distinctive
processes, it may well be that language is not learned.
Can we distinguish learning from growth in terms of the
nature of the state attained - say, a system of belief or
knowledge, with facts or principles stored in the memory
accessible to mental computation in the case of learning, or
something of this sort? If we do, then it is not clear that any
coherent notion of "learning" will remain. It is entirely
possible that significant components of such cognitive states
are "wired-in," taking their explicit shape in the mind in
perhaps something like the way that the distribution of
horizontal and vertical receptors in the visual cortex is fixed
within certain bounds by the character of presented visual
experience. Knowledge of behavior of objects in visual space
or of principles and rules of language, and much else, arises in
ways that do not seem crucially different from other forms of
growth or selection from a set of highly restricted alternatives,
so far as we know.
Dennett (1975) has suggested that we think of "learning" as
what he calls "self-design." In some cases of transition from
state to state, the new design "exists ready made in the old
design, in the sense that its implementation at this time is
already guaranteed by its old design" (presumably, given
some triggering event). In other cases "the old design does not
determine in this way what the new design will be"; rather,
the design process generates alternatives that are tested
"against a whole array of requirements and constraints"
(Dennett 1975, citing Herbert Simon). If the "whole array of
requirements and constraints" is taken to be confirmation by
evidence, "simplicity" in some sense relevant to choice
among theories, and the like, then self-design (that is, learn-
ing) seems pretty much like what Peirce called "abduction" -
a process in which the mind forms hypotheses according to
some rule and selects among them with reference to evidence
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
13

Chomsky: Rules and representations
and, presumably, other factors. It is convenient sometimes to
think of language acquisition in these terms, as if a mind
equipped with universal grammar generates alternative
grammars that are tested against the data of experience, with
the most highly-valued one selected; I have occasionally used
this metaphor, but I don't think that it should be taken too
seriously. If we take it partially seriously, then under this
concept of learning as "abduction" or "self-design," the
question whether language is learned or grows will depend on
whether the mind equipped with universal grammar presents
a set of grammars as hypotheses to be selected on the basis of
data and an evaluation metric, or whether the steady-state
grammar arises in another way - for example, by virtue of a
hierarchy of accessibility (stated, perhaps, in terms of the very
same evaluation metric) and a process of selection of the most
accessible grammar compatible with given data. The distinc-
tion between such alternatives lies so far beyond conceivable
research that the question whether knowledge is the result of
learning or growth is hardly worth considering, if learning is
characterized in these terms. It is rather doubtful, in fact, that
there is much in the natural world that falls under "learning,"
so conceived, if the metaphors are taken seriously.
There is an interesting discussion of related questions by
the immunologist Jerne (1967). He distinguishes between
instructive and selective theories in biology, where an instruc-
tive theory holds that a signal from the outside imparts its
character to the system that receives it, and a selective theory
holds that change of the system takes place when some
already-present character is identified and amplified by the
intruding stimulus. He argues that "Looking back into the
history of biology, it appears that wherever a phenomenon
resembles learning, an instructive theory was first proposed to
account for the underlying mechanisms. In every case this
was later replaced by a selective theory." The primary
example that he deals with is the development of antibodies
by the immune system. This was first assumed to be a kind of
learning process in which the antigen played an instructive
role, the reason being that the number of antigens was so
immense, including even artificially synthesized substances
that had never existed in the world, that no other account
seemed conceivable. But this theory has been abandoned. An
animal "cannot be stimulated to make specific antibodies,
unless it has already made antibodies of this specificity before
the antigen arrives," so that antibody formation is a selective
process in which the antigen plays a selective and amplifying
role.
As another example, Jerne cites the familiar Darwinian
account of a factory well covered with brown moths, later
found to be covered with white moths after it is painted
white. Darwinian theory offers a selective account based on
the fact that the moths of lighter color were already present
before the new signal arrived. "In this case, the signal that
entered into the system, that is, the color change, was not even
received by the moths, but by the birds" that fed on them.
After reviewing a number of such examples, Jerne turns to
some speculations on the central nervous system. He notes
certain analogies to the immune system. Both systems develop
through experience, with change of state induced by outside
elements. Both appear to be learning in response to these
external events, and the changes are not transmitted to the
offspring. He suggests that learning from experience may be
"based on a diversity in certain parts of the DNA, or to
plasticity of its translation into protein, which then controls
the effective synaptic network underlying the learning
process." If such speculations are valid, "It thus remains to be
asked if learning by the central nervous system might not also
be a selective process; i.e., perhaps learning is not learning
either." The air of paradox in this last remark can be
dissipated if we think of the term "learning" as a rigid
designator, perhaps commonly misapplied; or, to take a
standard example, as analogous to such terms as "witch,"
commonly applied at one time but always misapplied.
Jerne suggests, finally, a distinction between learning and
selection in terms of level of analysis, a distinction that would
explain why accounts in terms of learning come to be
replaced by accounts in terms of selection as inquiry
proceeds. Keeping to the interaction of the whole system and
an external signal, we see what appears to be an "instructive
process"; the system changes and the change is caused by the
stimulus. Thus in the case of the moths, one might say that the
signal of painting the wall white " 'instructed' the population
of moths to mimic the color change," even though the moths
never received the signal. But processes that are "instructive"
at the system level, in this sense, "imply selective mecha-
nisms, through which products that were already present in
the system prior to the arrival of the signal are selected and
amplified." So when we analyze an "instructive" process, we
find that learning is not learning either.
I don't think that the notion of selection from preexisting
materials is rich enough to provide an analysis for the
large-scale interactions that are loosely called "learning," but
it may be a step along the way. It is possible that the notion
"learning" may go the way of the rising and setting of the
sun.
Outside of cognitive capacities that are part of our intrinsic
nature, modification and fixing of belief may proceed by
trial-and-error, conditioning, abstraction, induction, and the
like; that is, in domains in which the mind is equipped with
no special structure to deal with properties of the task
situation (See Chomsky 1975a, Chapters 1 and 4; 1980,
Chapter 6). Learning theory will then reduce to the study of
tasks and problems for which we have no special design,
which are at the borders of cognitive capacities or beyond,
and are thus guaranteed to tell us very little about the nature
of the organism. This is not, of course, to demean the content
of what is learned. What is significant for human life is not
necessarily significant for the person inquiring into human
nature. In the case of "language learning," mechanisms of
association (etc.) may be involved in the acquisition of idio-
syncracies (e.g., specific inflectional patterns and choice of
vocabulary items), though even here it is highly likely that
powerful intrinsic constraints guide the course of develop-
ment. For example, the rate of vocabulary acquisition is so
high at certain stages of life, and the precision and delicacy of
the concepts acquired so remarkable, that it seems necessary
to conclude that in some manner the conceptual system with
which lexical items are connected is already substantially in
place.
From the point of view of the study of human nature, the
most interesting aspects of learning (as distinct from growth
of knowledge and belief) may well turn out to be those to
which Dennett's remarks direct our attention: essentially,
Peircean abduction. In some domains - acquisition of
language, object perception, and so on - the growth of our
knowledge just happens to us, in effect. The mental faculty
grows from its initial to its steady state without choice, though
not necessarily without effort or willed action [see Gyr et al.:
"Motor-Sensory Feedback and Geometry of Visual Space"
BBS 2(1) 1979]. In other domains - the natural sciences, for
example - the growth of knowledge involves deliberate
inquiry involving hypothesis formation and confirmation,
guided no doubt by "abductive" constraints on potential
hypotheses as well as other equally obscure factors that enter
into choice of idealization and the like. The basic elements of
rational inquiry may have some of the properties of such
cognitive systems as the language faculty, though the ways in
which they are employed are surely quite different: scientific
knowledge does not grow in the mind of someone placed in
an appropriate environment. The study of human knowledge
should, it seems, consider a number of rather different types
14
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

of systems: the growth of "natural" faculties such as those that
provide common-sense understanding of the physical and
social world or language (Moravcsik 1979); learning by asso-
ciation, conditioning, induction, and the like on the periphery
of fixed cognitive capacities; deliberate inquiry employing
"abductive" constraints on intelligible hypotheses and other
elements of so-called "scientific method." In each of these
domains, elements of our knowledge appear to be innate, and
still other elements, ungrounded, in any reasonable sense of
the term.
If we hope to assimilate the study of human intelligence
and its products to the natural sciences insofar as possible and
to learn something about human nature in this way, we would
do well, I think, to devote particular attention to those
domains in which rich and complex mental structures arise
under minimal exposure to the environment, language being
a striking example, though for reasons discussed elsewhere
(Chomsky 1980) no more "typical" than others.
As I have tried to show here and elsewhere (Chomsky 1980)
it makes sense to think of other cognitive systems on the
model of the human language faculty, despite the fact that
knowledge of language is not a "central case" of knowledge
and, on the assumption of modularity, cannot be expected to
involve principles that enter into other cognitive systems. My
own feeling is that a theory of mind should proceed by
tentatively identifying such cognitive systems and submitting
them to detailed study to determine their specific properties.
Some such systems may be like language in that they are
properly conceived in terms of grammar-like theories of rules
and representations. It may turn out that, in the domains
where we speak of "knowledge of X" (knowledge of
language, of music, of mathematics, of the behavior of
objects, of social structure, of human characteristics, etc.),
with the consequences of such knowledge in the form of
expectations or knowing that such-and-such, there is a
mentally-represented system of this nature that can be taken
to be an object of knowledge, just as there is good reason, I
believe, to think of what we know as a grammar when we
speak loosely of "knowing a language." These cognitive
systems serve as vehicles for the exercise of our various
capacities and thus enter into our thought and action, as when
we come to understand what is said to us, or what is
happening around us, or what some other person is doing -
say, reading a book or pursuing a goal (see also Chomsky
1969; and Premack and Woodruff 1978a, b). To identify
these cognitive systems and to discover their properties and
modes of interaction, we must be willing to entertain fairly
far-reaching idealization and to attribute internal structure,
sometimes in the form of rules and representations, to the
human mind, including substantial innate structure, which
might take various forms: principles, rules, systems of repre-
sentation, schemata, modes of functioning and integration,
and so on. We must, in short, be willing to approach the study
of mind much in the manner of the natural sciences.
In the book from which this paper is abstracted I have been
trying to make two basic points. First, a variety of objections
of principle that have been raised to such an approach are not
well-founded, while alternative approaches to similar prob-
lems that seek to avoid attribution of internal mental struc-
tures as vehicles for the exercise of cognitive capacities are
fundamentally flawed. And second, in some domains of
human knowledge it is possible to obtain nontrivial results by
studying the rules and representations of cognitive systems. A
framework of the sort I have been discussing seems to me
natural and appropriate for the study of such products of the
human mind as human language, or the study of the use of
language. I would like to end by speculating that if the
so-called "cognitive sciences" do develop in a serious and
fruitful way, it will be within a framework of essentially this
character.
Commentary /Chomsky: Rules and representations
Open Peer Commentary
Commentaries submitted by the qualified professional readership of
this journal will be considered for publication in a later issue as
Continuing Commentary on this article.
by J6zsef Andor
Medical University of Pecs, Foreign Language Department, Pecs, Hungary
Some remarks on the notion of competence
In my view, Chomsky's analysis of the mental state of knowing a
language in terms of different components (i.e., a "grammatical" and a
"pragmatic" component) is a bit too rigid and unnatural. I think it
inadvisable to accept the view according to which one can have full
grammatical competence without a functioning pragmatic compe-
tence. My guess is that much of what was considered to belong to the
domain of performance in terms of Chomsky's Standard Theory (or the
later Extended Standard Theory) has now been incorporated into the
"pragmatic competence" notion outlined here. I do not see, however,
whether such a division of competence has any empirical support or
psychological validity (a topic Chomsky seems to address for the first
time since the development of generative models of natural
languages). In Chomsky's view, "grammatical competence" pertains
to aspects of form and meaning â that is, the rules of syntactic and
semantic structures. He has nothing to say, however, about the precise
nature of the mental organization of these domains.
In my view, the above domains cannot be represented in a single
component, since their mental organization is not uniform. Moreover, it
is incorrect to separate them rigidly from pragmatic factors in the way
that Chomsky does in his target article. I assume that "linguistic
competence" refers to a set of cognitive domains or macrocompon-
ents in the mind that are of heterogeneous nature. These mental
macrocomponents are composed of cognitively-based chains of
knowledge structures developed on the basis of our empirical knowl-
edge of the world.
I assume that the constructs and categories of recent "frame
semantics" and "cognitive semantics" models play a critical role in the
description of our linguistic competence. In the cognizing process we
store knowledge in terms of sets of scenes and frames (van Dijk 1977;
Fillmore 1975; Minsky 1977), and the activation of such knowledge
involves bringing certain frames to the fore by putting them into
perspective (Fillmore 1977). I accordingly take it that our competence
is mainly of a semantic nature, but that the semantic chains stored are
closely related to empirical experience and knowledge and are thus
strongly influenced by sociological, cultural, as well as psychological
factors - the former two are greatly overlooked by Chomsky in the
present paper.
The way we make assertions about our environment by linguistic
means, and our evaluation of our own experiences and the experi-
ences and assertions of others, depend greatly on the limitations of our
knowledge structures, the level of our factual knowledge, our cognitive
capacity, and our sociocultural background. Hence, we do not express
(or need to express) everything in our memory during the communica-
tive interaction (e.g., in conversation), since we possess a set of
mentally-conditioned filters that help us decide what to bring into
perspective in given situations under certain conditions, and what to
leave verbally unexpressed. The same set of cognitive filters acts upon
our judgment of the coherence relations of textual units.
Of course, it would require further research to investigate to what
extent such filters are influenced by our knowledge of the complex
system of syntactic operations of a given language, or by our naive
conception of that system, or whether the filters themselves are
dependent on semantic or pragmatic factors (only). What is crucial
here is that we certainly possess such a set of stored filters, as their
operation can be traced and analysed in an account of the success or
failure of surfacing procedures and criteria in the individual evaluation
and judgment of the acceptability of verbalised grammatical strings.
(Preliminary data on such research can be found in Andor 1978;
Kintsch 1977; Kintsch and van Dijk 1978; Schlesinger 1977; Schlesin-
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
15

Commentary / Chomsky: Rules and representations
ger 1979.) Everyone has his own cognitive filters, since the develop-
ment of knowledge structures based on scenes and frames is highly
individual in nature, depending upon age and the above-mentioned
factors.
Thus, I would rather propose that Chomsky's pragmatic compe-
tence be integrated with semantic component of competence; and I
would definitely separate the latter from the (cognitively based?) level
of the ability to master syntactic rules, both mentally and at the surface.
I do not think that our knowledge of grammar can be described in the
sense Chomsky assumes. It is true that our knowledge of rules has a
great influence on the way we think (hence it is often the case that we
think in terms of sets of rules without ever "surfacing" our ideas
verbally), but still, I consider our semantic and pragmatic knowledge
(and intuitions) to have a more critical role in comprehension than
syntactic factors. This is the point where the relevance of semantic and
pragmatic factors as well as evidence from syntax should be tested
psychologically, and their role in a systematic approach to a typologi-
cal analysis of context (a still imprecisely defined domain) requires
further research.
by Richard F. Cromer
MRC Developmental Psychology Unit. London WCIH OAN, England
Empirical evidence in support of non-empiricist
theories of mind
It is incumbent on those who make a case for an unpopular position
within a particular theoretical climate to present more convincing
arguments and a greater amount of evidence than would be required
merely to challenge relatively minor problems in current theory. Other-
wise, there is the danger that the unpopular position will be ignored or
dismissed for reasons not entirely relevant to the real issues involved.
The theoretical orientation for which Chomsky argues in his target
article is of some interest, and psychologists' growing awareness of
the role of "growth" as opposed to exclusive interest in learning is
important, but Chomsky does himself a disservice by stating too much
of his case in the form of assertions frequently not backed up with
supporting evidence and therefore open to criticism.
It should be stated at the outset that there is a good deal of empirical
evidence to support Chomsky's claims, but he fails to cite it. Indeed,
some recent data from early child language studies (and from studies
of cognitive growth in general) that have been overlooked reveal
precisely the kind of evidence that should give most psychologists
pause when they are tempted to reject theories of growth and innate
mechanisms outright. Thus, rather than to criticize the form of the
particular assertions that Chomsky makes, it would seem of interest to
call attention to some of the evidence that could be seen as supporting
his overall position.
Perhaps the best illustration of how some of Chomsky's arguments
have the unfortunate effect of weakening his claims occurs with what
he calls "the argument from the poverty of the stimulus." This
argument is used to make strong claims for the richness of internal
structure. However, there are various possible interpretations of "pov-
erty of the stimulus." It would appear that what Chomsky means by the
poverty of the stimulus is that many aspects of the rule system that the
child eventually "possesses" (or that describes adult language knowl-
edge) simply do not appear in the input data, however well-formed,
short, simple, and "grammatical."
Most psychologists and psycholinguists have taken "poverty of the
stimulus" in a rather different sense, based on claims that Chomsky
had made earlier (Chomsky 1967) about the input stimulus being
composed mainly of pauses, hesitations, and false starts. They argue
that data from mother-child interaction studies demonstrate that the
input to the child is not a degenerate stimulus of this type. It is made up
of short, well-formed structures and constitutes an ideal stimulus for
inducing grammatical regularities (see, e.g., various contributions to
Snow and Ferguson 1977). They conclude that since Chomsky's
arguments for innateness are primarily based on the poverty of the
input stimulus (in this sense of ill-formed utterances), his position has
accordingly been falsified. This conclusion, however, ignores important
aspects of the child's productions. These include some of the findings
from the early work in the 1960's, which formed part of the basic
argument against simple associationistic theories of language acquisi-
tion.
To state the earlier work in the form relevant to the present
argument: the child may well be receiving clear input stimuli consisting
of grammatically well-formed sentences, but what he produces
diverges drastically and systematically from that input. His utterances
are not merely "telegraphic," as was first thought. Rather, his produc-
tions evidence rules of formation that differ from the rules descriptive of
the input stimulus. The child hears clear and well-formed negatives, but
his production of negatives can be described in terms of a series of
stages (Bellugi 1967) the earliest of which is the placement of a
negative morpheme like "no" or "not" in front of affirmative utter-
ances, thus producing "no wipe finger," "not fit," and the like - forms
not present in the short, clear, reduced input. In spite of being exposed
to well-formed questions, the child forms his interrogatives, for exam-
ple, without auxiliary inversion. In spite of exposure to clear examples
of pronominal self-reference, the child again moves through a series of
stages (e.g., "Why me spilled it?", "What me doing?") in which his
utterances do not match the adult model (Bellugi 1971).
Child language data are replete with structures evidencing the
child's own productive system. These production data are important
evidence, first, that children are not matching the adult model, no
matter how clear the input; and second, that children are not deriving
the same rules that adults use in their knowledge of language particu-
lars. Thus, even on this interpretation of "poverty of the stimulus,"
recent mother-child interaction studies, in spite of contributing a great
deal of important information concerning communication and language
in the broader sense, have revealed little concerning how the child
acquires the structural properties of grammar. Production data from
children serve as important evidence that language acquisition is a
more mysterious process than most learning theories, or even modern
"cognitive" theories lead one to believe.
It is, of course possible to argue from the production data that
children form a series of inductions or generate hypotheses against
which to test language input data. Chomsky merely asserts that
hypothesis-formation and confirmation would not explain the
language-acquisition process. He does so primarily on philosophical
and logical grounds (but we also know from such arguments that
Achilles cannot outrun the tortoise). Since Chomsky's claim concerns
the methods by which children come to possess the linguistic rules
used to describe adult utterances, it is useful to seek evidence from
language-acquisition studies on this point. When this is done, it
becomes apparent that nothing in the language-acquisition data so far
is at variance with Chomsky's emphasis on innate, unfolding factors in
language acquisition. Since many psycholinguists appear to believe
that studies have shown precisely the opposite, it is instructive to see
why this is so.
Under Chomsky's influence from linguistics and Piaget's contribu-
tions from genetic epistemology, research on child development and
language acquisition has moved away from viewing the child as a
passive organism dependent on the input stimuli for all development.
Instead, the child has come increasingly to be seen as an active
organism interacting with environmental variables. This change coin-
cided with Bruner's earlier seminal work (Bruner, Goodnow, and Austin
1956) on the use adults make of "strategies" in concept-attainment
tasks. Child language research took up the idea and began to focus on
the strategies children use during the language-acquisition process.
For example, in an influential paper, Bever (1970) noted various
perceptual strategies that are used for interpreting sentences. One of
these, used by four-year-old children, consists of interpreting NP,-
V-NP2 strings so that NP, is the actor, leading to incorrect interpretation
of reversible passive sentences. Some children have been found to use
this strategy across a variety of structures (Dewart 1975), and it is
more correctly characterized as "treat the first animate NP as the
actor."
A number of other strategies have now been examined. These
include a "probable event strategy" (Strohner and Nelson 1974), in
which two- and three-year-old children will often incorrectly interpret
16
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Commentary / Chomsky: Rules and representations
improbable active sentences (e.g., showing the horse jumping over a
tence when in fact the given sentence is "The fence jumps the horse");
a related "congruency strategy" (Wilcox and Palermo 1975), in which
the child places the toy items in the most usual relations, thus
misinterpreting incongruent sentences like "Put the boat on the
bridge"; strategies of carrying out the easiest motor response in
sentence comprehension tasks (Dewart 1975; Huttenlocher et al 1968;
Huttenlocher and Strauss 1968; Wilcox and Palermo 1975); strategies
in which children base sentence interpretation on avoiding noun
phrases serving a "double function" (Bever 1970) or "non-parallel
function" (Sheldon 1974) or requiring "rule change" (Maratsos 1973);
strategies in which the order of mention is taken to reflect the actual
order of events in time (Clark 1971; 1973a; Cromer 1968; Ferreiro
1971; Ferreiro and Sinclair 1971); and a variety of strategies based on
"localized" circumstances, such as where certain items should be
placed in relation to horizontal surfaces and containers (Clark 1973b),
and other extralinguistic considerations (Donaldson and Balfour 1968;
Donaldson and McGarrigle 1974).
In a comprehensive review of the work on developmental language
strategies (Cromer 1976b), however, it was argued that in most
instances the concept of "strategy" has not been very instructive
concerning how the child acquires the structures of language. This can
be most succinctly illustrated by noting some results from Dewart's
series of experimental studies on children's comprehension strategies
(Dewart 1975). In her experiments, Dewart attempted to influence
children's interpretations in various ways. For example, noting that
children were influenced by situational context, she manipulated the
context of passive sentences by preceding them with short verbal
phrases that made the particular passive either appropriate or inappro-
priate. In an experiment examining motor strategies, she placed a toy
in the child's hand and found that some children performed the
sentence-comprehension task on the basis of moving the "mobile" toy
and treating it as the "actor" regardless of its noun-phrase position in
passive sentences. What is of especial interest in these experiments is
that all children were initially tested on their knowledge of passive
sentence structure in a "no context" condition. The children who
evidenced adult knowledge of passive-voice sentences were not
influenced by inappropriate linguistic contexts preceding the utter-
ances or by having the incorrect toy in their hand when the sentence in
the comprehension task was uttered. The children who evidenced
contextual strategies or a mobile-toy strategy were those who did not
yet know how to perform the passive in the adult manner, as gauged
by their performance in the no-context condition.
The same point is illustrated in Strohner and Nelson's findings
(1974) on the strategies children use at various ages. In their experi-
mental task, the two-year-old children used the probable-event strat-
egy mentioned earlier. By age four, however, they used word-order
strategies. And by age five, most children interpreted sentences
correctly even when they violated probable events. These children
would show the fence jumping over the horse, since that is what the
adult interpretation of the syntactic structure called for, and they did so
in spite of knowing much more about real world event probabilities than
the two-year-old children. The strategies used by younger children,
then, are ways of behaving when forced by psycholinguists to perform
on comprehension tasks when they do not yet comprehend particular
language structures. They in no way lead the child to an understanding
of those structures. Indeed, they lead the child to give a systematic set
of wrong responses; they in no way explain the acquisition process.
The strategies that have been investigated are not hypotheses about
specific language structures that the child is trying out.
Furthermore, child language production studies do not give
evidence of hypothesis-testing and confirmation. It would be difficult to
know what would count as confirmation for the child in any case.
Studies of production have repeatedly shown that children use some
structures that are not being used by the adult models around them
and that are therefore "disconfirmed," sometimes for years, before
the child moves on to other rule systems.
The general notion of reinforcement or feedback in development is
likewise challenged by empirical evidence. When Chomsky postulates
a more prominent place for "growth" in various natural faculties (as
opposed to learning by association, conditioning, and induction), he is
putting forward a position that is uncogenial in the current intellectual
climate. But the unpopularity of a position is no argument against its
empirical validity. A single example from an area of cognitive growth
other than language may be used to illustrate some of the problems
that exist for the more usual notions of hypothesis-testing, confirma-
tion, and feedback. Many experiments have been carried out in the last
decade on the acquisition of Piagetian concepts such as conservation.
Many of these experiments employ instructional techniques in an
attempt to show the possibility of accelerating development. A
common assumption is that what can be accomplished in the experi-
mental laboratory, by fairly direct methods of reinforcement or feed-
back, is accomplished more slowly in real life situations in which the
feedback is more incidental and not so direct. According to this view,
for example, the child becomes a "conserver" on operational tasks
because of his experience of the invariance of quantities in everyday,
real life transformations.
Years ago, however, Smedslund (1961) carried out an ingenious
experiment. He induced weight-conservation answers in nonconserv-
ing children with an experimental technique involving the transformation
of plasticine and the use of balances on which the transformed pieces
could be tested. Later, however, he surreptitiously took away some of
the plasticine during its transformation into other shapes. The trained
conservers immediately reverted to their original answers when the
scales no longer balanced. They were not bothered and simply gave
nonconservation answers as they had originally done. By contrast,
many natural, untrained conservers in true Piagetian style resisted
these attempts at "extinguishing" answers based on their operative
cognitive structure; they argued that some of the plasticine must have
been stolen or had been lost on the floor.
These results are usually cited in the context of arguing against
experimental induction of true operational concepts. But they reveal
something else that is equally significant. Not only were naturally
conserving children resistant to direct feedback, but the nonconserving
children in this experiment were given direct evidence on nonconserva-
tion. Feedback in real life is incidental and unconcentrated, but these
children were given direct, concentrated, first-hand experience that the
weight of objects changes with their transformation! Smedslund does
not report on the later natural conservation development of the
children in the experimental group, but it would be surprising if these
children were found to be significantly retarded in their operational
ability or if later, as young adults, they believed in nonconservation of
weight due to their direct experience of manipulated feedback. It is not
clear how developments in language or in cognitive growth in general
occur, but the assumptions on which most theories of learning by
association, conditioning, induction, and feedback rest have by no
means been shown to describe or explain those developments.
Another approach in child language has been to hypothesize that
language acquisition is explainable in terms of general cognitive growth
(Beilin 1975; Cromer 1968; Macnamara 1972). A straightforward
cognitive theory of language-learning would assert that the acquisition
of particular linguistic structures depends on prior cognitive growth,
allowing the formation of certain concepts by the child. It is assumed
that, as the child develops certain meanings and intentions, he notes
how these are encoded in the speech he hears about him. In this view
the child forms associations between the situational events and the
language he hears. It is said to be a "modern" associationist
viewpoint, since the child is viewed as taking an active part in the
process, as opposed to the view of the passive child of the earlier
behaviourist theories (Donaldson 1978).
The basic problem with cognitive theories such as Donaldson's is
that, once the child has the concepts, there is nothing more to explain
about language acquisition. All the child has to do is to see how the
concepts are encoded in the input language. This input language has
now been shown, by careful mother-child interaction studies, to be
clear and free of hesitations, false starts, and the like. But the problem
with this naive theory is that the productive utterances by normal
children in their natural environment are at variance with its claims.
Empirical research on the utterances children produce while acquiring
language simply does not support associationist claims. (This argu-
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
17

Commentary / Chomsky: Rules and representations
ment is developed more fully elsewhere; Cromer 1974; 1976a; in
press). In addition, there is evidence from studies of adult aphasia,
some of which Chomsky does quote in his target article, showing that
the retention of certain concepts does not necessarily ensure the
retention of linguistic structures in which these concepts are encoded.
Indeed, some aphasic individuals have been trained in a communica-
tion-symbol system in spite of severe linguistic impairment (Glass et al.
1973). Hughes (1972; 1974/75) obtained similar results with children
with cogenital or early acquired aphasia. There is, then, a good deal of
empirical evidence, from both normal, unimpaired children acquiring
language and from aphasic children and adults, that concepts and
their encoding in language are not identical. Cognitive theories that do
not allow for specifically linguistic processes are seriously flawed and
are simply not supported by empirical research.
So far, it has been argued that the main thrust of Chomsky's
arguments â namely that the language faculty and perhaps other
aspects of the human cognitive system should be characterized in
terms of growth rather than learning â is not at variance with what is
known from empirical research. Although he has stated many of his
claims merely as assertions, it has been shown that there is evidence
that can be cited in support of his views. However, the kind of
innateness in which Chomsky appears to believe is not the only
possible one.
There are other ways to view innateness and growth. In comparing
and contrasting the views of Chomsky and Lenneberg, Catlin (1978),
has characterized two basic approaches to innate structures. In one,
the preformationist view attributed to Chomsky, the various innate
properties are in some sense fully formed at the beginning of develop-
ment. Environmental factors play little or no role in the formation of
universal grammar. Thus Chomsky takes universal grammar as a given
property that influences the acquisition of particular languages. By
contrast, Lenneberg's view is characterized by Catlin as "epigenetic";
environmental influences are seen as playing a role in development as
certain innate aspects unfold and interact with the environment.
At present there is no empirical way to judge between these two
ways of viewing possible innate factors in language. Chomsky, by
focusing on universal grammar, appears to undervalue environmental
influences. But those who are interested in child language are
concerned with the acquisition of a particular language. For this task,
whatever may be innate about universal grammar must interact with the
stimulus input. Much of the continuing research in mother-child interac-
tion, strategies, and cognitive theories of language acquisition contin-
ues at some level to emphasize associationistic types of principles,
which are discredited by empirical evidence. Alternative approaches to
the study of child language are possible, however. The cross-cultural
studies of language by Slobin and his associates (Slobin 1978; 1979),
and the experimental studies by Karmiloff-Smith (1977; 1978; 1979),
which detail the interactions between what a child brings to the
language-acquisition task and the particular structures of the language
he is acquiring, represent true advances in the attempt to understand
this still mysterious process. A description of these studies in terms of
an epigenetic-interactionist viewpoint can be found elsewhere (Cro-
mer, in press). Although the question is still open, nothing in the
empirical evidence is at odds with some notion of species-specific
innate factors in language.
by Robert Cummins and Robert M. Harnish
Department of Philosophy, University of Wisconsin, Milwaukee, Wise. 53223;
Department of Philosophy, Department of Linguistics, University of Arizona,
Tucson, Ariz. 85721
The language faculty and the interpretation of
linguistics
Chomsky thinks there is a language faculty (LF) characterizable via a
system of rules and representations, the structure of which is largely
innate or innately determined. With all this we are inclined to agree. But
we have a pair of related concerns about Chomsky's characterization
of the LF: (i) Chomsky assumes that linguistics is about the LF, and this
assumption is undefended and dubious, (ii) Given (i), we need, but do
not have, a proper characterization of what the LF contributes to
"linguistic capacities" broadly conceived.
We are puzzled as to why Chomsky is puzzled when he writes;
"What is 'psychological reality' as distinct from 'truth in a certain
domain'?" and "Why didn't [Sapir's] 'linguistic evidence' suffice to
establish 'psychological reality'?" If linguistics is about the mind, or one
of its faculties - if it is about psychological states - then, of course,
evidence for the truth of the theory is evidence of psychological reality.
But linguistic evidence itself can't tell us whether linguistics is about the
mind, and that's the issue - subject matter - that linguistics is about.
The "psychological reality" dispute boils down to this: should the
theoretical terms playing an essential role in the results of linguistic
analysis and description be interpreted as about mental states, or not?
After all, most practicing linguists were brought up on the following
words:
From now on I will consider a language to be a set (finite or infinite)
of sentences, each finite in length and constructed out of a finite set
of elements . . . The grammar of L will thus be a device that
generates all of the grammatical sequences of L and none of the
ungrammatical ones (Chomsky, 1957, p. 13).
Theories of language constructed to the letter (and in the spirit) of such
remarks need no more be about the mind than a piece of set theory is.
A linguist may decide to characterize a psychological competence or
capacity, or to provide a minimal axiomatization of all available
linguistic properties and relations. The resulting systems need not have
much in common: Why assume they are about the same thing?
Chomsky's puzzlement about the "psychological reality" issue
strongly suggests that he thinks there is no alternative to supposing
that linguistics is psychology.- And it seems clear that he thinks this
because he is a "conceptualist" about language - i.e., because he
thinks there is no such thing as a natural language independent of
speaker's psychological states, hence nothing for a nonpsychologized
linguistics to be about. Talk about language is just disguised talk about
shared psychological states. This may be the right view to take, but it
hasn't been adequately defended.
The view does have consequences, however, for on this view,
whatever truths linguists uncover must be psychological truths: there is
nothing else for them to be. Indeed, they must be truths about the LF. It
seems to us that this approach runs a serious risk of either saddling
linguistics with unmotivated psychological constraints, or imputing to
the LF psychologically unmotivated aspects of linguistic descriptions.
For instance, given that language is a social as well as a biological
phenomenon, it will have a conventional as well as a genetic aspect,
and linguistic descriptions will describe both. It may or may not be true
that promises obligate, but should the fact that this is not biology
matter to a linguist? Also, as we pointed out earlier, the simplest
axiomatization of the linguistic facts need not restrict itself to formal
apparatus that is psychologically motivated. These points will be
obscured (or prejudiced) if the problem of interpreting linguistics is
assimilated to the problem of assessing its empirical support.
This brings us to our second concern about the specification of the
LF. Faculties, of course, are functionally identified, so if we want to
know how Chomsky envisions the LF, we will do well to ask how
Chomsky thinks the LF will figure in an analtyical explanation of the
capacity to use and assess language. (By the capacity to use a natural
language, we mean the capacity to speak and understand it, to
communicate with it - in short, to employ it in speech acts. By the
capacity to assess a natural language we mean the capacity to judge
grammaticality, intersentential relations, and the like.) We are to
imagine the Use and Assessment System (UAS) analyzed into three
components: 1) the LF proper, which provides syntactic and phonolog-
ical analyses and relates these to representations of "meaning"; 2) a
conceptual system, which "involves the system of object reference
and also such relations as 'agent,' 'goal,' 'instrument' . . . ," and
perhaps aitiational analysis of concepts; and 3) the Use system
proper, the characteristic capacity of which is presumably the capacity
to perform and recognize speech acts.
18
THE BEHAVIORAL AND 8RAIN SCIENCES (1980), 3

Commentary / Chomsky: Rules and representations
Chomsky suggests that a system consisting of only components (2)
and (3) might be able to communicate, even be a party to communica-
tive conventions. Let's call the result of deleting the LF from the UAS
the Communication System (CS). Adding some ritzy supporting equip-
ment, we get a system that could refer, predicate, tell the general what
it saw and order the troops to move out. Well, maybe. Anyway,
Chomsky certainly leaves this possibility wide open. We think it is the
capacities we have assigned to the CS that most philosophers and
psychologists have (traditionally) had in mind when they thought about
linguistic capacities. The following research problems appear, on
Chomsky's conception, to be attackable without bothering about the
LF: a) a theory of denotation, truth, and, to some extent, meaning; b) a
theory of speech acts, including referring and predicating; c) a theory
of communication and linguistic conventions; and d) a theory of
understanding.
If the LF isn't implicated in the explanations proferred by these
theories, what is its explanatory role? Chomsky appears to leave this
to future empirical inquiry, supposing, presumably, that the LF can be
sufficiently characterized in terms of its content. Indeed, it is clear
enough what outputs the LF can make available to the UAS. What has
yet to be articulated is an hypothesis concerning how those outputs
enter into the explanation of the capacities of the UAS. (We can see
how it enters into the explanation of language assessment, but that is
surely not the main act.) Lacking such an hypothesis, we don't know
why we should favor Chomsky's analysis of the UAS to some other
analysis. When we have a clear idea what the outputs of the LF are for,
we will have a useful fix on what the LF is. Chomsky is offering a
"modular" approach to mind - i.e., a functional analysis of mental
capacities. But the LF hasn't been functionally identified.
The same point can be seen from a slightly different perspective. On
Gricean accounts (and what else is there?), the CS is up to its ears in
propositional attitudes, cognitions, and subtle reasoning. That is why it
is a methodological battleground. The LF, by contrast, looks comforta-
bly computational: comfortably nonrepresentational, in fact. The only
reason to characterize the outputs of the LF in terms of their represen-
tational contents is that the availability of these representations is
required to explain the capacities of the UAS. This is just where the light
is dimmest: we don't know which representations we need, hence what
to impute to the LF, until we have a fairly clear picture of how the LF is
supposed to interact with the other components of the UAS.
by Daniel C. Dennett
Department of Philosophy, Tufts University, Medford. Mass. 021SS
Passing the buck to biology
I think that Chomsky's claim that universal grammar is inately fixed in
the form of explicit rules is gratuitously strong. That is, although on a
sympathetic interpretation it could turn out to be true, the evidence and
argument so far adduced support only a milder and less specific
version of the thesis: (roughly) there are innately fixed structural
features - design features - that specifically constrain the develop-
ment of linguistic competence in the child. So stated, the thesis is no
news at all; what is news, and not entirely welcome news, is that the
constraints are much stronger than one might have thought. Since I
know from discussions that other commentators - e.g., Searle - will
produce good arguments against Chomsky's strong version, I will take
the opportunity to comment on why even a milder version of his thesis
is in a certain respect unwelcome. (We should always seek Truth, but
what we find may nevertheless be regrettable on occasion.) This is
intended not as an objection to Chomsky, but as reflections on the
context in which his arguments take place.
We can all agree, these days, that extreme tabula rasa theories of
learning or cognitive development are false. Even Skinner acknowl-
edges the necessity of a modicum of genetically transmitted structure
for fixing the effects on the organism of his postulated reinforcers. And
no one flies to the opposite extreme and denies that there is
phenotypic learning (or differential development) in response to differ-
ent environments or perceptual histories. The truth lies somewhere in
the middle, and the disagreements concern the amount, specificity,
and detailed structure of the innate contribution. Perhaps no one
supposes there is a larger innate contribution than Chomsky does, and
perhaps the facts will eventually bear out a position close to his, but his
polemics sometimes ignore the perfectly reasonable motivation behind
the contrary perspective - what we might call the minimalist research
strategy.
Moving more and more structure into the category of innate may
help us to get a more realistic picture of the individual capacity for
cognition and learning, but what is innate must have been "learned" in
evolutionary history, so the task of explaining the genesis of the design
in the organism remains. Views imputing a minimally-prestructured
organization to the infant (that easily succumb to empirical refutation)
may nevertheless be rehabilitated if they are interpreted as rational
reconstructions of the genesis of intelligence. View them, perhaps, on
the model of social contract myths, or Rawls's "original position"
thought experiment, which are attempts to explain the genesis of social
or political structures, rules, or principles at a level of abstraction that
renders them immune from disconfirmation by brute historical fact. Of
course, there is no guarantee that such a high level of abstraction will
yield any reliable or theoretically useful results, but there may be no
practical research alternatives - due to the simple inaccessability to
research of the actual processes one wants to describe.
Let me add one more specimen to this garden of analogies.
Suppose the evidence mounted in support of the hypothesis that life
did not in fact evolve on Earth from the lifeless soup of preorganic
molecules; rather, the Earth was seeded at some early time by living
"spores" (or whatever) from elsewhere in the universe, perched on
some meteor, or intercepted while floating by. There is something
profoundly unappealing about this hypothesis, and it is easy to say
what it is: if it is true, then the fascinating question of how life developed
from nonliving "materials" (as it must have, somewhere) becomes
drastically less accessible to study. For example, if we will not be able
to rely on well-grounded assumptions about the prevailing conditions
on Earth during various periods of its early history as boundary
conditions for candidate scenarios of this momentous development,
then our efforts to devise and confirm the right scenario will probably
be too unconstrained to permit anything but "unscientific" speculation.
We would like to be able to view the infancy of the Earth as a sufficient
tabula rasa for the genesis of life; "gifts" of life from elsewhere would
be most unwelcome, for it would be immensely more difficult to infer
the genesis of their design than if the entire process could be assumed
to occur locally. Unwelcome though such a hypothesis would be, it is
empirically possible, and one can imagine being able to prove that it
was true - e.g., from arguments that fixed a maximal speed of muta-
tion and selection and showed that there had not been enough time on
Earth for the whole process to have occurred locally.
Chomsky's arguments, from the poverty of the stimulus and the
speed of language acquisition, are analogous; they purport to show
that there must be large gifts of design in the infant if we are to explain
the speedy development of the mature competence. And while we can
take solace in the supposition that we may someday be able to confirm
the presence of these innate structures by direct examination of the
nervous system (like finding fossils of our extraterrestrial ancestors),
we will have to accept the disheartening conclusion that a larger
portion than we had hoped of learning theory, considered in its most
general form as the attempt to explain the transition from utter
ignorance to knowledge, is not the province of psychology at all, but
rather of evolutionary biology at its most speculative. The more the
infant brain can be viewed as a tabula rasa, the more accessible to
experimental research the ultimate mysteries of learning will be; if the
facts constrain psychologists to pass the buck to the evolutionary
biologists, we will have to settle for more abstract and speculative
answers to the ultimate questions. No a priori argument could refute
Chomsky's empirical contention about the amount of innate structure
actually to be found in the infant, but it is nevertheless reasonable to
hope, for the sake of science, that he has overstated the case.
Note
D. C. Dennett is a Fellow for 1979-80 at the Center for Advanced Study in
the Behavioral Sciences, Stanford, California 94305.
THE BEHAVIORAL AND'BRAIN SCIENCES (1980), 3
19

Commentary / Chomsky: Rules and representations
by Michael T. Ghiselin
University of California. Bodega Marine Laboratory, Bodega Bay. Calif. 94923
Evolutionary anatomy and language
Anatomy, as I see it, may fruitfully be defined as the study of
organization. As such it does not partake of the static character of
morphology but has a functional aspect as well. It includes not only the
study of organized beings, but the processes - such as selection and
learning - that organize them. Nor does it seem expedient to limit its
scope to the body. Languages as well as people have more than just
morphology - and surely both have evolved. One might well expect to
find some kind of parallelism between language and other evolving
systems.
Chomsky and I agree that biological and linguistic entities have much
in common. But as a comparative anatomist I question some of his
premises and conclusions. In particular, he wishes to establish that
there exists a separate linguistic faculty radically different from other
biological entities. My response will be cast as a dilemma. By analogy
with what we know about organized beings in general, he has gone too
far. If this be so, either the effort to ground linguistics in anatomy must
be abandoned, or else language is probably more closely integrated
with other faculties and shares more principles with them than
Chomsky maintains.
Chomsky rightly points out that language diversification is analogous
to speciation. Indeed the parallels between linguistic entities and
biological ones could hardly fail to escape the attention of evolution-
ists. Languages "speciate." A language (such as French) corresponds
to a species (such as Homo sapiens). So too with a dialect and a race,
and an organism and an idiolect. One could list a host of other
analogies, such as that between dines - character gradients within
species - and their equivalents in dialect geography.
However, we seem to differ upon a fundamental ontological issue. I
am a professed realist, whereas Chomsky advocates a peculiar
version of conceptualism. It is not just classes that Chomsky treats as
"idealizations" - a view I would dispute as well - but also individuals.
An uncertainty as to what exists "in the mind" and "in nature" can
scarcely fail but raise havoc with theories that depend upon what
.biologists call "natural classification" for their epistemic power and
ontological legitimacy. Chomsky treats the individual organism as an
"idealization reflecting a particular way of looking at things and
processes," but he seems to be asserting that the individuals them-
selves have no properties "apart from our mode of conception." (I
wondered if this were merely an unfortunate ambiguity in one sentence,
but I found levels treated analogously elsewhere.) It seems rash indeed
to treat an organ or an organism - individuals in the logical sense - as
conceptual. If I dissect any creature or a part of it, its properties do
come to me prepackaged, in the sense that they existed apart from my
thinking about them.
It has lately been recognized that species are, in the logical sense,
individuals, not classes (Ghiselin 1974 and earlier works cited therein;
Hull 1976). This thesis has numerous implications for all sciences in
which change is significant (Hull 1975; Reed 1979; Qhiselin 1980).
Individuals have no defining properties (or essential attributtes in the
old terminology). Much error has resulted from an understandable, but
nonetheless mistaken, interpretation of biological and linguistic groups
alike as classes. Trying to "define" French, Noam Chomsky, or H.
sapiens is a hopeless task, beyond an ostensive definition as with
other proper names. "Human language" has no defining properties for
the same reason that "Noam Chomsky's idiolect" and "tellurian life"
have none: they are individuals again. If we are to define any classes
here, they must be like the class of species, or classes of language-like
or life-like individuals. This is precisely what one would expect of
entities that change through time. But it runs counter to the hopes and
expectations of those who have attempted to treat species and
languages as if they were classes, often in the vain and egotistical
hope of putting our species in some privileged metaphysical position.
Although H. sapiens has acquired a lot of pecularities (none of which
are defining) gradually through time, many people wish to have a point
at which there arose a "set" of "essentially human" beings. Might not
the same have occurred with this "human language" entity? It is ironic
that the ability to speak was long taken to be a "defining" property of
Homo, a view that went well with the doctrine that only man can use
language and therefore think. When apes were taught a sort of
language, the effort was not abandoned; it turns out that apes are not
really using the linguistic faculty. Rather they are aping it with the
cognitive one. Apes think now. [See Cognition and Consciousness in
Nonhuman Species: BBS 1(4) 1978]
In disowning our relatives, it helps to erect a modular theory of the
linguistic faculty. Ideally this should be separate from every other
faculty and rest upon principia sui generis linguae. But how great is the
difference, really? Consider some analogies.
For Chomsky, language is modular in the sense of functioning apart
from other faculties. But consider the analogy of the nervous and
endocrine systems. They are so intimately interdependent in function
that we are hard-pressed to say where one ends and the other begins.
They work together as one integrated apparatus. Nor can we say that
they share no common principles: consider inhibition and excitation.
Why should not the same be true of language and cognition generally?
Chomsky never tells us precisely how independent they are, though he
suggests empirical means of resolving this issue. Destroying one organ
might lead to its functional replacement by another. But what of the
converse equipment - destroying the nonlinguistic "organs" to see if
language is unaffected? We can substitute hearing for vision, to a
considerable extent, when the corresponding organs are destroyed.
But observations on the effects might only tell us peculiarities of each
organ, and not whatever they have in common. If one blood vessel
becomes blocked, another may take over its function. But it is not clear
how any peculiarities of the new arrangement would bear upon the
question of whether we were dealing with organs working upon
different principles.
Another sense of "modularity" is not used by Chomsky. This is the
occurrence of "iterative" structure - modules like the virtually identical
units in a motel. For good reasons, many organized beings exist as
groups of parts having a great deal in common, albeit with variations. It
seems easier to construct and control structures if the parts have the
same arrangement and principles of functioning and organization.
Anyone who examines the vertebrate nervous system can hardly fail to
be impressed by its segmental character. That segments work on the
same principles can be demonstrated by experimentally adding super-
numerary limbs to embryos: these function more or less normally. At
the anterior end of the body specialization and diversification have
extensively occurred - but we cannot rule out common principles. If the
right and left halves of the brain differ, the principles are close enough
to make the differentiation hard to detect. It would seem, indeed, that
Chomsky has carried the principle of division of labor far beyond what
is biologically or economically reasonable (Ghiselin 1978). Our teeth
are iteratively organized, with a gradient from front to rear. Incisors do
one thing, molars another, but premolars both grind and slice. All the
teeth work upon common mechanical principles, resemble one another
structurally, and develop in much the same way. The faculty of
mastication should not be divided outright into slicing and grinding,
even though the distinction is a real one. Nor should the teeth be
denied their use in speech.
Finally, I wonder if the search for a single, universal grammar might
be somewhat misguided. Nature abounds in alternative modes of
organizing herself. There seem to be several ways of proceeding from
a zygote to a fully developed organism. The obvious example is in the
distinction between determinate and regulative eggs. The organism
can be "represented" as a kind of spatial pattern in the cytoplasm, or
as a series of events that trigger subsequent events. And some of the
rules are not, strictly speaking, in the nucleus. The trabeculae of the
bones, for example, are arranged in a pattern well-adapted to resisting
stress. But abnormally healed fractures show that the arrangement is
quite flexible, evidently involving a response to the stresses them-
selves. Hence it becomes very problematic, for one versed in develop-
mental mechanics, to decide to what degree, and in what sense,
"universal grammar is an element of the genotype." For all we know it
may be that the zygote is instructed to produce language one way or
another, that there are few ways of doing so, and that it "discovers"
which among various possibilities happen to work. In such an extreme
20
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Commentary / Chomsky: Rules and representations
case, organisms would have to "invent" or "discover" the principles,
and select among alternative ones every generation - much as some
animals must discover what is edible. Chomsky rightly considers many
such possibilities, but they need to be pressed. I do not believe that an
adequate answer will be obtained until we possess an empirical
approach in which truly decisive tests of the hypotheses are proposed
and executed. We need something analogous to an experimental
embryology, not just a physiology, of language.
Acknowledgements
I thank Edward S. Reed and Jan David Wald lor advice and comments on a rough
dralt.
by Gilbert Gottlieb
North Cmrolinm Division of Mental Health. Raleigh, N.C. 27611
Elaboration of maturational and experiential
contributions to the development of rules and
representations
Although no one can yet pretend to understand the precise nature and
extent of "innate" influences on psychological development, many of
us readily share Chomsky's notion (even if it is necessarily vague in
detail) that human linguistic and cognitive development are constrained
in certain ways, that "predispositions" abound, and that traditional
conceptions of learning are ill-suited to deal with these significant
complexities. In fact, the behavioral and psychological development of
nonhuman animals is similarly constrained in all cases yet investi-
gated - nowhere do we find indefinite malleability or infinite plasticity -
and traditional concepts of learning are equally unsuited to the task of
understanding the species-typical motor and perceptual development
of nonhuman organisms. Based on the present evidence from a variety
of species, the "blank slate" theory of mind should be relegated to a
minor station in scientific discourse: indefinite plasticity is the excep-
tion, not the rule. Even in those cases where patterned sensory
experience plays a crucial role in the attainment of species-specific
perceptual outcomes, the influence of such experience is sharply
delimited: exposure to only certain patterns of stimulation is effective in
channeling perception, and perceptual development can be channeled
only into certain paths and not others (e.g., Gottlieb, in press; Wiens
1970). In those cases where the range of malleability seems more
extensive (Jaisson 1975), temporal factors ("critical periods") circum-
scribe the duration of such susceptibilities in the developmental history
of the organism.
Thus Jaisson's ants are more flexible in their perceptual develop-
ment than we might have imagined, and humans are probably more
constrained than we had been led to believe, yet experience (not to
say conventional learning) plays an important role in normal psycholog-
ical and behavioral development. So, what then? I think it is obvious
that we must begin to formulate the various roles of experience in
species-typical development in ways that are compatible with the facts
of neurosensory and neuromotor maturation. This is a task that seems
highly relevant to Chomsky's doubts about the adequacy of traditional
concepts of learning in helping us to understand what he calls "the
growth of grammar in the mind." Along this line, perhaps I may be
forgiven for calling attention to the fact that newly formulated concepts
of the role of experience in the species-typical development of animals
(Gottlieb 1976a; 1976b) are beginning to find some application in the
study of phonological development in humans (Aslin and Pisoni 1980).
In brief, what Aslin and Pisoni have done is relate recently delineated
functions of early experience in animals (maintenance, facilitation,
induction) to hypotheses concerning phonological development in
humans (which they term universal theory, attunement theory, and
perceptual learning theory, respectively). The attempt here is to identify
the specific roles of early experience in three different versions of how
phonemic perception might arise during the course of human develop-
ment. This is an experiential framework that explicitly takes maturation
into account and thus seems relevant to Chomsky's contention that
". . . we do not really learn language; rather, grammar grows in the
mind." Although I admittedly do not follow the details of Chomsky's
proposal as well as I would like to, his analogies of language
acquisition with the role of experience in establishing receptor
networks in the visual cortex make me think he may find the concepts
of maintenance, facilitation, and induction congenial to his program of
thought.
by Gilbert Harman
Department of Philosophy, Princeton University, Princeton, N.J. 08540
Two quibbles about analyticity and psychological
reality
1. About analyticity. Certain propositions are sometimes said to
be "analytic" or true by definition. Favorite examples are: a bachelor is
an unmarried man and a cat is an animal. But how can anything be true
merely by definition? A definition is an assumption or hypothesis of a
certain sort. To say that something can be true by definition is to say
that one can sometimes make something true by assuming it is true.
How can one do that? No adequate answer to this question has ever
been given.
Examples of allegedly analytic truths are often not even true; for
instance, there are bachelors whose divorces are not yet final (Harman
1973, Winograd 1976). Other examples we can easily imagine reject-
ing, as we would reject a cat is an animal given the discovery that cats
are radio-controlled robots from Mars (Putnam 1962).
Chomsky suggests that there are better examples of analytic
connections "involving properties of the verbal system," such as, ///
persuaded you to leave, then at some point you intended to leave. But,
in order to persuade you to leave, I might keep you ignorant of the fact
that what you are doing is leaving, so that at no point do you intend to
leave. And, even if some such connection held between persuading
and intending, it would not be an analytic connection. We could
conceivably discover that intentions are a myth and that people never
intend to do anything (maybe Skinner is right after all). Given such a
discovery, we could still suppose that people sometimes persuade
other people to do things.
Of course, as Chomsky observes, intuitions about such examples
are "dubious" and uncertain. So let me stress that the real issue
concerning analyticity is not whether examples of putative analytic
truths can be found, but whether assuming or supposing or postulating
that something is true can ever make it true. I do not see that
Chomsky's work sheds any light on this.
2. About psychological 
reality. Chomsky claims that it is
pointless to distinguish the question of psychological reality from that
of truth, and he asserts that no similar distinction is made in the natural
sciences. But, given any theory we take to be true, we can always ask
what aspects of the theory correspond to reality and what aspects are
mere artifacts of our notation. Geography contains true statements
locating mountains and rivers in terms of longitude and latitude without
implying that the equator has the sort of physical reality the Mississippi
River does. Similarly, we can describe some part of the universe, given
a choice of spatiotemporal coordinates, recognizing that the special
role of that choice of coordinates in our description is an artifact of our
notation. And we might present a theory in axiomatic form without
assigning any physical significance to the distinction between axioms
and theorems.
Sometimes we are not sure about the physical reality of some
aspect of a theory, even given strong evidence for the truth of the
theory. A different sort of evidence may be needed. The postulation of
quarks gives a structure to the proliferation of subatomic particles, but
physicists demand a different sort of evidence in order to establish the
physical reality of quarks.
Chomsky implicitly recognizes the point as it applies to linguistics
when he acknowledges that one linguistic theory may be a "notational
variant" of another. Aspects of a true theory not shared by its
notational variants are not taken to have psychological reality. The
"linguistic evidence" for a given linguistic theory is like the evidence
that led to quark theory - namely that the theory brings order to a given
domain. That by itself may not indicate what aspects of the theory
correspond to reality and what aspects are artifacts of notation. We
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
21

Commentary / Chomsky: Rules and representations
might wonder, for example, whether the grammatical structures of
sentences have psychological reality or are mere artifacts of our
notation, so that a notational variant of our theory could assign
different structures to sentences. Click experiments, as in Bever et al.
(1969), might be relevant here (subjects who heard clicks while they
were listening to sentences tended to hear the clicks as displaced in
the direction of major clause boundaries).
I completely agree with Chomsky that this does not mean we have to
appeal to psychological experiments to provide evidence for psycho-
logical reality. The following argument from Chomsky (1975a) makes
the point. Consider the hypothesis H that in acquiring a language one
acquires an internal representation of the rules of grammar, where
these rules are similar to those Chomsky or one of his associates
would give for the language acquired. It turns out that some of these
rules could not be learned through trial and error, since errors are
never made. People acquiring the language never violate these parti-
cular rules and never have to be corrected. H implies that these rules
must be built-in ahead of time before it is determined what language is
being acquired. This means that the rules in question are either
universal rules, applying to every language, or at least that they
represent the "unmarked case" applying to a language unless some-
one acquiring the language would hear that the rule is violated. The
hypothesis H therefore leads to predictions about other languages,
where these predictions are based entirely on evidence from a single
language such as English. To the extent that these predictions are
confirmed (and to a surprising extent they are), that is evidence for H
and therefore evidence for the psychological reality of the rules of
grammar - evidence that is not based on psychological experiments.
by Patrick T. W. Hudson
Institute for Perception TNO. Soesterberg, The Netherlands
Minimalism in cognition and language: rich man, poor
man
Let us be clear. In his article Chomsky states plainly that his terminol-
ogy may be confusing, and he goes on to offer to replace the loaded
term "know" by "cognize." Furthermore, he makes it quite clear that
when he uses the words "mind" or "mental," he is making no claims,
unlike a true dualist, to some special level of existence, but rather to
"an abstract characterisation of the properties of certain physical
mechanisms." He wishes to defend the abstract level of much theoreti-
cal linguistics as being a proper scientific enterprise, much like modern
particle physics, which has an equally or even more abstract vocabu-
lary. As this all seems so unexceptionable, one wonders what all the
fuss is about. Nevertheless, recently psychologists, at least, have
reacted against Chomsky's formulations of what is here called cogni-
tive science. They wish to deny the special status of the language
faculty and, accordingly, the modular approach to mind.
Why should this be so? Strict behaviourists we may ignore; they are
committed to no internal structure and therefore no modularity; what is
more they have their minds (whose existence they deny) made up.
There are, then, two possibilities within those who subscribe to some
form of richly structured system; one group, which Chomsky advo-
cates, prefers relatively independent and highly structured modules,
the other prefers a homogeneous rich structure that defines heuristics
for the creation of high-level knowledge from external sources. At one
level it is, as Chomsky reiterates, obvious that some prior structure or
knowledge is present, and that not merely at the level of physical
structures such as limbs. Anyone who has handled neonates will verify
that the newborn baby can walk. That is to say, that he possesses the
crucial information for walking, which can be seen (given adequate
support and encouragement) by placing the child upright on a flat
surface and letting him walk. This information cannot be actively used,
however, until many months later. In such an example we see that the
core knowledge about walking - about forward locomotion by the
coordinated actions of the legs, whilst later requiring sufficient strength
and knowledge about balance and the operation of muscles - does
not, of necessity, include that latter knowledge as part of the informa-
tion for walking per se. So it is, I take from this article, with language.
I understand that the core knowledge, which grammarians refer to
as universal grammar, also requires other systems of knowledge for its
effective use. These systems may be identified as the conceptual
system and perhaps specialised systems for handling speech sounds
in perception and production. These may be interdependent in opera-
tion but, at some level of analysis, may be considered entirely on their
own. Our task, then, is to characterise and describe both the general
structures that may be available to many systems and the specific
structures that mark out and define a particular structure. So far so
good. Chomsky, arguing from the poverty of the stimulus and of the
world - factors that can only underdetermine the possible outcomes of
generalised systems - wishes us to accept that the distinct modules,
or faculties, that he proposes are themselves richly structured.
Certainly current work (reviewed by Pinker 1979) on the learnability of
languages suggests that the initial state of a language-learner must
contain a number of fixed assumptions if he is to make any headway at
all. These assumptions, or preset parameters are another description
or form of the knowledge that the language-learner brings to the
problem of learning a language. It seems that what Chomsky proposes
here is that this internal structure is rich, which implies that it contains
many preset values, fixed for a given organism.
This appears to lead us to a paradox, or very close to one.
Chomsky has championed the minimalist approach to linguistics: the
use of as few explanatory constructs as possible to adequately explain
the data. The minimalist approach currently seems to be very success-
ful in linguistics, and Marcus' (1978) use of the determinism hypothesis
has shown elegantly how one can go further. One of the major lines of
the argument presented in Chomsky's target article is against those
psychologists who wish to explain as much as possible of the
development and end-state of the cognitive system with only a few
restricted operations and assumptions. At the same time we appear to
see Chomsky advocating explanatory theories with a minimal and poor
structure as strongest in linguistics, while at the same time advocating
the most liberal of approaches when considering the wider sphere of
cognition, of which he takes language as an example. How can he
criticise minimalists for carrying out a program he recommends?
Maybe there is no paradox after all. Maybe we have been misled by
a lack of clarity in the definition of "rich," just as many psychologists
have been misled by (their own) misunderstanding of such terms as
"know," "mental," and "incorporate" when they tried to understand
and use generative grammar. What may be meant by "rich" here is
that, in the limiting case, a cognitive structure will be distinct and rich
even if it possesses only one extra structural element. In the ideal case
we may attempt to relate specific cognitive structures to the outcome
of that one specific value associated with a crucial parameter.
Certainly in development one small specific factor at a critical time may
have large and far-reaching effects; for instance, the merest push is
sufficient to set a balanced pole to fall in the direction of the initial push.
Marcus (1978) argues that the constraints of linguistic theory, which at
that level must be accepted as pure stipulations, can be seen to fall out
naturally as a consequence of building a parser single-mindedly
following the determinism hypothesis, of allowing no back-up or
alterations in a natural language parser. If this is at all true, we can see
with greater clarity what is meant by the rich structure - what are the
fixed assumptions that enable the system to work and, possibly, to be
developed at all.
This argument is not with what Chomsky says but how he says it.
by George Lakoff
Department of Linguistics. University of California. Berkeley. Calif. 94720
What ever happened to deep structure?
There are two levels on which to view Chomsky's work: 1) the
technical apparatus and empirical considerations that enter into the
detailed linguistic descriptions he advocates; and 2) the broad general
claims he makes concerning the nature of the mind. The technical
apparatus and empirical considerations have changed drastically in
the past twenty years. In the mid-1960's, he viewed linguistic structure
22
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Commentary / Chomsky: Rules and representations
as based on "deep structures" with semantic significance, and trans-
formations thai mapped deep structures onto "surface structures." In
the past several years the role of transformations and deep structures
has become virtually nonexistent. Deep structures have lost their
semantic significance and come to look more and more like surface
structures; and correspondingly, transformations have virtually disap-
peared. In 1965, generative grammarians had found hundreds of
transformations. A decade later, Chomsky (1975c) was speculating
that there might only be one. This would make the deep structures of
most sentences identical to their surface structures. There is no
mention of deep structures and transformations in the present work.
The reason for this will be discussed shortly.
Outside of linguistics, the academic public knows virtually nothing of
the technical details of Chomsky's linguistics. What seems to stick in
most people's minds are his claims about innateness. On the whole,
his view of innateness has not changed. Nor has his view on what he
now calls "modularity." His views on modularity are extreme and, I
think, fundamentally mistaken. Briefly, modularity in Chomsky's linguis-
tics means the following:
1. The syntactic rules of a language are matters of pure form. They
are completely independent of:
a. meaning;
b. the way people use language to communicate;
c. the processing of language, in both perception (hearing and
understanding) and production (speaking); and
d. any other aspect of human experience.
2. The syntactic rules form a "module" that interacts with, but is
independent of, other modules.
3. One of the things that principally separates man from the lower
primates is the presence of a syntactic module with the above
properties. Hence, Chomsky grants in his target article that primates
may have part of a conceptual system and may be able to communi-
cate, but he holds firm on their lacking a syntactic system ("even the
rudiments of the computational structure of human language").
4. The syntactic rules (which are independent of meaning, communi-
cation, processing, and experience in general) form the most central
and important part of the "human language faculty." Apes don't have
syntax and so are "in this regard like humans without the language
faculty."
5. What is innate in humans, as opposed to lower primates, is the
presence of an independent syntactic "module" - that is, the capacity
to structure language in terms of pure form in the way humans do.
Chomsky suggests that this view of modularity and innateness is
grounded in empirical linguistic research. That is highly questionable, to
say the least. The way Chomsky uses the modularity claim amounts to
a matter of definition. The principal reason that Chomsky's views on
the technical details of linguistics have shifted so radically is that he is
trying to maintain his views on modularity in the face of mountains of
evidence to the contrary. Perhaps the main reason that deep struc-
tures and transformations have disappeared is that it turned out to be
impossible to both keep them and maintain the principal assumption of
modularity: the independence of syntax. Most of the research showing
this was done by a group of the first generation of Chomsky's
followers: myself, Paul Postal, John Robert Ross, James D. McCawley,
Robin Lakoff, Charles Fillmore, David Perlmutter, Edward Keenan, and
others. What we found was that meaning and use (communicative
function) effected virtually every rule of syntax. In order to keep the
central modularity assumption - the independence of syntax -
Chomsky has progressively redefined and narrowed the domain of
syntax so that rules that were traditionally part of syntax (e.g. case
assignment, pronoun agreement constraints, the occurrence of nega-
tive polarity items) were redefined as being in "semantics" - that is, in
a different module. Only by constant redefinition and narrowing of the
facts for which the syntactic module is supposed to account has
Chomsky been able to maintain modularity.
What is new in Chomsky's present essay is terminology, analogies,
and metaphors - mostly from the realm of biology. The biological
analogies have no linguistic content - that is, they make no new
empirical claims about the structure of language. The analogies are
almost entirely gratuitous. When Chomsky analogizes between the
linguistic and conceptual systems on the one hand and the visual and
circulatory systems on the other, we are in the realm of rhetoric, not
science. But as rhetoric, it is effective - at least so far as academic
politics is concerned. The term "mental organ" for the linguistic faculty
is artfully chosen. The effect is to say: "I'm doing for the mind what
biologists are doing for the body." The use of biological terminology
and bibliography has the effect of suggesting rapport with biologists -
simply by speaking their language. It also has the effect of making it
seem to those who don't know the linguistic details that Chomsky's
views have biological backing.
It is particularly striking that the biological analogies Chomsky uses
come not from contemporary biology - molecular biology, genetics,
and so on - but from earlier biology - the biology of separate systems
- the circulatory system, the visual system, and so on. Perhaps the
greatest leap forward in contemporary biology has come from trans-
cending the separate systems approach and asking what is in
common: cell structure, DNA structure, and so on. For me, the most
exciting question at present in the cognitive sciences is what similarities
there are in the various cognitive faculties - language, thought, vision,
motor control, and so on.
Chomsky downplays what he calls "loose analogies, perhaps in
terms of figure and ground, or properties of memory." But the
similarities are there, and they are more than "loose analogies." In my
own research I have been particularly impressed by the structural
similarities. For example, syntactic rules can be stated in terms of the
same kind of network structures that are used in cognitive and visual
representations in cognitive psychology and artificial intelligence
(Lakoff 1977). And Johnson and I (1980) show coherences between
the metaphorical structure of the conceptual system on the one hand
and syntactic structure on the other. My own feeling is that cognitive
science will best progress by transcending the independent modules
approach and instead looking at the interdependencies and similarities
among the various aspects of cognition.
by John C. Marshall
Neuropaychology Unit, University Department of Clinical Neurology, The Radclifle
Infirmary, Oxford, England
The new organology
Imagine a man who denied that "the moral and intellectual acts of man
flow from understanding and will, independent of the body" (Hollander
1920, p. 232). Such a man might regard the brain as part of the body
and conjecture that "the brain is the organ of the mind" (Hollander
1920, p. 214). This, in turn, might lead him to propose a research
program in which psychology was to be rescued from metaphysics in
order to become a branch of general biology (Lewes 1871). Pursuing
an analogy between organs of the body and organs of the mind, our
scholar would see little point in drawing too sharp an epistemological
distinction between bodily organs, perceptuomotor systems, and
cognitive faculties: "For sight and hearing are just as much psychic
talents as are the different kinds of ideas" (Lesky 1970, p. 303). If,
indeed, the maturation of, say, the visual system were analogous to the
maturation of, say, the language system, the scientist would perhaps
claim, as a general principle, that "the development of the mind of the
child, far from being a mere moulding of it by the impression made
upon it by its environment is . . . an unfolding of latent potentialities"
(Hollander 1920, p. 249). The claim that the "elementary qualities of
the mind are innate" would nonetheless require, of course, that these
qualities must be "drawn out and cultivated" by the environment
(Hollander 1920, p. 249). This viewpoint might lead one to expect that
"the primary mental powers do not develop simultaneously" (Hol-
lander, 1920 p. 249). One might rather expect to discover that "some
develop early in life and speedily reach maturity, while others are late in
coming into activity" (Hollander 1920, p. 249).
Our scholar could state the explanatory goal of his research
program as follows: "We have to discover the fundamental powers of
the mind, for it is only these that can have separate organs in the
brain" (Hollander 1920, p. 238). The hypothesis that there are sepa-
rate powers to be discovered would not, however, lead one to
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
23

Commentary / Chomsky: Rules and representations
suppose that they cannot interact. On the contrary, one might expect
overt behavior to be consequent upon the interaction of distinct
faculties: "Indeed, we believe that the total nervous system is a
combination of many; that all these individual systems differ in their
office; that the offices are related to the development of the organs;
that more or less of a bond, and therefore of reciprocal influence,
exists between all the individual systems" (Lesky 1970, p. 309).
Continuing this line of investigation, one might suppose that the
innate propensities and faculties are "unequally shared by the different
species of animals" (Hollander 1920, p. 237). It could thus be the case
that man alone possesses "the faculty of speech and unlimited
educability - two inexhaustible sources of knowledge and action"
(Hollander 1920, p. 246). Stated in more general terms, "the internal
and external worlds" of different species will "vary to infinity, diminish-
ing or increasing in the same proportion as the number of these organs
diminishes or increases" (Hollander 1920, p. 237). "The external
world," then, "is known only to the extent of our perception of it, which
varies according to our own individuality" (Hollander 1920, p. 238). But
it assuredly does not follow from this view that man is a prisoner of his
biological endowment. On the contrary, one might plausibly argue that
the proliferation of biological constraints protects man from manipula-
tion by the environment: "The more complex the organization, the
greater the choice, the greater the freedom" (Hollander 1920, p. 245).
In this sense, one might claim that man, in principle, is more free than
the other animals, for "all the facts quoted by metaphysics in favour of
a free will are only met with in the conditions where the intellect
predominates over the instincts and sentiments" (Hollander 1920, p.
245).
Speculating yet further, we might suppose that creativity itself is a
basic human trait: "The same organ, which in the nightingale produces
singing, in the beaver the faculty to build, produces correspondingly in
man music, architecture . . . etc." (Hollander 1920, p. 252). In short,
"the arts and sciences were not invented because of the necessities
arising for them, but because of our innate disposition" (Hollander
1920, p. 252).
Despite their obviously libertarian stance, men who argue in the
above fashion have often been accused of denying the existence of
free-will or of "explaining it away." Those who stress the biological
prerequisites of meaningful experience are, for reasons unknown,
peculiarly prone to such attacks. What defence could our scientist
offer at his trial - a trial at which he is accused of propagating the
materialist doctrine that "we are the instruments rather than the
masters of our actions; we are slaves to our internal impulses"
(Hollander 1920, p. 244)?
He might reply that "it is highly important to know how the soul
operates in this life in its alliance with the body, and according to what
law it acts" (Hollander 1920, p. 214). He could argue that "the most
decided and undeniable experience teaches us that the brain, of all
parts of the body, is the one by means of which the mind manifests its
powers" (Hollander 1920, p. 214). When his judges proclaimed that
the postulate of modularity denied the unity of the soul, he would simply
ask "why should not the soul require for its various attributes structur-
ally distinct parts of the brain" (Young 1970, p. 19)? If nature has
constructed particular organs for seeing, hearing, salivating, producing
bile, "why should She have made an exception for the brain" (Young
1970, p. 19)? When this failed to convince his opponents, he might
point out that he was only studying the structure of the faculties and, as
a good Aristotelian, the material not the effective causation of behav-
ior: "The brain centres determine the disposition or tendency but not
the actions themselves" (Hollander 1920, p. 245). Finally, he could
quote Herder's remark "that force and organ are indeed most
intimately connected, but not one and the same thing" (Lesky 1970, p.
307). And he might stress yet again that the activity he was pursuing
was empirical science: "We, physicians and surgeons, limit our investi-
gations to the facts cognizable by the senses, and leave everything
else to the clergy and revelation" (Hollander 1920, p. 214). None of
this would save him, especially so when he remarked that "the
pervasive religious ideas of man and revealed religion would have been
absolutely impossible if the human species had not been endowed with
the appropriate nervous apparatus for having these experiences"
(Young 1970, p. 16).
The position I have outlined in the preceeding paragraphs is, of
course, the o/d organology. All quotations and paraphrases have been
taken from the writings of Franz-Joseph Gall. It is not too difficult,
however, to see the family resemblance between Gall's work and the
new organology of "Rules and Representations."
In 1802 Gall was thrown out of Vienna by decree of Emperor Francis
I; Pius VII excommunicated him in 1817 and placed his books on the
Index; the medical establishment of Europe denounced him as a
charlatan or worse: "Mankind must revolt when it hears that a
preacher of fatalistic theories promulgates teaching which would be
abhorred even by the most savage people without morals and religion"
(Walter 1805). It is not, however, without interest to note that every
major position for which Gall argues has become a commonplace of
modern neuroscience. (It is, of course, a vulgar error to suppose that
Gall was primarily a craniologist: "They call me a craniologist, and the
science which I have discovered, craniology. I rather think that the wise
men have baptised the child before it was born. The object of my
researches is the brain" (Hollander 1920, p. 344)).
In particular. Gall's central hypothesis - that cognition is modular -
has accumulated wide-ranging support. Studies of the psychological
consequences of local damage (Coltheart, Patterson, and Marshall
1980) reveal patterns of deficit and preservation that fractionate the
mind into categories far more specific than those that the nineteenth-
century neurologists were prepared to conjecture; electrophysiological
recording suggests similarly that many areas of cortex are organized
into specialized cytoarchitectonic fields within which cells respond to a
very narrow range of stimuli (Zeki 1978).
We would hope, however, that the new organology will go signifi-
cantly beyond the old and raise questions that could not even be
formulated within the conceptual framework of nineteenth-century
investigations. In what ways is this hope being realized? Young (1970,
p. 29) writes: "If one asks what Gall had to say about how the brain
functions as opposed to what are the functions of the brain, he has
little to offer." Young's assessment is perfectly fair. It is here that
recent work in linguistics has indeed progressed beyond the bound-
aries of Gall's organology. As Chomsky notes, core grammar aims to
provide an "abstract characterization of the properties of certain
physical mechanisms, as yet almost entirely unknown." Yet the status
of the principles of core grammar continues, I suspect, to worry even
those psychologists and neuroscientists who are quite prepared to
endorse Chomsky's "realist" philosophy of theoretical constructs. Let
us take the example of WH-movement. Free movement of WH-phrases
into COMP, subject to the subjacency principle and interacting with the
successive cyclic application of movement rules undoubtedly provides
a rich account of question formation. The theory as a whole incorpo-
rates principles of mental computation that show promise of being
"genuinely explanatory in that they unify a variety o f . . . generalizations
and ground them in a system that has a certain degree of deductive
structure" (Chomsky 1978, p. 16). So far so good. But very naturally,
by virtue of their professional background, psychologists must be
concerned with the role of the grammar in the perception and
production of language. The grammar is not in and of itself a
characterization of these abilities, and has never been claimed by
Chomsky to be so. The failure of the derivational theory of complexity
(and the analysis-by-synthesis algorithm upon which that theory was
based) has regrettably led psychologists to ignore, almost totally, the
developments that have taken place in linguistics over the last decade.
This can be seen most clearly by looking at any recent textbook of
psycholinguistics. One consequence of this neglect is outlined by
Chomsky: It does indeed appear that many "psycholinguistic"
phenomena that have been uncovered in recent years have little or
nothing to do with the properties of the language faculty. The phenom-
ena are no less interesting for this reason, but their interpretation has
typically been chaotic and ad hoc to the point of despair.
Much current work in "artificial intelligence" thus conflates proper-
ties of the language faculty (e.g. the structural configurations that
determine sentence-internal anaphora) with, for example, one's knowl-
24
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Commentary / Chomsky: Rules and representations
edge of the appropriate way to behave in restaurants. The a priori
likelihood that the intersection of these sets constitutes a theoretically
coherent domain is not great. Similar considerations apply to the brief
vogue that "generative semantics" enjoyed in the eyes of psycholo-
gists. That any "performance datum" will necessarily reflect much
knowledge and skill over and above the knowledge represented in
linguistic theory misled psychologists into accepting that all human
knowledge should be encoded into a monolithic structural derivation.
The "psychological reality" of the overt phenomena was thus
confused with a theoretical claim about the distinctness of different
knowledge sources. The related vogue for "case grammar" in studies
of language-acquisition was based on an even more disastrous
confusion. From the fact that one often wants to know "who did what
to whom with what," it surely does not follow that the primary
categories of the grammar must be "Agent," "Object," "Instrument,"
and so on (see Smith 1979). It requires more than fiat to equate the
child's ontology with the syntactic categories that are available for the
expression of thought. And it is thus hardly surprising that so much of
the traditional language-acquisition literature has so signally failed to
move beyond superficial description of what the child typically says at
age n, n + 1, n + 2, and so on. Contrariwise, when the distinction
between language and effective communication has been honoured,
significant results have emerged; the work of Dennis (1980), in which
she shows that the parsing principles of isolated left and right
hemispheres are quite distinct, is a case in point. Such findings in no
way rule out the possibility that, in the normal intact brain, the two
hemispheres cooperate in assigning structural descriptions to incom-
ing signals.
In the long run, however, the concept of distinct yet interacting
systems will only make practical sense (and psycholinguistic sense) to
psychologists once we can see, in principle at least, how the grammar
might be incorporated within the performance machinery. Minimally,
the grammar must constrain the class of mechanisms that could be
postulated for parsing and producing utterances (Fodor 1978).
Contact might also be achieved at the level of surface filters. A
well-known example is filter 20 of Chomsky and Lasnik (1977); the
constraint *(NPNP tense VP) interacts with the on-line perceptual
strategy of interpreting structures that can stand as independent
clauses as main clauses of the construction. A set of analyses where
the free operation of a useful heuristic gives the wrong result is thereby
blocked by the filter.
The necessity of a psychological interlevel (in the narrow sense of
"psychological") becomes even more apparent when we consider the
relationship of the grammar to biology. All primary data are perfor-
mance data; with the possible exception of "pure" anatomical studies,
no investigation of the brain constitutes an exception to this fact. It
follows that there will be no coherent explanation of "physiological"
data that does not require us to "filter" the results through an abstract
theory of a performance device that tells us what the software system
is doing. Talk of single cells acting as line detectors is emphatically not
a description of the visual system. A singlecell connected to perhaps
10* other cells is what the neurophysiologist is recording from, and the
system whereby the organism computes a representation of a visual
object escapes us (but see Marr 1976). One of the most striking
examples of what happens when a systemic characterization is
ignored can be seen in a recent paper by Ojemann and Mateer (1979).
In this work the "syntax center" is located by electrical stimulation
during craniotomy. Further comment is unnecessary.
I have discussed some positive aspects in which Chomsky's "bi-
ologism" is closely related to Gall's These aspects are basically
strategic. We should, I agree, use the metaphors of growth and
environmental triggering and regulation when looking at language-
acquisition. There is, I think, a significant analogy between the mecha-
nisms of speciation and the ways in which, in core grammar, "a small
change in parameters may lead to what appears to be a radical
change in the resulting system" (Chomsky, target article).
A revealing example of such a mechanism can be found in Bard's
model of zebra striping patterns (Bard 1977). The immunological
analogy, on the other hand, I find less compelling (Adinolfi 1978). True,
molecular recognition and antibody production is a "selectional," not
an "instructional," process. But I am unaware of any deeper parallel
between immune responses and "learning" in the central nervous
system. Similar considerations apply to the putative parallel between
classical (Mendelian) genetics and the conditions on formal structures
that are captured in universal grammar (Jenkins 1978). Exploitation of
this surface analogy really cries out for an analysis of what it could
possibly mean to "reduce" linguistic theory in a fashion analogous to
the reduction of classical to molecular genetics that has been such a
conspicuous success-story of twentieth-century biology (Goosens
1978).
The problem, then, for Gall and for Chomsky is that none of the
above seems to bring us any closer to biology in the narrow sense of
the term. By "narrow sense" I mean a concern with the neurophysio-
logical realization of the mechanisms in question.
In 1808, Pierre Flourens produced the definitive critique of Gall's
theory. He paid tribute to Gall's outstanding achievements as an
anatomist, and he was not totally unsympathetic to what Gall was
trying to do as a "biological psychologist." He did, however, remark
that Gall's works contained not "one word of special anatomy, of
secret anatomy, of what might be called anatomy of the Doctrine; or, in
other terms, as it would be expressed at the present day, of phreno-
logical anatomy. . . . The anatomy of Gall's memoir is nothing but very
ordinary anatomy" (Young 1970, p.25).
The current revival of studies in the anatomy of language (Galubur-
da, Sanides, and Geschwind 1978) is likewise concerned with ordinary
anatomy. Transposed into modern terms, I take it that Flourens was
asking for the anatomy of WH-movement. Such crude and naive
"translationism" is widely regarded as either conceptually incoherent
or empirically ridiculous. These feelings will cut little ice, however, until
a viable alternative is proposed; some way surely has to be found in
which results phrased in the languages of linguistics, psychology, and
physiology can be made to bear upon each other. I am inclined to
believe that Chomsky has posed the crucial questions in the biology of
language. And it is precisely this belief that leads me to wonder what
would happen if workers in related disciplines took Chomsky's biolo-
gism literally.
Acknowledgments
I am grateful to Robert May and to Mary-Louise Kean for their critical
comments on an earlier draft of this paper.
by Robert J. Matthews
Department ot Humanities, Cook College, Rutgers University, New Brunswick. N.J.
08903
Language learning versus grammar growth
Chomsky suspects that we may well misdescribe language acquisition
when we call it "learning." In certain fundamental respects, he
suggests, we do not really learn language; rather, grammar grows in
the mind. I share Chomsky's suspicions: it seems to me very likely that
future empirical research will force us to conclude that language
acquisition is best described as the growth of a mental organ. But
though I endorse Chomsky's words, I am not certain that we envision
the same eventuality. In this commentary I should like to examine
Chomsky's account of the distinction between language learning and
grammar growth. The distinction, I shall argue, is nontrivial: believing
that language acquisition is a matter of grammar growth rather than
learning is tantamount to abandoning a rationalist account of language
acquisition.
The question that interests me here is this: What sorts of discoveries
about language acquisition should lead us to conclude that language
acquisition is a matter of grammar growth rather than grammar
learning? (I use the expression "grammar learning" rather than "lan-
guage learning" in order to make clear that I don't think that the issue
here has much to do with the characterization of linguistic capacity.)
Chomsky does not address this question explicitly; however, his
discussion of a related question (p. 13) suggests that if language
acquisition is not to be characterized in terms of such processes as
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
25

Commentary / Chomsky: Rules and representations
are typically associated with learning (e.g., association, induction,
conditioning, hypothesis-formation and confirmation, abstraction and
generalization, etc.), then it may well be that language isn't learned. His
discussion of Peircean abductive procedures develops this sugges-
tion. In effect, he seems to say that if language acquisition is a matter
of generating hypotheses and then testing them against primary
linguistic data (in conjunction with an evaluation metric), then it's
learning; otherwise, it's growth. The basic difference between these
two abductive procedures seemingly has to do with the role of
experience in language acquisition: in the learning case, experience
serves as evidence against which hypothesized grammars are evalu-
ated; in the growth case, experience serves directly in the selection of
the most accessible grammar. Quantitatively speaking, convergence
on a target grammar is presumably much more rapid in the second
case.
Although we know very little as yet about abductive procedures of
this second sort, we do know quite a bit about procedures of the first
sort, enough at least to know what kind of empirical evidence might
bear on the claim that language acquisition instantiates such proce-
dures (cf. Pinker 1979). Indeed, we know enough so that if this is what
we mean by "learning," then language acquisition is not learning. The
reason is that, given both the complexity of the grammars attained and
the poverty of the data on the basis of which grammars are attained,
learning can be achieved only if there are very severe constraints on
the form of acceptable grammars (cf. Matthews 1979). In fact, these
constraints are so severe as to render grossly inappropriate any
characterization of the acquisition process in terms of hypothesis-
testing. Data serve not so much as evidence for a hypothesized
grammar as they serve as a series of triggering events that determine
the course of grammatical development. Chomsky apparently has
something like this in mind when he talks of "grammar growth":
universal grammar narrowly constrains the category of attainable
grammars, but with parameters that remain to be fixed during language
acquisition. Differences in acquired language manifest differences in
the fixed values of these parameters. Preference for talk of "grammar
growth" thus reflects basic assumptions about the role of experience
in language acquisition. These assumptions are rationalist inasmuch as
this account of the role of experience presupposes that the learner
comes to the acquisition task with extremely rich innate linguistic
structure.
Although I do not object to Chomsky's decision to mark his
rationalist commitment by the expression "grammar growth," I do
believe that there is a more straightforward sense in which language
acquisition may turn out to be a matter of grammar growth rather
than grammar learning. The straightforward sense of the distinction,
like Chomsky's, has to do with the vocabulary in which a theory of
language acquisition will be couched. Just as empiricists assume that
an adequate theory of language will be framed in terms of notions of
association, induction, generalization, and so on, so too have rational-
ists made particular assumptions about the appropriate vocabulary for
an adequate theory of language acquisition. Specifically, rationalists
assume that the same vocabulary used to characterize the structures
attained in language acquisition will be suitable for characterizing the
actual attaining of those structures. This extremely strong assumption
is effectively embodied in the condition of explanatory adequacy that is
levelled against linguistic theory; however, it is most clearly manifested
in the abductive accounts of language acquisition that Chomsky
employed in the past (cf. Chomsky 1965) but now rejects for other
reasons. Such accounts were supposed to "represent a hypothesis
about the innate intellectual equipment that a child brings to bear in
language learning" (Chomsky 1962, p. 530). In employing these
accounts, Chomsky committed himself to the assumption that an
adequate theory of language acquisition would employ the intentional
idiom of knowledge, belief, intention, and the like as its theoretical
vocabulary. For, on these accounts, the learner is characterized as
knowing (innately) certain principles, as selecting certain hypotheses
from within the class of possible grammars, as testing those hypoth-
eses against primary linguistic data, as choosing the optimal grammar
from among those compatible with the data using an evaluation
measure, and so on. Of course, Chomsky did not deny that there are
any number of other descriptions of the development of linguistic
capacity in the child. But he apparently believed (hypothesized) that
the appropriate vocabulary for a theory of language acquisition would
characterize the relevant states and processes of the learner in
intentional terms.
Chomsky now seems willing to abandon the hypothesis-testing
idiom of these earlier accounts; however, this should not be construed
as an abandonment of the intentional idiom itself. For he still believes
that the innate structure (or schematism) necessary for language
acquisition can be characterized intentionally in terms of what the
learner innately knows (or cognizes): a system of universal grammar is
a set of highly restrictive principles cognized by the learner. Thus, for
example, if on the basis of linguistic research Chomsky hypothesizes
that all natural languages satisfy his structure dependency principle,
and if he further hypothesizes that this fact about natural languages
relfects a constraint imposed by the innate structure of human linguistic
capacity, then on his rationalist account of language acquisition, he will
characterize the learner as standing innately in a certain relation to the
content "that all natural languages satisfy the structure dependency
principle." Whether this relation is appropriately characterized as one
of knowing is, as Chomsky says, of little interest here. The crucial point
is this: innate structure relevant to language acquisition is character-
ized intentionally in terms of both the content of a state and the
learner's relation to that content (e.g., knowing that p, hypothesizing
that q, etc.); the various processes and state-changes thought to
characterize the acquisition process are defined over such contents.
The rationalist's insistence that it is content rather than mechanism that
is innate expresses a commitment to the intentional idiom as providing
the appropriate characterization of innate structure (cf. Matthews
1979).
It seems to me quite possible that, when functionally interpreted, the
intentional idiom characterizes the etiology of behavior at a level of
abstraction appropriate for capturing the behaviorally relevant similari-
ties common to the possibly disparate physiological processes that
eventuate in a single type of behavior. It is surely some measure of the
appropriateness of this idiom that explanations and predictions of folk
psychology - our only marginally successful psychology to date - are
couched in it. But why assume that this is the appropriate level of
abstraction for a theory of language acquisition? Although being in
certain intentionally characterizable internal states may be relevant to
an organism's behaving in the way that it does, why suppose that there
is an intentional characterization of how the organism comes to be in
those states? In particular, why assume that there is such an account
for language acquisition? We don't suppose that there is an intentional
description of the construction of a mechanical chess-player just
because the behavior of this device is best explained and predicted in
intentional terms. Proponents of intentional accounts make much of the
intentional character of folk psychology, but folk psychology is notably
silent on matters of learning. For all that folk psychology tells us,
"learning" might be more akin to muscle-building, which is to say that a
theory of "learning" would employ a nonintentional, presumably physi-
ological vocabulary, describing learning as the growth of a mental
organ under suitable conditions of sensory stimulation. In such an
eventuality, talk of "grammar growth" would be quite appropriate,
since the characterization of linguistic development would be of a
piece with characterizations of the development of various organs. But,
in so characterizing language acquisition, one would in effect be
abandoning a rationalist account of language acquisition. This in itself
is probably sufficient to insure that my notion of "grammar growth" is
not Chomsky's. But if it is not, one must wonder why he finds his notion
appropriate. More importantly, why does he find it plausible? Surely
nothing in his present paper contributes to this finding.
by James D. McCawley
Department of Linguistics. University ot Chicago. Chicago, III. 60637
iTabula si, rasa no!
Chomsky has often argued that treatments of the human mind as
initially a blank slate have not done justice to the mind. However, they
have done even less justice to slates. No slate (or paper, or magnetic
26
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Commentary / Chomsky: Rules and representations
tape, etc. -1 will use "slate" to reler indiscriminately to all media for
writing, since the physical substance is irrelevant to the analogy) is
wholly unstructured. Blackboards provide two dimensions, while
stacks of transparent plastic sheets provide three, and punched tapes,
only one; slates differ with regard to whether erasure is practicable
(with blackboards and magnetic tape it is, with clay tablets and punch
cards it isn't); and they differ with regard to whether the slate provides
devices that facilitate the writing of particular kinds of messages, as do
the rulings on graph paper or the staves on music paper, or for that
matter, the questions and spaces for answers on a dog license
application form. The idea of a completely unstructured slate may
indeed be incoherent, in that slates are supposed to provide not only a
medium on which messages can be written, but also a medium off of
which messages can be read; you might try to write a message on an
infinite-dimensional vacuum if you could find one, but no one would be
able to read it.
In a conception of the mind as involving a slate, the interesting issue
is not whether the slate is ever blank, but what the structure and
functions of the slate are. What determines what is entered in the slate
and where it is entered on it? Does the slate have different components
that differ from one another in internal structure? How are existing
entries on the slate used in cognition, action, and further learning?
There is of course a more basic question: namely, does the mind
involve a slate at all? In this target article Chomsky speaks as if it does
not; his remarks, however, turn out to relate to a different issue.
Chomsky expresses serious reservations about the notion of "learn-
ing." ("It is rather doubtful . . . that there is much in the natural world
that falls under 'learning,' so conceived, if the metaphors are taken
seriously"; "It is possible that the notion 'learning' may go the way of
the rising and setting of the sun.") He suggests that there is no real
difference between learning and growth, and he approvingly quotes
Jerne's conjecture that supposed instances of learning may turn out
not to be "instructive" changes (in which "a signal from the outside
imparts its character to the system that receives it"), but rather
"selective" changes (in which "some already present character is
identified and amplified by the intruding stimulus"). Selection, however,
is only one aspect of learning - and, to my mind, the least interesting
aspect of it. Selection (generally called "reinforcement" by those
whose accounts of learning have dealt with it) may provide an account
of why a person entertaining a particular hypothesis will retain or reject
that hypothesis, but it gives no insight into what I take to be the two
biggest questions about learning: how does a person come to enter-
tain the hypotheses that he does, and what happens to a hypothesis
once selection has operated in its favor - i.e., how is it incorporated
into the person's repository of knowledge (= "slate")?
At various places in this target article and earlier works, Chomsky
touches on these questions but stops far short of answers to them. He
maintains that one's innate language faculty heavily constrains what
hypotheses are entertained, but he offers no hint as to where the
language-particular hypotheses come from. While an innate language
faculty might well make available both the hypothesis "object
precedes verb" and "object follows verb," with selection (= "rein-
forcement") deciding which one wins, it is implausible to suppose that
it makes available to the learner a range of hypotheses as to the
meaning of assassinate that includes "kill in order to remove from
political power." His statement that "grammars are internally repre-
sented in the brain" appears to make reference to a component of a
mental slate, perhaps in a form analogous to a pad of dog license
application forms, providing a checklist of features on which languages
can differ, with a separate sheet to be filled out for each language that
one learns. However, the programmatic accounts of language acquisi-
tion that appear in Chomsky's works (e.g. 1965; 1975a) deal only with
the end-product of language acquisition and have nothing to say about
the developmental steps that would lead to that end-product - in
particular, the steps in which entries are made on the slate. Selection
surely is involved in language acquisition, but that isn't saying much.
Chomsky wonders whether we can "distinguish learning from
growth in terms of the state attained." We can, since learning and
growth individuate differently. If one is given appropriate exposure to
French, Flemish, and German, one develops command of all three
languages but does not develop three larynxes or three pairs of ears.
Your genes fix in advance the number of organs of each type that you'll
develop, but they don't fix in advance the number of bodies of
knowledge (e.g. languages) that you'll acquire through the use of each
"mental organ." The possibility of acquiring several bodies of knowl-
edge of a given type is the clearest evidence that I know of for the
proposition that the mind involves some sort of slate.
Chomsky asks, "Is the mind organized into distinct cognitive facul-
ties with their specific structures and principles, or are there uniform
principles of learning, accommodation, assimilation, abstraction,
induction, strategy, or whatever, that simply apply to different stimulus
materials to provide our knowledge of the behavior of objects in
physical space, our knowledge that certain strings of words do or do
not have certain meanings, and so on?" Here he sets up a false
dichotomy: there is no reason why the "modules" that Chomsky
regards human cognitive capacities as being composed of should
correspond in.a one-to-one fashion to "cognitive domains." Chom-
sky's analogy between cognitive capacities and bodily organs indeed
suggests that among the cognitive modules there could well be some
that have communicative or organizational functions analogous to
those of the circulatory system or the nervous system. The "learning
theories" of behaviorist psychologists have been implausible largely
because they were supposed to accomplish the whole of learning
without assistance from anything other than the sense organs; such
theories had the absurdity of a theory of food preparation that posits a
Cuisinart and a well-stocked refrigerator but no cook. General-
purpose "cognitive modules," such as a general mechanism for the
construction of gestalts, are plausible if their action is directed by other
cognitive modules, even in such a trivial fashion as that in which each
cognitive module may direct the gestalt-former to look for specific
types of factors as components of the gestalts. Chomsky is willing to
admit the possibility of general-purpose cognitive faculties to deal with
"domains in which the mind is equipped with no special structure to
deal with properties of the task situation." If we have cognitive faculties
that are not restricted to particular cognitive domains, I see no reason
why they would turn themselves off when language is being acquired.
I will conclude this commentary by taking up briefly Chomsky's
remarks on "psychological reality" and "psychological evidence."
Chomsky regards these terms as objectionable, in that they mislead-
ingly suggest that there is some special kind of reality that some
linguistic analyses have but others do not, and that there is a privileged
kind of evidence for linguistic analyses. For Chomsky, any theory or
grammar "carries a truth claim" and "in each case we have
evidence - good or bad, convincing or not - as to the truth of each of
the theories we are constructing"; "psychological evidence" does not
testify to any special sort of reality of the theory. This is fine, except
that in many cases it is unclear what truth claims, if any, are embodied
in particular analyses, or whether there is any sort of reality, psycholog-
ical or not, that those analyses purport to have. For example, it is not
clear what Chomsky and Halle (1968, pp. 233-4) are claiming when
they maintain that the word right has the underlying form /rixt/.
Chomsky and Halle indeed offer evidence in support of this conclusion,
but the observations that they cite count as evidence only by conven-
tion. Their ingenious argument for right = /rixt/ is based on a fact
about the pronunciation of righteous and is relevant to their conclusion
only under the assumption that the relationship between right and
righteous is such that the underlying form of the former must be a
constituent of the underlying form of the latter. Transformational
grammarians uncritically accept each other's judgements of related-
ness among words and share a policy of assigning common underlying
elements to related words. Chomsky and Halle's premises, as they
stand, tell us not about any English speaker's linguistic competence
but about what transformational grammarians are willing to let each
other get away with. Linguists, especially transformational grammar-
ians, frequently commit a sophisticated version of the error that
Chomsky castigates Searle for: that of taking the "intuitive plausibility"
of rules and structures as support for them, with the transformational
grammarian's intuition in place of that of the speaker of English.
Psychological evidence is essential if one is to know how to interpret
putative linguistic facts and whether to take them seriously.
THE BEHAVIORAL AND BRAIN SCIENCES (1980). 3
27

Commentary / Chomsky: Rules and representations
fcyJuliusM. Moravcsik
Department of Philosophy. Stanford University. Stanford, Calif. 94305
Chomsky's radical break with modern traditions
This target article, and the book from which it is extracted, represent
what is perhaps Chomsky's philosophically richest writing. Though
Chomsky's views have been discussed by social scientists and
philosophers for more than two decades, the central ideas have not
been adequately understood, and the opposition is often put forward
dogmatically, without much empirical support or conceptual argument.
In these brief remarks I shall attempt to show just how radical
Chomsky's departure is from key modern traditions, both in philosophy
and in the social sciences. Chomsky differs from philosophers and
scientists in that he argues for what I shall label a "deep" theory of
mind, while all other practitioners opt for what shall be labelled
"shallow" theories of mind. Chomsky differs from analytic philoso-
phers in his conception of the relationship between science and
philosophy. Finally, he differs from philosophers, since his main interest
lies in a theory of understanding, while analytic philosophy has been
preoccupied with problems of propositional knowledge and the analy-
sis of empirical evidential relations.
"Deep" and "shallow" theories. I shall label as "deep" (with-
out implying any depth in a normative sense) the theories that refer to
many layers of unobservables in their explanations, and I shall regard
even some of the fundamental facts to be accounted for as lying
beneath the level of observability. Such theories are guided by the
intuition that the observable appearances can be explained adequately
only by the examination of the underlying unobservable aspects of
nature. ("Nature does not wear its essence on its sleeves.") What I
label "shallow" theories are those that try to stick as close to the
observable as possible, aim mostly at correlations between observ-
ables, and posit something unobservable only when this seems
unavoidable - even then, such theories demand some direct relation-
ships between the observable and the unobservable.
Needless to say, the applications of this distinction depend on
historical context, and the dichotomy admits of plenty of borderline
cases and "matters-of-degree" judgments.
The history of the natural sciences like physics, chemistry, and
biology is a clear record of the success story of "deep" theories. The
more sophisticated and complex the underlying system of unob-
servables becomes in physics or chemistry, the more we seem to be
able to account for. In fact, even the application to the practical - i.e.
the rise of technology - was made possible only after the considerable
"deepening" of physics and chemistry. Earlier in this century the
positivists tried to establish rules that would relate the unobservable to
the observable in a legitimate scientific theory. It turned out, however,
that these rules could not be used to describe even such obviously
legitimate sciences as modern physics. Today, the effort has been
largely abandoned.
When we come to the social sciences, we encounter a strange
anomaly. For while there is a lot of talk about aiming to be "scientific,"
one finds in the social sciences a widespread and unargued-for
predilection for "shallow" theories of the mind; e.g., on both the
introspectionist and behaviourist account of the mind, its contents are
open to direct observation by the agent and - on the behaviourist
view - also by the investigator. There is a reluctance to refer to
unobservables, at least as far as complex mechanisms, obeying
abstract principles, are concerned. The one notable exception might
seem to be Freud; but even in his case, it is better to talk about the
positing of unobservable forces, rather than complex mechanisms with
clear mathematical structure.
In the face of this widespread agreement on the preferability of
"shallow" theories, Chomsky argues unhesitatingly for a "deep"
theory of the mind. His argument rests on the analogy between
theories of physics and the other successful sciences and what one
should try to accomplish in the social sciences. If "deep" theories have
been the successful ones in the natural sciences, why should one not
expect the same to hold for the social sciences?
Though on the modern scene, Chomsky is alone in advocating a
"deep" theory of the mind, it is worth pointing out that this approach
has its roots in classical Greek thought. In the Republic Plato raises the
question of how one should distinguish two allegedly different mental
capacities. His answer avoids saying anything about introspective or
behavioural data. He claims that an adequate answer must lie in
drawing careful distinctions between the respective objects of the
mental capacities. This view underlies his early version of innatism (the
so-called theory of recollection) and his view that deep self-knowledge
is possible only indirectly. We do not know directly the rational contents
of our minds; only cooperative investigation can unearth these in the
form of theories explaining the observed mental phenomena.
Given the unargued-for nature of the opposition to Chomsky, and of
the preference for "shallow" theories of mind, it is worth speculating
on the roots of this phenomenon.
Some of the roots are deep and are embedded in our religious and
moral heritage. Many of the tenets of the Judeo-Christian tradition
presuppose that a human can inspect directly the content of his or her
mind. For example, the doctrine of repentance and asking of forgive-
ness for sins seem to presuppose such strong forms of self-
knowledge. Again, the doctrine that intentions are what counts most in
the eye of God, and the assumption that what counts most is
something that we can have direct knowledge of, rest on the same
presupposition.
The same direct form of self-knowledge, and hence a "shallow"
theory of mind, underlies some of our moral practices. For example,
this seems to be assumed by the practice of demanding that someone
should promise to be a certain kind of person (faithful, etc.). How can
one know that one will keep such a promise unless one can inspect in
one's mind the relevant feelings and intentions?
Apart from these deep-rooted tacit assumptions in our culture, there
is a motive for "shallow" theories of mind that is more closely related
to one's view of the social sciences. Many social scientists think that
their fields will ultimately turn out to be "reducible" to discourse about
such material constituents as neurophysiological elements. Given this
assumption, a "shallow" theory recommends itself, since if we have
such theories - it is felt - the eventual "reduction" will be easier. Crude
materialist assumptions suggest that it is all right to have a rich set of
commitments to material elements, but that it is not all right to have
such posits in the case of the mental.
Once we unearth these sources of the prejudice for "shallow"
theories of the mind, we see how groundless they are. Given a "deep"
theory of mind, we might have to revise some of the specific ethical
practices that we embrace. But, in general, a "deep" theory of mind is
compatible both with religious and nonreligious views - with a deontic
view of morality or with alternative conceptions.
Similar considerations apply to the "materialist pull." A "deep"
theory of mind is neutral with regard to the materialist-dualist contro-
versy. Whether the abstract structures that Chomsky posits to explain
a variety of cognitive competences can be reduced to discourse about
"material" elements is an open, empirical question. But why should this
question attract so much attention from philosophers and social
scientists? The materialism-dualism controversy is vastly overrated in
importance. Many seem to think that the thesis that humans have a
soul, the thesis of immortality, or theses about the uniqueness of the
species and hence grounds for human dignity, rest on the outcome of
this debate. But the theses of there being a soul, there being
immortality, there being something unique about human rationality, are
all equally compatible with materialism or dualism.
Thus the resistence to "deep" theories of mind is more of a visceral
reaction than a well-argued stance. It is also responsible for the
resistance to Chomsky's "modular" view of the mind - i.e., his hypoth-
esis that different structures underlie such cognitive competences as
the mastery of a language, the ability to reason, and the capacity to
calculate. The basis for Chomsky's preference is the analogy with
biology. There we found fruitful the positing of different, highly specific
structures to explain a variety of biological functions. The resistance
seems to be based on the fact that if we have a "modular" view, then
we will probably be committed to a "deep" theory of mind as well.
Furthermore, it is felt at times that a uniform account of the mind is
more elegant than a pluralistic account. But mathematical elegance
may clash with biological feasibility. Biologically, it might be advanta-
28
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Commentary / Chomsky: Rules and representations
geous for the human mind to be a "mathematically messy" organ.
Chomsky and the analytic philosophers. Though the analytic
philosophers share the predilection of the social scientists for "shal-
low" theories of mind, they are divided from Chomsky also in two
further respects.
With the rise of specialization there came the demand to spell out
what the special domain of philosophy is. We need not go through the
many proposals that have been made. Quine (1960) has rejected the
distinction between analytic, conceptual, and empirical truths; he has
also maintained that philosophy and science form a continuum. The
latter deals more with issues closer to the observational level, while the
former deals with matters more removed from observation -
but the distinction, according to Quine, is one of degree. Chomsky
rejects, on the one hand, Quine's views on analyticity largely on the
ground that rule-structures must play important and distinct roles in
explaining cognitive competences. On the other hand, he agrees with
Quine on the philosophy-science continuum. Hence, he holds a posi-
tion different from that of all the main current schools.
In examining the structure of human cognitive competences,
Chomsky is concerned mainly with aspects of human understanding.
Modern philosophers have been preoccupied with analyses of what it
means to know a proposition to be true, and with the analysis of the
notion of viable empirical evidence. They leave questions about
understanding to the psychologist. Given Chomsky's philosophy-
science continuum view, one can see why he regards this as unsatis-
factory. He insists - rightly, it seems to me - that there are important
conceptual problems regarding notions like "understanding," "learn-
ing," "growth," "development," and so forth, and that the tools of
modern epistemology are not adequate for dealing with these.
Conclusion. In these brief remarks I have tried to show how deep
the differences are that separate Chomsky from the main trends in
current social science and analytic philosophy. I have also tried to
show that the opposition to his views rests, by and large, on unarticu-
lated assumptions that are very deeply rooted in our culture. One can
only hope that a better understanding of Chomsky's position, and the
nature of the opposition, will lead to a shifting of the level of dialogue,
to a more rational and better articulated plane.
by Adam Morton
Department of Philosophy, University of Bristol. Bristol BS8 IRJ, England
There are many modular theories of mind
Almost any sane psychological theory will account for behavior by
reference to internal mental structure. But to say this is to rule out only
the most naive tabula rasa empiricism or the most clumsy stimulus-
response behaviorism. In particular, it does not commit psychology to
a framework of discrete modular systems of concepts, whose interac-
tion produces behavior. Chomsky presents an argument that our
internal mental structure is indeed modular and that the mind has
organs in much the way that the body has; he in fact presents some
conjectures about what the modules may be. The argument consists
essentially of a restatement of his reasons for thinking that language is
based on such an autonomous conceptual system, and an imaginative
extrapolation to the more general situation.
There is no doubt, as I see it, that there may be such modules; the
idea is not incoherent. And there is now, after twenty years of
campaigning by Chomsky and his followers, a presumption in favor of
the idea that in language we have such a module. What Chomsky is
now trying to do is to develop these insights into a general account of
human capacity, of at least enough specificity to advise us what to look
for when approaching nonlinguistic skills.
Human capacity breaks down into language, the system of
concepts, sociality, musicality, and so on, apparently. But these
modules are not at all basic; linguistic competence surely breaks down
into phonetic competence, syntactic competence, semantic compe-
tence, at least. These things can clearly vary independently, though
just as clearly they can only function normally in combination. This is
typically the case, as we are discovering in cognitive psychology;
spatial ability, for example, almost certainly consists of a number of
distinct capacities, which might even occur in different degrees in
different populations (Jahoda 1979; Serpell 1979). Any recognizable
piece of behavior, or any skill as described common-sensically, will
result from the interaction of a number of more primary skills. It is now
unlikely, to the point of incredibility, that there should be, for example,
primitive arithmetic or musical skills. If there are absolutely primary
skills, their number must be very large and their characterization very
theoretical. (A little reflection on the systematic but paradoxical disrup-
tions of capacity produced by brain lesions will lead one in the same
direction; Wilkes 1980.) And if this is so, then the skills that underlie
distinct capacities may overlap. It seems likely that some syntactic
competence is put to use in arithmetic and musical skill; there is some
neurological evidence for this in the case of music.
What could one learn about the workings of the liver by studying the
workings of the heart? Very little. What could one learn about the
interaction of the respiratory and circulatory systems by studying the
interaction of the nervous and digestive systems? The problem is that,
to the extent that we think that the most profitable analysis of
something is in terms of autonomous modules, we must think that what
we learn from one module is unlikely to transfer in any easy way to
another. In what ways are nonlinguistic capacities likely to require a
treatment different from those involved in language? Some basic
features of the Chomskian analysis of language have much less force
when applied elsewhere. The underlying regularities may not be rules;
they may not even be manipulations of representations. They are even
less likely to involve the possession of implicit innate concepts. One
prepsychological reason for doubt on this score is the fact that
nonlinguistic skills typically come in degrees; there is not usually
something that one simply does or does not have.
These remarks are an exercise in the separation of possibilities.
Mental structure does not entail modularity; modularity does not entail
the presence of rules and representations. The fact that language is
both the best candidate for modularity and the best candidate for a
representational mental framework does not tell us much about the
nature of other skills. Chomsky gives rigorous arguments for
describing language in terms of rules and representations, and heuris-
tic arguments for modularity. But the two conclusions do not combine
in the way he wants; if anything, modularity tells against the promise of
language as a paradigm of human skill. I do not think that Chomsky has
given us what we need in order to imagine a physiology of mind - a
study of the interaction of essentially different mental components. To
say this is neither to suggest that such a thing may not be found nor to
deny the wish that someone find it.
by John Morton
MRC Applied Psychology Unit, Cambridge CB2 2EF, England
Language: levels of characterisation
The issue I would like to address is the separateness of what Chomsky
terms "abstract characterisation" on the one hand and "physical
mechanisms" on the other hand. The distinction is introduced early in
the article, when Chomsky is establishing that his use of terms like mind
and mental representation ". . .need in no sense imply the existence of
entities removed from the physical world." It is a sad commentary on
the quality of the current debate that this qualification has to be made,
since such a position is entirely natural for a cognitive psychologist.
The essence of the information-processing approach is to describe
cognitive function without regard to the substrate. To discuss the
"existence" of such functions would be as strange as talking about the
existence of a particular program in a computer. It is simply not an
issue. What is important is the way in which the functions described in-a
psychological model are implemented in the brain. But note that
without knowing what the psychological functions are, we cannot ask
how they are implemented.
Chomsky talks about our knowledge of language being represented
"in structures that we can hope to characterise abstractly, and in
principle quite concretely, in terms of physical mechanisms." It is not
quite clear, from this, what form we should expect the latter to take,
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
29

Commentary / Chomsky: Rules and representations
since shortly after, Chomsky continues "In the same way, a theory of
human vision may be formulated in concrete terms, referring, say, to
specific cells in the visual cortex and their properties."
There seem to be three possibilities here. The first is an account of
human vision where the basic units are physiological. In such an
account the stress would be on the responsiveness of single cells, their
interconnections and projections, and perhaps their structure. The
second possibility would talk about the implementation of the psycho-
logical formuation in neural terms. This would include phrases such as
"Function F is located in area A" or "It would be possible for function F
to be realised in neural terms in the following way. . . . " The third
possibility would be the reverse of the preceding one. That is, it would
take a neural unit and describe its role in psychological terms. A typical
statement in such an account would be "Area A is involved in functions
F, G, and H." The extent to which these three possibilities overlap, with
respect to what counts as data, seems to depend critically on the
extent to which the psychological functions are localised. It seems
possible that some simple visual functions might be localised, but it
appears to be unlikely that any useful localisation of language function
exists (Zangwill 1978). For language function, then, the accounts are
likely to be distinct. In any case, a proper psychological theory is
insulated from such considerations, since its justification will be, in
Chomsky's words, "by success in providing insight and explanation."
One might note here that the use of behavioural data from brain-
damaged patients does not of itself constitute a bridging of the gap
between the levels. Thus I am aware of no work in which knowledge of
the location of a lesion has played a role in the evolution of a
psychological theory. For example, Bradley et al. (1979) compare data
from normals and agrammatic patients and conclude that there is a
separate lexicon for function words. They also postulate that this
lexicon is in the left hemisphere. However, none of their strictly
psychological arguments would be affected if it in fact turned out to be
in the right foot.
It should be clear that the separation of levels I am discussing is
neutral with respect to Chomsky's claim that linguistics is a part of
psychology. If we are to accept this, then it should follow that
psychologists should be able to provide evidence to decide among
linguistic theories. It would be interesting to discover what such
evidence might look like. Previous attempts seem not to have been too
successful, and one recent move to support the claims of a particular
grammar (Bresnan 1978) seems to me to have mistaken a computa-
tional device (A.T.N.'s) for a psychological model [see Arbib and
Caplan: BBS 2(4) 1979]. Of course, if linguistics is actually more
abstract than psychology, and is better to be considered at a different
level, then neither can produce evidence crucial for the other, any more
than physiology can decide between psychological models or vice
versa. The proper questions would then be of the form "which
psychological functions are responsible for linguistic function L?" We
will discover, of course, that not only will linguists disagree as to the
nature of the relationship between linguistics and psychology, but also,
the kind of theory they produce will differ. The mode of interaction of
psychology and linguistics, then, would depend crucially upon the level
of abstractness of the particular linguistic theory being considered.
by Howard Rachlin
Department of Psychology, Stete University ot New York, Stony Brook, NY. It 794
Cross purposes
With a little semantic revision ("instinctive behavioral patterns" instead
of "mind" for instance), Chomsky's brief discussion of learning of
grammar (p. 13) might have come from Staddon and Simmelhag's
(1971) behavioristic discussion of "learning" and evolution. But the
parallelism is illusory. Prior to this discussion, one encounters Chom-
sky's response to those critics who have claimed that his grammar
"has no psychological reality." Chomsky says that he never meant to
distinguish "psychological reality" from what constitutes good linguis-
tics in the first place. A behaviorist would also deny the distinction. A
grammar, to a behaviorist, is a theory of behavior. But for the
behaviorist the grammar is the theory of the linguist. For Chomsky, the
grammar is not only the theory of the linguist, it is also represented, as
an organ, called a "mental organ" but real, like the heart, lungs, liver,
eyes, held captive inside the speaker. This assumption (the physiologi-
cal justification of which is claimed to be far in the future) is what
behaviorists are likely to find unacceptable. Chomsky seems to feel
that the facts call for an extreme degree of nativism with regard to
language, and that nativism, in turn, requires the concept that the
language faculty is a "mental organ." A psychologist, even a nativist,
even a cognitivist (let alone a behaviorist) would begin with different
assumptions.
At first I suspected that "mental organ" was meant to be a collective
name for the areas of the brain known to be necessary for the control
of speaking and understanding speech. But Chomsky seems to feel
that these areas contain something beyond what (little) we know about
them. The language "organ," as Chomsky describes it, seems
intended to embody inside the organism, in concrete form, whatever is
important in language, structurally and functionally. Why is it necessary
to (so to speak) hold a behavioral function hostage in the human
body? Where does this get us? Do we need to fear that this imprisoned
function (in the case of language) will escape and lodge itself in a
dolphin or a chimp or even, God forbid, a pigeon? Our bodies
themselves are organized in a symmetric way and presumably have
evolved that way. Do we then have to have an "organ of symmetry"
inside us to explain the way our bodies are? |See Corballis & Morgan:
BBS 1(2) 1978.1
If not, then it cannot be the innateness of language that prompts the
postulation of an organ for it; nor can it be the fact that language has a
complex organization. These things language shares (or might well
share) with walking, bicycle riding, genuflecting, and many other
functions. To understand better what Chomsky is driving at, I tried to
imagine some behavior that people might agree has a large innate
component where (unlike the various manifestations of language) there
is clearly little variation among cultures. Perhaps, walking will do as an
example. (There are those who would argue that the common nature
of walking is due to common shaping of the environment and common
reinforcement for locomotion, but let us ignore such arguments and
agree that walking is a largely innate behavior.) There could be
constructed a grammar of walking, perhaps not as complicated as
grammars of speaking but complicated enough. Certainly each
instance of walking is different in some respects from all others;
elements can be replaced by other elements; limps, skips, hops, struts,
and other variations have their own regularities yet fit within a general
pattern. A given environmental demand (say a low wall) brings forth
unique solutions that yet fit within the "grammar." A mime might
construct syntacticly correct walking without semantic content (without
getting anywhere) corresponding to similar constructions (jabber-
wocky) of language. Although, to my knowledge, there are no written
grammars of walking, there is no reason I can think of why the job, in
principle, cannot be done. In addition, in the brain there are structures
that, if damaged, will impair walking.
Granting all this, the facts still do not compel the postulation of a
physiological "module" that contains somehow all that is or can be
important about walking. Perhaps the reason Chomsky proposes such
an all-inclusive organ for speech is what he calls "the impoverished
environment." This phrase is repeated several times but remains
unexplained. Impoverished with respect to what? In what way is the
stimulus poor? And how is such an "impoverished" stimulus supposed
to "fine-tune" behavior (Chomsky refers to all behavioral shaping such
as that which causes differences between Persian and English as
"fine-tuning")? The stimulus in question is other people talking and
acting. Except perhaps in the case of a poet or linguistic stylist, our
linguistic environment seems at least as complicated as our linguistic
behavior. Certainly all children (and adults probably) hear or see more
sentences than they speak. If by "poverty" is meant merely the fact
that I speak certain particular sentences that I have not heard, then that
is also true generally in my behavior. I might whistle nondissonant
melodies that I have not heard, or build a house different from any I've
seen, or put on my pants in the morning in a new way, or (to cite a
social action like language) relate to a friend in a unique way; all of
these conform to the rules governing these behaviors, but not to any
30
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Commentary / Chomsky: Rules and representations
specific instance I've seen or heard before. Does this mean that my
environment is impoverished? And even if this new (and utterly useless)
definition is given to the word "impoverished," does it mean that there
is an organ inside me corresponding to these activities? No, it does
not. If a stone obeys the law of gravity, will we find the law of gravity
"encoded" somewhere inside the stone when we break it open? (The
best argument I have seen against such physiological mythologizing
comes from Fodor (1975), who in other respects seems to be in
Chomsky's hemisphere.)
The postulation of an organ for language in this literal way leads to
all sorts of difficulties. "Philosophical" questions that, since Wittgen-
stein, have been answered by psychologists with "Who gives a
damn?" are dredged up again. "May a man know English while he is
sleeping?" is one we are asked to consider. Well that, of course,
depends on what you mean by "knowing English." If we find it useful
(as we do) to say of a person who intermittently speaks English that he
"knows English," then a person who is sleeping may know English. If a
person speaks English at time A and it is now time B (say, one hour
later), we may want to say provisionally that he knows English, and that
if and when he comes to speak English again, he will have "known
English" in the interim. And that if he dies right now, we will never know
for sure (and never care) whether he could speak English at the very
time of his death. What is more (or less) mysterious in this respect
about "knowing English" than "knowing how to dance?" unless, with
Chomsky, one arbitrarily permits an organ inside to play music for one
and bans such music for the other?
There are other difficulties: Chomsky says, "Two people might
share exactly the same knowledge but differ greatly in their capacity to
use it." Here he takes what is essentially a temporal difference and
makes it into a structural (really, in the absence of physiological
content, a spiritual) difference. Knowledge of English obviously
involves use of English over an extended time period, whereas
impaired capacity to use English involves disability over a smaller time
period. To identify such dispositions with structures, like personification
of the deity, may serve a psychological purpose but not a logical one.
Similarly, we have the child knowing English grammar but speaking
through a "filter" that passes only content words. Where is this filter? Is
it outside the child? If not, then do we have another child inside the first
child speaking through the filter located in the outer but not the inner
child? This terminological swamp is where we arrive by identifying
behavior with organs of the body.
As far as actual data cited in Chomsky's target article are
concerned, one would have hoped that, after twenty years of research,
some could be cited instead of the catalog of possible future experi-
ments (p. 6) and coy references to "not entirely fanciful" data.
On the basis of these not-entirely-fanciful and presumably not-
entirely-real findings, a "theory of the mind" is proposed. And, given
their lack of observational content, organs of the mind may be juggled
at will. Perhaps in a "fuller theory of the mind" there is a mental organ
for "computation" and one for "conception." Why not? And a really
full theory of the mind will undoubtedly include organs for all behavioral
dispositions from amativeness (Gall's first area) to awe (his thirty-
eighth). And why should they not interact with each other? From this
point on, any scenario is possible. Of course, "mere" behavior tells us
"little or nothing" (p. 6, p. 11) about these scenarios; they are entirely
divorced from behavior, entirely hidden. Where would one begin to do
empirical work on mental states about which behavior is said to be
irrelevant?
And so on. To Chomsky there is no comparing of speaking to
bicycle-riding, because language has cognitive rules whereas bicycle-
riding is merely a "skill." But the point of the comparison is that there is
no more evidence for the existence wholly inside the speaker of
cognitive rules for speaking than there is evidence for the existence
wholly inside the bicycle rider of cognitive rules for bicycle-riding.
Chomsky does not deal with this point. He just denies it.
Why such lack of contact? Why such contempt for the other side?
("mere behavior . . . " "It is a sad commentary on the field . . .," ". . .
there is really nothing to discuss.") It is more than "structuralism" vs.
"functionalism." Perhaps the difference comes down to one's objec-
tive in the complicated network of observation and inference that must
constitute any theory of the mind; the behaviorist views inference as
useful only in going from observation to observation, whereas
Chomsky seems to view observation as useful only (if at all) in going
from inference to inference.
by Bernard E. Rollin
Department of Philosophy. Department of Physiology and Biophysics, Colorado
State University, Fort Collins, Colo. 80523
Innate and a priori
In the course of his innovative discussion, Professor Chomsky seems
to suggest that, in addition to providing a basis for a new and fruitful
approach to empirical psychological research, he is solving, dissolving,
or recasting some traditional problems of knowledge and metaphysics.
For example, it appears that Chomsky is suggesting that the traditional
dispute between empiricism and rationalism, arguing whether there is
any knowledge that is a priori and synthetic, (i.e., that tells us about the
world but is not grounded in experience), is resolved by the empirical
results of his linguistic theory.
What Chomsky has shown, persuasively in the case of language, is
that there is a set of rules, presumably genetically determined and thus
innate, that determine our knowledge or "cognition" of language, and
that can empirically be shown to be universal (i.e. to hold across all
known languages). His arguments from the poverty and diversity of the
stimulus, and from our ability to generate an infinite number of
sentences, are certainly plausible, and his claims about the universality
of these rules across human languages is empirically testable. His
theory does suggest various lines of empirical research that have been
and will continue to be fruitful in understanding human language. Thus
far, we may admit that Chomsky has given us empirical evidence for
the claim that knowledge of language is, in his sense, innate and in
traditional terminology also synthetic - i.e. informative about some
aspect of reality.
He further suggests that other cognitive systems - mathematics, or
our concepts of physical objects - may also be innate, and he asserts
that they might be fruitfully studied along the same lines as language. It
is not clear, however, that Chomsky has given us reason to believe that
the innateness hypothesis is true of these other systems - he has
presented neither empirical nor conceptual reasons for supposing that
what is true of language is true of other faculties. The argument from
poverty of the stimulus, for example, is simply not persuasive when
applied to our knowledge that a typewriter won't fly - simplicity seems
to dictate that we can explain this strictly empirically. Nor does there
seem to be an analogue to the claim about language that empiricism
cannot explain an ability to make infinite use of finite means, or
generate new types of sentences, and so on. It is also difficult to
imagine any empirical research that could test the innateness hypothe-
sis with regard to our knowledge of physical objects, since we
experience the properties of objects as soon as we begin to experi-
ence. There exist plausible accounts of the development of our
knowledge of objects that do not require that we postulate innate
structures. Language is clearly a rule-governed activity, and so it is
plausible to inquire after the sources of the rules. On the other hand,
our knowledge of objects does not appear to be rule-governed in the
way language is; there is no obvious "grammar of objects," so the
burden of proof is on one who hopes to treat them analogously.
It is worth recalling, as I have shown elsewhere (Rollin 1971; 1976;
1978), that innateness by itself poses no necessary threat to the basic
tenets of the epistemology of traditional empiricism - it is a priori
synthetic truths rather than innate ideas that are anathema. But, in
addition to the innateness hypothesis, there seems also to be in
Chomsky's argument a metaphysical/epistemological claim, to the
effect that it is by way of innate structures that we must experience or
know the world; tfiat they are constitutive of experience in a given
dimension and thus cannot be grounded in experience, and as such
cannot sensibly be said to be refutable by experience. Thus experi-
ence depends on them, rather than their depending on experience,
and so his claim seems to make them a priori and synthetic in Kant's
sense, as well as innate. But Chomsky's a priori synthetic is markedly
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
31

Commentary / Chomsky: Rules and representations
different from Kant's, in that while Kant claims that the same a priori
synthetic categories he deduces can be shown transcendentally to be
necessary for any being with an ectypal intellect (i.e., any being at all
who gets his cognitive material from "outside" himself, and must
synthesize it), Chomsky has no such argument for the universality and
necessity of his "categories" or rules.
If we take Chomsky's clearest example, knowledge of language, it
seems to be merely a contingent, biological fact, rather than a logical
requirement, that this is the shape language must take! There is no
reason given that shows that language could not appear in some other
form. There is no reason to believe that there could not be creatures,
even humans, with other innate structuring principles, perhaps also
biologically developed as necessary or accidental results of selective
evolutionary pressures. For that matter, one can imagine some new
radiation in the atmosphere that would cause changes in the brain and
would change one or more of the rules and our knowledge of the rules.
Indeed, Chomsky gives no reason why all the citizens of the world
could not get together and simply decide to change one of the rules, by
fiat. All of this shows that while the rules may be innate and synthetic,
they are not a priori in any traditional sense and thus do not shed light
on the traditional philosophical problems associated with this concept.
Chomsky might respond by asserting that any change in the rules
would result in something that would not be language. But this would
seem to be quite implausible, especially if one could translate across
the two differently rule-governed sign-systems. If it is suggested that it
is a priori impossible to effect translation, Chomsky is left with his own
version of a well-known difficulty: Even if we can prove in various ways
that basic rules governing our knowledge of language are innate, this
does not mean that they are cross-culturally similar in all existing
cultures, let alone all possible cultures. It may be that while these
sign-systems always require innate principles, different ones might
have different principles, as remarked above. But if there were the
case, it is difficult to see how we could know this, since ex hypothesi
the two "languages," ours and theirs, are incommensurable. We could
not understand other systems, except as filtered through our own.
(There are, of course, those who suggest that different cultures do
have different cognitive apparatuses. This is not a priori impossible.
Like major physical and social differences, these could be biologically
based. Would it then be possible for us to explain them in Chomskyan
terms?) What we have just said of language applies mutatis mutandis
to any other cognitive system allegedly based on innate principles: for
example, to Chomsky's claim about our knowledge of objects.
I have argued, in essence, that any knowledge based on biologically
determined rules, even though those rules are innate, will be contingent
- empirically changeable, or refutable. This leads us to a further
difficulty in Chomsky's argument. Let us suppose that our knowledge
of mathematics or logic is determined, in part, by innate knowledge of
rules. (Since these areas are clearly rule-governed, this seems more
plausible than the idea that our knowledge of objects is so based.)
These rules, as we have just seen, are subject to change on the basis
of evolution, or as a result of radiation, chemicals, and so on. Would it
then follow that what we now call our knowledge of mathematics and
logic would change, or worse, be rendered false by empirically caused
changes in the brain and correlative^ in the innate rules? It is difficult to
see how Chomsky can avoid this conclusion, yet it is also difficult to
see how any distinction between a priori and a posteriori knowledge
can be sustained if all cognition is based on biologically determined
innate principles that are subject to change. If Chomsky is not
disturbed by the prospect of destroying this distinction, once again the
burden of proof is on him to give reasons as to why we should not mark
such apparently major differences.
On the other hand, I grant that the sense in which the innate rules he
postulates are empirical or a posteriori, or better, contingent, is an
unusual one, since they are presuppositional for our current experi-
ence. Clearly, if Chomsky is right about the role of these rules in the
knowledge of objects, for example, the sorts of changes I envisioned
that could take place in the rules are not much like finding the
proverbial white raven. If the rule changes were drastic enough (or
perhaps if there were any changes at all), our entire way of experienc-
ing the world would change - we would literally live in a world totally
different in fundamental ways from the old one - and it is conceivable
that the old world would no longer even be comprehensible to us. I
believe that Chomsky would assert that our traditional distinction
between a priori and a posteriori requires further refinement to do
justice to such dramatic cases, although I am uncertain as to what form
this reworking would take. As suggested above, he may in the final
analysis wish to eliminate any hard and fast notion of a priori altogeth-
er, and have nothing stronger than a concept of what is currently
presuppositional on the basis of our mental makeup. Again, this is
prima facie implausible when applied to mathematics and logic.
In sum, I consider Chomsky's analysis viewed as a program and
theoretical basis for psychological research to be a salubrious coun-
terforce to the atheoretical, haphazard dabblings that characterize
much of behavioral psychology. I should like to see more discussion of
the analogy between knowledge of language and knowledge of
objects, as well as a sketch of what empirical research would be like in
domains like knowledge of objects or knowledge of mathematics. I
should further like to see Chomsky extend his program to animal
psychology as well, since his arguments from poverty and diversity of
stimuli and uniformity of result apply to the mental lives of animals as
well as men. Indeed, prima facie at least, it appears that the evidence
tor innate principles in animals' minds is even stronger, since animal
minds obviously develop uniformly within species despite vast environ-
mental and experiential differences - there is here no cultural overlay
to mask the similarities. The possibility for intra- and interspecies
communication would be a natural target of study, for example [see
BBS 1(4) 1978]. On the other hand, I do not think that the implications
of Chomsky's analysis for traditional metaphysics and epistemology
are quite as dramatic as they may appear to be at first blush.
Ackno wledgmen ts
I have benefitted from discussions with Professors Kenneth Freeman and Ron
Williams.
by David M. Rosenthal
Department of Philosophy, Graduate School and University Center, City University
of New York, New York, N.Y. 10038
The modularity and maturation of cognitive capacities
The two central themes in Chomsky's discussion that I want to
consider are his hypothesis that "the mind [is] modular in structure,"
and his inviting idea that we acquire much of our knowledge in a way
more like ordinary biological growth and development than like learn-
ing, as learning has traditionally been conceived. In section I, Chomsky
notes that the question of modularity is distinct from the issue of
whether the mind has rich initial structures. But he also claims there
that "there is a relation between the views, in part conceptual," for the
assumption of modularity "leads to the natural conclusion that [the
various] systems [of mind] are intrinsically determined." He does not,
however, offer support for the converse connection and, indeed, notes
that "|o|ne might hold that there is rich innate structure but little or no
modularity."
It may not seem immediately clear, however, why Chomsky believes
that, by itself, the hypothesis of modularity has any bearing at all on
whether there are rich initial structures. Nor is it clear just how strong he
takes the relationship between the two hypotheses to be. In some
passages he seems to mean nothing more than that "opinions (about
the hypotheses! cluster. Those who tend toward the assumption of
modularity also tend to assume rich innate structure." It does seem
clear that our mature mental capacities, and the mature structures we
can assume underlie those capacities, reflect diverse families of
principles. If one took modularity to consist in this relatively uncontro-
versial observation, and if that observation somehow made plausible
the idea of rich initial structures, then perhaps innateness would inherit
some of the uncontroversial and common-sense character of modular-
ity. But the clustering of these two views, so understood, does not
actually occur. Many would agree that our mental structures, when fully
developed, reflect divergent principles without being at all inclined to
endorse the idea of rich initial structures.
But at other points Chomsky writes as if modularity is a substantially
32
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Commentary / Chomsky: Rules and representations
stronger thesis, which actually entails the assumption of rich initial
structures. For example, at the outset of section III he claims that "|i]f
the modular approach is incorrect," the study of interacting mental
systems would "reveal . . . that these systems involve the same
principles and develop in the same way from a common basis." And
early in section II, having offered as an example of modularity the
distinction between the computational and conceptual aspects of
language, he goes on to urge that it might be possible "to distinguish
these systems much as we distinguish the visual and circulatory
system." This analogy between bodily organic systems and the
modularity of mental structures is repeated often (e.g., eight para-
graphs later and throughout the second half of section I), and it
reinforces the impression that such modularity is a matter not only of
the diversity of mature capacities but also of their genetically controlled
development from diverse initial structures.
Perhaps this seems clearest in a passage that comes directly after
Chomsky has distinguished modularity from rich initial structures in
section I. For he writes that "we are . . . led to the conclusion that
intrinsic structure is rich (by the argument from poverty of the stimulus)
and diverse (by virtue of the apparent diversity in fundamental princi-
ples of capacities and mental structures attained)." Here as else-
where, Chomsky evidently uses "intrinsic" in a way that implies
innateness; for richness of "intrinsic structures" amounts to the
richness of initial structures. But then it is these initial structures that, on
the thesis of modularity, are said to be diverse; the "diversity in
fundamental principles of capacities and mental structures attained" is
offered as evidence for the diversity of rich initial structures. So it is not
simply that "opinions |about modularity and rich initial structures]
cluster"; modularity actually includes the assumption of rich initial
structures.
The foregoing quotation also calls attention to a striking pattern of
inference that recurs in Chomsky's discussion - namely, the passage
from "diversity in fundamental principles of capacities and mental
structures attained" to some corresponding diversity in initial and
innate mental structures. It is possible, of course, that fundamental
principles of our mature mental structures could illuminate features of
the initial structures from which mature structures develop. And
perhaps with language this is the case. For one might take the
presence of highly abstract but strong constraints, to which the
otherwise divergent grammars of all human languages seem to
conform, as being evidence of common features in the relevant initial
structures. And Chomsky is surely right that, insofar as we currently
understand these constraints, "|i|t would be surprising indeed if we
were to find that the principles governing these phenomena are
operative in other cognitive systems."
But the inference from the principles governing mature mental
capacities and structures to those governing initial mental structures is
far less credible in the case of the other "mental faculties" that
Chomsky touches on, such as "knowledge of... music, of mathemat-
ics, of the behavior of objects, of social structure, of human character-
istics, and so on." In the case of music, there is a great diversity of
musical systems, which might seem to echo the diversity of human
languages. But here the common features in these diverse systems
appear to derive from well-understood apects of the mechanisms
underlying the production of sound, rather than from anything innate in
the organism. And the presence of features common to otherwise
significantly diverse systems is wholly absent in the case of mathemat-
ics, though according to Chomsky "it seems reasonable to suppose
that [the number] faculty is an intrinsic component of the human mind."
Chomsky's brief treatment of the "number faculty" merits special
attention. For he claims that "|t]he capacity to deal with the number
system . . . is surely unlearned in its essentials." If Chomsky has in
mind, here, either the "second-order sense of 'capacity' " that he
isolates at the outset or the sense of "capacity" as a mental faculty,
his claim that our capacity to deal with the number system is unlearned
will be trivial and uninformative; for it is a matter of meaning that, in
these senses, capacities are unlearned. So Chomsky must have in
mind the more interesting but surprising claim that our mature capacity
to deal with the number system, though in many respects the product
of training, is, "in its essentials," innate. Without some idea of what the
"essentials" of this capacity are, however, even this claim would lack
significant import. But Chomsky tells us that "|t]he very essence of the
number system is the concept of adding one, indefinitely," presumably
inviting us to infer from the "very essence of the number system" to an
understanding of what the "capacity to deal with the number system
. . . (is] in its essentials." Chomsky is of course right that "the concept
of adding one, indefinitely" is sufficient to distinguish our number
system from the rudimentary numerical abilities of other terrestrial
species. But it is far from clear that understanding the essence of our
number system can, by itself, help us to understand our capacity to
deal with that system.
Chomsky would presumably agree that the essence of our number
system, for example, cannot by itself reveal details of specific mecha-
nisms that underlie the relevant capacity and mental structure. But he
would insist that the essence of our number system does serve to
characterize that structure at the appropriate level of abstraction. As
he puts it at the outset of section III, his discussion "proceeds as an
inquiry at a certain level of abstraction into the nature of certain
mechanisms . . . . now largely unknown. The level of abstraction is
appropriate insofar as it enables fundamental properties of |cognitive|
systems to be isolated, analyzed, and explained; and insofar as results
obtained at this level provide a guide for the study of mechanisms." An
accurate and revealing description of a subject matter with which
mature humans can deal is, of course, useful and perhaps ultimately
necessary for a satisfactory study of the human capacity to'deal with
that subject matter. But that is because such a description defines the
problem under investigation. Such a description does not, as Chomsky
makes it appear, constitute the beginning of an actual theory about the
nature of the target capacity, even "at a certain level of abstraction."
Chomsky believes that such descriptions can "provide a guide for
the study of [underlying] mechanisms, much as the study of chemical
properties provides a guide for inquiry into atomic theory" {ibid).
Presumably the intended analogy is that, just as atomic processes
must be able to give rise to chemical properties, so neural mechanisms
must be able to generate and deal with the number system. This
naturalism with respect to mental phenomena is thoroughly laudable.
But the usefulness of chemical properties in studying atomic structures
depends on our having some active grasp of atomic mechanisms. One
could not have predicted how these mechanisms would turn out to be
able to achieve their effects at the level of chemistry merely by knowing
how those effects can be systematized, at their own distinctive level.
Indeed, some fair success at the level of atomic theory seems to have
been necessary before we could arrive at an accurate and revealing
systematization of chemical phenomena. And in general, the ways of
systematizing phenomena at higher levels of organization have often
proved to be false guides to the nature of phenomena at underlying,
lower levels of organization. Moreover, since the mechanisms that
produce effects at higher levels of organization are largely unpredict-
able on the basis simply of a knowledge of those effects, the idea of
higher and lower "levels of abstraction" seems straightforwardly
inapplicable in this context. For it is not as though we could arrive at
descriptions at higher levels of organization by way of some process of
abstraction. And it is even less credible that we might arrive at
acceptable descriptions of our mathematical or musical systems by
abstracting from innate mental structures or from their underlying
neural mechanisms. So, although more abstract descriptions often do
illuminate concrete details, this process cannot be expected to help in
the present context. It is these concerns, and not some antinaturalist
attitude towards the mental, that are responsible for the worry that
Chomsky's theories may well lack psychological reality.
The worry about psychological reality also arises in connection with
the question of whether Chomsky's approach can capture, in a
non-question-begging way, the distinction he appeals to in section III
between having knowledge and having a skill. The example he offers
of two missiles does not help here. For we know that the "cognizing"
missile "incorporates an explicit theory" simply because it was so
constructed. What we need is some clear idea of how to tell when a
system of mechanisms incorporates rules and representations which
does not simply reduce to the question of whether the system can be
described as if it did. Chomsky supposes that in many cases "there is
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
33

Commentary / Chomsky: Rules and representations
a mentally-represented system of |a grammar-like] nature, which can
be taken to be an object of knowledge." But he suggests no clear way
of trying to decide whether what we have is merely a set of
mechanisms that act as if they embody rules and representations, or a
set of mechanisms that actually does.
Even when modularity is understood as a thesis about the divergent
principles of initial as well as mature mental structures, modularity and
the hypothesis of rich initial structures do not jointly imply Chomsky's
striking speculation that "a central part of what we call 'learning' " is
essentially a matter of biological growth and development. Nor is it
obvious that the hypotheses of modularity and rich initial structures
would, if true, even provide evidence for this bold thesis about learning.
Even if our acquisition of knowledge depends in some way on initial
mental structures that are both rich and diverse, such acquisition might
nonetheless be more like a process of imitation and adaptation, for
example, than like the maturation of a bodily organ. And slight
differences in initial structures could lead to great diversity in mature
structures whether the fundamental mechanisms involve interactions
with the environment or internally-controlled processes. The idea that
acquisition of knowledge is basically a matter of biological maturation
does of course imply modularity and rich initial structures. But the
converse does not hold; the idea of learning as growth is a further step
in the analogy of our cognitive capacities with physiological systems.
However, this view about the acquisition of knowledge does fit well with
the idea that systematizing the objects of our knowledge is likely to
shed light on the nature of the operative mental capacities and
structures. For, if "a central part" of our knowledge develops in the
manner of genetically-determined maturation, it is then reasonable to
expect that the character of our ultimate objects of knowledge will be
informative about initial mental structures. And if one were convinced
that the ultimate objects of knowledge would be revealing in this way.
the model of genetically-guided development would very probably
seem appealing.
If "a central part" of our acquisition of knowledge is essentially a
matter of biological maturation, the relevant genetic instruction will then
determine to some degree what it is possible for us to know. Chomsky
does not shrink from this consequence, writing at the close of section I
that "the very same intrinsic factors that permit [cognitive] achieve-
ments also impose severe limits on the states that can be attained."
Chomsky's frequent references to biological determinants of our
perceptual cognitive capacities lend some support to this idea. For it is
obvious that the range and character of our perceptual knowledge is a
function of our organic perceptual apparatus.
But Chomsky also holds that much of our nonperceptual knowledge
is acquired by a process essentially like biological maturation, though
often it remains unclear whether, in a particular passage, he is simply
asserting modularity of initial structures or also affirming the idea of
learning as growth. But he does suppose that "|i|t is entirely possible
that significant components of |many| cognitive states are 'wired in,' "
and his examples of this (e.g., at the end of section III) range well
beyond perceptual knowledge. Chomsky's formulations of this idea
tend always to involve phrases such as "significant components," "a
central part," "in its essentials," "substantially in place," and the like;
this results in some measure of obscurity about just what this idea
involves. Presumably he would urge, as he does in a related context,
that we are dealing with "a difficult empirical question, only partially
clear, which can become more precise only in the course of finding
some answers to it."
However the issues are sharpened, Chomsky's idea "that significant
components of [many nonperceptual] cognitive states are 'wired in1 "
will require that what propositional knowledge we can have is, to some
degree, a function of our biological endowment. And an apparent
consequence of this view is that cognitive beings with suitably diverse
biological endowments will diverge in what propositional knowledge
they can have and, hence, would have to differ even in the range of
propositions they could comprehend. If this were so, it would be
possible for organisms to exist whose cognitive capacities were
comparable to ours in richness and range, but with whom communica-
tion would be severely obstructed because of differences between
them and us with respect to what propositional content can coherently
enter into speech and thought. And it would perhaps also be possible
for organisms to exist who could comprehend all our thoughts but think
things literally unthinkable by us. This striking idea, though it appeals to
biological rather than divine determinants, is reminiscent of Descartes'
vexed view about the nature of the eternal truths, according to which it
is a contingent fact about our minds that we "cannot conceive a
mountain without a valley, or an aggregate of one and two which is not
three" (Kenny, p. 236; see Frankfurt, especially section VI, for a highly
illuminating discussion).
Many, however, would contest the very intelligibility of this difficult
thesis, arguing that one respect in which propositional cognitive
capacities differ from perceptual cognitive capacities is that, given time
to define terms and explain theories, a certain threshold intelligence is
all that is needed to comprehend any proposition whatever. Perhaps
progress could be made in giving some measure of intelligibility to the
idea that biological endowment can cause variation in what proposi-
tions are thinkable. But cognate views, such as the idea that different
human languages might embody distinct conceptual schemes, or the
idea that children may have something like distinct conceptual
schemes at successive stages of cognitive development, have been
notoriously unyielding in the face of efforts to confirm them, or even
give them clear content. Much of the difficulty in giving content to such
views results from the complex interactions that hold between meaning
and belief, which Chomsky touches on midway through section II,
though perhaps some nonarbitrary ways can be found to sort out these
factors.
Whatever the case on these questions, it seems clear that, if
essential aspects of our propositional knowledge have biological
determinants in some nonvacuous respect, other cognitive beings
could diverge from us in respect of what propositional content could
enter their mental lives. The difficulty of making clear sense of that
possibility, therefore, should make us cautious about whether clear
sense can be given to Chomsky's idea of learning as growth. One
might maintain, of course, that if such divergence were a genuine
possibility, our difficulty in comprehending that possibility might simply
be the result of biologically determined limits on our knowledge. But
there is no reason to suppose that these limits would be responsible
for this particular case of our being unable to comprehend something;
for one would expect some things to be incomprehensible no matter
what one's cognitive capacities, and such divergence might be a case
of this sort. Such self-supporting defenses aside, therefore, the appar-
ent incomprehensibility of this sort of divergence in the ability to
entertain propositions gives us compelling reason to seek an alterna-
tive to any theory of the acquisition of knowledge that has this
consequence.
by Geoffrey Sampson
Department of Linguistics. University of Lancaster, Lancaster LAI 4YT, England
Chomsky's evidence against Chomsky's theory
Contrary to Chomsky's claims, there is good reason to argue that "the
brain is unique in the biological world," in that its complex products are
determined hardly at all by fixed mechanisms but emerge as attempts
to make sense of experience in ways unpredictable on the basis of
initial state. Furthermore, it is Chomsky himself who has drawn
attention to the evidence for this view in various of his works on
language, even though he interprets his evidence in a very different
way.
34
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Commentary / Chomsky: Rules and representations
Some of those who have discussed Chomsky's writings over the
years have taken the issue as one to be settled by pure philosophical
analysis. Chomsky himself, in this piece as elsewhere, insists that the
question is an empirical one. He argues that the evidence overwhelm-
ingly favours his view that complex products of human minds, such as
- most obviously - language, are determined in advance by genetic
inheritance in much the same sense as that in which the structure of the
eye, say, is predetermined; by presenting the question as one to be
settled empirically, he implicitly concedes that the view he opposes is in
no way logically incoherent or objectionable - it just turns out
(Chomsky claims) not to fit the facts.
Let us therefore reconstruct this alternative, non-nativist account of
how an individual might acquire his first language. So far as I can see, if
we assume that the individual begins life with no inherited "knowledge"
(or "cognizance") of language (and I shall not pursue the purely
conceptual discussion of how it is legitimate to use the word "know" -
I concede all that material to Chomsky for the sake of argument), then
the most plausible account of language-acquisition will be one in
harmony with the evolutionary epistemology of Sir Karl Popper: we
must envisage the child formulating small-scale, fallible hypotheses in
reaction to (but not predictable from) the experience impinging on him;
many of these hypotheses will be weeded out as incompatible with
further experience, but some will be retained; these will be built on in
formulating higher-level, more general, but still fallible hypotheses, and
so on. If we assume that initial state does not determine the details of
the mental construct that eventually emerges, then we must presum-
ably say that the hypotheses are invented creatively rather than being
drawn from a range predetermined by the machinery of mind. Of
course, there are conceptual problems with this account (e.g., what is
it to "formulate a hypothesis" when one does not yet speak any
language?); I believe these objections can be satisfactorily answered,
but the important thing to note here is that such objections are not
available to Chomsky, for whom (to repeat) the question of innate
knowledge of language is an empirical question that cannot be settled
by ruling out the alternative view on conceptual grounds.
If this non-nativist, evolutionary account of language-acquisition is
reasonable a priori, is there anything that would count as evidence for
its truth? Yes. HA. Simon (1962) has argued that, for reasons having
to do with the mathematics of probability, any complex product that
has emerged from a process formally akin to that of Darwinian
evolution will be expected to manifest certain fairly general structural
properties, having to do with the notion of "hierarchy." In a number of
my own writings (Sampson 1978; 1979; 1980) I have argued that, on
the Popperian view just sketched, the acquisition of syntax would be an
evolutionary process in the sense required for Simon's argument to be
applicable - indeed, Simon's argument ought to apply better to the
case of language than to various of the domains discussed by Simon
himself (Sampson 1980, p. 147). (Furthermore, on this view, the
individual's acquisition of language would in its general outline recapitu-
late the process by which languages emerged within originally
languageless communities.) If the Popperian, non-nativist view is
correct, then we would expect the languages that have developed in
each human community, and likewise the individual mental representa-
tions of their mother-tongue that are attained by each member of a
speech-community, all to share certain abstract grammatical proper-
ties (while differing in detail); they should all be based on hierarchical
structure, and the syntactic operations found in them should always be
"structure-dependent" ones.
In many of his best-known works (e.g. 1968, Ch. 2; 1973, Ch. 1;
1976a; Ch. 3) Chomsky argues that these properties are universal;
indeed, it is their universality that he uses as his central evidence for
innateness. But, while the hypothesis of an innate, fixed language
faculty predicts only that there will be some linguistic universals, the
Popperian hypothesis of fallible evolution of knowledge predicts, via
Simon's argument, certain specific linguistic universals, and just those
are what we observe - so the Popperian account must be preferred.
That is, while observation of linguistic universals might in general count
as evidence for Chomsky's nativist view of mind, the particular
universals cited by Chomsky are evidence against, rather than for, that
view. A detailed examination (Sampson 1980, Ch. 9) of Chomsky's
and other linguists' theories of linguistic universals shows that these
match beautifully the properties that Simon's argument leads us to
expect, if languages are created from scratch rather than being largely
built-in in advance.
The uniformity of certain properties of language is Chomsky's
principal argument for nativism, both here and in his previous writings.
In the final section of this piece he alludes to a subsidiary argument
when he says that "the rate of vocabulary acquisition is so high at
certain stages of life, and the precision and delicacy of the concepts
acquired so remarkable, that it seems necessary" to accept a nativist
account of the acquisition of vocabulary. This is a specialized variant of
a form of argument for nativism that Chomsky has used elsewhere:
children learn their first language so rapidly and so well that they must
know much of its structure before they start - they could never finish in
the same time if they had to begin from scratch. Any argument of this
form seems to me wholly empty, since it falsely assumes that we have
some way of measuring the attainments that would be expected if the
nativist hypothesis were wrong. I do not know the peak rate at which
children acquire vocabulary, but suppose it is twenty words a day. On
what grounds does Chomsky call this a "high" rather than a "low"
rate? How fast should children be able to learn new words if their
"conceptual system" were not "already substantially in place": five a
day? one a day? one a year? Similarly, how much less precise and
delicate would concept-acquisition be on this latter assumption? -
indeed, in what units could this "precision" conceivably be measured
and compared? Without discussion of these issues (which Chomsky
never gives), this strand of the nativist argument collapses.
I conclude that the traditional view, according to which minds differ
from bodies in being creative and not limited to a well-defined range of
predetermined possibilities, is on Chomsky's own evidence the correct
by Roger C. Schank
Department of Computer Science. Yalo University, New Haven, Conn. 06520
An artificial intelligence perspective on Chomsky's
view of language
Is there any reason to believe that there is a separate "language
faculty" that is one particular component of the mind? I take Chom-
sky's main point in this article to be that there is such a component of
the mind, which he believes can be clearly distinguished from all other
components. The arguments that he makes in its favor indicate that he
holds a great many presuppositions about language, and what a
theory of language must explain, that seem quite tenuous.
What ground must a theory of language cover? What is a theory of
language supposed to explain? To those of us who work in artificial
intelligence (Al), the answer to these questions seems quite clear. We
wish to produce specific models, or algorithms, that simulate the
communication process - i.e., that produce language in response to
inputs. Three issues arise with respect to the above goal and Chom-
sky's position. First, would any model that an Al researcher
constructed, that successfully modelled a human speaker/hearer,
necessarily embody a theory of language? Second, would any purely
formal competence theory of the kind Chomsky advocates aid the
development of a working computer model? Third, what would be the
relation between the presuppositions of an Al theory of language and
the presuppositions that Chomsky presents in his paper?
Answers to the first two questions are frequently polemical.
Chomsky and others have stated that a computer model of language
comprehension and production, even if perfect in its input-output
behavior, could still possibly be of no interest to the linguist and could
possibly fail to embody a theory of language. Al workers, on the other
hand, often simply assert that their programs are their theories and
leave it at that. What is in fact the case? Are Al workers also serious
language theorists? If they are not, should they be?
I will, of course, claim that they are, but I shall try to do so by using
Chomsky's own arguments from this target article.
First, let me point out that it is very easy to say that mechanisms that
perform certain tasks need not embody theories of those tasks. We
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
35

Commentary / Chomsky: Rules and representations
are better off asking whether people embody theories of language. An
Al response to such a question is that, while people do speak and
comprehend, they do not have conscious theories of how they do so.
Our task as language theorists then is to determine exactly how they
do speak and comprehend. Thus, a theory here becomes equivalent
to a model. When Chomsky states that knowledge of language is not a
"task-oriented device," he is quite mistaken. Certainly, people have
knowledge of their language that they employ in the task of communi-
cating. But if that is what he is referring to, then how can that
knowledge be anything other than task-oriented? People know their
language so that they can communicate!
The theory that Chomsky is interested in constructing can only be
relevant if it is somehow related to what people are doing with
language, and consequently to computer simulations of the communi-
cative process. Chomsky accepts this point by claiming that grammars
are actually knowledge that people have, which they use in performing
language tasks. But he continues to make excuses for why it isn't
possible for him to "construct specific models," or why he cannot
"attempt a systematic presentation of such a model." He seems
simply to be hoping that some sort of hard evidence will be found to
support his theories. But, while Al workers and psychologists continue
to find evidence that supports theories quite antithetical to Chomsky's
(Bower et al. 1979; Graesser et al. 1979; Nelson and Gruendel 1978),
he dismisses his lack of evidence with statements such as "Data that
remain unexplained by some coherent theory will continue to be
described in whatever descriptive scheme one chooses, but will simply
not be considered very important for the moment." He does this
because he holds the belief that "substantial coverage of data is not a
particularly significant result; it can be obtained in many ways."
It is remarkable that Chomsky holds such beliefs. If the construction
of specific models that amount to "substantial coverage of data" is so
easy, then why hasn't Chomsky or any of his followers ever
constructed one? The answer to this question is found on p. 4 of the
target article, where Chomsky poses a question that he regards as a
difficult one for a theory of language. Before I begin to discuss this
question, however, let me first point out that, although I use many of the
same terms that Chomsky does, this nonetheless appears to involve
next to no agreement on what a theory of language must explain. Let
me reassert my view here:
A theory of language must explain how people can comprehend
sentences that they read or hear, and how they respond appropriately.
In my view, a theory of language must embody a theory of comprehen-
sion, a theory of production, a theory of memory, a theory of motivation
and behavior, and much more. Thus, I believe that there is no
possibility of constructing a model of the process of communication
without having fully developed theories of all these concomitant
processes. For me, then, a theory of language per se is a vacuous
idea, impossible on the face of it and pointless on a deeper level. A
theory that accounted for language and language alone could not
possibly account for communication. Since communication is at the
heart of language, such a theory would be only so much formal
apparatus, explaining nothing; it would exist as something to prove
theorems about but not as something to build specific models upon.
My point is that there is a reason for Chomsky's failure to produce
specific models despite a purported interest in those models. The
reason is that it is impossible to produce a model of language alone,
and that is precisely what Chomsky has stated his goal to be. The
phenomenon of language alone, apart from beliefs, goals, points of
view, and world knowledge, simply does not exist. Language cannot
be studied apart from its use and still maintain any of its important
properties. The only properties it would continue to have in such a
study would be those associated with its formal structure, as distinct
from its communicative content. This is, of course, precisely what
Chomsky has chosen to study. To see this better, consider Chomsky's
example on p. 4 of his article.
On p. 4 Chomsky presents a problem in the "process of forming
questions." He states that the process first selects "some Noun
Phrase in a sentence," which is then "replace(d)... by an appropriate
question word." This is then placed at the beginning of the sentence to
form a question. He states, "Thus, on the model of the sentence 'John
saw a man' we can form 'Whom did John see?' "
Embodied in this example are the rudiments of Chomsky's theory of
language. His view is that the process of forming questions is a matter
of formal procedures, which transform declarative sentences into
interrogative ones. Chomsky uses the word "process," but it is not
clear what he means by this. In Al, an adequate theory of a process is
one that explains that process in terms of step-by-step procedures
that can be tested computationally. Thus, it is the processes that
people use when communicating that ought to be of interest to the
language theorist. This is also the source of the "psychological
validity" issue about which Chomsky seems in such a quandary. Let
me clarify this by presenting an Al explanation of question-formation.
When people form the question "Whom did John see?", we have to
imagine that they do so because they desire to know the answer to this
question. In other words, the input to the process of question-formation
is not a declarative sentence, but rather a desire for information. This
desire for information, combined with a belief that the person to whom
the question will be addressed possesses that information, starts the
process of question-formation. In this particular case, more information
is desired about some person. Once the need to know about some
feature of a person is established, the generation process begins. At
Yale we have written rules that are explicit enough to enable comput-
ers to both ask and answer questions in quite natural English. Such
rules are not all that mysterious. However, they depend on the ability to
use knowledge of the situation in question as well as knowledge about
what information our source has that can identify the "who" for us
(Lehnert 1977). To do this, we examine our knowledge of this "who,"
such as prior situations that this "who" has participated in. For
example, we might have available to us the information that John went
to a psychiatrist, and thus we want to know his name. Alternatively, we
might have heard that John spotted a famous celebrity and we want to
know his name or status. Equally plausibly, we might know that John
was arranging for an appointment for himself with an official, and we
want to know the rank or position of the official, rather than his name.
One of these desires is already known to us prior to forming the
question, and is instrumental in the process of forming the question.
Thus we might generate, "Whom did John see?", or perhaps "Whom
did John spot?", or "Whom did John have an appointment with?"
In none of these cases are we transforming a declarative into an
interrogative. One can, of course, imagine a formal procedure that
generates questions by the use of such transformations, but of what
explanatory use would such formal rules be? A procedure that
modelled people's question-formation process would not attempt to
transform a sentence such as "The lesson was harder than the
teacher had told the class it would be," an example that presents
difficulties for Chomsky's theory of question-formation. Chomsky has
such difficulties because the complexity of his theories leaves him no
choice but to claim "innateness" as an explanation of these theories.
Chomsky postulates an important "general property of language"
from the fact that people do not actually attempt to transform this
sentence into an interrogative that questions "the class." Actually, he
does think that people are silly enough to try it, but he allows that they
are also smart enough to realize that such a question would be more
than cumbersome, and thus somehow they are able to "block" that
question!
Chomsky gets into this kind of trouble because he insists on
separating a theory of language from a theory of motivation or
knowledge-acquisition. Thus he ends up wondering about how people
turn off this formal apparatus that he has invented when it goes
haywire. To do this he invents ad hoc blocking mechanisms that he
then decides are "general properties of language." Such general
properties must be innate, he reasons, because how could they have
been learned?
How, indeed! There is no way to imagine how such mechanisms
could be learned, but that is not because they are innate. They need
not be learned, because they do not exist. We do not form questions
apart from our desire to know something. We do not possess a purely
formal question-former that cleverly blocks itself from forming absurd
36
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Commentary / Chomsky: Rules and representations
questions. To imagine such a mechanism in people is to believe that
people do not think at all, or to believe that their language faculty is
apart from their other cognitive faculties and in very poor communica-
tion with those faculties.
The issue here, I believe, is to determine what a theory of language
should explain. The issue as Chomsky sees it, however, is what form a
theory of language must take. Actually, Chomsky doesn't see this as
an issue; he simply asserts the answer - a grammar. This belief that
grammars are learned causes him great problems, however. For
example, he asserts that
An investigation of the final states attained - that is, the grammars -
reveals that the knowledge acquired, and to a large extent shared,
involves judgments of extraordinary delicacy and detail. The argu-
ment from poverty of the stimulus leaves us no reasonable alterna-
tive but to suppose that these properties are somehow determined
in universal grammar, as part of the genotype. There is simply no
evidence available to the language learner to fix them, in many
crucial cases that have been studied. Nevertheless, people
obviously speak different languages depending on their limited
individual experience." (p. 9)
In other words, these grammars are so complex that no one could ever
learn them. I have no doubt as to the truth of that statement, but there
is an obvious explanation as to why no one could learn them. We don't
learn them because we don't use them. Grammars exist in the minds of
linguists only.
Is the stimulus really so impoverished? Recent research at Yale
indicates that it should be possible to learn to understand a language
by relying upon a well-formed conceptual model before starting to
learn language, and by using this method to guide the learning process
(Selfridge 1979). In such a view of language learning, the need for a
rich set of language experiences is minimized. A rich conceptual
apparatus guides the language learner in finding out what he wants to
know. And what does he want to know? Not formal properties of
language, surely. He wants task-oriented knowledge that will allow him
to communicate. This kind of knowledge of language is obtainable
through interactions with one's environment in a real setting. Chomsky
would have us divorce the conceptual from the language, leaving the
poor child truly quite impoverished. As long as Chomsky acknowl-
edges that child language acquisition is an important issue, I cannot
see how he can maintain that abstract formal descriptions of language
are the proper domain of study for the language theorist.
In the end, of course, we in Al are concerned with psychological
reality. Chomsky clearly is not concerned with that problem. Rather, he
is concerned with "(truth) at the level of description at which (he is)
working." by those ground rules, any game he plays is the right one.
But there are means of testing assertions about processes, both
computationally and through psychological experimentation. Chomsky
strongly disavows both of these tests. One wonders what is left. Surely
the "cognitive sciences" of which Chomsky speaks will be in for
difficult times if the framework they adopt is "studying the rules and
representations of cognitive systems" without regard for how people
actually think and speak, and without regard for the natural processes
that comprise their ability to do so. Formal systems, in and of
themselves, apart from any role in the process of communication, are
of no interest at all to cognitive science; if they are of interest to
linguistics, then linguistics is in a sorry state indeed.
by John R. Searle
Departmanl of Philosophy, University of California. Berkeley, Calif. 94720
Rules and causation
It is a peculiar characteristic of some of Chomsky's responses to
discussions of his work that he assumes that attempts to characterize
his work must be objections. When I wrote (Searle 1976) that the rules
of his grammar are "abstract and complicated" and lacked "the
intuititive plausibility of ordinary grammar rules," I was not putting that
forward as an objection, but rather as a characterization of his
position, and a characterization he could hardly disagree with. The
objection of which these characterizations were a part - I would prefer
to call it a problem - is rather more subtle. Since he did not understand
it from my earlier writings, I will spell (part of) it out.
In the explanation of a natural phenomenon, such as the behavior of
a falling body, we specify general laws or hypotheses under which the
behavior of the body can be subsumed. The laws describe the
behavior of the body; they play no causal role in producing it. But when
it comes to explaining human behavior in terms of rules and systems of
rules, the situation is quite different. If, for example, we explain my
car-driving behavior in part by saying that I am following the rule: "Drive
on the right-hand side of the road," that rule doesn't just describe my
behavior; rather, my internalization of the content of the rule plays a
causal role in the production of the behavior (and it is important to
emphasize that it is the content of the rule that acts causally, since the
form of causation in question involves following the rule). In the natural
sciences hypotheses merely describe and explain; in the explanation
of human behavior the rules cause the very behavior that they describe
and explain, and they don't explain the behavior unless they cause it. If
the rule is one that people are actually following, then the content of the
rule must function causally in the production of the very behavior that
the rule explains. Now, this distinction has an important consequence
for any attempt to analyze cognitive structures as "systems of rules
and representations." The claim that the agent is acting on rules
involves more than simply the claim that the rules describe his behavior
and predict future behavior. Additional evidence is required to show
that they are rules that the agent is actually following, and not mere
hypotheses or generalizations that correctly describe his behavior. It is
not enough to get rules that have the right predictive powers; there
must be some independent reason for supposing that the rules are
functioning causally.
Well, what sort of evidence would show that people are following
rules of language? One kind of evidence would be to make people
aware of the rules and get them to see or agree that those are indeed
the rules they are following. This is, in fact, the implicit procedure I
follow in Speech Acts, that Grice follows in "Logic and Conversation,"
and that is followed in a host of similar investigations. Such evidence,
like all empirical evidence, is inconclusive; and it is not the only possible
sort of evidence that one is following a rule unconsciously. But for
someone who does not have this sort of evidence, there ought to be
some other sort. In Chomsky's case I am unable to see what he thinks
the evidence is, or even that he adequately recognizes the problem.
In his target article Chomsky asks us to assimilate the study of
language to the natural sciences. We are to think of the "mind" as
"modular" and as containing three systems for language: the compu-
tational system, the conceptual system, and the pragmatic system. In
the case of the pragmatic and the conceptual systems we at least have
some evidence that people are engaging in rule-governed behavior,
and that they can be brought to an awareness of the rules they are
following. The rules are ceteris paribus rules, and their causal effect is
a matter of their content. But what about the computational system?
And in particular, what is the evidence that the rules of universal
grammar are actually playing a causal rule in the production of the
behavior they describe? This question becomes more pressing when
we reflect on the following: precisely to the extent that we take
Chomsky's analogy with biology seriously, to that very extent we do
not need the hypothesis of rules and representations. If we are to think
of the language organ on analogy with the heart or the liver, then we do
not need the additional hypothesis of rule-governed behavior at all.
The heart does not follow rules, nor does the liver; rather, there are
certain general functional principles that describe their operations, and
there are even semiteleogical statements that we can make about their
functioning. But none of these statements or principles are rules, for
there is no mental content playing a causal rule in the operation of the
heart or the liver. Similarly with many of Chomsky's other analogies:
that a certain bunch of neurons fires when my optical apparatus is
stimulated by a certain light frequency is a matter of natural fact. There
is no question of my following a set of rules. And in describing the very
complex antibody-antigen reactions in the human organism, the
biochemist describes chemical reactions; he does not have to add a
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
37

Commentary / Chomsky: Rules and representations
series of mental contents that are producing the behavior. Again, it is a
fact about my visual apparatus that I am incapable of perceiving
infrared and ultraviolet, but that is not because I follow a rule of
"universal visual grammar" that forbids such perceptions; it is just a
fact about my physiology.
"Well," one might say, "what difference does it make? Suppose
Chomsky had the 'rules' of universal grammar stated correctly; then it
wouldn't matter whether people followed these rules or whether the
rules were 'mere hypotheses' describing what happens." But unless
the principles are stated in the form of rules that actually play a causal
role in the production of behavior, there cannot be a level of "mental
organs" that are constituted as system of rules and representations.
To see this point, consider an alternative speculation to the ones
that Chomsky makes. Suppose that the structure of possible human
language is constrained by the structure of the human brain (and
notice that I say "brain" and not "mind"). Suppose that quite specific
neurophysiological structures in the brain constrain possible natural
human languages in the same sense of "constrain" that the neuro-
physiological structure of the visual system constrains possible visual
experiences. Now, if that were the case, then the rules of all human
languages would have certain features in common, and we might even
be able to state these features as a set of generalizations satisfied by
all human languages. And this commonality might give us the illusion
that, in addition to the actual rules of real human languages such as
French and English, there were some super rules of "universal
grammar" that collectively constituted a mental organ. But that would
be an illusion created by the fact that actual physical structures in the
brain were doing their work, in the same way that it would be an illusion
to suppose that the visual system follows a super rule blocking the
perception of ultraviolet and infrared. In neither case do the alleged
"rules" play any causal role, which is another way of saying there
aren't any such rules. In both cases the appearance of a rule would be
a product of the fact that the underlying neurophysiological systems
place constraints on the actual systems of rules and representations in
both vision and language. The super rules, in short, would be artifacts
produced by the fact that a common neurophysiological structure
constrains actual rules. If such a speculation were indeed accurate,
then there would be two levels of description. First, there would be a
mental level where we describe how actual rules and representations
function causally. Such rules and representations are of course real-
ized in the neurophysiology, but they require a separate level of
analysis because of their causal efficacy at the level of rules and
representations. And secondly, there would be a neurophysiological
level where we describe how any such system of rules is realized in the
structure of the brain.
Now, Chomsky's claim is that there is another level of rules beyond
all possible introspection - but not neurophysiological, either. My claim
is simply that any evidence for such a level would have to show its
reality by showing its causal efficacy, and Chomsky has not said
anything to show this - or, in this article, even indicated any awareness
of the problem. Furthermore, the very biological analogy that he and I
both find so appealing tends to undermine the assumption that there is
any such level. If there really is a language organ in the brain sufficient
to constrain the grammar of any possible human language, then there
is no need for a universal grammar; and if there really is a universal
grammar, then it can only be because the language organ is not by
itself sufficient to produce the constraints without an intervening level of
rules.
As my previous discussions of Chomsky have tended to be misun-
derstood, I will conclude by blocking some possible misunderstand-
ings:
1. I have not claimed that genuine rules must be accessible to
introspection. I have claimed that where they are not accessible to
introspection there ought to be at least some other sort of evidence
that the agent is following the rules.
2.1 have not denied that geniune rules could be innate or "wired
in." I have rather claimed that genuine rules must play a causal role
in the production of the behavior they explain.
3. I have not denied the existence of universal grammar or of a
computational module in the mind. I have simply called attention to
some unanswered questions in the attempt to establish their exis-
tence.
by Elliott Sober
Philosophy Department. University ot Wisconsin-Madison, Madison, Wise. 53706
Representation and psychological reality
In this target article, Chomsky provides an interesting formulation of the
idea of psychological reality: one that is meant both to clarify what is
involved in attributions of psychological reality to linguistic hypotheses,
and to defend such attributions from the philosophical criticisms to
which they have been subjected. Chomsky believes that a grammatical
hypothesis is psychologically real in just the sense that a physical
hypothesis is physically real. Claims of physical reality, in turn, have
two, unproblematic, components: for a hypothesis to be physically real
is for it to be physical in its subject matter and true. Applying this
analogical analysis to the idea of linguistic hypotheses having psycho-
logical reality, we get: (i) linguistics is a branch of (individual) psycholo-
gy; (ii) for a psychological hypothesis to have psychological reality is
nothing more or less than for it to be true.
In this brief space I won't take up the issues involved in (i). There are
two conceivable alternatives to Chomsky's psychological interpreta-
tion: that linguistic hypotheses describe social regularities, and that
they describe abstract mathematical structures that are no more
psychological in character than the axioms of number theory. The
thought behind (ii) is to show that if one finds plausible so-called
"realist" philosophical doctrines about science generally, then one
should have no particular qualms about the idea of psychological
reality. A realist about a particular science will hold that it is the task of
that science not only to construct hypotheses that accurately predict
observable phenomena, but also to formulate and confirm conjectures
about the underlying causal mechanisms that are responsible for the
observed regularities. For Chomsky, hypotheses about the internalized
grammatical representations of a speaker-hearer, though couched in
mentalistic vocabulary, will nevertheless be about the underlying physi-
cal mechanisms (now largely unknown) that are responsible for
behavior. By analyzing "psychological reality" in this way, Chomsky
hopes to demystify the concept: a psychological hypothesis will be
entitled to this label if it is the best explanation available. There is no
special problem about the concept, once one has accepted a realist
view of psychology.
In this brief space I want to describe how Chomsky's analysis of
"psychological reality" departs from what I think is a fairly standard
construal of the idea. This familiar formulation arises from distinguish-
ing between someone's following a rule and someone's acting in
conformity with a rule. The former idea, but not the latter, involves the
idea that the person has some mental representation of the rule that
plays a certain causal role in determining behavior. Although there may
be many grammatical rules to which a person's verbal behavior
(ignoring slips of the tongue and other performance interferences)
conforms, only some of those rules have psychological reality; these
are the ones that are internalized in thought and play some appropriate
causal role.
If we construe psychological reality in this way, then there are two
objections to Chomsky's analogy between psychological reality and
physical reality. The first one has to do with their possessing different
degrees of intensionality: If X is a law of nature that has physical reality,
and if Y is logically equivalent to X, then Y too has physical reality.
However, if X is a grammatical rule that has psychological reality, and if
Y is a rule that is logically guaranteed to be input-output equivalent to
X, it does not follow that /has psychological reality. In this, psychologi-
cal reality resembles other mentalistic properties: for example, some-
one may believe or doubt X, but not bear the same relation to V, even
though X and Y are logically equivalent. This difference between the
concept of physical reality and that of psychological reality suggests
that there are special issues that need to be taken up if one is to clarify
and defend the idea of psychological reality. The parallelism between
the two concepts is not total.
The construal of psychological reality as involving the idea of mental
38
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Commentary / Chomsky: Rules and representations
representation, and Chomsky's analysis, which interprets psychologi-
cal reality to mean psychological in subject matter and true, differ in a
second respect. What is it for a hypothesis to be psychological in its
subject matter? One way to answer this question is to imagine a
language in which all the predicates express phonological, syntactic,
and semantic properties and relations. Any sentence formulable in this
language that is not a logical truth will be linguistic in its subject matter.
Will each of the truths expressible in this language be psychologically
real? I think not. Some constraints on humanly possible languages
issue from the physical constitution of the vocal organs, for example.
Some phonological rules will be true in virtue of these physical
constraints. These rules will not have psychological reality, in that they
will not be mentally represented. For a hypothesis to be psychological
in its subject matter is for it to be formulable in terms of some
proprietary vocabulary. But for a hypothesis to be psychologically real
is not simply for it to be psychological in its subject matter and true. A
psychological law may be true even though it is not mentally repre-
sented; numerous other characteristics of the organism may be
responsible for its being true. Thus, if we understand the idea of
psychological reality as involving the idea of mental representation,
there will be truths of psychology that are not psychologically real. This
argument against Chomsky's analysis of psychological reality is quite
consistent with the physicalist assumption that hypothesized psycho-
logical mechanisms are in fact identical with physical mechanisms.
Perhaps every truth of psychology is true in virtue of physical structures
of the organism. Nevertheless, only some of those truths have psycho-
logical reality.
by Stephen P. Stich
Department of Philosophy and Committee on the History and Philosophy of
Science. University of Maryland. College Perk, Md. 20742
What every speaker cognizes
Much of the story that Chomsky tells in Rules and Representations, he
has told before. But no matter. The story is a profoundly important one,
and it improves with retelling. The basic features of Chomsky's
account of the mind are convincing, many of the details are not.
Let me begin with an issue where the distance between Chomsky
and some of his critics has grown progressively smaller. Can a
speaker be said to know the rules of his grammar? Many philosophers
have argued that the answer is no (see Nagel 1969; Schwartz 1969;
Stich 1971; Cooper 1975). The basic strategy of the critics has been to
note features that are typical of unproblematic cases of knowledge but
that are absent in the relation between a speaker and the rules of his
grammar. Given these disanalogies, the critics have argued, it would
be inappropriate to call the relation between a speaker and his
grammar knowledge unless there were extenuating circumstances;
special features of the case that made the term knowledge appro-
priate despite the disanalogies. Finding no such extenuating circum-
stances, they conclude that speakers do not know the rules of their
grammar. (For a detailed version of this argument, see Stich 1971,
sees. IVâVI; for a reply, cf. Graves et. al. 1973.)
Now, suppose that this argument is a telling one, as indeed I think it
is. Would Chomsky lose anything worth keeping by simply conceding
the point? It is central to Chomsky's view that organisms have rich
systems of internal representations that are exploited in varying ways
in action, perception, cognition, and so on. It is also important for
Chomsky that in humans one of these interacting systems internally
represents the rules of the speaker's grammar. But whether the
grammatical information is known or is merely internally represented in
some way that does not count as knowledge surely is of lesser
moment. Unfortunately, some of Chomsky's critics (myself included)
have written as though the argument showing that speakers don't
know the rules of their grammar also shows that the rules are not
internally represented in some other way that does not warrant the
knowledge label. However, this additional claim is simply a nonsequitur.
Once it is conceded that the argument against knowledge of grammar
entails nothing about other ways in which grammar may be internally
represented, Chomsky could simply drop the knowledge claim alto-
gether. And, indeed, this seems to be the position he adopts in Rules
and Representations, where he introduces the term "cognize" to cover
both knowledge and other sorts of internal representation.
The remaining disagreement with Chomsky on the topic of knowl-
edge turns on a pair of claims he makes about the difference between
knowledge and other sorts of cognizing. He suggests, several times,
that the only difference between knowing a rule or proposition and
internally representing it in a way that does not count as knowledge is
that a known rule is accessible to consciousness, while a cognized (but
not known) rule is not. He goes on to suggest that the distinction
between knowledge and other forms of cognizing is of little impor-
tance. I think both claims are mistaken. There is a second feature of
the propositions and rules we know (or believe) that distinguishes them
from propositions and rules internally represented in some other way.
The former, but not the latter, form a system that is highly integrated
inferentially. Perhaps the briefest way to explain this notion is with a
simple example. If I believe both q and if p, then not-q, and if I
subsequently come to believe p, substantial stress is put on my
cognitive system, and there is a substantial probability that I will
accommodate this stress by coming to believe not-q (and ceasing to
believe q) or by ceasing to believe if p, then q. Contrast this with the
situation in which I start out cognizing q (but not believing it) and
believing // p, then not-q. We might, for vividness, suppose that q is
some appropriate formulation of Chomsky's "principle of locality,"
represented in the speaker's grammatical-processing "organ." In this
case, coming to believe that p will put no comparable stress on my
cognitive system, since the cognized representation of q is inferentially
insulated from the beliefs p and it p, then not-q.
The fact that systems of cognized representations that are not
believed also are not inferentially integrated with the body of a
subject's beliefs or with other systems of cognized (but not believed)
representations, suggests a picture along the following lines. Our
mental apparatus is divided into a number of distinct components.
Among these is a store of beliefs that are well integrated inferentially
and generally accessible to consciousness. There are other compo-
nents that serve special functions: grammatical processing, visual
signal analysis, integrating motor activity to produce actions, and so
forth. Each of these components may have a rich store of internally
represented information. And, of course, the components interact with
each other in complex ways. However, each component has only very
limited access (or sometimes perhaps none at all) to the information
stored and utilized by the other components. This picture (developed
further in Stich 1978b) is of a piece with the "homuncular functional-
ism" advocated by Dennett (1978) and Lycan (in preparation), and is
thoroughly congenial to Chomsky's "mental organs" view. The differ-
ences between beliefs, which are accessible to consciousness and
inferentially integrated, and other forms of cognizing, which are neither,
give us reason to suspect that beliefs are subserved by a distinct
mental organ.
I fear that all this agreeableness may make for dull reading. So let
me now turn to a topic where the clash with Chomsky's views will
generate a few sparks. It is Chomsky's view that "grammars are
internally represented in the mind." Why should we believe this? Here, I
think, the question can usefully be divided into two parts. First, why
should we think that some rich system of grammatical information is
internally represented in the mind? Second, why should we think that
what is internally represented is a grammar of the sort that might be
produced by a Chomsky-style linguist, whose principal data are the
utterances the speaker makes and the judgements the speaker
renders about the acceptability of sentences, the relations among
sentences, and so on. In answer to the first of these questions,
Chomsky offers what I take to be a compelling argument. It is the only
game in town. We simply have no serious idea how the complex
system of linguistic judgements and discriminations that a speaker
makes could possibly be made by any complex object (be it organism
or automaton) that did not have a rich and intricate store of grammati-
cal information. It is, of course, logically possible that some future
Newton of cognition will discover a way in which these discriminations
and judgements could be made by a system lacking an internal store of
grammatical information. But that shows no more than that the internal
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
39

Commentary / Chomsky: Rules and representations
mental representation hypothesis is an empirical hypothesis; like all
empirical hypotheses, it might turn out to be false. It remains the case
that there is no currently available substantive alternative to the
assumption that the speaker has a great deal of internally represented
grammatical information.
But now what about our second question? Granting that some very
rich store of grammatical information must be internally represented in
the mind, why should we think that what is represented is a Chomsky-
style grammar? On my view there is little to recommend the claim that
what we have internally represented is a grammar. For there are
indefinitely many other ways in which grammatical information may be
stored and utilized by the mind: alternative systems of rules, systems of
propositions, frames, and still other alternatives as yet unexplored or
unimagined. Which of these is actually used is an empirical question.
But it is an empirical question that we are only beginning to address.
What is more, it is not a question that can be answered if we restrict
ourselves to the data and techniques of the generative linguist.
An example should make all of this a bit clearer. Winograd's (1972)
SHRDLU patently has a great deal of internally represented information
about English grammar, but it does not have an internal representation
of a Chomsky-style transformational grammar of English. Of course,
SHDLU's mastery of English is far from complete. But there is no
reason to suppose that an even more impressive SON-OF-SHRDLU,
with a much more complete mastery of English, would have to include a
grammar of English. Now suppose that student-of-Winograd has
constructed such a SON-OF-SHRDLU which, in addition to its greater
linguistic prowess, also has the capacity to answer questions about its
own linguistic intuitions. Finally, suppose that SON-OF-SHRDLU's intui-
tions are a fair match to those of a native English speaker, say mine.
What sort of a grammar would be written by a Chomsky-style linguist
who has been given the task of producing a grammar for SON-
OF-SHRDLU? Obviously it would be much the same generative gram-
mar the linguist would produce using me as his informant. Yet
SON-OF-SHRDLU has no such grammar internally represented. Is
there, then, any reason to think that /have an internal representation of
the linguist's generative grammar? Clearly, the answer is no.
Before leaving this topic, two points need stressing. First, I take the
question of how grammatical information is represented in our minds to
be an empirical and not an altogether intractable one. By studying
processing times, mistakes, confusions, the effects of brain damage,
and so on, we can learn a great deal about how grammatical
information is represented. The traditional data of the generative
linguist - actual speech and intuitive judgements - are relevant too, of
course. What I have been arguing is that a theory that restricts itself to
these "traditional" data cannot decide among a broad range of
theories about how grammatical information is represented. The
second point to stress is that there is some danger that this kind of
disagreement can degenerate into a purely verbal dispute. It is possible
for Chomsky to reply by insisting that the clause "grammars are
internally represented in the mind" did not refer to the sorts of
grammars he and other generative grammarians now write on the
basis of linguistic evidence. Rather, the reply would continue, it referred
to the sorts of grammars that would be written by cognitive simulators
who gave due attention to the full range of potental psychological data.
I think this is an unlikely interpretation, but if it is nonetheless the
interpretation Chomsky actually prefers, then I must agree that gram-
mars (in this sense) are internally represented in the mind. But if we
paper over the dispute in this way, it quickly emerges elsewhere. For,
given our new sense of "grammar" on which the right grammar simply
is the system of rules, propositions, or whatever that actually are
internally represented in the speaker's mind, I would contend that we
now have almost no idea about the details of the grammar for any
natural language.
Let me turn, now, to Chomsky's "argument from the poverty of the
stimulus." Here again I am partly in agreement: His question-formation
example, his "each other" example, and a large number of other
examples that he has elaborated elsewhere make it overwhelmingly
clear that the grammatical knowledge the speaker ultimately ends up
with (however it may be represented) simply could not be inferred from
the data available to the child by a rational person, unless that person
was initially provided with a rich additional body of information. And to
show this is, as Chomsky has frequently contended, to show that no
empiricist theory of language acquisition could possibly be correct.
However, Chomsky often draws a very different sort of conclusion from
the argument from the poverty of the stimulus, a conclusion that the
argument simply will not bear. The essential strategy of the argument
from the poverty of the stimulus is to locate some relatively abstract
principle, like the principle of locality, which has a pair of properties:
i) the speaker's language clearly accords with the principle, and ii) it is
wildly implausible that in acquiring his language the speaker had
sufficient evidence to infer that the principle characterized the
language of his elders. Since the data provide insufficient evidence (or
perhaps no evidence at all), it follows that innate features of the
language-acquisition mechanism must play a large role in the explana-
tion of why the speaker acquires a language that accords with the
principle. All this seems correct. But Chomsky often seems to infer
something more: viz. that the principle that is radically underdetermined
by the evidence available to the learner must be a universal feature of
all languages. This inference, however, simply does not follow.
Perhaps the simplest way to see the point is to consider a simplified
and rather fanciful example. Suppose that there are two quite different
categories of languages that humans can learn. All the languages in
category A exhibit the principle of locality, the principle of opacity, and
the rest of the "universal" principles Chomsky and his co-workers
discern in English. The languages in category B, however, exhibit none
of these "category A universals"; they all exhibit quite a different set of
abstract and nontrivial "universal" features. One of the innate princi-
ples of the language-acquisition mechanism instructs the system to
restrict itself to either category A grammars or category B grammars
as a function of some quite arbitrary feature of the stimulus (or
"primary linguistic data"). For concreteness we might imagine the
innate instruction to read: "If the word for mother begins with a
consonant, the right grammar must have category A features; if the
word for mother begins with a vowel, the right grammar must have
category B features." Now there is, we will suppose, no way in which a
person initially uninformed about this conditional principle could induc-
tively infer, from the data available to a child in an English-speaking
community, the conclusion that the language being spoken exhibits
category A "universals." The child's innate knowledge is heavily
implicated in the explanation of the fact that he comes to speak a
language that exhibits category A "universals." But these category A
"universals" are not real universals at all. Ex hypothesi there are many
languages that do not exhibit them, but that a child put in the proper
environment could learn with equal facility. It would be natural enough
to say that both category A principles and category B principles are
innate. What I have been arguing, then, is that innate principles need
not be universal. (For an elaboration of this argument cf. Stich 1978a;
1979).
by Robert Van Gulick
Department of Philosophy, Rutgers College, Rutgers University, New Brunswick, NJ
08903
Knowledge and learning
As the concepts of knowledge and learning play an important role in
Professor Chomsky's discussion, it will be useful to inquire further
about each of them as well as about their interrelation. I believe the two
notions are correlatives, and thus I will try to exhibit their mutual
conceptual and theoretical interdependence in a way that, I hope,
clarifies several issues raised by Chomsky.
Most philosophical treatments of knowledge add to a requirement of
true belief or accurate representation some further conditions concern-
ing the origin or support of the belief or representation. Both justifica-
tion accounts and causal theories of knowledge place constraints on
the sorts of belief production processes that can be thought of as
leading to knowledge. Our first point of contact now emerges. For a
learning process is a process of acquiring beliefs or information. And
40
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Commentary / Chomsky: Rules and representations
the beliefs acquired must more often than not be true if we are to count
the process as one of learning. Learning, like knowledge, is a
success-loaded concept. Indeed, there seems some basis for under-
standing learning as a knowledge-acquisition process. Thus the two
questions: "When is an information acquisition process a learning
process?" and "Which processes are of the sort that can produce
knowledge?" are intimately interrelated, though we need not assume
them to have a common answer.
In addressing these issues, it will be best to retreat to some notion
that abstracts the concept of knowledge somewhat from considera-
tions about its production. I suggest that we focus on the idea of
information possession, which I take to be more general and illuminat-
ing here than that of true belief. Put crudely, an organism (or system)
possesses information about some fact if its structure is such as to
modify or regulate its behavior in ways that are specifically adaptive,
given that fact. Information possession is a matter of the organism's
being structured or "shaped" to interact successfully with the world
along the lines of its ends or interests. (For further discussion of such a
notion of information, see Konrad Lorenz, 1965.)
So conceived, the question of when an organism ought to be
described as having knowledge or possessing information seems less
pressing. Such descriptions will be of wide applicability in characteriz-
ing organisms and their organizational structure. Rather, the interest
shifts to determining how the content of the information possessed is
to be specified, especially as regards its sophistication, Even if both I
and the earth-worm at my feet can be said to possess information
about the ground's being wet, the information we possess is clearly not
identical in content. The crucial differences between us concern the
much wider variety of ways in which the information I possess can
adaptively affect my behavior - especially the ways in which its
behavioral role depends on its interaction with the other items of
information I possess. A high degree of such inferential connection is
particularly needed if we wish to think of this information possession as
belief or to specify its content by the use of "that" clauses (i.e., "that"
followed by a sentence, as in "Jones believes that Smith is tall.").
Given this admittedly crude account of information-possessing, we
can detect difficulties with Chomsky's concept of "cognizing." The
technical term "cognize" is apparently introduced to sidestep difficul-
ties that might arise concerning the common-sense term "know." Yet it
should now be clear that the theoretical problems remain. The
language faculty may be said in some sense to embody the rules and
representations of the grammar in its operation, but how we ought to
specify the content of what information it possesses or what it
cognizes about those items will require a detailed account of the
processes within the faculty that operate on those items. Chomsky's
remark that we would not hesitate to say that any person who became
conscious of the grammar and its rules knew them thus begs the
question and misleadingly suggests that any controversy here merely
concerns conscious or introspective access. Access to consciousness
is relevant only insofar as the contents of our conscious mental states
are of a sort that reflect their rich inferential relations. It is a long step
from claiming that our best theories of the language faculty describe it
as embodying thus-and-such rules and representations of a grammar
in its processes, to any claim that the language faculty cognizes that
the rules or grammar are thus-and-such. Much more would be needed
to justify the assertion that the information possessed in such cases is
at all comparable to that associated with standard intentional attitudes.
The shift from "know" to "cognize" leaves intact all those problems
about how to specify the content of what is cognized, which can only
be resolved by appeal to detailed theories about the internal
processes involved. A similar difficulty arises with respect to Chom-
sky's cognizing rocket, which is said to "incorporate an explicit theory
of the motions of the heavenly bodies." One would need to say more
about the case, especially about how and in what ways the rocket was
able to apply this information it possessed before we could specify the
content of that information. It is quite unclear whether or not we should
think of it as realizing an informational state at all like that realized by a
competent human scientist who knows or cognizes the theory. I do not
mean to say that Chomsky argues for such an equivalence; my intent is
only to emphasize that the difficult questions here are those concerning
the specification of content and that these problems apply as much to
the notion of cognizing as they do to cases of knowlege or information
possession.
Using our notion of information possession, we might describe a
learning process as one that leads to the acquisition of information.
Learning might be said to have taken place whenever some real-world
feature induced a change in an organism that modified its behavior in
ways specifically adaptive to that feature. Such a characterization
would be overly broad to provide the sort of contrast Chomsky desires
between knowledge acquired by learning and by growth. His own
characterization of what is to be counted as a learning process is
partly based on a specification of stereotypical cases of such
processes: association, induction, conditioning, hypothesis formation
and confirmation, and abstraction and generalization. Is there some
principled reason for grouping such information-acquisition processes
together and thinking of them as distinctively learning processes? What
theoretically relevant features might they share?
One thing they have in common is a high degree of generality; they
are processes that are not specific to any particular subject matter or
type of information-acquisition problem. They can all be thought of as
methods for extracting information from environmental inputs, but as
themselves embodying the possession of very little or no information
about that environment. They thus conform to a traditional empiricist
picture, still influential today, which rather sharply distinguishes
between factual knowledge and the relatively pure a priori methods for
arriving at that knowledge - methods which are thought of as relatively
uninfected by actual empirical content. Attacks upon this view have
come with the recent interest in causal theories of knowledge and
naturalized epistemology. One approach has been to specify the
acquisition conditions in accounts of knowledge by reference to
reliable belief-production processes (reliable, that is, in the sense of
leading regularly if not invariably to truth). Crucial here is the recogni-
tion that reliability is context-relative. That is, whether or not a given
production process is reliable depends on the actual real-world
environment within which it operates. Part of the motivation has been to
answer skeptical challenges to claims of knowledge by arguing that the
skeptical counterpossibilities need not be taken into account in
assessing reliability. The point of interest for our questions about
learning is that, if a given belief production process is reliable in its
actual environment but would not be so generally, its presence in an
organism can be understood as a case of phylogenetically acquired
information about that environment. Thus, insofar as both the methods
of the traditional empiricist picture and those methods that seem
paradigmatically to be cases of learning processes share a high
degree of generality, they might be thought to embody the possession
of less information of any specific sort about the environment than do
other reliable belief or information-acquisition processes. The result is
one Chomsky should find congenial. For the internalization of a
grammar might be thought not to be a case of knowledge acquisition
by learning, either because no new information was acquired or
because the information was acquired by a process that was not of a
sort appropriately characterized as learning. However, these two
possibilities can now be seen to be somewhat collapsible. For while
there remain distinctions of degree, the farther we move from paradig-
matically learning processes, the more antecedent information we
must recognize as having been embodied in the relevant acquisition
process.
One last point requires comment. In his discussion of selective and
instructive processes, Chomsky suggests that, on analysis, it may turn
out that learning is not really learning. His reasoning is that, on analysis,
instructive processes that he equates with learning may turn out to be
realized at underlying levels by selective (i.e. nonlearning) processes.
Such discoveries may well occur, but they would not by themselves
show that the higher-level processes were incorrectly thought of as
learning, anymore than decomposing a feedback process into underly-
ing nonfeedback processes would show that the former was not
indeed a feedback process. Descriptions that are appropriate to a
process at one level need not equally apply to the processes at levels
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
41

Response / Chomsky: Rules and representations
that underlie their realization. It may well turn out that far fewer of our
ways of acquiring information are really learning processes than is
generally supposed. But we cannot conclude that learning is not really
learning if decomposition should show it not to be learning all the way
down.
Author's Response
by Noam Chomsky
Department of Linguistics and Philosophy, Massachusetts Institute ot Technology,
Cambridge. Mass. 02139
The new organology
I borrow the title of this Response from Marshall's elegant
demonstration that there is nothing new under the sun. I
would also like to emphasize his closing remark that "some
way surely has to be found in which results phrased in the
languages of linguistics, psychology, and physiology can be
made to bear upon each other." As a number of the commen-
taries make clear, current work in epistemology, philosophy
of mind, and philosophy of language promises to make a
substantial contribution to this inquiry; and vice versa, I
believe.
As noted in the abstract, the target article was excerpted
from a longer work (Chomsky 1980). Omitted completely
was a chapter outlining some ideas about universal grammar
(UG) and its realization in the particular case of English, and
also considerable discussion of alternative views and other
topics. The excerpted discussion of a research program is
perhaps a bit misleading, in that it understates the specificity
of hypotheses that have been investigated in pursuing this
program. These matters go beyond the excerpt, and indeed
beyond the book from which the excerpts were taken, which
was concerned primarily with conceptual issues rather than
systematic presentation of elements of a theory of universal or
particular grammar. In the technical literature, particular
questions are investigated in considerable detail. My intention
here was to discuss a general framework in which these
technical studies can be understood, in my view. A number of
commentators noted that my discussion was quite short on
facts and specific proposals. That is correct, but it reflects in
part the specific purposes of this discussion. I gave only a
handful of facts as illustration: namely, a few properties of
anaphoric expressions and questions. I will refer to these
below simply as "sample facts." They are selected, for illus-
tration, from a wide array of similar cases, and there are some
fairly definite proposals in the literature, not discussed here,
with regard to the rules and principles that may account for
them. In short, I would not want to leave the reader with the
impression that we can go no further than the qualitative
remarks presented here with regard to the nature of UG and
particular grammars.
Given the variety of issues raised and points of view
expressed in the Commentary, it seemed best to respond
individually. This leads to some redundancy, but perhaps it
will facilitate comparison of the commentaries and responses.
Andor. Andor suggests that "our semantic and pragmatic
knowledge and intuitions" have a "more crucial role in
comprehension than syntactic factors." I do not know how to
measure relative contributions, but let us suppose that this is
true. Nothing follows with regard to what I have proposed. It
remains a valid problem to determine the nature of the rules
that he calls "syntactic" and to find their precise scope and
character, as well as to ask how they interact with "semantic
and pragmatic knowledge." Andor states correctly that in this
paper I have nothing precise to say about grammar; see the
introductory comment, above. Perhaps Andor is right in
proposing that our judgments and behavior involve "cogni-
tive filters" in his sense. If he is also right in his beliefs about
the nature of these "cognitive filters" (namely, that they are
highly individual, based on "scenes and frames" that vary
widely depending on external factors), then the study of these
"filters" will be more informative about the nature of the
environment than about the nature of the mind. If he is right,
then, one who is more interested in the nature of the mind
will therefore be more concerned with other properties of the
attained and initial state, however large or small their contri-
bution to evaluation, expression, and comprehension - specif-
ically, with what Andor calls the "syntactic factors," includ-
ing those that enter into the representation of sound and
meaning.
Cromer. Before discussing Cromer's contribution, I would
like to clear away several misunderstandings. Let us distin-
guish two notions: "poverty of the stimulus" and "degeneracy
of the stimulus." The first is the concept discussed in my
paper. The stimulus is "degenerate" if the data-base for
language acquisition contains expressions that are not well-
formed. Cromer states that in earlier work I had claimed that
"the input stimulus [is] composed mainly of pauses, hesita-
tions, and false starts," referring to Chomsky (1967). He states
further that "most psychologists and psycholinguists," misled
by these "claims," have understood "poverty of the stimulus"
to mean what I am now calling "degeneracy of the stimulus."
Perhaps most psychologists have been misled, as he says, but
hardly on the basis of the reference he cites, where the
discussion in the text concerns only poverty of the stimulus,
and the matter of degeneracy is relegated to a footnote (in
which, incidentally, there is no claim that the stimulus is
"mainly" degenerate). Thus, it is simply not the case that my
arguments for innateness, there or elsewhere, "are primarily
based on the poverty of the input stimulus" in the sense of
degeneracy. The latter is a marginal issue and has always
been presented as such.
Cromer points out that "accumulating data" show that
when people speak to children, they generally speak simply
and carefully - hardly a surprising result, one might have
thought. But it definitely has not been shown that these
simplified data constitute the data-base for language acquisi-
tion, or that such data are a necessary condition for language
acquisition. There is no evidence for this, and there is
evidence to the contrary (see Newport, Gleitman, and Gleit-
man 1977). Thus, the fact that people tend to speak clearly
and simply to children does not show that the "input
language" - that is, the data base for language acquisition -
"has now been shown by careful mother-child interaction
studies to be clear and to be free of hesitations, false starts,
and the like." Furthermore, as Wexler (1978) notes, such
simplified data are far from serving as an "ideal" data-base; if
the data were restricted in this way, the problem of explain-
ing how a child gains knowledge of language would simply be
rendered a deeper mystery. But we need not pursue the
matter, since what is crucially at issue is poverty, not degener-
acy of the stimulus.
A second misunderstanding appears in Cromer's statement
that I argue against "hypothesis-formation and confirmation"
as explanation for language acquisition "primarily on philo-
sophical and logical grounds." First, I do not argue against
this approach at all; cf. p. 14 of the target article. Rather, I
raised the question of how such an approach could be
distinguished from a growth theory. Second, I have argued
against various specific "learning theory approaches," but on
factual grounds.
These misunderstandings aside, one can only welcome
42
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Response / Chomsky: Rules and representations
Cromer's insistence on careful attention to data on language
acquisition. His commentary is enlightening, in particular, in
pointing out the hazards of interpretation, as in the case of
strategies used by children who do not yet comprehend
particular language structures, and in emphasizing the
disparity between the child's rule systems and the data
available (analogously, the resistance of natural conservers to
direct contrary evidence).
As for the "preformationist" versus "epigenetic" ap-
proaches to innateness and growth, I take no stand (here or
elsewhere), agreeing that there seems no current possibility of
distinguishing them empirically.
There are many different ways to approach the questions
of innateness and acquisition; individuals will pursue one or
another course on the basis of their evaluation of prospects
and their own predilections. It seems to me that for the
present, the most productive way to develop precise hypo-
theses concerning the initial state of the language faculty,
hence the basis for language acquisition, is by detailed investi-
gation of explanatory theories of the state attained, applying
the useful (though obviously nondemonstrative) argument
from poverty of the stimulus. But I would not try to urge this
personal judgment on others, and, as my article should make
clear, I am completely receptive - as any rational person must
be - to results emerging from other lines of study.
Cummins and Harnish. C&H agree that "there is a language
faculty (LF) characterizable via a system of rules and repre-
sentations, the structure of which is largely innate or innately
determined." Therefore there is a valid field of inquiry, call it
LF-theory, which seeks to determine the nature of such
systems in the mature state and their innate determinants in
the initial state, these being matters of fact. State of what? I
would say: state of the mind, ultimately brain. Thus, hypo-
theses about the mature system (the grammar) and the innate
determinants (UG) are hypotheses about the mind/brain.
True, one can imagine alternatives. Perhaps LF really resides
in the liver, or is somewhere in outer space. I see no point in
pursuing such possibilities, for obvious reasons, and therefore
continue to assume that the LF that C&H and I agree exists is
"characterizable via a system of rules and representations"
that is internally represented in the mind/brain.
C&H appear to disagree with these moves. They feel that
"linguistics" need not be "about the LF." With that, I agree. I
would not want to legislate the usage of the term "linguistics."
It is of no concern to me whether LF-theory is called
"linguistics," and contrary to what C&H assert, I see many
alternatives to LF-theory; most of what is called "linguistics"
is not directed to this end.
C&H argue that the real issue concerning "psychological
reality" has to do with the reference of the term "linguis-
tics" - is "linguistics" to be construed as LF-theory, which is a
valid field of inquiry on their assumptions, or as something
else? About this terminological issue, I have no position and
no concern. My concerns, rather, have to do with the issues
concerning "psychological reality" raised in the literature to
which I referred.
Note that, on C&H's grounds, one could also say that
"psychological evidence" (e.g., results of reaction time or
click experiments) has not been shown to bear on the "psy-
chological reality" of theories accounting for it, since one
might (perversely) construct such theories with no concern
for their truth, say, as one or another way of axiomatizing
some range of data. Thus in their terms, there is not only a
way of construing "linguistics" so that it is not part of
psychology, but also a way of so construing "psychology." As
in their version of "linguistics," so in this version of "psychol-
ogy," one need not be concerned about "psychological
constraints" deriving from other studies, or about any of the
problems that interest someone concerned to discover true
theories.
What exactly do C&H mean when they say that there has
been no adequate defense for the view that "talk about
language is just disguised talk about shared psychological
states"? They agree that there are grammars that are largely
innately determined, and that these characterize LF. Insofar
as "talk about language" is talk about these grammars, hence
about LF, it is talk (not disguised) about psychological states,
internal mechanisms, and so on. This follows from their
assumption that these structures do exist and are innately
determined. Their point, then, seems to be that talk about
language need not adopt these concerns, which is no more
interesting than the fact that talk about some range of
physical data need not be concerned with determining true
theories. As for the fact that promises obligate, this may be a
fact about LF (hence represented in the grammar) or a fact
about some other system, in which case knowledge of the fact
will be represented outside of LF - a possibility that seems to
have no consequences for the questions they are raising.
Perhaps C&H are taking the position that such facts as the
"sample facts" could be facts about "English" (an infinite
system), even if there were no representation of knowledge of
English in the minds of speaker-hearers (or anywhere). They
do not try to develop this possibility, so I will not pursue it. Cf.
Chomsky (1980) for some discussion.
C&H cite the opening paragraph of my Syntactic Struc-
tures (Chomsky 1957), where a grammar is defined as a
device that generates the sentences of an infinite set (a
language). They conclude that "theories of language
conducted to the letter (and in the spirit) of such remarks
need no more be about the mind than a piece of set theory is."
I would like to make clear that Syntactic Structures is
explicitly concerned with LF-theory. It proceeds from the
initial characterization of a grammar that C&H cite, to argue
that a partial theory of language understanding can be
developed in terms of levels of representation generated by
grammars of an appropriate sort, and that the theory of such
grammars (LF-theory) can have explanatory power in
accounting for the way sentences are assessed and understood.
Subsequent work has been devoted to the same ends. C&H
assert that this work fails to provide "a proper characteriza-
tion of what the LF contributes to 'linguistic capacities'
broadly construed," and that we "lack a hypothesis " about
the contribution of the LF component to the theory of
understanding. I don't know what they would consider a
"proper characterization," but it is simply not the case that
we lack any hypotheses. There are quite specific hypotheses
in the literature, from Syntactic Structures to the present,
about the structures that are generated by the grammar and
that enter into the understanding of language - hypotheses
concerning anaphora, quantificational structure, assignment
of thematic relations on the basis of abstract syntactic struc-
tures, and many other topics relevant to a theory of under-
standing.
C&H state further that I left "wide open" the possibility of
a theory of understanding and communication (their CS)
without an LF component, and they allege that one can
develop theories of CS without consideration of LF. The first
point is based on a misunderstanding. I pointed out that one
can imagine a system lacking the computational devices of
LF that could be used in a rudimentary way to communicate
and, more significantly, to express thought over a finite
range - e.g., a system with a finite list of names and predi-
cates, the notion of reference and predication, and some
associated use system. We might say that such a system has a
trivial LF component, in which case an LF component is, to
use their terms, always "implicated in the explanations prof-
ferred by the theory of CS." As for their second point, all
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
43

Response / Chomsky: Rules and representations
work on their CS begins with assumptions, generally unana-
lyzed assumptions, about the form and structure of sample
utterances that are investigated. There can be no principled
objection, but surely such work does not undermine an
approach that seeks to examine and account for the unana-
lyzed assumptions - e.g., the sample facts. One would hope
that the latter study would contribute to inquiry into CS
based on unanalyzed assumptions about the form and mean-
ing of utterances. There have been some efforts by "commu-
nication theorists" to approach general questions about form
and meaning in terms of speech acts and similar notions.
These are, I believe, a dismal failure, begging all fundamental
questions (cf. Chomsky 1975, chapter 2).
C&H believe that the study of "linguistic capacities" can
be attacked "without bothering about the LF" - that is,
without bothering about the system of rules and representa-
tions, largely innately determined, that specify the language
and its grammatical properties (which, I have argued, include
quite specific properties that enter into representation of
meaning, - a conclusion that C&H do not contest). To an
extent, this is true. That is, progress can no doubt be made
leaving fundamental assumptions unanalyzed, simply consid-
ering examples that are taken to have certain structural
properties, without concern for the rules and representations
that determine these properties - that is, without concern for
LF, which C&H agree exists and which determines these
properties for the infinite class of expressions of the language.
But surely the study of such capacities can only gain by
integration into a more general theory that includes an
LF-theory, just as the latter can only gain by facing the
empirical test of incorporation into a broader theory that
includes the study of speech acts. C&H appear to disagree;
why, I do not understand.
Dennett. Dennett takes it to be obvious that "there are
innately fixed structural features - design features - that
specifically constrain the development of linguistic compe-
tence in the child," but it is, he says, "gratuitously strong" to
propose that such principles as locality and opacity, or other
proposed properties of universal grammar (UG), are innate.
"Gratuitously strong" in comparison to what? Perhaps in
comparison to some other principles that have been advanced
to account for the "sample facts" and others like them. If this
is what Dennett has in mind, I am sympathetic. In fact,
though it is beyond the bounds of this discussion, I think that
recent work shows promise of deriving such principles as
opacity from deeper principles of UG. But this does not seem
to be what Dennett has in mind. Rather, the proposed
principles are "gratuitously strong" in comparison to some
notion of "learning" and "design structure" that remains
unformulated. One can neither agree nor disagree with this
thesis, because it has no content at all.
Dennett feels that it would be "unwelcome" and "regretta-
ble" if research were to show that such principles as locality
and opacity were innate (in contrast to "design features"
about which we have no idea at all), because this would leave
"the task of explaining the genesis of the design in the
organism" still to be faced. By the same token, it would also
be unwelcome and regrettable if research were to show that
our genetic endowment determines that we grow arms rather
than wings, that we have the kind of digestive and circulatory
system we do, that we develop a human rather than an insect
eye, and so on. Note that even the most far-reaching proposals
concerning innate elements of the language faculty add only
a tiny increment to what is generally assumed without discus-
sion to be attributable to innate endowment. Adapting
Dennett's qualms to bodily organs, any specific proposal that
is put forth about the genetic basis for developing a human
rather than an insect eye should be rejected as "gratuitously
strong" and "unwelcome" in favor of the thesis that some
"design feature" about which no proposal is forthcoming is
responsible.
Dennett agrees that "moving more and more structure into
the category of innate may help us to get a more realistic
picture of the individual capacity for cognition and learning."
Thus, specific hypotheses concerning innate structure - say,
those I suggested - might contribute to a more "realistic
picture" of the problem I have been addressing: namely, the
transition from initial to attained state in cognitive growth.
But he would find this "disheartening" if true because of
some unspecified assumption about the kind of "design
feature" we are to assume innate, and because it remains to
explain the origins of UG - along with the vastly more diffi-
cult problem of explaining the evolutionary origin of all
bodily structures. It is curious to believe that it would be
"disheartening" to discover that some specific structure
results from millions of years of evolution, but "heartening"
to learn that it arises through interaction with the environ-
ment in early life in some manner that remains a complete
mystery.
All of this discussion seems to me completely pointless. I am
interested in developing what Dennett calls a "realistic
picture" of the basis in innate endowment for cognitive
growth: a "realistic picture" of his "design features" that
"specifically constrain the development of linguistic compe-
tence." Dennett offers no reason to suppose that these
features should be of the type he has in mind, whatever that
may be, rather than of the type to which recent research
seems to me to point. Evidence available now seems to me to
suggest that certain specific properties, such as those I
discussed, are innate as part of UG. Dennett finds this
conclusion "disheartening," even if it were to prove "realis-
tic." To me it seems that such conclusions, which would
provide the beginnings of an explanation of how we come to
know what we in fact know, would be "welcome" and
"heartening." In contrast to Dennett, I have no standard by
which I can judge whether these proposals are "gratuitously
strong" as compared to others that remain unformulated, and
I see no reason to accept his view that it would be "welcome"
if the attained state could be explained somehow in terms of
organism-environment interaction rather than in terms of
evolution of the species, whether in the case of arms and
wings, the circulatory system, the visual system, or human
language.
Ghiselin. When I suggest that the mind has a modular
structure, I do not mean to imply that the language faculty is
"radically different from other biological entities," as Ghise-
lin reads me as saying, but rather that, like others, it has
certain distinctive properties. Thus, I would not expect to find
in the language faculty the principles for face recognition, or
in the visual system, the principles of opacity and locality.
Conceivably, properties of one cognitive system relate to
those found in others, as noted in the target article; thus,
opacity and locality involve notions of "prominence" (name-
ly, the special role of the grammatical subject) and bounded-
ness of computation that might well appear elsewhere. We
will be able to make better guesses about these questions
when a number of cognitive faculties are studied to a suffi-
cient degree of depth. Thus I am suggesting nothing that goes
beyond standard assumptions about differentiation of organs.
As for the integration of the language faculty with others,
this is beyond dispute. Even the most radical "modularist"
takes for granted that the language faculty functions in the
most intimate connection with other systems, including those
I mentioned. Thus I do not hold that language functions
"apart from other faculties." Rather, Ghiselin's analogy to the
nervous and endocrine systems is reasonable, for my
purposes.
With regard to the matter of individuals, species, and
44
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Response / Chomsky: Rules and representations
idealization, we are speaking at cross purposes. There is no
doubt that when I dissect a creature, its properties exist apart
from my thinking about them. This is not denied when I say
that an individual organism is an "idealization reflecting a
particular way of looking at things and processes in the world,
which does not come ontologically prepackaged as a set of
individuals with properties (essential or other) apart from our
mode of conception." Ghiselin's formulation, which presup-
poses the identification of the creature and its parts, begs the
question I am addressing. That is, once we have organized the
world into individuals (in accordance with our mode of
conception), these individuals have properties that are real
(though we will perceive and comprehend them in a certain
way, given our mode of conception). But the world could be
viewed differently, with different individuals - a common-
place even within the framework of our modes of conception.
We may think of the creature we dissect as an individual
thing, or we may take a particle of food it ingests as an
individual, tracing its course in an environment, part of
which consists of parts of the creature. Or we can, and
sometimes do, view the world in quite different ways. Noth-
ing in this denies the reality of properties or things.
Nevertheless, the notion of "the creature I dissect" involves
substantial idealization, or, to put it differently, a complex
application of our modes of conception. We assume that it is
the same creature, despite numerous physical changes; we
distinguish the creature from the air it breathes, though the
latter enters into its constitution, and so on. None of this
troubles the person carrying out the dissection, because he
simply adopts a certain mode of conception for specific
purposes, though other ways of organizing the world might be
appropriate for other purposes.
With this in mind, consider the matter of "defining" such
notions as "human language" or "French." The former task
poses questions of a familiar sort, as when we speak of the
"human visual system" as distinct from that of cats or bees. In
speaking in these terms, we abstract away from individual
differences and from interconnections among systems, focus-
ing on one (idealized) element of a complex integrated whole
(which, as noted, represents one of many ways of organizing
the world). We might postulate that some principle for
identifying the structure of a body in motion is a property
(perhaps innate) of the human visual system, and that some
principle (say, opacity or locality) is a property of the human
language system. In this respect, it seems to me useful and
appropriate to think of the human visual system or human
language as analogous to an organ or bodily system, and to try
to characterize their properties, thus, in a sense, "defining the
human visual system" or "defining human language." "De-
fining French" is another matter. There seems to me little
purpose or hope in that. "French" is not a well-defined
linguistic concept, but one that has crucial sociopolitical
dimensions.
Note that I am not adopting the view that there are
"defining" or "essential" properties of individuals, organs, or
species; just properties. We might distinguish properties in
terms of the contribution of genetic and environmental
components, but that is a different matter. For some further
discussion, see Chomsky (1975, chapter 2).
With regard to language diversification and speciation, I
think we can now begin to go well beyond the traditional
analogues, along lines noted on p. 9.
I am not sure that I see the import of Ghiselin's remarks
about iterative structure. These raise questions about physical
mechanisms that realize the abstract properties that we may
hope to identify in the study of language: questions that are
fair enough in principle but that are, so far as I am aware, still
well beyond the bounds of direct investigation.
The same is true with regard to Ghiselin's interesting
speculations with regard to UG. These are questions for the
future. For the present, it seems to me that one primary task is
to identify general properties that can plausibly be attributed
to UG, one element of the human biological endowment. Any
discovery about this topic will leave open many possibilities as
to mechanisms and processes. It is implicit in the approach I
have outlined that any results that might be obtained in a
future "experimental embryology of language" of the sort
that Ghiselin recommends would be a welcome contribution
to this task, and that the relations between these fields should
in principle be reciprocal.
Gottlieb. The work to which Gottlieb refers is not only
congenial to the point of view I discussed, as he indicated, but
also very suggestive as to how such a research program should
be pursued. It would be quite interesting to ask whether
concepts similar to those he mentions are relevant to the
growth of grammar in the domains of syntax and semantics,
as well as phonology.
Harman. The points that Harman makes are well-taken. He
is, first of all, right in saying that my work sheds no light on
analyticity. I am less convinced about what he calls "the real
issue concerning analyticity." The question, I think, is not
"whether assuming or supposing or postulating that some-
thing is true can ever make it true," but whether the concep-
tual system that develops in the mind through the interaction
of innate and environmental factors in fact involves analytic
connections and, correspondingly, determines analytic
connections among expressions of language linked to these
concepts. Such connections, if they exist, are not assumed or
postulated, but just develop without choice. Thus it seems to
me that we face a rather obscure factual question, difficult to
resolve because intuitions are weak and theory is too tenuous
to bear any significant burden. As for the example Harman
discusses, my own (weak) intuitions suggest that if I kept you
ignorant of the fact that you were leaving, so that at no point
did you intend to leave, then I did not persuade you to leave
(I did not succeed in persuading you); and that if there are no
intentions, there is no persuasion. But I would not want to rest
much on these judgments.
With regard to psychological reality, my main point is that
no new problems of principle arise in the study of language
that are not familiar in the "hard " sciences, and that evidence
does not come in two epistemological categories: "linguistic
evidence" bearing on "good theories," and "psychological
evidence" bearing on "psychological reality." Harman and I
agree, I believe, on these points. As for the first, as I noted,
there are serious questions about what is meant when we take
a theory to be true: "what is the status of its theoretical
entities, its principles, its idealizations," and so on. Harman
points out some of these questions, quite appropriately -
though, I think, as his final example shows, it is misleading to
say that "linguistic evidence" merely shows that "the theory
brings order to a given domain" in any sense that does not
hold as well for a theory of click experiments and the like. He
is also right to emphasize that we may ask about the physical
reality of elements of a theory that we take to be true, and
that psychological reality is on a par with physical reality in
this respect. In this connection, he correctly points out an
error in my formulation: there is a question of physical (or
psychological) reality apart from truth in a certain domain, as
Harman explains.
There are interesting examples that go beyond notational
variants in a narrow sense. Thus, suppose we assume the trace
theory of movement rules (cf. Chomsky 1975; 1977).
Consider two theories: (1) generate base structures, which are
mapped to abstract S-structures including trace by transfor-
mations, with S-structures mapped to phonetic representa-
tions by the rules R, and to "logical form" representations
(LF) by the rules R2; (2) base-generate S-structures directly,
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
45

Response / Chomsky: Rules and representations
mapping them to phonetic representation by Rj and to LF by
rules R2 and Ra, where R3 have the properties of the transfor-
mational movement rules (properties distinct from R2) I
believe). These two theories are not notational variants in a
narrow sense, but it is not entirely clear whether they have
different empirical content within the domain of "linguistic
evidence," and it might be argued that on such evidence one
should not attempt to choose between these theories but only
to aim at a more abstract theory of which these are two
specific realizations (for discussion, see Chomsky 1977, chap-
ter 4; 1980, chapter 4; Koster 1978). Real and interesting
questions of this sort arise when theories are given a fairly
precise form, and Harman's comments are applicable to
them.
Hudson. Hudson points out an apparent paradox in my
commitment to a "minimalist" program in linguistics and
simultaneous rejection of a similar approach to cognition. We
should, I think, advocate a "minimalist" approach to cogni-
tive development as well, seeking general principles or
elements that enter into separate cognitive systems. Principles
and elements should not be multiplied unnecessarily. But I
think that to the (limited) extent that we have some under-
standing of specific cognitive systems, we find that they are
based on somewhat different principles, and I think that this
is not an unexpected result. In certain domains, central to
human life, we attain complex and highly articulated systems
of knowledge and belief, yielding subtle and delicate judg-
ments and expectations over a vast (indeed infinite) range,
and we do so on the basis of limited evidence. But the
domains in question are different in the problems they pose,
the opportunities they offer. Therefore, it would not be
surprising to discover preprogramming of quite specific types
for, e.g., identification of objects in space, expression of
thought in language (and derivatively, communication),
recognition of personality, and so forth. See Moravcsik's
comments on modularity.
Marcus's work, which Hudson cites, is important but does
not reach quite as far as he suggests. That is, the constraints of
linguistic theory do not literally "fall out" as a consequence of
the structure of a deterministic parser. Rather, Marcus's
parsing model has properties that are similar to certain
constraints suggested in linguistic theory (in particular, the
principles of locality and opacity). This is a provocative result
deserving closer examination, which would, however, take us
well byond the bounds of this discussion.
Lakoff. Lakoff divides his comments into two parts: on
technical apparatus, and on general observations concerning
the nature of mind. In the first category, his remarks betray
very serious misunderstanding of the work he is discussing.
The transition in my own work from 1965 to the present is
radically different from what he imagines. I am not
concerned now with assessment of this work, but with
description of it. The mid-1960s theories to which Lakoff
refers assumed base rules generating deep structures and
transformations mapping these to surface structures. Both the
base and transformational systems were quite unconstrained,
permitting a wide array of possible base and transformational
systems. In the years since, I and others have attempted to
restrict the variety of both systems. Thus, so-called "X-bar
theory" radically restricts the class of permitted base struc-
tures; and conditions on rules as well as "output conditions"
on surface structure and "logical form" have permitted a
substantial reduction in the class of possible transformations,
perhaps approaching the limit of a single rule "Move A,"
where A is an arbitrary category. Completely misunderstand-
ing these developments, Lakoff assumes that they lead to a
reduction of the depth of transformational derivation and to
making deep structures look "more like surface structures."
But that is not at all true. In particular, the trace theory of
movement rules, which is a central part of these develop-
ments, increases the abstractness of the structures (call them
S-structures) that are formed by transformation and that
underlie actual surface structures, and the rule "Move A" has
roughly the same scope as the numerous specific realizations
of it in the work of the mid-1960s with which Lakoff is
familiar.
There have been, to be sure, significant changes in my own
view as to the role of transformations. I argued in the late
1960s that it was a mistake to treat derived nominals in
transformational rather than lexical terms, thus proposing a
restriction of the depth of transformational derivations; and
work of Kayne and others has brought to light new transfor-
mational processes (e.g., VP-movement in Romance causa-
tives), thus extending the depth of such derivations. Other
examples, of both types, can be cited. But the picture has no
resemblance to what Lakoff describes.
Note that within trace theory a new question arises about
the status of transformations; see the final paragraph of my
response to Harman. Furthermore, arguments have been
advanced in favor of reducing the disparity between deep
and surface structure. Cf. Lightfoot (1979). But Lakoff shows
no awareness of these issues, and his comments have no
relevance to them.
Lakoff further believes that the reason for the allegedly
"radical" shift in my views on the technical details of linguis-
tics is that I have attempted to shore up a belief in modularity
in the face of counterevidence produced by Lakoff and his
colleagues, which showed that meaning and use "affected
virtually every rule of syntax." Thus, to preserve modularity,
it was necessary for me to "redefine and narrow the domain
of syntax." As noted, Lakoff seems completely unaware of the
actual character of the technical work to which he refers.
Furthermore, where I have proposed restrictions on the scope
(rather than the variety) of transformations - e.g., with
regard to nominalization - the motivation was completely
different from what Lakoff suggests, and in fact was internal
to the language faculty, largely syntactic. Semantic facts too
were relevant, in precisely the same respect as they have
always been in my work, since the early 1950s - a matter that
Lakoff has never understood (cf. Chomsky 1972a, chapter 3;
1977, chapter 1). What is more, these proposals were in sharp
opposition to the tendency of Lakoff and others to use
transformations very broadly - far too broadly, I believe.
Other changes in my own work have been motivated by
discoveries about what might be called "the syntax of logical
form," a matter that is internal to the independent language
faculty, in my view. As for "the independence of syntax,"
which Lakoff regards as my "central modularity assump-
tion," note that it is not even mentioned in the essay on which
he is commenting. For my views on this subject, see many
writings from Chomsky (1957) to Chomsky (1977, chapter 1).
My actual concern here is with modularity of the system of
rules that associates phonetic and semantic representation -
what I called "the language faculty. " A good deal has been
learned, I think, about how elements of this relation are
parcelled out among the several components of grammar and
about the nature of these components, including their relative
autonomy, and my own views have certainly changed on this
matter over the past 15 years and will continue to do so, I
presume. But there has been little change in my view
concerning the aspects of language that fall within this
sphere, apart from extensions, as many new phenomena have
been discovered and analyzed. One might argue, perhaps
correctly, that I have been overly conservative in this regard.
My point, however, is that Lakoff's misunderstanding of the
technical work is so far-reaching that his comments on it are
completely irrelevant.
None of this, of course, impugns Lakoffs positive proposal:
46
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Response / Chomsky: Rules and representations
that study of interdependencies and similarities among vari-
ous aspects of cognition will prove more valuable than investi-
gation of specific properties of particular cognitive systems
(about which he is skeptical).
Matthews. Matthews's comments assume a sharper distinc-
tion between abductive theories and growth theories than I
suggested; cf. p. 13 of the target article. But let us put that
aside and turn to his more central points.
We agree that, at some level, much of what is called
"learning" - and in particular, acquisition of grammar -
should be characterized in a "nonintentional, presumably
physiological vocabulary, describing learning as the growth of
a mental organ under suitable conditions of sensory stimula-
tion" (Matthews). But I do not see that this amounts to
abandoning a "rationalist" account of language acquisition in
which "the various processes and state changes thought to
characterize the acquisition process are defined over . . .
contents [of a state]," and innate structure "is characterized
intentionally in terms of both the content of a state and the
learner's relation to that content" (say cognizing). Rather,
these are characterizations at different levels; each may be
correct at the appropriate level. Similarly, the fact that I
know my name would not be challenged, but rather supple-
mented, by an account of how this knowledge is neurally
coded. We might argue that a physiological account of the
growth of a mental organ gives a specific content to the
rationalist account in an intentional idiom; it exemplifies, at
the level of mechanisms, what is meant by "cognizing."
To cognize (know) a grammar and its rules is to be in a
certain state, and to gain that knowledge is to "grow" that
state in the mind/brain. Similarly, suppose that a person
knows that an object moving along a certain trajectory (say, a
parabola) will emerge at a certain point as it passes behind a
screen. The intentional idiom is appropriate for describing
the person's expectations, predictions, and behavior. But we
need not deny that there is a physiological characterization of
the state of the person who has this knowledge, a character-
ization related to this specific element of his knowledge.
Furthermore, it might be true that this knowledge is "un-
grounded" and simply develops (perhaps as a result of trig-
gering stimulation) as a consequence of certain neural coding
that is innately determined, in which case it would be
appropriate, I think, to say that the (implicit) knowledge that
the object will emerge at a certain point is innate. My feeling
is that in substantial domains of human knowledge - roughly,
where we speak of "knowledge of" (of language, of the
behavior of objects, etc.) - an account in terms of internally
represented mental structures is often appropriate, and the
properties of these systems may involve significant innate
determinants. These mental structures can be regarded as
characterizations of certain physical systems, which are the
realization of what we describe in an intentional idiom, quite
appropriately at a certain level. I see no conflict between
reliance on a nonintentional physiological idiom at one level,
and on an intentional idiom at another, either with regard to
states attained or their growth.
Thus I do not think that the "rationalist" should insist, as
Matthews states, that "it is content rather than mechanism
that is innate." Rather, both are; the descriptions are at
different levels. This rationalist, as Matthews states, will insist
that "the intentional idiom [provides] the appropriate charac-
terization of innate structure" at one level of description, but
need not deny that there is an account in terms of a physiolog-
ical vocabulary at a different level of description.
Matthews agrees that the intentional idiom may be appro-
priate with regard to the state attained (as distinct from the
mechanical chess-player, where it is not). This, then, is a
matter of fact, rather as in the case of the missile systems I
discussed. It seems to me that exactly the same is true when
we consider the initial state, or the transition from the initial
to the attained state; that is, the appropriateness of the
intentional idiom, at a certain level, is an obscure matter of
fact. Suppose, to take Matthews's example, that the Structure
Dependency Principle is an element of state attained,
entering into the determination of specific cases of knowledge
that such-and-such a sentence is well-formed with a certain
meaning, while another is not. Suppose further that this
principle is innate, certainly a possibility. Suppose further
that some system of principles of this sort is innate and
becomes a basic element of the state attained by fixing certain
parameters on the basis of experience. Then it would seem
that if the intentional idiom is appropriate (as Matthews
assumes it may be) for the state attained, it is also appropriate
for the initial state and the transition to the state attained, on
grounds of the (assumed) success of a theory of language
acquisition given in these terms. My feeling is that the most
promising theories are of essentially this form. In no way do
they deny realization in terms of physiological mechanisms,
nor would they be refuted or shown inappropriate by the
discovery of such mechanisms, with regard to the state
attained, the initial state, or the transition between them.
McCawley. McCawley believes that in arguing against
tabula rasa theories I have overlooked the fact that even the
most radical empiricism attributes some kind of structure to
the mind. But he is wrong. The point he makes has been
repeated over and over by everyone who has discussed the
topic, myself included (see, e.g., Chomsky 1965, p. 47). What
has always been at issue, quite explicitly, is the character of
the initial structure.
McCawley then states that my discussion has nothing to say
about the origin of language-particular hypotheses and devel-
opmental steps. It is true that it has little to say, but then I
must return the compliment - indeed, generalize it. I assume
that the "origin" of language-particular hypotheses may lie,
in part, in parameters associated with the principles of UG.
These might be fixed by inspection. Consider, for example,
the theory of Rizzi (1978) concerning a complex range of
differences between Italian-type languages and English-type
languages, which he proposes to explain in terms of a slight
difference in the choice of categories relevant to a fixed-
locality principle. If he is right, then exposure to certain
constructions would suffice to fix the parameter, thus yielding
one or another set of conclusions as to the linguistic facts. As
for developmental steps, insight awaits more comprehensive
and systematic analyses of stages attained prior to the rela-
tively steady state that constitutes mature knowledge - a
difficult research task, but one that has been addressed with
some success.
As for the particular case McCawley mentions - namely,
fixing the meaning of assassinate - I am aware of no alterna-
tive to the view that the concepts that enter into the meaning
and conditions on their interconnections are available prior to
the acquisition of the word, and that some of them (e.g., the
"aitiational" elements) are primitive. If so, then the innate
language faculty does make available a range of hypotheses as
to the meaning - a narrow range, presumably, if the word is
learned easily on the basis of limited evidence as to use.
McCawley regards this as "implausible," without, however,
explaining why or suggesting a more plausible alternative.
McCawley has missed the point of my remarks on distin-
guishing learning from growth in terms of properties of the
state attained. As I noted (p. 13), we might do so by speaking
of "learning" in the case where the state attained is a system
of belief or knowledge, but "if we do, then it is not clear that
any coherent notion of 'learning' will remain," for reasons
given there. McCawley takes the criterial property of "learn-
ing" to be individuation; since our mind can acquire knowl-
edge of several languages, acquisition of language is "learn-
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
47

Response / Chomsky: Rules and representations
ing" (so that if it turned out that "coordinate bilingualism" is
impossible, rather only "compound bilingualism," in which
knowledge of one language is built on knowledge of another,
then first-language acquisition would not be "learning").
Clearly, this does not respond to the point I discussed. In fact,
McCawley's proposal raises the problem discussed in a more
severe form than mine did. The body can become accus-
tomed to a certain style of food (say, highly spiced). But it can
accommodate to several such styles. When I receive
eyeglasses with a stronger correction, I slowly come to accom-
modate and to see without distortion, but I continue to see
without distortion when the glasses are removed, so that my
visual system is in "two states" in McCawley's sense. If such
examples constitute "learning," in accordance with McCaw-
ley's criterion, then the prospects for a coherent notion of
"learning" seem even dimmer than if we identify "learning"
in the terms I suggested.
McCawley's next point is that general-purpose cognitive
faculties (say, those involved in learning pairs of nonsense
syllables) might also be involved in language acquisition.
They might indeed, for example, in acquisition of idiosyncra-
sies, as I suggested. As for the "false dichotomy" I am charged
with setting up, it is not formulated in the quote he cites or
elsewhere. The question whether cognitive capacities corre-
spond one-to-one with cognitive domains can be posed only if
"cognitive capacity" and "cognitive domain" are indepen-
dently characterized. I have not done so; nor has McCawley.
Therefore, it does not seem to me that he has posed a
substantive question.
For a response to McCawley's final point, about the
psychological reality of underlying representations postulated
in phonology, see p. 12 of the target article. In the case he
mentions, certain principles of phonology lead to the postula-
tion of an underlying representation for right, righteous,
height, and so on, which accounts for such facts as the vowel
quality in right-righteous (as compared with contrite-contri-
tion), the pronunciation of the t in righteous (as in question,
but not ambition), and the quality of the vowel and the form
of the affix in high-height as compared with wide-width. As
noted on p. 12, phonology is a finite system, so "linguistic
evidence" is weak, but not vacuous, for the reasons mentioned
there. What McCawley calls "psychological evidence" (dis-
tinguishing "linguistic ' from "psychological" evidence in
ways that don't make sense to me) would certainly be
welcome (were it available), as would additional "linguistic
evidence ' of the sort discussed. The question is whether these
kinds of evidence differ in epistemological category. McCaw-
ley evidently believes they do, but he provides no basis for the
distinction.
Moravcsik. Moravcsik's commentary helps considerably, I
think, to clarify the issues that lie at the core of these
discussions, just as earlier comments of his have helped me
personally to gain a clearer understanding of the nature of my
own work, in ways that I have inadequately acknowledged.
Moravcsik's work, some of which I cited, brings such concepts
as "understanding" and "rule structure" to the focus of
concern. His observations on the origins of the preference for
what he calls "shallow theories" also seem to me plausible, as
well as suggestive as a guide to further inquiry.
A. Morton. A. Morton suggests that "modularity tells against
the promise of language as a paradigm of human skill." Here,
the excerpting in the target article has been a bit misleading.
In the full text (Chomsky 1980) I argue along similar lines
that "knowledge of language may not be a central case [or
characteristic kind of knowledge]; nor knowledge of or about
anything else." There are some cognitive systems that seem to
lend themselves to analysis in terms of systems of rules and
representations; others may not. Where an approach in terms
of rules and representations is plausible, the principles of
organization and functioning may vary.
A. Morton also observes that "mental structure does not
entail modularity," by which he means that "primary skills"
may be variously combined in the systems that I have called
"modules." I think the point could be better expressed in
terms of "primary elements," since the notion "skill" seems to
me too narrow and often inappropriate (locality conditions,
for example, are not "skills"). But the basic point is reason-
able. We know too little about mental structures to advance
dogmatic claims, and we should certainly search for more
basic elements that may enter into various cognitive systems,
even if the latter are, as I tend to believe, quite tightly
organized and internally structured in some cases, containing
elements that may well be distinctive and unique. To advance
one speculation, consider the language faculty and the
number faculty, briefly mentioned in the target article and
discussed a bit further in Chomsky (1980). Both involve the
notion of discrete infinity; both appear to be outside the
capacity of other organisms. It is imaginable that, at some
early stage of human evolution, the capacity to deal with
systems of discrete infinity by systems of recursive computa-
tional rules developed in the mind. This may have given rise
to the number faculty (which was exploited only long after) as
well as to the language faculty's computational capacity to
generate an infinity of expressions, with compositionally-
determined structural properties, form, and meaning. This
would thus allow a more primitive conceptual system to be
used for the expression of thought (and, incidentally, for
communication) over a vast domain. If something like this is'
correct, then A. Morton's speculations are much to the point.
J. Morton. I am in sympathy, generally, with J. Morton's
clarification of the notion of levels of characterization, though
I would prefer a different formulation at certain points. Take
the matter of "linguistics ' and "psychology," and the ques-
tion whether "linguistics is actually more abstract than
psychology." Perhaps we can approach these questions in
terms of David Marr's discussion of the varying levels in
terms of which one may analyze and understand "a system as
complex as a nervous system or a developing embryo" (Marr
and Nishihara 1978). He and his colleagues distinguish four
levels:
At the lowest, there is basic component and circuit analy-
sisâhow do transistors (or neurons), diodes (or synapses)
work? The second level is the study of particular mecha-
nisms: adders, multipliers, and memories, these being
assemblies made from basic components. The third level is
that of the algorithm, the scheme for a computation; and
the top level contains the theory of the computation. (Marr
and Nishihara 1978)
They suggest further that "the top level is the most neglected
[and] also the most important," and that current research is
misguided in constructing algorithms without appropriate
prior understanding of the top level. Their own impressive
work on vision lends substance to this analysis (see, e.g.,
Ullman 1979, and the references cited in Marr and Nishiha-
ra). It is this work, incidentally, that I had in mind in several
of the analogies to the visual system in the target article.
Adopting this framework, we may consider the study of
grammar and UG to be at the level of the theory of the
computation. But the same is true of some work in artificial
intelligence (e.g., Marr and his coworkers), and parts of what
everyone calls "psychology" (e.g., Osherson 1976; 1978; Keil
1979; Kosslyn, forthcoming). I don't see any useful distinction
between "linguistics ' and "psychology," unless we choose to
use the former term for the study of the theory of the
computation in language, and the latter for the theory of the
algorithm (taking the other two levels to be the neurophysi-
ology of language). As work progresses, we surely hope to find
48
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

all sorts of interconnections, eroding any initial sense of
disciplinary boundaries. For this reason, I am uneasy with J.
Morton's proposal that perhaps ". . . linguistics is more
abstract than psychology, and is better to be considered at a
different level . . .," and with a distinction between "psycho-
logical" and "linguistic" functions.
The question of localization of language function is one on
which I am not competent to comment, but my own reading
of the literature leaves me less skeptical than J. Morton
appears to be. But even if it were to turn out that there are no
specific areas of the brain in which language function is
localized, still there are surely specific mechanisms involved
in the representation of language knowledge and the capacity
to use this knowledge, and we can hope to discover these.
Hence the question of localization, while an interesting one,
does not seem to me to have overriding importance. In fact,
one might argue that localization is interesting only insofar as
it leads to the discovery of specific mechanisms and their
organization.
Rachlin. Rachlin has not read my article very carefully. For
example, I nowhere refer to all "behavioral shaping" as "fine
tuning" (cf. p. 3); nor do I regard behavior as "irrelevant" to
"empirical work on mental states" - an obvious absurdity.
There are many similar errors, but I will put these aside, and
turn to the major points.
Rachlin's final comments come close to the heart of the
difference between us. His "behaviorist views inference as
useful only in going from observation to observation, whereas
Chomsky seems to view observation as useful only (if at all) in
going from inference to inference." If we replace his term
"inference" by "explanatory theory," we have the beginnings
of a sensible distinction between two points of view. It is true
that I view observation as useful (for my purposes) only
insofar as it provides evidence for an explanatory theory, and
I therefore have no interest in catalogues of observations,
which can easily be constructed on a massive scale. Nor would
I regard theory simply as a device for going from observation
to observation - say, a device for prediction. Rather, I find
observations interesting insofar as they can be used to gain
some understanding of the nature of the system. Observations
of behavior are of interest to me insofar as they can be used to
gain some understanding of the nature of the person carrying
out the behavior. The way to gain such understanding is to
construct a theory of the nature of this system, using what
evidence we can amass (e.g., from behavior) to test and refine
it. All of this seems obvious enough.
To return to the sample facts, I am interested in explaining,
not merely cataloguing, the fact that "the men expect each
other to win" means (roughly) that each expects the other to
win, whereas "the men expect each other will win" is not
well-formed, with the meaning that each expects that the
other will win. These are facts that both Rachlin and I know. I
want to know how we come to know them; what can we learn
about our internal states from such sample facts? If I am right,
an answer at one level is that we have an internal representa-
tion of a grammar that generates these facts, among infinitely
many others; and an answer at a deeper level is that the
language faculty, one subsystem of the mind/brain, is
equipped innately with the principle of opacity, or perhaps
some deeper principle from which it derives. An explanatory
theory is itself a descriptive theory: it postulates properties of
inner mechanisms, rightly or wrongly, and can therefore be
confronted with evidence of varied sorts. I agree with Rach-
lin's characterization, if he means to say that I am interested
in observations, say of the sample facts, only to the extent that
they contribute to this further end.
Rachlin asks why it is "necessary" to develop explanatory
theories of this sort, and to propose them to be true of the
mind/brain (to "hold a behavioral function hostage in the
Response / Chomsky: Rules and representations
human body," in his terms). The answer is that it is not
necessary. One need not be concerned to understand or
explain observations of behavior, just as some person might be
interested in collecting insects or rocks with no further
concern in mind; or one can conceive of an uncurious
engineer who might simply be concerned to predict what
some mechanism will do without caring how or why it does it.
A child is different from a pigeon or a chimpanzee in that,
presented with certain data, it will come to know the sample
facts and myriad others like them. Presumably this is because
the internal structure of the child is somehow different from
that of the pigeon or chimpanzee, surely not merely at the
level of sensory mechanisms, since the same results hold if the
language input is recoded for a different system. It is not
"necessary" to be interested in these properties of the child -
that is, in psychology and biology - or to try to discover and
understand them. But someone who is interested in these
questions will proceed to construct theories of hypothetical
inner mechanisms and will find observations "useful" insofar
as they contribute to these theories.
Rachlin asks in what respect the environment is "impover-
ished." Referring to the sample facts, the environment is
impoverished in that it is surely false that every person who
knows these facts has been provided with specific data or
training indicating that the facts are as they are - data block-
ing the natural inductive step that would interpret the ill-
formed sentence, for example. Rather, this knowledge arises
from properties of the mind/brain on the basis of much more
meager evidence. Our problem is to explain how this comes to
happen. One proposal is that the mind/brain is equipped
innately with the principle of opacity; therefore, given
enough information to determine that each other is a recipro-
cal expression, it applies the innate principle of opacity to
determine the sample facts. Like all efforts at explanation,
this one is hypothetical. Adopting this hypothesis, we will ask
whether other systems of linguistic knowledge reflect the
same principle, and whether other sample facts are accounted
for on the same assumption. One can investigate the truth of
the hypothesis in many other ways. The same is true in all of
the cases that Rachlin believes to be unproblematic: walking,
whistling melodies, building houses, and so on. We can
certainly live our lives without understanding why these acts
have the characteristics they do, without trying to understand
the nature of behavior or its determinants. But here too, if we
hope to understand these questions, we will proceed to
construct explanatory theories that postulate inner mecha-
nisms - mechanisms that distinguish an organism that
behaves in such-and-such a way from another physical system
that does not. Again, all of this seems so elementary that it is
difficult to comprehend why it has to be said at all.
Rachlin asks whether we must assume that the laws of
gravity are "encoded" somewhere inside a stone. The answer
is that we do not, for reasons that are well-known. But we do
have to attribute a property to the stone, namely ' mass.
Amazingly, he thinks that since we do not have to assume the
laws of gravity to be encoded in the stone, therefore we do not
need to attribute specific structure to a child to explain the
specific knowledge that the child attains (say, of the sample
facts). He must then believe that a pigeon or a chimpanzee
will attain this knowledge, indeed any organism will, given
comparable experience (perhaps properly recoded for its
sensory system), just as any organism will obey the laws of
gravity. Note that even if Rachlin does believe this, which I
doubt, it would still leave unanswered the question of how it
happens, of the inner mechanisms responsible.
Rachlin then discusses what he calls various "difficulties."
Since I fail to see in what sense they are "difficulties," I
cannot respond, except to remark that his discussion of
differences between capacity and knowledge in terms of a
"temporal difference" is completely incoherent.
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
49

Response / Chomsky: Rules and representations
Rachlin asks where is the "filter" that passes only content
words (assuming the correctness of a proposed account of
"telegraphic speech"; see p. 6). He assumes that if it is "inside
the child," then we are led to postulate "another child inside
the first child," and he feels that we are led into this
"terminological swamp" by "identifying behavior with
organs of the body." Note first that it would be absurd to
"identify behavior with organs of the body. " As for the
"terminological swamp," only sheer irrationality would lead
one into it. The proposed explanation postulates a certain
property of memory, and change in the system of memory.
The question of the mechanisms of memory is certainly a fair
one, but it is bizarre to suppose that the only approach to it is
to postulate a child inside the child.
Rachlin suggests further that there is no more evidence for
cognitive rules "wholly inside the speaker" than "for the
existence wholly inside the bicycle rider of cognitive rules for
bicycle riding." There are two points here: Is there evidence
for cognitive rules "wholly inside the speaker?" Is there
comparable evidence for the bicycle rider? I discussed the
reasons for a positive answer to the first question. With regard
to the second, I noted that in principle the answer might come
out either way, but there seems to be no reason to suppose the
answer to be positive. Rachlin claims that I did not "deal
with" the question, but it is not clear what he means. If he
means that I did not deal with the first question, he is
obviously wrong, though he might argue that my discussion
was insufficient or inaccurate. If he means that I did not deal
with the second question, he is quite right, but it is no serious
part of my concern in that discussion, for reasons that seem
obvious enough.
I think that Rachlin's comments are instructive. To a
"behaviorist" of this sort, it is simply inconceivable that one
might try to understand what makes a human different from
a bird or a chimpanzee, or why any of these organisms behave
as they do. In his effort to avoid the study of inner mecha-
nisms, he is led to the implicit claim that knowledge of, say,
the sample facts (or innumerable others like them) would
arise in any organism with an appropriate sensory apparatus
simply through the operation of physical laws such as the law
of gravity, no matter what its internal structure might be. For
example, since vast amounts of English have been spoken into
the telephone, it should follow that the telephone exchange
knows the sample facts, and that we should be able to elicit
behavior demonstrating this by experiment. Assuming that
Rachlin rejects such absurdities, his refusal to undertake the
study of inner mechanisms (and his further objection to
anyone undertaking it) simply amounts to a principled refusal
to try to understand the behavior of organisms. I think this is
an appropriate epitaph for a certain style of "behaviorism."
Rollin. Rollin comes close to my own views concerning the
important questions he raises when he suggests that the innate
structures I postulate are both contingent (in that a different
organism might have different structures) and "presupposi-
tional" (or, we might say, "constitutive") for our experience.
Changes in these innate structures would, as he says, lead to a
change in our way of experiencing the world, and might
make our "old world" incomprehensible to us.
What I have suggested about human language might,
certainly, be false. But for present purposes, it is enough that
it might be correct. Let us then tentatively assume that it is,
and see what follows. Suppose that UG, which is an innate
property of the language faculty, brings us to a state where
we know that /,, /2, . . ., given data D, where /,, f2, â¢ â¢ â¢ is an
infinite array of facts about form and meaning like the
sample facts. Then this knowledge-that is not warranted by
or grounded in experience; if UG were different, we would
know that the facts were otherwise, given D, Hence, our
knowledge that so-and-so need not be grounded or justified
knowledge.
Suppose that a child with UG was placed in a nonhuman
speech community characterized by UG' ^ UG and was
presented with the same data D. Then he would again come
to know that /,, /2, . . ., but his knowledge would not
correspond to that of others in the speech community. He
would be wrong about their language, but right (by defini-
tion) about his own. This would lead to all sorts of personal
difficulties for him, but no conceptual ones for us.
UG is not the only faculty of mind. Employing other
faculties, Rollin and I might decide that, henceforth, we will
use the sentence "the men expect each other will win" to
mean that each expects the other will win. We would still
know that the facts of our human language are otherwise, just
as we cannot help knowing the meaning of "chair," even if
we decide to use the term to refer to the square root of two
(the example is a bit misleading, in that naming does encom-
pass arbitrary acts, as distinct from determination of well-
formedness or compositional semantics). Our decision now
constructs for us something that departs from human
language, as defined by UG, but that might be perfectly
usable for communication and translatable to a human
language, namely our human language, the language deter-
mined by the grammar we have come to know through the
exercise of UG. Discussing such a case, Rollin suggests that I
"might respond by asserting that any change in the rules
would result in something that would not be language," a
move he rejects as implausible. But I would not respond that
way, since I do not know what the term "language" means,
and I doubt that it can be given a sense that is useful in this
context. Rather, I would respond by saying that the change
results in something that is not a human language; that is,
that it is not the image of suitable D under UG (which we are
assuming to exist as a component of the human mind).
(Further qualifications are necessary concerning markedness,
but let us ignore these issues.) I don't think that this response is
implausible. It amounts to the recognition that UG is only one
of the components of the human mind. The difficulties that
Rollin cites do not arise. Specifically, systems that are loosely
called "language" may differ cross-culturally, because they
may depart from "human language" through the interven-
tion of other faculties of mind, or because the "languages"
develop under conditions of conflict or diversity of data that
depart from the idealization to a homogeneous speech
community under which UG will map data to a "human
language," in the technical sense of this discussion. Thus
knowledge that /], /2, . . ., within a human language, is not
"empirically changeable, or refutable," in the specific sense
of Rollin's discussion (it is in other senses) - though such
knowledge might not correspond to some system that we or
others use for one or another reason.
Let us turn now to the question of knowledge of the
behavior of objects. First, Rollin is quite right in saying that I
gave no reason to suppose that what is true of language is true
of other faculties, but I do not agree that it is "difficult to
imagine any empirical research that could test the innateness
hypothesis [better, some specific hypothesis about innateness,
since there is no general "innateness hypothesis"] with regard
to our knowledge of physical objects." Suppose, for example,
that it is shown that a kitten with no relevant shaping
experience refuses to step off a cliff (not a hypothetical
example, in this case). Then it would be reasonable to say that
the kitten knows that it will fall; it knows certain facts about
the world. Suppose the same is true of children, as it may well
be. Then it is fair to attribute comparable knowledge to the
child, as an innate property, though perhaps one that func-
tions only with triggering experience, at a certain stage of
maturation, and so forth. Suppose we can show that a child
50
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Response / Chomsky: Rules and representations
lacking relevant grounding experience will extrapolate the
motion of an object along a straight line or a parabola as it
passes behind a screen. Then we can say, quite properly, that
the child seems to know (and may in fact know) that the
object will emerge at a certain point (if not stopped, etc.).
Again, this would be knowledge without grounds: knowledge
that results from the application of certain innate principles
concerning the nature of objects in visual space. Suppose we
can go further, and discover that observing several successive
presentations of an object in motion, the child will determine
that it has a certain shape, perhaps applying the principle of
rigidity suggested by Oilman (1979): the principle that if
successive presentations are uniquely interpretable as motion
of a rigid object, then they are taken to be successive appear-
ances of this rigid object. If indeed these presentations are
stages in the motion of a rigid object of form X, then the child
knows that the object in motion has the form X. Suppose
further that various other properties of objects (say, those
exhibited in perceptual constancies) are known without
grounds on the basis of innate principles. Again, empirical
research might support these conclusions, and, in a limited
way, already does. Assuming results such as these, we could
properly conclude that knowledge of the behavior of objects
is (in these respects) innate, based on such principles as
rigidity, and so forth.
Suppose now that some such story proves true, as it may.
Let us then construct a case analogous to that of the child
exposed to data D in a speech community that has UG' rather
than UG as a biological property. We are assuming that the
child has a system of innate principles P, which lead to
knowledge that /,, /2, . . ., given experience D; and that the
child is placed in a world where things behave differently.
The child's expectations would often be mistaken. Thus, the
child expects that a physical object passing behind a screen on
a parabolic course will emerge at such-and-such a point unless
stopped, deflected, and so forth. It does not emerge at the
expected point. Therefore the child concludes that it was
stopped, deflected, and so forth, or perhaps that it was not a
"physical object" in his sense. We might say that in this world
the child still knows that physical objects behave in such-
and-such a way, but that the things in this world are not
physical objects (in the child's conceptual categorization), or
that there is for some reason no unobstructed motion (in his
sense); or we might say that the cognitive system constructed
by the child's mind does not constitute knowledge in this
world. But still the child has knowledge of the properties of
real objects in the real world, if it satisfies what Rollin calls his
"presuppositions for experience." If he is in a different world,
he is in trouble, but we are not in conceptual trouble. We can
still say that in our real world the child does in fact have
knowledge that /,, /2, ... with regard to the behavior of
objects, though this knowledge is not grounded in or
warranted by experience, but rather results from the applica-
tion to data of certain innate properties of mind.
Actual examples are not difficult to find. Take Cromer's
example of a "conserving" child who argues that some of the
plasticine was lost or stolen, whatever the presented facts, in
the Smedslund experiment that he cites. The principle of
conservation involved in these judgments might be innate,
though perhaps operational only at a certain stage of matura-
tion. The beliefs that the child is using in drawing these
conclusions do constitute knowledge, so far as I can see,
whatever their origin. The real world largely conforms to the
constructed word of experience in this case, though it does not
when mass is converted to energy.
I haven't spoken of the case of mathematics and logic,
which raises other questions about the status of the truths of
these theories. But for the crucial case of knowledge of the
behavior of objects, I think we may discover something like
the following: There are certain innate principles P which,
under appropriate experience and maturation, lead to a
system of rules and representations that provide expectations
about the behavior of objects. They lead to the belief that /,,
/2l. . . , over an infinite range. These beliefs are not grounded
in experience or warranted by experience. If they are true of
the actual world, then they constitute knowledge about the
actual world. Thus, it is correct to say that the child knows
that the object will emerge from behind the screen at a
certain point (unless deflected, etc.), if it happens to be
following a certain trajectory (say, a parabola); that successive
presentations are of a rigid object of structure X, that the
plasticine was lost or stolen, that he will fall if he steps over a
cliff, and so on. If we deny the term "knowledge ' in such
cases as these, then little will be left of "knowledge about the
world. " But such knowledge need have no grounds in any
sense of this term that will carry the epistemological burden
required in empiricist theories.
I have avoided the terms "a priori, " "synthetic, " and so on.
I am not sure that they are appropriate for an account of the
various kinds of human knowledge. I agree with Rollin that
what I have been saying about humans is, if on the right track,
applicable as well to animals, at least prima facie. My feeling
is that the study of human (and animal) knowledge should be
recast in such terms as these. Warrant and justification are not
necessary conditions for much of what we call "knowledge " -
specifically, factual knowledge - and if the concept is
narrowed to exclude these cases, then central areas of what
has been called "knowledge" will be excluded. In some
respects, traditional analysis of knowledge in terms of
warranted true belief may well be appropriate (apart from
Gettier problems and the like); namely, instances of knowl-
edge that do not derive from the structure of our fundamental
cognitive capacities as they grow; for example, knowledge of
scientific fact, which must be acquired through careful exper-
iment and theory construction (in which, I assume, innate
factors must also enter crucially, for reasons I will not discuss
here). In these cases, we must have adequate grounds for our
knowledge claims, or they are worthless. Knowledge comes in
many varieties, and for crucial elements of our knowledge,
the traditional empiricist paradigm seems to me quite inade-
quate. How extensive these elements are remains to be
discovered. Language seems to be one case, and if the
remarks just briefly outlined prove to be somewhere near
accurate, then the same is true of what are regarded as more
"typical" cases of knowledge.
I recognize that these remarks are sketchy and imprecise,
but I see no fundamental reason why they cannot be
expanded and made more exact. Furthermore, it seems to me
that the little that is known about our beliefs, expectations,
and so on, with regard to physical objects suggests that it
might prove quite proper to analyze "knowledge" in the
terms suggested here, in terms of internalized mental struc-
tures (of rules and representations, in some cases), for substan-
tial areas of cognition.
Rosenthal. Rosenthal's thought-provoking comments begin
by distinguishing two different applications of the notion
"modularity": to the state attained, and to the initial state of
the mind. Let's call these "attained" and "initial" modularity,
respectively. Suppose we reject initial modularity and accept
attained modularity. Then we are assuming that "such differ-
entiation as there may be [in the state attained] will reflect
differentiation in the environment" (p. 3 of the target article);
that is, that attained modularity reflects environmental
modularity. I find this implausible in the cases mentioned,
because of the argument from poverty of the stimulus. Thus,
if it is true that the environment does not yield the postulated
principles of UG (say, locality and opacity) or the rigidity
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
51

Response / Chomsky: Rules and representations
principle and others involved in our knowledge about objects
(see response to Rollin), then attained modularity reflects
initial modularity in these respects. While these remarks do
not establish my conclusion that attained modularity in these
respects reflects initial modularity, they do at least indicate
how one could proceed to verify this conclusion. It is this line
of reasoning that underlies the "striking pattern of inference"
to which Rosenthal calls attention, namely, from attained to
initial modularity.
Rosenthal suggests that while this pattern of argument may
be plausible in the case of language, it is "far less credible" in
the case of knowledge of music, mathematics, the behavior of
objects, social structure, human characteristics, and so on. It
seems to me that the plausibility of the argument closely
reflects what we know (or plausibly conjecture) about these
topics: the more we know, the more plausible the inference is.
Take behavior of objects. The work of Marr and his
colleagues, cited above, makes very specific proposals about
levels of visual processing in terms of a "primal sketch"
involving intensity changes, local representation of shape and
orientation of surfaces, axes of elongation and symmetry
("stick figures"), determination of structure from motion by
virtue of the rigidity hypothesis, and so on. It does not seem
likely that these principles of visual processing (assuming they
are valid) operate in the analysis of sound input in terms of
syllables, phonological features, and so on (though one may
find some common properties). If so, we have another case of
attained modularity, which it would be only reasonable to
ascribe to initial modularity. There is, of course, a traditional
view that "higher-level" processes are uniform even if sensory
and perceptual systems are modular; perhaps so, but it seems
to me a dubious argument from ignorance. As for music, it is
not obvious that properties of phrasing, tonality, theme-
and-variation, and so on, can be derived from "well-
understood aspects of the mechanism underlying the pro-
duction of sound," and there is work suggesting that common
features of musical systems may indeed derive from some-
thing innate in the organism (cf. Hindemith 1961; Bernstein
1976; Jackendoff 1977; Jackendoff and Lerdahl, forthcom-
ing).
With regard to the number faculty, we agree that the
concept of adding one, indefinitely, distinguishes our number
system from abilities of other known species, but Rosenthal
adds that understanding this does not "by itself, help us to
understand our capacity to deal with [the number] system." I
think it does help but does not exhaust the matter. It does not
seem to me a "surprising claim" that our mature capacity to
deal with the number system is, in its essentials, innate. On
the contrary, it is difficult to imagine by what inductive,
associative, or other "learning process' this capacity might
have derived from experience (though, as I noted, it may be
triggered by experience). I've heard reports that aborigines
lacking any relevant experience master the number system
very easily when they enter a market economy, which would
suggest, if true, that the capacities are latent, ready to be put
to use. The lack of diversity, which Rosenthal notes, does not
seem to me to be a crucial factor; identification of common
properties of a variety of diverse systems is not a necessary
condition for attribution of innate structure.
I do not quite follow Rosenthal's discussion of the analogy
to chemical properties and underlying physical mechanisms.
It is true that "the mechanisms that produce effects at higher
levels of organization are largely unpredictable on the basis
simply of a knowledge of those effects." My point, however,
was different: that knowledge of these higher level effects sets
empirical conditions to be met by the study of the underlying
mechanisms. This seems to me true in both of the cases I
mentioned: chemical properties - physical mechanisms,
linguistic properties - neural mechanisms. I do not see the
basis for Rosenthal's skepticism about comparable investiga-
tion of musical and mathematical abilities, nor do I follow the
connection he suggests to the issue of psychological reality.
As for the two missile systems, Rosenthal agrees that it is an
empirical problem to determine whether the missile is or is
not a "cognizing" one in my sense; thus in one case we know
it is because "it was so constructed," implying that it is a
matter of fact. He then points out, correctly, that I suggest no
method for determining whether or not a system is of this
type - that is, for settling this matter of fact. But there are no
general methods for determining facts of this sort, in the case
of missiles, cognitive capacity, atomic theory, or whatever. I
would like to recall again the rule of thumb I mentioned in
the text: that it is improper to impose demands on the "soft
sciences" that cannot be met, even for advanced sciences.
Rosenthal observes that conclusions about initial and
attained modularity do not strictly "imply" that much of
what we call "learning" is essentially a matter of growth and
development. That is correct, but they do seem to me to
provide evidence for the latter thesis, if "learning" is under-
stood as the application to arbitrary content domains of fixed
principles of induction, association, and so forth. I do, howev-
er, agree with Rosenthal's conclusion: "the idea of learning as
growth is a further step in the analogy of our cognitive
capacities with physiological system." I think it is a step that
should be explored, to begin with, by sharpening the notions
"learning" and "growth," which could do with much closer
analysis.
Is it indeed unintelligible to propose that "what proposi-
tional knowledge we can have is, to some degree, a function
of our biological endowment," or to imagine that organisms
might "diverge from us in respect of what propositional
content could enter their mental lives"? Such a thesis might
be false, but it does not seem to me "incomprehensible. ' We
can characterize two distinct "cognitive beings," in Rosen-
thal's sense, which differ in "the range of propositions they
could comprehend." Suppose one to incorporate a system of
mereology and the other a system of set theory, for example.
The notion seems intelligible; the question is whether some
such thesis holds of humans. One can imagine several versions
of such a thesis. Suppose that our conceptual capacities,
including principles of individuation, construction of more
complex concepts, abduction, and so on, are the fixed princi-
ples P, by virtue of biological endowment. Then we have a
class of "humanly intelligible theories" that are attainable in
principle by the principles of P. We can then consider a
strong or a weak thesis of "unattainability of theories" for an
organism characterized by P. Some theory T might be liter-
ally not in the range of P, regarded as a function. Or, some
theory might be humanly intelligible in this sense, but at so
far a remove that within realistic constraints of time, atten-
tion, availability of data, and so on (say, within bounds set by
the potential existence of the species), it cannot be attained by
the principles of P. In either case, some other organism can be
imagined for which the inaccessible theories might be readily
intelligible.
In fact, this seems to me not only comprehensible, but even,
conceivably, subject to investigation (see Chomsky 1980,
chapter 6; 1975, chapter 4). It might turn out, for example,
that one could give precise content in this manner to
Descartes' thesis that we may not "have intelligence enough"
to comprehend how free action can be indeterminate, though
it would be "absurd to doubt" that it is so (see Chomsky 1980,
chapter 1). Such an analysis would depart from Descartes'
framework in a number of respects - among them, in recog-
nizing a notion of "human mind" as distinct from "mind. "
In short, I do not think that these speculations are ruled out
on grounds of unintelligibility, nor that general considerations
of the sort suggested in Rosenthal's comments give compel-
ling reason "to seek an alternative to any theory of the
acquisition of knowledge that has this consequence." Natural-
52
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Response / Chomsky: Rules and representations
ly, one should seek alternatives. My own speculation is that
the search for alternatives will be productive in clarifying
their inadequacy, but that, of course, remains speculation.
Sampson. Sampson asserts that he has demonstrated that a
Popperian thesis combined with an argument of Simon's
"predicts" the postulated linguistic universals. Let us distin-
guish two strands of the argument: evolutionary and ontoge-
netic. Only the latter is relevant here. The question is whether
by attributing the Popperian thesis and Simon's assumptions
to the child, as part of its initial state, we can predict that the
child will construct only structure-dependent rules, the prin-
ciples that account for the sample facts, and so on. To be
concrete, the question is whether these assumptions will
account for the fact that, given such examples as "the men
like each other," meaning that each likes the other, the child
will unerringly construct a hypothesis that predicts that "the
men expect each other to win" will mean that "each expects
the other to win," whereas "the men expect each other will
win" is not well-formed, with the meaning that "each expects
the other will win"; similarly, with innumerable other exam-
ples. Nothing in the published literature comes anywhere
near substantiating such a claim, which seems quite a remark-
able one; I cannot, of course, comment on the unpublished
book in which Sampson claims to have provided the demon-
stration he reports. Note that arguments based on the likeli-
hood that hierarchic structure will develop in evolution, such
as the argument of Simon's that Sampson cites, do not seem to
have any bearing on the ontogenetic argument.
As for the rapidity of growth of vocabulary items with
highly specific properties, Sampson is right in saying that I
offered no precise argument, but wrong in saying that the
argument is "wholly empty." His task is to show that, on his
"Popperian assumptions," the specific properties of vocabu-
lary items, and the uniformity with which they are acquired,
can be predicted, given the data available to the child. My
point was qualitative, not precise; namely, that observation of
the specificity, intricacy, uniformity of acquisition, rate of
acquisition, and poverty of the data base suggests the
approach he favors is unlikely of success. Rather, an approach
such as that proposed by Fodor (1975, and subsequent work)
seems to me more plausible, given these qualitative observa-
tions. It is clear what Sampson must do to substantiate his
thesis. One must certainly remain open-minded; personally, I
am not exactly holding my breath.
Schank. Schank purports to speak for "those of us who work
in artificial intelligence." His claim, fortunately, is too broad.
Marshall, in his commentary, is more accurate when he says,
probably with Schank in mind, that "much [not all] work in
'artificial intelligence' thus conflates properties of the
language faculty (e.g., the structural configurations that
determine sentence-internal anaphora) with, for example,
one's knowledge of the appropriate way to behave in restau-
rants. The a priori likelihood that the intersection of these sets
constitutes a theoretically coherent domain is not great." I
think that Marshall is right, and that the work of Schank's
group substantiates his judgment. I will not attempt to evalu-
ate that work here; for an analysis concluding - persuasively,
I believe - that this work has been virtually without issue, see
Dresher and Hornstein 1976; 1977. However, I do want to
stress that work in artificial intelligence (AI) is not limited to
Schank's approach. For example, Marr and Nishihara (1978),
whose work falls strictly within AI, are harshly critical of the
tendency to center research on problems "in which human
skills seem to rest on a huge base of knowledge and expertise"
rather than focusing on components of such problems.
Furthermore, they argue that it is a serious error to con-
struct a "mechanism to mimic some small aspect of
human performance, for example by writing a language-
understanding program . . . applicable only in a highly
specialized domain," as in the work to which Schank refers.
They argue that "such studies are misguided" because they
fail to reveal the basic structure of the problem, and lacking a
theory of the computation and its components, they consider
only "the mechanisms through which their solutions are
implemented." I think that these criticisms are sound and
apply directly to the work that Schank recommends - for
example, the studies that "simply assert that their programs
are their theories and leave it at that." The question goes
beyond the scope of our discussion here, but it should be
understood that Schank in no sense speaks for "artificial
intelligence," as he claims; in my view, its contributions lie
elsewhere.
The issue Schank raises can be clarified by a closer look at
the example he cites. One of my "sample facts" was that (1)
but not (2) is a well-formed question: (1) Which class did the
teacher think that his assistant had told to study the lesson? (2)
Which class was the lesson harder than the teacher had told
that it would be? Schank misunderstood my account of these
facts, but that is unimportant. Consider, rather, his own
reaction to them. He does not propose an explanation for such
facts. Rather, he denies that an explanation should be sought,
since "we do not form questions apart from our desire to
know something." Such facts as these are not worth consider-
ing (or perhaps are not facts) because people are not "silly
enough" to produce such sentences as (1) and (2). It is
therefore of no interest to him that such sample facts about
our knowledge provide evidence bearing on the structure of
comparatives, on general principles of locality, and so on, in
English and other languages. His attitude is like that of
someone who objects to physics on the grounds that in normal
life one doesn't find balls rolling down smooth inclined
planes, let alone more exotic facts.
Schank might have argued, more reasonably, that an expla-
nation for the sample facts will not contribute to his specific
goals. Perhaps, though I doubt it, for reasons implicit in
Marshall's commentary, cited above. But he goes much
further. He states that a theory can only be "relevant" if it is
related to "computer simulations of the communicative
process," that there do not exist mechanisms that account for
the sample facts, and that therefore no such mechanisms have
been developed as part of the state attained. This seems a
rather perverse attitude. Facts do not disappear because we
can think of no way of explaining them, nor do theories
become "irrelevant" if we can think of no way of using them
for some project in which we happen to be engaged.
Schank's statement that "grammars exist in the minds of
linguists only" might be rephrased in a more rational form:
namely, he might have argued that if we had process models
in his sense, they would explain such facts as my sample facts
without recourse to the idea that grammars are mentally
represented. As I have frequently pointed out, this might
prove correct. But Shank does not attempt to argue in this
way. Rather, he denies the existence of the facts, and thus
denies the existence of principles that explain them or mecha-
nisms that satisfy these principles. This is simply a form of
obscurantism.
My paper began with the statement that "I will not attempt
a systematic presentation of ... a model here, "but will rather
keep to some conceptual problems. Schank reads this as a
refusal to "construct specific models" at all, though he knows
perfectly well that in much work not reviewed here quite
specific models have been presented and studied (though not
models for ordering hamburgers). He states that I "dismiss
[my] lack of evidence," though he knows that in these
technical studies a great deal of evidence is presented and
analyzed. This is, again, a curious kind of comment.
Schank objects to my statement that knowledge of
language is not a task-oriented device, on grounds that
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
53

Response / Chomsky: Rules and representations
"people know their language so that they can communicate."
This is an obvious equivocation. I distinguished language
from the "cognizing missile" in that the latter, but not the
former, is designed to carry out a specific task (hitting the
moon). In this sense, language is not task-oriented, whatever
the relation between language and communication may be.
Schank's statement, just quoted, is incoherent as it stands,
though one can imagine what he has in mind. Attempts to
provide some sense to the notion that communication is
somehow the essential property of language have not been
very successful in my view (see Chomsky 1975, chapter 2),
but the question is plainly irrelevant to the point I was
making.
Schank asserts categorically that "it is impossible to
produce a model of language alone." Language does not exist,
he asserts, "apart from beliefs, goals, points of view and world
knowledge." This denial of a proposal concerning modularity
might prove correct. But mere assertion does not constitute an
argument, and one will search in vain, here or elsewhere, for
something that goes beyond mere assertion. In fact, Schank's
refusal to concede even the existence of obvious facts and his
rejection of theoretical work that does not seem to contribute
to his specific projects as "irrelevant" makes clear where such
dogmatism leads.
Schank claims that I "strongly disavow" computational and
psychological experimentation. How one could derive that
conclusion from my paper, or anything else I have written, I
have no idea. It is true that I believe that Schank's approach
has achieved nothing, and will not, because of its strange
built-in limitations, but that does not amount to a "strong
disavowal" of computational and psychological experimenta-
tion.
Schank argues finally that the cognitive sciences "will be in
for difficult times" if they study rules and representations
"without regard for how people actually think and speak, and
without regard for the natural processes that comprise their
ability to do so." Study of the transition from the initial to the
attained state of knowledge is study of a "natural process,"
and study of these states and their properties should contrib-
ute to sensible investigation of how people actually think and
speak. One would also hope that studies of how people think
and speak would yield results bearing on properties of the
initial and attained state, though this seems to me most
unlikely along the lines that Schank proposes, with his narrow
focus on programs applicable only in some highly restricted
domain, his failure to consider "the theory of the computa-
tion" or the components of complex problems, and his lack of
concern for many other questions about the nature of the
systems that interact to produce the phenomena that we
observe in real-life situations.
Searle. Searle begins by stating that his characterization of
my work was not an objection but rather part of an objection
- one that failed, I argued. It is difficult to see the significance
of the distinction. His comments in part recapitulate the
argument to which I have already responded, but with some
modifications. Let us consider now his new formulation.
Let us first be clear about some things that are not at issue.
Searle is not objecting to my usage of the term "rule" to refer
to elements of the kinds I postulate as components of gram-
mars or UG: "Move A," opacity, and so forth. Thus, he argues
that we would have evidence that the elements I postulate are
rules that the person follows if the person could become
aware of the rules and agree that he follows them. Second, he
is not insisting that rules must be accessible to introspection
(though, as we shall see, there remains some equivocation
here). Rather, if they are not, there must be some other
evidence that the postulated rules are rules we follow - rules
that play a "causal role" in behavior, in his usage. And finally,
he does not deny that there might be innate rules of the type I
have discussed, but he insists that there must be evidence
supporting any such hypothesis. With all of this, I agree.
Where then do we disagree? Let us begin by comparing
three kinds of fact: (1) when a person is dropped, he falls; (2)
the person understands the sample facts in the manner
indicated; (3) the person has acquired the knowledge that the
sample facts are as they are on the basis of a certain exposure
to data. How do we proceed to explain these facts?
In each case we proceed by attributing to the person a
certain structure. In case (1), mass; in case (2), an attained
state AS; in case (3), an initial state IS. What is the nature of
AS and IS? We can attempt to characterize these structures at
various levels: e.g., in terms of neural elements, or in terms of
general properties of such elements, I have made certain
proposals, at the second level, in terms of rules, representa-
tions, and principles of computation: AS contains the rules of
a grammar G, and computations using these rules yield the
facts; IS contains the principles of a universal grammar UG,
and AS is determined by fixing the parameters of UG through
experience (inter alia). Returning to the sample facts, if G
contains the relevant rules of English and the mind/brain uses
(follows) these rules in computing representations, then the
person will know that the sample facts about reciprocals, and
so on, are as they are. And if UG contains the principle of
opacity, the person will acquire this knowledge on the basis of
evidence sufficient to establish that each other is a reciprocal
expression, rather than the name of a tree.
Searle argues that this is not enough: "there must be some
independent reason for supposing that the rules are function-
ing causally" for the person, or else the rules are "mere
hypotheses that correctly describe his behavior." Searle states
that I have provided no "independent" evidence that the
rules are more than "mere hypotheses" describing behavior.
There are a number of problems in Searle's discussion.
First, the rules are not hypotheses describing behavior. Rath-
er, our hypothesis (mere or not) is that AS contains a certain
system of rules and that IS contains another system, and that
these rules function in the manner described in the course of
behavior, with what Searle calls a "causal" role. It is quite
important to be clear about this distinction. It is standard
practice to use the term "grammar" ambiguously, referring
to the linguist's theory or the system of rules attributed to the
mind in this theory (similarly, "universal grammar"). But one
must be careful not to be misled by this practice.
Keeping the distinction clearly in mind, let us return to
Searle's criticism. When I say that AS contains the rule "Move
A" and the principle of opacity, among others, and that these
rules are used to form representations that enter into our
judgments and other behavior in the ways described, I am
formulating a hypothesis about AS, about its modes of compu-
tation and representation. But the rule "Move A" and the
principle of opacity (etc.) are not hypotheses describing
behavior. What Searle should have said, then, is that I have
provided no evidence for my hypothesis that AS has the
structure I postulate: namely, that AS contains the rules I
propose and that these rules are followed in the manner
postulated in behavior (e.g., judgment). Thus my hypothesis
remains "mere hypothesis. " But when his objection is
correctly formulated, eliminating the confusion just noted, we
see at once that it is groundless. Though of course the
hypothesis remains "mere hypothesis" (i.e., empirical hypo-
thesis), I have certainly offered evidence to support it,
however one may evaluate the strength of this evidence (an
issue that Searle does not raise in this connection). The
evidence bearing on the hypothesis attributing rules of gram-
mar to the mind is that sample facts are explained on the
assumption that the postulated rules are part of the structure
of AS and are used in computations eventuating in such
behavior as judgments about form and meaning. The
evidence with regard to UG is that properties of states
54
THE BEHAVIORAL AND BRAIN SCIENCES (1980). 3

Response / Chomsky: Rules and representations
attained are explained on the assumption that the principles
are as postulated in IS: the behavior of reciprocals, of indirect
questions, of disjoint reference of pronouns, of purposive
infinitivals, and so on. One might plausibly argue that the
evidence is insufficient or not compelling, or that it is not
opacity but some other principle that is involved, and so on,
but it is certainly false to say that no evidence has been
offered for the hypothesis that AS and IS are as postulated.
Searle's notion of "independent" evidence has not been given
sense. The evidence that has been put forth is certainly
relevant to the truth of the hypothesis that AS and IS are as
postulated, and that their rules are used in the course of
behavior, in the manner proposed.
A second problem in Searle's account is that there is little
sense to the statement that the rules of language, whether the
ones I postulate or the ones that Searle postulates, "cause the
very behavior that they describe and explain" (my emphasis),
even if they enter into behavior. Rules that we follow do not
"cause" our behavior. But let us put this question aside,
accepting Searle's odd usage of the term "cause," and keep to
the first problem.
To Searle, none of the evidence that I have provided is
evidence that the person is following the postulated rules.
Something else is required in principle, some "independent"
evidence over and above the explanatory power of the hypo-
theses. What else? Suppose that the rules could miraculously
be made accessible to consciousness, as in the case of the rules
that Searle has in mind, which are part of what Moravcsik
calls a "shallow theory" of the mind (and which, of course.do
not bear on the kinds of empirical problems that I have been
discussing, as I take it Searle would agree). Then Searle would
agree that we have evidence that the rules are being followed;
in his paper, which I discussed in my target article, he went
further, but now he states, more reasonably, that such intro-
spective judgment would simply provide inconclusive
evidence for the hypothesis that the postulated rules are part
of the state attained. But why is this particular kind of
evidence of such significance? Why would the speaker's
obviously fallible and uncertain intuitions and judgments
about the rules he allegedly follows provide evidence that the
rules are being followed, whereas the kinds of evidence I
discuss (namely, explanation of the sample facts on the basis
of the hypothesis that the rules are being followed) in princi-
ple is not evidence at all? To this question Searle still offers no
response, perhaps because of the confusion with regard to the
status of the rules: not hypotheses describing behavior, but
rather attributed to AS as part of its structure in hypotheses
that purport to explain behavior on the assumption that the
rules attributed to AS are followed in behavior ("cause"
behavior). Once this confusion is overcome, it seems clear that
evidence has been provided (whatever its weight) for the
hypothesis that the rules constitute part of the structure of AS
and are followed in behavior; and further, evidence has been
provided for the hypothesis that the principles of UG consti-
tute part of the structure of IS and play a "causal role" in
determining AS (note that in the latter case, the notion
"causal role" is appropriate, since questions of will and choice
do not appear to enter - AS is determined, it is postulated, by
IS, given experience). Searle has provided no sound argument
against these hypotheses and no support for his claim that no
evidence has been provided for them.
Note that if Searle's fallacious argument had any force, it
would apply as well to other theories of mental computation.
Consider again the theory of visual processing proposed by
Marr and his colleagues (see my response to Rosenthal). This
theory postulates certain computational rules (e.g., those that
provide analysis into "stick figures") that are used in identify-
ing objects, and so on. The rules are not accessible to
consciousness. Empirical evidence has been provided that the
structure of the visual system is as postulated at the appro-
priate level of description; that is, that these rules enter into
computations of certain representations in the course of
identification of objects, and so forth. By Searle's standards,
no "independent" evidence has been provided for the inter-
nal structure postulated, with its rules, representations, and
computations. While there are differences between the two
cases, in the present context the analytic principles proposed
in this theory of vision have the same status as the rules of
grammar attributed to AS in the hypotheses that Searle has
misconstrued as rules.
Searle proceeds to argue that "the heart does not follow
rules, nor does the liver; rather, there are certain general
principles that describe their operations." This is a fact of
type (1), above. In investigating the heart and the liver, we try
to determine the structural properties of these organs that
account for the fact that they conform to the general princi-
ples that describe their operation, attributing these properties
to the organ in question. Again, we can do this at various
levels: in terms of specific physical mechanisms, or more
abstractly in terms of properties of these mechanisms. At the
second level we can ask a question analogous to the one raised
about the two missile systems I discussed, and we will presum-
ably conclude that it would be wrong, in this case, to attribute
to the heart and liver a computational system of rules and
representations of the sort attributed to the cognizing missile,
the visual system, or the language faculty. All of this seems
relatively straightforward in principle, once we are careful to
distinguish hypotheses about the system from elements at-
tributed to the system: in some cases, rules that are followed.
Searle then proposes what he calls "an alternative specula-
tion to the ones that Chomsky makes." To keep things clear,
note that this is an "alternative speculation" to my hypotheses
concerning UG, not concerning grammar. Let us suppose,
with Searle, that "the structure of possible human language is
constrained by the structure of the human brain," by virtue of
"quite specific neurophysiological structures in the brain." So
far there is no disagreement. I also have a proposal as to the
properties of these neurophysiological structures: they have
the properties of UG. What is proposed, at the level of
abstract characterization, is that the specific neurophysiologi-
cal mechanisms that we both assume to exist realize the
principles of UG, and that a grammar results (in part) by
fixing the parameters of UG, this grammar then playing what
Searle calls a "causal" role in behavior. But Searle asserts that
any apparent success of this proposal concerning the structure
of the human brain is "an illusion created by the fact that
actual physical structures in the brain were doing their
work." By parity of argument, it is an "illusion" to suppose
that Marr's principles correctly characterize visual processing
at the appropriate level of abstraction, because they hold only
by virtue of the fact that the brain is doing its work. And more
generally, whenever we succeed in developing a theory that
attributes to the mind/brain certain properties, the success of
this theory is an "illusion" because it does what it aims to do:
account for phenomena on the basis of hypotheses attributing
a certain kind of structure to the brain, which enters into
behavior in a certain way. Note that, in the specific case in
question, the structure that my hypothesis attributes to IS is
(in part) a system of rules and principles, which becomes a
grammar when parameters are fixed, and so on. This is a
particular proposal about IS - about the function that maps
experience into state attained. The rules and principles at-
tributed to UG thus play a "causal role," according to this
theory, in two respects. First, they play a part in causing the
transition from IS to AS, and then, constituting a part of AS,
they "cause" behavior (in Searle's sense).
In short, the rules of UG (assuming this theory to be correct,
and Searle offers no argument that it is not) are not "artifacts
produced by the fact that a common neurophysiological
structure constrains actual rules" of grammar. Rather, the
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
55

Response / Chomsky: Rules and representations
rules and principles of UG form part of a characterization of
this common neurophysiological structure at the mental level
of characterization, and they also form part of the characteri-
zation of the state attained, at the same level. Note that Searle
does not object to describing systems such as the brain at these
two levels: in terms of mechanisms, in terms of general
properties of such mechanisms (rule systems, in some cases).
Turning now to state attained, rather than initial state, he
agrees that in his "alternative" there would be "a mental level
where we describe how actual rules and representations
function causally" and a neurophysiological level in which
these rules and representations are "realized." Adopting still
his usage of the term "causally," we may say that the rules
and principles of UG (in IS) and of the grammar (in AS)
function causally, in the manner already indicated. Where
then is the disagreement? We can disentangle it from Searle's
statement that "Chomsky's claim is that there is another level
of rules beyond all possible introspection but not neurophy-
siological either" (my emphasis); that is, a level of rules that is
neither mental nor physiological in the sense just described.
True, the rules of grammar and of UG that I postulate are not
"neurophysiological," but rather neurophysiologically real-
ized, in the sense that both he and I agree to be legitimate.
Why then are these rules not at Searle's "mental level "?
Precisely because they are "beyond all possible introspec-
tion"; that is the only relevant property that they lack. Once
again, as in his original article, Searle has been trapped by his
completely unwarranted assumption that rules can be attrib-
uted at the "mental level of characterization" only if they are
open to introspection. While Searle now explicitly denies that
he is making this assumption, as soon as we actually eliminate
it, as we must, his error appears clearly. My hypothesis, to
which he refers, is that the rules in question are at his "mental
level," even though they are "beyond all possible introspec-
tion," and the evidence for this hypothesis is the kind of
evidence I have reviewed, which counts as evidence that the
rules have "causal efficacy" (in his sense).
We are left with certain theories of grammar and UG that
are offered as an account of AS and IS. These theories offer
hypotheses as to the rules, representations, and computations
that enter into behavior. The hypotheses concerning AS and
IS may be right or wrong, but Searle has offered no argument
whatsoever bearing on this question, nor any alternative
account to be considered.
Sober. The points Sober raises can be clarified, I think, if we
are careful once again to distinguish between (i) the linguist's
hypothesis that such-and-such a rule is part of the mentally-
represented grammar, and (ii) the rule so attributed. Thus, let
R be a rule and H(R) the hypothesis that this rule has what
Sober calls "some appropriate causal role"; H(R) attributes R
to the mind/brain and asserts that computations eventuating
in behavior use R.
Sober begins by stating that "a psychological hypothesis
will be entitled to [the label 'psychological reality] if it is the
best explanation available," in my view. Thus H(R) is entitled
to this label if it is part of the best theory dealing with the
speaker's judgments, and so forth. Rut he then shifts his
ground and says that "rules have psychological reality," in
accordance with "a fairly standard construal of the idea" of
psychological reality, only if they "play some appropriate
causal role." But this "standard construal" refers not to the
psychological reality of H(R), but of R, a different matter. Let
us distinguish the two notions PR(theory) and PR(entity);
respectively, psychological reality of a theory and its
hypotheses, such as H(R), and psychological reality of entities
such as R attributed by the theory to the mind/brain. Sober's
comparison of my view with the "standard construal" thus
involves a crucial equivocation between PR(theory) and
PR(entity).
Turning now to the physical analogy that Sober discusses,
note that it is misleading in one respect: hypotheses such as
H(R) are not analogous to laws of nature, but rather to
hypotheses about the structure of particular systems such as
the sun or the human visual system. Let us therefore recast
Sober's argument in these more appropriate terms, which
does not affect its thrust. Suppose that the theory T(sun) states
that the sun contains Helium and the theory T(vision) states
that the human visual system contains edge-detectors. Then
T(sun) and T(vision) are analogous to H(R), and Helium and
edge-detectors are analogous to R.
Sober begins by comparing attribution of physical reality to
theories such as T(sun) and T(vision) with attribution of
psychological reality to rules (note again that I have
reformulated his argument, replacing "laws of nature" by
theories of specific systems, as is appropriate in this context).
But this is an equivocation, for the reasons just noted. Let us
then reformulate the argument to eliminate the equivocation.
Let us accept Sober's statement (now properly reformulated)
that if T(sun) and T(vision) have physical reality, and some
theories T'(sun) and T'(vision) are logically equivalent to
them, then T'(sun) and T'(vision) also have physical reality.
Analogously, if H(R) has PR(theory) and some hypothesis
H'(R) is logically equivalent to it, then H'(R) has PR(theory).
So far there is no problem.
Turning next to PR(entity), Sober argues that if R has
PR(entity), and Y is "logically guaranteed to be input-output
equivalent" with R, then it does not follow that Y has
PR(entity). The analogue would be a situation in which
Helium has the physical analogue of PR(entity) with respect
to the sun, and some entity Y is "logically guaranteed" to have
the same empirical effects as Helium in the sun (similarly,
edge-detectors in the visual system). But, Sober's
reformulated argument asserts, it does follow that Y has
physical reality, so physical and psychological reality are
different. But now that the equivocation is removed, it is
difficult to make any sense of the argument. To say that two
entities are "logically guaranteed" to have the same empirical
effects ("to be "input-output equivalent") is simply to say that
the theories postulating them are logically equivalent and
hence have the same "reality" at the level of PR(theory). But
the theory of English has the same status as the theory of the
sun or of vision in this regard, and the same is true of the
elements they postulate. There is no distinction of
intensionality. Thus Sober's objection has no force.
There are some subtleties that should be kept in mind.
Thus, consider two theories of representation of meaning in
human language, one that holds that grammars generate
representations using one notation (say, familiar quantifier-
variable notation) and another that holds that grammars
generate representations using a different notation (say,
variable-free notation). These notational systems might be
equivalent in the sense that anything expressible in one is
expressible in the other: inferences match, and so on. But
nevertheless the two theories may be empirically different. In
fact, this seems to be true in the case in question; cf. Chomsky
(1975; 1977; 1980).
Similar questions arise when we consider more carefully
Sober's reference to rules that are "logically guaranteed to be
input-output equivalent" but yet do not, in his view, neces-
sarily have the same status at the level of PR(entity). Above, I
assumed that he meant that the theories postulating these
rules were logically equivalent, but one might give a different
interpretation to his contention. Suppose that linguistic theory
LT assigns a grammar G to a certain language, while linguis-
tic theory LT' assigns grammar G' to this language. Suppose
that G and G' are strongly equivalent in the sense that they
not only generate the same set of strings but also assign to
them the same structures (a notion that can be made precise).
56
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

Response / Chomsky: Rules and representations
Suppose further that G and G' differ by only one rule, R in G
and R' in G'. Suppose further that from inspection of LT and
LT' we can deduce the strong equivalence of G and G'.
Perhaps this is what is meant by saying that R and R' are
"logically guaranteed to be input-output equivalent." If so,
does it then follow that there is no empirical difference
between G and G', R and R'? No, it does not. For example,
investigation of some other language might reveal that there
is empirical evidence for a certain general property in linguis-
tic theory that permits R but not R'. Or, R and R' might yield
derivations that differ in some property (say, length), and
psycholinguistic experiment might support one but not the
other consequence. In principle, there are many possible
kinds of evidence that might bear on the choice between,
respectively, R-R', G-G', and LT-LT'. Thus, while Sobers
conclusion (now reformulated) that PR(entity) for R does not
imply PR(entity) for R' is correct, this has nothing to do with
intensionality; and furthermore, the same considerations
apply to the analogue of PR(entity) with regard to Helium,
edge-detectors, and so on.
Sober's second objection is that, among the hypotheses that
are psychological in their subject matter and true, only some
are "psychologically real" in the sense that they postulate
mentally-represented rules that are followed in computations
eventuating in behavior. Other such hypotheses may not
attribute mechanisms, or may be true by virtue of properties
of the vocal organs, for example. The distinctions are worth
noting, and I have no objection to the use of the term
"psychologically real" in the specific sense that Sober
suggests, though my own inclination, as noted in the target
article, is to avoid the term altogether as seriously misleading,
just as the term "physically real" is rarely used in the natural
sciences. See, in this connection, Harman's comments and my
response.
Consider, finally, the alternatives that Sober suggests to my
"psychological interpretation" of linguistic hypotheses. Sober
suggests that these hypotheses might be taken to describe
"social regularities" or "abstract mathematical structures."
But then we surely want to know why there are these social
regularities and not others, or why we consider these abstract
mathematical structures and not others. Surely the facts
might be otherwise. The principle of opacity, for example,
need not be true of English or other languages. For some
aspects of language - say, the irregular past tense of go - it
may be correct to attribute our shared knowledge to
something like "social regularity," but, for the reasons I
discussed, this seems highly unlikely in the case of the
"sample facts" and such principles as opacity. I can see no
reasonable alternative to the assumption that the opacity
hypothesis and many others like it are true (if they are)
because the mechanisms are as postulated rather than of some
other sort. Even in the case of "shallow rules" in Moravcsik's
sense, such as the rule giving the past tense of go, we are led to
postulate mechanisms, though the matter is relatively
uninteresting in this case. When we turn to more significant
properties of language, the same move is appropriate, but
with far more interesting results, if we hope to understand
how "social regularities" are observed or how the relevant
cognitive systems arise, or if we are sufficiently curious as to
ask why certain abstract mathematical structures are relevant
to the study of language while others, no less plausible on a
priori grounds, are not.
Stich. Stich raises two important questions: (1) about
knowledge, and (2) about universals. Let me take the second
first, since it seems more readily addressed.
First, I do accept the answer that Stich felt to be an
"unlikely interpretation" of my views: namely, that all
evidence (from linguistic intuitions, psychological experi-
ment, brain damage, cognitive simulation, etc.) is potentially
relevant to determining what the internally represented
grammar is. Now to the difficulty that, Stich suggests,
"quickly emerges elsewhere."
Stich alleges that I argue that if we have evidence of the
sort he outlines for some principle (say, locality), then I go on
to infer that "the principle that is radically underdetermined
by the evidence available to the learner must be a universal
feature of all languages." He comments that this inference
does not follow. I agree, and would not argue for necessity,
only plausibility. In fact, "conditional universals" have often
been proposed. But let us take the hypothetical case Stich
proposes at the end of his commentary. Given the two
alternatives he suggests, anyone would certainly choose the
assumption that the category A principles are universal in the
absence of evidence to the contrary, in favor of the pair of
conditionals. The reasons for such choices deserve considera-
tion, but not in the present context. They do not bear
specifically on psychology or linguistics.
The first question seems to me a more difficult one. Stich
and others have argued that "unproblematic cases of knowl-
edge" have certain properties not shared by "knowledge of
the rules of grammar." One difference is accessibility to
consciousness, and if this were the only difference, we could
simply say that "cognizing" in my sense is just unconscious or
tacit knowledge: something that we would call knowledge if
it were conscious. But Stich suggests another distinction:
namely, the unproblematic cases "form a highly integrated
inferential system" whereas material internally represented
in some other way involves principles "inferentially insu-
lated" from factual belief. But here problems arise. Take our
shared knowledge of the sample facts: e.g., that "the men
expected each other will win" is not well-formed, with the
meaning that each expected the other will win. This seems to
me a relatively unproblematic case of propositional knowl-
edge - knowledge that so-and-so. But this case forms part of a
system containing inferentially insulated principles, accord-
ing to Stich's account. Or suppose that our knowledge that an
object on a parabolic course passing behind a screen will
emerge at such-and-such a point is based on an innate
principle P. For present purposes it is enough that this might
be true, that there is nothing incoherent in assuming it to be
true. This case of knowledge-that also seems unproblematic,
indeed rather typical of much of the discussion in the litera-
ture. But if matters are as just suggested, then both of these
unproblematic cases form part of a highly integrated system
(though perhaps not strictly an "inferential" system) includ-
ing principles (opacity, P) that are unconscious, innate, and
perhaps inferentially insulated (see response to Rollin). The
integrated systems may not have the properties that Stich
requires. Furthermore, the elements of this system, even the
unproblematic cases, might very well lack what are generally
taken to be crucial features of knowledge: specifically,
grounding and warrant. Thus it does not seem to me clear
that the allegedly unproblematic cases have what are often
regarded as typical properties of knowledge.
As for the modular approach to systems of knowledge that
Stich suggests, it is, as he says, quite congenial to my view,
though I suspect that many of the core beliefs that constitute
what might be called our "common-sense understanding" of
things and events around us are parts of integrated systems
with crucial elements that are inaccessible to consciousness,
possibly innate, and perhaps inferentially insulated or consti-
tutive.
Van Gulick. Van Gulick's comments are quite apt, but they
somewhat mistake my intentions. In introducing the notion
"cognize," I did not hope to sidestep the problems of analysis
of knowledge, but rather to focus attention on them in
preference to other questions that seem to me less interest-
ing - e.g., whether accessibility to consciousness is a necessary
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
57

References /Chomsky: Rules and representations
feature of what someone would call "knowledge." I do not
think I was begging any questions in saying that if a person
could become conscious of the rules of his grammar, we
would not hesitate to say that he knew these rules, given the
way they interact to produce cases that no one hesitates to call
"knowledge" (e.g., the sample facts). But this leaves open the
more interesting question of the nature of the structures and
processes that enter into what we call "knowledge" when
there is no issue of accessibility, and what we would call
"knowledge " when this issue is set aside.
Thus I had intended to identify a certain domain of
problems in introducing the concept "cognize." A person
cognizes that a string of expressions has certain properties,
that an object passing behind a screen will emerge at a certain
point, and so on; and the person also cognizes the principles
and rules that enter into determining these items, whatever
their origin, in the case of cognitive systems of rules and
representations. (I do not suggest, however, that "the
language faculty cognizes that the rules . . . are thus-and-
such.') But I agree with Van Gulick that the interesting
questions arise right here: the problem is to analyze the kinds
of content and processes that enter into "cognizing." Here
there is no substitute for the detailed study of specific
cognitive systems: language, object identification, and so on.
Thus Van Gulick is quite right to say that "the shift from
'know' to 'cognize' leaves intact all those problems about how
to specify the content of what is cognized, which can only be
resolved by appeal to detailed theories about the internal
processes involved."
I think that Van Gulick's characterization of "information
possession" and "the content of information" may be too
narrow. An organism may possess information about some
event (say, the hour that Napoleon was born) without being
structured "to interact successfully with the world along the
lines of its ends or interests" by virtue of possession of this
information. One may have no relevant ends or interests and
no way of interacting with the world related to this informa-
tion (apart from answering questions on a quiz show, in which
case the notion trivializes). Furthermore, two people may
possess information that is "identical in content" though they
would use it quite differently; say, a tall and short person
knowing that a desired object is at a certain height from the
floor (which is not to deny Van Gulick's specific point about
the earthworm and the person). Van Gulick's reference to
causal theories of knowledge is to the point and is discussed
briefly in Chomsky (1980). He is right in thinking that I find
much of this work close to my own views, though I think it
tends to underestimate the importance of integrated mental
structures and sometimes to misconceive the nature of innate
elements.
As for the discussion of "selective" and "instructive"
processes and levels of description, Van Gulick is again right.
Note that Jerne (1967) makes essentially the same point when
he distinguishes "between learning and selection in terms of
levels of analysis " (cf. p. 14 of my paper). This of course
leaves open the question of which higher level processes
should properly be called "learning, " even at the more
abstract level of analysis - a question that can only be
resolved by further conceptual analysis and empirical discov-
ery. The directions Van Gulick outlines may well contribute
to this end.
References
Adinolfi, M. (1978) The immune system and the brain. Developmental 
Medi-
cine and Child Neurology 20:509-16. 
(JCM]
Andor, J. (1978) Case grammar, deep semantic relations and cognition. In:
W. U. Dressier and W. Meid, (eds.) Proceedings of the Twelfth Interna-
tional Congress of Linguists, pp. 163-66. Innsbruck: Innsbrucker Beitrage
zur Sprachwissenschaft, 
[JA]
Aslin, R. N., and Pisoni, D. B. (1980) Some developmental processes in speech
perception. In: G. H. Yeni-Komshian; J. F. Kavanagh; and C A. Ferguson
(eds.) Child phonology: perception and production. New York: Academic
Press. 
[CC]
Bard, J. B. L. (1977) A unity underlying the different zebra striping patterns.
Journal of Zoology, London 183:527-39. 
[JCM]
Beilin, H. (1975) Studies in the cognitive basis of language 
development.
New York: Academic Press. 
[RFC]
Bellugi, U. (1967) The acquisition of the system of negation in children's
speech. Unpublished doctoral dissertation. Harvard University. 
[RFC]
(1971) Simplification in children's language. In: R. Huxley and E. Ingram
(eds.) Language acquisition: models and methods, pp. 95-119. London
and New York: Academic Press. 
[RFC]
Bernstein, L. (1976) The unanswered question. Cambridge: Harvard Univ.
Press. 
(NC]
Bever, T. C. (1970) The cognitive basis for linguistic structures. In: J. R. Hayes
(ed.) Cognition and the development of language, pp. 279-362. New
York: John Wiley & Sons. 
[RFC]
Bever, T. G.; Lackner, J. R.; and Kirk, R. (1969) The underlying structures of
sentences are the primary units of immediate speech processing. Percep-
tion and Psychophysics 5:225-34. 
[GH]
Blakemore, C. (1973) Developmental factors in the formation of feature ex-
tracting neurons. In: F. O. Schmitt and F. G. Worden (eds.) The neuro-
sdences: third study program. Cambridge: MIT Press [NC]
Blank, M.; Gessner, M.; and Esposito, A. (1978) Language without communica-
tion: a case study (Mimeo). Dept. of Psychiatry, Rutgers Medical Sch. Pis-
cataway, N.J. 
[NC]
Bower, G. H.; Black, J. B.; and Turner, T. J. (1979) Scripts in text comprehen-
sion and memory. Cognitive Psychology 11:177-220. 
[RCS]
Bradley, D.; Garrett, M. F.; and Zurif, E. (1979) Syntactic deficits in Broca's
Aphasia. In: D. Caplan (ed.) Biological studies of mental processes. Cam-
bridge: MIT Press. [JM]
Bresnan, J. (1978) A realistic transformational grammar. In: M. Halle; J. Bres-
nan and I. Miller (eds.) Linguistic theory and psychological reality. Cam-
bridge: MIT Press. 
[JM]
Bruner, J. S; Goodnow, J. J.; and Austin, G. A. (1956) A study of thinking.
New York: John Wiley & Sons. 
[RFC]
Bryant, P. (1974) Perception and understanding in young children: an experi-
mental approach. New York: Basic Books. 
[NC]
Catlin, J. (1978) Discussion of the chapters by Stolzenberg and Chomsky. In:
G. A. Miller and E. Lenneberg (eds.) Psychology and biology of language
and thought, pp. 271-80. New York: Academic Press. 
[RFC]
Chomsky, N. (1957) Syntactic structures. The Hague: Mouton. 
[NC, RC]
(1962) Explanatory models in linguistics. In: E. Nagel; P. Suppes; and A.
Tarski, (eds.) Logic, methodology, and philosophy of science. Stanford:
Stanford Univ. Press. 
[RJM]
(1965) Aspects of the theory of syntax. Cambridge: MIT Press. 
[NC, JDM,
RJM]
(1967) The formal nature of language. In: E. H. Lenneberg (ed.) Biological
foundations of language. New York: Wiley. 
[NC, RFC]
(1968) Language and mind. New York: Harcourt Brace & World. [GS]
(1969) Some empirical assumptions in modern philosophy of language. In:
S. Morgenbesser; P. Suppes; and M. White (eds.) Philosophy, Science and
Method (Essays in honor of Ernest Nagel) New York: St. Martin's Press.
(1972) Language and mind. New York: Harcourt Brace Jovanovich. 
[NC]
(1972a) Studies on semantics in generative grammar. The Hague. Mou-
ton. 
[NC]
(1973) Problems of knowledge and freedom. London: Fontana. 
[GS]
(1975a) Reflections on language. New York: Pantheon. 
[NC, GH, GL,
JDM]
(1975b) Knowledge of language. In: K. Gunderson (ed.) Language, mind
and knowledge. Minneapolis. Univ. of Minnesota Press. 
[NC]
(1976a) Reflections on language. London: Temple Smith. 
[GS]
(1976) On the nature of language. In: Hamad, S. R.; Steklis, H. D.; and Lan-
caster, J. (eds.) Origins and evolution of language and speech, p. 280. An-
nals of the New York Academy of Sciences. 
[NC]
(1977) Essays on form and interpretation. New York: North Holland Else-
vier. 
[NC]
(1978) A theory of core grammar. Clot 1:7-26. 
[JCM]
(1980) Rules and representations. New York: Columbia Univ. Press. 
[NC]
(Forthcoming) Human language and other semiotic systems. Semioti-
ca. 
[NC]
and Halle, Morris (1968) The sound pattern of English. New York: Harper
and Row. 
[JDM]
and Lasnik, H. (1977) Filters and control. Linguistic Inquiry 7:425-
504. 
[JCM]
58
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

References /Chomsky: Rules and representations
Clark, K. V. (1971) On the acquisition of the meaning of before and after.
Journal of Verbal Learning and Verbal Behaviour 10:266-75. [RFC]
(1973a) How children describe time and order. In: C. A. Ferguson and D. I.
Slobin (eds.) Studies of child language development, pp. 585-606. New
York: Holt, Rinehart, and Winston. [RFC]
(1973b) Non-linguistic strategies and the acquisition of word meaning. Cog-
nition 2:161-82. [RFC]
Coltheart, M; Patterson, K.; and Marshall, J. C, (eds.) (1980) Deep dyslexia.
London: Routledge and Kegan Paul. [JCM]
Cooper, D. (1975) Knowledge of language. New York: Prism Press, London
and Humanities Press. [SPS]
Cromer, R. F. (1968) The development of temporal reference during the ac-
quisition of language. Unpublished doctoral dissertation, Harvard Univer-
sity. [RFC]
(1974) The development of language and cognition: the cognition hypothe-
sis. In: B. Foss (ed.) New perspectives in child development, pp. 184-252.
Harmondsworth, Middlesex: Penguin Books. [RFC]
(1976a) The cognitive hypothesis of language acquisition and its implications
for child language deficiency. In: D. M. Morehead, and A. E. Morehead
(eds) Normal and deficient child language, pp. 283-333. Baltimore,
Maryland: University Park Press. [RFC]
(1976b) Developmental strategies for language. In: V. Hamilton, and M. D.
Vernon (eds.) The development of cognitive processes, pp. 305-58. Lon-
don and New York: Academic Press. [RFC]
(in press) Reeonceptualizing language acquisition and cognitive develop-
ment. In: R. L. Schiefelbusch, and D. Bricker (eds.) Early language inter-
vention. Baltimore: University Park Press. [RFC]
Curtiss, S. (1977) Genie: a psycholinguistic study of a modern-day "wild
child." New York: Academic Press. [NC]
Danto, A. C, and Morgenbesser, S. (1957) Character and free will. Journal of
Philosophy 54:502. [NC]
Davis, L., and Gardner, H. (1976) Strategies of mastering a visual communica-
tion system in aphasia. In: Hamad, S. R.; Steklis, H. D.; and Lancaster, J.
(eds.) Origins and evolution of language and speech. Annals of the New
York Academy of Sciences: 280. [NC]
Denenberg, V. H.; Carbanati, J.; Sherman, C; Yutzey, D. A.; and Kaplan, R.
(1978) Infantile stimulation induces brain lateralization in rats. Science
201:1150-51. [NC]
Dennett, D. C. (1975) Why the law of effect will not go away. Journal of the
Theory of Social Behavior 5:169-87. [NC]
(1978) Brainstorms. Montgomery, Vt.: Bradford Books. [SPS]
Dennis, M. (1978) Language acquisition in a single hemisphere: semantic orga-
nization. In: D. Caplan (ed.) Biological studies of mental processes. Cam-
bridge: MIT Press. [NC]
(1980) Capacity and strategy for syntactic comprehension after left or right
hemidecortication. Brain and Language 10. [JCM]
and Whitaker, H. (1976) Language, acquisition following hemideeortica-
tion: linguistic superiority of the left over right hemisphere. Brain and
Language 3:404-33. [NC]
Dewart, M. H. (1975) A psychological investigation of sentence comprehension
by children. Unpublished doctoral dissertation. University College, Lon-
don. [RFC]
Donaldson, M. (1978) Children's minds. Glasgow: Fontana/Collins. [RFC]
and Balfour, G. (1968) Less is more: a study of language comprehension in
children. British Journal of Psychology 59:461-72. [RFC]
and McGarrigle, J. (1974) Some clues to the nature of semantic develop-
ment. Journal of Child Language 1:185-94. [RFC]
Donnellan, K. S. (1977) Review of Gunderson. Language. 53(3). [NC]
Dresner, B. E., and Hornstein, N. (1976) On some supposed contributions of
artificial intelligence to the scientific study of language. Cognition 4:321-
398. [NC]
(1977) Reply to Schank and Wilensky. Cognition 5:147-49. [NC]
Ferreiro, E. (1971) Les relations temporelles dans le langage de I'enfant.
Geneve: Librairie Droz. [RFC]
and Sinclair H. (1971) Temporal relations in language. International Jour-
nal of Psychology 6: 39-47. [RFC]
Fillmore, C. J. (1975) An alternative to checklist theories of meaning. In:
C. Cogen et al. (eds.) Proceedings of the First Annual Meeting of the
Berkeley Linguistics Society, Berkeley, pp. 123-31. [JA]
(1977) The case for case reopened. In: P. Cole and J. M. Sadock (eds.) Syntax
and Semantics Vol. 8., Grammatical Relations, pp. 59-81. New York: Aca-
demic Press. [JA]
Fodor, J. A. (1975) Language of thought. New York: Thomas Crowell. [NC,
HR]
Fodor, J. D. (1978) Parsing strategies and constraints on transformations. Lin-
guistic Inquiry 9:427-73. [JCM]
Frankfurt, Harry, (1977) Descartes on the creation of the eternal truths. The
Philosophical Review, LXXXVI:36-57. [DMR]
Galaburda, A. M.; Sanides, F.; and Geschwind, N. (1978) Human Brain: Cyto-
arehitectonic left-right asymmetries in the temporal speech region. Ar-
chives of Neurology 35:812-17. [JCM]
Gardner, H.; Zurif, E.; Berry, T.; and Baker, E. (1976) Visual communication
in aphasia. Neuropsychologia 14:275-92. [NC]
Chiselin, M. T. (1974) A radical solution to the species problem. Systematic
Zoology 23:536-44. [MTG]
(1978) The economy of the body. American Economic Review 68:233-37.
(1980 In press) Natural kinds and literary accomplishments. Michigan Quar-
terly Review. [MTG]
Glass, A. V.; Gazzaniga, M. S.; and Premack, D. (1973) Artificial language
training in global aphasics. Neuropsychologia 11:95-103. [NC, RFC]
Goosens, W. K. (1978) Reduction by molecular genetics. Philosophy of Science
45:73-95. [JCM]
Gottlieb, G. (1976a) The roles of experience in the development of behavior
and the nervous system. In.: G. Gottlieb (ed.) Development of neural and
behavioral specificity. New York: Academic Press. [GG]
(1976b) Conceptions of prenatal development: behavioral embryology. Psy-
chological Review 83:215-34. [GG]
(in press) Development of species identification in ducklings: VI. Specific
embryonic experience required to maintain species-typical perception in
Peking ducklings. Journal of Comparative and Physiological Psycholo-
gy- [GG]
Graesser, A. G; Gordon, S. E.; and Sawyer, J. D. (1979) Recognition memory
for typical and atypical actions in scripted activities: tests of a script
pointer and tag hypothesis. Journal of Verbal Learning and Verbal Be-
havior 18:319-32. [RCS]
Graves, C; Katz, J. J.; Nishiyama, Y.; Soames, S.; Sleeker, R.; and Tovey, P.
(1973) Tacit knowledge. Journal of Philosophy 70. [SPS]
Grice, H. P. (1957) Logic and Conversation. Unpublished William James lec-
tures. Harvard Univ. [JRS]
Harman, G. (1973) Thought. Princeton: Princeton Univ. Press. [GH]
Hamad, S. R.; Steklis, H. D.; and Lancaster, J. (eds.) (1976) Origins and evolu-
tion of language and speech. Annals of the New York Academy of
Sciences: 280. [NC]
Hill, J. H., and Most, R. B. (1978) Review of Harnard, Steklis, and Lancaster
(1976) Language 54:651-2. [NC]
Hindemith, P. (1961) A composer's world. New York: Anchor. [NC]
Hollander, B. (1920) In search of the soul. London: Kegan Paul. [JCM]
Hubel, D. H. (1978) Vision and the brain. Bulletin of the American Academy
of Arts and Sciences. 31:28. [NC]
Hughes, J. (1972) Language and communication: acquisition of a non-vocal
"language" by previously languageless children. Unpublished Bachelor of
Technology thesis, Brunei University. [RFC]
(1974/75) Acquisition of a non-vocal "language" by aphasic children. Cog-
nition 3:41-55. [RFC]
Hull, D. L. (1975) Central subjects and historical narratives. History and The-
ory 14:253-74. [MTG]
(1976) Are species really individuals? Systematic Zoology 25:174-
91. [MTG]
Huttenlocher, J., and Strauss, S. (1968) Comprehension and a statement's rela-
tion to the situation it describes. Journal of Verbal Learning And Verbal
Behaviour 7:300-4. [RFC]
Huttenlocher, J.; Eisenberg, K.; and Strauss, S. (1968) Comprehension: relation
between perceived actor and logical subject. Journal of Verbal Learning
and Verbal Behaviour 7:527-30. [RFC]
Jackendoff, R. (1977) Review-article: Bernstein, The unanswered questions.
Language 53:883-894. [NC]
(1979) How to keep ninety from rising. Linguistic Inquiry. 10:172-
177. [NC]
and Lerdahl, F. (forthcoming) A generative theory of tonal music. Cam-
bridge: MIT Press. [NC]
Jacob, F. (1977) Evolution and tinkering. Science 196:1161-64. [NC]
(1978) Darwinism reconsidered. Le Monde Sept. 6-8, 1977; translated in At-
las. [NC]
Jahoda, G. (1979) On the nature of difficulties in spatio-perceptual tasks. Brit-
ish Journal of Psychology 70:351-63. [AM]
Jaisson, P. (1975) L'impregnation dans l'ontogenese des comportements de
soins aux cocons chez la jeune formi rousse (Formica polyctena Forst.) Be-
haviour 52:1-37. [GG]
Jenkins, L. (1978) Language and genetics. Theoretical Linguistics 5:77-
82. [JCM]
Jerne, N. K. (1967) Antibodies and learning: selection versus instruction. In:
G. C. Quarton; T. Melnechuk; and F. O. Schmitt (eds.) The neurosdences:
a study program. New York: Rockefeller Univ. Press. [NC]
Karmiloff-Smith, A. (1977) The child's construction of a system of plurifunc-
tional markers. In: M. Bullowa (Chair) Language development. Sympo-
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
59

References /Chomsky: Rules and representations
sium presented at the biennial conference of the International Society for
the Study of Behavioural Development, Pavia, Italy. [RFC]
(1978) The interplay between syntax, semantics, and phonology in language
acquisition processes. In: R. N. Campbell, and P. T. Smith (eds.) Recent
advances in the psychology of language: language development and
mother-child interaction, pp. 1-23. New York: Plenum Press. [RFC]
(1979) A functional approach to child language: a study of determiners
and reference. Cambridge: Cambridge Univ. Press. [RFC]
Kasher, A. (1977) Foundations of philosophical pragmatics. In: R. E. Butts and
J. Hintikka (eds.) Basic problems in methodology and linguistics: logic,
methodology and philosophy of science, V. Dordrecht: Reidel. [NC]
Katz, J. (1972) Semantic theory. New York: Harper & Row. [NC]
Keil, F. C. (1979) Semantic and conceptual development. Cambridge: Har-
vard Univ. Press. [NC]
Kenny, Anthony, translator and editor. (1970) Descartes: philosophical letters.
Oxford: Clarendon Press. [DMR]
Kintsch, W. (1977) Memory and cognition. New York: John Wiley. [JA]
and van Dijk, T. A. (1978) Toward a model of text comprehension and pro-
duction. Psychological review 85:363-94. [JA]
Kitcher, P. (1978) The nativist's dilemma. Philosophical Quarterly. [NC]
Koehler, O. (1956) The ability of birds to "count." In: J. R. Newman, (ed.) The
world of mathematics. New York: Simon & Schuster. [NC]
Kosslyn, S. (forthcoming) Image and mind. Cambridge: Harvard Univ.
Press. [NC]
Koster, J. (1978) Locality principles in syntax. Dordrecht: Foris. [NC]
Lakoff, G. (1977) Linguistic gestalts. Proceedings of the Chicago Linguistics
Society, 1050 E. 59 St., Chicago. [GL]
and Johnson, M. (1980) Metaphors we live by. Chicago: Univ. of Chicago
Press. [GL]
Lehnert, W. G. (1977) The process of question answering. Hillsdale, N.J.:
Lawrence Erlbaum Associates. [RCS]
Lesky, E. (1970) Structure and function in Gall. Bulletin of the History of
Medicine 44:297-314. [JCM]
Lewes, G. H. (1871) The history of philosophy from Thales to Comte. Lon-
don: Longmans. [JCM]
Lightfoot, D. W. (1979) Principles of diachronic syntax. New York and Cam-
bridge: Cambridge Univ. Press. [NC]
Limber, J. (1977) Language in child and chimp? American Psychologist
32:280-94. [NC]
Lorenz, K. (1965) The evolution and modification of behavior. Chicago: Univ.
of Chicago Press. [RVG]
Lycan, W. (in preparation) Functionalism and psychological laws. [SPS]
Macnamara, J. (1972) Cognitive basis of language learning in infants. Psycho-
logical Review 79:1-13. [RFC]
Maratsos, M. P. (1973) The effects of stress on the understanding of pronomi-
nal co-reference in children. Journal of Psycholinguistic Research 2:1-
8. [RFC]
Marcus, M. (1978) A theory of syntactic recognition for natural language.
Unpublished Ph.D. Thesis, Massachusetts Institute of Technology.
[PTVVH]
Marr, D. (1976) Early processing of visual information. Philosophical Transac-
tions of the Royal Society, B, 275:483-524. [JCM]
and Nishihara, H. K. (1978) Visual information processing: artificial intelli-
gence and the sensorium of sight. Technology Review 81:2-23. [NC]
Matthews, R. (1979) The plausibility of rationalism. To be presented to the an-
nual meeting of the Society for Philosophy and Psychology, March,
1980. [RJM]
Mehler, J. and Bertendini, J. (1979) Infants' perception of speech and other
acoustic stimuli. In: J. Morton and J. Marshall (eds.) Psycholinguistic Se-
ries II. Cambridge: MIT Press. [NC]
Minsky, M. (1977) Frame-system theory. In: P. N. Johnson-Laird and P. C.
Wason (eds.) Thinking, pp. 355-76. Cambridge: Cambridge Univ.
Press. [JA]
Moravcsik, J. (1975) Aitia as generative factor in Aristotle's philosophy. Dia-
logue. [NC]
(1977) "How do words get their meaning?" Yehoshua Bar-Hillel lecture, Je-
rusalem, forthcoming. [NC]
(1979) Understanding. Dialectica. [NC]
Nagel, T. (1969) Linguistics and epistemology. In: S. Hook (ed.) Language and
Philosophy. New York: New York Univ. Press. [SPS]
Nelson, K., and Gruendel, J. (1978) From person episode to social script: two
dimensions in the development of event knowledge. Paper presented at
the Biennial Meeting of the Society for Research in Child Development,
San Francisco. [RCS]
Newport, E.; Gleitman, H.; and Gleitman, L. (1977) Mother, I'd rather do it
myself: some effects and non-effects of maternal speech style. In: C. E.
Snow and C. A. Ferguson (eds.) Talking to children: language input and
acquisition. Cambridge: Cambridge Univ. Press. [NC]
Ojemann, G., and Mateer, C. (1979) Human language cortex: localization of
memory, syntax, and sequential motor-phoneme identification systems.
Science 205:1401-3. [JCM]
Osherson, D. N. (1976) Logical abilities in children. New York: Wiley. [NC]
Pinker, S. (1979) Formal models of language learning. Cognition 7:217-83.
[PTWH, RJM]
Premack, D. & Woodruff, G. (1978a) Chimpanzee problem-solving: a test for
comprehension. Science 202:532-35. [NC]
(1978b) Does the Chimpanzee have a theory of mind? The Behavioral and
Brain Sciences 1:515-26. [NC]
Putnam, H. (1962) It ain't necessarily so. Journal of Philosophy 59:658-
71. [GH]
Quine, W. V. O. (1960). Word and object. New York: John Wiley 6t
Sons. [JMM]
Quine, W. V. O. (1975) Mind and verbal dispositions. In: S. Cuttenplan (ed.)
Mind and language. London: Oxford. [NC]
Reed, E. S. (1979) The role of symmetry in Chiselin's "radical solution to the
species problem." Systematic Zoology 28:71-78. [MTG]
Rizzi, L. (1978) Violations of the Wh island constraint in Italian and the subja-
cency condition. In: C. Dubisson; D. Lightfoot; and Y. C. Morin (eds.)
Montreal Working Papers in Linguistics 2:155-90. [NC]
Rpllin, B. (1971) Hume's blue patch and the mind's creativity. Journal of the
History of Ideas XXXII:119ff. [BER]
(1976) Natural and conventional meaning: an examination of the distinc-
tion. The Hague: Mouton. [BER]
(1978) Thomas Reid and the semiotics of perception. The Monist
61:257ff. [BER]
Sampson, G. R. (1978) Linguistic universals as evidence for empiricism. Jour-
nal of Linguistics 14:183-206. [GS]
(1979) A non-nativist account of language universals. Linguistics and Phi-
losophy 3:99-104. [GS]
(1980) Making sense. Oxford and New York: Oxford Univ. Press. [GS]
Sapir, E. (1933) The psychological reality of the phonene. Reprinted in English
translation in: D. G. Mandelbaum (ed.) Selected writings of Edward Sa-
pir. Berkeley and Los Angeles: Univ. of California Press, 1949. [NC]
Savage-Rumbaugh, E. S.; Rumbaugh, D. M.; and Boysen, S. (1978) Symbolic
communication between two chimpanzees. Science 201:641-42. [NC]
Schlesinger, I. M. (1977) Production and comprehension of utterances. Hills-
dale, N.J.: L. Erlbaum [JA]
(1979) Cognitive structures and semantic deep structures. Journal of Lin-
guistics 15:307-24. [JA]
Schopenhauer, A. (1974) The fourfold root of the principle of sufficient reason.
La Salle, Illinois: Open Court. [NC]
Schwartz, R. (1969) On knowing a grammar. In: S. Hook (ed.) Language and
philosophy: New York: New York Univ. Press. [SPS]
Searle, J. R. (1969) Speech acts. Cambridge and New York: Cambridge Univ.
Press. [JRS]
(1976) The rules of the language game. Review article on Reflections on
Language. Times Literary Supplement. Sept. 10. [NC, JRS]
Selfridge, M. (1979) A process model of language acquisition. Ph.D. Thesis,
Department of Computer Science, Yale University, New Haven,
CT. [RCS]
Serpell, R. (1979) How specific are perceptual skills? British Journal of Psy-
chology 70:365-80. [AM]
Sheldon, A. (1974) The role of parallel function in the acquisition of relative
clauses in English. Journal of Verbal Learning and Verbal Behaviour
13:272-81. [RFC]
Simon, H. A. (1962) The architecture of complexity. Proceedings of the Amer-
ican Philosophical Society 106:467-82; reprinted (1969) in The sciences
of the artificial, Cambridge, Mass.: MIT Press. [GS]
Slobin, D. I. (1978) Universal and particular in the acquisition of language. Pa-
per presented at the workshop-conference, "Language acquisition: state of
the art," University of Pennsylvania. May 19-22. [RFC]
(1979) The role of language in language acquisition. Paper presented at the
Eastern Psychological Association, Philadelphia, April 21. [RFC]
Smedslund, J. (1961) The acquisition of conservation of substance and weight
in children: III. Extinction of conservation of weight acquired "normally"
and by means of empirical controls on a balance. Scandinavian Journal of
Psychology 2:85-87. [RFC]
Smith, N. (1979) Syntax for psychologists. In: J. Morton, and J. C. Marshall
(eds.) Psycholinguistics Series, Vol. 2. London: Elek. [JCM]
Snow, C. E., and Ferguson, C. A. (eds.) (1977) Talking to children: language
input and acquisition. Cambridge: Cambridge Univ. Press. [RFC]
Staddon, J. E. R., and Simmelhag, V. L. (1971) The "superstitution" experi-
ment: a reexamination of its implications for the principles of adaptive be-
havior. Psychological Review 78:16-43. [HR]
Stich, S. (1971) What every speaker knows. Philosophical Review 80:476-
96. [SPS]
60
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3

(1978a) Empiricism, innateness and linguistic universal. Philosophical
Studies 33:273-86. [SPS]
(1978b) Beliefs and subdoxastic states. Philosophy oj Science 45:499-
518. [SPS]
(1979) Between Chomskian rationalism and Popperian empiricism. British
Journal for the Philosophy of Science 30. [SPS]
Strohner, H., and Nelson, K. E. (1974) The young child's development of sen-
tence comprehension: influence of event probability, nonverbal context,
syntactic form, and strategies. Child Development 45:567-76. [RFC]
Taub, E. (1976) Motor behavior following deafferentation in the developmen-
tally and motorically mature monkey. In: R. M. Herrman; S. Grillner;
P. S. G. Stein; and D. G. Stuart (eds.) Neural control of locomotion. New
York: Plenum. [NC]
Terrace, H. (forthcoming) Is problem solving language? Journal of the Experi-
mental Analysis of Behavior. [NC)
Twaddell, W. F. (1935) On defining the phoneme. Language Monograph No.
16. [NC]
Ullman, S. (1978) The interpretation of visual motion. Cambridge: MIT
Press. [NC]
van Dijk, T. A. (1977) Context and Cognition: Knowledge frames and speech
act comprehension. Journal of Pragmatics 1:211-32. [JA]
Velletri-Glass, A.; Gazzaniga, M; and Premack, D. (1973) Artificial language
training in global aphasics. Neuropsychologia 11:95-104. [NC, RFC]
References /Chomsky: Rules and representations
Walter, J. G. (1805) Etwas uber Herrn Dr. Call's HirnschUdellehre. Berlin:
Scherer. [JCM]
Wexler, K. (1978) A principle theory for language acquisition, Social Science
Research Reports, vol. 20, Univ. of California, Irvine. [NC]
Wiens, J. A. (1970) Effects of early experience on substrate pattern selection in
Rana aurora tadpoles. Copeia No. 3, 543-48. [GG]
Wilcox, S., and Palermo, D. S. (1975) "In," "on," and "under" revisited. Cog-
nition 3:245-54. [RFC]
Wilkes, K. V. (1980) Brain lesions. Philosophical Quarterly, forthcom-
ing. [AM]
Williams, M. (1977) Groundless belief. New Haven: Yale Univ. Press. [NC]
Winograd, T. (1972) Understanding natural language. Cognitive Psychology
2:1-191. [SPS]
(1976) Towards a procedural understanding of semantics. Revue Interna-
tionale de Philosophic 30:260-303. [GH]
Young, R. M. (1970) Mind, brain and adaptation in the nineteenth century.
Oxford: Clarendon Press. [JCM]
Zangwill, O. L. (1978). Aphasia and the concept of brain centers. In: G. A.
Miller, and E. Lenneberg (eds.) Psychology and biology of language and
thought. New York: Academic Press. [JM]
Zeki, S. M. (1978) Functional specialization in the visual cortex of the rhesus
monkey. Nature 274:423-28. [JCM]
THE BEHAVIORAL AND BRAIN SCIENCES (1980), 3
61

