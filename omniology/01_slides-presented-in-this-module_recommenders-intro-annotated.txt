Machine Learning Specialization 
Recommending 
Products 
Emily Fox & Carlos Guestrin 
Machine Learning Specialization 
University of Washington 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
Where we see  
recommender systems 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
3	  
Personalization is transforming  
our experience of the world 
Information overload  
   ê  
Browsing is “history” 
- Need new ways  
to discover content 
100 Hours a Minute 
What do I care about? 
Personalization: Connects users & items 
©2015 Emily Fox & Carlos Guestrin 
viewers 
videos 

Machine Learning Specialization 
4	  
Movie recommendations 
©2015 Emily Fox & Carlos Guestrin 
Connect users with movies  
they may want to watch 

Machine Learning Specialization 
5	  
Product recommendations  
©2015 Emily Fox & Carlos Guestrin 
Recommendations combine  
global & session interests 

Machine Learning Specialization 
6	  
Music recommendations 
©2015 Emily Fox & Carlos Guestrin 
Recommendations form 
coherent & diverse sequence 

Machine Learning Specialization 
7	  
Friend recommendations 
©2015 Emily Fox & Carlos Guestrin 
Users and “items”  
are of the same “type” 

Machine Learning Specialization 
8	  
Drug-target interactions 
What drug should we  
“repurpose” for some disease? 
Cobanoglu et al. ‘13 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
Building a recommender system 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
Solution 0:  Popularity 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
11	  
Simplest approach: Popularity 
•  What are people 
viewing now? 
- Rank by global 
popularity 
 
•  Limitation:  
- No personalization 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
Solution 1:  Classiﬁcation model 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
13	  
What’s the probability I’ll buy this product? 
©2015 Emily Fox & Carlos Guestrin 
User info 
 
Purchase history  
 
Product info 
 
Other info 
Classiﬁer 
Yes! 
No 
•  Pros: 
-  Personalized:  
Considers user info & purchase history 
-  Features can capture context:  
Time of the day, what I just saw,… 
-  Even handles limited user history: Age of user, … 

Machine Learning Specialization 
14	  
Limitations of classiﬁcation approach 
•  Features may not be available 
•  Often doesn’t perform as well as  
collaborative ﬁltering methods (next) 
©2015 Emily Fox & Carlos Guestrin 
User info 
 
Purchase history  
 
Product info 
 
Other info 
Classiﬁer 
Yes! 
No 

Machine Learning Specialization 
Solution 2:  People who bought this  
       also bought…  
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
16	  
Co-occurrence matrix 
•  People who bought diapers also  
bought baby wipes 
•  Matrix C:  
store # users who bought both items i & j 
-  (# items x # items) matrix 
-  Symmetric: # purchasing i & j same as # for j & i   (Cij = Cji) 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
17	  
Making recommendations using  
co-occurences 
•  User           purchased diapers 
1.  Look at diapers row of matrix 
2.  Recommend other items with largest counts 
- baby wipes, milk, baby food,… 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
18	  
Co-occurrence matrix must be  
normalized 
•  What if there are very popular items? 
- Popular baby item:  
Pampers Swaddlers diapers 
- For any baby item (e.g., i=Sophie giraﬀe    ) 
large count Cij for j=Pampers Swaddlers 
•  Result: 
- Drowns out other eﬀects 
- Recommend based on popularity 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
19	  
Normalize co-occurrences:  
Similarity matrix  
•  Jaccard similarity: normalizes by popularity 
-  Who purchased i and j divided by  
who purchased i or j 
•  Many other similarity metrics possible, e.g., cosine similarity 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
20	  
Limitations 
•  Only current page matters, no history 
-  Recommend similar items to the one you bought 
•  What if you purchased many items?  
-  Want recommendations based on purchase history 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
21	  
(Weighted) Average of purchased items 
•  User       bought items {diapers, milk} 
- Compute user-speciﬁc score for each item j  
in inventory by combining similarities: 
 
Score(       , baby wipes) =  
  
  
 ½ (Sbaby wipes, diapers + Sbaby wipes, milk) 
- Could also weight recent purchases more 
 
•  Sort Score(      , j ) and ﬁnd item j with highest similarity 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
22	  
Limitations 
•  Does not utilize: 
- context (e.g., time of day) 
- user features (e.g., age) 
- product features (e.g., baby vs. electronics) 
•  Cold start problem 
- What if a new user or product arrives? 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
Solution 3:  Discovering hidden structure 
       by matrix factorization 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
24	  
•  Users watch movies and rate them 
Movie recommendation 
©2015 Emily Fox & Carlos Guestrin 
User Movie 
Rating 
Each user only watches a few of the available movies	  

Machine Learning Specialization 
25	  
Matrix completion problem 
•  Data: Users score some movies 
•  Goal: Filling missing data?   
=
Rating(u,v)	  known for black cells 
Rating(u,v)	  unknown for white cells 
Rating 
©2015 Emily Fox & Carlos Guestrin 
Movies 
Users 

Machine Learning Specialization 
26	  
Suppose we had d topics for  
each user and movie 
•  Describe movie v               with topics Rv 
-  How much is it action, romance, drama,…  
•  Describe user u        with topics Lu 
-  How much she likes action, romance, drama,…  
•  Rating(u,v) is the product of the two vectors 
•  Recommendations: sort movies user hasn’t watched by Rating(u,v)  
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
27	  
Predictions in matrix form 
©2015 Emily Fox & Carlos Guestrin 
≈	   L
R’
=
Rating 
But we don’t  
know topics of 
users and movies… 	  

Machine Learning Specialization 
28	  
Matrix factorization model: 
Discovering topics from data 
 
•  Only use observed values to estimate “topic” vectors Lu and Rv 
•  Use estimated Lu and Rv for recommendations 
©2015 Emily Fox & Carlos Guestrin 
≈	  
=
Rating 
Many eﬃcient algorithms 
for factorization	  
Parameters  
of model 

Machine Learning Specialization 
29	  
Limitations of matrix factorization 
•  Cold-start problem 
-  This model still cannot handle a new user or movie 
©2015 Emily Fox & Carlos Guestrin 
=
Rating 

Machine Learning Specialization 
Bringing it all together:  
Featurized matrix factorization 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
31	  
Combining features and discovered topics 
•  Features capture context 
-  Time of day, what I just saw, user info, past purchases,… 
•  Discovered topics from matrix factorization capture  
groups of users who behave similarly 
-  Women from Seattle who teach and have a baby 
•  Combine to mitigate cold-start problem 
-  Ratings for a new user from features only 
-  As more information about user is discovered,  
matrix factorization topics become more relevant 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
32	  
Blending models 
•  Squeezing last bit of accuracy by  
blending models 
•  Netﬂix Prize 2006-2009 
- 100M ratings 
- 17,770 movies 
- 480,189 users 
-  Predict 3 million 
 ratings to  
 highest accuracy 
- Winning team blended over 100 models 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
A performance metric for  
recommender systems 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
34	  
The world of all baby products 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
35	  
User likes subset of items 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
36	  
Why not use classiﬁcation accuracy? 
•  Classiﬁcation accuracy =  
fraction of items correctly classiﬁed  
(liked vs. not liked) 
•  Here, not interested in what a person 
does not like 
•  Rather, how quickly can we discover the  
relatively few liked items? 
- (Partially) an imbalanced class problem 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
37	  
How many liked items were  
recommended? 
©2015 Emily Fox & Carlos Guestrin 
# liked & shown 
# liked 
Recall 

Machine Learning Specialization 
38	  
How many recommended items 
were liked? 
©2015 Emily Fox & Carlos Guestrin 
# liked & shown 
# shown 
Precision 

Machine Learning Specialization 
39	  
Maximize recall:  
Recommend everything 
©2015 Emily Fox & Carlos Guestrin 
# liked & shown 
# liked 
Recall 

Machine Learning Specialization 
40	  
Resulting precision? 
©2015 Emily Fox & Carlos Guestrin 
# liked & shown 
# shown 
Precision 

Machine Learning Specialization 
41	  
Optimal recommender 
©2015 Emily Fox & Carlos Guestrin 
Recall =1  
Precision = 1 

Machine Learning Specialization 
42	  
Precision-recall curve 
•  Input: A speciﬁc recommender system 
•  Output: Algorithm-speciﬁc precision-recall curve 
•  To draw curve, vary threshold on # items recommended 
-  For each setting, calculate the precision and recall 
©2015 Emily Fox & Carlos Guestrin 
recall 
precision 

Machine Learning Specialization 
43	  
Which Algorithm is Best? 
•  For a given precision, want recall as large as possible 
(or vice versa) 
•  One metric: largest area under the curve (AUC) 
•  Another: set desired recall and maximize precision
  
  
 
 
 
 
 
 
      
 (precision at k) 
©2015 Emily Fox & Carlos Guestrin 
recall 
precision 

Machine Learning Specialization 
Summary of  
recommender systems 
©2015 Emily Fox & Carlos Guestrin 

Machine Learning Specialization 
45	  
What you can do now… 
•  Describe the goal of a recommender system 
•  Provide examples of applications where recommender systems are useful 
•  Implement a co-occurrence based recommender system  
•  Describe the input (observations, number of “topics”) and output (“topic” 
vectors, predicted values) of a matrix factorization model 
•  Exploit estimated “topic” vectors (algorithms to come…) to make 
recommendations 
•  Describe the cold-start problem and ways to handle it (e.g., incorporating 
features) 
•  Analyze performance of various recommender systems in terms of precision 
and recall 
•  Use AUC or precision-at-k to select amongst candidate algorithms 
©2015 Emily Fox & Carlos Guestrin 

