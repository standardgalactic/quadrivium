
A Mathematical
Introduction to Logic

This Page Intentionally Left Blank

A Mathematical
Introduction to Logic
Second Edition
Herbert B. Enderton
University of California, Los Angeles
A Harcourt Science and Technology Company
San Diego
New York
Boston
London
Toronto
Sydney
Tokyo

Sponsoring Editor
Barbara Holland
Production Editor
Julie Bolduc
Editorial Coordinator
Karen Frost
Marketing Manager
Marianne Rutter
Cover Design
Judy Arisman, Arisman Design
Copyeditor
Kristin Landon
Composition
Interactive Composition Corporation
Printer
The Maple-Vail Book Manufacturing Group
This book is printed on acid-free paper. ⃝
∞
Copyright c⃝2001, 1972 by HARCOURT/ACADEMIC PRESS
All rights reserved.
No part of this publication may be reproduced or transmitted in any form or by any
means, electronic or mechanical, including photocopy, recording, or any
information storage and retrieval system, without permission in writing from the
publisher.
Requests for permission to make copies of any part of the work should be mailed to:
Permissions Department, Harcourt, Inc., 6277 Sea Harbor Drive, Orlando, Florida
32887-6777.
Academic Press
A Harcourt Science and Technology Company
525 B Street, Suite 1900, San Diego, California 92101-4495, USA
http://www.academicpress.com
Academic Press
Harcourt Place, 32 Jamestown Road, London NW1 7BY, UK
http://www.academicpress.com
Harcourt/Academic Press
A Harcourt Science and Technology Company
200 Wheeler Road, Burlington, Massachusetts 01803, USA
http://www.harcourt-ap.com
Library of Congress Catalog Card Number: 00-110670
International Standard Book Number: 0-12-238452-0
PRINTED IN THE UNITED STATES OF AMERICA
00 01 02 03 04 05 MB 9 8 7 6 5 4 3 2 1

for Eric and Bert

This Page Intentionally Left Blank

Contents
PREFACE
ix
INTRODUCTION
xi
CHAPTER ZERO
Useful Facts about Sets
1
CHAPTER ONE
Sentential Logic
11
1.0 Informal Remarks on Formal Languages
11
1.1 The Language of Sentential Logic
13
1.2 Truth Assignments
20
1.3 A Parsing Algorithm
29
1.4 Induction and Recursion
34
1.5 Sentential Connectives
45
1.6 Switching Circuits
54
1.7 Compactness and Effectiveness
59
CHAPTER TWO
First-Order Logic
67
2.0 Preliminary Remarks
67
2.1 First-Order Languages
69
2.2 Truth and Models
80
2.3 A Parsing Algorithm
105
2.4 A Deductive Calculus
109
2.5 Soundness and Completeness Theorems
131
2.6 Models of Theories
147
2.7 Interpretations Between Theories
164
2.8 Nonstandard Analysis
173
CHAPTER THREE
Undecidability
182
3.0 Number Theory
182
3.1 Natural Numbers with Successor
187
3.2 Other Reducts of Number Theory
193
3.3 A Subtheory of Number Theory
202
3.4 Arithmetization of Syntax
224
vii

viii
Contents
3.5 Incompleteness and Undecidability
234
3.6 Recursive Functions
247
3.7 Second Incompleteness Theorem
266
3.8 Representing Exponentiation
276
CHAPTER FOUR
Second-Order Logic
282
4.1 Second-Order Languages
282
4.2 Skolem Functions
287
4.3 Many-Sorted Logic
295
4.4 General Structures
299
SUGGESTIONS FOR FURTHER READING
307
LIST OF SYMBOLS
309
INDEX
311

Preface
T
his book, like the ﬁrst edition, presents the basic
concepts and results of logic: the topics are proofs,
truth, and computability. As before, the presentation
is directed toward the reader with some mathematical back-
ground and interests. In this revised edition, in addition to
numerous “local” changes, there are three “global” ways in
which the presentation has been changed:
First, I have attempted to make the material more ac-
cessible to the typical undergraduate student. In the main
development, I have tried not to take for granted informa-
tion or insights that might be unavailable to a junior-level
mathematics student.
Second, for the instructor who wants to ﬁt the book to his
or her course, the organization has been made more ﬂexible.
Footnotes at the beginning of many of the sections indicate
optional paths the instructor — or the independent reader —
might choose to take.
Third, theoretical computer science has inﬂuenced logic
in recent years, and some of that inﬂuence is reﬂected in this
edition. Issues of computability are taken more seriously.
Some material on ﬁnite models has been incorporated into
the text.
The book is intended to serve as a textbook for an in-
troductory mathematics course in logic at the junior-senior
level. The objectives are to present the important concepts
and theorems of logic and to explain their signiﬁcance and
their relationship to the reader’s other mathematical work.
As a text, the book can be used in courses anywhere from
a quarter to a year in length. In one quarter, I generally reach
the material on models of ﬁrst-order theories (Section 2.6).
The extra time afforded by a semester would permit some
glimpse of undecidability, as in Section 3.0. In a second
ix

x
Preface
term, the material of Chapter 3 (on undecidability) can be more adequately cov-
ered.
Thebookisintendedforthereaderwhohasnotstudiedlogicpreviously,butwho
has some experience in mathematical reasoning. There are no speciﬁc prerequisites
aside from a willingness to function at a certain level of abstraction and rigor.
There is the inevitable use of basic set theory. Chapter 0 gives a concise summary
of the set theory used. One should not begin the book by studying this chapter; it is
instead intended for reference if and when the need arises. The instructor can adjust
the amount of set theory employed; for example it is possible to avoid cardinal
numbers completely (at the cost of losing some theorems). The book contains
some examples drawn from abstract algebra. But they are just examples, and are
not essential to the exposition. The later chapters (Chapter 3 and 4) tend to be more
demanding of the reader than are the earlier chapters.
Induction and recursion are given a more extensive discussion (in Section 1.4)
than has been customary. I prefer to give an informal account of these subjects in
lectures and have a precise version in the book rather than to have the situation
reversed.
Exercises are given at the end of nearly all the sections. If the exercise bears a
boldface numeral, then the results of that exercise are used in the exposition in the
text. Unusually challenging exercises are marked with an asterisk.
I cheerfully acknowledge my debt to my teachers, a category in which I include
also those who have been my colleagues or students. I would be pleased to receive
comments and corrections from the users of this book. The Web site for the book
can be found at http://www.math.ucla.edu/∼hbe/amil.

Introduction
S
ymbolic logic is a mathematical model of deductive
thought. Or at least that was true originally; as with
other branches of mathematics it has grown beyond
the circumstances of its birth. Symbolic logic is a model
in much the same way that modern probability theory is a
model for situations involving chance and uncertainty.
How are models constructed? You begin with a real-life
object, for example an airplane. Then you select some fea-
tures of this original object to be represented in the model,
for example its shape, and others to be ignored, for example
its size. And then you build an object that is like the original
in some ways (which you call essential) and unlike it in oth-
ers (which you call irrelevant). Whether or not the resulting
model meets its intended purpose will depend largely on
the selection of the properties of the original object to be
represented in the model.
Logic is more abstract than airplanes. The real-life ob-
jectsarecertain“logicallycorrect”deductions.Forexample,
All men are mortal.
Socrates is a man.
Therefore, Socrates is mortal.
The validity of inferring the third sentence (the conclu-
sion) from the ﬁrst two (the assumptions) does not depend
on special idiosyncrasies of Socrates. The inference is jus-
tiﬁed by the form of the sentences rather than by empirical
facts about mortality. It is not really important here what
“mortal” means; it does matter what “all” means.
Borogoves are mimsy whenever it is brillig.
It is now brillig, and this thing is a borogove.
Hence this thing is mimsy.
xi

xii
Introduction
Again we can recognize that the third sentence follows from the ﬁrst two, even
without the slightest idea of what a mimsy borogove might look like.
Logically correct deductions are of more interest than the above frivolous ex-
amples might suggest. In fact, axiomatic mathematics consists of many such de-
ductions laid end to end. These deductions made by the working mathematician
constitute real-life originals whose features are to be mirrored in our model.
The logical correctness of these deductions is due to their form but is indepen-
dent of their content. This criterion is vague, but it is just this sort of vagueness that
prompts us to turn to mathematical models. A major goal will be to give, within
a model, a precise version of this criterion. The questions (about our model) we
will initially be most concerned with are these:
1. What does it mean for one sentence to “follow logically” from certain others?
2. If a sentence does follow logically from certain others, what methods of
proof might be necessary to establish this fact?
3. Is there a gap between what we can prove in an axiomatic system (say for
the natural numbers) and what is true about the natural numbers?
4. What is the connection between logic and computability?
Actually we will present two models. The ﬁrst (sentential logic) will be very
simple and will be woefully inadequate for interesting deductions. Its inadequacy
stems from the fact that it preserves only some crude properties of real-life de-
ductions. The second model (ﬁrst-order logic) is admirably suited to deductions
encountered in mathematics. When a working mathematician asserts that a par-
ticular sentence follows from the axioms of set theory, he or she means that this
deduction can be translated to one in our model.
This emphasis on mathematics has guided the choice of topics to include. This
book does not venture into many-valued logic, modal logic, or intuitionistic logic,
which represent different selections of properties of real-life deductions.
Thus far we have avoided giving away much information about what our model,
ﬁrst-order logic, is like. As brief hints, we now give some examples of the expres-
siveness of its formal language. First, take the English sentence that asserts the
set-theoretic principle of extensionality, “If the same things are members of a ﬁrst
object as are members of a second object, then those objects are the same.” This
can be translated into our ﬁrst-order language as
∀x ∀y( ∀z(z ∈x ↔z ∈y) →x = y).
As a second example, we can translate the sentence familiar to calculus students,
“For every positive number ε there is a positive number δ such that for any x whose
distance from a is less than δ, the distance between f (x) and b is less than ε” as
∀ε(ε > 0 →∃δ(δ > 0 ∧∀x(dxa < δ →d f xb < ε))).
We have given some hints as to what we intend to do in this book. We should
also correct some possible misimpressions by saying what we are not going to do.
This book does not propose to teach the reader how to think. The word “logic” is
sometimes used to refer to remedial thinking, but not by us. The reader already
knows how to think. Here are some intriguing concepts to think about.

Chapter
Z E R O
Useful Facts
about Sets
W
e assume that the reader already has
some familiarity with normal everyday
set-theoreticapparatus.Nonetheless,we
give here a brief summary of facts from set theory
we will need; this will at least serve to establish
the notation. It is suggested that the reader, instead
of poring over this chapter at the outset, simply
refer to it if and when issues of a set-theoretic na-
ture arise in later chapters. The author’s favorite
book on set theory is of course his Elements of Set
Theory (see the list of references at the end of this
book).
First a word about jargon. Throughout the book
we will utilize an assortment of standard mathe-
matical abbreviations. We use “⊣” to signify the
end of a proof. A sentence “If . . . , then . . .” will
sometimes be abbreviated “. . . ⇒. . . .” We also
have “⇐” for the converse implication (for the pe-
culiar way the word “implication” is used in math-
ematics). For “if and only if” we use the shorter
“iff” (this has become part of the mathematical lan-
guage) and the symbol “⇔.” For the word “there-
fore” we have the “∴” abbreviation.
The notational device that extracts “x ̸= y” as
the denial of “x = y” and “x /∈y” as the denial
of “x ∈y” will be extended to other cases. For
example, in Section 1.2 we deﬁne “ |= τ”; then
“ ̸|= τ” is its denial.
Now then, a set is a collection of things, called
its members or elements. As usual, we write “t ∈
A” to say that t is a member of A, and “t /∈A” to
saythatt isnotamemberof A.Wewrite“x = y”to
1

2
A Mathematical Introduction to Logic
mean that x and y are the same object. That is, the expression “x” on the
left of the equals sign is a name for the same object as is named by the
other expression “y.” If A = B, then for any object t it is automatically
true that t ∈A iff t ∈B. This holds simply because A and B are the
same thing. The converse is the principle of extensionality: If A and B
are sets such that for every object t,
t ∈A
iff
t ∈B,
then A = B. This reﬂects the idea of what a set is; a set is determined
just by its members.
A useful operation is that of adjoining one extra object to a set. For
a set A, let A; t be the set whose members are (i) the members of A,
plus (ii) the (possibly new) member t. Here t may or may not already
belong to A, and we have
A; t = A ∪{t}
using notation deﬁned later, and
t ∈A
iff
A; t = A.
One special set is the empty set ∅, which has no members at all. Any
other set is said to be nonempty. For any object x there is the singleton
set {x} whose only member is x. More generally, for any ﬁnite number
x1, . . . , xn of objects there is the set {x1, . . . , xn} whose members are
exactly those objects. Observe that {x, y} = {y, x}, as both sets have
exactly the same members. We have only used different expressions to
denote the set. If order matters, we can use ordered pairs (discussed
later).
This notation will be stretched to cover some simple inﬁnite cases.
For example, {0, 1, 2, . . .} is the set N of natural numbers, and {. . . , −2,
−1, 0, 1, 2, . . .} is the set Z of all integers.
We write “{x |
x
}” for the set of all objects x such that
x
.
We will take considerable liberty with this notation. For example,
{⟨m, n⟩| m < n
in
N} is the set of all ordered pairs of natural
numbers for which the ﬁrst component is smaller than the second. And
{x ∈A |
x
} is the set of all elements x in A such that
x
.
If A is a set all of whose members are also members of B, then A is a
subset of B, abbreviated “A ⊆B.” Note that any set is a subset of itself.
Also, ∅is a subset of every set. (“∅⊆A” is “vacuously true,” since
the task of verifying, for every member of ∅, that it also belongs to A
requires doing nothing at all. Or from another point of view, “A ⊆B”
can be false only if some member of A fails to belong to B. If A = ∅,
this is impossible.) From the set A we can form a new set, the power set
P A of A, whose members are the subsets of A. Thus
P A = {x | x ⊆A}.

Chapter 0:
Useful Facts about Sets
3
For example,
P∅= {∅},
P{∅} = {∅, {∅}}.
The union of A and B, A ∪B, is the set of all things that are members
of A or B (or both). For example, A; t = A ∪{t}. Similarly, the inter-
section of A and B, A ∩B, is the set of all things that are members
of both A and B. Sets A and B are disjoint iff their intersection is
empty (i.e., if they have no members in common). A collection of sets
is pairwise disjoint iff any two members of the collection are disjoint.
More generally, consider a set A whose members are themselves sets.
The union,  A, of A is the set obtained by dumping all the members
of A into a single set:

A = {x | x
belongs to some member of A}.
Similarly for nonempty A,

A = {x | x
belongs to all members of A}.
For example, if
A = {{0, 1, 5}, {1, 6}, {1, 5}},
then
 A = {0, 1, 5, 6},
 A = {1}.
Two other examples are
A ∪B = {A, B},
 P A = A.
In cases where we have a set An for each natural number n, the union
of all these sets, {An | n ∈N}, is usually denoted “
n∈N An” or just
“
n An.”
The ordered pair ⟨x, y⟩of objects x and y must be deﬁned in such a
way that
⟨x, y⟩= ⟨u, v⟩
iff
x = u
and
y = v.
Any deﬁnition that has this property will do; the standard one is
⟨x, y⟩= {{x}, {x, y}}.
For ordered triples we deﬁne
⟨x, y, z⟩= ⟨⟨x, y⟩, z⟩.

4
A Mathematical Introduction to Logic
More generally we deﬁne n-tuples recursively by
⟨x1, . . . , xn+1⟩= ⟨⟨x1, . . . , xn⟩, xn+1⟩
for n > 1. It is convenient to deﬁne also ⟨x⟩= x; the preceding equation
then holds also for n = 1. S is a ﬁnite sequence (or string) of members
of A iff for some positive integer n, we have S = ⟨x1, . . . , xn⟩, where
each xi ∈A. (Finite sequences are often deﬁned to be certain ﬁnite
functions, but the above deﬁnition is slightly more convenient for us.)
A segment of the ﬁnite sequence S = ⟨x1, . . . , xn⟩is a ﬁnite sequence
⟨xk, xk+1, . . . , xm−1, xm⟩,
where
1 ≤k ≤m ≤n.
This segment is an initial segment iff k = 1 and it is proper iff it is
different from S.
If ⟨x1, . . . , xn⟩= ⟨y1, . . . , yn⟩, then it is easy to see that xi = yi
for 1 ≤i ≤n. (The proof uses induction on n and the basic property
of ordered pairs.) But if ⟨x1, . . . , xm⟩= ⟨y1, . . . , yn⟩, then it does not
in general follow that m = n. After all, every ordered triple is also an
ordered pair. But we claim that m and n can be unequal only if some xi
is itself a ﬁnite sequence of y j’s, or the other way around:
LEMMA 0A
Assume that ⟨x1, . . . , xm⟩= ⟨y1, . . . , ym, . . . , ym+k⟩.
Then x1 = ⟨y1, . . . , yk+1⟩.
PROOF.
We use induction on m. If m = 1, the conclusion is imme-
diate. For the inductive step, assume that ⟨x1, . . . , xm, xm+1⟩=
⟨y1, . . . , ym+k, ym+1+k⟩. Then the ﬁrst components of this ordered
pair must be equal: ⟨x1, . . . , xm⟩= ⟨y1, . . . , ym+k⟩. Now apply
the inductive hypothesis.
⊣
For example, suppose that A is a set such that no member of A is a
ﬁnite sequence of other members. Then if ⟨x1, . . . , xm⟩= ⟨y1, . . . , yn⟩
and each xi and y j is in A, then by the above lemma m = n. Whereupon
we have xi = yi as well.
From sets A and B we can form their Cartesian product, the set
A × B of all pairs ⟨x, y⟩for which x ∈A and y ∈B. An is the set of
all n-tuples of members of A. For example, A3 = (A × A) × A.
A relation R is a set of ordered pairs. For example, the ordering
relation on the numbers 0–3 is captured by — and in fact is — the set of
ordered pairs
{⟨0, 1⟩, ⟨0, 2⟩, ⟨0, 3⟩, ⟨1, 2⟩, ⟨1, 3⟩, ⟨2, 3⟩}.
The domain of R (written dom R) is the set of all objects x such that
⟨x, y⟩∈R for some y. The range of R (written ran R) is the set of all
objects y such that ⟨x, y⟩∈R for some x. The union of dom R and
ran R is the ﬁeld of R, ﬂd R.

Chapter 0:
Useful Facts about Sets
5
An n-ary relation on A is a subset of An. If n > 1, it is a relation. But a
1-ary (unary) relation on A is simply a subset of A. A particularly simple
binary relation on A is the equality relation {⟨x, x⟩| x ∈A} on A. For
an n-ary relation R on A and subset B of A, the restriction of R to B
is the intersection R ∩Bn. For example, the relation displayed above is
the restriction to the set B = {0, 1, 2, 3} of the ordering relation on N.
A function is a relation F with the property of being single-valued:
For each x in dom F there is only one y such that ⟨x, y⟩∈F. As usual,
this unique y is said to be the value F(x) that F assumes at x. (This
notation goes back to Euler. It is a pity he did not choose (x)F instead;
that would have been helpful for the composition of functions: f ◦g is
the function whose value at x is f (g(x)), obtained by applying ﬁrst g
and then f .)
We say that F maps A into B and write
F : A →B
to mean that F is a function, dom F = A, and ran F ⊆B. If in addition
ran F = B, then F maps A onto B. F is one-to-one iff for each y in
ran F there is only one x such that ⟨x, y⟩∈F. If the pair ⟨x, y⟩is in
dom F, then we let F(x, y) = F(⟨x, y⟩). This notation is extended to
n-tuples; F(x1, . . . , xn) = F(⟨x1, . . . , xn⟩).
An n-ary operation on A is a function mapping An into A. For exam-
ple, addition is a binary operation on N, whereas the successor operation
S (where S(n) = n + 1) is a unary operation on N. If f is an n-ary op-
eration on A, then the restriction of f to a subset B of A is the function
g with domain Bn which agrees with f at each point of Bn. Thus,
g = f ∩(Bn × A).
This g will be an n-ary operation on B iff B is closed under f , in the
sense that f (b1, . . . , bn) ∈B whenever each bi is in B. In this case,
g = f ∩Bn+1, in agreement with our deﬁnition of the restriction of a
relation. For example, the addition operation on N, which contains such
triples as ⟨⟨3, 2⟩, 5⟩, is the restriction to N of the addition operation on
R, which contains many more triples.
A particularly simple unary operation on A is the identity function
Id on A, given by the equation
Id(x) = x
for
x ∈A.
Thus Id = {⟨x, x⟩| x ∈A}.
For a relation R, we deﬁne the following:
R is reﬂexive on A iff ⟨x, x⟩∈R for every x in A.
R is symmetric iff whenever ⟨x, y⟩∈R, then also ⟨y, x⟩∈R.
R is transitive iff whenever both ⟨x, y⟩∈R and ⟨y, z⟩∈R (if this
ever happens), then also ⟨x, z⟩∈R.

6
A Mathematical Introduction to Logic
R satisﬁes trichotomy on A iff for every x and y in A, exactly one of
the three possibilities, ⟨x, y⟩∈R, x = y, or ⟨y, x⟩∈R, holds.
R is an equivalence relation on A iff R is a binary relation on A that
is reﬂexive on A, symmetric, and transitive.
R is an ordering relation on A iff R is transitive and satisﬁes tri-
chotomy on A.
For an equivalence relation R on A we deﬁne, for x ∈A, the equiv-
alence class [x] of x to be {y | ⟨x, y⟩∈R}. The equivalence classes
then partition A. That is, the equivalence classes are subsets of A such
that each member of A belongs to exactly one equivalence class. For x
and y in A,
[x] = [y]
iff
⟨x, y⟩∈R.
The set N of natural numbers is the set {0, 1, 2, . . .}. (Natural num-
bers can also be deﬁned set-theoretically, a point that arises brieﬂy in
Section 3.7.) A set A is ﬁnite iff there is some one-to-one function f
mapping (for some natural number n) the set A onto {0, 1, . . . , n −1}.
(We can think of f as “counting” the members of A.)
A set A is countable iff there is some function mapping A one-to-one
into N. For example, any ﬁnite set is obviously countable. Now consider
an inﬁnite countable set A. Then from the given function f mapping
A one-to-one into N, we can extract a function f ′ mapping A one-to-
one onto N. For some a0 ∈A, f (a0) is the least member of ran f , let
f ′(a0) = 0. In general there is a unique an ∈A such that f (an) is the
(n + 1)st member of ran f ; let f ′(an) = n. Note that A = {a0, a1, . . .}.
(We can also think of f ′ as “counting” the members of A, only now the
counting process is inﬁnite.)
THEOREM 0B
Let A be a countable set. Then the set of all ﬁnite
sequences of members of A is also countable.
PROOF.
The set S of all such ﬁnite sequences can be characterized
by the equation
S =

n∈N
An+1.
Since A is countable, we have a function f mapping A one-
to-one into N.
The basic idea is to map S one-to-one into N by assigning
to ⟨a0, a1, . . . , am⟩the number 2 f (a0)+13 f (a1)+1 · . . . · p f (am)+1
m
,
where pm is the (m + 1)st prime. This suffers from the defect
that this assignment might not be well-deﬁned. For conceivably
there could be ⟨a0, a1, . . . , am⟩= ⟨b0, b1, . . . , bn⟩, with ai and
b j in A but with m ̸= n. But this is not serious; just assign to
each member of S the smallest number obtainable in the above

Chapter 0:
Useful Facts about Sets
7
fashion. This gives us a well-deﬁned map; it is easy to see that it
is one-to-one.
⊣
At times we will speak of trees, which can be useful in providing
intuitive pictures of some situations. But our comments on trees will
always be informal; the theorems and proofs will not rely on trees.
Accordingly, our discussion here of trees will be informal.
For each tree there is an underlying ﬁnite partial ordering. We can
draw a picture of this partial ordering R; if ⟨a, b⟩∈R, then we put a
lower than b and connect the points by a line. Pictures of two typical
tree orderings are shown.
(In mathematics, trees grow downward, not upward.) There is always a
highest point in the picture (the root). Furthermore, while branching is
permitted below some vertex, the points above any given vertex must
lie along a line.
In addition to this underlying ﬁnite partial ordering, a tree also has a
labeling function whose domain is the set of vertices. For example, one
tree, in which the labels are natural numbers, is shown.
At a few points in the book we will use the axiom of choice. But
usually these uses can be eliminated if the theorems in question are
restricted to countable languages. Of the many equivalent statements of
the axiom of choice, Zorn’s lemma is especially useful.
Say that a collection C of sets is a chain iff for any elements x and
y of C, either x ⊆y or y ⊆x.
ZORN’S LEMMA
Let A be a set such that for any chain C ⊆A, the set
 C is in A. Then there is some element m ∈A which is maximal
in the sense that it is not a subset of any other element of A.

8
A Mathematical Introduction to Logic
Cardinal Numbers
All inﬁnite sets are big, but some are bigger than others. (For example,
the set of real numbers is bigger than the set of integers.) Cardinal num-
bers provide a convenient, although not indispensable, way of talking
about the size of sets.
It is natural to say that two sets A and B have the same size iff there is
a function that maps A one-to-one onto B. If A and B are ﬁnite, then this
concept is equivalent to the usual one: If you count the members of A
and the members of B, then you get the same number both times. But it
is applicable even to inﬁnite sets A and B, where counting is difﬁcult.
Formally, then, say that A and B are equinumerous (written A ∼B)
iff there is a one-to-one function mapping A onto B. For example, the
set N of natural numbers and the set Z of integers are equinumerous. It
is easy to see that equinumerosity is reﬂexive, symmetric, and transitive.
For ﬁnite sets we can use natural numbers as measures of size. The
same natural number would be assigned to two ﬁnite sets (as measures
of their size) iff the sets were equinumerous. Cardinal numbers are
introduced to enable us to generalize this situation to inﬁnite sets.
To each set A we can assign a certain object, the cardinal number
(or cardinality) of A (written card A), in such a way that two sets are
assigned the same cardinality iff they are equinumerous:
card A = card B
iff
A ∼B.
(K)
There are several ways of accomplishing this; the standard one these
days takes card A to be the least ordinal equinumerous with A. (The
success of this deﬁnition relies on the axiom of choice.) We will not
discuss ordinals here, since for our purposes it matters very little what
card A actually is, any more than it matters what the number 2 actually
is. What matters most is that (K) holds. It is helpful, however, if for a
ﬁnite set A, card A is the natural number telling how many elements A
has. Something is a cardinal number, or simply a cardinal, iff it is card A
for some set A.
(Georg Cantor, who ﬁrst introduced the concept of cardinal number,
characterized in 1895 the cardinal number of a set M as “the general
concept which, with the help of our active intelligence, comes from the
set M upon abstraction from the nature of its various elements and from
the order of their being given.”)
Say that A is dominated by B (written A ⪯B) iff A is equinumerous
with a subset of B. In other words, A ⪯B iff there is a one-to-one
function mapping A into B. The companion concept for cardinals is
card A ≤card B
iff
A ⪯B.
(It is easy to see that ≤is well deﬁned; that is, whether or not κ ≤λ
depends only on the cardinals κ and λ themselves, and not the choice of

Chapter 0:
Useful Facts about Sets
9
sets having these cardinalities.) Dominance is reﬂexive and transitive. A
set A is dominated by N iff A is countable. The following is a standard
result in this subject.
SCHR¨ODER–BERNSTEIN THEOREM
(a) For any sets A and B, if A ⪯B
and B ⪯A, then A ∼B.
(b) For any cardinal numbers κ and λ, if κ ≤λ and λ ≤κ, then
κ = λ.
Part (b) is a simple restatement of part (a) in terms of cardinal num-
bers. The following theorem, which happens to be equivalent to the
axiom of choice, is stated in the same dual manner.
THEOREM 0C
(a) For any sets A and B, either A ⪯B or B ⪯A.
(b) For any cardinal numbers κ and λ, either κ ≤λ or λ ≤κ.
Thus of any two cardinals, one is smaller than the other. (In fact, any
nonempty set of cardinal numbers contains a smallest member.) The
smallest cardinals are those of ﬁnite sets: 0, 1, 2, . . . . There is next the
smallest inﬁnite cardinal, card N, which is given the name ℵ0. Thus we
have
0, 1, 2, . . . , ℵ0, ℵ1, . . . ,
where ℵ1 is the smallest cardinal larger than ℵ0. The cardinality of the
real numbers, card R, is called “2ℵ0.” Since R is uncountable, we have
ℵ0 < 2ℵ0.
The operations of addition and multiplication, long familiar for ﬁnite
cardinals, can be extended to all cardinals. To compute κ +λ we choose
disjoint sets A and B of cardinality κ and λ, respectively. Then
κ + λ = card(A ∪B).
This is well deﬁned; i.e., κ + λ depends only on κ and λ, and not on the
choice of the disjoint sets A and B. For multiplication we use
κ · λ = card(A × B).
Clearly these deﬁnitions are correct for ﬁnite cardinals. The arithmetic
of inﬁnite cardinals is surprisingly simple (with the axiom of choice).
The sum or product of two inﬁnite cardinals is simply the larger of them:
CARDINAL ARITHMETIC THEOREM
Forcardinalnumbersκ andλ,ifκ ≤
λ and λ is inﬁnite, then κ + λ = λ. Furthermore, if κ ̸= 0, then
κ · λ = λ.
In particular, for inﬁnite cardinals κ,
ℵ0 · κ = κ.

10
A Mathematical Introduction to Logic
THEOREM 0D
For an inﬁnite set A, the set 
n An+1 of all ﬁnite se-
quences of elements of A has cardinality equal to card A.
We already proved this for the case of a countable A (see Theo-
rem 0B).
PROOF.
Each An+1 has cardinality equal to card A, by the cardinal
arithmetic theorem (applied n times). So we have the union of ℵ0
sets of this size, yielding ℵ0 · card A = card A points altogether.
⊣
EXAMPLE.
It follows that the set of algebraic numbers has cardinal-
ity ℵ0. First, we can identify each polynomial (in one variable)
over the integers with the sequence of its coefﬁcients. Then by
the theorem there are ℵ0 polynomials. Each polynomial has a ﬁ-
nite number of roots. To give an extravagant upper bound, note
that even if each polynomial had ℵ0 roots, we would then have
ℵ0 · ℵ0 = ℵ0 algebraic numbers altogether. Since there are at least
this many, we are done.
Since there are uncountably many (in fact, 2ℵ0) real numbers, it
follows that there are uncountably many (in fact, 2ℵ0) transcendental
numbers.

Chapter
O N E
Sentential Logic
SECTION 1.0
Informal Remarks on
Formal Languages
We are about to construct (in the next section) a
language into which we can translate English sen-
tences. Unlike natural languages (such as English
or Chinese), it will be a formal language, with pre-
cise formation rules. But before the precision be-
gins, we will consider here some of the features to
be incorporated into the language.
As a ﬁrst example, the English sentence “Traces
of potassium were observed” can be translated into
the formal language as, say, the symbol K. Then for
the closely related sentence “Traces of potassium
were not observed,” we can use (¬ K). Here ¬ is
our negation symbol, read as “not.” One might also
think of translating “Traces of potassium were not
observed” by some new symbol, for example, J,
but we will prefer instead to break such a sentence
down into atomic parts as much as possible. For an
unrelated sentence, “The sample contained chlo-
rine,” we choose, say, the symbol C. Then the fol-
lowing compound English sentences can be trans-
lated as the formulas shown at the right:
If traces of potassium were ob-
served, then the sample did not
contain chlorine.
(K →(¬ C))
Thesamplecontainedchlorine,
and traces of potassium were ob-
served.
(C ∧K)
11

12
A Mathematical Introduction to Logic
The second case uses our conjunction symbol ∧to translate “and.”
The ﬁrst one uses the more familiar arrow to translate “if . . . , then . . . .”
In the following example the disjunction symbol ∨is used to translate
“or”:
Either no traces of potassium were observed, or
the sample did not contain chlorine.
((¬ K) ∨(¬ C))
Neither did the sample contain
(¬ (C ∨K))
chlorine, nor were traces of
or
potassium observed.
((¬ C) ∧(¬ K))
For this last sentence, we have two alternative translations. The re-
lationship between them will be discussed later.
One important aspect of the decompositions we will make of com-
pound sentences is that whenever we are given the truth or falsity of the
atomic parts, we can then immediately calculate the truth or falsity of
the compound. Suppose, for example, that the chemist emerges from
her laboratory and announces that she observed traces of potassium but
that the sample contained no chlorine. We then know that the four above
sentences are true, false, true, and false, respectively. In fact, we can con-
struct in advance a table giving the four possible experimental results
(Table I). We will return to the discussion of such tables in Section 1.2.
TABLE I
K
C
(¬(C ∨K))
((¬ C) ∧(¬ K))
F
F
T
T
F
T
F
F
T
F
F
F
T
T
F
F
Use of formal languages will allow us to escape from the imprecision
and ambiguities of natural languages. But this is not done without cost;
our formal languages will have a sharply limited degree of expressive-
ness.
In order to describe a formal language we will generally give three
pieces of information:
1. We will specify the set of symbols (the alphabet). In the present
case of sentential logic some of the symbols are
(, ), →, ¬, A1, A2, . . . .
2. We will specify the rules for forming the “grammatically correct”
ﬁnite sequences of symbols. (Such sequences will be called well-formed
formulas or wffs.) For example, in the present case
(A1 →(¬ A2))

Chapter 1:
Sentential Logic
13
will be a wff, whereas
)) →A3
will not.
3. We will also indicate the allowable translations between English
and the formal language. The symbols A1, A2, . . . can be translations
of declarative English sentences.
Only in this third part is any meaning assigned to the wffs. This
process of assigning meaning guides and motivates all we do. But it
will also be observed that it would theoretically be possible to carry out
various manipulations with wffs in complete ignorance of any possible
meaning. A person aware of only the ﬁrst two pieces of information
listed above could perform some of the things we will do, but it would
make no sense to him.
Before proceeding, let us look brieﬂy at another class of formal
languages of widespread interest today. These are the languages used
by (or at least in connection with) digital computers.
There are many of these languages. In one of them a typical wff is
011010110101000111110001000001111010.
In another a typical wff is
STEP#ADDIMAX, A.
(Here # is a symbol called a blank; it is brought into the alphabet so that
a wff will be a string of symbols.) A well-known language called C++
has wffs such as
while(∗s++);
In all cases there is a given way of translating the wffs into English,
and (for a restricted class of English sentences) a way of translating
from English into the formal language. But the computer is unaware of
the English language. An unthinking automaton, the computer juggles
symbols and follows its program slavishly. We could approach formal
languages that way, too, but it would not be much fun.
SECTION 1.1
The Language of Sentential Logic
We assume we are given an inﬁnite sequence of distinct objects which
we will call symbols, and to which we now give names (Table II). We
further assume that no one of these symbols is a ﬁnite sequence of other
symbols.

14
A Mathematical Introduction to Logic
TABLE II
Symbol
Verbose name
Remarks
(
left parenthesis
punctuation
)
right parenthesis
punctuation
¬
negation symbol
English: not
∧
conjunction symbol
English: and
∨
disjunction symbol
English: or (inclusive)
→
conditional symbol
English: if
, then
↔
biconditional symbol
English: if and only if
A1
ﬁrst sentence symbol
A2
second sentence symbol
· · ·
An
nth sentence symbol
· · ·
Several remarks are now in order:
1. The ﬁve symbols
¬, ∧, ∨, →, ↔
are called sentential connective symbols. Their use is suggested by the
English translation given above. The sentential connective symbols,
together with the parentheses, are the logical symbols. In translating to
and from English, their role never changes. The sentence symbols are
the parameters (or nonlogical symbols). Their translation is not ﬁxed;
instead they will be open to a variety of interpretations, as we shall
illustrate shortly.
2. We have included inﬁnitely many sentence symbols. On the one
hand, a more modest alternative would be to have one sentence symbol
A, and a prime ′. Then we could use the potentially inﬁnite sequence
A, A′, A′′, . . .
in place of
A1, A2, A3 . . . .
This alternative has the advantage that it brings the total number of
different symbols down to nine. On the other hand, a less modest al-
ternative would be to allow an arbitrary set of set sentence symbols,
countable or not. Much of what is said in this chapter would con-
tinue to be applicable in this case; the exceptions are primarily in Sec-
tion 1.7.
3. Some logicians prefer to call An the nth proposition symbol (and
to speak of propositional logic instead of sentential logic). This stems

Chapter 1:
Sentential Logic
15
from wanting the word “sentence” to refer to a particular utterance, and
wanting a proposition to be that which a sentence asserts.
4. We call these objects “symbols,” but we remain neutral as to what
the exact ontological status of symbols might be. In the leftmost column
of our list of symbols, names of the symbols are printed. For example,
A243 is one symbol, namely the 243rd sentence symbol. (On the other
hand, “A243” is a name of that symbol. The conditional symbol may
or may not have the geometric property of being shaped like an arrow,
although its name “→” does.) The symbols themselves can be sets,
numbers, marbles, or objects from a universe of linguistic objects. In
the last case, it is conceivable that they are actually the same things as
the names we use for them. Another possibility, which will be explained
in the next chapter, is that the sentence symbols are themselves formulas
in another language.
5. We have assumed that no symbol is a ﬁnite sequence of other
symbols. We mean by this that not only are the symbols listed distinct
(e.g., A3 ̸= ↔), but no one of them is a ﬁnite sequence of two or more
symbols. For example, we demand that A3 ̸= ⟨¬, A4, (⟩. The purpose of
this assumption is to assure that ﬁnite sequences of symbols are uniquely
decomposable. If
⟨a1, . . . , am⟩= ⟨b1, . . . , bn⟩
and each ai and each b j is a symbol, then m = n and ai = bi. (See
Chapter 0, Lemma 0A, and subsequent remarks.)
An expression is a ﬁnite sequence of symbols. We can specify an
expression by concatenating the names of the symbols; thus (¬ A1) is
the sequence ⟨(, ¬, A1, )⟩. This notation is extended: If α and β are
sequences of symbols, then αβ is the sequence consisting ﬁrst of the
symbols in the sequence α followed by the symbols in the sequence β.
For example, if α and β are the expressions given by the equations
α = (¬ A1),
β = A2,
then (α →β) is the expression
((¬ A1) →A2).
We should now look at a few examples of possible translations of
English sentences into expressions of the formal language. Let A, B,
. . . , Z be the ﬁrst twenty-six sentence symbols. (For example, E = A5.)
1. English: The suspect must be released from custody. Transla-
tion: R.
English: The evidence obtained is admissible. Translation: E.
English: The evidence obtained is inadmissible. Translation: (¬ E).

16
A Mathematical Introduction to Logic
English: The evidence obtained is admissible, and the suspect need
not be released from custody. Translation: (E ∧(¬ R)).
English: Either the evidence obtained is admissible, or the suspect
must be released from custody (or possibly both). Translation: (E ∨R).
English: Either the evidence obtained is admissible, or the suspect
must be released from custody, but not both. Translation: ((E ∨R) ∧
(¬ (E ∧R))). We intend always to use the symbol ∨to translate the
word “or” in its inclusive meaning of “and/or.”
English: The evidence obtained is inadmissible, but the suspect need
not be released from custody. Translation: ((¬ E) ∧(¬ R)). On the other
hand, the expression ((¬ E) ∨(¬ R)) translates the English: Either the
evidence obtained is inadmissible or the suspect need not be released
from custody.
2. English: If wishes are horses, then beggars will ride. Translation:
(W →B).
English: Beggars will ride if and only if wishes are horses. Transla-
tion: (B ↔W).
3. English: This commodity constitutes wealth if and only if it is
transferable, limited in supply, and either productive of pleasure or pre-
ventive of pain. Translation: (W ↔(T ∧(L ∧(P ∨Q)))). Here W is
the translation of “This commodity constitutes wealth.” Of course in the
preceding example we used W to translate a different sentence. We are
not tied to any one translation.
One note of caution: Do not confuse a sentence in the English lan-
guage (Roses are red) with a translation of that sentence in the formal
language (such as R). These are different. The English sentence is pre-
sumably either true or false. But the formal expression is simply a se-
quence of symbols. It may indeed be interpreted in one context as a true
(or false) English sentence, but it can have other interpretations in other
contexts.
Now some expressions cannot be obtained as translations of any
English sentences but are mere nonsense, such as
((→A3.
We want to deﬁne the well-formed formulas (wffs) to be the “gram-
matically correct” expressions; the nonsensical expressions must be
excluded. The deﬁnition will have the following consequences:
(a) Every sentence symbol is a wff.
(b) If α and β are wffs, then so are (¬ α), (α ∧β), (α ∨β), (α →β),
and (α ↔β).
(c) No expression is a wff unless it is compelled to be one by (a)
and (b).

Chapter 1:
Sentential Logic
17
We want to make this third property (about compulsion) more pre-
cise. A well-formed formula (or simply formula or wff) is an expres-
sion that can be built up from the sentence symbols by applying some
ﬁnite number of times the formula-building operations (on expressions)
deﬁned by the equations
E¬(α) = (¬ α)
E∧(α, β) = (α ∧β),
E∨(α, β) = (α ∨β),
E→(α, β) = (α →β),
E↔(α, β) = (α ↔β).
For example,
((A1 ∧A10) →((¬ A3) ∨(A8 ↔A3)))
is a wff, as can be seen by contemplating its ancestral tree:
The tree illustrates the construction of the expression from four sen-
tence symbols by ﬁve applications of formula-building operations. This
example is atypical in that it uses all ﬁve formula-building operations.
For a smaller example, A3 is a wff; its ancestral tree has only a single
vertex; each formula-building operation is used zero times. But this is
as small as examples get; we do not count the empty sequence as being
“built up from the sentence symbols.”
This sort of construction, of taking some basic building blocks (here
the sentence symbols) and “closing” under some operations (here ﬁve
operations), occurs frequently both in logic and in other branches of
mathematics. In Section 1.4, we will examine this sort of construction
in a more general setting.
We can elaborate on the “building” idea as follows. Deﬁne a con-
struction sequence to be a ﬁnite sequence ⟨ε1, . . . , εn⟩of expressions

18
A Mathematical Introduction to Logic
such that for each i ≤n we have at least one of
εi is a sentence symbol
εi = E¬(ε j) for some j < i
εi = E□(ε j, εk) for some j < i, k < i
where □is one of the binary connectives, ∧, ∨, →, ↔. Then the well-
formed formulas can be characterized as the expressions α such that
some construction sequence ends with α. We can think of εi as the
expression at stage i in the building process.
For our earlier example,
((A1 ∧A10) →((¬ A3) ∨(A8 ↔A3)))
we obtain a construction sequence by squashing its ancestral tree into a
linear ordering.
One feature of this sort of construction is that it yields an induction
principle. Say that a set S is closed under a two-place function f iff
whenever x ∈S and y ∈S then f (x, y) ∈S,andsimilarlyforone-place
functions and so forth.
INDUCTION PRINCIPLE
If S is a set of wffs containing all the sentence
symbols and closed under all ﬁve formula-building operations,
then S is the set of all wffs.
FIRST PROOF.
Consideranarbitrarywffα.Itisbuiltupfromsentence
symbols by applying some ﬁnite number of times the formula-
building operations. Working our way up the corresponding an-
cestral tree, we ﬁnd that each expression in the tree belongs to S.
Eventually (that is, after a ﬁnite number of steps) at the top of the
tree we ﬁnd that α ∈S.
⊣
SECOND PROOF.
We will repeat the argument, but without the trees.
Consider an arbitrary wff α. It is the last member of some con-
struction sequence ⟨ε1, . . . , εn⟩. By ordinary strong numerical in-
duction on the number i, we see that each εi ∈S, i ≤n.
That is, we suppose, as our inductive hypothesis, that ε j ∈S
for all j < i. We then verify that εi ∈S, by considering the
various cases. So by strong induction on i, it follows that εi ∈S
for each i ≤n. In particular, the last member α belongs to S.
⊣
This principle will receive much use in the coming pages. In the
following example we use it to show that certain expressions are not
wffs.
EXAMPLE.
Any expression with more left parentheses than right
parentheses is not a wff.

Chapter 1:
Sentential Logic
19
PROOF.
The idea is that we start with sentence symbols (having
zero left parentheses and zero right parentheses), and then ap-
ply formula-building operations which add parentheses only in
matched pairs. We can rephrase this argument as follows: The
set of “balanced” wffs (having equal numbers of left and right
parentheses) contains all sentence symbols and is closed under
the formula-building operations. The induction principle then as-
sures us that all wffs are balanced.
⊣
A special feature of our particular formula-building operations is that
they build up and never down. That is, the expression E□(α, β) always
includes as a segment the entire sequence α (and the entire sequence β)
plus other symbols. In particular, it is longer than either α or β.
This special feature will simplify the problem of determining, given
a wff ϕ, exactly how it was built up. All the building blocks, so to speak,
are included as segments in the sequence ϕ. For example, if ϕ does not
contain the symbol A4, then ϕ can be built up without ever using A4.
(See Exercise 4.)
Exercises
1. Give three sentences in English together with translations into our
formal language. The sentences should be chosen so as to have an
interesting structure, and the translations should each contain 15 or
more symbols.
2. Show that there are no wffs of length 2, 3, or 6, but that any other
positive length is possible.
3. Let α be a wff; let c be the number of places at which binary con-
nective symbols (∧, ∨, →, ↔) occur in α; let s be the number of
places at which sentence symbols occur in α. (For example, if α is
(A →(¬ A)) then c = 1 and s = 2.) Show by using the induction
principle that s = c + 1.
4. Assume we have a construction sequence ending in ϕ, where ϕ does
not contain the symbol A4. Suppose we delete all the expressions
in the construction sequence that contain A4. Show that the result is
still a legal construction sequence.
5. Suppose that α is a wff not containing the negation symbol ¬.
(a) Show that the length of α (i.e., the number of symbols in the
string) is odd.
(b) Show that more than a quarter of the symbols are sentence
symbols.
Suggestion: Apply induction to show that the length is of the form
4k + 1 and the number of sentence symbols is k + 1.

20
A Mathematical Introduction to Logic
SECTION 1.2
Truth Assignments
We want to deﬁne what it means for one wff of our language to fol-
low logically from other wffs. For example, A1 should follow from
(A1 ∧A2). For no matter how the parameters A1 and A2 are translated
back into English, if the translation of (A1 ∧A2) is true, then the transla-
tion of A1 must be true. But the notion of all possible translations back
into English is unworkably vague. Luckily the spirit of this notion can
be expressed in a simple and precise way.
Fix once and for all a set {F, T } of truth values consisting of two
distinct points:
F,
called falsity,
T,
called truth.
(It makes no difference what these points themselves are; they might as
well be the numbers 0 and 1.) Then a truth assignment v for a set S of
sentence symbols is a function
v : S →{F, T }
assigning either T or F to each symbol in S. These truth assignments
will be used in place of the translations into English mentioned in the
preceding paragraph.
(At this point we have committed ourselves to two-valued logic. It is
also possible to study three-valued logic, in which case one has a set of
three possible truth values. And then, of course, it is a small additional
step to allow 512 or ℵ0 truth values; or to take as the set of truth values
the unit interval [0, 1] or some other convenient space. A particularly
interesting case is that for which the truth values form something called
a complete Boolean algebra. But it is two-valued logic that has always
had the greatest signiﬁcance, and we will conﬁne ourselves to this case.)
Let S be the set of wffs that can be built up from S by the ﬁve
formula-building operations. (S can also be characterized as the set of
wffs whose sentence symbols are all in S; see the remarks at the end of
the preceding section.) We want an extension v of v,
v : S →{F, T },
that assigns the correct truth value to each wff in S. It should meet the
following conditions:
0. For any A ∈S, v(A) = v(A). (Thus v is an extension of v.)
For any α, β in S:
1. v((¬ α)) =

T
if
v(α) = F,
F
otherwise.

Chapter 1:
Sentential Logic
21
2. v((α ∧β)) =

T
if
v(α) = T
and
v(β) = T,
F
otherwise.
3. v((α ∨β)) =

T
if
v(α) = T
or
v(β) = T (or both),
F
otherwise.
4. v((α →β)) =

F
if
v(α) = T
and
v(β) = F,
T
otherwise.
5. v((α ↔β)) =

T
if
v(α) = v(β),
F
otherwise.
Conditions 1–5 are given in tabular form in Table III. It is at this point
thattheintendedmeaningof,forexample,theconjunctionsymbolenters
into our formal proceedings. Note especially the intended meaning of
→. Whenever α is assigned F, then (α →β) is considered “vacuously
true” and is assigned the value T . For this and the other connectives, it
is certainly possible to question how accurately we have reﬂected the
common meaning in everyday speech of “if . . . , then,” “or,” etc. But
our ultimate concern lies more with mathematical statements than with
the subtle nuances of everyday speech.
TABLE III
α
β
(¬ α)
(α ∧β)
(α ∨β)
(α →β)
(α ↔β)
T
T
F
T
T
T
T
T
F
F
F
T
F
F
F
T
T
F
T
T
F
F
F
T
F
F
T
T
For example, we might translate the English sentence, “If you’re
telling the truth then I’m a monkey’s uncle,” by the formula (V →M).
We assign this formula the value T whenever you are ﬁbbing. In as-
signing the value T , we are certainly not asserting any causal connec-
tion between your veracity and any simian features of my nephews or
nieces. The sentence in question is a conditional statement. It makes an
assertion about my relatives provided a certain condition — that you are
telling the truth — is met. Whenever that condition fails, the statement
is vacuously true.
Very roughly, we can think of a conditional formula (α →β) as
expressing a promise that if a certain condition is met (viz., that α is
true), then β is true. If the condition α turns out not to be met, then the
promise stands unbroken, regardless of β.
As an example of the calculation of v, let α be the wff
((A2 →(A1 →A6)) ↔((A2 ∧A1) →A6))

22
A Mathematical Introduction to Logic
and let v be the truth assignment for {A1, A2, A6} such that
v(A1) = T,
v(A2) = T,
v(A6) = F.
We want to compute v(α). We can look at the tree which displays the
construction of α:
Working from the bottom up, we can assign to each vertex β of the tree
the value v(β). So as a ﬁrst step we compute
v((A1 →A6)) = F
and
v((A2 ∧A1)) = T.
Next we compute v((A2 →(A1 →A6))) = F, and so forth. Finally, at
the top of the tree we arrive at v(α) = T .
Actually this computation can be carried out with much less writing.
First, the tree can be given in starker form:
And even this can be compressed into a single line (with the parentheses
restored):

Chapter 1:
Sentential Logic
23
THEOREM 12A
For any truth assignment v for a set S there is a
unique function v : S →{F, T } meeting the aforementioned
conditions 0–5.
Thefullproofofthistheoremwillemergeinthenexttwosections(1.3
and 1.4). But it should already seem extremely plausible, especially in
light of the preceding example. In proving the existence of v, the crucial
issue will, in effect, be the uniqueness of the trees mentioned in the
example.
We say that a truth assignment v satisﬁes ϕ iff v(ϕ) = T . (Of course
for this to happen, the domain of v must contain all sentence symbols in
ϕ.) Now consider a set  of wffs (thought of as hypotheses) and another
wff τ (thought of as a possible conclusion).
DEFINITION.
 tautologically implies τ (written  |= τ) iff every
truth assignment for the sentence symbols in  and τ that satisﬁes
every member of  also satisﬁes τ.
This deﬁnition reﬂects our intuitive feeling that a conclusion follows
from a set of hypotheses if the assumption that the hypotheses are true
guarantees that the conclusion is true.
Several special cases of the concept of tautological implication de-
serve mention. First, take the special case in which  is the empty set ∅.
Observe that it is vacuously true that any truth assignment satisﬁes every
member of ∅. (How could this fail? Only if there was some unsatisﬁed
member of ∅, which is absurd.) Hence we are left with: ∅|= τ iff every
truth assignment (for the sentence symbols in τ) satisﬁes τ. In this case
we say that τ is a tautology (written |= τ). For example, the wff ((A2 →
(A1 →A6)) ↔((A2 ∧A1) →A6)) was in a recent example found to be
satisﬁed by one of the eight possible truth assignments for {A1, A2, A6}.
In fact, it is satisﬁed by the other seven as well, and hence is a tautology.
Another special case is that in which no truth assignment satisﬁes
every member of . Then for any τ, it is vacuously true that  |= τ.
For example,
{A, (¬ A)} |= B.
There is no deep principle involved here; it is simply a by-product of
our deﬁnitions.
EXAMPLE.
{A, (A →B)} |= B. There are four truth assignments for
{A, B}. It is easy to check that only one of these four satisﬁes both
A and (A →B), namely the v for which v(A) = v(B) = T . This
v also satisﬁes B.

24
A Mathematical Introduction to Logic
If  is singleton {σ}, then we write “σ |= τ” in place of “{σ} |= τ.” If
both σ |= τ and τ |= σ, then σ and τ are said to be tautologically equiv-
alent (written σ |==| τ). For example, in Section 1.0 we encountered
the wffs (¬ (C∨K)) and ((¬ C)∧(¬ K)) as alternative translations of an
English sentence. We can now assert that they are tautologically equiv-
alent.
We can already state here a nontrivial fact whose proof will be given
later (in Section 1.7).
COMPACTNESS THEOREM
Let  be an inﬁnite set of wffs such that for
any ﬁnite subset 0 of , there is a truth assignment that satisﬁes
every member of 0. Then there is a truth assignment that satisﬁes
every member of .
This theorem can be restated more simply as: If every ﬁnite subset of
 is satisﬁable, then  itself is satisﬁable. (Readers familiar with some
general topology might try to discover why this is called “compactness
theorem”; it does assert the compactness of a certain topological space.
They can then prove the theorem for themselves, by using Tychonoff’s
theorem on product spaces.)
Truth Tables
There is a systematic procedure, which we will now illustrate, for check-
ing, given wffs σ1, . . . , σk, and τ, whether or not
{σ1, . . . , σk} |= τ.
In particular (when k = 0), the procedure will, given a wff, decide
whether or not it is a tautology.
As a ﬁrst example, we can show that
(¬ (A ∧B)) |= ((¬ A) ∨(¬ B)).
To do this, we consider all truth assignments for {A, B}. There are four
such assignments; in general there are 2n truth assignments for a set of
n sentence symbols. The four can be listed in a table:
A
B
T
T
T
F
F
T
F
F
This table can then be expanded to include (¬ (A∧B)) and ((¬ A)∨
(¬ B)). For each formula we compute the T ’s and F’s the way described
before, writing the truth value under the correct connective (Table IV).
(The two leftmost columns of Table IV are actually unnecessary.) We
can now see from this table that all those truth assignments satisfying
(¬ (A ∧B)) — and there are three such — also satisfy ((¬ A) ∨(¬ B)).

Chapter 1:
Sentential Logic
25
TABLE IV
A
B
(¬(A ∧B))
((¬A) ∨(¬B))
T
T
F T T T
F T F F T
T
F
T T F F
F T T T F
F
T
T F F T
T F T F T
F
F
T F F F
T F T T F
In fact, the converse holds also, and thus
(¬ (A ∧B)) |==| ((¬ A) ∨( ¬ B)).
To show that (¬ (A ∧B)) ̸|= ((¬ A) ∧(¬ B)) we can construct the
table as before. But only one line of the table is needed to establish that
there is indeed a truth assignment satisfying (¬ (A ∧B)) that fails to
satisfy ((¬ A) ∧(¬ B)).
The more generally applicable a procedure it is, the less efﬁcient it
is likely to be. For example, to show that
|= ((A ∨(B ∧C)) ↔((A ∨B) ∧(A ∨C))),
we could apply the truth-table method. But this requires eight lines
(for the eight possible truth assignments for {A, B, C}). With a little
cleverness, the tedium in this particular case can be reduced:
In the ﬁrst line we assumed only that v(A) = T . Since that is enough
information to obtain T for the wff, we assume in all later lines that
v(A) = F. In the second line we assume that v(B) = F; this again lets
us obtain T for the wff. So we may limit ourselves to the case v(B) = T .
Since the expression is symmetric in B and C, we may further suppose
v(C) = T . This leaves only the third line, whereupon we are done.
As an example of the avoidance of a 16-line table, consider the
following tautology:
Here in the ﬁrst line we dispose of the case where v(S) = T . In the
second line we dispose of the case where either v(P) = F or v(Q) = F.

26
A Mathematical Introduction to Logic
The third line incorporates the two remaining possibilities; here R is the
truth value assigned to R and R is the opposite value.
For the above example it is possible to see directly why it is a tautol-
ogy. The stronger the antecedent (the expression on the left side), the
weaker the conditional. Thus
(P ∧Q) |= P,
(P →R) |= ((P ∧Q) →R),
(((P ∧Q) →R) →S) |= ((P →R) →S).
The problem of developing effective procedures that reduce the
tedium is important for theorem proving by machine. Some of the pro-
grams here may require testing wffs of sentential logic having thousands
of sentence symbols. Truth tables are far too cumbersome for anything
this large. The problem of developing highly efﬁcient methods is a cur-
rent area of research in computer science.
Digression.
Applying the truth-table method — carried out in
full — to a wff with n sentence symbols requires making a table of
2n lines. The trouble is, as n increases, 2n grows “exponentially.” For
example, suppose you can generate the table at the rate of a million lines
per second. (We are supposing you are aided by a computer, of course.)
Then if n = 80, say, you will need “merely” 280 microseconds to form
the complete table. How long is that? Converted to years, 280 microsec-
onds is about 38 billion years. For comparison, the age of the universe
is around 15 billion years. The conclusion is that 280 microseconds is
more time than there has been time!
Is there a faster method? Might there be some general method that,
given any wff α with n sentence symbols, will determine whether or
not α is a tautology in only 10n5 microseconds (or some other function
of n that grows like a polynomial instead of growing exponentially)?
(For n = 80, 10n5 microseconds comes to only 9 hours.) The answer
to this question is unknown, but it is widely believed that the answer is
negative. The question is called the “P versus NP” problem, the most
prominent open problem in theoretical computer science today.
A Selected List of Tautologies
1. Associative and commutative laws for ∧, ∨, ↔.
2. Distributive laws:
((A ∧(B ∨C)) ↔((A ∧B) ∨(A ∧C))).
((A ∨(B ∧C)) ↔((A ∨B) ∧(A ∨C))).

Chapter 1:
Sentential Logic
27
3. Negation:
((¬ (¬ A)) ↔A).
((¬ (A →B)) ↔(A ∧(¬ B))).
((¬ (A ↔B)) ↔((A ∧(¬ B)) ∨((¬ A) ∧B))).
De Morgan’s laws:
((¬ (A ∧B)) ↔((¬ A) ∨(¬ B))).
((¬ (A ∨B)) ↔((¬ A) ∧(¬ B))).
4. Other
Excluded middle:
(A ∨(¬ A)).
Contradiction:
(¬ (A ∧(¬ A))).
Contraposition:
((A →B) ↔((¬ B) →(¬ A))).
Exportation:
(((A ∧B) →C) ↔(A →(B →C))).
Exercises
1. Show that neither of the following two formulas tautologically im-
plies the other:
(A ↔(B ↔C)),
((A ∧(B ∧C)) ∨((¬ A) ∧((¬ B) ∧(¬ C)))).
Suggestion: Only two truth assignments are needed, not eight.
2. (a) Is (((P →Q) →P) →P) a tautology?
(b) Deﬁne σk recursively as follows: σ0 = (P →Q) and σk+1 =
(σk →P). For which values of k is σk a tautology? (Part (a)
corresponds to k = 2.)
3. (a) Determine whether or not ((P→Q)∨(Q→P)) is a tautology.
(b) Determine whether or not ((P∧Q)→R) tautologically implies
((P →R) ∨(Q →R)).
4. Show that the following hold:
(a) ; α |= β iff  |= (α →β).
(b) α |==| β iff |= (α ↔β).
(Recallthat; α = ∪{α},theset togetherwiththeonepossibly
new member α.)
5. Prove or refute each of the following assertions:
(a) If either  |= α or  |= β, then  |= (α ∨β).
(b) If  |= (α ∨β), then either  |= α or  |= β.
6. (a) Show that if v1 and v2 are truth assignments which agree on all
the sentence symbols in the wff α, then v1(α) = v2(α). Use
the induction principle.

28
A Mathematical Introduction to Logic
(b) Let S be a set of sentence symbols that includes those in  and
τ (and possibly more). Show that  |= τ iff every truth assign-
ment for S which satisﬁes every member of  also satisﬁes τ.
(This is an easy consequence of part (a). The point of part (b)
is that we do not need to worry about getting the domain of a
truth assignment exactly perfect, as long as it is big enough. For
example, one option would be always to use truth assignments
on the set of all sentence symbols. The drawback is that these
are inﬁnite objects, and there are a great many — uncountably
many — of them.)
7. You are in a land inhabited by people who either always tell the
truth or always tell falsehoods. You come to a fork in the road
and you need to know which fork leads to the capital. There is a
local resident there, but he has time only to reply to one yes-or-no
question. What one question should you ask so as to learn which
fork to take? Suggestion: Make a table.
8. (Substitution) Consider a sequence α1, α2, . . . of wffs. For each wff
ϕ let ϕ∗be the result of replacing the sentence symbol An by αn,
for each n.
(a) Let v be a truth assignment for the set of all sentence symbols;
deﬁne u to be the truth assignment for which u(An) = v(αn).
Show that u(ϕ) = v(ϕ∗). Use the induction principle.
(b) Show that if ϕ is a tautology, then so is ϕ∗. (For example, one
of our selected tautologies is ((A ∧B) ↔(B ∧A)). From this
we can conclude, by substitution, that ((α ∧β) ↔(β ∧α)) is
a tautology, for any wffs α and β.)
9. (Duality) Let α be a wff whose only connective symbols are ∧, ∨,
and ¬. Let α∗be the result of interchanging ∧and ∨and replacing
each sentence symbol by its negation. Show that α∗is tautologically
equivalent to (¬ α). Use the induction principle.
Remark: It follows that if α |==| β then α∗|==| β∗.
10. Say that a set 1 of wffs is equivalent to a set 2 of wffs iff for any
wff α, we have 1 |= α iff 2 |= α. A set  is independent iff no
member of  is tautologically implied by the remaining members
in . Show that the following hold.
(a) A ﬁnite set of wffs has an independent equivalent subset.
(b) An inﬁnite set need not have an independent equivalent subset.
∗(c) Let  = {σ0, σ1, . . .}; show that there is an independent equiv-
alent set ′. (By part (b), we cannot hope to have ′ ⊆ in
general.)
11. Show that a truth assignment v satisﬁes the wff
( · · · (A1 ↔A2) ↔· · · ↔An)

Chapter 1:
Sentential Logic
29
iff v(Ai) = F for an even number of i’s, 1 ≤i ≤n. (By the
associative law for ↔, the placement of the parentheses is not
crucial.)
12. There are three suspects for a murder: Adams, Brown, and Clark.
Adams says “I didn’t do it. The victim was an old acquaintance of
Brown’s. But Clark hated him.” Brown states “I didn’t do it. I didn’t
even know the guy. Besides I was out of town all that week.” Clark
says “I didn’t do it. I saw both Adams and Brown downtown with
the victim that day; one of them must have done it.” Assume that
the two innocent men are telling the truth, but that the guilty man
might not be. Who did it?
13. An advertisement for a tennis magazine states, “If I’m not playing
tennis, I’m watching tennis. And if I’m not watching tennis, I’m
reading about tennis.” We can assume that the speaker cannot do
more than one of these activities at a time. What is the speaker
doing? (Translate the given sentences into our formal language;
consider the possible truth assignments.)
14. Let S be the set of all sentence symbols, and assume that v : S →
{F, T } is a truth assignment. Show there is at most one extension
v meeting conditions 0–5 listed at the beginning of this section.
(Suppose that v1 and v2 are both such extensions. Use the induction
principle to show that v1 = v2.)
15. Of the following three formulas, which tautologically imply which?
(a) (A ↔B)
(b) (¬ ((A →B) →(¬ (B →A))))
(c) (((¬ A) ∨B) ∧(A ∨(¬ B)))
SECTION 1.3
A Parsing Algorithm
The purpose of this section is to prove that we have used enough paren-
theses to eliminate any ambiguity in analyzing wffs. (The existence
of the extension v of a truth assignment v will hinge on this lack of
ambiguity.1)
It is instructive to consider the result of not having parentheses at all.
The resulting ambiguity is illustrated by the wff
A1 ∨A2 ∧A3,
1 The reader who has already accepted the existence of v may omit almost all of this
section. The ﬁnal subsection, on omitting parentheses, will still be needed.

30
A Mathematical Introduction to Logic
which can be formed in two ways, corresponding to ((A1 ∨A2) ∧A3)
and to (A1 ∨(A2 ∧A3)). If v(A1) = T and v(A3) = F, then there is an
unresolvable conﬂict that arises in trying to compute v(A1 ∨A2 ∧A3).
We must show that with our parentheses this type of ambiguity does
not arise but that on the contrary each wff is formed in a unique way.
There is one sense in which this fact is unimportant: If it failed, we
would simply change notation until it was true. For example, instead
of building formulas by means of concatenation, we could have used
ordered pairs and triples: ⟨¬, α⟩and ⟨α, ∧, β⟩, and so forth. (This is, in
fact, a tidy, but untraditional, method.) It would then be immediate that
formulas had unique decompositions. But we do not have to resort to
this device, and we will now prove that we do not.
LEMMA 13A
Every wff has the same number of left as right paren-
theses.
PROOF.
This was done as an example at the end of Section 1.1. ⊣
LEMMA 13B
Any proper initial segment of a wff contains an excess
of left parentheses. Thus no proper initial segment of a wff can
itself be a wff.
PROOF.
We apply the induction principle to the set S of wffs pos-
sessing the desired property (that proper initial segments are left-
heavy). A wff consisting of a sentence symbol alone has no proper
initial segments and hence is in S vacuously. To verify that S is
closed under E∧, consider α and β in S. The proper initial seg-
ments of (α ∧β) are the following:
1. (.
2. (α0, where α0 is a proper initial segment of α.
3. (α.
4. (α∧.
5. (α ∧β0, where β0 is a proper initial segment of β.
6. (α ∧β.
By applying the inductive hypothesis that α and β are in S
(in cases 2 and 5), we obtain the desired conclusion. For closure
under the other four formula-building operations, the argument is
similar.
⊣
A Parsing Algorithm
We are now going to describe a procedure that, given an expression,
both will determine whether or not the expression is a legal wff, and if
it is, will construct the tree showing how it was built up from sentence
symbols by application of the formula-building operations. Moreover,

Chapter 1:
Sentential Logic
31
we will see that this tree is uniquely determined by the wff. It is this
last fact that will assure us that we have enough parentheses for an
unambiguous notation.
Assume then that we are given an expression. We will construct a tree,
with the given expression at the top. Initially it is the only vertex in the
tree, but as the procedure progresses, the tree will grow downward from
the given expression. For an example, imagine the tree in Section 1.1.
The algorithm consists of the following four steps:
1. If all minimal vertices (the ones at the bottom) have sentence
symbols, then the procedure is completed. (The given expression is
indeed a wff, and we have constructed its tree.) Otherwise, select a
minimal vertex having an expression that is not a sentence symbol. We
examine that expression.
2. The ﬁrst symbol must∗be (. If the second symbol is the negation
symbol, jump to step 4. Otherwise, go on to step 3.
3. Scan the expression from the left until ﬁrst reaching (α, where
α is a nonempty expression having a balance between left and right
parentheses.∗∗Then α is the ﬁrst of the two constituents. The next
symbol must∗be ∧, ∨, →, or ↔. This is the principal connective. The
remainder of the expression, β), must∗consist of an expression β and a
right parenthesis. We extend the tree by creating two new vertices below
the present one, with α as the expression at the “left child” vertex, and
β as the expression at the “right child” vertex. Return to step 1.
4. The ﬁrst two symbols are now known to be (¬. The remainder
of the expression, β), must* consist of an expression β and a right
parenthesis. We extend the tree by creating one new vertex below the
present one, with β as the expression at the child vertex. Return to step 1.
Now for some comments in support of the correctness of this algo-
rithm.
First, given any expression, the procedure halts after a ﬁnite number
of steps. This is because any vertex contains a shorter expression than
the one above it, so the depth of the tree is bounded by the length of the
given expression.
Secondly, the choices made by the procedure could not have been
made differently. For example, in step 3 we arrive at an expression α. We
could not use less than α for a constituent, because it would not have a
balance between left and right parentheses (as required by Lemma 13A).
∗If not, then the expression here is not a wff. We reject the given expression as a non-wff,
and halt.
∗∗If the end of the expression is reached before ﬁnding such an α, then the expression
here is not a wff. We reject the given expression as a non-wff, and halt.

32
A Mathematical Introduction to Logic
We could not use more than α, because that would have the proper initial
segment α that was balanced (violating Lemma 13B). Thus α is forced
upon us. And then the choice of the principal connective is inevitable.
We conclude that this algorithm constructs the only possible tree for the
given expression.
Thirdly, if the algorithm uses the footnotes to reject the given expres-
sion, then that expression could not have been a wff — the rejection is
correct. That is because the only possible attempt to make its tree failed.
Finally, if the algorithm does not use the rejection footnotes, then the
given expression is indeed a legal wff. That is because we have its tree;
by working our way up the tree, we ﬁnd inductively that every vertex
has a wff, including the top vertex.
The second remark above lets us conclude that our language has
enough parentheses; each wff has a unique tree of the sort constructed
here. We have “unique readability.” And not only does a unique tree exist
for a wff, we know how to construct it; we can carry out this algorithm,
using a sufﬁciently large piece of paper.
Now to go back to the question of the existence of the extension
v of a truth assignment v: It is the uniqueness of the trees that is the
crucial fact here. For any wff ϕ there is a unique tree constructing it.
By working our way up this tree, assigning a truth value v(α) at each
vertex α, we can unambiguously arrive at a value for v(ϕ). And the
function described in this way meets conditions 0–5 listed at the start
of Section 1.2. And not only that, we know how, given ϕ and the values
of v at its sentence symbols, to carry out the calculation of v(ϕ).
Thus, using the parsing algorithm, we can make a function v as
described in Theorem 12A. And there can be only one such v; cf. Ex-
ercise 14 in Section 1.2.
The only reason the existence of v is an issue at all is that in Sec-
tion 1.2 it is described by recursion. That is, v(ϕ) is speciﬁed by making
use of the function v itself, applied to smaller formulas. In the next
section, we approach the matter of deﬁning a function by recursion
more generally. By treating the subject more abstractly, we can better
isolate what is at stake.
Polish Notation
It is possible to avoid both ambiguity and parentheses. This can be done
by a very simple device. Instead of, for example, (α ∧β) we use ∧αβ.
Let the set of P-wffs be the set generated from the sentence symbols by
the ﬁve operations
D¬(α) = ¬ α,
D∨(α, β) = ∨αβ,
D∧(α, β) = ∧αβ,
D→(α, β) = →αβ,
D↔(α, β) = ↔αβ.

Chapter 1:
Sentential Logic
33
For example, one P-wff is
→∧AD ∨¬ B ↔CB.
Here the need for an algorithm to analyze the structure is quite ap-
parent. Even for the short example above, it requires some thought to
see how it was built up. We will give a unique readability theorem for
such expressions in Section 2.3.
This way of writing formulas (but with N, K, A, C, and E in place
of ¬, ∧, ∨, →, and ↔, respectively) was introduced by the Polish logi-
cian Łukasiewicz. The notation is well suited to automatic processing.
Computer compiler programs often begin by converting the formulas
given them into Polish notation.
Omitting Parentheses
Hereafter when naming wffs, we will not feel compelled to mention
explicitly every parenthesis. To establish a more compact notation, we
now adopt the following conventions:
1. The outermost parentheses need not be explicitly mentioned. For
example, when we write “A ∧B” we are referring to (A ∧B).
2. The negation symbol applies to as little as possible. For example,
¬ A ∧B is (¬ A) ∧B, i.e., ((¬ A) ∧B). It is not the same as (¬ (A ∧
B)).
3. The conjunction and disjunction symbols apply to as little as pos-
sible, given that convention 2 is to be observed. For example,
A ∧B →¬ C ∨D
is
((A ∧B) →((¬ C) ∨D)).
4. Where one connective symbol is used repeatedly, grouping is to
the right:
α ∧β ∧γ
is
α ∧(β ∧γ ),
α →β →γ
is
α →(β →γ ).
It must be admitted that these conventions violate what was said ear-
lier about naming expressions. We can get away with this only because
we no longer have any interest in naming expressions that are not wffs.
Exercises
1. Rewrite the tautologies in the “selected list” at the end of Section 1.2,
but using the conventions of the present section to minimize the
number of parentheses.
2. Give an example of wffs α and β and expressions γ and δ such that
(α ∧β) = (γ ∧δ) but α ̸= γ .

34
A Mathematical Introduction to Logic
3. Carry out the argument for Lemma 13B for the case of the operation
E¬.
4. Suppose that we modify our deﬁnition of wff by omitting all right
parentheses. Thus instead of
((A ∧(¬ B)) →(C ∨D))
we use
((A ∧(¬ B →(C ∨D.
Show that we still have unique readability (i.e., each wff still has
only one possible decomposition). Suggestion: These expressions
have the same number of parentheses as connective symbols.
5. The English language has a tendency to use two-part connectives:
“both . . . and . . .” “either . . . or . . .” “if . . . , then . . . .” How does
this affect unique readability in English?
6. We have given an algorithm for analyzing a wff by constructing its
tree from the top down. There are also ways of constructing the tree
from the bottom up. This can be done by looking through the formula
for innermost pairs of parentheses. Give a complete description of
an algorithm of this sort.
7. Suppose that left and right parentheses are indistinguishable. Thus,
instead of (α ∨(β ∧γ )) we have |α ∨|β ∧γ ||. Do formulas still
have unique decomposition?
SECTION 1.4
Induction and Recursion1
Induction
There is one special type of construction that occurs frequently both in
logic and in other branches of mathematics. We may want to construct
a certain subset of a set U by starting with some initial elements of U,
and applying certain operations to them over and over again. The set we
seek will be the smallest set containing the initial elements and closed
under the operations. Its members will be those elements of U which
can be built up from the initial elements by applying the operations
some ﬁnite number of times.
1 On the one hand, the concepts in this section are important, and they arise in many
places throughout mathematics. On the other hand, readers may want to postpone — not
skip — study of this section.

Chapter 1:
Sentential Logic
35
In the special case of immediate interest to us, U is the set of expres-
sions, the initial elements are the sentence symbols, and the operations
are E¬, E∧, etc. The set to be constructed is the set of wffs. But we will
encounter other special cases later, and it will be helpful to view the
situation abstractly here.
To simplify our discussion, we will consider an initial set B ⊆U
and a class F of functions containing just two members f and g, where
f : U × U →U
and
g : U →U.
Thus f is a binary operation on U and g is a unary operation. (Actu-
ally F need not be ﬁnite; it will be seen that our simpliﬁed discussion
here is, in fact, applicable to a more general situation. F can be any
set of relations on U, and in Chapter 2 this greater generality will be
utilized. But the case discussed here is easier to visualize and is gen-
eral enough to illustrate the ideas. For a less restricted version, see
Exercise 3.)
If B contains points a and b, then the set C we wish to construct will
contain, for example,
b,
f (b, b), g(a),
f (g(a), f (b, b)), g( f (g(a), f (b, b))).
Of course these might not all be distinct. The idea is that we are given
certain bricks to work with, and certain types of mortar, and we want C
to contain just the things we are able to build.
In deﬁning C more formally, we have our choice of two deﬁnitions.
We can deﬁne it “from the top down” as follows: Say that a subset S of
U is closed under f and g iff whenever elements x and y belong to S,
then so also do f (x, y) and g(x). Say that S is inductive iff B ⊆S and
S is closed under f and g. Let C⋆be the intersection of all the inductive
subsets of U; thus x ∈C⋆iff x belongs to every inductive subset of
U. It is not hard to see (and the reader should check) that C⋆is itself
inductive. Furthermore, C⋆is the smallest such set, being included in
all the other inductive sets.
The second (and equivalent) deﬁnition works “from the bottom up.”
We want C⋆to contain the things that can be reached from B by applying
f and g a ﬁnite number of times. Temporarily deﬁne a construction
sequence to be a ﬁnite sequence ⟨x1, . . . , xn⟩of elements of U such that
for each i ≤n we have at least one of
xi ∈B,
xi = f (x j, xk)
for some
j < i, k < i,
xi = g(x j)
for some
j < i.
In other words, each member of the sequence either is in B or results
from earlier members by applying f or g. Then let C⋆be the set of all
points x such that some construction sequence ends with x.

36
A Mathematical Introduction to Logic
Let Cn be the set of points x such that some construction sequence
of length n ends with x. Then C1 = B,
C1 ⊆C2 ⊆C3 ⊆· · · ,
and C⋆= 
n Cn. For example, g( f (a, f (b, b))) is in C5 and hence in
C⋆, as can be seen by contemplating the tree shown:
We obtain a construction sequence for g( f (a, f (b, b))) by squashing
this tree into a linear sequence.
EXAMPLES
1. The natural numbers. Let U be the set of all real numbers,
and let B = {0}. Take one operation S, where S(x) = x +1. Then
C⋆= {0, 1, 2, . . .}.
The set C⋆of natural numbers contains exactly those numbers
obtainable from 0 by applying the successor operation repeatedly.
2. The integers. Let U be the set of all real numbers; let B =
{0}. This time take two operations, the successor operation S and
the predecessor operation P:
S(x) = x + 1
and
P(x) = x −1.
Now C⋆contains all the integers,
C⋆= {. . . , −2, −1, 0, 1, 2, . . .}.
Notice that there is more than one way of obtaining 2 as a member
of C⋆. For 2 is S(S(0)), but it is also S(P(S(S(0)))).
3. The algebraic functions. Let U contain all functions whose
domain and range are each sets of real numbers. Let B contain
the identity function and all constant functions. Let F contain the
operations (on functions) of addition, multiplication, division, and
root extraction. Then C⋆is the class of algebraic functions.
4. The well-formed formulas. Let U be the set of all expres-
sions and let B be the set of sentence symbols. Let F contain the
ﬁve formula-building operations on expressions: E¬, E∧, E∨, E→,
and E↔. Then C⋆is the set of all wffs.

Chapter 1:
Sentential Logic
37
At this point we should verify that our two deﬁnitions are actually
equivalent, i.e., that C⋆= C⋆.
To show that C⋆⊆C⋆we need only check that C⋆is inductive, i.e.,
that B ⊆C⋆and C⋆is closed under the functions. Clearly B = C1 ⊆C⋆.
If x and y areinC⋆,thenwecanconcatenatetheirconstructionsequences
and append f (x, y) to obtain a construction sequence placing f (x, y)
in C⋆. Similarly, C⋆is closed under g.
Finally, to show that C⋆⊆C⋆we consider a point in C⋆and a
construction sequence ⟨x0, . . . , xn⟩for it. By ordinary induction on i,
we can see that xi ∈C⋆, i ≤n. First x0 ∈B ⊆C⋆. For the inductive
step we use the fact that C⋆is closed under the functions. Thus we
conclude that

n
Cn = C⋆= C⋆=

{S | S
is inductive}.
(A parenthetical remark: Suppose our present study is embedded in
axiomatic set theory, where the natural numbers are usually deﬁned
from the top down. Then our deﬁnition of C⋆(employing ﬁniteness and
hence natural numbers) is not really different from our deﬁnition of C⋆.
But we are not working within axiomatic set theory; we are working
within informal mathematics. And the notion of natural number seems
to be a solid, well-understood intuitive concept.)
Since C⋆= C⋆, we call the set simply C and refer to it as the set
generated from B by the functions in F. We will often want to prove
theorems by using the following:
INDUCTION PRINCIPLE
Assume that C is the set generated from B by
the functions in F. If S is a subset of C that includes B and is
closed under the functions of F then S = C.
PROOF.
S is inductive, so C = C⋆⊆S. We are given the other
inclusion.
⊣
The special case now of interest to us is, of course, Example 4. Here
C is the class of wffs generated from the set of sentence symbols by the
formula-building operations. This special case has interesting features
of its own. Both α and β are proper segments of E∧(α, β), i.e., of (α ∧β).
More generally, if we look at the family tree of a wff, we see that each
constituent is a proper segment of the end product.

38
A Mathematical Introduction to Logic
Suppose, for example, that we temporarily call an expression spe-
cial if the only sentence symbols in it are among {A2, A3, A5} and the
only connective symbols in it are among {¬, →}. Then no special wff
requires A9 or E∧for its construction. In fact, every special wff belongs
to the set Cs generated from {A2, A3, A5} by E¬ and E→. (We can use
the induction principle to show that every wff either belongs to Cs or is
not special.)
Recursion
We return now to the more abstract case. There is a set U (such as the
set of all expressions), a subset B of U (such as the set of sentence
symbols), and two functions f and g, where
f : U × U →U
and
g : U →U.
C is the set generated from B by f and g.
The problem we now want to consider is that of deﬁning a function
on C recursively. That is, we suppose we are given
1. Rules for computing h(x) for x ∈B.
2a. Rules for computing h( f (x, y)), making use of h(x) and h(y).
2b. Rules for computing h(g(x)), making use of h(x).
(For example, this is the situation discussed in Section 1.2, where h is
the extension of a truth assignment for B.) It is not hard to see that there
can be at most one function h on C meeting all the given requirements.
But it is possible that no such h exists; the rules may be contradictory.
For example, let
U = the set of real numbers,
B = {0},
f (x, y) = x · y,
g(x) = x + 1.
Then C is the set of natural numbers. Suppose we impose the following
requirements on h:
1. h(0) = 0.
2a. h( f (x, y)) = f (h(x), h(y)).
2b. h(g(x)) = h(x) + 2.
Then no such function h can exist. (Try computing h(1), noting that we
have both 1 = g(0) and 1 = f (g(0), g(0)).)
A similar situation is encountered in algebra.2 Suppose that you
have a group G that is generated from B by the group multiplication
2 It is hoped that examples such as this will be useful to the reader with some algebraic
experience. The other readers will be glad to know that these examples are merely
illustrative and not essential to our development of the subject.

Chapter 1:
Sentential Logic
39
and inverse operation. Then an arbitrary map of B into a group H is
not necessarily extendible to a homomorphism of the entire group G
into H. But if G happens to be a free group with set B of independent
generators, then any such map is extendible to a homomorphism of the
entire group.
Say that C is freely generated from B by f and g iff in addition to
the requirements for being generated, the restrictions fC and gC of f
and g to C meet the following conditions:
1. fC and gC are one-to-one.
2. The range of fC, the range of gC, and the set B are pairwise
disjoint.
The main result of this section, the recursion theorem, says that if C
is freely generated then a function h on B always has an extension h on
C that follows the sorts of rules considered above.
RECURSION THEOREM
Assume that the subset C of U is freely gen-
erated from B by f and g, where
f : U × U →U,
g : U →U.
Further assume that V is a set and F, G, and h functions such that
h : B →V,
F : V × V →V,
G : V →V.
Then there is a unique function
h : C →V
such that
(i) For x in B, h(x) = h(x);
(ii) For x, y in C,
h( f (x, y)) = F(h(x), h(y)),
h(g(x)) = G(h(x)).
Viewed algebraically, the conclusion of this theorem says that any
map h of B into V can be extended to a homomorphism h from C (with
operations f and g) into V (with operations F and G).
If the content of the recursion theorem is not immediately apparent,
try looking at it chromatically. You want to have a function h that paints
each member of C some color. You have before you
1. h, telling you how to color the initial elements in B;
2. F, which tells you how to combine the color of x and y to obtain
the color of f (x, y) (i.e., it gives h( f (x, y)) in terms of h(x) and h(y));

40
A Mathematical Introduction to Logic
3. G, which similarly tells you how to convert the color of x into the
color of g(x).
The danger is that of a conﬂict in which, for example, F is saying
“green” but G is saying “red” for the same point (unlucky enough to
be equal both to f (x, y) and g(z) for some x, y, z). But if C is freely
generated, then this danger is avoided.
EXAMPLES.
Consideragaintheexamplesoftheprecedingsubsection.
1. B = {0} with one operation, the successor operation S.
Then C is the set N of natural numbers. Since the successor oper-
ation is one-to-one and 0 is not in its range, C is freely generated
from {0} by S. Therefore, by the recursion theorem, for any set
V , any a ∈V , and any F : V →V there is a unique h : N →V
such that h(0) = a and h(S(x)) = F(h(x)) for each x ∈N.
For example, there is a unique h : N →N such that h(0) = 0
and h(S(x)) = 1 −h(x). This function has the value 0 at even
numbers and the value 1 at odd numbers.
2. The integers are generated from {0} by the successor and
predecessor operations but not freely generated.
3. Freeness fails also for the generation of the algebraic func-
tions in the manner described.
4. The wffs are freely generated from the sentence symbols by
the ﬁve formula-building operations. This fact is implicit in the
parsing algorithm of the preceding section; we now want to focus
on it here:
UNIQUE READABILITY THEOREM
Theﬁveformula-buildingoperations,
when restricted to the set of wffs,
(a) Have ranges that are disjoint from each other and from the
set of sentence symbols, and
(b) Are one-to-one.
In other words, the set of wffs is freely generated from the set
of sentence symbols by the ﬁve operations.
PROOF.
To show that the restriction of E∧is one-to-one, suppose
that
(α ∧β) = (γ ∧δ),
where α, β, γ , and δ are wffs. Delete the ﬁrst symbol of each
sequence, obtaining
α ∧β) = γ ∧δ).
Then we must have α = γ , lest one be a proper initial segment of
the other (in contradiction to Lemma 13B). And then it follows at

Chapter 1:
Sentential Logic
41
once that β = δ. The same argument applies to E∨, E→, and E↔;
for E¬ a simpler argument sufﬁces.
A similar line of reasoning tells us that the operations have
disjoint ranges. For example, if
(α ∧β) = (γ →δ)
where α, β, γ , and δ are wffs, then as in the above paragraph
we have α = γ . But that implies that ∧= →, contradicting
the fact that our symbols are distinct. Hence E∧and E→(when
restricted to wffs) have disjoint ranges. Similarly for any two
binary connectives.
The remaining cases are simple. If (¬ α) = (β ∧γ ), then
β begins with ¬, which no wff does. No sentence symbol is a
sequence of symbols beginning with (.
⊣
Now let us return to the question of extending a truth assignment v
to v. First consider the special case where v is a truth assignment for
the set of all sentence symbols. Then by applying the unique readability
theorem and the recursion theorem we conclude that there is a unique
extension v to the set of all wffs with the desired properties.
Next take the general case where v is a truth assignment for a set S
of sentence symbols. The set S generated from S by the ﬁve formula-
building operations is freely generated, as a consequence of the unique
readability theorem. So by the recursion theorem there is a unique ex-
tension v of v to that set, having the desired properties.
EXAMPLE.
We can apply the recursion theorem to establish that there
is a unique function h deﬁned on the set of wffs such that
h(A) = 1
for a sentence symbol
A,
h((¬ α)) = 3 + h(α),
h((α ∧β)) = 3 + h(α) + h(β),
and similarly for ∨, →, and ↔. This function gives the length of
each wff.
PROOF OF THE RECURSION THEOREM.
The idea is to let h be the union
of many approximating functions. Temporarily call a function v
(which maps part of C into V ) acceptable if it meets the conditions
imposed on h by (i) and (ii). More precisely, v is acceptable iff
the domain of v is a subset of C, the range a subset of V, and for
any x and y in C:
(i′) If x belongs to B and to the domain of v, then v(x) = h(x).
(ii′) If f (x, y) belongs to the domain of v, then so do x and y,
and v( f (x, y)) = F(v(x), v(y)). If g(x) belongs to the domain
of v, then so does x, and v(g(x)) = G(v(x)).

42
A Mathematical Introduction to Logic
Let K be the collection of all acceptable functions, and let h =
 K, the union of all the acceptable functions. Thus
⟨x, z⟩∈h
iff
⟨x, z⟩belongs to some acceptable v
iff
v(x) = z for some acceptable v.
(1.1)
We claim that h meets our requirements. The argument is set-
theoretic, and comprises four steps. First, here is an outline of
four steps:
1. We claim that h is a function (i.e., that it is single-valued).
Let
S = {x ∈C | for at most one z, ⟨x, z⟩∈h}
= {x ∈C | all acceptable functions deﬁned at x agree
there}
It is easy to verify that S is inductive, by using (i′) and (ii′). Hence
S = C and h is a function.
2. We claim that h ∈K; i.e., that h itself is an acceptable
function. This follows fairly easily from the deﬁnition of h and
the fact that it is a function.
3. We claim that h is deﬁned throughout C. It sufﬁces to show
that the domain of h is inductive. It is here that the assumption of
freeness is used. For example, one case is the following: Suppose
that x is in the domain of h. Then h; ⟨g(x), G(h(x))⟩is accept-
able. (The freeness is required in showing that it is acceptable.)
Consequently, g(x) is in the domain of h.
4. We claim that h is unique. For given two such functions,
let S be the set on which they agree. Then S is inductive, and so
equals C.
⊣
Now for the details.
1. As above, let
S = {x ∈C | for at most one z, ⟨x, z⟩∈h}
= {x ∈C | all acceptable functions deﬁned at x agree there}
Toward showing that S is inductive, ﬁrst consider some x in B.
Suppose that v1 and v2 are acceptable functions deﬁned at x; we
seek to show that v1(x) = v2(x). But condition (i′) tells us that
both v1(x) and v2(x) must equal h(x), so indeed v1(x) = v2(x).
This shows that x ∈S; since x was an arbitrary member of B we
have B ⊆S.
Secondly we must check that S is closed under f and g. So
suppose that some x and y are in S; we ask whether f (x, y) is in
S. So suppose that v1 and v2 are acceptable functions deﬁned at

Chapter 1:
Sentential Logic
43
f (x, y); we seek to show that they agree there. But condition (ii′)
tells us that v1( f (x, y)) = F(v1(x), v1(y)) and v2( f (x, y)) =
F(v2(x), v2(y)). And because x and y are in S, we have v1(x) =
v2(x) and v1(y) = v2(y) (and these are deﬁned). So we conclude
that v1( f (x, y)) = v2( f (x, y)). This shows that f (x, y) ∈S.
Hence S is closed under f . A similar argument shows that S is
closed under g.
Thus S is inductive and so S = C. This shows that h is single-
valued, i.e., is a function. Because h includes every acceptable
function as a subset, we can say that
h(x) = v(x)
whenever v is an acceptable function and x ∈dom v.
2. We claim that h is acceptable. Clearly dom h ⊆C and
ran h ⊆V (by (∗)), and we have just veriﬁed that h is a function.
It remains to check that h satisﬁes conditions (i′) and (ii′).
First we examine (i′). Assume x ∈B and x ∈dom h (so that
⟨x, h(x)⟩∈h).Theremustbesomeacceptablev withv(x) = h(x).
Becausev satisﬁes(i′),wehavev(x) = h(x)whenceh(x) = h(x).
So h satisﬁes (i′).
Secondly we examine (ii′). Assume that f (x, y) ∈dom h.
Again there must be some acceptable v with v( f (x, y)) =
h( f (x, y)). Because v satisﬁes (ii′), we have v( f (x, y)) =
F(v(x), v(y)). Now h(x) = v(x) and h(y) = v(y) and hence
h( f (x, y)) = v( f (x, y)) = F(v(x), v(y)) = F(h(x), h(y)).
In a similar way, we ﬁnd that h(g(x)) = G(h(x)) whenever
g(x) ∈dom h. Hence h meets condition (ii′) and so is accept-
able.
3. Next we must show that dom h is inductive. First consider
a point x in B. Then the set {⟨x, h(x)⟩} is a (small) acceptable
function. For it clearly satisﬁes (i′). It also satisﬁes (ii′) because
x /∈ran fC and x /∈ran gC. Thus {⟨x, h(x)⟩} is acceptable and
therefore is included in h. Hence x ∈dom h. This shows that
B ⊆dom h.
We further claim that dom h is closed under f and g. Toward
this end, consider any s and t in dom h. We hope that f (s, t) ∈
dom h. But if not, then let
v = h ∪{⟨f (s, t), F(h(s), h(t))⟩},
the result of adding this one additional pair to h. It is clear that v is
a function, dom v ⊆C, and ran v ⊆V . We claim that v satisﬁes
(i′) and (ii′).

44
A Mathematical Introduction to Logic
First take (i′). If x ∈B ∩dom v then x ̸= f (s, t), by freeness.
Hence x ∈dom h and we have v(x) = h(x) = h(x).
Next take (ii′). Assume that f (x, y) ∈dom v for some x and
y in C. If f (x, y) ∈dom h then v( f (x, y)) = h( f (x, y)) =
F(h(x), h(y)) = F(v(x), v(y)) since h is acceptable. The other
possibility is that f (x, y) = f (s, t). Then by freeness we have
x = s and y = t, and we know that these points are in dom h ⊆
dom v. By construction,
v( f (s, t)) = F(h(s), h(t))
= F(v(s), v(t)).
Finally suppose that g(x) ∈dom v for x in C. Then by freeness
we have g(x) ̸= f (s, t). Hence g(x) ∈dom h, and consequently
v(g(x)) = h(g(x)) = G(h(x)) = G(v(x)).
Thus v is acceptable. But that tells us that v ⊆h, so that
f (s, t) ∈dom h after all.
A similar argument shows that dom h is closed under g as well.
Hence dom h is inductive and therefore coincides with C.
4. To show that h is unique, suppose that h1 and h2 both satisfy
theconclusionofthetheorem.Let S bethesetonwhichtheyagree:
S = {x ∈C | h1(x) = h2(x)}.
Then it is not hard to verify that S is inductive. Consequently
S = C and h1 = h2.
⊣
One ﬁnal comment on induction and recursion: The induction prin-
ciple we have stated is not the only one possible. It is entirely possible to
give proofs by induction (and deﬁnitions by recursion) on the length of
expressions, the number of places at which connective symbols occur,
etc. Such methods are inherently less basic but may be necessary in
some situations.
Exercises
1. Suppose that C is generated from a set B = {a, b} by the binary
operation f and unary operation g. List all the members of C2. How
many members might C3 have? C4?
2. Obviously (A3 →∧A4) is not a wff. But prove that it is not a wff.
3. We can generalize the discussion in this section by requiring of F
only that it be a class of relations on U. C⋆is deﬁned as before,
except that ⟨x0, x1, . . . , xn⟩is now a construction sequence provided
that for each i ≤n we have either xi ∈B or ⟨x j1, . . . , x jk, xi⟩∈R
for some R ∈F and some j1, . . . , jk all less than i. Give the correct
deﬁnition of C⋆and show that C⋆= C⋆.

Chapter 1:
Sentential Logic
45
SECTION 1.5
Sentential Connectives
We have thus far employed ﬁve sentential connective symbols. Even
in the absence of a general deﬁnition of “connective,” it is clear that
the ﬁve familiar ones are not the only ones possible. Would we gain
anything by adding more connectives to the language? Would we lose
anything by omitting some we already have?
In this section we make these questions precise and give some an-
swers. First consider an informal example. We could expand the lan-
guage by adding a three-place sentential connective symbol #, called
the majority symbol. We allow now as a wff the expression (#αβγ )
whenever α, β, and γ are wffs. In other words, we add a sixth formula-
building operator to our list:
E#(α, β, γ ) = (#αβγ ).
Then we must give the interpretation of this symbol. That is, we must
say how to compute v((#αβγ )), given the values v(α), v(β), and v(γ ).
We choose to deﬁne
v((#αβγ ))
is to agree with the majority of
v(α), v(β), v(γ ).
We claim that this extension has gained us nothing, in the following
precise sense: For any wff in the extended language, there is a tauto-
logically equivalent wff in the original language. (On the other hand,
the wff in the original language may be much longer than the wff in
the extended language.) We will prove this (in a more general situa-
tion) below; here we just note that it relies on the fact that (#αβγ ) is
tautologically equivalent to
(α ∧β) ∨(α ∧γ ) ∨(β ∧γ ).
(We note parenthetically that our insistence that v((#αβγ )) be cal-
culable from ⟨v(α), v(β), v(γ )⟩plays a deﬁnite role here. In everyday
speech, there are unary operators like “it is possible that” or “I believe
that.” We can apply one of these operators to a sentence, producing a
new sentence whose truth or falsity cannot be determined solely on the
basis of the truth or falsity of the original one.)
In generalizing the foregoing example, the formal language will be
more of a hindrance than a help. We can restate everything using only
functions. Say that a k-place Boolean function is a function from {F, T }k
into {F, T }. (A Boolean function is then anything which is a k-place
Boolean function for some k. We stretch this slightly by permitting
F and T themselves to be 0-place Boolean functions.) Some sample

46
A Mathematical Introduction to Logic
Boolean functions are deﬁned by the equations (where X ∈{F, T })
I n
i (X1, . . . , Xn) = Xi,
N(F) = T, N(T ) = F,
K(T, T ) = T,
K(F, X) = K(X, F) = F,
A(F, F) = F,
A(T, X) = A(X, T ) = T,
C(T, F) = F,
C(F, X) = C(X, T ) = T,
E(X, X) = T,
E(T, F) = E(F, T ) = F.
From a wff α we can extract a Boolean function. For example, if α
is the wff A1 ∧A2, then we can make a table, Table V. The 22 lines
of the table correspond to the 22 truth assignments for {A1, A2}. For
each of the 22 pairs ⃗X, we set Bα( ⃗X) equal to the truth value α receives
when its sentence symbols are given the values indicated by ⃗X.
TABLE V
A1
A2
A1 ∧A2
F
F
F
Bα(F, F) = F
F
T
F
Bα(F, T ) = F
T
F
F
Bα(T, F) = F
T
T
T
Bα(T, T ) = T
In general, suppose that α is a wff whose sentence symbols are at
most A1, . . . , An. We deﬁne an n-place Boolean function Bn
α (or just
Bα if n seems unnecessary), the Boolean function realized by α, by
Bn
α(X1, . . . , Xn) = the truth value given to α when
A1, . . . , An
are given the values
X1, . . . , Xn.
Or, in other words, Bn
α(X1, . . . , Xn) = v(α), where v is the truth as-
signment for {A1, . . . , An} for which v(Ai) = Xi. Thus Bn
α comes from
looking at v(α) as a function of v, with α ﬁxed.
For example, the Boolean functions listed previously are obtainable
in this way:
I n
i = Bn
Ai
N = B1
¬ A1,
K = B2
A1∧A2,
A = B2
A1∨A2,
C = B2
A1→A2,
E = B2
A1↔A2.
From these functions we can compose others. For example,
B2
¬ A1∨¬ A2(X1, X2) = A(N(I 2
1 (X1, X2)), N(I 2
2 (X1, X2))).

Chapter 1:
Sentential Logic
47
(The right-hand side of this equation can be compared with the result of
putting ¬ A1 ∨¬ A2 into Polish notation.) We will shortly come to the
question whether every Boolean function is obtainable in this fashion.
As the theorem below states, in shifting attention from wffs to the
Boolean functions they realize, we have in effect identiﬁed tautologi-
cally equivalent wffs. Impose an ordering on {F, T } by deﬁning F < T .
(If F = 0 and T = 1, then this is the natural order.)
THEOREM 15A
Let α and β be wffs whose sentence symbols are
among A1, . . . , An. Then
(a) α |= β iff for all ⃗X ∈{F, T }n, Bα( ⃗X) ≤Bβ( ⃗X).
(b) α |==| β iff Bα = Bβ.
(c) |= α iff Bα is the constant function with value T .
PROOF OF (A).
α |= β iff for all 2n truth assignments v for A1, . . . ,
An, whenever v(α) = T , then also v(β) = T . (This is true even if
the sentence symbols in α and β do not include all of A1, . . . , An;
cf. Exercise 6 of Section 1.2.) Thus
α |= β iff for all 2n assignments v, v(α) = T ⇒v(β) = T,
iff for all 2n n-tuples ⃗X,
Bn
α( ⃗X) = T ⇒Bn
β( ⃗X) = T,
iff for all 2n n-tuples ⃗X,
Bn
α( ⃗X) ≤Bn
β( ⃗X),
where F < T .
⊣
In addition to identifying tautologically equivalent wffs, we have
freed ourselves from the formal language. We are now at liberty to
consider any Boolean function, whether it is realized by a wff or not.
But this freedom is only apparent:
THEOREM 15B
Let G be an n-place Boolean function, n ≥1. We
can ﬁnd a wff α such that G = Bn
α, i.e., such that α realizes the
function G.
The primary reason for introducing Boolean functions is to allow us
to formulate this theorem. The theorem was stated by Emil Post in 1921.
PROOF.
Case I: G is the constant function with value F. Let α =
A1 ∧¬ A1.
Case II: Otherwise there are k points at which G has the value
T , k > 0. List these:
⃗X1 = ⟨X11, X12, . . . , X1n⟩,
⃗X2 = ⟨X21, X22, . . . , X2n⟩,
· · ·
⃗Xk = ⟨Xk1, Xk2, . . . , Xkn⟩.

48
A Mathematical Introduction to Logic
Let
βi j =

A j
iff
Xi j = T,
(¬ A j)
iff
Xi j = F,
γi = βi1 ∧· · · ∧βin,
α
= γi ∨γ2 ∨· · · ∨γk.
We claim that G = Bn
α.
At this point it might be helpful to consider a concrete example.
Let G be the three-place Boolean function as follows:
G(F, F, F) = F,
G(F, F, T ) = T,
G(F, T, F) = T,
G(F, T, T ) = F,
G(T, F, F) = T,
G(T, F, T ) = F,
G(T, T, F) = F,
G(T, T, T ) = T.
Then the list of triples at which G assumes the value T has four
members:
F FT
¬ A1 ∧¬ A2 ∧A3,
FT F
¬ A1 ∧A2 ∧¬ A3,
T F F
A1 ∧¬ A2 ∧¬ A3,
T T T
A1 ∧A2 ∧A3.
To the right of each triple above is written the corresponding
conjunction γi. Then α is the formula
(¬ A1 ∧¬ A2 ∧A3) ∨(¬ A1 ∧A2 ∧¬ A3) ∨
(A1 ∧¬ A2 ∧¬ A3) ∨(A1 ∧A2 ∧A3).
Notice how α lists explicitly the triples at which G assumes the
value T .
Toreturntotheproofofthetheorem,noteﬁrstthat Bn
α( ⃗Xi) = T
for 1 ≤i ≤k. (For the truth assignment corresponding to ⃗Xi
satisﬁes γi and hence satisﬁes α.) On the other hand, only one
truth assignment for {A1, . . . , An} can satisfy γi, whence only k
such truth assignments can satisfy α. Hence Bn
α( ⃗X) = F for the
2n −k other n-tuples ⃗Y. Thus in all cases, Bn
α(⃗Y) = G(⃗Y).
⊣
From this theorem we know that every Boolean function is realiz-
able. Of course the α that realizes G is not unique; any tautologically
equivalent wff will also realize the same function. It is sometimes of
interest to choose α to be as short as possible. (In the example done
above, the wff
A1 ↔A2 ↔A3
also realizes G.)

Chapter 1:
Sentential Logic
49
As a corollary to the above theorem, we may conclude that we have
enough (in fact, more than enough) sentential connectives. For suppose
that we expand the language by adding some exotic new sentential con-
nectives (such as the majority connective discussed at the beginning of
this section). Any wff ϕ of this expanded language realizes a Boolean
function Bn
ϕ. By the above theorem we have a wff α of the original lan-
guage such that Bn
ϕ = Bn
α. Hence ϕ and α are tautologically equivalent,
by Theorem 15A.
In fact, the proof shows that α can be of a rather special form. For
one thing, the only sentential connective symbols in α are ∧, ∨, and
¬. Furthermore, α is in so-called disjunctive normal form (abbreviated
DNF). That is, α is a disjunction
α = γ1 ∨· · · ∨γk,
where each γi is a conjunction
γi = βi1 ∧· · · ∧βini
and each βi j is a sentence symbol or the negation of a sentence symbol.
(The advantages of wffs in disjunctive normal form stem from the fact
that they explicitly list the truth assignments satisfying the formula.)
Thus we have the consequence:
COROLLARY 15C
For any wff ϕ, we can ﬁnd a tautologically equiv-
alent wff α in disjunctive normal form.
Because every function G : {F, T }n →{F, T } for n ≥1 can be
realized by a wff using only the connective symbols in {∧, ∨, ¬}, we
say that the set {∧, ∨, ¬} is complete. (Actually the completeness is
more a property of the Boolean functions K, A, and N that correspond to
these symbols. But the above terminology is convenient.) Once we have
a complete set of connectives, we know that any wff is tautologically
equivalent to one all of whose connectives are in that set. (For given any
wff ϕ, we can make α using those connectives and realizing Bϕ. Then
α |==| ϕ.) The completeness of {∧, ∨, ¬} can be improved upon:
THEOREM 15D
Both {¬, ∧} and {¬, ∨} are complete.
PROOF.
We must show that any Boolean function G can be realized
by a wff using only, in the ﬁrst case, {¬, ∧}. We begin with a wff α
using {¬, ∧, ∨} that realizes G. It sufﬁces to ﬁnd a tautologically
equivalent α′ that uses only {¬, ∧}. For this we use De Morgan’s
law:
β ∨γ |==| ¬ (¬ β ∧¬ γ ).
By applying this repeatedly, we can completely eliminate ∨
from α.

50
A Mathematical Introduction to Logic
(More formally, we can prove by induction on α that there is a
tautologically equivalent α′ in which only the connectives ∧, ¬
occur. Two cases in the inductive step are
Case ¬: If α is (¬ β), then let α′ be (¬ β′).
Case ∨: If α is (β ∨γ ), then let α′ be ¬ (¬ β′ ∧¬ γ ′). Since
β′ and γ ′ are tautologically equivalent to β and γ , respectively,
α′
= ¬ (¬ β′ ∧¬ γ ′)
|==| ¬ (¬ β ∧¬ γ )
|==| β ∨γ
= α.
Infutureproofsthatasetofconnectivesiscomplete,thisinduction
will be omitted. Instead we will just give, for example, the method
of simulating ∨by using ¬ and ∧.
⊣
Showing that a certain set of connectives is not complete is usually
more difﬁcult than showing that one is complete. The basic method is
ﬁrst to show (usually by induction) that for any wff α using only those
connectives, the function Bn
α has some peculiarity, and secondly to show
that some Boolean function lacks that peculiarity.
EXAMPLE.
{∧, →} is not complete.
PROOF.
The idea is that with these connectives, if the sentence sym-
bols are assigned T , then the entire formula is assigned T . In
particular, there is nothing tautologically equivalent to ¬ A.
In more detail, we can show by induction that for any wff α
using only these connectives and having A as its only sentence
symbol, we have A |= α. (In terms of functions, this says that
B1
α(T ) = T .) The same argument shows that {∧, ∨, →, ↔} is
not complete.
⊣
For each n there are 22nn-place Boolean functions. Hence if we iden-
tify a connective with its Boolean function (e.g., ∧with the function K
mentioned before), we have 22n n-ary connectives. We will now catalog
these for n ≤2.
0-ary Connectives
There are two 0-place Boolean functions, F and T . For the correspond-
ing connective symbols we take ⊥and ⊤. Now an n-ary connective
symbol combines with n wffs to produce a new wff. When n = 0, we
have that ⊥is a wff all by itself. It differs from the sentence symbols in
that v(⊥) = F for every v; i.e., ⊥is a logical symbol always assigned
the value F. Similarly, ⊤is a wff, and v(⊤) = T for every v. Then, for
example, A →⊥is a wff, tautologically equivalent to ¬ A, as can be
seen from a two-line truth table.

Chapter 1:
Sentential Logic
51
Unary Connectives
There are four unary connectives but only one of any interest. The
interesting case is negation. The other three one-place Boolean functions
are the identity function and the two constant functions.
Binary Connectives
There are 16 binary connectives, but only the last 10 listed in Table VI
are “really binary.”
TABLE VI
Symbol
Equivalent
Remarks
⊤
two-place constant, essentially 0-ary
⊥
two-place constant, essentially 0-ary
A
projection, essentially unary
B
projection, essentially unary
¬ A
negation, essentially unary
¬ B
negation, essentially unary
∧
A ∧B
and; if F = 0 and T = 1, then this gives
multiplication in the ﬁeld {0, 1}
∨
A ∨B
or (inclusive)
→
A →B
conditional
↔
A ↔B
biconditional
←
A ←B
reversed conditional
+
(A ∨B) ∧¬ (A ∧B)
exclusive or, “A or B and not both”; if
F = 0 and T = 1, then this gives the
usual addition (modulo 2) in the
ﬁeld {0, 1}
↓
¬ (A ∨B)
nor, “neither A nor B”
|
¬ (A ∧B)
nand, “not both A and B”; the symbol is
called the Sheffer stroke
<
(¬ A) ∧B
the usual ordering, where F < T
>
A ∧(¬ B)
the usual ordering, where F < T
Ternary Connectives
There are 256 ternary connectives; 2 are essentially 0-ary, 6 (= 2 · ( 3
1))
are essentially unary, and 30 (= 10 · ( 3
2)) are essentially binary. This
leaves 218 that are really ternary. We have thus far mentioned only
the majority connective #. There is, similarly, the minority connective.
In Exercise 7 we encounter +3, ternary addition modulo 2. +3αβγ is
assigned the value T iff an odd number of α, β, and γ are assigned
T . This formula is equivalent both to α + β + γ and to α ↔β ↔γ .
Another ternary connective arises in Exercise 8.

52
A Mathematical Introduction to Logic
EXAMPLE.
{|} and {↓} are complete.
PROOF.
For |
¬ α |==| α | α
α ∨β |==| (¬ α) | (¬ β).
Since {¬, ∨} is complete and ¬, ∨can be simulated using only
|, we conclude that {|} is complete.
⊣
EXAMPLE.
{¬, →} is complete. In fact, of the 10 connectives that
are really binary, eight have the property of forming, when added
to ¬, a complete set. The two exceptions are + and ↔; see
Exercise 5.
EXAMPLE.
{⊥, →} is complete. In fact, because with this set we can
realize even the two 0-place Boolean functions, it is supercom-
plete.
Exercises
1. Let G be the following three-place Boolean function.
G(F, F, F) = T,
G(T, F, F) = T,
G(F, F, T ) = T,
G(T, F, T ) = F,
G(F, T, F) = T,
G(T, T, F) = F,
G(F, T, T ) = F,
G(T, T, T ) = F.
(a) Find a wff, using at most the connectives ∨, ∧, and ¬, that
realizes G.
(b) Then ﬁnd such a wff in which connective symbols occur at not
more than ﬁve places.
2. Show that | and ↓are the only binary connectives that are complete
by themselves.
3. Show that {¬, #} is not complete.
4. Let M be the ternary minority connective. (Thus v(Mαβγ ) always
disagrees with the majority of v(α), v(β), and v(γ ).) Show the
following:
(a) {M, ⊥} is complete.
(b) {M} is not complete.
5. Show that {⊤, ⊥, ¬, ↔, +} is not complete. Suggestion: Show that
any wff α using these connectives and the sentence symbols A and
B has an even number of T ’s among the four possible values of
v(α).
Remark: Another approach uses the algebra of the ﬁeld {0, 1}.
Any Boolean function realizable with these connectives has a cer-
tain linearity property.

Chapter 1:
Sentential Logic
53
6. Show that {∧, ↔, +} is complete but that no proper subset is com-
plete.
7. Let +3 be the ternary connective such that +3αβγ is equivalent to
α + β + γ .
(a) Show that {⊤, ⊥, ∧, +3} is complete.
(b) Show that no proper subset is complete.
Remark: +3 is the ternary parity connective; the condition for
v(+α1α2α3) = T is that v(αi) = T for an odd number of i’s.
+ is the binary parity connective. The function G in the proof of
Theorem 15B is the 3-place parity function.
8. Let I be the ternary connective such that Iαβγ is assigned the value
T iff exactly one of the formulas α, β, γ is assigned the value T .
Show that there are no binary connectives ◦and △such that Iαβγ
is equivalent to (α ◦β)△γ .
9. Say that a formula α is in conjunctive normal form (abbreviated
CNF) iff it is a conjunction
α = γ1 ∧· · · ∧γk
where each γi is a disjunction
γi = βi1 ∨· · · ∨βin
and each βi j is either a sentence symbol or the negation of a sentence
symbol.
(a) Find a formula in conjunctive normal form that is tautologically
equivalent to A ↔B ↔C.
(b) Show that for any formula, we can ﬁnd a tautologically equiv-
alent formula in conjunctive normal form.
10. Add the 0-place connectives ⊤, ⊥to our language. For each wff
ϕ and sentence symbol A, let ϕ A
⊤be the wff obtained from ϕ by
replacing A by ⊤. Similarly for ϕ A
⊥. Then let ϕ A
∗= (ϕ A
⊤∨ϕ A
⊥).
Prove the following:
(a) ϕ |= ϕ A
∗.
(b) If ϕ |= ψ and A does not appear in ψ, then ϕ A
∗|= ψ.
(c) The formula ϕ is satisﬁable iff ϕ A
∗is satisﬁable.
Remarks: We can think of ϕ A
∗as trying to say everything ϕ says,
but without being able to use the symbol A. Parts (a) and (b) state
that ϕ A
∗is the strongest A-free consequence of ϕ. The formulas ϕ
and ϕ A
∗are not tautologically equivalent in general, but they are
“equally satisﬁable” by part (c). The operation of forming ϕ A
∗from
ϕ is (in another context) called resolution on A.
11. (Interpolation theorem) If α |= β, then there is some γ all of whose
sentence symbols occur both in α and in β and such that α |= γ |=
β. Suggestion: Use the preceding exercise.

54
A Mathematical Introduction to Logic
Remarks: There is an analogue of Exercise 11 that holds for ﬁrst-
order logic. But the proof in that case is very different, because there
is no analogue of Exercise 10.
12. Is the set {∧, ⊤, ⊥} complete? Support your answer.
SECTION 1.6
Switching Circuits1
Consider an electrical device (traditionally a black box) having n inputs
and one output (Fig. 1). Assume that to each input we apply a signal
having one of two values and that the output has one of two values. The
two possible values we call F and T . (We could also deﬁne the F value
as 0 potential and choose the unit of potential so that the T value has
potential 1.) Further assume that the device has no memory; i.e., the
present output level depends only on the present inputs (and not on past
history). Then the performance of the device is described by a Boolean
function:
G(X1, . . . , Xn) = the output level given the input signalsX1, . . . , Xn.
Figure 1. Electrical device with three inputs.
Devices meeting all these assumptions constitute an essential part of
digital-computer circuitry. There is, for example, the two-input AND
gate, for which the output is the minimum of the inputs (where F < T ).
This device realizes the Boolean function K of the preceding section.
It is convenient to attach the labels A1 and A2 to the inputs and to label
the output A1 ∧A2.
Similar devices can be made for other sentential connectives. For a
two-input OR gate (Fig. 2) the output voltage is the maximum of the in-
put voltages. Corresponding to the negation connective there is the NOT
device (or inverter), whose output voltage is the opposite of the input
voltage.
A circuit can be constructed from various devices of this sort. And it
is again natural to use wffs of our formal language to label the voltages
1 This section, which discusses an application of the ideas of previous sections, may be
omitted without loss of continuity.

Chapter 1:
Sentential Logic
55
Figure 2. OR gate.
at different points (Fig. 3). Conversely, given the wff thus attached to
the output, we can approximately reconstruct the circuit, which looks
very much like the tree of the wff’s formation.
Figure 3. Circuit with wffs as labels.
For example, the circuit for
((A ∧B) ∧D) ∨((A ∧B) ∧¬ C)
would probably be as shown in Fig. 4. Duplication of the circuit for
A ∧B would not usually be desirable.
Figure 4. Circuit for ((A ∧B) ∧D) ∨((A ∧B) ∧¬C).
Tautologically equivalent wffs yield circuits having ultimately the

56
A Mathematical Introduction to Logic
same performance, although possibly at different cost and (if the devices
are not quite instantaneous in operation) different speed. Deﬁne the
delay (also called the depth) of a circuit as the maximum number of
boxes through which the signal can pass in going from an input to the
output. The corresponding notion for formulas is conveniently deﬁned
by recursion.
1. The delay of a sentence symbol is 0.
2. The delay of ¬ α is one greater than the delay of α.
3. The delay of α∧β is one greater than the maximum of the delay
of α and the delay of β.
And similarly for any other connective.
For example, the circuit of (A1 ∧A2) ∨¬ A3 uses three devices and
has a delay of 2. The tautologically equivalent formula ¬ (A3 ∧(¬ A1∨
¬ A2)) gives a circuit having ﬁve devices and a delay of 4. The problem
facing many a computer engineer can be stated: Given a circuit (or its
wff), ﬁnd an equivalent circuit (or a tautologically equivalent wff) for
which the cost is a minimum, subject to constraints such as a maximum
allowable delay. For this problem there is some catalog of available
devices; for example, she might have available
NOT, two-input AND, three-input OR.
(It is clearly desirable that the available devices correspond to a com-
plete set of connectives.) The catalog of devices determines a formal
language, having a connective symbol for each device.
EXAMPLE 1.
Inputs: A, B, C. Output: To agree with the majority of
A, B, and C. Devices available: two-input OR, two-input AND.
One solution is
((A ∧B) ∨(A ∧C)) ∨(B ∧C),
which uses ﬁve devices and has a delay of 3. But a better solution
is
(A ∧(B ∨C)) ∨(B ∧C),
which uses four devices and has the same delay. Furthermore,
there is no solution using only three devices; cf. Exercise 1.
EXAMPLE 2.
Inputs: A and B. Output: T if the inputs agree, F oth-
erwise; i.e., the circuit is to test for equality. Device available:
two-input NOR. One solution is
((A ↓A) ↓B) ↓((B ↓B) ↓A).
This uses ﬁve devices; is there a better solution? And there is

Chapter 1:
Sentential Logic
57
the deeper question: Is there an efﬁcient procedure for ﬁnding a
minimal solution? These are questions that we merely raise here.
In recent years a great deal of work has gone into investigating
questions of this type.
EXAMPLE 3.
(Relay switching) Inputs: A, ¬ A, B, ¬ B, . . . Devices:
OR (any number of inputs), AND (any number of inputs). Cost:
Devices are free, but each use of an input costs one unit. To test
for equality of A and B we could use
(A ∧B) ∨(¬ A ∧¬ B).
The wiring diagram for the circuit is shown in Fig. 5. The circuit
will pass current iff A and B are assigned the same value. (This
formula, equivalent to A↔B, has the property that its truth value
changes whenever the value of one argument changes. For this
reason, the circuit is used, with double-throw switches, in wiring
hallway lights.)
Figure 5. Wiring diagram for (A ∧B) ∨(¬A ∧¬B).
But there is one respect in which relay circuits do not ﬁt the
description given at the beginning of this section. Relays are bilat-
eral devices; they will pass current in either direction. This feature
makes “bridge” circuits possible (Fig. 6). The methods described
here do not apply to such circuits.
Figure 6. Bridge circuit.

58
A Mathematical Introduction to Logic
EXAMPLE 4.
There are four inputs, and the circuit is to realize the
Boolean function G, where G is to have the value T at ⟨F, F, F,
T ⟩,⟨F, F, T, F⟩,⟨F, F, T, T ⟩,⟨F, T, F, F⟩,⟨F, T, F, T ⟩,⟨F, T,
T, F⟩, ⟨F, T, T, T ⟩, and ⟨T, F, F, T ⟩. G is to have the value
F at ⟨T, F, F, F⟩, ⟨T, F, T, F⟩, ⟨T, T, F, F⟩, ⟨T, T, T, F⟩, and
⟨T, T, T, T ⟩. At the remaining three points, ⟨F, F, F, F⟩, ⟨T, F,
T, T ⟩, and ⟨T, T, F, T ⟩, we don’t care about the value of G. (The
application of the circuit is such that these three combinations
never occur.)
We know that G can be realized by using, say, { ∧, ∨, ¬}. But
we want to do this in an efﬁcient way. The ﬁrst step is to repre-
sent the data in a more comprehensible form. We can do this by
means of Fig. 7. Since G(F, F, F, T ) = T , we have placed a T in
the square with coordinates ⟨¬ A, ¬ B, ¬ C, D⟩. Similarly, there
is an F in the square with coordinates ⟨A, B, ¬ C, ¬ D⟩because
G(T, T, F, F) = F. The three squares we do not care about are
left blank.
Figure 7. Diagram for Example 4.
Now we look for a simple geometrical pattern. The shaded area
includes all T ’s and no F’s. It corresponds to the formula
( ¬ A) ∨( ¬ C ∧D),
which is reasonably simple and meets all our requirements. Note
that the input B is not needed at all.

Chapter 1:
Sentential Logic
59
Exercises
1. In Example 1 of this section, verify that there is no solution using
only three devices.
2. Deﬁne a literal to be a wff which is either a sentence symbol or the
negation of a sentence symbol. An implicant of ϕ is a conjunction
α of literals (using distinct sentence symbols) such that α |= ϕ. We
showed in Section 1.5 (cf. Corollary 15C) that any satisﬁable wff ϕ
is tautologically equivalent to a disjunction α1∨· · · ∨αn where each
αi is an implicant of ϕ. An implicant α of ϕ is prime iff it ceases to be
an implicant upon the deletion of any of its literals. Any disjunction
of implicants equivalent to ϕ clearly must, if it is to be of minimum
length, consist only of prime implicants.
(a) Find all prime implicants of
(A →B) ∧( ¬ A →C).
(b) Which disjunctions of prime implicants enjoy the property of
being tautologically equivalent to the formula in part (a)?
3. Repeat (a) and (b) of Exercise 2, but for the formula
(A ∨¬ B) ∧( ¬ C ∨D) →B ∧((A ∧C) ∨( ¬ C ∧D)).
SECTION 1.7
Compactness and Effectiveness
Compactness
We now give a proof of the compactness theorem mentioned earlier
(Section 1.2). Call a set  of wffs satisﬁable iff there is a truth assign-
ment that satisﬁes every member of .
COMPACTNESS THEOREM
A set of wffs is satisﬁable iff every ﬁnite
subset is satisﬁable.
Let us temporarily say that  is ﬁnitely satisﬁable iff every ﬁnite
subset of  is satisﬁable. Then the compactness theorem asserts that
this notion coincides with satisﬁability. Notice that if  is satisﬁable,
then automatically it is ﬁnitely satisﬁable. Also if  is ﬁnite, then the
converse is trivial. (Every set is a subset of itself.) The nontrivial part is
to show that if an inﬁnite set is ﬁnitely satisﬁable, then it is satisﬁable.
PROOF OF THE COMPACTNESS THEOREM.
Theproofconsistsoftwodis-
tinct parts. In the ﬁrst part we take our given ﬁnitely satisﬁable
set  and extend it to a maximal such set . In the second part
we utilize  to make a truth assignment that satisﬁes .

60
A Mathematical Introduction to Logic
For the ﬁrst part let α1, α2, . . . be a ﬁxed enumeration of the
wffs. (This is possible since the set of sentence symbols, and hence
the set of expressions, is countable; see Theorem 0B.) Deﬁne by
recursion (on the natural numbers)
0 = ,
n+1 =
n; αn+1
if this is ﬁnitely satisﬁable,
n; ¬ αn+1
otherwise.
(Recall that n; αn+1 = n ∪{αn+1}.) Then each n is ﬁnitely
satisﬁable; see Exercise 1. Let  = 
n n, the limit of the n’s.
It is clear that (1)  ⊆ and that (2) for any wff α either
α ∈ or (¬ α) ∈. Furthermore, (3)  is ﬁnitely satisﬁable.
For any ﬁnite subset is already a ﬁnite subset of some n and
hence is satisﬁable.
This concludes the ﬁrst part of the proof; we now have a set
 having properties (1)–(3). There is in general not a unique
such set, but there is at least one. (An alternative proof of the
existence of such a  — and one that we can use even if there are
uncountably many sentence symbols — employs Zorn’s lemma.
The reader familiar with uses of Zorn’s lemma should perceive
its applicability here.)
For the second part of the proof we deﬁne a truth assignment
v for the set of all sentence symbols:
v(A) = T
iff
A ∈
for any sentence symbol A. Then for any wff ϕ, we claim that
v satisﬁes ϕ
iff
ϕ ∈.
This is proved by induction on ϕ; see Exercise 2. Since  ⊆,
v must then satisfy every member of .
⊣
COROLLARY 17A
If  |= τ, then there is a ﬁnite 0 ⊆ such that
0 |= τ.
PROOF.
We use the basic fact that  |= τ iff ; ¬ τ is unsatisﬁable.
0 ̸|= τ
for every ﬁnite 0 ⊆
⇒0; ¬ τ is satisﬁable for every ﬁnite
0 ⊆
⇒; ¬ τ
is ﬁnitely satisﬁable
⇒; ¬ τ
is satisﬁable
⇒ ̸|= τ.
⊣
In fact, the above corollary is equivalent to the compactness theorem;
see Exercise 3.

Chapter 1:
Sentential Logic
61
Effectiveness and Computability
Although the method of truth tables is rather cumbersome to use, the
existence of the method yields interesting theoretical conclusions. Sup-
pose we ask of a set  of wffs whether or not there is an effective
procedure that, given a wff τ, will decide whether or not  |= τ. By an
effective procedure we mean one meeting the following conditions:
1. There must be exact instructions (i.e., a program) explaining how
to execute the procedure. The instructions must be ﬁnite in length. After
all, it must be possible to give the instructions to the person or machine
doing the calculations, and one cannot give someone all of an inﬁnite
object. But we impose no upper limit in advance on exactly how long
the instructions can be. If there are more lines in the instructions than
there are electrons in the universe, we merely shrug and say, “That’s a
pretty long program.”
2. These instructions must not demand any brilliance or originality
on the part of the person or machine following them. The idea is that a
diligent clerk (who knows no mathematics but is very good at following
directions) or your computing machine (which does not think at all)
should be able to execute the instructions. That is, it must be possible
for the instructions to be mechanically implemented. The procedure
must avoid random devices (such as the ﬂipping of a coin), or any such
device that can, in practice, only be approximated.
3. In the case of a decision procedure, as asked for above, the pro-
cedure must be such that, given a wff τ, after a ﬁnite number of steps
the procedure produces a “yes” or “no” answer. (That is, the procedure
must be an algorithm for determining the answer.)
On the other hand, we place no bound in advance on the amount of
time that might be required before the answer appears. Nor do we place
any advance bound on the amount of scratch paper (or other storage
medium) that might be required. These will depend on, among other
things, the input τ. But for any one τ, the procedure is to require only a
ﬁnite number of steps to produce the answer, and so only a ﬁnite amount
of scratch paper will be consumed. It is no fair doing an inﬁnite number
of steps and then giving the answer.
People with a digital computing machine may regard a procedure as
being effective only when it can be carried out on their machine in a
“reasonable” length of time. Of course, the matter of what is reasonable
may change with the circumstances. Next year they plan to get a faster
machine with more memory. At that time, their idea of what can be done
in a reasonable length of time will be considerably extended. We want
here a concept of effective procedure that is the limiting case where
all the practical restrictions on running time and memory space are
removed.

62
A Mathematical Introduction to Logic
Of course the foregoing description can hardly be considered a pre-
cisedeﬁnitionoftheword“effective.”And,infact,thatwordwillbeused
only in an informal intuitive way throughout this book. (In Chapter 3
we will meet a precise counterpart, “recursive.”) But as long as we
restrict ourselves to positive assertions that there does exist an effective
procedure of a certain sort, the informal approach sufﬁces. We simply
display the procedure, show that it works, and people will agree that it
is effective. (But this relies on the empirical fact that procedures which
appear effective to one mathematician also appear so to others.) If we
wanted a negative result, that there did not exist an effective procedure
of a certain sort, then this informal viewpoint would be inadequate. (In
Chapter 3 we do want to obtain just such negative results.) Because the
notion of effectiveness is informal, deﬁnitions and theorems involving
it will be marked with a star. For example:
⋆THEOREM 17B
There is an effective procedure that, given any ex-
pression ε, will decide whether or not it is a wff.
PROOF.
See the algorithm in Section 1.3 and the footnotes thereto.
⊣
There is one technical point here, stemming from the fact that our lan-
guage has inﬁnitely many different sentence symbols. When we speak
of being “given” an expression ε, we imagine that someone might write
down the symbols in ε, one after the other. It is implausible that anyone
has the potential of writing down any one of an inﬁnitude of symbols.
To avoid this, we adopt the following “input/output format”: Instead of
writing down A5, for example, we use A′′′′, a string of ﬁve symbols.
Now the total number of symbols in our alphabet is only nine:
(, ), ¬, ∧, ∨, →, ↔, A, and ′.
(If weidentifytheseninesymbolswiththedigits1–9,wegetexpressions
that look particularly familiar in computational settings! And we still
have the 0 digit for separating expressions.)
Theorem 17B states that the set of wffs is decidable in the sense of
the following deﬁnition:
⋆DEFINITION.
A set  of expressions is decidable iff there exists
an effective procedure that, given an expression α, will decide
whether or not α ∈.
For example, any ﬁnite set is decidable. (The instructions can simply
list the ﬁnitely many members of the set. Then the algorithm can check
the input against the list.) Some inﬁnite sets are decidable but not all.
On the one hand, there are uncountably many (2ℵ0, to be exact) sets
of expressions. On the other hand, there can be only countably many
effective procedures. This is because the procedure is completely deter-

Chapter 1:
Sentential Logic
63
mined by its (ﬁnite) instructions. There are only ℵ0 ﬁnite sequences of
letters, and the instructions, when written out, form a ﬁnite sequence of
letters.
⋆THEOREM 17C
There is an effective procedure that, given a ﬁnite
set ; τ of wffs, will decide whether or not  |= τ.
PROOF.
The truth-table procedure (Section 1.2) meets the require-
ment.
⊣
In this theorem we speciﬁed that ; τ was ﬁnite, since one cannot
be “given” in any direct and effective way all of an inﬁnite object.
⋆COROLLARY 17D
For a ﬁnite set , the set of tautological conse-
quences of  is decidable. In particular, the set of tautologies is
decidable.
If  is an inﬁnite set — even a decidable one — then in general its set
of tautological consequences may not be decidable. (See Chapter 3.) But
we can obtain a weaker result, which is in a sense half of decidability.
Say that a set A of expressions is effectively enumerable iff there
exists an effective procedure that lists, in some order, the members of
A. If A is inﬁnite, then the procedure can never ﬁnish. But for any
speciﬁed member of A, it must eventually (i.e., in a ﬁnite length of
time) appear on the list.
To give more of a feeling for this concept, we now state an equivalent
way of formulating it.
⋆THEOREM 17E
A set A of expressions is effectively enumerable iff
there exists an effective procedure that, given any expression ε,
produces the answer “yes” iff ε ∈A.
If ε /∈A, the procedure might produce the answer “no”; more likely
it will go on forever without producing any answer, but it must not
lie to us and produce the answer “yes.” Such a procedure is called a
semidecision procedure — it is half of a decision procedure:
⋆DEFINITION.
A set A of expressions is semidecidable iff there exists
an effective procedure that, given any expression ε, produces the
answer “yes” iff ε ∈A.
Thus Theorem 17E states that a set is effectively enumerable iff it is
semidecidable.
PROOF.
If A is effectively enumerable, then given any ε we can
examine the listing of A as our procedure churns it out. If and
when ε appears, we say “yes.” (Thus if ε /∈A, no answer is ever
given. It is this that keeps A from being decidable. When ε has
failed to occur among the ﬁrst 1010 enumerated members of A,
there is in general no way of knowing whether ε /∈A — in which

64
A Mathematical Introduction to Logic
case one should give up looking — or whether ε will occur in the
very next step.)
Conversely, suppose that we have the procedure described
in the theorem. We want to create a listing of A. The idea is
to enumerate all expressions, and to apply our given procedure to
each. But we must budget our time sensibly. It is easy enough to
enumerate effectively all expressions:
ε1, ε2, ε3, . . . .
Then proceed according to the following scheme:
1. Spend one minute testing ε1, for membership in A (using
the given procedure).
2. Spend two minutes testing ε1, then two minutes testing ε2.
3. Spend three minutes testing ε1, three minutes testing ε2, and
three minutes testing ε3.
And so forth. Of course whenever our procedure produces a
“yes” answer, we put the accepted expression on the output list.
Thus any member of A will eventually appear on the list. (It
will appear inﬁnitely many times, unless we modify the above
instructions to check for duplication.)
⊣
Clearly any decidable set is also semidecidable. (We get a semide-
cision procedure even if the “no” bulb has burned out.) Hence any any
decidable set is effectively enumerable.
⋆THEOREM 17F
A set of expressions is decidable iff both it and its
complement (relative to the set of all expressions) are effectively
enumerable.
PROOF.
Exercise 8. This result is sometimes called “Kleene’s
theorem.”
⊣
Observe that if sets A and B are effectively enumerable, then so are
A ∪B and A ∩B (Exercise 11). The class of decidable sets is also
closed under union and intersection, and it is in addition closed under
complementation.
Now for a more substantive result:
⋆THEOREM 17G
If  is a decidable set of wffs, then the set of tau-
tological consequences of  is effectively enumerable.
PROOF.
Actually it is enough for  to be effectively enumerated;
consider an enumeration
σ1, σ2, σ3, . . . .

Chapter 1:
Sentential Logic
65
Given any wff τ, we can test (by truth tables) successively whether
or not
∅|= τ,
{σ1} |= τ,
{σ1, σ2} |= τ,
{σ1, σ2, σ3} |= τ,
and so forth. If any of these conditions is met, then we answer
“yes.” Otherwise, we keep trying.
This does produce an afﬁrmative answer whenever  |= τ, by
the corollary to the compactness theorem.
⊣
Later on, we will want to use effective procedures to compute func-
tions. We will say that a function f is effectively computable (or simply
computable) iff there exists an effective procedure that, given an input
x, will eventually produce the correct output f (x).
Exercises
1. Assume that every ﬁnite subset of  is satisﬁable. Show that the
same is true of at least one of the sets ; α and ; ¬ α. (This is
part of the proof of the compactness theorem.) Suggestion: If not,
then 1; α and 2; ¬ α are unsatisﬁable for some ﬁnite 1 ⊆
and 2 ⊆. Look at 1 ∪2.
2. Let  be a set of wffs such that (i) every ﬁnite subset of  is
satisﬁable, and (ii) for every wff α, either α ∈ or (¬ α) ∈.
Deﬁne the truth assignment v:
v(A) =

T
iff
A ∈,
F
iff
A /∈
for each sentence symbol A. Show that for every wff ϕ, v(ϕ) = T
iff ϕ ∈. (This is part of the proof of the compactness theorem.)
Suggestion: Use induction on ϕ.
3. Show that from the corollary to the compactness theorem we can
prove the compactness theorem itself (far more easily than we can
starting from scratch).
4. In 1977 it was proved that every planar map can be colored with
four colors. Of course, the deﬁnition of “map” requires that there
be only ﬁnitely many countries. But extending the concept, sup-
pose we have an inﬁnite (but countable) planar map with countries
C1, C2, C3, . . . . Prove that this inﬁnite planar map can still be col-
ored with four colors. (Suggestion: Partition the sentence symbols
into four parts. One sentence symbol, for example, can be used to
translate, “Country C7 is colored red.” Form a set 1 of wffs that
say, for example, C7 is exactly one of the colors. Form another set

66
A Mathematical Introduction to Logic
2 of wffs that say, for each pair of adjacent countries, that they
are not the same color. Apply compactness to 1 ∪2.)
5. Where  is a set of wffs, deﬁne a deduction from  to be a ﬁnite
sequence ⟨α0, . . . , αn⟩of wffs such that for each k ≤n, either (a)
αk is a tautology, (b) αk ∈, or (c) for some i and j less than k, αi
is (α j →αk). (In case (c), one says that αk is obtained by modus
ponens from αi and α j.) Give a deduction from the set
{¬ S ∨R, R →P, S}
the last component of which is P.
6. Let ⟨α0, . . . , αn⟩be a deduction from a set  of wffs, as in the
preceding problem. Show that  |= αk for each k ≤n. Suggestion:
Use strong induction on k, so that the inductive hypothesis is that
 |= αi for all i < k.
7. Show that whenever  |= τ, then there exists a deduction from
, the last component of which is τ. Remark: This result is called
“completeness”; the concepts in Exercises 5–7 will reappear in
Section 2.4.
8. Prove Theorem 17F. Remark: Two semidecision procedures make
a whole.
∗9. The concepts of decidability and effective enumerability can be
applied not only to sets of expressions but also to sets of integers
or to sets of pairs of expressions or integers. Show that a set A of
expressions is effectively enumerable iff there is a decidable set B
of pairs ⟨α, n⟩(consisting of an expression α and an integer n) such
that A = dom B.
10. Let  be an effectively enumerable set of wffs. Assume that for each
wff τ, either  |= τ or  |= ¬ τ. Show that the set of tautological
consequences of  is decidable.
(a) Do this where “or” is interpreted in the exclusive sense: either
 |= τ or  |= ¬ τ but not both.
(b) Do this where “or” is interpreted in the inclusive sense: either
 |= τ or  |= ¬ τ or both.
11. (a) Explain why the union of two effectively enumerable sets is
again effectively enumerable.
(b) Explain why the intersection of two effectively enumerable sets
is again effectively enumerable.
12. For each of the following conditions, give an example of an unsat-
isﬁable set  of formulas that meets the condition.
(a) Each member of  is — by itself — satisﬁable.
(b) For any two members γ1 and γ2 of , the set {γ1, γ2} is satisﬁ-
able.
(c) For any three members γ1, γ2, and γ3 of , the set {γ1, γ2, γ3}
is satisﬁable.

Chapter
T W O
First-Order Logic
SECTION 2.0
Preliminary Remarks
The preceding chapter presented the ﬁrst of our
mathematical models of deductive thought. It was
a simple model, indeed too simple. It is easy to
think of examples of intuitively correct deductions
that cannot be adequately mirrored in the model of
sentential logic.
Suppose we begin with a collection of hypothe-
ses(inEnglish)andapossibleconclusion.Bytrans-
lating everything to the language of sentential logic
we obtain a set  of hypotheses and a possible con-
clusion τ. Now if  |= τ, then we feel that the orig-
inal English-language deduction was valid. But if
 ̸|= τ, then we are unsure. It may well be that the
model of sentential logic was simply too crude to
mirror the subtlety of the original deduction.
This chapter presents a system of logic of much
greater ability. In fact, when the “working mathe-
matician” ﬁnds a proof, almost invariably what is
meant is a proof that can be mirrored in the system
of this chapter.
First, we want to give an informal description of
the features our ﬁrst-order languages might have
(or at least might be able to simulate). We begin
with a special case, the ﬁrst-order language for
number theory. For this language there is a certain
intended way of translating to and from English
(Table VII).
67

68
A Mathematical Introduction to Logic
TABLE VII
Formal expression
Intended translation
0
“Zero.” Here 0 is a constant symbol, intended to
name the number 0.
St
“The successor of t.” Here S is a one-place function
symbol. t is to be an expression that names some
number a. Then St names S(a), the successor of a.
For example, S0 is intended to name the number 1.
<v1v2
“v1 is less than v2.” Here < is a two-place predicate
symbol. At the end of Section 2.1 we will adopt
conventions letting us abbreviate the expression in
the more usual style: v1 < v2.
∀
“For every natural number.” The symbol ∀is the
universal quantiﬁer symbol. More generally, with
each translation of the language into English there
will be associated a certain set A (the so-called uni-
verse); ∀will then become “for every member of
the universe A.”
∀v1 < 0v1
“For every natural number v1, zero is less than v1.”
Or more euphoniously, “Every natural number is
larger than 0.” This formal sentence is false in the
intended translation, since zero is not larger than
itself.
One abbreviation is mentioned in Table VII. There will be more
(Table VIII).
Actually we will not be quite as generous as the tables might suggest.
There are two economy measures that we can take to obtain simpliﬁca-
tion without any essential loss of linguistic expressiveness:
First, we choose as our sentential connective symbols just ¬ and →.
We know from Section 1.5 that these form a complete set, so there is no
compelling reason to use more.
Secondly, we forego the luxury of an existential quantiﬁer, ∃x. In its
place we use ¬ ∀x ¬. This is justiﬁed, since an English sentence like
There is something rotten in the state of Denmark,
is equivalent to
It is not the case that for every x, x is not rotten in the state
of Denmark.
Thus the formula ∃v1 ∀v2 v1 = v2 becomes, in unabbreviated form,
(¬ ∀v1(¬ ∀v2 = v1v2)).

Chapter 2:
First-Order Logic
69
TABLE VIII
Abbreviated expression
Intended translation
x = y
“x equals y.” In unabbreviated form this will
become =xy.
∃v
“There exists a natural number v such that.” Or
more generally, “there exists a member of the
universe such that.”
∃v1 ∀v2 v1 = v2
“There is exactly one natural number.” Again
this formal sentence is false in the intended
translation.
∀v1(0 < v1 ∨0 = v1)
“Every natural number is greater than or equal
to zero.”
For an example in an ad hoc language, we might translate “Socrates
is a man” as Hs, where H is a one-place predicate symbol intended
to translate “is a man” and s is a constant symbol intended to name
Socrates. Similarly, to translate “Socrates is mortal” we take Ms. Then
“All men are mortal” is translated as ∀v1(Hv1 →Mv1).
The reader will possibly recognize the symbols ∀and ∃from previ-
ous mathematical contexts. Indeed, some mathematicians, when writing
on the blackboard during their lectures, already use a nearly formalized
language with only vestigial traces of English. That our ﬁrst-order lan-
guages resemble theirs is no accident. We want to be able to take one
step back and study not, say, sets or groups, but the sentences of set
theory or group theory. (The term metamathematics is sometimes used;
the word itself suggests the procedure of stepping back and examining
what the mathematician is doing.) The objects you, the logician, now
study are the sentences that you, the set theoretician, previously used in
the study of sets. This requires formalizing the language of set theory.
And we want our formal languages to incorporate the features used in,
for example, set theory.
SECTION 2.1
First-Order Languages
We assume henceforth that we have been given inﬁnitely many distinct
objects (which we call symbols), arranged as follows:
A. Logical symbols
0. Parentheses: ( , ).
1. Sentential connective symbols: →, ¬.

70
A Mathematical Introduction to Logic
2. Variables (one for each positive integer n):
v1, v2, . . . .
3. Equality symbol (optional): =.
B. Parameters
0. Quantiﬁer symbol: ∀.
1. Predicate symbols: For each positive integer n, some set (pos-
sibly empty) of symbols, called n-place predicate symbols.
2. Constant symbols: Some set (possibly empty) of symbols.
3. Function symbols: For each positive integer n, some set (pos-
sibly empty) of symbols, called n-place function symbols.
In A.3 we allow for the possibility of the equality symbol’s being
present, but we do not assume its presence. Some languages will have
it and others will not. The equality symbol is a two-place predicate
symbol but is distinguished from the other two-place predicate symbols
by being a logical symbol rather than a parameter. (This status will affect
its behavior under translations into English.) We do need to assume that
some n-place predicate symbol is present for some n.
In B.2, the constant symbols are also called 0-place function symbols.
This will often allow a uniform treatment of the symbols in B.2 and B.3.
As before, we assume that the symbols are distinct and that no symbol
is a ﬁnite sequence of other symbols.
In order to specify which language we have before us (as distinct
from other ﬁrst-order languages), we must (i) say whether or not the
equality symbol is present, and (ii) say what the parameters are.
We now list some examples of what this language might be:
1. Pure predicate language
Equality: No.
n-place predicate symbols: An
1, An
2, . . . .
Constant symbols: a1, a2, . . . .
n-place function symbols (n > 0): None.
2. Language of set theory
Equality: Yes (usually).
Predicate parameters: One two-place predicate symbol ∈.
Function symbols: None (or occasionally a constant symbol ∅).
3. Language of elementary number theory (as in Chapter 3)
Equality: Yes.
Predicate parameters: One two-place predicate symbol <.
Constant symbols: The symbol 0.

Chapter 2:
First-Order Logic
71
One-place function symbols: S (for successor).
Two-place function symbols: + (for addition), · (for multiplication),
and E (for exponentiation).
In examples 2 and 3 there are certain intended translations of the
parameters. We will presently give a number of examples of sentences
that can be translated into these languages and a few examples of sen-
tences that cannot be so translated.
It is important to notice that our notion of language includes the
language for set theory. For it is generally agreed that, by and large,
mathematics can be embedded into set theory. By this is meant that
(a) Statements in mathematics (such as the fundamental theorem of
calculus) can be expressed in the language of set theory; and
(b) The theorems of mathematics follow logically from the axioms
of set theory.
Our model of ﬁrst-order logic is fully adequate to mirror this procedure.
EXAMPLES
in the language of set theory. Here it is intended that ∀
should mean “for all sets” and ∈should mean “is a member of.”
1. “There is no set of which every set is a member.” We will
translate this into the language of set theory using several steps.
The intermediate sentences are neither in English nor in the formal
language but are in a mixed language.
¬[There is a set of which every set is a member]
¬ ∃v1[Every set is a member of v1]
¬ ∃v1 ∀v2 v2 ∈v1
Although it is tempting to stop here, we must now replace v2 ∈v1
by ∈v2v1, since predicate symbols will always go at the left in
such contexts. Furthermore, ∃v1 must be replaced by ¬ ∀v1 ¬,
as mentioned earlier. And we must use the correct number of
parentheses. The ﬁnished product is
(¬ (¬ ∀v1(¬ ∀v2 ∈v2v1))).
2. Pair-set axiom: “For any two sets, there is a set whose mem-
bers are exactly the two given sets.” Again we carry out the trans-
lation in stages.
∀v1 ∀v2 [There is a set whose members are exactly v1 and
v2]
∀v1 ∀v2 ∃v3 [The members of v3 are exactly v1 and v2]
∀v1 ∀v2 ∃v3 ∀v4(v4 ∈v3 ↔v4 = v1 ∨v4 = v2)
Now we replace ∃v3 by ¬ ∀v3 ¬, v4 ∈v3 by ∈v4v3, and v4 =vi
by =v4vi. In addition, we must eliminate ↔and ∧in favor of
our chosen connectives →and ¬. Thus
α ∨β becomes ¬ α →β;
α ↔β becomes ¬ ((α →β) →¬ (β →α)).

72
A Mathematical Introduction to Logic
The ﬁnished product is
∀v1 ∀v2(¬ ∀v3(¬ ∀v4(¬ ((∈v4v3 →(( ¬ =v4v1)→
= v4v2)) →(¬ (((¬ =v4v1) →=v4v2) →∈v4v3)))))).
The ﬁnished product is not nearly as pleasant to read as the ver-
sion that preceded it. As we have no interest in deliberately making
life unpleasant for ourselves, we will eventually adopt conventions
allowing us to avoid seeing the ﬁnished product at all. But for the
moment it should be regarded as an interesting, even if unattractive,
novelty.
EXAMPLES
in the language of elementary number theory. Here it is
intended that ∀should mean “for all natural numbers” and that
<, 0, S, +, ·, and E should have the obvious meanings.
1. As a name for the natural number 2 we have the term SS0,
since 2 is the successor of the successor of zero. Similarly, for 4
we have the term SSSS0. For the phrase “2 + 2” it is tempting to
use SS0 + SS0. But we will adopt the policy of always putting
the function symbol at the left (i.e., we will use Polish notation
for function symbols). Thus corresponding to the English phrase
“2 + 2” we have the term + SS0 SS0. The English sentence “Two
plus two is four” is translated as
= + SS0 SS0 SSSS0.
(The spaces are inserted to help the reader, but they do not con-
stitute an ofﬁcial feature of the language.)
2. “Any nonzero natural number is the successor of some num-
ber.” We will perform the translation in three steps:
∀v1 [ If v1 is nonzero, then v1 is the successor of some number.]
∀v1 (v1 ̸= 0 →∃v2 v1 = Sv2).
∀v1 ((¬ =v10) →(¬ ∀v2(¬ =v1Sv2))).
3. “Any nonempty set of natural numbers has a least element.”
This cannot be translated into our language, because we cannot
express “any . . . set.” This requires either something like the (ﬁrst-
order) language for set theory or a second-order language for
number theory. We could, however, translate, “The set of primes
has a least element.” (The ﬁrst step is to convert this sentence into,
“There is a smallest prime.” We leave the other steps to the reader;
hints can be found in the next section.)
EXAMPLES
in ad hoc languages
1. “All apples are bad.”
∀v1(Av1 →Bv1).

Chapter 2:
First-Order Logic
73
2. “Some apples are bad.”
Intermediate step: ∃v1(Av1 ∧Bv1).
Finished product: (¬ ∀v1(¬ (¬ (Av1 →(¬ Bv1))))).
These two examples illustrate patterns that arise continually.
An English sentence which asserts that everything in a certain
category has some property is translated
∀v(
→
).
A sentence which asserts that there is some object or objects in
the category and having the property is translated
∃v(
∧
).
The reader should be cautioned against confusing the two pat-
terns. For example,
∀v1(Av1 ∧Bv1)
translates “Everything is an apple and is bad,” which is a much
stronger assertion than the sentence in the ﬁrst example. Similarly,
∃v1(Av1 →Bv1) translates “There is something which is bad, if
it is an apple.” This is a much weaker assertion than the sentence
in the second example. It is true (vacuously) even if all apples are
good, provided only that the world has something which is not an
apple.
3. “Bobby’s father can beat up the father of any other kid on
the block.” Establish a language in which ∀is intended to mean
“for all people,” K x is to mean “x is a kid on the block,” b is to
mean “Bobby,” Bxy is to mean “x can beat up y,” and f x is to
mean “the father of x.” Then a translation is
∀v1(Kv1 →((¬ =v1b) →B f bf v1)).
4. In calculus, we learn the meaning of “the function f con-
verges to L as x approaches a”:
∀ε(ε > 0 →∃δ(δ > 0 ∧∀x(|x −a| < δ →| f x −L| < ε))).
This is, apart from notational matters, a formula of the sort we
are interested in, using a predicate symbol for ordering, function
symbols for f , subtraction, and absolute values, and constant
symbols for 0, a, and L.
Formulas
An expression is any ﬁnite sequence of symbols. Of course most ex-
pressions are nonsensical, but there are certain interesting expressions:
the terms and the wffs.

74
A Mathematical Introduction to Logic
The terms are the nouns and pronouns of our language; they are the
expressions that can be interpreted as naming an object. The atomic
formulas will be those wffs having neither connective nor quantiﬁer
symbols.
The terms are deﬁned to be those expressions that can be built up
from the constant symbols and the variables by preﬁxing the function
symbols. To restate this in the terminology of Chapter 1, we deﬁne for
each n-place function symbol f , an n-place term-building operation F f
on expressions:
F f (ε1, . . . , εn) = f ε1 · · · εn.
DEFINITION.
The set of terms is the set of expressions that can be
built up from the constant symbols and variables by applying (zero
or more times) the F f operations.
If there are no function symbols (apart from the constant symbols),
then the terms are just the constant symbols and the variables. In this
case we do not need an inductive deﬁnition.
Notice that we use Polish notation for terms by placing the function
symbol at the left. The terms do not contain parentheses or commas. We
will later prove a unique readability result, showing that given a term,
we can unambiguously decompose it.
The terms are the expressions that are translated as names of objects
(noun phrases), in contrast to the wffs which are translated as assertions
about objects.
Some examples of terms in the language of number theory are
+v2S0,
SSSS0,
+Ev1SS0 Ev2SS0.
The atomic formulas will play a role roughly analogous to that played
by the sentence symbols in sentential logic. An atomic formula is an
expression of the form
Pt1 · · · tn,
where P is an n-place predicate symbol and t1, . . . , tn are terms.
For example, =v1v2 is an atomic formula, since = is a two-place
predicate symbol and each variable is a term. In the language of set
theory we have the atomic formula ∈v5v3.

Chapter 2:
First-Order Logic
75
Notice that the atomic formulas are not deﬁned inductively. In-
stead we have simply said explicitly just which expressions are atomic
formulas.
The well-formed formulas are those expressions that can be built up
from the atomic formulas by use (zero or more times) of the connective
symbols and the quantiﬁer symbol. We can restate this in the terminol-
ogy of Chapter 1 by ﬁrst deﬁning some formula-building operations on
expressions:
E¬(γ ) = (¬ γ ),
E→(γ, δ) = (γ →δ),
Qi(γ ) = ∀viγ.
DEFINITION.
The set of well-formed formulas (wffs, or just formulas)
is the set of expressions that can be built up from the atomic
formulas by applying (zero or more times) the operations E¬,
E→, and Qi (i = 1, 2, . . .).
For example, on the one hand, ¬ v3 is not a wff. (Why?) On the other
hand,
∀v1((¬ ∀v3( ¬ ∈v3v1)) →(¬ ∀v2(∈v2v1→
(¬ ∀v4(∈v4v2 →( ¬ ∈v4v1))))))
is a wff, as is demonstrated by the following tree:

76
A Mathematical Introduction to Logic
But it requires some study to discover that this wff is the axiom of
regularity for set theory.
Free Variables
Two examples of wffs are ∀v2∈v2v1 and (¬ ∀v1(¬ ∀v2∈v2v1)). But
there is an important difference between the two examples. The second
might be translated back into English as
There is a set such that every set is a member of it.
The ﬁrst example, however, can be translated only as an incomplete
sentence, such as
Every set is a member of
1.
We are unable to complete the sentence without knowing what to do
with v1. In cases of this sort, we will say that v1 occurs free in the wff
∀v2∈v2v1.Incontrast,novariableoccursfreein(¬ ∀v1(¬ ∀v2∈v2v1)).
But of course we need a precise deﬁnition which does not refer to
possible translations to English but refers only to the symbols
themselves.
Consider any variable x. We deﬁne, for each wff α, what it means
for x to occur free in α. This we do by recursion:
1. For atomic α, x occurs free in α iff x occurs in (i.e., is a symbol
of) α.
2. x occurs free in (¬ α) iff x occurs free in α.
3. x occurs free in (α →β) iff x occurs free in α or in β.
4. x occurs free in ∀vi α iff x occurs free in α and x ̸= vi.
This deﬁnition makes tacit use of the recursion theorem. We can
restate the situation in terms of functions. We begin with the function h
deﬁned on atomic formulas:
h(α) = the set of all variables, if any, in the atomic formula α.
And we want to extend h to a function h deﬁned on all wffs in such a
way that
h(E¬(α)) = h(α),
h(E→(α, β)) = h(α) ∪h(β),
h(Qi(α)) = h(α) after removing vi, if present.
Thenwesaythat x occursfreeinα (orthat x isafreevariableofα)iff x ∈
h(α). The existence of a unique such h (and hence the meaningfulness
of our deﬁnition) follows from the recursion theorem of Section 1.4
and from the fact (proved in Section 2.3) that each wff has a unique
decomposition.

Chapter 2:
First-Order Logic
77
If no variable occurs free in the wff α (i.e., if h(α) = ∅), then α is a
sentence.(ThesentencesareintuitivelythewffstranslatableintoEnglish
without blanks, once we are told how to interpret the parameters.)
For example, ∀v2(Av2 →Bv2) and ∀v3(Pv3 →∀v3Qv3) are sen-
tences,butv1 occursfreein( ∀v1Av1→Bv1).Thesentencesareusually
the most interesting wffs. The others lead a second-class existence; they
are used primarily as building blocks for sentences.
In translating a sentence from English, the choice of particular vari-
ables is unimportant. We earlier translated “All apples are bad” as
∀v1(Av1 →Bv1). We could equally well have used
∀v27(Av27 →Bv27).
The variable is, in effect, used as a pronoun, just as in English we might
say, “For any object whatsoever, if it is an apple, then it is bad.” (We
have incorporated into our language an adequate supply of pronouns:
it1, it2, . . . .) Since the choice of particular variables is unimportant,
we will often not even specify the choice. Instead we will write, for
example, ∀x(Ax →Bx), where it is understood that x is some variable.
(The unimportance of the choice of variable will eventually become a
theorem.)
Similar usages of variables occur elsewhere in mathematics. In
7

i=1
ai j
i is a “dummy” variable but j occurs free.
On Notation
We can specify a wff (or indeed any expression) by writing a line that
displays explicitly every symbol. For example,
∀v1((¬ =v10) →(¬ ∀v2(¬ =v1Sv2))).
But this way of writing things, while splendidly complete, may not
be readily comprehensible. The incomprehensibility can be blamed (in
part) on the simpliﬁcations we wanted in the language (such as the lack
of an existential quantiﬁer symbol). We naturally want to have our cake
and eat it too, so we now will agree on methods of specifying wffs in
more indirect but more readable ways. These conventions will let us
write a line such as
∀v1(v1 ̸= 0 →∃v2 v1 = Sv2)
to name the same wff as is named by the other line above.
Note well that we are not changing our deﬁnition of what a wff is.
We are simply conspiring to ﬁx certain ways of naming wffs. In the
(rare) cases where the exact sequence of symbols becomes important,

78
A Mathematical Introduction to Logic
we may have to drop these new conventions and revert to primitive
notation.
We adopt then the following abbreviations and conventions. Here α
and β are formulas, x is a variable, and u and t are terms.
(α ∨β) abbreviates ((¬ α) →β).
(α ∧β) abbreviates ( ¬ (α →( ¬ β))).
(α ↔β) abbreviates ((α →β) ∧(β →α)); i.e.,
( ¬ ((α →β) →( ¬ (β →α)))).
∃x α abbreviates ( ¬ ∀x( ¬ α)).
u = t abbreviates =ut. A similar abbreviation applies to some other
two-place predicate and function symbols. For example, 2 < 3 abbre-
viates <2 3 and 2 + 2 abbreviates +2 2.
u ̸= t abbreviates (¬ =ut); similarly u ̸< t abbreviates ( ¬ <ut).
For parentheses we will use not only ( and ) but also [ and ], etc. And
we omit mention of just as many as we possibly can. Toward that end
we adopt the following conventions:
1. Outermost parentheses may be dropped. For example, ∀x α →β
is ( ∀x α →β).
2. ¬, ∀, and ∃apply to as little as possible. For example,
¬ α ∧β is (( ¬ α) ∧β),
and not
¬ (α ∧β);
∀x α →β is ( ∀x α →β),
and not
∀x(α →β);
∃x α ∧β is ( ∃x α ∧β),
and not
∃x(α ∧β).
Insuchcaseswemightevenaddgratuitousparentheses,asin(∃x α)∧β.
3. ∧and ∨apply to as little as possible, subject to item 2. For
example,
¬ α ∧β →γ is (( ¬ α) ∧β) →γ.
4. When one connective is used repeatedly, the expression is grouped
to the right. For example,
α →β →γ is α →(β →γ ).
EXAMPLES
of how we can eliminate abbreviations, rewriting the for-
mula in an unabbreviated way that explicitly lists each symbol in
order:
1. ∃x(Ax ∧Bx) is (¬ ∀x( ¬ ( ¬ (Ax →(¬ Bx))))).
But (¬ ∀x(Ax →(¬ Bx))) would be an equivalent formula (in any
reasonable notion of equivalence).
2. ∃x Ax →Bx is ((¬ ∀x(¬ Ax)) →Bx).
∃x(Ax →Bx) is (¬ ∀x( ¬ (Ax →Bx))).
We will try to use the various alphabets in a systematic way. The
system is listed below, but there will be occasional exceptions for special
reasons.

Chapter 2:
First-Order Logic
79
Predicate symbols: Uppercase italic letters. Also ∈, <.
Variables: vi, u, v, x, y, z.
Function symbols: f, g, h. Also S, +, etc.
Constant symbols: a, b, . . . . Also 0.
Terms: u, t.
Formulas: Lowercase Greek letters.
Sentences: σ, τ.
Sets of formulas: Uppercase Greek letters, plus certain italic letters
that pretend to be Greek, viz., A (alpha) and T (tau).
Structures (see the next section): Uppercase German (Fraktur) letters.
Exercises
1. Assume that we have a language with the following parameters:
∀, intended to mean “for all things”; N, intended to mean “is a
number”; I, intended to mean “is interesting”; <, intended to mean
“is less than”; and 0, a constant symbol intended to denote zero.
Translate into this language the English sentences listed below. If
the English sentence is ambiguous, you will need more than one
translation.
(a) Zero is less than any number.
(b) If any number is interesting, then zero is interesting.
(c) No number is less than zero.
(d) Any uninteresting number with the property that all smaller
numbers are interesting certainly is interesting.
(e) There is no number such that all numbers are less than it.
(f) There is no number such that no number is less than it.
2. With the same language as in the preceding exercise, translate back
into good English the wff
∀x(Nx →I x →¬ ∀y(Ny →I y →¬ x < y)).
In 3–8, translate each English sentence into the ﬁrst-order lan-
guagespeciﬁed.(Youmaywanttocarryoutthetranslationinseveral
steps, as in some of the examples.) Make full use of the notational
conventions and abbreviations to make the end result as readable
as possible.
3. Neither a nor b is a member of every set. (∀, for all sets; ∈, is a
member of; a, a; b, b.)
4. If horses are animals, then heads of horses are heads of animals.
(∀, for all things; E, is a horse; A, is an animal; hx, the head of x.)
5. (a) You can fool some of the people all of the time. (b) You can
fool all of the people some of the time. (c) You can’t fool all of
the people all of the time. (∀, for all things; P, is a person; T , is a

80
A Mathematical Introduction to Logic
time; Fxy, you can fool x at y. One or more of the above may be
ambiguous, in which case you will need more than one translation.)
6. (a) Adams can’t do every job right. (b) Adams can’t do any job
right. (∀, for all things; J, is a job; a, Adams; Dxy, x can do y
right.)
7. (a) Nobody likes everybody. (b) No Democrat likes every Repub-
lican. (∀, for all people; Lxy, x likes y; D, is a Democrat; R, is a
Republican.)
8. (a) Every farmer who owns a donkey needs hay. (b) Every farmer
who owns a donkey beats it. (∀, for all things; F, is a farmer; D, is
a donkey; Oxy, x owns y; H, needs hay; Bxy, x beats y.)
9. Give a precise deﬁnition of what it means for the variable x to occur
free as the ith symbol in the wff α. (If x is the ith symbol of α but
does not occur free there, then it is said to occur bound there.)
10. Rewrite each of the following wffs in a way which explicitly lists
each symbol in the actual order:
(a) ∃v1Pv1 ∧Pv1.
(b) ∀v1Av1 ∧Bv1 →∃v2 ¬ Cv2 ∨Dv2.
In each case, say which variables occur free in the wff.
SECTION 2.2
Truth and Models
In sentential logic we had truth assignments to tell us which sentence
symbols were to be interpreted as being true and which as false. In ﬁrst-
order logic the analogous role is played by structures, which can be
thought of as providing the dictionary for translations from the formal
language into English. (Structures are sometimes called interpretations,
but we prefer to reserve that word for another concept, to be encountered
in Section 2.7.)
A structure for a ﬁrst-order language will tell us
1. What collection of things the universal quantiﬁer symbol (∀)
refers to, and
2. What the other parameters (the predicate and function symbols)
denote.
Formally, a structure A for our given ﬁrst-order language is a function
whose domain is the set of parameters and such that1
1 The symbol “A” is the letter A in the German (Fraktur) alphabet. The next two letters
are B and C.

Chapter 2:
First-Order Logic
81
1. A assigns to the quantiﬁer symbol ∀a nonempty set |A| called
the universe (or domain) of A.
2. A assigns to each n-place predicate symbol P an n-ary relation
PA ⊆|A|n; i.e., PA is a set of n-tuples of members of the universe.
3. A assigns to each constant symbol c a member cA of the uni-
verse |A|.
4. A assigns to each n-place function symbol f an n-ary operation
f A on |A|; i.e., f A : |A|n →|A|.
The idea is that A assigns meaning to the parameters. ∀is to mean
“for everything in |A|.” The symbol c is to name the point cA. The
atomic formula Pt1 · · · tn is to mean that the n-tuple of points named by
t1, . . . , tn is in the relation PA. (We will shortly restate these conditions
more carefully.)
Note that we require the universe |A| to be nonempty. Notice also that
f A must have all of |A|n in for its domain; we have made no provision
for partially deﬁned functions.
EXAMPLE.
Consider the language for set theory, whose only param-
eter (other than ∀) is ∈. Take the structure A with
|A| = the set of natural numbers,
∈A = the set of pairs ⟨m, n⟩such that m < n.
(Thuswetranslate∈as“islessthan.”)Inthepresenceofastructure
we can translate sentences from the formal language into English
and attempt to say whether these translations are true or false. The
sentence of this ﬁrst-order language
∃x ∀y ¬ y ∈x
(or more formally, (¬ ∀v1(¬ ∀v2( ¬ ∈v2v1)))), which under an-
other translation asserts the existence of an empty set, is now
translated under A into
There is a natural number such that no natural number
is smaller,
which is true. Because of this we will say that ∃x ∀y ¬ y ∈x is
true in A, or that A is a model of the sentence. On the other hand,
A is not a model of the pair-set axiom,
∀x ∀y ∃z ∀t(t ∈z ↔t = x ∨t = y),
as the translation of this sentence under A is false. For there is no
natural number m such that for every n,
n < m
iff n = 1.
(The reader familiar with axiomatic set theory can check that A

82
A Mathematical Introduction to Logic
is a model of the extensionality axiom, the union axiom, and the
axiom of regularity.)
EXAMPLE.
Again assume the language has only the parameters ∀
and a two-place predicate symbol E. But this time, consider the
ﬁnite structure B with universe |B| consisting of a set of four
distinct objects {a, b, c, d}. Suppose the binary relation EB is the
following set of pairs:
EB = {⟨a, b⟩, ⟨b, a⟩, ⟨b, c⟩, ⟨c, c⟩}.
Then we can picture B as the directed graph whose vertex-set is
the universe {a, b, c, d}:
d
a
c
b
Here we interpret Exy as saying there is an edge from vertex x to
vertex y in the graph. (If the binary relation EB had been symmetric,
then we could have pictured the structure as an undirected graph.)
Consider now the sentence ∃x ∀y ¬ yEx. Under the structure
B, we can translate this as follows:
There is a vertex such that for any vertex,
no edge points from the latter to the former.
(The English version is harder to read than the symbolic one!) This
sentence is true in B, because no edge points to the vertex d.
In the preceding examples it was intuitively pretty clear that certain
sentences of the formal language were true in the structure and some
were false. But we want a precise mathematical deﬁnition of “σ is true
in A.” This should be stated in mathematical terms, without employing
translations into English or a supposed criterion for asserting that some
English sentences are true while the others are false. (If you think you
have such a criterion, try it on the sentence “This sentence is false.”) In
other words, we want to take our informal concept of “σ is true in A”
and make it part of mathematics.
In order to deﬁne “σ is true in A,”
|=A σ,
for sentences σ and structures A, we will ﬁnd it desirable ﬁrst to deﬁne
a more general concept involving wffs. Let
ϕ be a wff of our language,
A a structure for the language,

Chapter 2:
First-Order Logic
83
s : V →|A| a function from the set V of all variables into the universe
|A| of A.
Then we will deﬁne what it means for A to satisfy ϕ with s,
|=A ϕ[s].
The informal version is
|=A ϕ[s] if and only if the translation of ϕ determined by A, where
the variable x is translated as s(x) wherever it occurs free, is true.
The formal deﬁnition of satisfaction proceeds as follows:
I. Terms. We deﬁne the extension
s : T →|A|,
a function from the set T of all terms into the universe of A. The idea
is that s(t) should be the member of the universe |A| that is named by
the term t. s is deﬁned by recursion as follows:
1. For each variable x, s(x) = s(x).
2. For each constant symbol c, s(c) = cA.
3. If t1, . . . , tn are terms and f is an n-place function symbol, then
s( f t1 · · · tn) = f A(s(t1), . . . , s(tn)).
A commutative diagram, for n = 1, is
The existence of a unique such extension s of s follows from the recur-
sion theorem (Section 1.4), by using the fact that the terms have unique
decompositions (Section 2.3). Notice that s depends both on s and on A.
(In fact a reasonable alternative notation for s(t) would be tA[s], which
explicitly displays the dependence on A.)
II. Atomic formulas. The atomic formulas were deﬁned explicitly,
not inductively. The deﬁnition of satisfaction of atomic formulas is
therefore also explicit, and not recursive.
1. |=A =t1t2[s] iff s(t1) = s(t2).
(Thus = means =. Note that = is a logical symbol, not a parameter
open to interpretation.)
2. For an n-place predicate parameter P,
|=A Pt1 · · · tn[s] iff ⟨s(t1), . . . , s(tn)⟩∈PA.

84
A Mathematical Introduction to Logic
III. Other wffs. The wffs we deﬁned inductively, and consequently
here satisfaction is deﬁned recursively.
1. For atomic formulas, the deﬁnition is above.
2. |=A ¬ ϕ[s] iff ̸|=A ϕ[s].
3. |=A (ϕ →ψ)[s] iff either ̸|=A ϕ[s] or |=A ψ[s] or both.
(In other words, if A satisﬁes ϕ with s then A satisﬁes ψ with s.)
4. |=A ∀x ϕ[s] iff for every d ∈|A|, we have |=A ϕ[s(x | d)].
Here s(x | d) is the function which is exactly like s except for one thing:
At the variable x it assumes the value d. This can be expressed by the
equation
s(x | d)(y) =

s(y)
if
y ̸= x,
d
if
y = x.
(Thus ∀means “for all things in |A|.”)
At this point the reader might want to reconsider the informal version
of |=A ϕ[s] on page 83 and observe how it has been formalized.
We should remark that the deﬁnition of satisfaction is another ap-
plication of the recursion theorem together with the fact that the wffs
have unique decompositions. The deﬁnition can be restated in terms of
functions to make it clearer how the recursion theorem of Section 1.4
applies:
(i) Consider one ﬁxed A.
(ii) Deﬁne a function h (extending a function h deﬁned on atomic
formulas) such that for any wff ϕ, h(ϕ) is a set of functions from V
into |A|.
(iii) Deﬁne
|=A ϕ[s]
iff
s ∈h(ϕ).
We leave to the reader the exercise of writing down the explicit
deﬁnition of h and the clauses that uniquely determine its extension
h. (See Exercise 7.) An elegant alternative is to have h(ϕ) be a set of
functions on the set of those variables that occur free in ϕ.
EXAMPLE.
Assume that our language has the parameters ∀, P (a two-
place predicate symbol), f (a one-place function symbol), and c (a
constant symbol). Let A be the structure for his language deﬁned
as follows:
|A| = N, the set of all natural numbers,
PA = the set of pairs ⟨m, n⟩such that m ≤n,
f A = the successor function S; f A(n) = n + 1,
cA = 0.
We can summarize this in one line, by suppressing the fact that A

Chapter 2:
First-Order Logic
85
is really a function and merely listing its components:
A = (N; ≤, S, 0).
This notation is unambiguous only when the context makes clear
just which components go with which parameters.
Let s : V →N be the function for which s(vi) = i −1; i.e.,
s(v1) = 0, s(v2) = 1, and so forth.
1. s( f f v3) = S(S(2)) = 4 and s( f v1) = S(0) = 1.
2. s(c) = 0 and s( f f c) = 2; no use is made of s.
3. |=A Pcf v1[s]. This is informally obvious, since when we
translate back into English we get the true sentence “0 ≤1.” More
formally, the reason is that
⟨s(c), s( f v1)⟩= ⟨0, 1⟩∈PA.
4. |=A ∀v1 Pcv1. The translation into English is “0 is less
than or equal to any natural number.” Formally we must verify
that for any n in N,
|=A Pcv1[s(v1 | n)],
which reduces to
⟨0, n⟩∈PA,
i.e., 0 ≤n.
5. ̸|=A ∀v1 Pv2v1[s] because there is a natural number m such
that
̸|=A Pv2v1[s(v1 | m)];
i.e.,
⟨s(v2), m⟩/∈PA.
In fact, since s(v2) = 1, we must take m to be 0.
The reader is to be cautioned against confusing, for example,
the function symbol f with the function f A.
EXAMPLE.
Previously we considered the structure B with
|B| = {a, b, c, d}
and
EB = {⟨a, b⟩, ⟨b, a⟩, ⟨b, c⟩, ⟨c, c⟩}
for the language with parameters ∀and E:
d
a
c
b

86
A Mathematical Introduction to Logic
Then |=B ∀v2 ¬ Ev2v1[s] iff s(v1) = d. That is, there is no
edge pointing to the vertex d, but d is the only such vertex. Tak-
ing the negation of the formula, we have |=B ∃v2 Ev2v1[s] iff
s(v1) ∈{a, b, c}.
At this point we pause to verify that when we want to know whether
or not a structure A satisﬁes a wff ϕ with s, we do not really need all
of the (inﬁnite amount of) information s gives us. All that matter are
the values of the function s at the (ﬁnitely many) variables which occur
free in ϕ. In particular, if ϕ is a sentence, then s does not matter at all.
THEOREM 22A
Assume that s1 and s2 are functions from V into |A|
which agree at all variables (if any) that occur free in the wff ϕ.
Then
|=A ϕ[s1]
iff
|=A ϕ[s2].
PROOF.
Because satisfaction was deﬁned recursively, this proof
uses induction. We consider the ﬁxed structure A and show by
induction that every wff ϕ has the property that whenever two
functions s1, s2 agree on the variables free in ϕ then A satisﬁes ϕ
with s1 iff it does so with s2.
Case 1: ϕ = Pt1 · · · tn is atomic. Then any variable in ϕ occurs
free. Thus s1 and s2 agree at all the variables in each ti. It follows
that s1(ti) = s2(ti) for each i; a detailed proof would use induction
on ti. Consequently, A satisﬁes Pt1 · · · tn with s1 iff it does so
with s2.
Cases 2 and 3: ϕ has the form ¬ α or α →β. These cases are
immediate from the inductive hypothesis.
Case 4: ϕ = ∀x ψ. Then the variables free in ϕ are those free
in ψ with the exception of x. Thus for any d in |A|, s1(x | d) and
s2(x | d) agree at all variables free in ψ. By inductive hypothesis,
then, A satisﬁes ψ with s1(x | d) iff it does so with s2(x | d). From
this and the deﬁnition of satisfaction we see that A satisﬁes ∀x ψ
with s1 iff it does so with s2.
⊣
In effect, the above proof amounts to looking through the deﬁnition
of satisfaction and seeing what information given by s was actually
used. There is an analogous fact regarding structures: If A and B agree
at all the parameters that occur in ϕ, then |=A ϕ[s] iff |=B ϕ[s].
This theorem justiﬁes the following notation: Suppose that ϕ is a
formula such that all variables occurring free in ϕ are included among
v1, . . . , vk. Then for elements a1, . . . , ak of |A|,
|=A ϕ[[a1, . . . , ak]]

Chapter 2:
First-Order Logic
87
means that A satisﬁes ϕ with some (and hence with any) function
s : V →|A| for which s(vi) = ai, 1 ≤i ≤k. To return to a recent
example where A = (N; ≤, S, 0), we have |=A ∀v2 Pv1v2[[0]] but
̸|=A ∀v2 Pv1v2[[5]].
COROLLARY 22B
For a sentence σ, either
(a) A satisﬁes σ with every function s from V into |A|, or
(b) A does not satisfy σ with any such function.
If alternative (a) holds, then we say that σ is true in A (written |=A σ)
or that A is a model of σ. And if alternative (b) holds, then of course
σ is false in A. (They cannot both hold since |A| is nonempty). A is a
model of a set  of sentences iff it is a model of every member of .
EXAMPLE.
If R is the real ﬁeld, (R; 0, 1, +, ×), and Q is the rational
ﬁeld, (Q; 0, 1, +, ×), is there a sentence true in one and false in
the other? Yes; because
√
2 is irrational, the sentence ∃x(x · x =
1 + 1) is false in the rational ﬁeld, but true in the real ﬁeld.
EXAMPLE.
Suppose our given language has only the parameters ∀
and P, where P is a two-place predicate symbol. Then a structure
A is determined by the universe |A| and the binary relation PA.
With some minor illegality we again write
A = (|A|; PA).
Now consider the problem of characterizing the class of all models
of the following sentences:
1. ∀x ∀y x = y. A structure (A; R) is a model of this iff A
contains exactly one element. R can either be empty or can be the
singleton A × A.
2. ∀x ∀y Pxy. A structure (A; R) is a model of this iff R =
A × A. A can be any nonempty set.
3. ∀x ∀y ¬ Pxy. A structure (A; R) is a model of this iff
R = ∅.
4. ∀x ∃y Pxy. The condition for (A; R) to be a model of this
is that the domain of R is A.
The notational conventions adopted earlier were done in a ra-
tional way:
1. |=A (α ∧β)[s] iff |=A α[s] and |=A β[s]; similarly for ∨
and ↔.
2. |=A ∃x α[s] iff there is some d ∈|A| with the property that
|=A α[s(x | d)].

88
A Mathematical Introduction to Logic
The proof for the second of these is as follows:
|=A ∃x α[s]
iff |=A ¬ ∀x ¬ α[s],
iff
̸|=A ∀x ¬ α[s],
iff it is not the case that for all d in |A|,
|=A ¬ α[s(x | d)],
iff it is not the case that for all d in |A|,
̸|=A α[s(x | d)],
iff for some d in |A|, |=A α[s(x | d)].
Logical Implication
We now have the necessary tools to formulate the important concept of
logical implication for our language.
DEFINITION.
Let  be a set of wffs, ϕ a wff. Then  logically implies
ϕ, written  |= ϕ, iff for every structure A for the language and
every function s : V →|A| such that A satisﬁes every member
of  with s, A also satisﬁes ϕ with s.
We use the same symbol, “|=,” that was used in Chapter 1 for tau-
tological implication. But henceforth it will be used solely for logical
implication. As before we will write “γ |= ϕ” in place of “{γ } |= ϕ.”
Say that ϕ and ψ are logically equivalent (ϕ |==| ψ) iff ϕ |= ψ and
ψ |= ϕ.
The ﬁrst-order analogue of the concept of a tautology is the concept
of a valid formula: A wff ϕ is valid iff ∅|= ϕ (written simply “|= ϕ”).
Thus ϕ is valid iff for every A and every s : V →|A|, A satisﬁes ϕ
with s.
For sentences, the concept of logical implication can be stated more
concisely, by applying Theorem 22A:
COROLLARY 22C
For a set ; τ of sentences,  |= τ iff every model
of  is also a model of τ. A sentence τ is valid iff it is true in
every structure.
EXAMPLES
of logical implication. Readers are invited to convince
themselves of each of the following:
1. ∀v1 Qv1 |= Qv2.
2. Qv1 ̸|= ∀v1 Qv1.
Hereitsufﬁcestoﬁndjustonestructure
A and just one function s : V →|A| such that on the one hand,
|=A Qv1[s] but, on the other hand, A is not a model of ∀v1 Qv1.
|A| will need to have at least two members.
3. |= ¬ ¬ σ →σ.
If A is a model of ¬ ¬ σ, then ̸|=A ¬ σ
whence |=A σ. But one might raise the objection: Aren’t we

Chapter 2:
First-Order Logic
89
using here the law of double negation, the law we are claiming
to prove? The answer is a deﬁnite yes and no. We are proving
the law of double negation for the formal language we are talking
about (sometimes called the object language). In doing so, we can
of course use any correct reasoning (out in the meta-language,
English), exactly as we might do in reasoning about vector spaces
or graphs. In particular, the reasoning might involve principles
that when formally modeled would involve ¬ ¬ σ and σ. There
is no circularity. But the meta-language sentences we use are —
unsurprisingly — related to the object language formulas we talk
about. In this connection, see the book’s only picture (at the end
of Section 2.4).
4. ∀v1 Qv1 |= ∃v2 Qv2.
Recall that the universe of any
structure is nonempty.
5. ∃x ∀y Pxy |= ∀y ∃x Pxy.
This example will come up
again in Section 2.4.
6. ∀y ∃x Pxy ̸|= ∃x ∀y Pxy.
7. |= ∃x(Qx →∀x Qx).
This is a strange — but valid —
sentence.
The deﬁnition of logical implication is very much like the deﬁnition
of tautological implication in Chapter 1. But there is an important dif-
ference of complexity. Suppose in sentential logic you want to know
whether or not a wff α is a tautology. The deﬁnition requires that you
consider ﬁnitely many truth assignments, each of which is a ﬁnite func-
tion. For each such truth assignment v, you must calculate v(α), which
can be effectively done in a ﬁnite length of time. (Consequently, the set
of tautologies is decidable, as was observed before.)
In contrast to the ﬁnitary procedure for tautologies, suppose that you
want to know whether or not a wff ϕ (of our ﬁrst-order language) is
valid. The deﬁnition requires that you consider every structure A. (In
particular this requires using every nonempty set, of which there are a
great many.) For each of these structures, you then must consider each
function s from the set V of variables into |A|. And for each given A
and s, you must determine whether or not A satisﬁes ϕ with s. When
|A| is inﬁnite, this is a complicated notion in itself.
In view of these complications, it is not surprising that the set of
valid formulas fails to be decidable (cf. Section 3.5). What is surpris-
ing is that the concept of validity turns out to be equivalent to another
concept (deducibility) whose deﬁnition is much closer to being ﬁni-
tary. (See Section 2.4.) Using that equivalence we will be able to show
(under some reasonable assumptions) that the set of validities (i.e., the
set of valid wffs) is effectively enumerable. The effective enumeration
procedure yields a more concrete characterization of the set of valid
formulas.

90
A Mathematical Introduction to Logic
Deﬁnability in a Structure
Suppose we want to study the real ﬁeld, (R; 0, 1, +, ·), consisting of the
set R of real numbers, together with the distinguished elements 0 and 1
and the two operations of addition and multiplication. We can consider
the real ﬁeld as a structure
R = (R; 0, 1, +, ·)
where the language (with equality) has constant symbols 0 and 1 and
two-place function symbols + and ·.
Although we have not included an ordering symbol < in the lan-
guage, we still have a way to say “x ≥0.” Because in this structure, the
nonnegative elements are exactly the elements with square roots. That
is, the formula ∃v2 x = v2 · v2 is satisﬁed in the structure R whenever
x is assigned a nonnegative number, and only then:
|=R ∃v2 v1 = v2 · v2 [[a]] ⇐⇒a ≥0.
Because of this fact, we will say that the interval [0, ∞) is deﬁnable in
R, and that the formula ∃v2 v1 = v2 · v2 deﬁnes it.
Moreover, the ordering relation on the reals, i.e., the binary relation
{⟨a, b⟩∈R × R | a ≤b},
is deﬁned in the structure R by the formula expressing “v1 ≤v2”:
∃v3 v2 = v1 + v3 · v3.
For a smaller example, take the directed graph
A = ({a, b, c}; {⟨a, b⟩, ⟨a, c⟩})
where the language has parameters ∀and E:
c
b
a
Then in A, the set {b, c} (the range of the relation EA) is deﬁned by the
formula ∃v2 Ev2v1. In contrast, the set {b} is not deﬁnable in A. This
is because there is no deﬁnable property in this structure that would
separate b and c; the proof of this fact will utilize the homomorphism
theorem, to be proved later in this section.
We now want to set forth precisely this concept of deﬁnability of
a subset of the universe or of a relation on the universe. Consider a
structure A and a formula ϕ whose free variables are among v1, . . . , vk.
Then we can construct the k-ary relation on |A|
{⟨a1, . . . , ak⟩| |=A ϕ[[a1, . . . , ak]]}.
Call this the k-ary relation ϕ deﬁnes in A. In general, a k-ary relation

Chapter 2:
First-Order Logic
91
on |A| is said to be deﬁnable in A iff there is a formula (whose free
variables are among v1, . . . , vk) that deﬁnes it there.
EXAMPLE.
Assume that we have a part of the language for number
theory, speciﬁcally that our language has the parameters ∀, 0, S,
+, and ·. Let N be the intended structure:
|N| = N, the set of natural numbers.
0N = 0, the number 0.
SN, +N, and ·N are S, +, and ·, the functions of successor,
addition, and multiplication.
In one equation,
N = (N; 0, S, +, ·).
Some relations on N are deﬁnable in N and some are not. One
way to show that some are not deﬁnable is to use the fact that
there are uncountably many relations on N but only countably
many possible deﬁning formulas. (There is, however, an inherent
difﬁculty in giving a speciﬁc example. After all, if something is
undeﬁnable, then it is hard to say exactly what it is! Later we
will get to see a speciﬁc example, the set of G¨odel numbers of
sentences true in N; see Section 3.5.)
1. The ordering relation {⟨m, n⟩| m < n} is deﬁned in N by
the formula
∃v3 v1 + Sv3 = v2.
2. For any natural number n, {n} is deﬁnable. For example, {2}
is deﬁned by the equation
v1 = SS0.
Because of this we say that n is a deﬁnable element in N.
3. ThesetofprimesisdeﬁnableinN.Wecouldusetheformula
1 < v1 ∧∀v2 ∀v3(v1 = v2 · v3 →v2 = 1 ∨v3 = 1)
if we had parameters 1 and < for 1 and <. But since {1} and <
are deﬁnable in N, it is really quite unnecessary to add parameters
for them; we can simply use their deﬁnitions instead. Thus the set
of primes is deﬁnable by
∃v3 S0 + Sv3 = v1 ∧∀v2 ∀v3 (v1 = v2 · v3→
v2 = S0 ∨v3 = S0).
4. Exponentiation, {⟨m, n, p⟩| p = mn} is also deﬁnable in
N. This is by no means obvious; we will give a proof later (in
Section 3.8) using the Chinese remainder theorem.

92
A Mathematical Introduction to Logic
Infact,wewillarguelaterthatanydecidablerelationonNisdeﬁnable
in N, as is any effectively enumerable relation and a great many others.
To some extent the complexity of a deﬁnable relation can be measured
by the complexity of the simplest deﬁning formula. This idea will come
up again at the end of Section 3.5.
Deﬁnability of a Class of Structures
Many a mathematics class, on its ﬁrst day, begins with the instructor
saying something like one of the following:
1. “A graph is deﬁned to consist of a nonempty set V together with
a set E such that. . . .”
2. “A group is deﬁned to consist of a nonempty set G together with
a binary operation ◦satisfying the axioms. . . .”
3. “Anorderedﬁeld isdeﬁnedtoconsistofanonemptyset F together
with two binary operations + and · and a binary relation < satisfying
the axioms. . . .”
4. “A vector space is deﬁned to consist of a nonempty set V together
with a binary operation + and, for each real number r, an operation
called scalar multiplication such that. . . .”
We want to abstract from this situation. In each case, the objects of
study (the graphs, the groups, and so forth) are structures for a suitable
language. Moreover, they are required to satisfy a certain set  of sen-
tences (referred to as “axioms”). The course in question then studies the
models of the set  of axioms — or at least some of the models.
For a set  of sentences, let Mod  be the class of all models of ,
i.e., the class of all structures for the language in which every member
of  is true. For a single sentence τ we write simply “Mod τ” instead
of “Mod {τ}.” (The reader familiar with axiomatic set theory will notice
that Mod , if nonempty, is a proper class; i.e., it is too large to be a set.)
A class K of structures for our language is an elementary class (EC)
iff K = Mod τ for some sentence τ. K is an elementary class in the
wider sense (EC) iff K = Mod  for some set  of sentences. (The
adjective “elementary” is employed as a synonym for “ﬁrst-order.”)
EXAMPLES
1. Assume that the language has equality and the two pa-
rameters ∀and E, where E is a two-place predicate symbol.
Then a graph is a structure for this language A = (V ; EA)
consisting of a nonempty set V of objects called vertices (or
nodes), and an edge relation EA that is symmetric (if uEAv then
vEAu) and irreﬂexive (never vEAv). The axiom stating that the
edge relation is symmetric and irreﬂexive can be translated by
the sentence

Chapter 2:
First-Order Logic
93
∀x(¬ x Ex ∧∀y(x Ey →yEx)).
So the class of all graphs is an elementary class. For directed
graphs or digraphs, the assumption of symmetry is dropped. And
if one wants to allow “loops” then the assumption of irreﬂexivity
is dropped. But perhaps the instructor then explains that the course
will study only ﬁnite graphs. Is the class of all ﬁnite graphs an
elementary class? No, we will prove later that it is not, not even
in the wider sense.
2. Assume that the language has equality and the parameters
∀and P, where P is a two-place predicate symbol. As before, a
structure (A; R) for the language consists of a nonempty set A
together with a binary relation R on A. (A; R) is called an ordered
set iff R is transitive and satisﬁes the trichotomy condition (which
states that for any a and b in A, exactly one of ⟨a, b⟩∈R, a = b,
⟨b, a⟩∈R holds). Because these conditions can be translated into
a sentence of the formal language, the class of nonempty ordered
sets is an elementary class. It is, in fact, Mod τ, where τ is the
conjunction of the three sentences
∀x ∀y ∀z(x Py →yPz →x Pz);
∀x ∀y(x Py ∨x = y ∨yPx);
∀x ∀y(x Py→¬yPx).
The next two examples assume that the reader has had some
contact with algebra.
3. Assume that the language has = and the parameters ∀and
◦, where ◦is a two-place function symbol. The class of all groups
is an elementary class, being the class of all models of the con-
junction of the group axioms:
∀x ∀y ∀z (x ◦y) ◦z = x ◦(y ◦z);
∀x ∀y ∃z x ◦z = y;
∀x ∀y ∃z z ◦x = y.
The class of all inﬁnite groups is EC. To see this, let
λ2 = ∃x ∃y x ̸= y,
λ3 = ∃x ∃y ∃z(x ̸= y ∧x ̸= z ∧y ̸= z),
. . . .
Thus λn translates, “There are at least n things.” Then the group
axioms together with {λ2, λ3, . . .} form a set  for which Mod 
is exactly the class of inﬁnite groups. We will eventually (in Sec-
tion 2.6) be able to show that the class of inﬁnite groups is not EC.
4. Assume that the language has equality and the parameters
∀, 0, 1, +, ·. Fields can be regarded as structures for this language.

94
A Mathematical Introduction to Logic
The class of all ﬁelds is an elementary class. The class of ﬁelds of
characteristic zero is EC. It is not EC, a fact which will follow
from the compactness theorem for ﬁrst-order logic (Section 2.6
again).
Homomorphisms1
In courses about graphs or groups or vector spaces, one usually encoun-
ters the concept of what it means for two of the structures in question, A
and B, to be isomorphic: Roughly speaking, there must be a one-to-one
correspondence between their universes |A| and |B| that “preserves”
the operations and relations.
It is then explained that two isomorphic structures, although not
identical, must have all the same mathematical properties. We want to
deﬁne here the isomorphism concept in a general setting, and to show
that two isomorphic structures must satisfy exactly the same sentences.
Let A, B be structures for the language. A homomorphism h of A
into B is a function h : |A| →|B| with the properties:
(a) Foreachn-placepredicateparameter P andeachn-tuple⟨a1, . . . ,
an⟩of elements of |A|,
⟨a1, . . . , an⟩∈PA
iff
⟨h(a1), . . . , h(an)⟩∈PB.
(b) For each n-place function symbol f and each such n-tuple,
h( f A(a1, . . . , an)) = f B(h(a1), . . . , h(an)).
In the case of a constant symbol c this becomes
h(cA) = cB.
Conditions (a) and (b) are usually stated: “h preserves the relations
and functions.” (It must be admitted that some authors use a weakened
version of condition (a); our homomorphisms are their “strong homo-
morphisms.”)
If, in addition, h is one-to-one, it is then called an isomorphism (or
an isomorphic embedding) of A into B. If there is an isomorphism of
A onto B (i.e., an isomorphism h for which ran h = |B|), then A and
B are said to be isomorphic (written A ∼= B).
The reader has quite possibly encountered this concept before in
special cases such as structures that are groups or ﬁelds.
1 This topic can be postponed somewhat. But homomorphisms will be used in the proof
of the completeness theorem (with equality). And we make use of the isomorphism
concept, starting in Section 6 of Chapter 2.

Chapter 2:
First-Order Logic
95
EXAMPLE.
Assume that we have a language with the parameters ∀,
+, and ·. Let A be the structure (N; +, ·). We can deﬁne a function
h : N →{e, o} by
h(n) =

e
if n is even,
o
if n is odd.
Then h is a homomorphism of A onto B, where |B| = {e, o} and
+B, ·B are given by the following tables:
+B
e
o
·B
e
o
e
e
o
e
e
e
o
o
e
o
e
o
It can then be veriﬁed that condition (b) of the deﬁnition is satis-
ﬁed.Forexample,ifa andb arebothoddnumbers,then h(a+b) =
e and h(a) +B h(b) = o +B o = e.
EXAMPLE.
Let P be the set of positive integers, let <P be the usual
ordering relation on P, and let <N be the usual ordering relation
on N. Then there is an isomorphism h from the structure (P; <P)
onto (N; <N); we take h(n) = n −1. Also the identity map
Id : P →N is an isomorphism of (P; <P) into (N; <N). Because
of this last fact, we say that (P; <P) is a substructure of (N; <N).
More generally consider two structures A and B for the language
such that |A| ⊆|B|. It is clear from the deﬁnition of homomorphism
that the identity map from |A| into |B| is an isomorphism of A into
B iff
(a) PA is the restriction of PB to |A|, for each predicate param-
eter P;
(b) f A is the restriction of f B to |A|, for each function symbol f ,
and cA = cB for each constant symbol c.
If these conditions are met, then A is said to be a substructure of B,
and B is an extension of A.
For example, in a language with a two-place function symbol +, the
structure (Q; +Q) is a substructure of (C; +C). Here +C is the addition
operation on complex numbers. And +Q, addition on the rationals, is
exactly the restriction of +C to the set Q.
In this example, the set Q is closed under +C; that is, the sum of two
rational numbers is rational. More generally, whenever A is a substruc-
ture of B, then |A| must be closed under f B for every function symbol
f . After all, f B(⃗a) (where ⃗a ∈|A|n) is nothing but f A(⃗a), which must
be some element in |A|. This closure property even holds for the 0-place
function symbols; cB must belong to |A| for each constant symbol c.

96
A Mathematical Introduction to Logic
Conversely, suppose we have a structure B, and let A be any non-
empty subset of |B| that is closed under all of B’s functions, as in
the preceding paragraph. Then we can make a substructure of B with
universe A. In fact there is only one way to do this. The universe is A,
each predicate parameter P is assigned the restriction of PB to A, and
similarly for the function symbols. As an extreme case, if the language
has no function symbols at all (not even constant symbols), then we can
make a substructure out of any nonempty subset A of |B|.
These are basically algebraic concepts, but the following theorem
relates them to the logical concepts of truth and satisfaction.
HOMOMORPHISM THEOREM
Let h be a homomorphism of A into B,
and let s map the set of variables into |A|.
(a) For any term t, we have h(s(t)) = h ◦s(t), where s(t) is
computed in A and h ◦s(t) is computed in B.
(b) For any quantiﬁer-free formula α not containing the equal-
ity symbol,
|=A α[s]
iff
|=B α[h◦s].
(c) If h is one-to-one (i.e., is an isomorphism of A into B),
then in part (b) we may delete the restriction “not containing the
equality symbol.”
(d) If h is a homomorphism of A onto B, then in (b) we may
delete the restriction “quantiﬁer-free.”
PROOF.
Part (a) uses induction on t; see Exercise 13. Note that h ◦s
maps the set of variables into |B|; its extension to the set of all
terms is h ◦s. It is h ◦s that is here being evaluated at t.
(b) For an atomic formula such as Pt, we have
|=A Pt[s] ⇔s(t) ∈PA
⇔h(s(t)) ∈PB
since h is a homomorphism
⇔h ◦s(t) ∈PB
by (a)
⇔|=B Pt[h ◦s].
An inductive argument is then required to handle the connective
symbols ¬ and →, but it is completely routine.
(c) In any case,
|=A u = t[s] ⇔s(u) = s(t)
⇒h(s(u)) = h(s(t))
⇔h ◦s(u) = h ◦s(t)
by (a)
⇔|=B u = t[h ◦s].
If h is one-to-one, the arrow in the second step can be reversed.
(d) We must extend the routine inductive argument of part (b)
to include the quantiﬁer step. That is, we must show that if ϕ has

Chapter 2:
First-Order Logic
97
the property that for every s,
|=A ϕ[s] ⇔|=B ϕ[h ◦s],
then ∀x ϕ enjoys the same property. We have in any case (as a
consequence of the inductive hypothesis on ϕ) the implication
|=B ∀x ϕ[h ◦s] ⇒|=A ∀x ϕ[s].
This is intuitively very plausible; if ϕ is true of everything in the
larger set |B|, then a fortiori it is true of everything in the smaller
set ran h. The details are, for an element a of |A|,
|=B ∀x ϕ[h ◦s]⇒|=B ϕ[(h ◦s)(x | h(a))]
⇔|=B ϕ[h ◦(s(x | a))],
the functions
being the same
⇔|=A ϕ[s(x | a)]
by the inductive
hypothesis.
Now for the converse, suppose that ̸|=B ∀x ϕ[h ◦s], so that
|=B ¬ ϕ[(h ◦s)(x | b)] for some element b in |B|. We need the
implication
If for some b in |B|, |=B ¬ ϕ[(h ◦s)(x | b)], then for
(∗)
some a in |A|, |=B ¬ ϕ[(h ◦s)(s | h(a))].
For given (∗), we can proceed:
|=B ¬ ϕ[(h ◦s)(x | h(a))] ⇔|=B ¬ ϕ[h ◦(s(x | a))],
the functions
being the same
⇔|=A ¬ ϕ[s(x | a)]
by the inductive
hypothesis
⇏|=A ∀x ϕ[s].
If h maps |A| onto |B|, then (∗) is immediate; we take a such that
b = h(a). (But there might be other fortunate times when (∗) can
be asserted even if h fails to have range |B|.)
⊣
Two structures A and B for the language are said to be elementarily
equivalent (written A ≡B) iff for any sentence σ,
|=A σ ⇔|=B σ.
COROLLARY 22D
Isomorphicstructuresareelementarilyequivalent:
A ∼= B ⇒A ≡B
Actually more is true. Isomorphic structures are alike in every “struc-
tural” way; not only do they satisfy the same ﬁrst-order sentences, they
also satisfy the same second-order (and higher) sentences (i.e., they are
secondarily equivalent and more).
There are elementarily equivalent structures that are not isomorphic.
For example, it can be shown that the structure (R; <R) consisting of
the set of real numbers with its usual ordering relation is elementarily

98
A Mathematical Introduction to Logic
equivalent to the structure (Q; <Q) consisting of the set of rational
numbers with its ordering (see Section 2.6). But Q is a countable set
whereasRisnot,sothesestructurescannotbeisomorphic.InSection2.6
we will see how easy it is to make elementarily equivalent structures of
differing cardinalities.
EXAMPLE, revisited.
We had an isomorphism h from (P; <P) onto
(N; <N). So in particular, (P; <P) ≡(N; <N); these structures
are indistinguishable by ﬁrst-order sentences.
We furthermore noted that the identity map was an isomor-
phic embedding of (P; <P) into (N; <N). Hence for a function s:
V →P and a quantiﬁer-free ϕ,
|=(P;<P) ϕ[s] ⇔|=(N;<N ) ϕ[s].
This equivalence may fail if ϕ contains quantiﬁers. For example,
|=(P;<P) ∀v2(v1 ̸= v2 →v1 < v2)[[1]],
but
̸|=(N;<N ) ∀v2(v1 ̸= v2 →v1 < v2)[[1]].
An automorphism of the structure A is an isomorphism of A onto
A. The identity function on |A| is trivially an automorphism of A. A
may or may not have nontrivial automorphisms. (We say that A is rigid
if the identity function is its only automorphism.) As a consequence of
the homomorphism theorem, we can show that an automorphism must
preserve the deﬁnable relations:
COROLLARY 22E
Let h be an automorphism of the structure A, and
let R be an n-ary relation on |A| deﬁnable in A. Then for any
a1, . . . , an in |A|,
⟨a1, . . . , an⟩∈R ⇔⟨h(a1), . . . , h(an)⟩∈R.
PROOF.
Let ϕ be a formula that deﬁnes R in A. We need to know
that
|=A ϕ[[a1, . . . , an]] ⇔|=A ϕ[[h(a1), . . . , h(an)]].
But this is immediate from the homomorphism theorem.
⊣
This corollary is sometimes useful in showing that a given relation
is not deﬁnable. Consider, for example, the structure (R; <) consisting
of the set of real numbers with its usual ordering. An automorphism
of this structure is simply a function h from R onto R that is strictly
increasing:
a < b ⇔h(a) < h(b).

Chapter 2:
First-Order Logic
99
One such automorphism is the function h for which h(a) = a3. Since
this function maps points outside of N into N, the set N is not deﬁnable
in this structure.
Another example is provided by elementary algebra books, which
sometimes explain that the length of a vector in the plane cannot be
deﬁned in terms of vector addition and scalar multiplication. For the
map that takes a vector x into the vector 2x is an automorphism of the
plane with respect to vector addition and scalar multiplication, but it is
not length-preserving. From our viewpoint, the structure in question,
(E; +, fr)r∈R,
has for its universe the plane E, has the binary operation + of vector
addition, and has (for each r in the set R) the unary operation fr of scalar
multiplication by r. (Thus the language in question has a one-place
function symbol for each real number.) The doubling map described
above is an automorphism of this structure. But it does not preserve the
set of unit vectors,
{x | x ∈E and x has length 1}.
So this set cannot be deﬁnable in the structure. (Incidentally, the homo-
morphisms of vector spaces are called linear transformations.)
Exercises
1. Show that (a) ; α |= ϕ iff  |= (α →ϕ); and (b) ϕ |==| ψ iff
|= (ϕ ↔ψ).
2. Show that no one of the following sentences is logically implied
by the other two. (This is done by giving a structure in which the
sentence in question is false, while the other two are true.)
(a) ∀x ∀y ∀z(Pxy →Pyz →Pxz). Recall that by our conven-
tion α →β →γ is α →(β →γ ).
(b) ∀x ∀y(Pxy →Pyx →x = y).
(c) ∀x ∃y Pxy →∃y ∀x Pxy.
3. Show that
{∀x(α →β), ∀x α} |= ∀x β.
4. Show that if x does not occur free in α, then α |= ∀x α.
5. Show that the formula x = y →Pzf x →Pzf y (where f is a
one-place function symbol and P is a two-place predicate symbol)
is valid.
6. Show that a formula θ is valid iff ∀x θ is valid.
7. Restate the deﬁnition of “A satisﬁes ϕ with s” in the way described

100
A Mathematical Introduction to Logic
on page 84. That is, deﬁne by recursion a function h such that A
satisﬁes ϕ with s iff s ∈h(ϕ).
8. Assume that  is a set of sentences such that for any sentence τ,
either  |= τ or  |= ¬ τ. Assume that A is a model of . Show
that for any sentence τ, we have |=A τ iff  |= τ.
9. Assume that the language has equality and a two-place predicate
symbol P. For each of the following conditions, ﬁnd a sentence σ
such that the structure A is a model of σ iff the condition is met.
(a) |A| has exactly two members.
(b) PA is a function from |A| into |A|. (A function is a single-valued
relation, as in Chapter 0. For f to be a function from A into B,
the domain of f must be all of A; the range of f is a subset,
not necessarily proper, of B.)
(c) PA is a permutation of |A|; i.e., PA is a one-to-one function
with domain and range equal to |A|.
10. Show that
|=A ∀v2 Qv1v2[[cA]]
iff
|=A ∀v2 Qcv2.
Here Q is a two-place predicate symbol and c is a constant symbol.
11. For each of the following relations, give a formula which deﬁnes
it in (N; +, ·). (The language is assumed to have equality and the
parameters ∀, +, and ·).
(a) {0}.
(b) {1}.
(c) {⟨m, n⟩| n is the successor of m in N}.
(d) {⟨m, n⟩| m < n in N}.
Digression: This is merely the tip of the iceberg. A relation on
N is said to be arithmetical if it is deﬁnable in this structure.
All decidable relations are arithmetical, as are many others.
The arithmetical relations can be arranged in a hierarchy; see
Section 3.5.
12. Let R be the structure (R; +, ·). (The language is assumed to have
equality and the parameters ∀, +, and ·. R is the structure whose
universe is the set R of real numbers and such that +R and ·R are
the usual addition and multiplication operations.)
(a) Give a formula that deﬁnes in R the interval [0, ∞).
(b) Give a formula that deﬁnes in R the set {2}.
∗(c) Show that any ﬁnite union of intervals, the endpoints of which
are algebraic, is deﬁnable in R. (The converse is also true; these
are the only deﬁnable sets in the structure. But we will not prove
this fact.)
13. Prove part (a) of the homomorphism theorem.

Chapter 2:
First-Order Logic
101
14. WhatsubsetsofthereallineRaredeﬁnablein(R; <)?Whatsubsets
of the plane R × R are deﬁnable in (R; <)?
Remarks: The nice thing about (R; <) is that its automorphisms
are exactly the order-preserving maps from R onto itself. But stop
after the binary relations. There are 213 deﬁnable ternary relations,
so you do not want to catalog all of them.
15. Show that the addition relation, {⟨m, n, p⟩| p = m + n}, is not
deﬁnable in (N; ·). Suggestion: Consider an automorphism of (N; ·)
that switches two primes.
Digression: Algebraically, the structure of the natural numbers
with multiplication is nothing but the free Abelian semigroup with
ℵ0 generators (viz. the primes), together with a zero element. There
is no way you could deﬁne addition here. If you could deﬁne addi-
tion, then you could deﬁne ordering (by Exercise 11 and the natural
transitivity statement). But one generator looks just like another.
That is, there are 2ℵ0 automorphisms — simply permute the primes.
None of them is order-preserving except the identity.
16. Give a sentence having models of size 2n for every positive inte-
ger n, but no ﬁnite models of odd size. (Here the language should
include equality and will have whatever parameters you choose.)
Suggestion: One method is to make a sentence that says, “Every-
thing is either red or blue, and f is a color-reversing permutation.”
Remark: Given a sentence σ, it might have some ﬁnite models
(i.e., models with ﬁnite universes). Deﬁne the spectrum of σ to be
the set of positive integers n such that σ has a model of size n. This
exercise shows that the set of even numbers is a spectrum.
For example if σ is the conjunction of the ﬁeld axioms (there
are only ﬁnitely many, so we can take their conjunction), then its
spectrum is the set of powers of primes. This fact is proved in any
course on ﬁnite ﬁelds. The spectrum of ¬ σ, by contrast, is the set
of all positive integers (non-ﬁelds come in all sizes).
G¨unter Asser in 1955 raised the question: Is the complement of
every spectrum a spectrum? Once you realize that simply taking
a negation does not work (cf. the preceding paragraph), you see
that this is a nontrivial question. In fact the problem, known as the
spectrum problem, is still open. But modern work has tied it to
another open problem, whether or not co-NP = NP.
17. (a) Consider a language with equality whose only parameter (aside
from ∀) is a two-place predicate symbol P. Show that if A is
ﬁnite and A ≡B, then A is isomorphic to B. Suggestion:
Suppose the universe of A has size n. Make a single sentence σ
of the form ∃v1 · · · ∃vn θ that describes A “completely.” That
is, on the one hand, σ must be true in A. And on the other hand,
any model of σ must be exactly like (i.e., isomorphic to) A.

102
A Mathematical Introduction to Logic
∗(b) Show that the result of part (a) holds regardless of what param-
eters the language contains.
18. A universal (∀1) formula is one of the form ∀x1 · · · ∀xn θ, where
θ is quantiﬁer-free. An existential (∃1) formula is of the dual form
∃x1 · · · ∃xn θ. Let A be a substructure of B, and let s : V →|A|.
(a) Show that if |=A ψ[s] and ψ is existential, then |=B ψ[s]. And
if |=B ϕ[s] and ϕ is universal, then |=A ϕ[s].
(b) Conclude that the sentence ∃x Px is not logically equivalent to
any universal sentence, nor ∀x Px to any existential sentence.
Remark: Part (a) says (when ϕ is a sentence) that any univer-
sal sentenceis“preserved under substructures.”Being universal
is a syntactic property — it has to do with the string of symbols.
In contrast, being preserved under substructures is a semantic
property — it has to do with satisfaction in structures. But this
semantic property captures the syntactic property up to logical
equivalence (which is all one could ask for). That is, if σ is a
sentence that is always preserved under substructures, then σ
is logically equivalent to a universal sentence. (This fact is due
to Ło´s and Tarski.)
19. An ∃2 formula is one of the form ∃x1 · · · ∃xn θ, where θ is
universal.
(a) Show that if an ∃2 sentence in a language not containing func-
tion symbols (not even constant symbols) is true in A, then it
is true in some ﬁnite substructure of A.
(b) Conclude that ∀x ∃y Pxy is not logically equivalent to any ∃2
sentence.
20. Assume the language has equality and a two-place predicate symbol
P. Consider the two structures (N; <) and (R; <) for the language.
(a) Find a sentence true in one structure and false in the other.
∗(b) Show that any ∃2 sentence (as deﬁned in the preceding exer-
cise) true in (R; <) is also true in (N; <). Suggestion: First,
for any ﬁnite set of real numbers, there is an automorphism
of (R; <) taking those real numbers to natural numbers. Sec-
ondly, by Exercise 18, universal formulas are preserved under
substructures.
21. We could consider enriching the language by the addition of a new
quantiﬁer. The formula ∃!x α (read “there exists a unique x such
that α”) is to be satisﬁed in A by s iff there is one and only one
a ∈|A| such that |=A α[s(x | a)]. Assume that the language has the
equality symbol and show that this apparent enrichment comes to
naught, in the sense that we can ﬁnd an ordinary formula logically
equivalent to ∃!x α.
22. Assume that A is a structure and h is a function with ran h = |A|.

Chapter 2:
First-Order Logic
103
Show that there is a structure B such that h is a homomorphism of
B onto A. Suggestion: We need to take |B| = dom h. In general,
the axiom of choice will be needed to deﬁne the functions in B,
unless h is one-to-one.
Remark: The result yields an “upward L¨owenheim–Skolem the-
orem without equality” (cf. Section 2.6). That is, any structure A
has an extension to a structure B of any higher cardinality such that
A and B are elementarily equivalent, except for equality. There is
nothing deep about this. Not until you add equality.
23. Let A be a structure and g a one-to-one function with dom g = |A|.
Show that there is a unique structure B such that g is an isomor-
phism of A onto B.
24. Let h be an isomorphic embedding of A into B. Show that there is
a structure C isomorphic to B such that A is a substructure of C.
Suggestion: Let g be a one-to-one function with domain |B| such
that g(h(a)) = a for a ∈|A|. Form C such that g is an isomorphism
of B onto C.
Remark: The result stated in this exercise should not seem sur-
prising. On the contrary, it is one of those statements that is obvious
until you have to prove it. It says that if you can embed A isomor-
phically into B, then for all practical purposes you can pretend A
is a substructure of B.
25. Consider a ﬁxed structure A. Expand the language by adding a
new constant symbol ca for each a ∈|A|. Let A+ be the struc-
ture for this expanded language that agrees with A on the original
parameters and that assigns to ca the point a. A relation R on
|A| is said to be deﬁnable from points in A iff R is deﬁnable in
A+. (This differs from ordinary deﬁnability only in that we now
have parameters in the language for members of |A|.) Let R =
(R; <, +, ·).
(a) Show that if A is a subset of R consisting of the union of ﬁnitely
many intervals, then A is deﬁnable from points in R (cf. Exer-
cise 12).
(b) Assume that A ≡R. Show that any subset of |A| that is non-
empty, bounded (in the ordering <A), and deﬁnable from points
in A has a least upper bound in |A|.
Digression: Often when people speak of deﬁnability within a
structure, this is the concept they mean. The more standard phrase
is “deﬁnable from parameters”; here “points” is used because the
word “parameter” is used in a different sense in this chapter.
The real ordered ﬁeld can be characterized up to isomorphism
by saying that it is a complete ordered ﬁeld. (This fact should
be included in any analysis course.) But completeness (i.e., that
nonempty bounded sets have least upper bounds) is not a ﬁrst-

104
A Mathematical Introduction to Logic
order property. See Example 4 in Section 4.1 for its second-order
statement. The ﬁrst-order “image” of completeness is given by the
schema obtained from that second-order statement by replacing X
by a ﬁrst-order formula ϕ. The resulting schema (i.e., the set of
sentences you get by letting ϕ vary and taking universal closure)
says that the least-upper-bound property holds for the sets that are
deﬁnable from points. Ordered ﬁelds satisfying those sentences are
called “real closed-ordered ﬁelds.”
The surprising fact is that such ﬁelds were not invented by logi-
cians. They were previously studied by algebraists and you can read
about them in van der Waerden’s Modern Algebra book (volume I).
Of course, he uses a characterization of them that does not involve
logic.
What Tarski showed is that any real closed-ordered ﬁeld is el-
ementarily equivalent to the ﬁeld of real numbers. From this it
follows that the theory of the real-ordered ﬁeld is decidable.
26. (a) Consider a ﬁxed structure A and deﬁne its elementary type to
be the class of structures elementarily equivalent to A. Show
that this class is EC. Suggestion: Show it is Mod Th A.
(b) Call a class K of structures elementarily closed or ECL if when-
ever a structure belongs to K then all elementarily equivalent
structures also belong. Show that any such class is a union of
EC classes. (A class that is a union of EC classes is said to
be an EC class; this notation is derived from topology.)
(c) Conversely, show that any class that is the union of EC classes
is elementarily closed.
27. Assume that the parameters of the language are ∀and a two-place
predicate symbol P. List all of the non-isomorphic structures of
size 2. That is, give a list of structures (where the universe of each
has size 2) such that any structure of size 2 is isomorphic to exactly
one structure on the list.
28. For each of the following pairs of structures, show that they are
not elementarily equivalent, by giving a sentence true in one and
false in the other. (The language here contains ∀and a two-place
function symbol ◦.)
(a) (R; ×) and (R∗; ×∗), where × is the usual multiplication op-
eration on the real numbers, R∗is the set of non-zero reals, and
×∗is × restricted to the non-zero reals.
(b) (N; +) and (P; +∗), where P is the set of positive integers, and
+∗is usual addition operation restricted to P.
(c) Better yet, for each of the four structures of parts (a) and (b),
give a sentence true in that structure and false in the other
three.

Chapter 2:
First-Order Logic
105
SECTION 2.3
A Parsing Algorithm1
As in sentential logic, we need to know that we can decompose formulas
(and terms) in a unique way, discovering how they are built up. The
uniqueness is necessary to justify our deﬁnitions by recursion, such as
the deﬁnition of satisfaction in the preceding section.
For terms we used Polish notation; for formulas we relied on paren-
theses. Accordingly, we ﬁrst consider a decomposition procedure for
terms, showing unique readability. And then we extend the methods to
cover the formulas.
Recall that the terms are built up from the variables and constant
symbols by operations corresponding to the function symbols. We now
deﬁne a function K on the symbols involved such that for a symbol s,
K(s) = 1 −n, where n is the number of terms that must follow s to
obtain a term:
K(x) = 1 −0 = 1
for a variable x;
K(c) = 1 −0 = 1
for a constant symbol c;
K( f ) = 1 −n
for an n-place function symbol f.
We then extend K to the set of expressions using these symbols by
deﬁning
K(s1s2 · · · sn) = K(s1) + K(s2) + · · · + K(sn).
Since no symbol is a ﬁnite sequence of others, this deﬁnition is unam-
biguous.
LEMMA 23A
For any term t, K(t) = 1.
PROOF.
Use induction on t. The inductive step, for an n-place func-
tion symbol f , is
K( f t1 · · · tn) = (1 −n) + (1 + · · · + 1

	

n times
) = 1.
⊣
In fact, K was chosen to be the unique function on these symbols
for which Lemma 23A holds. It follows from this lemma that if ε is a
concatenation of m terms, then K(ε) = m.
By a terminal segment of a string ⟨s1, . . . , sn⟩of symbols we mean
a sequence of the form ⟨sk, sk+1, . . . , sn⟩, where 1 ≤k ≤n.
LEMMA 23B
Any terminal segment of a term is a concatenation of
one or more terms.
1 This section may be omitted by a reader willing to accept the meaningfulness of our
many deﬁnitions by recursion.

106
A Mathematical Introduction to Logic
PROOF.
We use induction on the term. For a one-symbol term (i.e.,
a variable or a constant symbol) the conclusion follows trivially.
For a term f t1 · · · tn, any terminal segment (other than the term
itself) must equal
t′
ktk+1 · · · tn,
where k ≤n and t′
k is a terminal segment of tk. By the inductive
hypothesis t′
k is a concatenation of, say, m terms, where m ≥1.
So altogether we have m + (n −k) terms.
⊣
COROLLARY 23C
No proper initial segment of a term is itself a term.
If t1 is a proper initial segment of a term t, then K(t1) < 1.
PROOF.
Suppose a term t is divided into a proper initial segment t1
and a terminal segment t2. Then 1 = K(t) = K(t1) + K(t2), and
by Lemma 23B, K(t2) ≥1. Hence K(t1) < 1 and t1 cannot be
a term.
⊣
Parsing Terms
We want an algorithm that, given an expression, will determine whether
or not the expression is a legal term, and if it is, will construct the unique
tree showing how the term is built up.
Assume then that we are given an expression. We will construct a
tree, with the given expression at the top (i.e., the root). Initially it is
the only vertex in the tree, but as the procedure progresses, the tree will
grow downward.
The algorithm consist of the following two steps.
1. If each minimal vertex (at the bottom) has a single symbol (which
must∗be a variable or a constant symbol), then the procedure is com-
pleted. (The given expression is indeed a term, and we have constructed
its tree.) Otherwise, select a minimal vertex having an expression with
two or more symbols. We examine that expression.
2. The ﬁrst symbol must* be an n-place function symbol, say f ,
where n > 0. We extend the tree downward by creating n new vertices
belowthepresentone.Scantheexpressionafterthe f ,untilﬁrstreaching
a string t (of variables, constant symbols, and function symbols) with
K(t) = 1.∗∗Then t is the expression that goes at the leftmost unlabeled
new vertex. Repeat with the remainder of the expression, until all n new
vertices have been labeled, and the expression has been exhausted.**
Return to step 1.
∗If not, then the expression here is not a term. We reject the given expression as a
non-term, and halt.
∗∗If the end of the expression is reached before ﬁnding such an t, then the expression here
is not a term. We reject the given expression as a non-term, and halt.

Chapter 2:
First-Order Logic
107
As in Section 1.3, the crucial point is that the tree could not have
been made differently. In step 2, we selected the ﬁrst string t we found
with K(t) = 1. We could not have used less than t (because we needed
K(t) = 1 by Lemma 23A). We could not have used more than t (because
that longer string would have the proper initial segment t with K(t) = 1,
contradicting Corollary 23C). The choice of t was the only possible
choice.
When the algorithm halts, either it has rejected the given expression
as a non-term, or it has constructed the one tree demonstrating that the
given expression is a legal tree.
We can rephrase the uniqueness in the terminology of Section 1.4 as
follows:
UNIQUE READABILITY THEOREM FOR TERMS
The set of terms is freely
generated from the set of variables and constant symbols by the
F f operations.
PROOF.
First, it is clear that iff f ̸= g, then ran F f is disjoint from
ran Fg; this requires checking only the ﬁrst symbol. Furthermore,
both ranges are disjoint from the set of variables and constant
symbols. It remains only to show that F f , when restricted to
terms, is one-to-one. Suppose, for a two-place f , we have
f t1t2 = f t3t4.
By deleting the ﬁrst symbol we are left with
t1t2 = t3t4.
If t1 ̸= t3, then one would be a proper initial segment of the other,
which is impossible for terms by Corollary 23C. So t1 = t3, and
we are then left with t2 = t4.
⊣
Parsing Formulas
To extend this argument to formulas, we now deﬁne K on the other
symbols:
K(() = −1;
K()) = 1;
K(∀) = −1;
K(¬) = 0;
K(→) = −1;
K(P) = 1 −n
for an n-place predicate symbol P;
K(=) = −1.
The idea behind the deﬁnition is again that K(s) should be 1 −n, where
n is the number of things (right parentheses, terms, or formulas) required
to go after s. We extend K as usual to the set of all expressions:
K(s1 · · · sn) = K(s1) + · · · + K(sn).

108
A Mathematical Introduction to Logic
LEMMA 23D
For any wff α, K(α) = 1.
PROOF.
Another straightforward induction.
⊣
LEMMA 23E
For any proper initial segment α′ of a wff α, K(α′) < 1.
PROOF.
Use induction on α. The details are left to Exercise 1.
⊣
COROLLARY 23F
No proper initial segment of a formula is itself a
formula.
Armed with these facts, we can proceed as in Section 1.3. Instead of
sentence symbols at the minimal vertices, we now have atomic formulas
(which are distinguished by having ﬁrst an n-place predicate symbol,
followed by n terms).
A wff that is non-atomic must begin either with ∀vi or with (. In
the former case we have one new vertex; in the latter case we need to
examine the next symbol to see if it is ¬. If not, then we can either count
parentheses or use the K function — both methods work — to ﬁnd the
correct split.
Again, the uniqueness can be phrased in the terminology of Sec-
tion 1.4 as follows:
UNIQUE READABILITY THEOREM FOR FORMULAS
Thesetofwffsisfreely
generated from the set of atomic formulas by the operations
E¬, E→, and Qi (i = 1, 2, . . .).
PROOF.
The unary operations E¬ and Qi are obviously one-to-one.
As in Section 1.4, we can show that the restriction of E→to wffs
is one-to-one.
The disjointness half of the theorem follows from the ad hoc
observations:
1. ran E¬, ran Qi, ran Q j, and the set of atomic formulas are
pairwise disjoint, for i ̸= j. (Just look at the ﬁrst two symbols.)
2. ran E→, ran Qi, ran Q j, and the set of atomic formulas are
similarly pairwise disjoint, for i ̸= j.
3. For a wff β, ( ¬ α) ̸= (β →γ ), because no wff begins
with ¬. Hence ran E¬ is disjoint from the range of the restriction
of E→to wffs.
⊣
Exercises
1. Show that for a proper initial segment α′ of a wff α, we have
K(α′) < 1.
2. Let ε be an expression consisting of variables, constant symbols, and
function symbols. Show that ε is a term iff K(ε) = 1 and for every
terminal segment ε′ of ε we have K(ε′) > 0. Suggestion: Prove the

Chapter 2:
First-Order Logic
109
stronger result that if K(ε′) > 0 for every terminal segment ε′ of ε,
then ε is a concatenation of K(ε) terms. (This algorithm is due to
J´askowski.)
SECTION 2.4
A Deductive Calculus
Suppose that  |= τ. What methods of proof might be required to
demonstrate that fact? Is there necessarily a proof at all?
Such questions lead immediately to considerations of what consti-
tutes a proof. A proof is an argument that you give to someone else
and that completely convinces that person of the correctness of your
assertion (in this case, that  |= τ).
Thus a proof should be ﬁnitely long, as you cannot give all of an
inﬁnite object to another person. If the set  of hypotheses is inﬁnite,
they cannot all be used. But the compactness theorem for ﬁrst-order
logic (which we will prove in Section 2.5 using the deductive calculus
of this section) will ensure the existence of a ﬁnite 0 ⊆ such that
0 |= τ.
Another essential feature of a proof (besides its being ﬁnite in length)
is that it must be possible for someone else (if that person is to be
convinced by it) to check the proof to ascertain that it contains no fal-
lacies. This check must be effective; it must be the sort of thing that
can be carried out without brilliant ﬂashes of insight on the part of
the checker. In particular, the set of proofs from the empty set of hy-
potheses (i.e., proofs that |= τ) should be decidable. This implies that
the set of formulas provable without hypotheses must be effectively
enumerable. For one could in principle enumerate provable sentences
by generating all strings of symbols and sorting out the proofs from
the nonproofs. When a proof is discovered, its last line is entered on
the output list. (This issue will be examined more carefully at the end
of Section 2.5.) But here again there is a theorem (the enumerability
theorem, proved in Section 2.5) stating that, under reasonable condi-
tions, the validities — the set of valid formulas — is indeed effectively
enumerable.
Thus the compactness theorem and the enumerability theorem are
necessary conditions for satisfactory proofs of logical implication al-
ways to exist. Conversely, we claim that these two theorems are sufﬁ-
cient for proofs (of some sort) to exist. For suppose that  |= τ. By
the compactness theorem, then, there is a ﬁnite set {σ0, . . . , σn} ⊆
that logically implies τ. Then σ0 →· · · →σn →τ is valid (Exercise 1,
Section 2.2). So to demonstrate conclusively that  |= τ one need only
carry out a ﬁnite number of steps in the enumeration of the validities

110
A Mathematical Introduction to Logic
until σ0 →· · · →σn →τ appears, and then verify that each σi ∈.
(This should be compared with the complex procedure suggested by the
original deﬁnition of logical implication, discussed in Section 2.2.) The
record of the enumeration procedure that produced σ0 →· · ·→σn →τ
can then be regarded as a proof that  |= τ. As a proof, it should be
acceptable to anyone who accepts the correctness of your procedure for
enumerating validities.
Against the foregoing general (and slightly vague) discussion, the
outline of this section can be described as follows: We will introduce
formal proofs but we will call them deductions, to avoid confusion
with our English-language proofs. These will mirror (in our model of
deductive thought) the proofs made by the working mathematician to
convince his or her colleagues of certain truths. Then in Section 2.5 we
will show that whenever  |= τ, there is a deduction of τ from  (and
only then). This will, as is suggested by the foregoing discussion, yield
proofs of the compactness theorem and the enumerability theorem. And
in the process we will get to see what methods of deduction are adequate
to demonstrate that a given sentence, is, in fact, logically implied by
certain others. In other words, our goal is to produce a mathematically
precise concept of deduction that, in the context of ﬁrst-order logic, is
adequate and correct.
Formal Deductions
We will shortly select an inﬁnite set  of formulas to be called logical
axioms. And we will have a rule of inference, which will enable us to
obtain a new formula from certain others. Then for a set  of formulas,
the theorems of  will be the formulas which can be obtained from
 ∪ by use of the rule of inference (some ﬁnite number of times). If
ϕ is a theorem of  (written  ⊢ϕ), then a sequence of formulas that
records (as explained below) how ϕ was obtained from  ∪ with the
rule of inference will be called a deduction of ϕ from .
The choice of  and the choice of the rule (or rules) of inference
are far from unique. In this section we are presenting one deductive
calculus for ﬁrst-order logic, chosen from the array of possible calculi.
(For example, one can have  = ∅by using many rules of inference.
We will take the opposite extreme; our set  will be inﬁnite but we will
have only one rule of inference.)
Our one rule of inference is traditionally known as modus ponens. It
is usually stated: From the formulas α and α →β we may infer β:
α, α →β
β
.
Thus the theorems of a set  are the formulas obtainable from  ∪
by use of modus ponens some ﬁnite number of times.

Chapter 2:
First-Order Logic
111
DEFINITION.
Adeductionofϕ from isaﬁnitesequence⟨α0, . . . , αn⟩
of formulas such that αn is ϕ and for each k ≤n, either
(a) αk is in  ∪, or
(b) αk is obtained by modus ponens from two earlier formulas
in the sequence; that is, for some i and j less than k, α j is αi →αk.
If such a deduction exists, we say that ϕ is deducible from , or that
ϕ is a theorem of , and we write  ⊢ϕ.
There is another viewpoint that is useful here: A deduction of ϕ from
 can be viewed as a construction sequence, showing how ϕ can be
obtained from the set  ∪ by applying modus ponens zero or more
times. (We hesitate to say that ϕ is built “up” from  ∪. Unlike the
formula-building operations that produce longer formulas from shorter
ones, modus ponens can produce shorter formulas from longer ones.)
That is, the set of theorems of  is exactly the set of formulas that are
obtainable from the “base” set  ∪ by applying modus ponens.
The situation here differs from the one discussed in Section 1.4 in two
ways, one unimportant and one important. The unimportant difference is
that we get the set of theorems by closing under the “partially deﬁned”
operation of modus ponens, whose domain consists only of pairs of
formulas of the form ⟨α, α →β⟩(in contrast to the “totally deﬁned”
formula-building operations). The more important difference is that the
set of theorems is not freely generated from  ∪ by modus ponens.
This reﬂects the fact that a theorem never has a unique deduction. In
Sections 1.3 and 2.3, we were concerned to show that for any wff ϕ,
there was a unique tree (which we could effectively calculate) showing
how ϕ was built up by use of formula-building operations. Now the tree
is by no means unique, and calculating one such tree is a very different
matter from before.
Nevertheless, this viewpoint does yield the following induction prin-
ciple. We say that a set S of formulas is closed under modus ponens if
whenever both α ∈S and (α →β) ∈S then also β ∈S.
INDUCTION PRINCIPLE
Suppose that S is a set of wffs that includes
 ∪ and is closed under modus ponens. Then S contains every
theorem of .
For example, if the formulas β, γ , and γ →β →α are all in  ∪,
then  ⊢α, as is evidenced by the tree which displays how α was

112
A Mathematical Introduction to Logic
obtained. Although it is tempting (and in some ways more elegant) to
deﬁne a deduction to be such a tree, it will be simpler to take deductions
to be the linear sequences obtained by squashing such trees into straight
lines.
Now at last we give the set  of logical axioms. These are arranged
in six groups. Say that a wff ϕ is a generalization of ψ iff for some
n ≥0 and some variables x1, . . . , xn,
ϕ = ∀x1 · · · ∀xnψ.
We include the case n = 0; any wff is a generalization of itself. The
logical axioms are then all generalizations of wffs of the following
forms, where x and y are variables and α and β are wffs:
1. Tautologies;
2. ∀x α →αx
t , where t is substitutable for x in α;
3. ∀x(α →β) →( ∀x α →∀x β);
4. α →∀x α, where x does not occur free in α.
And if the language includes equality, then we add
5. x = x;
6. x = y →(α →α′), where α is atomic and α′ is obtained from α
by replacing x in zero or more (but not necessarily all) places by y.
For the most part groups 3–6 are self-explanatory; we will see var-
ious examples later. Groups 1 and 2 require explanation. But ﬁrst we
should admit that the above list of logical axioms may not appear very
natural. Later it will be possible to see where each of the six groups
originated.
Substitution
In axiom group 2 we ﬁnd
∀x α →αx
t .
Here αx
t is the expression obtained from the formula α by replacing the
variable x, wherever it occurs free in α, by the term t. This concept can
also be (and for us ofﬁcially is) deﬁned by recursion:
1. For atomic α, αx
t is the expression obtained from α by replacing
the variable x by t. (This is elaborated upon in Exercise 1. Note that αx
t
is itself a formula.)
2. (¬ α)x
t = (¬ αx
t ).
3. (α →β)x
t = (αx
t →βx
t ).
4. (∀y α)x
t =

∀y α
if x = y,
∀y(αx
t ) if x ̸= y.

Chapter 2:
First-Order Logic
113
EXAMPLES
1. ϕx
x = ϕ.
2. (Qx →∀x Px)x
y = (Qy →∀x Px).
3. If α is ¬ ∀y x = y, then ∀x α →αx
z is
∀x ¬ ∀y x = y →¬ ∀y z = y.
4. For α as in 3, ∀x α →αx
y is
∀x ¬ ∀y x = y →¬ ∀y y = y.
The last example above illustrates a hazard which must be guarded
against. On the whole, ∀x α →αx
t seems like a plausible enough axiom.
(“If α is true of everything, then it should be true of t.”) But in Example 4,
we have a sentence of the form ∀x α →αx
t , which is nearly always false.
The antecedent, ∀x ¬ ∀y x = y, is true in any structure whose universe
contains two or more elements. But the consequent, ¬ ∀y y = y, is false
in any structure. So something has gone wrong.
The problem is that when y was substituted for x, it was immediately
“captured” by the ∀y quantiﬁer. We must impose a restriction on axiom
group 2 that will preclude this sort of quantiﬁer capture. Informally, we
can say that a term t is not substitutable for x in α if there is some variable
y in t that is captured by a ∀y quantiﬁer in αx
t . The real deﬁnition is
given below by recursion. (Since the concept will be used later in proofs
by induction, a recursive deﬁnition is actually the most usable variety.)
Let x be a variable, t a term. We deﬁne the phrase “t is substitutable
for x in α” as follows:
1. For atomic α, t is always substitutable for x in α. (There are no
quantiﬁers in α, so no capture could occur.)
2. t is substitutable for x in (¬ α) iff it is substitutable for x in α. t
is substitutable for x in (α →β) iff it is substitutable for x in both α
and β.
3. t is substitutable for x in ∀y α iff either
(a) x does not occur free in ∀y α, or
(b) y does not occur in t and t is substitutable for x in α.
(The point here is to be sure that nothing in t will be captured by the
∀y preﬁx and that nothing has gone wrong inside α earlier.)
For example, x is always substitutable for itself in any formula. If t
contains no variables that occur in α, then t is substitutable for x in α.
The reader is cautioned not to be confused about the choice of words.
Even if t is not substitutable for x in α, still αx
t is obtained from α by
replacing x wherever it occurs free by t. Thus in forming αx
t , we carry
out the indicated substitution even if a prudent person would think it
unwise to do so.

114
A Mathematical Introduction to Logic
Axiom group 2 consists of all generalizations of formulas of the form
∀x α →αx
t ,
where the term t is substitutable for the variable x in the formula α. For
example,
∀v3( ∀v1(Av1 →∀v2Av2) →(Av2 →∀v2Av2))
is in axiom group 2. Here x is v1, α is Av1 →∀v2Av2, and t is v2. On
the other hand,
∀v1 ∀v2Bv1v2 →∀v2Bv2v2
is not in axiom group 2, since v2 is not substitutable for v1 in ∀v2Bv1v2.
Tautologies
Axiom group 1 consists of generalizations of formulas to be called
tautologies. These are the wffs obtainable from tautologies of sentential
logic (having only the connectives ¬ and →) by replacing each sentence
symbol by a wff of the ﬁrst-order language. For example,
∀x[( ∀y ¬ Py →¬ Px) →(Px →¬ ∀y ¬ Py)]
belongs to axiom group 1. It is a generalization of the formula in square
brackets, which is obtained from a contraposition tautology
(A →¬ B) →(B →¬ A)
by replacing A by ∀y ¬ Py and B by Px.
There is another, more direct, way of looking at axiom group 1.
Divide the wffs into two groups:
1. The prime formulas are the atomic formulas and those of the form
∀x α.
2. The nonprime formulas are the others, i.e., those of the form ¬ α
or α →β.
Thus any formula is built up from prime formulas by the operations
E¬ and E→. Now go back to sentential logic, but take the sentence
symbols to be the prime formulas of our ﬁrst-order language. Then any
tautology of sentential logic (that uses only the connectives ¬, →) is in
axiom group 1. There is no need to replace sentence symbols here by
ﬁrst-order wffs; they already are ﬁrst-order wffs. Conversely, anything
in axiom group 1 is a generalization of a tautology of sentential logic.
(The proof of this uses Exercise 8 of Section 1.2.)
EXAMPLE, revisited.
( ∀y ¬ Py →¬ Px) →(Px →¬ ∀y ¬ Py).

Chapter 2:
First-Order Logic
115
This has two sentence symbols (prime formulas), ∀y ¬ Py and Px.
So its truth table has four lines:
( ∀y ¬ Py →¬ Px) →(Px →¬ ∀y ¬ Py)
T
F
F T
T
T
F
F T
T
T
T F
T
F
T
F T
F
T
F T
T
T
T
T F
F
T
T F
T
F
T
T F
From the table we see that it is indeed a tautology.
On the other hand, neither ∀x(Px →Px) nor ∀x Px →Px is
a tautology.
One remark: We have not assumed that our ﬁrst-order language has
only countably many formulas. So we are potentially employing an
extension of Chapter 1 to the case of an uncountable set of sentence
symbols.
A second remark: Taking all tautologies as logical axioms is overkill.
We could get by with much less, at the expense of lengthening deduc-
tions. On the one hand, the tautologies form a nice decidable set (the
decidability will be important for the enumerability theorem in Sec-
tion 2.5). On the other hand, there is no known fast decision procedure
for tautologies, as noted in Section 1.7. One option would be to cut
axiom group 1 down to a set of tautologies for which we do know de-
cision procedures that are fast (the technical term is “polynomial-time
decidable”). The other tautologies would then be obtainable from these
by use of modus ponens.
A third remark: Now that ﬁrst-order formulas are also wffs of sen-
tential logic, we can apply concepts from both Chapters 1 and 2 to them.
If  tautologically implies ϕ, then it follows that  also logically im-
plies ϕ. (See Exercise 3.) But the converse fails. For example, ∀x Px
logically implies Pc. But ∀x Px does not tautologically imply Pc, as
∀x Px and Pc are two different sentence symbols.
THEOREM 24B
 ⊢ϕ iff  ∪ tautologically implies ϕ.
PROOF.
(⇒): This depends on the obvious fact that {α, α →β}
tautologically implies β. Suppose that we have a truth assignment
v that satisﬁes every member of  ∪. By induction we can see
that v satisﬁes any theorem of . The inductive step uses exactly
the above-mentioned obvious fact.
(⇐): Assume that  ∪ tautologically implies ϕ. Then by
the corollary to the compactness theorem (for sentential logic),
there is a ﬁnite subset {γ1, . . . , γm, λ1, . . . , λn} that tautologically
implies ϕ. Consequently,
γ1 →· · · →γm →λ1 →· · · λn →ϕ

116
A Mathematical Introduction to Logic
is a tautology (cf. Exercise 4 of Section 1.2) and hence is in .
By applying modus ponens m + n times to this tautology and to
{γ1, . . . , γm, λ1, . . . , λn} we obtain ϕ.
⊣
(The above proof is related to Exercise 7 in Section 1.7. It uses
sentential compactness for a possibly uncountable language.)
Deductions and Metatheorems
We now have completed the description of the set  of logical axioms.
The set of theorems of a set  is the set built up from  ∪ by modus
ponens. For example,
⊢Px →∃y Py.
(Here  = ∅; we write “⊢α” in place of “∅⊢α.”) The formula
Px →∃y Py can be obtained by applying modus ponens (once) to two
members of , as displayed by the pedigree tree:
We get a deduction of Px →∃y Py (from ∅) by compressing this
tree into a linear three-element sequence.
As a second example, we can obtain a generalization of the formula
in the ﬁrst example:
⊢∀x(Px →∃y Py).
This fact is evidenced by the following tree, which displays the con-
struction of ∀x(Px →∃y Py) from  by modus ponens:

Chapter 2:
First-Order Logic
117
Again we can compress the tree into a deduction.
In these examples the pedigree trees may seem to have been pulled
out of the air. But we will shortly develop techniques for generating
such trees in a somewhat systematic manner. These techniques will
rely heavily on the generalization theorem and the deduction theorem
below.
Notice that we use the word “theorem” on two different levels. We say
that α is a theorem of  if  ⊢α. We also make numerous statements
in English, each called a theorem, such as the one below. It seems
unlikely that any confusion will arise. The English statements could
have been labeled metatheorems to emphasize that they are results about
deductions and theorems.
The generalization theorem reﬂects our informal feeling that if we
can prove
x
without any special assumptions about x, we then are
entitled to say that “since x was arbitrary, we have ∀x
x
.”
GENERALIZATION THEOREM
If  ⊢ϕ and x do not occur free in any
formula in , then  ⊢∀x ϕ.
PROOF.
Consider a ﬁxed set  and a variable x not free in . We
will show by induction that for any theorem ϕ of , we have
 ⊢∀x ϕ. For this it sufﬁces (by the induction principle) to show
that the set
{ϕ |  ⊢∀x ϕ}
includes  ∪ and is closed under modus ponens. Notice that x
can occur free in ϕ.
Case 1: ϕ is a logical axiom. Then ∀x ϕ is also a logical axiom.
And so  ⊢∀x ϕ.
Case 2: ϕ ∈. Then x does not occur free in ϕ. Hence
ϕ →∀x ϕ
is in axiom group 4. Consequently,  ⊢∀x ϕ, as is evidenced by
the tree:
Case 3: ϕ is obtained by modus ponens from ψ and ψ →
ϕ. Then by inductive hypothesis we have  ⊢∀x ψ and  ⊢
∀x(ψ →ϕ). This is just the situation in which axiom group 3 is
useful. That  ⊢∀x ϕ is evidenced by the tree:

118
A Mathematical Introduction to Logic
So by induction  ⊢∀x ϕ for every theorem ϕ of .
⊣
(The sole reasons for having axiom groups 3 and 4 are indicated by
the above proof.)
The restriction that x not occur free in  is essential. For example,
Px ̸|= ∀x Px,andsobythesoundnesstheoremtoappearinSection2.5,
Px ⊬∀x Px. On the other hand, x will in general occur free in the
formula ϕ. For example, at the beginning of this subsection we showed
ﬁrst that
⊢(Px →∃y Py).
The second example there,
⊢∀x(Px →∃y Py),
was obtained from the ﬁrst example as in case 3 of the above proof.
EXAMPLE.
∀x ∀y α ⊢∀y ∀x α.
The proof of the generalization theorem actually yields somewhat
more than was stated. It shows how we can, given a deduction of ϕ from
, effectively transform it to obtain a deduction of ∀x ϕ from .
LEMMA 24C (RULE T)
If  ⊢α1, . . . ,  ⊢αn and {α1, . . . , αn} tau-
tologically implies β, then  ⊢β.
PROOF.
α1 →· · · →αn →β is a tautology, and hence a logical
axiom. Apply modus ponens n times.
⊣
DEDUCTION THEOREM
If ; γ ⊢ϕ, then  ⊢(γ →ϕ).
(The converse clearly holds also; in fact, the converse is essentially
the rule modus ponens.)
FIRST PROOF
; γ ⊢ϕ
iff (; γ ) ∪ tautologically implies ϕ,
iff  ∪ tautologically implies (γ →ϕ),
iff  ⊢(γ →ϕ).
⊣

Chapter 2:
First-Order Logic
119
SECOND PROOF
The second proof does not use the compactness the-
orem of sentential logic as does the ﬁrst proof. It shows in a direct
way how to transform a deduction of ϕ from ; γ to obtain a de-
duction of (γ →ϕ) from . We show by induction that for every
theorem ϕ of ; γ the formula (γ →ϕ) is a theorem of .
Case 1: ϕ = γ . Then obviously ⊢(γ →ϕ).
Case 2: ϕ is a logical axiom or a member of . Then  ⊢ϕ.
And ϕ tautologically implies (γ →ϕ), whence by rule T we have
 ⊢(γ →ϕ).
Case 3: ϕ is obtained by modus ponens from ψ and ψ →ϕ. By
the inductive hypothesis,  ⊢(γ →ψ) and  ⊢(γ →(ψ →ϕ)).
And the set {γ →ψ, γ →(ψ →ϕ)} tautologically implies γ →ϕ.
Thus, by rule T,  ⊢(γ →ϕ).
So by induction the conclusion holds for any ϕ deducible from
; γ .
⊣
COROLLARY 24D (CONTRAPOSITION)
; ϕ ⊢¬ ψ iff ; ψ ⊢¬ ϕ.
PROOF
; ϕ ⊢¬ ψ ⇒ ⊢ϕ →¬ ψ
by the deduction theorem,
⇒ ⊢ψ →¬ ϕ
by rule T,
⇒; ψ ⊢¬ ϕ
by modus ponens.
(In the second step we use the fact that ϕ →¬ ψ tautologically
implies ψ →¬ ϕ.) By symmetry, the converse holds also.
⊣
Say that a set of formulas is inconsistent iff for some β, both β and
¬ β are theorems of the set. (In this event, any formula α is a theorem
of the set, since β →¬ β →α is a tautology.)
COROLLARY 24E (REDUCTIO AD ABSURDUM)
If ; ϕ is inconsistent,
then  ⊢¬ ϕ.
PROOF.
From the deduction theorem we have  ⊢(ϕ →β) and
 ⊢(ϕ →¬ β). And {ϕ →β, ϕ →¬ β} tautologically implies
¬ ϕ.
⊣
EXAMPLE.
⊢∃x ∀y ϕ →∀y ∃x ϕ.
There are strategic advantages to working backward.
It sufﬁces to show that ∃x ∀y ϕ ⊢∀y ∃x ϕ, by the deduction
theorem.

120
A Mathematical Introduction to Logic
It sufﬁces to show that ∃x ∀y ϕ ⊢∃x ϕ, by the generalization
theorem.
It sufﬁces to show that ¬ ∀x ¬ ∀y ϕ ⊢¬ ∀x ¬ ϕ, as this is the
same as the preceding.
It sufﬁces to show that ∀x ¬ ϕ ⊢∀x ¬ ∀y ϕ, by contraposition
(and rule T).
It sufﬁces to show that ∀x ¬ ϕ ⊢¬ ∀y ϕ, by generalization.
It sufﬁces to show that {∀x ¬ ϕ, ∀y ϕ} is inconsistent, by reductio
ad absurdum.
And this is easy:
1. ∀x ¬ ϕ ⊢¬ ϕ by axiom group 2 and modus ponens.
2. ∀y ϕ ⊢ϕ for the same reason.
Lines 1 and 2 show that {∀x ¬ ϕ, ∀y ϕ} is inconsistent.
Strategy
As the preceding example indicates, the generalization and deduction
theorems (and to a smaller extent the corollaries) will be very useful
in showing that certain formulas are deducible. But there is still the
matter of strategy: For a given  and ϕ, where should one begin in
order to show that  ⊢ϕ? One could, in principle, start enumerating
all ﬁnite sequences of wffs until one encountered a deduction of ϕ
from . Although this would be an effective procedure (for reasonable
languages) for locating a deduction if one exists, it is far too inefﬁcient
to have more than theoretical interest.
One technique is to abandon formality and to give in English a proof
that the truth of  implies the truth of ϕ. Then the proof in English can
be formalized into a legal deduction. (In the coming pages we will see
techniques for carrying out such a formalization in a reasonably natural
way.)
There are also useful methods based solely on the syntactical form
of ϕ. Assume then that ϕ is indeed deducible from  but that you are
seeking a proof of this fact. There are several cases:
1. Suppose that ϕ is (ψ →θ). Then it will sufﬁce to show that
; ψ ⊢θ (and this will always be possible).
2. Suppose that ϕ is ∀x ψ. If x does not occur free in , then it
will sufﬁce to show that  ⊢ψ. (Even if x should occur free in , the
difﬁculty can be circumvented. There will always be a variable y such
that  ⊢∀y ψ x
y and ∀y ψ x
y ⊢∀x ψ. See the re-replacement lemma,
Exercise 9.)
3. Finally, suppose that ϕ is the negation of another formula.
3a. If ϕ is ¬(ψ →θ), then it will sufﬁce to show that  ⊢ψ and
 ⊢¬ θ (by rule T). And this will always be possible.
3b. If ϕ is ¬ ¬ ψ, then of course it will sufﬁce to show that  ⊢ψ.

Chapter 2:
First-Order Logic
121
3c. The remaining case is where ϕ is ¬ ∀x ψ. It would sufﬁce to
show that  ⊢¬ ψ x
t , where t is some term substitutable for x in ψ.
(Why?) Unfortunately this is not always possible. There are cases in
which
 ⊢¬ ∀x ψ,
and yet for every term t,
 ⊬¬ ψ x
t .
(One such example is  = ∅, ψ = ¬ (Px →∀y Py).) Contraposition
is handy here;
; α ⊢¬ ∀x ψ
iff
; ∀x ψ ⊢¬ α.
(A variation on this is: ; ∀y α ⊢¬ ∀x ψ if ; ∀x ψ ⊢¬ α.) If all
else fails, one can try reductio ad absurdum.
EXAMPLE (Q2A).
If x does not occur free in α, then
⊢(α →∀x β) ↔∀x(α →β).
To prove this, it sufﬁces (by rule T) to show, that
⊢(α →∀x β) →∀x(α →β)
and
⊢∀x(α →β) →(α →∀x β).
For the ﬁrst of these, it sufﬁces (by the deduction and generaliza-
tion theorems) to show that
{(α →∀x β), α} ⊢β.
But this is easy; ∀x β →β is an axiom.
To obtain the converse,
⊢∀x(α →β) →(α →∀x β),
it sufﬁces (by the deduction and generalization theorems) to show
that
{∀x(α →β), α} ⊢β.
This again is easy.
In the above example we can replace α by ¬ α, β by ¬ β, and use
the contraposition tautology (among other things) to obtain the related
fact:

122
A Mathematical Introduction to Logic
(Q3B).
If x does not occur free in α, then
⊢( ∃x β →α) ↔∀x(β →α).
The reader might want to convince him- or herself that the above
formula is valid.
Frequently an abbreviated style is useful in writing down a proof of
deducibility, as in the following example.
EXAMPLE (EQ2).
∀x ∀y(x = y →y = x).
PROOF
1. ⊢x = y →x = x →y = x. Ax 6.
2. ⊢x = x. Ax 5.
3. ⊢x = y →y = x. 1, 2; T.
4. ⊢∀x ∀y(x = y →y = x). 3; gen2.
⊣
In line 1, “Ax 6” means that the formula belongs to axiom group 6.
In line 3, “1, 2; T” means that this line is obtained from lines 1 and 2 by
rule T. In line 4, “3; gen2” means that the generalization theorem can be
applied twice to line 3 to yield line 4. In the same spirit we write “MP,”
“ded,” and “RAA” to refer to modus ponens, the deduction theorem,
and reductio ad absurdum, respectively.
It must be emphasized that the four numbered lines above do not
constitute a deduction of ∀x ∀y(x = y →y = x). Instead they form
a proof (in the meta-language we continue, with little justiﬁcation,
to call English) that such a deduction exists. The shortest deduction
of ∀x ∀y(x = y →y = x) known to the author is a sequence of
17 formulas.
EXAMPLE.
⊢x = y →∀z Pxz →∀z Pyz.
PROOF
1. ⊢x = y →Pxz →Pyz. Ax 6.
2. ⊢∀z Pxz →Pxz. Ax 2.
3. ⊢x = y →∀z Pxz →Pyz. 1, 2; T.
4. {x = y, ∀z Pxz} ⊢Pyz. 3; MP2.
5. {x = y, ∀z Pxz} ⊢∀z Pyz. 4; gen.
6. ⊢x = y →∀z Pxz →∀z Pyz. 5; ded2.
⊣
EXAMPLE (EQ5).
Let f be a two-place function symbol. Then
⊢∀x1 ∀x2 ∀y1 ∀y2(x1 = y1 →x2 = y2 →f x1x2 = f y1y2).
PROOF.
Two members of axiom group 6 are
x1 = y1 →f x1x2 = f x1x2 →f x1x2 = f y1x2,
x2 = y2 →f x1x2 = f y1x2 →f x1x2 = f y1y2.

Chapter 2:
First-Order Logic
123
From ∀x x = x (in axiom group 5) we deduce
f x1x2 = f x1x2.
The three displayed formulas tautologically imply
x1 = y1 →x2 = y2 →f x1x2 = f y1y2.
⊣
EXAMPLE
(a) {∀x(Px →Qx), ∀z Pz} ⊢Qc. It is not hard to show that
such a deduction exists. The deduction itself consists of seven
formulas.
(b) {∀x(Px →Qx), ∀z Pz} ⊢Qy. This is just like (a). The
point we are interested in here is that we can use the same seven-
element deduction, with c replaced throughout by y.
(c) {∀x(Px →Qx), ∀z Pz} ⊢∀y Qy. This follows from
(b) by the generalization theorem.
(d) {∀x(Px →Qx), ∀z Pz} ⊢∀x Qx. This follows from
(c) by use of the fact that ∀y Qy ⊢∀x Qx.
Parts (a) and (b) of the foregoing example illustrate a sort of inter-
changeability of constant symbols with free variables. This interchange-
ability is the basis for the following variation on the generalization
theorem, for which part (c) is an example. Part (d) is covered by Corol-
lary 24G. ϕc
y is, of course, the result of replacing c by y in ϕ.
THEOREM 24F (GENERALIZATION ON CONSTANTS)
Assume that  ⊢ϕ
and that c is a constant symbol that does not occur in . Then there
is a variable y (which does not occur in ϕ) such that  ⊢∀y ϕc
y.
Furthermore, there is a deduction of ∀y ϕc
y from  in which c
does not occur.
PROOF.
Let ⟨α0, . . . , αn⟩be a deduction of ϕ from . (Thus αn =
ϕ.) Let y be the ﬁrst variable that does not occur in any of the αi’s.
We claim that
⟨(α0)c
y, . . . , (αn)c
y⟩
(∗)
is a deduction from  of ϕc
y. So we must check that each (αk)c
y is
in  ∪ or is obtained from earlier formulas by modus ponens.
Case 1: αk ∈. Then c does not occur in αk. So (αk)c
y = αk,
which is in .
Case 2: αk is a logical axiom. Then (αk)c
y is also a logical
axiom. (Read the list of logical axioms and note that introducing
a new variable will transform a logical axiom into another one.)
Case 3: αk is obtained by modus ponens from αi and α j (which
is (αi →αk)) for i, j less than k. Then (α j)c
y = ((αi)c
y →(αk)c
y).
So (αk)c
y is obtained by modus ponens from (αi)c
y and (α j)c
y.

124
A Mathematical Introduction to Logic
This completes the proof that (∗) above is a deduction of ϕc
y.
Let  be the ﬁnite subset of  that is used in (∗). Thus (∗) is
a deduction of ϕc
y from , and y does not occur in . So by
the generalization theorem,  ⊢∀y ϕc
y. Furthermore, there is a
deduction of ∀y ϕc
y from  in which c does not appear. (For the
proof to the generalization theorem did not add any new symbols
to a deduction.) This is also a deduction from  of ∀y ϕc
y.
⊣
We will sometimes want to apply this theorem in circumstances in
which not just any variable will do. In the following version, there is a
variable x selected in advance.
COROLLARY 24G
Assume that  ⊢ϕx
c , where the constant symbol
c does not occur in  or in ϕ. Then  ⊢∀x ϕ, and there is a
deduction of ∀x ϕ from  in which c does not occur.
PROOF.
By the above theorem we have a deduction (without c) from
 of ∀y((ϕx
c )c
y), where y does not occur in ϕx
c . But since c does
not occur in ϕ,

ϕx
c
c
y = ϕx
y.
It remains to show that ∀y ϕx
y ⊢∀x ϕ. We can easily do this if
we know that
(∀y ϕx
y) →ϕ
is an axiom. That is, x must be substitutable for y in ϕx
y, and
(ϕx
y)y
x must be ϕ. This is reasonably clear; for details see the
re-replacement lemma (Exercise 9).
⊣
COROLLARY 24H (RULE EI)
Assume that the constant symbol c does
not occur in ϕ, ψ, or , and that
; ϕx
c ⊢ψ.
Then
; ∃x ϕ ⊢ψ
and there is a deduction of ψ from ; ∃x ϕ in which c does not
occur.
PROOF.
By contraposition we have
; ¬ ψ ⊢¬ ϕx
c .
So by the preceding corollary we obtain
; ¬ ψ ⊢∀x ¬ ϕ.
Applying contraposition again, we have the desired result.
⊣

Chapter 2:
First-Order Logic
125
“EI” stands for “existential instantiation,” a bit of traditional termi-
nology.
We will not have occasion to use rule EI in any of our proofs, but it
may be handy in exercises. It is the formal counterpart to the reasoning:
“We know there is an x such that
x
. So call it c. Now from
c
we can prove ψ.” But notice that rule EI does not claim that ∃x ϕ ⊢ϕx
c ,
which is in fact usually false.
EXAMPLE, revisited.
⊢∃x ∀y ϕ →∀y ∃x ϕ.
By the deduction theorem, it sufﬁces to show that
∃x ∀y ϕ ⊢∀y ∃x ϕ.
By rule EI it sufﬁces to show that
∀y ϕx
c ⊢∀y ∃x ϕ,
where c is new to the language. By the generalization theorem it
sufﬁces to show that
∀y ϕx
c ⊢∃x ϕ.
Since ∀y ϕx
c ⊢ϕx
c , it sufﬁces to show that
ϕx
c ⊢∃x ϕ.
By contraposition this is equivalent to
∀x ¬ ϕ ⊢¬ ϕx
c ,
which is trivial (by axiom group 2 and modus ponens).
We can now see roughly how our particular list of logical axioms
was formed. The tautologies were included to handle the sentential
connective symbols. (We could economize considerably at this point by
using only some of the tautologies.) Axiom group 2 reﬂects the intended
meaning of the quantiﬁer symbol. Then in order to be able to prove the
generalization theorem we added axiom groups 3 and 4 and arranged
for generalizations of axioms to be axioms.
Axiom groups 5 and 6 will turn out to be just enough to prove the
crucial properties of equality; see the subsection on equality.
As we will prove in Section 2.5, every logical axiom is a valid for-
mula. It might seem simpler to use as logical axioms the set of all valid
formulas. But there are two (related) objections to doing this. For one,
the concept of validity was deﬁned semantically. That is, the deﬁnition
referred to possible meanings (i.e., structures) for the language and to
the concept of truth in a structure. For our present purposes (e.g., proving
that the validities are effectively enumerable) we need a class  with
a ﬁnitary, syntactical deﬁnition. That is, the deﬁnition of  involves
only matters concerning the arrangement of the symbols in the logical
axioms; there is no reference to matters of truth in structures. A second

126
A Mathematical Introduction to Logic
objection to the inclusion of all valid formulas as axioms is that we
prefer a decidable set , and the set of validities fails to be decidable.
Alphabetic Variants
Often when we are discussing a formula such as
∀x(x ̸= 0 →∃y x = Sy)
we are not interested in the particular choice of the variables x and y.
We want ⟨x, y⟩to be a pair of distinct variables, but often it makes no
difference whether the pair is ⟨v4, v9⟩or ⟨v8, v1⟩.
But when it comes time to substitute a term t into a formula, then
the choice of quantiﬁed variables can make the difference between the
substitutability of t and its failure. In this subsection we will discuss
what to do when substitutability fails. As will be seen, the difﬁculty can
always be surmounted by suitably juggling the quantiﬁed variables.
For example, suppose we want to show that
⊢∀x ∀y Pxy →∀y Pyy.
There is the difﬁculty that y is not substitutable for x in ∀y Pxy, so
the above sentence is not in axiom group 2. This is a nuisance resulting
from an unfortunate choice of variables. For example, showing that
⊢∀x ∀z Pxz →∀y Pyy
involves no such difﬁculties. So we can solve our original problem if
we know that
⊢∀x ∀y Pxy →∀x ∀z Pxz,
which, again, involves no difﬁculties.
This slightly circuitous strategy (of interpolating ∀x ∀z Pxz be-
tween ∀x ∀y Pxy and ∀y Pyy) is typical of a certain class of prob-
lems. Say that we desire to substitute a term t for x in a wff ϕ. If t is,
in fact, not so substitutable, then we replace ∀x ϕ by ∀x ϕ′, where t is
substitutable for x in ϕ′. In the above example ϕ is ∀y Pxy and ϕ′ is
∀z Pxz. In general ϕ′ will differ from ϕ only in the choice of quantiﬁed
variables. But ϕ′ must be formed in a reasonable way so as to be logi-
cally equivalent to ϕ. For example, it would be unreasonable to replace
∀y Pxy by ∀x Pxx, or ∀y ∀z Qxyz by ∀z ∀z Qxzz.
THEOREM 24I (EXISTENCE OF ALPHABETIC VARIANTS)
Let ϕ be a for-
mula, t a term, and x a variable. Then we can ﬁnd a formula ϕ′
(which differs from ϕ only in the choice of quantiﬁed variables)
such that
(a) ϕ ⊢ϕ′ and ϕ′ ⊢ϕ;
(b) t is substitutable for x in ϕ′.

Chapter 2:
First-Order Logic
127
PROOF.
We consider ﬁxed t and x, and construct ϕ′ by recursion on
ϕ. The ﬁrst cases are simple: For atomic ϕ we take ϕ′ = ϕ, and
then (¬ ϕ)′ = (¬ ϕ′), (ϕ →ψ)′ = (ϕ′ →ψ′). But now consider
the choice of ( ∀y ϕ)′.
If y does not occur in t, or if y = x, then we can just take
(∀y ϕ)′ = ∀y ϕ′. But for the general case we must change the
variable.
Choose a variable z that does not occur in ϕ′ or t or x. Then
deﬁne (∀y ϕ)′ = ∀z(ϕ′)y
z . To verify that (b) holds, we note that
z does not occur in t and t is substitutable for x in ϕ′ (by the
inductive hypothesis). Hence (since x ̸= z) t is also substitutable
for x in (ϕ′)y
z . To verify that (a) holds, we calculate:
ϕ ⊢ϕ′
by the inductive hypothesis;
∴∀y ϕ ⊢∀y ϕ′.
∀y ϕ′ ⊢(ϕ′)y
z
since z does not occur in ϕ′;
∴∀y ϕ′ ⊢∀z(ϕ′)y
z
by generalization;
∴∀y ϕ ⊢∀z(ϕ′)y
z .
In the other direction,
∀z(ϕ′)y
z ⊢((ϕ′)y
z )z
y,
which is ϕ′ by Exercise 9;
ϕ′ ⊢ϕ;
by the inductive hypothesis;
∴∀z(ϕ′)y
z ⊢ϕ
∴∀z(ϕ′)y
z ⊢∀y ϕ
by generalization.
The last step uses the fact that y does not occur free in (ϕ′)y
z unless
y = z, and so does not occur free in ∀z(ϕ′)y
z in any case.
⊣
The formulas ϕ′ constructed as in the proof of this theorem will be
called alphabetic variants of ϕ. The moral of the theorem is: One should
not be daunted by failure of substitutability; the right alphabetic variant
will avoid the difﬁculty.
Equality
We list here (assuming that our language includes =) the facts about
equality that will be needed in the next section. First, the relation deﬁned
by v1 =v2 is reﬂexive, symmetric, and transitive (i.e., is an equivalence
relation):
Eq1:
⊢∀x x = x.
PROOF.
Axiom group 5.
⊣
Eq2:
⊢∀x ∀y(x = y →y = x).

128
A Mathematical Introduction to Logic
PROOF.
Page 122.
⊣
Eq3:
⊢∀x ∀y ∀z(x = y →y = z →x = z).
PROOF.
Exercise 11.
⊣
In addition, we will need to know that equality is compatible with
the predicate and function symbols:
Eq4
(for a two-place predicate symbol P):
⊢∀x1 ∀x2 ∀y1 ∀y2(x1 = y1 →x2 = y2 →Px1x2 →Py1y2).
Similarly for n-place predicate symbols.
PROOF.
It sufﬁces to show that
{x1 = y1, x2 = y2, Px1x2} ⊢Py1y2.
This is obtained by application of modus ponens to the two mem-
bers of axiom group 6:
x1 = y1 →Px1x2 →Py1x2,
x2 = y2 →Py1x2 →Py1y2.
⊣
Eq5 (for a two-place function symbol f ):
⊢∀x1 ∀x2 ∀y1 ∀y2(x1 = y1 →x2 = y2 →f x1x2 = f y1y2).
Similarly for n-place function symbols.
PROOF.
Page 122.
⊣
Final Comments
A logic book in the bootstrap tradition might well begin with this section
on a deductive calculus. Such a book would ﬁrst state the logical axioms
and the rules of inference and would explain that they are acceptable to
reasonable people. Then it would proceed to show that many formulas
were deducible (or deducible from certain nonlogical axioms, such as
axioms for set theory).
Our viewpoint is very different. We study, among other things, the
facts about the procedure described in the preceding paragraph. And
we employ in this any correct mathematical reasoning, whether or not
such reasoning is known to have counterparts in the deductive calculus
under study.
Figure 8 is intended to illustrate the separation between (a) the level
at which we carry out our reasoning and prove our results, and (b) the
level of the deductive calculus which we study.

Chapter 2:
First-Order Logic
129
Figure 8. The meta-language above, in which we study the object
language below.
Exercises
1. For a term u, let ux
t be the expression obtained from u by replacing
the variable x by the term t. Restate this deﬁnition without using
any form of the word “replace” or its synonyms. Suggestion: Use
recursion on u. (Observe that from the new deﬁnition it is clear that
ux
t is itself a term.)
2. To which axiom groups, if any, do each of the following formulas
belong?
(a) [( ∀x Px →∀y Py) →Pz] →[∀x Px →( ∀y Py →Pz)].
(b) ∀y[∀x(Px →Px) →(Pc →Pc)].
(c) ∀x ∃y Pxy →∃y Pyy.
3. (a) Let A be a structure and let s : V →|A|. Deﬁne a truth assign-
ment v on the set of prime formulas by
v(α) = T
iff
|=A α[s].

130
A Mathematical Introduction to Logic
Show that for any formula (prime or not),
v(α) = T
iff
|=A α[s].
Remark: This result reﬂects the fact that ¬ and →were treated
in Chapter 2 the same way as in Chapter 1.
(b) Conclude that if  tautologically implies ϕ, then  logically
implies ϕ.
4. Give a deduction (from ∅) of ∀x ϕ →∃x ϕ. (Note that you should
not merely prove that such a deduction exists. You are instead asked
to write out the entire deduction.)
5. Find a function f such that if a formula ϕ has a deduction of length
n from a set , and if x does not occur free in , then ∀x ϕ has a
deduction from  of length f (n). The more slowly your function
grows, the better.
6. (a) Show that if ⊢α →β, then ⊢∀x α →∀x β.
(b) Show that it is not in general true that α →β |= ∀x α →∀x β.
7. (a) Show that ⊢∃x(Px →∀x Px).
(b) Show that {Qx, ∀y(Qy →∀z Pz)} ⊢∀x Px.
8. (Q2b) Assume that x does not occur free in α. Show that
⊢(α →∃x β) ↔∃x(α →β).
Also show that, under the same assumption, we have Q3a:
⊢( ∀x β →α) ↔∃x(β →α).
9. (Re-replacement lemma) (a) Show by example that (ϕx
y)y
x is not in
general equal to ϕ. And that it is possible both for x to occur in
(ϕx
y)y
x at a place where it does not occur in ϕ, and for x to occur in
ϕ at a place where it does not occur in (ϕx
y)y
x.
(b) Show that if y does not occur at all in ϕ, then x is substitutable
for y in ϕx
y and (ϕx
y)y
x = ϕ. Suggestion: Use induction on ϕ.
10. Show that
∀x ∀y Pxy ⊢∀y ∀x Pyx.
11. (Eq3) Show that
⊢∀x ∀y ∀z(x = y →y = z →x = z).
12. Show that any consistent set  of formulas can be extended to a
consistent set  having the property that for any formula α, either
α ∈ or (¬ α) ∈. (Assume that the language is countable. Do
not use the compactness theorem of sentential logic.)
13. Show that ⊢Py ↔∀x(x = y →Px).
Remarks: More generally, if t is substitutable for x in ϕ and x
does not occur in t, then
⊢[ϕx
t ↔∀x(x = t →ϕ)].

Chapter 2:
First-Order Logic
131
Thus the formula ∀x(x = t →ϕ) offers an alternative of sorts to
the substitution ϕx
t .
14. Show that ⊢( ∀x((¬ Px) →Qx) →∀y((¬ Qy) →Py)).
15. Show that deductions (from ∅) of the following formulas exist:
(a) ∃x α ∨∃x β ↔∃x(α ∨β).
(b) ∀x α ∨∀x β →∀x(α ∨β).
16. Show that deductions (from ∅) of the following formulas exist:
(a) ∃x(α ∧β) →∃x α ∧∃x β.
(b) ∀x(α ∧β) ↔∀x α ∧∀x β.
17. Show that deductions (from ∅) of the following formulas exist:
(a) ∀x(α →β) →( ∃x α →∃x β).
(b) ∃x(Py ∧Qx) ↔Py ∧∃x Qx.
SECTION 2.5
Soundness and Completeness Theorems
In this section we establish two major theorems: the soundness of our
deductive calculus ( ⊢ϕ ⇒ |= ϕ) and its completeness ( |=
ϕ ⇒ ⊢ϕ). We will then be able to draw a number of interesting
conclusions (including the compactness and enumerability theorems).
Although our deductive calculus was chosen in a somewhat arbitrary
way, the signiﬁcant fact is that some such deductive calculus is sound
and complete. This should be encouraging to the “working mathemati-
cian” concerned about the existence of proofs from axioms; see the
Retrospectus subsection of Section 2.6.
SOUNDNESS THEOREM
If  ⊢ϕ, then  |= ϕ.
The soundness theorem tells that our deductions lead only to “cor-
rect” conclusions — deductions would be rather pointless otherwise!
The idea of the proof is that the logical axioms are logically implied by
anything, and that modus ponens preserves logical implications.
LEMMA 25A
Every logical axiom is valid.
PROOF OF THE SOUNDNESS THEOREM, ASSUMING THE LEMMA.
Weshow
by induction that any formula ϕ deducible from  is logically im-
plied by .
Case 1: ϕ is a logical axiom. Then by the lemma |= ϕ, so a
fortiori  |= ϕ.
Case 2: ϕ ∈. Then clearly  |= ϕ.
Case 3: ϕ is obtained by modus ponens from ψ and ψ →ϕ,
where (by the inductive hypothesis)  |= ψ and  |= (ψ →ϕ).
It then follows at once that  |= ϕ.
⊣

132
A Mathematical Introduction to Logic
It remains, of course, to prove that lemma. We know from Exercise 6
of Section 2.2 that any generalization of a valid formula is valid. So it
sufﬁces to consider only logical axioms that are not themselves gener-
alizations of other axioms. We will examine the various axiom groups
in order of complexity.
Axiom group 3: See Exercise 3 of Section 2.2.
Axiom group 4: See Exercise 4 of Section 2.2.
Axiom group 5: Trivial. A satisﬁes x = x with s iff s(x) = s(x),
which is always true.
Axiom group 1: We know from Exercise 3 of the preceding section
that if ∅tautologically implies α, then ∅|= α. And that is just what we
need.
Axiom group 6 (for an example, see Exercise 5 of Section 2.2): As-
sume that α is atomic and α′ is obtained from α by replacing x at some
places by y. It sufﬁces to show that
{x = y, α} |= α′.
So take any A, s such that
|=A x = y[s],
i.e., s(x) = s(y).
Then any term t has the property that if t′ is obtained from t by replacing
x at some places by y, then s(t) = s(t′). This is obvious; a full proof
would use induction on t.
If α is t1 = t2, then α′ must be t′
1 = t′
2, where t′
i is obtained from ti as
described.
|=A α[s]
iff
s(t1) = s(t2),
iff
s(t′
1) = s(t′
2),
iff
|=A α′[s].
Similarly, if α is Pt1 · · · tn, then α′ is Pt′
1 · · · t′
n and an analogous
argument applies.
Finally, we come to axiom group 2. It will be helpful to consider ﬁrst
a simple case: we will show that ∀x Px →Pt is valid. Assume that
|=A ∀x Px[s].
Then for any d in |A|,
|=A Px[s(x | d)].
So in particular we may take d = s(t):
|=A Px[s(x | s(t))].
(a)
This is equivalent (by the deﬁnition of satisfaction of atomic formulas)
to
s(t) ∈PA,

Chapter 2:
First-Order Logic
133
which in turn is equivalent to
|=A Pt[s].
(b)
For this argument to be applicable to the nonatomic case, we need a
way of passing from (a) to (b). This will be provided by the substitution
lemma below, which states that
|=A ϕ[s(x | s(t))]
iff |=A ϕx
t [s]
whenever t is substitutable for x in ϕ.
Consider a ﬁxed A and s. For any term u, let ux
t be the result of
replacing the variable x in u by the term t.
LEMMA 25B
s(ux
t ) = s(x | s(t))(u).
This looks more complicated than it is. It asserts that a substitution
can be carried out either in the term u or in s, with equivalent results.
The corresponding commutative diagram is shown.
PROOF.
By induction on the term u. If u is a constant symbol or
a variable other than x, then ux
t = u and the desired equation
reduces to s(u) = s(u). If u = x, then the equation reduces to
s(t) = s(t). The inductive step, although cumbersome to write,
is mathematically trivial.
⊣
The substitution lemma is similar in spirit; it states that a substitution
can be carried out either within ϕ or in s, with equivalent results. For
an example see Exercise 10 of Section 2.2.
SUBSTITUTION LEMMA
If the term t is substitutable for the variable x
in the wff ϕ, then
|=A ϕx
t [s]
iff |=A ϕ[s(x | s(t))].
PROOF.
We use induction on ϕ to show that the above holds for
every s.
Case 1: ϕ is atomic. Then the conclusion follows from the
preceding lemma. For example, if ϕ is Pu for some term u, then
|=A Pux
t [s] iff s(ux
t ) ∈PA,
iff s(x | s(t))(u) ∈PA
by Lemma 25B,
iff |=A Pu[s(x | s(t))].

134
A Mathematical Introduction to Logic
Case 2: ϕ is ¬ ψ or ψ →θ. Then the conclusion for ϕ follows
at once from the inductive hypotheses for ψ and θ.
Case 3: ϕ is ∀y ψ, and x does not occur free in ϕ. Then s and
s(x | s(t)) agree on all variables that occur free in ϕ. And also ϕx
t
is simply ϕ. So the conclusion is immediate.
Case 4: ϕ is ∀y ψ, and x does occur free in ϕ. Because t is
substitutable for x in ϕ, we know that y does not occur in t and t
is substitutable for x in ψ (see the deﬁnition of “substitutable”).
By the ﬁrst of these,
s(t) = s(y | d)(t)
(∗)
for any d in |A|. Since x ̸= y, ϕx
t = ∀y ψ x
t .
|=A ϕx
t [s]
iff for every d,
|=A ψ x
t [s(y | d)],
iff for every d,
|=A ψ[s(y | d)(x | s(t))] by
the inductive hypothesis and (∗),
iff |=A ϕ[s(x | s(t))].
So by induction the lemma holds for all ϕ.
⊣
Axiom group 2: Assume that t is substitutable for x in ϕ. Assume
that A satisﬁes ∀x ϕ with s. We need to show that |=A ϕx
t [s]. We know
that for any d in |A|,
|=A ϕ[s(x | d)],
In particular, let d = s(t):
|=A ϕ[s(x | s(t))],
So, by the substitution lemma,
|=A ϕx
t [s].
Hence ∀x ϕ →ϕx
t is valid.
This completes the proof that all logical axioms are valid. And so the
soundness theorem is proved.
COROLLARY 25C
If ⊢(ϕ ↔ψ), then ϕ and ψ are logically equiva-
lent.
COROLLARY 25D
If ϕ′ is an alphabetic variant of ϕ (see Theo-
rem 24I), then ϕ and ϕ′ are logically equivalent.
Recall that a set  is consistent iff there is no formula ϕ such that
both  ⊢ϕ and  ⊢¬ ϕ. Deﬁne  to be satisﬁable iff there is some A
and s such that A satisﬁes every member of  with s.
COROLLARY 25E
If  is satisﬁable, then  is consistent.
This corollary is actually equivalent to the soundness theorem, as the
reader is invited to verify.

Chapter 2:
First-Order Logic
135
The completeness theorem is the converse to the soundness theorem
and is a deeper result.
COMPLETENESS THEOREM (G¨ODEL, 1930)
(a) If  |= ϕ, then  ⊢ϕ.
(b) Any consistent set of formulas is satisﬁable.
Actually parts (a) and (b) are equivalent; cf. Exercise 2. So it sufﬁces
to prove part (b). We will give a proof for a countable language; later
we will indicate what alterations are needed for languages of larger
cardinality. (A countable language is one with countably many symbols,
or equivalently, by Theorem 0B, one with countably many wffs.)
The ideas of the proof are related to those in the proof of the com-
pactness theorem for sentential logic. We begin with a consistent set .
In steps 1–3 we extend  to a set  of formulas for which
(i)  ⊆.
(ii)  is consistent and is maximal in the sense that for any formula
α, either α ∈ or (¬ α) ∈.
(iii) For any formula ϕ and variable x, there is a constant c such that
(¬ ∀x ϕ →¬ ϕx
c ) ∈.
Then in step 4 we form a structure A in which members of  not
containing = can be satisﬁed. |A| is the set of terms, and for a predicate
symbol P,
⟨t1, . . . , tn⟩∈PA
iff
Pt1 · · · tn ∈.
Finally, in steps 5 and 6 we change A to accommodate formulas con-
taining the equality symbol.
It is suggested that on a ﬁrst reading the details which are provided
for most of the steps be omitted. Once the outline is clearly in mind, the
entire proof should be read. (The nondetails are marked with a stripe in
the left margin.)
PROOF.
Let  be a consistent set of wffs in a countable language.
⊣
STEP 1:
Expand the language by adding a countably inﬁnite set of
new constant symbols. Then  remains consistent as a set of wffs
in the new language.
Details: If not then for some β, there is a deduction (in the expanded
language) of (β ∧¬ β) from . This deduction contains only ﬁnitely
many of the new constant symbols. By the theorem for generalization
on constants (Theorem 24F), each can be replaced by a variable. We
then have a deduction (in the original language) of (β′ ∧¬ β′) from .
This contradicts our assumption that  was consistent.

136
A Mathematical Introduction to Logic
STEP 2:
For each wff ϕ (in the new language) and each variable x,
we want to add to  the wff
¬ ∀x ϕ →¬ ϕx
c ,
where c is one of the new constant symbols. (The idea is that c
volunteers to name a counterexample to ϕ, if there is any.) We
can do this in such a way that  together with the set  of all the
added wffs is still a consistent set.
Details: Adopt a ﬁxed enumeration of the pairs ⟨ϕ, x⟩, where ϕ is a
wff (of the expanded language) and x is a variable:
⟨ϕ1, x1⟩, ⟨ϕ2, x2⟩, ⟨ϕ3, x3⟩, . . . .
This is possible since the language is countable. Let θ1 be
¬ ∀x1ϕ1 →¬ ϕ1
x1
c1,
where c1 is the ﬁrst of the new constant symbols not occurring in ϕ1.
Then go on to ⟨ϕ2, x2⟩and deﬁne θ2. In general, θn is
¬ ∀xnϕn →¬ ϕn
xn
cn ,
where cn is the ﬁrst of the new constant symbols not occurring in ϕn or
in θk for any k < n.
Let  be the set {θ1, θ2, . . .}. We claim that  ∪ is consistent. If
not, then (because deductions are ﬁnite) for some m ≥0,
 ∪{θ1, . . . , θm, θm+1}
is inconsistent. Take the least such m. Then by RAA
 ∪{θ1, . . . , θm} ⊢¬ θm+1.
Now θm+1 is
¬ ∀x ϕ →¬ ϕx
c
for some x, ϕ, and c. So by rule T, we obtain the two facts:
 ∪{θ1, . . . θm} ⊢¬ ∀x ϕ,
 ∪{θ1, . . . θm} ⊢ϕx
c .
(∗)
Since c does not appear in any formula on the left side, we can apply
the Corollary 24G to the second of these, obtaining
 ∪{θ1, . . . , θm} ⊢∀x ϕ.
This and (∗) contradict the leastness of m (or the consistency of , if
m = 0).

Chapter 2:
First-Order Logic
137
STEP 3:
We now extend the consistent set  ∪ to a consistent set
 which is maximal in the sense that for any wff ϕ either ϕ ∈
or (¬ ϕ) ∈.
Details: We can imitate the proof used at the analogous place in
the proof of sentential compactness in Section 1.7. Or we can argue as
follows: Let  be the set of logical axioms for the expanded language.
Since  ∪ is consistent, there is no formula β such that  ∪ ∪
tautologically implies both β and ¬ β. (This is by Theorem 24B; the
compactness theorem of sentential logic is used here.) Hence there is
a truth assignment v for the set of all prime formulas that satisﬁes
 ∪ ∪. Let
 = {ϕ | v(ϕ) = T }.
Clearly for any ϕ either ϕ ∈ or ( ¬ ϕ) ∈ but not both. Also we
have
 ⊢ϕ ⇒ tautologically implies ϕ
(since  ⊆),
⇒v(ϕ) = T
since v satisﬁes ,
⇒ϕ ∈.
Consequently,  is consistent, lest both ϕ and ( ¬ ϕ) belong to .
Actually, regardless of how  is constructed, it must be de-
ductively closed. That is,
 ⊢ϕ ⇒ ⊬¬ ϕ
by consistency,
⇒(¬ ϕ) /∈,
⇒ϕ ∈
by maximality.
STEP 4:
We now make from  a structure A for the new language,
but with the equality symbol (if any) replaced by a new two-place
predicate symbol E. A will not itself be the structure in which 
will be satisﬁed but will be a preliminary structure.
(a) |A| = the set of all terms of the new language.
(b) Deﬁne the binary relation EA by
⟨u, t⟩∈EA
iff
the formula u = t belongs to .
(c) For each n-place predicate parameter P, deﬁne the n-ary
relation PA by
⟨t1, . . . , tn⟩∈PA
iff
Pt1 · · · tn ∈.
(d) For each n-place function symbol f , let f A be the function
deﬁned by
f A(t1, . . . , tn) = f t1 · · · tn.

138
A Mathematical Introduction to Logic
This includes the n = 0 case; for a constant symbol c we take cA = c.
Deﬁne also a function s : V →|A|, namely the identity function
s(x) = x on V .
It then follows that for any term t, s(t) = t. For any wff ϕ, let ϕ∗
be the result of replacing the equality symbol in ϕ by E. Then
|=A ϕ∗[s]
iff
ϕ ∈.
Details: That s(t) = t can be proved by induction on t, but the proof
is entirely straightforward.
The other claim, that
|=A ϕ∗[s]
iff
ϕ ∈,
we prove by induction on the number of places at which connective or
quantiﬁer symbols appear in ϕ.
Case 1: Atomic formulas. We deﬁned A in such a way as to make
this case immediate. For example, if ϕ is Pt, then
|=A Pt[s]
iff s(t) ∈PA,
iff t ∈PA,
iff Pt ∈.
Similarly,
|=A uEt[s]
iff ⟨s(u), s(t)⟩∈EA,
iff ⟨u, t⟩∈EA,
iff u = t ∈.
Case 2: Negation.
|=A (¬ ϕ)∗[s]
if ̸|=A ϕ∗[s],
iff ϕ /∈
by inductive hypothesis,
iff (¬ ϕ) ∈
by properties of .
Case 3: Conditional.
|=A (ϕ →ψ)∗[s]
iff ̸|=A ϕ∗[s] or |=A ψ∗[s],
iff ϕ /∈ or ψ ∈ by inductive hypothesis,
iff (¬ ϕ) ∈ or ψ ∈,
⇒ ⊢(ϕ →ψ), in fact tautologically,
⇒ϕ /∈ or [ϕ ∈ and  ⊢ψ],
⇒(¬ ϕ) ∈ or ψ ∈,
which closes the loop. And
 ⊢(ϕ →ψ)
iff
(ϕ →ψ) ∈.
(This should be compared with Exercise 2 of Section 1.7.)
Case 4: Quantiﬁcation. We want to show that
|=A ∀x ϕ∗[s]
iff ∀x ϕ ∈.

Chapter 2:
First-Order Logic
139
(The notational ambiguity is harmless since ∀x(ϕ∗) is the same as
(∀x ϕ)∗.)  includes the wff θ:
¬ ∀x ϕ →¬ ϕx
c .
To show that
|=A ∀x ϕ∗[s] ⇒∀x ϕ ∈,
we can argue: If ϕ∗is true of everything, then it is true of c, whence by
the inductive hypothesis ϕx
c ∈. But then ∀x ϕ ∈, because c was
chosen to be a counterexample to ϕ if there was one. In more detail:
|=A ∀x ϕ∗[s] ⇒|=A ϕ∗[s(x | c)]
⇒|=A (ϕ∗)x
c[s]
by the substitution lemma
⇒|=A (ϕx
c )∗[s],
this being the same formula
⇒ϕx
c ∈
by the inductive hypothesis
⇒(¬ ϕx
c ) /∈
by consistency
⇒(¬ ∀x ϕ) /∈
since θ ∈ and  is
deductively closed
⇒∀x ϕ ∈.
(This is our only use of . We needed to know that if (¬ ∀x ϕ) ∈,
then for a particular c we would have (¬ ϕx
c ) ∈.)
We turn now to the converse. We can almost argue as follows:
̸|=A ∀x ϕ∗[s] ⇏|=A ϕ∗[s(x | t)]
for some t
⇝̸|=A (ϕx
t )∗[s]
by the substitution lemma
⇒ϕx
t /∈
by the inductive hypothesis
⇝∀x ϕ /∈
since  is deductively closed.
The ﬂaw here is that the two wavy implications require that t be
substitutable for x in ϕ. This may not be the case, but we can use the
usual repair: We change to an alphabetic variant ψ of ϕ in which t is
substitutable for x. Then
̸|=A ∀x ϕ∗[s] ⇏|=A ϕ∗[s(x | t)] for some t, henceforth ﬁxed
⇏|=A ψ∗[s(x | t)] by the semantical equivalence of
alphabetic variants (Corollary 25D)
⇏|=A (ψ x
t )∗[s]
by the substitution lemma
⇒ψ x
t /∈
by the inductive hypothesis
⇒∀x ψ /∈
since  is deductively closed
⇒∀x ϕ /∈
by the syntactical equivalence of
alphabetic variants (Theorem 24I).
This completes the list of possible cases; it now follows by induction
that for any ϕ,
|=A ϕ∗[s]
iff
ϕ ∈.

140
A Mathematical Introduction to Logic
If our original language did not include the equality symbol, then
we are done. For we need only restrict A to the original language to
obtain a structure that satisﬁes every member of  with the identity
function.
But now assume that the equality symbol is in the language. Then
A will no longer serve. For example, if  contains the sentence
c = d (where c and d are distinct constant symbols), then we need a
structure B in which cB = dB. We obtain B as the quotient structure
A/E of A modulo EA.
STEP 5:
EA is an equivalence relation on |A|. For each t in |A| let
[t] be its equivalence class. EA is, in fact, a congruence relation
for A. This means that the following conditions are met:
(i) EA is an equivalence relation on |A|.
(ii) PA is compatible with EA for each predicate symbol P:
⟨t1, . . . , tn⟩∈PA and ti EAt′
i for 1 ≤i ≤n ⇒⟨t′
1, . . . , t′
n⟩∈PA.
(iii) f A is compatible with EA for each function symbol f :
ti EAt′
i for 1 ≤i ≤n ⇒f A(t1, . . . , tn)EA f A(t′
1, . . . , t′
n).
Under these circumstances we can form the quotient structure A/E,
deﬁned as follows:
(a) |A/E| is the set of all equivalence classes of members of |A|.
(b) For each n-place predicate symbol P,
⟨[t1], . . . , [tn]⟩∈PA/E iff ⟨t1, . . . , tn⟩∈PA.
(c) For each n-place function symbol f ,
f A/E([t1], . . . , [tn]) = [ f A(t1, . . . , tn)].
This includes the n = 0 cases:
cA/E = [cA].
Let h : |A| →|A/E| be the natural map:
h(t) = [t].
Then h is a homomorphism of A onto A/E. Furthermore, EA/E
is the equality relation on |A/E|. Consequently, for any ϕ:
ϕ ∈ ⇔|=A ϕ∗[s]
⇔|=A/E ϕ∗[h ◦s]
⇔|=A/E ϕ[h ◦s]
So A/E satisﬁes every member of  (and hence every member of
) with h ◦s.

Chapter 2:
First-Order Logic
141
Details: Recall that
t EAt′
iff
(t = t′) ∈,
iff
 ⊢t = t′.
(i) EA is an equivalence relation on A by properties Eq1, Eq2, and
Eq3 of equality.
(ii) PA is compatible with EA by property Eq4 of equality.
(iii) f A is compatible with EA by property Eq5 of equality.
It then follows from the compatibility of PA with EA that PA/E is
well deﬁned. Similarly, f A/E is well deﬁned because f A is compatible
with EA.
It is immediate from the construction that h is a homomorphism of
A onto A/E. And
[t]EA/E[t′]
iff
t EAt′,
iff
[t] = [t′].
Finally,
ϕ ∈ ⇔|=A ϕ∗[s]
by step 4
⇔|=A/E ϕ∗[h ◦s]
by the homomorphism theorem
⇔|=A/E ϕ[h ◦s],
the last step being justiﬁed by the fact that EA/E is the equality relation
on |A/E|.
STEP 6:
Restrict the structure A/E to the original language. This
restriction of A/E satisﬁes every member of  with h ◦s.
⊣
For an uncountable language, a few modiﬁcations to the foregoing
proof of the completeness theorem are needed. Say that the language has
cardinality λ. (By this we mean that it has λ symbols or, equivalently,
λ formulas.) We will describe the modiﬁcations needed, assuming the
reader has a substantial knowledge of set theory. In step 1 we add λ
new constant symbols; the details remain unchanged. In step 2, only the
details change. The cardinal λ is an initial ordinal. (We have tacitly well
ordered the language here.) “Enumerate” the pairs
⟨ϕα, xα⟩α<λ
indexed by ordinals less than λ. For α < λ, θα is
¬ ∀xαϕα →(¬ ϕ)xα
cα ,
where cα is the ﬁrst of the new constant symbols not in ϕα or in θβ for
any β < α. (This excludes at most ℵ0 · card(α) constant symbols, so
there are some left.) Finally, in step 3, we can obtain the maximal set 
by use of Zorn’s lemma. The rest of the proof remains unchanged.

142
A Mathematical Introduction to Logic
COMPACTNESS THEOREM
(a) If  |= ϕ, then for some ﬁnite 0 ⊆
we have 0 |= ϕ.
(b) If every ﬁnite subset 0 of  is satisﬁable, then  is satis-
ﬁable.
In particular, a set  of sentences has a model iff every ﬁnite subset
has a model.
PROOF
To prove part (a) of the compactness theorem, we simply
observe that
 |= ϕ ⇒ ⊢ϕ
⇒0 ⊢ϕ for some ﬁnite 0 ⊆, deductions being ﬁnite
⇒0 |= ϕ.
Part (b) has a similar proof. If every ﬁnite subset of  is sat-
isﬁable, then by soundness every ﬁnite subset of  is consistent.
Thus  is consistent, since deductions are ﬁnite. So by complete-
ness,  is satisﬁable. (Actually parts (a) and (b) are equivalent;
cf. Exercise 3 of Section 1.7.)
⊣
When a person ﬁrst hears of the compactness theorem, his natural
inclination is to try to combine (by some algebraic or set-theoretic op-
eration) the structures in which the various ﬁnite subsets are satisﬁed,
in such a way as to obtain a structure in which the entire set is satisﬁed.
In fact, such a proof is possible; the operation to use is the ultraprod-
uct construction. But we will refrain from digressing further into this
intriguing possibility.
Notice that the compactness theorem involves only semantical no-
tions of Section 2.2; it does not involve deductions at all. And there are
proofs that avoid deductions. The same remarks apply to the following
theorem.
⋆ENUMERABILITY THEOREM
For a reasonable language, the set of valid
wffs can be effectively enumerated.
By a reasonable language we mean one whose set of parameters can
be effectively enumerated and such that the two relations
{⟨P, n⟩| P is an n-place predicate symbol}
and
{⟨f, n⟩| f is an n-place function symbol}
are decidable. For example, any language with only ﬁnitely many pa-
rameters (such a language will be called a ﬁnite language) is certainly
reasonable, because ﬁnite sets are always decidable. On the other hand,
a reasonable language must be countable, since we cannot effectively
enumerate an uncountable set. (In fact, a stronger statement applies: As

Chapter 2:
First-Order Logic
143
in Section 1.7, a suitable input/output format is needed in which the
underlying set of symbols communicated is ﬁnite, which implies that
the set of all strings is countable.)
A precise version of this theorem will be given in Section 3.4. (See
especially item 20 there.) The proofs of the two versions are in essence
the same.
PROOF.
The essential fact is that , and hence the set of deductions,
is decidable.
Suppose that we are given some expression ε. (The assumption
of reasonableness enters already here. There are only countably
many things eligible to be given by one person to another.) We
want to decide whether or not ε is in . First we check that
ε has the syntactical form necessary to be a formula. (For sen-
tential logic we gave detailed instructions for such a check; see
Section 1.3. Similar instructions can be given for ﬁrst-order lan-
guages, by using Section 2.3.) If ε passes that test, we then check
(by constructing a truth table) to see if ε is a generalization of a
tautology. If not, then we proceed to see if ε has the syntactical
form necessary to be in axiom group 2. And so forth. If ε has not
been accepted by the time we ﬁnish with axiom group 6, then ε
is not in .
(The above is intended to convince the reader that he really can
tell members of  from nonmembers. The reader who remains
dubious can look forward to the rerun in Section 3.4.)
Since  is decidable, the set of tautological consequences of
 is effectively enumerable; see Theorem 17G. But
{α | α is a tautological consequence of }
= {α | ⊢α} by Theorem 24B,
= {α | α is valid}.
⊣
An alternative to the last paragraph of this proof is the following
argument, which is possibly more illuminating: First we claim that the
set of deductions (from ∅) is decidable. For given a ﬁnite sequence
α0, . . . , αn we can examine each αi in turn to see if it is in  or is
obtainable by modus ponens from earlier members of the sequence.
Then to enumerate the validities, we begin by enumerating all ﬁnite
sequences of wffs. We look at each sequence as it is produced and
decide whether or not it is a deduction. If not, we discard it. But if it is,
then we put its last member on the list of validities. Continuing in this
way, we generate — in an inefﬁcient way — a list on which any valid
formula will eventually appear.
⋆COROLLARY 25F
Let  be a decidable set of formulas in a reason-
able language.

144
A Mathematical Introduction to Logic
(a) The set of theorems of  is effectively enumerable.
(b) The set {ϕ |  |= ϕ} of formulas logically implied by  is
effectively enumerable.
(Of course parts (a) and (b) refer to the same set. This corollary
includes the enumerability theorem itself, in which  = ∅.)
PROOF 1.
Enumerate the validities; whenever you ﬁnd one of the
form
αn →· · · →α1 →α0,
check to see if αn, . . . , α1 are in . If so, then put α0 on the list of
theorems of . In this way, any theorem of  is eventually listed.
⊣
PROOF 2.
∪ is decidable, so its set of tautological consequences
is effectively enumerable. And that is just the set we want.
⊣
For example, let  be the (decidable) set of axioms for any of the
usual systems of set theory. Then this corollary tells us that the set of
theorems of set theory is effectively enumerable.
More generally, in setting up some axiomatic theory, it is natural
to insist that the set of axioms be decidable. After all, we want proofs
from these axioms to be convincing arguments that can be veriﬁed. Part
of the veriﬁcation process involves checking that statements alleged
to be axioms are indeed axioms. For this to be possible, the set of
axioms needs to be decidable (or at least semidecidable). This has the
consequence that the set of theorems that follow from the axioms is
effectively enumerable.
⋆COROLLARY 25G
Assume that  is a decidable set of formulas in
a reasonable language, and for any sentence σ either  |= σ or
 |= ¬ σ. Then the set of sentences implied by  is decidable.
PROOF.
If  is inconsistent, then we have simply the (decidable)
set of all sentences. So assume that  is consistent. Suppose
that we are given a sentence σ and asked to decide whether or
not  |= σ. We can enumerate the theorems of  and look for
σ or ¬ σ. Eventually one will appear, and then we know the
answer.
⊣
(Observe that this proof actually describes two decision procedures.
One is correct when  is inconsistent, the other is correct when  is con-
sistent. So in either case a decision procedure exists. But we cannot nec-
essarily determine effectively, given a ﬁnite description of , which one
is to be used. A set is decidable if there exists a decision procedure for it.
That is not the same as having a known decision procedure in our hands.)

Chapter 2:
First-Order Logic
145
It should be remarked that our proofs of enumerability cannot, in
general, be strengthened to proofs of decidability. For almost all lan-
guages the set of validities is not decidable. (See Church’s Theorem,
Section 3.5.)
Historical Notes
The completeness theorem (for countable languages) was contained in
the 1930 doctoral dissertation of Kurt G¨odel. (It is not to be confused
with the “G¨odel incompleteness theorem,” published in 1931. We will
consider this latter result in Chapter 3.) The compactness theorem (for
countable languages) was given as a corollary.
The compactness theorem for uncountable languages was implicit
in a 1936 paper by Anatolii Mal′cev. His proof used Skolem functions
(cf. Section 4.2) and the compactness theorem of sentential logic. The
ﬁrst explicit statement of the compactness theorem for uncountable
languages was in a 1941 paper by Mal′cev.
The enumerability theorem, as well as following from G¨odel’s 1930
work, was also implicit in results published in 1928 by Thoralf
Skolem.
The proof we have given for the completeness theorem is patterned
after one given by Leon Henkin in his dissertation, published in 1949.
Unlike G¨odel’s original proof, Henkin’s proof generalizes easily to lan-
guages of any cardinality.
Exercises
1. (Semantical rule EI) Assume that the constant symbol c does not
occur in ϕ, ψ, or , and that ; ϕx
c |= ψ. Show (without using the
soundness and completeness theorems) that ; ∃x ϕ |= ψ.
2. Prove the equivalence of parts (a) and (b) of the completeness the-
orem. Suggestion:  |= ϕ iff  ∪{¬ ϕ} is unsatisﬁable. And 
is satisﬁable iff  ̸|= ⊥, where ⊥is some unsatisﬁable, refutable
formula like ¬ ∀x x = x.
Remark: Similarly, the soundness theorem is equivalent to the
statement that every satisﬁable set of formulas is consistent.
3. Assume that  ⊢ϕ and that P is a predicate symbol which occurs
neither in  nor in ϕ. Is there a deduction of ϕ from  in which
P nowhere occurs? Suggestion: There are two very different ap-
proaches to this problem. The “soft” approach makes use of two
languages, one that contains P and one that does not. The “hard”
approach considers the question whether P can be systematically
eliminated from a given deduction of ϕ from .

146
A Mathematical Introduction to Logic
4. Let  = {¬ ∀v1Pv1, Pv2, Pv3, . . .}. Is  consistent? Is  satisﬁ-
able?
5. Show that an inﬁnite map can be colored with four colors iff every
ﬁnite submap of it can be. Suggestion: Take a language having a
constantsymbolforeachcountryandhavingfourone-placepredicate
symbols for the colors. Use the compactness theorem.
6. Let 1 and 2 be sets of sentences such that nothing is a model
of both 1 and 2. Show that there is a sentence τ such that
Mod 1 ⊆Mod τ and Mod 2 ⊆Mod ¬ τ. (This can be stated:
Disjoint EC classes can be separated by an EC class.) Suggestion:
1 ∪2 is unsatisﬁable; apply compactness.
7. The completeness theorem tells us that each sentence either has a
deduction (from ∅) or has a counter-model (i.e., a structure in which
it is false). For each of the following sentences, either show there is
a deduction or give a counter-model.
(a) ∀x(Qx →∀y Qy)
(b) ( ∃x Px →∀y Qy) →∀z(Pz →Qz)
(c) ∀z(Pz →Qz) →( ∃x Px →∀y Qy)
(d) ¬ ∃y ∀x(Pxy ↔¬ Pxx)
8. Assume the language (with equality) has just the parameters ∀and
P, where P is a two-place predicate symbol. Let A be the structure
with |A| = Z, the set of integers (positive, negative, and zero) and
with ⟨a, b⟩∈PA iff |a −b| = 1. Thus A looks like an inﬁnite
graph:
· · · ←→• ←→• ←→• ←→· · ·
Show that there is an elementarily equivalent structure B that is not
connected. (Being connected means that for every two members of
|B|, there is a path between them. A path — of length n — from a
to b is a sequence ⟨p0, p1, . . . , pn⟩with a = p0 and b = pn and
⟨pi, pi+1⟩∈PB for each i.) Suggestion: Add constant symbols c
and d. Write down sentences saying c and d are far apart. Apply
compactness.
9. In Section 2.4 we used a certain set  of logical axioms. That set
can be altered, within limits.
(a) Suppose we add to  some formula ψ that is not valid. Show
that the soundness theorem now fails.
(b) At the other extreme, suppose we take no logical axioms at all:
 = ∅. Show that the completeness theorem now fails.
(c) Suppose we modify  by adding one new valid formula. Explain
why both the soundness theorem and the completeness theorem
still hold.

Chapter 2:
First-Order Logic
147
SECTION 2.6
Models of Theories
In this section we will leave behind deductions and logical axioms.
Instead we return to topics discussed in Section 2.2. But now, in the
presence of the theorems of the preceding section, we will be able to
answer more questions than we could before.
Finite Models
Some sentences have only inﬁnite models, for example, the sentence
saying that < is an ordering with no largest element. The negation of
such a sentence is ﬁnitely valid, that is, it is true in every ﬁnite structure.
It is also possible to have sentences having only ﬁnite models. For
example, any model of ∀x ∀y x = y has cardinality 1. But if all models
of  are ﬁnite, then there is a ﬁnite bound on the size of the models, by
the following theorem.
THEOREM 26A
If a set  of sentences has arbitrarily large ﬁnite
models, then it has an inﬁnite model.
PROOF.
For each integer k ≥2, we can ﬁnd a sentence λk that
translates, “There are at least k things.” For example,
λ2 = ∃v1 ∃v2v1 ̸= v2,
λ3 = ∃v1 ∃v2 ∃v3(v1 ̸= v2 ∧v1 ̸= v3 ∧v2 ̸= v3).
Consider the set
 ∪{λ2, λ3, . . .}.
By hypothesis any ﬁnite subset has a model. So by compactness
the entire set has a model, which clearly must be inﬁnite.
⊣
For example, it is a priori conceivable that there might be some very
subtle equation of group theory that was true in every ﬁnite group but
false in every inﬁnite group. But by the above theorem, no such equation
exists.
The proof to this theorem illustrates a useful method for obtaining a
structure with given properties. One writes down sentences (possibly in
an expanded language) stating the properties one wants. One then argues
that any ﬁnite subset of the sentences has a model. The compactness
theorem does the rest. We will see more examples of this method in the
coming pages.
COROLLARY 26B
The class of all ﬁnite structures (for a ﬁxed lan-
guage) is not EC. The class of all inﬁnite structures is not EC.

148
A Mathematical Introduction to Logic
PROOF.
The ﬁrst sentence follows immediately from the theorem.
If the class of all inﬁnite structures is Mod τ, then the class of all
ﬁnite structures is Mod ¬ τ. But this class isn’t even EC, much
less EC.
⊣
The class of inﬁnite structures is EC, being Mod{λ2, λ3, . . .}.
Next we want to consider decision problems connected with ﬁnite
structures. For any structure A, deﬁne the theory of A, written Th A,
to be the set of all sentences true in A. For a ﬁnite structure A, is Th A
decidable? Is the set of sentences having ﬁnite models decidable?
The following observations will help here:
1. Any ﬁnite structure A is isomorphic to a structure with universe
{1, 2, . . . , n} where n is the size of A (i.e., n = card |A|). The idea here
is, where |A| = {a1, . . . , an}, simply to replace ai by i.
For example, suppose the language has only the parameters ∀and
a two-place predicate symbol E (for the “edge” relation in a directed
graph). Consider the ﬁnite structure B with universe |B| consisting of
a set of four distinct objects {a, b, c, d}, and with
EB = {⟨a, b⟩, ⟨b, a⟩, ⟨b, c⟩, ⟨c, c⟩}.
Then B is isomorphic to the structure
({1, 2, 3, 4}; {⟨1, 2⟩, ⟨2, 1⟩, ⟨2, 3⟩, ⟨3, 3⟩}).
But there are other possibilities here; if we had focused on the mem-
bers of |B| in the order b, a, d, c then we would have arrived at the
isomorphic (but different) structure
({1, 2, 3, 4}; {⟨1, 2⟩, ⟨2, 1⟩, ⟨1, 4⟩, ⟨4, 4⟩}).
2. A ﬁnite structure of the sort just described can, for a ﬁnite lan-
guage, be speciﬁed by a ﬁnite string of symbols. In the example,
({1, 2, 3, 4}; {⟨1, 2⟩, ⟨2, 1⟩, ⟨2, 3⟩, ⟨3, 3⟩}),
the above line completely speciﬁes the structure, and it can be written
down with numerals in base 10 (or your favorite base) along with punc-
tuation and delimiters (e.g., parentheses). Therefore such a structure can
be communicated to another person or to a machine. The ﬁnite string of
symbols can be written down in a suitable input format.
3. Given a ﬁnite structure A for a ﬁnite language, with universe
{1, . . . , n} (and by the preceding observation, it is possible to be given
such an object), a wffϕ, and an assignment sϕ of numbers in this universe
to the variables free in ϕ (there are only ﬁnitely many, of course), we
can effectively decide whether or not |=A ϕ[sϕ].

Chapter 2:
First-Order Logic
149
For example, given
B = ({1, 2, 3, 4}; {⟨1, 2⟩, ⟨2, 1⟩, ⟨2, 3⟩, ⟨3, 3⟩})
ϕ = ∀v1(( ¬ ∀v2 ¬ Ev2v1) →Ev1v1),
we can organize the computation in the tree form shown in Fig. 9. We
ﬁnd that the sentence ϕ, which says “Anything in the range of E is
related to itself,” is false in B.
Figure 9. Checking the sentence ∀v1((¬∀v2¬Ev2v1) →Ev1v1) in a structure
with universe of size 4.
At each leaf in the tree (i.e., each minimal vertex), we have an atomic
formula and we do a “table look-up” to see if it is satisﬁed. Notice that
each quantiﬁer triggers a search through the n-element universe. For
a formula ϕ with k quantiﬁers, the number of leaves in the tree will
be bounded by a polynomial in n of degree k. If the language contains
function symbols, then each term needs to be evaluated, using the (ﬁnite)
function provided by the structure.
In particular, restricting ourselves to sentences, we can effectively
decide, given A as above and a sentence σ, whether or not A is a
model of σ. (In fact here σ could even be a second-order sentence, as in
Chapter 4.)
⋆THEOREM 26C
For a ﬁnite structure A in a ﬁnite language, Th A is
decidable.

150
A Mathematical Introduction to Logic
PROOF 1.
By observation 1, we can replace A by an isomorphic
structure with universe of the form {1, . . . , n}, without changing
which sentences are true. Then apply observation 3.
⊣
PROOF 2.
By Exercise 17(a) of Section 2.2, there is a sentence δA
that speciﬁes A up to isomorphism. It follows that
Th A = {σ | δA |= σ}.
(Details: For “⊆” note that if σ is true in A, then it is true in all
isomorphic copies, and hence in all models of δA. So δA |= σ. The
other direction is simpler; if δA |= σ then σ is true in all models
of δA, of which A is one.) Apply Corollary 25G, noting that for
each σ, either |=A σ or |=A ¬ σ.
⊣
4. Given a sentence σ and a positive integer n, we can effectively
decide whether or not σ has an n-element model. That is, the binary
relation
{⟨σ, n⟩| σ has a model of size n}
is decidable.
The key idea is that there are only ﬁnitely many structures to check,
and we can do that. The sentence σ has a model of size n if and only
if it has a model with universe {1, . . . , n} by observation 1. With the
language restricted to the parameters that occur in σ, there are only
ﬁnitely many such structures, and we can systematically generate all of
them. (For example, if the only parameters are ∀and a 2-place predicate
symbol, then there are 2n2 different structures.) Applying observation 3,
we test to see if any of these are models of σ.
5. The spectrum of a sentence σ is deﬁned to be {n | σ has a model
of size n}. See Exercise 16 in Section 2.2. It follows from observation 4
that the spectrum of any sentence is a decidable set of positive integers.
⋆THEOREM 26D
For a ﬁnite language, {σ | σ has a ﬁnite model} is
effectively enumerable.
PROOF.
Here is a semidecision procedure: Given σ, ﬁrst check to
see if it has a model of size 1, by using observation 4. If not, try
size 2. Keep going.
⊣
⋆COROLLARY 26E
Assume the language is ﬁnite, and let  be the set
of sentences true in every ﬁnite structure. Then its complement,
, is effectively enumerable.
PROOF.
For a sentence σ,
σ ∈ ⇐⇒(¬ σ) has a ﬁnite model.
We can apply the above semidecision procedure to (¬ σ).
⊣

Chapter 2:
First-Order Logic
151
It follows (by Theorem 17F) that  is decidable if and only if it
is effectively enumerable. But this does not happen. We state without
proof the following:
⋆TRAKHTENBROT’S THEOREM (1950)
The set of sentences
 = {σ | σ is true in every ﬁnite structure}
is not in general decidable or effectively enumerable.
Thus the analogue of the enumerability theorem for ﬁnite structures
only is false.
Size of Models
In the proof of the completeness theorem in Section 2.5, we started with
a consistent set  and formed a structure A/E in which it was satisﬁed.
How large was that structure? We claim that if our initial language
was countable, then |A/E| is a countable set. Thus a consistent set of
sentences in a countable language has a countable model.
A/E was constructed from a preliminary structure A. The universe
of A was the set of all terms in the language obtained by adding a
countable set of new constant symbols. But the augmented language
was still countable, so the set of all expressions (and hence the set of all
terms) was countable. That is, |A| was countable.
The universe of A/E consisted of equivalence classes of members
of A, so it, too, is a countable set. (We can map |A/E| one-to-one into
|A| by assigning to each equivalence class some chosen member.) The
conclusion is that A/E is a countable structure, as claimed.
L¨OWENHEIM–SKOLEM THEOREM (1915)
(a) Let  be a satisﬁable set
of formulas in a countable language. Then  is satisﬁable in some
countable structure.
(b) Let  be a set of sentences in a countable language. If 
has any model, then it has a countable model.
PROOF.
Firstobservethat isconsistent,bythesoundnesstheorem.
Then by the completeness theorem (plus the foregoing remarks)
it can be satisﬁed in a countable structure.
⊣
(There is another, more direct proof of this theorem that will be indi-
cated in Section 4.2; see especially Exercise 1 there. That proof, which
does not use a deductive calculus, begins with an arbitrary structure A
in which  can be satisﬁed, and by various manipulations extracts from
it a suitable countable substructure in which  is still satisﬁed.)
The L¨owenheim–Skolem theorem was published by Leopold
L¨owenheim in 1915 for the case where  is a singleton; Thoralf Skolem
in 1920 extended this to a possibly inﬁnite . The theorem marked a new
phase in mathematical logic. Earlier work had been done in the direction

152
A Mathematical Introduction to Logic
of formalizing mathematics by means of formal languages and deduc-
tive calculi; this work was initiated largely by Gottlob Frege in 1879.
For example, the Principia Mathematica (1910–1913) of Whitehead
and Russell carried out such a formalization in great detail. But the
modern phase began when logicians stepped back and began to prove
results about the formal systems they had been constructing. Other early
work in this trend was done by David Hilbert, Emil Post, Kurt G¨odel
(as mentioned before), Alfred Tarski, and others.
For a sample application of the L¨owenheim–Skolem theorem, let
AST be your favorite set of axioms for set theory. We certainly hope
these axioms are consistent. And so they have some model. By the
L¨owenheim–Skolem theorem, the axioms have a countable model S.
Of course, S is also a model of all the sentences logically implied by
AST. One of these sentences asserts (when translated back into English
according to the intended translation) that there are uncountably many
sets. There is no contradiction here, but the situation is sufﬁciently
puzzling to be called “Skolem’s paradox.” It is true that in the structure
S there is no point that satisﬁes the formal deﬁnition of being a one-
to-one map of the natural numbers onto the universe. But this in no
way excludes the possibility of there being (outside S) some genuine
function providing such a one-to-one correspondence.
Recall that the theory of A, written Th A, is the set of all sentences
true in A. We can apply the L¨owenheim–Skolem theorem (with  =
Th A) to prove that for any structure A for a countable language, there
is a countable elementarily equivalent structure B. If B is a model of
Th A then A ≡B because
|=A σ ⇒σ ∈Th A ⇒
|=B σ
and
̸|=A σ ⇒|=A ¬ σ ⇒( ¬ σ) ∈Th A ⇒|=B ¬ σ ⇏|=B σ.
For example, the real ﬁeld (R; 0, 1, +, ·) is an uncountable structure for
a ﬁnite language. Therefore there must be some countable structure (also
a ﬁeld) satisfying exactly the same sentences. (In fact Tarski showed we
can take the ﬁeld of algebraic real numbers for this.)
EXAMPLE.
Consider the structure
N = (N; 0, S, <, +, ·).
We claim that there is a countable structure M0, elementarily
equivalent to N (so that M0 and N satisfy exactly the same sen-
tences) but not isomorphic to N.
PROOF.
We will construct M0 by using the compactness theorem.
Expand the language by adding a new constant symbol c. Let
 = {0 < c, S0 < c, SS0 < c, . . .}.

Chapter 2:
First-Order Logic
153
We claim that  ∪Th N has a model. For consider a ﬁnite
subset. That ﬁnite subset is true in
Nk = (N; 0, S, <, +, ·, k)
(where k = cNk) for some large k. So by the compactness theorem
 ∪Th N has a model.
By the L¨owenheim–Skolem theorem, ∪Th N has a countable
model
M =

|M|; 0M, SM, <M, +M, ·M, cM
.
Let M0 be the restriction of M to the original language:
M0 =

|M|; 0M, SM, <M, +M, ·M
.
Since M0 is a model of Th N, we have M0 ≡N:
|=N σ ⇒σ ∈Th N ⇒
|=M0 σ
̸|=N σ ⇒¬ σ ∈Th N ⇒
|=M0 ¬ σ ⇒
̸|=M0 σ.
We leave it to the reader to verify that M0 is not isomorphic to
N. (|M0| contains the “inﬁnite” number cM.)
⊣
What about uncountable1 languages? Assume that in the proof of
the completeness theorem we started with a set  in a language of
cardinality λ. We claim that in this case, the structure A/E we made
has cardinality ≤λ.
A/E was constructed from that preliminary structure A. The universe
of A was the set of all terms in the language obtained by adding λ new
constant symbols. So the augmented language still had cardinality λ.
So (by Theorem 0D) the set of all expressions (and hence the set of all
terms) had cardinality ≤λ. (In fact, because we had at least the λ new
constant symbols, the set of terms had cardinality exactly λ.)
The universe of A/E consisted of equivalence classes of members of
A, so card |A/E| ≤card |A|. (We can map |A/E| one-to-one into |A|
by assigning to each equivalence class some chosen member, but now
we may need the axiom of choice.) Thus, when the smoke had cleared,
 was satisﬁed in a structure A/E of cardinality ≤λ.
L¨OWENHEIM–SKOLEM THEOREM
(a) Let  be a satisﬁable set of for-
mulas in a language of cardinality λ. Then  is satisﬁable in some
structure of size ≤λ.
(b) Let  be a set of sentences in a language of cardinality λ.
If  has any model, then it has a model of cardinality ≤λ.
1 The reader who wishes to avoid uncountable cardinals is advised to skip to the subsection
Theories.

154
A Mathematical Introduction to Logic
The earlier version of the L¨owenheim–Skolem theorem is a special
case of this version, wherein λ = ℵ0.
Suppose that we have an uncountable structure A for a countable
language. By the L¨owenheim–Skolem theorem (applied to Th A) there
is a countable B that is a model of Th A, and hence A ≡B, as noted
previously.
Conversely, suppose that we start with a countable structure B. Is
there an uncountable A such that A ≡B? If B is ﬁnite (and the language
includes equality), then this is impossible. But if B is inﬁnite, then there
willbesuchanA,bythefollowing“upwardanddownwardL¨owenheim–
Skolem theorem.” The upward part is due to Tarski, whence the “T” of
“LST.”
LST THEOREM
Let  be a set of formulas in a language of cardinality
λ, and assume that  is satisﬁable in some inﬁnite structure. Then
for every cardinal κ ≥λ, there is a structure of cardinality κ in
which  is satisﬁable.
PROOF.
Let A be the inﬁnite structure in which  is satisﬁable.
Expand the language by adding a set C of κ new constant symbols.
Let
 = {c1 ̸= c2 | c1, c2 distinct members of C}.
Then every ﬁnite subset of  ∪ is satisﬁable in the structure
A, expanded to assign distinct objects to the ﬁnitely many new
constant symbols in the subset. (Since A is inﬁnite, there is room
to accommodate any ﬁnite number of these.) So by compactness
 ∪ is satisﬁable, and by the L¨owenheim–Skolem theorem it
is satisﬁable in a structure B of cardinality ≤κ. (The expanded
language has cardinality λ + κ = κ.) But any model of  clearly
has cardinality ≥κ. So B has cardinality κ; restrict B to the
original language.
⊣
COROLLARY 26F
(a) Let  be a set of sentences in a countable lan-
guage. If  has some inﬁnite model, then  has models of every
inﬁnite cardinality.
(b) Let A be an inﬁnite structure for a countable language. Then
for any inﬁnite cardinal λ, there is a structure B of cardinality λ
such that B ≡A.
PROOF.
(a) Take  = , λ = ℵ0 in the theorem.
(b) Take  = Th A in part (a).
⊣
Consider a set  of sentences, to be thought of as nonlogical ax-
ioms. (For example,  might be a set of axioms for set theory or a set
of axioms for number theory.) Call  categorical iff any two models
of  are isomorphic. The above corollary implies that if  has any

Chapter 2:
First-Order Logic
155
inﬁnite models, then  is not categorical. There is, for example, no
set of sentences whose models are exactly the structures isomorphic
to (N; 0, S, +, ·). This is indicative of a limitation in the expressive-
ness of ﬁrst-order languages. (As will be seen in Section 4.1, there are
categorical second-order sentences. But second-order sentences are pe-
culiar objects, obtained at the cost of holding the notion of subset ﬁxed,
immune from interpretation by structures.)
Theories
We deﬁne a theory to be a set of sentences closed under logical impli-
cation. That is, T is a theory iff T is a set of sentences such that for any
sentence σ of the language,
T |= σ ⇒σ ∈T.
(Note that we admit only sentences, not formulas, with free variables.)
For example, there is always a smallest theory, consisting of the
valid sentences of the language. At the other extreme there is the theory
consisting of all the sentences of the language; it is the only unsatisﬁable
theory.
For a class K of structures (for the language), deﬁne the theory of K
(written Th K) by the equation
Th K = {σ | σ is true in every member of K}.
(This concept arose previously in the special case K = {A}.)
THEOREM 26G
Th K is indeed a theory.
PROOF.
Any member of K is a model of Th K. Thus if σ is true
in every model of Th K, then it is true in every member of K.
Whence it belongs to Th K.
⊣
For example, if the parameters of the language are ∀, 0, 1, +, and ·,
and F is the class of all ﬁelds, then Th F, the theory of ﬁelds, is simply
the set of all sentences of the language which are true in all ﬁelds. If F0
is the class of ﬁelds of characteristic 0, then Th F0 is the theory of ﬁelds
of characteristic 0.
Recall that for a set  of sentences, we deﬁned Mod  to be the class
of all models of . Th Mod  is then the set of all sentences which are
true in all models of . But this is just the set of all sentences logically
implied by . Call this set the set of consequences of , Cn . Thus
Cn  = {σ |  |= σ}
= Th Mod .
For example, set theory is the set of consequences of a certain set of
sentences, known, unsurprisingly, as axioms for set theory. A set T of
sentences is a theory iff T = Cn T .

156
A Mathematical Introduction to Logic
A theory T is said to be complete iff for every sentence σ, either
σ ∈T or (¬ σ) ∈T . For example, for any one structure A, Th{A}
(written, as before, “Th A”) is always a complete theory. In fact, it is
clear upon reﬂection that Th K is a complete theory iff any two members
of K are elementarily equivalent. And a theory T is complete iff any
two models of T are elementarily equivalent.
For example, the theory of ﬁelds is not complete, since the sentences
1 + 1 = 0,
∃x x · x = 1 + 1
are true in some ﬁelds but false in others. The theory of algebraically
closed ﬁelds of characteristic 0 is complete, but this is by no means
obvious. (See Theorem 26J.)
∗DEFINITION.
A theory T is axiomatizable iff there is a decidable set
 of sentences such that T = Cn .
DEFINITION.
A theory T is ﬁnitely axiomatizable iff T = Cn  for
some ﬁnite set  of sentences.
In the latter case we have T = Cn{σ} (written “T = Cn σ”), where
σ is the conjunction of the ﬁnitely many members of . For example,
the theory of ﬁelds is ﬁnitely axiomatizable. For the class F of ﬁelds
is Mod , where  is the ﬁnite set of ﬁeld axioms. And the theory of
ﬁelds is Th Mod  = Cn .
The theory of ﬁelds of characteristic 0 is axiomatizable, being Cn 0,
where 0 consists of the (ﬁnitely many) ﬁeld axioms together with the
inﬁnitely many sentences:
1 + 1 ̸= 0,
1 + 1 + 1 ̸= 0,
. . . .
This theory is not ﬁnitely axiomatizable. To prove this, ﬁrst note that no
ﬁnite subset of 0 has the entire theory as its set of consequences. (For
that ﬁnite subset would be true in some ﬁeld of very large characteristic.)
Then apply the following:
THEOREM 26H
If Cn  is ﬁnitely axiomatizable, then there is a ﬁnite
0 ⊆ such that Cn 0 = Cn .
PROOF.
Say that Cn  is ﬁnitely axiomatizable; then Cn  = Cn τ
for some one sentence τ. In general τ /∈, but at least  |= τ.
(τ ∈Cn τ = Cn .) By the compactness theorem there is a ﬁnite
0 ⊆ such that 0 |= τ. Then
Cn τ ⊆Cn 0 ⊆Cn ,
whence equality holds.
⊣

Chapter 2:
First-Order Logic
157
We can now restate Corollaries 25F and 25G in the present termi-
nology:
⋆COROLLARY 26I
(a) An axiomatizable theory (in a reasonable lan-
guage) is effectively enumerable.
(b) A complete axiomatizable theory (in a reasonable lan-
guage) is decidable.
We can represent the relationships among these concepts by means
of a diagram (in which we have included the results of Exercise 6):
For example, a theory that is given in axiomatic form (such as
Zermelo–Fraenkel set theory, which is Cn AZF for a certain set AZF)
is effectively enumerable. We will argue in Section 3.7 that set the-
ory (if consistent) is not decidable and not complete. Number theory,
the theory of the structure (N; 0, S, <, +, ·, E), is complete but is not
effectively enumerable and hence not axiomatizable (Section 3.5).
We can use part (b) of the preceding corollary to establish the de-
cidability of an axiomatizable theory, provided we can show that the
theory in question is complete. This can sometimes be done by means
of the Ło´s–Vaught test for completeness.
Say that a theory T is ℵ0-categorical iff all the inﬁnite countable
models of T are isomorphic. More generally, for a cardinal κ, say that T
is κ-categorical iff all models of T having cardinality κ are isomorphic.
ŁO´S–VAUGHT TEST (1954)
Let T be a theory in a countable lan-
guage. Assume that T has no ﬁnite models.
(a) If T is ℵ0-categorical, then T is complete.
(b) If T is κ-categorical for some inﬁnite cardinal κ, then T is
complete.
PROOF.
It sufﬁces to show for any two models A and B of T that
A ≡B. Since A and B are inﬁnite, there exist (by the LST
theorem) structures A′ ≡A and B′ ≡B having cardinality κ. A′
is isomorphic to B′, so we have
A ≡A′ ∼= B′ ≡B.
Thus A ≡B.
⊣
(If T is a theory in a language of cardinality λ, then we must demand
that λ ≤κ.)

158
A Mathematical Introduction to Logic
The converse to the Ło´s–Vaught test is false. That is, there are com-
plete theories which are not κ-categorical for any κ.
In Section 3.1 we will apply the Ło´s–Vaught test to prove the decid-
ability of the theory of the natural numbers with zero and successor. It
can also be used to prove the decidability of the theory of the complex
ﬁeld. But this proof will utilize an excursion into algebra.
THEOREM 26J
(a) The theory of algebraically closed ﬁelds of char-
acteristic 0 is complete.
⋆(b) The theory of the complex ﬁeld
C = (C; 0, 1, +, ·)
is decidable.
PROOF.
Let A be the class of algebraically closed ﬁelds of charac-
teristic 0. Then A = Mod(0 ∪), where 0 consists as before
of the axioms for ﬁelds of characteristic 0, and  consists of the
sentences
∀a ∀b ∀c(a ̸= 0 →∃x a · x · x + b · x + c = 0),
∀a ∀b ∀c ∀d(a ̸= 0 →∃x a · x · x · x + b · x · x + c · x + d = 0),
. . . .
The set 0 ∪ is decidable and Th A = Cn(0 ∪), so this
theory is axiomatizable. Part (a) of the theorem asserts that the
theory is also complete, whence it is decidable.
Part (b) follows from part (a). For we have C ∈A, whence
Th A ⊆Th C. The completeness of Th A implies that equality
holds; see Exercise 2.
To prove part (a), we apply the Ło´s–Vaught test. The models
of Th A are exactly the members of A. These are all inﬁnite. We
further claim that Th A is categorical in any uncountable cardinal-
ity. This is equivalent to saying that any two algebraically closed
ﬁelds of characteristic 0 having the same uncountable cardinality
are isomorphic.
This last assertion is a known result of algebra. We will sketch
the proof, for the interest of those readers familiar with this topic.
Any ﬁeld F is obtainable in the following way: (1) One begins
with the prime subﬁeld, which is determined to within isomor-
phism by the characteristic of F. (2) One takes a transcendental
extension, determined within isomorphism by the cardinality of
the transcendence basis, i.e., by the transcendence degree of F
(over its prime subﬁeld). (3) One ﬁnally takes some algebraic ex-
tension. We thus have a theorem of Steinitz: Two algebraically
closed ﬁelds are isomorphic iff they have the same characteristic
and the same transcendence degree.
If the transcendence degree of an inﬁnite ﬁeld F is κ, then the
cardinality of F is the larger of κ and ℵ0. Hence for an uncountable

Chapter 2:
First-Order Logic
159
ﬁeld, the cardinality equals the transcendence degree. So we con-
clude from Steinitz’s theorem that two algebraically closed ﬁelds
having the same characteristic and the same uncountable cardi-
nality are isomorphic.
⊣
The theory of the real ﬁeld
(R; 0, 1, +, ·)
is also decidable. But this result (which is due to Tarski) is much deeper
than the above theorem. The theory of the real ﬁeld is not categorical in
any inﬁnite cardinality, so the Ło´s–Vaught test cannot be applied.
As a ﬁnal application, we can show that the ordering of the rationals
is elementarily equivalent to the ordering of the reals,
(Q; <Q) ≡(R; <R),
where Q and R are the rationals and reals, respectively, and <Q and <R
are the corresponding orderings. To show elementary equivalence, we
show that both are models of some complete theory (which then must
coincide with the theory of each structure). The key fact is provided by
a theorem of Cantor: Any two countable dense linear orderings without
endpoints are isomorphic.
To give the details, we must back up a little. The language here has
equality and the parameters ∀and <. Let δ be the conjunction of the
following sentences:
1. Ordering axioms (trichotomy and transitivity):
∀x ∀y(x < y ∨x = y ∨y < x),
∀x ∀y(x < y →y ̸< x),
∀x ∀y ∀z(x < y →y < z →x < z).
2. Density:
∀x ∀y(x < y →∃z(x < z < y)).
3. No endpoints:
∀x ∃y ∃z(y < x < z).
The dense linear orderings without endpoints are, by deﬁnition, the
structures for this language that are models of δ. It is clear that they are
all inﬁnite. Furthermore, we claim that the theory of these orderings,
Cn δ, is ℵ0-categorical. This is provided by the following fact.
THEOREM 26K (CANTOR)
Any countable model of δ is isomorphic to
(Q, <Q).
We leave the proof to Exercise 4.

160
A Mathematical Introduction to Logic
We can now apply the Ło´s–Vaught test to conclude that Cn δ is
complete. Hence any two models of δ are elementarily equivalent; in
particular,
(Q; <Q) ≡(R; <R).
We can also conclude that these structures have decidable theories.
Prenex Normal Form
It will at times be convenient to move all the quantiﬁer symbols to the
left of other symbols. For example,
∀x(Ax →∀y Bxy)
is equivalent to
∀x ∀y(Ax →Bxy).
And
∀x(Ax →∃y Bxy)
is equivalent to
∀x ∃y(Ax →Bxy).
Deﬁne a prenex formula to be one of the form (for some n ≥0)
Q1x1 · · · Qnxn α,
where Qi is ∀or ∃and α is quantiﬁer-free.
PRENEX NORMAL FORM THEOREM
For any formula, we can ﬁnd a log-
ically equivalent prenex formula.
PROOF.
We will make use of the following quantiﬁer manipulation
rules.
Q1a.
¬ ∀x α |==| ∃x ¬ α.
Q1b.
¬ ∃x α |==| ∀x ¬ α.
Q2a.
(α →∀x β) |==| ∀x(α →β) for x not free in α.
Q2b.
(α →∃x β) |==| ∃x(α →β) for x not free in α.
Q3a.
( ∀x α →β) |==| ∃x(α →β) for x not free in β.
Q3b.
( ∃x α →β) |==| ∀x(α →β) for x not free in β.
Q1 is clear; for the others see the examples in Section 2.4 and
Exercise 8 there.
Wenowshowbyinductionthateveryformulahasanequivalent
prenex formula.
1. For atomic formulas this is vacuous, as any quantiﬁer-free
formula is trivially a prenex formula.
2. If α is equivalent to the prenex α′, then ∀x α is equivalent
to the prenex ∀x α′.

Chapter 2:
First-Order Logic
161
3. If α is equivalent to the prenex α′, then ¬ α is equivalent to
¬ α′. Apply Q1 to ¬ α′ to obtain a prenex formula; for example,
¬ ∀x ∃y ∃z β |==| ∃x ∀y ∀z ¬ β.
4. Finally we come to the case of α →β. By inductive hy-
pothesis we have prenex formulas α′ and β′ equivalent to α and
β, respectively. By our theorems on alphabetic variants, we may
further assume that any variable that occurs quantiﬁed in one of
the formulas α′ and β′ does not occur at all in the other. We
then use Q2 and Q3 to obtain a prenex formula equivalent to
α′ →β′ (and hence to α →β). Observe that there is some lati-
tude in the order in which the rules Q2 and Q3 are applied. For
example,
∀x ∃y ϕ →∃u ψ
(where x and y do not occur in ψ, u does not occur in ϕ) is
equivalent to any of the following:
∃x ∀y ∃u(ϕ →ψ),
∃x ∃u ∀y(ϕ →ψ),
∃u ∃x ∀y(ϕ →ψ).
⊣
Retrospectus
At the beginning of this book it was stated that symbolic logic is a
mathematical model of deductive thought. This is as good a time as
any to reﬂect on that statement, in the light of the material treated
thus far.
As a ﬁrst example, consider a mathematician working in set theory.
He uses a language with an equality symbol, a symbol ∈for member-
ship, and numerous deﬁned symbols (∅, ∪, and others). In principle the
deﬁned symbols could be eliminated and any sentence replaced by an
equivalent sentence in which the deﬁned symbols did not appear. (In
this connection see Section 2.7, where this topic is treated systemati-
cally.) He takes as primitive (or undeﬁned) notions the concepts of set
and membership. He adopts some set AST of axioms involving these
concepts. He asserts that for certain sentences (his theorems), these
sentences are true provided the axioms are true, regardless of what the
undeﬁned notions of set and membership actually mean. In support
of these assertions he offers proofs, which are ﬁnitely long arguments
intended to convince his colleagues of the correctness of the assertions.
In terms of ﬁrst-order logic we can describe all this as follows: The
language here is a ﬁrst-order language with equality and a two-place
predicate symbol ∈. Thus ∀and ∈are the only parameters open to
interpretation. There is a certain set AST of sentences in this language

162
A Mathematical Introduction to Logic
singled out as being the set of (nonlogical) axioms. Then certain other
sentences are logical consequences of AST, i.e., are true in any model of
AST. If τ is a consequence of AST (and only then), there is a deduction
of τ from AST.
Next consider a more typical case of the hypothetical working math-
ematician, that of the algebraist or analyst. The algebraist uses axioms
for (say) group theory, but he also employs some amount of set theory.
Similarly, the analyst deals with sentences that involve both numbers
and sets of numbers. In both cases it is generally recognized that one
could, in principle, convert the assertions of algebra and analysis to as-
sertions of set theory. And then the remarks of the preceding paragraph
again apply.
Theinterestthatsymboliclogicholdsforthemathematicianislargely
due to the accuracy with which it mirrors mathematical deductions. In
the long run, it will surely be useful to understand the fundamental
processes of doing mathematics.
There remains the question of the accuracy with which ﬁrst-order
logic mirrors nonmathematical deductive thought. Logic, symbolic and
nonsymbolic, has always formed a traditional part of the philosophical
study of the process by which people come to hold certain ideas. Non-
mathematical examples to which ﬁrst-order logic applies are provided
by a vast array of frivolous situations. Lewis Carroll gave such exam-
ples, one of which inferred that babies cannot manage crocodiles from
the three hypotheses: (1) Babies are illogical. (2) Nobody is despised
who can manage a crocodile. (3) Illogical persons are despised.
But what of nonfrivolous situations? Here the applicability is ob-
scured by the fact that we usually do not make explicit the assump-
tions we use in drawing conclusions. There are speciﬁc areas (in di-
verse ﬁelds such as physics, medicine, and law) where assumptions
not only can be made explicit but are being made explicit. In some
cases it appears that less than the full versatility of ﬁrst-order logic is
required to formalize the real-life deductions. Possibly in other cases —
ranging from everyday life to quantum mechanics — more features may
be necessary.
Exercises
1. Show that the following sentences are ﬁnitely valid (i.e., that they
are true in every ﬁnite structure):
(a) ∃x ∃y ∃z[(Px f x →Pxx) ∨(Pxy ∧Pyz ∧¬ Pxz)]
(b) ∃x ∀y ∃z[(Qzx →Qzy) →(Qxy →Qxx)]
Suggestion: Show that any model of the negation must be inﬁnite.
2. Let T1 and T2 be theories (in the same language) such that (i) T1 ⊆
T2, (ii) T1 is complete, and (iii) T2 is satisﬁable. Show that T1 = T2.

Chapter 2:
First-Order Logic
163
3. Establish the following facts:
(a) 1 ⊆2 ⇒Mod 2 ⊆Mod 1.
K1 ⊆K2 ⇒Th K2 ⊆Th K1.
(b)  ⊆Th Mod  and K ⊆Mod Th K.
(c) Mod  = Mod Th Mod  and Th K = Th Mod ThK. (Part
(c) follows from (a) and (b).)
4. Prove that any two countable dense linear orderings without end-
points are isomorphic (Theorem 26K). Suggestions: Let A and B
be such structures with |A| = {a0, a1, . . .} and |B| = {b0, b1, . . .}.
Construct an isomorphism in stages; at stage 2n be sure an is paired
with some suitable b j, and at stage 2n + 1 be sure bn is paired with
some suitable ai.
5. Find prenex formulas equivalent to the following.
(a) (∃x Ax ∧∃x Bx) →Cx.
(b) ∀x Ax ↔∃x Bx.
∗6. Prove the converse to part (a) of Corollary 26I: An effectively enu-
merable theory (in a reasonable language) is axiomatizable. Sug-
gestion: The set {σ0, σ1, σ2, . . .} is equivalent (in the sense of having
the same models) to the set {σ0, σ0 ∧σ1, σ0 ∧σ1 ∧σ2, . . .}.
7. Consider a language with a two-place predicate symbol <, and
let N = (N; <) be the structure consisting of the natural numbers
with their usual ordering. Show that there is some A elementarily
equivalent to N such that <A has a descending chain. (That is,
there must be a0, a1, . . . in |A| such that ⟨ai+1, ai⟩∈<A for all i.)
Suggestion: Apply the compactness theorem.
Remark: The point of this exercise is to demonstrate that in
this language, one can not express, “There is no descending chain.”
8. Assume that σ is true in all inﬁnite models of a theory T . Show
that there is a ﬁnite number k such that σ is true in all models A of
T for which |A| has k or more elements.
9. Say that a set  of sentences has the ﬁnite model property iff each
member σ of , if it has any models at all, has a ﬁnite model.
Assume that  is a set of sentences in a ﬁnite language (i.e., a
language with ﬁnitely many parameters) and that  has the ﬁnite
model property. Give an effective procedure that, given any member
σ of , will decide whether or not σ has any models. Suggestion: Is
the set of such sentences effectively enumerable? Is its complement
effectively enumerable?
10. Assume we have a ﬁnite language without function symbols.
(a) Show that the set of satisﬁable ∃2 sentences is decidable. (See
Exercise 19 in Section 2.2 for terminology and background.)
Suggestion: Apply the preceding exercise.

164
A Mathematical Introduction to Logic
(b) Show that the set of valid ∀2 sentences is decidable. (A ∀2
formula is one of the form ∀x1 · · · ∀xm ∃y1 · · · ∃yn θ where
θ is quantiﬁer-free.)
Remarks: In ﬁrst-order logic, the “decision problem” (Entschei-
dungsproblem) is the problem of deciding, given a formula, whether
or not it is valid. By Church’s theorem (Section 3.5), this problem
in general is unsolvable. This exercise gives a solvable subcase of
the decision problem.
SECTION 2.7
Interpretations Between Theories1
In some cases a theory T1 can be shown to be every bit as powerful as
another theory T0. This is certainly the case if the theories are in the
same language and T0 ⊆T1. But even if the theories are in different
languages, there may exist a way of translating from one language to
the other in such a way that members of T0 are translated as members
of T1. This sort of situation will be examined in this section.
We will begin by discussing the topic of deﬁned symbols. This topic,
as well as having signiﬁcant interest of its own, will serve as an example
for the situation of the preceding paragraph, wherein T0 is constructed
from T1 by adding a new deﬁned symbol. If the deﬁnition is done prop-
erly, the original theory T1 should in principle be just as strong as the
new T0. We will consider only the case of deﬁned function symbols,
since the case of deﬁned predicate symbols presents, in comparison, no
real difﬁculties.
Deﬁning Functions
Frequently in mathematics it is useful to introduce deﬁnitions of new
functions. For example, in set theory one deﬁnes the power-set operation
P by a sentence like, “Let Px be the set whose members are the subsets
of x.” Or by a sentence in a formal language (here containing ∈, ⊆,
and P),
∀v1 ∀v2[Pv1 = v2 ↔∀u(u ∈v2 ↔u ⊆v1)].
Now deﬁnitions are unlike theorems and unlike axioms. Unlike the-
orems, deﬁnitions are not things we prove. We just declare them by
ﬁat. But unlike axioms, we do not expect deﬁnitions to add substantive
information. A deﬁnition is expected to add to our convenience, not to
our knowledge.
1 The results of this section will be used only in the latter part of Section 3.7.

Chapter 2:
First-Order Logic
165
If this expectation is to be realized, the deﬁnition must be made in
a reasonable way. As an example of a most unreasonable deﬁnition in
number theory, suppose that we introduce a new function symbol by the
“deﬁnition”
f (x) = y
iff
x < y.
(Or by the sentence in a formal language: ∀v1 ∀v2( f v1 = v2 ↔v1<
v2).) Since we know that 1 < 2, we see that f (1) = 2. But also 1 < 3,
so we obtain f (1) = 3. And so we come to the conclusion (which does
not itself involve f ) that 2 = 3.
Obviously this deﬁnition of f was in some way very bad. It did not
just make matters convenient for us; it enabled us to conclude that 2 = 3,
which we could not have done without the deﬁnition. The trouble was
that the deﬁnition bestowed the name “ f (1)” ambiguously upon many
things (2 and 3 among them). Thus f (1) was not “well deﬁned.” Names
ought to designate unique objects.
In this subsection we want to consider conditions under which we can
be assured that a deﬁnition will be satisfactory. To simplify the notation,
we will consider only the deﬁnition of a one-place function symbol f ,
but the remarks will apply to n-place function symbols as well.
Consider then a theory T in a language not yet containing the one-
place function symbol f . (For example, T might be the set of conse-
quences of your favorite axioms for set theory.) We want to add f to
the language, introducing it by the deﬁnition
∀v1 ∀v2[ f v1 = v2 ↔ϕ],
(δ)
where ϕ is a formula in the original language (i.e., a formula not con-
taining f ) in which only v1 and v2 may occur free.
THEOREM 27A
In the above situation, the following are equivalent:
(a) (The deﬁnition is noncreative.) For any sentence σ in the
smaller language, if
T ; δ |= σ
(in the augmented language), then already T |= σ.
(b) ( f is well deﬁned.) The sentence
∀v1 ∃!v2 ϕ
(ε)
is in the theory T . (Here “∃!v2 ϕ” is an abbreviation for a longer
formula; see Exercise 21 of Section 2.2.)
PROOF.
To obtain (a) ⇒(b), simply note that δ |= ε. So by taking
σ = ε in part (a), we obtain T |= ε.
Conversely, assume that T |= ε. Let A be a model of T .
(A is a structure for the original language.) For d ∈|A|, let F(d)

166
A Mathematical Introduction to Logic
be the unique e ∈|A| such that |=A ϕ[[d, e]]. (There is a unique
such e because |=A ε.) Let (A, F) be the structure for the aug-
mented language that agrees with A on the original parameters
and that assigns F to the symbol f . Then it is easy to see that
(A, F) is a model of δ. Furthermore, A and (A, F) satisfy the
same sentences of the original language. In particular (A, F) is a
model of T . Hence
T ; δ |= σ ⇒|=(A,F) σ
⇒|=A σ.
⊣
(This argument can be stated more brieﬂy by using second-order
logic. ε is logically equivalent to the sentence ∃f δ.)
Interpretations
The basic idea is that it is possible for one theory to be just as strong (in
a sense to be made precise) as another theory in another language. In
considering two languages simultaneously, there is no point in allowing
them to conﬂict; e.g., the negation symbol of one language should not
be a predicate symbol in the other. We can eliminate such conﬂicts by
assuming that each of the languages is obtained from a third parent
language by deleting some parameters (and perhaps equality).
For example, axiomatic set theory is at least as strong as the theory of
the natural numbers with zero and successor, i.e., the theory of (N; 0, S).
Any sentence in the language of (N; 0, S) can be translated in a natural
way into a sentence of set theory. (This translation is sketched brieﬂy
in Section 3.7.) If the original sentence was true in (N; 0, S), then the
translation will be a consequence of the axioms of set theory. (This is
not obvious; the proof uses facts to be developed in Section 3.1.)
Let us look more carefully at a second example. Consider on the one
hand the theory of
(N; 0, S)
in its language, and on the other hand the theory of
(Z; +, ·)
in its language. (Here Z is the set of all integers, positive, negative, and
zero.) We will shortly be in a position to claim that the second theory is
as strong as the ﬁrst. How might a sentence about the natural numbers
N with 0 and S be translated into a sentence about the integers Z with
addition and multiplication?
The ﬁrst clue is provided by Lagrange’s theorem from number the-
ory: an integer is nonnegative iff it is the sum of four squares. Thus a
quantiﬁer ∀x in the ﬁrst language (where x is intended to range over N)

Chapter 2:
First-Order Logic
167
can be replaced by
∀x( ∃y1 ∃y2 ∃y3 ∃y4 x = y1 · y1 + y2 · y2 + y3 · y3 + y4 · y4→
in the second language.
The second clue is that {0} and the successor function (viewed as a
relation) are deﬁnable in (Z; +, ·). The set {0} is deﬁned by
v1 + v1 = v1.
The successor relation (extended to Z) is deﬁned by
∀z(z · z = z ∧z + z ̸= z →v1 + z = v2).
Thus the sentence about (N; 0, S)
∀x Sx ̸= 0
can be translated into
∀x[∃y1 ∃y2 ∃y3 ∃y4 x = y1 · y1 + y2 · y2 + y3 · y3 + y4 · y4→
¬ ∀u(u + u = u →∀v( ∀z(z · z = z ∧z + z ̸= z →x + z
= v) →v = u))].
So much for examples. For our general discussion it will be helpful
to introduce the notation
ϕ(t) = ϕv1
t ,
ϕ(t1, t2) =

ϕv1
t1
v2
t2 ,
and so forth. Thus ϕ = ϕ(v1) = ϕ(v1, v2). If we use “ϕ(x)” we will
not worry too much about whether or not x is substitutable for v1 in ϕ.
If it is not, then we actually want ϕ(x) to be ψv1
x , where ψ is a suitable
alphabetic variant of ϕ.
Assume now that we have the following general situation:
L0 is a language. (A language can for all practical purposes be a set
of parameters, possibly augmented by the equality symbol.)
T1 is a theory in a (possibly different) language L1, which includes
equality.
DEFINITION.
An interpretation π of L0 into T1 is a function on the
set of parameters of L0 such that
1. π assigns to ∀a formula π∀of L1 in which at most v1 occurs
free, such that
T1 |= ∃v1π∀.
(i)
(The idea is that in any model of T1, the formula π∀should deﬁne
a nonempty set to be used as the universe of an L0-structure.)
2. π assigns to each n-place predicate parameter P a formula
πP of L1 in which at most the variables v1, . . . vn occur free.

168
A Mathematical Introduction to Logic
3. π assigns to each n-place function symbol f a formula π f
of L1, in which at most v1, . . . , vn, vn+1 occur free, such that
T1 |= ∀v1 · · · ∀vn(π∀(v1) →· · · →π∀(vn)→
∃x(π∀(x) ∧∀vn+1(π f (v1, . . . , vn+1) ↔vn+1 = x))).
(ii)
(In English, this formula becomes, “For all ⃗v in the set deﬁned by
π∀, there is a unique x such that π f (⃗v, x), and furthermore x is
in the set deﬁned by π∀.” The idea is to ensure that in any model
of T1, π f deﬁnes a function on the universe deﬁned by π∀. In the
case of a constant symbol c, we have n = 0 and (ii) becomes
T1 |= ∃x(π∀(x) ∧∀v1(πc(v1) ↔v1 = x)).
In other words, πc deﬁnes a singleton whose one member is also
in the set deﬁned by π∀.)
For example, if L0 is the language of (N; 0, S) and T1 is the theory
of (Z; +, ·), then we have
π∀(x) = ∃y1 ∃y2 ∃y3 ∃y4 x = y1 · y1 + y2 · y2 + y3 · y3 + y4 · y4,
π0(x) = x + x = x,
πS(x, y) = ∀z (z · z = z ∧z + z ̸= z →x + z = y).
(We are here exploiting the fact that in (Z; +, ·) we can, in effect, deﬁne
the structure (N; 0, S).)
If L0 coincides with L1, there is trivially the identity interpretation
π, for which
π∀= v1 = v1,
πP = Pv1 · · · vn,
π f = f v1 · · · vn = vn+1.
The conditions (i) and (ii) are then met no matter what T1 is.
Now assume that π is an interpretation and let B be a model of T1.
There is a natural way to extract from B a structure πB for L0. Namely,
let
|πB| = the set deﬁned in B by π∀,
P
πB = the relation deﬁned in B by πP, restricted to |πB|,
f
πB(a1, . . . , an) = the unique b such that |=B π f [[a1, . . . , an, b]],
where a1, . . . , an are in |πB|.
By condition (i) in the deﬁnition of interpretations, |πB| ̸= ∅. And, by
condition (ii), the deﬁnition of f πB makes sense; i.e., there is a unique
b meeting the above condition. Hence πB is indeed a structure for the
language L0.
Deﬁne the set π−1[T1] of L0-sentences by the equation
π−1[T1] = Th{πB | B ∈Mod T1}
= {σ | σ is an L0-sentence true in every structure πB
obtainable from a model B of T1}.

Chapter 2:
First-Order Logic
169
This is a theory, as is Th K for any class K. It is a satisﬁable theory iff
T1 is satisﬁable.
EXAMPLE.
Earlier in this section we had a theory T containing the
sentence
∀v1 ∃!v2 ϕ.
(ε)
Weaugmentedthelanguagetoalargerlanguage L+ thatcontained
a function symbol f . The “deﬁnition” of f was provided by the
L+-sentence
∀v1 ∀v2( f v1 = v2 ↔ϕ).
(δ)
We showed that for a sentence σ in the original language of T , if
T ; δ |= σ, then T |= σ.
We have an interpretation π from L+ into T . π is the identity
interpretation on all parameters except f . The formula π f is ϕ. The
fact that T |= ε is just what we need to verify that π is indeed an
interpretation. For any model A of T , πA is a structure previously
called (A, F); it is a model of T ; δ.
We claim that
π−1[T ] = Cn(T ; δ).
First observe that any model B of T ; δ equals πB, where A is the
restriction of B to the language of T . Hence for an L+-sentence σ,
σ ∈π−1[T ] ⇔|=πA σ
for every model A of T
⇔|=B σ
for every model B of T ; δ
⇔T ; δ |= σ.
Syntactical Translation
In the preceding subsection on interpretations we talked about arbitrary
models and such. But the reader may already have noticed that there is
a much more down-to-earth thing to be said about an interpretation π
of L0 into T1. Brieﬂy: We can, given a formula ϕ of L0, ﬁnd a formula
ϕπ in L1 which in some sense corresponds exactly to ϕ. We deﬁne ϕπ
by recursion on ϕ.
First, consider an atomic formula α of L0. For example, if α is
P f gx,
then α is logically equivalent to
∀y(gx = y →∀z( f y = z →Pz)).
And we can take for απ the L1-formula
∀y(πg(x, y) →∀z(π f (y, z) →πP(z))).

170
A Mathematical Introduction to Logic
In general, scan an atomic formula α from right to left. The rightmost
place at which a function symbol occurs will initiate a segment of the
form gx1 · · · xn,for somen-place g. (Intheexamplen = 1.)Replacethis
by some new variable y, and preﬁx ∀y(πg(x1, . . . , xn, y))→. Continue
to the next place at which a function symbol occurs. Finally, replace the
predicate symbol P (if a parameter) by πP (with the correct variables).
The deﬁnition of απ can be stated more carefully by using recursion
on the number of places at which function symbols occur in α. If that
number is zero, then α is Px1 · · · xn and απ is πP(x1, . . . , xn). Other-
wise, take the rightmost place at which a function symbol g occurs. If
g is an n-place symbol, then that place initiates a segment gx1 · · · xn.
Replace this segment by some new variable y, obtaining a formula we
can call αgx1···xn
y
. Then απ is
∀y(πg(x1, . . . , xn, y) →(αgx1···xn
y
)π).
For example,
(P f gx)π = ∀y(πg(x, y) →(P f y)π)
= ∀y(πg(x, y) →∀z(π f (y, z) →(Pz)π))
= ∀y(πg(x, y) →∀z(π f (y, z) →πP(z))).
The interpretation of a nonatomic formula is deﬁned in the obvi-
ous way. (¬ ϕ)π is (¬ ϕπ), (ϕ →ψ)π is (ϕπ →ψπ), and ( ∀x ϕ)π is
∀x(π∀(x) →ϕπ). (Thus the quantiﬁers are “relativized” to π∀.)
The sense in which ϕπ “says the same thing” as ϕ is made precise in
the following basic lemma.
LEMMA 27B
Let π be an interpretation of L0 into T1, and let B be
a model of T1. For any formula ϕ of L0 and any map s of the
variables into |πB|,
|=πB ϕ[s]
iff |=B ϕπ[s].
This is not a deep fact. It just says that ϕπ was deﬁned correctly.
PROOF.
We use induction on ϕ, but only the case of an atomic
formula α is nontrivial. For α, we use induction on the number of
places at which function symbols occur. It is easy if that number
is zero. Otherwise,
απ = ∀y(πg(x, y) →βπ),
where β y
gx = α. (We have quietly assumed that g is a one-place
symbol; the notation is bad enough already.) Let
b = the unique b such that |=B πg[[s(x), b]]
= g
πB(s(x)).

Chapter 2:
First-Order Logic
171
Then
|=B απ[s] ⇔|=B βπ[s(y | b)]
⇔|=πB β[s(y | b)]
by the inductive hypothesis
⇔|=πB β y
gx[s]
by the substitution lemma
⇔|=πB α[s].
⊣
The following corollary justiﬁes our choice of notation for π−1[T1].
COROLLARY 27C
For a sentence σ of L0,
σ ∈π−1[T1]
iff
σ π ∈T1.
PROOF.
Recall that by deﬁnition
σ ∈π−1[T1] ⇔for every model B of T1, |=πB σ
⇔for every model B of T1, |=B σ π by Lemma 27B
⇔T1 |= σ π.
⊣
DEFINITION.
An interpretation π of a theory T0 into a theory T1 is
an interpretation π of the language of T0 into T1 such that
T0 ⊆π−1[T1].
In other words, it is necessary that for an L0-sentence σ,
σ ∈T0 ⇒σ π ∈T1.
π−1[T1] is the largest theory that π interprets into T1. If T0 = π−1[T1],
then we have
σ ∈T0 ⇔σ π ∈T1.
In this case π is said to be a faithful interpretation of T0 into T1.
To return to an earlier example, consider the structures (N; 0, S) and
(Z; +, ·). We had an interpretation π into Th(Z; +, ·), where
π∀(x) = ∃y1 ∃y2 ∃y3 ∃y4 x = y1 · y1 + y2 · y2 + y3 · y3 + y4 · y4,
π0(x) = x + x = x,
πS(x, y) = ∀z(z · z = z ∧z + z ̸= z →x + z = y).
We now claim that π is a faithful interpretation of Th(N; 0, S) into
Th(Z; +, ·). For in this case, π(Z; +, ·) is the structure (N; 0, S). Hence
|=(N;0,S) σ ⇐⇒|= π(Z;+,·) σ ⇐⇒|=(Z;+,·) σ π.
In Chapter 3 we will be able to show that there is no interpretation of
Th(Z; +, ·) into Th(N; 0, S). Thus the former theory is strictly stronger
than the latter.

172
A Mathematical Introduction to Logic
Finally,letusreturntothesituationwithwhichwestartedthissection.
Assume that T is a theory containing the sentence ε, where
ε = ∀v1 ∃!v2ϕ;
δ = ∀v1 ∀v2( f v1 = v2 ↔ϕ);
L+ = the language obtained by adding the new function symbol f
to the language of T ;
π = the interpretation of L+ into T that is the identity interpretation
on all parameters except f , and π f = ϕ.
In fact, π is a faithful interpretation of Cn(T ; δ) into T , since, as
noted previously,
π−1[T ] = Cn(T ; δ).
We can now draw an additional conclusion; the deﬁnition is eliminable.
THEOREM 27D
Assume that we have the situation described above.
Then for any L+-sentence σ we can ﬁnd the sentence σ π in the
original language such that
(a) T ; δ |= (σ ↔σ π).
(b) T ; δ |= σ ⇐⇒T |= σ π.
(c) If f does not occur in σ, then |= (σ ↔σ π).
PROOF.
Part (c) follows from the fact that π is the identity inter-
pretation on all parameters except f . Part (b) restates that π is a
faithful interpretation of Cn(T ; δ) into T . Since π is faithful, for
(a) it sufﬁces to show that
T |= (σ ↔σ π)π.
This follows from (c), since (σ ↔σ π)π is (σ π ↔σ ππ), which is
valid.
⊣
Exercises
1. Assume that L0 and L1 are languages with the same parameters
except that L0 has an n-place function symbol f not in L1 and L1
has an (n + 1)-place predicate symbol P not in L0. Show that for
any L0-theory T there is a faithful interpretation of T into some
L1-theory.
2. Let L0 be the language with equality and the two-place function
symbols + and ·. Let L1 be the same, but with three-place predicate
symbols for addition and multiplication. Let Ni = (N; +, ·) be the
structure for Li consisting of the natural numbers with addition and
multiplication (i = 0, 1). Show that any relation deﬁnable by an
L0-formula in N0 is also deﬁnable by an L1-formula in N1.

Chapter 2:
First-Order Logic
173
3. Show that an interpretation of a complete theory into a satisﬁable
theory is faithful.
SECTION 2.8
Nonstandard Analysis1
The differential and integral calculus was originally described by
Leibniz and Newton in the seventeenth century in terms of quantities
that were inﬁnitely small yet nonzero. Newton used in his calculations
a number o that, being inﬁnitely small, could be multiplied by any ﬁnite
number and still be negligible. But it was necessary to divide by o, so it
had to be nonzero. Leibniz’s dx was less than any assignable quantity,
yet was nonzero.
These ideas were not easy to comprehend or to accept. Throughout
the eighteenth century this business of working with inﬁnitesimals was
attacked (e.g., by Bishop Berkeley), distrusted (e.g., by D’Alembert),
and used in enthusiastic experimentation (e.g., by Euler). While Euler
was creating the mathematics that students now study in advanced cal-
culus, he used inﬁnitesimals in a loose, free-swinging manner that would
not be tolerated in today’s freshmen. Only in the nineteenth century were
the foundations of calculus presented in the form now found in text-
books. The treatment of limits was then rigorous, and debate subsided.
In 1961 Abraham Robinson introduced a new method for treating
limits, rescuing inﬁnitesimals from their intellectual disrepute. This
method combines the intuitive advantages of working with inﬁnitely
small quantities with modern standards of rigor. The basic idea is to
utilize a nonstandard model of the theory of the real numbers.
Construction of ∗R
We will use a very large ﬁrst-order language. In addition to symbols
for +, ·, and < we might as well add symbols for the exponentiation
and absolute-value functions. And since there is no good reason to stop
there, we go all the way and include a symbol for every operation on the
set R of reals. We do the same for every relation on R. Thus we have
the language with equality and the following parameters:
0. ∀, intended to mean “for all real numbers.”
1. An n-place predicate symbol PR for each n-ary relation R on R.
2. A constant symbol cr for each r ∈R.
3. An n-place function symbol f F for each n-ary operation F on R.
1 This section may be omitted without loss of continuity.

174
A Mathematical Introduction to Logic
For this language there is the standard structure R, with |R| = R,
PR
R = R, cR
r
= r, and f R
F = F. But now let us form a nonstandard
structure, by using the compactness theorem. Let  be the set
Th R ∪{crP<v1 | r ∈R}.
(Here crP<v1 formalizes “r is less than v1.”) Any ﬁnite subset of  can
be satisﬁed in R by assigning to v1 some large real number. Hence by
the compactness theorem there is a structure A and an element a ∈|A|
such that  is satisﬁed in A when v1 is assigned a. Since A is a model
of Th R, we have A ≡R. There is also an isomorphism h of R into
(but not onto) A deﬁned by
h(r) = cA
r .
To check that this is indeed an isomorphism, we use the fact that A ≡R.
h is one-to-one, since for r1 ̸= r2, the sentence cr1 ̸= cr2 holds in R and
hence in A. h preserves a binary relation R(= PR
R) since for any r and
s in R,
⟨r, s⟩∈PR
R ⇔|=R PRcrcs
⇔|=A PRcrcs
⇔

cA
r , cA
s

∈PA
R
⇔⟨h(r), h(s)⟩∈PA
R.
A similar calculation applies to any n-ary relation. Next we must show
that h preserves any function F(= f R
F ). Again for notational ease, sup-
pose that F is a binary operation. Consider any r and s in R, and let
t = F(r, s). Then
h

f R
F (r, s)

= h(F(r, s))
= h(t)
= cA
t .
Now the sentence ct = f Fcrcs holds in R and hence in A. Hence
cA
t = f A
F

cA
r , cA
s

= f A
F(h(r), h(s)).
So h preserves f F. For the constant symbols we have by the deﬁnition
of h,
h

cR
r

= h(r)
= cA
r .
Since we have an isomorphic copy of R inside A, we can ﬁnd an-
other structure ∗R isomorphic to A such that R is a substructure of ∗R.
The idea is simply to replace in A the point cA
r by the point r (provided
that |A| ∩R = ∅, as can always be arranged). For details, see Exer-
cise 24 of Section 2.2. Since ∗R is isomorphic to A, there is a point
b ∈|∗R| such that ∗R satisﬁes  when v1 is assigned b. In particular,
∗R ≡R.

Chapter 2:
First-Order Logic
175
To go much further, we need a less cumbersome notation. We will
use an asterisk to indicate passage from R to ∗R.
1. For each n-ary relation R on R, let ∗R be the relation P
∗R
R assigned
to the symbol PR by ∗R. In particular, R is a unary relation on R. Its
image ∗R equals the universe of ∗R, since the sentence ∀xPRx is true
in R and hence in ∗R. Since R is a substructure of ∗R, we have that
each relation R equals the restriction of ∗R to R.
2. For each n-ary operation F on R, let ∗F be the operation f
∗R
R
assigned to the symbol f F by ∗R. F is then the restriction to R of ∗F.
Observe that c
∗R
r
= r, so we need no special notation for this.
There is a general method (to be used heavily in the remainder of this
section) for demonstrating properties of a relation ∗R or an operation
∗F. One simply observes (1) that R or F has the property, (2) that the
property can be expressed by a sentence of the language, and (3) that
R ≡∗R.
Forexample,thebinaryrelation ∗<on ∗Ristransitive.Thisisbecause
< is transitive, and this property can be expressed by the sentence
∀x ∀y ∀z(xP<y →yP<z →xP<z).
By similar reasoning, ∗< satisﬁes trichotomy on ∗R and thus is an
ordering relation on ∗R.
For another example, we can prove that the binary operation ∗+ on
∗R is commutative, since + is commutative and the commutative law
can be expressed by a sentence. By applying this reasoning to each of
the ﬁeld axioms, we see that (∗R; 0, 1, ∗+, ∗·) is a ﬁeld.
This general method is used so much, we will shortly begin to take
it for granted. If, for example, we assert that ∗|a ∗+ b| ∗≤∗|a| ∗+ ∗|b|
for a and b in ∗R, we will take for granted that the reader perceives that
the general method yields this fact.
We have R ⊆∗R, but R ̸= ∗R. For we have some point b such that
|=∗R crP<v1[[b]]; i.e., r ∗< b. Thus b is inﬁnitely large, being larger
(in the ordering ∗<) than any standard r, i.e., any r ∈R. Its reciprocal
1 ∗/ b will be a sample inﬁnitesimal.
Properties of R that cannot be expressed in the language are likely
to fail in ∗R. The least-upper-bound property is one such. There are
non-empty bounded subsets S of ∗R that have no least upper bound
(with respect to the ordering ∗<). For example, R is such a subset of
∗R. It is bounded by the inﬁnite b of the preceding paragraph. But it has
no least upper bound; see Exercise 7.
Deﬁne the set F of ﬁnite elements by the equation
F = {x ∈∗R | ∗|x| ∗< y
for some
y ∈R}.

176
A Mathematical Introduction to Logic
Similarly, deﬁne the set I of inﬁnitesimals by the equation
I = {x ∈∗R | ∗|x| ∗< y
for all positive
y ∈R}.
If A ⊆R is unbounded, then ∗A contains inﬁnite points. For the
sentence “for any real r there is an element a ∈A larger than r” is true
and formalizable. Take some inﬁnite positive b; there must be a larger
(and hence inﬁnite) member of ∗A. For example, ∗N contains inﬁnite
numbers.
The only standard inﬁnitesimal, i.e., the only member of R ∩I, is 0.
But there are other inﬁnitesimals. For by the usual (formalizable) rules
for inequalities, the reciprocal of any inﬁnite number is an inﬁnitesimal.
Algebraic Properties
In the next theorem we collect some algebraic facts about F and I that
will be useful later.
THEOREM 28A
(a) F is closed under addition ∗+, subtraction ∗−,
and multiplication ∗·.
(b) I is closed under addition ∗+, subtraction ∗−, and multi-
plication from F:
x ∈I
and
z ∈F ⇒x ∗· z ∈I.
In algebraic terminology, part (a) says that F is a subring of the ﬁeld
∗R, and part (b) says that I is an ideal in the ring F. We will see a little
later what the quotient ring F/I is.
PROOF.
(a) Let x and y be ﬁnite, so that ∗|x| ∗< a, ∗|y| ∗< b for
standard a and b in R. Then
∗|x ∗± y| ∗≤∗|x| ∗+ ∗|y| ∗< a + b ∈R,
whence x ∗+ y, x ∗−y are ﬁnite. Also
∗|x ∗· y| ∗< a · b ∈R,
whence x ∗· y is ﬁnite, too.
(b) Let x and y be inﬁnitesimals. Then for any positive standard
a, ∗|x| ∗< a/2 and ∗|y| ∗< a/2. Hence
∗|x ∗± y| ∗< a/2 + a/2 = a,
so that x ∗+ y and x ∗−y are inﬁnitesimal. If z is ﬁnite, then
∗|z| ∗< b for some standard b. Since x is inﬁnitesimal, we have
∗|x| ∗< a/b, whence
∗|x ∗· z| ∗< (a/b)b = a.
Thus x ∗· z is also inﬁnitesimal.
⊣

Chapter 2:
First-Order Logic
177
DEFINITION.
x is inﬁnitely close to y (written x ≃y) iff x ∗−y is
inﬁnitesimal.
THEOREM 28B
(a) ≃is an equivalence relation on ∗R.
(b) If u ≃v and x ≃y, then u ∗+ x ≃v ∗+ y and ∗−u ≃
∗−v.
(c) If u ≃v and x ≃y and x, y, u, v are ﬁnite, then u ∗· x ≃
v ∗· y.
PROOF.
This is a consequence of part (b) of the preceding theorem
(I is an ideal in F).
(a) ≃is reﬂexive since 0 is inﬁnitesimal. ≃is symmetric since
the negative (∗−) of an inﬁnitesimal is inﬁnitesimal. Finally, sup-
pose that x ≃y and y ≃z. Then
x ∗−z = (x ∗−y) ∗+ (y ∗−z) ∈I
since I is closed under addition.
(b) If u ≃v and x ≃y, then
(u ∗+ x) ∗−(v ∗+ y) = (u ∗−v) ∗+ (x ∗−y) ∈I
since I is closed under addition. Also ∗−u ≃∗−v since I is
closed under negation.
(c) (u ∗· x) ∗−(v ∗· y) = (u ∗· x) ∗−(u ∗· y) ∗+ (u ∗· y) ∗−(v ∗· y)
= u ∗· (x ∗−y) ∗+ (u ∗−v) ∗· y ∈I
since I is closed under multiplication from F.
⊣
For standard r and s, we have r ≃s iff r = s, as 0 is the only
standard inﬁnitesimal.
LEMMA 28C
If x ̸≃y and at least one is ﬁnite, then there is a
standard q strictly between x and y.
PROOF.
We may suppose that x
∗< y. In fact, we may further
suppose that 0 ∗< x ∗< y; the case x ∗< y ∗≤0 is similar and the
case x ∗< 0 ∗< y is trivial. Since x ̸≃y there is a standard b such
that 0 < b ∗< y ∗−x. Since x is ﬁnite we have x ∗< mb for some
positive integer m; take the least such m. Then x ∗< mb ∗< y.
(By the leastness of m, (m −1)b ∗≤x. So mb ∗≤x ∗+ b ∗< y.)
⊣
THEOREM 28D
Every x ∈F is inﬁnitely close to a unique r ∈R.
PROOF.
For x ∈F the set
S = {y ∈R | y ∗< x}
of standard points below x has an upper bound in R. Let r be its
least upper bound; we claim that x ≃r.

178
A Mathematical Introduction to Logic
If x ̸≃r, then by the lemma there is a standard q between x
and r. If r < q ∗< x, then r fails to be an upper bound for S. If
x ∗< q < r, then q is also an upper bound for S, contradicting
the leastness of r. Hence x ≃r.
This establishes the existence of r. As for the uniqueness, note
that if x ≃r and x ≃s, then r ≃s. For standard r and s this
implies that r = s.
⊣
COROLLARY 28E
Each ﬁnite x has a unique decomposition of the
form x = s ∗+ i, where s is standard and i is inﬁnitesimal.
We call s the standard part of x, written st(x). (Another notation for
the standard part of x is ◦x.) Of course for standard r, st(r) = r. The
next theorem summarizes some properties of the st function.
THEOREM 28F
(a) st maps F onto R.
(b) st(x) = 0 iff x is inﬁnitesimal.
(c) st(x ∗+ y) = st(x) + st(y).
(d) st(x ∗· y) = st(x) · st(y).
PROOF.
(a) and (b) are clear. Since st(x) ≃x and st(y) ≃y, we
have by part (b) of Theorem 28B that st(x) + st(y) ≃x ∗+ y.
Hence the left side equals st(x ∗+ y). Part (d) is similar and uses
part (c) of Theorem 28B.
⊣
(In algebraic terminology, this theorem asserts that st is a homomor-
phism of the ring F onto the ﬁeld R, with kernel I. Consequently, the
quotient ring F/I is isomorphic to the real ﬁeld R.)
Henceforth in this section we will streamline our notation by omitting
the asterisks on the symbols for the arithmetic operations ∗+, ∗−, ∗·,
and ∗/.
Convergence
In calculus courses convergence is usually treated in terms of ε’s and δ’s
and variables that come delicately close to certain values. We will give
here the beginning of an alternative treatment of convergence, where
variables come inﬁnitely close to the limiting values.
DEFINITION.
Let F : R →R. Then F converges at a to b iff when-
ever x is inﬁnitely close to (but different from) a, then ∗F(x) is
inﬁnitely close to b.
PROOF OF EQUIVALENCE WITH THE ORDINARY DEFINITION. Firstsuppose
that F converges at a to b in the ordinary sense. That is, for any
ε > 0 there is a δ > 0 such that
0 ̸= |x −a| < δ ⇒|b −F(x)| < ε
for any x.
The displayed sentence (concerning the standard numbers ε and

Chapter 2:
First-Order Logic
179
δ) is formalizable and thus holds in ∗R. Now if x in ∗R is inﬁnitely
close to (but different from) a, then certainly 0 ̸= ∗|x −a| ∗< δ.
Hence ∗|b −∗F(x)| ∗< ε. Since ε was arbitrary, b ≃∗F(x).
Conversely, assume that the condition stated in the deﬁnition
is met. Then for any standard ε > 0, the sentence
There exists δ > 0 such that for all x, 0 ̸= |a−x| < δ ⇒|b−F(x)| < ε
(when formalized) holds in ∗R, since we can take δ to be inﬁnites-
imal. Hence the sentence holds in R also.
⊣
First remark: It is entirely possible that F does not converge at a to
any number. On the other hand, F converges at a to at most one b. For
if i is a nonzero inﬁnitesimal, then b = st(∗F(a + i)). It is traditional
to denote this b by “limx→a F(x).” Thus
lim
x→a F(x) = st(∗F(a + i)).
Second remark: It is not really necessary to have dom F = R. It is
enough for a to be an accumulation point of dom F. (a is an accumu-
lation point of S iff a is inﬁnitely close to, but different from, some
member of ∗S.)
COROLLARY 28G
F is continuous at a iff whenever x ≃a, then
∗F(x) ≃F(a).
Now consider a function F : R →R and a standard a ∈R. Then
the derivative F′(a) is
lim
h→0
F(a + h) −F(a)
h
By our deﬁnition of limit, this can also be stated: F′(a) = b iff for every
nonzero inﬁnitesimal dx we have dF/dx ≃b, where dF = ∗F(a +
dx) −F(a). Thus if there is such a b (i.e., if F′(a) exists), then
F′(a) = st(dF/dx)
for any nonzero inﬁnitesimal dx. Here dF/dx is the result of dividing
dF by dx. The fact that we simply use division here greatly facilitates
calculations.
EXAMPLE.
Let F(x) = x2. Then F′(a) = 2a, since
dF
dx = (a + dx)2 −a2
dx
= 2a(dx) + (dx)2
dx
= 2a +dx ≃2a.
THEOREM 28H
If F′(a) exists, then F is continuous at a.
PROOF.
For any nonzero inﬁnitesimal dx we have
∗F(a + dx) −F(a)
dx
≃F′(a).

180
A Mathematical Introduction to Logic
The right side is standard, so the left side is at least ﬁnite. Con-
sequently, when we multiply the left side by the inﬁnitesimal
dx we are left with the fact that ∗F(a + dx) −F(a) ∈I; i.e.,
∗F(a + dx) ≃F(a).
⊣
The reader should note that this result is not some nonstandard ana-
logue of a classical theorem, nor even a generalization of a classical
theorem. It is a classical theorem. It is only the proof that is nonstan-
dard. The same remarks apply to the next theorem. Let F ◦G be the
function whose value at a is F(G(a)).
CHAIN RULE
Assume that G′(a) and F′(G(a)) exist. Then (F ◦
G)′(a) exists and equals F′(G(a)) · G′(a).
PROOF.
First, notice that ∗(F ◦G) =∗F ◦∗G, since the sentence
∀v1 f F◦Gv1 = f Ff Gv1 holds in the structures. Now consider any
nonzero inﬁnitesimal dx. Let
dG = ∗G(a + dx) −G(a),
dF = ∗(F ◦G)(a + dx) −(F ◦G)(a)
= ∗F(∗G(a + dx)) −F(G(a))
= ∗F(G(a) + dG) −F(G(a)).
Then dG ≃0 since G is continuous at a. If dG ̸= 0, then by the
last of these equations dF/dG ≃F′(G(a)), whence
dF
dx = dF
dG · dG
dx ≃F′(G(a)) · G′(a).
If dG = 0, then dF = 0 and G′(a) ≃dG/dx = 0, so we again
have
dF
dx ≃F′(G(a)) · G′(a).
⊣
These theorems are but samples of the treatment of convergence in
terms of inﬁnite proximity. The method is not at all limited to elemen-
tary topics. One can construct delta functions δ with the property that
 ∞
−∞δ = 1 and yet δ(x) ≃0 for x ̸≃0. Original results in analysis
(e.g., in the theory of Hilbert spaces) have been obtained by the method
of nonstandard analysis. Possibly the method will be more widely used
in the future as more analysts become familiar with it.
Exercises
1. (Q is dense in R.) Let Q be the set of rational numbers. Show that
every member of ∗R is inﬁnitely close to some member of ∗Q.
2. (a) Let A ⊆R and F : A →R. Then F is also a binary relation on
R; show that ∗F : ∗A →∗R.
(b) Let S : N →R. Recall that S is said to converge to b iff for every
ε > 0 there is some k such that for all n > k, |S(n) −b| < ε.

Chapter 2:
First-Order Logic
181
Show that this is equivalent to the condition: ∗S(x) ≃b for every
inﬁnite x ∈∗N.
(c) Assume that Si : N →R and Si converges to bi for i = 1, 2.
Show that S1 + S2 converges to b1 + b2 and S1 · S2 converges to
b1 · b2.
3. Let F : A →R be one-to-one, where A ⊆R. Show that if x ∈∗A
but x /∈A, then ∗F(x) /∈R.
4. Let A ⊆R. Show that A = ∗A iff A is ﬁnite.
5. (Bolzano–Weierstrass theorem) Let A ⊆R be bounded and inﬁnite.
Show that there is a point p ∈R that is inﬁnitely close to, but
different from, some member of ∗A. Suggestion: Let S : N →A
with S one-to-one; look at ∗S(x) for inﬁnite x ∈∗N.
6. (a) Show that ∗Q has cardinality at least 2ℵ0, where Q is the set of
rational numbers. Suggestion: Use Exercise 1.
(b) Show that ∗N has cardinality at least 2ℵ0.
7. Let A be a subset of R having no greatest member. Then as a subset
of ∗R, A will have upper bounds (with respect to the ordering ∗<)
in ∗R. But show that A does not have a least such bound.

Chapter
T H R E E
Undecidability
SECTION 3.0
Number Theory
In this chapter we will focus our attention on a
speciﬁc language, the language of number theory.
This will be the ﬁrst-order language with equality
and with the following parameters:
∀, intended to mean “for all natural numbers.”
(Recall that the set N of natural numbers is the set
{0, 1, 2, . . .}. Zero is natural.)
0, a constant symbol intended to denote the
number 0.
S, a one-place function symbol intended to de-
note the successor function S : N →N, i.e., the
function for which S(n) = n + 1.
<, a two-place predicate symbol intended to
denote the usual (strict) ordering relation on N.
+, ·, E, two-place function symbols intended
to denote the operations +, ·, and E of addition,
multiplication, and exponentiation, respectively.
We will let N be the intended structure for this
language. Thus we may informally write
N = (N; 0, S, <, +, ·, E).
(More precisely, |N| = N, 0N = 0, and so forth.)
By number theory we mean the theory of this
structure, Th N. As warmup exercises we will
study (in Sections 3.1 and 3.2) certain reducts of N,
182

Chapter 3:
Undecidability
183
i.e., restrictions of N to sublanguages:
NS = (N; 0, S),
NL = (N; 0, S, <),
NA = (N; 0, S, <, +).
Finally, in Section 3.8 we will consider
NM = (N; 0, S, <, +, ·).
For each of these structures we will raise the same questions:
(A) Is the theory of the structure decidable? If so, what is a nice set
of axioms for the theory? Is there a ﬁnite set of axioms?
(B) What subsets of N are deﬁnable in the structure?
(C) What do the nonstandard models of the theory of the structure
look like? (By “nonstandard” we mean “not isomorphic to the intended
structure.”)
Our reason for choosing number theory (rather than, say, group
theory) for special study is this: We can show that a certain subtheory of
number theory is an undecidable set of sentences. We will also be able to
infer that any satisﬁable theory that is at least as strong as this fragment
of number theory (e.g., the full number theory or set theory) must be
undecidable. In particular, such a theory cannot be both complete and
axiomatizable.
In order to show that our subtheory of number theory is undecid-
able, we will show that it is strong enough to represent (in a sense
to be made precise) facts about sequences of numbers, certain opera-
tions on numbers, and ultimately facts about decision procedures. This
last feature then lets us perform a diagonal argument that demonstrates
undecidability.
We could alternatively use, in place of a subtheory of number theory,
some other theory (such as a fragment of the theory of ﬁnite sets) in
which we could conveniently represent facts about decision procedures.
Beforegivingexamplesoftheexpressivenessofthelanguageofnum-
ber theory, it is convenient to introduce some notational conventions.
As a concession to everyday usage, we will write
x < y,
x + y,
x · y,
and
x E y
in place of the ofﬁcial
< xy,
+ xy,
· xy,
and
E xy.
For each natural number k we have a term Sk0 (the numeral for k) that
denotes it:
S00 = 0,
S10 = S0,
S20 = SS0,
etc.
(The set of numerals is generated from {0} by the operation of

184
A Mathematical Introduction to Logic
preﬁxing S.) The fact that every natural number can be named in the
language will be a useful feature.
Even though only countably many relations on N are deﬁnable in N,
almost all the familiar relations are deﬁnable. For example, the set of
primes is deﬁned in N by
v1 ̸= S10 ∧∀v2 ∀v3(v1 = v2 · v3 →v2 = S10 ∨v3 = S10).
Later we will ﬁnd it important to show that many other speciﬁc relations
are deﬁnable in N.
One naturally expects the expressiveness of the language to be
severely restricted when some of the parameters are omitted. For exam-
ple, the set of primes, as we shall see, is not deﬁnable in NA. On the
other hand, in Section 3.8 we will show that any relation deﬁnable in N
is also deﬁnable in NM.
Preview
The main theorems of this chapter — the theorems associated with the
names of G¨odel, Tarski, and Church — are proved in Section 3.5. But
we can already sketch here some of the ideas involved. We want to
compare the concepts of truth and proof; that is, we want to compare
the set of sentences true in N with the set of sentences that might be
provable from an appropriate set A of axioms.
We can assign to each formula α of the language of number theory
an integer ♯α, called the G¨odel number of α. Any sufﬁciently straight-
forward way of assigning distinct integers to formulas would sufﬁce
for our purposes; a particular assignment is adopted at the beginning of
Section 3.4. What is important is that from α we can effectively ﬁnd
the number ♯α, and conversely. Similarly, to each ﬁnite sequence D of
formulas (such as a deduction) we assign an integer G(D). Note that for
any set A of formulas, we can form the corresponding set {♯α | α ∈A}
of numbers.
There are now three ways in which to proceed: the self-reference ap-
proach, the diagonalization approach, and the computability approach.
It will be argued later, however, that the three approaches are more
closely related than they appear — they are three aspects of one ap-
proach.
First, in the self-reference approach, we make a sentence σ that can
be thought of as saying, “I am unprovable.” More speciﬁcally, we have
the following:
THEOREM 30A
Let A ⊆Th N be a set of sentences true in N, and
assume that the set {♯α | α ∈A} of G¨odel numbers of members
of A is a set deﬁnable in N. Then we can ﬁnd a sentence σ such
that σ is true in N but σ is not deducible from A.

Chapter 3:
Undecidability
185
PROOF.
We will construct σ to express (in an indirect way) that σ
itself is not a theorem of A. Then the argument will go roughly as
follows: If A ⊢σ, then what σ says is false, contradicting the fact
that A consists of true sentences. And so A ⊬σ, whence σ is true.
To construct σ, we begin by considering the ternary relation R
deﬁned by
⟨a, b, c⟩∈R
iff
a is the G¨odel number of some formula
α and c is the value of G at some
deduction from A of α(Sb0).
Then because {♯α | α ∈A} is deﬁnable in N, it follows that R
is deﬁnable also. (The details of this step must wait until later
sections.) Let ρ be a formula that deﬁnes R in N. Let q be the
G¨odel number of
∀v3 ¬ ρ(v1, v1, v3).
(We use here the notation: ϕ(t) = ϕv1
t , ϕ(t1, t2) = (ϕv1
t1 )v2
t2 , and
so forth.) Then let σ be
∀v3 ¬ ρ(Sq0, Sq0, v3).
Thus σ says that no number is the value of G at a deduction from
A of the result of replacing, in formula number q, the variable
v1 by the numeral for q; i.e., no number is the value of G at a
deduction of σ.
Suppose that, contrary to our expectations, there is a deduc-
tion of σ from A. Let k be the value of G at a deduction. Then
⟨q, q, k⟩∈R and hence
|=N ρ(Sq0, Sq0, Sk0).
It is clear that
σ ⊢¬ ρ(Sq0, Sq0, Sk0)
and the two displayed lines tell us that σ is false in N. But A ⊢σ
and the members of A are true in N, so we have a contradiction.
Hence there is no deduction of σ from A. And so for every k,
we have ⟨q, q, k⟩/∈R. Thus for every k
|=N ¬ ρ(Sq0, Sq0, Sk0),
from which it follows (with the help of the substitution lemma)
that
|=N ∀v3 ¬ ρ(Sq0, Sq0, v3);
i.e., σ is true in N.
⊣
We will argue later — using something called Church’s thesis — that
any decidable set of natural numbers must be deﬁnable in N. The con-
clusion will then be that Th N is not axiomatizable.

186
A Mathematical Introduction to Logic
COROLLARY 30B
The set {♯τ | |=N τ} of G¨odel numbers of sentences
true in N is a set that is not deﬁnable in N.
PROOF.
If this set were deﬁnable, we could take A = Th N in the
preceding theorem to obtain a contradiction.
⊣
Section 3.5 will follow the self-reference approach, but with a varia-
tion in which the sentence σ tries to say, “I am false.” (The well-known
liar paradox is relevant here!)
But if this “self-reference” construction seems too much like a magic
trick, there is a second way to describe the situation: the diagonalization
approach, which does not use an obvious self-reference.
We start by deﬁning the following binary relation P on the natural
numbers:
⟨a, b⟩∈P ⇐⇒a is the G¨odel number of a formula α(v1)
(with just v1 free) and |=N α(Sb0).
(More informally, ⟨a, b⟩∈P ⇔“a is true of b.”) Then any set of natural
numbers that is deﬁnable in N equals, for some a, the “vertical section”
Pa = {b | ⟨a, b⟩∈P}
of P. Namely, we take a to be the G¨odel number of a formula deﬁning
the set, and use the fact that |=N α(Sb0) ⇔|=N α(v1)[[b]].
So any deﬁnable (in N) set of natural numbers is somewhere on the
list P1, P2, . . . . Now we “diagonalize out” of the list. Deﬁne the set:
H = {b | ⟨b, b⟩/∈P}.
(More informally, b ∈H ⇔“b is not true of b.”) Then H is nowhere
on the list P1, P2, . . . . (H ̸= P3 because 3 ∈H ⇔3 /∈P3, so the
number 3 belongs to exactly one of these two sets and not to the other.)
Therefore H is not deﬁnable in N.
Why is H undeﬁnable? After all, we have above speciﬁed that
b ∈H ⇐⇒not [b is not the G¨odel number of a formula α(v1)
(with just v1 free) and |=N α(Sb0)].
What is the barrier to translating this speciﬁcation into the language of
arithmetic? We will show that the barrier is not being the G¨odel number
of a formula — we can translate that — and the barrier is not having v1
free and not substituting the numeral Sb0 into a formula. By the process
of elimination, we will show that the only possible barrier is saying of
a sentence that is true in N.
THEOREM 30C
(a) The set {♯τ | |=Nτ} of G¨odel numbers of sen-
tences true in N is not deﬁnable in N.
⋆(b) The theory Th N is undecidable.
⋆(c) The theory Th N is not axiomatizable.

Chapter 3:
Undecidability
187
PROOF.
Part (a), which is the same as Corollary 30B in the self-
reference approach, has the diagonal proof sketched above. That
is, if to the contrary Th N were deﬁnable in N, then the above set
H would also be deﬁnable, which it is not.
Part (b) will then follow, after we argue every decidable set
of natural numbers must be deﬁnable in N. If Th N were decid-
able, then the corresponding set {♯τ | |=N τ} of numbers would
be decidable and hence deﬁnable in N, which it is not.
And part (c) is an immediate consequence of part (b) and
Corollary 26I, since Th N is a complete theory.
⊣
And thirdly, the computability approach presents us with a stark
difference between what is true and what is provable. From Section 2.6
we know that whenever A is a decidable set (or even an effectively
enumerable set) of axioms we might choose for Th N, the set Cn A of
provable sentence will be an effectively enumerable set.
In contrast, the computability approach will show — using Church’s
thesis — that the set Th N of all true sentences is not effectively enu-
merable. This fact, which is closely related to Theorem 30C, will follow
from another diagonal argument in Section 3.6.
⋆THEOREM 30D
For any decidable (or even effectively enumerable)
set A of axioms,
Cn A ̸= Th N
because the set on the left is effectively enumerable and the set
on the right is not.
Theorem 30D presents the dilemma: Either the axioms are lying to
us by allowing us to deduce false sentences, or else the axioms are
incomplete, in the sense that some true sentences cannot be deduced
from those axioms.
This computability approach is implicit in parts of Section 3.5, but
it is in Section 3.6 that the approach explicitly appears, and where it is
compared with the other two approaches.
SECTION 3.1
Natural Numbers with Successor
We begin with a situation that is simple enough to let us give reasonably
complete answers to our questions. We reduce the set of parameters
to just ∀, 0, and S, eliminating <, +, ·, and E. The corresponding
reduct of N is
NS = (N; 0, S).

188
A Mathematical Introduction to Logic
In this restricted language we still have the numerals, naming each point
in N. But the sentences we can express in the language are, from the
viewpoint of arithmetic, uninteresting.
We want to ask about NS the same questions that interest us in the
case of N. We want to know about the complexity of the set Th NS; we
want to study deﬁnability in NS; and we want to survey the nonstandard
models of NS.
To study the theory of the natural numbers with successor (Th NS),
we begin by listing a few of its members, i.e., sentences true in NS.
(These sentences will ultimately provide an axiomatization for the
theory.)
S1. ∀x Sx ̸= 0, a sentence asserting that zero has no predecessor.
S2. ∀x ∀y(Sx = Sy →x = y). This asserts that the successor
function is one-to-one.
S3. ∀y(y ̸= 0→∃x y = Sx).Thisassertsthatanynonzeronumber
is the successor of something.
S4.1 ∀x Sx ̸= x.
S4.2 ∀x SSx ̸= x.
· · ·
S4.n ∀x Snx ̸= x, where the superscript n indicates that the symbol
S occurs at n consecutive places.
Let AS be the set consisting of the above sentences S1, S2, S3, S4.n
(n = 1, 2, . . .). Clearly these sentences are true in NS; i.e., NS is a
model of AS. Hence
Cn AS ⊆Th NS.
(Anything true in every model of AS is true in this model.) What is
not so obvious is that equality holds. We will prove this by considering
arbitrary models of AS.
What can be said of an arbitrary model
A = (|A|; 0A, SA)
of the axioms AS? SA must be a one-to-one map of |A| onto |A| −{0A},
by S1, S2, and S3. And by S4.n, there can be no loops of size n. Thus
|A| must contain the “standard” points:
0A →SA(0A) →SA(SA(0A)) →. . . ,
which are all distinct. The arrow here indicates the action of SA. There
may or may not be other points. If there is another point a in |A|, then
there will be the successor of a, its successor, etc. Not only that, but
since (by S3) each nonzero element has a predecessor (something of
which it is the successor) which is (by S2) unique, |A| must contain
the predecessor of a, its predecessor, etc. These must all be distinct lest

Chapter 3:
Undecidability
189
there be a ﬁnite loop. Thus a belongs to a “Z-chain”:
· · · ∗→∗→a →SA(a) →SA(SA(a)) →· · · .
(We refer to these as Z-chains because they are arranged like the set
Z of all integers {. . . , −1, 0, 1, 2, . . .}.) There can be any number of
Z-chains. But any two Z-chains must be disjoint, as S2 prohibits merg-
ing. Similarly, any Z-chain must be disjoint from the standard part.
This can be restated in another way. Say that two points a and b in |A|
are equivalent if the function SA can be applied a ﬁnite number of times
to one point to yield the other point. This is an equivalence relation. (It
is clearly reﬂexive and symmetric; the transitivity follows from the fact
that SA is one-to-one.) The standard part of |A| is the equivalence class
containing 0A. For any other point (if any) a in |A|, the equivalence class
of a is the set generated from {a} by SA and its inverse. This equivalence
class is the Z-chain described above.
Conversely, any structure B (for this language) that has a stan-
dard part
0B →SB(0B) →SB(SB(0B)) →· · ·
and a nonstandard part consisting of any number of separate Z-chains
is a model of AS. (Check through the list of axioms in AS, and note that
each is true in B.) We thus have a complete characterization of what
the models of AS must look like.
If a model A of AS has only countably many Z-chains, then |A|
is countable. In general, if the set of Z-chains has cardinality1 λ, then
altogether the number of points in |A| is ℵ0 + ℵ0·λ. By facts of cardinal
arithmetic (cf. Chapter 0) this number is the larger of ℵ0 and λ. Hence
card |A| =

ℵ0
if A has countably many Z-chains,
λ
if A has an uncountable number λ of Z-chains.
LEMMA 31A
If A and A′ are models of AS having the same number
of Z-chains, then they are isomorphic.
PROOF.
There is a unique isomorphism between the standard part
of A and the standard part of A′. By hypothesis we are given a
one-to-one correspondence between the set of Z-chains of A and
the set of Z-chains of A′; thus each chain of A is paired with a chain
of A′. Clearly any two Z-chains are isomorphic. By combining
all the individual isomorphisms (which uses the axiom of choice)
we have an isomorphism of A onto A′.
⊣
Thus a model of AS is determined to within isomorphism by its num-
ber of Z-chains. For NS this number is zero, but any number is possible.
1 To avoid uncountable cardinals, see Exercise 3.

190
A Mathematical Introduction to Logic
The reader should note that there is no sentence of the language which
says, “There are no Z-chains.” In fact, there is no set  of sentences
such that a model A of AS satisﬁes  iff A has no Z-chains. For by the
LST theorem there is an uncountable structure A with A ≡NS. But A
has uncountably many Z-chains and NS has none.
THEOREM 31B
Let A and B be uncountable models of AS of the
same cardinality. Then A is isomorphic to B.
PROOF.
By the above discussion, A has card A Z-chains, and B
has card B Z-chains. Since card A = card B, they have the same
number of Z-chains and hence are isomorphic.
⊣
THEOREM 31C
Cn AS is a complete theory.
PROOF.
Apply the Lo´s–Vaught test of Section 2.6. The preceding
theorem asserts that the theory Cn AS is categorical in any un-
countable power. Furthermore, AS has no ﬁnite models. Hence
the Lo´s–Vaught test applies.
⊣
COROLLARY 31D
Cn AS = Th NS.
PROOF.
We have Cn AS ⊆Th NS; the ﬁrst theory is complete and
the second is satisﬁable.
⊣
⋆COROLLARY 31E
Th NS is decidable.
PROOF.
Any complete and axiomatizable theory is decidable (by
Corollary 25G). AS is a decidable set of axioms for this theory.
⊣
Elimination of Quantiﬁers
Once one knows a theory to be decidable, it is tempting to try to ﬁnd a
realistically practical decision procedure. We will give such a procedure
for Th NS, based on “elimination of quantiﬁers.”
DEFINITION.
A theory T admits elimination of quantiﬁers iff for
every formula ϕ there is a quantiﬁer-free formula ψ such that
T |= (ϕ ↔ψ).
Actually it is enough to consider only formulas ψ of a rather special
form:
THEOREM 31F
Assume that for every formula ϕ of the form
∃x(α0 ∧· · · ∧αn),
where each αi is an atomic formula or the negation of an atomic
formula, there is a quantiﬁer-free formula ψ such that T |=
(ϕ ↔ψ). Then T admits elimination of quantiﬁers.

Chapter 3:
Undecidability
191
PROOF.
First we claim that we can ﬁnd a quantiﬁer-free equivalent
for any formula of the form ∃x θ for quantiﬁer-free θ. We begin
by putting θ into disjunctive normal form (Corollary 15C). The
resulting formula,
∃x[(α0 ∧· · · ∧αm) ∨(β0 ∧· · · ∧βn) ∨· · · ∨(ξ0 ∧· · · ∧ξt)],
is logically equivalent to
∃x(α0 ∧· · · ∧αm) ∨∃x(β0 ∧· · · ∧βn) ∨· · ·
∨∃x(ξ0 ∧· · · ∧ξt).
By assumption, each disjunct of this formula can be replaced by
a quantiﬁer-free formula.
We leave it to the reader to show (in Exercise 2) that by using
the above paragraph one can obtain a quantiﬁer-free equivalent
for an arbitrary formula.
⊣
In the special case where the theory in question is the theory Th A of
a structure A, the deﬁnition can be restated: Th A admits elimination of
quantiﬁers iff for every formula ϕ there is a quantiﬁer-free formula ψ
such that ϕ and ψ are “equivalent in A”; i.e.,
|=A (ϕ ↔ψ)[s]
for any map s of the variables into |A|.
THEOREM 31G
Th NS admits elimination of quantiﬁers.
PROOF.
By the preceding theorem, it sufﬁces to consider a formula
∃x(α0 ∧· · · ∧αq),
where each αi is atomic or is the negation of an atomic formula.
We will describe how to replace this formula by another that is
quantiﬁer-free. The equivalence of the new formula to the given
one will, in fact, be a consequence of AS; see Exercise 3.
In the language of NS the only terms are of the form Sku, where
u is 0 or a variable. The only atomic formulas are equations. We
may suppose that the variable x occurs in each αi. For if x does
not occur in α, then
∃x(α ∧β) |==| α ∧∃x β.
Thus each αi has the form
Smx = Snu
or the negation of this equation, where u is 0 or a variable. We
may further suppose u is different from x, since Smx = Snx could
be replaced by 0 = 0 if m = n, and by 0 ̸= 0 if m ̸= n.

192
A Mathematical Introduction to Logic
Case1:Eachαi isthenegationofanequation.Thentheformula
may be replaced by 0 = 0. (Why?)
Case 2: There is at least one αi not negated; say α0 is
Smx = t,
where the term t does not contain x. Since the solution for x must
be non-negative, we replace α0 by
t ̸= 0 ∧· · · ∧t ̸= Sm−10
(or by 0 = 0 if m = 0). Then in each other α j we replace, say,
Skx = u
ﬁrst by
Sk+mx = Smu,
which in turn becomes
Skt = Smu.
We now have a formula in which x no longer occurs, so the quan-
tiﬁer may be omitted.
⊣
There are several interesting by-products of the quantiﬁer elimi-
nation procedure. For one, we get an alternative proof of the com-
pleteness of Cn AS. Suppose we begin with a sentence σ. The
quantiﬁer elimination procedure gives a quantiﬁer-free sentence τ such
that (by Exercise 3) AS |= (σ ↔τ). Now we claim that either AS |= τ
or AS |= ¬ τ. For τ is built up from atomic sentences by means of ¬
and →. An atomic sentence must be of the form Sk0 = Sl0 and is de-
ducible from AS if k = l, but is refutable (i.e., its negation is deducible)
from AS if k ̸= l. (In fact, just {S1, S2} sufﬁces for this.) Since every
atomic sentence can be deduced or refuted, so can every quantiﬁer-
free sentence. This establishes the claim. And so either AS |= σ or
AS |= ¬ σ.
Another by-product concerns the problem of deﬁnability in NS; see
Exercises 4 and 5. For any formula ϕ in which just v1 and v2 occur free
we now can ﬁnd a quantiﬁer-free ψ (with the same variables free) such
that
Th NS |= ∀v1 ∀v2(ϕ ↔ψ);
i.e.,
|=NS ∀v1 ∀v2(ϕ ↔ψ).
Thus the relation ϕ deﬁned is also deﬁnable by a quantiﬁer-free formula.

Chapter 3:
Undecidability
193
Exercises
1. Let A∗
S be the set of sentences consisting of S1, S2, and all sentences
of the form
ϕ(0) →∀v1(ϕ(v1) →ϕ(Sv1)) →∀v1 ϕ(v1),
where ϕ is a wff (in the language of NS) in which no variable except
v1 occurs free. Show that AS ⊆Cn A∗
S. Conclude that Cn A∗
S =
Th NS. (Here ϕ(t) is by deﬁnition ϕv1
t . The sentence displayed above
is called the induction axiom for ϕ.)
2. Complete the proof of Theorem 31F. Suggestion: Use induction.
3. The proof of quantiﬁer elimination for Th NS showed how, given a
formula ϕ, to ﬁnd a quantiﬁer-free ψ. Show that
AS |= (ϕ ↔ψ)
without using the completeness of Cn AS. (This yields an alternative
proof of the completeness of Cn AS, not involving Z-chains or the
Lo´s–Vaught test.)
4. Show that a subset of N is deﬁnable in NS iff either it is ﬁnite or its
complement (in N) is ﬁnite.
5. Show that the ordering relation {⟨m, n⟩| m < n in N} is not deﬁnable
in NS. Suggestion: It sufﬁces to show there is no quantiﬁer-free
deﬁnition of ordering. Call a relation R ⊆N × N linear if it can
be covered by a ﬁnite number of lines. Call R colinear if it is the
complement of a linear relation. Show that any relation deﬁnable
in NS is either linear or colinear. And that the ordering relation is
neither linear nor colinear.
6. Show that Th NS is not ﬁnitely axiomatizable. Suggestion: Show that
no ﬁnite subset of AS sufﬁces, and then apply Section 2.6.
SECTION 3.2
Other Reducts of Number Theory1
First let us add the ordering symbol < to the language. The intended
structure is
NL = (N; 0, S, <).
1 This section may be omitted without disastrous effects.

194
A Mathematical Introduction to Logic
Wewanttoshowthatthetheoryofthisstructureis(likeTh NS)decidable
and also admits elimination of quantiﬁers. But unlike Th NS, it is ﬁnitely
axiomatizable and is not categorical in any inﬁnite cardinality.
As axioms of Th NL we will take the ﬁnite set AL consisting of the
six sentences listed below. Here x ≤y is, of course, an abbreviation for
(x < y ∨x = y), and x ̸≤y abbreviates the negation of this formula.
∀y
(y ̸= 0 →∃x y = Sx)
(S3)
∀x ∀y
(x < Sy ↔x ≤y)
(L1)
∀x
x ̸< 0
(L2)
∀x ∀y
(x < y ∨x = y ∨y < x)
(L3)
∀x ∀y
(x < y →y ̸< x)
(L4)
∀x ∀y ∀z
(x < y →y < z →x < z)
(L5)
On the one hand, it is easy to see that all six axioms are true in NL.
Thus Cn AL ⊆Th NL. On the other hand, the opposite inclusion is not
obvious, and requires proof. We begin by listing some consequence of
these axioms.
(1)
AL ⊢∀x x < Sx.
PROOF.
In L1 take y to be x.
⊣
(2)
AL ⊢∀x x ̸< x.
PROOF.
In L4 take y to be x.
⊣
(3)
AL ⊢∀x ∀y(x ̸< y ↔y ≤x)
(trichotomy).
PROOF.
For “→” use L3. For “←” use L4 and (2).
⊣
(4)
AL ⊢∀x ∀y(x < y ↔Sx < Sy).
PROOF.
From AL we can deduce the biconditionals:
x < y ↔y ̸≤x
by (3);
↔y ̸< Sx
by L1;
↔Sx ≤y
by (3);
↔Sx < Sy
by L1.
⊣
(5)
AL ⊢S1 and AL ⊢S2.
PROOF.
S1 follows from L2 and (1). S2 comes from (4) by use of
L3 and (2).
⊣
(6)
AL ⊢S4.n for n = 1, 2, . . . .
PROOF.
This follows from (1) and (2), by using L5.
⊣

Chapter 3:
Undecidability
195
Thus any model A of AL is (when we ignore <A) also a model of
AS. So it must consist of a standard part plus zero or more Z-chains. In
addition, it is ordered by <A.
THEOREM 32A
The theory Cn AL admits elimination of quantiﬁers.
PROOF.
Again we consider a formula
∃x(β0 ∧· · · ∧βp),
where each βi is atomic or the negation of an atomic formula. The
terms are, as in Section 3.1, of the form Sku, where u is 0 or a
variable. There are two possibilities for atomic formulas,
Sku = Slt
and
Sku < Slt.
1. We can eliminate the negation symbol. Replace t1 ̸< t2 by
t2 < t1 ∨t1 = t2 and replace t1 ̸= t2 by t1 < t2 ∨t2 < t1. (This is
justiﬁed by L3 and L4.) By regrouping the atomic formulas and
noting that
∃x(ϕ ∧ψ) |==| ∃x ϕ ∧∃x ψ,
we may again reach formulas of the form
∃x(α0 ∧· · · ∧αq),
where now each αi is atomic.
2. We may suppose that the variable x occurs in each αi. This
is because if x does not occur in α, then
∃x(α ∧β) |==| α ∧∃x β.
Furthermore, we may suppose that x occurs on only one side of
the equality or inequality αi. For Skx = Slx can be dealt with as
in Section 3.1. Skx < Slx can be replaced by 0 = 0 if k < l, and
0 ̸= 0 otherwise. (This is justiﬁed by L1 and L4.)
Case 1: Suppose that some αi is an equality. Then we can
proceed as in case 2 of the quantiﬁer-elimination proof of
Theorem 31G.
Case 2: Otherwise each αi is an inequality. Then the formula
can be rewritten
∃x
 
i
ti < Smi x ∧

j
Sn j x < u j

.
(Here 
i indicates the conjunction of formulas indexed by i, so
γ0 ∧γ1 ∧· · · ∧γk can be abbreviated 
i γi.) In the ﬁrst con-
junction, 
i ti < Smi x, we have the lower bounds on x; in the
second conjunction, 
j Sn j x < u j, we have the upper bounds. If
the second conjunction is empty (i.e., if there are no upper bounds

196
A Mathematical Introduction to Logic
on x), then we can replace the formula by 0 = 0. (Why?) If the
ﬁrst conjunction is empty (i.e., if there are no lower bounds on x),
then we can replace the formula by

j
Sn j0 < u j,
which asserts that zero satisﬁes the upper bounds. Otherwise, we
rewrite the formula successively as
∃x

i, j
(ti < Smi x ∧Sn j x < u j).
(1)
∃x

i, j
(Sn jti < Smi+n j x < Smiu j).
(2)
⎛
⎝
i, j
Sn j+1ti < Smiu j
⎞
⎠∧

j
Sn j0 < u j.
(3)
This last formula says “any lower bound plus one satisﬁes any up-
per bound, and furthermore zero satisﬁes any upper bound.” This
implies that there is a gap between the greatest lower bound and
the least upper bound, whence there is a solution for x. The second
part guarantees that the solution for x is not forced to be negative.
In each case, we have arrived at a quantiﬁer-free version of the
given formula.
⊣
COROLLARY 32B
(a) Cn AL is complete.
(b) Cn AL = Th NL.
⋆(c) Th NL is decidable.
PROOF.
(a) The argument that followed the proof of Theorem 31G
is applicable here also. (b) This follows from (a), since Cn AL ⊆
Th NL and Th NL is satisﬁable. For (c), we can use the fact that
any complete axiomatizable theory is decidable. But the quantiﬁer
elimination proof yields a more efﬁcient decision procedure.
⊣
COROLLARY 32C
A subset of N is deﬁnable in NL iff it is either
ﬁnite or has ﬁnite complement.
PROOF.
Compare Exercise 4 of the preceding section.
⊣
On the other hand, NL has more deﬁnable binary relations than has
NS. For the ordering relation {⟨m, n⟩| m < n} is not deﬁnable in NS,
by Exercise 5 of the preceding section.
COROLLARY 32D
The addition relation,
{⟨m, n, p⟩| m + n = p},
is not deﬁnable in NL.

Chapter 3:
Undecidability
197
PROOF.
If we could deﬁne addition, we could then deﬁne the set of
even natural numbers. But this set is neither ﬁnite nor has ﬁnite
complement.
⊣
Now suppose we augment the language by the addition symbol +.
The intended structure is
NA = (N; 0, S, <, +).
The theory of this structure is also decidable, as we will prove shortly.
But to keep matters from getting even more complicated, we will avoid
listing any convenient set of axioms for the theory.
The nonstandard models of Th NA must also be models of Th NL.
So they have a standard part, followed by some Z-chains. But ordering
among the Z-chains can no longer be arbitrary. Let A be a nonstandard
model of Th NA. The ordering <A induces a well-deﬁned ordering on
the set of Z-chains. (See Exercise 3.) We claim that there is no largest
Z-chain, there is no smallest Z-chain, and there is between any two Z-
chains another one. The reasons, in outline, can be stated simply: If a
belongs to some Z-chain (i.e., is an inﬁnite element of A), then a +A a
is in a larger Z-chain. There must be some b such that b +A b is either
a or its successor; b must be in a smaller Z-chain. If a1 and a2 belong to
different Z-chains, then there must be some b such that b+A b is either
a1 +A a2 or its successor. And b will lie in a Z-chain between that of
a1 and that of a2. (These statements should seem quite plausible. The
reader who enjoys working with inﬁnite numbers might supply some
details.)
⋆THEOREM 32E (PRESBURGER, 1929)
The theory of the structure
NA = (N; 0, S, <, +) is decidable.
The proof is again based on a quantiﬁer elimination procedure.
The theory of NA itself does not admit elimination of quantiﬁers.
For example, the formula deﬁning the set of even numbers
∃y v1 = y + y
is not equivalent to any quantiﬁer-free formula. We can overcome
this by adding a new symbol ≡2 for congruence modulo 2. Sim-
ilarly, we add symbols ≡3, ≡4, . . . . The intended structure for
this expanded language is
N≡= (N; 0, S, <, +, ≡2, ≡3, . . .),
where ≡k is the binary relation of congruence modulo k. It turns
out that the theory of this structure does admit elimination of
quantiﬁers.
This by itself does not imply that the theory of either structure
is decidable. After all, we can start with any structure, and expand

198
A Mathematical Introduction to Logic
it to a structure having additional relations until a structure is ob-
tained that admits elimination of quantiﬁers. To obtain decidabil-
ity, we must show that we can, given a sentence σ, (1) effectively
ﬁnd a quantiﬁer-free equivalent σ ′, and then (2) effectively decide
if σ ′ is true.
We will now give the quantiﬁer elimination procedure for
Th N≡. For a term t and a natural number n, let nt be the term
t + t + · · · + t, with n summands. 0t is 0. Then any term can be
expanded to one of the form
Sn00 + n1x1 + · · · + nkxk
for k ≥0, ni ≥0 (where the xi’s are variables). For example,
S(x + S0) + Sy
becomes
S30 + x + y.
As usual we begin with a formula ∃y(β1 ∧· · · ∧βn), where
βi is an atomic formula or the negation of one.
1. Eliminate negation. Replace ¬(t1 = t2) by (t1<t2∨t2 < t1).
Replace ¬(t1 < t2) by (t1 = t2∨t2 < t1). And replace ¬(t1 ≡m t2)
by
t1 ≡m t2 + S10 ∨· · · ∨t1 ≡m t2 + Sm−10.
Then regroup into a disjunction of formulas of the form
∃y(α1 ∧· · · ∧αm),
where each αi is atomic. We may further suppose, as before, that
y occurs in each αi, and in fact that αi has one of the four forms
ny + t =
u,
ny + t ≡m u,
ny + t <
u,
u <
ny + t,
where u and t are terms not containing y. In what follows we
will take the liberty of writing these formulas with a subtraction
symbol:
ny =
u −t,
ny ≡m u −t,
ny <
u −t,
u −t <
ny.
These are merely abbreviations for the formulas without subtrac-
tion obtained by transposing terms.

Chapter 3:
Undecidability
199
For example, we might have at this point the formula
∃y(w < 4y ∧2y < u ∧3y < v ∧y ≡3 t),
where t, u, v, and w are terms not containing y.
2. Uniformize the coefﬁcients of y. Let p be the least common
multiple of the coefﬁcients of y. Each atomic formula can be
converted to one in which the coefﬁcient of y is p, by “multiplying
through” by the appropriate factor. This is obviously legitimate
for equalities and inequalities. In the case of congruences one
must remember to raise the modulus also:
a ≡m b
iff
ka ≡km kb.
In the example above p is 12, and we obtain
∃y(3w < 12y ∧12y < 6u ∧12y < 4v ∧12y ≡36 12t).
3. Eliminate the coefﬁcient of y. Replace py by x and add the
new conjunct x ≡p 0. (In place of ∃y · · · 12y · · · we can equally
well have, “There exists a multiple x of 12 such that · · · x · · · .”)
Our example is now converted to
∃x(3w < x ∧x < 6u ∧x < 4v ∧x ≡36 12t ∧x ≡12 0).
4. Special case. If one of the atomic formulas is an equality,
x + t = u, then we can replace
∃x θ
by
θ x
u−t ∧t ≤u.
Here replacement of x by “u−t” is the natural thing; we transpose
terms to compensate for the absence of subtraction. For example,
(x ≡m v)x
u−t
is
u ≡m v + t.
5. We may assume henceforth that = does not occur. So we
have a formula of the form
∃x[r0 −s0 < x ∧· · · ∧rl−1 −sl−1 < x
∧x < t0 −u0 ∧· · · ∧x < tk−1 −uk−1
∧x ≡m0 v0 −w0 ∧· · · ∧x ≡mn−1 vn−1 −wn−1],
where ri, si, ti, ui, vi, and wi are terms not containing x. This can
be abbreviated
∃x
⎡
⎣
j<l
r j −s j < x ∧

i<k
x < ti −ui ∧

i<n
x ≡mi vi −wi
⎤
⎦.
If there are no congruences (i.e., n = 0), then the formula as-
serts that there is a nonnegative space between the lower and

200
A Mathematical Introduction to Logic
upper bounds. We can replace the formula by the quantiﬁer-free
formula:

i<k

j<l
(r j −s j) + S0 < ti −ui ∧

i<k
0 < ti −ui.
Let M be the least common multiple of the moduli m0, . . . ,
mn−1. Then a + M ≡mi a. So as a increases, the pattern of residues
of a modulo m0, . . . , mn−1 has period M. Thus, in searching for a
solution to the congruences, we need only search M consecutive
integers.
We now have a formula that asserts the existence of a natural
number which is not less than certain lower bounds L1, . . . , Ll
and which satisﬁes certain upper bounds and certain congruences.
If there is such a solution, then one of the following is a solution:
L1, L1 + 1, . . . , L1 + M −1,
L2, L2 + 1, . . . , L2 + M −1,
· · ·
Ll, Ll + 1, . . . , Ll + M −1,
0, 1, . . . , M −1.
(The last line is needed to cover the case in which every L j is
negative. To avoid having to treat this line as a special case, we
will add a new lower bound of 0. That is, let rl = 0 and sl = S0
so that
rl −sl < x
is a formula 0 < x + S0 asserting that x is nonnegative. We now
have l + 1 lower bounds.)
Our formula (asserting the existence of a solution for x) can
now be replaced by a quantiﬁer-free disjunction that asserts that
one of the numbers in the above matrix is a nonnegative solution:

j≤l

1≤q≤M

i≤l
ri −si < (r j −s j) + Sq0
∧

i<k
(r j −s j) + Sq0 < ti −ui
∧

i<n
(r j −s j)+Sq0 ≡mivi −wi

.
In our continuing example we have, after adding the new lower
bound on x,
∃x(3w < x ∧0 < x + S0 ∧x < 6u ∧x < 4v
∧x ≡36 12t ∧x ≡12 0).
The quantiﬁer-free equivalent is a disjunction of 72 conjunctions.
Each conjunction has six constituents.

Chapter 3:
Undecidability
201
This proves half of the theorem. If we are given a sentence σ,
the above procedure tells us how to ﬁnd effectively a quantiﬁer-
free sentence τ (in the language of N≡) that is true (in the intended
structure) iff σ is. Now we must decide if τ is true.
But this is easy. It is enough to look at atomic sentences. Any
variable-free term can be put in the form Sn0. Then, for example,
Sn0 ≡m Sp0
is true iff n ≡m p.
⊣
Thus we have a decision procedure for Th NA. In 1974 Michael
Fischer and Michael Rabin showed, however, that there is no decision
procedure that is fast enough to be feasible for very long formulas.
A set D of natural numbers is said to be periodic if for some positive
p, any number n is in D iff n + p is in D. D is eventually periodic iff
there exist positive numbers M and p such that for all n greater than M,
n ∈D iff n + p ∈D.
THEOREM 32F
A set of natural numbers is deﬁnable in (N; 0, S,
<, +) iff it is eventually periodic.
PROOF.
Exercise 1 asserts that every eventually periodic set is de-
ﬁnable. Conversely, suppose D is deﬁnable. Then D is deﬁn-
able in N≡by a quantiﬁer-free formula (whose only variable is
v1). Since the class of eventually periodic sets is closed under
union, intersection, and complementation, it sufﬁces to show that
every atomic formula in the language of N≡whose only vari-
able is v1 deﬁnes an eventually periodic set. There are only four
possibilities:
nv1 + t =
u,
nv1 + t <
u,
u <
nv1 + t,
nv1 + t ≡m u,
where u and t are numerals. The ﬁrst two formulas deﬁne ﬁnite
sets (which eventually have period 1), the third deﬁnes a set with
ﬁnite complement, and the last formula deﬁnes a periodic set with
period m.
⊣
COROLLARY 32G
The multiplication relation
{⟨m, n, p⟩| p = m · n in N}
is not deﬁnable in (N; 0, S, <, +).
PROOF.
If we had a deﬁnition of multiplication, we could then use
that to deﬁne the set of squares. But the set of squares is not
eventually periodic.
⊣

202
A Mathematical Introduction to Logic
Exercises
1. Show that any eventually periodic set of natural numbers is deﬁnable
in the structure NA.
2. Show that in the structure (N; +) the following relations are
deﬁnable:
(a) Ordering, {⟨m, n⟩| m < n}.
(b) Zero, {0}.
(c) Successor, {⟨m, n⟩| n = S(m)}.
3. Let A be a model of Th NL (or equivalently a model of AL). For a
and b in |A| deﬁne the equivalence relation:
a ∼b ⇐⇒SA can be applied a ﬁnite number of times to one
of a, b to reach the other.
Let [a] be the equivalence class to which a belongs. Order equiva-
lence classes by
[a] ≺[b]
iff
a <A b
and
a ̸∼b.
Show that this is a well-deﬁned ordering on the set of equivalence
classes.
4. Show that the theory of the real numbers with its usual ordering,
Th(R; <), admits elimination of quantiﬁers. (Assume that the lan-
guage includes equality.)
SECTION 3.3
A Subtheory of Number Theory
We now return to the full language of number theory, as described in
Section 3.0. The parameters of the language are ∀, 0, S, <, +, ·, and
E. The intended structure for this language is
N = (N; 0, S, <, +, ·, E).
Actuallyin(N; ·, E)wecandeﬁne{0}, S, <,and+.(SeeExercise1.)
As we will show in Section 3.8, in (N; +, ·) we can deﬁne E as well as
0, S, and <. So there are ways in which we could economize. The luxury
of having all these parameters (particularly E) will simplify some of the
proofs.
As we shall see, Th N is a very strong theory and is neither decidable
nor axiomatizable. In order to prove this fact (and a number of related
results), it will be strategically wise to select for study a ﬁnitely axiom-
atizable subtheory of Th N. As hinted at in Section 3.0, this subtheory
should be strong enough to represent (in a sense to be made precise)
facts about decidable sets. The subtheory we have selected is Cn AE,

Chapter 3:
Undecidability
203
where AE is the set consisting of the eleven sentences listed below. (As
in the preceding section, x ≤y abbreviates x < y ∨x = y.)
Set AE of Axioms
∀x
Sx ̸= 0
(S1)
∀x ∀y
(Sx = Sy →x = y)
(S2)
∀x ∀y
(x < Sy ↔x ≤y)
(L1)
∀x
x ̸< 0
(L2)
∀x ∀y
(x < y ∨x = y ∨y < x)
(L3)
∀x
x + 0 = x
(A1)
∀x ∀y
x + Sy = S(x + y)
(A2)
∀x
x · 0 = 0
(M1)
∀x ∀y
x · Sy = x · y + x
(M2)
∀x
xE0 = S0
(E1)
∀x ∀y
x E Sy = x E y · x
(E2)
Since N is a model of AE, we have Cn AE ⊆Th N. But (as we will
prove in Section 3.5) equality does not hold here. In fact, it can be shown
that AE ⊬S3, where S3 is the sentence ∀y(y ̸= 0 →∃x y = Sx).
The ﬁrst ﬁve axioms give us some, but not all, of the axioms regard-
ing S and < that were useful in the preceding sections. The other six
axioms are the “recursion” equations for addition, multiplication, and
exponentiation.
We ﬁrst show that certain simple sentences in Th N are deducible
from AE.
LEMMA 33A
(a) AE ⊢∀x x ̸< 0.
(b) For any natural number k,
AE ⊢∀x(x < Sk+10 ↔x = S00 ∨· · · ∨x = Sk0).
Notice that (a) can be thought of as the k = −1 case of (b), where
the empty disjunction is ⊥. The lemma tells us that AE “knows” that
the numbers less than 7, for example, are exactly 0, 1, 2, 3, 4, 5, 6. So in
any model of AE, the standard points — the ones denoted by numerals
Sk0 — are ordered in the natural way, and (by L3) the inﬁnite points, if
any, are all larger than any standard point.
PROOF.
Part (a) is L2. For (b) we use induction (in English) on k.
We have as a consequence of L1,
x < S0 ↔x < 0 ∨x = 0,

204
A Mathematical Introduction to Logic
which together with L2 gives
x < S0 ↔x = 0,
which is the k = 0 case of (b). For the inductive step we again
apply L1:
x < Sk+10 ↔x < Sk0 ∨x = Sk0.
By the inductive hypothesis, x < Sk0 can be replaced by
x = S00 ∨· · · ∨x = Sk−10,
whereby we obtain (b).
⊣
LEMMA 33B
For any variable-free term t, there is a unique natural
number n such that
AE ⊢t = Sn0.
PROOF.
The uniqueness is immediate. (Why? Because AE, weak
as it is, at least knows, by S1, that 7 ̸= 0, and by S2 80 times,
that 87 ̸= 80.) For the existence half, we use induction on t. If t
is 0, we take n = 0. If t is Su, then by the inductive hypothesis
AE ⊢u = Sm0 for some m. Hence AE ⊢t = Sm+10.
Now suppose t is u1 + u2. By the inductive hypothesis
AE ⊢t = Sm0 + Sn0 for some m and n. We now apply A2 n
times and A1 once to obtain AE ⊢t = Sm+n0. The arguments for
multiplication and exponentiation are similar.
⊣
As a special case of this lemma we have “2 + 2 = 4” (i.e., S20 +
S20 = S40) as a consequence of AE. AE is at least smart enough to
evaluate variable-free terms. And the proof shows more than this. The
proof provides exact instructions for how, given such a term t, to ﬁnd
effectively the unique number n such that AE ⊢t = Sn0.
THEOREM 33C
For any quantiﬁer-free sentence τ true in N, AE ⊢τ.
PROOF.
Exercise 2. Start with the atomic sentences; these will be of
the form t1 = t2 or t1 < t2 for variable-free terms t1 and t2. Show
that AE proves τ if τ is true in N, and refutes τ (i.e., proves ¬ τ)
if τ is false in N.
⊣
Later on, we will improve on Theorem 33C by allowing τ to contain
“bounded quantiﬁers”; see Theorem 33I.
A simpliﬁed notation (used earlier in Section 2.7) for substitution
will be helpful in the coming pages:
ϕ(t) = ϕv1
t ,
ϕ(t1, t2) =

ϕv1
t1
v2
t2 ,
and so forth. Thus ϕ = ϕ(v1) = ϕ(v1, v2). Usually the term substituted

Chapter 3:
Undecidability
205
will be a numeral, for example
ϕ(Sa0, Sb0) =

ϕv1
Sa0
v2
Sb0.
But at times we will also substitute other terms, e.g., ϕ(x) = ϕv1
x , where
x is a variable. If, however, x is not substitutable for v1 in ϕ, then we
must take ϕ(x) = ψv1
x , where ψ is a suitable alphabetic variant of ϕ.
In the next proof (and elsewhere in this chapter) we make use of
the following consequence of the substitution lemma of Section 2.5:
For a formula ϕ in which at most v1, . . . , vn occur free and for natural
numbers a1, . . . , an,
|=N ϕ[[a1, . . . , an]] ⇔|=N ϕ(Sa10, . . . , San0).
An existential (∃1) formula is one of the form ∃x1 · · · ∃xkθ, where
θ is quantiﬁer-free. The following result improves Theorem 33C:
COROLLARY 33D
If τ is an existential sentence true in N, then
AE ⊢τ.
PROOF.
If ∃v1 ∃v2θ is true in N, then for some natural numbers
m and n, θ(Sm0, Sn0) is true in N. As this is a quantiﬁer-free true
sentence, it is deducible from AE. But it in turn logically implies
∃v1 ∃v2 θ.
⊣
On the other hand, it is known that there are true universal (∀1)
sentences (i.e., of the form ∀x1 · · · ∀xkθ for quantiﬁer-free θ) that are
not in Cn AE.
Representable Relations
Let R be an m-ary relation on N; i.e., R ⊆Nm. We know that a formula
ρ (in which only v1, . . . , vm occur free) deﬁnes R in N iff for every
a1, . . . , am in N,
⟨a1, . . . , am⟩∈R ⇔|=N ρ[[a1, . . . , am]]
⇔|=N ρ(Sa10, . . . , Sam0).
(The last condition here is equivalent to the preceding one by the sub-
stitution lemma.) We can recast this into two implications:
⟨a1, . . . , am⟩∈R ⇒|=N ρ(Sa10, . . . , Sam0),
⟨a1, . . . , am⟩/∈R ⇒|=N ¬ ρ(Sa10, . . . , Sam0).
We will say that ρ also represents R in the theory Cn AE if in these two
implications the notion of truth in N can be replaced by the stronger
notion of deducibility from AE.
More generally, let T be any theory in a language with 0 and S. Then
ρ represents R in T iff for every a1, . . . , am in N:
⟨a1, . . . , am⟩∈R ⇒ρ(Sa10, . . . , Sam0) ∈T,
⟨a1, . . . , am⟩/∈R ⇒( ¬ ρ(Sa10, . . . , Sam0)) ∈T.

206
A Mathematical Introduction to Logic
For example, ρ represents R in the theory Th N iff ρ deﬁnes R in N.
But ρ represents R in Cn AE iff for all a1, . . . , am:
⟨a1, . . . , am⟩∈R ⇒AE ⊢ρ(Sa10, . . . , Sam0),
⟨a1, . . . , am⟩/∈R ⇒AE ⊢¬ ρ(Sa10, . . . , Sam0).
The equality relation on N, for example, is represented in Cn AE by the
formula v1 = v2. For
m = n ⇒⊢Sm0 = Sn0,
m = n ⇒{S1, S2} ⊢¬ Sm0 = Sn0.
A relation is representable in T iff there exists some formula that rep-
resents it in T .
The concept of representability should be compared with that of
deﬁnability. In both cases we are somehow describing relations on the
natural numbers by formulas. In the case of deﬁnability, we ask about
the truth of sentences in the interpretation. In the case of representability
in Cn AE, we ask instead about the deducibility of sentences from the
axioms.
Say that a formula ϕ, in which no variables other than v1, . . . , vm
occur free, is numeralwise determined by AE iff for every m-tuple
a1, . . . , am of natural numbers, either
AE ⊢ϕ(Sa10, . . . , Sam0)
or
AE ⊢¬ ϕ(Sa10, . . . , Sam0)
THEOREM 33E
A formula ρ represents a relation R in Cn AE iff
(1) ρ is numeralwise determined by AE, and
(2) ρ deﬁnes R in N.
PROOF.
We use the fact that N is a model of AE. If ρ represents R
in Cn AE, then it is clear that (1) holds; (2) holds since “AE ⊢”
implies “|=N.” Conversely, if (1) and (2) hold, then we have
⟨a1, . . . , am⟩∈R ⇒|=N ρ(Sa10, . . . , Sam0)
by (2)
⇒AE ⊬¬ ρ(Sa10, . . . , Sam0)
since N is a model
of AE
⇒AE ⊢ρ(Sa10, . . . , Sam0)
by (1).
Similarly for the complement of R and ¬ ρ.
⊣
Church’s Thesis
We now turn to the relationship of the concepts of representability and
decidability.
⋆THEOREM 33F
Assume that R is a relation representable in a con-
sistent axiomatizable theory. Then R is decidable.

Chapter 3:
Undecidability
207
PROOF.
Say that ρ represents R in the consistent axiomatizable
theory T . Recall that T is effectively enumerable (Corollary 25F).
The decision procedure is as follows:
Given a1, . . . , am, enumerate the members of T . If, in the
enumeration, ρ(Sa10, . . . , Sam0) is found, then we are done and
⟨a1, . . . , am⟩∈R. If, in the enumeration, ¬ ρ(Sa10, . . . , Sam0) is
found, then we are done and ⟨a1, . . . , am⟩/∈R.
By the representability, one sentence or the other always ap-
pears eventually, whereupon the procedure terminates. Since T is
consistent, the answer given by the procedure is correct.
⊣
⋆COROLLARY 33G
Any relation representable in a consistent ﬁnitely
axiomatizable theory is decidable.
What about the converse to the above corollary? We cannot really
hope to prove the converse on the basis of our informal notion of de-
cidability. For our informal approach is usable only for giving lower
bounds on the class of decidable relations (i.e., for showing that certain
relations are decidable) and is unsuited to giving upper bounds (i.e., for
showing undecidability).
It is nevertheless possible to make plausibility arguments in support
of the converse. This will be easier to do at the end of Section 3.4 than
here. Roughly, the idea is that in a ﬁnite number of axioms we could
capture the (ﬁnitely long) instructions for the decision procedure.
The assertion that both the above corollary and its converse are cor-
rect is generally known as Church’s thesis. This assertion is not really
a mathematical statement susceptible to proof or disproof; rather it is a
judgment that the correct formalization of the informal notion of decid-
ability is by means of representability in consistent and ﬁnitely axiom-
atizable theories.
DEFINITION.
A relation R on the natural numbers is recursive iff it
is representable in some consistent ﬁnitely axiomatizable theory
(in a language with 0 and S).
Church’s thesis now can be put more succinctly: A relation is de-
cidable iff it is recursive. Or perhaps more accurately: The concept of
recursiveness is the correct precise counterpart to the informal concept
of decidability. The situation is analogous to one encountered in calcu-
lus. An intuitively continuous function (deﬁned on an interval) is one
whose graph you can draw without lifting your pencil off the paper. But
to prove theorems, some formal counterpart of this notion is needed.
And so one gives the usual deﬁnition of ε-δ-continuity. One should ask
if the precise notion of ε-δ-continuity is an accurate formalization of
intuitive continuity. If anything, the class of ε-δ-continuous functions is
too broad. It includes nowhere differentiable functions, whose graphs
cannot be drawn without lifting the pencil. But accurate or not, the class

208
A Mathematical Introduction to Logic
of ε-δ-continuous functions has been found to be a natural and important
class in mathematical analysis.
Very much the same situation occurs with recursiveness. One should
ask if the precise notion of recursiveness is an accurate formalization of
the informal notion of decidability. Again, the precisely deﬁned class
(of recursive relations) appears to be, if anything, too broad. It includes
relations for which any decision procedure will, for large inputs, require
so much computing time and memory (“scratchpad”) space as to make
implementation absurd. Recursiveness corresponds to decidability in
an idealized world, where length of computation and amount of mem-
ory are disregarded. But in any case, the class of recursive relations
has been found to be a natural and important class in mathematical
logic.
Empirical evidence that the class of recursive relations is not too
narrow is provided by the following:
1. Any relation considered thus far that mathematicians have felt
was decidable has been found to be recursive.
2. Several people have tried giving precise deﬁnitions of idealized
computing agents. The best-known such idealized agents are the “Turing
machines,” introduced by Alan Turing in 1936. (A variation on that idea
leads to the register machines described in Section 3.6.) The idea was
to devise something that could carry out any effective procedure. In
all cases, the class of relations having decision procedures executable
by such a computing agent has been exactly the class of recursive
relations. (Because of the importance of Turing’s analysis of effec-
tive computability, Church’s thesis is often called the Church–Turing
thesis.)
The fact that so many different (yet equivalent) deﬁnitions for the
class of recursive relations have been found is some indication of the
naturalness and importance of the concept.
In this book we will continue to exclude the informal notion of decid-
ability from nonstarred theorems. But in the remainder of the exposition
we will accept Church’s thesis. For example, we will speak of a set’s
being undecidable when we have a theorem stating it to be nonrecursive.
Obviously any relation representable in Cn AE is recursive. We will
prove later that the converse also holds; if a relation is representable in
any consistent ﬁnitely axiomatizable theory, then it is representable in
the one theory we have selected for special study. (This was, of course,
a motivating factor in our selection.)
The use of the word “recursive” in this context is the result of histori-
cal accident — even of historical error. Recently several mathematicians
have argued that the word “computable” would more accurately reﬂect
the intended ideas. But in the present context, we want to reserve the
word “computable” for an informal concept, to be deﬁned next. For
relations we have the informal concept of decidability; for functions the

Chapter 3:
Undecidability
209
analogous concept is computability. (As notational shorthand, a string
a1, . . . , ak can be written as ⃗a.)
⋆DEFINITION.
A function f : Nk →N is computable iff there is an
effective procedure that, given any k-tuple ⃗a of natural numbers,
will produce f (⃗a).
For example, addition and multiplication are computable. Effective
procedures, using base-10 notation, for these functions are taught in the
elementary schools. (Strictly speaking, in the concept of computabil-
ity one should refer to being given numerals, not numbers. For it is
numerals — strings of symbols like the triple 317 or the triple XCI —
that can be communicated. Nonetheless, we will suppress this point.) On
the other hand, of the uncountably many functions from Nk into N, only
countably many can be computable, because there are only countably
many effective procedures.
We want to give a mathematical counterpart to the informal concept
of computability, just as in the case of decidable relations. The clue to
the correct counterpart is provided by the next theorem. Recall that any
function f : Nk →N is also a (k + 1)-ary relation on N:
⟨a1, . . . , ak, b⟩∈f
⇐⇒
f (a1, . . . , ak) = b.
At one time it was popular to distinguish between the function and
the relation (which was called the graph of the function). Current set-
theoretic usage takes a function to be the same thing as its graph. But
we still have the two ways of looking at the function.
⋆THEOREM 33H
The following three conditions on a function
f : Nk →N are equivalent:
(a) f is computable.
(b) When viewed as a relation, f is a decidable relation.
(c) When viewed as a relation, f is an effectively enumerable
relation.
PROOF.
(a) ⇒(b): Assume that f is computable; we will de-
scribe the decision procedure. Given ⟨a1, . . . , ak, b⟩, ﬁrst com-
pute f (a1, . . . , ak). Then look to see if the result is equal to b. If
it is say “yes,” otherwise say “no.”
(b) ⇒(c): Any decidable relation is effectively enumerable.
For we can enumerate the set of all (k +1)-tuples of numbers, and
place on the output list those which meet the test of belonging to
the relation.
(c) ⇒(a): Assume that we have an effective enumeration of
(the graph of ) f . To compute f (a1, . . . , ak) we examine the
(k +1)-tuples in the enumeration until we ﬁnd the one that begins
with a1 . . . , ak. Its last component is then the desired function
value.
⊣

210
A Mathematical Introduction to Logic
Thus by using Church’s thesis, we can say that f is computable iff
f (viewed as a relation) is recursive. The class of recursive functions is
an interesting class even apart from its connection with incompleteness
theorems of logic. It represents an upper bound to the class of functions
that can actually be computed by programs for digital computers. The
recursive functions are those which are calculable by digital comput-
ers, provided one ignores practical limitations on computing time and
memory space.
We can now describe our plans for this section and the next. Our
basic goal is to obtain the theorems of Section 3.5. But some ground-
work is required before we can prove those theorems; we must ver-
ify that a number of relations (intuitively decidable) and a number
of functions (intuitively computable) are representable in Cn AE and
hence are recursive. In the process we will show (Theorem 34A) that
recursiveness is equivalent to representability in Cn AE. In the remain-
der of the present section we will establish general facts about rep-
resentability, and will show, for example, that certain functions for
encoding ﬁnite sequences of numbers into single numbers are repre-
sentable. Then in Section 3.4 we apply these results to particular re-
lations and functions related to the syntactical features of the formal
language.
The author is sufﬁciently realistic to know that many readers will be
more interested in the theorems of Section 3.5 than in the preliminary
spadework.Ifthereaderiswillingtobelievethatintuitivelydecidablere-
lations are all representable in Cn AE, and intuitively computable func-
tions are functionally representable (a concept we will deﬁne shortly)
there, then most if not all of the proofs in this spadework become un-
necessary. But it is hoped that the deﬁnitions and the statements of the
results will still receive some attention.
Numeralwise Determined Formulas
Theorem 33E tells us that we can show a relation to be representable
in Cn AE by ﬁnding a formula that deﬁnes it in N and is numeralwise
determined by AE. The next theorem will be useful in establishing
numeralwise determination.
THEOREM 33I
(a) Any atomic formula is numeralwise determined
by AE.
(b) If ϕ and ψ are numeralwise determined by AE, then so are
¬ ϕ and ϕ →ψ.
(c) If ϕ is numeralwise determined by AE, then so are the fol-
lowing formulas (obtained from ϕ by “bounded quantiﬁcation”):
∀x(x < y →ϕ),
∃x(x < y ∧ϕ).

Chapter 3:
Undecidability
211
PROOF.
Part (a) follows from Theorem 33C. Part (b) is easy. It
remains to prove part (c). We will consider a formula
∃x(x < y ∧ϕ(x, y, z))
in which just the variables y and z occur free. Consider two natural
numbers a and b; we must show that either
AE ⊢∃x(x < Sa0 ∧ϕ(x, Sa0, Sb0))
or
AE ⊢¬ ∃x(x < Sa0 ∧ϕ(x, Sa0, Sb0)).
Case 1: For some c less than a,
AE ⊢ϕ(Sc0, Sa0, Sb0).
(1)
(This case occurs iff ∃x(x < Sa0 ∧ϕ(x, Sa0, Sb0)) is true in N.)
We also have
AE ⊢Sc0 < Sa0.
(2)
And the sentences in (1) and (2) logically imply the sentence
∃x(x < Sa0 ∧ϕ(x, Sa0, Sb0)).
Case 2: Otherwise for every c less than a,
AE ⊢¬ ϕ(Sc0, Sa0, Sb0).
(3)
(This case occurs iff ∀x(x < Sa0 →¬ ϕ(x, Sa0, Sb0)) is true in
N.) We know from Lemma 33A that
AE ⊢∀x(x < Sa0 →x = S00 ∨· · · ∨x = Sa−10).
(4)
The sentence in (4) together with the sentences in (3) (for
c = 0, . . . , a −1) logically imply
∀x(x < Sa0 →¬ ϕ(x, Sa0, Sb0)).
And this is equivalent to
¬ ∃x(x < Sa0 ∧ϕ(x, Sa0, Sb0)).
This shows that ∃x(x < y ∧ϕ(x, y, z)) is numeralwise deter-
mined by AE. By applying this result to ¬ ϕ we obtain the fact
that the dual formula, ∀x(x < y →ϕ(x, y, z)), is numeralwise
determined by AE as well.
⊣
The argument in case 2 relied on the fact that the x quantiﬁer was
bounded by Sa0. We will see that it is possible for
¬ ψ(S00), ¬ ψ(S10), . . .

212
A Mathematical Introduction to Logic
all to be consequences of AE without having
∀x ¬ ψ(x)
be a consequence.
The preceding theorem is a useful tool for showing many relations
to be representable in Cn AE. For example, the set of primes is repre-
sented by
S10 < v1 ∧∀x(x < v1 →∀y(y < v1 →x · y ̸= v1)).
This formula deﬁnes the primes in N, and by the preceding theorem is
numeralwise determined by AE. It therefore represents the set of primes
in Cn AE.
Representable Functions
Often it is more convenient to work with functions than with relations.
Let f : Nm →N be an m-place function on the natural numbers. A for-
mula ϕ in which only v1, . . . , vm+1 occur free will be said to functionally
represent f (in the theory Cn AE) iff for every a1, . . . , am in N,
AE ⊢∀vm+1
 
ϕ(Sa10, . . . , Sam0, vm+1) ↔vm+1 = S f (a1,...,am)0
!
.
(Observe that the “←” half of this sentence is equivalent to ϕ(Sa10, . . . ,
Sam0, S f (a1,...,am)0). The “→” half adds an assertion of uniqueness.)
THEOREM 33J
If ϕ functionally represents f in Cn AE, then it also
represents f (as a relation) in Cn AE.
PROOF, WITH m = 1.
Since ϕ functionally represents f , we have
for any b:
AE ⊢ϕ(Sa0, Sb0) ↔Sb0 = S f (a)0.
If ⟨a, b⟩∈f , i.e., if f (a) = b, then the right half of this bicondi-
tional is valid and we get
AE ⊢ϕ(Sa0, Sb0).
But otherwise the right half is refutable from AE (i.e., its negation
is deducible), whence
AE ⊢¬ ϕ(Sa0, Sb0).
⊣
The converse of this theorem is false. But we can change the formula:
THEOREM 33K
Let f be a function on N that is (as a relation) repre-
sentable in Cn AE. Then we can ﬁnd a formula ϕ that functionally
represents f in Cn AE.

Chapter 3:
Undecidability
213
PROOF.
To simplify the notation we will take f to be a one-place
function on N. The desired sentence,
∀v2[ϕ(Sa0, v2) ↔v2 = S f (a)0],
is equivalent to the conjunction of the two sentences
ϕ(Sa0, S f (a)0)
(1)
and
∀v2[ϕ(Sa0, v2) →v2 = S f (a)0].
(2)
The sentence (1) is a theorem of AE whenever ϕ represents f .
The sentence (2) is an assertion of uniqueness; we must construct
ϕ in such a way that this will also be a theorem of AE.
Begin with a formula θ known to represent f (as a binary
relation). Let ϕ be
θ(v1, v2) ∧∀z(z < v2 →¬ θ(v1, z)).
We can then rewrite (2) as
∀v2[θ(Sa0, v2) ∧∀z(z < v2 →¬ θ(Sa0, z))
→v2 = S f (a)0].
(2′)
To show this to be a theorem of AE it clearly sufﬁces to show that
AE ∪{θ(Sa0, v2), ∀z(z < v2 →¬ θ(Sa0, z))} ⊢v2 = S f (a)0.
Call this set of hypotheses (to the left of “⊢”) . Since L3 ∈AE
it sufﬁces to show that
 ⊢v2 ̸< S f (a)0
(3)
and
 ⊢S f (a)0 ̸< v2.
(4)
It is easy to obtain (4), since from the last member of  we get
S f (a)0 < v2 →¬ θ(Sa0, S f (a)0)
and we know that
AE ⊢θ(Sa0, S f (a)0).
(5)
To obtain (3) we ﬁrst note that we have as theorems of AE,
v2 < S f (a)0 ↔v2 = S00 ∨· · · ∨v2 = S f (a)−10
(6)
and
¬ θ(Sa0, Sb0)
for b = 0, . . . , f (a) −1.
(7)
The formulas (6) and (7) imply the formula
v2 < S f (a)0 →¬ θ(Sa0, v2).
(8)
Since θ(Sa0, v2) ∈, we have (3).

214
A Mathematical Introduction to Logic
This shows (2) to be a theorem of AE; (5) and (8) show (1) to
be a theorem of AE as well.
⊣
We next want to show that certain basic functions are representable
(in Cn AE) and that the class of representable functions has certain clo-
sure properties. Henceforth in this section, when we say that a function
or relation is representable, we will mean that it is representable in the
theory Cn AE. But the phrase “in Cn AE” will usually be omitted.
In simple cases, an m-place function might be represented by an
equation
vm+1 = t.
In fact, any such equation, when the variables in t are among v1, . . . , vm,
deﬁnes in N an m-place function f . (The value of f at ⟨a1, . . . , am⟩
is the number assigned in N to t when vi is assigned ai, 1 ≤i ≤m.)
Furthermore, we know that any equation is numeralwise determined by
AE,sotheequationrepresents f asarelation.Infact,itevenfunctionally
represents f , for the sentence
∀vm+1[vm+1 = t(Sa10, . . . , Sam0) ↔vm+1 = S f (a1,...,am)0]
is logically equivalent to
t(Sa10, . . . , Sam0) = S f (a1,...,am)0,
which is a quantiﬁer-free sentence true in N. (Here t(u1, . . . , um) is the
term obtained by replacing v1 by u1, then v2 by u2, etc.) For example:
1. The successor function is represented (functionally) by the
equation
v2 = Sv1.
2. Any constant function is representable. The m-place function that
constantly assumes the value b is represented by the equation
vm+1 = Sb0.
3. The projection function (where 1 ≤i ≤m)
I m
i (a1, . . . , am) = ai
is represented by the equation
vm+1 = vi.
4. Addition, multiplication, and exponentiation are represented by
the equations
v3 = v1 + v2,
v3 = v1 · v2,
v3 = v1 E v2,
respectively.

Chapter 3:
Undecidability
215
The reader should not be misled by these simple examples; not every
representable function is representable by an equation.
We next want to show that the family of representable functions is
closed under composition. To simplify the notation, we will consider a
one-place function f on N, where
f (a) = g(h1(a), h2(a)).
Supposethat g isfunctionallyrepresentedbyψ andhi byθi.Torepresent
f it would be reasonable to try either
∀y1 ∀y2(θ1(v1, y1) →θ2(v1, y2) →ψ(y1, y2, v2))
or
∃y1 ∃y2(θ1(v1, y1) ∧θ2(v1, y2) ∧ψ(y1, y2, v2)).
(Think of ψ(y1, y2, v2) as saying “g(y1, y2) = v2” and think of
θi(v1, y1) as saying “hi(v1) = yi.” Then the ﬁrst formula translates,
“For any y1, y2, if h1(v1) = y1 and h2(v1) = y2, then g(y1, y2) = v2.”
The second formula translates, “There exist y1, y2 such that h1(v1) = y1
and h2(v1) = y2 and g(y1, y2) = v2.” Either one is a reasonable way
of saying, “g(h1(v1), h2(v1)) = v2.” There are two choices, because
when something is unique, either quantiﬁer can be used for it.)
Actually either formula would work; let ϕ be
∀y1 ∀y2(θ1(v1, y1) →θ2(v1, y2) →ψ(y1, y2, v2)).
Consider any natural number a; we have at our disposal
∀v2[ψ(Sh1(a)0, Sh2(a)0, v2) ↔v2 = S f (a)0].
(1)
∀y1[θ1(Sa0, y1) ↔y1 = Sh1(a)0].
(2)
∀y2[θ2(Sa0, y2) ↔y2 = Sh2(a)0].
(3)
And we want
∀v2(ϕ(Sa0, v2) ↔v2 = S f (a)0),
(4)
i.e.,
∀v2( ∀y1 ∀y2[θ1(Sa0, y1) →θ2(Sa0, y2) →ψ(y1, y2, v2)]
↔v2 = S f (a)0).
(4)
But (1), (2), and (3) imply (4), as the reader is asked to verify in
Exercise 4.
More generally we have
THEOREM 33L
Let g be an n-place function, let h1, . . . , hn be m-
place functions, and let f be deﬁned by
f (a1, . . . , am) = g(h1(a1, . . . , am), . . . , hn(a1, . . . , am)).

216
A Mathematical Introduction to Logic
From formulas functionally representing g and h1, . . . , hn we can
ﬁnd a formula that functionally represents f .
In the above proof we have m = 1 and n = 2. But the general case
is proved in exactly the same way.
In order to obtain a function such as
f (a, b) = g(h(a), b),
we note that
f (a, b) = g

h

I 2
1 (a, b)

, I 2
2 (a, b)

.
The above theorem then can be applied (twice) to show that f is repre-
sentable (provided that g and h are).
To facilitate discussion of functions with an arbitrary number of
variables, we will use vector notation. For example, the equation in the
above theorem can be written
f (⃗a) = g(h1(⃗a), . . . , hn(⃗a)).
Another important closure property of the functions representable in
Cn AE is closure under the “least-zero” operator.
THEOREM 33M
Assume that the (m + 1)-place function g is repre-
sentable and that for every a1, . . . , am there is a b such that
g(a1, . . . , am, b) = 0.
Then we can ﬁnd a formula that represents the m-place function
f , where
f (a1, . . . , am) = the least b such that g(a1, . . . , am, b) = 0.
(In vector notation we can rewrite this last equation:
f (⃗a) = the least b such that g(⃗a, b) = 0.
The traditional notation for the least-zero operator is
f (⃗a) = μb[g(⃗a, b) = 0]
and the operator is often called “the μ-operator.”)
PROOF.
To simplify the notation we take m = 1; thus
f (a) = b
iff g(a, b) = 0
and for all
c < b, g(a, c) ̸= 0.
If ψ represents g, then we can obtain a formula representing f (as
a relation) simply by formalizing the right side of this equivalence:
ψ(v1, v2, 0) ∧∀y(y < v2 →¬ ψ(v1, y, 0)).

Chapter 3:
Undecidability
217
This formula deﬁnes (the graph of ) f and is numeralwise deter-
mined by AE.
⊣
A Catalog
We now construct a repertoire of representable (in Cn AE) functions and
relations, including in particular functions for encoding and decoding
sequences.
0. As a consequence of Theorem 33I, any relation that has (in N) a
quantiﬁer-free deﬁnition is representable. And the class of representable
relations is closed under unions, intersections, and complements. And
if R is representable, then so are
{⟨a1, . . . , am, b⟩| for all c < b, ⟨a1, . . . , am, c⟩∈R}
and
{⟨a1, . . . , am, b⟩| for some c < b, ⟨a1, . . . , am, c⟩∈R}.
For example, any ﬁnite relation has a quantiﬁer-free deﬁnition, as does
the ordering relation.
1. A relation R is representable iff its characteristic function K R is.
(K R is the function for which K R(⃗a) = 1 when ⃗a ∈R, and K R(⃗a) = 0
otherwise.)
PROOF.
(⇐) Say that R is a unary relation (a subset of N) and
that K R is represented by ψ(v1, v2). We claim that ψ(v1, S0)
represents R. For it deﬁnes R and is numeralwise determined
by AE.
(⇒) Say that ϕ(v1) represents R. Then
(ϕ(v1) ∧v2 = S0) ∨( ¬ ϕ(v1) ∧v2 = 0)
represents (the graph of ) K R, for the same reason as in the last
paragraph. (Actually this formula even functionally represents
K R, as the reader can verify.)
⊣
2. If R is a representable binary relation and f , g are representable
functions, then
{⃗a | ⟨f (⃗a), g(⃗a)⟩∈R}
is representable. Similarly for an m-ary relation R and functions
f1, . . . , fm.
PROOF.
Its characteristic function at ⃗a has the value K R( f (⃗a),
g(⃗a)). Thus it is obtained from representable functions by com-
position.
⊣
For example, suppose that R is a representable ternary relation. Then
{⟨x, y⟩| ⟨y, x, x⟩∈R}

218
A Mathematical Introduction to Logic
is representable, being
"
⟨x, y⟩
##
I 2
2 (x, y), I 2
1 (x, y), I 2
1 (x, y)

∈R
$
.
In this way we can rearrange and repeat variables in describing a repre-
sentable relation.
3. If R is a representable binary relation, then so is
P = {⟨a, b⟩| for some c ≤b, ⟨a, c⟩∈R}.
PROOF.
We have from catalog item 0 that if
Q = {⟨a, b⟩| for some c < b, ⟨a, c⟩∈R},
then Q is representable. And
⟨a, b⟩∈P ⇔⟨a, S(b)⟩∈Q
⇔

I 2
1 (a, b), S

I 2
2 (a, b)

∈Q.
Hence by catalog item 2, P is representable.
⊣
More generally, if R is a representable (m + 1)-ary relation, then
{⟨a1, . . . , am, b⟩| for some c ≤b, ⟨a1, . . . , am, c⟩∈R}
is also representable. In vector notation this relation becomes
{⟨⃗a, b⟩| for some c ≤b, ⟨⃗a, c⟩∈R}.
Similarly
{⟨⃗a, b⟩| for all c ≤b, ⟨⃗a, c⟩∈R}
is representable.
4. The divisibility relation
{⟨a, b⟩| a divides b in N}
is representable.
PROOF.
We have a divides b iff for some q ≤b, a·q = b. We know
that{⟨a, b, q⟩| a·q = b}isrepresentable,asithasaquantiﬁer-free
deﬁnition. Upon applying the above items, we get the divisibility
relation. (In yet further detail, from catalog item 3 we get the
representability of
R = {⟨a, b, c⟩| for some q ≤c, a · q = b}
and a divides b iff ⟨a, b, b⟩∈R.)
⊣
5. The set of primes is representable.
6. The set of pairs of adjacent primes is representable.
PROOF.
⟨a, b⟩is a pair of adjacent primes iff a is prime and b is
prime and a < b and there does not exist any c < b such that

Chapter 3:
Undecidability
219
a < c and c is prime. The right side of this equivalence is easily
formalized by a numeralwise determined formula.
⊣
Note (for future use in Section 3.8) that we have not yet used the fact
that exponentiation is representable.
Observe that as this catalog progresses, we are in effect building up
a “language” L such that anything (any relation, any function) that is
L-deﬁnable (in N) will be certain to be representable in our theory.
Thus, Theorem 33I tells us that (a) atomic formulas are allowed in L,
(b) all sentential connectives are permitted, and (c) bounded quantiﬁers
can be used. (Unbounded quantiﬁers are not in general allowed.) Then
our catalog gradually adds particular predicate symbols and function
symbols; catalog item 6 adds a two-place predicate symbol for “adja-
cent primality”; and catalog item 7 will add a function symbol for the
prime-listing function. Theorem 33L justiﬁes using these function sym-
bols inside expressions of L.
7. The function whose value at a is pa, the (a + 1)st prime, is
representable. (Thus p0 = 2, p1 = 3, p2 = 5, p3 = 7, p4 = 11, and so
forth.)
PROOF.
pa = b iff b is prime and there exists some c ≤ba2, such
that (i)–(iii) hold:
(i) 2 does not divide c.
(ii) For any q < b and any r ≤b, if ⟨q,r⟩is a pair of adjacent
primes, then for all j < c,
q j divides c ⇐⇒r j+1 divides c.
(iii) ba divides c and ba+1 does not.
This equivalence is not obvious, but at least the relation deﬁned
by the right-hand side is representable. To verify the equivalence,
ﬁrst note that if pa = b, then we can take
c = 20 · 31 · 52 · . . . · pa
a.
It is easy to check that this value of c meets all the conditions.
Conversely, suppose c is a number meeting conditions (i)–(iii).
We claim that c must be
20 · 31 · . . . · ba · powers of larger primes.
Certainly the exponent of 2 in c is 0, by (i). We can use (ii) to
work our way across to the prime b. But by (iii) the exponent of
b is a, so b must be the (a + 1)st prime, pa.
⊣

220
A Mathematical Introduction to Logic
This function will be very useful in encoding ﬁnite sequences of
numbers into single numbers. Let
⟨a0, . . . , am⟩= pa0+1
0
· · · · · pam+1
m
= %
i≤m
pai+1
i
.
This holds also for m = −1; we deﬁne ⟨⟩= 1. For example,
⟨2, 1⟩= 23 · 32 = 72.
The idea is that 72 safely encodes the pair ⟨2, 1⟩.
There are other ways to encode pairs of numbers and ﬁnite sequences
of numbers. In Section 3.8, we will make use of a pairing function
J(a, b) = 1
2[(a + b)2 + 3a + b]
that has the advantage of growing at a polynomial rate, unlike the growth
rate of 2a+13b+1. Here is a very different way to encode, for example, the
numbers 24, 117, 11 (in that order). First we convert to numerals in base
9: 26, 140, 12. Secondly, we concatenate these numerals, separated by
9’s: 269140912. The triple is encoded by the number thereby designated
(in base 10), that is, 269,140,912. This method may seem tricky, but it
produces a result that is much smaller than 2253118512, which requires
73 digits in base 10.
8. Foreachm,thefunctionwhosevalueata0, . . . , am is⟨a0, . . . , am⟩
is representable.
9. There is a representable function (whose value at ⟨a, b⟩is written
(a)b) such that for b ≤m,
(⟨a0, . . . , am⟩)b = ab.
(This is our “decoding” function. For example, (72)0 = 2 and (72)1 = 1.)
PROOF.
We deﬁne (a)b to be the least n such that either a = 0 or
pn+2
b
does not divide a. (There always is such an n.) Observe that
(0)b = 0, and for a ̸= 0, (a)b is one less than the exponent of
pb in the prime factorization of a (but not less than 0). Hence for
b ≤m,
(⟨a0, . . . , am⟩)b = ab.
To prove representability we use the least-zero operator. Let
R = {⟨a, b, n⟩| a = 0 or pn+2
b
does not divide a}.
Then (a)b = μn[K R(a, b, n) = 0], where R is the complement
of R.
⊣
Since the method used in the above proof will be useful elsewhere
as well, we here state it separately:

Chapter 3:
Undecidability
221
THEOREM 33N
Assume that R is a representable relation such that
for every ⃗a there is some n such that ⟨⃗a, n⟩∈R. Then the function
f deﬁned by
f (⃗a) = the least n such that ⟨⃗a, n⟩∈R
is representable.
PROOF.
f (⃗a) = μn[K R(⃗a, n) = 0].
⊣
We will later use the notation
f (⃗a) = μn[⟨⃗a, n⟩∈R].
10. Say that b is a sequence number iff for some m ≥−1 and some
a0, . . . , am,
b = ⟨a0, . . . , am⟩.
(When m = −1 we get ⟨⟩= 1.) Then the set of sequence numbers is
representable.
PROOF.
Exercise 5.
⊣
11. There is a representable function lh such that
lh⟨a0, . . . , am⟩= m + 1.
(Here “lh” stands for “length.” For example, lh 72 = 2.)
PROOF.
We deﬁne lh a to be the least n such that either a = 0 or
pn does not divide a. This works.
⊣
12. There is a representable function (whose value at ⟨a, b⟩is called
the restriction of a to b, written a ↾b) such that for any b ≤m + 1,
⟨a0, . . . , am⟩↾b = ⟨a0, . . . , ab−1⟩.
PROOF.
Let a ↾b be the least n such that either a = 0 or both n ̸= 0
and for any j < b, any k < a
pk
j divides a ⇒pk
j divides n.
This works.
⊣
13. (Primitive recursion) With a (k + 1)-place function f we asso-
ciate another function f such that f (a, b1, . . . , bk) encodes the values
of f ( j, b1, . . . , bk) for all j < a. Speciﬁcally, let
f (a, ⃗b) = ⟨f (0, ⃗b), . . . , f (a −1, ⃗b)⟩.
For example, f (0, ⃗b) = ⟨⟩= 1, encoding the ﬁrst zero values of
f . f (1, ⃗b) = ⟨f (0, ⃗b)⟩. In any case, f (a, ⃗b) is a sequence number of
length a, encoding the ﬁrst a values of f .

222
A Mathematical Introduction to Logic
Now suppose we are given a (k + 2)-place function g. There exists
a unique function f satisfying
f (a, ⃗b) = g( f (a, ⃗b), a, ⃗b).
For example,
f (0, ⃗b) = g(⟨⟩, 0, ⃗b),
f (1, ⃗b) = g(⟨f (0, ⃗b)⟩, 1, ⃗b).
(The existence and uniqueness of this f should be intuitively clear. For
a proof, we can apply the recursion theorem of Section 1.4, obtaining
ﬁrst f and then extracting f .)
THEOREM 33P
Let g be a (k + 2)-place function and let f be the
unique (k + 1)-place function such that for all a and (k-tuples) ⃗b,
f (a, ⃗b) = g( f (a, ⃗b), a, ⃗b).
If g is representable, then so is f .
PROOF.
First we claim that f is representable.
This follows from the fact that
f (a, ⃗b) = the least s such that s is a sequence number of
length a and for i less than a, (s)i = g(s ↾i, i, ⃗b).
It then follows that f is representable, since
f (a, ⃗b) = g( f (a, ⃗b), a, ⃗b)
and the functions on the right are representable.
⊣
Actually the phrase “primitive recursion” is more commonly applied
to a simpler version of this, given in Exercise 8.
14. For a representable function F, the function whose value at
a, ⃗b is
&
i<a
F(i, ⃗b)
is also representable. Similarly with  in place of . (For a = 0, we
use the standard conventions: The empty product — the product of no
numbers — is 1, and the empty sum is 0.)
PROOF.
Call this function G; then
G(0, ⃗b) = 1,
G(a + 1, ⃗b) = F(a, ⃗b) · G(a, ⃗b).
Apply Exercise 8.
⊣
15. Deﬁne the concatenation of a and b, a ∗b, by
a ∗b = a ·
&
i<lhb
p(b)i+1
i+lh a .

Chapter 3:
Undecidability
223
This is a representable function of a and b, and
⟨a1, . . . , am⟩∗⟨b1, . . . , bn⟩= ⟨a1, . . . , am, b1, . . . , bn⟩.
The concatenation operation has the further property of being associa-
tive on sequence numbers.
16. We will also want a “capital asterisk” operation. Let
∗i<a f (i) = f (0) ∗f (1) ∗· · · ∗f (a −1).
For a representable function F, the function whose value at a, ⃗b is
∗i<a F(i, ⃗b) is representable.
PROOF. ∗i<0F(i, ⃗b) = ⟨⟩= 1 and
∗i<a+1F(i, ⃗b) = ∗i<a F(i, ⃗b) ∗F(a, ⃗b).
So this is just like catalog item 14.
⊣
Exercises
1. Show that in the structure (N; ·, E) we can deﬁne the addition re-
lation {⟨m, n, m + n⟩| m, n in N}. Conclude that in this structure
{0}, the ordering relation <, and the successor relation {⟨n, S(n)⟩|
n ∈N} are deﬁnable. (Remark: This result can be strengthened by
replacing the structure (N; ·, E) by simply (N; E). The multipli-
cation relation is deﬁnable here, by exploiting one of the laws of
exponents: (da)b = dab.)
2. Prove Theorem 33C, stating that true (in N) quantiﬁer-free sen-
tences are theorems of AE. (See the outline given there.)
3. A theory T (in a language with 0 and S) is called ω-complete iff
for any formula ϕ and variable x, if ϕx
Sn0 belongs to T for every
natural number n, then ∀xϕ belongs to T . Show that if T is a
consistent ω-complete theory in the language of N and if AE ⊆T ,
then T = Th N.
4. Show that in the proof preceding Theorem 33L, formula (4) is
logically implied by the set consisting of formulas (1), (2), and (3).
5. Show that the set of sequence numbers is representable (catalog
item 10).
6. Is 3 a sequence number? What is lh 3? Find (1∗3)∗6 and 1∗(3∗6).
7. Establish the following facts:
(a) a + 1 < pa.
(b) (b)k ≤b; equality holds iff b = 0.
(c) lh a ≤a; equality holds iff a = 0.
(d) a ↾i ≤a.
(e) lh(a ↾i) is the smaller of i and lh a.

224
A Mathematical Introduction to Logic
8. Let g and h be representable functions, and assume that
f (0, b) = g(b),
f (a + 1, b) = h( f (a, b), a, b).
Show that f is representable.
9. Show that there is a representable function f such that for every
n, a0, . . . , an,
f (⟨a0, . . . , an⟩) = an.
(For example, f (72) = 1 and f (750) = 2.)
10. Assume that R is a representable relation and that g and h are
representable functions. Show that f is representable, where
f (⃗a) =

g(⃗a)
if ⃗a ∈R,
h(⃗a)
if ⃗a /∈R.
11. (Monotone recursion) Assume that R is a representable binary re-
lation on N. Let C be the smallest subset of N (i.e., the intersection
of all subsets) such that for all n, a0, . . . , an−1, b,
⟨⟨a0, . . . , an−1⟩, b⟩∈R & ai ∈C (for all i < n) ⇒b ∈C.
Further assume that (1) for all n, a0, . . . , an−1, b,
⟨⟨a0, . . . , an−1⟩, b⟩∈R
⇒ai < b (for all i < n),
and (2) there is a representable function f such that for all n,
a0, . . . , an−1, b,
⟨⟨a0, . . . , an−1⟩, b⟩∈R
⇒n < f (b)
Show that C is representable. (C is, in a sense, generated by R.
C ̸= ∅in general because if ⟨⟨⟩, b⟩∈R, then b ∈C.)
SECTION 3.4
Arithmetization of Syntax
In this section we intend to develop two themes:
1. Certain assertions about wffs can be converted into assertions
about natural numbers (by assigning numbers to expressions).
2. These (English) assertions about natural numbers can in many
cases be translated into the formal language. And the theory Cn AE is
strong enough to prove many of the translations so obtained.
This will give us the ability to construct formulas that, by expressing
facts about numbers, indirectly express facts about formulas (even about
themselves!). Such an ability will be exploited in Section 3.5 to obtain
results of undeﬁnability and undecidability.

Chapter 3:
Undecidability
225
G¨odel Numbers
We ﬁrst want to assign numbers to expressions of the formal language.
Recall that the symbols of our language are those listed in Table IX.
TABLE IX
Parameters
Logical symbols
0. ∀
1. (
2. 0
3. )
4. S
5. ¬
6. <
7. →
8. +
9. =
10. ·
11. v1
12. E
13. v2, etc.
There is a function h assigning to each symbol the integer listed to
its left. Thus h(∀) = 0, h(0) = 2, and h(vi) = 9 + 2i. In order to make
our subsequent work more widely applicable, we will assume only that
we have some language with 0 and S which is recursively numbered. By
this we mean that we have a one-to-one function h from the parameters
of that language into the even numbers such that the two relations
{⟨k, m⟩| k is the value of h at some m-place predicate parameter}
and
{⟨k, m⟩| k is the value of h at some m-place function symbol}
are both representable in Cn AE. Of course in the case of the lan-
guage of N these sets are even ﬁnite. The ﬁrst set is {⟨6, 2⟩} and the
second is
{⟨2, 0⟩, ⟨4, 1⟩, ⟨8, 2⟩, ⟨10, 2⟩, ⟨12, 2⟩}.
We deﬁne h on the logical symbols as before; thus h(s) is an odd number
for each logical symbol s.
For an expression ε = s0 · · · sn of the language we deﬁne its G¨odel
number, ♯(ε), by
♯(s0 · · · sn) = ⟨h(s0), . . . , h(sn)⟩.
For example, using our original function h for the language of N, we
obtain
♯(∃v3 v3 = 0)
= ♯(( ¬ ∀v3( ¬ =v30)))
= ⟨1, 5, 0, 15, 1, 5, 9, 15, 2, 3, 3⟩
= 22 · 36 · 51 · 716 · 112 · 136 · 1710 · 1916 · 233 · 294 · 314.

226
A Mathematical Introduction to Logic
This is a large number, being of the order of 1.3 × 1075. To a set 
of expressions we assign the set
♯ = {♯(ε) | ε ∈}
of G¨odel numbers.
To a sequence ⟨α0, . . . , αn⟩of expressions (such as a deduction), we
assign the number
G(⟨α0, . . . , αn⟩) = ⟨♯α0, . . . , ♯αn⟩.
We now proceed to show that various relations and functions having
to do with G¨odel numbers are representable in Cn AE (and hence are
recursive). As in the preceding section, whenever we say that a relation
or function is representable (without specifying a theory) we mean that
it is representable in the theory Cn AE.
We will make use of certain abbreviations in the language we use (i.e.,
English, although it is coming to differ more and more from what one
ordinarily thinks of as English). For “there is a number a such that” we
write “∃a.” In the same spirit, “∃a, b < c” means “there are numbers
a and b both of which are less than c such that.” Similarly, we may
employ “∀.” We would not have dared to employ such abbreviations in
Chapter 2, for fear of creating confusion between the formal language
and the meta-language (English). But by now we trust the reader to
avoid such erroneous ways.
1. The set of G¨odel numbers of variables is representable.
PROOF.
It is {a | (∃b < a)a = ⟨11 + 2b⟩}. It follows from results
of the preceding section that this is a representable set.
⊣
2. The set of G¨odel numbers of terms is representable.
PROOF.
The set of terms was deﬁned inductively. And terms were
built up from constituents with smaller G¨odel numbers. We will
treat this case in some detail, since it is typical of the argument
used for inductively deﬁned relations.
Let f be the characteristic function of the set of G¨odel numbers
of terms. From the deﬁnition of “term” we obtain
f (a) =
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
1
if a is the G¨odel number of a variable,
1
if (∃i < □, ∃k < a) [i is a sequence number
& (∀j < lh i) f ((i) j) = 1 & k is the value of
h at some (lh i)-place function symbol &
a = ⟨k⟩∗∗j<lh i(i) j],
0
otherwise.
But what upper bound for i can we use in place of that “□”
symbol? Before we can argue that f is representable, we will

Chapter 3:
Undecidability
227
need an upper bound on i that depends in some representable
way on a.
The claim is that we can take i < aa lh a. To see this, suppose
that a = ♯st1 · · · tn (where s is an n-place function symbol and
t1, . . . , tn are terms). Then we want to take i = ⟨♯t1, . . . , ♯tn⟩.
How big could this be, in terms of a? We have the bounds:
i = 2♯t1+1 · · · p♯tn+1
n−1
≤2a · · · pa
n−1
< 2a · · · pa
lh a−1
because n = lh i < lh a
≤aa · · · aa
(lh a times) because a = 2(a)0+1 · · · p(a)lh a−1+1
lh a−1
≥plh a−1
= (aa)lh a = aa lh a
So in the above equation for f , we replace □by aa lh a.
Although the right side of this equation refers to f , it refers
only to f ((i) j), where (i) j < a. This feature permits us to apply
primitive recursion. f (a) = g( f (a), a), where
g(s, a) =
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
1
if a is the G¨odel number of a variable,
1
if (∃i < aa lh a, ∃k < a) [i is a sequence number
& (∀j < lh i)(s)(i) j = 1 & k is the value of
h at some (lh i)-place function symbol &
a = ⟨k⟩∗∗j<lh i(i) j],
0
otherwise.
For if in this equation we set s equal to f (a), then (s)(i) j = f ((i) j)
for (i) j < a. Hence by Theorem 33P, f is representable provided
that g is.
It remains to show that g is representable. But this is straight-
forward, by using results of the preceding section. Brieﬂy, the
graph of g is the union of three relations, corresponding to the
three clauses in the above equation. Each of the three is obtained
from equality and other representable relations by bounded quan-
tiﬁcation and the substitution of representable functions.
⊣
3. The set of G¨odel numbers of atomic formulas is representable.
PROOF.
a is the G¨odel number of an atomic formula iff (∃i <
aa lh a, ∃k < a) [i is a sequence number & (∀j < lh i)(i) j is the
G¨odel number of a term & k is the value of h at some (lh i)-place
predicate symbol & a = ⟨k⟩∗∗j<lh i(i) j].
⊣
4. The set of G¨odel numbers of wffs is representable.

228
A Mathematical Introduction to Logic
PROOF.
The wffs were inductively deﬁned. Let f be the character-
istic function of the set, then
f (a) =
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
1
if a is the G¨odel number of an atomic formula,
1
if (∃i < a)[a = ⟨h((), h(¬)⟩∗i ∗⟨h())⟩
& f (i) = 1],
1
if (∃i, j < a)[a = ⟨h(()⟩∗i ∗⟨h(→)⟩∗j ∗⟨h())⟩
& f (i) = f ( j) = 1],
1
if (∃i, j < a)[a = ⟨h(∀)⟩∗i ∗j & i is the G¨odel
number of a variable and f ( j) = 1],
0
otherwise.
By the same argument used for the set of G¨odel numbers of terms,
we have the representability of f .
⊣
5. There is a representable function Sb such that for a term or formula
α, variable x, and term t,
Sb(♯α, ♯x, ♯t) = ♯αx
t .
PROOF.
We will need to deﬁne Sb(a, b, c) making use of values
Sb(i, b, c) where i < a. As in the case of catalog item 2 (the char-
acteristic function of the set of terms), it will then be possible to
show that both Sb and Sb are representable.
The function Sb is described by the following six clauses
(i)–(vi):
(i) If a is the G¨odel number of a variable and a = b then
Sb(a, b, c) = c.
(ii) If (∃i < aa lh a, ∃k < a)[i is a sequence number & (∀j <
lh i)(i) j is the G¨odel number of a term & k is the value of h at some
(lh i)-place function or predicate symbol & a = ⟨k⟩∗∗j<lh i(i) j]
then
Sb(a, b, c) = ⟨k⟩∗∗j<lh iSb((i) j, b, c)
for that i and k.
(iii) If (∃i < a)[i is the G¨odel number of a wff & a =
⟨h((), h(¬)⟩∗i ∗⟨h())⟩] then
Sb(a, b, c) = ⟨h((), h(¬)⟩∗Sb(i, b, c) ∗⟨h())⟩
for that i.
(iv) If (∃i, j < a)[i and j are G¨odel numbers of wffs & a =
⟨h(()⟩∗i ∗⟨h(→)⟩∗j ∗⟨h())⟩] then
Sb(a, b, c) = ⟨h(()⟩∗Sb(i, b, c) ∗⟨h(→)⟩∗Sb( j, b, c) ∗⟨h())⟩
for that i and j.

Chapter 3:
Undecidability
229
(v) If (∃i, j < a)[i is the G¨odel number of a variable & i ̸= b
& j is the G¨odel number of a wff & a = ⟨h(∀)⟩∗i ∗j] then
Sb(a, b, c) = ⟨h(∀)⟩∗i ∗Sb( j, b, c)
for that i and j.
(vi) If none of the above conditions on a and b are met (where
we ignore the displayed equation for Sb(a, b, c)) then
Sb(a, b, c) = a.
Then the function Sb is obtained by primitive recursion
Sb(a, b, c) = G(Sb(a, b, c), a, b, c)
where G is a 4-place function. The graph of G is the union of six
5-ary relations
G = R1 ∪R2 ∪R3 ∪R4 ∪R5 ∪R6
corresponding to the six clauses above.
The ﬁrst of the six is
R1 = {⟨s, a, b, c, d⟩| a is the G¨odel number of a variable &
a = b & d = c}.
The second one is
R2 = {⟨s, a, b, c, d⟩| (∃i < aa lh a, ∃k < a)[i is a sequence number
& (∀j < lh i)(i) j is the G¨odel number of a term & k is the
value of h at some (lh i)-place function or predicate symbol &
a = ⟨k⟩∗∗j<lh i(i) j & d = ⟨k⟩∗∗j<lh i (s)(i) j]}
and the others are similar translations of the corresponding clauses
in the description of Sb.
It is necessary to note that G is indeed a function; it is single-
valued. This is because no two clauses could apply to one number
a. And if, for example, clause (ii) applies to a, then we know from
Section 2.3 that the numbers i and k are uniquely determined.
Finally, we apply the usual methods to verify that R1–R6 are
representable, so G is representable, so Sb is representable, so Sb
is representable. (Substitution is a complicated operation!)
⊣
6. The function whose value at n is ♯(Sn0) is representable.
PROOF.
Call this function f ; then
f (0) = ⟨h(0)⟩,
f (n + 1) = ⟨h(S)⟩∗f (n).
Apply Exercise 8 of the preceding section.
⊣
7. There is a representable relation Fr such that for a term or formula
α and a variable x,
⟨♯α, ♯x⟩∈Fr ⇔x occurs free in α.

230
A Mathematical Introduction to Logic
PROOF.
⟨a, b⟩∈Fr ⇔Sb(a, b, ♯0) ̸= a.
⊣
8. The set of G¨odel numbers of sentences is representable.
PROOF.
a is the G¨odel number of a sentence iff a is the G¨odel
number of a formula and for any b < a, if b is the G¨odel number
of a variable then ⟨a, b⟩/∈Fr.
⊣
9. There is a representable relation Sbl such that for a formula α,
variable x, and term t, ⟨♯a, ♯x, ♯t⟩∈Sbl iff t is substitutable for x in α.
PROOF.
Exercise 1.
⊣
10. The relation Gen, where ⟨a, b⟩∈Gen iff a is the G¨odel number of
a formula and b is the G¨odel number of a generalization of that formula,
is representable.
PROOF.
⟨a, b⟩∈Gen iff a = b or (∃i, j < b)[i is the G¨odel number
of a variable and ⟨a, j⟩∈Gen and b = ⟨(h(∀)⟩∗i ∗j]. Apply
the usual argument to the characteristic function of Gen.
⊣
11. The set of G¨odel numbers of tautologies is representable.
The set of tautologies is informally decidable since we can use the
method of truth tables. To obtain representability, we recast truth tables
in terms of G¨odel numbers. There are several preliminary steps:
11.1 The relation R, such that ⟨a, b⟩∈R iff a is the G¨odel number
of a formula α and b is the G¨odel number of a prime constituent of α,
is representable.
PROOF.
⟨a, b⟩∈R ⇔a is the G¨odel number of a formula and one
of the following:
(i) a = b & (a)0 ̸= h(().
(ii) (∃i < a)[a = ⟨h((), h(¬)⟩∗i ∗⟨(h())⟩and ⟨i, b⟩∈R].
(iii) The analogue to (ii) but with →.
Apply the usual argument to the characteristic function of R.
⊣
11.2 There is a representable function P such that for a formula
α, P(♯α) = ⟨♯β1, . . . , ♯βn⟩, the list of G¨odel numbers of prime con-
stituents of α, in numerical order.
PROOF.
First deﬁne a function g for locating the next prime con-
stituent in ♮a after ♮y (where ♮a is the formula α for which
a = ♯α).
g(a, y) = the least n such that either n = a + 1 or both
y < n and ⟨a, n⟩∈R.
Next deﬁne a function h such that h(a, n) gives the (n+1)st prime
constituent of ♮a (if there are that many):
h(a, 0) = g(a, 0)
h(a, n + 1) = g(a, h(a, n)).

Chapter 3:
Undecidability
231
Finally, let P(a) = ∗i<k⟨h(a, i)⟩where k is the least number for
which h(a, k) > a.
⊣
11.3 Say that the integer v encodes a truth assignment for α iff v is
a sequence number and lh v = lh P(♯α) and (∀i < lh v)(∃e < 2)(v)i =
⟨(P(♯α))i, e⟩. This is a representable condition on v and ♯α.
For example, if P(♯α) = ⟨♯β0, . . . , ♯βn⟩, then
v = ⟨⟨♯β0, e0⟩, . . . , ⟨♯βn, en⟩⟩,
where each ei is 0 or 1. We will later need an upper bound for v in terms
of ♯α. The largest v is obtained when each ei is 1. Also ♯βi ≤♯α, so
that
v ≤⟨⟨♯α, 1⟩, . . . , ⟨♯α, 1⟩⟩
= ∗i<lh P(♯α)⟨⟨♯α, 1⟩⟩.
11.4 There is a representable relation Tr such that for a formula α
and a v which encodes a truth assignment for α (or more), ⟨♯α, v⟩∈Tr
iff that truth assignment satisﬁes α.
PROOF.
Exercise 2.
⊣
Finally, α is a tautology iff α is a formula and for every v encoding a
truth assignment for α, ⟨♯α, v⟩∈Tr. The (English) quantiﬁer on v can
be bounded by a representable function of ♯α, as explained in 11.3.
12. The set of G¨odel numbers of formulas of the form ∀x ϕ →ϕx
t ,
where t is a term substitutable for the variable x in ϕ, is representable.
PROOF.
α is of this form iff (∃wff ϕ < α)(∃variable x < α)(∃term
t < α)[t is substitutable for x in ϕ and α = ∀x ϕ →ϕx
t ]. Here
“ϕ < α” means that ♯ϕ < ♯α. This is easily rewritten in terms of
G¨odel numbers: a belongs to the set iff (∃f < a)(∃x < a)(∃t < a)
[ f is the G¨odel number of a formula & x is the G¨odel number of
a variable & t is the G¨odel number of term and ⟨f, x, t⟩∈Sbl &
a = ⟨h( ( ), h(∀)⟩∗x ∗f ∗⟨h(→)⟩∗Sb( f, x, t) ∗⟨h())⟩].
13. The set of G¨odel numbers of formulas of the form ∀x(α→β)→
∀x α →∀x β is representable.
PROOF.
γ is of this form iff (∃variable x < γ )(∃formulas
α, β < γ ) [γ = ∀x(α →β) →∀x α →∀x β]. This is eas-
ily rewritten in terms of G¨odel numbers, as in 12.
⊣
14. The set of G¨odel numbers of formulas of the form α →∀x α,
where x does not occur free in α, is representable.
PROOF.
Similar to 13.
⊣
15. The set of G¨odel numbers of formulas of the form x = x is
representable.

232
A Mathematical Introduction to Logic
PROOF.
Similar to 13.
⊣
16. The set of G¨odel numbers of formulas of the form x=y→α→α′,
where α is atomic and α′ is obtained from α by replacing x at zero or
more places by y, is representable.
PROOF.
This is similar to 13, except for the relation of “partial
substitution.” Let ⟨a, b, x, y⟩∈Psb iff x and y are G¨odel numbers
of variables, a is the G¨odel number of an atomic formula, b is a
sequence number of length lh a, and for all j < lh a, either (a) j =
(b) j or (a) j = x and (b) j = y. This relation is representable. ⊣
17. The set of G¨odel numbers of logical axioms is representable.
PROOF.
α is a logical axiom iff ∃β ≤α such that α is a generaliza-
tion of β and β is in one of the sets in items 11–16.
⊣
18. For a ﬁnite set A of formulas,
{G(D) | D is a deduction from A}
is representable. In fact it is enough here for ♯A to be representable.
PROOF.
A number d belongs to this set iff d is a sequence number
of positive length and for every i less than lh d, either
1. (d)i ∈♯A,
2. (d)i is the G¨odel number of a logical axiom, or
3. (∃j, k < i)[(d) j = ⟨h(()⟩∗(d)k ∗⟨h(→)⟩∗(d)i ∗⟨h())⟩].
This is representable whenever ♯A is, as is certainly the case
for ﬁnite A.
⊣
19. Any recursive relation is representable in Cn AE.
PROOF.
Recall that the relation R is recursive iff there is some ﬁnite
consistent set A of sentences such that some formula ρ represents
R in Cn A. (There is no loss of generality in assuming that the
language has only ﬁnitely many parameters: those in the ﬁnite set
A, those in ρ, and 0, S, and ∀.) In the case of a unary relation R,
we have that a ∈R iff the least D which is a deduction from A of
either ρ(Sa0) or ¬ ρ(Sa0) is, in fact, a deduction of the former.
Moreformally,a ∈R iffthelastcomponentof f (a)is♯ρ(Sa0),
where
f (a) = the least d such that d is in the set of item 18 and the
last component of d is either ♯ρ(Sa0) or ♯¬ ρ(Sa0).
For this (ﬁxed) ρ, there always is such a d.
⊣
Since the converse to item 19 is immediate, we have
THEOREM 34A
A relation is recursive iff it is representable in the
theory Cn AE.

Chapter 3:
Undecidability
233
Henceforth we will usually use the word “recursive” in preference
to “representable.”
COROLLARY 34B
Any recursive relation is deﬁnable in N.
20. Now suppose we have a set A of sentences such that ♯A is re-
cursive. Then ♯Cn A need not be recursive (as we will show in the next
section). But we do have a way of deﬁning Cn A from A:
a ∈♯Cn A
iff
∃d[d is the number of a deduction from A
and the last component of d is a and a is the
G¨odel number of a sentence]
The part in square brackets is recursive, by the proof to item 18. But we
cannot in general put any bound on the number d. The best we can say
is that ♯Cn A is the domain of a recursive relation (or, as we will say
later, is recursively enumerable).
Item 20 will play a key role our subsequent work. In particular, it
will later be restated as Theorem 35I.
21. If ♯A is recursive and Cn A is a complete theory, then ♯Cn A is
recursive.
In other words, a complete recursively axiomatizable theory is re-
cursive. This is the analogue to Corollary 25G, which asserts that a
complete axiomatizable theory is decidable.
The proof is essentially unchanged. Let (in the consistent case)
g(s) = the least d such that s is not the G¨odel number of a sentence,
or d is in the set of item 18 and the last component of d is
either s or is ⟨h((), h(¬)⟩∗s ∗⟨h())⟩.
Thus g(♯σ) is G of the least deduction of σ or ( ¬ σ) from A. And
s ∈♯Cn A iff s > 0 and the last component of g(s) is s.
⊣
At this point we might reconsider the plausibility of Church’s thesis.
Suppose that the relation R is decidable. Then there is a ﬁnite list of
explicit instructions (a program) for the decision procedure. The pro-
cedure itself will presumably consist of certain atomic steps, which
are then performed repeatedly. (The reader familiar with computer pro-
gramming will know that a short program can still require much time
for its execution, but some commands will be utilized over and over.)
Any one atomic step is presumably very simple.
By devices akin to G¨odel numbering, we can mirror the decision
procedure in the integers. The characteristic function of R can then be
put in the form

234
A Mathematical Introduction to Logic
K R(⃗a) = U[the least s such that
(i) (s)0 encodes the input ⃗a;
(ii) for all positive i < lh s, (s)i is obtained from (s)i−1 by perfor-
mance of the applicable atomic step;
(iii) the last component of s describes a terminal situation, at which
the computation is completed],
where U (the upshot function) is some simple function that extracts
from the last component of s the answer (afﬁrmative or negative). The
recursiveness of R is now reduced to the recursiveness of U and of
the relations indicated in (i), (ii), and (iii). In special cases, such as
decision procedures provided by the register machines of Section 3.6,
the recursiveness of these components is easily veriﬁed. It seems most
improbablethatanydecisionprocedurewilleverberegardedaseffective
and yet will have components that are nonrecursive. For example, in (ii),
it seems that it ought to be possible to make each atomic step extremely
simple, and in particular to make each one recursive.
Exercises
1. Supply a proof for item 9 of this section.
2. Supply a proof for item 11.4 of this section.
3. Use Exercise 11 of Section 3.3 to give a new proof that the set of
G¨odel numbers of terms is representable (item 2).
4. Let T be a consistent recursively axiomatizable theory (in a recur-
sively numbered language with 0 and S). Show that any relation
representable in T must be recursive.
SECTION 3.5
Incompleteness and Undecidability
In this section we reap the rewards of our work in Sections 3.3 and 3.4.
We have assigned G¨odel numbers to expressions, and we have shown
that certain intuitively decidable relations on N (related to syntactical
notions about expressions) are representable in Cn AE.
Throughout this section we assume that the language in question is
the language of N. (This affects the meaning of “Cn” and “theory.”)
FIXED-POINT LEMMA
Given any formula β in which only v1 occurs
free, we can ﬁnd a sentence σ such that
AE ⊢[σ ↔β(S♯σ0)].
We can think of σ as indirectly saying, “β is true of me.” Ac-
tually, of course, σ doesn’t say anything; it’s just a string of sym-
bols. And even when translated into English according to the intended

Chapter 3:
Undecidability
235
structure N, it then talks of numbers and their successors and products
and so forth. It is only by virtue of our having associated numbers with
expressions that we can think of σ as referring to a formula, in this case
to σ itself.
PROOF.
Let θ(v1, v2, v3) functionally represent in Cn AE a func-
tion whose value at ⟨♯α, n⟩is ♯(α(Sn0)). (See items 5 and 6 in
Section 3.4.) First consider the formula
∀v3[θ(v1, v1, v3) →β(v3)].
(1)
(Wemaysupposev3 issubstitutableforv1 inβ.Theaboveformula
has only v1 free. It deﬁnes in N a set to which ♯α belongs iff
♯(α(S♯α0)) is in the set deﬁned by β.) Let q be the G¨odel number
of (1). Let σ be
∀v3[θ(Sq0, Sq0, v3) →β(v3)].
Thus σ is obtained from (1) by replacing v1, by Sq0. Notice that
σ does assert (under N) that ♯σ is in the set deﬁned by β. But we
must check that
σ ↔β(S♯σ0)
(2)
is a consequence of AE. Because θ functionally represents a func-
tion whose value at ⟨q, q⟩is ♯σ, we have
AE ⊢∀v3[θ(Sq0, Sq0, v3) ↔v3 = S♯σ0].
(3)
We can obtain (2) as follows:
(→) It is clear (by looking at σ) that
σ ⊢θ(Sq0, Sq0, S♯σ) →β(S♯σ0).
And, by (3),
AE ⊢θ(Sq0, Sq0, S♯σ0).
Hence
AE; σ ⊢β(S♯σ0),
which gives half of (2).
(←) The sentence in (3) implies
β(S♯σ0) →[∀v3(θ(Sq0, Sq0, v3) →β(v3))].
But the part in square brackets is just σ.
⊣
(Sometimes the notation ⌈σ ⌉is used for S♯σ0. In this notation, the
ﬁxed-point lemma states that AE ⊢(σ ↔β(⌈σ ⌉)).)
Our ﬁrst application of this lemma does not concern the subtheory
Cn AE, and requires only the weaker fact that
|=N [σ ↔β(S♯σ0)].

236
A Mathematical Introduction to Logic
TARSKI UNDEFINABILITY THEOREM (1933)
The set ♯Th N is not deﬁn-
able in N.
PROOF.
Consider any formula β (which you suspect might deﬁne
♯Th N). By the ﬁxed-point lemma (applied to ¬ β) we have a
sentence σ such that
|=N [σ ↔¬ β(S♯σ0)].
(If β did deﬁne ♯Th N, then σ would indirectly say “I am false.”)
Then
|=N σ ⇐⇏|=N β(S♯σ0),
so either σ is true but (its G¨odel number is) not in the set β deﬁnes,
or it is false and in that set. Either way σ shows that β cannot deﬁne
♯Th N.
⊣
The above theorem gives at once the undecidability of the theory
of N:
COROLLARY 35A
♯Th N is not recursive.
PROOF.
Any recursive set is (by Corollary 34B) deﬁnable in N.
⊣
G¨ODEL INCOMPLETENESS THEOREM (1931)
If A ⊆Th N and ♯A is re-
cursive, then Cn A is not a complete theory.
Thus there is no complete recursive axiomatization of Th N.
PROOF.
Since A ⊆Th N, we have Cn A ⊆Th N. If Cn A is a com-
plete theory, then equality holds. But if Cn A is a complete theory,
then ♯Cn A is recursive (item 21 of the preceding section). And
by the above corollary, ♯Th N is not recursive.
⊣
In particular, Cn AE is not a complete theory and so is not equal to
Th N. And the incompleteness would not be eliminated by the addition
of any recursive set of true axioms. (By a recursive set of sentences we
mean of course a set  for which ♯ is recursive.)
We can extract more information from the proof of G¨odel’s theorem.
Suppose we have a particular recursive A ⊆Th N in mind. Then by
item 20 in Section 3.4 we can ﬁnd a formula β that deﬁnes ♯Cn A in
N. The sentence σ produced by the proof of Tarski’s theorem is (as we
noted there) a true sentence not in Cn A. This sentence asserts that ♯σ
does not belong to the set deﬁned by β, i.e., it indirectly says, “I am
not a theorem of A.” Thus A ⊬σ, and of course A ⊬¬ σ as well. This
way of viewing the proof is closer to G¨odel’s original proof, which did
not involve a detour through Tarski’s theorem. For that matter, G¨odel’s
statement of the theorem did not involve Th N; we have taken some
liberties in the labeling of theorems.

Chapter 3:
Undecidability
237
Next we need a lemma which says (roughly) that one can add one
new axiom (and hence ﬁnitely many new axioms) to a recursive theory
without losing the property of recursiveness.
LEMMA 35B
If ♯Cn  is recursive, then ♯Cn(; τ) is recursive.
PROOF.
α ∈Cn(; τ) ⇔(τ →α) ∈Cn . Thus
a ∈♯Cn(; τ) ⇐⇒a is the G¨odel number of a sentence
and ⟨h(()⟩∗♯τ ∗⟨h(→)⟩∗a ∗⟨h())⟩
is in ♯Cn .
This is recursive by the results of the preceding sections.
⊣
THEOREM 35C (STRONG UNDECIDABILITY OF CN AE )
Let T be a the-
ory such that T ∪AE is consistent. Then ♯T is not recursive.
(Notice that because throughout this section the language in question
is the language of N, the word “theory” here means “theory in the
language of N.”)
PROOF.
Let T ′ be the theory Cn(T ∪AE). If ♯T is recursive, then
since AE is ﬁnite we can conclude by the above lemma that ♯T ′
is also recursive.
Suppose, then, that ♯T ′ is recursive and so is represented in
Cn AE by some formula β. From the ﬁxed-point lemma we get a
sentence σ such that
AE ⊢[σ ↔¬ β(S♯σ0)].
(∗)
(Indirectly σ asserts, “I am not in T ′.”)
σ /∈T ′ ⇒♯σ /∈♯T ′
⇒AE ⊢¬ β(S♯σ0)
⇒AE ⊢σ
by (∗)
⇒σ ∈T ′.
So we get σ ∈T ′. But this, too, is untenable:
σ ∈T ′ ⇒♯σ ∈♯T ′
⇒AE ⊢β(S♯σ0)
⇒AE ⊢¬ σ
by (∗)
⇒( ¬ σ) ∈T ′,
which contradicts the consistency of T ′.
⊣
COROLLARY 35D
Assume that ♯ is recursive and  ∪AE is con-
sistent. Then Cn  is not a complete theory.
PROOF.
A complete recursively axiomatizable theory is recursive
(item 21 of Section 3.4). But ♯Cn  is not recursive, by the above
theorem.
⊣
This corollary is G¨odel’s incompleteness theorem again, but with
truth in N replaced by consistency with AE.

238
A Mathematical Introduction to Logic
CHURCH’S THEOREM (1936)
The set of G¨odel numbers of valid sen-
tences (in the language of N) is not recursive.
PROOF.
In the strong undecidability of Cn AE, take T to be the
smallest theory in the language, the set of valid sentences.
⊣
The set of G¨odel numbers of valid wffs is not recursive either, lest
the set of valid sentences be recursive.
This proof applies to the language of N. For a language with more
parameters, the set of valid sentences is still nonrecursive (lest its inter-
section with the language of N be recursive). Actually it is enough for
the language to contain at least one two-place predicate symbol. (See
Corollary 37G.) On the other hand, some lower bound on the language
is needed. If the language has ∀as its only parameter (the language of
equality), then the set of valid formulas is decidable. (See Exercise 6.)
More generally, it is known that if the only parameters are ∀and one-
place predicate symbols, then the set of valid formulas is decidable.
Recursive Enumerability
A relation on the natural numbers is said to be recursively enumerable
iff it is of the form
{⃗a | ∃b ⟨⃗a, b⟩∈Q}
with Q recursive. Recursively enumerable relations play an important
role in logic. They constitute the formal counterpart to the effectively
enumerable relations (as will be explained presently).
(The standard abbreviation for “recursively enumerable” is “r.e.”
When the term “computable” is used instead of “recursive,” then one
speaks of computably enumerable — abbreviated c.e. — relations.)
Recursively enumerable relations are — like the recursive relations
— deﬁnable in N. If ϕ(v1, v2) deﬁnes in N a binary relation Q, then
∃v2 ϕ(v1, v2) deﬁnes {a | ∃b ⟨a, b⟩∈Q}.
THEOREM 35E
The following conditions on an m-ary relation R are
equivalent:
1. R is recursively enumerable.
2. R is the domain of some recursive relation Q.
3. For some recursive (m + 1)-ary relation Q,
R = {⟨a1, . . . , am⟩| ∃b ⟨a1, . . . , am, b⟩∈Q}.
4. For some recursive (m + n)-ary relation Q,
R = {⟨a1, . . . , am⟩| ∃b1, . . . , bn ⟨a1, . . . , am, b1, . . . , bn⟩∈Q}.
PROOF.
By deﬁnition 1 and 3 are equivalent. Also 2 and 3 are equiv-
alent by our deﬁnition (in Chapter 0) of domain and (m+1)-tuple.

Chapter 3:
Undecidability
239
Clearly 3 implies 4. So we have only to show that 4 implies 3.
This is because
∃b1, . . . , bn ⟨a1, . . . , am, b1, . . . , bn⟩∈Q
iff ∃c ⟨a1, . . . , am, (c)0, . . . , (c)n−1⟩∈Q
and
{⟨a1 . . . , am, c⟩| ⟨a1, . . . , am, (c)0, . . . , (c)n−1⟩∈Q}
is recursive whenever Q is recursive. (Here we have used our
sequence decoding function to collapse a string of quantiﬁers into
a single one.)
⊣
By part 4 of this theorem, R is recursively enumerable iff it is deﬁn-
able in N by a formula ∃x1 · · · ∃xnϕ, where ϕ is numeralwise deter-
mined by AE. In fact, we can require here that ϕ be quantiﬁer-free; this
result was proved in 1961 (with exponentiation) and in 1970 (without
exponentiation). The proofs involve some number theory; we will omit
them here.
Notice that any recursive relation is also recursively enumerable. For
if R is recursive, then it is deﬁned in N by a formula ∃x1 · · · ∃xnϕ,
where ϕ is numeralwise determined by AE and x1, . . . , xn do not occur
in ϕ.
THEOREM 35F
A relation is recursive iff both it and its complement
are recursively enumerable.
This is the formal counterpart to the fact (cf. Theorem 17F) that a
relation is decidable iff both it and its complement can be effectively
enumerated.
PROOF.
If a relation is recursive, then so is its complement, whence
both are recursively enumerable.
Conversely, suppose that both P and its complement are re-
cursively enumerable; thus for any ⃗a,
⃗a ∈P ⇔∃b ⟨⃗a, b⟩∈Q
⃗a /∈P ⇔∃b ⟨⃗a, b⟩∈R
for some recursive Q and R. Let
f (⃗a) = the least b such that either ⟨⃗a, b⟩∈Q or ⟨⃗a, b⟩∈R.
Such a number b always exists, and f is recursive. Finally,
⃗a ∈P ⇔⟨⃗a, f (⃗a)⟩∈Q,
so P is recursive.
⊣
The recursively enumerable relations constitute the formal counter-
part of the effectively enumerable relations. For we have the following

240
A Mathematical Introduction to Logic
informal result, paralleling a characterization of recursive enumerability
given by Theorem 35E.
⋆LEMMA 35G
A relation is effectively enumerable iff it is the do-
main of a decidable relation.
PROOF.
Assume that Q is effectively enumerated by some proce-
dure. Then ⃗a ∈Q iff ∃n[⃗a appears in the enumeration in n steps].
The relation deﬁned in square brackets is decidable and has do-
main Q.
Conversely, to enumerate {⟨a, b⟩| ∃n⟨a, b, n⟩∈R} for de-
cidable R, we check to see if ⟨(m)0, (m)1, (m)2⟩∈R for m =
0, 1, 2, . . . . Whenever the answer is afﬁrmative, we place ⟨(m)0,
(m)1⟩on the output list.
⊣
⋆COROLLARY 35H (CHURCH’S THESIS, SECOND FORM)
A relation is
effectively enumerable iff it is recursively enumerable.
PROOF.
By identifying the class of decidable relations with the class
of recursive relations, we automatically identify the domains of
decidable relations with domains of recursive relations.
⊣
The second form of Church’s thesis is, in fact, equivalent to the ﬁrst
form. To prove the ﬁrst form from the second, we use Theorems 35F
and 17F.
We have already shown that a recursively axiomatizable theory is
recursively enumerable, but using different words. We restate the result
here, as it indicates the role recursive enumerability plays in logic.
THEOREM 35I
If A is a set of sentences such that ♯A is recursive,
then ♯Cn A is recursively enumerable.
PROOF.
Item 20 of Section 3.4.
⊣
In particular, ♯Cn AE is recursively enumerable, but (by Theorem
35C) it is not recursive. In the next section, we will see other examples
of recursively enumerable sets that are not recursive.
This theorem is the precise counterpart of the informal fact that a
theory with a decidable set of axioms is effectively enumerable (Corol-
laries 25F and 26I). It indicates the gap between what is provable in
an axiomatic theory and what is true in the intended structure. With
a recursive set of axioms, all we can possibly obtain is a recursively
enumerable set of consequences. But by Tarski’s theorem, Th N is not
even deﬁnable in N, much less recursively enumerable.
Even if we expand the language or add new axioms, the same
phenomenon is present. As long as we can recursively distinguish de-
ductions from nondeductions, the set of theorems can be only recur-
sively enumerable. For example, the set of sentences of number theory
provable in your favorite system of axiomatic set theory is recursively

Chapter 3:
Undecidability
241
enumerable. Furthermore, this set includes AE and is consistent (un-
less you have very strange favorites). It follows that this set theory is
nonrecursive and incomplete. (This topic is discussed more carefully in
Section 3.7.)
Weak Representability
Consider a recursively enumerable set Q, where
a ∈Q ⇔∃b ⟨a, b⟩∈R
for recursive R. We know there is a formula ρ that represents R in
Cn AE. Consequently, the formula ∃v2ρ deﬁnes Q in N. This formula
cannot represent Q in Cn AE unless Q is recursive. But it can come
halfway.
a ∈Q ⇒⟨a, b⟩∈R
for some b
⇒AE ⊢ρ(Sa0, Sb0)
for some b
⇒AE ⊢∃v2ρ(Sa0, v2)
a /∈Q ⇒⟨a, b⟩/∈R
for all b
⇒AE ⊢¬ ρ(Sa0, Sb0)
for all b
⇒AE ⊬∃v2ρ(Sa0, v2)
The last step is justiﬁed by the fact that if AE ⊢¬ ϕ(Sb0) for all
b, then AE ⊬∃x ϕ(x). (The term ω-consistency is given to this prop-
erty.) For it is impossible for ∃x ϕ(x), ¬ ϕ(S00), ¬ ϕ(S10), . . . all to be
true in N.
Thus we have
a ∈Q ⇔AE ⊢∃v2ρ(Sa0, v2).
It will be convenient to formulate a deﬁnition of this half of repre-
sentability.
DEFINITION.
Let Q be an n-ary relation on N, ψ a formula in which
only v1, . . . , vn occur free. Then ψ weakly represents Q in a
theory T iff for every a1, . . . , an in N,
⟨a1, . . . , an⟩∈Q ⇔ψ(Sa10, . . . , San0) ∈T.
Observe that if Q is representable in a consistent theory T , then Q
is also weakly representable in T .
THEOREM 35J
A relation is weakly representable in Cn AE iff it is
recursively enumerable.
PROOF.
We just showed that a recursively enumerable unary rela-
tion Q is weakly representable in Cn AE; the same proof applies
to n-ary Q with only notational changes. Conversely, let Q be

242
A Mathematical Introduction to Logic
weakly represented by ψ in Cn AE. Then
⟨a1, . . . , an⟩∈Q ⇔∃D [D is a deduction of ψ(Sa10, . . . , San0)
from the axioms AE]
⇔∃d ⟨d, f (a1, . . . , an)⟩∈P
for a certain recursive function f and recursive relation P.
⊣
Arithmetical Hierarchy
Deﬁne a relation on the natural numbers to be arithmetical iff it is
deﬁnable in N. But some arithmetical relations are, in a sense, more
deﬁnable than others. We can organize the arithmetical relations into a
hierarchy according to how deﬁnable the relations are.
Let 1 be the class of recursively enumerable relations; these rela-
tions are “one quantiﬁer away” from recursiveness. Extending this idea,
we deﬁne the class of k relations and the class of k relations. For
example, the ﬁrst few classes consist of relations of the form shown in
the second column:
1 :
{⃗a | ∃b ⟨⃗a, b⟩∈R},
R recursive.
1 :
{⃗a | ∀b ⟨⃗a, b⟩∈R},
R recursive.
2 :
{⃗a | ∃c∀b ⟨⃗a, b, c⟩∈R},
R recursive.
2 :
{⃗a | ∀c∃b ⟨⃗a, b, c⟩∈R},
R recursive.
In general, a relation Q is in k iff it is of the form
{⃗a | ∀b1∃b2 · · · □bk ⟨⃗a, ⃗b⟩∈R}
for a recursive relation R. Here “□” is to be replaced by “∀” if k is odd
and by “∃” if k is even. Similarly, Q is in k iff it has the form
{⃗a | ∃b1∀b2 · · · □bk ⟨⃗a, ⃗b⟩∈R}
for recursive R, where now “□” is replaced by “∃” if k is odd and by
“∀” if k is even.
The classes k and k can also be deﬁned by recursion on k. 1 is
the class of recursively enumerable relations. Next, a relation belongs
to k iff its complement is in k. And a relation is in k+1 iff it is the
domain of a relation in k. (We can even start from k = 0, by letting
0 be the class of recursive relations.)
EXAMPLE.
The set of G¨odel numbers of formulas numeralwise
determined by AE is in 2.
PROOF.
a belongs to this set iff [a is the G¨odel number of a for-
mula α] and ∀b∃d[d is G of a deduction from AE either of
α(S(b)00, S(b)10, . . .) or of the negation of this sentence]. By the
technique of Section 3.4, we can show that the phrases in
square brackets deﬁne recursive relations. By using the English

Chapter 3:
Undecidability
243
counterpart to prenex form, we obtain the desired form,
{a | ∀b∃d ⟨a, b, d⟩∈R},
with R recursive.
⊣
One more bit of notation: Let 1 be the class of recursive relations.
Then our earlier result (Theorem 35F) stating that a relation is recursive
iff both it and its complement are recursively enumerable can now be
stated by the equation
1 = 1 ∩1.
Since this equation holds, we proceed to deﬁne n for n > 1 by the
analogous equation,
n = n ∩n.
The following inclusions hold:
The case 1 ⊆1 was mentioned previously (cf. Theorem 35F); its
proof hinged on the possibility of “vacuous quantiﬁcation.” The proofs
of the other cases are conceptually the same. If x does not occur in
ϕ, then ϕ, ∀x ϕ, and ∃x ϕ are all equivalent. For example, a rela-
tion in 1 is deﬁned by a formula ∃y ϕ, where ϕ is numeralwise de-
termined by AE. But the same relation is deﬁned by ∃y ∀x ϕ and
∀x ∃y ϕ (where x does not occur in ϕ). Hence the relation is also in 2
and 2.
It is also true that all the inclusions shown are proper inclusions,
i.e., equality does not hold. But we will not prove this fact here. The
inclusions are shown pictorially in Fig. 10.
The class of arithmetical relations equals 
k k and also 
k k. For
example, any relation in 2 is arithmetical, being deﬁned in N by a for-
mula ∃x ∀y ϕ, where ϕ is numeralwise determined by AE. Conversely,
any arithmetical relation is deﬁned in N by some prenex formula. The
quantiﬁer-free part of this prenex formula deﬁnes a recursive relation
(since quantiﬁer-free formulas are numeralwise determined by AE).
Consequently, the deﬁned relation falls somewhere in the hierarchy.
The technique of “collapsing” ∃∃· · · ∃quantiﬁers used in the proof of
Theorem 35E (and its dual technique for ∀∀· · · ∀) can be used to good
advantage here.

244
A Mathematical Introduction to Logic
Figure 10. Picture of PN.
Thus we have the following result, which relates deﬁnability in N to
the hierarchy we have just built up from the recursive relations:
THEOREM 35K
Arelationonthenaturalnumbersisarithmetical(i.e.,
deﬁnable in N) iff it is in k for some k, and this property in turn
is equivalent to being in l for some l.
In particular, any recursively enumerable relation is arithmetical, as
noted previously.
There are certain tricks which are useful in locating speciﬁc arith-
metical relations in the hierarchy. For example, let A be the set of G¨odel
numbers of formulas α such that for some n,
AE ⊢α(Sn0)
and
(∀i < n) AE ⊢¬ α(Si0).
Then a ∈A iff [a is the G¨odel of a wff α] and ∃n∃D[D is a deduction
from AE of α(Sn0)] and (∀i < n)(∃Di)[Di is a deduction from AE of
¬ α(Si0)]. The parts in square brackets are recursive so we count the
remaining quantiﬁers. The bounded quantiﬁer “∀i < n” need not be
counted. For we have
(∀i < n)(∃d)⟨d, i⟩∈P ⇔(∃d)(∀i < n)⟨(d)i, i⟩∈P.
Use of this fact lets us push the bounded quantiﬁer inward until it merges
with the recursive part. Consequently, A ∈1.
The following theorem generalizes Theorem 35I.

Chapter 3:
Undecidability
245
THEOREM 35L
Let A be a set of sentences such that ♯A is in k,
where k > 0. Then ♯Cn A is also in k.
PROOF.
Return to the proofs of items 18 and 20 of Section 3.4. We
had there:
a ∈♯Cn A ⇔a is the G¨odel number of a sentence and ∃d[d is a
sequence number and the last component of d is a and
for every i less than lh d, either (1) (d)i ∈♯A, (2) (d)i
is the G¨odel number of a logical axiom, or (3) for some
j and l less than i, (d) j = ⟨h(()⟩∗(d)l ∗⟨h(→)⟩
∗(d)i ∗⟨h())⟩].
Since ♯A ∈k in (1) we must replace “(d)i ∈♯A” by something
of the form
∃b1∀b2 · · · □bk⟨(d)i, ⃗b⟩∈Q
for recursive Q. It remains to convert the result into an English
prenex expression in k form. We suggest that the reader set k = 2
and write out this expression; the device used in the preceding
example will help.
⊣
Exercises
1. Show that there is no recursive set R such that ♯Cn AE ⊆R and
♯{σ | ( ¬ σ) ∈Cn AE} ⊆R, the complement of R. (This result can
be stated: The theorems of AE cannot be recursively separated from
therefutablesentences.)Suggestion:Makeasentence σ saying“My
G¨odel number is not in R.” Look to see where ♯σ is.
2. Let A be a recursive set of sentences in a recursively numbered
language with 0 and S. Assume that every recursive relation is rep-
resentableinthetheoryCn A.Furtherassumethat A isω-consistent;
i.e., there is no formula ϕ such that A ⊢∃x ϕ(x) and for all a ∈N,
A ⊢¬ ϕ(Sa0). Construct a sentence σ indirectly asserting that it
is not a theorem of A, and show that neither A ⊢σ nor A ⊢¬ σ.
Suggestion: See Section 3.0.
Remark: This is a version of the incompleteness theorem that
is closer to G¨odel’s original 1931 argument. Note that there is no
requirement that the axioms A be true in N. Nor is it required that
A include AE; the ﬁxed-point argument can still be applied.
3. Let T be a theory in a recursively numbered language (with 0 and S).
Assume that all recursive subsets of N are weakly representable in
T . Show that ♯T is not recursive. Suggestion: Construct a binary
relation P such that any weakly representable subset of N equals
{b | ⟨a, b⟩∈P} for some a, and such that P is recursive if ♯T is.

246
A Mathematical Introduction to Logic
Consider the set H = {b | ⟨b, b⟩/∈P}. See Section 3.0. The argu-
ment given there for the “diagonal approach” in the special case
T = Th N can be adapted here.
Remark: This exercise gives a version of the result, “Any sufﬁ-
ciently strong theory is undecidable.”
4. Show that there exist 2ℵ0 nonisomorphic countable models of Th N.
Suggestion: For each set A of primes, make a model having an
element divisible by exactly the primes in A.
5. (Lindenbaum) Let T be a decidable consistent theory (in a rea-
sonable language). Show that T can be extended to a complete
decidable consistent theory T ′. Suggestion: Examine in turn each
sentence σ; add either σ or ¬ σ to T . But take care to maintain
decidability.
6. Consider the language of equality, having ∀as its only parameter.
Let λn be the translation of “There are at least n things,” cf. the
proof of Theorem 26A. Call a formula simple iff it can be built up
from atomic formulas and the λn’s by use of connective symbols
(but no quantiﬁers). Show how, given any formula in the language
of equality, we can ﬁnd a logically equivalent simple formula. Sug-
gestion: View this as an elimination-of-quantiﬁers result (where the
quantiﬁers in λn do not count). Use Theorem 31F.
7. (a) Assume that A and B are subsets of N belonging to k (or
k). Show that A ∪B and A ∩B also belong to k (or k,
respectively).
(b) Assume that A is in k (or k) and that the functions f1, . . . ,
fm are recursive. Show that
{⃗a : ⟨f1(⃗a), . . . , fm(⃗a)⟩∈A}
is also in k (or k, respectively). Suggestion: First do this for
1. Then observe that the argument used can be generalized.
8. Let T be a theory in a recursively numbered language (with 0 and
S). Let n be ﬁxed, n ≥0. Assume that all subsets of N in n are
weakly representable in T . Show that ♯T is not in n. (Observe that
Exercise 3 is a special case of this, wherein n = 0. The suggestions
given there carry over to the present case.)
9. Show that
{♯σ | AE; σ is ω-consistent}
(see Exercise 2) is a 3 set.
10. The theory Cn AE has many complete extensions, of which Th N
is but one. How many? That is, what is the cardinality of the set of
complete theories (in the language) that extend AE?

Chapter 3:
Undecidability
247
SECTION 3.6
Recursive Functions
We have used recursive functions (i.e., functions that, when viewed
as relations, are recursive) to obtain theorems of incompleteness and
undecidability of theories. But the class of recursive functions is also
an interesting class in its own right, and in this section we will indicate
a few of its properties.
Recall that by Church’s thesis, a function is recursive iff it is com-
putable by an effective procedure (page 210). This fact is responsi-
ble for much of the interest in recursive functions. At the same time,
this fact makes possible an intuitive understanding of recursiveness,
which greatly facilitates the study of the subject. Suppose, for exam-
ple, that you are suddenly asked whether or not the inverse of a re-
cursive permutation of N is recursive. Before trying to prove this, you
should ﬁrst ask yourself the intuitive counterpart: Is the inverse of a
computable permutation f also computable? You then — one hopes —
perceive that the answer is afﬁrmative. To compute f −1(3), you can
compute f (0), f (1), . . . until for some k it is found that f (k) = 3.
Then f −1(3) = k. Having done this, you have gained two advan-
tages. For one, you feel certain that the answer to the question re-
garding recursive permutations must also be afﬁrmative. And secondly,
you have a good outline of how to prove this; the proof is found
by making rigorous the intuitive proof. This strategy for approach-
ing problems involving recursiveness will be very useful in this
section.
Before proceeding, it might be wise to summarize here some of the
facts about recursive functions we have already established. We know
that a function f is recursive iff it (as a relation) is representable in
Cn AE, by Theorem 34A. Consequently, every recursive function is
weakly representable in this theory.
In Section 3.3 a repertoire of recursive functions was developed. In
addition, it was shown that the class of recursive functions is closed
under certain operations, such as composition (Theorem 33L) and the
“least-zero” operator (Theorem 33M).
We also know of a few functions that are not recursive. There are
uncountablymany(tobeexact,2ℵ0)functionsfromNm intoNaltogether,
but only countably many of them can be recursive. So an abundance of
nonrecursive functions exists, despite the fact that the most commonly
met functions (such as the polynomials) were shown in Section 3.3 to be
recursive. By catalog item 1 of Section 3.3, the characteristic function of
a nonrecursive set is nonrecursive. For example, if f (a) = 1 whenever
a is the G¨odel number of a member of Cn AE and f (a) = 0 otherwise,
then f is not recursive.

248
A Mathematical Introduction to Logic
Normal Form
For any computable function, such as the polynomial function a2+3a+
5, one can in principle design a digital computer into which one feeds
a and out of which comes a2 + 3a + 5 (Fig. 11). But if you then want
a different function, you must build a different computer. (Or change
the wiring in the one you have.) It was recognized long ago that it is
usually more desirable to build a single general-purpose stored-program
computer. Into this you feed both a and the program for computing your
polynomial (Fig. 12). This “universal” computer requires two inputs,
and it will compute any one-place computable function (if supplied
with enough memory space), provided that the right program is fed
into it. Of course, there are some programs that do not produce any
function on N, as many a programmer has, to his sorrow, discovered.
(Such programs produce malfunctions instead!)
Figure 11. Special-purpose
computer.
Figure 12. General-purpose computer.
In this subsection and the next, we will repeat what has just been
said, but with recursive functions and with proofs. For our universal
computer we will have a recursive relation T1 and a recursive function
U. Then for any recursive f : N →N there will exist an e (analogous
to the program) such that
f (a) = U(the least k such that ⟨e, a, k⟩∈T1)
= U(μk ⟨e, a, k⟩∈T1),
where the second equation is to be understood as being an abbreviation
for the ﬁrst. Actually e will here be the G¨odel number of a formula

Chapter 3:
Undecidability
249
ϕ that represents (or at least weakly represents) f in Cn AE. And the
numbers k for which ⟨e, a, k⟩∈T1 will encode both f (a) and G of a
deduction from AE of ϕ(Sa0, S f (a)0).
DEFINITION.
For each positive integer m, let Tm be the (m + 2)-ary
relation to which an (m + 2)-tuple ⟨e, a1, . . . , am, k⟩belongs iff
(i) e is the G¨odel number of a formula ϕ in which only v1, . . . ,
vm, vm+1 occur free;
(ii) k is a sequence number of length 2, and (k)0 is G of a
deduction from AE of ϕ(Sa10, . . . , Sam0, S(k)10).
The idea here is that for any one-place recursive function f we
can ﬁrst of all take e to be the G¨odel number of a formula ϕ weakly
representing f (as a relation). Then we know that for any a and b,
AE ⊢ϕ(Sa0, Sb0)
iff
b = f (a).
So any number k meeting clause (ii) of the deﬁnition must equal
⟨(k)0, f (a)⟩, where (k)0 is G of a deduction of ϕ(Sa0, S f (a)0) from
AE. (We have departed from the usual deﬁnition of Tm here by not
requiring that k be as small as possible.)
Take for the “upshot” function U the function
U(k) = (k)1.
This U is recursive and in the situation described in the preceding para-
graph we have U(k) = f (a).
LEMMA 36A
For each m, the relation Tm is recursive.
PROOF, FOR m = 2.
⟨e, a1, a2, k⟩∈T2 iff e is the G¨odel number of
a formula, ♯(∀v1 ∀v2 ∀v3) ∗e is the G¨odel number of a sentence,
k is a sequence number of length 2, and (k)0 is G of a deduction
from AE of
Sb(Sb(Sb(e, ♯v1, g(a1)), ♯v2, g(a2)), ♯v3, g((k)1)),
where g(n) = ♯Sn0. From Section 3.4 we know all this to be
recursive.
⊣
THEOREM 36B
(a) For any recursive function f : Nm →N, there is
an e such that for all a1, . . . , am,
f (a1, . . . , am) = U(μk ⟨e, a1, . . . , am, k⟩∈Tm).
(In particular, such a number k exists.)
(b) Conversely, for any e such that ∀a1 · · · am∃k ⟨e, a1, . . . ,
am, k⟩∈Tm, the function whose value at a1, . . . , am is U(μk⟨e,
a1, . . . , am, k⟩∈Tm) is recursive.

250
A Mathematical Introduction to Logic
PROOF.
Part (b) follows immediately from the fact that U and Tm
are recursive. As for part (a), we take for e the G¨odel number of
a formula ϕ weakly representing f in Cn AE. Given any ⃗a, we
know that AE ⊢ϕ(Sa10, . . . , Sam0, S f (⃗a)0). If we let d be G of a
deduction from AE of this sentence, then ⟨e, ⃗a, ⟨d, f (⃗a)⟩⟩∈Tm.
Hence there is some k for which ⟨e, ⃗a, k⟩∈Tm. And for any such
k, we know that AE ⊢ϕ(Sa10, . . . , Sam0, S(k)10), since (k)0 is G
of a deduction. Consequently, U(k) = (k)1 = f (⃗a) by our choice
of ϕ. Thus we have U(μk ⟨e, ⃗a, k⟩∈Tm) = f (⃗a).
⊣
This theorem, due to Kleene in 1936, shows that every recursive
function is representable in the normal form
f (⃗a) = U(μk ⟨e, ⃗a, k⟩∈Tm).
Thus a computing machine able to calculate U and the characteristic
function of T1 is a “universal” computer for one-place recursive func-
tions. The input e corresponds to the program, and it must be chosen
with care if any output is to result (i.e., if there is to be any k such that
⟨e, a, k⟩∈T1).
Recursive Partial Functions
The theory of recursive functions becomes more natural if we consider
the broader context of partial functions.
DEFINITION.
An m-place partial function is a function f with
dom f ⊆Nm and ran f ⊆N. If ⃗a /∈dom f , then f (⃗a) is said to
be undeﬁned. If dom f = Nm, then f is said to be total.
The reader is hereby cautioned against reading too much into our
choice of the words “partial” and “total” (or the word “undeﬁned,” for
that matter). A partial function f may or may not be total; the words
“partial” and “total” are not antonyms.
We will begin by looking at those partial functions that are informally
computable.
⋆DEFINITION.
An m-place partial function f is computable iff there
is an effective procedure such that (a) given an m-tuple ⃗a in dom f ,
the procedure produces f (⃗a); and (b) given an m-tuple ⃗a not in
dom f , the procedure produces no output at all.
This deﬁnition extends the one previously given for total functions.
Atthattimeweprovedaresult(Theorem33H),partofwhichgeneralizes
to partial functions.
⋆THEOREM 36C
An m-place partial function f is computable iff f
(as an (m + 1)-ary relation) is effectively enumerable.

Chapter 3:
Undecidability
251
PROOF.
The proof is reminiscent of the proof of another result,
Theorem 17E. First suppose we have a way of effectively enu-
merating f . Given an m-tuple ⃗a, we examine the listing of the
relation as the procedure churns it out. If and when an (m + 1)-
tuple beginning with ⃗a appears, we print out its last component
as f (⃗a).
Conversely, assume that f is computable, and ﬁrst suppose
that f is a one-place partial function. We can enumerate f as a
relation by the following procedure:
1. Spend one minute calculating f (0).
2. Spend two minutes calculating f (0), then two minutes cal-
culating f (1).
3. Spend three minutes calculating f (0), three minutes calcu-
lating f (1), and three minutes calculating f (2).
And so forth. Of course, whenever one of these calculations
produces any output, we place the corresponding pair on the list
of members of the relation f .
For a computable m-place partial function, instead of calcu-
lating the value of f at 0, 1, 2, . . . we calculate its value at ⟨(0)0,
. . . , (0)m−1⟩, ⟨(1)0, . . . , (1)m−1⟩, ⟨(2)0, . . . , (2)m−1⟩, etc.
⊣
In the case of a computable total function f , we were also able to
conclude that f was a decidable relation. But this may fail for a nontotal
f . For example, let
f (a) =

0
if a ∈♯Cn AE,
undeﬁned
otherwise.
Then f is computable. (We compute f (a) by enumerating ♯Cn AE
and looking for a.) But f is not a decidable relation, lest ♯Cn AE be
decidable. On the basis of this example and the foregoing theorem,
we select our deﬁnition for the precise counterpart of the concept of
computable partial function.
DEFINITION.
A recursive partial function is a partial function that,
as a relation, is recursively enumerable.
The reader should be warned that “recursive partial function” is an
indivisible phrase; a recursive partial function need not be (as relation)
recursive. But at least for a total function our terminology is consistent
with past practice.
THEOREM 36D
Let f : Nm →N be a total function. Then f is a
recursive partial function iff f is recursive (as a relation).
PROOF.
If f is recursive (as a relation), then a fortiori f is re-
cursively enumerable. Conversely, suppose that f is recursively

252
A Mathematical Introduction to Logic
enumerable. Since f is total,
f (⃗a) ̸= b ⇐⇒∃c[ f (⃗a) = c & b ̸= c].
The form of the right-hand side shows that the complement of
f is also recursively enumerable. Thus by Theorem 35F, f is
recursive.
⊣
In ﬁrst discussing normal form results, we pictured a two-input de-
vice (Fig. 13). For any computable partial function, there is some pro-
gram that computes it. But now the converse holds: Any program will
produce some computable partial function. Of course many programs
will produce the empty function, but that is a computable partial func-
tion.
Figure 13. Computer with program for f .
For the recursive partial functions the same considerations apply.
Deﬁne, for each e ∈N, the m-place partial function [[e]]m by
[[e]]m(a1, . . . , am) = U(μk ⟨e, a1, . . . , am, k⟩∈Tm).
The right-hand side is to be understood as undeﬁned if there is no such
k. In other words,
⃗a ∈dom[[e]]m
iff
∃k ⟨e, a1, . . . , am, k⟩∈Tm,
in which case the value [[e]]m(⃗a) is given by the above equation.
The following theorem is an improved version of Theorem 36B:
NORMAL FORM THEOREM (KLEENE, 1943)
(a) The (m + 1)-place par-
tial function whose value at ⟨e, a1, . . . , am⟩is [[e]]m(a1, . . . , am)
is a recursive partial function.
(b) For each e ≥0, [[e]]m is an m-place recursive partial
function.
(c) Any m-place recursive partial function equals [[e]]m for
some e.
PROOF.
(a) We have
[[e]]m(⃗a) = b ⇔∃k[⟨e, ⃗a, k⟩∈Tm &U(k) = b &(∀k′< k)⟨e,⃗a,k′⟩/∈Tm].

Chapter 3:
Undecidability
253
The part in square brackets is recursive, so the function (as a
relation) is recursively enumerable.
(b) The above proof still applies, e now being held ﬁxed.
(c) Let f be an m-place recursive partial function, so that
{⟨⃗a, b⟩| f (⃗a) = b} is recursively enumerable. Hence there is a
formula ϕ that weakly represents this relation in Cn AE. We claim
that f = [[♯ϕ]]m. For if f (⃗a) = b, then AE ⊢ϕ(Sa10, . . . , Sam0,
Sb0). Hence there is a k such that ⟨♯ϕ, ⃗a, k⟩∈Tm. For any such
k, U(k) = b, since AE ⊬ϕ(Sa10, . . . , Sam0, Sc0) for c ̸= b. Sim-
ilarly, if f (⃗a) is undeﬁned, then AE ⊬ϕ(Sa10, . . . , Sam0, Sc0) for
any c, whence [[♯ϕ]]m is undeﬁned here also.
⊣
Part (a) of the normal form theorem (in the case m = 1) tells us that
the function  deﬁned by the equation
(e, a) = [[e]]1(a) = U(μk ⟨e, a, k⟩∈T1)
is a recursive partial function. And part (c) tells us that  is “universal”
in the sense that we can get any one-place recursive partial function
from  by holding the ﬁrst variable ﬁxed at a suitable value.
The informal counterpart of the universal function  is the computer
operating system. The operating system takes two inputs, the program
e and the data a. And it runs the program on that data. But the operating
system itself is computable as a two-place partial function.
The proof of normal form theorem gives us a way to compute the
values of our “operating system” , albeit in an extremely inefﬁcient
way. The straightforward idea of “looking at the program e and doing
what it says to the data a” has been obscured, to say the least.
The function [[e]]m is said to be the m-place recursive partial function
with index e. Part (c) of the normal form theorem tells us that every
recursive partial function has an index. The proof shows that the G¨odel
number of a formula weakly representing a function is always an index
of the function.
We now have a convenient indexing [[0]]1, [[1]]1, . . . of all the one-
place recursive partial functions. Function [[e]]1 is produced by the “in-
structions” encoded by e. Of course, that function will be empty unless
e is the G¨odel number of a formula and certain other conditions are met.
All the recursive total functions are included in our enumeration of
recursive partial functions. But we cannot tell effectively by looking at
a number e whether or not it is the index of a total function:
THEOREM 36E
{e | [[e]]1 is total} is not recursive.
PROOF.
Call this set A. Consider the function deﬁned by
f (a) =

[[a]]1(a) + 1
if a ∈A,
0
if a /∈A.

254
A Mathematical Introduction to Logic
Then f , by its construction, is total. Is it recursive? We have
f (a) = b ⇐⇒[(a /∈A & b = 0) or (a ∈A & ∃k(⟨a, a, k⟩∈T1
& b = U(k) + 1 & (∀j < k)⟨a, a, j⟩/∈T1))].
Thus if A is recursive, then f (as a relation) is recursively enu-
merable. But then f is a total recursive function, and so equals
[[e]]1 for some e ∈A. But f (e) = [[e]]1(e)+1, so we cannot have
f = [[e]]1. This contradiction shows that A cannot be recursive.
⊣
It is not hard to show that A is in 2. This classiﬁcation is the best
possible, as it can be shown that A is not in 2.
THEOREM 36F
The set
K = {a | [[a]]1(a) is deﬁned}
is recursively enumerable but not recursive.
PROOF.
K is recursively enumerable, since a ∈K ⇔∃k ⟨a, a, k⟩
∈T1. To see that K cannot be recursive, consider the function
deﬁned by
g(a) =

[[a]]1(a) + 1
if a ∈K,
0
if a /∈K.
This is a total function. Exactly as in the preceding theorem, we
have that K cannot be recursive.
⊣
COROLLARY 36G (UNSOLVABILITY OF THE HALTING PROBLEM)
The re-
lation
{⟨e, a⟩| [[e]]1(a) is deﬁned}
is not recursive.
PROOF.
We have a ∈K iff the pair ⟨a, a⟩belongs to this relation.
(Thus the problem of membership in K is “reducible” to the halt-
ing problem.) If this relation were recursive, then K would be,
which is not the case.
⊣
This corollary tells us that there is no effective way to tell, given a
program e for a recursive partial function and an input a, whether or not
the function [[e]]1 is deﬁned at a.
We can obtain an indexing of the recursively enumerable relations
by using the following characterization.
THEOREM 36H
A relation on N is recursively enumerable iff it is
the domain of some recursive partial function.
PROOF.
The domain of any recursively enumerable relation is also
recursively enumerable; cf. part 4 of Theorem 35E. In particular,

Chapter 3:
Undecidability
255
the domain of any recursive partial function is recursively enu-
merable.
Conversely, let Q be any recursively enumerable relation,
where
⃗a = Q ⇔∃b ⟨⃗a, b⟩∈R
with R recursive. Let
f (⃗a) = μb ⟨⃗a, b⟩∈R;
i.e.,
f (⃗a) = b ⇐⇒⟨⃗a, b⟩∈R & (∀c < b)⟨⃗a, c⟩/∈R.
Then f , as a relation, is recursive. Hence f is a recursive partial
function. Clearly its domain is Q.
⊣
Thus our indexing of the recursive partial functions induces an in-
dexing of the recursively enumerable relations. Deﬁne
We = dom[[e]]1.
Then W0, W1, W2, . . . is a list of all recursively enumerable subsets
of N. In Theorem 36E we showed that {e | We = N} is not recursive.
Similarly, Theorem 36F asserts that {e | e ∈We} is not recursive. Deﬁne
a relation Q by
Q = {⟨e, a⟩| a ∈We}.
Then Q is recursively enumerable, since ⟨e, a⟩∈Q ⇔∃k ⟨e, a, k⟩∈T1.
Furthermore, Q is universal for recursively enumerable sets, in the sense
that for any recursively enumerable A ⊆N there is some e such that
A = {a | ⟨e, a⟩∈Q}. The unsolvability of the halting problem can be
stated: Q is not recursive.
We can apply the classical diagonal argument to “diagonalize out”
of the list W0, W1, W2, . . . of recursively enumerable sets. The set
{a | a /∈Wa} cannot coincide with any Wq. In fact this set is exactly K,
the complement of the set K in Theorem 36F. Because
q ∈K ⇐⇒q /∈Wq,
the set K cannot equal any Wq; the number q witnesses the inequality
of the two sets K and Wq.
And there is more: Whenever Wq is a recursively enumerable subset
of K, that is, Wq ⊆K, then we can produce a number in K that is not
in Wq. Such a number is q itself. To see this, observe that in the line
displayed in the preceding paragraph we cannot have both sides false
(q ∈K and q ∈Wq) because Wq ⊆K. So both sides are true.
Theorem 36F asserts that K, although recursively enumerable, is
not recursive. To show non-recursiveness, it sufﬁces to show that its
complement K is not recursively enumerable. The preceding paragraph

256
A Mathematical Introduction to Logic
does this in a particularly strong way, thereby giving us a second proof
of Theorem 36F.
At this point, let us reconsider the G¨odel incompleteness theorem,
from the computability point of view.
The set K is recursively enumerable (i.e., 1). It follows (cf. Theo-
rem 35K) that K is arithmetical; that is, K is deﬁnable in the structure N.
So there is a formula (v1) with just v1 free that deﬁnes K in N.
And so the set K is deﬁned in N by the formula ¬ (v1). Thus we have
a ∈K ⇐⇒( ¬ (Sa0)) ∈Th N.
This fact tells how we can “reduce” questions about membership in the
set K to questions about Th N. Imagine that we are given a number a,
and we want to know whether or not a ∈K. We can compute the number
♯( ¬ (Sa0)). (Informally, it is clear that we can effectively compute this
number. Formally, we apply item 5 from Section 3.4 to make sure we
can recursively compute the number.) If we somehow had an oracle for
♯Th N (i.e., a magic device that, given a number, would tell us whether
or not that number was in ♯Th N), then we could answer the question
“Is a ∈K?”
Now let us eliminate the magic. For sets A and B of natural numbers,
we say that A is many-one reducible to B (in symbols, A ≤m B) iff there
exists a total recursive function f such that for every number a,
a ∈A ⇐⇒f (a) ∈B.
The earlier example tells us that K ≤m ♯Th N. More generally, the ar-
gument shows that any arithmetical set is many-one reducible to ♯Th N.
LEMMA 36I
Assume that A and B are sets of natural numbers with
A ≤m B.
(a) If B is recursive, then A is also recursive.
(b) If B is recursively enumerable, the A is also recursively
enumerable.
(c) If B is n for some n, the A is also n for that n.
PROOF.
Part (a) is already familiar; it was, in different terminology,
catalog item 2 in Section 3.3.
Part (b) is essentially part (a) “plus a quantiﬁer.” That is, be-
cause B is recursively enumerable, we know that for some recur-
sive binary relation Q,
c ∈B ⇐⇒∃b Q(c, b).
If f is the total recursive function that many-one reduces A to
B, then every number a,
a ∈A ⇐⇒f (a) ∈B ⇐⇒∃b[Q( f (a), b)].

Chapter 3:
Undecidability
257
The part in square brackets is recursive (i.e., {⟨a, b⟩| Q( f (a), b)}
is recursive), as in part (a) of the lemma. So we have A in the
required form to be recursively enumerable.
Part (c) is essentially part (a) “plus n quantiﬁers” and is proved
like part (b).
⊣
Our reason for examining the particular set K is that it gives us the
following consequence:
G¨ODEL INCOMPLETENESS THEOREM
Th N is not recursively axiomatiz-
able.
PROOF.
Th N cannot be recursively enumerable, lest K be recur-
sively enumerable, by the preceding lemma. But any recursively
axiomatizable theory would be recursively enumerable (item 20
of Section 3.4; also Theorem 35I).
⊣
In starkest terms, the situation is this: Any recursively axiomatizable
theory is recursively enumerable. But Th N is not recursively enumer-
able. So any recursively axiomatizable subtheory must be incomplete.
It will be worth while to go over this proof again, but replacing
negative statements (such-and-such a set does not have a particular
property) by positive statements.
Assume that T is any recursively axiomatizable subtheory of Th N.
(So by the above theorem, T is incomplete.) We want to lay our hands
on a sentence demonstrating the incompleteness.
We have made a total recursive function f that many-one reduces K
to ♯Th N, namely f (a) = ♯( ¬ (Sa0)); then for every a,
a ∈K ⇐⇒f (a) ∈♯Th N.
And f (a) is (the G¨odel number of ) the sentence saying “a /∈K.”
Consider the set J of numbers deﬁned by the condition
a ∈J ⇐⇒f (a) ∈♯T.
Thus J is the set of numbers that T “knows” are not in K. There are
two observations to be made concerning J:
First, J is recursively enumerable. It is many-one reduced by f to
the recursively enumerable set ♯T ; apply Lemma 36I(b).
Secondly, J ⊆K. We have T ⊆Th N, so if T knows that a /∈K,
then really a /∈K:
a ∈J ⇐⇒f (a) ∈♯T '⇒f (a) ∈♯Th N ⇐⇒a ∈K.
So J is a recursively enumerable subset of K. It is a proper subset,
because K is not recursively enumerable. That is, there is some number
q with q ∈K and q /∈J. Consequently, f (q) ∈♯Th N but f (q) /∈♯T .
That is, the sentence ( ¬ (Sq0)) is true (in N) but fails to be in T ,
thereby demonstrating the incompleteness of T .

258
A Mathematical Introduction to Logic
And what does this sentence “say”? For q, we can take any number
for which Wq = J. Then q ∈K and q /∈J.
Here then is the situation:
( ¬ (Sq0))
says q /∈K
i.e., q /∈Wq
i.e., q /∈J
since Wq = J
i.e., f (q) /∈♯T
by deﬁnition of J
i.e., T ̸⊢( ¬ (Sq0)).
The sentence we made to witness the incompleteness of T asserts its
own unprovability in the axiomatizable theory T !
The computability approach and the self-reference approach to
G¨odel’s incompleteness theorem are not so different after all. Moreover,
the computability approach is close to the diagonalization approach
(of Section 3.0), but with the diagonal argument moved to a different
context.
Reduction of Decision Problems1
Suppose we have a two-place recursive partial function f . Then we
claim that, for example, the function g deﬁned by
g(a) = f (3, a)
is also a recursive partial function. On the basis of informal computabil-
ity this is clear; one computes g by plugging in 3 for the ﬁrst variable
and then following the instructions for f . A proof can be found by for-
malizing this argument. There is some formula ϕ = ϕ(v1, v2, v3) that
weakly represents f (as a relation) in Cn AE. Then g is weakly repre-
sented by ϕ(S30, v1, v2), provided that v1 and v2 are substitutable in ϕ
for v2 and v3. (If not, we can always use an alphabetic variant of ϕ.)
Now all this is not very deep. But by standing back and looking at
what was said, we perceive a more subtle fact. We were able to transform
effectively the instructions for f into instructions for g. So there should
be a recursive function that, given an index for f and the number 3,
will produce an index for g. The following formulation of this fact is
sometimes known by the cryptic name of “the S-m-n theorem.”
PARAMETER THEOREM
For each m ≥1 and n ≥1 there is a recursive
function ρ such that for any e, ⃗a, ⃗b,
[[e]]m+n(a1, . . . , am, b1, . . . , bn) = [[ρ(e, a1, . . . , am)]]n(b1, . . . , bn).
(Equality here means of course that if one side is deﬁned, then so also
is the other side, and the values coincide. Sometimes a special symbol
“≃” is used for this role.)
1 The remainder of this section can be skipped on a ﬁrst reading.

Chapter 3:
Undecidability
259
On the left side of the equation ⃗a consists of arguments for the func-
tion [[e]]m+n; on the right side ⃗a consists of parameters upon which
the function [[ρ(e, ⃗a)]]n depends. In the example we had m = n = 1
and a1 = 3. Since ρ depends on m and n, the notation “ρm
n ” would be
logically preferable. But, in fact, we will use simply “ρ.”
PROOF, FOR m = n = 1.
It is possible to give a proof along the lines
indicatedbythediscussionthatprecededthetheorem.Buttoavoid
having to cope with alphabetic variants, we will adopt a slightly
different strategy.
We know from the normal form theorem that the three-place
partial function h deﬁned by
h(e, a, b) = [[e]]2(a, b)
is a recursive partial function. Hence there is a formula ψ that
weakly represents h (as a relation). We may suppose that in ψ the
variables v1 and v2 are not quantiﬁed. We can then take
ρ(e, a) = ♯ψ(Se0, Sa0, v1, v2)
= Sb(Sb(Sb(Sb(♯ψ,♯v1,♯Se0),♯v2,♯Sa0),♯v3,♯v1),♯v4,♯v2).
Then ρ(e, a) is the G¨odel number of a formula weakly represent-
ing the function g(b) = [[e]]2(a, b). Hence it is an index of g.
⊣
We will utilize the parameter theorem to show that certain sets are
not recursive. We already know that K = {a | [[a]]1(a) is deﬁned} is
not recursive. For a given nonrecursive set A we can sometimes ﬁnd a
(total) recursive function g such that
a ∈K ⇔g(a) ∈A
or a (total) recursive function g′ such that
a /∈K ⇔g′(a) ∈A.
In either case it then follows at once that A cannot be recursive lest K be.
In the former case we have K ≤m A and A is not 1 (by Lemma 36I); in
the latter case K ≤m A and A is not 1. In either case, A is not recursive.
The function g or g′ can often be obtained from the parameter theorem.
EXAMPLE.
{a | Wa = ∅} is not recursive.
PROOF.
Call this set A. First, note that A ∈1, since Wa = ∅
iff ∀b∀k ⟨a, b, k⟩/∈T1. Consequently, K cannot be many-one
reducible to A, but it is reasonable to hope that K might be. That
is, we want a total recursive function g such that
[[a]]1(a) is undeﬁned ⇔dom[[g(a)]]1 = ∅.

260
A Mathematical Introduction to Logic
This will hold if for all b, [[g(a)]]1(b) = [[a]]1(a). So start with
the recursive partial function
f (a, b) = [[a]]1(a)
and let g(a) = ρ( ˆf , a), where ˆf is an index for f . Then
[[g(a)]]1(b) = [[ρ( ˆf , a)]]1(b) = f (a, b) = [[a]]1(a).
Thus this g shows that K is many-one reducible to A.
⊣
THEOREM 36J (RICE, 1953)
LetC beasetofone-placerecursivepar-
tial functions. Then the set {e | [[e]]1 ∈C} of indices of members
of C is recursive iff either C is empty or C contains all one-place
recursive partial functions.
PROOF.
Only one direction requires proof. Let IC = {e | [[e]]1 ∈C}
be the set of indices of members of C.
Case I: The empty function ∅is not in C. If nothing at all is
in C we are done, but suppose some function ψ is in C. We can
show that K is many-one reducible to IC if we have a recursive
total function g such that
[[g(a)]]1 =

ψ
if a ∈K,
∅
if a /∈K.
For then a ∈K ⇔[[g(a)]]1 ∈C ⇔g(a) ∈IC.
We can obtain g from the parameter theorem by deﬁning
g(a) = ρ(e, a),
where
[[e]]2(a, b) =

ψ(b)
if a ∈K,
undeﬁned
if a /∈K.
The above is a recursive partial function, since
[[e]]2(a, b) = c ⇔a ∈K & ψ(b) = c
and the right-hand side is recursively enumerable.
Case II: ∅∈C. Then apply case I to the complement C of C. We
canthenconcludethat IC isnotrecursive.But IC isthecomplement
of IC, so IC cannot be recursive.
Thus in either case, IC is not recursive.
⊣
EXAMPLES.
For any ﬁxed e, the set {a | Wa = We} is not recursive, as
a consequence of Rice’s theorem. In particular, {a | Wa = ∅} is
not recursive, a result proved in an earlier example. For two other
applications of Rice’s theorem, we can say that {a | Wa is inﬁnite}
and {a | Wa is recursive} are not recursive.

Chapter 3:
Undecidability
261
Register Machines
There are many equivalent deﬁnitions of the class of recursive func-
tions. Several of these deﬁnitions employ idealized computing devices.
These computing devices are like digital computers but are free of any
limitation on memory space. The ﬁrst deﬁnition of this type was pub-
lished by Alan Turing in 1936; similar work was done by Emil Post at
roughly the same time. We will give here a variation on this theme, due
to Shepherdson and Sturgis (1963).
A register machine will have a ﬁnite number of registers, numbered
1, 2, . . . , K. Each register is capable of storing a natural number of
any magnitude. The operation of the machine will be determined by a
program. A program is a ﬁnite sequence of instructions, drawn from the
following list:
I r (where 1 ≤r ≤K). “Increment r.” The effect of this instruction
is to increase the contents of register r by 1. The machine then proceeds
to the next instruction in the program.
D r (where 1 ≤r ≤K). “Decrementr.” The effect of this instruction
depends on the contents of register r. If that number is nonzero, it is
decreased by 1 and the machine then proceeds, not to the next instruc-
tion, but to the following one. But if the number in register r is zero, the
machine just proceeds to the next instruction. In summary: The machine
tries to decrement register r and skips an instruction if it is successful.
T q (where q is an integer–positive, negative, or zero). “Transfer q.”
All registers are left unchanged. The machine takes as its next instruc-
tion the qth instruction following this one in the program (if q ≥0), or
the |q|th instruction preceding this one (if q < 0). The machine halts if
there is no such instruction in the program. An instruction of T 0 results
in a loop, with the machine executing this one instruction over and over
again.
EXAMPLES
1. Program to clear register 7.
Try to decrement 7.
Go back and repeat.
Halt.
2. Program to move a number from register r to register s.
Clear register s
(Use the program of the ﬁrst example.)
Take 1 from r.
Halt when zero.
Add 1 to s.
Repeat.

262
A Mathematical Introduction to Logic
This program has seven instructions altogether. It leaves a zero
in register r.
3. Program to add register 1 to registers 2 and 3.
4. (Addition) Say that a and b are in registers 1 and 2. We want
a + b in register 3, and we want to leave a and b still in registers 1
and 2 at the end.
Register contents
Clear register 3.
a
b
0
Move number from register 1 to register 4.
0
b
0
a
Add register 4 to registers 1 and 3.
a
b
a
0
Move number from register 2 to register 4.
a
0
a
b
Add register 4 to registers 2 and 3.
a
b
a + b
0
This program has 27 instructions as it is written, but three of
them are unnecessary. (In the fourth line we begin by clearing
register 4, which is already clear.) At the end we have the number
a back in register 1. But during the program register 1 must be
cleared; this is the only way of determining the number a.
5. (Subtraction) Let a −. b = max(a −b, 0). We leave this
program to the reader (Exercise 11).
Now suppose f is an n-place partial function on N. Possibly there
will be a program P such that if we start a register machine (having all
the registers to which P refers) with a1, . . . , an in registers 1, . . . , n and
apply program P, then the following conditions hold:
(i) If f (a1, . . . , an) is deﬁned, then the calculation eventually termi-
nates with f (a1, . . . , an) in register n + 1. Furthermore, the calculation
terminates by seeking a (p+1)st instruction, where p is the length of P.
(ii) If f (a1, . . . , an) is undeﬁned, then the calculation never termi-
nates.
If there is such a program P, we say that P calculates f .
THEOREM 36K
Let f be a partial function. Then there is a program
that calculates f iff f is a recursive partial function.
Thus by using register machines we arrive at exactly the class of
recursive partial functions, a class we originally deﬁned in terms of
representability in consistent ﬁnitely axiomatizable theories. The fact

Chapter 3:
Undecidability
263
thatsuchdifferentapproachesproducethesameclassofpartialfunctions
is evidence that this is a signiﬁcant class.
OUTLINE OF PROOF.
To show that the functions calculable by reg-
ister machines are recursive partial functions, one “arithmetizes
calculations” in the same spirit as we arithmetized deductions in
Section 3.4. That is, one assigns G¨odel numbers to programs and
to sequences of memory conﬁgurations. One then veriﬁes that the
relevant concepts, translated into numerical relations by the G¨odel
numbering, are all recursive. (After going through this, one per-
ceives that, from a sufﬁciently general point of view, deductions
and calculations are really about the same sort of thing.)
Conversely, to show that the recursive partial functions are cal-
culable by register machines, one can work through Sections 3.3
and 3.4 again, but where functions were previously shown to be
representable in Cn AE, they must now be shown to be calculable
by register machines. This is not as hard as it might sound, since
after the ﬁrst few pages, the proofs are all the same as the ones
used before. There is a reason for this similarity. It can be shown
that the class of all recursive functions is generated from a certain
handful of recursive functions by the operation of composition (in
the sense of Theorem 33L) and the “least-zero” operator (Theo-
rem 33M). Much of the work in Sections 3.3 and 3.4 amounts
to a veriﬁcation of this fact. Thus once one has shown that each
function in this initial handful is calculable by a register machine
and that the class of functions calculable by register machines
is closed under composition and the least-zero operator, then the
earlier work can be carried over, yielding the calculability of all
recursive functions.
⊣
Exercises
1. Deﬁne functions f and g by
f (n) =
 0
if Goldbach’s conjecture is true,
1
otherwise;
g(n) =
⎧
⎨
⎩
0
if in the decimal expansion of π there
is a run of at least n consecutive 7’s,
1
otherwise.
Is f recursive? Is g recursive? (Goldbach’s conjecture says that
every even integer greater than 2 is the sum of two primes. The ﬁrst
edition of this book used Fermat’s last theorem here.)

264
A Mathematical Introduction to Logic
2. Deﬁne the “diagonal” function d(a) = [[a]]1(a) + 1.
(a) Show that d is a recursive partial function.
(b) By part (a), we have d = [[e]]1 for a certain number e. So on
the one hand, d(e) = [[e]]1(e) and on the other hand d(e) =
[[e]]1(e)+1. Can we cancel, to conclude that 0 = 1? Suggestion:
Use the special symbol “≃” to mean that either both sides of
the equation are undeﬁned, or both sides are deﬁned and equal.
Restate the argument in this notation.
3. (a) Show that the range of any recursive partial function is recur-
sively enumerable.
(b) Show that the range of a strictly increasing (i.e., f (n) <
f (n + 1)) total recursive function f is recursive.
(c) Show that the range of a nondecreasing (i.e., f (n) ≤f (n +1))
total recursive function f is recursive.
4. (a) Let A be a nonempty recursively enumerable subset of N. Show
that A is the range of some total recursive function.
(b) Show that any inﬁnite recursively enumerable subset of N
includes an inﬁnite recursive subset.
5. Show that every recursive partial function has inﬁnitely many
indices.
6. Give an example of a function f and a number e such that for
all a,
f (a) = U(μk ⟨e, a, k⟩∈T1)
but e is not the G¨odel number of a formula weakly representing in
Cn AE.
7. Show that the parameter theorem can be strengthened by requiring
ρ to be one-to-one.
8. Recall that the union of two recursively enumerable sets is recur-
sively enumerable (Exercise 7 of Section 3.5). Show that there is a
total recursive function g such that Wg(a,b) = Wa ∪Wb.
9. Showthat{a | Wa has two or more members}isin1 butnotin1.
10. Show that there is no recursively enumerable set A such that {[[a]]1 |
a ∈A} equals the class of total recursive functions on N.
11. Give register machine programs that calculate the following func-
tions:
(a) Subtraction, a −. b = max(a −b, 0).
(b) Multiplication, a · b.
(c) max(a, b).
12. Assume that there is a register machine program that calculates the
n-place partial function
f . Show that given any positive

Chapter 3:
Undecidability
265
integers r1, . . . ,rn (all distinct), p, and k, we can ﬁnd a program
Q such that whenever we start a register machine (having all the
registers to which Q refers) with a1, . . . , an in registers r1, . . . ,rn
and apply program Q, then (i) if f (a1, . . . , an) is deﬁned, then the
calculation eventually terminates with f (a1, . . . , an) in register p,
with the contents of registers 1, 2, . . . , k (except for register p) the
same as their initial contents, and furthermore the calculation ter-
minates by seeking a (q + 1)st instruction, where q is the length
of Q; (ii) if f (a1, . . . , an) is undeﬁned, then the calculation never
terminates.
13. Let g : Nn+1 →N be a (total) function that is calculated by some
register machine program. Let f (a1, . . . , an) = μb[g(a1, . . . ,
an, b) = 0], where the right-hand side is undeﬁned if no such b
exists. Show that the partial function f can be calculated by some
register machine program.
14. Show that the following sets have the given location in the arithmeti-
cal hierarchy. (In each case, the given location is the best possible,
but we will not prove that fact.)
(a) {e | [[e]]1 is total} is 2.
(b) {e | We is ﬁnite} is 2.
(c) {e | We is coﬁnite} is 3.
(d) {e | We is recursive} is 3.
15. Let Tot = {e | [[e]]1 is total}. Clearly Tot ⊂K. Show that there is
no recursive set A with
Tot ⊆A ⊆K.
Remark: This result includes Theorems 36E and 36F; the proofs
used there can be adapted here.
16. (a) Show that each 2 set of natural numbers is, for some number
e, the set
{a | ∀b∃c T2(e, a, b, c)}.
(b) Show that the set {a | not ∀b∃c T2(a, a, b, c)} is 2 but
not 2.
∗(c) Generalize parts (a) and (b) to show that for each n, there is a
set that is n but not n.
17. Assume that A is a set of natural numbers that is arithmetical but
is not m. Use the argument of page 256 to show that ♯Th N
is not m.
Remark: Exercises 16 and 17 give a proof of Tarski’s theorem
(that ♯Th N is not arithmetical) from computability theory.

266
A Mathematical Introduction to Logic
SECTION 3.7
Second Incompleteness Theorem
Let us return once again to item 20 in Section 3.4. Suppose that we
have a recursively axiomatizable theory T given by a recursive set A of
axioms (i.e., ♯A is recursive). Then as in item 20
a ∈♯T
⇐⇒∃d [d is the number of a deduction from A
and the last component of d is a and a
is the G¨odel number of a sentence].
The set of pairs ⟨a, d⟩meeting the condition in brackets is recursive; let
π(v1, v2) be a formula — chosen in some natural way — that numeral-
wise represents that binary relation in AE.
For any sentence σ, we can express “T ⊢σ” by the sentence
∃v2 π(S♯σ0, v2). Let us give that sentence a name; deﬁne
PrbT σ = ∃v2π(S♯σ0, v2).
(Here Prb abbreviates “provable.” The subscript should perhaps be “A”
instead of “T ”; in constructing the sentence we utilize the recursiveness
of the set A of axioms.)
LEMMA 37A
Let T be a recursively axiomatizable theory as above.
(a) Whenever T ⊢σ then AE ⊢PrbT σ.
(b) If in addition T includes AE, then T has the “reﬂection”
property:
T ⊢σ '⇒T ⊢PrbT σ.
PROOF.
If T ⊢σ then we can let d be the number of a deduction
of σ from the axioms A for T . We have AE ⊢π(S♯σ0, Sd0),
and hence AE ⊢PrbT σ. This gives part (a), from which part (b)
follows immediately.
⊣
Thus under modest assumptions, whenever T proves a sentence, it
knows that it proves the sentence. Note that part (b) does not say that
T ⊢(σ →PrbT σ). For example, if σ is true (in N) but unprovable
from AE, then the sentence (σ →PrbAE σ) is not provable from AE,
and in fact is false in N.
Returning now to the proof of the G¨odel incompleteness theorem
(in the self-reference approach), we can apply the ﬁxed-point lemma to
obtain a sentence σ asserting its own unprovability in T :
AE ⊢(σ ↔¬ PrbT σ).
The following lemma provides part of the incompleteness theorem (the
other part being Exercise 2 in Section 3.5):

Chapter 3:
Undecidability
267
LEMMA 37B
Let T be a recursively axiomatizable theory including
AE and let σ be obtained from the ﬁxed-point lemma as above. If
T is consistent, then T ̸⊢σ.
PROOF
T ⊢σ ⇒T ⊢PrbT σ by reﬂection
⇒T ⊢¬ σ
by choice of σ
whence T is inconsistent.
⊣
So far, this lemma merely reﬂects ideas employed in Section 3.5, and
the proof of Lemma 37B was not very complex. And that is exactly the
point: The proof is not very complex, so perhaps it can be carried out
within the theory T , if T is “sufﬁciently strong.” That, we can hope that
the steps
PrbT σ →PrbT PrbT σ
→PrbT ¬ σ
→PrbT 0 = S0
can be carried out in a sufﬁciently strong extension T of AE.
If so, we get a remarkable conclusion. Let Cons T be the sentence
¬ PrbT 0 = S0, which we think of as saying “T is consistent.” (Here
0 = S0 is chosen simply as a convenient sentence refutable from AE.)
If T lets us carry out the steps in the preceding paragraph, then we can
conclude:
T ̸⊢Cons T,
unless T is inconsistent
(Of course, an inconsistent theory contains every sentence, including
sentences asserting — falsely — the theory’s consistency. The situation
we are ﬁnding here is that, under suitable assumptions, this is the only
way that a theory can prove its own consistency.) Let’s check the details:
Suppose T ⊢Cons T . Then by the preceding paragraph, T ⊢¬ PrbT σ.
By choice of σ, we then get T ⊢σ. Lemma 37B then applies.
To make matters less vague, call the theory T sufﬁciently strong if it
meets the following three “derivability” conditions.
1. AE ⊆T . This implies by Lemma 37A that T has the reﬂection
property, T ⊢σ ⇒T ⊢PrbT σ.
2. For any sentence σ, T ⊢( PrbT σ →PrbT PrbT σ). This is the
reﬂection property, formalized within T .
3. For any sentences ρ and σ, T ⊢(PrbT (ρ →σ) →(PrbT ρ →
PrbT σ)). This is modus ponens, formalized within T .
FORMALIZED LEMMA 37B
Assume that T is a sufﬁciently strong re-
cursively axiomatizable theory, and let σ be a sentence such that
AE ⊢(σ ↔¬ PrbT σ).
Then T ⊢(Cons T →¬ PrbT σ).

268
A Mathematical Introduction to Logic
PROOF.
We put the pieces together carefully. By the choice of σ
we get
T ⊢(σ →(PrbT σ →0 = S0)).
Applying ﬁrst reﬂection and then formalized modus ponens to
this formula yields
T ⊢(PrbT σ →PrbT (PrbT σ →0 = S0))
after which another application of formalized modus ponens
yields
T ⊢(PrbT σ →(PrbT PrbT σ →¬ Cons T )).
The formula displayed above (to the right of the turnstile), to-
gether with PrbT σ →PrbT PrbT σ (formalized reﬂection) imply
by sentential logic PrbT σ →¬ Cons T .
⊣
G¨ODEL’S SECOND INCOMPLETENESS THEOREM (1931)
Assumethat T is
a sufﬁciently strong recursively axiomatizable theory. Then
T ⊢Cons T if and only if T is inconsistent.
PROOF.
If T ⊢Cons T then by Formalized Lemma 37B we have
T ⊢¬ PrbT σ whence by our choice of σ, we have T ⊢σ. We
conclude from the (unformalized) Lemma 37B that T is incon-
sistent.
⊣
We can squeeze a bit more out of these ideas. Lemma 37B can be
regarded as a special case (where τ is 0 = S0) of the following:
LEMMA 37C
Let T be a recursively axiomatizable theory including
AE, let τ be a sentence, and let σ be obtained from the ﬁxed-point
lemma so that
AE ⊢(σ ↔(PrbT σ →τ)).
If T ⊢σ, then T ⊢τ.
PROOF.
We can think of σ as saying, “If I am provable, then τ.” If
T ⊢σ then by reﬂection T ⊢PrbT σ. By the choice of σ, we
have T ⊢τ.
⊣
Actually we are not interested in this lemma, but in its formalization:
FORMALIZED LEMMA 37C
Assume that T is a sufﬁciently strong re-
cursively axiomatizable theory. Let τ be a sentence, and let σ be
a sentence such that
AE ⊢(σ ↔(PrbT σ →τ)).
Then T ⊢( PrbT σ →PrbT τ).

Chapter 3:
Undecidability
269
PROOF.
We proceed as before. By the choice of σ we get
T ⊢(σ →(PrbT σ →τ)).
Applying ﬁrst reﬂection and then formalized modus ponens to
this formula yields
T ⊢(PrbT σ →PrbT (PrbT σ →τ))
afterwhichanotherapplicationofformalizedmodusponensyields
T ⊢(PrbT σ →(PrbT PrbT σ →PrbT τ)).
The formula displayed above (to the right of the turnstile), to-
gether with PrbT σ →PrbT PrbT σ (formalized reﬂection) imply
by sentential logic PrbT σ →PrbT τ.
⊣
L¨OB’S THEOREM (1955)
Assume that T is a sufﬁciently strong re-
cursively axiomatizable theory. If τ is any sentence for which
T ⊢( PrbT τ →τ), then T ⊢τ.
Clearly if T ⊢τ, then T ⊢(ρ →τ) for any sentence ρ. So the
conclusion to L¨ob’s theorem can be stated
T ⊢(PrbT τ →τ) ⇐⇒T ⊢τ.
PROOF.
Given the sentence τ, we construct σ to say, “If I am prov-
able then τ,” as above. Suppose that T ⊢( PrbT τ →τ). By
Formalized Lemma 37C we have T ⊢( PrbT σ →PrbT τ). By
our choice of σ, we conclude that T ⊢σ. So by the (unformalized)
Lemma 37C, we have T ⊢τ.
⊣
L¨ob’s theorem was originally devised in order to solve the problem
given in Exercise 1. But it implies (and in a sense is equivalent to)
G¨odel’s second incompleteness theorem. Assume that T is a sufﬁciently
strong axiomatizable theory. Applying L¨ob’s theorem and taking τ to
be 0 = S0, we have
T ⊢(PrbT (0 = S0) →0 = S0) ⇒T ⊢0 = S0,
that is,
T ⊢Cons T ⇒T is inconsistent.
Thus we obtain a proof of the second incompleteness theorem.
But there is an issue not yet examined: What theories are sufﬁciently
strong? Are there any at all (apart from the trivial case of the inconsistent
theory)?
Yes, and here are two. The ﬁrst is called “Peano arithmetic” (PA).
Its axioms consist of the AE axioms, plus all the “induction axioms.”
These are the universal closures of formulas having the form
ϕ(0) ∧∀x(ϕ(x) →ϕ(Sx)) →∀x ϕ(x)

270
A Mathematical Introduction to Logic
forawffϕ.Theinductionaxioms — whichstatetheordinaryprincipleof
mathematical induction — enable us to carry out many arguments about
thenaturalnumbers(e.g.,thecommutativelawofaddition)withinPeano
arithmetic. But to be sure that formalized reﬂection and formalized
modus ponens can be derived with Peano arithmetic, one must carry out
the details, which we will not go through here.
We know that Peano arithmetic is consistent, because it is true in N.
But by the second incompleteness theorem, PA cannot prove its own
consistency. We “know” that PA is consistent by means of an argument
we carry out either in informal mathematics, or — if we want — in set
theory. So set theory has a higher “consistency strength” than PA: It
proves the consistency of PA and PA does not.
A second sufﬁciently strong theory is axiomatic set theory. Or to be
more careful, it is the set of sentences in the language of number theory
that are provable in axiomatic set theory. The next subsection deals with
this situation. This theory has the advantage that it is quite believable —
on an informal level — that formalized reﬂection and formalized modus
ponens are derivable. But what are our grounds for thinking that set
theory is consistent? We know that PA is consistent because it is true in
the “standard model” N of number theory. It is not at all clear that we
can meaningfully speak of a “standard model of set theory”!
Applications to Set Theory
We know that in the language of number theory, Cn AE is incomplete
and nonrecursive, as is any compatible recursively axiomatizable theory
in the language.
But now suppose we leave arithmetic for a while and look at set the-
ory. Here we have a language (with the parameters ∀and ∈) and a set
of axioms. In all presently accepted cases the set of axioms is recursive.
Or more precisely, the set of G¨odel numbers of the axioms is recursive.
And so the theory (set theory) obtained is recursively enumerable. We
claim that this theory, if consistent, is not recursive and hence not com-
plete. We can already sketch the argument in rough form. We can, in a
very real sense, embed the language of number theory in set theory. We
can then look at that fragment of set theory which deals with the natu-
ral numbers and their arithmetic (the shaded area in Fig. 14). That is a
theory compatible with AE. And so it is nonrecursive. Now if set theory
were recursive, then its arithmetical part would also be recursive, which
it is not. As a bonus, we will come across the second incompleteness
theorem for the case of set theory.
Henceforth by set theory (ST) we mean that theory (in the language
with equality having the two parameters ∀and ∈) which is the set of con-
sequences of the reader’s favorite set-theoretic axioms. (The standard
Zermelo–Fraenkel axioms will do nicely, if the reader has no favorite.

Chapter 3:
Undecidability
271
A recursively
enumerable
theory which
includes AE
Sentences in the
language of num-
ber theory
(recursive)
Set theory
(recursively
enumerable)
(a)
(b)
Sentences in the language of
number theory (recursive)
Set theory
(recursively
enumerable)
    Image of the above
  set under an
interpretation
Figure 14. Set theory and number theory. (a) Flat picture. (b) A more accurate
picture.
We ask only that the set of axioms be recursive, and that it be strong
enough to yield certain everyday facts about sets.) We need an inter-
pretation π of Cn AE into ST. (The remainder of this section assumes a
familiarity with Section 2.7.) But the existence of such a π is a standard
result of set theory, although it is not usually stated in these words. We
need formulas of the language of ST that adequately express the concept
of being a natural number, being the sum of two given numbers, and so
forth. To ﬁnd these formulas, we turn to the way in which the arithmetic
of natural numbers can be “embedded” in set theory. That is, on the one
hand, natural numbers such as 2 or 7 do not appear to be sets. On the
other hand, we can, when we choose, select sets to represent numbers.
The standard approach is to take 0 to be the set ∅and n + 1 to be the
set n; n. This has the fringe beneﬁt that each number is the set of all
smaller numbers (e.g., 3 ∈7). Let ω be the collection of all these sets

272
A Mathematical Introduction to Logic
(these “number-sets”); thus ω is the set representing N.
The formula π∀is the result of eliminating the deﬁned symbol ω
from the formula v1 ∈ω. The formula π0 is similarly obtained from
the set-theoretic formula v1 = ∅, and the formula πS is obtained from
v2 = v1 ∪{v1}. The formula π< is simply v1 ∈v2. For π+ we use the
translation into the language of ST of
For any f,
if f : ω × ω →ω and for all a and b
in ω we have f (a, ∅) = a
and f (a, b ∪{b}) = f (a, b) ∪{ f (a, b)},
then f (v1, v2) = v3.
(The manner of translation is partially indicated in Chapter 0.) The
formulas π. and πE are obtained in much the same fashion.
The claim that this π is an interpretation of Cn AE into ST makes a
number (and the number is 17) of demands on ST.
(i) ∃v1π∀must be in ST. It is, since we can prove in set theory that
ω is nonempty.
(ii) For each of the ﬁve function symbols f in the language of
AE, ST must contain a sentence asserting, roughly, that π f deﬁnes a
function on the set deﬁned by π∀. (The exact sentence is set forth in
the deﬁnition of interpretation in Section 2.7.) In the case of 0, we have
in ST the result that there is a unique empty set and that it belongs to
ω. The case for S is simple, since πS deﬁnes a unary operation on the
universe of all sets, and ω is closed under this operation. For + we
must use the recursion theorem on ω. That is, we can prove in ST (as
sketched in Section 1.4) that there is a unique f : ω × ω →ω such that
f (a, ∅) = a and f (a, b ∪{b}) = f (a, b) ∪{ f (a, b)} for a, b in ω.
The required property of π+ then follows. Similar arguments apply to ·
and E.
(iii) For each of the 11 sentences σ in AE, the sentence σ π must be
in ST. For example, in the case of L3, we have in ST the fact that for
any m and n in ω, either m ∈n, m = n, or n ∈m.
Since these demands are ﬁnite in number, there is a ﬁnite  ⊆ST
such that π is also an interpretation of Cn AE into Cn .
THEOREM 37D (STRONG UNDECIDABILITY OF SET THEORY)
Let T be a
theory in the language of set theory such that T ∪ST (or at least
T ∪) is consistent. Then ♯T is not recursive.
PROOF.
Let  be the consistent theory Cn(T ∪). Let 0 be the
corresponding theory π−1[] in the language of number theory.
From Section 2.7 we know that 0 is a consistent theory (since
 is). Also AE ⊆0, since if σ ∈AE, then σ π ∈Cn  ⊆.

Chapter 3:
Undecidability
273
Hence by the strong undecidability of Cn AE (Theorem 35C), ♯0
is not recursive.
Now we must derive the nonrecursiveness of T from that of
0. We have
σ ∈0
iff
σ π ∈
and by the lemma below, ♯σ π depends recursively on ♯σ. That is,
♯0 ≤m ♯.Hence♯cannotberecursive,lest♯0 be.Similarly,
we have
τ ∈
iff
(ϕ →τ) ∈T,
where ϕ is the conjunction of the members of . Since ♯(ϕ →τ)
depends recursively on ♯τ, we have ♯ ≤m ♯T so that ♯T cannot
be recursive lest ♯ be.
⊣
LEMMA 37E
Thereisarecursivefunction p suchthatforanyformula
α of the language of number theory, p(♯α) = ♯(απ).
PROOF.
In Section 2.7 we gave explicit instructions for construct-
ing απ. The construction in some cases utilized formulas βπ for
formulas β simpler than α. The methods of Sections 3.3 and 3.4
can be applied to the G¨odel numbers of these formulas to show
that p is recursive. But the details are not particularly attractive,
and we omit them here.
⊣
COROLLARY 37F
If set theory is consistent, then it is not complete.
PROOF.
Set theory has a recursive set of axioms. If complete, the
theory is then recursive (by item 21 of Section 3.4). By the fore-
going theorem, this cannot happen if ST is consistent.
⊣
COROLLARY 37G
In the language with equality and a two-place
predicate symbol, the set of (G¨odel numbers of) valid sentences
is not recursive.
PARTIAL PROOF.
In the foregoing theorem take T = Cn∅, the set of
valid sentences. The theorem then assures us that ♯T is nonrecur-
sive, provided that  is consistent. We have not given the ﬁnite
set  explicitly. But we assure the reader that  can be chosen in
such a way as to be provably consistent.
⊣
It should be noted that π is not an interpretation of Th N into ST
(unless ST is inconsistent). For π−1[ST] is a recursively enumerable
theory in the language of N, as a consequence of Lemma 37E. Hence
it cannot coincide with Th N, and it can include the complete theory
Th N only if it is inconsistent.

274
A Mathematical Introduction to Logic
G¨odel’s Second Incompleteness Theorem
for Set Theory
We can employ our usual tricks to ﬁnd a sentence a of number theory
which indirectly asserts that its own interpretation σ π is not a theorem
of set theory. For let D be the ternary relation on N such that
⟨a, b, c⟩∈D
iff
a is the G¨odel number of a formula α of number
theory and c is the G¨odel number of a deduction
from the axioms of ST of α(Sb0)π.
The relation D is recursive (by the usual arguments); let δ(v1, v2, v3)
represent D in Cn AE. Let r be the G¨odel number of
∀v3 ¬ δ(v1, v1, v3)
and let σ be
∀v3 ¬ δ(Sr0, Sr0, v3).
Observe that σ does indirectly assert that σ π /∈ST. We will now prove
that the assertion is correct:
LEMMA 37H
If ST is consistent, then σ π /∈ST.
PROOF.
Suppose to the contrary that σ π is deducible from the ax-
ioms of ST; let k be G of such a deduction. Then ⟨r,r, k⟩∈D.
∴AE ⊢δ(Sr0, Sr0, Sk0);
∴AE ⊢∃v3δ(Sr0, Sr0, v3);
i.e.,
AE ⊢¬ σ.
Applying our interpretation π, we conclude that ¬ σ π is in ST,
whence ST is inconsistent. Thus
ST is consistent ⇒σ π /∈ST.
⊣
Now the above proof, like all those in this book, is carried out in
informal mathematics. But all of our work in the book could have been
carried out within ST. Indeed it is common knowledge that essentially
all work in mathematics can be carried out in ST. Imagine actually doing
so. Then instead of a proof of an English sentence, “ST is consistent
⇒σ π /∈ST,” we have a deduction from the axioms of ST of a certain
sentence in the formal language of set theory:
(Cons(ST) →□).
Here Cons(ST) is the result of translating (in a nice way) “ST is
consistent” into the language of set theory. Similarly, □is the result of
translating “σ π /∈ST.” But we already have a sentence in the language

Chapter 3:
Undecidability
275
of set theory asserting that σ π /∈ST. It is σ π. This strongly suggests
that □is (or is provably equivalent in ST to) σ π, from which we get
(Cons(ST) →σ π)
as a theorem of ST.
Now this can actually be carried out in such a way as to have □be
σ π. We have given above an argument, which we hope will convince
the reader that this is at least probable. And from it we now have the
result:
G¨ODEL’S SECOND INCOMPLETENESS THEOREM FOR SET THEORY
The sen-
tence Cons(ST) is not a theorem of ST, unless ST is inconsistent.
PROOF.
By the above (plausibility) argument
(Cons(ST) →σ π)
is a theorem of ST. So if Cons(ST) is also a theorem of ST, then σ π
is, too. But by Lemma 37H, if σ π ∈ST, then ST is inconsistent.
⊣
Of course if ST is inconsistent, then every sentence is a theorem,
including Cons(ST). Because of this, a proof of Cons(ST) within ST
would not convince people that ST was consistent. (And by G¨odel’s
second theorem, it would convince them of the opposite.) But prior to
G¨odel’s work it was possible to hope that Cons(ST) might be provable
from assumptions weaker than the axioms of set theory, ideally assump-
tions already known to be consistent. But we now see that Cons(ST) is
not in any subtheory of ST, unless of course ST is inconsistent.
We are left with the conclusion that any recursively axiomatizable
theory of sets (provided it meets the desirable conditions of being
consistent and strong enough to prove everyday facts) is an incom-
plete theory. This raises a challenge: to ﬁnd additional axioms to add
to the theory. On the one hand, we want the additional axioms to
strengthen the theory in useful ways. On the other hand, we want the
additional axioms to reﬂect accurately our informal ideas about what
sets really are and how they really behave.
Exercises
1. Let σ be a sentence such that
AE ⊢(σ ↔PrbAEσ).
(Thus σ says “I am provable,” in contrast to the sentence “I am
unprovable” that has been found to have such interesting properties.)
Does AE ⊢σ?

276
A Mathematical Introduction to Logic
2. Let T be a theory in a recursively numbered language, and assume
that there is an interpretation of Cn AE into T . Show that T is strongly
undecidable; i.e., whenever T ′ is a theory in the language for which
T ∪T ′ is consistent, then ♯T ′ is not recursive.
SECTION 3.8
Representing Exponentiation1
In Sections 3.1 and 3.2 we studied the theory of certain reducts of N
and found them to be decidable. Then in Section 3.3 we added both
multiplication and exponentiation. The resulting theory was found (in
Section 3.5) to be undecidable. Actually it would have been enough
to add only multiplication (and forego exponentiation); we would still
have undecidability.
Let NM be the reduct of N obtained by dropping exponentiation:
NM = (N; 0, S, <, +, ·).
Thus the symbol E does not appear in the language of NM. Let AM be
the set obtained from AE by dropping E1 and E2. The purpose of this
section is to show that all the theorems of Sections 3.3–3.5 continue to
hold when “AE” and “N” are replaced by “AM” and “NM.” The key fact
needed to establish this claim is that exponentiation is representable in
Cn AM. That is, there is a formula ε in the language of NM such that
for any a and b,
AM ⊢∀z[ε(Sa0, Sb0, z) ↔z = S(ab)0].
Thus ε(x, y, z) can be used to simulate the formula xEy = z without
actual use of the symbol E.
If we look to see what relations and functions are representable in
Cn AM, we ﬁnd at ﬁrst that everything (except for exponentiation itself)
that was shown to be representable in Cn AE is (by the same proof)
representable in Cn AM. Until, that is, we reach item 7 in the catalog
listing of Section 3.3. To go further, we must show that exponentiation
itself is representable in Cn AM.
We know that exponentiation can be characterized by the recursion
equations
a0 = 1,
ab+1 = ab · a.
1 This section may be omitted without loss of continuity.

Chapter 3:
Undecidability
277
From what we know about primitive recursion (catalog item 13 in
Section 3.3 plus Exercise 8 there), we might think of deﬁning
E∗(a, b) = the least s such that [(s)0 = 1 and
for all i < b, (s)i+1 = (s)i · a].
For then ab = (E∗(a, b))b. This fails to yield a proof of representabil-
ity, because we do not yet know that the decomposition function (a)b
is representable in Cn AM. But we do not really need that particular
decomposition function (which corresponded to a particular way of
encoding sequences). All we need is some function δ that acts like a
decomposition function; the properties we need are summarized in the
following lemma.
LEMMA 38A
There is a function δ representable in Cn AM such that
for every n, a0, . . . , an, there is an s for which δ(s, i) = ai for
all i ≤n.
Once the lemma has been established, we can deﬁne
E∗∗(a, b) = the least s such that [δ(s, 0) = 1 and
for all i < b, δ(s, i + 1) = δ(s, i) · a].
The lemma assures us that such an s exists. E∗∗is then representable in
Cn AM, as is exponentiation, since
ab = δ(E∗∗(a, b), b).
A function δ that establishes the lemma will be provided by some facts
of number theory.
A Pairing Function
As a ﬁrst step toward proving the foregoing lemma, we will construct
functions for encoding and decoding pairs of numbers. It is well known
that there exist functions mapping N × N one-to-one onto N. In partic-
ular, the function J does this, where in the diagram shown, J(a, b) has
been written at the point with coordinates ⟨a, b⟩.

278
A Mathematical Introduction to Logic
For example, J(2, 1) = 8 and J(0, 2) = 3. To obtain an equation
for J(a, b), we note that along the line x + y = n there are n + 1 points
(with coordinates in N). Thus
J(a, b) = the number of points in the plane to which J assigns smaller
values
= [the number of points on lines x + y = n for
n = 0, 1, . . . , (a + b −1)] + [the number of points on the
line x + y = a + b for which x < a]
= [1 + 2 + · · · + (a + b)] + a
= 1
2(a + b)(a + b + 1) + a
= 1
2[(a + b)2 + 3a + b].
Let K and L be the corresponding projection functions onto the axes,
i.e., the unique functions such that
K(J(a, b)) = a,
L(J(a, b)) = b.
For example, K(7) = 1, the x-coordinate of the point ⟨1, 2⟩in the plane
to which J assigned the number 7. Similarly, L(7) = 2, the y-coordinate
of that point.
We claim that J, K, and L are representable in Cn AM. The function
H(a) = the least b such that a ≤2b
has the property that H(a) = 1
2a for even a. Then we can write
J(a, b) = H((a + b) · (a + b + 1)) + a,
K(p) = the least a such that [for some b ≤p, J(a, b) = p],
L(p) = the least b such that [for some a ≤p, J(a, b) = p].
From the form of the four preceding equations we conclude that H, J,
K, and L are representable in Cn AM.
The G¨odel β-function
Let β be the function deﬁned as follows:
β(c, d, i) = the remainder in c ÷ [1 + (i + 1) · d]
= the least r such that for some q ≤c,
c = q · [1 + (i + 1) · d] + r.
This unlikely-looking function produces a satisfactory decomposition
function for Lemma 38A. Let
δ(s, i) = β(K(s), L(s), i).
It is clear that δ is representable in Cn AM. What is not so obvious is
that it meets the conditions of Lemma 38A. We want to show:
For any n and any a0, . . . , an, there are numbers
c and d such that β(c, d, i) = ai for all i ≤n.
(∗)
For then it follows that δ(J(c, d), i) = β(c, d, i) = ai for i ≤n.

Chapter 3:
Undecidability
279
Now (∗) is a statement of number theory, not logic. The proof of (∗)
is based on the Chinese remainder theorem. Numbers d0, . . . , dn are
said to be relatively prime in pairs iff no prime divides both di and d j
for i ̸= j.
CHINESE REMAINDER THEOREM
Let d0, . . . , dn, be relatively prime in
pairs; let a0, . . . , an be natural numbers with each ai < di. Then
we can ﬁnd a number c such that for all i ≤n,
ai = the remainder in c ÷ di.
PROOF.
Let p = i≤ndi, and for any c let F(c) be the (n +1)-tuple
of remainders when c is divided by d0, . . . , dn. Notice that there
are p possible values for this (n + 1)-tuple.
We claim that F is one-to-one on {k | 0 ≤k < p}. For suppose
that F(c1) = F(c2). Then each di divides |c1 −c2|. Since the di’s
are relatively prime, p must divide |c1 −c2|. For c1, c2 less than
p, this implies that c1 = c2.
Hence the restriction of F to {k | 0 ≤k < p} takes on all p
possible values. In particular, it assumes (at some point c) the
value ⟨a0, . . . , an⟩. And that is the c we want.
⊣
LEMMA 38B
For any s ≥0, the s + 1 numbers
1 + 1 · s!, 1 + 2 · s!,
. . . , 1 + (s + 1) · s!
are relatively prime in pairs.
PROOF.
All these numbers have the property that any prime factor
q cannot divide s!, whence q > s. If the prime q divides both
1+ j ·s! and 1+k ·s!, then it divides their difference, | j −k|·s!.
Since q does not divide s!, it divides | j −k|. But | j −k| ≤s < q.
This is possible only if | j −k| = 0.
⊣
PROOF OF (∗).
Assume we are given a0, . . . , an; we need numbers
c and d such that the remainder when c is divided by 1+(i +1)·d
is ai, for i ≤n.
Let s be the largest of {n, a0, . . . , an} and let d = s!. Then by
Lemma 38B, the numbers 1 + (i + 1) · d are relatively prime in
pairs for i ≤n. So by the Chinese remainder theorem there is a c
such that the remainder in c ÷ [1 + (i + 1) · d] is ai for i ≤n.
⊣
This completes the proof of Lemma 38A. And by the argument that
followed that lemma, we can conclude:
THEOREM 38C
Exponentiation is representable in Cn AM.
Armed with this theorem, we can now return to catalog item 7 of
Section 3.3. The proof given there now establishes that the function in
question (whose value at n is pn) is representable in Cn AM. For it was

TABLE X
Structure
Theory
Models of the theory
Deﬁnable sets
Comments
(N)
Decidable. Not ﬁnitely
Any inﬁnite set.
∅and N.
axiomatizable. Admits
{0} is not deﬁnable.
elimination of quantiﬁers.
(N; 0)
As above.
Any inﬁnite set with
∅, {0}, N −{0}, N.
distinguished element.
(N; 0, S)
As above.
Standard part plus any
Finite and coﬁnite sets.
{0} is deﬁnable in (N; S).
number of Z-chains.
< is not deﬁnable.
(N; 0, S, <)
Decidable. Finitely
As above, with any
Finite and coﬁnite sets.
{0} and S are deﬁnable
axiomatizable.
ordering of the Z-chains.
+ is not deﬁnable.
in (N; <).
Admits elimination of
quantiﬁers.
(N; 0, S, <, +)
Decidable (Presburger).
The Z-chains are densely
Eventually periodic sets.
{0}, S, and < are
ordered without
· is not deﬁnable.
deﬁnable in (N; +).
endpoints.
Also there is a suitable
addition operation.
(N; 0, S, <, +, ·)
Not arithmetical.
As above, but with a
All arithmetical relations
The arithmetical relations
∴not recursively
suitable multiplication
are deﬁnable.
are deﬁnable in
axiomatizable.
operation.
(N; S, ·), (N; +, ·),
and (N; <, D), where
D(x, y) = (x)y.
S is not deﬁnable.
280

Chapter 3:
Undecidability
281
formed by allowable methods from relations and functions (including
exponentiation) known to be representable in Cn AM.
The same phenomenon persists throughout Sections 3.3 and 3.4.
The representability proofs given there now establish representability
in Cn AM. Thus any recursive relation is representable in Cn AM, and if
therelationhappenstobeafunction,thenitisfunctionallyrepresentable.
The proofs given in Section 3.5 then apply to NM and AM as well as to
N and AE. In particular, we have the strong undecidability of Cn AM:
Any theory T in the language of NM for which T ∪AM is consistent
cannot be recursive.
Notice that any relation deﬁnable in N (i.e., any arithmetical relation)
is also deﬁnable in NM. For exponentiation, being representable in a
subtheory of Th NM, is a fortiori deﬁnable in NM. By the new version
of Tarski’s theorem, ♯ThNM is not deﬁnable in NM, and consequently
♯ThNM cannot be arithmetical.
In the terminology of Section 2.7, we can say that there is a faithful
interpretation of Th N into Th NM. It equals the identity interpretation
on all parameters except E, and to E it assigns a formula deﬁning ex-
ponentiation in NM.
In Table X we summarize some of the results of Chapter 3 on number
theory and its reducts.
Exercises
1. Let D(a, b) = (a)b. Show that any arithmetical relation is deﬁnable
in the structure (N; <, D). Remark: One may well ask why Th NA,
arithmeticwithaddition, isdecidable(asshowninSection3.2),while
Th NM, the theory of arithmetic with addition and multiplication, is
undecidable. One answer is that, as this section shows, multiplication
lets us do a certain amount of sequence coding and decoding. The
point of this exercise is to show that once we have the decoding
function D and ordering, we have the full complexity of arithmetic
with addition, multiplication, and exponentiation.
2. Show that the addition relation {⟨a, b, c⟩| a + b = c} is deﬁnable in
the structure (N; S, ·). Suggestion: Under what conditions does the
equation S(ac) · S(bc) = S(c · c · S(ab)) hold?
3. (a) Show that Th(Z; +, ·) is strongly undecidable. (See Exercise 2
of Section 3.7.)
(b) (This part assumes a background in algebra.) Show that the the-
ory of rings is undecidable and that the theory of commutative
rings is undecidable.

Chapter
F O U R
Second-Order
Logic
SECTION 4.1
Second-Order Languages
We can obtain — at a cost — richer, more expres-
sive languages than the ﬁrst-order languages con-
sidered thus far, by allowing quantiﬁcation of
predicate or function symbols. For example,
∃x(Px →∀x Px)
is a valid formula having ∀and P as its parameters.
Because it is true no matter how P is interpreted,
∀P ∃x(Px →∀x Px)
deserves to be called valid. (Now ∀is the only pa-
rameter, since P is treated as a predicate variable.)
Suppose, then, that we have in addition to the
symbols introduced at the beginning of Section 2.1,
the further logical symbols:
4. Predicate variables: For each positive integer
n we have the n-place predicate variables
Xn
1, Xn
2, . . . .
5. Function variables: For each positive integer
n, we have the n-place function variables
Fn
1, Fn
2, . . . .
The usual variables v1, v2, . . . will now be called
individual variables, to avoid confusion. The terms
are as before deﬁned as the expressions that can be
built up from the constant symbols and the
282

Chapter 4:
Second-Order Logic
283
individual variables by applying the function symbols (both the func-
tion parameters and the function variables). Atomic formulas are again
expressions Pt1 · · · tn, where t1, . . . , tn are terms and P is an n-place
predicate symbol (parameter or variable). The deﬁnition of wff is aug-
mented by new formula-building operations: If ϕ is a wff, then so also
are ∀Xn
i ϕ and ∀Fn
i ϕ. The concept of a variable occurring free in ϕ
is deﬁned just as before. A sentence is a wff σ in which no variable
(individual, predicate, or function) occurs free.
It should be remarked that the roles played by predicate parame-
ters and free predicate variables are essentially the same. There is the
same close relationship between constant symbols and free individual
variables, and between function parameters and free function variables.
By a structure we continue to mean a function on the set of parame-
ters meeting the conditions set forth in Section 2.2. We must extend the
deﬁnition of satisfaction in the natural way. Let V now be the set of all
variables, individual, predicate, or function. Let s be a function on V that
assigns to each variable the suitable type of object. Thus s(v1) is a mem-
ber of the universe, s(Xn) is an n-ary relation on the universe, and s(Fn)
is an n-ary operation. For a term t, s(t) is deﬁned in the natural way. In
particular, if F is a function variable, then s(Ft1 · · · tn) is the result of
applying the function s(F) to ⟨s(t1), . . . , s(tn)⟩. Satisfaction of atomic
formulas is also deﬁned essentially as before. For a predicate variable X,
|=A Xt1 · · · tn[s]
iff
⟨s(t1), . . . , s(tn)⟩∈s(X).
The only new features in the deﬁnition of satisfaction arise from our
new quantiﬁers.
5. |=A ∀Xn
i ϕ[s] iff for every n-ary relation R on |A|, we have
|=A ϕ[s(Xn
i | R)].
6. |=A ∀Fn
i ϕ[s] iff for every function f : |A|n →|A|, we have
|=A ϕ[s(Fn
i | f )].
Again it is easy to see that only the values of s at variables occurring
free in the formula are signiﬁcant. For a sentence σ, we may unam-
biguously speak of its being true or false in A. Logical (semantical)
implication is deﬁned exactly as before.
EXAMPLE 1.
A well-ordering is an ordering relation such that any
nonempty set has a least (with respect to the ordering) element.
This last condition can be translated into the second-order
sentence
∀X( ∃y Xy →∃y(Xy ∧∀z(Xz →y ≤z))).
Here, as elsewhere, we omit the subscripts on X and F when they
are immaterial, and we omit the superscripts if they are clear from
the context.

284
A Mathematical Introduction to Logic
EXAMPLE 2.
One of Peano’s postulates (the induction postulate)
states that any set of natural numbers that contains 0 and is closed
under the successor function is, in fact, the set of all natural num-
bers. This can be translated into the second-order language for
number theory as
∀X(X0 ∧∀y(Xy →XSy) →∀y Xy).
Any model of S1, S2, and the above Peano induction postu-
late is isomorphic to (N; 0, S); see Exercise 1. Thus this set of
sentences is categorical; i.e., all its models are isomorphic.
EXAMPLE 3.
For any formula ϕ in which the predicate variable Xn
does not occur free, the formula
∃Xn ∀v1 · · · ∀vn[Xnv1 · · · vn ↔ϕ]
is valid. (Here other variables may occur free in ϕ in addition to
v1, . . . , vn.) It says that there exists a relation consisting of exactly
the n-tuples satisfying ϕ. Formulas of this form are called relation
comprehension formulas. There are also the analogous function
comprehension formulas. If ψ is a formula in which the variable
Fn does not occur free, then
∀v1 · · · ∀vn ∃!vn+1 ψ →
∃Fn ∀v1 · · · ∀vn+1(Fnv1 · · · vn = vn+1 ↔ψ)
is valid. (Here “∃!vn+1 ψ” is an abbreviation for a formula ob-
tained from Exercise 21 of Section 2.2.)
EXAMPLE 4.
In the ordered ﬁeld of real numbers, any bounded non-
empty set has a least upper bound. We can translate this by the
second-order sentence
∀X[∃y ∀z(Xz →z ≤y) ∧∃z Xz →
∃y ∀y′( ∀z(Xz →z ≤y′) ↔y ≤y′)].
It is known that any ordered ﬁeld that satisﬁes this second-order
sentence is isomorphic to the ordered ﬁeld of reals.
EXAMPLE 5.
For each n ≥2, we have a ﬁrst-order sentence λn which
translates, “There are at least n things.” For example, λ3 is
∃x ∃y ∃z(x ̸= y ∧x ̸= z ∧y ̸= z).
The set {λ2, λ3, . . .} has for its class of models the EC class
consisting of the inﬁnite structures. There is a single second-
order sentence that is equivalent. A set is inﬁnite iff there is an
ordering on it having no last element. Or more simply, a set is

Chapter 4:
Second-Order Logic
285
inﬁnite iff there is a transitive irreﬂexive relation R on the set
whose domain is the entire set. This condition can be translated
into a second-order sentence λ∞:
∃X[∀u ∀v ∀w(Xuv →Xvw →Xuw) ∧∀u ¬ Xuu ∧
∀u ∃v Xuv].
Another sentence (using a function variable) that deﬁnes the class
of inﬁnite structures is
∃F[∀x ∀y(Fx = Fy →x = y) ∧∃z ∀x Fx ̸= z],
which says there is a one-to-one function that is not onto.
The preceding example shows that the compactness theorem fails for
second-order logic:
THEOREM 41A
There is an unsatisﬁable set of second-order sen-
tences every ﬁnite subset of which is satisﬁable.
PROOF.
The set is, in the notation of the above example,
{¬ λ∞, λ2, λ3, . . .}.
⊣
The L¨owenheim–Skolem theorem also fails for second-order logic.
By the language of equality we mean the language (with =) having no
parameters other than ∀. A structure for this language can be viewed
as being simply a nonempty set. In particular, a structure is determined
to within isomorphism by its cardinality. A sentence in this language is
therefore determined to within logical equivalence by the set of cardi-
nalities of its models (called its spectrum).
THEOREM 41B
There is a sentence in the second-order language of
equality that is true in a set iff its cardinality is 2ℵ0.
PROOF, USING CONCEPTS FROM ALGEBRA AND ANALYSIS.
Considerﬁrst
the conjunction of the (ﬁrst-order) axioms for an ordered ﬁeld,
further conjoined with the second-order sentence expressing the
least-upper-bound property (see Example 4 of this section). This
is a sentence whose models are exactly the isomorphs of the real
ordered ﬁeld (i.e., the structures isomorphic to the ordered ﬁeld
of real numbers). We now convert the parameters 0, 1, +, ·, < to
variables (individual, function, or predicate as appropriate) which
we existentially quantify. The resulting sentence has the desired
properties.
⊣
There are other cardinal numbers with second-order characteriza-
tions of this sort; cf. Exercise 2.

286
A Mathematical Introduction to Logic
THEOREM 41C
The set of G¨odel numbers of valid second-order sen-
tences is not deﬁnable in N by any second-order formula.
Here we assume that G¨odel numbers have been assigned to second-
order expressions in a manner like that used before. Although our proof
applies to the second-order language of number theory, the theorem is
true for any recursively numbered language having at least a two-place
predicate symbol.
PROOF.
Let T 2 be the second-order theory of N, i.e., the set of
second-order sentences true in N. The same argument used to
prove Tarski’s theorem shows that ♯T 2 is not deﬁnable in N by
any second-order formula.
Now let α be the conjunction of the members of AE with the
second-order Peano induction postulate (Example 2). Any model
of α is isomorphic to N; cf. Exercise 1. Consequently, for any
sentence σ,
σ ∈T 2
iff
(α →σ) is valid.
Consequently, the set of (G¨odel numbers of) validities cannot be
deﬁnable lest ♯T 2 be.
⊣
A fortiori, the set of G¨odel numbers of second-order validities is
not arithmetical and not recursively enumerable. That is, the enumer-
ability theorem fails for second-order logic. (In the other direction,
one can show that this set is not deﬁnable in number theory of or-
der three, or even of order ω. But these are topics we will not enter into
here.)
It is interesting to compare the effect of a second-order universal
sentence, such as the Peano induction postulate
∀X(X0 ∧∀y(Xy →XSy) →∀y Xy)
and the corresponding ﬁrst-order “schema,” i.e., the set of all sentences
ϕ(0) ∧∀y(ϕ(y) →ϕ(Sy)) →∀y ϕ(y),
where ϕ is a ﬁrst-order formula having just v1 free. If A is a model of
the Peano induction postulate, then any subset of |A| containing 0A and
closed under SA is in fact all of |A|. On the other hand, if A is a model of
the corresponding axiom schema, we can say only that every deﬁnable
subset of |A| containing 0A and closed under SA is all of |A|. There
may well be undeﬁnable subsets for which this fails. (For example,
take any model A of Th(N; 0, S) having Z-chains. Then A satisﬁes
the above ﬁrst-order schema, but it does not satisfy the second-order
induction postulate. The set of standard points is simply not deﬁnable
in N.)

Chapter 4:
Second-Order Logic
287
Exercises
1. Show that any structure for the language with parameters ∀, 0, and
S that satisﬁes the sentences
∀x Sx ̸= 0
(S1)
∀X ∀y(Sx = Sy →x = y)
(S2)
and the Peano induction postulate
∀X(X0 ∧∀y(Xy →XSy) →∀y Xy)
is isomorphic to NS = (N; 0, S).
2. (a) Give a sentence in the second-order language of equality that is
true in a set iff its cardinality is ℵ0.
(b) Do the same for ℵ1.
3. Let ϕ be a formula in which only the n-place predicate variable X
occurs free. Say that an n-ary relation R on |A| is implicitly deﬁned
in A by ϕ iff A satisﬁes ϕ with an assignment of R to X but does
not satisfy ϕ with an assignment of any other relation to X. Show
that ♯Th N, the set of G¨odel numbers of ﬁrst-order sentences true
in N, is implicitly deﬁnable in N by a formula without quantiﬁed
predicate or function variables. Suggestion: The idea is to write down
conditions that the set of true sentences must meet.
4. Consider a language (with equality) having the one-place predicate
symbols I and S and the two-place predicate symbol E. Find a
second-ordersentenceσ suchthat(i)if A isasetforwhich A ∩P A =
∅andif|A| = A ∪P A, I A = A, SA = P A, EA = {⟨a, b⟩| a ∈b ⊆
A}, then A is a model of σ; and (ii) every model of σ is isomorphic
to one of the sort described in (i). Remark: Roughly speaking, σ
translates “S = P I.”
SECTION 4.2
Skolem Functions
We want to show how, given any ﬁrst-order formula, one can ﬁnd
a logically equivalent prenex second-order formula of a very special
form:

288
A Mathematical Introduction to Logic
This is a prenex formula wherein all universal quantiﬁers are indi-
vidual ones that follow a string of existential individual and function
quantiﬁers.
In the simplest example, observe that
∀x ∃y ϕ(x, y) |==| ∃F ∀x ϕ(x, Fx).
In the “=|” direction this is easy to see. For the “|=” direction, consider
a structure A and an assignment function s satisfying ∀x ∃y ϕ(x, y).
We know that for any a ∈|A| there is at least one b ∈|A| such that
|=A ϕ(x, y)[s(x | a)(y | b)].
We obtain a function f on |A| by choosing one such b for each a and
taking f (a) = b. (The axiom of choice is used here.) Then
|=A ∀x ϕ(x, Fx)[s(F | f )].
This function f is called a Skolem function for the formula ∀x ∃y ϕ in
the structure A.
The same argument applies more generally. As a second example,
suppose that we begin with the formula
∃y1 ∀x1 ∃y2 ∀x2 ∀x3 ∃y3 ψ(y1, y2, y3).
(We have listed only y1, y2, and y3, but possibly other variables occur
free in ψ as well.) Here we already have the existential quantiﬁer ∃y1
at the left. What remains is
∀x1 ∃y2 ∀x2 ∀x3 ∃y3 ψ(y1, y2, y3).
This is a special case of the ﬁrst example (with ϕ(x1, y2) = ∀x2 ∀x3
∃y3 ψ(y1, y2, y3)). It is logically equivalent, as before, to
∃F2 ∀x1 ∀x2 ∀x3 ∃y3 ψ(y1, F2x1, y3).
Now we have the existential quantiﬁers ∃y1 ∃F2 at the left; what re-
mains is
∀x1 ∀x2 ∀x3 ∃y3 ψ(y1, F2x1, y3).
By the same reasoning as before, this is logically equivalent to
∃F3 ∀x1 ∀x2 ∀x3 ψ(y1, F2x1, F3x1x2x3),
where F3 is a three-place function variable. Thus the original formula
is equivalent to
∃y1 ∃F2 ∃F3 ∀x1 ∀x2 ∀x3 ψ(y1, F2x1, F3x1x2x3).
For quantiﬁer-free ψ, this is in the form we desire.
SKOLEM NORMAL FORM THEOREM
For any ﬁrst-order formula, we can
ﬁnd a logically equivalent second-order formula consisting of:

Chapter 4:
Second-Order Logic
289
(a) First a string (possibly empty) of existential individual and
function quantiﬁers, followed by
(b) A string (possibly empty) of universal individual quantiﬁers,
followed by
(c) A quantiﬁer-free formula.
A formal proof could be given using induction, but the preceding
example illustrates the general method.
Recall that a universal (∀1) formula is a ﬁrst-order prenex formula
all of whose quantiﬁers are universal: ∀x1 ∀x2 · · · ∀xk α, where α is
quantiﬁer-free. Similarly, an existential (∃1) formula is a ﬁrst-order
prenex formula all of whose quantiﬁers are existential.
COROLLARY 42A
For any ﬁrst-order ϕ, we can ﬁnd a universal for-
mula θ in an expanded language containing function symbols,
such that ϕ is satisﬁable iff θ is satisﬁable.
By applying this corollary to ¬ ϕ, we obtain an existential formula
(with function symbols) that is valid iff ϕ is valid.
PROOF.
Again we will only illustrate the situation by an example.
Say that ϕ is
∃y1 ∀x1 ∃y2 ∀x2 ∀x3 ∃y3 ψ(y1, y2, y3).
First we replace ϕ by the logically equivalent formula in Skolem
form:
∃y1 ∃F2 ∃F3 ∀x1 ∀x2 ∀x3 ψ(y1, F2x1, F3x1x2x3).
Then for θ we take
∀x1 ∀x2 ∀x3 ψ(c, f x1, gx1x2x3),
where c, f , and g are new function symbols having zero, one, and
three places, respectively. In general θ is not logically equivalent
to ϕ. But we do have θ |= ϕ (in the expanded language). And
any model A of ϕ can be expanded (by deﬁning cA, f A, and
gA correctly) to be a model of θ. Thus ϕ and θ are “equally
satisﬁable.”
⊣
This result reduces the general problem of testing ﬁrst-order formulas
for satisﬁability to the special case of universal formulas (with function
symbols). And by the same token, it reduces the problem of testing
for validity to the ∃1 case. From these reductions we can derive an
undecidability result for ﬁrst-order logic:
COROLLARY 42B
Consider a recursively numbered language having
a two-place predicate symbol and inﬁnitely many k-place function
symbols for each k ≥0.

290
A Mathematical Introduction to Logic
(a) The set of G¨odel numbers of satisﬁable universal (ﬁrst-order)
sentences is not recursive.
(b) The set of G¨odel numbers of valid existential (ﬁrst-order)
sentences is not recursive.
PROOF.
(b)Givenanysentenceσ wecan,byapplyingCorollary42A
to ¬ σ, effectively ﬁnd an existential sentence that is valid iff σ
is valid. Hence a decision procedure for the existential validities
would yield a decision procedure for arbitrary validities, in con-
tradiction to Church’s theorem.
⊣
We can use predicate variables instead of function variables in these
results, but at a price. Suppose we begin with a ﬁrst-order formula.
It is equivalent to a formula ψ in Skolem normal form; suppose for
simplicity that ψ = ∃F ϕ, where ϕ has only individual quantiﬁers and
F is a one-place function variable. We can choose ϕ in such a way that
F occurs only in equations of the form u = Ft (for terms t and u not
containing F). This can be done by replacing, for example, an atomic
formula α(Ft) by either ∀x(x = Ft →α(x)) or ∃x(x = Ft ∧α(x)).
Next observe that a formula
∃F
u = Ft
,
wherein F occurs only in the form shown, is equivalent to
∃X( ∀y ∃!z Xyz ∧
Xtu
).
If one pursues this question (as we will not do here) one ﬁnds that
any ﬁrst-order formula is logically equivalent to a second-order formula
consisting of
(a) A string of existential predicate quantiﬁers, followed by
(b) A string of universal individual quantiﬁers, followed by
(c) A string of existential individual quantiﬁers, followed by
(d) A quantiﬁer-free formula.
There are corresponding versions — see Exercise 4 — of Corollar-
ies 42A and 42B. The analogue of Corollary 42A reduces the problem
of testing ﬁrst-order formulas for satisﬁability to the special case of ∀2
formulas (with predicate symbols). The problem of testing for validity
is reduced to the ∃2 case.
The analogue of Corollary 42B can be compared with Exercise 10
in Section 2.6, where it is shown that the set of ∀2 validities without
function symbols is decidable.
Herbrand Expansions
We have seen (in Corollary 42A) how, given a formula of ﬁrst-order
logic, to ﬁnd an “equally satisﬁable” universal formula. And thus

Chapter 4:
Second-Order Logic
291
(Corollary 42B) the question of satisﬁability in ﬁrst-order logic is
reducible to the question of satisﬁability of universal formulas.
Now we go one step further: satisﬁability of these universal formulas
is reducible — but in a weaker sense — to satisﬁability in sentential
logic.
EXAMPLE.
We know that ∀x ∃y Pxy ̸|= ∃y ∀x Pxy. But pretend
we did not know this, and that we are interested in determin-
ing whether or not logic implication holds here. That is equiv-
alent to determining whether or not the hypothesis ∀x ∃yPxy
together with the negation of the conclusion ¬ ∃y ∀x Pxy is
unsatisﬁable.
By the Skolem normal form theorem, we can replace these sen-
tences by certain logically equivalent sentences; we wish to deter-
minewhetherornot∃F ∀x PxFx togetherwith∃G ∀y ¬ PGyy
is unsatisﬁable. And as in Corollary 42A, we replace these sen-
tences by equally satisﬁable universal sentences; we wish to de-
termine whether or not the set {∀x Px f x, ∀y Pgy y} is unsat-
isﬁable (where f and g are new function symbols).
But this set of universal sentences is satisﬁable, and moreover,
the set can be made to generate its own model. Here is how. For
the universe of our model we will use the Herbrand universe H,
which is the set of all terms (in the language with f and g). Thus
H contains, for each variable u, the terms
u, f u, gu, f f u, f gu, . . . .
Let  be the set of all instances of the universal sentences, that
is, the formulas obtained by dropping all the universal quantiﬁers
and plugging in (for the universally quantiﬁed variables) arbitrary
terms from the Herbrand universe. Thus  contains, for each
variable u, the quantiﬁer-free formulas
Pu f u, Pgu f gu, . . . , ¬ Pgu u, ¬ Pg f u f u, . . . .
Now we consider  from the point of view of sentential logic.
The sentence symbols are the atomic formulas, e.g., Pg f u f u.
And in this example  is satisﬁable in sentential logic. That is,
there is a truth assignment v on the set of sentence symbols so
that v(α) = T for every α in . Here is one such v:
v(Pt1t2) =

T
if t1 is shorter than t2
F
if t1 is at least as long as t2
Finally, we use this truth assignment v (in sentential logic) to
make a structure H (in ﬁrst-order logic) that will be a model of
the universal sentences. The universe is the Herbrand universe:

292
A Mathematical Introduction to Logic
|H| = H. (There are echos of the completeness proof of Sec-
tion 2.5 here.) The function symbols are interpreted autony-
mously — as naming themselves: f H(t) is f t and gH(t) is gt.
Where v comes in is to interpret the predicate symbol P:
⟨t1, t2⟩∈PH ⇐⇒v(Pt1t2) = T
This structure works. First |=H ∀x Px f x because for every
term t in the Herbrand universe, ⟨t, f t⟩
∈
PH. Secondly
|=H ∀y ¬ Pgy y because for every term t in the Herbrand uni-
verse, ⟨gt, t⟩/∈PH.
We conclude that the hypothesis ∀x ∃y Pxy together with the
negated conclusion ¬ ∃y ∀x Pxy is indeed satisﬁable, and hence
∀x ∃y Pxy ̸|= ∃y ∀x Pxy.
To what extent can we generalize from this example? Assume, for
simplicity, that the language does not contain equality. (Exercise 7 indi-
cates the changes needed to accommodate equality.) Suppose we want
to determine whether or not  |= ϕ for a set ; ϕ of formulas in ﬁrst-
order logic. This is equivalent to determining whether or not the set
; ¬ ϕ is unsatisﬁable.
We can replace each of the formulas here by a logically equivalent
formula in Skolem normal form. And as in Corollary 42A, we get an
equally satisﬁable set  of universal formulas. (In applying Skolem
normal form, we use different Skolem function symbols for each for-
mula, so that there is no clash between formulas.) This brings us to the
situation:
 |= ϕ ⇐⇒ is unsatisﬁable
and  is a set of universal formulas.
Let H be the Herbrand universe, that is, the set of all terms in the
language of . Let  be the set of all instances of the universal formulas
in (i.e.,formulas obtainedby droppingall theuniversalquantiﬁersand
plugging in for the universally quantiﬁed variables arbitrary terms from
the Herbrand universe). Then  consists of quantiﬁer-free formulas
only. We consider  from the viewpoint of sentential logic, where the
sentence symbols are the atomic formulas.
Case I:  is unsatisﬁable in sentential logic. In this case, we can
conclude that  is unsatisﬁable and  |= ϕ in ﬁrst-order logic. This
is because a universal formula logically implies all of its instances.
Therefore  |= δ for every δ in  (in ﬁrst-order logic). Any model of 
must be a model of . But from a model A of  we can extract a truth
assignment v that satisﬁes  in sentential logic. (Remember Exercise 3
in Section 2.4. Note the interesting interplay between ﬁrst-order logic
and sentential logic.)

Chapter 4:
Second-Order Logic
293
Case II:  is satisﬁable in sentential logic, say by the truth assign-
ment v. Then we will use v to make a structure H in which  is satisﬁable
and  ̸|= ϕ because H will give a counterexample.
As in the example, the universe |H| is the Herbrand universe H, the
set of all terms in the language of . And again the function symbols
are interpreted autonymously: f H(t1, . . . , tn) = f t1 · · · tn. To interpret
a predicate symbol P we use the truth assignment v:
⟨t1, . . . , tn⟩∈PH ⇐⇒v(Pt1 · · · tn) = T
Then we claim that every formula in  is satisﬁed in H by the identity
function s(x) = x on the variables. First, note that s(t) = t for any term
t in H; we had the same situation in step 4 of the completeness proof
in Section 2.5. Secondly, note that for an atomic formula Pt1 · · · tn,
|=H Pt1 · · · tn[s] ⇐⇒⟨t1, . . . , tn⟩∈PH ⇐⇒v(Pt1 · · · tn) = T.
By Exercise 3 of Section 2.4 again, any formula δ in  is satisﬁed in H
with s (because v(δ) = T ).
Consider any formula in . It is a universal formula; to simplify the
notation, say it is ∀v1 ∀v2 θ(v1, v2, v3), where θ is quantiﬁer-free. We
need to check for any terms t1 and t2 in H that |=H θ[[t1, t2, v3]]. This
is equivalent (by the substitution lemma) to saying that the formula
θ(t1, t2, v3) is satisﬁed in H by s. But this formula is an instance of
∀v1 ∀v2 θ(v1, v2, v3), and so θ(t1, t2, v3) is in . As noted above, our
construction was arranged so that every formula in  is satisﬁed in H
with s. This is what we needed.
We can summarize the result as follows. For simplicity, the result is
stated only for sentences.
HERBRAND’S THEOREM
Consider a set ; ϕ of sentences in a ﬁrst-
order language without equality. Let  be as above. Then either
(caseI)isunsatisﬁableinsententiallogicand |= ϕ,or(caseII)
 is satisﬁable in sentential logic and the structure H constructed
above is a model of  in which ϕ is false.
(Herbrand’s work was in his 1930 dissertation, completed not long
before he was killed in a mountain-climbing accident. His statement of
the theorem was quite different from this one, but the ideas follow his
work, and 1928 work of Thoralf Skolem.)
In case I, by the compactness theorem of sentential logic, some ﬁnite
subset of  is unsatisﬁable. This fact can be used to obtain a proof of
the compactness theorem for ﬁrst-order logic, not relying on Section
2.5 or the deductive calculus of Section 2.4.
Moreover, a proof of the enumerability theorem, similarly indepen-
dent of Sections 2.4 and 2.5, can be extracted from the Herbrand ap-
proach. Take the special case  = ∅. If ϕ is valid then as we produce

294
A Mathematical Introduction to Logic
more and more of , at some point we will have an unsatisﬁable set,
a fact we can recognize by use of truth-tables. If ϕ is not valid, then
as we produce more and more of , we are making a structure in
which ϕ fails, but the structure is inﬁnite and the construction never
terminates.
Exercises
1. Prove the L¨owenheim–Skolem theorem in the following improved
form: Let A be a structure for a countable language. Let S be a
countable subset of |A|. Then there is a countable substructure B of
A with S ⊆|B| with the property that for any function s mapping
the variables into |B| and any (ﬁrst-order) ϕ,
|=A ϕ[s]
iff
|=B ϕ[s].
Suggestion: ChooseSkolemfunctionsforallformulas.Close S under
the functions. Remark: A substructure B with this property is said
to be an elementary substructure. Note that the property implies (by
taking ϕ to be a sentence) that A ≡B. On the one hand, this form
gives a stronger conclusion than we had in Section 2.6. Not only
do we get that Th A has some countable model, we get a countable
submodel. On the other hand, the proof uses the axiom of choice.
2. Extend the previous exercise to the uncountable case. Assume that A
is a structure for a language of cardinality λ. Let S be a subset of |A|
having cardinality κ. Show that there is an elementary substructure
B of A of cardinality at most κ + λ with S ⊆|B|.
3. Show that Corollary 42B is optimal in the following sense:
(a) Given any ∃1 sentence σ we can effectively decide whether or
not σ is satisﬁable.
(b) Given any ∀1 sentence σ we can effectively decide whether or
not σ is valid.
4. (a) State the two corollaries (analogous to 42A and 42B) described
at the end of this section.
(b) Supply proofs.
5. Repeat the example given for Herbrand expansions, but for the con-
verse: ∃y ∀x Pxy |= ∀x ∃yPxy. Show that in this case the set 
is unsatisﬁable in sentential logic.
6. Apply the method of Herbrand expansions to establish the following:
|= ∃x(Px →∀x Px).
7. Modify the Herbrand expansion construction to accomodate a lan-
guage with equality. Suggestion: In effect, step 5 of the completeness
proof in Section 2.5 must be added. Add enough universal sentences
to assure that {⟨t1, t2⟩| v(t1 = t2) = T is a congruence relation.

Chapter 4:
Second-Order Logic
295
SECTION 4.3
Many-Sorted Logic
We now return to ﬁrst-order languages, but with many sorts of variables,
ranging over different universes. (In the next section this will be applied
to the case in which one sort of variable is for elements of a universe,
another for subsets of that universe, yet another for binary relations, and
so forth.)
In informal mathematics one sometimes says things like, “We use
Greek letters for ordinals, capital script letters for sets of integers, . . . .”
In effect, one thereby adopts several sorts of variables, each sort having
its own universe. We now undertake to examine this situation precisely.
As might be expected, nothing is drastically different from the usual
one-sorted situation. None of the results of this section are at all deep,
and most of the proofs are omitted.
Assume that we have a nonempty set I, whose members are called
sorts, and symbols arranged as follows:
A. Logical symbols
0. Parentheses: (, ).
1. Sentential connective symbols: ¬, →.
2. Variables: For each sort i, there are variables v i
1, v i
2, . . . of
sort i.
3. Equality symbols: For some i ∈I there may be the symbol
=i, said to be a predicate symbol of sort ⟨i, i⟩.
B. Parameters
0. Quantiﬁer symbols: For each sort i there is a universal quan-
tiﬁer symbol ∀i.
1. Predicatesymbols:Foreachn > 0andeachn-tuple⟨i1, . . . , in⟩
of sorts, there is a set (possibly empty) of n-place predicate
symbols, each of which is said to be of sort ⟨i1, . . . , in⟩.
2. Constant symbols: For each sort i there is a set (possibly
empty) of constant symbols each of which is said to be of
sort i.
3. Function symbols: For each n > 0 and each (n + 1)-tuple
⟨i1, . . . , in, in+1⟩of sorts, there is a set (possibly empty) of
n-place function symbols, each of which is said to be of sort
⟨i1, . . . , in, in+1⟩.
As usual, we must assume that these categories of symbols are
disjoint, and further that no symbol is a ﬁnite sequence of other
symbols.
Each term will be assigned a unique sort. We deﬁne the set of terms
of sort i inductively, simultaneously for all i:

296
A Mathematical Introduction to Logic
1. Any variable of sort i or constant symbol of sort i is a term of
sort i.
2. If t1, . . . , tn are terms of sort i1, . . . , in, respectively, and f is a
function symbol of sort ⟨i1, . . . , in, in+1⟩then f t1 · · · tn is a term of sort
in+1.
This deﬁnition can be recast into a more familiar form. The set of
pairs ⟨t, i⟩such that t is a term of sort i is built up from (i.e., generated
from) the basic set
{⟨v i
n, i⟩| n ≥1 & i ∈I} ∪{⟨c, i⟩| c is a constant symbol of sort i}
by the operations that, for a function symbol f of sort ⟨i1, . . . , in, in+1⟩,
produce the pair ⟨f t1 · · · tn, in+1⟩from the pairs ⟨t1, i1⟩, . . . , ⟨tn, in⟩.
An atomic formula is a sequence Pt1 · · · tn consisting of a predicate
symbol of sort ⟨i1, . . . , in⟩and terms t1, . . . , tn of sort i1, . . . , in, respec-
tively. The nonatomic formulas are then formed using the connectives
¬, →and the quantiﬁers ∀i v i
n.
A many-sorted structure A is a function on the set of parameters
which assigns to each the correct type of object:
1. To the quantiﬁer symbol ∀i, A assigns a nonempty set |A|i called
the universe of A of sort i.
2. To each predicate symbol P of sort ⟨i1, . . . , in⟩, A assigns a
relation
PA ⊆|A|i1 × · · · × |A|in.
3. To each constant symbol c of sort i, A assigns a point cA in |A|i.
4. To each function symbol f of sort ⟨i1, . . . , in, in+1⟩, A assigns a
function
f A : |A|i1 × · · · × |A|in →|A|in+1.
The deﬁnitions of truth and satisfaction are the obvious ones, given
that ∀i is to mean “for all members of the universe |A|i of sort i.”
In a many-sorted structure, the universes of the various sorts might or
might not be disjoint. But since we have no equality symbols between
sorts, any nondisjointness must be regarded as accidental. In partic-
ular, there will always be an elementarily equivalent structure whose
universes are disjoint.
Reduction to One-Sorted Logic
Many-sorted languages may at times be convenient (as in the following
section). But there is nothing essential that can be done with them that
cannot already be done without them. We now proceed to make this
assertion in a more precise form.

Chapter 4:
Second-Order Logic
297
We will consider a one-sorted language having all the predicate,
constant, and function symbols of our assumed many-sorted language.
In addition, it will have a one-place predicate symbol Qi for each i in I.
There is a syntactical translation taking each many-sorted formula ϕ
into a one-sorted formula ϕ∗. In this translation all equality symbols are
replaced by =. The only other change is in the quantiﬁers (the quantiﬁer
symbols and the quantiﬁed variables): We replace
∀iv i
n
v i
n
by
∀v(Qiv →
v
),
where v is a variable chosen not to conﬂict with the others. Thus the
quantiﬁers of sort i are “relativized” to Qi. (The free variables are left
alone.)
Turning now to semantics, we can convert a many-sorted structure
A into a structure A∗for the above one-sorted language. The universe
|A∗| is the union 
i∈I |A|i of all the universes of A. To Qi is assigned
the set |A|i. On the predicate and constant symbols, A∗agrees with A.
For a function symbol f , the function f A∗is an arbitrary extension of
f A. (Of course this last sentence does not completely specify f A∗. The
results we give for A∗hold for any structure obtained in the manner just
described.)
LEMMA 43A
A many-sorted sentence σ is true in A iff σ ∗is true
in A∗.
To prove this, one makes a stronger statement concerning formulas:
|=A ϕ[s] ⇐⇒|=A∗ϕ∗[s]
where s(v i
n) ∈|A|i. The stronger statement is then proved by induction.
Consider now the other direction. A one-sorted structure is not al-
ways convertible into a many-sorted structure. So we will impose some
conditions. Let  be the set consisting of the following one-sorted
sentences:
1. ∃vQiv, for each i in I.
2. ∀v1 · · · ∀vn(Qiv1 →· · · →Qinvn →Qin+1 f v1 · · · vn), for each
function symbol f of sort ⟨i1, . . . , in, in+1⟩. We include the case n = 0,
in which case the above becomes the sentence Qic for a constant symbol
c of sort i.
Notice that the above A∗was a model of . A one-sorted model B
of  does convert into a many-sorted B♯. The conversion is performed

298
A Mathematical Introduction to Logic
in the natural way:
|B♯|i = QB
i ;
PB♯= PB ∩(QB
i1 × · · · × QB
in ), where P is a predicate symbol
of sort ⟨i1, . . . , in⟩
cB♯= cB;
f B♯= f B ∩(QB
i1 × · · · × QB
in × QB
in+1), the restriction of
f B to QB
i1 × · · · × QB
in , where f is a function symbol
of sort ⟨i1, . . . , in, in+1⟩.
LEMMA 43B
If B is a model of , then B♯is a many-sorted struc-
ture. Furthermore, a many-sorted sentence σ is true in B♯iff σ ∗
is true in B.
The proof is similar to the proof of Lemma 43A.
Notice that B♯∗is not in general equal to B. (For example, |B| may
contain points not belonging to any QB
i .) On the other hand, A∗♯is equal
to A.
THEOREM 43C
In the many-sorted language
 |= σ
iff in the one-sorted language
∗∪ |= σ ∗.
PROOF.
(⇒) Assume that  |= σ and let B be a one-sorted model
of ∗∪ (where ∗= {σ ∗| σ ∈}). Then B♯is a model of
 by Lemma 43B. Hence B♯is a model of σ. So by Lemma 43B
again, B is a model of σ ∗.
(⇐) Similar, with Lemma 43A.
⊣
By using Theorem 43C, we can now infer the following three theo-
rems from the corresponding one-sorted results.
COMPACTNESS THEOREM
If every ﬁnite subset of a set  of many-
sorted sentences has a model, then  has a model.
PROOF.
Assume that every ﬁnite subset 0 of  has a many-sorted
model A0. Then a ﬁnite subset ∗
0 of ∗has the model A∗
0. Hence
by the ordinary compactness theorem, ∗has a model B. B♯is
then a model of .
⊣
ENUMERABILITY THEOREM
For a recursively numbered many-sorted
language, the set of G¨odel numbers of valid sentences is recur-
sively enumerable.
PROOF.
For a many-sorted σ, we have by Theorem 43C,
|= σ
iff
 |= σ ∗.

Chapter 4:
Second-Order Logic
299
Since  is recursive, Cn  is recursively enumerable. And σ ∗
depends recursively on σ, so we can apply Exercise 7(b) of Sec-
tion 3.5.
⊣
L¨OWENHEIM–SKOLEM THEOREM
For any many-sorted structure (for a
countable language) there is an elementarily equivalent countable
structure.
PROOF.
Say that the given structure is A. Then A∗is a one-sorted
model of (Th A)∗∪. Hence by the ordinary L¨owenheim–Skolem
theorem, (Th A)∗∪ has a countable model B. B♯is a model of
Th A and so is elementarily equivalent to A.
⊣
SECTION 4.4
General Structures
We now return to the discussion of second-order logic begun in Sec-
tion 4.1. We discussed there (a) the syntax, i.e., the set of wffs for second
order, and (b) the semantics, i.e., the concept of structure (which was
the same as for ﬁrst order) and the deﬁnition of satisfaction and truth.
In this section we want to leave (a) unchanged, but we want to present
an alternative to (b). The idea can be stated very brieﬂy: We view the
language (previously thought of as second-order) now as being a many-
sorted elementary (i.e., ﬁrst-order) language. The result is to make open
to interpretation not only the universe over which individual variables
range but also the universes for the predicate and function variables. This
approach is particularly suited to number theory; that case is examined
brieﬂy at the end of this section.
The Many-Sorted Language
Despite the fact that we want ultimately to consider the grammar of Sec-
tion 4.1, it will be expedient to consider also a many-sorted (ﬁrst-order)
language constructed from the second-order language of Section 4.1.
We take ℵ0 sorts: the one individual sort (with variables v1, v2, . . .); for
each n > 0, the n-place predicate sort (with variables Xn
1, Xn
2, . . .); and
for each n > 0, the n-place function sort (with variables Fn
1, Fn
2, . . .).
We will use equality (=) only between terms of the individual sort.
The predicate and function parameters of our assumed second-order
language will also be parameters of the many-sorted language, and will
take as arguments terms of the individual sort. (For a function parameter
f , the term f ⃗t is of the individual sort. The only terms of predicate or
function sort are the variables of those sorts.)
In addition, we now use two new classes of parameters. For each
n > 0 there is a membership predicate parameter εn which takes as

300
A Mathematical Introduction to Logic
arguments one term of the n-place predicate sort (i.e., a variable Xn
m)
and n terms of the individual sort. Thus, for example,
ε3X3v2v1v8
isawff.Itsintendedinterpretationisthatthetripledenotedby⟨v2, v1, v8⟩
is to belong to the relation denoted by X3. This is exactly the interpre-
tation assigned previously to the second-order formula
X3v2v1v8,
and, in fact, readers are advised to identify these two formulas closely
in their minds.
For each n > 0, there is also the evaluation function parameter En.
En takes as arguments one term of the n-place function sort (i.e., a
variable Fn
m) and n terms of the individual sort. The resulting term,
EnFnt1 · · · tn,
is itself of the individual sort. Again readers are advised to identify
closely the term EnFnt1 · · · tn with the previous Fnt1 · · · tn.
There is an obvious way of translating between the second-order
language of Section 4.1 and the present many-sorted language. In one
direction we stick on the εn and En symbols; in the other direction we
take them off. The purpose of these symbols is to make the language
conform to Section 4.3.
A many-sorted structure has universes for each sort and assigns suit-
able objects to the various parameters (as described in the preceding
section). First, we want to show that without loss of generality, we may
suppose that εn is interpreted as genuine membership and En as genuine
evaluation.
THEOREM 44A
Let A be a structure for the above many-sorted lan-
guage such that the different universes of A are disjoint. Then
there is a homomorphism h of A onto a structure B such that
(a) h is one-to-one, in fact the identity, on the individual uni-
verse (from which it follows that
|=A ϕ[s]
iff
|=B ϕ[h ◦s]
for each formula ϕ).
(b) The n-place predicate universe of B consists of certain n-
ary relations over the individual universe, and ⟨R, a1, . . . , an⟩is
in εB
n iff ⟨a1, . . . , an⟩∈R.
(c) The n-place function universe of B consists of certain
n-place functions on the individual universe, and EB
n ( f, a1, . . . ,
an) = f (a1, . . . , an).
PROOF.
Since the universes of A are disjoint, we can deﬁne h on one
universe at a time. On the individual universe U, h is the identity.

Chapter 4:
Second-Order Logic
301
On the universe of the n-place predicate sort,
h(Q) = {⟨a1, . . . , an⟩| each ai is in U and
⟨Q, a1, . . . , an⟩is in εA
n }.
Thus
⟨a1, . . . , an⟩∈h(Q)
iff
⟨Q, a1, . . . , an⟩is in εA
n .
(1)
Similarly, on the universe of the n-place function sort,
h(g) is the n-place function on U whose value at
⟨a1, . . . , an⟩is EA
n (g, a1, . . . , an).
Thus
h(g)(a1, . . . , an) = EA
n (g, a1, . . . , an).
(2)
For εB
n we take simply the membership relation,
⟨R, a1, . . . , an⟩is in εB
n
iff
⟨a1, . . . , an⟩∈R.
(3)
For EB
n we take the evaluation function,
EB
n ( f, a1, . . . , an) = f (a1, . . . , an).
(4)
On the other parameters (inherited from the second-order lan-
guage) B agrees with A.
Then it is clear upon reﬂection that h is a homomorphism of
A onto B. That h preserves εn follows from (1) and (3), where in
(3) we take R = h(Q). Similarly, from (2) and (4) it follows that
h preserves En.
Finally, we have to verify the parenthetical remark of part (a).
This follows from the many-sorted analogue of the homomor-
phism theorem of Section 2.2, by using the fact that we have
equality only for the individual sort, where h is one-to-one.
⊣
By the above theorem, we can restrict attention to structures B in
which εn and En are ﬁxed by (b) and (c) of the theorem. But since εB
n
and EB
n are determined by the rest of B, we really do not need them
at all. When we discard them, we have a general pre-structure for our
second-order grammar.
General Structures for Second-Order Languages
These structures provide the alternative semantics mentioned at the be-
ginning of this section.
DEFINITION.
A general pre-structure A for our second-order lan-
guage consists of a structure (in the original sense), together with
the additional sets:
(a) For each n > 0, an n-place relation universe, which is a
set of n-ary relations on |A|;

302
A Mathematical Introduction to Logic
(b) For each n > 0, an n-place function universe, which is a
set of functions from |A|n into |A|.
A is a general structure if, in addition, all comprehension sen-
tences are true in A.
The last sentence of the deﬁnition requires explanation. First, a com-
prehension sentence is a sentence obtained as a generalization of a
comprehension formula (see Example 3 of Section 4.1). Thus it is a
generalization of
∃Xn ∀v1 · · · ∀vn(Xnv1 · · · vn ↔ϕ),
where Xn does not occur free in ϕ, or a generalization of
∀v1 · · · ∀vn ∃!vn+1 ψ→
∃Fn ∀v1 · · · ∀vn+1(Fnv1 · · · vn = vn+1 ↔ψ),
where Fn does not occur free in ψ. (Here ϕ and ψ can have individual
variables, predicate variables, and function variables.)
Next we must say what it means for a comprehension sentence (or
any second-order sentence for that matter) to be true in A. Assume then
that A is a general pre-structure. Then a sentence σ is true in A iff the
result of converting σ into a many-sorted sentence (by adding εn and
En) is true in A, with εn interpreted as membership and En as evaluation.
More generally, let ϕ be a second-order formula, and let s be a func-
tion that assigns to each individual variable a member of |A|, to each
predicate variable a member of the relation universe of A, and to each
function variable a member of the function universe of A. Then we say
that A satisﬁes ϕ with s (written |=G
A ϕ[s]) iff the many-sorted version
of ϕ is satisﬁed with s in the structure A, where εn is interpreted as
membership and En as evaluation.
The essential consequences of this deﬁnition of satisfaction are the
following, which should be compared with 5 and 6 of page 283.
|=G
A ∀Xn ϕ[s]
iff for every R in the n-place relation
universe of A, |=G
A ϕ[s(Xn | R)].
|=G
A ∀Fn ϕ[s]
iff for every f in the n-place relation
universe of A, |=G
A ϕ[s(Fn | f )].
This, then, is the alternative approach mentioned at the beginning
of the section. It involves treating the second-order grammar as being
a many-sorted ﬁrst-order grammar in disguise. Because this approach
is basically ﬁrst-order, we have the L¨owenheim–Skolem theorem, the
compactness theorem, and the enumerability theorem.
L¨OWENHEIM–SKOLEM THEOREM
If the set  of sentences in a count-
able second-order language has a general model, then it has a
countable general model.

Chapter 4:
Second-Order Logic
303
Here a countable general model is one in which every universe is
countable (or equivalently, the union of all the universes is countable).
PROOF.
Let  be the set of comprehension sentences. Then  ∪,
viewed as a set of many-sorted sentences, has a countable many-
sorted model by the L¨owenheim–Skolem theorem of the pre-
ceding section. By Theorem 44A, a homomorphic image of that
model is a general pre-structure satisfying  ∪, and hence is a
general model of .
⊣
COMPACTNESS THEOREM
If every ﬁnite subset of a set  of second-
order sentences has a general model, then  has a general model.
PROOF.
The proof is exactly as above. Every ﬁnite subset of  ∪
has a many-sorted model, so we can apply the compactness the-
orem of the preceding section.
⊣
ENUMERABILITY THEOREM
Assume that the language is recursively
numbered. Then the set of G¨odel numbers of second-order
sentences that are true in every general structure is recursively
enumerable.
PROOF.
A sentence σ is true in every general structure iff it is a
many-sorted consequence of . And ♯ is recursive.
⊣
The above two theorems assure us that there is an acceptable deduc-
tive calculus such that τ is deducible from  iff τ is true in every general
model of  (see the remarks at the beginning of Section 2.4). But now
that we know there is such a complete deductive calculus, there is no
compelling reason to go into the detailed development of one.
We can compare the two approaches to second-order semantics as
follows: The version of Section 4.1 (which we will now call absolute
second-order logic) is a hybrid creature, in which the meaning of the
parameters is left open to interpretation by structures, but the concept of
being (for example) a subset is not left open, but is treated as having a
ﬁxed meaning. The version of the present section (general second-order
logic) avoids appealing to a ﬁxed notion of subset, and consequently is
reducible to ﬁrst-order logic. In this respect it is like axiomatic set theory,
where one speaks of sets and sets of sets and so forth, but the theory is
a ﬁrst-order theory.
By enlarging the class of structures, general second-order logic di-
minishes the cases in which logical implication holds. That is, if every
general model of  is a general model of σ, it then follows that  |= σ
in absolute second-order logic. But the converse fails. For example,
take  = ∅: The set of sentences true in all general models is a recur-
sively enumerable subset of the nonarithmetical set of valid sentences
of absolute second-order logic.

304
A Mathematical Introduction to Logic
Models of Analysis
We can illustrate the ideas of this section by focusing attention on the
most interesting special case: general models of second-order number
theory.Considerthenthesecond-orderlanguagefornumbertheory,with
the parameters 0, S, <, ·, and E. We take as our set of axioms the set A2
E
obtained from AE by adding as a twelfth member the Peano induction
postulate (Example 2, Section 4.1). From Exercise 1 of Section 4.1, we
can conclude that any model (in the semantics of that section) of A2
E is
isomorphic to N.
But what of the general models of our axiom set? They can differ
from N in either (or both) of two ways. We can employ the compact-
ness theorem as before to construct (nonstandard) general models of the
axioms having inﬁnite numbers (i.e., models A with an element larger
than the denotation of Sn0 in the ordering <A). We can also ﬁnd (non-
absolute) general models in which, for example, the set universe (the
unary relation universe) is less than the full power set of the individual
universe. Indeed, any countable general model must be of this kind.
It is traditional for logicians to refer to second-order number theory
as analysis. The name derives from the fact that it is possible to identify
real numbers with sets of natural numbers. In second-order number
theory we have quantiﬁers over sets of natural numbers, which we can
view as quantiﬁers over real numbers. The appropriateness of the name
is nevertheless open to question, but its usage is well established. By
a model of analysis we will mean a general model of the above axiom
set A2
E.
Deﬁne an ω-model of analysis to be a model of analysis in which
the individual universe is N and the denotations of 0 and S are the
genuine 0 and S. (Consequently, the denotations of <, +, ·, and E are
also standard.) The motivation for studying ω-models can be stated as
follows: We have a clear understanding — or so we think — of the set N.
But we do not have anything like the same understanding of its power
set PN. For example, we may be uncertain whether its cardinality is ℵ1
or ℵ2 or more. So it is reasonable to hold ﬁxed that which we are sure
of (N), but to leave open to interpretation by a structure that which we
are not sure of (PN).
Among the ω-models of analysis there is the one absolute model,
whose n-place relation universe consists of all n-ary relations on N (and
whose function universes consist of all possible functions). A ﬁrst-order
sentence is true in an arbitrary ω-model of analysis iff it is true in N.
But the ω-model may disagree with the absolute model on second-order
sentences.
In the next theorem we assert that an ω-model of analysis is com-
pletely determined by its set universe (i.e., its one-place relation uni-
verse).

Chapter 4:
Second-Order Logic
305
THEOREM 44B
If A and B are ω-models of analysis having the same
one-place relation universe, then A = B.
PROOF.
Suppose R belongs to the three-place relation universe of
A. Let ⟨R⟩be the “compression” of R into a unary relation:
⟨R⟩= {⟨a, b, c⟩| ⟨a, b, c⟩∈R}.
Our sequence-encoding function is recursive and hence is ﬁrst-
order deﬁnable in number theory by a formula ϕ. ⟨R⟩is in the set
universe of A by virtue of the comprehension sentence
∀X3 ∃X1 ∀u[X1u ↔∃v1 ∃v2 ∃v3(ϕ(v1, v2, v3, u)
∧X3v1v2v3)].
Thus ⟨R⟩is in the set universe of B; we unpack it by a similar
argument. R is in the three-place relation universe of B by virtue
of the comprehension sentence
∀X1∃X3 ∀v1 ∀v2 ∀v3[X3v1v2v3 ↔
∃u(ϕ(v1, v2, v3, u) ∧X1u)].
A similar argument applies to the function universes.
⊣
Consequently, we can identify an ω-model of analysis with its set
universe (which is included in PN). Not every subclass of PN is then
an ω-model of analysis, but only those for which the comprehension
sentences are satisﬁed.
EXAMPLES OF ω-MODELS.
We need only specify the set universe.
1. PN is the absolute model.
2. Let (A; ∈A) be a model of the usual axioms for set theory
such that (i) the relation ∈A is the genuine membership relation
{⟨a, b⟩| a ∈A, b ∈A, and a ∈b} on the universe A, and
(ii) A is transitive, i.e., if a ∈b ∈A, then a ∈A. Then the
collection of all those subsets of N that belong to A is an ω-model
of analysis.
3. For a class A ⊆PN, deﬁne DA to be the class of all sets
B ⊆N which are deﬁnable in the ω pre-structure with set uni-
verse A by a formula of the language of second-order number
theory, augmented by parameters for each set in A. Then deﬁne
by transﬁnite recursion on the ordinals:
A0 = ∅,
Aα+1 = DAα,
Aλ = 
α<λ Aα
for limit λ.
By cardinality considerations we see that this stops growing
at some ordinal β for which Aβ+1 = Aβ. Let β0 be the least

306
A Mathematical Introduction to Logic
such β; it can be shown (from the L¨owenheim–Skolem theorem)
that β0 is a countable ordinal. Aβ0 coincides with 
α Aα (the
union being over all ordinals α) and is called the class of rami-
ﬁed analytical sets. It is an ω-model of analysis; the truth of the
comprehension sentences follows from the fact that DAβ0 ⊆Aβ0.

Suggestions for Further
Reading
Jon Barwise (editor). Handbook of Mathematical Logic. North-Holland
Publishing Company, Amsterdam, 1978. This “handbook” collects
31 expository articles on model theory, set theory, recursion theory,
and proof theory, written by experts.
Jon Barwise and John Etchemendy. The Language of First-Order Logic.
Center for the Study of Language and Information, Stanford, 1992.
This introductory textbook comes with a disk for the Tarski’s World
software package. The same authors have produced the Turing’s
World and Hyperproof software packages.
J. L. Bell and M. Machover. A Course in Mathematical Logic. North-
Holland Publishing Company, Amsterdam, 1977.
George Boolos and Richard Jeffrey. Computability and Logic.
Cambridge University Press, Cambridge, 1974 (third edition 1989).
This textbook gives a lively treatment of some of topics in the present
book, addressed to a different audience.
C. C. Chang and H. J. Keisler. Model Theory. North-Holland Publishing
Company, Amsterdam, 1973 (third edition 1990). This remains the
classic book on model theory.
Herbert B. Enderton. Elements of Set Theory. Academic Press, New
York, 1977. This is the author’s favorite book on set theory.
Wilfrid Hodges. A Shorter Model Theory. Cambridge University Press,
Cambridge, 1997. This is a shorter version of his Model Theory,
published in 1993.
Hartley Rogers. Theory of Recursive Functions and Effective Com-
putability. McGraw-Hill Book Company, New York, 1967. This book
is still the standard work in its ﬁeld.
Joseph R. Shoenﬁeld. Mathematical Logic. Association for Symbolic
Logic and A K Peters, Natick, Massachusetts, 2000. First published
by Addison-Wesley in 1967, the book gives a compact graduate-level
treatment.
307

308
A Mathematical Introduction to Logic
Jean van Heijenoort (editor). From Frege to G¨odel: A Source Book
in Mathematical Logic, 1879–1931. Harvard University Press,
Cambridge, Massachusetts, 1967. This is a collection of 46 fun-
damental papers in logic, translated into English and supplied with
commentaries.

List of Symbols
The numbers indicate the pages on which the symbol ﬁrst
occurs.
∈
1
⊣
1
vn
68
/∈
1
⇒
1
=
69
=
1
⇐
1
0
70, 182
A; t
1
⇔
1
S
71, 182
∅
2
∴
1
<
70, 182
{x1, . . . , xn}
2
̸|=
1
+
71, 182
{x|
x
}
2
¬
11
·
71, 182
N
2
→
11
E
71, 182
Z
2
∧
11
F f
74
⊆
2
∨
12
Qi
75
P
2
↔
14
̸=
1, 78
∪
3
E
17
̸<
78
∩
3
F
20
|A|
81

3
T
20
c21
81

3
v
20
|=A ρ[s]
83
⟨x1, . . . , xn⟩
4
|=
1
§
83
A × B
4
|==
24
s(x|d)
84
dom R
4
D
32
|=
88
ran R
4
#
45
|==|
88
ﬂd R
4
Bn
α
46
Mod
92
An
5
⊥
50
EC
92
F : A →B
5
⊤
50
EC
92
[X]
5
↓
51
|=A ϕ[[a1, . . . , ak]]
90
A ∼B
8
|
51
A ∼= B
94
card A
8
+
51
h ◦s
96
⪯
8
⋆
62
A ≡B
97
ℵ
9
∀
68
Q
98
R
9
∃
68, 77
∀n
00
309

310
List of Symbols
∃n
00
Sk0
183
∃
225
∃!
102
♯α
184
∀
225

110
G
184
Sb
228
⊢
110
S4n
188
♮
230
αx
t
112
AS
188
n
242
̸⊢
121
AL
194
Q2a
113
≤
194
n
242
Eqn
114
̸≤
194
ST
270
Ax
122
Ln
194
AM
276
T
122
∧i
195
Tm
249
gen
122
≡n
197
U
249
MP
122
≡n
197
[[e]]m
252
ded
122
∨i
00
K
254
RAA
122
AE
203
We
255
Th
152
An
203
ρ
258
Cn
155
Mn
203
Xn
i
282
AST
161
En
203
Fn
i
283
ϕ(t1, . . . , tn)
167
I m
i
214
Qi
297
πS
168
μb−
216
A∗
297
πB
168
K R
217
B♯
297
π−1[T1]
168
pn
219

297
ϕπ
169
⟨a0, . . . , am⟩
220
εn
299
∗A
00
(a)b
220
En
300
F
175
lh
221
|=G
A ϕ[s]
302
I
176
a ↾b
221
⟨R⟩
305
≃
177
f
221
DA
305
st
178
a ∗b
222
R see pp. 182–192
182
∗
223

Index
A
Abbreviations, 1
Absolute model, 304, 305
Absolute second-order logic,
303
Adjoining, 2
Algebraically closed ﬁelds,
158–159
Algebraic numbers, 10
Algorithm, 61
Alphabetic variants, 126–127
Analysis, models of, 304–306
Analysis, nonstandard. See
Nonstandard analysis
Arithmetic. See Number
theory
Arithmetical hierarchy,
242–245
Arithmetical relations, 100,
242
Arithmetization of syntax,
224–234
Asser, G¨unter, 101
Atomic formulas, 74–75, 83
Automorphism, 98–99
Axiomatizable theory,
156–157
Axioms, logical. See Logical
axioms
B
Berkeley, George, 173
Biconditional symbol, 14
Binary connectives, 51
Bolzano–Weierstrass
theorem, 181
Boolean algebra, 20
Boolean functions, 45–52
Bounded quantiﬁers, 204,
210–211
Bound variables, 80
Bridge circuit, 57
C
Calculus, deductive. See
Deductive calculus
Cantor, Georg, 8
Cantor’s theorem, 159, 163
Capital asterisk operation,223
Cardinal arithmetic theorem,
9–10
Cardinality of languages, 141
Cardinality of structures,
153–154, 157
Cardinal numbers, 8–10
Carroll, Lewis, 162
Cartesian product, 4
Categorical sets, 154, 157
Categoricity in power, 157
Chain, 7
Chain rule, 180
Characteristic function, 217
Chinese remainder theorem,
91, 279
Church’s theorem, 145,
164, 238
Church’s thesis, 185, 187,
206–210, 233–234, 240,
247
Circuits, switching, 54–59
Closed, 5, 18, 35, 111
Compactness theorem
history of, 145
in ﬁrst-order logic, 109,
142, 293
in many-sorted logic, 298
in second-order logic, 285,
303
in sentential logic, 24,
59–60
Completeness theorem, 66,
135–145
Complete sets of connectives,
49
Complete theory, 156
Composition, 5, 215–216
Comprehension formulas,
284
Computability approach to
incompleteness, 184,
187, 257–258
Computable, 65, 208–209
Computable functions,
209–210, 250–251
See also Recursive
functions
Computably enumerable
(c.e.), 238
Computing agents, idealized,
208, 261–263
Concatenation function,
222–223
Conditional sentence, 21
Conditional symbol, 14
Congruence relation, 140
Conjunction symbol, 14
311

312
Index
Conjunctive normal form
(CNF), 53
Connectives. See Sentential
connectives
Consequences, set of, 155
Consequent, 113
Consistent sets, 119, 135
Constants, generalization on,
123–124
Constant symbols, 70, 79
Construction sequences,
17–18, 35–37, 111
Contraposition, 27, 119, 121
Convergence, 178–180
Countable language, 135,
145, 151–153
Countable sets, 6
C++, 13
Craig’s theorem, 163
D
D’Alembert, Jean, 173
Decidable sets, 62–63,
144, 185
See also Church’s thesis
Decidable theory, 144, 157
See also Undecidability
Decoding function, 220
Deducible formulas, 111
Deductions, 66, 110–112
Deduction theorem,
118–120
Deductive calculus, 66, 109
alphabetic variants,
126–127
equality, 127–128
formal deductions,
110–112
metatheorems and,
116–120
strategy, 120–126
substitution, 112–114
tautologies, 114–116
Deﬁnability
in a structure, 90–92
of a class of structures,
92–94
Deﬁnable element, 91
Deﬁnable relations, 90–92,
98, 287
from points, 103
Deﬁned function symbols,
164–166, 169, 172
Deﬁnition by recursion,
38–44
Delay of circuit, 56
De Morgan’s laws, 27, 49
Dense order, 159
Depth of circuit, 56
Derivability conditions, 267
Descriptions. See Deﬁned
function symbols
Diagonal function, 264
Diagonalization approach to
incompleteness, 184,
186–187, 245–246
Directed graphs (digraphs),
82, 93
Disjoint set, 3
Disjunction symbol, 14
Disjunctive normal form
(DNF), 49
Divisibility, 218
Domain
of relation, 4
of structure, 81
Dominance, 8–9
Donkey sentences, 80
Double negation, 89
Dovetailing, 64
Duality, 28
E
Effective computability, 65
See also Recursive
functions
Effective enumerability,
63–66
See also Recursively
enumerable relations
Effective procedures, 61–65
See also Church’s thesis
Elementarily closed (ECL),
104
Elementary class (EC, EC),
92–93
Elementary equivalence, 97
Elementary substructure, 294
Elementary type, 104
Eliminable deﬁnition, 172
Elimination of quantiﬁers,
190–192
Entscheidungsproblem, 164
Enumerability theorem, 109,
142–143, 145, 293
in many-sorted logic, 298
in second-order logic, 286,
303
Equality, 1–2, 127–128
language of, 246, 285
Equality symbol, 70
Equinumerous, 8
Equivalence classes and
relations, 6, 189
Euler, Leonhard, 5, 173
Evaluation function
parameter, 300
Eventually periodic set, 201
Excluded middle, 27
Exclusive disjunction, 51
Existential formula (∃1), 102,
205
Existential instantiation (rule
EI), 124–125, 145
Existential quantiﬁers, 67, 87,
287, 288
Exponential growth, 26
Exponentiation,
representation of,
276–281
Exportation, 27
Expressions, 15–16, 73–74
Extension, 95
Extensionality, principle of, 2
F
Faithful interpretations,
171–172
Falsity, 20
Field (of relation), 4
Fields, 87, 92, 93–94, 285
real-closed, 104
theory of, 155–156,
158–159
See also Algebraically
closed ﬁelds
Finite graphs, 93
Finite language, 142
Finitely axiomatizable
theories, 156
Finitely valid, 147
Finite model property, 163
Finite models, 147–151

Index
313
Finite sequence (string), 4
Finite set, 6
First-order language, 67–72,
167
examples of, 70–73
formulas, 73–76
free variables, 76–77
notation, 77–79
First-order logic
completeness theorem,
135–145
deductive calculus,
109–129
interpretations between
theories, 164–172
language of, 69–79
models of theories,
147–162
parsing algorithm,
105–108
soundness theorem,
131–135
translation methods, 68–69
truth and models, 80–99
Fischer, Michael, 201
Fixed-point lemma, 234–235
Formal languages, 11–13
computer, 13
features in, 11–13
sentential logic and, 13–19
Formula-building operations,
17, 75
Formulas
atomic, 74–75, 83
comprehension, 284
generalization of, 116
satisfaction of, 83–86
unique readability of,
40–41, 108
well-formed (wffs), 12,
17–18, 75
Freely generated sets, 39–40
See also Unique readability
theorem
Free variables, 76–77
Frege, Gottlob, 152
Function comprehension
formulas, 284
Functions, 5
deﬁning, 164–166
recursive, 247–263
representable, 212–217
Skolem, 145, 287–290
Function symbols, 70,
79, 128
Function universe, 302
Function variables, 282
G
Generalization
on constants, 123–124
of formulas, 112
Generalization theorem,
117–118
General pre-structure, 301
General second-order logic,
303
General structures,
299–306
Generated sets, 37
freely, 39
G¨odel, Kurt, 145, 152
β-function, 278–279, 281
completeness theorem,
135–145
incompleteness theorem,
145, 236, 256, 257–258
numbers, 91, 184,
225–234, 286
second incompleteness
theorem, 266–270,
274–275
Goldbach’s conjecture, 263
Graphs, 92
connected, 146
directed, 82, 93
ﬁnite, 93
of function, 209
Groups, 38, 92
H
Halting problem,
unsolvability of, 254
Henkin, Leon, 145
Herbrand expansions,
290–294
Herbrand, Jacques, 293
Herbrand’s theorem, 293
Herbrand universe, 291
Heterological, 186
Hilbert, David, 152
Homomorphisms, 94–99
Homomorphism theorem,
96–97
Hyperreal numbers. See
Nonstandard analysis
Hypothesis, 23, 67, 109, 213
I
Identity function, 5
Identity interpretation, 168
Iff, use of, 1
Implicant, 59
Implicitly deﬁnable relations,
287
Incompleteness theorem
(G¨odel)
ﬁrst, 145, 236, 256,
257–258
second, 266–270, 274–275
undecidability and,
234–245
Inconsistent sets, 119
Inconsistent sets. See
Consistent sets
Independent axiomatizations,
28
Index
of recursively enumerable
set, 255
of recursive partial
function, 253
Individual variables, 282–283
Induction, 30, 34–38
principle, 18–19, 37, 44,
111–112
Inductive sets, 35
Induction axiom. See Peano
induction postulate
Inﬁnitely close, 177
Inﬁnitesimal, 176
Initial segment, 4
Input/output format, 62, 209
Instances, 291
Integers, 2
Interpolation theorem, 53
Interpretations, 80
between theories,
164–172, 273
Intersection, 3
Isomorphic embedding, 94
Isomorphic structures, 94
Isomorphism, 94

314
Index
K
Kleene normal form,
249–250, 252–254, 257
Kleene’s theorem, 64, 239
L
Lagrange’s theorem, 166
Languages
many-sorted, 299–301
of equality, 285
See also First-order
languages, Formal
languages, Second-order
logic
Least-zero operator, 216,
220–221
Leibniz, G. W. v., 173
Length, 221
Lindenbaum’s theorem, 246
Linear connectives, 52
Linear transformations, 99
Literal, 59
L¨ob’s theorem, 269
Logical axioms, 110, 112,
125
recursiveness of, 232
validity of, 131–134
Logical implication, 88–99
Logically equivalence, 88
Logical symbols, 14,
69–70
Ło´s–Vaught test, 157–160,
190
L¨owenheim, Leopold, 151
L¨owenheim–Skolem
theorem, 103, 151–155,
190
in many-sorted logic, 299
in second-order logic, 285,
302–303
LST theorem, 154
Łukasiewicz, Jan, 33
See also Polish notation
M
Majority connective, 45
Mal´cev, Anatolii, 145
Many-one reducibility, 256
Many-sorted logic, 295–299
application to second-order
logic, 299–301
Many-valued logic, 20
Map, 5
Map coloring, 65, 146
Material conditional, 21
Membership predicate,
299–300
Meta-language, 89, 129
Metamathematics, use of
term, 69
Metatheorems, 116–120
Models, 80–99
of analysis, 304–306
of theories, 147–162
Modus ponens, 66, 110–111,
116
Monotone connectives, 54
Monotone recursion, 224
μ-operator, 216, 220–221
N
Nand, 51
Natural numbers, 2
See also Number theory
Negation symbol, 14, 17
Newton, Isaac, 173
Nonlogical symbols, 14
Nonprime formulas, 114
Nonstandard analysis,
173–181
algebraic properties,
176–178
construction of hyperreals,
173–176
convergence in, 178–180
Nonstandard models,
152–153, 183, 304
Normal form theorem,
for recursive functions,
252–253
Skolem, 288–289
Notation, 77–79
NP, 26, 101
Number theory, 182
language of, 70, 72, 182
with addition, 196–197,
280
with exponentiation,
202–205, 280
with multiplication,
276–281
with ordering, 193–196,
280
with successor, 187–193,
280
Numerals, 183–184, 209
Numeralwise determined
formulas, 206,
210–212
O
Object language, 89
Occur free, 76–77
ω-completeness, 223
ω-consistency, 241, 245
ω-models of analysis,
304–306
One-sorted logic, 296–299
One-to-one functions, 5
Onto, 5
Operating system, 253
Operations, 5
Ordered n-tuples, 3–4
Ordered pairs, 3, 4
Ordering relations, 6, 93, 159,
284
P
Pairing function, 220,
277–278
Pairwise disjoint set, 3
Parameters, 14, 70
Parameter theorem, 258–260,
264
Parentheses, use of, 33, 78
Parity connective, 53
Parsing algorithm
in ﬁrst-order logic,
105–108
in sentential logic, 29–33
Parsing formulas, 29–33,
107–108
Parsing terms, 106–107
Partial functions, 250
Partial recursive functions.
See Recursive functions,
partial
Partition, 6

Index
315
Peano arithmetic (PA),
269–270
Peano induction postulate,
193, 284, 286–287
Periodic set, 201
Permutation, 100
Polish notation, 32–33, 74
Polynomial-time decidable,
26, 115
Post, Emil, 47, 152, 261
Power set, 2–3
Predicate calculus. See
First-order logic
Predicate symbols, 70, 79,
128
Predicate variables, 282
Prenex formulas, 160
Prenex normal form, 160–161
Presburger’s theorem,
197–198
Prime formulas, 114–115
Prime implicants, 59
Prime numbers, 91, 184,
218–219
Primitive recursion, 221–222,
227
Principia Mathematica
(Whitehead and
Russell), 152
Proof, nature of, 109
See also Deductive
calculus
Propositional logic, 14
Proposition symbol, 14–15
Q
Quantiﬁer capture, 113
Quantiﬁers, 70
bounded, 204, 210–211
elimination of, 190–192
existential, 287, 288
Quantiﬁer symbol, universal,
80
Quotient structure, 140
R
Rabin, Michael, 201
Ramiﬁed analytical sets, 306
Range (of relation), 4
Reasonable language,
142–144
See also Recursively
numbered language
Recursion, 32, 38–44
monotone, 224
primitive, 221–222, 227
Recursion theorem, 39–40,
41–42
Recursive functions, 247–250
normal form, 248–250
partial, 250–258, 262
reduction of decision
problems, 258–260
register machines, 261–263
Recursively axiomatizable
theories, 233, 240
Recursively enumerable
(r.e.) relations, 233,
238–241
Recursively inseparable sets,
245
Recursively numbered
language, 225
Recursive relations, 207–210,
232
See also Recursively
enumerable relations
Reductio ad absurdum, 119,
121
Reducts of number theory,
182–183, 193–202
Reﬂexive relations, 5
Register machines, 208,
261–263
Relation comprehension
formulas, 284
Relations, 4–6
Relation universe, 301
Relay circuits, 57
Representable functions,
212–217
Representable relations,
205–206
and numeralwise
determined formulas,
206, 210–212
weakly, 241–242
Re-replacement lemma, 130
Resolution, 53
Restriction, 5, 221
Rice’s theorem, 260
Rigid structure, 98
Robinson, Abraham, 173
Root of tree, 7
Rule EI, 124–125, 145
Rules of inference, 110
Rule T, 118
S
Satisfaction of formulas, 23,
83–86
Satisﬁable sets, 59–60, 134
Schema, 286
Schr¨oder–Bernstein theorem,
9
Second-order logic
absolute, 303
and many-sorted logic,
295–299
general structures,
299–306
language of, 282–286
Skolem functions, 145,
287–290
Segments of sequences, 4
initial, 4
terminal, 105–106
Self-reference, 234–235, 315
approach to
incompleteness,
184–186
Semantics and syntax, 125
Semidecidable set, 63
Semidecision procedure, 63
Sentences, 77, 79
Sentence symbols, 14, 115
Sentential connectives, 14,
45–54
binary, 51
ternary, 51–52
unary, 51
0-ary, 50
Sentential logic
compactness, 24, 59–60
connectives, 45–52
language of, 13–19
parsing algorithm, 29–33
tautologies, 23
truth assignments, 20–27
Sequence encoding and
decoding, 220, 277, 281
Sequence number, 221
Sequences, ﬁnite, 4

316
Index
Sets
concept, 1–2
countable, 6
disjoint, 3
empty versus nonempty, 2
ﬁnite, 6
intersection of, 3
ordered, 93
pairwise disjoint, 3
power, 2–3
union of, 3
Set theory (ST) 152, 157,
161–162, 240–241,
270–275
G¨odel incompleteness
theorems for, 274–275
language of, 70, 71
Sheffer stroke, 51
Shepherdson, John C., 261
Shepherdson–Sturgis
machines, 261–263
Simpliﬁcation of formulas, 59
Single-valued relations, 5
Skolem, Thoralf, 145, 151,
293
functions, 145, 287–290
L¨owenheim–Skolem
theorem, 151–155
normal form, 288–289
paradox, 152
S-m-n theorem. See
Parameter theorem
Soundness theorem, 66, 131
Spectrum, 101, 150, 285
Standard part, 178
Steinitz’s theorem, 158–159
Strategy for deductions,
120–126
String, 4
Strong undecidability, 237,
272–273
Structures, 80–81
cardinality of, 153–154
deﬁnability in, 90–92
deﬁnability of a class of,
92–94
general, 299–306
Sturgis, H. E., 261
Subsets, 2
Substitutability, 113
Substitution, 28, 112–114
and alphabetic variants,
126
lemma, 133–134
of terms, 112, 129
representability of, 228
Substructures, 95–96, 294
Sufﬁciently strong theory,
246, 267
Switching circuits, 54–59
Symbols
logical, 14, 69–70
nonlogical, 14
parameter, 71
sentential connective, 14,
45–54
Symmetric relations, 5
Syntactical translation,
169–172
Syntax, arithmetization of,
224–234
Syntax and semantics, 125
T
Tarski, Alfred, 152, 154, 159,
286
undeﬁnability theorem,
236, 240
Tautological equivalence, 24
Tautological implication, 23
Tautologies, 23
in ﬁrst-order languages,
114–116
representability of,
230–231
selected list of, 26–27
Term-building operations, 74
Terminal segment, 105–106
Terms, 74, 79
parsing, 106–107
representing, 226–227
unique readability of, 107
Ternary connectives, 51–52
Theorem, concept of,
110–111, 117
Theories, 155–160
axiomatizable, 156
ﬁnitely axiomatizable, 156
interpretations between,
164–172
models of, 147–162
of structures, 148, 152, 155
Total function, 250
T -predicate, 249
Trakhtenbrot’s theorem, 151
Transitive relations, 5
Trees, 7
of deduction, 116–117
of well-formed formulas,
17, 22, 75
Trichotomy, 6, 93, 159, 194
Truth, 20
undeﬁnability of, 236, 240
Truth and models, in
ﬁrst-order logic, 80–99
Truth assignments, 20–27
Truth tables, 24–26
Truth values, 20
Turing, Alan, 208, 261
Turing machine, 208
Two-valued logic, 20
Tychonoff’s theorem, 24
U
Ultraproducts, 142
Unary connectives, 51
Uncountable languages, 141,
153–154
Undecidability
incompleteness and,
234–235
of number theory, 182–187
of set theory, 272
strong, 237, 272–273
Undeﬁnability theorem,
Tarski, 236, 240
Union, 3
Unique existential quantiﬁer,
102, 165
Unique readability theorem
for formulas, 108
for terms, 107
in sentential logic, 40–41
Universal formulas (∀1), 102
Universal quantiﬁer symbol,
68, 70, 80
Universe, of structures, 81
Unsolvability of halting
problem, 254
V
Valid formula, 88–89
in second-order logic, 286

Index
317
Variables, 70, 79
bound, 80
free, 76–77
function, 282
individual, 282–283
predicate, 282
Vaught’s test. See
Ło´s–Vaught test
Vector spaces, 92, 99
W
Weakly representability,
241–242
Well-deﬁned function, 165
Well-formed formulas (wffs),
12, 17–18, 75
Well-ordering, 283
Z
Z-chains, 189–190, 197
Zermelo–Fraenkel set theory,
157, 270
0-ary connectives, 50
0-place function symbols, 70
Zorn’s lemma, 7, 60, 141

