123
$MBVEJP$BOVUPt"OJUB5BCBDDP
Mathematical Analysis II
UNITEXT
UNITEXT
4FDPOE&EJUJPO

UNITEXT ‚Äì La Matematica per il 3+2
Volume 85
For further volumes:
http://www.springer.com/series/5418

Claudio Canuto ¬∑ Anita Tabacco
MathematicalAnalysisII
Second Edition

Claudio Canuto
Department of Mathematical Sciences
Politecnico di Torino
Torino, Italy
Anita Tabacco
Department of Mathematical Sciences
Politecnico di Torino
Torino, Italy
UNITEXT ‚Äì La Matematica per il 3+2
ISSN 2038-5722
ISSN 2038-5757 (electronic)
ISBN 978-3-319-12756-9
ISBN 978-3-319-12757-6 (eBook)
DOI 10.1007/978-3-319-12757-6
Springer Cham Heidelberg New York Dordrecht London
Library of Congress Control Number: 2014952083
¬© Springer International Publishing Switzerland 2015
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part
of the material is concerned, speciÔ¨Åcally the rights of translation, reprinting, reuse of illustrations, re-
citation, broadcasting, reproduction on microÔ¨Ålms or in any other physical way, and transmission or
information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar
methodology now known or hereafter developed. Exempted from this legal reservation are brief ex-
cerpts in connection with reviews or scholarly analysis or material supplied speciÔ¨Åcally for the purpose
of being entered and executed on a computer system, for exclusive use by the purchaser of the work.
Duplication of this publication or parts thereof is permitted only under the provisions of the Copyright
Law of the Publisher‚Äôs location, in its current version, and permission for use must always be obtained
from Springer. Permissions for use may be obtained through RightsLink at the Copyright Clearance
Center. Violations are liable to prosecution under the respective Copyright Law.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publi-
cation does not imply, even in the absence of a speciÔ¨Åc statement, that such names are exempt from the
relevant protective laws and regulations and therefore free for general use.
While the advice and information in this book are believed to be true and accurate at the date of pu-
blication, neither the authors nor the editors nor the publisher can accept any legal responsibility for
any errors or omissions that may be made. The publisher makes no warranty, express or implied, with
respect to the material contained herein.
Cover Design: Simona Colombo, Giochi di GraÔ¨Åca, Milano, Italy
Files provided by the Authors
Springer is a part of Springer Science+Business Media (www.springer.com)

To Arianna, Susanna
and Chiara, Alessandro, Cecilia

Preface
The purpose of this textbook is to present an array of topics that are found in
the syllabus of the typical second lecture course in Calculus, as oÔ¨Äered in many
universities. Conceptually, it follows our previous book Mathematical Analysis I,
published by Springer, which will be referred to throughout as Vol. I.
While the subject matter known as ‚ÄòCalculus 1‚Äô concerns real functions of real
variables, and as such is more or less standard, the choices for a course on ‚ÄòCalculus
2‚Äô can vary a lot, and even the way the topics can be taught is not so rigid. Due
to this larger Ô¨Çexibility we tried to cover a wide range of subjects, reÔ¨Çected in
the fact that the amount of content gathered here may not be comparable to the
number of credits conferred to a second Calculus course by the current programme
speciÔ¨Åcations. The reminders disseminated in the text render the sections more
independent from one another, allowing the reader to jump back and forth, and
thus enhancing the book‚Äôs versatility.
The succession of chapters is what we believe to be the most natural. With
the Ô¨Årst three chapters we conclude the study of one-variable functions, begun in
Vol. I, by discussing sequences and series of functions, including power series and
Fourier series. Then we pass to examine multivariable and vector-valued functions,
investigating continuity properties and developing the corresponding integral and
diÔ¨Äerential calculus (over open measurable sets of Rn Ô¨Årst, then on curves and
surfaces). In the Ô¨Ånal part of the book we apply some of the theory learnt to the
study of systems of ordinary diÔ¨Äerential equations.
Continuing along the same strand of thought of Vol. I, we wanted the present-
ation to be as clear and comprehensible as possible. Every page of the book con-
centrates on very few essential notions, most of the time just one, in order to
keep the reader focused. For theorems‚Äô statements, we chose the form that hastens
an immediate understanding and guarantees readability at the same time. Hence,
they are as a rule followed by several examples and pictures; the same is true for
the techniques of computation.
The large number of exercises, gathered according to the main topics at the
end of each chapter, should help the student test his improvements. We provide
the solution to all exercises, and very often the procedure for solving is outlined.

VIII
Preface
Some graphical conventions are adopted: deÔ¨Ånitions are displayed over grey
backgrounds, while statements appear on blue; examples are marked with a blue
vertical bar at the side; exercises with solutions are boxed (e.g., 12. ).
This second edition is enriched by two appendices, devoted to diÔ¨Äerential and
integral calculus, respectively. Therein, the interested reader may Ô¨Ånd the rigorous
explanation of many results that are merely stated without proof in the previous
chapters, together with useful additional material. We completely omitted the
proofs whose technical aspects prevail over the fundamental notions and ideas.
These may be found in other, more detailed, texts, some of which are explicitly
suggested to deepen relevant topics.
All Ô¨Ågures were created with MATLABTM and edited using the freely-available
package psfrag.
This volume originates from a textbook written in Italian, itself an expanded
version of the lecture courses on Calculus we have taught over the years at the
Politecnico di Torino. We owe much to many authors who wrote books on the
subject: A. Bacciotti and F. Ricci, C. Pagani and S. Salsa, G. Gilardi to name a
few. We have also found enduring inspiration in the Anglo-Saxon-Ô¨Çavoured books
by T. Apostol and J. Stewart.
Special thanks are due to Dr. Simon Chiossi, for the careful and eÔ¨Äective work
of translation.
Finally, we wish to thank Francesca Bonadei ‚Äì Executive Editor, Mathem-
atics and Statistics, Springer Italia ‚Äì for her encouragement and support in the
preparation of this textbook.
Torino, August 2014
Claudio Canuto, Anita Tabacco

Contents
1
Numerical series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Round-up on sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
Numerical series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.3
Series with positive terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
1.4
Alternating series. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
1.5
The algebra of series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
1.6
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
1.6.1
Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
2
Series of functions and power series . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
2.1
Sequences of functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
2.2
Properties of uniformly convergent sequences. . . . . . . . . . . . . . . . . . . . 37
2.2.1
Interchanging limits and integrals . . . . . . . . . . . . . . . . . . . . . . . 38
2.2.2
Interchanging limits and derivatives. . . . . . . . . . . . . . . . . . . . . . 39
2.3
Series of functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
2.4
Power series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
2.4.1
Algebraic operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
2.4.2
DiÔ¨Äerentiation and integration . . . . . . . . . . . . . . . . . . . . . . . . . . 53
2.5
Analytic functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
2.6
Power series in C . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
2.7
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
2.7.1
Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
3
Fourier series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
3.1
Trigonometric polynomials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
3.2
Fourier CoeÔ¨Écients and Fourier series . . . . . . . . . . . . . . . . . . . . . . . . . . 79
3.3
Exponential form . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
3.4
DiÔ¨Äerentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
3.5
Convergence of Fourier series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
3.5.1
Quadratic convergence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90

X
Contents
3.5.2
Pointwise convergence. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
3.5.3
Uniform convergence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
3.5.4
Decay of Fourier coeÔ¨Écients . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
3.6
Periodic functions with period T > 0 . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
3.7
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
3.7.1
Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
4
Functions between Euclidean spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
4.1
Vectors in Rn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
4.2
Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
4.3
Sets in Rn and their properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
4.4
Functions: deÔ¨Ånitions and Ô¨Årst examples . . . . . . . . . . . . . . . . . . . . . . . . 126
4.5
Continuity and limits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
4.5.1
Properties of limits and continuity . . . . . . . . . . . . . . . . . . . . . . . 137
4.6
Curves in Rm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
4.7
Surfaces in R3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
4.8
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
4.8.1
Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
5
DiÔ¨Äerential calculus for scalar functions. . . . . . . . . . . . . . . . . . . . . . . . 155
5.1
First partial derivatives and gradient . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
5.2
DiÔ¨Äerentiability and diÔ¨Äerentials. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
5.2.1
Mean Value Theorem and Lipschitz functions . . . . . . . . . . . . . 165
5.3
Second partial derivatives and Hessian matrix . . . . . . . . . . . . . . . . . . . 168
5.4
Higher-order partial derivatives. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
5.5
Taylor expansions; convexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
5.5.1
Convexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173
5.6
Extremal points of a function; stationary points . . . . . . . . . . . . . . . . . 174
5.6.1
Saddle points . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178
5.7
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183
5.7.1
Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186
6
DiÔ¨Äerential calculus for vector-valued functions . . . . . . . . . . . . . . . . 201
6.1
Partial derivatives and Jacobian matrix . . . . . . . . . . . . . . . . . . . . . . . . 201
6.2
DiÔ¨Äerentiability and Lipschitz functions . . . . . . . . . . . . . . . . . . . . . . . . 202
6.3
Basic diÔ¨Äerential operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204
6.3.1
First-order operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204
6.3.2
Second-order operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
6.4
DiÔ¨Äerentiating composite functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212
6.4.1
Functions deÔ¨Åned by integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . 214
6.5
Regular curves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
6.5.1
Congruence of curves; orientation. . . . . . . . . . . . . . . . . . . . . . . . 220
6.5.2
Length and arc length . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222
6.5.3
Elements of diÔ¨Äerential geometry for curves . . . . . . . . . . . . . . . 225
6.6
Variable changes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227

Contents
XI
6.6.1
Special frame systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230
6.7
Regular surfaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 236
6.7.1
Changing parametrisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240
6.7.2
Orientable surfaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241
6.7.3
Boundary of a surface; closed surfaces . . . . . . . . . . . . . . . . . . . . 243
6.7.4
Piecewise-regular surfaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247
6.8
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
6.8.1
Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251
7
Applying diÔ¨Äerential calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
7.1
Implicit Function Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
7.1.1
Local invertibility of a function. . . . . . . . . . . . . . . . . . . . . . . . . . 267
7.2
Level curves and level surfaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 268
7.2.1
Level curves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
7.2.2
Level surfaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
7.3
Constrained extrema . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274
7.3.1
The method of parameters. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
7.3.2
Lagrange multipliers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278
7.4
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285
7.4.1
Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288
8
Integral calculus in several variables . . . . . . . . . . . . . . . . . . . . . . . . . . . 297
8.1
Double integral over rectangles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298
8.2
Double integrals over measurable sets . . . . . . . . . . . . . . . . . . . . . . . . . . 304
8.2.1
Properties of double integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
8.3
Changing variables in double integrals. . . . . . . . . . . . . . . . . . . . . . . . . . 317
8.4
Multiple integrals. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322
8.4.1
Changing variables in triple integrals. . . . . . . . . . . . . . . . . . . . . 328
8.5
Applications and generalisations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 330
8.5.1
Mass, centre of mass and moments of a solid body . . . . . . . . . 330
8.5.2
Volume of solids of revolution . . . . . . . . . . . . . . . . . . . . . . . . . . . 332
8.5.3
Integrals of vector-valued functions . . . . . . . . . . . . . . . . . . . . . . 335
8.5.4
Improper multiple integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 335
8.6
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337
8.6.1
Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343
9
Integral calculus on curves and surfaces . . . . . . . . . . . . . . . . . . . . . . . 367
9.1
Integrating along curves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 368
9.1.1
Centre of mass and moments of a curve . . . . . . . . . . . . . . . . . . 374
9.2
Path integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 375
9.3
Integrals over surfaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 377
9.3.1
Area of a surface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 381
9.3.2
Centre of mass and moments of a surface . . . . . . . . . . . . . . . . . 383
9.4
Flux integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 383
9.5
The Theorems of Gauss, Green, and Stokes . . . . . . . . . . . . . . . . . . . . . 385

XII
Contents
9.5.1
Open sets, admissible surfaces and boundaries . . . . . . . . . . . . 386
9.5.2
Divergence Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 391
9.5.3
Green‚Äôs Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 393
9.5.4
Stokes‚Äô Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 395
9.6
Conservative Ô¨Åelds and potentials. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397
9.6.1
Computing potentials explicitly . . . . . . . . . . . . . . . . . . . . . . . . . 404
9.7
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 406
9.7.1
Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 410
10
Ordinary diÔ¨Äerential equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 421
10.1 Introductory examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 421
10.2 General deÔ¨Ånitions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 424
10.3 Equations of Ô¨Årst order . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 430
10.3.1 Equations with separable variables . . . . . . . . . . . . . . . . . . . . . . 430
10.3.2 Homogeneous equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 432
10.3.3 Linear equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 433
10.3.4 Bernoulli equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 437
10.3.5 Riccati equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 437
10.3.6 Second-order equations reducible to Ô¨Årst order . . . . . . . . . . . . 438
10.4 The Cauchy problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 440
10.4.1 Local existence and uniqueness . . . . . . . . . . . . . . . . . . . . . . . . . . 440
10.4.2 Maximal solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 444
10.4.3 Global existence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 446
10.4.4 Global existence in the future . . . . . . . . . . . . . . . . . . . . . . . . . . . 448
10.4.5 First integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 451
10.5 Linear systems of Ô¨Årst order . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 454
10.5.1 Homogeneous systems. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 456
10.5.2 Non-homogeneous systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 459
10.6 Linear systems with constant matrix A . . . . . . . . . . . . . . . . . . . . . . . . 461
10.6.1 Homogeneous systems with diagonalisable A . . . . . . . . . . . . . . 462
10.6.2 Homogeneous systems with non-diagonalisable A . . . . . . . . . . 466
10.6.3 Non-homogeneous systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 470
10.7 Linear scalar equations of order n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 473
10.8 Stability. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 478
10.8.1 Autonomous linear systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 480
10.8.2 Two-dimensional systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 481
10.8.3 Non-linear stability: an overview . . . . . . . . . . . . . . . . . . . . . . . . 487
10.9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 489
10.9.1 Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 494

Contents
XIII
Appendices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 509
A.1 Complements on diÔ¨Äerential calculus . . . . . . . . . . . . . . . . . . . . . . . . . . 511
A.1.1 DiÔ¨Äerentiability and Schwarz‚Äôs Theorem . . . . . . . . . . . . . . . . . . . . . . . 511
A.1.2 Taylor‚Äôs expansions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 513
A.1.3 DiÔ¨Äerentiating functions deÔ¨Åned by integrals . . . . . . . . . . . . . . . . . . . 515
A.1.4 The Implicit Function Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 518
A.2 Complements on integral calculus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 521
A.2.1 Norms of functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 521
A.2.2 The Theorems of Gauss, Green, and Stokes . . . . . . . . . . . . . . . . . . . . 524
A.2.3 DiÔ¨Äerential forms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 529
Basic deÔ¨Ånitions and formulas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 533
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 545

1
Numerical series
This is the Ô¨Årst of three chapters dedicated to series. A series formalises the idea of
adding inÔ¨Ånitely many terms of a sequence which can involve numbers (numerical
series) or functions (series of functions). Using series we can represent an irrational
number by the sum of an inÔ¨Ånite sequence of increasingly smaller rational numbers,
for instance, or a continuous map by a sum of inÔ¨Ånitely many piecewise-constant
functions deÔ¨Åned over intervals of decreasing size. Since the deÔ¨Ånition itself of
series relies on the notion of limit of a sequence, the study of a series‚Äô behaviour
requires all the instruments used for such limits.
In this chapter we will consider numerical series: beside their unquestionable
theoretical importance, they serve as a warm-up for the ensuing study of series
of functions. We begin by recalling their main properties. Subsequently we will
consider the various types of convergence conditions of a numerical sequence and
identify important classes of series, to study which the appropriate tools will be
provided.
1.1 Round-up on sequences
We brieÔ¨Çy recall here the deÔ¨Ånition and main properties of sequences, whose full
treatise is present in Vol. I.
A real sequence is a function from N to R whose domain contains a set
{n ‚ààN
:
n ‚â•n0} for some integer n0 ‚â•0. If one calls a the sequence, it is
common practice to denote the image of n by an instead of a(n); in other words
we will write a : n ‚Üían. A standardised way to indicate a sequence is {an}n‚â•n0
(ignoring the terms with n < n0), or even more concisely {an}.
The behaviour of a sequence as n tends to ‚àûcan be classiÔ¨Åed as follows. The
sequence {an}n‚â•n0 converges (to ‚Ñì) if the limit lim
n‚Üí‚àûan = ‚Ñìexists and is Ô¨Ånite.
When the limit exists but is inÔ¨Ånite, the sequence is said to diverge to +‚àûor
‚àí‚àû. If the sequence is neither convergent nor divergent, i.e., if lim
n‚Üí‚àûan does not
exist, the sequence is indeterminate.
C. Canuto, A. Tabacco: Mathematical Analysis II, 2nd Ed.,
UNITEXT ‚Äì La Matematica per il 3+2 85, DOI 10.1007/978-3-319-12757-6_1,
¬© Springer International Publishing Switzerland 2015

2
1 Numerical series
The fact that the behaviour of the Ô¨Årst terms is completely irrelevant justiÔ¨Åes
the following deÔ¨Ånition. A sequence {an}n‚â•n0 satisÔ¨Åes a certain property even-
tually, if there is an integer N ‚â•n0 such that the sequence {an}n‚â•N satisÔ¨Åes the
property.
The main theorems governing the limit behaviour of sequences are recalled
below.
Theorems on sequences
1. Uniqueness of the limit: if the limit of a sequence exists, it is unique.
2. Boundedness: a converging sequence is bounded.
3. Existence of the limit for monotone sequences: an eventually-monotone
sequence is convergent if bounded, divergent if unbounded (divergent to
+‚àûif increasing, to ‚àí‚àûif decreasing).
4. First Comparison Theorem: let {an}, {bn} be sequences with Ô¨Ånite or
inÔ¨Ånite limits lim
n‚Üí‚àûan = ‚Ñìand lim
n‚Üí‚àûbn = m. If an ‚â§bn eventually, then
‚Ñì‚â§m.
5a. Second Comparison Theorem - Ô¨Ånite case: let {an}, {bn} and {cn} be
sequences with lim
n‚Üí‚àûan = lim
n‚Üí‚àûcn = ‚Ñì‚ààR. If an ‚â§bn ‚â§cn eventually,
then lim
n‚Üí‚àûbn = ‚Ñì.
5b. Second Comparison Theorem - inÔ¨Ånite case: let {an}, {bn} be sequences
such that lim
n‚Üí‚àûan = +‚àû. If an ‚â§bn eventually, then lim
n‚Üí‚àûbn = +‚àû. A
similar result holds if the limit is ‚àí‚àû: lim
n‚Üí‚àûbn = ‚àí‚àûimplies lim
n‚Üí‚àûan =
‚àí‚àû.
6. Property: a sequence {an} is inÔ¨Ånitesimal, that is lim
n‚Üí‚àûan = 0, if and only
if the sequence of absolute values {|an|} is inÔ¨Ånitesimal.
7. Theorem: if {an} is inÔ¨Ånitesimal and {bn} bounded, {anbn} is inÔ¨Ånitesimal.
8. Algebra of limits: let {an}, {bn} be such that lim
n‚Üí‚àûan = ‚Ñìand lim
n‚Üí‚àûbn = m
(‚Ñì, m Ô¨Ånite or inÔ¨Ånite). Then
lim
n‚Üí‚àû(an ¬± bn) = ‚Ñì¬± m ,
lim
n‚Üí‚àûan bn = ‚Ñìm ,
lim
n‚Üí‚àû
an
bn
= ‚Ñì
m,
if bn Ã∏= 0 eventually,
whenever the right-hand sides are deÔ¨Åned.
9. Substitution Theorem: let {an} be a sequence with lim
n‚Üí‚àûan = ‚Ñìand sup-
pose g is a function deÔ¨Åned on a neighbourhood of ‚Ñì:
a) if ‚Ñì‚ààR and g is continuous at ‚Ñì, then lim
n‚Üí‚àûg(an) = g(‚Ñì);
b) if ‚Ñì/‚ààR and lim
x‚Üí‚Ñìg(x) = m exists, then lim
n‚Üí‚àûg(an) = m.

1.1 Round-up on sequences
3
10. Ratio Test: let {an} be a sequence for which an > 0 eventually, and suppose
the limit
lim
n‚Üí‚àû
an+1
an
= q
exists, Ô¨Ånite or inÔ¨Ånite. If q < 1 then lim
n‚Üí‚àûan = 0; if q > 1 then lim
n‚Üí‚àûan =
+‚àû.
Let us review some cases of particular relevance.
Examples 1.1
i) Consider the geometric sequence an = qn, where q is a Ô¨Åxed number in R. In
Vol. I, Example 5.18, we proved
lim
n‚Üí‚àûqn =
‚éß
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é©
0
if |q| < 1,
1
if q = 1,
+‚àû
if q > 1,
does not exist
if q ‚â§‚àí1.
(1.1)
ii) Let p > 0 be a given number and consider the sequence
n‚àöp. Using the
Substitution Theorem with g(x) = px we have
lim
n‚Üí‚àû
n‚àöp = lim
n‚Üí‚àûp1/n = p0 = 1 .
iii) Consider now
n‚àön; again using the Substitution Theorem,
lim
n‚Üí‚àû
n‚àön = lim
n‚Üí‚àûexp log n
n
= e0 = 1.
iv) The number e may be deÔ¨Åned as the limit of the sequence an =

1 + 1
n
n
,
which converges since it is strictly increasing and bounded from above.
v) At last, look at the sequences, all tending to +‚àû,
log n , nŒ± , qn , n! , nn
(Œ± > 0, q > 1) .
In Vol. I, Sect. 5.4, we proved that each of these is inÔ¨Ånite of order bigger than
the preceding one. This means that for n ‚Üí‚àû, with Œ± > 0 and q > 1, we have
log n = o(nŒ±) ,
nŒ± = o(qn) ,
qn = o(n!) ,
n! = o(nn) .
2

4
1 Numerical series
1.2 Numerical series
To introduce the notion of numerical series, i.e., of ‚Äúsum of inÔ¨Ånitely many num-
bers‚Äù, we examine a simple yet instructive situation borrowed from geometry.
Consider a segment of length ‚Ñì= 2 (Fig. 1.1). The middle point splits it into two
parts of length a0 = ‚Ñì/2 = 1. While keeping the left half Ô¨Åxed, we subdivide the
right one in two parts of length a1 = ‚Ñì/4 = 1/2. Iterating the process indeÔ¨Ånitely
one can think of the initial segment as the union of inÔ¨Ånitely many segments of
lengths 1, 1
2, 1
4, 1
8,
1
16, . . . Correspondingly, the total length of the starting segment
can be thought of as sum of the lengths of all sub-segments, in other words
2 = 1 + 1
2 + 1
4 + 1
8 + 1
16 + . . .
(1.2)
On the right we have a sum of inÔ¨Ånitely many terms. This inÔ¨Ånite sum can be
deÔ¨Åned properly using sequences, and leads to the notion of a numerical series.
Given the sequence {ak}k‚â•0, one constructs the so-called sequence of partial
sums {sn}n‚â•0 in the following manner:
s0 = a0 ,
s1 = a0 + a1 ,
s2 = a0 + a1 + a2,
and in general,
sn = a0 + a1 + . . . + an =
n

k=0
ak .
Note that sn = sn‚àí1 + an. Then it is natural to study the limit behaviour of such
a sequence. Let us (formally) deÔ¨Åne
‚àû

k=0
ak = lim
n‚Üí‚àû
n

k=0
ak = lim
n‚Üí‚àûsn .
The symbol
‚àû

k=0
ak is called (numerical) series, and ak is the general term of
the series.
0
2
1
3
2
7
4
15
8
1
1
2
1
4
1
8
1
16
Figure 1.1. Successive splittings of the interval [0, 2]. The coordinates of the subdivision
points are indicated below the blue line, while the lengths of sub-intervals lie above it

1.2 Numerical series
5
DeÔ¨Ånition 1.2 Given the sequence {ak}k‚â•0 and sn =
n

k=0
ak, consider the
limit lim
n‚Üí‚àûsn.
i) If the limit exists (Ô¨Ånite or inÔ¨Ånite), its value s is called sum of the
series and one writes
‚àû

k=0
ak = s = lim
n‚Üí‚àûsn .
-
If s is Ô¨Ånite, one says that the series
‚àû

k=0
ak converges.
-
If s is inÔ¨Ånite, the series
‚àû

k=0
ak diverges, to either +‚àûor ‚àí‚àû.
ii) If the limit does not exist, the series
‚àû

k=0
ak is indeterminate.
Examples 1.3
i) Let us go back to the interval split inÔ¨Ånitely many times. The length of the
shortest segment obtained after k + 1 subdivisions is ak =
1
2k , k ‚â•0. Thus, we
consider the series
‚àû

k=0
1
2k . Its partial sums read
s0 = 1 ,
s1 = 1 + 1
2 = 3
2 ,
s2 = 1 + 1
2 + 1
4 = 7
4 ,
...
sn = 1 + 1
2 + . . . + 1
2n .
Using the fact that an+1 ‚àíbn+1 = (a ‚àíb)(an + an‚àí1b + . . . + abn‚àí1 + bn), and
choosing a = 1 and b = x arbitrary but diÔ¨Äerent from one, we obtain the identity
1 + x + . . . + xn = 1 ‚àíxn+1
1 ‚àíx
.
(1.3)
Therefore
sn = 1 + 1
2 + . . . + 1
2n = 1 ‚àí
1
2n+1
1 ‚àí1
2
= 2
	
1 ‚àí
1
2n+1

= 2 ‚àí1
2n ,
and so
lim
n‚Üí‚àûsn = lim
n‚Üí‚àû
	
2 ‚àí1
2n

= 2 .
The series converges and its sum is 2, which eventually justiÔ¨Åes formula (1.2).

6
1 Numerical series
ii) The partial sums of the series
‚àû

k=0
(‚àí1)k satisfy
s0 = 1 ,
s1 = 1 ‚àí1 = 0 ,
s2 = s1 + 1 = 1 ,
s3 = s2 ‚àí1 = 0 ,
...
s2n = 1 ,
s2n+1 = 0 .
The terms with even index are all equal to 1, whereas the odd ones are 0.
Therefore lim
n‚Üí‚àûsn cannot exist and the series is indeterminate.
iii) The two previous examples are special cases of the following series, called
geometric series,
‚àû

k=0
qk ,
where q is a Ô¨Åxed number in R. The geometric series is particularly important.
If q = 1, then sn = a0 +a1+. . .+an = 1+1+. . .+1 = n+1 and lim
n‚Üí‚àûsn = +‚àû.
Hence the series diverges to +‚àû.
If q Ã∏= 1 instead, (1.3) implies
sn = 1 + q + q2 + . . . + qn = 1 ‚àíqn+1
1 ‚àíq
.
Recalling Example 1.1 i), we obtain
lim
n‚Üí‚àûsn = lim
n‚Üí‚àû
1 ‚àíqn+1
1 ‚àíq
=
‚éß
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é©
1
1 ‚àíq
if |q| < 1 ,
+‚àû
if q > 1 ,
does not exist
if q ‚â§‚àí1 .
In conclusion
‚àû

k=0
qk
‚éß
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é©
converges to
1
1 ‚àíq
if |q| < 1 ,
diverges to
+ ‚àû
if q ‚â•1 ,
is indeterminate
if q ‚â§‚àí1 .
2
Sometimes the sequence {ak} is only deÔ¨Åned for k ‚â•k0: DeÔ¨Ånition 1.2 then
modiÔ¨Åes in the obvious way. Moreover, the following fact holds, whose easy proof
is left to the reader.
Property 1.4 A series‚Äô behaviour does not change by adding, modifying or
eliminating a Ô¨Ånite number of terms.

1.2 Numerical series
7
Note that this property, in case of convergence, is saying nothing about the
sum of the series, which generally changes when the series is altered. For instance,
‚àû

k=1
1
2k =
‚àû

k=0
1
2k ‚àí1 = 2 ‚àí1 = 1 .
Examples 1.5
i) The series
‚àû

k=2
1
(k ‚àí1)k is called series of Mengoli. As
ak =
1
(k ‚àí1)k =
1
k ‚àí1 ‚àí1
k,
it follows that
s2 = a2 =
1
1 ¬∑ 2 = 1 ‚àí1
2
s3 = a2 + a3 =
	
1 ‚àí1
2

+
	1
2 ‚àí1
3

= 1 ‚àí1
3,
and in general
sn = a2 + a3 + . . . + an =
	
1 ‚àí1
2

+
	1
2 ‚àí1
3

+ . . . +
	
1
n ‚àí1 ‚àí1
n

=1 ‚àí1
n .
Thus
lim
n‚Üí‚àûsn = lim
n‚Üí‚àû
	
1 ‚àí1
n

= 1
and the series converges to 1.
ii) For the series
‚àû

k=1
log

1 + 1
k

we have
ak = log

1 + 1
k

= log k + 1
k
= log(k + 1) ‚àílog k ,
so
s1 = log 2 ,
s2 = log 2 + (log 3 ‚àílog 2) = log 3 ,
...
sn = log 2 + (log 3 ‚àílog 2) + . . . +

log(n + 1) ‚àílog n

= log(n + 1) .
Hence
lim
n‚Üí‚àûsn = lim
n‚Üí‚àûlog(n + 1) = +‚àû
and the series diverges (to +‚àû).
2
The two instances just considered belong to the larger class of telescopic
series. These are deÔ¨Åned by ak = bk+1 ‚àíbk for a suitable sequence {bk}k‚â•k0.

8
1 Numerical series
Since sn = bn+1 ‚àíbk0, the behaviour of a telescopic series is the same as that of
the sequence {bk}.
There is a simple yet useful necessary condition for a numerical series to con-
verge.
Property 1.6 Let
‚àû

k=0
ak be a converging series. Then
lim
k‚Üí‚àûak = 0 .
(1.4)
Proof.
Let s = lim
n‚Üí‚àûsn. Since ak = sk ‚àísk‚àí1,
lim
k‚Üí‚àûak = lim
k‚Üí‚àû(sk ‚àísk‚àí1) = s ‚àís = 0 .
2
Observe that condition (1.4) is not suÔ¨Écient to guarantee convergence. The
general term of a series may tend to 0 without the series having to converge.
For example we saw that
‚àû

k=1
log

1 + 1
k

diverges (Example 1.5 ii)), while the
continuity of the logarithm implies that lim
k‚Üí‚àûlog

1 + 1
k

= 0.
Example 1.7
It is easy to see that
‚àû

k=1

1‚àí1
k
k
does not converge, because the general term
ak =

1 ‚àí1
k
k
tends to e‚àí1 Ã∏= 0.
2
If a series
‚àû

k=0
ak converges to s, the quantity
rn = s ‚àísn =
‚àû

k=n+1
ak
is called nth remainder.
Now comes another necessary condition for convergence.
Property 1.8 Let
‚àû

k=0
ak be a convergent series. Then
lim
n‚Üí‚àûrn = 0 .
Proof.
Just note lim
n‚Üí‚àûrn = lim
n‚Üí‚àû(s ‚àísn) = s ‚àís = 0 .
2

1.3 Series with positive terms
9
It is not always possible to predict the behaviour of a series
‚àû

k=0
ak using merely
the deÔ¨Ånition. It may well happen that the sequence of partial sums cannot be com-
puted explicitly, so it becomes important to have other ways to establish whether
the series converges or not. In case of convergence it could also be necessary to
determine the actual sum explicitly. This may require using more sophisticated
techniques, which go beyond the scopes of this text.
1.3 Series with positive terms
We deal with series
‚àû

k=0
ak for which ak ‚â•0 for any k ‚ààN.
Proposition 1.9 A series
‚àû

k=0
ak with positive terms either converges or di-
verges to +‚àû.
Proof.
The sequence sn is monotonically increasing since
sn+1 = sn + an+1 ‚â•sn ,
‚àÄn ‚â•0 .
It is then suÔ¨Écient to use Theorem 3 on p. 2 to conclude that lim
n‚Üí‚àûsn
exists, and is either Ô¨Ånite or +‚àû.
2
We list a few tools for studying the convergence of positive-term series.
Theorem 1.10 (Comparison Test) Let
‚àû

k=0
ak and
‚àû

k=0
bk be positive-term
series such that 0 ‚â§ak ‚â§bk, for any k ‚â•0.
i) If
‚àû

k=0
bk converges, also
‚àû

k=0
ak converges and
‚àû

k=0
ak ‚â§
‚àû

k=0
bk .
ii) If
‚àû

k=0
ak diverges, then
‚àû

k=0
bk diverges as well.

10
1 Numerical series
Proof.
i) Denote by {sn} and {tn} the sequences of partial sums of
‚àû

k=0
ak,
‚àû

k=0
bk
respectively. Since ak ‚â§bk for all k,
sn ‚â§tn ,
‚àÄn ‚â•0 .
By assumption, the series
‚àû

k=0
bk converges, so lim
n‚Üí‚àûtn = t ‚ààR. Propos-
ition 1.9 implies that lim
n‚Üí‚àûsn = s exists, Ô¨Ånite or inÔ¨Ånite. By the First
Comparison Theorem (Theorem 4, p. 2) we have
s = lim
n‚Üí‚àûsn ‚â§lim
n‚Üí‚àûtn = t ‚ààR .
Therefore s ‚ààR, and the series
‚àû

k=0
ak converges. Furthermore s ‚â§t.
ii) By contradiction, if
‚àû

k=0
bk converged, part i) would force
‚àû

k=0
ak to
converge too.
2
Examples 1.11
i) Consider
‚àû

k=1
1
k2 . As
1
k2 <
1
(k ‚àí1)k ,
‚àÄk ‚â•2 ,
and the series of Mengoli
‚àû

k=2
1
(k ‚àí1)k converges (Example 1.5 i)), we conclude
that the given series converges to a sum ‚â§2. One can prove the sum is precisely
œÄ2
6 (see Example 3.18).
ii) The series
‚àû

k=1
1
k is known as harmonic series. Since log(1+x) ‚â§x , ‚àÄx > ‚àí1 ,
(Vol. I, Ch. 6, Exercise 12), it follows
log

1 + 1
k

‚â§1
k ,
‚àÄk ‚â•1 ;
but since
‚àû

k=1
log

1 + 1
k

diverges (Example 1.5 ii)), we conclude that the har-
monic series diverges.
iii) Subsuming the previous two examples we have
‚àû

k=1
1
kŒ± ,
Œ±
>
0 ,
(1.5)

1.3 Series with positive terms
11
called generalised harmonic series. Because
1
kŒ± > 1
k
for 0 < Œ± < 1 ,
1
kŒ± < 1
k2
for Œ± > 2 ,
the Comparison Test tells us the generalised harmonic series diverges for 0 < Œ± <
1 and converges for Œ± > 2. The case 1 < Œ± < 2 will be examined in Example 1.19.
2
Here is a useful criterion that generalises the Comparison Test.
Theorem 1.12 (Asymptotic Comparison Test) Let
‚àû

k=0
ak and
‚àû

k=0
bk be
positive-term series and suppose the sequences {ak}k‚â•0 and {bk}k‚â•0 have the
same order of magnitude for k ‚Üí‚àû. Then the series have the same behaviour.
Proof.
Having the same order of magnitude for k ‚Üí‚àûis equivalent to
lim
k‚Üí‚àû
ak
bk
= ‚Ñì‚ààR \ {0} .
Therefore the sequences
ak
bk

k‚â•0
and
 bk
ak

k‚â•0
are both convergent,
hence both bounded (Theorem 2, p. 2). There must exist constants
M1, M2 > 0 such that

ak
bk
 ‚â§M1
and

bk
ak
 ‚â§M2
for any k > 0, i.e.,
|ak| ‚â§M1|bk|
and
|bk| ‚â§M2|ak| .
Now it suÔ¨Éces to use Theorem 1.10 to Ô¨Ånish the proof.
2
Examples 1.13
i) Consider
‚àû

k=0
ak =
‚àû

k=0
k + 3
2k2 + 5 and let bk = 1
k . Then
lim
k‚Üí‚àû
ak
bk
= 1
2
and the given series behaves as the harmonic series, hence diverges.
ii) Take the series
‚àû

k=1
ak =
‚àû

k=1
sin 1
k2 . As sin 1
k2 ‚àº1
k2 for k ‚Üí‚àû, the series has
the same behaviour of
‚àû

k=1
1
k2 , so it converges.
2

12
1 Numerical series
Eventually, here are two results ‚Äì of algebraic Ô¨Çavour and often easy to employ ‚Äì
which prescribe suÔ¨Écient conditions for a series to converge or diverge.
Theorem 1.14 (Ratio Test)
Let the series
‚àû

k=0
ak have ak > 0, ‚àÄk ‚â•0.
Assume the limit
lim
k‚Üí‚àû
ak+1
ak
= ‚Ñì
exists, Ô¨Ånite or inÔ¨Ånite. If ‚Ñì< 1 the series converges; if ‚Ñì> 1 it diverges.
Proof.
First, suppose ‚ÑìÔ¨Ånite. By deÔ¨Ånition of limit we know that for any Œµ > 0,
there is an integer kŒµ ‚â•0 such that
‚àÄk > kŒµ
‚áí

ak+1
ak
‚àí‚Ñì
 < Œµ
i.e.,
‚Ñì‚àíŒµ < ak+1
ak
< ‚Ñì+ Œµ .
Assume ‚Ñì< 1. Choose Œµ = 1‚àí‚Ñì
2
and set q = 1+‚Ñì
2 , so
0 < ak+1
ak
< ‚Ñì+ Œµ = q ,
‚àÄk > kŒµ .
Repeating the argument we obtain
ak+1 < qak < q2ak‚àí1 < . . . < qk‚àíkŒµakŒµ+1
hence
ak+1 < akŒµ+1
qkŒµ qk ,
‚àÄk > kŒµ .
The claim follows by Theorem 1.10 and from the fact that the geometric
series, with q < 1, converges (Example 1.3).
Now consider ‚Ñì> 1. Choose Œµ = ‚Ñì‚àí1, and notice
1 = ‚Ñì‚àíŒµ < ak+1
ak
,
‚àÄk > kŒµ .
Thus ak+1 > ak > . . . > akŒµ+1 > 0, so the necessary condition for conver-
gence fails, for lim
k‚Üí‚àûak Ã∏= 0.
Eventually, if ‚Ñì= +‚àû, we put A = 1 in the condition of limit, and there
exists kA ‚â•0 with ak > 1, for any k > kA. Once again the necessary
condition to have convergence does not hold.
2
Theorem 1.15 (Root Test) Given a series
‚àû

k=0
ak with ak ‚â•0, ‚àÄk ‚â•0,
suppose
lim
k‚Üí‚àû
k‚àöak = ‚Ñì
exists, Ô¨Ånite or inÔ¨Ånite. If ‚Ñì< 1 the series converges, if ‚Ñì> 1 it diverges.
Proof.
This proof is essentially identical to the previous one, so we leave it to the
reader.
2

1.3 Series with positive terms
13
Examples 1.16
i) For
‚àû

k=0
k
3k we have ak = k
3k and ak+1 = k + 1
3k+1 , therefore
lim
k‚Üí‚àû
ak+1
ak
= lim
k‚Üí‚àû
1
3
k + 1
k
= 1
3 < 1 .
The given series converges by the Ratio Test 1.14.
ii) The series
‚àû

k=1
1
kk has
lim
k‚Üí‚àû
k‚àöak = lim
k‚Üí‚àû
1
k = 0 < 1 .
The Root Test 1.15 ensures that the series converges.
2
We remark that the Ratio and Root Tests do not allow to conclude anything
if ‚Ñì= 1. For example,
‚àû

k=1
1
k diverges and
‚àû

k=1
1
k2 converges, yet they both satisfy
Theorems 1.14 and 1.15 with ‚Ñì= 1.
In certain situations it may be useful to think of the general term ak as the value
at x = k of a function f deÔ¨Åned on the half-line [k0, +‚àû). Under the appropriate
assumptions, we can relate the behaviour of the series to that of the integral of f
over [k0, +‚àû). In fact,
Theorem 1.17 (Integral Test) Let f be continuous, positive and decreasing
on [k0, +‚àû), for k0 ‚ààN. Then
‚àû

k=k0+1
f(k) ‚â§
 +‚àû
k0
f(x) dx ‚â§
‚àû

k=k0
f(k) .
(1.6)
Therefore the integral and the series share the same behaviour:
a)
 +‚àû
k0
f(x) dx converges
‚áê‚áí
‚àû

k=k0
f(k) converges;
b)
 +‚àû
k0
f(x) dx diverges
‚áê‚áí
‚àû

k=k0
f(k) diverges.
Proof.
Since f decreases, for any k ‚â•k0 we have
f(k + 1) ‚â§f(x) ‚â§f(k) ,
‚àÄx ‚àà[k, k + 1] ,
and as the integral is monotone,
f(k + 1) ‚â§
 k+1
k
f(x) dx ‚â§f(k) .

14
1 Numerical series
Then for all n ‚ààN with n > k0 we obtain
n+1

k=k0+1
f(k) ‚â§
 n+1
k0
f(x) dx ‚â§
n

k=k0
f(k)
(after re-indexing the Ô¨Årst series). Passing to the limit for n ‚Üí+‚àûand
recalling f is positive and continuous, we conclude.
2
From inequalities (1.6) it follows easily that
 +‚àû
k0
f(x) dx ‚â§
‚àû

k=k0
f(k) ‚â§f(k0) +
 +‚àû
k0
f(x) dx .
Comparing with the improper integral of f allows to estimate, often accurately,
the remainder and the sum of the series, and use this to estimate numerically these
values:
Property 1.18 Under the assumptions of Theorem 1.17, if
‚àû

k=k0
f(k)
converges then for all n ‚â•k0
 +‚àû
n+1
f(x) dx ‚â§rn ‚â§
 +‚àû
n
f(x) dx ,
(1.7)
and
sn +
 +‚àû
n+1
f(x) dx ‚â§s ‚â§sn +
 +‚àû
n
f(x) dx .
(1.8)
Proof.
If
‚àû

k=k0
f(k) converges, (1.6) can we re-written substituting k0 with any
integer n ‚â•k0. Using the Ô¨Årst inequality,
rn = s ‚àísn =
‚àû

k=n+1
f(k) ‚â§
 +‚àû
n
f(x) dx ,
while changing k0 to n + 1 in the second one yields
 +‚àû
n+1
f(x) dx ‚â§rn .
This gives formula (1.7), from which (1.8) follows by adding sn to each
side.
2

1.3 Series with positive terms
15
Examples 1.19
i) The Integral Test is used to study the generalised harmonic series (1.5) for all
admissible values of the parameter Œ±. Note in fact that the function 1
xŒ± , Œ± > 0,
fulÔ¨Ålls the hypotheses and its integral over [1, +‚àû) converges if and only if Œ± > 1.
In conclusion,
‚àû

k=1
1
kŒ±
 converges if Œ± > 1 ,
diverges if 0 < Œ± ‚â§1 .
ii) In order to study
‚àû

k=2
1
k log k
we take the map f(x) =
1
x log x; its integral over [2, +‚àû) diverges, since
 +‚àû
2
1
x log x dx =
 +‚àû
log 2
1
t dt = +‚àû.
Consequently, the series
‚àû

k=2
1
k log k is divergent.
iii) Suppose we want to estimate the precision of the sum of
‚àû

k=1
1
k3 computed
up to the Ô¨Årst 10 terms.
We need to calculate
 +‚àû
n
f(x) dx with f(x) = 1
x3 :
 +‚àû
n
1
x3 dx =
lim
c‚Üí+‚àû

‚àí1
2x2
c
n
=
1
2n2 .
By (1.7) we obtain
r10 = s ‚àís10 ‚â§
 +‚àû
10
1
x3 dx =
1
2 (10)2 = 0.005
and
r10 ‚â•
 +‚àû
11
1
x3 dx =
1
2 (11)2 = 0.004132 . . .
The sum may be estimated with the help of (1.8):
s10 +
1
2 (11)2 ‚â§s ‚â§s10 +
1
2 (10)2 .
Since
s10 = 1 + 1
23 + . . . +
1
103 = 1.197532 . . . ,
we Ô¨Ånd 1.201664 ‚â§s ‚â§1.202532 . The exact value for s is 1.202057 . . .
2

16
1 Numerical series
1.4 Alternating series
These are series of the form
‚àû

k=0
(‚àí1)kbk
with
bk > 0 ,
‚àÄk ‚â•0.
For them the following result due to Leibniz holds.
Theorem 1.20 (Leibniz‚Äôs
Alternating
Series
Test) An alternating
series
‚àû

k=0
(‚àí1)kbk converges if the following conditions hold
i)
lim
k‚Üí‚àûbk = 0 ;
ii) the sequence {bk}k‚â•0 decreases monotonically .
Denoting by s its sum, for all n ‚â•0 one has
|rn| = |s ‚àísn| ‚â§bn+1
and
s2n+1 ‚â§s ‚â§s2n .
Proof.
As {bk}k‚â•0 is a decreasing sequence,
s2n = s2n‚àí2 ‚àíb2n‚àí1 + b2n = s2n‚àí2 ‚àí(b2n‚àí1 ‚àíb2n) ‚â§s2n‚àí2
and
s2n+1 = s2n‚àí1 + b2n ‚àíb2n+1 ‚â•s2n‚àí1 .
Thus the subsequence of partial sums made by the terms with even index
decreases, whereas the subsequence of odd indexes increases. For any n ‚â•
0, moreover,
s2n = s2n‚àí1 + b2n ‚â•s2n‚àí1 ‚â•. . . ‚â•s1
and
s2n+1 = s2n ‚àíb2n+1 ‚â§s2n ‚â§. . . ‚â§s0 .
Thus {s2n}n‚â•0 is bounded from below and {s2n+1}n‚â•0 from above. By
Theorem 3 on p. 2 both sequences converge, so let us put
lim
n‚Üí‚àûs2n = inf
n‚â•0 s2n = s‚àó
and
lim
n‚Üí‚àûs2n+1 = sup
n‚â•0
s2n+1 = s‚àó.
Since
s‚àó‚àís‚àó= lim
n‚Üí‚àû

s2n ‚àís2n+1

= lim
n‚Üí‚àûb2n+1 = 0 ,
we conclude that the series
‚àû

k=0
(‚àí1)kbk has sum s = s‚àó= s‚àó. In addition,
s2n+1 ‚â§s ‚â§s2n ,
‚àÄn ‚â•0 ,

1.4 Alternating series
17
in other words the sequence {s2n}n‚â•0 approximates s from above, while
{s2n+1}n‚â•0 approximates s from below. For any n ‚â•0 we have
0 ‚â§s ‚àís2n+1 ‚â§s2n+2 ‚àís2n+1 = b2n+2
and
0 ‚â§s2n ‚àís ‚â§s2n ‚àís2n+1 = b2n+1 ,
so |rn| = |s ‚àísn| ‚â§bn+1.
2
Examples 1.21
i) Consider the generalised alternating harmonic series
‚àû

k=1
(‚àí1)k 1
kŒ± , where
Œ± > 0. As lim
k‚Üí‚àûbk = lim
k‚Üí‚àû
1
kŒ± = 0 and the sequence
 1
kŒ±

k‚â•1 is strictly decreasing,
the series converges.
ii) Condition i) in Leibniz‚Äôs Test is also necessary, whereas ii) is only suÔ¨Écient.
In fact, for k ‚â•2 let
bk =
 1/k
k even ,
(k ‚àí1)/k2
k odd .
It is straightforward that bk > 0 and bk is inÔ¨Ånitesimal. The sequence is not
monotone decreasing since bk > bk+1 for k even, bk < bk+1 for k odd. Neverthe-
less,
‚àû

k=2
bk =
‚àû

k=2
(‚àí1)k 1
k +

k ‚â•3
k odd
1
k2
converges, for the two series on the right converge.
iii) We want to approximate the sum of
‚àû

k=0
(‚àí1)k
k!
to the third digit, meaning
with a margin less than 10‚àí3. The series, alternating for bk =
1
k!, converges by
Leibniz‚Äôs Test. From |s ‚àísn| ‚â§bn+1 we see that for n = 6
0 < s6 ‚àís ‚â§b7 =
1
5040 <
1
5000 = 0.0002 < 10‚àí3 .
As s6 = 0.368056 . . ., the estimate s ‚àº0.368 is correct up to the third place. 2
To study series with arbitrary signs the notion of absolute convergence is useful.
DeÔ¨Ånition 1.22 The series
‚àû

k=0
ak converges absolutely if the positive-
term series
‚àû

k=0
|ak| converges.

18
1 Numerical series
Example 1.23
The series
‚àû

k=0
(‚àí1)k 1
k2 converges absolutely because
‚àû

k=0
1
k2 converges.
2
The next fact ensures that absolute convergence implies convergence.
Theorem 1.24 (Absolute Convergence Test) If
‚àû

k=0
ak converges abso-
lutely then it also converges, and

‚àû

k=0
ak
 ‚â§
‚àû

k=0
|ak| .
Proof.
The proof is similar to that of the Absolute Convergence Test for improper
integrals.
DeÔ¨Åne sequences
a+
k =
 ak
if ak ‚â•0
0
if ak < 0
and
a‚àí
k =
 0
if ak ‚â•0
‚àíak
if ak < 0 .
Note a+
k , a‚àí
k ‚â•0 for all k ‚â•0, and
ak = a+
k ‚àía‚àí
k ,
|ak| = a+
k + a‚àí
k .
As 0 ‚â§a+
k , a‚àí
k ‚â§|ak|, for any k ‚â•0, the Comparison Test (Theorem 1.10)
tells us that
‚àû

k=0
a+
k and
‚àû

k=0
a‚àí
k converge. But for any n ‚â•0,
n

k=0
ak =
n

k=0

a+
k ‚àía‚àí
k

=
n

k=0
a+
k ‚àí
n

k=0
a‚àí
k ,
so also the series
‚àû

k=0
ak =
‚àû

k=0
a+
k ‚àí
‚àû

k=0
a‚àí
k converges.
Passing now to the limit for n ‚Üí‚àûin

n

k=0
ak
 ‚â§
n

k=0
|ak| ,
we obtain the desired inequality.
2

1.5 The algebra of series
19
Remark 1.25 There are series that converge, but not absolutely. The alternating
harmonic series
‚àû

k=1
(‚àí1)k 1
k is one such example, for it has a Ô¨Ånite sum, but does not
converge absolutely, since the harmonic series
‚àû

k=1
1
k diverges. In such a situation
one speaks about conditional convergence.
2
The previous criterion allows one to study alternating series by their absolute
convergence. As the series of absolute values has positive terms, all criteria seen
in Sect 1.3 apply.
1.5 The algebra of series
Two series
‚àû

k=0
ak,
‚àû

k=0
bk can be added, multiplied by numbers and multiplied
between themselves. The sum is deÔ¨Åned in the obvious way as the series whose
formal general term reads ck = ak + bk:
‚àû

k=0
ak +
‚àû

k=0
bk =
‚àû

k=0
(ak + bk) .
Assume the series both converge or diverge, and write s =
‚àû

k=0
ak, t =
‚àû

k=0
bk
(s, t ‚ààR ‚à™{¬±‚àû}). The sum is determinate (convergent or divergent) whenever
the expression s + t is deÔ¨Åned. If so,
‚àû

k=0
(ak + bk) = s + t
and the sum converges if s + t ‚ààR, diverges if s + t = ¬±‚àû.
If one series converges and the other is indeterminate the sum is necessarily
indeterminate.
Apart from these cases, the nature of the sum cannot be deduced directly from
the behaviour of the two summands, and must be studied case by case.
Let now Œª ‚ààR \ {0}; the series Œª
‚àû

k=0
ak is by deÔ¨Ånition the series with gen-
eral term Œªak. Its behaviour coincides with that of
‚àû

k=0
ak. Anyhow, in case of
convergence or divergence,
‚àû

k=0
Œªak = Œªs .

20
1 Numerical series
In order to deÔ¨Åne the product some thinking is needed. If two series converge
respectively to s, t ‚ààR we would like the product series to converge to st. This
cannot happen if one deÔ¨Ånes the general term ck of the product simply as the
product of the corresponding terms, by setting ck = akbk. An example will clarify
the issue: consider the two geometric series with terms ak =
1
2k and bk =
1
3k . Then
‚àû

k=0
1
2k =
1
1 ‚àí1
2
= 2 ,
‚àû

k=0
1
3k =
1
1 ‚àí1
3
= 3
2
while
‚àû

k=0
1
2k
1
3k =
‚àû

k=0
1
6k =
1
1 ‚àí1
6
= 6
5 Ã∏= 2 3
2 = 3 .
One way to multiply series and preserve the above property is the so-called
Cauchy product, deÔ¨Åned by its general term
ck =
k

j=0
ajbk‚àíj = a0bk + a1bk‚àí1 + ¬∑ ¬∑ ¬∑ + ak‚àí1b1 + akb0 .
(1.9)
By arranging the products a‚Ñìbm (‚Ñì, m ‚â•0) in a matrix
b0
b1
b2
. . .
a0
a0b0
a0b1
a0b2
. . .
a1
a1b0
a1b1
a1b2
. . .
a2
a2b0
a2b1
a2b2
. . .
...
each term ck becomes the sum of the entries on the kth anti-diagonal.
The reason for this particular deÔ¨Ånition will become clear when we will discuss
power series (Sect. 2.4.1).
It is possible to prove that the absolute convergence of
‚àû

k=0
ak and
‚àû

k=0
bk is
suÔ¨Écient to guarantee the convergence of
‚àû

k=0
ck, in which case
‚àû

k=0
ck =
 ‚àû

k=0
ak
  ‚àû

k=0
bk

= st .

1.6 Exercises
21
1.6 Exercises
1. Find the general term an of the following sequences, and compute lim
n‚Üí‚àûan:
a) 1
2, 2
3, 3
4, 4
5, . . .
b) ‚àí2
3, 3
9, ‚àí4
27, 5
81, . . .
c) 0, 1,
‚àö
2,
‚àö
3,
‚àö
4, . . .
2. Study the behaviour of the sequences below and compute the limit if this
exists:
a)
an = n(n ‚àí1) ,
n ‚â•0
b)
an = n + 5
2n ‚àí1 ,
n ‚â•0
c)
an = 2 + 6n2
3n + n2 ,
n ‚â•1
d)
an =
3‚àön
1 +
3‚àön ,
n ‚â•0
e)
an =
5n
3n+1 ,
n ‚â•0
f)
an = (‚àí1)n‚àí1n2
n2 + 1
,
n ‚â•0
g)
an = arctan5n ,
n ‚â•0
h)
an = 3 + cos nœÄ ,
n ‚â•0
i)
an = 1 + (‚àí1)n sin 1
n ,
n ‚â•1
‚Ñì)
an = n cosn
n3 + 1 ,
n ‚â•0
m) an =
‚àö
n + 3 ‚àí‚àön ,
n ‚â•0
n)
an = log(2 + en)
4n
,
n ‚â•1
o)
an = ‚àí3n + log(n + 1) ‚àílog n , n ‚â•1
p)
an = (‚àí3)n
n!
,
n ‚â•1
3. Study the behaviour of the following sequences:
a) an = n ‚àí‚àön
b) an = (‚àí1)n n2 + 1
‚àö
n2 + 2
c) an = 3n ‚àí4n
1 + 4n
d) an = (2n)!
n!
e) an = (2n)!
(n!)2
f) an =
	n
3

 6
n3
g) an =
	n2 ‚àín + 1
n2 + n + 2

‚àö
n2+2
h) an = 2n sin(2‚àínœÄ)
i) an = n cos n + 1
n
œÄ
2
‚Ñì) an = n!
	
cos
1
‚àö
n!
‚àí1

4. Tell whether the following series converge; if they do, calculate their sum:
a)
‚àû

k=1
4
	1
3

k‚àí1
b)
‚àû

k=1
2k
k + 5

22
1 Numerical series
c)
‚àû

k=0
tan k
d)
‚àû

k=1
	
sin 1
k ‚àísin
1
k + 1

e)
‚àû

k=0
3k + 2k
6k
f)
‚àû

k=1
1
2 + 3‚àík
5.
Using the geometric series, write the number 2.317 = 2.3171717 . . . as a ratio
of integers.
6. Determine the values of the real number x for which the series below converge.
Then compute the sum:
a)
‚àû

k=2
xk
5k
b)
‚àû

k=1
3k(x + 2)k
c)
‚àû

k=1
1
xk
d)
‚àû

k=0
tank x
7.
Find the real numbers c such that
‚àû

k=2
(1 + c)‚àík = 2 .
8.
Suppose
‚àû

k=1
ak (ak Ã∏= 0) converges. Show that
‚àû

k=1
1
ak
cannot converge.
9. Study the convergence of the following positive-term series:
a)
‚àû

k=0
3
2k2 + 1
b)
‚àû

k=2
2k
k5 ‚àí3
c)
‚àû

k=0
3k
k!
d)
‚àû

k=1
k!
kk
e)
‚àû

k=1
k arcsin 7
k2
f)
‚àû

k=1
log
	
1 + 5
k2

g)
‚àû

k=1
log k
k
h)
‚àû

k=1
1
2k ‚àí1
i)
‚àû

k=1
sin 1
k
‚Ñì)
‚àû

k=0
2 + 3k
2k
m)
‚àû

k=1
k + 3
3‚àö
k9 + k2
n)
‚àû

k=1
cos2 k
k
‚àö
k

1.6 Exercises
23
10. Find the real numbers p such that
‚àû

k=2
1
k(log k)p converges.
11.
Estimate the sum s of the series
‚àû

k=0
1
k2 + 4 using the Ô¨Årst six terms.
12. Study the convergence of the following alternating series:
a)
‚àû

k=1
(‚àí1)k log
	1
k + 1

b)
‚àû

k=0
(‚àí1)k

k3 + 3
2k3 ‚àí5
c)
‚àû

k=1
sin
	
kœÄ + 1
k

d)
‚àû

k=1
(‚àí1)k
	
1 + 1
k2

‚àö
2
‚àí1

e)
‚àû

k=1
(‚àí1)k3k
4k ‚àí1
f)
‚àû

k=1
(‚àí1)k+1
k2
k3 + 1
13. Check that the series below converge. Determine the minimum number n of
terms necessary for the nth partial sum sn to approximate the sum with the
given margin:
a)
‚àû

k=1
(‚àí1)k+1
k4
,
|rn| < 10‚àí3
b)
‚àû

k=1
(‚àí2)k
k!
,
|rn| < 10‚àí2
c)
‚àû

k=1
(‚àí1)kk
4k
,
|rn| < 2 ¬∑ 10‚àí3
14. Study the absolute convergence of the following series:
a)
‚àû

k=1
(‚àí1)k‚àí1
3‚àö
k
b)
‚àû

k=1
(‚àí4)k
k4
c)
‚àû

k=1
(‚àí2)k
k!
d)
‚àû

k=1
cos 3k
k3
e)
‚àû

k=1
(‚àí1)k
k
k2 + 3
f)
‚àû

k=1
sin k œÄ
6
k
‚àö
k
g)
‚àû

k=1
(‚àí1)k+15k‚àí1
(k + 1)2 4k+2
h)
‚àû

k=1
10k
(k + 2) 52k+1

24
1 Numerical series
15. Study the convergence of the series:
a)
‚àû

k=1
	
1 ‚àícos 1
k3

b)
‚àû

k=1
sin k
k2
c)
‚àû

k=1
1
k3
	k
2

d)
‚àû

k=1
(‚àí1)k 
k‚àö
2 ‚àí1

e)
‚àû

k=1
(‚àí1)k‚àí1k!
1 ¬∑ 3 ¬∑ 5 ¬∑ ¬∑ ¬∑ (2k ‚àí1)
f)
‚àû

k=1
(‚àí1)k 3k ‚àí1
2k + 1
16. Verify the following series converge and then compute the sum:
a)
‚àû

k=1
(‚àí1)k 2k‚àí1
5k
b)
‚àû

k=1
3k
2 ¬∑ 42k
c)
‚àû

k=1
2k + 1
k2(k + 1)2
d)
‚àû

k=0
1
(2k + 1)(2k + 3)
1.6.1 Solutions
1. General terms and limits:
a)
an =
n
n + 1 , n ‚â•1 ,
lim
n‚Üí‚àûan = 1
b)
an = (‚àí1)n n + 1
3n
, n ‚â•1 ,
lim
n‚Üí‚àûan = 0
c)
an = ‚àön , n ‚â•0 ,
lim
n‚Üí‚àûan = +‚àû
2. Sequences‚Äô behaviour and limit:
a) Diverges to +‚àû.
b) Converges to 1
2.
c) Converges to 6.
d) Converges to 1.
e) Diverges to +‚àû.
f) Since lim
n‚Üí‚àû
n2
n2 + 1 = 1, the sequence is indeterminate because
lim
n‚Üí‚àûa2n = lim
n‚Üí‚àû‚àí
(2n)2
(2n)2 + 1 = ‚àí1 ,
lim
n‚Üí‚àûa2n+1 = lim
n‚Üí‚àû
(2n + 1)2
(2n + 1)2 + 1 = 1 .
g) Converges to œÄ
2 .
h) Recalling that cos nœÄ = (‚àí1)n, we conclude immediately that the series is
indeterminate.
i) Since {sin 1
n}n‚â•1 is inÔ¨Ånitesimal and {(‚àí1)n}n‚â•1 bounded, we have
lim
n‚Üí‚àû(‚àí1)n sin 1
n = 0 ,
hence the given sequence converges to 1.

1.6 Exercises
25
‚Ñì) Since

n cosn
n3 + 1
 ‚â§
n
n3 + 1 ‚â§n
n3 = 1
n2 ,
‚àÄn ‚â•1 ,
by the Comparison Test we have
lim
n‚Üí‚àû
n cosn
n3 + 1 = 0 .
m) Converges to 0.
n) We have
log(2 + en)
4n
= log en(1 + 2e‚àín)
4n
= 1
4 + log(1 + 2e‚àín)
4n
so lim
n‚Üí‚àûan = 1
4.
o) Diverges to ‚àí‚àû.
p) Converges to 0.
3. Sequences‚Äô behaviour:
a) Diverges to +‚àû.
b) Indeterminate.
c) Recalling the geometric sequence (Example 1.1 i)), we have
lim
n‚Üí‚àûan = lim
n‚Üí‚àû
4n 
( 3
4)n ‚àí1

4n(4‚àín + 1) = ‚àí1 ;
and the convergence to ‚àí1 follows.
d) Diverges to +‚àû.
e) Let us write
an = 2n(2n ‚àí1) ¬∑ ¬∑ ¬∑ (n + 2)(n + 1)
n(n + 1) ¬∑ ¬∑ ¬∑ 2 ¬∑ 1
= 2n
n ¬∑ 2n ‚àí1
n ‚àí1 ¬∑ ¬∑ ¬∑ n + 2
2
¬∑ n + 1
1
> n + 1 ;
as lim
n‚Üí‚àû(n+1) = +‚àû, the Second Comparison Theorem (inÔ¨Ånite case), implies
the sequence diverges to +‚àû.
f) Converges to 1.
g) Since
an = exp
	
n2 + 2 log n2 ‚àín + 1
n2 + n + 2

,
we consider the sequence
bn =

n2 + 2 log n2 ‚àín + 1
n2 + n + 2 =

n2 + 2 log
	
1 ‚àí
2n + 1
n2 + n + 2

.
Note that
lim
n‚Üí‚àû
2n + 1
n2 + n + 2 = 0 ,
so
log
	
1 ‚àí
2n + 1
n2 + n + 2

‚àº‚àí
2n + 1
n2 + n + 2 ,
n ‚Üí‚àû.

26
1 Numerical series
Thus
lim
n‚Üí‚àûbn = ‚àílim
n‚Üí‚àû
‚àö
n2 + 2 (2n + 1)
n2 + n + 2
= ‚àílim
n‚Üí‚àû
2n2
n2 = ‚àí2 ;
and the sequence {an} converges to e‚àí2.
h) Setting x = 2‚àínœÄ, we have x ‚Üí0+ for n ‚Üí‚àû, so
lim
n‚Üí‚àûan = lim
x‚Üí0+ œÄ sin x
x
= œÄ
and {an} tends to œÄ.
i) Observe
cos n + 1
n
œÄ
2 = cos
œÄ
2 + œÄ
2n

= ‚àísin œÄ
2n ;
therefore, setting x =
œÄ
2n, we have
lim
n‚Üí‚àûan = ‚àílim
n‚Üí‚àûn sin œÄ
2n = ‚àílim
x‚Üí0+
œÄ
2
sin x
x
= ‚àíœÄ
2
so {an} converges to ‚àíœÄ/2.
‚Ñì) Converges to ‚àí1/2.
4. Series‚Äô convergence and computation of the sum:
a) Converges with sum 6.
b) Note
lim
k‚Üí‚àûak = lim
k‚Üí‚àû
2k
k + 5 = 2 Ã∏= 0 .
Hence the series does not converge, in fact it diverges to +‚àû.
c) Does not converge.
d) The series is telescopic; we have
sn = (sin 1 ‚àísin 1
2) + (sin 1
2 ‚àísin 1
3) + ¬∑ ¬∑ ¬∑ + (sin 1
n ‚àísin
1
n + 1)
= sin 1 ‚àísin
1
n + 1 .
As lim
n‚Üí‚àûsn = sin 1, the series converges with sum sin 1.
e) Because
‚àû

k=0
3k + 2k
6k
=
‚àû

k=0
	3
6

k
+
‚àû

k=0
	2
6

k
=
1
1 ‚àí1
2
+
1
1 ‚àí1
3
= 7
2 ,
the series converges to 7/2.
f) Does not converge.

1.6 Exercises
27
5. Write
2.317 = 2.3 + 17
103 + 17
105 + 17
107 + . . . = 2.3 + 17
103
	
1 +
1
102 +
1
104 + . . .

= 2.3 + 17
103
‚àû

k=0
1
102k = 2.3 + 17
103
1
1 ‚àí
1
102
= 23
10 +
17
1000
100
99
= 23
10 + 17
990 = 1147
495 .
6. Series‚Äô convergence and computation of the sum:
a) Converges for |x| < 5 and the sum is s =
x2
5(5‚àíx).
b) This geometric series has q = 3(x + 2), so it converges if |3(x + 2)| < 1, i.e., if
x ‚àà(‚àí7
3, ‚àí5
3). For x in this range the sum is
s =
1
1 ‚àí3(x + 2) ‚àí1 = ‚àí3x + 6
3x + 5 .
c) Converges for x ‚àà(‚àí‚àû, ‚àí1) ‚à™(1, +‚àû) with sum s =
1
x‚àí1.
d) This is a geometric series where q = tan x: it converges if | tan x| < 1, that is
if x ‚àà
k‚ààZ

‚àíœÄ
4 + kœÄ, œÄ
4 + kœÄ

. For such x, the sum is s =
1
1‚àítan x.
7. This is a geometric series with q =
1
1+c, which converges for |1 + c| > 1, i.e., for
c < ‚àí2 or c > 0. If so,
‚àû

k=2
(1 + c)‚àík =
1
1 ‚àí
1
1‚àíc
‚àí1 ‚àí
1
1 ‚àíc =
1
c(1 + c) .
Imposing
1
c(1+c) = 2, we obtain c = ‚àí1¬±
‚àö
3
2
. But as the parameter c varies within
(‚àí‚àû, ‚àí2) ‚à™(0, +‚àû), the only admissible value is c = ‚àí1+
‚àö
3
2
.
8. As
‚àû

k=1
ak converges, the necessary condition lim
k‚Üí‚àûak = 0 must hold. Therefore
lim
k‚Üí‚àû
1
ak
is not allowed to be 0, so the series
‚àû

k=1
1
ak
cannot converge.
9. Convergence of positive-term series:
a) Converges.
b) The general term ak tends to +‚àûas k ‚Üí‚àû. By Property 1.6 the series
diverges to +‚àû. Alternatively, one could invoke the Root Test 1.15.

28
1 Numerical series
c) By the Ratio Test 1.14:
lim
k‚Üí‚àû
ak+1
ak
= lim
k‚Üí‚àû
3k+1
(k + 1)!
k!
3k ;
writing (k + 1)! = (k + 1)k! and simplifying, we get
lim
k‚Üí‚àû
ak+1
ak
= lim
k‚Üí‚àû
3
k + 1 = 0 .
The series then converges.
d) Using again the Ratio Test 1.14:
lim
k‚Üí‚àû
ak+1
ak
= lim
k‚Üí‚àû
(k + 1)!
(k + 1)k+1 ¬∑ kk
k! = lim
k‚Üí‚àû
	
k
k + 1

k
= 1
e < 1
tells that the series converges.
e) As
ak ‚àºk 7
k2 = 7
k
for
k ‚Üí‚àû,
we conclude that the series diverges, by the Asymptotic Comparison Test 1.12
and the fact that the harmonic series diverges.
f) Converges.
g) Note log k > 1 for k ‚â•3, so that
log k
k
> 1
k ,
k ‚â•3 .
The Comparison Test 1.10 guarantees divergence.
Alternatively, we may observe that the function f(x) = log x
x
is positive and
continuous for x > 1. The sign of the Ô¨Årst derivative shows f is decreasing
when x > e. We can therefore use the Integral Test 1.17:
 +‚àû
3
log x
x
dx =
lim
c‚Üí+‚àû
 c
3
log x
x
dx =
lim
c‚Üí+‚àû
(log x)2
2

c
3
=
lim
c‚Üí+‚àû
(log c)2
2
‚àí(log 3)2
2
= +‚àû,
then conclude that the given series diverges.
h) Converges by the Asymptotic Comparison Test 1.12, because
1
2k ‚àí1 ‚àº1
2k ,
k ‚Üí+‚àû,
and the geometric series
‚àû

k=1
1
2k converges.

1.6 Exercises
29
i) Diverges by the Asymptotic Comparison Test 1.12, because
sin 1
k ‚àº1
k ,
k ‚Üí+‚àû,
and the harmonic series
‚àû

k=1
1
k diverges.
‚Ñì) Diverges.
m) Converges.
n) Converges by the Comparison Test 1.10, as
cos2 k
k
‚àö
k
‚â§
1
k
‚àö
k
,
k ‚Üí+‚àû
and the generalised harmonic series
‚àû

k=1
1
k3/2 converges.
10. Converges for p > 1.
11. Compute
 +‚àû
n
f(x) dx where f(x) =
1
x2+4 is a positive, decreasing and con-
tinuous map on [0, +‚àû):
 +‚àû
n
1
x2 + 4 dx = 1
2

arctan x
2
+‚àû
n
= œÄ
4 ‚àí1
2 arctan n
2 .
Since
s6 = 1
4 + 1
5 + . . . + 1
40 = 0.7614 ,
using (1.8)
s6 +
 +‚àû
7
f(x) dx ‚â§s ‚â§s6 +
 +‚àû
6
f(x) dx ,
and we Ô¨Ånd 0.9005 ‚â§s ‚â§0.9223.
12. Convergence of alternating series:
a) Converges conditionally.
b) Does not converge.
c) Since
sin

kœÄ + 1
k

= cos(kœÄ) sin 1
k = (‚àí1)k sin 1
k ,
the series is alternating, with bk = sin 1
k. Then
lim
k‚Üí‚àûbk = 0
and
bk+1 < bk .
By Leibniz‚Äôs Test 1.20, the series converges. It does not converge absolutely
since sin 1
k ‚àº1
k for k ‚Üí‚àû, so the series of absolute values is like a harmonic
series, which diverges.

30
1 Numerical series
d) Converges absolutely: by the relationship (1 + x)Œ± ‚àí1 ‚àºŒ±x, for x ‚Üí0, it
follows
(‚àí1)k
1 + 1
k2
‚àö
2 ‚àí1
 ‚àº
‚àö
2
k2 ,
k ‚Üí‚àû.
Bearing in mind Example 1.11 i), we may apply the Asymptotic Comparison
Test 1.12 to the series of absolute values.
e) Does not converges.
f) This is an alternating series with bk =
k2
k3 + 1. It is straightforward to check
lim
k‚Üí‚àûbk = 0 .
That the sequence bk is decreasing eventually is, instead, far from obvious. To
show this fact, consider the map
f(x) =
x2
x3 + 1 ,
and consider its monotonicity. Since
f ‚Ä≤(x) = x(2 ‚àíx3)
(x3 + 1)2
and we are only interested in x positive, we have f ‚Ä≤(x) < 0 if 2 ‚àíx3 < 0,
i.e., x >
3‚àö
2. Therefore, f decreases on the interval (
3‚àö
2, +‚àû). This means
f(k + 1) < f(k), so bk+1 < bk for k ‚â•2. In conclusion, the series converges by
Leibniz‚Äôs Test 1.20.
13. Series‚Äô approximation:
a) n = 5.
b) The series is alternating with bk = 2k
k! . Immediately we see lim
k‚Üí‚àûbk = 0, and
bk+1 < bk for any k > 1 since
bk+1 =
2k+1
(k + 1)! < 2k
k! = bk
‚áê‚áí
2
k + 1 < 1
‚áê‚áí
k > 1 .
Imposing bn+1 < 10‚àí2 = 0.01, one may check that
b7 =
8
315 = 0.02 ,
b8 =
2
315 = 0.006 < 0.01 .
The minimum number of terms needed is n = 7.
c) n = 5.

1.6 Exercises
31
14. Absolute convergence:
a) There is convergence but not absolute convergence. In fact, the alternating
series converges by Leibnitz‚Äôs Test 1.20, whereas the series of absolute values
is generalised harmonic with exponent Œ± = 1
3 < 1.
b) Does not converge.
c) The series converges absolutely, as one sees easily by the Ratio Test 1.14, for
example, since
lim
k‚Üí‚àû
bk+1
bk
= lim
k‚Üí‚àû
2k+1
(k + 1)! ¬∑ k!
2k = lim
k‚Üí‚àû
2
k + 1 = 0 < 1 .
d) Convergence is absolute, since the series of absolute values converges by the
Comparison Test 1.10:

cos 3k
k3
 ‚â§1
k3 ,
‚àÄk ‚â•1 .
e) Converges, but not absolutely.
f) Converges absolutely.
g) Does not converge since its general term does not tend to 0.
h) Converges absolutely.
15. Convergence of series:
a) Converges.
b) Observe

sin k
k2
 ‚â§1
k2 ,
for all k > 0 ;
the series
‚àû

k=1
1
k2 converges, so the Comparison Test 1.10 forces the series of
absolute values to converge, too. Thus the given series converges absolutely.
c) Diverges.
d) This is an alternating series, with bk =
k‚àö
2‚àí1. The sequence {bk}k‚â•1 decreases,
as
k‚àö
2 >
k+1‚àö
2 for any k ‚â•1. Thus we can use Leibniz‚Äôs Test 1.20 to infer
convergence. The series does not converge absolutely, for
k‚àö
2 ‚àí1 = elog 2/k ‚àí1 ‚àºlog 2
k
,
k ‚Üí‚àû,
just like the harmonic series, which diverges.

32
1 Numerical series
e) Note
bk =
k!
1 ¬∑ 3 ¬∑ 5 ¬∑ ¬∑ ¬∑ (2k ‚àí1) = 1 ¬∑ 2
3 ¬∑ 3
5 ¬∑ ¬∑ ¬∑
k
2k ‚àí1 <
	2
3

k‚àí1
since
k
2k ‚àí1 < 2
3 ,
‚àÄk ‚â•2 .
The convergence is then absolute, because
‚àû

k=1
bk converges by the Comparison
Test 1.10 (it is bounded by a geometric series with q = 2
3 < 1).
f) Does not converge.
16. Checking series‚Äô convergence and computing the sum:
a) ‚àí1/7 .
b) Up to a factor this is a geometric series; by Example 1.3 iii) we have
‚àû

k=1
3k
2 ¬∑ 42k = 1
2
‚àû

k=1
	 3
16

k
= 1
2
	
1
1 ‚àí3
16
‚àí1

= 3
26
(notice that the sum starts from index 1).
c) It is a telescopic series because
2k + 1
k2(k + 1)2 = 1
k2 ‚àí
1
(k + 1)2 ;
so
sn = 1 ‚àí
1
(n + 1)2 ,
and then s = lim
n‚Üí‚àûsn = 1.
d) 1/2 .

2
Series of functions and power series
The idea of approximating a function by a sequence of simple functions, or known
ones, lies at the core of several mathematical techniques, both theoretical and
practical. For instance, to prove that a diÔ¨Äerential equation has a solution one
can construct recursively a sequence of approximating functions and show they
converge to the required solution. At the same time, explicitly Ô¨Ånding the values
of such a solution may not be possible, not even by analytical methods, so one idea
is to adopt numerical methods instead, which can furnish approximating functions
with a particularly simple form, like piecewise polynomials. It becomes thus crucial
to be able to decide when a sequence of maps generates a limit function, what sort
of convergence towards the limit we have, and which features of the functions in
the sequence are inherited by the limit. All this will be the content of the Ô¨Årst part
of this chapter.
The recipe for passing from a sequence of functions to the corresponding series
is akin to what we have seen for a sequence of real numbers; the additional com-
plication consists in the fact that now diÔ¨Äerent kinds of convergence can occur.
Expanding a function in series represents one of the most important tools of
Mathematical Analysis and its applications, again both from the theoretical and
practical point of view. Fundamental examples of series of functions are given by
power series, discussed in the second half of this chapter, and by Fourier series, to
which the whole subsequent chapter is dedicated. Other instances include series of
the classical orthogonal functions, like the expansions in Legendre, Chebyshev or
Hermite polynomials, Bessel functions, and so on.
In contrast to the latter cases, which provide a global representation of a func-
tion over an interval of the real line, power series have a more local nature; in fact,
a power series that converges on an interval (x0 ‚àíR, x0 + R) represents the limit
function therein just by using information on its behaviour on an arbitrarily small
neighbourhood of x0. The power series of a functions may actually be thought of
as a Taylor expansion of inÔ¨Ånite order, centred at x0. This fact reÔ¨Çects the intu-
itive picture of a power series as an algebraic polynomial of inÔ¨Ånite degree, that
is a sum of inÔ¨Ånitely many monomials of increasing degree. In the Ô¨Ånal sections
we will address the problem of rigorously determining the convergence set of a
C. Canuto, A. Tabacco: Mathematical Analysis II, 2nd Ed.,
UNITEXT ‚Äì La Matematica per il 3+2 85, DOI 10.1007/978-3-319-12757-6_2,
¬© Springer International Publishing Switzerland 2015

34
2 Series of functions and power series
power series; then we will study the main properties of power series and of series
of functions, called analytic functions, that can be expanded in series on a real
interval that does not reduce to a point.
2.1 Sequences of functions
Let X be an arbitrary subset of the real line. Suppose that there is a real map
deÔ¨Åned on X, which we denote fn : X ‚ÜíR, for any n larger or equal than a
certain n0 ‚â•0. The family {fn}n‚â•n0 is said sequence of functions. Examples
are the families fn(x) = sin(x + 1
n), n ‚â•1 or fn(x) = xn, n ‚â•0, on X = R.
As for numerical sequences, we are interested in the study of the behaviour of
a sequence of maps as n ‚Üí‚àû. The Ô¨Årst step is to analyse the numerical sequence
given by the values of the maps fn at each point of X.
DeÔ¨Ånition 2.1 The sequence {fn}n‚â•n0 converges pointwise at x ‚ààX if
the numerical sequence {fn(x)}n‚â•n0 converges as n ‚Üí‚àû. The subset A ‚äÜX
of such points x is called set of pointwise convergence of the sequence
{fn}n‚â•n0. This deÔ¨Ånes a map f : A ‚ÜíR by
f(x) = lim
n‚Üí‚àûfn(x) ,
‚àÄx ‚ààA .
We shall write fn ‚Üíf pointwise on A, and speak of the limit function f of
the sequence.
Note f is the limit function of the sequence if and only if
lim
n‚Üí‚àû|fn(x) ‚àíf(x)| = 0 ,
‚àÄx ‚ààA .
Examples 2.2
i) Let fn(x) = sin

x + 1
n

, n ‚â•1, on X = R. Observing that x + 1
n ‚Üíx as
n ‚Üí‚àû, and using the sine‚Äôs continuity, we have
f(x) = lim
n‚Üí‚àûsin

x + 1
n

= sin x ,
‚àÄx ‚ààR ,
hence A = X = R.
ii) Consider fn(x) = xn, n ‚â•0, on X = R; recalling (1.1) we have
f(x) = lim
n‚Üí‚àûxn =
 0
if ‚àí1 < x < 1 ,
1
if x = 1 .
(2.1)
The sequence converges for no other value x, so A = (‚àí1, 1].
2
The notion of pointwise convergence is not suÔ¨Écient, in many cases, to transfer
the properties of the single maps fn onto the limit function f. Continuity (but also
diÔ¨Äerentiability, or integrability) is one such case. In the above examples the maps
fn(x) are continuous, but the limit function is continuous in case i), not for ii).

2.1 Sequences of functions
35
A more compelling convergence requirement, that warrants continuity is passed
onto the limit, is the so-called uniform convergence. To understand the diÔ¨Äerence
with pointwise convergence, let us make DeÔ¨Ånition 2.1 explicit. This states that
for any point x ‚ààA and any Œµ > 0 there is an integer n such that
‚àÄn ‚â•n0 , n > n
=‚áí
|fn(x) ‚àíf(x)| < Œµ .
In general n depends not only upon Œµ but also on x, i.e., n = n(Œµ, x). In other
terms the index n, after which the values fn(x) approximate f(x) with a margin
smaller than Œµ, may vary from point to point. For example consider fn(x) = xn,
with 0 < x < 1; then the condition
|fn(x) ‚àíf(x)| = |xn ‚àí0| = xn < Œµ
holds for any n > log Œµ
log x. Therefore the smallest n for which the condition is valid
tends to inÔ¨Ånity as x approaches 1. Hence there is no n depending on Œµ and not
on x.
The convergence is said uniform whenever the index n can be chosen inde-
pendently of x. This means that, for any Œµ > 0, there must be an integer n such
that
‚àÄn ‚â•n0 , n > n
=‚áí
|fn(x) ‚àíf(x)| < Œµ ,
‚àÄx ‚ààA .
Using the notion of supremum and inÔ¨Åmum, and recalling Œµ is arbitrary, we can
reformulate as follows: for any Œµ > 0 there is an integer n such that
‚àÄn ‚â•n0 , n > n
=‚áí
sup
x‚ààA
|fn(x) ‚àíf(x)| < Œµ .
DeÔ¨Ånition 2.3 The sequence {fn}n‚â•n0 converges uniformly on A to the
limit function f if
lim
n‚Üí‚àûsup
x‚ààA
|fn(x) ‚àíf(x)| = 0 .
Otherwise said, for any Œµ > 0 there is an n = n(Œµ) such that
‚àÄn ‚â•n0 , n > n
=‚áí
|fn(x) ‚àíf(x)| < Œµ ,
‚àÄx ‚ààA .
(2.2)
We will write fn ‚Üíf uniformly on A.
Let us introduce the symbol
‚à•g‚à•‚àû,A = sup
x‚ààA
|g(x)| ,
for a bounded map g : A ‚ÜíR; this quantity is variously called inÔ¨Ånity norm,
supremum norm, or sup-norm for short (see Appendix A.2.1, p. 521, for a compre-
hensive presentation of the concept of norm of a function). An alternative deÔ¨Ånition
of uniform convergence is thus
lim
n‚Üí‚àû‚à•fn ‚àíf‚à•‚àû,A = 0 .
(2.3)

36
2 Series of functions and power series
Clearly, the uniform convergence of a sequence is a stronger condition than
pointwise convergence. By deÔ¨Ånition of sup-norm in fact,
‚àÄx ‚ààA ,
|fn(x) ‚àíf(x)| ‚â§‚à•fn ‚àíf‚à•‚àû,A
so if the norm on the right tends to 0, so does the absolute value on the left.
Therefore
Proposition 2.4 If the sequence {fn}n‚â•n0 converges to f uniformly on A,
it converges pointwise on A.
The converse is false, as some examples show.
Examples 2.5
i) The sequence fn(x) = sin

x + 1
n

, n ‚â•1, converges uniformly to f(x) = sin x
on R. In fact, using known trigonometric identities, we have, for any x ‚ààR,
 sin

x + 1
n

‚àísin x
 = 2
 sin 1
2n

 cos

x + 1
2n
 ‚â§2 sin 1
2n;
moreover, equality is attained for x = ‚àí1
2n, for example. Therefore
‚à•fn ‚àíf‚à•‚àû,R = sup
x‚ààR
 sin

x + 1
n

‚àísin x
 = 2 sin 1
2n
and passing to the limit for n ‚Üí‚àûwe obtain the result (see Fig. 2.1, left).
ii) As already seen, fn(x) = xn, n ‚â•0, does not converge uniformly on I = [0, 1]
to f deÔ¨Åned in (2.1). For any n ‚â•0 in fact, ‚à•fn‚àíf‚à•‚àû,I = sup
0‚â§x<1
xn = 1 (Fig. 2.1,
right). Nevertheless, the convergence is uniform on every sub-interval Ia = [0, a],
0 < a < 1, for
‚à•fn ‚àíf‚à•‚àû,Ia = sup
x‚àà[0,a]
|xn ‚àí0| = an ‚Üí0
as n ‚Üí‚àû.
Therefore the sequence converges to zero uniformly on Ia. More generally one can
show the sequence converges uniformly to zero on any interval [‚àía, a], 0 < a < 1.
2
The following criterion is immediate to check, and useful for verifying uniform
convergence.
Proposition 2.6 Let the sequence {fn}n‚â•n0 converge pointwise on A to a
function f. Take a numerical sequence {Mn}n‚â•n0, inÔ¨Ånitesimal for n ‚Üí‚àû,
such that
|fn(x) ‚àíf(x)| ‚â§Mn ,
‚àÄx ‚ààA .
Then fn ‚Üíf uniformly on A.
The property has been used in the previous examples, with Mn = 2 sin 1
2n for
case i), and Mn = an for ii).

2.2 Properties of uniformly convergent sequences
37
x
y
f10
f2
f1
sin x
x
y
f1
f2
f10
f100
1
f
Figure 2.1. Graphs of the functions fn and their limit f relative to Examples 2.5 i)
(left) and ii) (right)
2.2 Properties of uniformly convergent sequences
As announced earlier, under uniform convergence the limit function inherits con-
tinuity from the sequence.
Theorem 2.7 Let the sequence of continuous maps {fn}n‚â•n0 converge uni-
formly to f on the real interval I. Then f is continuous on I.
Proof.
By uniform convergence, given Œµ > 0, there is an n = n(Œµ) ‚â•n0 such that
for any n > n and any x ‚ààI
|fn(x) ‚àíf(x)| < Œµ
3 .
Fix x0 ‚ààI and take n > n. As fn is continuous at x0, there is a Œ¥ > 0 such
that, for each x ‚ààI with |x ‚àíx0| < Œ¥,
|fn(x) ‚àífn(x0)| < Œµ
3 .
Let therefore x ‚ààI with |x ‚àíx0| < Œ¥. Then
|f(x) ‚àíf(x0)| ‚â§|f(x) ‚àífn(x)| + |fn(x) ‚àífn(x0)| +
+|fn(x0) ‚àíf(x0)| < Œµ
3 + Œµ
3 + Œµ
3 = Œµ ,
so f is continuous at x0 .
2
This result can be used to say that pointwise convergence is not always uniform.
In fact if the limit function is not continuous while the single terms in the sequence
are, the convergence cannot be uniform.

38
2 Series of functions and power series
2.2.1 Interchanging limits and integrals
Suppose fn ‚Üíf pointwise on I = [a, b]. If the maps are integrable, it is not true,
in general, that
 b
a
fn(x) dx ‚Üí
 b
a
f(x) dx .
Example 2.8
Let fn(x) = xn2e‚àínx on I = [0, 1]. Then fn(x) ‚Üí0 = f(x), as n ‚Üí‚àû, pointwise
on I. Therefore
 1
0
f(x) dx = 0; on the other hand, setting œï(t) = te‚àít we have
 1
0
fn(x) dx =
 1
0
œï(nx)n dx =
 n
0
œï(t) dt = ‚àíne‚àín +

‚àíe‚àítn
0
= ‚àíne‚àín ‚àíe‚àín + 1 ‚Üí1
for n ‚Üí‚àû.
2
Uniform convergence is a suÔ¨Écient condition for transferring integrability to
the limit.
Theorem 2.9 Let I = [a, b] be a closed, bounded interval and {fn}n‚â•n0 a
sequence of integrable functions over I such that fn ‚Üíf uniformly on I.
Then f is integrable on I, and
 b
a
fn(x) dx ‚Üí
 b
a
f(x) dx
as n ‚Üí‚àû.
(2.4)
Proof.
The integrability of the limit function is immediate if each fn is continuous,
for in that case f itself is continuous by the previous theorem. In general,
one needs to approximate the functions by means of step functions, as
prescribed by the deÔ¨Ånition of an integrable map; the details are left to
the reader‚Äôs good will.
In order to prove (2.4), let us Ô¨Åx Œµ > 0; then there exists an n = n(Œµ) ‚â•n0
such that, for any n > n and any x ‚ààI,
|fn(x) ‚àíf(x)| <
Œµ
b ‚àía .
Therefore, for all n > n, we have

 b
a
fn(x) dx ‚àí
 b
a
f(x) dx
 =

 b
a

fn(x) ‚àíf(x)

dx

‚â§
 b
a
|fn(x) ‚àíf(x)| dx <
 b
a
Œµ
b ‚àía dx = Œµ .
2

2.2 Properties of uniformly convergent sequences
39
Note that (2.4) can be written as
lim
n‚Üí‚àû
 b
a
fn(x) dx =
 b
a
lim
n‚Üí‚àûfn(x) dx ,
showing that uniform convergence allows to exchange the operations of limit and
integration.
2.2.2 Interchanging limits and derivatives
When considering limits of diÔ¨Äerentiable functions, certain assumptions on uniform
convergence guarantee the diÔ¨Äerentiability of the limit.
Theorem 2.10 Let {fn}n‚â•n0 be a sequence of C1 functions over the interval
I = [a, b]. Suppose there exist maps f and g on I such that
i) fn ‚Üíf pointwise on I;
ii) f ‚Ä≤
n ‚Üíg uniformly on I.
Then f is C1 on I, and f ‚Ä≤ = g. Moreover, fn ‚Üíf uniformly on I (and clearly,
f ‚Ä≤
n ‚Üíf ‚Ä≤ uniformly on I).
Proof.
Fix an arbitrary x0 ‚ààI and set
Àúf(x) = f(x0) +
 x
x0
g(t) dt .
(2.5)
We show Ô¨Årst that fn ‚ÜíÀúf uniformly on I. For this, let Œµ > 0 be given. By
i), there exists n1 = n1(Œµ; x0) ‚â•n0 such that for any n > n1 we have
|fn(x0) ‚àíf(x0)| < Œµ
2 .
By ii), there is n2 = n2(Œµ) ‚â•n0 such that, for any n > n2 and any t ‚àà[a, b],
|f ‚Ä≤
n(t) ‚àíg(t)| <
Œµ
2(b ‚àía) .
Note we may write each map fn as
fn(x) = fn(x0) +
 x
x0
f ‚Ä≤
n(t) dt ,
because of the Fundamental Theorem of Integral Calculus (see Vol. I,
Cor. 9.42). Thus, for any n > n = max(n1, n2) and any x ‚àà[a, b], we have
|fn(x) ‚àíÀúf(x)| =
fn(x0) ‚àíf(x0) +
 x
x0

f ‚Ä≤
n(t) ‚àíg(t)

dt


40
2 Series of functions and power series
‚â§|fn(x0) ‚àíf(x0)| +
 x
x0
|f ‚Ä≤
n(t) ‚àíg(t)| dt
< Œµ
2 +
Œµ
2(b ‚àía)
 b
a
dt = Œµ
2 + Œµ
2 = Œµ .
Therefore fn ‚ÜíÀúf uniformly on I, hence also pointwise, by Proposition
2.4. But fn ‚Üíf pointwise on I by assumption; by the uniqueness of the
limit then, Àúf coincides with f. From (2.5) and the Fundamental Theorem
of Integral Calculus it follows that f is diÔ¨Äerentiable with Ô¨Årst derivative g.
2
Under the theorem‚Äôs assumptions then,
lim
n‚Üí‚àûf ‚Ä≤
n(x) =

lim
n‚Üí‚àûfn(x)
‚Ä≤
,
‚àÄx ‚ààI ,
so the uniform convergence (of the Ô¨Årst derivatives) allows to exchange the limit
and the derivative.
Remark 2.11 A more general result, with similar proof, states that if a sequence
{fn}n‚â•n0 of C1 maps satisÔ¨Åes these two properties:
i)
there is an x0 ‚àà[a, b] such that lim
n‚Üí‚àûfn(x0) = ‚Ñì‚ààR;
ii) the sequence {f ‚Ä≤
n}n‚â•n0 converges uniformly on I to a map g (necessarily con-
tinuous on I),
then, setting
f(x) = ‚Ñì+
 x
x0
g(t) dt ,
fn converges uniformly to f on I. Furthermore, f ‚ààC1 and f ‚Ä≤(x) = g(x) for any
x ‚àà[a, b].
2
Remark 2.12 An example will explain why mere pointwise convergence of the
derivatives is not enough to conclude as in the theorem, even in case the sequence
of functions converges uniformly. Consider the sequence fn(x) = x ‚àíxn/n; it
converges uniformly on I = [0, 1] to f(x) = x because
|fn(x) ‚àíf(x)| =

xn
n
 ‚â§1
n ,
‚àÄx ‚ààI ,
and hence
‚à•fn ‚àíf‚à•‚àû,I ‚â§1
n ‚Üí0
as n ‚Üí‚àû.
Yet the derivatives f ‚Ä≤
n(x) = 1 ‚àíxn‚àí1 converge to the discontinuous function

2.3 Series of functions
41
g(x) =
 1
if x ‚àà[0, 1) ,
0
if x = 1 .
So {f ‚Ä≤
n}n‚â•0 converges only pointwise to g on [0, 1], not uniformly, and the latter
does not coincide on I with the derivative of f.
2
2.3 Series of functions
Starting with a sequence of functions {fk}k‚â•k0 deÔ¨Åned on a set X ‚äÜR, we can
build a series of functions
‚àû

k=k0
fk in a similar fashion to numerical sequences and
series. Precisely, we consider how the sequence of partial sums
sn(x) =
n

k=k0
fk(x)
behaves as n ‚Üí‚àû. DiÔ¨Äerent types of convergence can occur.
DeÔ¨Ånition 2.13 The series of functions
‚àû

k=k0
fk converges pointwise at x
if the sequence of partial sums {sn}n‚â•k0 converges pointwise at x; equivalently,
the numerical series
‚àû

k=k0
fk(x) converges. Let A ‚äÜX be the set of such points
x, called the set of pointwise convergence of
‚àû

k=k0
fk; we have thus deÔ¨Åned
the function s : A ‚ÜíR, called sum, by
s(x) = lim
n‚Üí‚àûsn(x) =
‚àû

k=k0
fk(x) ,
‚àÄx ‚ààA .
The pointwise convergence of a series of functions can be studied using at each
point x ‚ààX what we already know about numerical series. In particular, the
sequence {fk(x)}k‚â•k0 must be inÔ¨Ånitesimal, as k ‚Üí‚àû, in order for x to belong
to A. What is more, the convergence criteria seen in the previous chapter can be
applied, at each point.
DeÔ¨Ånition 2.14 The series of functions
‚àû

k=k0
fk converges absolutely on
A if for any x ‚ààA the series
‚àû

k=k0
|fk(x)| converges.

42
2 Series of functions and power series
DeÔ¨Ånition 2.15 The series of functions
‚àû

k=k0
fk converges uniformly to
the function s on A if the sequence of partial sums {sn}n‚â•k0 converges uni-
formly to s on A.
Both the absolute convergence (due to Theorem 1.24) and the uniform conver-
gence (Proposition 2.4) imply the pointwise convergence of the series. There are
no logical implications between uniform and absolute convergence, instead.
Example 2.16
The series
‚àû

k=0
xk is nothing but the geometric series of Example 1.3 where
q is taken as independent variable and re-labelled x. Thus, the series converges
pointwise to the sum s(x) =
1
1‚àíx on A = (‚àí1, 1); on the same set there is absolute
convergence as well. As for uniform convergence, it holds on every closed interval
[‚àía, a] with 0 < a < 1. In fact,
|sn(x) ‚àís(x)| =

1 ‚àíxn+1
1 ‚àíx
‚àí
1
1 ‚àíx
 = |x|n+1
1 ‚àíx ‚â§an+1
1 ‚àía ,
where we have used the fact that |x| ‚â§a implies 1 ‚àía ‚â§1 ‚àíx. Moreover,
the sequence Mn =
an+1
1‚àía tends to 0 as n ‚Üí‚àû, and the result follows from
Proposition 2.6.
2
It is clear from the deÔ¨Ånitions just given that Theorems 2.7, 2.9 and 2.10 can
be formulated for series of functions, so we re-phrase them for completeness‚Äô sake.
Theorem 2.17 Let {fk}k‚â•k0 be a sequence of continuous maps on a real
interval I such that the series
‚àû

k=k0
fk converges uniformly to a function s on
I. Then s is continuous on I.
Theorem 2.18 (Integration by series) Let I = [a, b] be a closed bounded
interval and {fk}k‚â•k0 a sequence of integrable functions on I such that
‚àû

k=k0
fk
converges uniformly to a function s on I. Then s is integrable on I, and
 b
a
s(x) dx =
 b
a
‚àû

k=k0
fk(x) dx =
‚àû

k=k0
 b
a
fk(x) dx .
(2.6)

2.3 Series of functions
43
This is worded alternatively by saying that the series is integrable term by term.
Theorem 2.19 (DiÔ¨Äerentiation of series) Let {fk}k‚â•k0 be a sequence of
C1 maps on I = [a, b]. Suppose there are maps s and t on I such that
i)
‚àû

k=k0
fk(x) = s(x) ,
‚àÄx ‚ààI;
ii)
‚àû

k=k0
f ‚Ä≤
k(x) = t(x) ,
‚àÄx ‚ààI and the convergence is uniform on I.
Then s ‚ààC1(I) and s‚Ä≤ = t. Furthermore,
‚àû

k=k0
fk converges uniformly to s on
I (and
‚àû

k=k0
f ‚Ä≤
k converges uniformly to s‚Ä≤).
That is to say,
‚àû

k=k0
f ‚Ä≤
k(x) =
 ‚àû

k=k0
fk(x)
‚Ä≤
,
‚àÄx ‚ààI ,
and the series is diÔ¨Äerentiable term by term.
The importance of uniform convergence should be clear by now. But checking
uniform convergence is another matter, often far from easy. Using the deÔ¨Ånition
requires knowing the sum, and as we have seen with numerical series, the sum is not
always computable explicitly. For this reason we will prove a condition suÔ¨Écient
to guarantee the uniform convergence of a series, even without knowing its sum in
advance.
Theorem 2.20 (Weierstrass‚Äô M-test) Let {fk}k‚â•k0 be a sequence of maps
on X and {Mk}k‚â•k0 a sequence of real numbers such that, for any k ‚â•k0,
|fk(x)| ‚â§Mk ,
‚àÄx ‚ààX .
Assume the numerical series
‚àû

k=k0
Mk converges. Then the series
‚àû

k=k0
fk con-
verges uniformly on X.

44
2 Series of functions and power series
Proof.
Fix x ‚ààX, so that the numerical series
‚àû

k=k0
|fk(x)| converges by the
Comparison Test, and hence the sum
s(x) =
‚àû

k=k0
fk(x) ,
‚àÄx ‚ààX ,
is well deÔ¨Åned. It suÔ¨Éces to check whether the partial sums {sn}n‚â•k0
converge uniformly to s on X. But for any x ‚ààX,
|sn(x) ‚àís(x)| =

‚àû

k=n+1
fk(x)
 ‚â§
‚àû

k=n+1
|fk(x)| ‚â§
‚àû

k=n+1
Mk ,
i.e.,
sup
x‚ààX
|sn(x) ‚àís(x)| ‚â§
‚àû

k=n+1
Mk .
As the series
‚àû

k=k0
Mk converges, the right-hand side is just the nth re-
mainder of a converging series, which goes to 0 as n ‚Üí‚àû.
In conclusion,
lim
n‚Üí‚àûsup
x‚ààX
|sn(x) ‚àís(x)| = 0
so
‚àû

k=k0
fk converges uniformly on X.
2
Example 2.21
We want to understand the uniform and pointwise convergence of
‚àû

k=1
sin k4x
k
‚àö
k
,
x ‚ààR .
Note

sin k4x
k
‚àö
k
 ‚â§
1
k
‚àö
k
,
‚àÄx ‚ààR ;
we may then use the M-test with Mk =
1
k
‚àö
k, since the series
‚àû

k=1
1
k3/2 converges
(it is generalised harmonic of exponent 3/2). Therefore the given series converges
uniformly, hence also pointwise, on R.
2
2.4 Power series
Power series are very special series in which the maps fk are polynomials. More
precisely,

2.4 Power series
45
DeÔ¨Ånition 2.22 Fix x0 ‚ààR and let {ak}k‚â•0 be a numerical sequence. One
calls power series a series of the form
‚àû

k=0
ak(x ‚àíx0)k = a0 + a1(x ‚àíx0) + a2(x ‚àíx0)2 + ¬∑ ¬∑ ¬∑
(2.7)
The point x0 is said centre of the series and the numbers {ak}k‚â•0 are the
series‚Äô coeÔ¨Écients.
The series converges at its centre, irrespective of the coeÔ¨Écients.
The next three examples exhaust the possible types of convergence set of a
series. We will show that such set is always an interval (possibly shrunk to the
centre).
Examples 2.23
i) The series
‚àû

k=1
kkxk = x + 4x2 + 27x3 + ¬∑ ¬∑ ¬∑
converges only at x = 0; in fact at any other x Ã∏= 0 the general term kkxk
is not inÔ¨Ånitesimal, so the necessary condition for convergence is not fulÔ¨Ålled
(Property 1.6).
ii) Consider
‚àû

k=0
xk
k! = 1 + x + x2
2! + x3
3! + ¬∑ ¬∑ ¬∑ ;
(2.8)
it is known as exponential series, because it sums to the function s(x) = ex.
This fact will be proved later in Example 2.46 i).
The exponential series converges for any x ‚ààR. Indeed, with a given x Ã∏= 0, the
Ratio Test for numerical series (Theorem 1.14) guarantees convergence:
lim
k‚Üí‚àû

xk+1
(k + 1)! ¬∑ k!
xk
 = lim
k‚Üí‚àû
|x|
k + 1 = 0 ,
‚àÄx ‚ààR \ {0} .
iii) Another familiar example is the geometric series
‚àû

k=0
xk = 1 + x + x2 + x3 + ¬∑ ¬∑ ¬∑
(recall Example 2.16). We already know it converges, for x ‚àà(‚àí1, 1), to the
function s(x) =
1
1‚àíx.
2
In all examples the series converge (absolutely) on a symmetric interval with
respect to the centre (the origin, in the speciÔ¨Åc cases). We will see that the con-
vergence set A of any power series, independently of the coeÔ¨Écients, is either a
bounded interval (open, closed or half-open) centered at x0, or the whole R.

46
2 Series of functions and power series
We start by series centered at the origin; this is no real restriction, because the
substitution y = x ‚àíx0 allows to reduce to that case.
Before that though, we need a technical result, direct consequence of the Com-
parison Test for numerical series (Theorem 1.10), which will be greatly useful for
power series.
Proposition 2.24 If the series
‚àû

k=0
akxk, x Ã∏= 0, has bounded terms, in par-
ticular if it converges, then the power series
‚àû

k=0
akxk converges absolutely for
any x such that |x| < |x|.
Proof.
As akxk is bounded, there is a constant M > 0 such that
|akxk| ‚â§M ,
‚àÄk ‚â•0 .
For any x with |x| < |x| then,
|akxk| =
akxk x
x
k ‚â§M
x
x

k
,
‚àÄk ‚â•0 .
But |x| < |x|, so the geometric series
‚àû

k=0
x
x
k
converges absolutely and,
by the Comparison Test,
‚àû

k=0
akxk converges absolutely.
2
Example 2.25
The series
‚àû

k=0
k ‚àí1
k + 1xk has bounded terms when x = ¬±1, since

k ‚àí1
k + 1
 ‚â§1 for
any k ‚â•0. The above proposition forces convergence when |x| < 1. The series
does not converge when |x| ‚â§1 because, in case x = ¬±1, the general term is not
inÔ¨Ånitesimal.
2
Proposition 2.24 has an immediate, yet crucial, consequence.
Corollary 2.26 If a power series
‚àû

k=0
akxk converges at x1 Ã∏= 0, it con-
verges absolutely on the open interval (‚àí|x1|, |x1|); if it does not converge
at x2 Ã∏= 0, it does not converge anywhere along the half-lines (|x2|, +‚àû) and
(‚àí‚àû, ‚àí|x2|).

2.4 Power series
47
0
x1
‚àíx2
‚àíx1
x2
no convergence
convergence
Figure 2.2. Illustration of Corollary 2.26
The statement is depicted in Fig. 2.2, for x1 > 0 and x2 < 0.
Now we are in a position to prove that the convergence set of a power series is
a symmetric interval, end-points excluded.
Theorem 2.27 Given a power series
‚àû

k=0
akxk, only one of the following
holds:
a) the series converges at x = 0 only;
b) the series converges pointwise and absolutely for any x ‚ààR; moreover, it
converges uniformly on every closed and bounded interval [a, b];
c) there is a unique real number R > 0 such that the series converges
pointwise and absolutely for any |x| < R, and uniformly on all intervals
[a, b] ‚äÇ(‚àíR, R). Furthermore, the series does not converge on |x| > R.
Proof.
Let A denote the set of convergence of
‚àû

k=0
akxk.
If A = {0}, we have case a).
Case b) occurs if A = R. In fact, Corollary 2.26 tells the series converges
pointwise and absolutely for any x ‚ààR. As for the uniform convergence
on [a, b], set L = max(|a|, |b|). Then
|fk(x)| = |akxk| ‚â§|akLk| ,
‚àÄx ‚àà[a, b] ;
and we may use Weierstrass‚Äô M-test 2.20 with Mk = |ak|Lk.
Now suppose A contains points other than 0 but is smaller that the whole
line, so there is an x /‚ààA. Corollary 2.26 says A cannot contain any x with
|x| > |x|, meaning that A is bounded. Set R = sup A, so R > 0 because A
is larger than {0}. Consider an arbitrary x with |x| < R: by deÔ¨Ånition of
supremum there is an x1 such that |x| < x1 < R and
‚àû

k=0
akxk
1 converges.
Hence Corollary 2.26 tells the series converges pointwise and absolutely at
x. For uniform convergence we proceed exactly as in case b). At last, by
deÔ¨Ånition of sup the set A cannot contain values x > R, but neither values

48
2 Series of functions and power series
x < ‚àíR (again by Corollary 2.26). Thus if |x| > R the series
‚àû

k=0
akxk does
not converge.
2
DeÔ¨Ånition 2.28 One calls convergence radius of the series
‚àû

k=0
akxk the
number
R = sup

x ‚ààR :
‚àû

k=0
akxk converges

.
Going back to Theorem 2.27, we remark that R = 0 in case a); in case b),
R = +‚àû, while in case c), R is precisely the strictly-positive real number of the
statement.
Examples 2.29
Let us return to Examples 2.23.
i) The series
‚àû

k=1
kkxk has convergence radius R = 0.
ii) For
‚àû

k=0
xk
k! the radius is R = +‚àû.
iii) The series
‚àû

k=0
xk has radius R = 1.
2
Beware that the theorem says nothing about the behaviour at x = ¬±R: the
series might converge at both end-points, at one only, or at none, as in the next
examples.
Examples 2.30
i) The series
‚àû

k=1
xk
k2
converges at x = ¬±1 (generalised harmonic of exponent 2 for x = 1, alternat-
ing for x = ‚àí1). It does not converge on |x| > 1, as the general term is not
inÔ¨Ånitesimal. Thus R = 1 and A = [‚àí1, 1].
ii) The series
‚àû

k=1
xk
k
converges at x = ‚àí1 (alternating harmonic series) but not at x = 1 (harmonic
series). Hence R = 1 and A = [‚àí1, 1).

2.4 Power series
49
iii) The geometric series
‚àû

k=1
xk
converges only on A = (‚àí1, 1) with radius R = 1.
2
Convergence at one end-point ensures the series converges uniformly on closed
intervals containing that end-point. Precisely, we have
Theorem 2.31 (Abel) Suppose R > 0 is Ô¨Ånite. If the series converges at
x = R, then the convergence is uniform on every interval [a, R] ‚äÇ(‚àíR, R].
The analogue statement holds if the series converges at x = ‚àíR.
If we now center a power series at a generic x0, the previous results read as
follows. The radius R is 0 if and only if
‚àû

k=0
ak(x‚àíx0)k converges only at x0, while
R = +‚àûif and only if the series converges at any x in R. In the remaining case
R is positive and Ô¨Ånite, and Theorem 2.27 says the set A of convergence satisÔ¨Åes
{x ‚ààR : |x ‚àíx0| < R} ‚äÜA ‚äÜ{x ‚ààR : |x ‚àíx0| ‚â§R} .
The importance of determining the radius of convergence is evident. The next
two criteria, easy consequences of the analogous Ratio and Root Tests for numerical
series, give a rather simple yet useful answer.
Theorem 2.32 (Ratio Test) Given the power series
‚àû

k=0
ak(x ‚àíx0)k
with ak Ã∏= 0 for all k ‚â•0, if the limit
lim
k‚Üí‚àû

ak+1
ak
 = ‚Ñì
exists, the radius of convergence R is given by
R =
‚éß
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é©
0
if ‚Ñì= +‚àû,
+‚àû
if ‚Ñì= 0 ,
1
‚Ñì
if 0 < ‚Ñì< +‚àû.
(2.9)

50
2 Series of functions and power series
Proof.
For simplicity suppose x0 = 0, and let x Ã∏= 0. The claim follows by the
Ratio Test 1.14 since
lim
k‚Üí‚àû

ak+1xk+1
akxk
 = lim
k‚Üí‚àû

ak+1
ak
 |x| = ‚Ñì|x| .
When ‚Ñì= +‚àû, we have ‚Ñì|x| > 1 and the series does not converge for any
x Ã∏= 0, so R = 0; when ‚Ñì= 0, ‚Ñì|x| = 0 < 1 and the series converges for any
x, so R = +‚àû. At last, when ‚Ñìis Ô¨Ånite and non-zero, the series converges
for all x such that ‚Ñì|x| < 1, so for |x| < 1/‚Ñì, and not for |x| > 1/‚Ñì; therefore
R = 1/‚Ñì.
2
Theorem 2.33 (Root Test) Given the power series
‚àû

k=0
ak(x ‚àíx0)k ,
if the limit
lim
k‚Üí‚àû
k
|ak| = ‚Ñì
exists, the radius R is given by formula (2.9).
The proof, left to the reader, relies on the Root Test 1.15 and follows the same
lines.
Examples 2.34
i) The series
‚àû

k=0
kxk
has radius R = 1, because lim
k‚Üí‚àû
k‚àö
k = 1; it does not
converge for x = 1 nor for x = ‚àí1.
ii) Consider
‚àû

k=0
k!
kk xk
and use the Ratio Test:
lim
k‚Üí‚àû
(k + 1)!
(k + 1)k+1 ¬∑ kk
k! = lim
k‚Üí‚àû
	
k
k + 1

k
= lim
k‚Üí‚àû
	
1 + 1
k

‚àík
= e‚àí1 .
The radius is thus R = e.
iii) To study
‚àû

k=2
2k + 1
(k ‚àí1)(k + 2)(x ‚àí2)2k
(2.10)

2.4 Power series
51
set y = (x ‚àí2)2 and consider the power series in y
‚àû

k=2
2k + 1
(k ‚àí1)(k + 2)yk
(2.11)
centred at the origin. Since
lim
k‚Üí‚àû
k
 
2k + 1
(k ‚àí1)(k + 2) = 1
the radius is 1. For y = 1 the series (2.11) reduces to
‚àû

k=2
2k + 1
(k ‚àí1)(k + 2) ,
which diverges like the harmonic series (
2k+1
(k‚àí1)(k+2) ‚àº2
k , k ‚Üí‚àû), whereas for
y = ‚àí1 the series (2.11) converges (by Leibniz‚Äôs Test 1.20). In summary, (2.11)
converges for ‚àí1 ‚â§y < 1.
Going back to the variable x, that means ‚àí1 ‚â§(x ‚àí2)2 < 1. The left inequality
is always true, while the right one holds for ‚àí1 < x ‚àí2 < 1. So, the series (2.10)
has radius R = 1 and converges on the interval (1, 3) (note the centre is x0 = 2).
iv) The series
‚àû

k=0
xk! = x + x + x2 + x6 + x24 + ¬∑ ¬∑ ¬∑
is a power series where inÔ¨Ånitely many coeÔ¨Écients are 0, and we cannot substitute
as we did before; in such cases the aforementioned criteria do not apply, and it
is more convenient to use directly the Ratio or Root Test for numerical series.
In the case at hand
lim
k‚Üí‚àû

x(k+1)!
xk!
 = lim
k‚Üí‚àû|x|(k+1)!‚àík!
= lim
k‚Üí‚àû|x|k!k =
! 0
if |x| < 1 ,
+‚àû
if |x| > 1 .
Thus R = 1. The series converges neither for x = 1, nor for x = ‚àí1.
v) Consider, for Œ± ‚ààR, the binomial series
‚àû

k=0
	Œ±
k

xk .
If Œ± = n ‚ààN the series is actually a Ô¨Ånite sum, and Newton‚Äôs binomial formula
(Vol. I, Eq. (1.13)) tells us that
n

k=0
	n
k

xk = (1 + x)n ,
hence the name. Let us then study for Œ± ‚ààR \ N and observe

 Œ±
k+1

Œ±
k

= |Œ±(Œ± ‚àí1) ¬∑ ¬∑ ¬∑ (Œ± ‚àík)|
(k + 1)!
¬∑
k!
|Œ±(Œ± ‚àí1) ¬∑ ¬∑ ¬∑ (Œ± ‚àík + 1)| = |Œ± ‚àík|
k + 1 ;

52
2 Series of functions and power series
therefore
lim
k‚Üí‚àû

 Œ±
k+1

Œ±
k

= lim
k‚Üí‚àû
|Œ± ‚àík|
k + 1 = 1
and the series has radius R = 1. The behaviour of the series at the endpoints
cannot be studied by one of the criteria presented above; one can prove that the
series converges at x = ‚àí1 only for Œ± > 0 and at x = 1 only for Œ± > ‚àí1.
2
2.4.1 Algebraic operations
The operations of sum and product of two polynomials extend in a natural manner
to power series centred at the same point x0; the problem remains of determining
the radius of convergence of the resulting series. This is addressed in the next
theorems, where x0 will be 0 for simplicity.
Theorem 2.35 Given Œ£1 =
‚àû

k=0
akxk and Œ£2 =
‚àû

k=0
bkxk , of respect-
ive radii R1, R2, their sum Œ£ =
‚àû

k=0
(ak + bk)xk has radius R satisfying
R ‚â•min(R1, R2). If R1 Ã∏= R2, necessarily R = min(R1, R2).
Proof.
Suppose R1 Ã∏= R2; we may assume R1 < R2. Given any point x such that
R1 < x < R2, if the series Œ£ converged we would have
Œ£1 =
‚àû

k=0
akxk =
‚àû

k=0
(ak + bk)xk ‚àí
‚àû

k=0
bkxk = Œ£ ‚àíŒ£2 ,
hence also the series Œ£1 would have to converge, contradicting the fact
that x > R1. Therefore R = R1 = min(R1, R2).
In case R1 = R2, the radius R is at least equal to such value, since the
sum of two convergent series is convergent (see Sect. 1.5).
2
In case R1 = R2, the radius R might be strictly larger than both R1, R2 due
to possible cancellations of terms in the sum.
Example 2.36
The series
Œ£1 =
‚àû

k=1
2k + 1
4k ‚àí2k xk
and
Œ£2 =
‚àû

k=1
1 ‚àí2k
4k + 2k xk
have the same radius R1 = R2 = 2. Their sum
Œ£ =
‚àû

k=1
4
4k ‚àí1 xk ,
though, has radius R = 4.
2

2.4 Power series
53
The product of two series is deÔ¨Åned so that to preserve the distributive property
of the sum with respect to the multiplication. In other words,
(a0 + a1x + a2x2 + . . .)(b0 + b1x + b2x2 + . . .)
= a0b0 + (a0b1 + a1b0)x + (a0b2 + a1b1 + a2b0)x2 + . . . ,
i.e.,
 ‚àû

k=0
akxk ‚àû

k=0
bkxk
=
‚àû

k=0
ckxk
(2.12)
where
ck =
k

j=0
ajbk‚àíj .
This multiplication rule is called Cauchy product: putting x = 1 returns precisely
the Cauchy product (1.9) of numerical series. Then we have the following result.
Theorem 2.37 Given Œ£1 =
‚àû

k=0
akxk and Œ£2 =
‚àû

k=0
bkxk , of respective radii
R1, R2, their Cauchy product has convergence radius R ‚â•min(R1, R2).
2.4.2 DiÔ¨Äerentiation and integration
Let us move on to consider the regularity of the sum of a power series. We have
already remarked that the functions fk(x) = ak(x ‚àíx0)k are C‚àûpolynomials
over all of R. In particular they are continuous and their sum s(x) is continuous,
where deÔ¨Åned (using Theorem 2.17), because the convergence is uniform on closed
intervals in the convergence set (Theorem 2.31). Let us see in detail how term-by-
term diÔ¨Äerentiation and integration Ô¨Åt with power series. For clarity we assume
x0 = 0 and begin with a little technical fact.
Lemma 2.38 The series "
1 =
‚àû

k=0
akxk and "
2 =
‚àû

k=0
kakxk have the same
radius of convergence.
Proof.
Call R1, R2 the radii of "
1, "
2 respectively. Clearly R2 ‚â§R1 (for |akxk| ‚â§
|kakxk|). On the other hand if |x| < R1 and x satisÔ¨Åes |x| < x < R1,
the series
‚àû

k=0
akxk converges and so |ak|xk is bounded from above by a
constant M > 0 for any k ‚â•0. Hence
|kakxk| = k|ak|xk x
x

k
‚â§Mk
x
x

k
.

54
2 Series of functions and power series
Since
‚àû

k=0
k
x
x
k
is convergent (Example 2.34 i)), by the Comparison
Test 1.10 also
‚àû

k=0
kakxk converges, whence R1 ‚â§R2. In conclusion
R1 = R2 and the claim is proved.
2
The series
‚àû

k=0
kakxk‚àí1 =
‚àû

k=1
kakxk‚àí1 =
‚àû

k=0
(k + 1)ak+1xk is the derivatives‚Äô
series of
‚àû

k=0
akxk.
Theorem 2.39 Suppose the radius R of the series
‚àû

k=0
akxk is positive, Ô¨Ånite
or inÔ¨Ånite. Then
a) the sum s is a C‚àûmap over (‚àíR, R). Moreover, the nth derivative of s
on (‚àíR, R) can be computed by diÔ¨Äerentiating
‚àû

k=0
akxk term by term n
times. In particular, for any x ‚àà(‚àíR, R)
s‚Ä≤(x) =
‚àû

k=1
kakxk‚àí1 =
‚àû

k=0
(k + 1)ak+1xk ;
(2.13)
b) for any x ‚àà(‚àíR, R)
 x
0
s(t) dt =
‚àû

k=0
ak
k + 1xk+1 .
(2.14)
Proof.
a) By the previous lemma a power series and its derivatives‚Äô series have
identical radii, because
‚àû

k=1
kakxk‚àí1 = 1
x
‚àû

k=1
kakxk for any x Ã∏= 0. The
derivatives‚Äô series converges uniformly on every interval [a, b] ‚äÇ(‚àíR, R);
thus Theorem 2.19 applies, and we conclude that s is C1 on (‚àíR, R) and
that (2.13) holds. Iterating the argument proves the claim.
b) The result follows immediately by noticing
‚àû

k=0
akxk is the derivatives‚Äô
series of
‚àû

k=0
ak
k + 1xk+1. These two have same radius and we can use The-
orem 2.18.
2

2.4 Power series
55
Example 2.40
DiÔ¨Äerentiating term by term
‚àû

k=0
xk =
1
1 ‚àíx ,
x ‚àà(‚àí1, 1) ,
(2.15)
we infer that for x ‚àà(‚àí1, 1)
‚àû

k=1
kxk‚àí1 =
‚àû

k=0
(k + 1)xk =
1
(1 ‚àíx)2 .
(2.16)
Integrating term by term the series
‚àû

k=0
(‚àí1)kxk =
1
1 + x ,
x ‚àà(‚àí1, 1) ,
obtained from (2.15) by changing x to ‚àíx, we have for all x ‚àà(‚àí1, 1)
‚àû

k=0
(‚àí1)k
k + 1 xk+1 =
‚àû

k=1
(‚àí1)k‚àí1
k
xk = log(1 + x) .
(2.17)
At last from
‚àû

k=0
(‚àí1)kx2k =
1
1 + x2 ,
x ‚àà(‚àí1, 1) ,
obtained from (2.15) writing ‚àíx2 instead of x, and integrating each term separ-
ately, we see that for any x ‚àà(‚àí1, 1)
‚àû

k=0
(‚àí1)k
2k + 1x2k+1 = arctan x .
(2.18)
Proposition 2.41 Suppose
‚àû

k=0
ak(x ‚àíx0)k has radius R > 0. The series‚Äô
coeÔ¨Écients depend on the derivatives of the sum s(x) as follows:
ak = 1
k! s(k)(x0) ,
‚àÄk ‚â•0 .
Proof.
Write the sum as s(x) =
‚àû

h=0
ah(x‚àíx0)h; diÔ¨Äerentiating each term k times
gives
s(k)(x) =
‚àû

h=k
h(h ‚àí1) ¬∑ ¬∑ ¬∑ (h ‚àík + 1)ah(x ‚àíx0)h‚àík
=
‚àû

h=0
(h + k)(h + k ‚àí1) ¬∑ ¬∑ ¬∑ (h + 1)ah+k(x ‚àíx0)h .

56
2 Series of functions and power series
For x = x0 only the term indexed by h = 0 contributes, and the above
expression becomes
s(k)(x0) = k! ak ,
‚àÄk ‚â•0 .
2
2.5 Analytic functions
The previous section examined the properties of the sum of a power series, summar-
ised in Theorem 2.39. Now we want to take the opposite viewpoint, and demand
that an arbitrary function (necessarily C‚àû) be the sum of some power series. Said
better, we take f ‚ààC‚àû(X), X ‚äÜR, x0 ‚ààX and ask whether, on a suitable interval
(x0 ‚àíŒ¥, x0 + Œ¥) ‚äÜX with Œ¥ > 0, it is possible to represent f as the sum of a power
series
f(x) =
‚àû

k=0
ak(x ‚àíx0)k ;
(2.19)
by Proposition 2.41 we must necessarily have
ak = f (k)(x0)
k!
,
‚àÄk ‚â•0 .
In particular when x0 = 0, f is given by
f(x) =
‚àû

k=0
f (k)(0)
k!
xk .
(2.20)
DeÔ¨Ånition 2.42 The series (2.19) is called the Taylor series of f centred
at x0. If the radius is positive and the sum coincides with f around x0 (i.e.,
on some neighbourhood of x0), one says the map f has a Taylor series ex-
pansion, or is an analytic function, at x0. If x0 = 0, one speaks sometimes
of Maclaurin series of f.
The deÔ¨Ånition is motivated by the fact that not all C‚àûfunctions admit a power
series representation, as in this example.
Example 2.43
Consider
f(x) =

e‚àí1/x2
if x Ã∏= 0 ,
0
if x = 0 .
It is not hard to check f is C‚àûon R with f (k)(0) = 0 for all k ‚â•0. Therefore
the terms of (2.20) all vanish and the sum (the zero function) does not represent
f anywhere around the origin.
2

2.5 Analytic functions
57
The partial sums in (2.19) are precisely the Taylor polynomials of f at x0:
sn(x) =
n

k=0
f (k)(x0)
k!
(x ‚àíx0)k = T fn,x0(x) .
Therefore f having a Taylor series expansion is equivalent to the convergence to
f of the sequence of its own Taylor polynomials:
lim
n‚Üí‚àûsn(x) = lim
n‚Üí‚àûT fn,x0(x) = f(x) ,
‚àÄx ‚àà(x0 ‚àíŒ¥, x0 + Œ¥) .
In such a case the nth remainder of the series rn(x) = f(x)‚àísn(x) is inÔ¨Ånitesimal,
as n ‚Üí‚àû, for any x ‚àà(x0 ‚àíŒ¥, x0 + Œ¥):
lim
n‚Üí‚àûrn(x) = 0 .
There is a suÔ¨Écient condition for a C‚àûmap to have a Taylor series expansion
around a point.
Theorem 2.44 Take f ‚ààC‚àû(x0 ‚àíŒ¥, x0 + Œ¥), Œ¥ > 0. If there are an index
k0 ‚â•0 and a constant M > 0 such that
|f (k)(x)| ‚â§M k!
Œ¥k ,
‚àÄx ‚àà(x0 ‚àíŒ¥, x0 + Œ¥)
(2.21)
for all k ‚â•k0, then f has a Taylor series expansion at x0 whose radius is at
least Œ¥.
Proof.
Write the Taylor expansion of f at x0 of order n ‚â•k0 with Lagrange
remainder (see Vol. I, Thm 7.2):
f(x) = T fn,x0(x) +
1
(n + 1)!f (n+1)(xn)(x ‚àíx0)n+1 ,
where xn is a certain point between x0 and x. By assumption, for any
x ‚àà(x0 ‚àíŒ¥, x0 + Œ¥) we have
|rn(x)| =
1
(n + 1)!|f (n+1)(xn)| |x ‚àíx0|n+1 ‚â§M
	|x ‚àíx0|
Œ¥

n+1
.
If we assume |x ‚àíx0|/Œ¥< 1, then
lim
n‚Üí‚àûrn(x) = 0
and the claim is proved.
2

58
2 Series of functions and power series
Remark 2.45 Condition (2.21) holds in particular if all derivatives f (k)(x) are
uniformly bounded, independently of k: this means there is a constant M > 0 for
which
|f (k)(x)| ‚â§M ,
‚àÄx ‚àà(x0 ‚àíŒ¥, x0 + Œ¥) .
(2.22)
In fact, from Example 1.1 v) we have
k!
Œ¥k ‚Üí‚àûas k ‚Üí‚àû, so k!
Œ¥k ‚â•1 for k bigger
or equal than a certain k0.
A similar argument shows that (2.21) is true more generally if
|f (k)(x)| ‚â§M k ,
‚àÄx ‚àà(x0 ‚àíŒ¥, x0 + Œ¥) .
(2.23)
Examples 2.46
i) We can eventually prove the earlier claim on the exponential series, that is to
say
ex =
‚àû

k=0
xk
k!
‚àÄx ‚ààR .
(2.24)
We already know the series converges for any x ‚ààR (Example 2.23 ii)); addition-
ally, the map ex is C‚àûon R with f (k)(x) = ex, f (k)(0) = 1 . Fixing an arbitrary
Œ¥ > 0, inequality (2.22) holds since
|f (k)(x)| = ex ‚â§eŒ¥ = M ,
‚àÄx ‚àà(‚àíŒ¥,Œ¥ ) .
Hence f has a Maclaurin series and (2.24) is true, as promised.
More generally, ex has a Taylor series at each x0 ‚ààR:
ex =
‚àû

k=0
ex0
k! (x ‚àíx0)k ,
‚àÄx ‚ààR .
ii) Writing ‚àíx2 instead of x in (2.24) yields
e‚àíx2 =
‚àû

k=0
(‚àí1)k x2k
k! ,
‚àÄx ‚ààR .
Integrating term by term we obtain a representation in series of the error func-
tion
erf x =
2
‚àöœÄ
 x
0
e‚àít2 dt =
2
‚àöœÄ
‚àû

k=0
(‚àí1)k
k!
x2k+1
2k + 1 ,
which has a role in Probability and Statistics.
iii) The trigonometric functions f(x) = sin x, g(x) = cos x are analytic for any
x ‚ààR. Indeed, they are C‚àûon R and all derivatives satisfy (2.22) with M = 1.
In the special case x0 = 0,
sin x =
‚àû

k=0
(‚àí1)k
(2k + 1)! x2k+1 ,
‚àÄx ‚ààR ,
(2.25)
cos x =
‚àû

k=0
(‚àí1)k
(2k)! x2k ,
‚àÄx ‚ààR .
(2.26)

2.5 Analytic functions
59
iv) Let us prove that for Œ± ‚ààR \ N
(1 + x)Œ± =
‚àû

k=0
	Œ±
k

xk ,
‚àÄx ‚àà(‚àí1, 1) .
(2.27)
In Example 2.34 v) we found the radius of convergence R = 1 for the right-hand
side. Let f(x) denote the sum of the series:
f(x) =
‚àû

k=0
	Œ±
k

xk ,
‚àÄx ‚àà(‚àí1, 1) .
DiÔ¨Äerentiating term-wise and multiplying by (1 + x) gives
(1 + x)f ‚Ä≤(x) = (1 + x)
‚àû

k=1
k
	Œ±
k

xk‚àí1 =
‚àû

k=0
(k + 1)
	
Œ±
k + 1

xk +
‚àû

k=1
k
	Œ±
k

xk
=
‚àû

k=0

(k + 1)
	
Œ±
k + 1

+ k
	Œ±
k


xk = Œ±
‚àû

k=0
	Œ±
k

xk = Œ±f(x) .
Hence f ‚Ä≤(x) = Œ±(1 + x)‚àí1f(x). Now take the map g(x) = (1 + x)‚àíŒ±f(x) and
note
g‚Ä≤(x) = ‚àíŒ±(1 + x)‚àíŒ±‚àí1f(x) + (1 + x)‚àíŒ±f ‚Ä≤(x)
= ‚àíŒ±(1 + x)‚àíŒ±‚àí1f(x) + Œ±(1 + x)‚àíŒ±‚àí1f(x) = 0
for any x ‚àà(‚àí1, 1). Therefore g(x) is constant and we can write
f(x) = c(1 + x)Œ± .
The value of the constant c is Ô¨Åxed by f(0) = 1, so c = 1.
v) When Œ± = ‚àí1, formula (2.27) gives the Taylor series of f(x) =
1
1+x at the
origin:
1
1 + x =
‚àû

k=0
(‚àí1)kxk .
Actually, f is analytic at all points x0 Ã∏= ‚àí1 and the corresponding Taylor series‚Äô
radius is R = |1 + x0|, i.e., the distance of x0 from the singular point x = ‚àí1;
indeed, one has
f (k)(x) = (‚àí1)kk!(1 + x)‚àí(k+1)
and it is not diÔ¨Écult to check estimate (2.21) on a suitable neighbourhood of x0.
Furthermore, the Root Test (Theorem 2.33) gives
R = lim
k‚Üí‚àû
k#
|1 + x0|k+1 = |1 + x0| > 0 .
vi) One can prove the map f(x) =
1
1+x2 is analytic at each point x0 ‚ààR. This
does not mean, though, that the radius of the generic Taylor expansion of f is
+‚àû. For instance, at x0 = 0,
f(x) =
‚àû

k=0
(‚àí1)kx2k
has radius 1. In general the Taylor series of f at x0 will have radius

1 + x2
0
(see the next section).

60
2 Series of functions and power series
vi) The last two instances are, as a matter of fact, rational, and it is known that
rational functions ‚Äì more generally all elementary functions ‚Äì are analytic at
every point lying in the interior of their domain.
2
2.6 Power series in C
The deÔ¨Ånition of power series extends easily to the complex numbers. By a power
series in C we mean an expression like
‚àû

k=0
ak(z ‚àíz0)k ,
where {ak}k‚â•0 is a sequence of complex numbers, z0 ‚ààC and z is the complex
variable. The notions of convergence (pointwise, absolute, uniform) carry over
provided we substitute everywhere the absolute value with the modulus.
The convergence interval of a real power series is now replaced by a disc in the
complex plane, centred at z0 and of radius R ‚àà[0, +‚àû].
The term analytic map determines a function of one complex variable that is
the sum of a power series in C. Examples include rational functions of complex
variable
f(z) = P(z)
Q(z) ,
where P, Q are coprime polynomials over the complex numbers; with z0 ‚ààdom f
Ô¨Åxed, the convergence radius of the series centred at z0 whose sum is f coincides
with the distance (in the complex plane) between z0 and the nearest zero of the
denominator, i.e., the closest singularity.
The exponential, sine and cosine functions possess a natural extension to C,
obtained by substituting the real variable x with the complex z in (2.24), (2.25) and
(2.26). These new series converge on the whole complex plane, so the corresponding
functions are analytic on C.
2.7 Exercises
1. Over the given interval I determine the sets of pointwise and uniform conver-
gence, and the limit function, for:
a)
fn(x) =
nx
1 + n3x3 ,
I = [0, +‚àû)
b)
fn(x) =
x
1 + n2x2 ,
I = [0, +‚àû)
c)
fn(x) = enx ,
I = R

2.7 Exercises
61
d)
fn(x) = nxe‚àínx ,
I = R
e)
fn(x) =
4nx
3nx + 5nx ,
I = R
2.
Study uniform and pointwise convergence for the sequence of maps:
fn(x) = nx(1 ‚àíx2)n ,
x ‚àà[‚àí1, 1] .
Does the following formula hold?
lim
n‚Üí‚àû
 1
0
fn(x) dx =
 1
0
lim
n‚Üí‚àûfn(x) dx .
3.
Study uniform and pointwise convergence for the sequence of maps:
fn(x) = arctan nx ,
x ‚ààR .
Tell whether the formula
lim
n‚Üí‚àû
 1
a
fn(x) dx =
 1
a
lim
n‚Üí‚àûfn(x) dx ,
holds, with a = 0 or a = 1/2.
4. Determine the sets of pointwise convergence of the series:
a)
‚àû

k=1
(k + 2)x
k3 +
‚àö
k
,
b)
‚àû

k=1

1 + x
k
k2
c)
‚àû

k=1
1
xk + x‚àík ,
x > 0
d)
‚àû

k=1
xk
xk + 2k ,
x Ã∏= ‚àí2
e)
‚àû

k=1
(‚àí1)kkx sin 1
k
f)
‚àû

k=1

k ‚àí

k2 ‚àí1
x
5.
Determine the sets of pointwise and uniform convergence of the series
‚àû

k=2
ekx.
Compute its sum, where deÔ¨Åned.
6.
Setting fk(x) = cos x
k , check
‚àû

k=1
f ‚Ä≤
k(x) converges uniformly on [‚àí1, 1], while
‚àû

k=1
fk(x) converges nowhere.

62
2 Series of functions and power series
7. Determine the sets of pointwise and uniform convergence of the series:
a)
‚àû

k=1
k1/x
b)
‚àû

k=1
(log k)x
k
c)
‚àû

k=1

(k2 + x2)
1
k2+x2 ‚àí1

8.
Knowing that
‚àû

k=0
ak4k converges, can one infer the convergence of the following
series?
a)
‚àû

k=0
ak(‚àí2)k
b)
‚àû

k=0
ak(‚àí4)k
9. Suppose that
‚àû

k=0
akxk converges for x = ‚àí4 and diverges for x = 6. What can
be said about the convergence or divergence of the following series?
a)
‚àû

k=0
ak
b)
‚àû

k=0
ak7k
c)
‚àû

k=0
ak(‚àí3)k
d)
‚àû

k=0
(‚àí1)kak9k
10.
Let p be a positive integer. Determine, as p varies, the radius of convergence
of
‚àû

k=0
(k!)p
(pk)! xk .
11. Find radius and set of convergence of the power series:
a)
‚àû

k=1
xk
‚àö
k
b)
‚àû

k=0
(‚àí1)kxk
k + 1
c)
‚àû

k=0
kx2k
d)
‚àû

k=2
(‚àí1)k
xk
3k log k
e)
‚àû

k=0
k2(x ‚àí4)k
f)
‚àû

k=0
k3(x ‚àí1)k
10k
g)
‚àû

k=1
(‚àí1)k (x + 3)k
k3k
h)
‚àû

k=1
k!(2x ‚àí1)k
i)
‚àû

k=1
kxk
1 ¬∑ 3 ¬∑ 5 ¬∑ ¬∑ ¬∑ (2k ‚àí1)
‚Ñì)
‚àû

k=1
(‚àí1)kx2k‚àí1
2k ‚àí1

2.7 Exercises
63
12.
The function
J1(x) =
‚àû

k=0
(‚àí1)kx2k+1
k! (k + 1)! 22k+1
is called Bessel function of order 1. Determine its domain.
13.
Given the function
f(x) = 1 + 2x + x2 + 2x3 + ¬∑ ¬∑ ¬∑ =
‚àû

k=0
akxk ,
where a2k = 1, a2k+1 = 2 for any k ‚â•0, determine the domain of f and an
explicit formula for it.
14. Determine the convergence set of the series:
a)
‚àû

k=1
	2
3

k
(x2 ‚àí1)k
b)
‚àû

k=1
1
k‚àö
k
	1 + x
1 ‚àíx

k
c)
‚àû

k=1
k + 1
k2 + 1 2‚àíkx2
d)
‚àû

k=1
1
k
(3x)k

x + 1
x
k
15.
Determine the radius of convergence of the power series
‚àû

k=0
a
‚àö
kxk
as the real parameter a > 0 varies.
16. Expand in Maclaurin series the following functions, computing the radius of
convergence of the series thus obtained:
a)
f(x) =
x3
x + 2
b)
f(x) = 1 + x2
1 ‚àíx2
c)
f(x) = log(3 ‚àíx)
d)
f(x) =
x3
(x ‚àí4)2
e)
f(x) = log 1 + x
1 ‚àíx
f)
f(x) = sin x4
g)
f(x) = sin2 x
h)
f(x) = 2x
17. Expand the maps below in Taylor series around the point x0, and tell what is
the radius of the series:
a)
f(x) = 1
x ,
x0 = 1
b)
f(x) = ‚àöx ,
x0 = 4
c)
f(x) = log x ,
x0 = 2

64
2 Series of functions and power series
18.
Verify that

k=1
k2xk = x2 + x
(1 ‚àíx)3
for |x| < 1.
19. Write the Ô¨Årst three terms of the Maclaurin series of:
a)
f(x) = log(1 ‚àíx)
ex
b) f(x) = e‚àíx2 cos x
c) f(x) = sin x
1 ‚àíx
20. Write as Maclaurin series the following indeÔ¨Ånite integrals:
a)

sin x2 dx
b)
 
1 + x3 dx
21. Using series‚Äô expansions compute the deÔ¨Ånite integrals with the accuracy re-
quired:
a)
 1
0
sin x2 dx ,
up to the third digit
b)
 1/10
0

1 + x3 dx ,
with an absolute error < 10‚àí8
2.7.1 Solutions
1. Limits of sequences of functions:
a) Since fn(0) = 0 for every n, f(0) = 0; if x Ã∏= 0,
fn(x) ‚àº
nx
n3x3 =
1
n2x2 ‚Üí0
for
n ‚Üí+‚àû.
The limit function f is identically zero on I.
For the uniform convergence, we study the maps fn on I and notice
f ‚Ä≤
n(x) = n(1 ‚àí2n3x3)
(1 + n3x3)2
and f ‚Ä≤
n(x) = 0 for xn =
1
3‚àö
2n with fn(xn) =
2
3 3‚àö
2 (Fig. 2.3). Hence
sup
x‚àà[0,+‚àû)
|fn(x)| =
2
3
3‚àö
2
and the convergence is not uniform on [0, +‚àû). Nonetheless, with Œ¥ > 0 Ô¨Åxed
and n large enough, fn is decreasing on [Œ¥, +‚àû), so
sup
x‚àà[Œ¥,+‚àû)
|fn(x)| = fn(Œ¥) ‚Üí0
as
n ‚Üí+‚àû.
The convergence is uniform on all intervals [Œ¥, +‚àû) with Œ¥ > 0.

2.7 Exercises
65
x
y
2
3 3‚àö
2
f1
f2
f6
f20
f
Figure 2.3. Graphs of fn and f relative to Exercise 1. a)
b) Reasoning as before, the sequence converges pointwise on I to the limit f(x) =
0, for any x ‚ààI. Moreover
f ‚Ä≤
n(x) =
1 ‚àín2x2
(1 + n2x2)2 ,
and for any x ‚â•0
f ‚Ä≤
n(x) = 0
‚áê‚áí
x = 1
n
with
fn
 1
n

= 1
2n .
Thus there is uniform convergence on I, since
lim
n‚Üí‚àû
sup
x‚àà[0,+‚àû)
|fn(x)| = lim
n‚Üí‚àû
1
2n = 0 .
See Fig. 2.4.
c) The sequence converges pointwise on (‚àí‚àû, 0] to
f(x) =
 0
if x < 0,
1
if x = 0.
We have no uniform convergence on (‚àí‚àû, 0] as f is not continuous; but on all
half-lines (‚àí‚àû, ‚àíŒ¥], for any Œ¥ > 0, this is the case, because
x
y
f1
f2
f4
f10
f
Figure 2.4. Graphs of fn and f relative to Exercise 1. b)

66
2 Series of functions and power series
lim
n‚Üí‚àû
sup
x‚àà(‚àí‚àû,‚àíŒ¥]
enx = lim
n‚Üí‚àûe‚àínŒ¥ = 0 .
d) We have pointwise convergence to f(x) = 0 for all x ‚àà[0, +‚àû), and uniform
convergence on every [Œ¥, +‚àû), Œ¥ > 0.
e) Note fn(0) = 1/2. As n ‚Üí‚àûthe maps fn satisfy
fn(x) ‚àº
!
(4/3)nx
if x < 0 ,
(4/5)nx
if x > 0 .
Anyway for x Ã∏= 0
f(x) = lim
n‚Üí‚àûfn(x) = 0 .
Hence the sequence converges pointwise on R to the limit
f(x) =
 0
if x Ã∏= 0,
1/2
if x = 0.
The convergence is not uniform on R because the limit is not continuous on that
domain. But we do have uniform convergence on every set AŒ¥ = (‚àí‚àû, ‚àíŒ¥] ‚à™
[Œ¥, +‚àû), Œ¥ > 0, since
lim
n‚Üí‚àûsup
x‚ààAŒ¥
|fn(x)| = lim
n‚Üí‚àûmax

fn(Œ¥), fn(‚àíŒ¥)

= 0 .
2. Notice fn(1) = fn(‚àí1) = 0 for all n. For any x ‚àà(‚àí1, 1) moreover, 1 ‚àíx2 < 1;
hence
lim
n‚Üí‚àûfn(x) = 0 ,
‚àÄx ‚àà(‚àí1, 1) .
Then the sequence converges to f(x) = 0 , ‚àÄx ‚àà[‚àí1, 1].
What about uniform convergence? For this we consider the odd maps fn, so it
suÔ¨Éces to take x ‚àà[0, 1]. Then
f ‚Ä≤
n(x) = n(1 ‚àíx2)n ‚àí2nx2(1 ‚àíx2)n‚àí1 = n(1 ‚àíx2)n‚àí1(1 ‚àíx2 ‚àí2nx2) ,
and fn(x) has a maximum point x = 1/‚àö1 + 2n (and by symmetry a minimum
point x = ‚àí1/‚àö1 + 2n). Therefore
sup
x‚àà[‚àí1,1]
|fn(x)| = fn
	
1
‚àö1 + 2n

=
n
‚àö1 + 2n
	
2n
1 + 2n

n
,
and the convergence is not uniform on [‚àí1, 1], for
lim
n‚Üí‚àû
n
‚àö1 + 2n
	
2n
1 + 2n

n
= e‚àí1/2 lim
n‚Üí‚àû
n
‚àö1 + 2n = +‚àû.

2.7 Exercises
67
From this argument the convergence cannot be uniform on the interval [0, 1] either,
and we cannot swap the limit with diÔ¨Äerentiation. Let us check the formula. Put-
ting t = 1 ‚àíx2, we have
lim
n‚Üí‚àû
 1
0
fn(x) dx = lim
n‚Üí‚àû
n
2
 1
0
tn dt = lim
n‚Üí‚àû
n
2(n + 1) = 1
2 ,
while
 1
0
lim
n‚Üí‚àûfn(x) dx = 0 .
3. Since
lim
n‚Üí‚àûfn(x) =
‚éß
‚é®
‚é©
œÄ/2
if x > 0 ,
0
if x = 0 ,
‚àíœÄ/2
if x < 0 ,
we have pointwise convergence on R, but not uniform: the limit is not continuous
despite the fn are. Similarly, no uniform convergence on [0, 1]. Therefore, if we put
a = 0, it is not possible to exchange limit and integration automatically. Compute
the two sides of the equality independently:
lim
n‚Üí‚àû
 1
0
fn(x) dx = lim
n‚Üí‚àû
	
x arctan nx
1
0 ‚àí
 1
0
nx
1 + n2x2 dx

= lim
n‚Üí‚àû

arctan n ‚àílog(1 + n2x2)
2n

1
0

= lim
n‚Üí‚àû
	
arctann ‚àílog(1 + n2)
2n

= œÄ
2 .
Moreover
 1
0
lim
n‚Üí‚àûfn(x) dx =
 1
0
œÄ
2 dx = œÄ
2 .
Hence the equality holds even if the sequence does not converge uniformly on [0, 1].
If we take a = 1/2, instead, we have uniform convergence on [1/2, 1], so the
equality is true by Theorem 2.18.
4. Convergence set for series of functions:
a) Fix x, so that
fk(x) = (k + 2)x
k3 +
‚àö
k
‚àº
1
k3‚àíx ,
k ‚Üí‚àû.
The series is like the generalised harmonic series of exponent 3 ‚àíx, so it
converges if 3 ‚àíx > 1, hence x < 2, and diverges if 3 ‚àíx ‚â§1, so x ‚â•2.

68
2 Series of functions and power series
b) Given x, use the Root Test to see
lim
k‚Üí‚àû
k
|fk(x)| = lim
k‚Üí‚àû

1 + x
k
k
= ex .
Then the series converges if ex < 1, i.e., x < 0, and diverges if ex > 1, so
x > 0. If x = 0, the series diverges because the general term is always 1. The
convergence set is the half-line (‚àí‚àû, 0).
c) If x = 1, the general term does not tend to 0 so the series cannot converge. If
x Ã∏= 1, as k ‚Üí‚àûwe have
fk(x) ‚àº

x‚àík
if x > 1,
xk
if x < 1 .
In either case the series converges. Thus the convergence set is (0, +‚àû) \ {1}.
d) If |x| < 2, the convergence is absolute as |fk(x)| ‚àº
 |x|
2
k, k ‚Üí‚àû. If x ‚â§‚àí2 or
x ‚â•2 the series does not converge since the general term is not inÔ¨Ånitesimal.
The set of convergence is (‚àí2, 2).
e) Observe that
|fk(x)| ‚àº
1
k1‚àíx ,
k ‚Üí‚àû.
The series converges absolutely if 1 ‚àíx > 1, so x < 0. By Leibnitz‚Äôs Test, the
series converges pointwise if 0 < 1‚àíx ‚â§1, i.e., 0 ‚â§x < 1. It does not converge
(it is indeterminate, actually) if x ‚â•1, since the general term does not tend
to 0. The convergence set is thus (‚àí‚àû, 1).
f) Given x, the general term is equivalent to that of a generalised harmonic series:
fk(x) =
	
1
k +
‚àö
k2 ‚àí1

x
‚àº
	 1
2k

x
,
k ‚Üí‚àû.
The convergence set is (1, +‚àû).
5. Geometric series with q = ex, converging pointwise on (‚àí‚àû, 0) and uniformly
on (‚àí‚àû, ‚àíŒ¥], for any Œ¥ > 0. Moreover for any x < 0
‚àû

k=2
(ex)k =
1
1 ‚àíex ‚àí1 ‚àíex =
e2x
1 ‚àíex .
6. For any x ‚ààR, lim
k‚Üí‚àûcos x
k = 1 Ã∏= 0. Hence the convergence set of
‚àû

k=1
cos x
k is
empty.
As f ‚Ä≤
k(x) = ‚àí1
k sin x
k , we have
|f ‚Ä≤
k(x)| ‚â§|x|
k2 ‚â§1
k2 ,
‚àÄx ‚àà[‚àí1, 1] .

2.7 Exercises
69
Since
‚àû

k=1
1
k2 converges, the M-test of Weierstrass tells
‚àû

k=1
f ‚Ä≤
k(x) converges uni-
formly on [‚àí1, 1].
7. Sets of pointwise and uniform convergence:
a) This is harmonic with exponent ‚àí1/x, so: pointwise convergence on (‚àí1, 0),
uniform convergence on any sub-interval [a, b] of (‚àí1, 0).
b) The Integral Test tells the convergence is pointwise on (‚àí‚àû, ‚àí1). Uniform
convergence happens on every half-line (‚àí‚àû, ‚àíŒ¥], for any Œ¥ > 1.
c) Observing
fk(x) ‚àº
1
k2 + x2 log(k2 + x2) ,
k ‚Üí‚àû,
the series converges pointwise on R. Moreover,
sup
x‚ààR
|fk(x)| = fk(0) = exp
	 1
k2 log k2

‚àí1 = Mk .
The numerical series
‚àû

k=1
Mk converges just like
‚àû

k=1
2 log k
k2
. The M-test implies
the convergence is also uniform on R.
8. The assumption ensures the radius of convergence is bigger or equal than 4.
Hence the Ô¨Årst series converges, while for the second one we cannot say anything.
9. Convergence of power series:
a) Converges.
b) Diverges.
c) Converges.
d) Diverges.
10. We have

ak+1
ak
 =

(k + 1)!
p (pk)!

p(k + 1)

! (k!)p
(k + 1)p
(pk + 1)(pk + 2) ¬∑ ¬∑ ¬∑ (pk + p) .
Thus
lim
k‚Üí‚àû

ak+1
ak
 = lim
k‚Üí‚àû
k + 1
pk + 1
k + 1
pk + 2 ¬∑ ¬∑ ¬∑ k + 1
pk + p = 1
pp ,
and the Ratio Test gives R = pp.
11. Radius and set of convergence for power series:
a) R = 1, I = [‚àí1, 1)
b) R = 1, I = (‚àí1, 1]
c) R = 1, I = (‚àí1, 1)
d) R = 3, I = (‚àí3, 3]
e) R = 1, I = (3, 5)
f) R = 10, I = (‚àí9, 11)
g) R = 3, I = (‚àí6, 0]
h) R = 0, I = { 1
2}
i) R = +‚àû, I = R
‚Ñì) R = 1, I = [‚àí1, 1]

70
2 Series of functions and power series
12. Using the Ratio Test:
lim
k‚Üí‚àû

ak+1
ak
 = lim
k‚Üí‚àû
k! (k + 1)! 22k+1
(k + 1)! (k + 2)! 22k+3 = lim
k‚Üí‚àû
1
4(k + 2)(k + 1) = 0 .
Hence R = +‚àûand the domain of the function is R.
13. Since lim
k‚Üí‚àû
k
|ak| = 1, the radius is R = 1. It is straightforward to see the
series does not converge for x = ¬±1 because the general term does not tend to 0.
Hence dom f = (‚àí1, 1), and for x ‚àà(‚àí1, 1),
f(x) =
‚àû

k=0
x2k + 2
‚àû

k=0
x2k+1
1
1 ‚àíx2 +
2x
1 ‚àíx2 = 1 + 2x
1 ‚àíx2 .
14. Set of convergence:
a) Put y = x2 ‚àí1 and look at the power series
‚àû

k=1
2
3
k
yk
in the variable y, with radius Ry. Since
lim
k‚Üí‚àû
k
2
3
k
= 2
3 ,
Ry = 3
2. For y = ¬± 3
2 the series does not converge as the general term does not
tend to 0. In conclusion, the series converges if ‚àí3
2 < x2 ‚àí1 < 3
2. The Ô¨Årst
inequality holds for any x, whereas the second one equals x2 < 5
2; The series
converges on

‚àí
#
5
2,
#
5
2

.
b) Let x Ã∏= 1; set y = 1+x
1‚àíx and consider the series
‚àû

k=1
1
k‚àö
k
yk in y. Since
lim
k‚Üí‚àû
k
 
1
k‚àö
k
= lim
k‚Üí‚àûe‚àí1
k2 log k = 1 ,
we obtain Ry = 1. For y = ¬±1 there is no convergence as the general term
does not tend to 0. Hence, the series converges for
‚àí1 < 1 + x
1 ‚àíx < 1 ,
i.e.,
x < 0 .
c) Write y = 2‚àíx2 and consider the power series
‚àû

k=1
k + 1
k2 + 1 yk. Immediately we
have Ry = 1; in addition the series converges if y = ‚àí1 (like the alternating
harmonic series) and diverges if y = 1 (harmonic series). Returning to the
variable x, the series converges if ‚àí1 ‚â§2‚àíx2 < 1. The left inequality is trivial,
the right one holds when x Ã∏= 0. Overall the set of convergence is R \ {0}.

2.7 Exercises
71
d) When x Ã∏= 0 we set y =
x
x + 1
x
=
x2
1 + x2 and then study
‚àû

k=1
3k
k yk. Its radius
equals Ry = 1
3, so it converges on [‚àí1
3, 1
3).
Back to the x, we impose the conditions
‚àí1
3 ‚â§
x2
1 + x2 < 1
3 .
This is equivalent to 2x2 < 1, making

‚àí
‚àö
2
2 ,
‚àö
2
2

\ {0} the convergence set.
15. Exploiting the Ratio Test we have
lim
k‚Üí‚àû

ak+1
ak
 = lim
k‚Üí‚àû
a
‚àök+1
a
‚àö
k
= lim
k‚Üí‚àûa
‚àök+1‚àí
‚àö
k = lim
k‚Üí‚àûa
1
‚àök+1+
‚àö
k = 1 .
Hence R = 1 for any a > 0.
16. Maclaurin series:
a) Using the geometric series with q = ‚àíx
2 ,
f(x) = x3
2
1
1 + x
2
= x3
2
‚àû

k=0

‚àíx
2
k
=
‚àû

k=0
(‚àí1)k xk+3
2k+1 ;
this has radius R = 2.
b) With the geometric series where q = x2, we have
f(x) = ‚àí1 +
2
1 ‚àíx2 = ‚àí1 + 2
‚àû

k=0
x2k ,
whose radius is R = 1.
c) Expanding the function g(t) = log(1 + t), where t = ‚àíx
3, we obtain
f(x) = log 3 + log(1 ‚àíx
3 ) = log 3 +
‚àû

k=1
(‚àí1)k+1
k

‚àíx
3
k
= log 3 ‚àí
‚àû

k=1
xk
k3k ;
This has radius R = 3.
d) Expanding g(t) =
1
(1 ‚àít)2 (recall (2.16)) with t = x
4,
f(x) = x3
16
1
(1 ‚àíx
4 )2 = x3
16
‚àû

k=0
(k + 1)
x
4
k
=
‚àû

k=0
(k + 1)xk+3
4k+2
;
Now the radius is R = 4.

72
2 Series of functions and power series
e) Recalling the series of g(t) = log(1 + t), with t = x and then t = ‚àíx, we Ô¨Ånd
f(x) = log(1 + x) ‚àílog(1 ‚àíx) =
‚àû

k=1
(‚àí1)k+1
k
xk ‚àí
‚àû

k=1
(‚àí1)k+1
k
(‚àíx)k
=
‚àû

k=1
1
k

(‚àí1)k+1 + 1

xk =
‚àû

k=0
2
2k + 1 x2k+1 ;
thus the radius equals R = 1.
f) f(x) =
‚àû

k=0
(‚àí1)k
x8k+4
(2k + 1)! has radius R = ‚àû.
g) Since sin2 x = 1
2(1 ‚àícos 2x), and remembering the expansion of g(t) = cos t
with t = 2x, we have
f(x) = 1
2 ‚àí1
2
‚àû

k=0
(‚àí1)k 22kx2k
(2k)! ,
R = +‚àû.
h) f(x) =
‚àû

k=0
(log 2)k
k!
xk , with R = +‚àû.
17. Taylor series:
a) One can proceed directly and compute the derivatives of f to obtain
f (k)(x) = (‚àí1)k
k!
xk+1 ,
whence
f (k)(1) = (‚àí1)kk! ,
‚àÄk ‚ààN .
Therefore
f(x) =
‚àû

k=0
(‚àí1)k(x ‚àí1)k ,
R = 1 .
Alternatively, one could set t = x ‚àí1 and take the Maclaurin series of f(t) =
1
1+t to arrive at the same result:
1
1 + t =
‚àû

k=0
(‚àí1)ktk =
‚àû

k=0
(‚àí1)k(x ‚àí1)k ,
R = 1 .
b) Here as well we compute directly
f ‚Ä≤(x) = 1
2x‚àí1/2 ,
f (k)(x) = (‚àí1)k+1 1 ¬∑ 3 ¬∑ 5 ¬∑ ¬∑ ¬∑ (2k ‚àí3)
2k
x‚àí2k‚àí1
2
,
for all k ‚â•2; then

2.7 Exercises
73
f(x) = 2 + 1
4(x ‚àí4) +
‚àû

k=1
(‚àí1)k+1 1 ¬∑ 3 ¬∑ 5 ¬∑ ¬∑ ¬∑ (2k ‚àí3)
k!2k
2‚àí(2k‚àí1) (x ‚àí4)k
and the radius is R = 4.
Alternatively, put t = x ‚àí4, to the eÔ¨Äect that
‚àöx =
‚àö
4 + t = 2

1 + t
4
= 2 + 1
4(x ‚àí4) + 2
‚àû

k=2
	 1
2
k

 	 t
4

k
= 2 + 1
4(x ‚àí4) + 2
‚àû

k=2
1
2
 1
2 ‚àí1

¬∑ ¬∑ ¬∑
 1
2 ‚àík + 1

k!
1
4k (x ‚àí4)k
= 2 + 1
4(x ‚àí4) + 2
‚àû

k=2
1 ¬∑ 3 ¬∑ ¬∑ ¬∑ (2k ‚àí3)
2kk!
(‚àí1)k+1
22k
(x ‚àí4)k
= 2 + 1
4(x ‚àí4) +
‚àû

k=2
(‚àí1)k+1 1 ¬∑ 3 ¬∑ 5 ¬∑ ¬∑ ¬∑ (2k ‚àí3)
k!23k‚àí1
(x ‚àí4)k .
c) log x = log 2 +
‚àû

k=1
(‚àí1)k+1
k2k
(x ‚àí2)k ,
R = 2.
18. The equality is trivial for x = 0. DiÔ¨Äerentiating term by term, for |x| < 1 we
have
‚àû

k=0
xk =
1
1 ‚àíx ,
‚àû

k=1
kxk‚àí1 =
1
(1 ‚àíx)2 ,
‚àû

k=2
k(k ‚àí1)xk‚àí2 =
2
(1 ‚àíx)3 .
From the last relationship, when x Ã∏= 0, we have
2
(1 ‚àíx)3 =
‚àû

k=1
k(k + 1)xk‚àí1 =
‚àû

k=1
k2xk‚àí1 +
‚àû

k=1
kxk‚àí1 = 1
x
‚àû

k=1
k2xk +
1
(1 ‚àíx)2 .
Therefore
‚àû

k=1
k2xk =
2x
(1 ‚àíx)3 ‚àí
x
(1 ‚àíx)2 = x2 + x
(1 ‚àíx)3 .
19. Maclaurin series:
a) Using the well-known series of g(x) = log(1 ‚àíx) and h(x) = e‚àíx yields
f(x) = e‚àíx log(1 ‚àíx) =

1 ‚àíx + x2
2 ‚àíx3
3! + ¬∑ ¬∑ ¬∑

‚àíx ‚àíx2
2 ‚àíx3
3 ‚àí¬∑ ¬∑ ¬∑

= ‚àíx + x2 ‚àí1
2x2 ‚àí1
3x3 + 1
2x3 ‚àí1
2x3 + ¬∑ ¬∑ ¬∑
= ‚àíx + 1
2x2 ‚àí1
3x3 + ¬∑ ¬∑ ¬∑

74
2 Series of functions and power series
b) f(x) = 1 ‚àí3
2x2 + 25
24x4 ‚àí¬∑ ¬∑ ¬∑
c) f(x) = x + x2 + 5
6x3 + ¬∑ ¬∑ ¬∑
20. IndeÔ¨Ånite integrals:
a) Since
sin x2 =
‚àû

k=0
(‚àí1)k
(2k + 1)! x2(2k+1) ,
‚àÄx ‚ààR ,
a term-by-term integration produces

sin x2 dx = c +
‚àû

k=0
(‚àí1)kx4k+3
(4k + 3)(2k + 1)!
with arbitrary constant c.
b)
 
1 + x3 dx = c + x + x4
8 +
‚àû

k=2
(‚àí1)k‚àí1 1 ¬∑ 3 ¬∑ 5 ¬∑ ¬∑ ¬∑ (2k ‚àí3)
2kk!(3k + 1)
x3k+1 .
21. DeÔ¨Ånite integrals:
a)
 1
0
sin x2 dx ‚àº0.310 .
b)
 1/10
0

1 + x3 dx ‚àº0.10001250.

3
Fourier series
The sound of a guitar, the picture of a footballer on tv, the trail left by an oil tanker
on the ocean, the sudden tremors of an earthquake are all examples of events, either
natural or caused by man, that have to do with travelling-wave phenomena. Sound
for instance arises from the swift change in air pressure described by pressure waves
that move through space. The other examples can be understood similarly using
propagating electromagnetic waves, water waves on the ocean‚Äôs surface, and elastic
waves within the ground, respectively.
The language of Mathematics represents waves by one or more functions that
model the physical object of concern, like air pressure, or the brightness of an
image‚Äôs basic colours; in general this function depends on time and space, for in-
stance the position of the microphone or the coordinates of the pixel on the screen.
If one Ô¨Åxes the observer‚Äôs position in space, the wave appears as a function of the
time variable only, hence as a signal (acoustic, of light, . . . ). On the contrary, if we
Ô¨Åx a moment in time, the wave will look like a collection of values in space of the
physical quantity represented (think of a picture still on the screen, a photograph
of the trail taken from a plane, and so on).
Propagating waves can have an extremely complicated structure; the desire to
understand and be able to control their behaviour in full has stimulated the quest
for the appropriate mathematical theories to analyse them, in the last centuries.
Generally speaking, this analysis aims at breaking down a complicated wave‚Äôs
structure in the superposition of simpler components that are easy to treat and
whose nature is well understood. According to such theories there will be a collec-
tion of ‚Äòelementary waves‚Äô, each describing a speciÔ¨Åc and basic way of propagation.
Certain waves are obtained by superposing a Ô¨Ånite number of elementary ones, yet
the more complex structures are given by an inÔ¨Ånite number of elementary waves,
and then the tricky problem arises ‚Äì as always ‚Äì of making sense of an inÔ¨Ånite
collection of objects and how to handle them.
The so-called Fourier Analysis is the most acclaimed and widespread frame-
work for describing propagating phenomena (and not only). In its simplest form,
Fourier Analysis considers one-dimensional signals with a given periodicity. The
elementary waves are sine functions characterised by a certain frequency, phase
C. Canuto, A. Tabacco: Mathematical Analysis II, 2nd Ed.,
UNITEXT ‚Äì La Matematica per il 3+2 85, DOI 10.1007/978-3-319-12757-6_3,
¬© Springer International Publishing Switzerland 2015

76
3 Fourier series
and amplitude of oscillation. The composition of a Ô¨Ånite number of elementary
waves generates trigonometric polynomials, whereas an inÔ¨Ånite number produces
a series of functions, called Fourier series. This is an extremely eÔ¨Écient way of rep-
resenting in series a large class of periodic functions. This chapter introduces the
rudiments of Fourier Analysis through the study of Fourier series and the issues
of their convergence to a periodic map.
Beside standard Fourier Analysis, other much more sophisticated tools for ana-
lysing and representing functions have been developed, especially in the last dec-
ades of the XX century, among which the so-called Wavelet Analysis. Some of
those theories lie at the core of the recent, striking success of Mathematics in sev-
eral groundbreaking technological applications such as mobile phones, or digital
sound and image processing. Far from obfuscating the classical subject matter,
these latter-day developments highlight the importance of the standard theory as
foundational for all successive advancements.
3.1 Trigonometric polynomials
We begin by recalling periodic functions.
DeÔ¨Ånition 3.1 A map f : R ‚ÜíR is periodic of period T > 0 if
f(x + T ) = f(x) ,
‚àÄx ‚ààR.
If f is periodic of period T it is also periodic of period kT , with k ‚ààN \ {0},
including that f might be periodic of period T/k, k ‚ààN \ {0}. The minimum
period of f is the smallest T (if existent) for which f is periodic. Moreover, f is
known when we know it on an interval [x0, x0 + T ) (or (x0, x0 + T ]) of length T .
Usually one chooses the interval [0, T ) or

‚àíT
2 , T
2

. Note that if f is constant, it
is periodic of period T , for any T > 0.
Any map deÔ¨Åned on a bounded interval [a, b) can be prolonged to a periodic
function of period T = b ‚àía, by setting
f(x + kT ) = f(x) ,
k ‚ààZ , ‚àÄx ‚àà[a, b) .
Such prolongation is not necessarily continuous at the points x = a + kT , even if
the original function is.
Examples 3.2
i) The functions f(x) = cos x, g(x) = sin x are periodic of period 2kœÄ with
k ‚ààN \ {0}. Both have minimum period 2œÄ.
ii) f(x) = cos x
4 is periodic of period 8œÄ, 16œÄ, . . .; its minimum period is 8œÄ.
iii) The maps f(x) = cos œâx, g(x) = sin œâx, œâ Ã∏= 0, are periodic with minimum
period T0 = 2œÄ
œâ .
iv) The mantissa map f(x) = M(x) is periodic of minimum period T0 = 1.
2

3.1 Trigonometric polynomials
77
The following properties are easy to prove.
Proposition 3.3 Let f be periodic of period T > 0; for any x0 ‚ààR then,
 T
0
f(x) dx =
 x0+T
x0
f(x) dx .
In particular, if x0 = ‚àíT/2,
 T
0
f(x) dx =
 T/2
‚àíT/2
f(x) dx .
Proof.
By the properties of deÔ¨Ånite integrals,
 T
0
f(x) dx =
 x0
0
f(x) dx +
 x0+T
x0
f(x) dx +
 T
x0+T
f(x) dx .
Putting x = y + T in the last integral, by periodicity
 T
x0+T
f(x) dx =
 0
x0
f(y + T ) dy =
 0
x0
f(y) dy ‚àí
 x0
0
f(y) dy ,
whence the result.
2
Proposition 3.4 Let f be a periodic map of period T1 > 0 and take T2 > 0.
Then g(x) = f

T1
T2 x

is periodic of period T2.
Proof.
For any x ‚ààR,
g(x + T2) = f
T1
T2
(x + T2)

= f
T1
T2
x + T1

= f
T1
T2
x

= g(x) .
2
The periodic function f(x) = a sin(œâx + œÜ), where a, œâ,œÜ are constant, is
rather important for the sequel. It describes in Physics a special oscillation of sine
type, and goes under the name of simple harmonic. Its minimum period equals
T = 2œÄ
œâ and the latter‚Äôs reciprocal
œâ
2œÄ is the frequency, i.e., the number of wave
oscillations on each unit interval (oscillations per unit of time, if x denotes time);
œâ is said angular frequency. The quantities a and œÜ are called amplitude and
phase (oÔ¨Äset) of the oscillation. Modifying a > 0 has the eÔ¨Äect of widening or
shrinking the range of f (the oscillation‚Äôs crests and troughs move apart or get
closer, respectively), while a positive or negative variation of œÜ translates the wave
left or right (Fig. 3.1). A simple harmonic can also be represented as a sin(œâx+œÜ) =

78
3 Fourier series
‚àí1
1
‚àí2œÄ
2œÄ
x
y
‚àí1
1
x
y
‚àí2
2
‚àí2œÄ
2œÄ
x
y
‚àí1
1
‚àí2œÄ‚àíœÜ
2œÄ‚àíœÜ
‚àíœÜ
x
y
Figure 3.1. Simple harmonics for various values of angular frequency, amplitude and
phase: (œâ, a,œÜ) = (1, 1, 0), top left; (œâ, a,œÜ) = (5, 1, 0), top right; (œâ, a,œÜ) = (1, 2, 0),
bottom left; (œâ, a,œÜ) = (1, 1, œÄ
3 ), bottom right
Œ± cos œâx + Œ≤ sin œâx with Œ± = a sin œÜ and Œ≤ = a cos œÜ; the inverse transformation of
the parameters is a =

Œ±2 + Œ≤2, œÜ = arctan Œ±
Œ≤ .
In the sequel we shall concentrate on periodic functions of period 2œÄ because
all results can be generalised by a simple variable change, thanks to Proposition
3.4. (More details can be found in Sect. 3.6.)
The superposition of simple harmonics whose frequencies are all multiple of
one fundamental frequency, say 1/2œÄ for simplicity, gives rise to trigonometric
polynomials.
DeÔ¨Ånition 3.5 A trigonometric polynomial of order or degree n is a
Ô¨Ånite linear combination
P(x) = a0 + a1 cos x + b1 sin x + . . . + an cos nx + bn sin nx
= a0 +
n

k=1
(ak cos kx + bk sin kx) ,
where ak, bk are real constants and at least one of an, bn is non-zero. Rep-
resenting simple harmonics in terms of their amplitude and phase, a trigono-
metric polynomial can be written as
P(x) = a0 +
n

k=1
Œ±k sin(kx + œïk) .

3.2 Fourier CoeÔ¨Écients and Fourier series
79
The name stems from the observation that each algebraic polynomial of degree
n in X and Y generates a trigonometric polynomial of the same degree n, by
substituting X = cos x, Y = sin x and using suitable trigonometric identities. For
example, p(X, Y ) = X3 + 2Y 2 gives
p(cos x, sin x) = cos3 x + 2 sin2 x
= cos x 1 + cos 2x
2
+ 2 1 ‚àícos 2x
2
= 1 + 1
2 cos x ‚àícos 2x + 1
2 cos x cos 2x
= 1 + 1
2 cos x ‚àícos 2x + 1
4(cos x + cos 3x)
= 1 + 3
4 cos x ‚àícos 2x + 1
4 cos 3x = P(x).
Obviously, not all periodic maps can be represented as trigonometric polynomials
(e.g., f(x) = esin x). At the same time though, certain periodic maps (that include
the functions appearing in applications) may be approximated, in a sense to be
made precise, by trigonometric polynomials: they can actually be expanded in
series of trigonometric polynomials. These functions are called Fourier series
and are the object of concern in this chapter.
3.2 Fourier CoeÔ¨Écients and Fourier series
Although the theory of Fourier series can be developed in a very broad context,
we shall restrict to a subclass of all periodic maps (of period 2œÄ), namely those
belonging to the space ÀúC2œÄ, which we will introduce in a moment. First though, a
few preliminary deÔ¨Ånitions are required.
DeÔ¨Ånition 3.6 A map f periodic of period 2œÄ is piecewise continuous if
it is continuous on [0, 2œÄ] except for at most a Ô¨Ånite number of points x0. At
such points there can be a removable singularity or a singularity of the Ô¨Årst
kind, so the left and right limits
f(x+
0 ) = lim
x‚Üíx+
0
f(x)
and
f(x‚àí
0 ) = lim
x‚Üíx‚àí
0
f(x)
exist and are Ô¨Ånite.
If, in addition,
f(x0) = 1
2

f(x+
0 ) + f(x‚àí
0 )

,
(3.1)
at each discontinuity x0, f is called regularised.

80
3 Fourier series
DeÔ¨Ånition 3.7 We denote by ÀúC2œÄ the space of maps deÔ¨Åned on R that are
periodic of period 2œÄ, piecewise continuous and regularised.
The set ÀúC2œÄ is an R-vector space (i.e., Œ±f + Œ≤g ‚ààÀúC2œÄ for any Œ±,Œ≤ ‚ààR and all
f, g ‚ààÀúC2œÄ); it is not hard to show that given f, g ‚ààÀúC2œÄ, the expression
(f, g) =
 2œÄ
0
f(x)g(x) dx
(3.2)
deÔ¨Ånes a scalar product on ÀúC2œÄ (we refer to Appendix A.2.1, p. 521, for the
general concept of scalar product and of norm of a function). In fact,
i) (f, f) ‚â•0 for any f ‚ààÀúC2œÄ, and (f, f) = 0 if and only if f = 0;
ii) (f, g) = (g, f), for any f, g ‚ààÀúC2œÄ;
iii) (Œ±f + Œ≤g, h) = Œ±(f, h) + Œ≤(g, h), for all f, g, h ‚ààÀúC2œÄ and any Œ±,Œ≤ ‚ààR.
The only non-trivial fact is that (f, f) = 0 forces f = 0. To see that, let x1, . . . , xn
be the discontinuity points of f in [0, 2œÄ]; then
0 =
 2œÄ
0
f 2(x) dx =
 x1
0
f 2(x) dx +
 x2
x1
f 2(x) dx + . . . +
 2œÄ
xn
f 2(x) dx .
As f is continuous on every sub-interval (xi, xi+1), we get f(x) = 0 on each of
them. At last, f(xi) = 0 at each point of discontinuity, by (3.1).
Associated to the scalar product (3.2) is a norm
‚à•f‚à•2 = (f, f)1/2 =
  2œÄ
0
|f(x)|2 dx
1/2
called quadratic norm. As any other norm, the quadratic norm enjoys the fol-
lowing characteristic properties:
i) ‚à•f‚à•2 ‚â•0 for any f ‚ààÀúC2œÄ and ‚à•f‚à•2 = 0 if and only if f = 0;
ii) ‚à•Œ±f‚à•2 = |Œ±| ‚à•f‚à•2, for all f ‚ààÀúC2œÄ and any Œ± ‚ààR;
iii) ‚à•f + g‚à•2 ‚â§‚à•f‚à•2 + ‚à•g‚à•2, for any f, g ‚ààÀúC2œÄ.
The Cauchy-Schwarz inequality
|(f, g)| ‚â§‚à•f‚à•2 ‚à•g‚à•2 ,
‚àÄf, g ‚ààÀúC2œÄ ,
(3.3)
holds.
Let us now recall that a family {fk} of non-zero maps in ÀúC2œÄ is said an ortho-
gonal system if
(fk, f‚Ñì) = 0
for k Ã∏= ‚Ñì.

3.2 Fourier CoeÔ¨Écients and Fourier series
81
By normalising ÀÜfk =
fk
‚à•fk‚à•2
for any k, an orthogonal system generates an or-
thonormal system { ÀÜfk},
( ÀÜfk, ÀÜf‚Ñì) = Œ¥k‚Ñì=
 1
if k = ‚Ñì,
0
if k Ã∏= ‚Ñì.
The set of functions
F =

1, cos x, sin x, . . . , cos kx, sin kx, . . .

=

œïk(x) = cos kx : k ‚â•0

‚à™

œàk(x) = sin kx : k ‚â•1

(3.4)
forms an orthogonal system in ÀúC2œÄ, whose associated orthonormal system is
ÀÜF =

1
‚àö
2œÄ
,
1
‚àöœÄ cos x,
1
‚àöœÄ sin x, . . . , 1
‚àöœÄ cos kx,
1
‚àöœÄ sin kx, . . .

.
(3.5)
This follows from the relationships
 2œÄ
0
cos2 kx dx =
 2œÄ
0
sin2 kx dx = œÄ ,
‚àÄk ‚â•1
 2œÄ
0
cos kx cos ‚Ñìx dx =
 2œÄ
0
sin kx sin ‚Ñìx dx = 0 ,
‚àÄk,‚Ñì‚â•0, k Ã∏= ‚Ñì,
 2œÄ
0
cos kx sin ‚Ñìx dx = 0 ,
‚àÄk,‚Ñì‚â•0 .
(3.6)
The above orthonormal system in ÀúC2œÄ plays the role of the canonical orthonor-
mal basis {ek} of Rn: each element in the vector space is uniquely writable as
linear combination of the elements of the system, with the diÔ¨Äerence that now
the linear combination is an inÔ¨Ånite series. Fourier series are precisely the expan-
sions in series of maps in ÀúC2œÄ, viewed as formal combinations of the orthonormal
system (3.5).
A crucial feature of this expansion is the possibility of approximating a map
by a linear combination of simple functions. Precisely, for any n ‚â•0 we consider
the (2n + 1)-dimensional subset Pn ‚äÇÀúC2œÄ of trigonometric polynomials of degree
‚â§n. This subspace is spanned by maps œïk and œàk of F with index k ‚â§n, forming
a Ô¨Ånite orthogonal system Fn. A ‚Äúnatural‚Äù approximation in Pn of a map of ÀúC2œÄ
is provided by its orthogonal projection on Pn.

82
3 Fourier series
DeÔ¨Ånition 3.8 We call orthogonal projection of f ‚ààÀúC2œÄ on Pn the ele-
ment Sn,f ‚ààPn deÔ¨Åned by
Sn,f(x) = a0 +
n

k=1
(ak cos kx + bk sin kx) ,
(3.7)
where ak, bk are
a0 = 1
2œÄ
 2œÄ
0
f(x) dx ;
ak = 1
œÄ
 2œÄ
0
f(x) cos kx dx ,
k ‚â•1 ;
bk = 1
œÄ
 2œÄ
0
f(x) sin kx dx ,
k ‚â•1 .
(3.8)
Note Sn,f can be written as
Sn,f(x) =
n

k=0
akœïk(x) +
n

k=1
bkœàk(x)
and the coeÔ¨Écients ak, bk become
ak = (f,œï k)
(œïk, œïk)
for k ‚â•0 ,
bk = (f,œà k)
(œàk, œàk)
for k ‚â•1 .
(3.9)
There is an equivalent representation with respect to the Ô¨Ånite orthonormal
system ÀÜFn made by the elements of ÀÜF of index k ‚â§n; in fact
Sn,f(x) =
n

k=0
ÀÜak ÀÜœïk(x) +
n

k=1
ÀÜbk ÀÜœàk(x)
where
ÀÜak = (f, ÀÜœïk)
for k ‚â•0 ,
ÀÜbk = (f, ÀÜœàk)
for k ‚â•1 .
(3.10)
The equivalence follows from
ak =
1
‚à•œïk‚à•2
2
(f,œï k) =
1
‚à•œïk‚à•2

f,
œïk
‚à•œïk‚à•2

=
1
‚à•œïk‚à•2
ÀÜak
hence
akœïk(x) = ÀÜak
œïk(x)
‚à•œïk‚à•2
= ÀÜak ÀÜœïk(x) ;
similarly one proves bkœàk(x) = ÀÜbk ÀÜœàk(x).

3.2 Fourier CoeÔ¨Écients and Fourier series
83
To understand the properties of the orthogonal projection of f on Pn, we stress
that the quadratic norm deÔ¨Ånes a distance on ÀúC2œÄ:
d(f, g) = ‚à•f ‚àíg‚à•2 ,
f, g ‚ààÀúC2œÄ .
(3.11)
The number ‚à•f ‚àíg‚à•2 measures how ‚Äúclose‚Äù f and g are. The expected properties
of distances hold:
i) d(f, g) ‚â•0 for any f, g ‚ààÀúC2œÄ, and d(f, g) = 0 precisely if f = g;
ii) d(f, g) = d(g, f), for all f, g ‚ààÀúC2œÄ;
iii) d(f, g) ‚â§d(f, h) + d(h, g), for any f, g, h ‚ààÀúC2œÄ.
The orthogonal projection of f on Pn enjoys therefore the following properties,
some of which are symbolically represented in Fig. 3.2.
Proposition 3.9 i) The function f ‚àíSn,f is orthogonal to every element
of Pn, and Sn,f is the unique element of Pn with this property.
ii) Sn,f is the element in Pn with minimum distance to f with respect to
(3.11), i.e.,
‚à•f ‚àíSn,f‚à•2 = min
P ‚ààPn ‚à•f ‚àíP‚à•2 .
Hence Sn,f is the polynomial of Pn that best approximates f in quadratic
norm.
iii) The minimum square error ‚à•f ‚àíSn,f‚à•2 of f satisÔ¨Åes
‚à•f ‚àíSn,f‚à•2
2 =
 2œÄ
0
|f(x)|2 dx ‚àí2œÄa2
0 ‚àíœÄ
n

k=1
(a2
k + b2
k) .
(3.12)
Proof.
This proposition transfers to ÀúC2œÄ the general properties of the orthogonal
projection of a vector, belonging to a vector space equipped with a dot
product, onto the subspace generated by a Ô¨Ånite orthogonal system. For
the reader not familiar with such abstract notions, we provide an adapted
proof.
For i), let
P(x) =
n

k=0
Àúakœïk(x) +
n

k=1
Àúbkœàk(x)
be a generic element of Pn. Then f ‚àíP is orthogonal to every element in
Pn if and only if, for any k ‚â§n,
(f ‚àíP,œï k) = 0
and
(f ‚àíP,œà k) = 0 .
Using the orthogonality of œïk, œàk, that is equivalent to
(f,œï k) ‚àíÀúak(œïk, œïk) = 0
and
(f,œà k) ‚àíÀúbk(œàk, œàk) = 0 .

84
3 Fourier series
P
Pn
ÀúC2œÄ
Sn,f
f
O
Figure 3.2. Orthogonal projection of f ‚ààÀúC2œÄ on Pn
Hence Àúak = ak and Àúbk = bk for any k ‚â§n, recalling (3.9). In other words,
P = Sn,f.
To prove ii), note Ô¨Årst that
‚à•f + g‚à•2
2 = ‚à•f‚à•2
2 + ‚à•g‚à•2
2 + 2(f, g) ,
‚àÄf, g ‚ààÀúC2œÄ
by deÔ¨Ånition of norm. Writing ‚à•f ‚àíP‚à•2 as ‚à•(f ‚àíSn,f)+ (Sn,f ‚àíP)‚à•2, and
using the previous relationship with the fact that f ‚àíSn,f is orthogonal
to Sn,f ‚àíP ‚ààPn by i), we obtain
‚à•f ‚àíP‚à•2
2 = ‚à•f ‚àíSn,f‚à•2
2 + ‚à•Sn,f ‚àíP‚à•2
2 ;
the equation is to be considered as a generalisation of Pythagoras‚Äô Theorem
to spaces with a scalar product (Fig. 3.2). Then
‚à•f ‚àíP‚à•2
2 ‚â•‚à•f ‚àíSn,f‚à•2
2 ,
‚àÄP ‚ààPn ,
and equality holds if and only if Sn,f ‚àíP = 0 if and only if P = Sn,f. This
proves ii).
Claim iii) follows from
‚à•f ‚àíSn,f‚à•2
2 =

f ‚àíSn,f, f ‚àíSn,f

=

f, f ‚àíSn,f

‚àí

Sn,f, f ‚àíSn,f

=

f, f ‚àíSn,f

= ‚à•f‚à•2
2 ‚àí

f, Sn,f

and

f, Sn,f

=
 2œÄ
0
f(x) Sn,f(x) dx = 2œÄa2
0 + œÄ
n

k=1
(a2
k + b2
k) .
2
At this juncture it becomes natural to see if, and in which sense, the polynomial
sequence Sn,f converges to f as n ‚Üí‚àû. These are the partial sums of the series
a0 +
‚àû

k=1
(ak cos kx + bk sin kx) ,

3.2 Fourier CoeÔ¨Écients and Fourier series
85
where the coeÔ¨Écients ak, bk are given by (3.8). We are thus asking about the
convergence of the series.
DeÔ¨Ånition 3.10 The Fourier series of f ‚ààÀúC2œÄ is the series of functions
a0 +
‚àû

k=1
(ak cos kx + bk sin kx) ,
(3.13)
where a0, ak, bk (k ‚â•1) are the real numbers (3.8) and are called the Fourier
coeÔ¨Écients of f. We shall write
f ‚âàa0 +
‚àû

k=1
(ak cos kx + bk sin kx) .
(3.14)
The symbol ‚âàmeans that the right-hand side of (3.14) represents the Fourier
series of f; more explicitly, the coeÔ¨Écients ak and bk are prescribed by (3.8). Due
to the ample range of behaviours of a series (see Sect. 2.3), one should expect the
Fourier series of f not to converge at all, or to converge to a sum other than f.
That is why we shall use the equality sign in (3.14) only in case the series pointwise
converges to f. We will soon discuss suÔ¨Écient conditions for the series to converge
in some way or another.
It is possible to deÔ¨Åne the Fourier series of a periodic, piecewise-continuous
but not-necessarily-regularised function. Its series coincides with the one of the
regularised function built from f.
Example 3.11
Consider the square wave (Fig. 3.3)
f(x) =
‚éß
‚é™
‚é®
‚é™
‚é©
‚àí1
if ‚àíœÄ < x < 0 ,
0
if x = 0, ¬±œÄ ,
1
if 0 < x < œÄ .
By Proposition 3.3, for any k ‚â•0
 2œÄ
0
f(x) cos kx dx =
 œÄ
‚àíœÄ
f(x) cos kx dx = 0 ,
as f(x) cos kx is an odd map, whence ak = 0. Moreover
bk = 1
œÄ
 œÄ
‚àíœÄ
f(x) sin kx dx = 2
œÄ
 œÄ
0
sin kx dx
= 2
kœÄ (1 ‚àícos kœÄ) = 2
kœÄ (1 ‚àí(‚àí1)k) =
! 0
if k is even ,
4
kœÄ
if k is odd .

86
3 Fourier series
x
y
œÄ
‚àíœÄ
2œÄ
‚àí2œÄ
0
x
y
œÄ
‚àíœÄ
0
Figure 3.3. Graphs of the square wave (top) and the corresponding polynomials
S1,f(x), S9,f(x), S41,f(x) (bottom)
Writing every odd k as k = 2m + 1, the Fourier series of f reads
f ‚âà4
œÄ
‚àû

m=0
1
2m + 1 sin(2m + 1)x .
2
The example shows that if the map f ‚ààÀúC2œÄ is symmetric, computing its Fourier
coeÔ¨Écients can be simpler. The precise statement goes as follows.
Proposition 3.12 If the map f ‚ààÀúC2œÄ is odd,
ak = 0 ,
‚àÄk ‚â•0 ,
bk = 2
œÄ
 œÄ
0
f(x) sin kx dx ,
‚àÄk ‚â•1 ;
If f is even,
bk = 0 ,
‚àÄk ‚â•1 ,
a0 = 1
œÄ
 œÄ
0
f(x) dx ;
ak = 2
œÄ
 œÄ
0
f(x) cos kx dx ,
‚àÄk ‚â•1 .
Proof.
Take, for example, f even. Recalling Proposition 3.3, it suÔ¨Éces to note
f(x) sin kx is odd for any k ‚â•1, and f(x) cos kx is even for any k ‚â•0, to
obtain that
 2œÄ
0
f(x) sin kx dx =
 œÄ
‚àíœÄ
f(x) sin kx dx = 0 ,
‚àÄk ‚â•1 ,

3.2 Fourier CoeÔ¨Écients and Fourier series
87
and, for any k ‚â•0,
 2œÄ
0
f(x) cos kx dx =
 œÄ
‚àíœÄ
f(x) cos kx dx = 2
 œÄ
0
f(x) cos kx dx .
2
Example 3.13
Let us determine the Fourier series for the rectiÔ¨Åed wave f(x) = | sin x|
(Fig. 3.4). As f is even, the bk vanish and we just need to compute ak for
k ‚â•0:
a0 = 1
2œÄ
 œÄ
‚àíœÄ
| sin x| dx = 1
œÄ
 œÄ
0
sin x dx = 2
œÄ ,
a1 = 1
œÄ
 œÄ
0
sin 2x dx = 0 ,
ak = 2
œÄ
 œÄ
0
sin x cos kx dx = 1
œÄ
 œÄ
0

sin(k + 1)x ‚àísin(k ‚àí1)x

dx
= 1
œÄ
1 ‚àícos(k + 1)œÄ
k + 1
‚àí1 ‚àícos(k ‚àí1)œÄ
k ‚àí1

=
‚éß
‚é™
‚é®
‚é™
‚é©
0
if k is odd ,
‚àí
4
œÄ(k2 ‚àí1)
if k is even ,
‚àÄk > 1 .
The Fourier series of the rectiÔ¨Åed wave thus reads
f ‚âà2
œÄ ‚àí4
œÄ
‚àû

m=1
1
4m2 ‚àí1 cos 2mx .
2
x
y
œÄ
‚àíœÄ
0
x
y
œÄ
‚àíœÄ
0
Figure 3.4. Graphs of the rectiÔ¨Åed wave (top) and the corresponding polynomials
S2,f(x), S10,f(x), S30,f(x) (bottom)

88
3 Fourier series
3.3 Exponential form
The exponential form is an alternative, but equivalent, way of representing a Four-
ier series; it is more concise and sometimes easier to use, but the price for this is
that it requires complex numbers.
The starting point is the Euler identity (Vol. I, Eq. (8.31))
eiŒ∏ = cos Œ∏ + i sin Œ∏ , Œ∏
‚ààR ;
(3.15)
setting Œ∏ = ¬±kx, k ‚â•1 integer, we may write cos kx and sin kx as linear combin-
ations of the functions eikx, e‚àíikx:
cos kx = 1
2(eikx + e‚àíikx) ,
sin kx = 1
2i(eikx ‚àíe‚àíikx) .
On the other hand, 1 = ei0x trivially. Substituting in (3.14) and rearranging terms
yields
f ‚âà
+‚àû

k=‚àí‚àû
ckeikx ,
(3.16)
where
c0 = a0 ,
ck = ak ‚àíibk
2
,
c‚àík = ak + ibk
2
,
for k ‚â•1 .
(3.17)
It is an easy task to check
ck = 1
2œÄ
 2œÄ
0
f(x)e‚àíikx dx ,
k ‚ààZ .
Expression (3.16) represents the Fourier series of f in exponential form, and the
coeÔ¨Écients ck are the complex Fourier coeÔ¨Écients of f.
The complex Fourier series embodies the (formal) expansion of a function f ‚àà
ÀúC2œÄ with respect to the orthogonal system of functions eikx, k ‚ààZ. In fact,
(eikx, ei‚Ñìx) = 2œÄŒ¥kl =
! 2œÄ
if k = ‚Ñì,
0
if k Ã∏= ‚Ñì,
where
(f, g) =
 2œÄ
0
f(x)g(x) dx
is deÔ¨Åned on ÀúC‚àó
2œÄ, the set of complex-valued maps f = fr + ifi : R ‚ÜíC whose real
part fr and imaginary part fi belong to ÀúC2œÄ.

3.4 DiÔ¨Äerentiation
89
For this system the complex Fourier coeÔ¨Écients of f become
ck =
(f, eikx)
(eikx, eikx) ,
k ‚ààZ ,
(3.18)
in analogy to (3.9). Since this formula makes sense for all maps in ÀúC‚àó
2œÄ, equa-
tion (3.16) might deÔ¨Åne Fourier series on ÀúC‚àó
2œÄ as well.
It is straighforward that f ‚ààÀúC‚àó
2œÄ is a real map (fi = 0) if and only if its
complex Fourier coeÔ¨Écients satisfy c‚àík = ck, for any k ‚ààZ. If so, the real Fourier
coeÔ¨Écients of f are just
a0 = c0 ,
ak = ck + c‚àík ,
bk = i(ck ‚àíc‚àík) ,
for k ‚â•1 .
(3.19)
3.4 DiÔ¨Äerentiation
Consider the real Fourier series (3.13) and let us diÔ¨Äerentiate it (formally) term
by term. This gives
Œ±0 +
‚àû

k=1
(Œ±k cos kx + Œ≤k sin kx) ,
with
Œ±0 = 0 ,
Œ±k = kbk ,
Œ≤k = ‚àíkak ,
for k ‚â•1 .
(3.20)
Supposing f ‚ààÀúC2œÄ is C1 on R, in which case the derivative f ‚Ä≤ still belongs to
ÀúC2œÄ, the previous expression coincides with the Fourier series of f ‚Ä≤. In fact,
Œ±0 = 1
2œÄ
 2œÄ
0
f ‚Ä≤(x) dx = 1
2œÄ

f(2œÄ) ‚àíf(0)

= 0
by periodicity. Moreover, for k ‚â•1, integrating by part gives
Œ±k = 1
œÄ
 2œÄ
0
f ‚Ä≤(x) cos kx dx
= 1
œÄ

f(x) cos kx
2œÄ
0 + k
œÄ
 2œÄ
0
f(x) sin kx dx = kbk ,
and similarly, Œ≤k = ‚àíkak.
In summary,
f ‚Ä≤ ‚âà
‚àû

k=1
(k bk cos kx ‚àík ak sin kx) .
(3.21)
A similar reasoning shows that such representation holds under weaker hypotheses
on the diÔ¨Äerentiability of f, e.g., if f is piecewise C1 (see DeÔ¨Ånition 3.24).

90
3 Fourier series
The derivatives‚Äô series becomes all the more explicit if we exploit the complex
form (3.16). From (3.15) in fact,
d
dŒ∏ eiŒ∏ = (‚àísin Œ∏) + i cos Œ∏ = i(cosŒ∏ + i sin Œ∏) = ieiŒ∏ .
Therefore
d
dx eikx = ikeikx ,
whence
f ‚Ä≤ ‚âà
+‚àû

k=‚àí‚àû
ikckeikx .
If f is Cr on R, r ‚â•1, this fact generalises in the obvious way:
f (r) ‚âà
+‚àû

k=‚àí‚àû
(ik)rckeikx ;
Thus, the kth complex Fourier coeÔ¨Écient Œ≥k of the rth derivative of f is
Œ≥k = (ik)rck .
(3.22)
3.5 Convergence of Fourier series
This section is devoted to the convergence properties of the Fourier series of a
piecewise-continuous, periodic map of period 2œÄ (not regularised necessarily). We
shall treat three kinds of convergence: quadratic, pointwise and uniform. We omit
the proofs of all theorems, due to their prevailingly technical nature1.
3.5.1 Quadratic convergence
We begin by the deÔ¨Ånition.
DeÔ¨Ånition 3.14 Let f and fk, k ‚â•0, be square-integrable functions deÔ¨Åned
on a closed and bounded interval [a, b]. The series
‚àû

k=0
fk converges in quad-
ratic norm to f on [a, b] if
lim
n‚Üí‚àû
 b
a
f(x) ‚àí
n

k=0
fk(x)

2
dx = lim
n‚Üí‚àû
$$$f ‚àí
n

k=0
fk
$$$
2
2 = 0 .
1 A classical text where the interested reader may Ô¨Ånd these proofs is Y. Katznelson‚Äôs,
Introduction to Harmonic Analysis, Cambridge University Press, 2004.

3.5 Convergence of Fourier series
91
Directly from this, the uniform convergence of
‚àû

k=0
fk to f implies the quadratic
convergence, for
 b
a
f(x) ‚àí
n

k=0
fk(x)

2
dx ‚â§
 b
a

sup
x‚àà[a,b]
f(x) ‚àí
n

k=0
fk(x)

2
dx
‚â§(b ‚àía)
$$$f ‚àí
n

k=0
fk
$$$
2
‚àû,[a,b] ;
hence, if the last expression is inÔ¨Ånitesimal as n ‚Üí‚àû, so is the Ô¨Årst one.
Quadratic convergence of the Fourier series of a map in ÀúC2œÄ is guaranteed by
the next fundamental result, whose proof we omit.
Theorem 3.15 The Fourier series of f ‚ààÀúC2œÄ converges to f in quadratic
norm:
lim
n‚Üí+‚àû‚à•f ‚àíSn,f‚à•2 = 0 .
Let us describe some consequences.
Corollary 3.16 Any f ‚ààÀúC2œÄ satisÔ¨Åes Parseval‚Äôs formula:
 2œÄ
0
|f(x)|2 dx = 2œÄa2
0 + œÄ
+‚àû

k=1
(a2
k + b2
k) .
(3.23)
Proof.
This is an easy corollary of the above theorem. By (3.12) in fact,
0 =
lim
n‚Üí+‚àû‚à•f ‚àíSn,f‚à•2 =
lim
n‚Üí+‚àû
  2œÄ
0
|f(x)|2 dx ‚àí2œÄa2
0 ‚àíœÄ
n

k=1
(a2
k + b2
k)

=
 2œÄ
0
|f(x)|2 dx ‚àí2œÄa2
0 ‚àíœÄ
‚àû

k=1
(a2
k + b2
k) .
2
Corollary 3.17 (Riemann-Lebesgue Lemma) Given f ‚ààÀúC2œÄ,
lim
k‚Üí+‚àûak =
lim
k‚Üí+‚àûbk = 0 .
Proof.
From Parseval‚Äôs identity (3.23) the series
‚àû

k=1
(a2
k +b2
k) converges. Therefore
its general term a2
k + b2
k goes to zero as k ‚Üí+‚àû, and the result follows. 2

92
3 Fourier series
If f ‚ààÀúC‚àó
2œÄ is expanded in complex Fourier series (3.16), Parseval‚Äôs formula
becomes
 2œÄ
0
|f(x)|2 dx = 2œÄ
+‚àû

k=‚àí‚àû
|ck|2 ,
while the Riemann-Lebesgue Lemma says
lim
k‚Üí‚àûck = 0 .
Corollary 3.16 is useful to compute sums of numerical series.
Example 3.18
The map f(x) = x, deÔ¨Åned on (‚àíœÄ,œÄ ) and prolonged by periodicity to all R
(sawtooth wave) (Fig. 3.5), has a simple Fourier series. The map is odd, so
ak = 0 for all k ‚â•0, and bk = 2
k (‚àí1)k+1, hence
f ‚âà
‚àû

k=1
2
k (‚àí1)k+1 sin kx.
The series converges in quadratic norm to f(x), and via Parseval‚Äôs identity we
Ô¨Ånd
 œÄ
‚àíœÄ
|f(x)|2 dx = œÄ
‚àû

k=1
b2
k .
Since
 œÄ
‚àíœÄ
x2 dx = 2œÄ3
3
,
x
y
œÄ
‚àíœÄ
3œÄ
‚àí3œÄ
0
x
y
œÄ
‚àíœÄ
0
Figure 3.5. Graphs of the sawtooth wave (left) and the corresponding polynomials
S1,f(x), S7,f(x), S25,f(x) (right)

3.5 Convergence of Fourier series
93
we have
2œÄ3
3
= œÄ
‚àû

k=1
4
k2 ,
whence the sum of the inverses of all natural numbers squared is
‚àû

k=1
1
k2 = œÄ2
6 ;
This fact was stated without proof in Example 1.11 i).
2
We remark, at last, that additional assumptions of the regularity on f allow to
estimate the remainder of the Fourier series in terms of n, and furnish informations
on the speed at which the Fourier series tends to f in quadratic norm. For instance,
if f ‚ààÀúC2œÄ is Cr on R, r ‚â•1, it can be proved that
‚à•f ‚àíSn,f‚à•2 ‚â§1
nr ‚à•f (r)‚à•2 .
This is coherent with what will happen in Sect. 3.5.4.
3.5.2 Pointwise convergence
We saw that the Fourier series of f ‚ààÀúC2œÄ converges to f in quadratic norm, so in a
suitable integral sense; this, though, does not warrant pointwise convergence. We
are thus left with the hard task of Ô¨Ånding conditions that ensure pointwise con-
vergence: alas, not even assuming f continuous guarantees the Fourier series will
converge. On the other hand the uniform convergence of the Fourier series implies
pointwise convergence (see the remark after DeÔ¨Ånition 2.15). As the trigonometric
polynomials are continuous, uniform convergence still requires f be continuous (by
Theorem 2.17). We shall state, without proving them, some suÔ¨Écient conditions
for the pointwise convergence of the Fourier series of a non-necessarily continuous
map. The Ô¨Årst ones guarantee convergence on the entire interval [0, 2œÄ]. But before
that, we introduce a piece of notation.
DeÔ¨Ånition 3.19 i) A function f is called piecewise regular on an interval
[a, b] ‚äÇR in case
a) it is diÔ¨Äerentiable everywhere on [a, b] except at a Ô¨Ånite number of points
at most;
b) it is piecewise continuous, together with its derivative f ‚Ä≤.
ii) f is piecewise monotone if the interval [a, b] can be divided in a Ô¨Ånite
number of sub-intervals where f is monotone.

94
3 Fourier series
Theorem 3.20 Let f ‚ààÀúC2œÄ and suppose one of the following holds:
a) f is piecewise regular on [0, 2œÄ];
b) f is piecewise monotone on [0, 2œÄ].
Then the Fourier series of f converges pointwise to f on [0, 2œÄ].
The theorem also holds under the assumption that f is not regularised; in such
a case (like for the square wave or the sawtooth function),
at a discontinuity point x0, the Fourier series converges to the regularised value
f(x‚àí
0 ) + f(x+
0 )
2
of f, and not to f(x0).
Now let us see a local condition for pointwise convergence.
DeÔ¨Ånition 3.21 A
piecewise-continuous
map
admits
left
pseudo-
derivative and right pseudo-derivative at x0
‚ààR if the following
respective limits exist and are Ô¨Ånite
f ‚Ä≤(x‚àí
0 ) = lim
x‚Üíx‚àí
0
f(x) ‚àíf(x‚àí
0 )
x ‚àíx0
,
f ‚Ä≤(x+
0 ) = lim
x‚Üíx+
0
f(x) ‚àíf(x+
0 )
x ‚àíx0
.
(Fig. 3.6 explains the geometric meaning of pseudo-derivatives.) If in addition f
is continuous at x0, the pseudo-derivatives are nothing else than the left and right
derivatives.
Note that a piecewise-regular function on [0, 2œÄ] admits pseudo-derivatives at
each point of [0, 2œÄ]; despite this, there are functions that are not piecewise regular
yet admit pseudo-derivatives everywhere in R (an example is f(x) = x2 sin 1
x, for
x Ã∏= 0, x ‚àà[‚àíœÄ,œÄ ] and f(0) = 0).
x
y
x0
f(x0)
f(x‚àí
0 )
f(x+
0 )
Figure 3.6. Geometric meaning of the left and right pseudo-derivatives of f at x0

3.5 Convergence of Fourier series
95
Theorem 3.22 Let f ‚ààÀúC2œÄ. If at x0 ‚àà[0, 2œÄ] the left and right pseudo-
derivatives exist, the Fourier series of f at x0 converges to the (regularised)
value f(x0).
Example 3.23
Let us go back to the square wave of Example 3.11. Condition a) of Theorem
3.20 holds, so we have pointwise convergence on R. Looking at Fig. 3.3 we can
see a special behaviour around a discontinuity. If we take a neighbourhood of
x0 = 0, the x-coordinates of points closest to the maximum and minimum points
of the nth partial sum tend to x0 as n ‚Üí‚àû, whereas the y-coordinates tend to
diÔ¨Äerent limits ‚Ñì¬± ‚àº¬±1.18; the latter are not the limits f(0¬±) = ¬±1 of f at 0.
Such anomaly appears every time one considers a discontinuous map in ÀúC2œÄ, and
goes under the name of Gibbs phenomenon.
2
3.5.3 Uniform convergence
As already noted, there is no uniform convergence for the Fourier series of a dis-
continuous function, and we know that continuity is not suÔ¨Écient (it does not
guarantee pointwise convergence either).
Let us then introduce a new class of maps.
DeÔ¨Ånition 3.24 A function f ‚ààÀúC2œÄ is piecewise C1 if it is continuous on
R and piecewise regular on [0, 2œÄ].
The square wave is not piecewise C1 (since not continuous), in contrast to the
rectiÔ¨Åed wave.
We now state the following important theorem.
Theorem 3.25 Let f ‚ààÀúC2œÄ be piecewise C1. Its Fourier series converges
uniformly to f everywhere on R.
More generally, the following localization principle holds.
Theorem 3.26 Let f ‚ààÀúC2œÄ be piecewise regular on [0, 2œÄ]. Its Fourier series
converges uniformly to f on any closed sub-interval where the map is continu-
ous.

96
3 Fourier series
Example 3.27
i) The rectiÔ¨Åed wave has uniformly convergent Fourier series on R (Fig. 3.4).
ii) The Fourier series of the square wave converges uniformly to the function on
every interval [Œµ,œÄ ‚àíŒµ] or [œÄ + Œµ, 2œÄ ‚àíŒµ] (0 < Œµ < œÄ /2), because the square wave
is piecewise regular on [0, 2œÄ] and continuous on (0, œÄ) and (œÄ, 2œÄ).
2
3.5.4 Decay of Fourier coeÔ¨Écients
The equations of Sect. 3.4, relating the Fourier coeÔ¨Écients of a map and its deriv-
atives, help to establish a link between the coeÔ¨Écients‚Äô asymptotic behaviour, as
|k| ‚Üí‚àû, and the regularity of the function. For simplicity we consider complex
coeÔ¨Écients. Let f ‚ààÀúC2œÄ be of class Cr on R, with r ‚â•1; from (3.22) we obtain,
for any k Ã∏= 0,
|ck| =
1
|k|r |Œ≥k| .
The sequence |Œ≥k| is bounded for |k| ‚Üí‚àû; in fact, using (3.18) on f (r) gives
Œ≥k = (f (r), eikx)
(eikx, eikx) ;
the inequality of Schwarz tells
|Œ≥k| ‚â§‚à•f (r)‚à•2‚à•eikx‚à•2
‚à•eikx‚à•2
2
=
1
‚àö
2‚à•f (r)‚à•2 .
Thus we have proved
|ck| = O
	 1
|k|r

as |k| ‚Üí‚àû.
The result for real coeÔ¨Écients, i.e.,
|ak|, |bk| = O
	 1
kr

for k ‚Üí+‚àû,
is similarly found using (3.19) or a direct computation. In any case, if f has period
2œÄ and is Cr on R, its Fourier coeÔ¨Écients are inÔ¨Ånitesimal of order at least r with
respect to the test function 1/|k|.
Vice versa, it can be proved that the speed of decay of Fourier coeÔ¨Écients
determines, in a suitable sense, the function‚Äôs regularity.
3.6 Periodic functions with period T > 0
In case a function f belongs to ÀúCT , i.e., is deÔ¨Åned on R, piecewise continuous on
[0, T ], regularised and periodic of period T > 0, its Fourier series assumes the form

3.6 Periodic functions with period T > 0
97
f ‚âàa0 +
‚àû

k=1

ak cos k 2œÄ
T x + bk sin k 2œÄ
T x

,
where
a0 = 1
T
 T
0
f(x) dx ,
ak = 2
T
 T
0
f(x) cos k 2œÄ
T x dx ,
k ‚â•1 ,
bk = 2
T
 T
0
f(x) sin k 2œÄ
T x dx ,
k ‚â•1 .
The theorems concerning quadratic, pointwise and uniform convergence of the
Fourier series of a map in ÀúC2œÄ transfer in the obvious manner to maps in ÀúCT .
Parseval‚Äôs formula reads
 T
0
|f(x)|2 dx = T a2
0 + T
2
‚àû

k=1
(a2
k + b2
k) .
As far as the Fourier series‚Äô exponential form is concerned, (3.16) must be re-
placed by
f ‚âà
+‚àû

k=‚àí‚àû
ckeik 2œÄ
T x ,
(3.24)
where
ck = 1
T
 T
0
f(x)e‚àíik 2œÄ
T x dx ,
k ‚ààZ ;
Parseval‚Äôs identity takes the form
 T
0
|f(x)|2 dx = T
+‚àû

k=‚àí‚àû
|ck|2 .
Example 3.28
Let us write the Fourier expansion for f(x) = 1 ‚àíx2 on I = [‚àí1, 1], made
periodic of period 2. As f is even, the coeÔ¨Écients bk are zero. Moreover,
a0 = 1
2
 1
‚àí1
(1 ‚àíx2) dx =
 1
0
(1 ‚àíx2) dx = 2
3 ,
ak = 2
2
 1
‚àí1
(1 ‚àíx2) cos kœÄx dx = 2
 1
0
(1 ‚àíx2) cos kœÄx dx =
4
k2œÄ2 (‚àí1)k+1
for any k ‚â•1.

98
3 Fourier series
Hence
f ‚âà2
3 + 4
œÄ2
‚àû

k=1
(‚àí1)k+1
k2
cos kœÄx.
Since f is piecewise of class C1 the convergence is uniform on R, hence also
pointwise at every x ‚ààR. We can write
f(x) = 2
3 + 4
œÄ2
‚àû

k=1
(‚àí1)k+1
k2
cos kœÄx ,
‚àÄx ‚ààR.
In particular
f(0) = 1 = 2
3 + 4
œÄ2
‚àû

k=1
(‚àí1)k+1
k2
,
whence the sum of the generalised alternating harmonic series can be eventually
computed
‚àû

k=1
(‚àí1)k+1
k2
= œÄ2
12 .
2
3.7 Exercises
1. Determine the minimum period of the following maps:
a) f(x) = cos(3x ‚àí1)
b) f(x) = sin x
3 ‚àícos 4x
c) f(x) = 1 + cos x + sin 3x
d) f(x) = sin x cos x + 5
e) f(x) = 1 + cos2 x
f) f(x) = | cos x| + sin 2x
2.
Sketch the graph of the functions on R that on [0, œÄ) coincide with f(x) = ‚àöx
and are:
a) œÄ-periodic;
b) 2œÄ-periodic, even;
c) 2œÄ-periodic, odd.
3.
Given f(x) = cos3 x + sin 3x ‚àí4,
a) determine its minimum period;
b) compute its Fourier series;
c) study quadratic, pointwise, uniform convergence of such expansion.
4. Determine the Fourier series expansion of the 2œÄ-periodic maps deÔ¨Åned, on
[‚àíœÄ,œÄ ], as follows:
a)
f(x) = 1 ‚àí2 cosx + |x|
b)
f(x) = 1 + x + sin 2x
c)
f(x) = 4| sin3 x|
d)
f(x) =
 0
if ‚àíœÄ ‚â§x < 0 ,
‚àícos x
if 0 ‚â§x < œÄ

3.7 Exercises
99
5. Determine the Fourier series of the regularised maps of period T = 1 below:
a) f(x) =
! 1
if x ‚àà

‚àí1
4, 1
4

,
0
if x ‚àà
 1
4, 3
4

b) f(x) = | sin 2œÄx|
c) f(x) =
! sin 2œÄx
if x ‚àà

0, 1
2

,
0
if x ‚àà
 1
2, 1

d) f(x) =
! x
if x ‚àà

0, 1
2

,
1 ‚àíx
if x ‚àà
 1
2, 1

6.
Let f be the T -periodic, piecewise-continuous, regularised function whose
Fourier series is
f ‚âà1 +
‚àû

k=1
k
(2k + 1)3 sin 2kx .
Determine the period T and the symmetries (where present) of f.
7. Appropriately using the Fourier series of f(x) = x2 and g(x) = x3, calculate
the sum of:
a)
‚àû

k=1
1
k4
b)
‚àû

k=1
1
k6
8.
Determine the Fourier series of the 2œÄ-periodic map deÔ¨Åned on [‚àíœÄ,œÄ ] by
f(x) = |œï(x)| + œï(x)
2
,
where œï(x) = x2 ‚àí1.
9.
Determine the Fourier series for the 2œÄ-periodic, even, regularised function
deÔ¨Åned on [0, œÄ] by
f(x) =
 œÄ ‚àíx
if 0 ‚â§x < œÄ
2 ,
0
if œÄ
2 < x ‚â§œÄ .
Use the expansion to compute the sum of the series
‚àû

k=0
1
(2k + 1)2 .
10. Find the Fourier coeÔ¨Écients for the 2œÄ-periodic, odd map f(x) = 1 + sin 2x +
sin 4x deÔ¨Åned on [0, œÄ].

100
3 Fourier series
11.
Consider the 2œÄ-periodic map
f(x) =
 cos 2x
if |x| ‚â§œÄ
2 ,
‚àí1
if |x| > œÄ
2 and |x| ‚â§œÄ
deÔ¨Åned on [‚àíœÄ,œÄ ]. Determine the Fourier series of f and f ‚Ä≤; then study the
uniform convergence of the two series obtained.
12.
Consider the 2œÄ-periodic function that coincides with f(x) = x2 on [0, 2œÄ].
Verify its Fourier series is
f ‚âà4
3œÄ2 + 4
‚àû

k=1
 1
k2 cos kx ‚àíœÄ
k sin kx

.
Study the convergence of the above and use the results to compute the sum of
the series
‚àû

k=1
(‚àí1)k
k2
.
13.
Consider
f(x) = 2 +
‚àû

k=1
1
2k sin kx ,
x ‚ààR .
Check that f ‚ààC‚àû(R). Deduce the Fourier series of f ‚Ä≤ and the values of ‚à•f‚à•2
and
 2œÄ
0
f(x) dx .
14. Consider the 2œÄ-periodic function deÔ¨Åned on [‚àíœÄ,œÄ ) as f(x) = x. Determine
the Fourier series of f and study its quadratic, pointwise and uniform conver-
gence.
3.7.1 Solutions
1. Minimum period:
a)
T = 2
3œÄ .
b) T = 6œÄ .
c) T = 2œÄ .
d)
T = œÄ .
e) T = œÄ .
f) T = œÄ .
2. Graphs of maps: see Fig. 3.7.
3. a) The minimum period is T = 2œÄ.

3.7 Exercises
101
x
y
0
œÄ
2œÄ
‚àíœÄ
‚àí2œÄ
a)
x
y
0
œÄ
2œÄ
‚àíœÄ
‚àí2œÄ
b)
x
y
0
œÄ
2œÄ
‚àíœÄ
‚àí2œÄ
c)
Figure 3.7. The graphs relative to Exercise 2
b) Variously using trigonometric identities one gets
f(x) = ‚àí4 + sin 3x + cos x cos2 x
= ‚àí4 + sin 3x + 1
2 cos x(1 + cos 2x)
= ‚àí4 + 1
2 cos x + sin 3x + 1
4(cos 3x + cos x)
= ‚àí4 + 3
4 cos x + sin 3x + 1
4 cos 3x .
c) As f is a trigonometric polynomial, the Fourier series is a Ô¨Ånite sum of simple
harmonics. Thus all types of convergence hold.
4. Fourier series‚Äô expansions:
a) The function is the sum of the trigonometric polynomial 1 ‚àí2 cosx and the
map g(x) = |x|. It is suÔ¨Écient to determine the Fourier series for g. The latter
is even, so bk = 0 for all k ‚â•1. Let us Ô¨Ånd the coeÔ¨Écients ak:
a0 = 1
2œÄ
 œÄ
‚àíœÄ
|x| dx = 1
œÄ
 œÄ
0
x dx = œÄ
2 ,
ak = 1
œÄ
 œÄ
‚àíœÄ
|x| cos kx dx = 2
œÄ
 œÄ
0
x cos kx dx
=
2
œÄk2

cos kx + kx sin kx
œÄ
0 =
2
œÄk2

(‚àí1)k ‚àí1

=
‚éß
‚é®
‚é©
0
if k even,
‚àí4
œÄk2
if k odd ,
k ‚â•1 .

102
3 Fourier series
In conclusion,
g ‚âàœÄ
2 ‚àí4
œÄ
‚àû

k=0
1
(2k + 1)2 cos(2k + 1)x ,
so
f ‚âà1 + œÄ
2 ‚àí

2 + 4
œÄ

cos x ‚àí4
œÄ
‚àû

k=1
1
(2k + 1)2 cos(2k + 1)x .
b)
f ‚âà1 + 2 sin x + 2
‚àû

k=3
(‚àí1)k+1
k
sin kx .
c) The map is even, so bk = 0 for all k ‚â•1. As for the ak:
a0 = 1
2œÄ
 œÄ
‚àíœÄ
4| sin3 x| dx = 4
œÄ
 œÄ
0
sin3 x dx = 4
œÄ
cos3 x
3
‚àícos x
œÄ
0
= 16
3œÄ
ak = 1
œÄ
 œÄ
‚àíœÄ
4| sin3 x| cos kx dx = 8
œÄ
 œÄ
0
sin3 x cos kx dx
= 2
œÄ
 œÄ
0
(3 sin x ‚àísin 3x) cos kx dx
=
‚éß
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é©
2
œÄ

sin4 x
œÄ
0
if k = 1 ,
6
œÄ
cos 2x
4
‚àícos 4x
8
œÄ
0
‚àí1
3œÄ

sin2 3x
œÄ
0
if k = 3 ,
2
œÄ

‚àí3
2
	cos(1 + k)x
1 + k
+ cos(1 ‚àík)x
1 ‚àík

+
1
2
	cos(3 ‚àík)x
3 ‚àík
+ cos(3 + k)x
3 + k

œÄ
0
if k Ã∏= 1, 3 ,
=
‚éß
‚é®
‚é©
0
if k = 1, k = 3,
48
œÄ(1 ‚àík2)(9 ‚àík2)

(‚àí1)k + 1

if k Ã∏= 1, 3 ,
=
‚éß
‚é®
‚é©
0
if k odd,
96
œÄ(1 ‚àík2)(9 ‚àík2)
if k even .
Overall,
f ‚âà16
3œÄ + 96
œÄ
‚àû

k=1
1
(1 ‚àí4k2)(9 ‚àí4k2) sin 2kx .

3.7 Exercises
103
d) Calculating the coeÔ¨Écients ak, bk gives:
a0 = 1
2œÄ
 œÄ
0
(‚àícos x) dx = 0 ,
ak = ‚àí1
œÄ
 œÄ
0
cos x cos kx dx
=
‚éß
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é©
‚àí1
œÄ
x
2 + sin 2x
4
œÄ
0
for k = 1 ,
‚àí1
œÄ
sin(1 ‚àík)x
2(1 ‚àík)
+ sin(1 + k)x
2(1 + k)
œÄ
0
for k Ã∏= 1 ,
=
!
‚àí1
2
for k = 1 ,
0
for k Ã∏= 1 ;
bk = ‚àí1
œÄ
 œÄ
0
cos x sin kx dx
=
‚éß
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é©
‚àí1
œÄ
sin2 x
2
œÄ
0
for k = 1 ,
1
œÄ
cos(k ‚àí1)x
2(k ‚àí1)
+ cos(k + 1)x
2(k + 1)
œÄ
0
for k Ã∏= 1 ,
=
‚éß
‚é®
‚é©
‚àí
2k
œÄ(k2 ‚àí1)
for k even ,
0
for k odd .
Therefore
f ‚âà‚àí1
2 cos x ‚àí4
œÄ
‚àû

k=1
k
4k2 ‚àí1 sin 2kx .
5. Fourier series‚Äô expansions:
a) f ‚âà1
2 + 2
œÄ
‚àû

k=1
(‚àí1)k‚àí1
2k ‚àí1 cos 2œÄ(2k ‚àí1)x .
b) f ‚âà2
œÄ ‚àí4
œÄ
‚àû

k=1
1
4k2 ‚àí1 cos 4œÄkx .
c) f ‚âà1
œÄ + 1
2 sin 2œÄx ‚àí2
œÄ
‚àû

k=1
1
4k2 ‚àí1 cos 4œÄkx .
d) f ‚âà1
4 ‚àí2
œÄ2
‚àû

k=1
1
(2k ‚àí1)2 cos 2œÄ(2k ‚àí1)x .

104
3 Fourier series
6. Since
f ‚âà1 + 1
27 sin 2x +
2
125 sin 4x + ¬∑ ¬∑ ¬∑ ,
we have T = œÄ, which is the minimum period of the simple harmonic sin 2x.
The function is not symmetric, as sum of the even map g(x) = 1 and the odd
one h(x) =
‚àû

k=1
k
(2k + 1)3 sin 2kx.
7. Sum of series:
a) We determine the Fourier coeÔ¨Écients for the 2œÄ-periodic map deÔ¨Åned as f(x) =
x2 on [‚àíœÄ,œÄ ]. Being even, it has bk = 0 for all k ‚â•1. Moreover,
a0 = 1
œÄ
 œÄ
0
x2 dx = œÄ2
3 ,
ak = 2
œÄ
 œÄ
0
x2 cos kx dx = 2
œÄ
2x
k2 cos kx +
	x2
k ‚àí2
k3

sin kx
œÄ
0
= 4
k2 (‚àí1)k ,
k ‚â•1 .
Therefore
f ‚âàœÄ2
3 + 4
‚àû

k=1
(‚àí1)k
k2
cos kx ;
Parseval‚Äôs identity yields
 œÄ
‚àíœÄ
x4 dx = 2
9œÄ5 + 16œÄ
‚àû

k=1
1
k4 ,
so
‚àû

k=1
1
k4 = œÄ4
90 .
b)
‚àû

k=1
1
k6 = œÄ6
945 .
8. Observe
f(x) =
 x2 ‚àí1
if x ‚àà[‚àíœÄ, ‚àí1] ‚à™[1, œÄ] ,
0
if x ‚àà(‚àí1, 1)
(Fig. 3.8). The map is even so bk = 0 for all k ‚â•1. Moreover
a0 = 1
œÄ
 œÄ
1
(x2 ‚àí1) dx = œÄ2
3 ‚àí1 + 2
3œÄ ,
ak = 2
œÄ
 œÄ
1
(x2 ‚àí1) cos kx dx

3.7 Exercises
105
x
y
0
œÄ
‚àíœÄ
2œÄ
‚àí2œÄ
Figure 3.8. The graph of f relative to Exercise 8
= 2
œÄ
 1
k3

2kx coskx + (k2x2 ‚àí2) sin kx

‚àísin kx
k
œÄ
1
=
4
œÄk2

(‚àí1)kœÄ + sin k
k
‚àícos k

,
k ‚â•1 ;
then
f ‚âàœÄ2
3 ‚àí1 + 2
3œÄ + 4
œÄ
‚àû

k=1
1
k2

(‚àí1)kœÄ + sin k
k
‚àícos k

cos kx .
9. For convenience let us draw the graph of f (Fig. 3.9).
As f is even, the coeÔ¨Écients bk for k ‚â•1 all vanish. The other ones are:
a0 = 1
œÄ
 œÄ/2
0
(œÄ ‚àíx) dx = 3
8œÄ ,
ak = 2
œÄ
 œÄ/2
0
(œÄ ‚àíx) cos kx dx = 2
sin kx
x
‚àí
1
œÄk2

cos kx + kx sin kx
œÄ/2
0
x
y
œÄ
‚àíœÄ
œÄ
2
‚àíœÄ
2
œÄ
œÄ
2
œÄ
4
0
Figure 3.9. The graph of f relative to Exercise 9

106
3 Fourier series
= 1
k sin œÄ
2 k ‚àí
2
œÄk2 cos œÄ
2 k +
2
œÄk2 ,
k ‚â•1 .
Hence
f ‚âà3
8œÄ +
‚àû

k=1
	1
k sin œÄ
2 k ‚àí
2
œÄk2 cos œÄ
2 k +
2
œÄk2

cos kx .
The series converges pointwise to f, regularised; in particular, for x = œÄ
2
œÄ
4 = 3
8œÄ +
‚àû

k=1
	1
k sin œÄ
2 k ‚àí
2
œÄk2 cos œÄ
2 k +
2
œÄk2

cos œÄ
2 k .
Now, as
sin œÄ
2 k =
 0
if k = 2m ,
(‚àí1)m
if k = 2m + 1 ,
cos œÄ
2 k =
 (‚àí1)m
if k = 2m ,
0
if k = 2m + 1 ,
we have
‚àíœÄ
8 =
‚àû

m=1
1
2œÄm2

(‚àí1)m ‚àí1

‚àí
‚àû

k=0
1
œÄ(2k + 1)2 ,
whence
‚àû

k=0
1
(2k + 1)2 = œÄ2
8 .
10. We have
ak = 0 , ‚àÄk ‚â•0;
b2 = b4 = 1 , b2m = 0 , ‚àÄm ‚â•3 ;
b2m+1 =
4
œÄ(2m + 1) , ‚àÄm ‚â•0 .
11. The graph is shown in Fig. 3.10. Let us begin by Ô¨Ånding the Fourier coeÔ¨Écients
of f. The map is even, implying bk = 0 for all k ‚â•1. What is more,
x
y
0
œÄ
‚àíœÄ
2œÄ
‚àí2œÄ
Figure 3.10. The graph of f relative to Exercise 11

3.7 Exercises
107
a0 = 1
œÄ
 œÄ
0
f(x) dx 1
œÄ
 œÄ/2
0
cos 2x dx ‚àí
 œÄ
œÄ/2
dx

= ‚àí1
2 ,
ak = 2
œÄ
 œÄ
0
f(x) cos kx dx 2
œÄ
 œÄ/2
0
cos 2x cos kx dx ‚àí
 œÄ
œÄ/2
cos kx dx

=
‚éß
‚é™
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é™
‚é©
2
œÄ
%x
2 + sin 4x
8
œÄ/2
0
‚àí
1
2 sin 2x
œÄ
œÄ/2
&
for k = 2 ,
2
œÄ
%sin(2 ‚àík)x
2(2 ‚àík)
+ sin(2 + k)x
2(2 + k)
œÄ/2
0
‚àí
1
k sin kx
œÄ
œÄ/2
&
for k Ã∏= 2 ,
=
‚éß
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é©
1
2
for k = 2 ,
0
for k = 2m , m > 1 ,
8(‚àí1)m
œÄ(2m + 1)

4 ‚àí(2m + 1)2
for k = 2m + 1 , m ‚â•0 .
Hence
f ‚âà‚àí1
2 + 1
2 cos 2x + 8
œÄ
‚àû

k=0
(‚àí1)k
(2k + 1)(3 ‚àí4k ‚àí4k2) cos(2k + 1)x .
Note the series converges uniformly on R by Weierstrass‚Äô M-test: for k ‚â•0,

(‚àí1)k
(2k + 1)(3 ‚àí4k ‚àí4k2) cos(2k + 1)x
 ‚â§
1
(2k + 1)(4k2 + 4k ‚àí3) = Mk ,
and
‚àû

k=0
Mk converges (like the generalised harmonic series of exponent 3, because
Mk ‚àº
1
8k3 , as k ‚Üí‚àû). In particular, the Fourier series converges for any x ‚ààR
pointwise. Alternatively, one could invoke Theorem 3.20.
Instead of computing directly the Fourier coeÔ¨Écients of f ‚Ä≤ with the deÔ¨Ånition,
we shall check if the convergence is uniform for the derivatives‚Äô Fourier series; thus,
we will be able to use Theorem 2.19. Actually one sees rather immediately f is
C1(R) with
f ‚Ä≤(x) =
 ‚àí2 sin 2x
if |x| < œÄ
2 ,
0
if œÄ
2 ‚â§|x| ‚â§œÄ ,
while f ‚Ä≤ is piecewise C1 on R (f ‚Ä≤‚Ä≤ has a jump discontinuity at ¬± œÄ
2 ). Therefore the
Fourier series of f ‚Ä≤ converges uniformly (hence, pointwise) on R, and so
f ‚Ä≤(x) = ‚àísin 2x + 8
œÄ
‚àû

k=0
(‚àí1)k
4k2 + 4k ‚àí3 sin(2k + 1)x .

108
3 Fourier series
12. We have
a0 = 1
2œÄ
 2œÄ
0
x2 dx = 4
3œÄ2 ,
ak = 1
œÄ
 2œÄ
0
x2 cos kx dx
= 1
œÄ
1
k x2 sin kx + 2
k2 x cos kx ‚àí2
k3 sin kx
2œÄ
0
= 4
k2 ,
k ‚â•1 ,
bk = 1
œÄ
 2œÄ
0
x2 sin kx dx
= 1
œÄ

‚àí1
k x2 cos kx + 2
k2 x sin kx + 2
k3 cos kx
2œÄ
0
= ‚àí4œÄ
k ,
k ‚â•1 ;
so the Fourier series of f is the given one.
The function f is continuous and piecewise monotone on R, so its Fourier series
converges to the regularised f pointwise ( Àúf(2kœÄ) = 2œÄ2, ‚àÄk ‚ààZ). Furthermore,
the series converges to f uniformly on all closed sub-intervals not containing the
points 2kœÄ, ‚àÄk ‚ààZ.
In particular,
f(œÄ) = œÄ2 = 4
3œÄ2 + 4
‚àû

k=1
1
k2 cos kœÄ = 4
3œÄ2 + 4
‚àû

k=1
(‚àí1)k
k2
whence
‚àû

k=1
(‚àí1)k
k2
= 1
4(œÄ2 ‚àí4
3œÄ2) = ‚àíœÄ2
12 .
13. The series
‚àû

k=1
1
2k sin kx converges to R uniformly because Weierstrass‚Äô M-test
applies with Mk =
1
2k ; this is due to
|fk(x)| =

1
2k sin kx
 ‚â§1
2k ,
‚àÄx ‚ààR .
Analogous results hold for the series of derivatives:
|f ‚Ä≤
k(x)| =

k
2k cos kx
 ‚â§k
2k ,
‚àÄx ‚ààR ,
|f ‚Ä≤‚Ä≤
k (x)| =

k2
2k sin kx
 ‚â§k2
2k ,
‚àÄx ‚ààR ,
...
|f (n)
k
(x)| ‚â§kn
2k ,
‚àÄx ‚ààR .

3.7 Exercises
109
Consequently, for all n ‚â•0 the series
‚àû

k=0
f (n)
k
(x) converges on R uniformly; by
Theorem 2.19 the map f is diÔ¨Äerentiable inÔ¨Ånitely many times: f ‚ààC‚àû(R). In
particular, the Fourier series of f ‚Ä≤ is
f ‚Ä≤(x) =
‚àû

k=1
k
2k cos kx ,
‚àÄx ‚ààR .
To compute ‚à•f‚à•2 we use Parseval‚Äôs formula
‚à•f‚à•2
2 =
 2œÄ
0
|f(x)|2 dx = 2œÄa0 + œÄ
‚àû

k=1
(a2
k + b2
k) = 4œÄ + œÄ
‚àû

k=1
1
4k
= 4œÄ + œÄ
	
1
1 ‚àí1
4
‚àí1

= 4œÄ + œÄ
3 = 13
3 œÄ ,
from which ‚à•f‚à•2 = 5
#
13
3 œÄ. At last,
 2œÄ
0
f(x) dx = 2œÄa0 = 4œÄ .
14. We have
f ‚âà2
‚àû

k=1
(‚àí1)k+1
k
sin kx .
This converges quadratically; it converges pointwise to the regularised map coin-
ciding with f for x Ã∏= œÄ + 2kœÄ and equal to 0 for x = œÄ + 2kœÄ, k ‚ààZ; it converges
uniformly on every closed interval not containing œÄ + 2kœÄ, k ‚ààZ.

4
Functions between Euclidean spaces
This chapter sees the dawn of the study of multivariable and vector-valued func-
tions, that is, maps between the Euclidean spaces Rn and Rm or subsets thereof,
with one of n and m bigger than 1. Subsequent chapters treat the relative diÔ¨Äer-
ential and integral calculus and constitute a large part of the course.
To warm up we brieÔ¨Çy recall the main notions related to vectors and matrices,
which students should already be familiar with. Then we review the indispensable
topological foundations of Euclidean spaces, especially neighbourhood systems of
a point, open and closed sets, and the boundary of a set. We discuss the properties
of subsets of Rn, which naturally generalise those of real intervals, highlighting the
features of this richer, higher-dimensional landscape.
We then deal with the continuity features of functions and their limits; despite
these extend the ones seen in dimension one, they require particular care, because
of the subtleties and snags speciÔ¨Åc to the multivariable setting.
At last, we start exploring a remarkable class of functions describing one- and
two-dimensional geometrical objects ‚Äì present in our everyday life ‚Äì called curves
and surfaces. The careful study of curves and surfaces will continue in the second
part of Chapter 6, at which point the diÔ¨Äerential calculus apparatus will be avail-
able. The aspects connected to integral calculus will be postponed to Chapter 9.
4.1 Vectors in Rn
Recall Rn is the vector space of ordered n-tuples x = (xi)i=1,...,n, called vectors.
The components xi of x may be written either horizontally, to give a row vector
x = (x1, . . . , xn) ,
or vertically, producing a column vector
x =
‚éõ
‚éù
x1
...
xn
‚éû
‚é†= (x1, . . . , xn)T .
C. Canuto, A. Tabacco: Mathematical Analysis II, 2nd Ed.,
UNITEXT ‚Äì La Matematica per il 3+2 85, DOI 10.1007/978-3-319-12757-6_4,
¬© Springer International Publishing Switzerland 2015

112
4 Functions between Euclidean spaces
These two expressions will be equivalent in practice, except for some cases where
writing vertically or horizontally will make a diÔ¨Äerence. For typesetting reasons
the horizontal notation is preferable.
Any vector of Rn can be represented using the canonical basis {e1, . . . , en}
whose vectors have components all zero except for one that equals 1
ei = (Œ¥ij)1‚â§j‚â§n
where Œ¥ij =

1
if i = j
0
if i Ã∏= j
.
(4.1)
Then
x =
n

i=1
xiei .
(4.2)
The vectors of the canonical basis are usually denoted by i, j in R2 and i, j, k in
R3. It can be useful to identify a vector (x1, x2) = x1i + x2j ‚ààR2 with the vector
(x1, x2, 0) = x1i + x2j + 0 k ‚ààR3: the expression x1i + x2j will thus indicate a
vector of R2 or R3, according to the context.
In Rn the dot product of two vectors is deÔ¨Åned as
x ¬∑ y = x1y1 + . . . + xnyn =
n

i=1
xiyi .
This in turn deÔ¨Ånes the Euclidean norm
‚à•x‚à•= ‚àöx ¬∑ x =
+
,
,
-
n

i=1
x2
i ,
for which the Cauchy-Schwarz inequality
|x ¬∑ y| ‚â§‚à•x‚à•‚à•y‚à•
(4.3)
and the triangle inequality
‚à•x + y‚à•‚â§‚à•x‚à•+ ‚à•y‚à•
(4.4)
hold. Two vectors x and y satisfying x ¬∑ y = 0 are called orthogonal, and a
vector x such that ‚à•x‚à•= 1 is said a unit vector, or of length 1. The canonical
basis of Rn is an example of an orthonormal system of vectors, i.e., a set of n
normalised and pairwise orthogonal vectors; its elements satisfy in fact
ei ¬∑ ej = Œ¥ij ,
1 ‚â§i, j ‚â§n .
From (4.2) we have
xi = x ¬∑ ei
for the ith component of a vector x.
It makes sense to associate x ‚ààRn to the unique point P in Euclidean n-
space whose coordinates in an orthogonal Cartesian frame are the components of

4.1 Vectors in Rn
113
x; this fact extends what we already know for the plane and space. Under this
identiÔ¨Åcation ‚à•x‚à•is the Euclidean distance between the point P, of coordinates
x, and the origin O. The quantity ‚à•x ‚àíy‚à•=

(x1 ‚àíy1)2 + . . . + (xn ‚àíyn)2 is
the distance between the points P and Q of respective coordinates x and y.
In R3 the cross or wedge product x ‚àßy of two vectors x = x1i + x2j + x3k
and y = y1i + y2j + y3k is the vector of R3 deÔ¨Åned by
x ‚àßy = (x2y3 ‚àíx3y2)i + (x3y1 ‚àíx1y3)j + (x1y2 ‚àíx2y1)k .
(4.5)
It can also be computed by the formula
x ‚àßy = det
‚éõ
‚éù
i
j
k
x1
x2
x3
y1
y2
y3
‚éû
‚é†
(4.6)
by expanding the determinant formally along the Ô¨Årst row (see deÔ¨Ånition (4.11)).
The cross product of two vectors is orthogonal to both (Fig. 4.1, left):
(x ‚àßy) ¬∑ x = 0 ,
(x ‚àßy) ¬∑ y = 0 .
(4.7)
The number ‚à•x‚àßy‚à•is the area of the parallelogram with the vectors x, y as sides,
while ‚à•(x ‚àßy) ¬∑ z‚à•represents the volume of the prism of sides x, y, z (Fig. 4.1).
We have some properties:
y ‚àßx = ‚àí(x ‚àßy) ,
x ‚àßy = 0
‚áê‚áí
x = Œªy for some Œª ‚ààR ,
(x + y) ‚àßz = x ‚àßz + y ‚àßz ,
(4.8)
the Ô¨Årst of which implies x ‚àßx = 0.
Furthermore,
i ‚àßj = k ,
j ‚àßk = i ,
k ‚àßi = j ;
these and previous ones prove for instance that if x = x1i + x2j, y = y1i + y2j
then x ‚àßy = (x1y2 ‚àíx2y1)k.
 
 
 
x
y
x ‚àßy
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
x
y
z
Figure 4.1. Wedge products x ‚àßy (left) and (x ‚àßy) ¬∑ z (right)

114
4 Functions between Euclidean spaces
A triple (v1, v2, v3) of pairwise non-aligned, unit vectors is said positively
oriented (or right-handed) if
(v1 ‚àßv2) ¬∑ v3 > 0 ,
i.e., if v3 and v1 ‚àßv2 lie on the same side of the plane spanned by v1 and v2. A
practical way to decide whether a triple is positively oriented is to use the right-
hand rule: the pointing Ô¨Ånger is v1, the long Ô¨Ånger v2, the thumb v3. (The left
hand works, too, as long as we take the long Ô¨Ånger for v1, the pointing Ô¨Ånger for
v2 and the thumb for v3.)
The triple (v1, v2, v3) is negatively oriented (or left-handed) if (v1, v2, ‚àív3)
is oriented positively
(v1 ‚àßv2) ¬∑ v3 < 0 .
4.2 Matrices
A real matrix A with m rows and n columns (an m √ó n matrix) is a collection of
m √ó n real numbers arranged in a table
A =
‚éõ
‚éú
‚éú
‚éú
‚éù
a11
a12
. . .
a1n
a21
a22
. . .
a2n
...
am1
am2
. . .
amn
‚éû
‚éü
‚éü
‚éü
‚é†
or, more concisely,
A = (aij) 1‚â§i‚â§m
1‚â§j ‚â§n
‚ààRmn .
The vectors formed by the entries of one row (resp. column) of A are the row
vectors (column vectors) of A. Thus m √ó 1 matrices are vectors of Rm written as
column vectors, while 1 √ó n matrices are vectors of Rn seen as row vectors. When
m = n the matrix is called square of order n. The set of m √ó n matrices is a
vector space: usually indicated by Rm,n, it is isomorphic to the Euclidean space
Rmn. The matrix C = ŒªA + ŒºB, Œª, Œº ‚ààR, has entries
cij = Œªaij + Œºbij ,
1 ‚â§i ‚â§m , 1 ‚â§j ‚â§n .
If A is m √ó n and B is n √ó p, the product C = AB has by deÔ¨Ånition m rows and
p columns; its generic entry is the dot product of a row vector of A with a column
vector of B:
cij =
n

k=1
aikbkj ,
1 ‚â§i ‚â§m , 1 ‚â§j ‚â§p .
In particular, if B = x is n √ó 1, hence a column vector in Rn, the matrix product
with the vector Ax is well deÔ¨Åned: it is a column vector in Rm. If p = m, we have

4.2 Matrices
115
square matrices AB of order m and BA of order n. If n = m, AB Ã∏= BA in
general, because the product of matrices is not commutative.
The Ô¨Årst minor Aij (1 ‚â§i ‚â§m, 1 ‚â§j ‚â§n) of an m √ó n matrix A is the
(m ‚àí1) √ó (n ‚àí1) matrix obtained erasing from A the ith row and jth column.
The rank r ‚â§min(m, n) of A is the maximum number of linearly independent
rows thought of as vectors of Rn (or linearly independent columns, seen as vectors
of Rm).
Given an m √ó n matrix A, its transpose is the n √ó m matrix AT with entries
aT
ij = aji ,
1 ‚â§i ‚â§n , 1 ‚â§j ‚â§m ;
otherwise put, AT is obtained from A by orderly swapping rows and columns;
clearly, (AT )T = A. Whenever deÔ¨Åned, the product of matrices satisÔ¨Åes (AB)T =
BT AT . The dot product of vectors in Rn is a special case of matrix product
x ¬∑ y = xT y = yT x, provided we think x and y as column vectors.
In Rm,n there is a norm, associated to the Euclidean norm,
‚à•A‚à•= max{‚à•Ax‚à•: x ‚ààRn, ‚à•x‚à•= 1} ,
(4.9)
that satisÔ¨Åes the inequalities
‚à•Ax‚à•‚â§‚à•A‚à•‚à•x‚à•
and
‚à•AB‚à•‚â§‚à•A‚à•‚à•B‚à•
(4.10)
for any x ‚ààRn and B ‚ààRn,p.
Square matrices
From now on we will consider square matrices of order n. Among them a par-
ticularly important one is the identity matrix I = (Œ¥ij)1‚â§i,j‚â§n, which satisÔ¨Åes
AI = IA = A for any square matrix A of order n. A matrix A is called sym-
metric if it coincides with its transpose
aij = aji ,
1 ‚â§i, j ‚â§n ;
it is normal if AAT = AT A, and in particular orthogonal if AAT = AT A = I.
To each square matrix A one can associate a number det A, the determinant
of A, which may be computed recursively using Laplace‚Äôs rule: det A = a if n = 1
and A = (a), whereas for n > 1
det A =
n

j=1
(‚àí1)i+jaij det Aij ,
(4.11)
where i ‚àà{1, . . . , n} is arbitrary, but Ô¨Åxed. For instance
det
	
a
b
c
d

= ad ‚àíbc .

116
4 Functions between Euclidean spaces
The following properties hold:
det(AB) = det A det B ,
det(ŒªA) = Œªn det A ,
det AT = det A ,
det A‚Ä≤ = ‚àídet A
if A‚Ä≤ is A with two rows (or columns) exchanged. Immediate consequences are
that det I = 1 and | det A| = 1 for A orthogonal.
The matrix A is said non-singular if det A Ã∏= 0. This is equivalent to the
invertibility of A, i.e., the existence of a matrix A‚àí1 of order n, called the inverse
of A, such that
AA‚àí1 = A‚àí1A = I .
If A and B are invertible,
det(A‚àí1) = (det A)‚àí1 ,
(AB)‚àí1 = B‚àí1A‚àí1 ,
(AT )‚àí1 = (A‚àí1)T ;
from the last equation it follows, as special case, that the inverse of a symmetric
matrix is still symmetric. Every orthogonal matrix A is invertible, for A‚àí1 = AT .
There are several equivalent conditions to invertibility, among which:
‚Ä¢
the rank of A equals n;
‚Ä¢
the linear system Ax = b has a solution x ‚ààRn for any b ‚ààRn;
‚Ä¢
the homogeneous linear system Ax = 0 has only the trivial solution x = 0.
The last one amounts to saying that 0 is no eigenvalue of A.
Eigenvalues and eigenvectors
The eigenvalues of A are the zeroes (in C) of the characteristic polynomial
of degree n
œá(Œª) = det(A ‚àíŒªI) .
In other words, the eigenvalues are complex numbers Œª for which there exists a
vector v Ã∏= 0, called (right) eigenvector of A associated to Œª, such that
Av = Œªv
(4.12)
(here and henceforth all vectors should be thought of as column vectors). The
Fundamental Theorem of Algebra predicts the existence of p distinct eigenvalues
Œª(1), . . . , Œª(p) with 1 ‚â§p ‚â§n, each having algebraic multiplicity (as root of the
polynomial œá) Œº(i), such that Œº(1) + . . . + Œº(p) = n. The maximum number of
linearly independent eigenvectors associated to Œª(i) is the geometric multiplicity
of Œª(i); we denote it by m(i), and observe m(i) ‚â§Œº(i). Eigenvectors associated to
distinct eigenvalues are linearly independent. Therefore when the algebraic and
geometric multiplicities of each eigenvalue coincide, there are in total n linearly
independent eigenvectors, and thus a basis made of eigenvectors. In such a case
the matrix is diagonalisable.
The name means that the matrix can be made diagonal. To see this we number
the eigenvalues by Œªk, 1 ‚â§k ‚â§n for convenience, repeating each one as many times

4.2 Matrices
117
as its multiplicity; let vk be an eigenvector associated to Œªk, chosen so that the
set {vk}1‚â§k‚â§n is made of linearly independent vectors. The equations
Avk = Œªkvk ,
1 ‚â§k ‚â§n ,
can be rewritten in matrix form
AP = P Œõ ,
(4.13)
where Œõ = diag (Œª1, . . . , Œªn) is the diagonal matrix with the eigenvalues as entries,
and P = (v1, . . . , vn) is the square matrix of order n whose columns are the
eigenvectors of A. The linear independence of the eigenvectors is equivalent to the
invertibility of P , so that (4.13) becomes
A = P Œõ P‚àí1 ,
(4.14)
and consequently A is similar to a diagonal matrix.
Returning to the general setting, it is relevant to notice that as A is a real
matrix (making the characteristic polynomial a real polynomial), its eigenvalues
are either real or complex conjugate; the same is true for the corresponding eigen-
vectors. The determinant of A coincides with the product of the eigenvalues
det A = Œª1Œª2 ¬∑ ¬∑ ¬∑ Œªn‚àí1Œªn .
The eigenvalues of A2 = AA are the squares of those of A, with the same eigen-
vectors, and the analogue fact will hold for the generic power of A. At the same
time, if A is invertible, the eigenvalues of the inverse matrix are the inverses of
the eigenvalues of A, while the eigenvectors stay the same; by assumption in fact,
(4.12) is equivalent to
v = ŒªA‚àí1v ,
so
A‚àí1v = 1
Œªv .
The spectral radius of A is by deÔ¨Ånition the maximum modulus of the ei-
genvalues
œÅ(A) = max
1‚â§k‚â§n |Œªk| .
The (Euclidean) norm of A satisÔ¨Åes
‚à•A‚à•=
#
œÅ(AT A) ;
a special case is that of symmetric matrices A, for which ‚à•A‚à•= œÅ(A); if A is
additionally orthogonal, then ‚à•A‚à•=

œÅ(I) = 1.
Symmetric matrices
Symmetric matrices A have pivotal properties concerning eigenvalues and eigen-
vectors. Each eigenvalue is real and its algebraic and geometric multiplicities coin-
cide, rendering A always diagonalisable. The eigenvectors, all real, may be chosen

118
4 Functions between Euclidean spaces
to form an orthonormal basis (in fact, eigenvectors relative to distinct eigenvalues
are orthogonal, those with same eigenvalue can be made orthonormal); the matrix
P associated to such a basis is thus orthogonal, so (4.14) reads
A = P Œõ PT .
(4.15)
Hence the transformation x ‚ÜíP T x = y deÔ¨Ånes an orthogonal change of basis in
Rn, from the canonical basis {ei}1‚â§i‚â§n to the basis of eigenvectors {vk}1‚â§k‚â§n; in
this latter basis A is diagonal. The inverse transformation is y ‚ÜíP y = x.
Every real symmetric matrix A is associated to a quadratic form Q, which
is a function Q : Rn ‚ÜíR satisfying Q(Œªx) = Œª2Q(x) for any x ‚ààRn, Œª ‚ààR; to
be precise,
Q(x) = 1
2x ¬∑ Ax = 1
2xT Ax .
(4.16)
The eigenvalues of A determine the quadratic form Q: substituting to A the
expression (4.15) and setting y = P T x, we get
Q(x) = 1
2xT P Œõ PT x = 1
2(P T x)T Œõ(P T x) = 1
2yT Œõy .
Since Œõy = (Œªkyk)1‚â§k‚â§n if y = (yk)1‚â§k‚â§n, we conclude
Q(x) = 1
2
n

k=1
Œªky2
k .
(4.17)
Consequently, one can classify A according to the sign of Q:
‚Ä¢
A is positive deÔ¨Ånite if Q(x) > 0 for any x ‚ààRn, x Ã∏= 0; equivalently, all
eigenvalues of A are strictly positive.
‚Ä¢
A is positive semi-deÔ¨Ånite if Q(x) ‚â•0 for any x ‚ààRn; equivalently, all
eigenvalues of A are non-negative.
‚Ä¢
A is indeÔ¨Ånite if Q assumes on Rn both positive and negative values; this is
to say A has positive and negative eigenvalues.
The notion of negative-deÔ¨Ånite and negative semi-deÔ¨Ånite matrices are clear.
Positive-deÔ¨Ånite symmetric matrices may be characterised in many other equi-
valent ways. For example, all Ô¨Årst minors of A (those obtained by erasing the same
rows and columns) have positive determinant. In particular, the diagonal entries
aii are positive.
A crucial geometrical characterisation is the following: if A is positive deÔ¨Ånite
and symmetric, the level sets
{x ‚ààRn : Q(x) = c > 0}
of Q are generalised ellipses (e.g., ellipses in dimension 2, ellipsoids in dimension
3), with axes collinear to the eigenvectors of A.

4.2 Matrices
119
x1
x2
y1
y2
v1
v2
y ‚Üíx = Py
Figure 4.2. The conic associated to a positive-deÔ¨Ånite symmetric matrix
In fact, (restricting to dimension two for simplicity) the equation
1
2(Œª1y2
1 + Œª2y2
2) = c ,
i.e.,
y2
1

2c/Œª1
 +
y2
2

2c/Œª2
 = 1
deÔ¨Ånes an ellipse in canonical form with semi-axes of length

2c/Œª1 and

2c/Œª2
in the coordinates (y1, y2) associated to the eigenvectors v1, v2. In the original
coordinates (x1, x2) the ellipse is rotated in the directions of v1, v2 (Fig. 4.2).
Equation (4.17) implies easily
Q(x) ‚â•Œª‚àó
2 ‚à•x‚à•2 ,
‚àÄx ‚ààRn ,
(4.18)
where Œª‚àó= min
1‚â§k‚â§n Œªk. In fact,
Q(x) ‚â•Œª‚àó
2
n

k=1
y2
k = Œª‚àó
2 ‚à•y‚à•2
and ‚à•y‚à•2 = ‚à•P T x‚à•2 = xT P P T x = xT x = ‚à•x‚à•2 as P is orthogonal.
Example 4.1
Take the symmetric matrix of order 2
A =

4
Œ±
Œ±
2

with Œ± a real parameter. Solving the characteristic equation det(A ‚àíŒªI) =
(4 ‚àíŒª)(2 ‚àíŒª) ‚àíŒ±2 = 0, we Ô¨Ånd the eigenvalues:
Œª1 = 3 ‚àí

1 + Œ±2 ,
Œª2 = 3 +

1 + Œ±2 > 0 .
Then
|Œ±| < 2
‚àö
2
‚áí
Œª1 > 0
‚áí
A positive deÔ¨Ånite ,
|Œ±| = 2
‚àö
2
‚áí
Œª1 = 0
‚áí
A positive semi-deÔ¨Ånite ,
|Œ±| > 2
‚àö
2
‚áí
Œª1 < 0
‚áí
A indeÔ¨Ånite .
2

120
4 Functions between Euclidean spaces
4.3 Sets in Rn and their properties
The study of limits and the continuity of functions of several variables require that
we introduce some notions on vectors and subsets of Rn.
Using distances we deÔ¨Åne neighbourhoods in Rn.
DeÔ¨Ånition 4.2 Take x0 ‚ààRn and let r > 0 be a real number. One calls
neighbourhood of x0 of radius r the set
Br(x0) = {x ‚ààRn : ‚à•x ‚àíx0‚à•< r}
consisting of all points in Rn with distance from x0 smaller than r. The set
Br(x0) = {x ‚ààRn : ‚à•x ‚àíx0‚à•‚â§r}
is called closed neighbourhood of x0 of radius r.
Therefore Br(x0) is the disc (n = 2) or the ball (n = 3) centred at x0 of radius r,
while Br(x0) is a disc or ball without boundary.
If X is a subset of Rn, by C X = Rn \ X we denote the complement of X.
DeÔ¨Ånition 4.3 A point x ‚ààRn is called
i) an interior point of X if there is a neighbourhood Br(x) contained in
X;
ii) an exterior point of X if it belongs to the interior of C X;
iii) a boundary point of X if it is neither interior nor exterior for X.
Fig. 4.3 depicts the various possibilities.
Boundary points can also be deÔ¨Åned as the points whose every neighbourhood
contains points of X and C X alike. It follows that X and its complement have
the same boundary set.
DeÔ¨Ånition 4.4 The set of interior points of X forms the interior of X,
denoted by
‚ó¶
X or int X. Similarly, boundary points form the boundary of
X, written ‚àÇX. Exterior points form the exterior of X. Eventually, the set
X ‚à™‚àÇX is the closure of X, written X.
To be absolutely accurate, given a topological space X the set ‚àÇX deÔ¨Åned above
should be called ‚Äòfrontier‚Äô, because the term ‚Äòboundary‚Äô is used in a diÔ¨Äerent sense
for topological manifolds (deÔ¨Åning the topology of which is a rather delicate mat-

4.3 Sets in Rn and their properties
121
 
 
 
 
x2
X
x1
x3
Figure 4.3. An interior point x1, a boundary point x2, an exterior point x3 of a set X
ter). Section 6.7.3 will discuss explicit examples where X is a surface. We shall
not be this subtle and always speak about the boundary ‚àÇX of X.
From the deÔ¨Ånition,
‚ó¶
X ‚äÜX ‚äÜX .
When one of the above inclusions is an equality the space X deserves one of the
following names:
DeÔ¨Ånition 4.5 The set X is open if all its points are interior points,
‚ó¶
X =
X. It is closed if it contains its boundary, X = X.
A set is then open if and only if it contains a neighbourhood of each of its points,
i.e., when it does not contain boundary points. Consequently, X is closed precisely
if its complement is open, since a set and its complement share the boundary.
Examples 4.6
i) The sets Rn and ‚àÖare simultaneously open and closed (and are the only such
subsets of Rn, by the way). Their boundary is empty.
ii) The half-plane X = {(x, y) ‚ààR2 : x > 1} is open. In fact, given (x0, y0) ‚ààX,
any neighbourhood of radius r ‚â§x0 ‚àí1 is contained in X (Fig. 4.4, left). The
boundary ‚àÇX is the line x = 1 parallel to the y-axis (Fig. 4.4, right), hence the
complementary set C X = {(x, y) ‚ààR2 : x ‚â§1} is closed.
Any half-plane X ‚äÇR2 deÔ¨Åned by an inequality like
ax + by > c
or
ax + by < c ,
with one of a, b non-zero, is open; inequalities like
ax + by ‚â•c
or
ax + by ‚â§c
deÔ¨Åne closed half-planes. In either case the boundary ‚àÇX is the line ax + by = c.

122
4 Functions between Euclidean spaces
X
x
y
r
x0
Br(x0)
X
x
y
‚àÇX
Figure 4.4. The boundary (right) of the half-plane x > 1 and the neighbourhood of a
point (left)
iii) Let X = B1(0) = {x ‚ààRn : ‚à•x‚à•< 1} be the n-dimensional ball with centre
the origin and radius 1, without boundary. It is open, because for any x0 ‚ààX,
Br(x0) ‚äÜX if we set r ‚â§1 ‚àí‚à•x0‚à•: for ‚à•x ‚àíx0‚à•< r in fact, we have
‚à•x‚à•= ‚à•x ‚àíx0 + x0‚à•‚â§‚à•x ‚àíx0‚à•+ ‚à•x0‚à•< 1 ‚àí‚à•x0‚à•+ ‚à•x0‚à•= 1 .
The boundary ‚àÇX = {x ‚ààRn : ‚à•x‚à•= 1} is the ‚Äòsurface‚Äô of the ball (the
n-dimensional sphere), while the closure of X is the ball itself, i.e., the closed
neighbourhood B1(0).
In general, for arbitrary x0 ‚ààRn and r > 0, the neighbourhood Br(x0) is open,
it has boundary {x ‚ààRn : ‚à•x‚àíx0‚à•= r}, and the closed neighbourhood Br(x0)
is the closure.
iv) The set X = {x ‚ààRn : 2 ‚â§‚à•x ‚àíx0‚à•< 3} (an annulus for n = 2, a spherical
shell for n = 3) is neither open nor closed, for its interior is
‚ó¶
X = {x ‚ààRn : 2 < ‚à•x ‚àíx0‚à•< 3}
and the closure
X = {x ‚ààRn : 2 ‚â§‚à•x ‚àíx0‚à•‚â§3} .
The boundary,
‚àÇX = {x ‚ààRn : ‚à•x ‚àíx0‚à•= 2} ‚à™{x ‚ààRn : ‚à•x ‚àíx0‚à•= 3} ,
is the union of the two spheres delimiting X.
v) The set X = [0, 1]2 ‚à©Q2 of points with rational coordinates inside the unit
square has empty interior and the whole square [0, 1]2 as boundary. Since rational
numbers are dense in R, any neighbourhood of a point in [0, 1]2 contains inÔ¨Ånitely
many points of X and inÔ¨Ånitely many of the complement.
2

4.3 Sets in Rn and their properties
123
DeÔ¨Ånition 4.7 A point x ‚ààRn is called a limit point of X if each of its
neighbourhoods contains points of X diÔ¨Äerent from x:
‚àÄr > 0 ,

Br(x) \ {x}

‚à©X Ã∏= ‚àÖ.
A point x ‚ààX is isolated if there exists a neighbourhood Br(x) not contain-
ing points of X other than x:
‚àÉr > 0 ,

Br(x) \ {x}

‚à©X = ‚àÖ,
or equivalently,
‚àÉr > 0 ,
Br(x) ‚à©X = {x} .
Interior points of X are certainly limit points in X, whereas no exterior point can
be a limit point. A boundary point of X must necessarily be either a limit point
of X (belonging to X or not) or an isolated point. Conversely, a limit point can
be interior or a non-isolated boundary point, and an isolated point is forced to lie
on the boundary.
Example 4.8
Consider X the set X = {(x, y) ‚ààR2 : y2
x2 ‚â§1 or x2 + (y ‚àí1)2 ‚â§0} .
Requiring
y2
x2 ‚â§1, hence
|y|
|x| ‚â§1, deÔ¨Ånes the region lying between the lines
y = ¬±x (included) and containing the x-axis except the origin (due to the
denominator). To this we have to add the point (0, 1), the unique solution to
x2 + (y ‚àí1)2 ‚â§0. See Fig. 4.5.
The limit points of X are those satisfying y2 ‚â§x2. They are either interior, when
y2 < x2, or boundary points, when y = ¬±x (origin included). An additional
boundary point is (0, 1), also the only isolated point.
2
x
y
y = ‚àíx
y = x
1
Figure 4.5. The set X = {(x, y) ‚ààR2 : y2
x2 ‚â§1 or x2 + (y ‚àí1)2 ‚â§0}

124
4 Functions between Euclidean spaces
Let us deÔ¨Åne a few more notions that will be useful in the sequel.
DeÔ¨Ånition 4.9 A set X is bounded if there exists a real number R > 0
such that
‚à•x‚à•‚â§R ,
‚àÄx ‚ààX ,
i.e., if X is contained in a closed neighbourhood BR(0) of the origin.
DeÔ¨Ånition 4.10 A set X is said compact if it is closed and bounded.
Examples 4.11
i) The unit square X = [0, 1]2 ‚äÇR2 is compact; it manifestly contains its bound-
ary, and if we take x ‚ààX,
‚à•x‚à•=
#
x2
1 + x2
2 ‚â§
‚àö
1 + 1 =
‚àö
2 .
In general, the n-dimensional cube X = [0, 1]n ‚äÇRn is compact.
ii) The elementary plane Ô¨Ågures (such as rectangles, polygons, discs, ovals) and
solids (tetrahedra, prisms, pyramids, cones and spheres) are all compact.
iii) The closure of a bounded set is compact.
2
Let a , b be distinct points of Rn, and call S[a, b] the (closed) segment with
end points a, b, i.e., the set of points on the line through a and b that lie between
the two points:
S[a, b] = {x = a + t(b ‚àía) : 0 ‚â§t ‚â§1}
= {x = (1 ‚àít)a + tb : 0 ‚â§t ‚â§1} .
(4.19)
DeÔ¨Ånition 4.12 A set X is called convex if the segment between any two
points of X is all contained in X.
Given r +1 points a0, a1, . . . , ar in Rn, all distinct (except possibly for a0 = ar),
one calls polygonal path of vertices a0, a1, . . . , ar the union of the r segments
S[ai‚àí1, ai], 1 ‚â§i ‚â§r, joint at the end points:
P[a0, . . . , ar] =
r0
i=1
S[ai‚àí1, ai] .
DeÔ¨Ånition 4.13 An open set A ‚äÜRn is (path-)connected if, given two
arbitrary points x, y in A, there is a polygonal path joining them that is
entirely contained in A.
Figure 4.6 shows an example.

4.3 Sets in Rn and their properties
125
x
y
A
Figure 4.6. A connected (but not convex) set A
Examples 4.14
i) The only open connected subsets of R are the open intervals.
ii) An open and convex set A in Rn is obviously connected.
iii) Any annulus A = {x ‚ààR2 : r1 < ‚à•x ‚àíx0‚à•< r2}, with x0 ‚ààR2, r2 > r1 ‚â•0,
is connected but not convex (Fig. 4.7, left). Finding a polygonal path between
any two points x, y ‚ààA is intuitively quite easy.
iv) The open set A = {x = (x, y) ‚ààR2 : xy > 1} is not connected (Fig. 4.7,
right).
2
It is a basic fact that an open non-empty set A of Rn is the union of a family
{Ai}i‚ààI of non-empty, connected and pairwise-disjoint open sets:
A =
0
i‚ààI
Ai
with
Ai ‚à©Aj = ‚àÖfor i Ã∏= j .
Each Ai is called a connected component of A.
x
y
x
y
x
y
xy = 1
Figure 4.7. The set A of Examples 4.14 iii) (left) and iv) (right)

126
4 Functions between Euclidean spaces
Every open connected set has only one connected component, namely itself.
The set A of Example 4.14 iv) has two connected components
A1 = {x = (x, y) ‚ààA : x > 0}
and
A2 = {x = (x, y) ‚ààA : x < 0} .
DeÔ¨Ånition 4.15 We call region any subset R of Rn made by the union of
a non-empty, open, connected set A and part of the boundary ‚àÇA
R = A ‚à™Z
with
‚àÖ‚äÜZ ‚äÜ‚àÇA .
When Z = ‚àÖthe region is open, when Z = ‚àÇA it is closed.
A region may be deÔ¨Åned equivalently as a non-empty set R of Rn whose interior
A =
‚ó¶
R is connected and such that A ‚äÜR ‚äÜA.
Example 4.16
The set R = {x ‚ààR2 :

4 ‚àíx2 ‚àíy2 < 1} is a region in the plane, for
R = {x ‚ààR2 :
‚àö
3 < ‚à•x‚à•‚â§2} .
Therefore A =
‚ó¶
R is the open annulus {x ‚ààR2 :
‚àö
3 < ‚à•x‚à•< 2}, while Z = {x ‚àà
R2 : ‚à•x‚à•= 2} ‚äÇ‚àÇA.
2
4.4 Functions: deÔ¨Ånitions and Ô¨Årst examples
We begin discussing real-valued maps, sometimes called (real) scalar functions.
Let n be a given integer ‚â•1. A function f deÔ¨Åned on Rn with values in R is a
real function of n real variables; if dom f denotes its domain, we write
f : dom f ‚äÜRn ‚ÜíR .
The graph Œì(f) = {(x, f(x)) ‚ààRn+1 : x ‚ààdom f} is a subset of Rn+1.
The case n = 1 (one real variable) was dealt with in Vol. I exhaustively, so in
the sequel we will consider scalar functions of two or more variables. If n = 2 or 3
the variable x will also be written as (x, y) or (x, y, z), respectively.
Examples 4.17
i) The map z = f(x, y) = 2x ‚àí3y, deÔ¨Åned on R2, has the plane 2x ‚àí3y ‚àíz = 0
as graph.
ii) The function z = f(x, y) = y2 + x2
y2 ‚àíx2 is deÔ¨Åned on R2 without the lines y = ¬±x.
iii) The function w = f(x, y, z) =

z ‚àíx2 ‚àíy2 has domain dom f = {(x, y, z) ‚àà
R3 : z ‚â•x2 + y2}, which is made of the elliptic paraboloid z = x2 + y2 and the
region inside of it.

4.4 Functions: deÔ¨Ånitions and Ô¨Årst examples
127
iv) The function f(x) = f(x1, . . . , xn) = log(1 ‚àíx2
1 ‚àí. . . ‚àíx2
n) is deÔ¨Åned inside
the n-dimensional sphere x2
1+. . .+x2
n = 1, since dom f =

x ‚ààRn :
n

i=1
x2
i < 1

.
2
In principle, a scalar function can be drawn only when n ‚â§2. For example,
f(x, y) =

9 ‚àíx2 ‚àíy2 has graph in R3 given by z =

9 ‚àíx2 ‚àíy2. Squaring the
equation yields
z = 9 ‚àíx2 ‚àíy2
hence
x2 + y2 + z2 = 9 .
We recognise the equation of a sphere with centre the origin and radius 3. As
z ‚â•0, the graph of f is the hemisphere of Fig. 4.8.
Another way to visualise a function‚Äôs behaviour, in two or three variables, is
by Ô¨Ånding its level sets. Given a real number c, the level set
L(f, c) = {x ‚ààdom f : f(x) = c}
(4.20)
is the subset of Rn where the function is constant, equal to c. Figure 4.9 shows
some level sets for the function z = f(x, y) of Example 4.9 ii).
Geometrically, in dimension n = 2, a level set is the projection on the xy-plane
of the intersection between the graph of f and the plane z = c. Clearly, L(f, c) is
not empty if and only if c ‚ààim f. A level set may have an extremely complicated
shape. That said, we shall see in Sect. 7.2 certain assumptions on f that guarantee
L(f, c) consists of curves (dimension two) or surfaces (dimension three).
Consider now the more general situation of a map between Euclidean spaces,
and precisely: given integers n, m ‚â•1, we denote by f an arbitrary function on
Rn with values in Rm
f : dom f ‚äÜRn ‚ÜíRm .
x
y
z
(0, 0, 3)
(0, 3, 0)
(3, 0, 0)
Figure 4.8. The function f(x, y) =

9 ‚àíx2 ‚àíy2

128
4 Functions between Euclidean spaces
x
y
Figure 4.9. Level sets for z = f(x, y) = y2 + x2
y2 ‚àíx2
If m = 1, we have the scalar functions of above. If m ‚â•2 we shall say f is a real
vector-valued function.
Let us see some interesting cases. Curves, seen in Vol. I for m = 2 (plane
curves) and m = 3 (curves in space), are special vector-valued maps where n = 1;
surfaces in space are vector-valued functions with n = 2 and m = 3. The study of
curves and surfaces is postponed to Sects. 4.6, 4.7 and Chapter 6 in particular. In
the case n = m, f is called a vector Ô¨Åeld. An example with n = m = 3 is the
Earth‚Äôs gravitational Ô¨Åeld.
Let fi, 1 ‚â§i ‚â§m, be the components of f with respect to the canonical basis
{ei}1‚â§i‚â§m of Rm:
f(x) =

fi(x)

1‚â§i‚â§m =
m

i=1
fi(x)ei .
Each fi is a real scalar function of one or more real variables, deÔ¨Åned on dom f
at least; actually, dom f is the intersection of the domains of the components of f.
Examples 4.18
i) Consider the vector Ô¨Åeld on R2
f(x, y) = (‚àíy, x) .
The best way to visualise a two-dimensional Ô¨Åeld is to draw the vector cor-
responding to f(x, y) as position vector at the point (x, y). This is clearly not
possible everywhere on the plane, but a suÔ¨Écient number of points might still
give a reasonable idea of the behaviour of f. Since f(1, 0) = (0, 1), we draw
the vector (0, 1) at the point (1, 0); similarly, we plot the vector (‚àí1, 0) at (0, 1)
because f(0, 1) = (‚àí1, 0) (see Fig. 4.10, left).
Notice that each vector is tangent to a circle centred at the origin. In fact, the
dot product of the position vector x = (x, y) with f(x) is zero:
x ¬∑ f(x) = (x, y) ¬∑ (‚àíy, x) = ‚àíxy + xy = 0 ,

4.4 Functions: deÔ¨Ånitions and Ô¨Årst examples
129
x
y
f(1, 0)
f(0, 1)
x
y
z
Figure 4.10. The Ô¨Åelds f(x, y) = (‚àíy, x) (left) and f(x, y, z) = (0, 0, z) (right)
making x and f(x) orthogonal vectors. Additionally, ‚à•f(x)‚à•= ‚à•x‚à•, so the
length of f(x, y) coincides with the circle‚Äôs radius.
This vector Ô¨Åeld represents the velocity of a wheel spinning counter-clockwise.
ii) Vector Ô¨Åelds in R3 can be understood in a similar way. Figure 4.10, right,
shows a picture of the vector Ô¨Åeld
f(x, y, z) = (0, 0, z) .
All vectors are vertical, and point upwards if they lie above the xy-plane, down-
wards if below the plane z = 0. The magnitude increases as we move away from
the xy-plane.
iii) Imagine a Ô¨Çuid running through a pipe with velocity f(x, y, z) at the point
(x, y, z). The function f assignes a vector to each pont (x, y, z) in a certain
domain Œ© (the region inside the pipe) and so is a vector Ô¨Åeld of R3, called the
velocity vector Ô¨Åeld. A concrete example is in Fig. 4.11.
 
 
 
 
 
 
 
 
Figure 4.11. The velocity vector Ô¨Åeld of a Ô¨Çuid moving in a pipe

130
4 Functions between Euclidean spaces
iv) The R3-valued map
f(x, y, z) =
	
x
(x2 + y2 + z2)3/2 ,
y
(x2 + y2 + z2)3/2 ,
z
(x2 + y2 + z2)3/2

=
x
‚à•x‚à•3 ,
on R3\{0} represents the electrostatic force Ô¨Åeld generated by a charged particle
placed in the origin.
v) Let A = (aij) 1 ‚â§i ‚â§m
1 ‚â§j ‚â§n
be a real m √ó n matrix. The function
f(x) = Ax ,
is a linear map from Rn to Rm.
2
4.5 Continuity and limits
The notion of continuity for functions between Euclidean spaces is essentially the
same as what we have seen for one-variable functions (Vol. I, Ch. 3), with the
proviso that the absolute value of R must be replaced by an arbitrary norm in Rn
or Rm (which we shall indicate with ‚à•¬∑ ‚à•for simplicity).
DeÔ¨Ånition 4.19 A function f : dom f ‚äÜRn ‚ÜíRm is said continuous at
x0 ‚ààdom f if for any Œµ > 0 there exists a Œ¥ > 0 such that
‚àÄx ‚ààdom f,
‚à•x ‚àíx0‚à•< Œ¥
‚áí
‚à•f(x) ‚àíf(x0)‚à•< Œµ ;
that is to say,
‚àÄx ‚ààdom f,
x ‚ààBŒ¥(x0)
‚áí
f(x) ‚ààBŒµ(f(x0)).
A map f is continuous on a set Œ© ‚äÜdom f if it is continuous at each point
x ‚ààŒ©.
The following result is used a lot to study the continuity of vector-valued func-
tions. Its proof is left to the reader.
Proposition 4.20 The map f = (fi)1‚â§i‚â§m is continuous at x0 ‚ààdom f if
and only if all its components fi are continuous.
Due to this result we shall merely provide some examples of scalar functions.
Examples 4.21
i) Let us verify f : R2 ‚ÜíR, f(x) = 2x1 + 5x2 is continuous at x0 = (3, 1). Using
the fact that |yi| ‚â§‚à•y‚à•for all i (mentioned earlier), we have
|f(x) ‚àíf(x0)| = |2(x1 ‚àí3) + 5(x2 ‚àí1)| ‚â§2|x1 ‚àí3| + 5|x2 ‚àí1| ‚â§7‚à•x ‚àíx0‚à•.

4.5 Continuity and limits
131
Given Œµ > 0 then, it is enough to choose Œ¥ = Œµ/7 to conclude. The same argument
shows f is continuous at each x0 ‚ààR2.
ii) The above function is an aÔ¨Éne map f : Rn ‚ÜíR, i.e., a map of type f(x) =
a ¬∑ x + b (a ‚ààRn, b ‚ààR). AÔ¨Éne maps are continuous at each x0 ‚ààRn because
|f(x) ‚àíf(x0)| = |a ¬∑ x ‚àía ¬∑ x0| = |a ¬∑ (x ‚àíx0)| ‚â§‚à•a‚à•‚à•x ‚àíx0‚à•
(4.21)
by the Cauchy-Schwarz inequality (4.3).
If a = 0, the result is trivial. If a Ã∏= 0, continuity holds if one chooses Œ¥ = Œµ/‚à•a‚à•
for any given Œµ > 0.
2
The map f is uniformly continuous on Œ© if we may choose Œ¥ independently
of x0 in the above deÔ¨Ånition; this is made precise as follows.
DeÔ¨Ånition 4.22 A function is said uniformly continuous on Œ© ‚äÜdom f
if for any Œµ > 0 there exists a Œ¥ > 0 such that
‚àÄx‚Ä≤, x‚Ä≤‚Ä≤ ‚ààŒ©,
‚à•x‚Ä≤ ‚àíx‚Ä≤‚Ä≤‚à•< Œ¥
‚áí
‚à•f(x‚Ä≤) ‚àíf(x‚Ä≤‚Ä≤)‚à•< Œµ .
(4.22)
For instance, the above aÔ¨Éne function f is uniformly continuous on Rn.
A continuous function on a closed and bounded set (i.e., a compact set) Œ© is
uniformly continuous therein (Theorem of Heine-Cantor, given in Appendix A.1.3,
p. 515).
Often one can study the continuity of a function of several variables without
turning to the deÔ¨Ånition. To this end the next three criteria are rather practical.
i) If the map œï is deÔ¨Åned and continuous on a set I ‚äÜR, then
f(x) = œï(x1)
is deÔ¨Åned and continuous on Œ© = I √ó Rn‚àí1 ‚äÜRn.
In general, any continuous map of m variables is continuous if we think of it
as a map of n > m variables.
For example, the following functions are continuous:
f1(x, y) = ex
on dom f1 = R2 ,
f2(x, y, z) =

1 ‚àíy2
on dom f2 = R √ó [‚àí1, 1] √ó R .
ii) If f and g are continuous on Œ© ‚äÜRn, then also f + g, f ‚àíg and fg are
continuous on Œ©, while f/g is continuous on the subset of Œ© where g Ã∏= 0.
Examples of continuous maps:
h1(x, y) = ex + sin y
on dom h1 = R2 ,

132
4 Functions between Euclidean spaces
h2(x, y) = y log x
on dom h2 = (0, +‚àû) √ó R ,
h3(x, y, z) = arctan y
x2 + z2
on dom h3 = R3 \

{0} √ó R √ó {0}

.
iii) If f is continuous on Œ© ‚äÜRn and g is continuous on I ‚äÜR, the composite
map g ‚ó¶f is continuous on dom g ‚ó¶f = {x ‚ààŒ© : f(x) ‚ààI}.
For instance,
h1(x, y) = log(1 + xy)
on dom h1 = {(x, y) ‚ààR2 : xy > ‚àí1} ,
h2(x, y, z) =

x3 + y2
z ‚àí1

on dom h2 = R2 √ó

R \ {1}

,
h3(x) =
4
x4
1 + . . . + x4n
on dom h3 = Rn .
In particular, Proposition 4.20 and criterion iii) imply the next result, which
is about the continuity of a composite map in the most general setting.
Proposition 4.23 Let
f : dom f ‚äÜRn ‚ÜíRm ,
g : dom g ‚äÜRm ‚ÜíRp
be functions and x0 ‚ààdom f a point such that y0 = f(x0) ‚ààdom g. Consider
the composite map
h = g ‚ó¶f : dom h ‚äÜRn ‚ÜíRp ,
where x0 ‚ààdom h. Then if f is continuous at x0 and g is continuous at y0,
h is continuous at x0.
The deÔ¨Ånition of Ô¨Ånite limit of a vector-valued map, for x ‚Üíx0 ‚ààRn, is
completely analogous to the one-variable case. From now on we will suppose f is
deÔ¨Åned on dom f ‚äÜRn and x0 ‚ààRn is a limit point of dom f.
DeÔ¨Ånition 4.24 One says that f has limit ‚Ñì‚ààRm (or tends to ‚Ñì) as x
tends to x0, in symbols
lim
x‚Üíx0 f(x) = ‚Ñì,
if for any Œµ > 0 there is a Œ¥ > 0 such that
‚àÄx ‚ààdom f,
0 < ‚à•x ‚àíx0‚à•< Œ¥
‚áí
‚à•f(x) ‚àí‚Ñì‚à•< Œµ ,
(4.23)
i.e.,
‚àÄx ‚ààdom f,
x ‚ààBŒ¥(x0) \ {x0}
‚áí
f(x) ‚ààBŒµ(‚Ñì) .

4.5 Continuity and limits
133
As for one real variable, if f is deÔ¨Åned on x0, then
f continuous at x0
‚áê‚áí
lim
x‚Üíx0 f(x) = f(x0) .
The analogue of Proposition 4.20 holds for limits, justifying the component-by-
component approach.
Examples 4.25
i) The map
f(x, y) = x4 + y4
x2 + y2
is deÔ¨Åned on R2 \ {(0, 0)} and continuous on its domain, as is clear by using
criteria i) and ii) on p. 131. What is more,
lim
(x,y)‚Üí(0,0) f(x, y) = 0 ,
because
x4 + y4 ‚â§x4 + 2x2y2 + y4 = (x2 + y2)2
and by deÔ¨Ånition of limit

x4 + y4
x2 + y2
 ‚â§x2 + y2 < Œµ
if
0 < ‚à•x‚à•< ‚àöŒµ ;
therefore the condition is true with Œ¥ = ‚àöŒµ.
ii) Let us check that
lim
(x,y)‚Üí(0,0)
|x| + |y|
x2 + y2 = +‚àû.
Since
x2 + y2 ‚â§x2 + 2|x| |y| + y2 = (|x| + |y|)2,
so that ‚à•x‚à•‚â§|x| + |y|, we have
f(x, y) = |x| + |y|
‚à•x‚à•2
= |x| + |y|
‚à•x‚à•
1
‚à•x‚à•‚â•
1
‚à•x‚à•,
and f(x, y) > A if ‚à•x‚à•< 1/A; the condition for the limit is true by taking
Œ¥ = 1/A.
2
A necessary condition for the limit of f(x) to exist (Ô¨Ånite or not) as x ‚Üíx0, is
that the restriction of f to any line through x0 has the same limit. This observation
is often used to show that a certain limit does not exist.
Example 4.26
The map
f(x, y) = x3 + y2
x2 + y2
does not admit limit for (x, y) ‚Üí(0, 0). Suppose the contrary, and let

134
4 Functions between Euclidean spaces
L =
lim
(x,y)‚Üí(0,0) f(x, y)
be Ô¨Ånite or inÔ¨Ånite. Necessarily then,
L = lim
x‚Üí0 f(x, 0) = lim
y‚Üí0 f(0, y) .
But f(x, 0) = x, so lim
x‚Üí0 f(x, 0) = 0, and f(0, y) = 1 for any y Ã∏= 0, whence
lim
y‚Üí0 f(0, y) = 1 .
2
One should not be led to believe, though, that the behaviour of the function
restricted to lines through x0 is suÔ¨Écient to compute the limit. Lines represent
but one way in which we can approach the point x0. DiÔ¨Äerent relationships among
the variables may give rise to completely diÔ¨Äerent behaviours of the limit.
Example 4.27
Let us determine the limit of
f(x, y) =

xex/y
if y Ã∏= 0 ,
0
if y = 0 ,
at the origin. The map tends to 0 along each straight line passing through (0, 0):
lim
x‚Üí0 f(x, 0) = lim
y‚Üí0 f(0, y) = 0
because the function is identically zero on the coordinate axes, and along the
other lines y = kx, k Ã∏= 0,
lim
x‚Üí0 f(x, kx) = lim
x‚Üí0 xek = 0 .
Yet along the parabolic arc y = x2 , x > 0, the map tends to inÔ¨Ånity, for
lim
x‚Üí0+ f(x, x2) = lim
x‚Üí0+ xe1/x = +‚àû.
Therefore the function does not admit limit as (x, y) ‚Üí(0, 0).
2
A function of several variables can be proved to admit limit for x tending to x0
(see Remark 4.35 for more details) if and only if the limit behaviour is independent
of the path through x0 chosen (see Fig. 4.12 for some examples). The previous
cases show that if that is not true, the limit does not exist.
 
 
 
 
x0
 
 
 
 
x0
 
 
 
 
x0
Figure 4.12. DiÔ¨Äerent ways of approaching the point x0

4.5 Continuity and limits
135
For two variables, a useful suÔ¨Écient condition to study the limit‚Äôs existence
relies on polar coordinates
x = x0 + r cos Œ∏ ,
y = y0 + r sin Œ∏ .
Proposition 4.28 Suppose there exist ‚Ñì‚ààR and a map g depending on the
variable r such that, on a neighbourhood of (x0, y0),
|f(x0 + r cos Œ∏ , y0 + r sin Œ∏) ‚àí‚Ñì| ‚â§g(r)
with
lim
r‚Üí0+ g(r) = 0 .
Then
lim
(x,y)‚Üí(x0,y0) f(x, y) = ‚Ñì.
Examples 4.29
i) The above result simpliÔ¨Åes the study of the limit of Example 4.25 i):
f(r cos Œ∏, r sin Œ∏) = r4 sin4 Œ∏ + r4 cos4 Œ∏
r2
= r2(sin4 Œ∏ + cos4 Œ∏)
‚â§r2(sin2 Œ∏ + cos2 Œ∏) = r2 ,
recalling | sin Œ∏| ‚â§1 and | cos Œ∏| ‚â§1. Thus
|f(r cos Œ∏, r sin Œ∏)| ‚â§r2
and the criterion applies with g(r) = r2.
ii) Consider
lim
(x,y)‚Üí(0,1)
x log y

x2 + (y ‚àí1)2 .
Then
f(r cos Œ∏, 1 + r sin Œ∏) = r cos Œ∏ log(1 + r sin Œ∏)
r
= cos Œ∏ log(1 + r sin Œ∏) .
Remembering that
lim
t‚Üí0
log(1 + t)
t
= 1 ,
for t small enough we have

log(1 + t)
t
 ‚â§2 ,
i.e., | log(1 + t)| ‚â§2|t|. Then
|f(r cos Œ∏, 1 + r sin Œ∏)| = | cos Œ∏ log(1 + r sin Œ∏)| ‚â§2r| sin Œ∏ cos Œ∏| ‚â§2r .
The criterion can be used with g(r) = 2r, to the eÔ¨Äect that
lim
(x,y)‚Üí(0,1)
x log y

x2 + (y ‚àí1)2 = 0 .
2

136
4 Functions between Euclidean spaces
We would also like to understand what happens when the norm of the inde-
pendent variable tends to inÔ¨Ånity. As there is no natural ordering on Rn for n ‚â•2,
one cannot discern, in general, how the argument of the map moves away from
the origin. In contrast to dimension one, where it is possible to distinguish the
limits for x ‚Üí+‚àûand x ‚Üí‚àí‚àû, in higher dimensions there is only one ‚Äúpoint‚Äù
at inÔ¨Ånity ‚àû. Neighbourhoods of the point at inÔ¨Ånity are by deÔ¨Ånition
BR(‚àû) = {x ‚ààRn : ‚à•x‚à•> R}
with
R > 0 .
Each BR(‚àû) is the complement of the closed neighbourhood BR(0) of radius R
centred at the origin.
With this, the deÔ¨Ånition of limit (Ô¨Ånite or inÔ¨Ånite) assumes the usual form.
For example a function f with unbounded domain in Rn has limit ‚Ñì‚ààRm as x
tends to ‚àû, written
lim
x‚Üí‚àûf(x) = ‚Ñì‚ààRm ,
if for any Œµ > 0 there is an R > 0 such that
‚àÄx ‚ààdom f ,
‚à•x‚à•> R
‚áí
‚à•f(x) ‚àí‚Ñì‚à•< Œµ ,
i.e.,
‚àÄx ‚ààdom f ,
x ‚ààBR(‚àû)
‚áí
f(x) ‚ààBŒµ(‚Ñì) .
Eventually, we discuss inÔ¨Ånite limits. A scalar function f has limit +‚àû(or
tends to +‚àû) as x tends to x0, written
lim
x‚Üíx0 f(x) = +‚àû,
if for any R > 0 there is a Œ¥ > 0 such that
‚àÄx ‚ààdom f,
0 < ‚à•x ‚àíx0‚à•< Œ¥
‚áí
f(x) > R ,
(4.24)
i.e.,
‚àÄx ‚ààdom f,
x ‚ààBŒ¥(x0) \ {x0}
‚áí
f(x) ‚ààBR(+‚àû).
The deÔ¨Ånitions of
lim
x‚Üíx0 f(x) = ‚àí‚àû
and
lim
x‚Üí‚àûf(x) = ‚àí‚àû
descend from the previous ones, substituting f(x) > R with f(x) < ‚àíR.
In the vectorial case, the limit is inÔ¨Ånite when at least one component of f
tends to ‚àû. Here as well we cannot distinguish how f grows. Precisely, f has
limit ‚àû(or tends to ‚àû) as x tends to x0, which one indicates by
lim
x‚Üíx0 f(x) = ‚àû,

4.5 Continuity and limits
137
if
lim
x‚Üíx0 ‚à•f(x)‚à•= +‚àû.
Similarly we deÔ¨Åne
lim
x‚Üí‚àûf(x) = ‚àû.
4.5.1 Properties of limits and continuity
The main theorems on limits of one-variable maps, discussed in Vol. 1, Ch. 4,
carry over to several variables. Precisely, we still have uniqueness of the limit,
local invariance of tha function‚Äôs sign, the various Comparison Theorems plus
corollaries, the algebra of limits with the relative indeterminate forms. Clearly,
x ‚Üíc should be understood by thinking c as either a point x0 ‚ààRn or ‚àû.
We can also use the Landau formalism for a local study in several variables.
The deÔ¨Ånition and properties of the symbols O, o, ‚âç, ‚àºdepend on limits, and
thus extend. The expression f(x) = o(‚à•x‚à•) as x ‚Üí0, for instance, means
lim
x‚Üí0
f(x)
‚à•x‚à•= 0 .
An example satisfying this property is f(x, y) = 2x2 ‚àí5y3.
Some continuity theorems of global nature, see Vol. I, Sect. 4.3, have a counter-
part for scalar maps of several variables. For example, the theorem on the existence
of zeroes goes as follows.
Theorem 4.30 Let f be a continuous map on a region R ‚äÜRn. If f assumes
on R both positive and negative values, it necessarily has a zero on R.
Proof.
If a, b ‚ààR satisfy f(a) < 0 and f(b) > 0, and if P[a, . . . , b] is an arbitrary
polygonal path in R joining a and b, the map f restricted to P[a, . . . , b] is
a function of one variable that satisÔ¨Åes the ordinary Theorem of Existence
of Zeroes. Therefore an x0 ‚ààP[a, . . . , b] exists with f(x0) = 0.
2
From this follows, as in the one-dimensional case, the Mean Value Theorem.
We also have Weierstrass‚Äôs Theorem, which we will see in Sect. 5.6, Theorem 5.24.
For maps valued in Rm, m ‚â•1, we have the results on limits that make sense
for vectorial quantities (e.g., the uniqueness of the limit and the limit of a sum of
functions, but not the Comparison Theorems).
The Substitution Theorem holds, just as in dimension one (Vol. I, Thm. 4.15);
for continuous maps this guarantees the continuity of the composite map, as men-
tioned in Proposition 4.23.

138
4 Functions between Euclidean spaces
Examples 4.31
i) We prove that
lim
(x,y)‚Üí‚àûe‚àí
1
|x|+|y| = 1 .
As (x, y) ‚Üí‚àû, we have |x| + |y| ‚Üí+‚àû, hence t = ‚àí
1
|x|+|y| ‚Üí0; but the
exponential map t ‚Üíet is continuous at the origin, so the result follows.
ii) Let us show
lim
(x,y)‚Üí‚àû
x4 + y4
x2 + y2 = +‚àû.
This descends from
x4 + y4
x2 + y2 ‚â•1
4‚à•x‚à•2 ,
‚àÄx ‚ààR2 , x Ã∏= 0
(4.25)
and the Comparison Theorem, for (x, y) ‚Üí‚àûis clearly the same as ‚à•x‚à•‚Üí+‚àû.
To get (4.25), note that if x2 ‚â•y2, we have
‚à•x‚à•2 = x2 + y2 ‚â§2x2 ,
so
x4 + y4
x2 + y2 ‚â•x4
2x2 = 1
2x2 ‚â•1
4‚à•x‚à•2 ;
at the same result we arrive if y2 ‚â•x2.
2
4.6 Curves in Rm
A curve can describe the way the boundary of a plane region encloses the region
itself ‚Äì think of a polygon or an ellipse, or the trajectory of a point-particle mov-
ing in time under the eÔ¨Äect of a force. Chapter 9 will provide us with a means
of integrating along a curve, hence allowing us to formulate mathematically the
physical notion of the work of a force.
Let us start with the deÔ¨Ånition of curve. Given a real interval I and a map
Œ≥ : I ‚ÜíRm, we denote by Œ≥(t) =

xi(t)

1‚â§i‚â§m =
m

i=1
xi(t)ei ‚ààRm the image of
t ‚ààI under Œ≥.
DeÔ¨Ånition 4.32 A continuous function Œ≥ : I ‚äÜR ‚ÜíRm is called a curve.
The set Œì = Œ≥(I) ‚äÜRm is said trace of the curve.
If the trace of the curve lies on a plane, one speaks about a plane curve.
The most common curves are those in the plane (m = 2)
Œ≥(t) =

x(t), y(t)

= x(t) i + y(t) j ,

4.6 Curves in Rm
139
and curves in space (m = 3)
Œ≥(t) =

x(t), y(t), z(t)

= x(t) i + y(t) j + z(t) k .
We wish to stress the diÔ¨Äerence occurring between a curve, which is a function
of one real variable, and its trace, a set in Euclidean space Rm. A curve provides
a way to parametrise its trace by associating to the parameter t ‚ààI one (and only
one) point of the trace. Still, Œì may be the trace of many curves, because it may be
parametrised in distinct ways. For instance the plane curves Œ≥(t) = (t, t), t ‚àà[0, 1],
and Œ¥(t) = (t2, t2), t ‚àà[0, 1] have the segment AB of end points A = (0, 0) and
B = (1, 1) as common trace; Œ≥ and Œ¥ are two parametrisations of the segment.
The mid-point of AB, for example, corresponds to the value t = 1
2 for Œ≥, t =
‚àö
2
2
for Œ¥.
A curve Œ≥ is said simple if Œ≥ is a one-to-one map, i.e., if distinct parameter‚Äôs
values determine distinct points of the trace.
If the interval I = [a, b] is closed and bounded, as in the previous examples, the
curve Œ≥ will be named arc. We call end points of the arc the points P0 = Œ≥(a),
P1 = Œ≥(b); precisely, P0 is the initial point and P1 the end point, and Œ≥ joins
P0 and P1. An arc is closed if its end points coincide: Œ≥(a) = Œ≥(b); although
a closed arc cannot be simple, one speaks anyway of a simple closed arc (or
Jordan arc) when the point Œ≥(a) = Œ≥(b) is the unique point on the trace where
injectivity fails. Figure 4.13 illustrates a few arcs; in particular, the trace of the
Jordan arc (bottom left) shows a core property of Jordan arcs, known as Jordan
Curve Theorem.
Œ≥(a)
Œ≥(b)
Œ≥(a)
Œ≥(b)
Œ≥(a) = Œ≥(b)
Œ≥(a) = Œ≥(b)
Figure 4.13. The trace Œì = Œ≥([a, b]) of a simple arc (top left), a non-simple arc (top
right), a simple closed arc or Jordan arc (bottom left) and a closed non-simple arc (bottom
right)

140
4 Functions between Euclidean spaces
Theorem 4.33 The trace Œì of a Jordan arc in the plane divides the plane
in two connected components Œ£i and Œ£e with common boundary Œì, where Œ£i
is bounded, Œ£e is unbounded.
Conventionally, Œ£i is called the region ‚Äúinside‚Äù Œì, while Œ£e is the region
‚Äúoutside‚Äù Œì.
Like for curves, there is a structural diÔ¨Äerence between an arc and its trace.
It must be said that very often one uses the term ‚Äòarc‚Äô for a subset of Euclidean
space Rm (as in: ‚Äòcircular arc‚Äô), understanding the object as implicitly parametrised
somehow, usually in the simplest and most natural way.
Examples 4.34
i) The simple plane curve
Œ≥(t) = (at + b, ct + d) ,
t ‚ààR , a Ã∏= 0
has the line y = c
ax + ad ‚àíbc
a
as trace. Indeed, putting x = x(t) = at + b and
y = y(t) = ct + d gives t = x ‚àíb
a
, so
y = c
a(x ‚àíb) + d = c
ax + ad ‚àíbc
a
.
ii) Let œï : I ‚ÜíR be a continuous function on the interval I; the curve
Œ≥(t) = ti + œï(t)j ,
t ‚ààI
has the graph of œï as trace.
iii) The trace of
Œ≥(t) =

x(t), y(t)

= (1 + cos t, 3 + sin t) ,
t ‚àà[0, 2œÄ]
is the circle with centre (1, 3) and radius 1, for in fact

x(t) ‚àí1
2 +

y(t) ‚àí
3
2 = cos2 t + sin2 t = 1. The arc is simple and closed, and is the standard
parametrisation of the circle starting at the point (2, 3) and running counter-
clockwise.
More generally, the closed, simple arc
Œ≥(t) =

x(t), y(t)

= (x0 + r cos t, y0 + r sin t) ,
t ‚àà[0, 2œÄ]
has trace the circle centred at (x0, y0) with radius r.
If t varies in an interval [0, 2kœÄ], with k ‚â•2 a positive integer, the curve has the
same trace seen as a set; but because we wind around the centre k times, the
curve is not simple.
Instead, if t varies in [0, œÄ], the curve is a circular arc, simple but not closed.
iv) Given a, b > 0, the map
Œ≥(t) =

x(t), y(t)

= (a cos t, b sin t) ,
t ‚àà[0, 2œÄ]

4.6 Curves in Rm
141
is a simple closed curve parametrising the ellipse with centre in the origin and
semi-axes a and b:
x2
a2 + y2
b2 = 1 .
v) The trace of
Œ≥(t) =

x(t), y(t)

= (t cos t, t sin t) = t cost i + t sin t j ,
t ‚àà[0, +‚àû]
is a spiral coiling counter-clockwise around the origin, see Fig. 4.14, left. Since the
point Œ≥(t) has distance

x2(t) + y2(t) = t from the origin, so it moves farther
aÔ¨Åeld as t grows, the spiral a simple curve.
vi) The simple curve
Œ≥(t) =

x(t), y(t), z(t)

= (cos t, sin t, t) = cos t i + sin t j + t k ,
t ‚ààR
has the circular helix of Fig. 4.14, right, as trace. It rests on the inÔ¨Ånite cylinder
{(x, y, z) ‚ààR3 : x2 + y2 = 1} along the z-axis with radius 1.
vii) Let P and Q be distinct points of Rm, with m ‚â•2 arbitrary. The trace of
the simple curve
Œ≥(t) = P + (Q ‚àíP)t ,
t ‚ààR
is the line through P and Q, because Œ≥(0) = P, Œ≥(1) = Q and the vector Œ≥(t)‚àíP
has constant direction, being parallel to Q ‚àíP.
There is a more general parametrisation of the same line
Œ≥(t) = P + (Q ‚àíP) t ‚àít0
t1 ‚àít0
,
t ‚ààR ,
(4.26)
with t0 Ã∏= t1; in this case Œ≥(t0) = P, Œ≥(t1) = Q.
2
x
y
 
 
 
 
 
 
 
 
x
y
z
Figure 4.14. Spiral and circular helix, see Examples 4.34 v) and vi)

142
4 Functions between Euclidean spaces
Some of the above curves have a special trace, given as the locus of points in
the plane satisfying an equation of type
f(x, y) = c ;
(4.27)
otherwise said, they parametrise level sets of f. With suitable assumptions on f,
one can start from an implicit equation like (4.27) and obtain a curve Œ≥(t) =

x(t), y(t)

of solutions. The details may be found in Sect. 7.2.
Remark 4.35 We posited in Sect. 4.5 that the existence of the limit of f, as x
tends to x0 ‚ààRn, is equivalent to the fact that the restrictions of f to the trace
of any curve through x0 admit the same limit; namely, one can prove that
lim
x‚Üíx0 f(x) = ‚Ñì
‚áê‚áí
lim
t‚Üít0 f

Œ≥(t)

= ‚Ñì
for any curve Œ≥ : I ‚Üídom f such that Œ≥(t0) = x0 for some t0 ‚ààI.
2
Curves in polar, cylindrical and spherical coordinates
Representing a curve using Cartesian coordinates, as we have done so far, is but
one possibility. Sometimes it may be better to use polar coordinates in dimension
2, and cylindrical or spherical coordinates in dimension 3 (these were introduced
in Vol. I, Sect. 8.1, and will be discusses anew in Sect. 6.6.1).
A plane curve R2 can be deÔ¨Åned by a continuous map Œ≥p : I ‚äÜR ‚Üí[0, +‚àû)√óR,
where Œ≥p(t) =

r(t), Œ∏(t)

are the polar coordinates of the point image of the value
t of the parameter. It corresponds to the curve Œ≥(t) = r(t) cos Œ∏(t) i+r(t) sin Œ∏(t) j
in Cartesian coordinates. The spiral of Example 4.34 v) can be parametrised, in
polar coordinates, by Œ≥p(t) = (t, t), t ‚àà[0, +‚àû).
Similarly, we can represent a curve in space using cylindrical coordinates,
Œ≥c(t) =

r(t), Œ∏(t), z(t)

, with Œ≥c : I ‚äÜR ‚Üí[0, +‚àû) √ó R2 continuous, or using
spherical coordinates, Œ≥s(t) =

r(t), œï(t), Œ∏(t)

, with Œ≥s : I ‚äÜR ‚Üí[0, +‚àû) √ó R2
continuous. The circular helix of Example 4.34 vi) is Œ≥c(t) = (1, t, t), t ‚ààR,
while a meridian arc of the unit sphere, joining the North and the South poles, is
Œ≥s(t) = (1, t, Œ∏0), for t ‚àà[0, œÄ] and with given Œ∏0 ‚àà[0, 2œÄ].
4.7 Surfaces in R3
Surfaces are continuous functions deÔ¨Åned on special subsets of R2, namely plane
regions (see DeÔ¨Ånition 4.15); these regions play the role intervals had for curves.
DeÔ¨Ånition 4.36 Let R ‚äÜR2 be a region. A continuous map œÉ : R ‚ÜíR3 is
said surface, and Œ£ = œÉ(R) ‚äÜR3 is the trace of the surface.

4.7 Surfaces in R3
143
The independent variables in R are usually denoted (u, v), and
œÉ(u, v) =

x(u, v), y(u, v), z(u, v)

= x(u, v)i + y(u, v)j + z(u, v)k
is the Cartesian representation of œÉ.
A surface is simple if the restriction of œÉ to the interior of R is one-to-one.
A surface is compact if the region R is compact. It is the 2-dimensional
analogue of an arc.
Examples 4.37
i) Consider vectors a, b ‚ààR3 such that a ‚àßb Ã∏= 0, and c ‚ààR3. The surface
œÉ : R2 ‚ÜíR3
œÉ(u, v) = au + bv + c
= (a1u + b1v + c1)i + (a2u + b2v + c2)j + (a3u + b3v + c3)k
parametrises the plane Œ† passing through the point c and parallel to a and b
(Fig. 4.15, left).
The Cartesian equation is found by setting x = (x, y, z) = œÉ(u, v) and observing
x ‚àíc = au + bv ,
i.e., x ‚àíc is a linear combination of a and b. Hence by (4.7)
(a ‚àßb) ¬∑ (x ‚àíc) = (a ‚àßb) ¬∑ a u + (a ‚àßb) ¬∑ b v = 0 ,
so
(a ‚àßb) ¬∑ x = (a ‚àßb) ¬∑ c .
The plane has thus equation
Œ±x + Œ≤y + Œ≥z = Œ¥ ,
where Œ±,Œ≤ and Œ≥ are the components of a ‚àßb, and Œ¥ = (a ‚àßb) ¬∑ c.
 
 
a
b
c
Œ†
x
y
z
 
 
x
y
z
Figure 4.15. Representation of the plane Œ† (left) and the hemisphere (right) relative
to Examples 4.37 i) and ii)

144
4 Functions between Euclidean spaces
ii) Any continuous scalar function œï : R ‚ÜíR deÔ¨Åned on a plane region produces
a surface œÉ : R ‚ÜíR3
œÉ(u, v) = ui + vj + œï(u, v)k ,
whose trace is the graph of œï. Such a surface is sometimes referred to as topo-
graphic (with respect to the z-axis).
The surface œÉ : R = {(u, v) ‚ààR2 : u2 + v2 ‚â§1} ‚ÜíR3,
œÉ(u, v) = ui + vj +

1 ‚àíu2 ‚àív2 k
produces as trace the upper hemisphere centred at the origin and with unit
radius (Fig. 4.15, right).
Permuting the components u, v, œï(u, v) of œÉ clearly gives rise to surfaces whose
equation is solved for x or y instead of z.
iii) The plane curve Œ≥ : I ‚äÜR ‚ÜíR3 given by Œ≥(t) =

Œ≥1(t), 0, Œ≥3(t)

, Œ≥1(t) ‚â•0
for any t ‚ààI has trace Œì in the half-plane xz where x ‚â•0.
Rotating Œì around the z-axis gives the trace Œ£ of the surface œÉ : I √ó[0, 2œÄ] ‚ÜíR3
deÔ¨Åned by
œÉ(u, v) = Œ≥1(u) cos v i + Œ≥1(u) sin v j + Œ≥3(u)k .
One calls surface of revolution (around the z-axis) a surface thus obtained.
The generating arc is said meridian (arc). For example, revolving around the
z-axis the parabolic arc Œì parametrised by Œ≥ : [‚àí1, 1] ‚ÜíR3, Œ≥(t) = (4 ‚àít2, 0, t)
yields the lateral surface of a plinth, see Fig. 4.16, left.
Akin surfaces can be deÔ¨Åned by revolution around the other coordinate axes.
iv) The vector-valued map
œÉ(u, v) = (x0 + r sin u cosv)i + (y0 + r sin u sin v)j + (z0 + r cos u)k
on R = [0, œÄ] √ó [0, 2œÄ] is a compact surface with trace the spherical surface
of centre x0 = (x0, y0, z0), radius r > 0. Slightly more generally, consider the
(surface of the) ellipsoid, centred at x0 with semi-axes a, b, c > 0, deÔ¨Åned by
(x ‚àíx0)2
a2
+ (y ‚àíy0)2
b2
+ (z ‚àíz0)2
c2
= 1 ;
This surface is parametrised by
œÉ(u, v) = (x0 + a sin u cos v)i + (y0 + b sin u sin v)j + (z0 + c cos u)k .
v) The function œÉ : R ‚ÜíR3,
œÉ(u, v) = u cosv i + u sin vj + vk
with R = [0, 1]√ó [0, 4œÄ], deÔ¨Ånes a compact surface; its trace is the ideal parking-
lot ramp, see Fig. 4.16, right. The name helicoid is commonly used for this
surface deÔ¨Åned on R = [0, 1] √ó R.
All surfaces considered so far are simple.
2

4.8 Exercises
145
 
 
x
y
z
Œ≥
 
 
x
y
z
Figure 4.16. Plinth (left) and helicoid (right) relative to Examples 4.37 iii) and v)
We will see in Sect. 7.2 suÔ¨Écient conditions for an implicit equation
f(x, y, z) = c
to be solved in one of the variables, i.e., to determine the trace of a surface which
is locally a graph.
For surfaces, too, there is an alternative representation making use of cylindrical
or spherical coordinates. The lateral surface of an inÔ¨Ånite cylinder with axis z
and radius 1, for instance, has cylindrical parametrisation œÉc : [0, 2œÄ] √ó R ‚Üí
R3, œÉc(u, v) =

r(u, v), Œ∏(u, v), z(u, v)

= (1, u, v). Similarly, the unit sphere at
the origin has a spherical parametrisation œÉs : [0, œÄ] √ó [0, 2œÄ] ‚ÜíR3, œÉs(u, v) =

r(u, v), œï(u, v), Œ∏(u, v)

= (1, u, v). The surfaces of revolution of Example 4.37
iii) are œÉc : I √ó [0, 2œÄ] ‚ÜíR3, with œÉc(u, v) =

Œ≥1(u), v, Œ≥3(u)

in cylindrical
coordinates.
4.8 Exercises
1. Determine the interior, the closure and the boundary of the following sets. Say
if the sets are open, closed, connected, convex or bounded:
a)
A = {(x, y) ‚ààR2 : 0 ‚â§x ‚â§1, 0 < y < 1}
b)
B =

B2(0) \ ([‚àí1, 1] √ó {0})

‚à™

(‚àí1, 1) √ó {3}

c)
C = {(x, y) ‚ààR2 : |y| > 2}
2. Determine the domain of the functions:
a)
f(x, y) = x ‚àí3y + 7
x ‚àíy2

146
4 Functions between Euclidean spaces
b)
f(x, y) =

1 ‚àí3xy
c)
f(x, y) =

3x + y + 1 ‚àí
1
‚àö2y ‚àíx
d)
f(x, y, z) = log(x2 + y2 + z2 ‚àí9)
e)
f(x, y) =

y

x2 + y2 , ‚àí
x

x2 + y2

f)
f(x, y, z) =
	
arctan y, log z
x

g)
Œ≥(t) = (t3,
‚àö
t ‚àí1,
‚àö
5 ‚àít)
h)
Œ≥(t) =
	t ‚àí2
t + 2, log(9 ‚àít2)

i)
œÉ(u, v) =

log(1 ‚àíu2 ‚àív2), u,
1
u2 + v2

‚Ñì)
œÉ(u, v) =
‚àö
u + v,
2
4 ‚àíu2 ‚àív2 , v

3. Say whether the following limits exist, and compute them:
a)
lim
(x,y)‚Üí(0,0)
xy

x2 + y2
b)
lim
(x,y)‚Üí(0,0)
xy
x2 + y2
c)
lim
(x,y)‚Üí(0,0)
x
y log(1 + x)
d)
lim
(x,y)‚Üí(0,0)
3x2y
x2 + y2
e)
lim
(x,y)‚Üí(0,0)
x2y
x4 + y2
f)
lim
(x,y,z)‚Üí(0,0,0)
xy + yz2 + xz2
x2 + y2 + z4
g)
lim
(x,y)‚Üí(0,0)
x2

x2 + y2
h)
lim
(x,y)‚Üí(0,0)
x2 ‚àíx3 + y2 + y3
x2 + y2
i)
lim
(x,y)‚Üí(0,0)
x ‚àíy
x + y
‚Ñì)
lim
(x,y)‚Üí(0,0)(x2 + y2) log(x2 + y2) + 5
m)
lim
(x,y)‚Üí‚àû
x2 + y + 1
x2 + y4
n)
lim
(x,y)‚Üí‚àû

1 + 3x2 + 5y2
x2 + y2
4. Determine the set on which the following maps are continuous:
a)
f(x, y) = arcsin(xy ‚àíx ‚àí2y)
b) f(x, y, z) =
xyz
x2 + y2 ‚àíz
5.
As the real number Œ± ‚â•0 varies, study the continuity of:
f(x, y) =
!
|x|Œ±
sin y
x2 + y2
if (x, y) Ã∏= (0, 0) ,
0
if (x, y) = (0, 0) .

4.8 Exercises
147
6.
The cylinders z = x2 and z = 4y2 intersect along the traces of two curves.
Find a parametrisation of the one containing the point (2, ‚àí1, 4).
7.
Parametrise (with a curve) the intersection of the plane x + y + z = 1 and the
cylinder z = x2.
8. Parametrise (with a curve) the intersection of x2 + y2 = 16 and z = x + y.
9. Find a Cartesian parametrisation for the curve Œ≥(t) =

r(t), Œ∏(t)

, t ‚àà[0, 2œÄ],
given in polar coordinates, when:
a)
Œ≥(t) = (sin2 t, t)
b)
Œ≥(t) =

sin t
2, t

10. Eliminate the parameters u, v to obtain a Cartesian equation in x, y, z rep-
resenting the trace of:
a)
œÉ(u, v) = au cos vi + bu sin vj + u2k ,
a, b ‚ààR
elliptic paraboloid
b)
œÉ(u, v) = ui + a sin vj + a cos vk ,
a ‚ààR
cylinder
c)
œÉ(u, v) = (a + b cosu) sin vi + (a + b cosu) cos vj + b sin uk ,
0 < b < a
torus
4.8.1 Solutions
1. Properties of sets:
a) The interior of A is
‚ó¶
A = {(x, y) ‚ààR2 : 0 < x < 1, 0 < y < 1} ,
which is the open square (0, 1)2. Its closure is
A = {(x, y) ‚ààR2 : 0 ‚â§x ‚â§1, 0 ‚â§y ‚â§1} ,
i.e., the closed square [0, 1]2. The boundary is
‚àÇA = {(x, y) ‚ààR2 : x = 0 or x = 1, 0 ‚â§y ‚â§1} ‚à™
‚à™{(x, y) ‚ààR2 : y = 0 or y = 1, 0 ‚â§x ‚â§1} ,
which is the union of the four sides (perimeter) of [0, 1]2.
Then A is neither open nor closed, but connected, convex and bounded, see
Fig. 4.17, left.

148
4 Functions between Euclidean spaces
x
y
1
1
A
x
y
2
3
B
1
‚àí1
x
y
‚àí2
2
C
Figure 4.17. The sets A, B, C of Exercise 1
b) The interior of B is
‚ó¶
B = B2(0) \ ([‚àí1, 1] √ó {0}) ,
the closure
B = B2(0) ‚à™

[‚àí1, 1] √ó {3}

,
the boundary
‚àÇB = {(x, y) ‚ààR2 : x2 + y2 = 2} ‚à™([‚àí1, 1] √ó {0}) ‚à™([‚àí1, 1] √ó {3}) .
Hence B is not open, closed, connected, nor convex; but it is bounded, see
Fig. 4.17, middle.
c) The interior of C is C itself; its closure is
C = {(x, y) ‚ààR2 : |y| ‚â•2} ,
while the boundary is
‚àÇC = {(x, y) ‚ààR2 : y = ¬±2} ,
making C open, not connected, nor convex, nor bounded (Fig. 4.17, right).
2. Domain of functions:
a) The domain is {(x, y) ‚ààR2 : x Ã∏= y2}, the set of all points in the plane except
those on the parabola x = y2.
b) The map is deÔ¨Åned where the radicand is ‚â•0, so the domain is
{(x, y) ‚ààR2 : y ‚â§1
3x if x > 0, y ‚â•1
3x if x < 0, y ‚ààR if x = 0} ,
which describes the points lying between the two branches of the hyperbola
y =
1
3x.
c) The map is deÔ¨Åned for 3x + y + 1 ‚â•0 and 2y ‚àíx > 0, implying the domain is
{(x, y) ‚ààR2 : y ‚â•‚àí3x ‚àí1} ‚à©{(x, y) ‚ààR2 : y > x
2} .
See Fig. 4.18 .

4.8 Exercises
149
y = x
2
y = ‚àí3x ‚àí1
Figure 4.18. The domain of the function f of Exercise 2. c)
d) The function‚Äôs domain is deÔ¨Åned by the positivity of the log‚Äôs argument,
whence
{(x, y, z) ‚ààR3 : x2 + y2 + x2 > 9} .
These are the points of the plane outside the sphere at the origin of radius 3.
e) dom f = R2 \ {0} .
f) The map is deÔ¨Åned for z > 0 and x Ã∏= 0; there are no constraints on y. The
domain is thus the subset of R3 given by the half-space z > 0 without the
half-plane x = 0.
g) dom Œ≥ = I = [1, 5].
h) The components x(t) = t ‚àí2
t + 2 and y(t) = log(9 ‚àít2) of the curve are well
deÔ¨Åned for t Ã∏= ‚àí2 and t ‚àà(‚àí3, 3) respectively. Therefore Œ≥ is deÔ¨Åned on the
intervals I1 = (‚àí3, ‚àí2) and I2 = (‚àí2, 3).
i) The surface is deÔ¨Åned for 0 < u2 + v2 < 1, i.e., for points of the punctured
open unit disc on the plane uv.
‚Ñì) The domain of œÉ is dom œÉ = {(u, v) ‚ààR2 : u + v ‚â•0, u2 + v2 Ã∏= 4}. See
Fig. 4.19 for a picture.
y
x
2
Figure 4.19. The domain of the surface œÉ of Exercise 2. ‚Ñì)

150
4 Functions between Euclidean spaces
3. Limits:
a) From
|x| =
‚àö
x2 ‚â§

x2 + y2
follows
|x|

x2 + y2 ‚â§1 .
Hence
|f(x, y)| =
|x| |y|

x2 + y2 ‚â§|y| ,
and by the Squeeze Rule we conclude the limit is 0.
b) If y = 0 or x = 0 the map f(x, y) =
xy
x2 + y2 is identically zero. When com-
puting limits along the axes, then, the result is 0:
lim
x‚Üí0 f(x, 0) = lim
y‚Üí0 f(0, y) = 0 .
But along the line y = x the function equals 1
2, so
lim
x‚Üí0 f(x, x) = lim
x‚Üí0
x2
x2 + x2 = 1
2 .
In conclusion, the limit does not exist.
c) Let us compute the function f(x, y) = x
y log(1+x) along the lines y = kx with
k Ã∏= 0; from
f(x, kx) = 1
k log(1 + x)
follows
lim
x‚Üí0 f(x, kx) = 0 .
Along the parabola y = x2 though, f(x, x2) = 1
x log(1 + x), i.e.,
lim
x‚Üí0 f(x, x2) = 1 .
The limit does not exist.
d) 0 .
e) Does not exist.
f) Does not exist.
g) Since
|f(r cos Œ∏, r sin Œ∏)| = r2 cos2 Œ∏
r
= r cos2 Œ∏ ‚â§r ,
Proposition 4.28, with g(r) = r, implies the limit is 0.
h) 1.

4.8 Exercises
151
i) From
f(r cos Œ∏, r sin Œ∏) = cos Œ∏ ‚àísin Œ∏
cos Œ∏ + sin Œ∏
follows
lim
r‚Üí0 f(r cos Œ∏, r sin Œ∏) = cos Œ∏ ‚àísin Œ∏
cos Œ∏ + sin Œ∏ ;
thus the limit does not exist.
‚Ñì) 5 .
m) Set f(x, y) = x2 + y + 1
x2 + y4
, so that
f(x, 0) = x2 + 1
x2
and
f(0, y) = y + 1
y4
.
Hence
lim
x‚Üí¬±‚àûf(x, 0) = 1
and
lim
y‚Üí¬±‚àûf(0, y) = 0
and we conclude the limit does not exist.
n) Note
0 ‚â§

1 + 3x2 + 5y2
x2 + y2
‚â§

1 + 5(x2 + y2)
x2 + y2
,
‚àÄ(x, y) Ã∏= (0, 0) .
Set t = x2 + y2, so that
lim
(x,y)‚Üí‚àû

1 + 5(x2 + y2)
x2 + y2
=
lim
t‚Üí+‚àû
‚àö1 + 5t
t
= 0
and
0 ‚â§
lim
(x,y)‚Üí‚àû

1 + 3x2 + 5y2
x2 + y2
‚â§
lim
t‚Üí+‚àû
‚àö1 + 5t
t
= 0 .
The required limit is 0.
4. Continuity sets:
a) The function is continuous on its domain as composite map of continuous
functions. For the domain, recall that arcsin is deÔ¨Åned when the argument lies
between ‚àí1 and 1, so
dom f = {(x, y) ‚ààR2 : ‚àí1 ‚â§xy ‚àíx ‚àí2y ‚â§1} .
Let us draw such set. The points of the line x = 2 do not belong to dom f. If
x > 2, the condition ‚àí1 + x ‚â§(x ‚àí2)y ‚â§1 + x is equivalent to
1 +
1
x ‚àí2 = x ‚àí1
x ‚àí2 ‚â§y ‚â§x + 1
x ‚àí2 = 1 +
3
x ‚àí2 ;

152
4 Functions between Euclidean spaces
this means dom f contains all points lying between the graphs of the two
hyperbolas y = 1 +
1
x ‚àí2 and y = 1 +
3
x ‚àí2. Similarly, if x < 2, the domain is
1 +
3
x ‚àí2 ‚â§y ‚â§1 +
1
x ‚àí2 .
Overall, dom f is as in Fig. 4.20.
b) The continuity set is C = {(x, y, z) ‚ààR3 : z Ã∏= x2 + y2}.
5. Let us compute
lim
(x,y)‚Üí(0,0) f(x, y). Using polar coordinates,
f(r cos Œ∏, r sin Œ∏) = rŒ±‚àí2| cos Œ∏|Œ± sin(r sin Œ∏) ;
but | sin t| ‚â§|t|, valid for any t ‚ààR, implies
|f(r cos Œ∏, r sin Œ∏)| ‚â§rŒ±‚àí1| cos Œ∏|Œ±| sin Œ∏| ,
so the limit is zero if Œ± > 1, and does not exist if Œ± ‚â§1. Therefore if Œ± > 1 the
map is continuous on R2, if 0 ‚â§Œ± ‚â§1 it is continuos only on R2 \ {0}.
6. The system
 z = x2
z = 4y2
gives x2 = 4y2. The cylinders‚Äô intersection projects onto the plane xy as the two
lines x = ¬±2y (Fig. 4.21). As we are looking for the branch containing (2, ‚àí1, 4),
we choose x = ‚àí2y. One possible parametrisation is given by t = y, hence
Œ≥(t) = (‚àí2t, t, 4t2) ,
t ‚ààR .
x
y
y = 1 +
1
x‚àí2
2
1
y = 1 +
3
x‚àí2
Figure 4.20. The continuity set of f(x, y) = arcsin(xy ‚àíx ‚àí2y)

4.8 Exercises
153
 
 
 
 
 
 
 
 
x
y
z
Figure 4.21. The intersection of the cylinders z = x2 and z = 4y2
7. We have x + y + x2 = 1, and choosing t = x as parameter,
Œ≥(t) = (t, 1 ‚àít ‚àít2, t2) ,
t ‚ààR .
8. Use cylindrical coordinates with x = 4 cost, y = 4 sin t. Then
Œ≥(t) = (4 cos t, 4 sin t, 4(cos t + sin t)) ,
t ‚àà[0, 2œÄ] .
9. Curves in Cartesian coordinates:
a) We have r(t) = sin2 t and Œ∏(t) = t; recalling that x = r cos Œ∏ and y = r sin Œ∏,
gives
x = sin2 t cos t
and
y = sin3 t .
In Cartesian coordinates then, Œ≥ : [0, 2œÄ] ‚ÜíR2 can be written Œ≥(t) =

x(t), y(t)

=

sin2 t cos t, sin3 t

, see Fig. 4.22, left.
b) We have Œ≥(t) =

sin t
2 cos t, sin t
2 sin t

. The curve is called cardioid, see
Fig. 4.22, right.
10. Graphs:
a) It is straightforward to see
x2
a2 + y2
b2 = u2 cos2 v + u2 sin2 v = u2 = z,
giving the equation of an elliptic paraboloid.
b)
y2 + z2 = a2 .

154
4 Functions between Euclidean spaces
y
x
1
‚àí1
y
x
1
‚àö
2
2
-
‚àö
2
2
Figure 4.22. Traces of the curves of Exercise 9. a) (left) and 9. b) (right)
c) Note that x2 +y2 = (a+b cosu)2 and a+b cosu > 0; therefore

x2 + y2 ‚àía =
b cos u . Moreover,

x2 + y2 ‚àía
2 + z2 = b2 cos2 u + b2 sin2 u = b2 ;
in conclusion

x2 + y2 ‚àía
2 + z2 = b2 .

5
DiÔ¨Äerential calculus for scalar functions
While the previous chapter dealt with the continuity of multivariable functions
and their limits, the next three are dedicated to diÔ¨Äerential calculus. We start in
this chapter by discussing scalar functions.
The power of diÔ¨Äerential tools should be familiar to students from the Ô¨Årst Cal-
culus course; knowing the derivatives of a function of one variable allows to capture
the function‚Äôs global behaviour, on intervals in the domain, as well as the local
one, on arbitrarily small neighbourhoods. In passing to higher dimension, there
are more instruments available that adapt to a more varied range of possibilities.
If on one hand certain facts attract less interest (drawing graphs for instance, or
understanding monotonicity, which is tightly related to the ordering of the reals,
not present any more), on the other new aspects come into play (from Linear
Algebra in particular) and become central. The Ô¨Årst derivative in one variable is
replaced by the gradient vector Ô¨Åeld, and the Hessian matrix takes the place of
the second derivative. Due to the presence of more variables, some notions require
special attention (diÔ¨Äerentiability at a point is a more delicate issue now), whereas
others (convexity, Taylor expansions) translate directly from one to several vari-
ables. The study of so-called unconstrained extrema of a function of several real
variables carries over eÔ¨Äortlessly, thus generalising the known Fermat and Weier-
strass‚Äô Theorems, and bringing to the fore a new kind of stationary points, like
saddle points, at the same time.
5.1 First partial derivatives and gradient
The simplest case where partial derivatives at a point can be seen is on the plane,
i.e., in dimension two, which we start from.
Let f : dom f ‚äÜR2 ‚ÜíR be a function of two variables deÔ¨Åned in a neighbour-
hood of the point x0 = (x0, y0). The map x ‚Üíf(x, y0), obtained by Ô¨Åxing the
second variable to a constant, is a real-valued map of one real variable, deÔ¨Åned
C. Canuto, A. Tabacco: Mathematical Analysis II, 2nd Ed.,
UNITEXT ‚Äì La Matematica per il 3+2 85, DOI 10.1007/978-3-319-12757-6_5,
¬© Springer International Publishing Switzerland 2015

156
5 DiÔ¨Äerential calculus for scalar functions
around the point x0 ‚ààR. If this is diÔ¨Äerentiable at x0, one says f admits partial
derivative with respect to x at x0 and sets
‚àÇf
‚àÇx (x0) = d
dxf(x, y0)

x=x0
= lim
x‚Üíx0
f(x, y0) ‚àíf(x0, y0)
x ‚àíx0
.
Similarly, if y ‚Üíf(x0, y) is diÔ¨Äerentiable at y0, f is said to admit partial deriv-
ative with respect to y at x0 and one deÔ¨Ånes
‚àÇf
‚àÇy (x0) = d
dy f(x0, y)

y=y0
= lim
y‚Üíy0
f(x0, y) ‚àíf(x0, y0)
y ‚àíy0
.
The geometric meaning of partial derivatives is explained in Fig. 5.1.
This can be generalised to functions of n variables, n ‚â•3, in the most obvious
way. Precisely, let a map in n variables f : dom f ‚äÜRn ‚ÜíR be deÔ¨Åned on the
neighbourhood of x0 = (x01, . . . , x0n) =
n

i=1
x0iei, where ei is the ith unit vector
of the canonical basis of Rn seen in (4.1). One says f admits partial derivative
with respect to xi at x0 if the function of one real variable
x ‚Üíf(x01, . . . , x0,i‚àí1, x, x0,i+1, . . . , x0n) ,
 
 
 
 
 
 
 
 
P0
x
y
z
(x0, y0)
(x, y0)
(x0, y)
Œì(f)
r2
r1
 
 
  
  
  
  
 
 
   
   
  
  
 
 
  
  
 
 
Figure 5.1. The partial derivatives of f at x0 are the slopes of the lines r1, r2, tangent
to the graph of f at P0

5.1 First partial derivatives and gradient
157
obtained by making all independent variables but the ith one constant, is diÔ¨Äer-
entiable at x = x0i. If so, one deÔ¨Ånes the symbol
‚àÇf
‚àÇxi
(x0) = d
dxf(x01, . . . , x0,i‚àí1, x, x0,i+1, . . . , x0n)

x=x0i
= lim
Œîx‚Üí0
f(x0 + Œîx ei) ‚àíf(x0)
Œîx
.
(5.1)
The partial derivative of f at x0 with respect to the variable xi is also denoted
as follows
Dxif(x0) ,
Dif(x0) ,
fxi(x0)
(or simply fi(x0), if no confusion arises).
DeÔ¨Ånition 5.1 Assume f admits partial derivatives at x0 with respect to all
variables. The gradient ‚àáf(x0) of f at x0 is the vector deÔ¨Åned by
‚àáf(x0) =
 ‚àÇf
‚àÇxi
(x0)

1‚â§i‚â§n = ‚àÇf
‚àÇx1
(x0) e1 + . . . + ‚àÇf
‚àÇxn
(x0) en ‚ààRn .
Another notation for it is grad f(x0).
We remind that, as any vector in Rn, ‚àáf(x0) can be written both as row or
column vector, according to need.
Examples 5.2
i) Let f(x, y) =

x2 + y2 be the function ‚Äòdistance from the origin‚Äô. At the point
x0 = (2, ‚àí1),
‚àÇf
‚àÇx (x0) = d
dx

x2 + 1

x=2 =
x
‚àö
x2 + 1

x=2
=
2
‚àö
5 ,
‚àÇf
‚àÇy (x0) = d
dy

4 + y2

y=‚àí1 =
y

4 + y2

y=‚àí1
= ‚àí1
‚àö
5 .
Therefore
‚àáf(x0) =
 2
‚àö
5, ‚àí1
‚àö
5

=
1
‚àö
5(2, ‚àí1) .
ii) For f(x, y, z) = y log(2x ‚àí3z), at x0 = (2, 3, 1) we have
‚àÇf
‚àÇx (x0) = d
dx 3 log(2x ‚àí3)

x=2 = 3
2
2x ‚àí3

x=2
= 6 ,
‚àÇf
‚àÇy (x0) = d
dy y log 1

y=3 = 0 ,

158
5 DiÔ¨Äerential calculus for scalar functions
‚àÇf
‚àÇz (x0) = d
dz 3 log(4 ‚àí3z)

z=1 = 3
‚àí3
4 ‚àí3z

z=1
= ‚àí9 ,
whence
‚àáf(x0) = (6, 0, ‚àí9) .
iii) Let f : Rn ‚ÜíR be the aÔ¨Éne map f(x) = a ¬∑ x + b, a ‚ààRn, b ‚ààR. At any
point x0 ‚ààRn,
‚àáf(x0) = a .
iv) Take a function f not depending on the variable xi on a neighbourhood of
x0 ‚ààdom f. Then ‚àÇf
‚àÇxi
(x0) = 0.
In particular, f constant around x0 implies ‚àáf(x0) = 0.
2
The function
‚àÇf
‚àÇxi
: x ‚Üí‚àÇf
‚àÇxi
(x) ,
deÔ¨Åned on a suitable subset dom ‚àÇf
‚àÇxi
‚äÜdom f ‚äÜRn and with values in R, is called
(Ô¨Årst) partial derivative of f with respect to xi. The gradient function of f,
‚àáf : x ‚Üí‚àáf(x),
whose domain dom ‚àáf is the intersection of the domains of the single Ô¨Årst partial
derivatives, is an example of a vector Ô¨Åeld, being a function deÔ¨Åned on a subset of
Rn with values in Rn.
In practice, each partial derivative ‚àÇf
‚àÇxi
is computed by freezing all variables of
f diÔ¨Äerent from xi (taking them as constants), and diÔ¨Äerentiating in the only one
left xi. We can then use on this function everything we know from Calculus 1.
Examples 5.3
We shall use the previous examples.
i) For f(x, y) =

x2 + y2 we have
‚àáf(x) =

x

x2 + y2 ,
y

x2 + y2

=
x
‚à•x‚à•
with dom ‚àáf = R2 \ {0}. The formula holds in any dimension n if f(x) = ‚à•x‚à•
is the norm function on Rn.
ii) For f(x, y, z) = y log(2x ‚àí3z) we obtain
‚àáf(x) =
	
2y
2x ‚àí3z, log(2x ‚àí3z),
‚àí3y
2x ‚àí3z

,
with dom ‚àáf = dom f = {(x, y, z) ‚ààR3 : 2x ‚àí3z > 0}.

5.1 First partial derivatives and gradient
159
iii) The total resistance R produced by three conductors with resistances
R1, R2, R3 in a parallel circuit is given by the formula:
1
R = 1
R1
+ 1
R2
+ 1
R3
.
We want to compute the partial derivative of R with respect to one of the Ri,
say R1. As
R(R1, R2, R3) =
1
1
R1 +
1
R2 +
1
R3
=
R1R2R3
R2R3 + R1R3 + R1R2
,
we have
‚àÇR
‚àÇR1
(R1, R2, R3) =
R2
2R2
3
(R2R3 + R1R3 + R1R2)2 .
2
Partial derivatives with respect to the xi, i = 1, . . . , n, are special cases of
the directional derivative along a vector. Let f be a map deÔ¨Åned around a point
x0 ‚ààRn and let v ‚ààRn be a given non-zero vector. Then f admits partial
derivative, or directional derivative, along v at x0 if
‚àÇf
‚àÇv (x0) = lim
t‚Üí0
f(x0 + tv) ‚àíf(x0)
t
(5.2)
exists and is Ô¨Ånite.
Another notation for this is Dvf(x0). The condition spells out the fact that
the map t ‚Üíf(x0 + tv) is diÔ¨Äerentiable at t0 = 0 (the latter is deÔ¨Åned in a
neighbourhood of t0 = 0, since x0+tv belongs to the neighbourhood of x0 where f
is deÔ¨Åned, for t small enough). See Fig. 5.2 to interpret geometrically the directional
derivative.
 
 
 
 
 
 
 
 
x
y
z
x0
P0
x0 + tv
r
Œì(f)
Figure 5.2. The directional derivative is the slope of the line r tangent to the graph of
f at P0

160
5 DiÔ¨Äerential calculus for scalar functions
The directional derivative of f at x0 with respect to xi is obtained by choosing
v = ei; thus
‚àÇf
‚àÇei
(x0) = ‚àÇf
‚àÇxi
(x0),
i = 1, . . . , n ,
as is immediate by comparing (5.2) with (5.1), using Œîx = t.
In the next section we discuss the relationship between the gradient and direc-
tional derivatives of diÔ¨Äerentiable functions.
5.2 DiÔ¨Äerentiability and diÔ¨Äerentials
Recall from Vol. I, Sect. 6.6 that a real map of one real variable f, diÔ¨Äerentiable
at x0 ‚ààR, satisÔ¨Åes the Ô¨Årst formula of the Ô¨Ånite increment
f(x) = f(x0) + f ‚Ä≤(x0)(x ‚àíx0) + o(x ‚àíx0) ,
x ‚Üíx0 .
(5.3)
This is actually equivalent to diÔ¨Äerentiability at x0, because if there is a number
a ‚ààR such that
f(x) = f(x0) + a (x ‚àíx0) + o(x ‚àíx0) ,
x ‚Üíx0 ,
necessarily f is diÔ¨Äerentiable at x0, and a = f ‚Ä≤(x0). From the geometric viewpoint,
furthermore, diÔ¨Äerentiability at x0 amounts to the existence of the tangent line to
the graph of f at the point P0 =

x0, f(x0)

:
y = t(x) = f(x0) + f ‚Ä≤(x0)(x ‚àíx0) .
In presence of several variables, the picture is more involved and the existence of
the gradient of f at x0 does not guarantee the validity of a formula like (5.3), e.g.,
f(x) = f(x0) + ‚àáf(x0) ¬∑ (x ‚àíx0) + o(‚à•x ‚àíx0‚à•) ,
x ‚Üíx0 ,
(5.4)
nor the existence of the tangent plane (or hyperplane, if n > 2) to the graph of f
at P0 =

x0, f(x0)

‚ààRn+1. Consider for example the function
f(x, y) =
‚éß
‚é™
‚é®
‚é™
‚é©
x2y
x2 + y2
if (x, y) Ã∏= (0, 0) ,
0
if (x, y) = (0, 0) .
The map is identically zero on the coordinate axes (f(x, 0) = f(0, y) = 0 for any
x, y ‚ààR), so
‚àÇf
‚àÇx(0, 0) = ‚àÇf
‚àÇy (0, 0) = 0 ,
i.e.,
‚àáf(0, 0) = (0, 0) .

5.2 DiÔ¨Äerentiability and diÔ¨Äerentials
161
If we had (5.4), at x0 = (0, 0) we would Ô¨Ånd
lim
(x,y)‚Üí(0,0)
x2y
(x2 + y2)

x2 + y2 = 0 ;
but moving along the line y = x, for instance, we have
lim
x‚Üí0¬±
x3
2
‚àö
2x2|x| = ¬± 1
2
‚àö
2 Ã∏= 0 .
Not even the existence of every partial derivative at x0 warrants (5.4) will hold. It
is easy to see that the above f has directional derivatives along any given vector v.
Thus it makes sense to introduce the following deÔ¨Ånition.
DeÔ¨Ånition 5.4 A function f is diÔ¨Äerentiable at an interior point x0 of the
domain, if ‚àáf(x0) exists and the following formula holds:
f(x) = f(x0) + ‚àáf(x0) ¬∑ (x ‚àíx0) + o(‚à•x ‚àíx0‚à•) ,
x ‚Üíx0 .
(5.5)
In the case n = 2,
z = f(x0) + ‚àáf(x0) ¬∑ (x ‚àíx0) ,
(5.6)
i.e.,
z = f(x0, y0) + ‚àÇf
‚àÇx(x0, y0)(x ‚àíx0) + ‚àÇf
‚àÇy (x0, y0)(y ‚àíy0) ,
(5.7)
deÔ¨Ånes a plane, called the tangent plane to the graph of the function f at P0 =

x0, y0, f(x0, y0)

. This is the plane that best approximates the graph of f on a
neighbourhood of P0, see Fig. 5.3. The diÔ¨Äerentiability at x0 is equivalent to the
existence of the tangent plane at P0. In higher dimensions n > 2, equation (5.6)
deÔ¨Ånes the hyperplane (aÔ¨Éne subspace of codimension 1, i.e., of dimension n ‚àí1)
tangent to the graph of f at the point P0 =

x0, f(x0)

.
Equation (5.5) suggests a natural way to approximate the map f around x0
by means of a polynomial of degree one in x. Neglecting the higher-order terms,
we have in fact
f(x) ‚àºf(x0) + ‚àáf(x0) ¬∑ (x ‚àíx0)
on a neighbourhood of x0. This approximation, called linearisation of f at x0,
often allows to simplify in a constructive and eÔ¨Écient way the mathematical de-
scription of a physical phenomenon.
Here is yet another interpretation of (5.5): put Œîx = x ‚àíx0 in the formula,
so that
f(x0 + Œîx) = f(x0) + ‚àáf(x0) ¬∑ Œîx + o(‚à•Œîx‚à•) ,
Œîx ‚Üí0 ,

162
5 DiÔ¨Äerential calculus for scalar functions
 
 
 
 
 
 
 
 
x
y
z
x0
P0
Œ†
Œì(f)
Figure 5.3. Tangent plane at P0
in other words
Œîf = f(x0 + Œîx) ‚àíf(x0) = ‚àáf(x0) ¬∑ Œîx + o(‚à•Œîx‚à•) ,
Œîx ‚Üí0 .
Then the increment Œîf of the dependent variable is, up to an inÔ¨Ånitesimal of order
bigger than one, proportional to the increment Œîx of the independent variable.
This means the linear map Œîx ‚Üí‚àáf(x0) ¬∑ Œîx is an approximation, often suÔ¨É-
ciently accurate, of the variation of f in a neighbourhood of x0. This fact justiÔ¨Åes
the next deÔ¨Ånition.
DeÔ¨Ånition 5.5 The linear map dfx0 : Rn ‚ÜíR
dfx0(Œîx) = ‚àáf(x0) ¬∑ Œîx
is called diÔ¨Äerential of f at x0.
Example 5.6
Consider f(x, y) = ‚àö1 + x + y and set x0 = (1, 2). Then ‚àáf(x0) =
 1
4, 1
4

and
the diÔ¨Äerential at x0 is the function
dfx0(Œîx,Œîy ) = 1
4Œîx + 1
4Œîy .
Choosing for instance (Œîx,Œîy ) =
 1
100, 1
20

, we will have
Œîf =

203
50 ‚àí2 = 0.014944 . . .
while
dfx0
 1
100, 1
20

= 0.015 .
2
Just like in dimension one, diÔ¨Äerentiability implies continuity also for several
variables.

5.2 DiÔ¨Äerentiability and diÔ¨Äerentials
163
Proposition 5.7 A diÔ¨Äerentiable map f at x0 is continuous at x0.
Proof.
From (5.4),
lim
x‚Üíx0 f(x) = lim
x‚Üíx0

f(x0) + ‚àáf(x0) ¬∑ (x ‚àíx0) + o(‚à•x ‚àíx0‚à•)

= f(x0) .
2
This property shows that the deÔ¨Ånition of a diÔ¨Äerentiable function of several
variables is the correct analogue of what we have in dimension one.
In order to check whether a map is diÔ¨Äerentiable at a point of its domain,
the following suÔ¨Écient condition if usually employed. Its proof may be found in
Appendix A.1.1, p. 511.
Proposition 5.8 Assume f admits continuous partial derivatives on a
neighbourhood of x0. Then f is diÔ¨Äerentiable at x0.
Here is another feature of diÔ¨Äerentiable maps.
Proposition 5.9 If a function f is diÔ¨Äerentiable at x0, it admits at x0 dir-
ectional derivatives along any vector v Ã∏= 0, and moreover
‚àÇf
‚àÇv (x0) = ‚àáf(x0) ¬∑ v = ‚àÇf
‚àÇx1
(x0) v1 + ¬∑ ¬∑ ¬∑ + ‚àÇf
‚àÇxn
(x0) vn .
(5.8)
Proof.
Using (5.4),
f(x0 + tv) = f(x0) + t‚àáf(x0) ¬∑ v + o(‚à•tv‚à•) ,
‚à•tv‚à•‚Üí0 .
Since ‚à•tv‚à•= |t|‚à•v‚à•, we have o(‚à•tv‚à•) = o(t) , t ‚Üí0, and hence
‚àÇf
‚àÇv (x0) = lim
t‚Üí0
f(x0 + tv) ‚àíf(x0)
t
= lim
t‚Üí0
t‚àáf(x0) ¬∑ v + o(t)
t
= ‚àáf(x0) ¬∑ v .
2
Note that (5.8) furnishes the expressions
‚àÇf
‚àÇxi
(x0) = ei ¬∑ ‚àáf(x0),
i = 1, . . . , n ,
which might turn out to be useful.
Formula (5.8) establishes a simple-yet-crucial result concerning the behaviour
of a map around x0 in case the gradient is non-zero at that point. How does
the directional derivative of f at x0 vary, when we change the direction along

164
5 DiÔ¨Äerential calculus for scalar functions
which we diÔ¨Äerentiate? To answer this we Ô¨Årst of all establish bounds for ‚àÇf
‚àÇv (x0)
when v is a unit vector (‚à•v‚à•= 1) in Rn. By (5.8), recalling the Cauchy-Schwarz
inequality (4.3), we have

‚àÇf
‚àÇv (x0)
 ‚â§‚à•‚àáf(x0)‚à•
i.e.,
‚àí‚à•‚àáf(x0)‚à•‚â§‚àÇf
‚àÇv(x0) ‚â§‚à•‚àáf(x0)‚à•.
Now, equality is attained for v = ¬± ‚àáf(x0)
‚à•‚àáf(x0)‚à•, and then ‚àÇf
‚àÇv(x0) reaches its (posit-
ive) maximum or (negative) minimum according to whether v is plus or minus the
unit vector parallel to ‚àáf(x0). In summary we have proved the following result,
shown in Fig. 5.4 (see Sect. 7.2.1 for more details).
Proposition 5.10 At points x0 where the gradient of f does not vanish, f
has the greatest rate of increase, starting from x0, in the direction of the
gradient, and the greatest decrease in the opposite direction.
The next property will be useful in the sequel. The proof of Proposition 5.9
showed that the map œï(t) = f(x0 + tv) is diÔ¨Äerentiable at t = 0, and
œï‚Ä≤(0) = ‚àáf(x0) ¬∑ v .
(5.9)
+
‚àí
‚àáf(x0)
‚àí‚àáf(x0)
v
x0
Figure 5.4. Level curves and direction of steepest slope

5.2 DiÔ¨Äerentiability and diÔ¨Äerentials
165
More generally,
Property 5.11 Let a, v ‚ààRn be given points and suppose f is diÔ¨Äerentiable
at a + t0v, t0 ‚ààR. Then the map œï(t) = f(a + tv) is diÔ¨Äerentiable at t0, and
œï‚Ä≤(t0) = ‚àáf(a + t0v) ¬∑ v .
(5.10)
Proof.
Set Œît = t ‚àít0, so that a + tv = (a + t0v) + Œît v and then œï(t) =
f(a + t0v + Œîtv) = œà(Œît). Now apply (5.9) to the map œà.
2
Formula (5.10) is nothing else but a special case of the rule for diÔ¨Äerentiating
a composite map of several variables, for which see Sect. 6.4.
5.2.1 Mean Value Theorem and Lipschitz functions
Let a , b be distinct points in Rn and
S[a, b] = {x(t) = (1 ‚àít)a + tb : 0 ‚â§t ‚â§1}
be the segment between a and b, as in (4.19). The result below is the n-dimensional
version of the famous result for one-variable functions due to Lagrange.
Theorem 5.12 (Mean Value Theorem or Lagrange Theorem) Let f :
dom f ‚äÜRn ‚ÜíR be deÔ¨Åned and continuous at any point of S[a, b], and
diÔ¨Äerentiable at any point of S[a, b] with the (possible) exception of the end-
points a and b. Then there exists an x ‚ààS[a, b] diÔ¨Äerent from a, b such
that
f(b) ‚àíf(a) = ‚àáf(x) ¬∑ (b ‚àía) .
(5.11)
Proof.
Consider the auxiliary map œï(t) = f

x(t)

, deÔ¨Åned - and continuous - on
[0, 1] ‚äÇR, as composite of the continuous maps t ‚Üíx(t) and f, for any
x(t). Because x(t) = a+t(b‚àía), and using Property 5.11 with v = b‚àía,
we obtain that œï is diÔ¨Äerentiable (at least) on (0, 1), plus
œï‚Ä≤(t) = ‚àáf

x(t)

¬∑ (b ‚àía) ,
0 < t < 1 .
Then œï satisÔ¨Åes the one-dimensional Mean Value Theorem on [0, 1], and
there must be a t ‚àà(0, 1) such that
œï(1) ‚àíœï(0) = œï‚Ä≤(t) .
Putting x = x(t) in the above gives precisely (5.11).
2

166
5 DiÔ¨Äerential calculus for scalar functions
As an application, we will Ô¨Ånd a result known to the reader at least in dimension
one.
Proposition 5.13 Let R be a region in Rn and f : R ‚äÜRn ‚ÜíR a continu-
ous map on R, diÔ¨Äerentiable everywhere on A =
‚ó¶
R. Then
‚àáf = 0
on A
‚áê‚áí
f is constant on R .
Proof.
We have seen that f constant on R, hence on A a fortiori, implies ‚àáf = 0
at each point of A (Example 5.2 iv)).
Conversely, let us Ô¨Åx an arbitrary a in A, and choose any b in R. There
is a polygonal path P[a0, . . . , ar] with a0 = a, ar = b, going from one
to the other (directly from the deÔ¨Ånition of open connected set if b ‚ààA,
while if b ‚àà‚àÇA we can join it to a point of A through a segment). On
each segment S[aj‚àí1, aj], 1 ‚â§j ‚â§r forming the path, the hypotheses of
Theorem 5.12 hold, so from (5.11) and the fact that ‚àáf = 0 identically,
follows
f(aj) ‚àíf(aj‚àí1) = 0 ,
whence f(b) = f(a) for any b ‚ààR. That means f is constant.
2
Consequently, if f is diÔ¨Äerentiable everywhere on an open set A and its gradient
is zero on A, then f is constant on each connected component of A.
The property we are about to introduce is relevant for the applications. For
this, let R be a region of dom f.
DeÔ¨Ånition 5.14 The map f is Lipschitz on R if there is a constant L ‚â•0
such that
|f(x1) ‚àíf(x2)| ‚â§L‚à•x1 ‚àíx2‚à•,
‚àÄx1, x2 ‚ààR .
(5.12)
The smallest number L verifying the condition is said Lipschitz constant
of f on R.
By deÔ¨Ånition of least upper bound we easily see that the Lipschitz constant of
f on R is
sup
x1,x2‚ààR
x1Ã∏=x2
|f(x1) ‚àíf(x2)|
‚à•x1 ‚àíx2‚à•
.
To say that f is Lipschitz on R tantamounts to the assertion that the supremum
is Ô¨Ånite.
Examples 5.15
i) The aÔ¨Éne map f(x) = a ¬∑ x + b (a ‚ààRn, b ‚ààR) is Lipschitz on Rn, as shown
by (4.21). It can be proved the Lipschitz constant equals ‚à•a‚à•.

5.2 DiÔ¨Äerentiability and diÔ¨Äerentials
167
ii) The function f(x) = ‚à•x‚à•, mapping x ‚ààRn to its Euclidean norm, is Lipschitz
on Rn with Lipschitz constant 1, as
‚à•x1‚à•‚àí‚à•x2‚à•
 ‚â§‚à•x1 ‚àíx2‚à•,
‚àÄx1, x2 ‚ààRn .
This is a consequence of x1 = x2 + (x1 ‚àíx2) and the triangle inequality (4.4)
‚à•x1‚à•‚â§‚à•x2‚à•+ ‚à•x1 ‚àíx2‚à•,
i.e.,
‚à•x1‚à•‚àí‚à•x2‚à•‚â§‚à•x1 ‚àíx2‚à•;
swapping x1 and x2 yields the result.
iii) The map f(x) = ‚à•x‚à•2 is not Lipschitz on all Rn. In fact, choosing x2 = 0,
equation (5.12) becomes
‚à•x1‚à•2 ‚â§L‚à•x1‚à•,
which is true if and only if ‚à•x1‚à•‚â§L. It becomes Lipschitz on any bounded region
R, for
‚à•x1‚à•2 ‚àí‚à•x2‚à•2 =

‚à•x1‚à•+ ‚à•x2‚à•
 ‚à•x1‚à•‚àí‚à•x2‚à•

‚â§2M
‚à•x1‚à•‚àí‚à•x2‚à•
 ,
‚àÄx1, x2 ‚ààR ,
where M = sup{‚à•x‚à•: x ‚ààR} and using the previous example.
2
Note if R is open, the property of being Lipschitz implies the (uniform) con-
tinuity on R.
There is a suÔ¨Écient condition for being Lipschitz, namely:
Proposition 5.16 Let f be diÔ¨Äerentiable over a convex region R inside
dom f, with bounded (Ô¨Årst) partial derivatives. Then f is Lipschitz on R.
Precisely, for any M ‚â•0 such that

‚àÇf
‚àÇxi
(x)
 ‚â§M ,
‚àÄx ‚ààR, i = 1, . . . , n ,
one has (5.12) with L = ‚àön M.
Proof.
Pick x1, x2 ‚ààR. By assumption the segment S[x1, x2] is contained in R
and f is diÔ¨Äerentiable (hence, continuous) at any point of S[x1, x2]. Thus
by the Mean Value Theorem 5.12 there is an x ‚ààR with
f(x1) ‚àíf(x2) = ‚àáf(x) ¬∑ (x1 ‚àíx2) .
The Cauchy-Schwarz inequality (4.3) tells us
|f(x1) ‚àíf(x2)| ‚â§‚à•‚àáf(x)‚à•‚à•x1 ‚àíx2‚à•.
To conclude, observe
‚à•‚àáf(x)‚à•=
 n

i=1

‚àÇf
‚àÇxi
(x)

21/2
‚â§
 n

i=1
M 2
1/2
= ‚àön M .
2

168
5 DiÔ¨Äerential calculus for scalar functions
The assertion that the existence and boundedness of the partial derivatives
implies being Lipschitz is a fact that holds under more general assumptions: for
instance if R is compact, or if the boundary of R is suÔ¨Éciently regular.
5.3 Second partial derivatives and Hessian matrix
Let f admit partial derivative in xi on a whole neighbourhood of x0. If ‚àÇf
‚àÇxi
admits
Ô¨Årst derivative at x0 with respect to xj, we say f admits at x0 second partial
derivative with respect to xi and xj, and set
‚àÇ2f
‚àÇxj‚àÇxi
(x0) =
‚àÇ
‚àÇxj
	 ‚àÇf
‚àÇxi

(x0) .
If i Ã∏= j one speaks of mixed second partial derivatives, while for i = j second
partial derivatives are said of pure type and denoted by the symbol ‚àÇ2f
‚àÇx2
i
. Other
ways to denote second partial derivatives are
D2
xjxif(x0) ,
D2
jif(x0) ,
fxjxi(x0) ,
fji(x0) .
In case i is diÔ¨Äerent from j, and assuming f admits at x0 mixed derivatives
‚àÇ2f
‚àÇxj‚àÇxi
(x0) and
‚àÇ2f
‚àÇxi‚àÇxj
(x0), these might diÔ¨Äer. Take for example
f(x, y) =
‚éß
‚é®
‚é©
xy x2 ‚àíy2
x2 + y2
if (x, y) Ã∏= (0, 0),
0
if (x, y) = (0, 0),
a function such that ‚àÇ2f
‚àÇy‚àÇx(0, 0) = ‚àí1 while ‚àÇ2f
‚àÇx‚àÇy(0, 0) = 1.
We have arrived at an important suÔ¨Écient condition, very often fulÔ¨Ålled, for
the mixed derivatives to coincide.
Theorem 5.17 (Schwarz) If the mixed partial derivatives
‚àÇ2f
‚àÇxj‚àÇxi
and
‚àÇ2f
‚àÇxi‚àÇxj
(j Ã∏= i) exist on a neighbourhood of x0 and are continuous at x0,
they coincide at x0.
Proof.
See Appendix A.1.1, p. 512.
2

5.3 Second partial derivatives and Hessian matrix
169
DeÔ¨Ånition 5.18 If f possesses all second partial derivatives at x0, the matrix
Hf(x0) = (hij)1‚â§i,j‚â§n
where
hij =
‚àÇ2f
‚àÇxj‚àÇxi
(x0) ,
(5.13)
or
Hf(x0) =
‚éõ
‚éú
‚éú
‚éú
‚éú
‚éú
‚éú
‚éú
‚éú
‚éú
‚éù
‚àÇ2f
‚àÇx2
1
(x0)
‚àÇ2f
‚àÇx2‚àÇx1
(x0)
. . .
‚àÇ2f
‚àÇxn‚àÇx1
(x0)
‚àÇ2f
‚àÇx1‚àÇx2
(x0)
‚àÇ2f
‚àÇx2
2
(x0)
. . .
‚àÇ2f
‚àÇxn‚àÇx2
(x0)
...
...
‚àÇ2f
‚àÇx1‚àÇxn
(x0)
. . .
. . .
‚àÇ2f
‚àÇx2n
(x0)
‚éû
‚éü
‚éü
‚éü
‚éü
‚éü
‚éü
‚éü
‚éü
‚éü
‚é†
,
is called Hessian matrix of f at x0 (Hessian for short).
The Hessian matrix is also commonly denoted by Hessf(x0), or Hf(x0).
If the mixed derivatives are continuous at x0, the matrix Hf(x0) is symmet-
ric by Schwarz‚Äôs Theorem. Then the order of diÔ¨Äerentiation is irrelevant, and
fxixj(x0), fij(x0) is the same as fxjxi(x0), fji(x0).
The Hessian makes its appearance when studying the local behaviour of f at
x0, as explained in Sect. 5.6.
Examples 5.19
i) For the map f(x, y) = x sin(x + 2y) we have
‚àÇf
‚àÇx(x, y) = sin(x + 2y) + x cos(x + 2y) ,
‚àÇf
‚àÇy (x, y) = 2x cos(x + 2y) ,
so that
‚àÇ2f
‚àÇx2 (x) = 2 cos(x + 2y) ‚àíx sin(x + 2y) ,
‚àÇ2f
‚àÇx‚àÇy(x) = ‚àÇ2f
‚àÇy‚àÇx(x) = 2 cos(x + 2y) ‚àí2x sin(x + 2y) ,
‚àÇ2f
‚àÇy2 (x) = ‚àí4x sin(x + 2y) .
At the origin x0 = 0 the Hessian of f is
Hf(0) =
	
2
2
2
0

.
ii) Given the symmetric matrix A ‚ààRn√ón, a vector b ‚ààRn and a constant
c ‚ààR, we deÔ¨Åne the map f : Rn ‚ÜíR by
f(x) = x ¬∑ Ax + b ¬∑ x + c =
n

p=1
xp
 n

q=1
apqxq

+
n

p=1
bpxp + c .

170
5 DiÔ¨Äerential calculus for scalar functions
For the product Ax to make sense, we are forced to write x as a column vector,
as will happen for all vectors considered in the example. By the chain rule
‚àÇf
‚àÇxi
(x) =
n

p=1
‚àÇxp
‚àÇxi
 n

q=1
apqxq

+
n

p=1
xp
 n

q=1
apq
‚àÇxq
‚àÇxi

+
n

p=1
bp
‚àÇxp
‚àÇxi
.
For each pair of indices p, i between 1 and n,
‚àÇxp
‚àÇxi
= Œ¥pi =

1
if p = i ,
0
if p Ã∏= i ,
so
‚àÇf
‚àÇxi
(x) =
n

q=1
aiqxq +
n

p=1
xpapi + bi .
On the other hand A is symmetric and the summation is index arbitrary, so
n

p=1
xpapi =
n

p=1
aipxp =
n

q=1
aiqxq .
Then
‚àÇf
‚àÇxi
(x) = 2
n

q=1
aiqxq + bi ,
i.e.,
‚àáf(x) = 2Ax + b .
DiÔ¨Äerentiating further,
hij =
‚àÇ2f
‚àÇxj‚àÇxi
(x) = 2aij ,
1 ‚â§i, j ‚â§n ,
Hf(x) = 2A .
Note the Hessian of f is independent of x.
iii) The kinetic energy of a body with mass m moving at velocity v is K = 1
2mv2.
Then
‚àáK(m, v) =
1
2v2, mv

and
HK(m, v) =
	
0
v
v
m

.
Note that
‚àÇK
‚àÇm
‚àÇ2K
‚àÇv2 = K .
2
5.4 Higher-order partial derivatives
The second partial derivatives
‚àÇ2f
‚àÇxj‚àÇxi
of f have been deÔ¨Åned as Ô¨Årst partial deriv-
atives of the functions ‚àÇf
‚àÇxi
; under Schwarz‚Äôs Theorem, the order of diÔ¨Äerentiation
is inessential. Similarly one deÔ¨Ånes the partial derivatives of order three as Ô¨Årst de-
rivatives of the maps
‚àÇ2f
‚àÇxj‚àÇxi
(assuming this is possible, of course). In general, by

5.5 Taylor expansions; convexity
171
successive diÔ¨Äerentiation one deÔ¨Ånes kth partial derivatives (or partial deriv-
atives of order k) of f, for any integer k ‚â•1. Supposing that the mixed partial
derivatives of all orders are continuous, and thus satisfy Schwarz‚Äôs Theorem, one
indicates by
‚àÇkf
‚àÇxŒ±1
1 ‚àÇxŒ±2
2 . . . ‚àÇxŒ±n
n
(x0)
the kth partial derivative of f at x0, obtained diÔ¨Äerentiating Œ±1 times with respect
to x1, Œ±2 times with respect to x2, . . . , Œ±n times with respect to xn. The exponents
Œ±i are integers between 0 and k such that Œ±1 +Œ±2+. . .+Œ±n = k. Frequent symbols
include DŒ±f(x0), that involves the multi-index Œ± = (Œ±1, Œ±2, . . . , Œ±n) ‚ààNn, but
also, e.g., fxxy to denote diÔ¨Äerentiation in x twice, in y once.
One last piece of notation concerns functions f, called of class Ck (k ‚â•1)
over an open set Œ© ‚äÜdom f if the partial derivatives of any order ‚â§k exist and
are continuous everywhere on Œ©. The set of such maps is indicated by Ck(Œ©).
By extension, C0(Œ©) will be the set of continuous maps on Œ©, and C‚àû(Œ©) the
set of maps belonging to Ck(Œ©) for any k, hence the functions admitting partial
derivatives of any order on Œ©. Notice the inclusions
C‚àû(Œ©) ‚äÇ. . . ‚äÇCk(Œ©) ‚äÇCk‚àí1(Œ©) ‚äÇ. . . ‚äÇC0(Œ©) .
Thanks to Propostion 5.8, a function in C1(Œ©) is diÔ¨Äerentiable everywhere on Œ©.
Instead of the open set Œ©, we may take the closure Œ©, and assume Œ© is con-
tained in dom f. If so, we write f ‚ààC0(Œ©) if f is continuous at any point of Œ©;
for 1 ‚â§k ‚â§‚àû, we write f ‚ààCk(Œ©), or say f is Ck on Œ©, if there is an open set
Œ©‚Ä≤ with Œ© ‚äÇŒ©‚Ä≤ ‚äÜdom f and f ‚ààCk(Œ©‚Ä≤).
5.5 Taylor expansions; convexity
Taylor expansions allow to approximate, locally, a function using a polynomial in
the independent variables by the knowledge of certain partial derivatives, just as in
dimension one. We already encountered examples; for a diÔ¨Äerentiable map formula
(5.5) holds, which is the Taylor expansion at Ô¨Årst order with Peano‚Äôs remainder.
Note
T f1,x0(x) = f(x0) + ‚àáf(x0) ¬∑ (x ‚àíx0)
is a polynomial of degree less or equal than 1 in the xi, called Taylor polynomial
of f at x0 of order 1. Besides, if f is C1 on a neighbourhood of x0, then (5.11)
holds with a = x0 and b = x arbitrarily chosen in the neighbourhood, so
f(x) = f(x0) + ‚àáf(x) ¬∑ (x ‚àíx0) ,
x ‚ààS[x, x0] .
(5.14)

172
5 DiÔ¨Äerential calculus for scalar functions
Viewing the constant f(x0) as a 0-degree polynomial, the formula gives the Taylor
expansion of f at x0 of order 0, with Lagrange‚Äôs remainder.
Increasing the map‚Äôs regularity we can Ô¨Ånd Taylor formulas that are more and
more precise. For C2 maps we have the following results, whose proofs are given
in Appendix A.1.2, p. 513 and p. 514.
Theorem 5.20 A function f of class C2 around x0 admits at x0 the Taylor
expansion of order one with Lagrange‚Äôs remainder:
f(x) = f(x0) + ‚àáf(x0) ¬∑ (x ‚àíx0) + 1
2(x ‚àíx0) ¬∑ Hf(x)(x ‚àíx0) ,
(5.15)
where x is interior to the segment S[x, x0].
Formulas (5.4) and (5.15) are two diÔ¨Äerent ways of writing the remainder of f
in the degree-one Taylor polynomial T f1,x0(x).
The expansion of order two is given by
Theorem 5.21 A function f of class C2 around x0 admits at x0 the follow-
ing Taylor expansion of order two with Peano‚Äôs remainder:
f(x) = f(x0) + ‚àáf(x0) ¬∑ (x ‚àíx0) + 1
2(x ‚àíx0) ¬∑ Hf(x0)(x ‚àíx0)
+o(‚à•x ‚àíx0‚à•2) ,
x ‚Üíx0 .
(5.16)
The expression
T f2,x0(x) = f(x0) + ‚àáf(x0) ¬∑ (x ‚àíx0) + 1
2(x ‚àíx0) ¬∑ Hf(x0)(x ‚àíx0)
is a polynomial of degree ‚â§2 in the xi, called Taylor polynomial of f at
x0 of order 2. It gives the best quadratic approximation of the map on the
neighbourhood of x0 (see Fig. 5.5 for an example).
For clarity‚Äôs sake, let us render (5.16) explicit for an f(x, y) of two variables:
f(x, y) = f(x0, y0) + fx(x0, y0)(x ‚àíx0) + fy(x0, y0)(y ‚àíy0)
+1
2fxx(x0, y0)(x ‚àíx0)2 + fxy(x0, y0)(x ‚àíx0)(y ‚àíy0) + 1
2fyy(x0, y0)(y ‚àíy0)2
+o

(x ‚àíx0)2 + (y ‚àíy0)2
,
(x, y) ‚Üí(x0, y0) .
For the quadratic term we used the fact that the Hessian is symmetric by Schwarz‚Äôs
Theorem.
Taylor formulas of arbitrary order n can be written assuming f is Cn around
x0. These, though, go beyond the scope of the present text.

5.5 Taylor expansions; convexity
173
 
 
P0
f
T f2,x0
Figure 5.5. Graph of the order-two Taylor polynomial of f at x0 (osculating paraboloid
at P0)
5.5.1 Convexity
The idea of convexity, both global and local, for one-variable functions (Vol. I,
Sect. 6.9) can be generalised to several variables.
Global convexity goes through the convexity of the set of points above the
graph, and namely: take f : C ‚äÜRn ‚ÜíR with C a convex set, and deÔ¨Åne
Ef =

(x, y) ‚ààRn+1 : x ‚ààC, y ‚â•f(x)

.
Then f is convex on C if the set Ef is convex.
Local convexity depends upon the mutual position of f‚Äôs graph and the tangent
plane. Precisely, f diÔ¨Äerentiable at x0 ‚ààdom f is said convex at x0 if there is a
neighbourhood Br(x0) such that
f(x) ‚â•f(x0) + ‚àáf(x0) ¬∑ (x ‚àíx0) ,
‚àÄx ‚ààBr(x0) ;
f is strictly convex at x0 if the inequality is strict for any x Ã∏= x0.
It can be proved that the local convexity of a diÔ¨Äerentiable map f at any point
in a convex subset C ‚äÜdom f is equivalent to the global convexity of f on C.
Take a C2 map f around a point x0 in dom f. Using Theorem 5.21 and the
properties of the symmetric matrix Hf(x0) (see Sect. 4.2), we can say that
Hf(x0) is positive semi-deÔ¨Ånite
‚áê‚áí
f is convex at x0
Hf(x0) is positive deÔ¨Ånite
=‚áí
f is strictly convex at x0 .

174
5 DiÔ¨Äerential calculus for scalar functions
5.6 Extremal points of a function; stationary points
Extremum values and extremum points (local or global) in several variables are
deÔ¨Åned in analogy to dimension one.
DeÔ¨Ånition 5.22 A point x0 ‚ààdom f is a relative (or local) maximum
point for f if, on a neighbourhood Br(x0) of x0,
‚àÄx ‚ààBr(x0) ‚à©dom f,
f(x) ‚â§f(x0).
The value f(x0) is a relative maximum of f.
Moreover, x0 is said an absolute, or global, maximum point for f if
‚àÄx ‚ààdom f,
f(x) ‚â§f(x0),
and correspondingly f(x0) is the absolute maximum of f. Either way, the
maximum is strict if f(x) < f(x0) when x Ã∏= x0.
Inverting the inequalities deÔ¨Ånes relative and absolute minimum points.
Minimum and maximum points alike are called extrema, or extremum points,
for f.
Examples 5.23
i) The map f(x) = ‚à•x‚à•has a strict global minimum at the origin, for f(0) = 0
and f(x) > 0 for any x Ã∏= 0. Clearly f has no maximum points (neither relative,
nor absolute) on Rn.
ii) The function f(x, y) = x2(e‚àíy2 ‚àí1) is always ‚â§0, since x2 ‚â•0 and e‚àíy2 ‚â§1
for all (x, y) ‚ààR2. Moreover, it vanishes if x = 0 or y = 0, i.e., f(0, y) = 0 for
any y ‚ààR and f(x, 0) = 0 for all x ‚ààR. Hence all points on the coordinate axes
are global maxima (not strict).
2
Extremum points as of DeÔ¨Ånition 5.22 are commonly called unconstrained, be-
cause the independent variable is ‚Äúfree‚Äù to roam the whole domain of the function.
Later (Sect. 7.3) we will see the notion of ‚Äúconstrained‚Äù extremum points, for which
the independent variable is restricted to a subset of the domain, like a curve or a
surface.
A suÔ¨Écient condition for having extrema in several variables is Weierstrass‚Äôs
Theorem (seen in Vol. I, Thm. 4.31); the proof is completely analogous.
Theorem 5.24 (Weierstrass) Let f be continuous on a compact set K ‚äÜ
dom f. Its image f(K) is a closed and bounded subset of R, and in particular,
f(K) is a closed interval if K is connected.
Consequently, f has on K a maximum and a minimum value.

5.6 Extremal points of a function; stationary points
175
For example, f(x) = ‚à•x‚à•admits absolute maximum on every compact set
K ‚äÇRn.
There is also a notion of critical point for functions of several variables.
DeÔ¨Ånition 5.25 A point x0 at which f is diÔ¨Äerentiable is critical or sta-
tionary for f if ‚àáf(x0) = 0. If, instead, ‚àáf(x0) Ã∏= 0, x0 is said a regular
point for f.
By (5.8) a stationary point annihilates all directional derivatives of f.
In two variables stationary points have a neat geometric interpretation. Re-
calling (5.7), a point is stationary if the tangent plane to the graph is horizontal
(Fig. 5.6).
It is Fermat‚Äôs Theorem that justiÔ¨Åes the interest in Ô¨Ånding stationary points;
we state it below for the several-variable case.
Theorem 5.26 (Fermat) Let f be diÔ¨Äerentiable at the extremum point x0.
Then x0 is stationary for f.
Proof.
By assumption the map of one variable
x ‚Üíf(x01, . . . , x0,i‚àí1, x, x0,i+1, . . . , x0n)
is, for any i, deÔ¨Åned and diÔ¨Äerentiable on a neighbourhood of x0i; the latter
is an extremum point. Thus, Fermat‚Äôs Theorem for one-variable functions
gives ‚àÇf
‚àÇxi
(x0) = 0 .
2
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
P1
P3
P2
P4
Figure 5.6. Tangent planes at stationary points in two variables

176
5 DiÔ¨Äerential calculus for scalar functions
In the light of this result, we make a few observations on the relationship
between extrema and stationary points.
i) Having an extremum point for f does not mean f is diÔ¨Äerentiable at it, nor
that the point is stationary. This is exactly what happens to f(x) = ‚à•x‚à•of Ex-
ample 5.23 i): the origin is an absolute minimum, but f does not admit partial
derivatives there. In fact f behaves, along each direction, as the absolute value,
for f(0, . . . , 0, x, 0, . . . , 0) = |x|.
ii) For maps that are diÔ¨Äerentiable on the whole domain, Fermat‚Äôs Theorem
provides a necessary condition for an extremum point; this means extremum points
are to be found among stationary points.
iii) That said, not all stationary points are extrema. Consider f(x, y) = x3y3: the
origin is stationary, yet neither a maximum nor a minimum point. This map is
zero along the axes in fact, positive in the Ô¨Årst and third quadrants, negative in
the others.
Taking all this into consideration, it makes sense to search for suÔ¨Écient con-
ditions ensuring a stationary point x0 is an extremum point. Apropos which, the
Hessian matrix Hf(x0) is useful when the function f is at least C2 around x0. With
these assumptions and the fact that x0 is stationary, we have Taylor‚Äôs expansion
(5.16)
f(x) ‚àíf(x0) = Q(x ‚àíx0) + o(‚à•x ‚àíx0‚à•2) ,
x ‚Üíx0 ,
(5.17)
where Q(v) = 1
2v ¬∑ Hf(x0)v is the quadratic form associated to the symmetric
matrix Hf(x0) (see Sect. 4.2).
Now we do have a suÔ¨Écient condition for a stationary point to be extremal.
Theorem 5.27 Let f be C2 on some neighbourhood of x0, a stationary point
for f. Then
i) if x0 is a minimum (respectively, maximum) point for f, Hf(x0) is pos-
itive (negative) semi-deÔ¨Ånite;
ii) if Hf(x0) is positive (negative) deÔ¨Ånite, the point x0 is a local strict min-
imum (maximum) for f.
Proof.
i) To Ô¨Åx ideas let us suppose x0 is a local minimum for f, and Br(x0) is a
neighbourhood of x0 where f(x) ‚â•f(x0). Choosing an arbitrary v ‚ààRn,
let x = x0 + Œµv with Œµ > 0 small enough so that x ‚ààBr(x0). From (5.17),
Q(x ‚àíx0) + o(‚à•x ‚àíx0‚à•2) ‚â•0 ,
x ‚Üíx0 .
But Q(x‚àíx0) = Q(Œµv) = Œµ2Q(v), and o(‚à•x‚àíx0‚à•2) = o(Œµ2‚à•v‚à•2) = Œµ2o(1)
as Œµ ‚Üí0+. Therefore
Œµ2Q(v) + Œµ2o(1) ‚â•0 ,
Œµ ‚Üí0+ ,

5.6 Extremal points of a function; stationary points
177
i.e.,
Q(v) + o(1) ‚â•0 ,
Œµ ‚Üí0+ .
Taking the limit Œµ ‚Üí0+ and noting Q(v) does not depend on Œµ, we get
Q(v) ‚â•0. But as v is arbitrary, Hf(x0) is positive semi-deÔ¨Ånite.
ii) Let Hf(x0) be positive deÔ¨Ånite. Then Q(v) ‚â•Œ±‚à•v‚à•2 for any v ‚ààRn,
where Œ± = Œª‚àó/2 and Œª‚àó> 0 denotes the smallest eigenvalue of Hf(x0)
(see (4.18)). By (5.17),
f(x) ‚àíf(x0) ‚â•Œ±‚à•x ‚àíx0‚à•2 + ‚à•x ‚àíx0‚à•2o(1)
=

Œ± + o(1)

‚à•x ‚àíx0‚à•2 ,
x ‚Üíx0 .
On a neighbourhood Br(x0) of suÔ¨Éciently small radius, Œ±+o(1) > 0 hence
f(x) ‚â•f(x0).
2
As corollary of the theorem, on a neighbourhood of a minimum point x0 for
f, where Hf(x0) is positive deÔ¨Ånite, the graph of f is well approximated by the
quadratic map g(x) = f(x0) + Q(x ‚àíx0), an elliptic paraboloid in dimension 2.
Furthermore, the level sets are approximated by the level sets of Q(x ‚àíx0); as we
recalled in Sect. 4.2, these are ellipses (in dimension 2) or ellipsoids (in dimension
3) centred at x0.
Remark 5.28 One could prove that if f is C2 on its domain and Hf(x) every-
where positive (or negative) deÔ¨Ånite, then f admits at most one stationary point
x0, which is also a global minimum (maximum) for f.
2
Examples 5.29
i) Consider
f(x, y) = 2xe‚àí(x2+y2)
on R2 and compute
‚àÇf
‚àÇx(x, y) = 2(1 ‚àí2x2)e‚àí(x2+y2) ,
‚àÇf
‚àÇy (x, y) = ‚àí4xye‚àí(x2+y2) .
The zeroes of these expressions are the stationary points x1 =
 ‚àö
2
2 , 0

and
x2 =

‚àí
‚àö
2
2 , 0

. Moreover,
‚àÇ2f
‚àÇx2 (x, y) = 4x(2x2 ‚àí3)e‚àí(x2+y2) ,
‚àÇ2f
‚àÇx‚àÇy(x, y) = ‚àÇ2f
‚àÇy‚àÇx(x, y) = 4y(2x2 ‚àí1)e‚àí(x2+y2) ,
‚àÇ2f
‚àÇy2 (x, y) = 4x(2y2 ‚àí1)e‚àí(x2+y2) ,
so
Hf
‚àö
2
2 , 0

=
	 ‚àí4
‚àö
2e‚àí1/2
0
0
‚àí2
‚àö
2e‚àí1/2


178
5 DiÔ¨Äerential calculus for scalar functions
 
 
 
 
x
y
z
x
y
Figure 5.7. Graph and level curves of f(x, y) = 2xe‚àí(x2+y2)
and
Hf

‚àí
‚àö
2
2 , 0

=

4
‚àö
2e‚àí1/2
0
0
2
‚àö
2e‚àí1/2

.
The Hessian matrices are diagonal, whence Hf(x1) is negative deÔ¨Ånite while
Hf(x2) positive deÔ¨Ånite. In summary, x1 and x2 are local extrema (a local
maximum and a local minimum, respectively). Fig. 5.7 shows the graph and the
level curves of f.
ii) The function
f(x, y, z) = 1
x + y2 + 1
z + xz
is deÔ¨Åned on dom f = {(x, y, z) ‚ààR3 : x Ã∏= 0 and z Ã∏= 0} . As
‚àáf(x, y, z) =
	
‚àí1
x2 + z, 2y, ‚àí1
z2 + x

,
imposing ‚àáf(x, y, z) = 0 produces only one stationary point x0 = (1, 0, 1). Then
Hf(x, y, z) =
‚éõ
‚éú
‚éù
2/x3
0
1
0
2
0
1
0
2/z3
‚éû
‚éü
‚é†,
whence
Hf(1, 0, 1) =
‚éõ
‚éú
‚éú
‚éù
2
0
1
0
2
0
1
0
2
‚éû
‚éü
‚éü
‚é†.
The characteristic equation of A = Hf(1, 0, 1) reads
det(A ‚àíŒªI) = (2 ‚àíŒª)

(2 ‚àíŒª)2 ‚àí1

= 0 ,
solved by Œª1 = 1, Œª2 = 2, Œª3 = 3. Therefore the Hessian at x0 is positive deÔ¨Ånite,
making x0 a local minimum point.
2
5.6.1 Saddle points
Recalling what an indeÔ¨Ånite matrix is (see Sect. 4.2), statement i) of Theorem 5.27
may be formulated in the following equivalent way.

5.6 Extremal points of a function; stationary points
179
Proposition 5.30 Let f be of class C2 around a stationary point x0. If
Hf(x0) is indeÔ¨Ånite, x0 is not an extremum point.
A stationary point x0 for f such that Hf(x0) is indeÔ¨Ånite is called a saddle
point. The name stems from the shape of the graph in the following example
around x0.
Example 5.31
Consider f(x, y) = x2 ‚àíy2: as ‚àáf(x, y) = (2x, ‚àí2y), there is only one stationary
point, the origin. The Hessian matrix
Hf(x, y) =
	 2
0
0
‚àí2

is independent of the point, hence indeÔ¨Ånite. Therefore the origin is a saddle
point.
It is convenient to consider in more detail the behaviour of f around such a
point. Moving along the x-axis, the map f(x, 0) = x2 has a minimum at the
origin. Along the y-axis, by contrast, the function f(0, y) = ‚àíy2 has a maximum
at the origin:
f(0, 0) = min
x‚ààR f(x, 0) = max
x‚ààR f(0, y) .
Level curves and the graph (from two viewpoints) of the function f are shown
in Fig. 5.8 and 5.9.
2
The kind of behaviour just described is typical of stationary points at which
the Hessian matrix is indeÔ¨Ånite and non-singular (the eigenvalues are non-zero and
have diÔ¨Äerent signs). Let us see more examples.
x
y
Figure 5.8. Level curves of f(x, y) = x2 ‚àíy2

180
5 DiÔ¨Äerential calculus for scalar functions
 
 
 
 
 
 
 
 
x
y
z
 
 
 
 
 
 
 
 
x
y
z
Figure 5.9. Graphical view of the function f(x, y) = x2 ‚àíy2 from diÔ¨Äerent angles
Examples 5.32
i) For the map f(x, y) = xy we have
‚àáf(x, y) = (y, x)
and
Hf(x, y) =

0
1
1
0

.
As before, x0 = (0, 0) is a saddle point, because the eigenvalues of the Hessian are
Œª1 = 1 and Œª2 = ‚àí1. Moving along the bisectrix of the Ô¨Årst and third quadrant,
f has a minimum at x0, while along the orthogonal bisectrix f has a maximum
at x0:
f(0, 0) = min
x‚ààR f(x, x) = max
x‚ààR f(x, ‚àíx) .
The directions of these lines are those of the eigenvectors w1 = (1, 1), w2 =
(‚àí1, 1) associated to the eigenvalues Œª1, Œª2.
Changing variables x = u ‚àív, y = u + v (corresponding to a rotation of œÄ/4 in
the plane, see Sect. 6.6 and Example 6.31 in particular), f becomes
f(x, y) = (u ‚àív)(u + v) = u2 ‚àív2 = Àúf(u, v) ,
the same as in the previous example in the new variables u, v.
ii) The function f(x, y, z) = x2+y2‚àíz2 has gradient ‚àáf(x, y, z) = (2x, 2y, ‚àí2z),
with unique stationary point the origin. The matrix
Hf(x, y, z) =
‚éõ
‚éú
‚éù
2
0
0
0
2
0
0
0
‚àí2
‚éû
‚éü
‚é†
is indeÔ¨Ånite, and the origin is a saddle point.

5.6 Extremal points of a function; stationary points
181
A closer look uncovers the hidden structure of the saddle point. Moving on the
xy-plane, we see that the origin is a minimum point for f(x, y, 0) = x2 + y2. At
the same time, along the z-axis the origin is a maximum for f(0, 0, z) = ‚àíz2.
Thus
f(0, 0, 0) =
min
(x,y)‚ààR2 f(x, y, 0) = max
z‚ààR f(0, 0, z) .
iii) A slightly more elaborate situation is provided by the function f(x, y, z) =
x2 + y3 ‚àíz2. Since ‚àáf(x, y, z) = (2x, 3y2, ‚àí2z) the origin is again stationary.
The Hessian
Hf(0, 0, 0) =
‚éõ
‚éú
‚éù
2
0
0
0
0
0
0
0
‚àí2
‚éû
‚éü
‚é†
is indeÔ¨Ånite, making the origin a saddle point. More precisely, (0, 0, 0) is a min-
imum if we move along the x-axis, a maximum along the z-axis, but on the y-axis
we have an inÔ¨Çection point.
2
The notion of saddle points can be generalised to subsume stationary points
where the Hessian matrix is (positive or negative) semi-deÔ¨Ånite. In such a case, the
mere knowledge of Hf(x0) is not suÔ¨Écient to determine the nature of the point.
In order to have a genuine saddle point x0 one must additionally require that there
exist a direction along which f has a maximum point at x0 and a direction along
which f has a minimum at x0. Precisely, there should be vectors v1, v2 such that
the maps t ‚Üíf(x0 + tvi), i = 1, 2, have a strict minimum and a strict maximum
point respectively, for t = 0.
As an example take f(x, y) = x2 ‚àíy4. The origin is stationary, and the Hessian
at that point is Hf(0, 0) =

2
0
0
0

, hence positive semi-deÔ¨Ånite. Since f(x, 0) =
x2 has a minimum at x = 0 and f(0, y) = ‚àíy4 has a maximum at y = 0, the above
requirement holds by taking v1 = i = (1, 0), v2 = j = (0, 1). We still call x0 a
saddle point.
Consider now f(x, y) = x2‚àíy3, for which the origin is stationary the Hessian is
the same as in the previous case. Despite this, for any m ‚ààR the map f(x, mx) =
x2 ‚àím3x3 has a minimum at x = 0, and f(0, y) = ‚àíy3 has an inÔ¨Çection point at
y = 0. Therefore no vector v2 exists that maximises t ‚Üíf(tv2) at t = 0. For this
reason x0 = 0 will not be called a saddle point.
We note that if x0 is stationary and Hf(x0) is positive semi-deÔ¨Ånite, then every
eigenvector w associated to an eigenvalue Œª > 0 ensures that t ‚Üíf(x0 + tw) has
a strict minimum point at t = 0 (whence w can be chosen as vector v1); in fact,
(5.17) gives
f(x0 + tw) = f(x0) + 1
2Œª‚à•w‚à•2t2 + o(t2) ,
t ‚Üí0 .

182
5 DiÔ¨Äerential calculus for scalar functions
Then x0 is a saddle point if and only if we can Ô¨Ånd a vector v2 in the kernel of
the matrix Hf(x0) such that t ‚Üíf(x0 + tv2) has a strict maximum at t = 0.
Similarly when Hf(x0) is negative semi-deÔ¨Ånite.
To conclude the chapter, we wish to provide the reader with a simple procedure
for classifying stationary points in two variables. The whole point is to determine
the eigenvalues‚Äô sign in the Hessian matrix, which can be done without eÔ¨Äort for
2 √ó 2 matrices. If A is a symmetric matrix of order 2, the determinant is the
product of the two eigenvalues. Therefore if det A > 0 the eigenvalues have the
same sign and A is deÔ¨Ånite, positive or negative according to the sign of either
diagonal term a11 or a22. If det A < 0, the eigenvalues have diÔ¨Äerent sign, making
A indeÔ¨Ånite. If det A = 0, the matrix is semi-deÔ¨Ånite, not deÔ¨Ånite.
Recycling this discussion with the Hessian Hf(x0) of a stationary point, and
bearing in mind Theorem 5.27, gives
det Hf(x0) > 0 ‚áí
!
x0 strict local minimum point, if fxx(x0) > 0
x0 strict local maximum point, if fxx(x0) < 0
det Hf(x0) < 0 ‚áíx0 saddle point
det Hf(x0) = 0 ‚áíthe nature of x0 cannot be determined by Hf(x0) only .
In the Ô¨Årst case det Hf(x0) > 0, the dichotomy maximum vs. minimum may be
sorted out by the sign of fyy(x0), which is also the sign of fxx(x0).
Example 5.33
The Ô¨Årst derivatives of f(x, y) = 2xy + e‚àí(x+y)2 are
fx(x, y) = 2

y ‚àí(x + y) e‚àí(x+y)2
,
fy(x, y) = 2

x ‚àí(x + y) e‚àí(x+y)2
,
and the second derivatives read
fxx(x, y) = fyy(x, y) = ‚àí2e‚àí(x+y)2
1 ‚àí2(x + y)2
,
fxy(x, y) = fxy(x, y) = 2 ‚àí2e‚àí(x+y)2
1 ‚àí2(x + y)2
.
There are three stationary points
x0 = (0, 0) ,
x1 =
1
2

log 2, 1
2

log 2

,
x2 = ‚àíx1 ,
and correspondingly,
Hf(x0) =
	
‚àí2
0
0
‚àí2

,
Hf(x1) = Hf(x2) =
	
1 ‚àí2 log 2
1 + 2 log 2
1 + 2 log 2
1 ‚àí2 log 2

.
Therefore x0 is a maximum point, for Hf(x0) is negative deÔ¨Ånite, while x1 and
x2 are saddle points since det Hf(x1) = det Hf(x2) = ‚àí8 log 2 < 0.
2

5.7 Exercises
183
5.7 Exercises
1. Compute the Ô¨Årst partial derivatives at the points indicated:
a)
f(x, y) =

3x + y2
at (x0, y0) = (1, 2)
b)
f(x, y, z) = yex+yz
at (x0, y0, z0) = (0, 1, ‚àí1)
c)
f(x, y) = 8x2 +
 y
1
e‚àít2 dt
at (x0, y0) = (3, 1)
2. Compute the Ô¨Årst partial derivatives of:
a)
f(x, y) = log(x +

x2 + y2)
b)
f(x, y) =
 y
x
cos t2 dt
c)
f(x, y, z, t) = x ‚àíy
z ‚àít
d)
f(x1, . . . , xn) = sin(x1 + 2x2 + . . . + nxn)
3. Compute the partial derivative indicated:
a) f(x, y) = x3y2 ‚àí3xy4 ,
fyyy
b) f(x, y) = x sin y ,
‚àÇ3f
‚àÇx‚àÇy2
c) f(x, y, z) = exyz ,
fxyx
d) f(x, y, z) = xaybzc ,
‚àÇ6f
‚àÇx‚àÇy2‚àÇz3
4. Determine which maps f satisfy fxx + fyy = 0, known as Laplace equation:
a)
f(x, y) = x2 + y2
b)
f(x, y) = x3 + 3xy2
c)
f(x, y) = log

x2 + y2
d)
f(x, y) = e‚àíx cos y ‚àíe‚àíy cos x
5.
Check that f(x, t) = e‚àít sin kx satisÔ¨Åes the so-called heat equation ft = 1
k2 fxx.
6. Check that the following maps solve ftt = fxx, known as wave equation:
a)
f(x, t) = sin x sin t
b)
f(x, t) = sin(x ‚àít) + log(x + t)

184
5 DiÔ¨Äerential calculus for scalar functions
7.
Given
f(x, y) =
‚éß
‚é®
‚é©
x3y ‚àíxy3
x2 + y2
if (x, y) Ã∏= (0, 0) ,
0
if (x, y) = (0, 0) ,
a) compute fx(x, y) and fy(x, y) for any (x, y) Ã∏= (0, 0);
b) calculate fx(0, 0), fy(0, 0) using the deÔ¨Ånition of second partial derivative;
c) discuss the results obtained in the light of Schwarz‚Äôs Theorem 5.17.
8. Determine the gradient map of:
a) f(x, y) = arctan x + y
x ‚àíy
b) f(x, y) = (x + y) log(2x ‚àíy)
c) f(x, y, z) = sin(x + y) cos(y ‚àíz)
d) f(x, y, z) = (x + y)z
9. Compute the directional derivatives along v, at the indicated points:
a) f(x, y) = x

y ‚àí3
v = (‚àí1, 6)
x0 = (2, 12)
b) f(x, y, z) =
1
x + 2y ‚àí3z
v = (12, ‚àí9, ‚àí4)
x0 = (1, 1, ‚àí1)
10. Determine the tangent plane to the graph of f(x, y) at the point P0 =

x0, y0, f(x0, y0)

:
a)
f(x, y) = 3x2 ‚àíy2 + 3y
at P0 = (‚àí1, 2, f(‚àí1, 2))
b)
f(x, y) = ey2‚àíx2
at P0 = (‚àí1, 1, f(‚àí1, 1))
c)
f(x, y) = x log y
at P0 = (4, 1, f(4, 1))
11. Relying on the deÔ¨Ånition, check the maps below are diÔ¨Äerentiable at the given
point:
a)
f(x, y) = y‚àöx
at (x0, y0) = (4, 1)
b)
f(x, y) = |y| log(1 + x)
at (x0, y0) = (0, 0)
c)
f(x, y) = xy ‚àí3x2
at (x0, y0) = (1, 2)
12.
Given
f(x, y) =
‚éß
‚é®
‚é©
xy
x2 + y2
if (x, y) Ã∏= (0, 0) ,
0
if (x, y) = (0, 0) ,
compute fx(0, 0) and fy(0, 0). Is f diÔ¨Äerentiable at the origin?

5.7 Exercises
185
13. Study the diÔ¨Äerentiability at (0, 0) of
f(x, y) =
‚éß
‚é®
‚é©
x2y3
x4 + y4
if (x, y) Ã∏= (0, 0) ,
0
if (x, y) = (0, 0) .
14.
Discuss the diÔ¨Äerentiability of
f(x, y) = |x| sin(x2 + y2)
at any point of the plane.
15. Study continuity and diÔ¨Äerentiability at the origin of
f(x, y) =
 |y|Œ± sin x
if y Ã∏= 0 ,
0
if y = 0
as Œ± varies in the reals.
16.
Study the diÔ¨Äerentiability at (0, 0, 0) of
f(x, y, z) =
‚éß
‚é®
‚é©
(x2 + y2 + z2) sin
1

x2 + y2 + z2
if (x, y, z) Ã∏= (0, 0, 0) ,
0
if (x, y, z) = (0, 0, 0) .
17.
Given f(x, y) = x2 + 3xy ‚àíy2, Ô¨Ånd its diÔ¨Äerential at (x0, y0) = (2, 3). If x
varies between 2 and 2.05, and y between 3 and 2.96, compare the increment
Œîf with the corresponding diÔ¨Äerential df(x0,y0).
18. Determine the diÔ¨Äerential at a generic point (x0, y0) of the functions:
a)
f(x, y) = ex cos y
b) f(x, y) = x sin xy
c)
f(x, y, z) = log(x2 + y2 + z2)
d) f(x, y, z) =
x
y + 2z
19.
Find the diÔ¨Äerential of f(x, y, z) = x3
y2 + z2 at (2, 3, 4) and then use it to
approximate the number 1.983 ‚àö
3.012 + 3.972.
20.
Tell whether
f(x, y) =
1
x + y + 1
is Lipschitz over the rectangle R = [0, 2] √ó [0, 1]; if yes compute the Lipschitz
constant.

186
5 DiÔ¨Äerential calculus for scalar functions
21. Determine if, how and where in R3 is
f(x, y, z) = e‚àí(3x2+2y4+z6)
a Lipschitz map.
22. Write the Taylor polynomial of order two for the following functions at the
point given:
a)
f(x, y) = cos x cos y
at (x0, y0) = (0, 0)
b)
f(x, y, z) = ex+y+z
at (x0, y0, z0) = (1, 1, 1)
c)
f(x, y, z) = cos(x + 2y ‚àí3z)
at (x0, y0, z0) = (0, 0, 1)
23. Determine the stationary points (if existent), specifying their nature:
a)
f(x, y) = x2y + x2 ‚àí2y
b)
f(x, y) = y log(x + y)
c)
f(x, y) = x + 1
6x6 + y2(y2 ‚àí1)
d)
f(x, y) = xye‚àíx
5 ‚àíy
6
e)
f(x, y) = x
y + 8
x ‚àíy
f)
f(x, y) = 2y log(2 ‚àíx2) + y2
g)
f(x, y) = e3x2‚àí6xy+2y3
h)
f(x, y) = y log x
i)
f(x, y) = log(x2 + y2 ‚àí1)
‚Ñì)
f(x, y, z) = xyz + 1
x + 1
y
1
z
24.
Determine and draw the domain of
f(x, y) =

y2 ‚àíx2 .
Find stationary points and extrema.
25.
Determine domain and stationary points of
f(x, y) = x2 log(1 + y) + x2y2 .
What is their nature?
5.7.1 Solutions
1. Partial derivatives of maps:
a)
‚àÇf
‚àÇx(1, 2) =
3
2
‚àö
7 ,
‚àÇf
‚àÇy (1, 2) =
2
‚àö
7 .

5.7 Exercises
187
b)
‚àÇf
‚àÇx(0, 1, ‚àí1) = e‚àí1 ,
‚àÇf
‚àÇy (0, 1, ‚àí1) = 0 ,
‚àÇf
‚àÇz (0, 1, ‚àí1) = e‚àí1 .
c) We have
‚àÇf
‚àÇx(x, y) = 16x
and
‚àÇf
‚àÇy (x, y) = e‚àíy2 ,
the latter computed by means of the Fundamental Theorem of Integral Cal-
culus. Thus
‚àÇf
‚àÇx(3, 1) = 48
and
‚àÇf
‚àÇy (3, 1) = e‚àí1 .
2. Partial derivatives:
a) We have
fx(x, y) =
1

x2 + y2 ,
fx(x, y) =
1
x +

x2 + y2 ¬∑
y

x2 + y2 .
b) Using the Fundamental Theorem of Integral Calculus we have
fx(x, y) = ‚àí‚àÇ
‚àÇx
 x
y
cos t2 dt = ‚àícos x2 ,
fy(x, y) = ‚àÇ
‚àÇy
 y
x
cos t2 dt = cos y2 .
c) We have
fx(x, y, z, t) =
1
z ‚àít ,
fy(x, y, z, t) =
1
t ‚àíz ,
fz(x, y, z, t) =
y ‚àíx
(z ‚àít)2 ,
ft(x, y, z, t) =
x ‚àíy
(z ‚àít)2 .
d) We have
‚àÇf
‚àÇx1
(x1, . . . , xn) = cos(x1 + 2x2 + . . . + nxn) ,
‚àÇf
‚àÇx2
(x1, . . . , xn) = 2 cos(x1 + 2x2 + . . . + nxn) ,
...
‚àÇf
‚àÇxn
(x1, . . . , xn) = n cos(x1 + 2x2 + . . . + nxn) , .
3. Partial derivatives:
a)
fyyy = ‚àí72xy .
b) fyyx = ‚àísin y .
c) fxyx = yz2exyz(2 + xyz) .
d)
fzzzyyx = abc(b ‚àí1)(c ‚àí1)(c ‚àí2)xa‚àí1yb‚àí2zc‚àí3 .

188
5 DiÔ¨Äerential calculus for scalar functions
4. Solutions of the Laplace equation:
a) No.
b) No.
c) Since f(x, y) = 1
2 log(x2 + y2),
fx =
x
x2 + y2 ,
fxx =
y2 ‚àíx2
(x2 + y2)2 ,
fy =
y
x2 + y2 ,
fyy =
x2 ‚àíy2
(x2 + y2)2 ,
hence fxx + fyy = 0 , ‚àÄx, y Ã∏= 0. Therefore the function is a solution of the
Laplace equation on R2 \ {0}.
d) Since
fx = ‚àíe‚àíx cos y + e‚àíy sin x ,
fxx = e‚àíx cos y + e‚àíy cos x ,
fy = ‚àíe‚àíx sin y + e‚àíy cos x ,
fyy = ‚àíe‚àíx cos y ‚àíe‚àíy cos x ,
we have fxx + fyy = 0 , ‚àÄ(x, y) ‚ààR2, and the function satisÔ¨Åes Laplace‚Äôs
equation on R2.
5. The assertion follows from
ft = ‚àíe‚àít sin kx ,
fx = ke‚àít cos kx ,
fxx = ‚àík2e‚àít sin kx .
6. Solutions of the wave equation:
a) From
fx = cos x sin t ,
fxx = ‚àísin x sin t ,
ft = sin x cos t ,
ftt = ‚àísin x sin t
follows fxx = ftt , ‚àÄ(x, t) ‚ààR2.
b) As
fx = cos(x ‚àít) +
1
x + t ,
fxx = ‚àísin(x ‚àít) ‚àí
1
(x + t)2 ,
ft = ‚àícos(x ‚àít) +
1
x + t ,
ftt = ‚àísin(x ‚àít) ‚àí
1
(x + t)2 ,
we have fxx = ftt , ‚àÄ(x, t) ‚ààR2 such that x + t > 0.
7. a) Using the usual rules, for (x, y) Ã∏= (0, 0) we have
fx(x, y) = (3x2y ‚àíy3)(x2 + y2) ‚àí2x(x3y ‚àíxy3)
(x2 + y2)2
= y(x4 + 4x2y2 ‚àíy4)
(x2 + y2)2
,
fy(x, y) = (x3 ‚àí3xy2)(x2 + y2) ‚àí2y(x3y ‚àíxy3)
(x2 + y2)2
= x(x4 ‚àí4x2y2 ‚àíy4)
(x2 + y2)2
.

5.7 Exercises
189
b) To compute fx(0, 0) and fy(0, 0) let us resort to the deÔ¨Ånition:
fx(0, 0) = lim
x‚Üí0
f(x, 0) ‚àíf(0, 0)
x
= lim
x‚Üí0 0 = 0 ,
fy(0, 0) = lim
y‚Üí0
f(0, y) ‚àíf(0, 0)
y
= lim
y‚Üí0 0 = 0 .
Moreover,
fxy(0, 0) = ‚àÇ2f
‚àÇy‚àÇx(0, 0) = lim
y‚Üí0
fx(0, y) ‚àífx(0, 0)
y
= lim
y‚Üí0 ‚àíy5
y5 = ‚àí1 ,
fyx(0, 0) = ‚àÇ2f
‚àÇx‚àÇy(0, 0) = lim
x‚Üí0
fy(x, 0) ‚àífy(0, 0)
x
= lim
x‚Üí0
x5
x5 = 1 .
c) Schwarz‚Äôs Theorem 5.17 does not apply, as the partial derivatives fxy, fyx are
not continuous at (0, 0) (polar coordinates show that the limits
lim
(x,y)‚Üí(0,0) fxy(x, y)
and
lim
(x,y)‚Üí(0,0) fyx(x, y) do not exist).
8. Gradients:
a)
‚àáf(x, y) =
	
‚àí
y
x2 + y2 ,
x
x2 + y2

.
b)
‚àáf(x, y) =
	
log(2x ‚àíy) + 2(x + y)
2x ‚àíy , log(2x ‚àíy) ‚àíx + y
2x ‚àíy

.
c)
‚àáf(x, y, z) =

cos(x + y) cos(y ‚àíz) , cos(x + 2y ‚àíz) , sin(x + y) sin(y ‚àíz)

.
d)
‚àáf(x, y, z) =

z(x + y)z‚àí1 , z(x + y)z‚àí1 , (x + y)z log(x + y)

.
9. Directional derivatives:
a)
‚àÇf
‚àÇv (x0) = ‚àí1 .
b) ‚àÇf
‚àÇv (x0) = ‚àí1
6 .
10. Tangent planes:
a) z = ‚àí6x ‚àíy + 1 .
b) By (5.7), we compute
fx(x, y) = ‚àí2xey2‚àíx2 ,
fy(x, y) = 2yey2‚àíx2 ,
f(‚àí1, 1) = 1 ,
fx(‚àí1, 1) = 2 ,
fy(‚àí1, 1) = 2 .
The equation is thus
z = f(‚àí1, 1) + fx(‚àí1, 1)(x + 1) + fy(‚àí1, 1)(y ‚àí1) = 2x + 2y + 1 .
c) z = 4y ‚àí4 .

190
5 DiÔ¨Äerential calculus for scalar functions
11. Checking diÔ¨Äerentiability:
a) From fx(x, y) =
y
2‚àöx and fy(x, y) = ‚àöx follows
f(4, 1) = 2 ,
fx(4, 1) = 1
4 ,
fy(4, 1) = 2 .
Then f is diÔ¨Äerentiable at (4, 1) if and only if
lim
(x,y)‚Üí(4,1)
f(x, y) ‚àíf(4, 1) ‚àífx(4, 1)(x ‚àí4) ‚àífy(4, 1)(y ‚àí1)

(x ‚àí4)2 + (y ‚àí1)2
= 0
i.e.,
L =
lim
(x,y)‚Üí(4,1)
y‚àöx ‚àí2 ‚àí1
4(x ‚àí4) ‚àí2(y ‚àí1)

(x ‚àí4)2 + (y ‚àí1)2
= 0 .
Put x = 4 + r cos Œ∏ e y = 1 + r sin Œ∏ and observe that for r ‚Üí0,
‚àö
4 + r cos Œ∏ = 2

1 + r
4 cos Œ∏ = 2

1 + r
8 cosŒ∏ + o(r)

,
so that
y‚àöx ‚àí2 ‚àí1
4(x ‚àí4) ‚àí2(y ‚àí1) = 2(1 + r sin Œ∏)

1 + r
8 cos Œ∏ + o(r)

+
‚àí2 ‚àí1
4r cos Œ∏ ‚àí2r sin Œ∏ = o(r) ,
r ‚Üí0 .
Hence
L = lim
r‚Üí0
o(r)
r
= lim
r‚Üí0 o(1) = 0 .
b) Note f(x, 0) = f(0, y) = 0, so fx(0, 0) = fy(0, 0) = 0. DiÔ¨Äerentiability at the
origin is the same as proving
lim
(x,y)‚Üí(0,0)
f(x, y) ‚àíf(0, 0) ‚àí‚àáf(0, 0) ¬∑ (x, y)

x2 + y2
= 0 ,
i.e., given that f(0, 0) = 0,
lim
(x,y)‚Üí(0,0)
|y| log(1 + x)

x2 + y2
= 0 .
Polar coordinates come to the rescue:

y log(1 + x)

x2 + y2
 = r| sin Œ∏ log(1 + r cos Œ∏)|
r
‚â§2r| sin Œ∏ cos Œ∏| ‚â§2r ;
Proposition 4.28 with g(r) = 2r allows to conclude.

5.7 Exercises
191
c) We have f(1, 2) = ‚àí1, fx(1, 2) = ‚àí4 and fy(1, 2) = 1; f is diÔ¨Äerentiable at
(1, 2) precisely when
L =
lim
(x,y)‚Üí(1,2)
xy ‚àí3x2 + 1 + 4(x ‚àí1) ‚àí(y ‚àí2)

(x ‚àí1)2 + (y ‚àí2)2
= 0 .
Setting x = 1 + r cos Œ∏ , y = 2 + r sin Œ∏ and computing,
L = lim
r‚Üí0 r cos Œ∏(sin Œ∏ ‚àí3 cos Œ∏).
The limit is zero by Proposition 4.28 with g(r) = 4r.
12. Observe f(x, 0) = f(0, y) = 0, so
fx(0, 0) = lim
x‚Üí0
f(x, 0) ‚àíf(0, 0)
x
= lim
x‚Üí0 0 = 0 ,
fy(0, 0) = lim
y‚Üí0
f(0, y) ‚àíf(0, 0)
y
= lim
y‚Üí0 0 = 0 .
The map is certainly not diÔ¨Äerentiable at the origin because it is not even con-
tinuous; in fact
lim
(x,y)‚Üí(0,0)f(x, y) does not exist, as one sees taking the limit along
the coordinate axes,
lim
x‚Üí0 f(x, 0) = lim
y‚Üí0 f(0, y) = 0 ,
and then along the line y = x,
lim
x‚Üí0 f(x, x) = 1
2 .
13. The function is not diÔ¨Äerentiable.
14. The map is certainly diÔ¨Äerentiable at all points (x, y) ‚ààR2 with x Ã∏= 0, by
Proposition 5.8. To study the points on the axis, let us Ô¨Åx (0, y0) and compute the
derivatives. No problems arise with fy since
fy(x, y) = 2|x|y sin(x2 + y2) ,
‚àÄ(x, y) ‚ààR2 ,
and fy(0, y0) = 0. As far as fx is concerned,
lim
x‚Üí0
f(x, y0) ‚àíf(0, y0)
x
= lim
x‚Üí0
|x| sin(x2 + y2
0)
x
.
If y0 = ¬±‚àönœÄ, with n ‚ààN, we have
fx(0, ¬±‚àönœÄ) = lim
x‚Üí0
|x|
x (‚àí1)n sin x2 = 0 ,

192
5 DiÔ¨Äerential calculus for scalar functions
otherwise
lim
x‚Üí0+
|x|
x sin(x2 + y2
0) = sin y2
0 ,
while
lim
x‚Üí0‚àí
|x|
x sin(x2 + y2
0) = ‚àísin y2
0 .
Thus fx(0, y0) exists only for y0 = ¬±‚àönœÄ, where f is continuous and therefore
diÔ¨Äerentiable.
15. The map is continuous if Œ± ‚â•0; it is diÔ¨Äerentiable if Œ± > 0.
16. Observe f(x, 0, 0) = x2 sin 1
|x|, hence fx(0, 0, 0) = 0, since
fx(0, 0, 0) = lim
x‚Üí0
f(x, 0, 0) ‚àíf(0, 0, 0)
x
= lim
x‚Üí0 x sin 1
|x| = 0 .
Similarly, fy(0, 0, 0) = fz(0, 0, 0) = 0. For diÔ¨Äerentiability at the origin we consider
lim
(x,y,z)‚Üí(0,0,0)
f(x, y, z)

x2 + y2 + z2 =
lim
(x,y,z)‚Üí(0,0,0)

x2 + y2 + z2 sin
1

x2 + y2 + z2 .
The limit is zero by the Squeeze rule:
0 ‚â§


x2 + y2 + z2 sin
1

x2 + y2 + z2
 ‚â§

x2 + y2 + z2 ,
for all (x, y, z) Ã∏= (0, 0, 0).
17. Since fx(x, y) = 2x + 3y , fy(x, y) = 3x ‚àí2y we have
df(2,3)(Œîx,Œîy ) = ‚àáf(2, 3) ¬∑ (x ‚àí2, y ‚àí3) = 13(x ‚àí2) .
Let now Œîx = (2.05 ‚àíx0, 2.96 ‚àíy0) =
 5
100, ‚àí4
100

, so
Œîf = f(2.05, 2.96) ‚àíf(2, 3) = 0.6449
and
df(2,3)
 5
100, ‚àí4
100

= 0.65 .
18. DiÔ¨Äerentials:
a) As fx(x, y) = ex cos y and fy(x, y) = ‚àíex sin y, the diÔ¨Äerential is
df(x0,y0)(Œîx,Œîy ) = ‚àáf(x0, y0) ¬∑ (Œîx,Œîy ) = ex0 cos y0 Œîx ‚àíex0 sin y0 Œîy .
b) df(x0,y0)(Œîx,Œîy ) = (sin x0y0 + x0y0 cos x0y0) Œîx + x2
0 cos x0y0 Œîy .

5.7 Exercises
193
c) df(x0,y0,z0)(Œîx,Œî y,Œîz ) =
2x0
x2
0 + y2
0 + z2
0
Œîx +
2y0
x2
0 + y2
0 + z2
0
Œîy+
+
2z0
x2
0 + y2
0 + z2
0
Œîz .
d) df(x0,y0,z0)(Œîx,Œî y,Œîz ) =
1
y0 + 2z0
Œîx ‚àí
x0
(y0 + 2z0)2 Œîy ‚àí
2x0
(y0 + 2z0)2 Œîz .
19. From
fx(x, y, z) = 3x2
y2 + z2 ,
fy(x, y, z) =
x3y

y2 + z2 ,
fz(x, y, z) =
x3z

y2 + z2
follows
df(2,3,4)(Œîx,Œî y,Œîz ) = 60Œîx + 24
5 Œîy + 32
5 Œîz .
Set Œîx =

‚àí
2
100,
1
100, ‚àí3
100

, so that
df(2,3,4)

‚àí
2
100, 1
100, ‚àí3
100

= ‚àí1.344 .
By linearising, we may approximate 1.983 ‚àö
3.012 + 3.972 by
f(2, 3, 4) + df(2,3,4)

‚àí
2
100, 1
100, ‚àí3
100

= 40 ‚àí1.344 = 38.656 .
20. First of all
‚àÇf
‚àÇx(x, y) = ‚àÇf
‚àÇy (x, y) = ‚àí
1
(x + y + 1)2 ,
and secondly
sup
(x,y)‚ààR
‚àÇf
‚àÇx(x, y)
 =
sup
(x,y)‚ààR
‚àÇf
‚àÇx(x, y)
 = 1 ;
Proposition 5.16 then tells us f is Lipschitz on R, with L =
‚àö
2.
21. The map is Lipschitz on the entire R3.
22. Taylor polynomials:
a) We have to Ô¨Ånd the Taylor polynomial for f at x0 of order 2
T f2,x0(x) = f(x0) + ‚àáf(x0) ¬∑ (x ‚àíx0) + 1
2(x ‚àíx0) ¬∑ Hf(x0)(x ‚àíx0) .
Let us begin by computing the partial derivatives involved:
fx(x, y) = ‚àísin x cos y
so fx(0, 0) = 0
fy(x, y) = ‚àícosx sin y
so fy(0, 0) = 0
fxx(x, y) = ‚àícos x cos y
so fxx(0, 0) = ‚àí1
fyy(x, y) = ‚àícosx cos y
so fyy(0, 0) = ‚àí1
fxy(x, y) = fyx(x, y) = sin x sin y
so fxy(0, 0) = fyx(0, 0) = 0

194
5 DiÔ¨Äerential calculus for scalar functions
As f(0, 0) = 1,
T f2,(0,0)(x, y) = 1 + 1
2(x, y) ¬∑

‚àí1
0
0
‚àí1

¬∑

x
y

= 1 + 1
2(x, y) ¬∑ (‚àíx, ‚àíy) = 1 ‚àí1
2x2 ‚àí1
2y2 .
Alternatively, we might want to recall that, for x ‚Üí0 and y ‚Üí0,
cos x = 1 ‚àí1
2x2 + o(x2) ,
cos y = 1 ‚àí1
2y2 + o(y2) ;
which we have to multiply. As the Taylor polynomial is unique, we Ô¨Ånd imme-
diately T f2,(0,0)(x, y) = 1 ‚àí1
2x2 ‚àí1
2y2.
b) Computing directly,
T f2,(1,1,1)(x, y, z) = e3
1 + (x ‚àí1) + (y ‚àí1) + (z ‚àí1) +
+1
2

(x ‚àí1)2 + (y ‚àí1)2 + (z ‚àí1)2
+
+(x ‚àí1)(y ‚àí1) + (x ‚àí1)(z ‚àí1) + (y ‚àí1)(z ‚àí1)

.
c) We have
T f2,(0,0,1)(x, y, z) = cos 3 + sin 3

x + 2y ‚àí3(z ‚àí1)

+
+1
2 cos 3

‚àíx2 ‚àí4y2 ‚àí9(z ‚àí1)2
+
+ cos3

‚àí2xy + 6x(z ‚àí1) + 6y(z ‚àí1)

.
23. Stationary points and type:
a) From
‚àÇf
‚àÇx(x, y) = 2x(y + 1) ,
‚àÇf
‚àÇy (x, y) = x2 ‚àí2
and the condition ‚àáf(x, y) = 0 we obtain the stationary points P1 = (
‚àö
2, ‚àí1),
P2 = (‚àí
‚àö
2, ‚àí1). Since
‚àÇ2f
‚àÇx2 (x, y) = 2(y + 1) ,
‚àÇ2f
‚àÇy2 (x, y) = 0 ,
‚àÇ2f
‚àÇx‚àÇy(x, y) = ‚àÇ2f
‚àÇy‚àÇx(x, y) = 2x ,
the Hessians at those points read
Hf(P1) =

0
2
‚àö
2
2
‚àö
2
0

,
Hf(P2) =

0
‚àí2
‚àö
2
‚àí2
‚àö
2
0

.
In either case the determinant is negative, so P1, P2 are saddle points.

5.7 Exercises
195
b) The function is deÔ¨Åned for x + y > 0, i.e., on the half-plane dom f = {(x, y) ‚àà
R2 : y > ‚àíx}. As
‚àÇf
‚àÇx(x, y) =
y
x + y ,
‚àÇf
‚àÇy (x, y) = log(x + y) +
y
x + y ,
imposing ‚àáf(x, y) = 0 yields the system
‚éß
‚é™
‚é®
‚é™
‚é©
y
x + y = 0
log(x + y) +
y
x + y = 0
whose unique solution is the stationary point P = (1, 0) ‚ààdom f. We have
then
‚àÇ2f
‚àÇx2 (x, y) = ‚àí
y
(x + y)2 ,
‚àÇ2f
‚àÇy2 (x, y) =
1
x + y +
x
(x + y)2 ,
‚àÇ2f
‚àÇx‚àÇy(x, y) = ‚àÇ2f
‚àÇy‚àÇx(x, y) =
x
(x + y)2 ,
so
Hf(P) =
	 0
1
1
2

.
The Hessian determinant is ‚àí1 < 0, making P a saddle point.
c) From
‚àÇf
‚àÇx(x, y) = 1 + x5 ,
‚àÇf
‚àÇy (x, y) = 4y3 ‚àí2y
and ‚àáf(x, y) = 0 we Ô¨Ånd three stationary points
P1 = (‚àí1, 0) ,
P2 =

‚àí1,
‚àö
2
2

,
P3 =

‚àí1, ‚àí
‚àö
2
2

.
Then
‚àÇ2f
‚àÇx2 (x, y) = 5x4 ,
‚àÇ2f
‚àÇx‚àÇy(x, y) = ‚àÇ2f
‚àÇy‚àÇx(x, y) = 0 ,
‚àÇ2f
‚àÇy2 (x, y) = 12y2 ‚àí2 .
Consequently,
Hf(‚àí1, 0) =
	 5
0
0
‚àí2

,
Hf

‚àí1,
‚àö
2
2

= Hf

‚àí1, ‚àí
‚àö
2
2

=
	 5
0
0
4

.
The Hessians are diagonal; the one of P1 is indeÔ¨Ånite, so P1 is a saddle point;
the other two are positive deÔ¨Ånite, and P2, P3 are local minimum points.

196
5 DiÔ¨Äerential calculus for scalar functions
d) The partial derivatives read
‚àÇf
‚àÇx(x, y) = y

1 ‚àíx
5

e‚àíx
5 ‚àíy
6 ,
‚àÇf
‚àÇy (x, y) = x

1 ‚àíy
6

e‚àíx
5 ‚àíy
6 .
The equation ‚àáf(x, y) = 0 implies
‚éß
‚é™
‚é®
‚é™
‚é©
y

1 ‚àíx
5

= 0
x

1 ‚àíy
6

= 0 ,
hence P1 = (0, 0) and P2 = (5, 6) are the stationary points. Now,
‚àÇ2f
‚àÇx2 (x, y) = 1
5y
x
5 ‚àí2

e‚àíx
5 ‚àíy
6 ,
‚àÇ2f
‚àÇx‚àÇy(x, y) = ‚àÇ2f
‚àÇy‚àÇx(x, y) =

1 ‚àíx
5
 
1 ‚àíy
6

e‚àíx
5 ‚àíy
6 ,
‚àÇ2f
‚àÇy2 (x, y) = 1
6x
y
6 ‚àí2

e‚àíx
5 ‚àíy
6 ,
so that
Hf(0, 0) =
	 0
1
1
0

,
Hf(5, 6) =
	 ‚àí6
5e‚àí2
0
0
‚àí5
6e‚àí2

.
Since det Hf(0, 0) = ‚àí1 < 0, P1 is a saddle point for f, while det Hf(5, 6) =
e‚àí4 > 0 and ‚àÇ2f
‚àÇx2 (5, 6) < 0 mean P2 is a relative maximum point. This last fact
could also have been established by noticing both eigenvectors are negative,
so the matrix is negative deÔ¨Ånite.
e) The map is deÔ¨Åned on the plane minus the coordinate axes x = 0, y = 0. As
‚àÇf
‚àÇx(x, y) = 1
y ‚àí8
x2 ,
‚àÇf
‚àÇy (x, y) = ‚àíx
y2 ‚àí1 ,
‚àáf(x, y) = 0 has one solution P = (‚àí4, 2) only. What this point is is readily
said, for
‚àÇ2f
‚àÇx2 (x, y) = 16
x3 ,
‚àÇ2f
‚àÇx‚àÇy(x, y) = ‚àÇ2f
‚àÇy‚àÇx(x, y) = ‚àí1
y2 ,
‚àÇ2f
‚àÇy2 (x, y) = 2x
y3 ,
and
Hf(‚àí4, 2) =

‚àí1
4
‚àí1
4
‚àí1
4
‚àí1

.
Since det Hf(‚àí4, 2) =
3
16 > 0 and ‚àÇ2f
‚àÇx2 (‚àí4, 2) = ‚àí1
4 < 0, P is a relative
maximum.

5.7 Exercises
197
f) The function is deÔ¨Åned on
dom f = {(x, y) ‚ààR2 : 2 ‚àíx2 > 0} ,
which is the horizontal strip between the lines y = ¬±
‚àö
2. From
‚àÇf
‚àÇx(x, y) = ‚àí4xy
2 ‚àíx2 ,
‚àÇf
‚àÇy (x, y) = 2 log(2 ‚àíx2) + 2y ,
equation ‚àáf(x, y) = 0 gives points P1 = (1, 0), P2 = (‚àí1, 0), P3 = (0, ‚àílog 2).
The second derivatives read:
‚àÇ2f
‚àÇx2 (x, y) = ‚àí4y(x2 + 2)
(2 ‚àíx2)2 ,
‚àÇ2f
‚àÇy2 (x, y) = 2 ,
‚àÇ2f
‚àÇx‚àÇy(x, y) = ‚àÇ2f
‚àÇy‚àÇx(x, y) = ‚àí
4x
2 ‚àíx2 ,
so
Hf(1, 0) =
	 0
‚àí4
‚àí4
2

,
Hf(‚àí1, 0) =
	 0
4
4
2

,
Hf(0, ‚àílog2) =
	 2 log 2
0
0
2

.
As det Hf(1, 0) = det Hf(‚àí1, 0) = ‚àí16 < 0, P1 and P2 are saddle points; P3
is a relative minimum because the Hessian Hf(P3) is positive deÔ¨Ånite.
g) Using
‚àÇf
‚àÇx(x, y) = 6(x ‚àíy)e3x2‚àí6xy+2y3 ,
‚àÇf
‚àÇy (x, y) = 6(y2 ‚àíx)e3x2‚àí6xy+2y3 ,
‚àáf(x, y) = 0 produces two stationary points P1 = (0, 0), P2 = (1, 1). As for
second-order derivatives,
‚àÇ2f
‚àÇx2 (x, y) = 6

1 + 6(x ‚àíy)2
e3x2‚àí6xy+2y3 ,
‚àÇ2f
‚àÇx‚àÇy(x, y) = ‚àÇ2f
‚àÇy‚àÇx(x, y) = 6

‚àí1 + 6(y2 ‚àíx)(x ‚àíy)

e3x2‚àí6xy+2y3 ,
‚àÇ2f
‚àÇy2 (x, y) = 6

2y + 6(y2 ‚àíx)2
e3x2‚àí6xy+2y3 ,
so
Hf(0, 0) =
	 6
‚àí6
‚àí6
0

,
Hf(1, 1) =
	 6e‚àí1
‚àí6e‚àí1
‚àí6e‚àí1
12e‚àí1

.
The Ô¨Årst is a saddle point, for det Hf(0, 0) = ‚àí36 < 0; as for the other point,
det Hf(1, 1) = 36e‚àí1 > 0 and ‚àÇ2f
‚àÇx2 (1, 1) = 6e‚àí1 > 0 imply P2 is a relative
minimum.

198
5 DiÔ¨Äerential calculus for scalar functions
h) The function is deÔ¨Åned on x > 0. The derivatives
‚àÇf
‚àÇx(x, y) = y
x ,
‚àÇf
‚àÇy (x, y) = log x
are zero at the point P = (1, 0). Since
‚àÇ2f
‚àÇx2 (x, y) = ‚àíy
x2 ,
‚àÇ2f
‚àÇx‚àÇy(x, y) = ‚àÇ2f
‚àÇy‚àÇx(x, y) = 1
x ,
‚àÇ2f
‚àÇy2 (x, y) = 0 ,
we have
Hf(1, 0) =
	 0
1
1
0

and det Hf(1, 0) = ‚àí1 < 0, telling that P is a saddle point.
i) There are no stationary points because
‚àáf(x, y) =

2x
x2 + y2 ‚àí1,
2y
x2 + y2 ‚àí1

vanishes only at (0, 0), which does not belong to the domain of f; in fact
dom f = {(x, y) ‚ààR2 : x2 + y2 > 1} consists of the points lying outside the
unit circle centred in the origin.
‚Ñì) Putting
‚àÇf
‚àÇx(x, y, z) = yz ‚àí1
x2 ,
‚àÇf
‚àÇy (x, y, z) = xz ‚àí1
y2 ,
‚àÇf
‚àÇz (x, y, z) = xy ‚àí1
z2
all equal 0 gives P1 = (1, 1, 1) and P2 = ‚àíP1. Moreover,
fxx(x, y) = 2
x3 ,
fyy(x, y) = 2
y3 ,
fzz(x, y) = 2
z3
fxy(x, y) = fyx = z ,
fxz(x, y) = fzx = y ,
fyz(x, y) = fzy = x ,
so the Hessians Hf(P1), Hf(P2) are positive deÔ¨Ånite (the eigenvalues are
Œª1 = 1, with multiplicity 2, and Œª2 = 4 in both cases). Therefore P1 and P2
are local minima for f.
24. The domain reads
dom f = {(x, y) ‚ààR2 : y2 ‚àíx2 ‚â•0} .
The inequality y2 ‚àíx2 ‚â•0 is (y ‚àíx)(y + x) ‚â•0, satisÔ¨Åed if the factors (y ‚àíx),
(y + x) have the same sign. Thus
dom f = {(x, y) ‚ààR2 : y ‚â•x and y ‚â•‚àíx} ‚à™{(x, y) ‚ààR2 : y ‚â§x and y ‚â§‚àíx} ,
see Fig. 5.10.

5.7 Exercises
199
y = x
x
y
y = ‚àíx
Figure 5.10. Domain of f(x, y) =

y2 ‚àíx2
The Ô¨Årst derivatives are
‚àÇf
‚àÇx(x, y) = ‚àí
x

y2 ‚àíx2 ,
‚àÇf
‚àÇy (x, y) =
y

y2 ‚àíx2 .
The lines y = x, y = ‚àíx are not contained in the domain of the partial derivatives,
preventing the possibility of having stationary points.
On the other hand it is easy to see that
f(x, x) = f(x, ‚àíx) = 0
and
f(x, y) ‚â•0 , ‚àÄ(x, y) ‚ààdom f .
All points on y = x and y = ‚àíx, i.e., those of coordinates (x, x) and (x, ‚àíx), are
therefore absolute minima for f.
25. First of all the function is deÔ¨Åned on
dom f = {(x, y) ‚ààR2 : 1 + y > 0} ,
which is the open half-plane determined by the line y = ‚àí1.
Secondly, the points annihilating the gradient function
‚àáf(x, y) =
	‚àÇf
‚àÇx(x, y), ‚àÇf
‚àÇy (x, y)

=
	
2x log(1 + y) + 2xy2,
x2
1 + y + 2x2y

are the solutions of
‚éß
‚é®
‚é©
2x

log(1 + y) + y2
= 0
x2
	
1
1 + y + 2y

= 0 .

200
5 DiÔ¨Äerential calculus for scalar functions
We Ô¨Ånd (0, y), with y > ‚àí1 arbitrary. Thirdly, we compute the second derivatives
‚àÇ2f
‚àÇx2 (x, y) = 2

log(1 + y) + y2
,
‚àÇ2f
‚àÇx‚àÇy(x, y) = ‚àÇ2f
‚àÇy‚àÇx(x, y) = 2x
	
1
1 + y + 2y

,
‚àÇ2f
‚àÇy2 (x, y) = x2
	
2 ‚àí
1
(1 + y)2

.
These tell that the Hessian at the stationary points is
Hf(0, y) =
	 2

log(1 + y) + y2
0
0
0

,
which unfortunately does not help to understand the points‚Äô nature.
This can be accomplished by direct inspection of the function. Write f(x, y) =
Œ±(x)Œ≤(y) with Œ±(x) = x2 and Œ≤(y) = log(1+y)+y2. Note also that f(0, y) = 0, for
any y > ‚àí1. It is not diÔ¨Écult to see that Œ≤(y) > 0 when y > 0, and Œ≤(y) < 0 when
y < 0 (just compare the graphs of the elementary functions œï(y) = log(1 + y) and
œà(y) = ‚àíy2). For any (x, y) in a suitable neighbourhood of (0, y) then,
f(x, y) ‚â•0
if
y > 0
and
f(x, y) ‚â§0
if
y < 0 .
In conclusion, for y > 0 the points (0, y) are relative minima, whereas for y < 0
they are relative maxima. The origin is neither.

6
DiÔ¨Äerential calculus for vector-valued functions
In resuming the study of vector-valued functions started in Chapter 4, we begin
by the various deÔ¨Ånitions concerning diÔ¨Äerentiability, and introduce the Jacobian
matrix, which gathers the gradients of the function‚Äôs components, and the basic
diÔ¨Äerential operators of order one and two. Then we will present the tools of diÔ¨Äer-
ential calculus; among them, the so-called chain rule for diÔ¨Äerentiating composite
maps has a prominent role, for it lies at the core of the idea of coordinate-system
changes. After discussing the general theory, we examine in detail the special,
but of the foremost importance, frame systems of polar, cylindrical, and spherical
coordinates.
The second half of the chapter devotes itself to regular, or piecewise-regular,
curves and surfaces, from a diÔ¨Äerential point of view. The analytical approach,
that focuses on the functions, gradually gives way to the geometrically-intrinsic
aspects of curves and surfaces as objects in the plane or in space. The fundamental
vectors of a curve (the tangent, normal, binormal vectors and the curvature) are
deÔ¨Åned, and we show how to choose one of the two possible orientations of a curve.
For surfaces we introduce the normal vector and the tangent plane, then discuss
the possibility of Ô¨Åxing a way to cross the surface, which leads to the dichotomy
between orientable and non-orientable surfaces, plus the notions of boundary and
closed surface. All this will be the basis upon which to build, in Chapter 9, an
integral calculus on curves and surfaces, and to establish the paramount Theorems
of Gauss, Green and Stokes.
6.1 Partial derivatives and Jacobian matrix
Given x0 ‚ààdom f, suppose every component fi of f admits at x0 all Ô¨Årst partial
derivatives ‚àÇfi
‚àÇxj
, j = 1, . . . , n, so that to have the gradient vector
‚àáfi(x0) =
 ‚àÇfi
‚àÇxj
(x0)

1‚â§j‚â§n =
 ‚àÇfi
‚àÇx1
(x0), . . . , ‚àÇfi
‚àÇxn
(x0)

,
here written as row vector.
C. Canuto, A. Tabacco: Mathematical Analysis II, 2nd Ed.,
UNITEXT ‚Äì La Matematica per il 3+2 85, DOI 10.1007/978-3-319-12757-6_6,
¬© Springer International Publishing Switzerland 2015

202
6 DiÔ¨Äerential calculus for vector-valued functions
DeÔ¨Ånition 6.1 The matrix with m rows and n columns
Jf(x0) =
 ‚àÇfi
‚àÇxj
(x0)

1 ‚â§i ‚â§m
1 ‚â§j ‚â§n
=
‚éõ
‚éú
‚éù
‚àáf1(x0)
...
‚àáfm(x0)
‚éû
‚éü
‚é†
is called Jacobian matrix of f at the point x0.
The Jacobian (matrix) is also indicated by Jf(x0) or Df(x0).
In particular if f = f is a scalar map (m = 1), then
Jf(x0) = ‚àáf(x0) .
Examples 6.2
i) The function f : R3 ‚ÜíR2, f(x, y, z) = xyz i+(x2+y2+z2) j has components
f1(x, y, z) = xyz and f2(x, y, z) = x2+y2+z2, whose partial derivatives we write
as entries of
Jf(x, y, z) =
	 yz
xz
xy
2x
2y
2z

.
ii) Consider
f : Rn ‚ÜíRn ,
f(x) = Ax + b ,
where A = (aij) 1‚â§i‚â§m
1‚â§j ‚â§n
‚ààRm√ón is an m √ó n matrix and b = (bi)1‚â§i‚â§m ‚ààRm.
The ith component of f is
fi(x) =
n

j=1
aijxj + bi ,
whence ‚àÇfi
‚àÇxj
(x) = aij for all j = 1, . . . , n x ‚ààRn. Therefore Jf(x) = A.
2
6.2 DiÔ¨Äerentiability and Lipschitz functions
Now we shall see if and how the previous chapter‚Äôs results extend to vector-valued
functions. Starting from diÔ¨Äerentiability, let us suppose each component of f is
diÔ¨Äerentiable at x0 ‚ààdom f (see DeÔ¨Ånition 5.5),
fi(x) = fi(x0) + ‚àáfi(x0) ¬∑ (x ‚àíx0) + o(‚à•x ‚àíx0‚à•) ,
x ‚Üíx0
for any i = 1, . . . , n. The dot product ‚àáfi(x0) ¬∑ (x ‚àíx0) is to be thought of as a
matrix product between the row vector ‚àáfi(x0) and the column vector x ‚àíx0.

6.2 DiÔ¨Äerentiability and Lipschitz functions
203
By deÔ¨Ånition of Jacobian matrix, we may write, vectorially,
f(x) = f(x0) + Jf(x0)(x ‚àíx0) + o(‚à•x ‚àíx0‚à•) ,
x ‚Üíx0 .
(6.1)
One says then f is diÔ¨Äerentiable at x0.
Let us consider a special case: putting Œîx = x ‚àíx0, we rewrite the above as
f(x0 + Œîx) = f(x0) + Jf(x0)Œîx + o(‚à•Œîx‚à•) ,
Œîx ‚Üí0 ;
the linear map dfx0 from Rn to Rm deÔ¨Åned by
dfx0 : Œîx ‚ÜíJf(x0)Œîx
is called diÔ¨Äerential of f at x0. Up to inÔ¨Ånitesimals of order greater than one,
the formula says the increment Œîf = f(x0 + Œîx)‚àíf(x0) is approximated by the
value of the diÔ¨Äerential dfx0 = Jf(x0)Œîx.
As for scalar functions, equation (6.1) linearises f at x0, written
f(x) ‚àºf(x0) + Jf(x0)(x ‚àíx0)
on a neighbourhood of x0; in other words it approximates f by means of a degree-
one polynomial in x (the Taylor polynomial of order 1 at x0).
Propositions 5.7 and 5.8 carry over, as one sees by taking one component at a
time.
Also vectorial functions can be Lipschitz. The next statements generalise DeÔ¨Ån-
ition 5.14 and Proposition 5.16. Let R be a region inside dom f.
DeÔ¨Ånition 6.3 The map f is Lipschitz on R if there is a constant L ‚â•0
such that
‚à•f(x1) ‚àíf(x2)‚à•‚â§L‚à•x1 ‚àíx2‚à•,
‚àÄx1, x2 ‚ààR .
(6.2)
The smallest such L is the Lipschitz constant of f on R.
Clearly f is Lipschitz on R if and only if all its components are.
Proposition 6.4 Let R be a connected region in dom f. Suppose f is dif-
ferentiable on such region and assume there is an M ‚â•0 such that

‚àÇfi
‚àÇxj
(x)
 ‚â§M ,
‚àÄx ‚ààR, i = 1, . . . , m , j = 1, . . . , n .
Then f is Lipschitz on R with L = ‚àönm M.

204
6 DiÔ¨Äerential calculus for vector-valued functions
The proof is an easy consequence of Proposition 5.16 applied to each component
of f.
Vector-valued functions do not have an analogue of the Mean Value The-
orem 5.12, since there might not be an x ‚ààS[a, b] such that f(b) ‚àíf(a) =
Jf(x)(b ‚àía) (whereas for each component fi there clearly is a point xi ‚ààS[a, b]
satisfying (5.11)). A simple counterexample is the curve f : R ‚ÜíR2, f(t) = (t2, t3)
with a = 0, b = 1, for which f(1) ‚àíf(0) = (1, 1) but Jf(t) = (2t, 3t2). We cannot
Ô¨Ånd any t such that Jf(t)(b ‚àía) = (2t, 3t
2) = (1, 1).
Nevertheless, one could prove, under hypotheses similar to Lagrange‚Äôs state-
ment 5.12, that
‚à•f(b) ‚àíf(a)‚à•‚â§
sup
x‚ààS[a,b]
‚à•Jf(x)‚à•‚à•b ‚àía‚à•,
where the Jacobian‚Äôs norm is deÔ¨Åned as in Sect. 4.2.
At last, we extend the notion of functions of class Ck, see Sect. 5.4. A map f is
of class Ck (0 ‚â§k ‚â§‚àû) on the open set Œ© ‚äÜdom f if all components are of class
Ck on Œ©; we shall write f ‚àà

Ck(Œ©)
n. A similar deÔ¨Ånition is valid if we take Œ©
instead of Œ©.
6.3 Basic diÔ¨Äerential operators
Given a real function œï, deÔ¨Åned on an open set Œ© in Rn and diÔ¨Äerentiable on Œ©,
we saw in Sect. 5.2 how to associate to such a scalar Ô¨Åeld on Œ© the (Ô¨Årst) partial
derivatives ‚àÇœï
‚àÇxj
with respect to the coordinates xj, j = 1, . . . , n; these are still
scalar Ô¨Åelds on Œ©. Each mapping œï ‚Üí‚àÇœï
‚àÇxj
is a linear operator, because
‚àÇ
‚àÇxj
(Œªœï + Œºœà) = Œª ‚àÇœï
‚àÇxj
+ Œº ‚àÇœà
‚àÇxj
for any pair of functions œï, œà diÔ¨Äerentiable on Œ© and any pair of numbers Œª, Œº ‚ààR.
The operator maps C1(Œ©) to C0(Œ©): each partial derivative of a C1 function on Œ©
is of class C0 on Œ©; in general, each operator
‚àÇ
‚àÇxj
maps Ck(Œ©) to Ck‚àí1(Œ©), for any
k ‚â•1.
6.3.1 First-order operators
Using operators involving (Ô¨Årst) partial derivatives we can introduce a host of
linear diÔ¨Äerential operators of order one that act on (scalar or vector) Ô¨Åelds deÔ¨Åned
and diÔ¨Äerentiable on Œ©, and return (scalar or vector) Ô¨Åelds on Œ©. The Ô¨Årst we wish

6.3 Basic diÔ¨Äerential operators
205
to describe is the gradient operator; as we know, it associates to a diÔ¨Äerentiable
scalar Ô¨Åeld the vector Ô¨Åeld of Ô¨Årst derivatives:
grad œï = ‚àáœï =
	 ‚àÇœï
‚àÇxj

1‚â§j‚â§n
= ‚àÇœï
‚àÇx1
e1 + ¬∑ ¬∑ ¬∑ + ‚àÇœï
‚àÇxn
en .
Thus if œï ‚ààC1(Œ©), then grad œï ‚àà

C0(Œ©)
n, meaning the gradient is a linear
operator from C1(Œ©) to

C0(Œ©)
n.
Let us see two other fundamental linear diÔ¨Äerential operators.
DeÔ¨Ånition 6.5 The divergence of a vector Ô¨Åeld f = f1e1 + ¬∑ ¬∑ ¬∑ + fnen,
diÔ¨Äerentiable on Œ© ‚äÜRn, is the scalar Ô¨Åeld
div f = ‚àÇf1
‚àÇx1
+ ¬∑ ¬∑ ¬∑ + ‚àÇfn
‚àÇxn
=
n

j=1
‚àÇfj
‚àÇxj
.
(6.3)
The divergence operator maps

C1(Œ©)
n to C0(Œ©).
DeÔ¨Ånition 6.6 The curl of a vector Ô¨Åeld f = f1i + f2j + f3k, diÔ¨Äerentiable
on Œ© ‚äÜR3, is the vector Ô¨Åeld
curl f =
	 ‚àÇf3
‚àÇx2
‚àí‚àÇf2
‚àÇx3

i +
	 ‚àÇf1
‚àÇx3
‚àí‚àÇf3
‚àÇx1

j +
	 ‚àÇf2
‚àÇx1
‚àí‚àÇf1
‚àÇx2

k
= det
‚éõ
‚éú
‚éú
‚éú
‚éù
i
j
k
‚àÇ
‚àÇx1
‚àÇ
‚àÇx2
‚àÇ
‚àÇx3
f1
f2
f3
‚éû
‚éü
‚éü
‚éü
‚é†
(6.4)
(the determinant is computed along the Ô¨Årst row). The curl operator maps

C1(Œ©)
3 to

C0(Œ©)
3. Another symbol used in many European countries is
rot, standing for rotor.
We remark that the curl, as above deÔ¨Åned, acts only on three-dimensional vector
Ô¨Åelds. In dimension 2, one deÔ¨Ånes the curl of a vector Ô¨Åeld f, diÔ¨Äerentiable on an
open set Œ© ‚äÜR2, as the scalar Ô¨Åeld
curl f = ‚àÇf2
‚àÇx1
‚àí‚àÇf1
‚àÇx2
.
(6.5)

206
6 DiÔ¨Äerential calculus for vector-valued functions
Note that this is the only non-zero component (the third one) of the curl of
Œ¶(x1, x2, x3) = f1(x1, x2)i + f2(x1, x2)j + 0k, associated to f; in other words
curlŒ¶ = 0i + 0j + (curl f) k .
(6.6)
Sometimes, in dimension 2, the curl of a diÔ¨Äerentiable scalar Ô¨Åeld œï on an open
set Œ© ‚äÜR2 is also deÔ¨Åned as the (two-dimensional) vector Ô¨Åeld
curl œï = ‚àÇœï
‚àÇx2
i ‚àí‚àÇœï
‚àÇx1
j .
(6.7)
Here, too, the deÔ¨Ånition is suggested by a suitable three-dimensional curl: setting
Œ¶(x1, x2, x3) = 0i + 0j + œï(x1, x2)k, we see immediately
curlŒ¶ = curl œï + 0k .
Higher-dimensional curl operators exist, but go beyond the purposes of this book.
Occasionally one Ô¨Ånds useful to have a single formalism to represent the three
operators gradient, divergence and curl. To this end, denote by ‚àáthe symbolic
vector whose components are the partial diÔ¨Äerential operators
‚àÇ
‚àÇx1
, . . . ,
‚àÇ
‚àÇxn
:
‚àá=
	 ‚àÇ
‚àÇxj

1‚â§j‚â§n
=
‚àÇ
‚àÇx1
e1 + ¬∑ ¬∑ ¬∑ +
‚àÇ
‚àÇxn
en .
In this way the gradient of a scalar Ô¨Åeld œï, denoted ‚àáœï, may be thought of as
obtained from the multiplication (on the right) of the vector ‚àáby the scalar œï.
Similarly, (6.3) shows the divergence of a vector Ô¨Åeld f is the dot product of the
two vectors ‚àáand f, whence one writes
div f = ‚àá¬∑ f .
In dimension 3 at last, the curl of a vector Ô¨Åeld f can be obtained, as (6.4) suggests,
computing the cross product of the vectors ‚àáand f, allowing one to write
curl f = ‚àá‚àßf .
Let us illustrate the geometric meaning of the divergence and the curl of a
three-dimensional vector Ô¨Åeld, and show that the former is related to the change
in volume of a portion of mass moving under the eÔ¨Äect of the vector Ô¨Åeld, while
the latter has to do with the rotation of a solid around a point. So let f : R3 ‚ÜíR3
be a C1 vector Ô¨Åeld, which we shall assume to have bounded Ô¨Årst derivatives on the
whole R3. For any x ‚ààR3 let Œ¶(t, x) be the trajectory of f passing through x at
time t = 0 or, equivalently, the solution of the Cauchy problem for the autonomous
diÔ¨Äerential system

6.3 Basic diÔ¨Äerential operators
207
 Œ¶‚Ä≤ = f(Œ¶) ,
t > 0 ,
Œ¶(0, x) = x .
We may also suppose that the solution exists at any time t ‚â•0 and is diÔ¨Äerentiable
with continuity with respect to both t and x (that this is true will be proved in
Ch. 10). Fix a bounded open set Œ©0 and follow its evolution in time by looking at
its images under Œ¶
Œ©t = Œ¶(t,Œ© 0) = {z = Œ¶(t, x) : x ‚ààŒ©0} .
We will introduce in Chapter 8 the triple integral of a map g deÔ¨Åned on Œ©t,

Œ©t
g(x, y, z) dx dy dz ,
and show that, when g is the constant function 1, the integral represents the
volume of the set Œ©t. Well, one can prove that
d
dt

Œ©t
dx dy dz =

Œ©t
div f dx dy dz ,
which shows it is precisely the divergence of f that governs the volume variation
along the Ô¨Åeld‚Äôs trajectories. In particular, if f is such that div f = 0 on R3, the
volume of the image of any open set Œ©0 is constant with time (see Fig. 6.1 for a
picture in dimension two).
 
 
 
 
 
 
  
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
x
y
t
t = 0
t = t1
t = t2
x
y
Œ©0
x
y
Œ©1
x
y
Œ©2
Figure 6.1. The area of a surface evolving in time under the eÔ¨Äect of a two-dimensional
Ô¨Åeld with zero divergence does not change

208
6 DiÔ¨Äerential calculus for vector-valued functions
Let now f(x) = Ax be a particular rigid motion of a three-dimensional solid
S, namely a (clockwise) rotation around the z-axis by an angle Œ∏. Then A is
orthogonal (viz. it does not aÔ¨Äect distances); precisely, it takes the form
A =
‚éõ
‚éú
‚éù
cos Œ∏
sin Œ∏
0
‚àísin Œ∏
cos Œ∏
0
0
0
1
‚éû
‚éü
‚é†.
It is easy to see that
curl f = 0i + 0j ‚àí2 sin Œ∏k ;
so the curl of f has only one non-zero component, in the direction of rotation,
that depends on the angle.
After this digression we return to the general properties of the operators gradi-
ent, divergence and curl, we observe that also the latter two are linear, like the
gradient
div (Œªf + Œºg) = Œª div f + Œº div g ,
curl (Œªf + Œºg) = Œª curl f + Œº curl g
for any pair of Ô¨Åelds f, g and scalars Œª, Œº. Moreover, we have a list of properties
expressing how the operators interact with various products between (scalar and
vector) Ô¨Åelds of class C1:
grad (œïœà) = œà grad œï + œï grad œà ,
grad (f ¬∑ g) = g Jf + f Jg ,
div (œïf) = grad œï ¬∑ f + œï div f ,
div (f ‚àßg) = g ¬∑ curl f ‚àíf ¬∑ curl g ,
curl (œïf) = grad œï ‚àßf + œï curl f ,
curl (f ‚àßg) = f div g ‚àíg div f + g Jf ‚àíf Jg .
Their proof is straightforward from the deÔ¨Ånitions and the rule for diÔ¨Äerentiating
a product.
In two special cases, the successive action of two of grad , div , curl on a
suÔ¨Éciently regular Ô¨Åeld gives the null vector Ô¨Åeld. The following results ensue
from the deÔ¨Ånitions by using Schwarz‚Äôs Theorem 5.17.

6.3 Basic diÔ¨Äerential operators
209
Proposition 6.7 i) Let œï be a scalar Ô¨Åeld of class C2 on an open set Œ© of
R3. Then
curl grad œï = ‚àá‚àß(‚àáœï) = 0
on Œ© .
ii) Let Œ¶ be a C2 vector Ô¨Åeld on an open set Œ© of R3. Then
div curlŒ¶ = ‚àá¬∑ (‚àá‚àßŒ¶) = 0
on Œ© .
The two-dimensional version of the above results reads
Proposition 6.8 Let œï be a scalar Ô¨Åeld of class C2 on an open set Œ© in R2.
Then
curl grad œï = 0
and
div curl œï = 0
on Œ© .
These propositions steer us to the examination of Ô¨Åelds with null gradient,
null curl or zero divergence on a set Œ©, a study with relevant applications. It is
known (Proposition 5.13) that a scalar Ô¨Åeld œï has null gradient on Œ© if and only
if œï is constant on connected components of Œ©. For the other two operators we
preliminarly need some terminology.
DeÔ¨Ånition 6.9 i) A vector Ô¨Åeld f, diÔ¨Äerentiable on an open set Œ© in R3
and such that curl f = 0, is said irrotational (or curl-free) on Œ©.
ii) A vector Ô¨Åeld f, diÔ¨Äerentiable on an open set Œ© of Rn and such that
div f = 0 is said divergence-free on Œ©.
DeÔ¨Ånition 6.10 i) A vector Ô¨Åeld f on an open set Œ© of Rn is conservative
in Œ© if there exists a scalar Ô¨Åeld œï such that f = grad œï on Œ©. The
function œï is called a (scalar) potential of f.
ii) A vector Ô¨Åeld f on an open set Œ© of R3 is of curl type if there exists
a vector Ô¨Åeld Œ¶ such that f = curlŒ¶ on Œ©. The function Œ¶ is called a
(vector) potential for f.
Taking these into consideration, Proposition 6.7 modiÔ¨Åes as follows: i) if a C1
vector Ô¨Åeld f on an open set Œ© of R3 is conservative (and so admits a scalar
potential of class C2), then it is necessarily irrotational. ii) If a C1 vector Ô¨Åeld f on
an open set Œ© of R3 admits a C2 vector potential, it is divergence-free. Equivalently,
we may concisely say that: i) f conservative implies f irrotational; ii) f of curl
type implies f divergence-free.
The natural question is whether the above necessary conditions are also suf-
Ô¨Åcient to guarantee the existence of a (scalar or vectorial) potential for f. The

210
6 DiÔ¨Äerential calculus for vector-valued functions
answer will be given in Sect. 9.6, at least for Ô¨Åelds with no curl. But we can say
that in the absence of additional assumptions on the open set Œ© the answer is neg-
ative. In fact, open subsets of R3 exist, on which there are irrotational vector Ô¨Åelds
of class C1 that are not conservative. Notwithstanding these counterexamples, we
will provide conditions on Œ© turning the necessary condition into an equivalence.
In particular, each C1 vector Ô¨Åeld on an open, convex subset of R3 (like the in-
terior of a cube, of a sphere, of an ellipsoid) is irrotational if and only if it is
conservative.
Comparable results hold for divergence-free Ô¨Åelds, in relationship to the exist-
ence of vector potentials.
Examples 6.11
i) Let f be the aÔ¨Éne vector Ô¨Åeld
f : R3 ‚ÜíR3 ,
f(x) = Ax + b
deÔ¨Åned by the 3 √ó 3 matrix A and the vector b of R3. Immediately we have
div f = a11 + a22 + a33 ,
curl f = (a32 ‚àía23)i + (a31 ‚àía13)j + (a21 ‚àía12)k .
Therefore f has no divergence on R3 if and only if the trace of A, tr A =
a11 + a22 + a33, is zero. The Ô¨Åeld is, instead, irrotational on R3 if and only if A
is symmetric.
Since R3 is clearly convex, to say f has no curl is the same as asserting f is
conservative. In fact if A is symmetric, a (scalar) potential for f is
œï(x) = 1
2x ¬∑ Ax ‚àíb ¬∑ x .
Similarly, f is divergence-free if and only if it is of curl type, for if tr A is zero,
a vector potential for f is
Œ¶(x) = 1
3(Ax) ‚àßx + 1
2b ‚àßx .
Note at last the Ô¨Åeld
f(x) = (y + z) i + (x ‚àíz) j + (x ‚àíy) k ,
corresponding to
A =
‚éõ
‚éú
‚éù
0
1
1
1
0
‚àí1
1
‚àí1
0
‚éû
‚éü
‚é†
and
b = 0 ,
is an example of a simultaneously irrotational and divergence-free Ô¨Åeld.
ii) Given f ‚àà

C1(Œ©)
3, and x0 ‚ààŒ©, consider the Jacobian Jf(x0) of f at x0.
Then (div f)(x0) = 0 if and only if tr

Jf(x0)

= 0, while

curl f

(x0) = 0 if
and only if Jf(x0) is symmetric. In particular, the curl of f measures the failure
of the Jacobian to be symmetric.
2

6.3 Basic diÔ¨Äerential operators
211
Finally, we state without proof a theorem that casts some light on DeÔ¨Åni-
tions 6.5 and 6.6.
Theorem 6.12 Let Œ© be an open convex subset of R3. Every C1 vector Ô¨Åeld
on Œ© decomposes (not uniquely) into the sum of an irrotational Ô¨Åeld and a
Ô¨Åeld with no divergence. In other terms, for any f ‚àà

C1(Œ©)
3 there exist
f (irr) ‚àà

C1(Œ©)
3 with curl f (irr) = 0 on Œ©, and f (divfree) ‚àà

C1(Œ©)
3 with
div f (divfree) = 0 on Œ©, such that
f = f (irr) + f (divfree) .
Such a representation is known as Helmholtz decomposition of f.
Example 6.13
We return to the aÔ¨Éne vector Ô¨Åeld on R3 (Example 6.11 i)). Let us decompose
the matrix A in the sum of its symmetric part A(sym) = 1
2(A + AT ) and skew-
symmetric part A(skew) = 1
2(A ‚àíAT ),
A = A(sym) + A(skew) .
Setting f (irr)(x) = A(sym)x+b and f (divfree)(x) = A(skew)x realises the Helm-
holtz decomposition of f: f (irr) is irrotational as A(sym) is symmetric, f (divfree)
is divergence-free as the diagonal of a skew-symmetric matrix is zero. Adding to
A(sym) an arbitrary traceless diagonal matrix D and subtracting the same from
A(skew) gives new Ô¨Åelds f (irr) and f (divfree) for a diÔ¨Äerent Helmholtz decom-
position of f.
2
6.3.2 Second-order operators
The consecutive action of two linear, Ô¨Årst-order diÔ¨Äerential operators typically pro-
duces a linear diÔ¨Äerential operator of order two, obviously deÔ¨Åned on a suÔ¨Éciently-
regular (scalar or vector) Ô¨Åeld. We have already remarked (Proposition 6.7) how
letting the curl act on the gradient, or computing the divergence of the curl, of
a C2 Ô¨Åeld produces the null operator. We list a few second-order operators with
crucial applications.
i) The operator div grad maps a scalar Ô¨Åeld œï ‚ààC2(Œ©) to the C0(Œ©) scalar Ô¨Åeld
div grad œï = ‚àá¬∑ ‚àáœï =
n

j=1
‚àÇ2œï
‚àÇx2
j
,
(6.8)
sum of the second partial derivatives of œï of pure type. The operator div grad is
known as Laplace operator, or simply Laplacian, and often denoted by Œî.

212
6 DiÔ¨Äerential calculus for vector-valued functions
Therefore
Œî = ‚àÇ2
‚àÇx2
1
+ ¬∑ ¬∑ ¬∑ + ‚àÇ2
‚àÇx2n
,
and (6.8) reads Œîœï. Another possibility to denote Laplace‚Äôs operator is ‚àá2, which
intuitively reminds the second equation of (6.8). Note ‚àá2œï cannot be confused
with ‚àá(‚àáœï), a meaningless expression as ‚àáacts on scalars, not on vectors; ‚àá2œï
is purely meant as a shorthand symbol for ‚àá¬∑ (‚àáœï).
A map œï such that Œîœï = 0 on an open set Œ© is called harmonic on Œ©. Harmonic
maps enjoy key mathematical properties and intervene in the description of several
physical phenomena. For example, the electrostatic potential generated in vacuum
by an electric charge at the point x0 ‚ààR3 is a harmonic function deÔ¨Åned on the
open set R3 \ {x0}.
ii) The Laplace operator acts (component-wise) on vector Ô¨Åelds as well, and one
sets
Œîf = Œîf1e1 + ¬∑ ¬∑ ¬∑ + Œîfnen
where f = f1e1+¬∑ ¬∑ ¬∑ fnen. Thus the vector Laplacian maps

C2(Œ©)
n to

C0(Œ©)
n.
iii) The operator grad div transforms vector Ô¨Åelds into vector Ô¨Åelds, and precisely
it maps

C2(Œ©)
n to

C0(Œ©)
n.
iv) Similarly the operator curl curl goes from

C2(Œ©)
3 to

C0(Œ©)
3.
The latter three operators are related by the formula
Œîf ‚àígrad div f + curl curl f = 0 .
6.4 DiÔ¨Äerentiating composite functions
Let
f : dom f ‚äÜRn ‚ÜíRm
and
g : dom g ‚äÜRm ‚ÜíRp
be two maps and x0 ‚ààdom f a point such that y0 = f(x0) ‚ààdom g, so that the
composite
h = g ‚ó¶f : dom h ‚äÜRn ‚ÜíRp ,
for x0 ‚ààdom h, is well deÔ¨Åned. We know the composition of continuous functions
is continuous (Proposition 4.23).
As far as diÔ¨Äerentiability is concerned, we have a result whose proof is similar
to the case n = m = p = 1.
Theorem 6.14 Let f be diÔ¨Äerentiable at x0 ‚ààdom h and g diÔ¨Äerentiable at
y0 = f(x0). Then h = g ‚ó¶f is diÔ¨Äerentiable at x0 and its Jacobian matrix is
J(g ‚ó¶f)(x0) = Jg(y0) Jf(x0)
(6.9)

6.4 DiÔ¨Äerentiating composite functions
213
Note Jf(x0) is m √ó n, Jg(y0) is p √ó m, hence the product of matrices on the
right-hand side is well deÔ¨Åned and produces a p √ó n matrix.
We shall make (6.9) explicit by writing the derivatives of the components of h
in terms of the derivatives of f and g. For this, set x = (xj)1‚â§j‚â§n and
y = f(x) =

fk(x)

1‚â§k‚â§m ,
z = g(y) =

gi(y)

1‚â§i‚â§p ,
z = h(x) =

hi(x)

1‚â§i‚â§p .
The entry on row i and column j of Jh(x0) is
‚àÇhi
‚àÇxj
(x0) =
m

k=1
‚àÇgi
‚àÇyk
(y0) ‚àÇfk
‚àÇxj
(x0) .
(6.10)
To remember these equations, we can write them as
‚àÇzi
‚àÇxj
(x0) =
m

k=1
‚àÇzi
‚àÇyk
(y0) ‚àÇyk
‚àÇxj
(x0) ,
1 ‚â§i ‚â§p , 1 ‚â§j ‚â§n ,
(6.11)
also known as the chain rule for diÔ¨Äerentiating composite maps.
Examples 6.15
i) Let f = (f1, f2) : R2 ‚ÜíR2 and g : R2 ‚ÜíR be diÔ¨Äerentiable. Call h = g ‚ó¶f :
R2 ‚ÜíR the composition, h(x, y) = g

f1(x, y), f2(x, y)

. Then
‚àáh(x) = ‚àág

f(x)

Jf(x) ;
(6.12)
putting u = f1(x, y), v = f2(x, y), this becomes
‚àÇh
‚àÇx(x, y) = ‚àÇg
‚àÇu(u, v) ‚àÇf1
‚àÇx (x, y) + ‚àÇg
‚àÇv (u, v) ‚àÇf2
‚àÇx (x, y)
‚àÇh
‚àÇy (x, y) = ‚àÇg
‚àÇu(u, v) ‚àÇf1
‚àÇy (x, y) + ‚àÇg
‚àÇv (u, v) ‚àÇf2
‚àÇy (x, y) .
ii) Let œï : I ‚äÜR ‚ÜíR be a diÔ¨Äerentiable map and f : R2 ‚ÜíR a scalar
diÔ¨Äerentiable function. The composite h(x) = f

x,œï (x)

is diÔ¨Äerentiable on I,
and
h‚Ä≤(x) = dh
dx(x) = ‚àÇf
‚àÇx

x,œï (x)

+ ‚àÇf
‚àÇy

x,œï (x)

œï‚Ä≤(x) ,
as follows from Theorem 6.14, since h = f‚ó¶Œ¶ with Œ¶ : I ‚ÜíR2, Œ¶(x) =

x,œï (x)

.
When a function depends on one variable only, the partial derivative symbol
in (6.9) should be replaced by the more precise ordinary derivative.

214
6 DiÔ¨Äerential calculus for vector-valued functions
iii) Consider a curve Œ≥ : I ‚äÜR ‚ÜíR3 of diÔ¨Äerentiable components Œ≥i, together
with a diÔ¨Äerentiable map f : R3 ‚ÜíR. Let h = f ‚ó¶Œ≥ : I ‚ÜíR be the composition.
Then
h‚Ä≤(t) = ‚àáf

Œ≥(t)

¬∑ Œ≥‚Ä≤(t) ,
(6.13)
or, putting (x, y, z) = Œ≥(t),
dh
dt (t) = ‚àÇf
‚àÇx(x, y, z) dŒ≥1
dt (t) + ‚àÇf
‚àÇy (x, y, z) dŒ≥2
dt (t) + ‚àÇf
‚àÇz (x, y, z) dŒ≥3
dt (t) .
2
Theorem 6.14 can be successfully applied to extend the one-variable res-
ult, known to the student, about the derivative of the inverse function (Vol. I,
Thm. 6.9). We show that under suitable hypotheses the Jacobian of the inverse
function is roughly speaking the inverse Jacobian matrix. Sect. 7.1.1 will give us
a suÔ¨Écient condition for the following corollary to hold.
Corollary 6.16 Let f : dom f ‚äÜRn ‚ÜíRn be diÔ¨Äerentiable at x0 with non-
singular Jf(x0). Assume further that f is invertible on a neighbourhood of
x0, and that the inverse map f ‚àí1 is diÔ¨Äerentiable at y0 = f(x0). Then
J(f ‚àí1)(y0) =

Jf(x0)
‚àí1 .
Proof.
Applying the theorem with g = f ‚àí1 will meet our needs, because
h = f ‚àí1 ‚ó¶f is the identity map (h(x) = x for any x around x0), hence
Jh(x0) = I. Therefore
J(f ‚àí1)(y0) Jf(x0) = I ,
whence the claim, as Jf(x0) is invertible.
2
6.4.1 Functions deÔ¨Åned by integrals
We encounter a novel way to deÔ¨Åne a function, a way that takes a given map of
two (scalar or vectorial) variables and integrates it with respect to one of them.
This kind of map has many manifestations, for instance in the description of elec-
tromagnetic Ô¨Åelds. In the sequel we will restrict to the case of two scalar variables,
although the more general treatise is not, conceptually, that more diÔ¨Écult.
Let then g be a real map deÔ¨Åned on the set R = I √ó J ‚äÇR2, where I is an
arbitrary real interval and J = [a, b] is closed and bounded. Suppose g is continuous
on R and deÔ¨Åne
f(x) =
 b
a
g(x, y) dy ;
(6.14)

6.4 DiÔ¨Äerentiating composite functions
215
this is a one-variable map deÔ¨Åned on I, because for any x ‚ààI the function y ‚Üí
g(x, y) is continuous hence integrable on J.
Our function f satisÔ¨Åes the following properties, whose proof can be found in
Appendix A.1.3, p. 516.
Proposition 6.17 The function f of (6.14) is continuous on I. Moreover, if
g admits continuous partial derivative ‚àÇg
‚àÇx on R, then f is of class C1 on I
and
f ‚Ä≤(x) =
 b
a
‚àÇg
‚àÇx(x, y) dy .
This proposition spells out a rule for diÔ¨Äerentiating integrals: diÔ¨Äerentiating in
one variable and integrating in the other are commuting operations, namely
d
dx
 b
a
g(x, y) dy =
 b
a
‚àÇg
‚àÇx(x, y) dy .
The above formula extends to higher derivatives:
f (k)(x) =
 b
a
‚àÇkg
‚àÇxk (x, y) dy ,
k ‚â•1 ,
provided the integrand exists and is continuous on R.
A more general form of (6.14) is
f(x) =
 Œ≤(x)
Œ±(x)
g(x, y) dy ,
(6.15)
where Œ± and Œ≤ are deÔ¨Åned on I with values in [a, b].
Notice that the integral function
f(x) =
 x
a
g(y) dy ,
considered in Vol. I, Sect. 9.8, is a special case.
Proposition 6.17 generalises in the following manner.
Proposition 6.18 If Œ± and Œ≤ are continuous on I, the map f deÔ¨Åned
by (6.15) is continuous on I. If moreover g admits continuous partial de-
rivative ‚àÇg
‚àÇx on R and Œ±, Œ≤ are C1 on I, then f is C1 on I, and
f ‚Ä≤(x) =
 Œ≤(x)
Œ±(x)
‚àÇg
‚àÇx(x, y) dy + Œ≤‚Ä≤(x)g

x,Œ≤ (x)

‚àíŒ±‚Ä≤(x)g

x,Œ± (x)

.
(6.16)

216
6 DiÔ¨Äerential calculus for vector-valued functions
Proof.
We shall only prove the formula, referring to Appendix A.1.3, p. 517, for
the rest of the proof.
DeÔ¨Åne on I √ó J2 the map
F(x, p, q) =
 q
p
g(x, y) dy ;
it admits continuous Ô¨Årst derivatives everywhere on its domain
‚àÇF
‚àÇx (x, p, q) =
 q
p
‚àÇg
‚àÇx(x, y) dy ,
‚àÇF
‚àÇp (x, p, q) = ‚àíg(x, p) ,
‚àÇF
‚àÇq (x, p, q) = g(x, q) .
The last two descend from the Fundamental Theorem of Integral Calculus.
The assertion now follows from the fact that f(x) = F

x,Œ± (x), Œ≤(x)

by
applying the chain rule
df
dx(x) = ‚àÇF
‚àÇx

x,Œ± (x), Œ≤(x)

+
+‚àÇF
‚àÇp

x,Œ± (x), Œ≤(x)

Œ±‚Ä≤(x) + ‚àÇF
‚àÇq

x,Œ± (x), Œ≤(x)

Œ≤‚Ä≤(x) .
2
Example 6.19
The map
f(x) =
 x2
x
e‚àíxy2
y
dy
is of the form (6.15) if we set g(x, y) = e‚àíxy2
y
, Œ±(x) = x, Œ≤(x) = x2. As g is
not integrable in elementary functions with respect to y, we cannot compute
f(x) explicitly. But g is C1 on any closed region contained in the Ô¨Årst quadrant
x > 0, y > 0, while Œ± and Œ≤ are regular everywhere. Invoking Proposition 6.18
we deduce f is C1 on (0, +‚àû), with derivative
f ‚Ä≤(x) = ‚àí
 x2
x
ye‚àíxy2 dy + g(x, x2) 2x ‚àíg(x, x)
= e‚àíxy2
y

y=x2
y=x + 2
x e‚àíx5 ‚àí1
x e‚àíx3 = 5
2xe‚àíx5 ‚àí3
2xe‚àíx3 .
Using this we can deduce the behaviour of f around the point x0 = 1. Firstly,
f(1) = 0 and f ‚Ä≤(1) = e‚àí1; secondly, diÔ¨Äerentiating f ‚Ä≤(x) once more gives f ‚Ä≤‚Ä≤(1) =
‚àí7e‚àí1. Therefore
f(x) = 1
e (x ‚àí1) ‚àí7
2e(x ‚àí1)2 + o

(x ‚àí1)2
,
x ‚Üí1 ,
implying f is positive, increasing and concave around x0.
2

6.5 Regular curves
217
T(t)
S(t)
œÉ
Œ≥(t)
PŒît = Œ≥(t0 + Œît)
Œ≥‚Ä≤(t0)
P0 = Œ≥(t0)
Figure 6.2. Tangent and secant vectors to a curve at P0
6.5 Regular curves
Curves were introduced in Sect. 4.6. A curve Œ≥ : I ‚ÜíRm is said diÔ¨Äerentiable
if its components xi : I ‚ÜíR, i ‚â§i ‚â§m, are diÔ¨Äerentiable on I (recall a map
is diÔ¨Äerentiable on an interval I if diÔ¨Äerentiable at all interior points of I, and
at the end-points of I where present). We denote by Œ≥‚Ä≤ : I ‚ÜíRm the derivative
Œ≥‚Ä≤(t) =

x‚Ä≤
i(t)

1‚â§i‚â§m = "m
i=1 x‚Ä≤
i(t)ei.
DeÔ¨Ånition 6.20 A curve Œ≥ : I ‚ÜíRm is regular if it is diÔ¨Äerentiable on I
with continuous derivative (the components are C1 on I) and if Œ≥‚Ä≤(t) Ã∏= 0, for
any t ‚ààI.
A curve Œ≥ : I ‚ÜíRm is piecewise regular if I is the Ô¨Ånite union of intervals
on which Œ≥ is regular.
If Œ≥ is a regular curve and t0 ‚ààI, we can interpret the vector Œ≥‚Ä≤(t0) geomet-
rically (Fig. 6.2). Calling P0 = Œ≥(t0) and taking t0 + Œît ‚ààI such that the point
PŒît = Œ≥(t0 + Œît) is distinct from P0, we consider the lines through P0 and PŒît;
by (4.26), a secant line can be parametrised as
S(t) = P0 +

PŒît ‚àíP0
t ‚àít0
Œît
= Œ≥(t0) + Œ≥(t0 + Œît) ‚àíŒ≥(t0)
Œît
(t ‚àít0) .
(6.17)
Letting now Œît tend to 0, the point PŒît moves towards P0 (in the sense that each
component of PŒît tends to the corresponding component of P0). Meanwhile, the
vector œÉ = œÉ(t0, Œî t) = Œ≥(t0 + Œît) ‚àíŒ≥(t0)
Œît
tends to Œ≥‚Ä≤(t0) by regularity.

218
6 DiÔ¨Äerential calculus for vector-valued functions
The limit position of (6.17) is thus
T (t) = Œ≥(t0) + Œ≥‚Ä≤(t0)(t ‚àít0) ,
t ‚ààR ,
the tangent line to the trace of the curve at P0. For this reason we introduce
DeÔ¨Ånition 6.21 Let Œ≥ : I ‚ÜíRm be a regular curve, and t0 ‚ààI. The vector
Œ≥‚Ä≤(t0) is called tangent vector to the trace of the curve at P0 = Œ≥(t0).
To be truly rigorous, the tangent vector at P0 is the position vector

P0, Œ≥‚Ä≤(t0)

,
but it is common practice to denote it by Œ≥‚Ä≤(t0). Later on we shall see the tangent
line at a point is an intrinsic object, and does not depend upon the chosen para-
metrisation; its length and orientation, instead, do depend on the parametrisation.
In kinematics, a curve in R3 models the trajectory of a point-particle occupying
the position Œ≥(t) at time t. When the curve is regular, Œ≥‚Ä≤(t) is the particle‚Äôs velocity
at the instant t.
Examples 6.22
i) All curves considered in Examples 4.34 are regular.
ii) Let œï : I ‚ÜíR denote a continuously-diÔ¨Äerentiable map on I; the curve
Œ≥(t) =

t,œï (t)

,
t ‚ààI ,
is regular, and has the graph of œï as trace. In fact,
Œ≥‚Ä≤(t) =

1, œï‚Ä≤(t)

Ã∏= (0, 0) ,
for any t ‚ààI .
iii) The arc Œ≥ : [0, 2] ‚ÜíR2 deÔ¨Åned by
Œ≥(t) =

(t, 1) ,
t ‚àà[0, 1) ,
(t, t) ,
t ‚àà[1, 2] ,
parametrises the polygonal path ABC (see Fig. 6.3, left); the arc
Œ≥(t) =
‚éß
‚é™
‚é®
‚é™
‚é©
(t, 1) ,
t ‚àà[0, 1) ,
(t, t) ,
t ‚àà[1, 2) ,

4 ‚àít, 2 ‚àí1
2(t ‚àí2)

,
t ‚àà[2, 4] ,
parametrises the path ABCA (Fig. 6.3, right). Both curves are piecewise regular.
iv) The curves
Œ≥(t) =

1 +
‚àö
2 cos t,
‚àö
2 sin t

,
t ‚àà[0, 2œÄ] ,
1Œ≥(t) =

1 +
‚àö
2 cos 2t, ‚àí
‚àö
2 sin 2t

,
t ‚àà[0, œÄ] ,
are diÔ¨Äerent parametrisations (counter-clockwise and clockwise, respectively) of
the same circle C, whose centre is (1, 0) and radius
‚àö
2.

6.5 Regular curves
219
1
1
2
A
B
C
O
1
1
2
A
B
C
O
Figure 6.3. The polygonal paths ABC (left) and ABCA (right) of Example 6.22 iii)
They are regular with derivatives
Œ≥‚Ä≤(t) =
‚àö
2

‚àísin t, cos t

,
1Œ≥‚Ä≤(t) = 2
‚àö
2

‚àísin 2t, ‚àícos2t

.
The point P0 = (0, 1) ‚ààC is the image under Œ≥ of t0 = 3
4œÄ, and of 1t0 = 5
8œÄ under
1Œ≥: P0 = Œ≥(t0) = 1Œ≥(1t0). In the Ô¨Årst case the tangent vector is Œ≥‚Ä≤(t0) = (‚àí1, ‚àí1)
and the tangent line at P0
T (t) = (0, 1) ‚àí(1, 1)

t ‚àí3
4œÄ

=

‚àít + 3
4œÄ, 1 ‚àít + 3
4œÄ

,
t ‚ààR ;
in the second case 1Œ≥‚Ä≤(1t0) = (2, 2) and
1T(t) = (0, 1) + (2, 2)

t ‚àí5
8œÄ

=

2(t ‚àí5
8œÄ), 1 + 2(t ‚àí5
8œÄ)

,
t ‚ààR .
The tangent vectors at P0 have diÔ¨Äerent length and orientation, but the same
direction. Recalling Example 4.34 i), in both cases y = 1 + x is the tangent line.
v) The curve Œ≥s : R ‚Üí[0, +‚àû) √ó R2, deÔ¨Åned in spherical coordinates by
Œ≥s(t) =

r(t), œï(t), Œ∏(t)

=

1, œÄ
2 (1 + 1
2 sin 8t), t

,
describes the periodic motion, on the unit sphere, of the point P(t) that re-
volves around the z-axis and simultaneously oscillates between the parallels of
colatitude œïmin = œÄ
4 and œïmax = 3
4œÄ (Fig. 6.4). The curve is regular, for
Œ≥‚Ä≤
s(t) = (0, 2œÄ cos 8t, 1) .
2

220
6 DiÔ¨Äerential calculus for vector-valued functions
 
 
 
 
 
 
 
 
x
y
z
Œì
t = 0
Figure 6.4. A point moving on a sphere (Example 6.22 v))
6.5.1 Congruence of curves; orientation
Now we discuss some useful relationships between curves parametrising the same
trace.
DeÔ¨Ånition 6.23 Let Œ≥ : I ‚ÜíRm and Œ¥ : J ‚ÜíRm be regular curves. They
are called congruent if there is a bijection œï : J ‚ÜíI, diÔ¨Äerentiable with
non-zero continuous derivative, such that
Œ¥ = Œ≥ ‚ó¶œï
(hence Œ¥(œÑ) = Œ≥

œï(œÑ)

for any œÑ ‚ààJ).
For the sequel we remark that congruent curves have the same trace, for x =
Œ¥(œÑ) if and only if x = Œ≥(t) with t = œï(œÑ). In addition, the tangent vectors at the
point P0 = Œ≥(t0) = Œ¥(œÑ0) are collinear, because diÔ¨Äerentiating Œ¥(œÑ) = Œ≥

œï(œÑ)

at
œÑ0 gives
Œ¥‚Ä≤(œÑ0) = Œ≥‚Ä≤
œï(œÑ0)

œï‚Ä≤(œÑ0) = Œ≥‚Ä≤(t0)œï‚Ä≤(œÑ0) ,
(6.18)
with œï‚Ä≤(œÑ0) Ã∏= 0. Consequently, the tangent line at P0 is the same for the two
curves.
The map œï, relating the congruent curves Œ≥, Œ¥ as in DeÔ¨Ånition 6.23, has œï‚Ä≤
always > 0 or always < 0 on J; in fact, by assumption œï‚Ä≤ is continuous and never
zero on J, hence has constant sign by the Theorem of Existence of Zeroes. This
entails we can divide congruent curves in two classes.
DeÔ¨Ånition 6.24 The congruent curves Œ≥ : I ‚ÜíRm, Œ¥ : J ‚ÜíRm are equi-
valent if the bijection œï : J ‚ÜíI has strictly positive derivative, while they
are anti-equivalent if œï‚Ä≤ is strictly negative.
Here is an example of two anti-equivalent curves.

6.5 Regular curves
221
DeÔ¨Ånition 6.25 Let Œ≥ : I ‚ÜíRm be a regular curve. Denoting by ‚àíI the
interval {t ‚ààR : ‚àít ‚ààI}, the curve ‚àíŒ≥ : ‚àíI ‚ÜíRm, (‚àíŒ≥)(t) = Œ≥(‚àít) is said
opposite to Œ≥, and is anti-equivalent to Œ≥.
We may write (‚àíŒ≥) = Œ≥ ‚ó¶œï, where œï : ‚àíI ‚ÜíI is the bijection œï(t) = ‚àít. If
Œ≥ : [a, b] ‚ÜíRm is a regular arc then ‚àíŒ≥ is still a regular arc deÔ¨Åned on the
interval [‚àíb, ‚àía].
If we take anti-equivalent curves Œ≥ and Œ¥ we may also write
Œ¥(œÑ) = Œ≥

œï(œÑ)

= Œ≥

‚àí(‚àíœï(œÑ))

= (‚àíŒ≥)

œà(œÑ)

where œà : J ‚Üí‚àíI, œà(œÑ) = ‚àíœï(œÑ). Since œà‚Ä≤(œÑ) = ‚àíœï‚Ä≤(œÑ) > 0, the curves Œ¥ and
(‚àíŒ≥) will be equivalent. In conclusion,
Property 6.26 Congruent curves are either equivalent or one is equivalent
to the opposite of the other.
Due to this observation we shall adopt the notation Œ¥ ‚àºŒ≥ to denote two
equivalent curves, and Œ¥ ‚àº‚àíŒ≥ for anti-equivalent ones.
By (6.18) now, equivalent curves have tangent vectors pointing in the same
direction, whereas anti-equivalent curves have opposite tangent vectors.
Assume from now on that curves are simple. It is immediate to verify that all
curves congruent to a simple curve are themselves simple. Moreover, one can prove
the following property.
Proposition 6.27 If Œì denotes the trace of a simple, regular curve Œ≥, any
other simple regular curve Œ¥ having Œì as trace is congruent to Œ≥.
Thus all parametrisations of Œì by simple regular curves are grouped into two
classes: two curves belong to the same class if they are equivalent, and live in
diÔ¨Äerent classes if anti-equivalent. To each class we associate an orientation of
Œì. Given any parametrisation of Œì in fact, we say the point P2 = Œ≥(t2) follows
P1 = Œ≥(t1) on Œ≥ if t2 > t1 (Fig. 6.5). Well, it is easy to see that if Œ¥ is equivalent
to Œ≥, P2 follows P1 also in this parametrisation, in other words P2 = Œ¥(œÑ2) and
P1 = Œ¥(œÑ1) with œÑ2 > œÑ1. Conversely, if Œ¥ is anti-equivalent to Œ≥, then P2 = Œ¥(œÑ2)
and P1 = Œ¥(œÑ1) with œÑ2 < œÑ1, so P1 will follow P2.
As observed earlier, the orientation of Œì can be also determined from the
orientation of its tangent vectors.
The above discussion explains why simple regular curves are commonly thought
of as geometrical objects, rather than as parametrisations, and often the two no-
tions are confused, on purpose. This motivates the following deÔ¨Ånition.

222
6 DiÔ¨Äerential calculus for vector-valued functions
x
y
z
P1
P2
Œì
Figure 6.5. An arc Œì in R3 and an orientation on it
DeÔ¨Ånition 6.28 A subset Œì of Rm is called a simple regular curve if it
can be described as the trace of a curve with the same properties.
If necessary one associates to Œì one of the two possible orientations. The choice
of Œì and of an orientation on it determine a class of simple regular curves all
equivalent to each other; within this class, one might select the most suitable
parametrisation for the speciÔ¨Åc needs.
Every deÔ¨Ånition and property stated for regular curves adapts easily to
piecewise-regular curves.
6.5.2 Length and arc length
We deÔ¨Åne the length of the regular arc Œ≥ : [a, b] ‚ÜíRm as the number
‚Ñì(Œ≥) =
 b
a
‚à•Œ≥‚Ä≤(t)‚à•dt =
 b
a
+
,
,
-
m

i=1

x‚Ä≤
i(t)
2 dt .
(6.19)
The reason is geometrical (see Fig. 6.6). We subdivide [a, b] using a = t0 < t1 <
. . . , tK‚àí1 < tK = b and consider the points Pk = Œ≥(tk) ‚ààŒì, k = 0, . . . , K. They
determine a polygonal path in Rm (possibly degenerate) whose length is
‚Ñì(t0, t1, . . . , tK) =
K

k=1
dist (Pk‚àí1, Pk) ,
where dist (Pk‚àí1, Pk) = ‚à•Pk ‚àíPk‚àí1‚à•is the Euclidean distance of two points. Note
‚à•Pk ‚àíPk‚àí1‚à•=
+
,
,
-
m

i=1

xi(tk) ‚àíxi(tk‚àí1)
2 =
+
,
,
-
m

i=1
	Œîxi
Œît

2
k
Œîtk

6.5 Regular curves
223
P0 = Œ≥(t0)
Pk‚àí1
Pk
PK = Œ≥(tK)
Figure 6.6. Approximation of the trace of an arc by a polygonal path
where Œîtk = tk ‚àítk‚àí1 and
	Œîxi
Œît

k
=
	xi(tk) ‚àíxi(tk‚àí1)
tk ‚àítk‚àí1

.
Therefore
‚Ñì(t0, t1, . . . , tK) =
K

k=1
+
,
,
-
m

i=1
	Œîxi
Œît

2
k
Œîtk ;
notice the analogy with the last integral in (6.19), of which the above is an approx-
imation. One could prove that if the curve is piecewise regular, the least upper
bound of ‚Ñì(t0, t1, . . . , tK) over all possible partitions of [a, b] is Ô¨Ånite, and equals
‚Ñì(Œ≥).
The length (6.19) of an arc depends not only on the trace Œì, but also on the
chosen parametrisation. For example, parametrising the circle x2 + y2 = r2 by
Œ≥1(t) = (r cos t, r sin t), t ‚àà[0, 2œÄ], we have
‚Ñì(Œ≥1) =
 2œÄ
0
r dt = 2œÄr ,
as is well known from elementary geometry. But if we take Œ≥2(t) = (r cos 2t, r sin 2t),
t ‚àà[0, 2œÄ], then
‚Ñì(Œ≥2) =
 2œÄ
0
2r dt = 4œÄr .
In the latter case we went around the origin twice. Recalling (6.18), it is easy to
see that two congruent arcs have the same length (see also Proposition 9.3 below,
where f = 1). We shall prove in Sect. 9.1 that the length of a simple (or Jordan)
arc depends only upon the trace Œì; it is called length of Œì, and denoted by ‚Ñì(Œì).

224
6 DiÔ¨Äerential calculus for vector-valued functions
In the previous example Œ≥1 is simple while Œ≥2 is not; the length ‚Ñì(Œì) of the circle
is ‚Ñì(Œ≥1).
Let Œ≥ be a regular curve deÔ¨Åned on the interval I, on which we Ô¨Åx an arbitrary
point t0 ‚ààI, and introduce the function s : I ‚ÜíR
s(t) =
 t
t0
‚à•Œ≥‚Ä≤(œÑ)‚à•dœÑ .
(6.20)
Recalling expression (6.19) for the length of an arc, we have
s(t) =
‚éß
‚é®
‚é©
‚Ñì(Œ≥|[t0,t]) ,
t > t0 ,
0 ,
t = t0 ,
‚àí‚Ñì(Œ≥|[t,t0]) ,
t < t0 .
The function s allows to deÔ¨Åne an equivalent curve that gives a new paramet-
risation of the trace of Œ≥. By the Fundamental Theorem of Integral Calculus, in
fact,
s‚Ä≤(t) = ‚à•Œ≥‚Ä≤(t)‚à•> 0 ,
‚àÄt ‚ààI ,
so s is a strictly increasing map, and hence invertible on I. Call J = s(I) the
image interval under s, and let t : J ‚ÜíI ‚äÜR be the inverse map of s. In
other terms we write t as a function of another parameter s, t = t(s). The curve
1Œ≥ : J ‚ÜíRm, 1Œ≥(s) = Œ≥(t(s)) is equivalent to Œ≥ (in particular it has the same trace
Œì). If P1 = Œ≥(t1) is an arbitrary point on Œì, then P1 = 1Œ≥(s1) with t1 and s1
related by t1 = t(s1). The number s1 is the arc length of P1.
Recalling the rule for diÔ¨Äerentiating an inverse function,
1Œ≥‚Ä≤(s) = d1Œ≥
ds (s) = dŒ≥
dt

t(s)
 dt
ds(s) =
Œ≥‚Ä≤(t)
‚à•Œ≥‚Ä≤(t)‚à•,
whence
‚à•1Œ≥‚Ä≤(s)‚à•= 1 ,
‚àÄs ‚ààJ .
(6.21)
This means that the arc length parametrises the curve with constant ‚Äúspeed‚Äù 1.
The deÔ¨Ånitions of length of an arc and arc length extend to piecewise-regular
curves.
Example 6.29
The curve Œ≥ : R ‚ÜíR3, Œ≥(t) = (cos t, sin t, t) has trace the circular helix (see
Example 4.34 vi)). Then
‚à•Œ≥‚Ä≤(t)‚à•= ‚à•(‚àísin t, cos t, 1)‚à•= (sin2 t + cos2 t + 1)1/2 =
‚àö
2 .
Choosing t0 = 0,
s(t) =
 t
0
‚à•Œ≥‚Ä≤(œÑ)‚à•dœÑ =
‚àö
2
 t
0
dœÑ =
‚àö
2t .

6.5 Regular curves
225
Therefore t = t(s) =
‚àö
2
2 s, s ‚ààR, and the helix can be parametrised anew by arc
length
1Œ≥(s) =

cos
‚àö
2
2 s, sin
‚àö
2
2 s,
‚àö
2
2 s

.
2
6.5.3 Elements of diÔ¨Äerential geometry for curves
This section is dedicated to the intrinsic geometry of curves in R3, and is not
strictly essential for the sequel. As such it may be skipped at Ô¨Årst reading.
We consider a regular, simple curve Œì in R3 parametrised by arc length s
(deÔ¨Åned from an origin point P ‚àó). Call Œ≥ = Œ≥(s) such parametrisation, deÔ¨Åned on
an interval J ‚äÜR, and suppose Œ≥ is of class C2 on J.
If t(s) = Œ≥‚Ä≤(s) is the tangent vector to Œì at P = Œ≥(s), by (6.21) we have
‚à•t(s)‚à•= 1 ,
‚àÄs ‚ààJ ,
making t(s) a unit vector. DiÔ¨Äerentiating once more in s gives t‚Ä≤(s) = Œ≥‚Ä≤‚Ä≤(s), a
vector orthogonal to t(s); in fact diÔ¨Äerentiating
‚à•t(s)‚à•2 =
3

i=1
t2
i (s) = 1 ,
‚àÄs ‚ààJ ,
we Ô¨Ånd
2
3

i=1
ti(s)t‚Ä≤
i(s) = 0 ,
i.e., t(s) ¬∑ t‚Ä≤(s) = 0. Recall now that if Œ≥(s) is the trajectory of a point-particle
in time, its velocity t(s) has constant speed = 1. Therefore t‚Ä≤(s) represents the
acceleration, and depends exclusively on the change of direction of the velocity
vector. Thus the acceleration is perpendicular to the direction of motion.
If at P0 = Œ≥(s0) the vector t‚Ä≤(s0) is not zero, we may deÔ¨Åne
n(s0) =
t‚Ä≤(s0)
‚à•t‚Ä≤(s0)‚à•,
(6.22)
called principal normal (vector) to Œì at P0. The orthonormal vectors t(s0) and
n(s0) lie on a plane passing through P0, the osculating plane to the curve Œì at
P0. Among all planes passing through P0, the osculating plane is the one that best
adapts to the curve; to be precise, the distance of a point Œ≥(s) on the curve from
the osculating plane is inÔ¨Ånitesimal of order bigger than s ‚àís0, as s ‚Üís0. The
osculating plane of a plane curve is, at each point, the plane containing the curve.
The orientation of the principal normal has to do with the curve‚Äôs convexity
(Fig. 6.7). If the curve is plane, in the frame system of t and n the curve can be
represented around P0 as the graph of a convex function.

226
6 DiÔ¨Äerential calculus for vector-valued functions
 
 
P0 = Œ≥(s0)
Œì
Œ†
n
t
b
Figure 6.7. Osculating plane and tangent, normal, binormal vectors of Œì at P0
The number K(s0) = ‚à•t‚Ä≤(s0)‚à•is the curvature of Œì at P0, and its inverse R(s0)
is called curvature radius. These names arise from the following considerations.
For simplicity suppose the curve is plane, and let us advance by R(s0) in the
direction of n, starting from P0(s0); the point C(s0) thus reached is the centre
of curvature (Fig. 6.8). The circle with centre C(s0) and radius R(s0) is tangent
to Œì at P0, and among all tangent circles we are considering the one that best
approximates the curve around P0 (osculating circle).
The orthogonal vector to the osculating plane,
b(s0) = t(s0) ‚àßn(s0) ,
(6.23)
is known as the binormal (vector) to Œì at P0. This completes a positively-oriented
triple (t, n, b) of orthonormal vectors, that deÔ¨Ånes a moving frame along a curve.
The binormal unit vector, being orthogonal to the osculating plane, is constant
along the curve if the latter is plane. Therefore, its variation measures how far the
curve is from being plane. If the curve is C3 it makes sense to consider the vector
b‚Ä≤(s0), the torsion vector of the curve at P0. DiÔ¨Äerentiating deÔ¨Ånition (6.23)
gives
b‚Ä≤(s0) = t‚Ä≤(s0) ‚àßn(s0) + t(s0) ‚àßn‚Ä≤(s0) = t(s0) ‚àßn‚Ä≤(s0)
as n(s0) is parallel to t‚Ä≤(s0). This explains why n‚Ä≤(s0) is orthogonal to t(s0). At
the same time, diÔ¨Äerentiating ‚à•b(s0)‚à•2 = 1 gives b‚Ä≤(s0) ¬∑ b(s0) = 0, making b‚Ä≤(s0)
orthogonal to b(s0) as well. Therefore b‚Ä≤(s0) is parallel to n(s0), and there must
exist a scalar œÑ(s0), called torsion of the curve, such that b‚Ä≤(s0) = œÑ(s0)n(s0). It
turns out that a curve is plane if and only if the torsion vanishes identically.
DiÔ¨Äerentiating the equation n(s) = b(s) ‚àßt(s) gives
n‚Ä≤(s0) = b(s0) ‚àßt‚Ä≤(s0) + b‚Ä≤(s0) ‚àßt(s0)
= b(s0) ‚àßK(s0)n(s0) + œÑ(s0)n(s0) ‚àßt(s0)
= ‚àíK(s0)t(s0) ‚àíœÑ(s0)b(s0) .

6.6 Variable changes
227
P0 = Œ≥(s0)
Œ†
n
t
R(s0)
C(s0)
Figure 6.8. Osculating circle, centre and radius of curvature at P0
To summarise, the unit vectors t, n, b of a C3 curve Œì satisfy the Frenet formulas
t‚Ä≤ = Kn ,
n‚Ä≤ = ‚àíKt ‚àíœÑb ,
b‚Ä≤ = œÑn .
(6.24)
We conclude by pointing out that the vectors t, n, b admit a representation in
terms of an arbitrary parametrisation of Œì.
6.6 Variable changes
Let R be a region of Rn. The generic point P ‚ààR is completely determined by its
Cartesian coordinates x1, x2, . . . , xn which, as components of a vector x, allow to
identify P = x. For i = 1, . . . , n the line
Ri = x + Rei = {xt = (x1, . . . , xi‚àí1, xi + t, xi+1, . . . , xn) : t ‚ààR}
contains P and is parallel to the ith canonical unit vector ei. Thus the lines Ri,
called coordinate lines through P, are mutually orthogonal.
DeÔ¨Ånition 6.30 Let R‚Ä≤ be another region of Rn, with interior A‚Ä≤. A vector
Ô¨Åeld Œ¶ : R‚Ä≤ ‚ÜíR deÔ¨Ånes a change of variables, or change of coordinates,
on R if Œ¶ is:
i) a bijective map between R‚Ä≤ and R;
ii) of class C1 on A‚Ä≤;
iii) regular on A‚Ä≤, or equivalently, the Jacobian JŒ¶ is non-singular everywhere
on A‚Ä≤.

228
6 DiÔ¨Äerential calculus for vector-valued functions
u1
u2
Q0
R‚Ä≤
u01
u02
Œ¶
x1
x2
P0
x01
x02
œÑ1
œÑ2
Œì1
R
Œì2
Figure 6.9. Change of variables in R
Let A indicate the image Œ¶(A‚Ä≤): then it is possible to prove that A is open, and
consequently A ‚äÜ
‚ó¶
R; furthermore, Œ¶(‚àÇR‚Ä≤) = Œ¶(‚àÇA‚Ä≤) is contained in R \ A.
Denote by Q = u the generic point of R‚Ä≤, with Cartesian coordinates
u1, . . . , un. Given P0 = x0 ‚ààA, part i) implies there exists a unique point
Q0 = u0 ‚ààA‚Ä≤ such that P0 = Œ¶(Q0), or x0 = Œ¶(u0). Thus we may determ-
ine P0, besides by its Cartesian coordinates x01, . . . , x0n, also by the Cartesian
coordinates u01, . . . , u0n of Q0; the latter are called curvilinear coordinates of
P0 (relative to the transformation Œ¶). The coordinate lines through Q0 produce
curves in R passing through P0. Precisely, the set
Œìi = {x = Œ¶(u0 + tei) : u0 + tei ‚ààR‚Ä≤ with t ‚ààIi} ,
where i = 1, . . . , n and Ii is an interval containing the origin, is the trace of the
curve (simple, by i))
t ‚ÜíŒ≥i(t) = Œ¶(u0 + tei)
deÔ¨Åned on Ii. These sets are the coordinate lines through the point P0 (relative
to Œ¶); see Fig. 6.9.
If P0 ‚ààA these are regular curves (by iii)), so tangent vectors at P0 exist
œÑi = Œ≥‚Ä≤
i(0) = JŒ¶(u0) ¬∑ ei = ‚àÇŒ¶
‚àÇui
(u0) ,
1 ‚â§i ‚â§n .
(6.25)
They are the columns of the Jacobian matrix of Œ¶ at u0. (Warning: the reader
should pay attention not to confuse these with the row vectors ‚àáœïi(u0), which are
the gradients of the components of Œ¶ = (œïi)1‚â§i‚â§n.) Therefore by iii), the vectors
œÑi, 1 ‚â§i ‚â§n, are linearly independent (hence, non-zero), and so they form a basis
of Rn. We shall denote by ti = œÑi/‚à•œÑi‚à•the corresponding unit vectors. If at every
P0 ‚ààA the tangent vectors are orthogonal, i.e., if the matrix JŒ¶(u0)T JŒ¶(u0) is
diagonal, the change of variables will be called orthogonal. If so, {t1, . . . , tn} will
be an orthonormal basis of Rn relative to the point P0.

6.6 Variable changes
229
Properties ii) and iii) have yet another important consequence. The map u ‚Üí
det JŒ¶(u) is continuous on A‚Ä≤ because the determinant depends continuously upon
the matrix‚Äô entries; moreover, det JŒ¶(u) Ã∏= 0 for any u ‚ààA‚Ä≤. We therefore deduce
det JŒ¶(u) > 0 ,
‚àÄu ‚ààA‚Ä≤ ,
or
det JŒ¶(u) < 0 ,
‚àÄu ‚ààA‚Ä≤ .
(6.26)
In fact, if det JŒ¶ were both positive and negative on A‚Ä≤, which is open and con-
nected, then Theorem 4.30 would necessarily force the determinant to vanish at
some point of A‚Ä≤, contradicting iii).
Now we focus on low dimensions. In dimension 2, the Ô¨Årst (second, respectively)
of (6.26) says that for any u0 ‚ààA‚Ä≤ the vector œÑ1 can be aligned to œÑ2 by a
counter-clockwise (clockwise) rotation of Œ∏ ‚àà(0, œÄ]. Identifying in fact each œÑi with
ÀúœÑi = œÑi + 0k ‚ààR3, we have
ÀúœÑ1 ‚àßÀúœÑ2 =

det JŒ¶(u0)

k ,
(6.27)
orienting the triple (ÀúœÑ1, ÀúœÑ2, k) positively (negatively).
In dimension 3, the triple (œÑ1, œÑ2, œÑ3) is positively-oriented (negatively-oriented)
if the Ô¨Årst (second) of (6.26) holds; in fact, (œÑ1 ‚àßœÑ2) ¬∑ œÑ3 = det JŒ¶(u0).
Changes of variable on a region in Rn are of two types, depending on the
sign of the Jacobian determinant. If the sign is plus, the variable change is said
orientation-preserving, if the sign is minus, orientation-reversing.
Example 6.31
The map
x = Œ¶(u) = Au + b ,
with A a non-singular matrix of order n, deÔ¨Ånes an aÔ¨Éne change of variables
in Rn. For example, the change in the plane (x = (x, y), u = (u, v))
x =
1
‚àö
2
(v + u) + 2 ,
y =
1
‚àö
2
(v ‚àíu) + 1 ,
is a translation of the origin to the point (2, 1), followed by a counter-clockwise
rotation of the axes by œÄ/4 (Fig. 6.10). The coordinate lines u = constant (v =
constant) are parallel to the bisectrix of the Ô¨Årst and third quadrant (resp. second
and fourth).
x
y
u
v
1
2
Figure 6.10. AÔ¨Éne change of variables in the plane

230
6 DiÔ¨Äerential calculus for vector-valued functions
The new frame system is still orthogonal, conÔ¨Årmed by the matrix
A =

1
‚àö
2
1
‚àö
2
‚àí1
‚àö
2
1
‚àö
2

,
which is orthogonal since AT A = I. (In general, an aÔ¨Éne change of variables
is orthogonal if the associated matrix is orthogonal.) The change preserves the
orientation, for det A = 1 > 0.
2
6.6.1 Special frame systems
We examine the changes of variables associated to relevant transformations of the
plane and of space.
i) Polar coordinates. Denote
Œ¶ : [0, +‚àû) √ó R ‚ÜíR2 ,
(r,Œ∏ ) ‚Üí(x, y) = (r cosŒ∏, r sin Œ∏)
the map transforming polar coordinates into Cartesian ones (Fig. 6.11, left). It is
diÔ¨Äerentiable, and its Jacobian
JŒ¶(r,Œ∏ ) =
 ‚àÇx
‚àÇr
‚àÇx
‚àÇŒ∏
‚àÇy
‚àÇr
‚àÇy
‚àÇŒ∏

=
	 cos Œ∏
‚àír sin Œ∏
sin Œ∏
r cos Œ∏

(6.28)
has determinant
det JŒ¶(r,Œ∏ ) = r cos2 Œ∏ + r sin2 Œ∏ = r .
(6.29)
Its positivity on (0, +‚àû) √ó R makes the Jacobian invertible; in terms of r and Œ∏,
we have
JŒ¶(r,Œ∏ )‚àí1 =
 ‚àÇr
‚àÇx
‚àÇr
‚àÇy
‚àÇŒ∏
‚àÇx
‚àÇŒ∏
‚àÇy

=
 cos Œ∏
sin Œ∏
‚àísin Œ∏
r
cos Œ∏
r

.
(6.30)
Therefore, Œ¶ is a change of variables in the plane if we choose, for example, R = R2
and R‚Ä≤ = (0, +‚àû) √ó (‚àíœÄ,œÄ ] ‚à™{(0, 0)}. The interior A‚Ä≤ = (0, +‚àû) √ó (‚àíœÄ,œÄ ) has
open image under Œ¶ given by A = R2 \ {(x, 0) ‚ààR2 : x ‚â§0}, the plane minus
the negative x-axis. The change is orthogonal, as JŒ¶T JŒ¶ = diag (1, r2), and
preserves the orientation, because det JŒ¶ > 0 on A‚Ä≤.
Rays emanating from the origin (for Œ∏ constant) and circles centred at the origin
(r constant) are the coordinate lines. The tangent vectors œÑi, i = 1, 2, columns of
JŒ¶, will henceforth be indicated by œÑr, œÑŒ∏ and written as row vectors
œÑr = (cos Œ∏, sin Œ∏) ,
œÑŒ∏ = r(‚àísin Œ∏, cos Œ∏) .
Normalising the second one we obtain an orthonormal basis of R2
tr = (cos Œ∏, sin Œ∏) ,
tŒ∏ = (‚àísin Œ∏, cos Œ∏)
(6.31)

6.6 Variable changes
231
O
x
y
r
Œ∏
P = (x, y)
y
x
0
P0
i
j
tŒ∏
tr
Figure 6.11. Polar coordinates in the plane (left); coordinate lines and unit tangent
vectors (right)
formed by the unit tangent vectors to the coordinate lines, at each point P ‚àà
R2 \ {(0, 0)} (Fig. 6.11, right).
Take a scalar map f(x, y) deÔ¨Åned on a subset of R2 not containing the origin.
In polar coordinates it will be
Àúf(r,Œ∏ ) = f(r cos Œ∏, r sin Œ∏) ,
or Àúf = f‚ó¶Œ¶. Supposing f diÔ¨Äerentiable on its domain, the chain rule (Theorem 6.14
or, more precisely, formula (6.12)) gives
‚àá(r,Œ∏) Àúf = ‚àáf(x,y) JŒ¶ ,
whose inverse is ‚àáf(x,y) = ‚àá(r,Œ∏) Àúf JŒ¶‚àí1. Dropping the symbol ‚àºfor simplicity,
those identities become, by (6.28), (6.30),
‚àÇf
‚àÇr = ‚àÇf
‚àÇx cos Œ∏ + ‚àÇf
‚àÇy sin Œ∏ ,
‚àÇf
‚àÇŒ∏ = ‚àí‚àÇf
‚àÇxr sin Œ∏ + ‚àÇf
‚àÇy r cos Œ∏
(6.32)
and
‚àÇf
‚àÇx = ‚àÇf
‚àÇr cos Œ∏ ‚àí‚àÇf
‚àÇŒ∏
sin Œ∏
r
,
‚àÇf
‚àÇy = ‚àÇf
‚àÇr sin Œ∏ + ‚àÇf
‚àÇŒ∏
cos Œ∏
r
.
(6.33)
Any vector Ô¨Åeld g(x, y) = g1(x, y)i + g2(x, y)j on a subset of R2 without the
origin can be written, at each point (x, y) = (r cos Œ∏, r sin Œ∏) of the domain, using
the basis {tr, tŒ∏}:
g = grtr + gŒ∏tŒ∏
(6.34)
(here and henceforth the subscripts r, Œ∏ do not denote partial derivatives, rather
components).

232
6 DiÔ¨Äerential calculus for vector-valued functions
As the basis is orthonormal,
gr = g ¬∑ tr = (g1i + g2j) ¬∑ tr = g1 cos Œ∏ + g2 sin Œ∏ ,
gŒ∏ = g ¬∑ tŒ∏ = (g1i + g2j) ¬∑ tŒ∏ = ‚àíg1 sin Œ∏ + g2 cos Œ∏ .
(6.35)
In particular, if g is the gradient of a diÔ¨Äerentiable function, grad f = ‚àÇf
‚àÇxi+ ‚àÇf
‚àÇy j,
by (6.32) we have
gr = ‚àÇf
‚àÇx cos Œ∏ + ‚àÇf
‚àÇy sin Œ∏ = ‚àÇf
‚àÇr ,
gŒ∏ = ‚àí‚àÇf
‚àÇx sin Œ∏ + ‚àÇf
‚àÇy cos Œ∏ = 1
r
‚àÇf
‚àÇŒ∏ ;
therefore the gradient in polar coordinates reads
grad f = ‚àÇf
‚àÇr tr + 1
r
‚àÇf
‚àÇŒ∏ tŒ∏ .
(6.36)
The divergence of a diÔ¨Äerentiable vector Ô¨Åeld g in polar coordinates is, similarly,
div g = ‚àÇg1
‚àÇx + ‚àÇg2
‚àÇy = ‚àÇg1
‚àÇr cos Œ∏ ‚àí‚àÇg1
‚àÇŒ∏
sin Œ∏
r
+ ‚àÇg2
‚àÇr sin Œ∏ + ‚àÇg2
‚àÇŒ∏
cos Œ∏
r
= ‚àÇ
‚àÇr (g1 cos Œ∏ + g2 sin Œ∏)+ 1
r
‚àÇ
‚àÇŒ∏(‚àíg1 sin Œ∏ + g2 cos Œ∏)+(g1 cos Œ∏ + g2 sin Œ∏)

;
using (6.34) and (6.35), we Ô¨Ånd
div g = ‚àÇgr
‚àÇr + 1
r gr + 1
r
‚àÇgŒ∏
‚àÇŒ∏ .
(6.37)
Combining this with (6.36) yields the polar representation of the Laplacian Œîf of
a C2 map on a plane region without the origin. Setting g = grad f in (6.37),
Œîf = ‚àÇ2f
‚àÇr2 + 1
r
‚àÇf
‚àÇr + 1
r2
‚àÇ2f
‚àÇŒ∏2 .
(6.38)
Let us return to (6.34), and notice that ‚Äì in contrast to the canonical unit
vectors i, j ‚Äì the unit vectors tr, tŒ∏ vary from point to point; from (6.31), in
particular, follow
‚àÇtr
‚àÇr = 0 ,
‚àÇtr
‚àÇŒ∏ = tŒ∏ ;
‚àÇtŒ∏
‚àÇr = 0 ,
‚àÇtŒ∏
‚àÇŒ∏ = ‚àítr .
(6.39)
To diÔ¨Äerentiate g with respect to r and Œ∏ then, we will use the usual product rule
‚àÇg
‚àÇr = ‚àÇgr
‚àÇr tr + ‚àÇgŒ∏
‚àÇr tŒ∏ ,
‚àÇg
‚àÇŒ∏ =
‚àÇgr
‚àÇŒ∏ ‚àígŒ∏

tr +
‚àÇgŒ∏
‚àÇŒ∏ + gr

tŒ∏ .

6.6 Variable changes
233
ii) Cylindrical coordinates. Consider the C‚àûtransformation
Œ¶ : [0, +‚àû) √ó R2 ‚ÜíR3 ,
(r, Œ∏, t) ‚Üí(x, y, z) = (r cos Œ∏, r sin Œ∏, t)
describing the passage from cylindrical to Cartesian coordinates (Fig. 6.12, left).
The Jacobian
JŒ¶(r, Œ∏, t) =
‚éõ
‚éù
cos Œ∏
‚àír sin Œ∏
0
sin Œ∏
r cos Œ∏
0
0
0
1
‚éû
‚é†
(6.40)
has determinant
det JŒ¶(r, Œ∏, t) = r ,
(6.41)
strictly positive on (0, +‚àû)√óR2, so the matrix is invertible. Moreover, JŒ¶T JŒ¶ =
diag (1, r2, 1).
Thus Œ¶ is an orthogonal, orientation-preserving change of coordinates from
R‚Ä≤ = (0, +‚àû) √ó (‚àíœÄ,œÄ ] √ó R ‚à™{(0, 0, t) : t ‚ààR} to R = R3. The interior of
R‚Ä≤ is A‚Ä≤ = (0, +‚àû) √ó (‚àíœÄ,œÄ ) √ó R, whose image under Œ¶ is the open set A =
R3 \ {(x, 0, z) ‚ààR3 : x ‚â§0, z ‚ààR}, the whole space minus half a plane.
The coordinate lines are: horizontal rays emanating from the z-axis, horizontal
circles centred along the z-axis, and vertical lines. The corresponding unit tangent
vectors at P ‚ààR3 \ {(0, 0, z) : z ‚ààR} are, with the obvious notations,
tr = (cos Œ∏, sin Œ∏, 0) ,
tŒ∏ = (‚àísin Œ∏, cos Œ∏, 0) ,
tt = (0, 0, 1) .
(6.42)
They form an orthonormal frame at P (Fig. 6.12, right).
A scalar map f(x, y, z), diÔ¨Äerentiable on a subset of R3 not containing the axis
z, is
Àúf(r, Œ∏, t) = f(r cos Œ∏, r sin Œ∏, t) ;
x
O
y
z
r
Œ∏
P = (x, y, z)
P ‚Ä≤ = (x, y, 0)
y
x
z
O
P0
i
j
k
tŒ∏
tt
tr
Figure 6.12. Cylindrical coordinates in space (left); coordinate lines and unit tangent
vectors (right)

234
6 DiÔ¨Äerential calculus for vector-valued functions
spelling out ‚àá(r,Œ∏,t) Àúf = ‚àáf(x,y,z)JŒ¶ gives
‚àÇf
‚àÇr = ‚àÇf
‚àÇx cos Œ∏ + ‚àÇf
‚àÇy sin Œ∏ ,
‚àÇf
‚àÇŒ∏ = ‚àí‚àÇf
‚àÇxr sin Œ∏ + ‚àÇf
‚àÇy r cos Œ∏ ,
‚àÇf
‚àÇt = ‚àÇf
‚àÇz .
The inverse formulas are
‚àÇf
‚àÇx = ‚àÇf
‚àÇr cos Œ∏ ‚àí‚àÇf
‚àÇŒ∏
sin Œ∏
r
,
‚àÇf
‚àÇy = ‚àÇf
‚àÇr sin Œ∏ + ‚àÇf
‚àÇŒ∏
cos Œ∏
r
,
‚àÇf
‚àÇz = ‚àÇf
‚àÇt .
At last, this is how the basic diÔ¨Äerential operators look like in cylindrical coordin-
ates
grad f = ‚àÇf
‚àÇr tr + 1
r
‚àÇf
‚àÇŒ∏ tŒ∏ + ‚àÇf
‚àÇt tt ,
div f = ‚àÇfr
‚àÇr + 1
r fr + 1
r
‚àÇfŒ∏
‚àÇŒ∏ + ‚àÇft
‚àÇt ,
curl f =
1
r
‚àÇft
‚àÇŒ∏ ‚àí‚àÇfŒ∏
‚àÇt

tr +
‚àÇfr
‚àÇt ‚àí‚àÇft
‚àÇr

tŒ∏ +
‚àÇfŒ∏
‚àÇr ‚àí1
r
‚àÇfr
‚àÇŒ∏ + 1
r fŒ∏

tt ,
Œîf = ‚àÇ2f
‚àÇr2 + 1
r
‚àÇf
‚àÇr + 1
r2
‚àÇ2f
‚àÇŒ∏2 + ‚àÇ2f
‚àÇt2 .
iii) Spherical coordinates. The function
Œ¶ : [0, +‚àû) √ó R2 ‚ÜíR3 ,
(r, œï,Œ∏ ) ‚Üí(x, y, z) = (r sin œï cos Œ∏, r sin œï sin Œ∏, r cos œï)
is diÔ¨Äerentiable inÔ¨Ånitely many times, and describes the passage from spherical
coordinates to Cartesian coordinates (Fig. 6.13, left). As
JŒ¶(r, œï,Œ∏ ) =
‚éõ
‚éú
‚éù
sin œï cos Œ∏
r cos œï cos Œ∏
‚àír sin œï sin Œ∏
sin œï sin Œ∏
r cos œï sin Œ∏
r sin œï cos Œ∏
cos œï
‚àír sin œï
0
‚éû
‚éü
‚é†,
(6.43)
we compute the determinant by expanding along the last row; recalling sin2 Œ∏ +
cos2 Œ∏ = 1 and sin2 œï + cos2 œï = 1, we Ô¨Ånd
det JŒ¶(r, œï,Œ∏ ) = r2 sin œï ,
(6.44)
strictly positive on (0, +‚àû)√ó(0, œÄ)√óR. The Jacobian is invertible on that domain.
Furthermore, JŒ¶T JŒ¶ = diag (1, r(cos2 œï + r sin2 œï), r2 sin œï).
Then Œ¶ is an orthogonal, orientation-preserving change of variables mapping
R‚Ä≤ = (0, +‚àû) √ó [0, œÄ] √ó (‚àíœÄ,œÄ ] ‚à™{(0, 0, 0)} onto R = R3. The interior of R‚Ä≤

6.6 Variable changes
235
x
O
y
z
r
Œ∏
œï
P = (x, y, z)
P ‚Ä≤ = (x, y, 0)
y
x
z
O
P0
i
j
k
tŒ∏
tœï
tr
Figure 6.13. Spherical coordinates in space (left); coordinate lines and unit tangent
vectors (right)
is A‚Ä≤ = (0, +‚àû) √ó (0, œÄ) √ó (‚àíœÄ,œÄ ), whose image is in turn the open set A =
R3 \ {(x, 0, z) ‚ààR3 : x ‚â§0, z ‚ààR}, as for cylindrical coordinates.
There are three types of coordinate lines, namely rays from the origin, vertical
half-circles centred at the origin (the Earth‚Äôs meridians), and horizontal circles
centred on the z-axis (the parallels). The unit tangent vectors at P ‚ààR3\{(0, 0, 0)}
result from normalising the columns of JŒ¶
tr = (sin œï cos Œ∏, sin œï sin Œ∏, cos œï) ,
tœï = (cos œï cos Œ∏, cos œï sin Œ∏, ‚àísin œï) ,
tŒ∏ = (‚àísin Œ∏, cos Œ∏, 0) .
(6.45)
They are an orthonormal basis of R3 at the point P (Fig. 6.13, right).
Given a scalar map f(x, y, z), diÔ¨Äerentiable away from the origin, in spherical
coordinates
Àúf(r, œï,Œ∏ ) = f(r sin œï cos Œ∏, r sin œï sin Œ∏, r cos œï) ,
we express ‚àá(r,œï,Œ∏) Àúf = ‚àáf(x,y,z)JŒ¶ (dropping ‚àº) as
‚àÇf
‚àÇr = ‚àÇf
‚àÇx sin œï cos Œ∏ + ‚àÇf
‚àÇy sin œï sin Œ∏ + ‚àÇf
‚àÇz cos œï
‚àÇf
‚àÇœï = ‚àÇf
‚àÇxr cos œï cos Œ∏ + ‚àÇf
‚àÇy r cos œï sin Œ∏ ‚àí‚àÇf
‚àÇz r sin œï
‚àÇf
‚àÇŒ∏ = ‚àí‚àÇf
‚àÇxr sin œï sin Œ∏ + ‚àÇf
‚àÇy r sin œï cos Œ∏ .

236
6 DiÔ¨Äerential calculus for vector-valued functions
The inverse relationships read
‚àÇf
‚àÇx = ‚àÇf
‚àÇr sin œï cos Œ∏ + ‚àÇf
‚àÇœï
cos œï cos Œ∏
r
‚àí‚àÇf
‚àÇŒ∏
sin Œ∏
r sin œï
‚àÇf
‚àÇy = ‚àÇf
‚àÇr sin œï sin Œ∏ + ‚àÇf
‚àÇœï
cos œï sin Œ∏
r
+ ‚àÇf
‚àÇŒ∏
cos Œ∏
r sin œï
‚àÇf
‚àÇz = ‚àÇf
‚àÇr cos œï ‚àí‚àÇf
‚àÇœï
sin œï
r
.
The usual diÔ¨Äerential operators in spherical coordinates read
grad f = ‚àÇf
‚àÇr tr + 1
r
‚àÇf
‚àÇœïtœï +
1
r sin œï
‚àÇf
‚àÇŒ∏ tŒ∏ ,
div f = ‚àÇfr
‚àÇr + 2
r fr + 1
r
‚àÇfœï
‚àÇœï + tan œï
r
fœï +
1
r sin œï
‚àÇfŒ∏
‚àÇŒ∏ ,
curl f =
1
r
‚àÇfŒ∏
‚àÇœï + tan œï
r
fŒ∏ ‚àí‚àÇfœï
‚àÇŒ∏

tr +

1
r sin œï
‚àÇfr
‚àÇŒ∏ ‚àí‚àÇfŒ∏
‚àÇr ‚àí1
r fŒ∏

tœï
+
‚àÇfœï
‚àÇr + 1
r fœï ‚àí‚àÇfr
‚àÇœï

tŒ∏ ,
Œîf = ‚àÇ2f
‚àÇr2 + 2
r
‚àÇf
‚àÇr + 1
r2
‚àÇ2f
‚àÇœï2 + tan œï
r2
‚àÇf
‚àÇœï +
1
r2 sin2 œï
‚àÇ2f
‚àÇŒ∏2 .
6.7 Regular surfaces
Surfaces, and in particular compact ones (deÔ¨Åned by a compact region R), were
introduced in Sect. 4.7.
DeÔ¨Ånition 6.32 A surface œÉ : R ‚ÜíR3 is regular if œÉ is C1 on A =
‚ó¶
R
and the Jacobian matrix JœÉ has maximal rank (= 2) at every point of A.
A compact surface is regular if it is the restriction to R of a regular surface
deÔ¨Åned on an open set containing R.
The condition on JœÉ is equivalent to the fact that the vectors ‚àÇœÉ
‚àÇu (u0, v0) and
‚àÇœÉ
‚àÇv (u0, v0) are linearly independent for any (u0, v0) ‚ààA. By DeÔ¨Ånition 6.1, such
vectors form the columns of the Jacobian JœÉ
JœÉ =
 ‚àÇœÉ
‚àÇu
‚àÇœÉ
‚àÇv

.
(6.46)

6.7 Regular surfaces
237
Examples 6.33
i) The surfaces seen in Examples 4.37 i), iii), iv) are regular, as simple calculations
will show.
ii) The surface of Example 4.37 ii) is regular if (and only if) œï is C1 on A. If so,
JœÉ =
‚éõ
‚éú
‚éú
‚éù
1
0
0
1
‚àÇœï
‚àÇu
‚àÇœï
‚àÇv
‚éû
‚éü
‚éü
‚é†,
whose Ô¨Årst two rows grant the matrix rank 2.
iii) The surface œÉ : R √ó [0, 2œÄ] ‚ÜíR3,
œÉ(u, v) = u cosv i + u sin vj + u k
parametrises the cone
x2 + y2 ‚àíz2 = 0 .
Its Jacobian is
JœÉ =
‚éõ
‚éù
cos v
‚àíu sin v
sin v
u cosv
1
0
‚éû
‚é†.
As the determinants of the Ô¨Årst minors are u, u sin v, ‚àíu cosv, the surface is not
regular: at points (u0, v0) = (0, v0), mapped to the cone‚Äôs apex, all minors are
singular.
2
Before we continue, let us point out the use of terminology. Although DeÔ¨Ån-
ition 4.36 privileges the analytical aspects, the prevailing (by standard practice)
geometrical viewpoint uses the term surface to mean the trace Œ£ ‚äÇR3 as well,
retaining for the function œÉ the role of parametrisation of the surface. We follow
the mainstream and adopt this language, with the additional assumption that all
parametrisations œÉ be simple. In such a way, many subsequent notions will have
a more immediate, and intuitive, geometrical representation. With this matter
settled, we may now see a deÔ¨Ånition.
DeÔ¨Ånition 6.34 A subset Œ£ of R3 is a regular and simple surface if Œ£
admits a regular and simple parametrisation œÉ : R ‚ÜíŒ£.
Let then Œ£ ‚äÇR3 be a regular simple surface parametrised by œÉ : R ‚ÜíŒ£,
and P0 = œÉ(u0, v0) the point on Œ£ image of (u0, v0) ‚ààA =
‚ó¶
R. Since the vectors
‚àÇœÉ
‚àÇu (u0, v0), ‚àÇœÉ
‚àÇv (u0, v0) are by hypothesis linearly independent, we introduce the
map Œ† : R2 ‚ÜíR3,
Œ†(u, v) = œÉ(u0, v0) + ‚àÇœÉ
‚àÇu (u0, v0) (u ‚àíu0) + ‚àÇœÉ
‚àÇv (u0, v0) (v ‚àív0) ,
(6.47)

238
6 DiÔ¨Äerential calculus for vector-valued functions
that parametrises a plane through P0 (recall Example 4.37 i)). It is called the
tangent plane to the surface at P0. Justifying the notation, notice that the
functions
u ‚ÜíœÉ(u, v0)
and
v ‚ÜíœÉ(u0, v)
deÔ¨Åne two regular curves lying on Œ£ and passing through P0. Their tangent vectors
at P0 are ‚àÇœÉ
‚àÇu (u0, v0) and ‚àÇœÉ
‚àÇv (u0, v0); therefore the tangent lines to such curves at
P0 lie on the tangent plane, and actually they span it by linear combination. In
general, the tangent plane contains the tangent vector to any regular curve passing
through P0 and lying on the surface Œ£.
DeÔ¨Ånition 6.35 The vector
ŒΩ(u0, v0) = ‚àÇœÉ
‚àÇu (u0, v0) ‚àß‚àÇœÉ
‚àÇv (u0, v0)
(6.48)
is the surface‚Äôs normal (vector) at P0. The corresponding unit normal will
be indicated by n(u0, v0) =
ŒΩ(u0, v0)
‚à•ŒΩ(u0, v0)‚à•.
Due to the surface‚Äôs regularity, ŒΩ(u0, v0) is non-zero. It is also orthogonal to
‚àÇœÉ
‚àÇu (u0, v0) and ‚àÇœÉ
‚àÇv (u0, v0), so if we compute it at P0 it will be orthogonal to
the tangent plane at P0; this explains the name (Fig. 6.14).
 
 
 
 
 
 
 
 
‚àÇœÉ
‚àÇu (u0, v0)
‚àÇœÉ
‚àÇv (u0, v0)
ŒΩ(u0, v0)
P0
Œ£
Œ†
Figure 6.14. Tangent plane Œ† and normal vector ŒΩ at P0

6.7 Regular surfaces
239
 
 
 
 
 
 
 
 
x
y
z
ŒΩ
(u0, v0)
Œ£
P0
Œ†
Figure 6.15. Normal vector of a surface
Example 6.36
i) The regular surface œÉ : R ‚ÜíR3, œÉ(u, v) = u i+v j+œï(u, v) k, with œï ‚ààC1(R)
(see Example 6.33 ii)), has
ŒΩ(u, v) = ‚àí‚àÇœï
‚àÇu (u, v) i ‚àí‚àÇœï
‚àÇv (u, v) j + k .
(6.49)
Note that, at any point, the normal vector points upwards, because ŒΩ ¬∑ k > 0
(Fig. 6.15).
ii) Let œÉ : [0, œÄ]√ó[0, 2œÄ] ‚ÜíR3 be the parametrisation of the ellipsoid with centre
the origin and semi-axes a, b, c > 0 (see Example 4.37 iv)). Then
‚àÇœÉ
‚àÇu (u, v) = a cosu cos v i + b cosu sin v j ‚àíc sin u k ,
‚àÇœÉ
‚àÇv (u, v) = ‚àía sin u sin v i + b sin u cosv j + 0k ,
whence
ŒΩ(u, v) = bc sin2u cosv i + ac sin2u sin v j + ab sin u cosu k .
If the surface is a sphere of radius r (when a = b = c = r),
ŒΩ(u, v) = r sin u(r sin u cosv i + r sin u sin v j + r cos u k)
so the normal ŒΩ at x is proportional to x, and thus aligned with the radial
vector.
2
Just like with the tangent to a curve, one could prove that the tangent plane is
intrinsic to the surface, in other words it does not depend on the parametrisation.
As a result the normal‚Äôs direction is intrinsic as well, while length and orientation
vary with the chosen parametrisation.

240
6 DiÔ¨Äerential calculus for vector-valued functions
6.7.1 Changing parametrisation
Suppose Œ£ is regular, with two parametrisations œÉ : R ‚ÜíŒ£ and 1œÉ : 1R ‚ÜíŒ£.
DeÔ¨Ånition 6.37 The parametrisations 1œÉ and œÉ are congruent if there
is a change of variables Œ¶ : 1R ‚ÜíR such that 1œÉ = œÉ ‚ó¶Œ¶. If Œ£ is a compact
surface, Œ¶ is required to be the restriction of a change of variables between
open sets containing 1R and R.
Although the deÔ¨Ånition does not require the parametrisations to be simple, we
shall assume they are throughout. The property of being regular and simple is
preserved by congruence.
Bearing in mind the discussion of Sect. 6.6, if A and 1A are the interiors of R
and 1R, then either
det JŒ¶ > 0
on
1A
or
det JŒ¶ < 0
on
1A .
In the former case 1œÉ is equivalent to œÉ, while in the latter 1œÉ is anti-equivalent
to œÉ. In other terms, an orientation-preserving (orientation-reversing) change of
variables induces a parametrisation equivalent (anti-equivalent) to the given one.
The tangent vectors ‚àÇ1œÉ
‚àÇÀúu and ‚àÇ1œÉ
‚àÇÀúv can be easily expressed as linear combinations
of ‚àÇœÉ
‚àÇu and ‚àÇœÉ
‚àÇv . As it happens, recalling (6.46) and the chain rule (6.9), and
omitting to write the point (u0, v0) = Œ¶(Àúu0, Àúv0) of diÔ¨Äerentiation, we have
 ‚àÇ1œÉ
‚àÇÀúu
‚àÇ1œÉ
‚àÇÀúv

=
 ‚àÇœÉ
‚àÇu
‚àÇœÉ
‚àÇv

JŒ¶ ;
setting JŒ¶ =
	
m11
m12
m21
m22

, these become
‚àÇ1œÉ
‚àÇÀúu = m11
‚àÇœÉ
‚àÇu + m21
‚àÇœÉ
‚àÇv ,
‚àÇ1œÉ
‚àÇÀúv = m12
‚àÇœÉ
‚àÇu + m22
‚àÇœÉ
‚àÇv .
They show, on one hand, that ‚àÇ1œÉ
‚àÇÀúu and ‚àÇ1œÉ
‚àÇÀúv generate the same plane of ‚àÇœÉ
‚àÇu and
‚àÇœÉ
‚àÇv , as prescribed by (6.47); therefore
the tangent plane to a surface Œ£ is invariant for congruent parametrisations.
On the other hand, the previous expressions and property (4.8) imply
‚àÇ1œÉ
‚àÇÀúu ‚àß‚àÇ1œÉ
‚àÇÀúv = m11m12
‚àÇœÉ
‚àÇu ‚àß‚àÇœÉ
‚àÇu + m11m22
‚àÇœÉ
‚àÇu ‚àß‚àÇœÉ
‚àÇv +

6.7 Regular surfaces
241
+m21m12
‚àÇœÉ
‚àÇv ‚àß‚àÇœÉ
‚àÇu + m21m22
‚àÇœÉ
‚àÇv ‚àß‚àÇœÉ
‚àÇv
= (m11m22 ‚àím12m21)‚àÇœÉ
‚àÇu ‚àß‚àÇœÉ
‚àÇv .
From these follows that the normal vectors at the point P0 satisfy
1ŒΩ = (det JŒ¶) ŒΩ ,
(6.50)
which in turn corroborates that
two congruent parametrisations generate parallel normal vectors; the two ori-
entations are the same for equivalent parametrisations (orientation-preserving
change of variables), otherwise they are opposite (orientation-reversing
change).
6.7.2 Orientable surfaces
Proposition 6.27 guarantees two parametrisations of the same regular, simple curve
Œì of Rm are congruent, hence there are always two orientations to choose from.
The analogue result for surfaces cannot hold, and we will see counterexamples (the
M¬®obius strip, the Klein bottle). Thus the following deÔ¨Ånition makes sense.
DeÔ¨Ånition 6.38 A regular simple surface Œ£ ‚äÇR3 is said orientable if any
two regular and simple parametrisations are congruent.
The name comes from the fact that the surface may be endowed with two ori-
entations (na¬®ƒ±vely, the crossing directions) depending on the normal vector. All
equivalent parametrisations will have the same orientation, whilst anti-equivalent
ones will have opposite orientations. It can be proved that a regular and simple
surface parametrised by an open plane region R is always orientable.
When the regular, simple surface is parametrised by a non-open region, the
picture becomes more complicated and the surface may, or not, be orientable. With
the help of the next two examples we shed some light on the matter. Consider Ô¨Årst
the cylindrical strip of radius 1 and height 2, see Fig. 6.16, left.
We parametrise this compact surface by the map
œÉ : [0, 2œÄ] √ó [‚àí1, 1] ‚ÜíR3 ,
œÉ(u, v) = cos u i + sin u j + vk ,
(6.51)
regular and simple because, for instance, injective on [0, 2œÄ) √ó [‚àí1, 1]. The associ-
ated normal
ŒΩ(u, v) = cos u i + sin u j + 0k

242
6 DiÔ¨Äerential calculus for vector-valued functions
constantly points outside the cylinder. To nurture visual intuition, we might say
that a person walking on the surface (staying on the plane xy, for instance) can
return to the starting point always keeping the normal vector on the same side.
The surface is orientable, it has two sides ‚Äì an inside and an outside ‚Äì and if the
person wanted to go to the opposite side it would have to cross the top rim v = 1
or the bottom one v = ‚àí1. (The rims in question are the surface‚Äôs boundaries, as
we shall see below.)
The second example is yet another strip, called M¬®obius strip, and shown in
Fig. 6.16, right. To construct it, start from the previous cylinder, cut it along a
vertical segment, and then glue the ends back together after twisting one by 180‚ó¶.
The precise parametrisation œÉ : [0, 2œÄ] √ó [‚àí1, 1] ‚ÜíR3 is
œÉ(u, v) =

1 ‚àív
2 cos u
2

cos u i +

1 ‚àív
2 cos u
2

sin u j ‚àív
2 sin u
2 k .
For u = 0, i.e., at the point P0 = (1, 0, 0) = œÉ(0, 0), the normal vector is ŒΩ = 1
2k.
As u increases, the normal varies with continuity, except that as we go back to
P0 = œÉ(2œÄ, 0) after a complete turn, we have ŒΩ = ‚àí1
2k, opposite to the one we
started with. This means that our imaginary friend starts from P0 and after one
loop returns to the same point (without crossing the rim) upside down! The M¬®obius
strip is a non-orientable surface; it has one side only and one boundary: starting
at any point of the boundary and going around the origin twice, for instance, we
reach all points of the boundary, in contrast to what happens for the cylinder.
At any rate the M¬®obius strip embodies a somehow ‚Äúpathological‚Äù situation.
Surfaces (compact or not) delimiting elementary solids ‚Äì spheres, ellipsoid, cylin-
ders, cones and the like ‚Äì are all orientable. More generally,
Proposition 6.39 Every regular simple surface Œ£ contained in the boundary
‚àÇŒ© of an open, connected and bounded set Œ© ‚äÇR3 is orientable.
We can thus choose for Œ£ either the orientation from inside towards outside
Œ©, or the converse. In the Ô¨Årst case the unit normal n points outwards, in the
second it points inwards.
 
 
 
 
 
 
 
 
 
 
n
 
 
 
 
 
 
Figure 6.16. Cylinder (left) and M¬®obius strip (right)

6.7 Regular surfaces
243
6.7.3 Boundary of a surface; closed surfaces
The other important object concerning a surface is the boundary, mentioned above.
This is a rather delicate notion if one wishes to discuss it in full generality, but we
shall present the matter in an elementary way.
Let Œ£ ‚äÇR3 be a regular and simple surface, which we assume to be a closed
subset Œ£ = Œ£ of R3 (in the sense of DeÔ¨Ånition 4.5). Then let œÉ : R ‚äÇR2 ‚ÜíŒ£ be
a parametrisation over the closed region R. Calling A =
‚ó¶
R the interior of R, the
image Œ£‚ó¶
œÉ = œÉ(A) is a subset of Œ£ = œÉ(R). The diÔ¨Äerence set
‚àÇŒ£œÉ = Œ£ \ Œ£‚ó¶
œÉ
will be called boundary of Œ£ (relative to œÉ). Subsequent examples will show
that ‚àÇŒ£œÉ contains all points that are obvious boundary points of Œ£ in purely
geometrical terms, but might also contain points that depend on the chosen para-
metrisation; this justiÔ¨Åes the subscript œÉ. It is thus logical to deÔ¨Åne the boundary
of Œ£ (viewed as an intrinsic object to the surface) as the set
‚àÇŒ£ =
2
œÉ
‚àÇŒ£œÉ ,
where the intersection is taken over all possible parametrisations (non-regular as
well) of Œ£. We point out that the symbol ‚àÇŒ£ denoted in Sect. 4.3 the frontier of
Œ£, seen as subset of R3; for regular surfaces this set coincides with Œ£ = Œ£, since
no interior points are present. Our treatise of surfaces will only involve the notion
of boundary, not of frontier. Here are the promised examples.
Examples 6.40
i) The upper hemisphere with centre (0, 0, 1) and radius 1
Œ£ = {(x, y, z) ‚ààR3 : x2 + y2 + (z ‚àí1)2 = 1, z ‚â•1}
is a closed set Œ£ = Œ£ inside R3. Geometrically, it is quite intuitive (Fig. 6.17,
left) that its boundary is the circle
‚àÇŒ£ = {(x, y, z) ‚ààR3 : x2 + y2 + (z ‚àí1)2 = 1, z = 1} .
If one parametrises Œ£ by
œÉ : R = {(u, v) ‚ààR2 : u2+v2 ‚â§1} ‚ÜíR3 ,
œÉ(u, v) = ui+vj+(1+

u2 + v2)k ,
it follows that
Œ£‚ó¶
œÉ = {(x, y, z) ‚ààR3 : x2 + y2 + (z ‚àí1)2 = 1, z > 1} ,
so Œ£ \ Œ£‚ó¶
œÉ is precisely the boundary we claimed. Parametrising Œ£ with spherical
coordinates, instead,
1œÉ : 1R = [0, œÄ
2 ]√ó[0, 2œÄ] ‚ÜíR3 ,
1œÉ(u, v) = sin u cos v i+sinu sin v j+(1+cosu)k ,
so 1A = (0, œÄ
2 ) √ó (0, 2œÄ), we obtain Œ£‚ó¶
œÉ as the portion of surface lying above the
plane z = 1, without the equatorial arc joining the North pole (0, 0, 2) to (1, 0, 1)
on the plane xz (Fig. 6.17, right); analytically,

244
6 DiÔ¨Äerential calculus for vector-valued functions
 
 
 
 
 
 
 
x
y
z
Œ£
‚àÇŒ£
 
 
 
 
 
 
 
1
2
x
y
z
Œ£
‚àÇŒ£
Figure 6.17. The hemisphere of Example 6.40 i)
Œ£‚ó¶
œÉ = {(x, y, z) ‚ààR3 : x2 + y2 + (z ‚àí1)2 = 1, z > 1}
\{(x, y, z) ‚ààR3 : x > 0, y = 0, x2 + (z ‚àí1)2 = 1} .
Besides the points on the geometric boundary, Œ£‚ó¶
œÉ consists of the aforementioned
arc, which is image of part of the boundary of 1R; these points depend on the
particular parametrisation we have chosen.
ii) Let
Œ£ = {(x, y, z) ‚ààR3 : x2 + y2 = 1, |z| ‚â§1}
be the (closed) cylinder of Fig. 6.18, whose boundary ‚àÇŒ£ consists of the circles
x2 + y2 = 1, z = ¬±1. Given u0 ‚àà[0, 2œÄ], we may parametrise Œ£ by
œÉu0 : [0, 2œÄ] √ó [‚àí1, 1] ‚ÜíR3 ,
œÉu0(u, v) = cos(u ‚àíu0) i + sin(u ‚àíu0) j + vk ,
generalising the parametrisation œÉ = œÉ0 seen in (6.51). Then
Œ£‚ó¶
œÉu0 = {(x, y, z) ‚ààR3 : x2 + y2 = 1, |z| < 1}
\{(cosu0, sin u0, z) ‚ààR3 : |z| < 1} ,
and ‚àÇŒ£œÉu0 contains, apart from the two circles giving ‚àÇŒ£, also the vertical
segment {(cos u0, sin u0, z) ‚ààR3 : |z| < 1}. Intersecting all sets ‚àÇŒ£œÉu0 ‚Äì any two
of them is enough ‚Äì gives the geometric boundary of Œ£.
iii) Consider at last the surface
Œ£ =

(x, y, z) ‚ààR3 : (x, y) ‚ààŒì, 0 ‚â§z ‚â§1

,
where Œì is the Jordan arc in the plane xy deÔ¨Åned by
Œ≥ : [0, 1] ‚ÜíR2 ,
Œ≥1(t) = œï(t) = t(1 ‚àít)2
and
Œ≥2(t) = œà(t) = (1 ‚àít)t2

6.7 Regular surfaces
245
 
 
 
 
 
 
x
y
z
Œ£
‚àÇŒ£
Figure 6.18. The cylinder relative to Example 6.40 ii)
(see Fig. 6.19, left). Let us Ô¨Årst parametrise Œ£ with œÉ : R ‚ÜíR3, where R =
[0, 1]2 and œÉ(u, v) =

œï(u), œà(u), v

. It is easy to convince ourselves that the
boundary ‚àÇŒ£œÉ of œÉ is ‚àÇŒ£œÉ = Œì0 ‚à™Œì1 ‚à™S0, where Œì0 = Œì √ó {0}, Œì1 = Œì √ó {1}
and S0 = {(0, 0)} √ó [0, 1] (Fig. 6.19, right). But if we extend the maps œï and
œà periodically to the intervals [k, k + 1], we may consider, for any u0 ‚ààR, the
parametrisations œÉu0 : R ‚ÜíR3 given by œÉu0(u, v) =

œï(u ‚àíu0), œà(u ‚àíu0), z

,
for which Œ£‚ó¶
œÉu0 = Œì0 ‚à™Œì1 ‚à™Su0, Su0 = {Œ≥(u0)} √ó [0, 1]. We conclude that the
vertical segment Su0 does depend upon the parametrisation, whereas the top
and bottom loops Œì0, Œì1 are common to all parametrisations. In summary, the
boundary of Œ£ is the union of the loops, ‚àÇŒ£ = Œì0 ‚à™Œì1.
2
x
y
0
Œì
 
 
 
 
 
 
 
 
x
y
z
S0
Œì0
Œì1
Œ£
Figure 6.19. The arc Œì and surface Œ£ of Example 6.40 iii)

246
6 DiÔ¨Äerential calculus for vector-valued functions
Among surfaces a relevant role is played by those that are closed. A regular,
simple surface Œ£ ‚äÇR3 is closed if it is bounded (as a subset of R3) and has
no boundary (‚àÇŒ£ = ‚àÖ). This notion, too, is heavily dependent on the surface‚Äôs
geometry, and diÔ¨Äers from the topological closure of DeÔ¨Ånition 4.5 (namely, each
closed surface is necessarily a closed subset of R3, but there are topologically-
closed surfaces with non-empty boundary). Examples of closed surfaces include
the sphere and the torus, which we introduce now.
Examples 6.41
i) Arguing as in Example 6.40 i), we see that the parametrisation of the unit
sphere Œ£ = {(x, y, z) ‚ààR3 : x2 + y2 + z2 = 1} by spherical coordinates (Ex-
ample 4.37 iii)) has a boundary, the semi-circle from the North pole to the South
pole lying in the half-plane x ‚â•0, y = 0. Any rotation of the coordinate system
will produce another parametrisation whose boundary is a semi-circle joining
antipodal points. It is straightforward to see that the boundaries‚Äô intersection is
empty.
ii) A torus is the surface Œ£ built by identifying the top and bottom boundaries
of the cylinder of Example 6.40 ii). It can also be obtained by a 2œÄ-revolution
around the z-axis of a circle of radius r lying on a plane containing the axis,
having centre at a point of the plane xy at a distance R + r, R ‚â•0, from the
axis (see Fig. 6.20). A parametrisation is œÉ : [0, 2œÄ] √ó [0, 2œÄ] ‚ÜíR3 with
œÉ(u, v) = (R + r cos u) cosv i + (R + r cos u) sin v j + r sin u k .
The boundary ‚àÇŒ£œÉ is the union of the circle on z = 0 with centre the origin and
radius R + r, and the circle on y = 0 centred at (R, 0, 0) with radius r.
Here, as well, changing the parametrisation shows the geometric boundary ‚àÇŒ£
is empty, making the torus a closed surface.
2
The next theorem is the closest kin to the Jordan Curve Theorem 4.33 for
plane curves.
 
 
 
 
 
 
x
y
z
R
r
Figure 6.20. The torus of Example 6.41 ii)

6.7 Regular surfaces
247
Theorem 6.42 A closed orientable surface Œ£ divides the space R3 in two
open regions Ai, Ae whose common frontier is Œ£. The region Ai (the in-
terior) is bounded, while the other region Ae (the exterior) is unbounded.
Nonetheless, there do exist closed non-orientable surfaces, which do not separ-
ate space in an inside and an outside. A traditional example is the Klein bottle,
built from the M¬®obius strip in the same fashion the torus is constructed by glueing
the cylinder‚Äôs two rims.
6.7.4 Piecewise-regular surfaces
This generalisation of regularity allows the surface to contain curves where diÔ¨Äeren-
tiability fails, and grants us a means of dealing with surfaces delimiting polyhedra
such as cubes, pyramids, and truncated pyramids, or solids of revolution like trun-
cated cones or cylinders. As in Sect. refsec:bordo, we shall assume all surfaces are
closed subsets of R3.
DeÔ¨Ånition 6.43 A subset Œ£ ‚äÇR3 is a piecewise-regular, simple surface
if it is the union of Ô¨Ånitely many regular, simple surfaces Œ£1, . . . , Œ£ K whose
pairwise intersections Œ£h ‚à©Œ£k (if not empty or a point) are piecewise-regular
curves Œìhk contained in the boundary of both Œ£h and Œ£k.
The analogue deÔ¨Ånition holds for piecewise-regular compact surfaces.
Each surface Œ£k is called a face (or component) of Œ£, and the intersection
curve between any two faces is an edge of Œ£ .
A piecewise regular simple surface Œ£ is orientable if every component is ori-
entable in such a way that adjacent components have compatible orientations.
Proposition 6.39 then extends to (compact) piecewise-regular, simple surfaces.
The boundary ‚àÇŒ£ of a piecewise-regular simple surface Œ£ is the closure of
the set of points belonging to the boundary of one, and one only, component.
Equivalently, consider the union of the single components‚Äô boundaries, without
the points common to two or more components, and then take the closure of this
set: this is ‚àÇŒ£. A piecewise-regular simple surface is closed if bounded and with
empty boundary.
Examples 6.44
i) The frontier of a cube is piecewise regular, and has the cube‚Äôs six faces as
components; it is obviously orientable and closed (Fig. 6.21, left).
ii) The piecewise-regular surface obtained from the previous one by taking away
two opposite faces (Fig. 6.21, right) is still orientable, but no longer closed. Its
boundary is the union of the boundaries of the faces removed.
2

248
6 DiÔ¨Äerential calculus for vector-valued functions
Figure 6.21. The cubes of Examples 6.44
Remark 6.45 Example ii) provides us with the excuse for explaining why one
should insist on the closure of the boundary, instead of taking the mere boundary.
Consider a cube aligned with the Cartesian axes, from which we have removed the
top and bottom faces. The union of the boundaries of the 4 faces left is given by
the 12 edges forming the skeleton. Getting rid of the points common to two faces
leaves us with the 4 horizontal top edges and the 4 bottom ones, without the 8
vertices. Closing what is left recovers the 8 missing vertices, so the boundary is
precisely the union of the 8 horizontal edges.
2
6.8 Exercises
1. Find the Jacobian matrix of the following functions:
a)
f(x, y) = e2x+y i + cos(x + 2y) j
b)
f(x, y, z) = (x + 2y2 + 3z3) i + (x + sin 3y + ez) j
2. Determine the divergence of the following vector Ô¨Åelds:
a)
f(x, y) = cos(x + 2y) i + e2x+y j
b)
f(x, y, z) = (x + y + z) i + (x2 + y2 + z2) j + (x3 + y3 + z3) k
3. Compute the curl of the vector Ô¨Åelds:
a)
f(x, y, z) = x i + y j + z k
b)
f(x, y, z) = xyz i + z sin y j + xey k
c)
f(x, y) =

y

x2 + y2

i +

x

x2 + y2

j
d)
f(x, y) = grad (logx y)2

6.8 Exercises
249
4.
Given f(x, y) = 3x + 2y and g(u, v) = (u + v) i + uv j, compute the composite
map f ‚ó¶g explicitly and Ô¨Ånd its gradient.
5. Compute the composite of the following pairs of maps and the composite‚Äôs
gradient:
a)
f(s, t) =
‚àö
s + t ,
g(x, y) = xy i + x
y j
b)
f(x, y, z) = xyz ,
g(r, s, t) = (r + s) i + (r + 3t) j + (s ‚àít) k
6.
Let f : R2 ‚ÜíR2 and g : R3 ‚ÜíR2 be deÔ¨Åned by
f(x, y) = sin(2x + y) i + ex+2y j ,
g(u, v, z) = (u + 2v2 + 3z3) i + (u2 ‚àí2v) j .
a) Compute their Jacobians Jf and Jg .
b) Determine the composite h = f ‚ó¶g and its Jacobian Jh at the point
(1, ‚àí1, 0).
7. Given the following maps, determine the Ô¨Årst derivative and the monotonicity
on the interval indicated:
a)
f(x) =
 x
0
arctan x2y
y
dy ,
t ‚àà[1, +‚àû)
b)
f(x) =
 ‚àö1‚àíx
0
y
3

8 + y4 ‚àíx
2 dy ,
t ‚àà[0, 1]
8. Compute the length of the arcs:
a)
Œ≥(t) = (t, 3t2) ,
t ‚àà[0, 1]
b)
Œ≥(t) = (t cos t, t sin t, t) ,
t ‚àà[0, 2œÄ]
c)
Œ≥(t) = (t2, t2, t3) ,
t ‚àà[0, 1]
9.
Determine the values of Œ± ‚ààR for which the length of Œ≥(t) = (t, Œ±t2, t3), t ‚àà
[0, T ], equals ‚Ñì(Œ≥) = T + T 3.
10.
Consider the closed arc Œ≥ whose trace is the union of the segment between
A = (‚àílog 2, 1/2) and B = (1, 0), the circular arc x2 + y2 = 1 joining B to
C = (0, 1), and the arc Œ≥3(t) = (t, et) from C to A. Compute its length.
11. Tell whether the following arcs are closed, regular or piecewise regular:
a)
Œ≥(t) =

t(t ‚àíœÄ)2(t ‚àí2œÄt), cos t

,
t ‚àà[0, 2œÄ]
b)
Œ≥(t) = (sin2 2œÄt, t) ,
t ‚àà[0, 1]

250
6 DiÔ¨Äerential calculus for vector-valued functions
12.
What are the values of the parameter Œ± ‚ààR for which the curve
Œ≥(t) =
 (Œ±t, t3, 0)
if t < 0 ,
(sin Œ±2t, 0, t3)
if t ‚â•0
is regular?
13.
Calculate the principal normal vector n(s), the binormal b(s) and the torsion
b‚Ä≤(s) for the circular helix Œ≥(t) = (cos t, sin t, t), t ‚ààR.
14.
If a curve Œ≥(t) = x(t)i + y(t)j is (r(t), Œ∏(t)) in polar coordinates, verify that
‚à•Œ≥‚Ä≤(t)‚à•2 =
dr
dt
2
+

r(t)dŒ∏
dt
2
.
15. Check that if a curve Œ≥(t) = x(t)i + y(t)j + z(t)k is given by

r(t), Œ∏(t), z(t)

in cylindrical coordinates, then
‚à•Œ≥‚Ä≤(t)‚à•2 =
dr
dt
2
+

r(t)dŒ∏
dt
2
+
dz
dt
2
.
16.
Check that the curve Œ≥(t) = x(t)i+y(t)j+z(t)k, given in spherical coordinates
by

r(t), œï(t), Œ∏(t)

, satisÔ¨Åes
‚à•Œ≥‚Ä≤(t)‚à•2 =
dr
dt
2
+

r(t)
2dœï
dt
2
+

r(t) sin œï(t)
2dŒ∏
dt
2
.
17.
Using Exercise 15, compute the length of the arc Œ≥(t) given in cylindrical
coordinates by
Œ≥(t) =

r(t), Œ∏(t), z(t)

=
‚àö
2 cos t, 1
‚àö
2
t, sin t

,
t ‚àà

0, œÄ
2

.
18.
Consider the parametric surface
œÉ(u, v) = uv i + (1 + 3u) j + (v3 + 2u) k .
a) Tell whether it is simple.
b) Determine the set R on which œÉ is regular.
c) Determine the normal to the surface at every point of R.
d) Write the equation of the plane tangent to the surface at P0 = œÉ(u0, v0) =
(1, 4, 3).

6.8 Exercises
251
19.
The surfaces
œÉ1(u, v) = cos(2 ‚àíu) i + sin(2 ‚àíu) j + v2 k ,
(u, v) ‚àà[0, 2œÄ] √ó [0, 1]
and
œÉ2(u, v) = sin(3 + 2u) i + cos(3 + 2u) j + (1 ‚àív) k ,
(u, v) ‚àà[0, œÄ] √ó [0, 1]
parametrise the same set Œ£ in R3.
a) Determine Œ£.
b) Say whether the orientations deÔ¨Åned by œÉ1 and œÉ2 coincide or not.
c) Compute the unit normals to Œ£, at P0 = (0, 1, 1
4), relative to œÉ1 and œÉ2.
20.
Consider the surface œÉ : R2 ‚ÜíR3,
œÉ(u, v) = u i + v j + (u2 + 3uv + v2) k .
a) What is the unit normal n(u, v) ?
b) Determine the points on the image Œ£ at which the normal is orthogonal to
the plane 8x + 7y ‚àí2z = 4.
6.8.1 Solutions
1. Jacobian matrices:
a)
Jf(x, y) =
	
2e2x+y
e2x+y
‚àísin(x + 2y)
‚àí2 sin(x + 2y)

b)
Jf(x, y, z) =
	
1
4y
9z2
1
3 cos3y
ez

2. Vector Ô¨Åelds‚Äô divergence:
a)
div f(x, y) = ‚àísin(x + 2y) + e2x+y
b)
div f(x, y, z) = 1 + 2y + 3z2
3. Curl of vector Ô¨Åelds:
a)
curl f(x, y, z) = 0
b)
curl f(x, y, z) = (xey ‚àísin y) i ‚àí(ey ‚àíxy) j ‚àíxz k
c)
curl f(x, y) =
2xy
(x2 + y2)3/2
d)
Since f is a gradient, Proposition 6.8 ensures its curl is null.

252
6 DiÔ¨Äerential calculus for vector-valued functions
4. We have
f ‚ó¶g(u, v) = f

g(u, v)

= f(u + v, uv) = 3(u + v) + 2uv
and
‚àáf ‚ó¶g(u, v) = (3 + 2v, 3 + 2u) .
5. Composite maps and gradients:
a) We have
f ‚ó¶g(x, y) = f

g(x, y)

= f

xy, x
y

=

xy + x
y
and
‚àáf ‚ó¶g(x, y) =
	1
2

y
xy2 + x

y + 1
y

, 1
2

y
xy2 + x

x ‚àíx
y2

.
b) Since
f

g(r, s, t)

= f(r + s, r + 3t, s ‚àít) = (r + s) (r + 3t) (s ‚àít) ,
setting h = f ‚ó¶g gives the gradient‚Äôs components
‚àÇh
‚àÇr (r, s, t) = (r + 3t) (s ‚àít) + (r + s) (s ‚àít) = 2rs + 2st ‚àí2rt + s2 ‚àí3t2
‚àÇh
‚àÇs (r, s, t) = (r + 3t) (s ‚àít) + (r + s) (r + 3t) = 2rs + 6st + 2rt ‚àí3t2 + r2
‚àÇh
‚àÇt (r, s, t) = 3(r + s) (s ‚àít) ‚àí(r + s) (r + 3t) = 2rs ‚àí6rt ‚àí6st + 3s2 ‚àír2 .
6. a) We have
Jf(x, y) =
	
2 cos(2x + y)
cos(2x + y)
ex+2y
2ex+2y

,
Jg(u, v, z) =
	
1
4v
9z2
2u
‚àí2
0

.
b) Since
h(u, v, z) = f(u + 2v2 + 3z3, u2 ‚àí2v)
= sin(u2 + 4v2 + 6z3 + 2u ‚àí2v) i + e2u2+2v2+3z3+u‚àí4vj
and g(1, ‚àí1, 0) = (3, 3), it follows that
Jh(1, ‚àí1, 0) = Jf

g(1, ‚àí1, 0)

Jg(1, ‚àí1, 0) = Jf(3, 3) Jg(1, ‚àí1, 0)
=
	
2 cos9
cos 9
e9
2e9

 	
1
‚àí4
0
2
‚àí2
0

=
	
4 cos9
‚àí10 cos9
0
5e9
‚àí8e9
0

.

6.8 Exercises
253
7. Derivatives of integral functions:
a) As
f ‚Ä≤(x) = arctanx3
x
> 0 ,
‚àÄx ‚ààR ,
the map is (monotone) increasing on [1, +‚àû).
b) Since
f ‚Ä≤(x) = ‚àí1
6
 ‚àö1‚àíx
0
y

8 + y4 ‚àíx
2
‚àí3/2 dy ‚àí1
2
3

8 + (1 ‚àíx)2 ‚àíx
2
= ‚àí1
2
1
3
 ‚àö1‚àíx
0
y

8 + y4 ‚àíx
2
‚àí3/2 dy +
3

x2 ‚àí5
2x + 9

,
we obtain f ‚Ä≤(x) ‚â§0 for any x ‚àà[0, 1]; hence f is decreasing on [0, 1].
8. Length of arcs:
We shall make use of the following indeÔ¨Ånite integral (Vol. I, Example 9.13 v)):
 
1 + x2 dx = 1
2x

1 + x2 + 1
2 log(

1 + x2 + x) + c .
a) From
Œ≥‚Ä≤(t) = (1, 6t)
and
‚à•Œ≥‚Ä≤(t)‚à•=

1 + 36t2
follows
‚Ñì(Œ≥) =
 1
0

1 + 36t2 dt = 1
6
 6
0

1 + x2 dx
= 1
6
1
2x

1 + x2 + 1
2 log(

1 + x2 + x)
6
0
= 1
2
‚àö
37 + 1
12 log(
‚àö
37 + 6) .
b) Since
Œ≥‚Ä≤(t) = (cos t ‚àít sin t, sin t + t cos t, 1)
and
‚à•Œ≥‚Ä≤(t)‚à•=

2 + t2 ,
we have
‚Ñì(Œ≥) =
 2œÄ
0

2 + t2 dt = 2
 ‚àö
2œÄ
0

1 + x2 dx
= 2
1
2x

1 + x2 + 1
2 log(

1 + x2 + x)
‚àö
2œÄ
0
=
‚àö
2œÄ

1 + 2œÄ2 + log

1 + 2œÄ2 +
‚àö
2œÄ

.

254
6 DiÔ¨Äerential calculus for vector-valued functions
c) ‚Ñì(Œ≥) =
1
27

17
‚àö
17 ‚àí16
‚àö
2

.
9. As Œ≥‚Ä≤(t) = (1, 2Œ±t, 3t2), we must have
‚Ñì(Œ≥) = T + T 3 =
 T
0

1 + 4Œ±2t2 + 9t4 dt .
Set g(T ) = T + T 3: the Fundamental Theorem of Integral Calculus yields
g‚Ä≤(T ) = 1 + 3T 2 =

1 + 4Œ±2T 2 + 9T 4 ,
i.e.,
(1 + 3T 2)2 = 1 + 4Œ±2T 2 + 9T 4 .
From this, 4Œ±2 = 6, so Œ± = ¬±

3/2.
10. We have
‚Ñì(Œ≥) = ‚Ñì(Œ≥1) + ‚Ñì(Œ≥2) + ‚Ñì(Œ≥3)
where
Œ≥1(t) =

t,
1 ‚àít
2(1 + log 2)

,
t ‚àà[‚àílog 2, 1] ,
Œ≥2(t) = (cos t, sin t) ,
t ‚àà

0, œÄ
2

Œ≥3(t) = (t, et) ,
t ‚àà[‚àílog 2, 0] .
From elementary geometry we know that
‚Ñì(Œ≥1) = d(A, B) =

(1 + log 2)2 + 1
4 =

5
4 + 2 log 2 + log2 2 ,
‚Ñì(Œ≥2) = 2œÄ
4 = œÄ
2 .
For ‚Ñì(Œ≥3), observe that Œ≥‚Ä≤
3(t) = (1, et), so
‚Ñì(Œ≥3) =
 0
‚àílog 2

1 + e2t dt .
Now, setting u =
‚àö
1 + e2t, we obtain e2t = u2 ‚àí1 and du =
e2t
‚àö
1+e2t dt = u2‚àí1
u
dt.
Therefore
‚Ñì(Œ≥3) =
 ‚àö
2
‚àö
5/2
u2
u2 ‚àí1 du =
 ‚àö
2
‚àö
5/2

1 + 1/2
u ‚àí1 ‚àí1/2
u + 1

du
=

u + 1
2 log

u ‚àí1
u + 1

‚àö
2
‚àö
5/2
=
‚àö
2 ‚àí
‚àö
5
2 + log(
‚àö
2 ‚àí1)(
‚àö
5 + 2) .

6.8 Exercises
255
To sum up,
‚Ñì(Œ≥) = œÄ
2 +

5
4 + 2 log 2 + log2 2 +
‚àö
2 ‚àí
‚àö
5
2 + log(
‚àö
2 ‚àí1)(
‚àö
5 + 2) .
11. Closed, regular, piecewise-regular arcs:
a) The arc is closed because Œ≥(0) = (0, 1) = Œ≥(2œÄ).
Moreover, Œ≥‚Ä≤(t) =

2(t ‚àíœÄ)(2t2 ‚àí4œÄt + œÄ2), ‚àísin t) implies that Œ≥‚Ä≤(t) is C1 on
[0, 2œÄ]. Next, notice sin t = 0 only when t = 0, œÄ ,2œÄ, and Œ≥‚Ä≤(0) = (‚àí2œÄ3, 0) Ã∏= 0,
Œ≥‚Ä≤(2œÄ) = (‚àí10œÄ3, 0) Ã∏= 0, Œ≥‚Ä≤(œÄ) = 0. The only non-regular point is thus the
one corresponding to t = œÄ. Altogether, the arc is piecewise regular.
b) The fact that Œ≥(0) = (0, 0) and Œ≥(1) = (0, 1) implies the arc is not closed.
What is more,
Œ≥‚Ä≤(t) = (4œÄ sin 2œÄt cos 2œÄt, 1) Ã∏= (0, 0) ,
‚àÄt ‚àà[0, 1] ,
making the arc regular.
12. Note Œ≥ is continuous for any t ‚ààR with
Œ≥‚Ä≤(t) =
 (Œ±, 3t2, 0)
if t < 0 ,
(Œ±2 cos Œ±2t, 0, 3t2)
if t ‚â•0 .
Certainly Œ≥‚Ä≤(t) Ã∏= 0 for t Ã∏= 0 and any Œ± ‚ààR. To study the point t = 0, observe
that
Œ≥‚Ä≤(0‚àí) = lim
t‚Üí0‚àíŒ≥‚Ä≤(t) = (Œ±, 0, 0) ,
Œ≥‚Ä≤(0+) = lim
t‚Üí0+ Œ≥‚Ä≤(t) = (Œ±2, 0, 0) ,
so Œ≥‚Ä≤(0) exists if Œ± = Œ±2, i.e., if Œ± = 0 or Œ± = 1. If Œ± = 0 then Œ≥‚Ä≤(0) = 0, while for
Œ± = 1 we have Œ≥‚Ä≤(0) = (1, 0, 0) Ã∏= 0. In conclusion, the only value of regularity is
Œ± = 1.
13. Bearing in mind Example 6.29, we may re-parametrise the helix by arc length:
1Œ≥(s) =

cos
‚àö
2
2 s, sin
‚àö
2
2 s,
‚àö
2
2 s

,
s ‚ààR .
For any s ‚ààR then,
t(s) = 1Œ≥‚Ä≤(s) =

‚àí
‚àö
2
2 sin
‚àö
2
2 s,
‚àö
2
2 cos
‚àö
2
2 s,
‚àö
2
2

,
and
t‚Ä≤(s) =

‚àí1
2 cos
‚àö
2
2 s, ‚àí1
2 sin
‚àö
2
2 s, 0

with curvature K(s) = ‚à•t‚Ä≤(s)‚à•= 1/2. Therefore

256
6 DiÔ¨Äerential calculus for vector-valued functions
n(s) =

‚àícos
‚àö
2
2 s, ‚àísin
‚àö
2
2 s, 0

and
b(s) = t(s) ‚àßn(s) =
‚àö
2
2 sin
‚àö
2
2 s, ‚àí
‚àö
2
2 cos
‚àö
2
2 s,
‚àö
2
2

.
At last,
b‚Ä≤(t) =
1
2 cos
‚àö
2
2 s, 1
2 sin
‚àö
2
2 s, 0

and the scalar torsion is œÑ(s) = ‚àí1
2.
14. Remembering that
x = r cos Œ∏ ,
y = r sin Œ∏ ,
and using the chain rule,
x‚Ä≤(t) = dx
dt = ‚àÇx
‚àÇr
dr
dt + ‚àÇx
‚àÇŒ∏
dŒ∏
dt = cosŒ∏dr
dt ‚àír sin Œ∏dŒ∏
dt
y‚Ä≤(t) = dy
dt = ‚àÇy
‚àÇr
dr
dt + ‚àÇy
‚àÇŒ∏
dŒ∏
dt = sin Œ∏dr
dt + r cos Œ∏dŒ∏
dt .
The required equation follows by using sin2 Œ∏ + cos2 Œ∏ = 1, for any Œ∏ ‚ààR, and
‚à•Œ≥‚Ä≤(t)‚à•2 =

x‚Ä≤(t)
2 +

y‚Ä≤(t)
2.
16. Recalling
x = r sin œï cos Œ∏ ,
y = r sin œï sin Œ∏ ,
x = r cos œï ,
and the chain rule, we have
x‚Ä≤(t) = dx
dt = ‚àÇx
‚àÇr
dr
dt + ‚àÇx
‚àÇœï
dœï
dt + ‚àÇx
‚àÇŒ∏
dŒ∏
dt
= sin œï cos Œ∏dr
dt + r cos œï cos Œ∏dœï
dt ‚àír sin œï sin Œ∏dŒ∏
dt
y‚Ä≤(t) = dy
dt = ‚àÇy
‚àÇr
dr
dt + ‚àÇy
‚àÇœï
dœï
dt + ‚àÇy
‚àÇŒ∏
dŒ∏
dt
= sin œï sin Œ∏dr
dt + r cos œï sin Œ∏dœï
dt + r sin œï cos Œ∏dŒ∏
dt
z‚Ä≤(t) = dz
dt = ‚àÇz
‚àÇr
dr
dt + ‚àÇz
‚àÇœï
dœï
dt + ‚àÇz
‚àÇŒ∏
dŒ∏
dt
= cos œïdr
dt ‚àír sin œïdœï
dt .
Now using sin2 Œæ + cos2 Œæ = 1, for any Œæ ‚ààR, and ‚à•Œ≥‚Ä≤(t)‚à•2 =

x‚Ä≤(t)
2 +

y‚Ä≤(t)
2 +

z‚Ä≤(t)
2, a little computation gives the result.

6.8 Exercises
257
17. Since
r‚Ä≤(t) = ‚àí
‚àö
2 sin t , Œ∏
‚Ä≤(t) =
1
‚àö
2 ,
z‚Ä≤(t) = cos t ,
we have
‚Ñì(Œ≥) =
 œÄ/2
0

2 sin2 t +

2 cos2 t
 1
2 + cos2 t dt =
‚àö
2
 œÄ/2
0
dt =
‚àö
2
2 œÄ .
Notice the arc‚Äôs trace lies on the surface of the ellipsoid x2 + y2 + 2z2 = 2. The
initial point is (
‚àö
2, 0, 0), the end point (0, 0, 1) (see Fig. 6.22).
18. a) The surface is simple if, for (u1, v1), (u2, v2) ‚ààR2, we have
œÉ(u1, v1) = œÉ(u2, v2)
‚áí
(u1, v1) = (u2, v2) .
The left equation means
! u1v1 = u2v2
1 + 3u1 = 1 + 3u2
v3
1 + 2u1 = v3
2 + 2u2 .
From the middle line we obtain u1 = u2, and then v1 = v2 by substitution.
b) Consider the Jacobian
JœÉ =
‚éõ
‚éù
v
u
3
0
2
3v2
‚éû
‚é†.
The three minors‚Äô determinants are ‚àí3u, 9v2, 3v3 ‚àí2u. The only point at which
they all vanish is the origin. Thus œÉ is regular on R = R2 \ {(0, 0)}.
c) For (u, v) Ã∏= 0,
ŒΩ(u, v) = det
‚éõ
‚éù
i
j
k
v
3
2
u
0
3v2
‚éû
‚é†= 9v2 i + (2u ‚àí3v3) j ‚àí3u k .
 
 
 
 
 
 
x
y
z
(
‚àö
2, 0, 0)
(0,
‚àö
2, 0)
(0, 0, 1)
Figure 6.22. The arc of Exercise 17

258
6 DiÔ¨Äerential calculus for vector-valued functions
d) Imposing
uv = 1 ,
1 + 3u = 4 ,
v2 + 2u = 3
shows the point P0 = (1, 4, 3) is the image under œÉ of (u0, v0) = (1, 1). Therefore
the tangent plane in question is
Œ†(u, v) = œÉ(1, 1) + ‚àÇœÉ
‚àÇu (1, 1) (u ‚àí1) + ‚àÇœÉ
‚àÇv (1, 1) (v ‚àí1)
= (1, 4, 3) + (1, 3, 2)(u ‚àí1) + (1, 0, 3)(v ‚àí1)
= (u + v ‚àí1) i + (3u + 1) j + (2u + 3v ‚àí2) k .
Using Cartesian coordinates x = u + v ‚àí1, y = 3u + 1, z = 2u + 3v ‚àí2, the plane
reads 9x ‚àíy ‚àí3z + 4 = 0.
19. a) As u varies in [0, 2œÄ], the vector cos(2 ‚àíu) i + sin(2 ‚àíu) j runs along the
unit circle in the plane z = 0, while for v in [0, 1], the vector v2 k describes the
segment [0, 1] on the z-axis. Consequently Œ£ is a cylinder of height 1 with axis on
the z‚Äôs.
b) Using formula (6.48) the normal vector deÔ¨Åned by œÉ1 is
ŒΩ1(u, v) = ‚àí2v cos(2 ‚àíu) i ‚àí2v sin(2 ‚àíu) j ,
while the normal of œÉ2 is
ŒΩ2(u, v) = 2 sin(3 + 2u) i + 2 cos(3 + 2u) j .
If P = œÉ(u1, v1) = œÉ2(u2, v2) is an arbitrary point on Œ£, then
cos(2 ‚àíu1) = sin(3 + 2u2)
and
sin(2 ‚àíu1) = cos(3 + 2u2) ,
and so
ŒΩ1(u1, v1) = ‚àív1ŒΩ2(u2, v2) .
Since v1 is non-negative, the orientations are opposite.
c) We have P0 = œÉ

2‚àíœÄ
2 , 1
2

= œÉ

œÄ‚àí2
3, 3
4

. Hence ŒΩ1(P0) = ‚àíj, while ŒΩ2(P0) = 2j.
The unit normals then are n1(P0) = ‚àíj and n2(P0) = j.
20. a) Expression (6.49) yields
ŒΩ(u, v) = ‚àí(2u + 3v) i ‚àí(3u + 2v) j + k ,
normalising which produces
n(u, v) = ‚àí(2u + 3v)
‚à•ŒΩ‚à•
i ‚àí(3u + 2v)
‚à•ŒΩ‚à•
j +
1
‚à•ŒΩ‚à•k ,
with ‚à•ŒΩ‚à•2 = 13(u2 + v2) + 24uv + 1.

6.8 Exercises
259
b) The orthogonality follows by imposing ŒΩ be parallel to the vector 8i + 7j ‚àí2k.
Thus we impose
‚éß
‚é®
‚é©
‚àí(2u + 3v) = 8Œª
‚àí(3u + 2v) = 7Œª
1 = ‚àí2Œª .
Solving the system gives Œª = ‚àí1/2 and u = 1/2, v = 1. The required condition is
valid for the point P0 = œÉ
 1
2, 1

=
 1
2, 1, 11
4

.

7
Applying diÔ¨Äerential calculus
We conclude with this chapter the treatise of diÔ¨Äerential calculus for multivariate
and vector-values functions. Two are the themes of concern: the Implicit Function
Theorem with its applications, and the study of constrained extrema.
Given an equation in two or more independent variables, the Implicit Function
Theorem provides suÔ¨Écient conditions to express one variable in terms of the
others. It helps to examine the nature of the level sets of a function, which, under
regularity assumptions, are curves and surfaces in space. Finally, it furnishes the
tools for studying the locus deÔ¨Åned by a system of equations.
Constrained extrema, in other words extremum points of a map restricted to
a given subset of the domain, can be approached in two ways. The Ô¨Årst method,
called parametric, reduces the problem to understading unconstrained extrema
in lower dimension; the other geometrically-rooted method, relying on Lagrange
multipliers, studies the stationary points of a new function, the Lagrangian of the
problem.
7.1 Implicit Function Theorem
An equation of type
f(x, y) = 0
(7.1)
sets up an implicit relationship between the variables x and y; in geometrical terms
it deÔ¨Ånes the locus of points P = (x, y) in the plane whose coordinates satisfy the
equation. Very often it is possible to write one variable as a function of the other
at least locally (in the neighbourhood of one solution), as y = œï(x) or x = œà(y).
For example, the equation
f(x, y) = ax + by + c = 0 ,
with
a2 + b2 Ã∏= 0 ,
deÔ¨Ånes a line on the plane, and is equivalent to y = œï(x) = ‚àí1
b(ax + c), if b Ã∏= 0,
or x = œà(y) = ‚àí1
a(by + c) if a Ã∏= 0.
C. Canuto, A. Tabacco: Mathematical Analysis II, 2nd Ed.,
UNITEXT ‚Äì La Matematica per il 3+2 85, DOI 10.1007/978-3-319-12757-6_7,
¬© Springer International Publishing Switzerland 2015

262
7 Applying diÔ¨Äerential calculus
Instead,
f(x, y) = x2 + y2 ‚àír2 = 0 ,
with
r > 0
deÔ¨Ånes a circle centred at the origin with radius r; if (x0, y0) belongs to the circle
and y0 > 0, we may solve the equation for y on a neighbourhood of x0, and
write y = œï(x) =
‚àö
r2 ‚àíx2; if x0 < 0, we can write x = œà(y) = ‚àí

r2 ‚àíy2 on a
neighbourhood of y0. It is not possible to write y in terms of x on a neighbourhood
of x0 = r or ‚àír, nor x as a function of y around y0 = r or ‚àír, unless we violate
the deÔ¨Ånition of function itself. But in any of the cases where solving explicitly
for one variable is possible, one partial derivative of f is non-zero ( ‚àÇf
‚àÇy = b Ã∏= 0,
‚àÇf
‚àÇx = a Ã∏= 0 for the line, ‚àÇf
‚àÇy = 2y0 > 0, ‚àÇf
‚àÇx = 2x0 < 0 for the circle); conversely,
where one variable cannot be made a function of the other the partial derivative
is zero.
Moving on to more elaborate situations, we must distinguish between the ex-
istence of a map between the independent variables expressing (7.1) in an explicit
way, and the possibility of representing such map in terms of known elementary
functions. For example, in
y e2x + cos y ‚àí2 = 0
we can solve for x explicitly,
x = 1
2 log(2 ‚àícos y) ‚àí1
2 log y ,
but we are not able to do the same with
x5 + 3x2y ‚àí2y4 ‚àí1 = 0 .
Nonetheless, analysing the graph of the function, e.g., around the solution (x0, y0) =
(1, 0), shows that the equation deÔ¨Ånes y in terms of x, and the study we are about
to embark on will conÔ¨Årm rigorously the claim (see Example 7.2). Thus there is
a huge interest in Ô¨Ånding criteria that ensure a function y = y(x), say, at least
exists, even if the variable y cannot be written in an analytically-explicit way in
terms of x. This lays a solid groundwork for the employ of numerical methods. We
discuss below a milestone result in Mathematics, the Implicit Function Theorem,
also known as Dini‚Äôs Theorem in Italy, which yields a suÔ¨Écient condition for the
function y(x) to exist; the condition is the non-vanishing of the partial derivative
of f in the variable we are solving for.
All these considerations evidently apply to equations with three or more vari-
ables, like
f(x, y, z) = 0 .
(7.2)
Under special assumptions, we are allowed to deÔ¨Åne z = œï(x, y) as a function of x
and y. A second generalisation concerns systems of equations.
Numerous are the applications of the Implicit Function Theorem. To name a
few, many laws of Physics (think of Thermodynamics) tie two or more quantities

7.1 Implicit Function Theorem
263
through implicit relationships which, depending on the system‚Äôs speciÔ¨Åc state, can
be made explicit. In geometry the Theorem allows to describe as a regular simple
surface, if locally, the locus of points whose coordinates satisfy (7.2); it lies at the
heart of an ‚Äòintrinsic‚Äô viewpoint that regards a surface as a set of points deÔ¨Åned
by algebraic and transcendental equations.
So let us begin to see the two-dimensional version. Its proof may be found in
Appendix A.1.4, p. 518.
Theorem 7.1 Let Œ© be a non-empty open set in R2 and f : Œ© ‚ÜíR a C1 map.
Assume at the point (x0, y0) ‚ààŒ© we have f(x0, y0) = 0. If ‚àÇf
‚àÇy (x0, y0) Ã∏= 0,
there exists a neighbourhood I of x0 and a function œï : I ‚ÜíR such that:
i)

x,œï (x)

‚ààŒ© for any x ‚ààI;
ii) y0 = œï(x0);
iii) f

x,œï (x)

= 0 for any x ‚ààI;
iv) œï is a C1 map on I with derivative
œï‚Ä≤(x) = ‚àí
‚àÇf
‚àÇx

x,œï (x)

‚àÇf
‚àÇy

x,œï (x)
 .
(7.3)
On a neighbourhood of (x0, y0) moreover, the zero set of f coincides with the
graph of œï.
We remark that x ‚ÜíŒ≥(x) =

x,œï (x)

is a curve in the plane whose trace is
precisely the graph of œï.
Example 7.2
Consider the equation
x5 + 3x2y ‚àí2y4 = 1 ,
already considered in the introduction. It is solved by (x0, y0) = (1, 0). To study
the existence of other solutions in the neighbourhood of that point we deÔ¨Åne the
function
f(x, y) = x5 + 3x2y ‚àí2y4 ‚àí1 .
We have fy(x, y) = 3x2 ‚àí8y3, hence fy(1, 0) = 3 > 0. The above theorem
guarantees there is a function y = œï(x), diÔ¨Äerentiable on a neighbourhood I of
x0 = 1, such that œï(1) = 0 and
x5 + 3x2œï(x) ‚àí2

œï(x)
4 = 1 ,
x ‚ààI .
From fx(x, y) = 5x4 + 6xy we get fx(1, 0) = 5, so œï‚Ä≤(1) = ‚àí5
3. The map œï is
decreasing at x0 = 1, where the tangent to its graph is y = ‚àí5
3(x ‚àí1).
2

264
7 Applying diÔ¨Äerential calculus
In case ‚àÇf
‚àÇx(x0, y0) Ã∏= 0, we arrive at a similar result to Theorem 7.1 in which
x and y are swapped. To summarise (see Fig. 7.1),
Corollary 7.3 Let Œ© be a non-empty open set in R2 and f : Œ© ‚ÜíR a C1
map. The equation f(x, y) = 0 can be solved for one variable, y = œï(x) or
x = œà(y), around any zero (x0, y0) of f at which ‚àáf(x0, y0) Ã∏= 0 (i.e., around
each regular point).
There remains to understand what is the true structure of the zero set in the
neighbourhood of a stationary point. Assuming f is C2, the previous chapter‚Äôs
study of the Hessian matrix Hf(x0, y0) provides useful information.
i) If Hf(x0, y0) is deÔ¨Ånite (positive or negative), (x0, y0) is a local strict minimum
or maximum; therefore f will be strictly positive or negative on a whole punctured
neighbourhood of (x0, y0), making (x0, y0) an isolated zero for f. An example is
the origin for the map f(x, y) = x2 + y2.
ii) If Hf(x0, y0) is indeÔ¨Ånite, i.e., it has eigenvalues Œª1 > 0 and Œª2 < 0, one can
prove that the zero set of f around (x0, y0) is not the graph of a function, because it
consists of two distinct curves that meet at (x0, y0) and form an angle that depends
upon the eigenvalues‚Äô ratio. For instance, the zeroes of f(x, y) = 4x2 ‚àí25y2 belong
to the lines y = ¬± 2
5x, crossing at the origin (Fig. 7.2, left).
x
y
x0
y1
I
J
f(x, y) = 0
(x1, y1)
(x0, y0)
x = œà(y)
y = œï(x)
Figure 7.1. Some intervals where f(x, y) = 0 can be solved for x or y

7.1 Implicit Function Theorem
265
x
y
y = 2
5x
y = ‚àí2
5x
x
y
y =
3‚àö
x4
x
y
y = 1
4x2
y = ‚àí1
4x2
Figure 7.2. The zero sets of f(x, y) = 4x2 ‚àí25y2 (left), f(x, y) = x4 ‚àíy3 (centre) and
f(x, y) = x4 ‚àí16y2 (right)
iii) If Hf(x0, y0) has one or both eigenvalues equal zero, nothing can be said in
general. For example, assuming the origin as point (x0, y0), the zeroes of f(x, y) =
x4 ‚àíy3 coincide with the graph of y =
3‚àö
x4 (Fig. 7.2, centre). The map f(x, y) =
x4 ‚àí16y2, instead, vanishes along the parabolas y = ¬± 1
4x2 that meet at the origin
(Fig. 7.2, right).
We state the Implicit Function Theorem for functions in three variables. Its
proof is easily obtained by adapting the one given in two dimensions.
Theorem 7.4 Let Œ© be a non-empty open subset of R3 and f : Œ© ‚ÜíR a
map of class C1 with a zero at (x0, y0, z0) ‚ààŒ©. If ‚àÇf
‚àÇz (x0, y0, z0) Ã∏= 0, there
exist a neighbourhood A of (x0, y0) and a function œï : A ‚ÜíR such that:
i)

x, y,œï (x, y)

‚ààŒ© for any (x, y) ‚ààA;
ii) z0 = œï(x0, y0);
iii) f

x, y,œï (x, y)

= 0 for any (x, y) ‚ààA;
iv) œï is C1 on A, with partial derivatives
‚àÇœï
‚àÇx (x, y) = ‚àí
‚àÇf
‚àÇx

x, y,œï (x, y)

‚àÇf
‚àÇz

x, y,œï (x, y)
 ,
‚àÇœï
‚àÇy (x, y) = ‚àí
‚àÇf
‚àÇy

x, y,œï (x, y)

‚àÇf
‚àÇz

x, y,œï (x, y)
 .
(7.4)
Moreover, on a neighbourhood of (x0, y0, z0) the zero set of f coincides with
the graph of œï.
The function (x, y) ‚ÜíœÉ(x, y, z) =

x, y,œï (x, y)

deÔ¨Ånes a regular simple surface
in space, whose properties will be examined in Sect. 7.2.
The result may be applied, as happened above, under the assumption the point
(x0, y0, z0) be regular, possibly after swapping the independent variables‚Äô roles.
These two theorems are in fact subsumed by a general statement on vector-
valued maps.

266
7 Applying diÔ¨Äerential calculus
Let n, m be integers with n ‚â•2 and 1 ‚â§m ‚â§n ‚àí1. Take an open, non-empty
set Œ© in Rn and let F : Œ© ‚ÜíRm be a C1 map on it. Select m of the n independent
variables x1, x2, . . . , xn; without loss of generality we can take the last m variables
(always possible by permuting the variables). Then write x as two sets of coordin-
ates (Œæ, Œº), where Œæ = (x1, . . . , xn‚àím) ‚ààRn‚àím and Œº = (xn‚àím+1, . . . , xn) ‚ààRm.
Correspondingly, decompose the Jacobian of F at x ‚ààŒ© into the matrix JŒæF (x)
with m rows and n‚àím columns containing the Ô¨Årst n‚àím columns of JF (x), and
the m √ó m matrix JŒºF (x) formed by the remaining m columns of JF (x).
We are ready to solve locally the implicit equation F (x) = 0, now reading
F (Œæ, Œº) = 0, and obtain Œº = Œ¶(Œæ).
Theorem 7.5 (Implicit Function Theorem, or Dini‚Äôs Theorem) With
the above conventions, let x0 = (Œæ0, Œº0) ‚ààŒ© be a point such that F (x0) = 0.
If the matrix JŒºF (x0) is non-singular there exist neighbourhoods A ‚äÜŒ© of
x0, and I of Œæ0 in Rn‚àím, such that the zero set
{x ‚ààA : F (x) = 0}
of F coincides with the graph
{x =

Œæ, Œ¶(Œæ)

: Œæ ‚ààI}
of a C1 map Œ¶ : I ‚ÜíRm satisfying Œ¶(Œæ0) = Œº0. On I, the Jacobian of Œ¶
(with m rows and n ‚àím columns) is the solution of the linear system
JŒºF

Œæ, Œ¶(Œæ)

JŒ¶(Œæ) = ‚àíJŒæF

Œæ, Œ¶(Œæ)

.
(7.5)
Theorems 7.1 and 7.4 are special instances of the above, as can be seen taking
n = 2, m = 1, and n = 3, m = 1. The next example elucidates yet another case of
interest.
Example 7.6
Consider the system of two equations in three variables
 f1(x, y, z) = 0
f2(x, y, z) = 0
where fi are C1 on an open set Œ© in R3, and call x0 = (x0, y0, z0) ‚ààŒ© a solution.
Specialising the theorem with n = 3, m = 2 and F = (f1, f2) ensures that if
‚éõ
‚éú
‚éú
‚éù
‚àÇf1
‚àÇy (x0)
‚àÇf1
‚àÇz (x0)
‚àÇf2
‚àÇy (x0)
‚àÇf2
‚àÇz (x0)
‚éû
‚éü
‚éü
‚é†
is not singular, the system admits inÔ¨Ånitely many solutions around x0; these
are of the form

x,œï 1(x), œï2(x)

, where Œ¶ = (œï1, œï2) : I ‚äÇR ‚ÜíR2 is C1 on a
neighbourhood I of x0.

7.1 Implicit Function Theorem
267
The components of the Ô¨Årst derivative Œ¶‚Ä≤ at x ‚ààI solve the system
‚éõ
‚éú
‚éú
‚éù
‚àÇf1
‚àÇy

x,œï 1(x), œï2(x)

‚àÇf1
‚àÇz

x,œï 1(x), œï2(x)

‚àÇf2
‚àÇy

x,œï 1(x), œï2(x)

‚àÇf2
‚àÇz

x,œï 1(x), œï2(x)

‚éû
‚éü
‚éü
‚é†
‚éõ
‚éú
‚éù
œï‚Ä≤
1(x)
œï‚Ä≤
2(x)
‚éû
‚éü
‚é†=
= ‚àí
‚éõ
‚éú
‚éù
‚àÇf1
‚àÇx

x,œï 1(x), œï2(x)

‚àÇf2
‚àÇx

x,œï 1(x), œï2(x)

‚éû
‚éü
‚é†.
The function x ‚ÜíŒ≥(x) =

x,œï 1(x), œï2(x)

represents a (regular) curve in space.
2
7.1.1 Local invertibility of a function
One application is the following: if the Jacobian of a regular map of Rn is non-
singular, then the function is invertible around the point.
This generalises to multivariable calculus a property of functions of one real
variable, namely: if f is C1 around x0 ‚ààdom f ‚äÜR and if f ‚Ä≤(x0) Ã∏= 0, then
f ‚Ä≤ has constant sign around x0; as such it is strictly monotone, hence invertible;
furthermore, f ‚àí1 is diÔ¨Äerentiable and (f ‚àí1)‚Ä≤(y0) = 1/f ‚Ä≤(x0).
Proposition 7.7 Let f : dom f ‚äÜRn ‚ÜíRn be C1 around a point x0 ‚àà
dom f. If Jf(x0) is non-singular, the inverse function x = f ‚àí1(y) is well
deÔ¨Åned on a neighbourhood of y0 = f(x0), of class C1, and satisÔ¨Åes
J(f ‚àí1)(y0) =

Jf(x0)
‚àí1 .
(7.6)
Proof.
DeÔ¨Åne the auxiliary map F : dom f √ó Rn ‚äÜR2n ‚ÜíRn by F (x, y) =
f(x) ‚àíy. Then F (x0, y0) = 0 and JF (x0, y0) = ( Jf(x0) , I ) (an
n √ó 2n matrix). Since JxF (x0, y0) = Jf(x0), Theorem 7.5 guarantees
there is a neighbourhood Br(y0) and a C1 map g : Br(y0) ‚Üídom f
such that F

g(y), y

= 0, i.e., f

g(y)

= y, ‚àÄy ‚ààBr(y0). Therefore
g(y) = f ‚àí1(y), so (7.6) follows from (7.5).
2
The formula for the Jacobian of the inverse function was obtained in Corollary 6.16
as a consequence of the chain rule; that corollary‚Äôs assumptions are eventually
substantiated by the previous proposition.
What we have seen can be read in terms of a system of equations. Let us
interpret
f(x) = y
(7.7)
as a (non-linear) system of n equations in n unknowns, where the right-hand side
y is given and x is the solution. Suppose, for a given datum y0, that we know a

268
7 Applying diÔ¨Äerential calculus
solution x0. If the Jacobian Jf(x0) is non-singular, the equation (7.7) admits one,
and only one solution x in the proximity of x0, for any y suÔ¨Éciently close to y0.
In turn, the Jacobian‚Äôs invertibility at x0 is equivalent to the fact that the linear
system
f(x0) + Jf(x0)(x ‚àíx0) = y ,
(7.8)
obtained by linearising the left-hand side of (7.7) around x0, admits a solution
whichever y ‚ààRn is taken (it suÔ¨Éces to write the system as Jf(x0)x = y ‚àí
f(x0) + Jf(x0)x0 and notice the right-hand side assumes any value of Rn as y
varies in Rn).
In conclusion, the knowledge of one solution x0 of a non-linear equation for a
given datum y0, provided the linearised equation around that point can be solved,
guarantees the solvability of the non-linear equation for any value of the datum
that is suÔ¨Éciently close to y0.
Example 7.8
The system of non-linear equations
 x3 + y3 ‚àí2xy = a
3x2 + xy2 = b
admits (x0, y0) = (1, 2) as solution for (a, b) = (5, 7). Calling f(x, y) = (x3 +
y3 ‚àí2xy, 3x2 + xy2), we have
Jf(x, y) =
	
3x2 ‚àí2y
3y2 ‚àí2x
6x + y2
2xy

.
As
det Jf(1, 2) = det
	
10
4
‚àí1
10

= 104 > 0 ,
we can say the system admits a unique solution (x, y) for any choice of a, b close
enough to 5, 7 respectively.
2
7.2 Level curves and level surfaces
At this juncture we can resume level sets L(f, c) of a given function f, seen
in (4.20). The diÔ¨Äerential calculus developed so far allows us to describe such
sets at least in the case of suitably regular functions. The study of level sets oÔ¨Äers
useful informations on the function‚Äôs behaviour, as the constant c varies. At the
same time, solving an equation like
f(x, y) = 0 ,
or
f(x, y, z) = 0 ,
is, as a matter of fact, analogous to determining the level set L(f, 0) of f. Un-
der suitable assumptions, as we know, implicit relations of this type among the
independent variables generate regular and simple curves, or surfaces, in space.
In the sequel we shall consider only two and three dimensions, beginning from
the former situation.

7.2 Level curves and level surfaces
269
7.2.1 Level curves
Let then f be a real map of two real variables; given c ‚ààim f, denote by L(f, c) the
corresponding level set and let x0 ‚ààL(f, c). Suppose f is C1 on a neighbourhood
of the regular point x0, so that ‚àáf(x0) Ã∏= 0. Corollary 7.3 applies to the map
f(x) ‚àíc to say that on a certain neighbourhood B(x0) of x0 the points of L(f, c)
lie on a regular simple curve Œ≥ : I ‚ÜíB(x0) (a graph in one of the variables);
moreover, the point t0 ‚ààI such that Œ≥(t0) = x0 is in the interior of I. In other
terms,
L(f, c) ‚à©B(x0) = {x ‚ààR2 : x = Œ≥(t), with t ‚ààI} ,
whence
f

Œ≥(t)

= c
‚àÄt ‚ààI .
(7.9)
If the argument is valid for any point of L(f, c), hence if f is C1 on an open set
containing L(f, c) and all points of L(f, c) are regular, the level set is made of
traces of regular, simple curves. If so, one speaks of level curves of f. The next
property is particularly important (see Fig. 7.3).
Proposition 7.9 The gradient of a map is orthogonal to level curves at any
of their regular points.
Proof.
DiÔ¨Äerentiating (7.9) at t0 ‚ààI (recall (6.13)) gives
‚àáf(x0) ¬∑ Œ≥‚Ä≤(t) = 0 ,
and the result follows .
2
Moving along a level curve from x0 maintains the function constant, whereas in
the perpendicular direction the function undergoes the maximum variation (by
Proposition 5.10). It can turn out useful to remark that curlf, as of (6.7), is
always orthogonal to the gradient, so it is tangent to the level curves of f.
x = Œ≥(t)
x0
Œ≥‚Ä≤(t0)
‚àáf(x0)
Figure 7.3. Level curves and gradient of a map

270
7 Applying diÔ¨Äerential calculus
 
 
 
 
 
 
 
 
x
y
z
Figure 7.4. The relationship between graph and level sets
Fig. 7.4 shows the relationship between level curves and the graph of a map.
Recall that the level curves deÔ¨Åned by f(x, y) = c are the projections on the xy-
plane of the intersection between the graph of f and the planes z = c. In this
way, if we vary c by a Ô¨Åxed increment and plot the corresponding level curves, the
latter will be closer to each other where the graph is ‚Äústeeper‚Äù, and sparser where
it ‚ÄúÔ¨Çattens out‚Äù.
x
y
c = 0
c = 1
c = 2
c = 3
Figure 7.5. Level curves of f(x, y) =

9 ‚àíx2 ‚àíy2

7.2 Level curves and level surfaces
271
x
y
z
x
y
x
y
z
x
y
Figure 7.6. Graph and level curves of f(x, y) = ‚àíxye‚àíx2‚àíy2 (top), and f(x, y) =
‚àí
x
x2 + y2 + 1 (bottom)
Examples 7.10
i) The graph of f(x, y) =

9 ‚àíx2 ‚àíy2 was shown in Fig. 4.8. The level curves
are

9 ‚àíx2 ‚àíy2 = c
i.e.,
x2 + y2 = 9 ‚àíc2 .
This is a family of circles with centre the origin and radii
‚àö
9 ‚àíc2, see Fig. 7.5.
ii) Fig. 7.6 shows some level curves and the corresponding graph.
2
Patently, a level set may contain non-regular points of f, hence stationary
points. In such a case the level set may not be representable, around the point, as
trace of a curve.

272
7 Applying diÔ¨Äerential calculus
x
y
1
‚àí1
Figure 7.7. Level set L(f, 0) for f(x, y) = x4 ‚àíx2 + y2
Example 7.11
The level set L(f, 0) of
f(x, y) = x4 ‚àíx2 + y2
is shown in Fig. 7.7. The origin is a saddle-like stationary point. On every neigh-
bourhood of the origin the level set consists of two branches that intersect or-
thogonally; as such, it cannot be the graph of a function in one of the variables.
2
Archetypal examples of how level curves might be employed are the maps used
in topography, as in Fig. 7.8. On pictures representing a piece of land level curves
join points on the Earth‚Äôs surface at the same height above sea level: such paths
do not go uphill nor downhill, and in fact they are called isoclines (lit. ‚Äòof equal
inclination‚Äô).
Another frequent instance is the representation of the temperature of a certain
region at a given time. The level curves are called isotherms and connect points
with the same temperature. Similarly for isobars, the level curves on a map joining
points having identical atmospheric pressure.
Figure 7.8. Three-dimensional representation of a territory and the corresponding iso-
clines

7.2 Level curves and level surfaces
273
7.2.2 Level surfaces
In presence of three independent variables, level sets can be parametrised around
regular points. To be precise, if f is C1 around x0 ‚ààL(f, c) and ‚àáf(x0) Ã∏= 0, the
3-dimensional analogue of Corollary 7.3 (that easily descends from Theorem 7.4)
guarantees the existence of a neighbourhood B(x0) of x0 and of a regular, simple
surface œÉ : R ‚ÜíB(x0) such that
L(f, c) ‚à©B(x0) = {x ‚ààR3 : x = œÉ(u, v), with (u, v) ‚ààR} ,
hence
f

œÉ(u, v)

= c
‚àÄ(u, v) ‚ààR .
(7.10)
In other terms L(f, c) is locally the image of a level surface of f, and Proposition 7.9
has an analogue
Proposition 7.12 At any regular point, the gradient of a function is parallel
to the normal of the level surface.
Proof.
The partial derivatives of f ‚ó¶œÉ at (u0, v0) ‚ààR such that œÉ(u0, v0) = x0
are
‚àáf(x0) ¬∑ ‚àÇœÉ
‚àÇu (u0, v0) = 0 ,
‚àáf(x0) ¬∑ ‚àÇœÉ
‚àÇv (u0, v0) = 0 .
The claim follows now from (6.48)
2
Examples 7.13
i) The level surfaces of f(x, y, z) = x2 + y2 + z2 form a family of concentric
spheres with radii ‚àöc. The normal vectors are aligned with the gradient of f,
see Fig. 7.9.
ii) Let us explain how the Implicit Function Theorem, and its corollaries, may
be used for studying a surface deÔ¨Åned by an algebraic equation. Let Œ£ ‚äÇR3 be
the set of points satisfying
f(x, y, z) = 2x4 + 2y4 + 2z4 + x ‚àíy ‚àí6 = 0 .
The gradient ‚àáf(x, y, z) = (8x3+1, 8y3‚àí1, 8z3) vanishes only at P0 = (‚àí1
2, 1
2, 0),
but the latter does not satisfy the equation, i.e., P0 /‚ààŒ£. Therefore all points
P of Œ£ are regular, and Œ£ is a regular simple surface; around any point P the
surface can be represented as the graph of a function expressing one variable in
terms of the other two.
Notice also
lim
x‚Üí‚àûf(x) = +‚àû,
so the open set
Œ© = {(x, y, z) ‚ààR3 : f(x, y, z) < 0} ,

274
7 Applying diÔ¨Äerential calculus
x
y
z
x2 + y2 + z2 = 1
x2 + y2 + z2 = 4
x2 + y2 + z2 = 9
Figure 7.9. Level surfaces of f(x, y, z) =

x2 + y2 + z2
containing the origin and of which Œ£ is the boundary, is bounded; consequently
Œ£ is a compact set. One could prove Œ£ has no boundary, making it a closed
surface.
Proposition 7.9 proves, for example, that the normal vector (up to sign) to Œ£ at
P1 = (1, 1, 1) is proportional to ‚àáf(1, 1, 1) = (9, 7, 8). The unit normal ŒΩ at P1,
chosen to point away from the origin (ŒΩ ¬∑ x > 0), is then
ŒΩ =
1
‚àö
194(9i + 7j + 8k) .
2
7.3 Constrained extrema
With Sect. 5.6 we have learnt how to Ô¨Ånd extremum points lying inside the do-
main of a suÔ¨Éciently regular function. That does not exhaust all possible extrema
though, because there might be some lying on the domain‚Äôs boundary (without
mentioning some extrema could be non-regular points). At the same time in many
applications it is required we search for minimum and maximum points on a partic-
ular subset of the domain; for instance, if the subset is deÔ¨Åned through equations or
inequalities of the independent variable, one speaks about constrained extrema.
The present section develops two methods to Ô¨Ånd extrema of the kind just
described, and for this we start with an example.
Suppose we want to Ô¨Ånd the minimum of the linear map f(x) = a ¬∑ x, a =
(1,
‚àö
3) ‚ààR2, among the unit vectors x of the plane, hence under the constraint

7.3 Constrained extrema
275
‚à•x‚à•= 1. Geometrically, the point P = x = (x, y) can only move on the unit
circle x2 + y2 = 1. If g(x) = x2 + y2 ‚àí1 = 0 is the equation of the circle and
G = {x ‚ààR2 : g(x) = 0} the set of constrained points, we are looking for x0
satisfying
x0 ‚ààG
and
f(x0) = min
x‚ààG f(x) .
The problem can be tackled in two diÔ¨Äerent ways, one privileging the analytical
point of view, the other the geometrical aspects. The Ô¨Årst consists in reducing the
number of variables from two to one, by observing that the constraint is a simple
closed arc and as such can be written parametrically. Precisely, set Œ≥ : [0, 2œÄ] ‚ÜíR2,
Œ≥(t) = (cos t, sin t), so that G coincides with the trace of Œ≥. Then f restricted to
G becomes f ‚ó¶Œ≥, a function of the variable t; moreover,
min
x‚ààG f(x) =
min
t‚àà[0,2œÄ] f

Œ≥(t)

.
Now we Ô¨Ånd the extrema of œï(t) = f

Œ≥(t)

= cos t +
‚àö
3 sin t; the map is periodic
of period 2œÄ, so we can think of it as a map on R and ignore extrema that fall
outside [0, 2œÄ]. The Ô¨Årst derivative œï‚Ä≤(t) = ‚àísin t +
‚àö
3 cos t vanishes at t = œÄ
3 and
4
3œÄ. As œï‚Ä≤‚Ä≤( œÄ
3 ) = ‚àí2 < 0 and œï‚Ä≤‚Ä≤( 4
3œÄ) = 2 > 0, we have a maximum at t = œÄ
3
and a minimum at t = 4
3œÄ. Therefore there is only one solution to the original
constrained problem, namely x0 =

cos 4
3œÄ, sin 4
3œÄ

= ‚àí
 1
2,
‚àö
3
2

.
The same problem can be understood from a geometrical perspective relying
on Fig. 7.10. The gradient of f is ‚àáf(x) = a, and we recall f is increasing along
x
y
x0
x1
a
G
 
 
 
 
 
 
 
 
x
y
z
x0
x1
a
G
Figure 7.10. Level curves of f(x) = a ¬∑ x (left) and restriction to the constraint G
(right)

276
7 Applying diÔ¨Äerential calculus
a (with the greatest rate, actually, see Proposition 5.10); the level curves of f are
the perpendicular lines to a. Obviously, f restricted to the unit circle will reach
its minimum and maximum at the points where the level curves touch the circle
itself. These points are, respectively, x0 = ‚àí
 1
2,
‚àö
3
2

, which we already know of,
and its antipodal point x1 =
 1
2,
‚àö
3
2

. They may also be characterised as follows.
The gradient is orthogonal to level curves, and the circle is indeed a level curve for
g(x); to say therefore that the level curves of f and g are tangent at xi, i = 0, 1
tantamounts to requiring that the gradients are parallel; otherwise said at each
point xi there is a constant Œª such that
‚àáf(x) = Œª‚àág(x) .
These, together with the constraining equation g(x) = 0, allow to Ô¨Ånd the con-
strained extrema of f. In fact, we have
‚éß
‚é®
‚é©
Œªx = 1
Œªy =
‚àö
3
x2 + y2 = 1 ;
substituting the Ô¨Årst and second in the third equation gives
‚éß
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é©
x = 1
Œª
y =
‚àö
3
Œª
Œª2 = 4 ,
so
Œª = ¬±2 ,
and the solutions are x0 and x1. Since f(x0) < f(x1), x0 will be the minimum
point and x1 the maximum point for f.
In the general case, let f : dom f ‚äÜRn ‚ÜíR be a map in n real variables, and
G ‚ààdom f a proper subset of the domain of f, called in the sequel admissible
set. First of all we introduce the notion of constrained extremum.
DeÔ¨Ånition 7.14 A point x0 ‚ààG is said a relative extremum point of f
constrained to G if x0 is a relative extremum for the restriction f|G of f
to G. In other words, there exists a neighbourhood Br(x0) such that
‚àÄx ‚ààBr(x0) ‚à©G
f(x) ‚â§f(x0)
for a constrained maximum, or
‚àÄx ‚ààBr(x0) ‚à©G
f(x) ‚â•f(x0)
in case of a constrained minimum.

7.3 Constrained extrema
277
Constrained absolute maxima and minima are respectively deÔ¨Åned by
f(x0) = max
x‚ààG f(x)
and
f(x0) = min
x‚ààG f(x) .
A constrained extremum f is not necessarily an extremum as well. The function
f(x, y) = xy, for example, has a saddle at the origin, but when we restrict to the
bisectrix of the Ô¨Årst and third quadrant (or second and fourth), the origin becomes
a constrained absolute minimum (maximum).
A recurring situation is that in which the set G is a subset deÔ¨Åned by equations
or inequalities, called constraints. We begin by examining one constraint and one
equation, and consider a map g : dom g ‚äÜRn ‚ÜíR, with G ‚äÇdom g, such that
G = {x ‚ààdom g : g(x) = 0} ;
in other terms G is the zero set of g, or the level set L(g, 0). We discuss both
approaches mentioned in the foreword for this admissible set.
Assume henceforth f and g are C1 on an open set containing G. The aim is to
Ô¨Ånd the constrained extrema of f by looking at the stationary points of suitable
maps.
7.3.1 The method of parameters
This method originates from the possibility of writing the admissible set G in
parametric form, i.e., as image of a map deÔ¨Åned on a subset of Rn‚àí1. To be
precise, suppose we know a C1 map œà : A ‚äÜRn‚àí1 ‚ÜíRn such that
G = {x ‚ààRn : x = œà(u) with u ‚ààA} .
In dimensions 2 and 3, this forces G to be the trace of a curve œà = Œ≥ : I ‚ÜíR2 or
a surface œà = œÉ : R ‚ÜíR3. The function œà can be typically recovered from the
equation g(x) = 0; the Implicit Function Theorem 7.5 guarantees this is possible
provided G consists of regular points for g. Studying f restricted to G is equivalent
to studying the composite f ‚ó¶œà, so we will detect the latter‚Äôs extrema on A, which
has one dimension less than the domain of f. In particular, when n = 2 we will
consider the map t ‚Üíf

Œ≥(t)

of one variable, when n = 3 we will have the
two-variable map (u, v) ‚Üíf

œÉ(u, v)

.
Let us then examine the interior points of A Ô¨Årst, because if one such, say u0,
is an extremum for f ‚ó¶œà, then it is stationary; putting x0 = œà(u0), we necessarily
have
‚àáu(f ‚ó¶œà)(u0) = ‚àáf

œà(u0)

Jœà(u0) = 0 .
Stationary points solving the above equation have to be examined carefully to tell
whether they are extrema or not. After that, we inspect the boundary ‚àÇA to Ô¨Ånd
other possible extrema.

278
7 Applying diÔ¨Äerential calculus
x
y
A
B
C
G
O
Figure 7.11. The level curves and the admissible set of Example 7.15
Example 7.15
Consider f(x, y) = x2 + y ‚àí1 and let G be the perimeter of the triangle with
vertices O = (0, 0), A = (1, 0), B = (0, 1), see Fig. 7.11. We want to Ô¨Ånd the
minima and maxima of f on G, which exist by compactness. Parametrise the
three sides OA, OB, AB by Œ≥1(t) = (t, 0), Œ≥2(t) = (0, t), Œ≥3(t) = (t, 1 ‚àít),
where 0 ‚â§t ‚â§1 for all three. The map f|OA(t) = t2 ‚àí1 has minimum at O
and maximum at A; f|OB(t) = t ‚àí1 has minimum at O and maximum at B,
and f|AB(t) = t2 ‚àít has minimum at C =
 1
2, 1
2

and maximum at A and B.
Since f(O) = ‚àí1, f(A) = f(B) = 0 and f(C) = ‚àí1
4, the function reaches its
minimum value at O and its maximum at A and B.
2
7.3.2 Lagrange multipliers
The idea behind Lagrange multipliers is a particular feature of any regular con-
strained extremum point, shown in Fig. 7.12.
Proposition 7.16 Let x0 ‚ààG be a regular point for g. If x0 is an extremum
for f constrained to G, there exists a unique constant Œª0 ‚ààR, called Lag-
range multiplier, such that
‚àáf(x0) = Œª0‚àág(x0) .
(7.11)
Proof.
For simplicity we assume n = 2 or 3. In the former case what we have seen
in Sect. 7.2.1 applies to g, since x0 ‚ààG = L(g, 0). Thus a regular simple
curve Œ≥ : I ‚ÜíR2 exists, with x0 = Œ≥(t0) for some t0 interior to I, such
that g(x) = g

Œ≥(t)

= 0 on a neighbourhood of x0; additionally,
‚àág(x0) ¬∑ Œ≥‚Ä≤(t0) = 0 .

7.3 Constrained extrema
279
x0
‚àág
‚àáf
G
Figure 7.12. At a constrained extremum the gradients of f and g are parallel
But by assumption t ‚Üíf

Œ≥(t)

has an extremum at t0, which is stationary
by Fermat‚Äôs Theorem. Consequently
d
dtf

Œ≥(t)

|t=t0 = ‚àáf(x0) ¬∑ Œ≥‚Ä≤(t0) = 0 .
As ‚àáf(x0) and ‚àág(x0) are both orthogonal to the same vector Œ≥‚Ä≤(t0) Ã∏= 0
(Œ≥ being regular), they are parallel, i.e., (7.11) holds. The uniqueness of
Œª0 follows from ‚àág(x0) Ã∏= 0.
The proof in three dimensions is completely similar, because on the one
hand g

œÉ(u, v)

= 0 around x0 for a suitable regular and simple surface
œÉ : A ‚ÜíR3 (Sect. 7.2.2); on the other the map f

œÉ(u, v)

has a relative
extremum at (u0, v0), interior to A and such that œÉ(u0, v0) = x0. At the
same time then
‚àág(x0)JœÉ(u0, v0) = 0 ,
and
‚àáf(x0)JœÉ(u0, v0) = 0 .
As œÉ is regular, the column vectors of JœÉ(u0, v0) are linearly independent
and span the tangent plane to œÉ at x0. The vectors ‚àáf(x0) and ‚àág(x0)
are both perpendicular to the plane, and so parallel.
2
This is the right place to stress that (7.11) can be fulÔ¨Ålled, with g(x) = 0,
also by a point x0 which is not a constrained extremum. That is because the
two conditions are necessary yet not suÔ¨Écient for the existence of a constrained
extremum. For example, f(x, y) = x ‚àíy5 and g(x, y) = x ‚àíy3 satisfy g(0, 0) = 0,
‚àáf(0, 0) = ‚àág(0, 0) = (1, 0); nevertheless, f restricted to G = {(x, y) ‚ààR2 :
x = y3} has neither a minimum nor a maximum at the origin, for it is given by
y ‚Üíf(y3, y) = y3 ‚àíy5 (y0 = 0 is a horizontal inÔ¨Çection point).
There is an equivalent formulation for the previous proposition, that associates
to x0 an unconstrained stationary point relative to a new function depending on
f and g.

280
7 Applying diÔ¨Äerential calculus
DeÔ¨Ånition 7.17 Set Œ© = dom f ‚à©dom g ‚äÜRn. The function L : Œ© √óR ‚ÜíR
deÔ¨Åned by
L(x, Œª) = f(x) ‚àíŒªg(x)
is said Lagrangian (function) of f constrained to g.
The gradient of L looks as follows
‚àá(x,Œª)L(x, Œª) =

‚àáxL(x, Œª), ‚àÇL
‚àÇŒª (x, Œª)

=

‚àáf(x) ‚àíŒª‚àág(x), g(x)

.
Hence the condition ‚àá(x,Œª)L(x0, Œª0) = 0, expressing that (x0, Œª0) is stationary for
L, is equivalent to the system
 ‚àáf(x0) = Œª0‚àág(x0) ,
g(x0) = 0 .
Proposition 7.16 ensures that each regular extremum point of f constrained by g
determines a unique stationary point for the Lagrangian L.
Under this new light, the procedure breaks into the following steps.
i)
Write the system of n + 1 equations in n + 1 unknowns x = (x1, . . . , xn)
and Œª
 ‚àáf(x) = Œª‚àág(x)
g(x) = 0
(7.12)
and solve it; as the system is not, in general, linear, there may be a number
of distinct solutions.
ii) For each solution (x0, Œª0) found, decide whether x0 is a constrained ex-
tremum for f, often with ad hoc arguments.
In general, after (7.12) has been solved, the multiplier Œª0 stops being useful.
If G is compact for instance, Weierstrass‚Äô Theorem 5.24 guarantees the
existence of an absolute minimum and maximum of f|G (distinct if f is not
constant on G); therefore, assuming G only consists of regular points for
g, these two must be among the ones found previously; comparing values
will permit us to pin down minima and maxima.
iii) In presence of non-regular points (stationary) for g in G (or points where
f and/or g are not diÔ¨Äerentiable) we are forced to proceed case by case,
lacking a general procedure.

7.3 Constrained extrema
281
 
 
 
 
 
x
y
z
x1
x2
x3
x4
x5
x6
x7
Figure 7.13. The graph of the admissible set G (Ô¨Årst octant only) and the stationary
points of f on G (Example 7.18)
Example 7.18
Let us Ô¨Ånd the points of R3 lying on the manifold deÔ¨Åned by x4 + y4 + z4 = 1
with smallest and largest distance from the origin (see Fig. 7.13).
The problem consists in extremising the function f(x, y, z) = ‚à•x‚à•2 = x2+y2+z2
on the set G deÔ¨Åned by g(x, y, z) = x4 + y4 + z4 ‚àí1 = 0. We consider the square
distance, rather than the distance ‚à•x‚à•=

x2 + y2 + z2, because the two have
the same extrema, but the former has the advantage of simplifying computations.
We use Lagrange multipliers, and consider the system (7.12):
‚éß
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é©
2x = Œª4x3
2y = Œª4y3
2z = Œª4z3
x4 + y4 + z4 ‚àí1 = 0 .
As f is invariant under sign change in its arguments, f(¬±x, ¬±y, ¬±z) = f(x, y, z),
and similarly for g, we can just look for solutions belonging in the Ô¨Årst octant
(x ‚â•0, y ‚â•0, z ‚â•0). The Ô¨Årst three equations are solved by
x = 0 or x =
1
‚àö
2Œª
,
y = 0 or y =
1
‚àö
2Œª
,
z = 0 or z =
1
‚àö
2Œª
,
combined in all possible ways. The point (x, y, z) = (0, 0, 0) is to be excluded
because it fails to satisfy the last equation. The choices

1
‚àö
2Œª, 0, 0

,

0,
1
‚àö
2Œª, 0

or

0, 0,
1
‚àö
2Œª

force
1
4Œª2 = 1, hence Œª = 1
2 (since Œª > 0). Similarly, (x, y, z) =

1
‚àö
2Œª,
1
‚àö
2Œª, 0

,

1
‚àö
2Œª, 0,
1
‚àö
2Œª

or

0,
1
‚àö
2Œª,
1
‚àö
2Œª

satisfy the fourth equation if Œª =
‚àö
2
2 , while

1
‚àö
2Œª,
1
‚àö
2Œª,
1
‚àö
2Œª

fulÔ¨Ålls it if Œª =
‚àö
3
2 . The solutions then are:
x1 = (1, 0, 0) , f(x1) = 1 ;
x4 =
 1
4‚àö
2,
1
4‚àö
2, 0

, f(x4) =
‚àö
2 ;
x2 = (0, 1, 0) , f(x2) = 1 ;
x5 =
 1
4‚àö
2, 0,
1
4‚àö
2

, f(x5) =
‚àö
2 ;

282
7 Applying diÔ¨Äerential calculus
x3 = (0, 0, 1) ,
f(x3) = 1 ;
x6 =

0,
1
4‚àö
2,
1
4‚àö
2

, f(x6) =
‚àö
2 ;
x7 =
 1
4‚àö
3,
1
4‚àö
3,
1
4‚àö
3

, f(x7) =
‚àö
3 .
In conclusion, the Ô¨Årst octant contains 3 points of G, x1, x2, x3, with the shortest
distance to the origin, and 1 farthest point x7. The distance function on G has
stationary points x4, x5, x6, but no minimum nor maximum.
2
Now we pass to brieÔ¨Çy consider the case of an admissible set G deÔ¨Åned by
m < n equalities, of the type gi(x) = 0, 1 ‚â§i ‚â§m. If x0 ‚ààG is a constrained
extremum for f on G and regular for each gi, the analogue to Proposition 7.16
tells us there exist m constants Œª0i, 1 ‚â§i ‚â§m (the Lagrange multipliers), such
that
‚àáf(x0) =
m

i=1
Œª0i‚àági(x0) .
Equivalently, set Œª = (Œªi)i=1,...,m) ‚ààRm and g(x) =

g1(x)

i=1,...,m: then the
Lagrangian
L(x, Œª) = f(x) ‚àíŒª ¬∑ g(x)
(7.13)
admits a stationary point (x0, Œª0). To Ô¨Ånd such points we have to write the system
of n + m equations in the n + m unknowns given by the components of x and Œª,
‚éß
‚é™
‚é®
‚é™
‚é©
‚àáf(x) =
m

i=1
Œªi‚àági(x) ,
gi(x) = 0 ,
1 ‚â§i ‚â§m ,
which generalises (7.12).
Example 7.19
We want to Ô¨Ånd the extrema of f(x, y, z) = 3x + 3y + 8z constrained to the
intersection of two cylinders, x2 + z2 = 1 and y2 + z2 = 1. DeÔ¨Åne
g1(x, y, z) = x2 + z2 ‚àí1
and
g2(x, y, z) = y2 + z2 ‚àí1
so that the admissible set is G = G1 ‚à©G2, Gi = L(gi, 0). Each point of Gi is
regular for gi, so the same is true for G. Moreover G is compact, so f certainly
has minimum and maximum on it.
As ‚àáf = (3, 3, 8), ‚àág1 = (2x, 0, 2z), ‚àág2 = (0, 2y, 2z), system (7.13) reads
‚éß
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é©
3 = Œª12x
3 = Œª22y
8 = (Œª1 + Œª2)2z
x2 + z2 ‚àí1 = 0
y2 + z2 ‚àí1 = 0 ;

7.3 Constrained extrema
283
the Ô¨Årst three equations tell x =
3
2Œª1 , y =
3
2Œª2 , z =
4
Œª1+Œª2 , (with Œª1 Ã∏= 0, Œª2 Ã∏= 0,
Œª1 + Œª2 Ã∏= 0), so that the remaining two give
Œª1 = Œª2 = ¬±5
2 .
Then, setting x0 =
 3
5, 3
5, 4
5

and x1 = ‚àíx0, we have f(x0) > 0 and f(x1) < 0.
We conclude that x0 is an absolute constrained maximum point, while x1 is an
absolute constrained minimum.
2
Finally, let us assess the case in which the set G is deÔ¨Åned by m inequalities;
without loss of generality we may assume the constraints are of type gi(x) ‚â•0,
i = 1, . . . , m. So Ô¨Årst we examine interior points of G, with the techniques of
Sect. 5.6. Secondly, we look at the boundary ‚àÇG of G, indeed at points where at
least one inequality is actually an equality. This generates a constrained extremum
problem on ‚àÇG, which we know how to handle.
Due to the profusion of situations, we just describe a few possibilities using
examples.
Examples 7.20
i) Let us return to Example 7.15, and suppose we want to Ô¨Ånd the extrema of f
on the whole triangle G of vertices O, A, B.
Set g1(x, y) = x, g2(x, y) = y, g3(x, y) = 1 ‚àíx ‚àíy, so that G = {(x, y) ‚àà
R2 : gi(x, y) ‚â•0, i = 1, 2, 3}. There are no extrema on the interior of G, since
‚àáf(x) = (2x, 1) Ã∏= 0 precludes the existence of stationary points. The extrema
of f on G, which have to be present by the compactness of G, must then belong
to the boundary, and are those we already know of from Example 7.15.
ii) We look for the extrema of f of Example 7.18 that belong to G deÔ¨Åned by
x4 + y4 + z4 ‚â§1. As ‚àáf(x) = 2x, the only extremum interior to G is the origin,
where f reaches the absolute minimum. But G is compact, so there must also be
an absolute maximum somewhere on the boundary ‚àÇG. The extrema constrained
to the latter are exactly those of the example, so we conclude that f is maximised
on G by x7 =
 1
4‚àö
3,
1
4‚àö
3,
1
4‚àö
3

, and at the other seven points obtained from this
by Ô¨Çipping any sign.
iii) We determine the extrema of f(x, y) = (x + y)e‚àí(x2+y2) subject to g(x, y) =
2x + y ‚â•0. Note immediately that f(x, y) ‚Üí0 as ‚à•x‚à•‚Üí‚àû, so f must admit
absolute maximum and minimum on G. The interior points where the constraint
holds form the (open) half-space y > ‚àí2x. Since
‚àáf(x) = e‚àí(x2+y2)
1 ‚àí2x(x + y), 1 ‚àí2y(x + y)

,
f has stationary points x = ¬±
 1
2, 1
2

; the only one of these inside G is x0 =
 1
2, 1
2

, for which Hf(x0) = ‚àíe‚àí1/2
	
3
1
1
3

. The Hessian matrix tells us that
x0 is a relative maximum for f. On the boundary ‚àÇG, where y = ‚àí2x, the
composite map
œï(x) = f(x, ‚àí2x) = ‚àíxe‚àí5x2

284
7 Applying diÔ¨Äerential calculus
x
y
x0
x1
x2
Figure 7.14. The level curves of f and the admissible set G of Example 7.20 iii)
admits absolute maximum at x = ‚àí
1
‚àö
10 and minimum at x =
1
‚àö
10. Setting
x1 =

1
‚àö
10, ‚àí
2
‚àö
10

and x2 =

‚àí
1
‚àö
10,
2
‚àö
10

, we can without doubt say x1 is the
unique absolute minimum on G. For the absolute maxima, we need to compare
the values attained at x0 and x2. But since f(x0) = e‚àí1/2 and f(x2) =
1
‚àö
10e‚àí1/2,
x0 is the only absolute maximum point on G (Fig. 7.14).
iv) Consider f(x, y) = x + 2y on the set G deÔ¨Åned by
x + 2y + 8 ‚â•0 ,
5x + y + 13 ‚â•0 ,
x ‚àí4y + 11 ‚â•0 ,
2x + y ‚àí5 ‚â§0 ,
5x ‚àí2y ‚àí8 ‚â§0 .
x
y
A
B
C
D
E
Figure 7.15. Level curves of f and admissible set G of Example 7.20 iv)

7.4 Exercises
285
The set G is the (irregular) pentagon of Fig. 7.15, having vertices A = (0, ‚àí4),
B = (‚àí2, ‚àí3), C = (‚àí3, 2), D = (1, 3), E = (2, 1) and obtained as intersection
of the Ô¨Åve half-planes deÔ¨Åned by the above inequalities. As ‚àáf(x) = (1, 2) Ã∏= 0,
the function f attains minimum and maximum on the boundary of G; and since
f is linear on the perimeter, any extremum point must be a vertex. Thus it is
enough to compare the values at the corners
f(A) = f(B) = ‚àí8 ,
f(C) = 1 ,
f(D) = 7 ,
f(E) = 4 ;
f restricted to G is smallest at each point of AB and largest at D. This simple
example is the typical problem dealt with by Linear Programming, a series of
methods to Ô¨Ånd extrema of linear maps subject to constraints given by linear
inequalities. Linear Programming is relevant in many branches of Mathemat-
ics, like Optimization and Operations Research. The reader should refer to the
speciÔ¨Åc literature for further information on the matter.
2
7.4 Exercises
1.
Supposing you are able to write x3y + xy4 = 2 in the form y = œï(x), compute
œï‚Ä≤(x). Determine a point x0 around which this is feasible.
2.
The equation x2 + y3z =
xz
y
admits the solution (2, 1, 4). Verify it can be
written as y = œï(x, z), with œï deÔ¨Åned on a neighbourhood of (2, 4). Compute
the partial derivatives of œï at (2, 4).
3.
Check that
ex‚àíy + x2 ‚àíy2 ‚àíe(x + 1) + 1 = 0
deÔ¨Ånes a function y = œï(x) on a neighbourhood of x0 = 0. What is the nature
of the point x0 for œï?
4.
Verify that the equation
x2 + 2x + ey + y ‚àí2z3 = 0
gives a map y = œï(x, z) deÔ¨Åned around P = (x0, z0) = (‚àí1, 0). Such map
deÔ¨Ånes a surface, of which the tangent plane at the point P should be determ-
ined.
5.
a) Verify that around P0 = (0, 2, ‚àí1) the equation
x log(y + z) + 3(y ‚àí2)z + sin x = 0
deÔ¨Ånes a regular simple surface Œ£.
b) Determine the tangent plane to Œ£ at P0, and the unit normal forming with
v = 4i + 2j ‚àí5k an acute angle.

286
7 Applying diÔ¨Äerential calculus
6.
Check that the system
 3x ‚àícos y + y + ez = 0
x ‚àíex ‚àíy + z + 1 = 0
yields, around the origin, a curve in space of equations
Œ≥(t) =

t,œï 1(t), œï2(t)

,
t ‚ààI(0) .
Write the equation of the tangent to the curve at the origin.
7.
Verify that
y7 + 3y ‚àí2xe3x = 0
deÔ¨Ånes a function y = œï(x) for any x ‚ààR. Study œï and sketch its graph.
8. Represent the following maps‚Äô level curves:
a)
f(x, y) = 6 ‚àí3x ‚àí2y
b)
f(x, y) = 4x2 + y2
c)
f(x, y) = 2xy
d)
f(x, y) = 2y ‚àí3 log x
e)
f(x, y) =

4x + 3y
f)
f(x, y) = 4x ‚àí2y2
9.
Match the functions below to the graphs A‚ÄìF of Fig. 7.16 and to the level
curves I‚ÄìVI of Fig. 7.17:
a) z = cos

x2 + 2y2
b) z = (x2 ‚àíy2)e‚àíx2‚àíy2
c) z =
15
9x2 + y2 + 1
d) z = x3 ‚àí3xy2
e) z = cos x sin 2y
f) z = 6 cos2 x ‚àí1
10x2
10.
Describe the level surfaces of the following maps:
a)
f(x, y, z) = x + 3y + 5z
b)
f(x, y, z) = x2 ‚àíy2 + z2
11.
Determine the maximum and minimum points of
f(x, y) = x2 + y2 + 3
2x + 1
on the set G = {(x, y) ‚ààR2 : 4x2 + y2 ‚àí1 = 0}.
12.
Find maximum and minimum points for f(x, y) = x + 3y + 2 on the compact
set G = {(x, y) ‚ààR2 : x, y ‚â•0, x2 + y2 ‚â§1}.

7.4 Exercises
287
 
A
 
B
 
C
 
D
 
E
 
F
Figure 7.16. The graphs of Exercise 9
I
II
III
IV
V
V I
Figure 7.17. The level curves of Exercise 9

288
7 Applying diÔ¨Äerential calculus
13.
Consider the function
f(x, y) = x2(y + 1) ‚àí2y .
a) Find its stationary points and describe their type.
b) Compute the map‚Äôs absolute minimum and maximum on the set
G = {(x, y) ‚ààR2 :

1 + x2 ‚â§y ‚â§2} .
14.
Determine the extrema of f(x, y) = 2x2 + y2 constrained to
G = {(x, y) ‚ààR2 : x4 ‚àíx2 + y2 ‚àí5 = 0} .
15.
What are the absolute minimum and maximum of f(x, y) = 4x2 + y2 ‚àí2x ‚àí
4y + 1 on
G = {(x, y) ‚ààR2 : 4x2 + y2 ‚àí1 = 0} ?
7.4.1 Solutions
1. Set f(x, y) = x3y + xy4 ‚àí2; then
fx(x, y) = 3x2y + y4
and
fy(x, y) = x3 + 4xy3 ,
so
œï‚Ä≤(x) = ‚àí3x2œï(x) +

œï(x)
4
x3 + 4x

œï(x)
3
for any x Ã∏= 0 with x2 Ã∏= ‚àí4y3.
For instance, the point (x0, y0) = (1, 1) solves the equation, thus there is a map
y = œï(x) deÔ¨Åned around x0 = 1 because fy(1, 1) = 5 Ã∏= 0. Moreover, œï‚Ä≤(1) = ‚àí4/5.
2. Setting f(x, y, z) = x2 + y3z ‚àíxz
y , we have
fx(x, y, z) = 2x ‚àíz
y
with fx(2, 1, 4) = 0 ,
fy(x, y, z) = 3y2z + xz
y2
with fy(2, 1, 4) = 20 Ã∏= 0 ,
fz(x, y, z) = y3 ‚àíx
y
with fz(2, 1, 4) = ‚àí1 Ã∏= 0 .
Due to Theorem 7.4 we can solve for y, hence express y as a function of x and z,
around (2, 4); otherwise said, there exists y = œï(x, z) such that
‚àÇœï
‚àÇx (2, 4) = 0 ,
‚àÇœï
‚àÇz (2, 4) = 1
20 .

7.4 Exercises
289
3. Call f(x, y) = ex‚àíy + x2 ‚àíy2 ‚àíe(x + 1) + 1 and notice (0, ‚àí1) is a solution.
Then
fx(x, y) = ex‚àíy + 2x ‚àíe ,
fy(x, y) = ‚àíex‚àíy ‚àí2y
with fx(0, ‚àí1) = 0, fy(0, ‚àí1) = 2 ‚àíe Ã∏= 0. Theorem 7.1 guarantees the existence
of a map y = œï(x), deÔ¨Åned around the origin, such that
œï‚Ä≤(0) = ‚àífx(0, ‚àí1)
fy(0, ‚àí1) = 0 .
Hence x0 = 0 is a critical point of œï.
4. If we set
f(x, y, z) = x2 + 2x + ey + y ‚àí2z3
then f(‚àí1, 0, 0) = 0. We have
fx(x, y, z) = 2x + 2
with fx(‚àí1, 0, 0) = 0 ,
fy(x, y, z) = ey + 1
with fy(‚àí1, 0, 0) = 2 Ã∏= 0 ,
fz(x, y, z) = ‚àí6z2
with fz(‚àí1, 0, 0) = 0 .
By Theorem 7.4 there is a map y = œï(x, z) around (‚àí1, 0) satisfying
‚àÇœï
‚àÇx (‚àí1, 0) = ‚àÇœï
‚àÇz (‚àí1, 0) = 0 .
The tangent plane is therefore
y = œï(‚àí1, 0) + œïx(‚àí1, 0)(x + 1) + œïz(‚àí1, 0)(z ‚àí0) = 0 .
5. a) The gradient of f(x, y, z) = x log(y + z) + 3(y ‚àí2)z + sin x is
‚àáf(x, y, z) =

log(y + z) + cos x,
x
y + z + 3z,
x
y + z + 3(y ‚àí2)

,
so ‚àáf(P0) = (1, ‚àí3, 0) Ã∏= 0. By Theorem 7.4 then, we can express x via y and
z, or y in terms of x, z. Therefore, around P0 the surface Œ£ is locally a regular
simple graph.
b) The tangent plane at P0 = x0 is, recalling Proposition 7.9,
‚àáf(x0) ¬∑ (x ‚àíx0) = x ‚àí3(y ‚àí2) = 0 ,
so x ‚àí3y = ‚àí6. The unit normal at P0 will be ŒΩ =
œÉ
‚àö
10(i ‚àí3j), with œÉ ‚àà{¬±1}
deÔ¨Åned by ŒΩ ¬∑ v = ‚àí2œÉ
‚àö
10 > 0, whence œÉ = ‚àí1.
6. Referring to Theorem 7.5 and Example 7.6, let us set
 f1(x, y, z) = 3x ‚àícos y + y + ez
f2(x, y, z) = x ‚àíex ‚àíy + z + 1 .

290
7 Applying diÔ¨Äerential calculus
Then
‚àÇf1
‚àÇy (x, y, z) = sin y + 1 ,
‚àÇf1
‚àÇz (x, y, z) = ez ,
‚àÇf2
‚àÇy (x, y, z) = ‚àí1 ,
‚àÇf2
‚àÇz (x, y, z) = 1 .
Now consider the matrix
‚éõ
‚éú
‚éú
‚éù
‚àÇf1
‚àÇy (0)
‚àÇf1
‚àÇz (0)
‚àÇf2
‚àÇy (0)
‚àÇf2
‚àÇz (0)
‚éû
‚éü
‚éü
‚é†=
‚éõ
‚éù
1
1
‚àí1
1
‚éû
‚é†;
this being non-singular, it deÔ¨Ånes around t = 0 a curve Œ≥(t) =

t,œï 1(t), œï2(t)

.
For the tangent line we need to compute Œ≥‚Ä≤(t) =

1, œï‚Ä≤
1(t), œï‚Ä≤
2(t)

, and in par-
ticular Œ≥‚Ä≤(0) =

1, œï‚Ä≤
1(0), œï‚Ä≤
2(0)

. But
‚éõ
‚éú
‚éú
‚éù
‚àÇf1
‚àÇy (0)
‚àÇf1
‚àÇz (0)
‚àÇf2
‚àÇy (0)
‚àÇf2
‚àÇz (0)
‚éû
‚éü
‚éü
‚é†
‚éõ
‚éù
œï‚Ä≤
1(0)
œï‚Ä≤
2(0)
‚éû
‚é†= ‚àí
‚éõ
‚éú
‚éú
‚éù
‚àÇf1
‚àÇx (0)
‚àÇf2
‚àÇx (0)
‚éû
‚éü
‚éü
‚é†
is

1
1
‚àí1
1
 
œï‚Ä≤
1(0)
œï‚Ä≤
2(0)

= ‚àí

3
0

,
so
 œï‚Ä≤
1(0) + œï‚Ä≤
2(0) = ‚àí3
œï‚Ä≤
1(0) ‚àíœï‚Ä≤
2(0) = 0
,
solved by œï‚Ä≤
1(0) = œï‚Ä≤
2(0) = ‚àí3/2. In conclusion, the tangent line is
T (t) = Œ≥(0) + Œ≥‚Ä≤(0)t =

1, ‚àí3
2, ‚àí3
2

t =

t, ‚àí3
2t, ‚àí3
2t

.
7. The map f(x, y) = y7 + 3y ‚àí2xe3x has derivatives
fx(x, y) = ‚àí2e3x(1 + 3x) ,
fy(x, y) = 7y6 + 3 > 0 .
Theorem 7.1 says we can have y as a function of x around every point of R2, so
let y = œï(x) be such a map. Then
œï‚Ä≤(x) = ‚àífx(x, y)
fy(x, y) = 2e3x(1 + 3x)
7y6 + 3
,
and œï‚Ä≤(x) = 0 for x = ‚àí1/3, œï‚Ä≤(x) > 0 for x > ‚àí1/3. Observe that f(0, 0) = 0, so
œï(0) = 0. The function passes through the origin, is increasing when x > ‚àí1/3,
decreasing when x < ‚àí1/3. The point x = ‚àí1/3 is an (absolute) minimum for œï,
with œï(‚àí1/3) < 0.

7.4 Exercises
291
x
y
‚àí1
3
Figure 7.18. The graph of the implicit function of Exercise 7
To compute the limits as x ‚Üí¬± ‚àû, note

œï(x)
7 + 3

œï(x)

= 2xe3x
and
lim
x‚Üí‚àí‚àû2xe3x = 0 ,
lim
x‚Üí+‚àû2xe3x = +‚àû.
Let ‚Ñì=
lim
x‚Üí‚àí‚àûœï(x), so that
‚Ñì7 + 3‚Ñì= ‚Ñì(‚Ñì6 + 3) = 0
and hence
‚Ñì= 0 .
Then call m =
lim
x‚Üí+‚àûœï(x); necessarily m = +‚àû, for otherwise we would have
m7 + 3m = +‚àû, a contradiction.
In summary,
lim
x‚Üí‚àí‚àûœï(x) = 0 ,
lim
x‚Üí+‚àûœï(x) = +‚àû;
the point x = ‚àí1/3 is an absolute minimum and the graph of f can be seen in
Fig. 7.18.
8. Level curves:
a) These are the level curves:
6 ‚àí3x ‚àí2y = k
i.e.,
3x + 2y + k ‚àí6 = 0 .
They form a family of parallel lines with slope ‚àí3/2, see Fig. 7.19, left.
b) The level curves
4x2 + y2 = k
i.e.,
x2
k/4 + y2
k = 1 ,
are, for k > 0, a family of ellipses centred at the origin and semi-axes
‚àö
k/2,
‚àö
k. See Fig. 7.19, right.

292
7 Applying diÔ¨Äerential calculus
x
y
x
y
Figure 7.19. Level curves of f(x, y) = 6 ‚àí3x ‚àí2y (left), and of f(x, y) = 4x2 + y2
(right)
c) See Fig. 7.20, left.
d) See Fig. 7.20, right.
e) See Fig. 7.21, left.
f) See Fig. 7.21, right.
9. The correct matches are : a-D-IV; b-E-III; c-A-V; d-B-I; e-C-VI; f-F-II.
10. Level surfaces:
a) We are considering a family of parallel planes of equation
x + 3y + 5z ‚àík = 0 .
b) These are hyperboloids (with one or two sheets) with axis on the y-axis.
x
y
k > 0
k = 0
k < 0
k > 0
k < 0
x
y
Figure 7.20. Level curves of f(x, y) = 2xy (left), and of f(x, y) = 2y ‚àí3 log x (right)

7.4 Exercises
293
x
y
x
y
Figure 7.21. Level curves of f(x, y) = ‚àö4x + 3y (left), and of f(x, y) = 4x ‚àí2y2 (right)
11. The set G is an ellipse that we can parametrise as Œ≥(t) =
 1
2 cos t, sin t

,
t ‚àà[0, 2œÄ). Thus
œï(t) = f ‚ó¶Œ≥(t) = 1
4 cos2 t + sin2 t + 3
4 cos t + 1 = ‚àí3
4 cos2 t + 3
4 cos t + 2 ,
with
œï‚Ä≤(t) = 3
2 sin t cost ‚àí3
4 sin t = 3
2 sin t

cos t ‚àí1
2

.
Note œï‚Ä≤(t) = 0 for sin t = 0 or cos t = 1
2, so for t1 = 0, t2 = œÄ, t3 = œÄ
3 , t4 = 5
3œÄ.
Moreover, œï‚Ä≤(t) > 0 for t ‚àà

0, œÄ
3

‚à™

œÄ, 5
3œÄ

, hence œï increases on

0, œÄ
3

and

œÄ, 5
3œÄ

, while it decreases on
 œÄ
3 , œÄ

and
 5
3œÄ, 2œÄ

. Therefore P1 = Œ≥(t1) = ( 1
2, 0)
and P2 = Œ≥(t2) = (‚àí1
2, 0) are local minima with values f(P1) = 2, f(P2) = 1
2;
the points P3 = Œ≥(t3) = ( 1
4,
‚àö
3
2 ), P4 = Œ≥(t4) = ( 1
4, ‚àí
‚àö
3
2 ) are local maxima with
f(P3) = f(P4) = 35
16. In particular, the maximum value of f on G is 35
16, reached
at both P3 and P4, while the minimum value 1/2 is attained at P2.
An alternative way to solve the exercise is to use Lagrange multipliers. If we
set g(x, y) = 4x2 + y2 ‚àí1, the Lagrangian is
L(x, y,Œª ) = f(x, y) ‚àíŒªg(x, y) .
Since ‚àáf(x, y) = (2x + 3
2, 2y), ‚àág(x, y) = (8x, 2y), we have to solve the system
‚éß
‚é™
‚é®
‚é™
‚é©
2x + 3
2 = 8Œªx
2y = 2Œªy
4x2 + y2 = 1 .
From the second equation we get Œª = 1 or y = 0. With Œª = 1 we Ô¨Ånd x = 1
4,
y = ¬±
‚àö
3
2
(the points P3, P4); taking y = 0 gives x = ¬± 1
2 (and we obtain P1 and
P2). Computing f at these points clearly gives the same result of the parameters‚Äô
method.

294
7 Applying diÔ¨Äerential calculus
12. Since ‚àáf(x, y) = (1, 3) Ã∏= (0, 0) for all (x, y), there are no critical points on
the interior of G. We look for extrema on the boundary, which must exist by
Weierstrass‚Äô Theorem. Now, ‚àÇG decomposes in three pieces: two segments, on the
x- and the y-axis, that join the origin to the points A = (1, 0) and B = (0, 1),
and the arc of unit circle connecting A to B. Restricted to the segment OA,
the function is f(x, 0) = x + 2, x ‚àà[0, 1], so x = 0 is a (local) minimum with
f(0, 0) = 2, and x = 1 is a (local) maximum with f(1, 0) = 3. Similarly, on OB
the map is f(0, y) = 3y + 2, y ‚àà[0, 1], so y = 0 is a (local) minimum, f(0, 0) = 2,
and y = 1 a (local) maximum with f(0, 1) = 5. At last, parametrising the arc by
Œ≥(t) = (cos t, sin t), t ‚àà[0, œÄ /2] gives
œï(t) = f ‚ó¶Œ≥(t) = cos t + 3 sin t + 2 .
Since œï‚Ä≤(t) = ‚àísin t + 3 cost is zero at t0 = arctan3, and œï‚Ä≤(t) > 0 for t ‚àà[0, t0],
the function f has a (local) maximum at Œ≥(t0) = (x0, y0). To compute x0, y0
explicitly, observe that
 sin t0 = 3 cost0
sin2 t0 + cos2 t0 = 1 ,
whence 9 cos2 t0 + cos2 t0 = 9x2
0 + x2
0 = 10x2
0 = 1, x0 = 1/
‚àö
10, and so y0 = 3/
‚àö
10
(remember x, y ‚â•0 on G). Furthermore, f(x0, y0) = 2 +
‚àö
10. Overall, the origin
is the absolute minimum and (x0, y0) the absolute maximum for f.
13. a) Given that ‚àáf(x, y) =

2x(y + 1), x2 ‚àí2

, the stationary points are P1 =
(
‚àö
2, ‚àí1) and P2 = (‚àí
‚àö
2, ‚àí1). The Hessian
Hf(x, y) =
	 2(y + 1)
2x
2x
0

at those points reads
Hf(P1) =
	
0
2
‚àö
2
2
‚àö
2
0

,
Hf(P2) =
	
0
‚àí2
‚àö
2
‚àí2
‚àö
2
0

,
so P1, P2 are both saddle points.
b) By part a), there are no extrema on the interior of G. But since G is compact,
Weierstrass‚Äô Theorem ensures there are extremum points, and they belong to ‚àÇG.
The boundary of G is the union of the horizontal segment between A = (‚àí
‚àö
3, 2)
and B = (
‚àö
3, 2) and of the arc joining A to B with equation y =
‚àö
1 + x2
(Fig. 7.22).
On AB we have
f(x, 2) = 3x2 ‚àí4 ,
x ‚àà[‚àí
‚àö
3,
‚àö
3]
whence f has local minimum at x = 0 and local maximum at x = ¬±
‚àö
3, with
f(0, 2) = ‚àí4 and f(¬±
‚àö
3, 2) = 5 respectively.

7.4 Exercises
295
x
y
(‚àí
‚àö
3, 2)
(
‚àö
3, 2)
1
2
‚àö
1 + x2
G
Figure 7.22. The admissible set G of Exercise 13
On the arc connecting A and B along y =
‚àö
1 + x2, we have
œï(x) = f(x,

1 + x2) = x2(

1 + x2 + 1) ‚àí2

1 + x2 ,
x ‚àà[‚àí
‚àö
3,
‚àö
3] .
As
œï‚Ä≤(x) = x 3x2 + 2
‚àö
1 + x2
‚àö
1 + x2
vanishes at x = 0 only, and is positive for x > 0, the point x = 0 is a local minimum
with f(0, 1) = ‚àí2, while x = ¬±
‚àö
3 are local maxima.
Therefore, P1 = (0, 2) is the absolute minimum, P2 = (
‚àö
3, 0) and P3 =
(‚àí
‚àö
3, 0) are absolute maxima on G.
14. DeÔ¨Åne g(x, y) = x4 ‚àíx2 + y2 ‚àí5 and use Lagrange multipliers. As
‚àáf(x, y) = (4x, 2y) ,
‚àág(x, y) = (4x3 ‚àí2x, 2y) ,
we consider the system
‚éß
‚é®
‚é©
4x = Œª2x(2x2 ‚àí1)
2y = Œª2y
x4 ‚àíx2 + y2 ‚àí5 = 0 .
The second equation gives Œª = 1 or y = 0. In the former case we have x = 0 or
x = ¬±

3/2, and correspondingly y = ¬±
‚àö
5 or y = ¬±
‚àö
17/2; in the latter case
x2 = 1¬±
‚àö
21
2
, so x = ¬±
#
1+
‚àö
21
2
(note 1 ‚àí
‚àö
21 < 0 gives a non-valid x2). Therefore,
P1,2 = (0, ¬±
‚àö
5) ,
P3,4,5,6 =

¬±

3
2, ¬±
‚àö
17
2

,
P7,8 =

¬±
 
1 +
‚àö
21
2
, 0

are extrema, constrained to G. From
f(P1,2) = 5 ,
f(P3,4,5,6) = 29
4 ,
f(P7,8) = 1 +
‚àö
21
the maximum value of f is 29/4, the minimum 5.

296
7 Applying diÔ¨Äerential calculus
15. Let us use Lagrange‚Äôs multipliers putting g(x, y) = 4x2 + y2 ‚àí1 and observing
‚àáf(x, y) = (4x + 2, 2y ‚àí4) ,
‚àág(x, y) = (8x, 2y) .
We have to solve
‚éß
‚é®
‚é©
8x + 2 = 8Œªx
2y ‚àí4 = 2Œªy
4x2 + y2 ‚àí1 = 0
‚áê‚áí
‚éß
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é©
x =
1
4(Œª ‚àí1)
y = ‚àí
2
Œª ‚àí1
1
4
1
(Œª ‚àí1)2 +
4
(Œª ‚àí1)2 = 1 .
Note Œª Ã∏= 1, for otherwise the Ô¨Årst two equations would be inconsistent. The third
equation on the right gives Œª ‚àí1 = ¬±
‚àö
17
2 , hence x = ¬±
1
2
‚àö
17 and y = ‚àì
4
‚àö
17. The
extrema are therefore
P1 =

1
2
‚àö
17, ‚àí4
‚àö
17

and
P2 =

‚àí
1
2
‚àö
17,
4
‚àö
17

.
From f(P1) = 2 +
‚àö
17, f(P2) = 2 ‚àí
‚àö
17, we see the maximum is 2 +
‚àö
17, the
minimum 2 ‚àí
‚àö
17.

8
Integral calculus in several variables
The deÔ¨Ånite integral of a function of one real variable allowed us, in Vol. I, to
deÔ¨Åne and calculate the area of a suÔ¨Éciently regular region in the plane. The
present chapter extends this notion to multivariable maps by discussing multiple
integrals; in particular, we introduce double integrals for dimension 2 and triple
integrals for dimension 3. These new tools rely on the notions of a measurable
subset of Rn and the corresponding n-dimensional measure; the latter extends the
idea of the area of a plane region (n = 2), and the volume of a solid (n = 3) to
more general situations.
We continue by introducing methods for computing multiple integrals. Among
them, dimensional-reduction techniques transform multiple integrals into one-
dimensional integrals, which can be tackled using the rules the reader is already
familiar with. On the other hand a variable change in the integration domain can
produce an expression, as for integrals by substitution, that is computable with
more ease than the multiple integral.
In the sequel we shall explain the part played by multiple integrals in the correct
formulation of physical quantities, like mass, centre of gravity, and moments of
inertia of a body with given density.
The material cannot hope to exhaust multivariable integral calculus. Integrat-
ing a map that depends on n variables over a lower-dimensional manifold gives rise
to other kinds of integrals, with great applicative importance, such as curvilinear
integrals, or Ô¨Çux integrals through a surface. These in particular will be carefully
dealt with in the subsequent chapter, where we will also show how to recover a
map from its gradient, i.e., Ô¨Ånd a primitive of sorts, essentially.
The technical nature of many proofs, that are often adaptations of one-
dimensional arguments, has induced us to skip them1. The wealth of examples
we present will in any case illustrate the statements thoroughly.
1 The interested reader may Ô¨Ånd the proofs in, e.g., the classical textbook by R. Courant
and F. John, Introduction to Calculus and Analysis, Vol. II, Springer, 1999.
C. Canuto, A. Tabacco: Mathematical Analysis II, 2nd Ed.,
UNITEXT ‚Äì La Matematica per il 3+2 85, DOI 10.1007/978-3-319-12757-6_7,
¬© Springer International Publishing Switzerland 2015

298
8 Integral calculus in several variables
x
y
z
a
b
c
d
Figure 8.1. The cylindroid of a map
8.1 Double integral over rectangles
Consider a real function f : B ‚ÜíR, deÔ¨Åned on a closed rectangle B = [a, b] √ó
[c, d] ‚äÇR2 and bounded over it. We call cylindroid of f the three-dimensional
region C(f; B) between B and the graph of f
C(f; B) = {(x, y, z) ‚ààR3 : (x, y) ‚ààB, 0 ‚â§z ‚â§f(x, y) or f(x, y) ‚â§z ‚â§0} ,
see Fig. 8.1. (The choice of bounds for z depends on the sign of f(x, y).) If f
satisÔ¨Åes certain requirements, we may associate to the cylindroid of f a number
called the double integral of f over B. In case f is positive, this number represents
the region‚Äôs volume. In particular, when the cylindroid is a simple solid (e.g., a
parallelepiped, a prism, and so on) it gives the usual expression for the volume.
Many are the ways to construct the double integral of a function; we will explain
the method due to Riemann, which generalises what we saw in Vol. I, Sects. 9.4
and 9.5, for dimension 1.
Let us thus consider arbitrary partitions of [a, b] and [c, d] associated to the
ordered points {x0, x1, . . . , xp} and {y0, y1, . . . , yq}
a = x0 < x1 < ¬∑ ¬∑ ¬∑ < xp‚àí1 < xp = b ,
c = y0 < y1 < ¬∑ ¬∑ ¬∑ < yq‚àí1 < yq = d ,
with
I = [a, b] =
p0
h=1
Ih =
p0
h=1
[xh‚àí1, xh] ,
J = [c, d] =
q0
k=1
Jk =
q0
k=1
[yk‚àí1, yk] .

8.1 Double integral over rectangles
299
x
y
a = x0 x1
x2
x3
b = x4
c = y0
y1
y2
d = y3
B32 =I3√óJ2
Figure 8.2. Subdivision of the rectangle B
The rectangle B is made of p ¬∑ q products Bhk = Ih √ó Jk; we have thus built a
partition or subdivision of B, say D = {Bhk : h = 1, . . . p, k = 1, . . . , q}, which is
the product of the partitions of [a, b] and [c, d] (Fig. 8.2). Set
mhk =
inf
(x,y)‚ààBhk f(x, y)
and
Mhk =
sup
(x,y)‚ààBhk
f(x, y)
and deÔ¨Åne the lower and upper sum of f on B relative to the subdivision D by
s = s(D, f) =
q

k=1
p

h=1
mhk(xh ‚àíxh‚àí1)(yk ‚àíyk‚àí1) ,
S = S(D, f) =
q

k=1
p

h=1
Mhk(xh ‚àíxh‚àí1)(yk ‚àíyk‚àí1) .
(8.1)
Since f is bounded on B, there exist constants m and M such that, for each
subdivision D,
m(b ‚àía)(d ‚àíc) ‚â§s(D, f) ‚â§S(D, f) ‚â§M(b ‚àía)(d ‚àíc) .
The following quantities are thus well deÔ¨Åned

B
f = inf
D S(D, f)
and

B
f = sup
D
s(D, f) ,
(8.2)

300
8 Integral calculus in several variables
x
y
z
x
y
z
Figure 8.3. Lower (left) and upper sum (right)
respectively called upper integral and lower integral of f over B. As in the
one-dimensional case, it is not hard to check that

B
f ‚â§

B
f .
DeÔ¨Ånition 8.1 A map f bounded on B = [a, b] √ó [c, d] = I √ó J is Riemann
integrable on B if

B
f =

B
f .
This value is called the double integral of f over B, and denoted by one
of the symbols

B
f ,

B
f ,

B
f(x, y) dx dy ,

J

I
f(x, y) dx dy ,
 d
c
 b
a
f(x, y) dx dy .
The geometrical meaning is clear when f is positive on B. Given a partition D
of B, the cylindroid of f is contained inside the solid formed by the union of the
parallelepipeds with base Bhk and height Mhk, and it contains the solid made by
the parallelepipeds with the same base and mhk as height (see Fig. 8.3).
The upper integral is an over-estimate of the region, while the lower integral an
under-estimate. Thus f is integrable when these two concide, i.e., when the region
deÔ¨Ånes a number representing its volume.

8.1 Double integral over rectangles
301
Examples 8.2
i) Suppose f is constant on B, say equal K. Then for any partition D, we have
mhk = Mhk = K, so
s(D, f) = S(D, f) =
q

k=1
p

h=1
K (xh ‚àíxh‚àí1)(yk ‚àíyk‚àí1) = K (b ‚àía)(d ‚àíc) .
Therefore

B
f = K (b ‚àía)(d ‚àíc) = K ¬∑ area(B) .
ii) Let f be the two-dimensional Dirichlet function on B = [0, 1] √ó [0, 1]
f(x, y) =
 1
if x, y ‚ààQ, 0 ‚â§x, y ‚â§1,
0
otherwise .
For any given partiton D then,
s(D, f) =
q

k=1
p

h=1
0 ¬∑ (xh ‚àíxh‚àí1)(yk ‚àíyk‚àí1) = 0 ,
S(D, f) =
q

k=1
p

h=1
1 ¬∑ (xh ‚àíxh‚àí1)(yk ‚àíyk‚àí1) = 1 .
This shows f is not integrable on B.
2
Remark 8.3 Let us examine, in detail, similarities and diÔ¨Äerences with the deÔ¨Ån-
ition, as of Vol. I, of a Riemann integrable map on an interval [a, b]. We may sub-
divide the rectangle B = [a, b] √ó [c, d] without having to use Cartesian products
of partitions of [a, b] and [c, d]. For instance, we could subdivide B = ‚à™N
i=1Bi by
taking coordinate rectangles Bi as in Fig. 8.4. Clearly, the kind of partitions we
consider are a special case of these.
Furthermore, if we are given a generic two-dimensional step function œï associ-
ated to such a rectangular partition, it is possible to deÔ¨Åne its double integral in
an elementary way, namely: let
œï(x, y) = ci ,
‚àÄ(x, y) ‚ààBi ,
i = 1, . . . , N ;
then

B
œï =
N

i=1
ciarea(Bi) .
Notice the lower and upper sums of a bounded map f : B ‚ÜíR, deÔ¨Åned in (8.1),
are precisely the integrals of two step functions, one smaller and one larger than f.
Their constant values on each sub-rectangle coincide respectively with the greatest
lower bound and least upper bound of f on the sub-rectangle. We could have
considered the set S‚àí
f (resp. S+
f ) of step functions that are smaller (larger) than
f. The lower and upper integrals thus obtained,

B
f = sup{

B
g : g ‚ààS‚àí
f }
and

B
f = inf{

B
g : g ‚ààS+
f },

302
8 Integral calculus in several variables
x
y
a
b
c
d
Figure 8.4. Generic partition of the rectangle B
coincide with those introduced in (8.2). In other terms, the two recipes for the
deÔ¨Ånite integral give the same result.
2
As for one-variable maps, it is imperative to Ô¨Ånd classes of integrable functions
and be able to compute their integrals directly, without turning to the deÔ¨Ånition.
A partial answer to the Ô¨Årst problem is provided by the following theorem. Further
classes of integrable functions will be considered in subsequent sections.
Theorem 8.4 If f is continuous on the rectangle B, then it is integrable
on B.
Our next result allows us to reduce a double integral, under suitable assump-
tions, to the computation of two integrals over real intervals.
Theorem 8.5 Let f be integrable over B = [a, b] √ó [c, d].
a) If, for any y ‚àà[c, d], the integral g(y) =
3 b
a f(x, y) dx exists, the map
g : [c, d] ‚ÜíR is integrable on [c, d] and

B
f =
 d
c
g(y) dy =
 d
c
 b
a
f(x, y) dx

dy .
(8.3)

8.1 Double integral over rectangles
303
b) If, for any x ‚àà[a, b], the integral h(x) =
3 d
c f(x, y) dy exists, the map
h : [a, b] ‚ÜíR is integrable on [a, b] and

B
f =
 b
a
h(x) dx =
 b
a
 d
c
f(x, y) dy

dx .
(8.4)
In particular, if f is continuous on B,

B
f =
 b
a
 d
c
f(x, y) dy

dx =
 d
c
 b
a
f(x, y) dx

dy .
(8.5)
Formulas (8.3) and (8.4) are said, generically, reduction formulas for iterated in-
tegrals. When they hold simultaneously, as happens for continuous maps, we say
that the order of integration can be swapped in the double integral.
Examples 8.6
i) A special case occurs when f has the form f(x, y) = h(x)g(y), with h integrable
on [a, b] and g integrable on [c, d]. Then it can be proved that f is integrable on
B = [a, b] √ó [c, d], and formulas (8.3), (8.4) read

B
f =
 b
a
h(x) dx

¬∑
 d
c
g(y) dy

.
This means the double integral coincides with the product of the two one-
dimensional integrals of h and g.
ii) Let us determine the double integral of f(x, y) = cos(x + y) over B = [0, œÄ
4 ] √ó
[0, œÄ
2 ]. The map is continuous, so we may indiÔ¨Äerently use (8.3) or (8.4). For
example,

B
f =
 œÄ/4
0
 œÄ/2
0
cos(x + y) dy

dx =
 œÄ/4
0

sin(x + y)
y=œÄ/2
y=0
dx
=
 œÄ/4
0

sin(x + œÄ
2 ) ‚àísin x

dx =
‚àö
2 ‚àí1 .
iii) Let us compute the double integral of f(x, y) = x cos xy over B = [1, 2]√ó[0, œÄ].
Although (8.3) and (8.4) are both valid, the latter is more convenient here. In
fact,

B
x cos xy dx dy =
 2
1
	 œÄ
0
x cos xy dy

dx
=
 2
1

sin xy
y=œÄ
y=0 dx =
 2
1
sin œÄx dx = ‚àí2
œÄ .
Formula (8.3) involves more elaborate computations which the reader might want
to perform.
2

304
8 Integral calculus in several variables
x
y
z
a
b
c
d
x0
Figure 8.5. The geometrical meaning of integrating on cross-sections
Remark 8.7 To interpret an iterated integral geometrically, let us assume for sim-
plicity f is positive and continuous on B, and consider (8.4). Given an x0 ‚àà[a, b],
h(x0) =
3 d
c f(x0, y) dy represents the area of the region obtained as intersection
between the cylindroid of f and the plane x = x0. The region‚Äôs volume is the
integral from a to b of such area (Fig. 8.5).
2
8.2 Double integrals over measurable sets
For one-dimensional integrals the region over which to integrate is always an in-
terval, or a Ô¨Ånite union of intervals. Since double-integrating only over rectangles
(or Ô¨Ånite unions thereof) is too restrictive, we need to introduce the kind of sets
over which we will discuss integrability. To this end, let Œ© be an arbitrary bounded
subset of R2, and denote by œáŒ© : R2 ‚ÜíR its characteristic function
œáŒ©(x) =
 1
if x ‚ààŒ© ,
0
if x /‚ààŒ©
(see Fig. 8.6).
We Ô¨Åx an arbitrary rectangle B containing Œ©, and ask ourselves whether œáŒ©
is integrable on B. It is easy to check that if yes, and if B‚Ä≤ is any other rectangle
containing Œ©, the function œáŒ© is still integrable on B‚Ä≤. Moreover the two integrals
3
B œáŒ© and
3
B‚Ä≤ œáŒ© coincide, so the common value can be denoted by
3
Œ© œáŒ©. That
said, let us introduce the notion of a measurable set `a la Peano-Jordan.
DeÔ¨Ånition 8.8 A bounded subset Œ© ‚äÇR2 is measurable if, for an arbitrary
rectangle B containing Œ©, the function œáŒ© is integrable on B. If so, the non-
negative number
|Œ©| =

Œ©
œáŒ©
is the measure (or area) of Œ©.

8.2 Double integrals over measurable sets
305
 
 
 
 
 
 
 
 
x
y
z
Œ©
B
Figure 8.6. The characteristic function of a set Œ©
Examples of measurable sets include polygons and discs, and the above notion
is precisely what we already know as their surface area. At times we shall write
area(Œ©) instead of |Œ©|. In particular, for any rectangle B = [a, b] √ó [c, d] we see
immediately that
|B| = area(B) =

B
dx dy =
 d
c
 b
a
dx dy = (b ‚àía)(d ‚àíc).
Not all bounded sets in the plane are measurable. Think of the points in the square
[0, 1]√ó[0, 1] with rational coordinates. The characteristic function of this set is the
Dirichlet function relative to Example 8.2 ii), which is not integrable. Therefore
the set is not measurable.
Another deÔ¨Ånition will turn out useful in the sequel.
DeÔ¨Ånition 8.9 A set Œ© has zero measure if it is measurable and |Œ©| = 0.
With this we can characterise measurable sets in the plane. In fact, the next
result is often used the tell whether a given set is measurable or not.
Theorem 8.10 A bounded set Œ© ‚äÇR2 is measurable if and only if its bound-
ary ‚àÇŒ© has measure zero.
Among zero-measure sets are:
i)
subsets of sets with zero measure;
ii) Ô¨Ånite unions of sets with zero measure;
iii) sets consisting of Ô¨Ånitely many points;

306
8 Integral calculus in several variables
iv) segments;
v) graphs Œì = {

x, f(x)

} or Œì = {

f(y), y

} of integrable maps f : [a, b] ‚ÜíR;
vi) traces of (piecewise-)regular plane curves.
As for the last, we should not confuse the measure of the trace of a plane curve
with its length, which is in essence a one-dimensional measure for sets that are
not contained in a line.
A case of zero-measure set of particular relevance is the graph of a continuous
map deÔ¨Åned on a closed and bounded interval. Therefore, measurable sets include
bounded sets whose boundary is a Ô¨Ånite union of such graphs, or more gener-
ally, a Ô¨Ånite union of regular Jordan arcs. At last, bounded and convex sets are
measurable.
Measurable sets and their measures enjoy some properties.
Property 8.11 If Œ©1 and Œ©2 are measurable,
i) Œ©1 ‚äÜŒ©2 implies |Œ©1| ‚â§|Œ©2|;
ii) Œ©1 ‚à™Œ©2 and Œ©1 ‚à©Œ©2 are measurable with
|Œ©1 ‚à™Œ©2| = |Œ©1| + |Œ©2| ‚àí|Œ©1 ‚à©Œ©2| ,
hence
|Œ©1 ‚à™Œ©2| ‚â§|Œ©1| + |Œ©2| .
Here is a simple, yet useful result for the sequel.
Property 8.12 If Œ© is a measurable set, so are the interior
‚ó¶
Œ©, the closure Œ©,
and in general all sets ÀúŒ© such that
‚ó¶
Œ© ‚äÜÀúŒ© ‚äÜŒ©. Any of these has measure |Œ©|.
Proof.
All sets ÀúŒ© have the same boundary ‚àÇÀúŒ© = ‚àÇŒ©. Therefore Theorem 8.10
tells they are measurable. But they diÔ¨Äer from one another by subsets of
‚àÇŒ©, whose measure is zero.
2
Now we introduce the notion of integrability for bounded maps on a given
measurable set Œ©. The method is completely similar to the way we selected meas-
urable sets. Let f : Œ© ‚ÜíR be a bounded map, and consider Àúf : R2 ‚ÜíR (called
the trivial extension of f to R2), deÔ¨Åned by
Àúf(x) =
 f(x)
if x ‚ààŒ©,
0
if x /‚ààŒ©
(8.6)
(see Fig. 8.7).

8.2 Double integrals over measurable sets
307
x
y
z
B
Œ©
Figure 8.7. Trivial extension of a map to a rectangle B
DeÔ¨Ånition 8.13 The map f is (Riemann) integrable on Œ© if Àúf is integrable
on any rectangle B containing Œ©. In that case, the integral

B
Àúf is independent
of the choice of B, and we set

Œ©
f =

B
Àúf .
This value is called the double integral of f over Œ©. Other symbols to
denote it are

Œ©
f ,

Œ©
f(x, y) dx dy ,

Œ©
f dŒ© .
Observe that if f coincides with the characteristic function of Œ©, what we have
just deÔ¨Åned is exactly the measure of Œ©.
The Ô¨Årst large class of integrable maps we wish to describe is a sort of gener-
alisation of piecewise-continuous functions in one variable.
DeÔ¨Ånition 8.14 A map f : Œ© ‚ÜíR, bounded on a measurable set Œ©, is said
generically continuous on Œ© if the discontinuity set has zero measure.
A bounded, continuous map on Œ© is clearly generically continuous, as no dis-
continuity points are present. An example of a generically continuous, but not
continuous, function is given by the map f(x, y) = sign(x ‚àíy) on the square
Œ© = (0, 1)2.
Then we have the following result.

308
8 Integral calculus in several variables
Theorem 8.15 Let f be generically continuous on a measurable set Œ©. Then
f is integrable on Œ©.
There is a way to compute the double integral on special regions in the plane,
which requires a deÔ¨Ånition.
DeÔ¨Ånition 8.16 A set Œ© ‚äÇR2 is normal with respect to the y-axis if
it is of the form
Œ© = {(x, y) ‚ààR2 : a ‚â§x ‚â§b, g1(x) ‚â§y ‚â§g2(x)}
with g1, g2 : [a, b] ‚ÜíR continuous.
Analogously, Œ© is normal with respect to the x-axis if
Œ© = {(x, y) ‚ààR2 : c ‚â§y ‚â§d, h1(y) ‚â§y ‚â§h2(y)}
with h1, h2 : [c, d] ‚ÜíR continuous. We will shorten this by the terms normal
for y and normal for x respectively.
This notion can be understood geometrically. The set Œ© is normal with respect to
the y-axis if any vertical line x = x0 either does not meet Œ©, or it intersects it in the
segment (possibly reduced to a point) with end points

x0, g1(x0)

,

x0, g2(x0)

.
Similarly, Œ© is normal for x if a horizontal line y = y0 has intersection either empty
or the segment between

h1(y0), y0

,

h2(y0), y0

with Œ©. Examples are shown in
Fig. 8.8 and Fig. 8.9.
Normal sets for either variable are clearly measurable, because their boundary
is a Ô¨Ånite union of zero-measure sets (graphs of continuous maps and segments).
The next proposition allows us to compute a double integral by iteration, thus
generalising Theorem 8.5 for rectangles.
x
y
a
b
x0
x
y
a
b
x0
x
y
a
b
x0
Figure 8.8. Normal sets for y

8.2 Double integrals over measurable sets
309
x
y
c
d
y0
x
y
c
d
y0
x
y
c
d
y0
Figure 8.9. Normal sets for x
Theorem 8.17 Let f : Œ© ‚ÜíR be continuous on Œ©. If Œ© is normal for y,
then

Œ©
f =
 b
a
 g2(x)
g1(x)
f(x, y) dy

dx .
(8.7)
If Œ© is normal for x,

Œ©
f =
 d
c
 h2(y)
h1(y)
f(x, y) dx

dy .
(8.8)
Proof.
Suppose Œ© is normal for x. From the deÔ¨Ånition, Œ© is a closed and bounded,
hence compact, subset of R2. By Weierstrass‚Äô Theorem 5.24, f is bounded
on Œ©. Then Theorem 8.15 implies f is integrable on Œ©. As for formula (8.8),
let B = [a, b] √ó [c, d] be a rectangle containing Œ©, and consider the trivial
extension Àúf of f to B. The idea is to use Theorem 8.5 a); for this, we
observe that for any y ‚àà[c, d], the integral
g(y) =
 b
a
Àúf(x, y) dx
exists because x ‚ÜíÀúf(x, y) has not more than two discontinuity points
(see Fig. 8.10). Moreover
 b
a
Àúf(x, y) dx =
 h2(y)
h1(y)
f(x, y) dx ,
so

Œ©
f =

B
Àúf =
 d
c
 b
a
Àúf(x, y) dx

dy =
 d
c
 h2(y)
h1(y)
f(x, y) dx

dy ,
proving (8.8). Formula (8.7) is similar.
2

310
8 Integral calculus in several variables
 
 
 
 
 
 
 
 
x
y
z
B
y0
Œ©
Figure 8.10. Reduction formula for an iterated integral
Also (8.7) and (8.8) are iterated integrals, respectively referred to as formula of
vertical and of horizontal integration.
Examples 8.18
i) Compute

Œ©
(x + 2y) dx dy ,
where Œ© is the region in the Ô¨Årst quadrant bounded by the curves y = 2x,
y = 3 ‚àíx2, x = 0 (as in Fig. 8.11, left). The Ô¨Årst line and the parabola meet at
two points with x = ‚àí3 and x = 1, the latter of which delimits Œ© on the right.
The set Œ© is normal for both x and y, but given its shape we prefer to integrate
in y Ô¨Årst. In fact,
Œ© =

(x, y) ‚ààR2 : 0 ‚â§x ‚â§1, 2x ‚â§y ‚â§3 ‚àíx2
.
Hence,

Œ©
(x + 2y) dx dy =
 1
0
 3‚àíx2
2x
(x + 2y) dy

dx =
 1
0

xy + y2y=3‚àíx2
y=2x
dx
=
 1
0

x4 ‚àíx3 ‚àí12x2 + 3x + 9

dx
=
1
5x5 ‚àí1
4x4 ‚àí4x3 + 3
2x2 + 9x
x=1
x=0
= 129
20 .
Had we chosen to integrate in x Ô¨Årst, we would have had to write the domain as
Œ© =

(x, y) ‚ààR2 : 0 ‚â§y ‚â§3, 0 ‚â§x ‚â§h2(y)

,
where h2(y) is
h2(y) =
‚éß
‚é®
‚é©
1
2y
if 0 ‚â§y ‚â§2 ,
‚àö3 ‚àíy
if 2 < y ‚â§3 .
The form of h2(y) clearly suggests why the former technique is to be preferred.

8.2 Double integrals over measurable sets
311
1
x
3
2
y = 2x
y = 3 ‚àíx2
x
y
x
y
2
4
4
x = ‚àöy
Figure 8.11. The set Œ© = {(x, y) ‚ààR2 : 0 ‚â§x ‚â§1, 2x ‚â§y ‚â§3 ‚àíx2} (left) and
Œ© = {(x, y) ‚ààR2 : 0 ‚â§y ‚â§4, ‚àöy ‚â§x ‚â§4} (right)
ii) Consider

Œ©
(5y + 2x) dx dy
where Œ© is the plane region bounded by y = 0, y = 4, x = 4 and by the graph of
x = ‚àöy (see Fig. 8.11, right). Again, Œ© is normal for both x and y, but horizontal
integration will turn out to be better. In fact, we write
Œ© =

(x, y) ‚ààR2 : 0 ‚â§y ‚â§4, ‚àöy ‚â§x ‚â§4

;
therefore

Œ©
(5y + 2x) dx dy =
 4
0
 4
‚àöy
(5y + 2x) dx

dy =
 4
0

5xy + x2x=4
x=‚àöy dy
=
 4
0

19y + 16 ‚àí5y3/2
dy
=
19
2 y2 + 16y ‚àí2y5/2
y=4
y=0
= 152.
2
For positive functions that are integrable on generic measurable sets Œ©, e.g.,
rectangles, the double integral makes geometrical sense, namely it represents the
volume vol(C) of the cylindroid of f
C = C(f; Œ©) = {(x, y, z) ‚ààR3 : (x, y) ‚ààŒ©, 0 ‚â§z ‚â§f(x, y)} .
See Fig. 8.12.

312
8 Integral calculus in several variables
x
y
z
Œ©
Figure 8.12. The cylindroid of a positive map
Example 8.19
Compute the volume of
C =

(x, y, z) ‚ààR3 : 0 ‚â§y ‚â§3
4x, x2 + y2 ‚â§25, z ‚â§xy

.
The solid is the cylindroid of f(x, y) = xy with base
Œ© =

(x, y) ‚ààR2 : 0 ‚â§y ‚â§3
4x, x2 + y2 ‚â§25

.
The map is integrable (as continuous) on Œ©, which is normal for both x and y
(Fig. 8.13). Therefore vol(C) =
3
Œ© xy dx dy.
x
y
x =

25 ‚àíy2
5
x = 4
3y
3
Figure 8.13. The set Œ© =

(x, y) ‚ààR2 : 0 ‚â§y ‚â§3,
4
3y ‚â§x ‚â§

25 ‚àíy2


8.2 Double integrals over measurable sets
313
The region Œ© lies in the Ô¨Årst quadrant, is bounded by the line y = 3
4x and the
circle x2 + y2 = 25 centred at the origin with radius 5. For simplicity let us
integrate horizontally, since
Œ© =

(x, y) ‚ààR2 : 0 ‚â§y ‚â§3, 4
3y ‚â§x ‚â§

25 ‚àíy2

.
Thus

Œ©
xy dx dy =
 3
0
 ‚àö
25‚àíy2
4
3 y
xy dx

dy
=
 3
0
1
2yx2
x=‚àö
25‚àíy2
x= 4
3 y
dy
= 1
2
 3
0

y(25 ‚àíy2) ‚àí16
9 y3
dy = 225
8 .
2
8.2.1 Properties of double integrals
In this section we state a bunch of useful properties of double integrals.
Theorem 8.20 Let f, g be integrable maps on a measurable set Œ© ‚äÇR2.
i) (Linearity) For any Œ±,Œ≤ ‚ààR, the map Œ±f + Œ≤g is integrable on Œ© and

Œ©
Œ±f + Œ≤g = Œ±

Œ©
f + Œ≤

Œ©
g .
ii) (Positivity) If f ‚â•0 on Œ©, then

Œ©
f ‚â•0 .
In addition, if f is continuous and Œ© measurable with |Œ©| > 0, we have
equality above if and only if f is identically zero.
iii) (Comparison/Monotonicity) If f ‚â§g on Œ©, then

Œ©
f ‚â§

Œ©
g .
iv) (Boundedness) The map |f| is integrable on Œ© and


Œ©
f
 ‚â§

Œ©
|f| .

314
8 Integral calculus in several variables
v) (Mean Value Theorem) If Œ© is measurable and
m =
inf
(x,y)‚ààŒ© f(x, y) ,
M =
sup
(x,y)‚ààŒ©
f(x, y) ,
then
m ‚â§
1
|Œ©|

Œ©
f ‚â§M .
The number
1
|Œ©|

Œ©
f
(8.9)
is called (integral) mean value of f on Œ©.
vi) (Additivity of domains) Let Œ© = Œ©1‚à™Œ©2, with Œ©1‚à©Œ©2 of zero measure.
If f is integrable on Œ©1 and on Œ©2, then f is integrable on Œ©, and

Œ©
f =

Œ©1
f +

Œ©2
f .
vii) If f = g except that on a zero-measure subset of Œ©, then

Œ©
f =

Œ©
g .
Property vi) is extremely useful when integrals are deÔ¨Åned over unions of Ô¨Ånitely
many normal sets for one variable.
There is a counterpart to Property 8.12 for integrable functions.
Property 8.21 Let f be integrable on a measurable set Œ©, and suppose it is
deÔ¨Åned on the closure Œ© of Œ©. Then f is integrable over any subset ÀúŒ© such
that
‚ó¶
Œ© ‚äÜÀúŒ© ‚äÜŒ©, and

Àú
Œ©
f =

Œ©
f .
Otherwise said, the double integral of an integrable map does not depend on
whether bits of the boundary belong to the integration domain.
Examples 8.22
i) Consider

Œ©
(1 + x) dx dy ,
where Œ© = {(x, y) ‚ààR2 : y > |x|, y < 1
2x + 2}.

8.2 Double integrals over measurable sets
315
‚àí4
3
4
Œ©2
Œ©1
y = 1
2x + 2
y = |x|
x
y
Figure 8.14. The set Œ© relative to Example 8.22 i)
The domain Œ©, depicted in Fig. 8.14, is made of the points lying between the
graphs of y = |x| and y = 1
2x+2. The set Œ© is normal for both x and y; it is more
convenient to start integrating in y. Due to the presence of y = |x|, moreover, it
is better to compute the integral on Œ© as sum of integrals over the subsets Œ©1
and Œ©2 of the picture. The graphs of y = |x| and y = 1
2x + 2 meet for x = 4 and
x = ‚àí4
3. Then Œ©1 and Œ©2 are, respectively,
Œ©1 = {(x, y) ‚ààR2 : 0 ‚â§x < 4, x < y < 1
2x + 2}
and
Œ©2 = {(x, y) ‚ààR2 : ‚àí4
3 < x < 0, ‚àíx < y < 1
2x + 2}.
Therefore

Œ©1
(1 + x) dx dy =
 4
0

1
2 x+2
x
(1 + x) dy

dx =
 4
0
[y + xy]
1
2 x+2
x
dx
=
 4
0
	
‚àí1
2x2 + 3
2x + 2

dx =

‚àí1
6x3 + 3
4x2 + 2x
4
0
= 28
3
and

Œ©2
(1 + x) dx dy =
 0
‚àí4
3

1
2 x+2
‚àíx
(1 + x) dy

dx =
 0
‚àí4
3
[y + xy]
1
2 x+2
‚àíx
dx
=
 0
‚àí4
3
	3
2x2 + 7
2x + 2

dx =
1
2x3 + 7
4x2 + 2x
0
‚àí4
3
= 20
27.
In conclusion,

Œ©
(1 + x) dx dy =

Œ©1
(1 + x) dx dy +

Œ©2
(1 + x) dx dy = 28
3 + 20
27 = 272
27 .

316
8 Integral calculus in several variables
5
x2 + y2 = 25
Œ©2
P
x2 + y2 ‚àí25
4 x = 0
3
2
‚àö
5
y = 1
2x
Œ©1
Q
4
x
y
Figure 8.15. The set Œ© relative to Example 8.22 ii)
ii) Consider

Œ©
y
x + 1 dx dy ,
with Œ© bounded by the circles x2 + y2 = 25, x2 + y2 ‚àí25
4 x = 0 and the line
y = 1
2x (Fig. 8.15). The Ô¨Årst curve has centre in the origin and radius 5, the
second in ( 25
8 , 0) and radius 25
8 . They meet at P = (4, 3) in the Ô¨Årst quadrant;
moreover, the line y = 1
2x intersects x2 + y2 = 25 in Q = (2
‚àö
5,
‚àö
5). The region
is normal with respect to both axes; we therefore integrate by dividing Œ© in two
parts Œ©1, Œ©2, whose horizontal projections on the x-axis are [0, 4] and [4, 2
‚àö
5]:

Œ©
y
x + 1 dx dy =

Œ©1
y
x + 1 dx dy +

Œ©2
y
x + 1 dx dy
=
 4
0
 ‚àö
25
4 x‚àíx2
x/2
y
x + 1 dy

dx +
 2
‚àö
5
4
 ‚àö
25‚àíx2
x/2
y
x + 1 dy

dx
= 1
2
 4
0
25x ‚àí5x2
x + 1
dx + 1
8
 2
‚àö
5
4
100 ‚àí5x2
x + 1
dx
= 1
8
 4
0

‚àí5x + 30 ‚àí
30
x + 1

dx + 1
8
 2
‚àö
5
4

‚àí5x + 5 +
95
x + 1

dx
= 5
8

10 + 2
‚àö
5 ‚àí25 log 5 + 19 log(1 + 2
‚àö
5)

.
2

8.3 Changing variables in double integrals
317
8.3 Changing variables in double integrals
This section deals with the analogue of the substitution method for one-dimensional
integrals. This generalisation represents an important computational tool, besides
furnishing an alternative way to understand the Jacobian determinant of plane
transformations.
Consider a measurable region Œ© ‚äÇR2 and a continuous map f that is bounded
on it. As f is integrable on Œ©, we may ask how
3
Œ© f varies if we change variables
in the plane.
Precisely, retaining the notation of Sect. 6.6, let Œ©‚Ä≤ be a measurable region
and Œ¶ : Œ©‚Ä≤ ‚ÜíŒ©, (x, y) = Œ¶(u, v) a variable change, like in DeÔ¨Ånition 6.30. We
want to write the integral of f(x, y) over Œ© as integral over Œ©‚Ä≤ by means of the
composite map Àúf = f ‚ó¶Œ¶, i.e., Àúf(u, v) = f

Œ¶(u, v)

, deÔ¨Åned on Œ©‚Ä≤. To do that
though, we ought to recall the integral is deÔ¨Åned using the areas of elementary sets,
such as rectangles, into which the domain is divided. It becomes thus relevant to
understand how areas change when passing from Œ©‚Ä≤ to Œ© via Œ¶.
So let us start with a rectangle B‚Ä≤ in Œ©‚Ä≤, whose sides are parallel to the axes
u and v and whose vertices are u0, u1 = u0 + Œîu e1, u2 = u0 + Œîv e2 and
u3 = u0 +Œîu e1 +Œîv e2 (Fig. 8.16, left); here Œîu,Œîv denote positive, and small,
increments. The area of B‚Ä≤ is |B‚Ä≤| = ŒîuŒîv, clearly.
Denote by B the image of B‚Ä≤ under Œ¶ (Fig. 8.16, right); it has sides along the
coordinate lines of Œ¶ and vertices given by xi = Œ¶(ui), i = 0, . . . , 3. In order to
express the area of B in terms of B‚Ä≤ we need to make some approximations, justiÔ¨Åed
by the choice of suÔ¨Éciently small Œîu and Œîv. First of all, let us approximate B
with the parallelogram Bp with three vertices at x0, x1, x2. It is known that its
area is the absolute value of the cross product of any two adjacent sides:
|B| ‚àº|Bp| = ‚à•(x1 ‚àíx0) ‚àß(x2 ‚àíx0)‚à•.
On the other hand, the Taylor expansion of Ô¨Årst order at u0 gives, also using (6.25),
 
 
 
 
u
v
u0
u1
u2
u3
B‚Ä≤
Œîu
Œîv
 
 
 
 
x
y
x0
x1
x2
x3
B
Bp
‚àºœÑ1Œîu
‚àºœÑ2Œîv
Figure 8.16. How a variable change transforms a rectangle

318
8 Integral calculus in several variables
x1 ‚àíx0 = Œ¶(u1) ‚àíŒ¶(u0) ‚àº‚àÇŒ¶
‚àÇu (u0)Œîu = œÑ1Œîu ,
and similarly
x2 ‚àíx0 ‚àºœÑ2Œîv ,
with
œÑ2 = ‚àÇŒ¶
‚àÇv (u0) .
Therefore
|B| ‚àº‚à•œÑ1 ‚àßœÑ2‚à•ŒîuŒîv = ‚à•œÑ1 ‚àßœÑ2‚à•|B‚Ä≤| .
Now (6.27) yields
‚à•œÑ1 ‚àßœÑ2‚à•= | det JŒ¶(u0)| ,
so that
|B| ‚àº| det JŒ¶(u0)| |B‚Ä≤| .
(8.10)
Up to inÔ¨Ånitesimals of order greater than Œîu and Œîv then, the quantity | det JŒ¶|
represents the ratio between the areas of two (small) surface elements B‚Ä≤ ‚äÇŒ©‚Ä≤, B ‚äÇ
Œ©, which correspond under Œ¶. This relationship is usually written symbolically as
dx dy = | det JŒ¶(u, v)| du dv ,
(8.11)
where du dv is the area of the ‚ÄòinÔ¨Ånitesimal‚Äô surface element in Œ©‚Ä≤ and dx dy the
area of the image in Œ©.
Examples 8.23
i) Call Œ¶ the aÔ¨Éne transformation Œ¶(u) = Au + b, where A is a non-singular
matrix. Then B is a parallelogram of vertices x0, x1, x2, x3, and concides with
Bp, so all approximations are actually exact. In particular, the position vectors
along the sides at x0 read
x1 ‚àíx0 = a1Œîu ,
x2 ‚àíx0 = a2Œîv ,
where a1 and a2 are the column vectors of A. Hence
|B| = ‚à•a1 ‚àßa2‚à•ŒîuŒîv = | det A|ŒîuŒîv = | det JŒ¶| |B‚Ä≤| ,
and (8.10) is an equality.
ii) Consider the transformation Œ¶ : (r,Œ∏ ) ‚Üí(r cos Œ∏, r sin Œ∏) relative to polar
coordinates in the plane. The image under Œ¶ of a rectangle B‚Ä≤ = [r0, r0 + Œîr] √ó
[Œ∏0, Œ∏0+ŒîŒ∏] in the rŒ∏-plane is the region of Fig. 8.17. It has height Œîr in the radial
direction and base ‚àºrŒîŒ∏ along the angle direction; but since polar coordinates
are orthogonal,
|B| ‚àºrŒîrŒîŒ∏ = r|B‚Ä≤| .
This is the form that (8.10) takes in the case at hand, because indeed r =
det JŒ¶(r,Œ∏ ) > 0 (recall (6.29)).
2
After this detour we are ready to integrate. If D‚Ä≤ = {B‚Ä≤
i}i‚ààI is a partition of
Œ©‚Ä≤ into rectangular elements, D = {Bi = Œ¶(B‚Ä≤
i)}i‚ààI will be a partition of Œ© in
rectangular-like regions; denote by | det JŒ¶i| the value appearing in (8.10) for the

8.3 Changing variables in double integrals
319
r
Œ∏
r0
r0 + Œîr
Œ∏0 + ŒîŒ∏
Œ∏0
B‚Ä≤
x
y
Œîr
ŒîŒ∏
‚àºrŒîŒ∏
B
Figure 8.17. Area element in polar coordinates
element Bi. If fi is an approximation of f on Bi (consequently, an approximation
of the transform Àúf = f ‚ó¶Œ¶ on B‚Ä≤
i as well), then by using (8.10) on each element
we obtain

i‚ààI
fi|Bi| ‚àº

i‚ààI
fi| det JŒ¶i| |B‚Ä≤
i| .
Now reÔ¨Åning the partition of Œ©‚Ä≤ further and further, by taking rectangles of
sides Œîu, Œîv going to 0, one can prove that the sums on the right converge
to
3
Œ©‚Ä≤ f

Œ¶(u, v)

| det JŒ¶(u, v)| du dv, while those on the left to
3
Œ© f(x, y) dx dy,
provided f is continuous and bounded on Œ©.
All the above discussion should justify, though heuristically, the following key
result (clearly, everything can be made rigorous).
Theorem 8.24 Let Œ¶ : Œ©‚Ä≤ ‚ÜíŒ© be a change of variables between measurable
regions Œ©‚Ä≤, Œ© in R2, as in DeÔ¨Ånition 6.30, with components
x = œï(u, v)
and
y = œà(u, v).
If f is a continuous and bounded map on Œ©,

Œ©
f(x, y) dx dy =

Œ©‚Ä≤ f

œï(u, v), œà(u, v)

| det JŒ¶(u, v)| du dv .
(8.12)
In the applications, it may be more convenient to use the inverse transformation
(u, v) = Œ®(x, y), such that Œ©‚Ä≤ = Œ®(Œ©) and det JŒ¶(u, v) =

det JŒ®(x, y)
‚àí1.
Let us make this formula explicit by considering two special changes of vari-
ables, namely an aÔ¨Éne map and the passage to polar coordinates.
For aÔ¨Éne transformations, set x = Œ¶(u) = Au + b where A =
	 a11
a12
a21
a22

and b =
	 b1
b2

; hence x = œï(u, v) = a11u + a12v + b1 and y = œà(u, v) = a21u +

320
8 Integral calculus in several variables
a22v + b2. If Œ© is measurable and Œ©‚Ä≤ = Œ¶‚àí1(Œ©), we have

Œ©
f(x, y) dx dy = | det A|

Œ©‚Ä≤ f(a11u + a12v + b1, a21u + a22v + b2) du dv .
As for polar coordinates, x = œï(r,Œ∏ ) = r cos Œ∏, y = œà(r,Œ∏ ) = r sin Œ∏, and
det JŒ¶(r,Œ∏ ) = r. Therefore, setting again Œ©‚Ä≤ = Œ¶‚àí1(Œ©), we obtain

Œ©
f(x, y) dx dy =

Œ©‚Ä≤ f(r cos Œ∏, r sin Œ∏) r dr dŒ∏ .
Examples 8.25
i) The map
f(x, y) = (x2 ‚àíy2) log

1 + (x + y)4
is deÔ¨Åned on Œ© = {(x, y) ‚ààR2 : x > 0, 0 < y < 2 ‚àíx}, see Fig. 8.18, right. The
map is continuous and bounded on Œ©, so
3
Œ© f(x, y) dx dy exists. The expression
of f suggests deÔ¨Åning
u = x + y
and
v = x ‚àíy ,
which entails we are considering the linear map
x = œï(u, v) = u + v
2
,
y = œà(u, v) = u ‚àív
2
deÔ¨Åned by A =
	 1/2
1/2
1/2
‚àí1/2

with | det A| = 1/2. The pre-image of Œ© under Œ¶
is the set
Œ©‚Ä≤ = {(u, v) ‚ààR2 : 0 < u < 2, ‚àíu < v < u}
of Fig. 8.18, left.
v
u
2
2
‚àí2
v = ‚àíu
Œ©‚Ä≤
v = u
x
y
2
2
Œ©
y = 2 ‚àíx
Figure 8.18. The sets Œ© = {(x, y) ‚ààR2 : x > 0, 0 < y < 2 ‚àíx} (right) and Œ©‚Ä≤ =
{(u, v) ‚ààR2 : 0 < u < 2, ‚àíu < v < u} (left)

8.3 Changing variables in double integrals
321
Then

Œ©
(x2 ‚àíy2) log

1 + (x + y)4
dx dy = 1
2

Œ©‚Ä≤ uv log(1 + u4) du dv
= 1
2
 2
0
	 u
‚àíu
v dv

u log(1 + u4) du
= 1
4
 2
0

v2v=u
v=‚àíuu log(1 + u4) du = 0 .
ii) Consider
f(x, y) =
1
1 + x2 + y2
over
Œ© = {(x, y) ‚ààR2 : 0 < y <
‚àö
3x, 1 < x2 + y2 < 4}.
Passing to polar coordinates gives
Œ©‚Ä≤ = {(r,Œ∏ ) : 1 < r < 2, 0 < Œ∏ < œÄ
3 }
(Fig. 8.19), so

Œ©
f(x, y) dx dy =

Œ©‚Ä≤
1
1 + r2 r dr dŒ∏ =
 œÄ/3
0
	 2
1
r
1 + r2 dr

dŒ∏
=
 œÄ/3
0
dŒ∏
 	 2
1
r
1 + r2 dr

= œÄ
6 log 5
2.
2
r
Œ∏
1
2
œÄ
3
Œ©‚Ä≤
x
y
1
2
1
2
y =
‚àö
3x
Œ©
Figure 8.19. The sets Œ© = {(x, y) ‚ààR2 : 0 < y <
‚àö
3x, 1 < x2 + y2 < 4} (right) and
Œ©‚Ä≤ = {(r,Œ∏ ) : 1 < r < 2, 0 < Œ∏ < œÄ
3 } (left)

322
8 Integral calculus in several variables
8.4 Multiple integrals
Since the deÔ¨Ånition of multiple integral ‚Äì or n-dimensional integral ‚Äì for a map
of n ‚â•3 real variables closely resembles the one just seen for 2 variables, we
merely point out the diÔ¨Äerences with the previous situations due to the increased
dimension in the case n = 3.
The role of plane rectangles is now taken by parallelepipeds in space. The
generic set B = [a1, b1] √ó [a2, b2] √ó [a3, b3] can be broken up into the product of
partitions of the intervals [a1, b1], [a2, b2], [a3, b3], using the points {x0, x1, . . . , xp},
{y0, y1, . . . , yq} and {z0, z1, . . . , zr} respectively. The solid B is thus the union of
parallelepipeds
Bhk‚Ñì= [xh‚àí1, xh] √ó [yk‚àí1, yk] √ó [z‚Ñì‚àí1, z‚Ñì].
Take f : B ‚ÜíR bounded; the lower and upper sums of f over B relative to the
above partition D are, by deÔ¨Ånition,
s = s(D, f) =
r

‚Ñì=1
q

k=1
p

h=1
mhk‚Ñì(xh ‚àíxh‚àí1)(yk ‚àíyk‚àí1)(z‚Ñì‚àíz‚Ñì‚àí1) ,
S = S(D, f) =
r

‚Ñì=1
q

k=1
p

h=1
Mhk‚Ñì(xh ‚àíxh‚àí1)(yk ‚àíyk‚àí1)(z‚Ñì‚àíz‚Ñì‚àí1) ,
where
mhk‚Ñì=
inf
(x,y,z)‚ààBhk‚Ñì
f(x, y, z) ,
Mhk‚Ñì=
sup
(x,y,z)‚ààBhk‚Ñì
f(x, y, z) .
A map f is said integrable on B if
inf
D S(D, f) = sup
D
s(D, f);
such value, called the (triple) integral of f on B, is denoted by one of the
symbols

B
f ,

B
f ,

B
f(x, y, z) dx dy dz .
Here, as well, continuity guarantees integrability. One also has the analogue of
Theorem 8.5.
Example 8.26
Compute
3
B xyz dx dy dz over B = [0, 1] √ó [‚àí1, 2] √ó [0, 2]. We have

B
xyz dx dy dz =
 2
0
	 2
‚àí1
	 1
0
xyz dx

dy

dz
= 1
2
 2
0
	 2
‚àí1
yz dy

dz = 3
4
 2
0
z dz = 3
2.
2

8.4 Multiple integrals
323
To be able to integrate over bounded sets Œ© ‚äÇR3, it is necessary to deÔ¨Åne
what ‚Äòmeasurable‚Äô means in space. In analogy to DeÔ¨Ånition 8.8, we substitute the
rectangle B with a parallelepiped containing Œ©, and put
|Œ©| =

Œ©
œáŒ© =

B
œáŒ© .
This is independent of the choice of B. The familiar sets of Euclidean geometry,
like spheres, cylinders, polyhedra and so on, turn out to be all measurable. This
notion of measure is indeed the volume, so we shall sometimes write |Œ©| = vol(Œ©).
DeÔ¨Ånition 8.9, Theorem 8.10 and Property 8.12 hold also in higher dimensions.
For instance, if D ‚äÇR2 is measurable and g : D ‚ÜíR integrable on D, the graph
has 3-dimensional measure equal zero. In particular, the traces of regular surfaces
have, as subsets of R3, zero measure.
Take f : Œ© ‚ÜíR bounded, with Œ© measurable. Given an arbitrary paral-
lelepiped B containing Œ©, we extend f by setting it to zero on B \ Œ©, and call the
extension Àúf. One says f is integrable on Œ© if Àúf is integrable on B, in which case

Œ©
f =

B
Àúf ;
this number, not depending on B, is the (triple) integral of f on Œ©, also denoted
by

Œ©
f ,

Œ©
f(x, y, z) dx dy dz ,

Œ©
f dŒ© .
Again, DeÔ¨Ånition 8.14 and Theorem 8.15 adapt to the present situation, and sim-
ilarly happens for Theorem 8.20.
A completely analogous construction leads to multiple integrals in dimen-
sion n > 3.
We would like to Ô¨Ånd examples of regions in space where integrals are easy
to compute explicitly. These should work as normal sets did in the plane, i.e.,
reducing triple integrals to lower-dimensional ones. We consider in detail normal
regions for the z-axis, the other cases being completely similar.
DeÔ¨Ånition 8.27 We call Œ© ‚äÇR3 a normal set for z (normal with respect
to the z-axis, to be precise) if
Œ© = {(x, y, z) ‚ààR3 : (x, y) ‚ààD, g1(x, y) ‚â§z ‚â§g2(x, y)} ,
(8.13)
for a closed measurable region D in R2 and continuous maps g1, g2 : D ‚ÜíR.
Fig. 8.20 shows a few normal regions.
The boundary of a normal set has thus zero measure, hence a normal set is
measurable. Triple integrals over normal domains can be reduced to iterated double

324
8 Integral calculus in several variables
x
y
z
D
g1(x, y)
g2(x, y)
x
y
z
D
g1(y, z)
g2(y, z)
x
y
z
D
g1(x, z)
g2(x, z)
Figure 8.20. Normal sets
and/or simple integrals. For clarity, we consider normal domains for the vertical
axis, and let Œ© be deÔ¨Åned as in (8.13); then we have an iterated integral

Œ©
f =

D
 g2(x,y)
g1(x,y)
f(x, y, z) dz

dx dy ,
(8.14)
see Fig. 8.21, where f is integrated Ô¨Årst along vertical segments in the domain.
Dimensional reduction is possible for other kinds of measurable sets. Suppose
the measurable set Œ© ‚äÇR3 is such that the z-coordinate of its points varies within
an interval [Œ±,Œ≤ ] ‚äÇR. For any z0 in this interval, the plane z = z0 cuts Œ© along
the cross-section Œ©z0 (Fig. 8.22); so let us denote by
Az0 = {(x, y) ‚ààR2 : (x, y, z0) ‚ààŒ©}
x
y
z
(x, y) D
g1(x, y)
g2(x, y)
Figure 8.21. Integration along segments

8.4 Multiple integrals
325
 
 
 
 
 
 
 
 
 
x
y
z
Œ±
Œ≤
Œ©z
Az
Figure 8.22. Integration over cross-sections
the xy-projection of the slice Œ©z0. Thus Œ© reads
Œ© = {(x, y, z) ‚ààR3 : z ‚àà[Œ±,Œ≤ ], (x, y) ‚ààAz} .
Now assume every Az is measurable in R2. This is the case, for example, if the
boundary of Œ© is a Ô¨Ånite union of graphs, or if Œ© is convex.
Taking a continuous and bounded function f : Œ© ‚ÜíR guarantees all integrals
3
Az f(x, y, z) dx dy, z ‚àà[Œ±,Œ≤ ], exist, and one could prove that

Œ©
f =
 Œ≤
Œ±
	
Az
f(x, y, z) dx dy

dz ;
(8.15)
this is yet another iterated integral, where now f is integrated Ô¨Årst over two-
dimensional cross-sections of the domain.
Examples 8.28
i) Compute

Œ©
x dx dy dz
where Œ© denotes the tetrahedron enclosed by the planes x = 0, y = 0, z = 0 and
x + y + z = 1 (Fig. 8.23). The solid is a normal region for z, because
Œ© = {(x, y, z) ‚ààR3 : (x, y) ‚ààD, 0 ‚â§z ‚â§1 ‚àíx ‚àíy}
where
D = {(x, y) ‚ààR2 : 0 ‚â§x ‚â§1, 0 ‚â§y ‚â§1 ‚àíx} .
At the same time we can describe Œ© as
Œ© = {(x, y, z) ‚ààR3 : 0 ‚â§z ‚â§1, (x, y) ‚ààAz}

326
8 Integral calculus in several variables
x
y
z
1
1
1
D
Œ©z
Figure 8.23. The tetrahedron relative to Example 8.28 i)
with
Az = {(x, y) ‚ààR2 : 0 ‚â§x ‚â§1 ‚àíz, 0 ‚â§y ‚â§1 ‚àíz ‚àíx}.
See Fig. 8.24 for a picture of D and Az. Then we can integrate in z Ô¨Årst, so that

Œ©
x dx dy dz =

D
	 1‚àíx‚àíy
0
x dz

dx dy

D
(1 ‚àíx ‚àíy)x dx dy
=
 1
0
	 1‚àíx
0
(1 ‚àíx ‚àíy)x dy

dx = ‚àí1
2
 1
0

(1 ‚àíx ‚àíy)2y=1‚àíx
y=0
x dx
= 1
2
 1
0
(1 ‚àíx)2x dx = 1
24.
x
y
1
1
y = 1 ‚àíx
D
x
y
1 ‚àíz
1 ‚àíz
Az
y = 1 ‚àíz ‚àíx
Figure 8.24. The sets D (left) and Az (right) relative to Example 8.28 i)

8.4 Multiple integrals
327
But we can also compute the double integral in dx dy Ô¨Årst,

Œ©
x dx dy dz =
 1
0
	
Az
x dx dy

dz =
 1
0
	 1‚àíz
0
	 1‚àíx‚àíz
0
x dy

dx

dz
=
 1
0
	 1‚àíz
0
x(1 ‚àíx ‚àíz) dx

dz =
 1
0
1
2x2(1 ‚àíz) ‚àí1
3x3x=1‚àíz
x=0
dz
= 1
6
 1
0
(1 ‚àíz)3 dz = 1
24.
ii) Consider

Œ©

y2 + z2 dx dy dz ,
where Œ© is bounded by the paraboloid x = y2+z2 and the plane x = 2 (Fig. 8.25,
left). We may write
Œ© = {(x, y, z) ‚ààR3 : 0 ‚â§x ‚â§2, (y, z) ‚ààAx}
with slices
Ax = {(y, z) ‚ààR2 : y2 + z2 ‚â§x} .
See Fig. 8.25, right, for the latter. We can thus integrate over Ax Ô¨Årst, and the
best option is to use polar coordinates in the plane yz, given the shape of the
region and the function involved. Then

Ax

y2 + z2 dy dz =
 2œÄ
0
 ‚àöx
0
r2 dr

dŒ∏ = 2
3œÄx‚àöx ,
and consequently

Œ©

y2 + z2 dx dy dz = 2
3œÄ
 2
0
x‚àöx dx = 16
15
‚àö
2œÄ .
x
y
z
Œ©
2
y
z
‚àöx
Ax
Figure 8.25. Example 8.28 ii): paraboloid (left) and the set Ax (right)

328
8 Integral calculus in several variables
Notice the region Œ© is normal for any coordinate, so the integral may be com-
puted by reducing in diÔ¨Äerent ways; the most natural choice is to look at Œ© as
being normal for x:
Œ© = {(x, y, z) ‚ààR3 : (y, z) ‚ààD, y2 + z2 ‚â§x ‚â§2}
with D = {(y, z) ‚ààR2 : 0 ‚â§x ‚â§y2 + z2}. The details are left to the reader.
2
8.4.1 Changing variables in triple integrals
Theorem 8.24, governing variable changes, now reads as follows.
Theorem 8.29 Let Œ¶ : Œ©‚Ä≤ ‚ÜíŒ©, with Œ©‚Ä≤, Œ© measurable in R3, be a change
of variables on Œ©, and set x = Œ¶(u). If f is a continuous and bounded map
on Œ©, we have

Œ©
f(x) dŒ© =

Œ©‚Ä≤ f

Œ¶(u)

| det JŒ¶(u)| dŒ©‚Ä≤ .
(8.16)
The same formula holds in any dimension n > 3.
Let us see how a triple integral transforms if we use cylindrical or spherical
coordinates.
Let Œ¶ deÔ¨Åne cylindrical coordinates in R3, see Sect. 6.6; Fig. 8.26, left, shows
the corresponding volume element. If Œ© is a measurable set and Œ©‚Ä≤ = Œ¶‚àí1(Œ©),
from formula (6.41) we have

Œ©
f(x, y, z) dx dy dz =

Œ©‚Ä≤ f(r cos Œ∏, r sin Œ∏, t) r dr dŒ∏ dt .
O
x
y
z
r
ŒîŒ∏
Œîr Œîz
rŒîŒ∏
O
x
y
z
r
œï
ŒîŒ∏
Œîr
rŒîœï
r sin œïŒîŒ∏
Figure 8.26. Volume element in cylindrical coordinates (left), and in spherical coordin-
ates (right)

8.4 Multiple integrals
329
The variables x, y and z can be exchanged according to the need. Example 8.28
ii) indeed used the cylindrical transformation Œ¶(r, Œ∏, t) = (t, r cos Œ∏, r sin Œ∏).
Consider the transformation Œ¶ deÔ¨Åning spherical coordinates in R3; the volume
element is shown in Fig. 8.26, right. If Œ©‚Ä≤ and Œ© are related by Œ©‚Ä≤ = Œ¶‚àí1(Œ©),
equation (6.44) gives

Œ©
f(x, y, z) dx dy dz =

Œ©‚Ä≤ f(r sin œï cos Œ∏, r sin œï sin Œ∏, r cos œï) r2 sin œï dr dœï dŒ∏ .
Here, too, the roles of the variables can be exchanged.
Examples 8.30
i) Let us compute

Œ©
(x2 + y2) dx dy dz ,
Œ© being the region inside the cylinder x2 + y2 = 1, below the plane z = 3 and
above the paraboloid x2 + y2 + z = 1 (Fig. 8.27, left).
In cylindrical coordinates the cylinder has equation r = 1, the paraboloid t =
1 ‚àír2. Hence,
0 ‚â§r ‚â§1 ,
0 ‚â§Œ∏ ‚â§2œÄ ,
1 ‚àír2 ‚â§t ‚â§3
and
Œ©
(x2 + y2) dx dy dz =
 2œÄ
0
 1
0
 3
1‚àír2 r3 dt dr dŒ∏ = 2œÄ
 1
0

r3t
t=3
t=1‚àír2 dr
= 2œÄ
 1
0
(2r3 + r5) dr = 4
3œÄ .
 
 
 
 
x
y
z
Œ©
x
y
z
Œ©
Figure 8.27. The regions relative to Examples 8.30 i) e ii)

330
8 Integral calculus in several variables
ii) Find the volume of the solid deÔ¨Åned by z ‚â•

x2 + y2 and x2 + y2 + z2 ‚àí
z ‚â§0. This region Œ© lies above the cone z =

x2 + y2 and inside the sphere
x2 + y2 +

z ‚àí1
2
2 = 1
4 with centre (0, 0, 1
2) and radius 1
2 (Fig. 8.27, right).
The volume is given by 3
Œ© dx dy dz, for which we use spherical coordinates. Then
0 ‚â§Œ∏ ‚â§2œÄ ,
0 ‚â§œï ‚â§œÄ
4 .
The bounds on r are found by noting that the sphere has equation r2 = r cos œï,
i.e., r = cos œï. Therefore 0 ‚â§r ‚â§cosœï. In conclusion,
vol(Œ©) =

Œ©
dx dy dz =
 2œÄ
0
 œÄ/4
0
 cos œï
0
r2 sin œï dr dœï dŒ∏
= 2
3œÄ
 œÄ/4
0
cos3 œï sin œï dœï = ‚àí1
6œÄ

cos4 œï
œï=œÄ/4
œï=0
= œÄ
8 .
2
8.5 Applications and generalisations
This last section is devoted to some applications of multiple integrals. We will
consider solids of revolution and show how to compute their volume, and eventually
extend the notion of integral to cover vector-values functions and integrals over
unbounded sets in Rn.
8.5.1 Mass, centre of mass and moments of a solid body
Double and triple integrals are used to determine the mass, the centre of gravity
and the moments of inertia of plane regions or solid Ô¨Ågures. Let us consider, for
a start, a physical body whose width in the z-direction is negligible with respect
to the other dimensions x and y, such as a thin plate. Suppose its mean section,
in the z direction, is given by a region Œ© in the plane. Call Œº(x, y) the surface‚Äôs
density of mass (the mass per unit of area); then the body‚Äôs total mass is
m =

Œ©
Œº(x, y) dx dy .
(8.17)
The centre of mass (also known as centre of gravity, or centroid), of Œ© is
the point G = (xG, yG) with coordinates
xG = 1
m

Œ©
xŒº(x, y) dx dy ,
yG = 1
m

Œ©
yŒº(x, y) dx dy .
(8.18)
Assuming the body has constant density (a homogeneous body), we have

8.5 Applications and generalisations
331
xG =
1
area(Œ©)

Œ©
x dx dy ,
yG =
1
area(Œ©)

Œ©
y dx dy ;
the coordinates of the centre of mass of Œ© are the mean values (see (8.9)) of the
coordinates of its generic point.
The moment (of inertia) of Œ© about a given line r (the axis) is
Ir =

Œ©
d 2
r (x, y)Œº(x, y) dx dy ,
where dr(x, y) denotes the distance of (x, y) from r. In particular, the moments
about the coordinate axes are
Ix =

Œ©
y2Œº(x, y) dx dy ,
Iy =

Œ©
x2Œº(x, y) dx dy .
Their sum is called (polar) moment (of inertia) about the origin
I0 = Ix + Iy =

Œ©
(x2 + y2)Œº(x, y) dx dy =

Œ©
d 2
0 (x, y)Œº(x, y) dx dy ,
with d0(x, y) denoting the distance between (x, y) and the origin.
Similarly, for a solid body Œ© in R3 with mass density Œº(x, y, z):
m =

Œ©
Œº(x, y, z) dx dy dz ,
xG = 1
m

Œ©
xŒº(x, y, z) dx dy dz ,
yG = 1
m

Œ©
yŒº(x, y, z) dx dy dz ,
zG = 1
m

Œ©
zŒº(x, y, z) dx dy dz .
Its moments about the axes are
Ix =

Œ©
(y2 + z2)Œº(x, y, z) dx dy dz ,
Iy =

Œ©
(x2 + z2)Œº(x, y, z) dx dy dz ,
Iz =

Œ©
(x2 + y2)Œº(x, y, z) dx dy dz ,
and the moment about the origin is
I0 = Ix + Iy + Iz =

Œ©
(x2 + y2 + z2)Œº(x, y) dx dy .

332
8 Integral calculus in several variables
x
y
1
1
x = 1 ‚àíy2
Figure 8.28. The set Œ© relative to Example 8.31
Example 8.31
Consider a thin plate Œ© in the Ô¨Årst quadrant bounded by the parabola x = 1‚àíy2
and the axes. Knowing its density Œº(x, y) = y, we want to compute the above
quantities.
The region Œ© is represented in Fig. 8.28. We have
m =

Œ©
y dx dy =
 1
0
 1‚àíy2
0
dx

y dy =
 1
0
y(1 ‚àíy2) dy = 1
4 ,
xG = 4

Œ©
xy dy dx = 4
 1
0
 1‚àíy2
0
x dx

y dy = 2
 1
0
y(1 ‚àíy2)2 dy = 1
3 ,
yG = 4

Œ©
y2 dy dx = 4
 1
0
 1‚àíy2
0
dx

y2 dy = 4
 1
0
y2(1 ‚àíy2) dy = 8
15 ,
Ix =

Œ©
y3 dy dx =
 1
0
 1‚àíy2
0
dx

y3 dy =
 1
0
y3(1 ‚àíy2) dy = 1
12 ,
Iy =

Œ©
x2y dy dx =
 1
0
 1‚àíy2
0
x2 dx

y dy = 1
3
 1
0
y(1 ‚àíy2)3 dy = 1
24 .
2
8.5.2 Volume of solids of revolution
Let Œ© be obtained by rotating around the z-axis the trapezoid T determined by the
function f : [a, b] ‚ÜíR, y = f(z) in the yz-plane (Fig. 8.29). The region T is called
the meridian section of Œ©. The volume of Œ© equals the integral
3
Œ© dx dy dz.
The region Œ©z0, intersection of Œ© with the plane z = z0, is a circle of radius f(z0).
Integrating over the slices Œ©z and recalling the notation of p. 325, then
vol(Œ©) =
 b
a
	
Az
dx dy

dz = œÄ
 b
a

f(z)
2 dz ,
(8.19)

8.5 Applications and generalisations
333
 
 
x
y
z
a
b
y = f(z)
Œ©z0
Figure 8.29. A solid of revolution
since the double integral over Az coincides with the area of Œ©z, that is œÄ

f(z)
2.
Formula (8.19) can be understood geometrically using the centre of mass of the
section T . In fact,
yG =
3
T y dy dz
3
T dy dz =
1
area(T )
 b
a
 f(z)
0
y dy dz =
1
2area(T )
 b
a

f(z)
2 dz .
Using (8.19) then,
yG =
vol(Œ©)
2œÄ area(T )
or
vol(Œ©) = 2œÄyG area(T ) .
(8.20)
This proves the so-called Centroid Theorem of Pappus (variously known also as
Guldin‚Äôs Theorem, or Pappus‚ÄìGuldin Theorem).
Theorem 8.32 The volume of a solid of revolution is the product of the area
of the meridian section times the length of the circle described by the section‚Äôs
centre of mass.
This result extends to the solids of revolution whose meridian section T is not
the trapezoid of a function f, but instead a measurable set in the plane. The
examples that follow are exactly of this kind.
Examples 8.33
i) Compute the volume of the solid Œ©, obtained revolving the triangle T of
vertices A = (1, 1), B = (2, 1), C = (1, 3) in the plane yz around the z-axis.
Fig. 8.30 shows T , whose area is clearly 1. As the line through B and C is
z = ‚àí2y + 5, we have

334
8 Integral calculus in several variables
y
z
1
1
2
3
C
z = ‚àí2y + 5
B
A
Figure 8.30. The triangle T in Example 8.33 i)
vol(Œ©) = 2œÄyG = 2œÄ

T
y dy dz = 2œÄ
 2
1
	 ‚àí2y+5
1
dz

y dy
= 4œÄ
 2
1
(2 ‚àíy)y dy = 8
3œÄ .
ii) Rotate the circle T given by (y ‚àíy0)2 + (z ‚àíz0)2 = r2, 0 < r < y0, in the
plane yz. The solid Œ© obtained is a torus, see Fig. 8.31. Since area(T ) = œÄr2
and the centre of mass of a circle coincides with its geometric centre, we have
vol(Œ©) = 2œÄ2r2y0 .
2
 
 
 
 
 
 x
y
z
T
Figure 8.31. The torus relative to Example 8.33 ii)

8.5 Applications and generalisations
335
8.5.3 Integrals of vector-valued functions
Let f : Œ© ‚äÇRn ‚ÜíRm be a vector-valued map deÔ¨Åned on a measurable set Œ©
(with n, m ‚â•2 arbitrary); let f =
m

i=1
fiei be its representation in the canonical
basis of Rm.
Then f is said integrable on Œ© if all its coordinates fi are integrable, in which
case one deÔ¨Ånes the integral of f over Œ© as the vector of Rm

Œ©
f dŒ© =
m

i=1
 
Œ©
fi dŒ©

ei .
For instance, if v is the velocity Ô¨Åeld of a Ô¨Çuid inside a measurable domain Œ© ‚äÇR3,
then
vŒ© =
1
|Œ©|

Œ©
v dŒ©
is the mean velocity vector in Œ©.
8.5.4 Improper multiple integrals
We saw in Vol. I how to deÔ¨Åne rigorously integrals of unbounded maps and integrals
over unbounded intervals. As far as multivariable functions are concerned, we shall
only discuss unbounded domains of integrations. For simplicity, let f(x, y) be a
map of two real variables deÔ¨Åned on the entire R2, positive and integrable on
every disc BR(0) centred at the origin with radius R. As R grows to +‚àû, the discs
clearly become bigger and tend to cover the plane R2. So it is natural to expect
that f will be integrable on R2 if the limit of the integrals of f over BR(0) exists
and is Ô¨Ånite, as R ‚Üí+‚àû. More precisely,
DeÔ¨Ånition 8.34 Let f
:
R2
‚Üí
R be a positive and integrable map
over any disc BR(0). Then f is said integrable on R2 if the limit
lim
R‚Üí+‚àû

BR(0)
f(x, y) dx dy exists and is Ô¨Ånite. The latter, called improper
integral of f on R2, is denoted by

R2 f(x, y) dx dy =
lim
R‚Üí+‚àû

BR(0)
f(x, y) dx dy .
Remark 8.35 i) The deÔ¨Ånition holds for maps of any sign by requiring |f(x, y)|
to be integrable. Recall that each map can be written as the diÔ¨Äerence of two
positive functions, its positive part f+(x, y) = max

f(x, y), 0

and its negative
part f‚àí(x, y) = max

‚àíf(x, y), 0

, i.e., f(x, y) = f+(x, y) ‚àíf‚àí(x, y); then

336
8 Integral calculus in several variables

R2 f(x, y) dx dy =

R2 f+(x, y) dx dy ‚àí

R2 f‚àí(x, y) dx dy .
ii) Other types of sets may be used to cover R2. Consider for example squares
QR(0) = [‚àíR, R] √ó [‚àíR, R] of base 2R, all centred at the origin. One can prove
that f integrable implies
lim
R‚Üí+‚àû

BR(0)
f(x, y) dx dy =
lim
R‚Üí+‚àû

QR(0)
f(x, y) dx dy .
iii) If the map is not deÔ¨Åned on all R2, but rather on an unbounded subset Œ©, one
considers the limit of

BR(0)‚à©Œ©
f(x, y) dx dy as R ‚Üí+‚àû. If this is Ô¨Ånite, again by
deÔ¨Ånition we set

Œ©
f(x, y) dx dy =
lim
R‚Üí+‚àû

BR(0)‚à©Œ©
f(x, y) dx dy .
2
Examples 8.36
i) Consider f(x, y) =
1

(3 + x2 + y2)3 , a map deÔ¨Åned on R2, positive and con-
tinuous. The integral on the disc BR(0) can be computed in polar coordinates:

BR(0)
f(x, y) dx dy =
 2œÄ
0
 R
0
r

(3 + r2)3 dr dŒ∏
= ‚àí2œÄ

(3 + r2)‚àí1/2R
0 = 2œÄ
 1
‚àö
3
‚àí
1
‚àö
3 + R2

.
Therefore

R2 f(x, y) dx dy =
lim
R‚Üí+‚àû2œÄ
 1
‚àö
3 ‚àí
1
‚àö
3 + R2

= 2œÄ
‚àö
3 ,
making f integrable on R2.
ii) Take f(x, y) =
1
1 + x2 + y2 . Proceeding as before, we have

BR(0)
f(x, y) dx dy =
 2œÄ
0
 R
0
r
1 + r2 dr dŒ∏
= œÄ

log(1 + r2)
R
0 = œÄ log(1 + R2) .
Thus
lim
R‚Üí+‚àû

BR(0)
f(x, y) dx dy =
lim
R‚Üí+‚àûœÄ log(1 + R2) = +‚àû
so the map is not integrable on R2.
iii) With what we have learned we are now able to compute an integral, of
paramount importance in Probability, that has to do with Gaussian density:
S =
 +‚àû
‚àí‚àû
e‚àíx2 dx .

8.6 Exercises
337
Let f(x, y) = e‚àíx2‚àíy2 and observe

R2 e‚àíx2‚àíy2 dx dy =
	
R
e‚àíx2 dx

	
R
e‚àíy2 dy

= S2 .
On the other hand

R2 e‚àíx2‚àíy2 dx dy =
lim
R‚Üí+‚àû

BR(0)
e‚àíx2‚àíy2 dx dy =
lim
R‚Üí+‚àû
 2œÄ
0
 R
0
e‚àír2r dr dŒ∏
=
lim
R‚Üí+‚àûœÄ

‚àíe‚àír2R
0 =
lim
R‚Üí+‚àûœÄ(1 ‚àíe‚àíR2) = œÄ .
Therefore
S =
 +‚àû
‚àí‚àû
e‚àíx2 dx = ‚àöœÄ .
2
8.6 Exercises
1. Draw a rough picture of the region A and then compute the double integrals
below:
a)

A
x
x2 + y2 dx dy
where A = [1, 2] √ó [1, 2]
b)

B
xy dx dy
where B = {(x, y) ‚ààR2 : x ‚àà[0, 1], x2 ‚â§y ‚â§1 + x}
c)

C
(x + y) dx dy
where C = {(x, y) ‚ààR2 : 2x3 ‚â§y ‚â§2‚àöx}
d)

D
‚àöx dx dy
where D = {(x, y) ‚ààR2 : y ‚àà[0, 1], y ‚â§x ‚â§ey}
e)

E
y3 dx dy
where E is the triangle of vertices (0, 2), (1, 1), (3, 2)
f)

F
ey2 dx dy
where F = {(x, y) ‚ààR2 : 0 ‚â§y ‚â§1, 0 ‚â§x ‚â§y}
g)

G
x cos y dx dy
where G is bounded by y = 0, y = x2, x = 1
h)

H
yex dx dy
where H is the triangle of vertices (0, 0), (2, 4), (6, 0)
2. Let f(x, y) be a generic continuous map on R2. Find the domain of integration
in the plane and change the order of integration in the following integrals:
a)
 1
0
 x
0
f(x, y) dy dx
b)
 œÄ/2
0
 sin x
0
f(x, y) dy dx

338
8 Integral calculus in several variables
x
y
1
1
B1
B2
B3
x
y
1
‚àí1
2
1
‚àí1
y = ‚àíx2
x = 1 + y2
Figure 8.32. The sets A and B relative to Exercise 4
c)
 2
1
 log x
0
f(x, y) dy dx
d)
 1
0
 2‚àíy
y2
f(x, y) dx dy
e)
 4
0
 2
y/2
f(x, y) dx dy
f)
 1
0
 œÄ/4
arctan x
f(x, y) dy dx
3. Draw a picture of the integration domain and compute the integrals:
a)
 1
0
 œÄ
œÄy
sin x
x
dx dy
b)
 1
0
 1
y
e‚àíx2 dx dy
c)
 1
0
 1
x
‚àöy
x2 + y2 dy dx
d)
 1
0
 1
‚àöx
ey3 dy dx
e)
 3
0
 9
y2 y cos x2 dx dy
f)
 1
0
 œÄ/2
arcsin y
cos x

1 + cos2 x dx dy
4. Referring to Fig. 8.32, write the domains of integration as unions of normal
domains, then compute the integrals:
a)

A
x2 dx dy
b)

B
xy dx dy
5.
Compute

A
y dx dy over the domain A deÔ¨Åned by
R2 ‚â§x2 + y2 ,
0 ‚â§x ‚â§2 ,
0 ‚â§y ‚â§x
as R ‚â•0 varies.
6. As R ‚â•0 varies, calculate the double integral

A
x dx dy over A deÔ¨Åned by
R2 ‚â•x2 + y2 ,
0 ‚â§x ‚â§1 ,
‚àíx ‚â§y ‚â§0 .

8.6 Exercises
339
7.
Compute

A
x sin |x2 ‚àíy| dx dy
where A is the unit square [0, 1] √ó [0, 1].
8. Determine

A
| sin x ‚àíy| dx dy
where A is the rectangle [0, œÄ] √ó [0, 1].
9. For any real Œ± calculate

A
ye‚àíŒ±|x‚àíy2| dx dy
where A is the square [0, 1] √ó [0, 1].
10. Draw a picture of the given region and, using suitable coordinate changes,
compute the integrals:
a)

A
1
x2y2 dx dy
where A is bounded by y = x2, y = 2x2,
and by x = y2, x = 3y2
b)

B
x5y5
x3y3 + 1 dx dy
where B, in the Ô¨Årst quadrant, is bounded by
y = x, y = 3x, xy = 2, xy = 6
c)

C
(3x + 4y2) dx dy
where C = {(x, y) ‚ààR2 : y ‚â•0, 1 ‚â§x2 + y2 ‚â§4}
d)

D
xy dx dy
where D = {(x, y) ‚ààR2 : x2 + y2 ‚â§9}
e)

E
e‚àíx2‚àíy2 dx dy
where E is bounded by x =

4 ‚àíy2 and x = 0
f)

F
arctan y
x dx dy
where F = {(x, y) ‚ààR2 : 1 ‚â§x2 + y2 ‚â§4,
|y| ‚â§|x|}
g)

G
x

x2 + y2 dx dy
where G = {(x, y) ‚ààR2 : y ‚â•0, x + y ‚â•0,
3 ‚â§x2 + y2 ‚â§9}
h)

H
x dx dy
where H = {(x, y) ‚ààR2 : x, y ‚â•0, x2 + y2 ‚â§4,
x2 + y2 ‚àí2y ‚â•0}

340
8 Integral calculus in several variables
11.
By transforming into Cartesian coordinates, compute the following integral in
polar coordinates

A‚Ä≤
1

cos2 Œ∏ + sin Œ∏/r + 1/r2 dr dŒ∏
where A‚Ä≤ =

(r,Œ∏ ) : 0 ‚â§Œ∏ ‚â§œÄ
2 , r ‚â§
1
cos Œ∏, r ‚â§
1
sin Œ∏

.
12. By transforming into Cartesian coordinates, compute the following integral in
polar coordinates

A‚Ä≤
log r(cos Œ∏ + sin Œ∏)
cos Œ∏
dr dŒ∏
where A‚Ä≤ =

(r,Œ∏ ) : 0 ‚â§Œ∏ ‚â§œÄ
4 , 1 ‚â§r cos Œ∏ ‚â§2

.
13.
Use polar coordinates to write the sum of the integrals
 1
1/
‚àö
2
 x
‚àö
1‚àíx2 xy dy dx +
 ‚àö
2
1
 x
0
xy dy dx +
 2
‚àö
2
 ‚àö
4‚àíx2
0
xy dy dx
as a single double integral, then compute it.
14.
Determine mass and centre of gravity of a thin triangular plate of vertices
(0, 0), (1, 0), (0, 2) if its density is Œº(x, y) = 1 + 3x + y.
15.
A thin plate, of the shape of a semi-disc of radius a, has density proportional
to the distance of the centre from the origin. Find the centre of mass.
16.
Determine the moments Ix, Iy, I0 of a disc with constant density Œº(x, y) = Œº,
centre at the origin and radius a.
17.
Let D be a disc with unit density, centre at C = (a, 0) and radius a. Verify
the equation
I0 = IC + a2A
holds, where I0 and IC are the moments about the origin and the centre C,
and A is the disc‚Äôs area.
18. Compute the moment about the origin of the thin plate C deÔ¨Åned by
C = {(x, y) ‚ààR2 : x2 + y2 ‚â§4, x2 + y2 ‚àíx ‚â•0}
knowing that its density Œº(x, y) equals the distance of (x, y) from the origin.

8.6 Exercises
341
19.
A thin plate C occupies the quarter of disc x2 + y2 ‚â§1 contained in the Ô¨Årst
quadrant. Find its centre of mass knowing the density at each point equals the
distance of that point from the x-axis.
20. A thin plate has the shape of a parallelogram with vertices (3, 0), (0, 6), (‚àí1, 2),
(2, ‚àí4). Assuming it has unit density, compute Iy, the moment about the
axis y.
21. Determine the following multiple integrals:
a)

A
(xy ‚àíz3) dx dy dz
where A = [‚àí1, 1] √ó [0, 1] √ó [0, 2]
b)

B
2y dx dy dz
where B = {(x, y, z) ‚ààR3 : 0 ‚â§x ‚â§z ‚â§2,
0 ‚â§y ‚â§
‚àö
4 ‚àíz2}
c)

C
xz sin y5 dx dy dz
where C = {(x, y, z) ‚ààR3 : 0 ‚â§x ‚â§y ‚â§1,
y ‚â§z ‚â§2y}
d)

D
y dx dy dz
where D, in the Ô¨Årst octant, is bounded by
the planes x + y = 1, y + z = 1
e)

E
y dx dy dz
where E is bounded by the paraboloid
y = 4x2 + 4z2 and the plane y = 4
f)

F
z dx dy dz
where F, in the Ô¨Årst octant, is bounded by the
plane y = 3x and the cylinder y2 + z2 = 9
22. Write the triple integral

A
f(x, y, z) dx dy dz as an iterated integral in at least
three diÔ¨Äerent ways, with A being the solid with lateral surface:
a) x = 0, x = z, y2 = 1 ‚àíz
b) x2 + y2 = 9, z = 0, z = 6
23.
Consider the region A in the Ô¨Årst octant bounded by the planes x+y‚àíz+1 = 0
and x + y = a. Determine the real number a > 0 so that the volume equals
vol(A) = 5
6.
24.
Compute the volume of the region A common to the cylinders x2 +y2 ‚â§1 and
x2 + z2 ‚â§1.
25.
Compute

A
1
3 ‚àíz dx dy dz

342
8 Integral calculus in several variables
over the region A deÔ¨Åned by
9z ‚â§1 + y2 + 9x2 ,
0 ‚â§z ‚â§

9 ‚àí(y2 + 9x2) .
26.
The plane x = K divides the tetrahedron of vertices (1, 0, 0), (0, 2, 0), (0, 0, 3),
(0, 0, 0) in two regions C1, C2. Determine K so that the two solids obtained
have the same volume.
27.
By suitable variable changes, compute the following integrals:
a)

A

x2 + y2 dx dy dz
with A bounded by the cylinder x2 + y2 = 25 and
the planes z = ‚àí1, z = 2
b)

B
x dx dy dz
with B bounded by the cylinders x2 + z2 = 1, x2 + z2 = 4 and
the planes y = 0 and y = z + 2
c)

C
(x + z) dx dy dz
with C = {(x, y, z) ‚ààR3 : 1 ‚â§x ‚â§2, x2 + y2 + z2 ‚â§4}
d)

D
x dx dy dz
with D in the Ô¨Årst octant and bounded by the spheres x2+ y2+ z2 =1
and x2 + y2 + z2 = 4
e)

E

x2 + y2 + z2 dx dy dz
with E bounded below by the cone œï = œÄ
6 and above by the sphere r = 2
28.
Compute the following integrals with the help of a variable change:
a)
 1
‚àí1
 ‚àö
1‚àíz2
‚àí
‚àö
1‚àíz2
 2‚àíx2‚àíz2
x2+z2
(x2 + z2)3/2 dy dx dz
b)
 3
0
 ‚àö
9‚àíy2
0
 ‚àö
18‚àíx2‚àíy2
‚àö
x2+y2
(x2 + y2 + z2) dz dx dy
29.
Calculate the integral

Œ©

4x2 + 16
9 y2 + z2
dx dy dz
where Œ© is the solid bounded by the ellipsoid x2
4 + y2
9 + z2
16 = 1.

8.6 Exercises
343
30.
Find mass and centre of gravity of Œ©, the part of cylinder x2+y2 ‚â§1 in the Ô¨Årst
octant bounded by the plane z = 1, assuming the density is Œº(x, y, z) = x + y.
31.
What is the volume of the solid Œ© obtained by revolution around the z-axis of
T = {(y, z) ‚ààR2 : 2 ‚â§y ‚â§3, 0 ‚â§z ‚â§y, y2 ‚àíz2 ‚â§4} ?
32. The region T , lying on the plane xy, is bounded by the curves y = x2, y = 4,
x = 0 with 0 ‚â§x ‚â§2. Compute the volume of Œ©, obtained by revolution of T
around the axis y.
33.
Rotate around the z-axis the region
T = {(x, z) ‚ààR2 : sin z < x < œÄ ‚àíz, 0 < z < œÄ}
to obtain the solid Œ©. Find its volume and centre of mass.
8.6.1 Solutions
1. Double integrals:
a) The region A is a square, and the integral equals
I = 1
2

7 log 2 ‚àí3 log 5 ‚àí2 arctan2 ‚àí4 arctan 1
2 + 3
2œÄ

.
b) The domain B is represented in Fig. 8.33, left. The integral equals I = 5
8.
x
y
1
1
y = 1 + x
y = x2
x
y
1
2
y = 2x3
y = 2‚àöx
Figure 8.33. The sets B relative to Exercise 1. b) (left) and C to Exercise 1. c) (right)

344
8 Integral calculus in several variables
x
y
1
1
x = ey
y = x
x
y
1
3
1
2
y = 1
2 (x + 1)
y = 2 ‚àíx
Figure 8.34. The sets D relative to Exercise 1. d) (left) and E to Exercise 1. e) (right)
c) See Fig. 8.33, right for the region C. The integral is I = 39
35.
d) The region D is represented in Fig. 8.34, left. The integral‚Äôs value is I =
4
9e3/2 ‚àí32
45.
e) The region E can be seen in Fig. 8.34, right. The lines through the triangle‚Äôs
vertices are y = 2, y = 1
2(x + 1) and y = ‚àíx + 2. Integrating horizontally with
the bounds 1 ‚â§y ‚â§2 and 2 ‚àíy ‚â§x ‚â§2y ‚àí1 gives

E
y3 dx dy =
 2
1
	 2y‚àí1
2‚àíy
y3 dx

dy = 147
20 .
f) The region F is shown in Fig. 8.35, left. Let us integrate between 0 ‚â§y ‚â§1
and 0 ‚â§x ‚â§y to obtain

F
ey2 dx dy =
 1
0
	 y
0
ey2 dx

dy =
 1
0
ey2 [x]y
0 dy
x
y
1
1
y = x
x
y
1
y = x2
Figure 8.35. The sets F relative to Exercise 1. f) (left), and G to Exercise 1. g) (right)

8.6 Exercises
345
x
y
2
6
4
y = 2x
y = 6 ‚àíx
Figure 8.36. The set H relative to Exercise 1. h)
=
 1
0
yey2 dy =
1
2ey21
0
= 1
2(e ‚àí1) .
g) The set G is represented in Fig. 8.35, right. We integrate vertically with 0 ‚â§
x ‚â§1, 0 ‚â§y ‚â§x2:

G
x cos y dx dy =
 1
0
 x2
0
x cos y dy

dx =
 1
0
x [sin y]x2
0
dx
=
 1
0
x sin x2 dx =

‚àí1
2 cos x2
1
0
= 1
2(1 ‚àícos 1) .
h) The region H is shown in Fig. 8.36. The lines passing through the vertices
of the triangle are y = 0, y = ‚àíx + 6, y = 2x. It is convenient to integrate
horizontally with 0 ‚â§y ‚â§4 and y/2 ‚â§x ‚â§6 ‚àíy. Integrating by parts then,

H
yex dx dy =
 4
0
 6‚àíy
y/2
yex dx

dy = e6 ‚àí9e2 ‚àí4 .
2. Order of integration:
a) The domain A is represented in Fig. 8.37, left. Exchanging the integration
order gives
 1
0
 x
0
f(x, y) dy dx =
 1
0
 1
y
f(x, y) dx dy .
b) For the domain B see Fig. 8.37, right. Exchanging the integration order gives
 œÄ/2
0
 sin x
0
f(x, y) dy dx =
 1
0
 œÄ/2
arcsin y
f(x, y) dx dy .

346
8 Integral calculus in several variables
x
y
1
1
y = x
x
y
œÄ
2
y = sin x
1
Figure 8.37. The sets A relative to Exercise 2. a) (left) and B to Exercise 2. b) (right)
c) The domain C is represented in Fig. 8.38, left. Exchanging the integration
order gives
 2
1
 log x
0
f(x, y) dy dx =
 log 2
0
 2
ey f(x, y) dx dy .
d) The region D is drawn in Fig. 8.38, right. In order to integrate vertically, we
must Ô¨Årst divide D in two parts, to the eÔ¨Äect that
 1
0
 2‚àíy
y2
f(x, y) dx dy =
 1
0
 ‚àöx
0
f(x, y) dy dx +
 2
1
 2‚àíx
0
f(x, y) dy dx .
e) The domain E is given in Fig. 8.39, left. Exchanging the integration order
gives
 4
0
 2
y/2
f(x, y) dx dy =
 2
0
 2x
0
f(x, y) dy dx .
f) F is represented in Fig. 8.39, right. Exchanging the integration order gives
 1
0
 œÄ/4
arctan x
f(x, y) dy dx =
 œÄ/4
0
 tan y
0
f(x, y) dx dy .
x
y
1
2
log 2
y = log x
x
y
1
‚àöx
2
1
y = 2 ‚àíx
Figure 8.38. The sets C relative to Exercise 2. c) (left) and D to Exercise 2. d) (right)

8.6 Exercises
347
x
y
2
4
y = 2x
x
y
œÄ
4
y = arctan x
1
Figure 8.39. The sets E relative to Exercise 2. e) (left) and F to Exercise 2. f) (right)
3. Double integrals:
a) The domain A is normal for x and y, so we may write
A = {(x, y) ‚ààR2 : 0 ‚â§y ‚â§1, œÄ y‚â§x ‚â§œÄ}
= {(x, y) ‚ààR2 : 0 ‚â§x ‚â§œÄ, 0 ‚â§y ‚â§x
œÄ } .
See Fig. 8.40, left.
Given that the integrand map is not integrable in elementary functions in x,
it is necessary to exchange the order of integration. Then
 1
0
 œÄ
œÄy
sin x
x
dx dy =
 œÄ
0
 x/œÄ
0
sin x
x
dy

dx =
 œÄ
0
sin x
x
[y]x/œÄ
0
dx
= 1
œÄ
 œÄ
0
sin x dx = 2
œÄ .
b) The domain is normal for x and y, so
B = {(x, y) ‚ààR2 : 0 ‚â§y ‚â§1, y ‚â§x ‚â§1}
= {(x, y) ‚ààR2 : 0 ‚â§x ‚â§1, 0 ‚â§y ‚â§x} .
x
y
œÄ
1
y = x
œÄ
x
y
1
1
y = ‚àöx
Figure 8.40. The sets A relative to Exercise 3. a) (left) and D to Exercise 3. d) (right)

348
8 Integral calculus in several variables
It coincides with the set A of Exercise 2. a), see Fig. 8.37, left.
As in the previous exercise, the map is not integrable in elementary functions
in x, so we exchange the order
 1
0
 1
y
e‚àíx2 dx dy =
 1
0
	 x
0
e‚àíx2 dy

dx =
 1
0
xe‚àíx2 dx = 1
2(1 ‚àíe‚àí1) .
c) The integration domain is normal for x and y, so we write
C = {(x, y) ‚ààR2 : 0 ‚â§x ‚â§1, x ‚â§y ‚â§1}
= {(x, y) ‚ààR2 : 0 ‚â§y ‚â§1, 0 ‚â§x ‚â§y} .
It is the same as the set F of Exercise 1. f), see Fig. 8.35, left.
As in the previous exercise, the map is not integrable in elementary functions
in y, but we can exchange integration order
 1
0
 1
x
‚àöy
x2 + y2 dy dx =
 1
0
	 y
0
‚àöy
x2 + y2 dx

dy
=
 1
0
‚àöy 1
y arctan x
y
y
0
dy = œÄ
4
 1
0
1
‚àöy dy = œÄ
2 .
d) The domain D is as in Fig. 8.40, right, and the integral equals I = (e ‚àí1)/3.
e) The domain E is represented by Fig. 8.41, the integral is I = 1
4 sin 81.
f) The domain is normal for x and y, so
F = {(x, y) ‚ààR2 : 0 ‚â§y ‚â§1, arcsiny ‚â§x ‚â§œÄ
2 }
= {(x, y) ‚ààR2 : 0 ‚â§x ‚â§œÄ
2 , 0 ‚â§y ‚â§sin x} .
It is precisely the set B from Exercise 2. b), see Fig. 8.37, right.
As in the previous exercise the map is not integrable in elementary functions
in x, so we exchange orders
 1
0
 œÄ/2
arcsin y
cos x

1 + cos2 x dx dy =
 œÄ/2
0
 sin x
0
cos x

1 + cos2 x dy

dx
x
y
9
3
y = ‚àöx
Figure 8.41. The set E relative to Exercise 3. e)

8.6 Exercises
349
 œÄ/2
0
sin x cos x

1 + cos2 x dx = 1
2
 2
1
‚àö
t dt = 2
‚àö
2 ‚àí1
3
.
4. Double integrals:
a) The integral is 1.
b) Referring to Fig. 8.32 we divide B into three subsets:
B1 = {(x, y) ‚ààR2 : ‚àí1 ‚â§x ‚â§0, ‚àíx2 ‚â§y ‚â§1}
B2 = {(x, y) ‚ààR2 : 0 ‚â§y ‚â§1, 0 ‚â§x ‚â§1 + y2}
B3 = {(x, y) ‚ààR2 : ‚àí1 ‚â§y ‚â§0, ‚àö‚àíy ‚â§x ‚â§1 + y2} .
After a little computation,

B
xy dx dy =

B1
xy dx dy +

B2
xy dx dy +

B3
xy dx dy
=
 0
‚àí1
 1
‚àíx2 xy dy dx +
 1
0
 1+y2
0
xy dx dy +
 0
‚àí1
 1+y2
‚àö‚àíy
xy dx dy
= 0 .
5. When 0 ‚â§x ‚â§2 the circle x2 + y2 = R2 and the line y = x meet at P =
 R
‚àö
2, R
‚àö
2

. Hence for
R
‚àö
2 > 2, i.e., R > 2
‚àö
2, A is empty and the integral is 0.
So let 0 ‚â§R ‚â§2
‚àö
2, and we have to distinguish two cases: 0 ‚â§R ‚â§2 and
2 < R ‚â§2
‚àö
2. See Fig. 8.42 for A.
Take 0 ‚â§R ‚â§2: using Fig. 8.42 we can write

A
y dx dy =

A1
y dx dy +

A2
y dx dy
x
y
R
‚àö
2
R
2
0 ‚â§R ‚â§2
A1
A2
x
y
R
‚àö
2 2
R
2 ‚â§R ‚â§2
‚àö
2
A
Figure 8.42. The set A relative to Exercise 5

350
8 Integral calculus in several variables
=
 R
R/
‚àö
2
 x
‚àö
R2‚àíx2 y dy dx +
 2
R
 x
0
y dy dx
= 1
2
 R
R/
‚àö
2
(2x2 ‚àíR2) dx + 1
2
 2
R
x2 dx = 4
3 + 1
6R3(
‚àö
2 ‚àí2) .
Now suppose 2 < R ‚â§2
‚àö
2: then

A
y dx dy =
 2
R/
‚àö
2
 x
‚àö
R2‚àíx2 y dy dx
= 1
2
 2
R/
‚àö
2
(2x2 ‚àíR2) dx = 8
3 ‚àíR2 +
1
3
‚àö
2R3 .
6. We have

A
x dx dy =
‚éß
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é©
‚àö
2
6 R3
if 0 ‚â§R < 1 ,
‚àö
2
6 R3 ‚àí1
3(R2 ‚àí1)3/2
if 1 ‚â§R <
‚àö
2 ,
1
3
if R ‚â•
‚àö
2 .
7. The integrand changes sign according to whether (x, y) ‚ààA is above or below
the parabola y = x2 (see Fig. 8.43). Precisely, for any (x, y) ‚ààA,
x sin |x2 ‚àíy| =
 x sin(x2 ‚àíy)
if y ‚â§x2 ,
‚àíx sin(x2 ‚àíy)
if y > x2 .
x
y
1
1
y = x2
A1
A2
Figure 8.43. The set A relative to Exercise 7

8.6 Exercises
351
Looking at Fig. 8.43 then, we have

A
x sin |x2 ‚àíy| dx dy =

A1
x sin(x2 ‚àíy) dx dy ‚àí

A2
x sin(x2 ‚àíy) dx dy
=
 1
0
 x2
0
x sin(x2 ‚àíy) dy dx ‚àí
 1
0
 1
x2 x sin(x2 ‚àíy) dy dx
=
 1
0

x cos(x2 ‚àíy)
x2
0
dx ‚àí
 1
0

x cos(x2 ‚àíy)
1
x2 dx
=
 1
0
x(1 ‚àícos x2) dx ‚àí
 1
0
x

cos(x2 ‚àí1) ‚àí1

dx = 1 ‚àísin 1 .
8. The result is I = œÄ ‚àí2.
9. We have

A
ye‚àíŒ±|x‚àíy2| dx dy =
‚éß
‚é™
‚é™
‚é®
‚é™
‚é™
‚é©
1
Œ±2 (e‚àíŒ± ‚àí1 + Œ±)
if Œ± Ã∏= 0 ,
1
2
if Œ± = 0 .
10. Double integrals:
a) The region A is bounded by four parabolas, see Fig. 8.44, left. Set u = y
x2 , v =
x
y2 , which deÔ¨Åne the transformation (u, v) = Œ®(x, y); with that change, A
becomes the rectangle A‚Ä≤ = [1, 2] √ó [1, 3]. The Jacobian of Œ® reads
JŒ®(x, y) =
	 ‚àí2y/x3
1/x2
1/y2
‚àí2x/y3

x
y
y = x2
y = 2x2
x = y2
x = 3y2
A
x
y
y = x
y = 3x
xy = 6
B
xy = 2
Figure 8.44. The sets A relative to Exercise 10. a) (left) and B to Exercise 10. b) (right)

352
8 Integral calculus in several variables
with
det JŒ®(x, y) =
4
x2y2 ‚àí
1
x2y2 =
3
x2y2 = 3u2v2 ;
therefore, if Œ¶ = Œ®‚àí1, we have det JŒ¶(u, v) =
1
3u2v2 . Thus

A
1
x2y2 dx dy =
 2
1
 3
1
u2v2
1
3u2v2 dv du = 2
3 .
b) B is bounded by 2 lines and 2 hyperbolas, see Fig. 8.44, right.
DeÔ¨Åne (u, v) = Œ®(x, y) by u = xy, v = y
x. Then B becomes the rectangle
B‚Ä≤ = [2, 6] √ó [1, 3], and
JŒ®(x, y) =
	
y
x
‚àíy/x2
1/x

,
det JŒ®(x, y) = 2 y
x = 2v .
Calling Œ¶ = Œ®‚àí1, we have det JŒ¶(u, v) = 1/2v, so

B
x5y5
x3y3 + 1 dx dy =
 3
1
 6
2
u5
u3 + 1
1
2v du dv = 1
2

log v
3
1
 6
2
	
u2 ‚àí
u2
u3 + 1

du
= 1
2 log 3
1
3u3 ‚àí1
3 log(u3 + 1)
6
2
= 1
6 log 3

208 + log 9
217

.
c) The region C is shown in Fig. 8.45, left.
Passing to polar coordinates (r,Œ∏ ), C transforms into C‚Ä≤ = [1, 2] √ó [0, œÄ], so

C
(3x + 4y2) dx dy =
 œÄ
0
 2
1
(3r cos Œ∏ + 4r2 sin2 Œ∏)r dr dŒ∏
=
 œÄ
0

r3 cos Œ∏ + r4 sin2 Œ∏
2
1 dŒ∏ =
 œÄ
0

7 cosŒ∏ + 15 sin2 Œ∏

dŒ∏
=
 œÄ
0
	
7 cos Œ∏ + 15
2 (1 ‚àícos 2Œ∏)

dŒ∏ = 15
2 œÄ .
x
y
2
1
C
x
y
3
D
Figure 8.45. The sets C relative to Exercise 10. c) (left) and D to Exercise 10. d) (right)

8.6 Exercises
353
x
y
1
E
x
y
1
F
2
Figure 8.46. The sets E relative to Exercise 10. e) (left) and F to Exercise 10. f) (right)
d) For D see Fig. 8.45, right. The integral is I = 0 .
e) Fig. 8.46, left, shows the region E, and the integral is I = œÄ
2 (1 ‚àíe‚àí4).
f) F is represented in Fig. 8.46, right, the integral is I = 0.
g) G is shown in Fig. 8.47, left. The integral equals I = 3
‚àö
2
2 .
h) The region H lies in the Ô¨Årst quadrant, and consists of points inside the circle
centred at the origin of radius 2 but outside the circle with centre (0, 1) and
unit radius (Fig. 8.47, right). In polar coordinates H becomes H‚Ä≤ in the (r,Œ∏ )-
plane deÔ¨Åned by 0 ‚â§Œ∏ ‚â§œÄ
2 and 2 sin Œ∏ ‚â§r ‚â§2; that is because the circle
x2 + y2 ‚àí2y ‚â•0 reads r ‚àí2 sin Œ∏ ‚â•0 in polar coordinates. Therefore

H
x dx dy =
 œÄ/2
0
 2
2 sin Œ∏
r2 cos Œ∏ dr dŒ∏ = 1
3
 œÄ/2
0
cos Œ∏

r32
2 sin Œ∏ dŒ∏
= 8
3
 œÄ/2
0
(cos Œ∏ ‚àícos Œ∏ sin3 Œ∏) dŒ∏ = 8
3

sin Œ∏ ‚àí1
4 sin4 Œ∏
œÄ/2
0
= 2 .
11. If we pass to Cartesian coordinates, the condition 0 ‚â§Œ∏ ‚â§
œÄ
2 means we
only have to consider points in the Ô¨Årst quadrant, while r =
1
cos Œ∏ and r =
1
sin Œ∏
x
y
‚àö
3
G
3
x
y
2
1
H
Figure 8.47. The sets G relative to Exercise 10. g) (left) and H to Exercise 10. h) (right)

354
8 Integral calculus in several variables
correspond to the lines x = 1, y = 1. In the plane (x, y) then, A‚Ä≤ becomes the
square A = [0, 1] √ó [0, 1], so

A‚Ä≤
1

cos2 Œ∏ + sin Œ∏/r + 1/r2 dr dŒ∏ =

A‚Ä≤
1
‚àö
r2 cos2 Œ∏ + r sin Œ∏ + 1
r dr dŒ∏
=

A
1

x2 + y + 1
dx dy =
 1
0
 1
0
1

x2 + y + 1
dx dy
= 2
 1
0

x2 + y + 1
1
0 dx = 2
 1
0

x2 + 2 ‚àí

x2 + 1

dx
= 2
%
x
‚àö
x2 + 2
2
+ log(x +

x2 + 2) ‚àíx
‚àö
x2 + 1
2
‚àí1
2 log(x +

x2 + 1)
&1
0
=
‚àö
3 ‚àí
‚àö
2 + log 2 +
‚àö
3
1 +
‚àö
2
.
12. I = 4 log 2 ‚àí2.
13. Note x ‚àà
 1
‚àö
2, 2

and the curves y =
‚àö
1 ‚àíx2 and y =
‚àö
4 ‚àíx2 are semi-circles
at the origin with radius 1 and 2. The region A in the coordinates (x, y) is made
of the following three sets:
A1 = {(x, y) ‚ààR2 :
1
‚àö
2 ‚â§x ‚â§1,

1 ‚àíx2 ‚â§y ‚â§x}
A2 = {(x, y) ‚ààR2 : 1 ‚â§x ‚â§
‚àö
2, 0 ‚â§y ‚â§x}
A3 = {(x, y) ‚ààR2 :
‚àö
2 ‚â§x ‚â§2, 0 ‚â§y ‚â§

4 ‚àíx2} ;
see Fig. 8.48.
x
y
1
2
A1
A2 A3
Figure 8.48. The set A relative to Exercise 13

8.6 Exercises
355
In polar coordinates A becomes A‚Ä≤ = {(r,Œ∏ ) : 0 ‚â§Œ∏ ‚â§œÄ
4 , 1 ‚â§r ‚â§2}, so
I =

A‚Ä≤ r3 sin Œ∏ cos Œ∏ dr dŒ∏ =
 œÄ/4
0
 2
1
r3 sin Œ∏ cos Œ∏ dr dŒ∏ = 15
16 .
14. The thin plate is shown in Fig. 8.49, left, and we can write
A = {(x, y) ‚ààR2 : 0 ‚â§x ‚â§1, 0 ‚â§y ‚â§2 ‚àí2x} .
Hence
m(A) =

A
Œº(x, y) dx dy =
 1
0
 2‚àí2x
0
(1 + 3x + y) dy dx = 8
3 ,
xB(A) =
1
m(A)

A
xŒº(x, y) dx dy = 3
8
 1
0
 2‚àí2x
0
x(1 + 3x + y) dy dx = 3
8 ,
yB(A) =
1
m(A)

A
yŒº(x, y) dx dy = 3
8
 1
0
 2‚àí2x
0
y(1 + 3x + y) dy dx = 11
16 ,
so the centre of mass has coordinates ( 3
8, 11
16).
15. The thin plate A is the upper semi-circle of x2 + y2 = a2 (Fig. 8.49, right).
The distance of (x, y) from the centre (the origin) is

x2 + y2, whence the
density becomes Œº(x, y) = K

x2 + y2, with given K > 0. In polar coordinates,
m(A) =

A
Œº(x, y) dx dy =
 œÄ
0
 a
0
Kr2 dr dŒ∏ = KœÄa3
3
.
Since the thin plate and its density are symmetric with respect to y, the centre of
mass has to lie on the axis, so xB(A) = 0. As for the other coordinate:
yB(A) =
1
m(A)

A
yŒº(x, y) dx dy =
3
KœÄa3
 œÄ
0
 a
0
Kr3 sin Œ∏ dr dŒ∏ = 3a
2œÄ .
Therefore the centroid‚Äôs coordinates are (0, 3a
2œÄ).
x
y
2
1
y = 2 ‚àí2x
x
y
‚àía
a
x2 + y2 = a2
Figure 8.49. The sets A relative to Exercises 14 (left) and 15 (right)

356
8 Integral calculus in several variables
16. In polar coordinates
I0 =

D
(x2 + y2)Œº dx dy = Œº
 2œÄ
0
 a
0
r3 dr dŒ∏ = œÄ
2 Œºa4 .
By symmetry, Ix = Iy, so the equation I0 = Ix + Iy gives immediately
Ix = Iy = œÄ
4 Œºa4 .
17. Fig. 8.50 shows the disc D, whose boundary has equation (x ‚àía)2 + y2 = a2,
or polar r = 2a cosŒ∏. Thus
I0 =

D
(x2 + y2) dx dy =
 œÄ/2
‚àíœÄ/2
 2a cos Œ∏
0
r3 dr dŒ∏
= 4
 œÄ/2
‚àíœÄ/2
a4 cos4 Œ∏ dŒ∏ = 8a4
 œÄ/2
0
cos4 Œ∏ dŒ∏ = 3
2œÄa4 ,
IC =

D
[(x ‚àía)2 + y2] dx dy =

D‚Ä≤(t2 + y2) dt dy
=
 2œÄ
0
 a
0
r3 dr dŒ∏ = 1
2œÄa4 .
But as A = œÄa2, we immediately Ô¨Ånd I0 = IC + a2A.
18. I0 = 64
5 œÄ ‚àí16
75.
19. Since Œº(x, y) = y we have
m(A) =

C
y dx dy =
 œÄ/2
0
 1
0
r2 sin Œ∏ dr dŒ∏ = 1
3 ,
x
y
1
2
Figure 8.50. The disc D relative to Exercise 17

8.6 Exercises
357
xB(A) = 3

C
xy dx dy = 3
 œÄ/2
0
 1
0
r3 sin Œ∏ cos Œ∏ dr dŒ∏ = 3
8 ,
yB(A) = 3

C
y2 dx dy = 3
 œÄ/2
0
 1
0
r3 sin2 Œ∏ dr dŒ∏ = 3
16œÄ .
20. Iy = 33.
21. Triple integrals:
a) I = ‚àí8.
b) I = 4.
c) I =
3
20(1 ‚àícos 1).
d) We have

D
y dx dy dz =
 1
0
y
	 1‚àíy
0
dx
 1‚àíy
0
dz

dy
=
 1
0
y(1 ‚àíy)2 dy = 1
12 .
See Fig. 8.51, left.
e) Since

E
y dx dy dz =
 4
0

Ey
dx dz

y dy
with Ey = {(x, z) ‚ààR2 : x2 + z2 = y
4}, the integral 3
Ey dx dz is the area of
Ey, hence œÄ y
4. Therefore

E
y dx dy dz = œÄ
4
 4
0
y2 dy = 16
3 œÄ ,
see Fig. 8.51, right.
x
y
z
1
1
1
x
y
z
Ey √ó {y}
Figure 8.51. The regions relative to Exercise 21. d) (left) and Exercise 21. e) (right)

358
8 Integral calculus in several variables
f) We have

F
z dx dy dz =
 3
0

1
3
‚àö
9‚àíz2
0
dx
  ‚àö
9‚àíz2
0
dy

z dz = 27
4 .
See Fig. 8.52, left.
22. Triple integrals:
a) We have
I =
 1
‚àí1
 1‚àíy2
0
 z
0
f(x, y, z) dx dz dy =
 1
0
 ‚àö1‚àíz
‚àí‚àö1‚àíz
 z
0
f(x, y, z) dx dy dz
=
 1
0
 1
x
 ‚àö1‚àíz
‚àí‚àö1‚àíz
f(x, y, z) dy dz dx =
 1
0
 z
0
 ‚àö1‚àíz
‚àí‚àö1‚àíz
f(x, y, z) dy dx dz
=
 1
‚àí1
 1‚àíy2
0
 1‚àíy2
x
f(x, y, z) dz dx dy =
 1
0
 ‚àö1‚àíx
‚àí‚àö1‚àíx
 1‚àíy2
x
f(x, y, z) dz dy dx .
b) Simply computing,
I =
 3
‚àí3
 6
0
 ‚àö
9‚àíy2
‚àí‚àö
9‚àíy2 f(x, y, z) dx dz dy =
 6
0
 3
‚àí3
 ‚àö
9‚àíy2
‚àí‚àö
9‚àíy2 f(x, y, z) dx dy dz
=
 3
‚àí3
 6
0
 ‚àö
9‚àíx2
‚àí
‚àö
9‚àíx2 f(x, y, z) dy dz dx =
 6
0
 3
‚àí3
 ‚àö
9‚àíx2
‚àí
‚àö
9‚àíx2 f(x, y, z) dy dx dz
=
 3
‚àí3
 ‚àö
9‚àíy2
‚àí‚àö
9‚àíy2
 6
0
f(x, y, z) dz dx dy =
 3
‚àí3
 ‚àö
9‚àíx2
‚àí
‚àö
9‚àíx2
 6
0
f(x, y, z) dz dy dx .
x
y
z
1
3
a
a
D
x
y
z
Figure 8.52. The regions relative to Exercise 21. f) (left) and to Exercise 23 (right)

8.6 Exercises
359
23. Integrating in z Ô¨Årst, with 0 ‚â§z ‚â§x + y + 1, gives
vol(A) =

D
 x+y+1
0
dz dx dy
where D = {(x, y) ‚ààR2 : 0 ‚â§x ‚â§a, 0 ‚â§y ‚â§a ‚àíx}, see Fig. 8.52, right. The
computations yield
vol(A) =
 a
0
 a‚àíx
0
(x + y + 1) dy dx = 1
2a2 + 1
3a3 .
Imposing vol(A) = 5
6 we obtain
1
2a2 + 1
3a3 = 5
6
i.e.,
(a ‚àí1)(2a2 + 5a + 5) = 0 .
In conclusion, a = 1.
24. By symmetry it suÔ¨Éces to compute the volume of the region restricted to the
Ô¨Årst octant, then multiply it by 8. Reducing the integral,
vol(A) = 8
 1
0
 ‚àö
1‚àíx2
0
 ‚àö
1‚àíx2
0
dz dx dy = 16
3 .
See Fig. 8.53.
25. The surface 9z = 1 + y2 + 9x2 is a paraboloid, whereas z =

9 ‚àí(y2 + 9x2)
is an ellipsoid centred at the origin with semi-axes a = 1, b = 3, c = 3. Then

A
1
3 ‚àíz dx dy dz =
 1
0
1
3 ‚àíz
	
Az
dx dy

dz .
For the integral inbetween brackets we distinguish 0 ‚â§z ‚â§1
9 and 1
9 ‚â§z ‚â§1. In the
Ô¨Årst case Az is an ellipse in (x, y) with semi-axes a = 1
3
‚àö
9 ‚àíz2 and b =
‚àö
9 ‚àíz2
x
y
z
Figure 8.53. The region relative to Exercise 24

360
8 Integral calculus in several variables
 
 
 
 
 
 
 
 
x
y
z
Az √ó {z}
 
 
 
 
 
 
 
 
x
y
z
Az √ó {z}
Figure 8.54. The regions relative to Exercise 25
(Fig. 8.54, left); the integral is the area of Az, whence œÄab = œÄ
3 (9 ‚àíz2). In case
1
9 ‚â§z ‚â§1, Az is the region bounded by the ellipses 9x2 + y2 = 9z ‚àí1 and
9x2 + y2 = 9 ‚àíz2 (Fig. 8.54, right) with
a1 =
‚àö9z ‚àí1
3
,
b1 =
‚àö
9z ‚àí1 ,
a2 =
‚àö
9 ‚àíz2
3
,
b2 =

9 ‚àíz2 .
Therefore

Az
dx dy = œÄa2b2 ‚àíœÄa1b1 = œÄ
3 (9 ‚àíz2) ‚àíœÄ
3 (9z ‚àí1) .
Returning to the starting integral,

A
1
3 ‚àíz dx dy dz = œÄ
3
 1/9
0
9 ‚àíz2
3 ‚àíz dz + œÄ
3
 1
1/9
	9 ‚àíz2
3 ‚àíz ‚àí9z ‚àí1
3 ‚àíz

dz
= œÄ
3
 1
0
(3 + z) dz + œÄ
3
 1
1/9
	
9 +
26
z ‚àí3

dz
= 23
6 œÄ + 26
3 œÄ log 9
13 .
26. Both volumes can be found by integrating in x the cross-sections:
vol(C1) =
 K
0
	
Ax
dy dz

dx =
 1
K
	
Ax
dy dz

dx = vol(C2) .
The set Ax, contained in (y, z), is
Ax =

(y, z) ‚ààR2 : 0 ‚â§y ‚â§2(1 ‚àíx), 0 ‚â§z ‚â§3 ‚àí3x ‚àí3
2y

;
Fig. 8.55 shows the product Ax √ó {x}. We must thus have
 K
0
 2(1‚àíx)
0
 3‚àí3x‚àí3
2 y
0
dz dy dx =
 1
K
 2(1‚àíx)
0
 3‚àí3x‚àí3
2 y
0
dz dy dx ,

8.6 Exercises
361
x
y
z
Ax √ó {x}
1
2
3
Figure 8.55. The region relative to Exercise 26
hence
1 ‚àí(1 ‚àíK)3 = (1 ‚àíK)3 ,
from which K = 1 ‚àí1/
3‚àö
2.
27. Triple integrals:
a) In cylindrical coordinates A becomes
A‚Ä≤ = {(r, Œ∏, t) : 0 ‚â§r ‚â§5, 0 ‚â§Œ∏ ‚â§2œÄ, ‚àí1 ‚â§t ‚â§2} .
Therefore

A

x2 + y2 dx dy dz =
 2
‚àí1
 2œÄ
0
 5
0
r2 dr dŒ∏ dt = 250œÄ .
b) We shall use cylindrical coordinates with axis y, i.e., x = r cos Œ∏, y = t, z =
r sin Œ∏. Then (see Fig. 8.56)
B = {(x, y, z) ‚ààR3 : 1 ‚â§x2 + z2 ‚â§4, 0 ‚â§y ‚â§z + 2}
becomes
B‚Ä≤ = {(r, Œ∏, t) : 1 ‚â§r ‚â§2, 0 ‚â§Œ∏ ‚â§2œÄ, 0 ‚â§t ‚â§r sin Œ∏ + 2} ;

362
8 Integral calculus in several variables
x
y
z
Figure 8.56. The region relative to Exercise 27. b)
therefore

B
x dx dy dz =
 2œÄ
0
 2
1
 r sin Œ∏+2
0
r2 cos Œ∏ dt dr dŒ∏
=
 2œÄ
0
 2
1
r2 cos Œ∏(r sin Œ∏ + 2) dr dŒ∏
=
1
4r42
1
1
2 sin2 Œ∏
2œÄ
0 +
2
3r32
1

sin Œ∏
2œÄ
0
= 0 .
c)
9
4œÄ.
d) The region D is, in spherical coordinates,
D‚Ä≤ = {(r, œï,Œ∏ ) : 1 ‚â§r ‚â§2, 0 ‚â§œï,Œ∏ ‚â§œÄ
2 } ,
so

D
x dx dy dz =
 2
1
 œÄ/2
0
 œÄ/2
0
r3 sin2 œï cos Œ∏ dŒ∏ dœï dr
=
	 2
1
r3 dr

  œÄ/2
0
cos Œ∏ dŒ∏
  œÄ/2
0
sin2 œï dœï

= 15
4 ¬∑ 1 ¬∑ 1
2
 œÄ/2
0

1 ‚àícos 2œï

dœï = 15
16œÄ .
e) 4(2 ‚àí
‚àö
3)œÄ.

8.6 Exercises
363
28. Triple integrals:
a) In spherical coordinates Œ© is deÔ¨Åned by
‚àí

1 ‚àíz2 ‚â§x ‚â§

1 ‚àíz2 ,
x2 + z2 ‚â§y ‚â§2 ‚àíx2 ‚àíz2 ,
‚àí1 ‚â§z ‚â§1 .
The Ô¨Årst and last constraints determine the inside of the cylinder x2 + z2 = 1,
so cylindrical coordinates (along y) are convenient:
x = r cos Œ∏ ,
y = t ,
z = r sin Œ∏ .
Thus Œ© becomes
Œ©‚Ä≤ = {(r, Œ∏, t) : 0 ‚â§r ‚â§1, 0 ‚â§Œ∏ ‚â§2œÄ, r2 ‚â§t ‚â§2 ‚àír2}
and the integral reads

Œ©
(x2 + z2)3/2 dx dy dz =
 1
0
 2œÄ
0
 2‚àír2
r2
r4 dt dŒ∏ dr = 8
35œÄ .
b)
486
5 (
‚àö
2 ‚àí1)œÄ.
29. Let us use generalised spherical coordinates
x = 2r sin œï cos Œ∏ ,
y = 3r sin œï sin Œ∏ ,
z = 4r cos œï
where dx dy dz = 24r2 sin œï dr dœï dŒ∏; now Œ©‚Ä≤ is described by 0 ‚â§r ‚â§1 , 0 ‚â§Œ∏ ‚â§
2œÄ , 0 ‚â§œï ‚â§œÄ . Thus,

Œ©

4x2 + 16
9 y2 + z2
dx dy dz = 16 ¬∑ 24
 1
0
 2œÄ
0
 œÄ
0
r4 sin œï dœï dŒ∏ dr = 1536
5
œÄ .
30. Let us Ô¨Årst Ô¨Ånd the mass using cylindrical coordinates. As Œ© is
Œ©‚Ä≤ = {(r, Œ∏, t) : 0 ‚â§r ‚â§1, 0 ‚â§Œ∏ ‚â§œÄ
2 , 0 ‚â§t ‚â§1} ,
we have
m =

Œ©
(x + y) dx dy dz =
 1
0
 1
0
 œÄ/2
0
r2(cos Œ∏ + sin Œ∏) dŒ∏ dr dt = 2
3 .
By symmetry, xG = yG, and, similarly to the previous calculation,
xG = 3
2

Œ©
x(x + y) dx dy dz = 3
2
 1
0
 1
0
 œÄ/2
0
r3 cos Œ∏(cos Œ∏ + sin Œ∏) dŒ∏ dr dt
= 3
8
 œÄ/2
0
(cos2 Œ∏ + cos Œ∏ sin Œ∏) dŒ∏ dr dt = 3
16

Œ∏ + 1
2 sin 2Œ∏ + sin2 Œ∏
œÄ/2
0
= 3
16

1 + œÄ
2

= yG ,
zG = 3
2

Œ©
z(x + y) dx dy dz = 3
2
 1
0
 1
0
 œÄ/2
0
t r2(cos Œ∏ + sin Œ∏) dŒ∏ dr dt = 1
2 .

364
8 Integral calculus in several variables
y
z
2
3
z = y
z =

y2 ‚àí4
Figure 8.57. The meridian section relative to Exercise 31
31. The meridian section T is shown in Fig. 8.57. Theorem 8.32 tells us
vol(Œ©) = 2œÄ

T
y dy dz .
Then
vol(Œ©) = 2œÄ
 3
2
 y
‚àö
y2‚àí4
y dz

dy = 2œÄ
 3
2

y2 ‚àíy

y2 ‚àí4

dy
= 2œÄ
1
3y3 ‚àí1
3(y2 ‚àí4)3/23
2 = 2
3(19 ‚àí5
‚àö
5)œÄ .
32. 8œÄ.
33. The section T is drawn in Fig. 8.58, left. Using Theorem 8.32 the volume is
vol(Œ©) = 2œÄ

T
x dx dz = 2œÄ
 œÄ
0
  œÄ‚àíz
sin z
x dx

dz = œÄ
 œÄ
0

(œÄ ‚àíz)2 ‚àísin2 z

dz
= œÄ

‚àí1
3(œÄ ‚àíz)3 ‚àí1
2(z ‚àí1
2 sin 2z)
œÄ
0 = 1
3œÄ4 ‚àí1
2œÄ2 .
But as Œ© is a solid of revolution around z, the centre of mass is on that axis, so
xG = yG = 0. To Ô¨Ånd zG, we integrate cross-sections:
zG =
1
vol(Œ©)

Œ©
z dx dy dz =
1
vol(Œ©)
 œÄ
0
z
	
Az
dx dy

dz
where Az is the projection on xy of the annulus Œ©z of Fig. 8.58, right.

8.6 Exercises
365
x
z
œÄ
œÄ
x = œÄ ‚àíz
x=sin z
x
y
z
Œ©z
Figure 8.58. Meridian section (left) and region Œ©z (right) relative to Exercise 33
The integral

Az
dx dy is the area of Az, which is known to be œÄ

(œÄ‚àíz)2 ‚àísin2 z

.
In conclusion,
zG =
œÄ
vol(Œ©)
 œÄ
0
z

(œÄ ‚àíz)2 ‚àísin2 z

dx dy dz =
1
vol(Œ©)
œÄ5
12 ‚àíœÄ3
4

= œÄ3 ‚àí3œÄ
4œÄ2 ‚àí6 .

9
Integral calculus on curves and surfaces
With this chapter we conclude the study of multivariable integral calculus. In
the Ô¨Årst part we deÔ¨Åne integrals along curves in Rm and over surfaces in space,
by considering Ô¨Årst real-valued maps, then vector-valued functions. Integrating a
vector Ô¨Åeld‚Äôs tangential component along a curve, or its normal component on a
surface, deÔ¨Ånes line and Ô¨Çux integrals respectively; these are interpreted in Physics
as the work done by a force along a path, or the Ô¨Çow across a membrane immersed
in a Ô¨Çuid. Curvilinear integrals rely, de facto, on integrals over real intervals,
in the same way as surface integrals are computed by integrating over domains
in the plane. A certain attention is devoted to how integrals depend upon the
parametrisations and orientations of the manifolds involved.
Path and Ô¨Çux integrals crop up in a series of results, among which three are
pivotal: the Divergence Theorem (also known as Gauss‚Äô Theorem), Green‚Äôs The-
orem and Stokes‚Äô Theorem. They transfer to a multivariable framework the idea
at the heart of one-dimensional integration by parts, and namely: changing the
integral over a given domain into an integral over its boundary by modifying the
integrand function. The aforementioned theorems have a large number of applic-
ations, in particular diÔ¨Äerential equations governing physical laws; for instance,
the Divergence Theorem allows to compute the variation of the Ô¨Çow of a unit of
matter by means of an integral over the volume, thus giving rise to the so-called
conservation laws.
The last part deals with conservative Ô¨Åelds, which are gradients of vector Ô¨Åelds,
and with the problem of computing the potential of a given Ô¨Åeld. That is the mul-
tivariable version of indeÔ¨Ånite integration, which seeks primitive maps on the real
line. The applicative importance of conservative Ô¨Åelds and their potentials is well
known: in many cases a gravitational Ô¨Åeld or an electric force Ô¨Åeld is conservative,
a fact allowing to compute the force‚Äôs work simply by diÔ¨Äerence of two values of
the potential.
C. Canuto, A. Tabacco: Mathematical Analysis II, 2nd Ed.,
UNITEXT ‚Äì La Matematica per il 3+2 85, DOI 10.1007/978-3-319-12757-6_9,
¬© Springer International Publishing Switzerland 2015

368
9 Integral calculus on curves and surfaces
9.1 Integrating along curves
Curvilinear integrals in several variables are the natural generalisation of the def-
inite integral of a real map over a real interval. Curves were introduced in Sect. 4.6,
while their diÔ¨Äerential aspects were discussed in Sect. 6.5.
Let Œ≥ : I = [a, b] ‚ÜíRm (m ‚â•2) be a regular arc, and Œì = Œ≥(I) its trace.
Suppose f : dom f ‚äÜRm ‚ÜíR is a map deÔ¨Åned on Œì, at least, meaning Œì ‚äÜdom f.
Suppose further that the composite f ‚ó¶Œ≥ : [a, b] ‚ÜíR, (f ‚ó¶Œ≥)(t) = f(Œ≥(t)), is
(piecewise) continuous on [a, b].
DeÔ¨Ånition 9.1 The integral of f along Œ≥ is the number

Œ≥
f =
 b
a
f

Œ≥(t)

‚à•Œ≥‚Ä≤(t)‚à•dt .
(9.1)
Sometimes the name ‚Äòcurvilinear integral‚Äô can be met.
The right-hand side of (9.1) is well deÔ¨Åned, because the integrand function
f

Œ≥(t)

‚à•Œ≥‚Ä≤(t)‚à•is (piecewise) continuous on [a, b]. As Œ≥ is regular, in fact, its com-
ponents‚Äô Ô¨Årst derivatives are continuous and so is the norm ‚à•Œ≥‚Ä≤(t)‚à•, by composition;
moreover, f

Œ≥(t)

is (piecewise) continuous by hypothesis.
The geometrical meaning is the following. Let Œ≥ be a simple plane arc and f
non-negative along Œì; call
G(f) = {(x, y, z) ‚ààR3 : (x, y) ‚ààdom f, z = f(x, y)}
the graph of f. If
Œ£ = {(x, y, z) ‚ààR3 : (x, y) ‚ààŒì, 0 ‚â§z ‚â§f(x, y)}
denotes the upright surface fencing Œì up to the graph of f (see Fig. 9.1), it can be
proved that the area of Œ£ is given by the integral of f along Œ≥. Say, for instance,
f is constant equal to h on Œì: then the area of Œ£ is the product of h times the
length of Œì; by Sect. 6.5.2 the length is ‚Ñì(Œì) =
3 b
a ‚à•Œ≥‚Ä≤(t)‚à•dt, whence
area (Œ£) = h ‚Ñì(Œì) =
 b
a
f

Œ≥(t)

‚à•Œ≥‚Ä≤(t)‚à•dt =

Œ≥
f .
If f is not constant, instead, we can divide the interval I into K sub-intervals
Ik = [tk‚àí1, tk] of width Œîtk = tk ‚àítk‚àí1 suÔ¨Éciently small. Call Œìk = Œ≥(Ik) the
restriction to Ik, whose length is ‚Ñì(Œìk) =
3 tk
tk‚àí1 ‚à•Œ≥‚Ä≤(t)‚à•dt; then let Œ£k = {(x, y, z) ‚àà
R3 : (x, y) ‚ààŒìk, 0 ‚â§z ‚â§f(x, y)} be the part of Œ£ over Œìk (see again Fig. 9.1).
Given any t‚àó
k ‚ààIk, with P ‚àó
k = Œ≥(t‚àó
k) ‚ààŒìk, we will have
area(Œ£k) ‚âÉf(P ‚àó
k )‚Ñì(Œìk) =
 tk
tk‚àí1
f

Œ≥(t‚àó
k)

‚à•Œ≥‚Ä≤(t)‚à•dt .

9.1 Integrating along curves
369
 
 
 
 
 
 
 
 
G(f)
Œ£
Œì
dom f
Œìk
Œ£k
P ‚àó
k
(P ‚àó
k , f (P ‚àó
k ))
Figure 9.1. The geometrical meaning of integrating along a curve
Summing over k and letting the intervals‚Äô width shrink to zero yields precisely
formula (9.1).
Recalling DeÔ¨Ånition 9.1, we can observe that the arc length s = s(t) of (6.20)
satisÔ¨Åes
ds
dt = ‚à•Œ≥‚Ä≤(t)‚à•
which, in Leibniz‚Äôs notation, we may re-write as
ds = ‚à•Œ≥‚Ä≤(t)‚à•dt .
The diÔ¨Äerential ds is the ‚ÄòinÔ¨Ånitesimal‚Äô line element along the curve, corresponding
to an ‚ÄòinÔ¨Ånitesimal‚Äô increment dt of the parameter t. Such considerations justify
indicating the integral of (9.1) by

Œ≥
f ds ,
or

Œ≥
f dŒ≥
(9.2)
(in the latter case, the map s = s(t) is written as Œ≥ = Œ≥(t), not to be confused
with the vector notation of an arc Œ≥ = Œ≥(t)).
Examples 9.2
i) Let Œ≥ : [0, 1] ‚ÜíR2 be the regular arc Œ≥(t) = (t, t2) parametrising the parabola
y = x2 between O = (0, 0) and A = (1, 1). Since Œ≥‚Ä≤(t) = (1, 2t), we have
‚à•Œ≥‚Ä≤(t)‚à•=
‚àö
1 + 4t2. Suppose f : R√ó [0, +‚àû) ‚ÜíR is the map f(x, y) = 3x+ ‚àöy.
The composite f ‚ó¶Œ≥ is f

Œ≥(t)

= 3t +
‚àö
t2 = 4t, so

Œ≥
f =
 1
0
4t

1 + 4t2 dt ;

370
9 Integral calculus on curves and surfaces
this is computed by substituting r = 1 + 4t2,

Œ≥
f = 1
2
 5
1
‚àör dr = 1
2
2
3r3/25
1 = 1
3(5
‚àö
5 ‚àí1) .
ii) The regular arc Œ≥ : [0, 1] ‚ÜíR3, Œ≥(t) = ( 1
3t3,
‚àö
2
2 t2, t), gives
Œ≥‚Ä≤(t) = (t2,
‚àö
2t, 1)
whence
‚à•Œ≥‚Ä≤(t)‚à•=

t4 + 2t2 + 1 = (1 + t2) .
Take now f(x, y, z) = 3
‚àö
2xyz2; then

Œ≥
f =
 1
0
t7(1 + t2) dt =
1
8t8 + 1
10t101
0 = 9
40 .
iii) Parametrise the circle centred in (2, 1) with radius 2 by Œ≥ : [0, 2œÄ] ‚ÜíR2,
Œ≥(t) = (2 + 2 cos t, 1 + 2 sin t). Then
‚à•Œ≥‚Ä≤(t)‚à•=

4 sin2 t + 4 cos2 t = 2 ,
‚àÄt .
For the map f(x, y) = (x‚àí2)(y ‚àí1)+1 we have f

Œ≥(t)

= 4 sin t cost+1, hence

Œ≥
f = 2
 2œÄ
0
(4 sin t cos t + 1) dt = 2

‚àícos 2t + t
2œÄ
0
= 4œÄ .
Using the curve Œ≥‚àówith the same components of Œ≥ but t ranging in [0, 2kœÄ] (i.e.,
going around k times, instead of only once), we have

Œ≥‚àó
f = 2
 2kœÄ
0
(4 sin t cos t + 1) dt = 4kœÄ.
2
This last example explains that curvilinear integrals depend not only on the
trace of the curve, but also on the chosen parametrisation. Nonetheless, congruent
parametrisations give rise to equal integrals, as we now show.
Let f be deÔ¨Åned on the trace of a regular arc Œ≥ : [a, b] ‚ÜíRm so that f ‚ó¶Œ≥
is (piecewise) continuous and the integral along Œ≥ exists. Then f ‚ó¶Œ¥, too, where
Œ¥ is an arc congruent to Œ≥, will be (piecewise) continuous because composition of
a continuous map between real intervals and the (piecewise-)continuous function
f ‚ó¶Œ≥.
Proposition 9.3 Let Œ≥ : [a, b] ‚ÜíRm be a regular arc of trace Œì, and f a
map on Œì such that f ‚ó¶Œ≥ is (piecewise) continuous. Then

Œ¥
f =

Œ≥
f ,
for any curve Œ¥ congruent to Œ≥.

9.1 Integrating along curves
371
Proof.
Let Œ¥ = Œ≥ ‚ó¶œï, with œï : [c, d] ‚Üí[a, b], be any congruent arc to Œ≥, so
Œ¥‚Ä≤(œÑ) = Œ≥‚Ä≤
œï(œÑ)

œï‚Ä≤(œÑ). Then

Œ¥
f =
 d
c
f

Œ¥(œÑ)

‚à•Œ¥‚Ä≤(œÑ)‚à•dœÑ =
 d
c
f

Œ≥(œï(œÑ))

‚à•Œ≥‚Ä≤
œï(œÑ)

œï‚Ä≤(œÑ)‚à•dœÑ
=
 d
c
f

Œ≥(œï(œÑ))

‚à•Œ≥‚Ä≤
œï(œÑ)

‚à•|œï‚Ä≤(œÑ)| dœÑ .
Substituting t = œï(œÑ) gives dt = œï‚Ä≤(œÑ) dœÑ. Note that œï(c) = a, œï(d) = b if
œï‚Ä≤ > 0 (Œ¥ and Œ≥ are equivalent), or œï(c) = b, œï(d) = a if œï‚Ä≤ < 0 (Œ¥ and Œ≥
are anti-equivalent). In the Ô¨Årst case we obtain

Œ¥
f =
 b
a
f

Œ≥(t)

‚à•Œ≥‚Ä≤(t)‚à•dt =

Œ≥
f
whereas in the second case

Œ¥
f = ‚àí
 a
b
f

Œ≥(t)

‚à•Œ≥‚Ä≤(t)‚à•dt =
 b
a
f

Œ≥(t)

‚à•Œ≥‚Ä≤(t)‚à•dt =

Œ≥
f .
2
By the previous proposition the following result is straightforward.
Corollary 9.4 The curvilinear integral of a function does not change by tak-
ing opposite arcs.
Given an arbitrary point c in (a, b) and setting Œ≥1 = Œ≥|[a,c], Œ≥2 = Œ≥|[c,b], by
additivity we have

Œ≥
f =

Œ≥1
f +

Œ≥2
f .
(9.3)
This suggests how to extend the notion of integral to include piecewise-regular
arcs. More precisely, let Œ≥ : [a, b] ‚ÜíRm be a piecewise-regular arc and a = a0 <
a1 < . . . < an = b points in [a, b] such that the arcs Œ≥i = Œ≥|[ai‚àí1,ai], i = 1, . . . , n,
are regular. Take f, as above, deÔ¨Åned at least on Œì such that f ‚ó¶Œ≥ is (piecewise)
continuous on [a, b]. By deÔ¨Ånition, then, we set

Œ≥
f =
n

i=1

Œ≥i
f .
(9.4)
Remark 9.5 Computing integrals along curves is made easier by Proposition 9.3.
In fact,

Œ≥
f =
n

i=1

Œ¥i
f ,
(9.5)
where each Œ¥i is an arc congruent to Œ≥i, i = 1, . . . , n, chosen in order to simplify
the corresponding integral on the right.
2

372
9 Integral calculus on curves and surfaces
Example 9.6
Compute
3
Œ≥ x2, where Œ≥ : [0, 4] ‚ÜíR2 is the following parametrisation of the
square [0, 1] √ó [0, 1]
Œ≥(t) =
‚éß
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é©
Œ≥1(t) = (t, 0)
if 0 ‚â§t < 1 ,
Œ≥2(t) = (1, t ‚àí1)
if 1 ‚â§t < 2 ,
Œ≥3(t) = (3 ‚àít, 1)
if 2 ‚â§t < 3 ,
Œ≥4(t) = (0, 4 ‚àít)
if 3 ‚â§t ‚â§4
(see Fig. 9.2, left). Consider the parametrisations
Œ¥1(t) = Œ≥1(t)
0 ‚â§t ‚â§1 ,
Œ¥1 = Œ≥1 ,
Œ¥2(t) = (1, t)
0 ‚â§t ‚â§1 ,
Œ¥2 ‚àºŒ≥2 ,
Œ¥3(t) = (t, 1)
0 ‚â§t ‚â§1 ,
Œ¥3 ‚àº‚àíŒ≥3 ,
Œ¥4(t) = (0, t)
0 ‚â§t ‚â§1 ,
Œ¥4 ‚àº‚àíŒ≥4
(see Fig. 9.2, right). Then

Œ≥
x2 =
 1
0
t2 dt +
 1
0
1 dt +
 1
0
t2 dt +
 1
0
0 dt = 5
3 .
2
Curvilinear integrals bear the same properties of linearity, positivity, monoton-
icity and so on, seen for ordinary integrals.
Remark 9.7 Let Œ≥ : [a, b] ‚ÜíR be a regular arc. Its length ‚Ñì(Œ≥) can be written as
‚Ñì(Œ≥) =

Œ≥
1 .
(9.6)
The arc length s = s(t), see (6.20) with t0 = a, satisÔ¨Åes s(a) = 0 and s(b) =
3 b
a ‚à•Œ≥‚Ä≤(œÑ)‚à•dœÑ = ‚Ñì(Œ≥). We want to use it to integrate a map f by means of the
O
1
Œ≥1
Œ≥2
Œ≥3
Œ≥4
O
1
Œ¥1
Œ¥2
Œ¥3
Œ¥4
Figure 9.2. Parametrisations of the unit square relative to Example 9.6

9.1 Integrating along curves
373
parametrisation 1Œ≥(s) = Œ≥(t(s)), equivalent to Œ≥, already seen on p. 224. Then

Œ≥
f =

Œ≥
f =
 ‚Ñì(Œ≥)
0
f
1Œ≥(s)

ds ,
useful to simplify integrals if we know the arc length‚Äôs analytical expression.
2
In view of subsequent applications, it makes sense to consider integrals along
a simple and regular arc Œì, thought of as a subset of Rm, see DeÔ¨Ånition 6.28.
We already know that all parametrisations of Œì by simple, regular arcs are con-
gruent (Proposition 6.27), and hence give rise to the same integral of a (piecewise-)
continuous map f along Œì (Proposition 9.3). For this reason one calls integral of
f along Œì the number

Œì
f =

Œ≥
f ,
(9.7)
where Œ≥ is any regular and simple parametrisation of Œì. Equivalent symbols are

Œì
f ds ,

Œì
f dŒ≥ ,

Œì
f d‚Ñì.
The generalisation to piecewise-regular, simple arcs should be clear. In case Œì is
closed, the integral might be denoted using the symbols
4
Œì
f ,
4
Œì
f ds ,
4
Œì
f dŒ≥ ,
4
Œì
f d‚Ñì.
Remark 9.8 The integral of a (piecewise-)continuous f can be deÔ¨Åned along a
regular curve Œ≥ : I ‚ÜíRm, where I is a bounded, but not closed, interval. For this,
t ‚Üíf

Œ≥(t)

‚à•Œ≥‚Ä≤(t)‚à•must be integrable (improperly as well) on I, with integral

Œ≥
f =

I
f

Œ≥(t)

‚à•Œ≥‚Ä≤(t)‚à•dt .
For example, parametrise the unit semi-circle centred at the origin and lying on
y ‚â•0 by Œ≥ : [‚àí1, 1] ‚ÜíR2, Œ≥(t) = (t,
‚àö
1 ‚àít2); the curve is regular only on (‚àí1, 1),
for Œ≥‚Ä≤(t) =

1, ‚àí
t
‚àö
1‚àít2

. If f(x, y) = 1,

Œ≥
f =
 1
‚àí1
1
‚àö
1 ‚àít2 dt =

arcsint
1
‚àí1 = œÄ ,
the right-hand-side integral being improper.
2

374
9 Integral calculus on curves and surfaces
9.1.1 Centre of mass and moments of a curve
As with thin plates and solid bodies, see Sect. 8.5, we can use curvilinear integ-
rals to deÔ¨Åne certain physical quantities related to a thin wire resting along a
(piecewise-)regular, simple arc Œì ‚äÇR3.
Let Œº = Œº(P) be the wire‚Äôs linear density (mass per unit of length) at a generic
P = x = (x, y, z) ‚ààŒì. The total mass will be
m =

Œì
Œº ,
and its centre of mass G = xG = (xG, yG, zG) is
xG = 1
m

Œì
xŒº ,
or
xG = 1
m

Œì
xŒº ,
yG = 1
m

Œì
yŒº ,
zG = 1
m

Œì
zŒº .
The moment (of inertia) about a line or a point is
I =

Œì
d2Œº ,
where d = d(P) is the distance of P ‚ààŒì from the line or point considered. The
axial moments
Ix =

Œì
(y2 + z2)Œº ,
Iy =

Œì
(x2 + z2)Œº ,
Iz =

Œì
(x2 + y2)Œº ,
are special cases of the above, and their sum I0 = Ix +Iy +Iz represents the wire‚Äôs
moment about the origin.
Example 9.9
Let us determine the moment about the origin of the arc Œì
x2 + y2 + z2 = 1 ,
y = z ,
y ‚â•0 ,
joining A = (1, 0, 0) to B = (0,
‚àö
2
2 ,
‚àö
2
2 ). We can parametrise the arc by Œ≥(t) =
(
‚àö
1 ‚àí2t2, t, t), 0 ‚â§t ‚â§
‚àö
2
2 , so that
‚à•Œ≥‚Ä≤(t)‚à•=

4t2
1 ‚àí2t2 + 1 + 1 =
‚àö
2
‚àö
1 ‚àí2t2 ,
and
I0 =
 ‚àö
2/2
0
(1 ‚àí2t2 + t2 + t2)
‚àö
2
‚àö
1 ‚àí2t2 dt =

arcsin
‚àö
2t
‚àö
2/2
0
= œÄ
2 .
2

9.2 Path integrals
375
9.2 Path integrals
Integrating vector Ô¨Åelds along curves gives rise to the notion of path integral,
presented below.
Let I = [a, b] and Œ≥ : I ‚ÜíRm be a regular arc with trace Œì = Œ≥(I). Take a
vector Ô¨Åeld f in Rm, deÔ¨Åned on Œì at least. The composite map f ‚ó¶Œ≥ : t ‚Üíf

Œ≥(t)

from I to Rm is thus deÔ¨Åned. We shall assume the latter (piecewise) continuous,
so that all fi

Œ≥(t)

are (piecewise) continuous from I to R. For any t ‚ààI, recall
that
œÑ(t) = œÑŒ≥(t) =
Œ≥‚Ä≤(t)
‚à•Œ≥‚Ä≤(t)‚à•
is the unit tangent vector at P(t) = Œ≥(t). The map fœÑ = f ¬∑ œÑ,
fœÑ(t) =

f ¬∑ œÑ

(t) = f

Œ≥(t)

¬∑ œÑ(t) ,
is the component of f along the tangent direction to Œ≥ at P(t).
DeÔ¨Ånition 9.10 The path integral of f along Œ≥ is the integral along Œ≥
of the map fœÑ:

Œ≥
f ¬∑ œÑ =

Œ≥
fœÑ .
Another name for it is line integral of f along Œ≥.
By deÔ¨Ånition of œÑ we have

Œ≥
f ¬∑ œÑ =
 b
a
f

Œ≥(t)

¬∑ œÑ(t) ‚à•Œ≥‚Ä≤(t)‚à•dt =
 b
a
f

Œ≥(t)

¬∑ Œ≥‚Ä≤(t) dt .
Thus, the integral of f along the path Œ≥ can be computed using

Œ≥
f ¬∑ œÑ =
 b
a
f

Œ≥(t)

¬∑ Œ≥‚Ä≤(t) dt .
(9.8)
Writing dŒ≥
dt = Œ≥‚Ä≤(t) as Leibniz does, or dŒ≥ = Œ≥‚Ä≤(t) dt, we may also use the notation

Œ≥
f ¬∑ dŒ≥ .
There is a diÔ¨Äerence between the symbol dŒ≥ (a vector) and the diÔ¨Äerential dŒ≥
of (9.2) (a scalar).
The physical meaning of path integrals is paramount. If f models a Ô¨Åeld of
forces applied to the trace of the curve, the path integral is the work (the work
integral) of the force during the motion along Œ≥. The counterpart to Proposition 9.3
is the following.

376
9 Integral calculus on curves and surfaces
Proposition 9.11 Let Œ≥ : [a, b] ‚ÜíRm be a regular arc of trace Œì, f a vector
Ô¨Åeld on Œì such that f ‚ó¶Œ≥ is (piecewise) continuous. Then

Œ¥
f ¬∑ œÑŒ¥ =

Œ≥
f ¬∑ œÑŒ≥ ,
for any arc Œ¥ equivalent to Œ≥,
and

Œ¥
f ¬∑ œÑŒ¥ = ‚àí

Œ≥
f ¬∑ œÑŒ≥ ,
for any arc Œ¥ anti-equivalent to Œ≥.
Proof.
This is a consequence of Proposition 9.3, because unit tangent vectors
satisfy œÑŒ¥ = œÑŒ≥ when Œ¥ ‚àºŒ≥, and œÑŒ¥ = ‚àíœÑŒ≥ when Œ¥ ‚àº‚àíŒ≥.
2
Corollary 9.12 Swapping an arc with its opposite changes the sign of the
path integral:

‚àíŒ≥
f ¬∑ œÑ(‚àíŒ≥) = ‚àí

Œ≥
f ¬∑ œÑŒ≥ .
In Physics it means that the work done by a force changes sign if one reverses the
orientation of the arc; once that is Ô¨Åxed, the work depends only on the path and
not on the way one moves along it.
Here is another recurring deÔ¨Ånition in the applications.
DeÔ¨Ånition 9.13 If Œ≥ is a regular, closed arc, the path integral of f is said
circulation of f along Œ≥ and denoted
4
Œ≥
f ¬∑ œÑ .
Examples 9.14
i) The vector Ô¨Åeld f : R3 ‚ÜíR3, f(x, y, z) = (ex, x+y, y+z) along Œ≥ : [0, 1] ‚ÜíR3,
Œ≥(t) = (t, t2, t3), is given by
f

Œ≥(t)

= (et, t + t2, t2 + t3)
with
Œ≥‚Ä≤(t) = (1, 2t, 3t2) .
Hence, the path integral of f on Œ≥ is

Œ≥
f ¬∑ œÑ =
 1
0
(et, t + t2, t2 + t3) ¬∑ (1, 2t, 3t2) dt
=
 1
0

et + 2(t2 + t3) + 3(t4 + t5)

dt = e + 19
15 .

9.3 Integrals over surfaces
377
ii) Take the vector Ô¨Åeld f : R2 ‚ÜíR2 given by f(x, y) = (y, x). Parametrise the
ellipse x2
9 + y2
4 = 1 by Œ≥ : [0, 2œÄ] ‚ÜíR2, Œ≥(t) = (3 cos t, 2 sin t). Then f

Œ≥(t)

=
(2 sin t, 3 cost) and Œ≥‚Ä≤(t) = (‚àí3 sin t, 2 cos t). The integral of f along the ellipse
is zero:
4
Œ≥
f ¬∑ œÑ =
 2œÄ
0
(2 sin t, 3 cost) ¬∑ (‚àí3 sin t, 2 cost) dt = 6
 2œÄ
0
(‚àísin2 t + cos2 t) dt
= 6
 2œÄ
0
(2 cos2 t ‚àí1) dt = 12
 2œÄ
0
cos2 t dt ‚àí12œÄ = 0 ,
where we have used  2œÄ
0
cos2 t dt =
1
2t + 1
4 sin 2t
2œÄ
0
= œÄ .
2
Path integrals exist on piecewise-regular arcs, too: it is enough to deÔ¨Åne, as in
formula (9.4),

Œ≥
f ¬∑ œÑ =
n

i=1

Œ≥i
f ¬∑ œÑŒ≥i ,
(9.9)
where Œ≥i are regular arcs constituting Œ≥.
At last, if we think geometrically (see DeÔ¨Ånition 6.28) and take a piecewise-
regular simple arc Œì ‚äÇRm, the path integral along Œì can be deÔ¨Åned properly only
after one orientation on Œì has been chosen, and the orientation depends on the
tangent vector œÑ. Then we can deÔ¨Åne the path integral of f along Œì by

Œì
f ¬∑ œÑ =

Œ≥
f ¬∑ œÑŒ≥ ,
(9.10)
where Œ≥ is any simple, (piecewise-)regular parametrisation of Œì with the chosen
orientation. Clearly, reversing the orientation has the eÔ¨Äect of changing the integ-
ral‚Äôs sign. The circulation of f along a piecewise-regular Jordan arc (closed and
simple) will be indicated by
4
Œì
f ¬∑ œÑ .
A diÔ¨Äerent notation for the path integral, based on the language of diÔ¨Äerential
forms, is provided in Appendix A.2.3, p. 529.
9.3 Integrals over surfaces
In perfect analogy to curves, the integral on a surface of a map in three variables is a
natural way to extend double integrals over Ô¨Çat regions. This section is dedicated

378
9 Integral calculus on curves and surfaces
to integrating over surfaces. To review surfaces, see Sect. 4.7, whilst for their
diÔ¨Äerential calculus see Sect. 6.7.
Let R be a compact, measurable region in R2, œÉ : R ‚ÜíR3 a compact regular
surface with trace Œ£. The normal vector ŒΩ = ŒΩ(u, v) at P = œÉ(u, v) was deÔ¨Åned
in (6.48). Take a map f : dom f ‚äÜR3 ‚ÜíR deÔ¨Åned on Œ£ at least, and assume
f ‚ó¶œÉ is generically continuous on R.
DeÔ¨Ånition 9.15 The integral of f over the surface œÉ is the number

œÉ
f =

R
f

œÉ(u, v)

‚à•ŒΩ(u, v)‚à•du dv .
(9.11)
As the surface is regular, the function (u, v) ‚Üí‚à•ŒΩ(u, v)‚à•is continuous on R, so
the right-hand-side integrand is generically continuous, hence integrable.
The deÔ¨Ånition is inspired by the following considerations. Suppose R is a rect-
angle with sides parallel to the (u, v)-axes, and let us divide it into rectangles
Rhk = [uh, uh + Œîu] √ó [vk, vk + Œîv] with lengths Œîu, Œîv, such that the interiors
‚ó¶
Rhk are pairwise disjoint (as in Fig. 9.3, left). The image of Rhk is the subset
Œ£hk of Œ£ bounded by the coordinate lines through œÉ(uh, vk), œÉ(uh + Œîu, vk),
œÉ(uh, vk + Œîv) and œÉ(uh + Œîu, vk + Œîv) (Fig. 9.3, right). If Œîu and Œîv are
small enough, the surface is well approximated by the parallelogram Œ†hk lying on
the surface‚Äôs tangent plane at œÉ(uh, vk), which is spanned by the tangent vectors
‚àÇœÉ
‚àÇu (uh, vk)Œîu and ‚àÇœÉ
‚àÇv (uh, vk)Œîv (Fig. 9.4). The area ŒîœÉ of Œ†hk is
ŒîœÉ =
$$$$
‚àÇœÉ
‚àÇu (uh, vk) ‚àß‚àÇœÉ
‚àÇv (uh, vk)
$$$$ ŒîuŒîv = ‚à•ŒΩ(uh, vk)‚à•ŒîuŒîv ,
a number that approximates the area of Œ£hk. Therefore, we may consider the term
vk ‚àí
vk + Œîv ‚àí
uh
‚àí
uh + Œîu
‚àí
Rhk
u
v
 
 
 
 
 
 
 
 
u
v
z
Rhk
Œ£hk
Œ£
  
 
 
 
 
 
 
  
  
 
 
 
Figure 9.3. Partitions of the domain (left) and of the trace (right) of a compact surface

9.3 Integrals over surfaces
379
 
 
 
 
 
 
 
 
Œ£hk
Œ†hk
Phk
‚àÇœÉ
‚àÇu (Phk)Œîu
‚àÇœÉ
‚àÇv (Phk)Œîv
 
 
  
 
 
 
 
 
 
 
 
 
 
Figure 9.4. Element Œ£hk and corresponding tangent plane Œ†hk
dœÉ = ‚à•ŒΩ(u, v)‚à•du dv
in the right-hand side of (9.11) as an ‚ÄòinÔ¨Ånitesimal‚Äô surface element on Œ£. In
particular, if the surface is simple, we shall see that the area of Œ£ is precisely

œÉ
1 =

R
‚à•ŒΩ(u, v)‚à•du dv .
Example 9.16
Let us suppose the regular compact surface œÉ : R ‚ÜíR3 is given by œÉ(u, v) =
ui + vj + œï(u, v)k. Recalling (6.49), we have
‚à•ŒΩ(u, v)‚à•=
 
1 +
	‚àÇœï
‚àÇu

2
+
	‚àÇœï
‚àÇv

2
,
and so the integral of f = f(x, y, z) on œÉ is

œÉ
f =

R
f

u, v,œï (u, v)

 
1 +
	‚àÇœï
‚àÇu

2
+
	‚àÇœï
‚àÇv

2
du dv .
For example, if œÉ is deÔ¨Åned by œï(u, v) = uv over the unit square R = [0, 1]2,
and f(x, y, z) = z/

1 + x2 + y2, then

œÉ
f =
 1
0
 1
0
uv
‚àö
1 + u2 + v2

1 + v2 + u2 du dv
=
 1
0
 1
0
uv du dv = 1
4 .
2
Surface integrals are invariant under congruent parametrisations, as stated by
the next proposition.

380
9 Integral calculus on curves and surfaces
Proposition 9.17 Let œÉ : R ‚ÜíR3 be a compact surface with trace Œ£ and
f a map on Œ£ such that f ‚ó¶œÉ is generically continuous on R. Then for any
parametrisation 1œÉ : 1R ‚ÜíŒ£ congruent to œÉ,

œÉ
f =

œÉ
f .
Proof.
Call Œ¶ : 1R ‚ÜíR the change of variables such that 1œÉ = œÉ ‚ó¶Œ¶. By (6.50)
and Theorem 8.24,

œÉ
f =


R
f
1œÉ(1u, 1v)

‚à•1ŒΩ(1u, 1v)‚à•d1u d1v
=


R
f

œÉ(Œ¶(1u, 1v))

‚à•det JŒ¶(1u, 1v)ŒΩ

Œ¶(1u, 1v)

‚à•d1u d1v
=


R
f

œÉ(Œ¶(1u, 1v))

‚à•ŒΩ

Œ¶(1u, 1v)

‚à•| det JŒ¶(1u, 1v)| d1u d1v
=

R
f

œÉ(u, v)

‚à•ŒΩ(u, v)‚à•du dv =

œÉ
f .
2
The above result allows us to deÔ¨Åne integrals over regular, simple, compact
surfaces Œ£ ‚äÇR2 thought of as geometrical surfaces (see DeÔ¨Ånition 6.34). To be
precise, one calls integral of f on the surface Œ£ the quantity

Œ£
f =

œÉ
f ,
(9.12)
where œÉ is any regular, simple parametrisation of Œ£. Since all such œÉ are congruent,
the deÔ¨Ånition makes sense. Alternatively, one may also write

Œ£
f(œÉ) dœÉ
or

Œ£
f dœÉ .
Integrals can be deÔ¨Åned over piecewise-regular compact surfaces Œ£, meaning
the union of n regular, simple compact surfaces Œ£1, . . . , Œ£n as of DeÔ¨Ånition 6.43.
In such a case, one declares

Œ£
f =
n

i=1

Œ£i
f .
Remark 9.18 The deÔ¨Ånition extends to cover non-compact surfaces, as we did
for curvilinear integrals (Remark 9.8), with the proviso that the right-hand-side
map of (9.11) be integrable on R.

9.3 Integrals over surfaces
381
For instance, the unit hemisphere Œ£ deÔ¨Åned by
x2 + y2 + z2 = 1 ,
z ‚â•0 ,
is not compact in Cartesian coordinates, for
œÉ(u, v) =

u, v,

1 ‚àíu2 ‚àív2
cannot be prolonged diÔ¨Äerentiably to an arbitrary open set containing the unit
disc D. Nonetheless, we may still use (9.9) to Ô¨Ånd the surface‚Äôs area, because the
map
‚à•ŒΩ(u, v)‚à•=
1
‚àö
1 ‚àíu2 ‚àív2
is integrable on D. In fact,

Œ£
1 =

D
‚à•ŒΩ(u, v)‚à•du dv =
 2œÄ
0
 1
0
r
‚àö
1 ‚àír2 dr dŒ∏ = 2œÄ .
2
9.3.1 Area of a surface
Via surface integrals we can deÔ¨Åne the area of a compact surface Œ£ (piecewise
regular and simple) thoroughly, by
area(Œ£) =

Œ£
1 .
Example 9.19
i) The example of Remark 9.18 adapts to show that the area of the hemisphere
Œ£ of radius r is
area(Œ£) =

Œ£
1 = 2œÄr2 ,
as elementary geometry tells us.
ii) Let us compute the lateral surface Œ£ of a cylinder of radius r and height L.
Supposing the cylinder‚Äôs axis is the segment [0, L] along the z-axis, the surface Œ£
is parametrised by œÉ(u, v) = r cos u i+r sin u j +v k, (u, v) ‚ààR = [0, 2œÄ]√ó[0, L].
Easily then,
ŒΩ(u, v) = r cos u i + r sin u j + 0 k ,
whence ‚à•ŒΩ(u, v)‚à•= r. In conclusion,
area(Œ£) =
 2œÄ
0
 L
0
r du dv = 2œÄrL ,
another old acquaintance of elementary geometry‚Äôs fame.
2

382
9 Integral calculus on curves and surfaces
It is no coincidence that the area is found by integrating along a meridian arc.
The cylinder is in fact a surface of revolution (Example 4.37 iii)):
Proposition 9.20 Let Œ£ deÔ¨Åne the surface of revolution generated by re-
volving the arc Œì, on the plane xz, around the z-axis. Then
area(Œ£) = 2œÄ

Œì
x .
Proof.
Retaining the notation of Example 4.37 iii) we easily obtain
ŒΩ(u, v) = ‚àíŒ≥1(u)Œ≥‚Ä≤
3(u) cos v i + Œ≥1(u)Œ≥‚Ä≤
3(u) sin v j
+

Œ≥1(u)Œ≥‚Ä≤
1(u) cos2 v + Œ≥1(u)Œ≥‚Ä≤
1(u) sin2 v

k ,
whence
‚à•ŒΩ(u, v)‚à•=
#
Œ≥2
1(u)

(Œ≥‚Ä≤
1(u))2 + (Œ≥‚Ä≤
3(u))2
= Œ≥1(u)‚à•Œ≥‚Ä≤(u)‚à•.
Above we assumed x = Œ≥1(u) non-negative along the curve. Therefore
area(Œ£) =

Œ£
1 =
 2œÄ
0

I
Œ≥1(u)‚à•Œ≥‚Ä≤(u)‚à•dudv
= 2œÄ

I
Œ≥1(u)‚à•Œ≥‚Ä≤(u)‚à•dudv = 2œÄ

Œì
x .
2
As 2œÄx is the length of the circle described by P = (x, 0, z) ‚ààŒì during the
revolution around the axis, and
xG =
3
Œì x
3
Œì 1 =
3
Œì x
‚Ñì(Œì)
is the coordinate of the centre of mass G of Œì, corresponding to unit density along
the curve, we can state the formula as
area(Œ£) = 2œÄ xG ‚Ñì(Œì) .
This is known as Guldin‚Äôs Theorem.
Theorem 9.21 The area of a surface of revolution Œ£ is the product of the
length of the meridian section times the length of the circle described by the
arc‚Äôs centre of mass.

9.4 Flux integrals
383
9.3.2 Centre of mass and moments of a surface
Imagine a thin shell covering a (piecewise-)regular, simple, compact surface Œ£ ‚äÇ
R3. Denoting by Œº = Œº(P) the shell‚Äôs density of mass (mass per unit of area) at
P ‚ààŒ£, we can compute the total mass
m =

Œ£
Œº
and the centre of mass G = (xG, yG, zG)
xG = 1
m

Œ£
xŒº ,
so
xG = 1
m

Œ£
xŒº ,
yG = 1
m

Œ£
yŒº ,
zG = 1
m

Œ£
zŒº .
The moment (of inertia) about an axis or a point is
I =

Œ£
d2Œº ,
where d = d(P) is the distance of the generic P ‚ààŒ£ from the line or point given.
The moments about the coordinate axes
Ix =

Œ£
(y2 + z2)Œº ,
Iy =

Œ£
(x2 + z2)Œº ,
Iz =

Œ£
(x2 + y2)Œº ,
are special cases; their sum I0 = Ix + Iy + Iz represents the moment about the
origin.
9.4 Flux integrals
After learning how to integrate scalar Ô¨Åelds on surfaces, we now turn to vector-
valued maps and deÔ¨Åne the fundamental notion of Ô¨Çux integral, which will occupy
this section.
Let f be a vector Ô¨Åeld on R3 that is deÔ¨Åned (at least) on the trace Œ£ of a
regular, compact surface œÉ : R ‚ÜíŒ£, with R compact and measurable in R2. We
assume the composite f ‚ó¶œÉ is generically continuous on R. If n = n(u, v) is the
unit normal to Œ£, one calls normal component of f the component fn = f ¬∑ n
along n.

384
9 Integral calculus on curves and surfaces
DeÔ¨Ånition 9.22 The surface integral of f on œÉ is the integral on the
surface œÉ of the map fn:

œÉ
f ¬∑ n =

œÉ
fn .
Because of DeÔ¨Ånition 6.35 we can compute surface integrals by

œÉ
f ¬∑ n =

R
f

œÉ(u, v)

¬∑ ŒΩ(u, v) du dv .
(9.13)
As already seen for path integrals, congruent parametrisations in surface integrals
possibly entail a sign ambiguity.
Proposition 9.23 Let œÉ : R ‚ÜíR3 be a regular compact surface with trace
Œ£, f a vector Ô¨Åeld on Œ£ such that f ‚ó¶œÉ is generically continuous. Then

œÉ
f ¬∑ 1n =

œÉ
f ¬∑ n ,
for any compact surface 1œÉ equivalent to œÉ,
and

œÉ
f ¬∑ 1n = ‚àí

œÉ
f ¬∑ n ,
for any compact surface 1œÉ anti-equivalent to œÉ .
Proof.
The proof descends from Proposition 9.17 by observing that unit normals
are equal, 1n = n, if 1œÉ is equivalent to œÉ, and opposite, 1n = ‚àín, if 1œÉ is
anti-equivalent to œÉ .
2
The proposition allows us to deÔ¨Åne the surface integral of a vector Ô¨Åeld f
over a (piecewise-)regular, simple, compact surface Œ£ seen as embedded in R3. In
the light of Sect. 6.7.2, it is though necessary to consider orientable surfaces only
(DeÔ¨Ånition 6.38).
Let us thus assume that Œ£ is orientable, and that we have Ô¨Åxed an orientation
on it, corresponding to one of the unit normals, henceforth denoted n. Now we
are in the position to deÔ¨Åne the Ô¨Çux integral of f on Œ£ as

Œ£
f ¬∑ n =

œÉ
f ¬∑ n ,
(9.14)
where œÉ is any simple and (piecewise-)regular parametrisation of Œ£ inducing
the chosen orientation. This integral is often called simply Ô¨Çux of f across, or
through, Œ£. The terminology stems from Physics; suppose the surface is immersed
in a Ô¨Çuid of density Œº = Œº(x), and v = v(x) is the velocity of the point-particle

9.5 The Theorems of Gauss, Green, and Stokes
385
at P = x. Set f = Œºv and denote by ŒîŒ£ the element of area ŒîœÉ and normal n.
Then (f ¬∑ n) ŒîœÉ is the volume rate of Ô¨Çuid Ô¨Çow through ŒîŒ£ per unit of time, i.e.,
the discharge. Summing, and passing to the limit, the Ô¨Çux integral of f across Œ£
is the diÔ¨Äerence between the overall outÔ¨Çow and inÔ¨Çow through the surface Œ£.
When the surface Œ£ is bounded and encloses an open domain Œ©, one speaks
about outgoing Ô¨Çux or ingoing Ô¨Çux according to whether the normal n leaves
Œ© or enters Œ© respectively.
Example 9.24
Let us determine the outgoing Ô¨Çux of f(x) = yi ‚àíxj + zk through the sphere
centred in the origin and of radius r. We opt for spherical coordinates and para-
metrise by œÉ : [0, œÄ] √ó [0, 2œÄ] ‚ÜíR3, œÉ(u, v) = r sin u cosv i + r sin u sin v j +
r cos u k (see Example 4.37 iv)). The outgoing normal is
ŒΩ(x) = r sin u x = r sin u(xi + yj + zk) ,
see Example 6.36 ii). Therefore (f ¬∑ ŒΩ)(x) = r sin uz2 = r3 sin u cos2 u, and
recalling (9.13), we have

Œ£
f ¬∑ n =
 2œÄ
0
 œÄ
0
r3 sin u cos2 u dudv = 4
3œÄr3 .
2
For the Ô¨Çux integral, too, we may use an alternative notation based on the
language of diÔ¨Äerential forms; see Appendix A.2.3, p. 529.
9.5 The Theorems of Gauss, Green, and Stokes
The three theorems of the title should be considered multi-dimensional versions
of the formula of integration by parts. Each one of them allows to transform the
integral of an expression involving the diÔ¨Äerential operators of Sect. 6.3.1 on a two-
or three-dimensional domain, or a surface, into the integral over the boundary of
an expression without derivatives.
The importance of such results is paramount, both from the theoretical point
of view and in relationship to applications. They typically manifest themselves,
for example, when one formulates a law of Physics (e.g., the conservation of mass
or energy) in mathematical language (a PDE); but they may also play a role in
determining the conditions that guarantee the solvability of said equations (exist-
ence and uniqueness of solutions); at last, several numerical techniques for solving
equations (such as the Ô¨Ånite-volume method and the Ô¨Ånite-element method) are
implemented by using one of the theorems.
At a more immediate level, these results enable to simplify an integral, and
crop up when examining special vector Ô¨Åelds, like conservatives Ô¨Åelds.
We start by discussing a class of open sets and surfaces, that we will call
admissible, for which the theorems hold. A Ô¨Årst, basic study of Sects. 9.5.2 - 9.5.4
does not require such level of detail.

386
9 Integral calculus on curves and surfaces
 
 
 
 
n
t
P
Œì
Figure 9.5. Unit tangent to a portion of the Jordan arc Œì, and unit normal rotated
by œÄ/2
9.5.1 Open sets, admissible surfaces and boundaries
Open sets in the plane. Let Œì ‚äÇR2 be a piecewise-regular Jordan arc with a
given orientation. The unit tangent vector t = t1i+t2j exists at all points P of Œì,
with the exception of a Ô¨Ånite number. At P the normal direction v to Œì (orthogonal
to t) is thus well deÔ¨Åned. In particular, the unit vector n = n1i+n2j = t2i‚àít1j to
Œì at P is obtained rotating t clockwise by œÄ/2 (Fig. 9.5); otherwise said, identifying
n and t with n + 0k and t + 0k in R3 makes the triple (n, t, k) right-handed, for
(n‚àßt)¬∑k = 1. (Notice that the unit vector n might not coincide with the principal
normal of (6.22), whose orientation varies with the curve‚Äôs convexity; at any rate
the two vectors clearly diÔ¨Äer by a sign, at most.) Furthermore, Œì separates the
region inside Œì from the external region, by virtue of Jordan‚Äôs Curve Theorem 4.33.
DeÔ¨Ånition 9.25 We call a bounded open set Œ© ‚äÇR2 G-admissible if the
following hold:
i) the boundary ‚àÇŒ© is a Ô¨Ånite union of piecewise-regular, pairwise-disjoint
Jordan arcs Œì1, . . . , ŒìK;
ii) Œ© is entirely contained either inside, or outside, each Œìk.
Each point P ‚àà‚àÇŒ© will belong to one, and one only, Jordan arc Œìk, so there
will be (save for a Ô¨Ånite number of points) a unit normal n to Œìk at P, that
is chosen to point outwards Œ© (precisely, all points Q = P + Œµn, with Œµ > 0
suÔ¨Éciently small, lie outside Œ©). We will say n is the outgoing unit normal to
‚àÇŒ©, or for short, the outgoing normal of ‚àÇŒ©.
The choice of the outward-pointing orientation induces an orientation on the
boundary ‚àÇŒ©. In fact, on every arc Œìk we will Ô¨Åx the orientation so that, if t denotes
the tangent vector, the frame (n, t, k) is oriented positively. Intuitively, one could
say that a three-dimensional observer standing as k and walking along
Œìk will see Œ© on his left (Fig. 9.6). We shall call this the positive orientation
of ‚àÇŒ© (and the opposite one negative).

9.5 The Theorems of Gauss, Green, and Stokes
387
n
n
n
t
t
t
Œ©
Figure 9.6. A G-admissible open set in the plane
Open sets in space. The whole discussion on two-dimensional G-admissible open
sets extends easily to space. For this, we recall that every closed and orientable
surface divides space in a region enclosed by the surface and one outside it (The-
orem 6.42).
DeÔ¨Ånition 9.26 We call a bounded open set Œ© ‚äÇR3 G-admissible if:
i) its boundary ‚àÇŒ© is the union of a Ô¨Ånite number of pairwise-disjoint sur-
faces Œ£1, . . . , Œ£K;
ii) each Œ£k is piecewise regular, simple, orientable and closed;
iii) Œ© lies entirely inside or outside every surface Œ£k.
For a given G-admissible open set there is a well-deÔ¨Åned outgoing normal n
to ‚àÇŒ©, which will coincide with the normal to the surface Œ£k oriented from the
inside towards the outside of Œ© (Fig. 9.7).
Here are some examples of G-admissible open sets.
Examples 9.27
i) The inside of the elementary solids (e.g., parallelepipeds, polyhedra, cylinders,
cones, spheres), and of any regular deformation of these, are G-admissible.
ii) We say an open bounded set Œ© ‚äÇR3 is regular and normal for z in case
Œ© is normal for z as in DeÔ¨Ånition 8.27,
Œ© =

(x, y, z) ‚ààR3 : (x, y) ‚ààD,Œ± (x, y) < z < Œ≤(x, y)

,
where D is open in R2 with boundary ‚àÇD a piecewise-regular Jordan arc, and
Œ±,Œ≤ are C1 maps on D. Such an open set is G-admissible.

388
9 Integral calculus on curves and surfaces
 
 
 
 
 
 
 
 
Œ£
Œ£
Œ£
Œ£
Œ£
n
n
n
n
Figure 9.7. A G-admissible open set in R3 (with K = 1)
The boundary of Œ© consists of a single surface Œ£1, piecewise regular, normal,
orientable and closed; in fact, we can decompose Œ£1 = Œ£Œ≤ ‚à™Œ£Œ± ‚à™Œ£‚Ñì, where
Œ£Œ≤ =

x, y,Œ≤ (x, y)

‚ààR3 : (x, y) ‚ààD

,
Œ£Œ± =

x, y,Œ± (x, y)

‚ààR3 : (x, y) ‚ààD

,
Œ£‚Ñì=

(x, y, z) ‚ààR3 : (x, y) ‚àà‚àÇD,Œ± (x, y) ‚â§z ‚â§Œ≤(x, y)

.
The outgoing unit normal nŒ≤ to Œ£Œ≤ is obtained by normalising
ŒΩŒ≤(x, y) = ‚àí‚àÇŒ≤
‚àÇx(x, y) i ‚àí‚àÇŒ≤
‚àÇy (x, y) j + k ,
Œ£Œ≤ being a local graph (see Example 6.36, i)).
Similarly, the outgoing unit normal nŒ± to Œ£Œ± is the unit vector corresponding
to
ŒΩŒ±(x, y) = ‚àÇŒ±
‚àÇx (x, y) i + ‚àÇŒ±
‚àÇy (x, y) j ‚àík .
The outgoing normal n‚Ñìto Œ£‚Ñìis
n = n‚àÇD + 0k ,
where n‚àÇD is the outgoing unit normal (in two dimensions) of ‚àÇD.
Regular and normal sets for x or y are deÔ¨Åned in the same way.
iii) Let us see how to generalise the above situation. The open sets Œ©1, . . . , Œ©K
form a partition of an open set Œ© if the Œ©k are pairwise disjoint and the union
of their closures coincides with the closure of Œ©:
Œ© =
K
0
k=1
Œ©k
with
Œ©h ‚à©Œ©k = ‚àÖ
if h Ã∏= k .
We then say an open bounded set Œ© of R3 is piecewise regular and normal
for xi (i = 1, 2, 3) if it admits a partition into open, regular, normal sets for xi
(see Fig. 9.8 for the two-dimensional picture). Such Œ© is G-admissible.
2

9.5 The Theorems of Gauss, Green, and Stokes
389
Œ©1
Œ©2
Œ©3
Œ©4
Œ©5
Œ©6
Figure 9.8. Partition of Œ© ‚äÇR2 into the union of normal sets for y
Compact surfaces. Henceforth Œ£ will denote a piecewise-regular, normal and
orientable compact surface as of Sect. 6.7.4; let Œ£k, k = 1, . . . , K, be its faces,
each of which is normal, regular and compact.
The notion of S-admissible compact surfaces is relevant in view of Stokes‚Äô
Theorem.
DeÔ¨Ånition 9.28 We call S-admissible a compact, piecewise-regular, nor-
mal, orientable surface Œ£ whose faces Œ£k, k = 1, . . . , K, can be parametrised
by maps œÉk : Rk ‚ÜíŒ£k where Rk = Œ©k is the closure of a G-admissible open
set Œ©k in the plane.
Given such an S-admissible, compact surface Œ£, we will assume to have Ô¨Åxed
one orientation by choosing a normal n to Œ£. On each face Œ£k, n coincides with
one of the unit normals to Œ£k, say nk. Without loss of generality we may suppose
nk is the unit normal associated to the parametrisation œÉk, see DeÔ¨Ånition 6.35.
(If not, it is enough to swap œÉk with 1œÉk on 1Rk = {(u, v) ‚ààR2 : (‚àíu, v) ‚ààRk}
given by 1œÉk(u, v) = (‚àíu, v), whose unit normal is opposite to that of œÉk.)
By compactness, the unit normal n is deÔ¨Åned right up to the boundary of Œ£
(with the exception of Ô¨Ånitely many points, at most). For this reason we can choose
an orientation on ‚àÇŒ£. Roughly speaking, the positive orientation is given by
the walking direction of an ideal observer standing as n that proceeds
along the boundary and keeps the surface at his left.
A more accurate deÔ¨Ånition requires a little extra work. Every point P belonging
to ‚àÇŒ£, except for a Ô¨Ånite number, lies on the boundary of exactly one face Œ£k
(Fig. 9.9); moreover, around P the boundary ‚àÇŒ£k is a regular arc Œìk in R3, given by
the image under œÉk of a regular arc Œîk in R2 contained in the boundary of a region
Rk. In other terms, Œîk = {Œ≥k(t) : t ‚ààIk}, where Œ≥k is the parametrisation of the
Jordan arc containing Œîk, and correspondingly Œìk = {Œ∑k(t) = œÉk

Œ≥k(t)

: t ‚ààIk};
the point P ‚ààŒìk will be image under œÉk of a point p0 ‚ààŒîk identiÔ¨Åed by t = t0,
hence P = œÉk(p0) = œÉk

Œ≥k(t0)

= Œ∑k(t0). To the (column) vector œÑ = Œ≥‚Ä≤
k(t0),

390
9 Integral calculus on curves and surfaces
u
v
p0
œÑ
n
Rk
Œîk
 
 
 
 
 
 
 
 
P
Œ†
x
y
z
t
g
n
Œ£k
Œìk
œÉk
Figure 9.9. The positive orientation of a compact surface‚Äôs boundary
tangent to Œîk at p0, corresponds the (column) vector
dŒ∑k
dt (t0) = JœÉk(p0)Œ≥‚Ä≤
k(t0)
(recall the chain rule), tangent to Œìk at P. Let t be the corresponding unit vector.
Then, if we assume that Œ≥k induces the positive orientation on the Jordan arc
where Œîk lies, we will say the orientation of the arc Œìk ‚äÇ‚àÇŒ£ induced by
the unit vector t is positive. We can say the same in the following way. Let Œ†
be the tangent plane to Œ£ at P that contains t, and denote by g the unit vector
orthogonal to t, lying on Œ† and pointing outside Œ£; then the positive orientation
of ‚àÇŒ£ is the one rendering (g, t, n) a positively-oriented triple (see again Fig. 9.9).
Example 9.29
Suppose Œ£ is given by
Œ£ = {(x, y, z) ‚ààR3 : (x, y) ‚ààR, z = œï(x, y)} ,
(9.15)
where R is a closed, bounded region of the plane, the boundary ‚àÇR is a regular
Jordan arc Œì parametrised by Œ≥ : I ‚ÜíŒì, and œï is a C1 map on the open set A
containing R; let Œ© indicate the region inside Œì.
The surface Œ£ is thus compact, S-admissible and parametrised by œÉ : R ‚ÜíŒ£,
œÉ(x, y) =

x, y,œï (x, y)

. The corresponding unit normal is
n =
ŒΩ
‚à•ŒΩ‚à•,
where
ŒΩ = ‚àíœïxi ‚àíœïyj + k .
(9.16)
If Œ≥ parametrises Œì with positive orientation (counter-clockwise), also the bound-
ary
‚àÇŒ£ =

Œ∑(t) =

Œ≥1(t), Œ≥2(t), œï(Œ≥1(t), Œ≥2(t)

: t ‚ààI

will be positively oriented, that is to say, Œ£ lies constantly on its left.

9.5 The Theorems of Gauss, Green, and Stokes
391
The corresponding unit tangent to ‚àÇŒ£ is t =
Œ∑‚Ä≤
‚à•Œ∑‚Ä≤‚à•, where
Œ∑‚Ä≤(t) =

Œ≥‚Ä≤
1(t), Œ≥‚Ä≤
2(t), œïx(Œ≥(t))Œ≥‚Ä≤
1(t) + œïy(Œ≥(t))Œ≥‚Ä≤
2(t)

.
(9.17)
2
9.5.2 Divergence Theorem
The theorem in question asserts that under suitable hypotheses the integral of a
Ô¨Åeld‚Äôs divergence over an open bounded set of Rn is the Ô¨Çux integral of the Ô¨Åeld
across the boundary: letting Œ© denote the open set and n the outward normal to
the boundary ‚àÇŒ©, we have

Œ©
div f =

‚àÇŒ©
f ¬∑ n .
(9.18)
We held back on purpose from making precise hypotheses on Œ© and f, as
multiple possibilities exist. The theorem‚Äôs proofs may be sensibly simpliÔ¨Åed by
suÔ¨Éciently restrictive assumptions, at the cost of diminishing its far-reaching im-
pact. Finding ‚Äòminimal‚Äô hypotheses for its validity is a task beyond the scope of
our study.
In the sequel the Divergence Theorem will be stated under the assumption that
the domain Œ© be G-admissible, as discussed in Sect. 9.5.1; far from being the most
general, our statement will hold nonetheless in the majority of cases of interest.
The reader that wishes to skip the details might think of a G-admissible set as
an open bounded set whose boundary is made of Ô¨Ånitely many graphs of regular
maps, locally viewing the open set on the same side. The outward normal of the
open set will be the outward normal of each graph.
Let us begin in dimension three, by the following preparatory, but relevant
irrespectively, result. The proof is available in Appendix A.2.2, p. 524, under more
stringent, but still signiÔ¨Åcant, assumptions on the domain. Hereafter, Cartesian
coordinates will be equivalently denoted by x1, x2, x3 or by x, y, z.
Proposition 9.30 Let the open set Œ© ‚äÇR3 be G-admissible, and assume
f ‚ààC0(Œ©) with ‚àÇf
‚àÇxi
‚ààC0(Œ©), i ‚àà{1, 2, 3}. Then

Œ©
‚àÇf
‚àÇxi
dx dy dz =

‚àÇŒ©
fni dœÉ ,
where ni is the ith component of the outward normal to ‚àÇŒ©.
Proposition 9.30 is the most straightforward multi-dimensional generalisation
of the recipe for integrating by parts on a bounded real interval, as we mentioned
in the chapter‚Äôs introduction. Its importance is cardinal, because the Divergence
Theorems and Green‚Äôs Theorem descend easily from it. Let us see the Ô¨Årst of these
consequences.

392
9 Integral calculus on curves and surfaces
Theorem 9.31 (Divergence Theorem of Gauss) Let Œ© ‚äÇR3 be a G-
admissible open set, n the outward normal to ‚àÇŒ©. For any vector Ô¨Åeld f ‚àà

C1(Œ©)
3,

Œ©
div f dx dy dz =

‚àÇŒ©
f ¬∑ n dœÉ .
(9.19)
Proof.
Each component fi of f fulÔ¨Ålls the assumptions of the previous proposition,
so

Œ©
‚àÇfi
‚àÇxi
dx dy dz =

‚àÇŒ©
fini dœÉ
for i = 1, 2, 3 .
Summing over i proves the claim.
2
There is actually a version of the Divergence Theorem in every dimension
n ‚â•2. We will only show how the two-dimensional form below is a consequence
of the three-dimensional one; for this we shall use a trick.
Theorem 9.32 Let the open set Œ© ‚äÇR2 be G-admissible and the normal n
to ‚àÇŒ© point outwards. Then for any vector Ô¨Åeld f ‚àà

C1(Œ©)
2

Œ©
div f dx dy =

‚àÇŒ©
f ¬∑ n dŒ≥ .
(9.20)
Proof.
DeÔ¨Åne the open set Q = Œ© √ó (0, 1) ‚äÇR3, which is G-admissible (see
Fig. 9.10); let Œ¶ = f + 0k ‚àà

C1(Œ©)
3, a vector Ô¨Åeld constant with respect
to z for which div Œ¶ = div f. Then

Œ©
div f dx dy =
 1
0

Œ©
div f dx dy dz =

Q
div Œ¶ dx dy dz .
On the other hand, if N is the outward normal to ‚àÇQ, it is easily seen that
f ¬∑ n = Œ¶ ¬∑ N on ‚àÇŒ© √ó (0, 1), whereas Œ¶ ¬∑ N = 0 on Œ© √ó {0} and Œ© √ó {1}.
 
 
 
 
 
 
 
 
Œ©
Q
x
y
z
Figure 9.10. From the two-dimensional Œ© to the three-dimensional Q

9.5 The Theorems of Gauss, Green, and Stokes
393
Therefore

‚àÇŒ©
f ¬∑ n dŒ≥ =
 1
0

‚àÇŒ©
f ¬∑ n dŒ≥ =

‚àÇŒ©√ó(0,1)
Œ¶ ¬∑ N dœÉ =

‚àÇQ
Œ¶ ¬∑ N dœÉ .
The result now follows by applying the Divergence Theorem to the Ô¨Åeld
Œ¶ on Q.
2
Example 9.33
Let us compute the Ô¨Çux of f(x, y, z) = 2i ‚àí5j + 3k through the lateral surface
Œ£ of the solid Œ© deÔ¨Åned by
x2 + y2 < 9 ‚àíz ,
0 < z < 8 .
First, ‚àÇŒ© = Œ£ ‚à™B0 ‚à™B1, where B0 is the circle of centre the origin and radius 3
on the plane z = 0, while B1 is the circle with radius 1 and centre in the origin
of the plane z = 8. Since div f = 0, the Divergence Theorem implies
0 =

Œ©
div f dx dy dz =

‚àÇŒ©
f ¬∑ n =

Œ£
f ¬∑ n +

B0
f ¬∑ n +

B1
f ¬∑ n .
But as
B0
f ¬∑ n =

B0
(‚àí3) = ‚àí27œÄ
and

B1
f ¬∑ n =

B1
3 = 3œÄ ,
we conclude that

Œ£
f ¬∑ n = 24œÄ .
2
9.5.3 Green‚Äôs Theorem
Other important facts ensue from Proposition 9.30. Let Œ© ‚äÇR3 be a G-admissible
open set and f a C1 vector Ô¨Åeld on Œ©. As we know, the Ô¨Årst component of the curl
of f is
(curl f)1 = ‚àÇf3
‚àÇy ‚àí‚àÇf2
‚àÇz .
Therefore integrating over Œ© and using the proposition repeatedly, we obtain

Œ©
(curl f)1 dx dy dz =

Œ©
‚àÇf3
‚àÇy ‚àí‚àÇf2
‚àÇz

dx dy dz =

‚àÇŒ©
(n ‚àßf)1 dœÉ .
Identities of this kind hold for the other components of the curl of f. Altogether
we then have the following result, that we might call Curl Theorem.
Theorem 9.34 Let Œ© ‚äÇR3 be open, G-admissible, and n the outward nor-
mal to ‚àÇŒ©. Then, for any vector Ô¨Åeld f ‚àà

C1(Œ©)
3, we have

Œ©
curl f dx dy dz =

‚àÇŒ©
n ‚àßf dœÉ .
(9.21)

394
9 Integral calculus on curves and surfaces
 
 
 
 
Œ©
P
‚àÇŒ©
t
n
Figure 9.11. Outward normal vector and positive orientation of ‚àÇŒ©
If we write the curl as ‚àá‚àßf, the formula can be remembered as follows: the
integral over Œ© becomes an integral on ‚àÇŒ© and the vector n takes the place of ‚àá.
As we show in the online material, Green‚Äôs Theorem should be considered a
two-dimensional version of the above, and can be easily deduced with the trick
used for Theorem 9.32.
One last remark is in order in the run up to Green‚Äôs Theorem. Let Œ© ‚äÇR2 be
open and G-admissible. If n = n1i + n2j is the outward normal to ‚àÇŒ©, the unit
vector t = ‚àín2i + n1j is tangent to ‚àÇŒ© and oriented along the positive direction
of the boundary: a three-dimensional observer standing as k and walking along
‚àÇŒ© will see Œ© constantly on his left (Fig. 9.11). Now recall that given a Ô¨Åeld
f = f1i + f2j ‚àà

C1(Œ©)
2, we deÔ¨Åned in (6.5) the function curl f = ‚àÇf2
‚àÇx ‚àí‚àÇf1
‚àÇy .
Finally everything is in place for the statement, whose proof may be found in
Appendix A.2.2, p. 525.
Theorem 9.35 (Green) Let Œ© ‚äÇR2 be a G-admissible open set whose
boundary ‚àÇŒ© is positively oriented. Take a vector Ô¨Åeld f = f1i + f2j in

C1(Œ©)
2. Then

Œ©
‚àÇf2
‚àÇx ‚àí‚àÇf1
‚àÇy

dx dy =
4
‚àÇŒ©
f ¬∑ œÑ .
(9.22)
The theorem can be successfully employed to reduce the computation of the
area of a domain in the plane to a path integral. Fix Œ© ‚äÇR2 open and G-admissible
as in the theorem. Then
area(Œ©) =
4
‚àÇŒ©
1
2(‚àíyi + xj) ¬∑ œÑ .
(9.23)

9.5 The Theorems of Gauss, Green, and Stokes
395
In fact, f(x, y) = ‚àíyi + xj has constant curl f = 2, so Green‚Äôs Theorem gives
4
‚àÇŒ©
f ¬∑ œÑ = 2

Œ©
dx dy ,
whence (9.23).
But notice that any vector Ô¨Åeld with constant curl on Œ© may be used to obtain
other expressions for the area of Œ©, like
area(Œ©) =
4
‚àÇŒ©
(‚àíy)i ¬∑ œÑ =
4
‚àÇŒ©
xj ¬∑ œÑ .
Example 9.36
Let us determine the area of the elliptical region E = {(x, y) ‚ààR2 : x2
a2 + y2
b2 ‚â§1}.
We may parametrise the boundary by Œ≥(t) = a cos t i + b sint j, t ‚àà[0, 2œÄ]. Then
area(E) = 1
2
 2œÄ
0
(ab sin2 t + ab cos2 t) dt = 1
2ab
 2œÄ
0
dt = œÄab .
2
9.5.4 Stokes‚Äô Theorem
We discuss Stokes‚Äô Theorem for a rather large class of surfaces, that is S-admissible
compact surfaces, introduced with DeÔ¨Ånition 9.28. Eschewing the formal deÔ¨Ånition,
the reader may think of an S-admissible compact surface as the union of Ô¨Ånitely
many regular local graphs forming an orientable and simple compact surface. With
a given crossing direction Ô¨Åxed, we shall say the boundary is oriented positively if
an observer standing as the normal and advancing along the boundary, views the
surface on the left.
First of all we re-phrase Green‚Äôs Theorem in an equivalent way, the advantage
being to understand it now as a special case of Stokes‚Äô Theorem. We can identify
the closure of Œ©, in R2, with the compact surface Œ£ = Œ©√ó{0} in R3 (see Fig. 9.12);
the latter admits the trivial parametrisation œÉ : Œ© ‚ÜíŒ£, œÉ(u, v) = (u, v, 0), and
is obviously regular, simple and orientable, hence S-admissible. The boundary is
‚àÇŒ£ = ‚àÇŒ©√ó{0}. Fix as crossing direction of Œ£ the one given by the z-axis: by calling
n the unit normal, we have n = k. Furthermore, the positive orientation on ‚àÇŒ©
coincides patently with the positive orientation of ‚àÇŒ£. The last piece of notation
is the vector Ô¨Åeld Œ¶ = f + 0k (constant in z), for which curl f = (curlŒ¶ )3 =
(curlŒ¶ ) ¬∑ n; Equation (9.22) then becomes

Œ£
(curlŒ¶ ) ¬∑ n =
4
‚àÇŒ£
Œ¶ ¬∑ œÑ ,
which ‚Äì as we shall see ‚Äì is precisely what Stokes‚Äô Theorem claims.
We are then ready to state Stokes‚Äô Theorem in full generality; the proof is
available in Appendix A.2.2, p. 526, in the case the faces are suÔ¨Éciently regular
local graphs.

396
9 Integral calculus on curves and surfaces
 
 
 
 
 
 
 
 
Œ£
‚àÇŒ£
n
x
y
z
Figure 9.12. Green‚Äôs Theorem as a special case of Stokes‚Äô Theorem
Theorem 9.37 (Stokes) Let Œ£ ‚äÇR3 be an S-admissible compact surface
oriented by the unit normal n; correspondingly, let the boundary ‚àÇŒ£ be ori-
ented positively. Suppose the vector Ô¨Åeld f, deÔ¨Åned on an open set A ‚äÜR3
containing Œ£, is such that f ‚àà

C1(A)
3. Then

Œ£
(curl f) ¬∑ n =
4
‚àÇŒ£
f ¬∑ œÑ .
(9.24)
In other words, the Ô¨Çux of the curl of f across the surface equals the path
integral of f along the surface‚Äôs (closed) boundary.
Example 9.38
We use Stokes‚Äô Theorem to tackle Example 9.33 in an alternative way. The idea
is to write f = 2i ‚àí5j + 3k as f = curlŒ¶ . Since the components of f are
constant, it is natural to look for a Œ¶ of the form
Œ¶(x, y, z) = (Œ±1x + Œ±2y + Œ±3z)i + (Œ≤1x + Œ≤2y + Œ≤3z)j + (Œ≥1x + Œ≥2y + Œ≥3z)k ,
so
curlŒ¶ = (Œ≥2 ‚àíŒ≤3)i + (Œ±3 ‚àíŒ≥1)j + (Œ≤1 ‚àíŒ±2)k .
Then Œ≥2 ‚àíŒ≤3 = 2, Œ±3 ‚àíŒ≥1 = ‚àí5, Œ≤1 ‚àíŒ±2 = 3. A solution is then Œ¶(x, y, z) =
‚àí5zi + 3xj + 2yk. (Notice that the existence of a Ô¨Åeld Œ¶ such that f = curlŒ¶
is warranted by Sect. 6.3.1, for div f = 0 and Œ© is convex.) By Stokes‚Äô Theorem,

Œ£
f ¬∑ n =

Œ£
curlŒ¶ ¬∑ n =

‚àÇŒ£
Œ¶ ¬∑ œÑ .
We know ‚àÇŒ£ = ‚àÇB0 ‚à™‚àÇB1, see Example 9.33, where the circle ‚àÇB0 is oriented
clockwise, while ‚àÇB1 counter-clockwise.

9.6 Conservative Ô¨Åelds and potentials
397
Then
B0
Œ¶ ¬∑ œÑ =
 2œÄ
0
(0i + 9 cos t j + 6 sin t k) ¬∑ (3 cos t i + 3 sin t j + 0k) dt
= 27
 2œÄ
0
cos2 t dt = 27œÄ ,

B1
Œ¶ ¬∑ œÑ = ‚àí
 2œÄ
0
(‚àí40i + 3 cost j + 2 sin t k) ¬∑ (cos t i + sin t j + 0k) dt
= 40
 2œÄ
0
cos t dt ‚àí3
 2œÄ
0
cos2 t dt = ‚àí3œÄ ,
so eventually

‚àÇŒ£
f ¬∑ n = 24œÄ .
2
9.6 Conservative Ô¨Åelds and potentials
In Sect. 6.3.1, DeÔ¨Ånition 6.10, we introduced the notion of a conservative Ô¨Åeld on
an open set Œ© of Rn as a Ô¨Åeld f that is the gradient of a map œï, called the potential
of f
f = grad œï ,
on Œ© .
Path integrals of conservative Ô¨Åelds enjoy very special properties. The Ô¨Årst one
we encounter is in a certain sense the generalisation to curves of the Fundamental
Theorem of Integral Calculus (see in particular Vol. I, Cor. 9.39).
Proposition 9.39 If f = grad œï is a conservative and continuous Ô¨Åeld on
Œ© ‚äÜRn, then

Œ≥
f ¬∑ œÑ = œï

Œ≥(b)

‚àíœï

Œ≥(a)

for any (piecewise-)regular arc Œ≥ : [a, b] ‚ÜíŒ©.
Proof.
It suÔ¨Éces to consider a regular curve. Recalling formula (9.8) for path
integrals, and the chain rule (esp. (6.13)), we have
(grad œï)

Œ≥(t)

¬∑ Œ≥‚Ä≤(t) = d
dtœï

Œ≥(t)

,
so

Œ≥
f ¬∑ œÑ =
 b
a
d
dtœï

Œ≥(t)

dt =

œï

Œ≥(t)
b
a = œï

Œ≥(b)

‚àíœï

Œ≥(a)

.
2

398
9 Integral calculus on curves and surfaces
Corollary 9.40 Under the hypotheses of the previous proposition, let Œì ‚äÇ
Rn be a (piecewise-)regular, simple arc oriented by the tangent vector œÑ. Then

Œì
f ¬∑ œÑ = œï(P1) ‚àíœï(P0) ,
where P0 and P1 are the initial and end points of Œì.
An elementary but remarkable use of this corollary is that the potential of a
conservative Ô¨Åeld is deÔ¨Åned up to a constant on each connected component of Œ©.
Hence potentials behave somehow similarly to primitives in R, namely:
Proposition 9.41 Two scalar Ô¨Åelds œï, œà are potentials of the same continu-
ous vector Ô¨Åeld f on Œ© if and only if on every connected component Œ©i of Œ©
there is a constant ci such that œï ‚àíœà = ci.
Proof.
It is clear that if œï and œà diÔ¨Äer by a constant on Œ©i, then ‚àáœï = ‚àáœà.
For the converse, Ô¨Åx P0 arbitrarily in Œ©i; given any P ‚ààŒ©i, let Œì be a
polygonal path starting at P0 and ending at P (such will exist because Œ©i
is connected, see DeÔ¨Ånition 4.13). Then the corollary guarantees

Œì
f ¬∑ œÑ = œï(P) ‚àíœï(P0) = œà(P) ‚àíœà(P0) ,
from which œï(P) ‚àíœà(P) = œï(P0) ‚àíœà(P0) = ci.
2
Proposition 9.39 and Corollary 9.40 tell us the path integral of a conservat-
ive Ô¨Åeld depends only on the end points and not on the path itself. Equivalently,
arcs joining the same two points give rise to equal path integrals. In particular,
the integral along a closed arc is zero. That each of these two facts character-
ise conservative Ô¨Åelds is of primary importance. To establish this, we need some
notation, also useful for later. If Œ≥ : [a, b] ‚ÜíRn is an arc between P0 = Œ≥(a)
and P1 = Œ≥(b), we shall write Œ≥[P0, P1] to mean that Œ≥ goes from P0 to P1. The
opposite arc ‚àíŒ≥ (see DeÔ¨Ånition 6.25) joins P1 to P0, i.e., ‚àíŒ≥[P1, P0] = Œ≥[P0, P1].
Given Œ≥1 = Œ≥1[P0, P1] and Œ≥2 = Œ≥2[P1, P2], by Œ≥ ‚àºŒ≥1 + Œ≥2 we will denote any
arc Œ≥ with the following property: if Œ≥ : [a, b] ‚ÜíRn, there is a c ‚àà(a, b) with
Œ≥|[a,c] ‚àºŒ≥1 and Œ≥|[c,b] ‚àºŒ≥2. (An example can be easily found using increas-
ing linear maps from [a, c], [c, b] to the domains of Œ≥1, Œ≥2 respectively.) Observe
Œ≥(c) = P1 and Œ≥ = Œ≥[P0, P2], so Œ≥ connects P0 to P2 passing through P1; moreover,
the traces Œì,Œì 1 and Œì2 satisfy Œì = Œì1 ‚à™Œì2. The symbol Œ≥ ‚àºŒ≥1 ‚àíŒ≥2 will stand
for Œ≥ ‚àºŒ≥1 + (‚àíŒ≥2) whenever Œ≥1 = Œ≥1[P0, P1] and Œ≥2 = Œ≥2[P2, P1]. By the ad-
ditivity of curvilinear integrals, and recalling how they depend upon congruent
parametrisations (9.5), we have

Œ≥
f ¬∑ œÑ =

Œ≥1
f ¬∑ œÑ ¬±

Œ≥2
f ¬∑ œÑ
if
Œ≥ ‚àºŒ≥1 ¬± Œ≥2 .
(9.25)

9.6 Conservative Ô¨Åelds and potentials
399
Now we are in a position to state the result.
Theorem 9.42 If f is a continuous vector Ô¨Åeld on the open set Œ© ‚äÜRn, the
following are equivalent:
i) f is conservative;
ii) for any (piecewise-)regular arcs Œ≥1, Œ≥2 with trace in Œ© and common end
points,

Œ≥1
f ¬∑ œÑ =

Œ≥2
f ¬∑ œÑ ;
iii) for any (piecewise-)regular, closed arc Œ≥ with trace in Œ©,
4
Œ≥
f ¬∑ œÑ = 0 .
Proof.
The implication i) ‚áíii) follows easily from Proposition 9.39 on Œ≥1, Œ≥2
(Fig. 9.13, left). For the converse, we manufacture an explicit potential for
f. Let Œ©i denote a connected component of Œ© and P0 ‚ààŒ©i a given point.
For any P ‚ààŒ©i of coordinates x = (x1, . . . , xn), set
œï(x) =

Œ≥
f ¬∑ œÑ
where Œ≥ = Œ≥[P0, P] is an arbitrary (piecewise-)regular arc with trace inside
Œ©i, joining P0 and P. The deÔ¨Ånition of œï(x) does not depend on the choice
of Œ≥, by ii). We claim that grad œï = f, and will prove it only for the Ô¨Årst
component
‚àÇœï
‚àÇx1
(x) = f1(x) .
Let Œîx1 Ã∏= 0 be an increment such that P + ŒîP = x + Œîx1e1 still
belongs to Œ©i, and call Œ≥[P, P + ŒîP] the curve Œ≥(t) = x + te1 from P to
P0
P1
Œ≥1
Œ≥2
P0
P
P + ŒîP
Œ≥[P0, P + ŒîP]
Œ≥[P0, P]
Œ≥[P, P + ŒîP] = (x + tŒîx)e1
Figure 9.13. Proof of Theorem 9.42

400
9 Integral calculus on curves and surfaces
P + ŒîP, with t ‚àà[0, Œî x1] if Œîx1 > 0 and t ‚àà[Œîx1, 0] if Œîx1 < 0. Let
Œ≥[P0, P] and Œ≥[P0, P + ŒîP] be regular, simple curves from P0 to P and
P + ŒîP respectively (Fig. 9.13, right). Then Œ≥[P0, P + ŒîP] ‚àºŒ≥[P0, P] +
Œ≥[P, P + ŒîP], and by (9.25) and (9.8), we have
œï(x + Œîx1e1) ‚àíœï(x)
Œîx1
=
1
Œîx1

Œ≥[P0,P +ŒîP ]
f ¬∑ œÑ ‚àí

Œ≥[P0,P ]
f ¬∑ œÑ

=
1
Œîx1

Œ≥[P,P +ŒîP ]
f ¬∑ œÑ =
1
Œîx1
 Œîx1
0
f1(x1 + t, x2, . . . , xn) dt .
The last term is the integral average of the map t ‚Üíf1(x1 + t, x2, . . . , xn)
on the interval between 0 and Œîx1, so the continuity of f and the Mean
Value Theorem (Vol. I, Thm. 9.35) force
œï(x + Œîx1e1) ‚àíœï(x)
Œîx1
= f1(x1 + ¬Øt, x2, . . . , xn)
for a certain ¬Øt with |¬Øt| ‚â§|Œîx1|. The limit for Œîx1 ‚Üí0 proves the claim.
The equivalence of ii) and iii) is an immediate consequence of (9.25): if
Œ≥1, Œ≥ fulÔ¨Åll ii) then each Œ≥ ‚àºŒ≥1 ‚àíŒ≥2 satisÔ¨Åes iii), while a Œ≥ satisfying iii),
as seen above, is the diÔ¨Äerence of Œ≥1, Œ≥2 with common end points.
2
The question remains of how to characterise conservative Ô¨Åelds. A necessary
condition is the following.
Property 9.43 Let f be a C1 vector Ô¨Åeld on Œ© ‚äÜRn. If it is conservative,
we have
‚àÇfi
‚àÇxj
= ‚àÇfj
‚àÇxi
‚àÄi Ã∏= j .
(9.26)
Proof.
Take a potential œï for f, so fi =
‚àÇœï
‚àÇxi for i = 1, . . . , n; in particular œï ‚àà
C2(Œ©). Then formula (9.26) is nothing but Schwarz‚Äôs Theorem 5.17.
2
We met this property in Sect. 6.3.1 (Proposition 6.8 for dimension two and Pro-
position 6.7 for dimension three); in fact, it was proven there that a conservative
C1 vector Ô¨Åeld is necessarily irrotational, curl f = 0, on Œ©.
At this juncture one would like to know if, and under which conditions, being
curl-free is also suÔ¨Écient to be conservative. From now on we shall suppose Œ©
is open in R2 or R3. By default we will think in three dimensions, and highlight
a few peculiarities of the two-dimensional situation. Referring to the equivalent
formulation appearing in Theorem 9.42 iii), note that if Œ≥ is any regular, simple
arc whose trace Œì is the boundary of a regular and simple compact surface Œ£
contained in Œ©, Stokes‚Äô Theorem 9.37 makes sure that f irrotational implies

9.6 Conservative Ô¨Åelds and potentials
401
4
Œ≥
f ¬∑ œÑ =

Œ£
curl f ¬∑ n = 0 .
Nevertheless, not all regular and simple closed arcs Œì in Œ© are boundaries of a
regular and simple compact surface Œ£ in Œ©: the shape of Œ© might prevent this
from happening. If, for example, Œ© is the complement in R3 of the axis z, it is
self-evident that any compact surface having a closed boundary encircling the axis
must also intersect the axis, so it will not be contained entirely in Œ© (see Fig. 9.14);
in this circumstance Stokes‚Äô Theorem does not hold. This fact in itself does not
obstruct the vanishing of the circulation of a curl-free Ô¨Åeld around z; it just says
Stokes‚Äô Theorem does not apply. In spite of that, if we consider the Ô¨Åeld
f(x, y, z) = ‚àí
y
x2 + y2 i +
x
x2 + y2 j + 0 k
on Œ©, undoubtedly curl f = 0 on Œ©, whereas
4
Œì
f ¬∑ œÑ = 2œÄ
with Œì the counter-clockwise unit circle on the xy-plane centred at the origin. This
is therefore an example (extremely relevant from the physical viewpoint, by the
way, f being the magnetic Ô¨Åeld generated by a current along a wire on the z-axis)
of an irrotational vector Ô¨Åeld that is not conservative on Œ©.
The discussion suggests to narrow the class of open sets Œ©, in such a way that
f
curl-free
‚áí
f
conservative
holds. With this in mind, let us give a deÔ¨Ånition.
 
 
x
y
z
Œ£
Œì
Figure 9.14. A compact surface Œ£, with boundary Œì, crossed by the z-axis

402
9 Integral calculus on curves and surfaces
DeÔ¨Ånition 9.44 An open connected set Œ© ‚äÜRn is simply connected if the
trace Œì of any arc in Œ© can be deformed with continuity to a point, always
staying within Œ©.
More precisely: Œ© is simply connected if any closed curve Œ≥ : I ‚ÜíRn belongs to a
one-parameter family of closed curves Œ≥s : I ‚ÜíRn, 0 ‚â§s ‚â§1, with the following
properties:
i)
the map (t, s) ‚ÜíŒ≥s(t) from I √ó [0, 1] to Rn is continuous;
ii) each trace Œìs = Œ≥s(I) is contained in Œ©;
iii) Œ≥1 = Œ≥ and Œ≥0 is constant, i.e., Œì0 is a point.
One says Œ≥ is homotopic to a point, and the map (t, s) ‚ÜíŒ≥s(t) is known as
a homotopy.
Simply connectedness can be deÔ¨Åned alternatively. For instance, in dimension
2 we may equivalently demand that
‚Ä¢
the complement of Œ© in R2 is a connected set,
or
‚Ä¢
for any Jordan arc Œ≥ in Œ©, the interior Œ£i is entirely contained in Œ©.
Na¬®ƒ±vely, an open connected set in the plane is simply connected if it has no
‚Äòholes‚Äô; an (open) annulus is thus not simply connected (see Fig. 9.15, left).
The situation in three dimension is more intricate. The open domain enclosed
by two concentrical spheres is simply connected, whereas an open torus is not
(Fig. 9.15, middle and right).
Likewise, the open set obtained by removing one point from R3 is simply con-
nected, but if we take out a whole line it is not simply connected any longer. It
can be proved that an open connected set Œ© in R3 is simply connected if and only
if for any (piecewise-)regular Jordan arc Œì in Œ©, there exists a regular compact
surface Œ£ in Œ© that has Œì as boundary.
 
 
 
 
 
 
Figure 9.15. A simply connected open set (middle) and non-simply connected ones (left
and right)

9.6 Conservative Ô¨Åelds and potentials
403
 
 
 
 
Figure 9.16. A closed simple arc (left) bordering a compact surface (right)
The above characterisation leads to the rather-surprising result for which any
curve in space that closes up, even if knotted, is the boundary of a regular compact
surface. This is possible because the surface is not required to be simple; as a matter
of fact its trace may consist of faces intersecting transversely (as in Fig. 9.16).
Returning to the general set-up, there exist geometrical conditions that guar-
antee an open set Œ© ‚äÜRn is simply connected. For instance, convex open sets
are simply connected, and the same is true for star-shaped sets; the latter admit
a point P0 ‚ààŒ© such that the segment P0P from P0 to an arbitrary P ‚ààŒ© is con-
tained in Œ© (see Fig. 9.17). In particular, a convex set is star-shaped with respect
to any of its points.
Finally, here is the awaited characterization of conservative Ô¨Åelds; the proof is
given in Appendix A.2.2, p. 527.
Theorem 9.45 Let Œ© ‚äÜRn, with n = 2 or 3, be open and simply connected.
A vector Ô¨Åeld f of class C1 on Œ© is conservative if and only if it is curl-free.
A similar result ensures the existence of a potential vector for a Ô¨Åeld with no
divergence.
Remark 9.46 The concepts and results presented in this section may be equi-
valently expressed by the terminology of diÔ¨Äerential forms. We refer to Ap-
pendix A.2.3, p. 529, for further details.
2
 
 
 
 
P0
P1
P2
Figure 9.17. A star-shaped set for P0

404
9 Integral calculus on curves and surfaces
9.6.1 Computing potentials explicitly
Suppose f is conservative on an open (without loss of generality, connected) set
Œ© ‚äÜRn. We wish to Ô¨Ånd a potential for f, which we already know will be deÔ¨Åned
up to a constant. Let us explain two diÔ¨Äerent methods for doing this.
The Ô¨Årst method uses the representation seen in Theorems 9.42 and 9.45. To
be precise, Ô¨Åx a point P0 and deÔ¨Åne the potential at every P ‚ààŒ© of coordinate x
by
œï(x) =

Œì[P0,P ]
f ¬∑ œÑ ,
where Œì[P0, P] ‚äÇŒ© is a simple and (piecewise-)regular arc from P0 to P. The
idea is to choose the path to make the integral as simple as possible to compute
(recall that the integral is independent of the path, by part ii) of Theorem 9.42).
In many cases, the best option is a polygonal path with segments parallel to the
coordinate axes; if so, over each segment the integrand f ¬∑ œÑ depends only on one
component of f.
Example 9.47
Consider the Ô¨Åeld
f(x, y) =
y
‚àö1 + 2xy i +
x
‚àö1 + 2xy j
deÔ¨Åned on the open set Œ© between the branches of the hyperbola xy = ‚àí1/2. It
is not hard to convince oneself that Œ© is star-shaped with respect to the origin,
and curl f = 0 on Œ©; hence the vector Ô¨Åeld is conservative. To Ô¨Ånd a potential,
we may use as path the segment from (0, 0) to P = (x, y) given by Œ≥(t) = (tx, ty),
0 ‚â§t ‚â§1. Then
œï(x, y) =
 1
0
f

Œ≥(t)

¬∑ Œ≥‚Ä≤(t) dt =
 1
0
2xyt

1 + 2xyt2 dt .
Substituting u = 1 + 2xyt2, so du = 4xyt dt, we have
œï(x, y) =
 1+2xy
1
1
2‚àöu du =
‚àöu
1+2xy
1
=

1 + 2xy ‚àí1 .
The generic potential of f on Œ© will be
œï(x, y) =

1 + 2xy + c .
2
The second method we propose, often easier to use than the previous one,
consists in integrating with respect to the single variables, using one after the
other the relationships
‚àÇœï
‚àÇx1
= f1 ,
‚àÇœï
‚àÇx2
= f2 ,
. . .
,
‚àÇœï
‚àÇxn
= fn .
We exemplify the procedure in dimension 2 and give an explicit example for di-
mension 3.

9.6 Conservative Ô¨Åelds and potentials
405
From
‚àÇœï
‚àÇx (x, y) = f1(x, y)
we obtain
œï(x, y) = F1(x, y) + œà1(y) ,
where F1(x, y) is any primitive map of f1(x, y) with respect to x, i.e., it satisÔ¨Åes
‚àÇF1
‚àÇx (x, y) = f1(x, y), while œà1(y), for the moment unknown, is the constant of the
previous integration in x, hence depends on y only. To pin down this function, we
diÔ¨Äerentiate the last displayed equation with respect to y
dœà1
dy (y) = ‚àÇœï
‚àÇy (x, y) ‚àí‚àÇF1
‚àÇy (x, y) = f2(x, y) ‚àí‚àÇF1
‚àÇy (x, y) = g(y) .
Note f2(x, y) ‚àí‚àÇF1
‚àÇy (x, y) depends only on y, because its x-derivative vanishes
by (9.26), since
‚àÇf2
‚àÇx (x, y) ‚àí‚àÇ
‚àÇy
‚àÇF1
‚àÇx (x, y) = ‚àÇf2
‚àÇx (x, y) ‚àí‚àÇf1
‚àÇy (x, y) = 0 .
Calling G(y) an arbitrary primitive of g(y), we have
œà1(y) = G(y) + c
whence
œï(x, y) = F1(x, y) + G(y) + c .
In higher dimension, successive integrations determine one after the other the
unknown maps œà1(x2, . . . , xn), œà2(x3, . . . , xn), . . . , œàn‚àí1(xn) that depend on a de-
creasing number of variables.
Example 9.48
Consider the vector Ô¨Åeld in R3
f(x, y, z) = 2yz i + 2z(x + 3y)j +

y(2x + 3y) + 2z

k .
It is straightforward to check curl f = 0, making the Ô¨Åeld conservative. Integ-
rating
‚àÇœï
‚àÇx (x, y, z) = 2yz
produces œï(x, y, z) = 2xyz + œà1(y, z). Its derivative in y, and ‚àÇœï
‚àÇy (x, y, z) =
2xz + 6yz, tells that ‚àÇœà1
‚àÇy (y, z) = 6yz, so
œà1(y, z) = 3y2z + œà2(z) .

406
9 Integral calculus on curves and surfaces
DiÔ¨Äerentiating the latter with respect to z, and recalling ‚àÇœï
‚àÇz (x, y, z) = 2xy +
3y2 + 2z, gives
dœà2
dz (z) = 2z ,
hence œà2(z) = z2 + c. In conclusion, all potentials for f are of the form
œï(x, y, z) = 2xyz + 3y2z + z2 + c .
2
We close the section by calling the attention to a class of conservative Ô¨Åelds
for which the potential is particularly easy to Ô¨Ånd. These are the so-called radial
vector Ô¨Åelds,
f(x) = g(‚à•x‚à•) x ,
where g = g(r) is a real, continuous function on an interval I of [0, +‚àû). A Ô¨Åeld is
radial when at each point P it is collinear with the vector OP, and its norm depends
merely on the distance of P from the origin. A straightforward computation shows
f is conservative on Œ© = {x ‚ààRn : ‚à•x‚à•‚ààI} and gives a potential. Precisely,
deÔ¨Åne
œï(x) = G(‚à•x‚à•)
where G = G(r) is an arbitrary primitive map of rg(r) on I. In fact, the chain
rule plus Example 5.3 i), give
‚àáœï(x) = G‚Ä≤(‚à•x‚à•) x
‚à•x‚à•= ‚à•x‚à•g(‚à•x‚à•) x
‚à•x‚à•= f(x) .
For example, f(x) =
x

1 + ‚à•x‚à•2 admits œï(x) =

1 + ‚à•x‚à•2 as potential.
9.7 Exercises
1.
Compute the integral of the map
f(x, y, z) =
x2(1 + 8y)

1 + y + 4x2y
along the arc Œ≥ deÔ¨Åned by Œ≥(t) = (t, t2, log t) , t ‚àà[1, 2].
2. Let Œì be the union of the parabolic arc y = 4 ‚àíx2 going from A = (‚àí2, 0)
to C = (2, 0), and the circle x2 + y2 = 4 from C to A. Integrate the function
f(x, y) = x along the closed curve Œì.

9.7 Exercises
407
3.
Integrate f(x, y) = x + y along the closed loop Œì, contained in the Ô¨Årst quad-
rant, that is union of the segment between O = (0, 0) and A = (1, 0), the
elliptical arc 4x2 + y2 = 4 from A to B = (
‚àö
2
2 ,
‚àö
2) and the segment joining B
to the origin.
4. Compute the integral of f(x, y) =
1
x2 + y2 + 1 along the simple closed arc Œ≥
whose trace is made of the segment from the origin to A = (
‚àö
2, 0), the circular
arc x2 + y2 = 2 from A to B = (1, 1), and the segment from B back to the
origin.
5.
Let Œ≥1 : [0, 2
3œÄ] ‚ÜíR2 be given by Œ≥1(t) = (t cos t, t sin t), and Œ≥2, Œ≥3 paramet-
rise the segments from B = (‚àíœÄ
3 ,
œÄ
‚àö
3) to C = (‚àíœÄ, 0) and from C to A = (0, 0).
Compute the length of Œ≥ ‚àºŒ≥1 + Œ≥2 + Œ≥3 whose trace is the union Œì of the
traces of Œ≥1, Œ≥2, Œ≥3, and then Ô¨Ånd the area of the domain inside Œì.
6. Find the centre of mass of the arc Œì, parametrised by Œ≥(t) = et cos t i‚àíet sin t j,
t ‚àà[0, œÄ /2], with unit density.
7.
Consider the arc Œ≥ whose trace Œì is the union of the segment from A =
(2
‚àö
3, ‚àí2) to the origin, and the parabolic arc y2 = 2x from (0, 0) to B =
( 1
2k2, k). Knowing it has unit density, determine k so that the centre of gravity
of Œì belongs to the x-axis.
8.
Determine the moment about z of the arc Œì parametrised by Œ≥(t) = t cos t i +
t sin t j + t k, t ‚àà[0,
‚àö
2] and having unit density.
9.
Integrate the Ô¨Åeld f(x, y) = (x2, xy) along Œ≥(t) = (t2, t), t ‚àà[0, 1].
10. What is the path integral of f(x, y, z) = (z, y, 2x) along the arc Œ≥(t) =
(t, t2, t3), t ‚àà[0, 1]?
11. Integrate f(x, y, z) = (2‚àöz, x, y) along Œ≥(t) = (‚àísin t, cos t, t2), t ‚àà[0, œÄ
2 ].
12.
Compute the integral of f(x, y) = (xy2, x2y) along Œì, the polygonal path
joining A = (0, 1), B = (1, 1), C = (0, 2) and D = (1, 2).
13. Integrate f(x, y) = (0, y) along the following simple closed arc: a segment from
the origin to A = (1, 0), a circle x2+y2 = 1 from A to B = (
‚àö
2
2 ,
‚àö
2
2 ), a segment
from B to the origin.
14.
Determine k so that the work done by the force
f(x, y) = (x2 ‚àíxy)i + (y2 ‚àíx2)j
along the parabola y2 = 2kx from the origin to P = (k/2, k) equals 9/5.

408
9 Integral calculus on curves and surfaces
15. Compute the work integral of
f(x, y) = (ax2y ‚àísin x)i + (x3 + y log y)j
along Œì, union of the arcs Œì1, Œì2, Œì3 of respective equations y = x2, y = 1,
x = 0. Determine the parameter a so that the work is zero.
16.
Let f(x, y, z) = z(y‚àí2x). Compute the integral of f over the surface œÉ(u, v) =
(u, v,
‚àö
16 ‚àíu2 ‚àív2), deÔ¨Åned on R = {(u, v) ‚ààR2 : u ‚â§0, v ‚â•0, u2 + v2 ‚â§
16, u2
4 + v2 ‚â•1}.
17.
Integrate
f(x, y, z) =
y + 1
#
1 + x2
4 + 4y2
over Œ£, which is the portion of the elliptical paraboloid z = ‚àíx2
4 ‚àíy2 above
the plane z = ‚àí1.
18.
Determine the area of the compact surface Œ£, intersection of the surface z =
1
2y2 with the prism given by the planes x + y = 4, y ‚àíx = 4, y = 0.
19. Compute the area of the portion of surface z =

x2 + y2 below the plane
z =
1
‚àö
2(y + 2).
20.
Find the moment, about the axis z, of the surface Œ£ part of the cone z2 =
3(x2 + y2) satisfying 0 ‚â§z ‚â§3, y ‚â•x (assume unit density).
21. Let R in the zy-plane be the union of
R1 = {(y, z) ‚ààR2 : y ‚â§0,

1 ‚àí(y + 1)2 ‚â§z ‚â§

4 ‚àíy2}
and
R2 = {(y, z) ‚ààR2 : y ‚â•0, y ‚â§z ‚â§

4 ‚àíy2}.
Find the coordinate xG of the centre of mass for the part of the surface x =

4 ‚àíy2 ‚àíz2 projecting onto R (assume unit density).
22.
Using Green‚Äôs Theorem, compute the work done by
f(x, y) = xyi + x4yj
along the closed counter-clockwise loop Œì, union of Œì1, Œì2, Œì3, Œì4 of respective
equations x = y2, y = 1, x2 + y2 = 5, y = 0, (x, y ‚â•0).

9.7 Exercises
409
23.
Using Green‚Äôs Theorem, compute the work done by f(x, y) = x2y2i + axj, as
the parameter a varies, along the closed counter-clockwise curve Œì, union of
Œì1, Œì2, Œì3 of equations x2 + y2 = 1, x = 1, y = x2 + 1 (x, y ‚â•0).
24.
Let Œì be the union of Œì1 parametrised by Œ≥1(t) = (e‚àí(t‚àíœÄ/4) cos t, sin t), t ‚àà
[0, œÄ /4], and the segments from the origin to the end points of Œì1, A = (eœÄ/4, 0)
and B = (
‚àö
2/2,
‚àö
2/2). Find the area of the region Œ© bounded by Œì.
25.
With the aid of the Divergence Theorem, determine the outgoing Ô¨Çux of
f(x, y, z) = (x3 + yz)i + (xz + y3)j + (xy + z3 + 1)k
across Œ©, deÔ¨Åned by
x2 + y2 + z2 ‚â§1 ,
x2 + y2 ‚àíz2 ‚â§0 ,
y ‚â•0 ,
z ‚â•0 .
26. Find the Ô¨Çux of
f(x, y, z) = (xy2 + z3)i + (x2 + 1
3y3)j + 2(x2z + 1
3z3 + 2)k
leaving the compact surface
x2 + y2 + z2 ‚â§2 ,
x2 + y2 ‚àíz2 ‚â•0 ,
y ‚â•0 ,
z ‚â•0 .
27.
Using Stokes‚Äô Theorem, compute the integral of
f(x, y, z) = xi + yj + xyk
along the boundary of Œ£, intersection of the cylinder x2 + y2 = 4 and the
paraboloid z = x2
9 + y2
4 , oriented so that the normal points toward the z-axis.
28.
Given the vector Ô¨Åeld
f(x, y, z) = (y + z)i + 2(x + z)j + 3(x + y)k
and the sphere x2 + y2 + z2 = 2, Ô¨Ånd the Ô¨Çux of the curl of f going out of the
portion of sphere above z = y.
29.
Verify the Ô¨Åeld f(x, y, z) = xi ‚àí2yj + 3zk is conservative and Ô¨Ånd a potential
for it.
30.
Determine the map g ‚ààC‚àû(R) with g(0) = 0 that makes the vector Ô¨Åeld
f(x, y) = (y sin x + xy cos x + ey)i +

g(x) + xey
j
conservative. Find a potential for the resulting f.

410
9 Integral calculus on curves and surfaces
31. Consider
f(x, y) =
g(y)
x
+ cos y

i + (2y log x ‚àíx sin y)j .
a) Determine the map g ‚ààC‚àû(R) with g(1) = 1, so that f is conservative.
b) Determine for the Ô¨Åeld thus obtained the potential œï such that œï(1, œÄ
2 ) = 0.
32. Consider the Ô¨Åeld
f(x, y) = (2x log y ‚àíy sin x)i +
g(x)
y
+ cos x

j .
a) Determine g ‚ààC‚àû(R) such that g(0) = 1 and making f conservative.
b) For this Ô¨Åeld Ô¨Ånd the potential œï such that œï( œÄ
3 , 1) = 0.
33. Consider
f(x, y, z) = (3y + cos(x + z2))i + (3x + y + g(z))j + (y + 2z cos(x + z2))k .
a) Determine the map g ‚ààC‚àû(R) so that g(1) = 0 and f is conservative.
b) For the above Ô¨Åeld determine the potential œï with œï(0, 0, 0) = 0.
34. Determine the value of Œª such that
f(x, y, z) = (x2 + 5Œªy + 3yz)i + (5x + 3Œªxz ‚àí2)j + ((2 + Œª)xy ‚àí4z)k
is conservative. Then Ô¨Ånd the potential œï with œï(3, 1, ‚àí2) = 0.
9.7.1 Solutions
1. For t ‚àà[1, 2] we have f

Œ≥(t)

=
t2(1 + 8t2)
‚àö
1 + t2 + 4t4 , and Œ≥‚Ä≤(t) =

1, 2t, 1
t

, so

Œ≥
f =
 2
1
t2(1 + 8t2)
‚àö
1 + t2 + 4t4
1
t

1 + t2 + 4t4 dt =
 2
1
t(1 + 8t2) dt = 63
2 .
2. 0.
3. Let us compute Ô¨Årst the coordinates of B, in the Ô¨Årst quadrant, intersection
of the line y = 2x and the ellipse 4x2 + y2 = 4, which are B = (
‚àö
2
2 ,
‚àö
2). The
piecewise-regular arc Œ≥ can be divided in three regular arcs Œ≥1, Œ≥2, Œ≥3 of respective
traces the segment OA, the elliptical arc AB and the segment BO. We can deÔ¨Åne
arcs Œ¥1, Œ¥2, Œ¥3 congruent to Œ≥1, Œ≥2, Œ≥3 as follows:
Œ¥1(t) = (t, 0)
0 ‚â§t ‚â§1 ,
Œ¥1 = Œ≥1 ,
Œ¥2(t) = (cos t, 2 sin t)
0 ‚â§t ‚â§œÄ
4 ,
Œ¥2 ‚àºŒ≥2 ,
Œ¥3(t) = (t, 2t)
0 ‚â§t ‚â§
‚àö
2
2 ,
Œ¥3 ‚àº‚àíŒ≥3 ,

9.7 Exercises
411
so that

Œ≥
f =

Œ¥1
f +

Œ¥2
f +

Œ¥3
f .
Since
f

Œ¥1(t)

= t ,
f

Œ¥2(t)

= cos t + 2 sin t ,
f

Œ¥3(t)

= 3t ,
Œ¥‚Ä≤
1(t) = (1, 0) ,
Œ¥‚Ä≤
1(t) = (‚àísin t, 2 cost) ,
Œ¥‚Ä≤
3(t) = (1, 2) ,
‚à•Œ¥‚Ä≤
1(t)‚à•= 1 ,
‚à•Œ¥‚Ä≤
2(t)‚à•=

sin2 t + 4 cos2 t ,
‚à•Œ¥‚Ä≤
3(t)‚à•=
‚àö
5 ,
it follows

Œ≥
f =
 1
0
t dt +
 œÄ/4
0

cos t + 2 sin t

sin2 t + 4 cos2 t dt +
 ‚àö
2/2
0
3
‚àö
5t dt
= 1
2 + 3
4
‚àö
5 +
 œÄ/4
0
cos t

4 ‚àí3 sin2 t dt + 2
 œÄ/4
0
sin t

1 + 3 cos2 t dt
= 1
2 + 3
4
‚àö
5 + I1 + I2 .
For I1, set u =
‚àö
3 sin t, so du =
‚àö
3 cos t dt, and obtain
I1 =
1
‚àö
3
 ‚àö
6/2
0

4 ‚àíu2 du .
Substituting v = u
2 we have
I1 =
1
‚àö
3
1
2u

4 ‚àíu2 + 2 arcsin u
2
‚àö
6/2
0
=
‚àö
5
4 + 2
‚àö
3 arcsin
‚àö
6
4 .
Similarly for I2, we set u =
‚àö
3 cos t, so du = ‚àí
‚àö
3 sin t dt and
I2 = ‚àí2
‚àö
3
 ‚àö
6/2
‚àö
3

1 + u2 du .
Then
I2 = ‚àí1
‚àö
3

u

1 + u2 + log

1 + u2 + u
‚àö
6/2
‚àö
3
= ‚àí
‚àö
5
2 + 2 + 1
‚àö
3

log(2 +
‚àö
3) ‚àílog
‚àö
10 +
‚àö
6
2

.
4. 2 arctan
‚àö
2 +
‚àö
2
12 œÄ.
5. Since ‚Ñì(Œ≥) = ‚Ñì(Œ≥1) + ‚Ñì(Œ≥2) + ‚Ñì(Œ≥3), we compute the lengths separately. The last
two are elementary, ‚Ñì(Œ≥2) =
‚àö
7
3 œÄ and ‚Ñì(Œ≥3) = œÄ. As for the Ô¨Årst one,

412
9 Integral calculus on curves and surfaces
Œ©1
A
B
x
y
C
œÄ
‚àö
3
Œ≥1
Œ≥2
Œ≥3
Figure 9.18. The arc Œ≥ and the region Œ©1 relative to Exercise 5
‚Ñì(Œ≥1) =
 2/3œÄ
0
‚à•Œ≥‚Ä≤(t)‚à•dt =
 2/3œÄ
0

1 + t2 dt
= 1
3œÄ

1 + 4
9œÄ2 + 1
2 log
2
3œÄ +

1 + 4
9œÄ2
.
The area is then the sum of the triangle ABC and the set Œ©1 of Fig. 9.18. We
know that area(ABC) =
œÄ2
2
‚àö
3. As Œ©1 reads, in polar coordinates,
Œ©‚Ä≤
1 =

(r,Œ∏ ) : 0 ‚â§r ‚â§Œ∏, 0 ‚â§Œ∏ ‚â§2
3œÄ

,
we have
area(Œ©1) =

Œ©1
dx dy =
 (2/3)œÄ
0
 Œ∏
0
r dr dŒ∏ = 4
81œÄ3 .
6. We have
xG =
eœÄ ‚àí2
5(eœÄ/2 ‚àí1) ,
yG =
2eœÄ + 1
5(1 ‚àíeœÄ/2) .
7. The parameter k is Ô¨Åxed by imposing yG = 0. At the same time,
yG =

Œ≥1
y +

Œ≥2
y
where Œ≥1(t) = (‚àí
‚àö
3t, t), t ‚àà[‚àí2, 0] and Œ≥2(t) = ( 1
2t2, t), t ‚àà[0, k]. Then
yG =
 0
‚àí2
2t dt +
 k
0
t

1 + t2 dt = 1
3

(1 + k2)3/2 ‚àí13

;
the latter is zero when k =
‚àö
132/3 ‚àí1.
8. As Œ≥‚Ä≤(t) = (cos t ‚àít sin t)i + (sin t + t cost)j + k and ‚à•Œ≥‚Ä≤(t)‚à•2 = 2 + t2, we have
Iz =

Œì
(x2 + y2) =
 ‚àö
2
0
t2
2 + t2 dt = 3
2
‚àö
2 ‚àí1
2 log(1 +
‚àö
2) .

9.7 Exercises
413
9. From f

Œ≥(t)

= (t4, t3) and Œ≥‚Ä≤(t) = (2t, 1) follows

Œ≥
f ¬∑ dP =
 1
0
(t4, t3) ¬∑ (2t, 1) dt =
 1
0
(2t5 + t3) dt = 7
12 .
10. 9
4 ;
11. œÄ
4 .
12. The piecewise-regular arc Œ≥ restricts to three regular arcs Œ≥1, Œ≥2, Œ≥3, whose
traces are the segments AB, BC, CD. We can deÔ¨Åne arcs Œ¥1, Œ¥2 and Œ¥3 congruent
to Œ≥1, Œ≥2, Œ≥3:
Œ¥1(t) = (t, 1)
0 ‚â§t ‚â§1 ,
Œ¥1 ‚àºŒ≥1 ,
Œ¥2(t) = (t, 2 ‚àít)
0 ‚â§t ‚â§1 ,
Œ¥2 ‚àº‚àíŒ≥2 ,
Œ¥3(t) = (t, 2)
0 ‚â§t ‚â§1 ,
Œ¥3 ‚àºŒ≥3 ,
Then from
f

Œ¥1(t)

= (t, t2) ,
f

Œ¥2(t)

=

t(2 ‚àít)2, t2(2 ‚àít)

,
f

Œ¥3(t)

= (4t, 2t2)
Œ¥‚Ä≤
1(t) = (1, 0) ,
Œ¥‚Ä≤
2(t) = (1, ‚àí1) ,
Œ¥‚Ä≤
3(t) = (1, 0) ,
we have

Œ≥
f ¬∑ dP =

Œ¥1
f ¬∑ dP ‚àí

Œ¥2
f ¬∑ dP +

Œ¥3
f ¬∑ dP
=
 1
0
(t, t2) ¬∑ (1, 0) dt ‚àí
 1
0

t(2 ‚àít)2, t2(2 ‚àít)

¬∑ (1, ‚àí1) dt
+
 1
0
(4t, 2t2) ¬∑ (1, 0) dt = 2 .
13. 0.
14. Let us impose

Œ≥
f ¬∑ œÑ = 9
5
where Œ≥(t) =
 1
2kt2, t

, t ‚àà[0, k] (note k Ã∏= 0, otherwise the integral is zero). Since
Œ≥‚Ä≤(t) =
 1
kt, 1

,

Œ≥
f ¬∑ œÑ =
 k
0
 t5
4k3 ‚àít4
2k2 + t2 ‚àít4
4k2

dt = 9
40k3 .
Therefore
9
40k3 = 9
5, so k = 2.
15. The work integral equals L = 2
5 ‚àí2
15a, which vanishes if a = 3.
16. The surface is the graph of œï(u, v) =
‚àö
16 ‚àíu2 ‚àív2, so (6.49) gives

414
9 Integral calculus on curves and surfaces
D1
D2
‚àí4
‚àí2
1
4
u
v
Figure 9.19. The regions D1 and D2 relative to Exercise 16
‚à•ŒΩ(u, v)‚à•=

1 +
‚àÇœï
‚àÇu
2 +
‚àÇœï
‚àÇv
2 =
4
‚àö
16 ‚àíu2 ‚àív2 .
Therefore

œÉ
f =

R

16 ‚àíu2 ‚àív2(v ‚àí2u)
4
‚àö
16 ‚àíu2 ‚àív2 du dv
= 4

R
(v ‚àí2u) du dv .
The region R is in the second quadrant and lies between the circle with radius
4, centre the origin, and the ellipse with semi-axes a = 2, b = 1 (Fig. 9.19).
Integrating in v Ô¨Årst and dividing the domain into D1 and D2, we Ô¨Ånd

œÉ
f = 4
  ‚àí2
‚àí4
 ‚àö
16‚àíu2
0
(v ‚àí2u) dv du +
 0
‚àí2
 ‚àö
16‚àíu2

1‚àíu2
4
(v ‚àí2u) dv du

= 728
3 .
17. A parametrisation for Œ£ is (Fig. 9.20)
œÉ(u, v) = (u, v, ‚àíu2
4 ‚àív2) ,
(u, v) ‚ààR = {(u, v) ‚ààR2 : u2
4 + v2 = 1} .
Then ‚à•ŒΩ(u, v)‚à•2 = 1 + u2
4 + 4v2 and

Œ£
f =

R
(v + 1) du dv .
Passing to elliptical polar coordinates,

Œ£
f = 2
 2œÄ
0
 1
0
(r sin Œ∏ + 1)r dr dŒ∏ = 2œÄ .

9.7 Exercises
415
u
v
2
‚àí1
‚àí2
1
R
 
 
 
 
 
 
 
 
x
y
z
‚àí1
Figure 9.20. The region R (left) and the surface Œ£ (right) relative to Exercise 17
18. Parametrise Œ£ by
œÉ(u, v) =

u, v, 1
2v2
,
(u, v) ‚ààR ,
where R is the triangle in the uv-plane of vertices (‚àí4, 0), (4, 0), (0, 4) (Fig. 9.21).
In this way ‚à•ŒΩ(u, v)‚à•=
‚àö
1 + v2, so
area(Œ£) =

Œ£
1 =

R

1 + v2 du dv =
 4
0
  4‚àív
v‚àí4

1 + v2 du

dv
= 14
3
‚àö
17 + 4 log(4 +
‚àö
17) + 2
3 .
19. area(Œ£) = 8œÄ.
20. Using cylindrical coordinates Œ£ reads
œÉ(r,Œ∏ ) = (r, Œ∏,
‚àö
3r) ,
(r,Œ∏ ) ‚ààR = {(r,Œ∏ ) : 0 ‚â§r ‚â§
‚àö
3, œÄ
4 ‚â§Œ∏ ‚â§5
4œÄ}
(see Fig. 9.22). Then ‚à•ŒΩ(r,Œ∏ )‚à•= 2 and
‚àí4
4
4
u
v
v = 4 ‚àíu
v = 4 + u
R
 
 
 
 
x
y
z
‚àí4
4
4
8
Figure 9.21. The region R (left) and the surface Œ£ (right) relative to Exercise 18

416
9 Integral calculus on curves and surfaces
u
v
‚àö
3
u = v
R
 
 
 
 
 
 
 
 
x
y
z
3
y = x
Figure 9.22. The region R (left) and the surface Œ£ (right) relative to Exercise 20

Œ£
(x2 + y2) = 2

R
r2r dr dŒ∏ = 2
 (5/4)œÄ
œÄ/4
 ‚àö
3
0
r3 dr dŒ∏ = 9
2œÄ .
21. xG =
2œÄ
œÄ+4.
22. The arc is shown in Fig. 9.23. The work equals L =
5
Œì f ¬∑ œÑ, but also
L =

Œ©
‚àÇf2
‚àÇx ‚àí‚àÇf1
‚àÇy

dx dy
by Green‚Äôs Theorem, with Œ© inside Œì and f1(x, y) = xy, f2(x, y) = x4y. Then if
we integrate in x Ô¨Årst,
L =
 1
0
 ‚àö
5‚àíy2
y2
(4x3y ‚àíx) dx dy = 47
6 .
Œ©
0
1
1
x
y
2
‚àö
3
Œ≥1
Œ≥2
Œ≥3
Œ≥4
x =

5 ‚àíy2
x = y2
Figure 9.23. The arc Œì and the region Œ© relative to Exercise 22

9.7 Exercises
417
Œ©
1
1
2
x
y
Œ≥1
Œ≥2
Œ≥3
y = 1 + x2
y =
‚àö
1 ‚àíx2
Figure 9.24. The arc Œì and the region Œ© relative to Exercise 23
23. The arc Œì is shown in Fig. 9.24. Green‚Äôs Theorem implies the work is
L =
4
Œì
f ¬∑ œÑ =

Œ©
(a ‚àí2x2y) dx dy ,
where Œ© is inside Œì. Integrating vertically,
L =
 1
0
 x2+1
‚àö
1‚àíx2(a ‚àí2x2y) dy dx =
 1
0

ay ‚àíx2y2y=x2+1
y=
‚àö
1‚àíx2 dx = a
4
3 ‚àíœÄ
4

‚àí26
35 .
24. We use (9.23) on the arc Œì (see Fig. 9.25). The integral along OA and OB is
zero; since Œ≥‚Ä≤
1(t) = (‚àíe‚àí(t‚àíœÄ/4)(cos t + sin t), cos t), it follows
area(Œ©) = 1
2
 œÄ/4
0

sin t(cos t + sin t) + cos2 t

e‚àí(t‚àíœÄ/4) dt = ‚àí11
20 + 3
5eœÄ/4 .
Œ©
A
B
0
x
y
Œ≥1
Figure 9.25. The arc Œì and the region Œ© relative to Exercise 24

418
9 Integral calculus on curves and surfaces
25. The Divergence Theorem tells

‚àÇŒ©
f ¬∑ n =

Œ©
div f =

Œ©
3(x2 + y2 + z2) dx dy dz .
In spherical coordinates Œ© becomes Œ©‚Ä≤ deÔ¨Åned by 0 ‚â§r ‚â§1, 0 ‚â§œï ‚â§œÄ/4 and
0 ‚â§Œ∏ ‚â§œÄ. Then

‚àÇŒ©
f ¬∑ n =
 œÄ
0
 œÄ/4
0
 1
0
3r4 sin œï dr dœï dŒ∏ = 3
10œÄ(2 ‚àí
‚àö
2) .
26. The Ô¨Çux is 8
5œÄ(
‚àö
2 ‚àí1).
27. Let us parametrise Œ£ by
œÉ(u, v) =

u, v, u2
9 + v2
4

,
with
(u, v) ‚ààR =

(u, v) ‚ààR2 : u2 + v2 ‚â§4

.
Then ŒΩ(u, v) = (‚àí2
9u, ‚àív
2, 1) is oriented as required. In order to use Stokes‚Äô The-
orem, notice curl f = xi ‚àíyj + 0k, and

‚àÇŒ£
f ¬∑ œÑ =

Œ£
curl f ¬∑ n =

R
(ui ‚àívj + 0k) ¬∑

‚àí2
9u i ‚àív
2j + k

du dv
=

R
(‚àí2
9u2 + 1
2v2) du dv .
In polar coordinates,

‚àÇŒ£
f ¬∑ œÑ =
 2œÄ
0
 2
0

‚àí2
9 cos2 Œ∏ + 1
2 sin2 Œ∏

r3 dr dŒ∏ = 10
9 œÄ .
28. We use Stokes‚Äô Theorem with
Œ£ =

(x, y, z) ‚ààR3 : x2 + y2 + z2 = 2, z ‚â•y

,
whose boundary is ‚àÇŒ£ = {(x, y, z) ‚ààR3 : x2 + y2 + z2 = 2, z = y}. So we
parametrise ‚àÇŒ£ by
Œ≥(t) = (
‚àö
2 cos t, sin t, sin t) ,
t ‚àà[0, 2œÄ] ;
then
f

Œ≥(t)

= 2 sin t i + 2(
‚àö
2 cos t + sin t) j + 3(
‚àö
2 cos t + sin t) k ,
Œ≥‚Ä≤(t) = ‚àí
‚àö
2 sin t i + cos t j + cos t k
and

Œ£
curl f ¬∑ n =

‚àÇŒ£
f ¬∑ œÑ = 3
‚àö
2œÄ .

9.7 Exercises
419
29. The Ô¨Åeld f is deÔ¨Åned on the whole R3 (clearly simply connected), and its curl
is zero. By Theorem 9.45 then, f is conservative.
To Ô¨Ånd a potential œï, start from
‚àÇœï
‚àÇx = x ,
‚àÇœï
‚àÇy = ‚àí2y ,
‚àÇœï
‚àÇz = 3z .
(9.27)
From the Ô¨Årst we get
œï(x, y, z) = 1
2x2 + œà1(y, z) .
DiÔ¨Äerentiating in y and using the second equation in (9.27) gives
‚àÇœï
‚àÇy (x, y, z) = ‚àÇœà1
‚àÇy (y, z) = ‚àí2y ,
hence
œà1(y, z) = ‚àíy2 + œà2(z)
and
œï(x, y, z) = 1
2x2 ‚àíy2 + œà2(z) .
Now we diÔ¨Äerentiate œï in z and use the last in (9.27):
‚àÇœï
‚àÇz (x, y, z) = dœà2
dz (z) = 3z ,
so
œà2(z) = 3
2z2 + c .
All in all, a potential for f is
œï(x, y, z) = 1
2x2 ‚àíy2 + 3
2z2 + c ,
c ‚ààR .
30. The Ô¨Åeld is deÔ¨Åned over the simply connected plane R2. It is thus enough to
impose
‚àÇf1
‚àÇy (x, y) = ‚àÇf2
‚àÇx (x, y) ,
where f1(x, y) = y sin x + xy cos x + ey and f2(x, y) = g(x) + xey, for the Ô¨Åeld to
be conservative. This translates to
sin x + x cos x + ey = g‚Ä≤(x) + ey ,
i.e., g‚Ä≤(x) = sin x + x cos x. Integrating,
g(x) =

(sin x + x cos x) dx = x sin x + c ,
c ‚ààR .
The condition g(0) = 0 forces c = 0, so the required map is g(x) = x sin x.
To Ô¨Ånd a potential œï for f, we must necessarily have
‚àÇœï
‚àÇy (x, y, z) = y sin x + xy cos x + ey
and
‚àÇœï
‚àÇy (x, y, z) = x sin x + xey .

420
9 Integral calculus on curves and surfaces
The second equation gives
œï(x, y) = xy sin x + xey + œà(x) ;
diÔ¨Äerentiating in x and using the Ô¨Årst equation gives
‚àÇœï
‚àÇx (x, y, z) = y sin x + xy cos x + ey + œà‚Ä≤(x) = y sin x + xy cos x + ey .
Therefore œà‚Ä≤(x) = 0, so œà(x) = c for an arbitrary constant c in R. In conclusion,
œï(x, y) = xy sin x + xey + c ,
c ‚ààR .
31. a) g(y) = y2;
b) œï(x, y) = y2 log x + x cos y.
32. a) g(x) = x2 + 1;
b) œï(x, y) = (x2 + 1) log y + y cos x ‚àí1
2.
33. a) g(z) = z ‚àí1;
b) œï(x, y, z) = 3xy + 1
2y2 + yz ‚àíy + sin(x + z2).
34. Œª = 1 e œï(x, y, z) = 1
3x3 + 3xyz + 5xy ‚àí2z2 ‚àí2y + 4.

10
Ordinary diÔ¨Äerential equations
DiÔ¨Äerential equations are among the mathematical instruments most widely used
in applications to other Ô¨Åelds. The book‚Äôs Ô¨Ånal chapter presents in a self-contained
way the main notions, theorems and techniques of so-called ordinary diÔ¨Äerential
equations. After explaining the basic principles underlying the theory we review
the essential methods for solving several types of equations. We tackle existence
and uniqueness issues for a solution to the initial value problem of a vectorial
equation, then describe the structure of solutions of linear systems, for which
algebraic methods play a central role, and equations of order higher than one. In
the end the reader will Ô¨Ånd a concise introduction to asymptotic stability, with
applications to pendulum motion, with and without damping.
Due to the matter‚Äôs richness and complexity, this exposition is far from ex-
haustive and will concentrate on the qualitative aspects especially, keeping rigorous
arguments to a minimum1.
10.1 Introductory examples
The reader will presumably be already familiar with diÔ¨Äerential equation that
formalise certain physical principles, like Newton‚Äôs law of motion. DiÔ¨Äerential
equations are natural tools, hence widely employed to build mathematical mod-
els describing phenomena and processes of the real world. The reason is that
two quantities (the variables) often interact by aÔ¨Äecting one another‚Äôs variation,
which is expressed by a relationship between one variable and some derivative of
the other. Newton‚Äôs law, for instance, states that a force inÔ¨Çuences a particle‚Äôs ac-
celeration, i.e., the change of its velocity in time; and velocity itself is the variation
of displacement. If the force is a function of the particle‚Äôs position, as happens in
the case of a spring, we obtain an equation of motion in terms of time t
1 For proofs, the interested reader may consult, among others, the rich monograph by
G. Teschl, Ordinary DiÔ¨Äerential Equations and Dynamical Systems, American Math-
ematical Society, 2012.
C. Canuto, A. Tabacco: Mathematical Analysis II, 2nd Ed.,
UNITEXT ‚Äì La Matematica per il 3+2 85, DOI 10.1007/978-3-319-12757-6_10,
¬© Springer International Publishing Switzerland 2015

422
10 Ordinary diÔ¨Äerential equations
md2x
dt2 = ‚àíkx ;
what this says is that the spring‚Äôs pulling force is proportional to the displacement,
and acts against motion (k > 0). A more complicated example is
md2x
dt2 = ‚àí(k + Œ≤x2)x ,
where the spring‚Äôs rigidity is enhanced by an increase of the displacement; both
these are diÔ¨Äerential equations of second order in the variable t. Another ex-
ample originating from classical Mechanics, that will accompany us throughout
the chapter, is that of a pendulum swinging freely on a vertical plane under the
eÔ¨Äect of gravity and possibly some friction. The relationship between the angle Œ∏
swept by the rod and the bob‚Äôs angular velocity and acceleration reads
d2Œ∏
dt2 + Œ±dŒ∏
dt + k sin Œ∏ = 0 .
Multiple mass-spring systems, or compound pendulums, are governed by systems
of diÔ¨Äerential equations correlating the positions of the various masses involved,
or the angles of the rods forming the pendulum.
The diÔ¨Äerential equations of concern, like all those treated in the chapter,
are ordinary, which means the unknowns depend upon one independent variable,
conventionally called t (the prevailing applications are dynamical, of evolution
type, so t is time). Partial diÔ¨Äerential equations, instead, entail unknown functions
of several variables (like time and space coordinates), and consequently also partial
derivatives.
Ordinary diÔ¨Äerential equations and systems are fundamental to explain how
electric and electronic circuits work. The simplest situation is that of an LRC
circuit, where the current i = i(t) satisÔ¨Åes a linear equation of second order of the
type
‚Ñìd2i
dt2 + r di
dt + i
c = f .
Electric networks can be modelled by systems of as many of the above equations
as the number of loops, to which one adds suitable conservation laws at the nodes
(KirchhoÔ¨Ä‚Äôs laws). For electronic circuits with active components, diÔ¨Äerential mod-
els are typically non-linear.
Materials Sciences, Chemistry, Biology, and more generally Life and Social Sci-
ences, are all fertile sources of mathematical models based on ordinary diÔ¨Äerential
equations. For instance,
y‚Ä≤ = ky

10.1 Introductory examples
423
describes the radioactive decay of a substance y (the rate of disappearance is pro-
portional, for k < 0, to the quantity of matter itself). But the same equation
regulates the dynamics of populations (called in this case Malthus‚Äô law, it predicts
that the rate of growth y‚Ä≤/y of a population in time equals the diÔ¨Äerence k = n‚àím
between the constant birth rate n and death rate m). Malthus‚Äô model becomes real-
istic by further assuming k is corrected by a braking term that prevents unlimited
growth, via the so-called logistic growth equation
y‚Ä≤ = (k ‚àíŒ≤y)y .
Another example are the Volterra-Lotka equations
 p‚Ä≤
1 = (k1 ‚àíŒ≤1p2)p1
p‚Ä≤
2 = (‚àík2 + Œ≤2p1)p2 ,
that preside over the interactions of two species, labelled preys p1 and predators p2,
whose relative change rates p‚Ä≤
i/pi are functions not only of the species‚Äô respective
features (k1, k2 > 0), but also of the number of antagonist individuals present on
the territory (Œ≤1, Œ≤2 > 0).
At last, we mention a source ‚Äì intrinsic, so to say, to diÔ¨Äerential modelling ‚Äì of
very large systems of diÔ¨Äerential equations: the discretisation with respect to the
spatial variables of partial diÔ¨Äerential equations describing evolution phenomena.
A straightforward example is the heat equation
‚àÇu
‚àÇt ‚àík ‚àÇ2u
‚àÇx2 = 0 ,
0 < x < L , t > 0 ,
(10.1)
controlling the termperature u = u(t) of a metal bar of length L in time. Dividing
the bar in n + 1 parts of width Œîx by points xj = jŒîx, 0 ‚â§j ‚â§n + 1 (with
(n + 1)Œîx = L), we can associate to each node the variable uj = uj(t) telling
how the temperature at xj changes in time. Using Taylor expansions, the second
spatial derivative can be approximated by a diÔ¨Äerence quotient
‚àÇ2u
‚àÇx2 (xj, t) ‚àºuj‚àí1(t) ‚àí2uj(t) + uj+1(t)
Œîx2
,
so equation (10.1) is well approximated by a system of n linear ordinary diÔ¨Äerential
equations, one for each internal node:
u‚Ä≤
j ‚àí
k
Œîx2 (uj‚àí1 ‚àí2uj + uj+1) = 0 ,
1 ‚â§j ‚â§n .
The Ô¨Årst and last equation of the system contain the temperatures u0 and un+1 at
the bar‚Äôs ends, which can be Ô¨Åxed by suitable boundary conditions (e.g., u0(t) = œÜ,
un+1(t) = œà if the temperatures at the ends are kept constant by thermostats).

424
10 Ordinary diÔ¨Äerential equations
10.2 General deÔ¨Ånitions
We introduce Ô¨Årst of all ‚Äòscalar‚Äô diÔ¨Äerential equations (those with one unknown),
for the beneÔ¨Åt of readers who have not seen them in other courses.
An ordinary diÔ¨Äerential equation (ODE is the standard acronym) is a
relationship between a real independent variable (here, t), an unknown function
y = y(t), and the derivatives y(k) up to order n
F(t, y, y‚Ä≤, ..., y(n)) = 0,
(10.2)
where F is a real map of n + 2 real variables. The diÔ¨Äerential equation has order
n, if n is the highest order of the derivatives of y appearing in (10.2). A solution
(in the classical sense) of the diÔ¨Äerential equation on the real interval J is a map
y : J ‚ÜíR, diÔ¨Äerentiable n times on J, such that
F(t, y(t), y‚Ä≤(t), ..., y(n)(t)) = 0
for all t ‚ààJ.
Using (10.2) it is often useful to write the highest derivative y(n) in terms of
t and the other derivatives (in several applications this is precisely the way a dif-
ferential equation is typically written). In general, the Implicit Function Theorem
(Sect. 7.1) makes sure that equation (10.2) can be solved for y(n) when the partial
derivative of F in the last variable is non-zero. If so, (10.2) reads
y(n) = f(t, y, ..., y(n‚àí1)),
(10.3)
with f a real map of n+1 real variables. Then one says the diÔ¨Äerential equation is
in normal form. The deÔ¨Ånition of solution for normal ODEs changes accordingly.
As the warm-up examples have shown, beside single equations also systems of
diÔ¨Äerential equations are certainly worth studying. The simplest instance is that
of a system of order one in n unknowns, written in normal form as
‚éß
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é©
y‚Ä≤
1 = f1(t, y1, y2, . . . , yn)
y‚Ä≤
2 = f2(t, y1, y2, . . . , yn)
...
y‚Ä≤
n = fn(t, y1, y2, . . . , yn) ,
(10.4)
where fi is a function of n + 1 variables. The vectorial notation
y‚Ä≤ = f(t, y)
(10.5)
where y = (yi)1‚â§i‚â§n and f = (fi)1‚â§i‚â§n is quite convenient. A solution is now
understood as a vector-valued map y : J ‚ÜíRn, diÔ¨Äerentiable on J and satisfying
y‚Ä≤(t) = f

t, y(t)

for all t ‚ààJ .

10.2 General deÔ¨Ånitions
425
An especially relevant case is that of linear systems
‚éß
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é©
y‚Ä≤
1 = a11(t)y1 + a12(t)y2 + . . . + a1n(t)yn + b1(t)
y‚Ä≤
2 = a21(t)y1 + a22(t)y2 + . . . + a2n(t)yn + b2(t)
...
y‚Ä≤
n = an1(t)y1 + an2(t)y2 + . . . + ann(t)yn + bn(t) ,
or, in compact form,
y‚Ä≤ = A(t)y + b(t)
(10.6)
where A(t) =

aij(t)

1‚â§i,j‚â§n maps J to the vector space Rn,n or square n √ó n
matrices, and b(t) =

bi(t)

1‚â§i‚â§n is a map from J to Rn. First-order linear equa-
tions play a particularly important role, both theoretically and in view of the
applications: on one hand, they describe many problems that are linear in nature,
on the other hand they approximate more complicated, non-linear equations by a
linearisation process (see Remark 10.25).
In writing a diÔ¨Äerential equation like (10.5) or (10.6), it is customary not to
write the t-dependency of the solution y explicitly.
Systems of Ô¨Årst order are the main focus of our study, because they capture
many types of diÔ¨Äerential equations provided one adds the necessary number of
unknowns. Each diÔ¨Äerential equation of order n can be indeed written as a system
of order one in n unknonws. To be precise, given equation (10.3), set
yi = y(i‚àí1) ,
1 ‚â§i ‚â§n ,
i.e.,
y1 = y(0) = y
y2 = y‚Ä≤ = y‚Ä≤
1
y3 = y‚Ä≤‚Ä≤ = (y‚Ä≤)‚Ä≤ = y‚Ä≤
2
...
yn = y(n‚àí1) = (y(n‚àí2))‚Ä≤ = y‚Ä≤
n‚àí1 .
(10.7)
The diÔ¨Äerential equation then becomes
y‚Ä≤
n = f(t, y1, . . . , yn) ,
so we obtain the Ô¨Årst-order system
‚éß
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é©
y‚Ä≤
1 = y2
...
y‚Ä≤
n‚àí1 = yn
y‚Ä≤
n = f(t, y1, y2, . . . , yn) .
(10.8)

426
10 Ordinary diÔ¨Äerential equations
It is clear that any solution of equation (10.3) generates a solution y of the system,
by (10.7); conversely, if y solves the system, it is easy to convince ourselves the
Ô¨Årst component y1 is a solution of the equation. System (10.8) is then equivalent
to equation (10.3).
The generalisation of (10.4) is a system of n diÔ¨Äerential equations in n un-
knonws, where each equation has order greater or equal than 1. Every equation of
order at least two transforms into a system of Ô¨Årst order. Altogether, then, we can
always reduce to a system of order one in m ‚â•n equations and unknonws.
Let us go back to equation (10.5), and suppose it is deÔ¨Åned on the open set
Œ© = I √ó D ‚äÜRn+1, where I ‚äÜR is open and D ‚äÜRn open, connected; assume
further f is continuous on Œ©.
DeÔ¨Ånition 10.1 A solution of the diÔ¨Äerential equation (10.5) is a C1 func-
tion y = y(t) : J ‚ÜíD, with J a non-empty open interval in I, such that
y‚Ä≤(t) = f

t, y(t)

, ‚àÄt ‚ààJ.
We remark that a solution may not be deÔ¨Åned on the entire I.
A solution y(t) is therefore a diÔ¨Äerentiable curve deÔ¨Åned on J with trace con-
tained in D. The vector f

t‚àó, y(t‚àó)

, when not 0, is tangent to the curve at each
point t‚àó‚ààJ.
The graph of y(t)
G(y) =

(t, y(t)) ‚ààI √ó D ‚äÜRn+1 : t ‚ààJ

is called an integral curve of the diÔ¨Äerential equation (see Fig. 10.1).
 
 
 
 
 
 
 
 
t0
t1
t2
y2
y1
t
 
 
 
 
 
 
  
  
 
 
 
  
 
 
Figure 10.1. Integral curves of a diÔ¨Äerential equation and corresponding tangent vectors

10.2 General deÔ¨Ånitions
427
The diÔ¨Äerential equation has, in general, inÔ¨Ånitely many solutions. Typically
these depend, apart from t, upon n arbitrary constants c1, . . . , cn. We indicate
with y(t; c1, . . . , cn) the set of solutions, which is called general integral.
A natural way to select a special solution is to impose that this solution takes
at the time t0 ‚ààI a given value y0 ‚ààD. We thus consider the problem of Ô¨Ånding
y = y(t) such that
 y‚Ä≤ = f(t, y)
in J ,
y(t0) = y0 ,
(10.9)
where J is an open sub-interval of I containing t0. Since J in general depends on the
solution, it cannot be determined a priori. This kind of question is called Cauchy
problem for the diÔ¨Äerential equation, or initial value problem because it models
the temporal evolution of a physical system, which at t0, the initial moment of the
mathematical simulation, is in the conÔ¨Åguration y0. Geometrically speaking, the
condition at time t0 is equivalent to asking that the integral curve pass through the
point (t0, y0) ‚ààŒ©. A Cauchy problem may be solvable locally (on a neighbourhood
J of t0), or globally (J = I, in which case one speaks of a global solution); these
two situations will be treated in Sects. 10.4.1 and 10.4.3, respectively.
A particularly important class of ODEs is that of autonomous equations
y‚Ä≤ = f(y) ,
for which f does not depend explicitly on t. The linear system
y‚Ä≤ = Ay
with given A ‚ààRn.n, is one such example, and will be studied in Sect. 10.6. For
autonomous ODEs, the structure of solutions can be analysed by looking at their
traces in the open set D ‚äÜRn. The space Rn then represents the phase space of
the equation.
The projection of an integral curve on the phase space (Fig. 10.2)
Œì(y) =

y(t) ‚ààD : t ‚ààJ

is called an orbit or trajectory of the solution y. A solution y of the Cauchy
problem (10.9) deÔ¨Ånes an orbit passing through y0, which consists of a past tra-
jectory (t < t0) and a future trajectory (t > t0). The orbit is closed if it is closed
viewed as trace of y. Conventionally an orbit in phase space is pictured by the
streamline of the Ô¨Çow, and the orientation on it describes the generating solution‚Äôs
evolution.
Application: the simple pendulum (I). The simple (gravity) pendulum is the
idealised model of a mass m (the bob) Ô¨Åxed to the end of a massless rod of length L
suspended from a pivot (the point O). When given an initial push, the pendulum

428
10 Ordinary diÔ¨Äerential equations
y1
y2
t
t = t0
Œì(y)
G(y)
Figure 10.2. An integral curve and the orbit in phase space y1y2 of an autonomous
equation
swings back and forth on a vertical plane, and the bob describes a circle with
centre O and radius L (Fig. 10.3). In absence of external forces, e.g., air drag or
friction of sorts, the bob is subject to the force of gravity g, a vector lying on the
Ô¨Åxed plane of motion and pointing downwards. To describe the motion of m, we
use polar coordinates (r,Œ∏ ) for the point P on the plane where m belongs: the
pole is O and the unit vector i = (cos 0, sin 0) is vertical and heads downwards; let
tr = tr(Œ∏), tŒ∏ = tŒ∏(Œ∏) be the orthonormal frame, as of (6.31).
The position of P in time is given by the vector OP (t) = Ltr(Œ∏(t)), itself
determined by Newton‚Äôs law
md2OP
dt2
= g .
(10.10)
y
I
S
0
g
Œ∏
Œ∏
P
Figure 10.3. The simple pendulum

10.2 General deÔ¨Ånitions
429
Successively diÔ¨Äerentiating OP(t), with the aid of (6.39) we obtain
dOP
dt
= Ldtr
dŒ∏
dŒ∏
dt = LdŒ∏
dt tŒ∏ ,
d2OP
dt2
= Ld2Œ∏
dt2 tŒ∏ + LdŒ∏
dt
dtŒ∏
dŒ∏
dŒ∏
dt = Ld2Œ∏
dt2 tŒ∏ ‚àíL
	dŒ∏
dt

2
tr .
On the other hand, if g is the modulus of gravity‚Äôs pull, then g = mgi =
mg cos Œ∏ tr ‚àímg sin Œ∏ tŒ∏, so Newton‚Äôs law becomes
mL

‚àí
	dŒ∏
dt

2
tr + d2Œ∏
dt2 tŒ∏

= mg

cos Œ∏ tr ‚àísin Œ∏ tŒ∏

.
Taking only the angular component, with k = g/L > 0, produces the equation of
motion
d2Œ∏
dt2 + k sin Œ∏ = 0 ;
(10.11)
notice that the mass does not appear anywhere in the formula.
A mathematically more realistic model takes into account the deceleration
generated by a damping force at the point O: this will be proportional but opposite
to the velocity, and given by the vector
a = ‚àíŒ±mL dŒ∏
dt tŒ∏ ,
with Œ± > 0 ,
adding to g in Newton‚Äôs equation. As previously, the equation of motion (10.11)
becomes
d2Œ∏
dt2 + Œ±dŒ∏
dt + k sin Œ∏ = 0 .
(10.12)
An ideal (free, undamped) motion is subsumed by taking Œ± = 0, so we shall
suppose from now on Œ± ‚â•0 and k > 0.
To Ô¨Ånd the position of P at time t, we Ô¨Årst need to know its position and
velocity at the starting time, say t0 = 0. Let us then declare Œ∏0 = Œ∏(0) and
Œ∏1 = dŒ∏
dt (0), which, in essence, is the statement of an initial value problem for an
equation of order two:
‚éß
‚é™
‚é®
‚é™
‚é©
d2Œ∏
dt2 + Œ±dŒ∏
dt + k sin Œ∏ = 0 ,
t > 0 ,
Œ∏(0) = Œ∏0 ,
dŒ∏
dt (0) = Œ∏1 .
(10.13)
To capture the model‚Äôs properties, let us transform this to Ô¨Årst-order form
(10.34) by setting

430
10 Ordinary diÔ¨Äerential equations
y = (y1, y2) = (Œ∏, dŒ∏
dt ) ,
y0 = (Œ∏0, Œ∏1) ,
f(t, y) = f(y) = ( y2 , ‚àík sin y1 ‚àíŒ±y2) .
The system is autonomous, with I = R and D = R2.
(The example continues on p. 448.)
2
10.3 Equations of Ô¨Årst order
Before we undertake the systematic study of diÔ¨Äerential equations of order n,
we examine a few types of Ô¨Årst-order ODEs that stand out, in that they can be
reduced to the computation of primitive maps.
10.3.1 Equations with separable variables
One speaks of separable variables (or of a separable ODE) for equations of the
following sort
y‚Ä≤ = g(t)h(y),
(10.14)
where g is continuous in t and h continuous in y. This means the function f(t, y)
is a product of a map depending only on t and a map depending only on y, so that
the variables are ‚Äòseparate‚Äô.
If ¬Øy ‚ààR is a zero of h, h(¬Øy) = 0, the constant map y(t) = ¬Øy is a particular
integral of (10.14), for the equation becomes 0 = 0. Therefore a separable ODE
has, Ô¨Årst of all, as many integrals y(t) = constant as the number of the distinct
roots of h. These are called singular integrals of the equation.
On every interval J where h(y) does not vanish we can write (10.14) as
1
h(y)
dy
dt = g(t) .
Let H(y) be a primitive of
1
h(y) (with respect to y). The formula for diÔ¨Äerentiating
composite functions gives
d
dtH(y(t)) = dH
dy
dy
dt =
1
h(y)
dy
dt = g(t) ,
whence H(y(t)) is a primitive of g(t). Thus, given any primitive G(t) of g(t) we
will have
H(y(t)) = G(t) + c ,
c ‚ààR .
(10.15)
But since
1
h(y) = dH
dy never vanishes on J by assumption ‚Äì and thus does not
change sign, being continuous ‚Äì the map H(y) will be strictly monotone on J,

10.3 Equations of Ô¨Årst order
431
hence invertible (Vol. I, Thm. 2.8). This implies we may solve (10.15) for y(t), to
get
y(t) = H‚àí1(G(t) + c),
(10.16)
where H‚àí1 is the inverse of H. The above is the general integral of (10.14) on
every interval where h(y(t)) is not zero. But, should we not be able to attain the
analytic expression of H‚àí1(x), formula (10.16) would have a paltry theoretical
meaning. In such an event one is entitled to stop at the implicit form (10.15).
If equation (10.14) admits singular integrals, these might be of the form (10.16)
for suitable constants c. Certain singular integrals can be inferred formally from
(10.16) letting c tend to ¬±‚àû.
One recovers expression (10.15) in a formal and easy-to-remember manner
by interpreting the derivative dy
dt as a ‚Äòquotient‚Äô, in Leibniz‚Äôs notation. In fact,
dividing (10.14) by h(y) and ‚Äòmultiplying‚Äô by dt gives
dy
h(y) = g(t) dt ,
which can be then integrated

dy
h(y) =

g(t) dt.
This corresponds exactly to (10.15). At any rate the reader must not forget that
the correct proof of the formula is the aforementioned one!
Examples 10.2
i) Let us solve y‚Ä≤ = y(1 ‚àíy). If we set g(t) = 1 and h(y) = y(1 ‚àíy), the zeroes
of h determine two singular integrals y1(t) = 0 and y2(t) = 1. Next, assuming
h(y) diÔ¨Äerent from 0, we rewrite the equation as

dy
y(1 ‚àíy) =

dt,
then integrate with respect to y on the left and t on the right to obtain
log

y
1 ‚àíy
 = t + c
Exponentiating yields

y
1 ‚àíy
 = et+c = ket,
where k = ec is an arbitrary constant > 0. Therefore
y
1 ‚àíy = ¬±ket = Ket,

432
10 Ordinary diÔ¨Äerential equations
with K being any non-zero constant. Solving now for y in terms of t gives
y(t) =
Ket
1 + Ket .
In this case the singular integral y1(t) = 0 belongs to the above family of solutions
for K = 0, a value originally excluded. The other integral y2(t) = 1 arises
formally by taking the limit, for K going to inÔ¨Ånity, in the general expression.
ii) Consider the ODE
y‚Ä≤ = ‚àöy.
It has a singular integral y1(t) = 0. Separating variables gives

dy
‚àöy =

dt ,
so
2‚àöy = t + c ,
i.e.,
y(t) =
	 t
2 + c

2
,
c ‚ààR ,
where we have written c in place of c/2.
iii) The diÔ¨Äerential equation
y‚Ä≤ = et + 1
ey + 1
has g(t) = et + 1, h(y) =
1
ey + 1 > 0 for any y, so there are no singular integrals.
The separating recipe gives

(ey + 1) dy =

(et + 1) dt ,
so
ey + y = et + t + c ,
c ‚ààR .
But now we are forced to stop for it is not possible to explicitly write y as
function of the variable t.
2
10.3.2 Homogeneous equations
Homogeneous are ODEs of the type
y‚Ä≤ = œï
y
t

(10.17)
with œï = œï(z) continuous in z. The map f(t, y) depends on t and y in terms of
their ratio y
t only; equivalently, f(Œªt,Œªy ) = f(t, y) for any Œª Ã∏= 0.
A homogeneous equation can be transformed into one with separable variables
by the obvious substitution z = y
t , understood as z(t) = y(t)
t . Then y(t) = tz(t)
and y‚Ä≤(t) = z(t) + tz‚Ä≤(t), so (10.17) becomes
z‚Ä≤ = œï(z) ‚àíz
t
,

10.3 Equations of Ô¨Årst order
433
which has separable variables z and t, as required. The technique of Section 10.3.1
solves it: each solution ¬Øz of œï(z) = z gives rise to a singular integral z(t) = ¬Øz,
hence y(t) = ¬Øzt. Assuming œï(z) diÔ¨Äerent from z, instead, we have

dz
œï(z) ‚àíz =
 dt
t ,
giving
H(z) = log |t| + c
where H(z) is a primitive of
1
œï(z) ‚àíz . Indicating by H‚àí1 the inverse function, we
have
z(t) = H‚àí1(log |t| + c),
hence, returning to y, the general integral of (10.17) reads
y(t) = t H‚àí1(log |t| + c).
Example 10.3
We solve
t2y‚Ä≤ = y2 + ty + t2.
(10.18)
In normal form, this is
y‚Ä≤ =
y
t
2
+ y
t + 1,
a homogeneous equation with œï(z) = z2+z+1. The substitution y = tz generates
a separable equation
z‚Ä≤ = z2 + 1
t
.
There are no singular integrals, for z2 + 1 is always positive. Integration gives
arctan z = log |t| + c
so the general integral of (10.18) is
y(t) = t tan(log |t| + c).
The constant c can be chosen independently in (‚àí‚àû, 0) and (0, +‚àû), because
of the singularity at t = 0. Notice also that the domain of each solution depends
on the value of c.
2
10.3.3 Linear equations
The diÔ¨Äerential equation
y‚Ä≤ = a(t)y + b(t)
(10.19)

434
10 Ordinary diÔ¨Äerential equations
with a, b continuous on I, is called linear.2 The map f(t, y) = a(t)y + b(t) is
a polynomial of degree one in y with coeÔ¨Écients dependent on t. The equation
is called homogeneous if the source term vanishes identically, b(t) = 0, non-
homogeneous otherwise.
Let us start by solving the homogeneous equation
y‚Ä≤ = a(t)y.
(10.20)
It is a special case of equation with separable variables where g(t) = a(t) and
h(y) = y, see (10.14). Therefore the constant map y(t) = 0 is a solution. Apart
from that, we can separate variables
 1
y dy =

a(t) dt.
If A(t) indicates a primitive of a(t), i.e., if

a(t) dt = A(t) + c,
c ‚ààR,
(10.21)
then
log |y| = A(t) + c ,
or equivalently
|y(t)| = eceA(t) ,
so
y(t) = ¬±KeA(t),
where K = ec > 0. The particular solution y(t) = 0 is subsumed by the gen-
eral formula if we let K be 0. Therefore the solutions of the homogeneous linear
equation (10.20) are given by
y(t) = KeA(t),
K ‚ààR,
with A(t) as in (10.21).
Now we tackle the non-homogeneous case. We use the so-called method of
variation of constants, or parameters, which consists in searching for solutions of
the form
y(t) = K(t) eA(t),
where now K(t) is a function to be determined. The representation of y(t) is always
possible, for eA(t) > 0. Substituting into (10.19), we obtain
K‚Ä≤(t)eA(t) + K(t)eA(t)a(t) = a(t)K(t)eA(t) + b(t),
so
K‚Ä≤(t) = e‚àíA(t)b(t).
2 Contrary to the description of Vol. I, here we prefer to write the linear term y on the
right, to be consistent with the theory of linear systems.

10.3 Equations of Ô¨Årst order
435
Calling B(t) a primitive of e‚àíA(t)b(t),

e‚àíA(t)b(t) dt = B(t) + c,
c ‚ààR,
(10.22)
we have
K(t) = B(t) + c,
so the general solution to (10.19) is
y(t) = eA(t)
B(t) + c

,
(10.23)
with A(t) and B(t) deÔ¨Åned by (10.21) and (10.22). The integral is more often than
not found in the form
y(t) = e

a(t) dt

e‚àí

a(t) dt b(t) dt,
(10.24)
where the steps leading to the solution are clearly spelt out, namely: one has to
integrate twice in succession.
If we want to solve the Cauchy problem
 y‚Ä≤ = a(t)y + b(t)
on the interval I,
y(t0) = y0,
with t0 ‚ààI and y0 ‚ààR,
(10.25)
it might be convenient to choose as primitive of a(t) the one vanishing at t0, which
we write A(t) =
 t
t0
a(s) ds, according to the Fundamental Theorem of Integral
Calculus; the same can be done for B(t) by putting
B(t) =
 t
t0
e‚àí
 s
t0 a(u) du b(s) ds
(recall that the variables in the deÔ¨Ånite integral are arbitrary symbols). Using these
expressions for A(t) and B(t) in (10.23) we obtain y(t0) = c, hence the solution of
the Cauchy problem (10.25) will satisfy c = y0, i.e.,
y(t) = e
 t
t0 a(u) du
	
y0 +
 t
t0
e‚àí
 s
t0 a(u) du b(s) ds

.
(10.26)
Examples 10.4
i) Find the general integral of the linear equation
y‚Ä≤ = ay + b,
where a Ã∏= 0 and b are real numbers.

436
10 Ordinary diÔ¨Äerential equations
Choosing A(t) = at and B(t) = ‚àíb
ae‚àíat generates the integral
y(t) = ceat ‚àíb
a.
If a = 1 and b = 0, the formula shows that all solutions of y‚Ä≤ = y come in the
form y(t) = cet.
If we want to solve the Cauchy problem
!
y‚Ä≤ = ay + b
on [1, +‚àû),
y(1) = y0,
it is better to choose A(t) = a(t ‚àí1) and B(t) = b
a

1 ‚àíe‚àía(t‚àí1)
, so that
y(t) =
	
y0 + b
a

ea(t‚àí1) ‚àíb
a.
In case a < 0, the solution converges to ‚àíb/a (independent of the initial datum
y0) as t ‚Üí+‚àû.
ii) We Ô¨Ånd the integral curves of the ODE
ty‚Ä≤ + y = t2
that lie in the Ô¨Årst quadrant of the plane (t, y). Written as (10.19), the equation
is
y‚Ä≤ = ‚àí1
t y + t,
so a(t) = ‚àí1/t, b(t) = t. Choose A(t) = ‚àílog t, and then eA(t) = 1/t, e‚àíA(t) = t;
consequently,

e‚àíA(t)b(t) dt =

t2 dt = 1
3t3 + c.
Therefore for t > 0, the general integral reads
y(t) = 1
t
	1
3t3 + c

= 1
3t2 + c
t .
If c ‚â•0, then y(t) > 0 for any t > 0, while if c < 0, y(t) > 0 when t >
3
3|c|. 2
Remark 10.5 In the sequel it will turn out useful to consider linear equations of
the form
z‚Ä≤ = Œªz ,
(10.27)
where Œª is a complex number. We should determine the solution over the complex
Ô¨Åeld: this will be a diÔ¨Äerentiable map z = Re z + i Im z : R ‚ÜíC (i.e., its real and
imaginary parts are diÔ¨Äerentiable). Recall that the equation
d
dt eŒªt = Œª eŒªt ,
t ‚ààR
(10.28)

10.3 Equations of Ô¨Årst order
437
(proved in Vol. I, Eq. (11.30)) is still valid for Œª ‚ààC. Then we can say that any
solution of (10.27) can be written as
z(t) = c eŒªt
(10.29)
with c ‚ààC arbitrary.
2
10.3.4 Bernoulli equations
This family of equations is characterised by the following form
y‚Ä≤ = p(t)yŒ± + q(t)y , Œ±
Ã∏= 0, Œ± Ã∏= 1 ,
(10.30)
with p, q continuous on I. If Œ± > 0, the constant map 0 is a solution. Supposing
then y Ã∏= 0 and dividing by yŒ± gives
y‚àíŒ±y‚Ä≤ = p(t) + q(t)y1‚àíŒ± .
As (y1‚àíŒ±)‚Ä≤ = (1 ‚àíŒ±)y‚àíŒ±y‚Ä≤, the substitution z = y1‚àíŒ± transforms the equation
into a linear equation in z
z‚Ä≤ = (1 ‚àíŒ±)p(t) + (1 ‚àíŒ±)q(t)z ,
solvable by earlier methods.
Example 10.6
Take y‚Ä≤ = t3y2 + 2ty, a Bernoulli equation where p(t) = t3, q(t) = 2t and Œ± = 2.
The transformation suggested above reduces the equation to z‚Ä≤ = ‚àí(2tz + t3),
solved by z(t) = cet2 ‚àí(2 + t2). Hence
y(t) =
1
cet2 ‚àí(2 + t2)
solves the original equation.
2
10.3.5 Riccati equations
Equations of Riccati type crop up in optimal control problems, and have the typical
form
y‚Ä≤ = p(t)y2 + q(t)y + r(t) ,
(10.31)
where p, q, r are continuous on I. The general integral can be found provided we
know a particular integral y = u(t). In fact, putting
y = u(t) + 1
z ,
hence
y‚Ä≤ = u‚Ä≤(t) ‚àíz‚Ä≤
z2 ,

438
10 Ordinary diÔ¨Äerential equations
we obtain
u‚Ä≤(t) ‚àíz‚Ä≤
z2 = p(t)

u2(t) + 2u(t)
z
+ 1
z2

+ q(t)

u(t) + 1
z

+ r(t) .
Since u is a solution, this simpliÔ¨Åes to
z‚Ä≤ = ‚àí

2u(t)p(t) + q(t)

z ‚àíp(t) ,
and once again we recover a linear equation in the unknown z.
Example 10.7
Consider the Riccati equation
y‚Ä≤ = ty2 +
	1 ‚àí2t2
t

y + t2 ‚àí1
t
,
where
p(t) = t ,
q(t) = 1 ‚àí2t2
t
,
r(t) = t2 ‚àí1
t
.
There is a particular solution u(t) = 1. The aforementioned change of variables
gives
z‚Ä≤ = ‚àíz
t ‚àít ,
solved by
z(t) = c ‚àít3
3|t| .
It follows the solution is
y(t) = 1 +
3|t|
c ‚àít3 ,
c ‚ààR .
2
10.3.6 Second-order equations reducible to Ô¨Årst order
When a diÔ¨Äerential equation of order two does not explicitly contain the dependent
variable, as in
y‚Ä≤‚Ä≤ = f(t, y‚Ä≤) ,
(10.32)
the substitution z = y‚Ä≤ leads to the equation of order one
z‚Ä≤ = f(t, z)
in z = z(t). If the latter has a general integral z(t; c1), all solutions of (10.32) arise
from
y‚Ä≤ = z ,

10.3 Equations of Ô¨Årst order
439
hence from the primitives of z(t; c1). This introduces another integration constant
c2. The general integral of (10.32) is thus
y(t; c1, c2) =

z(t; c1) dt = Z(t; c1) + c2,
where Z(t; c1) is a particular primitive of z(t; c1).
Example 10.8
Solve the second-order equation
y‚Ä≤‚Ä≤ ‚àí(y‚Ä≤)2 = 1.
Set z = y‚Ä≤ to obtain the separable ODE
z‚Ä≤ = z2 + 1.
The general integral is arctan z = t + c1, so
z(t, c1) = tan(t + c1).
Integrating again gives
y(t; c1, c2) =

tan(t + c1) dt = ‚àílog

cos(t + c1)

+ c2 ,
c1, c2 ‚ààR .
2
Consider, at last, a second-order autonomous equation
y‚Ä≤‚Ä≤ = f(y, y‚Ä≤) .
(10.33)
We shall indicate a method for each interval I ‚äÜR where y‚Ä≤(t) has constant sign.
In such case y(t) is strictly monotone, so invertible; we may consider therefore
t = t(y) as function of y on J = y(I), and consequently everything will depend on
y as well; in particular, z = dy
dt should be thought of as map in y. Then
y‚Ä≤‚Ä≤ = dz
dt = dz
dy
dy
dt = dz
dy z ,
whereby y‚Ä≤‚Ä≤ = f(y, z) becomes
dz
dy = g(y, z) = 1
z f(y, z) .
This is of order one, y being the independent variable and z the unknown. Sup-
posing we are capable of Ô¨Ånding all its solutions z = z(y; c1), the solutions y(t)
arise from the autonomous equation of order one
dy
dt = z(y; c1) ,
coming from the deÔ¨Ånition of t.

440
10 Ordinary diÔ¨Äerential equations
Example 10.9
Find the solutions of
yy‚Ä≤‚Ä≤ = (y‚Ä≤)2
i.e.,
y‚Ä≤‚Ä≤ = (y‚Ä≤)2
y
,
(y Ã∏= 0) .
Set f(y, z) = z2
y , and solve
dz
dy = g(y, z) = z
y .
This gives z(y) = c1y, and then
dy
dt = c1y ,
whence y(t) = c2ec1t, c2 Ã∏= 0.
2
10.4 The Cauchy problem
We return to diÔ¨Äerential equations in their most general form (10.5) and discuss
the solvability of the Cauchy problem.
As in Sect. 10.2, let I ‚äÜR be an open interval and D ‚äÜRn an open connected
set. Call Œ© = I √ó D ‚äÜRn+1, and take a map f : Œ© ‚ÜíRn deÔ¨Åned on Œ©. Given
points t0 in I and y0 in D, we examine the Cauchy problem
 y‚Ä≤ = f(t, y) ,
y(t0) = y0 .
(10.34)
10.4.1 Local existence and uniqueness
Step one of our study is to determine conditions on f that guarantee the Cauchy
problem can be solved locally, by which we mean on a neighbourhood of t0.
It is remarkable that the continuity of f alone, in t and y simultaneously, is
enough to ensure the existence of a solution, as the next result, known as Peano‚Äôs
Existence Theorem, proves.
Theorem 10.10 (Peano) Suppose f is continuous on Œ©. Then there exist
a closed neighbourhood [t0 ‚àíŒ±, t0+Œ±] of t0 and a map y : [t0 ‚àíŒ±, t0 +Œ±] ‚ÜíD,
diÔ¨Äerentiable with continuity, that solves the Cauchy problem (10.34).
There is a way of estimating the size of the interval where the solution exists.
Let Ba(t0) and Bb(y0) be neighbourhoods of t0 and y0 such that the compact set
K = Ba(t0) √ó Bb(y0) is contained in Œ©, and set M =
max
(t,y)‚ààK ‚à•f(t, y)‚à•. Then the
theorem holds with Œ± = min(a, b/M).

10.4 The Cauchy problem
441
Peano‚Äôs Theorem does not claim anything on the solution‚Äôs uniqueness, and in
fact the mere continuity of f does not prevent to have inÔ¨Ånitely many solutions
to (10.34).
Example 10.11
The initial value problem
!
y‚Ä≤ = 3
2
3‚àöy ,
y(0) = 0 ,
solvable by separating variables, admits solutions y(t) = 0 (the singular integral)
and y(t) =
‚àö
t3; actually, there are inÔ¨Ånitely many solutions, some of which
y(t) = yŒ±(t) =
 0
if t ‚â§Œ± ,

(t ‚àíŒ±)3
if t > Œ± ,
Œ± ‚â•0 ,
are obtained by ‚Äòglueing‚Äô the previous two in a suitable way (Fig. 10.4).
2
That is why we need to add further hypotheses in order to grant uniqueness,
besides requiring the solution depend continuously on the initial datum.
A very common assumption is this one:
DeÔ¨Ånition 10.12 A map f deÔ¨Åned on Œ© = I √ó D is said Lipschitz in y,
uniformly in t, over Œ©, if there exists a constant L ‚â•0 such that
‚à•f(t, y1) ‚àíf(t, y2)‚à•‚â§L‚à•y1 ‚àíy2‚à•,
‚àÄy1, y2 ‚ààD, ‚àÄt ‚ààI .
(10.35)
t
y
Œ±
yŒ±(t)
Figure 10.4. The inÔ¨Ånitely many solutions of the Cauchy problem relative to Ex-
ample 10.11

442
10 Ordinary diÔ¨Äerential equations
Using Proposition 6.4 for every t ‚ààI, it is easy to see that a map is Lipschitz if
all its components admit bounded yj-derivatives on Œ©:
sup
(t,y)‚ààŒ©

‚àÇfi
‚àÇyj
(t, y)
 < +‚àû,
1 ‚â§i, j ‚â§n .
Examples 10.13
i) Let us consider the function f(t, y) = y2, deÔ¨Åned and continuous on R √ó R.
Then ‚àÄy1, y2 ‚ààR and ‚àÄt ‚ààR,
|f(t, y1) = f(t, y2)| = |y2
1 ‚àíy2
2| = |y1 + y2| |y1 ‚àíy2| .
Hence f is Lipschitz in the variable y, uniformly in t, on every domain Œ© =
Œ©R = R √ó DR with DR = (‚àíR, R), R > 0; the corresponding Lipschitz constant
L = LR equals LR = 2R. Note that the function is not Lipschitz on R √ó R,
because |y1 + y2| tends to +‚àûas y1 and y2 tend to inÔ¨Ånity with the same sign.
ii) Consider now the map f(t, y) = sin(ty), deÔ¨Åned and continuous on R √ó R. It
satisÔ¨Åes
| sin(ty1) ‚àísin(ty2)| ‚â§|(ty1) ‚àí(ty2)| = |t| |y1 ‚àíy2| ,
‚àÄy1, y2 ‚ààR, ‚àÄt ‚ààR, because Œ∏ ‚Üísin Œ∏ is Lipschitz on R with constant 1.
Therefore f is Lipschitz in y, uniformly in t, on every region Œ© = Œ©R = IR √ó R,
with IR = (‚àíR, R), R > 0, with Lipschitz constant L = LR = R. Again, f is
not Lipschitz on the whole R √ó R.
iii) Finally, let us consider the aÔ¨Éne map f(t, y) = A(t)y + b(t), where A(t) ‚àà
Rn,n, b(t) ‚ààRn are deÔ¨Åned and continuous on the open interval I ‚äÜR. Then f
is deÔ¨Åned and continuous on I √ó Rn. For any y1, y2 ‚ààRn and any t ‚ààI, we have
‚à•f(t, y1) ‚àíf(t, y2)‚à•= ‚à•A(t)y1 ‚àíA(t)y2‚à•
= ‚à•A(t)(y1 ‚àíy2)‚à•‚â§‚à•A(t)‚à•‚à•y1 ‚àíy2‚à•,
where ‚à•A(t)‚à•is the norm of the matrix A(t) deÔ¨Åned in (4.9), and the inequality
follows from (4.10). Observe that the map Œ±(t) = ‚à•A(t)‚à•is continuous on I (as
composite of continuous maps). If Œ± is bounded, f is Lipschitz in y, uniformly
in t on Œ© = I √ó R, with Lipschitz constant L = supt‚ààI Œ±(t). If not, we can at
least say Œ± is bounded on every closed and bounded interval J ‚äÇI (Weierstrass‚Äô
Theorem), so f is Lipschitz on every Œ© = J √ó Rn.
2
The next result is of paramount importance. It is known as the Theorem of
Cauchy-Lipschitz (or Picard-Lindel¬®of).
Theorem 10.14 (Cauchy-Lipschitz) Let f(t, y) be continuous on Œ© and
Lipschitz in y, uniformly in t. Then the Cauchy problem (10.34) admits one,
and only one, solution y = y(t) deÔ¨Åned on a closed neighbourhood [t0‚àíŒ±, t0+
Œ±] of t0, with values in Œ©, and diÔ¨Äerentiable with continuity on Œ©.

10.4 The Cauchy problem
443
 
 
 
 
t0
y0
D
t
y
(t, y(t))
Œ©
I
Figure 10.5. Local existence and uniqueness of a solution
The solution‚Äôs uniqueness and its dependency upon the initial datum are con-
sequences of the following property.
Proposition 10.15 Under the assumptions of the previous theorem, let y,
z be solutions of the Cauchy problems
 y‚Ä≤ = f(t, y) ,
y(t0) = y0 ,
and
 z‚Ä≤ = f(t, z) ,
z(t0) = z0 ,
over an interval J containing t0, for given y0 and z0 ‚ààD. Then
‚à•y(t) ‚àíz(t)‚à•‚â§eL|t‚àít0|‚à•y0 ‚àíz0‚à•,
‚àÄt ‚ààJ .
(10.36)
In particular, if z0 = y0, z coincides with y on J.
What the property is saying is that the solution of (10.34) depends in a continuous
way upon the initial datum y0: a small deformation Œµ of the initial datum perturbs
the solution at t Ã∏= t0 by eL|t‚àít0|Œµ at most. In other words, the distance between
two orbits at time t grows by a factor not larger than eL|t‚àít0|. Since this factor
is exponential, its magnitude depends on the distance |t ‚àít0| as well as on the
Lipschitz constant of f.
For certain equations it is possible to replace eL|t‚àít0| with eœÉ(t‚àít0) if t > t0,
or eœÉ(t0‚àít) if t < t0, with œÉ < 0 (see Example 10.22 ii) and Sect. 10.8.1). In these
cases the solutions move towards one another exponentially.
Remark 10.16 Assume that a mathematical problem is formalised as
P(s) = d
where d is the datum and s the solution. Whenever s
‚Ä¢
exists for any datum d,
‚Ä¢
is unique, and

444
10 Ordinary diÔ¨Äerential equations
‚Ä¢
depends upon d with continuity,
the problem is said to be well posed (in the sense of Hadamard).
Theorem 10.14 and the subsequent proposition guarantee the Cauchy prob-
lem (10.34) is well posed with the assumptions made on f.
2
From the Theorem of Cauchy-Lipschitz we infer important consequences of
qualitative nature regarding the solution set of the diÔ¨Äerential equation. To be
precise, its hypotheses imply:
‚Ä¢
two integral curves with a common point must necessarily coincide (by unique-
ness of the solution on the neighbourhood of every common point);
‚Ä¢
for autonomous systems in particular, the orbits Œì(y), as y varies among
solutions, form a disjoint partition of phase space; it can be proved that an
orbit is closed if and only if the corresponding solution is periodic in time,
y(t + T ) = y(t), for all t ‚ààR and a suitable T > 0;
‚Ä¢
the solutions on Œ© of the ODE depend on n real parameters, as anticipated
in Sect. 10.2: given any t0 ‚ààI, there is a distinct solution for every choice of
datum y0 on the open set D, and the coordinates c1 = y01, . . . , cn = y0n of y0
should be considered as the free parameters upon which the solution depends.
10.4.2 Maximal solutions
The Theorem of Cauchy-Lipschitz ensures the existence of a closed interval [t0 ‚àí
Œ±, t0 + Œ±], containing t0, where the problem (10.34) is solvable; we shall call u =
u(t) the corresponding solution henceforth. However, this interval might not be
the largest interval containing t0 where the problem can be solved (the maximal
interval of existence). In fact, suppose t1 = t0 + Œ± lies inside I and y1 = u(t1) is
inside D. Then we can re-ignite the Cauchy problem at t1
 y‚Ä≤ = f(t, y) ,
y(t1) = y1 .
(10.37)
Because the assumptions of Theorem 10.14 are still valid, the new problem has a
unique solution v = v(t) deÔ¨Åned on an interval [t1 ‚àíŒ≤, t1 + Œ≤] ‚äÜI. Both functions
u, v solve the ODE and satisfy the condition u(t1) = y1 = v(t1) on the interval
J = [t0, t1] ‚à©[t1 ‚àíŒ≤, t1], which contains a left neighbourhood of t1 (see Fig. 10.6).
Therefore they must solve problem (10.37) on J. We can use inequality (10.36)
with t0 replaced by t1, to obtain
‚à•u(t) ‚àív(t)‚à•‚â§eL|t1‚àít0|‚à•y1 ‚àíy1‚à•= 0 ,
‚àÄt ‚ààJ ;
that shows v must coincide with u on J. Since v is also deÔ¨Åned on the right of t1,
we may consider the prolongation
Àúu(t) =
 u(t)
in [t0 ‚àíŒ±, t0 + Œ±] ,
v(t)
in [t0 + Œ±, t0 + Œ± + Œ≤] ,

10.4 The Cauchy problem
445
t
y
y0
y1
u(t)
v(t)
J
t0
t0 ‚àíŒ±
t1 = t0 + Œ±
t1 ‚àíŒ≤
t1 + Œ≤
Figure 10.6. Prolongation of a solution beyond t1
that extends the previous solution to the interval [t0 ‚àíŒ±, t0 + Œ± + Œ≤]. A similar
prolongation to the left of t0 ‚àíŒ± is possible if t0 ‚àíŒ± is inside I and u(t0 ‚àíŒ±) still
lies in D.
The procedure thus described may be iterated so that to prolong u to an open
interval Jmax = (t‚àí, t+), where, by deÔ¨Ånition:
t‚àí= inf{t‚àó‚ààI : problem (10.34) has a solution on [t‚àó, t0]}
and
t+ = sup{t‚àó‚ààI : problem (10.34) has a solution on [t0, t‚àó]} .
This determines precisely the maximal interval on which a solution u to prob-
lem (10.34) lives.
Suppose t+ is strictly less than the least upper bound of I (so that the solution
cannot be extended beyond t+, despite f is continuous and Lipschitz in y). Then
 
 
 
 
t
y
t+
t0
D
Figure 10.7. Right limit t+ of the maximal interval Jmax for the solution of a Cauchy
problem

446
10 Ordinary diÔ¨Äerential equations
one could prove u(t) moves towards the boundary ‚àÇD as t tends to t+ (from the
left), see Fig. 10.7. Similar considerations hold for t‚àí.
Example 10.17
Consider the Cauchy problem
!
y‚Ä≤ = y2 ,
y(0) = y0 .
The Lipschitz character of f(t, y) = y2 was discussed in Example (10.13) i):
for any R > 0 we know f is Lipschitz on Œ©R = R √ó DR, DR = (‚àíR, R). The
problem‚Äôs solution is
y(t) =
y0
1 ‚àíy0t .
If y0 ‚ààDR, it is not hard to check that the maximal interval of existence in DR,
i.e., the set of t for which y(t) ‚ààDR, is
Jmax =
‚éß
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é©
( ‚àí‚àû, 1
y0
‚àí1
R)
if y0 > 0 ,
(‚àí‚àû, +‚àû)
if y0 = 0 ,
( 1
y0
+ 1
R, +‚àû)
if y0 < 0 .
Notice that limt‚Üít+ y(t) = R when y0 > 0, conÔ¨Årming that the solution reaches
the boundary of DR as t ‚Üít+.
2
10.4.3 Global existence
We wish to Ô¨Ånd conditions on f that force every solution of (10.34) to be deÔ¨Åned
on the whole interval I. A solution for which Jmax = I is said to exist globally,
and called a global solution.
The petty example of an autonomous system in dimension 1,
y‚Ä≤ = f(y) ,
is already suÔ¨Écient to show the various possibilities. The map f(t, y) = f(y) =
ay + b is Lipschitz on all R √ó R, and the corresponding ODE‚Äôs solutions
y(t) = ceat ‚àíb
a
are deÔ¨Åned on R (see Example 10.4 i)). In contrast, f(t, y) = f(y) = y2 is not
Lipschitz on the entire R2 (Example 10.13 i)) and its non-zero solutions exist on
semi-bounded intervals (Example 10.17). The linear example is justiÔ¨Åed by the
following suÔ¨Écient condition for global existence.
Theorem 10.18 Let Œ© = I √ó Rn and assume Theorem 10.14 holds. Then
the solution of the Cauchy problem (10.34) is deÔ¨Åned everywhere on I.

10.4 The Cauchy problem
447
This result is coherent with the fact, remarked earlier, that if the supremum t+
of Jmax is not the supremum of I, the solution converges to the boundary of D,
as t ‚Üít+ (and analogously for t‚àí). In the present situation D = Rn has empty
boundary, and therefore the end-points of Jmax must coincide with those of I.
Being globally Lipschitz imposes a severe limitation on the behaviour of f as
y ‚Üí‚àû: f can grow, but not more than linearly. In fact if we choose y1 = y ‚ààRn
arbitrarily, and y2 = 0 in (10.35), we deduce
‚à•f(t, y) ‚àíf(t, 0)‚à•‚â§L‚à•y‚à•,
‚àÄy ‚ààRn .
The triangle inequality then yields
‚à•f(t, y)‚à•= ‚à•f(t, 0) + f(t, y) ‚àíf(t, 0)‚à•
‚â§‚à•f(t, 0)‚à•+ ‚à•f(t, y) ‚àíf(t, 0)‚à•,
so necessarily
‚à•f(t, y)‚à•‚â§‚à•f(t, 0)‚à•+ L‚à•y‚à•,
y ‚ààRn .
Observe that f continuous on Œ© forces the map Œ≤(t) = ‚à•f(t, 0)‚à•to be continuous
on I.
Consider the autonomous equation
y‚Ä≤ = y log2 y ,
for which f(t, y) = f(y) = y log2 y grows slightly more than linearly as y ‚Üí+‚àû.
The solutions
y(t) = e‚àí1/(x+c)
are deÔ¨Åned over not all of R, showing that a growth that is at most linear is close
to being optimal. Still, we can achieve some level of generalisation in this direction.
We may attain the same result as Theorem 10.18, in fact, imposing that f
grows in y at most linearly, and weakening the Lipschitz condition on I √ó Rn;
precisely, it is enough to have f locally Lipschitz (in y) over Œ©. Equivalently, f
is Lipschitz in y, uniformly in t, on every compact set K in Œ©; if so, the Lipschitz
constant LK may depend on K. All maps considered in Examples 10.13 are indeed
locally Lipschitz (on R √ó R for the Ô¨Årst two examples, on I √ó Rn for the last).
Theorem 10.19 Let f be continuous and locally Lipschitz in y, uniformly
in t, over Œ© = I √ó Rn; assume
‚à•f(t, y)‚à•‚â§Œ±(t)‚à•y‚à•+ Œ≤(t) ,
‚àÄy ‚ààRn, ‚àÄt ‚ààI .
(10.38)
with Œ±,Œ≤ continuous and non-negative on I. Then the solution to the Cauchy
problem (10.34) is deÔ¨Åned everywhere on I.
Moreover, if Œ± and Œ≤ are integrable on I (improperly, possibly), every solution
is bounded on I.

448
10 Ordinary diÔ¨Äerential equations
A crucial application regards linear systems.
Corollary 10.20 Let A(t) ‚ààRn,n, b(t) ‚ààRn be continuous on the open
interval I ‚äÜR. Then any solution of the system of ODEs
y‚Ä≤ = A(t)y + b(t)
is deÔ¨Åned on the entire I. In particular, the corresponding Cauchy prob-
lem (10.34) with arbitrary y0 ‚ààRn admits one, and one only, solution over
all of I.
Proof.
The map f(t, y) = A(t)y + b(t) is locally Lipschitz on I √ó Rn, by Ex-
ample 10.13 iii). Following that argument,
‚à•f(t, y)‚à•‚â§‚à•A(t)‚à•‚à•y‚à•+ ‚à•b(t)‚à•,
‚àÄy ‚ààRn, ‚àÄt ‚ààI ,
and Œ±(t) = ‚à•A(t)‚à•, Œ≤(t) = ‚à•b(t)‚à•are continuous by hypothesis. The claim
follows from the previous theorem.
2
Application: the simple pendulum (II). Let us resume the example of p. 430.
The map f(y) has
Jf(y) =
	
0
1
‚àík cos y1 ‚àíŒ±

so the Jacobian‚Äôs components are uniformly bounded on R2, for

‚àÇfi
‚àÇyj
(y)
 ‚â§max(k,Œ±) ,
‚àÄy ‚ààR2 ,
1 ‚â§i, j ‚â§2 ;
then f is Lipschitz on the whole of R2. Theorems 10.14, 10.18 guarantee existence
and uniqueness for any (Œ∏0, Œ∏1) ‚ààR2, and the solution exists for all t > 0.
(Continues on p. 453.)
2
10.4.4 Global existence in the future
Many concrete applications require an ODE to be solved ‚Äòin the future‚Äô, rather
than ‚Äòin the past‚Äô: it is important, namely, to solve for all t > t0, and the aim is
to ensure the solution exists on some interval J bounded by t0 on the left (e.g.,
[t0, +‚àû)), whereas the solution for t < t0 is of no interest. The next result cashes
in on a special feature of f to warrant the global existence of the solution in the
future to an initial value problem.
A simple example will help us to understand. The autonomous problem

y‚Ä≤ = ‚àíy3 ,
y(0) = y0 ,

10.4 The Cauchy problem
449
is determined by f(y) = ‚àíy3: this is locally Lipschitz on R, and clearly grows faster
than a linear map as y ‚Üí‚àû; therefore it does not fulÔ¨Åll the previous theorems,
as the solution
y(t) =
y0

1 + 2y2
0t
,
(10.39)
not deÔ¨Åned on the entire R, conÔ¨Årms. Yet y exists on [0, +‚àû), whichever the initial
datum y0. The fact that the solution does not ‚Äòblow up‚Äô, as t increases, can be
derived directly from the diÔ¨Äerential equation, even without solving. Just multiply
the ODE by y and observe
yy‚Ä≤ = 1
22y dy
dt = d
dt
	1
2y2

;
then
d
dt
	1
2y2

= ‚àíy4 ‚â§0 ,
i.e., the quantity E(y(t)) = 1
2|y(t)|2 is non-increasing as t grows. In particular,
1
2|y(t)|2 ‚â§1
2|y(0)|2 = 1
2|y0|2 ,
‚àÄt ‚â•0 ,
so
|y(t)| ‚â§|y0| ,
‚àÄt ‚â•0 .
At all ‚Äòfuture‚Äô instants the solution‚Äôs absolute value is bounded by the initial value,
which can also be established from the analytic expression (10.39).
The argument relies heavily on the sign of f(y) (Ô¨Çipping from ‚àíy3 to +y3
invalidates the result); this property is not ‚Äòseen‚Äô by other conditions like (10.35)
or (10.38), which involve the norm of f(t, y).
This example is somehow generalised by a condition for global existence in the
future.
Proposition 10.21 Let f be continuous and locally Lipschitz in y, uniformly
in t, on Œ© = I √ó Rn. If
y ¬∑ f(t, y) ‚â§0 ,
‚àÄy ‚ààRn ,
‚àÄt ‚ààI ,
(10.40)
the solution of the Cauchy problem (10.34) exists everywhere to the right of
t0, hence on J = I ‚à©[t0, +‚àû). Moreover, one has
‚à•y(t)‚à•‚â§‚à•y0‚à•,
‚àÄt ‚ààJ .
(10.41)
Proof.
Dot-multiply the ODE by y:
y ¬∑ y‚Ä≤ = y ¬∑ f(t, y) .

450
10 Ordinary diÔ¨Äerential equations
As
y ¬∑ y‚Ä≤ =
n

i=1
yi
dyi
dt = 1
2
n

i=1
d
dty2
i = 1
2
d
dt‚à•y‚à•2 ,
we have
d
dt
	1
2‚à•y‚à•2

‚â§0 ,
whence ‚à•y(t)‚à•‚â§‚à•y0‚à•for any t > t0 where the solution exists. Thus we
may use the Local Existence Theorem to extend the solution up to the
right end-point of I.
2
A few examples will shed light on (10.40).
Examples 10.22
i) Let y‚Ä≤ = Ay, with A a real skew-symmetric matrix, in other words A satisÔ¨Åes
AT = ‚àíA. Then
y ¬∑ f(y) = y ¬∑ Ay = 0 ,
‚àÄy ‚ààRn ,
because y ¬∑ Ay = yT Ay = (Ay)T y = yT AT y = ‚àíyT Ay, so this quantity must
be zero. Hence
d
dt
	1
2‚à•y‚à•2

= 0 ,
i.e., the map E(y(t)) = 1
2‚à•y(t)‚à•2 is constant in time. We call it a Ô¨Årst integral
of the diÔ¨Äerential equation, or an invariant of motion. The diÔ¨Äerential system is
called in this case conservative.
ii) Take y‚Ä≤ = ‚àí(Ay + g(y)), with A a symmetric, positive-deÔ¨Ånite matrix, and
g(y) of components

g(y)

i = œÜ(yi) ,
1 ‚â§i ‚â§n ,
where œÜ : R ‚ÜíR is continuous, œÜ(0) = 0 and sœÜ(s) ‚â•0, ‚àÄs ‚ààR (e.g., œÜ(s) = s3
an in the initial discussion). Recalling (4.18), we have
y ¬∑ f(y) = ‚àí(y ¬∑ Ay + y ¬∑ g(y)) ‚â§‚àíy ¬∑ Ay ‚â§‚àíŒª‚àó‚à•y‚à•2 ‚â§0 ,
‚àÄy ‚ààRn ,
with Œª‚àó> 0. Setting as above E(y) = 1
2‚à•y‚à•2, one has
d
dt E(y(t)) ‚â§‚àíŒª‚àó‚à•y(t)‚à•2 ,
‚àÄt > t0 ,
from which we deduce
E(y(t)) ‚â§e‚àí2Œª‚àó(t‚àít0)E(y0) ,
‚àÄt > t0 ;
therefore E(y(t)) decays exponentially at t increases. Equivalently,
‚à•y(t)‚à•‚â§e‚àíŒª‚àó(t‚àít0)‚à•y0‚à•,
t > t0 ,
and all solutions converge exponentially to 0 as t ‚Üí+‚àû. In Sect. 10.8 we shall
express this by saying the constant solution y = 0 is asymptotically uniformly
stable, and speak of a dissipative system.

10.4 The Cauchy problem
451
Assuming furthermore œÜ convex, one could prove that two solutions y, z starting
at y0, z0 satisfy
‚à•y(t) ‚àíz(t)‚à•‚â§e‚àíŒª‚àó(t‚àít0)‚à•y0 ‚àíz0‚à•,
t > t0 ,
a more accurate inequality than (10.36) for t > t0.
The map y ‚ÜíE(y) is an example of a Lyapunov function for the diÔ¨Äerential
system, relative to the origin. The name denotes any regular map V : B(0) ‚ÜíR,
where B(0) is a neighbourhood of the origin, satisfying
‚Ä¢
V (0) = 0 ,
V (y) > 0 on B(0) \ {0} ,
‚Ä¢
d
dt V (y(t)) ‚â§0 for any solution y of the ODE on B(0).
2
10.4.5 First integrals
Take an autonomous equation y‚Ä≤ = f(y), with Lipschitz f : D ‚äÜRn ‚ÜíRn.
DeÔ¨Ånition 10.23 A scalar map Œ¶ : D ‚ÜíR is a Ô¨Årst integral of the
equation if Œ¶ is constant along every orbit of the diÔ¨Äerential equation, i.e.,
Œ¶(y(t)) = constant
for every solution y(t) of the ODE.
A Ô¨Årst integral is naturally deÔ¨Åned up to an additive constant.
If the equation has a Ô¨Årst integral Œ¶, each orbit will be contained in a level set of
Œ¶. The study of level sets can then provide useful informations about the solution‚Äôs
global existence. For instance, if the orbit of a particular solution belongs to a level
set that does not touch the boundary of D, we can be sure the solution will exist
at any time.
Likewise, the study of the solutions‚Äô asymptotic stability (see Sect. 10.8) could
proÔ¨Åt from what the level sets of a Ô¨Årst integral can tell.
To start with, consider the autonomous equation of order two
y‚Ä≤‚Ä≤ + g(y) = 0 ,
(10.42)
where g : R ‚ÜíR is C1. Such kind of equations play a paramount role in Mechanics
(read, Newton‚Äôs law of motion). Another incarnation is equation (10.11) regulating
a simple pendulum.
Let Œ† be an arbitrary primitive of g on R, so that dŒ†
dy (y) = g(y) , ‚àÄy ‚ààR. If
y = y(t) is a solution for t ‚ààJ then, we can multiply (10.42) by y‚Ä≤, to get
d
dt
	dy
dt

 dy
dt + dŒ†
dy
dy
dt = 0 ,
i.e.,
d
dt
	1
2 (y‚Ä≤(t))2 + Œ†(y(t))

= 0 ,
‚àÄt ‚ààJ .

452
10 Ordinary diÔ¨Äerential equations
Thus
E(y, y‚Ä≤) = 1
2 (y‚Ä≤)2 + Œ†(y)
is constant for any solution. One calls Œ†(y) the potential energy of the mechan-
ical system described by the equation, and K(y‚Ä≤) = 1
2(y‚Ä≤)2 is the kinetic energy.
The total energy E(y, y‚Ä≤) = K(y‚Ä≤) + Œ†(y) is therefore preserved during motion
(the work done equals the gain of kinetic energy).
The function E turns out to be a Ô¨Årst integral, in the sense of DeÔ¨Ånition 10.23,
for the autonomous vector equation y‚Ä≤ = f(y) given by
 y‚Ä≤
1 = y2
y‚Ä≤
2 = ‚àíg(y1) ,
(10.43)
equivalent to (10.42) by putting y1 = y, y2 = y‚Ä≤. In other words Œ¶(y) = E(y1, y2) =
1
2y2
2 + Œ†(y1), and we may study the level curves of Œ¶ in phase space y1y2 to
understand the solutions‚Äô behaviour. At the end of the section we will see an
example, the undamped pendulum.
Generalising this picture we may say that an autonomous equation y‚Ä≤ = f(y)
over a connected open set D of the plane admits inÔ¨Ånitely many Ô¨Årst integrals if
f is the curl of a scalar Ô¨Åeld Œ¶ on D, i.e., f(y) = curl Œ¶(y).
Property 10.24 Let Œ¶ be a C1 Ô¨Åeld on D ‚äÜR2. The equation
y‚Ä≤ = curl Œ¶
(10.44)
admits Œ¶ as Ô¨Årst integral.
Proof.
If y = y(t) is a solution deÔ¨Åned for t ‚ààJ, by the chain rule
d
dtŒ¶(y) = (grad Œ¶) ¬∑ dy
dt = (grad Œ¶) ¬∑ (curl Œ¶) = 0 ,
because gradient and curl are orthogonal in dimension two.
2
Bearing in mind Sect. 7.2.1 with regard to level cuves, equation (10.44) forces y
to move along a level curve of Œ¶.
By Sect. 9.6, a suÔ¨Écient condition to have f = curl Œ¶ is that f is divergence-
free on a simply connected, open set D. In the case treated at the beginning,
f(y) = (y2, ‚àíg(y1)) = curl E(y1, y2), and div f = 0 over all D = R2.
To conclude, equation (10.44) extends to dimension 2n, if y = (y1, y2) ‚àà
Rn √ó Rn = R2n is deÔ¨Åned by a system of 2n equations

10.4 The Cauchy problem
453
‚éß
‚é™
‚é™
‚é®
‚é™
‚é™
‚é©
y‚Ä≤
1 = ‚àÇŒ¶
‚àÇy2
y‚Ä≤
2 = ‚àí‚àÇŒ¶
‚àÇy1
,
(10.45)
where Œ¶ is a map in 2n variables and each partial derivative symbol denotes the n
components of the gradient of Œ¶ with respect to the indicated vectorial variable.
Such a system is called a Hamiltonian system, and the Ô¨Årst integral Œ¶ is known
as a Hamiltonian (function) of the system. An example, that generalises (10.42),
is provided by the equation of motion of n bodies
z‚Ä≤‚Ä≤ + grad Œ†(z) = 0 ,
z ‚ààRn ,
(10.46)
with Œ† a function of n variables. Proceeding as for n = 1 we can transform the
second-order equation into a system of order one like (10.45). The Hamiltonian Œ¶
is the total energy Œ¶(y1, y2) = E(z, z‚Ä≤) = 1
2‚à•z‚Ä≤‚à•2 + Œ†(z) of the system.
When D = Rn, it can be proved that the ODE‚Äôs solutions are deÔ¨Åned at all
times if the potential energy is bounded from below.
Application: the simple pendulum (III). The example continues from p. 448.
The simple pendulum (Œ± = 0) is governed by
dŒ∏2
dt2 + k sin Œ∏ = 0 .
The equation is of type (10.42), with g(Œ∏) = k sin Œ∏; therefore the potential energy
is Œ†(Œ∏) = c‚àík cos Œ∏, with arbitrary constant c. It is certainly bounded from below,
conÔ¨Årming the solutions‚Äô existence at any instant of time t ‚ààR. The customary
choice c = k makes the potential energy vanish when Œ∏ = 2œÄ‚Ñì, ‚Ñì‚ààZ, in corres-
pondence with the lowest point S of the bob, and maximises Œ†(Œ∏) = 2k > 0 for
Œ∏ = (2‚Ñì+ 1)œÄ, ‚Ñì‚ààZ, when the highest point I is reached. With that choice the
total energy is
E(Œ∏,Œ∏ ‚Ä≤) = 1
2(Œ∏‚Ä≤)2 + k(1 ‚àícos Œ∏) ,
or
E(y1, y2) = 1
2y2
2 + k(1 ‚àícos y1)
(10.47)
in the phase space of coordinates y1 = Œ∏, y2 = Œ∏‚Ä≤. Let us examine this map on R2:
it is always ‚â•0 and vanishes at (2œÄ‚Ñì,0), ‚Ñì‚ààZ, which are thus absolute minima:
the pendulum is still in the position S. The gradient ‚àáE(y1, y2) = (k sin y1, y2) is
zero at (œÄ‚Ñì,0), ‚Ñì‚ààZ, so we have additional stationary points

(2‚Ñì+ 1)œÄ, 0

, ‚Ñì‚ààZ,
easily seen to be saddle points. The level curves E(y1, y2) = c ‚â•0, deÔ¨Åned by
y2 = ¬±

2(c ‚àík) + 2k cos y1 ,
have the following structure (see Fig. 10.8):

454
10 Ordinary diÔ¨Äerential equations
y1
y2
œÄ
‚àíœÄ
0
c > 2k
c = 2k
c < 2k
Figure 10.8. The orbits of a simple pendulum coincide with the level curves of the
energy E(y1, y2)
‚Ä¢
When c < 2k, they are closed curves encircling the minima of E; they cor-
respond to periodic oscillations between Œ∏ = ‚àíŒ∏0 and Œ∏0 (plus multiples of
2œÄ), where Œ∏0 is determined by requiring that all energy c be potential, that is
k(1 ‚àícos Œ∏0) = c.
‚Ä¢
When c = 2k, the curve‚Äôs branches connect two saddle points of E, and corres-
pond to the limit situation in which the bob reaches the top equilibrium point
I with zero velocity (in an inÔ¨Ånite time).
‚Ä¢
When c > 2k, the curves are neither closed nor bounded; they correspond to
a minimum non-zero velocity, due to which the pendulum moves past the top
point and then continues to rotate around O, without stopping.
(Continues on p. 486.)
2)
10.5 Linear systems of Ô¨Årst order
The next two sections concentrate on vectorial linear equations of order one
y‚Ä≤ = A(t)y + b(t) ,
(10.48)
where A is a map from an interval I of the real line to the vector space Rn√ón of
square matrices of order n, while b is a function from I to Rn. We shall assume A
and b are continuous in t. Equation (10.48) is shorthand writing for a system of
n diÔ¨Äerential equations in n unknown functions

10.5 Linear systems of Ô¨Årst order
455
‚éß
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é©
y‚Ä≤
1 = a11(t)y1 + a12(t)y2 + . . . + a1n(t)yn + b1(t)
y‚Ä≤
2 = a21(t)y1 + a22(t)y2 + . . . + a2n(t)yn + b2(t)
...
y‚Ä≤
n = an1(t)y1 + an2(t)y2 + . . . + ann(t)yn + bn(t) .
Remark 10.25 The concern with linear equations can be ascribed to the fact
that many mathematical models are regulated by such equations. Models based
on non-linear equations are often approximated by simpler and more practicable
linear versions, by the process of linearisation. The latter essentially consists in
arresting the Taylor expansion of a non-linear map to order one, and disregarding
the remaining part.
More concretely, suppose f is a C1 map on Œ© in the variable y and that ¬Øy(t),
t ‚ààJ ‚äÜI, is a known solution of the ODE y‚Ä≤ = f(t, y) (e.g., a constant solution
¬Øy(t) = ¬Øy0). Then the solutions y(t) that are ‚Äòclose to ¬Øy(t)‚Äô can be approximated
as follows: for any given t ‚ààJ, the expansion of y ‚Üíf(t, y) around the point ¬Øy(t)
reads
f(t, y) = f

t, ¬Øy(t)

+ Jyf

t, ¬Øy(t)

y ‚àí¬Øy(t)

+ g(t, y)
(10.49)
with g(t, y) = o

y ‚àí¬Øy(t)

for y ‚Üí¬Øy(t); Jyf denotes the Jacobian matrix of f
with respect to y only. Set
A(t) = Jyf

t, ¬Øy(t)

and note that f

t, ¬Øy(t)

= ¬Øy‚Ä≤(t), ¬Øy being a solution. Substituting (10.49) in y‚Ä≤ =
f(t, y) gives
(y ‚àí¬Øy)‚Ä≤ = A(t)(y ‚àí¬Øy) + g(t, y) ;
ignoring the inÔ¨Ånitesimal part g then, we can approximate the solution y by setting
z ‚àºy ‚àí¬Øy and solving the linear equation
z‚Ä≤ = A(t)z ;
if y0 is deÔ¨Åned by the initial condition y(t0) = y0 at t0 ‚ààJ, z will be determined
by the datum z(t0) = y0 ‚àí¬Øy(t0). Once z is known, the approximation of y(t) is
Àúy(t) = ¬Øy(t) + z(t).
In the special case of autonomous systems with a constant solution ¬Øy0, the
matrix A is not time-dependent.
2
We will show in the sequel that equation (10.48) admits exactly n linearly
independent solutions; as claimed in Sect. 10.2, therefore, the general integral
depends on n arbitrary constants that may be determined by assigning a Cauchy
condition at a point t0 ‚ààI. Furthermore, if A does not depend on t, so that the aij
are constants, the general integral can be recovered from the (possibly generalised)
eigenvalues and eigenvectors of A.
We begin by tackling the homogeneous case, in other words b = 0.

456
10 Ordinary diÔ¨Äerential equations
10.5.1 Homogeneous systems
Consider the homogeneous equation associated to (10.48), namely
y‚Ä≤ = A(t)y ,
t ‚ààI ,
(10.50)
and let us prove a key fact.
Proposition 10.26 The set S0 of solutions to (10.50) is a vector space of
dimension n.
Proof.
Since the equation is linear, any linear combination of solutions is still a
solution, making S0 a vector space.
To compute its dimension, we shall exhibit an explicit basis. To that end,
Ô¨Åx an arbitrary point t0 ‚ààI and consider the n Cauchy problems
 y‚Ä≤ = A(t)y ,
t ‚ààI ,
y(t0) = ei ,
where {ei}i=1,...,n is the canonical basis of Rn. Recalling Corollary 10.20,
each system admits a unique solution y = ui(t) of class C1 on I. The maps
ui, i = 1, . . . , n, are linearly independent: in fact, if y =
n

i=1
Œ±iui is the
zero map on I, then
n

i=1
Œ±iui(t) = 0 for any t ‚ààI, so also for t = t0
n

i=1
Œ±iui(t0) =
n

i=1
Œ±iei = 0 ,
whence Œ±i = 0, ‚àÄi, proving the linear independence of the ui.
Eventually, if y = y(t) is an element in S0, we write the vector y0 = y(t0)
as y0 =
n

i=1
y0iei; then
y(t) =
n

i=1
y0iui(t) ,
because both sides solve the equation and agree on t0, and the solution is
unique.
2
The set {ui}i=1,...,n of maps satisfying
 u‚Ä≤
i = A(t)ui ,
t ‚ààI ,
ui(t0) = ei ,
(10.51)

10.5 Linear systems of Ô¨Årst order
457
is an example of a fundamental system of solutions.
DeÔ¨Ånition 10.27 Any basis of S0 is called a fundamental system of solu-
tions of the ODE (10.50).
There is a useful way to check whether a set of n solutions to (10.50) is a
fundamental system.
Proposition 10.28 Let w1, . . . , wn ‚ààS0.
a) If at a point t0 ‚ààI the vectors w1(t0), . . . , wn(t0) are linearly independent,
w1, . . . , wn constitute a fundamental system of solutions.
b) If w1, . . . , wn form a fundamental system of solutions, at each point t0 ‚ààI
the vectors w1(t0), . . . , wn(t0) are linearly independent.
Proof.
a) It suÔ¨Éces to show that w1, . . . , wn are linearly independent. Suppose
then there exist coeÔ¨Écients ci such that
n

i=1
ciwi(t) = 0 ,
‚àÄt ‚ààI .
Choosing t = t0, the hypothesis forces every ci to vanish.
b) Suppose there exist c1, . . . , cn with
n

i=1
ciwi(t0) = 0 .
DeÔ¨Åne the map z(t) =
n

i=1
ciwi(t); since it solves the Cauchy problem
 z‚Ä≤ = Az
z(t0) = 0 ,
by uniqueness we have z(t) = 0 for any t ‚ààI. Therefore all ci must be
zero.
2
Owing to the proposition, the linear dependence of n vector-valued maps on I
reduces to the (much easier to verify) linear dependence of n vectors in Rn.
We explain now how a fundamental system permits to Ô¨Ånd all solutions
of (10.50) and also to solve the corresponding initial value problem. Given then
a fundamental system {w1, . . . , wn}, for any t ‚ààI we associate to it the n √ó n
matrix

458
10 Ordinary diÔ¨Äerential equations
W (t) =

w1(t), . . . , wn(t)

whose columns are the vectors wi(t); by part b) above, the matrix W (t) is
non-singular since its columns are linearly independent. This matrix is called
the fundamental matrix, and using it we may write the n vectorial equations
w‚Ä≤
i = A(t)wi, i = 1, . . . , n, in the compact form
W ‚Ä≤ = A(t)W .
(10.52)
Every solution y = y(t) of (10.50) is represented as
y(t) =
n

i=1
ciwi(t)
for suitable constants ci ‚ààR. Equivalently, setting c = (c1, . . . , cn)T , we have
y(t) = W(t) c .
(10.53)
The solution to the generic Cauchy problem
 y‚Ä≤ = Ay
on I ,
y(t0) = y0 ,
(10.54)
is found by solving the linear system
W(t0) c = y0 .
(10.55)
Therefore we may write the solution, formally, as
y(t) = W(t)W ‚àí1(t0) y0 .
We can simplify this by choosing the fundamental matrix U(t) associated with the
special basis {ui} deÔ¨Åned by (10.51); it arises as solution of the Cauchy problem
in matrix form
 U ‚Ä≤ = A(t)U
on I ,
U(t0) = I ,
(10.56)
and allows us to write the solution to (10.54) as
y(t) = U(t) y0 .
We put on hold, for the time being, the study of equation (10.50) to discuss
non-homogeneous systems. We will resume it in Sect. 10.6 under the hypothesis
that A be constant.

10.5 Linear systems of Ô¨Årst order
459
10.5.2 Non-homogeneous systems
Indicate by Sb the set of all solutions to (10.48). This set can be characterised
starting from a particular solution, also known as particular integral.
Proposition 10.29 Given a solution yp of equation (10.48), Sb is the aÔ¨Éne
space Sb = yp + S0.
Proof.
If y ‚ààSb, by linearity y ‚àíyp solves the homogeneous equation (10.50),
hence y ‚àíyp ‚ààS0.
2
The proposition says that for any given fundamental system w1, . . . , wn of solu-
tions to the homogeneous equation, each solution of (10.48) has the form
y(t) = W(t) c + yp(t) =
n

i=1
ciwi(t) + yp(t)
for some c = (c1, . . . , cn)T ‚ààRn.
An alternative route to arrive at the general integral of (10.48) is the method of
variation of constants, already seen in Sect. 10.3.3 for scalar equations. By (10.53)
we look for a solution of the form
y(t) = W(t) c(t)
with c(t) diÔ¨Äerentiable to be determined. Substituting, we obtain
W ‚Ä≤(t) c(t) + W(t) c‚Ä≤(t) = A(t)W(t) c(t) + b(t) .
By (10.52) we arrive at
W(t) c‚Ä≤(t) = b(t) ,
from which
c‚Ä≤(t) = W ‚àí1(t) b(t) ,
i.e.,
c(t) =

W ‚àí1(t) b(t) dt ,
(10.57)
where the indeÔ¨Ånite integral denotes the primitive of the vector W ‚àí1(t) b(t), com-
ponent by component. The general integral of (10.48) is then
y(t) = W(t)

W ‚àí1(t) b(t) dt .
(10.58)

460
10 Ordinary diÔ¨Äerential equations
Example 10.30 Consider the equation
y‚Ä≤ =

2
‚àí2
‚àí2
2

y +
‚éõ
‚éú
‚éú
‚éù
1
‚àö
1 ‚àít2 ‚àí
e4t
1 + t2
1
‚àö
1 ‚àít2 ‚àí
e4t
1 + t2
‚éû
‚éü
‚éü
‚é†.
(10.59)
A fundamental system of solutions of the homogeneous equation is
w1(t) =
	
1
1

,
w2(t) = e4t
	
1
‚àí1

(as we shall explain in the next section). The fundamental matrix and its inverse
are, thus,
W (t) =
	
1
e4t
1
‚àíe4t

,
W ‚àí1(t) = 1
2
	
1
1
e‚àí4t
‚àíe‚àí4t

.
Consequently
W ‚àí1(t)b(t) =
‚éõ
‚éú
‚éù
1
‚àö
1 ‚àít2
1
1 + t2
‚éû
‚éü
‚é†,
so

W ‚àí1(t)b(t) dt =
	 arcsint + c1
arctant + c2

.
Due to (10.58), the general integral is
y(t) =
	 arcsint + c1 + e4t(arctan t + c2)
arcsint + c1 ‚àíe4t(arctan t + c2)

.
2
Whenever we have to solve the Cauchy problem
 y‚Ä≤ = A(t)y + b(t)
on I ,
y(t0) = y0 ,
(10.60)
it is convenient to write (10.57) as
c(t) = c +
 t
t0
W ‚àí1(s) b(s) ds .
with arbitrary c ‚ààRn. Equation (10.58) then becomes
y(t) = W(t)c +
 t
t0
W(t)W ‚àí1(s) b(s) ds ;
putting t = t0 gives y(t0) = W(t0)c, so c is still determined by solving (10.55).
Altogether, the solution to the Cauchy problem is
y(t) = yhom(t) + yp(t) ,

10.6 Linear systems with constant matrix A
461
where yhom(t) = W(t)W ‚àí1(t0)y0 solves the homogeneous system (10.54), while
yp(t) =
 t
t0
W(t)W ‚àí1(s) b(s) ds
(10.61)
solves the non-homogeneous problem with null datum at t = t0.
Example 10.31 Let us solve the Cauchy problem (10.60) for the same equation
of the previous example, and with y(0) = (4, 2)T . The general integral found
earlier is
y(t) =

c1 + e4tc2
c1 ‚àíe4tc2

+

arcsin t + e4t arctant
arcsin t ‚àíe4t arctant

;
the Ô¨Årst bracket represents the solution yhom of the associated homogeneous
equation, and the second is the particular solution yp vanishing at t = 0. The
constants c1, c2 are found by setting t = 0 and solving the linear system
	
1
1
1
‚àí1

 	
c1
c2

=
	
4
2

,
whence c1 = 3 and c2 = 1.
2
10.6 Linear systems with constant matrix A
We are ready to resume equation (10.48), under the additional assumption that A
is independent of time. We wish to explain a procedure for Ô¨Ånding a fundamental
system of solutions for
y‚Ä≤ = Ay
on I = R .
(10.62)
The method relies on the computation of the eigenvalues of A, the roots of the
so-called characteristic polynomial of the equation, deÔ¨Åned by
œá(Œª) = det(A ‚àíŒªI) ,
and the corresponding eigenvectors (perhaps generalised, and deÔ¨Åned in the se-
quel).
At the heart of the whole matter lies an essential property:
if Œª is an eigenvalue of A with eigenvector v, the map
w(t) = eŒªtv
solves equation (10.62) (in C, if Œª is complex).

462
10 Ordinary diÔ¨Äerential equations
Indeed, using (10.28) and Av = Œªv, we have
w‚Ä≤(t) = d
dt

eŒªtv

= deŒªt
dt v = ŒªeŒªt v = eŒªtAv = A

eŒªtv

= Aw(t) .
At this point the treatise needs to split in three parts: Ô¨Årst, we describe the
explicit steps leading to a fundamental system, then explain the procedure by
means of examples, and at last provide the theoretical backgrounds.
To simplify the account, the case where A is diagonalisable is kept separate.
Diagonalisable matrices include prominent cases, like symmetric matrices (whose
eigenvalues and eigenvectors are real) and more generally normal matrices (see
Sect. 4.2). Only afterwards we examine the more involved situation of a matrix
that cannot be diagonalised.
In the end we illustrate a solving method for non-homogeneous equations, with
emphasis on special choices of the source term b(t).
10.6.1 Homogeneous systems with diagonalisable A
Suppose A has ‚Ñìreal eigenvalues Œª1, . . . , Œª‚Ñìand n ‚àí‚Ñìcomplex eigenvalues which,
being A real, come in m complex-conjugate pairs Œª‚Ñì+1, Œª‚Ñì+1, . . . , Œª‚Ñì+m, Œª‚Ñì+m; ei-
genvalues are repeated according to their algebraic multiplicity, hence ‚Ñì+ 2m = n.
Each real Œªk, 1 ‚â§k ‚â§‚Ñì, is associated to a real eigenvector vk, while to each pair
(Œª‚Ñì+k, Œª‚Ñì+k), 1 ‚â§k ‚â§m, corresponds a pair (v‚Ñì+k, v‚Ñì+k) of complex-conjugate
eigenvectors. As A is diagonalisable, we can assume the eigenvectors are linearly
independent (over C).
‚Ä¢
For each real eigenvalue Œªk, 1 ‚â§k ‚â§‚Ñì, deÔ¨Åne the map
wk(t) = eŒªktvk .
‚Ä¢
For each pair (Œª‚Ñì+k, Œª‚Ñì+k), 1 ‚â§k ‚â§m, we decompose eigenvalues and eigen-
vectors into real and imaginary parts: Œª‚Ñì+k = œÉk + iœâk, v‚Ñì+k = v(1)
k
+ iv(2)
k .
DeÔ¨Åne maps
w(1)
k (t) = Re

eŒª‚Ñì+ktv‚Ñì+k

= eœÉkt
v(1)
k
cos œâkt ‚àív(2)
k
sin œâkt

,
w(2)
k (t) = Im

eŒª‚Ñì+ktv‚Ñì+k

= eœÉkt
v(1)
k
sin œâkt + v(2)
k
cos œâkt

.
Proposition 10.32 With the
above
conventions,
the
set
of
functions
{w1, . . . , w‚Ñì, w(1)
1 , w(2)
1 , . . . , w(1)
m , w(2)
m } is a fundamental system of solutions
to (10.62).

10.6 Linear systems with constant matrix A
463
The general integral is then of the form
y(t) =
‚Ñì

k=1
ckwk(t) +
m

k=1

c(1)
k w(1)
k (t) + c(2)
k w(2)
k (t)

,
(10.63)
with c1, . . . , c‚Ñì, c(1)
1 , c(2)
1 , . . . , c(1)
m , c(2)
m ‚ààR.
The above is nothing but the general formula (10.53) adapted to the present situ-
ation; W (t) is the fundamental matrix associated to the system.
Examples 10.33
i) The matrix
A =
	
‚àí1
2
2
‚àí1

admits eigenvalues Œª1 = 1, Œª2 = ‚àí3 and corresponding eigenvectors
v1 =
	
1
1

and
v2 =
	
1
‚àí1

.
As a consequence, (10.63) furnishes the general integral of (10.62):
y(t) = c1et
	
1
1

+ c2e‚àí3t
	
1
‚àí1

=
	
c1et + c2e‚àí3t
c1et ‚àíc2e‚àí3t

.
For a particular solution we can consider the Cauchy problem with initial datum
y(0) = y0 =
	
2
1

for example, corresponding to the linear system
 c1 + c2 = 2
c1 ‚àíc2 = 1 .
Therefore c1 = 3/2, c2 = 1/2 and the solution reads
y(t) = 1
2
	 3et + e‚àí3t
3et ‚àíe‚àí3t

.
ii) The matrix
A =
‚éõ
‚éù
1
1
0
0
‚àí1
1
0
‚àí10
5
‚éû
‚é†
has eigenvalues Œª1 = 1, Œª2 = 2 + i and its conjugate Œª2 = 2 ‚àíi. The eigenvectors
are easy to Ô¨Ånd:
v1 =
‚éõ
‚éù
1
0
0
‚éû
‚é†,
v2 =
‚éõ
‚éù
1
1 + i
2 + 4i
‚éû
‚é†=
‚éõ
‚éù
1
1
2
‚éû
‚é†+ i
‚éõ
‚éù
0
1
4
‚éû
‚é†,
v2 =
‚éõ
‚éù
1
1
2
‚éû
‚é†‚àíi
‚éõ
‚éù
0
1
4
‚éû
‚é†.

464
10 Ordinary diÔ¨Äerential equations
Therefore (10.63) (we write c2 = c(1)
2
and c3 = c(2)
2
for simplicity), tells us that
the general integral of (10.62) is
y(t) = c1et
‚éõ
‚éù
1
0
0
‚éû
‚é†+ c2e2t
‚é°
‚é£
‚éõ
‚éù
1
1
2
‚éû
‚é†cos t ‚àí
‚éõ
‚éù
0
1
4
‚éû
‚é†sin t
‚é§
‚é¶+
+ c3e2t
‚é°
‚é£
‚éõ
‚éù
1
1
2
‚éû
‚é†sin t +
‚éõ
‚éù
0
1
4
‚éû
‚é†cos t
‚é§
‚é¶
= c1
‚éõ
‚éù
1
0
0
‚éû
‚é†et +
‚é°
‚é£c2
‚éõ
‚éù
1
1
2
‚éû
‚é†‚àíc3
‚éõ
‚éù
0
1
4
‚éû
‚é†
‚é§
‚é¶e2t cos t +
+
‚é°
‚é£‚àíc2
‚éõ
‚éù
0
1
4
‚éû
‚é†+ c3
‚éõ
‚éù
1
1
2
‚éû
‚é†
‚é§
‚é¶e2t sin t
=
‚éõ
‚éú
‚éù
c1et + c2e2t cos t + c3e2t sin t
(c2 ‚àíc3)e2t cos t + (c3 ‚àíc2)e2t sin t
(c2 ‚àí4c3)e2t cos t + (2c3 ‚àí4c2)e2t sin t
‚éû
‚éü
‚é†.
2
Explanation. Since eigenvalues and eigenvectors of A may not be real, it is
convenient to think (10.62) within the complex Ô¨Åeld. Thus we view y = y(t) as a
map from R to Cn; the real part yr(t) and the imaginary part yi(t) solve the real
systems
y‚Ä≤
r = Ayr
and
y‚Ä≤
i = Ayi
on I = R .
All subsequent operations are intended over C (clearly, complex arithmetic is
not necessary when A is diagonalisable over R, when all eigenvalues‚Äìhence all
eigenvectors‚Äìare real). Call Œõ = diag(Œª1, . . . , Œªn) the diagonal matrix with the ei-
genvalues as entries, and P = (v1, . . . , vn) the square matrix with the eigenvectors
as columns. Thus A becomes
A = P Œõ P‚àí1 .
(10.64)
Let y be an arbitrary complex solution of (10.62); substituting (10.64) in equa-
tion (10.62), and multiplying by P ‚àí1 on the left, gives

P ‚àí1y
‚Ä≤ = Œõ

P ‚àí1y

,
by associativity. Now setting
z = P ‚àí1y ,
i.e.,
y = P z ,
(10.65)

10.6 Linear systems with constant matrix A
465
equation (10.62) becomes diagonal
z‚Ä≤ = Œõz .
(10.66)
In other words we obtain n equations
z‚Ä≤
k = Œªkzk ,
1 ‚â§k ‚â§n .
By Remark 10.5 these have solutions
zk(t) = dkeŒªkt ,
1 ‚â§k ‚â§n ,
with dk ‚ààC arbitrary constants. Using the diagonal matrix
eŒõt = diag

eŒª1t, . . . , eŒªnt
(10.67)
and the constant vector d = (d1, . . . , dn)T ‚ààCn, we can write the solutions as
z(t) = eŒõtd .
Writing in terms of the unknown y, by the second equation in (10.65), we have
y(t) = P eŒõtd ;
(10.68)
it is of the general form (10.53) with W (t) = P eŒõt. Making the columns of this
matrix explicit, we have
y(t) = d1eŒª1tv1 + ¬∑ ¬∑ ¬∑ + dneŒªntvn = d1w1(t) + ¬∑ ¬∑ ¬∑ + dnwn(t) ,
(10.69)
where
wk(t) = eŒªktvk ,
1 ‚â§k ‚â§n .
The upshot is that every complex solution of equation (10.62) is a linear com-
bination (with coeÔ¨Écients in C) of the n solutions wk, which therefore are a
fundamental system in C.
To represent the real solutions, consider the generic eigenvalue Œª with eigen-
vector v. Note that if Œª ‚ààR (so v ‚ààRn), the function w(t) = eŒªtv is a real solution
of (10.62). Instead, if Œª = œÉ + iœâ ‚ààC, so v = v(1) + iv(2) ‚ààCn, the functions
w(1)(t) = Re

eŒªtv

= eœÉt
v(1) cos œât ‚àív(2) sin œât

,
w(2)(t) = Im

eŒªtv

= eœÉt
v(1) sin œât + v(2) cos œât

,
are real solutions of (10.62); this is clear by taking real and imaginary parts of the
equation and remembering A is real.
In such a way, retaining the notation of Proposition 10.32, we obtain n real
solutions
w1(t), . . . , w‚Ñì(t)
and
w(1)
1 (t), w(2)
1 (t), . . . , w(1)
m (t), w(2)
m (t) .

466
10 Ordinary diÔ¨Äerential equations
There remains to verify they are linearly independent (over R). With the help of
Proposition 10.28 with t0 = 0, it suÔ¨Éces to show v1, . . . , v‚Ñì, v(1)
1 , v(2)
1 , . . . , v(1)
m , v(2)
m
are linearly independent over R. An easy Linear Algebra exercise will show that
this fact is a consequence of the linear independence of the eigenvectors v1, . . . , vn
over C (actually, it is equivalent).
Remark 10.34 Imposing the datum y(0) = y0 for t0 = 0 in (10.68), solution of
y‚Ä≤ = Ay, we Ô¨Ånd P d = y0, so d = P ‚àí1y0. The solution of the Cauchy problem
 y‚Ä≤ = Ay
on I = R ,
y(0) = y0
can therefore be represented as
y(t) = eAty0 ,
(10.70)
where we have used the exponential matrix
eAt = P eŒõtP ‚àí1
The above formula generalises the expression y(t) = eaty0 for the solution to the
Cauchy problem y‚Ä≤ = ay, y(0) = y0 .
The representation (10.70) is valid also when A is not diagonalisable. In that
case though, the exponential matrix is deÔ¨Åned otherwise
eAt =
‚àû

k=0
1
k! (tA)k .
This formula is suggested by the power series (2.24) of the exponential function
ex; the series converges for any matrix A and for any t ‚ààR.
2
10.6.2 Homogeneous systems with non-diagonalisable A
By Œª1, . . . , Œªp we number the distinct eigenvalues of A, while Œºk denotes the algeb-
raic multiplicity of Œªk, i.e., the multiplicity as root of the characteristic polynomial
det(A‚àíŒªI). Then n = Œº1+. . .+Œºp. Call mk ‚â§Œºk the geometric multiplicity of Œªk,
that is the maximum number of linearly independent eigenvectors vk,1, . . . , vk,mk
relative to Œªk. We remind A is diagonalisable if and only if the algebraic and geo-
metric multiplicities of every eigenvalue coincide; from now on we suppose mk < Œºk
for at least one Œªk. Then it is possible to prove there are dk = Œºk ‚àímk vectors
rk,1, . . . , rk,dk, called generalised eigenvectors associated to Œªk, such that the
Œºk vectors vk,1, . . . , vk,mk, rk,1, . . . , rk,dk are linearly independent. Moreover, the
collection of eigenvectors and generalised eigenvectors, for k = 1, . . . , p, builds a
basis of Cn.

10.6 Linear systems with constant matrix A
467
Let us see how to construct generalised eigenvectors associated to Œªk. For every
eigenvector vk,‚Ñì, 1 ‚â§‚Ñì‚â§mk, deÔ¨Åne r(0)
k,‚Ñì= vk,‚Ñìand seek whether a solution of
(A ‚àíŒªkI)r = r(0)
k,‚Ñì
(10.71)
exists. The matrix A ‚àíŒªkI is singular, by deÔ¨Ånition of eigenvalue. The system
may not have solutions, in which case the eigenvector vk,‚Ñìwill not furnish gener-
alised eigenvectors. If however the system is consistent, a solution r(1)
k,‚Ñìwill be a
generalised eigenvector associated to Œªk. Now we substitute r(1)
k,‚Ñìto r(0)
k,‚Ñìin (10.71),
and repeat the argument. This will produce a cascade of linear systems
(A ‚àíŒªkI)r(1)
k,‚Ñì= r(0)
k,‚Ñì,
(A ‚àíŒªkI)r(2)
k,‚Ñì= r(1)
k,‚Ñì,
...
(10.72)
that stops once the system (A‚àíŒªkI)r = r(h)
k,‚Ñì, h ‚â•0, has no solutions. As a result,
we obtain qk,‚Ñì= h ‚àí1 generalised eigenvectors. Varying ‚Ñì= 1, . . . , mk will yield
all the dk = qk,1 + . . . + qk,mk generalised eigenvectors relative to Œªk.
Let us now move to fundamental systems of solutions for (10.62).
‚Ä¢
For every eigenvalue Œªk (1 ‚â§k ‚â§p) and associated eigenvector vk,‚Ñì(1 ‚â§‚Ñì‚â§
mk), deÔ¨Åne
w(0)
k,‚Ñì(t) = eŒªktvk,‚Ñì.
‚Ä¢
If qk,‚Ñì> 0, so if there are generalised eigenvectors r(h)
k,‚Ñì(1 ‚â§h ‚â§qk,‚Ñì), build
maps
w(1)
k,‚Ñì(t) = eŒªkt
t r(0)
k,‚Ñì+ r(1)
k,‚Ñì

= eŒªkt
t vk,‚Ñì+ r(1)
k,‚Ñì

,
w(2)
k,‚Ñì(t) = eŒªkt1
2t2r(0)
k,‚Ñì+ t r(1)
k,‚Ñì+ r(2)
k,‚Ñì

,
and so on; in general, we set
w(h)
k,‚Ñì(t) = eŒªkt
h

j=0
1
(h ‚àíj)! th‚àíjr(j)
k,‚Ñì,
1 ‚â§h ‚â§qk,‚Ñì.
Proposition 10.35 With the above notations, the set of functions {w(h)
k,‚Ñì:
1 ‚â§k ‚â§p, 1 ‚â§‚Ñì‚â§mk, 0 ‚â§h ‚â§qk,‚Ñì} is a fundamental system of solutions
over C of (10.62).

468
10 Ordinary diÔ¨Äerential equations
Hence the general integral reads
y(t) =
p

k=1
mk

‚Ñì=1
qk,‚Ñì

h=0
c(h)
k‚Ñìw(h)
k,‚Ñì(t) ,
(10.73)
with c(h)
k‚Ñì‚ààC.
If we wish to represent real solutions only, observe that Œªk ‚ààR implies all
eigenvectors (proper and generalised) are real, hence also the maps w(h)
k,‚Ñì(t), built
from them, are real. In presence of a complex-conjugate pair Œªk, Œªk‚Ä≤ = Œªk of
eigenvalues, the corresponding eigenvectors (generalised or not) will crop up in
conjugate pairs. For that reason it is enough to replace each pair of complex-
conjugate functions, deÔ¨Åned by those vectors, with their real and imaginary parts.
The construction of a real fundamental system for (10.62) is thus complete.
Remark 10.36 We have assumed A not diagonalisable. But actually the above
recipe works even when the matrix can be diagonalised (when the algebraic mul-
tiplicity is greater than 1, one cannot know a priori whether a matrix is diagon-
alisable or not, except in a few cases, e.g., symmetric matrices). If the matrix is
diagonalisable, systems (10.71) will be inconsistent, rendering (10.73) equivalent
to the solution of Sect. 10.6.1.
2
Examples 10.37
i) The matrix
A =
‚éõ
‚éù
4
0
‚àí1
1
5
1
1
0
2
‚éû
‚é†
has eigenvalues Œª1 = 5, Œª2 = 3. The Ô¨Årst has algebraic multiplicity Œº1 = 1, and
v11 = (0, 1, 0)T is the associated eigenvector. The second eigenvalue has algebraic
multiplicity Œº2 = 2 and geometric m2 = 1. The vector v21 = (1, ‚àí1, 1)T is
associated to Œª2. By solving (A‚àí3I)r = v21 we obtain a generalised eigenvector
r(1)
21 = (1, ‚àí1, 0)T which, together with v11, v21, gives a basis of R3. Therefore,
the general integral of (10.62) is
y(t) = c1e5t
‚éõ
‚éù
0
1
0
‚éû
‚é†+ c2e3t
‚éõ
‚éù
1
‚àí1
1
‚éû
‚é†+ c3e3t
‚é°
‚é£t
‚éõ
‚éù
1
‚àí1
1
‚éû
‚é†+
‚éõ
‚éù
1
‚àí1
0
‚éû
‚é†
‚é§
‚é¶.
ii) The matrix
A =
‚éõ
‚éù
3
0
0
0
3
0
1
0
3
‚éû
‚é†

10.6 Linear systems with constant matrix A
469
has a unique eigenvalue Œª = 3 with geometric multiplicity m = 2, in fact v11 =
(0, 1, 0)T and v12 = (0, 0, 1)T are linearly independent eigenvectors associated to
it. The system
(A ‚àí3I)r = v11
has no solutions, whereas
(A ‚àí3I)r = v12
gives, for instance, r(1)
12 = (1, 0, 0)T .
Hence, the general integral of (10.62) is
y(t) = c1e3t
‚éõ
‚éù
0
1
0
‚éû
‚é†+ c2e3t
‚éõ
‚éù
0
0
1
‚éû
‚é†+ c3e3t
‚é°
‚é£t
‚éõ
‚éù
0
0
1
‚éû
‚é†+
‚éõ
‚éù
1
0
0
‚éû
‚é†
‚é§
‚é¶.
iii) Consider
A =
‚éõ
‚éù
1
5
0
0
1
0
4
0
1
‚éû
‚é†
with one eigenvalue Œª = 1 and one eigenvector v11 = (0, 0, 1)T (geometric mul-
tiplicity m = 1). As the set of all eigenvectors is a basis of R3, equations (10.72)
will spawn two generalised eigenvectors. In fact
(A ‚àíI)r(1)
11 = v11
(A ‚àíI)r(2)
11 = r(1)
11
are solved by r(1)
11 = (1/4, 0, 0)T and r(2)
11 = (0, 1/20, 0)T. The general integral
reads
y(t) = c1et
‚éõ
‚éù
0
0
1
‚éû
‚é†+ c2et
‚é°
‚é£t
‚éõ
‚éù
0
0
1
‚éû
‚é†+
‚éõ
‚éù
1/4
0
0
‚éû
‚é†
‚é§
‚é¶+
+c3et
‚é°
‚é£1
2t2
‚éõ
‚éù
0
0
1
‚éû
‚é†+ t
‚éõ
‚éù
1/4
0
0
‚éû
‚é†+
‚éõ
‚éù
0
1/20
0
‚éû
‚é†
‚é§
‚é¶.
2
Explanation. All the results about eigenvectors, both proper and generalised,
can be proved starting from the so-called Jordan canonical form of a matrix,
whose study goes beyond the reach of the course.
What we can easily do is account for the linear independence of the maps
w(h)
k,‚Ñì(t) of Proposition 10.35. Taking t0 = 0 in Proposition 10.28 gives
w(h)
k,‚Ñì(0) = r(h)
k,‚Ñì
for any k, ‚Ñì, h, so the result follows from the analogue property for A.

470
10 Ordinary diÔ¨Äerential equations
10.6.3 Non-homogeneous systems
In the light of Proposition 10.29, a non-homogeneous equation
y‚Ä≤ = Ay + b(t)
(10.74)
can be solved by simply Ô¨Ånding a particular integral yp.
The method of variation of parameters, and especially formula (10.61), provides
us with a general means. However, in many situations the source term b(t) can be
broken into elementary functions like exponentials, polynomials or trigonometric
maps. Then a particular integral of the same elementary type is usually easy to
Ô¨Ånd.
Henceforth we shall call a polynomial any function p(t), q(t), . . . from R to Rn
whose components are real algebraic polynomials; a polynomial has degree m if
the maximum degree of the components is m, in which case it can be written as
q(t) = c0tm + c1tm‚àí1 + . . . + cm‚àí1t + cm ,
with cj ‚ààRn and c0 Ã∏= 0.
Let us suppose that
b(t) = eŒ±tp(t)
(10.75)
with Œ± ‚ààR and p(t) a degree-m polynomial. Then there exists a particular integral
yp(t) = eŒ±tq(t) ,
(10.76)
where q(t) is a polynomial of degree
‚Ä¢
m if Œ± is not an eigenvalue of A,
‚Ä¢
m + Œº if Œ± is an eigenvalue of algebraic multiplicity Œº ‚â•1.
Borrowing from Physics, one refers to the latter situation as resonance.
The undetermined coeÔ¨Écients of q(t) are found by substituting (10.76) in equa-
tion (10.74), simplifying the exponential terms and matching the coeÔ¨Écients of the
corresponding powers of t. This produces a series of linear systems with matrix
A‚àíŒ±I that allow to determine solutions c0, c1, . . . , cm+Œº starting from the highest
power of t. In case of resonance, A‚àíŒ±I is singular; then the Ô¨Årst system just says
that c0 is an eigenvector of A, and the other systems require compatibility condi-
tions to be solved. Example 10.38 ii) illustrates a situation of this type, detailing
the computation to be performed.
If the source term looks like
b(t) = eŒ±tp(t) cos œât
or
b(t) = eŒ±tp(t) sin œât ,
(10.77)

10.6 Linear systems with constant matrix A
471
with Œ± ‚ààR, p(t) a polynomial of degree m, œâ Ã∏= 0, then a particular integral will
be
yp(t) = eŒ±t
q1(t) cos œât + q2(t) sin œât

(10.78)
with q1(t), q2(t) polynomials of degree
‚Ä¢
m if Œ± + iœâ is not eigenvalue of A,
‚Ä¢
m + Œº if Œ± + iœâ is an eigenvalue of algebraic multiplicity Œº ‚â•1.
The latter case is once again called of resonance. The polynomials‚Äô undetermined
coeÔ¨Écients are found as before, preliminarly separating terms with cos œât from
those with sin œât.
Examples 10.38
i) Find a particular integral of (10.74), where
A =
‚éõ
‚éù
0
‚àí1
0
1
0
0
1
0
2
‚éû
‚é†
and
b(t) =
‚éõ
‚éù
0
t
t2
‚éû
‚é†.
Referring to (10.75), Œ± = 0, p(t) = b0t2 + b1t with b0 = (0, 0, 1)T , b1 = (0, 1, 0)T
(and b2 = 0). Since Œ± is not a root of the characteristic polynomial œá(Œª) =
(2 ‚àíŒª)(Œª2 + 1), we look for a particular integral
yp(y) = q(t) = c0t2 + c1t + c2 .
Substituting in (10.74), we have
2c0t + c1 = Ac0t2 + Ac1t + Ac2 + b0t2 + b1t ,
so comparing terms yields the cascade of systems
‚éß
‚é®
‚é©
Ac0 = ‚àíb0
Ac1 = 2c0 ‚àíb1
Ac2 = c1 .
These give c0 = (0, 0, ‚àí1/2)T, c1 = (‚àí1, 0, 0)T and c2 = (0, 1, 0)T, and a partic-
ular integral is then
yp(t) =
‚éõ
‚éù
0
0
‚àí1/2
‚éû
‚é†t2 +
‚éõ
‚éù
‚àí1
0
0
‚éû
‚é†t +
‚éõ
‚éù
0
1
0
‚éû
‚é†=
‚éõ
‚éù
‚àít
1
‚àí1
2t2
‚éû
‚é†.
ii) Consider equation (10.74) with
A =
	
9
‚àí4
8
‚àí3

and
b(t) = et
	
1
0

.
As Œ± = 1 is a root of the characteristic polynomial œá(Œª) = (Œª ‚àí5)(Œª ‚àí1), we are
in presence of resonance, so we must try to Ô¨Ånd a particular integral of the form
yp(t) = et(c0t + c1) .
Substituting and simplifying, we have
c0 + c0t + c1 = Ac0t + Ac1 + b0

472
10 Ordinary diÔ¨Äerential equations
where b0 = (1, 0)T , and so  (A ‚àíI)c0 = 0
(A ‚àíI)c1 = c0 ‚àíb0 .
The Ô¨Årst system yields an eigenvector c0 = (Œ≥, 2Œ≥)T associated to Œª = 1, for some
Œ≥ ‚ààR. This constant Œ≥ is Ô¨Åxed requiring the second system to be consistent,
meaning c0 ‚àíb0 is a linear combination of the columns of A ‚àíI. But that
matrix has rank 1 since the columns are linearly dependent, so the condition is
that c0 ‚àíb0 is a multiple of another column, (Œ≥ ‚àí1, 2Œ≥)T = k(1, 1)T; this implies
Œ≥ ‚àí1 = 2Œ≥, so Œ≥ = ‚àí1. Substituting gives c0 = (‚àí1, ‚àí2)T and c1 = (1, 5/2)T,
for example. In conclusion, a particular integral has the form
yp(t) = et
	
‚àí1
‚àí2

t +
	
1
5/2


= et
	
‚àít + 1
‚àí2t + 5/2

.
iii) Find a particular integral of (10.74) with
A =
‚éõ
‚éù
0
‚àí1
0
1
0
0
0
1
‚àí1
‚éû
‚é†
and
b(t) =
‚éõ
‚éù
1
0
0
‚éû
‚é†sin 2t .
Referring to (10.77), now Œ± = 0, p(t) = (1, 0, 0)T = p0 and œâ = 2. The complex
number Œ± + iœâ = 2i is no eigenvalue of A (these are ‚àí1, ¬±i), so (10.78) will be
yp(t) = q1 cos 2t + q2 sin 2t
with q1, q2 ‚ààR3. Let us substitute in (10.74) to get
‚àí2q1 sin 2t + 2q2 cos 2t = Aq1 cos 2t + Aq2 sin 2t + p0 sin 2t ;
comparing the corresponding terms we obtain the two linear systems
 ‚àí2q1 = Aq2 + p0
2q2 = Aq1 ,
solved by q1 = (‚àí2/3, 0, 1/6)T, q2 = (0, ‚àí1/3, ‚àí1/12)T. We conclude that a
particular integral is given by
yp(t) =
‚éõ
‚éù
‚àí2/3
0
1/6
‚éû
‚é†cos 2t ‚àí
‚éõ
‚éù
0
1/3
1/12
‚éû
‚é†sin 2t = ‚àí1
12
‚éõ
‚éù
8 cos 2t
4 sin 2t
sin 2t ‚àí2 cos2t
‚éû
‚é†.
2
The superposition principle
Ultimately, suppose b(t) is the sum of terms like (10.75) or (10.77). By virtue of
linearity, a particular solution yp will be the sum of particular solutions of the
single summands:
if b = b1 + b2 + . . . + bK, and ypk solves y‚Ä≤ = Ay + bk for k = 1, . . . , K,
then yp = yp1 + . . . + ypK solves y‚Ä≤ = Ay + b.

10.7 Linear scalar equations of order n
473
In fact,
y‚Ä≤
p = y‚Ä≤
p1 + . . . + y‚Ä≤
pK = (Ayp1 + b1) + . . . + (AypK + bK)
= A(yp1 + . . . + ypK) + (b1 + . . . + bK) = Ayp + b .
The property is known as superposition (or linearity) principle. Example 10.42 ii)
will provide us with a tangible application.
10.7 Linear scalar equations of order n
In this section we tackle linear scalar equations
y(n) + a1y(n‚àí1) + . . . + an‚àí1y‚Ä≤ + any = b(t) ,
(10.79)
where n is an integer ‚â•2, the coeÔ¨Écients a1, . . . , an are real constants and b is a
real-valued continuous map deÔ¨Åned on the real interval I. We abbreviate by Ly
the left-hand side; the operator L : y ‚ÜíL y is linear because diÔ¨Äerentiation is a
linear operation. Then
Ly = y(n) + a1y(n‚àí1) + . . . + an‚àí1y‚Ä≤ + any = 0
(10.80)
is called the homogeneous equation associated to (10.79).
The background theory can be deduced from the results on linear systems
of Ô¨Årst-order equations, settled in the previous section. In fact, we remarked in
Sect. 10.2 that any ODE of order n is equivalent to a system of n diÔ¨Äerential
equations of order one. In the case at hand, we set yi(t) = y(i‚àí1)(t), 1 ‚â§i ‚â§n, so
that (10.79) is equivalent to the linear system
‚éß
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é©
y‚Ä≤
1 = y2
y‚Ä≤
2 = y3
...
y‚Ä≤
n = ‚àía1yn ‚àí. . . ‚àían‚àí1y2 ‚àíany1 + b(t) ;
the latter may be written as (10.48), and precisely
y‚Ä≤ = Ay + b(t) ,
(10.81)
by putting
y =
‚éõ
‚éú
‚éú
‚éù
y1
y2
...
yn
‚éû
‚éü
‚éü
‚é†,
A =
‚éõ
‚éú
‚éú
‚éú
‚éú
‚éù
0
1
0
. . .
. . .
0
0
1
0
. . .
...
. . .
. . .
0
0
1
‚àían
‚àían‚àí1
. . .
. . .
‚àía1
‚éû
‚éü
‚éü
‚éü
‚éü
‚é†
,
b(t) =
‚éõ
‚éú
‚éú
‚éù
0
...
0
b(t)
‚éû
‚éü
‚éü
‚é†.
The Ô¨Årst component of y is the solution of (10.79).

474
10 Ordinary diÔ¨Äerential equations
The homogeneous equation
Equation (10.80) corresponds to the homogeneous system relative to (10.81). From
this we recover the following central result.
Proposition 10.39 i) The set S0 of solutions to the homogeneous equa-
tion (10.80) is an n-dimensional vector space.
ii) The set Sb of solutions to (10.79) is the aÔ¨Éne space Sb = yp + S0, where
yp is any solution.
Proof.
i) S0 is a vector space because (10.80) is a linear constraint. With Propos-
ition 10.26 in mind, let w1, . . . , wn be a fundamental system of solutions
for y‚Ä≤ = Ay. Denote by zi = wi ¬∑ e1 the Ô¨Årst components of the vectors,
which clearly solve (10.80).
If y ‚ààS0, the associated vector-valued map y is a linear combination
of the wi; in particular its Ô¨Årst component is a combination of the zi.
Thus S0 is spanned by those solutions. The claim follows provided we
show that the functions z1, . . . , zn are linearly independent. By successively
diÔ¨Äerentiating
n

i=1
cizi(t) = 0 ,
‚àÄt ‚ààR ,
we get, for all 1 ‚â§k ‚â§n ‚àí1,
n

i=1
ciz(k)
i
(t) = 0 ,
‚àÄt ‚ààR .
But z(k)
i
is the (k+1)th component of wi, so we obtain the vector equation
n

i=1
ciwi(t) = 0 ,
‚àÄt ‚ààR ,
whence c1 = . . . = cn = 0 by linear independence of the wi.
ii) The argument is similar to the one used in Proposition 10.29.
2
In order to Ô¨Ånd a basis for S0, the linear system associated to (10.80) is not
necessary, because one can act directly on the equation: we are looking for solu-
tions y(t) = eŒªt, with Œª constant, possibly complex. Substituting into (10.80), and
recalling (10.28), gives
L(eŒªt) = (Œªn + a1Œªn‚àí1 + . . . + an‚àí1Œª + an) eŒªt = 0 ,
i.e.,
L(eŒªt) = œá(Œª)eŒªt = 0 ,

10.7 Linear scalar equations of order n
475
where œá(Œª) = Œªn+a1Œªn‚àí1+. . .+an‚àí1Œª+an is the characteristic polynomial of
the ODE (10.79). Since eŒªt is always non-zero, y(t) = eŒªt solves the homogeneous
equation if and only if Œª is a root of the characteristic polynomial, that is if and
only if Œª satisÔ¨Åes the characteristic equation
Œªn + a1Œªn‚àí1 + . . . + an‚àí1Œª + an = 0 .
(10.82)
Hence, the diÔ¨Äerential problem is reduced to a purely algebraic question, that the
Fundamental Theorem of Algebra can handle. We know that (10.82) has p distinct
solutions Œª1, . . . , Œªp, 1 ‚â§p ‚â§n; each root Œªk, 1 ‚â§k ‚â§p, has multiplicity Œºk ‚â•1,
so that overall Œº1 + . . . + Œºp = n. The characteristic equation‚Äôs zeroes are nothing
but the eigenvalues of A in (10.81), because one could prove
det(A ‚àíŒªI) = (‚àí1)nœá(Œª) .
This gives directly p distinct solutions
eŒª1t, . . . , eŒªpt
to (10.80). If p < n, any root Œªk of multiplicity Œºk > 1 gives Œºk‚àí1 further solutions
t eŒªkt, t2 eŒªkt, . . . , tŒºk‚àí1 eŒªkt .
The n solutions thus found can be proven to be linearly independent. In summary,
the result reads as follows.
Proposition 10.40 The functions
zk,‚Ñì(t) = t‚ÑìeŒªkt ,
1 ‚â§k ‚â§p,
0 ‚â§‚Ñì‚â§Œºk ‚àí1 ,
form a basis for the space S0 of solutions to (10.80). Equivalently, every solu-
tion of the equation has the form
y(t) =
p

k=1
qk(t) eŒªkt ,
with qk a polynomial of degree ‚â§Œºk ‚àí1.
In presence of complex(-conjugate) roots of equation (10.82), the corresponding
basis functions are complex-valued. But we can Ô¨Ånd a real basis if we replace the
pair t‚ÑìeŒªkt, t‚ÑìeŒªkt with the real and imaginary parts of either of them, for any pair
of complex-conjugate eigenvalues Œªk = œÉk + iœâk, Œªk = œÉk ‚àíiœâk. That is to say,
t‚ÑìeœÉkt cos œâkt
and
t‚ÑìeœÉkt sin œâkt
are n linearly independent, real solutions.

476
10 Ordinary diÔ¨Äerential equations
Examples 10.41
i) Let us make the previous construction truly explicit for an equation of order
two,
y‚Ä≤‚Ä≤ + a1y‚Ä≤ + a2y = 0 .
(10.83)
Let Œî = a2
1 ‚àí4a2 be the discriminant of Œª2 + a1Œª + a2 = 0.
When Œî > 0, there are two distinct real roots Œª1,2 = (‚àía1 ¬±
‚àö
Œî)/2, so the
generic solution to (10.83) is
y(t) = c1 eŒª1t + c2 eŒª2t .
(10.84)
When Œî = 0, the real root Œª1 = ‚àía1/2 is double, Œº1 = 2; so, the generic solution
reads
y(t) = (c1 + c2t) eŒª1t .
(10.85)
Eventually, when Œî < 0 we have complex-conjugate roots Œª1 = œÉ +iœâ = ‚àía/2+
i

|Œî| and Œª2 = œÉ ‚àíiœâ = ‚àía/2 ‚àíi

|Œî|, and the solution to (10.83) is
y(t) = eœÉt(c1 cos œât + c2 sin œât) .
(10.86)
ii) Solve the homogeneous equation of fourth order
y(4) + y = 0 .
The characteristic zeroes, solving Œª4 + 1 = 0, are fourth roots of ‚àí1, Œª1,2,3,4 =
‚àö
2
2 (¬±1 ¬± i). Therefore y takes the form
y(t) = e(
‚àö
2/2) t
c1 cos
‚àö
2
2 t + c2 sin
‚àö
2
2 t

+ e‚àí(
‚àö
2/2) t
c3 cos
‚àö
2
2 t + c4 sin
‚àö
2
2 t

.
2
The non-homogeneous equation
Just as for systems of order one, a particular integral is easy to Ô¨Ånd when b(t) has
a special form. For instance, for
b(t) = eŒ±tp(t)
(10.87)
with Œ± ‚ààR, p(t) an algebraic polynomial of degree m with real coeÔ¨Écients, there
is a particular integral
yp(t) = eŒ±ttŒºq(t) ,
(10.88)
where Œº ‚â•0 is the multiplicity of Œ± as a zero of œá(Œª) = 0 (with Œº = 0 if Œ± is not
a root, while Œº ‚â•1 gives resonance), and q(t) is a polynomial of degree m with
unknown coeÔ¨Écients. These coeÔ¨Écients are determined by substituting (10.88)
in (10.79), simplifying the common factor eŒ±t and comparing the polynomial func-
tions in t.
Take another example, like
b(t) = eŒ±tp(t) cos œât
or
b(t) = eŒ±tp(t) sin œât ,
(10.89)

10.7 Linear scalar equations of order n
477
with Œ± ‚ààR, p(t) a real algebraic polynomial of degree m, œâ Ã∏= 0. This gives a
particular integral
yp(t) = eŒ±ttŒº
q1(t) cos œât + q2(t) sin œât

,
(10.90)
where Œº ‚â•0 is the multiplicity of Œ± + iœâ, and q1, q2 are unknown polynomials of
degree m to be found as above, i.e., separating the terms in cos œât and sin œât.
The superposition principle is still valid if b(t) is a sum of terms bk(t) like (10.87)
or (10.89): a particular integral for (10.79) will be a sum of particular integrals for
the bk(t).
Examples 10.42
i) Determine the general integral of
y‚Ä≤‚Ä≤ ‚àíy‚Ä≤ ‚àí6y = te‚àí2t .
The characteristic equation Œª2 ‚àíŒª ‚àí6 = 0 has roots Œª1 = ‚àí2, Œª2 = 3, so the
general homogeneous integral is
yhom(t) = c1e‚àí2t + c2e3t .
In a situation of resonance between the source term and a component of yhom,
the particular integral has to be of type
yp(t) = t(at + b)e‚àí2t .
We diÔ¨Äerentiate and substitute back in the ODE to obtain
‚àí10at + 2a ‚àí5b = t
(the coeÔ¨Écient of t2 on the left is zero, as a consequence of resonance), from
which ‚àí10a = 1 and 2a ‚àí5b = 0, so a = ‚àí1/10, b = ‚àí1/25. In conclusion,
y(t) =

‚àí1
10t2 ‚àí1
25t + c1

e‚àí2t + c2e3t .
ii) Let us Ô¨Ånd the general integral of
y‚Ä≤‚Ä≤‚Ä≤ + y‚Ä≤ = cos t ‚àí2e3t .
By superposition
y(t) = yhom(t) + yp1(t) ‚àí2yp2(t) ,
where yhom is the general homogeneous integral, yp1 and yp2 are particular in-
tegrals relative to sources cos t and e3t.
The characteristic equation Œª3 + Œª = 0 has roots Œª1 = 0, Œª2,3 = ¬±i, hence
yhom(t) = c1 + c2 cos t + c3 sin t .
Taking resonance into account, we want yp1 of the form yp1(t) = t(a cos t+b sint).
Computing successive derivatives of yp1 and substituting them into
y‚Ä≤‚Ä≤‚Ä≤
p1 + y‚Ä≤
p1 = cos t
gives ‚àí2a cost ‚àí2b sin t = cos t, so a = ‚àí1/2 and b = 0. Therefore yp1(t) =
‚àí1
2 cos t.

478
10 Ordinary diÔ¨Äerential equations
Now we search for yp2 of the form yp2(t) = de3t. By diÔ¨Äerentiating and substi-
tuting in the equation
y‚Ä≤‚Ä≤‚Ä≤
p2 + y‚Ä≤
p2 = e3t ,
we obtain d = 1/30, and then yp2(t) =
1
30e3t. All-in-all,
y(t) = c1 +

c2 ‚àí1
2t

cos t + c3 sin t ‚àí1
15e3t
is the general integral of the given equation.
2
10.8 Stability
The long-time behaviour of solutions of an ODE is a problem of great theoretical
and applicative importance. A large class of dynamical systems, i.e., of systems
whose state depends upon time and that are modelled by one or more diÔ¨Äerential
equations, admit solutions at any time t after a given instant t0. The behaviour
of a particular solution can be very diversiÔ¨Åed: for instance, after a starting trans-
ition where it depends strongly on the initial data, it could subsequently converge
asymptotically to a limit solution, independent of time; it could, instead, present
a periodic, or quasi-periodic, course, or approach such a conÔ¨Åguration; a solution
could even have an absolutely unpredictable, or chaotic, behaviour in time.
Perhaps more interesting than the single solution is though the behaviour of
a family of solutions that diÔ¨Äer by slight perturbations either of the initial data,
or of the ODE. In fact, the far future of one solution might not be representative
of other solutions that kick oÔ¨Änearby. Often the mathematical model described
by an ODE is just an approximation of a physically-more-complex system; to
establish the model‚Äôs reliability it is thus fundamental to determine how ‚Äòrobust‚Äô
the information that can be extracted from it is, with respect to the possible errors
of the model. In the majority of cases moreover, the ODE is solved numerically, and
the discretised problem will introduce extra perturbations. These and other reasons
lead us to ask ourselves whether solutions that are initially very close stay close at
all times, even converge to a limit solution, rather than moving eventually apart
from one another. These kinds of issues are generically referred to as concerning
(asymptotic) stability. The results on continuous dependency upon initial data,
discussed in Sect. 10.4.1 (especially Proposition 10.15), do not answer the question
satisfactorily. They merely provide information about bounded time intervals: the
constant eL|t‚àít0| showing up in (10.36) grows exponentially from the instant t0. A
more speciÔ¨Åc and detailed analysis is needed to properly understand the matter.
We shall discuss stability exclusively in relationship with stationary solutions;
the generalisation to periodic orbits and chaotic behaviours is incredibly fascinat-
ing but cannot be dealt with at present.
Let us begin with the Cauchy problem
 y‚Ä≤ = f(t, y) ,
t > t0 ,
y(t0) = y0 ,
(10.91)

10.8 Stability
479
 
 
 
 
 
 
 
 
y1
(t, y(t, y0))
y2
t
t = 0
œµ
Œ¥(œµ)
¬Øy0
y0
(t, ¬Øy0)
Figure 10.9. Lyapunov stability
and suppose there is a ¬Øy0, belonging to D, such that f(t, ¬Øy0) = 0 for any t ‚â•t0.
Then y(t) = ¬Øy0, ‚àÄt ‚â•t0, is a constant solution that we shall call stationary solu-
tion. The point ¬Øy0 is said critical point, stationary point, or equilibrium
point for the equation. A further hypothesis will be that the solutions to (10.91)
are deÔ¨Åned at all times t > t0, whichever the initial datum y0 in a suitable neigh-
bourhood ¬ØB of ¬Øy0; from now on y(t, y0) will denote such a solution. Therefore, it
makes sense to compare these solutions to ¬Øy0 over the interval [t0, +‚àû). To this
end, the notions of (Lyapunov) stability and attractive solution are paramount.
DeÔ¨Ånition 10.43 The stationary solution ¬Øy0 = y(t, ¬Øy0) to problem (10.91)
is stable if, for any neighbourhood BŒµ(¬Øy0) of ¬Øy0, there exists a neighbourhood
BŒ¥(¬Øy0) such that
y0 ‚àà¬ØB ‚à©BŒµ(¬Øy0)
=‚áí
y(t, y0) ‚ààBŒ¥(¬Øy0) ‚àÄt ‚â•t0 .
This is exempliÔ¨Åed in Fig. 10.9.
DeÔ¨Ånition 10.44 The stationary solution ¬Øy0 is called attractive (or an
attractor) if there exists a neighbourhood B(¬Øy0) ‚äÜ¬ØB such that
y0 ‚ààB(¬Øy0)
=‚áí
lim
t‚Üí+‚àûy(t, y0) = ¬Øy0 ,
 
 
 
 
 
 
 
y1
(t, y(t, y0))
y2
t
t = 0
œµ
Œ¥(œµ)
¬Øy0
y0
(t, ¬Øy0)
 
 
 
 
 
 
y1
(t, y(t, y0))
y2
t
t = 0
œµ
Œ¥(œµ)
¬Øy0
y0
(t, ¬Øy0)

480
10 Ordinary diÔ¨Äerential equations
and uniformly attractive (a uniform attractor) if the above limit is uni-
form with respect to y0, i.e.,
lim
t‚Üí+‚àû
sup
y0‚ààB(¬Øy0)
‚à•y(t, y0) ‚àí¬Øy0)‚à•= 0 .
The two properties of stability and attractiveness are unrelated. The point ¬Øy0 is
uniformly asymptotically stable if it is both stable and uniformly attractive.
Example 10.45
The simplest (yet rather meaningful, as we will see) case is the autonomous
linear problem
 y‚Ä≤ = Œªy ,
t > 0 ,
Œª ‚ààR ,
y(t0) = y0 ,
whose only stationary solution is ¬Øy0 = 0. The solutions y(t, y0) = eŒªty0 conÔ¨Årm
that 0 is stable if and only if Œª ‚â§0 (in this case we may choose Œ¥ = Œµ in the
deÔ¨Ånition). Moreover, for Œª = 0 the point 0 is not an attractor (all solutions are
clearly constant), whereas for Œª < 0, the point 0 is uniformly attractive (hence
uniformly asymptotically stable): for example setting B(0) = B1(0) = (‚àí1, 1),
we have
sup
y0‚ààB(0)
|y(t, y0)| = eŒªt ‚Üí0
as t ‚Üí+‚àû.
As far as stability is concerned, we obtain similar results when Œª ‚ààC (complex-
valued solutions) provided we replace Œª with Re Œª.
2
This example generalises directly to autonomous linear systems, now examined.
10.8.1 Autonomous linear systems
Suppose f(t, y) = f(y) = Ay + b has A ‚ààRn,n and b ‚ààRn independent of time.
A stationary solution of (10.91) corresponds to a solution of the linear system
Ay = ‚àíb (unique if A is non-singular). If ¬Øy0 is one such solution the variable
change z = y ‚àí¬Øy0 allows us to study the stability of the zero solution of the
homogeneous equation z‚Ä≤ = Az. There is so no loss of generality in considering,
henceforth, the stability of the solution y(t, 0) = 0 of the homogeneous problem
 y‚Ä≤ = Ay ,
t > 0 ,
y(t0) = y0 .
(10.92)
From Sect. 10.6, in particular Proposition 10.35, we know every solution y(t, y0)
is a linear combination of
w(t) = eŒªtp(t) ,

10.8 Stability
481
where Œª ‚ààC is an eigenvalue of A, and p(t) is a vector-valued polynomial in t
depending on the eigenvector (or one of the eigenvectors) associated to Œª. In case
the algebraic and geometric multiplicities of Œª coincide, every p(t) associated to
it has degree 0, and so is constant; otherwise, there exist polynomials of positive
degree, which therefore tend to ‚àûas t ‚Üí+‚àû.
Consequences:
‚Ä¢
if every eigenvalue of A has negative real part, then all basis elements w(t)
tend to 0 as t ‚Üí+‚àû(recall eœÉttŒ≤ ‚Üí0 for t ‚Üí+‚àûif œÉ = Re Œª < 0, for any
Œ≤);
‚Ä¢
if all eigenvalues of A have negative or zero real part, and the latter ones
have coinciding algebraic and geometric multiplicities, all w(t) are bounded on
[0, +‚àû);
‚Ä¢
if there are eigenvalues of A with positive real part, or zero real part and
algebraic multiplicity greater than the geometric multiplicity, then some w(t)
tends to ‚àûas t ‚Üí+‚àû.
How this translates in the language of stability is easily said.
Proposition 10.46 a) The origin y(t, 0) = 0 is a stable solution of (10.92)
if and only if all eigenvalues Œª of A satisfy Re Œª ‚â§0, and those with Re Œª = 0
have the same algebraic and geometric multiplicity.
b) The origin is a uniformly attractive solution (hence, uniformly asymptot-
ically stable) if and only if all eigenvalues of A satisfy Re Œª < 0.
We shall investigate now all the scenarios for systems of two equations.
10.8.2 Two-dimensional systems
The generic 2 √ó 2 matrix
A =
	
a
b
c
d

has determinant detA = ad ‚àíbc and trace trA = a + d. Its eigenvalues are roots
of the characteristic polynomial œá(Œª) = Œª2 ‚àítrA Œª + detA, so
Œª = trA ¬±

(trA)2 ‚àí4 detA
2
.
If (trA)2 Ã∏= 4 detA, then the eigenvalues are distinct, necessarily simple, and the
matrix is diagonalisable. If, instead, (trA)2 = 4 detA, the double eigenvalue Œª =
trA/2 has geometric multiplicity 2 if and only if b = c = 0, i.e., A is diagonal; if
the multiplicity is one, A is not diagonalisable.
Let us assume Ô¨Årst A is diagonalisable. Then Proposition 10.32 tells us each
solution of (10.92) can be written as
y(t, y0) = z1(t)v1 + z2(t)v2 ,
(10.93)

482
10 Ordinary diÔ¨Äerential equations
where v1, v2 are linearly independent vectors (in fact, they are precisely the ei-
genvectors if the eigenvalues are real, or two vectors manufactured from a complex
eigenvector‚Äôs real and imaginary parts if the eigenvalues are complex-conjugate);
z1(t) and z2(t) denote real maps satisfying, in particular, z1(0)v1 + z2(0)v2 = y0.
To understand properly the possible asymptotic situations, it proves useful to
draw a phase portrait, i.e., a representation of the orbits
Œì(y) = {y(t, y0) = (y1(t), y2(t)) : t ‚â•0}
on the phase plane R2 of coordinates y1, y2. We will see straight away that it is
possible to eliminate t and obtain an explicit functional relationship between y1
and y2. Actually, it will be better to perform such operation on the variables z1
and z2 Ô¨Årst, represent the orbit Œì(z) = {(z1(t), z2(t)) : t ‚â•0} in the phase plane
z1z2, and then pass to the plane y1y2 using the linear transformation (10.93).
We have to distinguish six cases.
i) Two real non-zero eigenvalues with equal sign: Œª2 ‚â§Œª1 < 0 or 0 < Œª1 ‚â§Œª2.
Then
z1(t) = d1eŒª1t ,
z2(t) = d2eŒª2t ,
with d1, d2 dependent on y0. If d1 = 0 or d2 = 0, the orbits lie on the coordinate
axes z1 = 0 or z2 = 0. If neither is zero,
z2(t) = d2

eŒª1t Œª2
Œª1 = d2
	z1(t)
d1

 Œª2
Œª1
,
so the orbits are graphs of
z2 = dzŒ±
1 ,
with Œ± ‚â•1
z1
z2
y1
y2
Figure 10.10. Phase portrait for y‚Ä≤ = Ay in the z1z2-plane (left) and in the y1y2-plane
(right): the case Œª2 < Œª1 < 0 (node)

10.8 Stability
483
z1
z2
y1
y2
Figure 10.11. Phase portrait for y‚Ä≤ = Ay in the z1z2-plane (left) and in the y1y2-plane
(right): the case Œª2 < Œª1 = 0
(which are half-lines if Œª1 = Œª2.) Points on the orbits move in time towards the
origin, which is thus uniformly asymptotically stable, if the eigenvalues are negative
(Fig. 10.10, left); the orbits leave the origin if the eigenvalues are positive. On the
plane y1y2 the corresponding orbits are shown by Fig. 10.10, right, where we took
v1 = (3, 1), v2 = (‚àí1, 1).
The origin is called a node, and is stable or unstable according to the eigen-
values‚Äô signs.
ii) Two real eigenvalues, at least one of which is zero:
Œª2 ‚â§Œª1 = 0 or 0 = Œª1 ‚â§Œª2.
The function z1(t) = d1 is constant. Therefore if Œª2 Ã∏= 0, the orbits are vertical
half-lines, oriented towards the axis z2 = 0 if Œª2 < 0, the other way if Œª2 > 0
(Fig. 10.11). If Œª2 = 0, the matrix A is null (being diagonalisable), hence all orbits
are constant. Either way, the origin is a stable equilibrium point, but not attractive.
iii) Two real eigenvalues with opposite signs: Œª2 < 0 < Œª1.
The z1z2-orbits are the four semi-axes, together with the curves
z2 = dzŒ±
1 ,
with Œ± < 0
(hyperbolas, if Œ± = ‚àí1), oriented as in Fig. 10.12.
The origin, called a saddle point, is neither stable nor attractive.
iv) Two purely-imaginary eigenvalues: Œª = ¬±iœâ , œâ Ã∏= 0.
As
z1(t) = d1 cos(œât + d2)
and
z2(t) = d1 sin(œât + d2) ,
the orbits are concentric circles on the phase plane z1z2, and concentric ellipses on
y1y2 (Fig. 10.13).
The origin is called a centre, and is stable but not attractive.

484
10 Ordinary diÔ¨Äerential equations
z1
z2
y1
y2
Figure 10.12. Phase portrait for y‚Ä≤ = Ay in the z1z2-plane (left) and in the y1y2-plane
(right): the case Œª2 < 0 < Œª1 (saddle point)
v) Complex-conjugate eigenvalues, with non-zero real part: Œª = œÉ ¬± iœâ, with
œâ Ã∏= 0 and œÉ < 0 or œÉ > 0.
From
z1(t) = d1eœÉt cos(œât + d2)
and
z2(t) = d1eœÉt sin(œât + d2) ,
we see the orbits spiralling towards the origin if œÉ < 0, and moving outward if
œÉ > 0 (Fig. 10.14). In the former case the origin is uniformly asymptotically stable.
The origin is a focus, stable or unstable according to the sign of œÉ.
The last case occurs for non-diagonalisable A, in other words if there is a double
eigenvalue with geometric multiplicity equal 1. Then v1 is the unique eigenvector
in (10.93), and v2 is the associated generalised eigenvector, see (10.71).
z1
z2
y1
y2
Figure 10.13. Phase portrait for y‚Ä≤ = Ay in the z1z2-plane (left) and in the y1y2-plane
(right): the case Œª = ¬±œâ (centre)

10.8 Stability
485
z1
z2
y1
y2
Figure 10.14. Phase portrait for y‚Ä≤ = Ay in the z1z2-plane (left) and in the y1y2-plane
(right): the case Œª = œÉ ¬± œâ (focus)
vi) One real double eigenvalue Œª, of geometric multiplicity 1.
We have
z1(t) = d1eŒª1t ,
z2(t) = eŒª2t(d2 + d1t) .
When Œª = 0, and d1 Ã∏= 0, the orbits are vertical straight lines as shown in Fig. 10.15;
for d1 = 0 the orbits are Ô¨Åxed points on z1 = 0. Therefore, the origin is neither
stable, nor attractive.
When Œª Ã∏= 0 instead, t can be written as t =
1
|Œª| log
 z1
d1
, whence
z2 =
	d1
d2
+ 1
|Œª| log

z1
d1


z1 .
z1
z2
y1
y2
Figure 10.15. Phase portrait for y‚Ä≤ = Ay in the z1z2-plane (left) and in the y1y2-plane
(right): the case Œª1 = Œª2 = 0, bc Ã∏= 0

486
10 Ordinary diÔ¨Äerential equations
z1
z2
y1
y2
Figure 10.16. Phase portrait for y‚Ä≤ = Ay in the z1z2-plane (left) and in the y1y2-plane
(right): the case Œª1 = Œª2 Ã∏= 0, bc Ã∏= 0 (improper node)
Figure 10.16 shows the orbits oriented to, or from, the origin according to whether
Œª < 0, Œª > 0. The origin is uniformly asymptotically stable, and still called (de-
generate, or improper) node; again, it is stable or unstable depending on the
eigenvalue sign.
Application: the simple pendulum (IV). The example continues from p. 454.
The dynamical system y‚Ä≤ = f(y) has an inÔ¨Ånity of equilibrium points ¬Øy0, because
f(¬Øy0) = 0
if and only if
¬Øy2 = 0 and ¬Øy1 = ‚ÑìœÄ with ‚Ñì‚ààZ .
The solutions Œ∏(t) = ‚ÑìœÄ, with ‚Ñìan even number, correspond to a vertical rod, with
P in the lowest point S (Fig. 10.3); when ‚Ñìis odd the bob is in the highest position
I. It is physically self-evident that moving P from S a little will make the bob
swing back to S; on the contrary, the smallest nudge to the bob placed in I will
make it move away and never return, at any future moment. This is precisely the
meaning of a stable point S and an unstable point I.
The discussion of Sect. 10.8.2 renders this intuitive idea precise. Consider a
simpliÔ¨Åed model for the pendulum, obtained by linearising equation (10.12) around
an equilibrium position.
On a neighbourhood of the point ¬ØŒ∏ = 0 we have sin Œ∏ ‚àºŒ∏, so equation (10.12)
can be replaced by
d2Œ∏
dt2 + Œ±dŒ∏
dt + kŒ∏ = 0 ,
(10.94)
which describes small oscillations around the equilibrium S; the value Œ± = 0
gives the equation of harmonic motion. The corresponding solution to the Cauchy
problem (10.13) is easy to Ô¨Ånd by referring to Example 10.4. Equivalently, the
initial value problem assumes the form (10.92) with
A =
	 0
1
‚àík ‚àíŒ±

= Jf(0, 0) ,

10.8 Stability
487
whose eigenvalues are Œª = ‚àíŒ± ¬±
‚àö
Œ±2 ‚àí4k
2
. Owing to Sect. 10.8.2, we have that
‚Ä¢
if Œ±2 ‚â•4k, the origin ¬Øy0 = (0, 0) is a uniformly asymptotically stable node
[cases i) or vi)] ;
‚Ä¢
if 0 < Œ±2 < 4k, the origin is a uniformly asymptotically stable focus [case
v)] ;
‚Ä¢
if Œ± = 0, the origin is a centre [case iv)] .
Whatever the case, the bottom position S is always stable.
Linearising (10.12) around the equilibrium ¬ØŒ∏ = œÄ, and changing variables œï =
Œ∏ ‚àíœÄ (so that sin Œ∏ = ‚àísin œï) produces a problem of the form (10.92), with
A =
	
0
1
k ‚àíŒ±

= Jf(œÄ, 0) .
The eigenvalues Œª = ‚àíŒ± ¬±
‚àö
Œ±2 + 4k
2
are always non-zero and of distinct sign. The
point ¬Øy0 = (œÄ, 0) is thus a saddle [case iii)], and so unstable. This substantiates
the claim that I is an unstable equilibrium.
The discussion will end on p. 488.
2
10.8.3 Non-linear stability: an overview
Certain stability features of linear systems are inherited by non-linear systems,
thought of as deformations of linear ones. Suppose the function f(t, y) appearing
in (10.91) has the form
f(t, y) = Ay + g(t, y) ,
(10.95)
with g continuous and such that
g(t, y) = o(‚à•y‚à•)
as y ‚Üí0 uniformly in t ;
(10.96)
this means there exists a continuous map œÜ : R+ ‚ÜíR+ such that œÜ(s) ‚Üí0,
s ‚Üí0+, and
‚à•g(t, y)‚à•‚â§œÜ(‚à•y‚à•)‚à•y‚à•,
‚àÄy ‚ààB(0) ,
‚àÄt > t0 ,
on a neighbourhood B(0) of the origin. Then, the origin is an equilibrium for
equation (10.91). What can we say about its asymptotic stability? One answer is
given by the following fact.
Theorem 10.47 Let f be deÔ¨Åned by (10.95), with g as in (10.96).
a) If all eigenvalues of A have strictly negative real part, the origin is a
uniformly asymptotically stable equilibrium for (10.91).
b) If there is an eigenvalue of A with strictly positive real part, the origin is
unstable.

488
10 Ordinary diÔ¨Äerential equations
Under the given hypotheses the properties of the non-linear system y‚Ä≤ = Ay +
g(t, y) are the same of the corresponding linear one y‚Ä≤ = Ay; the latter is nothing
but the linearisation, around the origin, of the former (compare Remark 10.25).
We cannot say much more if all eigenvalues have non-positive real parts and some
are purely imaginary: stability in this case depends upon other properties of g.
Yet, the theorem has an important consequence for autonomous systems
around an equilibrium ¬Øy0. The criterion is known as Principle of linearised
stability.
Corollary 10.48 Let f : D ‚äÜRn ‚ÜíRn be a C1 map, ¬Øy0 ‚ààD such that
f(¬Øy0) = 0, and A = Jf(¬Øy0) the Jacobian of f at ¬Øy0. Then the autonomous
system y‚Ä≤ = f(y) has the following stability properties.
a) If all eigenvalues of A have negative real part, ¬Øy0 is a uniformly asymp-
totically stable equilibrium for (10.91).
b) If there is an eigenvalue of A with positive real part, ¬Øy0 is unstable.
Proof.
Using the Taylor expansion (5.16) at ¬Øy0,
f(y) = f(¬Øy0) + Jf(¬Øy0)(y ‚àí¬Øy0) + g(y) = A(y ‚àí¬Øy0) + g(y) ,
with g(y) = o(‚à•y ‚àí¬Øy0‚à•) as y ‚Üí¬Øy0. The variable change z = y ‚àí¬Øy0
puts us in the hypotheses of the previous theorem, thus concluding the
proof.
2
These two results are local in nature. Global information concerning the stabil-
ity of a stationary point can be obtained, for autonomous systems, from the know-
ledge of a Ô¨Årst integral (Sect. 10.4.5), or a Lyapunov function (Example 10.22 ii)).
A conservative system corresponding to an equation like (10.42) or (10.46)
admits a Ô¨Årst integral, namely the total energy E; therefore, by a theorem due
to Lagrange, we can say that if the origin is a strict minimum for the potential
energy Œ†, it must be a stable equilibrium for the system.
The same conclusion follows if the origin is stationary for a system admitting a
Lyapunov function V . Furthermore, if the derivative of V along any trajectory is
strictly negative (with the exception of the origin), then the origin is an attractor.
Application: the simple pendulum (V). The results about the linearised equa-
tion (10.94) determine the stability of the stationary points of (10.12) in presence
of damping. As a consequence of linearised stability (Corollary 10.48), if Œ± > 0 the
matrix Jf(¬Øy0) = A has two eigenvalues with negative real part for ¬Øy0 = (0, 0), and
one eigenvalue with positive real part for ¬Øy0 = (œÄ, 0). As in the linearised problem,
the bottom equilibrium point S is uniformly asymptotically stable, whereas the
top point I is unstable. Figure 10.17 zooms on the phase portrait. Multiplying
equation (10.12) by dŒ∏
dt gives
d
dtE(Œ∏,Œ∏ ‚Ä≤) = ‚àíŒ±
	dŒ∏
dt

2
‚â§0 ,

10.9 Exercises
489
y1
y2
œÄ
‚àíœÄ
Figure 10.17. Trajectories in the phase plane for the dampled pendulum (restricted to
|y1| ‚â§œÄ). The shaded region is the basin of attraction to the origin. The points lying
immediately above (resp. below) it, between two orbits, are attracted to the stationary
point (2œÄ, 0) ((‚àí2œÄ, 0)), and so on.
making the energy a Lyapunov function, which thus decreases along the orbits
(compare with Fig. 10.8).
For a free undamped motion, equilibria behave in the same way in the linear and
non-linear problems; this, though, can be proved by other methods. In particular,
the origin‚Äôs stability follows from the the fact that it minimises the potential energy,
by Lagrange‚Äôs Theorem.
2
10.9 Exercises
1. Determine the general integral of the following separable ODEs:
a)
y‚Ä≤ = (t + 2)y
t(t + 1)
b) y‚Ä≤ =
y2
t log t ‚àí
1
t log t
2. Tell what the general integral of the following homogeneous equations is:
a)
4t2y‚Ä≤ = y2 + 6ty ‚àí3t2
b) t2y‚Ä≤ ‚àíy2et/y = ty
3. Integrate the following linear diÔ¨Äerential equations:
a)
y‚Ä≤ = 1
t y ‚àí3t + 2
t3
b) ty‚Ä≤ = y +
2t2
1 + t2

490
10 Ordinary diÔ¨Äerential equations
4.
Find the general integral of the Bernoulli equations:
a) y‚Ä≤ = 1
t y ‚àíy2
b) y‚Ä≤ = 1
t y + t
y log t
5.
Determine the particular integral of the ODE
y‚Ä≤ = 1 ‚àíe‚àíy
2t + 1
subject to the condition y(0) = 1.
6.
Establish if there are solutions to
y‚Ä≤ = ‚àí2y + e‚àí2t
with null derivative at the origin.
7. Solve, on [ 4‚àöe, +‚àû), the Cauchy problem
!
eyy‚Ä≤ = 4t3 log t(1 + ey)
y( 4‚àöe) = 0.
8. Solve on the interval (‚àí2, 2) the initial value problem
‚éß
‚é®
‚é©
y‚Ä≤ =
3t
t2 ‚àí4|y|
y(0) = ‚àí1.
9. Given the ODE
y‚Ä≤ sin 2t ‚àí2(y + cos t) = 0,
t ‚àà

0, œÄ
2

,
determine the general integral and write a solution that stays bounded as
t ‚ÜíœÄ
2
‚àí.
10.
Solve the Cauchy problem
‚éß
‚é®
‚é©
d
dt (y2) = y2 + t
y
y(0) = 1 .

10.9 Exercises
491
11. Solve the Cauchy problem
‚éß
‚é™
‚é®
‚é™
‚é©
y‚Ä≤‚Ä≤

1 + (y‚Ä≤)
3/2 =
8t3
(t4 + 1)2
y(1) = 0 ,
y‚Ä≤(1) = 0 .
12.
Find the solutions of the initial value problem
‚éß
‚é®
‚é©
y‚Ä≤‚Ä≤ = 4
y3
y(0) = 2 ,
y‚Ä≤(0) = ‚àí
‚àö
3 .
13. Determine the particular integral of the diÔ¨Äerential equation
yy‚Ä≤‚Ä≤ ‚àí(y‚Ä≤)2 = y2 log y
such that y(0) = y‚Ä≤(0) = 1.
14.
As Œ± varies in R, solve the diÔ¨Äerential equation
y‚Ä≤ = (2 + Œ±)y ‚àí2eŒ±t
with initial datum y(0) = 3.
15.
Let a, b be real numbers. Solve
!
y‚Ä≤ = ay
t + 3tb
y(2) = 1
on the interval [2, +‚àû).
16.
Given the ODE
y‚Ä≤(t) = ‚àí3ty(t) + kt
depending on the real number k, Ô¨Ånd the solution vanishing at the origin.
17. Given
y‚Ä≤ = y2 ‚àí2y ‚àí3
2(1 + 4t)
,
a) determine its general integral;
b) Ô¨Ånd the particular integral y0(t) satisfying y0(0) = 1;
18.
Given the ODE y‚Ä≤ = f(t, y) = ‚àöt + y, determine open sets Œ© = I √ó D =
(Œ±,Œ≤ ) √ó (Œ≥,Œ¥) inside the domain of f, for which Theorem 10.14 is valid.

492
10 Ordinary diÔ¨Äerential equations
19.
Find the maximal interval of existence for the autonomous equation
y‚Ä≤ = f(y)
with:
a) f(y) =
#
1 + y2
1 + y2
2 i + arctan(y1 + y2) j
on R2
b) f(y) =
sin ‚à•y‚à•2
log3(2 + ‚à•y‚à•2) y
on Rn
20.
Verify that the autonomous equation y‚Ä≤ = f(y), with
a) f(y) =
y2
1 + 3y2
1 + 5y4
2
i ‚àí
y1
1 + 3y2
1 + 5y4
2
j
b) f(y) = (4y2
1y3
2 + 2y1y2)i ‚àí(2y1y4
2 + y2
2)j
admits on R2 a Ô¨Årst integral, then compute it.
21. Determine the general integral of the system y‚Ä≤ = Ay, where:
a) A =
	
9
‚àí4
8
‚àí3

b)
A =
	
3
‚àí4
4
3

c)
A =
‚éõ
‚éù
13
0
‚àí4
15
2
‚àí5
30
0
‚àí9
‚éû
‚é†
d) A =
‚éõ
‚éù
4
3
‚àí2
3
2
‚àí6
1
3
1
‚éû
‚é†
e)
A =
‚éõ
‚éù
0
1
0
0
0
1
0
‚àí10
‚àí6
‚éû
‚é†
f) A =
‚éõ
‚éù
4
0
0
0
‚àí2
9
0
4
‚àí2
‚éû
‚é†
g)
A =
‚éõ
‚éù
3
0
0
0
3
0
1
0
3
‚éû
‚é†
h) A =
‚éõ
‚éù
1
5
0
0
1
0
4
0
1
‚éû
‚é†
22. Determine a particular integral of the systems:
a) y‚Ä≤ =
‚éõ
‚éù
0
‚àí1
0
1
0
0
1
0
2
‚éû
‚é†y +
‚éõ
‚éù
0
t
t2
‚éû
‚é†
b) y‚Ä≤ =
‚éõ
‚éù
‚àí1
‚àí1
0
1/8
0
‚àí1
0
1/8
‚àí1
‚éû
‚é†y +
‚éõ
‚éù
1
1
0
‚éû
‚é†e‚àí2t
c) y‚Ä≤ =
‚éõ
‚éù
0
‚àí1
0
1
0
0
0
1
‚àí1
‚éû
‚é†y +
‚éõ
‚éù
1
0
0
‚éû
‚é†sin 2t

10.9 Exercises
493
23. Solve
‚éß
‚é®
‚é©
y‚Ä≤
1 = 2y1 + y3
y‚Ä≤
2 = y3
y‚Ä≤
3 = 8y1
with constraints y1(0) = y2(0) = 1 and y3(0) = 0.
24.
Find the solutions of
 y‚Ä≤
1 + y‚Ä≤
2 = 5y2
3y‚Ä≤
1 ‚àí2y‚Ä≤
2 = 5y1
with initial data y1(0) = 2, y2(0) = ‚àí1.
25.
Determine, in function of the real number b, the solutions of
y‚Ä≤ =
	
‚àí1
b
b
‚àí1

y
with y(0) = (1, 1)T .
26. As the real parameter a varies, Ô¨Ånd the general integral of
y‚Ä≤ =
‚éõ
‚éù
1 + a
0
1
a ‚àí2
3a ‚àí1
1 ‚àía
0
0
a
‚éû
‚é†y .
27.
Solve the system
 x‚Ä≤ = 2x ‚àíy
y‚Ä≤‚Ä≤ = ‚àí10x + 5y ‚àí2y‚Ä≤ .
28. Write the general integral for the following linear equations of order two:
a) y‚Ä≤‚Ä≤ + 3y‚Ä≤ + 2y = t2 + 1
b)
y‚Ä≤‚Ä≤ ‚àí4y‚Ä≤ + 4y = e2t
c)
y‚Ä≤‚Ä≤ + y = 3 cost
d)
y‚Ä≤‚Ä≤ ‚àí3y‚Ä≤ + 2y = et
e)
y‚Ä≤‚Ä≤ ‚àí9y = e‚àí3t
f)
y‚Ä≤‚Ä≤ ‚àí2y‚Ä≤ ‚àí3y = sin t
29. Solve the Cauchy problems:
a)
‚éß
‚é™
‚é®
‚é™
‚é©
y‚Ä≤‚Ä≤ + 2y‚Ä≤ + 5y = 0
y(0) = 0
y‚Ä≤(0) = 2
b)
‚éß
‚é™
‚é®
‚é™
‚é©
y‚Ä≤‚Ä≤ ‚àí5y‚Ä≤ + 4y = 2t + 1
y(0) = 7
8
y‚Ä≤(0) = 0

494
10 Ordinary diÔ¨Äerential equations
30. Integrate the following linear ODEs of order n:
a)
y‚Ä≤‚Ä≤‚Ä≤ + y‚Ä≤‚Ä≤ ‚àí2y = 0
b) y‚Ä≤‚Ä≤‚Ä≤ ‚àí2y‚Ä≤‚Ä≤ + y‚Ä≤ = 0
c)
y(4) ‚àí5y‚Ä≤‚Ä≤‚Ä≤ + 7y‚Ä≤‚Ä≤ ‚àí5y‚Ä≤ + 6y = sin t
31.
Determine the general integral of y‚Ä≤‚Ä≤ + y‚Ä≤ ‚àí6y = ekt in function of the real k.
32. Determine the general integral of the diÔ¨Äerential equation y‚Ä≤‚Ä≤ ‚àí2y‚Ä≤+(1+k)y =
0, as k varies in R.
33.
Determine the general integral of
y‚Ä≤‚Ä≤‚Ä≤ ‚àí2y‚Ä≤‚Ä≤ + 49y‚Ä≤ ‚àí98y = 48 sin t + (Œ≤2 + 49)eŒ≤t
for every Œ≤ in R.
34. Determine the general integral of the ODE y‚Ä≤‚Ä≤‚Ä≤ + 9ay‚Ä≤ = cos 3t in function of
a ‚ààR.
35.
Discuss the stability of the origin in R3 for the equation
y‚Ä≤ = Ay
with
A =
‚éõ
‚éù
‚àí3
0
‚àí5
0
‚àí1
0
5
0
‚àí2
‚éû
‚é†.
36.
Study the stability of y0 = (‚àí3, 1) for the following equation in R2:
y‚Ä≤ = f(y)
where
f(y) = (3y1y2 ‚àí2y2
2 + 11)i + (y1 + 3y2)j .
10.9.1 Solutions
1. ODEs with separable variables:
a) The map h(y) = y has a zero at y = 0, which is thus a singular integral.
Suppose y Ã∏= 0 and separate variables, so that
 1
y dy =

t + 2
t(t + 1) dt = log
ct2
|t + 1| ,
c > 0 .
Passing to exponentials,
y = y(t) = c
t2
t + 1 ,
c Ã∏= 0 .
The singular integral y = 0 is obtained by putting c = 0 in the general formula.

10.9 Exercises
495
c) y = y(t) = 1 + c log2 t
1 ‚àíc log2 t ,
c ‚ààR .
2. Homogeneous ODEs:
a) Supposing t Ã∏= 0 and dividing by 4t2 gives
y‚Ä≤ = 1
4
y2
t2 + 3
2
y
t ‚àí3
4 .
Substitute z = y
t , so that y‚Ä≤ = z + tz‚Ä≤ and then
z + tz‚Ä≤ = 1
4z2 + 3
2z ‚àí3
4 ,
4tz‚Ä≤ = (z ‚àí1)(z + 3) .
Since œï(z) = (z ‚àí1)(z + 3) vanishes at z = 1 and z = ‚àí3, we get y = t and
y = ‚àí3t as singular integrals. For the general integral we separate the variables,

4
(z ‚àí1)(z + 3) dz =
 1
t dt .
Then exponentiating
log

z ‚àí1
z + 3
 = log c|t| ,
c > 0
and solving for z, we have
z = 1 + 3ct
1 ‚àíct ,
c ‚ààR ,
in which the singular integral z = 1 is included. Altogether, the general integral
of the equation is
y = t + 3ct2
1 ‚àíct ,
c ‚ààR .
b) y = y(t) = ‚àí
t
log log c|t| ,
c > 0 .
3. Linear equations:
a) Formula (10.24), with a(t) = 1
t and b(t) = ‚àí3t+2
t3 , gives
y = e

1
t dt

e‚àí
1
t dt
	
‚àí3t + 2
t3

dt = 3
2t + 2
3t2 + ct ,
c ‚ààR .
b) y = 2t arctant + ct ,
c ‚ààR .

496
10 Ordinary diÔ¨Äerential equations
4. Bernoulli equations:
a) In the notation of Sect. 10.3.4,
p(t) = ‚àí1 ,
q(t) = 1
t ,
Œ± = 2 .
As Œ± = 2 > 0, y(t) = 0 is a solution. Now divide by y2,
1
y2 y‚Ä≤ = 1
ty ‚àí1 ,
and set z = z(t) = y1‚àí2 = 1
y; then z‚Ä≤ = ‚àí1
y2 y‚Ä≤ and the equation reads z‚Ä≤ =
1 ‚àí1
t z. Solving for z,
z = z(t) = t2 + c
2t
,
c ‚ààR .
Therefore,
y = y(t) =
1
z(t) =
2t
t2 + c ,
c ‚ààR
to which we have to add y(t) = 0.
b) We have
p(t) = t log t ,
q(t) = 1
t ,
Œ± = ‚àí1 .
Set z = y2, so z‚Ä≤ = 2yy‚Ä≤ and the equation reads
z‚Ä≤ = 2
t z + 2t log t .
Integrating the linear equation in z thus obtained, we have
z = z(t) = t2(log2 t + c) ,
c ‚ààR .
Therefore,
y = y(t) = ¬±t
#
log2 t + c ,
c ‚ààR .
5. The ODE is separable. The constant solution y = 0 is not valid because it fails
the initial condition y(0) = 1. By separating variables we get

1
1 ‚àíe‚àíy dy =

1
2t + 1 dx ;
Then
log |1 ‚àíey| = 1
2 log |2t + 1| + c ,
c ‚ààR .
Solving for y, and noticing that y = 0 corresponds to c = 0, we obtain the general
integral:
y = log

1 ‚àíc

|2t + 1|

,
c ‚ààR.

10.9 Exercises
497
The datum y(0) = 1 forces c = 1 ‚àíe, so
y = log

1 + (e ‚àí1)

|2t + 1|

.
6. The equation‚Äôs general integral reads
y = e‚àí

2 dt

e

2 dte‚àí2t dt = e‚àí2t(t + c) ,
c ‚ààR .
The condition is y‚Ä≤(0) = 0. Setting x = 0 in y‚Ä≤(t) = ‚àí2y(t) + e‚àí2t gives the new
condition y(0) = 1
2, from which c = 1
2. Thus,
y = e‚àí2t
	
t + 1
2

.
7. y = log

2et4(log t‚àí1
4 ) ‚àí1

.
8. y = ‚àí
8
(4 ‚àít2)3/2 .
9. y = sin t ‚àí1
cos t
.
10. The equation is
2yy‚Ä≤ = y2 + t
y
i.e.,
y‚Ä≤ = 1
2y +
t
2y2 .
It can be made into a Bernoulli equation by taking
p(t) = t
2 ,
q(t) = 1
2 ,
Œ± = ‚àí2 .
Set z = z(t) = y3, so that z‚Ä≤ = 3y2y‚Ä≤ and z‚Ä≤ = 3
2z + 3
2t. Solving for z,
z = z(t) = ce(3/2)t ‚àít ‚àí2
3 .
Therefore
y = y(t) =
3

ce(3/2)t ‚àít ‚àí2
3 .
The initial condition y(0) = 1 Ô¨Ånally gives c = 5/3, so
y = y(t) =
3

5
3e(3/2)t ‚àít ‚àí2
3 .
11. y = y(t) = 1
6t3 + 1
2t ‚àí2
3.
12. This second-order equation can be reduced to Ô¨Årst order by y‚Ä≤ = z(y), and
observing z‚Ä≤ = 1
z
4
y3 . Then z = z(y) satisÔ¨Åes z2 = ‚àí4
y2 + c1. Using the initial
conditions plus y‚Ä≤ = z(y) must give
(‚àí
‚àö
3)2 = ‚àí1 + c1
i.e.,
c1 = 4 .

498
10 Ordinary diÔ¨Äerential equations
Therefore
z2 = 4
y2 (y2 ‚àí1)
hence
z = ‚àí2
y

y2 ‚àí1
(the minus sign is due to y‚Ä≤(0) = ‚àí
‚àö
3). Now the equation is separable:
y‚Ä≤ = ‚àí2
y

y2 ‚àí1 .
Solving

y2 ‚àí1 = ‚àí2t + c2
with y(0) = 2 produces c2 =
‚àö
3, and then
y = y(t) =
#
1 + (
‚àö
3 ‚àí2t)2 .
13. y = y(t) = esinh t.
14. The ODE is linear, and the general integral is straightforward
y = e
 (2+Œ±) dt

e‚àí (2+Œ±) dt(‚àí2eŒ±t) dt = eŒ±t(1 + c e2t) ,
c ‚ààR.
From y(0) = 3 we Ô¨Ånd 3 = 1 + c, so c = 2. The solution is thus
y = eŒ±t(1 + 2e2t).
15. Directly from the formula for linear ODEs,
y = ea

1
t dt
	
3

e‚àía

1
t dttb dt

= ta
	
3

tb‚àía dt

=
‚éß
‚é®
‚é©
ta
	
3
b ‚àía + 1 tb‚àía+1 + c

if b ‚àía Ã∏= ‚àí1,
ta (3 log t + c)
if b ‚àía = ‚àí1 ,
=
‚éß
‚é®
‚é©
3
b ‚àía + 1tb+1 + c ta
if b ‚àía Ã∏= ‚àí1,
3ta log t + cta
if b ‚àía = ‚àí1.
Now, y(2) = 1 imposes
‚éß
‚é®
‚é©
3
b ‚àía + 1 2b+1 + c 2a = 1
if b ‚àía Ã∏= ‚àí1,
3 ¬∑ 2a log 2 + c 2a = 1
if b ‚àía = ‚àí1 ,
so
‚éß
‚é®
‚é©
c = 2‚àía
	
1 ‚àí
3
b ‚àía + 1 2b+1

if b ‚àía Ã∏= ‚àí1,
c = 2‚àía ‚àí3 log 2
if b ‚àía = ‚àí1.

10.9 Exercises
499
The solution is
y =
‚éß
‚é™
‚é®
‚é™
‚é©
3
b ‚àía + 1 tb+1 + 2‚àía
	
1 ‚àí
3
b ‚àía + 1 2b+1

ta
if b ‚àía Ã∏= ‚àí1,
3ta log t +

2‚àía ‚àí3 log 2

ta
if b ‚àía = ‚àí1.
16. The integral of this linear equation is
y = e‚àí3  t dt

e3  t dt kt dt = k
3 + c e‚àí3
2 t2,
c ‚ààR.
Condition y(0) = 0 implies c = ‚àík
3. Therefore
y = k
3

1 ‚àíe‚àí3
2 t2
.
17. Solving the ODE y‚Ä≤ = y2‚àí2y‚àí3
2(1+4t) :
a) y(t) = 3 + c

|1 + 4t|
1 ‚àíc

|1 + 4t|
, c ‚ààR, plus the constant solution y(t) = ‚àí1.
b) y0(t) = 3 ‚àí

|1 + 4t|
1 +

|1 + 4t|
;
18. We have dom f = {(t, y) ‚ààR2 : t + y ‚â•0}. As
‚àáf =
	
1
2‚àöt + y,
1
2‚àöt + y

,
f is Lipschitz in y on every Œ© where
1
2‚àöt+y is bounded. Since
sup
t‚àà(Œ±,Œ≤), y‚àà(Œ≥,Œ¥)
1
2‚àöt + y =
1
2‚àöŒ± + Œ≥ ,
the condition holds for any real Œ±, Œ≥ such that Œ± + Œ≥ > 0. The end-points Œ≤, Œ¥ are
completely free, and may also be +‚àû.
19. Global solutions:
a) We have
‚àÇf1
‚àÇyj
=
yj
1 + y2
1 + y2
2
,
‚àÇf2
‚àÇyj
=
1
1 + (y1 + y2)2 ,
1 ‚â§j ‚â§2 ,
so
 ‚àÇfi
‚àÇyj
 ‚â§1 on R2. Hence f is Lipschitz on D = R2, and every solution exists
on the whole I = R.

500
10 Ordinary diÔ¨Äerential equations
b) The map f is certainly diÔ¨Äerentiable on Rn, with continuous partial derivatives
(as composites of C1 elementary functions; besides, the denominator is never
zero). Partial derivatives are thus bounded by Weierstrass‚Äô Theorem, making
f locally Lipschitz on Rn. Moreover,
‚à•f(y)‚à•‚â§
1
(log 2)3 ‚à•y‚à•,
‚àÄy ‚ààRn .
Therefore Theorem 10.19 holds, and any solution exists on I = R.
20. Existence of Ô¨Årst integrals:
a) As y¬∑f(y) = 0 the equation is conservative, so Œ¶(y) = 1
2‚à•y‚à•2 is a Ô¨Årst integral
(Example 10.22 i)).
b) Since div f(y) = 8y1y3
2 + 2y2 ‚àí(8y1y3
2 + 2y2) = 0 on R2, f is a curl, and the
equation admits a Ô¨Årst integral Œ¶ such that curl Œ¶ = f. Then
‚àÇŒ¶
‚àÇy2
= 4y2
1y3
2 + 2y1y2 ,
‚àí‚àÇŒ¶
‚àÇy1
= ‚àí(2y1y4
2 + y2
2) ;
integrating the Ô¨Årst gives
Œ¶(y) = y2
1y4
2 + y1y2
2 + c(y1) ,
and using the second we Ô¨Ånd c(y1) = constant. Hence a family of Ô¨Årst integrals
is
Œ¶(y) = y2
1y4
2 + y1y2
2 + c .
21. General integrals:
a) y(t) = c1et
	
1
2

+ c2e5t
	
1
1

.
b) y(t) = c1e3t
	
cos 4t
sin 4t

+ c2e3t
	
‚àísin 4t
cos 4t

.
c) The matrix A has eigenvalues Œª1 = 1, Œª2 = 2, Œª3 = 3 corresponding to
eigenvectors
v1 = (1, 0, 3)T ,
v2 = (0, 1, 0)T ,
v1 = (2, 5, 5)T .
The general integral is thus of type
y(t) = c1et
‚éõ
‚éù
1
0
3
‚éû
‚é†+ c2e2t
‚éõ
‚éù
0
1
0
‚éû
‚é†+ c3e3t
‚éõ
‚éù
2
5
5
‚éû
‚é†.

10.9 Exercises
501
d) A has eigenvalues Œª1 = 3, Œª2,3 = 2 ¬± 3i with eigenvectors
v1 = (2, 0, 1)T ,
v2,3 = (1, ¬±i, 1)T .
Thus
y(t) = c1e3t
‚éõ
‚éù
2
0
1
‚éû
‚é†+ c2e2t
‚éõ
‚éù
cos 3t
‚àísin 3t
cos 3t
‚éû
‚é†+ c3e2t
‚éõ
‚éù
sin 3t
cos 3t
sin 3t
‚éû
‚é†
is the general integral.
e) y(t) = c1
‚éõ
‚éù
1
0
0
‚éû
‚é†+ c2e‚àí3t
‚éõ
‚éù
cos t
‚àí3 cost ‚àísin t
8 cost + 6 sin t
‚éû
‚é†+ c3e‚àí3t
‚éõ
‚éù
‚àísin t
‚àícost + 3 sin t
6 cos t ‚àí8 sin t
‚éû
‚é†.
f) A has eigenvalues Œª1 = 4 with multiplicity 2, and Œª2 = ‚àí8. The eigenvectors
of Œª1 are v(1)
1
= (1, 0, 0)T and v(2)
1
= (0, 3, 2)T, while the eigenvector corres-
ponding to Œª2 is v2 = (0, 3, ‚àí2)T. Therefore
y(t) = c1e‚àí8t
‚éõ
‚éù
0
3
‚àí2
‚éû
‚é†+ c2e4t
‚éõ
‚éù
1
0
0
‚éû
‚é†+ c3e4t
‚éõ
‚éù
0
3
2
‚éû
‚é†.
g) The matrix A has one eigenvalue Œª = 3 of multiplicity 3. There are two
linearly independent eigenvectors v(1)
1
= (0, 1, 0)T, v(2)
1
= (0, 0, 1)T. Moreover,
the latter gives a generalised eigenvector r1 = (1, 0, 0)T . Therefore
y(t) = c1e3t
‚éõ
‚éù
0
1
0
‚éû
‚é†+ c2e3t
‚éõ
‚éù
0
0
1
‚éû
‚é†+ c3e3t
‚éõ
‚éùt
‚éõ
‚éù
0
0
1
‚éû
‚é†+
‚éõ
‚éù
1
0
0
‚éû
‚é†
‚éû
‚é†.
h) The matrix A has a unique eigenvalue Œª = 1 with multiplicity 3, and one
eigenvector v1 = (0, 0, 1)T . This produces two generalised eigenvectors r1 =
(1/4, 0, 0)T, r2 = (0, 1/20, 0)T. Hence
y(t) = c1et
‚éõ
‚éù
0
0
1
‚éû
‚é†+ c2et
‚éõ
‚éùt
‚éõ
‚éù
0
0
1
‚éû
‚é†+
‚éõ
‚éù
1/4
0
0
‚éû
‚é†
‚éû
‚é†
+c3et
‚éõ
‚éùt2
2
‚éõ
‚éù
0
0
1
‚éû
‚é†+ t
‚éõ
‚éù
1/4
0
0
‚éû
‚é†+
‚éõ
‚éù
0
1/20
0
‚éû
‚é†
‚éû
‚é†
is the general integral.
22. Particular integrals:
a) We have
y(t) =
‚éõ
‚éù
0
0
‚àí1/2
‚éû
‚é†t2 +
‚éõ
‚éù
‚àí1
0
0
‚éû
‚é†t +
‚éõ
‚éù
0
1
0
‚éû
‚é†.

502
10 Ordinary diÔ¨Äerential equations
b) We have
y(t) =
‚éõ
‚éù
‚àí25/18
‚àí7/18
7/144
‚éû
‚é†e‚àí2t .
c) A particular integral is
y(t) =
‚éõ
‚éù
‚àí2/3
0
1/6
‚éû
‚é†cos 2t +
‚éõ
‚éù
0
‚àí1/3
‚àí1/12
‚éû
‚é†sin 2t .
23. We have
y1(t) = 1
3e‚àí2t + 2
3e4t ,
y2(t) = 2
3e‚àí2t + 1
3e4t ,
y3(t) = ‚àí4
3e‚àí2t + 4
3e4t .
24. The system reads, in normal form,
y‚Ä≤ = Ay
with
A =
	
1
2
‚àí1
3

.
The eigenvalues of A are Œª1,2 = 2 ¬± i corresponding to v1,2 = (2, 1 ¬± i)T . The
general integral is
y(t) = e2t
	
c1
	
2 cos t
cos t ‚àísin t

+ c2
	
2 sin t
cos t + sin t


.
Imposing the constraints gives c1 = 1, c2 = ‚àí2.
25. The eigenvalues of A =
	
‚àí1
b
b
‚àí1

are Œª1,2 = ‚àí1 ¬± b.
If b Ã∏= 0, they are distinct, with corresponding eigenvectors v1 = (1, 1)T, v2 =
(1, ‚àí1)T, and the general integral is
y(t) = c1e(b‚àí1)t
	
1
1

+ c2e‚àí(1+b)t
	
1
‚àí1

.
If b = 0 the eigenvectors stay the same, but the integral reads
y(t) = c1e‚àít
	
1
1

+ c2e‚àít
	
1
‚àí1

.
In either case the initial datum gives c1 = 1 and c2 = 0. The required solution is,
for any b,
y(t) = e(b‚àí1)t
	
1
1

.

10.9 Exercises
503
26. For a Ã∏= 1
2, a Ã∏= 1,
y(t) = c1eat
‚éõ
‚éù
2a ‚àí1
3 ‚àí2a
1 ‚àí2a
‚éû
‚é†+ c2e(1+a)t
‚éõ
‚éù
2a ‚àí2
2 ‚àía
0
‚éû
‚é†+ c3e(3a‚àí1)t
‚éõ
‚éù
0
1
0
‚éû
‚é†;
for a = 1,
y(t) = c1et
‚éõ
‚éù
1
1
‚àí1
‚éû
‚é†+ c2e2t
‚éõ
‚éù
0
1
0
‚éû
‚é†+ c3e2t
‚éõ
‚éùt
‚éõ
‚éù
0
1
0
‚éû
‚é†+
‚éõ
‚éù
‚àí1
0
0
‚éû
‚é†
‚éû
‚é†;
for a = 1/2,
y(t) = c1e(3/2)t
‚éõ
‚éù
‚àí1
3/2
0
‚éû
‚é†+ c2e(1/2)t
‚éõ
‚éù
0
1
0
‚éû
‚é†+ c3e(1/2)t
‚éõ
‚éùt
‚éõ
‚éù
0
1
0
‚éû
‚é†+
‚éõ
‚éù
‚àí1/2
0
1/2
‚éû
‚é†
‚éû
‚é†;
27. Calling y1 = x, y2 = y, y3 = y‚Ä≤ we may write y‚Ä≤ = Ay where
A =
‚éõ
‚éù
2
‚àí1
0
0
0
1
‚àí10
5
‚àí2
‚éû
‚é†.
The matrix A has eigenvalues Œª1 = 0, Œª2 = 3, Œª3 = ‚àí3 and, correspondingly,
v1 = (1, 2, 0)T ,
v2 = (1, ‚àí1, ‚àí3)T ,
v3 = (1, 5, ‚àí15)T .
Consequently, the general integral is
y(t) = c1
‚éõ
‚éù
1
2
0
‚éû
‚é†+ c2e3t
‚éõ
‚éù
1
‚àí1
‚àí3
‚éû
‚é†+ c3e‚àí3t
‚éõ
‚éù
1
5
‚àí15
‚éû
‚é†
i.e.,
x(t) = c1 + c2e3t + c3e‚àí3t ,
y(t) = 2c1 ‚àíc2e3t + 5c3e‚àí3t .
28. Second-order linear equations:
a) y(t; c1, c2) = c1e‚àít + c2e‚àí2t + 1
2t2 ‚àí3
2t + 9
4 , c1, c2 ‚ààR .
b) We solve Ô¨Årst the homogeneous equation. The characteristic equation Œª2‚àí4Œª+
4Œª = 0 has one double solution Œª = 2, so the general homogeneous integral will
be
y0(t; c1, c2) = (c1 + c2t)e2t ,
c1, c2 ‚ààR .
Since Œº = Œª = 2, we look for a particular integral yp(t) = Œ±t2e2t. This gives
2Œ±e2t = e2t
by substitution, hence Œ± = 1
2. Therefore yp(t) = 1
2t2e2t and the general integral
is
y(t; c1, c2) = (c1 + c2t)e2t + 1
2t2e2t ,
c1, c2 ‚ààR .

504
10 Ordinary diÔ¨Äerential equations
c) The characteristic equation Œª2 + 1 = 0 has discriminant Œî = ‚àí4, so œÉ = 0 and
œâ = 1. The general integral of the homogeneous equation is
y0(t; c1, c2) = c1 cos t + c2 sin t ,
c1, c2 ‚ààR .
As Œº = œÉ = 0, we need to Ô¨Ånd a particular integral yp(t) = t(Œ± cos t + Œ≤ sin t).
By substitution,
‚àí2Œ± sin t + 2Œ≤ cos t = 3 cost ,
so Œ± = 0 and Œ≤ = 3
2. Therefore yp(t) = 3
2t cos t and the general integral is
y(t; c1, c2) = c1 cos t + c2 sin t + 3
2t cos t ,
c1, c2 ‚ààR .
d) y(t; c1, c2) = c1et + c2e2t ‚àítet , c1, c2 ‚ààR .
e) The characteristic equation Œª2 ‚àí9 = 0 is solved by Œª = ¬±3. Hence the general
integral of the homogeneous ODE is
y0(t; c1, c2) = c1e‚àí3t + c2e3t ,
c1, c2 ‚ààR .
The particular integral must have form yp(t) = Œ±te‚àí3t, so substituting,
‚àí6Œ±e‚àí3t = e‚àí3t ,
hence Œ± = ‚àí1
6. Therefore yp(t) = ‚àí1
6te‚àí3t and the general integral of the
equation is
y(t; c1, c2) = c1e‚àí3t + c2e3t ‚àí1
6te‚àí3t ,
c1, c2 ‚ààR .
f) y(t; c1, c2) = c1e‚àít + c2e3t + 1
10 cos t ‚àí1
5 sin t , c1, c2 ‚ààR .
29. Cauchy problems:
a) y(t) = e‚àít sin 2t .
b) Let us treat the homogeneous equation Ô¨Årst. The characteristic equation Œª2 ‚àí
5Œª + 4 = 0 gives Œª = 1, Œª = 4. Thus the homogeneous general integral is
y0(t; c1, c2) = c1et + c2e4t ,
c1, c2 ‚ààR .
Substituting the particular integral yp(t) = Œ±t + Œ≤ in the equation we Ô¨Ånd
‚àí5Œ± + 4Œ±t + 4Œ≤ = 2t + 1 ,
so Œ± = 1
2 and Œ≤ = 7
8. Therefore yp(t) = 1
2t + 7
8 and the general solution is
y(t; c1, c2) = c1et + c2e4t + 1
2t + 7
8 ,
c1, c2 ‚ààR .

10.9 Exercises
505
Imposing the initial conditions gives the system
! c1 + c2 = 0
c1 + 4c2 + 1
2 = 0 ,
so c1 = 1
6 and c2 = ‚àí1
6. Therefore
y = 1
6et ‚àí1
6e4t + 1
2t + 7
8 .
30. Linear ODEs of order n:
a) The characteristic polynomial œá(Œª) = Œª3 + Œª2 ‚àí2 has a real root Œª1 = 1 and
two complex-conjugate zeroes Œª2,3 = ‚àí1 ¬± i. Then the general integral, in real
form, is
y(t) = c1et + c2e‚àít cos t + c3e‚àít sin t ,
c1, c2, c3 ‚ààR .
b) y(t) = c1et + c2tet + c3 ,
c1, c2, c3 ‚ààR .
c) The characteristic polynomial œá(Œª) = Œª4 ‚àí5Œª3 +7Œª2 ‚àí5Œª+6 has roots Œª1 = 2,
Œª2 = 3, Œª3,4 = ¬±i. The homogeneous general integral is thus
y0(t) = c1e2t + c2te3t + c3 cos t + c4 sin t ,
c1, c2, c3, c4 ‚ààR .
Because of resonance, we search for a particular integral of type
yp(t) = t(Œ± sin t + Œ≤ cos t) .
DiÔ¨Äerentiating, substituting in the ODE and comparing terms produces the
system
 Œ± + Œ≤ = 0 ,
10Œ± ‚àí10Œ≤ = 1 ,
whence
 Œ± = 1/20 ,
Œ≤ = ‚àí1/20 .
In conclusion,
y = y(t) = y0(t) + 1
20t(sin t ‚àícos t)
is the general integral.
31. The associated homogeneous equation has general integral
y0(t) = c1e2t + c2e‚àí3t ,
as one easily sees. The particular integral of the equation depends on k. In fact,
yp(t) =
 Œ±ekt
if k Ã∏= 2, k Ã∏= ‚àí3 ,
Œ±tekt
if k = 2, or k = ‚àí3

506
10 Ordinary diÔ¨Äerential equations
with the constant Œ± to be determined. DiÔ¨Äerentiating this expression and substi-
tuting,
Œ± =
‚éß
‚é™
‚é™
‚é®
‚é™
‚é™
‚é©
1
(k ‚àí2)(k + 3)
if k Ã∏= 2, k Ã∏= ‚àí3 ,
1
2k + 1
if k = 2, or k = ‚àí3 .
Therefore,
y(t) =
‚éß
‚é™
‚é™
‚é®
‚é™
‚é™
‚é©
c1e2t + c2e‚àí3t +
1
(k ‚àí2)(k + 3)ekt
if k Ã∏= 2, k Ã∏= ‚àí3 ,
c1e2t + c2e‚àí3t +
1
2k + 1tekt
if k = 2, or k = ‚àí3 .
32. We have
y(t) =
‚éß
‚é™
‚é®
‚é™
‚é©
et
c1 cos
‚àö
k t + c2 sin
‚àö
k t

if k > 0 ,
et(c1 + tc2)
if k = 0 ,
c1e(1+‚àö‚àík)t + c2e(1‚àí‚àö‚àík)t
if k < 0 ,
with c1, c2 ‚ààR.
33. The characteristic polynomial
œá(Œª) = Œª3 ‚àí2Œª2 + 49Œª ‚àí98 = (Œª ‚àí2)(Œª2 + 49)
has roots Œª1 = 2, Œª2,3 = ¬±7i. The homogeneous integral reads
y0(t) = c1e2t + c2 cos 7t + c3 sin 7t ,
c1, c2, c3 ‚ààR .
Putting b1(t) = 48 sin t and b2(t) = (Œ≤2 + 49)eŒ≤t, by the principle of superposition
we begin with a particular integral of the equation with source b1 of the form
yp1(t) = a cost + b sin t. This will give a = ‚àí1/5 and b = ‚àí2/5.
The other term b2 depends on the parameter Œ≤. When Œ≤ Ã∏= 2, we want a
particular integral yp2(t) = aeŒ≤t. Proceeding as usual, we obtain a = 1/(Œ≤ ‚àí2).
When Œ≤ = 2, the particular integral will be yp2(t) = ate2t and in this case we Ô¨Ånd
a = 1. So altogether, the general integral is
y(t) =
!
y0(t) +
1
Œ≤‚àí2eŒ≤t ‚àí1
5 cos t ‚àí2
5 sin t
if Œ≤ Ã∏= 2 ,
y0(t) + te2t ‚àí1
5 cos t ‚àí2
5 sin t
if Œ≤ = 2 .
34. We have
y(t) =
‚éß
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é™
‚é©
c1 + c2e3‚àö‚àía t + c3e‚àí3‚àö‚àía t +
1
27(a ‚àí1) sin 3t
if a < 0 ,
c1 + c2t + c3t2 ‚àí1
27 sin 3t
if a = 0 ,
c1 + c2 cos 3‚àöa t + c3 sin 3‚àöa t +
1
27(a ‚àí1) sin 3t
if a > 0, a Ã∏= 1 ,
c1 + c2 cos 3t + c3 sin 3t ‚àít
18 cos 3t
if a = 1 .

10.9 Exercises
507
35. The eigenvalues of A are Œª1 = ‚àí1, Œª2,3 = ‚àí5¬±
‚àö
163
2
, so Re Œª < 0 for both. The
origin is thus uniformly asymptotically stable (see Proposition 10.46).
36. We have
Jf(y) =
	
3y2
3y1 ‚àí4y2
1
3

.
The matrix
Jf(‚àí3, 1) =
	
‚àí9
‚àí11
1
3

has eigenvalues Œª1 = ‚àí8, Œª2 = 2, so the origin is unstable (Corollary 10.48).

Appendices

A.1
Complements on diÔ¨Äerential calculus
In this appendix, the reader may Ô¨Ånd the proofs of various results presented in
Chapters 5, 6, and 7. In particular, we prove Schwarz‚Äôs Theorem and we justify
the Taylor formulas with Lagrange‚Äôs and Peano‚Äôs remainders, as well as the rules
for diÔ¨Äerentiating integrals. At last, we prove Dini‚Äôs implicit function Theorem in
the two dimensional case.
A.1.1 DiÔ¨Äerentiability and Schwarz‚Äôs Theorem
‚ñ∂Proof of Proposition 5.8, p. 163
Proposition 5.8 Assume f admits continuous partial derivatives in a neigh-
bourhood of x0. Then f is diÔ¨Äerentiable at x0.
Proof. For simplicity we consider only the case n = 2.
Let then x = (x, y) be a point in the neighbourhood of x0 = (x0, y0) where the
hypotheses hold. Call (h, k) = (x ‚àíx0, y ‚àíy0); we must prove that for (h, k) ‚Üí
(0, 0),
f(x0 + h, y0 + k) = f(x0, y0) + ‚àÇf
‚àÇx(x0, y0)h + ‚àÇf
‚àÇy (x0, y0)k + o(

h2 + k2) .
Using the Ô¨Årst formula of the Ô¨Ånite increment for the map x ‚Üíf(x, y0) gives
f(x0 + h, y0) = f(x0, y0) + ‚àÇf
‚àÇx(x0, y0)h + o(h) ,
h ‚Üí0 .
At the same time, Lagrange‚Äôs Mean Value Theorem tells us that y ‚Üíf(x0 + h, y)
satisÔ¨Åes
f(x0 + h, y0 + k) = f(x0 + h, y0) + ‚àÇf
‚àÇy (x0 + h, y)k
C. Canuto, A. Tabacco: Mathematical Analysis II, 2nd Ed.,
UNITEXT ‚Äì La Matematica per il 3+2 85, DOI 10.1007/978-3-319-12757-6_A1,
¬© Springer International Publishing Switzerland 2015

512
A.1 Complements on diÔ¨Äerential calculus
for some y = y(h, k) between y0 and y0 + k. Since ‚àÇf
‚àÇy is continuous on the neigh-
bourhood of (x0, y0), we have
‚àÇf
‚àÇy (x, y) = ‚àÇf
‚àÇy (x0, y0) + o(1) ,
(x, y) ‚Üí(x0, y0) ,
and because (x0 + h, y) ‚Üí(x0, y0) for (h, k) ‚Üí(0, 0), we may write
‚àÇf
‚àÇy (x0 + h, y) = ‚àÇf
‚àÇy (x0, y0) + o(1) ,
(h, k) ‚Üí(0, 0) .
In conclusion, when (h, k) ‚Üí(0, 0),
f(x0 + h, y0 + k) = f(x0, y0) + ‚àÇf
‚àÇx(x0, y0)h + ‚àÇf
‚àÇy (x0, y0)k + o(h) + o(1)k .
But o(h) + o(1)k = o(
‚àö
h2 + k2) , (h, k) ‚Üí(0, 0). In fact, |h|, |k| ‚â§
‚àö
h2 + k2
implies
|o(h)|
‚àö
h2 + k2 ‚â§|o(h)|
|h|
=

o(h)
h
 ‚Üí0 ,
(h, k) ‚Üí(0, 0)
and
|o(1)k|
‚àö
h2 + k2 ‚â§|o(1)k|
|k|
= |o(1)| ‚Üí0 ,
(h, k) ‚Üí(0, 0) .
The claim now follows.
2
‚ñ∂Proof of Schwarz‚Äôs Theorem, p. 168
Theorem 5.17 (Schwarz) If the mixed partial derivatives
‚àÇ2f
‚àÇxj‚àÇxi
and
‚àÇ2f
‚àÇxi‚àÇxj
(j Ã∏= i) exist on a neighbourhood of x0 and are continuous at x0,
they coincide at x0.
Proof. For simplicity let us only consider n = 2. We have to prove
‚àÇ2f
‚àÇy‚àÇx(x0, y0) = ‚àÇ2f
‚àÇx‚àÇy(x0, y0) ,
under the assumption that the derivatives exist on a neighbourhood Br(x0, y0) of
x0 = (x0, y0) and are continuous at x0.
Let x = (x, y) ‚ààBr(x0, y0) and set (h, k) = (x ‚àíx0, y ‚àíy0). Consider the
function
g(h, k) = f(x0 + h, y0 + k) ‚àíf(x0 + h, y0) ‚àíf(x0, y0 + k) + f(x0, y0) .

A.1.2
Taylor‚Äôs expansions
513
Putting œï(x) = f(x, y0 + k) ‚àíf(x, y0) we see that
g(h, k) = œï(x0 + h) ‚àíœï(x0) .
The second formula of the Ô¨Ånite increment for the function x ‚Üíœï(x) gives a point
Œæ = Œæ(h, k), between x0 and x0 + h, for which
g(h, k) = hœï‚Ä≤(Œæ) = h
‚àÇf
‚àÇx(Œæ, y0 + k) ‚àí‚àÇf
‚àÇx(Œæ, y0)

.
Let us use the same formula again, this time to œà(y) = ‚àÇf
‚àÇx(Œæ, y), to obtain a point
Œ∑ = Œ∑(h, k) between y0 and y0 + k such that
‚àÇf
‚àÇx(Œæ, y0 + k) ‚àí‚àÇf
‚àÇx(Œæ, y0) = k ‚àÇ2f
‚àÇy‚àÇx(Œæ,Œ∑ )
and so
g(h, k) = hk ‚àÇ2f
‚àÇy‚àÇx(Œæ,Œ∑ ) .
Now letting (h, k) ‚Üí(0, 0) we have (Œæ,Œ∑ ) ‚Üí(x0, y0); therefore, since
‚àÇ2f
‚àÇy‚àÇx is
continuous at (x0, y0), we will have
lim
(h,k)‚Üí(0,0)
g(h, k)
hk
=
lim
(Œæ,Œ∑)‚Üí(x0,y0)
‚àÇ2f
‚àÇy‚àÇx(Œæ,Œ∑ ) = ‚àÇ2f
‚àÇy‚àÇx(x0, y0) .
(A.1.1)
But we can write g as
g(h, k) = f(x0+h, y0+k)‚àíf(x0, y0+k)‚àíf(x0+h, y0)+f(x0, y0) = Àúœà(y0+k)‚àíÀúœà(y0) ,
having put Àúœà(y) = f(x0 + h, y) ‚àíf(x0, y). Swapping the variables and proceeding
as before gives
lim
(h,k)‚Üí(0,0)
g(h, k)
hk
= ‚àÇ2f
‚àÇx‚àÇy(x0, y0) .
(A.1.2)
Since the limit on the left in (A.1.1) and (A.1.2) is the same, the equality follows.
2
A.1.2 Taylor‚Äôs expansions
‚ñ∂Proof of Theorem 5.20, p. 172
Theorem 5.20 A function f of class C2 around x0 admits at x0 the Taylor
expansion of order one with Lagrange‚Äôs remainder:
f(x) = f(x0) + ‚àáf(x0) ¬∑ (x ‚àíx0) + 1
2(x ‚àíx0) ¬∑ Hf(x)(x ‚àíx0) ,
where x is interior to the segment S[x, x0].

514
A.1 Complements on diÔ¨Äerential calculus
Proof. Set Œîx = x ‚àíx0 = (Œîxi)1‚â§i‚â§n for simplicity. We consider the function
of one real variable œï(t) = f(x0 + tŒîx), deÔ¨Åned around t0 = 0, and show it
is diÔ¨Äerentiable twice around 0. In that case we will Ô¨Ånd its Taylor expansion of
second order. Property 5.11 ensures that œï is diÔ¨Äerentiable on some neighbourhood
of the origin, with
œï‚Ä≤(t) = ‚àáf(x0 + tŒîx) ¬∑ Œîx =
n

i=1
Œîxi
‚àÇf
‚àÇxi
(x0 + tŒîx) .
Now set œài(t) = ‚àÇf
‚àÇxi (x0 + tŒîx) and use Property 5.11 on them, to obtain
œà‚Ä≤
i(t) = ‚àá
 ‚àÇf
‚àÇxi

(x0 + tŒîx) ¬∑ Œîx =
n

j=1
‚àÇ2f
‚àÇxj‚àÇxi
(x0 + tŒîx)Œîxj .
This implies œï can be diÔ¨Äerentiated twice, and also that
œï‚Ä≤‚Ä≤(t) =
n

i=1
Œîxi
n

j=1
‚àÇ2f
‚àÇxj‚àÇxi
(x0 + tŒîx)Œîxj
= Œîx ¬∑ Hf(x0 + tŒîx)Œîx ,
as Hf is symmetric.
The Taylor expansion of œï of order two, centred at t0 = 0, and computed at t = 1
reads
œï(1) = œï(0) + œï‚Ä≤(0) + 1
2œï‚Ä≤‚Ä≤(t)
con
0 < t < 1 ;
substituting the expressions of œï‚Ä≤(0) and œï‚Ä≤‚Ä≤(t) found earlier, and putting x =
x0 + tŒîx, proves the claim.
2
‚ñ∂Proof of Theorem 5.21, p. 172
Theorem 5.21 A function f of class C2 around x0 admits at x0 the following
Taylor expansion of order two with Peano‚Äôs remainder:
f(x) = f(x0) + ‚àáf(x0) ¬∑ (x ‚àíx0) + 1
2(x ‚àíx0) ¬∑ Hf(x0)(x ‚àíx0)
+o(‚à•x ‚àíx0‚à•2) ,
x ‚Üíx0 .
Proof. Consider the generic summand
1
2
‚àÇ2f
‚àÇxj‚àÇxi
(x)ŒîxiŒîxj

A.1.3
DiÔ¨Äerentiating functions deÔ¨Åned by integrals
515
in the quadratic part on the right-hand side of (5.15). As the second derivative of
f is continuous at x0 and x belongs to the segment S[x, x0], we have
‚àÇ2f
‚àÇxj‚àÇxi
(x) =
‚àÇ2f
‚àÇxj‚àÇxi
(x0) + Œ∑ij(x) ,
where lim
x‚Üíx0 Œ∑ij(x) = 0. Hence
‚àÇ2f
‚àÇxj‚àÇxi
(x)ŒîxiŒîxj =
‚àÇ2f
‚àÇxj‚àÇxi
(x0)ŒîxiŒîxj + Œ∑ij(x)ŒîxiŒîxj .
We will prove the last term is in fact o(‚à•Œîx‚à•2); for this, we recall that 0 ‚â§
(a ‚àíb)2 = a2 + b2 ‚àí2ab for any pair of real numbers a, b, so that ab ‚â§1
2(a2 + b2).
Now note that the following inequalities hold
|Œîxi| |Œîxj| ‚â§1
2(|Œîxi|2 + |Œîxj|2) ‚â§1
2‚à•Œîx‚à•2 ,
so
0 ‚â§|Œ∑ij(x)ŒîxiŒîxj|
‚à•Œîx‚à•2
‚â§1
2|Œ∑ij(x)|
and then
lim
x‚Üíx0
Œ∑ij(x)ŒîxiŒîxj
‚à•Œîx‚à•2
= 0 .
In summary,
1
2(x ‚àíx0) ¬∑ Hf(x)(x ‚àíx0) = 1
2(x ‚àíx0) ¬∑ Hf(x0)(x ‚àíx0)
+o(‚à•x ‚àíx0‚à•2) ,
x ‚Üíx0 ,
whence the result.
2
A.1.3 DiÔ¨Äerentiating functions deÔ¨Åned by integrals
First, we state the following result, of great importance per se, that will be used
below.
Theorem A.1.1 (Heine-Cantor) Let f : dom f ‚äÜRn ‚ÜíRm be a continu-
ous map on a compact set Œ© ‚äÜdom f. Then f is uniformly continuous on
Œ©.
Proof. The proof is similar to what we saw in the one dimensional case, using
the multidimensional version of the Bolzano-Weierstrass Theorem (see Vol. I, Ap-
pendix A.3).
2

516
A.1 Complements on diÔ¨Äerential calculus
‚ñ∂Proof of Theorem 6.17, p. 215
Proposition 6.17 The function f deÔ¨Åned by (6.14) is continuous on I.
Moreover, if g admits continuous partial derivative ‚àÇg
‚àÇx on R, then f is of
class C1 on I and
f ‚Ä≤(x) =
 b
a
‚àÇg
‚àÇx(x, y) dy .
Proof. Suppose x0 is an interior point of I (the proof can be easily adapted to the
case where x0 is an end-point). Then there is a œÉ > 0 such that [x0‚àíœÉ, x0 +œÉ] ‚äÇI;
the rectangle E = [x0 ‚àíœÉ, x0 + œÉ] √ó J isa compact set in R2.
Let us begin by proving the continuity of f at x0. As we assumed g continu-
ous on R, hence on the compact subset E, Heine-Cantor‚Äôs Theorem implies g
is uniformly continuous on E. Hence, for any Œµ > 0 there is a Œ¥ > 0 such that
|g(x1) ‚àíg(x2)| < Œµ for any pair of points x1 = (x1, y1), x2 = (x2, y2) in E with
‚à•x1 ‚àíx2‚à•< Œ¥. We may assume Œ¥ < œÉ. Let now x ‚àà[x0 ‚àíœÉ, x0 + œÉ] be such that
|x ‚àíx0| < Œ¥; for any given y in [a, b], then,
‚à•(x, y) ‚àí(x0, y)‚à•= |x ‚àíx0| < Œ¥ ,
so |g(x, y) ‚àíg(x0, y)| < Œµ. Therefore
|f(x)‚àíf(x0)| =

 b
a

g(x, y)‚àíg(x0, y)

dy
 ‚â§
 b
a
g(x, y)‚àíg(x0, y)
 dy < Œµ(b‚àía) ,
proving continuity.
As for diÔ¨Äerentiability at x0, in case ‚àÇg
‚àÇx exists and is continuous on I √ó J, we
observe
f(x) ‚àíf(x0)
x ‚àíx0
=
1
x ‚àíx0
 b
a

g(x, y) ‚àíg(x0, y)

dy =
 b
a
g(x, y) ‚àíg(x0, y)
x ‚àíx0
dy .
Given y ‚àà[a, b], we can use The Mean Value Theorem (in dimension 1) on x ‚Üí
g(x, y). This gives a point Œæ between x and x0 for which
g(x, y) ‚àíg(x0, y)
x ‚àíx0
= ‚àÇg
‚àÇx(Œæ, y) .
By assumption, ‚àÇg
‚àÇx is uniformly continuous on E (again by Heine-Cantor‚Äôs The-
orem). Consequently, for any Œµ > 0 there is a Œ¥ > 0 (Œ¥ < œÉ) such that, if x1, x2 ‚ààE
with ‚à•x1‚àíx2‚à•< Œ¥, we have
‚àÇg
‚àÇx(x1)‚àí‚àÇg
‚àÇx(x2)
 < Œµ. In particular, when x1 = (Œæ, y)
and x2 = (x0, y) with ‚à•x1 ‚àíx2‚à•= |Œæ ‚àíx0| < Œ¥, we have

A.1.3
DiÔ¨Äerentiating functions deÔ¨Åned by integrals
517
‚àÇg
‚àÇx(Œæ, y) ‚àí‚àÇg
‚àÇx(x0, y)
 < Œµ .
Therefore

f(x) ‚àíf(x0)
x ‚àíx0
‚àí
 b
a
‚àÇg
‚àÇx(x0, y) dy

=

 b
a
	g(x, y) ‚àíg(x0, y)
x ‚àíx0
‚àí‚àÇg
‚àÇx(x0, y)

dy

=

 b
a
	‚àÇg
‚àÇx(Œæ, y) ‚àí‚àÇg
‚àÇx(x0, y)

dy
 < Œµ(b ‚àía)
which proves diÔ¨Äerentiability at x0 and also the formula
f ‚Ä≤(x0) =
 b
a
‚àÇg
‚àÇx(x0, y) dy .
2
‚ñ∂Proof of Theorem 6.18, p. 215
Proposition 6.18 If Œ± and Œ≤ are continuous on I, the map f deÔ¨Åned by (6.15)
is continuous on I. If moreover g admits continuous partial derivative ‚àÇg
‚àÇx on
R and Œ±, Œ≤ are C1 on I, then f is C1 on I, and
f ‚Ä≤(x) =
 Œ≤(x)
Œ±(x)
‚àÇg
‚àÇx(x, y) dy + Œ≤‚Ä≤(x)g

x,Œ≤ (x)

‚àíŒ±‚Ä≤(x)g

x,Œ± (x)

.
Proof. The only thing to prove is the continuity of f, because the rest is shown
on p. 215.
As in the previous argument, we may Ô¨Åx x0 ‚ààI and assume it is an interior
point. Call E = [x0‚àíœÉ, x0+œÉ]√óJ ‚äÇR, the set on which g is uniformly continuous.
Let now Œµ > 0; since g is uniformly continuous on E and by the continuity of the
maps Œ± and Œ≤ on I, there is a number Œ¥ > 0 (with Œ¥ < œÉ) such that |x ‚àíx0| < Œ¥
implies
|g(x, y) ‚àíg(x0, y)| < Œµ ,
for all y ‚ààJ ,
and
|Œ±(x) ‚àíŒ±(x0)| < Œµ ,
|Œ≤(x) ‚àíŒ≤(x0)| < Œµ .
Then, setting M =
max
(x,y)‚ààE |g(x, y)| gives
|f(x) ‚àíf(x0)| =
 Œ≤(x)
Œ±(x)
g(x, y) dy ‚àí
 Œ≤(x0)
Œ±(x0)
g(x0, y) dy

518
A.1 Complements on diÔ¨Äerential calculus
=
 Œ±(x0)
Œ±(x)
g(x, y) dy +
 Œ≤(x0)
Œ±(x0)
g(x, y) dy +
+
 Œ≤(x)
Œ≤(x0)
g(x, y) dy ‚àí
 Œ≤(x0)
Œ±(x0)
g(x0, y) dy
=
 Œ±(x0)
Œ±(x)
g(x, y) dy +
 Œ≤(x)
Œ≤(x0)
g(x, y) dy +
‚àí
 Œ≤(x0)
Œ±(x0)

g(x, y) ‚àíg(x0, y)

dy
‚â§M|Œ±(x) ‚àíŒ±(x0)| + M|Œ≤(x) ‚àíŒ≤(x0)| + Œµ|Œ≤(x0) ‚àíŒ±(x0)|
‚â§

2M + |Œ≤(x0) ‚àíŒ±(x0)|

Œµ
and f‚Äôs continuity at x0 follows immediately.
2
A.1.4 The Implicit Function Theorem
‚ñ∂Proof of Theorem 7.1, p. 263
Teorema 7.1 Let Œ© be a non-empty open set in R2 and f : Œ© ‚ÜíR a C1 map.
Assume at the point (x0, y0) ‚ààŒ© we have f(x0, y0) = 0. If ‚àÇf
‚àÇy (x0, y0) Ã∏= 0,
there exists a neighbourhood I of x0 and a function œï : I ‚ÜíR such that:
i)

x,œï (x)

‚ààŒ© for any x ‚ààI;
ii) y0 = œï(x0);
iii) f

x,œï (x)

= 0 for any x ‚ààI;
iv) œï is a C1 map on I with derivative
œï‚Ä≤(x) = ‚àí
‚àÇf
‚àÇx

x,œï (x)

‚àÇf
‚àÇy

x,œï (x)
 .
(A.1.3)
On a neighbourhood of (x0, y0) moreover, the zero set of f coincides with the
graph of œï.
Proof. Since the map fy = ‚àÇf
‚àÇy is continuous and non-zero at (x0, y0), the local
invariance of the function‚Äôs sign (¬ß 4.5.1) guarantees there exists a neighbourhood
A ‚äÜŒ© of (x0, y0) where fy Ã∏= 0 has constant sign. On a such neighbourhood the
auxiliary map g(x, y) = ‚àífx(x, y)/fy(x, y) is well deÔ¨Åned and continuous.

A.1.4
The Implicit Function Theorem
519
Consider then the Cauchy problem (Section 10.4)
{ y ‚Ä≤ = g(x, y)y(x0) = y0 .
This admits, by Peano‚Äôs Theorem 10.10, a solution y = œï(x) deÔ¨Åned and of class
C1 on a neighbourhood I of x0 such that

x,œï (x)

‚ààA for any x ‚ààI. Thus
conditions i) and ii) hold; but then also iv) is satisÔ¨Åed, by deÔ¨Ånition of solution
to the diÔ¨Äerential equation. As for iii), we deÔ¨Åne the map h(x) = f

x,œï (x)

: it
satisÔ¨Åes, on I,
h‚Ä≤(x) = fx

x,œï (x)

+ fy

x,œï (x)

œï‚Ä≤(x)
= fx

x,œï (x)

+ fy

x,œï (x)

g

x,œï (x)

= fx

x,œï (x)

+ fy

x,œï (x)


‚àífx

x,œï (x)

fy

x,œï (x)


= 0 ,
so it is constant; but as h(x0) = f(x0, y0) = 0, h is necessarily the zero map,
wherefore iii).
Concerning the last statement, note that if (x, y) ‚ààA with x ‚ààI, then
f(x, y) = f

x,œï (x)

+
 y
œï(x)
‚àÇf
‚àÇy (x, s) ds =
 y
œï(x)
‚àÇf
‚àÇy (x, s) ds
as a consequence of the Fundamental Theorem of Calculus (Vol. I, Cor. 9.42)
applied to y ‚Üíf(x, y). The integral vanishes if and only if y = œï(x), because
the integrand is always diÔ¨Äerent from 0 (recall the property stated in Vol. I,
Thm. 9.33 iii)). Therefore on the neighbourhood of (x0, y0) where x ‚ààI we have
f(x, y) = 0 precisely when y = œï(x).
2

A.2
Complements on integral calculus
In this appendix, we Ô¨Årst introduce the notion of norm of a function, illustrated by
several examples including norms of integral type. Next, we justify the Theorems
of Gauss, Green and Stokes; for the sake of clarity, we conÔ¨Åne our discussion to
the case of speciÔ¨Åc, yet representative, geometries. The proof of the equivalence
between conservative Ô¨Åelds and irrotational Ô¨Åelds in simply connected domains
is the subsequent result. In the last section, we brieÔ¨Çy outline the language of
diÔ¨Äerential forms, and we express various properties of vector Ô¨Åelds, discussed in
the text, using the corresponding terminology.
A.2.1 Norms of functions
The norm of a function is a non-negative real number that somehow provides
a measure of the ‚Äúsize‚Äù of the function. For instance, if f is a function and Àúf
is another function approximating it, the norm of the diÔ¨Äerence f ‚àíÀúf gives a
quantitative indication of the quality of the approximation: a small value of the
norm corresponds, in a suitable sense, to a good approximation of f by means
of Àúf.
DeÔ¨Ånition A.2.1 Given a family F of real functions deÔ¨Åned on a set Œ© ‚äÜ
Rn, that forms a vector space, we call norm a map from F to R, denoted by
f ‚Üí‚à•f‚à•, that fulÔ¨Ålls the following properties: for all f, g ‚ààF and all Œ± ‚ààR
one has
i) ‚à•f‚à•‚â•0 and ‚à•f‚à•= 0 if and only if f = 0 (positivity);
ii) ‚à•Œ±f‚à•= |Œ±|‚à•f‚à•(homogeneity);
iii) ‚à•f + g‚à•‚â§‚à•f‚à•+ ‚à•g‚à•(triangle inequality).
Note the analogy with the properties that deÔ¨Åne a norm over vectors in Rn.
C. Canuto, A. Tabacco: Mathematical Analysis II, 2nd Ed.,
UNITEXT ‚Äì La Matematica per il 3+2 85, DOI 10.1007/978-3-319-12757-6_A2,
¬© Springer International Publishing Switzerland 2015

522
A.2 Complements on integral calculus
Remarkable examples of norms of functions are as follows. If F denotes the
vector space of the bounded functions on the set Œ©, it is easily checked that
‚à•f‚à•‚àû,Œ© = sup
x‚ààŒ©
|f(x)|
is a norm, called the supremum norm or inÔ¨Ånity norm. It has been introduced
in Sect. 2.1 for Œ© = A ‚äÜR. If in addition Œ© is a compact subset of Rn and we
restrict ourselves to consider the continuous functions on Œ©, namely f ‚ààC0(Œ©),
then the supremum in the previous deÔ¨Ånition is actually a maximum, as the func-
tion |f(x)| is continuous on Œ© and Weierstrass‚Äô Theorem 5.24 applies to it. So we
deÔ¨Åne
‚à•f‚à•C0(Œ©) = max
x‚ààŒ© |f(x)| = ‚à•f‚à•‚àû,Œ© ,
which is called the maximum norm in the space C0(Œ©).
Other commonly used norms are those of integral type, which measure the size
of a function ‚Äúin the average‚Äù. If Œ© is a measurable set and F is the vector space
of all Riemann-integrable functions on Œ© (recall Theorem 8.20), we may deÔ¨Åne the
absolute-value norm, or 1-norm, as
‚à•f‚à•1,Œ© =

Œ©
|f(x)| dx
as well as the quadratic norm, or 2-norm, as
‚à•f‚à•2,Œ© =
	
Œ©
|f(x)|2 dx

1/2
.
The latter norm has been introduced in Sect. 3.2 for Œ© = [0, 2œÄ] ‚äÇR. The two
integral norms deÔ¨Åned above are instances in the family of p-norms, with real
1 ‚â§p < +‚àû, deÔ¨Åned as
‚à•f‚à•p,Œ© =
	
Œ©
|f(x)|p dx

1/p
.
The quadratic norm is particularly important, since it is associated to a scalar
product between integrable functions; its deÔ¨Ånition is
(f, g)2,Œ© =

Œ©
f(x)g(x) dx,
and one has ‚à•f‚à•2,Œ© =

(f, f)2,Œ© . In general, the following deÔ¨Ånition applies.

A.2.1
Norms of functions
523
DeÔ¨Ånition A.2.2 A scalar product (or inner product) in F is a map
from F √ó F to R, denoted by f, g ‚Üí(f, g), that fulÔ¨Ålls the following properties:
for all f, g, f1, f2 ‚ààF and all Œ±,Œ≤ ‚ààR one has
i) (f, f) ‚â•0 and (f, f) = 0 if and only if f = 0 (positivity);
ii) (f, g) = (g, f) (symmetry);
iii) (Œ±f1 + Œ≤f2, g) = Œ±(f1, g) + Œ≤(f2, g) (linearity).
It is easily checked that the quantity ‚à•f‚à•= (f, f)1/2 is a norm, called the norm
associated with the scalar product under consideration. It satisÔ¨Åes the Cauchy-
Schwarz inequality
|(f, g)| ‚â§‚à•f‚à•‚à•g‚à•,
‚àÄf, g ‚ààF .
A scalar product allows us to deÔ¨Åne the concept of orthogonality between
functions: two functions f, g ‚ààF are called orthogonal if (f, g) = 0. In a vector
space endowed with a scalar product, the Theorem of Pythagoras holds; it is
expressed by the relation
‚à•f + g‚à•2 = ‚à•f‚à•2 + ‚à•g‚à•2
if and only if
(f, g) = 0 .
Indeed, one has
‚à•f + g‚à•2 = (f + g, f + g)
= (f, f) + (f, g) + (g, f) + (g, g)
= ‚à•f‚à•2 + 2(f, g) + ‚à•g‚à•2 ,
whence the equivalence.
Going back to norms, for a diÔ¨Äerentiable function it may be useful to measure
the size of its derivatives, in addition to that of the function. For instance, if Œ©
is a bounded open set in Rn, consider the vector space C1(Œ©) of the functions of
class C1 on the compact set Œ© (see Sect. 5.4); then, it is natural to deÔ¨Åne therein
the norm
‚à•f‚à•C1(Œ©) = ‚à•f‚à•C0(Œ©) +
n

i=1
‚à•Dxif‚à•C0(Œ©) .
If the maximum norms in this deÔ¨Ånition are replaced by norms of integral type
(such as the quadratic norms of f and its Ô¨Årst-order partial derivatives Dxif), we
obtain the so-called Sobolev norms.

524
A.2 Complements on integral calculus
A.2.2 The Theorems of Gauss, Green, and Stokes
‚ñ∂Proof of Proposition 9.30, p. 391
Proposition 9.30 Let the open set Œ© ‚äÇR3 be G-admissible, and assume
f ‚ààC0(Œ©) with ‚àÇf
‚àÇxi
‚ààC0(Œ©), i ‚àà{1, 2, 3}. Then

Œ©
‚àÇf
‚àÇxi
dx dy dz =

‚àÇŒ©
fni dœÉ ,
where ni is the ith component of the outward normal to ‚àÇŒ©.
Proof. Without loss of generality take i = 3. As claimed, we shall prove the
statement only for open, piecewise-regular sets that are normal for x3 = z. We
begin by assuming further that Œ© is regular and normal for z, and use the notation
introduced in Example 9.27 ii).
Integrating along segments and then by parts we obtain

Œ©
‚àÇf
‚àÇz (x, y, z) dx dy dz =

D
 Œ≤(x,y)
Œ±(x,y)
‚àÇf
‚àÇz (x, y, z) dz dx dy
=

D
f

x, y,Œ≤ (x, y)

dx dy ‚àí

D
f

x, y,Œ± (x, y)

dx dy .
(A.2.1)
As nz|Œ£Œ≤ = 1/‚à•ŒΩŒ≤‚à•, recalling (9.12) and (9.11), we have

D
f

x, y,Œ≤ (x, y)

dx dy =

D
f

x, y,Œ≤ (x, y)

nz|Œ£Œ≤ (x, y)‚à•ŒΩŒ≤(x, y)‚à•dx dy
=

Œ£Œ≤
fnz dœÉ .
Likewise, nz|Œ£Œ± = ‚àí1/‚à•ŒΩŒ±‚à•, hence
‚àí

D
f

x, y,Œ± (x, y)

dx dy =

D
f

x, y,Œ± (x, y)

nz|Œ£Œ±(x, y)‚à•ŒΩŒ±(x, y)‚à•dx dy
=

Œ£Œ±
fnz dœÉ .
Eventually, from nz|Œ£‚Ñì= 0 follows

Œ£‚Ñì
fnz dœÉ = 0 .

A.2.2
The Theorems of Gauss, Green, and Stokes
525
We conclude that

‚àÇŒ©
fnz dœÉ =

Œ£Œ≤
fnz dœÉ +

Œ£Œ±
fnz dœÉ +

Œ£‚Ñì
fnz dœÉ
=

D
f

x, y,Œ≤ (x, y)

dx dy ‚àí

D
f

x, y,Œ± (x, y)

dx dy
and the assertion follows from (A.2.1).
Now let us suppose the open set is piecewise regular and normal for z, as in
Example 9.27 iii). Call {Œ©k}k=1,...,K a partition of Œ© into regular, normal sets for
z. Using the above result on each Œ©k, we have

Œ©
‚àÇf
‚àÇz dx dy dz =
K

k=1

‚àÇŒ©k
fn(k)
z
dœÉ .
(A.2.2)
If Œì = ‚àÇŒ©k ‚à©‚àÇŒ©h denotes the intersection of two partition elements (intersection
which we assume bigger than a point), then n(k)
|Œì = ‚àín(h)
|Œì and

Œì
fn(k)
z
dœÉ +

Œì
fn(h)
z
dœÉ = 0 .
In other terms, the integrals over the parts of boundary of each Œ©k that are
contained in Œ© cancel out in pairs; what remains on the right-hand side of (A.2.2)
is
K

k=1

‚àÇŒ©k‚à©‚àÇŒ©
fn(k)
z
dœÉ =

‚àÇŒ©
fnz dœÉ ,
proving the claim.
2
‚ñ∂Proof of Green‚Äôs Theorem, p. 394
Theorem 9.35 (Green) Let Œ© ‚äÇR2 be a G-admissible open set whose bound-
ary ‚àÇŒ© is positively oriented. Take a vector Ô¨Åeld f = f1i + f2j in

C1(Œ©)
2.
Then

Œ©
‚àÇf2
‚àÇx ‚àí‚àÇf1
‚àÇy

dx dy =
4
‚àÇŒ©
f ¬∑ œÑ .
Proof. From (6.6) we know that curl f = (curlŒ¶ )3, Œ¶ being the three-dimensional
vector Ô¨Åeld f + 0k (constant in z). Setting Q = Œ© √ó (0, 1) as in the proof of The-
orem 9.32,

Œ©
‚àÇf2
‚àÇx ‚àí‚àÇf1
‚àÇy

dx dy =

Œ©
curl f dx dy =
 1
0

Œ©
(curlŒ¶ )3 dx dy dz
=

Q
(curlŒ¶ )3 dx dy dz .

526
A.2 Complements on integral calculus
Let us then apply Theorem 9.34 to the Ô¨Åeld Œ¶ ‚àà

C1(Œ©)
3, and consider the third
component of equation (9.21), giving

Q
(curlŒ¶ )3 dx dy dz =

‚àÇQ
(N ‚àßŒ¶)3 dœÉ ,
with N being the unit normal outgoing from ‚àÇQ. It is immediate to check (N ‚àß
Œ¶)3 = f2n1 ‚àíf1n2 = f ¬∑ t on ‚àÇŒ© √ó (0, 1), whereas (N ‚àßŒ¶)3 = 0 on Œ© √ó {0} and
Œ© √ó {1}. Therefore

‚àÇQ
(N ‚àßŒ¶)3 dœÉ =
 1
0

‚àÇŒ©
(N ‚àßŒ¶)3 dx dy dz =

‚àÇŒ©
f ¬∑ t dŒ≥ =
4
‚àÇŒ©
f ¬∑ œÑ ,
and the result follows.
2
‚ñ∂Proof of Stokes‚Äô Theorem, p. 396
Theorem 9.37 (Stokes) Let Œ£ ‚äÇR3 be an S-admissible compact surface
oriented by the unit normal n; correspondingly, let the boundary ‚àÇŒ£ be oriented
positively. Suppose the vector Ô¨Åeld f, deÔ¨Åned on an open set A ‚äÜR3 containing
Œ£, is such that f ‚àà

C1(A)
3. Then

Œ£
(curl f) ¬∑ n =
4
‚àÇŒ£
f ¬∑ œÑ .
In other words, the Ô¨Çux of the curl of f across the surface equals the path
integral of f along the surface‚Äôs (closed) boundary.
Proof. We start with the case in which Œ£ is the surface (9.15) from Example 9.29,
whose notations we retain; additionally, let us assume the function œï belongs to
C2(R). Where possible, partial derivatives will be denoted using subscripts x, y, z,
and likewise for the components of normal and tangent vectors. Recalling (9.13)
and the expression (9.16) for the unit normal of Œ£, we have

Œ£
(curl f) ¬∑ n =

R
(f2,z ‚àíf3,y)œïx + (f3,x ‚àíf1,z)œïy + (f2,x ‚àíf1,y) dx dy
=

R
‚àí(f1,y + f1,zœïy) + (f2,x + f3,zœïx) + (f3,xœïy ‚àíf3,yœïx) dx dy ,
where the derivatives of the components of f are taken on

x, y,œï (x, y)

as (x, y)
varies in R. By the chain rule f1,y + f1,zœïy is the partial derivative in y of the
map f1

x, y,œï (x, y)

; similarly, f2,x + f3,zœïx represents the partial x-derivative of
the map f2

x, y,œï (x, y)

. Moreover, adding and subtracting f3,zœïxœïy +f3,yœï2
xy to
formula f3,xœïy ‚àíf3,yœïx, we see that this expression equals

A.2.2
The Theorems of Gauss, Green, and Stokes
527
‚àÇ
‚àÇx

f3

x, y,œï (x, y)

œïy(x, y)

‚àí‚àÇ
‚àÇy

f3

x, y,œï (x, y)

œïx(x, y)

.
Therefore we can use the two-dimensinal analogue of Proposition 9.30 to obtain

Œ£
(curl f) ¬∑ n =

‚àÇR

‚àíf1ny + f2nx + f3(œïynx ‚àíœïxny)

dŒ≥ ,
(A.2.3)
where nx, ny are the components of the outgoing unit normal of ‚àÇR.
If Œ≥ : I ‚ÜíR2 denotes a positive parametrisation of the boundary of R, then
ny = ‚àíŒ≥‚Ä≤
1/‚à•Œ≥‚Ä≤‚à•and nx = Œ≥‚Ä≤
2/‚à•Œ≥‚Ä≤‚à•. Furthermore the arc Œ∑ : I ‚ÜíR3 given by Œ∑(t) =

Œ≥1(t), Œ≥2(t), œï(Œ≥1(t), Œ≥2(t))

is a positive parametrisation of ‚àÇŒ£ with respect to
the chosen orientation of Œ£. The corresponding tangen vector is given by (9.17).
Overall then, recalling the deÔ¨Ånitions of integral along a curve and line integral,

‚àÇR

‚àíf1ny + f2nx + f3(œïynx ‚àíœïxny)

dŒ≥ =

I
(f1Œ∑‚Ä≤
1 + f2Œ∑‚Ä≤
2 + f3Œ∑‚Ä≤
3) dt
=
4
‚àÇŒ£
f ¬∑ œÑ .
Equation (9.24) in the present case follows from (A.2.3).
Let us now suppose Œ£ is made by K faces Œ£1, . . . , Œ£K, each as above. Using
the result just found on every Œ£k, and summing over k, we Ô¨Ånd

Œ£
(curl f) ¬∑ n =
K

k=1
4
‚àÇŒ£k
f ¬∑ œÑ (k) .
(A.2.4)
If Œì = ‚àÇŒ£h ‚à©‚àÇŒ£k is the intersection of two faces (suppose not a point), the unit
tangents to ‚àÇŒ£h and ‚àÇŒ£k satisfy t(h)
|Œì = ‚àít(k)
|Œì , hence

Œì
f ¬∑ œÑ (h) +

Œì
f ¬∑ œÑ (k) = 0 .
That is, the integrals over the boundary parts common to two faces cancel out;
the right-hand side of (A.2.2) thus reduces to
K

k=1

‚àÇŒ£k‚à©‚àÇŒ£
f ¬∑ œÑ (k) =
4
‚àÇŒ£
f ¬∑ œÑ ,
proving the assertion.
2
‚ñ∂Proof of Theorem 9.45, p. 403
Theorem 9.45 Let Œ© ‚äÜRn, with n = 2 or 3, be open and simply connected.
A vector Ô¨Åeld f of class C1 on Œ© is conservative if and only if it is curl-free.

528
A.2 Complements on integral calculus
Proof. We have shown, in Proposition 9.43, the arrow f conservative ‚áíf curl-
free. Let us deal with the opposite implication.
First, though, we handle the two-dimensional case, and prove condition iii) of
Theorem 9.42. Suppose Œ≥ is a simple closed (i.e., Jordan) arc, (piecewise) regular
and with trace Œì contained in Œ©; its interior Œ£ is all contained Œ©. Hence we can
use Green‚Äôs Theorem 9.35 and conclude

Œ≥
f ¬∑ œÑ = ¬±

Œ£
curl f dx dy = 0
(the sign on the second integral is determined by the orientation of Œì). Should the
arc be not simple, we can decompose it in closed simple arcs to which the result
applies.
Now let us consider the three-dimensional picture, for which we discuss only
the case of star-shaped sets; build explicitly the potential f, in analogy to‚Äìand
using the notation of‚Äìthe proof of Theorem 9.42. Precisely, if P0 is the point for
which Œ© is star-shaped, we deÔ¨Åne the potential at P of coordinates x by setting
œï(x) =

Œì[P0,P ]
f ¬∑ œÑ
where Œì[P0,P ] is the segment joining P0 and P. We claim grad œï = f, and will
prove it for the Ô¨Årst component only. So let P + ŒîP = x + Œîx1 e1 ‚ààŒ© be a
nearby point to P, Œì[P0,P +ŒîP ] the segment joining P0 to P + ŒîP, and Œì[P,P +ŒîP ]
the (horizontal) segment from P to P + ŒîP. We wish to prove

Œì[P0,P +ŒîP ]
f ¬∑ œÑ ‚àí

Œì[P0,P ]
f ¬∑ œÑ =

Œì[P,P +ŒîP ]
f ¬∑ œÑ .
(A.2.5)
But this is straightforward if P0, P and P + ŒîP are collinear. If not, they form a
triangle Œ£, which is entirely contained in Œ©, the latter being star-shaped. Calling Œì
the boundary of Œ£ oriented from P0 to P along Œì[P0,P ], we invoke Stokes‚Äô Theorem
and have

Œì
f ¬∑ œÑ =

Œì
curl f ‚àßn = 0 ,
i.e.,

Œì[P0,P ]
f ¬∑ œÑ +

Œì[P0,P +ŒîP ]
f ¬∑ œÑ ‚àí

Œì[P,P +ŒîP ]
f ¬∑ œÑ = 0 ,
whence (A.2.5). Therefore
œï(x + Œîx1e1) ‚àíœï(x)
Œîx1
=
1
Œîx1

Œì[P,P +ŒîP ]
f ¬∑ œÑ
=
1
Œîx1
 Œîx1
0
f1(x + te1) dt ,
and we conclude as in Theorem 9.42.
2

A.2.3
DiÔ¨Äerential forms
529
A.2.3 DiÔ¨Äerential forms
In this section, we introduce a few essential notions about diÔ¨Äerential forms;
through them, it is possible to reformulate various deÔ¨Ånitions and relevant prop-
erties of vector Ô¨Åelds, that we encountered in previous chapters. The forthcoming
exposition is deliberately informal and far from being complete; our goal indeed is
just to establish a relation between certain notations adopted in this textbook and
the language of diÔ¨Äerential forms, which is commonly used in various applications.
Let us assume to be in dimension 3; as usual, the reduction to dimension
2 is straightforward, while several concepts may actually be formulated in any
dimension n. So, in the sequel Œ© will be an open set in R3.
A diÔ¨Äerential 0-form F is, in our notation, a real-valued function (also called
a scalar Ô¨Åeld) œï = œï(x, y, z) deÔ¨Åned in Œ©, i.e.,
F = œï .
A diÔ¨Äerential 1-form œâ is an expression like
œâ = P dx + Q dy + R dz ,
where P = P(x, y, z), Q = Q(x, y, z) and R = R(x, y, z) are scalar Ô¨Åelds deÔ¨Åned
in Œ©. In our notation, it corresponds to the vector Ô¨Åeld
f = P i + Q j + R k .
Thus, the symbols dx, dy and dz denote particular 1-forms, that span all the oth-
ers by linear combinations. They correspond to the vectors i, j and k, respectively,
of the canonical basis in R3.
An expression like

Œì
œâ =

Œì
(P dx + Q dy + R dz) ,
where Œì is an arc contained in Œ©, corresponds in our notation to the path integral

Œì
f ¬∑ œÑ .
Formally, the relationship may be motivated by multiplying and dividing by dt
under the integral sign,

Œì
œâ =

Œì
	
P dx
dt + Q dy
dt + R dz
dt

dt
and thinking of Œ≥(t) = (x(t), y(t), z(t)) as the parametrization of the arc Œì (re-
call (9.8) and (9.10)).

530
A.2 Complements on integral calculus
The derivative of a 0-form F is deÔ¨Åned as the 1-form
dF = ‚àÇœï
‚àÇx dx + ‚àÇœï
‚àÇy dy + ‚àÇœï
‚àÇz dz ,
obviously assuming the scalar Ô¨Åeld œï diÔ¨Äerentiable in Œ©. In our notation, this
relation is expressed as
f = grad œï .
A diÔ¨Äerential 1-form œâ is called exact if there exists a 0-form F such that
œâ = dF .
In our notation, this is equivalent to the property that the vector Ô¨Åeld f associated
with the form œâ is conservative.
It is possible to deÔ¨Åne the derivative of a 1-form œâ = P dx + Q dy + R dz as
the 2-form
dœâ =
	‚àÇR
‚àÇy ‚àí‚àÇQ
‚àÇz

dy‚àßdz +
	‚àÇP
‚àÇz ‚àí‚àÇR
‚àÇx

dz‚àßdx +
	‚àÇQ
‚àÇx ‚àí‚àÇP
‚àÇy

dx‚àßdy .
If we identify the symbols dx, dy and dz with the vectors of the canonical basis in
R3 and we formally interpret the symbol ‚àßas the external product of two vectors
(recall (4.5)), then we have dy ‚àßdz = dx, dz ‚àßdx = dy and dx ‚àßdy = dz; this
shows that, with respect to our notation, the diÔ¨Äerential form dœâ is associated
with the vector Ô¨Åeld
g = curl f
(recall (6.4)). In general, for a diÔ¨Äerential 2-form
Œ® = S dy‚àßdz + T dz‚àßdx + U dx‚àßdy ,
where S = S(x, y, z), T = T (x, y, z) and U = U(x, y, z) are scalar Ô¨Åelds, it is
possible to deÔ¨Åne the integral

Œ£
Œ®
over a surface Œ£ contained in Œ©; it corresponds, in our notation, to the Ô¨Çux integral

Œ£
g ¬∑ n
(recall (9.14)), where g = Si + T j + Uk is the vector Ô¨Åeld associated with the
form Œ®. In particular, we have

Œ£
dœâ =

Œ£
(curl f) ¬∑ n .

A.2.3
DiÔ¨Äerential forms
531
Hence, in the language of diÔ¨Äerential forms, Stokes‚Äô Theorem 9.37 takes the elegant
expression

Œ£
dœâ =

‚àÇŒ£
œâ .
A diÔ¨Äerential 1-form œâ is called closed if
dœâ = 0 ;
in our notation, this corresponds to the property that the vector Ô¨Åeld f associated
with the form is irrotational, i.e., it satisÔ¨Åes
curl f = 0 .
One has the property
d2F = d (dF) = 0
that in our notation is equivalent to the identity
curl grad œï = 0
(recall Proposition 6.7). Such a property may be formulated as
an exact diÔ¨Äerential 1-form is closed
that corresponds to state that a conservative vector Ô¨Åeld is irrotational (see Prop-
erty 9.43). If the domain Œ© is simply connected, then we have the equivalence
a diÔ¨Äerential 1-form is exact if and only if it is closed
that translates into the language of diÔ¨Äerential forms our Theorem 9.45, accord-
ing to which in such a domain a vector Ô¨Åeld is conservative if and only if it is
irrotational.

Basic deÔ¨Ånitions and formulas
Sequences and series
Geometric sequence (p. 3):
lim
n‚Üí‚àûqn =
‚éß
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é©
0
if |q| < 1,
1
if q = 1,
+‚àû
if q > 1,
does not exist
if q ‚â§‚àí1
.
The number e (p. 3):
e = lim
n‚Üí‚àû

1 + 1
n
n
=
‚àû

k=0
1
n!
Geometric series (p. 6):
‚àû

k=0
qk
‚éß
‚é™
‚é™
‚é™
‚é®
‚é™
‚é™
‚é™
‚é©
converges to
1
1 ‚àíq
if |q| < 1 ,
diverges to
+ ‚àû
if q ‚â•1 ,
is indeterminate
if q ‚â§‚àí1
Mengoli‚Äôs series (p. 7):
‚àû

k=2
1
(k ‚àí1)k = 1
Generalised harmonic series (p. 15):
‚àû

k=1
1
kŒ±
 converges if Œ± > 1 ,
diverges if Œ± ‚â§1
C. Canuto, A. Tabacco: Mathematical Analysis II, 2nd Ed.,
UNITEXT ‚Äì La Matematica per il 3+2 85, DOI 10.1007/978-3-319-12757-6,
¬© Springer International Publishing Switzerland 2015

534
DeÔ¨Ånitions and formulas
Power series
Convergence radius (p. 48):
R = sup

x ‚ààR :
‚àû

k=0
akxk converges

Ratio Test (p. 49):
lim
k‚Üí‚àû

ak+1
ak
 = ‚Ñì
=‚áí
R =
‚éß
‚é®
‚é©
0
if ‚Ñì= +‚àû,
+‚àû
if ‚Ñì= 0 ,
1/‚Ñì
if 0 < ‚Ñì< +‚àû
Root Test (p. 50):
lim
k‚Üí‚àû
k
|ak| = ‚Ñì
=‚áí
R =
‚éß
‚é®
‚é©
0
if ‚Ñì= +‚àû,
+‚àû
if ‚Ñì= 0 ,
1/‚Ñì
if 0 < ‚Ñì< +‚àû
.
Power series for analytic functions (p. 56):
f(x) =
‚àû

k=0
f (k)(x0)
k!
(x ‚àíx0)k
Special power series (p. 54 and 58):
1
1 ‚àíx =
‚àû

k=0
xk ,
x ‚àà(‚àí1, 1)
1
1 + x2 =
‚àû

k=0
(‚àí1)kx2k ,
x ‚àà(‚àí1, 1)
(1 + x)Œ± =
‚àû

k=0
	Œ±
k

xk ,
x ‚àà(‚àí1, 1)
ex =
‚àû

k=0
xk
k! ,
x ‚ààR
log(1 + x) =
‚àû

k=0
(‚àí1)k
k + 1 xk+1 =
‚àû

k=1
(‚àí1)k‚àí1
k
xk ,
x ‚àà(‚àí1, 1)
sin x =
‚àû

k=0
(‚àí1)k
(2k + 1)! x2k+1 ,
x ‚ààR
cos x =
‚àû

k=0
(‚àí1)k
(2k)! x2k ,
x ‚ààR

DeÔ¨Ånitions and formulas
535
Fourier series
Fourier coeÔ¨Écients of a map f (p. 82):
a0 = 1
2œÄ
 2œÄ
0
f(x) dx
ak = 1
œÄ
 2œÄ
0
f(x) cos kx dx ,
k ‚â•1
bk = 1
œÄ
 2œÄ
0
f(x) sin kx dx ,
k ‚â•1
ck = 1
2œÄ
 2œÄ
0
f(x)e‚àíikx dx ,
k ‚ààZZ
Fourier series of a map f ‚ààÀúC2œÄ (p. 85):
f ‚âàa0 +
‚àû

k=1
(ak cos kx + bk sin kx) ‚âà
+‚àû

k=‚àí‚àû
ckeikx
Parseval‚Äôs formula (p. 91):
 2œÄ
0
|f(x)|2 dx = 2œÄa2
0 + œÄ
+‚àû

k=1
(a2
k + b2
k) = 2œÄ
+‚àû

k=‚àí‚àû
|ck|2
Square wave (p. 85):
f(x) =
‚éß
‚é®
‚é©
‚àí1
if ‚àíœÄ < x < 0 ,
0
if x = 0, ¬±œÄ ,
1
if 0 < x < œÄ ,
f ‚âà4
œÄ
‚àû

m=0
1
2m + 1 sin(2m + 1)x
RectiÔ¨Åed wave (p. 87):
f(x) = | sin x| ,
f ‚âà2
œÄ ‚àí4
œÄ
‚àû

m=1
1
4m2 ‚àí1 cos 2mx
Sawtooth wave (p. 87):
f(x) = x ,
x ‚àà(‚àíœÄ,œÄ ) ,
f ‚âà
‚àû

k=1
2
k (‚àí1)k+1 sin kx

536
DeÔ¨Ånitions and formulas
Real-valued functions
Partial derivative (p. 157):
‚àÇf
‚àÇxi
(x0) = lim
Œîx‚Üí0
f(x0 + Œîx ei) ‚àíf(x0)
Œîx
Gradient (p. 157):
‚àáf(x0) = grad f(x0) =
 ‚àÇf
‚àÇxi
(x0)

1‚â§i‚â§n
DiÔ¨Äerential (p. 162):
dfx0(Œîx) = ‚àáf(x0) ¬∑ Œîx
Directional derivative (p. 163):
‚àÇf
‚àÇv (x0) = ‚àáf(x0) ¬∑ v = ‚àÇf
‚àÇx1
(x0) v1 + ¬∑ ¬∑ ¬∑ + ‚àÇf
‚àÇxn
(x0) vn
Second partial derivative (p. 168):
‚àÇ2f
‚àÇxj‚àÇxi
(x0) =
‚àÇ
‚àÇxj
	 ‚àÇf
‚àÇxi

(x0)
Hessian matrix (p. 169):
Hf(x0) = (hij)1‚â§i,j‚â§n
with
hij =
‚àÇ2f
‚àÇxj‚àÇxi
(x0)
Taylor expansion with Peano‚Äôs remainder (p. 172):
f(x) = f(x0) + ‚àáf(x0) ¬∑ (x ‚àíx0) + 1
2(x ‚àíx0) ¬∑ Hf(x0)(x ‚àíx0) + o(‚à•x ‚àíx0‚à•2)
Curl in dimension 2 (p. 206):
curl f = ‚àÇf
‚àÇx2
i ‚àí‚àÇf
‚àÇx1
j
Fundamental identity (p. 209):
curl grad f = ‚àá‚àß(‚àáf) = 0
Laplace operator (p. 211):
Œîf = div grad f = ‚àá¬∑ ‚àáf =
n

j=1
‚àÇ2f
‚àÇx2
j

DeÔ¨Ånitions and formulas
537
Vector-valued functions
Jacobian matrix (p. 202):
Jf(x0) =
 ‚àÇfi
‚àÇxj
(x0)

1 ‚â§i ‚â§m
1 ‚â§j ‚â§n
=
‚éõ
‚éú
‚éù
‚àáf1(x0)
...
‚àáfm(x0)
‚éû
‚éü
‚é†
DiÔ¨Äerential (p. 203):
dfx0(Œîx) = Jf(x0)Œîx
Divergence (p. 205):
div f = ‚àá¬∑ f = ‚àÇf1
‚àÇx1
+ ¬∑ ¬∑ ¬∑ + ‚àÇfn
‚àÇxn
=
n

j=1
‚àÇfj
‚àÇxj
Curl in dimension 3 (p. 205):
curl f = ‚àá‚àßf =
	 ‚àÇf3
‚àÇx2
‚àí‚àÇf2
‚àÇx3

i +
	 ‚àÇf1
‚àÇx3
‚àí‚àÇf3
‚àÇx1

j +
	 ‚àÇf2
‚àÇx1
‚àí‚àÇf1
‚àÇx2

k
Curl in dimension 2 (p. 205):
curl f = ‚àÇf2
‚àÇx1
‚àí‚àÇf1
‚àÇx2
Fundamental identity (p. 209):
div curl f = ‚àá¬∑ (‚àá‚àßf) = 0
Derivative of a composite map ‚Äì Chain rule (p. 212):
J(g ‚ó¶f)(x0) = Jg(y0) Jf(x0)
Tangent line to a curve (p. 217):
T (t) = Œ≥(t0) + Œ≥‚Ä≤(t0)(t ‚àít0) ,
t ‚ààR
Length of a curve (p. 222):
‚Ñì(Œ≥) =
 b
a
‚à•Œ≥‚Ä≤(t)‚à•dt
Tangent plane to a surface (p. 237):
Œ†(u, v) = œÉ(u0, v0) + ‚àÇœÉ
‚àÇu (u0, v0) (u ‚àíu0) + ‚àÇœÉ
‚àÇv (u0, v0) (v ‚àív0)
Normal vector of a surface (p. 238):
ŒΩ(u0, v0) = ‚àÇœÉ
‚àÇu (u0, v0) ‚àß‚àÇœÉ
‚àÇv (u0, v0)

538
DeÔ¨Ånitions and formulas
Polar coordinates
From polar to Cartesian coordinates (p. 230):
Œ¶ : [0, +‚àû) √ó R ‚ÜíR2 ,
(r,Œ∏ ) ‚Üí(x, y) = (r cosŒ∏, r sin Œ∏)
Jacobian matrix and determinant (p. 230):
JŒ¶(r,Œ∏ ) =
	 cos Œ∏
‚àír sin Œ∏
sin Œ∏
r cos Œ∏

,
det JŒ¶(r,Œ∏ ) = r
Partial derivatives in polar coordinates (p. 231):
‚àÇf
‚àÇr = ‚àÇf
‚àÇx cos Œ∏ + ‚àÇf
‚àÇy sin Œ∏ ,
‚àÇf
‚àÇŒ∏ = ‚àí‚àÇf
‚àÇxr sin Œ∏ + ‚àÇf
‚àÇy r cos Œ∏
‚àÇf
‚àÇx = ‚àÇf
‚àÇr cos Œ∏ ‚àí‚àÇg
‚àÇŒ∏
sin Œ∏
r
,
‚àÇf
‚àÇy = ‚àÇg
‚àÇr sin Œ∏ + ‚àÇf
‚àÇŒ∏
cos Œ∏
r
Variable change in double integrals (p. 320):

Œ©
f(x, y) dx dy =

Œ©‚Ä≤ f(r cos Œ∏, r sin Œ∏) r dr dŒ∏
Cylindrical coordinates
From cylindrical to Cartesian coordinates (p. 233):
Œ¶ : [0, +‚àû) √ó R2 ‚ÜíR3 ,
(r, Œ∏, t) ‚Üí(x, y, z) = (r cos Œ∏, r sin Œ∏, t)
Jacobian matrix and determinant (p. 233):
JŒ¶(r, Œ∏, t) =
‚éõ
‚éù
cos Œ∏
‚àír sin Œ∏
0
sin Œ∏
r cos Œ∏
0
0
0
1
‚éû
‚é†,
det JŒ¶(r, Œ∏, t) = r
Partial derivatives in cylindrical coordinates (p. 233):
‚àÇf
‚àÇr = ‚àÇf
‚àÇx cos Œ∏ + ‚àÇf
‚àÇy sin Œ∏ ,
‚àÇf
‚àÇŒ∏ = ‚àí‚àÇf
‚àÇxr sin Œ∏ + ‚àÇf
‚àÇy r cos Œ∏ ,
‚àÇf
‚àÇt = ‚àÇf
‚àÇz
‚àÇf
‚àÇx = ‚àÇf
‚àÇr cos Œ∏ ‚àí‚àÇf
‚àÇŒ∏
sin Œ∏
r
,
‚àÇf
‚àÇy = ‚àÇf
‚àÇr sin Œ∏ + ‚àÇf
‚àÇŒ∏
cos Œ∏
r
,
‚àÇf
‚àÇz = ‚àÇf
‚àÇt
Variable change in triple integrals (p. 328):

Œ©
f(x, y, z) dx dy dz =

Œ©‚Ä≤ f(r cos Œ∏, r sin Œ∏, t) r dr dŒ∏ dt

DeÔ¨Ånitions and formulas
539
Spherical coordinates
From spherical to Cartesian coordinates (p. 234):
Œ¶ : [0, +‚àû) √ó R2 ‚ÜíR3 ,
(r, œï,Œ∏ ) ‚Üí(x, y, z) = (r sin œï cos Œ∏, r sin œï sin Œ∏, r cos œï)
Jacobian matrix (p. 234):
JŒ¶(r, œï,Œ∏ ) =
‚éõ
‚éú
‚éù
sin œï cos Œ∏
r cos œï cos Œ∏
‚àír sin œï sin Œ∏
sin œï sin Œ∏
r cos œï sin Œ∏
r sin œï cos Œ∏
cos œï
‚àír sin œï
0
‚éû
‚éü
‚é†
Jacobian determinant (p. 234):
det JŒ¶(r, œï,Œ∏ ) = r2 sin œï
Partial derivatives in spherical coordinates (p. 233):
‚àÇf
‚àÇr = ‚àÇf
‚àÇx sin œï cos Œ∏ + ‚àÇf
‚àÇy sin œï sin Œ∏ + ‚àÇf
‚àÇz cos œï
‚àÇf
‚àÇœï = ‚àÇf
‚àÇxr cos œï cos Œ∏ + ‚àÇf
‚àÇy r cos œï sin Œ∏ ‚àí‚àÇf
‚àÇz r sin œï
‚àÇf
‚àÇŒ∏ = ‚àí‚àÇf
‚àÇxr sin œï sin Œ∏ + ‚àÇf
‚àÇy r sin œï cos Œ∏
‚àÇf
‚àÇx = ‚àÇf
‚àÇr sin œï cos Œ∏ + ‚àÇf
‚àÇœï
cos œï cos Œ∏
r
‚àí‚àÇf
‚àÇŒ∏
sin Œ∏
r sin œï
‚àÇf
‚àÇy = ‚àÇf
‚àÇr sin œï sin Œ∏ + ‚àÇf
‚àÇœï
cos œï sin Œ∏
r
+ ‚àÇf
‚àÇŒ∏
cos Œ∏
r sin œï
‚àÇf
‚àÇz = ‚àÇf
‚àÇr cos œï ‚àí‚àÇf
‚àÇœï
sin œï
r
Variable change in triple integrals (p. 329):

Œ©
f(x, y, z) dx dy dz =

Œ©‚Ä≤f(r sin œï cos Œ∏, r sin œï sin Œ∏, r cos œï) r2 sin œï dr dœï dŒ∏

540
DeÔ¨Ånitions and formulas
Multiple integrals
Vertical integration (p. 309):

Œ©
f =
 b
a
 g2(x)
g1(x)
f(x, y) dy

dx
Horizontal integration (p. 309):

Œ©
f =
 d
c
 h2(y)
h1(y)
f(x, y) dx

dy
Iterated integral (p. 324):

Œ©
f =

D
 g2(x,y)
g1(x,y)
f(x, y, z) dz

dx dy
Iterated integral (p. 325):

Œ©
f =
 Œ≤
Œ±
	
Az
f(x, y, z) dx dy

dz
Variable change in multiple integrals (p. 328):
.

Œ©
f(x) dŒ© =

Œ©‚Ä≤ f

Œ¶(u)

| det JŒ¶(u)| dŒ©‚Ä≤
Pappus‚Äô Centroid Theorem (p. 333):
vol(Œ©) = 2œÄyG area(T )

DeÔ¨Ånitions and formulas
541
Integrals on curves and surfaces
Integral along a curve (p. 368):

Œ≥
f =
 b
a
f

Œ≥(t)

‚à•Œ≥‚Ä≤(t)‚à•dt
Path integral (p. 375):

Œ≥
f ¬∑ œÑ =

Œ≥
fœÑ =
 b
a
f

Œ≥(t)

¬∑ Œ≥‚Ä≤(t) dt
Integral on a surface (p. 378):

œÉ
f =

R
f

œÉ(u, v)

‚à•ŒΩ(u, v)‚à•du dv
Flux integral (p. 384):

œÉ
f ¬∑ n =

œÉ
fn =

R
f

œÉ(u, v)

¬∑ ŒΩ(u, v) du dv
.
Divergence Theorem (p. 391):

Œ©
div f =

‚àÇŒ©
f ¬∑ n
Green‚Äôs Theorem (p. 394):

Œ©
‚àÇf2
‚àÇx ‚àí‚àÇf1
‚àÇy

dx dy =
4
‚àÇŒ©
f ¬∑ œÑ
Stokes‚Äô Theorem (p. 396):

Œ£
(curl f) ¬∑ n =
4
‚àÇŒ£
f ¬∑ œÑ

542
DeÔ¨Ånitions and formulas
Examples of quadrics
 
 
 
 
 
 
 
 
x
y
Ellipsoid
x2
a2 + y2
b2 + z2
c2 = 1
z
 
 
 
 
 
 
 
 
x
y
Hyperbolic paraboloid
z
c = ‚àíx2
a2 + y2
b2
z
 
 
 
 
 
 
 
 
x
y
Elliptic paraboloid
z
c = x2
a2 + y2
b2
z

DeÔ¨Ånitions and formulas
543
 
 
 
 
 
 
 
 
x
y
Cone
z2
c2 = x2
a2 + y2
b2
z
 
 
 
 
 
 
 
 
x
y
One-sheeted hyperboloid
x2
a2 + y2
b2 ‚àíz2
c2 = 1
z
 
 
 
 
 
 
 
 
x
y
Two-sheeted hyperboloid
z2
c2 ‚àíx2
a2 ‚àíy2
b2 = 1
z

Index
Arc, 139
closed, 139
end points, 139
Jordan, 139
length, 222‚Äì224
meridian, 144, 332
simple, 139
Area, 304, 368, 378, 381
Binormal, 226
Boundary, 243, 247
of a set, 120
Canonical basis, 112
Centre
of a power series, 45
of curvature, 226
of gravity, 330
of mass, 330, 374, 383
Centroid, 330, 383
Chain rule, 213
Change
of variable, 227, 317, 319
Closure
of a set, 120
CoeÔ¨Écients
Fourier, 85
of a power series, 45
Component, 247
connected, 125
Constraint, 277
Convergence
absolute, 41
pointwise, 34, 41, 93, 94
quadratic, 90, 91
uniform, 35, 42, 95
Coordinates
curvilinear, 228
cylindrical, 233, 328
polar, 230, 318
spherical, 234, 329
Cross product, 113
Curl, 205, 393
Curvature, 226
Curve, 138
anti-equivalent, 220
congruent, 220
diÔ¨Äerentiable, 217
equivalent, 220
homotopic, 402
integral, 426
length, 222
level, 268, 269
opposite, 221, 371
piecewise regular, 217
plane, 138
regular, 217, 222
simple, 139, 222
Cylindroid
of a function, 298, 311
Derivative
directional, 159
partial, 156, 159, 168, 171
Determinant, 115
C. Canuto, A. Tabacco: Mathematical Analysis II, 2nd Ed.,
UNITEXT ‚Äì La Matematica per il 3+2 85, DOI 10.1007/978-3-319-12757-6,
¬© Springer International Publishing Switzerland 2015

546
Index
DiÔ¨Äerential, 162, 203
DiÔ¨Äerential equation
autonomous, 427
Bernoulli, 437
homogeneous, 432, 434, 474
linear, 433
non-homogeneous, 434, 476
ordinary, 424
Riccati, 437
solution, 424, 426
with separable variables, 430
Divergence, 205, 391
Dot product, 112
Edge, 247
Eigenvalue, 116
Eigenvector, 116
generalised, 466
Ellipsoid, 144
Error function, 58
Estremum
constrained, 274, 276
unconstrained, 174
Existence
global, 446
local, 440
Exterior
of a set, 120
Face, 247
Field, 128
conservative, 209, 397
curl-free, 209
divergence-free, 209
irrotational, 209, 403, 527
of curl type, 209
radial, 406
vector, 158
Flux, 383, 384
Form
diÔ¨Äerential, 529
closed, 531
exact, 530
normal, 424
quadratic, 118, 176
Formulas
Frenet, 227
reduction, 309
Frequency, 77
Function
analytic, 56
Bessel, 63
continuous, 130
deÔ¨Åned by integral, 214, 516
diÔ¨Äerentiable, 161, 203
error, 58
expansion in Taylor series, 56
generically continuous, 307
gradient, 158
harmonic, 212
implicit, 261, 263, 265, 266, 518
integrable, 300, 307, 322, 335
Lagrangian, 280
limit, 34
Lipschitz, 166, 203, 441
locally Lipschitz, 447
Lyapunov, 451
of class Ck, 171
of several variables, 126
orthogonal, 523
partial derivative, 158
periodic, 76
piecewise C1, 95
piecewise continuous, 79
piecewise monotone, 93
piecewise regular, 93
rectiÔ¨Åed wave, 87, 95, 96
regularised, 79
sawtooth wave, 92
scalar, 126
square wave, 85, 95, 96
vector-valued, 128, 201
Gibbs phenomenon, 95
Gradient, 157, 205
Helicoid, 144
Helmholtz decomposition, 211
Hessian of a function, 169
Homotopy, 402
Inequality
Cauchy-Schwarz, 80, 112, 523
triangle, 112
Integral
along a curve, 368, 373
circulation, 376
double, 297, 298, 304

Index
547
Ô¨Årst, 451
Ô¨Çux, 383, 384
general, 427
improper, 335
iterated, 310, 324, 325
lower, 300
multiple, 297, 322, 335
on a surface, 378, 380
particular, 459, 470
singular, 430
triple, 297, 322
upper, 300
Integration
reduction formula, 303, 310, 324, 325
Interior
of a set, 120
Jacobian, 202
Klein bottle, 247
Lagrange multipliers, 278
Lagrangian, 280
Laplacian, 211
Length, 222
Level set, 127
Limit, 132, 136
Line
coordinate, 228
integral, 375, 377
Linearisation, 455
M-test
Weierstrass, 43
M¬®obius strip, 242, 247
Mass, 330, 374
centre of, 330
Matrix, 114
deÔ¨Ånite, 118
determinant, 115
diagonalisable, 116
exponential, 466
Hessian, 169
identity, 115
indeÔ¨Ånite, 118
inverse, 116
Jacobian, 202
minor, 115
non-singular, 116
norm, 115
normal, 115
orthogonal, 115
rank, 115
semi-deÔ¨Ånite, 118
similar, 117
square, 114, 115
symmetric, 115
transpose, 115
Maximum, 174
Measure, 304, 305
Meridian section, 332
Minimum, 174
Minimum square error, 83
Minor, 115
Moment, 374
of inertia, 331, 383
Multiplicity
algebraic, 116
geometric, 116
Neighbourhood, 120
Norm, 521
absolute value, 522
Euclidean, 112, 115
inÔ¨Ånity, 35, 522
maximum, 522
quadratic, 80, 522
sup-norm, 35
supremum, 35, 522
Normal, 225
unit, 238
Normal vector
unit, 386
ODE, 424
separable, 430
Operator
diÔ¨Äerential, 211
Laplace, 211
Orbit, 427
closed, 427
Order, 424
Orientation, 221, 241, 389
Orthogonal functions, 523
Parametrisation, 237, 240
anti-equivalent, 240
equivalent, 240

548
Index
Parseval‚Äôs formula, 91, 97
Partition, 298
Path integral, 375, 377
Phase space, 427
Plane
osculating, 225
tangent, 161, 238
Point
boundary, 120
centre, 483
critical, 175, 479
equilibrium, 479
exterior, 120
extremum, 174
focus, 484
interior, 120
isolated, 123
limit, 123
maximum, 174
minimum, 174
node, 483
regular, 175
saddle, 179, 483
stationary, 175, 479
Polinomial
trigonometric, 78
Polygonal path, 124
Polynomial
characteristic, 116, 461, 475
Taylor, 171
Positively-oriented triple, 114, 229
Potential, 209, 404
Power series, 45
Problem
Cauchy, 427
initial value, 427
Product
Cauchy, 20
scalar, 80, 523
Pseudo-derivative, 94
Radius
of convergence, 48‚Äì50
of curvature, 226
spectral, 117
Rank, 115
Region, 126
Remainder
Lagrange, 172, 513
of a series, 8, 14, 16
Peano, 172, 514
Resonance, 470, 476
Riemann-Lebesgue Lemma, 91
Saddle point, 179, 483
Sawtooth, 92
Sequence
convergent, 1, 34
divergent, 1
geometric, 3
indeterminate, 1
numerical, 1
of functions, 34
of partial sums, 4
Series
absolutely convergent, 17
alternating, 16
binomial, 51, 59
centre, 45
coeÔ¨Écients, 45
conditionally converging, 19
convergent, 5
diÔ¨Äerentiation, 43, 54
divergent, 5
exponential, 45, 58
Fourier, 75, 85, 96
general term, 4
geometric, 6, 42
harmonic, 10, 15, 17
indeterminate, 5
integration, 42, 54
Maclaurin, 56
Mengoli, 7
numerical, 4
of derivatives, 54
of functions, 41
positive-term, 9
power, 45
product, 20
radius, 48‚Äì50
remainder, 14, 16
sum, 41
Taylor, 56
telescopic, 7
Set
G-admissible, 386
bounded, 124
closed, 121

Index
549
compact, 124
connected, 124
convergence, 34, 41
convex, 124
level, 127, 268
measurable, 304
normal, 308, 323
open, 121
simply connected, 402
star-shaped, 403
Solution
attractive, 479
global, 427, 444
of a diÔ¨Äerential equation, 424, 426
stable, 479
stationary, 479
uniformly attractive, 480
Stability, 478
linearised, 488
Sum, 41
lower, 299
of a series, 5
upper, 299
Surface, 142, 236
S-admissible, 389
boundary, 243, 247
closed, 246
compact, 381, 389
exterior region, 247
helicoidal, 144
integral, 384
interior region, 247
level, 268, 273
of revolution, 144, 382
orientable, 241, 247
piecewise regular, 247
regular, 236, 237
simple, 143, 237
spherical, 144
topographic, 144
System
autonomous, 480
conservative, 450
dissipative, 450
fundamental, 457
Hamiltonian, 453
homogeneous, 456, 462, 466
linear, 456
non-homogeneous, 459, 470
orthogonal, 80
orthonormal, 81, 112
Taylor expansion, 172, 513, 514
Test
absolute convergence, 18
asymptotic comparison, 11
comparison, 2, 9
integral, 13
Leibniz, 16
ratio, 3, 12, 49
root, 12, 50
Weierstrass‚Äô M-test, 43
Theorem
Abel, 49
Cauchy-Lipschitz, 442
comparison, 2
Curl, 393
Dini, 266, 518
divergence, 391
Fermat, 175
Gauss, 391, 524
Green, 393, 525
Guldin, 333, 382
Heine-Cantor, 515
Jordan curve, 140
Lagrange, 165
Mean Value, 165, 314
Pappus, 333
Peano‚Äôs Existence, 440
Pythagoras, 523
Schwarz, 168, 512
Stokes, 395, 526, 531
substitution, 2
Weierstrass, 174
Torus, 147, 246, 334
Trace, 142
of a curve, 138
of a surface, 142
Trajectory, 427
Triple
positively oriented, 390
Variable change, 328
Vector, 111
binormal, 226
normal, 225, 238, 242
orthogonal, 112

550
Index
tangent, 218, 225
torsion, 226
unit, 112, 225
Volume, 311, 332
Wave
rectiÔ¨Åed, 87, 95, 96
square, 85, 95, 96
Wedge product, 113

Collana Unitext ‚Äì La Matematica per il 3+2
Series Editors:
A. Quarteroni (Editor-in-Chief)
L. Ambrosio
P. Biscari
C. Ciliberto
M. Ledoux
W.J. Runggaldier
Editor at Springer:
F. Bonadei
francesca.bonadei@springer.com
As of 2004, the books published in the series have been given a volume num-
ber. Titles in grey indicate editions out of print.
As of 2011, the series also publishes books in English.
A. Bernasconi, B. Codenotti
Introduzione alla complessit√† computazionale
1998, X+260 pp, ISBN 88-470-0020-3
A. Bernasconi, B. Codenotti, G. Resta
Metodi matematici in complessit√† computazionale
1999, X+364 pp, ISBN 88-470-0060-2
E. Salinelli, F. Tomarelli
Modelli dinamici discreti
2002, XII+354 pp, ISBN 88-470-0187-0
S. Bosch
Algebra
2003, VIII+380 pp, ISBN 88-470-0221-4
S. Graffi, M. Degli Esposti
Fisica matematica discreta
2003, X+248 pp, ISBN 88-470-0212-5
S. Margarita, E. Salinelli
MultiMath ‚Äì Matematica Multimediale per l‚ÄôUniversit√†
2004, XX+270 pp, ISBN 88-470-0228-1

A. Quarteroni, R. Sacco, F.Saleri
Matematica numerica (2a Ed.)
2000, XIV+448 pp, ISBN 88-470-0077-7
2002, 2004 ristampa riveduta e corretta
(1a edizione 1998, ISBN 88-470-0010-6)
13. A. Quarteroni, F. Saleri
Introduzione al Calcolo ScientiÔ¨Åco (2a Ed.)
2004, X+262 pp, ISBN 88-470-0256-7
(1a edizione 2002, ISBN 88-470-0149-8)
14. S. Salsa
Equazioni a derivate parziali - Metodi, modelli e applicazioni
2004, XII+426 pp, ISBN 88-470-0259-1
15. G. Riccardi
Calcolo differenziale ed integrale
2004, XII+314 pp, ISBN 88-470-0285-0
16. M. Impedovo
Matematica generale con il calcolatore
2005, X+526 pp, ISBN 88-470-0258-3
17. L. Formaggia, F. Saleri, A. Veneziani
Applicazioni ed esercizi di modellistica numerica
per problemi differenziali
2005, VIII+396 pp, ISBN 88-470-0257-5
18. S. Salsa, G. Verzini
Equazioni a derivate parziali ‚Äì Complementi ed esercizi
2005, VIII+406 pp, ISBN 88-470-0260-5
2007, ristampa con modiÔ¨Åche
19. C. Canuto, A. Tabacco
Analisi Matematica I (2a Ed.)
2005, XII+448 pp, ISBN 88-470-0337-7
(1a edizione, 2003, XII+376 pp, ISBN 88-470-0220-6)
20. F. Biagini, M. Campanino
Elementi di Probabilit√† e Statistica
2006, XII+236 pp, ISBN 88-470-0330-X

21. S. Leonesi, C. Toffalori
Numeri e CrittograÔ¨Åa
2006, VIII+178 pp, ISBN 88-470-0331-8
22. A. Quarteroni, F. Saleri
Introduzione al Calcolo ScientiÔ¨Åco (3a Ed.)
2006, X+306 pp, ISBN 88-470-0480-2
23. S. Leonesi, C. Toffalori
Un invito all‚ÄôAlgebra
2006, XVII+432 pp, ISBN 88-470-0313-X
24. W.M. Baldoni, C. Ciliberto, G.M. Piacentini Cattaneo
Aritmetica, CrittograÔ¨Åa e Codici
2006, XVI+518 pp, ISBN 88-470-0455-1
25. A. Quarteroni
Modellistica numerica per problemi differenziali (3a Ed.)
2006, XIV+452 pp, ISBN 88-470-0493-4
(1a edizione 2000, ISBN 88-470-0108-0)
(2a edizione 2003, ISBN 88-470-0203-6)
26. M. Abate, F. Tovena
Curve e superÔ¨Åci
2006, XIV+394 pp, ISBN 88-470-0535-3
27. L. Giuzzi
Codici correttori
2006, XVI+402 pp, ISBN 88-470-0539-6
28. L. Robbiano
Algebra lineare
2007, XVI+210 pp, ISBN 88-470-0446-2
29. E. Rosazza Gianin, C. Sgarra
Esercizi di Ô¨Ånanza matematica
2007, X+184 pp, ISBN 978-88-470-0610-2
30. A. Mach√¨
Gruppi ‚Äì Una introduzione a idee e metodi della Teoria dei Gruppi
2007, XII+350 pp, ISBN 978-88-470-0622-5
2010, ristampa con modiÔ¨Åche

31 Y. Biollay, A. Chaabouni, J. Stubbe
Matematica si parte!
A cura di A. Quarteroni
2007, XII+196 pp, ISBN 978-88-470-0675-1
32. M. Manetti
Topologia
2008, XII+298 pp, ISBN 978-88-470-0756-7
33. A. Pascucci
Calcolo stocastico per la Ô¨Ånanza
2008, XVI+518 pp, ISBN 978-88-470-0600-3
34. A. Quarteroni, R. Sacco, F. Saleri
Matematica numerica (3a Ed.)
2008, XVI+510 pp, ISBN 978-88-470-0782-6
35. P. Cannarsa, T. D‚ÄôAprile
Introduzione alla teoria della misura e all‚Äôanalisi funzionale
2008, XII+268 pp, ISBN 978-88-470-0701-7
36. A. Quarteroni, F. Saleri
Calcolo scientiÔ¨Åco (4a Ed.)
2008, XIV+358 pp, ISBN 978-88-470-0837-3
37. C. Canuto, A. Tabacco
Analisi Matematica I (3a Ed.)
2008, XIV+452 pp, ISBN 978-88-470-0871-3
38. S. Gabelli
Teoria delle Equazioni e Teoria di Galois
2008, XVI+410 pp, ISBN 978-88-470-0618-8
39. A. Quarteroni
Modellistica numerica per problemi differenziali (4a Ed.)
2008, XVI+560 pp, ISBN 978-88-470-0841-0
40. C. Canuto, A. Tabacco
Analisi Matematica II
2008, XVI+536 pp, ISBN 978-88-470-0873-1
2010, ristampa con modiÔ¨Åche
41. E. Salinelli, F. Tomarelli
Modelli Dinamici Discreti (2a Ed.)
2009, XIV+382 pp, ISBN 978-88-470-1075-8

42. S. Salsa, F.M.G. Vegni, A. Zaretti, P. Zunino
Invito alle equazioni a derivate parziali
2009, XIV+440 pp, ISBN 978-88-470-1179-3
43. S. Dulli, S. Furini, E. Peron
Data mining
2009, XIV+178 pp, ISBN 978-88-470-1162-5
44. A. Pascucci, W.J. Runggaldier
Finanza Matematica
2009, X+264 pp, ISBN 978-88-470-1441-1
45. S. Salsa
Equazioni a derivate parziali ‚Äì Metodi, modelli e applicazioni (2a Ed.)
2010, XVI+614 pp, ISBN 978-88-470-1645-3
46. C. D‚ÄôAngelo, A. Quarteroni
Matematica Numerica ‚Äì Esercizi, Laboratori e Progetti
2010, VIII+374 pp, ISBN 978-88-470-1639-2
47. V. Moretti
Teoria Spettrale e Meccanica Quantistica ‚Äì Operatori in spazi di Hilbert
2010, XVI+704 pp, ISBN 978-88-470-1610-1
48. C. Parenti, A. Parmeggiani
Algebra lineare ed equazioni differenziali ordinarie
2010, VIII+208 pp, ISBN 978-88-470-1787-0
49. B. Korte, J. Vygen
Ottimizzazione Combinatoria. Teoria e Algoritmi
2010, XVI+662 pp, ISBN 978-88-470-1522-7
50. D. Mundici
Logica: Metodo Breve
2011, XII+126 pp, ISBN 978-88-470-1883-9
51. E. Fortuna, R. Frigerio, R. Pardini
Geometria proiettiva. Problemi risolti e richiami di teoria
2011, VIII+274 pp, ISBN 978-88-470-1746-7
52. C. Presilla
Elementi di Analisi Complessa. Funzioni di una variabile
2011, XII+324 pp, ISBN 978-88-470-1829-7

53. L. Grippo, M. Sciandrone
Metodi di ottimizzazione non vincolata
2011, XIV+614 pp, ISBN 978-88-470-1793-1
54. M. Abate, F. Tovena
Geometria Differenziale
2011, XIV+466 pp, ISBN 978-88-470-1919-5
55. M. Abate, F. Tovena
Curves and Surfaces
2011, XIV+390 pp, ISBN 978-88-470-1940-9
56. A. Ambrosetti
Appunti sulle equazioni differenziali ordinarie
2011, X+114 pp, ISBN 978-88-470-2393-2
57. L. Formaggia, F. Saleri, A. Veneziani
Solving Numerical PDEs: Problems, Applications, Exercises
2011, X+434 pp, ISBN 978-88-470-2411-3
58. A. Mach√¨
Groups. An Introduction to Ideas and Methods of the Theory of Groups
2011, XIV+372 pp, ISBN 978-88-470-2420-5
59. A. Pascucci, W.J. Runggaldier
Financial Mathematics. Theory and Problems for Multi-period Models
2011, X+288 pp, ISBN 978-88-470-2537-0
60. D. Mundici
Logic: a Brief Course
2012, XII+124 pp, ISBN 978-88-470-2360-4
61. A. Mach√¨
Algebra for Symbolic Computation
2012, VIII+174 pp, ISBN 978-88-470-2396-3
62. A. Quarteroni, F. Saleri, P. Gervasio
Calcolo Scientifico (5a ed.)
2012, XVIII+450 pp, ISBN 978-88-470-2744-2
63. A. Quarteroni
Modellistica Numerica per Problemi Differenziali (5a ed.)
2012, XVIII+628 pp, ISBN 978-88-470-2747-3

64. V. Moretti
Spectral Theory and Quantum Mechanics
With an Introduction to the Algebraic Formulation
2013, XVI+728 pp, ISBN 978-88-470-2834-0
65. S. Salsa, F.M.G. Vegni, A. Zaretti, P. Zunino
A Primer on PDEs. Models, Methods, Simulations
2013, XIV+482 pp, ISBN 978-88-470-2861-6
66. V.I. Arnold
Real Algebraic Geometry
2013, X+110 pp, ISBN 978-3-642‚Äì36242-2
67. F. Caravenna, P. Dai Pra
Probabilit√†. Un‚Äôintroduzione attraverso modelli e applicazioni
2013, X+396 pp, ISBN 978-88-470-2594-3
68. A. de Luca, F. D‚ÄôAlessandro
Teoria degli Automi Finiti
2013, XII+316 pp, ISBN 978-88-470-5473-8
69. P. Biscari, T. Ruggeri, G. Saccomandi, M. Vianello
Meccanica Razionale
2013, XII+352 pp, ISBN 978-88-470-5696-3
70. E. Rosazza Gianin, C. Sgarra
Mathematical Finance: Theory Review and Exercises. From Binomial
Model to Risk Measures
2013, X+278pp, ISBN 978-3-319-01356-5
71. E. Salinelli, F. Tomarelli
Modelli Dinamici Discreti (3a Ed.)
2014, XVI+394pp, ISBN 978-88-470-5503-2
72. C. Presilla
Elementi di Analisi Complessa. Funzioni di una variabile (2a Ed.)
2014, XII+360pp, ISBN 978-88-470-5500-1
73. S. Ahmad, A. Ambrosetti
A Textbook on Ordinary Differential Equations
2014, XIV+324pp, ISBN 978-3-319-02128-7

74. A. Berm√∫dez, D. G√≥mez, P. Salgado
Mathematical Models and Numerical Simulation in Electromagnetism
2014, XVIII+430pp, ISBN 978-3-319-02948-1
75. A. Quarteroni
Matematica Numerica. Esercizi, Laboratori e Progetti (2a Ed.)
2013, XVIII+406pp, ISBN 978-88-470-5540-7
76. E. Salinelli, F. Tomarelli
Discrete Dynamical Models
2014, XVI+386pp, ISBN 978-3-319-02290-1
77. A. Quarteroni, R. Sacco, F. Saleri, P. Gervasio
Matematica Numerica (4a Ed.)
2014, XVIII+532pp, ISBN 978-88-470-5643-5
78. M. Manetti
Topologia (2a Ed.)
2014, XII+334pp, ISBN 978-88-470-5661-9
79. M. Iannelli, A. Pugliese
An Introduction to Mathematical Population Dynamics. Along the trail
of Volterra and Lotka
2014, XIV+338pp, ISBN 978-3-319-03025-8
80. V. M. Abrusci, L. Tortora de Falco
Logica. Volume 1
2014, X+180pp, ISBN 978-88-470-5537-7
81. P. Biscari, T. Ruggeri, G. Saccomandi, M. Vianello
Meccanica Razionale (2a Ed.)
2014, XII+390pp, ISBN 978-88-470-5725-8
82. C. Canuto, A. Tabacco
Analisi Matematica I (4a Ed.)
2014, XIV+508pp, ISBN 978-88-470-5722-7
83. C. Canuto, A. Tabacco
Analisi Matematica II (2a Ed.)
2014, XII+576pp, ISBN 978-88-470-5728-9
84. C. Canuto, A. Tabacco
Mathematical Analysis I (2nd Ed.)
2015, XIV+484pp, ISBN 978-3-319-12771-2

85. C. Canuto, A. Tabacco
Mathematical Analysis II (2nd Ed.)
2015, XII+550pp, ISBN 978-3-319-12756-9
The online version of the books published in this series is available at
SpringerLink.
For further information, please visit the following link:
http://www.springer.com/series/5418

