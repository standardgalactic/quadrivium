Telecommunication 
Principles 

TUTORIAL GUIDES IN ELECTRONIC ENGINEERING 
Series editors 
Professor G.G. Bloodworth, University of York 
Professor A.P. Dorey, University of Lancaster 
Professor J.K. Fidler, Open University 
This series is aimed at first- and second-year undergraduate courses. Each text is 
complete in itself, although linked with others in the series. Where possible, the 
trend towards a 'systems' approach is acknowledged, but classical fundamental 
areas of study have not been excluded, neither has mathematics, although titles 
wholly devoted to mathematical topics have been eschewed in favour of including 
necessary mathematical concepts under appropriate applied headings. Worked 
examples feature prominently and indicate, where appropriate, a number of 
approaches to the same problem. 
A format providing marginal notes has been adopted to allow the authors to 
include ideas and material to support the main text. These notes include references 
to standard mainstream texts and commentary on the applicability of solution 
methods, aimed particularly at covering points normally found difficult. Graded 
problems are provided at the end of each chapter, with answers at the end of the 
book. 
1. Transistor Circuit Techniques: discrete and integrated -
G.J. Ritchie 
2. Feedback Circuits and Op. Amps. -
D.H. Horrocks 
3. Pascal for Electronic Engineers -
J. Attikiouzel 
4. Computers and Microprocessors: components and systems -
A.C. Downton 
5. Telecommunication Principles -
J.J. O'Reilly 
6. Digital Logic Techniques: principles and practice -
T.J. Stonham 

Telecommunication 
Principles 
J.J. O'Reilly 
Department of Electrical Engineering Science 
University of Essex 
~ 
Van Nostrand Reinhold (UK) Co. Ltd 

© 1984,1.1. O'Reilly 
All rights reserved. No part of this work covered by the 
copyright hereon may be reproduced or used in any form or 
by any means -
graphic, electronic, or mechanical, 
including photocopying, recording, taping, or information 
storage or retrieval systems -
without the written permission 
of the publishers. 
First published in 1984 by 
Van Nostrand Reinhold (UK) Co. Ltd. 
Molly Millars Lane, Wokingham, Berkshire, England 
Typeset in lOon 12pt Times by 
Colset Private Ltd., Singapore 
Library of Congress Cataloging in Publication Data 
O'Reilly, 10hn 1. 
Telecommunication principles. 
(Tutorial guides in electronic engineering) 
Includes index. 
1. Telecommunication. 
I. Title. 
II. Series. 
TK5101.073 
1984 
621.38 
84-5170 
ISBN-13:978-0-442-30592-5 
e-ISBN-13:978-94-009-5576-9 
001: 10.1007/978-94-009-5576-9 

Preface 
This book provides a first introduction to the subject of telecommunications suit-
able for first and second year undergraduates following degree or similar courses in 
electronic engineering. There are very few specific prerequisites other than a 
general background in electric circuit principles and a level of mathematical 
maturity consistent with entry to engineering courses in British universities. 
The intention is to provide a broad perspective of modern telecommunication 
principles and applications. Following a general overview of telecommunications, 
a thorough, albeit introductory, treatment is provided of underlying principles 
such as signal representation and analysis, sampling, analogue and digital trans-
mission, modulation and coding. The book concludes with a description of several 
important systems applications which serve as case studies to illustrate further the 
principles introduced and demonstrate their application in a practical context. 
Many people have contributed, directly and indirectly, to this book. I am espe-
cially grateful to Professor Kel Fidler of the Open University for suggesting that I 
write the book and for the support and guidance he has provided throughout the 
endeavour. The Telecommunications Research Group of the Department of Elec-
trical Engineering Science at the University of Essex has provided a stimulating 
environment in which to develop my appreciation of telecommunication systems 
and in particular Professor Ken Cattermole has influenced my thinking greatly. 
Also, the close working relationship between the Telecommunications Group 
and British Telecom Research Laboratories has proved most fruitful and I am 
indebted to Drs Peter Cochrane, Ian Garrett and Mike O'Mahony of BTRL for 
valuable discussions. Dr Tim Dennis and his colleagues in the Visual Systems 
Research Group at Essex provided invaluable assistance with television picture 
coding for the illustrations. Finally, thanks go to Jenny, my photographic model. 
v 

Contents 
Preface 
v 
1 Signals, systems and communications 
1 
Communication signals 
2 
Communication channels 
4 
Communication Networks 
14 
Telecommunications Worldwide 
20 
2 Signal representation and analysis 
23 
The time domain 
24 
The frequency domain 
28 
Fourier series analysis 
34 
Frequency domain representation of aperiodic signals 
40 
Fourier transforms 
41 
Frequency domain representation for signals of arbitrary waveshape 
46 
Amplitude distribution of signals 
47 
3 Sinusoidal carrier modulation 
53 
Introduction 
53 
Amplitude modulation 
53 
Angle modulation 
61 
Frequency division multiplexing 
62 
4 Radio receiver principles 
67 
Tuned radio frequency (TRF) receiver 
69 
Superheterodyne (superhet) receivers 
70 
5 Pulse modulation systems 
76 
Pulse amplitude modulation 
76 
Other pulse modulation schemes 
82 
Time division multiplexing 
83 
6 Pulse code modulation 
86 
Quantization 
86 
Sampling and pulse encoding 
88 
Non-uniform quantization 
90 
Differential pulse code modulation 
92 
PCM-TDM telephony 
94 
7 Digital communications 
97 
Digital transmission 
97 
The eye diagram 
102 
Signal design 
102 
vii 

viii 
Error probability 
Coding for digital transmission 
Digital modulation 
8 Systems case studies 
Broadcast FM radio 
Television systems 
Videotex systems 
Appendix: Decibels 
Answers to Numerical Problems 
Index 
104 
107 
115 
119 
119 
122 
129 
136 
138 
140 

Signals, Systems and 
Communications 
o To provide a broad overview of telecommunication systems. 
o To introduce the concept of a signal and show the relation to electrical 
waveforms. 
o To introduce the concept of a communication channel and to discuss diverse 
practical realisations, such as; coaxial cables, optical fibres and radio links. 
o To introduce communication networks and discuss different topologies and 
design philosophies. 
o To explain the terms local area network (LAN), wide area network (WAN) 
and integrated services digital network (ISDN) 
Telecommunication systems are concerned with the transmission of information, 
or messages, from one point to another. The origin of the message is referred to as 
the source and the destination as the sink. An illustrative communication link is 
shown in Fig. 1.1. In order to effect this transfer of information the messages from 
the source are represented by a signal which takes the form of a voltage varying 
with time: the signal waveform. Arguably this is a restricted view of telecom-
munications, which means simply communication at a distance, and could rea-
sonably be taken to encompass other forms of message transport, of which the 
postal service and acoustic transmission systems, such as the speaking tube of the 
nineteenth century, are but two examples. The restriction is readily justified, 
though, since electrical -
or more properly electromagnetic -
signals are 
invariably used for near instantaneous long-range communications. The main rea-
sons for this are that electrical signals are readily generated and modified with the 
aid of electronic circuits and they travel at, or close to, the velocity of light. 
Message 
source 
Input 
signal 
Encoder-
modulator 
Distortion, interference 
and noise 
Message 
sink 
Output 
signal 
Demodulator 
-decoder 
Transmitted 
Received 
signal 
~------o.j Communication I----...J signal 
channel 
Fig. 1.1 
Illustrative communication link. 
1 
Objectives 

2 
Exercise 1.1 
Determine the time delay experienced by; 
(a) an electrical signal travelling at the velocity of light in vacuum (approximately 
3 x 108 mls) 
(b) an acoustic signal travelling at the velocity of sound in air (approximately 343 mls) 
over a distance of 5000 km, corresponding approximately to transatlantic communication. 
Considering only signal delay, comment briefly on the viability of some form of acoustic 
transmission for two-way long distance telecommunication. 
Communication Signals 
An example of an electrical signal is the voltage waveform produced by a 
microphone in response to a spoken message. The precise form of the speech wave-
form depends on the message, the speaker and the characteristics of the 
microphone but an illustrative example is shown in Fig. 1.2a. The voltage varies 
a 
b~ 
.. 
o 
4kHz 
f 
c 
d 
0 
5.5MHz f 
0 
64/-15 
e 
LJ 
li 
-T 
0 
T 
2T 
3T 
0 
1/T 
21T f 
9 
h 
ijwn!h~lWf!in .. 
!\ 
t 
~1[ ~i~J~YY'V,~ l~vxr 
• 
0 
Fe 
f 
1 
F: 
Fig. 1.2 Typical signal waveforms and corresponding power spectra. (a) Speech 
waveform; (b) speech spectrum; (c) television waveform; (d) television spectrum; 
(e) binary data waveform; (f) binary data spectrum; (g) bandpass signal; (h) 
bandpass spectrum. 

continuously with time in an unpredictable manner and it is the task of the com-
munication link to produce a close replica of this waveform at the receiver. This 
may be achieved by passing the signal along a pair of wires but communication over 
long distances usually requires some modification of the signal to render it com-
patible with an available channel such as a radio link. Depending on its form this 
modification is referred to variously as encoding and/or modulation and a reverse 
process is required at the receiver to undo the modification and recover the original 
message waveform. These processes are discussed in some detail in later chapters; 
for the present consider the message signal itself. In practice it is neither necessary 
nor possible for the message waveform to be reproduced exactly at the receiver; a 
close approximation suffices. This last observation is of profound importance and 
influences significantly the design of communication systems. For example, a 
speech waveform may be passed through a filter which removes certain frequency 
components and yet the speech may be quite intelligible. Some idea can be obtained 
of which components are likely to be most important by examining the distribution 
of the signal power with frequency, as shown in Fig. 1.2b. This form of signal 
representation, known as a power spectrum or power spectral density junction, is 
discussed further in Chapter 2. Here it is sufficient to note that a communication 
system should provide good transmission at frequencies for which the signal power 
spectrum is significant. Just what level constitutes significant in this context is open 
to question; any judgement as to whether or not a speech signal has been 
significantly impaired by filtering must be subjective. The quality of a communica-
tion channel may need to be assessed on the basis of subjective tests. From such 
tests it has been found that if a communication channel passes relatively 
unimpaired signal components with frequencies in the critical range 300 Hz to 
3.4 kHz then speech is entirely intelligible. In view of this, telephone systems incor-
porate filters to limit the speech signal to this frequency band. To allow for imper-
fections of practical filters telephone speech is often treated as if it were 4 kHz low-
pass. That is, the constituent signal frequencies are taken to extend from very low 
values (essentially d.c.) up to 4 kHz. We refer to the range of significant frequency 
components in a signal waveform as the signal bandwidth. 
Speech, albeit very important, is only one type of signal it is wished to convey. 
High quality music signals contain significant frequency components over the 
whole of the audible range which extends from about 20 Hz to approaching 
20 kHz. Good reproduction is obtained by treating music signals as lowpass with a 
bandwidth of 15 kHz. 
Television provides another example. The saying 'a picture is worth a thousand 
words' is exemplified by the bandwidth requirements of 5.5 MHz lowpass for 
broadcast quality television signals. Fig. 1.2c provides a representative illustration 
of a television waveform and a television system forms the basis of one of the case 
studies of Chapter 8. 
A binary data signal is shown in Fig. 1.2e. The voltage varies with time, alter-
nating between two values to delimit the data corresponding with the message. The 
smallest interval between transitions, T, is known as the signalling interval or bit 
time and liTis the signalling rate in bits per second[bitls]. It can be seen from the 
power spectrum that most of the signal power is concentrated at frequencies less 
than liT. Therefore, it can be expected that the transmission bandwidth required 
for a binary data system would be proportional to, and perhaps of the same 
order as, the bit rate. More is said about binary data signals in Chapter 7 
The power spectrum of a signal 
is discussed further in Chapter 
2. 
3 

4 
where these tentative conclusions are found to be broadly correct. Here it is noted 
that if there is a requirement to send a large amount of data in a short time a high 
data rate is involved and thus a wide bandwidth channel is required. It is quite com-
mon to encounter data rates upto 140 Mbitls in the telecommunication network, 
with experimental systems operating at rates above 1 Gbitls being studied at the 
time of writing (1983). 
The signals discussed so far are all lowpass. That is, they have been concentrated 
in a frequency band extending from close to d.c. up to some maximum frequency 
fmax' which thus corresponds closely to the signal bandwidth, B :::: fmax. Not all sig-
nals are of this type. Some are bandpass, concentrated in a band of frequencies 
extending from a lower frequency fmin to an upper frequency fmax and have a band-
width B :::: fmax - fmin' A bandpass signal is illustrated in Fig. 1.2g. Most com-
monly, bandpass signals are derived from lowpass signals by way of a modulation 
process. The purpose of this lowpass to bandpass signal transformation is to 
enable the message to be conveyed over a bandpass channel, a topic examined in 
Chapter 3. 
Having discussed briefly some of the types of signal it may be required 
to transmit and noted the wide diversity in terms of signal bandwidth, atten-
tion is now turned to the possible channels over which these signals may be 
conveyed. 
Communication Channels 
An ideal communication channel would convey unimpaired the communication 
signal from source to destination. To do this it would have to pass all frequencies 
equally well; that is, it would have a uniform frequency response. Also, it would 
need to be free from extraneous disturbances such as unwanted signals which might 
be added to the wanted signal and interfere with communication. And, of course, it 
would be ideal for the signal to reach its destination unattenuated to obviate the 
need for signal amplification at the receiver. It comes as no suprise that practical 
channels are not like this! A signal may suffer considerable attenuation, which may 
be more severe at some frequencies than others and may also vary with time. In 
addition, the signal is liable to suffer corruption by the addition of interfering sig-
nals. The relative significance of these various forms of signal impairment depends 
on the particular physical channel involved. Consider briefly two broad classifica-
tions:' (i) guided wave systems in which the signal is conveyed via some constraining 
physical medium such as a pair of wires, and (ii) radio systems in which signal 
transfer is effected via a freely propagating electromagnetic wave. 
First note that the range of frequencies available is very wide, ranging from d.c. 
(zero frequency) to optical frequencies of the order 1014 Hz as shown in Table 1.1. 
In order to exploit effectively this wide range of frequencies it is necessary that 
source messages be processed and combined with other messages to form a single 
composite signal in which the constituents are individually identifiable. This pro-
cess, known as multiplexing, is discussed in later chapters. For the present it 
suffices to note that message signals can be combined and translated in frequency 
for transmission and that the individual messages are recoverable at a remote 
location. 

Table 1.1 Communication Frequency Designations 
Baseband: 
VLF: 
LF: 
MF: 
HF: 
VHF: 
UHF: 
,SHF: 
EHF: 
(millimetre waves) 
a basic message signal con-
centrated at low frequencies with 
bandwidth depending on type of 
message 
very low frequencies 
low frequencies 
medium frequencies 
high frequencies 
very high frequencies 
ultra high frequencies 
super high frequencies 
Extra high frequencies 
Frequency 
<30 kHz 
300 kHz 
3 MHz 
30 MHz 
300 MHz 
3 GHz 
30 GHz 
300 GHz 
lightwaves 
Optical frequencies 
;;; 1014 Hz 
Twisted Pair Cables 
Wavelength 
10 km 
1 km 
100m 
10m 
1m 
lOcm 
1 cm 
100 mm 
Il1-m 
A very widely used form of communication channel consists simply of a pair of 
electrical conductors. Such wire pairs may be used, for example, to connect com-
puter terminals to a nearby central processor or to connect telephone instruments 
to a local exchange. The physical structure of the transmission line strongly 
influences the primary electrical parameters: 
capacitance between conductors 
conductor resistance 
leakage conductance between conductors 
inductance 
C [F/m] 
R [O/m] 
G [S/m] 
L [Him] 
These in turn influence the characteristics ofthe transmission line as a communica-
tion channel. An analytic treatment of line operation is not considered here, but it 
should be noted that the total attenuation of a cable depends on its length. Con-
sider, for example, two identical 1 metre sections of cable connected in cascade, as 
shown in Fig. 1.3, with the second section appropriately terminated. The voltage 
transfer ratio for each section is given by: 
More details of transmission line 
principles may be found in 
Coates. R.F., Modern Com-
munication Systems, Macmillan, 
1975, 1983. 
Here it is assumed that the 
second section is appropriately 
terminated so that 'looking into' 
section 2 or section 1 towards 
the load the same impedance, Z, 
(1.1) 
is seen. 
Hence the overall voltage transfer ratio is 
Cable 
section 
1 
Cable 
section 
2 
Fig. 1.3 Cascade connection of cable sections. 
0.2) 1J:B]z 
I 
I 
, 
, 
Z 
Z 
5 

More generally, for a cable of length d the transfer ratio is 
VdlVO = Kd 
(1.3) 
Decibel measures are reviewed 
briefly in Appendix A. 
Expressing this in terms of decibels: 
6 
(dB/km) 
0.6 
0.5 
0.4 
0.3 
0.2 
20 10gIO( VdlVo) = 2010g IO(Kd) 
= d2010g IO(K) 
= -ad dB 
(1.4) 
Here a = - 20 10gIO(K) is the cable attenuation in dB/m and the introduction of the 
minus sign yields a positive value for the cable attenuation constant given that K < 
I * 10g(K) < O. The signal attenuation in decibels is thus proportional to 
transmission distance d for a cable system. 
As one might expect, given the primary electrical parameters noted above, the 
attenuation is also frequency dependent and tends to increase with frequency as 
shown in Fig. l.4a. Hence, to achieve an acceptable bandwidth some form of 
frequency sensitive compensating network may be required. Such a network is 
known as an equalizer since it makes uniform, or equal, the transmission of the 
cable over the frequency range of interest. For simple pair cable this can often be 
achieved by introducing series inductors, known in this context as loading coils, at 
suitable points along the cable. The effect of loading coils on the transmission 
characteristic of a length of telephone cable is also illustrated in Fig. l.4a. Notice 
that the resulting bandwidth is rather limited and depends on length. 
A representative mUlti-pair telephone cable is shown in Fig. l.4b from which a 
further deficiency may be anticipated. Currents flowing in the conductors produce 
magnetic fields which can couple to, and induce currents in, other wire pairs in the 
same cable. Cross-coupling may also arise due to capacitance between the different 
conductors. The result is that a wanted signal may be impaired by the addition of 
interfering signals from other cable pairs. The problem was first encountered with 
speech telephony where it takes the form of talking in the background -
it is thus 
referred to as crosstalk. The various wire-pairs may be randomized in position 
along the length of the cable thus ensuring that a given channel receives inter-
ference more or less uniformly from all other channels rather than predominantly 
Without 
loading 
coils 
a 
b 
0.1.f-----------
+---~---~----~------~----._~-f 
o 
2 
3 
4 
5 
(kHz) 
Fig. 1.4 (a) Attenuation characteristic of twisted-pair cable; (b) multi-pair cable. 

from one. This has the effect of rendering the crosstalk less intelligible. Subjective 
tests have shown that telephone users are considerably more tolerant to crosstalk if 
it is unintelligible. 
Coaxial Cables 
For applications requiring greater bandwidths than are available with wire pairs 
coaxial cables are generally used. The attenuation for such a cable increases 
approximately with the square root of frequency so equalization is required for 
long distance, wide bandwidth operation. Coaxial cable systems are available 
which provide a usable signal bandwidth of 60 MHz or can accommodate 
140 Mbitls digital transmission. Greater bandwidths/data rates can be achieved 
but large cable diameters are required for low transmission loss to result. This 
arises because at high frequencies the current is concentrated near the surface of a 
conductor. Owing to this so called skin effect an increase in cable diameter is 
required as the operating frequency is increased if the effective cross-sectional area 
of the conductor is to be maintained. A further advantage of the coaxial structure is 
that it can result in much reduced crosstalk. The electric and magnetic fields are 
almost entirely constrained within the cable, the outer, surrounding conductor 
being earthed. 
Optical Fibres 
Guided wave transmission at microwave frequencies is not currently employed for 
long distance communications despite an extensive research and development 
effort spread over several years, in the UK, USA and elsewhere. This is largely 
because recent advances in optical (or lightwave) communications have made this 
latter option far more attractive both technologically and economically. Guided 
wave optical communication systems make use of fine strands of high purity glass, 
approximately 100 microns (~m) in overall diameter. The technology is particu-
larly well suited to digital communications so we will concentrate on this. Note in 
passing, however, that analogue communication over optical channels is possible 
both directly and with the aid of various pulse modulation schemes (see Chapters 5, 
6, and 7). 
The simplest form of optical fibre has a relatively large central core (- 50 ~m in 
diameter) with refractive index n1 surrounded by a lower refractive index cladding 
n2• Light can thus travel along the central core by way of a series of total internal 
reflections at the core-cladding interface, as shown in Fig. 1.5. In order to be 
n2 
Cladding n2 
n2 
n, 
(;::\ 
o 
-+----+-- n(r) 
a 
b 
c 
Fig. 1.5 
Step-index multimode optical fibre. (a) End view; (b) side view showing 
ray propagation; (c) refractive index profile. 
The use of optical fibres for 
communications was proposed 
in 1 966 by two research engi-
neers, Kao and Hockham, work-
ing at the British laboratories of 
STL. 
7 

8 
Refractive 
index 
Refracted 
ray 
n2 < n, 
Dielectric 
-Re-f-ra-c-tiv-e------"tE--------interface 
index 
n, 
Incident 
rays 
.... , .... 
' .... ,.100... Totally 
internally 
reflected 
ray 
Fig. 1.6 Total internal reflection. 
trapped within the core in this way light rays must be at a relatively shallow angle 
relative to the fibre axis. This may be appreciated as follows: 
Consider light undergoing refraction at a plane dielectric interface, as shown in 
Fig. 1.6. Snell's law for refraction takes the form 
(1.5) 
Here n I > n 2 implies (jJ1 < (jJ2. If the angle of incidence (jJ1 is increased a critical 
angle is reached, defined by 
(1.6) 
That is, Snell's law predicts that the refracted ray makes an angle of 90° to the per-
pendicular. The ray is totally reflected back into the high index region; total inter-
nal reflection occurs and this applies also for all angles (jJ1 > (jJc. The angle () of the 
ray to the fibre axis is related to the angle at the core-cladding interface by 
sin(jJ = cos () 
(1.7) 
and (jJc defines the minimum value for (jJ1 for total internal reflection. This 
corresponds to a maximum value ()m for (): 
(1.8) 
Light is trapped within the fibre core provided it makes an angle () < ()m to the fibre 
axis. 
Consider now a very short pulse of light launched into a fibre of length L at angle 
() to the axis. If () = 0 the light travels directly along the fibre core axis and emerges 
at the exit after a delay given by 
(1.9) 
where v I = cI n I is the velocity of light in the core. On the other hand, light inclined 
at an angle () to the axis follows a zig-zag path of length P given by 

P = L/cosO 
and so arrives at the exit after a delay which depends on 0: 
niL 
T(O) = P/v i = C cos 8 
For the extreme ray, travelling at angle 8m, 
(1.10) 
(1.11) 
(1.12) 
Hence if a short pulse of light is launched such that components enter the fibre at all 
angles 0 < 8 < 8m the pulse arrives at the exit spread out in time by an amount given 
by 
(1.13) 
This pulse spreading places a limit on the rate at which pulses may be transmitted 
over a fibre of given length, L. Pulse spreading of this sort is characteristic of step 
index fibres, that is, fibres in which the refractive index is uniform in the core and 
steps down abruptly to the cladding value. 
An optical fibre has core refractive index n I = 1.5 and cladding refractive index 
Worked Example 1.1 
n 2 = 1.45. Estimate the maximum signalling rate attainable for fibre lengths of (i) 
100 m (ii) 10 km. 
Solution: To avoid undue overlap of pulses at the exit of the fibre they must be 
separated in time by approximately .IT or more. Hence the maximum signalling 
rate is/max ::=: lI.lT. Now n I ::=: n2; hence 
whence 
Imax ::=: c/0.05L 
(i) For L = 100 m 
Imax ::=: 3 x 108/(0.05 x 100) ::=: 60 MHz 
(ii) For 1 = 10 km 
Imax ::=: 3 x 108/(0.05 X 104) =:: 600 kHz 
(1.14) 
Notice that the effective bandwidth of a step index fibre depends on length Land 
on the index difference (n I - n 2). For short haul systems, for example data links 
within buildings, ships, aircraft and so on, fibres of this type are quite suitable. For 
long haul, high data rate systems, however, alternative structures are required. 
9 

10 
If the refractive index in the core region gradually reduces from a maximum at 
the centre to some lower value at the cladding, as shown in Fig. 1.7, the fibre band-
width is greatly improved. The light now follows a curved, approximately 
sinusoidal path, being continuously refracted within the core rather than reflected 
at the core-cladding boundary. A fibre of this type is referred to as a graded index 
fibre. Notice that light rays at shallow angles, with the shorter physical path 
lengths, are confined to the central high index region where the velocity of light is 
relatively low. In contrast, rays at steep angles with long physical path lengths 
penetrate further into the low refractive index regions where the velocity of light is 
higher. Appropriate choice of the refractive index profile results in all ray paths 
having almost the same propagation delay and pulse spreading is very much 
reduced compared with a step index fibre. The best index profile has been found to 
be approximately parabolic, although there is no profile which results in all ray 
paths having precisely the same delay. Hence some pulse spreading is inevitable 
and can prove a limiting factor for high data rate, long distance systems. 
IIi these discussions of optical fibres rays of light have been considered; we have 
used a ray optics model. This is reasonable provided the fibre diameter is large 
compared to the wavelength of light so that diffraction/wave effects can be 
ignored. More properly, though, it should be noted that light is an electromagnetic 
phenomenon. If wave effects are included in the analysis it emerges that light can-
not propagate in a fibre at all the angles predicted by ray optics but only at certain 
discrete angles. These ray angles correspond to different modes of electromagnetic 
propagation. For large core diameter fibres with a large index difference there are 
many possible propagation angles or modes and such fibres are referred to as 
multimode. The pulse spreading corresponds to the different modes having dif-
ferent propagation velocities. In a graded index multimode fibre the mode 
velocities are almost, but not quite, equal. With a large core diameter and index dif-
ference the allowed ray angles are very closely spaced and the continuous 
approximation of ray optics is reasonable. However, by making the core diameter 
and index difference sufficiently small we can ensure that there is essentially only 
one possible mode. The result is a monomode fibre and since there is only a single 
mode pulse spreading due to mode velocity differences cannot exist. 
There are other effects which can limit the bandwidth of an optical fibre system. 
For example, the refractive index varies with wavelength so if the optical source 
emits more than one wavelength pulse dispersion may result owing to different 
wavelengths travelling at different velocities. This has resulted in very long haul 
--+-----f---n(r) 
a 
b 
Fig. 1.7 Graded index multimode fibre. (a) Side view showing ray propagation; 
(b) refractive index profile. 

Loss 
(dB/km) 
600 
800 
Wavelengths 
used for 
~oPtical fibre 
~ 
telecommunications 
1000 
1200 
1400 
1600 
A 
(nm) 
Fig. 1.8 Illustrative loss versus wavelength characteristic for silica optical fibre. 
optical fibre systems being designed to operate at a wavelength of 1300 nm where 
material dispersion is minimal for silica -
the dominant component of high grade 
optical fibres. The attenuation at this wavelength is also very low, but it can be even 
lower at 1550 nm, as shown in Fig. 1.8. Fortunately it is possible to achieve both 
low loss and low dispersion at 1550 nm by appropriate mono mode fibre design. At 
the time of writing, optical fibre systems operating at 850 nm, 1300 nm and 
1550 nm are in use and are being further developed. A particularly intriguing 
aspect of optical fibre communication is that this one basic technology is applicable 
to such a wide range of applications, from low data rate, short distance links within 
equipments and buildings to very high bandwidth, long distance links exemplified 
by transatlatic submarine telecommunications systems. 
Radio Systems 
Considering radio systems, an electromagnetic wave is launched from an antenna 
at the transmitter, propagates through the atmosphere and on arrival at the 
receiver is picked up by a receiving antenna. Depending on the form of the antenna, 
the wave may propagate out from the transmitter in all directions or may be 
restricted to some narrow sector in a chosen well-defined direction. In the first case 
the transmitting antenna is said to be omnidirectional, as opposed to directional. 
Omnidirectional transmission is used for radio broadcasting since receivers may 
generally be positioned at any location around the transmitter. On the other hand, 
ifit is wished to implement a point-to-point radio communication link then use of a 
directional antenna is desirable since this causes the available power of the 
transmitter to be concentrated in the direction of the receiver. For either system it is 
appropriate for the receiver antenna to be directional since then the receiver is most 
sensitive to the desired signals as opposed to potential interference signals arriving 
at the receiver location from other directions. Illustrative antenna directionality 
patterns are shown in Fig. 1.9. The directionality of an antenna is related to the 
ratio of the antenna physical dimension, D, to the wavelength A. A directional 
antenna is often referred to as having a gain G since the concentration of the 
transmitted power in a given direction results in an increased signal power density 
compared with an omnidirectional antenna. For example, for a parabolic reflector 
11 

12 
a 
Side 
Main 
tc5-
Relative 
sensitivity 
o 
b 
Directional 
antenna 
Directional 
o 
Isotropic 
radiator 
Isotropic 
;radiator 
() 
Angle from 
beam direction 
Fig. 1.9 Antenna directionality. (a) Polar diagrams; (b) relative sensitivity versus 
angle. 
antenna such as might be used at microwave frequencies the power gain G is given 
by 
G = (DI}..)2 
(1.15) 
where D is the diameter of the reflecting parabolic dish. 
Worked Example 1.2 
Consider a 2 m diameter reflecting parabolic dish used as the transmitting antenna 
for (a) ).. = 10 cm and (b) }.. = 3 cm microwave radio systems. (i) Determine the 
antenna gain in each case and (ii) comment on the increased effective radiated 
power provided by (b) compared with (a). 
Solution: 
(i) 
(a) G = (2/0.1)2 
= 400 == 26 dB 
(b) G = (2/0.0W = 4,444 == 37 dB 
(ii) There is thus an effective increase in radiated power of approximately 
37 - 26 dB = 11 dB owing to the reduced wavelength and correspondingly 
improved directionality. 
Any practical antenna cannot be 100070 efficient. In the case of a directional 
antenna this may be partly owing to imperfect radiation efficiency and partly to 

geometrical irregularities giving rise to some radiation outside the intended beam 
directions. These factors are often accounted for by referring to the effective 
isotropic radiated power (e.i.r.p.). The radiation from a directional antenna is thus 
equivalent to G x (e.i.r.p.) from an omnidirectional antenna. 
No matter how directional the antenna, as the wave moves away from the 
transmitter it spreads out. For the omnidirectional case a good analogy, albeit in 
two dimensions rather than three, is provided by the waves caus"ed by a stone 
thrown into a pool. By the e.i.r.p. concept a similar argument holds for the direc-
tional case too. As a consequence, the power density reduces with increasing 
distance from the transmitter. To quantify this, consider concentric spheres of 
radius r1, r2 centred on the transmitter. The surface area of a sphere varies with 1/fl 
but the power flow across the total area of each sphere, assuming no power dissipa-
tion, is the same. The power density thus reduces proportional to 11 fl and the 
power detected by a given receiver at distance r2 compared with power detected by 
the same receiver at distance r1 is given by 
(2.16) 
It is concluded the effective signal attenuation in decibels for such a radio system 
varies with the log of the distance between the transmitter and the receiver. It is 
interesting to contrast this with a cable system for which, as has been seen, the 
attenuation in decibels increases linearly with distance. On these grounds it is 
tempting to suggest that radio systems are best suited to long distance communica-
tions since, as shown in Fig. 1.10, the logarithmic dependence of loss means that 
ultimately, at some distance, the loss of a radio system is less than the loss of a cable 
system. While there is some truth in this, the argument is too trite. To be practically 
useful any such comparison must take account of different forms of radio wave 
propagation and of actual cable attenuation levels. 
The form of propagation discussed above is appropriate to 'line of sight' systems 
in which the transmitter and receiver antennas are in view of one another. There 
are, however, other forms of radio propagation which find application. Briefly, 
the most important forms are as follows: 
(i) Surface wave or ground wave. The radio wave travels along the surface, 
following the curvature of the Earth, as a result of currents flowing in the ground. 
At low frequencies this is the dominant propagation mechanism and it can provide 
Loss 
(dB) 
Cable 
~ 
__ --- Radio 
¥-----------------Distance 
Fig. 1.10 Comparison of linear (cable) and logarithmic (radio) loss 
characteristics. 
13 

More detail on radio propagation 
in telecommunications can be 
found in Hills, M.T. and Evans, 
B.G., Transmission Systems, 
(George Allen & Unwin, 1973, 
chapter 5. 
14 
- --:-- Ionosphere 
Earth 
Fig. 1.11 
Ionospheric propagation. 
for long distance communications. It is, however, prone to variation with the con-
ductivity of the ground. 
(ii) /onsopheric propagation. Radiowaves can be refracted by the ionosphere-
a layer of ionized particles above the surface of the Earth -
and returned to the 
surface some considerable distance from the transmitter. The physical mechanism 
whereby the radiowaves are bent and returned to Earth is one of continuous refrac-
tion due to gradual reduction with height of the refractive index in the ionosphere, 
as shown in Fig. 1.11. The height and density of the ionosphere depends on solar 
activity and there is considerable variation between day and night and with the 
seasons. The wave returned to earth may be reflected at the surface so that very 
long distance communication via multiple hops is possible. 
(iii) Tropospheric scattering. Radio waves can be scattered by small particles in 
the lower atmosphere to provide over-the-horizon radio communication as shown 
in Fig. 1.12. 
(iv) Free space propagation. A freely propagating radio wave provides for line 
of sight communications. Such a wave can propagate without the aid of a physical 
medium and this mode is thus known as free space propagation. It is applicable to 
space communications arid, indeed, this is how light from the sun and other stars 
reaches the Earth. It is not restricted to lightwaves, though, and can apply at any 
frequency. This is the form referred to earlier as having 1/ r dependence of power 
density with distance. Within the Earth's atmosphere, however, attenuation owing 
to absorption modifies this dependence and makes the range attainable strongly 
dependent on frequency. Each of the various radio propagation modes is more 
appropriate at some frequencies than others. However, taken together these dif-
ferent modes make possible a wide variety of radio communication systems. 
Transmitting 
antenna 
beam 
Scatter 
volume 
\ 
Earth 
Receiving 
antenna 
beam 
Fig. 1.12 Tropospheric scatter propagation. 
Communication Networks 
It was observed at the outset that telecommunications involves the sending of 
messages from a source to a sink. It should not be assumed that this communica-

n=3 
3 links 
n=4 
6 links 
n=5 
10 links 
Fig. 1.13 Examples of fully connected networks. 
tion takes place in isolation; frequently there are many possible sources and sinks 
and messages may need to be sent between varying source-sink combinations. To 
simplify the discussion, while at the same time increasing its generality, co-located 
source-sink pairs referred to as nodes are considered. A node may thus act as a 
source, a sink or, in the more general case, simultaneously as a source and a sink. 
The problem is now one of communication between nodes and the question arises 
as to how the nodes should best be connected together to form a communication 
network. It can be seen that there is no single, univerally applicable solution to the 
network structuring problem; different interconnection patterns and techniques 
are used depending on circumstances. 
Given a set of n nodes required to communicate with one another, such that any 
node may wish to send a message to any other node, we can form ajully connected 
network by introducing a separate bidirectional link between each pair of nodes. 
This arrangement is illustrated in Fig. 1.13 for certain small-n cases from which it 
is clear that the number of links required increases rather rapidly with n. A fully 
connected n-node network has n(n - 1)/2 links and the network size-complexity 
thus increases approximately with the square of the number of nodes. 
A computer-communication subsystem contains 8 processing nodes joined together to form 
Exercise 1.2 
a fully connected network. If an extra processor is to be incorporated into the system how 
many extra links are required to preserve the fully connected structure? 
A local area telephone system has 1000 subscribers. How many extra links would 
Worked Example 1.3 
be required to allow a new subscriber to be added if the system employed a fully 
connected network structure? In view of this, is it likely that telephone networks 
are actually fully connected? 
Solution: The extra telephone instrument would require a separate, direct link to 
each of the 1000 existing subscribers. Hence, to add just one new subscriber we 
need 1000 extra links! It seems unlikely, in view of this, that a fully connected 
structure could economically be employed in a telephone network. 
Switched Networks 
From the above example it is observed that the cost of adding a new subscriber 
increases linearly with the number of existing subscribers in a fully connected net-
work. This is a very undesirable characteristic since, if charging for actual install a-
15 

16 
'Satellite' 
/nodes 
...------£i 
Central 
node 
Fig. 1.14 Star network. 
tion costs, the 1000th subscriber would pay ten times the line charges of the 100th 
subscriber. There is a preference for the cost to be both lower and more uniformly 
distributed. Also, in all probability, most of the links are idle most of the time. A 
normal telephone system allows for interconnection of pairs of subscribers so that 
only one link to a subscriber would be in use at any time. Given the excessive line 
costs and poor link utilisation for a fully connected telephone network this 
structure is not employed. Instead a special central node is introduced which allows 
lines to be coupled together as required. A star network results, as shown in 
Fig. 1.14. Now any subscriber can communicate with any other via the central 
node or switching centre. The switching centre (e.g. a telephone exchange) can 
produce all n(n - 1)12 possible connections required but not all at once. If all 
subscribers were using the system simultaneously then just nl2 links would be 
needed but even this requirement is extremely unlikely to arise. In practise less links 
are employed and these can be switched between pairs of subscribers as required. 
The principle is illustrated in Fig. 1.15 where three links are provided to allow a 
group of 10 subscribers to communicate with one another. The essential feature of 
this switched network is that expensive items, in this case links, can be time-shared. 
The statistical properties of the communication requirements of large user groups 
are relied upon to effect an economy. As a result the amount of new equipment 
which must be provided when adding a new subscriber is modest and largely 
independent of the size of the existing group of users. 
C 
3 
connection B 
links 
A 
Cross-point 
switches 
-f-denotes cross-point in use 
/ 
'l!1,{ 
~I"-
2 
'l!1,{ 
)'1"-
lor 
3 
4 
567 
10 subscriber lines 
.. 
r' 
8 
9 
10 
Fig. 1.15 A small communications switching centre. Note: subscribers 2 and 5 
are communicating via link C; subscribers 3 and 8 are communicating via link A; 
link B is available. 

To higher level 
switching centre 
Central 
switching 
centre 
/ 
User 
terminals 
",Local 
switching 
centres 
Fig. 1.16 A hierarchical 'star of stars' network. 
The idea of a star connection into a switching centre can be extended to form a 
star of stars hierarchical network, as indicated in Fig. 1.16. Users in a restricted 
geographical area are connected to a local switching centre as described above and 
local switching centres are connected together via a central switching centre. For all 
but the minimum of cross-exchange communication traffic (Le. communication 
between subscribers on different local exchanges) the links between local and 
central switching centres must have sufficient communication capacity to allow 
several messages to be transferred simultaneously. This is achieved by combining 
the several message waveforms to form a single composite message. This process, 
known as multiplexing, was mentioned briefly earlier and is discussed in some 
detail in later chapters. 
A large network may have many levels in the hierarchy and it is usual to 
incorporate additional cross connections, for example between local exchanges, 
when this is justified by the expected or experienced volume of communication 
traffic. Expediency demands that practical networks are neither fully connected 
nor purely hierarchical. This is illustrated by the transmission plan of Fig. 1.17 
which shows various types of telephone switching centre and possible 
interconnections. 
Of course, the adoption of a switched network configuration carries with it 
certain overheads. In particular, there is a need for extra equipment to control the 
network. A user must first communicate with the switching centre his or her wish to 
make a call together with the identity of the called party. A free connecting link 
must be identified and the switching centre must then check whether or not the 
called party is free. If so, the switching centre must communicate with the called 
party sending a signal to get attention. The link can then be completed and 
messages transferred. At the end of the conversation the link is returned to the pool 
to be made available to other users as required. The control of a large switching 
system is a complex task now frequently delegated to a computer program. This 
form of switching systems control is referred to as stored program control (s.p.c.). 
17 

More details on switched net-
works with particular reference 
to telephony are provided in 
Hills, M.T., Telecommunication 
Switching Principles, George 
Allen & Unwin, 1979). 
18 
International switching centre 
Main switching centre 1i.:'I=========liel 
Group switching centrer..:p.,,========lre"i 
Local exchange 
Subscribers 
Fig. 1.17 A national transmission plan showing cross-links in the hierarchy. 
Data Networks 
Our discussion up to this point has been couched in terms of speech telephony but 
the ideas outlined are more broadly applicable. For example, the special signals 
used in establishing a telephone connection are an aspect of the signalling sub-
system. This is an important consideration in the development of any new telecom-
munications system and has its counterpart in the more general communications 
context. For data and computer communications the link set-up procedure is 
referred to as a link-level protocol. A protocol is a well-defined procedure to enable 
terminals/nodes to communicate effectively over a network. Protocols for modern 
data communication systems can be extremely complex -
involving several layers 
as indicated in Fig. 1.18 -
and require careful design and verification. 
As a further example of the diverse character of communication networks con-
sider the ring structure of Fig. 1.19a. Any node may communicate with any other 
by simply applying signals to the ring. Of course, only one message may be 
transmitted at any time but by time-sharing the circuit between different messages 
with different source and destination nodes effectively simultaneous transfer of 
multiple messages is achieved. This is the essence of a form of local area network 
(LAN) used for computer/data communication, developed at the University of 
Cambridge and known as the Cambridge Ring. Data circulate around the ring in 
packets, a packet being a sequence of binary digits represented by a pulse wave-
form. A hypothetical packet is shown in Fig. 1.19b. Note that a packet may be 
empty, in which case a node wishing to transmit a message may insert data into the 
packet, or it may be full. All nodes monitor the packets as they circulate around the 
ring since the data destination is contained in the header. A node reads the data in 
the packet ifit is the intended destination and is free to accept data. It indicates that 
it has done so by changing the response bits. A packet is cleared on return to the 
source node. More than one packet may be circulating around the ring allowing 
several messages to be transferred simultaneously by time-sharing the physical ring 
connection. 
The technique of data communication by way of packets is also used in other net-

User A 
6 Presentation 
layer 
5 Session 
layer 
4 Transmission 
layer 
a 
~Logical flow~ 
D~r~u.!!l~d~~~e~C.£e~~ ____ __ 
document exchange. etc 
E~ 
~r:!!I~ti~g..!.o ..!U.!!. <!!!fere~t ___ _ 
presentation media 
Synchronizes data flow between end points. 
coordinates exChanges:QrouPs data into -
units 
Matches data exchange rate to processing 
capability Of terminaiS; enCiPhers datalf-
required for security 
Sends data in 'packets' between end-user 
~----------------
terminals. controls data flow and congestion 
in the network 
Provides reliable data transmission between 
adjacent nodes along a route using error-
control coding if appropriate 
Provides physical connection 
between adjacent nodes- -
-
-
-
-
-
Physical flow involving intermediate 
nodes and links as appropriate 
Fig. 1.18 Protocol layering. 
Nodes or 
/ 
'Stations' 
Physical ring channel 
11 1M I 
F IDestinationl Source 
Data 
b 
UserB 
Fig. 1.19 A ring network. (a) Ring network configuration; (b) Cambridge ring 
data packet: M = monitor bit, F = full or empty bit, P = parity bit (see Chapter 7), 
'destination' and 'source' are 8-bit addresses, Rl and R2 are response bits changed 
by receiving station to indicate action taken. 
19 

20 
work structures. The nodes in a network examine the header and send the packet 
along an appropriate route towards its destination. Packet switching networks of 
this type may be geographically distributed over a wide area. They are thus some-
times referred to as wide area networks (WANs). 
Integrated Services Digital Network 
The distinction between data and telephone speech communication is by no means 
sharp. It is seen in Chapter 6 that speech and other analogue signals may be con-
verted into the form of digital data. Indeed, this is now the most common way of 
transmitting speech in the higher levels of the telephone network. Increasingly, 
both signal transmission and switching is implemented using digital data 
techniques and the telephone systems of many countries are rapidly moving over to 
a digital network. In addition, there is an increasing need for the provision of a 
wider range of communication services: data transmission, electronic mail, 
facsimile (still picture) transmission and so on. Given the existence and extent of 
the telephone network it is not suprising that this is being considered as the basis for 
the integration of these and many other services into a single network. Means of 
transmitting data over the telephone network were devised even before digital 
transmission within the telephone network itself was widespread. More recently 
there has been a conscious attempt to bring together the various services and make 
these widely available on a single network, with as much uniformity as practicable. 
These moves towards service integration together with the continued expansion of 
digital transmission and switching have led to the proposal of an integrated services 
digital network (ISDN). Just how the telephone network may/should evolve 
towards this goal is the subject of much current research and debate. 
Telecommunications Worldwide 
The telephone network has grown up over the years so that it is now possible to 
place a call to almost anywhere in the world, usually without the assistance of an 
operator. The call may be carried by a wide variety of communication media: wire 
pairs, coaxial cables, optical fibres, radio/microwave links and so on. In addition, 
several links may be used in combination. For example, if telephoning from 
London to Los Angeles on the west coast of the United States of America, a 
hypothetical connection might involve the following: 
(a) Direct transmission of analogue speech signal via wire pair to local exchange. 
(b) Conversion to digital form and switching to a (time-shared) optical fibre link 
for transmission to a satellite Earth station at Goonhilly Downs. 
(c) Modulation on to a 6 GHz carrier for transmission to a satellite positioned 
over the Atlantic ocean. 
(d) Conversion within the satellite to a 4 GHz carrier for transmission to an Earth 
station on the eastern seaboard of America (the Atlantic satellites cannot com-
municate directly with California). 
(e) Transmission over landlines, using frequency division multiplexing, to a main 
switching centre within Los Angeles. 
(0 Conversion to a multiplex format involving less channels for transmission over 
cable to another, local, switching centre. 

(g) Conversion to baseband for transmission over a wire-pair to the destination 
subscriber. 
Alternatively, the signal might be sent via an undersea cable to the east coast of 
America and then over land as above. A user generally has no need to know which 
route a call takes -
all that is required is a good connection. There are, however 
factors which must be taken into account by the network controllers when routeing 
calls. For example, time differences around the world give rise to non-synchronous 
peaks of demand in different locations. When it is breakfast time in New York it is 
still night time in California. As a result, it is not unknown for telephone calls at 
busy times between New York and Washington D.C. on the east coast to be routed 
via, say, Los Angeles when all direct links are occupied. Another factor which must 
be taken into account is signal delay. For telephone speech routed via radio, 
surface links or undersea cables this presents no difficulties. The use of a satellite in 
the chain, however, introduces some 270 ms of one-way delay. This represents a 
pause of approximately 0.5 s between speaking and receiving the answer. This is 
perceptible but subjectively acceptable to users. However, if two satellites are 
included in a chain the attendant delay exceeding one second makes conversation 
virtually impossible. In view of this, telephone connections from England to 
eastern Australia are restricted to no more than one satellite segment (a satellite 
over the Indian ocean), the link being completed via cable. Similarly communica-
tion from Europe to the west coast of America makes extensive use of land lines 
even though combined use of the Indian and Pacific ocean satellites would avoid 
this. 
This constraint does not apply to one-way communication such as broadcast 
television or non-interactive data transmission. There is thus great flexibility for 
information transfer around the world, with routeing strategies taking account of 
varying demand peaks, tolerance of different services to delay and so on, to allow 
for effective utilization of this worldwide telecommunications network. 
Summary 
This chapter has provided a general overview of many aspects of telecommunica-
tions with some emphasis on the large-scale nature of the systems involved. A 
message is represented by a signal corresponding to a voltage or current waveform. 
The signal, which may represent speech, a television picture or data, for example, 
can be conveyed over long distances using a suitable communication channel such 
as a coaxial cable, radio link or optical fibre. To render the signal compatible with 
the available channel some form of signal processing such as modulation or coding 
may be required while to make effective use of a wide bandwidth channel several 
signals may be combined and transmitted simultaneously. There is a need for com-
plex interconnection networks to provide for multi-message communication 
between many different centres, and there is a move towards an integrated services 
digital network (ISDN) to allow for digital transmission within a single network 
structure of a wide variety of different types of signals. 
21 

22 
Problems 
1.1 A step index multi mode fibre has a core refractive index of 1.52, a cladding 
index of 1.51 and a loss of 5 dB/km. 
(i) 
From the point of view of pulse spreading what is the maximum fibre 
length allowable for data transmission at 2 Mbitls? 
(ii) What would be the loss of a fibre of this length? 
(iii) If 0.5 m W of optical power is launched into the fibre determine the out-
put power level, expressing this both in terms of watts and in terms of 
dBm. 
1.2 A small satellite ground station is to be up-graded by replacing the 2 m 
diameter reflecting parabolic dish antenna by one of 4 m diameter. How much 
improvement in received signal strength would you expect this to provide? 
1.3 A software engineering laboratory is equipped with 16 microcomputer-based 
workstations. It is required to interconnect these so that they can communicate 
with one another and also with a printer and a separate storage system known 
as a file server. Determine how many 2-way links would be required for a fully 
connected network. Suggest an alternative network structure which might be 
more appropriate in this instance. 
1.4 The Cambridge ring operates at 10 Mbitls but there are only 16 data bits per 
40 bit data packet. In view of this, estimate the maximum information transfer 
rate in bitls. 

Signal Representation and 
Analysis 
D To provide a basis for describing signals analytically in the time domain. 
D To show how signals may be scaled and translated in time. 
D To introduce the concept of a signal spectrum and of a signal description in 
the frequency domain. 
D To explain what is meant by negative frequency and a bilateral or double-
sided spectrum. 
D To show how signals may be described in either domain and to establish the 
relationship between these descriptions via Fourier analysis. 
D To illustrate the effect of filtering on a signal spectrum. 
D To note briefly that spectral methods can be extended to encompass signals 
of arbitrary waveshape such as practical communication signals. 
D To introduce the idea of describing signals probabilistically in terms of the 
amplitude distribution. 
It was seen in the previous chapter that communication links involve the transmis-
sion of a signal waveform representing the message from a source to a destination. 
At the destination the received waveform is processed and the message is recovered 
as nearly as possible -
'as nearly as possible' because the received waveform 
generally contains two components: an attenuated and delayed version of the 
original signal from which the message could be recovered exactly, together with an 
extraneous, unwanted component which interferes with the wanted part and may 
give rise to error in the recovered message. The unwanted components may be due 
to signal distortion by the channel, to interference from nearby electrical equip-
ment, or it may simply be electrical noise: apparently random signal variations of 
thermodynamic or quantum origin. It is not necessary to be concerned with the 
physical mechanisms giving rise to these random waveforms but it is necessary to 
assess their implications for the performance of communication systems. In order 
to do this both the message or signal waveform and the unwanted noise/inter-
ference components must be represented mathematically. In this chapter the 
various ways in which signals may be represented are examined. Before doing this, 
however, it is appropriate to note that it is neither necessary nor practicable to 
assess the performance of a system by examining how it will process all possible 
message waveforms. For speech communication this would involve a considera-
tion of all possible speakers (including, presumably, some not yet born) and all 
possible sentences (some not yet uttered)! Instead prototype signals with character-
istics similar to those of the actual signals to be conveyed are used. For example, for 
speech telephony much useful analysis can be based on how a system responds to 
sinusoidal signals of different frequencies and amplitudes, while for data com-
munication the response of a system to a single pulse may provide an insight into 
how the system responds to a message waveform corresponding to a sequence of 
2 
Objectives 
23 

24 
V(tl 
Vcos(2'nFt + qy, 
/ 
-0 
0 
1+-------- T = 1 IF --------~ 
Fig. 2.1 
A sinusoidal signal in the time domain. 
pulses. In view of this the study of signals is commenced by considering the repre-
sentation and analysis of such idealized signals. 
The Time Domain 
A signal waveform may be viewed as the variation with time of a quantity such as 
voltage or current. For the sake of definiteness consider voltage waveforms. As a 
first example, consider the sinusoidal voltage signal given by 
v(t) = Vcos(27C'Ft + ¢) 
(2.1) 
Here V is the peak voltage, F is the frequency and ¢ is the relative phase. These 
parameters are indicated on the diagram of Fig. 2.1. The waveform is periodic with 
period T = 1/ F since 
v(t) = v(t + T) 
(2.2) 
This description is called a representation of the signal in the time domain: the sig-
nal is viewed as a function of time. This is by far the most common way of 
representing signals and of observing them in the laboratory. Whenever an 
oscilloscope is used to observe a voltage waveform the signal is being viewed in the 
time domain. It is necessary to be able to describe signals analytically in the time 
domain; some examples are given below. 
Some Examples oj Signals in the Time Domain 
Consider a rectangular pulse signal, as shown in Fig. 2.2a. The signal waveform is 
zero up to some time 'I = -112 at which point it steps up to a value 1. The waveform 
value is lover the interval ( - 112, 112) and at the end of this interval drops down to 
zero. The waveform value is zero for all t > 112. Expressing this analytically 
.:l [1 
xl(t) = rect(t) = 
0 
I tl < 112 
elsewhere 
(2.3) 
Here rect(t) is simply a shorthand way of describing a rectangular pulse with unit 
height and unit width centred on the origin of the time axis. A similar rectangular 
pulse occurring at some other time, say centred on t = to as shown in Fig. 2.2b, may 
be expressed in terms of the rect( ) function as follows: 

a 
1 
"2 
o 
x,(t) = rect(t) 
b 
1 
"2 
c 
o 
t- 1 
t 
to +-21 
o 
2 
0 
x3(t) = rect(t/T) 
.-----+---....., 1 
- T/2 
o 
T/2 
Fig. 2.2 Rectangular pulse signals. 
(2.4) 
In order to confirm this, note that the centre of the rectangular pulse corresponds 
to the argument of the function, rect(u) being zero. 
Here 
u = 1-/0 
and 
u = 0 
~ I - 10 = 0 ~ I = 10 
The pulse is centred on I = 10 , This is referred to as signal translation or shifting on 
the time axis. Notice that subtracting a constant, 10, from I in the function argu-
ment has the effect of shifting the function to the right; that is, to a delay of 10, 
Consider now a pulse of non-unit width, say of duration T, as shown in 
Fig. 2.2c. This may be expressed analytically as 
x3(/) = rect(llT) 
(2.5) 
To check the validity of this formulation note that rect(u) steps from 0 to 1 at 
u = - 112 and from 1 to 0 at u = 112. That is, the transitions occur at I u I = 112. 
Putting u = liT it is concluded that transitions occur at I u I = I I I IT = 112 
~ 
I II = T12. Transitions occur at 1= ± T12 and the pulse is of width T. This is 
referred to as signal scaling on the time axis, or simply as time scaling. 
Amplitude scaling gives no difficulty. A rectangular pulse of height A is simply 
A rect(t). 
Consider a rectangular pulse signal of height A and duration T centred at a point in 
time t = 10 > T. Sketch the signal waveform in the time domain and obtain an 
analytic representation in terms of the rect( ) function. 
Solution: Since 10 > T12 > 0 the pulse is shifted to the right as shown in Fig. 2.3. 
The signal may be expressed analytically as 
Note that a minus sign in the 
argument produces a shift along 
the positive time axis. 
Note that dividing the argument 
by T has the effect of multi-
plying the pulse width by T. 
Worked Example 2.1 
25 

26 
f''' ~ A"" ", -"oIlTl 
A 1------------ ·I~ 
o 
Fig. 2.3 
Time-translated rectangular pulse of duration T. 
x(t) = A rect[(t - to)/T] 
This may be verified as follows: 
(i) The rect(u) function is centred on u = O. 
Here 
u = (t - to)/T 
and 
u = 0 
~ (t - to)/ T = 0 * t = to 
Hence the pulse of Equation 2.6 is centred on t = to. 
(ii) Transitions occur in rect(u) when u = ± 112. 
Here 
and 
u = (t - to)/T 
u = ±112 * (t - to)/T= ±112 
* t - to = ± TI2 
~ t = to ± TI2 
Hence transitions are separated by T; the pulse is of width T. 
(iii) The amplitude of the pulse corresponds to the value at t = to. 
A rect[(t - to)/T] I 
t = to 
= A rect(O) 
= A, since rect(O) = 1. 
(2.6) 
Consider now how a binary digital signal, such as the pulse sequence of Fig. 2.4a, 
may be represented. In this example, the signal consists of pulses of width Tlocated 
at t = 0, 2T, 3Tand ST. Thus: 
x(t) = rect(t/T) + rect[(t - 2T)/T] + rect[(t - 3T)/T] + rect[(t - ST)/T] 
(2.6) 
where each term describes the corresponding pulse. More generally: 
x(t) = ao rect(t/T) 
+ a1 rect[(t - T)/T] 

lX!t) 
I 
0 
0 
I 
.. 
- T/2 0 
T/2 
T 
2T 
3T 
4T 
5T 
a 
.. 
-T 
0 
T 
b 
I 6/! 
o 
T 
2T 
3T 
4T 
5T 
t 
c 
Fig. 2.4 Binary data signals in the time domain. (a) Non-return to zero (NRZ) 
binary data signal; (b) smoothed pulse signalling element; smoothed data signal 
based on the signalling element of (b). 
+ a2 rect[(t - 2T)IT] 
+ ... + an rect[(t - nnlT] + 
= :L an rect[(t - nnlT] 
n 
(2.7) 
where [an] represents the data, an taking the value 1 or 0 according to whether or not 
a pulse is present in the corresponding time slot of duration T centred on t = n T. 
The summation is taken over all relevant (integer) values for n. Very often the sig-
nal is assumed to exist throughout all time and can be written 
00 
x(t) = A ~ an rect[(t - nnlT] 
(2.8) 
n = -00 
with an E [0, 1 J for a unipolar binary data signal of amplitude A. For a bipolar 
signal an E [-1, IJ while for a unipolar, multilevel pulse signal we have an E 
[0, 1, .. . (N - 1)] if the signal can assume one of N uniformly separated values in 
each time slot. 
A similar procedure may be used to describe pulse sequences in which the basic 
pulse element, the signalling element, waveform is not rectangular. Denoting the 
elemental pulse waveform as p(t), 
00 
x(t) = 
~ anp(t - nT) 
(2.9) 
n = -00 
27 

28 
.. 
-T 
-Tf2 0 
Tf2 
T 
Fig. 2.5 
A rectangular wavetrain. 
An illustrative segment of such a signal is shown in Fig. 2.4b, c based on a pulse 
waveform p(/) of raised cosine form: 
p(/) = [g + cos(1rIID]/2 
III < TI2 
elsewhere 
Exercise 2.1 
Obtain an analytic expression for the periodic rectangular wavetrain of Fig. 2.5. 
The Frequency Domain 
(2.10) 
Consider once more the sinusoidal voltage waveform of Equation 2.1. The word 
'sinusoidal' indicates the shape of the waveform. Given a sinusoidal signal a com-
plete specification of the signal is provided by the amplitude V, the frequency F and 
the phase q,. These three parameters, together with the knowledge that the signal is 
sinusoidal, are sufficient to be able to draw the voltage waveform; the triple (V, F, 
q,) fully specifies the signal. For the time being attention is restricted to signals of 
strictly co sinusoidal form, i.e. q, = 0, and we will deal with just the amplitude V 
and frequency F: now the pair (V, F) fully specifies the signal. In this representa-
tion F and V can take any positive value and the signal can be represented 
graphically as shown in Fig. 2.6. This is a representation in thefrequency domain. 
With this view, a co sinusoidal signal is represented by a vertical arrow located at 
some point F on the frequency axis and the height of the arrow corresponds to V, 
the amplitude of the signal. Note that if F = 0 then there is a d.c. signal with 
amplitude V. This can also be represented in the frequency domain by an arrow of 
height V located at the origin. 
The frequency domain representation is very useful because more complicated 
signals can be considered as a superposition (i.e. a summation) of sinusoidal 
components with different amplitudes, frequencies and phases. For periodic sig-
nals the frequencies are integer related. If Tis the period then the waveform is said 
to have a fundamental frequency of liT. The next lowest frequency contained in 
v ---------
o 
F= 1fT 
f 
Fig. 2.6 A sinusoidal signal in the frequency domain. 

t 
1 
t 
t 
.. 
o 
1fT 
2fT 
3fT 
4fT 
f 
Fig. 2.7 A non-sinusoidal, periodic signal viewed in the frequency domain. 
the waveform is 2fT, termed the second harmonic, and after that comes the third 
harmonic, frequency 3fT, and so on. Generally, the various harmonic components 
have different amplitudes and phases (some may have zero amplitude). To obtain a 
general appreciation of the harmonic content of a complicated waveform it is con-
venient to represent the signal graphically in the frequency domain, as illustrated in 
Fig. 2.7 (once again, phase is neglected). The heights of the arrows represent the 
strengths of the various harmonic components -
the amplitudes of the various 
cosinusoidal components comprising the complicated periodic waveform. This 
frequency domain representation is often called the spectrum of the signal; the 
various constituent frequency components are the spectral components or spectral 
lines. It was noted previously that it is common practice to view signals in the time 
domain using an oscilloscope. It is possible also to view signals in the frequency 
domain (neglecting phase) using an instrument called a spectrum analyser. Fig. 2.8 
shows an illustrative signal spectrum as displayed on a spectrum analyser. 
Fig. 2.8 A frequency domain view of a signal as displayed on a spectrum 
analyser. 
29 

30 
The frequency domain representation presented up to this point is incomplete in 
that it contains only amplitude information and omits any mention of the relative 
phases of the various comoponents. This can be remedied in various ways. One 
solution is to label each arrow with the phase ofthat component. That is, each com-
ponent corresponds to a time domain contribution of the form 
An COS(2'lIFnt + cPn) 
where An is the amplitude, Fn = nlTis the frequency and cPn is the phase. A compo-
site signal may be the sum of many terms of this form and may also contain a d.c. 
component. A periodic signal x(t) with period T can be represented as follows: 
x(t) = Ao·+ AI cos[27r(tln + cPll 
+ A2 cos[27r(2tIT) + cP21 ... 
+ An cos[27r(ntln + cPnl + 
or, more concisely, as 
CD 
= Ao + ~ An cos[27r(ntIT) + cPnl 
n = I 
(2.11) 
(2.12) 
This is known as a Fourier series representation for x(t). Note its close relationship 
with the frequency domain representation: the amplitudes An give the heights of 
the various spectral lines. 
An alternative Fourier series representation may be obtained by using the 
trigonometric identity 
cos(A + B) = cos(A) cos(B) - sin(A) sin(B) 
to write 
(2.13) 
An cos[27r(ntln + cPn] = An[cos(27rntIT) cos(cPn) - sin(27rntIT) sin(cPn)] 
= [An cos(cPn)]cos(27rntln + [ -An sin(cPn)]sin(27rntIT) 
= ancos(27rntln + bnsin(27rntIT) 
(2.14) 
where 
an = An cos(cPn) 
bn = -An sin(cPn) 
We can thus represent x(t) in the form 
CD 
CD 
x(t) = Ao + ~ an cos(27rntIT) + ~ bn sin(27rntIT) 
n = I 
n = I 
That is, a periodic signal can be considered as a sum of: 
(i) a d.c. term of amplitude Ao, 
(2.15) 
(ii) a set of harmonically related co~inusoidal signals with amplitude an> and 
(iii) a set of harmonically related sinusoidal signals with amplitude bn• 
Yet another representation makes use of the observation that 
A 
expUA) + exp( - jA) 
cos 
= 
2 
(2.16) 

whence 
An cos[(21rntID + ¢n] 
= ~n ( expU(21rntIT + ¢n)] + exp[ - j(21rntIT + ¢n)] J 
= ~n [exPU21rntIDexPU¢n) + exp( - j21rntIDexp( - j¢n) ] 
= cnexpU21rntiD + c_nexp( -j21rntID 
where 
and 
An 
( 
.,j..) 
* 
c_ n = TexP -j'fJn = C n 
assuming An is real. 
Thus x(t) can be expressed as 
00 
x(t) = Ao + ~ [cn expU21rntlT + c_n) exp( - j21rntIT)] 
n - I 
Using the fact that 
expU21rntIT) I = eO = 1 for n = 0 
n-O 
(2.17) 
(2.18), 
and defining Co = Ao, x(t) can be expressed in terms of a single series ranging over 
all integers: 
00 
x(t) = 
~ Cn expU21rntlD 
(2.19) 
n = -co 
This, the exponential form of the Fourier series, is particularly useful in signal 
analysis. The Cn values are complex numbers with Icnl corresponding to the mag-
nitudes and arg(cn) to the phases of the constituent spectral components. In this 
representation, however, n takes both positive and negative values and it is con-
venient to consider a two-sided spectrum of the form shown in Fig. 2.9. By analogy 
with the earlier discussion of graphical representation of a signal spectrum, each 
arrow corresponds to a spectral line; the nth term is a component of freqency niT. 
-4fT-3fT-2fT-1fT 0 
1fT 2fT 3fT 4fT 
f 
Fig. 2.9 A two-sided (bilateral) frequency domain representation. 
31 

The concept of negative fre-
quency described here is 
extremely important. Take time 
to become familiar with the 
idea. 
32 
Imaginary 
---------If-----+--------Real 
Fig. 2.10 A cosine wave represented by two contra-rotating vectors in an 
Argand diagram. 
Since n ranges over both positive and negative values this makes it necessary to give 
some meaning to negativefrequency. The idea may take a little getting used to! It is 
not being suggested that a real signal has a negative frequency -
nor indeed that it 
has a positive frequency. A real signal has afrequency, such as FHz. However, a 
real signal may be considered for the purposes of analysis as the sum of positive and 
negative frequency components, just as a cosine wave may be considered as the 
sum of two complex exponential factors. 
With this perspective 
cos(27rFt) = co sinusoidal signal with frequency F 
expU27rFt) + exp( - 27rFt) 
2 
= IexP( + j27rFt) 
+ IexP( - j27rFt) 
positive frequency term 
negative frequency term 
(2.20) 
The signal may be represented on an Argand diagram by two contra-rotating 
vectors, as shown in Fig. 2.10. The vector rotating in the positive (anticlockwise) 
direction has angular velocity + 27rF and is said to correspond to a positive 
frequency term. The vector rotating in the negative (clockwise) direction has 
angular velocity - 27rF and is said to correspond to a negative frequency term. The 
sum of the two components, corresponding to the signal x(t) , is always real. Each 
individual component is a complex function of time but since both terms always 
occur together, as complex conjugates, the resultant is always real. Thus the signal 
V cos(27rFt) can be represented in the frequency domain by a diagram of the form 
shown in Fig. 2.11. With this double-sided representation a cosine wave has two 
frequency components of equal strength located atf = ±F. This says no more than 
1 
1 
.. 
-F 
o 
+F 
f 
Fig. 2.11 
Bilateral frequency domain representation for a cosine wave. 

-3F, 
-F, 
0 
+F, 
+3F, f 
Fig. 2.12 Bilateral spectrum for a signal of Equation 2.21 with F2 = 3Fj and 
B = AI2. 
that we are dealing with a cosine wave of frequency F but are using a model in 
which this is viewed as a sum of two vectors rotating in opposite directions. 
Some Examples of Signals in the Frequency Domain 
(i) Sum of Cosine Waves. Consider a signal comprising two cosine waves of 
different frequencies: 
x(t) = A COS(2'lIFjt) + Bcos(27rF2t) 
(2.21) 
Expanding this in terms of complex exponential factors, we obtain 
x(t) = 1 
exp( + j27rFjt) + 1 
exp( - j27rFjt) + ~ exp( + j27rF2t) + ~ exp( - j27rF2t) 
(2.22) 
positive 
negative 
positive 
negative 
frequency 
frequency 
frequency 
frequency 
term 
term 
term 
term 
at +Fj 
at -Fj 
at +F2 
at -F2 
For example, if F2 = 3Fj and B = AI2 this signal has a frequency spectrum of the 
form shown in Fig. 2.12. 
(ii) Square wave signal. A square wave can be viewed as a sum of harmonically 
related co sinusoidal components. This is illustrated graphically in Fig. 2.13. 
Starting with a term cos(27rtlT) as the fundamental component, we then add a 
third harmonic component, -1I3cos(27r3tlT). This has the effect of slightly 
depressing the peaks whilst sharpening the transitions. The resultant waveform 
looks a little more like a square wave than does the original cosine wave. If we now 
add a fifth harmonic term, + 1I5cos(27r5tIT), a seventh harmonic term, 
-1I7cos(27r7tlT), and so on; the resultant approaches closer and closer to a 
square wave. It can be said that the partial sum -
that is, the sum up to some 
(2n - l)th harmonic -
approximates to a square wave, or that the sum converges 
to a square wave as n ~ 00. The square wave signal may be viewed in the frequency 
domain as shown in Fig. 2.14. Since the double-sided representation is used the 
fundamental term at f = liT gives rise to spectral lines of strength 112 at 
f = ± liT, and so on. 
The procedure just outlined may be termed Fourier synthesis in that a 
close approximation to a square wave has been constructed (or synthesized) by 
adding together sinusoids having appropriate frequency, amplitude and phase 
relationships one to another. The inverse of this process, Fourier analysis, is 
33 

Fourier analysis plays a very 
important part in communication 
systems studies. When Baron de 
Jean Baptiste Joseph Fourier 
(1768-1830) first introduced 
the technique and applied it to 
the theory of heat conduction in 
1822 his contemporaries had 
great difficulty accepting the 
ideas. The theory was the sub-
ject of some controversy for 
almost a century. You may find 
it takes you, also, some time to 
come to terms with the ideas. 
34 
- jcos (27r3tlT) 
/ 
/' ~cos (27r5tlT) 
a 
1 st 
/ 
/15t + 3rd 
/ .____1 5t + 3rd + 5th 
r+.,.....,~-7~-"t-'I:-, 
----- Square wave 
----~~-------~ 
b 
Fig. 2.13 Harmonic synthesis of a square wave. (a) Low-order harmonic 
components of a square wave; (b) sequence of partial sums of (a) converge 
towards the square wave. 
1 
rO 
-51T 
-31T 
1 
2 
1 
2 
-11T 
0 
11T 
Fig. 2.14 Spectrum of a square wave. 
required to determine just what the relationship must be for the partial sum of 
harmonically related sinusoids to approach a given signal. 
Fourier Series Analysis 
It was suggested previously that a periodic· signal x(t) = x(t + T) could be 
expressed in terms of an exponential Fourier series of the form 
x(t) = ~cn expU27rntlT) 
(2.23) 
n 
where en are the Fourier coefficients corresponding to the amplitudes and phases of 
the individual frequency components. These coefficients are related to the time 
domain signal by 

1 JTI2 
Cn = T 
x(t) exp( - j27rntIT) dt 
-T12 
(2.24) 
We will not formally prove this statement but the following argument should 
provide a sufficiently convincing demonstration that the statement is reasonable. 
First note that the choice of indexing integer in Equation 2.23 is arbitrary; thus 
the following can be written: 
x(t) = ~Ck expU27rktlT) 
k 
Now substitute Equation 2.25 for x(t) in Equation 2.24: 
Cn = -
~Ck expU27rktIT) exp( - j27rntlT) dt 
1 I 
TI2 
[ 
] 
T -TI2 
k 
(2.25) 
(2.26) 
where the change from n to k for the indexing integer in Equation 2.25 has avoided 
a clash with the use of n as an index in Equation 2.24. The strategy now is to 
demonstrate the consistency of Equation 2.26: to show that the right hand side 
reduces to cn' Interchanging the operations of integration and summation: 
1 
JTI2 
cn = - ~ 
Ck expU27rktlT) exp( - j27rntIT) dt 
T k 
-T12 
1 
JTI2 
= -
~Ck 
expU27r(k - n)tIT) dt 
T k 
-T12 
Consider now the integral in Equation 2.27 with m = k - n: 
J(m) = r TI2 expU27rmtIT) dt 
J -T/2 
= [exPU27rmtIT) ] TI2 
j27rmlT 
-TI2 
eXPU7rm) - exp( - j7rm) 
j27rmlT 
m = 0 
m =1= 0 (m integer) 
(2.27) 
(2.28) 
That is, the integral is zero unless m = k - n = O. Hence in Equation 2.27 only the 
term k = n in the summation is non-zero and 
C=~~ cT=c 
n 
T 
k. 
k 
n 
(2.29) 
k=n 
Thus it can be concluded that Equations 2.23 and 2.24 are consistent; if a periodic 
signal x(t) can be expanded according to Equation 2.23, then the coefficients Cn are 
given by Equation 2.24. 
Relationships between Fourier Coefficients 
Only real time functions x(t) are of concern since it is required to analyse signals 
35 

36 
corresponding, for example, to the variation of a voltage value with time. With this 
constraint a relationship between Cn and C _ n can be established as follows: 
1 JTI2 
cn = -
x(t) exp( - j27rntIT) dt 
T -T12 
1 JTI2 
= -
x(t)[cos(27rntlT) - j sin(27rntlT)] dt 
T -T/2 
1 J T/2 
1 J 
TI2 
= -
x(t) cos(27rntlT) dt - j-
x(t) sin(27rntlT) dt 
T -T/2 
T -T/2 
= Re (cn) - j Im(cn) 
1 JTI2 
C -n = -
x(t) exp[ - j27r( - n)tlT] dt 
T -T/2 
1 JTI2 
= -
x(t)[cos(27rntlT) + j sin(27rntIT)] dt 
T -T12 
1 JT/2 
1 J 
TI2 
= -
x(t) cos(27rntlT) dt + j-
x(t) sin(27rntlT) dt 
T -TI2 
T -TI2 
= Re (cn) + j Im(cn) = cn * 
(2.30) 
Hence for a real time signal x(t) the Fourier coefficients form complex conjugate 
pairs: Cn = C -n * . 
If additional constraints on the time signal x(t) are considered then further 
relationships emerge: 
(i) x(t) = x( -t), an even time function: 
1 J TI2 
Cn = -
x(t) exp( - j27rntlT) dt 
T -TI2 
1 fTI2 
= -
x(t)[cos(27rntlT) - j sin(27rntlT)] dt 
T -TI2 
= ~Jx(t) cos(27rntlT) dt - j ~Jx(t) sin(27rntlT) dt 
even x even 
= even function 
even x odd 
= odd function 
(2.31) 
The integral of an odd function between symmetrical limits about the origin is zero, 
hence 
1 JTI2 
cn = -
x(t) cos(27rntIT) dt 
T -T/2 
(2.32) 
and the Fourier coefficients are all real. But having established generally that 
Cn = C -n *, then Cn = C -no real, if x(t) is an even function. 
(ii) x(t) = - x( - t), an odd time function: 
1 J 
TI2 
x(t) = -
x(t) exp( - j27rntIT) dt 
T -T/2 

1 J TI2 
1 J TI2 
= -
x(t) cos(27rntlT) dt - j-
x(t) sin(27rntlT) dt 
T-T12 
T-T12 
odd x even 
= odd junction 
odd x odd 
= even junction 
This time, then, the real part is zero and Cn is purely imaginary: 
1 fTI2 
cn = -j T 
x(t) sin(27rntIT) dt 
-TI2 
Now since Cn = C_n * , Cn = - C_n , imaginary, if x(t) is an odd function. 
(iii) Linearity, y(t) = axit) + bxlt): 
(2.33) 
(2.34) 
Consider two time signals xl(t) and xi!) with common period T and Fourier series 
expansions given by 
xl(t) = ~ cl • expU27rntlT) 
n 
x2(t) = ~ c2• expU27rntIT) 
n 
(2.35a) 
(2.35b) 
A signaly(t) = axl(t) + bxit), which is a linear superposition of xl(t) , x2(t), also has 
period T and Fourier series as follows: 
y(t) = a ~ cl • expU27rntlT) + b ~ c2• expU27rntIT) 
n 
n 
= ~ acl• expU27rntlT) + ~ bc2• expU27rntlT) 
n 
n 
= ~ (acl• + bc2) expU27rntlT) 
n 
= ~ Cn expU27rntIT) 
(2.36) 
n 
It can be concluded that if two signals with a common period can be combined 
linearly then their Fourier coefficients can be combined linearly. That is, if 
y(t) = axl(t) + bx2(t), then Cn = aCI + bC2 where [Cn] , [cI ], [c2 ] are the Fourier 
coefficients for y(t), xl(t) and xit) respectively. A spe'cial ~ase of interest is 
y(t) = -x(t); changing the sign of the signal simply changes the sign of the Fourier 
coefficients. 
(iv) Time translation, y(t) = x(t - 7): 
Assume the Fourier series expansions as follows: 
n 
y(t) = ~ cn expU27rntIT) 
n 
(2.37a) 
(2.37b) 
where [cn] are the Fourier coefficients for x(t) and [cn] the Fourier coefficients for 
y(t) = x(t - 7). It follows, ~hen, that 
y(t) = x(t - 7) = ~ 
Cn expU27rn(t - 7)IT) 
n 
= ~ Cn expU27rntlT) exp(-j27rnrIT) 
n 
37 

38 
= ~ [cn exp(-j27rnrIT)] expU27rntlT) 
n 
= ~ en expU27rntIT) 
n 
and 
(2.38) 
(2.39) 
That is, the Fourier coefficients for the time translated signal y(t) have the same 
magnitude as the coefficients for x(t) .. The time translation simply introduces a 
phase shift of - j27rnrlT proportional to n, the harmonic number. 
(v) x(t) = -x(t + TI2): 
Here if 
x(t) = ~cn expU27rntlT) 
n 
and 
x(t + TI2) = ~ en expU27rntIT) 
n 
we note from Equation 2.39 that 
n even 
n odd 
(2.40a) 
(2.40b) 
(2.41) 
Butthe condition x(t) = - x(t + TI2) implies Cn = - en and it can be concluded that 
n even 
n odd 
(2.42) 
That is, only odd harmonics are present in the Fourier series expansion for such a 
function; the square wave considered previously provides an illustrative example. 
Worked Example 2.2 
Consider a periodic rectangular wave signal as shown in Fig. 2.15 and described by 
x(t) = ~ rect[(t - kT)/r] 
(2.43) 
k 
Express this in terms of an exponential Fourier series of the form 
x(t) = ~ 
Cn expU27rntIT) 
(2.44) 
n 
Sketch the signal spectrum, X(f), using the double-sided representation. 
] o 
o 
-2T 
-T 
-T120 TI2 
T 
2T 
Fig. 2.15 Periodic rectangular wave. 

/Spectrallines 
Spectral envelope 
/~ ~'~/ 
/ 
""-
" /' 
"'...'" 
' 
I " 
/", 
I 
, 
o 
-1fT 
Fig. 2.16 Spectrum of a rectangular wave. 
Solution: Equation 2.24 gives 
1 IT12 
en = T 
rect(tlr) exp(-j27rntIT) dt 
-T12 
f 
1 [ -T12 
JT12 
= T r 
0 X exp(-j27rntIT) dt + 
1 x exp(-j27rntIT) dt 
J -T12 
-T12 
rr2 
] 
+ J 0 x exp(-j27rntlT) dt 
T/2 
1 T/2 
= TJ 
exp(-j27rntlT) dt 
-TI2 
_ ~ [eXp(-j27rntlT)] TI2 
- T 
-j27rnIT 
-T/2 
1 exp(-j7rnTIT) - expU7rnTIT) 
1 sin(7rnTlT) 
= T 
-j27rnIT 
= T 
7rniT 
_ 2. sin(7rnTIT) .1 2.. ( 
IT) 
- T (7rnTIT) 
= T smc 7rnT 
and the time signal may be expressed as 
x(t) = ~ 2.sinc(7rnTIT) expU27rntIT) 
n T 
The signal spectrum thus has the form shown in Fig. 2.16. 
(2.45) 
(2.46) 
With reference to the above example, notice from the spectrum of Fig. 2.16 that 
spectral lines occur at integer multiples of liT, the fundamental frequency, and 
that the strength (amplitude) of these lines is determined by the spectral envelope, 
which may be defined as 
Eif) = Tsinc(7r!T)IT 
(2.47) 
This coincides with Equation 2.46 at! = niT. It can be concluded that the general 
shape of the spectrum depends on the amplitude and width of the elemental pulse, 
rect(tlT), while the line structure is governed by the pulse repetition frequency, 
liT. 
39 

x(t) = x(t + T) 
Fig. 2.17 
Periodic triangular wave. 
Exercise 2.2 
Consider the periodic triangular wave signal x(t) shown in Fig. 2.17. 
Use is made of this result when 
sampling is studied in Chapter 5. 
It is possible to obtain a unified 
treatment encompassing the 
Fourier series and Fourier 
integral. Some care is needed, 
however, concerning 
convergence and it is generally 
mathematically more 
satisfactory to obtain the series 
from the integral. 
40 
(i) Suggest possible frequencies which may be expected to be identified in this signal if it 
were subjected to Fourier series analysis. 
(ii) Express x(t) as an exponential form Fourier series and calculate non-zero coefficients 
up to Inl = 5. Hence sketch the signal spectrum, X(f), over a corresponding frequency 
range. 
Spectrum of a Train of Narrow Pulses 
Consider now a periodic rectangular wave described by 
x(t) = ~ .!..rect[(t - nT)h] 
n 
7 
(2.48) 
Note in this instance the individual pulses have unit area whatever value of 7 < Tis 
adopted. Consider the spectrum as 7-t0; the sequence illustrated in Fig. 2.18 is 
obtained. As 7 -t 0 the individual spectral components, while preserving their 
frequency separation of liT, get closer and closer to all having the same strength. 
This limit case forms a useful approximation when dealing with a train of narrow 
pulses of large amplitude. 
Frequency Domain Representation of Aperiodic Signals 
It is possible to obtain a meaningful frequency domain representation for non-
periodic signals. However, such signals have continuous spectra since they have no 
well-defined period and thus do not generally give rise to discrete spectral lines. 
First consider pulse signals which are represented in the frequency domain by way 
of a Fourier integral or Fourier transform. (This is not examined in detail here but 
it is useful to consider in general terms the frequency domain representation for 
aperiodic signals.) Recall the periodic rectangular wave of Fig. 2.15 described by 
Equation 2.43 with spectrum as shown in Fig. 2.16. (For convenience the spectrum 
is normalized to unit amplitude at f = 0.) Letting T -t 0 while keeping 7 constant 
the line components, which are spaced IITapart, come closer and closer together. 
In the limit these lines may be thought of as merging together to form a continuous 
spectrum. 
As noted previously the envelope or overall shape of the spectrum is determined 
by the pulse width. Hence it is reasonable to assume that a rectangular pulse of 
width 7 has a continuous spectrum of the form shown in Fig. 2.19a. Notice that the 
signal is largely concentrated at low frequencies, If I < 117. We might reasonably 
expect, therefore, that a lowpass filter would transmit the signal relatively undis-

Spectral envelope 
sine (fT) 
",,-/1 
a 
b 
~ 
I 
I 
I 
o liT 
1 -
f 
72 < 7, 
-41T 
-21T 
0 
21T 
41T 
f 
-31T 
-liT 
liT 
31T 
------ -------------
1 -
--- ---
7--+0 ~ llT--+ 00 
- 21T_l IT 0 
1 IT 21T 31T 41T 51T 61T 
f 
c 
Fig. 2.18 Spectrum of rectangular wave of Equation 2.48, with unit area per 
pulse, for various values of pulse width 7. 
torted if the filter bandwidth B is rather greater than lIT, as suggested by 
Fig. 2.19b. One of the benefits of representing signals in the frequency domain is 
that it is rather easy to appreciate the influence of filtering operations on the signal 
spectrum. 
Fourier Transforms 
Consider a signal x(t) satisfying 
J 
~oo x2(t) dt < 00 
(2.49) 
Such a signal is said to have finite energy since if x(t) corresponds to the voltage 
across a 1 {)·resistor Equation 2.47 represents the energy dissipated. An example of 
a finite energy signal is the rectangular pulse rect(tln while a cosine wave or 
square wave provides an example of infinite energy but finite average power signal. 
The Fourier series provides a means of obtaining a frequency domain description 
41 

This form of the inverse Fourier 
transform differs from that given 
in some texts because we are 
making use of the frequency 
variable f rather than angular 
frequency. 
42 
a 
b 
-2IT 
-1IT 
-----, 
Filtered 
spectrum'\. 
\ 
o. 
o 
1/T 
21T 
Lowpass filter 
/response 
31T 
Signal components 
/ removed by filter 
... -------
f 
Fig. 2.19 Continuous spectrum and the influence of filtering viewed in the 
frequency domain. (a) Continuous'Sll~rrum of isolated rectangular pulse; 
(b) influence of lowpass filter. 
of finite average power periodic signals; a frequency domain representation for 
finite energy signals is provided by' the Fourier transform. 
Consider a finite energy signal x(t). Its Fourier transform X(f) is given by 
X(f) = C. x(t) exp(-j27rft) dt 
(2.50a) 
and x(t) may be obtained from X(f) by way of an inverse transform: 
x(t) = C, X(f) expU27rft) df 
(2.50b) 
Comparing Equation 2.50a, b with the expressions employed in obtaining a 
Fourier series expansion of a periodic signal it is noted that Equation 2.50a plays 
the same role as the expression for the Fourier coefficients while Equation 2.50b 
corresponds to the expression for a time function in terms of its coefficients. The 
essential difference is that instead of a discrete set of coefficients [en] giving rise to a 
discrete line spectrum Xd(f) for the periodic signal xiI) there is a continuum of 
coefficients encapsulated in the continuous spectrum Xc(f) for an aperiodic finite 
energy signal xc(t). The signal and its Fourier transform are intimately linked in 
that given one it is possible to find the other using the relations of Equation 2.50. 
To emphasize this one-to-one correspondence we refer to a Fourier transform pair, 
denoting this by way of a double-headed arrow: 
x(t) ~ X(f) 
(2.51) 

Many of the results which are derived earlier for Fourier series have their 
counterparts for the Fourier transform and a unified treatment is both possible, 
enlightening and practically useful. However, we shall not require more than a 
passing acquaintance with Fourier transforms. The topic has been introduced 
largely to suggest that the idea of representing signals alternatively in the time and 
frequency domains is of rather general application. Some illustrative examples 
suffice for our purposes. 
Find the Fourier transform of 
(i) a rectangular pulse located at the origin defined by: 
x(t) 
= rect(tIT) 
(ii) a rectangular pulse delayed by to defined by 
y(t) 
= x(t - to) = rect[(t - to)/T] 
Solution: (i) From Equation 2.50a: 
X(f) = rex> rect(tIT) exp(-j27rJt) dt 
TI2 
= r 
exp(-j27rJt) dt 
LT12 
= [exp( -j2 7rJt) ] TI2 
-j27rJ 
-TI2 
exp(-j7rfT) - exp( + j7rjT) 
-j27rJ 
1 exp( + j 7rjT) - exp( -j7rjT) 
= 7rJ 
2j 
= T sin(7rjT).1 
Tsinc(fT) 
7rfT 
(2.52) 
Notice that this is in broad agreement with the earlier intuitive argument based 
on increasing the period of a rectangular wavetrain. The result is illustrated in 
Fig. 2.20. 
(ii) Here 
tat f= o~ 
Zero at non-zero integer 
m"7~~ 
---=~~~----~~----+-----~----~~==~~--f 
o 
3fT 
Fig. 2.20 Spectrum of a unit amplitude isolated rectangular pulse. 
A precise and readable account 
of the unified treatment of 
Fourier theory is provided by 
Lighthill, M.J., An Introduction 
to Fourier Analysis and 
Generalised Functions, 
Cambridge University Press, 
1958. 
Worked Example 2.3 
43 

The Dirac delta function, named 
after P.A.M. Dirac, the physicist 
who introduced it in the context 
of quantum theory, is best 
thought of as the limit of a 
sequence of functions as 
illustrated below: 
44 
Y(j) = C. rect[(t - to)/T] exp(-j27rJt) dt 
= X(j) exp(-j27rJto) 
(2.53) 
The time delay to simply introduces a phase shift of - 27rJto which is linear with 
frequency; time translation corresponds to a linear phase shift in the frequency 
domain, just as for Fourier series. 
A Generalized Function and TransJorn:z 
The Fourier transform is an appropriate tool for dealing with finite energy signals, 
but it is not restricted to this class of functions. We will consider a very special 
exception, the Dirac delta Junction o(t), defined by: 
r.,. o(t) dt = 1 
o(t) 
= 0, t #= 0 
(2.54a) 
(2.54b) 
It is observed that this is a strange 'function' since it is zero everywhere except at 
t = 0 and its value at this point is not defined explicitly. Indeed, this is not a 
function in the usual sense; it is an example of a generalized Junction and is best 
defined for our purposes by a limiting operation such as 
lim 1 
o(t) = 
T rect(tIT) 
T-O 
(2.55) 
On the right-hand side there is, prior to taking the limit, a rectangular function of 
width T and height liT. The area is thus unity for all T> 0 so Equation 2.54a is 
satisfied. Now note that rect(tlT) = 0 for all It I > Tso as T-+ 0 Equation 2.54b is 
satisfied. With this perspective the delta function is seen as the limiting case of a 
sequence of rectangular pulses with successively larger amplitudes and smaller 
widths such that the area of each member function of the sequence is unity. 
Fig. 2.21 provides an illustration. 
Turning to the question of the Fourier transform of 0(1): the form of the defini-
tion of o(t) precludes direct computation of the transform. Instead a limiting 
o(t) 
1 
r-r- -
1 
:--- 2 reet (tlr) 
...____reet (t) -+ 
rect (2t) 
I 
1/ 
/treet( 
J 
j 
1 
I' 
4t) 
- 2 
-
- T/2 
T/2 
2 
o 
Fig. 2.21 
Sequence of unit area rectangular pulses converging to o(t) as T -+ O. 

Fig. 2.22 Sequence of sinc (jr) spectra converging to unity as T--+ O. 
argument based on Equation 2.55 is employed. For any given T> 0 the Fourier 
transform from Equation 2.52 can be obtained as 
~rect(tIT) :} sinc(fT) 
(2.56) 
If T--+ 0 the sinc(fT) function gets closer and closer to a constant value of 1, as 
indicated in Fig. 2.22. A delta function thus has a Fourier transform which is 
uniform over all frequencies: 
o(t) {:} 1 
Reciprocity and the Fourier Transform 
There is a simple reciprocity theorem which may be stated compactly as 
If 
g(t) {:} G(f) 
then 
G(t) {:} g(-f) 
We will not concern ourselves with a proof, but note two examples: 
(i) d. c. value: 
o(t) {:} 1 
:} 
1 
{:} o(t) 
(2.57) 
(2.58) 
(2.59) 
The Fourier transform of a d.c. component is represented by a delta function at the 
origin in the frequency domain. 
(ii) sinc( ) function and the ideallowpass filter: 
Having observed that a rectangular time domain pulse has a 'sinc function' 
spectrum, Equation 2.59 gives 
rect(tIT) {:} Tsinc(fT) 
:} 
sinc(t/T) {:} Trect(fT) 
(2.60) 
The function rect(fT) is an ideal lowpass function in that it is uniform for 
ifi < 112Tand zero for ifi > 112T. It is a useful approximate model for a lowpass 
filter. 
Filtering and the Fourier Transform 
The ideallowpass filter is often expressed in terms of a transfer function of the 
form 
H(f) = rectLf/(2B)] 
(2.61) 
45 

46 
Time domain 
Impulse 
Constant 
d.c. 
level 
Rectangular 
pulse 
t 
c5(t) 
o 
o 
.. 
.. 
.. 
Frequency domain 
.. 
o 
f 
t 
.. 
o 
f 
Constant 
spectrum 
Impulse 
spectrum 
~ 
Sinc function 
.JI\....,. .. spectrum 
o 
f 
Rectangular 
I I L 
(ideal lowpass) 
~ 
spectrum 
-
....... -+-----.J---J~_ 
o 
f 
Fig. 2.23 
Illustration of reciprocity for Fourier transform pairs. 
which is unity for ifi < B and zero for ifi > B. If a signal x(t) <=> X(f) is applied to 
the input of a lowpass filter the spectrum of the output signal y(t) <=> Y(f) is given 
by 
Y(f) = H(f)X(f) 
For an ideallowpass filter, then, 
Y(f) = rectlf/(2B)]X(f) 
Y(f) = [Xio (j) 
If I < B 
elsewhere 
(2.62) 
(2.63) 
As observed earlier, one of the features of frequency domain analysis is that it is 
particularly easy to accommodate filtering operations: filtering a signal corres-
ponds to multiplying the signal spectrum by the filter transfer function. This 
observation applies equally to periodic and aperiodic signals, the latter being 
characterized in the frequency domain by way of the Fourier transform. 
Frequency Domain Representation for Signals of Arbitrary Waveshape 
The Fourier series and integral are powerful tools in signal analysis but, in general, 
frequency domain representations are required for arbitrary signals. The foregoing 
should make it seem reasonable that a relatively arbitrary signal may have a mean-
ingful representation in the frequency domain. In particular, many signals have a 
lowpass spectrum, being concentrated at low frequencies ifi < B where B is the 
signal bandwidth. For example, audio signals are concentrated in the band 
ifi < 20 kHz and even if the range of frequencies is restricted to ifi < 3.4 kHz by 
using a lowpass filter it is found that speech is still perfectly intelligible. This latter 
observation is exploited in telephony. Television signals, on the other hand, while 
still being essentially 'Iowpass', occupy frequencies up to -5.5 MHz. It is found to 

-
-
____ L-______ ~---------L----~f 
-8 
o 
8 
Fig. 2.24 Bandlimited spectrum of an arbitrary lowpass signal. 
be convenient to represent such signals diagrammatically as illustrated in Fig. 2.24. 
Note, however, that it is not being suggested that the signal: spectrum has this 
precise shape -
only that it is of lowpass form concentrated in If! < B. 
There is a profoundly important point hidden in the above disCi:ussion, and it 
concerns the nature of the spectral characterization we can hope to obtain for 
information signals. It was found previously when dealing with deterministic 
signals that knowledge of the spectrum implied knowledge oJ the time domain 
signal. We stated this explicitly in terms of the Fourier transform pair; 
x(t) <=> X(f), but we observed a similar one-to-one coli1:espondence for Fourier 
series. How, then, can a spectral representation for an arbitrary information signal 
waveform such as a speech signal be obtained? If the spectrum were known it 
would be possible to reconstruct the time signal for all values of t. The sort of 
signals being considered have some degree of randomness associated with them, 
their precise future behaviour is not known. And yet certain characteristics of the 
signal, such as its mean power, may be known. For such a signal x(t) the appro-
priate spectral characterization is the power spectrum or power spectral density 
function, Sx(f). This indicates the concentration of signal power as a function of 
frequency. Power is a non-negative quantity so Sx(f) is a non-negative function; its 
integral over all frequencies is the total average signal power: 
Sx(f) > 0 for allf 
P = C. Sx(f) df 
(2.64) 
The influence of filtering on signals described by their power spectrum is of 
interest. Noting that a filter transfer function corresponds to a ratio of signal 
amplitudes and that power is proportional to (amplitude)2, we conclude that the 
power spectrum at the output of a filter with transfer function H(f) is given by 
So(f) = S,{f)IH(f)12 
and the total power is thus 
Po = C. So(f) df = roo S,{f)IH(f)12 df 
Amplitude Distribution of Signals 
(2.65) 
For a deterministic signal such as a cosine wave the time domain description is a 
47 

Notions of randomness and 
probability are at the very heart 
of the communication process. 
Prior to receiving a message we 
are uncertain as to its content: 
this uncertainty is reduced, 
ideally to zero, once we receive 
the message. 
48 
a 
b 
x(t) 
.. x 
Fig. 2.25 
(a) Continuous signal waveform and (b) amplitude distribution. 
precise characterization of the instantaneous variation of the amplitude of the 
signal; it indicates the amplitude of the signal for each value of the time variable t. 
For a randomly varying signal such as a speech waveform no such precise and 
complete description is possible. Nevertheless, it is generally useful (and often 
necessary) to have some sort of signal characterization relating to possible ampli-
tude values. This is provided by the amplitude distribution which is a measure of 
the relative frequency of occurrence of the various instantaneous values of the 
signal. The amplitude distribution of a signal x(t) is denoted by 
( ) _ lim fraction of time spent in dx 
p x -
dx"'O 
dx 
(2.66) 
where dxis an elemental interval centred onx. An illustrative signal waveform and 
its corresponding amplitude distribution is shown in Fig. 2.25. 
Given the amplitue distribution p(x), the fraction of time the amplitude of a 
signal x(t) lies within the interval (x)' x2) can be calculated as 
J
X, 
F(x) < x < xz) = 
p(x) dx 
XI 
(2.67) 
Note that the fraction of time a signal spends in an interval can never be negative 
and that the signal always has some finite amplitude, hence: 
p(x) ~ 0 for all x 
J ~ooP(X) dx = 1 
(2.68) 
An alternative interpretation of F(x) < x < x2) is that it measures the probability 
that a randomly selected sample of the signal x(t) falls within the interval (x)' x2). 
This probability can be obtained by integrating p(x) over the interval and p(x) is 
thus usually referred to as a probability density junction. 
The above description relates to continuous signals. Some modification is 
required for discontinuous signals which take on only certain discrete values. The 
amplitude distribution is then composed of discrete lines with weights correspond-
ing to the fraction of time the signal takes on the corresponding amplitude value. 
Fig. 2.26 provides an illustration. For the discrete case, P(y;) = fraction of time the 
signal spends at Yi and 
~P(y;) = 1 
(2.69) 
i 

a 
.. t 
b 
Ply,) 
y 
Fig. 2.26 (a) Discrete signal waveform and (b) amplitude distribution. 
Here the alternative probabilistic perspective is that P(y;) denotes the probability 
that the amplitude of a random sample of the signal waveform will be precisely y;. 
The preceding discussion of amplitude distributions is couched in terms of 
random signals but they can be applied to deterministic signals too. For example, 
the amplitude distributions for square, sawtooth and sine waves are illustrated in 
Fig. 2.27. The square wave takes on just two possible values and thus has a discrete 
distribution while the triangular and sine wave take on a continuum of values 
between -A and +A and so have continuous amplitude distributions. 
x(t) 
I J I 
.. 
t 
a 
x(t) 
p(xi) 
I~ 
0 
i 
-1 
0 
pIx) 
t 
.. x 
.. 
x 
-----.---+--~----~ 
o 
x 
Fig. 2.27 Illustrative waveform (left) and amplitude distribution (right). 
(a) Square wave; (b) sawtooth wave; (c) sinusoidal wave. 
49 

50 
Signal Power 
It has been shown previously that the average power in a signal may be obtained by 
integrating the power spectral density function over all frequencies; it can now be 
seen how it may be obtained from the probability density function. Assume for 
convenience that x(t) is a voltage waveform across a 1 () resistor. The instantaneous 
power dissipated in the resistor is xl(t) and the average power is found by averaging 
over all time: 
I. 
TI2 
-.:1 
1m 
J 
P = xl = 
T .... oo liT 
xl(t) dt 
-T12 
(2.70) 
Alternatively the average power may be calculated as 
(2.71) 
Equation 2.70 is referred to as a time-average and Equation 2.71 as a statistical 
average. The equivalence of these two expressions is not immediately apparent but 
may be appreciated as follows: Equation 2.70 indicates that power is the average of 
the square of the signal amplitude; in this instance a time-average is involved. On 
the other hand, the amplitude distribution measures the relative frequency with 
which the signal assumes the possible amplitude values and this is based on average 
behaviour over a long time interval. Hence, if the squares of all possible amplitude 
values are considered and added up weighted by their relative frequency of occur-
rence the result is equivalent to having calculated the time-average of the square of 
the signal. A specific example may help here: consider the sawtooth waveform of 
Fig. 2.27b. The signal has a well-defined period so the power can be calculated on 
the basis of a time-average without recourse to the limiting operation as 
TI2 
P = T1 J 
xl(t) dt 
-TI2 
1 JTI2 (Vt) 2 
=-
-
dt 
T -T/2 
T 
= ~( ;r [~L:: 
1 (V)2 P 
= T T IT = Vll12 
(2.72) 
Consider now the statistical approach: the signal amplitude is uniformly dis-
tributed on ( - VI2, VI2) and the probability density function is thus 
1 
P(x) = Vrect(xl V) 
(2.73) 
Equation 2.71 gives the signal power as 

1 VI2 
= -I 
.xl dx 
V -VI2 
= 1.[X3]V/2 
V 3 -VI2 
= Vl/12 as above. 
Summary 
In this chapter we have seen how various signals may be described analytically and 
how a complicated signal can often usefully be viewed as a combination of a large 
number of simpler signals. We introduced the concepts of the time domain and fre-
quency domain and showed how Fourier analysis provided a link between these 
two domains. In particular, the Fourier series was introduced and the exponential 
form emphasised. The idea of 'negative' and 'positive' frequency was discussed 
and graphical representations for signals in the frequency domain, ranging over 
negative and positive frequency, were introduced. The role of the Fourier trans-
form in providing a spectral description for aperiodic signals was noted briefly. 
The amplitude distribution was introduced as another useful characterization 
for a signal. Distributions were presented and we saw how the signal power may be 
calculated either as a time average in terms of the signal waveform or as a statistical 
average in terms of the signal amplitude distribution or probability density 
function. 
Problems 
2.1 Consider the signal element p(t) shown in Fig. 2.4b. This is used as the basis for 
binary data transmission with data Is represented by a pulse and Os by the 
absence of a pulse. Write down analytic expressions for the signal waveforms 
corresponding to the data sequence. 
10101101 
if the data rate is (i) 11 T bit! s, and (ii) 112 T bit! s. 
2.2 Consider the periodic signal x(t) = x(t + 1) defined by 
.. 
x(t) = 
~ rect[3(t - nn/T] 
n =-00 
(i) 
Sketch a representative segment of this waveform in the time domain. 
(ii) Express x(t) in terms of an exponential Fourier series and determine 
values for the coefficients enior Inl < 10. 
(iii) Hence sketch X(f) {::> x(t), showing clearly both the form of the spectral 
envelope and significant detailed structure. 
2.3 Let y(t) = x(t) - 113 where x(t) is as given in Problem 2.2. How does the 
spectrum Y(f) differ from X(f)? 
51 

52 
2.4 Consider an infinite train of unit impulses uniformly spaced in time by 
intervals T. 
(i) 
Sketch this signal in the time domain and write down a corresponding 
analytic expression. 
(ii) Deduce and sketch the form of the spectrum. 
(iii) Write down an analytic expression for the spectrum. 
[Hint: Consider the spectrum of a train of narrow unit area pulses as the pulse 
width is reduced.] 
2.5 Consider an isolated triangular pulse defined by 
x(t) = [b -ItllT 
It I < T 
elsewhere. 
(i) 
Sketch this signal in the time domain. 
(ii) Using the Fourier transform determine and sketch the corresponding 
Fourier spectrum. 
2.6 A signal with power spectral density 
SAf) = [b -lfllW 
Ifl<W 
elsewhere 
is passed through an ideallowpass filter. The filter bandwidth B is intended to 
be set to B = W but is inadvertently set to B = W12. Determine the resulting 
relative decrease in output signal power. 
2.7 A signal has a uniform amplitude distribution given by 
p(x) = [b/4 
Ixl<2 
elsewhere 
(i) 
What is the relative frequency with which x exceeds the value 1.5? 
(ii) What is the relative frequency with which x goes outside the range 
Ixl < 1.5? 
2.8 For a periodic signal the power spectrum looks very like the Fourier spectrum 
but the weights of the line components for the former are equal to the square of 
the corresponding weights for the latter. Confirm this by considering a sinu-
soidal signal as follows: 
(i) 
Obtain a Fourier spectrum representation. 
(ii) Obtain a power spectrum by squaring the weights obtained in (i). 
(iii) Add up the weights to obtain the total power in the signal. 
(iv) Check this against a result obtained directly using a time integral. 

Sinusoidal Carrier Modulation 
3 
o To describe how modulation enables a message to be matched to a band pass 
Objectives 
channel. 
o To show that amplitude modulation corresponds to multiplication of a 
message with a sinusoidal carrier. 
o To determine the spectral occupancy of various amplitude modulated signals 
(DSB-SC, SSB-SC, conventional envelope modulation) in terms of the 
carrier and message spectrum. 
o To explain how a message is recoverable from an AM signal using coherent 
detection. 
o To assess the influence of phase errors on coherent detection. 
o To show that angle (frequency or phase) modulation can be used to convey a 
message over a band pass channel. 
o To determine the spectral occupancy of a composite signal produced by 
frequency division mUltiplexing. 
Introduction 
The reader may be aware that radio systems generally use rather high frequencies. 
For example, the so-called 'citizen's band' is in the vicinity of 27 MHz. On the 
other hand, it has already been seen that speech signals are concentrated at 
relatively low frequencies, ifi < 20 kHz. How then can speech signals be conveyed 
over a radio channel? The answer is that a process called modulation is used to 
match the speech to the available communication channel. 
This process of modulation involves the variation of some parameter of one 
signal (the carrier) by another (the message), the result being a modulated carrier. 
The modulated carrier contains complete information about the message signal 
and the original message can be recovered by suitable signal processing. 
There are various forms of modulation. Consider a sinusoidal signal as the 
carrier: an information-bearing message signal can be impressed on to this by vary-
ing the amplitude, the frequency or the phase. All of these schemes are used, both 
separately and in combination. Only the basic methods are examined here, paying 
particular attention to the simplest, namely amplitude modulation. 
Amplitude Modulation 
There are various forms of amplitude modulation; only three are considered here: 
(i) double sideband suppressed carrier modulation, (ii) single sideband modula-
tion, and (iii) conventional (envelope) amplitude modulation. 
Double Sideband Suppressed Carrier Modulation 
Let m(t) = Amcoswmt represent a message signal and xc(t) = Accoswct a carrier, with 
This is just one example. For 
some purposes· radio systems 
use a carrier frequency as low 
as 15kHz while at the other 
extreme optical communication 
systems have carrier 
frequencies of the order of 
1014 Hz. 
53 

A multiplication process is at the 
heart of all amplitude modulation 
systems. 
Recall that this representation in 
terms of 'positive' and 
'negative' frequency 
components is largely a matter 
of mathematical convenience, a 
consequence of expansion in 
terms of complex exponentials. 
54 
Fig. 3.1 
Message -0--'x(t) = mIt) x (t) 
mW 
f 
. 
Carrier 
Xc (t) 
Double sideband s.uppressed carrier modulation. 
Fe» Fm. If the two signals are multiplied together as shown in Fig. 3.1, the follow-
ing is obtained: 
x(t) = m(t)xe(t) = AmcoswmtAecoswet 
= A~e [cos(we + wm)t + cos(we - wm)t] 
(3.1) 
This signal is concentrated in the vicinity of Fe and is composed of two terms known 
as sidebands. The term at (Fe + Fm) is the upper sideband and the term at (Fe - Fm) 
is the lower sideband. Notice that there is no component at the carrier frequency 
itself, hence the name double sideband-suppressed carrier (DSB-SC) modulation. 
The message information is carried in the sidebands. This modulation process can 
be interpreted in the frequency domain by writing the cosine waves in terms of 
phasors: 
x(t) - AmAe [exPU(We + wm)t] + exp[-j(we + wm)t] 
J 
-
4 
+ expU(we - wm)t] + exp[-j(we - wm)t] 
(3.2) 
This corresponds to a two-sided spectrum with positive frequency terms at 
(we + wm) and (we - wm) together with negative frequency terms at - (we + wm) and 
- (we - wm), as illustrated in Fig. 3.2. 
With reference to these diagrams, note that the positive frequency part of the 
modulated signal is of the same form as the message spectrum but is centred on 
J1\J 
mIt) = Amcoswmt 
(message) 
~W!!IWW~ 
~ r~vr~ r~ rr~ ~ 
~ 
xeltl = Aecoswet 
(carrier) 
x(t) = mltl xeltl 
(modulated carrier) 
... t 
.. t 
[ I [ 
.. , 
-FmO Fm 
(message spectrum) 
I 
--, 
-Fe 
0 
Fe 
(carrier spectrum) 
(modulated signal spectrum) 
Fig. 3.2 Time (left) and frequency (right) domain views of DSB-SC modulation. 

-W 
0 
W 
.f 
-Fe 
0 
Fe 
.. f 
x(t) 
I
X(f) 
--L..-u---+-------'-----t-o ---1U . 
-Fe -W 
-Fe +W 
0 
Fe- W 
Fe+ W 
-Fe 
Fe 
Fig. 3.3 
DSB-SC modulation for a general message signal. 
1= + Fc rather than 1= 0 and is scaled in amplitude by A/2. Similarly, the 
negative term is centred onl = - Fc. In essence, this modulation process has pro-
duced copies of the message spectrum atl = ± Fc' with an amplitude scaling factor 
A/2. This is just what is required to match message to a bandpass channel centred 
on III = Fc. The situation applies equally well to a more general message wave. 
Consider m(t) bandlimited to III < Wmodulatedon to a carrier xc(t) = Accoswct, as 
shown in Fig. 3.3. Note that the modulated signal is of bandpass form with band-
width 2W. 
This technique allows a message to be translated to a different region of 
frequency space for transmission over a bandpass channel. At the receiver it is 
necessary to be able to recover the message from the modulated signal; this can be 
achieved by a second multiplication process in combination with lowpass filtering. 
This message recovery process is called demodulation; a suitable receiver signal 
processing scheme is illustrated schematically in Fig. 3.4. 
To appreciate how this demodulation process operates, consider once more a 
DSB-SC signal for a cosine message: 
x(t) = AmcoswmtAccoswct 
xc(t) = Accoswct 
DSB-SC 
signal 
x(t) 
y(t) 
Carrier replica 
xe(t) = Ae coswet 
Lowpass 
filter 
zit) 
Recovered 
message 
Fig. 3.4 Demodulation of a DSB-SC signal. 
A multiplication process 
facilitates recovery of the 
message from an amplitude 
modulated signal. 
55 

56 
Fig. 3.5 
Demodulated DSB-SC signal. 
The output from the multiplier, y(t), is thus 
y(t) = x(t)xc(t) = (AmcoswmtAccoswct)Accoswct 
= AmAc2coswmt(coswct)2 
A2 
= Amcoswmt-t[1 + cos(2wct)] 
A2 
A2 
= -tAmcoswmt + Amcoswmt-tcos(2wct) 
.. f 
(3.3) 
The first term corresponds with the message m(t) = Amcoswmt scaled in amplitude 
by AH2 and the second to a DBS-SC signal centred on f = 2Fc. Hence the 
spectrum of y(t) , denoted as Y(f), has the form shown in Fig. 3.5. 
The output spectrum is the product of Y(f) and the filter transfer function H(f). 
With H(f) corresponding to an 'ideal' lowpass filter only the (scaled) message 
signal appears at the output: 
(3.4) 
Once again, this result holds also for a general message spectrum, as illustrated in 
Fig. 3.6. 
Exercise 3.1 
An audio signal occupies the frequency range 30 Hz < If I < 15 kHz. This signal is to be con-
veyed using DSB-SC amplitude modulation over a bandpass channel which transmits 
signals in the range 90 kHz to 120 kHz'. Determine a suitable carrier frequency to match the 
audio signal to this channel. 
Influence of carrier phase. The availability at the receiver of a replica of the carrier 
to facilitate demodulation has been assumed. In practice this must be derived from 
the incoming DSB-SC signal - not a trivial task since the carrier is 'suppressed'. In 
fact, deriving a signal of the right frequency is not too difficult but this is not suffi-
cient; it must also have the correct phase as shall be seen. 
Consider the DSB-SC signal m(t)coswct and a local carrier given by 
C:J 
[:J 
.. f 
-w 
0 
W 
Fig. 3.6 Demodulation of a general DSB-SC signal. 

cos(Wct + e/» where e/> is the phase error. With reference to Fig. 3.4 the output from 
the multiplier is then 
y(t) = [m(t)coswJ] 
cos(wJ + e/» 
DSB-SC 
carrier replica 
signal 
with phase error e/> 
= mit) [cose/> + cos(2wJ + e/»} 
= mit) cose/> + my) cos(2wJ + e/» 
(3.5) 
The first term is a message scaled in amplitude by a factor of (cose/»12 while the 
second term corresponds to a DSB-SC signal in the vicinity of 2Fc• The special case 
of e/> = 0 (no phase error) has already been considered; now consider e/> = 7r12. In 
this case cose/> = COS7r12 = 0 and there is no component in the output correspond-
ing to the message; we simply have 
y(t) = mit) cos(2wct + 7r12) 
(3.6) 
That is, a DSB-SC signal in the vicinity of 2Fc• We conclude that the phase of the 
carrier reinserted at the receiver is of crucial importance. All this suggests that a 
rather complex receiver structure may be required if DSB-SC modulation is 
employed. It is appr<;>priate, therefore, to consider other possible modulation 
formats which may offer the possibility of simpler receiver structures, or perhaps 
other advantages. 
The DSB-SC signal is 
susceptible to carrier phase 
errors on demodulation. 
Coherent detection of a DSB-SC signal is performed with a local oscillator, the phase of 
Exercise 3.2 
which varies by ± 10° about the optimum value. Deduce the resultant variation in the 
amplitude of the demodulated message. 
Single Sideband Modulation 
The modulation process described previously provides two complete copies of the 
message spectrum, one at + Fc and one at - Fc' and both the positive and negative 
frequency parts of the message spectrum are preserved in each replication. As we 
shall see, this is redundant. It suffices to translate the positive part to the vicinity 
of + Fc and the negative part to - Fc. We can establish this by considering the 
simple message signal 
m(t) = Amcoswmt 
and a cosinusoidal carrier 
xc(t) = Accoswcf 
DSB-SC modulation gives a spectrum as shown in Fig. 3.7. 
I , I 
I , I .. f 
o 
Fig. 3.7 A DSB-SC signal. 
57 

This is the simplest and perhaps 
the most widely used of three 
basic methods for generating 
SS8-SC signals. 
58 
-------, 
I 
I 
I 
I 
I 
I 
I 
I 
o 
r------
I 
I 
.. f 
Fig. 3.8 A single sideband signal obtained by filtering a DSB-SC signal. 
If this signal is passed through a high pass filter which rejects all components 
If I < Fe and passes all components If I > Fe a signal is obtained with spectrum as 
shown in Fig. 3.8. 
This signal corresponds to two contra-rotating phasors atf = ± (Fc + Fm) and may 
be expressed analytically as 
y(t) = Ac~m [ exp[-j(wc + wm)t] + expU(wc + wm)t] J 
(3.7) 
negative 
positive 
frequency 
frequency 
part 
part 
Considering now a more general message signal, we have the situation in 
Fig. 3.9. The signal is of bandlimited form with bandwidth W, one-half the band-
width required for DSB-SC modulation. The SSB signal format is said to be 
spectrally efficient. 
It must now be shown that the message is recoverable from this SSB signal. To do 
this consider the cosine modulation case, for which the SSB signal corresponds to a 
cosine wave with a frequency of (Fe + Fm). We can use the same demodulation 
process as for DSB-SC, which involves multiplication by a replica of the carrier 
followed by lowpass filtering; thus 
A 2A 
SSB signal x(t) = ~cos(wc + wm)t 
Carrier replica xc(t) = Accoswct 
A2A 
y(t) = x(t)xc(t) = 2cos(wc + wm)tcoswct 
= Ac~Am [ coswmt + cos(2wc + wm)t J 
(3.8) 
Again the first term corresponds to the message, which can be separated from the 
term at (2wc + wm) by lowpass filtering. 
-------1 
N /-
1 .... -
I 
-
I 
I 
I 
I 
r-------
["",h 
-
., 
o 
Fig. 3.9 Single sideband modulation, general message spectrum. 

Note that SSB is rather more tolerant with respect to phase errors in the 
reinserted carrier than is DSB-SC. Here a carrier error cp simply results in a similar 
phase shift in the demodulated message component -
the amplitude remains 
unchanged. Some message signals, including speech, are unimpaired by such phase 
shifts; this can allow a significant reduction in receiver complexity. 
Assuming a sinusoidal message, determine the influence of a phase error cp on 
Worked Example 3.1 
demodulation of an SB-SC signal. 
Solution: The carrier replica is now xc(t) = Accos(2'llFJ + cp); hence 
and lowpass filtering gives 
(3.9) 
The recovered message is thus phase shifted by cp. 
Conventional (Envelope) Amplitude Modulation 
The two previous modulation schemes require that a replica of the carrier be avail-
able at the receiver to enable the message signal to be recovered. This complication 
is avoided in conventional amplitude modulation (AM) systems by making the 
carrier envelope the information-bearing parameter. The modulation process is 
again based on multiplication but a d.c. component is added to the message prior to 
modulation to render the signal (message + d.c. component) non-negative. The 
envelope of the modulated carrier then has the same shape as the message; the 
principle is illustrated in Fig. 3.10. 
a 
v · 
-w 0 W 
.. f 
b 
.. f 
-W 0 W 
c 
Fig. 3.10 Conventional amplitude modulation. (a) Message m(t), Im(t)1 < 1; 
(b) message + d.c. term, 1 + m(t); (c) envelope modulated signal, 
x(t) = [1 + m(t)]AccoswJ. 
59 

The simplicity of the receiver for 
envelope AM is the feature 
which resulted in its universal 
adoption for commercial AM 
broadcasting. 
60 
I 
L ___ , 
-Fe 
0 
F. 
N1 
I 
N1 
.. f 
-Fe -
W -Fe -Fe + W 
0 
Fe -
W 
F,. F, -+ W 
Ih 
I 
Ih .. f 
-F -
W 
-F + W 
C 
-Fe 
C 
0 
Fe -
W F. F,'-+ W 
Fig. 3.11 
Conventional amplitude modulation, spectral representation. 
(a) Unmodulated carrier; (b) DSB-SC component; (c) envelope modulated 
signal spectrum. 
To examine this process in the frequency domain, consider m(t) = Amcoswmt with 
IAml< 1: 
x(t) = [1 + AmcoswmtJAccoswct 
= Accoswct + AmcoswmtAccoswct 
(3.10) 
The first term is simply an unmodulated carrier while the second corresponds to a 
DSB-SC modulated signal. The spectrum is thus the sum of the spectra for each of 
these signals. This result applies also for a general message as illustrated in 
Fig. 3.11. The modulated signal spectrum is of bandpass form with bandwidth 
2W. 
The unmodulated carrier being independent of the message conveys no informa-
tion. It thus constitutes 'wasted' power, so that conventional amplitude modula-
tion makes rather inefficient use of the power available at the transmitter. On the 
other hand, it does provide for very simple (and hence inexpensive) receivers; it is 
amenable to envelope detection for which no replica of the carrier is required. 
Envelope detection. A simple envelope detector is shown in Fig. 3.12. Assuming 
the diode to be ideal only the positive halves of the modulated carrier appear at the 
input to the lowpass filter. This signal is non-negative: it contains a d.c. compo-
AM signal 
K4A~nn.,,-,( • 
,y. {VlJP-
Rectified AM signal 
''tCiWkll'6 
/ 
Lowpass 
Filter 
Fig. 3.12 Envelope detection. 
Recovered 
message 
~ 

nent, a relatively slowly varying component corresponding to the message m(t) and 
high frequency terms in the vicinity of the carrier frequency Fc and its harmonics. 
Only the d.c. and low frequency components are passed by the lowpass filter 
whereby the message m(t) is recovered. (The d.c. term is readily removed by a.c. 
coupling.) This method of signal recovery is known as envelope detection. 
Considering 'envelope' modulation and a sinusoidal message with Am = 1, deter-
Worked Example 3.2 
mine the fraction of the transmitted power 'wasted' in the carrier. 
Solution: From Equation 3,10 
x(t) = (1 + coswmt)Accoswct 
= Accoswct + ~CCOS(wc + wm)t + ~CCOS(wc - wm)t 
For a sum of sine waves with different frequencies the total power is the sum of the 
powers in each term, giving 
x2(t) _ 
Ac2 
-
2 
+ 
A2 
_c 
4 
carrier 
sideband 
power 
power 
Hence 213 of the transmitted power is 'wasted'. 
Angle Modulation 
(3.11) 
As an alternative to varying the amplitude of a carrier, its frequency or phase can 
be varied; both of these come under the general heading of angle modulation. This 
can have advantages in certain circumstances. For example, an angle modulated 
signal has a constant envelope which can result in more efficient use being made of 
the peak power capability of the transmitter. A detailed discussion is outside the 
scope of this text but frequency modulation (FM) is examined briefly here in view 
of its widespread use. 
Frequency Modulation 
In frequency modulation the carrier frequency is made to vary instantaneously in 
sympathy with the message. The instantaneous frequency Fi is given by: 
Fi = Fc + Krffl(t) 
where Kf is a modulation constant which determines the peak deviation of the 
carrier from its centre frequency Fc. A frequency modulated wave is illustrated in 
Fig. 3.13. 
The FM signal is not amenable to simple analysis so the spectrum is not derived 
here. However, the bandwidth ofthe modulated signal can be estimated as follows: 
61 

It is the ability of FM to provide 
very high quality transmission 
which has resulted in its 
widespread use for high-fidelity 
(Hi-Fi) and stereophonic 
broadcasting. The spectral 
inefficiency dictates the use of 
very high carrier frequencies 
(e.g. VHF in the region of 
100 MHz in the UK). 
Exercise 3.3 
The most widely adopted 
demodulation scheme makes 
use of a phase-locked loo.p, a 
circuit of widespread application 
in communication systems. It is 
discussed briefly in Chapter 4 
and more fully in Gardner, F.M., 
Phase Lock Techniques, Wiley, 
1966. 
62 
a 
b 
c 
Fig.3.13 Frequency modulation process. (a) Message; (b) unmodulated 
carrier; (c) frequency modulated signal. 
if Fd is the peak frequency deviation then the instantaneous frequency varies 
between Fe - Fd and Fe + Fd. This suggests that a transmission bandwidth B of the 
order of 2Fd may be required for a channel to pass the FM signal. But this is 
independent ofthe bandwidth of the message -
an unlikely result. In fact, it trans-
pires that the bandwidth is not independent of the message but is given approxi-
mately by 
B=2Fd +2W 
(3.12) 
Many systems employ Fd» W and the FM bandwidth requirement can exceed 
considerably that for AM. Hence FM is not spectrally efficient. However, if the 
required bandwidth is available, FM has the capability to provide a very high 
quality transmission system (e.g. FM broadcasting) although we cannot go into the 
details of this here. 
The FM broadcasting system adopted in the United Kingdom employs a frequency deviation 
of ± 75 kHz. The message bandwidth is 15 kHz for monophonic transmission and 53 kHz 
for stereo. Determine the approximate bandpass channel bandwidth required in each case. 
Compare this with the bandwidth requirements for DSB-SC. 
Considering now demodulation, a particularly simple scheme makes use of a 
frequency selective network such that the frequency variations give rise also to 
amplitude variations. The message can then be recovered by using an envelope 
detector. This scheme is illustrated schematically in Fig. 3.14 and may be appre-
ciated as follows: when the input signal instantaneous frequency is low, say f = f(, 
the output from the frequency selective network is small. On the other hand, if the 
input instantaneous frequency is high, f = f2' the output is large. As the instan-
taneous frequency varies between these extremes, in sympathy with the message, so 
the amplitude of the output varies giving rise to 'envelope' modulation. The 
message may now be recovered using an envelope detector. This detection scheme 
for frequency modulation is known as slope detection. Other methods of FM 
detection are available; however, the above should suffice to allow the principle of 
frequency modulation and demodulation to be appreciated. 
Frequency Division Multiplexing 
Frequently it is desired to combine several messages into a composite signal for 

" - " 
f; - f2 
FM 
signal 
~ 
'----1-----1-__+, 
" 
'2 
Frequency 
Envelope 
modulated 
selective 
Vo 
network 
FMsignal 
Envelope 
Lowpass 
detector r--
filter 
Fig.3.14 Slope detection of FM signal. 
transmission over a single communication channel. This is the case, for example, 
with intercontinental communication for which many telephone conversations are 
combined and then transmitted via a submarine cable or a communications satel-
lite. This can be achieved with the aid of frequency division multiplexing (FDM). 
The various messages are amplitude modulated on to different carrier frequencies 
and the modulated signals are added together to form a composite message signal. 
Provided the carrier separation is sufficient to ensure that there is no spectral over-
lap of the sidebands of one signal with those of another the messages can be 
separated at the receiver by bandpass filtering. They can then be demodulated in 
the usual way. Any of the forms of amplitude modulation mentioned can be 
employed in principle but often power economy dictates that a supressed carrier 
(DSB-SC or SSB-SC) scheme be adopted. 
In the interests of bandwidth economy SSB-SC is preferred. The principle is 
illustrated in Fig. 3.15 using a single-sided spectral representation. The channel 
.. , 
a 
r-----., 
cJcJicJicJ 
... , 
b 
.. , 
c 
Fig. 3.15 
Frequency division multiplexing/demultiplexing. (a) Representative 
message signal spectrum; (b) composite FDM signal spectrum; (c) separated 
channel, ready for demodulation. 
r--- Recovered 
message 
63 

Telephone speech is 
concentrated in the band 
300 Hz to 3.4 kHz. To allow for 
finite cut-off filters, however, a 
nominal channel allocation of 0 
to 4 kHz is usually assumed, 
leading to a 4 kHz channel 
spacing in an FDM assembly. 
64 
spacing is slightly greater than the message information bandwidth Wto facilitate 
channel separation filtering at the receiver. Once an individual SSB channel signal 
has been separated, demodulation in the usual way allows the message to be 
recovered. 
Quite complex multiplexing and modulation formats are encountered in 
practical telecommunication systems. For example, the CCITT (Consultative 
Committee of the International Telecommunications Union -
an international 
advisory body) recommend an FDM hierarchy for teiephony as shown in Table 
3.1. This structure allows telephone calls to be combined in blocks of appropriate 
sizes for transmission through a national or international telecommunications 
network. 
Table 3.1 CCITT FDM Hierarchy 
Channel 
Group 
Supergroup 
Mastergroup 
Supermastergroup 
5 groups 
5 supergroups 
3 mastergroups 
1 channel (4 kHz) 
12 channels (48 kHz) 
60 channels (240 kHz) 
300 channels (1.2 MHz) 
900 channels (3.6 MHz) 
When considering the transmission of information through networks we often 
refer to traffic flowing through, or carried by, the network in analogy with 
vehicular traffic flowing along roads. One of the attributes of multiplexing is that it 
enables us to combine traffic (e.g. telephone calls) into suitably sized units for effi-
cient and economic transmission. 
It should be noted that an FDM signal may be subjected to further modulation 
processes in transmission. For example, it is not uncommon to combine several 
telephone channels using FDM based on SSB-SC modulation and then to use 
frequency modulation to transmit this composite signal over a radio or satellite 
link. 
Summary 
It has been shown that by the process of modulation a message signal can be 
translated in frequency space and thereby rendered compatible with a bandpass 
channel. The original message may be recovered by a related process, demodula-
tion. Specifically, amplitude modulation schemes have been examined in some 
detail and we have noted that the fundamental process is that of multiplication; 
amplitude modulation is achieved by multiplying a message by a sinusoidal carrier 
and, in the case of SSB, by filtering the resultant signal. Demodulation involves 
similar processes; mUltiplication of the modulated signal by a carrier replica and 
lowpass filtering. Other schemes, such as frequency and phase modulation, have 
been mentioned only briefly. 
The purpose of all modulation schemes is to render the message compatible 
with the available channel. This is especially important when a large number 
of messages need to be transmitted simultaneously. We have seen that by modu-
lating the several messages on to different carriers it is possible to form a com-
posite signal for transmission in which the constituents are kept separate in 

frequency space. This process, known as frequency division mUltiplexing, is in 
widespread use. It is employed, for example, in long distance telephony for which 
messages are combined in accordance with CCITT guidelines. Also, albeit in a 
rather less structured way, it is essentially what is involved in broadcast radio. The 
various stations are allocated different 'frequencies' to allow them to be received 
separately. 
Finally, we note that in this chapter we have assumed the use of a sinusoidal 
carrier. While this is certainly commonplace it is by no means universal. There are, 
as is seen later, various forms of pulse modulation which have a part to play in tele-
communication systems. 
Problems 
3.1 Consider conventional amplitude modulation of a sinusoidal carrier xc(t) with 
a sinusoidal message m(t): 
Determine the fraction of the total transmitted power concentrated in 
the modulation sidebands for (i) Am = Ac; (ii) Am = A/2; (iii) Am = aAc; 
lal < 1. 
For a speech message it is generally required that the r.m.s. value of the 
message must not exceed about one-tenth of the peak carrier value. Assuming 
that the same general behaviour noted above for sinusoidal messages holds 
also for the more complex speech signal, estimate the fraction of the trans-
mitted power concentrated in the message sidebands for speech modulation at 
the level suggested. 
3.2 Show that amplitude modulation of a sinusoidal carrier, be it DSB, SSB or 
envelope modulation, is a linear modulation scheme. Consider the message 
signal as the input to a modulation process and the modulated signal as the 
output and recall that a system is linear if the following two conditions 
hold: 
Proportionality 
input --+ output 
:} ax--+ ay 
Superposition 
XI 
--+ YI 
X2 
--+ 12 
:} XI + x2 --+ YI + 12 
a is scalar 
3.3 By considering a sinusoidal message Amcoswmt examine the influence of a local 
oscillator frequency error at the receiver for the detection of (i) a DSB-SC 
signal, and (ii) an SSB-SC signal. 
Hence suggest why for some signals, such as speech, SSB-SC may be subjec-
tively more tolerant to frequency errors than is DSB-SC. 
3.4 Twelve speech signals are to be combined using frequency division multiplex-
ing for transmission over a wideband radio link. Each signal is concentrated in 
300 Hz < If I < 3.4 kHz and is allocated a nominallowpass channel bandwidth 
65 

66 
of 4 kHz to allow for the use of practical filters with finite transition regions. 
Estimate the radio bandwidth required if the signals are combined using 
SSB-SC frequency division multiplexing and the radio receiver employs 
conventional (envelope) amplitude modulation. 

Radio Receiver Principles 
4 
D To introduce the concept of selectivity. 
Objectives 
D To explain the principle of a tuned radio frequency (TRF) receiver. 
D To explain the principle of the superheterodyne (superhet) receiver. 
D To introduce and distinguish between adjacent channel and image rejection. 
D To note the criteria influencing selection of the intermediate frequency for a 
superhet receiver. 
D To note briefly the double conversion receiver principle. 
D To describe the principle of automatic frequency control (AFC). 
In the previous chapter it was explained how it is possible to modulate a carrier with 
a message and subsequently to recover the message from the modulate carrier. In a 
radio system, the modulation process is performed at the transmitter, and the 
modulated signal is then amplified and broadcast as a radio signal- a propagating 
electromagnetic wave field. At the receiver this signal is picked up by a receiving 
aerial or antenna and it is the task of the radio receiver to process this signal so that 
it can be applied to a demodulator for message recovery. The details of radio pro-
pagation and the physical mechanism whereby an aerial can pick up the radio 
signal are not dealt with here. Receiver system principles and the associated signal 
processing operations are considered. 
It should be noted first that radio communication involves a form of frequency 
division multiplexing in that different radio channels in a given geographical 
location use separate carrier frequencies. These carriers are sufficiently well 
separated in frequency to ensure that, with the aid of a tuned circuit, a receiver can 
be adjusted (tuned) to pass the carrier and modulation sidebands of a wanted 
signal while rejecting substantially the unwanted signals. 
A simple radio receiver employs a single tuned circuit for channel selection; the 
Worked Example 4.1 
relative response is given approximately by 
IH(f)i2 = 1 + (f ~ fo)2 / B2 
(4.1) 
wherefo = centre frequency and B = - 3 dB bandwidth. If two equally strong, co-
located stations transmit atfo and atf! = fo + 7B, determine the ratio at the input 
to the demodulator of the wanted signal to interference power, expressed in 
decibels. 
Solution: The ratio of the wanted signal to interference power after filtering is 
given by 
P wanted 
IH(fo)12 
Pinterferenee 
IH(f!)12 
(4.2) 
Note the use of IH(f)12 because 
we are interested in the power 
which is ~roportional to 
(voltage) . 
67 

= 1 + ([1 - fo)21B2 
= 1 + (7B)2!B2 = 50 
= 10 IOglO(50) == 17 dB 
This would require an ideal 
bandpass filter. 
One of the tasks of a radio receiver is to effect this selection of the wanted from 
the unwanted signals. A useful measure of the selectivity of a receiver is provided 
by the ratio of the bandwidth at different levels on the relative response curve. 
The - 40 dB to - 3 dB bandwidth ratio is often considered, for example. Note that 
a large ratio implies poor selectivity, as illustrated in Fig. 4.1. An ideal receiver 
would have a selectivity ratio of unity. 
68 
Relative response (dB) 
-
3 dB bandwidth 
a 
----~===4~=t==~==~-----f 
Fig. 4.1 
Low (a) and high (b) selectivity receivers. 
Exercise 4.1 
Determine the selectivity ratio for the receiver of Worked Example 4.1. 
Amplification of the radio frequency signal -
RF amplification -
is also usually 
required since the received signal can be of rather low amplitude. The amount of 
RF amplification required depends on the strength of the received signal which in 
turn depends on the distance of the receiver from the transmitter and on the effec-
tiveness of the receiving aerial. To allow for variations in signal strength a variable 
gain amplifier is employed in conjunction with an automatic feedback loop. This 
automatic gain control (AGC) system acts to keep the signal at the input to the 
demodulator at a suitable predetermined average level. 
Worked Example 4.2 
Consider a line-of-sight radio system in which a receiver is required to operate satis-
factorily at distances from the transmitter varying from 1 km to 100 km. Estimate 
the AGC range required, expressing this in dB. 
Solution: Since power density at the receiver varies with the square of the distance 
from the transmitter the ratio of the received powers is given by 
P(dooD} = (dmax ) 2 
p(dmax> 
dOOn 
(4.3) 
where dmin and dmax are the minimum and maximum transmitter-receiver distances 
and P(dooJ, P(dmax} are the corresponding received signal powers. 

Here: 
P(1 km) = (100)2 = 1()4 
P(100 km) 
1 
:; 10 10glO(1()4) = 40 dB 
The AGe system must thus have a dynamic range, defined as the difference 
between the maximum and minimum gains expressed in dB, of at least 40 dB. 
There are thus three main signal processing operations to be performed prior to 
demodulation: filtering for channel selection; amplification to ensure an adequate 
signal; and AGe to ensure a constant signal level at the input to the demodulator 
for a wide range of received signal strengths. Attention can now be turned to 
possible receiver structures which can provide these features. 
Tuned Radio Frequency (TRF) Receiver 
The simplest radio receivers are based directly on the three processes noted above. 
An RF amplifier provides both gain and, by the inclusion of tuned circuits, 
frequency selectivity. The output from the RF amplifier is then applied to a 
demodulator. Level adjustment may be provided by an AGe loop which varies the 
gain of the RF amplifier in accordance with the detected signal level at the output of 
the demodulator. Such a receiver is shown schematically in Fig. 4.2, where for the 
sake of definiteness envelope amplitude modulation has been assumed. This is a 
very simple receiver (so much so that the AGe loop may well be omitted and signal 
level adjustments effected manually) but it is not widely used. The main reason for 
this is that the tuned circuits in the various stages of the RF amplifier must remain 
properly aligned with one another as we tune the receiver over its operating range in 
order to select different frequency transmissions. This is generally achieved with 
the aid of a ganged capacitor, which is actually several variable capacitors all 
sharing a common control shaft. This becomes increasingly inconvenient as more 
stages are incorporated to improve selectivity or provide increased gain and in 
practice there is a limit to the number of stages which can be kept in step in this way. 
TRF receivers thus tend to provide rather poor selectivity. 
Radio 
TRF 
amplifier 
Envelope Audio amplifier 
detector 
and loudspeaker 
Fig. 4.2 TRF receiver. 
Broadly similar tracking 
problems arise with 
electronically tuned receivers 
based on voltage-variable 
capacitance diodes if many 
stages are involved. 
69 

70 
Superheterodyne (Superhet) Receivers 
Most practical radio receivers employ the superheterodyne principle in which the 
incoming signal centred on Fe is translated (or converted) in frequency to a fixed 
intermediatefrequency (IF) band. The necessary frequency translation of the input 
signal is achieved by multiplication in the time domain by a fixed amplitude sinu-
soidal signal with frequency FLO offset from the carrier by an amount FIF. This is 
illustrated schematically in Fig. 4.3. The principle may be appreciated as follows: 
Consider, by way of example, a DSB-SC signal: 
x(t) = m(t) cos(2'l1Fet) 
(4.4) 
multiplied by a constant amplitude sinusoid provided by an oscillator within the 
receiver, known as a local oscillator: 
xLO(t) = A COS(2'l1FLOt) 
The output from the multiplier is given by 
y(t) = m(t) cos(2'l1Fet)A cos(2nFLOt) 
Am(t) 
= -2-[cos[27["(Fe + FLO)t] + cos[27["(Fe - FLO]t] 
A 
A 
= m(t)Tcos[27["(Fe + FLO)t] + m(t)T cos(27["FIFt) 
= DSB-SC signal 
centre on 
f= Fe + FLO 
+ 
DSB-SC signal 
centred on 
f = FIF = /Fe - FLOI 
(4.5) 
(4.6) 
If this signal is applied to a multi-stage bandpass amplifier with a response centred 
on the fixed intermediate frequency IFe - FLOI, the terms centred on IFc + FLOI are 
heavily attenuated while the terms at FIF = IFe - FLOI are amplified. The output 
from the bandpass amplifier is thus 
(4.7) 
where B represents the voltage gain of the IF amplifier, and this signal can be 
demodulated as discussed in Chapter 3. 
The frequency conversion process does not require a perfect multiplier; it is 
Input frequency 
F, 
Local oscillator 
frequency = FLO 
Mixing terms 
at I F, + FLO I, I Fe -
FLO I 
Bandpass 
filter 
F'F 
Fig. 4.3 
Superheterodyne principle. 
Output frequency 
F'F = I Fe -
FLO I 

sufficient for the modulated carrier and local oscillator signals to be combined in a 
suitable non-linear manner to produce the required sum and difference frequency 
components. The circuit is generally referred to as a mixer. To illustrate this we 
consider a square-law device operating on xe(t) + xLO(t) with output y(t) given by 
y(t) = [xe(t) + xLO(t)]2 
= [m(t)COS(2'IIFet) + Acos(27rFLOt)]2 
= m2(t)cos2(27rFet) + A2cos2(27rFLOt) + 2m(t)Acos(27rFet)cos(27rFLOt) 
1 
= m2(t)I[1 + cos(47rFJ)] 
1 
+ A2I [1 + cos(47rFLOt)] 
+ m(t)Acos[27r(Fe ± FLO)t] 
(4.8) 
The first term contains components at baseband and at 2Fe which are not passed 
by the bandpass IF stage. The second term contains a d.c. component and a 
component at 2Fe; these are similarly rejected by the IF filter. The final term con-
tains sum and difference frequency components centred on lFe + FLOI and on 
IFe - FLOI = F IP, as obtained previously with a true multiplier. 
Although we have considered explicitly only DSB-SC signals, the same results 
hold for other modulation schemes: the output from the IF stage is a modulated 
signal (DBS-SC, envelope AM, FM, and so on) with effective carrier frequency 
FIP' 
Adjacent Channel Rejection 
The primary advantage of the superheterodyne principle is that it provides for high 
gain and selectivity in the IF amplifier. Adjacent radio channels close to Fe' say at 
Fe ± b.F, give rise to components at the output of the mixer centred on F IP ± b.F. 
Provided the response of the IF amplifier is sufficiently small at frequencies ± b.F 
removed from the centre frequency FIP these unwanted adjacent channel signals are 
strongly attenuated. The selectivity of the IF stage thus controls the adjacent 
channel rejection capability of the receiver. Since the IF amplifier operates at a 
fixed frequency band sophisticated multiple-tuned circuits or other highly selective 
filtering techniques can be readily incorporated. It is not necessary for the various 
sections of the IF amplifier to be able to track one another as the receiver is tuned 
since this is accomplished simply by adjusting the local oscillator such that the 
difference between the carrier frequency Fe and the local oscillator frequency FLO 
corresponds to the fixed IF frequency FIP' 
Image Channel Rejection 
Here it is noted that IFe - FLOI = FIP admits two possible values for Fe, namely 
Fel = FLO + FIP 
Fc2 = FLO - F IP 
(4.9) 
Hence, if the receiver is tuned to Fel and there is also a radio signal with frequency 
F c2 present at the receiver input then both of these signals are converted down to the 
IF band where they are amplified and passed to the demodulator. The unwanted 
component is referred to as an image signal and the image rejection of the receiver 
depends on the RF response prior to the mixer. A tuned RF amplifier is often 
Note that other non-linearities 
may also be employed with 
broadly similar results. 
71 

72 
Relative 
response 
--~--------~--~----L-~~--_f 
F, 
Fig. 4.4 Image response. 
incorporated to provide a degree of image rejection. This amplifier has a centre 
frequency which is offset from the local oscillator by F',.F and is variable in step 
with the local oscillator by way of a ganged capacitor. The image frequency is given 
by 
Fe + 2FIF 
if 
Fimage = Fe -
2FIF 
(4.10) 
The problem of image rejection is illustrated in Fig. 4.4, from which it can be seen 
that the image response is reduced if the IF frequency is increased since Fimage is then 
further removed from the main peak of the RF response. 
Worked Example 4.3 
A superheterodyne receiver, tuned to receive an AM broadcast signal at 1 MHz, 
employs a single tuned circuit RF amplifier with bandwidth BRF = 100 kHz and an 
IF amplifier centred on 455 kHz. The local oscillator is set on the high side of the 
carrier. Determine (i) the local oscillator frequency; (ii) the image frequency; and 
(iii) the image rejection. 
Solution: 
(i) FLO = Fe + FIF = 1 MHz + 455 kHz = 1.455 MHz 
(ii) Fimage = Fe + 2FIF = 1 MHz + 0.91 MHz = 1.91 MHz 
(iii) From Equation 4.1 of Worked Example 4.1, the RF amplifier response is 
given approximately by 
IH(j)12 
1 + (f -Fe)2/B2 
1 
IH(Fimage)i2 = 1 + (910)211002 = 0.012 
== -:-19.2 dB 
The receiver provides some 19.2 dB of image rejection. 
There are thus two conflicting requirements influencing the choice of IF 
frequency: 
(i) It must be low enough so that, allowing for practical circuit elements with 
limited Q values, a sufficiently steep attenuation characteristic can be obtained 
outside the IF signal bandwidth to substantially suppress adjacent channel 
signals. 

RFinput 
1 st local 
oscillator 
1st IF 
amplifier 
2nd local 
oscillator 
2nd IF 
amplifier 
Fig. 4.5 Double-conversion receiver. 
Detector 
(ii) It must be high enough so that the RF amplifier provides adequate attenuation 
of unwanted signals at the image frequency. 
The image rejection capability of a receiver can be further enhanced by using 
double conversion, as shown in Fig. 4.5. A relatively high IF frequency is chosen so 
that the RF amplifier provides substantial attenuation of image signals. Only 
modest adjacent channel rejection is provided, however, due to the limited Q of the 
filter components and the use of a high IF. The output from the first IF stage is then 
down-converted by a second mixer to a lower second intermediate frequency 
(second IF). This is chosen to be sufficiently low that good adjacent channel rejec-
tion can be obtained. 
Automatic Frequency Control (AFC) 
The frequency of a tunable local oscillator is liable to fluctuate slightly. This may 
result, for example, from temperature variations which may change the inductive 
and capacitive properties of the elements used in the frequency defining tuned 
circuits; the properties of the active devices (transistors) are also liable to change 
with temperature and so influence the local oscillator frequency. For FM systems 
frequency stability is especially important and an automatic frequency control 
(AFC) loop is usually incorporated to overcome these frequency drifts. The action 
of the loop is as follows: any error in the average frequency of the signal applied to 
the discriminator results in a d.c. offset at the output and the output can thus be 
lowpass filtered to remove signal components and extract the d.c. term. This can 
then be used to operate automatically on the local oscillator so as to minimize any 
frequency error. 
A voltage controlled oscillator with a voltage-to-frequency conversion sensitivity 
of 200 kHz/V is found to drift by ± 100 kHz. It is to be used as the local oscillator 
for an FM radio receiver requiring frequency errors not exceeding ± 100 Hz. If the 
frequency discriminator produces 1 V output per 100 kHz of frequency offset 
determine the minimum voltage gain required in the AFC feedback path. 
Solution: The AFC system may be modelled by the negative feedback system 
shown in Fig. 4.6, in which the local oscillator is assumed to operate above the 
carrier frequency. We make the' following definitions: 
Fc = input carrier frequency 
FIF = nominal IF frequency 
FE = local oscillator frequency error in the absence of AFC 
Detected 
I----I~ message 
Frequency stability is especially 
important at high carrier 
frequencies since a small 
percentage frequency deviation 
corresponds to a very large 
absolute frequency deviation. 
Having said that, mixing at 
optical frequencies has been 
successfully demonstrated in 
research laboratories, and 
optical AFC loops are under 
development for optical fibre 
communication systems. 
Worked Example 4.4 
73 

74 
RF input For 
IF 
F,F 
Frequency 
,,,X 
amplifier 
discriminator 
veo 
/. 
lowpass 
~ 
filter 
Fig. 4.6 Automatic frequency control loop. 
FLO = actual local oscillator frequency 
KF = voltage-to-frequency conversion gain of local oscillator [Hz IV] 
Ky = frequency-to-voltage conversion gain of FM discriminator (V 1Hz) 
A = voltage gain of AFC feedback path 
Now 
and 
local oscillator 
frequency in the 
absence of AFC 
correction term 
provided by 
AFCloop 
Vo = Ky 
(FLO - Fc - F1F) 
actual frequency 
error 
=KyF 
Here F = FLO - Fc - FIF = FE - KFA Vo 
=FE - KFKyAF 
:} F(1 + KFKyA) = FE 
whence 
F= 
FE 
1 + KFKyA 
That is, the local oscillator drift is reduced by the feedback factor (1 + KFKyA). 
Here 
KF = 200 kHz/V = 2 x 105 [Hz/V] 
Ky = 1 V 1100 kHz = 10-5 [V 1Hz] 
IFEI < 100 kHz = 105 [Hz] 
IFI < 100 Hz = 102 [Hz] 
Hence the following is required: 

that is, 
A >500 
Summary 
We have seen how a radio signal may be received and processed, allowing recovery 
of the message signal. The simple tuned radio frequency receiver principle was 
described and its limited adjacent channel capabilities noted. The superheterodyne 
receiver was then described and shown to offer considerable benefits in this 
respect, but in this instance image rejection must also be considered. 
We noted that for effective adjacent and image channel rejection the local oscil-
lator frequency and the intermediate frequency filter characteristics must be judi-
ciously selected. It was suggested that double conversion, involving two IF stages, 
could usefully be adopted for demanding applications if the increased complexity 
(two local oscillators, two mixers and two IFs) is acceptable. 
It was noted that automatic feedback loops may be required to correct for varia-
tions of signal level and for local oscillator frequency errors. 
Problems 
4.1 A TRF receiver uses an RF amplifier incorporating two identical tuned circuits 
prior to demodulation. Estimate the selectivity of this receiver, measured as 
the ratio of the - 40 dB to - 3 dB bandwidths. 
4.2 A superheterodyne FM radio receiver uses a 10.6 MHz IF and, in the interests 
of economy, employs a single fixed tuned circuit RF amplifier prior to the 
mixer. The - 3 dB bandwidth of this RF stage is adjust~d to allow the receiver 
to operate over the band 88 MHz to 108 MHz. If the local oscillator operates 
above the carrier frequency, estimate 
(i) the frequency range over which the local oscillator must be tunable; 
(ii) the range of image frequencies the receiver encounters; and 
(iii) the worst case image rejection ratio, expressed in decibels. 
75 

76 
5 Pulse Modulation Systems 
Objectives 
0 To describe the principle of pulse amplitude modulation (PAM). 
o To introduce the concept of sampling, show its relation to PAM and state 
the sampling theorem. 
o To explain what is meant by aliassing distortion and how it can arise. 
o To note briefly other pulse modulation schemes: pulse frequency modulation 
(PFM), pulse position modulation (PPM), pulse width modulation (PWM). 
o To introduce the concept of time-division multiplexing (TDM). 
Pulse Amplitude Modulation 
In Chapter 3 we showed how a double sideband suppressed carrier modulated 
signal could be produced as the product of a message signal m (I) and a sinusiodal 
carrier xc(t). The result was that copies of the message spectrum M(f) were 
produced at ±Fc, i.e. in the vicinity of the spectral components of the carrier. We 
now wish to examine the consequences of employing a pulse train, rather than a 
sinusoid, as the carrier. This modulation scheme is shown in outline in Fig. 5.1. 
The pulse train carrier xp(t) has the form 
xp(t) = }; p(t - kT) 
k 
where 
p(t) = rect (tlr) = 
mIt) 
Message m(t) with 
spectrum M(t); 
[01 
M(t) = 0 for I t I > W 
111<712 
elsewhere 
--®----
PAM 
I 
"g",' 
xpW = fP(t - k T) 
Fig. 5.1 
Pulse amplitude modulation. 
(5.1) 

Possible 
m(t)",,/--, Misinterpretation ,'--, 
/" \ 
/ 
\ 
\ 
I 
\ 
............ 
' 
I 
\ 
........ \ 
I 
a 
, 
, 
/ 
, 
I 
I , 
Fig. 5.2 Sampled sine waves. (a) T« 1/W; (b) T~ 1/W. 
The pulse amplitude modulated (PAM) signal thus has the form 
x(t) = m(t)xp(t) 
= m(t) ~ p(t - kT) 
k 
(5.2) 
Before proceeding with the analysis, it is helpful to examine the form of x(t) for 
various values of T. Recall that the message m (t) is assumed strictly bandlimited to 
If I < W, so that m (t) changes only slightly over time intervals « 1/ W. Hence, if 
T« 1 I W, as in Fig. 5.2a, the heights of successive modulated pulses in x( t) are 
almost equal and it is easy to 'guess' the likely form of m(t) from the form of x(t). 
Note that for m(t) > 0 the output pulses are positive and for m(t) < 0 the output 
pulses are negative. Thus it is expected that a close approximation to m(t) should 
be obtained by lowpass filtering x(t). This is indeed the case. Considering now 
Fig. 5.2b for which T> l/Wit is not possible to guess m(t) fromx(t); it transpires 
that m(t) cannot be recovered from x(t) in this case. We conclude that PAM 
requires a sufficiently high carrier pulse repetition frequency (PRF). In order to 
quantify this it is appropriate to examine the problem in the frequency domain. 
The analysis is commenced by considering the Fourier series representation for 
xp(t): 
xp(t) = ~ p(t - kT) 
k 
00 
= 
~ cn expU27rntIT) 
n =-(10 
00 
= Co + ~ 2cn cos(27rntIT) 
(5.3) 
n-I 
Note that this is the pulse carrier 
analogue of DS8-SC. 
77 

A Fourier series representation 
for this repetitive pulse train was 
obtained in Chapter 2. 
78 
where the last form arises since xp(t) is an even function which admits a Fourier 
cosine series expansion. 
Hence, 
X(t) = m(t)xp(t) 
= m(t) [co + 2 n~) cn COS(21l'ntID] 
= com(t) + 2c)m(t)cos(21l'tIT) 
+ 2c2m(t) cos(21l'2tlD 
+ 2cnm(t) cos(21l'ntIT) 
(5.4) 
Examination of Equation 5.4 reveals that the PAM signal contains the following 
components: 
com(t) 
= the message, scaled by Co 
2c)m(t) cos(21l'tlD 
= DSB-SC signal with 
(suppressed) carrier frequency = liT 
2c2m(t) cos(21l'2tlD = DSB-SC signal with 
(suppressed) carrier frequency = 21T 
and so on. 
(5.5) 
Since DSB-SC produces a scaled copy of the message spectrum at ±Fc' it can be 
concluded that the PAM signal contains a multiplicity of scaled copies of the 
message at ± niT, n integer, as shown in Fig. 5.3. The relative strengths of these 
various copies depend on the Fourier coefficients Cno which in turn depend on the 
!\ 
.. f 
a 
-w 
0 
w 
t 
t 
r" 
t 
t .. f 
-21T 
-1fT 
0 
1fT 
21T 
b 
XI f) 
, ______________ , 
Lowpass filter response 
, 
'/ 
' 
I 
I 
I 
I 
, 
I 
I 
I 
I 
I 
, 
~~~~~~~-+--~~~~--~~~,~-+--~--~--~~~f 
-21T 
-lIT 
o 
c 
: 
lIT 
I 
l-w 
T 
21T 
Fig. 5.3 Spectral regresentations of PAM. (a) Message spectrum, M(f); (b) 
spectrum, Xp(f), of pulse train xp(t), T< 1I2W; (c) PAM signal spectrum with 
liT> 2Wshowing recovery of M(f) by Iowpass filtering. 

precise form of the pulse waveform, p(t). The Cn are examined explicitly shortly; 
for the present simply note that provided 1 IT> 2 W the various replications of the 
message spectrum are disjoint in the frequency domain and the message can be 
recovered by lowpass filtering, as shown in Fig. 5.3. 
Sampling 
Sampling is a limiting case of PAM in which the pulses are of very short duration 
such that, for practical purposes, the PAM signal depends on the value of the 
message at only discrete points in time, t=nT. To represent this analytically it is 
convenient to consider the pulse p(t) to take the form 
1 
[lIT 
p(t) = T reet (tIT) = 0 
It I < Tl2 
elsewhere 
such that 
1 
(t -kT) 
xp(t) = T f rect -r-
= ~ cn expU21rntlT) 
n 
whence 
TI2 
[ I 
. 
] T/2 
-
1 I 1. 
('2 tiT) dt _ ~ ;- exp( - J21rntlT) 
cn -
-,y; 
exp - J 1rn 
- T 
-J'2 niT 
1 
-TI2 r 
1r 
-T/2 
(5.6) 
(5.7) 
= ~ sin(1rnTlT) = ! sinc( 1rnr) 
(5.8) 
T 
1rmiT 
T 
T 
Taking the limit as r--+O, corresponding to short duration, large amplitude 
sampling pulses, we obtain 
1 
c=-
n 
T 
since 
for all n 
lim sinc(x) = 1 
x--+O 
(5.9) 
Hence with this idealization a sampled signal contains replications of the message 
spectrum M(j) 4=> m(t) located at multiples of the sampling frequency F. = liT. 
The replications are of equal strength corresponding to the message being scaled in 
amplitude by liT. This may be written formally as 
X(j) = ! ~ M(f - !!...) 
TnT 
(5.10) 
The message is recoverable by lowpass filtering provided F. > 2 W, where W is the 
bandwidth of the (lowpass) message corresponding to the highest possible fre-
quency component contained in the message. If F. < 2 W, spectral overlap occurs, 
as shown in Fig. 5.4, and lowpass filtering can recover only a distorted form of the 
79 

80 
Region of 
j ,,,..,,"', ove'" 
-2fT 
-1fT 
1 
o 1-W 
W 
2fT 
1fT 
Fig.5.4 Spectral overlap due to sampling at lIT< 2W. 
message. The character of this form of distortion is best appreciated by reference to 
a sinusoidal message, as follows: 
Consider 
m(t) = cos(211"Fmt) 
(5.11) 
with spectrum 
(5.12) 
containing components at ±Fm. If the signal is sampled at F. such that 
Fm = Ps/2 + e the resulting spectrum contains components at nFs ± Fm as shown 
in Fig. 5.5. Notice that the output contains terms at ifi = F/2 - e so that it is 
I 
I 
I 
I 
I .. , 
-2F. 
-F, 
o 
F. 
2F. 
I. 
, I 
.. , 
0 
~ F _F. E 
2 
m-"2+ 
t t 
.. , 
2F. 
Fig. 5.5 Illustration of aliassing. (a) Spectrum of sampling pulse train, F. = liT; 
(b) spectrum of cosinusoidal message; (c) spectrum of sampled signal with aliassed 
components atf = ± [(Fs/2) - e). 

Input 
signal 
m,(t) 
Lowpass 
filter 
BW= w<i 
Anti-aliasing 
filter 
Lowpass 
filter 
BW= W 
Recovery 
filter 
Bandlimited 
message m(t) 
Sampling 
pulse train, 
F, 
1------,1- Recovered 
message mIt) 
PAM or sampled 
signal 
Fig. 5.6 A PAM or 'sampled data' system. 
impossible for a lowpass filter to recover the original message terms 
at ± F m = + (Fs /2 + E) without also passing the terms at ± (Fs /2 - E). The 
recovered signal is thus distorted. Note, however, that the output term at 
(Fs/2 - E) could equally well be due to an input term at this frequency. If we 
assume the use of an ideallowpass filter with bandwidth B=Fs/2 then the term 
Fs/2 + E at the input is in a sense mass masquerading as a message component at 
(Fs/2 - E). This is referred to as an alias or an aliassed component and this form of 
distortion is called aliassing. In order to minimize alias sing distortion the message 
can be passed through a sharp cut-off lowpass filter prior to sampling, as shown in 
Fig. 5.6. Since any practical filter has a finite transition region, the bandwidth of 
this anti-aliassingfilter must be somewhat less than Fs/2. 
These observations are of such importance that we encapsulate them formally in 
a theorem. 
The Sampling Theorem 
A strictly bandlimited signal m(t) with spectrum M(f) = 0 for all If I > Wmay be 
recovered from samples m (n T) taken uniformly in time at a rate Fs = 1/ T if and 
only if Fs > 2 W. Provided this condition is satisfied then m(t) may in principle be 
recovered from the sampled signal by using an ideallowpass filter with bandwidth 
W. 
Note that, unlike the various amplitude modulation schemes discussed in 
Chapter 3, message recovery from a PAM or sampled data signal format does not 
require a demodulator; a lowpass filter is all that is required. 
Alias: Name by which one is 
called on other occasions 
(Concise Oxford Dictionary). 
There are more general forms of 
this theorem. See, for example, 
Cattermole, K.W., Principles of 
Pulse Code Modulation, lIiffe, 
1969. 
Suggest suitable sampling frequencies for the following signals: (i) telephone quality speech, 
Exercise 5.1 
bandlimited to the range 300 Hz-3.4 kHz; (ii) a music quality audio signal with spectrum 
extending to 15 kHz; and (iii) a television signal with an essentially lowpass spectrum 
extending to 5.5 MHz. 
A telephone quality speech signal is generally considered to be concentrated in the 
Worked Example 5.1 
band 300 Hz to 3.4 kHz but to allow for finite filter transition regions is often 
81 

82 
treated as having a spectral occupancy corresponding to 4 kHz lowpass. On these 
grounds a sampling frequency of 8 kHz is selected for a sampled data speech 
system and afirst-order anti-aliassing filter with a - 3 dB frequency of 3.4 kHz is 
employed. A similar filter is used for signal recovery. In testing the anti-aliassing 
performance it is found that if a 4.6 kHz sinusoidal signal is applied to the input an 
approximately sinusoidal signal at 3.4 kHz appears at the output. Explain why this 
is so and determine the relative strength of this component compared with a similar 
amplitude 'wanted' component at 1 kHz. Comment on the adequacy or otherwise 
of the anti-aliassing filter. 
Solution: The first-order filter has a magnitude response given by 
1 
IH(/)I = ../1 + (j/F.)2 
(S.13) 
where Fc = 3.4 kHz. Hence the 4.6 kHz input signal is attenuated by a factor of 
[I + (4.6/3.4)2]-1I2!::: 0.S9 at the input to the sampler. This gives rise to a com-
ponent in the sampled output of strength 0.S9/Tat 3.4 kHz. This is attenuated by a 
factor of 1I.J'i by the recovery filter to give an output signal of strength - O.4IS/T 
at 3.4 kHz. In contrast, the 1 kHz tone would be only slightly affected by 
the filters; attenuated by a factor of [I + (113.4)2] -1/2 in each case equals 
[1 + (113.4)2]-1 - liT overall. The relatively high level of aliassing distortion 
encountered here suggests that a sharper cut-off anti-alias sing filter should be 
used. 
Other Pulse Modulation Schemes 
In Chapter 3 it was noted that a message could be impressed on to the amplitude, 
phase or frequency of a sinusoidal carrier, although the various amplitude modula-
tion schemes were discussed in the most detail. Similarly here, while going into 
some detail on amplitude modulation of a pulse train carrier, the existence of other 
pulse modulation schemes broadly analogous to phase and frequency modulation 
are considered briefly. Of the various possibilities, perhaps the most widely known 
and employed are the following. 
Pulse Frequency Modulation (PFM) 
This is an almost exact analogue of frequency modulation (FM) of a sinusoidal 
carrier. The pulse repetition frequency of a pulse train is made to vary in sympathy 
with the message and signal recovery can be achieved as for FM. This modulation 
scheme is adopted for low cost, high performance analogue communication over 
optical fibre channels since it avoids any non-linearities in the opto-electronic 
devices impairing signal quality. 
Pulse Position Modulation (PPM) 
The position of each pulse within a time slot of duration T is made to vary in 
sympathy with the message. Signal recovery is achieved by measuring the varia-
tion of the time interval between the occurrence of a pulse and the occurrence of 

.. t 
a 
n nnnn n n n .. t 
b 
~ 
~ 
~ 
~ 
~ 
~ 
.. 
t 
c 
n n 
0 n n n 
.. t 
d 
Fig. 5.7 Various pulse modulation schemes. (a) PAM, (b) PFM, (c) PPM, 
(d) PWM. 
transitions in a regular timing signal at rate F, = 1/ T. The latter signal is extracted 
from the incoming modulated waveform, a narrowband filter or phase locked loop 
being used to smooth out perturbations due to the message. 
Pulse Width Modulation (PWM) 
The width or duration of the pulses is made to vary with the message; signal 
recovery can be achieved by lowpass filtering. 
These various pulse modulation schemes are illustrated in Fig. 5.7 together with 
PAM for comparison purposes. There is a further class of pulse modulation 
schemes for analogue communication, namely pulse code modulation (PCM). 
However, these are quite different in character to those noted here and are of such 
importance that they are treated in some detail in the next chapter. 
Time Division Multiplexing 
It is convenient and appropriate here to introduce the idea of time division multi-
plexing (TOM) - the dual of frequency division multiplexing discussed in Chapter 
3. For the present, attention is confined to TOM-PAM, time division multiplexing 
of pulse amplitude modulated signals. 
Consider a set of Nindependent messages: ml (t), m2(t), ... mN(t), each strictly 
bandlimited to If I < W. If these are sampled at F, = liT = 2 W each results in a 
PAM signal with F, samples/second. With the sampling for each message offset by 
a time interval T/ N the various sampled signals can be added together to produce a 
composite time-division multiplexed signal. This is illustrated in Fig. 5.8 for N = 4. 
In this way several messages can be combined into a composite TOM-PAM format 
for transmission over a single communication channel at NF, samples/second. 
To recover the individual messages it is necessary to sample the composite TOM-
83 

84 
.. t 
.. t 
.. t 
.. t 
x(t) 
n n 
n n 
_ n u n 
.. t 
a 
Lowpass 
mk(t) 
recovery 
filter 
Ep (t - nT - kT) 
N 
b (hereN = 4) 
Fig. 5.8 Time division multiplexing of PAM signals. (a) TOM signal format; (b) 
demultiplexing and message recovery for kth channel. 
PAM signal at appropriate epochs at a rateF. = liT. For the example of Fig. 5.8, 
recovery of message m3(t) involves sampling x(t) at times t = nT + 3T14. The 
message is then recovered from this sampled signal by lowpass filtering. 
The above discussion outlines the principle of TOM. It can be applied also to cer-
tain other analogue pulse modulation schemes, such as PPM, and is fundamental 
to many digital and data transmission systems. Perhaps the most widespread 
application of TOM, however, is to PCM telephony. 
Summary 
This chapter has been concerned with some of the more common methods of trans-
mitting analogue signals via a pulse carrier. The sampling principle is at the heart of 
all such methods and this has been examined in both the time domain and the fre-
quency domain. Using a frequency domain view we have seen that the sampling 
rate must be at least twice the frequency of the maximum message frequency com-
ponent (Le. twice the message bandwidth for a baseband signal) if the message is to 
be subsequently recoverable without distortion using a lowpass filter. This is the 
key result of the chapter. 

Various modulation schemes involving variation of the amplitude (PAM), fre-
quency (PFM), position (PPM) and width (PWM) of a pulse carrier have been 
described in outline. We saw also that several signals may be combined using pulse 
modulation and time-division mUltiplexing. 
Problems 
5.1 Suggest suitable sampling frequencies for the following signals: 
(i) A group of 12 speech signals, each of nominal bandwidth 4 kHz, which 
have been frequency division multiplexed (FOM) into the band 60 kHz to 
108 kHz. 
(ii) A group of 5 FOM signals of the form in (i) which have been frequency 
division mUltiplexed into a minimum bandwidth equivalent lowpass signal. 
(iii) A composite FM stereo signal (to be discussed in detail in Chapter 8) 
which is effectively lowpass, extending from 30 Hz to 53 kHz. 
(b) State what bandwidth recovery filter is required in each of the above cases. 
5.2 A sampling system uses a fourth-order anti-aliassing filter with a cut-off fre-
quency of 10 kHz. The filter provides 24 dB attenuation per factor of 2 in fre-
quency above cut-off (e.g. 48 dB at 40 kHz). A similar filter is used for signal 
recovery; the sampling rate is 30 kHz. On testing the system it is found that if a 
1 V r.m.s. 25 kHz sine wave is applied to the input a low amplitude component 
at 5 kHz appears at the output. Estimate the relative strength of this inter-
ference term compared with the output obtained when a 1 Vr.m.s. 5 kHz sine 
wave input is used. 
5.3 (i) Thirty speech signals, each of nominal bandwidth 4 kHz, are to be com-
bined using PAM-TOM. What is the effective sample rate for the combined 
signal? 
(ii) If instead the 30 signals are combined using SSB-FOM to produce a 
minimum bandwidth lowpass composite signal and this signal is then sampled 
what is the minimum sampling rate required? 
85 

6 Pulse Code Modulation 
Objectives 
The invention of PCM is 
attributed to a British research 
engineer, Alec Harley Reeves. It 
was to some extent ahead of 
the technological developments 
required to make it a practical 
proposition. Only in recent years 
has it been applied 
internationally. 
86 
0 
0 
0 
0 
0 
0 
0 
To describe and analyse the process of uniform quantization. 
To describe the principle of pulse code modulation (PCM) as a combination 
of quantizing, sampling and pulse encoding. 
To assess analytically the noise performance of a PCM system. 
To note briefly the merits of non-uniform quantization or companding for 
encoding certain signals, such as speech. 
To examine the application of PCM to television and to illustrate the 
subjective impairment of contouring. 
To discuss briefly differential pulse code modulation (OPCM) and delta 
modulation (OM) schemes. 
To outline the principles of, and note the CCITT recommentations for, 
PCM-TOM telephony. 
The modulation schemes discussed so far provide for the representation of 
arbitrarily small perturbations in the message signal. In practical applications, 
however, a received signal is impaired by unwanted interference and noise and this 
limits the accuracy with which the message can be recovered. As an alternative, a 
certain small error in message representation can be accepted at the outset and the 
freedom this implies to obtain a degree of immunity to disturbance on the channel 
can be exploited. This is the essential idea behind pulse code modulation (PCM). 
Its practical implementation makes use of sampling together with two further pro-
cesses: quantization and pulse encoding. 
Quantization 
It is appropriate first to consider quantization -
the process whereby a continuous 
message signal m (t) is replaced by an approximation mQ (t) assuming only discrete 
values. The process is illustrated schematically in Fig. 6.1a. The message is 
assumed to be bounded, - V<m(t)< V, and mQ(t) can assume any of 2N possible 
output levels. The levels are taken to be uniformly spaced by an amount.d, where 
(6.1) 
The quantization error e(t) is defined as the difference between m(t) and mQ(t): 
(6.2) 
and is bounded by -,:V~ < e(t) < .112, as illustrated in Fig. 6.1b. That is, 
le(t)1 <.d/2 and the worst case quantization error is thus .d/2. One means of 
specifying the fidelity of the quantized signal is by the ratio of the peak signal to the 
worst case quantization error: 

Voltage 
+ V---- ---------
0----
- V ---- -----
Binary code 
-
111 
110 
101 
100 
011 
010 
001 
000 
6./2 
o 
...,-s:--.--~----,A,...,ArTA --rA --rA -'-1\""TM'----'/I'---A"--I1--ro=M"--=: 
~""(V i!vv ld1 ITlTvu t.t::s:r::: 
- 6./2 
\ 
e(t) = m(t) - mo(t) 
Signal sampling 
instants 
I Binary code for mo(t) 
001 
000 
101 
100 
111 
at sampling instants 
Binary pulse 
sequence 
Fig. 6.1 
Pulse code modulation. (a) Signal quantization and binary code assign-
ment; (b) quantization error wareforms; (c) sampling and pulse encoding. 
Iml 
V 
V 
lei = A/2 (2V/2N )/2 
= 2N 
(6.3) 
From this it can be concluded that the signal quality increases in proportion to the 
number of levels, or is inversely proportional to the size of the quantel step, A. 
While this is certainly a valid measure, it is not the most useful. After all, the 
message m(t) may reach its peak value only very occasionally while the quantiza-
tion error le(t)1 reaches its peak value each time m(t) crosses a boundary between 
adjacent quantization levels. A more appropriate measure is obtained if the ratio 
of the power in the signal to the power in the quantizing error is considered -
the 
signal-to-quantizing noise ratio SNRQ• Considering the signal, power is propor-
tional to voltage squared; hence 
I· 
1 
TI2 
Srxm2~ 
1m -J 
m 2(t)dt 
T->oo T 
-TI2 
(6.4) 
87 

Note the equivalencing of time 
averaging and statistical 
averaging. This is often possible 
and can lead to considerable 
simplifications in analysis. 
The signal-to-quantizing noise 
ratio improves 6 dB per extra bit 
allocated to the uniform 
quantizer. 
A peak-to-mean power ratio, a, can usefully be defined for the signal, usually 
expressed in dB as 
adB = 10 10glO (,~:) 
(6.5) 
Considering now the quantization error e(t), the waveform is closely approxi-
mated by triangular segments ranging over ±ill2. Hence e(t) is uniformly distri-
buted over the interval ( - ill2, ill2) and has mean square value given by 
-
lim 
1 JTI2 
JTI2 
e2 = T 
T 
e2(t) dt = 
v2 Pe(v) dv 
~ 
00 
-TI2 
-TI2 
(6.6) 
where Pe(v) is the probability density function for the error e(t). The latter is 
uniform on ( - ill2, ill2) of strength 11 il; hence 
e2 Jlil2 v2 dv = 1. [~] lil2 = il2/12 
-li/2 
il 
3 
-li/2 
It follows that 
Expressing this in dB: 
SNRQ == 10 loglO(3) + 20Nlog lO(2) -
adB 
= 4.77 + 6N -
adB 
(6.7) 
(6.8) 
(6.9) 
Worked Example 6.1 
A speech signal has a peak-to-mean power ratio of 10 dB. Ascertain the number of 
quantization levels M = 2N , (a power of 2) required to ensure a signal-to-
quantization noise ratio of at least 50 dB. 
88 
Solution: 
Let 
SNRQ == 4.77 + 6N -
adB =:= 50 dB 
Then 6N=:= 50 + adB - 4.77 = 55.23 
and 
N=:= 55.23/6 = 9.25 
Hence N = lOis the smallest integer exceeding 9.25 and M = 2N = 210 = 1 024 levels are 
required. 
Sampling and Pulse Encoding 
In the foregoing, it is assumed that the number of quantization levels is a power of 
2. This allows each level to be represented by an N-bit binary number, as illustrated 
in Fig. 6.1c. By combining the operations of sampling, quantization and binary 

pulse encoding, pulse code modulation is obtained, in which quantized samples of 
the message are transmitted as binary pulse sequences, as shown in Fig. 6.1c. At 
the receiver, the binary signal is reconstructed into a quantized and sampled ver-
sion of m(t) and is then filtered to recover an approximation to m(t). A major 
benefit offered by PCM is that binary encoding allows us to make use of digital 
transmission. As can be seen in a later chapter, this enables us to recover at the 
receiver, with arbitrarily small error, the binary signals. Hence the only significant 
signal impairment derives from the quantization process employed at the 
transmitter. Assuming there is no corruption of the binary signal in transmission 
the signal-to-noise ratio obtainable at the receiver is precisely the same as that 
developed previously in Equation 6.9. This deceptively simple statement requires 
some justification. 
Consider a signal m(t) bandlimited to ifi < Wand sampled at Fs =2W. The 
message can in principle be recovered unimpaired by ideallowpass filtering to 
ifi < W. If message quantization prior to sampling is now considered, the signal at 
the output of the quantizer may be written as 
mQ(t) = m(t) + e(t) 
(6.10) 
and hence the spectrum of the quantized signal has the form 
MQ(f) = M(f) + E(f) 
(6.11) 
Now m(t) is bandlimited and can thus be sampled at Fs = 2Wwithout suffering 
aliassing distortion; not so e(t), however! The error signal contains frequent, rapid 
transitions between - A/2 and A/2 and thus has considerable high frequency con-
tent. It can be concluded that E(f) extends to ifi » W and, after sampling, the 
various replications of E (f) overlap such that an entire copy of E (f) is folded into 
the interval. (-F.l2, Fs/2), as illustrated in Fig. 6.2. The result is that, due to 
alias sing of the quantization error, there is as much error power in the band 
(-F.l2, Fs/2) after sampling as was contained in the whole error signal e(t) <* 
E(f) prior to sampling. Hence on lowpass filtering the message signal m(t) is 
recovered corrupted by an aliassed error signal with mean square value equal to e2• 
, I 
I 
I 
E(f) 
~.~ 
.. f 
- 3F, 
- 2F, 
- F, 
0 
F, 
2F, 
3F, 
-F,/2 
F,/2 
.. f 
Fig. 6.2 Influence of sampling on quantization error spectrum. (a) Quantization 
error spectrum; (b) sampled quantization error spectrum with replications falling 
in the band (-Fs/2, Fs/2). 
This result is difficult to 
establish formally. See, for 
example, Cattermole, K.W. and 
O'Reilly, J.J., Problems of 
Randomness in Communications 
Engineering, Pentech Press, 
1983. 
89 

The above argument assumes W =FJ2.lfthe sampling rate is greater than twice 
the message bandwidth then the output error will be reduced by a further factor of 
2W/Fs compared with e2• 
Worked Example 6.2 
A nominally 4 kHz speech signal is to be conveyed over a 64 kbitls digital trans-
mission system. Determine the signal-to-noise power ratio attainable assuming a 
10 dB peak-to-mean power ratio for speech and uniformly spaced quantization 
levels. 
Various companding laws are 
discussed in some detail in 
Cattermole, K.W., Principles of 
Pulse Code Modulation, /Iiffe, 
1969. 
90 
Solution: 
The signal must be sampled at not less than 8 kHz to avoid aliassing 
distortion; hence we have available 64/8 = 8 bits/sample. With minimum 
sampling rate and assuming an ideal recovery filter with bandwidth W = 4 kHz, the 
output signal-to-noise ratio is thus 
SNR = 4.77 + 6N -
adD 
= 4.77 + 48 - 10 
::= 42.77 dB 
Non-uniform Quantization 
For peM transmission of speech it is usual to employ a non-uniform series of 
quantization levels allowing small amplitude signals to be more finely quantized, as 
illustrated in Fig. 6.3. There are two reasons for this. First, the mean level of 
speech is much less than its peak value, the latter being attained only rarely. That is, 
there is a predominance of low level signals and these small fluctuations must be 
reproduced if the speech is to be intelligible. Second, different users of a system 
speak at different volume levels; with non-uniform quantization only the high 
signal level 'loud talkers' exercise the large amplitude quantel steps for which a 
high quantization noise results. Appropriate choice of the quantizing non-linearity 
can result in a nearly uniform signal-to-noise ratio for a wide range of talker 
volumes. Non-uniform quantization corresponds to an effective 'compression' of 
the signal range which must be processed at the transmitter and makes use of a 
compensating 'expansion' at the receiver. The whole process, referred to as com-
panding, has the effect of reducing the number of bits required for encoding. This 
is perhaps most easily appreciated with reference to a specific example. Study has 
yoltage 
V 
Quantized ramp 
'-...,. 
0---
Binary code 
1111 
1110 
1101 
1100 
1011 
----1Q1Q 1 0011000 
Fig. 6.3 
Non-uniform quantizer (only positive half shown). 

Fig. 6.4 Influence of quantization levels on PCM TV picture. (a) 1 bit/sample; 
(b) 2 bits/sample; (c) 3 bits/sample; (d) 4 bits/sample; (e) 8 bits/sample. 
shown that the range of significant fluctuation for a constant volume speech signal 
is of the order of 30 dB while a further 30 dB variation can be encountered with dif-
ferent talker volumes. This demands a signal-to-smallest quantel step size of 
60 dB, equivalent to 2000 levels or some 11 binary digits using uniform quantiza-
tion. But uniform quantizing to this precision is quite unnecessary when dealing 
with the higher-level signals and it transpires that an 8-bit representation suffices 
with suitable companding. 
In contrast to speech, PCM encoding of television (TV) signals generally makes 
use of uniform quantization. This is in part because the mean signal level is more 
closely defined but also has its origins in the way the eye perceives brightness varia-
tions. Uniform encoding to 7 or 8 bits has been found to provide adequate fidelity 
91 

92 
for broadcast quality pictures. The influence of the number of bits on the subjec-
tive quality of the encoded TV picture is illustrated in Fig. 6.4. A subjective impair-
ment known as contouring is clearly visible in the more coarsely quantized pictures. 
Worked Example 6.3 
A 5.5 MHz TV signal is to be PCM encoded into 8 bit samples using uniform 
quantization. Determine (i) the minimum sampling rate; (ii) the signalling rate (in 
bit/s) required for digital transmission; and (iii) the signal-to-noise ratio 
attainable. 
Solution: 
(i) From the sampling theorem, a sampling rate of at least II MHz is required. 
(ii) Hence 8 bits/sample and II Msamples/second implies a signalling rate of 88 
Mbit/s. 
(iii) The quality of a TV signal is often assessed in terms of the peak-to-peak 
signal-to-r.m.s. noise ratio. Hence, from Equation 6.9 with C\' = I = 0 dB, 
SNRQ = 4.77 + 6N = 4.77 + 48 = 52.77 dB 
Differential Pulse Code Modulation 
The preceeding example illustrates a major disadvantage of PCM -
it can require 
very high digital transmission rates. One means of obviating this difficulty, which 
can provide a significant improvement if the signal changes only slightly from one 
sample to the next, is to encode only the difference between successive samples 
rather than the sample values themselves. This principle is illustrated in Fig. 6.5a. 
In practical implementations of this idea we encode not the differences between 
adjacent samples but the difference between the actual sample and our prediction 
on the basis of past behaviour, as shown in Fig. 6.5b. The receiver employs an 
identical predictor to the transmitter and uses the incoming samples both to correct 
and to update the present prediction. 
A potential limitation of DPCM is that it suffers from rate limiting at large 
amplitude transitions. This can be minimized by the use of non-uniform 
quantization -
by quantizing large differences more coarsely than small differ-
ences. DPCM has proved particularly effective as a means of reducing the bit rate 
required for digital transmission of TV signals. For example, Fig. 6.6 shows a TV 
picture encoded using 4 level (2 bits/sample) DPCM. Subjectively, the 2-bit 
DPCM picture is almost undiscernable from the 8-bit PCM picture shown in 
Fig. 6.4 and yet it requires only 114 of the digital transmission capacity. It is 
perhaps worth noting that the acceptability of DPCM encoded signals really does 
require subjective assessment and the conclusions depend significantly on the form 
of communication involved. With TV encoding, for example, we can exploit a 
phenomonon known as spatial masking; the eye is rather insensitive to coding 
errors in the presence of sudden large changes in brightness so coarse quantization 
of such changes is acceptable. Quite different conclusions can apply to speech or 
music signals for which spatial masking cannot apply. 

a 
b 
Sampled signal 
,-- --, , , , 
, 
, 
, 
" ----
/(1 
Difference between samples 
, 
, 
, 
, 
, 
, , 
--
, - -r 
Signal 
range 
,J 
__ L 
t t 
t t 
Difference 
_--'---'L-.J-t ----.--;.----~-y-~-'----'-----'L--1.< 
• .. 
_ 
signal 
Sampled 
signal 
+ 
Sampling 
Delay 
pulse train 
T 
Sampling 
pulse train 
Pulse 
decoder 
+ 
--r- range 
Sample difference 
Sign~1 
Ouantizer 
and pulse 
encoder 
Ouantizer 
Pulse 
I-----.--.-j encoder 
+ 
Differentially 
t-------o- encoded 
output 
Predictor 
)-----------1~-l Recovery t--------I-
filter 
Predictor 
Fig. 6.5 Differential pulse code modulation. (a) Principle of differential encod-
ing; (b) DPCM system using prediction from output. 
Delta Modulation 
A limiting case of DPCM is obtained if we represent signal changes by just one 
binary digit. This is known as delta modulation (DM). The main attraction of DM 
is the marked simplicity of the encoder and decoder, as shown in Fig. 6.7. The 
main application of DM is to low-cost encoding of speech signals. To avoid slope 
93 

See Steele, R., Delta Modulation 
Systems, Pentech Press, 1975, 
for a comprehensive discussion 
of this topic. 
94 
Fig. 6.6 Four-level (2 bits sample) DPCM encoded TV picture. 
overload, however, the sampling frequency must be high such that for similar 
signal-to-noise ratio performance the digital transmission rate required for 
DM can be broadly similar to that required for PCM. A variant of DM known as 
delta-sigma modulation (DSM) incorporates the integrator within the transmitter 
feedback loop. Among other advantages, this has the effect of enabling the trans-
mission of d.c. components and further simplifies the receiver to just a lowpass 
filter. 
Bandlimited 
input 
signal 
Comparator 
(1 bit quantizer) 
Integrator 
Clock 
(sampling 
pulse train) 
Delta 
modulated 
signal 
Recovered 
(DM) 
output 
) 
signal 
[------------1 I 
t--~---t Integ rator 1---;-: ---<_ 
I 
I 
I 
D M decoder: 
L ____________ J 
Fig. 6.7 Simple delta modulation system. 
PCM-TDM Telephony 
PCM is used in conjunction with TDM to realize multichannel digital telephony. 
The principle is shown in Fig. 6.8. While there are some variants, an interna-
tionally agreed CCITT standard provides for the combining of 30 speech channels, 
together with 2 subsidiary channels for signal/system monitoring, each speech 

m, 
1 
m2 m 0 
m3 
0 
0 
m. 
0 cc= 
Input rate F, bit/s/channel 
30 
PCM 
: 
1 st level 
speech 3'0 multiplexer 
signals 
2.048 Mbit/s 
x4 
Time 
division 
multiplexer 
8.448 Mbit/s 
m2 m. m2 m. 
m, m3 m, m3 
fililo 0[1]0 OrT 
.. t 
Output rate Fo = 4 x F, bit/s 
139.26 
1\.---..1 Mbit 
34.368 Mbit/s 
Fig. 6.8 Multichannel digital telephony: PCM-TDM. (a) Principle of PCM-
TDM; (b) CCITT PCM-TDM hierarchy (note: higher levels, corresponding to 
- 280 Mbit/s and - 565 Mbitls are under investigation/in use, but there is no 
formally agreed standard at the time of writing. 
signal being sampled at 8 kHz and quantized into 8 bits. The digital rate per 
channel is thus 64 kbitls and for the composite 30 + 2 channel signal is 
32 x 64 kbit/s = 2.048 Mbitls. For convenience this is often referred to as a 
2 Mbitls PCM signal. 
The CCITT also provides for higher levels of multiplexing combining groups of 
signals in blocks of 4. At each level the bit rate increases by slightly more than a 
factor of 4 since extra bits are added to provide for frame alignment, to facilitate 
satisfactory demultiplexing. The successive levels in the CCITT digital multiplex 
hierarchy are shown in Table 6.1. 
Table 6.1 CCITT PCM Hierachy 
Level 
1 
2 
3 
4 
Summary 
No. 64-kbitls 
channels 
30 
120 
480 
1920 
Approximate binary 
data rate 
2 Mbitls 
8 Mbitls 
34 Mbitls 
140 Mbitls 
In this chapter we have seen how analogue signals may be represented for transmis-
sion in digital form using pulse code modulation. There are three aspects 
CCITT (Comite Consultatif de 
relephone et de relegraphie) -
International Consultative 
Committee for Telephony and 
Telegraphy. 
95 

96 
to this: sampling, as discussed in Chapter 5; quantization of the samples such that 
only a finite discrete set of values are possible; and pulse encoding whereby each 
discrete value is represented by a unique digital pulse sequence. We have seen that 
the quantization process involves some impairment of the signal but that Lt. 
:_ .. 
be small if a sufficiently large number of quantization levels are employe ... 
Further, we noted that for some applications, such as speech encoding, compand-
ing (non-uniform quantization) may have merits. 
For PCM television, companding is not generally used and the influence on pic-
ture quality of the number of bits employed to delimit the levels was illustrated. It 
was suggested that differential coding (DPCM) may reduce the number of bits 
required per sample. The limiting case of this is delta modulation in which only one 
bit per sample is employed; delta modulation schemes where described briefly. 
Finally, the combined use of PCM and TDM techniques to allow several signals 
to be transmitted via a single digital link was described. 
Problem 
6.1 In contrast to speech, PCM encoding of television (TV) signals makes use of 
uniform quantization. Also, the quality of a TV signal is often assessed in 
terms of peak-to-peak signal-to-r.m.s. noise ratio. Consider a low bandwidth 
TV signal bandlimited to 3.2 MHz. If this is to be PCM encoded into 6-bit 
words using uniform quantization, determine (i) the minimum sampling rate; 
(ii) the signalling rate required for binary transmission; (iii) the signal-to-noise 
ratio attainable; and (iv) compare these requirements and performance figures 
with those appropriate to full 5.5 MHz bandwidth, 8-bit systems. 

Digital Communications 
7 
o To describe and provide an analytic formulation for baseband digital 
Objectives 
transmission. 
o To show how an eye diagram is produced and explain its significance for 
system performance assessment. 
o To note briefly what is involved in digital signal design. 
o To introduce the term 'error probability' and to quantify this for a Gaussian 
noise channel. 
o To introduce the concept of a discrete channel model. 
o To explain the principle of source coding as a means of reducing redundancy 
in a signal. 
o To introduce the concept of channel coding for error control. 
o To show how judicious inclusion of controlled redundancy in the form of 
parity bits in a digital signal can provide for error detection and correction. 
o To introduce the concept of line coding, to explain its significance and to 
provide illustrations of some practical line codes. 
o To describe briefly some elementary forms of digital modulation, 
specifically: amplitude shift keying (ASK), phase shift keying (PSK) and 
frequency shift keying (FSK). 
The general thrust of developments in modern communications is towards increas-
ing digitization. For example, the widespread use of computers has led to an 
increased need for man-computer and computer-computer communications and 
thus an increasing proportion of the information we wish to transmit is inherently 
digital. Also, even in the field of human telecommunications exemplified by tele-
phony. it is often found expedient to digitize the analogue signals (for instance, 
using PCM as discussed in the previous chapter) and to employ digital trans-
mission. There are many reasons for this. For example, digital signals provide for 
virtually error-free transmission and such errors as do occur may be detected 
and/or corrected by using suitable data encoding and decoding. Also, digital 
signals are compatible with digital logic circuits and computer systems and can thus 
be economically processed and re-routed as required using such circuits and 
systems. Indeed, arguably it is the economic benefits of digital switching and signal 
processing which provide the main justification for the use of digital transmission 
for telephony; this admits the possibility of combining data, speech and other 
services into an integrated services digital network (ISDN), as noted briefly in 
Chapter 1. This point is returned to in due course; for the present various aspects of 
digital transmission are examined. 
Digital Transmission 
Consider a user of a computer terminal equipped with a typewriter-like keyboard. 
97 

5pecial purpose integrated 
circuits are available to ease 
asynchronous communications: 
ACIA -
Asynchronous 
Communication Interface 
Adaptor. 
98 
Each time the user strikes a key a binary code is generated which identifies this key. 
For example, the numeral 9 might be represented by the 8-bit binary word 
10001001. This code must be transmitted to the computer. If the computer is local 
to the user it may be most convenient to send the signal along 8 parallel wires; this 
might apply, for example, to the keyboard of a personal computer. This mode of 
operation is referred to as bit-parallel, word-serial. If the code 00000000 represents 
no key then the computer can recognize that a key has been struck when one or 
more bits take the value 1. 
For transmission over greater distances the above scheme is inconvenient since it 
involves the use of 8 separate signal wires together with a 9th wire to provide a 
reference (ground). A bulky and expensive cable would thus be required. To 
circumvent this difficulty the data can be serialized for transmission over a single 
pair of wires, as shown in Fig. 7.1. A start bit can be added to the beginning of each 
character code to give the receiver warning that data are about to be sent and one or 
more stop bits are appended to delimit the end of a character. The receiver then 
interprets the binary sequence with reference to a clock oscillator. This is referred 
to as asynchronous serial transmission since a character can appear at any time and 
the receiver interprets the data accordingly. It is an appropriate basis for 
man-machine communication in which there are likely to be significant, variable, 
pauses between successive characters. It is quite common for a return channel to be 
Source 
.J1L 
0 
0 
0 
J1L 
0 
0 
J1L 
:;J;: 
a 
5,1 000 1 0015253 
JIl n rIll. 
5, = start bit 
52' 53 = stop bits 
1, 0 = data bits 
b 
t 
8 signal wires + 
Destination 
1 reference wire 
,~ 
SL 
' 
\ 
! 
...JL 
SL 
I 
mo 0 OmO omsJSJ 
,,- -, 1 signal wire + 
'. ,} 1 reference wire 
• t 
Fig. 7.1 . (a) Bit-parallel, word-serial data transmission; (b) asynchronous-serial 
data transmission. 

Transmission 
Transmitter f-- channel 
r---
Equalizer ---
Threshold 
'""' Hetiming r---
(e.g. coaxial 
detector 
cable) 
a 
Data 
o 
o 
o 0 
®DClD 
0 
® 
C">- ~ 
............ 
J 
-=--
~ " 
© 
® [] iLl! 0: 
iCL 
® 
Dc=JD 
0 
® tt!!tt!!!! 
b 
Circuit 
® 
Clock 
f = 1 
extraction 
C 
T 
Fig. 7.2 Binary digital transmission system. (a) System block diagram; 
(b) waveforms in the absence of noise. 
provided, generally using the same pair of wires, and for the computer to echo the 
character to the display screen of the terminal. In this way the user obtains visual 
confirmation that the computer has received the transmitted data uncorrupted. 
For machine-machine communication, however, this mode of operation is 
necessarily wasteful. There is no reason for a large amount of data not to be sent as 
a continuous binary digit stream, as a sequence of positive and negative pulses for 
example, provided the transmitter and receiver can be kept in step. This is known as 
synchronous transmission. It provides for efficient digital communication and is 
the technique adopted for the transmission of digitized speech samples in PCM 
systems. Accordingly we will discuss this method in some detail. 
Baseband binary transmission principles 
A binary transmission system is shown in outline in Fig. 7.2. The transmitted 
signal, when it arrives at the output of the channel, is attenuated and distorted due 
to the loss and restricted bandwidth of the channel. It is the role of the receiver to 
recover a faithful reproduction of the original data. This is made all the more diffi-
cult by the fact that the much attenuated signal is corrupted by random fluctua-
tions, referred to as noise. The high frequency attenuation of the channel is 
99 

This clock recovery process is 
not discussed here but a 
relatively simple treatment is 
available in Cattermole, K.W. 
and O'Reilly, J.J., Problems of 
Randomness in Communication 
Engineering, Pentech Press, 
1983. 
100 
partially corrected by use of an equaliser -
a frequency dependent network which 
enhances high frequency components. This equalised waveform is then applied to a 
threshold device which restores the signal to its original form except that the timing 
of the transitions may be irregular. This arises because the transition times depend 
on the precise form of the channel output, which will depend on the adjustment of 
the equaliser frequency response relative to the channel. Also, of course, the signal 
at the input to the threshold circuit is corrupted by noise and this too can perturb 
transition timings. Hence, to restore the relative regularity of data transitions a 
clock waveform of frequency Fc = liT is extracted from the signal and used to 
retime the data. This combination of threshold and retiming circuitry provides for 
data recovery and corresponds to making decisions on the basis of samples of the 
signal taken at regularly spaced intervals of T seconds, the sampling epochs being 
adjusted to provide data extraction at the peaks and troughs of the equalised signal 
waveform. This provides maximum immunity to noise since at these points a noise 
voltage is in excess of the difference between the threshold and the peak/trough 
signal value will need to occur before a decision-error is induced. Given this over-
view, we now proceed to a more detailed examination of the problem. 
Intersymbo/ Interference 
Consider a binary signal, x(t), given by 
~'" 
J!l 0 ~ 
0 fT[ilo 
.. t 
-3T 
-T 0 
T 2T 3T4T 
a 
-2T 
x(t) # X(f) JL 
.. 
.. t 
- TI20 TI2 
-21T -lIT 
0 
liT 
21T 
f 
x2(t) = x 2(t - 2n 
mOO • t 
- T/2 0 TI2 
2T 
21T 
f 
.. t 
- TI2 0 TI2 
4T 
b 
Fig. 7.3 
Synchronous binary data and related periodic pulse patterns. 
(a) Synchronous binary data signal, lITbitls; (b) spectrum of a rectangular 
pulse and of related periodic pulse patterns. 

a 
.. t 
b 
7~~ 
.. t 
c 
d 
t 
Fig. 7.4 Effect of bandlimiting on a binary data signal. (a) Rectangular data 
sequence; (b) response of first-order lowpass channel to (a); (c) zero 
intersymbol interference (isi) channel response to (a); (d) nominal decision 
times. 
00 
x(t) = 
~ an rect((t - n1)/1) 
(7.1) 
n = -00 
where [an] represents the binary data, an = 0 or 1. This signal has the form shown in 
Fig. 7.3. The first question to ask is: 'What bandwidth is required to transmit the 
signal unimpaired?' In Chapter 2 we suggested that the occupancy of an isolated 
rectangular pulse has the form in Fig. 7.3b; illustrative spectra for certain repeti-
tive pulse patterns are also shown. All these spectra contain non-zero components 
at arbitrarily high frequencies, Ifl-t 00, and we conclude that an infinite bandwidth 
channel is required if x(t) is to be preserved unimpaired. More realistically, the 
question is asked: 'what channel bandwidth and frequency response is required if 
the data [an] are to be readily discernable at the output when x(t) is applied to the 
input of the channel? This is illustrated with reference to the simple, single time 
constant, lowpass channel in Fig. 7.4b. It is noted that, although the limited band-
width distorts x(t), the data values are still readily discernable if the output is 
sampled at appropriate time instants and sample values> 0 represent Is and 
sample values < 0 represent Os. Another possible output signal form, correspond-
ing to a different channel response, is shown in Fig. 7.4c; the output signal may be 
expressed mathematically as 
00 
y(t) = 
~ onp(t - n1) 
(7.2) 
n = -00 
where p(t) is the signal element pulse shape corresponding to the response of the 
channel to an isolated pulse. Examination of Fig. 7.4b reveals that the actual 
values of the samples corresponding, for example, to a 1 can vary widely. It is seen 
101 

102 
a 
;7\ ~ .. t 
~ 
~ 
A 
--
.. t 
<> 
~ 
b 
/\ ~ 
.. 
~ 
./ 
c 
d 
t 
t 
.. 
0 
0 
(error) 
.. 
e 
Fig. 7.5 
Influence of noise and interference on binary transmission. (a) Signal, 
no noise; (b) notional noise waveform; (c) signal and noise; (d) decision times; 
(e) recovered data. 
shortly that this may be undesirable since the closer the signal is to zero at the 
sample time the more likely noise and interference on the channel is to cause an 
error, as illustrated in Fig. 7.5. In the absence of the latter disturbances, variation 
in the signal sample values corresponding to Is, and similarly Os, is caused by the 
presence or absence of data pulses in adjacent time slots. If an = 1 and an+ I = 0, a 
slowly decaying channel response of the form of Fig. 7.4b results in the output at 
time t = (n + l)T being more positive than if an = O. It is said that the various 
symbols are interfering with one another and this phenomenon is referred to as 
intersymbo/ interference (lSI). 
The Eye Diagram 
lSI is most readily observable if the synchronous superposition of all possible data 
patterns is considered, as shown schematically in Fig. 7.6a. This effect is achieved 
in the laboratory by triggering the oscilloscope on the data clock signal so that the 
digital signal becomes overlapped at multiples of the clock interval; Fig. 7.6b pro-
vides an example. The resulting pattern is referred to as an eye diagram in view of 
the shape of the central section. The eye is open if there is little lSI in which case all 
data 1 values are nearly equal at the sample time, and similarly for Os. The eye 
diagram thus provides a ready visual check in the time domain of the adequacy of 
the transmission channel bandwidth/frequency response. 
Signal Design 
lSI depends on the basic signal element pulse shape, p(t). If it is desired to have 
strictly zero lSI then p(t) must satisfy 

a 
b 
Illustrative 
signal 
segments 
Decision 
times 
Eye 
diagram 
Sampling 
epoch 
Fig. 7.6 Binary eye diagrams. (a) Formulation of eye diagram by 
superposition of data segments. (b) Observed eye diagram for an experimental 
binary transmission system. 
p(O) = k 
p(nT) = 0 
a non-zero constant 
n:i=O 
(7.3) 
Fig. 7. 7a provides an illustration of pulses satisfying these constraints. It is in 
principle possible to obtain zero lSI and yet have a limited bandwidth. To illustrate 
this recall that the spectrum of a rectangular pulse, rect(t), has the form 
sinc(/) ~ sin( 7rf)/ 7rJ. As a consequence of the near symmetry of the Fourier trans-
form relations (Equations 2.S0a, b) which relate time domain pulse signals and 
their frequency domain representations, it transpires that a sinc(t) pulse has a rect-
angular, strictly bandlimited, spectrum. This result, established formally in 
Equation 2.60, is illustrated in Fig. 7. 7b. Hence if we could realize a channel with a 
sinc(t/1) pulse response it would provide zero lSI while having a bandwidth of only 
112 T, one-half of the signalling rate. Further, it can be shown that this is the limit 
103 

It is not uncommon to consider 
non-causal signals for the 
purpose of analysis in 
communication engineering. 
These may often be rendered 
approximately causal by 
introducing an appropriate 
delay. 
104 
,A. 
3T 
If 
-3T 
a 
... 
'-./ 
'-"'..... 
-3T 
- T 0 
2T 3T t 
-2T 
T 
A specific zero isi signal 
b 
1 
21" 
o 
2T 
Corresponding bandlimited 
spectrum 
.. f 
Fig. 7.7 Illustrative zero isi signals. (a) Zero isi signals constraints marked x; 
(b) sinc (//1) and its spectrum. 
case; zero lSI signalling requires a bandwidth of not less than 112 T. Interesting and 
important though this result may be, it should not be interpreted too enthusias-
tically. It is not being suggested that strictly zero lSI can be obtained in practice-
only that it is possible in principle in a restricted bandwidth. Note that the function 
sinc(I/1) extends over - 00 < 1< 00. A practical, causal, channel pulse response 
must be zero for t < 0 and even if a delayed version is considered, sinc[(t - 7)/7], 
there is no infinite value 7 such that the signal is causal, i.e. strictly zero for t < O. 
Hence a more meaningful conclusion is that a signalp(t) which is a close approxi-
mation to sin[(t - 7)/1] may provide almost zero lSI and yet have a limited band-
width. There are many other functions which provide zero lSI and although these 
require a bandwidth greater than 112 T it is generally expedient to choose such a 
function, with a less steeply bandlimited spectrum, as the target for practical 
approximation. This reduces the complexity of the filter required and increases the 
tolerance of the system to variations in the transmission rate. 
Error Probability 
The relative immunity to noise provided by a properly designed digital system has 
been alluded to on a number of occasions; this is now examined quantitatively. 
Recall the system of Fig. 7.2a in which a binary signal, taking values ±A at the 
decision instants, is corrupted by additive noise. The noise is assumed to be 
Gaussian, such that samples of the noise voltage are distributed according to 
p(v) = .J(2~) (J exp(-v212u2) 
(7.4) 

Distribution of signal + noise 
when a 1 ('" + Al is 
transmitted 
1 signal level + A -+---------t--
'Tail' area = P(1101, 
probability that a 0 
will be interpreted as a 1 
Decision threshold 0 -+-C1f---------
'Tail' area = P (011 I, 
probability that a 1 
will be interpreted as a 0 
o signal level -A -+---------+-
Distribution of signal and noise 
when a 0 ('" - Al is 
transmitted 
Fig. 7.8 Errors induced by noise in binary transmission. 
where a is the r.m.s. noise voltage. This noise appears at the input to the decision 
circuit added to the signal voltage, which is + A for a 1 and - A for a 0, at which 
point the signal then has a mean value + A when a 1 is transmitted and - A when a 
o is transmitted. These voltage distributions for signal-plus-noise are shown in 
Fig. 7.8. Errors occur when a transmitted 1 is interpreted at the receiver as a 0 and 
vice versa. These events occur with probability P(Oll), POlO) given by 
Jo 
1 
P(Oll) = -<»'J(27r)a exp[-(v - A)2I2a2] dv 
(7.5a) 
and 
<» 
1 
P(110) = L 
'J(27r) a exp[-(v + A)2/2a2] dv 
(7.5b) 
The average bit error probability is given by 
p. = P(1 )P(Oll) + P(0)P(110) 
(7.6) 
where P(O), PO) are the element probabilities -
the relative frequencies of occur-
rence of 0 and 1 respectively. Usually it is assumed that 1 s and Os are equally likely 
in which case P(O) = PO) = 112. Using the change of variable x = (v - A)/a in 
Equation 7.5a and x = (v + A)/ a in Equation 7.5b: 
<» 
1 
P(Oll) = POlO) = L/a 'J(27r) exp[(-x2/2) dx~T(A/a) 
whence: 
p. = P(Oll)/2 + PO 10)/2 
= T(A/a)/2 + T(A/a)/2 
= T(A/a) 
(7.7) 
(7.8) 
The notation P(011 I denotes 
conditional probability. This is 
the probability that a 0 is 
detected when a 1 is present at 
the input to the receiver. 
105 

Note that SNRdB = 2010glO{Ala) 
since A and a are voltages. 
106 
a 
b 
10- 5 
10-' 
10- 9 
Area = probability 
that the voltage 
V 
V falls between 
-t----t---.p{v) 
1 0 -"t--+----+---+---<-+--___ 
12 13 14 15 16 SNRd• == 20 log,o (Ala) 
Fig. 7.9 Error probability for binary transmission in the presence of Gaussian 
noise. (a) Interpretation of probability density function for a noise waveform; 
(b) Gaussian tail probability: Pe versus SNRdB • 
This is known as the Gaussian tail function. It is plotted in Fig. 7.9 as a function of 
the signal-to-noise ratio A/a expressed in dB: 
(7.9) 
Note that the error probability falls very rapidly with increasing signal-to-noise 
ratio. For example, with A/a::::: 6 == SNRdB ::::: 15.5 dB, Pe::::: 10-9• This is a realistic 
design figure for a high quality digital transmission system in a telecommunica-
tions network and at this level a 1 dB increase in signal-to-noise ratio reduces the 
error probability by more than two orders of magnitude. To appreciate just how 
low these figures are, consider the problem of measuring the error probability for a 
practical system. If a fixed, pseudo-random, data pattern which is known in 
advance to the receiver is transmitted then any errors which occur can be noted. To 
have reasonable confidence in the results an average must be taken. Assume that 
this is done by recording N, the total number of bits transmitted from some 
arbitrary start point until the time that 100 errors are detected. The average error 
probability can then be estimated as 100/ N. For Pe::::: 10-9 this implies N::::: 1011 bits. 
At a data rate of 2 Mbitls this would require a measurement time of the order of 
1011/(2 x 106)::::: 50 000 seconds; approximately 14 hours! 

/B(1
11)=1_ex1 
P(110) = ex 
P (011) = ex 
o 
0 
P (010) = 1 -
ex 
Input 
symbols 
Output 
symbols 
3 == 11-----~3 
O==OO~---~O 
Input 
symbols 
Output 
symbols 
Fig. 7.10 Discrete channel representations. (a) Binary symmetric channel 
(BSC); (b) discrete quaternary channel. 
Discrete Channel Models 
In the foregoing we have discussed how digital signals may be transmitted over 
what is essentially an analogue communication link and may then be recovered at 
the receiver, possibly with the occasional digit being in error. The main emphasis 
has been on binary transmission. With this perspective simplified, discrete, 
channel models for digital transmission systems, as shown in Fig. 7.10, can be 
introduced. The digital channel is seen to correspond to a probabilistic mapping 
between input and output digits. For binary transmission, an input 1 has a prob-
ability P(Oll) of appearing incorrectly at the output as a 0 and probability 
1 - P(Oll) of appearing correctly as a l. Similarly for an input 0 there is a prob-
ability POlO) that it appears at the output as aI, and so on. If P(Oll) = POlO) the 
channel is symmetrical in the way it treats 1 s and Os; this widely adopted channel 
model is referred to as the Binary Symmetric Channel (BSC) and is shown in 
Fig. 7 . lOa. Multi-level, or m-ary, signalling can also be employed in which case it is 
possible for a signal element or symbol to convey more than one bit of information. 
For example, if there are four possible levels then each can be given a binary 
designation 00, 01, 10 or 11 and we can send 2 bits per symbol. A corresponding 
discrete channel representation is shown in Fig. 7.lOb. 
Coding for Digital Transmission 
Having shown how real, analogue, communication links can be used to provide 
purely digital channels attention can now be turned to the problem of transmitting 
data over such a channel and consequently to the subject of coding for digital 
transmission. 
Source Coding 
Source coding is concerned with the following problem: given a source of informa-
tion how should messages from this source be represented such that on average the 
information is conveyed using the minimum number of bits. It is not attempted to 
treat this problem formally but rather to demonstrate the principle with reference 
to a specific example: that of encoding English text. 
Messages are constructed as sequences of symbols, the set of possible symbols 
being known as the source alphabet. In this case the source alphabet is composed of 
107 

The Morse code, named after S. 
Morse, was devised in 1843. 
Matching to the frequency of 
occurrence of letters in normal 
English was effected by Morse's 
colleague, A. Vail, counting the 
number of letters in the type 
boxes at the local newspaper 
office. 
108 
the 26 letters A-Z, the numerals 0-9, a space and various punctuation characters. It 
may also be necessary to distinguish between upper case and lower case letters. The 
total source alphabet is thus considerably larger than the usual 26 letters and if it is 
desired to represent each symbol by a unique, fixed length, binary code some 7 bits 
are required giving 27 = 128 distinct possible characters. A 7 bit code widely used 
for this purpose in computer and data communications, known as ASCII (Ameri-
can Standard Code for Information Interchange), is illustrated in Table 7.1. 
Table 7.1 
Seven-bit ASCII Code 
Character 
Binary code 
Character 
Binary Code 
Communication r 
A 
1000001 
control 
characters 
0011111 
Z 
1011010 
Space 
0100000 
[ 
(1011011 
, 
r~1 
Punctuation 
Punctuation 
and symbols 
and symbols 
'\. 
1100000 
/ 
0101111 
a 
1100001 
0 
0110000 
z 
1111010 
9 
0111001 
[1111011 
Punctuation 
(0111010 
and symbols 
Punctuation 
and symbols 
1111110 
@ 
1000000 
Delete 
1111111 
Here all characters are denoted by code words of the same length. An alternative 
strategy is to allocate short codes to characters which occur most often and long 
codes to characters occurring only infrequently. In this way the average number of 
bits required to transmit a message can be minimized. A familiar example of this 
latter strategy is provided by the Morse code. This was designed on the basis of the 
observed relative frequencies of letters in English text and is based on the signalling 
elements dot, dash and pause. Since in English the letter E occurs very frequently it 
is allocated a very short code, a single dot. On the other hand, the letter Y is rather 
infrequent and accordingly attracts a relatively long code. A disadvantage of this 
kind of code is that the signalling time varies from character to character (2 units 
for E, 13 units for Y, and so on). One consequence of this is the need to introduce a 
specific character to separate letters, as well as the usual space character to separate 
words, although some variable length codes avoid this problem. More seriously, 
the variable character length is inconvenient for automatic data processing. For 
example, if it is necessary to refer to the 12th member of a string of ASCII char-
acters we can readily do so. In contrast, to locate the 12th member of a string of 
Morse coded characters each character must be read in turn, since only by inter-
preting one character do we find out where the next one starts. Hence, if data is to 
be not only transmitted but also stored and processed a variable length code may 
be inappropriate. On the other hand, if the primary concern is with serial trans-

mission then efficient source encoding can be worthwhile. For machine-machine 
communication a simple regular code, such as ASCII, has many attractions. For 
human-human communications different considerations can apply and the Morse 
code is widely adopted for amature radio and for ship-ship/ship-shore com-
munications. Generally this is based on hand signalling in which operators tap out 
the letter codes by hand using a key switch to gate on and off an oscillator. Some 
illustrative Morse code character representations are shown in Table 7.2. 
Table 7.2 Illustrative Morse 
Code Representations 
Letter 
Code 
E 
A 
Y 
If it is required to transmit text yet more efficiently account is taken not only of 
individual letter frequencies but also of the relative frequencies of letter groups. 
For example, since in English there are no words in which the letter Q occurs 
without it being followed immediately by a U, the U is in a sense redundant: it 
carries no information when following a Q. The likelihood of a U occurring is 
increased to the level of certainty given that a Q has just appeared; it is said that 
there is strong conditionality or that the symbols are correlated. This is a very 
special case, but there are many less extreme examples. The probability of occur-
rence of each member of the source alphabet is, in general, strongly influenced by 
what has gone before. Very efficient encoding of text can be achieved if these 
symbol correlations are considered. 
This has been discussed at some length not because of the practical importance 
of this particular example, which is slight, but because it provides a useful illustra-
tion of the principle of source coding. Also, only discrete sources have been con-
sidered: sources characterized by a countable alphabet. The same general ideas 
apply more broadly, however. Indeed, there is a sense in which the DPCM schemes 
of the previous chapter constitute source coding. The correlation between adjacent 
PCM samples is exploited by using a shorter, albeit fixed length, code to represent 
the change in the sample values rather than their absolute value. Source coding is a 
very active field for present day research and there are many subtleties, alternative 
strategies, even competing philosophies. We will not pursue these further here but 
simply note that whatever the efficiency of the source code employed the result is a 
sequence of binary symbols. Attention can now be turned to the problem of con-
veying these symbols with as few errors as possible over a discrete communication 
channel. 
Error Control Coding 
The presence of noise and interference on a communication link can result in cor-
ruption such that the received signal may differ from that which is sent. For a 
digital communication system this means that the received data pattern is in error 
in certain digit positions. The idea behind error control coding is that, by introduc-
ing extra digits into the transmitted signal to provide carefully structured redun-
dancy, it may be possible to detect the presence of errors in the received pattern. 
109 

110 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
I 
0 
Parity violation 
o -- * error in this word 
0 
0 
I ' 
Data bits 
Parity 
bit 
Fig. 7.11 
Single error detection using a parity bit. 
Indeed, it is seen that it is even possible to so structure the signal that certain errors 
can be corrected. We shall restrict our attention to binary data since the majority of 
practical implementations are of this form and also the principle is far easier to 
appreciate for this case. 
Parity checks. Consider the effect of appending an extra bit to the ASCII 
character codes of Table 7.1 in such a way as to produce an even number of I s in 
any character. This extra bit is called a parity bit and the 8-bit words representing 
the characters are said to have even parity. If an error occurs during transmission it 
involves the translation of a I to a 0 or a 0 to a I. In either case, provided no more 
than one error occurs in any character, the result is aparity violation; an erroneous 
bit results in the associated 8-bit character having odd parity and the character is 
thus known to be in error. The appending of a single parity bit thus provides for 
single error detection, as illustrated in Fig. 7.11. In order to enable erroneous data 
to be corrected a return path can be provided, allowing the receiver to send a signal 
back to the transmitter requesting re-transmission. This can be implemented on a 
per-character basis or the data can be sent as blocks of characters and the whole 
block accepted or rejected in accordance with a parity check. 
Sum check. An extension of the above idea, widely used in computer communica-
tions, considers the sum of the characters viewed as binary numbers. If the number 
representation adopted admits both positive and negative values a group of 
characters can be appended to the message to render the total sum zero. This 
technique, illustrated in Fig. 7.12, is known as a sum check; transmission errors 
will, with very high probability, cause the sum check to fail. There is effectively no 
limit to the size of the block of characters which may be checked in this way since 
modular addition can be employed. 
HAVE A NICE DAY 10 
~----~v~----_-J~/ 
Message 
Sum 
check 
Fig. 7.12 Character-based sum check. 
Rowand column parity checks. The parity checking scheme can also be extended 
to provide for error correction. One way to achieve this is to consider the trans-
mission of groups of characters and to imagine these organized in a table. Adding a 
parity bit to each row of the table allows us to check for errors in individual 

r 
Row parity bits 
0 
0 
0 
I 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
Column_ 0 
0 
0 
0 
I -Check on column parity bits 
parity 
LCheck on row parity bits 
bits 
o 
I 000 
E~roneous~o: 
0 
I _Parity violation 
bit 
L __ ~ 
101 0 
o 
I 
0 
I 
I 
00100 
o 0 
001 
L 
Parity violation 
Fig.7.13 Rowand column parity checking. (a) No errors; (b) single error 
detection and identification. 
characters but if a parity bit is added for each column then it is also possible to 
identify the bit position in which an error occurs. With this arrangement, known as 
row and column parity checking, single errors can be detected and corrected, as 
illustrated in Fig. 7.13. Note that certain multiple errors can also be detected but 
not corrected. 
Block coding. As a further example of error detection and correction (EDC) 
coding, appending a number of check bits to a block of information bits is con-
sidered. This technique is referred to as block coding to distinguish it from con-
volutional coding in which the check digits are mixed in with the information bits in 
a complicated, more or less continuous manner. Specifically, the (7.4) Hamming 
code is discussed, in which each block contains a total of 7 bits: 4 information bits 
and 3 check bits. This code provides for both the detection and correction of single 
errors; the check bits are generated from the data using modulo-2 addition, corres-
ponding to the exclusive-or operation. Consider the data word structure: 
[d1 
d2 
d3 
d4 
information 
or data bits 
cl c2 c3] 
check 
bits 
The check bits are generated from the data as follows: 
c1 = d1 @d2@d4 
c2 = d1@d3@d4 
c3 = d2(t)d3(t)d4 
(7.10) 
(7. 11 a) 
(7.11b) 
(7.11c) 
One of the earliest papers on 
this subject is Hamming. R.W .• 
"Error detecting and error 
correcting codes". Bell Systems 
Technical Journal. 29. April 
1950. 147-160.~isve~ 
readable. requiring no advanced 
mathematical skills. 
Here(£) denotes addition 
modul0-2 and corresponds to an 
exclusive-or operation: 
0(£>0=0 
1(£)0=1 
O(£) 1 = 1 
1<3>1 -0 
111 

112 
and these same equations are used to check the correctness of the data at the 
receiver. If during transmission anyone of [c1 ,d1 ,d2,d4j becomes corrupted then 
at the receiver Equation 7.11a does not hold. Similarly for [c2,d1,d3,d4j and 
[c3,d2,d3,d4j in relation to Equation 7.IIb and c. Consider, for example, that d3 is 
in error, so that test 7.11 a succeeds but 7.11 band 7.11 c fail. Since 7.11 a is satisfied 
it is known that [eI ,dI ,d2,d4j are all correct. Hence the failure of 7.11 b is caused by 
c2 or d3, [d1,d4j having been validated by 7.11a. But 7.1 Icfails, so the error cannot 
be c2 since this is not involved in 7 .IIc; it is concluded that d3 is in error. d3 is now 
corrected by complementing it, that is by setting it to 1 if 0 was received and to 0 if 1 
was received. 
A reordering of (7.10) of the form 
[cI ,c2,dI ,c3,d2,d3,d4] 
(7.12) 
is often used since an appropriate reformulation of the tests of Equation 7.11 then 
allows the position of an error to be directly specified. To achieve this the idea of an 
error syndrome [S] = (sl ,s2,s3) which specifies the location of an error in 7.12 is 
introduced. [S] = (0, 0, 0) means no error, [S] = (0,0,1) says that c 1, the first bit, is 
in error, etc. The error syndrome is constructed as follows: 
[
Sl = c3 <±> d2<±> d3 <±> d4 
[S] = 
s2 = c2<±> d1 <±> d3 <±> d4 
s3 = eI <±> dl <±> d2<±> d4 
Here Equation 7.13 is obtained from Equation 7.t1a by noting that 
eI = d1 <±> d2<±>d4 
eI <±> dl <±> d2<±>d4 = 0 
(7.13) 
(7.14) 
and similarly for 7.11 b, c. Here use is made of the result that addition modul0-2 
and subtraction modulo-2 are identical operations. Applying Equation 7.13 to the 
example where d3 is in error we obtain [S] = (1,1,0), specifying, correctly, that the 
error is in bit 6 of 7.12. 
This general idea can be extended to larger blocks and to the detection of multi-
ple errors per block but this is not considered in this text. Of course, these schemes 
only work satisfactorily if the number of errors in a block is limited. If errors are 
likely to occur closely together, in bursts, yet the average error rate is still reason-
ably low, then EDC can be achieved by distributing check and corresponding data 
digits throughout the transmitted sequence such that they are widely separated. By 
this means even if several adjacent bits are corrupted the information can be recon-
structed from the uncorrupted check and data digits elsewhere in the data stream. 
There are many further aspects of error control coding but the above should suffice 
to illustrate the underlying principle. Broadly speaking we are concerned with 
deliberately introducing redundancy -
extra bits -
in such a way that errors that 
occur during transmission can be detected and/or corrected. This is in marked 
contrast to source coding where the aim is to remove unwanted redundancy so as to 
reduce the average number of bits required to represent a message. It is important 
to realize, however, that the two ideas are complementary rather than contra-
dictory! A source may contain considerable natural redundancy and yet this may 
not be in a form which allows for ready and reliable error detection and correction. 

a:c. coupled I 
r-------.t 
signal 
U 
.. t 
Fig. 7.14 Binary signal with 'droop' due to a.c. coupling. 
In these circumstances it may be appropriate to employ source coding to remove 
the unwanted, unuseable, redundancy and to follow this by EDC coding to provide 
immunity to channel errors. The resultant data rate might be the same, greater, or 
less than that of the uncoded source signal and yet improved information transfer 
may result. 
Line Coding 
Both source coding and error control coding are concerned with matching the 
source to the channel. With source coding we seek to make the source compatible 
with a lower data rate channel than might otherwise be required; with error control 
coding we seek to obtain reliable communication despite a certain degree of unreli-
ability in data transfer over the channel. Line coding is concerned with yet another 
aspect of matching a source to an available channel. 
It is frequently the case that a communication link cannot transmit d.c. compo-
nents. This is the case in the telephone network, for example, in which a.c. coupling 
is provided via transformers. In these circumstances, if it is attempted to send a 
long string of Is or Os, the signal 'droops', as shown in Fig. 7.14, leading to dis-
crimination difficulties at the receiver. A line code employs redundancy of some 
form to eliminate this problem. 
Perhaps the simplest example is provided by alternate mark inversion (AMI) in 
which the binary (2-level) data are converted into a ternary (3-level) signal by repre-
senting alternate Is -
or marks -
by positive and negative pulses, zeros being left 
unchanged. This is illustrated in Fig. 7.15; the result is a signal which is balanced 
around zero. This arrangement avoids the need to transmit a d.c. component but 
long runs of Os can still be experienced and the absence of frequent transitions in 
the data means that the receiver is likely to get out of step with the transmitter. For 
example, if the receiver clock frequency is 11/10 times that of the transmitter then 
a run of 10 zeros is interpreted as 11 zero's. To avoid this problem it is required that 
the line signal should contain frequent transitions from which the receiver clock 
frequency and phase can be continuously adjusted. A widely used modification of 
Binary [iJor;==lJo[1Jo 0 
0 o I ' 
10 
data 
• t 
AMI R 
I+il 
I+ill+il 
B 
l:iJ 
~ 
• 
t 
Fig.7.15 Alternate mark inversion. 
113 

Various line codes and their 
properties are discussed in more 
detail in Bylanski, P. and Ingram, 
D.G.W., Digital Transmission 
Systems, Peter Peregrinus, 
1976, Chapter 11. 
114 
tion of AMI which achieves this is known as HDB3 -
high density bipolar code 
with substitution after three consecutive zeros. The coding rules are as for AMI 
unless this would result in more than three consecutive zeros at the output, in which 
case a' l' is inserted but in such a way as to violate the alternating mark sequence. It 
can thus be recognized as a violation at the receiver and removed to restore the 
original data. However, these violations could upset the balance of the line signal 
so they must themselves alternate and yet be distinguishable from data marks. The 
result is a rather complex set of coding rules which will not be detailed here. Note, 
however, that HDB3 has been adopted by the CCITT as a standard code for inter-
facing 30 + 2 channel (2 Mbitls) PCM systems. 
An alternative, more efficient form of line coding operates on blocks of data bits 
rather than on the individual digits. An example is provided by the 4B3T codes in 
which groups of four binary digits are mapped on to words of three ternary digits. 
Wherever possible balanced output words, whose digits sum to zero, are employed. 
For example, the ternary word + 1,0, - 1 has a zero digit sum and is said to be a 
zero disparity word, while + 1, + 1, + 1 has a digit sum, or disparity, of + 3. Non-
zero disparity words are grouped in pairs, one positive and one negative, and the 
positive or negative code word is transmitted as appropriate in order to reduce 
towards zero the accumulated disparity or running digital sum. An illustrative 
section of a 4B3T code translation table is shown in Table 7.3. 
Table 7.3 A 4B3T Code Table 
Ternary output 
Code transmitted when 
Binary input 
0000 
0001 
0010 
0011 
0100 
0101 
0110 
0111 
1000 
1001 
1010 
1011 
1100 
1101 
1110 
1111 
disparity is: 
negative 
+ 0 -
- + 0 
0-+ 
+ - 0 
+ + 0 
0++ 
+ 0 + 
+ + + 
+ + -
-
+ + 
+ - + 
+ 0 0 
0+0 
00+ 
0+-
- 0 + 
positive 
+ 0 -
-
+ 0 
0-+ 
+ - 0 
o 
o 
- 0 -
-
-
+ 
+ -
-
- + -
- 0 0 
0-0 
00-
0+-
- 0 + 
Note that the output codeword 000 is not allowed, although it is zero disparity, 
since it contains no transitions. 
We have discussed ternary line codes since these have found most widespread 
application in the past. With the advent of optical fibre communications, however, 

there is an increased need for purely binary line codes. This is because a laser or 
light emitting diode source can be readily switched on and off to produce pulses of 
light; a pulse of light can then represent a 1 and no pulse a O. Since the intensity of 
the source is being modulated it is not possible, however, to have negative light! 
That is not to say that ternary transmission is not possible -levels equivalent to 0, 
+ 1 and + 2 could be used -
but it is inconvenient and, it transpires, makes less 
effective use of the power capability of the optical source. A binary line code 
involves mapping a group of n input bits into n + m output bits. In the interests of 
efficiency we would like m to be as small as possible to avoid transmitting more bits 
than necessary. In practice this is invariably achieved by making n odd and m = 1. 
Examples of common binary line codes are IB2B, 3B4B, 5B6B, 7B8B. The first 
two are illustrated in Table 7.4. Note that n,n + 1 codes are based on n odd since 
only with n + 1 even can zero disparity output words exist. 
Table 7.4 Illustrative Binary Line Codes 
IB2B 
3B4B 
Input 
Output 
Input 
0 
o 1 
000 
1 
1 0 
001 
010 
011 
100 
101 
110 
111 
Digital Modulation 
+ ve 
1101 
1011 
Output 
zero 
1001 
1010 
0011 
1100 
0101 
0110 
-ve 
0010 
0100 
A digital signal can be conveyed over a bandpass channel with the aid of modula-
tion using schemes similar to those discussed for analogue messages in Chapter 3. 
This is another aspect of matching the information source to the available physical 
channel and may be used in conjunction with the various coding schemes discussed 
above. The three main forms of digital modulation are only considered briefly. 
Amplitude Shift Keying 
This is a form of amplitude modulation in which a sinusoidal carrier is switched on 
for a binary 1 and off for a O. The transmitted signal has the form 
x(t) = (~an rect[(t - n1)/1]} COS(2'lI-Fet) 
(7.15) 
where Fe is the carrier frequency, liTis the signalling rate and an = Oor 1 for binary 
signalling. The scheme is readily extended to multi-level signalling by allowing 
other values for an. Fig. 7 .16a provides an illustration of the binary case. 
115 

116 
I 0 I 1 I 0 I 1 I 1 I 0 I 0 I 
a 
~UH 
nm 
~~~U~~~U 
~n~~nn~ 
.. t 
b 
(\ M (\M(\ 
WWV VIJ 
.. t 
c 
(\ M~M(\ MUU~~M(\ 
VHU~ vnrnn~n V 
.. t 
Fig. 7.16 Digital modulation schemes. (a) Amplitude shift keying (ASK); 
(b) phase shift keying (PSK); (c) frequency shift keying (FSK). 
Phase Shift Keying 
Here the carrier phase is switched in sympathy with the data; Fig. 7 .16b provides 
an illustration. Multi-phase signalling is common and a phasor diagram for a 
4-phase case, denoted 4<f>PSK, is shown in Fig. 7.17. Here each of four possible 
signal phases is used to represent a group of two binary data digits. As a result the 
binary data rate is twice the signalling rate (2 bits per symbol). It is convenient to 
distinguish the binary data rate, measured in bit/s, from the channel signalling 
rate, measured in baud: 1 baud corresponds to 1 signalling element per second. 
40 
PSK 
signal 
o 0 
0 1 
I 
I 
I 
~Tj 
o 1 
Fig. 7.17 Four-phase PSK (4<f>PSK). (a) Signal vector diagram; (b) illustrative 
time domain signal. Signalling rate = lITbaud, data rate = 21Tbitls. 
Frequency Shift Keying 
Yet another alternative is to switch the instantaneous frequency of the carrier, as 
shown in Fig. 7 .16c. Once again m-ary signalling is possible and in this instance it 
corresponds to multi frequency operation, which is widely used. 
Combined Modulation Schemes 
It is perfectly possible to combine the various modulation schemes, a particularly 
common format being combined multiple-amplitude and multiple-phase shift 
keying. Fig. 7.18 provides an illustrative signal space diagram in which the various 
points represent possible signal values. Such a diagram is referred to as a signal 
constellation. The primary motive for using these more complex schemes is that 

0001 
0000 
• 
• 
• 
• 
0011 
0010 Illustrative 
• 
• 
• 
signal vector 
• 
• 
• 
• 
• 
• 
• 
• 
Fig. 7.18 Signal constellation for a simple combined amplitude and phase 
digital modulation scheme. 
they make it possible to achieve a high data rate on a narrowband channel. Broadly 
speaking, the bandwidth required is related to the symbol rate while the data rate is 
the symbol rate multiplied by the number of bits per symbol. Hence, if a constella-
tion contains 2N points, corresponding to N bits per symbol, a data rate of NIT 
bitls is achieved while signalling at lITbaud over a channel with a bandwidth of 
the order of liT Hz. 
Summary 
Various aspects of digital communication have been discussed. We began with a 
description of baseband digital transmission principles and showed how the signal 
is related to the data sequence being transmitted. The undesirable phenomenon of 
intersymbol interference was described and the eye diagram was introduced as a 
convenient and practically useful means of assessing lSI. Some aspects of signal 
design for low lSI were discussed briefly. Error probability was introduced as a 
measure of performance and the process whereby additive Gaussian noise may 
induce errors was described and quantified. Discrete channel models allowing for 
finite error probability were discussed. 
Several facets of coding for digital transmission were discussed: Source coding 
involves removing unwanted redundancy from messages; error control coding 
involves the controlled introduction of redundancy to protect the message data 
from errors in digital transmission; line coding involves controlled introduction of 
redundancy to match the digital signal to the physical characteristics of the trans-
mission medium (e.g. zero d.c. content) and facilitate synchronization of the 
terminal equipment. Digital signals may be conveyed over a bandpass channel by 
modulating a sinusoidal carrier, and some of the more elementary digital modula-
tion schemes were described. 
Problems 
7.1 A digital transmission system employs a signal element waveform at the input 
to the decision circuit given by 
117 

118 
( ) _ [1 - cos(211"1IT)] 
P 1 -
2(11"111)2 
Show that this provides zero lSI for a binary signalling rate of lITbitis. 
7.2 It is required to check the error performance of an 8 Mbitls binary data trans-
mission system. Approximately how long does it take to make the measure-
ment, with reasonable precision, if the error probability is of the order of 10-1O? 
7.3 Consider a source which produces messages based on three symbols: A, B, C. 
The symbols are found to occur, on average, with relative frequencies A = 0.5, 
B = 0.25, C = 0.25. It is required to encode messages in a binary format; two 
coding schemes are proposed: 
Scheme 1 
A = 01 
B = 10 
C=l1 
Scheme 2 
A = 1 
B = 01 
C = 00 
Show that, on average, a smaller number of bits per message are required for 
scheme 2 than for scheme 1. 
7.4 A digital transmission system uses the (7,4) Hamming code to provide error 
detection and correction with the check digits positioned as shown in Equation 
7.12. If the binary data pattern 1010111 is received determine whether it is 
correct or erroneous and, if the latter, the location of the error. 
7.5 A combined amplitude and phase modulation scheme has the signal constella-
tion shown in Fig. 7.19. Determine (i) the maximum number of bits which can 
be represented by each symbol; (ii) the signalling rate required to achieve an 
information rate of 64 kbitls; and (iii) the approximate transmission band-
width required. 
• 
• 
• 
• 
• 
• 
• 
• 
• 
• 
• 
• 
Fig.7.19 Signal constellation for Problem 7.5. 

Systems Case Studies 
8 
o To illustrate the technique and principles discussed in previous chapters with 
Objectives 
reference to specific systems of practical importance. 
o To describe the system adopted in the UK for FM monophonic and 
stereophonic sound broadcasting. 
o To describe the monochrome and colour television systems adopted in the 
UK. 
o To show how the design of a television system is strongly influenced by the 
characteristics of human vision. 
o To describe briefly some of the multi-media telematic services such as 
videotex -
encompassing teletext and viewdata systems -
and facsimile. 
In this chapter several illustrative communication systems are examined in some 
detail. The particular examples included here have been chosen both for their 
practical importance and because they provide useful illustration of the various 
techniques and principles discussed earlier. 
Broadcast FM Radio 
FM radio broadcasting in the United Kingdom is concentrated in the VHF region 
of the spectrum, based on carrier frequencies in the range 88 MHz to 97.6 MHz. 
Other carrier frequencies are used elsewhere in the world and to allow for this a 
receiver usually tunes from 88 MHz to 108 MHz. Radio stations are assigned 
carrier frequencies at 200 kHz intervals within this band. Signals received beyond 
the line of sight distance are weak and prone to fading and this, together with the 
characteristic of FM receivers to suppress weak interfering signals in the presence 
of a strong intended signal, serves to define the transmitter broadcast area. In allo-
cating channels (operating carrier frequencies) due account is taken of the geo-
graphical distribution of transmitting stations together with the transmitter broad-
cast area. A carrier stability of not worse than 0.002070, approximately 2 kHz, is 
required by international agreement. 
Monophonic FM radio provides for high quality audio signal reception with a 
message bandwidth extending to 15 kHz. A peak frequency deviation of75 kHz is 
employed so that the required receiver bandwidth, by Carson's rule, is given 
approximately as follows: 
BT = 2(Jd + W) = 2(75 + 15) kHz 
= 180 kHz. 
(8.1) 
Hence with a 200 kHz channel spacing there is a guard band of 20 kHz between 
adjacent channels to allow for imperfect filtering. 
In the receiver, a relatively high IF of 10.7 MHz is commonly employed to 
ensure good image channel rejection. Ceramic or other high selectivity filters may 
Carson's rule for FM system 
bandwidth is discussed in 
Chapter 3. 
119 

FDM is discussed in Chapter 3. 
See Chapter 4 for a discussion 
of receiver principles. 
120 
Suppressed 38 kH, 
Pilot 
subcarrier 
tone 
I 
/ 
L+R 
L -
R 
L -
R 
(LSB) 
(USB) 
f(kt) 
o 
15 
19 
23 
38 
53 
Fig. 8.1 
Composite stereo baseband signal spectrum. 
be incorporated in the IF stage to provide good adjacent channel rejection. Alter-
natively, a double conversion superhet receiver may be employed with a first IF at 
10.7 MHz to facilitate image channel rejection and a second IF at 465 kHz to facil-
itate adjacent channel rejection. 
FM Stereophonic Broadcasting 
Stereophonic reproduction of sound makes use of two audio channels, designated 
left (L) and right (R). For stereophonic broadcasting the two audio signals need to 
be combined in such a way that following transmission to the receiver they can be 
separated for presentation to two disjoint audio amplifier-and-Ioudspeaker 
systems. Also, when the FM stereo system was being devised there was -
and 
indeed still is -
a requirement that the stereo signal should be compatible with any 
existing monophonic receivers. This was accomplished by providing at the trans-
mitter a composite baseband signal of the form shown in Fig. 8.1. This is essen-
tially an FDM signal comprising (L + R) and (L - R) signals together with a 
19 kHz pilot tone. The combined left plus right signals, corresponding to a mono-
phonic signal, are concentrated in the frequency range below 15 kHz. This is 
termed the sum signal, L + R. A difference signal, L - R, is produced and, with 
the aid of double sideband suppressed carrier modulation, is translated to the fre-
quency range 23 kHz-53 kHz. It is centred on the (suppressed) carrier frequency 
of 38 kHz. The latter is referred to as a subcarrier of 38 kHz to distinguish it from 
the FM carrier frequency used for transmission. A low-level 19 kHz signal in phase 
synchronism with the suppressed 38 kHz subcarrier is introduced. This is termed a 
pi/ot tone and is provided to facilitate detection of the DSB-SC L - R signal. The 
composite stereo signal is thus an FDM signal comprising the (L + R) and (L - R) 
signals together with a 19 kHz pilot tone. It occupies the frequency range up to 
53 kHz and may be treated as a composite baseband message signal. It may thus be 
frequency modulated in the normal way on to a VHF carrier. Once again, a peak 
deviation of 75 kHz is employed. An illustrative FM stereo encoder is shown in 
Fig. 8.2. 
At the receiver the composite signal is first recovered by using conventional FM 
receiver principles. The receiver bandwidth required is slightly greater for stereo 
than for mono since the composite baseband message has a bandwidth of 53 kHz 
compared with 15 kHz for a mono audio signal. Applying Carson's rule: 
BT stereo = 2(fd + W) 
= 2(75 + 53) kHz 
= 256 kHz 

R 
L 
38kHz 
Composite 
baseband 
signal 
. Voltage to 
E 
frequency 
conversion 
FM 
Frequencey 
translation 
1.o.. ___ 
.J signal ...... _--
38 kHz 
Frequency 
oscillator t---+--..j .,. 2 
Fig. 8.2 FM stereo encoder and transmitter. 
FM 
signal 
at Fe 
Note that this is slightly greater than the normal channel spacing for FM radio, so 
care is needed when allocating channel frequencies to transmitters in the same geo-
graphical locality. Following FM detection of the composite signal, it must then be 
decoded and the separate Land R signals recovered. There are various methods 
whereby this can be achieved; one is illustrated in Fig. 8.3. In this method the 
L + R signal is recovered by way of a 15 kHz lowpass filter, as in a mono receiver. 
A bandpass filter centred on 38 kHz and passing signal frequencies in the range 
23 kHz to 53 kHz separates out the DSB-SC signal carrying L - R information. 
The L - R signal is then recovered by synchronous detection and lowpass filtering, 
as discussed in Chapter 3. This makes use of a phase synchronous 38 kHz local 
oscillator, phase synchronism being achieved by phase locking to the pilot tone a 
19 kHz signal derived from the local oscillator. The separate left and right channel 
signals are then obtained by adding and subtracting the (L + R) and (L - R) 
signals: 
(L + R) + (L - R) = 2L 
(L + R) - (L - R) = 2R 
Recovered 
composite 
baseband 
FM 
FM 
signal 
signal 
receiver 
at Fe 
LPF 
15 kHz 
BPF 
38± 
15 kHz 
BPF 
19 kHz 
L+R 
DSB-SC 
L -
R 
Signal 
Frequency 
x2 
LPF 
15 kHz 
Fig. 8.3 
FM stereo receiver and decoder. 
(8.2) 
+ 
2L 
2R 
The effectiveness of a stereo system depends on the separation achieved between 
the two channels. Slight imbalances in signal levels tend to result in some crosstalk 
between left and right channels. Separation can be improved by matrixing the two 
signals, as shown in Fig. 8.4. If the decoded signals are expressed as 
121 

L' = L + aR 
----~~-----------; 
R'=R+~~b~L __ ~ 
__________ ~ 
L"=L(1-ab) 
)----
R" = R (1 - ab) 
}----
Fig. S.4 Matrix to improve stereo separation. 
L' = L + aR 
R' = R + bL 
(S.3a) 
(S.3b) 
where a,b« 1 represent crosstalk, a multiplied by Equation S.3b is subtracted 
from Equation S.3a and b Equation S.3a from Equation S.3b to obtain 
L" = L + aR - a(R + bL) 
= L - abL = L(1 - ab) == L 
R" = R + bL - b(L + aR) 
= R - abR = R(1 - ab) == R 
(S.4a) 
(S.4b) 
The matrix may also allow for any differences in level between the decoded left and 
right channel signals. It should be noted, however, that the crosstalk is generally 
frequency dependent so perfect separation is not obtained with a frequency 
independent matrix of the form shown above. 
Exercise 8.1 
A stereo decoder of the form shown in Fig. 8.3 is found to produce poor separation. On 
investigation it is found that the 38 kHz local oscillator in the receiver has a phase error of 
50. Suggest a matrixing scheme to correct for this and determine appropriate settings for the 
adjustable parameters. 
CCIR (Comite Consultatif 
International de 
Radiocommunications) -
International Consultative Radio 
Committee. 
122 
Television Systems 
This section begins with an examination of monochrome, or black-and-white, tele-
vision principles. This is done not so much because monochrome systems are less 
complex than colour systems -
although that is certainly the case -
but because 
the monochrome system came first and the design of a colour system was thus 
influenced by the need for compatibility with existing monochrome receivers. And 
indeed, this requirement still exists since small monochrome receivers are still 
produced and sold in large quantities owing to their considerably lower complexity 
(and hence price) and great portability compared with colour receivers. In this 
respect the development of television parallels that of FM broadcast radio dis-
cussed earlier in which the stereophonic system is required to be compatible with 
the lower complexity/cost monophonic receivers. 
The specific descriptions of television principles presented here relate to systems 
in use in the United Kingdom, which conform to CCIR recommendations. Slightly 
different schemes have been adopted in some other parts of the world (notably the 
United States of America) but these differences are largely of implementation 
rather than of fundamental principle. 

Monochrome Television 
A visual scene may be mapped into an electrical signal waveform by way of a raster 
scanning process, as illustrated in Fig. 8.S. Generally this is achieved by imaging 
the scene on to a photosensitive surface which is continuously scanned by an 
electron beam. A current is detected with intensity dependent on the brightness of 
the image at each point in the scanned field, and this current forms the electrical 
signal. Note that the scanning process provides for the mapping of two-
dimensional information (a picture) on to a one-dimensional coordinate (time). At 
the receiver an inverse process is employed -
scanning is used to convert the one-
dimensional signal into a two-dimensional field. The displayed picture inevitably 
contains a line structure associated with the scanning process. Also, since it is 
required to transmit moving pictures the scanning process must be repeated over 
and over again -
one frame at a time -
so that the observer is presented with a 
rapid sequence of pictures. The acceptability of this form of signal encoding 
depends ultimately on the characteristics of the human vision system. The 
eye-brain system interprets a sufficiently rapid sequence of incrementally changing 
pictures as continuous motion and provided the lines are sufficiently close together 
the limited spatial resolution of the eye will render these non-visible. Broadly 
speaking we conclude that a good television system would have very closely spaced 
scanning lines and would present picture frames in rapid succession. On the other 
hand in the interests of spectral efficiency it is required that the encoded signal 
occupies as small a bandwidth as practicable. These two requirements -
accuracy 
of representation versus spectral efficiency -
are such that a compromise is 
required. Systems are designed such that the signal bandwidth is as small as 
possible given the need for a subjectively acceptable picture display. 
The elimination of discernable flicker requires some 40 to SO frames per second 
while at desirable viewing distances about SOO raster lines per picture are required. 
The total number of scan lines employed is 62S but not all of these are displayed 
since time is required for the scanning spot to return to the top of the screen before 
beginning a new picture. Also, in practice an interlaced scanning arrangement is 
employed in which every other line is first displayed and the scanning spot then 
Solid black image 
on uniform background 
Line fly baC:k--S~~~~~=: 
Field fly back 
Background 
grey level 
Black level 
a 
I 
I 
I 
: 
I:: 
J 
I 
I 
I 
1 ___ I t_J 
.. 
~------~ 
:s:;-_____ ~ -_-_-_-~ 
----
-- Scan lines for field 1 
- - - - Scan lines for field 2 
-
- -
Field fly backs 
b 
Fig. 8.S Raster scanning principles. (a) Simple scanning raster and video 
waveform corresponding to a single line. (b) An interlaced scanning 
arrangement. 
See Pearson, D.E., Transmission 
and Display of Pictorial 
Information, Pentech Press, 
1975, Chapter 2. 
123 

124 
returns to the top of the screen to fill in the gaps on a second pass. There are thus 
two fields per complete picture or frame. An interlaced scan is illustrated in 
Fig. 8.5b. With this arrangement a complete picture is displayed once every 1I25th 
of a second (25 Hz frame rate) yet, with the 2: 1 interlace giving a field rate of 
50 Hz, picture flicker is acceptably slight. 
From the above it can be deduced that every line must be scanned in (1/25)/625 
seconds, giving a line rate of 15.625 kHz. Time must be allowed for the spot to fly 
back from the end of one line to the beginning of another so the active line time is 
only about 52 microseconds. The bandwidth required for a television signal can 
now be estimated by assuming that the horizontal resolution is required to be com-
parable to the vertical resolution as set by the number of lines per picture. Allowing 
for the usual 4 : 3 width to height aspect ratio of a television display and noting that 
some 50 lines per picture are allocated to frame flyback the process is as follows: 
The picture is viewed as made up of a rectangular array of picture elements or pels. 
The vertical separation between pels is set by the number of active lines 
(625 - 50) = 575 and for equal vertical and horizontal resolution we need a similar 
horizontal spacing. Thus approximately 575 x 4/3 pels per line are required and 
these must be displayed in the active line time of 52 microseconds. The effective 
time separation between pels is 
tp = 52 x 10-6/(575 x 4/3) = 68 ns 
corresponding to a rate of 11(68 x 10-9) = 14.7 x 1Q6pels per second. The question 
now arises: what bandwidth is required to be able to transmit pels at this rate? By 
considering sequences of alternating black and white pels along a line, as shown in 
Fig. 8.6, it can be concluded that the highest fundamental frequency encountered 
is given by 
fmax = 1/(211"tp) = 7.3 MHz 
Now the average picture brightness corresponds to a d.c. signal so there is a tempta-
tion to conclude that faithful reproduction of a television signal requires a band-
width extending from 0 to 7 MHz. In fact this is rather pessimistic. An alternative 
estimate can be based on risetime considerations. Let tp correspond with the 100/0 to 
90% risetime of a first-order system with time-constant 
tp = 2.27 
a 
Fig. 8.6 Determining horizontal resolution. (a) Vertical black and white bars 
with separation equal to 1 pel; (b) video waveform for a single line. 

Fig. 8.7 Spectrum of a television signal. (a) Wide scan showing bandwidth 
requirement; (b) detail showing structure at line rate of 15.625 kHz. 
But the 3 dB bandwidth of such a system is given by 
B = 11(271"7) 
Hence 
B = 2.21(271"tp) = 5.1 MHz. 
This might be expected to be an underestimate since filters with a rather sharper 
cut-off are generally involved. In practice a bandwidth of 5.5 MHz is employed 
and found acceptable. It may also be noted in passing that the scanned origin of the 
signal results in a far from uniform distribution in frequency space. Power is 
concentrated in the vicinity of multiples of the 15.625 kHz line rate as shown in 
Fig. 8.7. 
Timing information is combined with the television signal to enable the receiver 
to obtain proper line and field synchronization. The resultant composite video 
signal is shown in Fig. 8.8. The line synchronizing pulses are of 4.7 microseconds 
duration and occur once every 64 microseconds during the active picture time. A 
more complicated synchronization pattern is employed during the field flyback 
interval to allow for interlacing and provide for relatively simple synchronization 
circuitry within the receiver. 
Colour Television 
Colour television relies on the principle of additive colour mixing. The wide range 
of colours required for faithful reproduction of a colour scene can be obtained by 
adding together appropriate contributions of the primary colours: red (R), blue (B) 
and green (G). The same principles of scanning and interlacing are employed as for 
monochrome systems but now three separate photosensitive surfaces are required 
in the television camera; one for each primary colour. A colour separation optical 
assembly is employed to direct the R,G,B components in a scene to the appropriate 
camera tube. The images on these tubes are scanned synchronously so that at each 
time instant R,G,B signals are obtained indicating the amount of red, green and 
blue n;quired at the receiver to reproduce the colour and luminosity at a corres-
A detailed specification for the 
625-line colour television 
system I is provided in the ISA 
Technical Review No.2, 
September 1972. 
125 

See Pearson, D.E., Transmission 
and Display of Pictorial 
Information, Pentech Press, 
1975, Chapter 8. 
126 
ponding point in the image. There are now three related video signals to be trans-
mitted and to do this using separate channels for each signal, each having the same 
bandwidth as for monochrome television, would require a total bandwidth of 
3 x 5.5 MHz = 16.5 MHz. Fortunately it is possible to combine the signals, 
effecting considerable bandwidth economy and at the same time achieving com-
patibility with monochrome receivers. The first step is to produce a luminance 
signal Y corresponding to a weighted sum of the R,G,B components. The weight-
ing employed takes account of the relative luminous efficiencies of the different 
colour phosphors used in television display tubes. For the purposes of illustration, 
however, assume a simple summation: 
This luminance signal is the required video signal for monochrome display. The 
chrominance (i.e. colour) information is then represented by colour difference 
signals: R - Y and B - Y. There are still three signals to transmit but one of them 
now corresponds to the monochrome signal required for compatibility. Next, if the 
bandwidth required for colour as opposed to luminance information is considered, 
it is found that a considerable reduction is possible. 
A - 3 dB bandwidth of only 1.3 MHz is employed with chrominance signal level 
gradually reducing to - 20 dB at 4 MHz. 
It is now required to combine the three signals: 
Y 
luminance, 5.5 MHz bandwidth 
R - Y 1 [COlOUr difference signals, 
= 
1.3 MHz bandwidth, 
B - Y 
gradual roll-off 
and form a composite video signal such that luminance and colour difference 
signals can be recovered for colour display, yet the signal is directly compatible 
with monochrome receivers. To achieve this we first double sideband suppressed 
Fig. 8.8 Monochrome video signal incorporating composite synchronization 
information. 

Luminance 
\ 
2 
3 
a 
Chrominance 
Subcarrier 
4 
5 
6 
f(MH,) 
5.5MH, 
Luminance 
components 
\ 
n 15.625 
b 
! , , , , 
III ,,, 
"' 
i:::1 
11111 
11'11 
11111 
Chrominance 
components 
in 'gap' 
(n + 1) 
f(kH,) 
15.625 
Fig. 8.9 Spectrum of composite colour video signal. (a) General view; 
(b) detail showing interleaving of luminance and chrominance components. 
carrier modulate the R - Y component on to a cosine colour subcarrier of 
frequency -4.43 MHz and simultaneously modulate the B - Y component on to a 
corresponding sine subcarrier. These two components are added together to form a 
quadrature amplitude modulated (QAM) signal. The combined signal has the same 
spectral occupancy as each component and yet the individual modulating signals 
(R - Y), (B - Y) are readily recovered using synchronous demodulation with 
appropriately phased carriers. 
The two colour difference signals (R - Y), (B - Y) may be viewed as separate messages 
mt(t) and m2(t) modulated on to quadrature carriers, cos(27fFt), sin(27fFt). Show that the 
messages may be recovered at the receiver provided accurate quadrature carrier replicas are 
available for synchronous demodulation. 
Referring to the previous discussion on monochrome television, recall that the 
spectrum of the· luminance signal is concentrated at multiples of the line rate of 
15.625 kHz with very little signal power at intermediate frequencies. The chromi-
nance sub carrier frequency has been selected such that the modulated chrominance 
signal spectral components fall into these gaps in the luminance spectrum. The 
baseband luminance and chrominance signals may be added to form the required 
composite colour video signal as illustrated in Fig. 8.9. 
In Chapter 3 it was seen that synchronous demodulation of a DSB-SC signal 
requires a carrier replica to be available at the receiver. This carrier replica must 
have not only the correct frequency but also the correct phase relationship to the 
(suppressed) carrier associated with the signal to be detected. With QAM the 
demands on phase accuracy are considerable since an error results in a fraction of 
the R - Y information being demodulated as B - Y and vice-versa. This would 
give rise to colour (hue) errors in the displayed picture. To ease these difficulties an 
accurate subcarrier reference is transmitted as a short burst at the beginning of each 
line. The oscillator in the receiver uses the burst as a reference to correct for any 
phase errors. In addition the phase of the burst is made to alternate on successive 
lines. The details of this phase alternation are not dealt with in this text but note 
simply that it is such that any iesidual phase errors in the channel tend to give rise to 
errors of colour saturation rather than of hue. The latter have been found to be 
subjectively more objectionable than the former. We note also that this phase 
variation on alternate lines gives rise to the usual name for this particular colour 
television system: the PAL system. An illustrative line of a composite colour video 
signal is shown in Fig. 8.10. The varying amplitude and phase chrominance 
information is seen to be superposed on the luminance signal. A monochrome 
Exercise 8.2 
Note: QAM and SSB have equal 
spectral efficiency. A message 
of bandwidth W can be 
transmitted in a passband of 
B = W using SSB while two 
messages each of bandwidth 
WI2 can be transmitted in a 
passband of B = 2 (WI2) = W 
using QAM. 
127 

128 
White 
Chrominance 
subcarrier 
burst 
\ 
Black 
Sync level 
, , 
I 
, 
I 
I 
!.. __ J , , 
I 
Colour bars 
(various amplitudes and 
I 
/ phases of chrominance subcarrierl 
..... --, 
, 
I 
I 
.--, 
: 
: 
~--~ 
Luminance 
: i%,' signal 
I 
r--' 
I 
I 
I 
I 
' 
I 
I 
, 
I 
I , 
L __ J 
I 
L __ ~ 
" 
, 
L __ -I 
I 
, , 
, 
I 
' 
, 
____ 1 ___ _ 
~I·----- 64p.slinetime -----+1.1 
Fig. 8.10 Composite video signal for a colour bar display. 
receiver essentially responds to just the luminance component although the 
chrominance subcarrier components do sometimes give rise to visible patterning, 
depending on picture content. A colour receiver, on the other hand, can separate 
luminance and chrominance signals using a delayline filter and recover the individ-
ual colour difference signals R - Y, B - Y using synchronous detection. Having 
recovered Y, R - Y and B - Y, three separate signals R' ,G' ,B' can be produced 
corresponding approximately to the original R,G,B signals but modified by the 
different bandlimiting applied to the luminance and colour difference signals. 
These R' ,G' ,B' signals are then used to control the currents in three separate 
electron beams within a television display tube. Each is directed to fall on 
phosphors of the appropriate colour on the face of the tube as shown schematically 
in Fig. 8.11. 
R 
Colour 
G' 
signals 
B 
Electron 
beams 
Electron 
guns 
ed 
reen 
Blue 
Shadow mask 
ensures beams 
fall on correct 
colour phosphor 
regions 
3-colour 
\ / 
phosphar 
\ 
screen 
Fig. 8.11 
Principle of a colour television display. 
Broadcast Television Transmission 
For both monochrome and colour television the video signal is essentially lowpass 
occupying the band If I < 5.5 MHz. In view of this large message bandwidth a spec-
trally efficient modulation scheme is required; double sideband amplitude modula-

Vision 
carrier 
Chrominance 
sub-carrier 
: 
Sound 
I 
carrier 
~1.3:-
Luminanc~~~ : 
" 
, I 
,r'Chrominancet 
~~::plus 
I 
/," '<Luminance 
• 
,<: , 
,I 
- 2 :-1 
1 
2 
3 
4 
5: 6 
-11.251+---- 5.5 MH,------+i 
I 
' 
1---8 MH, channel---·i 
a 
b 
Vision 
Sound 
carrier 
carrier 
I 
I 
I 
5.5 MH,----+I 
Fig. 8.12 Spectral occupancy of a broadcast television based on 
asymmetric/vestigial sideband modulation. (a) Transmitted ASB television 
signal plus sound in 8 MHz channel; (b) receiver response to provide ideal VSB 
signal. 
tion would require a transmission bandwidth of at least 11 MHz per television 
channel. Note" however, that the signal contains a d.c. component corresponding 
to the average brightness of the picture. This suggests that a single sideband 
modulation (SSB) scheme cannot be employed since with SSB d.c. and very low 
frequency components in the message are removed by the sideband filter. The 
solution lies in the use of an asymmetrical sideband (ASB) amplitude modulation 
scheme in which most but not all of the lower sideband is removed at the trans-
mitter, as shown in Fig. 8.12a. At the receiver skew symmetric filtering about the 
carrier frequency is employed to produce a vestigial sideband (VSB) signal as 
shown in Fig. 8.12b. Note that the carrier and any d.c. components in the video 
message signal are accommodated at half-amplitude. If such a signal is synchro-
nously detected the message waveform is recovered undistorted -
the low 
frequency attenuation of the upper sideband is compensated by the attenuated 
residual (vestige) lower sideband. In practice even if envelope detection is 
employed the distortion is not too severe since a strong carrier signal is present. The 
associated sound signal is conveyed using frequency modulation of a separate 
sound carrier located 6 MHz above the vision carrier. The combined modulated 
sound and vision signal thus occupies a bandwidth of 8 MHz per channel. 
Videotex Systems 
Videotex systems employ alphanumeric characters and graphics on a television 
type display to provide for data retrieval. An illustrative segment of a videotext dis-
play is shown in Fig. 8.13. A black and white presentation is adopted here but in 
practice full colour displays are employed. The display is based on a rectangular 
array of character cells arranged to fill the screen; data stored within the videotex 
terminal governs the character or graphic symbol displayed at any given location 
on the screen and also the use of different colours within the display. There are 
essentially two general classes: teletext and viewdata. The former is based on 
broadcast television while the latter involves the use of two-way communication 
These are examples of te/ematic 
services based on a judicious 
blend of computer and 
communications techniques. 
129 

130 
Fig. 8.13 
A videotex display. 
over the switched telephone network. In the UK two hardware compatible teletext 
systems known as CEEFAX and ORACLE are operated by the television broadcasting 
stations and a viewdata service known as PRESTEL is provided by British Telecom. 
Only these systems are considered here, although it should be noted that various 
different schemes are in use or under investigation in other countries. 
Teletext (Broadcast Videotex) 
Teletext is a data broadcasting system in which information is carried by bursts of 
digital signals added to a television video signal. Alphanumerics and graphics are 
used in conjunction with a television receiver to provide for selective display of 
information as requested by the user. It is a one-way information system in which a 
sequence of pages of information are sent repetitivily. The user indicates the 
address of the page he wishes to view by entering the code on a small hand-held key-
board and must then wait until this page appears in the transmitted sequence so 
that his receiver can capture and display it. A page comprises 24 rows of 40 charac-
ters, induding a special top row called the page header. This contains address and 
control data to identify the page and to control its display; it is also used to display 
general information such as the time, date, page identity, and so on. The rate at 
which pages can be transmitted depends on how many of the 26 potentially avail-
able spare television lines are used for teletext data. When first introduced the 
system used two lines per field (four per picture) and could then transmit four full 
pages per second. The system constitutes a form of electronic magazine giving con-
tinuously updated news, stockmarket reports, etc. and can also provide subtitles 
for overlaying on to the normal television picture to help the hard of hearing. We 
will not consider further the various possible applications of the system; nor will we 
detail the display format employed. Rather we concentrate on the signal and 
coding aspects to provide practical illustration of the digital communication 
principles outlined in Chapter 7. 
The data are carried as a non-return to zero (NRZ) baseband binary signal super-

'---------Field blanking interval (25 lines)--------------i 
1------- Available lines for teletext -------+1"1 
I 
Teletext Ttl 
I 
I 
I data i . es 
I 
I 
I 
I lines I signals I 
I 
I 
I 
I 
I 
I 
I 
I 
320 
Fig. 8.14 Teletext data lines in field blanking internal. 
posed on otherwise unused lines, outside the active picture time, during the field 
flyback intervals. The relationship between the bursts of data and the normal tele-
vision signal is shown in Fig. 8.14. The data signal is bandlimited so that the time 
domain data pulse and its spectrum are approximately as shown in Fig. 8.15. Note 
that the spectrum has skew symmetry about the Nyquist frequency (3.47 MHz) of 
one half the signalling rate (6.94 MHz). This is to minimize intersymbol interfer-
ence (isi) as discussed in Chapter 7. 
Each data line contains 360 bits of information organized as 45 8-bit bytes. Each 
line begins with a synchronization pattern: there are 16 bits (2 bytes) of alternating 
ones and zeros, 101010 ... , to ease bit-clock synchronization and these are 
followed by a single byte framing code, 11100100, which provides for byte 
synchronization. This allows the receiver to determine whether a particular bit is, 
for example, the last bit of the nth byte or the first bit of the (n + l)th byte. These 
first three bytes have even parity; the total number of ones is even. The remaining 
42 bytes in a line use odd parity and carry address, control and information 
character data. The use of odd parity ensures that the maximum interval between 
data transitions is 14 bits. This is essentially a simple form of line code which eases 
the recovery of bit-clock from data, as discussed in Chapter 7. 
It is especially important that address and page control data be received correctly 
since the user selects information by address and the page control data determines 
- 2T 
- TOT 
T == 144 ns 
a 
, 
0+--+---<-+-+ -.+---+--=--0--0_ 
2T 
t 
0 
2 
3: 4 
5 
6 f(MH,) 
1 
2T 
b 
Fig. 8.15 Teletext data pulse and spectrum. (a) Data plus shape; (b) spectrum 
of data pulse. 
131 

132 
how the information is presented on the television screen. Consequently error 
detection and correction coding is employed for these data items. This is based on a 
Hamming code in which each byte contains four message bits and four protection 
bits. This allows for the correction of both single-bit and multiple-bit errors. If 
multiple-bit errors are detected then the message is rejected and the receiver waits 
for its next occurrence in the data sequence. 
Perhaps the greatest limitation of teletext is that, being a non-interactive, broad-
cast system, the average time required to access a page increases with the number of 
pages included in the transmission sequence. There is thus a definite practical limit 
to the volume of data to which the user can be given access if the waiting time 
following page selection is not to be too great. This problem does not arise with a 
viewdata system. 
Viewdata (Interactive Videotex) 
Viewdata is a two-way information system based on a combination of television 
display, local storage and processing, together with access to a remote data store 
via the public telephone network. Since a two-way communication channel is avail-
able each user is able to select specific information and only this specifically 
requested information is transmitted to the user. As a result the amount of 
information to which the user can be given almost immediate access is practically 
unlimited. The information pages stored in the remote database are accessed via a 
tree search procedure which allows the user to penetrate to increasing levels of 
detail, as illustrated schematically in Fig. 8.16. 
In the UK similar data formats and coding schemes have been adopted for view-
data and teletext in the interests of maximum hardware compatibility. The differ-
ences lie in the way in which the user selects the information to be displayed and in 
how the information is conveyed to the user's premises. The public switched 
telephone network provides an essentially analogue communication channel to the 
user, even if digital transmission is employed within the network itself. Conse-
quently some form of digital modulation is required. This is provide by a data 
modem (modulator and demodulator) incorporated in the user terminal. Data 
transmission is effected at a rate of 1.2 kbit/s using frequency shift keying. 
I 
Telephone 
directory 
__ --1- __ 
Entry point 
(main index) 
I 
I 
News 
__ --.l __ 
Finance 
__ ..L __ 
USA 
I 
I 
People 
Air 
I 
British 
Airways 
I 
Express 
I 
I 
Travel 
I 
I _n 
TWA 
Fig. 8.16 Segment of tree-structured database. 

Since data transfer is user specific, viewdata can in principle provide an elec-
tronic mail facility; messages directed to a particular user or group of users can be 
stored until that user makes a call into the system, identifies himself or herself and 
requests messages. This emphasizes once again the major difference between 
teletext and viewdata. Teletext, being a broadcast system, is well suited to the trans-
mission of a limited volume of information to which a large number of users 
require access. Viewdata on the other hand is discriminatory: it provides for user 
interaction so that data can be selectively directed to specific locations. 
Facsimile 
Facsimile provides a means of transmitting information directly from a printed, 
drawn or handwritten page and is seen as an important facet of the evolving 'elec-
tronic office'. It offers the prospect of an electronic mail service in which the need 
to physically transport letters, documents, and so on, is avoided by electronically 
transmitting their contents and regenerating the documents at the receiver. It 
makes use of a scanning system to effect the requisite two-dimension to one-
dimension mapping at the transmitter and similarly for the inverse operation at the 
receiver. In this respect it is broadly similar to television but only static images are 
involved so there is no need for frequent re-scanning to accommodate motion and 
avoid flicker. A document is scanned just once, transmitted and reproduced at the 
receiver. There is thus no fundamental restriction on the length of time taken to 
scan a page and very high spatial resolution can be achieved over a limited band-
width channel. 
Most facsimile communication makes use of the public switched telephone 
network and there are a variety of equipments available. The simplest of these 
(Group 1 machines) provide a resolution of 3 .85lines/mm and use analogue trans-
mission based on double sideband amplitude modulation of a 1.3 kHz or 1.9 kHz 
carrier. They require some 6 minutes to transmit an A4 page. Some improvement is 
provided by Group 2 machines which make more effective use of the available 
telephone channel bandwidth by using vestigial sideband modulation of a 2.1 kHz 
carrier. This reduces the transmission time to about 3 minutes. Group 3 machines 
on the other hand are digital. Only black and white documents are transmitted and 
various coding schemes are adopted to reduce the number of bits required to 
describe the document. A resolution of 7.7 lines/mm is provided and a trans-
mission rate of 4.8 kbitls is employed. Coding is performed on a one-line-at-a-
time basis and the transmission time required for a line depends on the information 
density in that line. As a result the transmission time depends on the type of 
document involved but typically an A4 page can be transmitted in less than one 
minute. 
A coding scheme which can be used to reduce the number of bits required to 
describe a document is considered as follows: The document is scanned and a 
sequence of black and white picture elements is encountered; these are represented 
by 1 s and Os respectively. These occur in the form of runs of Os separated by runs of 
Is. Rather than transmit the Is and Os as such, the length of each run of Is and Os 
occurring along each line can be transmitted. This is referred to as run-length 
coding. It makes use of the fact that there is a high degree of correlation between 
adjacent pels: a 0 is much more likely to be followed by another 0 than by a 1 since 
most documents consisting of printed or written material are predominantly white 
space. The general principle of run-length coding is illustrated schematically in 
133 

134 
Data 
sequence 
Run 
lengths; 
11 runs 
,. 
100 pels 
., 
, 
, 
: 
'" 1 00 bits uncoded 
: 
: 
\ White 
, 
U 
lIlll 
Ln Black 
, 
, 
, 
' 
1--20__51---30------+l1-10~1__19__15151 
2//\ 
\ 
2 1 
1 
Fig. 8.17 Principle of run-length coding. A fixed 5-bit code per run (maximum 
run 32 pels) == 55 bits. 
Fig. 8.17. This provides a practical illustration of the general principle of source 
coding outlined in Chapter 7. Essentially a notional mathematical model is con-
structed for the source which takes account of the structure in the data as deter-
mined by the type of documents required to transmit. The coding scheme is in some 
sense matched to the source model and so reduces the number of bits required to 
represent messages from the source. 
One of the consequences of employing source coding is that the messages 
become less tolerant of transmission errors. For an uncoded picture an isolated bit 
error would affect just one pel but with a run-length coded picture a single bit error 
changes the length of a run and so corrupts all subsequent pel information on that 
line. Error control coding can be used to alleviate these difficulties. It may at first 
sight seem odd that having reduced the redundancy with the aid of source coding it 
is now proposed to put back redundancy in the form of channel coding. However, 
by doing this an overall benefit can be achieved. The redundancy required in the 
error control code to achieve adequately reliable transmission is small compared 
with the redundancy reduction provided by the source coding operation. The 
reduction in the number of bits required to be transmitted as a result of the coding 
operations depends on the type of document and ranges from 17 : 1 for business 
letters and diagrams to 5 : 1 for very dense text. Other more efficient coding 
schemes are under investigation but the above should suffice to enable the 
principles and prospects to be appreciated. 
Summary 
In this chapter we have described a number of practical communication systems. 
These are important in their own right but serve also to illustrate further the 
principles introduced previously. Broadcast FM radio provides an illustration of 
frequency modulation while stereophonic FM broadcasting involves also double 
sideband suppressed carrier (DSBSC) modulation and frequency division multi-
plexing (FDM) principles. Television has been seen to involve a scanning process, a 
2-D to I-D mapping operation, to translate the message (the scene or picture) into 
an electrical signal (the TV waveform). Colour television has been seen to make use 
of DSB-SC and quadrature amplitude modulation (QAM) techniques and to 
exploit the line structure of the TV signal spectrum to allow colour and luminance 
information to be combined in a limited bandwidth of approximately 6 MHz. TV 
transmission makes use of vestigial sideband modulation in the interests of spectral 
economy. 

The combined use of television, computer database, and digital transmission 
techniques to realize both broadcast and interactive videotex system has been dis-
cussed. These provide examples of 'Telematic' systems -
i.e. information systems 
involving a judicious merging of computer and communication techniques. 
Finally, another telematic service, facsimile, was considered. Modern, digital 
facsimile systems make use of run-length coding to remove redundancy from the 
message. This provides a simple, practical illustration of source coding. 
135 

136 
Appendix 
Decibels 
The decibel is a logarithmic measure used for comparing two power levels, say PI 
and P2. The power ratio P2/ PI may be expressed in decibels (dB) as 
(A.I) 
We can then say that the power level P2 is x dB relative to PI' Note that since 
10g(I) = 0, x < 0 implies P2 < PI while x > 0 implies P2 > PI' 
Equation A.I may be rewritten in terms of voltages as follows: If PI corresponds 
to a voltage VI across a resistor RI, and P2 to a voltage V2 across a resistor R2, with 
PI = VI2/RI, P2 = V22/R2, then 
(A.3) 
The decibel is defined in terms of power ratios but it is not uncommon for voltage 
ratios to be expressed in terms of decibels, following Equation A.3. This is strictly 
valid only if RI = R2 although on occasions it may be convenient not to adhere 
rigidly to this condition. 
The logarithmic character of the decibel measure for transfer ratio has an impor-
tant consequence when considering cascade connections of networks. Consider, 
for example, two networks in cascade, as shown in Fig. A.I, such that 
VI = AI Vo 
V2 = A 2 VI 
whence 
and 
(A.4) 

y'U 
A, I y,[ I A, Uy' 
Fig. A.l Two networks in cascade. 
That is, the overall voltage gain is the product of the individual stage gains. Con-
sider now the voltage transfer ratios expressed in decibels: 
AdD = 2010g\O(A IA 2) 
= 20 10g\O(A I ) + 2010g\O(A2 ) 
= AI + A2 
dB 
dB 
That is, we add transfer ratios expressed in decibels for cascade networks. 
(A.S) 
Finally, we note that in communication systems studies it is often convenient to 
express absolute power levels in terms to decibels relative to some fixed power 
reference. For example, the logarithmic measure dBm is used to denote power 
levels relative to 1 mW and since 100 mW is 20 dB (i. e. 100 times) greater than 
1 mW it corresponds to a power level of 20 dBm. For larger power levels dBW, 
taking 1 W as the reference, is employed. Table A.l provides some illustrative 
examples. 
Table A.I Various power levels expressed in 
watts, dBm and dBW 
1 p.W 
= 10-6 W == -30 dBm == -60 dBW 
10 p.W 
= 10-5 W == -20 dBm == -50 dBW 
100 p.W = 10-4 W == -10 dBm == -40 dBW 
1 mW = 10-3 W== 
0 dBm == -30 dBW 
1 W 
= loo W == +30 dBm == 
0 dBW 
10 W 
= 101 W == +40 dBm == + 10 dBW 
137 

l38 
Answers to Numerical Problems 
1.1 (i) 
15 km. 
(ii) 75 dB. 
(iii) 1.6 x 10-14 W == -78 dBm. 
1.2 + 6 dB == 4 times. 
1.3 153 links; use a LAN. 
1.4 4 Mbit/s. 
2.1 (i) 
p(t) + p(t - 2T) + p(t - 4T) + p(t - 5T) + p(t - 7T). 
2.2 (ii) p(t) + p(t - 4T) + p(t - 8T) + p(t - lOT) + p(t - 14T). 
2.2 (iii) x(t) = ~ Cn exp( - j27rnt/T) 
n 
with Cn = ~ sinc(n/3) = sin(7rn/3)hrn 
1 
1 
~3 
Co = 3; C1 = C_1 = 27r; C2 = C_2 = 27r; C3 = C_3 = 0; 
-1 
-~3 
C4 = C_4 = 87r; Cs = C_s = 
107r; C6 = C-6 = 0; 
1 
~3 
C7 = C_7 = 147r; Cs = C s = 167r; C9 = C_9 = o. 
2.3 
Y(f) = X(f) - ~, i.e. Co = 0, no d.c. component. 
00 
(i) xU) = 
~ oU - nT). 
n=-oo 
(iii) X(f) = liT. 
2.5 (ii) X(f) = Tsinc2(jT). 
2.6 25%. 
2.7 (i) 
118. 
(ii) 114. 
1 
2.8 (i) 
Let x(t) = cos(27rt); then X(f) = 2 o(j ± 1), 
3.1 
i.e. Co = 0, C1 = C_1 = ~, Cn = 0 for Inl > l. 
(ii) Sx(f) = i o(j ± 1). 
( ... ) P 
1 
III 
= 2. 
(iv) P = ~. 
(i) 
1 
}-
(ii) 
1 
"9. 

a2 
(iii) --:-::------c:-:-
(2 + a2)" 
For speech - 11101 == 1070. 
3.3 (i) 
Two audio tones at Wm + We and Wm -
We' 
(ii) Single audio tone at Wm + We' 
Here We is the carrier/local oscillator frequency error. For speech the distor-
tion (splitting) of the message spectrum in (i) is subjectively more annoying 
then the translation of the message spectrum in (ii). 
3.4 96 kHz. 
4.1 10. 
4.2 (i) 
98.6 MHz to 118.6 MHz. 
(ii) 109.2 MHz to 129.2 MHz. 
(iii) Close to ° 
dB (input at 88 MHz has image frequency of 109.2 MHz -
this is so close to 108 MHz that there is virtually no image rejection). 
5.1 (a) (i) 
>216 kHz. 
(ii) > 480 kHz. 
(iii) > 106 kHz. 
(b) (i) 
108 kHz. 
(ii) 240 kHz. 
(iii) 53 kHz. 
5.2 -32 dB. 
5.3 (i) 
240 kHz. 
(ii) 240 kHz. 
6.1 (i) 
6.4 MHz. 
(ii) 38.4 Mbit/s. 
(iii) 46.77 dB. 
(iv) 11 MHz, 88 Mbitls, 58.77 dB. 
7.l p(o) = l;p(nT) = ° 
for n integer, n*O. 
7.2 - 35 hours. 
7.3 2 bits/symbol for scheme 1, 1.5 bits/symbol for scheme 2. 
7.4 Erroneous. Correct data = 1010101. 
7.5 (i) 
4 bits. 
(ii) 16 kbaud (16 ksymbols/s). 
(iii) 8 kHz. 
139 

140 
Index 
Accumulated disparity, 114 
Active line time, 124 
Additive noise, 104 
Adjacent channel rejection, 71 
Aerial, 67 
AFC,73 
AGC,68 
Aliassing, 80 
Alternate mark inversion, 113 
AM, 60 
AMI, 113 
Amplitude distribution, 48 
Amplitude distribution of signals, 47 
Amplitude modulation, 53, 61 
Amplitude shift keying, 115 
Analogue speech signal, 20 
Antenna, 11, 67 
Anti-aliassing filter, 81 
Aperiodic signals, 40 
Argand diagram, 32 
ASB,129 
ASCII code, 108 
ASK, 116 
Asymmetrical sideband modulation, 129 
Asynchronous transmission, 98 
Attenuation, 6 
Audio amplifier, 69 
Automatic frequency control, 73 
Automatic gain control, 68 
Average power, 50 
Averaging, 88 
Bandpass filtering, 63, 70 
Bandpass signal, 2, 4 
Bandwidth, 3, 6, 101 
Baseband, 5, 99 
Baseband binary transmission, 99 
Bilateral frequency representation, 31 
Bilateral spectrum, 33 
Binary line codes, ll5 
Binary signal, 2, 26 
Binary symmetric channel, 107 
Block coding, III 
Broadcast FM radio, 119 
Broadcast television, 21,128 
Broadcast videotext, 130 
BSC,107 
4B3T, 114 
Cambridge ring, 18 
Carrier, 53 
Carrier power, 61 
Carrier replica, 55 
Carson's rule, 119 
CCIR,122 
CCITT, 64, 94, 114 
CCITT PCM hierarchy, 95 
CEEFAX,130 
Central switching centre, 17 
Channel, 3 
Channel selection, 67, 69 
Check bits, III 
Chrominance signal, 127 
Clock recovery, 101 
Coaxial cable, 7 
Coding, 107 
Colour difference signal, 126 
Colour television, 125 
Combined modulation schemes, 116 
Communication channel, 4 
Communication networks, 14 
Communication satellite, 63 
Communication signal, 4 
Communication traffic, 17 
Companding, 90 
Composite colour signal, 127 
Composite stereo signal, 120 
Conditional probability, 105 
Continuous spectra, 40, 42 
Contouring, 92 
Conventional amplitude modulation, 53, 
59 
Convolutional coding, III 
Correlation, 109 
Cross-point, 16 
Crosstalk, 6, 7,121 
Database, 132 
Data communication, 18 
Data networks. 18 
dBm,137 
dBW,137 
Decibel, 6, 136 
Decision threshold, 103 
Decision times, 103 
Delta function, 44 
Delta modulation, 93 
Delta-sigma modulation, 94 
Demodulation, 55, 132 
Deterministic signal, 49 
Differential pulse code modulation, 92 
Digital modulation, 115 
Digital transmission, 20, 97: 106 
Discrete channel, 107 

Disparity, 114 
DM,93 
Double-conversion, 73 
Double sideband, 53, 126 
DPCM, 92, 109 
DSB-SC, 54, 63, 77, 127 
DSM,94 
Dynamic range, 69 
Earth station, 20 
EDC, 112 
Effective isotropic radiated power, 13 
E.i.r.p., 13 
Electrical noise, 23 
Electronic mail, 133 
Electronic office, 133 
Envelope detection, 60, 69, 129 
Envelope modulation, 53, 59 
Equalizer, 6, 100 
Error control coding, 109, 134 
Error detection, 110, 132 
Error probability, 104 
Even parity, 110, 131 
Even time function, 36 
Exponential Fourier series, 31 
Extra high frequencies, 5 
Eye diagram, 102 
Facsimile" 133 
Fading, 119 
FDM, 63,119 
FDM hierarchy, 64 
Feedback factor, 74 
Field synchronization, 125 
Filter, 3,41,45,82 
Finite energy signal, 41 
Finite power signal, 41 
First-order filter, 82 
FM, 61, 121 
FM detection, 121 
FM stereophonic broadcasting, 120 
Fourier coefficients, 34 
Fourier integral, 40 
Fourier series, 30, 34 
Fourier synthesis, 24 
Fourier transform, 40 
Fourier transform pair, 42 
Free space propagation, 14 
Frequency, 24, 32 
Frequency deviation, 62 
Frequency discriminator, 74 
Frequency division multiplexing, 62, 120 
Frequency domain, 28, 33 
Frequency modulation, 61, 121 
Frequency response, 102 
Frequency shift keying, 116 
FSK, 116 
Fully connected network, 15 
Fundamental component, 34 
Fundamental frequency, 39 
Gaussian noise, 106 
Generalized function, 44 
Graded index fibre, 10 
Ground wave, 13 
Group switching centre, 18 
Guided wave system, 4 
Hamming code, Ill, 132 
Harmonic component, 29, 34 
Harmonic synthesis, 33 
HDB3,114 
Hierarchical network, 17 
Hi-Fi,62 
High frequencies, 5 
Ideal bandpass filter, 68 
Ideallowpass filter, 45, 56, 89 
IF,70 
IF amplifier, 71 
Image channel rejection, 71 
Image response, 72 
Image signal, 71 
Infinite energy signal, 41 
Information systems, 135 
Instantaneous frequency, 61 
Instantaneous power, 50 
Integrated services digital network, 20, 97 
Interference, 4, 23 
Interlaced scanning, 123 
Intermediate frequency, 70 
International switching centre, 18 
Intersymbol interference, 100, 131 
Ionospheric propagation, 14 
ISDN, 20, 97 
LAN,18 
Landlines, 20 
Lightwave communications, 7 
Linearity, 37 
Line coding, 113 
Line of sight systems, 13 
Line synchronization, 125 
Link-level protocol, 18 
Loading coils, 6 
Local area network, 18 
Local exchange, 17 
Local oscillator, 70, 74, 121 
Local switching centre, 17 
Loudspeaker, 69 
Lower sideband, 54 
Low frequencies, 5 
Lowpass filter, 40, 42, 55 
Lowpass signal, 4 
Luminance signal, 126 
Main switching centre, 18 
M-ary signalling, 116 
141 

142 
Material dispersion, 11 
Matrixing, 121 
Medium frequencies, 5 
Message, 4, 53 
Mixer, 71 
Mixing terms, 70 
Modes, 10 
Modulation, 54 
Modulator, 132 
Modulo-2 addition, III 
Monochrome television, 123 
Monochrome video signal, 126 
Monomode fibre, 10 
Monophonic FM, 119 
Morse code, 108 
Multilevel signal, 27, 115 
Multimode fibre, 10 
Multi-pair cable, 6 
Multiplexing, 4, 17 
Multiplier, 70 
Multi-stage bandpass amplifier, 70 
Negative frequency, 32 
Nodes, 15 
Noise, 23, 99, 102 
Noise waveform, 102 
Non-causal signals, 104 
Non-return to zero, 27 
Non-uniform quantization, 90 
NRZ, 27,130 
Nyquist frequency, 131 
Odd parity, 110 
Odd time function, 36 
Omnidirectional antenna, 11 
Optical communication, 7, 11 
Optical fibre link, 20 
Optical fibres, 7, 11, 20 
Optical frequencies, 4 
ORACLE,130 
Oscillator 70 
Packets, 18 
Packet switching, 20 
Page control, 131 
PAL system, 127 
PAM,77 
Parabolic dish, 12 
Parity, 110 
Parity checks, 110 
PCM, 86, 94 
PCM-TDM,94 
Pel,124 
Periodic signal, 29 
Periodic waveform, 24 
PFM,82 
Phase, 24 
Phase-locked loop, 62 
Phase shift, 38 
Phase-shift keying, 116 
Pilot tone, 120 
Power spectral density, 3, 47 
Power spectrum, 3, 47 
PPM,82 
Predictor, 93 
PRESTEL, 130 
Primary colours, 125 
Probability, 48 
Probability density function, 48, 88 
Protocol, 18 
Protocol layering, 19 
Pseudo-random data, 106 
PSK, 116 
Public switched telephone network, 133 
Pulse amplitude modulation, 76 
Pulse code modulation, 86 
Pulse encoding, 86 
Pulse frequency modulation, 82 
Pulse position modulation, 82 
Pulse spreading, 9 
Pulse width modulation, 83 
PWM,83 
QAM, 126, 134 
Quadrature amplitude modulation, 126 
Quantization, 86 
Quantization error, 86, 89 
Quantizing noise, 87 
Radiation efficiency, 12 
Radio signal, 67 
Radio systems, 4, 11 
Randomness, 48 
Raster scanning, 123 
Ray optics, 10 
Reciprocity, 45 
Rectangular pulse, 24 
Rectangular wave, 38 
Rectangular wavetrain, 28 
Redundancy, 109 
RF amplification, 68 
Rowand column parity checks, 110 
Run-length coding, 133 
Running digital sum, 114 
Sampled data signal, 81 
Sampling, 79, 81, 86, 88, 103 
Sampling theorem, 81 
Satellite, 20 
Sawtooth wave, 49 
Scanning, 123 
Selectivity, 68 
Sideband power. 61 
Signal, 1,3, 13,24,33,46 
Signal design, 102 
Signalling element, 27 
Signalling subsystem, 18 
Signal power, 50 

Signals in the frequency domain, 33 
Signals of arbitrary waveshape, 46 
Signal space, 116 
Signal-to-noise ratio, 87, 90, 106 
Signal-to-quantizing-noise ratio, 88 
Sinc function, 45 
Single sideband 53, 57,129 
Sinusoidal signal, 24 
Sinusoidal wave, 49 
Skew symmetric filtering, 129 
Skin effect, 7 
Slope detection, 62 
Snell's law, 8 
Source, 1, 107, 134 
Source alphabet, 107 
Source coding, 107, 134 
Spatial masking, 92 
S.p.c., 17 
Spectral components, 29 
Spectral efficiency, 58, 62, 123 
Spectral envelope, 39 
Spectral lines, 29, 39 
Spectrum, 29 
Spectrum analyser, 29 
Speech signal, 3 
Square wave, 33,49 
SSB, 129 
SSB-SC, 58, 63 
Star network, 16 
Statistical average, 50, 88 
Step index fibre, 9 
Stereophonic broadcasting, 62 
Stereo separation, 122 
Stored program control, 17 
Subcarrier, 127 
Submarine cable, 63 
Submarine telecommunications, 11, 63 
Subscribers, 18 
Sum check, 110 
Superhet, 70 
Superheterodyne receiver, 70 
Super high frequencies, 5 
Suppressed carrier, 53, 126 
Surface wave, 13 
Switched networks, 15 
Switching centre, 16 
Symbol correlations, 109 
Synchronization, 131 
Synchronous binary data, 100 
Synchronous detection, 121 
Synchronous transmission, 99 
Syndrome, 112 
TDM-PAM,83 
TDM signal, 84 
Telecommunciation network, 4 
Telematic services, 129, 135 
Telephone cable, 6 
Telephone networks, 16 
Telephone speech, 3, 21, 64, 81 
Teletext, 129 
Television signal, 3, 91, 124 
Television systems, 122 
Television waveform, 2 
Time average, 50, 88 
Time division multiplexing, 83 
Time domain, 24 
Time scaling, 25 
Time translation, 24, 37 
Total internal reflection, 7 
Transmission bandwidth, 102 
Transmission errors, 110, 134 
Transmission line, 5 
Transmission plan, 17 
TRF receiver, 69 
Triangular wave, 40 
Tropospheric scattering, 14 
Tuned circuit, 67 
Tuned radio frequency receiver, 69 
Twisted pair cable, 5 
Ultra-high frequencies, 5 
Undersea cable, 21 
Unipolar signal, 27 
Upper sideband, 54 
Very high frequencies, 5 
Very low frequencies, 5 
Vestigial sideband modulation, 129 
VHF,119 
Video signal, 124, 127, 130 
Videotex systems, 129 
Viewdata, 129 
VSB,129 
WAN,20 
Wide area networks, 20 
Wire pair, 5, 20 
Zero isi signals, 104 
143 

