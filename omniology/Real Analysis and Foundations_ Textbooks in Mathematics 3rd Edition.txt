TEXTBOOKS in MATHEMATICS
Real Analysis  
and Foundations
Steven G. Krantz
T H I R D  E D I T I O N

Real Analysis  
and Foundations
T H I R D  E D I T I O N

TEXTBOOKS in MATHEMATICS
Series Editor: Denny Gulick
PUBLISHED TITLES
ABSTRACT ALGEBRA: AN INTERACTIVE APPROACH
William Paulsen
COLLEGE GEOMETRY: A UNIFIED DEVELOPMENT
David C. Kay
COMPLEX VARIABLES: A PHYSICAL APPROACH WITH APPLICATIONS AND MATLAB®
Steven G. Krantz
ESSENTIALS OF TOPOLOGY WITH APPLICATIONS
Steven G. Krantz
INTRODUCTION TO ABSTRACT ALGEBRA
Jonathan D. H. Smith
INTRODUCTION TO MATHEMATICAL PROOFS: A TRANSITION
Charles E. Roberts, Jr.
INTRODUCTION TO PROBABILITY WITH MATHEMATICA®, SECOND EDITION
Kevin J. Hastings
LINEAR ALBEBRA: A FIRST COURSE WITH APPLICATIONS
Larry E. Knop
LINEAR AND NONLINEAR PROGRAMMING WITH MAPLE™: AN INTERACTIVE, APPLICATIONS-BASED 
APPROACH
Paul E. Fishback
MATHEMATICAL AND EXPERIMENTAL MODELING OF PHYSICAL AND BIOLOGICAL PROCESSES
H. T. Banks and H. T. Tran
ORDINARY DIFFERENTIAL EQUATIONS: APPLICATIONS, MODELS, AND COMPUTING
Charles E. Roberts, Jr.
REAL ANALYSIS AND FOUNDATIONS, THIRD EDITION
Steven G. Krantz

TEXTBOOKS in MATHEMATICS
Real Analysis  
and Foundations
Steven G. Krantz
T H I R D  E D I T I O N

CRC Press
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
© 2014 by Taylor & Francis Group, LLC
CRC Press is an imprint of Taylor & Francis Group, an Informa business
No claim to original U.S. Government works
Version Date: 20130524
International Standard Book Number-13: 978-1-4665-8732-8 (eBook - PDF)
This book contains information obtained from authentic and highly regarded sources. Reasonable 
efforts have been made to publish reliable data and information, but the author and publisher cannot 
assume responsibility for the validity of all materials or the consequences of their use. The authors and 
publishers have attempted to trace the copyright holders of all material reproduced in this publication 
and apologize to copyright holders if permission to publish in this form has not been obtained. If any 
copyright material has not been acknowledged please write and let us know so we may rectify in any 
future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, 
transmitted, or utilized in any form by any electronic, mechanical, or other means, now known or 
hereafter invented, including photocopying, microfilming, and recording, or in any information stor-
age or retrieval system, without written permission from the publishers.
For permission to photocopy or use material electronically from this work, please access www.copy-
right.com (http://www.copyright.com/) or contact the Copyright Clearance Center, Inc. (CCC), 222 
Rosewood Drive, Danvers, MA 01923, 978-750-8400. CCC is a not-for-profit organization that pro-
vides licenses and registration for a variety of users. For organizations that have been granted a pho-
tocopy license by the CCC, a separate system of payment has been arranged.
Trademark Notice: Product or corporate names may be trademarks or registered trademarks, and are 
used only for identification and explanation without intent to infringe.
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the CRC Press Web site at
http://www.crcpress.com

v
To Stan Philipp, who taught me real analysis.
And to Walter Rudin, who wrote the books from which I learned.


Preface to the Third
Edition
The enthusiastic reception that the ﬁrst two editions of this book have received
has been pleasing. We write this third edition with a view to making the text
more ﬂexible and useful for our readers.
In particular, we have endeavored to make the book more streamlined.
Worth mention are these changes:
• The beginning chapter on set theory and logic is now an appendix. Many
students will be familiar with this material, and can refer to this for review
when needed. In this way we can get the students quickly into the guts of
real analysis.
• The chapter on number systems has been shortened so that it now concen-
trates on the real numbers and the complex numbers. It is safe to assume
that students are familiar with the natural numbers, the integers, and the
rational numbers. The more elementary number systems are treated in
Appendix I at the end of the book.
• Diﬀerential equations have always been the wellspring of analysis, and we
have retained most of our applications to ordinary diﬀerential equations
and partial diﬀerential equations. But we have removed the material on
the method of characteristics, as it is ancillary.
• We have removed the chapter on wavelet theory, as it is truly beyond the
scope of a typical real variables course.
• We have removed the material on measure theory because it is just too
diﬃcult.
• We have removed the material on diﬀerential forms as it is really best
suited to a more geometric course.

viii
There are still some nice chapters that, after the student has been through
the basic material, oﬀer some “dessert.” These include a treatment of Riemann-
Stieltjes integrals, a chapter on Fourier analysis, a chapter on metric spaces and
applications, and a chapter on diﬀerential equations. We have added a chapter
on normed linear spaces. After all, a look at inﬁnite dimensional analysis is
deﬁnitely a glimpse of future work.
Of course we have taken this opportunity to augment most every chapter
with additional examples and exercises. Diﬃcult or challenging exercises are
still marked with a ∗. And we have corrected some errors and clariﬁed some
passages.
Instead of having exercise sets at the end of each chapter, we now have
exercise sets at the end of each section. This will make the book more useful,
and also help the students to key the exercises to appropriate text passages.
The student who works with this book will come away with a solid foun-
dation in mathematical analysis and its applications. He/she will be ready for
further exploration of measure theory, functional analysis, harmonic analysis,
and beyond.
It is a particular pleasure to thank Zhongshan “Jason” Li and his colleagues
at Georgia State University for their many edits and corrections. All this terriﬁc
information has certainly resulted in a better book.
Bob Stern has been my editor for many years, and has always been a trusted
collaborator and friend. I thank him for our many books.
As always, we welcome responses and input from our readers.
— Steven G. Krantz
St. Louis, Missouri

Preface to the Second
Edition
The book Real Analysis and Foundations, ﬁrst published in 1991, is unique in
several ways.
It was the ﬁrst book to attempt a bridge between the rather
hard-edged classical books in the subject—like Walter Rudin’s Principles of
Mathematical Analysis—and the softer and less rigorous books of today. This
book combines authority, rigor, and readability in a manner that makes the
subject accessible to students while still teaching them the strict discourse of
mathematics.
Real Analysis and Foundations was a timely book, and it has been a success-
ful book. It is used not only in mathematics departments but also in economics
and physics and engineering and ﬁnance programs. The book’s wide acceptance
speaks for itself. Since the volume has been in print for thirteen years, it seems
that a new edition is long overdue.
Like much of classical mathematics, real analysis is a subject that is im-
mutable. It has not changed appreciably for 150 years, and it is not about to
change. But there are new ideas that build on the old ones, and the presentation
can evolve as well. In this new edition, we propose to build on the basic ideas
of Fourier analysis (Chapter 12) and to develop some of the new ideas about
wavelets (Chapter 15). We will indicate applications of wavelets to the theory
of signal processing.
We can also augment the Fourier-analytic theory with applications to or-
dinary diﬀerential equations, and even to some partial diﬀerential equations.
Elliptic boundary value problems on the disc, and their interpretation in terms
of steady-state heat ﬂow, are a natural crucible for the applications of real
analysis.
As part of our treatment of diﬀerential equations we present the method
of power series, the method of characteristics, and the Picard existence and
uniqueness theorem.
These are lovely pieces of mathematics, and they also
allow us to show how fundamental ideas like uniform convergence and power
series are applied.

x
We will amplify the development of real analysis of several variables. After
all, the real world is three-dimensional and we must have the tools of multi-
variable analysis in order to attack the concrete engineering problems that arise
in higher dimensions. We will present the rudiments of the Lebesgue integration
theory, primarily as an invitation to further study. We will also present the
basics of diﬀerential forms and integration on surfaces. We will give a brief
treatment of Stokes’s theorem and its variants.
The exercise sets are rich and robust. Each chapter has an extensive and
diverse collection of problems. Diﬃcult or challenging exercises are marked with
a ∗.
Of course we have re-thought and developed all the exercise sets and all the
examples in the book. We have added more ﬁgures. We have corrected the few
errors that have arisen over the years, tightened up the statements and proofs of
the theorems, and provided end-of-section appendices to help the student with
review topics.
In sum, the second edition of Real Analysis and Foundations will be a new
book—even more lively and more vital than the popular ﬁrst edition. I am
happy to express my gratitude to my editor Robert Stern, who made this pub-
lishing experience a smooth and happy one. I look forward to hearing remarks
and criticisms from my readers, in hopes of making future editions of this book
more accurate and more useful.
— Steven G. Krantz
St. Louis, Missouri

Preface to the First Edition
Overview
The subject of real analysis, or “advanced calculus,” has a central posi-
tion in undergraduate mathematics education. Yet, because of changes in the
preparedness of students, and because of their early exposure to calculus (and
therefore lack of exposure to certain other topics) in high school, this position
has eroded. Students unfamiliar with the value of rigorous, axiomatic mathe-
matics are ill-prepared for a traditional course in mathematical analysis.
Thus there is a need for a book that simultaneously introduces students to
rigor, to the need for rigor, and to the subject of mathematical analysis. The
correct approach, in my view, is not to omit important classical topics like the
Weierstrass Approximation theorem and the Ascoli-Arzela theorem, but rather
to ﬁnd the simplest and most direct path to each. While mathematics should
be written “for the record” in a deductive fashion, proceeding from axioms to
special cases, this is not how it is learned. Therefore (for example) I do treat
metric spaces (a topic that has lately been abandoned by many of the current
crop of analysis texts). I do so not at ﬁrst but rather at the end of the book as
a method for unifying what has gone before. And I do treat Riemann-Stieltjes
integrals, but only after ﬁrst doing Riemann integrals. I develop real analysis
gradually, beginning with treating sentential logic, set theory, and constructing
the integers.
The approach taken here results, in a technical sense, in some repetition of
ideas. But, again, this is how one learns. Every generation of students comes
to the university, and to mathematics, with its own viewpoint and background.
Thus I have found that the classic texts from which we learned mathematical
analysis are often no longer suitable, or appear to be inaccessible, to the present
crop of students. It is my hope that my text will be a suitable source for modern
students to learn mathematical analysis. Unlike other authors, I do not believe
that the subject has changed; therefore I have not altered the fundamental
content of the course. But the point of view of the audience has changed, and
I have written my book accordingly.

xii
The current crop of real analysis texts might lead one to believe that real
analysis is simply a rehash of calculus. Nothing could be further from the truth.
But many of the texts written thirty years ago are simply too dry and austere
for today’s audience. My purpose here is to teach today’s students the mathe-
matics that I grew to love in a language that speaks to them.
Prerequisites
A student with a standard preparation in lower division mathematics—
calculus and diﬀerential equations—has adequate preparation for a course based
on this text. Many colleges and universities now have a “transitions” course that
helps students develop the necessary mathematical maturity for an upper divi-
sion course such as real analysis. I have taken the extra precaution of providing
a mini-transitions course in my Chapters 1 and 2. Here I treat logic, basic set
theory, methods of proof, and constructions of the number systems. Along the
way, students learn about mathematical induction, equivalence classes, com-
pleteness, and many other basic constructs.
In the process of reading these
chapters, written in a rigorous but inviting fashion, the student should gain
both a taste and an appreciation for the use of rigor. While many instructors
will want to spend some class time with these two chapters, others will make
them assigned reading and begin the course proper with Chapter 3.
How to Build a Course from this Text
Chapters 3 through 7 present a ﬁrst course in real analysis. I begin with the
simplest ideas—sequences of numbers—and proceed to series, topology (on the
real line only), limits and continuity of functions, and diﬀerentiation of func-
tions. The order of topics is similar to that in traditional books like Principles
of Mathematical Analysis by Walter Rudin, but the treatment is more gentle.
There are many more examples, and much more explanation. I do not short-
change the really interesting topics like compactness and connectedness. The
exercise sets provide plenty of drill, in addition to the more traditional “Prove
this, Prove that.” If it is possible to obtain a simpler presentation by giving up
some generality, I always opt for simplicity.
Today many engineers and physicists are required to take a term of real
analysis. Chapters 3 through 7 are designed for that purpose. For the more
mathematically inclined, this ﬁrst course serves as an introduction to the more
advanced topics treated in the second part of the book.
In Chapter 8 I give a rather traditional treatment of the integral. First the
Riemann integral is covered, then the Riemann-Stieltjes integral. I am careful
to establish the latter integral as the natural setting for the integration by parts
theorem. I establish explicitly that series are a special case of the Riemann-
Stieltjes integral. Functions of bounded variation are treated brieﬂy and their
utility in integration theory is explained.
The usual material on sequences and series of functions in Chapter 9 (includ-

xiii
ing uniform convergence) is followed by a somewhat novel chapter on “Special
Functions.” Here I give a rigorous treatment of the elementary transcendental
functions as well as an introduction to the gamma function and its application
to Stirling’s formula. The chapter concludes with an invitation to Fourier series.
I feel strongly, based in part on my own experience as a student, that
analysis of several variables is a tough nut the ﬁrst time around. In particular,
college juniors and seniors are not (except perhaps at the very best schools)
ready for diﬀerential forms.
Therefore my treatment of functions of several
variables in Chapter 11 is brief, it is only in R3, and it excludes any reference
to diﬀerential forms. The main interests of this chapter, from the student’s
point of view, are (i) that derivatives are best understood using linear algebra
and matrices and (ii) that the inverse function theorem and implicit function
theorem are exciting new ideas. There are many ﬁne texts that cover diﬀerential
forms and related material and the instructor who wishes to treat that material
in depth should supplement my text with one of those.
Chapter 12 [now Chapter 14] is dessert. For I have waited until now to
introduce the language of metric spaces. But now comes the power, for I prove
and apply both the Baire category theorem and the Ascoli-Arzela theorem. This
is a suitable ﬁnish to a year-long course on the elegance and depth of rigorous
reasoning.
I would teach my second course in real analysis by covering all of Chapters
8 through 12. Material in Chapters 10 and 12 is easily omitted if time is short.
Audience
This book is intended for college juniors and seniors and some beginning
graduate students. It addresses the same niche as the classic books of Apostol,
Royden, and Rudin. However, the book is written for today’s audience in today’s
style. All the topics which excited my sense of wonder as a student—the Cantor
set, the Weierstrass nowhere diﬀerentiable function, the Weierstrass approxi-
mation theorem, the Baire category theorem, the Ascoli-Arzela theorem—are
covered. They can be skipped by those teaching a course for which these topics
are deemed inappropriate. But they give the subject real texture.
Acknowledgements
It is a pleasure to thank Marco Peloso for reading the entire manuscript of
this book and making a number of useful suggestions and corrections. Respon-
sibility for any remaining errors of course resides entirely with me.
Peloso also wrote the solutions manual, which certainly augments the use-
fulness of the book.
Peter L. Duren, Peter Haskell, Kenneth D. Johnson, and Harold R. Parks
served as reviewers of the manuscript that was submitted to CRC Press. Their

xiv
comments contributed decisively to the clarity and correctness of many passages.
I am also grateful to William J. Floyd for a number of helpful remarks.
Russ Hall of CRC Press played an instrumental and propitious role in re-
cruiting me to write for this publishing house. Wayne Yuhasz, Executive Editor
of CRC Press, shepherded the project through every step of the production
process. Lori Pickert of Archetype, Inc. typeset the book in TEX. All of these
good people deserve my sincere thanks for the high quality of the ﬁnished book.
— Steven G. Krantz
St. Louis, Missouri

Table of Contents
Preface to the Third Edition
iii
Preface to the Second Edition
v
Preface to the First Edition
vii
1
Number Systems
1
1.1
The Real Numbers . . . . . . . . . . . . . . . . . . . . . . . . . .
1
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.2
The Complex Numbers . . . . . . . . . . . . . . . . . . . . . . . .
9
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
2
Sequences
15
2.1
Convergence of Sequences . . . . . . . . . . . . . . . . . . . . . .
15
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
2.2
Subsequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
2.3
Lim sup and Lim inf
. . . . . . . . . . . . . . . . . . . . . . . . .
26
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
2.4
Some Special Sequences . . . . . . . . . . . . . . . . . . . . . . .
29
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
3
Series of Numbers
33
3.1
Convergence of Series
. . . . . . . . . . . . . . . . . . . . . . . .
33
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
3.2
Elementary Convergence Tests
. . . . . . . . . . . . . . . . . . .
39
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
45
3.3
Advanced Convergence Tests
. . . . . . . . . . . . . . . . . . . .
46
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
51
3.4
Some Special Series . . . . . . . . . . . . . . . . . . . . . . . . . .
52
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
57
xv

xvi
3.5
Operations on Series . . . . . . . . . . . . . . . . . . . . . . . . .
59
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
62
4
Basic Topology
63
4.1
Open and Closed Sets
. . . . . . . . . . . . . . . . . . . . . . . .
63
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
68
4.2
Further Properties of Open and Closed Sets . . . . . . . . . . . .
69
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
4.3
Compact Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
76
4.4
The Cantor Set . . . . . . . . . . . . . . . . . . . . . . . . . . . .
76
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
79
4.5
Connected and Disconnected Sets . . . . . . . . . . . . . . . . . .
80
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
4.6
Perfect Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
83
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
84
5
Limits and Continuity of Functions
85
5.1
Basic Properties of the Limit of a Function
. . . . . . . . . . . .
85
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
90
5.2
Continuous Functions
. . . . . . . . . . . . . . . . . . . . . . . .
91
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
96
5.3
Topological Properties and Continuity . . . . . . . . . . . . . . .
96
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
5.4
Classifying Discontinuities and Monotonicity
. . . . . . . . . . . 104
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
6
Diﬀerentiation of Functions
111
6.1
The Concept of Derivative . . . . . . . . . . . . . . . . . . . . . . 111
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
6.2
The Mean Value Theorem and Applications . . . . . . . . . . . . 120
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
6.3
More on the Theory of Diﬀerentiation
. . . . . . . . . . . . . . . 127
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
7
The Integral
133
7.1
Partitions and the Concept of Integral . . . . . . . . . . . . . . . 133
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
7.2
Properties of the Riemann Integral . . . . . . . . . . . . . . . . . 140
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
7.3
Another Look at the Integral . . . . . . . . . . . . . . . . . . . . 149
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
7.4
Advanced Results on Integration Theory . . . . . . . . . . . . . . 153
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160

xvii
8
Sequences and Series of Functions
163
8.1
Partial Sums and Pointwise Convergence . . . . . . . . . . . . . . 163
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
8.2
More on Uniform Convergence
. . . . . . . . . . . . . . . . . . . 168
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
8.3
Series of Functions . . . . . . . . . . . . . . . . . . . . . . . . . . 172
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
8.4
The Weierstrass Approximation Theorem
. . . . . . . . . . . . . 176
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180
9
Elementary Transcendental Functions
183
9.1
Power Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188
9.2
More on Power Series: Convergence Issues . . . . . . . . . . . . . 189
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
9.3
The Exponential and Trigonometric Functions
. . . . . . . . . . 194
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199
9.4
Logarithms and Powers of Real Numbers
. . . . . . . . . . . . . 201
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
10 Diﬀerential Equations
205
10.1 Picard’s Existence and Uniqueness Theorem . . . . . . . . . . . . 205
10.1.1 The Form of a Diﬀerential Equation . . . . . . . . . . . . 205
10.1.2 Picard’s Iteration Technique . . . . . . . . . . . . . . . . . 206
10.1.3 Some Illustrative Examples . . . . . . . . . . . . . . . . . 207
10.1.4 Estimation of the Picard Iterates . . . . . . . . . . . . . . 209
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
10.2 Power Series Methods
. . . . . . . . . . . . . . . . . . . . . . . . 212
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
11 Introduction to Harmonic Analysis
223
11.1 The Idea of Harmonic Analysis . . . . . . . . . . . . . . . . . . . 223
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224
11.2 The Elements of Fourier Series
. . . . . . . . . . . . . . . . . . . 225
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
11.3 An Introduction to the Fourier Transform . . . . . . . . . . . . . 235
11.3.1 APPENDIX: Approximation by Smooth Functions . . . . 238
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240
11.4 Fourier Methods and Diﬀerential Equations . . . . . . . . . . . . 243
11.4.1 Remarks on Diﬀerent Fourier Notations . . . . . . . . . . 243
11.4.2 The Dirichlet Problem on the Disc . . . . . . . . . . . . . 244
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248

xviii
12 Functions of Several Variables
253
12.1 A New Look at the Basic Concepts of Analysis . . . . . . . . . . 253
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 257
12.2 Properties of the Derivative . . . . . . . . . . . . . . . . . . . . . 258
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
12.3 The Inverse and Implicit Function Theorems
. . . . . . . . . . . 264
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
13 Advanced Topics
271
13.1 Metric Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275
13.2 Topology in a Metric Space . . . . . . . . . . . . . . . . . . . . . 276
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279
13.3 The Baire Category Theorem . . . . . . . . . . . . . . . . . . . . 280
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284
13.4 The Ascoli-Arzela Theorem . . . . . . . . . . . . . . . . . . . . . 284
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287
14 Normed Linear Spaces
289
14.1 What Is This Subject About? . . . . . . . . . . . . . . . . . . . . 289
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290
14.2 What Is a Normed Linear Space? . . . . . . . . . . . . . . . . . . 290
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293
14.3 Finite-Dimensional Spaces . . . . . . . . . . . . . . . . . . . . . . 294
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 295
14.4 Linear Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . 296
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298
14.5 The Three Big Results . . . . . . . . . . . . . . . . . . . . . . . . 299
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304
14.6 Applications of the Big Three . . . . . . . . . . . . . . . . . . . . 305
EXERCISES
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315
APPENDIX I: Elementary Number Systems
317
APPENDIX II: Logic and Set Theory
335
APPENDIX III: Review of Linear Algebra
369
Table of Notation
377
Glossary
383
Bibliography
403
Index
407

Chapter 1
Number Systems
1.1
The Real Numbers
This is a book about analysis in the real number system. Such a study must be
founded on a careful consideration of what the real numbers are and how they
are constructed. In the present section we give a careful treatment of the real
number system. In the next we consider the complex numbers.
We know from calculus that, for many purposes, the rational numbers are
inadequate. It is important to work in a number system which is closed with
respect to the operations we shall perform. This includes limiting operations.
While the rationals are closed under the usual arithmetic operations, they are
not closed under the mathematical operation of taking limits. For instance, the
sequence of rational numbers 3, 3.1, 3.14, 3.141, . . . consists of terms that seem
to be getting closer and closer together, seem to tend to some limit, and yet
there is no rational number which will serve as a limit (of course it turns out
that the limit is π—an “irrational” number).
We will now deal with the real number system, a system which contains all
limits of sequences of rational numbers (as well as all limits of sequences of real
numbers!). In fact our plan will be as follows: in this section we shall discuss
all the requisite properties of the reals. The actual construction of the reals is
rather complicated, and we shall put that in an Appendix to Section 1.1.
Deﬁnition 1.1 Let A be an ordered set and X a subset of A. The set X is
called bounded above if there is an element b ∈A such that x ≤b for all x ∈X.
We call the element b an upper bound for the set X.
Example 1.2 Let A = Q (the rational numbers) with the usual ordering. The
set X = {x ∈Q : 2 < x < 4} is bounded above. For example, 15 is an upper
bound for X. So are the numbers 12 and 4. It is interesting to observe that
no element of this particular X can actually be an upper bound for X. The
number 4 is a good candidate, but 4 is not an element of X. In fact if b ∈X
1

2
CHAPTER 1. NUMBER SYSTEMS
then (b + 4)/2 ∈X and b < (b + 4)/2, so b could not be an upper bound for X.
It turns out that the most convenient way to formulate the notion that
the real numbers have “no holes” (i.e.
that all sequences which seem to be
converging actually have something to converge to) is in terms of upper bounds.
Deﬁnition 1.3 Let A be an ordered set and X a subset of A. An element
b ∈A is called a least upper bound (or supremum) for X if b is an upper bound
for X and b ≤b′ for every upper bound b′ for X. We denote the supremum of
X by sup X. The supremum is also sometimes called the least upper bound and
denoted by lub X.
By its very deﬁnition, if a least upper bound exists then it is unique.
Example 1.4 In the last example, we considered the set X of rational numbers
strictly between 2 and 4. We observed there that 4 is the least upper bound for
X. Note that this least upper bound is not an element of the set X.
The set Y = {y ∈Z : −9 ≤y ≤7} has least upper bound 7. In this case,
the least upper bound is an element of the set Y.
Notice that we may deﬁne a lower bound for a subset of an ordered set in a
fashion similar to that for an upper bound: ℓ∈A is a lower bound for X ⊆A if
ℓ≤x for all x ∈X. A greatest lower bound (or inﬁmum) for X is then deﬁned
to be a lower bound ℓsuch that there is no lower bound ℓ′ with ℓ′ > ℓ. We
denote the inﬁmum of X by inf X. The supremum is also sometimes called the
greatest lower bound and denoted by glb X.
Example 1.5 The set X in the last two examples has lower bounds −20, 0, 1,
2, for instance. The greatest lower bound is 2, which is not an element of the
set.
The set Y in the last example has lower bounds—among others—given by
−53, −22, −10, −9. The number −9 is the greatest lower bound. It is an element
of Y.
The purpose that the real numbers will serve for us is as follows: they will
contain the rationals, they will still be an ordered ﬁeld, and every subset which
has an upper bound will have a least upper bound. [See [KRA1] for a thorough
treatment of the concept of ordered ﬁeld.] We formulate this result as a theorem.
Theorem 1.6 There exists an ordered ﬁeld R which (i) contains Q and (ii)
has the property that any nonempty subset of
R which has an upper bound
has a least upper bound (in the number system R).
The last property described in this theorem is called the Least Upper Bound
Property of the real numbers. As mentioned previously, this theorem will be
proved in the Appendix to Section 1.1. Now we begin to realize why it is so
important to construct the number systems that we will use. We are endowing

1.1. THE REAL NUMBERS
3
R with a great many properties. Why do we have any right to suppose that
there exists a set with all these properties? We must produce one! We do so in
the Appendix to Section 1.1.
Let us begin to explore the richness of the real numbers. The next the-
orem states a property which is certainly not shared by the rationals.
It is
fundamental in its importance.
Theorem 1.7 Let x be a real number such that x > 0. Then there is a positive
real number y such that y2 = y · y = x.
Proof: We will use throughout this proof the fact that if 0 < a < b then
a2 < b2.
Let
S = {s ∈R : s > 0 and s2 < x}.
Then S is not empty since x/2 ∈S if x < 2 and 1 ∈S otherwise. Also S is
bounded above since x + 1 is an upper bound for S. By Theorem 1.6, the set
S has a least upper bound. Call it y. Obviously, 0 < min{x/2, 1} ≤y hence
y is positive. We claim that y2 = x. To see this, we eliminate the other two
possibilities.
If y2 < x then set ǫ = (x −y2)/[4(x + 1)]. Then ǫ > 0 and
(y + ǫ)2
=
y2 + 2 · y · ǫ + ǫ2
=
y2 + 2 · y · x −y2
4(x + 1) + x −y2
4(x + 1) · x −y2
4(x + 1)
<
y2 + 2 · y · x −y2
4y
+ x −y2
4(x + 1) · x −y2
4(x + 1)
<
y2 + x −y2
2
+ x −y2
4
· x
4x
<
y2 + (x −y2)
=
x.
Thus y + ǫ ∈S, and y cannot be an upper bound for S. This contradiction tells
us that y2 ̸< x.
Similarly, if it were the case that y2 > x then we set ǫ = (y2−x)/[4(x+1)]. A
calculation like the one we just did (see Exercise 5) then shows that (y−ǫ)2 ≥x.
Hence y −ǫ is also an upper bound for S, and y is therefore not the least upper
bound. This contradiction shows that y2 ̸> x.
The only remaining possibility is that y2 = x.
A similar proof shows that, if n is a positive integer and x a positive real
number, then there is a positive real number y such that yn = x. Exercise 12
asks you to provide the details.
We next use the Least Upper Bound Property of the Real Numbers to
establish two important qualitative properties of the Real Numbers:

4
CHAPTER 1. NUMBER SYSTEMS
Theorem 1.8 The set R of real numbers satisﬁes the Archimedean Property:
Let a and b be positive real numbers. Then there is a natural number
n such that na > b.
The set Q of rational numbers satisﬁes the following Density Property:
Let c < d be real numbers. Then there is a rational number q with
c < q < d.
Proof: Suppose the Archimedean Property to be false. Then S = {na : n ∈N}
has b as an upper bound. Therefore S has a ﬁnite supremum β. Since a > 0, it
follows that β −a < β. So β −a is not an upper bound for S, and there must
be a natural number n′ such that n′ · a > β −a. But then (n′ + 1)a > β, and β
cannot be the supremum for S. This contradiction proves the ﬁrst assertion.
For the second property, let λ = d −c > 0. By the Archimedean Property,
choose a positive integer N such that N · λ > 1.
Again the Archimedean
Property gives a natural number P such that P > N · c and another Q such
that Q > −N · c. Thus we see that Nc falls between the integers −Q and P;
therefore there must be an integer M between −Q and P such that
M −1 ≤Nc < M .
Thus c < M/N. Also
M ≤Nc + 1 hence M
N ≤c + 1
N < c + λ = d.
So M/N is a rational number lying between c and d.
In Appendix II at the end of the book we establish that the set of all
decimal representations of numbers is uncountable. It follows that the set of all
real numbers is uncountable. In fact the same proof shows that the set of all
real numbers in the interval (0, 1), or in any nonempty open interval (c, d), is
uncountable.
The set R of real numbers is uncountable, yet the set Q of rational numbers
is countable. It follows that the set R \ Q of irrational numbers is uncountable.
In particular, it is nonempty. Thus we may see with very little eﬀort that there
exist a great many real numbers which cannot be expressed as a quotient of
integers. However, it can be quite diﬃcult to see whether any particular real
number (such as π or e or
5√
2) is irrational.
We conclude by recalling the “absolute value” notation:
Deﬁnition 1.9 Let x be a real number. We deﬁne
|x| =



x
if
x > 0
0
if
x = 0
−x
if
x < 0

APPENDIX: CONSTRUCTION OF THE REALS
5
It is left as an exercise for you to verify the important triangle inequality:
|x + y| ≤|x| + |y| .
[Hint: It is convenient to verify that the square of the lefthand side is less than
or equal to the square of the righthand side.]
APPENDIX:Construction of the Real Numbers
There are several techniques for constructing the real number system R from
the rational numbers system Q. We use the method of Dedekind (Julius W. R.
Dedekind, 1831-1916) cuts because it uses a minimum of new ideas and is fairly
brief.
The number system that we shall be constructing is an instance of a ﬁeld
(the complex numbers, in the next section, also form a ﬁeld). The deﬁnition is
as follows:
Deﬁnition 1.10 A set S is called a ﬁeld if it is equipped with a binary operation
(usually called addition and denoted “+”) and a second binary operation (called
multiplication and denoted “·”) such that the following axioms are satisﬁed
(Here A stands for “addition,” M stands for “multiplication,” and D stands for
“distributive law.”):
A1. S is closed under addition: if x, y ∈S then x + y ∈S.
A2. Addition is commutative: if x, y ∈S then x + y = y + x.
A3. Addition is associative: if x, y, z ∈S then x + (y + z) = (x + y) + z.
A4. There exists an element, called 0, in S which is an additive identity: if
x ∈S then 0 + x = x.
A5. Each element of S has an additive inverse: if x ∈S then there is an
element −x ∈S such that x + (−x) = 0.
M1. S is closed under multiplication: if x, y ∈S then x · y ∈S.
M2. Multiplication is commutative: if x, y ∈S then x · y = y · x.
M3. Multiplication is associative: if x, y, z ∈S then x · (y · z) = (x · y) · z.
M4. There exists an element, called 1, which is a multiplicative identity: if
x ∈S then x · 1 = x.
M5. Each nonzero element of S has a multiplicative inverse: if 0 ̸= x ∈S then
there is an element x−1 ∈S such that x · (x−1) = 1. The element x−1 is
sometimes denoted 1/x.

6
CHAPTER 1. NUMBER SYSTEMS
D1. Multiplication distributes over addition: if x, y, z ∈S then
x · (y + z) = x · y + x · z .
Deﬁnition 1.11 A cut is a subset C of Q with the following properties:
• C ̸= ∅
• If s ∈C and t < s then t ∈C
• If s ∈C then there is a u ∈C such that u > s
• There is a rational number x such that c < x for all c ∈C
You should think of a cut C as the set of all rational numbers to the left of
some point in the real line. Since we have not constructed the real line yet, we
cannot deﬁne a cut in that simple way; we have to make the construction more
indirect. But if you consider the four properties of a cut, they describe a set
that looks like a “rational halﬂine.”
Notice that, if C is a cut and s ̸∈C, then any rational t > s is also not in C.
Also, if r ∈C and s ̸∈C then it must be that s > r.
Deﬁnition 1.12 If C and D are cuts then we say that C < D provided that C
is a subset of D but C ̸= D.
Check for yourself that “<” is an ordering on the set of all cuts.
Now we introduce operations of addition and multiplication which will turn
the set of all cuts into a ﬁeld.
Deﬁnition 1.13 If C and D are cuts then we deﬁne
C + D = {c + d : c ∈C, d ∈D}.
We deﬁne the cut b0 to be the set of all negative rationals.
The cut b0 will play the role of the additive identity. We are now required to
check that ﬁeld axioms A1-A5 hold.
For A1, we need to see that C + D is a cut. Obviously C + D is not empty.
If s is an element of C +D and t is a rational number less than s, write s = c+d,
where c ∈C and d ∈D. Then t −c < s −c = d ∈D so t −c ∈D; and c ∈C.
Hence t = c + (t −c) ∈C + D . A similar argument shows that there is an r > s
such that r ∈C + D . Finally, if x is a rational upper bound for C and y is a
rational upper bound for D, then x + y is a rational upper bound for C + D. We
conclude that C + D is a cut.
Since addition of rational numbers is commutative, it follows immediately
that addition of cuts is commutative. Associativity follows in a similar fashion.
Now we show that if C is a cut then C + b0 = C. For if c ∈C and z ∈b0 then
c + z < c + 0 = c hence C + b0 ⊆C. Also, if c′ ∈C then choose a d′ ∈C such

APPENDIX: CONSTRUCTION OF THE REALS
7
that c′ < d′. Then c′ −d′ < 0 so c′ −d′ ∈b0. And c′ = d′ + (c′ −d′). Hence
C ⊆C + b0. We conclude that C + b0 = C.
Finally, for Axiom A5, we let C be a cut and set −C to be equal to {d ∈
Q : c + d < 0 for all c ∈C}. If x is a rational upper bound for C and c ∈C then
−x ∈−C so −C is not empty. By its very deﬁnition, C + (−C) ⊆b0. Further,
if z ∈b0 and c ∈C we set c′ = z −c. Then c′ ∈−C and z = c + c′. Hence
b0 ⊆C + (−C). We conclude that C + (−C) = b0.
Having veriﬁed the axioms for addition, we turn now to multiplication.
Deﬁnition 1.14 If C and D are cuts then we deﬁne the product C·D as follows:
• If C, D > b0 then C · D = {q ∈Q : q < c · d for some c ∈C, d ∈D with
c > 0, d > 0 }
• If C > b0, D < b0 then C · D = −(C · (−D))
• If C < b0, D > b0 then C · D = −((−C) · D)
• If C, D < b0 then C · D = (−C) · (−D)
• If either C = b0 or D = b0 then C · D = b0.
Notice that, for convenience, we have deﬁned multiplication of negative numbers
just as we did in high school. The reason is that the deﬁnition that we use for
the product of two positive numbers cannot work when one of the two factors
is negative (exercise).
It is now a routine exercise to verify that the set of all cuts, with this
deﬁnition of multiplication, satisﬁes ﬁeld axioms M1-M5. The proofs follow
those for A1-A5 rather closely.
For the distributive property, one ﬁrst checks the case when all the cuts are
positive, reducing it to the distributive property for the rationals. Then one
handles negative cuts on a case by case basis.
We now know that the collection of all cuts forms an ordered ﬁeld. Denote
this ﬁeld by the symbol R. We next verify the crucial property of R that sets it
apart from Q :
Theorem 1.15 The ordered ﬁeld R satisﬁes the least upper bound property.
Proof: Let S be a subset of R which is bounded above. Deﬁne
S∗=
[
C∈S
C .
Then S∗is clearly nonempty, and it is therefore a cut since it is a union of cuts.
It is also clearly an upper bound for S since it contains each element of S. It
remains to check that S∗is the least upper bound for S.
In fact if T < S∗then T ⊆S∗and there is a rational number q in S∗\ T .
But, by the deﬁnition of S∗, it must be that q ∈C for some C ∈S. So C > T ,

8
CHAPTER 1. NUMBER SYSTEMS
and T cannot be an upper bound for S. Therefore S∗is the least upper bound
for S, as desired.
We have shown that R is an ordered ﬁeld which satisﬁes the least upper
bound property. It remains to show that R contains (a copy of) Q in a natural
way. In fact, if q ∈Q we associate to it the element ϕ(q) = Cq ≡{x ∈Q : x < q}.
Then Cq is obviously a cut. It is also routine to check that
ϕ(q + q′) = ϕ(q) + ϕ(q′) and ϕ(q · q′) = ϕ(q) · ϕ(q′).
Therefore we see that ϕ represents Q as a subﬁeld of R.
Exercises
1. Let A be a set of real numbers that is bounded above and set α = sup A.
Let B = {−a : a ∈A}. Prove that inf B = −α. Prove the same result
with the roles of inﬁmum and supremum reversed.
2. Complete the calculation in the proof of Theorem 1.7.
3. What is the least upper bound of the set
S = {x : x2 < 2} ?
Explain why this question has a sensible answer in the real number system
but not in the rational number system.
4. Prove that the least upper bound and greatest lower bound for a set of
real numbers is unique.
5. Consider the unit circle C. Let
S = {α : 2α < (the circumference of C)} .
Show that S is bounded above. Let p be the least upper bound of S. Say
explicitly what the number p is. This exercise works in the real number
system, but not in the rational number system. Why?
6. Give an example of a set that contains its least upper bound but not its
greatest lower bound. Give an example of a set that contains its greatest
lower bound but not its least upper bound.
7. Give an example of a set of real numbers that does not have a least upper
bound. Give an example of a set of real numbers that does not have a
greatest lower bound.
8. Prove the triangle inequality.
9. Prove that addition of the real numbers (as constructed in the Appendix)
is commutative. Now prove that it is associative.

1.2. THE COMPLEX NUMBERS
9
10. Let ∅be the empty set. Prove that sup ∅= −∞and inf ∅= +∞.
*
11. Let f be a function with domain the reals and range the reals. Assume
that f has a local minimum at each point x in its domain. (This means
that, for each x ∈R, there is an ǫ > 0 such that whenever | x −t |< ǫ
then f(x) ≤f(t)). Do not assume that f is diﬀerentiable, or continuous,
or anything nice like that. Prove that the image of f is countable. (Hint:
When I solved this problem as a student my solution was ten pages long;
however, there is a one-line solution due to Michael Spivak.)
*
12. Let λ be a positive irrational real number. If n is a positive integer, choose
by the Archimedean Property an integer k such that kλ ≤n < (k + 1)λ.
Let ϕ(n) = n −kλ. Prove that the set of all ϕ(n) is dense in the interval
[0, λ]. (Hint: Examine the proof of the density of the rationals in the
reals.)
*
13. Let n be a natural number and x a positive real number. Prove that there
is a positive real number y such that yn = x. Is y unique?
1.2
The Complex Numbers
When we ﬁrst learn about the complex numbers, the most troublesome point
is the very beginning: “Let’s pretend that the number −1 has a square root.
Call it i.” What gives us the right to “pretend” in this fashion? The answer is
that we have no such right.1 If −1 has a square root, then we should be able to
construct a number system in which that is the case. That is what we shall do
in this section.
Deﬁnition 1.16 The system of complex numbers, denoted by the symbol C,
consists of all ordered pairs (a, b) of real numbers. We add two complex numbers
(a, b) and (ea,eb) by the formula
(a, b) + (ea,eb) = (a + ea, b + eb) .
We multiply two complex numbers by the formula
(a, b) · (ea,eb) = (a · ea −b · eb, a · eb + ea · b) .
Remark 1.17 If you are puzzled by this deﬁnition of multiplication, do not
worry. In a few moments you will see that it gives rise to the notion of mul-
tiplication of complex numbers that you are accustomed to.
Perhaps more
1The complex numbers were initially developed so that we would have a number system in
which all polynomial equations are solvable. One of the reasons, historically, that mathemati-
cians had trouble accepting the complex numbers is that they did not believe that they really
existed—they were just made up. This is, in part, how they came to be called “imaginary.”
Mathematicians had similar trouble accepting negative numbers; for a time, negative numbers
were called “forbidden.”

10
CHAPTER 1. NUMBER SYSTEMS
importantly, a naive rule for multiplication like (a, b) · (ea,eb) = (aea, beb) gives rise
to nonsense like (1, 0) · (0, 1) = (0, 0). It is really necessary for us to use the
initially counterintuitive deﬁnition of multiplication that is presented here.
Example 1.18 Let z = (3, −2) and w = (4, 7) be two complex numbers. Then
z + w = (3, −2) + (4, 7) = (3 + 4, −2 + 7) = (7, 5) .
Also
z · w = (3, −2) · (4, 7) = (3 · 4 −(−2) · 7, 3 · 7 + 4 · (−2)) = (26, 13) .
As usual, we ought to check that addition and multiplication are commuta-
tive, associative, that multiplication distributes over addition, and so forth. We
shall leave these tasks to the exercises. Instead we develop some of the crucial,
and more interesting, properties of our new number system.
Theorem 1.19 The following properties hold for the number system C.
(a) The number 1 ≡(1, 0) is the multiplicative identity: 1 · z = z for any
z ∈C.
(b) The number 0 ≡(0, 0) is the additive identity: 0 + z = z for any z ∈C.
(c) Each complex number z = (x, y) has an additive inverse −z = (−x, −y):
it holds that z + (−z) = 0.
(d) The number i ≡(0, 1) satisﬁes i·i = −1; in other words, i is a square root
of −1.
Proof: These are direct calculations, but it is important for us to work out
these facts.
First, let z = (x, y) be any complex number. Then
1 · z = (1, 0) · (x, y) = (1 · x −0 · y, 1 · y + x · 0) = (x, y) = z .
This proves the ﬁrst assertion.
For the second, we have
0 + z = (0, 0) + (x, y) = (0 + x, 0 + y) = (x, y) = z .
With z as above, set −z = (−x, −y). Then
z + (−z) = (x, y) + (−x, −y) = (x + (−x), y + (−y)) = (0, 0) = 0 .
Finally, we calculate
i · i = (0, 1) · (0, 1) = (0 · 0 −1 · 1, 0 · 1 + 0 · 1) = (−1, 0) = −1 .
Thus, as asserted, i is a square root of −1.

1.2. THE COMPLEX NUMBERS
11
Proposition 1.20 If z ∈C, z ̸= 0, then there is a complex number w such that
z · w = 1.
Proof: Write z = (x, y) and set
w =
 
x
p
x2 + y2 ,
−y
p
x2 + y2
!
.
Since z ̸= 0, this deﬁnition makes sense. Then it is straightforward to verify
that z · w = 1.
Thus every nonzero complex number has a multiplicative inverse. The other
ﬁeld axioms for C are easy to check. We conclude that the number system C
forms a ﬁeld. You will prove in the exercises that it is not possible to order this
ﬁeld. If α is a real number then we associate α with the complex number (α, 0).
Thus we have the natural “embedding”
R ∋α 7−→(α, 0) ∈C .
In this way, we can think of the real numbers as a subset of the complex numbers.
In fact, the real ﬁeld R is a subﬁeld of the complex ﬁeld C. This means that
if α, β ∈R and (α, 0), (β, 0) are the corresponding elements in C then α + β
corresponds to (α+β, 0) and α·β corresponds to (α, 0)·(β, 0). These assertions
are explored more thoroughly in the exercises.
With the remarks in the preceding paragraph we can sometimes ignore the
distinction between the real numbers and the complex numbers. For example,
we can write
5 · i
and understand that it means (5, 0) · (0, 1) = (0, 5). Likewise, the expression
5 · 1
can be interpreted as 5 · 1 = 5 or as (5, 0) · (1, 0) = (5, 0) without any danger of
ambiguity.
Theorem 1.21 Every complex number can be written in the form a + b · i,
where a and b are real numbers. In fact, if z = (x, y) ∈C then
z = x + y · i .
Proof: With the identiﬁcation of real numbers as a subﬁeld of the complex
numbers, we have that
x + y · i = (x, 0) + (y, 0) · (0, 1) = (x, 0) + (0, y) = (x, y) = z
as claimed.

12
CHAPTER 1. NUMBER SYSTEMS
Now that we have constructed the complex number ﬁeld, we will adhere to
the usual custom of writing complex numbers as z = a + b · i or, more simply,
a + bi. We call a the real part of z, denoted by Re z, and b the imaginary part
of z, denoted Im z. We have
(a + bi) + (ea + ebi) = (a + ea) + (b + eb)i
and
(a + bi) · (ea + ebi) = (a · ea −b · eb) + (a · eb + ea · b)i .
If z = a + bi is a complex number then we deﬁne its complex conjugate to
be the number z = a −bi. We record some elementary facts about the complex
conjugate:
Proposition 1.22 If z, w are complex numbers then
(1) z + w = z + w;
(2) z · w = z · w;
(3) z + z = 2 · Re z;
(4) z −z = 2 · i · Im z;
(5) z · z ≥0, with equality holding if and only if z = 0.
Proof: Write z = a + bi, w = c + di. Then
z + w
=
(a + c) + (b + d)i
=
(a + c) −(b + d)i
=
(a −bi) + (c −di)
=
z + w.
This proves (1). Assertions (2), (3), (4) are proved similarly.
For (5), notice that
z · z = (a + bi) · (a −bi) = a2 + b2 ≥0.
Clearly equality holds if and only if a = b = 0.
The expression |z| is deﬁned to be the nonnegative square root of z · z:
|z| = +
√
z · z =
p
x2 + y2
when z = x + iy. It is called the modulus of z and plays the same role for the
complex ﬁeld that absolute value plays for the real ﬁeld. It is the distance of z
to the origin. The modulus has the following properties.
Proposition 1.23 If z, w ∈C then

1.2. THE COMPLEX NUMBERS
13
(1) |z| = |z|;
(2) |z · w| = |z| · |w|;
(3) |Re z| ≤|z| ,
|Im z| ≤|z|;
(4) |z + w| ≤|z| + |w|;
Proof: Write z = a + bi, w = c + di. Then (1), (2), (3) are immediate. For
(4) we calculate that
|z + w|2
=
(z + w) · (z + w)
=
z · z + z · w + w · z + w · w
=
|z|2 + 2Re (z · w) + |w|2
≤
|z|2 + 2|z · w| + |w|2
=
|z|2 + 2|z| · |w| + |w|2
=
(|z| + |w|)2.
Taking square roots proves (4).
Observe that, if z is real, then z = a + 0i and the modulus of z equals
the absolute value of a. Likewise, if z = 0 + bi is pure imaginary, then the
modulus of z equals the absolute value of b. In particular, the fourth part of
the proposition reduces, in the real case, to the triangle inequality
|a + b| ≤|a| + |b| .
If z is any nonzero complex number, then let r = |z|. Now deﬁne ξ = z/r.
Certainly ξ is a complex number of modulus 1. Thus ξ lies on the unit circle, so
it subtends an angle θ with the positive x-axis. Certainly then ξ = cos θ+i sinθ.
It is shown in Section 9.3 that
eiθ = ξ = cos θ + i sin θ .
[Hint: You may verify this formula for yourself by writing out the power series
for the exponential and writing out the power series for cosine and sine.]
We conclude this discussion by recording the most important basic fact
about the complex numbers. Carl Friedrich Gauss gave ﬁve proofs of this the-
orem (the Fundamental Theorem of Algebra) in his doctoral dissertation:
Theorem 1.24 Let p(z) be any polynomial of degree at least 1. Then p has a
root α ∈C such that p(α) = 0.
Using a little algebra, one can in fact show that a polynomial of degree k
has k roots (counting multiplicity).

14
CHAPTER 1. NUMBER SYSTEMS
Exercises
1. Taking the commutative, associative, and distributive laws for the real
number system for granted, establish these laws for the complex numbers.
2. Consider the function φ : R →C given by φ(x) = x + i · 0. Prove that φ
respects addition and multiplication in the sense that φ(x + x′) = φ(x) +
φ(x′) and φ(x · x′) = φ(x) · φ(x′).
3. If z, w ∈C then prove that z/w = z/w.
4. Prove that the set of all complex numbers is uncountable.
5. Prove that the set of all complex numbers with rational real part is un-
countable.
6. Prove that the set of all complex numbers with both real and imaginary
parts rational is countable.
7. Prove that the set {z ∈C : |z| = 1} is uncountable.
8. Prove that the ﬁeld of complex numbers cannot be made into an ordered
ﬁeld. (Hint: Since i ̸= 0 then either i > 0 or i < 0. Both lead to a
contradiction.)
9. Find all cube roots of the complex number 1 + i.
10. Use the Fundamental Theorem of Algebra to prove that any polynomial
of degree k has k (not necessarily distinct) roots.
11. Prove that the complex roots of a polynomial with real coeﬃcients occur
in complex conjugate pairs.
12. Calculate the square roots of i.
13. In the complex plane, draw a picture of
S = {z ∈C : |z −1| + |z + 1| = 2} .
14. In the complex plane, draw a picture of
T = {z ∈C : |z + z| −|z −z| = 2} .
15. Prove that any nonzero complex number has kth roots r1, r2, . . . , rk.
That is, prove that there are k of them.

Chapter 2
Sequences
2.1
Convergence of Sequences
A sequence of real numbers is a function ϕ : N →R. We often write the sequence
as ϕ(1), ϕ(2), . . . or, more simply, as ϕ1, ϕ2, . . . . A sequence of complex numbers
is deﬁned similarly, with R replaced by C.
Example 2.1 The function ϕ(j) = 1/j is a sequence of real numbers. We will
often write such a sequence as ϕj = 1/j or as {1, 1/2, 1/3, . . .} or as {1/j}∞
j=1 .
The function ψ(j) = cos j + i sin j is a sequence of complex numbers.
Do not be misled into thinking that a sequence must form a pattern, or be
given by a formula. Obviously the ones which are given by formulas are easy
to write down, but they are certainly not typical. For example, the coeﬃcients
in the decimal expansion of π, {3, 1, 4, 1, 5, 9, 2, 6, 5, . . .}, ﬁt our deﬁnition of
sequence—but they are not given by any obvious pattern.
The most important question about a sequence is whether it converges. We
deﬁne this notion as follows.
Deﬁnition 2.2 A sequence {aj} of real (resp. complex) numbers is said to
converge to a real (resp. complex) number α if, for each ǫ > 0, there is an
integer N > 0 such that if j > N then |aj −α| < ǫ. We call α the limit of the
sequence {aj}. We write limj→∞aj = α. We also sometimes write aj →α.
If a sequence {aj} does not converge then we frequently say that it diverges.
Example 2.3 Let aj = 1/j, j = 1, 2, . . .. Then the sequence converges to 0.
For let ǫ > 0.
Choose N to be the next integer after 1/ǫ (we use here the
Archimedean principle). If j > N then
|aj −0| = |aj| = 1
j < 1
N < ǫ,
proving the claim.
15

16
CHAPTER 2. SEQUENCES
Let bj = (−1)j, j = 1, 2, . . .. Then the sequence does not converge. To
prove this assertion, suppose to the contrary that it does. Say that the sequence
converges to a number α. Let ǫ = 1/2. By deﬁnition of convergence, there is an
integer N > 0 such that, if j > N, then |bj −α| < ǫ = 1/2. For such j we have
|bj −bj+1| ≤|bj −α| + |α −bj+1|
(by the triangle inequality—see the end of Section 1.1). But this last is
< ǫ + ǫ = 1 .
On the other hand,
|bj −bj+1| =
(−1)j −(−1)j+1 = 2 .
The last two lines yield that 2 < 1, a clear contradiction. So the sequence {bj}
has no limit.
We begin with a few intuitively appealing properties of convergent sequences
which will be needed later. First, a deﬁnition.
Deﬁnition 2.4 A sequence aj is said to be bounded if there is a number M > 0
such that |aj| ≤M for every j.
Now we have
Proposition 2.5 Let {aj} be a convergent sequence. Then we have:
• The limit of the sequence is unique.
• The sequence is bounded.
Proof: Suppose that the sequence has two limits α and eα. Let ǫ > 0. Then
there is an integer N > 0 such that for j > N we have the inequality |aj −α| < ǫ.
Likewise, there is an integer e
N > 0 such that for j > e
N we have |aj −eα| < ǫ.
Let N0 = max{N, e
N}. Then, for j > N0, we have
|α −eα| ≤|α −aj| + |aj −eα| < ǫ + ǫ = 2ǫ .
Since this inequality holds for any ǫ > 0 we have that α = eα.
Next, with α the limit of the sequence and ǫ = 1, we choose an integer
N > 0 such that j > N implies that |aj −α| < ǫ = 1. For such j we have that
|aj| ≤|aj −α| + |α| < 1 + |α| ≡P .
Let Q = max{|a1|, |a2|, . . . , |aN|}.
If j is any natural number then either
1 ≤j ≤N (in which case |aj| ≤Q) or else j > N (in which case |aj| ≤P).
Set M = max{P, Q}. Then |aj| ≤M for all j, as desired. So the sequence is
bounded.
The next proposition records some elementary properties of limits of se-
quences.

2.1. CONVERGENCE OF SEQUENCES
17
Proposition 2.6 Let {aj} be a sequence of real or complex numbers with limit
α and {bj} be a sequence of real or complex numbers with limit β. Then we
have:
(1) If c is a constant then the sequence {c · aj} converges to c · α;
(2) The sequence {aj + bj} converges to α + β;
(3) The sequence aj · bj converges to α · β;
(4) If bj ̸= 0 for all j and β ̸= 0 then the sequence aj/bj converges to α/β.
Proof: For the ﬁrst part, we may assume that c ̸= 0 (for when c = 0 there is
nothing to prove). Let ǫ > 0. Choose an integer N > 0 such that for j > N it
holds that
|aj −α| < ǫ
|c| .
For such j we have that
|c · aj −c · α| = |c| · |aj −α| < |c| · ǫ
|c| = ǫ .
This proves the ﬁrst assertion.
The proof of the second assertion is similar, and we leave it as an exercise.
For the third assertion, notice that the sequence {aj} is bounded (by the
second part of Proposition 2.5): say that |aj| ≤M for every j. Let ǫ > 0.
Choose an integer N > 0 so that |aj −α| < ǫ/(2M + 2|β|) when j > N. Also
choose an integer e
N > 0 such that |bj −β| < ǫ/(2M + 2|β|) when j > e
N. Then,
for j > max{N, e
N}, we have that
|ajbj −αβ|
=
|aj(bj −β) + β(aj −α)|
≤
|aj(bj −β)| + |β(aj −α)|
<
M ·
ǫ
2M + 2|β| + |β| ·
ǫ
2M + 2|β|
≤
ǫ
2 + ǫ
2
=
ǫ.
So the sequence {ajbj} converges to αβ.
Part (4) is proved in a similar fashion and we leave the details as an exer-
cise.
Remark 2.7 You were probably puzzled by the choice of N and e
N in the proof
of part (3) of Proposition 2.6—where did the number ǫ/(2M +2|β|) come from?
The answer of course becomes obvious when we read on further in the proof.
So the lesson here is that a proof is constructed backward: you look to the end
of the proof to see what you need to specify earlier on. Skill in these matters
can come only with practice.

18
CHAPTER 2. SEQUENCES
When discussing the convergence of a sequence, we often ﬁnd it inconvenient
to deal with the deﬁnition of convergence as given. For this deﬁnition makes
reference to the number to which the sequence is supposed to converge, and we
often do not know this number in advance. Would it not be useful to be able to
decide whether a series converges without knowing to what limit it converges?
Deﬁnition 2.8 Let {aj} be a sequence of real (resp. complex) numbers. We
say that the sequence satisﬁes the Cauchy criterion (A. L. Cauchy, 1789-1857)—
more brieﬂy, that the sequence is Cauchy—if, for each ǫ > 0, there is an integer
N > 0 such that if j, k > N then |aj −ak| < ǫ.
Notice that the concept of a sequence being Cauchy simply makes precise the
notion of the elements of the sequence (i) getting closer together and (ii) staying
close together.
Lemma 2.9 Every Cauchy sequence is bounded.
Proof: Let ǫ = 1 > 0. There is an integer N > 0 such that |aj −ak| < ǫ = 1
whenever j, k > N. Thus if j ≥N + 1 we have
|aj|
≤
|aN+1 + (aj −aN+1)|
≤
|aN+1| + |aj −aN+1|
≤
|aN+1| + 1 ≡K.
Let L = max{|a1|, |a2|, . . . , |aN|}.
If j is any natural number, then either
1 ≤j ≤N, in which case |aj| ≤L, or else j > N, in which case |aj| ≤K.
Set M = max{K,L}. Then, for any j, |aj| ≤M as required.
Theorem 2.10 Let {aj} be a sequence of real numbers.
The sequence is
Cauchy if and only if it converges to some limit α.
Proof: First assume that the sequence converges to a limit α.
Let ǫ > 0.
Choose, by deﬁnition of convergence, an integer N > 0 such that if j > N then
|aj −α| < ǫ/2. If j, k > N then
|aj −ak| ≤|aj −α| + |α −ak| < ǫ
2 + ǫ
2 = ǫ.
So the sequence is Cauchy.
Conversely, suppose that the sequence is Cauchy. Deﬁne
S = {x ∈R : x < aj for all but ﬁnitely many j}.
[Hint: You might ﬁnd it helpful to think of this set as
S = {x ∈R : there is a positive integer k such that x < aj for all j ≥k} .]
By the lemma, the sequence {aj} is bounded by some number M. If x is a real
number less than −M, then x ∈S, so S is nonempty. Also S is bounded above

2.1. CONVERGENCE OF SEQUENCES
19
by M. Let α = sup S. Then α is a well-deﬁned real number, and we claim that
α is the limit of the sequence {aj}.
To see this, let ǫ > 0. Choose an integer N > 0 such that |aj −ak| < ǫ/2
whenever j, k > N. Notice that this last inequality implies that
|aj −aN+1| < ǫ/2 when j ≥N + 1
(2.10.1)
hence
aj > aN+1 −ǫ/2 when j ≥N + 1.
Thus aN+1 −ǫ/2 ∈S and it follows that
α ≥aN+1 −ǫ/2.
(2.10.2)
Line (2.10.1) also shows that
aj < aN+1 + ǫ/2 when j ≥N + 1 .
Thus aN+1 + ǫ/2 ̸∈S and
α ≤aN+1 + ǫ/2.
(2.10.3)
Combining lines (2.10.2) and (2.10.3) gives
|α −aN+1| ≤ǫ/2.
(2.10.4)
But then line (2.10.4) yields, for j > N, that
|α −aj| ≤|α −aN+1| + |aN+1 −aj| < ǫ/2 + ǫ/2 = ǫ .
This proves that the sequence {aj} converges to α, as claimed.
Corollary 2.11 Let {αj} be a sequence of complex numbers. The sequence is
Cauchy if and only if it is convergent.
Proof: Write αj = aj + ibj, with aj, bj real. Then {αj} is Cauchy if and only if
{aj} and {bj} are Cauchy. Also {αj} is convergent to a complex limit α if and
only if {aj} converges to Re α and {bj} converges to Im α. These observations,
together with the theorem, prove the corollary.
Deﬁnition 2.12 Let {aj} be a sequence of real numbers. The sequence is said
to be increasing if a1 ≤a2 ≤. . . . It is decreasing if a1 ≥a2 ≥. . . .
A sequence is said to be monotone if it is either increasing or decreasing.
Proposition 2.13 If {aj} is an increasing sequence which is bounded above—
aj ≤M < ∞for all j—then {aj} is convergent. If {bj} is a decreasing sequence
which is bounded below—bj ≥K > −∞for all j—then {bj} is convergent.

20
CHAPTER 2. SEQUENCES
Proof: Let ǫ > 0. Let α = sup aj < ∞. By deﬁnition of supremum, there is
an integer N so that |aN −α| < ǫ. Then, if ℓ≥N + 1, we have aN ≤aℓ≤α
hence |aℓ−α| < ǫ. Thus the sequence converges to α.
The proof for decreasing sequences is similar and we omit it.
Example 2.14 Let a1 =
√
2 and set aj+1 = p2 + aj for j ≥1. You can verify
that {aj} is increasing and bounded above (by 4 for example). What is its limit
(which is guaranteed to exist by the proposition)?
A proof very similar to that of the proposition gives the following useful
fact:
Corollary 2.15 Let S be a nonempty set of real numbers which is bounded
above and below. Let β be its supremum and α its inﬁmum. If ǫ > 0 then there
are s, t ∈S such that |s −β| < ǫ and |t −α| < ǫ.
Proof: This is a restatement of the proof of the proposition.
We conclude the section by recording one of the most useful results for
calculating the limit of a sequence:
Proposition 2.16 (The Pinching Principle) Let {aj}, {bj}, and {cj} be se-
quences of real numbers satisfying
aj ≤bj ≤cj
for every j suﬃciently large. If
lim
j→∞aj = lim
j→∞cj = α
for some real number α, then
lim
j→∞bj = α .
Proof: This proof is requested of you in the exercises.
Example 2.17 Deﬁne
aj = sin j cos 2j
j2
.
Then
0 ≤|aj| ≤1
j2 .
It is clear that
lim
j→∞0 = 0

EXERCISES
21
and
lim
j→∞
1
j2 = 0 .
Therefore
lim
j→∞|aj| = 0
so that
lim
j→∞aj = 0 .
Exercises
1. Prove parts (2) and (4) of Proposition 2.6.
2. Prove the following result, which we have used without comment in the
text: Let S be a set of real numbers which is bounded above and let
t = sup S. For any ǫ > 0 there is an element s ∈S such that t −ǫ <
s ≤t.
(Remark: Notice that this result makes good intuitive sense:
the elements of S should become arbitrarily close to the supremum t,
otherwise there would be enough room to decrease the value of t and
make the supremum even smaller.) Formulate and prove a similar result
for the inﬁmum.
3. Let {aj} be a sequence of real or complex numbers. Suppose that every
subsequence has itself a subsequence which converges to a given number
α. Prove that the full sequence converges to α.
4. Let {aj} be a sequence of complex numbers. Suppose that, for every pair
of integers N > M > 0, it holds that |aM −aM+1| + |aM+1 −aM+2| +
· · · + |aN−1 −aN| ≤1. Prove that {aj} converges.
5. Let a1, a2 > 0 and for j ≥3 deﬁne aj = aj−1 + aj−2. Show that this
sequence cannot converge to a ﬁnite limit.
6. Suppose a sequence {aj} has the property that, for every natural number
N, there is a jN such that ajN = ajN+1 = · · · = ajN+N. In other words,
the sequence has arbitrarily long repetitive strings. Does it follow that
the sequence converges?
7. Let α be an irrational real number and let aj be a sequence of rational
numbers converging to α. Suppose that each aj is a fraction expressed in
lowest terms: aj = αj/βj. Prove that the βj tend to ∞.
8. Let {aj} be a sequence of rational numbers all of which have denominator
a power of 2. What are the possible limits of such a sequence?
9. Redo Exercise 8 with the additional hypothesis that all of the denomina-
tors are less then or equal to 210.

22
CHAPTER 2. SEQUENCES
10. Use the integral of 1/(1 + t2), together with Riemann sums (ideas which
you know from calculus, and which we shall treat rigorously later in the
book), to develop a scheme for calculating the digits of π.
2.2
Subsequences
Let {aj} be a given sequence. If
0 < j1 < j2 < · · ·
are positive integers then the function
k 7→ajk
is called a subsequence of the given sequence. We usually write the subsequence
as
{ajk}∞
k=1
or
{ajk} .
Example 2.18 Consider the sequence
{2j} = {2, 4, 8, . . .}.
Then the sequence
{22k} = {4, 16, 64, . . .}
(2.18.1)
is a subsequence. Notice that the subsequence contains a subcollection of ele-
ments of the original sequence in the same order. In this example, jk = 2k.
Another subsequence is
{2(2k)} = {4, 16, 256, . . .}.
In this instance, it holds that jk = 2k. Notice that this new subsequence is in fact
a subsequence of the ﬁrst subsequence (2.18.1). That is, it is a sub-subsequence
of the original sequence {2j}.
Proposition 2.19 If {aj} is a convergent sequence with limit α, then every
subsequence converges to the limit α.
Conversely, if a sequence {bj} has the property that each of its subsequences
is convergent then {bj} itself is convergent.
Proof: Assume {aj} is convergent to a limit α, and let {ajk} be a subsequence.
Let ǫ > 0 and choose N > 0 such that |aj −α| < ǫ whenever j > N. Now
if k > N then jk > N hence |ajk −α| < ǫ.
Therefore, by deﬁnition, the
subsequence {ajk} also converges to α.
The converse is trivial, simply because the sequence is a subsequence of
itself.
Now we present one of the most fundamental theorems of basic real analysis
(due to B. Bolzano, 1781-1848, and K. Weierstrass, 1815-1897).

2.2. SUBSEQUENCES
23
Theorem 2.20 (Bolzano-Weierstrass) Let {aj} be a bounded sequence in
R. Then there is a subsequence which converges.
Proof: Say that |aj| ≤M for every j. We may assume that M > 0.
One of the two intervals [−M, 0] and [0, M] must contain inﬁnitely many
elements of the sequence. Say that [0, M] does. Choose aj1 to be one of the
inﬁnitely many sequence elements in [0, M].
Next, one of the intervals [0, M/2] and [M/2, M] must contain inﬁnitely
many elements of the sequence. Say that it is [0, M/2]. Choose an element
aj2, with j2 > j1, from [0, M/2]. Continue in this fashion, halving the interval,
choosing a half with inﬁnitely many sequence elements, and selecting the next
subsequential element from that half.
Let us analyze the resulting subsequence. Notice that |aj1 −aj2| ≤M since
both elements belong to the interval [0, M]. Likewise, |aj2 −aj3| ≤M/2 since
both elements belong to [0, M/2]. In general, |ajk −ajk+1| ≤2−k+1 · M for each
k ∈N. Now let ǫ > 0. Choose an integer N > 0 such that 2−N < ǫ/(2M).
Then, for any m > l > N we have
|ajl −ajm|
=
|(ajl −ajl+1) + (ajl+1 −ajl+2) + · · · + (ajm−1 −ajm)|
≤
|ajl −ajl+1| + |ajl+1 −ajl+2| + · · · + |ajm−1 −ajm|
≤
2−l+1 · M + 2−l · M + · · · + 2−m+2 · M
=
 2−l+1 + 2−l + 2−l−1 + · · · + 2−m+2
· M
=
 (2−l+2 −2−l+1) + (2−l+1 −2−l) + . . .
+(2−m+3 −2−m+2)

· M
=
 2−l+2 −2−m+2
· M
<
2−l+2 · M
<
2 ·
ǫ
2M · M
=
ǫ.
We see that the subsequence {ajk} is Cauchy, so it converges.
Remark 2.21 The Bolzano-Weierstrass theorem is a generalization of our re-
sult from the last section about increasing sequences which are bounded above
(resp. decreasing sequences which are bounded below). For such a sequence is
surely bounded above and below (why?). So it has a convergent subsequence.
And thus it follows easily that the entire sequence converges. Details are left as
an exercise.
It is a fact—which you can verify for yourself—that any real sequence has
a monotone subsequence. This fact implies Bolzano-Weierstrass.
Example 2.22 In this text we have not yet given a rigorous deﬁnition of the
function sin x (see Section 9.3). However, just for the moment, use the deﬁnition

24
CHAPTER 2. SEQUENCES
you learned in calculus class and consider the sequence {sin j}∞
j=1. Notice that
the sequence is bounded in absolute value by 1. The Bolzano-Weierstrass the-
orem guarantees that there is a convergent subsequence, even though it would
be very diﬃcult to say precisely what that convergent subsequence is.
Corollary 2.23 Let {αj} be a bounded sequence of complex numbers. Then
there is a convergent subsequence.
Proof: Write αj = aj + ibj, with aj, bj ∈R. The fact that {αj} is bounded
implies that {aj} is bounded. By the Bolzano-Weierstrass theorem, there is a
convergent subsequence {ajk}.
Now the sequence {bjk} is bounded. So it has a convergent subsequence
{bjkl}. Then the sequence {αjkl } is convergent, and is a subsequence of the
original sequence {αj}.
In earlier parts of this chapter we have discussed sequences that converge
to a ﬁnite number. Such a sequence is, by Proposition 2.5, bounded. However,
in some mathematical contexts, it is useful to speak of a sequence “diverging1
to inﬁnity.” We now will treat brieﬂy the idea of “divergence to inﬁnity.”
Deﬁnition 2.24 We say that a sequence {aj} of real numbers diverges to +∞
if, for every M > 0, there is an integer N > 0 such that aj > M whenever
j > N. We write aj →+∞.
We say that {aj} diverges to −∞if, for every K > 0, there is an integer
N > 0 such that aj < −K whenever j > N. We write aj →−∞.
Remark 2.25 Notice that the statement aj →+∞means that we can make aj
become arbitrarily large and positive and stay large and positive just by making
j large enough.
Likewise, the statement aj →−∞means that we can force aj to be arbi-
trarily large and negative, and stay large and negative, just by making j large
enough.
Example 2.26 The sequence {j2} diverges to +∞. The sequence {−2j + 18}
diverges to −∞. The sequence {j + (−1)j · j} has no inﬁnite limit and no ﬁnite
limit. However, the subsequence {0, 0, 0, . . .} converges to 0 and the subsequence
{4, 8, 12 . . .} diverges to +∞.
With the new language provided by Deﬁnition 2.24, we may generalize
Proposition 2.13:
Proposition 2.27 Let {aj} be a increasing sequence of real numbers. Then
the sequence has a limit—either a ﬁnite number or +∞.
Let {bj} be a decreasing sequence of real numbers. Then the sequence has
a limit—either a ﬁnite number or −∞.
1Some books say “converging to inﬁnity,” but this terminology can be confusing.

EXERCISES
25
In the same spirit as the last deﬁnition, we also have the following:
Deﬁnition 2.28 If S is a set of real numbers which is not bounded above, we
say that its supremum (or least upper bound) is +∞.
If T is a set of real numbers which is not bounded below then we say that
its inﬁmum (or greatest lower bound) is −∞.
Exercises
1. Use the Bolzano-Weierstrass theorem to show that every increasing se-
quence that is bounded above converges.
2. Provide the details of the proof of Proposition 2.27.
*
3. Provide the details of the assertion, made in the text, that the sequence
{cos j} is dense in the interval [−1, 1].
4. Let n be a positive integer. Consider n, n + 1, . . . modulo π. This means
that you subtract from each number the greatest multiple of π that does
not exceed it. Prove that this collection of numbers is dense in [0, π]. That
is, the numbers get arbitrarly close to any element of this interval.
*
5. Let S = {0, 1, 1/2, 1/3, 1/4, . . .}. Give an example of a sequence {aj} with
the property that, for each s ∈S, there is a subsequence converging to s,
but no subsequence converges to any limit not in S.
*
6. Give another proof of the Bolzano-Weierstrass theorem as follows. If {aj}
is a bounded sequence let bj = inf{aj, aj+1, . . . }. Then each bj is ﬁnite,
b1 ≤b2 ≤. . . , and {bj} is bounded above. Now use Proposition 2.13.
7. Give an example of a sequence of rational numbers with the property that,
for any real number α, or for α = +∞or α = −∞, there is a subsequence
approaching α.
8. Construct a sequence α of real numbers with the property that, for every
x ∈R, there is a subsequence of α that converges to x.
9. Prove that if {aj} has a subsequence diverging to ±∞then {aj} cannot
converge.
10. Let x1 = 2. For j ≥1, set
xj+1 = xj −x2
j −2
2xj
.
Show that the sequence {xj} is decreasing and bounded below. What is
its limit?

26
CHAPTER 2. SEQUENCES
2.3
Lim sup and Lim inf
Convergent sequences are useful objects, but the unfortunate truth is that most
sequences do not converge. Nevertheless, we would like to have a language for
discussing the asymptotic behavior of any real sequence {aj} as j →∞. That
is the purpose of the concepts of “limit superior” (or “upper limit”) and “limit
inferior” (or “lower limit”).
Deﬁnition 2.29 Let {aj} be a sequence of real numbers that is bounded below.
For each j let
Aj = inf{aj, aj+1, aj+2, . . . }.
Then {Aj} is a increasing sequence (since as j becomes large we are taking the
inﬁmum of a smaller set of numbers), so it has a limit. We deﬁne the limit
inﬁmum of {aj} to be
lim inf aj = lim
j→∞Aj.
Likewise, in case the sequence is bounded above, let
Bj = sup{aj, aj+1, aj+2, . . . }.
Then {Bj} is a decreasing sequence (since as j becomes large we are taking the
supremum of a smaller set of numbers), so it has a limit. We deﬁne the limit
supremum of {aj} to be
lim sup aj = lim
j→∞Bj.
Notice that the lim sup or lim inf of a sequence can be ±∞.
Remark 2.30 What is the intuitive content of this deﬁnition? For each j, Aj
picks out the greatest lower bound of the sequence in the jth position or later. So
the sequence {Aj} should tend to the smallest possible limit of any subsequence
of {aj}.
Likewise, for each j, Bj picks out the least upper bound of the sequence
in the jth position or later. So the sequence {Bj} should tend to the greatest
possible limit of any subsequence of {aj}. We shall make this remark more
precise in Proposition 2.32 below.
Notice that it is implicit in the deﬁnition that every real sequence has a
limit supremum and a limit inﬁmum.
A further comment is that we can talk about the limit inﬁmum of a sequence
even when the sequence is not bounded below. But then some or all of the Aj
may be −∞and the limit inﬁmum may be −∞. Likewise we may discuss the
limit supremum of a sequence that is not bounded above.
Example 2.31 Consider the sequence {(−1)j}. Of course this sequence does
not converge. Let us calculate its lim sup and lim inf.
Referring to the deﬁnition, we have that Aj = −1 for every j. So
lim inf (−1)j = lim (−1) = −1.

2.3. LIM SUP AND LIM INF
27
Similarly, Bj = +1 for every j. Therefore
lim sup (−1)j = lim (+1) = +1.
As we predicted in the remark, the lim inf is the least subsequential limit,
and the lim sup is the greatest subsequential limit.
Now let us prove the characterizing property of lim sup and lim inf to which
we have been alluding.
Proposition 2.32 Let {aj} be a sequence of real numbers. Let β = lim supj→∞aj
and α = lim infj→∞aj. If {ajℓ} is any subsequence of the given sequence then
α ≤lim inf
ℓ→∞ajℓ≤lim sup
ℓ→∞
ajℓ≤β .
Moreover, there is a subsequence {ajk} such that
lim
k→∞ajk = α
and another sequence {ank} such that
lim
k→∞ank = β .
Proof: For simplicity in this proof we assume that the lim sup and lim inf are
ﬁnite. The case of inﬁnite lim sups and inﬁnite lim infs is left to Exercise 36.
We begin by considering the lim inf. There is a j1 ≥1 such that |A1−aj1| <
2−1. We choose j1 to be as small as possible. Next, we choose j2, necessarily
greater than j1, such that j2 is as small as possible and |aj2 −A2| < 2−2.
Continuing in this fashion, we select jk > jk−1 such that |ajk −Ak| < 2−k, etc.
Recall that Ak →α = lim infj→∞aj. Now ﬁx ǫ > 0. If N is an integer so
large that k > N implies that |Ak −α| < ǫ/2 and also that 2−N < ǫ/2 then for
such k we have
|ajk −α|
≤
|ajk −Ak| + |Ak −α|
<
2−k + ǫ
2
<
ǫ
2 + ǫ
2
=
ǫ .
Thus the subsequence {ajk} converges to α, the lim inf of the given sequence. A
similar construction gives a (diﬀerent) subsequence {ank} converging to β, the
lim sup of the given sequence.
Now let {ajℓ} be any subsequence of the sequence {aj}.
Let β∗be the
lim sup of this subsequence. Then, by the ﬁrst part of the proof, there is a
subsequence {ajℓm} such that
lim
m→∞ajℓm = β∗.

28
CHAPTER 2. SEQUENCES
But ajℓm ≤Bjℓm by the very deﬁnition of the Bs. Thus
β∗= lim
m→∞ajℓm ≤lim
m→∞Bjℓm = β
or
lim sup
ℓ→∞
ajℓ≤β ,
as claimed. A similar argument shows that
lim inf
l→∞ajl ≥α .
This completes the proof of the proposition.
Corollary 2.33 If {aj} is a sequence and {ajk} is a convergent subsequence
then
lim inf
j→∞aj ≤lim
k→∞ajk ≤lim sup
j→∞
aj .
We close this section with a fact that is analogous to one for the supremum
and inﬁmum. Its proof is analogous to arguments we have seen before.
Proposition 2.34 Let {aj} be a sequence and set lim sup aj = β and lim inf aj =
α. Assume that α, β are ﬁnite real numbers. Let ǫ > 0. Then there are arbi-
trarily large j such that aj > β −ǫ. Also there are arbitrarily large k such that
ak < α + ǫ.
Exercises
1. Consider {aj} both as a sequence and as a set. How are the lim sup and
the sup related? How are the lim inf and the inf related? Give examples.
2. Let {aj} be a sequence of positive numbers. How are the lim sup and
lim inf of {aj} related to the lim sup and lim inf of {1/aj}?
3. Prove the last proposition in this section.
*
4. Find the lim sup and lim inf of the sequences
{| sin j|sin j} and {| cos j|cos j}.
5. How are the lim sup and lim inf of {aj} related to the lim sup and lim inf
of {−aj}?
6. Let {aj} be a real sequence. Prove that if
lim inf aj = lim sup aj
then the sequence {aj} converges. Prove the converse as well.

2.4. SOME SPECIAL SEQUENCES
29
7. Let a < b be real numbers. Give an example of a real sequence whose
lim sup is b and whose lim inf is a.
8. Explain why we can make no sense of the concepts of lim sup and lim inf
for complex sequences.
9. Let {aj}, {bj} be sequences of real numbers. Prove the inequality lim sup(aj+
bj) ≤lim sup aj + lim sup bj. How are the lim infs related? How is the
quantity (lim sup aj) · (lim sup bj) related to lim sup(aj · bj)? How are the
lim infs related?
10. Prove a version of Proposition 2.34 when the indicated lim sup and/or
lim inf are ±∞.
2.4
Some Special Sequences
We often obtain information about a new sequence by comparison with a se-
quence that we already know. Thus it is well to have a catalogue of fundamental
sequences which provide a basis for comparison.
Example 2.35 Fix a real number a.
The sequence {aj} is called a power
sequence. If −1 < a < 1 then the sequence converges to 0. If a = 1 then the
sequence is a constant sequence and converges to 1. If a > 1 then the sequence
diverges to +∞. Finally, if a ≤−1 then the sequence diverges.
Recall that, in Section 1.1, we discussed the existence of nth roots of positive
real numbers. If α > 0, m ∈Z, and n ∈N then we may deﬁne
αm/n = (αm)1/n .
Thus we may talk about rational powers of a positive number. Next, if β ∈R
then we may deﬁne
αβ = sup{αq : q ∈Q, q < β} .
Thus we can deﬁne any real power of a positive real number. Exercise 11 asks
you to verify several basic properties of these exponentials.
Lemma 2.36 If α > 1 is a real number and β > 0 then αβ > 1.
Proof: Let q be a positive rational number which is less than β. Say that
q = m/n, with m, n integers.
It is obvious that αm > 1 and hence that
(αm)1/n > 1. Since αβ majorizes this last quantity, we are done.
Example 2.37 Fix a real number α and consider the sequence {jα}. If α > 0
then it is easy to see that jα →+∞: to verify this assertion ﬁx M > 0 and take
the number N to be the ﬁrst integer after M 1/α.
If α = 0 then jα is a constant sequence, identically equal to 1.
If α < 0 then jα = 1/j−α. The denominator of this last expression tends
to +∞hence the sequence jα tends to 0.

30
CHAPTER 2. SEQUENCES
Example 2.38 The sequence {j1/j} converges to 1. In fact, consider the ex-
pressions αj = j1/j −1 > 0. We have that
j = (αj + 1)j ≥j(j −1)
2
(αj)2 ,
(the latter being just one term from the binomial expansion). Thus
0 < αj ≤
p
2/(j −1)
as long as j ≥2. It follows that αj →0 or j1/j →1.
Example 2.39 Let α be a positive real number. Then the sequence α1/j con-
verges to 1. To see this, ﬁrst note that the case α = 1 is trivial, and the case
α > 1 implies the case α < 1 (by taking reciprocals). So we concentrate on
α > 1. But then we have
1 < α1/j < j1/j
when j > α. Since j1/j tends to 1, Proposition 2.16 applies and the proof is
complete.
Example 2.40 Let λ > 1 and let α be real. Then the sequence
jα
λj
∞
j=1
converges to 0.
To see this, ﬁx an integer k > α and consider j > 2k. [Notice that k is
ﬁxed once and for all but j will be allowed to tend to +∞at the appropriate
moment.] Writing λ = 1 + µ, µ > 0, we have that
λj = (1 + µ)j > j(j −1)(j −2) · · · (j −k + 1)
k(k −1)(k −2) · · · 2 · 1
µk · 1j−k .
Of course this comes from picking out the kth term of the binomial expansion
for (1 + µ)j. Notice that, since j > 2k, then each of the expressions j, (j −
1), . . . (j −k + 1) in the numerator on the right exceeds j/2. Thus
λj >
jk
2k · k! · µk
and
0 < jα
λj < jα · 2k · k!
jk · µk = jα−k · 2k · k!
µk
.
Since α −k < 0, the right side tends to 0 as j →∞.
Example 2.41 The sequence
(
1 + 1
j
j)

EXERCISES
31
converges. In fact it is increasing and bounded above. Use the Binomial Ex-
pansion to prove this assertion. The limit of the sequence is the number that
we shall later call e (in honor of Leonhard Euler, 1707-1783, who ﬁrst studied
it in detail). We shall study this sequence in detail later in the book.
Example 2.42 The sequence

1 −1
j
j
converges to 1/e, where the deﬁnition of e is given in the last example. More
generally, the sequence

1 + x
j
j
converges to ex (here ex is deﬁned as in the discussion following Example 2.35
above).
Exercises
1. Let α be a positive real number and let p/q = m/n be two diﬀerent
representations of the same rational number r. Prove that
(αm)1/n = (αp)1/q .
Also prove that
(α1/n)m = (αm)1/n.
If β is another positive real and γ is any real then prove that
(α · β)γ = αγ · βγ .
*
2. Prove that

1 + x
j
j
converges to ex for any real number x.
3. Discuss the convergence of the sequence {(1/j)1/j}∞
j=1.
4. Discuss the convergence of the sequence {(jj)/(2j)!}∞
j=1.
5. Consider the sequence given by
aj =

1 + 1
2 + 1
3 + · · · + 1
j

−log j .
Use a picture (remember that log is the antiderivative of 1/x) to give a
convincing argument that the sequence {aj} converges. The limit number
is called γ. This number was ﬁrst studied by Euler. It arises in many
diﬀerent contexts in analysis and number theory.

32
CHAPTER 2. SEQUENCES
As a challenge problem, show that
|aj −γ| ≤C
j
for some universal constant C > 0.
It is not known whether γ is rational or irrational.
6. Give a recursive deﬁnition of the Fibonacci sequence. Find a generating
function for the Fibonacci sequence and use it to derive an explicit formula
for the nth term of the sequence.
7. A sequence is deﬁned by the rule a0 = 2, a1 = 1, and aj = 3aj−1 −aj−2.
Find a formula for aj.
8. A sequence is deﬁned by the rule a0 = 4, a1 = −1, and aj = −aj−1+2aj−2.
Find a formula for aj.
9. Prove that the exponential, as deﬁned in this section, satisﬁes
(ab)c = abc
and
abac = ab+c .

Chapter 3
Series of Numbers
3.1
Convergence of Series
In this section we will use standard summation notation:
n
X
j=m
aj ≡am + am+1 + · · · + an .
A series is an inﬁnite sum. One of the most eﬀective ways to handle an inﬁnite
process in mathematics is with a limit. This consideration leads to the following
deﬁnition:
Deﬁnition 3.1 The formal expression
∞
X
j=1
aj ,
where the ajs are real or complex numbers, is called a series. For N = 1, 2, 3, . . .,
the expression
SN =
N
X
j=1
aj = a1 + a2 + . . . aN
is called the Nth partial sum of the series. In case
lim
N→∞SN
exists and is ﬁnite we say that the series converges. The limit of the partial
sums is called the sum of the series. If the series does not converge, then we say
that the series diverges.
Notice that the question of convergence of a series, which should be thought of
as an addition process, reduces to a question about the sequence of partial sums.
33

34
CHAPTER 3. SERIES OF NUMBERS
Example 3.2 Consider the series
∞
X
j=1
2−j .
The Nth partial sum for this series is
SN = 2−1 + 2−2 + · · · + 2−N .
In order to determine whether the sequence {SN} has a limit, we rewrite SN as
SN
=
 2−0 −2−1
+
 2−1 −2−2
+ . . .
 2−N+1 −2−N
.
The expression on the right of the last equation telescopes (i.e., successive pairs
of terms cancel) and we ﬁnd that
SN = 2−0 −2−N .
Thus
lim
N→∞SN = 2−0 = 1 .
We conclude that the series converges.
Example 3.3 Let us examine the series
∞
X
j=1
1
j
for convergence or divergence. Now
S1
=
1 = 2
2
S2
=
1 + 1
2 = 3
2
S4
=
1 + 1
2 +
1
3 + 1
4

≥
1 + 1
2 +
1
4 + 1
4

≥1 + 1
2 + 1
2 = 4
2
S8
=
1 + 1
2 +
1
3 + 1
4

+
1
5 + 1
6 + 1
7 + 1
8

≥
1 + 1
2 +
1
4 + 1
4

+
1
8 + 1
8 + 1
8 + 1
8

=
5
2 .
In general this argument shows that
S2k ≥k + 2
2
.

3.1. CONVERGENCE OF SERIES
35
The sequence of SNs is increasing since the series contains only positive
terms. The fact that the partial sums S1, S2, S4, S8, . . . increases without bound
shows that the entire sequence of partial sums must increase without bound.
We conclude that the series diverges.
Just as with sequences, we have a Cauchy criterion for series:
Proposition 3.4 The series P∞
j=1 aj converges if and only if, for every ǫ > 0,
there is an integer N ≥1 such that, if n ≥m > N, then

n
X
j=m
aj

< ǫ.
(3.4.1)
The condition (3.4.1) is called the Cauchy criterion for series.
Proof: Suppose that the Cauchy criterion holds. Pick ǫ > 0 and choose N so
large that (3.4.1) holds. If n ≥m > N, then
|Sn −Sm| =

n
X
j=m+1
aj

< ǫ
by hypothesis. Thus the sequence {SN} is Cauchy in the sense discussed for
sequences in Section 2.1. We conclude that the sequence {SN} converges; by
deﬁnition, therefore, the series converges.
Conversely, if the series converges then, by deﬁnition, the sequence {SN}
of partial sums converges. In particular, the sequence {SN} must be Cauchy.
Thus, for any ǫ > 0, there is a number N > 0 such that if n ≥m > N then
|Sn −Sm| < ǫ .
This just says that

n
X
j=m+1
aj

< ǫ ,
and this last inequality is the Cauchy criterion for series.
Example 3.5 Let us use the Cauchy criterion to verify that the series
∞
X
j=1
1
j · (j + 1)
converges.
Notice that, if n ≥m > 1, then

36
CHAPTER 3. SERIES OF NUMBERS

n
X
j=m
1
j · (j + 1)

=
 1
m −
1
m + 1

+

1
m + 1 −
1
m + 2

+ . . .
+
 1
n −
1
n + 1

.
The sum on the right plainly telescopes and we have

n
X
j=m
1
j · (j + 1)

= 1
m −
1
n + 1 .
Let ǫ > 0. Let us choose N to be the next integer after 1/ǫ. Then, for n ≥m >
N, we may conclude that

n
X
j=m
1
j · (j + 1)

= 1
m −
1
n + 1 < 1
m < 1
N < ǫ .
This is the desired conclusion.
The next result gives a necessary condition for a series to converge. It is a
useful device for detecting divergent series, although it can never tell us that a
series converges.
Proposition 3.6 (The Zero Test) If the series
∞
X
j=1
aj
converges then the terms aj tend to zero as j →∞.
Proof: Since we are assuming that the series converges, then it must satisfy
the Cauchy criterion. Let ǫ > 0. Then there is an integer N ≥1 such that, if
n ≥m > N, then

n
X
j=m
aj

< ǫ .
(3.6.1)
We take n = m and m > N. Then (3.6.1) becomes
|am| < ǫ .
But this is precisely the conclusion that we desire.

EXERCISES
37
Example 3.7 The series P∞
j=1(−1)j must diverge, even though its terms appear
to be cancelling each other out. The reason is that the summands do not tend
to zero; hence the preceding proposition applies.
Write out several partial sums of this series to see more explicitly that the
partial sums are −1, +1, −1, +1, . . . and hence that the series diverges.
We conclude this section with a necessary and suﬃcient condition for con-
vergence of a series of nonnegative terms. As with some of our other results on
series, it amounts to little more than a restatement of a result on sequences.
Proposition 3.8 A series
∞
X
j=1
aj
with all aj ≥0 is convergent if and only if the sequence of partial sums is
bounded.
Proof: Notice that, because the summands are nonnegative, we have
S1 = a1 ≤a1 + a2 = S2 ,
S2 = a1 + a2 ≤a1 + a2 + a3 = S3 ,
and in general
SN ≤SN + aN+1 = SN+1 .
Thus the sequence {SN} of partial sums forms a increasing sequence. We know
that such a sequence is convergent to a ﬁnite limit if and only if it is bounded
above (see Section 2.1). This completes the proof.
Example 3.9 The series P∞
j=1 1 is divergent since the summands are nonneg-
ative and the sequence of partial sums {SN} = {N} is unbounded.
Referring back to Example 3.3, we see that the series P∞
j=1
1
j diverges be-
cause its partial sums are unbounded.
We see from the ﬁrst example that the series P∞
j=1 2−j converges because
its partial sums are all bounded above by 1.
It is frequently convenient to begin a series with summation at j = 0 or
some other term instead of j = 1. All of our convergence results still apply to
such a series because of the Cauchy criterion. In other words, the convergence
or divergence of a series will depend only on the behavior of its “tail.”
Exercises
1. Discuss convergence or divergence for each of the following series:

38
CHAPTER 3. SERIES OF NUMBERS
(a)
∞
X
j=1
(2j)2
j!
(b)
∞
X
j=1
(2j)!
(3j)!
(c)
∞
X
j=1
j!
jj
(d)
∞
X
j=1
(−1)j
3j2 −5j + 6
(e)
∞
X
j=1
2j −1
3j2 −2
(f)
∞
X
j=1
2j −1
3j3 −2
(g)
∞
X
j=1
log(j + 1)
[1 + log j]j
(h)
∞
X
j=12
1
j log3 j
(i)
∞
X
j=2
log(1)
log j
(j)
∞
X
j=2
1
j log1.1 j
2. If bj > 0 for every j and if P∞
j=1 bj converges then prove that P∞
j=1(bj)2
converges. Prove that the assertion is false if the positivity hypothesis is
omitted. How about third powers?
3. If bj > 0 for every j and if P∞
j=1 bj converges then prove that P∞
j=1
1
1+bj
diverges.
4. Let P∞
j=1 aj be a divergent series of positive terms. Prove that there exist
numbers bj, 0 < bj < aj, such that P∞
j=1 bj diverges.
Similarly, let P∞
j=1 cj be a convergent series of positive terms. Prove that
there exist numbers dj, 0 < cj < dj, such that P∞
j=1 dj converges.
Thus we see that there is no “smallest” divergent series and no “largest”
convergent series.
5. TRUE or FALSE: If aj > c > 0 and P 1/aj converges, then P aj con-
verges.
*
6. Discuss convergence and divergence for the series P
j(sin j)/j and
P
j(sin j)2/j.
7. If bj > 0 and P
j bj converges then what can you say about P
j bj/(1+bj)?
8. If bj > 0 and P
j bj diverges, then what can you say about P
j 2−jbj?
9. If bj > 0 and P
j bj converges, then what can you say about P
j bj/j2?
10. If aj > 0 and P
j a2
j converges, then what can you say about P
j a4
j? How
about P
j a3
j?

3.2. ELEMENTARY CONVERGENCE TESTS
39
3.2
Elementary Convergence Tests
As previously noted, a series may converge because its terms are nonnegative
and diminish in size fairly rapidly (thus causing its partial sums to grow slowly)
or it may converge because of cancellation among the terms. The tests which
measure the ﬁrst type of convergence are the most obvious and these are the
“elementary” ones that we discuss in the present section.
Proposition 3.10 (The Comparison Test) Suppose that P∞
j=1 aj is a con-
vergent series of nonnegative terms. If {bj} are real or complex numbers and if
|bj| ≤aj for every j then the series P∞
j=1 bj converges.
Proof: Because the ﬁrst series converges, its satisﬁes the Cauchy criterion for
series. Hence, given ǫ > 0, there is an N so large that if n ≥m > N then

n
X
j=m
aj

< ǫ .
But then

n
X
j=m
bj

≤
n
X
j=m
|bj| ≤
n
X
j=m
aj < ǫ .
It follows that the series P bj satisﬁes the Cauchy criterion for series. Therefore
it converges.
Corollary 3.11 If P∞
j=1 aj is as in the proposition and if 0 ≤bj ≤aj for every
j then the series P∞
j=1 bj converges.
Proof: Obvious.
Example 3.12 The series P∞
j=1 2−j sin j is seen to converge by comparing it
with the series P∞
j=1 2−j.
Theorem 3.13 (The Cauchy Condensation Test) Assume that a1 ≥a2 ≥
· · · ≥aj ≥. . . 0. The series
∞
X
j=1
aj
converges if and only if the series
∞
X
k=1
2k · a2k
converges.

40
CHAPTER 3. SERIES OF NUMBERS
Proof: First assume that the series P∞
j=1 aj converges. Notice that, for each
k ≥1,
2k−1 · a2k
=
a2k + a2k + · · · + a2k
|
{z
}
2k−1 times
≤
a2k−1+1 + a2k−1+2 + · · · + a2k.
=
2k
X
m=2k−1+1
am
Therefore
N
X
k=1
2k−1 · a2k ≤
N
X
k=1
2k
X
m=2k−1+1
am =
2N
X
m=2
am .
Since the partial sums on the right are bounded (because the series of ajs
converges), so are the partial sums on the left. It follows that the series
∞
X
k=1
2k · a2k
converges.
For the converse, assume that the series
∞
X
k=1
2k · a2k
(3.13.1)
converges. Observe that, for k ≥1,
2k
X
m=2k−1+1
aj
=
a2k−1+1 + a2k−1+2 + · · · + a2k
≤
a2k−1 + a2k−1 + · · · + a2k−1
|
{z
}
2k−1 times
=
2k−1 · a2k−1 .
It follows that
2N
X
m=2
aj
=
N
X
k=1
2k
X
m=2k−1+1
am
≤
N
X
k=1
2k−1 · a2k−1 .

3.2. ELEMENTARY CONVERGENCE TESTS
41
By the hypothesis that the series (3.13.1) converges, the partial sums on the
right must be bounded. But then the partial sums on the left are bounded as
well. Since the summands aj are nonnegative, the series on the left converges.
Example 3.14 We apply the Cauchy condensation test to the harmonic series
∞
X
j=1
1
j .
It leads us to examine the series
∞
X
k=1
2k · 1
2k =
∞
X
k=1
1 .
Since the latter series diverges, the harmonic series diverges as well.
Proposition 3.15 (Geometric Series) Let α be a complex number.
The
series
∞
X
j=0
αj
is called a geometric series. It converges if and only if |α| < 1. In this circum-
stance, the sum of the series (that is, the limit of the partial sums) is 1/(1 −α).
Proof: Let SN denote the Nth partial sum of the geometric series. Then
α · SN
=
α(1 + α + α2 + . . . αN)
=
α + α2 + . . . αN+1 .
It follows that α · SN and SN are nearly the same: in fact
α · SN + 1 −αN+1 = SN .
Solving this equation for the quantity SN yields
SN = 1 −αN+1
1 −α
when α ̸= 1.
If |α| < 1 then αN+1 →0, hence the sequence of partial sums tends to the
limit 1/(1 −α). If |α| > 1 then αN+1 diverges, hence the sequence of partial
sums diverges. This completes the proof for |α| ̸= 1. But the divergence in case
|α| = 1 follows because the summands will not tend to zero.
Corollary 3.16 The series
∞
X
j=1
1
jr
converges if r is a real number that exceeds 1 and diverges otherwise.

42
CHAPTER 3. SERIES OF NUMBERS
Proof: When r > 1 we can apply the Cauchy Condensation Test. This leads
us to examine the series
∞
X
k=1
2k · 2−kr =
∞
X
k=1
 21−rk .
This last is a geometric series, with the role of α played by the quantity α = 21−r.
When r > 1 then |α| < 1 so the series converges. Otherwise it diverges.
Theorem 3.17 (The Root Test) Consider the series
∞
X
j=1
aj .
If
lim sup
j→∞
|aj|1/j < 1
then the series converges.
Proof: Refer again to the discussion of the concept of limit superior in Chapter
2. By our hypothesis, there is a number 0 < β < 1 and an integer N > 1 such
that for all j > N it holds that
|aj|1/j < β .
In other words,
|aj| < βj .
Since 0 < β < 1 the sum of the terms on the right constitutes a convergent
geometric series. By the Comparison Test, the sum of the terms on the left
converges.
Theorem 3.18 (The Ratio Test) Consider a series
∞
X
j=1
aj .
If
lim sup
j→∞

aj+1
aj
 < 1
then the series converges.
Proof: It is possible to supply a proof similar to that of the Root Test. We leave
such a proof for the exercises, and instead supply an argument which relates
the two tests in an interesting fashion.

3.2. ELEMENTARY CONVERGENCE TESTS
43
Let
λ = lim sup
j→∞

aj+1
aj
 < 1 .
Select a real number µ such that λ < µ < 1. By the deﬁnition of lim sup, there
is an N so large that if j > N then

aj+1
aj
 < µ .
This may be rewritten as
|aj+1| < µ · |aj|
,
j ≥N .
Thus (much as in the proof of the Root Test) we have for k ≥0 that
|aN+k| ≤µ · |aN+k−1| ≤µ · µ · |aN+k−2| ≤· · · ≤µk · |aN| .
It is convenient to denote N + k by n, n ≥N. Thus the last inequality reads
|an| < µn−N · |aN|
or
|an|1/n < µ(n−N)/n · |aN|1/n .
Remembering that N has been ﬁxed once and for all, we pass to the lim sup as
n →∞. The result is
lim sup
n→∞|an|1/n ≤µ .
Since µ < 1, we ﬁnd that our series satisﬁes the hypotheses of the Root Test.
Hence it converges.
Remark 3.19 The proof of the Ratio Test shows that if a series passes the
Ratio Test then it passes the Root Test (the converse is not true, as you will
learn in Exercise 11). Put another way, the Root Test is a better test than the
Ratio Test because it will give information whenever the Ratio Test does and
also in some circumstances when the Ratio Test does not.
Why do we therefore learn the Ratio Test? The answer is that there are
circumstances when the Ratio Test is easier to apply than the Root Test.
Example 3.20 The series
∞
X
j=1
2j
j!
is easily studied using the Ratio Test (recall that j! ≡j ·(j −1)·. . . 2·1). Indeed
aj = 2j/j! and

aj+1
aj
 = 2j+1/(j + 1)!
2j/j!
.

44
CHAPTER 3. SERIES OF NUMBERS
We can perform the division to see that

aj+1
aj
 =
2
j + 1 .
The lim sup of the last expression is 0. By the Ratio Test, the series converges.
Notice that in this example, while the Root Test applies in principle, it
would be diﬃcult to use in practice.
Example 3.21 We apply the Root Test to the series
∞
X
j=1
j2
2j .
Observe that
aj = j2
2j
hence that
|aj|1/j =
 j1/j2
2
.
As j →∞, we see that
lim sup
j→∞
|aj|1/j = 1
2 .
By the Root Test, the series converges.
It is natural to ask whether the Ratio and Root Tests can detect divergence.
Neither test is necessary and suﬃcient: there are series which elude the analysis
of both tests.
However, the arguments that we used to establish Theorems
3.17 and 3.18 can also be used to establish the following (the proofs are left as
exercises):
Theorem 3.22 (The Root Test for Divergence) Consider the series
∞
X
j=1
aj
of nonzero terms. If
lim sup
j→∞
|aj|1/j > 1
then the series diverges.
Theorem 3.23 (The Ratio Test for Divergence) Consider the series
∞
X
j=1
aj .

EXERCISES
45
If there is an N > 0 such that
aj+1
aj
 ≥1 ,
∀j ≥N
then the series diverges.
In both the Root Test and the Ratio Test, if the lim sup is equal to 1, then
no conclusion is possible. The exercises give examples of series, some of which
converge and some of which do not, in which these tests give lim sup equal to 1.
Exercises
y
1. Let p be a polynomial with no constant term. If bj > 0 for every j and if
P∞
j=1 bj converges then prove that the series P∞
j=1 p(bj) converges.
2. Examine the series
1
3 + 1
5 + 1
32 + 1
52 + 1
33 + 1
53 + 1
34 + 1
54 + . . .
Prove that the Root Test shows that the series converges while the Ratio
Test gives no information.
3. Check that both the Root Test and the Ratio Test give no information
for the series P∞
j=1
1
j , P∞
j=1
1
j2 . However, one of these series is divergent
and the other is convergent.
4. Prove Theorem 3.22.
5. Prove Theorem 3.23.
6. Let aj be a sequence of real numbers. Deﬁne
mj = a1 + a2 + . . . aj
j
.
Prove that if limj→∞aj = ℓthen limj→∞mj = ℓ. Give an example to
show that the converse is not true.
7. Imitate the proof of the Root Test to give a direct proof of the Ratio Test.
8. Let P
j aj and P
j bj be series of positive terms. Prove that if there is a
constant C > 0 such that
1
C ≤aj
bj
≤C
for all j large then either both series diverge or both series converge.
9. TRUE or FALSE: If P aj converges, then P(aj)3 converges. What hap-
pens if we replace the power 3 with some other power?
10. TRUE or FALSE: If the aj are positive P aj converges then P aj/j con-
verges.

46
CHAPTER 3. SERIES OF NUMBERS
3.3
Advanced Convergence Tests
In this section we consider convergence tests for series which depend on cancel-
lation among the terms of the series. One of the most profound of these depends
on a technique called summation by parts. You may wonder whether this pro-
cess is at all related to the “integration by parts” procedure that you learned in
calculus—it certainly has a similar form. Indeed it will turn out (and we shall
see the details of this assertion as the book develops) that summing a series and
performing an integration are two aspects of the same limiting process. The
summation by parts method is merely our ﬁrst glimpse of this relationship.
Proposition 3.24 (Summation by Parts) Let {aj}∞
j=0 and {bj}∞
j=0 be two
sequences of real or complex numbers. For N = 0, 1, 2, . . . set
AN =
N
X
j=0
aj
(we adopt the convention that A−1 = 0). Then, for any 0 ≤m ≤n < ∞, it
holds that
n
X
j=m
aj · bj
=
[An · bn −Am−1 · bm]
+
n−1
X
j=m
Aj · (bj −bj+1) .
Proof: We write
n
X
j=m
aj · bj
=
n
X
j=m
(Aj −Aj−1) · bj
=
n
X
j=m
Aj · bj −
n
X
j=m
Aj−1 · bj
=
n
X
j=m
Aj · bj −
n−1
X
j=m−1
Aj · bj+1
=
n−1
X
j=m
Aj · (bj −bj+1) + An · bn −Am−1 · bm .
This is what we wished to prove.
Now we apply summation by parts to prove a convergence test due to Niels
Henrik Abel (1802-1829).
Theorem 3.25 (Abel’s Convergence Test) Consider the series
∞
X
j=0
aj · bj .

3.3. ADVANCED CONVERGENCE TESTS
47
Suppose that
1. The partial sums AN = PN
j=0 aj form a bounded sequence;
2. b0 ≥b1 ≥b2 ≥. . . ;
3. limj→∞bj = 0.
Then the original series
∞
X
j=0
aj · bj
converges.
Proof: Suppose that the partial sums AN are bounded in absolute value by a
number K. Pick ǫ > 0 and choose an integer N so large that bN < ǫ/(2K). For
N ≤m ≤n < ∞we use the partial summation formula to write

n
X
j=m
aj · bj

=

An · bn −Am−1 · bm +
n−1
X
j=m
Aj · (bj −bj+1)

≤
K · |bn| + K · |bm| + K ·
n−1
X
j=m
|bj −bj+1| .
Now we take advantage of the facts that bj ≥0 for all j and that bj ≥bj+1 for
all j to estimate the last expression by
K ·

bn + bm +
n−1
X
j=m
(bj −bj+1)

.
[Notice that the expressions bj −bj+1, bm, and bn are all nonnegative.] Now the
sum collapses and the last line is estimated by
K · [bn + bm −bn + bm] = 2 · K · bm .
By our choice of N the right side is smaller than ǫ. Thus our series satisﬁes the
Cauchy criterion and therefore converges.
Example 3.26 (The Alternating Series Test) As a ﬁrst application of
Abel’s convergence test, we examine alternating series.
Consider a series of
the form
∞
X
j=1
(−1)j · bj ,
(3.26.1)

48
CHAPTER 3. SERIES OF NUMBERS
with b1 ≥b2 ≥b3 ≥· · · ≥0 and bj →0 as j →∞. We set aj = (−1)j and apply
Abel’s test. We see immediately that all partial sums AN are either −1 or 0. In
particular, this sequence of partial sums is bounded. And the bjs are decreasing
and tending to zero. By Abel’s convergence test, the alternating series (3.26.1)
converges.
Proposition 3.27 Let b1 ≥b2 ≥. . . and assume that bj →0. Consider the
alternating series P∞
j=1(−1)jbj as in the last example. It is convergent: let S
be its sum. Then the partial sums SN satisfy |S −SN| ≤bN+1.
Proof: Observe that
|S −SN| = |bN+1 −bN+2 + bN+3 −+ . . . | .
But
bN+2 −bN+3 + −. . .
≤
bN+2 + (−bN+3 + bN+3)
+(−bN+5 + bN+5) + . . .
=
bN+2
and
bN+2 −bN+3 + −. . .
≥
(bN+2 −bN+2) + (bN+4 −bN+4) + . . .
=
0 .
It follows that
|S −SN| ≤|bN+1|
as claimed.
Example 3.28 Consider the series
∞
X
j=1
(−1)j 1
j .
Then the partial sum S100 = −.688172 is within 0.01 (in fact within 1/101) of
the full sum S and the partial sum S10000 = −.6930501 is within 0.0001 (in fact
within 1/10001) of the sum S.
Example 3.29 Next we examine a series which is important in the study of
Fourier analysis. Consider the series
∞
X
j=1
sin j
j
.
(3.29.1)
We already know that the series P 1
j diverges. However, the expression sin j
changes sign in a rather sporadic fashion. We might hope that the series (3.29.1)

3.3. ADVANCED CONVERGENCE TESTS
49
converges because of cancellation of the summands. We take aj = sin j and
bj = 1/j. Abel’s test will apply if we can verify that the partial sums AN of the
ajs are bounded. To see this we use a trick:
Observe that
cos(j + 1/2) = cos j · cos 1/2 −sin j · sin 1/2
and
cos(j −1/2) = cos j · cos 1/2 + sin j · sin 1/2 .
Subtracting these equations and solving for sin j yields that
sin j = cos(j −1/2) −cos(j + 1/2)
2 · sin 1/2
.
We conclude that
AN =
N
X
j=1
aj =
N
X
j=1
cos(j −1/2) −cos(j + 1/2)
2 · sin 1/2
.
Of course this sum collapses and we see that
AN = −cos(N + 1/2) + cos 1/2
2 · sin 1/2
.
Thus
|AN| ≤
2
2 · sin 1/2 =
1
sin 1/2 ,
independent of N.
Thus the hypotheses of Abel’s test are veriﬁed and the series
∞
X
j=1
sin j
j
converges.
Remark 3.30 It is interesting to notice that both the series
∞
X
j=1
| sin j|
j
and
∞
X
j=1
sin2 j
j
diverge. The proofs of these assertions are left as exercises for you.
We turn next to the topic of absolute and conditional convergence. A series
of real or complex constants
∞
X
j=1
aj

50
CHAPTER 3. SERIES OF NUMBERS
is said to be absolutely convergent if
∞
X
j=1
|aj|
converges. We have:
Proposition 3.31 If the series P∞
j=1 aj is absolutely convergent, then it is
convergent.
Proof: This is an immediate corollary of the Comparison Test.
Deﬁnition 3.32 A series P∞
j=1 aj is said to be conditionally convergent if
P∞
j=1 aj converges, but it does not converge absolutely.
We see that absolutely convergent series are convergent but the next exam-
ple shows that the converse is not true.
Example 3.33 The series
∞
X
j=1
(−1)j
j
converges by the Alternating Series Test. However, it is not absolutely conver-
gent because the harmonic series
∞
X
j=1
1
j
diverges.
There is a remarkable robustness result for absolutely convergent series that
fails dramatically for conditionally convergent series. This result is enunciated
in the next theorem. We ﬁrst need a deﬁnition.
Deﬁnition 3.34 Let P∞
j=1 aj be a given series. Let {pj}∞
j=1 be a sequence in
which every positive integer occurs once and only once (but not necessarily in
the usual order). We call {pj} a permutation of the natural numbers.
Then the series
∞
X
j=1
apj
is said to be a rearrangement of the given series.
Theorem 3.35 (Riemann, Weierstrass) If the series P∞
j=1 aj of real num-
bers is absolutely convergent to a (limiting) sum ℓ, then every rearrangement
of the series converges also to ℓ. If the real series P∞
j=1 bj is conditionally con-
vergent and if β is any real number or ±∞then there is a rearrangement of the
series such that its sequence of partial sums converges to β.

EXERCISES
51
Proof: We prove the ﬁrst assertion here and explore the second in the exercises.
Let us choose a rearrangement of the given series and denote it by P∞
j=1 apj,
where pj is a permutation of the positive integers. Pick ǫ > 0. By the hypothesis
that the original series converges absolutely we may choose an integer N > 0
such that N < m ≤n < ∞implies that
n
X
j=m
|aj| < ǫ .
(3.35.1)
[The presence of the absolute values in the left side of this inequality will prove
crucial in a moment.] Choose a positive integer M such that M ≥N and the
integers 1, . . . , N are all contained in the list p1, p2, . . . , pM. If K > M then the
partial sum PK
j=1 aj will trivially contain the summands a1, a2, . . . aN. Also the
partial sum PK
j=1 apj will contain the summands a1, a2, . . . aN. It follows that
K
X
j=1
aj −
K
X
j=1
apj
will contain only summands after the Nth one in the original series. By inequal-
ity (3.35.1) we may conclude that

K
X
j=1
aj −
K
X
j=1
apj

≤
∞
X
j=N+1
|aj| ≤ǫ .
We conclude that the rearranged series converges; and it converges to the same
sum as the original series.
Exercises
1. If 1/2 > bj > 0 for every j and if P∞
j=1 bj converges then prove that
P∞
j=1
bj
1−bj converges.
2. Follow these steps to give another proof of the Alternating Series Test: a)
Prove that the odd partial sums form an increasing sequence; b) Prove
that the even partial sums form a decreasing sequence; c) Prove that
every even partial sum majorizes all subsequent odd partial sums; d) Use
a pinching principle.
3. What can you say about the convergence or divergence of
∞
X
j=1
(2j + 3)1/2 −(2j)1/2
j3/4
?

52
CHAPTER 3. SERIES OF NUMBERS
4. If bj > 0 and P∞
j=1 bj converges then prove that
∞
X
j=1
(bj)1/2 · 1
jα
converges for any α > 1/2. Give an example to show that the assertion is
false if α = 1/2.
5. For which exponents k and ℓdoes the series
∞
X
j=2
1
jk| log j|ℓ
converge?
6. Let p be a polynomial with integer coeﬃcients and degree at least 1. Let
b1 ≥b2 ≥· · · ≥0 and assume that bj →0. Prove that if (−1)p(j) is not
always positive and not always negative then in fact it will alternate in
sign so that P∞
j=1(−1)p(j) · bj will converge.
*
7. Assume that P∞
j=1 bj is a convergent series of positive real numbers. Let
sj = Pj
ℓ=1 bℓ. Discuss convergence or divergence for the series P∞
j=1 sj ·bj.
Discuss convergence or divergence for the series P∞
j=1
bj
1+sj .
*
8. If bj > 0 for every j and if P∞
j=1 bj diverges then deﬁne sj = Pj
ℓ=1 bℓ.
Discuss convergence or divergence for the series P∞
j=1
bj
sj .
*
9. Let P∞
j=1 bj be a conditionally convergent series of real numbers.
Let
β be a real number. Prove that there is a rearrangement of the series
that converges to β.
(Hint: First observe that the positive terms of
the given series must form a divergent series. Also, the negative terms
form a divergent series. Now build the rearrangement by choosing ﬁnitely
many positive terms whose sum “just exceeds” β. Then add on enough
negative terms so that the sum is “just less than” β. Repeat this oscillatory
procedure.)
*
10. Let P∞
j=1 aj be a conditionally convergent series of complex numbers.
Let S be the set of all possible complex numbers to which the various
rearrangements could converge. What forms can S have? (Hint: Exper-
iment!)
3.4
Some Special Series
We begin with a series that deﬁnes a special constant of mathematical analysis.

3.4. SOME SPECIAL SERIES
53
Deﬁnition 3.36 The series
∞
X
j=0
1
j! ,
where j! ≡j · (j −1) · (j −2) · · · 1 for j ≥1 and 0! ≡1, is convergent (by
the Ratio Test, for instance). Its sum is denoted by the symbol e in honor of
the Swiss mathematician L´eonard Euler, who ﬁrst studied it (see also Example
2.41, where the number e is studied by way of a sequence). We shall see in
Proposition 3.37 that these two approaches to the number e are equivalent.
Like the number π, to be considered later in this book, the number e is
one which arises repeatedly in a number of contexts in mathematics. It has
many special properties. We ﬁrst relate the series deﬁnition of e to the sequence
deﬁnition:
Proposition 3.37 The limit
lim
n→∞

1 + 1
n
n
exists and equals e.
Proof: We need to compare the quantities
AN ≡
N
X
j=0
1
j!
and
BN ≡

1 + 1
N
N
.
We use the binomial theorem to expand BN :
BN
=
1 + N
1 · 1
N + N · (N −1)
2 · 1
· 1
N 2 + N · (N −1) · (N −2)
3 · 2 · 1
· 1
N 3
+ . . . N
1 ·
1
N N−1 + 1 ·
1
N N
=
1 + 1 + 1
2! · N −1
N
+ 1
3! · N −1
N
· N −2
N
+ . . .
+
1
(N −1)! · N −1
N
· N −2
N
· · · 2
N
+ 1
N! · N −1
N
· N −2
N
· · · 1
N
=
1 + 1 + 1
2! ·

1 −1
N

+ 1
3! ·

1 −1
N

·

1 −2
N

+ . . .
+
1
(N −1)! ·

1 −1
N

·

1 −2
N

· · ·

1 −N −2
N

+ 1
N! ·

1 −1
N

·

1 −2
N

· · ·

1 −N −1
N

.

54
CHAPTER 3. SERIES OF NUMBERS
Notice that every summand that appears in this last equation is positive. Thus,
for 0 ≤M ≤N,
BN
≥
1 + 1 + 1
2! ·

1 −1
N

+ 1
3! ·

1 −1
N

·

1 −2
N

+ · · · + 1
M! ·

1 −1
N
 
1 −2
N

· · ·

1 −M −1
N

.
In this last inequality we hold M ﬁxed and let N tend to inﬁnity. The result is
that
lim inf
N→∞BN ≥1 + 1 + 1
2! + 1
3! + · · · + 1
M! = AM .
Now, as M →∞, the quantity AM converges to e (by the deﬁnition of e). So
we obtain
lim inf
N→∞BN ≥e .
(3.37.1)
On the other hand, our expansion for BN allows us to observe that BN ≤
AN. Thus
lim sup
N→∞
BN ≤e .
(3.37.2)
Combining (3.37.1) and (3.37.2) we ﬁnd that
e ≤lim inf
N→∞BN ≤lim sup
N→∞
BN ≤e
hence that limN→∞BN exists and equals e. This is the desired result.
Remark 3.38 The last proof illustrates the value of the concepts of lim inf and
lim sup. For we do not know in advance that the limit of the expressions BN
exists, much less that the limit equals e. However, the lim inf and the lim sup
always exist. So we estimate those instead, and ﬁnd that they are equal and
that they equal e.
The next result tells us how rapidly the partial sums AN of the series deﬁn-
ing e converge to e. This is of theoretical interest, but will also be applied to
determine the irrationality of e.
Proposition 3.39 With AN as above, we have that
0 < e −AN <
1
N · N! .
Proof: Observe that
e −AN
=
1
(N + 1)! +
1
(N + 2)! +
1
(N + 3)! + . . .
=
1
(N + 1)! ·

1 +
1
N + 2 +
1
(N + 2)(N + 3) + . . .

<
1
(N + 1)! ·

1 +
1
N + 1 +
1
(N + 1)2 + . . .

.

3.4. SOME SPECIAL SERIES
55
Now the expression in parentheses is a geometric series. It sums to (N + 1)/N.
Since AN < e, we have
e −AN = |e −AN|
hence
|e −AN| <
1
N · N! ,
proving the result.
Next we prove that e is an irrational number.
Theorem 3.40 Euler’s number e is irrational.
Proof: Suppose to the contrary that e is rational. Then e = p/q for some
positive integers p and q. By the preceding proposition,
0 < e −Aq <
1
q · q!
or
0 < q! · (e −Aq) < 1
q .
(3.40.1)
Now
e −Aq = p
q −

1 + 1 + 1
2! + 1
3! + · · · + 1
q!

hence
q! · (e −Aq)
is an integer. But then equation (3.40.1) says that this integer lies between
0 and 1/q. In particular, this integer lies strictly between 0 and 1. That, of
course, is impossible. So e must be irrational.
It is a general principle of number theory that a real number that can be
approximated too rapidly by rational numbers (the degree of rapidity being mea-
sured in terms of powers of the denominators of the rational numbers) must be
irrational. Under suitable conditions an even stronger conclusion holds: namely,
the number in question turns out to be transcendental. A transcendental num-
ber is one which is not the solution of any polynomial equation with integer
coeﬃcients.
The subject of transcendental numbers is explored in the exercises. The
exercises also contain a sketch of a proof that e is transcendental.
In Exercise 5 of Section 2.4, we brieﬂy discussed Euler’s number γ. Both
this special number and also the more commonly encountered number π arise in
many contexts in mathematics. It is unknown whether γ is rational or irrational.
The number π is known to be transcendental, but it is unknown whether π + e
(where e is Euler’s number) is transcendental.

56
CHAPTER 3. SERIES OF NUMBERS
In recent years, questions about the the irrationality and transcendence of
various numbers have become a matter of practical interest. For these proper-
ties prove to be useful in making and breaking secret codes, and in encrypting
information so that it is accessible to some users but not to others.
In Appendix II we prove that
SN ≡
N
X
j=1
j = N · (N + 1)
2
.
We conclude this section with a method for summing higher powers of j.
Say that we wish to calculate
Sk,N ≡
N
X
j=1
jk
for some positive integer k exceeding 1. We may proceed as follows: Write
(j + 1)k+1 −jk+1
=

jk+1 + (k + 1) · jk + (k + 1) · k
2
· jk−1
+ · · · + (k + 1) · k
2
· j2 + (k + 1) · j + 1

−jk+1
=
(k + 1) · jk + (k + 1) · k
2
· jk−1 + . . .
+(k + 1) · k
2
· j2 + (k + 1) · j + 1 .
Summing from j = 1 to j = N yields
N
X
j=1

(j + 1)k+1 −jk+1	
=
(k + 1) · Sk,N + (k + 1) · k
2
· Sk−1,N + . . .
+(k + 1) · k
2
· S2,N + (k + 1) · S1,N + N .
The sum on the left collapses to (N + 1)k+1 −1. We may solve for Sk,N and
obtain
Sk,N
=
1
k + 1 ·

(N + 1)k+1 −1 −N −(k + 1) · k
2
· Sk−1,N
−. . .
−(k + 1) · k
2
· S2,N −(k + 1) · S1,N

.

EXERCISES
57
We have succeed in expressing Sk,N in terms of S1,N, S2,N, . . . , Sk−1,N. Thus
we may inductively obtain formulas for Sk,N, any k. It turns out that
S2,N
=
N(N + 1)(2N + 1)
6
S3,N
=
N 2(N + 1)2
4
S4,N
=
(N + 1)N(2N + 1)(3N 2 + 3N −1)
30
These formulas are treated in further detail in the exercises.
Exercises
1. Use induction to prove the formulas provided in the text for the sum of the
ﬁrst N perfect squares, the ﬁrst N perfect cubes, and the ﬁrst N perfect
fourth powers.
2. A real number s is called algebraic if it satisﬁes a polynomial equation of
the form
a0 + a1x + a2x2 + · · · + amxm = 0
with the coeﬃcients aj being integers and am ̸= 0. Prove that if we replace
the word “integers” in this deﬁnition with “rational numbers” then the
set of algebraic numbers remains the same. Prove that np/q is algebraic
for any positive integers p, q, n.
*
3. Refer to Exercise 2 for terminology. A real number is called transcendental
if it is not algebraic.
Prove that the number of algebraic numbers is
countable. Explain why this implies that the number of transcendental
numbers is uncountable.
Thus most real numbers are transcendental;
however, it is extremely diﬃcult to verify that any particular real number
is transcendental.
*
4. Refer to Exercises 2 and 3 for terminology. Provide the details of the
following sketch of a proof that Euler’s number e is transcendental. [Note:
in this argument we use some simple ideas of calculus. These ideas will
be treated in rigorous detail later in the book.] Seeking a contradiction,
we suppose that the number e satisﬁes a polynomial equation of the form
a0 + a1x + · · · + amxm = 0
with integer coeﬃcients aj.
(a) We may assume that a0 ̸= 0.

58
CHAPTER 3. SERIES OF NUMBERS
(b) Let p be an odd prime that will be speciﬁed later. Deﬁne
g(x) = xp−1(x −1)p · · · (x −m)p
(p −1)!
and
G(x) = g(x) + g(1)(x) + g(2)(x) + · · · g(mp+p−1)(x) .
(Here parenthetical exponents denote derivatives.) Verify that
|g(x)| < mmp+p−1
(p −1)!
for a suitable range of x.
(c) Check that
d
dx

e−xG(x)
	
= −e−xg(x)
and thus that
aj
Z j
0
e−xg(x)dx = ajG(0) −aje−jG(j) .
(∗)
(d) Multiply the last equation by ej, sum from j = 0 to j = m, and use
the polynomial equation that e satisﬁes to obtain that
m
X
j=0
ajej
Z j
0
e−xg(x)dx = −
m
X
j=0
mp+p−1
X
i=0
ajg(i)(j) .
(∗∗)
(e) Check that g(i)(j) is an integer for all values of i and all j from 0 to
m inclusive.
(f) Referring to the last step, show that in fact g(i)(j) is an integer di-
visible by p except in the case that j = 0 and i = p −1.
(g) Check that
g(p−1)(0) = (−1)p(−2)p · · · (−m)p .
Conclude that g(p−1)(0) is not divisible by p if p > m.
(h) Check that if p > |a0| then the right side of equation (∗∗) consists of
a sum of terms each of which is a multiple of p except for the term
−a0g(p−1)(0). It follows that the sum on the right side of (∗∗) is a
nonzero integer.

3.5. OPERATIONS ON SERIES
59
(i) Use equation (∗) to check that, provided p is chosen suﬃciently large,
the left side of (∗∗) satisﬁes

m
X
j=0
ajej
Z j
0
e−xg(x)dx

≤



m
X
j=0
|aj|


em (mm+2)p−1
(p −1)!
< 1 .
(j) The last two steps contradict each other.
This proof is from [NIV].
*
5. Prove that
∞
X
j=1
| sin j|
j
and
∞
X
j=1
sin2 j
j
are both divergent series.
6. Compare Exercise 5. What can you say about the convergence of P
j[sin j]k/j
for k a positive integer?
7. Discuss convergence of P
j 1/[ln j]k for k a positive integer.
8. Discuss convergence of P
j 1/p(j) for p a polynomial.
9. Discuss convergence of P
j exp(p(j)) for p a polynomial.
3.5
Operations on Series
Some operations on series, such as addition, subtraction, and scalar multiplica-
tion, are straightforward. Others, such as multiplication, entail subtleties. This
section treats all these matters.
Proposition 3.41 Let
∞
X
j=1
aj
and
∞
X
j=1
bj
be convergent series of real or complex numbers; assume that the series sum to
limits α and β respectively. Then
(a) The series P∞
j=1(aj + bj) converges to the limit α + β.
(b) If c is a constant then the series P∞
j=1 c · aj converges to c · α.
Proof: We shall prove assertion (a) and leave the easier assertion (b) as an
exercise.
Pick ǫ > 0. Choose an integer N1 so large that n > N1 implies that the
partial sum Sn ≡Pn
j=1 aj satisﬁes |Sn −α| < ǫ/2. Choose N2 so large that
n > N2 implies that the partial sum Tn ≡Pn
j=1 bj satisﬁes |Tn −β| < ǫ/2. If Un

60
CHAPTER 3. SERIES OF NUMBERS
is the nth partial sum of the series P∞
j=1(aj + bj) and if n > N0 ≡max(N1, N2)
then
|Un −(α + β)| ≤|Sn −α| + |Tn −β| < ǫ
2 + ǫ
2 = ǫ .
Thus the sequence {Un} converges to α + β. This proves part (a). The proof
of (b) is similar.
In order to keep our discussion of multiplication of series as straightforward
as possible, we deal at ﬁrst with absolutely convergent series. It is convenient
in this discussion to begin our sum at j = 0 instead of j = 1. If we wish to
multiply
∞
X
j=0
aj
and
∞
X
j=0
bj ,
then we need to specify what the partial sums of the product series should be.
An obvious necessary condition that we wish to impose is that if the ﬁrst series
converges to α and the second converges to β then the product series, whatever
we deﬁne it to be, should converge to α · β.
The naive method for deﬁning the summands of the product series is to
let cj = aj · bj. However, a glance at the product of two partial sums of the
given series shows that such a deﬁnition would be ignoring the distributivity of
addition.
Cauchy’s idea was that the summands for the product series should be
cn ≡
n
X
j=0
aj · bn−j .
This particular form for the summands can be easily motivated using power
series considerations (which we shall provide in Section 9.1). For now we con-
centrate on verifying that this “Cauchy product” of two series really works.
Theorem 3.42 Let P∞
j=0 aj and P∞
j=0 bj be two absolutely convergent series
which converge to limits α and β respectively. Deﬁne the series P∞
m=0 cm with
summands cm = Pm
j=0 aj · bm−j. Then the series P∞
m=0 cm converges to α · β.
Proof: Let An, Bn, and Cn be the partial sums of the three series in question.
We calculate that
Cn
=
(a0b0) + (a0b1 + a1b0) + (a0b2 + a1b1 + a2b0)
+ · · · + (a0bn + a1bn−1 + · · · + anb0)
=
a0 · Bn + a1 · Bn−1 + a2 · Bn−2 + · · · + an · B0 .
We set λn = Bn −β, each n, and rewrite the last line as
Cn
=
a0(β + λn) + a1(β + λn−1) + · · · an(β + λ0)
=
An · β + [a0λn + a1 · λn−1 + · · · + an · λ0] .

3.5. OPERATIONS ON SERIES
61
Denote the expression in square brackets by the symbol ρn. Suppose that
we could show that limn→∞ρn = 0. Then we would have
lim
n→∞Cn
=
lim
n→∞(An · β + ρn)
=
( lim
n→∞An) · β + ( lim
n→∞ρn)
=
α · β + 0
=
α · β .
Thus it is enough to examine the limit of the expressions ρn.
Since P∞
j=1 aj is absolutely convergent, we know that A = P∞
j=1 |aj| is a
ﬁnite number.
Choose ǫ > 0.
Since P∞
j=1 bj converges to β it follows that
λn →0. Thus we may choose an integer N > 0 such that n > N implies that
|λn| < ǫ. Thus, for n = N + k, k > 0, we may estimate
|ρN+k|
≤
|λ0aN+k + λ1aN+k−1 + + · · · + λNak|
+|λN+1ak−1 + λN+2ak−2 + · · · + λN+ka0|
≤
|λ0aN+k + λ1aN+k−1 + + · · · + λNak|
+maxp≥1{|λN+p|} · (|ak−1| + |ak−2| + · · · + |a0|)
≤
(N + 1) · maxℓ≥k|aℓ| · max0≤j≤N|λj| + ǫ · A .
With N ﬁxed, we let k →∞in the last inequality. Since maxℓ≥k|aℓ| →0, we
ﬁnd that
lim sup
n→∞|ρn| ≤ǫ · A .
Since ǫ > 0 was arbitrary, we conclude that
lim
n→∞|ρn| →0 .
This completes the proof.
Notice that, in the proof of the theorem, we really only used the fact that
one of the given series was absolutely convergent, not that both were abso-
lutely convergent. Some hypothesis of this nature is necessary, as the following
example shows.
Example 3.43 Consider the Cauchy product of the two conditionally conver-
gent series
∞
X
j=0
(−1)j
√j + 1
and
∞
X
j=0
(−1)j
√j + 1 .
Observe that

62
CHAPTER 3. SERIES OF NUMBERS
cm
=
(−1)0(−1)m
√
1√m + 1
+ (−1)1(−1)m−1
√
2√m
+ · · ·
+(−1)m(−1)0
√m + 1
√
1
=
m
X
j=0
(−1)m
1
p
(j + 1) · (m + 1 −j)
.
However, for 0 ≤j ≤m,
(j + 1) · (m + 1 −j) ≤(m + 1) · (m + 1) = (m + 1)2 .
Thus
|cm| ≥
m
X
j=0
1
m + 1 = 1 .
We thus see that the terms of the series P∞
m=0 cm do not tend to zero, so the
series cannot converge.
Exercises
1. Let P∞
j=1 aj and P∞
j=1 bj be convergent series of positive real numbers.
Discuss division of these two series. Use the idea of the Cauchy product.
2. Let P∞
j=1 aj and P∞
j=1 bj be convergent series of positive real numbers.
Discuss convergence of P∞
j=1 ajbj.
3. Prove Proposition 3.41(b).
4. Calculate the Cauchy product of the series P
j 1/j2 and the series P
j 1/j4.
5. Explain how you could discover the Cauchy product using multiplication
of polynomials.
6. Explain division of power series in the language of the Cauchy product.
7. Discuss the concept of the exponential of a power series.
8. Is there a way to calculate the square root of a power series?
9. Is there a way to calculate the logarithm of a power series?
10. Discuss the concept of composition of power series.

Chapter 4
Basic Topology
4.1
Open and Closed Sets
To specify a topology on a set is to describe certain subsets that will play the
role of neighborhoods. These sets are called open sets.
In what follows, we will use “interval notation”: If a ≤b are real numbers
then we deﬁne
(a, b)
=
{x ∈R : a < x < b} ,
[a, b]
=
{x ∈R : a ≤x ≤b} ,
[a, b)
=
{x ∈R : a ≤x < b} ,
(a, b]
=
{x ∈R : a < x ≤b} .
Intervals of the form (a, b) are called open. Those of the form [a, b] are called
closed. The other two are termed half-open or half-closed. See Figure 4.1.
Now we extend the terms “open” and “closed” to more general sets.
Deﬁnition 4.1 A set U ⊆R is called open if, for each x ∈U, there is an ǫ > 0
such that the interval (x −ǫ, x + ǫ) is contained in U. See Figure 4.2.
Remark 4.2 The interval (x −ǫ, x + ǫ) is frequently termed a neighborhood of
x, and is commonly denoted Nǫ(x).
Example 4.3 The set U = {x ∈R : |x −3| < 2} is open. To see this, choose
a point x ∈U. Let ǫ = 2 −|x −3| > 0. Then we claim that the interval
I = (x −ǫ, x + ǫ) ⊆U.
For if t ∈I then
|t −3|
≤
|t −x| + |x −3|
<
ǫ + |x −3|
=
(2 −|x −3|) + |x −3| = 1.
63

64
CHAPTER 4. BASIC TOPOLOGY
Figure 4.1: Intervals.
(a,b)
x
x -
x +
a
b
Figure 4.2: An open set.
But this means that t ∈U.
We have shown that t ∈I implies t ∈U. Therefore I ⊆U. It follows from
the deﬁnition that U is open.
Remark 4.4 The way to think about the deﬁnition of open set is that a set
is open when none of its elements is at the “edge” of the set—each element is
surrounded by other elements of the set, indeed a whole interval of them. See
Figure 4.3. The remainder of this section will make these comments precise.
Proposition 4.5 If Uα are open sets, for α in some (possibly uncountable)
index set A, then
U =
[
α∈A
Uα
is open.
Figure 4.3: A set that is not open.

4.1. OPEN AND CLOSED SETS
65
Proof: Let x ∈U. By deﬁnition of union, the point x must lie in some Uα. But
Uα is open. Therefore there is an interval I = (x −ǫ, x + ǫ) such that I ⊆Uα.
Therefore certainly I ⊆U. This proves that U is open.
Proposition 4.6 If U1, U2, . . . , Uk are open sets then the set
V =
k\
j=1
Uj
is also open.
Proof: Let x ∈V . Then x ∈Uj for each j. Since each Uj is open there is
for each j a positive number ǫj such that Ij = (x −ǫj, x + ǫj) lies in Uj. Set
ǫ = min{ǫ1, . . . , ǫk}. Then ǫ > 0 and (x −ǫ, x + ǫ) ⊆Uj for every j. But that
just means that (x −ǫ, x + ǫ) ⊆V . Therefore V is open.
Notice the diﬀerence between these two propositions: arbitrary unions of
open sets are open. But, in order to guarantee that an intersection of open sets
is still open, we had to assume that we were only intersecting ﬁnitely many such
sets. To understand this matter, bear in mind the example of the open sets
Uj =

−1
j , 1
j

,
j = 1, 2, . . . .
The intersection of the sets Uj is the singleton {0}, which is not open.
The same analysis as in the ﬁrst example shows that, if a < b, then the
interval (a, b) is an open set. On the other hand, intervals of the form (a, b] or
[a, b) or [a, b] are not open. In the ﬁrst instance, the point b is the center of no
interval (b −ǫ, b + ǫ) contained in (a, b]. Think about the other two intervals
to understand why they are not open. We call intervals of the form (a, b) open
intervals.
We are now in a position to give a complete description of all open sets.
Proposition 4.7 Let U ⊆R be a nonempty open set. Then there are either
ﬁnitely many or countably many pairwise disjoint open intervals Ij such that
U =
∞
[
j=1
Ij .
See Figure 4.4.
Proof: Assume that U is an open subset of the real line. We deﬁne an equiv-
alence relation on the set U. The resulting equivalence classes will be the open
intervals Ij.
Let a and b be elements of U. We say that a is related to b if all real numbers
between a and b are also elements of U. It is obvious that this relation is both

66
CHAPTER 4. BASIC TOPOLOGY
Figure 4.4: Structure of an open set.
Figure 4.5: A closed set.
reﬂexive and symmetric. For transitivity notice that if a is related to b and b is
related to c then (assuming that a, b, c are distinct) one of the numbers a, b, c
must lie between the other two. Assume for simplicity that a < b < c. Then
all numbers between a and c lie in U, for all such numbers are either between
a and b or between b and c or are b itself. Thus a is related to c. (The other
possible orderings of a, b, c are left for you to consider.)
Thus we have an equivalence relation on the set U. Call the equivalence
classes {Uα}α∈A. We claim that each Uα is an open interval. In fact if a, b
are elements of some Uα then all points between a and b are in U. But then
a moment’s thought shows that each of those “in between” points is related to
both a and b. Therefore all points between a and b are elements of Uα. We
conclude that Uα is an interval. Is it an open interval?
Let x ∈Uα. Then x ∈U so that there is an open interval I = (x −ǫ, x + ǫ)
contained in U. But x is related to all the elements of I; it follows that I ⊆Uα.
Therefore Uα is open.
We have exhibited the set U as a union of open intervals. These intervals
are pairwise disjoint because they arise as the equivalence classes of an equiva-
lence relation. Finally, each of these open intervals contains a (diﬀerent) rational
number (why?). Therefore there can be at most countably many of the intervals
Uα.
Deﬁnition 4.8 A subset F ⊆R is called closed if the complement R \ F is
open. See Figure 4.5.
Example 4.9 The set [0, 1] is closed. For its complement is
(−∞, 0) ∪(1, ∞) ,
which is certainly open.
Example 4.10 An interval of the form [a, b] = {x : a ≤x ≤b} is closed. For
its complement is (−∞, a) ∪(b, ∞), which is the union of two open intervals.
The ﬁnite set A = {−4, −2, 5, 13} is closed because its complement is
(−∞, −4) ∪(−4, −2) ∪(−2, 5) ∪(5, 13) ∪(13, ∞) ,
which is open.

4.1. OPEN AND CLOSED SETS
67
The set B = {1, 1/2, 1/3, 1/4, . . .} ∪{0} is closed, for its complement is the
set
(−∞, 0) ∪



∞
[
j=1
(1/(j + 1), 1/j)


∪(1, ∞) ,
which is open.
Verify for yourself that if the point 0 is omitted from the set B, then the
set is no longer closed.
Proposition 4.11 If Eα are closed sets, for α in some (possibly uncountable)
index set A, then
E =
\
α∈A
Eα
is closed.
Proof: This is just the contrapositive of Proposition 4.5 above: if Uα is the
complement of Eα, each α, then Uα is open. Then U = ∪Uα is also open. But
then
E =
\
Eα =
\ c (Uα) = c [
Uα

= cU
is closed. Here cS denotes the complement of a set S.
The fact that the set B in the last example is closed, but that B \ {0} is
not, is placed in perspective by the next proposition.
Proposition 4.12 Let S be a set of real numbers. Then S is closed if and
only if every Cauchy sequence {sj} of elements of S has a limit which is also an
element of S.
Proof: First suppose that S is closed and let {sj} be a Cauchy sequence in S.
We know, since the reals are complete, that there is an element s ∈R such that
sj →s. The point of this half of the proof is to see that s ∈S. If this statement
were false then s ∈T = R\S. But T must be open since it is the complement of
a closed set. Thus there is an ǫ > 0 such that the interval I = (s −ǫ, s + ǫ) ⊆T .
This means that no element of S lies in I. In particular, |s −sj| ≥ǫ for every
j. This contradicts the statement that sj →s. We conclude that s ∈S.
Conversely, assume that every Cauchy sequence in S has its limit in S. If
S were not closed then its complement would not be open. Hence there would
be a point t ∈R \ S with the property that no interval (t −ǫ, t + ǫ) lies in R \ S.
In other words, (t −ǫ, t + ǫ) ∩S ̸= ∅for every ǫ > 0. Thus for j = 1, 2, 3, . . . we
may choose a point sj ∈(t −1/j, t + 1/j) ∩S. It follows that {sj} is a sequence
of elements of S that converge to t ∈R \ S. That contradicts our hypothesis.
We conclude that S must be closed.
Let S be a subset of R. A point x is called an accumulation point of S if
every neighborhood of x contains inﬁnitely many distinct elements of S. See

68
CHAPTER 4. BASIC TOPOLOGY
Figure 4.6: The idea of an accumulation point.
Figure 4.6. In particular, x is an accumulation point of S if it is the limit of a
sequence of distinct elements in S. The last proposition tells us that closed sets
are characterized by the property that they contain all of their accumulation
points.
Exercises
1. Let S be any set and ǫ > 0. Deﬁne T = {t ∈R : |t−s| < ǫ for some s ∈S}.
Prove that T is open.
2. Let S be any set and deﬁne V = {t ∈R : |t −s| ≤1 for some s ∈S}. Is
V necessarily closed?
3. The closure of a set S is the intersection of all closed sets that contain S.
Call a set S robust if it is the closure of its interior. Which sets of reals
are robust?
4. Give an example of nonempty closed sets X1 ⊇X2 ⊇. . . such that ∩jXj =
∅.
5. Give an example of nonempty closed sets X1 ⊆X2 . . . such that ∪jXj is
open.
6. Give an example of open sets U1 ⊇U2 . . . such that ∩jUj is closed and
nonempty.
7. Exhibit a countable collection of open sets Uj such that each open set
O ⊆R can be written as a union of some of the sets Uj.
8. Let S be an uncountable subset of R. Prove that S must have inﬁnitely
many accumulation points. Must it have uncountably many?
9. Let S be any set and deﬁne, for x ∈R,
dis(x, S) = inf{|x −s| : s ∈S} .
Prove that, if x ̸∈S, then dis(x, S) > 0. If x, y ∈R then prove that
|dis(x, S) −dis(y, S)| ≤|x −y| .
10. Let S be a set of real numbers. If S is not open then must it be closed?
If S is not closed then must it be open?

4.2. FURTHER PROPERTIES OF OPEN AND CLOSED SETS
69
Figure 4.7: The idea of a boundary point.
S
boundary points
0
1
Figure 4.8: Boundary of the open unit interval.
4.2
Further Properties of Open and Closed Sets
Let S ⊆R be a set. We call b ∈R a boundary point of S if every nonempty
neighborhood (b −ǫ, b + ǫ) contains both points of S and points of R \ S. See
Figure 4.7. We denote the set of boundary points of S by ∂S.
A boundary point b might lie in S and might lie in the complement of S.
The next example serves to illustrate the concept:
Example 4.13 Let S be the interval (0, 1). Then no point of (0, 1) is in the
boundary of S since every point of (0, 1) has a neighborhood that lies entirely
inside (0, 1). Also, no point of the complement of [0, 1] lies in the boundary of S
for a similar reason. Indeed, the only candidates for elements of the boundary
of S are 0 and 1. See Figure 4.8. The point 0 is an element of the boundary
since every neighborhood (0 −ǫ, 0 + ǫ) contains the point ǫ/2 ∈S and the point
−ǫ/2 ∈R \ S. A similar calculation shows that 1 lies in the boundary of S.
Now consider the set T = [0, 1]. Certainly there are no boundary points in
(0, 1), for the same reason as in the ﬁrst paragraph. And there are no boundary
points in R\ [0, 1], since that set is open. Thus the only candidates for elements
of the boundary are 0 and 1. As in the ﬁrst paragraph, these are both indeed
boundary points for T . See Figure 4.9.
Notice that neither of the boundary points of S lie in S while both of the
boundary points of T lie in T .
The collection of all boundary points of a set S is called the boundary of S
and is denoted by ∂S.
T
boundary points
0
1
Figure 4.9: Boundary of the closed unit interval.

70
CHAPTER 4. BASIC TOPOLOGY
Figure 4.10: The idea of an interior point.
isolated points
Figure 4.11: The idea of an isolated point.
Example 4.14 The boundary of the set Q is the entire real line. For if x is any
element of R then every interval (x −ǫ, x + ǫ) contains both rational numbers
and irrational numbers.
The union of a set S with its boundary is called the closure of S, denoted
S. The next example illustrates the concept.
Example 4.15 Let S be the set of rational numbers in the interval [0, 1]. Then
the closure S of S is the entire interval [0, 1].
Let T be the open interval (0, 1). Then the closure T of T is the closed
interval [0, 1].
Deﬁnition 4.16 Let S ⊆R. A point s ∈S is called an interior point of S if
there is an ǫ > 0 such that the interval (s −ǫ, s + ǫ) lies in S. See Figure 4.10.
We call the set of all interior points the interior of S, and we denote this set by
◦
S.
A point t ∈S is called an isolated point of S if there is an ǫ > 0 such that
the intersection of the interval (t −ǫ, t + ǫ) with S is just the singleton {t}. See
Figure 4.11.
By the deﬁnitions given here, an isolated point t of a set S ⊆R is a boundary
point. For any interval (t −ǫ, t + ǫ) contains a point of S (namely, t itself) and
points of R \ S (since t is isolated).
Proposition 4.17 Let S ⊆R. Then each point of S is either an interior point
or a boundary point of S.
Proof: Fix s ∈S. If s is not an interior point then no open interval centered
at s contains only elements of s. Thus any interval centered at s contains an
element of S (namely, s itself) and also contains points of R \ S. Thus s is a
boundary point of S.
Example 4.18 Let S = [0, 1]. Then the interior points of S are the elements
of (0, 1). The boundary points of S are the points 0 and 1. The set S has no
isolated points.

4.2. FURTHER PROPERTIES OF OPEN AND CLOSED SETS
71
Let T = {1, 1/2, 1/3, . . .}∪{0}. Then the points 1, 1/2, 1/3, . . . are isolated
points of T . The point 0 is an accumulation point of T . Every element of T is
a boundary point, and there are no others.
Remark 4.19 Observe that the interior points of a set S are elements of S—by
their very deﬁnition. Also isolated points of S are elements of S. However, a
boundary point of S may or may not be an element of S.
If x is an accumulation point of S then every open neighborhood of x
contains inﬁnitely many elements of S.
Hence x is either a boundary point
of S or an interior point of S; it cannot be an isolated point of S.
Proposition 4.20 Let S be a subset of the real numbers. Then the boundary
of S equals the boundary of R \ S.
Proof: Obvious.
The next theorem allows us to use the concept of boundary to distinguish
open sets from closed sets.
Theorem 4.21 A closed set contains all of its boundary points. An open set
contains none of its boundary points.
Proof: Let S be closed and let x be an element of its boundary. If every neigh-
borhood of x contains points of S other than x itself then x is an accumulation
point of S hence x ∈S. If not every neighborhood of x contains points of S
other than x itself, then there is an ǫ > 0 such that {(x−ǫ, x)∪(x, x+ǫ)}∩S = ∅.
The only way that x can be an element of ∂S in this circumstance is if x ∈S.
That is what we wished to prove.
For the other half of the theorem notice that if T is open then cT is closed.
But then cT will contain all its boundary points, which are the same as the
boundary points of T itself (why is this true?). Thus T can contain none of its
boundary points.
Proposition 4.22 Every nonisolated boundary point of a set S is an accumu-
lation point of the set S.
Proof: This proof is treated in the exercises.
Deﬁnition 4.23 A subset S of the real numbers is called bounded if there is a
positive number M such that |s| ≤M for every element s of S. See Figure 4.12.
The next result is one of the great theorems of nineteenth century analysis.
It is essentially a restatement of the Bolzano-Weierstrass theorem of Section 2.2.
Theorem 4.24 (Bolzano-Weierstrass) Every bounded, inﬁnite subset of R
has an accumulation point.

72
CHAPTER 4. BASIC TOPOLOGY
M
-M
Figure 4.12: A bounded set.
Proof: Let S be a bounded, inﬁnite set of real numbers. Let {aj} be a sequence
of distinct elements of S. By Theorem 2.19, there is a subsequence {ajk} that
converges to a limit α. Then α is an accumulation point of S.
Corollary 4.25 Let S ⊆R be a nonempty, closed, and bounded set. If {aj} is
any sequence in S, then there is a Cauchy subsequence {ajk} that converges to
an element of S.
Proof: Merely combine the Bolzano-Weierstrass theorem with Proposition 4.12
of the last section.
Exercises
1. Let S be any set of real numbers. Prove that S ⊆S. Prove that S is a
closed set. Prove that S \
◦
S is the boundary of S.
2. What is the interior of the Cantor set?
What is the boundary of the
Cantor set?
3. Prove Proposition 4.20.
4. The union of inﬁnitely many closed sets need not be closed. It need not
be open either. Give examples to illustrate the possibilities.
5. The intersection of inﬁnitely many open sets need not be open. It need
not be closed either. Give examples to illustrate the possibilities.
6. Give an example of a one-to-one, onto, continuous function f with a con-
tinuous inverse from the half line (0, ∞) to the full line (−∞, ∞).
7. Prove Proposition 4.22.
8. Let S be any set of real numbers. Prove that
◦
S is open. Prove that S is
open if and only if S equals its interior.
9. Give an example of a closed set in the plane whose projection on the x-axis
is not closed.
10. Show that the projection of an open set onto the x-axis must be open.

4.3. COMPACT SETS
73
4.3
Compact Sets
Compact sets are sets (usually inﬁnite) which share many of the most important
properties of ﬁnite sets. They play an important role in real analysis.
Deﬁnition 4.26 A set S ⊆R is called compact if every sequence in S has a
subsequence that converges to an element of S.
Theorem 4.27 (Heine-Borel) A set S ⊆R is compact if and only if it is
closed and bounded.
Proof: That a closed, bounded set has the property of compactness is the
content of Corollary 4.25 and Proposition 4.12.
Now let S be a set that is compact. If S is not bounded, then there is
an element s1 of S that has absolute value larger than 1. Also there must be
an element s2 of S that has absolute value larger than 2. Continuing, we ﬁnd
elements sj ∈S satisfying
|sj| > j
for each j. But then no subsequence of the sequence {sj} can be Cauchy. This
contradiction shows that S must be bounded.
If S is compact but S is not closed, then there is a point x which is the
limit of a sequence {sj} ⊆S but which is not itself in S. But every sequence in
S is, by deﬁnition of “compact,” supposed to have a subsequence converging to
an element of S. For the sequence {sj} that we are considering, x is the only
candidate for the limit of a subsequence. Thus it must be that x ∈S. That
contradiction establishes that S is closed.
In the abstract theory of topology (where there is no notion of distance),
sequences cannot be used to characterize topological properties (instead there is
a concept of nets, which we cannot treat here). Therefore a diﬀerent deﬁnition
of compactness is used. For interest’s sake, and for future use, we now show
that the deﬁnition of compactness that we have been discussing is equivalent to
the one used in topology theory. First we need a new deﬁnition.
Deﬁnition 4.28 Let S be a subset of the real numbers. A collection of open
sets {Oα}α∈A (each Oα is an open set of real numbers) is called an open covering
of S if
[
α∈A
Oα ⊇S .
See Figure 4.13.
Example 4.29 The collection C = {(1/j, 1)}∞
j=1 is an open covering of the
interval I = (0, 1). No ﬁnite subcollection of the elements of C covers I.
The collection D = {(1/j, 1)}∞
j=1 ∪{(−1/5, 1/5), (4/5, 6/5)} is an open cov-
ering of the interval J = [0, 1]. However, not all the elements D are actually
needed to cover J. In fact

74
CHAPTER 4. BASIC TOPOLOGY
Figure 4.13: Open covers and compactness.
(−1/5, 1/5) , (1/6, 1) , (4/5, 6/5)
cover the interval J.
It is the distinction displayed in this example that distinguishes compact
sets from the point of view of topology.
To understand the point, we need
another deﬁnition:
Deﬁnition 4.30 If C is an open covering of a set S and if D is another open
covering of S such that each element of D is also an element of C then we call
D a subcovering of C.
We call D a ﬁnite subcovering if D has just ﬁnitely many elements.
Example 4.31 The collection of intervals
C = {(j −1, j + 1)}∞
j=1
is an open covering of the set S = [5, 9]. The collection
D = {(j −1, j + 1)}∞
j=5
is a subcovering.
However, the collection
E = {(4, 6), (5, 7), (6, 8), (7, 9), (8, 10)}
is a ﬁnite subcovering.
Theorem 4.32 A set S ⊆R is compact if and only if every open covering
C = {Oα}α∈A of S has a ﬁnite subcovering.
Proof: Assume that S is a compact set and let C = {Oα}α∈A be an open
covering of S.
By Theorem 4.27, S is closed and bounded. Therefore it holds that a = inf S
is a ﬁnite real number, and an element of S. Likewise, b = sup S is a ﬁnite real
number and an element of S. Write I = [a, b]. The case a = b is trivial so we
assume that a < b.
Set
A = {x ∈I : C contains a ﬁnite subcover that covers S ∩[a, x]} .
Then A is nonempty since a ∈A. Let t = sup A. Then some element O0 of
C contains t. Let s be an element of O0 to the left of t. Then, by the deﬁnition

4.3. COMPACT SETS
75
of t, s is an element of A. So there is a ﬁnite subcovering C′ of C that covers
S ∩[a, s]. But then D = C′ ∪{O0} covers S ∩[a, t], showing that t = sup A lies
in A. But in fact D even covers points to the right of t. Thus t cannot be the
supremum of A unless t = b.
We have learned that t must be the point b itself and that therefore b ∈A.
But that says that S ∩[a, b] = S can be covered by ﬁnitely many of the elements
of C. That is what we wished to prove.
For the converse, assume that every open covering of S has a ﬁnite subcov-
ering. Let {aj} be a sequence in S. Assume, seeking a contradiction, that the
sequence has no subsequence that converges to an element of S. This must mean
that for every s ∈S there is an ǫs > 0 such that no element of the sequence sat-
isﬁes 0 < |aj −s| < ǫs. Let Is = (s −ǫs, s + ǫs). The collection C = {Is} is then
an open covering of the set S. By hypothesis, there exists a ﬁnite subcovering
Is1, . . . Isk of open intervals that cover S. But each Isℓcould only contain at
most one element of the sequence {aj}—namely, sℓitself. We conclude that the
sequence has only ﬁnitely many distinct elements, a clear contradiction. Thus
the sequence does have a convergent subsequence whose limit is in S.
Example 4.33 If A ⊆B and both sets are nonempty then A ∩B = A ̸= ∅.
A similar assertion holds when intersecting ﬁnitely many nonempty sets A1 ⊇
A2 ⊇· · · ⊇Ak; it holds in this circumstance that ∩k
j=1Aj = Ak.
However, it is possible to have inﬁnitely many nonempty nested sets with
null intersection. An example is the sets Ij = (0, 1/j). Certainly Ij ⊇Ij+1 for
all j yet
∞
\
j=1
Ij = ∅.
By contrast, if we take Kj = [0, 1/j] then
∞
\
j=1
Kj = {0} .
The next proposition shows that compact sets have the intuitively appealing
property of the Kjs rather than the unsettling property of the Ijs.
Proposition 4.34 Let
K1 ⊇K2 ⊇· · · ⊇Kj ⊇. . .
be nonempty compact sets of real numbers. Set
K =
∞
\
j=1
Kj .
Then K is compact and K ̸= ∅.

76
CHAPTER 4. BASIC TOPOLOGY
Proof: Each Kj is closed and bounded hence K is closed and bounded. Thus
K is compact. Let xj ∈Kj, each j. Then {xj} ⊆K1. By compactness, there is
a convergent subsequence {xjk} with limit x0 ∈K1. However, {xjk}∞
k=2 ⊆K2.
Thus x0 ∈K2. Similar reasoning shows that x0 ∈Km for all m = 1, 2, . . . . In
conclusion, x0 ∈∩jKj = K.
Exercises
1. Let K be a compact set and let U be an open set that contains K. Prove
that there is an ǫ > 0 such that, if k ∈K, then the interval (k −ǫ, k + ǫ)
is contained in U.
2. Let K be compact and L closed, and assume that the two sets are disjoint.
Show that there is a positive distance between the two sets.
3. Let K be a compact set. Let δ > 0. Prove that there is a ﬁnite collection
of intervals of radius δ that covers K.
4. Let K be a compact set. Let U = {Uj}k
j=1 be a ﬁnite covering of K. Show
that there is a δ > 0 so that, if x is any point of K, then the disc or
interval of center x and radius δ lies entirely in one of the Uj.
5. Prove that the intersection of a compact set and a closed set is compact.
6. Assume that we have intervals [a1, b1] ⊇[a2, b2] ⊇· · · and that limj→∞|aj−
bj| = 0. Prove that there is a point x such that x ∈[aj, bj] for every j.
7. If K in R is compact then show that cK is not compact.
8. Prove that the intersection of any number of compact sets is compact.
The analogous statement for unions is false.
9. Let U ⊂R be any open set. Show that there exist compact sets K1 ⊂
K2 ⊂· · · so that ∪jKj = U.
10. Produce an open set U in the real line so that U may not be written as
the decreasing intersection of compact sets.
4.4
The Cantor Set
In this section we describe the construction of a remarkable subset of R with
many pathological properties.
It only begins to suggest the richness of the
structure of the real number system.
We begin with the unit interval S0 = [0, 1]. We extract from S0 its open
middle third; thus S1 = S0 \ (1/3, 2/3). Observe that S1 consists of two closed
intervals of equal length 1/3. See Figure 4.14.

4.4. THE CANTOR SET
77
0
1
Figure 4.14: Construction of the Cantor set.
Figure 4.15: Second step in the construction of the Cantor set.
Now we construct S2 from S1 by extracting from each of its two intervals
the middle third: S2 = [0, 1/9] ∪[2/9, 3/9] ∪[6/9, 7/9] ∪[8/9, 1]. Figure 4.15
shows S2.
Continuing in this fashion, we construct Sj+1 from Sj by extracting the
middle third from each of its component subintervals. We deﬁne the Cantor set
C to be
C =
∞
\
j=1
Sj .
Notice that each of the sets Sj is closed and bounded, hence compact.
By
Proposition 4.34 of the last section, C is therefore not empty. The set C is
closed and bounded, hence compact.
Proposition 4.35 The Cantor set C has zero length, in the sense that the
complementary set [0, 1] \ C has length 1.
Proof: In the construction of S1, we removed from the unit interval one interval
of length 3−1. In constructing S2, we further removed two intervals of length
3−2. In constructing Sj, we removed 2j−1 intervals of length 3−j. Thus the
total length of the intervals removed from the unit interval is
∞
X
j=1
2j−1 · 3−j .
This last equals
1
3
∞
X
j=0
2
3
j
.
The geometric series sums easily and we ﬁnd that the total length of the intervals
removed is
1
3

1
1 −2/3

= 1 .
Thus the Cantor set has length zero because its complement in the unit interval
has length one.
Proposition 4.36 The Cantor set is uncountable.

78
CHAPTER 4. BASIC TOPOLOGY
Proof: We assign to each element of the Cantor set a “label” consisting of a
sequence of 0s and 1s that identiﬁes its location in the set.
Fix an element x in the Cantor set. Then certainly x is in S1. If x is in
the left half of S1, then the ﬁrst digit in the “label” of x is 0; otherwise it is
1. Likewise x ∈S2. By the ﬁrst part of this argument, it is either in the left
half S21 of S2 (when the ﬁrst digit in the label is 0) or the right half S22 of S2
(when the ﬁrst digit of the label is 1). Whichever of these is correct, that half
will consist of two intervals of length 3−2. If x is in the leftmost of these two
intervals then the second digit of the “label” of x is 0. Otherwise the second
digit is 1. Continuing in this fashion, we may assign to x an inﬁnite sequence
of 0s and 1s.
Conversely, if a, b, c, . . . is a sequence of 0s and 1s, then we may locate a
unique corresponding element y of the Cantor set. If the ﬁrst digit is a zero
then y is in the left half of S1; otherwise y is in the right half of S1. Likewise
the second digit locates y within S2, and so forth.
Thus we have a one-to-one correspondence between the Cantor set and the
collection of all inﬁnite sequences of zeroes and ones. [Notice that we are in
eﬀect thinking of the point assigned to a sequence c1c2c3 . . . of 0s and 1s as the
limit of the points assigned to c1, c1c2, c1c2c3, . . . Thus we are using the fact
that C is closed.] However, as we can learn in Appendix I at the end of the
book, the set of all inﬁnite sequences of zeroes and ones is uncountable. Thus
we see that the Cantor set is uncountable.
The Cantor set is quite thin (it has zero length) but it is large in the sense
that it has uncountably many elements. Also it is compact. The next result
reveals a surprising, and not generally well known, property of this “thin” set.
Theorem 4.37 Let C be the Cantor set and deﬁne
S = {x + y : x ∈C, y ∈C} .
Then S = [0, 2].
Proof: We sketch the proof here and treat the details in the exercises.
Since C ⊆[0, 1] it is clear that S ⊆[0, 2]. For the reverse inclusion, ﬁx
an element t ∈[0, 2]. Our job is to ﬁnd two elements c and d in C such that
c + d = t.
First observe that {x + y : x ∈S1, y ∈S1} = [0, 2]. Therefore there exist
x1 ∈S1 and y1 ∈S1 such that x1 + y1 = t.
Similarly, {x + y : x ∈S2, y ∈S2} = [0, 2]. Therefore there exist x2 ∈S2
and y2 ∈S2 such that x2 + y2 = t.
Continuing in this fashion we may ﬁnd for each j numbers xj and yj such
that xj, yj ∈Sj and xj + yj = t. Of course {xj} ⊆C and {yj} ⊆C hence
there are subsequences {xjk} and {yjk} which converge to real numbers c and d
respectively. Since C is compact, we can be sure that c ∈C and d ∈C. But the

EXERCISES
79
operation of addition respects limits, thus we may pass to the limit as k →∞
in the equation
xjk + yjk = t
to obtain
c + d = t .
Therefore [0, 2] ⊆{x + y : x ∈C}. This completes the proof.
In the exercises at the end of the section we shall explore constructions
of other Cantor sets, some of which have zero length and some of which have
positive length. The Cantor set that we have discussed in detail in the present
section is sometimes distinguished with the name “the Cantor ternary set.” We
shall also consider in the exercises other ways to construct the Cantor ternary
set.
Observe that, whereas any open set is the countable or ﬁnite disjoint union
of open intervals, the existence of the Cantor set shows us that there is no
such structure theorem for closed sets. That is to say, we cannot hope to write
an arbitrary closed set as the disjoint union of closed intervals. [However, de
Morgan’s Law shows that an arbitrary closed set can be written as the countable
intersection of sets, each of which is the union of two disjoint closed intervals.]
In fact closed intervals are atypically simple when considered as examples of
closed sets.
Exercises
1. Fix the sequence aj = 3−j, j = 1, 2, . . . . Consider the set S of all sums
∞
X
j=1
µjaj ,
where each µj is one of the numbers 0 or 2. Show that S is the Cantor
set. If s is an element of S, s = P µjaj, and if µj = 0 for all j suﬃciently
large, then show that s is an endpoint of one of the intervals in one of the
sets Sj that were used to construct the Cantor set in the text.
*
2. Discuss which sequences aj of positive numbers could be used as in Exer-
cise 1 to construct sets which are like the Cantor set.
3. Let us examine the proof that {x + y : x ∈C, y ∈C} equals [0, 2] more
carefully.
a) Prove for each j that {x+y : x ∈Sj, y ∈Sj} equals the interval [0, 2].
b) For t ∈C, explain how the subsequences {xjk} and {yjk} can be
chosen to satisfy xjk + yjk = t. Observe that it is important for the
proof that the index jk be the same for both subsequences.

80
CHAPTER 4. BASIC TOPOLOGY
c) Formulate a suitable statement concerning the assertion that the bi-
nary operation of addition “respects limits” as required in the argu-
ment in the text. Prove this statement and explain how it allows us
to pass to the limit in the equation xjk + yjk = t.
4. Use the characterization of the Cantor set from Exercise 1 to give a new
proof of the fact that {x + y : x ∈C, y ∈C} equals the interval [0, 2].
5. Construct a Cantor-like set by removing the middle ﬁfth from the unit
interval, removing the middle ﬁfth of each of the remaining intervals, and
so on. What is the length of the set that you construct in this fashion?
Is it uncountable? Is it perfect (see Section 4.6)? Is it diﬀerent from the
Cantor set constructed in the text?
6. Refer to Exercise 5. Construct a Cantor set by removing, at the jth step,
a middle subinterval of length 3−2j+1 from each existing interval. The
Cantor-like set that results should have positive length.
What is that
length? Does this Cantor set have the other properties of the Cantor set
constructed in the text?
7. Let S be a compact set and T a closed set of real numbers. Assume that
S ∩T = ∅. Prove that there is a number δ > 0 such that |s −t| > δ for
every s ∈S and every t ∈T . Prove that the assertion is false if we only
assume that S is closed.
8. Prove that the assertion of Exercise 7 is false if we assume that S and T
are both open.
9. Let 0 < λ < 1. Imitate the construction of the Cantor set to produce a
perfect subset (see Section 4.6) of the unit interval whose complement has
length λ.
10. Describe how to produce a two-dimensional Cantor-like set in the plane.
11. How many endpoints of intervals are there in the Cantor set? How many
non-endpoints?
12. How many points in the Cantor set have ﬁnite ternary expansions? How
many have inﬁnite ternary expansions?
4.5
Connected and Disconnected Sets
Let S be a set of real numbers. We say that S is disconnected if it is possible
to ﬁnd a pair of open sets U and V such that
U ∩S ̸= ∅, V ∩S ̸= ∅,
(U ∩S) ∩(V ∩S) = ∅,

4.5. CONNECTED AND DISCONNECTED SETS
81
Figure 4.16: The idea of disconnected.
Figure 4.17: A closed interval is connected.
and
S = (U ∩S) ∪(V ∩S) .
See Figure 4.16. If no such U and V exist then we call S connected.
Example 4.38 The set T = {x ∈R : |x| < 1, x ̸= 0} is disconnected. For take
U = {x : x < 0} and V = {x : x > 0}. Then
U ∩T = {x : −1 < x < 0} ̸= ∅
and
V ∩T = {x : 0 < x < 1} ̸= ∅.
Also (U ∩T ) ∩(V ∩T ) = ∅.
Clearly T = (U ∩T ) ∪(V ∩T ), hence T is
disconnected.
Example 4.39 The set X = [−1, 1] is connected. To see this, suppose to the
contrary that there exist open sets U and V such that U ∩X ̸= ∅, V ∩X ̸=
∅, (U ∩X) ∩(V ∩X) = ∅, and
X = (U ∩X) ∪(V ∩X) .
Choose a ∈U ∩X and b ∈V ∩X. Set
α = sup (U ∩[a, b]}) .
Now [a, b] ⊆X hence U ∩[a, b] is disjoint from V . Thus α ≤b. But cV is closed
hence α ̸∈V . It follows that α < b.
If α ∈U then, because U is open, there exists an eα ∈U such that α < eα < b.
This would mean that we chose α incorrectly. Hence α ̸∈U. But α ̸∈U and
α ̸∈V means α ̸∈X. On the other other hand, α is the supremum of a subset
of X (since a ∈X, b ∈X, and X is an interval). Since X is a closed interval, we
conclude that α ∈X. This contradiction shows that X must be connected.
With small modiﬁcations, the discussion in the last example demonstrates
that any closed interval is connected (Exercise 1). See Figure 4.17. Also (see
Exercise 2), we may similarly see that any open interval or half-open interval is
connected. In fact the converse is true as well:
Theorem 4.40 A subset S of R is connected if and only if S is an interval.

82
CHAPTER 4. BASIC TOPOLOGY
Proof: If S is not an interval then there exist a ∈S, b ∈S and a point t between
a and b such that t ̸∈S. Deﬁne U = {x ∈R : x < t} and V = {x ∈R : t < x}.
Then U and V are open and disjoint, U ∩S ̸= ∅, V ∩S ̸= ∅, and
S = (U ∩S) ∪(V ∩S) .
Thus S is disconnected.
We have proved the contrapositive of the statement of the theorem, hence
we are ﬁnished.
The Cantor set is not connected; indeed it is disconnected in a special sense.
Call a set S totally disconnected if, for each distinct x ∈S, y ∈S, there exist
disjoint open sets U and V such that x ∈U, y ∈V , and S = (U ∩S) ∪(V ∩S).
Proposition 4.41 The Cantor set is totally disconnected.
Proof: Let x, y ∈C be distinct and assume that x < y. Set δ = |x−y|. Choose
j so large that 3−j < δ. Then x, y ∈Sj, but x and y cannot both be in the same
interval of Sj (since the intervals will have length equal to 3−j). It follows that
there is a point t between x and y that is not an element of Sj, hence certainly
not an element of C. Set U = {s : s < t} and V = {s : s > t}. Then x ∈U ∩C
hence U ∩C ̸= ∅; likewise V ∩C ̸= ∅. Also (U ∩C) ∩(V ∩C) = ∅. Finally
C = (C ∩U) ∪(C ∩V ). Thus C is totally disconnected.
Exercises
1. Imitate the example in the text to prove that any closed interval is con-
nected.
2. Imitate the example in the text to prove that any open interval or half-
open interval is connected.
3. Give an example of a totally disconnected set S ⊆[0, 1] such that S =
[0, 1].
4. Write the real line as the union of two totally disconnected sets.
5. Let S ⊆R be a set. Let s, t ∈S. We say that s and t are in the same
connected component of S if the entire interval [s, t] lies in S. What are
the connected components of the Cantor set? Is it possible to have a set
S with countably many connected components? With uncountably many
connected components?
6. If A is connected and B is connected then will A ∩B be connected?
7. If A is connected and B is connected then will A ∪B be connected?

4.6. PERFECT SETS
83
8. If A is connected and B is connected then does it follow that A × B is
connected?
9. If A is connected and B is disconnected then what can you say about
A ∩B?
10. If sets Uj form the basis of a topology on a space X (that is to say, each
open set in X can be written as a union of some of the Uj) and if each Uj
is connected, then what can you say about X?
4.6
Perfect Sets
A set S ⊆R is called perfect if it is closed and if every point of S is an accu-
mulation point of S. The property of being perfect is a rather special one: it
means that the set has no isolated points.
Obviously a closed interval [a, b] is perfect. After all, a point x in the interior
of the interval is surrounded by an entire open interval (x −ǫ, x + ǫ) of elements
of the interval; moreover a is the limit of elements from the right and b is the
limit of elements from the left.
Perhaps more surprising is that the Cantor set, a totally disconnected set,
is perfect. It is certainly closed. Now ﬁx x ∈C. Then certainly x ∈S1. Thus
x is in one of the two intervals composing S1. One (or perhaps both) of the
endpoints of that interval does not equal x. Call that endpoint a1. Likewise
x ∈S2. Therefore x lies in one of the intervals of S2. Choose an endpoint a2 of
that interval which does not equal x. Continuing in this fashion, we construct
a sequence {aj}. Notice that each of the elements of this sequence lies in the
Cantor set (why?). Finally, |x −aj| ≤3−j for each j. Therefore x is the limit
of the sequence. We have thus proved that the Cantor set is perfect.
The fundamental theorem about perfect sets tells us that such a set must
be rather large. We have
Theorem 4.42 A nonempty perfect set must be uncountable.
Proof: Let S be a nonempty perfect set. Since S has accumulation points, it
cannot be ﬁnite. Therefore it is either countable or uncountable.
Seeking a contradiction, we suppose that S is countable. Write S = {s1,
s2, . . . }. Set U1 = (s1 −1, s1 + 1). Then U1 is a neighborhood of s1. Now s1 is
a limit point of S so there must be inﬁnitely many elements of S lying in U1.
We select a bounded open interval U2 such that U 2 ⊆U1, U2 does not contain
s1, and U2 does contain some element of S.
Continuing in this fashion, assume that s1, . . . , sj have been selected and
choose a bounded interval Uj+1 such that (i) U j+1 ⊆Uj, (ii) sj ̸∈Uj+1, and
(iii) Uj+1 contains some element of S.
Observe that each set Vj = U j ∩S is closed and bounded, hence compact.
Also each Vj is nonempty by construction but Vj does not contain sj−1. It
follows that V = ∩jVj cannot contain s1 (since V2 does not), cannot contain s2

84
CHAPTER 4. BASIC TOPOLOGY
(since V3 does not), indeed cannot contain any element of S. Hence V , being a
subset of S, is empty. But V is the decreasing intersection of nonempty compact
sets, hence cannot be empty!
This contradiction shows that S cannot be countable. So it must be un-
countable.
Corollary 4.43 If a < b then the closed interval [a, b] is uncountable.
Proof: The interval [a, b] is perfect.
We also have a new way of seeing that the Cantor set is uncountable, since
it is perfect:
Corollary 4.44 The Cantor set is uncountable.
Exercises
*
1. Let S1, S2, . . . be closed sets and assume that ∪jSj = R. Prove that at
least one of the sets Sj has nonempty interior. (Hint: Use an idea from
the proof that perfect sets are uncountable.)
2. Let U1 ⊆U2 . . . be open sets and assume that each of these sets has
bounded, nonempty complement. Prove that ∪jUj ̸= R.
*
3. Let S be a nonempty set of real numbers. A point x is called a conden-
sation point of S if every neighborhood of x contains uncountably many
points of S. Prove that the set of condensation points of S is closed. Is it
necessarily nonempty? Is it nonempty when S is uncountable?
If T is an uncountable set then show that the set of its condensation points
is perfect.
4. Prove that any closed set can be written as the union of a perfect set and
a countable set. (Hint: Refer to Exercise 3.)
*
5. Let 0 < α < 1. Construct a Cantor-like set that has length α. Verify that
this set has all the properties (except the length property) of the Cantor
set that was discussed in the text.
6. Let X1, X2, . . . each be perfect sets and suppose that X1 ⊇X2 ⊇. . . . Set
X = ∩jXj. Is X perfect?
7. Is the product of perfect sets perfect?
8. If A ∩B is perfect, then what may we conclude about A and B?
9. If A ∪B is perfect, then what may we conclude about A and B?
10. Call a set imperfect if its complement is perfect. Which sets are imperfect?
Can you specify a connected imperfect set?

Chapter 5
Limits and Continuity of
Functions
5.1
Deﬁnition and Basic Properties of the Limit
of a Function
In this chapter we are going to treat some topics that you have seen before
in your calculus class. However, we shall use the deep properties of the real
numbers that we have developed in this text to obtain important new insights.
Therefore you should not think of this chapter as review. Look at the concepts
introduced here with the power of your new understanding of analysis.
Deﬁnition 5.1 Let E ⊆R be a set and let f be a real-valued function with
domain E. Fix a point P ∈R that is an accumulation point of E. Let ℓbe a
real number. We say that
lim
E∋x→P f(x) = ℓ
if, for each ǫ > 0, there is a δ > 0 such that when x ∈E and 0 < |x −P| < δ
then
|f(x) −ℓ| < ǫ .
The deﬁnition makes precise the notion that we can force f(x) to be just
as close as we please to ℓby making x suﬃciently close to P. Notice that the
deﬁnition puts the condition 0 < |x −P| < δ on x, so that x is not allowed to
take the value P. In other words we do not look at x = P, but rather at x near
to P.
Also observe that we only consider the limit of f at a point P that is not
isolated. In the exercises you will be asked to discuss why it would be nonsensical
to use the above deﬁnition to study the limit at an isolated point.
Example 5.2 Let E = R \ {0} and
f(x) = x · sin(1/x) if x ∈E .
85

86
CHAPTER 5. LIMITS AND CONTINUITY OF FUNCTIONS
y
x
Figure 5.1: The limit of an oscillatory function.
See Figure 5.1. Then limx→0 f(x) = 0. To see this, let ǫ > 0. Choose δ = ǫ. If
0 < |x −0| < δ then
|f(x) −0| = |x · sin(1/x)| ≤|x| < δ = ǫ ,
as desired. Thus the limit exists and equals 0.
Example 5.3 Let E = R and
g(x) =

1
if
x is rational
0
if
x is irrational.
Then limx→P g(x) does not exist for any point P of E.
To see this, ﬁx P ∈R. Seeking a contradiction, assume that there is a
limiting value ℓfor g at P. If this is so then we take ǫ = 1/2 and we can ﬁnd a
δ > 0 such that 0 < |x −P| < δ implies
|g(x) −ℓ| < ǫ = 1
2 .
(5.3.1)
If we take x to be rational then (5.3.1) says that
|1 −ℓ| < 1
2 ,
(5.3.2)
while if we take x irrational then (5.3.1) says that
|0 −ℓ| < 1
2 .
(5.3.3)
But then the triangle inequality gives that
|1 −0|
=
|(1 −ℓ) + (ℓ−0)|
≤
|1 −ℓ| + |ℓ−0|,

5.1. BASIC PROPERTIES OF THE LIMIT OF A FUNCTION
87
which by (5.3.2) and (5.3.3) is
< 1 .
This contradiction, that 1 < 1, allows us to conclude that the limit does not
exist at P.
Proposition 5.4 Let f be a function with domain E, and let P be an accu-
mulation point of E. If limx→P f(x) = ℓand limx→P f(x) = m, then ℓ= m.
Proof: Let ǫ > 0. Choose δ1 > 0 such that if x ∈E and 0 < |x −P| < δ1, then
|f(x)−ℓ| < ǫ/2. Similarly choose δ2 > 0 such that if x ∈E and 0 < |x−P| < δ2,
then |f(x) −m| < ǫ/2. Deﬁne δ to be the minimum of δ1 and δ2. If x ∈E and
0 < |x −P| < δ, then the triangle inequality tells us that
|ℓ−m|
=
|(ℓ−f(x)) + (f(x) −m)|
≤
|(ℓ−f(x)| + |f(x) −m)|
<
ǫ
2 + ǫ
2
=
ǫ
Since |ℓ−m| < ǫ for every positive ǫ we conclude that ℓ= m. That is the
desired result.
The point of the last proposition is that if a limit is calculated by two diﬀer-
ent methods, then the same answer will result. While of primarily philosophical
interest now, this will be important information later when we establish the
existence of certain limits.
This is a good time to observe that the limits
lim
x→P f(x)
and
lim
h→0 f(P + h)
are equal in the sense that if one limit exists then so does the other and they
both have the same value.
In order to facilitate checking that certain limits exist, we now record some
elementary properties of the limit. This requires that we ﬁrst recall how func-
tions are combined.
Suppose that f and g are each functions which have domain E. We deﬁne
the sum or diﬀerence of f and g to be the function
(f ± g)(x) = f(x) ± g(x) ,
the product of f and g to be the function
(f · g)(x) = f(x) · g(x) ,

88
CHAPTER 5. LIMITS AND CONTINUITY OF FUNCTIONS
and the quotient of f and g to be
f
g

(x) = f(x)
g(x) .
Notice that the quotient is only deﬁned at points x for which g(x) ̸= 0. Now we
have:
Theorem 5.5 (Elementary Properties of Limits of Functions) Let f and
g be functions with domain E and ﬁx a point P that is an accumulation point
of E. Assume that
(i) lim
x→P f(x) = ℓ
(ii) lim
x→P g(x) = m .
Then
(a) lim
x→P(f ± g)(x) = ℓ± m
(b) lim
x→P(f · g)(x) = ℓ· m
(c) lim
x→P(f/g)(x) = ℓ/m provided m ̸= 0 .
Proof: We prove part (b). Parts (a) and (c) are treated in the exercises.
Let ǫ > 0. We may also assume that ǫ < 1. Choose δ1 > 0 such that, if
x ∈E and 0 < |x −P| < δ1, then
|f(x) −ℓ| <
ǫ
2(|m| + 1) .
Choose δ2 > 0 such that if x ∈E and 0 < |x −P| < δ2 then
|g(x) −m| <
ǫ
2(|ℓ| + 1) .
(Notice that this last inequality implies that |g(x)| < |m| + |ǫ|.) Let δ be the
minimum of δ1 and δ2. If x ∈E and 0 < |x −P| < δ then
|f(x) · g(x) −ℓ· m| = |(f(x) −ℓ) · g(x) + (g(x) −m) · ℓ|
≤|(f(x) −ℓ) · g(x)| + |(g(x) −m) · ℓ|
<

ǫ
2(|m| + 1)

· |g(x)| +

ǫ
2(|ℓ| + 1)

· |ℓ|
≤

ǫ
2(|m| + 1)

· (|m| + |ǫ|) + ǫ
2
< ǫ
2 + ǫ
2
= ǫ .

5.1. BASIC PROPERTIES OF THE LIMIT OF A FUNCTION
89
Example 5.6 It is a simple matter to check that, if f(x) = x, then
lim
x→P f(x) = P
for every real P. (Indeed, for ǫ > 0 we may take δ = ǫ.) Also, if g(x) ≡α is the
constant function taking value α, then
lim
x→P g(x) = α .
It then follows from parts (a) and (b) of the theorem that, if f(x) is any
polynomial function, then
lim
x→P f(x) = f(P) .
Moreover, if r(x) is any rational function (quotient of polynomials) then we may
also use part (c) of the theorem to conclude that
lim
x→P r(x) = r(P)
for all points P at which the rational function r(x) is deﬁned.
Example 5.7 If x is a small, positive real number then 0 < sin x < x. This
is true because sin x is the nearest distance from the point (cos x, sin x) to the
x-axis while x is the distance from that point to the x-axis along an arc. If
ǫ > 0, then we set δ = ǫ. We conclude that if 0 < |x −0| < δ then
| sin x −0| < |x| < δ = ǫ .
Since sin(−x) = −sin x, the same result holds when x is a negative number
with small absolute value. Therefore
lim
x→0 sin x = 0 .
Since
cos x =
p
1 −sin2 x
for all x ∈[−π/2, π/2] ,
we may conclude from the preceding theorem that
lim
x→0 cos x = 1 .
Now ﬁx any real number P. We have
lim
x→P sin x
=
lim
h→0 sin(P + h)
=
lim
h→0
 sin P cos h + cos P sin h

=
sin P · 1 + cos P · 0
=
sin P .

90
CHAPTER 5. LIMITS AND CONTINUITY OF FUNCTIONS
We of course have used parts (a) and (b) of the theorem to commute the limit
process with addition and multiplication. A similar argument shows that
lim
x→P cos x = cos P .
Remark 5.8 In the last example, we have used the deﬁnition of the sine func-
tion and the cosine function that you learned in calculus. In Chapter 9, when
we learn about series of functions, we will learn a more rigorous method for
treating the trigonometric functions.
We conclude by giving a characterization of the limit of a function using
sequences.
Proposition 5.9 Let f be a function with domain E and P be an accumulation
point of E. Then
lim
x→P f(x) = ℓ
(5.9.1)
if and only if, for any sequence {aj} ⊆E \ {P} satisfying limj→∞aj = P, it
holds that
lim
j→∞f(aj) = ℓ.
(5.9.2)
Proof: Assume that condition (5.9.1) fails. Then there is an ǫ > 0 such that
for no δ > 0 is it the case that when 0 < |x −P| < δ then |f(x) −ℓ| < ǫ. Thus,
for each δ = 1/j, we may choose a number aj ∈E \{P} with 0 < |aj −P| < 1/j
and |f(aj) −ℓ| ≥ǫ. But then condition (5.9.2) fails for this sequence {aj}.
If condition (5.9.2) fails then there is some sequence {aj} such that limj→∞aj
= P but limj→∞f(aj) ̸= ℓ. This means that there is an ǫ > 0 such that for
inﬁnitely many aj it holds that |f(aj) −ℓ| ≥ǫ. But then, no matter how small
δ > 0, there will be an aj satisfying 0 < |aj −P| < δ (since aj →P) and
|f(aj) −ℓ| ≥ǫ. Thus (5.9.1) fails.
Exercises
1. Let f and g be functions on a set A = (a, c) ∪(c, b) and assume that
f(x) ≤g(x) for all x ∈A. Assuming that both limits exist, show that
lim
x→c f(x) ≤lim
x→c g(x) .
Does the conclusion improve if we assume that f(x) < g(x) for all x ∈A?
2. Prove parts (a) and (c) of Theorem 5.5.
3. Prove that the limit of a function is unique.
4. Give a deﬁnition of limit using the concept of open set.

5.2. CONTINUOUS FUNCTIONS
91
5. Give a deﬁnition of limit using the concept of distance.
6. If limx→c f(x) = ℓ> 0 then prove that there is a δ > 0 so small that
|x −c| < δ guarantees that f(x) > ℓ/2.
7. Give an example of a function f : R →R so that limx→c does not exist
for any c ∈R.
*
8. Give an example of a function f : R →R so that limx→c f(x) exists when
c is irrational but does not exist when c is rational.
9. Show that, if f is a monotone function, then f has a limit at “most”
points. What does the word “most” mean in this context?
10. Give an example of a function such that limx→c f(x) exists at every point
but f is discontinuous at every point.
11. Prove that limx→P f(x) = limh→0 f(P + h) whenever both expressions
make sense.
5.2
Continuous Functions
Deﬁnition 5.10 Let E ⊆R be a set and let f be a real-valued function with
domain E. Fix a point P which is in E and is also an accumulation point of E.
We say that f is continuous at P if
lim
x→P f(x) = f(P) .
We learned from the penultimate example of Section 1 that polynomial
functions are continuous at every real x. So are the transcendental functions
sin x and cos x (see Example 5.7). A rational function is continuous at every
point of its domain.
Example 5.11 The function
h(x) =
 sin(1/x)
if
x ̸= 0
1
if
x = 0
is discontinuous at 0. See Figure 5.2. The reason is that
lim
x→0 h(x)
does not exist. (Details of this assertion are left for you: notice that h(1/(jπ)) =
0 while h(2/[(4j + 1)π]) = 1 for j = 1, 2, . . . .)
The function
k(x) =
 x · sin(1/x)
if
x ̸= 0
1
if
x = 0
is also discontinuous at x = 0.
This time the limit limx→0 k(x) exists (see
Example 5.2), but the limit does not agree with k(0).

92
CHAPTER 5. LIMITS AND CONTINUITY OF FUNCTIONS
Figure 5.2: A function discontinuous at 0.
However, the function
m(x) =
 x · sin(1/x)
if
x ̸= 0
0
if
x = 0
is continuous at x = 0 because the limit at 0 exists and agrees with the value
of the function there. See Figure 5.3.
The arithmetic operations +, −, ×, and ÷ preserve continuity (so long as
we avoid division by zero). We now formulate this assertion as a theorem.
Theorem 5.12 Let f and g be functions with domain E and let P be a point
of E. If f and g are continuous at P then so are f ± g, f · g, and (provided
g(P) ̸= 0) f/g.
Proof: Apply Theorem 5.5 of Section 1.
Continuous functions may also be characterized using sequences:
Proposition 5.13 Let f be a function with domain E and ﬁx P ∈E. The
function f is continuous at P if and only if, for every sequence {aj} ⊆E
satisfying limj→∞aj = P, it holds that
lim
j→∞f(aj) = f(P) .
Proof: Apply Proposition 5.9 of Section 1.
Recall that if g is a function with domain D and range E and if f is a
function with domain E and range F then the composition of f and g is
f ◦g(x) = f(g(x)) .

5.2. CONTINUOUS FUNCTIONS
93
y
x
Figure 5.3: A function continuous at 0.
Figure 5.4: Composition of functions.

94
CHAPTER 5. LIMITS AND CONTINUITY OF FUNCTIONS
See Figure 5.4.
Proposition 5.14 Let g have domain D and range E and let f have domain
E and range F. Let P ∈D. Assume that g is continuous at P and that f is
continuous at g(P). Then f ◦g is continuous at P.
Proof: Let {aj} be any sequence in D such that limj→∞aj = P. Then
lim
j→∞f ◦g(aj) = lim
j→∞f(g(aj)) = f

lim
j→∞g(aj)

= f

g

lim
j→∞aj

= f(g(P)) = f ◦g(P) .
Now apply Proposition 5.9.
Remark 5.15 It is not the case that if
lim
x→P g(x) = ℓ
and
lim
t→ℓf(t) = m
then
lim
x→P f ◦g(x) = m .
A counterexample is given by the functions
g(x) = 0
f(x) =
 2
if
x ̸= 0
5
if
x = 0.
Notice that limx→0 g(x) = 0, limt→0 f(t) = 2, yet limx→0 f ◦g(x) = 5.
The additional hypothesis that f be continuous at ℓis necessary in order
to guarantee that the limit of the composition will behave as expected.
Next we explore the topological approach to the concept of continuity.
Whereas the analytic approach that we have been discussing so far considers
continuity one point at a time, the topological approach considers all points
simultaneously. Let us call a function continuous if it is continuous at every
point of its domain.
Deﬁnition 5.16 Let f be a function with domain E and let W be any set of
real numbers. We deﬁne
f −1 (W) = {x ∈E : f(x) ∈W} .
We sometimes refer to f −1(W) as the inverse image of W under f.

5.2. CONTINUOUS FUNCTIONS
95
Theorem 5.17 Let f be a function with domain E. The function f is contin-
uous if and only if the inverse image of any open set under f is the intersection
of E with an open set.
In particular, if E is open then f is continuous if and only if the inverse
image of every open set under f is open.
Proof: Assume that f is continuous. Let O be any open set and let P ∈f −1(O).
Then, by deﬁnition, f(P) ∈O. Since O is open, there is an ǫ > 0 such that
the interval (f(P) −ǫ, f(P) + ǫ) lies in O. By the continuity of f we may select
a δ > 0 such that if x ∈E and |x −P| < δ then |f(x) −f(P)| < ǫ. In other
words, if x ∈E and |x −P| < δ then f(x) ∈O or x ∈f −1(O). Thus we have
found an open interval I = (P −δ, P + δ) about P whose intersection with E is
contained in f −1(O). So f −1(O) is the intersection of E with an open set.
Conversely, suppose that for any open set O ⊆R we have that f −1(O) is the
intersection of E with an open set. Fix P ∈E. Choose ǫ > 0. Then the interval
(f(P)−ǫ, f(P)+ǫ) is an open set. By hypothesis the set f −1((f(P)−ǫ, f(P)+ǫ))
is the intersection of E with an open set. This set certainly contains the point
P. Thus there is a δ > 0 such that
E ∩(P −δ, P + δ) ⊆f −1((f(P) −ǫ, f(P) + ǫ)) .
But that just says that
f (E ∩(P −δ, P + δ)) ⊆(f(P) −ǫ, f(P) + ǫ) .
In other words, if |x −P| < δ and x ∈E then |f(x) −f(P)| < ǫ. But that
means that f is continuous at P.
Remark 5.18 Since any open subset of the real numbers is a countable or ﬁnite
disjoint union of intervals then—in order to check that the inverse image under
a function f of every open set is open—it is enough to check that the inverse
image of any open interval is open. This is frequently easy to do.
For example, if f(x) = x2 then the inverse image of an open interval (a, b)
is (−
√
b, −√a) ∪(√a,
√
b) if a > 0, is (−
√
b,
√
b) if a ≤0, b ≥0, and is ∅if
a < b < 0. Thus the function f is continuous.
Note that, by contrast, it is somewhat tedious to give an ǫ −δ proof of the
continuity of f(x) = x2.
Corollary 5.19 Let f be a function with domain E. The function f is continu-
ous if and only if the inverse image of any closed set F under f is the intersection
of E with some closed set.
In particular, if E is closed then f is continuous if and only if the inverse
image of any closed set F under f is closed.
Proof: It is enough to prove that
f −1 (cF) = c  f −1(F)

.
We leave this assertion as an exercise for you.

96
CHAPTER 5. LIMITS AND CONTINUITY OF FUNCTIONS
Exercises
1. Let 0 < α ≤1. A function f with domain E is said to satisfy a Lipschitz
condition of order α if there is a constant C > 0 such that, for any s, t ∈E,
it holds that |f(s) −f(t)| ≤C · |s −t|α. Prove that such a function must
be uniformly continuous.
2. Deﬁne the function
g(x) =

0
if
x is irrational
x
if
x is rational
At which points x is g continuous? At which points is it discontinuous?
3. Is the composition of uniformly continuous functions uniformly continu-
ous?
4. Let f be a continuous function whose domain contains an open interval
(a, b). What form can f((a, b)) have? (Hint: There are just four possibil-
ities.)
5. Explain why it would be foolish to deﬁne the concept of limit at an isolated
point.
6. If f is deﬁned on a set A = (a, c) ∪(c, b) and if limx→c f(x) = r > 0 then
prove that there is a δ > 0 such that if 0 < |x −c| < δ, then |f(x)| > r/2.
7. Let f be a continuous function on the open interval (a, b). Under what
circumstances can f be extended to a continuous function on [a, b]?
8. Deﬁne an onto, continuous function from R2 to R.
9. Deﬁne continuity using the notion of closed set.
10. The image of a compact set under a continuous function is compact (see
the next section).
But the image of a closed set need not be closed.
Explain. The inverse image of a compact set under a continuous function
need not be compact. Explain.
5.3
Topological Properties and Continuity
Recall that in Chapter 4 we learned a characterization of compact sets in terms
of open covers. In Section 2 of the present chapter we learned a characterization
of continuous functions in terms of inverse images of open sets. Thus it is not
surprising that compact sets and continuous functions interact in a natural way.
We explore this interaction in the present section.

5.3. TOPOLOGICAL PROPERTIES AND CONTINUITY
97
E
f
L
f(L)
Figure 5.5: The image of the set L under the function f.
Deﬁnition 5.20 Let f be a function with domain E and let L be a subset of
E. We deﬁne
f(L) = {f(x) : x ∈L} .
The set f(L) is called the image of L under f. See Figure 5.5.
Theorem 5.21 The image of a compact set under a continuous function is also
compact.
Proof: Let f be a continuous function with domain E and let K be a subset
of E that is compact. Our job is to show that f(K) is compact.
Let C = {Oα} be an open covering of f(K). Since f is continuous we know
that, for each α, the set f −1(Oα) is the intersection of E with an open set Uα.
Let bC = {Uα}α∈A. Since C covers f(K) it follows that bC covers K. But K is
compact; therefore (Theorem 4.31) there is a ﬁnite subcovering
{Uα1, Uα2, . . . Uαm}
of K. But then it follows that f(Uα1 ∩E), . . . , f(Uαm ∩E) covers f(K), hence
Oα1, Oα2, . . . , Oαm
covers f(K).
We have taken an arbitrary open cover C for f(K) and extracted from it a
ﬁnite subcovering. It follows that f(K) is compact.
It is not the case that the continuous image of a closed set is closed. For
instance, take f(x) = 1/(1 + x2) and E = R: the set E is closed and f is
continuous but f(E) = (0, 1] is not closed.

98
CHAPTER 5. LIMITS AND CONTINUITY OF FUNCTIONS
It is also not the case that the continuous image of a bounded set is bounded.
As an example, take f(x) = 1/x and E = (0, 1). Then E is bounded and f
continuous but f(E) = (1, ∞) is unbounded.
However, the combined properties of closedness and boundedness (that is,
compactness) are preserved. That is the content of the preceding theorem.
Corollary 5.22 Let f be a continuous, real-valued function with compact do-
main ⊆R. Then there is a number L such that
|f(x)| ≤L
for all x ∈K.
Proof: We know from the theorem that f(K) is compact. By Theorem 4.26,
we conclude that f(K) is bounded. Thus there is a number L such that |t| ≤L
for all t ∈f(K). But that is just the assertion that we wish to prove.
In fact we can prove an important strengthening of the corollary. Since
f(K) is compact, it contains its supremum M and its inﬁmum m. Therefore
there must be a number C ∈K such that f(C) = M and a number c ∈K
such that f(c) = m. In other words, f(c) ≤f(x) ≤f(C) for all x ∈K. We
summarize:
Theorem 5.23 Let f be a continuous function on a compact set K ⊆R. Then
there exist numbers c and C in K such that f(c) ≤f(x) ≤f(C) for all x ∈K.
We call c an absolute minimum for f on K and C an absolute maximum for
f on K. We call f(c) the absolute minimum value for f on K and f(C) the
absolute maximum value for f on K.
Notice that, in the last theorem, the location of the absolute maximum and
absolute minimum need not be unique. For instance, the function sin x on the
compact interval [0, 4π] has an absolute minimum at 3π/2 and 7π/2. It has an
absolute maximum at π/2 and at 5π/2.
Now we deﬁne a reﬁned type of continuity called “uniform continuity.” We
shall learn that this new notion of continuous function arises naturally for a
continuous function on a compact set. It will also play an important role in our
later studies, especially in the context of the integral.
Deﬁnition 5.24 Let f be a function with domain E ⊆R.
We say that f
is uniformly continuous on E if, for each ǫ > 0, there is a δ > 0 such that,
whenever s, t ∈E and |s −t| < δ, then |f(s) −f(t)| < ǫ.
Observe that “uniform continuity” diﬀers from “continuity” in that it treats
all points of the domain simultaneously: the δ > 0 that is chosen is independent
of the points s, t ∈E. This diﬀerence is highlighted by the next two examples.

5.3. TOPOLOGICAL PROPERTIES AND CONTINUITY
99
Example 5.25 Suppose that a function f : R →R satisﬁes the condition
|f(s) −f(t)| ≤C · |s −t| ,
(5.25.1)
where C is some positive constant. This is called a Lipschitz condition, and it
arises frequently in analysis. Let ǫ > 0 and set δ = ǫ/C. If |x −y| < δ then, by
(5.25.1),
|f(x) −f(y)| ≤C · |x −y| < C · δ = C · ǫ
C = ǫ .
It follows that f is uniformly continuous.
Example 5.26 Consider the function f(x) = x2. Fix a point P ∈R, P > 0,
and let ǫ > 0. In order to guarantee that |f(x) −f(P)| < ǫ we must have (for
x > 0)
|x2 −P 2| < ǫ
or
|x −P| <
ǫ
x + P .
Since x will range over a neighborhood of P, we see that the required δ in
the deﬁnition of continuity cannot be larger than ǫ/(2P). In fact the choice
|x −P| < δ = ǫ/(2P + 1) will do the job.
Put in slightly diﬀerent words, let ǫ = 1. Then |f(j + 1/j) −f(j)| > ǫ = 1
for any j. Thus, for this ǫ, we may not take δ to be 1/j for any j. So no uniform
δ exists.
Thus the choice of δ depends not only on ǫ (which we have come to expect)
but also on P.
In particular, f is not uniformly continuous on R.
This a
quantitative reﬂection of the fact that the graph of f becomes ever steeper as
the variable moves to the right.
Notice that the same calculation shows that the function f with restricted
domain [a, b], 0 < a < b < ∞, is uniformly continuous. That is because, when
the function is restricted to [a, b], its slope does not become arbitrarily large.
See Figure 5.6.
Now the main result about uniform continuity is the following:
Theorem 5.27 Let f be a continuous function with compact domain K. Then
f is uniformly continuous on K.
Proof: Pick ǫ > 0. By the deﬁnition of continuity there is for each point x ∈K
a number δx > 0 such that if |x−t| < δx then |f(t)−f(x)| < ǫ/2. The intervals
Ix = (x −δx/2, x + δx/2) form an open covering of K. Since K is compact, we
may therefore (by Theorem 4.31) extract a ﬁnite subcovering
Ix1, . . . Ixm .
Now let δ = min{δx1/2, . . . , δxm/2} > 0. If s, t ∈K and |s −t| < δ then
s ∈Ixj for some 1 ≤j ≤m. It follows that
|s −xj| < δxj/2

100
CHAPTER 5. LIMITS AND CONTINUITY OF FUNCTIONS
Figure 5.6: Uniform continuity on the interval [a, b].
and
|t −xj| ≤|t −s| + |s −xj| < δ + δxj/2 ≤δxj/2 + δxj/2 = δxj .
We know that
|f(s) −f(t)| ≤|f(s) −f(xj)| + |f(xj) −f(t)| .
But since each of s and t is within δxj of xj we may conclude that the last line
is less than
ǫ
2 + ǫ
2 = ǫ .
Notice that our choice of δ does not depend on s and t (indeed, we chose δ before
we chose s and t). We conclude that f is uniformly continuous.
Remark 5.28 Where in the proof did the compactness play a role? We deﬁned
δ to be the minimum of δx1, . . . δxm. In order to guarantee that δ be positive it
is crucial that we be taking the minimum of ﬁnitely many positive numbers. So
we needed a ﬁnite subcovering.
Example 5.29 The function f(x) = sin(1/x) is continuous on the domain E =
(0, ∞) since it is the composition of continuous functions (refer again to Figure
5.2). However, it is not uniformly continuous since
f
 1
2jπ

−f
 
1
(4j+1)π
2
! = 1
for j = 1, 2, . . .. Thus, even though the arguments are becoming arbitrarily close
together, the images of these arguments remain bounded apart. We conclude
that f cannot be uniformly continuous. See Figure 5.2.

5.3. TOPOLOGICAL PROPERTIES AND CONTINUITY
101
However, if f is considered as a function on any interval of the form [a, b], 0 <
a < b < ∞, then the preceding theorem tells us that the function f is uniformly
continuous.
As an exercise, you should check that
g(x) =
 x sin(1/x)
if
x ̸= 0
0
if
x = 0
is uniformly continuous on any interval of the form [−N, N]. See Figure 5.3.
Next we show that continuous functions preserve connectedness.
Theorem 5.30 Let f be a continuous function with domain an open interval
I. Suppose that L is a connected subset of I. Then f(L) is connected.
Proof: Suppose to the contrary that there are open sets U and V such that
U ∩f(L) ̸= ∅, V ∩f(L) ̸= ∅,
(U ∩f(L)) ∩(V ∩f(L)) = ∅,
and
f(L) = (U ∩f(L)) ∪(V ∩f(L)) .
Since f is continuous, f −1(U) and f −1(V ) are open. They each have nonempty
intersection with L since U ∩f(L) and V ∩f(L) are nonempty. By the def-
inition of f −1, they are certainly disjoint. And since U ∪V contains f(L) it
follows, by deﬁnition, that f −1(U) ∪f −1(V ) contains L. But this shows that L
is disconnected, and that is a contradiction.
Corollary 5.31 (The Intermediate Value Theorem) Let f be a continu-
ous function whose domain contains the interval [a, b]. Let γ be a number that
lies between f(a) and f(b). Then there is a number c between a and b such that
f(c) = γ. Refer to Figure 5.7.
Proof: The set [a, b] is connected. Therefore f([a, b]) is connected. But f([a, b])
contains the points f(a) and f(b). By connectivity, f([a, b]) must contain the
interval that has f(a) and f(b) as endpoints. In particular, f([a, b]) must con-
tain any number γ that lies between f(a) and f(b). But this just says that there
is a number c lying between a and b such that f(c) = γ. That is the desired
conclusion.

102
CHAPTER 5. LIMITS AND CONTINUITY OF FUNCTIONS
Figure 5.7: The Intermediate Value Theorem.
Exercises
1. If f is continuous on [0, 1] and if f(x) is positive for each rational x, then
does it follow that f is positive at all x?
2. Give an example of a continuous function f and a connected set E such
that f −1(E) is not connected. Is there a condition you can add that will
force f −1(E) to be connected?
3. Give an example of a continuous function f and an open set U so that
f(U) is not open.
4. Let S be any subset of R. Deﬁne the function
f(x) = inf{|x −s| : s ∈S} .
[We think of f(x) as the distance of x to S.] Prove that f is uniformly
continuous.
5. Deﬁne the function g(x) to take the value 0 at irrational values of x and
to take the value 1/q when x = p/q is a rational number in lowest terms,
q > 0. At which points is g continuous? At which points is the function
discontinuous?
6. Let f be any function whose domain and range is the entire real line. If
A and B are disjoint sets does it follow that f(A) and f(B) are disjoint
sets? If C and D are disjoint sets does it follow that f −1(C) and f −1(D)
are disjoint?
7. Let f be any function whose domain is the entire real line. If A and B
are sets then is f(A ∪B) = f(A) ∪f(B)? If C and D are sets then is

EXERCISES
103
f −1(C ∪D) = f −1(C) ∪f −1(D)? What is the answer to these questions
if we replace ∪by ∩?
8. Prove that the function f(x) = sin x can be written, on the interval (0, 2π),
as the diﬀerence of two increasing functions.
*
9. A function f from an interval (a, b) to an interval (c, d) is called proper if,
for any compact set K ⊆(c, d), it holds that f −1(K) is compact. Prove
that if f is proper then either
lim
x→a+ f(x) = c
or
lim
x→a+ f(x) = d .
Likewise prove that either
lim
x→b−f(x) = c
or
lim
x→b−f(x) = d .
10. We know that the continuous image of a connected set (i.e., an interval) is
also a connected set (another interval). Suppose now that A is the union
of k disjoint intervals and that f is a continuous function. What can you
say about the set f(A)?
11. A function f with domain A and range B is called a homeomorphism if it
is one-to-one, onto, continuous, and has continuous inverse. If such an f
exists then we say that A and B are homeomorphic. Which sets of reals
are homeomorphic to the open unit interval (0, 1)? Which sets of reals are
homeomorphic to the closed unit interval [0, 1]?
12. Let f be a continuous function with domain [0, 1] and range [0, 1]. Prove
that there exists a point P ∈[0, 1] such that f(P) = P. (Hint: Apply
the Intermediate Value theorem to the function g(x) = f(x) −x.) Prove
that this result is false if the domain and range of the function are both
(0, 1).
13. Let f be a continuous function and let {aj} be a Cauchy sequence in the
domain of f. Does it follow that {f(aj)} is a Cauchy sequence? What if
we assume instead that f is uniformly continuous?
*
14. Let E be any closed set of real numbers. Prove that there is a continuous
function f with domain R such that {x : f(x) = 0} = E.
15. Let E and F be disjoint closed sets of real numbers. Prove that there
is a continuous function f with domain the real numbers such that {x :
f(x) = 0} = E and {x : f(x) = 1} = F.
16. If K and L are sets then deﬁne
K + L = {k + ℓ: k ∈K and ℓ∈L} .
If K and L are compact then prove that K + L is compact. If K and L
are merely closed, does it follow that K + L is closed?
17. Provide the details of the proof of Corollary 5.19.

104
CHAPTER 5. LIMITS AND CONTINUITY OF FUNCTIONS
5.4
Classifying Discontinuities and Monotonic-
ity
We begin by reﬁning our notion of limit:
Deﬁnition 5.32 Fix P ∈R. Let f be a function with domain E. Suppose
that P is a limit point of E ∩[P −1, P). We say that f has left limit ℓat P,
and write
lim
x→P −f(x) = ℓ
if, for every ǫ > 0, there is a δ > 0 such that, whenever x ∈E and P −δ < x < P,
then it holds that
|f(x) −ℓ| < ǫ .
Now suppose that P is a limit point of E ∩(P, P + 1]. We say that f has
right limit m at P, and write
lim
x→P + f(x) = m
if, for every ǫ > 0, there is a δ > 0 such that, whenever x ∈E and P < x < P +δ,
then it holds that
|f(x) −m| < ǫ .
This deﬁnition simply formalizes the notion of either letting x tend to P
from the left only or from the right only.
Deﬁnition 5.33 Fix P ∈R. Let f be a function with domain E. Suppose
that P is a limit point of E ∩[P −1, P) and that P is an element of E. We say
that f is left continuous at P if
lim
x→P −f(x) = f(P) .
Likewise, in case P is a limit point of E ∩(P, P + 1] and is also an element
of E, we say that f is right continuous at P if
lim
x→P + f(x) = f(P) .
Let f be a function with domain E. Let P in E and assume that f is
discontinuous at P. There are two ways in which this discontinuity can occur:
I. If limx→P −f(x) and limx→P + f(x) both exist but either do not equal each
other or do not equal f(P) then we say that f has a discontinuity of the
ﬁrst kind (or sometimes a simple discontinuity) at P.

5.4. CLASSIFYING DISCONTINUITIES AND MONOTONICITY
105
y
x
y
x
discontinuity of the second kind
discontinuity of the first kind
Figure 5.8: Discontinuities of the ﬁrst and second kind.
II. If either limx→P −does not exist or limx→P + does not exist then we say
that f has a discontinuity of the second kind at P.
Refer to Figure 5.8.
Example 5.34 Deﬁne
f(x) =

sin(1/x)
if
x ̸= 0
0
if
x = 0
g(x) =



1
if
x > 0
0
if
x = 0
−1
if
x < 0
h(x) =
 1
if x is irrational
0
if x is rational
Then f has a discontinuity of the second kind at 0 while g has a discontinuity
of the ﬁrst kind at 0. The function h has a discontinuity of the second kind at
every point.
Deﬁnition 5.35 Let f be a function whose domain contains an open interval
(a, b). We say that f is increasing on (a, b) if, whenever a < s < t < b, it holds
that f(s) ≤f(t). We say that f is decreasing on (a, b) if, whenever a < s < t < b,
it holds that f(s) ≥f(t). See Figure 5.9.
If a function is either increasing or decreasing then we call it monotone or
monotonic. Compare with the deﬁnition of monotonic sequences in Section 2.1.
As with sequences, the word “monotonic” is superﬂuous in many contexts.
But its use is traditional and occasionally convenient.

106
CHAPTER 5. LIMITS AND CONTINUITY OF FUNCTIONS
y
x
y
x
monotone increasing function
monotone decreasing function
Figure 5.9: Increasing and decreasing functions.
Proposition 5.36 Let f be a monotonic function on an open interval (a, b).
Then all of the discontinuities of f are of the ﬁrst kind.
Proof: It is enough to show that for each P ∈(a, b) the limits
lim
x→P −f(x)
and
lim
x→P + f(x)
exist.
Let us ﬁrst assume that f is monotonically increasing. Fix P ∈(a, b). If
a < s < P then f(s) ≤f(P). Therefore S = {f(s) : a < s < P} is bounded
above. Let M be the least upper bound of S. Pick ǫ > 0. By deﬁnition of
least upper bound there must be an f(s) ∈S such that |f(s) −M| < ǫ. Let
δ = |P −s|. If P −δ < t < P then s < t < P and f(s) ≤f(t) ≤M or
|f(t) −M| < ǫ. Thus limx→P −f(x) exists and equals M.
If we set m equal to the inﬁmum of the set T = {f(t) : P < t < b} then a
similar argument shows that limx→P + f(x) exists and equals m. That completes
the proof.
Corollary 5.37 Let f be a monotonic function on an interval (a, b). Then f
has at most countably many discontinuities.
Proof: Assume for simplicity that f is monotonically increasing. If P is a
discontinuity then the proposition tells us that
lim
x→P −f(x) <
lim
x→P + f(x) .

EXERCISES
107
Therefore there is a rational number qP between limx→P −f(x) and limx→P + f(x).
Notice that diﬀerent discontinuities will have diﬀerent rational numbers associ-
ated to them because if bP is another discontinuity and, say, bP < P then
lim
x→b
P −f(x) < q b
P <
lim
x→b
P + f(x) ≤
lim
x→P −f(x) < qP <
lim
x→P + f(x) .
Thus we have exhibited a one-to-one function of the set of discontinuities
of f into the set of rational numbers. It follows that the set of discontinuities is
countable.
A continuous function f has the property that the inverse image under f of
any open set is open. However, it is not in general true that the image under f
itself of any open set is open. A counterexample is the function f(x) = x2 and
the open set O = (−1, 1) whose image under f is [0, 1).
Suppose that f is a function on (a, b) such that a < s < t < b implies
f(s) < f(t). Such a function is called strictly increasing (strictly decreasing
functions are deﬁned similarly). We refer to such functions as strictly monotone.
It is clear that a strictly increasing (resp. decreasing) function is one-to-one,
hence has an inverse. Now we prove:
Theorem 5.38 Let f be a strictly monotone, continuous function with domain
[a, b]. Then f −1 exists and is continuous.
Proof: Assume without loss of generality that f is strictly monotone increasing.
Let us extend f to the entire real line by deﬁning
f(x) =



(x −a) + f(a)
if
x < a
as given
if
a ≤x ≤b
(x −b) + f(b)
if
x > b .
See Figure 5.10. Then it is easy to see that this extended version of f is still
continuous and is strictly monotone increasing on all of R.
That f −1 exists has already been discussed. The extended function f takes
any open interval (c, d) to the open interval (f(c), f(d)). Since any open set is
a union of open intervals, we see that f takes any open set to an open set. In
other words,

f −1−1 takes open sets to open sets. But this just says that f −1
is continuous.
Since the inverse of the extended function f is continuous, then so is the
inverse of the original function f. That completes the proof.
Exercises
1. Let A be any left-to-right ordered, countable subset of the reals. Construct
an increasing function whose set of points of discontinuity is precisely the
set A. Explain why this is, in general, impossible for an uncountable set
A.

108
CHAPTER 5. LIMITS AND CONTINUITY OF FUNCTIONS
Figure 5.10: A strictly monotonically increasing function.
2. Give an example of two functions, discontinuous at x = 0, whose sum
is continuous at x = 0. Give an example of two such functions whose
product is continuous at x = 0.
How does the problem change if we
replace “product” by “quotient”?
3. Let f be a function with domain R. If f 2(x) = f(x) · f(x) is continuous
does it follow that f is continuous? If f 3(x) = f(x)·f(x)·f(x) is continuous
does it follow that f is continuous?
4. Fix an interval (a, b). Is the collection of increasing functions on (a, b)
closed under +, −, ×, or ÷?
*
5. TRUE or FALSE: If f is a function with domain and range the real num-
bers and which is both one-to-one and onto, then f must be either in-
creasing or decreasing. Does your answer change if we assume that f is
continuously diﬀerentiable?
*
6. Let I ⊆R be an open interval and f : I →R a function. We say that f
is convex if whenever α, β ∈I and 0 ≤t ≤1 then
f((1 −t)α + tβ) ≤(1 −t)f(α) + tf(β) .
Prove that a convex function must be continuous. What does this deﬁni-
tion of convex function have to do with the notion of “concave up” that
you learned in calculus?
7. Let f be a continuous function whose domain contains a closed, bounded
interval [a, b]. What topological properties does f([a, b]) possess? Is this
set necessarily an interval?
8. Refer to Exercise 11 of Section 5.3 for terminology. Show that there is no
homeomorphism from the real line to the interval [0, 1).

EXERCISES
109
9. Let f be a function with domain R. Prove that the set of discontinuities
of the ﬁrst kind for f is countable. (Hint: If the left and right limits at
a point disagree then you can slip a rational number between them.)
* 10. What can you say about diﬀerentiability of a convex function?


Chapter 6
Diﬀerentiation of Functions
6.1
The Concept of Derivative
Let f be a function with domain an open interval I. If x ∈I then the quantity
f(t) −f(x)
t −x
measures the slope of the chord of the graph of f that connects the points
(x, f(x)) and (t, f(t)). See Figure 6.1. If we let t →x then the limit of the
quantity represented by this “Newton quotient” should represent the slope of
the graph at the point x. These considerations motivate the deﬁnition of the
derivative:
Deﬁnition 6.1 If f is a function with domain an open interval I and if x ∈I
then the limit
lim
t→x
f(t) −f(x)
t −x
,
y
x
(x,f(x))
(t,f(t))
Figure 6.1: The Newton quotient.
111

112
CHAPTER 6. DIFFERENTIATION OF FUNCTIONS
y
x
(x,f(x))
Figure 6.2: The derivative.
when it exists, is called the derivative of f at x. See Figure 6.2. If the derivative
of f at x exists then we say that f is diﬀerentiable at x. If f is diﬀerentiable at
every x ∈I then we say that f is diﬀerentiable on I.
We write the derivative of f at x either as
f ′(x)
or
d
dxf
or
df
dx .
We begin our discussion of the derivative by establishing some basic prop-
erties and relating the notion of derivative to continuity.
Lemma 6.2 If f is diﬀerentiable at a point x then f is continuous at x. In
particular, limt→x f(t) = f(x).
Proof: We use Theorem 5.5(b) about limits to see that
lim
t→x (f(t) −f(x))
=
lim
t→x

(t −x) · f(t) −f(x)
t −x

=
lim
t→x(t −x) · lim
t→x
f(t) −f(x)
t −x
=
0 · f ′(x)
=
0.
Therefore limt→x f(t) = f(x) and f is continuous at x.
Thus all diﬀerentiable functions are continuous: diﬀerentiability is a stronger
property than continuity. Observe that the function f(x) = |x| is continuous at
every x but is not diﬀerentiable at 0. So continuity does not imply diﬀerentia-
bility. Details appear in Example 6.4.
Theorem 6.3 Assume that f and g are functions with domain an open interval
I and that f and g are diﬀerentiable at x ∈I. Then f ± g, f · g, and f/g are
diﬀerentiable at x (for f/g we assume that g(x) ̸= 0). Moreover

6.1. THE CONCEPT OF DERIVATIVE
113
(a) (f ± g)′(x) = f ′(x) ± g′(x);
(b) (f · g)′(x) = f ′(x) · g(x) + f(x) · g′(x);
(c)
f
g
′
(x) = g(x) · f ′(x) −f(x) · g′(x)
g2(x)
.
Proof: Assertion (a) is easy and we leave it as an exercise for you.
For (b), we write
lim
t→x
(f · g)(t) −(f · g)(x)
t −x
=
lim
t→x
(f(t) −f(x)) · g(t)
t −x
+ (g(t) −g(x)) · f(x)
t −x

=
lim
t→x
(f(t) −f(x)) · g(t)
t −x

+ lim
t→x
(g(t) −g(x)) · f(x)
t −x

=
lim
t→x
(f(t) −f(x))
t −x

·

lim
t→x g(t)

+ lim
t→x
(g(t) −g(x))
t −x

·

lim
t→x f(x)

,
where we have used Theorem 5.5 about limits. Now the ﬁrst limit is the deriva-
tive of f at x, while the third limit is the derivative of g at x. Also notice that
the limit of g(t) equals g(x) by the lemma. The result is that the last line equals
f ′(x) · g(x) + g′(x) · f(x) ,
as desired.
To prove (c), write
lim
t→x
(f/g)(t) −(f/g)(x)
t −x
=
lim
t→x
1
g(t) · g(x)
f(t) −f(x)
t −x
· g(x)
−g(t) −g(x)
t −x
· f(x)

.
The proof is now completed by using Theorem 5.5 about limits to evaluate
the individual limits in this expression.
Example 6.4 That f(x) = x is diﬀerentiable follows from
lim
t→x
t −x
t −x = 1 .

114
CHAPTER 6. DIFFERENTIATION OF FUNCTIONS
Any constant function is diﬀerentiable (with derivative identically zero) by a
similar argument. It follows from the theorem that any polynomial function is
diﬀerentiable.
On the other hand, the continuous function f(x) = |x| is not diﬀerentiable
at the point x = 0. This is so because
lim
t→0−
|t| −|0|
t −x
= lim
t→0−
−t −0
t −0 = −1
while
lim
t→0+
|t| −|0|
t −x
= lim
t→0+
t −0
t −0 = 1 .
So the required limit does not exist.
Since the subject of diﬀerential calculus is concerned with learning uses of
the derivative, it concentrates on functions which are diﬀerentiable. One comes
away from the subject with the impression that most functions are diﬀerentiable
except at a few isolated points—as is the case with the function f(x) = |x|.
Indeed this was what the mathematicians of the nineteenth century thought.
Therefore it came as a shock when Karl Weierstrass produced a continuous
function that is not diﬀerentiable at any point. In a sense that will be made
precise in Chapter 14, most continuous functions are of this nature: their graphs
“wiggle” so much that they cannot have a tangent line at any point. Now we
turn to an elegant variant of the example of Weierstrass that is due to B. L. van
der Waerden (1903–1996).
Theorem 6.5 Deﬁne a function ψ with domain R by the rule
ψ(x) =
 x −n
if
n ≤x < n + 1 and n is even
n + 1 −x
if
n ≤x < n + 1 and n is odd
for every integer n. The graph of this function is exhibited in Figure 6.3. Then
the function
f(x) =
∞
X
j=1
3
4
j
ψ
 4jx

is continuous at every real x and diﬀerentiable at no real x.
Proof: Since we have not yet discussed series of functions, we take a moment
to understand the deﬁnition of f. Fix a real x. Then the series becomes a series
of numbers, and the jth summand does not exceed (3/4)j in absolute value.
Thus the series converges absolutely; therefore it converges. So it is clear that
the displayed formula deﬁnes a function of x.
Step I: f is continuous. To see that f is continuous, pick an ǫ > 0. Choose
N so large that
∞
X
j=N+1
3
4
j
< ǫ
4

6.1. THE CONCEPT OF DERIVATIVE
115
Figure 6.3: The van der Waerden example.
(we can of course do this because the series P   3
4
j converges). Now ﬁx
x. Observe that, since ψ is continuous and the graph of ψ is composed of
segments of slope 1, we have
|ψ(s) −ψ(t)| ≤|s −t|
for all s and t. Moreover |ψ(s) −ψ(t)| ≤1 for all s, t.
For j = 1, 2, . . . , N, pick δj > 0 so that, when |t −x| < δj, then
ψ
 4jt

−ψ
 4jx
 < ǫ
8 .
Let δ be the minimum of δ1, . . . δN.
Now, if |t −x| < δ, then
|f(t) −f(x)|
=

N
X
j=1
3
4
j
·
 ψ(4jt) −ψ(4jx)

+
∞
X
j=N+1
3
4
j
·
 ψ(4jt) −ψ(4jx)


≤
N
X
j=1
3
4
j  ψ(4jt) −ψ(4jx)

+
∞
X
j=N+1
3
4
j ψ(4jt) −ψ(4jx)

≤
N
X
j=1
3
4
j
· ǫ
8 +
∞
X
j=N+1
3
4
j
.
Here we have used the choice of δ to estimate the summands in the ﬁrst
sum. The ﬁrst sum is thus less than ǫ/2 (just notice that P∞
j=1(3/4)j < 4).

116
CHAPTER 6. DIFFERENTIATION OF FUNCTIONS
The second sum is less than ǫ/2 by the choice of N. Altogether then
|f(t) −f(x)| < ǫ
whenever |t −x| < δ. Therefore f is continuous, indeed uniformly so.
Step II: f is nowhere diﬀerentiable. Fix x. For ℓ= 1, 2, . . . deﬁne tℓ=
x ± 4−ℓ/2. We will say whether the sign is plus or minus in a moment
(this will depend on the position of x relative to the integers). Then

f(tℓ) −f(x)
tℓ−x
 =

1
tℓ−x


ℓ
X
j=1
3
4
j  ψ(4jtℓ) −ψ(4jx)

+
∞
X
j=ℓ+1
3
4
j  ψ(4jtℓ) −ψ(4jx)




.
(6.5.1)
Notice that, when j ≥ℓ+1, then 4jtℓand 4jx diﬀer by an even integer.
Since ψ has period 2, we ﬁnd that each of the summands in the second
sum is 0. Next we turn to the ﬁrst sum.
We choose the sign—plus or minus—in the deﬁnition of tℓso that there
is no integer lying between 4ℓtℓand 4ℓx. We can do this because the two
numbers diﬀer by 1/2. But then the ℓth summand has magnitude
(3/4)ℓ· |4ℓtℓ−4ℓx| = 3ℓ|tℓ−x| .
On the other hand, the ﬁrst ℓ−1 summands add up to not more than
ℓ−1
X
j=1
3
4
j
· |4jtℓ−4jx| =
ℓ−1
X
j=1
3j · 4−ℓ/2 ≤3ℓ−1
3 −1 · 4−ℓ/2 ≤3ℓ· 4−ℓ−1 .

6.1. THE CONCEPT OF DERIVATIVE
117
It follows that

f(tℓ) −f(x)
tℓ−x

=
1
|tℓ−x| ·

ℓ
X
j=1
3
4
j  ψ(4jtℓ) −ψ(4jx)


=
1
|tℓ−x|

·
ℓ−1
X
j=1
3
4
j  ψ(4jtℓ) −ψ(4jx)

+
3
4
ℓ ψ(4ℓtℓ) −ψ(4ℓx)


≥
1
|tℓ−x| ·

3
4
ℓ
ψ(4ℓtℓ) −
3
4
ℓ
ψ(4ℓx)

−
1
|tℓ−x|

ℓ−1
X
j=1
3
4
j  ψ(4jtℓ) −ψ(4jx)


≥
3ℓ−
1
(4−ℓ/2) · 3ℓ· 4−ℓ−1
≥
3ℓ−1.
Thus tℓ→x but the Newton quotients blow up. Therefore the limit
lim
t→x
f(t) −f(x)
t −x
cannot exist. The function f is not diﬀerentiable at x.
The proof of the last theorem was long, but the idea is simple: the function
f is built by piling oscillations on top of oscillations. When the ℓth oscillation
is added, it is made very small in size so that it does not cancel the previous
oscillations. But it is made very steep so that it will cause the derivative to
become large.
The practical meaning of Weierstrass’s example is that we should realize
that diﬀerentiability is a very strong and special property of functions. Most
continuous functions are not diﬀerentiable at any point. Theorem 13.42 will
make this assertion precise. When we are proving theorems about continuous
functions, we should not think of them in terms of properties of diﬀerentiable
functions.
Next we turn to the Chain Rule.
Theorem 6.6 Let g be a diﬀerentiable function on an open interval I and let
f be a diﬀerentiable function on an open interval that contains the range of g.
Then f ◦g is diﬀerentiable on the interval I and
(f ◦g)′ (x) = f ′(g(x)) · g′(x)

118
CHAPTER 6. DIFFERENTIATION OF FUNCTIONS
for each x ∈I.
Proof: We use the notation ∆t to stand for an increment in the variable t. Let
us use the symbol V(r) to stand for any expression which tends to 0 as ∆r →0.
Fix x ∈I. Set r = g(x). By hypothesis,
lim
∆r→0
f(r + ∆r) −f(r)
∆r
= f ′(r)
or
f(r + ∆r) −f(r)
∆r
−f ′(r) = V(r)
or
f(r + ∆r) = f(r) + ∆r · f ′(r) + ∆r · V(r) .
(6.6.1)
Notice that equation (6.6.1) is valid even when ∆r = 0. Since ∆r in equation
(6.6.1) can be any small quantity, we set
∆r = ∆x · [g′(x) + V(x)] .
Substituting this expression into (6.6.1) and using the fact that r = g(x) yields
f(g(x)+∆x[g′(x) + V(x)]) =
f(r) + (∆x · [g′(x) + V(x)]) · f ′(r) + (∆x · [g′(x) + V(x)]) · V(r)
= f(g(x)) + ∆x · f ′(g(x)) · g′(x) + ∆x · V(x).
(6.6.2)
Just as we derived (6.6.1), we may also obtain
g(x + ∆x)
=
g(x) + ∆x · g′(x) + ∆x · V(x)
=
g(x) + ∆x[g′(x) + V(x)] .
We may substitute this equality into the left side of (6.6.2) to obtain
f(g(x + ∆x)) = f(g(x)) + ∆x · f ′(g(x)) · g′(x) + ∆x · V(x) .
With some algebra this can be rewritten as
f(g(x + ∆x)) −f(g(x))
∆x
−f ′(g(x)) · g′(x) = V(x) .
But this just says that
lim
∆x→0
(f ◦g)(x + ∆x) −(f ◦g)(x)
∆x
= f ′(g(x)) · g′(x) .
That is, (f ◦g)′(x) exists and equals f ′(g(x)) · g′(x), as desired.

EXERCISES
119
Exercises
1. For which positive integers k is it true that if f k = f·f · · · f is diﬀerentiable
at x then f is diﬀerentiable at x?
2. Let f be a function that has domain an interval I and takes values in the
complex numbers. Then we may write f(x) = u(x) + iv(x) with u and
v each being real-valued functions. We say that f is diﬀerentiable at a
point x ∈I if both u and v are. Formulate an alternative deﬁnition of
diﬀerentiability of f at a point x which makes no reference to u and v (but
instead deﬁnes the derivative directly in terms of f) and prove that your
new deﬁnition is equivalent to the deﬁnition in terms of u and v.
3. Verify the properties of the derivative presented in Theorem 6.3 in the
new context of complex-valued functions.
*
4. Let E ⊆R be a closed set. Fix a nonnegative integer k. Show that there
is a function f in Ck(R) (that is, a k-times continuously diﬀerentiable
function) such that E = {x : f(x) = 0}.
*
5. Prove that the nowhere diﬀerentiable function constructed in Theorem 6.5
is in Lipα for all α < 1.
6. Let f(x) equal 0 if x is irrational; let f(x) equal 1/q if x is a rational
number that can be expressed in lowest terms as p/q. Is f diﬀerentiable
at any x?
7. Assume that f is a continuous function on (−1, 1) and that f is diﬀeren-
tiable on (−1, 0) ∪(0, 1). If the limit limx→0 f ′(x) exists then is f diﬀer-
entiable at x = 0?
8. Formulate notions of “left diﬀerentiable” and “right diﬀerentiable” for
functions deﬁned on suitable half-open intervals. Also formulate deﬁni-
tions of “left continuous” and “right continuous.” If you have done things
correctly, then you should be able to prove that a left diﬀerentiable (right
diﬀerentiable) function is left continuous (right continuous).
*
9. Prove that the Weierstrass nowhere diﬀerentiable function f satisﬁes
|f(x + h) + f(x −h) −2f(x)|
|h|
≤C|h|
for all nonzero h but f is not in Lip1.
10. Give an example of a function f : R →R which is diﬀerentiable at every
point but so that the derivative function is not continuous.
11. Prove part (a) of Theorem 6.3.

120
CHAPTER 6. DIFFERENTIATION OF FUNCTIONS
y
x
local maximum
local minimum
Figure 6.4: Some extrema.
6.2
The Mean Value Theorem and Applications
We begin this section with some remarks about local maxima and minima of
functions.
Deﬁnition 6.7 Let f be a function with domain (a, b). A point x ∈(a, b) is
called a local maximum for f (we also say that f has a local maximum at x) if
there is a δ > 0 such that f(t) ≤f(x) for all t ∈(x−δ, x+δ). A point x ∈(a, b)
is called a local minimum for f (we also say that f has a local minimum at x) if
there is a δ > 0 such that f(t) ≥f(x) for all t ∈(x −δ, x + δ). See Figure 6.4.
Local minima (plural of minimum) and local maxima (plural of maximum)
are referred to collectively as local extrema.
Proposition 6.8 (Fermat) If f is a function with domain (a, b), if f has a
local extremum at x ∈(a, b), and if f is diﬀerentiable at x, then f ′(x) = 0.
Proof: Suppose that f has a local minimum at x. Then there is a δ > 0 such
that if x −δ < t < x then f(t) ≥f(x). Then
f(t) −f(x)
t −x
≤0 .
Letting t →x, it follows that f ′(x) ≤0. Similarly, if x < t < x + δ for suitable
δ, then
f(t) −f(x)
t −x
≥0 .
It follows that f ′(x) ≥0. We must conclude that f ′(x) = 0.
A similar argument applies if f has a local maximum at x. The proof is
therefore complete.

6.2. THE MEAN VALUE THEOREM AND APPLICATIONS
121
Before going on to mean value theorems, we provide a striking application
of the proposition:
Theorem 6.9 (Darboux’s Theorem) Let f be a diﬀerentiable function on
an open interval I. Pick points s < t in I and suppose that f ′(s) < ρ < f ′(t).
Then there is a point u between s and t such that f ′(u) = ρ.
Proof: Consider the function g(x) = f(x) −ρx. Then g′(s) < 0 and g′(t) > 0.
Assume for simplicity that s < t. The sign of the derivative at s shows that
g(bs) < g(s) for bs greater than s and near s. The sign of the derivative at t
implies that g(bt) < g(t) for bt less than t and near t. Thus the minimum of the
continuous function g on the compact interval [s, t] must occur at some point u
in the interior (s, t). The preceding proposition guarantees that g′(u) = 0, or
f ′(u) = ρ as claimed.
If f ′ were a continuous function then the theorem would just be a spe-
cial instance of the Intermediate Value Property of continuous functions (see
Corollary 5.31). But derivatives need not be continuous, as the example
f(x) =
 x2 · sin(1/x)
if
x ̸= 0
0
if
x = 0
illustrates. Check for yourself that f ′(0) exists and vanishes but limx→0 f ′(x)
does not exist. This example illustrates the signiﬁcance of the theorem. Since
the theorem says that f ′ will always satisfy the Intermediate Value Property
(even when it is not continuous), its discontinuities cannot be of the ﬁrst kind.
In other words:
Proposition 6.10 If f is a diﬀerentiable function on an open interval I then
the discontinuities of f ′ are all of the second kind.
Next we turn to the simplest form of the Mean Value Theorem.
Theorem 6.11 (Rolle’s Theorem) Let f be a continuous function on the
closed interval [a, b] which is diﬀerentiable on (a, b). If f(a) = f(b) = 0 then
there is a point ξ ∈(a, b) such that f ′(ξ) = 0. See Figure 6.5.
Proof: If f is a constant function then any point ξ in the interval will do. So
assume that f is nonconstant.
Theorem 5.23 guarantees that f will have both a maximum and a minimum
in [a, b]. If one of these occurs in (a, b) then Proposition 6.8 guarantees that f ′
will vanish at that point and we are done. If both occur at the endpoints then all
the values of f lie between 0 and 0. In other words f is constant, contradicting
our assumption.
Of course the point ξ in Rolle’s theorem need not be unique. If f(x) =
x3 −x2 −2x on the interval [−1, 2] then f(−1) = f(2) = 0 and f ′ vanishes at
two points of the interval (−1, 2). Refer to Figure 6.6.

122
CHAPTER 6. DIFFERENTIATION OF FUNCTIONS
y
x
(a,0)
(b,0)
(  , f(  ))
Figure 6.5: Rolle’s theorem.
y
x
Figure 6.6: An example of Rolle’s theorem.

6.2. THE MEAN VALUE THEOREM AND APPLICATIONS
123
Figure 6.7: The Mean Value Theorem.
If you rotate the graph of a function satisfying the hypotheses of Rolle’s
theorem, the result suggests that, for any continuous function f on an interval
[a, b], diﬀerentiable on (a, b), we should be able to relate the slope of the chord
connecting (a, f(a)) and (b, f(b)) with the value of f ′ at some interior point.
That is the content of the standard Mean Value Theorem:
Theorem 6.12 (The Mean Value Theorem) Let f be a continuous func-
tion on the closed interval [a, b] that is diﬀerentiable on (a, b). There exists a
point ξ ∈(a, b) such that
f(b) −f(a)
b −a
= f ′(ξ) .
See Figure 6.7.
Proof: Our scheme is to implement the remarks preceding the theorem: we
“rotate” the picture to reduce to the case of Rolle’s theorem. More precisely,
deﬁne
g(x) = f(x) −

f(a) + f(b) −f(a)
b −a
· (x −a)

if
x ∈[a, b] .
By direct veriﬁcation, g is continuous on [a, b] and diﬀerentiable on (a, b) (after
all, g is obtained from f by elementary arithmetic operations). Also g(a) =
g(b) = 0.
Thus we may apply Rolle’s theorem to g and we ﬁnd that there
is a ξ ∈(a, b) such that g′(ξ) = 0. Remembering that x is the variable, we
diﬀerentiate the formula for g to ﬁnd that
0 = g′(ξ)
=

f ′(x) −f(b) −f(a)
b −a

x=ξ
=

f ′(ξ) −f(b) −f(a)
b −a

.

124
CHAPTER 6. DIFFERENTIATION OF FUNCTIONS
As a result,
f ′(ξ) = f(b) −f(a)
b −a
.
Corollary 6.13 If f is a diﬀerentiable function on the open interval I and if
f ′(x) = 0 for all x ∈I then f is a constant function.
Proof: If s and t are any two elements of I then the theorem tells us that
f(s) −f(t) = f ′(ξ) · (s −t)
for some ξ between s and t. But, by hypothesis, f ′(ξ) = 0. We conclude that
f(s) = f(t). But, since s and t were chosen arbitrarily, we must conclude that
f is constant.
Corollary 6.14 If f is diﬀerentiable on an open interval I and f ′(x) ≥0 for
all x ∈I, then f is increasing on I; that is, if s < t are elements of I, then
f(s) ≤f(t).
If f is diﬀerentiable on an open interval I and f ′(x) ≤0 for all x ∈I, then
f is decreasing on I; that is, if s < t are elements of I, then f(s) ≥f(t).
Proof: Similar to the preceding corollary.
Example 6.15 Let us verify that, if f is a diﬀerentiable function on R, and if
|f ′(x)| ≤1 for all x, then |f(s) −f(t)| ≤|s −t| for all real s and t.
In fact, for s ̸= t there is a ξ between s and t such that
f(s) −f(t)
s −t
= f ′(ξ) .
But |f ′(ξ)| ≤1 by hypothesis hence

f(s) −f(t)
s −t
 ≤1
or
|f(s) −f(t)| ≤|s −t| .
Example 6.16 Let us verify that
lim
x→+∞
 √
x + 5 −√x

= 0 .
Here the limit operation means that, for any ǫ > 0, there is an N > 0 such that
x > N implies that the expression in parentheses has absolute value less than ǫ.
Deﬁne f(x) = √x for x > 0. Then the expression in parentheses is just
f(x + 5) −f(x). By the Mean Value Theorem this equals
f ′(ξ) · 5

6.2. THE MEAN VALUE THEOREM AND APPLICATIONS
125
for some x < ξ < x + 5. But this last expression is
1
2 · ξ−1/2 · 5 .
By the bounds on ξ, this is
≤5
2x−1/2 .
Clearly, as x →+∞, this expression tends to zero.
A powerful tool in analysis is a generalization of the usual Mean Value
Theorem that is due to A. L. Cauchy (1789–1857):
Theorem 6.17 (Cauchy’s Mean Value Theorem) Let f and g be contin-
uous functions on the interval [a, b] which are both diﬀerentiable on the interval
(a, b). Assume that g′ ̸= 0 on the interval. Then there is a point ξ ∈(a, b) such
that
f(b) −f(a)
g(b) −g(a) = f ′(ξ)
g′(ξ) .
Proof: Apply the usual Mean Value Theorem to the function
h(x) = g(x) · {f(b) −f(a)} −f(x) · {g(b) −g(a)} .
Clearly the usual Mean Value Theorem (Theorem 6.12) is obtained from
Cauchy’s by taking g(x) to be the function x.
We conclude this section by
illustrating a typical application of the result.
Example 6.18 Let f be a diﬀerentiable function on an interval I such that f ′
is diﬀerentiable at a point x ∈I. Then
lim
h→0+
f(x + h) + f(x −h) −2f(x)
h2
= (f ′)′(x) ≡f ′′(x) .
To see this, ﬁx x and deﬁne F(h) = f(x + h) + f(x −h) −2f(x) and G(h) = h2.
Then
f(x + h) + f(x −h) −2f(x)
h2
= F(h) −F(0)
G(h) −G(0) .
According to Cauchy’s Mean Value Theorem, there is a ξ between 0 and h such
that the last line equals
F′(ξ)
G′(ξ) .
Writing this expression out gives
f ′(x + ξ) −f ′(x −ξ)
2ξ
=
1
2 · f ′(x + ξ) −f ′(x)
ξ
+ 1
2 · f ′(x −ξ) −f ′(x)
−ξ
,

126
CHAPTER 6. DIFFERENTIATION OF FUNCTIONS
and the last line tends, by the deﬁnition of the derivative, to the quantity
(f ′)′(x).
It is a fact that the standard proof of l’Hˆopital’s Rule (Guillaume Fran¸cois
Antoine de l’Hˆopital, Marquis de St.-Mesme, 1661–1704) is obtained by way of
Cauchy’s Mean Value Theorem. This line of reasoning is explored in the next
section.
Exercises
1. Give an example of a function f for which the limit in Example 6.18 exists
at some x but for which f is not twice diﬀerentiable at x.
2. Let f be a function that is continuous on [0, ∞) and diﬀerentiable on
(0, ∞). If f(0) = 0 and |f ′(x)| ≤|f(x)| for all x > 0 then prove that
f(x) = 0 for all x. [This result is often called Gronwall’s inequality.]
3. Let f be a continuous function on [a, b] that is diﬀerentiable on (a, b).
Assume that f(a) = m and that |f ′(x)| ≤K for all x ∈(a, b). What
bound can you then put on the magnitude of f(b)?
4. Let f be a diﬀerentiable function on an open interval I and assume that
f has no local minima nor local maxima on I.
Prove that f is either
increasing or decreasing on I.
5. Let 0 < α ≤1. Prove that there is a constant Cα > 0 such that, for
0 < x < 1, it holds that
| ln x| ≤Cα · x−α .
Prove that the constant cannot be taken to be independent of α.
6. Let f be a function that is twice diﬀerentiable on (0, ∞) and assume that
f ′′(x) ≥c > 0 for all x. Prove that f is not bounded from above.
7. Let f be diﬀerentiable on an interval I and f ′(x) > 0 for all x ∈I. Does
it follow that (f 2)′ > 0 for all x ∈I? What additional hypothesis on f
will make the conclusion true?
8. Answer Exercise 7 with the exponent 2 replaced by any positive integer
exponent.
9. Use the Mean Value Theorem to say something about the behavior at ∞
of the function f(x) = √x + 1 −√x.
10. Refer to Exercise 9. What can you say about the asymptotics at inﬁnity
of √x + 1/√x?

6.3. MORE ON THE THEORY OF DIFFERENTIATION
127
6.3
More on the Theory of Diﬀerentiation
l’Hˆopital’s Rule (actually due to his teacher J. Bernoulli (1667-1748)) is a useful
device for calculating limits, and a nice application of the Cauchy Mean Value
Theorem. Here we present a special case of the theorem.
Theorem 6.19 Suppose that f and g are diﬀerentiable functions on an open
interval I and that p ∈I. If limx→p f(x) = limx→p g(x) = 0 and if
lim
x→p
f ′(x)
g′(x)
(6.19.1)
exists and equals a real number ℓthen
lim
x→p
f(x)
g(x) = ℓ.
Proof: Fix a real number a > ℓ. By (6.19.1) there is a number q > p such that,
if p < x < q, then
f ′(x)
g′(x) < a .
(6.19.2)
But now, if p < s < t < q, then
f(t) −f(s)
g(t) −g(s) = f ′(x)
g′(x)
for some s < x < t (by Cauchy’s Mean Value Theorem). It follows then from
(6.19.2) that
f(t) −f(s)
g(t) −g(s) < a .
Now let s →p and invoke the hypothesis about the zero limit of f and g at p
to conclude that
f(t)
g(t) ≤a
when p < t < q. Since a is an arbitrary number to the right of ℓwe conclude
that
lim sup
t→p+
f(t)
g(t) ≤ℓ.
Similar arguments show that
lim inf
t→p+
f(t)
g(t) ≥ℓ;
lim sup
t→p−
f(t)
g(t) ≤ℓ;
lim inf
t→p−
f(t)
g(t) ≥ℓ.

128
CHAPTER 6. DIFFERENTIATION OF FUNCTIONS
We conclude that the desired limit exists and equals ℓ.
A closely related result, with a similar proof, is this:
Theorem 6.20 Suppose that f and g are diﬀerentiable functions on an open
interval I and that p ∈I. If limx→p f(x) = limx→p g(x) = ±∞and if
lim
x→p
f ′(x)
g′(x)
(6.20.1)
exists and equals a real number ℓthen
lim
x→p
f(x)
g(x) = ℓ.
Example 6.21 Let
f(x) =
ln |x|
(x2) .
We wish to determine limx→0 f(x). To do so, we deﬁne
F(x) = ln f(x) = x2 ln
ln |x|
 = ln | ln |x||
1/x2
.
Notice that both the numerator and the denominator tend to ±∞as x →0. So
the hypotheses of l’Hˆopital’s rule are satisﬁed and the limit is
lim
x→0
ln | ln |x||
1/x2
= lim
x→0
1/[x ln |x|]
−2/x3
= lim
x→0
−x2
2 ln |x| = 0 .
Since limx→0 F(x) = 0 we may calculate that the original limit has value
limx→0 f(x) = 1.
Proposition 6.22 Let f be an invertible function on an interval (a, b) with
nonzero derivative at a point x ∈(a, b). Let X = f(x). Then
 f −1′ (X) exists
and equals 1/f ′(x).
Proof: Observe that, for T ̸= X,
f −1(T ) −f −1(X)
T −X
=
1
f(t)−f(x)
t−x
,
(6.22.1)
where T = f(t). Since f ′(x) ̸= 0, the diﬀerence quotients for f in the denom-
inator are bounded from zero hence the limit of the formula in (6.22.1) exists.
This proves that f −1 is diﬀerentiable at X and that the derivative at that point
equals 1/f ′(x).

6.3. MORE ON THE THEORY OF DIFFERENTIATION
129
Example 6.23 We know that the function f(x) = xk, k a positive integer, is
one-to-one and diﬀerentiable on the interval (0, 1).
Moreover the derivative
k · xk−1 never vanishes on that interval. Therefore the proposition applies and
we ﬁnd for X ∈(0, 1) = f((0, 1)) that
 f −1′ (X) =
1
f ′(x) =
1
f ′(X1/k)
=
1
k · X1−1/k = 1
k · X
1
k −1 .
In other words,

X1/k′
= 1
k X
1
k −1 .
We conclude this section by saying a few words about higher derivatives.
If f is a diﬀerentiable function on an open interval I then we may ask whether
the function f ′ is diﬀerentiable. If it is, then we denote its derivative by
f ′′ or f (2) or
d2
dx2 f or d2f
dx2 ,
and call it the second derivative of f. Likewise the derivative of the (k −1)th
derivative, if it exists, is called the kth derivative and is denoted
f ′′...′ or f (k) or
dk
dxk f or dkf
dxk .
Observe that we cannot even consider whether f (k) exists at a point unless
f (k−1) exists in a neighborhood of that point.
If f is k times diﬀerentiable on an open interval I and if each of the deriva-
tives f (1), f (2), . . . , f (k) is continuous on I then we say that the function f is k
times continuously diﬀerentiable on I. We write f ∈Ck(I). Obviously there is
some redundancy in this deﬁnition since the continuity of f (j−1) follows from
the existence of f (j). Thus only the continuity of the last derivative f (k) need be
checked. Continuously diﬀerentiable functions are useful tools in analysis. We
denote the class of k times continuously diﬀerentiable functions on I by Ck(I).
For k = 1, 2, . . . the function
fk(x) =

xk+1
if
x ≥0
−xk+1
if
x < 0
will be k times continuously diﬀerentiable on R but will fail to be k + 1 times
diﬀerentiable at x = 0. More dramatically, an analysis similar to the one we
used on the Weierstrass nowhere diﬀerentiable function shows that the function
gk(x) =
∞
X
j=1
3j
4j+jk sin(4jx)

130
CHAPTER 6. DIFFERENTIATION OF FUNCTIONS
is k times continuously diﬀerentiable on R but will not be k + 1 times dif-
ferentiable at any point (this function, with k = 0, was Weierstrass’s original
example).
A more reﬁned notion of smoothness/continuity of functions is that of
H¨older continuity or Lipschitz continuity (see Section 5.3). If f is a function
on an open interval I and if 0 < α ≤1 then we say that f satisﬁes a Lipschitz
condition of order α on I if there is a constant M such that for all s, t ∈I we
have
|f(s) −f(t)| ≤M · |s −t|α .
Such a function is said to be of class Lipα(I). Clearly a function of class Lipα
is uniformly continuous on I. For, if ǫ > 0, then we may take δ = (ǫ/M)1/α: it
follows that, for |s −t| < α, we have
|f(s) −f(t)| ≤M · |s −t|α < M · ǫ/M = ǫ .
Interestingly, when α > 1 the class Lipα contains only constant functions.
For in this instance the inequality
|f(s) −f(t)| ≤M · |s −t|α
leads to

f(s) −f(t)
s −t
 ≤M · |s −t|α−1 .
Because α −1 > 0, letting s →t yields that f ′(t) exists for every t ∈I and
equals 0. It follows from Corollary 6.13 of the last section that f is constant on
I.
Instead of trying to extend the deﬁnition of Lipα(I) to α > 1 it is customary
to deﬁne classes of functions Ck,α, for k = 0, 1, . . . and 0 < α ≤1, by the
condition that f be of class Ck on I and that f (k) be an element of Lipα(I).
We leave it as an exercise for you to verify that Ck,α ⊆Cℓ,β if either k > ℓor
both k = ℓand α ≥β.
In more advanced studies in analysis, it is appropriate to replace Lip1(I),
and more generally Ck,1, with another space (invented by Antoni Zygmund,
1900–1992) deﬁned in a more subtle fashion using second diﬀerences as in Ex-
ample 6.18. These matters exceed the scope of this book, but we shall make a
few remarks about them in the exercises.
Exercises
1. Suppose that f is a C2 function on R and if |f ′′(x)| ≤C for all x. Prove
that

f(x + h) + f(x −h) −2f(x)
h2
 ≤C .
*
2. In which class Ck,α is the function x · ln |x| on the interval [−1/2, 1/2]?
How about the function x/ ln |x|?

EXERCISES
131
*
3. Give an example of a function on R such that

f(x + h) + f(x −h) −2f(x)
h
 ≤C
for all x and all h ̸= 0 but f is not in Lip1(R). (Hint: See Exercise 2.)
4. Fix a positive integer k. Give an example of two functions f and g neither
of which is in Ck but such that f · g ∈Ck.
5. Fix a positive integer ℓand deﬁne f(x) = |x|ℓ. In which class Ck does f
lie? In which class Ck,α does it lie?
6. Let f be a diﬀerentiable function on an open interval I. Prove that f ′ is
continuous if and only if the inverse image under f ′ of any point is the
intersection of I with a closed set.
7. In the text we give suﬃcient conditions for the inclusion Ck,α ⊆Cℓ,β.
Show that the inclusion is strict if either k > ℓor k = ℓand α > β.
8. Suppose that f is a diﬀerentiable function on an interval I and that f ′(x)
is never zero. Prove that f is invertible. Then prove that f −1 is diﬀeren-
tiable. Finally, use the Chain Rule on the identity f
 f −1
= x to derive
a formula for
 f −1′.
9. Suppose that a function f on the interval (0, 1) has left derivative equal
to zero at every point. What conclusion can you draw?
10. We know that the ﬁrst derivative can be characterized by the Newton
quotient. Find an analogous characterization of second derivatives. What
about third derivatives?
*
11. We know that a continuous function on the interval [0, 1] can be uniformly
approximated by polynomials. But if the function f is continuously dif-
ferentiable on [0, 1] then we can actually say something about the rate of
approximation. That is, if ǫ > 0 then f can be approximated uniformly
within ǫ by a polynomial of degree not greater than N = N(ǫ). Calculate
N(ǫ).


Chapter 7
The Integral
7.1
Partitions and the Concept of Integral
We learn in calculus that it is often useful to think of an integral as representing
area. However, this is but one of many important applications of integration
theory. The integral is a generalization of the summation process. That is the
point of view that we shall take in the present chapter.
Deﬁnition 7.1 Let [a, b] be a closed interval in R.
A ﬁnite, ordered set of
points P = {x0, x1, x2, . . . , xk−1, xk} such that
a = x0 ≤x1 ≤x2 ≤· · · ≤xk−1 ≤xk = b
is called a partition of [a, b]. Refer to Figure 7.1.
If P is a partition of [a, b], then we let Ij denote the interval [xj−1, xj],
j = 1, 2, . . . , k.
The symbol ∆j denotes the length of Ij.
The mesh of P,
denoted by m(P), is deﬁned to be max ∆j.
The points of a partition need not be equally spaced, nor must they be distinct
from each other.
Example 7.2 The set P = {0, 1, 1, 9/8, 2, 5, 21/4, 23/4, 6} is a partition of the
interval [0, 6] with mesh 3 (because I5 = [2, 5], with length 3, is the longest
interval in the partition). See Figure 7.2.
Figure 7.1: A partition.
133

134
CHAPTER 7. THE INTEGRAL
0
1
9/8
2
5
21/4
23/4
6
Figure 7.2: The partition in Example 7.2.
Deﬁnition 7.3 Let [a, b] be an interval and let f be a function with domain
[a, b]. If P = {x0, x1, x2, . . . , xk−1, xk} is a partition of [a, b] and if, for each j,
sj is an element of Ij, then the corresponding Riemann sum is deﬁned to be
R(f, P) =
k
X
j=1
f(sj)∆j .
Example 7.4 Let f(x) = x2 −x and [a, b] = [1, 4]. Deﬁne the partition P =
{1, 3/2, 2, 7/3, 4} of this interval. Then a Riemann sum for this f and P is
R(f, P) =
 12 −1

· 1
2 +
 (7/4)2 −(7/4)

· 1
2
+
 (7/3)2 −(7/3)

· 1
3 +
 32 −3

· 5
3
= 10103
864 .
Notice that we have complete latitude in choosing each point sj from the cor-
responding interval Ij. While at ﬁrst confusing, we will ﬁnd this freedom to be
a powerful tool when proving results about the integral.
The ﬁrst main step in the theory of the Riemann integral is to determine
a method for “calculating the limit of the Riemann sums” of a function as the
mesh of the partitions tends to zero. There are in fact several methods for doing
so. We have chosen the simplest one.
Deﬁnition 7.5 Let [a, b] be an interval and f a function with domain [a, b].
We say that the Riemann sums of f tend to a limit ℓas m(P) tends to 0 if,
for any ǫ > 0, there is a δ > 0 such that, if P is any partition of [a, b] with
m(P) < δ, then |R(f, P) −ℓ| < ǫ for every choice of sj ∈Ij.
It will turn out to be critical for the success of this deﬁnition that we
require that every partition of mesh smaller than δ satisfy the conclusion of the
deﬁnition. The theory does not work eﬀectively if for every ǫ > 0 there is a
δ > 0 and some partition P of mesh less than δ which satisﬁes the conclusion
of the deﬁnition.
Deﬁnition 7.6 A function f on a closed interval [a, b] is said to be Riemann
integrable on [a, b] if the Riemann sums of R(f, P) tend to a ﬁnite limit ℓas
m(P) tends to zero.

7.1. PARTITIONS AND THE CONCEPT OF INTEGRAL
135
The value ℓof the limit, when it exists, is called the Riemann integral of f
over [a, b] and is denoted by
Z b
a
f(x) dx .
Remark 7.7 We mention now a useful fact that will be formalized in later
sections. Suppose that f is Riemann integrable on [a, b] with the value of the
integral being ℓ. Let ǫ > 0. Then, as stated in the deﬁnition (with ǫ/2 replacing
ǫ), there is a δ > 0 such that, if Q is a partition of [a, b] of mesh smaller than δ,
then |R(f, Q) −ℓ| < ǫ/2. It follows that, if P and P′ are partitions of [a, b] of
mesh smaller than δ, then
|R(f, P) −R(f, P′)| ≤|R(f, P) −ℓ| + |ℓ−R(f, P′)| < ǫ
2 + ǫ
2 = ǫ .
Note, however, that we may choose P′ to equal the partition P. Also we
may for each j choose the points sj, where f is evaluated for the Riemann sum
over P, to be a point where f very nearly assumes its supremum on Ij. Likewise
we may for each j choose the points s′
j, where f is evaluated for the Riemann
sum over P′, to be a point where f very nearly assumes its inﬁmum on Ij. It
easily follows that when the mesh of P is less than δ then
X
j
 
sup
Ij
f −inf
Ij f
!
∆j ≤ǫ .
(7.7.1)
This consequence of integrability will prove useful to us in some of the discus-
sions in this and the next section. In the exercises we shall consider in detail
the assertion that integrability implies (7.7.1) and the converse as well.
Deﬁnition 7.8 If P, P′ are partitions of [a, b] then their common reﬁnement is
the union of all the points of P and P′. See Figure 7.3.
We record now a technical lemma that will be used in several of the proofs
that follow:
Lemma 7.9 Let f be a function with domain the closed interval [a, b]. The
Riemann integral
Z b
a
f(x) dx
exists if and only if, for every ǫ > 0, there is a δ > 0 such that, if P and P′ are
partitions of [a, b] with m(P) < δ and m(P′) < δ, then their common reﬁnement
Q has the property that
|R(f, P) −R(f, Q)| < ǫ
and
(7.9.1)
|R(f, P′) −R(f, Q)| < ǫ .

136
CHAPTER 7. THE INTEGRAL
P
P
partition
partition
‘
Common refinement of      and
P
P
a
b
a
a
b
b
‘
Figure 7.3: The common reﬁnement.
Proof: If f is Riemann integrable then the assertion of the lemma follows
immediately from the deﬁnition of the integral.
For the converse note that (7.9.1) certainly implies that, if ǫ > 0, then there
is a δ > 0 such that, if P and P′ are partitions of [a, b] with m(P) < δ and
m(P′) < δ, then
|R(f, P) −R(f, P′)| < ǫ
(7.9.2)
(just use the triangle inequality).
Now, for each ǫj = 2−j, j = 1, 2, . . ., we can choose a δj > 0 as in (7.9.2).
Let Sj be the closure of the set
{R(f, P) : m(P) < δj} .
By the choice of δj, the set Sj is contained in a closed interval of length not
greater than 2ǫj.
On the one hand,
\
j
Sj
must be nonempty since it is the decreasing intersection of compact sets. On the
other hand, the length estimate implies that the intersection must be contained
in a closed interval of length 0—that is, the intersection is a point. That point
is then the limit of the Riemann sums, that is, it is the value of the Riemann
integral.
The most important, and perhaps the simplest, fact about the Riemann
integral is that a large class of familiar functions is Riemann integrable.
Theorem 7.10 Let f be a continuous function on a nontrivial closed, bounded
interval I = [a, b]. Then f is Riemann integrable on [a, b].

7.1. PARTITIONS AND THE CONCEPT OF INTEGRAL
137
Proof: We use the lemma. Given ǫ > 0, choose (by the uniform continuity of
f on I—Theorem 5.27) a δ > 0 such that, whenever |s −t| < δ then
|f(s) −f(t)| <
ǫ
b −a .
(7.10.1)
Let P and P′ be any two partitions of [a, b] of mesh smaller than δ. Let Q be
the common reﬁnement of P and P′.
Now we let Ij denote the intervals arising in the partition P (and having
length ∆j) and eIℓthe intervals arising in the partition Q (and having length e∆ℓ).
Since the partition Q contains every point of P, plus some additional points as
well, every eIℓis contained in some Ij. Fix j and consider the expression

f(sj)∆j −
X
eIℓ⊆Ij
f(tℓ)e∆ℓ

.
(7.10.2)
We write
∆j =
X
eIℓ⊆Ij
e∆ℓ.
This equality enables us to rearrange (7.10.2) as

f(sj) ·
X
eIℓ⊆Ij
e∆ℓ−
X
eIℓ⊆Ij
f(tℓ)e∆ℓ

=

X
eIℓ⊆Ij
[f(sj) −f(tℓ)]e∆ℓ

≤
X
eIℓ⊆Ij
|f(sj) −f(tℓ)|e∆ℓ.
But each of the points tℓis in the interval Ij, as is sj. So they diﬀer by less
than δ. Therefore, by (7.10.1), the last expression is less than
X
eIℓ⊆Ij
ǫ
b −a
e∆ℓ
=
ǫ
b −a
X
eIℓ⊆Ij
e∆ℓ
=
ǫ
b −a · ∆j.

138
CHAPTER 7. THE INTEGRAL
Now we conclude the argument by writing
|R(f, P) −R(f, Q)|
=

X
j
f(sj)∆j −
X
ℓ
f(tℓ)e∆ℓ

≤
X
j

f(sj)∆j −
X
eIℓ⊆Ij
f(tℓ)e∆ℓ

<
X
j
ǫ
b −a · ∆j
=
ǫ
b −a ·
X
j
∆j
=
ǫ
b −a · (b −a)
=
ǫ.
The estimate for |R(f, P′) −R(f, Q)| is identical and we omit it. The result
now follows from Lemma 7.9.
In the exercises we will ask you to extend the theorem to the case of functions
f on [a, b] that are bounded and have ﬁnitely many, or even countably many,
discontinuities.
We conclude this section by noting an important fact about Riemann in-
tegrable functions. A Riemann integrable function on an interval [a, b] must be
bounded. If it were not, then one could choose the points sj in the construction
of R(f, P) so that f(sj) is arbitrarily large, and the Riemann sums would be-
come arbitrarily large, hence cannot converge. You will be asked in the exercises
to work out the details of this assertion.
Exercises
1. If f is a Riemann integrable function on [a, b] then show that f must be
a bounded function.
2. Deﬁne the Dirichlet function to be
f(x) =
 1
if
x is rational
0
if
x is irrational
Prove that the Dirichlet function is not Riemann integrable on the interval
[a, b].
3. Prove that the Dirichlet function (see Exercise 2) is the pointwise limit of
Riemann integrable functions.

EXERCISES
139
4. Deﬁne
g(x) =
 x · sin(1/x)
if
x ̸= 0
0
if
x = 0
Is g Riemann integrable on the interval [−1, 1]?
5. Provide the details of the assertion that, if f is Riemann integrable on the
interval [a, b] then, for any ǫ > 0, there is a δ > 0 such that, if P is a
partition of mesh less than δ, then
X
j
 
sup
Ij
f −inf
Ij f
!
∆j < ǫ .
[Hint: Follow the scheme presented in Remark 7.7. Given ǫ > 0, choose
δ > 0 as in the deﬁnition of the integral. Fix a partition P with mesh
smaller than δ. Let K + 1 be the number of points in P. Choose points
tj ∈Ij so that |f(tj) −supIj f| < ǫ/(2(K + 1)); also choose points t′
j ∈Ij
so that |f(t′
j) −infIj f| < ǫ/(2(K + 1)). By applying the deﬁnition of the
integral to this choice of tj and t′
j we ﬁnd that
X
j
 
sup
Ij
f −inf
Ij f
!
∆j < 2ǫ .
The result follows.]
6. To what extent is the following statement true? If f is Riemann integrable
on [a, b] then 1/f is Riemann integrable on [a, b].
7. Prove the converse of the statement in Exercise 5. [Hint: Note that any
Riemann sum over a suﬃciently ﬁne partition P is trapped between the
sum in which the inﬁmum is always chosen and the sum in which the
supremum is always chosen.]
8. Give an example of a function f such that f 2 is Riemann integrable but
f is not.
9. Show that any Riemann integrable function is the pointwise limit of con-
tinuous functions.
10. If f is Riemann integrable on the interval [a, b] and if µ : [α, β] →[a, b] is
continuously diﬀerentiable then prove that f ◦µ is Riemann integrable on
[α, β].
*
11. Give an example to show that the composition of Riemann integrable
functions need not be Riemann integrable.
12. Prove that, if f is continuous on the interval [a, b] except at ﬁnitely many
points and is bounded, then f is Riemann integrable on [a, b].
13. Do Exercise 12 with the phrase “ﬁnitely many” replaced by “countably
many.”

140
CHAPTER 7. THE INTEGRAL
7.2
Properties of the Riemann Integral
We begin this section with a few elementary properties of the integral that
reﬂect its linear nature.
Theorem 7.11 Let [a, b] be a nonempty interval, let f and g be Riemann
integrable functions on the interval, and let α be a real number. Then f ± g
and α · f are integrable and we have
(a)
R b
a f(x) ± g(x) dx =
R b
a f(x) dx ±
R b
a g(x) dx;
(b)
R b
a α · f(x) dx = α ·
R b
a f(x) dx.
Proof: For (a), let
A =
Z b
a
f(x) dx
and
B =
Z b
a
g(x) dx .
Let ǫ > 0. Choose a δ1 > 0 such that if P is a partition of [a, b] with mesh less
than δ1 then
|R(f, P) −A| < ǫ
2 .
Similarly choose a δ2 > 0 such that if P is a partition of [a, b] with mesh less
than δ2 then
|R(f, P) −B| < ǫ
2 .
Let δ = min{δ1, δ2}. If P′ is any partition of [a, b] with m(P′) < δ then
|R(f ± g, P′) −(A ± B)|
=
|R(f, P′) ± R(g, P′) −(A ± B)|
≤
|R(f, P′) −A| + |R(g, P′) −B|
<
ǫ
2 + ǫ
2
=
ǫ.
This means that the integral of f ± g exists and equals A ± B, as we were
required to prove.
The proof of (b) follows similar lines but is much easier and we leave it as
an exercise for you.
Theorem 7.12 If c is a point of the interval [a, b] and if f is Riemann integrable
on both [a, c] and [c, b] then f is integrable on [a, b] and
R c
a f(x) dx+
R b
c f(x) dx =
R b
a f(x) dx.

7.2. PROPERTIES OF THE RIEMANN INTEGRAL
141
Proof: Let us write
A =
Z c
a
f(x) dx
and
B =
Z b
c
f(x) dx .
Now pick ǫ > 0. There is a δ1 > 0 such that if P is a partition of [a, c] with
mesh less than δ1 then
|R(f, P) −A| < ǫ
3 .
Similarly, choose δ2 > 0 such that if P′ is a partition of [c, b] with mesh less
than δ2 then
|R(f, P′) −B| < ǫ
3 .
Let M be an upper bound for |f| (recall, from the remark at the end of
Section 1, that a Riemann integrable function must be bounded).
Set δ =
min{δ1, δ2, ǫ/(6M)}. Now let V = {v1, . . . , vk} be any partition of [a, b] with
mesh less than δ. There is a last point vn which is in [a, c] and a ﬁrst point
vn+1 in [c, b]. Observe that P = {v0, . . . , vn, c} is a partition of [a, c] with mesh
smaller than δ1 and P′ = {c, vn+1, . . . , vk} is a partition of [c, b] with mesh
smaller than δ2. Let us rename the elements of P as {p0, . . . , pn+1} and the
elements of P′ as {p
′
0, · · · p
′
k−n+1}. Notice that pn+1 = p
′
0 = c. For each j let sj
be a point chosen in the interval Ij = [vj−1, vj] from the partition V.
Then we have
R(f, V) −

A + B

=

 n
X
j=1
f(sj)∆j −A

+ f(sn+1)∆n+1 +

k
X
j=n+2
f(sj)∆j −B

=

 n
X
j=1
f(sj)∆j + f(c) · (c −vn) −A

+

f(c) · (vn+1 −c) +
k
X
j=n+2
f(sj)∆j −B

+

f(sn+1) −f(c)

· (c −vn) +

f(sn+1) −f(c)

· (vn+1 −c)

≤

 n
X
j=1
f(sj)∆j + f(c) · (c −vn) −A

+


f(c) · (vn+1 −c) +
k
X
j=n+2
f(sj)∆j −B

+
(f(sn+1) −f(c)) · (vn+1 −vn)


142
CHAPTER 7. THE INTEGRAL
=
R(f, P) −A
 +
R(f, P′) −B

+
(f(sn+1) −f(c)) · (vn+1 −vn)

<
ǫ
3 + ǫ
3 + 2M · δ
≤
ǫ
by the choice of δ.
This shows that f is integrable on the entire interval [a, b] and the value of
the integral is
A + B =
Z c
a
f(x) dx +
Z b
c
f(x) dx .
Remark 7.13 The last proof illustrates why it is useful to be able to choose
the sj ∈Ij arbitrarily.
Remark 7.14 If we adopt the convention that
Z a
b
f(x) dx = −
Z b
a
f(x) dx
(which is consistent with the way that the integral was deﬁned in the ﬁrst place),
then Theorem 7.12 is true even when c is not an element of [a, b]. For instance,
suppose that c < a < b. Then, by Theorem 7.12,
Z a
c
f(x) dx +
Z b
a
f(x) dx =
Z b
c
f(x) dx .
But this may be rearranged to read
Z b
a
f(x) dx = −
Z a
c
f(x) dx +
Z b
c
f(x) dx =
Z c
a
f(x) dx +
Z b
c
f(x) dx .
One of the basic tools of analysis is to perform estimates. Thus we require
certain fundamental inequalities about integrals. These are recorded in the next
theorem.
Theorem 7.15 Let f and g be integrable functions on a nonempty interval
[a, b]. Then
(i)

Z b
a
f(x) dx
 ≤
Z b
a
|f(x)| dx;
(ii) If f(x) ≤g(x) for all x ∈[a, b] then
Z b
a
f(x) dx ≤
Z b
a
g(x) dx.

7.2. PROPERTIES OF THE RIEMANN INTEGRAL
143
Proof: If P is any partition of [a, b] then
|R(f, P)| ≤R(|f|, P) .
The ﬁrst assertion follows.
Next, for part (ii),
R(f, P) ≤R(g, P) .
This inequality implies the second assertion.
Another fundamental operation in the theory of the integral is “change of
variable” (sometimes called the “u-substitution” in calculus books). We next
turn to a careful formulation and proof of this operation. First we need a lemma:
Lemma 7.16 If f is a Riemann integrable function on [a, b] and if φ is a con-
tinuous function on a compact interval that contains the range of f then φ ◦f
is Riemann integrable.
Proof: Let ǫ > 0. Since φ is a continuous function on a compact set, it is
uniformly continuous (Theorem 5.27). Let δ > 0 be selected such that (i) δ < ǫ
and (ii) if |x −y| < δ then |φ(x) −φ(y)| < ǫ.
Now the hypothesis that f is Riemann integrable implies that there exists
a eδ > 0 such that if P and P′ are partitions of [a, b] and m(P), m(P′) < eδ then,
for the common reﬁnement Q of P and P′, it holds that
|R(f, P) −R(f, Q)| < δ2
and
R(f, eP) −R(f, Q)
 < δ2 .
Fix such a P, P′ and Q. Let Jℓbe the intervals of Q and Ij the intervals of P.
Each Jℓis contained in some Ij(ℓ). We write
R(φ ◦f, P) −R(φ ◦f, Q)

=

X
j
φ ◦f(tj)∆j −
X
ℓ
φ ◦f(sℓ)∆ℓ

=

X
j
X
Jℓ⊆Ij
φ ◦f(tj)∆ℓ−
X
j
X
Jℓ⊆Ij
φ ◦f(sℓ)∆ℓ

=

X
j
X
Jℓ⊆Ij

φ ◦f(tj) −φ ◦f(sℓ)

∆ℓ

≤

X
j
X
Jℓ⊆Ij,ℓ∈G

φ ◦f(tj) −φ ◦f(sℓ)

∆ℓ

+

X
j
X
Jℓ⊆Ij,ℓ∈B

φ ◦f(tj) −φ ◦f(sℓ)

∆ℓ
 ,

144
CHAPTER 7. THE INTEGRAL
where we put ℓin G if Jℓ⊆Ij(ℓ) and 0 ≤

supIj(ℓ) f −infIj(ℓ) f

< δ; otherwise
we put ℓinto B. Notice that
X
ℓ∈B
δ∆ℓ
≤
X
ℓ∈B

sup
Ij(ℓ)
f −inf
Ij(ℓ) f

· ∆ℓ
=
k
X
j=1
X
Jℓ⊆Ij

sup
Ij
f −inf
Ij f

· ∆ℓ
=
k
X
j=1

sup
Ij
f −inf
Ij f

∆j
<
δ2
by the choice of eδ (and Remark 7.7). Therefore
X
ℓ∈B
∆ℓ< δ .
Let M be an upper bound for |φ| (Theorem 5.22). Then

X
j
X
Jℓ⊆Ij,ℓ∈B

φ ◦f(tj) −φ ◦f(sℓ)

∆ℓ

≤

X
j
X
Jℓ⊆Ij,ℓ∈B

2 · M

∆ℓ

≤
2 · δ · M
<
2Mǫ.
Also

X
j
X
Jℓ⊆Ij,ℓ∈G
(φ ◦f(tj) −φ ◦f(sℓ)) ∆ℓ

≤

X
j
X
Jℓ⊆Ij,ℓ∈G
ǫ∆ℓ

since, for ℓ∈G, we know that |f(α) −f(β)| < δ for any α, β ∈Ij(ℓ). However,
the last line does not exceed (b −a) · ǫ. Putting together our estimates, we ﬁnd
that
|R(φ ◦f, P) −R(φ ◦f, Q)| < ǫ · (2M + (b −a)) .
By symmetry, an analogous inequality holds for P′. By Lemma 7.9, this is what
we needed to prove.
An easier result is that if f is Riemann integrable on an interval [a, b] and if
µ : [α, β] →[a, b] is continuously diﬀerentiable, then f ◦µ is Riemann integrable.
Corollary 7.17 If f and g are Riemann integrable on [a, b], then so is the
function f · g.
Proof: By Theorem 7.11, f + g is integrable.
By the lemma, (f + g)2 =
f 2 + 2f · g + g2 is integrable. But the lemma also implies that f 2 and g2 are

7.2. PROPERTIES OF THE RIEMANN INTEGRAL
145
integrable (here we use the function φ(x) = x2). It results, by subtraction, that
2 · f · g is integrable. Hence f · g is integrable.
Theorem 7.18 Let f be an integrable function on an interval [a, b] of positive
length. Let ψ be a continuously diﬀerentiable function from another interval
[α, β] of positive length into [a, b]. Assume that ψ is increasing, one-to-one, and
onto. Then
Z b
a
f(x) dx =
Z β
α
f(ψ(x)) · ψ′(x) dx .
Proof: Since f is integrable, its absolute value is bounded by some number M.
Fix ǫ > 0. Since ψ′ is continuous on the compact interval [α, β], it is uniformly
continuous (Theorem 5.27). Hence we may choose δ > 0 so small that if |s−t| <
δ then |ψ′(s) −ψ′(t)| < ǫ/ (M · (β −α)). If P = {p0, . . . , pk} is any partition of
[a, b] then there is an associated partition eP = {ψ−1(p0), . . . , ψ−1(pk)} of [α, β].
For simplicity denote the points of eP by epj. Let us choose the partition P so
ﬁne that the mesh of eP is less than δ. If tj are points of Ij = [pj−1, pj] then
there are corresponding points sj = ψ−1(tj) of eIj = [epj−1, epj]. Then we have
k
X
j=1
f(tj)∆j
=
k
X
j=1
f(tj)(pj −pj−1)
=
k
X
j=1
f(ψ(sj))(ψ(epj) −ψ(epj−1)
=
k
X
j=1
f(ψ(sj))ψ′(uj)(epj −epj−1),
where we have used the Mean Value Theorem in the last line to ﬁnd each uj.
Our problem at this point is that f ◦ψ and ψ′ are evaluated at diﬀerent points.
So we must do some estimation to correct that problem.
The last displayed line equals
k
X
j=1
f(ψ(sj))ψ′(sj)(epj −epj−1) +
k
X
j=1
f(ψ(sj)) (ψ′(uj) −ψ′(sj)) (epj −epj−1) .
The ﬁrst sum is a Riemann sum for f(ψ(x) · ψ′(x) and the second sum is an
error term. Since the points uj and sj are elements of the same interval eIj of
length less than δ, we conclude that |ψ′(uj) −ψ′(sj)| < ǫ/(M · |β −α|). Thus
the error term in absolute value does not exceed
k
X
j=1
M ·
ǫ
M · |β −α| · (epj −epj−1) =
ǫ
β −α
k
X
j=0
(epj −epj−1) = ǫ .

146
CHAPTER 7. THE INTEGRAL
This shows that every Riemann sum for f on [a, b] with suﬃciently small mesh
corresponds to a Riemann sum for f(ψ(x)) · ψ′(x) on [α, β] plus an error term
of size less than ǫ. A similar argument shows that every Riemann sum for
f(ψ(x)) · ψ′(x) on [α, β] with suﬃciently small mesh corresponds to a Riemann
sum for f on [a, b] plus an error term of magnitude less than ǫ. The conclusion is
then that the integral of f on [a, b] (which exists by hypothesis) and the integral
of f(ψ(x))·ψ′(x) on [α, β] (which exists by the corollary to the lemma) agree.
We conclude this section with the very important
Theorem 7.19 (The Fundamental Theorem of Calculus) Let f be an in-
tegrable function on the interval [a, b]. For x ∈[a, b] we deﬁne
F(x) =
Z x
a
f(s) ds .
If f is continuous at x ∈(a, b) then
F ′(x) = f(x) .
Proof: Fix x ∈(a, b).
Let ǫ > 0.
Choose, by the continuity of f at x, a
δ > 0 such that |s −x| < δ implies |f(s) −f(x)| < ǫ. We may assume that
δ < min{x −a, b −x}. If |t −x| < δ then

F(t) −F(x)
t −x
−f(x)

=

R t
a f(s) ds −
R x
a f(s) ds
t −x
−f(x)

=

R t
x f(s) ds
t −x
−
R t
x f(x) ds
t −x

=

R t
x (f(s) −f(x)) ds
t −x
 .
Notice that we rewrote f(x) as the integral with respect to a dummy variable
s over an interval of length |t −x| divided by (t −x). Assume for the moment
that t > x. Then the last line is dominated by
R t
x |f(s) −f(x)| ds
t −x
≤
R t
x ǫ ds
t −x
=
ǫ.
A similar estimate holds when t < x (simply reverse the limits of integration).
This shows that
lim
t→x
F(t) −F(x)
t −x
exists and equals f(x). Thus F ′(x) exists and equals f(x).
In the exercises we shall consider how to use the theory of one-sided limits
to make the conclusion of the Fundamental Theorem true on the entire interval
[a, b]. We conclude with

EXERCISES
147
Corollary 7.20 If f is a continuous function on [a, b] and if G is any continu-
ously diﬀerentiable function on [a, b] whose derivative equals f on (a, b) then
Z b
a
f(x) dx = G(b) −G(a) .
Proof: Deﬁne F as in the theorem. Since F and G have the same derivative
on (a, b), they diﬀer by a constant (Corollary 6.13). Then
Z b
a
f(x) dx = F(b) = F(b) −F(a) = G(b) −G(a)
as desired.
Exercises
1. Imitate the proof of the Fundamental Theorem of Calculus in this section
to show that, if f is continuous on [a, b] and if we deﬁne
F(x) =
Z x
a
f(t) dt ,
then the one-sided derivative F ′(a) exists and equals f(a) in the sense
that
lim
t→a+
F(t) −F(a)
t −a
= f(a) .
Formulate and prove an analogous statement for the one-sided derivative
of F at b.
2. Let f be a bounded function on an unbounded interval of the form [A, ∞).
We say that f is integrable on [A, ∞) if f is integrable on every compact
subinterval of [A, ∞) and
lim
B→+∞
Z B
A
f(x) dx
exists and is ﬁnite.
Assume that f is Riemann integrable on [1, N] for every N > 1 and that
f is decreasing. Show that f is Riemann integrable on [1, ∞) if and only
if P∞
j=1 f(j) is ﬁnite.
Suppose that g is nonnegative and integrable on [1, ∞). If 0 ≤|f(x)| ≤
g(x) for x ∈[1, ∞) and f is integrable on compact subintervals of [1, ∞),
then prove that f is integrable on [1, ∞).

148
CHAPTER 7. THE INTEGRAL
3. Let f be a function on an interval of the form (a, b] such that f is integrable
on compact subintervals of (a, b]. If
lim
ǫ→0+
Z b
a+ǫ
f(x) dx
exists and is ﬁnite then we say that f is integrable on (a, b]. Prove that,
if we restrict attention to bounded f, then in fact this deﬁnition gives rise
to no new integrable functions. However, there are unbounded functions
that can now be integrated. Give an example.
Give an example of a function g that is integrable by the deﬁnition in the
preceding paragraph but is such that |g| is not integrable.
4. Suppose that f is a continuous, nonnegative function on the interval [0, 1].
Let M be the maximum of f on the interval. Prove that
lim
n→∞
Z 1
0
f(t)n dt
1/n
= M .
5. Let f be a continuously diﬀerentiable function on the interval [0, 2π]. Fur-
ther assume that f(0) = f(2π) and f ′(0) = f ′(2π). For n ∈N deﬁne
bf(n) = 1
2π
Z 2π
0
f(x) sin nx dx .
Prove that
∞
X
n=1
| bf(n)|2
converges. [Hint: Use integration by parts to obtain a favorable estimate
on | bf(n)|.]
*
6. Prove that
lim
η→0+
Z 1/η
η
cos(2r) −cos r
r
dr
exists.
7. Let f1, f2, . . . be Riemann integrable functions on [0, 1].
Suppose that
f1(x) ≥f2(x) ≥· · · for every x and that limj→∞fj(x) ≡f(x) exists and
is ﬁnite for every x. Is it the case that f is Riemann integrable?
*
8. Suppose that f is a Riemann integrable function on the interval [0, 1]. Let
ǫ > 0. Show that there is a polynomial p so that
Z 1
0
|f(x) −p(x)| dx < ǫ .
9. Prove part (b) of Theorem 7.11.

7.3. ANOTHER LOOK AT THE INTEGRAL
149
7.3
Another Look at the Integral
For many purposes, such as integration by parts, it is natural to formulate the
integral in a more general context than we have considered in the ﬁrst two
sections. Our new formulation is called the Riemann-Stieltjes integral and is
described below.
Fix an interval [a, b] and a monotonically increasing function α on [a, b]. If
P = {p0, p1, . . . , pk} is a partition of [a, b], then let ∆αj = α(pj) −α(pj−1). Let
f be a bounded function on [a, b] and deﬁne the upper Riemann sum of f with
respect to α and the lower Riemann sum of f with respect to α as follows:
U(f, P, α) =
k
X
j=1
Mj∆αj
and
L(f, P, α) =
k
X
j=1
mj∆αj .
Here the notation Mj denotes the supremum of f on the interval Ij = [pj−1, pj]
and mj denotes the inﬁmum of f on Ij.
In the special case α(x) = x the Riemann sums discussed here have a form
similar to the Riemann sums considered in the ﬁrst two sections. Moreover,
L(f, P, α) ≤R(f, P) ≤U(f, P, α) .
We deﬁne
I∗(f) = inf U(f, P, α)
and
I∗(f) = sup L(f, P, α) .
Here the supremum and inﬁmum are taken with respect to all partitions of the
interval [a, b]. These are, respectively, the upper and lower integrals of f with
respect to α on [a, b].
By deﬁnition it is always true that, for any partition P,
L(f, P, α) ≤I∗(f) ≤I∗(f) ≤U(f, P, α) .
It is natural to declare the integral to exist when the upper and lower integrals
agree:
Deﬁnition 7.21 Let α be an increasing function on the interval [a, b] and let
f be a bounded function on [a, b]. We say that the Riemann-Stieltjes integral
of f with respect to α exists if
I∗(f) = I∗(f) .
When the integral exists we denote it by
Z b
a
f dα .

150
CHAPTER 7. THE INTEGRAL
Notice that the deﬁnition of Riemann-Stieltjes integral is diﬀerent from the
deﬁnition of Riemann integral that we used in the preceding sections. It turns
out that, when α(x) = x, the two deﬁnitions are equivalent (this assertion is
explored in the exercises). In the present generality it is easier to deal with
upper and lower integrals in order to determine the existence of integrals.
Deﬁnition 7.22 Let P and Q be partitions of the interval [a, b]. If each point
of P is also an element of Q then we call Q a reﬁnement of P.
Notice that the reﬁnement Q is obtained by adding points to P. The mesh
of Q will be less than or equal to that of P. The following lemma enables us to
deal eﬀectively with our new language.
Lemma 7.23 Let P be a partition of the interval [a, b] and f a function on
[a, b]. Fix an increasing function α on [a, b]. If Q is a reﬁnement of P then
U(f, Q, α) ≤U(f, P, α)
and
L(f, Q, α) ≥L(f, P, α) .
Proof: Since Q is a reﬁnement of P it holds that any interval Iℓarising from Q
is contained in some interval Jj(ℓ) arising from P. Let MIℓbe the supremum of
f on Iℓand MJj(ℓ) the supremum of f on the interval Jj(ℓ). Then MIℓ≤MJj(ℓ).
We conclude that
U(f, Q, α) =
X
ℓ
MIℓ∆αℓ≤
X
ℓ
MJj(ℓ)∆αℓ.
We rewrite the righthand side as
X
j
MJj

X
Iℓ⊆Jj
∆αℓ

.
However, because α is monotone, the inner sum simply equals α(pj)−α(pj−1) =
∆αj. Thus the last expression is equal to U(f, P, α), as desired.
A similar argument applies to the lower sums.
Example 7.24 Let [a, b] = [0, 10] and let α(x) be the greatest integer function.1
That is, α(x) is the greatest integer that does not exceed x. So, for example,
α(0.5) = 0, α(2) = 2, and α(−3/2) = −2. Certainly α is an increasing function
on [0, 10]. Let f be any continuous function on [0, 10]. We shall determine
whether
Z 10
0
f dα
1In many texts the greatest integer in x is denoted by [x]. We do not use that notation
because it could get confused with our notation for a closed interval.

7.3. ANOTHER LOOK AT THE INTEGRAL
151
exists and, if it does, calculate its value.
Let P be a partition of [0, 10]. By the lemma, it is to our advantage to as-
sume that the mesh of P is smaller than 1. Observe that ∆αj equals the number
of integers that lie in the interval Ij—that is, either 0 or 1. Let Ij0, Ij2, . . . Ij10
be, in sequence, the intervals from the partition which do in fact contain each
distinct integer (the ﬁrst of these contains 0, the second contains 1, and so on
up to 10). Then
U(f, P, α) =
10
X
ℓ=0
Mjℓ∆αjℓ=
10
X
ℓ=1
Mjℓ
and
L(f, P, α) =
10
X
ℓ=0
mjℓ∆αjℓ=
10
X
ℓ=1
mjℓ
because any term in these sums corresponding to an interval not containing an
integer must have ∆αj = 0. Notice that ∆αj0 = 0 since α(0) = α(p1) = 0.
Let ǫ > 0. Since f is uniformly continuous on [0, 10], we may choose a δ > 0
such that |s −t| < δ implies that |f(s) −f(t)| < ǫ/20. If m(P) < δ then it
follows that |f(ℓ) −Mjℓ| < ǫ/20 and |f(ℓ) −mjℓ| < ǫ/20 for ℓ= 0, 1, . . . 10.
Therefore
U(f, P, α) <
10
X
ℓ=1

f(ℓ) + ǫ
20

and
L(f, P, α) >
10
X
ℓ=1

f(ℓ) −ǫ
20

.
Rearranging the ﬁrst of these inequalities leads to
U(f, P, α) <
 10
X
ℓ=1
f(ℓ)
!
+ ǫ
2
and
L(f, P, α) >
 10
X
ℓ=1
f(ℓ)
!
−ǫ
2 .
Thus, since I∗(f) and I∗(f) are trapped between U and L, we conclude that
|I∗(f) −I∗(f)| < ǫ .
We have seen that, if the partition is ﬁne enough, then the upper and lower
integrals of f with respect to α diﬀer by at most ǫ. It follows that R 10
0
fd α
exists. Moreover,
I∗(f) −
10
X
ℓ=1
f(ℓ)
 < ǫ

152
CHAPTER 7. THE INTEGRAL
and
I∗(f) −
10
X
ℓ=1
f(ℓ)
 < ǫ .
We conclude that
Z 10
0
f dα =
10
X
ℓ=1
f(ℓ) .
The example demonstrates that the language of the Riemann-Stieltjes in-
tegral allows us to think of the integral as a generalization of the summation
process. This is frequently useful, both philosophically and for practical reasons.
The next result, sometimes called Riemann’s lemma, is crucial for proving
the existence of Riemann-Stieltjes integrals.
Proposition 7.25 (Riemann’s Lemma) Let α be an increasing function on
[a, b] and f a bounded function on the interval. The Riemann-Stieltjes integral
of f with respect to α exists if and only if, for every ǫ > 0, there is a partition
P such that
|U(f, P, α) −L(f, P, α)| < ǫ .
(7.25.1)
Proof: First assume that (7.25.1) holds. Fix ǫ > 0. Since L ≤I∗≤I∗≤U,
inequality (7.25.1) implies that
|I∗(f) −I∗(f)| < ǫ .
But this means that R b
a f dα exists.
Conversely, assume that the integral exists. Fix ǫ > 0. Choose a partition
Q1 such that
|U(f, Q1, α) −I∗(f)| < ǫ/2 .
Likewise choose a partition Q2 such that
|L(f, Q2, α) −I∗(f)| < ǫ/2 .
Since I∗(f) = I∗(f) it follows that
|U(f, Q1, α) −L(f, Q2, α)| < ǫ .
(7.25.2)
Let P be the common reﬁnement of Q1 and Q2. Then we have, again by Lemma
7.23, that
L(f, Q2, α) ≤L(f, P, α) ≤
Z b
a
f dα ≤U(f, P, α) ≤U(f, Q1, α) .
But, by (7.25.2), the expressions on the far left and on the far right of these
inequalities diﬀer by less than ǫ. Thus P satiﬁes the condition (7.25.1).
We note in passing that the basic properties of the Riemann integral noted
in Section 2 (Theorems 7.11 and 7.12) hold without change for the Riemann-
Stieltjes integral. The proofs are left as exercises for you (use Riemann’s lemma!).

EXERCISES
153
Exercises
1. Deﬁne α(x) by the condition that α(x) = −x + k when k ≤x < k + 1.
Calculate
Z 6
2
t2 dα(t) .
2. Let α(x) be the greatest integer function as discussed in the text. Deﬁne
the “fractional part” function by the formula α(x) = x −α(x). Explain
why this function has the name “fractional part.” Calculate
Z 5
0
x dα .
3. If
R
f dα =
R
g dα for every choice of α, then what can you conclude about
f and g?
4. If
R
f dα =
R
f dβ for every choice of f, then what can you conclude about
α and β?
5. Give an example of a continuous f and an α for which
R
f dα does not
exist.
6. Let α(x) be the greatest integer function and f(x) = x2.
Calculate
R 3
0 f dα.
7. Let f(x) = α(x) be the greatest integer function. Calculate R 4
0 f dα.
8. Any series can be represented as a Riemann-Stieltjes integral. But the
converse is not true. Explain.
9. State and prove a version of Theorem 7.11 for Riemann-Stieltjex integrals.
10. State and prove a version of Theorem 7.12 for Riemann-Stieltjex integrals.
7.4
Advanced Results on Integration Theory
We now turn to establishing the existence of certain Riemann-Stieltjes integrals.
Theorem 7.26 Let f be continuous on [a, b] and assume that α is monotoni-
cally increasing. Then
Z b
a
f dα
exists.

154
CHAPTER 7. THE INTEGRAL
Proof: We may assume that α is nonconstant; otherwise there is nothing to
prove.
Pick ǫ > 0. By the uniform continuity of f we may choose a δ > 0 such
that if |s −t| < δ then |f(s) −f(t)| < ǫ/(α(b) −α(a)). Let P be any partition
of [a, b] that has mesh smaller than δ. Then
|U(f, P, α) −L(f, P, α)|
=

X
j
Mj∆αj −
X
j
mj∆αj

=
X
j
|Mj −mj| ∆αj
<
X
j
ǫ
α(b) −α(a)∆αj
=
ǫ
α(b) −α(a) ·
X
j
∆αj
=
ǫ .
Here, of course, we have used the monotonicity of α to observe that the last
sum collapses to α(b) −α(a). By Riemann’s lemma, the proof is complete.
Notice how simple Riemann’s lemma is to use. You may ﬁnd it instructive
to compare the proofs of this section with the rather diﬃcult proofs in Section
2. What we are learning is that a good deﬁnition (and accompanying lemma(s))
can, in the end, make everything much clearer and simpler. Now we establish a
companion result to the ﬁrst one.
Theorem 7.27 If α is an increasing and continuous function on the interval
[a, b] and if f is monotonic on [a, b] then
R b
a f dα exists.
Proof: We may assume that α(b) > α(a) and that f is monotone increasing.
Let L = α(b) −α(a) and M = f(b) −f(a). Pick ǫ > 0. Choose k so that
L · M
k
< ǫ .
Let p0 = a and choose p1 to be the ﬁrst point to the right of p0 such that
α(p1)−α(p0) = L/k (this is possible, by the Intermediate Value Theorem, since
α is continuous). Continuing, choose pj to be the ﬁrst point to the right of pj−1
such that α(pj) −α(pj−1) = L/k. This process will terminate after k steps and
we will have pk = b. Then P = {p0, p1, . . . , pk} is a partition of [a, b].
Next observe that, for each j, the value Mj of sup f on Ij is f(pj) since f
is increasing. Similarly the value mj of inf f on Ij is f(pj−1). We ﬁnd therefore

7.4. ADVANCED RESULTS ON INTEGRATION THEORY
155
that
U(f, P, α) −L(f, P, α)
=
k
X
j=1
Mj∆αj −
k
X
j=1
mj∆αj
=
k
X
j=1

(Mj −mj)L
k

=
L
k
k
X
j=1
(f(xj) −f(xj−1))
=
L · M
k
<
ǫ.
Therefore inequality (7.25.1) of Riemann’s lemma is satisﬁed and the integral
exists.
One of the useful features of Riemann-Stieltjes integration is that it puts
integration by parts into a very natural setting. We begin with a lemma.
Lemma 7.28 Let f be continuous on an interval [a, b] and let g be monotone
increasing and continuous on that interval. If G is an antiderivative for g then
Z b
a
f(x)g(x) dx =
Z b
a
f dG .
Proof: Apply the Mean Value Theorem to the Riemann sums for the integral
on the right.
Theorem 7.29 (Integration by Parts) Suppose that both f and g are con-
tinuous, increasing functions on the interval [a, b]. Let F be an antiderivative
for f on [a, b] and G an antiderivative for g on [a, b]. Then we have
Z b
a
F dG = [F(b) · G(b) −F(a) · G(a)] −
Z b
a
G dF .
Proof: Notice that, by the preceding lemma, both integrals exist. Set P(x) =
F(x) · G(x). Then P has a continuous derivative on the interval [a, b]. Thus the
Fundamental Theorem applies and we may write
P(b) −P(a) =
Z b
a
P ′(x) dx = [F(b) · G(b) −F(a) · G(a)] .
Now writing out P ′ explicitly, using Leibnitz’s Rule for the derivative of a prod-
uct, we obtain
Z b
a
F(x)g(x) dx = [F(b)G(b) −F(a)G(a)] −
Z b
a
G(x)f(x) dx .

156
CHAPTER 7. THE INTEGRAL
But the lemma allows us to rewrite this equation as
Z b
a
F dG = [F(b)G(b) −F(a)G(a)] −
Z b
a
G(x) dF .
Remark 7.30 The integration by parts formula can also be proved by applying
summation by parts to the Riemann sums for the integral
Z b
a
f dg .
This method is explored in the exercises.
We have already observed that the Riemann-Stieltjes integral
Z b
a
f dα
is linear in f; that is,
Z b
a
(f + g) dα =
Z b
a
f dα +
Z b
a
g dα
and
Z b
a
c · f dα = c ·
Z b
a
f dα
when both f and g are Riemann-Stieltjes integrable with respect to α and for
any constant c. We also would expect, from the very way that the integral is
constructed, that it would be linear in the α entry. But we have not even deﬁned
the Riemann-Stieltjes integral for nonincreasing α. And what of a function α
that is the diﬀerence of two increasing functions?
Such a function certainly
need not be monotone.
Is it possible to identify which functions α can be
decomposed as sums or diﬀerences of monotonic functions? It turns out that
there is a satisfactory answer to these questions, and we should like to discuss
these matters brieﬂy.
Deﬁnition 7.31 If α is a monotonically decreasing function on [a, b] and f is
a function on [a, b] then we deﬁne
Z b
a
f dα = −
Z b
a
f d(−α)
when the right side exists.
The deﬁnition exploits the simple observation that if α is decreasing then −α
is increasing; hence the preceding theory applies to the function −α.
Next we have

7.4. ADVANCED RESULTS ON INTEGRATION THEORY
157
Deﬁnition 7.32 Let α be a function on [a, b] that can be expressed as
α(x) = α1(x) −α2(x) ,
where both α1 and α2 are increasing. Then for any f on [a, b] we deﬁne
Z b
a
f dα =
Z b
a
f dα1 −
Z b
a
f dα2 ,
provided that both integrals on the right exist.
Now, by the very way that we have formulated our deﬁnitions,
R b
a f dα
is linear in both the f entry and the α entry.
But the deﬁnitions are not
satisfactory unless we can identify those α that can actually occur in the last
deﬁnition. This leads us to a new class of functions.
Deﬁnition 7.33 Let f be a function on the interval [a, b]. For x ∈[a, b] we
deﬁne
Vf(x) = sup
k
X
j=1
|f(pj) −f(pj−1)| ,
where the supremum is taken over all partitions P of the interval [a, x].
If Vf ≡Vf(b) < ∞then the function f is said to be of bounded variation
on the interval [a, b]. In this circumstance the quantity Vf(b) is called the total
variation of f on [a, b].
A function of bounded variation has the property that its graph does not have
unbounded total oscillation.
Example 7.34 Deﬁne f(x) = sin x, with domain the interval [0, 2π]. Let us
calculate Vf. Let P be a partition of [0, 2π]. Since adding points to the partition
only makes the sum
k
X
j=1
|f(pj) −f(pj−1)|
larger (by the triangle inequality), we may as well suppose that
P = {p0, p1, p2, . . . , pk}
contains the points π/2, 3π/2. Say that pℓ1 = π/2 and pℓ2 = 3π/2. Then
k
X
j=1
|f(pj) −f(pj−1)|
=
ℓ1
X
j=1
|f(pj) −f(pj−1)|
+
ℓ2
X
j=ℓ1+1
|f(pj) −f(pj−1)|
+
k
X
j=ℓ2+1
|f(pj) −f(pj−1)| .

158
CHAPTER 7. THE INTEGRAL
However, f is increasing on the interval [0, π/2] = [0, pℓ1]. Therefore the ﬁrst
sum is just
ℓ1
X
j=1
f(pj) −f(pj−1) = f(pℓ1) −f(p0) = f(π/2) −f(0) = 1 .
Similarly, f is monotone on the intervals [π/2, 3π/2] = [pℓ1, pℓ2] and [3π/2, 2π] =
[pℓ2, pk]. Thus the second and third sums equal f(pℓ1)−f(pℓ2) = 2 and f(pk)−
f(pℓ2) = 1 respectively. It follows that
Vf = Vf(2π) = 1 + 2 + 1 = 4 .
Of course Vf(x) for any x ∈[0, 2π] can be computed by similar means (see the
exercises).
In general, if f is a continuously diﬀerentiable function on an interval [a, b]
then
Vf(x) =
Z x
a
|f ′(t)| dt .
This assertion will be explored in the exercises.
Lemma 7.35 Let f be a function of bounded variation on the interval [a, b].
Then the function Vf is increasing on [a, b].
Proof: Let s < t be elements of [a, b]. Let P = {p0, p1, . . . , pk} be a partition
of [a, s]. Then eP = {p0, p1, . . . , pk, t} is a partition of [a, t] and
k
X
j=1
|f(pj) −f(pj−1)|
≤
k
X
j=1
|f(pj) −f(pj−1)| + |f(t) −f(pk)|
≤
Vf(t).
Taking the supremum on the left over all partitions P of [a, s] yields that
Vf(s) ≤Vf(t) .
Lemma 7.36 Let f be a function of bounded variation on the interval [a, b].
Then the function Vf −f is increasing on the interval [a, b].
Proof: Let s < t be elements of [a, b]. Pick ǫ > 0. By the deﬁnition of Vf we
may choose a partition P = {p0, p1, . . . , pk} of the interval [a, s] such that
Vf(s) −ǫ <
k
X
j=1
|f(pj) −f(pj−1)| .
(7.36.1)

7.4. ADVANCED RESULTS ON INTEGRATION THEORY
159
But then eP = {p0, p1, . . . , pk, t} is a partition of [a, t] and we have that
k
X
j=1
|f(pj) −f(pj−1)| + |f(t) −f(s)| ≤Vf(t) .
Using (7.36.1), we may conclude that
Vf(s) −ǫ + f(t) −f(s) <
k
X
j=1
|f(pj) −f(pj−1)| + |f(t) −f(s)| ≤Vf(t) .
We conclude that
Vf(s) −f(s) < Vf(t) −f(t) + ǫ .
Since the inequality holds for every ǫ > 0, we see that the function Vf −f is
increasing.
Now we may combine the last two lemmas to obtain our main result:
Proposition 7.37 If a function f is of bounded variation on [a, b], then f
may be written as the diﬀerence of two increasing functions. Conversely, the
diﬀerence of two increasing functions is a function of bounded variation.
Proof: If f is of bounded variation write f = Vf −(Vf −f) ≡f1 −f2. By the
lemmas, both f1 and f2 are increasing.
For the converse, assume that f = f1 −f2 with f1, f2 increasing. Then it is
easy to see that
Vf(b) ≤|f1(b) −f1(a)| + |f2(b) −f2(a)| .
Thus f is of bounded variation.
Now the main point of this discussion is the following theorem:
Theorem 7.38 If f is a continuous function on [a, b] and if α is of bounded
variation on [a, b] then the integral
Z b
a
f dα
exists and is ﬁnite.
If g is of bounded variation on [a, b] and if β is a continuous function of
bounded variation on [a, b] then the integral
Z b
a
g dβ
exists and is ﬁnite.
Proof: Write the function(s) of bounded variation as the diﬀerence of increas-
ing functions. Then apply Theorems 7.26 and 7.27.

160
CHAPTER 7. THE INTEGRAL
Exercises
1. Prove that, if f is a continuously diﬀerentiable function on the interval
[a, b], then
Vf =
Z b
a
|f ′(x)| dx .
[Hint: You will prove two inequalities. For one, use the Fundamental
Theorem. For the other, use the Mean Value Theorem.]
2. Prove that the integral
Z ∞
0
sin x
x
dx
exists.
*
3. Let f be a continuous function on the interval [0, 1] that only takes non-
negative values there. Prove that
Z 1
0
f(t) dt
2
≤
Z 1
0
f(t)2 dt .
4. Let f(x) = sin x on the interval [0, 2π]. Calculate Vf(x) for any x ∈[0, 2π].
5. Give an example of a continuous function on the interval [0, 1] that is not
of bounded variation.
6. Let β be a increasing function on the interval [a, b]. Set m = β(a) and
M = β(b). For any number λ lying between m and M set Sλ = {x ∈
[a, b] : β(x) > λ}. Prove that Sλ must be an interval. Let ℓ(λ) be the
length of Sλ. Then prove that
Z b
a
β(t)p dt
=
−
Z M
m
sp dℓ(s)
=
Z M
0
ℓ(s) · p · sp−1 ds.
7. If ϕ is a convex function on the real line, then prove that, for f integrable
on [0, 1],
ϕ
Z 1
0
f(x) dx

≤
Z 1
0
ϕ(f(x)) dx .
*
8. Show that, if f and g are continuous on the interval [0, 1], then

Z 1
0
f(x)g(x) dx
 ≤
Z 1
0
|f(x)|2 dx1/2 ·
Z 1
0
|g(x)|2 dx1/2 .
9. Give an example of a continuously diﬀerentiable function on an open in-
terval that is not of bounded variation.

EXERCISES
161
10. Prove that a continuously diﬀerentiable function on a compact interval is
certainly of bounded variation.
*
11. Explain how the summation by parts formula may be derived from the
integration by parts formula proved in this section.
*
12. Explain how the integration by parts formula may be derived from the
summation by parts process.


Chapter 8
Sequences and Series of
Functions
8.1
Partial Sums and Pointwise Convergence
A sequence of functions is usually written
f1, f2, . . .
or
{fj}∞
j=1 .
We will generally assume that the functions fj all have the same domain S.
Deﬁnition 8.1 A sequence of functions {fj}∞
j=1 with domain S ⊆R is said to
converge pointwise to a limit function f on S if, for each x ∈S, the sequence of
numbers {fj(x)} converges to f(x).
Example 8.2 Deﬁne fj(x) = xj with domain S = {x : 0 ≤x ≤1}. If 0 ≤x <
1 then fj(x) →0. However, fj(1) →1. Therefore the sequence fj converges
pointwise to the function
f(x) =
 0
if
0 ≤x < 1
1
if
x = 1
See Figure 8.1. We see that, even though the fj are each continuous, the limit
function f is not.
Here are some of the basic questions that we must ask about a sequence of
functions fj that converges to a function f on a domain S:
(1) If the functions fj are continuous, then is f continuous?
(2) If the functions fj are integrable on an interval I, then is f integrable on
I?
(3) If f is integrable on I, then does the sequence
R
I fj(x) dx converge to
R
I f(x) dx?
163

164
CHAPTER 8. SEQUENCES AND SERIES OF FUNCTIONS
y
x
Figure 8.1: The sequence {xj}.
(4) If the functions fj are diﬀerentiable, then is f diﬀerentiable?
(5) If f is diﬀerentiable, then does the sequence f ′
j converge to f ′?
We see from Example 8.1 that the answer to the ﬁrst question is “no”:
Each of the fj is continuous but f certainly is not. It turns out that, in order to
obtain a favorable answer to our questions, we must consider a stricter notion
of convergence of functions. This motivates the next deﬁnition.
Deﬁnition 8.3 Let fj be a sequence of functions on a domain S. We say that
the functions fj converge uniformly to f if, given ǫ > 0, there is an N > 0 such
that, for any j > N and any x ∈S, it holds that |fj(x) −f(x)| < ǫ.
Notice that the special feature of uniform convergence is that the rate at
which fj(x) converges is independent of x ∈S. In Example 8.1, fj(x) is con-
verging very rapidly to zero for x near zero but arbitrarily slowly to zero for
x near 1—see Figure 8.1. In the next example we shall prove this assertion
rigorously:
Example 8.4 The sequence fj(x) = xj does not converge uniformly to the
limit function
f(x) =

0
if
0 ≤x < 1
1
if
x = 1
on the domain S = [0, 1]. In fact it does not even do so on the smaller domain
[0, 1). To see this, notice that no matter how large j is we have, by the Mean
Value Theorem, that
fj(1) −fj(1 −1/(2j)) = 1
2j · f ′
j(ξ)

8.1. PARTIAL SUMS AND POINTWISE CONVERGENCE
165
for some ξ between 1 −1/(2j) and 1. But f ′
j(x) = j · xj−1 hence |f ′
j(ξ)| < j and
we conclude that
|fj(1) −fj(1 −1/(2j))| < 1
2
or
fj(1 −1/(2j)) > fj(1) −1
2 = 1
2 .
In conclusion, no matter how large j, there will be values of x (namely, x =
1−1/(2j)) at which fj(x) is at least distance 1/2 from the limit 0. We conclude
that the convergence is not uniform.
Theorem 8.5 If fj are continuous functions on a set S that converge uniformly
on S to a function f then f is also continuous.
Proof: Let ǫ > 0. Choose an integer N so large that if j > N then |fj(x) −
f(x)| < ǫ/3 for all x ∈S. Fix P ∈S. Choose δ > 0 so small that if |x −P| < δ
then |fN(x) −fN(P)| < ǫ/3. For such x we have
|f(x) −f(P)|
≤
|f(x) −fN(x)| + |fN(x) −fN(P)| + |fN(P) −f(P)|
<
ǫ
3 + ǫ
3 + ǫ
3
by the way that we chose N and δ. But the last line sums to ǫ, proving that f
is continuous at P. Since P ∈S was chosen arbitrarily, we are done.
Example 8.6 Deﬁne functions
fj(x) =



0
if
x = 0
j
if
0 < x ≤1/j
0
if
1/j < x ≤1
for j = 2, 3, . . . .
Then limj→∞fj(x) = 0 ≡f(x) for all x in the interval
I = [0, 1]. However
Z 1
0
fj(x) dx =
Z 1/j
0
j dx = 1
for every j. Thus the fj converge to the integrable limit function f(x) ≡0 (with
integral 0), but their integrals do not converge to the integral of f.
Example 8.7 Let q1, q2, . . . be an enumeration of the rationals in the interval
I = [0, 1]. Deﬁne functions
fj(x) =
 1
if
x ∈{q1, q2, . . . , qj}
0
if
x ̸∈{q1, q2, . . . , qj}
Then the functions fj converge pointwise to the Dirichlet function f which is
equal to 1 on the rationals and 0 on the irrationals. Each of the functions fj
has integral 0 on I. But the function f is not integrable on I.

166
CHAPTER 8. SEQUENCES AND SERIES OF FUNCTIONS
The last two examples show that something more than pointwise conver-
gence is needed in order for the integral to respect the limit process.
Theorem 8.8 Let fj be integrable functions on a nontrivial bounded interval
[a, b] and suppose that the functions fj converge uniformly to the limit function
f. Then f is integrable on [a, b] and
lim
j→∞
Z b
a
fj(x) dx =
Z b
a
f(x) dx .
Proof: Pick ǫ > 0. Choose N so large that if j > N then |fj(x) −f(x)| <
ǫ/[2(b −a)] for all x ∈[a, b]. Notice that, if j, k > N, then

Z b
a
fj(x) dx −
Z b
a
fk(x) dx
 ≤
Z b
a
|fj(x) −fk(x)| dx .
(8.8.1)
But |fj(x) −fk(x)| ≤|fj(x) −f(x)| + |f(x) −fk(x)| < ǫ/(b −a). Therefore line
(8.8.1) does not exceed
Z b
a
ǫ
b −a dx = ǫ .
Thus the numbers
R b
a fj(x) dx form a Cauchy sequence. Let the limit of this
sequence be called A. Notice that, if we let k →∞in the inequality

Z b
a
fj(x) dx −
Z b
a
fk(x) dx
 ≤ǫ ,
then we obtain

Z b
a
fj(x) dx −A
 ≤ǫ
for all j ≥N. This estimate will be used below.
By hypothesis there is a δ > 0 such that, if P = {p1, . . . , pk} is a partition
of [a, b] with m(P) < δ, then
R(fN, P) −
Z b
a
fN(x) dx
 < ǫ .
But then, for such a partition, we have
|R(f, P) −A|
≤
R(f, P) −R(fN, P)
 +
R(fN, P) −
Z b
a
fN(x) dx

+

Z b
a
fN(x) dx −A
 .
We have already noted that, by the choice of N, the third term on the right is
smaller than ǫ. The second term is smaller than ǫ by the way that we chose the

EXERCISES
167
partition P. It remains to examine the ﬁrst term. Now
R(f, P) −R(fN, P)

=

k
X
j=1
f(sj)∆j −
k
X
j=1
fN(sj)∆j

≤
k
X
j=1
f(sj) −fN(sj)
∆j
<
k
X
j=1
ǫ
2(b −a)∆j
=
ǫ
2(b −a)
k
X
j=1
∆j
=
ǫ
2 .
Therefore |R(f, P) −A| < 3ǫ when m(P) < δ. This shows that the function f
is integrable on [a, b] and has integral with value A.
We have succeeded in answering questions (1) and (2) that were raised at
the beginning of the section. In the next section we will answer questions (3),
(4), and (5).
Exercises
1. If fj →f uniformly on a domain S and if fj, f never vanish on S then
does it follow that the functions 1/fj converge uniformly to 1/f on S?
2. Write out the ﬁrst ﬁve partial sums for the series
∞
X
j=1
sin3 j
j2
.
3. Write a series of polynomials that converges to f(x) = sin x2. Can you
prove that it converges?
4. Write a series of trigonometric functions that converges to f(x) = x. Can
you prove that it converges?
5. Write a series of piecewise linear functions that converges to f(x) = x2 on
the interval [0, 1]. Can you prove that it converges?
6. Write a series of functions that converges pointwise on [0, 1] but does not
converge uniformly on any proper subinterval. [Hint: First consider a
sequence.]

168
CHAPTER 8. SEQUENCES AND SERIES OF FUNCTIONS
7. Give an example of a Taylor series that converges uniformly on compact
sets to its limit function.
8. A Taylor series will never converge only pointwise. Explain.
9. Show that if P
j f ′
j converges uniformly on [0, 1] (where the prime stands
for the derivative), and if fj(0) = 0 for all j, then P
j fj converges uni-
formly on compact sets.
10. TRUE or FALSE: If P
j fj converges absolutely and uniformly and P
j gj
converges absolutely and uniformly on a compact interval [a, b], then so
does P
j fjgj.
8.2
More on Uniform Convergence
In general, limits do not commute. Since the integral is deﬁned with a limit,
and since we saw in the last section that integrals do not always respect limits
of functions, we know some concrete instances of non-commutation of limits.
The fact that continuity is deﬁned with a limit, and that the limit of continuous
functions need not be continuous, gives even more examples of situations in
which limits do not commute. Let us now turn to a situation in which limits do
commute:
Theorem 8.9 Fix a set S and a point s ∈S. Assume that the functions fj
converge uniformly on the domain S \ {s} to a limit function f. Suppose that
each function fj(x) has a limit as x →s. Then f itself has a limit as x →s and
lim
x→s f(x) = lim
j→∞lim
x→s fj(x) .
Because of the way that f is deﬁned, we may rewrite this conclusion as
lim
x→s lim
j→∞fj(x) = lim
j→∞lim
x→s fj(x) .
In other words, the limits limx→s and limj→∞commute.
Proof: Let αj = limx→s fj(x). Let ǫ > 0. There is a number N > 0 (inde-
pendent of x ∈S \ {s}) such that j ≥N implies that |fj(x) −f(x)| < ǫ/4.
Fix j, k ≥N.
Choose δ > 0 such that 0 < |x −s| < δ implies both that
|fj(x) −αj| < ǫ/4 and |fk(x) −αk| < ǫ/4. Then
|αj −αk| ≤|αj −fj(x)| + |fj(x) −f(x)| + |f(x) −fk(x)| + |fk(x) −αk| .
The ﬁrst and last expressions are less than ǫ/4 by the choice of x. The middle
two expressions are less than ǫ/4 by the choice of N. We conclude that the
sequence αj is Cauchy. Let α be the limit of that sequence.
Letting k →∞in the inequality
|αj −αk| < ǫ

8.2. MORE ON UNIFORM CONVERGENCE
169
that we obtained above yields
|αj −α| ≤ǫ
for j ≥N. Now, with δ as above and 0 < |x −s| < δ, we have
|f(x) −α| ≤|f(x) −fj(x)| + |fj(x) −αj| + |αj −α| .
By the choices we have made, the ﬁrst term is less than ǫ/4, the second is less
than ǫ/2, and the third is less than or equal to ǫ. Altogether, if 0 < |x −s| < δ
then |f(x) −α| < 2ǫ. This is the desired conclusion.
Parallel with our notion of Cauchy sequence of numbers, we have a concept
of Cauchy sequence of functions in the uniform sense:
Deﬁnition 8.10 A sequence of functions fj on a domain S is called a uniformly
Cauchy sequence if, for each ǫ > 0, there is an N > 0 such that, if j, k > N,
then
|fj(x) −fk(x)| < ǫ
∀x ∈S .
Proposition 8.11 A sequence of functions fj is uniformly Cauchy on a domain
S if and only if the sequence converges uniformly to a limit function f on the
domain S.
Proof: The proof is straightforward and is assigned as an exercise.
We will use the last two results in our study of the limits of diﬀerentiable
functions. First we consider an example.
Example 8.12 Deﬁne the function
fj(x) =



0
if
x ≤0
jx2
if
0 < x ≤1/(2j)
x −1/(4j)
if
1/(2j) < x < ∞
We leave it as an exercise for you to check that the functions fj converge uni-
formly on the entire real line to the function
f(x) =
 0
if
x ≤0
x
if
x > 0
(draw a sketch to help you see this). Notice that each of the functions fj is
continuously diﬀerentiable on the entire real line, but f is not diﬀerentiable at
0.
It turns out that we must strengthen our convergence hypotheses if we want
the limit process to respect diﬀerentiation. The basic result is

170
CHAPTER 8. SEQUENCES AND SERIES OF FUNCTIONS
Theorem 8.13 Suppose that a sequence fj of diﬀerentiable functions on an
open interval I converges pointwise to a limit function f. Suppose further that
the sequence f ′
j converges uniformly on I to a limit function g. Then the limit
function f is diﬀerentiable on I and f ′(x) = g(x) for all x ∈I.
Proof: There is no loss of generality to assume that I is an interval of length
1. Let ǫ > 0. The sequence {f ′
j} is uniformly Cauchy. Therefore we may choose
N so large that j, k > N implies that
f ′
j(x) −f ′
k(x)
 < ǫ
2
∀x ∈I .
(8.13.1)
Fix a point P ∈I. Deﬁne
µj(x) = fj(x) −fj(P)
x −P
for x ∈I, x ̸= P. It is our intention to apply Theorem 8.9 above to the functions
µj.
First notice that, for each j, we have
lim
x→P µj(x) = f ′
j(P) .
Thus
lim
j→∞lim
x→P µj(x) = lim
j→∞f ′
j(P) = g(P) .
That calculates the limits in one order.
On the other hand,
lim
j→∞µj(x) = f(x) −f(P)
x −P
≡µ(x)
for x ∈I \ {P}. If we can show that this convergence is uniform then Theorem
8.9 applies and we may conclude that
lim
x→P µ(x) = lim
j→∞lim
x→P µj(x) = lim
j→∞f ′
j(P) = g(P) .
But this just says that f is diﬀerentiable at P and the derivative equals g. That
is the desired result.
To verify the uniform convergence of the µj, we apply the Mean Value
Theorem to the function fj −fk. For x ̸= P we have
|µj(x) −µk(x)|
=
1
|x −P| · |(fj(x) −fk(x)) −(fj(P) −fk(P))|
=
1
|x −P| · |x −P| · |(fj −fk)′(ξ)|
=
|(fj −fk)′(ξ)|
for some ξ between x and P. But line (8.13.1) guarantees that the last line does
not exceed ǫ/2. That shows that the µj converge uniformly and concludes the
proof.

EXERCISES
171
Remark 8.14 A little additional eﬀort shows that we need only assume in the
theorem that the functions fj converge at a single point x0 in the domain. One
of the exercises asks you to prove this assertion.
Notice further that, if we make the additional assumption that each of the
functions f ′
j is continuous, then the proof of the theorem becomes much easier.
For then
fj(x) = fj(x0) +
Z x
x0
f ′
j(t) dt
by the Fundamental Theorem of Calculus. The hypothesis that the f ′
j converge
uniformly then implies, by Theorem 8.8, that the integrals converge to
Z x
x0
g(t) dt .
The hypothesis that the functions fj converge at x0 then allows us to conclude
that the sequence fj(x) converges for every x to f(x) and
f(x) = f(x0) +
Z x
x0
g(t) dt .
The Fundamental Theorem of Calculus then yields that f ′ = g as desired.
Exercises
1. Prove that, if a series of continuous functions converges uniformly, then
the sum function is also continuous.
2. Prove Proposition 8.11. Refer to the parallel result in Chapter 3 for some
hints.
3. Prove the assertion made in Remark 8.14 that Theorem 8.13 is still true if
the functions fj are assumed to converge at just one point (and also that
the derivatives f ′
j converge uniformly).
*
4. A function is called “piecewise linear” if it is (i) continuous and (ii) its
graph consists of ﬁnitely many linear segments. Prove that a continuous
function on an interval [a, b] is the uniform limit of a sequence of piecewise
linear functions.
5. If a sequence of functions fj on a domain S ⊆R has the property that
fj →f uniformly on S, then does it follow that (fj)2 →f 2 uniformly on
S? What simple additional hypothesis will make your answer aﬃrmative?
6. Let fj be a uniformly convergent sequence of functions on a common
domain S. What would be suitable conditions on a function φ to guarantee
that φ ◦fj converges uniformly on S?

172
CHAPTER 8. SEQUENCES AND SERIES OF FUNCTIONS
*
7. Construct a sequence of continuous functions fj(x) that has the property
that fj(q) increases monotonically to +∞for each rational q but such
that, at each irrational x, |fj(x)| ≤1 for inﬁnitely many j.
8. Prove that a sequence {fj} of functions converges pointwise if and only if
the series
f1 +
∞
X
j=2
(fj −fj−1)
converges pointwise. Prove the same result for uniform convergence.
9. Assume that fj are continuous functions on the interval [0, 1]. Suppose
that limj→∞fj(x) exists for each x ∈[0, 1] and deﬁnes a function f on
[0, 1]. Further suppose that f1 ≤f2 ≤· · · . Can you conclude that f is
continuous?
10. Let f : R →R be a function. We say that f is piecewise constant if the
real line can be written as the inﬁnite disjoint union of intervals and f is
constant on each of those intervals. Now let ϕ be a continuous function on
[a, b]. Show that ϕ can be uniformly approximated by piecewise constant
functions.
11. Refer to Exercise 10 for terminology. Let f be a piecewise constant func-
tion. Show that f is the pointwise limit of polynomials.
8.3
Series of Functions
Deﬁnition 8.15 The formal expression
∞
X
j=1
fj(x) ,
where the fj are functions on a common domain S, is called a series of functions.
For N = 1, 2, 3, . . . the expression
SN(x) =
N
X
j=1
fj(x) = f1(x) + f2(x) + · · · + fN(x)
is called the Nth partial sum for the series. In case
lim
N→∞SN(x)
exists and is ﬁnite then we say that the series converges at x. Otherwise we say
that the series diverges at x.
Notice that the question of convergence of a series of functions, which should
be thought of as an addition process, reduces to a question about the sequence
of partial sums. Sometimes, as in the next example, it is convenient to begin
the series at some index other than j = 1.

8.3. SERIES OF FUNCTIONS
173
Example 8.16 Consider the series
∞
X
j=0
xj .
This is the geometric series from Proposition 3.15. It converges absolutely for
|x| < 1 and diverges otherwise.
By the formula for the partial sums of a geometric series,
SN(x) = 1 −xN+1
1 −x
.
For |x| < 1 we see that
SN(x) →
1
1 −x.
Deﬁnition 8.17 Let
∞
X
j=1
fj(x)
be a series of functions on a domain S. If the partial sums SN(x) converge
uniformly on S to a limit function g(x) then we say that the series converges
uniformly on S.
Of course all of our results about uniform convergence of sequences of func-
tions translate, via the sequence of partial sums of a series, to results about
uniformly convergent series of functions. For example,
(a) If fj are continuous functions on a domain S and if the series
∞
X
j=1
fj(x)
converges uniformly on S to a limit function f then f is also contin-
uous on S.
(b) If fj are integrable functions on [a, b] and if
∞
X
j=1
fj(x)
converges uniformly on [a, b] to a limit function f then f is also
integrable on [a, b] and
Z b
a
f(x) dx =
∞
X
j=1
Z b
a
fj(x) dx .

174
CHAPTER 8. SEQUENCES AND SERIES OF FUNCTIONS
You will be asked to provide details of these assertions, as well as a statement
and proof of a result about derivatives of series, in the exercises. Meanwhile we
turn to an elegant test for uniform convergence that is due to Weierstrass.
Theorem 8.18 (The Weierstrass M-Test) Let {fj}∞
j=1 be functions on a
common domain S. Assume that each |fj| is bounded on S by a constant Mj
and that
∞
X
j=1
Mj < ∞.
Then the series
∞
X
j=1
fj
(8.18.1)
converges uniformly on the set S.
Proof: By hypothesis, the sequence TN of partial sums of the series P∞
j=1 Mj
is Cauchy. Given ǫ > 0 there is therefore a number K so large that q > p > K
implies that
q
X
j=p+1
Mj = |Tq −Tp| < ǫ .
We may conclude that the partial sums SN of the original series P fj satisfy,
for q > p > K,
|Sq(x) −Sp(x)| =

q
X
j=p+1
fj(x)

≤
q
X
j=p+1
|fj(x)| ≤
q
X
j=p+1
Mj < ǫ.
Thus the partial sums SN(x) of the series (8.18.1) are uniformly Cauchy. The
series (8.18.1) therefore converges uniformly.
Example 8.19 Let us consider the series
f(x) =
∞
X
j=1
2−j sin
 2jx

.
The sine terms oscillate so erratically that it would be diﬃcult to calculate
partial sums for this series. However, noting that the jth summand fj(x) =
2−j sin(2jx) is dominated in absolute value by 2−j, we see that the Weierstrass
M-Test applies to this series. We conclude that the series converges uniformly
on the entire real line.
By property (a) of uniformly convergent series of continuous functions that
was noted above, we may conclude that the function f deﬁned by our series

EXERCISES
175
is continuous. It is also 2π-periodic: f(x + 2π) = f(x) for every x since this
assertion is true for each summand. Since the continuous function f restricted
to the compact interval [0, 2π] is uniformly continuous (Theorem 5.27), we may
conclude that f is uniformly continuous on the entire real line.
However, it turns out that f is nowhere diﬀerentiable. The proof of this as-
sertion follows lines similar to the treatment of nowhere diﬀerentiable functions
in Theorem 6.5. The details will be covered in an exercise.
Exercises
1. Formulate and prove a result about the derivative of the sum of a conver-
gent series of diﬀerentiable functions.
*
2. Let 0 < α ≤1. Prove that the series
∞
X
j=1
2−jα sin
 2jx

deﬁnes a function f that is nowhere diﬀerentiable. To achieve this end,
follow the scheme that was used to prove Theorem 6.5: a) Fix x; b) for h
small, choose M such that 2−M is approximately equal to |h|; c) break the
series up into the sum from 1 to M −1, the single summand j = M, and
the sum from j = M + 1 to ∞. The middle term has very large Newton
quotient and the ﬁrst and last terms are relatively small.
3. Prove Dini’s theorem: If fj are continuous functions on a compact set
K, f1(x) ≤f2(x) ≤. . . for all x ∈K, and the fj converge to a continuous
function f on K then in fact the fj converge uniformly to f on K.
4. Use the concept of boundedness of a function to show that the functions
sin x and cos x cannot be polynomials.
5. Prove that, if p is any polynomial, then there is an N large enough that
ex > |p(x)| for x > N. Conclude that the function ex is not a polynomial.
6. Find a way to prove that tan x and ln x are not polynomials.
7. Prove that the series
∞
X
j=1
sin jx
j
converges uniformly on compact intervals that do not contain odd multi-
ples of π/2. (Hint: Sum by parts and the result will follow.)
*
8. Prove that the sequence of functions fj(x) = sin(jx) has no subsequence
that converges at every x.

176
CHAPTER 8. SEQUENCES AND SERIES OF FUNCTIONS
9. Suppose that the sequence fj(x) on the interval [0, 1] satisﬁes |fj(s) −
fj(t)| ≤|s −t| for all s, t ∈[0, 1]. Further assume that the fj converge
pointwise to a limit function f on the interval [0, 1].
Does the series
converge uniformly?
10. Prove a comparison test for uniform convergence of series: if fj, gj are
functions and 0 ≤fj ≤gj and the series P gj converges uniformly then
so also does the series P fj.
11. Show by giving an example that the converse of the Weierstrass M-Test
is false.
12. If fj are continuous functions on a domain S and if the series
∞
X
j=1
fj(x)
converges uniformly on S to a limit function f then f is also continuous
on S.
13. Prove that if a series P∞
j=1 fj of integrable functions on an interval [a, b]
is uniformly convergent on [a, b] then the sum function f is integrable and
Z b
a
f(x) dx =
∞
X
j=1
Z b
a
fj(x) dx .
14. Let k be a positive integer. Modify the function in Exercise 2 to obtain a
function that is k-times continuously diﬀerentiable, but not (k + 1) times
diﬀerentiable at any point.
8.4
The Weierstrass Approximation Theorem
The name Weierstrass has occurred frequently in this chapter.
In fact Karl
Weierstrass (1815-1897) revolutionized analysis with his examples and theorems.
This section is devoted to one of his most striking results. We introduce it with
a motivating discussion.
It is natural to wonder whether the usual functions of calculus—sin x, cos x,
and ex, for instance—are actually polynomials of some very high degree. Since
polynomials are so much easier to understand than these transcendental func-
tions, an aﬃrmative answer to this question would certainly simplify mathe-
matics. Of course a moment’s thought shows that this wish is impossible: a
polynomial of degree k has at most k real roots. Since sine and cosine have
inﬁnitely many real roots they cannot be polynomials. A polynomial of degree
k has the property that if it is diﬀerentiated enough times (namely, k +1 times)
then the derivative is zero. Since this is not the case for ex, we conclude that ex
cannot be a polynomial. The exercises of the last section discuss other means for

8.4. THE WEIERSTRASS APPROXIMATION THEOREM
177
distinguishing the familiar transcendental functions of calculus from polynomial
functions.
In calculus we learned of a formal procedure, called Taylor series, for associ-
ating polynomials with a given function f. In some instances these polynomials
form a sequence that converges back to the original function. Of course the
method of the Taylor expansion has no hope of working unless f is inﬁnitely
diﬀerentiable. Even then, it turns out that the Taylor series rarely converges
back to the original function—see the discussion at the end of Section 10.2.
Nevertheless, Taylor’s theorem with remainder might cause us to speculate that
any reasonable function can be approximated in some fashion by polynomi-
als. In fact the theorem of Weierstrass gives a spectacular aﬃrmation of this
speculation:
Theorem 8.20 (The Weierstrass Approximation Theorem) Let f be a
continuous function on an interval [a, b]. Then there is a sequence of polynomials
pj(x) with the property that the sequence pj converges uniformly on [a, b] to f.
In a few moments we shall prove this theorem in detail. Let us ﬁrst consider
some of its consequences. A restatement of the theorem would be that, given a
continuous function f on [a, b] and an ǫ > 0, there is a polynomial p such that
|f(x) −p(x)| < ǫ
for every x ∈[a, b]. If one were programming a computer to calculate values
of a fairly wild function f, the theorem guarantees that, up to a given degree
of accuracy, one could use a polynomial instead (which would in fact be much
easier for the computer to handle). Advanced techniques can even tell what
degree of polynomial is needed to achieve a given degree of accuracy. The proof
that we shall present also suggests how this might be done.
Let f be the Weierstrass nowhere diﬀerentiable function.
The theorem
guarantees that, on any compact interval, f is the uniform limit of polynomials.
Thus even the uniform limit of inﬁnitely diﬀerentiable functions need not be
diﬀerentiable—even at one point. This explains why the hypotheses of Theorem
8.13 needed to be so stringent.
We shall break up the proof of the Weierstrass Approximation Theorem
into a sequence of lemmas.
Lemma 8.21 Let ψj be a sequence of continuous functions on the interval
[−1, 1] with the following properties:
(i) ψj(x) ≥0 for all x;
(ii)
R 1
−1 ψj(x) dx = 1 for each j;
(iii) For any δ > 0 we have
lim
j→∞
Z
δ≤|x|≤1
ψj(x) dx = 0 .

178
CHAPTER 8. SEQUENCES AND SERIES OF FUNCTIONS
If f is a continuous function on the real line which is identically zero oﬀthe
interval [0, 1] then the functions
fj(x) =
Z 1
−1
ψj(t)f(x −t) dt
converge uniformly on the interval [0, 1] to f(x).
Proof: By multiplying f by a constant we may assume that sup |f| = 1. Let
ǫ > 0. Since f is uniformly continuous on the interval [0, 1] we may choose a
δ > 0 such that if |x −t| < δ then |f(x) −f(t)| < ǫ/2. By property (iii) above
we may choose an N so large that j > N implies that |
R
δ≤|t|≤1 ψj(t) dt| < ǫ/4.
Then, for any x ∈[0, 1], we have
|fj(x) −f(x)|
=

Z 1
−1
ψj(t)f(x −t) dt −f(x)

=

Z 1
−1
ψj(t)f(x −t) dt −
Z 1
−1
ψj(t)f(x) dt
 .
Notice that, in the last line, we have used fact (ii) about the functions ψj to
multiply the term f(x) by 1 in a clever way. Now we may combine the two
integrals to ﬁnd that the last line
=

Z 1
−1
(f(x −t) −f(x))ψj(t) dt

≤
Z δ
−δ
|f(x −t) −f(x)|ψj(t) dt
+
Z
δ≤|t|≤1
|f(x −t) −f(x)|ψj(t) dt
=
A + B .
To estimate term A, we recall that, for |t| < δ, we have |f(x −t) −f(x)| < ǫ/2;
hence
A ≤
Z δ
−δ
ǫ
2 ψj(t) dt ≤ǫ
2 ·
Z 1
−1
ψj(t) dt = ǫ
2 .
For B we write
B
≤
Z
δ≤|t|≤1
2 · sup |f| · ψj(t) dt
≤
2 ·
Z
δ≤|t|≤1
ψj(t) dt
<
2 · ǫ
4 = ǫ
2 ,
where in the penultimate line we have used the choice of j. Adding together
our estimates for A and B, and noting that these estimates are independent of
the choice of x, yields the result.

8.4. THE WEIERSTRASS APPROXIMATION THEOREM
179
Lemma 8.22 Deﬁne ψj(t) = kj · (1 −t2)j, where the positive constants kj are
chosen so that
R 1
−1 ψj(t) dt = 1. Then the functions ψj satisfy the properties
(i)–(iii) of the last lemma.
Proof: Of course property (ii) is true by design. Property (i) is obvious. In
order to verify property (iii), we need to estimate the size of kj.
Notice that
Z 1
−1
(1 −t2)j dt
=
2 ·
Z 1
0
(1 −t2)j dt
≥
2 ·
Z 1/√j
0
(1 −t2)j dt
≥
2 ·
Z 1/√j
0
(1 −jt2) dt ,
where we have used the binomial theorem. But this last integral is easily eval-
uated and equals 4/(3√j). We conclude that
Z 1
−1
(1 −t2)j dt >
1
√j .
As a result, kj < √j.
Now, to verify property (iii) of the lemma, we notice that, for δ > 0 ﬁxed
and δ ≤|t| ≤1, it holds that
|ψj(t)| ≤kj · (1 −δ2)j ≤
p
j · (1 −δ2)j
and this expression tends to 0 as j →∞. Thus ψj →0 uniformly on {t : δ ≤
|t| ≤1}. It follows that the ψj satisfy property (iii) of the lemma.
Proof of the Weierstrass Approximation Theorem: We may assume
without loss of generality (just by changing coordinates) that f is a continuous
function on the interval [0, 1]. After adding a linear function (which is a poly-
nomial) to f, we may assume that f(0) = f(1) = 0. Thus f may be continued
to be a continuous function which is identically zero on the entire real line.
Let ψj be as in Lemma 8.22 and form fj as in Lemma 8.21. Then we know
that the fj converge uniformly on [0, 1] to f. Finally,
fj(x)
=
Z 1
−1
ψj(t)f(x −t) dt
=
Z 1
0
ψj(x −t)f(t) dt
=
kj
Z 1
0
(1 + (x −t)2)jf(t) dt .

180
CHAPTER 8. SEQUENCES AND SERIES OF FUNCTIONS
But multiplying out the expression (1 + (x −t)2)j in the integrand then shows
that fj is a polynomial of degree at most 2j in x. Thus we have constructed a
sequence of polynomials fj that converges uniformly to the function f on the
interval [0, 1].
Exercises
*
1. Use the Weierstrass Approximation Theorem and Mathematical Induction
to prove that, if f is k times continuously diﬀerentiable on an interval [a, b],
then there is a sequence of polynomials pj with the property that
pj →f
uniformly on [a, b],
p′
j →f ′
uniformly on [a, b],
. . .
p(k)
j
→f (k)
uniformly on [a, b].
*
2. Let a < b be real numbers. Call a function of the form
f(x) =

1
if
a ≤x ≤b
0
if
x < a or x > b
a characteristic function for the interval [a, b]. Then a function of the form
g(x) =
k
X
j=1
aj · fj(x) ,
with the fj characteristic functions of intervals [aj, bj], is called simple.
Prove that any continuous function on an interval [c, d] is the uniform
limit of a sequence of simple functions. (Hint: The proof of this asser-
tion is conceptually simple; do not imitate the proof of the Weierstrass
Approximation Theorem.)
3. If f is a continuous function on the interval [a, b] and if
Z b
a
f(x)p(x) dx = 0
for every polynomial p, then prove that f must be the zero function.
(Hint: Use Weierstrass’s Approximation Theorem.)

EXERCISES
181
4. Let {fj} be a sequence of continuous functions on the real line. Suppose
that the fj converge uniformly to a function f. Prove that
lim
j→∞fj(x + 1/j) = f(x)
uniformly on any bounded interval.
Can any of these hypotheses be weakened?
*
5. Deﬁne a trigonometric polynomial to be a function of the form
k
X
j=1
aj · cos jx +
ℓ
X
j=1
bj · sin jx .
Prove a version of the Weierstrass Approximation Theorem on the interval
[0, 2π] for 2π-periodic continuous functions and with the phrase “trigono-
metric polynomial” replacing “polynomial.” (Hint: Prove that
j
X
ℓ=−j

1 −
|ℓ|
j + 1

(cos ℓt) =
1
j + 1
 
sin j+1
2 t
sin 1
2t
!2
.
Use these functions as the ψjs in the proof of Weierstrass’s theorem.)
6. Prove that the Weierstrass Approximation Theorem fails if we restrict
attention to polynomials of degree less than or equal to 1000.
7. Is the Weierstrass Approximation Theorem true if we restrict ourselves to
only using polynomials of even degree?
8. Is the Weierstrass Approximation Theorem true if we restrict ourselves to
only using polynomials with coeﬃcients of size not exceeding 1?
9. Use the polar form of complex numbers (that is, z = reiθ) to show that,
on the unit circle, trigonometric polynomials and ordinary polynomials
are really the same thing.


Chapter 9
Elementary Transcendental
Functions
9.1
Power Series
A series of the form
∞
X
j=0
aj(x −c)j
is called a power series expanded about the point c. Our ﬁrst task is to determine
the nature of the set on which a power series converges.
Proposition 9.1 Assume that the power series
∞
X
j=0
aj(x −c)j
converges at the value x = d with d ̸= c. Let r = |d −c|. Then the series
converges uniformly and absolutely on compact subsets of I = {x : |x−c| < r}.
Proof: We may take the compact subset of I to be K = [c −s, c + s] for some
number 0 < s < r. For x ∈K it then holds that
∞
X
j=0
aj(x −c)j =
∞
X
j=0
aj(d −c)j ·

x −c
d −c

j
.
In the sum on the right, the ﬁrst expression in absolute values is bounded
by some constant C (by the convergence hypothesis). The quotient in absolute
values is majorized by L = s/r < 1. The series on the right is thus dominated
by
∞
X
j=0
C · Lj .
183

184
CHAPTER 9. ELEMENTARY TRANSCENDENTAL FUNCTIONS
This geometric series converges. By the Weierstrass M-Test, the original
series converges absolutely and uniformly on K.
An immediate consequence of the proposition is that the set on which the power
series
∞
X
j=0
aj(x −c)j
converges is an interval centered about c. We call this set the interval of con-
vergence. The series will converge absolutely and uniformly on compact subsets
of the interval of convergence. The radius of the interval of convergence (called
the radius of convergence) is deﬁned to be half its length. Whether convergence
holds at the endpoints of the interval will depend on the particular series being
studied. Ad hoc methods must be used to check the endpoints. Let us use the
notation C to denote the open interval of convergence.
It happens that, if a power series converges at either of the endpoints of its
interval of convergence, then the convergence is uniform up to that endpoint.
This is a consequence of Abel’s partial summation test; details will be explored
in the exercises.
On the interval of convergence C, the power series deﬁnes a function f. Such
a function is said to be real analytic. More precisely, we have
Deﬁnition 9.2 A function f, with domain an open set U ⊆R and range either
the real or the complex numbers, is called real analytic if, for each c ∈U, the
function f may be represented by a convergent power series on an interval of
positive radius centered at c:
f(x) =
∞
X
j=0
aj(x −c)j .
We need to know both the algebraic and the calculus properties of a real
analytic function: is it continuous? diﬀerentiable? How does one add/subtract/
multipy/divide two such functions?
Proposition 9.3 Let
∞
X
j=0
aj(x −c)j and
∞
X
j=0
bj(x −c)j
be two power series with intervals of convergence C1 and C2 centered at c. Let
f1(x) be the function deﬁned by the ﬁrst series on C1 and f2(x) the function
deﬁned by the second series on C2. Then, on their common domain C = C1 ∩C1,
it holds that
(1) f(x) ± g(x) = P∞
j=0(aj ± bj)(x −c)j;
(2) f(x) · g(x) = P∞
m=0
P
j+k=m(aj · bk)(x −c)m.

9.1. POWER SERIES
185
Proof: Let
AN =
N
X
j=0
aj(x −c)j and BN =
N
X
j=0
bj(x −c)j
be, respectively, the Nth partial sums of the power series that deﬁne f and g.
If CN is the Nth partial sum of the series
∞
X
j=0
(aj ± bj)(x −c)j
then
f(x) ± g(x)
=
lim
N→∞AN ± lim
N→∞BN = lim
N→∞[AN ± BN]
=
lim
N→∞CN =
∞
X
j=0
(aj ± bj)(x −c)j .
This proves (1).
For (2), let
DN =
N
X
m=0
X
j+k=m
(aj · bk)(x −c)m and RN =
∞
X
j=N+1
bj(x −c)j .
We have
DN
=
a0BN + a1(x −c)BN−1 + · · · + aN(x −c)NB0
=
a0(g(x) −RN) + a1(x −c)(g(x) −RN−1)
+ · · · + aN(x −c)N(g(x) −R0)
=
g(x)
N
X
j=0
aj(x −c)j
−[a0RN + a1(x −c)RN−1 + · · · + aN(x −c)NR0] .
Clearly,
g(x)
N
X
j=0
aj(x −c)j
converges to g(x)f(x) as N approaches ∞. In order to show that DN →g · f,
it will thus suﬃce to show that
a0RN + a1(x −c)RN−1 + · · · + aN(x −c)NR0

converges to 0 as N approaches ∞. Fix x. Now we know that
∞
X
j=0
aj(x −c)j

186
CHAPTER 9. ELEMENTARY TRANSCENDENTAL FUNCTIONS
is absolutely convergent so we may set
A =
∞
X
j=0
|aj||x −c|j .
Also P∞
j=0 bj(x −c)j is convergent. Therefore, given ǫ > 0, we can ﬁnd N0 so
that N ≥N0 implies |RN| ≤ǫ. Thus we have
a0RN + a1(x −c)RN−1 + · · · + aN(x −c)NR0

≤
|a0RN + · · · + aN−N0(x −c)N−N0RN0|
+|aN−N0+1(x −c)N−N0+1RN0−1 + · · · + aN(x −c)NR0|
≤
sup
M≥N0
RM ·


∞
X
j=0
|aj||x −c|j


+|aN−N0+1(x −c)N−N0+1RN0−1 · · · + aN(x −c)NR0|
≤
ǫA + |aN−N0+1(x −c)N−N0+1RN0−1 · · · + aN(x −c)NR0| .
Thus
a0RN + a1(x −c)RN−1 + · · · + aN(x −c)NR0

≤
ǫ · A + M ·
N
X
j=N−N0+1
|aj||x −c|j ,
where M is an upper bound for |Rj(x)|. Since the series deﬁning A converges,
we ﬁnd on letting N →∞that
lim sup
N→∞
a0RN + a1(x −c)RN−1 + · · · + aN(x −c)NR0
 ≤ǫ · A .
Since ǫ > 0 was arbitrary, we may conclude that
lim
N→∞
a0RN + a1(x −c)RN−1 + · · · + aN(x −c)NR0
 = 0 .
Remark 9.4 Observe that the form of the product of two power series pro-
vides some motivation for the form that the product of numerical series took in
Theorem 3.42.
Next we turn to division of real analytic functions.
If f and g are real
analytic functions, both deﬁned on an open interval I, and if g does not vanish
on I, then we would like f/g to be a well-deﬁned real analytic function (it
certainly is a well-deﬁned function) and we would like to be able to calculate
its power series expansion by formal long division. This is what the next result
tells us.

9.1. POWER SERIES
187
Proposition 9.5 Let f and g be real analytic functions, both of which are
deﬁned on an open interval I. Assume that g does not vanish on I. Then the
function
h(x) = f(x)
g(x)
is real analytic on I. Moreover, if I is centered at the point c and if
f(x) =
∞
X
j=0
aj(x −c)j and g(x) =
∞
X
j=0
bj(x −c)j ,
then the power series expansion of h about c may be obtained by formal long
division of the latter series into the former. That is, the zeroeth coeﬃcient c0
of h is
c0 = a0/b0 ,
the order one coeﬃcient c1 is
c1 = 1
b0

a1 −a0b1
b0

,
etc.
Proof: If we can show that the power series
∞
X
j=0
cj(x −c)j
converges on I then the result on multiplication of series in Proposition 9.2
yields this new result. There is no loss of generality in assuming that c = 0.
Assume for the moment that b1 ̸= 0.
Notice that one may check inductively that, for j ≥1 ,
cj = 1
b0
(aj −b1 · cj−1) .
(9.5.1)
Without loss of generality, we may scale the ajs and the bjs and assume
that the radius of I is 1 + ǫ, some ǫ > 0. Then we see from the last displayed
formula that
|cj| ≤C · (|aj| + |cj−1|) ,
where C = max{|1/b0|, |b1/b0|}. It follows that
|cj| ≤C′ · (1 + |aj| + |aj−1| + · · · + |a0|) ,
Since the radius of I exceeds 1, P |aj| < ∞and we see that the |cj| are
bounded. Hence the power series with coeﬃcients cj has radius of convergence
1.

188
CHAPTER 9. ELEMENTARY TRANSCENDENTAL FUNCTIONS
In case b1 = 0 then the role of b1 is played by the ﬁrst nonvanishing
bm, m > 1. Then a new version of formula (9.5.1) is obtained and the argu-
ment proceeds as before.
In practice it is often useful to calculate f/g by expanding g in a “geometric
series.” To illustrate this idea, we assume for simplicity that f and g are real
analytic in a neighborhood of 0. Then
f(x)
g(x)
=
f(x) ·
1
g(x)
=
f(x) ·
1
b0 + b1x + · · ·
=
f(x) · 1
b0
·
1
1 + (b1/b0)x + · · · .
Now we use the fact that, for β small,
1
1 −β = 1 + β + β2 + · · · .
Setting β = −(b1/b0)x−(b2/b0)x2−· · · and substituting the resulting expansion
into our expression for f(x)/g(x) then yields a formula that can be multiplied
out to give a power series expansion for f(x)/g(x). We explore this technique
in the exercises.
Exercises
1. Prove that the composition of two real analytic functions, when the com-
position makes sense, is also real analytic.
2. Prove that
sin2 x + cos2 x = 1
directly from the power series expansions.
3. Let f(x) = P∞
j=0 ajxj be deﬁned by a power series convergent on the
interval (−r, r) and let Z denote those points in the interval where f
vanishes. Prove that if Z has an accumulation point in the interval then
f ≡0. (Hint: If a is the accumulation point, expand f in a power series
about a. What is the ﬁrst nonvanishing term in that expansion?)
*
4. Verify that the function
f(x) =
 0
if
x = 0
e−1/x2
if
x ̸= 0
is inﬁnitely diﬀerentiable on all of R and that f (k)(0) = 0 for every k.
However, f is certainly not real analytic.

9.2. MORE ON POWER SERIES: CONVERGENCE ISSUES
189
5. Use the technique described at the end of this section to calculate the ﬁrst
ﬁve terms of the power series expansion of sin x/ex about the origin.
6. Use the technique described at the end of this section to calculate the ﬁrst
ﬁve terms of the power series expansion of ln x/ sin(πx/2) about c = 1.
7. Provide the details of the method for dividing real analytic functions that
is described in the text.
8. Show that the inverse of a (suitable) real analytic function is real analytic.
9. Show that the solution of the diﬀerential equation y′ + y = x will be real
analytic.
10. Prove the assertion from the text that, if a power series converges at an
endpoint of the interval of convergence, then the convergence is uniform
up to that endpoint.
9.2
More on Power Series: Convergence Issues
We now introduce the Hadamard formula for the radius of convergence of a
power series.
Lemma 9.6 (Hadamard) For the power series
∞
X
j=0
aj(x −c)j ,
deﬁne A and ρ by
A = lim sup
n→∞|an|1/n ,
ρ =



0
if A = ∞,
1/A
if 0 < A < ∞,
∞
if A = 0 ,
then ρ is the radius of convergence of the power series about c.
Proof: Observing that
lim sup
n→∞|an(x −c)n|1/n = A|x −c| ,
we see that the lemma is an immediate consequence of the Root Test.
Corollary 9.7 The power series
∞
X
j=0
aj(x −c)j

190
CHAPTER 9. ELEMENTARY TRANSCENDENTAL FUNCTIONS
has radius of convergence ρ if and only if, when 0 < R < ρ, there exists a
constant 0 < C = CR such that
|an| ≤C
Rn .
From the power series
∞
X
j=0
aj(x −c)j
it is natural to create the derived series
∞
X
j=1
jaj(x −c)j
using term-by-term diﬀerentiation.
Proposition 9.8 The radius of convergence of the derived series is the same
as the radius of convergence of the original power series.
Proof: We observe that
lim sup
n→∞|nan|1/n
=
lim
n→∞n−1/n lim sup
n→∞|nan|1/n
=
lim sup
n→∞|an|1/n .
So the result follows from the Hadamard formula.
Proposition 9.9 Let f be a real analytic function deﬁned on an open interval
I.
Then f is continuous and has continuous, real analytic derivatives of all
orders. In fact the derivatives of f are obtained by diﬀerentiating its series
representation term by term.
Proof: Since, for each c ∈I, the function f may be represented by a convergent
power series with positive radius of convergence, we see that, in a suﬃciently
small open interval about each c ∈I, the function f is the uniform limit of a
sequence of continuous functions: the partial sums of the power series repre-
senting f. It follows that f is continuous at c. Since the radius of convergence
of the derived series is the same as that of the original series, it also follows
that the derivatives of the partial sums converge uniformly on an open interval
about c to a continuous function. It then follows from Theorem 8.13 that f is
diﬀerentiable and its derivative is the function deﬁned by the derived series. By
induction, f has continuous derivatives of all orders at c.
We can now show that a real analytic function has a unique power series
representation at any point.

9.2. MORE ON POWER SERIES: CONVERGENCE ISSUES
191
Corollary 9.10 If the function f is represented by a convergent power series
on an interval of positive radius centered at c,
f(x) =
∞
X
j=0
aj(x −c)j ,
then the coeﬃcients of the power series are related to the derivatives of the
function by
an = f (n)(c)
n!
.
Proof: This follows readily by diﬀerentiating both sides of the above equation
n times, as we may by the proposition, and evaluating at x = c.
Finally, we note that integration of power series is as well-behaved as dif-
ferentiation.
Proposition 9.11 The power series
∞
X
j=0
aj(x −c)j
and the series
∞
X
j=0
aj
j + 1(x −c)j+1
obtained from term-by-term integration have the same radius of convergence,
and the function F deﬁned by
F(x) =
∞
X
j=0
aj
j + 1(x −c)j+1
on the common interval of convergence satisﬁes
F ′(x) =
∞
X
j=0
aj(x −c)j = f(x) .
Proof: The proof is left to the exercises.
It is sometimes convenient to allow the variable in a power series to be a
complex number. In this case we write
∞
X
j=0
aj(z −c)j ,
where z is the complex argument. We now allow c and the ajs to be complex
numbers as well. Noting that the elementary facts about series hold for complex

192
CHAPTER 9. ELEMENTARY TRANSCENDENTAL FUNCTIONS
series as well as real series (you should check this for yourself), we see that the
arguments of this section show that the domain of convergence of a complex
power series is a disc in the complex plane with radius ρ given as follows:
A = lim sup
n→∞|an|1/n
ρ =



0
if
A = ∞
1/A
if
0 < A < ∞
∞
if
A = 0 .
The proofs in this section apply to show that convergent complex power series
may be added, subtracted, multiplied, and divided (provided that we do not
divide by zero) on their common domains of convergence. They may also be
diﬀerentiated and integrated term by term.
These observations about complex power series will be useful in the next
section.
We conclude this section with a consideration of Taylor series:
Theorem 9.12 (Taylor’s Expansion) For k a nonnegative integer, let f be
a k + 1 times continuously diﬀerentiable function on an open interval I = (a −
ǫ, a + ǫ). Then, for x ∈I,
f(x) =
k
X
j=0
f (j)(a)(x −a)j
j!
+ Rk,a(x),
where
Rk,a(x) =
Z x
a
f (k+1)(t)(x −t)k
k!
dt .
Proof: We apply integration by parts to the Fundamental Theorem of Calculus
to obtain
f(x)
=
f(a) +
Z x
a
f ′(t) dt
=
f(a) +

f ′(t)(t −x)
1!

x
a
−
Z x
a
f ′′(t)(t −x)
1!
dt
=
f(a) + f ′(a)(x −a)
1!
+
Z x
a
f ′′(t)x −t
1!
dt .
Notice that, when we performed the integration by parts, we used t −x as an
antiderivative for dt. This is of course legitimate, as a glance at the integration
by parts theorem reveals. We have proved the theorem for the case k = 1. The
result for higher values of k is obtained inductively by repeated applications of
integration by parts.

EXERCISES
193
Taylor’s theorem allows us to associate with any inﬁnitely diﬀerentiable
function a formal expansion of the form
∞
X
j=0
aj(x −a)j .
However, there is no guarantee that this series will converge; even if it does
converge, it may not converge back to f(x). An important example to keep in
mind is the function
h(x) =
 0
if
x = 0
e−1/x2
if
x ̸= 0.
This function is inﬁnitely diﬀerentiable at every point of the real line (including
the point 0—use l’Hˆopital’s Rule). However, all of its derivatives at x = 0 are
equal to zero (this matter will be treated in the exercises). Therefore the formal
Taylor series expansion of h about a = 0 is
∞
X
j=0
0 · (x −0)j = 0 .
We see that the formal Taylor series expansion for h converges to the zero
function at every x, but not to the original function h itself.
In fact the theorem tells us that the Taylor expansion of a function f con-
verges to f at a point x if and only if Rk,a(x) →0. In the exercises we shall
explore the following more quantitative assertion:
An inﬁnitely diﬀerentiable function f on an interval I has Taylor
series expansion about a ∈I that converges back to f on a neigh-
borhood J of a if and only if there are positive constants C, R such
that, for every x ∈J and every k, it holds that
f (k)(x)
 ≤C · k!
Rk .
The function h considered above should not be thought of as an isolated
exception. For instance, we know from calculus that the function f(x) = sin x
has Taylor expansion that converges to f at every x. But then, for ǫ small, the
function gǫ(x) = f(x) + ǫ · h(x) has Taylor series that does not converge back to
gǫ(x) for x ̸= 0. Similar examples may be generated by using other real analytic
functions in place of sine.
Exercises
1. Assume that a power series converges at one of the endpoints of its interval
of convergence. Use summation by parts to prove that the function deﬁned
by the power series is continuous on the half-closed interval including that
endpoint.

194
CHAPTER 9. ELEMENTARY TRANSCENDENTAL FUNCTIONS
*
2. The function deﬁned by a power series may extend continuously to an
endpoint of the interval of convergence without the series converging at
that endpoint. Give an example.
3. Let f be an inﬁnitely diﬀerentiable function on an interval I. If a ∈I and
there are positive constants C, R such that, for every x in a neighborhood
of a and every k, it holds that
f (k)(x)
 ≤C · k!
Rk ,
then prove that the Taylor series of f about a converges to f(x). (Hint:
estimate the error term.) What is the radius of convergence?
4. Let f be an inﬁnitely diﬀerentiable function on an open interval I centered
at a. Assume that the Taylor expansion of f about a converges to f at
every point of I.
Prove that there are constants C, R and a (possibly
smaller) interval J centered at a such that, for each x ∈J, it holds that
f (k)(x)
 ≤C · k!
Rk .
*
5. Prove that, if a function on an interval I has derivatives of all orders which
are positive at every point of I, then f is real analytic on I.
6. Give examples of power series, centered at 0, on the interval (−1, 1), which
(a) converge only on (−1, 1), (b) converge only on [−1, 1), (c) converge
only on (−1, 1], (d) converge only on [−1, 1].
7. Prove Proposition 9.11.
8. The real analytic function 1/(1 + x2) is well deﬁned on the entire real
line. Yet its power series about 0 only converges on an interval of radius
1. Explain why.
9. How does Exercise 8 diﬀer for the function 1/(1 −x2)?
9.3
The Exponential and Trigonometric Func-
tions
We begin by deﬁning the exponential function:
Deﬁnition 9.13 The power series
∞
X
j=0
zj
j!
converges, by the Ratio Test, for every complex value of z. The function deﬁned
thereby is called the exponential function and is written exp(z).

9.3. THE EXPONENTIAL AND TRIGONOMETRIC FUNCTIONS
195
Proposition 9.14 The function exp(z) satisﬁes
exp(a + b) = exp(a) · exp(b)
for any complex numbers a and b.
Proof: We write the righthand side as


∞
X
j=0
aj
j!

·


∞
X
j=0
bj
j!

.
Now convergent power series may be multiplied term by term. We ﬁnd that the
last line equals
∞
X
j=0
 j
X
ℓ=0
a(j−ℓ)
(j −ℓ)! · bℓ
ℓ!
!
.
(9.14.1)
However, the inner sum on the right side of this equation may be written as
1
j!
j
X
ℓ=0
j!
ℓ!(j −ℓ)!aj−ℓbℓ= 1
j!(a + b)j .
It follows that line (9.14.1) equals exp(a + b).
We set e = exp(1). This is consistent with our earlier treatment of the
number e in Section 3.4 The proposition tells us that, for any positive integer
k, we have
ek = e · e · · · e = exp(1) · exp(1) · · · exp(1) = exp(k) .
If m is another positive integer then
(exp(k/m))m = exp(k) = ek ,
whence
exp(k/m) = ek/m .
We may extend this formula to negative rational exponents by using the fact
that exp(a) · exp(−a) = 1. Thus, for any rational number q,
exp(q) = eq .
Now note that the function exp is increasing and continuous. It follows
(this fact is treated in the exercises) that if we set, for any r ∈R,
er = sup{q ∈Q : q < r}
(this is a deﬁnition of the expression er) then ex = exp(x) for every real x. [You
may ﬁnd it useful to review the discussion of exponentiation in Sections 2.4, 3.4;
the presentation here parallels those treatments.] We will adhere to custom and
write ex instead of exp(x) when the argument of the function is real.

196
CHAPTER 9. ELEMENTARY TRANSCENDENTAL FUNCTIONS
Proposition 9.15 The exponential function ex, for x ∈R, satisﬁes
(a) ex > 0 for all x;
(b) e0 = 1;
(c) (ex)′ = ex;
(d) ex is strictly increasing;
(e) the graph of ex is asymptotic to the negative x-axis
(f) for each integer N > 0 there is a number cN such that ex > cN · xN when
x > 0.
Proof: The ﬁrst three statements are obvious from the power series expansion
for the exponential function.
If s < t then the Mean Value Theorem tells us that there is a number ξ
between s and t such that
et −es = (t −s) · eξ > 0;
hence the exponential function is strictly increasing.
By inspecting the power series we see that ex > 1 + x hence ex increases to
+∞. Since ex · e−x = 1 we conclude that e−x tends to 0 as x →+∞. Thus the
graph of the exponential function is asymptotic to the negative x-axis.
Finally, by inspecting the power series for ex, we see that the last assertion
is true with cN = 1/N!.
Now we turn to the trigonometric functions. The deﬁnition of the trigono-
metric functions that is found in calculus texts is unsatisfactory because it relies
too heavily on a picture and because the continual need to subtract oﬀsuper-
ﬂuous multiples of 2π is clumsy. We have nevertheless used the trigonometric
functions in earlier chapters to illustrate various concepts. It is time now to give
a rigorous deﬁnition of the trigonometric functions that is independent of these
earlier considerations.
Deﬁnition 9.16 The power series
∞
X
j=0
(−1)j
x2j+1
(2j + 1)!
converges at every point of the real line (by the Ratio Test). The function that
it deﬁnes is called the sine function and is usually written sin x.
The power series
∞
X
j=0
(−1)j x2j
(2j)!
converges at every point of the real line (by the Ratio Test). The function that
it deﬁnes is called the cosine function and is usually written cos x.

9.3. THE EXPONENTIAL AND TRIGONOMETRIC FUNCTIONS
197
You may recall that the power series that we use to deﬁne the sine and
cosine functions are precisely the Taylor series expansions for the functions sine
and cosine that were derived in your calculus text. But now we begin with the
power series and must derive the properties of sine and cosine that we need from
these series.
In fact the most convenient way to achieve this goal is to proceed by way of
the exponential function. [The point here is mainly one of convenience. It can
be veriﬁed by direct manipulation of the power series that sin2 x + cos2 x = 1
and so forth but the algebra is extremely unpleasant.] The formula in the next
proposition is usually credited to Euler.
Proposition 9.17 The exponential function and the functions sine and cosine
are related by the formula (for x and y real and i2 = −1)
exp(x + iy) = ex · (cos y + i sin y) .
Proof: We shall verify the case x = 0 and leave the general case for the reader.
Thus we are to prove that
eiy = cos y + i sin y .
(9.17.1)
Writing out the power series for the exponential, we ﬁnd that the lefthand side
of (9.17.1) is
∞
X
j=0
(iy)j
j!
and this equals

1 −y2
2! + y4
4! −+ · · ·

+ i
 y
1! −y3
3! + y5
5! −+ · · ·

.
Of course the two series on the right are the familiar power series for cosine and
sine. Thus
eiy = cos y + i sin y ,
as desired.
In what follows, we think of the formula (9.17.1) as deﬁning what we mean
by eiy. As a result,
ex+iy = ex · eiy = ex · (cos y + i sin y) .
Notice that e−iy = cos(−y) + i sin(−y) = cos y −i sin y (we know that the sine
function is odd and the cosine function even from their power series expansions).
Then formula (9.17.1) tells us that
cos y = eiy + e−iy
2

198
CHAPTER 9. ELEMENTARY TRANSCENDENTAL FUNCTIONS
and
sin y = eiy −e−iy
2i
.
Now we may prove:
Proposition 9.18 For every real x it holds that
sin2 x + cos2 x = 1 .
Proof: Simply substitute into the left side the formulas for the sine and cosine
functions which were displayed before the proposition and simplify.
We list several other properties of the sine and cosine functions that may
be proved by similar methods. The proofs are requested of you in the exercises.
Proposition 9.19 The functions sine and cosine have the following properities:
(a) sin(s + t) = sin s cos t + cos s sin t;
(b) cos(s + t) = cos s cos t −sin s sin t;
(c) cos(2s) = cos2 s −sin2 s;
(d) sin(2s) = 2 sin s cos s;
(e) sin(−s) = −sin s;
(f) cos(−s) = cos s;
(g) sin′(s) = cos s;
(h) cos′(s) = −sin s.
One important task to be performed in a course on the foundations of
analysis is to deﬁne the number π and establish its basic properties.
In a
course on Euclidean geometry, the constant π is deﬁned to be the ratio of the
circumference of a circle to its diameter. Such a deﬁnition is not useful for our
purposes (however, it is consistent with the deﬁnition about to be given here).
Observe that cos 0 is the real part of ei0 which is 1. Thus if we set
α = inf{x > 0 : cos x = 0}
then α > 0 and, by the continuity of the cosine function, cos α = 0. We deﬁne
π = 2α.
Applying Proposition 9.18 to the number α yields that sin α = ±1. Since
α is the ﬁrst zero of cosine on the right half line, the cosine function must be
positive on (0, α). But cosine is the derivative of sine. Thus the sine function
is increasing on (0, α). Since sin 0 is the imaginary part of ei0 which is 0, we
conclude that sin α > 0 hence that sin α = +1.

EXERCISES
199
Now we may apply parts (c) and (d) of Proposition 9.19 with s = α to
conclude that sin π = 0 and cos π = −1. A similar calculation with s = π
shows that sin 2π = 0 and cos 2π = 1. Next we may use parts (a) and (b) of
Proposition 9.19 to calculate that sin(x + 2π) = sin x and cos(x + 2π) = cos x
for all x. In other words, the sine and cosine functions are 2π−periodic.
The business of calculating a decimal expansion for π would take us far
aﬁeld. One approach would be to utilize the already-noted fact that the sine
function is strictly increasing on the interval [0, π/2] hence its inverse function
Sin−1 : [0, 1] →[0, π/2]
is well deﬁned. Then one can determine (see Chapter 6) that
 Sin−1′ (x) =
1
√
1 −x2 .
By the Fundamental Theorem of Calculus,
π
2 = Sin−1(1) =
Z 1
0
1
√
1 −x2 dx .
By approximating the integral by its Riemann sums, one obtains an approxi-
mation to π/4 and hence to π itself. This approach will be explored in more
detail in the exercises.
Let us for now observe that
cos 2
=
1 −22
2! + 24
4! −26
6! + −· · ·
=
1 −2 + 16
24 −64
720 + . . . .
Since the series deﬁning cos 2 is an alternating series with terms that strictly de-
crease to zero in magnitude, we may conclude (following reasoning from Chapter
4) that the last line is less than the sum of the ﬁrst three terms:
cos 2 < −1 + 2
3 < 0 .
It follows that α = π/2 < 2 hence π < 4. A similar calculation of cos(3/2)
would allow us to conclude that π > 3.
Exercises
1. Provide the details of the assertion preceding Proposition 9.15 to the eﬀect
that if we deﬁne, for any real R,
er = sup{q ∈Q : q < r} ,
then ex = exp(x) for every real x.

200
CHAPTER 9. ELEMENTARY TRANSCENDENTAL FUNCTIONS
2. Prove the equality
 Sin−1′ = 1/
√
1 −x2.
3. Prove that
cos 2x = cos2 x −sin2 x
directly from the power series expansions.
4. Prove that
sin 2x = 2 sin x cos x
directly from the power series expansions.
5. Use one of the methods described at the end of Section 3 to calculate π
to two decimal places.
6. Prove Proposition 9.19.
*
7. Complete the following outline of a proof of Ivan Niven (see [NIV]) that
π is irrational:
(a) Deﬁne
f(x) = xn(1 −x)n
n!
,
where n is a positive integer to be selected later. For each 0 < x < 1
we have
0 < f(x) < 1/n!.
(∗)
(b) For every positive integer j we have f (j)(0) is an integer.
(c) f(1 −x) = f(x) hence f (j)(1) is an integer for every positive integer
j.
(d) Seeking a contradiction, assume that π is rational. Then π2 is ratio-
nal. Thus we may write π2 = a/b, where a, b are positive integers
and the fraction is in lowest terms.
(e) Deﬁne
F(x) = bn  π2nf(x)
−π2n−2f (2)(x) + π2n−4f (4)(x)
−· · · + (−1)nf (2n)(x)

.
Then F(0) and F(1) are integers.
(f) We have
d
dx [F ′(x) sin(πx)
−πF(x) cos(πx)]
= π2anf(x) sin(πx) .

EXERCISES
201
(g) We have
πan
Z 1
0
f(x) sin(πx) dx
=
F ′(x) sin x
π
−F(x) cos πx
1
0
= F(1) + F(0).
(h) From this and (∗) we conclude that
0 < πan
Z 1
0
f(x) sin(πx) dx
< πan
n! < 1.
When n is suﬃciently large this contradicts the fact that F(0)+F(1)
is an integer.
8. Prove that the trigonometric polynomials, that is to say, the functions of
the form
p(x) =
N
X
j=−N
ajeijx ,
are dense in the continuous functions on [0, 2π] in the uniform topology.
9. Prove the general case of Proposition 9.17.
10. Find a formula for tan4 x in terms of sin 2x, sin 4x, cos 2x, and cos 4x.
9.4
Logarithms and Powers of Real Numbers
Since the exponential function exp(x) = ex is positive and strictly increasing it
is a one-to-one function from R to (0, ∞). Thus it has a well-deﬁned inverse
function that we call the natural logarithm. We write this function as ln x.
Proposition 9.20 The natural logarithm function has the following properties:
(a) (ln x)′ = 1/x;
(b) ln x is strictly increasing;
(c) ln(1) = 0;
(d) ln e = 1;
(e) the graph of the natural logarithm function is asymptotic to the negative
y axis;
(f) ln(s · t) = ln s + ln t;

202
CHAPTER 9. ELEMENTARY TRANSCENDENTAL FUNCTIONS
(g) ln(s/t) = ln s −ln t.
Proof: These follow immediately from corresponding properties of the expo-
nential function. For example, to verify part (f), set s = eσ and t = eτ. Then
ln(s · t)
=
ln(eσ · eτ)
=
ln(eσ+τ)
=
σ + τ
=
ln s + ln t .
The other parts of the proposition are proved similarly.
Proposition 9.21 If a and b are positive real numbers then
ab = eb·ln a .
Proof: When b is an integer then the formula may be veriﬁed directly using
Proposition 9.20, part (f). For b = m/n a rational number the formula follows
by our usual trick of passing to nth roots. For arbitrary b we use a limiting
argument as in our discussions of exponentials in Sections 2.3 and 9.3.
Remark 9.22 We have discussed several diﬀerent approaches to the exponen-
tiation process. We proved the existence of nth roots, n ∈N, as an illustration
of the completeness of the real numbers (by taking the supremum of a certain
set). We treated rational exponents by composing the usual arithmetic process
of taking mth powers with the process of taking nth roots. Then, in Sections
2.4 and 9.3, we passed to arbitrary powers by way of a limiting process.
Proposition 9.21 gives us a uniﬁed and direct way to treat all exponentials at
once. This uniﬁed approach will prove (see the next proposition) to be particu-
larly advantageous when we wish to perform calculus operations on exponential
functions.
Proposition 9.23 Fix a > 0. The function f(x) = ax has the following prop-
erties:
(a) (ax)′ = ax · ln a;
(b) f(0) = 1;
(c) if 0 < a < 1 then f is decreasing and the graph of f is asymptotic to the
positive x-axis;
(d) if 1 < a then f is increasing and the graph of f is asymptotic to the
negative x-axis.

EXERCISES
203
Proof: These properties follow immediately from corresponding properties of
the function exp.
The logarithm function arises, among other places, in the context of prob-
ability and in the study of entropy. The reason is that the logarithm function
is uniquely determined by the way that it interacts with the operation of mul-
tiplication:
Theorem 9.24 Let φ(x) be a continuously diﬀerentiable function with domain
the positive reals and which satisﬁes the identity
φ (s · t) = φ(s) + φ(t)
(9.24.1)
for all positive s and t. Then there is a constant C > 0 such that
φ(x) = C · ln x
for all x.
Proof: Diﬀerentiate the equation (9.24.1) with respect to s to obtain
t · φ′(s · t) = φ′(s) .
Now ﬁx s and set t = 1/s to conclude that
φ′(1) · 1
s = φ′(s) .
We take the constant C to be φ′(1) and apply Proposition 9.20(a) to conclude
that φ(s) = C · ln s + D for some constant D. But φ cannot satisfy (9.24.1)
unless D = 0, so the theorem is proved.
Observe that the natural logarithm function is then the unique continuously
diﬀerentiable function that satisﬁes the condition (9.24.1) and whose derivative
at 1 equals 1. That is the reason that the natural logarithm function (rather
than the common logarithm, or logarithm to the base ten) is singled out as the
focus of our considerations in this section.
Exercises
1. Prove Proposition 9.23 by following the hint provided.
2. Prove Proposition 9.20, except for part (f).
3. Prove that condition (9.24.1) implies that φ(1) = 0. Assume that φ is
diﬀerentiable at x = 1 but make no other hypothesis about the smoothness
of φ. Prove that condition (9.24.1) then implies that φ is diﬀerentiable at
every x > 0.

204
CHAPTER 9. ELEMENTARY TRANSCENDENTAL FUNCTIONS
4. Show that the hypothesis of Theorem 9.24 may be replaced with f ∈
Lipα([0, 2π]), some α > 0.
5. Provide the details of the proof of Proposition 9.21.
6. Calculate
lim
j→∞
jj/2
j! .
*
7. The Lambert W function is deﬁned implicitly by the equation
z = W(z) · eW(z) .
It is a fact that any elementary transcendental function may be expressed
(with an elementary formula) in terms of the W function. Prove that this
is so for the exponential function and the sine function.
*
8. Prove Euler’s formula relating the exponential to sine and cosine not by
using power series, but rather by using diﬀerential equations.
9. Give three distinct reasons why the natural logarithm function is not a
polynomial.
10. At inﬁnity, any nontrivial polynomial function dominates the natural log-
arithm function. Explain what this means, and prove it.

Chapter 10
Applications of Analysis to
Diﬀerential Equations
Diﬀerential equations are the heart and soul of analysis. Virtually any law of
physics or engineering or biology or chemistry can be expressed as a diﬀerential
equation—and frequently as a ﬁrst-order equation (i.e., an equation involving
only ﬁrst derivatives). Much of mathematical analysis has been developed in
order to ﬁnd techniques for solving diﬀerential equations.
Most introductory books on diﬀerential equations ([COL] and [BIR] are two
excellent texts) devote themselves to elementary techniques for ﬁnding solutions
to a very limited selection of equations. In the present book we take a diﬀerent
point of view. We instead explore certain central and broadly applicable prin-
ciples which apply to virtually any diﬀerential equation. These principles, in
particular, illustrate some of the key ideas of the book.
10.1
Picard’s Existence and Uniqueness Theo-
rem
10.1.1
The Form of a Diﬀerential Equation
A fairly general ﬁrst-order diﬀerential equation will have the form
dy
dx = F(x, y) .
(10.1.1)
Here F is a continuously diﬀerentiable function on some domain (a, b) × (c, d).
We think of y as the dependent variable (that is, the function that we seek) and
x as the independent variable. That is to say, y = y(x). For technical reasons,
we assume that the function F is bounded,
|F(x, y)| ≤M ,
(10.1.2)
205

206
CHAPTER 10. DIFFERENTIAL EQUATIONS
and in addition that F satisﬁes a Lipschitz condition:
|F(x, s) −F(x, t)| ≤C · |s −t| .
(10.1.3)
[In many treatments it is standard to assume that F is bounded and ∂F/∂y
is bounded. It is easy to see, using the mean value theorem, that these two
conditions imply (10.1.2), (10.1.3).]
Example 10.2 Consider the equation
dy
dx = x2 sin y −y ln x .
Then this equation ﬁts the paradigm of equation (10.1.1) with F(x, y) = x2 sin y−
y ln x provided that 1 ≤x ≤2 and 0 ≤y ≤3 (for instance).
In fact the most standard, and physically appealing, setup for a ﬁrst-order
equation such as (10.1.1) is to adjoin to it an initial condition.
For us this
condition will have the form
y(x0) = y0 .
(10.1.4)
Thus the problem we wish to solve is (10.1.1) and (10.1.4) together.
Picard’s idea is to set up an iterative scheme for doing so. The most re-
markable fact about Picard’s technique is that it always works: As long as F
satisﬁes the Lipschitz condition, then the problem will possess one and only one
solution.
10.1.2
Picard’s Iteration Technique
While we will not actually give a complete proof that Picard’s technique works,
we will set it up and indicate the sequence of functions it produces that converges
uniformly to the solution of our problem.
Picard’s approach is inspired by the fact that the diﬀerential equation
(10.1.1) and initial condition (10.1.4), taken together, are equivalent to the
single integral equation
y(x) = y0 +
Z x
x0
F(t, y(t)) dt .
(10.1.5)
We invite the reader to diﬀerentiate both sides of this equation, using the Funda-
mental Theorem of Calculus, to derive the original diﬀerential equation (10.1.1).
Of course the initial condition (10.1.4) is built into (10.1.5). This integral equa-
tion inspires the iteration scheme that we now describe.
We assume that x0 ∈(a, b) and that y0 ∈(c, d). We set
y1(x) = y0 +
Z x
x0
F(t, y0) dt .

10.1. PICARD’S EXISTENCE AND UNIQUENESS THEOREM
207
For x near to x0, this deﬁnition makes sense. Now we deﬁne
y2(x) = y0 +
Z x
x0
F(t, y1(t)) dt
and, more generally,
yj+1(x) = y0 +
Z x
x0
F(t, yj(t)) dt .
(10.1.6)
It turns out that the sequence of functions {y1, y2, . . . } will converge uniformly
on an interval of the form (x0 −h, x0 + h) ⊆(a, b).
10.1.3
Some Illustrative Examples
Picard’s iteration method is best apprehended by way of some examples that
show how the iterates arise and how they converge to a solution.
We now
proceed to develop such illustrations.
Example 10.3 Consider the initial value problem
y′ = 2y ,
y(0) = 1 .
Of course this could easily be solved by the method of ﬁrst order linear
equations, or by separation of variables (see [KRS] for a description of these
methods). Our purpose here is to illustrate how the Picard method works.
First notice that the stated initial value problem is equivalent to the integral
equation
y(x) = 1 +
Z x
0
2y(t) dt .
Following the paradigm (10.1.6), we thus ﬁnd that
yj+1(x) = 1 +
Z x
0
2yj(x) dx .
Using y0 = 1, we then ﬁnd that
y1(x)
=
1 +
Z x
0
2 dt = 1 + 2x ,
y2(x)
=
1 +
Z x
0
2(1 + 2t) dt = 1 + 2x + 2x2 ,
y3(x)
=
1 +
Z x
0
2(1 + 2t + 2t2) dt = 1 + 2x + 2x2 + 4x3
3
.
In general, we ﬁnd that
yj(x) = 1 + 2x
1! + (2x)2
2!
+ (2x)3
3!
+ · · · + (2x)j
j!
=
j
X
ℓ=0
(2x)ℓ
ℓ!
.

208
CHAPTER 10. DIFFERENTIAL EQUATIONS
It is plain that these are the partial sums for the power series expansion of
y = e2x. We conclude that the solution of our initial value problem is y = e2x.
You are encouraged to check that y = e2x does indeed solve the diﬀerential
equation and initial condition stated at the beginning of the example.
Example 10.4 Let us use Picard’s method to solve the initial value problem
y′ = 2x −y ,
y(0) = 1 .
The equivalent integral equation is
y(x) = 1 +
Z x
0
[2t −y(t)] dt
and (10.1.6) tells us that
yj+1(x) = 1 +
Z x
0
[2t −yj(t)] dt .
Taking y0 = 1, we then ﬁnd that
y1(x)
=
1 +
Z x
0
(2t −1) dt = 1 + x2 −x ,
y2(x)
=
1 +
Z x
0
 2t −[1 + t2 −t]

dt
= 1 + 3x2
2
−x −x3
3 ,
y3(x)
=
1 +
Z x
0
 2t −[1 + 3t2/2 −t −t3/3]

dt
= 1 + 3x2
2
−x −x3
2 + x4
4 · 3 ,
y4(x)
=
1 +
Z x
0
 2t −[1 + 3t2/2 −t −t3/2 + t4/4 · 3]

dt
= 1 + 3x2
2
−x −x3
2 + x4
4 · 2 −
x5
5 · 4 · 3 .
In general, we ﬁnd that
yj(x)
=
1 −x + 3x2
2! −3x3
3! + 3x4
4! −+ · · ·
+(−1)j 3xj
j! + (−1)j+1 2xj+1
(j + 1)!
=
[2x −2] + 3 ·
j
X
ℓ=0
(−x)j
j!
+ (−1)j+1 2xj+1
(j + 1)! .
Of course the last term tends to 0 as j →+∞. Thus we see that the iterates
yj(x) converge to the solution y(x) = [2x−2]+3e−x for the initial value problem.
Check that this function does indeed satisfy the given diﬀerential equation and
initial condition.

10.1. PICARD’S EXISTENCE AND UNIQUENESS THEOREM
209
10.1.4
Estimation of the Picard Iterates
To get an idea of why the assertion at the end of Subsection 10.1.2—that the
functions yj converge uniformly—is true, let us do some elementary estimations.
Choose h > 0 so small that h·C < 1, where C is the constant from the Lipschitz
condition (10.1.3). We will assume in the following calculations that |x−x0| < h.
Now we proceed with the iteration. Let y0 be the initial value as usual.
Then
|y0 −y1(t)|
=

Z x
x0
F(t, y0) dt

≤
Z x
x0
|F(t, y0)| dt
≤
M · |x −x0|
≤
M · h .
We have of course used the boundedness condition (10.1.2).
Next we have
|y1(x) −y2(x)|
=

Z x
x0
F(t, y0(t)) dt −
Z x
x0
F(t, y1(t)) dt

≤
Z x
x0
|F(t, y0(t)) −F(t, y1(t))| dt
≤
Z x
x0
C · |y0(t) −y1(t)| dt
≤
C · M · h · h
=
M · C · h2 .
One can continue this procedure to ﬁnd that
|y2(x) −y3(x)| ≤M · C2 · h3 = M · h · (Ch)2 .
and, more generally,
|yj(x) −yj+1(x)| ≤M · Cj · hj+1 < M · h · (Ch)j .
Now, if 0 < K < L are integers, then
|yK(x) −yL(x)|
≤
|yK(x) −yK+1(x)| + |yK+1(x) −yK+2(x)|
+ · · · + |yL−1(x) −yL(x)|
≤
M · h ·
 [Ch]K + [Ch]K+1 + · · · [Ch]L−1
.
Since |Ch| < 1 by design, the geometric series P
j[Ch]j converges. As a result,
the expression on the right of our last display is as small as we please, for K
and L large, just by the Cauchy criterion for convergent series. It follows that

210
CHAPTER 10. DIFFERENTIAL EQUATIONS
the sequence {yj} of approximate solutions converges uniformly to a function
y = y(x). In particular, y is continuous.
Furthermore, we know that
yj+1(x) = y0 +
Z x
x0
F(t, yj(t)) dt .
Letting j →∞, and invoking the uniform convergence of the yj, we may pass
to the limit and ﬁnd that
y(x) = y0 +
Z x
x0
F(t, y(x)) dt .
This says that y satisﬁes the integral equation that is equivalent to our original
initial value problem. This equation also shows that y is continuously diﬀeren-
tiable. Thus y is the function that we seek.
It can be shown that this y is in fact the unique solution to our initial value
problem. We shall not provide the details of the proof of this assertion.
In case F is not Lipschitz—say that F is only continuous—then it is still
possible to show that a solution y exists. But it will no longer be unique.
Exercises
1. Use the method of Picard iteration to solve the initial value problem y′ =
y + x, y(0) = 1.
2. A vector ﬁeld is a function
F(x, y) = ⟨α(x, y), β(x, y)⟩
that assigns to each point in the plane R2 a vector.
We call a curve
γ : (a, b) →R2 an integral curve of the vector ﬁeld if
γ′(t) = F(γ(t))
for each t. Thus γ “ﬂows along” the vector ﬁeld, and the tangent to the
curve at each point is given by the value of the vector ﬁeld at that point.
Put suitable conditions on F that will guarantee that if P ∈R2 then there
will be an integral curve for F through the point P. [Hint: Of course use
the Picard theorem to obtain your result. What is the correct initial value
problem?]
3. Give an example which illustrates that the integral curve that you found
in Exercise 2 will only, in general, be deﬁned in a small neighborhood of
P. [Hint: Think of a vector ﬁeld that “dies out.”]
4. Refer to Exercises 2 and 3. Find integral curves for each of the following
vector ﬁelds:

EXERCISES
211
(a) F(x, y) = (−y, x)
(b) F(x, y) = (x + 1, y −2)
(c) F(x, y) = (2xy, x2)
(d) F(x, y) = (−x, 2y)
5. For each diﬀerential equation, sketch the family of solutions on a set of
axes:
(a) y′ −xy = 1
(b) y′ + y = ex
(c) y′ = x
(d) y′ = 1 −y
*
6. Does the Picard theorem apply to the initial value problem
edy/dx + dy
dx = x2 ,
y(1) = 2 ?
Why or why not? [Hint: Think in terms of the Implicit Function Theorem—
Section 12.3.]
7. Formulate a version of the Picard theorem for vector-valued functions.
Indicate how its proof diﬀers, if at all, from the proof for scalar-valued
functions. Now explain how one can use this vector-valued version of Pi-
card to obtain an existence and uniqueness theorem for kth-order ordinary
diﬀerential equations.
8. Verify that the function y = 1/
p
2(x + 1) is a solution of the diﬀerential
equation
y′ + y3 = 0 .
(∗)
Can you use separation of variables to ﬁnd the general solution? [Hint:
It is y = 1/
p
2(x + c).] Now ﬁnd the solution to the initial value problem
(∗) with initial condition y(1) = 4.
9. Check that the function
y =
r
2
3 ln(1 + x2) + C
solves the diﬀerential equation
dy
dx =
2x
3y + 3yx2 .
Find the particular solution that satisﬁes the initial condition y(0) = 2.
10. In the method of Picard, suppose that the function F is given by a power
series. Formulate a version of the Picard iteration technique in the lan-
guage of power series.

212
CHAPTER 10. DIFFERENTIAL EQUATIONS
10.2
Power Series Methods
One of the techniques of broadest applicability in the subject of diﬀerential
equations is that of power series, or real analytic functions. The philosophy is
to guess that a given problem has a solution that may be represented by a power
series, and then to endeavor to solve for the coeﬃcients of that series. Along the
way, one uses (at least tacitly) fundamental properties of these series—that they
may be diﬀerentiated and integrated term by term, for instance. And that their
intervals of convergence are preserved under standard arithmetic operations.
Example 10.5 Let p be an arbitrary real constant. Let us use a diﬀerential
equation to derive the power series expansion for the function
y = (1 + x)p .
Of course the given y is a solution of the initial value problem
(1 + x) · y′ = py ,
y(0) = 1 .
We assume that the equation has a power series solution
y =
∞
X
j=0
ajxj = a0 + a1x + a2x2 + · · ·
with positive radius of convergence R. Then
y′ =
∞
X
j=1
j · ajxj−1 = a1 + 2a2x + 3a3x2 + · · · ;
xy′ =
∞
X
j=1
j · ajxj = a1x + 2a2x2 + 3a3x3 + · · · ;
py =
∞
X
j=0
pajxj = pa0 + pa1x + pa2x2 + · · · .
By the diﬀerential equation, we see that the sum of the ﬁrst two of these series
equals the third. Thus
∞
X
j=1
jajxj−1 +
∞
X
j=1
jajxj =
∞
X
j=0
pajxj .
We immediately see two interesting anomalies: the powers of x on the lefthand
side do not match up, so the two series cannot be immediately added. Also the
summations do not all begin in the same place. We address these two concerns
as follows.

10.2. POWER SERIES METHODS
213
First, we can change the index of summation in the ﬁrst sum on the left to
obtain
∞
X
j=0
(j + 1)aj+1xj +
∞
X
j=1
jajxj =
∞
X
j=0
pajxj .
Write out the ﬁrst few terms of the new sum, and the original sum, to see that
they are just the same.
Now every one of our series has xj in it, but they begin at diﬀerent places.
So we break oﬀthe extra terms as follows:
∞
X
j=1
(j + 1)aj+1xj +
∞
X
j=1
jajxj −
∞
X
j=1
pajxj = −a1x0 + pa0x0 .
(10.5.1)
Notice that all we have done is to break oﬀthe zeroeth terms of the ﬁrst and
third series, and put them on the right.
The three series on the lefthand side of (10.5.1) are begging to be put
together: they have the same form, they all involve powers of x, and they all
begin at the same index. Let us do so:
∞
X
j=1

(j + 1)aj+1 + jaj −paj

xj = −a1 + pa0 .
Now the powers of x that appear on the left are 1, 2, . . . , and there are none
of these on the right. We conclude that each of the coeﬃcients on the left is
zero; by the same reasoning, the coeﬃcient (−a1 + pa0) on the right (i.e., the
constant term) equals zero. So we have the equations1
−a1 + pa0
=
0
(j + 1)aj+1 + (j −p)aj
=
0 .
Our initial condition tells us that a0 = 1. Then our ﬁrst equation implies
that a1 = p. The next equation, with j = 1, says that
2a2 + (1 −p)a1 = 0 .
Hence a2 = (p −1)a1/2 = (p −1)p/2. Continuing, we take j = 2 in the second
equation to get
3a3 + (2 −p)a2 = 0
so a3 = (p −2)a2/3 = (p −2)(p −1)p/(3 · 2).
We may continue in this manner to obtain that
aj = p(p −1)(p −2) · · · (p −j + 1)
j!
.
1A set of equations like this is called a recursion. It expresses ajs with later indices in
terms of ajs with earlier indices.

214
CHAPTER 10. DIFFERENTIAL EQUATIONS
Thus the power series expansion for our solution y is
y
=
1 + px + p(p −1)
2!
x2 + p(p −1)(p −2)
3!
x3 + · · ·
+p(p −1)(p −2) · · · (p −j + 1)
j!
xj + · · · .
Since we knew in advance that the solution of our initial value problem was
y = (1 + x)p ,
we ﬁnd that we have derived Isaac Newton’s general binomial theorem (or bi-
nomial series):
(1 + x)p
=
1 + px + p(p −1)
2!
x2 + p(p −1)(p −2)
3!
x3 + · · ·
+p(p −1)(p −2) · · · (p −j + 1)
j!
xj + · · · .
Example 10.6 Let us consider the diﬀerential equation
y′ = y .
Of course we know from elementary considerations that the solution to this
equation is y = C · ex, but let us pretend that we do not know this. Our goal
is to instead use power series to discover the solution. We proceed by guessing
that the equation has a solution given by a power series, and we proceed to
solve for the coeﬃcients of that power series.
So our guess is a solution of the form
y = a0 + a1x + a2x2 + a3x3 + · · · .
Then
y′ = a1 + 2a2x + 3a3x2 + · · · ,
and we may substitute these two expressions into the diﬀerential equation. Thus
a1 + 2a2x + 3a3x2 + · · · = a0 + a1x + a2x2 + · · · .
Now the powers of x must match up (i.e., the coeﬃcients must be equal). We
conclude that
a1
=
a0
2a2
=
a1
3a3
=
a2

10.2. POWER SERIES METHODS
215
and so forth. Let us take a0 to be an unknown constant C. Then we see that
a1
=
C ;
a2
=
C
2 ;
a3
=
C
3 · 2 ;
etc.
In general,
an = C
n! .
In summary, our power series solution of the original diﬀerential equation is
y =
∞
X
j=0
C
j!xj = C ·
∞
X
j=0
xj
j! = C · ex .
Thus we have a new way, using power series, of discovering the general solution
of the diﬀerential equation y′ = y.
Example 10.7 Let us use the method of power series to solve the diﬀerential
equation
(1 −x2)y′′ −2xy′ + p(p + 1)y = 0 .
(10.7.1)
Here p is an arbitrary real constant. This is called Legendre’s equation.
We therefore guess a solution of the form
y =
∞
X
j=0
ajxj = a0 + a1x + a2x2 + · · ·
and calculate
y′ =
∞
X
j=1
jajxj−1 = a1 + 2a2x + 3a3x2 + · · ·
and
y′′ =
∞
X
j=2
j(j −1)ajxj−2 = 2a2 + 3 · 2 · a3x + · · · .
It is most convenient to treat the diﬀerential equation in the form (10.7.1). We
calculate
−x2y′′ = −
∞
X
j=2
j(j −1)ajxj
and
−2xy′ = −
∞
X
j=1
2jajxj .

216
CHAPTER 10. DIFFERENTIAL EQUATIONS
Substituting into the diﬀerential equation now yields
∞
X
j=2
j(j −1)ajxj−2 −
∞
X
j=2
j(j −1)ajxj −
∞
X
j=1
2jajxj + p(p + 1)
∞
X
j=0
ajxj = 0 .
We adjust the index of summation in the ﬁrst sum so that it contains xj rather
than xj−2 and we break oﬀspare terms and collect them on the right. The
result is
∞
X
j=2
(j + 2)(j + 1)aj+2xj −
∞
X
j=2
j(j −1)ajxj
−
∞
X
j=2
2jajxj + p(p + 1)
∞
X
j=2
ajxj
=
−2a2 −6a3x + 2a1x −p(p + 1)a0 −p(p + 1)a1x .
In other words,
∞
X
j=2

(j + 2)(j + 1)aj+2 −j(j −1)aj −2jaj + p(p + 1)aj

xj
=
−2a2 −6a3x + 2a1x −p(p + 1)a0 −p(p + 1)a1x .
As a result,

(j + 2)(j + 1)aj+2 −j(j −1)aj −2jaj + p(p + 1)aj

= 0
for j = 2, 3, . . .
together with
−2a2 −p(p + 1)a0 = 0
and
−6a3 + 2a1 −p(p + 1)a1 = 0 .
We have arrived at the recursion
a2 = −p(p + 1)
1 · 2
· a0 ,
a3 = −(p −1)(p + 2)
2 · 3
· a1 ,
aj+2 = −(p −j)(p + j + 1)
(j + 2)(j + 1)
· aj
for j = 2, 3, . . . .
(10.7.2)
We recognize a familiar pattern: The coeﬃcients a0 and a1 are unspeciﬁed, so
we set a0 = A and a1 = B. Then we may proceed to solve for the rest of the
coeﬃcients. Now
a2 = −p(p + 1)
2
· A ,

10.2. POWER SERIES METHODS
217
a3 = −(p −1)(p + 2)
2 · 3
· B ,
a4 = −(p −2)(p + 3)
3 · 4
a2 = p(p −2)(p + 1)(p + 3)
4!
· A ,
a5
=
−(p −3)(p + 4)
4 · 5
a3
=
(p −1)(p −3)(p + 2)(p + 4)
5!
· B ,
a6
=
−(p −4)(p + 5)
5 · 6
a4
=
−p(p −2)(p −4)(p + 1)(p + 3)(p + 5)
6!
· A ,
a7
=
−(p −5)(p + 6)
6 · 7
a5
=
−(p −1)(p −3)(p −5)(p + 2)(p + 4)(p + 6)
7!
· B ,
and so forth. Putting these coeﬃcient values into our supposed power series
solution we ﬁnd that the general solution of our diﬀerential equation is
y
=
A

1 −p(p + 1)
2!
x2 + p(p −2)(p + 1)(p + 3)
4!
x4
−p(p −2)(p −4)(p + 1)(p + 3)(p + 5)
6!
x6 + −· · ·

+B

x −(p −1)(p + 2)
3!
x3 + (p −1)(p −3)(p + 2)(p + 4)
5!
x5
−(p −1)(p −3)(p −5)(p + 2)(p + 4)(p + 6)
7!
x7 + −· · ·

.
We assure the reader that, when p is not an integer, then these are not
familiar elementary transcendental functions. They are what we call Legendre
functions.
In the special circumstance that p is a positive even integer, the
ﬁrst function (that which is multiplied by A) terminates as a polynomial. In
the special circumstance that p is a positive odd integer, the second function
(that which is multiplied by B) terminates as a polynomial. These are called
Legendre polynomials, and they play an important role in mathematical physics,
representation theory, and interpolation theory.
Some diﬀerential equations have singularities. In the present context, this
means that the higher order terms have coeﬃcients that vanish to high degree.
As a result, one must make a slightly more general guess as to the solution of the
equation. This more general guess allows for a corresponding singularity to be
built into the solution. Rather than develop the full theory of these Frobenius
series, we merely give one example.

218
CHAPTER 10. DIFFERENTIAL EQUATIONS
Example 10.8 We use the method of Frobenius series to solve the diﬀerential
equation
2x2y′′ + x(2x + 1)y′ −y = 0
(10.8.1)
about the regular singular point 0.
We guess a solution of the form
y = xm ·
∞
X
j=0
ajxj =
∞
X
j=0
ajxm+j
and therefore calculate that
y′ =
∞
X
j=0
(m + j)ajxm+j−1
and
y′′ =
∞
X
j=0
(m + j)(m + j −1)ajxm+j−2 .
Substituting these calculations into the diﬀerential equation yields
2
∞
X
j=0
(m + j)(m + j −1)ajxm+j
+2
∞
X
j=0
(m + j)ajxm+j+1
+
∞
X
j=0
(m + j)ajxm+j −
∞
X
j=0
ajxm+j
= 0 .
We make the usual adjustments in the indices so that all powers of x are
xm+j, and break oﬀthe odd terms to put on the righthand side of the equation.
We obtain
2
∞
X
j=1
(m + j)(m + j −1)ajxm+j
+2
∞
X
j=1
(m + j −1)aj−1xm+j
+
∞
X
j=1
(m + j)ajxm+j −
∞
X
j=1
ajxm+j
=
−2m(m −1)a0xm −ma0xm + a0xm .

10.2. POWER SERIES METHODS
219
The result is

2(m + j)(m + j −1)aj + 2(m + j −1)aj−1
+(m + j)aj −aj

= 0
for j = 1, 2, 3, . . .
(10.8.2)
together with
[−2m(m −1) −m + 1]a0 = 0 .
It is clearly not to our advantage to let a0 = 0. Thus
−2m(m −1) −m + 1 = 0 .
This is the indicial equation.
The roots of this quadratic equation are m = −1/2, 1. We put each of these
values into (10.8.2) and solve the resulting recursion.
Now (10.8.2) says that
(2m2 + 2j2 + 4mj −j −m −1)aj = (−2m −2j + 2)aj−1 .
For m = −1/2 this is
aj =
3 −2j
−3j + 2j2 aj−1
so
a1 = −a0 ,
a2 = −1
2a1 = 1
2a0 , etc.
For m = 1 we have
aj =
−2j
3j + 2j2 aj−1
so
a1 = −2
5a0 ,
a2 = −4
14a1 = 4
35a0 .
Thus we have found the linearly independent solutions
a0x−1/2 ·
 1 −x + 1
2x2 −+ · · ·

and
a0x ·
 1 −2
5x + 4
35x2 −+ · · ·

.
The general solution of our diﬀerential equation is then
y = Ax−1/2 ·
 1 −x + 1
2x2 −+ · · ·

+ Bx ·
 1 −2
5x + 4
35x2 −+ · · ·

.

220
CHAPTER 10. DIFFERENTIAL EQUATIONS
Exercises
1. Explain why the method of power series would not work very well to solve
the diﬀerential equation
y′ −|x|y = sin x .
2. Solve the initial value problem
y′′ −xy = x2
,
y(0) = 2, y′(0) = 1
by the method of power series.
3. Solve the initial value problem
y′ −xy = sin x
, y(1) = 2
by the method of power series. [Hint: Given the nature of the initial
condition, it would be best to use power series in powers of (x −1).]
4. Solve the diﬀerential equation
y′′′ −xy′ = x
by the method of power series. Since there are no initial conditions, you
should obtain a general solution with three free parameters.
5. Solve the initial value problem
y′ −y = x
,
y(0) = 1
both by Picard’s method and by the method of power series. Verify that
you get the same solution by both means.
6. When you solve a diﬀerential equation by the method of power series, you
cannot in general expect the power series to converge on the entire real
line. As an example, solve the diﬀerential equation
y′ + 1
xy = 1
x2
by the method of power series (expanded about 1). What is the radius of
convergence of the power series? Can you suggest why that is so?
7. Solve the diﬀerential equation
y′′ + y =
1
1 + x2
by the method of power series (expanded about 0). What is the radius of
convergence of the power series? Can you suggest why that is so?

EXERCISES
221
8. Consider the diﬀerential equation
y′′ −y = x2 .
The function x2 is even. If the function y is even, then y′′ will be even
also. Thus it makes sense to suppose that there is a power series solution
with only even powers of x. Find it.
9. Consider the diﬀerential equation
y′′ + y = x3 .
The function x3 is odd. If the function y is odd, then y′′ will also be odd.
Thus it makes sense to suppose that there is a power series solution with
only odd powers of x. Find it.
*
10. What are suﬃcient conditions on the function F so that the diﬀerential
equation
y′ = F(x, y)
has the property that its solution y is continuously diﬀerentiable?
11. Find all solutions of the diﬀerential equation
y′ = xy .
12. Find all solutions of the diﬀerential equation
y′ = y
x .
13. Use power series methods to solve the diﬀerential equation
y′′ + 4y = 0 .
*
14. Find a solution of the partial diﬀerential equation
 ∂2
∂x2 + ∂2
∂y2

u(x, y) = x + y
using the method of power series in two variables.
15. Solve the diﬀerential equation
y′ = y2 .


Chapter 11
Introduction to Harmonic
Analysis
11.1
The Idea of Harmonic Analysis
Fourier analysis ﬁrst arose historically in the context of the study of a certain
partial diﬀerential equation of mathematical physics. The equation could be
solved explicitly when the input (i.e., the righthand side of the equation) was a
function of the form sin jx or cos jx for j an integer. The question arose whether
an arbitrary input could be realized as the superposition of sine functions and
cosine functions.
In the late eighteenth century, debate raged over this question. It was fueled
by the fact that there was no solid understanding of just what constituted a
function.
The important treatise [FOU] of Joseph Fourier gave a somewhat
dreamy but nevertheless precise method for expanding virtually any function
as a series in sines and cosines. It took almost a century, and the concerted
eﬀorts of Dirichlet, Cauchy, Riemann, Weierstrass, and many other important
analysts, to put the so-called theory of “Fourier series” on a rigorous footing.
We now know, and can prove exactly, that if f is a continuously diﬀeren-
tiable function on the interval [0, 2π] then the coeﬃcients
cn = 1
2π
Z 2π
0
f(t)e−int dt
give rise to a series expansion
f(t) =
∞
X
n=0
cneint
that is valid (i.e., convergent) at every point, and converges back to f. [No-
tice that the convenient notation eijt given to us by Euler’s formula carries
information both about the sine and the cosine.] This expansion validates the
223

224
CHAPTER 11. INTRODUCTION TO HARMONIC ANALYSIS
vague but aggressive ruminations in [FOU] and lays the foundations for a pow-
erful and deep method of analysis that today has wide applicability in physics,
engineering, diﬀerential equations, and harmonic analysis.1
In the present chapter we shall explore the foundations of Fourier series
and also learn some of their applications. All of our discussions will of course
be rigorous and precise. They will certainly take advantage of all the tools of
analysis that we have developed thus far in the present book.
Exercises
*
1. Explain why the only continuous multiplicative homomorphisms from the
circle group T, which is just the set of all eiθ in the plane, into C \ {0} are
given by
eiθ 7−→eikθ
for some integer k.
2. Answer Exercise 1 with the circle group replaced by the real line.
3. Classical harmonic analysis is done on a space with a group action—such
as the circle group, or the line, or N-dimensional Euclidean space. Explain
what this assertion means, and supply some detail.
4. It can be proved, using elementary Fourier series (see Section 11.2), that
∞
X
j=1
1
j2 = π2
6 .
This fact was established by Leonhard Euler in 1735. It is a matter of
great interest to ﬁnd similar formulas for
∞
X
j=1
1
jk
when k = 3, 4, . . .. Apery has shown that, when k = 3, then the sum
is irrational. This set of ideas has to do with the Riemann zeta function
and the distribution of primes. Do some experiments on your computer
to determine what this might mean.
1Notice that the result enunciated here is a decisive improvement over what we know about
Taylor series. We have asserted that a function that is only continuously diﬀerentiable has a
Fourier series that converges at every point. But even an inﬁnitely diﬀerentiable function can
have Taylor series that converges at no point.

11.2. THE ELEMENTS OF FOURIER SERIES
225
11.2
The Elements of Fourier Series
In this section it will be convenient for us to work on the interval [0, 2π]. We will
perform arithmetic operations on this interval modulo 2π: for example, 3π/2 +
3π/2 is understood to equal π because we subtract from the answer the largest
multiple of 2π that it exceeds. When we refer to a function f being continuous
on [0, 2π], we require that it be right continuous at 0, left continuous at 2π, and
that f(0) = f(2π). Similarly for continuous diﬀerentiability and so forth.
If f is a (either real- or complex-valued) Riemann integrable function on
this interval and if n ∈Z then we deﬁne
bf(n) = 1
2π
Z 2π
0
f(t)e−int dt .
We call bf(n) the nth Fourier coeﬃcient of f. The formal expression
Sf(x) ∼
∞
X
n=−∞
bf(n)einx
is called the Fourier series of the function f. In circumstances where the Fourier
series converges to the function f, some of which we shall discuss below, the
series provides a decomposition of f into simple component functions. This type
of analysis is of importance in the theory of diﬀerential equations, in signal and
image processing, and in scattering theory. There is a rich theory of Fourier
series which is of interest in its own right.
Observe that, in case f has the special form
f(x) =
N
X
j=−N
ajeijt ,
(11.2.1)
then we may calculate that
1
2π
Z 2π
0
f(t)e−int dt = 1
2π
N
X
j=−N
aj
Z 2π
0
ei(j−n)t dt .
Now the integral equals 0 if j ̸= n (this is so because
R 2π
0
eikt dt = 0 when k is
a nonzero integer). And the term with j = n gives rise to an · 1. Thus we ﬁnd
that
an = 1
2π
Z 2π
0
f(t)e−int dt .
(11.2.2)
Since, in Exercise 8 of Section 9.3, we showed that functions of the form (11.2.1)
are dense in the continuous functions, we might hope that a formula like (11.2.2)
will give a method for calculating the coeﬃcients of a trigonometric expansion
in considerable generality. In any event, this calculation helps to justify (after
the fact) our formula for bf(n).

226
CHAPTER 11. INTRODUCTION TO HARMONIC ANALYSIS
The other theory that you know for decomposing a function into simple
components is the theory of Taylor series. However, in order for a function to
have a Taylor series it must be inﬁnitely diﬀerentiable. Even then, as we have
learned, the Taylor series of a function usually does not converge, and if it does
converge its limit may not be the original function—see Section 9.2. The Fourier
series of f converges to f under fairly mild hypotheses on f, and thus provides
a useful tool in analysis.
The ﬁrst result we shall prove about Fourier series gives a growth condition
on the coeﬃcients bf(n):
Proposition 11.1 (Bessel’s Inequality) If f 2 is integrable then
N
X
n=−N
| bfn|2 ≤
Z 2π
0
|f(t)|2 dt.
Proof: Recall that eijt = e−ijt and |a|2 = a · a for a ∈C. We calculate
1
2π
Z 2π
0
|f(t) −SN(t)|2 dt
=
1
2π
Z 2π
0
 
f(t) −
N
X
n=−N
bf(n)eint
!
·
 
f(t) −
N
X
n=−N
bf(n)eint
!
dt
=
1
2π
Z 2π
0
|f(t)|2 dt −
N
X
n=−N
1
2π
Z 2π
0
f(t)e−int dt · bf(n)
−
N
X
n=−N
1
2π
Z 2π
0
f(t)e−int dt · bf(n) +
X
m,n
1
2π
Z 2π
0
eimt · e−int dt .
Now each of the ﬁrst two sums equals PN
n=−N | bf(n)|2. In the last sum, any
summand with m ̸= n equals 0. Thus our equation simpliﬁes to
1
2π
Z 2π
0
|f(t) −SN(t)|2 dt
=
1
2π
Z 2π
0
|f(t)|2 dt −
N
X
n=−N
| bf(n)|2.
Since the left side is nonnegative, it follows that
N
X
n=−N
| bf(n)|2 ≤1
2π
Z 2π
0
|f(t)|2 dt ,
as desired.
Corollary 11.2 If f 2 is integrable then the Fourier coeﬃcients bf(n) satisfy
bf(n) →0
as
n →∞.

11.2. THE ELEMENTS OF FOURIER SERIES
227
Proof: Since P | bf(n)|2 < ∞we know that | bf(n)|2 →0. This implies the result.
Remark 11.3 In fact, with a little extra eﬀort, one can show that the conclu-
sion of the corollary holds if only f is integrable. This entire matter is addressed
from a slightly diﬀerent point of view in Proposition 11.16 below.
Deﬁnition 11.4 Let f be an integrable function on the interval [0, 2π]. We let
SN(x) denote the Nth partial sum of the Fourier series of f:
SNf(x) =
N
X
n=−N
bf(n)einx .
Since the coeﬃcients of the Fourier series, at least for a square integrable
function, tend to zero, we might hope that the Fourier series will converge in
some sense. Of course the best circumstance would be that SNf →f (pointwise,
or in some other manner). We now turn our attention this problem.
Proposition 11.5 (The Dirichlet Kernel) If f is integrable then
SNf(x) = 1
2π
Z 2π
0
DN(x −t)f(t) dt,
where
DN(t) = sin(N + 1
2)t
sin 1
2t
.
Proof: Observe that
SNf(x)
=
N
X
n=−N
bf(n)einx
=
N
X
n=−N
1
2π
Z 2π
0
f(t)e−int dt · einx
=
N
X
n=−N
1
2π
Z 2π
0
f(t)ein(x−t) dt
=
1
2π
Z 2π
0
f(t)
"
N
X
n=−N
ein(x−t)
#
dt.
Thus we are ﬁnished if we can show that the sum in [ ] equals DN(x −t).
Rewrite the sum as
N
X
n=0

ei(x−t)n
+
N
X
n=0

e−i(x−t)n
−1 .

228
CHAPTER 11. INTRODUCTION TO HARMONIC ANALYSIS
Then each of these last two sums is the partial sum of a geometric series. Thus
we use the formula from Proposition 3.15 to write the last line as
ei(x−t)(N+1) −1
ei(x−t) −1
+ e−i(x−t)(N+1) −1
e−i(x−t) −1
−1 .
We put everything over a common denominator to obtain
cos N(x −t) −cos(N + 1)(x −t)
1 −cos(x −t)
.
We write
N(x −t)
=

(N + 1
2)(x −t) −1
2(x −t)

,
(N + 1)(x −t)
=

(N + 1
2)(x −t) + 1
2(x −t)

,
(x −t)
=
1
2(x −t) + 1
2(x −t)
and use the sum formula for the cosine function to ﬁnd that the last line equals
2 sin
 (N + 1
2)(x −t)

sin
  1
2(x −t)

2 sin2   1
2(x −t)

=
sin(N + 1
2)(x −t)
sin 1
2(x −t)
=
DN(x −t) .
That is the desired conclusion.
Remark 11.6 We have presented this particular proof of the formula for DN
because it is the most natural. It is by no means the shortest. Another proof is
explored in the exercises.
Note also that, by a change of variable, the formula for SN presented in the
proposition can also be written as
SNf(x) = 1
2π
Z 2π
0
DN(t)f(x −t) dt
provided we adhere to the convention of doing all arithmetic modulo multiples
of 2π.
Lemma 11.7 For any N it holds that
1
2π
Z 2π
0
DN(t) dt = 1 .

11.2. THE ELEMENTS OF FOURIER SERIES
229
Proof: It would be quite diﬃcult to prove this property of DN from the formula
that we just derived. However, if we look at the proof of the proposition we
notice that
DN(t) =
N
X
n=−N
eint.
Hence
1
2π
Z 2π
0
DN(t) dt
=
1
2π
Z 2π
0
N
X
n=−N
eint dt
=
N
X
n=−N
1
2π
Z 2π
0
eint dt
=
1
because any power of eit, except the zeroeth power, integrates to zero. This
completes the proof.
Next we prove that, for a large class of functions, the Fourier series converges
back to the function at every point.
Theorem 11.8 Let f be a function on [0, 2π] that satisﬁes a Lipschitz condi-
tion: there is a constant C > 0 such that if s, t ∈[0, 2π] then
|f(s) −f(t)| ≤C · |s −t|.
(11.8.1)
[Note that at 0 and 2π this condition is required to hold modulo 2π—see the
remarks at the beginning of the section.] Then, for every x ∈[0, 2π], it holds
that
SNf(x) →f(x)
as
N →∞.
Indeed, the convergence is uniform in x.
Proof: Fix x ∈[0, 2π]. We calculate that
|SNf(x) −f(x)|
=

1
2π
Z 2π
0
f(x −t)DN(t) dt −f(x)

=

1
2π
Z 2π
0
f(x −t)DN(t) dt
−1
2π
Z 2π
0
f(x)DN(t) dt
 ,
where we have made use of the lemma. Now we combine the integrals to write

230
CHAPTER 11. INTRODUCTION TO HARMONIC ANALYSIS
|SNf(x) −f(x)|
=

1
2π
Z 2π
0
[f(x −t) −f(x)]DN(t) dt

=

1
2π
Z 2π
0
f(x −t) −f(x)
sin t/2

· sin

(N + 1
2)t

dt

≤

1
2π
Z 2π
0
f(x −t) −f(x)
sin t/2
· cos t
2

sin Nt dt

+

1
2π
Z 2π
0
f(x −t) −f(x)
sin t/2
· sin t
2

cos Nt dt

≤

1
2π
Z 2π
0
h(t) sin Nt dt
 +

1
2π
Z 2π
0
k(t) cos Nt dt
 ,
where we have denoted the ﬁrst expression in [ ] by hx(t) = h(t) and the second
expression in [ ] by kx(t) = k(t). We use our hypothesis (11.8.1) about f to see
that
|h(t)| =

f(x −t) −f(x)
t
 ·

t
sin(t/2)
 ·
cos t
2
 ≤C · 3.
[Here we have used the elementary fact that 2/π ≤| sin u/u| ≤1.] Thus h is a
bounded function. It is obviously continuous, because f is, except perhaps at
t = 0. So h is integrable—since it is bounded it is even square integrable. An
even easier discussion shows that k is square integrable. Therefore Corollary
10.2 applies and we may conclude that the Fourier coeﬃcients of h and of k
tend to zero. However, the integral involving h is nothing other than (bh(N) −
bh(−N))/(2i) and the integral involving k is precisely (bk(N) + bk(−N))/2. We
conclude that these integrals tend to zero as N →∞; in other words,
|SNf(x) −f(x)| →0
as
N →∞.
Since the relevant estimates are independent of x, we see that the convergence
is uniform.
Corollary 11.9 If f ∈C1([0, 2π]) (that is, f is continuously diﬀerentiable)
then SNf →f uniformly.
Proof: A C1 function, by the Mean Value Theorem, satisﬁes a Lipschitz con-
dition.
In fact the proof of the theorem suﬃces to show that if f is a Riemann
square-integrable function on [0, 2π] and if f is diﬀerentiable at x then SNf(x) →
f(x).
In the exercises we shall explore other methods of summing Fourier series
that allow us to realize even discontinuous functions as the limits of certain
Fourier expressions.

EXERCISES
231
It is natural to ask whether the Fourier series of a function characterizes
that function. We can now give a partial answer to this question:
Corollary 11.10 If f is a function on [0, 2π] that satisﬁes a Lipschitz condition
and if the Fourier series of f is identically zero then f ≡0.
Proof: By the preceding corollary, the Fourier series converges uniformly to f.
But the Fourier series is 0.
Corollary 11.11 If f and g are functions on [0, 2π] that satisfy a Lipschitz con-
dition and if the Fourier coeﬃcients of f are the same as the Fourier coeﬃcients
of g then f ≡g.
Proof: Apply the preceding corollary to f −g.
Example 11.12 Let f(t) = t2 −2πt, 0 ≤t ≤2π. Then f(0) = f(2π) = 0 and
f is Lipschitz modulo 2π. Calculating the Fourier series of f, setting t = 0, and
using the theorem reveals that
∞
X
j=1
1
j2 = π2
6 .
You are requested to provide the details.
Exercises
1. Find the Fourier series for the function
f(x) =





0
if
−π ≤x < 0
1
if
0 ≤x ≤π
2
0
if
π
2 < x ≤π .
2. Find the Fourier series of the function
f(x) =

0
if
−π ≤x < 0
sin x
if
0 ≤x ≤π
3. Find the Fourier series for each of these functions. Pay special attention
to the reasoning used to establish your conclusions; consider alternative
lines of thought.
(a) f(x) = π
,
−π ≤x ≤π
(b) f(x) = sin x
,
−π ≤x ≤π
(c) f(x) = cos x
,
−π ≤x ≤π

232
CHAPTER 11. INTRODUCTION TO HARMONIC ANALYSIS
(d) f(x) = π + sin x + cos x
,
−π ≤x ≤π
4. Find the Fourier series for the function given by
(a)
f(x) =
 −a
if
−π ≤x < 0
a
if
0 ≤x ≤π
for a a positive real number.
(b)
f(x) =

−1
if
−π ≤x < 0
1
if
0 ≤x ≤π
(c)
f(x) =

−π
4
if
−π ≤x < 0
π
4
if
0 ≤x ≤π
(d)
f(x) =

−1
if
−π ≤x < 0
2
if
0 ≤x ≤π
(e)
f(x) =

1
if
−π ≤x < 0
2
if
0 ≤x ≤π
5. (a) Show that the Fourier series for the periodic function
f(x) =
 0
if
−π ≤x < 0
x2
if
0 ≤x < π
is
f(x)
=
π2
6 + 2
∞
X
j=1
(−1)j cos jx
j2
+π
∞
X
j=1
(−1)j+1 sin jx
j
−4
π
∞
X
j=1
sin(2j −1)x
(2j −1)3
.
(b) Sketch the graphs of the partial sums of this series on the interval
−5π ≤x ≤5π.
(c) Use the series in part (a) with x = 0 and x = π to obtain the two
sums
1 −1
22 + 1
32 −1
42 + −· · · = π2
12
and
1 + 1
22 + 1
32 + 1
42 + · · · = π2
6 .

EXERCISES
233
(d) Derive the second sum in (c) from the ﬁrst. [Hint: Add 2 P
j(1/[2j])2
to both sides.]
*
6. (a) Find the Fourier series for the periodic function deﬁned by f(x) = ex,
−π ≤x ≤π. [Hint: Recall that sinh x = [ex −e−x]/2.
(b) Sketch the graph of the partial sums of this series on the interval
−5π ≤x ≤5π.
(c) Use the series in (a) to establish the sums
∞
X
j=1
1
j2 + 1 = 1
2

π
tanh π −1

and
∞
X
j=1
(−1)j
j2 + 1 = 1
2

π
sinh π −1

.
7. The functions sin2 x and cos2 x are both even. Show, without using any
calculations, that the identities
sin2 x = 1
2(1 −cos 2x) = 1
2 −1
2 cos 2x
and
cos2 x = 1
2(1 + cos 2x) = 1
2 + 1
2 cos 2x
are actually the Fourier series expansions of these functions.
8. Prove the trigonometric identities
sin3 x = 3
4 sin x −1
4 sin 3x
and
cos3 x = 3
4x + 1
4 cos 3x
and show brieﬂy, without calculation, that these are the Fourier series
expansions of the functions sin3 x and cos3 x.
9. Show that
L
2 −x = L
π
∞
X
j=1
1
j sin 2jπx
L
,
0 < x < L .
10. Find the cosine series for the function deﬁned on the interval 0 ≤x ≤1 by
f(x) = x2−x+1/6. This is a special instance of the Bernoulli polynomials.
*
11. If f is an integrable function on [0, 2π] and 0 < r < 1 then deﬁne
Prf(x) = 1
2π
Z 2π
0
Pr(x −t)(t) dt

234
CHAPTER 11. INTRODUCTION TO HARMONIC ANALYSIS
where
Pr(x −t) =
1 −r2
1 −2r cos(x −t) + r2 .
This is the Poisson integral. Prove that if f is continuous on [0, 2π] and
f(0) = f(2π) then Prf(x) →f(x), uniformly in x, as r →1−.
12. Refer to Exercise 11. It would be quite diﬃcult to calculate the relevant
integrals for this problem by hand. Instead, use your symbol manipulation
software, such as Maple or Mathematica, to calculate the Poisson integral
of the given function on [−π, π].
(a) f(θ) = ln2 θ
(b) f(θ) = θ3 · cos θ
(c) f(θ) = eθ · sin θ
(d) f(θ) = eθ · ln θ
13. Give another proof for the formula for DN(t) by completing the following
outline:
(a) DN(t) = PN
n=−N eint;
(b) (eit −1) · DN(t) = ei(N+1)t −e−iNt;
(c) Multiply both sides of the last equation by e−it/2.
(d) Conclude that DN(t) = sin(N+ 1
2 )t
sin(t/2) .
*
14. If f is integrable on the interval [0, 2π] and if N is a nonnegative integer
then deﬁne
σNf(x) =
1
N + 1
N
X
n=0
SN(x) .
This is called the Nth Cesaro mean for the Fourier series of f. Prove that
σNf(x) = 1
2π
Z 2π
0
KN(x −t)f(t) dt ,
where
KN(x −t) =
1
N + 1
(
sin N+1
2 (x −t)
sin 1
2t
)2
.
15. Refer to Exercise 14 for notation. Prove that if δ > 0 then limN→∞KN(t)
= 0 with the limit being uniform for all |t| ≥δ.
16. Refer to Exercise 141 for notation. Prove that
1
2π
R 2π
0
|KN(t)| dt = 1.

11.3. AN INTRODUCTION TO THE FOURIER TRANSFORM
235
*
17. Use the results of the preceding three exercises to prove that if f is con-
tinuous on [0, 2π] and f(0) = f(2π) then σNf(x) →f(x) uniformly on
[0, 2π]. [Hint: Let ǫ > 0. Choose δ > 0 such that |s −t| < δ implies that
|f(s)−f(t)| < ǫ. Now divide the integral into the set where |t| < δ and the
set where |t| > δ and imitate the proof of the Weierstrass Approximation
Theorem.]
*
18. Examine σNf when f has a jump discontinuity. To what do these sums
converge at the point of discontinuity?
11.3
An Introduction to the Fourier Transform
It turns out that Fourier analysis on the interval [0, 2π] and Fourier analysis on
the entire real line R are analogous; but they diﬀer in certain particulars that
are well worth recording. In the present section we present an outline of the
theory of the Fourier transform on the line.
A thorough treatment of Fourier analysis in Euclidean space may be found
in [STG]. See also [KRA2]. Here we give a sketch of the theory. Most of the
results parallel facts that we have already seen in the context of Fourier series
on the circle. Others will reﬂect the structure of Euclidean space.
We deﬁne the Fourier transform of an integrable function f on R by
bf(ξ) =
Z
R
f(t)eit·ξ dt .
Many references will insert a factor of 2π in the exponential or in the measure.
Others will insert a minus sign in the exponent. There is no agreement on this
matter. We have opted for this particular deﬁnition because of its simplicity.
We note that the signiﬁcance of the exponentials eit·ξ is that the only contin-
uous multiplicative homomorphisms of R into the circle group are the functions
φξ(t) = eit·ξ, ξ ∈R. These functions are called the characters of the additive
group R. We refer the reader to [KRA2] for more on this matter.
Proposition 11.13 If f is an integrable function, then
| bf(ξ)| ≤
Z
R
|f(t)| dt .
Proof: Observe that, for any ξ ∈R,
| bf(ξ)| =

Z
R
f(t)eit·ξ dt
 ≤
Z
R
|f(t)eit·ξ| dt ≤
Z
|f(t)| dt.
Proposition 11.14 If f is integrable, f is diﬀerentiable, and f ′ is integrable,
then
(f ′)b(ξ) = −iξ bf(ξ) .

236
CHAPTER 11. INTRODUCTION TO HARMONIC ANALYSIS
Proof: Integrate by parts: if f is an inﬁnitely diﬀerentiable function that
vanishes outside a compact set, then
(f ′)b(ξ)
=
Z
f ′(t)eit·ξ dt dt
=
−
Z
f(t)[eit·ξ]′ dt
=
−iξ
Z
f(t)eit·ξ dt
=
−iξ bf(ξ) .
[Of course the “boundary terms” in the integration by parts vanish since f van-
ishes outside a compact set.] The general case follows from a limiting argument
(see the Appendix at the end of this section).
Proposition 11.15 If f is integrable and ixf is integrable, then
(ixf)b= ∂
∂ξ
bf .
Proof: Diﬀerentiate under the integral sign.
Proposition 11.16 (The Riemann-Lebesgue Lemma) If f is integrable,
then
lim
ξ→∞| bf(ξ)| = 0.
Proof: First assume that g ∈C2(R) and vanishes outside a compact set. We
know that |bg| is bounded. Also
ξ2bg(ξ)
 = |[g′′]b| ≤
Z
R
|g′′(x)| dx = C′ .
Then (1 + |ξ|2)bg is bounded. Thus
|bg(ξ)| ≤
C′′
1 + |ξ|2
|ξ|→∞
−→0 .
This proves the result for g ∈C2
c . [Notice that the argument also shows that, if
g ∈C2(R) and vanishes outside a compact set, then bg is integrable.]
Now let f be an arbitrary integrable function. Then there is a function
ψ ∈C2(R), vanishing outside a compact set, such that
Z
R
|f(x) −ψ(x)| dx < ǫ/2 .

11.3. AN INTRODUCTION TO THE FOURIER TRANSFORM
237
[See the Appendix to this section for the details of this assertion.] Choose M
so large that, when |ξ| > M, then | bψ(ξ)| < ǫ/2. Then, for |ξ| > M, we have
| bf(ξ)|
=
|(f −ψ)b(ξ) + bψ(ξ)|
≤
|(f −ψ)b(ξ)| + | bψ(ξ)|
≤
Z
R
|f(x) −ψ(x)| dx + ǫ
2
<
ǫ
2 + ǫ
2 = ǫ .
This proves the result.
Remark 11.17 The Riemann-Lebesgue lemma is intuitively clear when viewed
in the following way. Fix an integrable function f. An integrable function is
well-approximated by a continuous function, so we may as well suppose that
f is continuous. But a continuous function is well-approximated by a smooth
function (see the Appendix to this section), so we may as well suppose that f is
smooth. On a small interval I—say of length 1/M—a smooth function is nearly
constant. So, if we let |ξ| >> 2πM 2, then the character eiξ·x will oscillate at
least M times on I, and will therefore integrate against a constant to a value
that is very nearly zero. As M becomes larger, this statement becomes more
and more accurate. That is the Riemann-Lebesgue lemma.
Proposition 11.18 Let f be integrable on R. Then bf is uniformly continuous.
Proof: Let us ﬁrst assume that f is continuous and vanishes outside a compact
set. Then
lim
ξ→ξ0
bf(ξ) = lim
ξ→ξ0
Z
f(x)eix·ξ dx =
Z
lim
ξ→ξ0 f(x)eix·ξ dx = bf(ξ0) .
[Exercise: Justify passing the limit under the integral sign.] Since bf also van-
ishes at ∞, the result is immediate when f is continuous and vanishing outside
a compact set. The general result follows from an approximation argument (see
the Appendix to this section).
Let C0(R) denote the continuous functions on R that vanish at ∞. Equip
this space with the supremum norm. Then our results show that the Fourier
transform maps the integrable functions to C0 continuously.
It is natural to ask whether the Fourier transform is univalent; put in other
words, can we recover a function from its Fourier transform? If so, can we do
so with an explicit integral formula? The answer to all these questions is “yes,”
but advanced techniques are required for the proofs. We cannot treat them
here, but see [KRA2] for the details. We content ourselves with the formulation
of a single result and its consequences.

238
CHAPTER 11. INTRODUCTION TO HARMONIC ANALYSIS
Theorem 11.19 Let f be a continuous, integrable function on R and suppose
also that bf is integrable. Then
f(x) = 1
2π
Z
R
bf(ξ)e−ix·ξ dξ
for every x.
Corollary 11.20 If f is continuous and integrable and bf(ξ) ≡0 then f ≡0.
Corollary 11.21 If f, g are continuous and integrable and bf(ξ) = bg(ξ) then
f ≡g.
We refer to the circle of ideas in this theorem and the two corollaries as
“Fourier inversion.” See [KRA2] for the details of all these assertions.
11.3.1
APPENDIX: Approximation by Smooth Functions
At several junctures in this section we have used the idea that an integrable
function may be approximated by smooth functions. We take a moment now to
discuss this notion. Not all of the details appear here, but the interested reader
may supply them as an exercise.
Let f be any integrable function on the interval [0, 1].
Then f may be
approximated by its Riemann sums in the following sense. Let
0 = x0 < x1 < · · · < xk = 1
be a partition of the interval. For j = 1, . . . , k deﬁne
hj(x) =



0
if
0 ≤x < xj−1
1
if
xj−1 ≤x ≤xj
0
if
xj < x ≤1 .
Then the function
Rf(x) =
k
X
j=1
f(xj) · hj(x)
is a Riemann sum for f and the expression
Z
R
|f(x) −Rf(x)| dx
(11.3.1.1)
will be small if the mesh of the partition is suﬃciently ﬁne. In fact the ex-
pression (11.3.1.1) is a standard “distance between functions” that is used in
mathematical analysis (for more on the concept of “metric,” see Chapter 13).
We often denote this quantity by ∥f −Rf∥L1 and we call it “the L1 norm” or
“L1 distance.” More generally, we call the expression
Z
R
|g(x)| dx ≡∥g∥L1

11.3. AN INTRODUCTION TO THE FOURIER TRANSFORM
239
1
-1
Figure 11.1: A compactly supported, smooth function.
the L1 norm of the function g.
Now our strategy is to approximate each of the functions hj by a “smooth”
function. Let f(x) = 10x3 −15x4 + 6x5. Notice that f(0) = 0, f(1) = 1, and
both f ′ and f ′′ vanish at 0 and at 1.
The model for the sort of smooth function we are looking for is
ψ(x) =





















0
if
x < −2
f(x + 2)
if
−2 ≤x ≤−1
1
if
−1 < x < 1
f(2 −x)
if
1 ≤x ≤2
0
if
2 < x .
Refer to Figure 11.1. You may calculate that this function is twice continuously
diﬀerentiable. It vanishes outside the interval [−2, 2]. And it is identically equal
to 1 on the interval [−1, 1].
More generally, we will consider the functions
ψδ(x) =

































0
if
x < −1 −δ
f
x + (1 + δ)
δ

if
−1 −δ ≤x ≤−1
1
if
−1 < x < 1
f
(1 + δ) −x
δ

if
1 ≤x ≤1 + δ
0
if
1 + δ < x .

240
CHAPTER 11. INTRODUCTION TO HARMONIC ANALYSIS
1
-1
Figure 11.2: Another compactly supported, smooth function.
for δ > 0 and
ψ[a,b]
δ
(x) = ψδ
2x −b −a
b −a

for δ > 0 and a < b. Figure 11.2 shows that ψδ is similar to the function ψ, but
its sides are contracted so that it climbs from 0 to 1 over the interval [−1−δ, −1]
of length δ and then descends from 1 to 0 over the interval [1, 1 + δ] of length δ.
The function ψ[a,b]
δ
is simply the function ψδ adapted to the interval [a, b] (Figure
11.3). The function ψ[a,b]
δ
climbs from 0 to 1 over the interval [a−(δ(b−a))/2, a]
of length δ(b−a)/2 and descends from 1 to 0 over the interval [b, b+(δ(b−a)/2)]
of length δ(b −a)/2.
Finally, we approximate the function hj by kj(x) ≡ψ[xj−1,xj]
δ
for j =
1, . . . , k. See Figure 11.4. Then the function f is approximated in L1 norm
by
Sf(x) =
k
X
j=1
f(xj) · kj(x) .
See Figure 11.5. If δ > 0 is suﬃciently small, then we can make ∥f −Sf∥L1 as
small as we please.
The approximation by twice continuously diﬀerentiable (or C2) functions
that we have constructed here is easily modiﬁed to achieve approximation by
Ck functions for any k. One merely replaces the polynomial f by a polynomial
that vanishes to higher order (order at least k) at 0 and at 1.
Exercises
1. Determine whether each of the following functions is even, odd, or neither:
x5 sin x , x2 sin 2x , ex , (sin x)3 , sin x2 ,

EXERCISES
241
a
b
Figure 11.3: The compactly supported, smooth function translated and dilated.
Figure 11.4: Unit for approximation.

242
CHAPTER 11. INTRODUCTION TO HARMONIC ANALYSIS
y = f(x)
a
b
Figure 11.5: Approximation by a smooth function.
cos(x + x3) , x + x2 + x3 , ln 1 + x
1 −x .
2. Show that any function f deﬁned on a symmetrically placed interval can
be written as the sum of an even function and an odd function. [Hint:
f(x) = 1
2[f(x) + f(−x)] + 1
2[f(x) −f(−x)].]
3. A version of the Poisson summation formula says that, if f is a suitable
function on the real line, then
∞
X
n=−∞
f(n) =
∞
X
k=−∞
bf(k) .
Find a proof of this assertion.
4. Calculate the Fourier transform of f(x) = x · χ[0,1].
5. Calculate the Fourier transform of g(x) = cos x · χ[0,2].
6. If f, g are integrable functions on R then deﬁne their convolution to be
h(x) = f ∗g(x) =
Z
R
f(x −t)g(t) dt .
Prove that
bh(ξ) = bf(ξ) · bg(ξ) .
*
7. Let f be a function on R that vanishes outside a compact set. Prove that
bf does not vanish outside any compact set.
*
8. Calculate the Fourier transform of the function f(x) = e−x2.

11.4. FOURIER METHODS AND DIFFERENTIAL EQUATIONS
243
9. Use the calculation from Exercise 8 to discover an eigenfunction of the
Fourier transform.
10. Refer to Exercise 9. What are the eigenvalues of the Fourier transform?
11. Calculate all the continuous, multiplicative homomorphisms of the real
line into the circle group.
11.4
Fourier Methods in the Theory of Diﬀer-
ential Equations
In fact an entire separate book could be written about the applications of Fourier
analysis to diﬀerential equations and to other parts of mathematical analysis.
The subject of Fourier series grew up hand in hand with the analytical areas to
which it is applied. In the present brief section we merely indicate a couple of
examples.
11.4.1
Remarks on Diﬀerent Fourier Notations
In Section 11.2, we found it convenient to deﬁne the Fourier coeﬃcients of an
integrable function on the interval [0, 2π] to be
bf(n) = 1
2π
Z 2π
0
f(x)e−inx dx .
From the point of view of pure mathematics, this complex notation has proved
to be useful, and it has become standardized.
But, in applications, there are other Fourier paradigms. They are easily
seen to be equivalent to the one we have already introduced. The reader who
wants to be conversant in this subject should be aware of these diﬀerent ways
of writing the basic ideas of Fourier series. We will introduce one of them now,
and use it in the ensuing discussion.
If f is integrable on the interval [−π, π] (note that, by 2π-periodicity, this
is not essentially diﬀerent from [0, 2π]), then we deﬁne the Fourier coeﬃcients
a0 = 1
2π
Z π
−π
f(x) dx ,
an = 1
π
Z π
−π
f(x) cos nx dx
for n ≥1 ,
bn = 1
π
Z π
−π
f(x) sin nx dx
for n ≥1 .
This new notation is not essentially diﬀerent from the old, for
bf(n) = 1
2

an + ibn


244
CHAPTER 11. INTRODUCTION TO HARMONIC ANALYSIS
for n ≥1. The change in normalization (i.e., whether the constant before the
integral is 1/π or 1/2π) is dictated by the observation that we want to exploit
the fact (so that our formulas come out in a neat and elegant fashion) that
1
2π
Z 2π
0
|e−int|2 dt = 1 ,
in the theory from Section 11.2 and that
1
2π
Z π
−π
12 dx = 1 ,
1
π
Z π
−π
| cos nt|2 dt = 1
for n ≥1 ,
1
π
Z π
−π
| sin nt|2 dt = 1
for n ≥1
in the theory that we are about to develop.
It is clear that any statement (as in Section 11.2) that is formulated in the
language of bf(n) is easily translated into the language of an and bn and vice
versa. In the present discussion we shall use an and bn just because that is the
custom, and because it is convenient for the points that we want to make.
11.4.2
The Dirichlet Problem on the Disc
We now study the two-dimensional Laplace equation, which is
△= ∂2u
∂x2 + ∂2u
∂y2 = 0 .
(11.4.2.1)
This is probably the most important diﬀerential equation of mathematical physics.
It describes a steady-state heat distribution, electrical ﬁelds, and many other
important phenomena of nature.
It will be useful for us to write this equation in polar coordinates. To do
so, recall that
r2 = x2 + y2 ,
x = r cos θ ,
y = r sin θ .
Thus
∂
∂r
=
∂x
∂r
∂
∂x + ∂y
∂r
∂
∂y = cos θ ∂
∂x + sin θ ∂
∂y
∂
∂θ
=
∂x
∂θ
∂
∂x + ∂y
∂θ
∂
∂y = −r sin θ ∂
∂x + r cos θ ∂
∂y
We may solve these two equations for the unknowns ∂/∂x and ∂/∂y. The result
is
∂
∂x = cos θ ∂
∂r −sin θ
r
∂
∂θ
and
∂
∂y = sin θ ∂
∂r −cos θ
r
∂
∂θ .

11.4. FOURIER METHODS AND DIFFERENTIAL EQUATIONS
245
A tedious calculation now reveals that
△= ∂2
∂x2 + ∂2
∂y2
=

cos θ ∂
∂r −sin θ
r
∂
∂θ
 
cos θ ∂
∂r −sin θ
r
∂
∂θ

+

sin θ ∂
∂r −cos θ
r
∂
∂θ
 
sin θ ∂
∂r −cos θ
r
∂
∂θ

=
∂2
∂r2 + 1
r
∂
∂r + 1
r2
∂2
∂θ2 .
Let us use the so-called separation of variables method to analyze our partial
diﬀerential equation (11.4.2.1). We will seek a solution w = w(r, θ) = u(r)·v(θ)
of the Laplace equation. Using the polar form, we ﬁnd that this leads to the
equation
u′′(r) · v(θ) + 1
r u′(r) · v(θ) + 1
r2 u(r) · v′′(θ) = 0 .
Thus
r2u′′(r) + ru′(r)
u(r)
= −v′′(θ)
v(θ) .
Since the lefthand side depends only on r, and the righthand side only on θ,
both sides must be constant. Denote the common constant value by λ.
Then we have
v′′ + λv = 0
(11.4.2.2)
and
r2u′′ + ru′ −λu = 0 .
(11.4.2.3)
If we demand that v be continuous and periodic, then we must insist that λ > 0
and in fact that λ = n2 for some nonnegative integer n.2 For n = 0 the only
suitable solution is v ≡constant and for n > 0 the general solution (with λ = n2)
is
v = A cos nθ + B sin nθ ,
as you can verify directly.
We set λ = n2 in equation (11.4.2.3), and obtain
r2u′′ + ru′ −n2u = 0 ,
(11.4.2.4)
which is Euler’s equidimensional equation.
The change of variables r = ez
transforms this equation to a linear equation with constant coeﬃcients, and
that can in turn be solved with standard techniques. To wit, the equation that
we now have is
u′′ −n2u = 0 .
The variable is now z. We guess a solution of the form u(z) = eαz. Thus
α2eαz −n2eαz = 0
(11.4.2.5)
2More explicitly, λ = 0 gives a linear function for a solution and λ < 0 gives an exponential
function for a solution.

246
CHAPTER 11. INTRODUCTION TO HARMONIC ANALYSIS
so that
α = ±n .
Hence the solutions of (11.4.2.5) are
u(z) = enz
and
u(z) = e−nz
provided that n ̸= 0. It follows that the solutions of the original Euler equation
(11.4.2.4) are
u(r) = rn
and
u(r) = r−n
for n ̸= 0 .
In case n = 0 the solution is readily seen to be u = 1 or u = ln r.
The result is
u = A + B ln r
if n = 0 ;
u = Arn + Br−n
if n = 1, 2, 3, . . . .
We are most interested in solutions u that are continuous at the origin; so we
take B = 0 in all cases. The resulting solutions are
n = 0 ,
w = a constant a0/2 ;
n = 1 ,
w = r(a1 cos θ + b1 sin θ) ;
n = 2 ,
w = r2(a2 cos 2θ + b2 sin 2θ) ;
n = 3 ,
w = r3(a3 cos 3θ + b3 sin 3θ) ;
. . .
Of course any ﬁnite sum of solutions of Laplace’s equation is also a solution.
The same is true for inﬁnite sums. Thus we are led to consider
w = w(r, θ) = 1
2a0 +
∞
X
j=0
rj(aj cos jθ + bj sin jθ) .
On a formal level, letting r →1−in this last expression gives
1
2a0 +
∞
X
j=1
(aj cos jθ + bj sin jθ) .
We draw all these ideas together with the following physical rubric. Con-
sider a thin aluminum disc of radius 1, and imagine applying a heat distribution
to the boundary of that disc. In polar coordinates, this distribution is speciﬁed
by a function f(θ). We seek to understand the steady-state heat distribution on
the entire disc. See Figure 11.6. So we seek a function w(r, θ), continuous on the
closure of the disc, which agrees with f on the boundary and which represents
the steady-state distribution of heat inside. Some physical analysis shows that
such a function w is the solution of the boundary value problem
△w
=
0 ,
u

∂D
=
f .

11.4. FOURIER METHODS AND DIFFERENTIAL EQUATIONS
247
Figure 11.6: Steady-state heat.
According to the calculations we performed prior to this last paragraph,
a natural approach to this problem is to expand the given function f in its
sine/cosine series:
f(θ) = 1
2a0 +
∞
X
j=1
(aj cos jθ + bj sin jθ)
and then posit that the w we seek is
w(r, θ) = 1
2a0 +
∞
X
j=1
rj(aj cos jθ + bj sin jθ) .
This process is known as solving the Dirichlet problem on the disc with boundary
data f.
Example 11.22 Let us follow the paradigm just sketched to solve the Dirichlet
problem on the disc with f(θ) = 1 on the top half of the boundary and f(θ) = −1
on the bottom half of the boundary. See Figure 11.7.
It is straightforward to calculate that the Fourier series (sine series) expan-
sion for this f is
f(θ) = 4
π

sin θ + sin 3θ
3
+ +sin 5θ
5
+ · · ·

.
The solution of the Dirichlet problem is therefore
w(r, θ) = 4
π

r sin θ + r3 sin 3θ
3
+ +r5 sin 5θ
5
+ · · ·

.

248
CHAPTER 11. INTRODUCTION TO HARMONIC ANALYSIS
+1
-1
Figure 11.7: Boundary data.
Exercises
Solve the following two exercises without worrying about convergence of series
or diﬀerentiability of functions.
*
1. If y = F(x) is an arbitrary function, then y = F(x + at) represents a
wave of ﬁxed shape that moves to the left along the x-axis with velocity
a (Figure 11.8).
Similarly, if y = G(x) is another arbitrary function, then y = G(x −at) is
a wave moving to the right, and the most general one-dimensional wave
with velocity a is
y(x, t) = F(x + at) + G(x −at) .
(∗)
(a) Show that (∗) satisﬁes the wave equation a2uxx −utt = 0.
(b) It is easy to see that the constant a in the wave equation has the
dimensions of velocity. Also, it is intuitively clear that if a stretched
string is disturbed, then the waves will move in both directions away
from the source of the disturbance.
These considerations suggest
introducing the new variables α = x + at, β = x −at. Show that,
with these independent variables, equation (∗) becomes
∂2y
∂α∂β = 0 .
From this derive (∗) by integration. Formula (∗) is called d’Alembert’s
solution of the wave equation. It was also obtained, slightly later and
independently, by Euler.

EXERCISES
249
y = F(x)
y = F(x + at)
at
y
x
Figure 11.8: A wave of ﬁxed shape.
*
2. Consider an inﬁnite string stretched taut on the x-axis from −∞to +∞.
Let the string be drawn aside into a curve y = f(x) and released, and
assume that its subsequent motion is described by the wave equation.
(a) Use (∗) in Exercise 1 to show that the string’s displacement is given
by d’Alembert’s formula
y(x, t) = 1
2[f(x + at) + f(x −at)] .
(∗∗)
Hint: Remember the initial conditions.
(b) Assume further that the string remains motionless at the points x = 0
and x = π (such points are called nodes), so that y(0, t) = y(π, t) = 0,
and use (∗∗) to show that f is an odd function that is periodic with
period 2π (that is, f(−x) = f(x) and f(x + 2π) = f(x)).
(c) Show that, since f is odd and periodic with period 2π, then f nec-
essarily vanishes at 0 and π.
3. Solve the vibrating string problem in the text if the initial shape y(x, 0) =
f(x) is speciﬁed by the given function. In each case, sketch the initial
shape of the string on a set of axes.
(a)
f(x) =
 2cx/π
if
0 ≤x ≤π/2
2c(π −x)/π
if
π/2 ≤x ≤π
(b)
f(x) = 1
π x(π −x)

250
CHAPTER 11. INTRODUCTION TO HARMONIC ANALYSIS
(c)
f(x) =



x
if
0 ≤x ≤π/4
π/4
if
π/4 < x < 3π/4
π −x
if
3π/4 ≤x ≤π
*
4. Solve the vibrating string problem in the text if the initial shape y(x, 0) =
f(x) is that of a single arch of the sine curve f(x) = c sin x. Show that
the moving string always has the same general shape, regardless of the
value of c. Do the same for functions of the form f(x) = c sin nx. Show
in particular that there are n −1 points between x = 0 and x = π at
which the string remains motionless; these points are called nodes, and
these solutions are called standing waves. Draw sketches to illustrate the
movement of the standing waves.
5. The problem of the struck string is that of solving the wave equation with
the boundary conditions
y(0, t) = 0 ,
y(π, t) = 0
and the initial conditions
∂y
∂t

t=0
= g(x)
and
y(x, 0) = 0 .
[These initial conditions reﬂect the fact that the string is initially in the
equilibrium position, and has an initial velocity g(x) at the point x as a
result of being struck.] By separating variables and proceeding formally,
obtain the solution
y(x, t) =
∞
X
j=1
cj sin jx sin jat ,
where
cj =
2
πja
Z π
0
g(x) sin jx dx .
6. Solve the boundary value problem
a2 ∂2w
∂x2
=
∂w
∂t
w(x, 0)
=
f(x)
w(0, t)
=
0
w(π, t)
=
0
if the last three conditions—the boundary conditions—are changed to
w(x, 0)
=
f(x)
w(0, t)
=
w1
w(π, t)
=
w2 .
Hint: Write w(x, t) = W(x, t) + g(x).

EXERCISES
251
*
7. Suppose that the lateral surface of the thin rod that we analyzed in the
text is not insulated, but in fact radiates heat into the surrounding air.
If Newton’s law of cooling (that a body cools at a rate proportional to
the diﬀerence of its temperature with the temperature of the surrounding
air) is assumed to apply, then show that the 1-dimensional heat equation
becomes
a2 ∂2w
∂x2 = ∂w
∂t + c(w −w0)
where c is a positive constant and w0 is the temperature of the surrounding
air.
*
8. In Exercise 7, ﬁnd w(x, t) if the ends of the rod are kept at 0◦C, w0 = 0◦C,
and the initial temperature distribution on the rod is f(x).
9. In the solution of the heat equation, suppose that the ends of the rod are
insulated instead of being kept ﬁxed at 0◦C. What are the new bound-
ary conditions? Find the temperature w(x, t) in this case by using just
common sense.
10. Solve the problem of ﬁnding w(x, t) for the rod with insulated ends at
x = 0 and x = π (see the preceding exercise) if the initial temperature
distribution is given by w(x, 0) = f(x).
*
11. The 2-dimensional heat equation is
a2
∂2w
∂x2 + ∂2w
∂y2

= ∂w
∂t .
Use the method of separation of variables to ﬁnd a steady-state solution
of this equation in the inﬁnite strip of the x-y plane bounded by the lines
x = 0, x = π, and y = 0 if the following boundary conditions are satisﬁed:
w(0, y) = 0
w(π, y) = 0
w(x, 0) = f(x)
lim
y→+∞w(x, y) = 0 .
12. Solve the Dirichlet problem for the unit disc when the boundary function
f(θ) is deﬁned by
(a) f(θ) = cos θ/2 ,
−π ≤θ ≤π
(b) f(θ) = θ ,
−π < θ < 0
(c) f(θ) =

0
if
−π ≤θ < 0
sin θ
if
0 ≤θ ≤π
(d) f(θ) =

0
if
−π ≤θ < π/2
1
if
π/2 ≤θ ≤π
(e) f(θ) = θ2/4 ,
−π ≤θ ≤π

252
CHAPTER 11. INTRODUCTION TO HARMONIC ANALYSIS
13. Show that the Dirichlet problem for the disc {(x, y) : x2+y2 ≤R2}, where
f(θ) is the boundary function, has the solution
w(r, θ) = 1
2a0 +
∞
X
j=1
 r
R
j
(aj cos jθ + bj sin jθ)
where aj and bj are the Fourier coeﬃcients of f.
Show also that the
Poisson integral formula for this more general disc setting is
w(r, θ) = 1
2π
Z π
−π
R2 −r2
R2 −2Rr cos(θ −φ) + r2 f(φ) dφ .
*
14. Let w be a harmonic function in a planar region (that is, a function an-
nihilated by the Laplacian), and let C be any circle entirely contained
(along with its interior) in this region. Prove that the value of w at the
center of C is the average of its values on the circumference.

Chapter 12
Functions of Several
Variables
12.1
A New Look at the Basic Concepts of
Analysis
A point of Rk is denoted (x1, x2, . . . , xk). In the analysis of functions of one
real variable, the domain of a function is typically an open interval. Since any
open set in R1 is the disjoint union of open intervals, it is natural to work in
the context of intervals. Such a simple situation does not obtain in the analysis
of several variables. We will need some new notation and concepts in order to
study functions in Rk.
We measure distance between two points s = (s1, s2, . . . , sk) and t =
(t1, t2, . . . , tk) in Rk by the formula
∥s −t∥=
p
(s1 −t1)2 + (s2 −t2)2 + · · · + (sk −tk)2 .
Of course this notion of distance can be justiﬁed by considerations using the
Pythagorean theorem (see the exercises), but we treat this as a deﬁnition. The
distance between two points is nonnegative, and equals zero if and only if the
two points are identical. Moreover, there is a triangle inequality:
∥s −t∥≤∥s −u∥+ ∥u −t∥.
We sketch a proof of this inequality in the exercises (by reducing it to the
one-dimensional triangle inequality).
Deﬁnition 12.1 If x ∈Rk and r > 0 then the open ball with center x and
radius r is the set
B(x, r) = {t ∈Rk : ∥x −t∥< r} .
The closed ball with center x and radius r is the set
B(x, r) = {t ∈Rk : ∥t −x∥≤r}.
253

254
CHAPTER 12. FUNCTIONS OF SEVERAL VARIABLES
Deﬁnition 12.2 A set U ⊆Rk is said to be open if, for each x ∈U, there is
an r > 0 such that the ball B(x, r) is contained in U.
Example 12.3 Let
S = {x = (x1, x2, x3) ∈R3 : 1 < ∥x∥< 2} .
This set is open. For, if x ∈S, let r = min{∥x∥−1, 2 −∥x∥}. Then B(x, r) is
contained in S for the following reason: if t ∈B(x, r) then
∥x∥≤∥t −x∥+ ∥t∥
hence
∥t∥≥∥x∥−∥t −x∥> ∥x∥−r ≥∥x∥−(∥x∥−1) = 1 .
Likewise,
∥t∥≤∥x∥+ ∥t −x∥< ∥x∥+ r ≤∥x∥+ (2 −∥x∥) = 2 .
It follows that t ∈S hence B(x, r) ⊆S. We conclude that S is open.
However, a moment’s thought shows that S could not be written as a disjoint
union of open balls, or open cubes, or any other regular type of open set.
In this chapter we consider functions with domain a set (usually open) in Rk.
This means that the function f may be written in the form f(x1, x2, . . . , xk).
An example of such a function is f(x1, x2, x3, x4) = x1 · (x2)4 −x3/x4 or
g(x1, x2, x3) = (x3)2 · sin(x1 · x2 · x3).
Deﬁnition 12.4 Let E ⊆Rk be a set and let f be a real-valued function with
domain E. Fix a point P which is either in E or is an accumulation point of E
(in the sense discussed in Chapter 4). We say that
lim
x→P f(x) = ℓ,
with ℓa real number if, for each ǫ > 0 there is a δ > 0 such that, when x ∈E
and 0 < ∥x −P∥< δ, then
|f(x) −ℓ| < ǫ.
Compare this deﬁnition with the deﬁnition in Section 5.1: the only diﬀerence is
that we now measure the distance between points of the domain of f using ∥∥
instead of | |.
Example 12.5 The function
f(x1, x2, x3) =



x1x2
x2
1 + x2
2 + x2
3
if
(x1, x2, x3) ̸= 0
0
if
(x1, x2, x3) = 0
has no limit as x →0. For if we take x = (t, 0, 0) then we obtain the limit
lim
t→0 f(t, 0, 0) = 0

12.1. A NEW LOOK AT THE BASIC CONCEPTS OF ANALYSIS
255
while if we take x = (t, t, t) then we obtain the limit
lim
t→0 f(t, t, t) = 1
3 .
Thus, for ǫ < 1
6 = 1
2 · 1
3, there will exist no δ satisfying the deﬁnition of limit.
However, the function
g(x1, x2, x3, x4) = x2
1 + x2
2 + x2
3 + x2
4
satisﬁes
lim
x→0 g(x) = 0
because, given ǫ > 0, we take δ =
p
ǫ/4.
Then ∥x −0∥< δ implies that
|xj −0| <
p
ǫ/4 for j = 1, 2, 3, 4 hence
|g(x1, x2, x3, x4) −0| <

 √ǫ
√
4
2
+
 √ǫ
√
4
2
+
 √ǫ
√
4
2
+
 √ǫ
√
4
2 = ǫ.
Notice that, just as in the theory of one variable, the limit properties of f
at a point P are independent of the actual value of f at P.
Deﬁnition 12.6 Let f be a function with domain E ⊆Rk and let P ∈E. We
say that f is continuous at P if
lim
x→P f(x) = f(P) .
The limiting process respects the elementary arithmetic operations, just as
in the one-variable situation explored in Chapter 5. We will treat these matters
in the exercises. Similarly, continuous functions are closed under the arithmetic
operations (provided that we do not divide by zero). Next we turn to the more
interesting properties of the derivative. [We refer the reader to Appendix III for
a review of linear algebra.] In what follows, we use the notation tM to denote
the transpose of the matrix M. We need the transpose so that the indicated
matrix multiplications make sense.
Deﬁnition 12.7 Let f(x) be a function whose domain contains a ball B(P, r).
We say that f is diﬀerentiable at P if there is a 1 × k matrix MP = MP(f) such
that, for all h ∈Rk satisfying ∥h∥< r, it holds that
f(P + h) = f(P) + MP · th + RP(f, h) ,
(12.7.1)
where
lim
h→0
RP(f, h)
∥h∥
= 0 .
The matrix MP = MP(f) is called the derivative of f at P.

256
CHAPTER 12. FUNCTIONS OF SEVERAL VARIABLES
The best way to begin to understand any new idea is to reduce it to a
situation that we already understand. If f is a function of one variable that is
diﬀerentiable at P ∈R then there is a number M such that
lim
h→0
f(P + h) −f(P)
h
= M .
We may rearrange this equality as
f(P + h) −f(P)
h
−M = SP,
where SP →0 as h →0. But this may be rewritten as
f(P + h) = f(P) + M · h + RP(f, h),
(12.8)
where RP = h · SP and
lim
h→0
RP(f, h)
h
= 0 .
Equation (12.8) is parallel to the equation in Deﬁnition 12.7 that deﬁnes the
concept of derivative. The role of the 1 × k matrix MP is played here by the
numerical constant M. But a numerical constant is a 1 × 1 matrix. Thus our
equation in one variable is a special case of the equation in k variables. In one
variable, the matrix representing the derivative is just the singleton consisting
of the numerical derivative.
Note in passing that (in the one-variable case) the way that we now deﬁne
the derivative of a function of several variables is closely related to the Taylor
expansion. The number M in the one-variable case is the coeﬃcient of the ﬁrst
order term in that expansion, which we know from Chapter 9 to be the ﬁrst
derivative.
What is the signiﬁcance of the matrix MP in our deﬁnition of derivative
for a function of k real variables? Suppose that f is diﬀerentiable according
to Deﬁnition 12.7. Let us attempt to calculate the “partial derivative” (as in
calculus) with respect to x1 of f. Let h = (h, 0, . . . , 0). Then
f(P1 + h, P2, . . . , Pk) = f(P) + MP ·





h
0
...
0




+ RP(f, h) .
Rearranging this equation we have
f(P1 + h, P2, . . . , Pk) −f(P)
h
= (MP)1 + SP ,
where SP →0 as h →0 and (MP)1 is the ﬁrst entry of the 1 × k matrix MP.
But, letting h →0 in this last equation, we see that the partial derivative
with respect to x1 of the function f exists at P and equals (MP)1. A similar

EXERCISES
257
calculation shows that the partial derivative with respect to x2 of the function
f exists at P and equals (MP)2; likewise the partial derivative with respect to
xj of the function f exists at P and equals (MP)j for j = 1, . . . , k.
We summarize with a theorem:
Theorem 12.9 Let f be a function deﬁned on an open ball B(P, r) and sup-
pose that f is diﬀerentiable at P with derivative the 1 × k matrix MP. Then
the ﬁrst partial derivatives of f at P exist and they are, respectively, the entries
of MP. That is,
(MP)1 =
∂
∂x1
f(P) ,
(MP)2 =
∂
∂x2
f(P) ,
. . .
,
(MP)k =
∂
∂xk
f(P) .
Unfortunately the converse of this theorem is not true: it is possible for the
ﬁrst partial derivatives of f to exist at a single point P without f being diﬀer-
entiable at P in the sense of Deﬁnition 12.7. Counterexamples will be explored
in the exercises. On the other hand, the two diﬀerent notions of continuous
diﬀerentiablity are the same. We formalize this statement with a proposition:
Proposition 12.10 Let f be a function deﬁned on an open ball B(P, r). As-
sume that f is diﬀerentiable at each point of B(P, r) in the sense of Deﬁnition
12.7 and that the function
x 7→Mx
is continuous in the sense that each of the functions
x 7→(Mx)j
is continuous, j = 1, 2, . . . , k. Then each of the partial derivatives
∂
∂x1
f(x)
∂
∂x2
f(x)
. . . ,
∂
∂xk
f(x)
exists for x ∈B(P, r) and is continuous.
Conversely, if each of the partial derivatives exists on B(P, r) and is contin-
uous at each point then Mx exists at each point x ∈B(P, r) and is continuous.
The entries of Mx are given by the partial derivatives of f.
Proof: This is essentially a routine check of deﬁnitions. The only place where
the continuity is used is in proving the converse: that the existence and con-
tinuity of the partial derivatives implies the existence of Mx. In proving the
converse you should apply the one-variable Taylor expansion to the function
t 7→f(x + th).
Exercises
1. Fix elements s, t, u ∈Rk. First assume that these three points are colinear.
By reduction to the one-dimensional case, prove the triangle inequality
∥s −t∥≤∥s −u∥+ ∥u −t∥.

258
CHAPTER 12. FUNCTIONS OF SEVERAL VARIABLES
Now establish the general case of the triangle inequality by comparison
with the colinear case.
2. Give another proof of the triangle inequality by squaring both sides and
invoking the Schwarz inequality.
3. If s, t ∈Rk then prove that
∥s + t∥≥∥s∥−∥t∥.
4. Formulate and prove the elementary properties of limits for functions of
k variables (refer to Chapter 5 for the one-variable analogues).
5. Prove Proposition 12.10.
6. Give an example of an inﬁnitely diﬀerentiable function with domain R2
such that {(x1, x2) : f(x1, x2) = 0} = {(x1, x2) : |x1|2 + |x2|2 ≤1}.
7. Formulate a notion of uniform convergence for functions of k real vari-
ables. Prove that the uniform limit of a sequence of continuous functions
is continuous.
8. Formulate a notion of “compact set” for subsets of Rk. Prove that the
continuous image, under a vector-valued function, of a compact set is
compact.
9. Refer to Exercise 8. Prove that if f is a continuous function on a compact
set then f assumes both a maximum value and a minimum value.
10. Justify our notion of distance in Rk using Pythagorean Theorem consid-
erations.
*
11. Give an example of a function f of two variables such that f has both ﬁrst
partial derivatives at a point P, yet f is not diﬀerentiable at P according
to Deﬁnition 12.7.
12.2
Properties of the Derivative
The arithmetic properties of the derivative—that is the sum and diﬀerence,
scalar multiplication, product, and quotient rules—are straightforward and are
left to the exercises for you to consider. However, the Chain Rule takes on a
diﬀerent form and requires careful consideration.
In order to treat meaningful instances of the Chain Rule, we must ﬁrst
discuss vector-valued functions. That is, we consider functions with domain a
subset of Rk and range either R1 or R2 or Rm for some integer m > 0. When we
consider vector-valued functions, it simpliﬁes notation if we consider all vectors
to be column vectors. This convention will be in eﬀect for the rest of the chapter.
(Thus we will no longer use the “transpose” notation.) Note in passing that the

12.2. PROPERTIES OF THE DERIVATIVE
259
expression ∥x∥means the same thing for a column vector as it does for a row
vector—the square root of the sum of the squares of the components. Also f(x)
means the same thing whether x is written as a row vector or a column vector.
Example 12.11 Deﬁne the function
f(x1, x2, x3) =

(x1)2 −x2 · x3
x1 · (x2)3

.
This is a function with domain consisting of all triples of real numbers, or R3,
and range consisting of all pairs of real numbers, or R2. For example,
f(−1, 2, 4) =

−7
−8

.
We say that a vector-valued function of k variables
f(x) = (f1(x), f2(x), . . . , fm(x))
(where m is a positive integer) is diﬀerentiable at a point P if each of its com-
ponent functions is diﬀerentiable in the sense of Section 1. For example, the
function
f(x1, x2, x3) =
 x1 · x2
(x3)2

is diﬀerentiable at all points while the function
g(x1, x2, x3) =

x2
|x3| −x1

is not diﬀerentiable at points of the form (x1, x2, 0).
It is a good exercise in matrix algebra (which you will be asked to do at the
end of the section) to verify that a vector-valued function f is diﬀerentiable at
a point P if and only if there is an m × k matrix (where k is the dimension of
the domain and m the dimension of the range) MP(f) such that
f(P + h) = f(P) + MP(f)h + RP(f, h) ;
here h is a k-column vector and the remainder term RP is a column vector
satisfying
∥RP(f, h)∥
∥h∥
→0
as h →0. One nice consequence of this formula is that, by what we learned
in the last section about partial derivatives, the entry in the ith row and jth
column of the matrix M is ∂fi/∂xj.
Of course the Chain Rule provides a method for diﬀerentiating compositions
of functions. What we will discover in this section is that the device of thinking
of the derivative as a matrix occurring in an expansion of f about a point a
makes the Chain Rule a very natural and easy result to derive. It will also prove
to be a useful way of keeping track of information.

260
CHAPTER 12. FUNCTIONS OF SEVERAL VARIABLES
Theorem 12.12 Let g be a function of k real variables taking values in Rm
and let f be a function of m real variables taking values in Rn. Suppose that
the range of g is contained in the domain of f, so that f ◦g makes sense. If g
is diﬀerentiable at a point P in its domain and f is diﬀerentiable at g(P) then
f ◦g is diﬀerentiable at P and its derivative is Mg(P)(f) · MP(g). We use the
symbol · here to denote matrix multiplication.
Proof: By the hypothesis about the diﬀerentiability of g,
(f ◦g)(P + h) = f(g(P + h))
= f

g(P) + MP(g)h + RP(g, h)

= f (g(P) + k) ,
(12.12.1)
where
k = MP(g)h + RP(g, h) .
But then the diﬀerentiability of f at g(P) implies that (12.12.1) equals
f(g(P)) + Mg(P)(f)k + Rg(P)(f, k) .
Now let us substitute in the value of k. We ﬁnd that
(f ◦g)(P + h)
=
f(g(P)) + Mg(P)(f)[MP(g)h + RP(g, h)]
+Rg(P)(f, MP(g)h + RP(g, h))
=
f(g(P)) + Mg(P)(f)MP(g)h
+

Mg(P)(f)RP(g, h)
+ Rg(P)(f, MP(g)h + RP(g, h))
	
≡
f(g(P)) + Mg(P)(f)MP(g)h
+QP(f ◦g, h) ,
where the last equality deﬁnes Q.
The term Q should be thought of as a
remainder term. Since
∥RP(g, h)∥
∥h∥
→0
as h →0, it follows that
Mg(P)(f)RP(g, h)
∥h∥
→0 .
(Details of this assertion are requested of you in the exercises.) Similarly,
Rg(P)(f, MP(g)h + RP(g, h))
∥h∥
→0

12.2. PROPERTIES OF THE DERIVATIVE
261
as h →0.
In conclusion, we see that f ◦g is diﬀerentiable at P and that the derivative
equals Mg(P)(f)MP(g), the product of the derivatives of f and g.
Remark 12.13 Notice that, by our hypotheses, MP(g) is an m× k size matrix
and Mg(P)(f) is an n × m size matrix. Thus their product makes sense.
In general, if g is a function from a subset of Rk to Rm then, if we want
f ◦g to make sense, f must be a function from a subset of Rm to some Rn. In
other words, the dimension of the range of g had better match the dimension
of the domain of f. Then the derivative of g at some point P will be an m × k
matrix and the derivative of f at g(P) will be an n × m matrix. Hence the
matrix multiplication Mg(P)(f)MP(g) will make sense.
Corollary 12.14 (The Chain Rule in Coordinates) Let f : Rm →Rn
and g : Rk →Rm be vector-valued functions and assume that h = f ◦g makes
sense. If g is diﬀerentiable at a point P of its domain and f is diﬀerentiable at
g(P) then for each i and j we have
∂hi
∂xj
(P) =
m
X
ℓ=1
∂fi
∂sℓ
(g(P)) · ∂gℓ
∂xj
(P) .
Proof: The function ∂hi/xj is the entry of MP(h) in the ith row and jth
column. However, MP(h) is the product of Mg(P)(f) with MP(g). The entry
in the ith row and jth column of that product is
m
X
ℓ=1
∂fi
∂sℓ
(g(P)) · ∂gℓ
∂xj
(P).
We conclude this section by deriving a Taylor expansion for scalar-valued
functions of k real variables: this expansion for functions of several variables is
derived in an interesting way from the expansion for functions of one variable.
We say that a function f of several real variables is k times continuously diﬀer-
entiable if all partial derivatives of orders up to and including k exist and are
continuous on the domain of f.
Theorem 12.15 (Taylor’s Expansion) For q a nonnegative integer let f be
a q+1 times continuously diﬀerentiable scalar-valued function on a neighborhood
of a closed ball B(P, r) ⊆Rk. Then, for x ∈B(P, r),
f(x)
=
X
0≤j1+j2+···+jk≤q
∂j1+j2+···+jkf
∂xj1
1 ∂xj2
2 · · · ∂xjk
k
(P) · (x1 −P1)j1(x2 −P2)j2 · · · (xk −Pk)jk
(j1)!(j2)! · · · (jk)!
+ Rq,P(x),

262
CHAPTER 12. FUNCTIONS OF SEVERAL VARIABLES
where
|Rq,P(x)| ≤C0 · ∥x −P∥q+1
(q + 1)!
,
and
C0 =
sup
s∈B(P,r)
ℓ1+ℓ2+···+ℓk=q+1

∂j1+j2+···+jkf
∂xj1
1 ∂xj2
2 · · · ∂xjk
k
(s)
 .
Proof: With P and x ﬁxed, deﬁne
F(s) = f(P + s(x −P)) ,
0 ≤s <
r
∥x −P∥.
We apply the one-dimensional Taylor theorem to the function F, expanded
about the point 0:
F(s) =
q
X
ℓ=0
F(ℓ)(0)sℓ
ℓ! + Rq,0(F, s) .
Now the Chain Rule shows that
F(ℓ)(0)
=
X
j1+j2+···+jk=ℓ
∂j1+j2+···+jkf
∂xj1
1 ∂xj2
2 · · · ∂xjk
k
(P)
·
ℓ!
(j1)!(j2)! · · · (jk)! · (x1 −P1)j1(x2 −P2)j2 · · · (xk −Pk)jk .
Substituting this last equation, for each ℓ, into the formula for F(s) and setting
s = 1 (recall that r/∥x−P∥> 1 since x ∈B(P, r)) yields the desired expression
for f(x). It remains to estimate the remainder term.
The one-variable Taylor theorem tells us that, for s > 0,
|Rq,0(F, s)|
=

Z s
0
F(q+1)(σ)(s −σ)q
q!
dσ

≤
Z s
0
C0 · ∥x −P∥q+1 ·

(s −σ)q
q!
 dσ
=
C0 · ∥x −P∥q+1
(q + 1)!
.
Here we have of course used the Chain Rule to pass from derivatives of F to
derivatives of f. This is the desired result.

EXERCISES
263
Exercises
1. Formulate a product rule for functions taking values in Rm for m > 1.
2. Use the Chain Rule for a function f : Rn →Rn to ﬁnd a formula for the
derivative of the inverse of f in terms of the derivative of f itself.
3. Formulate a deﬁnition of second derivative parallel to the deﬁnition of ﬁrst
derivative given in Section 12.2. Your deﬁnition should involve a matrix.
What does this matrix tell us about the second partial derivatives of the
function?
4. If f and g are vector-valued functions both taking values in Rk and both
having the same domain, then we can deﬁne the dot product function
h(x) = f(x) · g(x). Formulate and prove a product rule for this type of
product.
5. Prove that if a function with domain an open subset of Rk is diﬀerentiable
at a point P then it is continuous at P.
6. Verify the last two assertions in the proof of Theorem 12.12.
7. Let f be a function deﬁned on a ball B(P, r). Let u = (u1, u2, . . . , uk) be
a vector of unit length. If f is diﬀerentiable at P then give a deﬁnition of
the directional derivative Duf(P) of f in the direction u at P in terms of
MP.
8. If f is diﬀerentiable on a ball B(P, r) and if Mx is the zero matrix for
every x ∈B(P, r) then prove that f is constant on B(P, r).
9. Refer to Exercise 7 for notation. For which collections of vectors u1, u2, . . . , uk
in Rk is it true that if Dujf(x) = 0 for all x ∈B(P, r) and all j =
1, 2, . . . , k then f is identically constant?
*
10. There is no mean value theorem as such in the theory of functions of
several real variables. For example, if γ : [0, 1] →Rk is a diﬀerentiable
function on (0, 1), continuous on [0, 1], then it is not necessarily the case
that there is a point ξ ∈(0, 1) such that ˙γ(ξ) = γ(1) −γ(0). Provide a
counterexample to substantiate this claim.
However, there is a serviceable substitute for the mean value theorem: if
we assume that γ : [a, b] →RN is continuously diﬀerentiable on an open
interval that contains [a, b] and if M = maxt∈[a,b] |˙γ(t)| then
|γ(b) −γ(a)| ≤M · |b −a|.
Prove this statement.
*
11. What does the Taylor expansion of a function of two variables look like?
Explain your answer.

264
CHAPTER 12. FUNCTIONS OF SEVERAL VARIABLES
12. Prove that a vector-valued function f is diﬀerentiable at a point P if and
only if there is an m × k matrix (where k is the dimension of the domain
and m the dimension of the range) MP(f) such that
f(P + h) = f(P) + MP(f)h + RP(f, h) ;
here h is a k-column vector and the remainder term RP is a column vector
satisfying
∥RP(f, h)∥
∥h∥
→0
as h →0.
13. Conﬁrm the vanishing of the remainder term at the end of the proof of
the Chain Rule.
12.3
The Inverse and Implicit Function Theo-
rems
It is easy to tell whether a continuous function of one real variable is invertible. If
the function is strictly monotone increasing or strictly decreasing on an interval
then the restriction of the function to that interval is invertible. The converse
is true as well. It is more diﬃcult to tell whether a function of several variables,
when restricted to a neighborhood of a point, is invertible. The reason, of course,
is that such a function will in general have diﬀerent monotonicity behavior in
diﬀerent directions.
However, if we look at the one-variable situation in a new way, it can be
used to give us an idea for analyzing functions of several variables. Suppose
that f is continuously diﬀerentiable on an open interval I and that P ∈I. If
f ′(P) > 0 then the continuity of f ′ tells us that, for x near P, f ′(x) > 0. Thus
f is strictly increasing on some (possibly smaller) open interval J centered at
P. Such a function, when restricted to J, is an invertible function. The same
analysis applies when f ′(P) < 0.
Now the hypothesis that f ′(P) > 0 or f ′(P) < 0 has an important geometric
interpretation—the positivity of f ′(P) means that the tangent line to the graph
of f at P has positive slope, hence that the tangent line is the graph of an
invertible function (Figure 12.1); likewise the negativity of f ′(P) means that the
tangent line to the graph of f at P has negative slope, hence that the tangent
line is the graph of an invertible function (Figure 12.2). Since the tangent line
is a very close approximation at P to the graph of f, our geometric intuition
suggests that the local invertibility of f is closely linked to the invertibility of
the function describing the tangent line. This guess is in fact borne out in the
discussion in the last paragraph.
We would like to carry out an analysis of this kind for a function f from a
subset of Rk into Rk. If P is in the domain of f and if a certain derivative of f at
P (to be discussed below) does not vanish, then we would like to conclude that

12.3. THE INVERSE AND IMPLICIT FUNCTION THEOREMS
265
y
x
positive slope
means invertble
Figure 12.1: An invertible function.
y
x
negative slope
means invertible
Figure 12.2: Negative slope implies invertible.

266
CHAPTER 12. FUNCTIONS OF SEVERAL VARIABLES
there is a neighborhood U of P such that the restriction of f to U is invertible.
That is the content of the Inverse Function Theorem.
Before we formulate and prove this important theorem, we ﬁrst discuss the
kind of derivative of f at P that we shall need to examine.
Deﬁnition 12.16 Let f be a diﬀerentiable function from an open subset U of
Rk into Rk. The Jacobian matrix of f at a point P ∈U is the matrix
Jf(P) =












∂f1
∂x1
(P)
∂f1
∂x2
(P)
· · ·
∂f1
∂xk
(P)
∂f2
∂x1
(P)
∂f2
∂x2
(P)
· · ·
∂f2
∂xk
(P)
· · ·
∂fk
∂x1
(P)
∂fk
∂x2
(P)
· · ·
∂fk
∂xk
(P)












.
Notice that if we were to expand the function f in a Taylor series about P
(this would be in fact a k-tuple of expansions, since f = (f1, f2, . . . , fk)) then
the expansion would be
f(P + h) = f(P) + Jf(P)h + . . . .
Thus the Jacobian matrix is a natural object to study. Moreover we see that
the expression f(P+h)−f(P) is well approximated by the expression Jf(P)h.
Thus, in analogy with one-variable analysis, we might expect that the invert-
ibility of the matrix Jf(P) would imply the existence of a neighborhood of P
on which the function f is invertible. This is indeed the case:
Theorem 12.17 (The Inverse Function Theorem) Let f be a continuously
diﬀerentiable function from an open set U ⊆Rk into Rk. Suppose that P ∈U
and that the matrix Jf(P) is invertible. Then there is a neighborhood V of P
such that the restriction of f to V is invertible.
Proof: The proof of the theorem as stated is rather diﬃcult. Therefore we
shall content ourselves with the proof of a special case: we shall make the
additional hypothesis that the function f is twice continuously diﬀerentiable in
a neighborhood of P.
Choose s > 0 such that B(P, s) ⊆U and so that det Jf(x) ̸= 0 for all
x ∈B(P, s). Thus the Jacobian matrix Jf(x) is invertible for all x ∈B(P, s).
With the extra hypothesis, Taylor’s theorem tells us that there is a constant C
such that if ∥h∥< s/2 then
f(Q + h) −f(Q) = Jf(Q)h + R1,Q(f, h) ,
(12.17.1)
where
|R1,Q(h)| ≤C · ∥h∥2
2! ,

12.3. THE INVERSE AND IMPLICIT FUNCTION THEOREMS
267
and
C =
sup
t∈B(Q,r)
j1+j2+···+jk=2

∂j1+j2+···+jkf
∂xj1
1 ∂xj2
2 · · · ∂xjk
k
 .
However, all the derivatives in the sum specifying C are, by hypothesis, continu-
ous functions. Since all the balls B(Q, s/2) are contained in the compact subset
B(P, s) of U it follows that we may choose C to be a ﬁnite number independent
of Q.
Now the matrix Jf(Q)−1 exists by hypothesis.
The coeﬃcients of this
matrix will be continuous functions of Q because those of Jf are. Thus these
coeﬃcients will be bounded above on B(P, s). By Corollary A2.10 in Appendix
I, there is a constant K > 0 independent of Q such that for every k ∈Rk we
have
∥Jf(Q)−1k∥≤K∥k∥.
Taking k = Jf(Q)h yields
∥h∥≤K∥Jf(Q)h∥.
(12.17.2)
Now set
r = min{s/2, 1/(KC)}.
Line (12.17.1) tells us that, for Q ∈B(P, r) and ∥h∥< r,
∥f(Q + h) −f(Q)∥≥∥Jf(Q)h∥−∥R1,Q(h)∥.
But estimate (12.17.2), together with our estimate from above on the error term
R, yields that the right side of this equation is
≥∥h∥
K −C
2 ∥h∥2.
The choice of r tells us that ∥h∥≤1/(KC) hence the last line majorizes
(K/2)∥h∥.
But this tells us that, for any Q ∈B(P, r) and any h satisfying ∥h∥< r, it
holds that f(Q + h) ̸= f(Q). In particular, the function f is one-to-one when
restricted to the ball B(P, r/2). Thus f|B(P,s/2) is invertible.
In fact the estimate
∥f(Q + h) −f(Q)∥≥K
2 ∥h∥
that we derived easily implies that the image of every B(Q, s) contains an open
ball B(f(Q), s′), some s′ > 0. This means that f is an open mapping. You will
be asked in the exercises to provide the details of this assertion.
With some additional eﬀort it can be shown that f −1 is continuously dif-
ferentiable in a neighborhood of f(P). However, the details of this matter are
beyond the scope of this book. We refer the interested reader to [RUD1].

268
CHAPTER 12. FUNCTIONS OF SEVERAL VARIABLES
Next we turn to the Implicit Function Theorem. This result addresses the
question of when we can solve an equation
f(x1, x2, . . . , xk) = 0
for one of the variables in terms of the other (k −1) variables. It is illustrative
to ﬁrst consider a simple example. Look at the equation
f(x1, x2) = (x1)2 + (x2)2 = 1 .
We may restrict attention to −1 ≤x1 ≤1, −1 ≤x2 ≤1. As a glance at the
graph shows, we can solve this equation for x2, uniquely in terms of x1, in a
neighborhood of any point except for the points (±1, 0). At these two exceptional
points it is impossible to avoid the ambiguity in the square root process, even
by restricting to a very small neighborhood. At other points, we may write
t2 = +
p
1 −(t1)2
for points (t1, t2) near (x1, x2) when x2 > 0 and
t2 = −
p
1 −(t1)2
for points (t1, t2) near (x1, x2) when x2 < 0.
What distinguishes the two exceptional points from the others is that the
tangent line to the locus (a circle) is vertical at each of these points. Another
way of saying this is that
∂f
x2
= 0
at these points (Figure 12.3). These preliminary considerations motivate the
following theorem.
Theorem 12.18 (The Implicit Function Theorem) Let f be a function of
k real variables, taking scalar values, whose domain contains a neighborhood of
a point P. Assume that f is continuously diﬀerentiable and that f(P) = 0. If
(∂f/∂xk)(P) ̸= 0 then there are numbers δ > 0, η > 0 such that if |x1 −P1| < δ,
|x2−P2| < δ, . . . , |xk−1−Pk−1| < δ, then there is a unique xk with |xk−Pk| < η
and
f(x1, x2, . . . , xk) = 0.
(12.18.1)
In other words, in a neighborhood of P, the equation (12.18.1) uniquely deter-
mines xk in terms of x1, x2, . . . , xk−1.
Proof: We consider the function
T : (x1, x2, . . . , xk) 7−→(x1, x2, . . . , xk−1, f(x1, x2, . . . , xk)) .
The Jacobian matrix of T at P is

EXERCISES
269
y
x
vertical slope so
cannot solve for
x   in terms of x   .
2
1
Figure 12.3: Vertical tangents.







1
0
· · ·
0
0
1
· · ·
0
· · ·
0
· · ·
1
0
∂f
∂x1 (P)
∂f
∂x2 (P)
· · ·
∂f
∂xk (P)







.
Of course the determinant of this matrix is ∂f/∂xk(P), which we hypothesized
to be nonzero. Thus the Inverse Function Theorem applies to T . We conclude
that T is invertible in a neighborhood of P. That is, there is a number η > 0
and a neighborhood W of the point (P1, P2, . . . , Pk−1, 0) such that
T : B(P, η) 7−→W
is a one-to-one, onto, continuously diﬀerentiable function which is invertible.
Select δ > 0 such that if |x1 −P1| < δ, |x2 −P2| < δ, . . . , |xk−1 −Pk−1| < δ
then the point (x1, x2, . . . , xk−1, 0) ∈W. Such a point (x1, x2, . . . , xk−1, 0) then
has a unique inverse image under T that lies in B(P, η). But this just says that
there is a unique xk such that f(x1, x2, . . . , xk) = 0. We have established the
existence of δ and η as required, hence the proof is complete.
Exercises
*
1. Prove that the Inverse Function Theorem implies the Implicit Function
Theorem.
2. Prove that a function satisfying the hypotheses of the Inverse Function
Theorem is an open mapping in a neighborhood of the point P.

270
CHAPTER 12. FUNCTIONS OF SEVERAL VARIABLES
3. Prove that the Implicit Function Theorem is still true if the equation
f(x1, x2, . . . , xk) = 0 is replaced by f(x1, x2, . . . , xk) = c. (Hint: Do not
repeat the proof of the Implicit Function Theorem.)
4. Let f be a twice continuously diﬀerentiable curve in R2. Use the Inverse
Function Theorem to show that there is a well-deﬁned notion of “projec-
tion” of a neighborhood of the curve onto the curve itself.
5. Provide the details of the open mapping discussion following the Inverse
Function Theorem in the text.
6. Let y = ϕ(x) be a twice continuously diﬀerentiable function on [0, 1] with
nonvanishing ﬁrst derivative. Let U be the graph of ϕ. Show that there is
an open neighborhood W of U so that, if P ∈W, then there is a unique
point X ∈U which is nearest to P.
7. Give an example of a curve which is not twice continuously diﬀerentiable
for which the result of Exercise 6 fails.
* 8. Use the Implicit Function Theorem to give a proof of the Fundamental
Theorem of Algebra.
9. Use the Implicit Function Theorem to show that the natural logarithm
function can have only one zero.
10. Use the Implicit Function Theorem to show that the exponential function
can have no zeros.

Chapter 13
Advanced Topics
13.1
Metric Spaces
As you studied Chapter 12, and did the exercises developing the basic properties
of functions of several variables, you should have noticed that many of the proofs
were identical to those in Chapters 5 and 6. The arguments generally involved
clever use of the triangle inequality. For functions of one variable, the inequality
was for | |. For functions of several variables, the inequality was for ∥∥.
This section formalizes a general context in which we may do analysis any
time we have a reasonable notion of calculating distance. Such a structure will
be called a metric:
Deﬁnition 13.1 A metric space is a pair (X, ρ), where X is a set and
ρ : X × X →{t ∈R : t ≥0}
is a function satisfying
1. ∀x, y ∈X, ρ(x, y) = ρ(y, x);
2. ρ(x, y) = 0 if and only if x = y;
3. ∀x, y, z ∈X, ρ(x, y) ≤ρ(x, z) + ρ(z, y).
The function ρ is called a metric on X.
Example 13.2 The pair (R, ρ), where ρ(x, y) = |x−y|, is a metric space. Each
of the properties required of a metric is in this case a restatement of familiar
facts from the analysis of one dimension.
The pair (Rk, ρ), where ρ(x, y) = ∥x −y∥, is a metric space. Each of the
properties required of a metric is in this case a restatement of familiar facts
from the analysis of k dimensions.
The ﬁrst example presented familiar metrics on two familiar spaces. Now
we look at some new ones.
271

272
CHAPTER 13. ADVANCED TOPICS
Example 13.3 The pair (R2, ρ), where ρ(x, y) = max{|x1 −y1|, |x2 −y2|}, is
a metric space. Only the triangle inequality is not trivial to verify, but that
reduces to the triangle inequality of one variable.
The pair (R, µ), where µ(x, y) = 1 if x ̸= y and 0 otherwise, is a metric
space. Checking the triangle inequality reduces to seeing that if x ̸= y then
either x ̸= z or y ̸= z.
Example 13.4 Let X denote the space of continuous functions on the interval
[0, 1]. If f, g ∈X then let ρ(f, g) = supt∈[0,1] |f(t)−g(t)|. Then the pair (X, ρ) is
a metric space. The ﬁrst two properties of a metric are obvious and the triangle
inequality reduces to the triangle inequality for real numbers.
This example is a dramatic new departure from the analysis we have done in
the previous thirteen chapters. For X is a very large space—inﬁnite dimensional
in a certain sense. Using the ideas that we are about to develop, it is nonetheless
possible to study convergence, continuity, compactness, and the other basic
concepts of analysis in this more general context. We shall see applications of
these new techniques in later sections.
Now we begin to develop the tools of analysis in metric spaces.
Deﬁnition 13.5 Let (X, ρ) be a metric space. A sequence {xj} of elements of
X is said to converge to a point α ∈X if, for each ǫ > 0, there is an N > 0
such that if j > N then ρ(xj, α) < ǫ. We call α the limit of the sequence {xj}.
We sometimes write xj →α.
Compare this deﬁnition of convergence with the corresponding deﬁnition
for convergence in the real line in Section 2.1. Notice that it is identical, except
that the sense in which distance is measured is now more general.
Example 13.6 Let (X, ρ) be the metric space from Example 13.4, consisting of
the continuous functions on the unit interval with the indicated metric function
ρ. Then f = sin x is an element of this space, and so are the functions
fj =
j
X
ℓ=0
(−1)ℓ
x2ℓ+1
(2ℓ+ 1)! .
Observe that the functions fj are the partial sums for the Taylor series of sin x.
We can check from simple estimates on the error term of Taylor’s theorem that
the functions fj converge uniformly to f.
Thus, in the language of metric
spaces, fj →f in the metric space notion of convergence.
Deﬁnition 13.7 Let (X, ρ) be a metric space. A sequence {xj} of elements of
X is said to be Cauchy if, for each ǫ > 0 there is an N > 0 such that if j, k > N
then ρ(xj, xk) < ǫ.
Now the Cauchy criterion and convergence are connected in the expected
fashion:

13.1. METRIC SPACES
273
Proposition 13.8 Let {xj} be a convergent sequence, with limit α, in the
metric space (X, ρ). Then the sequence {xj} is Cauchy.
Proof: Let ǫ > 0. Choose an N so large that, if j > N, then ρ(xj, α) < ǫ/2. If
j, k > N then
ρ(xj, xk) ≤ρ(xj, α) + ρ(α, xk) < ǫ
2 + ǫ
2 = ǫ .
That completes the proof.
The converse of the proposition is true in the real numbers (with the usual
metric), as we proved in Section 1.1. However, it is not true in every metric
space. For example, the rationals Q with the usual metric ρ(s, t) = |s −t| is a
metric space; but the sequence
3, 2.1, 2.14, 2.141, 2.1415, 2.14159, . . . ,
while certainly Cauchy, does not converge to a rational number. Thus we are
led to a deﬁnition:
Deﬁnition 13.9 We say that a metric space (X, ρ) is complete if every Cauchy
sequence converges to an element of the metric space.
Thus the real numbers, with the usual metric, form a complete metric space.
The rational numbers do not.
Example 13.10 Consider the metric space (X, ρ) from Example 13.4 above,
consisting of the continuous functions on the closed unit interval with the in-
dicated metric function ρ. If {gj} is a Cauchy sequence in this metric space
then each gj is a continuous function on the unit interval and this sequence of
continuous functions is Cauchy in the uniform sense (see Chapter 8). Therefore
they converge uniformly to a limit function g that must be continuous. We
conclude that the metric space (X, ρ) is complete.
Example 13.11 Consider the metric space (X, ρ) consisting of the polyno-
mials, taken to have domain the interval [0, 1], with the distance function
ρ(f, g) = supt∈[0,1] |f(t) −g(t)|. This metric space is not complete. For if h is
any continuous function on [0, 1] that is not a polynomial, such as h(x) = sin x,
then by the Weierstrass Approximation Theorem there is a sequence {pj} of
polynomials that converges uniformly on [0, 1] to h. Thus this sequence {pj}
will be Cauchy in the metric space, but it does not converge to an element of
the metric space. We conclude that the metric space (X, ρ) is not complete.
If (X, ρ) is a metric space then an (open) ball with center P ∈X and radius
r is the set
B(P, r) = {x ∈X : ρ(x, P) < r} .
The closed ball with center P and radius r is the set
B(P, r) = {x ∈X : ρ(x, P) ≤r} .

274
CHAPTER 13. ADVANCED TOPICS
Deﬁnition 13.12 Let (X, ρ) be a metric space and E a subset of X. A point
P ∈E is called an isolated point of E if there is an r > 0 such that E∩B(P, r) =
{P}. If a point of E is not isolated then it is called nonisolated.
We see that the notion of “isolated” has intuitive appeal: an isolated point
is one that is spaced apart—at least distance r—from the other points of the
space. A nonisolated point, by contrast, has neighbors that are arbitrarily close.
Deﬁnition 13.13 Let (X, ρ) be a metric space and f : X →R. If P ∈X is a
nonisolated point and ℓ∈R we say that the limit of f at P is ℓ, and write
lim
x→P f(x) = ℓ,
if for any ǫ > 0 there is a δ > 0 such that if 0 < ρ(x, P) < δ then |f(x) −ℓ| < ǫ.
Notice in this deﬁnition that we use ρ to measure distance in X—that is the
natural notion of distance with which X comes equipped—but we use absolute
values to measure distance in R.
The following lemma will prove useful.
Lemma 13.14 Let (X, ρ) be a metric space and P ∈X a nonisolated point.
Let f be a function from X to R. Then limx→P f(x) = ℓif and only if, for every
sequence {xj} ⊆X satisfying xj →P, it holds that f(xj) →f(P).
Proof: This is straightforward and is treated in the exercises.
Deﬁnition 13.15 Let (X, ρ) be a metric space and E a subset of X. Suppose
that P ∈E. We say that a function f : E →R is continuous at P if
lim
x→P f(x) = f(P) .
Example 13.16 Let (X, ρ) be the space of continuous functions on the interval
[0, 1] equipped with the supremum metric as in Example 13.4 above. Deﬁne the
function F : X →R by the formula
F(f) =
Z 1
0
f(t) dt .
Then F takes an element of X, namely a continuous function, to a real number,
namely its integral over [0, 1]. We claim that F is continuous at every point of
X.
For ﬁx a point f ∈X. If {fj} is a sequence of elements of X converging in
the metric space sense to the limit f, then (in the language of classical analysis
as in Chapters 5–8) the fj are continuous functions converging uniformly to the
continuous function f on the interval [0, 1]. But, by Theorem 8.8, it follows that
Z 1
0
fj(t) dt →
Z 1
0
f(t) dt .

EXERCISES
275
But this just says that F(fj) →F(f). Using the lemma, we conclude that
lim
g→f F(g) = F(f) .
Therefore F is continuous at f.
Since f ∈X was chosen arbitrarily, we conclude that the function F is
continuous at every point of X.
In the next section we shall develop some topological properties of metric
spaces.
Exercises
1. Let (X, ρ) be a metric space. Prove that the function
σ(s, t) =
ρ(s, t)
1 + ρ(s, t)
is also a metric on X and that the open sets deﬁned by the metric ρ are
the same as the open sets deﬁned by σ. Finally prove that σ(s, t) < 1 for
all s, t ∈X. This is a method for constructing a bounded metric from an
arbitrary metric.
2. Let (X, ρ) be a metric space and E a subset of X. Deﬁne the boundary of
E to be those elements x ∈X with the property that every ball B(x, r)
contains both points of E and points of cE. Prove that the boundary of
E must be closed. Prove that the interior of E (deﬁne!) is disjoint from
the boundary of E.
3. Let (X, ρ) and (Y, σ) be metric spaces. Describe a method for equipping
the set X × Y with a metric manufactured from ρ and σ.
4. Let X be the collection of all continuously diﬀerentiable functions on the
interval [0, 1]. If f, g ∈X then deﬁne
ρ(f, g) = sup
x∈[0,1]
|f ′(x) −g′(x)| .
Is ρ a metric? Why or why not?
5. Prove Lemma 13.14.
6. Consider the set of all polynomials of one variable of degree not exceeding
4, and deﬁne
ρ(p, q)
=
max{|p(1) −q(1)|, |p(2) −q(2)|, |p(3) −q(3)|,
|p(4) −q(4)|, |p(5) −q(5)|, |p(6) −q(6)|} .
Prove that ρ is a metric on this space of polynomials. Why does this not
work if we consider polynomials of degree not exceeding 10?

276
CHAPTER 13. ADVANCED TOPICS
7. How many diﬀerent metrics are there on the space with three points?
8. Deﬁne a metric on the real numbers R so that the space becomes discrete.
9. Give an example of a metric space which is discrete.
* 10. Can there be a countable, complete metric space?
13.2
Topology in a Metric Space
Fix a metric space (X, ρ). A set U ⊆X is called open if for each u ∈U there is
an r > 0 such that B(u, r) ⊆U. A set E ⊆X is called closed if its complement
in X is open. Notice that these deﬁnitions are analogous to those that we gave
in the topology chapter for subsets of R.
Example 13.17 Consider the set of real numbers R equipped with the metric
ρ(s, t) = 1 if s ̸= t and ρ(s, t) = 0 otherwise. Then each singleton U = {x} is
an open set. For let P be a point of U. Then P = x and the ball B(P, 1/2) lies
in U.
However, each singleton is also closed. For the complement of the singleton
U = {x} is the set S = R \ {x}. If s ∈S then B(s, 1/2) ⊆S as in the preceding
paragraph.
Example 13.18 Let (X, ρ) be the metric space of continuous functions on the
interval [0, 1] equipped with the metric ρ(f, g) = supx∈[0,1] |f(x) −g(x)|. Deﬁne
U = {f ∈X : f(1/2) > 5} .
Then U is an open set in the metric space.
To verify this assertion, ﬁx an
element f ∈U. Let ǫ = f(1/2) −5 > 0. We claim that the metric ball B(f, ǫ)
lies in U. For let g ∈B(f, ǫ). Then
g(1/2)
=
f(1/2) −|f(1/2) −g(1/2)|
≥
f(1/2) −ρ(f, g)
>
f(1/2) −ǫ
=
5 .
It follows that g ∈U. Since g ∈B(f, ǫ) was chosen arbitrarily, we may conclude
that B(f, ǫ) ⊆U. But this says that U is open.
We may also conclude from this calculation that
cU = {f ∈X : f(1/2) ≤5}
is closed.
Deﬁnition 13.19 Let (X, ρ) be a metric space and S ⊆X. A point x ∈X is
called an accumulation point of S (also called a limit point or a cluster point) if
every B(x, r) contains inﬁnitely many elements of S.

13.2. TOPOLOGY IN A METRIC SPACE
277
Proposition 13.20 Let (X, ρ) be a metric space. A set S ⊆X is closed if and
only if every accumulation point of S lies in S.
Proof: The proof is similar to the corresponding result in Section 4.1 and we
leave it to the exercises.
Deﬁnition 13.21 Let (X, ρ) be a metric space. A subset S ⊆X is said to be
bounded if S lies in some ball B(P, r).
Deﬁnition 13.22 Let (X, ρ) be a metric space. A set S ⊆X is said to be
compact if every sequence in S has a subsequence that converges to an element
of S.
Example 13.23 In Chapter 4 we learned that, in the real number system,
compact sets are closed and bounded, and conversely. Such is not the case in
general metric spaces.
As an example, consider the metric space (X, ρ) consisting of all contin-
uous functions on the interval [0, 1] with the supremum metric as in previous
examples. Let
S = {fj(x) = xj : j = 1, 2, . . . } .
This set is bounded since it lies in the ball B(0, 2) (here 0 denotes the identically
zero function). We claim that S contains no Cauchy sequences. This follows
(see the discussion of uniform convergence in Chapter 8) because, no matter
how large N is, if k > j > N then we may write
|fj(x) −fk(x)| =
xj (xk−j −1)
 .
Fix j. If x is suﬃciently near to 1 then |xj| > 3/4. But then we may pick k so
large that |xk−j| < 1/4. Thus
|fk(x) −fj(x)| ≥9/16 .
So there is no Cauchy subsequence. We may conclude (for vacuous reasons)
that S is closed.
But S is not compact. For, as just noted, the sequence {fj} consists of in-
ﬁnitely many distinct elements of S which do not have a convergent subsequence
(indeed not even a Cauchy subsequence).
In spite of the last example, half of the Heine-Borel theorem is true:
Proposition 13.24 Let (X, ρ) be a metric space and S a subset of X. If S is
compact then S is closed and bounded.
Proof: Let {sj} be a Cauchy sequence in S. By compactness, this sequence
must contain a subsequence converging to some limit P.
But since the full

278
CHAPTER 13. ADVANCED TOPICS
sequence is Cauchy, the full sequence must converge to P (exercise). Thus S is
closed.
If S is not bounded, we derive a contradiction as follows. Fix a point P1 ∈S.
Since S is not bounded we may ﬁnd a point P2 that has distance at least 1 from
P1. Since S is unbounded, we may ﬁnd a point P3 of S that is distance at least
2 from both P1 and P2. Continuing in this fashion, we select Pj ∈S which
is distance at least j from P1, P2, . . . Pj−1. Such a sequence {Pj} can have no
Cauchy subsequence, contradicting compactness. Therefore S is bounded.
Deﬁnition 13.25 Let S be a subset of a metric space (X, ρ). A collection of
open sets {Oα}α∈A (each Oα is an open set in X) is called an open covering of
S if
∪α∈AOα ⊇S .
Deﬁnition 13.26 If C is an open covering of a set S and if D is another open
covering of S such that each element of D is also an element of C then we call
D a subcovering of C.
We call D a ﬁnite subcovering if D has just ﬁnitely many elements.
Theorem 13.27 A subset S of a metric space (X, ρ) is compact if and only if
every open covering C = {Oα}α∈A of S has a ﬁnite subcovering.
Proof: The forward direction is beyond the scope of this book and we shall not
discuss it.
The proof of the reverse direction is similar in spirit to the proof in Section
4.3 (Theorem 4.32). We leave the details for the exercises.
Proposition 13.28 Let S be a compact subset of a metric space (X, ρ). If E
is a closed subset of S then E is compact.
Proof: Let C be an open covering of E. The set U = X \ E is open and the
covering C′ consisting of all the open sets in C together with the open set U
covers S. Since S is compact we may ﬁnd a ﬁnite subcovering
O1, O2, . . . Ok
that covers S. If one of these sets is U then discard it. The remaining k −1
open sets cover E.
The exercises will ask you to ﬁnd an alternative proof of this last fact.
Deﬁnition 13.29 If (X, ρ) is a metric space and E ⊆X then the closure of
E is deﬁned to be the union of E with the set of its accumulation points.

EXERCISES
279
Exercises
1. Let (X, ρ) be a metric space. Prove that the closure of any set in X is
closed. Prove that the closure of any E equals the union of the interior
and the boundary.
2. Let (X, ρ) be a metric space.
Let K1 ⊇K2 . . . be a nested family of
countably many nonempty compact sets. Prove that ∩jKj is a nonempty
set.
3. Give an example of a metric space (X, ρ), a point P ∈X, and a positive
number r such that B(P, r) is not the closure of the ball B(P, r).
4. Let (X, ρ) be a compact metric space. Prove that X has a countable dense
subset. [We call such a space separable.]
5. Let K be a compact subset of a metric space (X, ρ). Let P ∈X not lie in
K. Prove that there is an element k0 ∈K such that
ρ(k, P) = inf
x∈K ρ(x, P) .
6. Consider the metric space Q equipped with the Euclidean metric. Describe
all the open sets in this metric space.
7. In R, if I is an open interval then every element of I is a limit point of I. Is
the analogous statement true in an arbitrary metric space, with “interval”
replaced by “ball”?
8. The Bolzano-Weierstrass Theorem tells us that, in R1, a bounded inﬁ-
nite set must have a limit point. Show by example that the analogous
statement is false in an arbitrary metric space. But it is true in RN.
9. Let E be a subset of a metric space. Is the interior of E equal to the
interior of the closure of E? Is the closure of the interior of E equal to the
closure of E itself?
10. Let (X, ρ) be a metric space. Call a subset E of X connected if there do
not exist open sets U and V in X such that U ∩E and V ∩E are nonempty,
disjoint, and (U ∩E) ∪(V ∩E) = E. Is the closure of a connected set
connected? Is the product of two connected sets connected? Is the interior
of a connected set connected?
11. Refer to Exercise 10 for terminology.
Give exact conditions that will
guarantee that the union of two connected sets is connected.
12. Let (X, ρ) be the metric space of continuously diﬀerentiable functions on
the interval [0, 1] equipped with the metric
ρ(f, g) = sup
x∈[0,1]
|f(x) −g(x)| .

280
CHAPTER 13. ADVANCED TOPICS
Consider the function
T (f) = f ′(1/2) .
Is T continuous? Is there some metric with which we can equip X that
will make T continuous?
13. Let (X, ρ) be a metric space and let {xj} be a Cauchy sequence in X. If
a subsequence {xjk} converges to a point P ∈X then prove that the full
sequence {xj} converges to P.
14. Prove the converse direction of Theorem 13.27.
15. Give a proof of Proposition 13.28 that uses the sequential deﬁnition of
compactness.
*
16. Let (X, ρ) be any metric space.
Consider the space b
X of all Cauchy
sequences of elements of X, subject to the equivalence relation that {xj}
and {yj} are equivalent if ρ(xj, yj) →0 as j →∞. Explain why, in a
natural way, this space of equivalence class of Cauchy sequences may be
thought of as the completion of X, that is, explain in what sense b
X ⊇X
and b
X is complete. Prove that b
X is minimal in a certain sense. Prove
that if X is already complete then this space of equivalence classes can be
identiﬁed in a natural way with X.
17. It is a theorem (fairly tricky to prove) that a metric space always has
a countable dense subset.
What is the countable dense subset of the
space of continuous functions on the interval [0, 1]? What is the countable
dense subset of the space of polynomials of degree not exceeding 10 on the
interval [0, 1] (equipped with the supremum norm)?
18. Prove Proposition 13.20.
13.3
The Baire Category Theorem
Let (X, ρ) be a metric space and S ⊆X a subset. A set E ⊆X is said to be
dense in S if every element of S is the limit of some sequence of elements of E.
Example 13.30 The set of rational numbers Q is dense in any nontrivial in-
terval of R.
Example 13.31 Let (X, ρ) be the metric space of continuous functions on the
interval [0, 1] equipped with the supremum metric as usual. Let E ⊆X be the
polynomial functions. Then the Weierstrass Approximation Theorem tells us
that E is dense in X.
Example 13.32 Consider the real numbers R with the metric ρ(s, t) = 1 if
s ̸= t and ρ(s, t) = 0 otherwise. Then no proper subset of R is dense in R. To
see this, notice that if E were dense and were not all of R and if P ∈R\ E then
ρ(P, e) > 1/2 for all e ∈E. So elements of E do not get close to P. Thus E is
not dense in R.

13.3. THE BAIRE CATEGORY THEOREM
281
Refer to Deﬁnition 13.29 for the concept of closure of a set.
Example 13.33 Let (X, ρ) be the set of real numbers with the usual metric
and set E = Q ∩(−2, 2). Then the closure of E is [−2, 2].
Let (Y, σ) be the continuous functions on [0, 1] equipped with the supremum
metric as in Example 13.4. Take E ⊆Y to be the polynomials. Then the closure
of E is Y .
We note in passing that, if B(P, r) is a ball in a metric space (X, ρ), then
B(P, r) will contain but need not be equal to the closure of B(P, r) (for which
see Exercise 3 of the last section).
Deﬁnition 13.34 Let (X, ρ) be a metric space. We say that E ⊆X is nowhere
dense in X if the closure of E contains no ball B(x, r) for any x ∈X, r > 0.
Example 13.35 Let us consider the integers Z as a subset of the metric space
R equipped with the standard metric. Then the closure of Z is Z itself. And of
course Z contains no metric balls. Therefore Z is nowhere dense in R.
Example 13.36 Consider the metric space X of all continuous functions on
the unit interval [0, 1], equipped with the usual supremum metric. Fix k > 0
and consider
E ≡{p(x) : p is a polynomial of degree not exceeding k} .
Then the closure of E is E itself (that is, the limit of a sequence of polynomials of
degree not exceeeding k is still a polynomial of degree not exceeding k—details
are requested of you in the exercises). And E contains no metric balls. For if
p ∈E and r > 0 then p(x) + (r/2) · xk+1 ∈B(p, r) but p(x) + (r/2) · xk+1 ̸∈E.
We recall, as noted in Example 13.31 above, that the set of all polynomials
is dense in X; but if we restrict attention to polynomials of degree not exceeding
a ﬁxed number k then the resulting set is nowhere dense.
Theorem 13.37 (The Baire Category Theorem) Let (X, ρ) be a complete
metric space.
Then X cannot be written as the union of countably many
nowhere dense sets.
Proof: This proof is quite similar to the proof that we presented in Chapter 4
that a perfect set must be uncountable. You may wish to review that proof at
this time.
Seeking a contradiction, suppose that X may be written as a countable
union of nowhere dense sets Y1, Y2, . . . . Choose a point x1 ∈cY 1. Since Y1
is nowhere dense we may select an r1 > 0 such that B1 ≡B(x1, r1) satisﬁes
B1 ∩Y 1 = ∅. Assume without loss of generality that r1 < 1.
Next, since Y2 is nowhere dense, we may choose x2 ∈B1 ∩cY 2 and an
r2 > 0 such that B2 = B(x2, r2) ⊆B1 ∩cY 2. Shrinking B2 if necessary, we
may assume that r2 < 1
2r1. Continuing in this fashion, we select at the jth

282
CHAPTER 13. ADVANCED TOPICS
step a point xj ∈Bj−1 ∩cY j and a number rj > 0 such that rj < 1
2rj−1 and
Bj = B(xj, rj) ⊆Bj−1 ∩cY j.
Now the sequence {xj} is Cauchy since all the terms xj for j > N are
contained in a ball of radius rN < 2−N hence are not more than distance 2−N
apart. Since (X, ρ) is a complete metric space, we conclude that the sequence
converges to a limit point P. Moreover, by construction, P ∈Bj for every j
hence is in the complement of every Y j. Thus S
j Yj ̸= X. That is a contradic-
tion, and the proof is complete.
There is quite a lot of terminology associated with the Baire theorem, and
we shall not detail it all here. We do note that a Gδ is the countable intersection
of open sets.
Before we apply the Baire Category Theorem, let us formulate some re-
statements, or corollaries, of the theorem which follow immediately from the
deﬁnitions.
Corollary 13.38 Let (X, ρ) be a complete metric space.
Let Y1, Y2, . . . be
countably many closed subsets of X, each of which contains no nontrivial open
ball. Then S
j Yj also has the property that it contains no nontrivial open ball.
Corollary 13.39 Let (X, ρ) be a complete metric space. Let O1, O2, . . . be
countably many dense open subsets of X. Then T
j Oj is dense in X.
Note that the result of the second corollary follows from the ﬁrst corollary
by complementation. The set T
j Oj, while dense, need not be open.
Example 13.40 The metric space R, equipped with the standard Euclidean
metric, cannot be written as a countable union of nowhere dense sets.
By contrast, Q can be written as the union of the singletons {qj} where
the qj represent an enumeration of the rationals. Each singleton is of course
nowhere dense since it is the limit of other rationals in the set. However, Q is
not complete.
Example 13.41 Baire’s theorem contains the fact that a perfect set of real
numbers must be uncountable. For if P were perfect and countable we could
write P = {p1, p2, . . . }. Therefore
P =
∞
[
j=1
{pj} .
But each of the singletons {pj} is a nowhere dense set in the metric space P.
And P is complete. (You should verify both these assertions for yourself.) This
contradicts the Category Theorem. So P cannot be countable.
A set that can be written as a countable union of nowhere dense sets is
said to be of ﬁrst category. If a set is not of ﬁrst category, then it is said to be

13.3. THE BAIRE CATEGORY THEOREM
283
of second category. The Baire Category Theorem says that a complete metric
space must be of second category. We should think of a set of ﬁrst category
as being “thin” and a set of second category as being “fat” or “robust.” (This
is one of many ways that we have in mathematics of distinguishing “fat” sets.
Countability and uncountability is another.
Lebesgue’s measure theory is a
third.)
One of the most striking applications of the Baire Category Theorem is
the following result to the eﬀect that “most” continuous functions are nowhere
diﬀerentiable. This explodes the myth that most of us mistakenly derive from
calculus class that a typical continuous function is diﬀerentiable at all points
except perhaps at a discrete set of bad points.
Theorem 13.42 Let (X, ρ) be the metric space of continuous functions on the
unit interval [0, 1] equipped with the metric
ρ(f, g) = sup
x∈[0,1]
|f(x) −g(x)| .
Deﬁne a subset of E of X as follows: f ∈E if there exists one point at which f
is diﬀerentiable. Then E is of ﬁrst category in the complete metric space (X, ρ).
Proof: For each pair of positive integers m, n we let
Am,n = {f ∈X : ∃x ∈[0, 1] such that |f(x) −f(t)| ≤n|x −t|
∀t ∈[0, 1] that satisfy |x −t| ≤1/m} .
Fix m and n. We claim that Am,n is nowhere dense in X. In fact, if f ∈Am,n
set
Kf = max
x∈[0,1]

f(x ± 1/m) −f(x)
1/m
 .
Let h(x) be a continuous piecewise linear function, bounded by 1, consisting of
linear pieces having slope 3Kf. Then for every ǫ > 0 it holds that f + ǫ · h has
metric distance less than ǫ from f and is not a member of Am,n. This proves
that Am,n is nowhere dense.
We conclude from Baire’s theorem that ∪m,nAm,n is nowhere dense in X.
Therefore S = X \ ∪m,nAm,n is of second category. But if f ∈S then for every
x ∈[0, 1] and every n > 0 there are points t arbitrarily close to x (that is, at
distance ≤1/m from x) such that

f(x) −f(t)
t −x
 > n .
It follows that f is diﬀerentiable at no x ∈[0, 1]. That proves the assertion.

284
CHAPTER 13. ADVANCED TOPICS
Exercises
1. Let (X, ρ) be the collection of continuous functions on the interval [0, 1]
equipped with the usual supremum metric. For j a positive integer, let
Ej = {p(x) : p is a polynomial of degree not exceeding j} .
Then, as noted in the text, each Ej is nowhere dense in X. Yet ∪jEj
is dense in X. Explain why these assertions do not contradict Baire’s
theorem.
*
2. Assume fj is a sequence of continuous, real-valued functions on R with the
property that {fj(x)} is unbounded whenever x ∈Q. Use the Category
Theorem to prove that it cannot then be true that whenever t is irrational
then the sequence {fj(t)} is bounded.
3. Even if we did not know the transcendental functions sin x, cos x, ln x, ex,
etc. explicitly, the Baire Category Theorem demonstrates that transcen-
dental functions must exist. Explain why this assertion is true.
4. Let {p(x)} be a sequence of polynomial functions on the real line, each of
degree not exceeding k. Assume that this sequence converges pointwise to
a limit function f. Prove that f is a polynomial of degree not exceeding
k.
5. Give an example of a perfect set with empty interior. Show that, in the
reals, there is no perfect set with countable interior.
6. Show that the set of polynomials is of ﬁrst category in the space of con-
tinuous functions on the interval [0, 1].
7. Show that the rational numbers Q are of ﬁrst category in the reals R.
8. Is the set Z of integers of ﬁrst category in the rationals Q?
9. Show that any compact metric space is of second category.
10. Give two examples of sets of ﬁrst category that are dense in the reals R.
13.4
The Ascoli-Arzela Theorem
Let F = {fα}α∈A be a family, not necessarily countable, of functions on a metric
space (X, ρ). We say that the family F is equicontinuous on X if for every ǫ > 0
there is a δ > 0 such that when ρ(s, t) < δ then |fα(s) −fα(t)| < ǫ. Notice that
equicontinuity mandates not only uniform continuity of each fα but also that
the uniformity occur simultaneously, and at the same rate, for all the fα.

13.4. THE ASCOLI-ARZELA THEOREM
285
Example 13.43 Let (X, ρ) be the unit interval [0, 1] with the usual Euclidean
metric. Let F consist of all functions f on X that satisfy the Lipschitz condition
|f(s) −f(t)| ≤2 · |s −t|
for all s, t. Then F is an equicontinuous family of functions. For if ǫ > 0 then
we may take δ = ǫ/2. Then if |s −t| < δ and f ∈F we have
|f(s) −f(t)| ≤2 · |s −t| < 2 · δ = ǫ .
Observe, for instance, that the Mean Value Theorem tells us that sin x, cos x,
2x, x2 are elements of F.
If F is a family of functions on X, then we call F equibounded if there is a
number M > 0 such that
|f(x)| ≤M
for all x ∈X and all f ∈F. For example, the functions fj(x) = sin jx on [0, 1]
form an equibounded family.
One of the cornerstones of classical analysis is the following result of Ascoli
and Arzela:
Theorem 13.44 (The Ascoli-Arzela Theorem) Let (Y, σ) be a metric space
and assume that Y is compact. Let F be an equibounded, equicontinuous family
of functions on Y . Then there is a sequence {fj} ⊆F that converges uniformly
to a continuous function on Y .
Before we prove this theorem, let us comment on it. Let (X, ρ) be the metric
space consisting of the continuous functions on the unit interval [0, 1] equipped
with the usual supremum norm. Let F be an equicontinuous, equibounded fam-
ily of functions on [0, 1]. Then the theorem says that F is a compact set in this
metric space. For any inﬁnite subset of F is guaranteed to have a convergent
subsequence. As a result, we may interpret the Ascoli-Arzela theorem as iden-
tifying certain compact collections of continuous functions.
Proof of the Ascoli-Arzela Theorem: We divide the proof into a sequence
of lemmas.
Lemma 13.45 Let η > 0. There exist ﬁnitely many points y1, y2, . . . yk ∈Y
such that every ball B(s, η) ⊆Y contains one of the yj. We call y1, . . . , yk an
η-net for Y .
Proof: Consider the collection of balls {B(y, η/2) : y ∈Y }. This is an open
covering of Y hence, by compactness, has a ﬁnite subcovering B(y1, η/2), . . . ,
B(yk, η/2). The centers y1, . . . , yk are the points we seek. For if B(s, η) is any
ball in Y then its center s must be contained in some ball B(yj, η/2). But then
B(yj, η/2) ⊆B(s, η) hence, in particular, yj ∈B(s, η).

286
CHAPTER 13. ADVANCED TOPICS
Lemma 13.46 Let ǫ > 0. There is an η > 0, a corresponding η-net y1, . . . yk,
and a sequence {fm} ⊆F such that
• The sequence {fm(yℓ)}∞
m=1 converges for each yℓ;
• For any y ∈Y the sequence {fm(y)}∞
j=1 is contained in an interval in the
real line of length at most ǫ.
Proof: By equicontinuity there is an η > 0 such that if ρ(s, t) < η then |f(s) −
f(t)| < ǫ/3 for every f ∈F. Let y1, . . . , yk be an η-net. Since the family F is
equibounded, the set of numbers {f(y1) : f ∈F} is bounded. Thus there is a
subsequence fj such that {fj(y1)} converges. But then, by similar reasoning, we
may choose a subsequence fjk such that {fjk(y2)} converges. Continuing in this
fashion, we may ﬁnd a sequence, which we call {fm}, which converges at each
point yℓ. The ﬁrst assertion is proved. Discarding ﬁnitely many of the fms, we
may suppose that for every m, n and every j it holds that |fm(yj)−fn(yj)| < ǫ/3.
Now if y is any point of Y then there is an element yt of the η-net such that
ρ(y, yt) < η. But then, for any m, n, we have
|fm(y) −fn(y)|
≤
|fm(y) −fm(yt)|
+ |fm(yt) −fn(yt)|
+ |fn(yt) −fn(y)|
<
ǫ
3 + ǫ
3 + ǫ
3
=
ǫ.
That proves the second assertion.
Proof of the Theorem: With ǫ = 2−1 apply Lemma 13.46 to obtain a se-
quence fm. Apply Lemma 13.46 again, with ǫ = 2−2 and the role of F being
played by the sequence {fm}. This yields a new sequence {fmr}. Apply Lemma
13.46 once again with ǫ = 2−3 and the role of F being played by the second
sequence {fmr}. Keep going to produce a countable list of sequences.
Now produce the ﬁnal sequence by selecting the ﬁrst element of the ﬁrst
sequence, the second element of the second sequence, the third element of the
third sequence, and so forth.1 This sequence, which we call {fw}, will satisfy
the conclusion of the theorem.
For, if ǫ > 0, then there is a j such that 2−j < ǫ. After j terms, the sequence
{fw} is a subsequence of the jth sequence constructed above. Hence, at every
y ∈Y , all the terms fw(y), w > j, lie in an interval of length ǫ. But that just
veriﬁes convergence at the point y. Note moreover that the choice of j in this
last argument was independent of y ∈Y . That shows that the convergence is
uniform. The proof is complete.
1This very standard type of construction is called a “diagonalization argument.”

EXERCISES
287
Exercises
*
1. Consider a collection F of diﬀerentiable functions on the interval [a, b]
that satisfy the conditions |f(x)| ≤K and |f ′(x)| ≤C for all x ∈[a, b].
Demonstrate that the Ascoli-Arzela theorem applies to F and describe
the resulting conclusion.
2. A function on the interval [0, 1] is Lipschitz if it satisﬁes the condition
|f(s) −f(t)| ≤C|s −t|
for some positive constant C. Use the Ascoli-Arzela theorem to show that
the set of Lipschitz functions with constant C less than or equal to 1 is a
compact subset of the continuous functions on [0, 1].
3. Explain in detail why the Ascoli-Arzela theorem is a compactness theorem.
4. Why is there no Ascoli-Arzela theorem (without any additional hypothe-
ses) for the continuous functions on a compact interval?
5. A version of the Rellich lemma says that if β > α then the Lipschitz space
of order β is compact in the Lipschitz space of order α. Explain exactly
what this means, and why it is true.
6. Let X be a ﬁnite set and Y a ﬁnite set and let F be the set of functions
from X to Y . Then, no matter what topology we put on X and Y , F will
be compact. Why is that so?
* 7. Give an example of a space that is compact inside the space of integrable
functions on the unit interval.
8. Is the space of twice continuously diﬀerentiable functions compact inside
the space of once continuously diﬀerentiable functions? Why or why not?
9. On the domain the unit interval [0, 1], consider the set S of all polynomials
of degree not exceeding 10 with coeﬃcients of absolute value not larger
than 1. Show that the Ascoli-Arzela theorem applies to S.
10. On the domain the interval [0, 2π], consider the set T of all trigonometric
polynomials of degree not exceeding 50 with coeﬃcients of absolute value
not larger than 5. Show that the Ascoli-Arzela theorem applies to T .


Chapter 14
Normed Linear Spaces
14.1
What Is This Subject About?
The mathematical analysts of the nineteenth century (Cauchy, Riemann, Weier-
strass, and others) contented themselves with studying one function at a time.
As a sterling instance, the Weierstrass nowhere diﬀerentiable function is a world-
changing example of the real function theory of “one function at a time.” Some
of Riemann’s examples in Fourier analysis give other instances. This was the
world view 150 years ago. To be sure, Cauchy and others considered sequences
and series of functions, but the end goal was to consider the single limit function.
A major paradigm shift took place, however, in the early twentieth century.
For then people began to consider spaces of functions.
By this we mean a
linear space, equipped with a norm. The process began slowly. At ﬁrst people
considered very speciﬁc spaces, such as the square-integrable real functions on
the unit circle.
Much later, people branched out to more general classes of
spaces. And an important feature of the spaces under study was that they must
be complete. For we want to pass to limits, and completeness guarantees that
this process is reliable.
Thus was born the concepts of Hilbert space and Banach space. People like
to joke that, in the early 1940s, David Hilbert went to one of his colleagues in
G¨ottingen and asked, “What is a Hilbert space?” Perhaps he did. For it was a
very new idea at the time, and not well established. Banach spaces took even
longer to catch on. But indeed they did. Later came topological vector spaces.
These all proved to be powerful and ﬂexible tools that provide new insights and
new power to the study of classical analysis. They also provide a completely
diﬀerent point of view in the subjects of real and complex analysis. Functional
analysis is a lovely instance of how mathematical abstraction enables one to see
new things, and see them very clearly.
The purpose of this chapter is to introduce the reader to the wealth of ideas
that is functional analysis. This will not be a thorough grounding, but rather
a taste of what the subject is like. We shall make a special eﬀort to provide
289

290
CHAPTER 14. NORMED LINEAR SPACES
concrete applications of the abstract ideas, just so that the neophyte can get
a concrete grip on the techniques.
Certainly we provide references to more
advanced and more comprehensive texts.
As the reader works through this chapter, he/she may ﬁnd it useful to refer
to some of the great classic texts, such as [DUS], [RES], and [YOS].
Exercises
1. Glance ahead at Section 14.2 to see what a norm is. Explain why the unit
interval [0, 1] cannot be made into a normed linear space in any natural
way.
2. What is the diﬀerence between a norm and a metric?
3. Give three diﬀerent norms on the space R2.
14.2
What Is a Normed Linear Space?
Let X be a collection of objects equipped with a binary operation + of addition
and also with a notion of scalar multiplication. Thus, if x, y ∈X, then x+y ∈X.
Also, if x ∈X and c ∈C then cx ∈X. [Note that the scalar ﬁeld can be the
real numbers R or the complex numbers C. For us it will usually be C, but
there will be exceptions. When we want to refer to the scalar ﬁeld generically,
we use the letter k.] We shall equip X with a norm ∥∥; thus, if x ∈X, then
∥x∥∈R+ ≡{t ∈R : t ≥0}. We demand that
1. ∥x∥≥0;
2. ∥x∥= 0 if and only if x = 0;
3. If x ∈X and c ∈R then ∥cx∥= |c| · ∥x∥;
4. If x, y ∈X, then ∥x + y∥≤∥x∥+ ∥y∥.
We call X a normed linear space (or NLS).
Notice that X as described above is naturally equipped with balls. If x ∈X
and r > 0 then
B(x, r) = {t ∈X : ∥x −t∥< r}
is the (open) ball with center x and radius r. We may think of the collection
of balls as the subbasis for a topology on X. Concomitantly, we say that a
sequence {xj} ⊆X converges to x ∈X if ∥xj −x∥→0 as j →∞.
The
sequence {xj} is Cauchy if, for any ǫ > 0, there is a J so large that j, k > J
implies ∥xj −xk∥< ǫ.
We use the notation B(x, r) ≡{t ∈X : ∥x −t∥≤r} to denote the closed
ball with center x and radius r. It is worth commenting that this closed ball is
not necessarily the closure of the open ball (exercise).

14.2. WHAT IS A NORMED LINEAR SPACE?
291
Deﬁnition 14.1 Let X be a normed linear space. We say that X is a Banach
space if X is complete in the topology induced by the norm. That is to say,
if {xj} is a Cauchy sequence, then there is a limit element x ∈X such that
xj →x as j →∞.
Example 14.2 Let X = RN equipped with the usual norm: If x = (x1, x2,
. . . , xN) is a point of RN, then
∥x∥=


N
X
j=1
x2
j


1/2
.
We certainly know that this norm satisﬁes the axioms for a norm outlined above.
And it is a standard fact that RN, equipped with the topology coming from this
norm, is complete. So RN is a Banach space.
Example 14.3 Let
X = {f : f is a continuous function on the unit interval [0, 1] with values in R} .
We equip X with the norm, for f ∈X, given by
∥f∥= max
t∈[0,1] |f(t)| .
It is straightforward to verify that this norm satisﬁes the four axioms outlined
above.
Furthermore, if {fj} is a Cauchy sequence in this norm, then in fact {fj}
is uniformly Cauchy.
We know from Chapter 8 that such a sequence has a
continuous limit function f. Hence our space is complete. And X is therefore a
Banach space. We usually denote this space by C([0, 1]).
Example 14.4 Let us consider the space X = ℓ1 of sequences α = {aj} of real
numbers with the property that P
j |aj| < ∞. The norm on this space is
∥α∥≡
X
j
|aj| .
It is easy to check the four axioms of a norm. Of course addition is deﬁned
componentwise, as is scalar multiplication.
Finally, if αj = {aj
ℓ}∞
ℓ=1 is a Cauchy sequence of elements of X then let
ǫ > 0. Choose K > 0 such that, if j, k > K then ∥αj −αk∥< ǫ/5. It follows for
such j, k and any index ℓthat
|aj
ℓ−ak
ℓ| ≤∥αj −αk∥< ǫ
5 .
By the completeness of the real numbers, we ﬁnd that the sequence {aj
ℓ}∞
j=1
converges to a real limit a′
ℓ. We claim that the sequence A ≡{a′
ℓ} is the limit
in norm of the original Cauchy sequence {αj}. This is almost obvious.

292
CHAPTER 14. NORMED LINEAR SPACES
Fix ǫ > 0. Let K be as above. Now choose L so large that P∞
m=L |αK
m| <
ǫ/5. If n > K then
∞
X
m=L
|an
m| ≤
∞
X
m=L
|an
m −aK+1
m
| +
∞
X
m=L
|aK+1
m
| < ǫ
5 + ǫ
5 .
(14.4.1)
As a result,
∞
X
m=1
|an
m −a′
m| ≤
L−1
X
m=1
|an
m −a′
m| +
∞
X
m=L
|an
m| +
∞
X
m=L
|a′
m| < ǫ
5 + 2ǫ
5 + 2ǫ
5 = ǫ .
Here we use the fact that an
m →a′
m, each m, so the ﬁrst sum is less than ǫ/5 if
n is large enough. That the last sum is less than 2ǫ/5 follows from (14.4.1) by
letting n →∞. Therefore the αj converge to A as desired.
We see that X is complete, so it is a Banach space. We usually denote this
space by ℓ1.
Example 14.5 It is a fact, and we shall not provide all the details here, that if
1 ≤p < ∞, then the collection of sequences α = {aj} such that P
j |aj|p < ∞
forms a Banach space. The appropriate norm is
∥α∥≡

X
j
|aj|p


1/p
.
We usually denote this space by ℓp.
For p = ∞, the appropriate space is that of all bounded sequences α = {aj}
of real numbers. The right norm is
∥α∥= sup
j
|aj| .
We denote this space by ℓ∞. See [RUD2] or [RUD3] for a thorough treatment
of these spaces. All of the ℓp spaces are complete.
As previously indicated, the balls B(x, r) in a normed linear space X may
be taken to be a subbasis for the topology on X.
Proposition 14.6 The topology on a normed linear space is Hausdorﬀ.
Proof: Let x, y ∈X be distinct elements. Let ∥x −y∥= δ > 0. Then, by
the triangle inequality, the balls B(x, δ/3) and B(y, δ/3) are disjoint. Hence the
space is Hausdorﬀ.

EXERCISES
293
Exercises
1. Give an example of a normed linear space with a countable basis. Give
an example of a normed linear space with an uncountable basis.
2. Let ∥
∥be a norm on a real linear space X. Assume that this norm
satisﬁes the parallelogram law
∥x + y∥2 + ∥x −y∥2 = 2
 ∥x∥2 + ∥y∥2
.
Then prove that
⟨x, y⟩≡1
4
 ∥x + y∥2 −∥x −y∥2
is an inner product on X.
*
3. Let X be a normed linear space in which the norm comes from an inner
product ⟨· , · ⟩. What properties should such an inner product have? The
Cauchy-Schwarz inequality says that
|⟨x, y⟩| ≤∥x∥· ∥y∥.
Prove this inequality. Prove that the Cauchy-Schwarz inequality is a strict
inequality except in the case when the two vectors are linearly dependent.
4. Refer to Exercise 3 for terminology. Show that, in an inner product space,
the shortest distance between two points is realized by a straight line.
However, show that in an arbitrary normed linear space this result is
false.
5. TRUE or FALSE: A norm on R2 satisﬁes the parallelogram law (Exercise
2) if and only if its unit ball is the interior of an ellipse.
6. Is there a relationship between strict convexity for the closed unit ball of
a norm and the fact that the triangle inequality is strict when the two
vectors are linearly independent?
7. Show that, in a normed linear space, any convex set is connected.
8. Let X be the space of continuous functions on the interval [0, 1] equipped
with the supremum norm.
Show that the collection of polynomials of
degree at most 10 is closed in X. Also show that it is nowhere dense.
9. Let X be as in Exercise 8. Consider the mapping
F : X
−→
X
f
7−→
f 2 .
Is F continuous? What if we instead equip X with the norm
∥f∥1 =
Z 1
0
|f(x)| dx ?

294
CHAPTER 14. NORMED LINEAR SPACES
10. TRUE or FALSE: Equip the space X of continuously diﬀerentiable func-
tions on [0, 1] with the norm
∥f∥= max
x∈[0,1] |f(x)| + max
x∈[0,1] |f ′(x)| .
Is the collection of polynomials dense in X?
11. Show that a normed linear space is complete if and only if its closed unit
ball is complete.
12. Let X be a normed linear space. Then its completion is the set of equiva-
lence classes of Cauchy sequences in X. What equivalence relation should
we be using here? Show that the completion is complete.
13. Refer to Exercise 12 for terminology. What is the completion of the set
of polynomials on [0, 1] in the supremum norm? What is the completion
in the ∥∥1 norm from Exercise 9?
14. Give an example of a linear space that is complete in the norm
∥f∥=
Z 1
0
|f(x)| dx
but not complete in the supremum norm.
14.3
Finite-Dimensional Spaces
The examples of the previous section indicate that there are many interesting
norms on inﬁnite-dimensional spaces. Such is not the case in ﬁnite dimensions.
Recall that a linear space is ﬁnite dimensional if it has a basis with ﬁnitely
many elements. It is an easy, basic result that, in this circumstance, any two
bases have the same number of elements N. We call N the dimension of the
space.
Proposition 14.7 Let X be a ﬁnite-dimensional space. Then any two norms
∥∥1 and ∥∥2 on X are equivalent in the sense that there is a constant C > 1
so that, for any x ∈X,
1
C · ∥x∥1 ≤∥x∥2 ≤C · ∥x∥1 .
Proof: The unit sphere in the norm ∥
∥1 is closed and bounded, so it is a
compact set. The function
x 7−→∥x∥2
is a continuous, nonvanishing function on that unit sphere. So it has a positive
minimum m and a positive maximum M. Thus
m ≤∥x∥2 ≤M

EXERCISES
295
for all x in the ∥∥1 unit sphere. In other words,
m∥x∥1 ≤∥x∥2 ≤M∥x∥1
for all x in the ∥∥1 unit sphere. Now, if x is any element of X, then we apply
the last set of inequalities to x/∥x∥1. The result is
m∥x∥1 ≤∥x∥2 ≤M∥x∥1
for all elements x ∈X. Now we simply take C to be the maximum of M and
1/m.
Remark 14.8 Notice that the compactness of the unit sphere in the ∥∥1 norm
played a key role in the last proof. Pick one of the examples in the last section
and show that the unit sphere in that inﬁnite-dimensional space is not compact.
The upshot of this last proposition is that, for a given dimension N, the
only normed linear space with that dimension is RN. This is a frequently useful
observation.
An important piece of information for us is the following:
Proposition 14.9 The norm on a normed linear space X is continuous. That
is to say, the function
X ∋x 7−→∥x∥
is a continuous function from X to R.
Proof: From the triangle inequality,
∥x∥−∥y∥
 ≤∥x −y∥.
That shows that the function is in fact Lipschitz.
Exercises
1. The standard norm on RN gives a unit ball that is in fact a geometric
ball. Is there another norm on RN for which the unit ball is a box?
2. Let there be given an ellipse E centered at the origin in R2. This ellipse
induces a norm on R2 (think of the ellipse as the set of unit vectors). Give
a precise deﬁnition of this norm. Give an algebraic equation for this norm.
3. Show that the set Q of rational numbers cannot be written as the inter-
section of a countable family of open sets. So Q is not a Gδ.
4. Give three distinct inner products on R3.

296
CHAPTER 14. NORMED LINEAR SPACES
5. Explain why the collection of polynomials of one variable may not be
thought of as a ﬁnite-dimensional space.
6. Give three examples of ﬁnite-dimensional subspaces of the continuous
functions on [0, 1].
7. Give three examples of ﬁnite-dimensional subspaces of the polynomials of
one variable.
8. Give three examples of ﬁnite-dimensional subspaces of the integrable func-
tions on [0.1].
9. Show that if a normed linear space X has a subspace of dimension k, then
it has subspaces of dimension m for any integer 0 ≤m < k.
10. Give a norm on the space of polynomials of one variable that involves two
derivatives.
14.4
Linear Operators
All of modern mathematics is formulated in the language of sets and functions.
In the subject of functional analysis, the most important functions are the linear
operators (linear transformations).
If X and Y are normed linear spaces and
Λ : X −→Y
is a function such that
Λ(c1x1 + c2x2) = c1Λ(x1) + c2Λ(x2)
for all x1, x2 ∈X and scalars c1, c2, then we call Λ a linear operator. In the
special case that Y is the scalar ﬁeld then we call Λ a linear functional on X.
The collection of continuous, linear functionals on X, denoted by X∗, is a very
important space in itself that carries a great deal of powerful information about
X.
Example 14.10 Let X be the space C([0, 1]) and deﬁne the linear operator Λ
by
C([0, 1]) ∋f 7−→
Z 1
0
f(x) dx ∈R .
This is a linear functional on X.
Example 14.11 Let X be the space C([0, 1]) and deﬁne the linear operator Λ
by
C([0, 1]) ∋f 7−→x2 · f(x) ∈C([0, 1]) .
This is a linear operator from X to itself.

14.4. LINEAR OPERATORS
297
Example 14.12 Let X be the space C([0, 1]) and deﬁne, for f ∈X and j ∈Z,
bf(j) =
Z 1
0
f(t)e−2πijt dt .
It is easy to see that | bf(j)| ≤∥f∥C([0,1]).
Now consider the linear operator from C([0, 1]) to ℓ∞given by
C([0, 1]) ∋f 7−→{ bf(j)}∞
j=−∞.
This is a very important operator in Fourier analysis.
Deﬁnition 14.13 Let T : X →Y be a linear operator.
The norm of the
operator T is deﬁned to be
∥T ∥=
sup
∥x∥X≤1
∥T x∥Y .
We sometimes denote this norm by ∥T ∥X,Y .
In case S : X →C is a linear functional, then the norm is
∥S∥=
sup
∥x∥X≤1
|Sx| .
Now the most important linear operators, and particularly linear function-
als, are the continuous ones. It turns out that these are particularly easy to
recognize and to deal with.
Theorem 14.14 Let X and Y be normed linear spaces and let T : X →Y be
a linear map. Then the following statements are equivalent:
(a) T is continuous;
(b) T is continuous at 0;
(c) T is bounded (i.e., there is a C > 0 so that ∥T x∥Y ≤C∥x∥X for all
x ∈X).
Proof: That (a) implies (b) is trivial.
Now assume (b).
Then there is a
neighborhood U of 0 such that T (U) ⊆{y ∈Y : ∥y∥≤1}. Also U must contain
a ball (0, δ) about 0. Hence ∥T x∥≤1 when ∥x∥≤δ. Since T commutes with
scalar multiplication, we see that ∥T x∥≤aδ−1 whenever ∥x∥≤a. That is to
say, ∥T x∥≤δ−1∥x∥. So we see that (b) implies (c).
Finally, if ∥T x∥Y ≤C∥x∥X for all x, then ∥T x1−T x2∥Y = ∥T (x1−x2)∥Y ≤
ǫ whenever ∥x1 −x2∥X ≤C−1ǫ. Hence T is continuous.

298
CHAPTER 14. NORMED LINEAR SPACES
Exercises
1. Let X be the space of integrable funcions on [0, 1]. Deﬁne a mapping by
F : X
−→
X
f
7−→
Z x
0
f(t) dt .
Is this mapping continuous?
2. Equip the space X of continuously diﬀerentiable functions on [0, 1] with
the norm
∥f∥= max |f(x)| + max |f ′(x)| .
Equip the space Y of continuous functions on [0, 1] with the supremum
norm. Deﬁne a mapping
F : X
−→
Y
f
7−→
f ′ .
Is F continuous?
*
3. Consider the linear spaces
L1([0, 1]) =

f :
Z 1
0
|f(x)| dx ≡∥f∥L1 < ∞

and
L2([0, 1]) =

f :
Z 1
0
|f(x)|2 dx1/2 ≡∥f∥L1 < ∞

.
Show that these two spaces are not linearly equivalent by comparing the
convexity of their two unit balls.
4. Give an example of a bounded linear operator from the continuous func-
tions C on [0, 1] (with the supremum norm) to the polynomials P of one
variable.
5. Give an example of a bounded linear operator from the polynomials of
one variable to the continuous functions on [0, 1].
6. Give an example of a bounded linear operator from the integrable functions
I on [0.1] to the continuous functions C on [0, 1].
*
7. It is quite diﬃcult to write down an explicit example of a linear operator
that is not continuous.
But one can show abstractly that they exist.
Explain.
8. If X and Y are normed linear spaces, then the collection of bounded linear
operators from X to Y forms a normed linear space. Explain. What about
the collection of unbounded linear operators?

14.5. THE THREE BIG RESULTS
299
9. The famous spectral theorem says, in eﬀect, that every bounded linear
operator on L2 (the square integrable functions) comes from multiplication
by an essentially bounded function.
Explain why multiplication by an
essentially bounded function certainly gives a bounded linear operator.
*
10. The Fourier transform is a bounded linear operator from the square inte-
grable functions on R to the square integrable functions on R. Explain.
14.5
The Three Big Results
Elementary Banach space theory boils down to three big theorems. We shall
enunciate them and prove them, and then give a number of remarkable examples
to illustrate their importance.
In what follows we shall use the notion of semicontinuity. We say that a
function f : X →R is upper semicontinuous if, for each real β, {x ∈X : f(x) <
β} is open. It is lower semicontinuous if, for each real α, {x ∈X : f(x) > α} is
open. Clearly, if f is both lower and upper semicontinuous, then f is continuous.
Recall that a Gδ is the countable intersection of open sets.
If Tα : X →Y is a collection of operators then we say that {Tα} is uniformly
bounded if there is a constant M > 0 such that ∥Tα∥op ≤M. We say that the
Tα blow up on a dense Gδ set E if supα∈A ∥Tαx∥= ∞for every x in E.
Theorem 14.15 (The Banach-Steinhaus Theorem)
Suppose that X is
a Banach space and that Y is a normed linear space (not necessarily complete).
Assume that {Tα} : X →Y is a collection of bounded linear operators, for α
in some index set A. Then either the {Tα} are uniformly bounded or else they
blow up on a dense Gδ.
Remark 14.16 The Banach-Steinhaus theorem is sometimes also called the
uniform boundedness principle.
The uniform boundedness aspect is the ﬁrst
option and the denial of uniform boundedness is the second option. This result
is a lovely application of the Baire category theorem.
Proof of the Banach-Steinhaus Theorem: This is a straightforward appli-
cation of the Baire category theorem and elementary analysis. The proof may
be found in many textbooks, including [RUD2].
Set, for x ∈X,
φ(x) = sup
α∈A
∥Tαx∥.
Put
Vn = {x ∈X : φ(x) > n}
for n = 1, 2, 3, . . .. Since each Tα is continuous and since the norm function on
Y is continuous, each function x →∥Tαx∥is continuous on X. Thus φ, the
supremum of such functions, is lower semicontinuous. We conclude then that
each Vn is open. There are now two cases:

300
CHAPTER 14. NORMED LINEAR SPACES
(a) Suppose that every Vn is dense in X. In this case, ∩nVn is a dense Gδ in
X by the Baire category theorem. Since φ(x) = ∞for every x ∈∩nVn,
we see that the blow up holds.
(b) If instead some Vm fails to be dense in X, then there is a point x0 ∈X
and an r > 0 such that ∥x∥≤r implies that x0 + x ̸∈Vm (in other words,
Vm misses a ball). We see then that φ(x0 + x) ≤m, or
∥Tα(x0 + x)∥≤m
for all α ∈A and all x with ∥x∥≤r. Now we have
∥Tαx∥= ∥Tα((x0 + x) + (−x0))∥≤∥Tα(x0 + x)∥+ ∥Tα(x0)∥≤2m .
We conclude that uniform boundedness holds with M = 2m/r.
That completes the proof.
Theorem 14.17 (The Open Mapping Principle) Let X and Y be Banach
spaces. Let Λ : X →Y be a bounded, surjective, linear transformation. Then
the image of any open set is open. That is to say, if U ⊆X is open, then
Λ(U) ≡{Λu : u ∈U} ⊆Y is open.
Remark 14.18 An immediate consequence of the theorem is that there is a
δ > 0 so that
Λ(U) ⊃δV ,
where U, V are the open unit balls in X and Y respectively. In case Λ is both
injective and surjective, we thus see that Λ−1 is continuous (see more on this
point below). This is important information.
Proof of the Open Mapping Principle: See [RUD2] for the ideas behind
this proof.
Let y ∈Y . Then there is an x ∈X such that Λx = y. For any k > 0, if
∥x∥< k then y ∈Λ(kU). Thus Y is the union of the sets Λ(kU), k = 1, 2, 3, . . ..
Since Y is complete, the Baire category theorem then tells us that there is a
nonempty open set W in the closure of some Λ(kU). Therefore every point of
W is the limit of a sequence Λxj, where xj ∈kU for some k. Fix this k and
this W.
Select y0 ∈W, and choose η > 0 such that y0 + y ∈W for all ∥y∥< η. For
any such point y there are sequences {aj} and {bj} in kU such that
Λaj →y0
and
Λbj →y0 + y
as j →∞. Set xj = bj −aj. Then we have ∥xj∥< 2k and Λxj →y. This is
true for every y with ∥y∥< η. So the linearity of Λ tells us that, if δ ≡η/2k
then, for every y ∈Y and every ǫ > 0, there is an x ∈X so that
∥x∥≤1
δ · ∥y∥
and
∥y −Λx∥< ǫ .
(14.18.1)

14.5. THE THREE BIG RESULTS
301
We want to shrink ǫ to 0.
Now ﬁx y ∈δV and ǫ > 0. By (14.18.1), there is an x1 ∈X with ∥x1∥< 1
and
∥y −Λx1∥< 1
2δǫ .
Suppose now that x1, x2, . . . , xk are chosen so that
∥y −Λx1 −Λx2 −· · · −Λxk∥< 2−kδǫ .
(14.18.2)
Use (14.18.1), with y replaced by y −Λx1 −Λx2 −· · · −Λxk, to obtain an xk+1
such that (14.18.2) holds with k + 1 in place of k and such that
∥xk+1∥< 2−kǫ
(14.18.3)
for k = 1, 2, . . . .
If we set sk = x1 + x2 + · · · xk, then (14.18.3) shows that {sk} is a Cauchy
sequence in X. Since X is complete, there is therefore an x ∈X such that
sk →x. The inequality ∥x1∥< 1, along with (14.17.3), shows that ∥x∥< 1 + ǫ.
Since Λ is continuous, Λsk →Λx. By (14.18.2), Λsk →y. We conclude that
Λx = y.
So we have proved that
Λ((1 + ǫ)U) ⊃δV
or, dividing by (1 + ǫ),
Λ(U) ⊃(1 + ǫ)−1δV
(14.18.4)
for every ǫ > 0. The union of the sets on the righthand side of (14.18.4), taken
over all ǫ > 0, is δV . This proves that Λ(U) ⊃δV . It follows naturally that the
image of any open set is open, because any open set is the union of balls.
Corollary 14.19 Let X and Y be Banach spaces.
Let Λ : X →Y be a
univalent, surjective, bounded linear operator. Then there is a δ > 0 such that
∥Λx∥Y ≥δ∥x∥X
for all x ∈X. In other words, Λ−1 is a bounded linear operator from Y to X.
Remark 14.20 Notice that the inequality in the conclusion of the corollary is
just the opposite of the inequality that gives boundedness of the operator Λ.
Proof of the Corollary: Choose δ as in the statement of the open mapping
principle. Then the conclusion of that theorem, together with the fact that Λ is
one-to-one, shows that ∥Λx∥< δ implies that ∥x∥< 1. Taking contrapositives,
we see that ∥x∥≥1 implies that ∥x∥≥δ. That proves the assertion of the
corollary.

302
CHAPTER 14. NORMED LINEAR SPACES
The next result is the third and last of our “big three.” It is unusual in
that it does not require the space in question to be complete. In some sense it
is more of a logic result than a functional analysis result.
Historically, the Hahn-Banach theorem was ﬁrst proved for real normed
linear spaces. It was Bohnenblust who determined how to extend the result to
complex normed linear spaces.
If X is a normed linear space and E a subspace, then let λ : E →R be a
bounded linear functional. We call bλ : X →R an extension of λ to X if bλ

E= λ
and ∥bλ∥= ∥λ∥.
Theorem 14.21 (The Hahn-Banach Theorem) Let X be a normed linear
space and E a (not necessarily closed) subspace. Let λ be a bounded linear
functional on E. Then there exists an extension bλ of λ to X.
Remark 14.22 It is worth noting here that E need not be closed. And X need
not be complete. These are signals that the tools of analysis will not play a role
in the proof.
It should also be noted that the extension is not usually unique. In many
cases there will be uncountably many distinct extensions.
Remark 14.23 In fact the Hahn-Banach theorem is false for linear operators
(rather than linear functionals). We leave the details of this assertion for the
interested reader. Or refer to [KAK] or [SOB] or [KEL].
Proof of the Hahn-Banach theorem: This quite standard proof may be
found in [RUD2].
First assume that X is a real normed linear space, and that λ is a real-
linear, real-valued, bounded linear functional on E. If ∥λ∥= 0 then the desired
extension bλ is the zero-functional. Forgetting this trivial case, we may after a
renormalization assume that ∥λ∥= 1.
Select x0 ∈X with x0 ̸∈E. Let E1 be the linear space spanned by E and
x0. Thus E1 consists of all vectors of the form x + µx0, where x ∈E and µ is a
real scalar. Let us deﬁne T1(x + µx0) = λ(x) + µα, where α is some ﬁxed real
number (to be speciﬁed later). We see that T1 is a real linear functional on E1.
The catch is that we need to choose α so that the extended functional still has
norm 1. This will hold provided that
|λ(x) + µα| ≤∥x + µx0∥
(14.21.1)
for x ∈E and µ real. We replace x by −µx and divide both sides of (14.21.1)
by |µ|. Now the requirement becomes
|λ(x) −α| ≤∥x −x0∥
for x ∈E.
It is convenient now to rewrite our condition as
αx ≤α ≤βx ,

14.5. THE THREE BIG RESULTS
303
where
αx = λ(x) −∥x −x0∥
and
βx = λ(x) + ∥x −x0∥.
(14.21.2)
Such an α exists if and only if all the intervals [αx, βx] for x ∈E have a common
point. That is to say, if and only if
αx ≤βy
(14.21.3)
for all x ∈E, y ∈E. But
λ(x) −λ(y) = λ(x −y) ≤∥x −y∥≤∥x −x0∥+ ∥y −x0∥
or
λ(x) −∥x −x0∥≤λ(y) + ∥y −x0∥.
Hence
αx ≤βy
by (14.21.2).
Thus we have shown that there is a norm-preserving extension T1 of λ from
E to E1.
Now we come to the logic part of the proof. Let R be the collection of
all ordered pairs (E′, λ′), where E′ is a subspace of X which contains E and
where λ′ is a real-linear extension of λ to E′ with ∥λ′∥= 1. We may partially
order R by (E′, λ′) ≤(E′′, λ′′) if and only if E′ ⊂E′′ and λ′′(x) = λ′(x) for all
x ∈E′. We note that the axioms of a partial ordering are deﬁnitely satisﬁed
and also that R is not empty since (E, λ) lies in R. We may thus apply the
Hausdorﬀmaximality theorem (or Zorn’s lemma) to conclude that there is a
maximal totally ordered subcollection Π of R.
Let Ψ be the collection of all E′ such that (E′, λ′) ∈Π for some linear
functional λ′. Then Ψ is a totally ordered by set inclusion and hence the union
eE of all members of Ψ is a subspace1 of X. If x ∈eE then x ∈E′ for some
E′ ∈Ψ. Deﬁne eλ(x) = λ′(x), where λ′ is the functinal which occurs in the pair
(E′, λ′) ∈Ψ. Our deﬁnition of the partial order in Π shows that it does not
matter which E′ ∈Π we choose to deﬁne eλ as long as E′ contains x.
Now we easily check that eλ is a linear functional on eE, with ∥eλ∥= 1. If
eE is a proper subspace of X, then the ﬁrst part of the proof would give us
further extension of eλ, and that would contradict the maximality of Π. Thus
eE = X and we have completed the proof in the case of real scalars and real
linear functionals.
Next we treat Bohnenblust’s contribution.
If now λ is a complex-linear
functional on the subspace E of the complex normed linear space X, let η be
the real part of λ.
Use the real Hahn-Banach theorem, which we have just
proved, to extend η to a real-linear functional eµ on X with ∥eη∥= ∥η∥. Deﬁne
eλ(x) = eη(x) −ieη(ix)
1We need to be careful here, because the union of two subspaces need not be a subspace.
For example, the union of the x-axis and the y-axis in the Euclidean plane is not a subspace.

304
CHAPTER 14. NORMED LINEAR SPACES
for x ∈X. One may check directly that eλ is a complex-linear extension of λ
and that
∥eλ∥= ∥eη∥= ∥η∥= ∥λ∥.
That completes the proof in the case of complex scalars.
Exercises
1. Let X be any normed linear space.
Show that any ﬁnite-dimensional
subspace is closed.
2. Let f be a continuous, complex-valued function on the interval [0, 1]. As-
sume that f(0) = 0 and that |f(x)| ≤1 for all x. Show that the sequence of
powers f, f 2, f 3, . . . is equicontinuous if and only if maxx∈[0,1] |f(x)| < 1.
3. Let X be an inﬁnite-dimensional normed linear space and Y a ﬁnite-
dimensional subspace. Then the Hahn-Banach theorem tells us that any
bounded linear functional on Y has an extension to X. In fact there are
inﬁnitely many such extensions. Explain why.
4. Refer to Exercise 3. Give an example of an inﬁnite-dimensional X and
some subspace Y so that any linear functional on Y has only one extension
to X.
5. Let
ϕ(x) =



1
if
0 ≤x ≤1
0
if
x < 0
0
if
x > 1 .
Deﬁne a linear operator on the integrable functions by
T : f 7−→
Z
f(x −t)ϕ(t) dt .
Then in fact T maps the integrable functions to the integrable functions.
Use the open mapping principle to show that T is not onto.
6. Deﬁne, for j = 1, 2, . . . ,
ϕj(x) =



j
if
0 ≤x ≤1/j
0
if
x < 0
0
if
x > 1/j .
Set
Tj(f)(x) =
Z
ϕj(t)f(t) dt .
Apply the uniform boundedness principle to draw some conclusion about
the convergence of the Tj on the space of continuous functions on [0, 1].

14.6. APPLICATIONS OF THE BIG THREE
305
7. Why is the Hahn-Banach theorem trivial in the case of ﬁnite-dimensional
spaces?
8. Why is the uniform boundedness principle trivial in the case of ﬁnite-
dimensional spaces?
*
9. The closed graph theorem says this:
Theorem: Let Λ be a linear mapping of Banach space X to
Banach space Y . Assume that, for each sequence {xj} in X for
which x = limj→∞xj and y = limj→∞Λxj exist, it is true that
y = Λx. Then Λ is continuous.
Why is the open mapping principle (equivalently, the closed graph theo-
rem) trivial in the case of ﬁnite-dimensional spaces?
10. Refer to Exercise 9. Explain why the closed graph theorem follows from
the open mapping principle.
11. Refer to Exercise 9. Explain why the open mapping principle follows from
the closed graph theorem.
14.6
Applications of the Big Three
Now we shall spend some considerable time examining applications of the big
three theorems. This will help us to put these important results into perspective,
and also help us to understand what they say and what they mean.
The applications of these three important theorems are broad and diverse.
They come from partial diﬀerential equations, Fourier analysis, and many other
parts of mathematics. Some of them require a bit of background, which we
cannot provide in a chapter of this brevity. But we shall provide easily accessible
references.
It is useful in what follows to deﬁne the circle group T to be the interval
[0, 2π] with the endpoints identiﬁed. [We saw this idea before in the chapter on
Fourier analysis.] This identiﬁcation is nicely eﬀected by the map
[0, 2π] ∋θ 7→eiθ .
We continue to do arithmetic (and analysis) on [0, 2π] as usual, just remembering
that 0 and 2π are the same point.
Example 14.24 This example concerns convergence and divergence of Fourier
series. See [KAT] or [KRA2] for the chapter and verse in this matter.
If f is an L1 function on T, we deﬁne the nth Fourier coeﬃcient of f to be
bf(n) = 1
2π
Z 2π
0
f(t)e−int dt .

306
CHAPTER 14. NORMED LINEAR SPACES
The Nth partial sum of the Fourier series of f is deﬁned to be
SNf(eiθ) =
N
X
n=−N
bf(n)einθ .
In point of fact, one can easily calculate (again see [KAT] or [KRA2]) that
SNf(eiθ) = 1
2π
Z 2π
0
f(t)DN(θ −t) dt ,
where
DN(t) ≡sin
 N + 1
2

t
sin 1
2t
.
The function DN is known as the Dirichlet kernel.
Our goal in this example is to show that there exists a broad class of func-
tions with divergent Fourier series (in a sense to be speciﬁed).
It will be crucial for us to know the L1 norm of DN. In fact
Z 2π
0
|DN(t)| dt
=
Z π
−π
|DN(t)| dt
≥
2
Z π
0
| sin
 N + 1
2

t|
t
dt
=
2
Z (N+1/2)π
0
| sin t|
t
dt
>
2
(N+1/2)π
X
n=1
Z nπ
(n−1)π
| sin t|
nπ
dt
≥
4
π
N
X
n=1
1
n .
We see that ∥DN∥L1 →∞as N →∞.
Now we consider the operators SN operating on the Banach space
X =

f continuous on [0, 2π] such that f(0) = f(2π)

.
We claim that
∥SN∥= ∥DN∥L1 .
(14.24.1)
If we can prove (14.24.1), then ∥SN∥→∞. The uniform boundedness principle
then tells us that there is a dense subset D of X so that, for every f ∈D, the
Fourier series of f at 0 diverges. So all that remains is to prove the claim.
On the one hand, if f ∈X, then
|SN(f)| ≤1
2π
Z 2π
0
|f(s)||DN(s)| ds ≤·∥f∥sup · ∥DN∥L1 .

14.6. APPLICATIONS OF THE BIG THREE
307
That is one half of our task.
On the other hand, consider the closed set
E = {t ∈[0, 2π] : DN(t) ≥0} .
For n = 1, 2, . . . , let
fn(t) = 1 −nd(t, E)
1 + nd(t, E) .
Here d(t, E) denotes the distance of the point t to the set E. Then
(a) ∥fn∥sup ≤1;
(b) fn(t) = 1 for t ∈E;
(c) fn(t) →−1 for t ̸∈E.
Now the Lebesgue dominated convergence theorem tells us that
SN(fn) −→
Z 2π
0
|DN(s)| ds
as n →∞. We conclude that ∥SN∥= ∥DN∥L1 and our proof is complete.
It is well to recall here the Stone-Weierstrass theorem:
Theorem 14.25 Let A be an algebra of continuous functions on a compact,
Hausdorﬀspace X. Suppose that
(a) A separates points (i.e., if x ̸= y are elements of X then there is an f ∈A
such that f(x) ̸= f(y));
(b) A vanishes nowhere (i.e., if x ∈X then there is an f ∈A such that
f(x) ̸= 0);
(c) In case A and C([0, 1]) consist of complex-valued functions, then A is
closed under complex conjugation.
Then A is dense in C([0, 1]).
Of course the Stone-Weierstrass theorem is a generalization of the classical
Weierstrass approximation theorem.
Example 14.26 Let us take another look at the partial summation operators
for Fourier series. It is a matter of great interest to know whether, if f ∈Lp(T),
then does it follow that SNf →f in Lp norm?
If q is a trigonometric polynomial, then SNq = q as soon as N exceeds the
degree of q. So the convergence of SNq to q is trivial.

308
CHAPTER 14. NORMED LINEAR SPACES
Fix 1 ≤p < ∞and suppose that we know that ∥SN∥Lp,Lp ≤C, with the
estimate independent of N. If f ∈Lp is arbitrary, let ǫ > 0. By the Stone-
Weierstrass theorem, select a trigonometric polynomial q such that ∥f −q∥Lp <
ǫ. Select N so large that N exceeds the degree of q. Then we have
∥SNf −f∥Lp
≤
∥SN(f −q)∥Lp + ∥SNq −q∥Lp + ∥q −f∥Lp
≤
C∥f −q∥Lp + 0 + ǫ
≤
Cǫ + ǫ
=
(C + 1)ǫ .
So we see that a uniform bound on the operator norms of the summation oper-
ators SN gives us the desired Lp convergence of Fourier series.
For the converse, suppose it is known that SNf →f in Lp norm for every
f ∈Lp(T). Then the uniform boundedness principle tells us that there is a
constant C so that ∥SN∥Lp,Lp ≤C.
So we have a necessary and suﬃcient
condition for Lp convergence of Fourier series.
A classical calculation, amounting mainly to algebraic trickery (see [KRA2]),
in fact reduces the question of the uniform bound on the operator norms of
the SN to a single bound on a single operator called the Hilbert transform.
The Hilbert transform is arguably the most important linear operator in all of
analysis, and this discussion gives an indication of one of the reasons why.
Example 14.27 This is another application to Fourier series.
First we recall the Riemann-Lebesgue lemma. It says this:
Lemma: Let f ∈L1(T). Deﬁne the Fourier coeﬃcients as usual by
bf(n) = 1
2π
Z 2π
0
f(t)e−int dt .
Then
lim
n→±∞| bf(n)| = 0 .
The question that we want to consider now is whether the converse of the
Riemann-Lebesgue lemma is true. That is to say, if {aj} is a doubly inﬁnite
sequence of complex numbers that vanishes at ±∞then is there an f ∈L1 such
that bf(n) = an for all n ∈Z? The answer is “no,” and we shall see this using a
little functional analysis.
Let us deﬁne c0 to be the space of doubly inﬁnite sequences of complex
numbers which vanish at ±∞. The norm on this space is the supremum norm.
Now we have the operator
T : L1([0, 2π]) −→c0
given by
T (f) = { bf(n)}∞
n=−∞≡bf .

14.6. APPLICATIONS OF THE BIG THREE
309
We ﬁrst show that T is one-to-one. Suppose that f ∈L1 and T f = 0. Then
bf(n) = 0 for every n. It follows that, for any trigonometric polynomial p,
Z 2π
0
f(t)p(t) dt = 0 .
By the Stone-Weierstrass theorem, we may conclude than that
Z 2π
0
f(t)g(t) dt = 0
for any g ∈C([0, 2π]) with g(0) = g(2π). Now a simple approximation argument
allows us to conclude that
Z 2π
0
f(t)χ(t) dt = 0
for any χ the characteristic function of a disjoint union of intervals in [0, 2π]. It
follows that f ≡0. Thus T is univalent.
Now, seeking a contradiction, we suppose that the range of T is all of c0.
Then the corollary to the open mapping principle would say that there is a δ > 0
such that
∥bf∥ℓ∞≥δ∥f∥L1
(14.27.1)
for all f ∈L1([0, 2π]). Let Dn be the Dirichlet kernel as in the last example.
Then Dn ∈L1, ∥c
Dn∥ℓ∞= 1, and ∥Dn∥L1 →∞as n →∞. So there cannot be
a δ > 0 so that
∥c
Dn∥ℓ∞≥δ∥Dn∥L1
for every n. That is a contradiction.
Remark 14.28 It is actually quite diﬃcult to give a “constructive” proof of
the last result. And certainly functional analysis gives it to us rather easily.
Example 14.29 Now we shall take a moment to discuss the so-called closed
graph theorem. This is an extremely useful criterion for telling when a linear
operator is continuous. The statement is as follows:
Theorem: Suppose that X and Y are Banach spaces. Let Λ : X →
Y be a linear mapping. Assume that the graph G = {(x, Λx) : x ∈
X} is a closed set in X × Y . Then Λ is continuous.
For the proof, we begin by noticing that X ×Y is a vector space if we deﬁne
addition and scalar multiplication componentwise. We deﬁne a norm on X × Y
by
∥(x, y)∥X×Y ≡∥x∥+ ∥y∥.
Then it is straightforward to check that, so equipped, X × Y is a Banach space.

310
CHAPTER 14. NORMED LINEAR SPACES
The graph G of Λ is the set of ordered pairs (x, Λx) ∈X × Y . It is, by
hypothesis, closed. So G is itself a Banach space. Also the mapping
π1 : (x, Λx) 7−→x
is a continuous, one-to-one, linear mapping of G onto X. We also deﬁne
π2 : (x, y) 7−→y
from X × Y to Y .
Now the open mapping theorem guarantees that π−1
1
: X →G is continuous.
Trivially π2 is continuous. Therefore
Λ = π2 ◦π−1
1
is continuous, as was to be proved.
We close this discussion by noting that a common, and commonly used,
formulation of the closed graph theorem is this:
Theorem: Let Λ be a linear mapping of Banach space X to Banach
space Y . Assume that, for each sequence {xj} in X for which x =
limj→∞xj and y = limj→∞Λxj exist, it is true that y = Λx. Then
Λ is continuous.
We leave it to the reader to check that our two formulations of the closed graph
theorem are equivalent.
Example 14.30 It is a basic fact from harmonic analysis that any smoothly
bounded domain in RN has a Green’s function. See [KRA6] for the details. In
fact the argument in [KRA6] depends on Stokes’s theorem in an essential way.
We provide here, for planar domains, an alternative construction due to Peter
Lax [LAX]. The main tool is the Hahn-Banach theorem.
So let Ω⊆R2 be a smoothly bounded domain. This means that ∂Ωconsists
of ﬁnitely many smooth, disjoint, closed curves. Let w ∈Ω. A Green’s function
for Ωwith singularity at w is a function G( · , w) on Ωsuch that
(a) G( · , w) is continuous on Ω\ {w};
(b) G( · , w) vanishes on ∂Ω;
(c) G(z, w) + log |z −w|/(2π) is harmonic (in the z variable) on Ω.
It is clear that, if a Green’s function with singularity at w exists, then it is
unique (just apply the maximum principle).
We work in this example with real Banach spaces over the real ﬁeld R.
Let X be the space C(∂Ω) of real-valued functions continuous on ∂Ω. Let Y
be the subspace consisting of those continuous functions that have a harmonic

14.6. APPLICATIONS OF THE BIG THREE
311
extension to the interior of the domain Ω. Clearly Y is in fact a linear subspace
of X.2
We remind the reader that a C2 function u is harmonic on a domain Ωif
△u(x, y) ≡
 ∂2
∂x2 + ∂2
∂y2

u(x, y) ≡0
on Ω.
Obviously, if u ∈Y , then the harmonic extension bu to Ωis unique. Now ﬁx
w ∈Ω. Consider the functional
ϕw : Y →R
given by ϕw(u) = bu(w) for u ∈Y . Then of course ϕw is a linear functional on Y
and ∥ϕw∥= 1 by the maximum principle. By the Hahn-Banach theorem, there
is an extension c
ϕw of ϕw to X. And of course c
ϕw will also have norm 1.
Let z ∈R2 \ ∂Ω. For t ∈∂Ω, consider the function
ψz(t) = 1
2π · log |z −t| .
Then certainly ψz ∈X. If z ̸∈Ω, then
ϕw(ψz) = c
ψz(w) = 1
2π · log |z −w| .
If instead z ∈Ω, then we may deﬁne
H(z, w) = c
ϕw(ψz) .
Then we take
G(z, w) = H(z, w) −1
2π · log |z −w| .
We claim that G( · , w) is the Green’s function for Ωwith singularity at w.
For this purpose it suﬃces to show that H(z, w) is harmonic in z ∈Ωand
that H(z, w) tends to log |t0 −w|/(2π) as z tends to any t0 ∈∂Ω.
Of course c
ϕw is continuous and linear. Also
lim
h→0
log |z + h −t| −log |z −t|
h
exists uniformly for t ∈∂Ω(as long as z, z+h are inside Ω). Thus c
ϕw commutes
2This is a fascinating instance of formal reasoning. In the end, we know that X and Y
are the same space. That is to say, the Dirichlet problem can be solved for any continuous
boundary datum ϕ.
But the proof of that fact involves the Poisson kernel, and that is
constructed using the Green’s function. What we are doing here is constructing the Green’s
function. So we treat X and Y as formally distinct.

312
CHAPTER 14. NORMED LINEAR SPACES
t
z
z’
t0
Figure 14.1. The reﬂected point z′.
with diﬀerentiation with respect to x or y. As a result, for z ∈Ω,
 ∂2
∂x2 + ∂2
∂y2

H(z, w)
=
 ∂2
∂x2 + ∂2
∂y2

c
ϕw(ψz)
=
c
ϕw
 ∂2
∂x2 + ∂2
∂y2

ψz

=
c
ϕw(0)
=
0 ,
since ψz is harmonic in Ω.
Finally, if z is near to t0 ∈∂Ω, then let t be the point of ∂Ωthat is nearest
to z. Let z′ be the mirror image of z in the tangent line to ∂Ωat t (see Figure
14.1). Since ∂Ωis smooth, if z is suﬃciently near to t0, then z′ ̸∈Ωand z′ is
also near to t0. Hence
c
ϕw(ψz′) = ϕw(ψz′) = 1
2π · log |z′ −w| ,
and this tends to log |t0 −w|/(2π) as z →t0. On the other hand,
| c
ϕw(ψz) −c
ϕw(ψz′)| ≤∥ψz −ψz′∥∞,
and this expression tends to 0 as t →t0. Hence bϕw(ψz) →log |t0 −w|/(2π) as
z →t0. This proves that our G( · , w) is indeed the Green’s function for Ωwith
singularity at w ∈Ω.
Example 14.31 It is a classical manipulation (see [KRA6]) to construct the
Poisson kernel for a domain by calculating the unit outward normal derivative of
the Green’s function at the boundary. Here we take a more abstract approach—
using the Hahn-Banach theorem—to derive the Poisson integral formula.

14.6. APPLICATIONS OF THE BIG THREE
313
Let Ωbe a smoothly bounded domain in the plane and Ωits closure. Of
course ∂Ωdenotes the boundary of the domain.
Let Z be the space of those functions continuous on Ωand harmonic in the
interior. Using the supremum norm, we see that this is a Banach space. We
may also consider the space Y of restrictions of elements of Z to ∂Ω, and equip
Y with the supremum norm also. By the maximum principle, we see that, for
f ∈Z, we have
∥f∥Z = ∥f∥Y .
We also know that, if z ∈Ω, then
|f(z)| ≤∥f∥Y .
In particular, if f ∈Z and f(z) = 0 for all z ∈∂Ωthen f ≡0. In other words,
if f1, f2 ∈Z and f1 = f2 on ∂Ωthen f1 = f2.
Summarizing what we have learned, if f ∈Y then there is a unique extended
function (still denoted by f) on Ωso that f ∈Z and the restriction of the
extension to ∂Ωequals the original function f.
Now ﬁx a point z ∈Ω. We know that
λ : Y ∋f 7−→f(z)
is a bounded linear functional of norm 1. Now the Hahn-Banach theorem tells
us that there is an extension bλ of this functional to C(∂Ω). Certainly
bλ(1) = 1
and
∥bλ∥= 1 .
(14.31.1)
We claim that these facts imply that bλ is a positive linear functional on C(∂Ω).
To see this, let f ∈C(∂Ω) with 0 ≤f ≤1 and put g = 2f −1. We write
bλg = α + iβ ,
where α and β are real. Notice that −1 ≤g ≤1. Thus
|g + ir|2 ≤1 + r2
for any real constant r. Thus (14.31.1) implies that
(β + r)2 ≤|α + i(β + r)|2 = |bλ(g + ir)|2 ≤1 + r2 .
We conclude that
β2 + 2rβ ≤1
for every real r. This forces β = 0. Since ∥g∥Y ≤1, we conclude next that
|α| ≤1. As a result,
bλf = 1
2Λ(1 + g) = 1
2(1 + α) ≥0 .

314
CHAPTER 14. NORMED LINEAR SPACES
Now we may apply the Riesz representation theorem (see [RUD2], Theorem
2.14). It tells us that there is a regular, positive Borel measure µz on ∂Ωsuch
that
bλf =
Z
∂Ω
f dµz
for f ∈C(∂Ω). In particular, we see that
f(z) =
Z
∂Ω
f dµz
(14.31.2)
for f ∈z.
Let us summarize what we have proved:
Theorem: To each z ∈Ωthere corresponds a positive measure µz
on the boundary ∂Ωwhich “represents” z in the sense that (14.31.2)
holds for every f ∈Z.
Notice that bλ determines µz uniquely. But, in general, the Hahn-Banach
extension is certainly not unique. So, thus far, we cannot say anything about
the uniqueness of the representing measure.
Now let us specialize down. Let Ωbe the unit disc D in the complex plane
and let z ∈D. Write z = reiθ. Deﬁne
un(w) = wn
for n = 0, 1, 2, . . .. Then un ∈Z. Thus
rneinθ =
Z
∂Ω
undµz .
Since u−n = un on ∂Ω, we ﬁnd that
Z
∂Ω
undµz = r|n|einθ
(14.31.3)
for n = 0, ±1, ±2, . . .. Thus it makes sense to examine the real function
Pr(θ −t) =
∞
X
n=−∞
r|n|ein(θ−t)
(14.31.4)
for t real. Notice that
1
2π
Z 2π
0
Pr(θ −t)eint dt = r|n|eint
(14.31.5)
for n = 0, ±1, ±2, . . ..
We see that the series (14.31.4) is dominated by the convergent geometric
series P r|n|, so it is legitimate to insert the series into the integral (14.31.5)

EXERCISES
315
and to switch the sum and the integral (so that we integrate term by term).
That is what gives (14.31.5). Comparison of (14.31.5) and (14.31.3) gives
Z
∂Ω
f dµz = 1
2π
Z 2π
0
f(eit)Pr(θ −t) dt
for f = un, hence for any trigonometric polynomial p. Again, by the Stone-
Weierstrass theorem, we see that this last line holds for any continuous f on
∂D. So now we see that µz was uniquely determined.
In particular, the last line holds for f ∈Z. So we now have the representa-
tion
f(z) = 1
2π
Z 2π
0
f(eit)Pr(θ −t) dt
for f ∈Z. Now the series (14.31.4) can be summed explicitly, since it is the
real part of
1 + 2
∞
X
1
(ze−it)n = eit + z
eit −z = 1 −r2 + 2ir sin(θ −t)
|1 −ze−it|2
.
Thus we see that
Pr(θ −t) =
1 −r2
1 −2r cos(θ −t) + r2 .
This is the Poisson kernel for the unit disc.
Observe that Pr(θ −t) ≥0 if
0 ≤r < 1.
Exercises
1. Let X be the space of piecewise continuous functions on [0, 1] and let Y
be the subspace consisting of the piecewise constant functions. Use the
Hahn-Banach theorem (applied to Y ) to show that the integral of each
function in X exists.
2. Let X be the space of continuous functions on [0, 1]. Deﬁne the linear
functionals
αjf = f(1/j) −f(0)
1/j
.
Explain why the uniform boundedness principle does not apply to allow
us to conclude anything about the convergence of αjf.
3. Let f be an integrable function on the real line. There is no integrable
function g so that
f ∗g(x) ≡
Z
f(t)g(x −t) dt
equals f(x) for every such f. Use the open mapping principle to explain
why this is so.

316
CHAPTER 14. NORMED LINEAR SPACES
4. Let X be the space of doubly inﬁnite bounded sequences. Let Y be the
subspace consisting of those sequences α(j) with limits as j →±∞. Deﬁne
a nontrivial linear functional on Y and discuss its extension to X that is
guaranteed by the Hahn-Banach theorem.
5. Let ϕ be a continuous function with compact support on R. Apply the
Closed Graph Theorem to see that the mapping
f 7−→
Z
f(x −t)ϕ(t) dt
is bounded from the integrable functions to the integrable functions.
6. Let X be the space of C∞functions on [0, 1] equipped with the norm
∥f∥=
X
k
1
k!
sup |f (k)(x)|
sup |f (k)(x)| + 1 .
If f is in this space then let Tjf be the value of the jth-degree Taylor
polynomial of f at 1/2. What, if anything, does the uniform boundedness
principle tell us about these Tj?
7. Use the Closed Graph Theorem to show that the Fourier transform is
continuous.
8. Use the Closed Graph Theorem to show that any partial summation op-
erator for Fourier series is continuous.
9. Use the Hahn-Banach theorem to show that the Dirichlet problem on the
disc always has a solution (for any continuous boundary data).
10. What does the Uniform Boundedness Principle tell us about the partial
sums of Taylor’s series?

Appendix I: Elementary
Number Systems
Section A1.1. The Natural Numbers
Mathematics deals with a variety of number systems. The simplest number
system in real analysis is N, the natural numbers. As we have already noted,
this is just the set of positive integers {1, 2, 3, . . .}.
In a rigorous course of
logic, the set N is constructed from the axioms of set theory. However, in this
book we shall assume that you are familiar with the positive integers and their
elementary properties.
The principal properties of N are as follows:
1. 1 is a natural number.
2. If x is a natural number then there is another natural number bx which is
called the successor of x.
3. 1 ̸= bx for every natural number x.
4. If bx = by then x = y.
5. (Principle of Induction) If Q is a property and if
(a) 1 has the property Q;
(b) whenever a natural number x has the property Q it follows that bx
also has the property Q;
then all natural numbers have the property Q.
These rules, or axioms, are known as the Peano Axioms for the natural
numbers (named after Giuseppe Peano (1858-1932) who developed them). We
take it for granted that the usual set of positive integers satisﬁes these rules.
Certainly 1 is in that set. Each positive integer has a “successor”—after 1 comes
2 and after 2 comes 3 and so forth. The number 1 is not the successor of any
other positive integer. Two positive integers with the same successor must be
the same. The last axiom is more subtle but makes good sense: if some property
317

318
APPENDIX I
Q(n) holds for n = 1 and if whenever it holds for n then it also holds for n + 1,
then we may conclude that Q holds for all positive integers.
We will spend the remainder of this section exploring Axiom (5), the Prin-
ciple of Induction.
Example A1.1
Let us prove that for each positive integer n it holds that
1 + 2 + · · · + n = n · (n + 1)
2
.
We denote this equation by Q(n), and follow the scheme of the Principle of
Induction.
First, Q(1) is true since then both the left and the right side of the equation
equal 1. Now assume that Q(n) is true for some natural number n. Our job is
to show that it follows that Q(n + 1) is true.
Since Q(n) is true, we know that
1 + 2 + · · · + n = n · (n + 1)
2
.
Let us add the quantity n + 1 to both sides. Thus
1 + 2 + · · · + n + (n + 1) = n · (n + 1)
2
+ (n + 1).
The right side of this new equality simpliﬁes and we obtain
1 + 2 + · · · + (n + 1) = (n + 1) · ((n + 1) + 1)
2
.
But this is just Q(n + 1) or Q(bn)! We have assumed Q(n) and have proved
Q(bn), just as the Principle of Induction requires.
Thus we may conclude that property Q holds for all positive integers, as
desired.
The formula that we derived in Example A1.1 was probably known to the
ancient Greeks. However, a celebrated anecdote credits Karl Friedrich Gauss
(1777-1855) with discovering the formula when he was nine years old. Gauss
went on to become (along with Isaac Newton and Archimedes) one of the three
greatest mathematicians of all time.
The formula from Example A1.1 gives a neat way to add up the integers
from 1 to n, for any n, without doing any work. Any time that we discover a
new mathematical fact, there are generally several others hidden within it. The
next example illustrates this point.

APPENDIX I
319
Example A1.2
The sum of the ﬁrst m positive even integers is m·(m+1). To see this note
that the sum in question is
2 + 4 + 6 + · · · + 2m = 2(1 + 2 + 3 + · · · + m).
But, by the ﬁrst example, the sum in parentheses on the right is equal to
m · (m + 1)/2. It follows that
2 + 4 + 6 + · · · + 2m = 2 · m · (m + 1)
2
= m · (m + 1).
The second example could also be performed by induction (without using the
result of the ﬁrst example).
Example A1.3
Now we will use induction incorrectly to prove a statement that is com-
pletely preposterous:
All horses are the same color.
There are ﬁnitely many horses in existence, so it is convenient for us to prove
the slightly more technical statement
Any collection of k horses consists of horses
which are all the same color.
Our statement Q(k) is this last displayed statement.
Now Q(1) is true: one horse is the same color. (Note: this is not a joke,
and the error has not occurred yet.)
Suppose next that Q(k) is true: we assume that any collection of k horses
has the same color. Now consider a collection of bk = k + 1 horses. Remove one
horse from that collection. By our hypothesis, the remaining k horses have the
same color.
Now replace the horse that we removed and remove a diﬀerent horse. Again,
the remaining k horses have the same color.
We keep repeating this process: remove each of the k + 1 horses one by one
and conclude that the remaining k horses have the same color. Therefore every
horse in the collection is the same color as every other. So all k + 1 horses have
the same color. The statement Q(k + 1) is thus proved (assuming the truth of
Q(k)) and the induction is complete.
Where is our error? It is nothing deep—just an oversight. The argument
we have given is wrong when bk = k + 1 = 2. For remove one horse from a set of
two and the remaining (one) horse is the same color. Now replace the removed

320
APPENDIX I
horse and remove the other horse. The remaining (one) horse is the same color.
So what? We cannot conclude that the two horses are colored the same. Thus
the induction breaks down at the outset; the reasoning is incorrect.
Proposition A1.4
Let a and b be real numbers and n a natural number. Then
(a + b)n
=
an + n
1 an−1b + n(n −1)
2 · 1
an−2b2
+(n(n −1)(n −2)
3 · 2 · 1
an−3b3
+ · · · +
n(n −1) · · · 2
(n −1)(n −2) · · · 2 · 1abn−1 + bn.
Proof: The case n = 1 being obvious, proceed by induction.
Example A1.5
The expression
n(n −1) · · · (n −k + 1)
k(k −1) · · · 1
is often called the kth binomial coeﬃcient and is denoted by the symbol
 n
k

.
Using the notation m! = m · (m −1) · (m −2) · · · 2 · 1, for m a natural number,
we may write the kth binomial coeﬃcient as
 n
k

=
n!
(n −k)! · k! .
Section A1.2. The Integers
Now we will apply the notion of an equivalence class to construct the integers
(both positive and negative). There is an important point of knowledge to be
noted here. For the sake of having a reasonable place to begin our work, we
took the natural numbers N = {1, 2, 3, . . .} as given. Since the natural numbers
have been used for thousands of years to keep track of objects for barter, this
is a plausible thing to do. Even people who know no mathematics accept the
positive integers. However, the number zero and the negative numbers are a
diﬀerent matter.
It was not until the ﬁfteenth century that the concepts of

APPENDIX I
321
zero and negative numbers started to take hold—for they do not correspond to
explicit collections of objects (ﬁve ﬁngers or ten shoes) but rather to concepts
(zero books is the lack of books; minus 4 pens means that we owe someone four
pens). After some practice we get used to negative numbers, but explaining in
words what they mean is always a bit clumsy.
It is much more satisfying, from the point of view of logic, to construct the
integers (including the negative whole numbers and zero) from what we already
have, that is, from the natural numbers. We proceed as follows. Let A = N×N,
the set of ordered pairs of natural numbers. We deﬁne a relation (see Appendix
II, Section 6) R on A and A as follows:
(a, b) is related to (a′, b′) if a + b′ = a′ + b
See also Appendix II, Section 6 for the concept of equivalence relation.
Theorem A1.6
The relation R is an equivalence relation.
Proof: That (a, b) is related to (a, b) follows from the trivial identity a+b = a+b.
Hence R is reﬂexive. Second, if (a, b) is related to (a′, b′) then a + b′ = a′ + b
hence a′ + b = a + b′ (just reverse the equality) hence (a′, b′) is related to (a, b).
So R is symmetric.
Finally, if (a, b) is related to (a′, b′) and (a′, b′) is related to (a′′, b′′) then we
have
a + b′ = a′ + b
and
a′ + b′′ = a′′ + b′.
Adding these equations gives
(a + b′) + (a′ + b′′) = (a′ + b) + (a′′ + b′) .
Cancelling a′ and b′ from each side ﬁnally yields
a + b′′ = a′′ + b .
Thus (a, b) is related to (a′′, b′′). Therefore R is transitive. We conclude that R
is an equivalence relation.
Now our job is to understand the equivalence classes which are induced by
R. [We will ultimately call this number system the integers Z.] Let (a, b) ∈A
and let [(a, b)] be the corresponding equivalence class. If b > a then we will
denote this equivalence class by the integer b −a. For instance, the equivalence
class [(2, 7)] will be denoted by 5. Notice that if (a′, b′) ∈[(a, b)] then a + b′ =
a′ + b hence b′ −a′ = b −a. Therefore the integer symbol that we choose to
represent our equivalence class is independent of which element of the equivalence
class is used to compute it.

322
APPENDIX I
If (a, b) ∈A and b = a then we let the symbol 0 denote the equivalence
class [(a, b)]. Notice that if (a′, b′) is any other element of [(a, b)] then it must
be that a + b′ = a′ + b hence b′ = a′; therefore this deﬁnition is unambiguous.
If (a, b) ∈A and a > b then we will denote the equivalence class [(a, b)] by
the symbol −(a −b). For instance, we will denote the equivalence class [(7, 5)]
by the symbol −2. Once again, if (a′, b′) is related to (a, b) then the equation
a + b′ = a′ + b guarantees that our choice of symbol to represent [(a, b)] is
unambiguous.
Thus we have given our equivalence classes names, and these names look
just like the names that we usually give to integers: there are positive integers,
and negative ones, and zero. But we want to see that these objects behave like
integers. (As you read on, use the intuitive, non-rigorous mnemonic that the
equivalence class [(a, b)] stands for the integer b −a.)
First, do these new objects that we have constructed add correctly? Well,
let X = [(a, b)] and Y = [(c, d)] be two equivalence classes. Deﬁne their sum to
be X + Y = [(a + c, b + d)]. We must check that this is unambiguous. If (ea,eb)
is related to (a, b) and (ec, ed) is related to (c, d) then of course we know that
a + eb = ea + b
and
c + ed = ec + d .
Adding these two equations gives
(a + c) + (eb + ed) = (ea + ec) + (b + d)
hence (a+c, b+d) is related to (ea+ec,eb+ ed). Thus, adding two of our equivalence
classes gives another equivalence class, as it should.
Example A1.7
To add 5 and 3 we ﬁrst note that 5 is the equivalence class [(2, 7)] and
3 is the equivalence class [(2, 5)]. We add them componentwise and ﬁnd that
the sum is [(2 + 2, 7 + 5)] = [(4, 12)]. Which equivalence class is this answer?
Looking back at our prescription for giving names to the equivalence classes,
we see that this is the equivalence class that we called 12 −4 or 8. So we have
rediscovered the fact that 5+3 = 8. Check for yourself that if we were to choose
a diﬀerent representative for 5—say (6, 11)—and a diﬀerent representative for
3—say (24, 27)—then the same answer would result.
Now let us add 4 and −9. The ﬁrst of these is the equivalence class [(3, 7)]
and the second is the equivalence class [(13, 4]). The sum is therefore [(16, 11)],
and this is the equivalence class that we call −(16 −11) or −5. That is the
answer that we would expect when we add 4 to −9.
Next, we add −12 and −5. Previous experience causes us to expect the
answer to be −17. Now −12 is the equivalence class [(19, 7)] and −5 is the

APPENDIX I
323
equivalence class [(7, 2)]. The sum is [(26, 9)], which is the equivalence class that
we call −17.
Finally, we can see in practice that our method of addition is unambigu-
ous. Let us redo the second example using [(6, 10)] as the equivalence class
represented by 4 and [(15, 6)] as the equivalence class represented by −9. Then
the sum is [(21, 16)], and this is still the equivalence class −5, as it should be.
The assertion that the result of calculating a sum—no matter which rep-
resentatives we choose for the equivalence classes—will give only one answer is
called the “fact that addition is well deﬁned.” In order for our deﬁnitions to
make sense, it is essential that we check this property of well-deﬁnedness.
Remark A1.8
What is the point of this section? Everyone knows about negative numbers,
so why go through this abstract construction? The reason is that, until one sees
this construction, negative numbers are just imaginary objects—placeholders
if you will—which are a useful notation but which do not exist. Now they do
exist. They are a collection of equivalence classes of pairs of natural numbers.
This collection is equipped with certain arithmetic operations, such as addition,
subtraction, and multiplication. We now discuss these last two.
If x = [(a, b)] and y = [(c, d)] are integers, we deﬁne their diﬀerence to be
the equivalence class [(a + d, b + c)]; we denote this diﬀerence by x −y.
Remark A1.9
We calculate 8 −14. Now 8 = [(1, 9)] and 14 = [(3, 17)]. Therefore
8 −14 = [(1 + 17, 9 + 3)] = [(18, 12)] = −6 ,
as expected.
As a second example, we compute (−4) −(−8). Now
−4 −(−8) = [(6, 2)] −[(13, 5)] = [(6 + 5, 2 + 13)] = [(11, 15)] = 4 .
Example A1.10
When we ﬁrst learn that (−4)−(−8) = (−4)+8 = 4, the explanation is a bit
mysterious: why is “minus a minus equal to a plus”? Now there is no longer any
mystery: this property follows from our construction of the number system Z.

324
APPENDIX I
Finally, we turn to multiplication. If x = [(a, b)] and y = [(c, d)] are integers
then we deﬁne their product by the formula
x · y = [(a · d + b · c, a · c + b · d)].
This deﬁnition may be a surprise. Why did we not deﬁne x · y to be [(a · c, b ·
d)]? There are several reasons: ﬁrst of all, the latter deﬁnition would give the
wrong answer; moreover, it is not unambiguous (diﬀerent representatives of x
and y would give a diﬀerent answer). If you recall that we think of [(a, b)] as
representing b −a and [(c, d)] as representing d −c then the product should be
the equivalence class that represents (b −a) · (d −c). That is the motivation
behind our deﬁnition.
We proceed now to an example.
Example A1.11
We compute the product of −3 and −6. Now
(−3) · (−6) = [(5, 2)] · [(9, 3)] = [(5 · 3 + 2 · 9, 5 · 9 + 2 · 3)] = [(33, 51)] = 18 ,
which is the expected answer.
As a second example, we multiply −5 and 12. We have
−5 · 12 = [(7, 2)] · [(1, 13)] = [(7 · 13 + 2 · 1, 7 · 1 + 2 · 13)] = [(93, 33)] = −60 .
Finally, we show that 0 times any integer A equals zero. Let A = [(a, b)].
Then
0 · A = [(1, 1)] · [(a, b)] = [(1 · b + 1 · a, 1 · a + 1 · b)]
= [(a + b, a + b)]
= 0 .
Remark A1.12
Notice that one of the pleasant byproducts of our construction of the inte-
gers is that we no longer have to give artiﬁcial explanations for why the product
of two negative numbers is a positive number or why the product of a negative
number and a positive number is negative. These properties instead follow au-
tomatically from our construction.
Of course we will not discuss division for integers; in general division of one
integer by another makes no sense in the universe of the integers.
In the rest of this book we will follow the standard mathematical custom of
denoting the set of all integers by the symbol Z. We will write the integers not

APPENDIX I
325
as equivalence classes, but in the usual way as · · · −3, −2, −1, 0, 1, 2, 3, . . .. The
equivalence classes are a device that we used to construct the integers. Now
that we have the integers in hand, we may as well write them in the simple,
familiar fashion.
In an exhaustive treatment of the construction of Z, we would prove that
addition and multiplication are commutative and associative, prove the distribu-
tive law, and so forth. But the purpose of this section is to demonstrate modes
of logical thought rather than to be thorough.
Section A1.3. The Rational Numbers
In this section we use the integers, together with a construction using equiv-
alence classes, to build the rational numbers. Let A be the set Z × (Z \ {0}).
Here the symbol \ stands for “subtraction of sets”: Z\{0} denotes the set of all
elements of Z except 0 (see Section 1.6). In other words, A is the set of ordered
pairs (a, b) of integers subject to the condition that b ̸= 0. [Think, intuitively
and non-rigorously, of this ordered pair as “representing” the fraction a/b.] We
deﬁnitely want it to be the case that certain ordered pairs represent the same
number. For instance,
The number 1
2 should be the same number as 3
6.
This example motivates our equivalence relation. Declare (a, b) to be related to
(a′, b′) if a·b′ = a′ ·b. [Here we are thinking, intuitively and non-rigorously, that
the fraction a/b should equal the fraction a′/b′ precisely when a · b′ = a′ · b.]
Is this an equivalence relation? Obviously the pair (a, b) is related to itself,
since a · b = a · b. Also the relation is symmetric: if (a, b) and (a′, b′) are pairs
and a · b′ = a′ · b then a′ · b = a · b′. Finally, if (a, b) is related to (a′, b′) and
(a′, b′) is related to (a′′, b′′) then we have both
a · b′ = a′ · b and a′ · b′′ = a′′ · b′ .
Multiplying the left sides of these two equations together and the right sides
together gives
(a · b′) · (a′ · b′′) = (a′ · b) · (a′′ · b′) .
If a′ = 0 then it follows immediately that both a and a′′ must be zero. So
the three pairs (a, b), (a′, b′), and (a′′, b′′) are equivalent and there is nothing to
prove. So we may assume that a′ ̸= 0. We know a priori that b′ ̸= 0; therefore
we may cancel common terms in the last equation to obtain
a · b′′ = b · a′′ .
Thus (a, b) is related to (a′′, b′′), and our relation is transitive.
The resulting collection of equivalence classes will be called the set of ratio-
nal numbers, and we shall denote this set with the symbol Q.

326
APPENDIX I
Example A1.13
The equivalence class [(4, 12)] in the rational numbers contains all of the
pairs (4, 12), (1, 3), (−2, −6). (Of course it contains inﬁnitely many other pairs as
well.) This equivalence class represents the fraction 4/12, which we sometimes
also write as 1/3 or −2/(−6).
If [(a, b)] and [(c, d)] are rational numbers then we deﬁne their product to
be the rational number
[(a · c, b · d)] .
This is well deﬁned, for if (a, b) is related to (ea,eb) and (c, d) is related to (ec, ed)
then we have the equations
a · eb = ea · b and c · ed = ec · d.
Multiplying together the left sides and the right sides we obtain
(a · eb) · (c · ed) = (ea · b) · (ec · d) .
Rearranging, we have
(a · c) · (eb · ed) = (ea · ec) · (b · d) .
But this says that the product of [(a, b)] and [(c, d)] is related to the product of
[(ea,eb)] and [(ec, ed)]. So multiplication is unambiguous (i.e., well deﬁned).
Example A1.14
The product of the two rational numbers [(3, 8)] and [(−2, 5)] is
[(3 · (−2), 8 · 5)] = [(−6, 40)] = [(−3, 20)] .
This is what we expect: the product of 3/8 and −2/5 is −3/20.
If q = [(a, b)] and r = [(c, d)] are rational numbers and if r is not zero (that
is, [(c, d)] is not the equivalence class zero—in other words, c ̸= 0) then we deﬁne
the quotient q/r to be the equivalence class
[(ad, bc)] .
We leave it to you to check that this operation is well deﬁned.
Example A1.15
The quotient of the rational number [(4, 7)] by the rational number [(3, −2)]
is, by deﬁnition, the rational number
[(4 · (−2), 7 · 3)] = [(−8, 21)] .

APPENDIX I
327
This is what we expect: the quotient of 4/7 by −3/2 is −8/(21).
How should we add two rational numbers? We could try declaring [(a, b)]+
[(c, d)] to be [(a + c, b + d)], but this will not work (think about the way that
we usually add fractions). Instead we deﬁne
[(a, b)] + [(c, d)] = [(a · d + c · b, b · d)] .
We turn instead to an example.
Example A1.16
The sum of the rational numbers [(3, −14)] and [(9, 4)] is given by
[(3 · 4 + 9 · (−14), (−14) · 4)] = [(−114, −56)] = [(57, 28)] .
This coincides with the usual way that we add fractions:
−3
14 + 9
4 = 57
28 .
Notice that the equivalence class [(0, 1)] is the rational number that we
usually denote by 0. It is the additive identity, for if [(a, b)] is another rational
number then
[(0, 1)] + [(a, b)] = [(0 · b + a · 1, 1 · b)] = [(a, b)] .
A similar argument shows that [(0, 1)] times any rational number gives [(0, 1)]
or 0.
Of course the concept of subtraction is really just a special case of addition
(that is x −y is the same thing as x + (−y)). So we shall say nothing further
about subtraction.
In practice we will write rational numbers in the traditional fashion:
2
5 , −19
3
, 22
2 , 24
4 , . . . .
In mathematics it is generally not wise to write rational numbers in mixed form,
such as 2 3
5, because the juxtaposition of two numbers could easily be mistaken
for multiplication. Instead we would write this quantity as the improper fraction
13/5.
Deﬁnition A1.17
A set S is called a ﬁeld if it is equipped with a binary operation (usually called
addition and denoted “+”) and a second binary operation (called multiplication
and denoted “·”) such that the following axioms are satisﬁed:

328
APPENDIX I
A1. S is closed under addition: if x, y ∈S then x + y ∈S.
A2. Addition is commutative: if x, y ∈S then x + y = y + x.
A3. Addition is associative: if x, y, z ∈S then x + (y + z) = (x + y) + z.
A4. There exists an element, called 0, in S which is an additive identity: if
x ∈S then 0 + x = x.
A5. Each element of S has an additive inverse: if x ∈S then there is an
element −x ∈S such that x + (−x) = 0.
M1. S is closed under multiplication: if x, y ∈S then x · y ∈S.
M2. Multiplication is commutative: if x, y ∈S then x · y = y · x.
M3. Multiplication is associative: if x, y, z ∈S then x · (y · z) = (x · y) · z.
M4. There exists an element, called 1, which is a multiplicative identity: if
x ∈S then x · 1 = x.
M5. Each nonzero element of S has a multiplicative inverse: if 0 ̸= x ∈S then
there is an element x−1 ∈S such that x · (x−1) = 1. The element x−1 is
sometimes denoted 1/x.
D1. Multiplication distributes over addition: if x, y, z ∈S then
x · (y + z) = x · y + x · z .
Eleven axioms is a lot to digest all at once, but in fact these are all familiar
properties of addition and multiplication of rational numbers that we use every
day: the set Q, with the usual notions of addition and multiplication, forms a
ﬁeld. The integers, by contrast, do not: nonzero elements of Z (except 1 and
−1) do not have multiplicative inverses in the integers.
Let us now consider some consequence of the ﬁeld axioms.
Theorem A1.18
Any ﬁeld has the following properties:
(1) If z + x = z + y then x = y.
(2) If x + z = 0 then z = −x (the additive inverse is unique).
(3) −(−y) = y.
(4) If y ̸= 0 and y · x = y · z then x = z.
(5) If y ̸= 0 and y · z = 1 then z = y−1 (the multiplicative inverse is unique).

APPENDIX I
329
(6)
 x−1−1 = x.
(7) 0 · x = 0.
(8) If x · y = 0 then either x = 0 or y = 0.
(9) (−x) · y = −(x · y) = x · (−y).
(10) (−x) · (−y) = x · y.
Proof: These are all familiar properties of the rationals, but now we are con-
sidering them for an arbitrary ﬁeld. We prove just a few to illustrate the logic.
To prove (1) we write
z + x = z + y ⇒(−z) + (z + x) = (−z) + (z + y)
and now Axiom A3 yields that this implies
((−z) + z) + x = ((−z) + z) + y .
Next, Axiom A5 yields that
0 + x = 0 + y
and hence, by Axiom A4,
x = y .
To prove (7), we observe that
0 · x = (0 + 0) · x ,
which by Axiom M2 equals
x · (0 + 0).
By Axiom D1 the last expression equals
x · 0 + x · 0 ,
which by Axiom M2 equals 0 · x + 0 · x. Thus we have derived the equation
0 · x = 0 · x + 0 · x .
Axioms A4 and A2 let us rewrite the left side as
0 · x + 0 = 0 · x + 0 · x .
Finally, part (1) of the present theorem (which we have already proved)
yields that
0 = 0 · x ,
which is the desired result.

330
APPENDIX I
To prove (8), we suppose that x ̸= 0. In this case x has a multiplicative
inverse x−1 and we multiply both sides of our equation by this element:
x−1 · (x · y) = x−1 · 0 .
By Axiom M3, the left side can be rewritten and we have
(x · x−1) · y = x−1 · 0 .
Next, we rewrite the right side using Axiom M2:
(x · x−1) · y = 0 · x−1 .
Now Axiom M5 allows us to simplify the left side:
1 · y = 0 · x−1 .
We further simplify the left side using Axiom M4 and the right side using Part
(7) of the present theorem (which we just proved) to obtain:
y = 0 .
Thus we see that if x ̸= 0 then y = 0. But this is logically equivalent with x = 0
or y = 0, as we wished to prove. [If you have forgotten why these statements
are logically equivalent, write a truth table.]
Deﬁnition A1.19
Let A be a set. We shall say that A is ordered if there is a relation R on A
and A satisfying the following properties:
1. If a ∈A and b ∈A then one and only one of the following holds: (a, b) ∈R
or (b, a) ∈R or a = b.
2. If a, b, c are elements of A and (a, b) ∈R and (b, c) ∈R then (a, c) ∈R.
We call the relation R an order on A.
Rather than write an ordering relation as (a, b) ∈R it is usually more con-
venient to write it as a < b. The notation b > a means the same thing as a < b.
Example A1.20
The integers Z form an ordered set with the usual ordering <. We can
make this ordering precise by saying that x < y if y −x is a positive integer.
For instance,
6 < 8 because 8 −6 = 2 > 0 .

APPENDIX I
331
Likewise,
−5 < −1 because
−1 −(−5) = 4 > 0 .
Observe that the same ordering works on the rational numbers.
If A is an ordered set and a, b are elements then we often write a ≤b to
mean that either a = b or a < b.
When a ﬁeld has an ordering which is compatible with the ﬁeld operations
then a richer structure results:
Deﬁnition A1.21
A ﬁeld F is called an ordered ﬁeld if F has an ordering < that satisﬁes the
following addition properties:
(1) If x, y, z ∈F and y < z then x + y < x + z.
(2) If x, y ∈F, x > 0, and y > 0 then x · y > 0.
Again, these are familiar properties of the rational numbers: Q forms an
ordered ﬁeld. But there are many other ordered ﬁelds as well (for instance, the
real numbers R form an ordered ﬁeld).
Theorem A1.22
Any ordered ﬁeld has the following properties:
(1) If x > 0 and z < y then x · z < x · y.
(2) If x < 0 and z < y then x · z > x · y.
(3) If x > 0 then −x < 0. If x < 0 then −x > 0.
(4) If 0 < y < x then 0 < 1/x < 1/y.
(5) If x ̸= 0 then x2 > 0.
(6) If 0 < x < y then x2 < y2.
Proof: Again we prove just a few of these statements.
To prove (1), observe that the property (1) of ordered ﬁelds together with
our hypothesis implies that
(−z) + z < (−z) + y .
Thus, using (A2), we see that y −z > 0. Since x > 0, property (2) of ordered
ﬁelds gives
x · (y −z) > 0 .

332
APPENDIX I
Finally,
x · y = x · [(y −z) + z] = x · (y −z) + x · z > 0 + x · z
(by property (1) again). In conclusion,
x · y > x · z .
To prove (3), begin with the equation
0 = −x + x .
Since x > 0, the right side is greater than −x. Thus 0 > −x as claimed. The
proof of the other statement of (3) is similar.
To prove (5), we consider two cases. If x > 0 then x2 ≡x · x is positive
by property (2) of ordered ﬁelds. If x < 0 then −x > 0 (by part (3) of the
present theorem, which we just proved) hence (−x)·(−x) > 0. But part (10) of
the last theorem guarantees that (−x)·(−x) = x·x hence we see that x·x > 0.
We conclude this Appendix by recording an inadequacy of the ﬁeld of ra-
tional numbers; this will serve in part as motivation for learning about the real
numbers in the next section:
Theorem A1.23
There is no positive rational number q such that q2 = q · q = 2.
Proof: Seeking a contradiction, suppose that there is such a q. Write q in lowest
terms as
q = a
b ,
with a and b greater than zero. This means that the numbers a and b have no
common divisors except 1. The equation q2 = 2 can then be written as
a2 = 2 · b2 .
Since 2 divides the right side of this last equation, it follows that 2 divides the
left side. But 2 can divide a2 only if 2 divides a (because 2 is prime). We write
a = 2 · α for some positive integer α. But then the last equation becomes
4 · α2 = 2 · b2 .
Simplifying yields that
2 · α2 = b2 .
Since 2 divides the left side, we conclude that 2 must divide the right side. But
2 can divide b2 only if 2 divides b.
This is our contradiction: we have argued that 2 divides a and that 2 divides
b. But a and b were assumed to have no common divisors. We conclude that
the rational number q cannot exist.

APPENDIX I
333
In fact it turns out that a positive integer can be the square of a rational
number if and only if it is the square of a positive integer. This assertion is a
special case of a more general phenomenon in number theory known as Gauss’s
lemma.


Appendix II: Logic and Set
Theory
Everyday language is imprecise. Because we are imprecise by convention, we
can make statements like
All automobiles are not alike.
and feel conﬁdent that the listener knows that we actually mean
Not all automobiles are alike.
We can also use spurious reasoning like
If it’s raining then it’s cloudy.
It is not raining.
Therefore there are no clouds.
and not expect to be challenged, because virtually everyone is careless when
communicating informally. (Examples of this type will be considered in more
detail later.)
Mathematics cannot tolerate this lack of rigor and precision. In order to
achieve any depth beyond the most elementary level, we must adhere to strict
rules of logic. The purpose of the present chapter is to discuss the foundations
of formal reasoning.
In this chapter we will often use numbers to illustrate logical concepts. The
number systems we will encounter are
• The natural numbers N = {1, 2, 3, . . .}
• The integers Z = {. . . , −3, −2, −1, 0, 1, 2, 3, . . .}
• The rational numbers Q = {p/q : p is an integer, q is an integer, q ̸= 0}
• The real numbers R, consisting of all terminating and non-terminating
decimal expansions.
335

336
APPENDIX II
Chapter 1 reviewed the real and complex numbers. If you need to review the
other number systems, then refer to [KRA1]. For now we assume that you have
seen these number systems before. They are convenient for illustrating the log-
ical principles we are discussing.
Section A2.1. “And” and “Or”
The statement
“A and B”
means that both A is true and B is true. For instance,
George is tall and George is intelligent.
means both that George is tall and George is intelligent. If we meet George and
he turns out to be short and intelligent, then the statement is false. If he is
tall and stupid then the statement is false. Finally, if George is both short and
stupid then the statement is false. The statement is true precisely when both
properties—intelligence and tallness—hold. We may summarize these assertions
with a truth table. We let
A = George is tall.
and
B = George is intelligent.
The expression
A ∧B
will denote the phrase “A and B.” In particular, the symbol ∧is used to denote
“and.” The letters “T” and “F” denote “True” and “False,” respectively. Then
we have
A
B
A ∧B
T
T
T
T
F
F
F
T
F
F
F
F
Notice that we have listed all possible truth values of
A
and
B
and the
corresponding values of the conjunction A ∧B .
In a restaurant the menu often contains phrases like
soup or salad
This means that we may select soup or select salad, but we may not select both.
This use of “or” is called the exclusive “or”; it is not the meaning of “or” that
we use in mathematics and logic. In mathematics we instead say that “A or
B” is true provided that A is true or B is true or both are true. If we let
A ∨B
denote
“A or B”
(the symbol ∨denotes “or”) then the truth table
is

APPENDIX II
337
A
B
A ∨B
T
T
T
T
F
T
F
T
T
F
F
F
The only way that “A or B” can be false is if both A is false and B is
false. For instance, the statement
Gary is handsome or Gary is rich.
means that Gary is either handsome or rich or both. In particular, he will not
be both ugly and poor. Another way of saying this is that if he is poor he will
compensate by being handsome; if he is ugly he will compensate by being rich.
But he could be both handsome and rich.
Example A2.1
The statement
x > 5 and x < 7
is true for the number x = 11/2 because this value of x is both greater than 5
and less than 7. It is false for x = 8 because this x is greater than 5 but not less
than 7. It is false for x = 3 because this x is less than 7 but not greater than 5.
Example A2.2
The statement
x is even and x is a perfect square
is true for x = 4 because both assertions hold. It is false for x = 2 because
this x, while even, is not a square. It is false for x = 9 because this x, while a
square, is not even. It is false for x = 5 because this x is neither a square nor
an even number.
Example A2.3
The statement
x > 5 or x ≤2
is true for x = 1 since this x is ≤2 (even though it is not > 5). It holds for
x = 6 because this x is > 5 (even though it is not ≤2). The statement fails for
x = 3 since this x is neither > 5 nor ≤1.

338
APPENDIX II
Example A2.4
The statement
x > 5 or x < 7
is true for every real x.
Example A2.5
The statement
(A ∨B) ∧B
has the following truth table:
A
B
A ∨B
(A ∨B) ∧B
T
T
T
T
T
F
T
F
F
T
T
T
F
F
F
F
The words “and” and “or” are called connectives: their role in sentential
logic is to enable us to build up (or connect together) pairs of statements. In
the next section we will become acquainted with the other two basic connectives
“not” and “if–then.”
Section A2.2. “Not” and “If-Then”
The statement “not A,” written
∼A, is true whenever A is false. For
example, the statement
Gene is not tall.
is true provided the statement “Gene is tall” is false. The truth table for
∼A
is as follows
A
∼A
T
F
F
T
Although “not” is a simple idea, it can be a powerful tool when used in
proofs by contradiction. To prove that a statement A is true using proof by
contradiction, we instead assume
∼A. We then show that this hypothesis
leads to a contradiction. Thus
∼A
must be false; according to the truth
table, we see that the only possibility is that A is true.
Greater understanding is obtained by combining connectives:

APPENDIX II
339
Example A2.6
Here is the truth table for
∼(A ∨B):
A
B
A ∨B
∼(A ∨B)
T
T
T
F
T
F
T
F
F
T
T
F
F
F
F
T
Example A2.7
Now we look at the truth table for
(∼A) ∧(∼B):
A
B
∼A
∼B
(∼A) ∧(∼B)
T
T
F
F
F
T
F
F
T
F
F
T
T
F
F
F
F
T
T
T
Notice that the statements
∼(A ∨B)
and
(∼A) ∧(∼B)
have the
same truth table. We call such pairs of statements logically equivalent.
The logical equivalence of
∼(A ∨B)
with
(∼A) ∧(∼B)
makes
good intuitive sense: the statement
A∨B
fails if and only if
A
is false and
B is false. Since in mathematics we cannot rely on our intuition to establish
facts, it is important to have the truth table technique for establishing logical
equivalence.
A statement of the form “If
A
then
B” asserts that whenever
A
is
true then B is also true. This assertion (or “promise”) is tested when A is
true, because it is then claimed that something else (namely, B) is true as well.
However, when A is false then the statement “If A then B” claims nothing.
Using the symbols A ⇒B to denote “If A then B,” we obtain the following
truth table:
A
B
A ⇒B
T
T
T
T
F
F
F
T
T
F
F
T
Notice that we use here an important principle of Aristotelian logic: every
sensible statement is either true or false. There is no “in between” status. Thus
when A is false then the statement A ⇒B
is not tested. It therefore cannot

340
APPENDIX II
be false. So it must be true. In fact the only way that A ⇒B can be false is
if A is true and B is false.
Example A2.8
The statement
A ⇒B
is logically equivalent with ∼(A ∧∼B). For
the truth table for the latter is
A
B
∼B
A ∧∼B
∼(A ∧∼B)
T
T
F
F
T
T
F
T
T
F
F
T
F
F
T
F
F
T
F
T
which is the same as the truth table for
A ⇒B.
There are in fact inﬁnitely many pairs of logically equivalent statements. But
just a few of these equivalences are really important in practice—most others
are built up from these few basic ones.
Example A2.9
The statement
If
x is negative then
−5 · x is positive.
is true. For if x < 0 then −5 · x is indeed > 0; if x ≥0 then the statement is
unchallenged.
Example A2.10
The statement
If {x > 0 and x2 < 0} then x ≥10.
is true since the hypothesis “x > 0 and x2 < 0” is never true.
Example A2.11
The statement
If x > 0 then {x2 < 0 or 2x < 0}.

APPENDIX II
341
is false since the conclusion “x2 < 0 or 2x < 0” is false whenever the hypothesis
x > 0 is true.
Section A2.3. Contrapositive, Converse, and “Iﬀ”
The statement
If A then B.
or
A ⇒B.
is the same as saying
A suﬃces for B.
or as saying
A only if B.
All these forms are encountered in practice, and you should think about them
long enough to realize that they all say the same thing.
On the other hand,
If B then A.
or
B ⇒A.
is the same as saying
A is necessary for B.
or as saying
A if
B.
We call the statement B ⇒A the converse of A ⇒B.
Example A2.12
The converse of the statement
If x is a healthy horse then x has four legs.
is the statement
If
x
has four legs then
x
is a healthy horse.
Notice that these statements have very diﬀerent meanings: the ﬁrst statement
is true while the second (its converse) is false. For example, my desk has four
legs but it is not a healthy horse.
The statement
A if and only if B.

342
APPENDIX II
is a brief way of saying
If A then B.
and
If B then A.
We abbreviate
A if and only if B
as
A
⇔B
or as
A iﬀB. Here
is a truth table for A ⇔B.
A
B
A ⇒B
B ⇒A
A ⇔B
T
T
T
T
T
T
F
F
T
F
F
T
T
F
F
F
F
T
T
T
Notice that we can say that A ⇔B is true only when both A ⇒B and
B ⇒A are true. An examination of the truth table reveals that A ⇔B is
true precisely when A and B are either both true or both false. Thus A
⇔B means precisely that
A and
B are logically equivalent. One is true
when and only when the other is true.
Example A2.13
The statement
x > 0 ⇔2x > 0
is true. For if x > 0 then 2x > 0; and if 2x > 0 then x > 0.
Example A2.14
The statement
x > 0 ⇔x2 > 0
is false. For
x > 0 ⇒x2 > 0 is certainly true while
x2 > 0 ⇒x > 0 is false
( (−3)2 > 0 but −3 ̸> 0).
Example A2.15
The statement
{∼(A ∨B)} ⇔{(∼A) ∧(∼B)}
(A2.15.1)
is true because the truth table for ∼(A ∨B) and that for (∼A) ∧(∼B)
are the same (we noted this fact in the last section). Thus they are logically
equivalent: one statement is true precisely when the other is. Another way to
see the truth of (A2.15.1) is to examine the truth table:

APPENDIX II
343
A
B
∼(A ∨B)
(∼A) ∧(∼B)
∼(A ∨B) ⇔{(∼A) ∧(∼B)}
T
T
F
F
T
T
F
F
F
T
F
T
F
F
T
F
F
T
T
T
Given an implication
A ⇒B,
the contrapositive statement is deﬁned to be the implication
∼B ⇒∼A.
The contrapositive is logically equivalent to the original implication, as we see
by examining their truth tables:
A
B
A ⇒B
T
T
T
T
F
F
F
T
T
F
F
T
and
A
B
∼A
∼B
(∼B) ⇒(∼A)
T
T
F
F
T
T
F
F
T
F
F
T
T
F
T
F
F
T
T
T
Example A2.16
The statement
If it is raining, then it is cloudy.
has, as its contrapositive, the statement
If there are no clouds, then it is not raining.
A moment’s thought convinces us that these two statements say the same thing:
if there are no clouds, then it could not be raining; for the presence of rain im-
plies the presence of clouds.

344
APPENDIX II
Example A2.17
The statement
If X is a healthy horse then X has four legs.
has, as its contrapositive, the statement
If X does not have four legs then X is not a healthy horse.
A moment’s thought reveals that these two statements say precisely the same
thing. They are logically equivalent.
The main point to keep in mind is that, given an implication A ⇒B, its
converse B ⇒A and its contrapositive (∼B) ⇒(∼A)
are two diﬀerent
statements. The converse is distinct from, and logically independent from, the
original statement. The contrapositive is distinct from, but logically equivalent
to, the original statement.
Section A2.4. Quantiﬁers
The mathematical statements that we will encounter in practice will use
the connectives “and,” “or,” “not,” “if–then,” and “iﬀ.”
They will also use
quantiﬁers. The two basic quantiﬁers are “for all” and “there exists.”
Example A2.18
Consider the statement
All automobiles have wheels.
This statement makes an assertion about all automobiles. It is true, just because
every automobile does have wheels.
Compare this statement with the next one:
There exists a woman who is blonde.
This statement is of a diﬀerent nature. It does not claim that all women have
blonde hair—merely that there exists at least one woman who does. Since that
is true, the statement is true.
Example A2.19
Consider the statement
All positive real numbers are integers.

APPENDIX II
345
This sentence asserts that something is true for all positive real numbers. It is
indeed true for some positive real numbers, such as 1 and 2 and 193. However,
it is false for at least one positive number (such as π), so the entire statement
is false.
Here is a more extreme example:
The square of any real number is positive.
This assertion is almost true—the only exception is the real number 0: we see
that 02 = 0 is not positive. But it only takes one exception to falsify a “for all”
statement. So the assertion is false.
Example A2.20
Look at the statement
There exists a real number which is greater than 4.
In fact there are lots of real numbers which are greater than 4; some examples
are 7, 8π, and 97/3. Since there is at least one number satisfying the assertion,
the assertion is true.
A somewhat diﬀerent example is the sentence
There exists a real number which satisﬁes the equation
x3 + x2 + x + 1 = 0.
There is in fact only one real number which satisﬁes the equation, and that
is x = −1. Yet that information is suﬃcient to make the statement true.
We often use the symbol ∀to denote “for all” and the symbol ∃to denote
“there exists.” The assertion
∀x, x + 1 < x
claims that, for every x, the number x+1 is less than x. If we take our universe
to be the standard real number system, this statement is false (for example,
5 + 1 is not less than 5). The assertion
∃x, x2 = x
claims that there is a number whose square equals itself. If we take our universe
to be the real numbers, then the assertion is satisﬁed by x = 0 and by x = 1.
Therefore the assertion is true.
Quite often we will encounter ∀and ∃used together. The following exam-
ples are typical:

346
APPENDIX II
Example A2.21
The statement
∀x ∃y, y > x
claims that for any number x there is a number y which is greater than it. In
the realm of the real numbers this is true. In fact y = x + 1 will always do the
trick.
The statement
∃x ∀y, y > x
has quite a diﬀerent meaning from the ﬁrst one. It claims that there is an
x which is less than every y. This is absurd. For instance, x is not less than
y = x −1.
Example A2.22
The statement
∀x ∀y, x2 + y2 ≥0
is true in the realm of the real numbers: it claims that the sum of two squares
is always greater than or equal to zero.
The statement
∃x ∃y, x + 2y = 7
is true in the realm of the real numbers: it claims that there exist x and y such
that x + 2y = 6. Certainly the numbers x = 3, y = 2 will do the job (although
there are many other choices that work as well).
We conclude by noting that ∀and ∃are closely related. The statements
∀x, B(x)
and
∼∃x, ∼B(x)
are logically equivalent. The ﬁrst asserts that the statement B(x) is true for
all values of x. The second asserts that there exists no value of x for which B(x)
fails, which is the same thing.
Likewise, the statements
∃x, B(x)
and
∼∀x, ∼B(x)
are logically equivalent. The ﬁrst asserts that there is some x for which B(x)
is true. The second claims that it is not the case that B(x) fails for every x,
which is the same thing.
Remark A2.23
Most of the statements that we encounter in mathematics are formulated
using “for all” and “there exists.” For example,

APPENDIX II
347
Through every point P not on a line ℓthere is a line parallel to ℓ.
Each continuous function on a closed, bounded interval has an ab-
solute maximum.
Each of these statements uses (implicitly) both a “for all” and a “there exists.”
A “for all” statement is like an inﬁnite conjunction. The statement ∀x, P (x)
(when x is a natural number, let us say) says P (1) ∧P (2) ∧P (3) ∧· · · . A
“there exists” statement is like an inﬁnite disjunction. The statement ∃x, Q(x)
(when x is a natural number, let us say) says Q(1) ∨Q(2) ∨Q(3) ∨· · · . Thus
it is neither practical nor sensible to endeavor to verify statements such as these
using truth tables. This is one of the chief reasons that we learn to produce
mathematical proofs. One of the main themes of the present text is to gain new
insights and to establish facts about the real number system using mathematical
proofs.
Section A2.5. Set Theory and Venn Diagrams
The two most basic objects in all of mathematics are sets and functions. In
this section we discuss the ﬁrst of these two concepts.
A set is a collection of objects. For example, “the set of all blue shirts”
and “the set of all lonely whales” are two examples of sets. In mathematics, we
often write sets with the following “set-builder” notation:
{x : x + 5 > 0} .
This is read “the set of all x such that x+5 is greater than 0.” The universe from
which x is chosen (for us this will usually be the real numbers) is understood
from context, though sometimes we may be more explicit and write
{x ∈R : x + 5 > 0} .
Here ∈is a symbol that means “is an element of.”
Notice that the role of x in the set-builder notation is as a dummy variable;
the set we have just described could also be written as
{s : s + 5 > 0}
or
{α : α + 5 > 0} .
To repeat, the symbol
∈
is used to express membership in a set; for
example, the statement
4 ∈{x : x > 0}
says that 4 is a member of (or an element of ) the set of all numbers x which
are greater than 0. In other words, 4 is a positive number.

348
APPENDIX II
If A and B are sets, then the statement
A ⊂B
is read “A is a subset of B.” It means that each element of A is also an element
of B (but not vice versa!). In other words x ∈A ⇒x ∈B.
Example A2.24
Let
A = {x ∈R : ∃y such that x = y2}
and
B = {t ∈R : t + 3 > −5} .
Then A ⊂B. Why? The set A consists of those numbers that are squares—
that is, A is just the nonnegative real numbers. The set B contains all numbers
which are greater than −8. Since every nonnegative number (element of A) is
also greater than −8 (element of B), it is correct to say that A ⊂B.
However, it is not correct to say that B ⊂A, because −2 is an element of
B but is not an element of A.
We write A = B to indicate that both A ⊂B and B ⊂A. In these
circumstances we say that the two sets are equal: every element of A is an
element of B and every element of B is an element of A.
We use a slash through the symbols ∈or ⊂to indicate negation:
−4 ̸∈{x : x ≥−2}
and
{x : x = x2} ̸⊂{y : y > 1/2} .
It is often useful to combine sets. The set A∪B, called the union of A and
B, is the set consisting of all objects which are either elements of A or elements
of B (or both). The set A ∩B, called the intersection of A and B, is the set
consisting of all objects which are elements of both A and B.
Example A2.25
Let
A = {x : −4 < x ≤3} ,
B = {x : −1 ≤x < 7} ,
C = {x : −9 ≤x ≤12} .

APPENDIX II
349
Then
A ∪B = {x : −4 < x < 7}
A ∩B = {x : −1 ≤x ≤3} ,
B ∪C = {x : −9 ≤x ≤12} ,
B ∩C = {x : −1 ≤x < 7} .
Notice that B ∪C = C and B ∩C = B because B ⊂C.
Example A2.26
Let
A = {α ∈Z : α ≥9}
B = {β ∈R : −4 < β ≤24} ,
C = {γ ∈R : 13 < γ ≤30} .
Then
(A ∩B) ∩C = {x ∈Z : 9 ≤x ≤24} ∩C = {t ∈Z : 13 < t ≤24} .
Also
A ∩(B ∪C) = A ∩{x ∈R : −4 < x ≤30} = {y ∈Z : 9 ≤x ≤30} .
Try your hand at calculating A ∪(B ∪C).
The symbol ∅is used to denote the set with no elements. We call this set
the empty set. For instance,
A = {x ∈R : x2 < 0}
is a perfectly good set. However, there are no real numbers which satisfy the
given condition. Thus A is empty, and we write A = ∅.
Example A2.27
Let
A = {x : x > 8}
and
B = {x : x2 < 4} .
Then A ∪B = {x : x > 8 or −2 < x < 2} while A ∩B = ∅.
We sometimes use a Venn diagram to aid our understanding of set-theoretic
relationships. In a Venn diagram, a set is represented as a domain in the plane.
The intersection A ∩B of two sets A and B is the region common to the two
domains—see Figure A2.1.
Now let A, B, and C be three sets. The Venn diagram in Figure A2.2 makes
it easy to see that A ∩(B ∪C) = (A ∩B) ∪(A ∩C).

350
APPENDIX II
Figure A2.1: The intersection of two sets.
Figure A2.2: A ∩(B ∪C) = (A ∩B) ∪(A ∩C).

APPENDIX II
351
If A and B are sets then A \ B denotes those elements which are in A but
not in B. This operation is sometimes called subtraction of sets or set-theoretic
diﬀerence.
Example A2.28
Let
A = {x : 4 < x}
and
B = {x : 6 ≤x ≤8}.
Then
A \ B = {x : 4 < x < 6} ∪{x : 8 < x}
while
B \ A = ∅.
Notice that A \ A = ∅; this fact is true for any set.
Example A2.29
Let
S = {x : 5 ≤x}
and
T = {x : 4 < x < 6} .
Then
S \ T = {x : 6 ≤x}
and
T \ S = {x : 4 < x < 5} .
The Venn diagram in Figure A2.3 illustrates the fact that
A \ (B ∪C) = (A \ B) ∩(A \ C)
A Venn diagram is not a proper substitute for a rigorous mathematical
proof. However, it can go a long way toward guiding our intuition.
We conclude this section by mentioning a useful set-theoretic operation and
an application.
Suppose that we are studying subsets of a ﬁxed set X. We
sometimes call X the “universal set.” If S ⊂X then we use the notation cS to
denote the set X \ S or {x ∈X : x ̸∈S}. The set cS is called the complement
of S (in the set X).

352
APPENDIX II
Figure A2.3: A \ (B ∪C) = (A \ B) ∩(A \ C).
Example A2.30
When we study real analysis, most sets that we consider are subsets of the
real line R. If S = {x ∈R : 0 ≤x ≤5} then cS = {x ∈R : x < 0}∪{x ∈R : x >
5}. If T is the set of rational numbers then cT is the set of irrational numbers.
If A, B are sets then it is straightforward to verify that c(A ∪B) = cA ∩cB
and c(A ∩B) = cA ∪cB. These are known as de Morgan’s laws. Let us prove
the ﬁrst of these.
If x ∈c(A ∪B) then x is not an element of A ∪B. Hence x is not an
element of A and x is not an element of B. So x ∈cA and x ∈cB. Therefore
x ∈cA ∩cB. That shows that c(A ∪B) ⊂cA ∩cB. For the reverse direction,
assume that x ∈cA ∩cB. Then x ∈cA and x ∈cB. As a result, x ̸∈A and
x ̸∈B. So x ̸∈A ∪B. So x ∈c(A ∪B). This shows that cA ∩cB ⊂c(A ∪B).
The two inclusions that we have proved establish that c(A ∪B) = cA ∩cB.
Section A2.6. Relations and Functions
In more elementary mathematics courses we learn that a “relation” is a rule
for associating elements of two sets; and a “function” is a rule that associates
to each element of one set a unique element of another set. The trouble with
these deﬁnitions is that they are imprecise. For example, suppose we deﬁne the
function f(x) to be identically equal to 1 if there is life as we know it on Mars
and to be identically equal to 0 if there is no life as we know it on Mars. Is this
a good deﬁnition? It certainly is not a very practical one!
More important is the fact that using the word “rule” suggests that func-
tions are given by formulas. Indeed, some functions are; but most are not. Look

APPENDIX II
353
Year
Value of Yen Against Dollar
Figure A2.4: Value of the Yen against the Dollar.
at any graph in the newspaper—of unemployment, or the value of the Japanese
Yen (Figure A2.4), or the Gross National Product. The graphs represent values
of these parameters as a function of time. And it is clear that the functions are
not given by elementary formulas.
To summarize, we need a notion of function, and of relation, which is precise
and ﬂexible and which does not tie us to formulas. We begin with relations,
and then specialize down to functions.
Deﬁnition A2.31
Let A and B be sets. A relation on A and B is a collection of ordered pairs
(a, b) such that a ∈A and b ∈B. (Notice that we did not say “the collection of
all ordered pairs”—that is, a relation consists of some of the ordered pairs, but
not necessarily all of them.)
Example A2.32
Let A be the real numbers and B the integers. The set
R = {(π, 2), (3.4, −2), (
√
2, 94), (π, 50), (2 +
√
17, −2)}
is a relation on A and B. It associates certain elements of A to certain elements
of B. Observe that repetitions are allowed: π ∈A is associated to both 2 and
50 in B; also −2 ∈B is associated to both 3.4 and 2 +
√
17 in A. This relation
is certainly not given by any formula or rule.
Now let
A = {3, 17, 28, 42}
and
B = {10, 20, 30, 40} .

354
APPENDIX II
Then
R = {(3, 10), (3, 20), (3, 30), (3, 40), (17, 20), (17, 30),
(17, 40), (28, 30), (28, 40)}
is a relation on A and B. In fact a ∈A is related to b ∈B precisely when a < b.
This second relation is given by a rule.
Example A2.33
Let
A = B = {meter, pound, foot, ton, yard, ounce} .
Then
R = {(foot,meter), (foot,yard), (meter,yard), (pound,ton),
(pound,ounce),(ton,ounce), (meter,foot), (yard,foot),
(yard,meter),(ton,pound),(ounce,pound), (ounce,ton)}
is a relation on A and B. In fact two words are related by R if and only if they
measure the same thing: foot, meter, and yard measure length while pound,
ton, and ounce measure weight.
Notice that the pairs in R, and in any relation, are ordered pairs: the pair
(foot,yard) is diﬀerent from the pair (yard,foot).
Example A2.34
Let
A = {25, 37, 428, 695}
and
B = {14, 7, 234, 999}
Then
R = {(25, 234), (37, 7), (37, 234), (428, 14), (428, 234), (695, 999)}
is a relation on A and B. In fact two elements are related by R if and only if
they have at least one digit in common.
A function is a special type of relation, as we shall now learn.
Deﬁnition A2.35
Let A and B be sets. A function from A to B is a relation R on A and B
such that for each a ∈A there is one and only one pair (a, b) ∈R. We call A
the domain of the function and we call B the range.3
3Some textbooks use the word “codomain” instead of range. We shall use only the word
“range.”

APPENDIX II
355
Example A2.36
Let
A = {1, 2, 3, 4}
and
B = {α, β, γ, δ} .
Then
R = {(1, γ), (2, δ), (3, γ), (4, α)}
is a function from A to B. Notice that there is precisely one pair in R for each
element of A. However, notice that repetition of elements of B is allowed. Notice
also that there is no apparent “pattern” or “rule” that determines R. Finally
observe that not all the elements of B are used.
With the same sets A and B consider the relations
S = {(1, α), (2, β), (3, γ)}
and
T = {(1, α), (2, β), (3, γ), (4, δ), (2, γ)} .
Then S is not a function because it violates the rule that there be a pair for
each element of A. Also T is not a function because it violates the rule that
there be just one pair for each element of A.
The relations and function described in the last example were so simple that
you may be wondering what happened to the kinds of functions that we usually
look at in mathematics. Now we consider some of those.
Example A2.37
Let A = R and B = R, where R denotes the real numbers. The relation
R = {(x, sin x) : x ∈A}
is a function from A to B. For each a ∈A = R there is one and only one ordered
pair with ﬁrst element a.
Now let S = R and T = {x ∈R : −2 ≤x ≤2}. Then
U = {(x, sin x) : x ∈A}
is also a function from S to T . Technically speaking, it is a diﬀerent function
from R because it has a diﬀerent range. However, this distinction often has no
practical importance and we shall not mention the diﬀerence. It is frequently
convenient to write functions like R or U as
R(x) = sin x
and
U(x) = sin x .

356
APPENDIX II
The last example suggests that we distinguish between the set B where a
function takes its values and the set of values that the function actually assumes.
Deﬁnition A2.38
Let A and B be sets and let f be a function from A to B. Deﬁne the image
of f to be
Image f = {b ∈B : ∃a ∈A such that f(a) = b} .
The set Image f is a subset of the range B. In general the image will not equal
the range.
Example A2.39
Both the functions R and U from the last example have the set {x ∈R :
−1 ≤x ≤1} as image. In neither instance does the image equal the range.
If a function f has domain A and range B and if S is a subset of A then
we deﬁne
f(S) = {b ∈B : b = f(s) for some s ∈S} .
The set f(A) equals the image of f.
Example A2.40
Let A = R and B = {0, 1}. Consider the function
f = {(x, y) : y = 0 if x is rational and
y = 1 if x is irrational} .
The function f is called the Dirichlet function (P. G. Lejeune-Dirichlet, 1805-
1859). It is given by a rule, but not by a formula.
Notice that f(Q) = {0} and f(R) = {0, 1}.
Deﬁnition A2.41
Let A and B be sets and f a function from A to B.
We say that f is one-to-one if whenever (a1, b) ∈f and (a2, b) ∈f then
a1 = a2.
We say that f is onto if whenever b ∈B then there exists an a ∈A such
that (a, b) ∈f.

APPENDIX II
357
x
y
x
y
x
y
y
y = f(x)
y = g(x)
y = sin x
y = 2x  + 9x  + 12x + 4
3
2
Figure A2.5: One-to-one and onto functions.
Example A2.42
Let A = R and B = R. Consider the functions
f(x) = 2x + 5
,
g(x) = arctan x
h(x) = sin x
,
j(x) = 2x3 + 9x2 + 12x + 4 .
Then f is both one-to-one and onto, g is one-to-one but not onto, j is onto but
not one-to-one, and h is neither.
Refer to Figure A2.5 to convince yourself of these assertions.
When a function f is both one-to-one and onto then it is called a bijection
of its domain to its range. Sometimes we call such a function a set-theoretic
isomorphism. In the last example, the function f is a bijection of R to R.
If f and g are functions, and if the image of g is contained in the domain
of f, then we deﬁne the composition f ◦g to be
{(a, c) : ∃b such that g(a) = b and f(b) = c} .
This may be written more simply as
f ◦g(a) = f(g(a)) = f(b) = c .
Let f have domain A and range B. Assume for simplicity that the image of
f is all of B. If there exists a function g with domain B and range A such that
f ◦g(b) = b
∀b ∈B
and
g ◦f(a) = a
∀a ∈A ,

358
APPENDIX II
then g is called the inverse of f.
Clearly, if the function f is to have an inverse, then f must be one-to-one.
For if f(a) = f(a′) = b then it cannot be that both g(b) = a and g(b) = a′. Also
f must be onto. For if some b ∈B is not in the image of f then it cannot hold
that f ◦g(b) = b. It turns out that these two conditions are also suﬃcient for
the function f to have an inverse: If f has domain A and range B and if f is
both one-to-one and onto then f has an inverse.
Example A2.43
Deﬁne a function f, with domain R and range {x ∈R : x ≥0}, by the
formula f(x) = x2. Then f is onto but is not one-to-one (because f(−1) = f(1)),
hence it cannot have an inverse. This is another way of saying that a positive
real number has two square roots—not one.
However, the function g, with domain {x ∈R : x ≥0} and range {x ∈R :
x ≥0}, given by the formula g(x) = x2, does have an inverse. In fact the inverse
function is h(x) = +√x.
The function k(x) = x3, with domain R and range R, is both one-to-one and
onto. It therefore has an inverse: the function m(x) = x1/3 satisﬁes k◦m(x) = x,
and m ◦k(x) = x for all x.
Section A2.7. Countable and Uncountable Sets
One of the most profound ideas of modern mathematics is Georg Cantor’s
theory of the inﬁnite (George Cantor, 1845-1918). Cantor’s insight was that
inﬁnite sets can be compared by size, just as ﬁnite sets can. For instance, we
think of the number 2 as less than the number 3; so a set with two elements
is “smaller” than a set with three elements. We would like to have a similar
notion of comparison for inﬁnite sets. In this section we will present Cantor’s
ideas; we will also give precise deﬁnitions of the terms “ﬁnite” and “inﬁnite.”
Deﬁnition A2.44
Let A and B be sets. We say that A and B have the same cardinality if
there is a function f from A to B which is both one-to-one and onto (that is,
f is a bijection from A to B). We write card(A) = card(B). Some books write
|A| = |B|.
Example A2.45
Let A = {1, 2, 3, 4, 5}, B = {α, β, γ, δ, ǫ}, C = {a, b, c, d, e, f}. Then A and
B have the same cardinality because the function
f = {(1, α), (2, β), (3, γ), (4, δ), (5, ǫ)}

APPENDIX II
359
is a bijection of A to B. This function is not the only bijection of A to B (can
you ﬁnd another?), but we are only required to produce one.
On the other hand, A and C do not have the same cardinality; neither do
B and C.
Notice that if card(A) = card(B) via a function f1 and card(B) = card(C)
via a function f2 then card(A) = card(C) via the function f2 ◦f1.
Example A2.46
Let A and B be sets. If there is a one-to-one function from A to B but no
bijection between A and B then we will write
card(A) < card(B) .
This notation is read “A has smaller cardinality than B.”
We use the notation
card(A) ≤card(B)
to mean that either card(A) < card(B) or card(A) = card(B).
Example A2.47
An extremely simple example of this last concept is given by A = {1, 2, 3}
and B = {a, b, c, d, e}. Then the function
f : A
→
B
1
7→
a
2
7→
b
3
7→
c
is a one-to-one function from A to B. But there is no one-to-one function from
B to A. We write
card(A) < card(B) .
We shall see more profound applications, involving inﬁnite sets, in our later
discussions.
Notice that card(A) ≤card(B) and card(B) ≤card(C) imply that card(A) ≤
card(C). Moreover, if A ⊂B, then the inclusion map i(a) = a is a one-to-one
function of A into B; therefore card(A) ≤card(B).
The next theorem gives a useful method for comparing the cardinality of
two sets.

360
APPENDIX II
Theorem A2.48
(Schroeder-Bernstein)
Let A, B, be sets. If there is a one-to-one function f : A →B and a one-to-
one function g : B →A, then A and B have the same cardinality.
Proof: It is convenient to assume that A and B are disjoint; we may do so by
replacing A by {(a, 0) : a ∈A} and B by {(b, 1) : b ∈B}. Let D be the image of
f and C be the image of g. Let us deﬁne a chain to be a sequence of elements
of either A or B—that is, a function φ : N →(A ∪B)—such that
• φ(1) ∈B \ D;
• If for some j we have φ(j) ∈B, then φ(j + 1) = g(φ(j));
• If for some j we have φ(j) ∈A, then φ(j + 1) = f(φ(j)).
We see that a chain is a sequence of elements of A∪B such that the ﬁrst element
is in B \ D, the second in A, the third in B, and so on. Obviously each element
of B \ D occurs as the ﬁrst element of at least one chain.
Deﬁne S = {a ∈A : a is some term of some chain}. It is helpful to note
that
S = {x : x can be written in the form
g(f(g(· · · g(y) . . . ))) for some y ∈B \ D} .
(A2.48.1)
We set
k(x) =

f(x)
if
x ∈A \ S
g−1(x)
if
x ∈S
Note that the second half of this deﬁnition makes sense because S ⊆C. Then
k : A →B. We shall show that in fact k is a bijection.
First notice that f and g−1 are one-to-one. This is not quite enough to
show that k is one-to-one, but we now reason as follows: If f(x1) = g−1(x2) for
some x1 ∈A \ S and some x2 ∈S, then x2 = g(f(x1)). But, by (A2.48.1), the
fact that x2 ∈S now implies that x1 ∈S. That is a contradiction. Hence k is
one-to-one.
It remains to show that k is onto. Fix b ∈B. We seek an x ∈A such that
k(x) = b.
Case A: If g(b) ∈S, then k(g(b)) ≡g−1(g(b)) = b hence the x that we seek is
g(b).
Case B: If g(b) ̸∈S, then we claim that there is an x ∈A such that f(x) = b.
Assume this claim for the moment.
Now the x that we found in the last paragraph must lie in A \ S. For if not
then x would be in some chain. Then f(x) and g(f(x)) = g(b) would also lie in
that chain. Hence g(b) ∈S, and that is a contradiction. But x ∈A \ S tells us

APPENDIX II
361
that k(x) = f(x) = b. That completes the proof that k is onto. Hence k is a
bijection.
To prove the claim in Case B, notice that if there is no x with f(x) = b,
then b ∈B \ D. Thus some chain would begin at b. So g(b) would be a term of
that chain. Hence g(b) ∈S and that is a contradiction.
The proof of the Schroeder-Bernstein theorem is complete.
Remark A2.49
Let us reiterate some of the earlier ideas in light of the Schroeder-Bernstein
theorem. If A and B are sets and if there is a one-to-one function f : A →B,
then we know that card(A) ≤card(B).
If there is no one-to-one function
g : B →A, then we may write card(A) < card(B). But if instead there is
a one-to-one function g : B →A, then card(B) ≤card(A) and the Schroeder-
Bernstein theorem guarantees therefore that card(A) = card(B).
Now it is time to look at some speciﬁc examples.
Example A2.50
Let E be the set of all even integers and O the set of all odd integers. Then
card(E) = card(O) .
Indeed, the function
f(j) = j + 1
is a bijection from E to O.
Example A2.51
Let E be the set of even integers. Then
card(E) = card(Z) .
The function
g(j) = j/2
is a bijection from E to Z.
This last example is a bit surprising, for it shows that a set Z can be put in
one-to-one correspondence with a proper subset E of itself. In other words, we
are saying that the integers Z “have the same number of elements” as a proper
subset of Z. Such a phenomenon cannot occur with ﬁnite sets.

362
APPENDIX II
Example A2.52
We have
card(Z) = card(N) .
We deﬁne the function f from Z to N as follows:
• f(j) = −(2j + 1) if j is negative
• f(j) = 2j + 2 if j is positive or zero
The values that f takes on the negative numbers are 1, 3, 5, . . ., on the positive
numbers are 4, 6, 8, . . ., and f(0) = 2. Thus f is one-to-one and onto.
Example A2.53
If a set A has the same cardinality as N then we say that A is countable.
By putting together the preceding examples, we see that the set of even
integers, the set of odd integers, and the set of all integers are examples of
countable sets.
Example A2.54
The set of all ordered pairs of positive integers
S = {(j, k) : j, k ∈N}
is countable.
To see this we will use the Schroeder-Bernstein theorem. The function
f(j) = (j, 1)
is a one-to-one function from N to S. Also the function g(j, k) = 2j · 3k is a
one-to-one function from S to N. By the Schroeder-Bernstein theorem, S and
N have the same cardinality; hence S is countable.
Remark A2.55
You may check for yourself that the function F(j, k) = 2j−1 · (2k −1) is an
explicit bijection from S to N.
Since there is a bijection of the set of all integers with the set N, it follows
from the last example that the set of all pairs of integers (positive and negative)
is countable.

APPENDIX II
363
Notice that the word “countable” is a good descriptive word: if S is a count-
able set then we can think of S as having a ﬁrst element (the one corresponding
to 1 ∈N), a second element (the one corresponding to 2 ∈N), and so forth.
Thus we write S = {s(1), s(2), . . . } = {s1, s2, . . . }.
Deﬁnition A2.56
A nonempty set S is called ﬁnite if there is a bijection of S with a set of the
form {1, 2, . . ., n} for some positive integer n. If no such bijection exists, then
the set is called inﬁnite.
An important property of the natural numbers N is that any subset S ⊂N
has a least element. This is known as the Well Ordering Principle, and is studied
in a course on logic. In the present text we take the properties of the natural
numbers as given. We use some of these properties in the next proposition.
Proposition A2.57
If S is a countable set and R is a subset of S then either R is empty or R
is ﬁnite or R is countable.
Proof: Assume that R is not empty.
Write S = {s1, s2, . . .}. Let j1 be the least positive integer such that sj1 ∈R.
Let j2 be the least integer following j1 such that sj2 ∈R. Continue in this
fashion. If the process terminates at the nth step, then R is ﬁnite and has n
elements.
If the process does not terminate, then we obtain an enumeration of the
elements of R:
1 ←→sj1
2 ←→sj2
. . .
etc.
All elements of R are enumerated in this fashion since jℓ≥ℓ. Therefore R is
countable.
A set is called denumerable if it is either empty, ﬁnite, or countable. Notice
that the word “denumerable” is not the same as “countable.” In fact “count-
able” is just one instance of denumerable.
The set Q of all rational numbers consists of all expressions
a
b ,

364
APPENDIX II
where a and b are integers and b ̸= 0. Thus Q can be identiﬁed with the set of
all ordered pairs (a, b) of integers with b ̸= 0. After discarding duplicates, such
as 2
4 = 1
2, and using Examples A2.52 and A2.54 and Proposition A2.57, we ﬁnd
that the set Q is countable.
Theorem A2.58
Let S1, S2 be countable sets. Set S = S1 ∪S2. Then S is countable.
Proof: Let us write
S1 = {s1
1, s1
2, . . .}
S2 = {s2
1, s2
2, . . .} .
If S1 ∩S2 = ∅then the function
sk
j 7→(j, k)
is a bijection of S with a subset of {(j, k) : j, k ∈N}. We proved earlier (Example
A2.54) that the set of ordered pairs of elements of N is countable. By Proposition
A2.57, S is countable as well.
If there exist elements which are common to S1, S2 then discard any du-
plicates. The same argument (use the preceding proposition) shows that S is
countable.
Theorem A2.59
If S and T are each countable sets then so is
S × T ≡{(s, t) : s ∈S, t ∈T } .
Proof: Since S is countable there is a bijection f from S to N. Likewise there
is a bijection g from T to N. Therefore the function
(f × g)(s, t) = (f(s), g(t))
is a bijection of S ×T with N×N, the set of order pairs of positive integers. But
we saw in Example A2.54 that the latter is a countable set. Hence so is S×T.
Remark A2.60
We used the proposition as a vehicle for deﬁning the concept of set-theoretic
product: If A and B are sets then
A × B ≡{(a, b) : a ∈A, b ∈B} .

APPENDIX II
365
More generally, if A1, A2, . . . , Ak are sets then
A1 × A2 × · · · × Ak ≡{(a1, a2, . . . , ak) : aj ∈Aj for all j = 1, . . . , k} .
Corollary A2.61
If S1, S2, . . . , Sk are each countable sets then so is the set
S1 × S2 × · · · × Sk = {(s1, . . . , sk) : s1 ∈S1, . . . , sk ∈Sk}
consisting of all ordered k−tuples (s1, s2, . . . , sk) with sj ∈Sj.
Proof: We may think of S1×S2×S3 as (S1×S2)×S3. Since S1×S2 is countable
(by the proposition) and S3 is countable, then so is (S1×S2)×S3 = S1×S2×S3
countable. Continuing in this fashion, we can see that any ﬁnite product of
countable sets is also a countable set.
We are accustomed to the union A ∪B of two sets or, more generally, the
union A1∪A2∪· · ·∪Ak of ﬁnitely many sets. But sometimes we wish to consider
the union of inﬁnitely many sets. Let S1, S2, . . . be countably many sets. We
say that x is an element of
∞
[
j=1
Sj
if x is an element of at least one of the Sj.
Corollary A2.62
The countable union of countable sets is countable.
Proof: Let A1, A2, . . . each be countable sets. If the elements of Aj are enu-
merated as {aj
k} and if the sets Aj are pairwise disjoint then the correspondence
aj
k ←→(j, k)
is one-to-one between the union of the sets Aj and the countable set N × N.
This proves the result when the sets Aj have no common element. If some of
the Aj have elements in common then we discard duplicates in the union and
use Proposition A2.57.

366
APPENDIX II
Proposition A2.63
The collection P of all polynomials with integer coeﬃcients is countable.
Proof: Let Pk be the set of polynomials of degree k with integer coeﬃcients.
A polynomial p of degree k has the form
p(x) = p0 + p1x + p2x2 + · · · + pkxk .
The identiﬁcation
p(x) ←→(p0, p1, . . . , pk)
identiﬁes the elements of Pk with the (k + 1)-tuples of integers. By Corollary
A2.60, it follows that Pk is countable. But then Corollary A2.61 implies that
P =
∞
[
j=0
Pj
is countable.
Georg Cantor’s remarkable discovery is that not all inﬁnite sets are count-
able. We next give an example of this phenomenon.
In what follows, a sequence on a set S is a function from N to S. We usually
write such a sequence as s(1), s(2), s(3), . . . or as s1, s2, s3, . . . .
Example A2.64
There exists an inﬁnite set which is not countable (we call such a set un-
countable). Our example will be the set S of all sequences on the set {0, 1}. In
other words, S is the set of all inﬁnite sequences of 0s and 1s. To see that S is
uncountable, assume the contrary. Then there is a ﬁrst sequence
S1 = {s1
j}∞
j=1 ,
a second sequence
S2 = {s2
j}∞
j=1 ,
and so forth. This will be a complete enumeration of all the members of S. But
now consider the sequence T = {tj}∞
j=1, which we construct as follows:
• If s1
1 = 0 then make t1 = 1; if s1
1 = 1 then set t1 = 0;
• If s2
2 = 0 then make t2 = 1; if s2
2 = 1 then set t2 = 0;
• If s3
3 = 0 then make t3 = 1; if s3
3 = 1 then set t3 = 0;
. . .

APPENDIX II
367
• If sj
j = 0 then make tj = 1; if sj
j = 1 then make tj = 0;
etc.
Now the sequence T diﬀers from the ﬁrst sequence S1 in the ﬁrst element:
t1 ̸= s1
1.
The sequence T diﬀers from the second sequence S2 in the second element:
t2 ̸= s2
2.
And so on: the sequence T diﬀers from the jth sequence Sj in the jth
element: tj ̸= sj
j. So the sequence T is not in the set S. But T is supposed to
be in the set S because it is a sequence of 0s and 1s and all of these have been
hypothesized to be enumerated.
This contradicts our assumption, so S must be uncountable.
Example A2.65
Consider the set of all decimal representations of numbers—both terminat-
ing and non-terminating. Here a terminating decimal is one of the form
27.43926
while a non-terminating decimal is one of the form
3.14159265 . . . .
In the case of the non-terminating decimal, no repetition is implied; the decimal
simply continues without cease.
Now the set of all those decimals containing only the digits 0 and 1 can be
identiﬁed in a natural way with the set of sequences containing only 0 and 1
(just put commas between the digits). And we just saw that the set of such
sequences is uncountable.
Since the set of all decimal numbers is an even bigger set, it must be un-
countable also.
As you may know, the set of all decimals identiﬁes with the set of all real
numbers. We ﬁnd then that the set R of all real numbers is uncountable. (Con-
trast this with the situation for the rationals.) In Chapter 1 we learn more about
how the real number system is constructed using just elementary set theory.
It is an important result of set theory (due to Cantor) that, given any set
S, the set of all subsets of S (called the power set of S) has strictly greater
cardinality than the set S itself. As a simple example, let S = {a, b, c}. Then
the set of all subsets of S is


∅, {a}, {b}, {c}, {a, b}, {a, c}, {b, c}, {a, b, c}


.

368
APPENDIX II
The set of all subsets has eight elements while the original set has just three.
Even more signiﬁcant is the fact that if S is an inﬁnite set then the set of
all its subsets has greater cardinality than S itself. This is a famous theorem of
Cantor. Thus there are inﬁnite sets of arbitrarily large cardinality.
In some of the examples in this Appendix we constructed a bijection between
a given set (such as Z) and a proper subset of that set (such as E, the even
integers). It follows from the deﬁnitions that this is possible only when the sets
involved are inﬁnite.

Appendix III: Review of
Linear Algebra
Section A3.1. Linear Algebra Basics
When we ﬁrst learn linear algebra, the subject is diﬃcult because it is not
usually presented in the context of applications. In the current text we see one
of the most important applications of linear algebra: to provide a language in
which to do analysis of several real variables. We now give a quick review of
elementary linear algebra.
The principal properties of a vector space are that it have an additive struc-
ture and an operation of scalar multiplication.
If u = (u1, u2, . . . , uk) and
v = (v1, v2, . . . , vk) are elements of Rk and a ∈R then deﬁne the operations of
addition and scalar multiplication as follows:
u + v = (u1 + v1, u2 + v2, . . . , uk + vk)
and
a · u = (au1, au2, . . . , auk) .
Notice that the vector 0 = (0, 0, . . . , 0) is the additive identity: u + 0 = u for
any element u ∈Rk.
Also every element u = (u1, u2, . . . , uk) ∈Rk has an
additive inverse −u = (−u1, −u2, . . . , −uk) that satisﬁes u + (−u) = 0.
Example A3.1
We have
(3, −2, 7) + (4, 1, −9) = (7, −1, −2)
and
5 · (3, −2, 7, 14) = (15, −10, 35, 70).
The ﬁrst major idea in linear algebra is that of linear dependence:
369

370
APPENDIX III
Deﬁnition A3.2
A collection of elements u1, u2, . . . , um ∈Rk is said to be linearly dependent
if there exist constants a1, a2, . . . , am, not all zero, such that
m
X
j=1
ajuj = 0 .
Example A3.3
The vectors u = (1, 3, 4), v = (2, −1, −3), and w = (5, 1, −2) are linearly
dependent because 1 · u + 2 · v −1 · w = 0.
However, the vectors u′ = (1, 0, 0), v′ = (0, 1, 1), and w′ = (1, 0, 1) are not
linearly dependent since, if there were constants a, b, c such that
a u′ + b v′ + c w′ = 0 ,
then
(a + c, b, b + c) = 0 .
But this means that
a + c
=
0
b
=
0
b + c
=
0 .
We conclude that a, b, c must all be equal to zero. That is not allowed in the
deﬁnition of linear dependence.
A collection of vectors that is not linearly dependent is called linearly in-
dependent. The vectors u′, v′, w′ in the last example are linearly independent.
Any set of k linearly independent vectors in Rk is called a basis for Rk.
How do we recognize a basis? Notice that k vectors
u1
=
(u1
1, u1
2, . . . , u1
k)
u2
=
(u2
1, v2
2, . . . , v2
k)
. . .
uk
=
(uk
1, uk
2, . . . , uk
k)
are linearly dependent if and only if there are numbers a1, a2, . . . , ak, not all
zero, such that
a1 u1 + a2 u2 + · · · + ak uk = 0 .

APPENDIX III
371
This in turn is true if and only if the system of equations
a1u1
1 + a2u2
1 + · · · + akuk
1
=
0
a1u1
2 + a2u2
2 + · · · + akuk
2
=
0
· · ·
a1u1
k + a2u2
k + · · · + akuk
k
=
0
has a nontrivial solution. But such a system has a nontrivial solution if and
only if
det




u1
1
u2
1
· · ·
uk
1
u1
2
u2
2
· · ·
uk
2
· · ·
u1
k
u2
k
· · ·
uk
k



= 0.
So a basis is a set of k vectors as above such that this determinant is not 0.
Bases are important because if u1, u2, . . . , uk form a basis then every ele-
ment x of Rk can be expressed in one and only one way as
x = a1u1 + a2 u2 + · · · + ak uk ,
with a1, a2, . . . , ak scalars. We call this a representation of x as a linear com-
bination of u1, u2, . . . , uk. To see that such a representation is always possible,
and is unique, let x = (x1, x2, . . . , xk) be any element of Rk. If u1, u2, . . . , uk
form a basis then we wish to ﬁnd a1, a2, . . . , ak such that
x = a1 u1 + a2 u2 + · · · + ak uk .
But, as above, this leads to the system of equations
a1u1
1 + a2u2
1 + · · · + akuk
1
=
x1
a1u1
2 + a2u2
2 + · · · + akuk
2
=
x2
· · ·
a1u1
k + a2u2
k + · · · + ak
kuk
k
=
xk .
(A3.4)
Now Cramer’s Rule tells us that the unique solution of the system (A3.4)
is given by
a1 =
det




x1
u2
1
· · ·
uk
1
x2
u2
2
· · ·
uk
2
· · ·
xk
u2
k
· · ·
uk
k




det




u1
1
u2
1
· · ·
uk
1
u1
2
u2
2
· · ·
uk
2
· · ·
u1
k
u2
k
· · ·
uk
k




,
a2 =
det




u1
1
x1
· · ·
uk
1
u1
2
x2
· · ·
uk
2
· · ·
u1
k
xk
· · ·
uk
k




det




u1
1
u2
1
· · ·
uk
1
u1
2
u2
2
· · ·
uk
2
· · ·
u1
k
u2
k
· · ·
uk
k




,
· · ·

372
APPENDIX III
. . . , ak =
det




u1
1
u2
1
· · ·
x1
u1
2
u2
2
· · ·
x2
· · ·
u1
k
u2
k
· · ·
xk




det




u1
1
u2
1
· · ·
uk
1
u1
2
u2
2
· · ·
uk
2
· · ·
u1
k
u2
k
· · ·
uk
k




.
Notice that the nonvanishing of the determinant in the denominator is crucial
for this method to work.
In practice we will be given a basis u1, u2, . . . , uk for Rk and a vector x and
we wish to express x as a linear combination of u1, u2, . . . , uk. We may do so
by solving a system of linear equations as above. A more elegant way to do this
is to use the concept of the inverse of a matrix.
Deﬁnition A3.5
If
M = (mpq) p=1,...,k
q=1,...,ℓ
is a k × ℓmatrix (where k is the number of rows, ℓthe number of columns, and
mpq is the element in the pth row and qth column) and
N = (nrs) r=1,...,ℓ
s=1,...,m
is an ℓ× m matrix, then the product M · N is deﬁned to be the matrix
T = (tuv) u=1,...,k
q=1,...,m
where
tuv =
ℓ
X
q=1
muq · nqv .
Example A3.6
Let
M =




2
3
9
−1
4
0
5
−3
6
4
4
1





APPENDIX III
373
and
N =


−3
0
2
5
−4
−1

.
Then T = M · N is well deﬁned as a 4 × 2 matrix. We notice, for example, that
t11 = 2 · (−3) + 3 · 2 + 9 · (−4) = −36
and
t32 = 5 · 0 + (−3) · 5 + 6 · (−1) = −21 .
Six other easy calculations of this kind yield that
M · N =




−36
6
11
20
−45
−21
−8
19



.
Deﬁnition A3.7
Let M be a k × k matrix. A matrix N is called the inverse of M if M · N =
N · M = Ik = I , where
I =




1
0
· · ·
0
0
1
· · ·
0
· · ·
0
0
· · ·
1



.
When M has an inverse then it is called invertible. We denote the inverse by
M −1.
It follows immediately from the deﬁnition that, in order for a matrix to be
a candidate for being invertible, it must be square.
Proposition A3.8
Let M be a k × k matrix with nonzero determinant. Then M is invertible
and the elements of its inverse are given by
nij = (−1)i+j · det M(i, j)
det M
.
Here M(i, j) is the (k −1) × (k −1) matrix obtained by deleting the jth row
and ith column from M.
Proof: This is a direct calculation.

374
APPENDIX III
Deﬁnition A3.9
If M is either a matrix or a vector, then the transpose tM of M is deﬁned
as follows: If the ijth entry M is mij then the ijth entry of tM is mji.
We will ﬁnd the transpose notion useful primarily as notation. When we
want to multiply a vector by a matrix, the multiplication will only make sense
(in the language of matrix multiplication) after we have transposed the vector.
Proposition A3.10
If
u1
=
(u1
1, u1
2, . . . , u1
k)
u2
=
(u2
1, u2
2, . . . , u2
k)
· · ·
uk
=
(uk
1, uk
2, . . . , uk
k)
form a basis for Rk then let M be the matrix of the coeﬃcients of these vectors
and M −1 the inverse of M (which we know exists because the determinant of
the matrix is nonzero). If x = (x1, x2, . . . , xk) is any element of Rk then
x = a1 · u1 + a2 · u2 + · · · + ak · uk ,
where
(a1, a2, . . . , ak) = x · M −1 .
Proof: Let A be the vector of unknown coeﬃcients (a1, a2, . . . , ak). The system
of equations that we need to solve to ﬁnd a1, a2, . . . , ak can be written in matrix
notation as
A · M = x .
Applying the matrix M −1 to both sides of this equation (on the right) gives
(A · M) · M −1 = x · M −1
or
A · I = x · M −1
or
A = x · M −1 ,
as desired.

APPENDIX III
375
The standard basis for Rk consists of the vectors
e1
=
(1, 0, . . . , 0)
e2
=
(0, 1, . . . , 0)
· · ·
ek
=
(0, 0, . . . , 1) .
(A3.11)
If x = (x1, x2, . . . , xk) is any element of Rk, then we may write
x = x1 e1 + x2 e2 + · · · + xk · ek .
In other words, the usual coordinates with which we locate points in k-dimensional
space are the coordinates with respect to the special basis (A3.11). We write
this basis as e1, e2, . . . , ek.
If x = (x1, x2, . . . , xk) and y = (y1, y2, . . . , yk) are elements of Rk then we
deﬁne
∥x∥=
p
(x1)2 + (x2)2 + · · · + (xk)2
and
x · y = x1y1 + x2y2 + · · · + xkyk .
Proposition A3.12
(The Schwarz Inequality)
If x and y are elements of Rk then
|x · y| ≤∥x∥∥y∥.
Proof: Write out both sides and square. If all terms are moved to the right then
the right side becomes a sum of perfect squares and the inequality is obvious.


Table of Notation
Notation
Section
Deﬁnition
Q
1.1
the rational numbers
sup X
1.1
supremum of X
lub X
1.1
least upper bound of X
inf X
1.1
inﬁmum of X
glb X
1.1
greatest lower bound of X
R
1.1
the real numbers
|x|
1.1
absolute value
|x + y| ≤|x| + |y|
1.1
triangle inequality
C
1.1AP
a cut
C
1.2
the complex numbers
z
1.2
a complex number
i
1.2
the square root of −1
z
1.2
complex conjugate
|z|
1.2
modulus of z
eiθ
1.2
complex exponential
{aj}
2.1
a sequence
aj
2.1
a sequence
ajk
2.2
a subsequence
lim inf aj
2.3
limit inﬁmum of aj
lim sup aj
2.3
limit supremum of aj
aj
2.4
a power sequence
e
2.4
Euler’s number e
P∞
j=1 aj
3.1
a series
SN
3.1
a partial sum
PN
j=1 aj
3.1
a partial sum
P∞
j=1(−1)jbj
3.3
an alternating series
j!
3.4
j factorial
P∞
n−0
Pn
j=0 aj · bn−j
3.5
the Cauchy product of series
377

378
TABLE OF NOTATION
Notation
Section
Deﬁnition
(a, b)
4.1
open interval
[a, b]
4.1
closed interval
[a, b)
4.1
half-open interval
(a, b]
4.1
half-open interval
U
4.1
an open set
F
4.1
a closed set
∂S
4.1
boundary of S
cS
4.1
complement of S
S
4.2
closure of S
◦
S
4.2
interior of S
{Oα}
4.3
an open cover
Sj
4.4
step in constructing the Cantor set
C
4.4
the Cantor set
limE∋x→P f(x)
5.1
limit of f at P
ℓ
5.1
a limit
f + g
5.1
sum of functions
f −g
5.1
diﬀerence of functions
f · g
5.1
product of functions
f/g
5.1
quotient of functions
f ◦g
5.2
composition of functions
f −1
5.2
inverse function
f −1(W)
5.2
inverse image of a set
f(L)
5.3
image of the set L
m
5.3
minimum for a function f
M
5.3
maximum for a function f
limx→P −f(x)
5.4
left limit of f at P
limx→P + f(x)
5.4
right limit of f at P
f ′(x)
6.1
derivative of f at x
df/dx
6.1
derivative of f
Lipα(I)
6.3
space of Lipschitz functions
Ck,α(I)
6.3
space of smooth functions of order k, α
P
7.1
a partition
Ij
7.1
interval from the partition
∆j
7.1
length of Ij
m(P)
7.1
mesh of the partition
R(f, P)
7.1
Riemann sum
R b
a f(x) dx
7.1
Riemann integral
R a
b f(x) dx
7.2
integral with reverse orientation
U(f, P, α)
7.3
upper Riemann sum
L(f, P, α)
7.3
lower Riemann sum
I∗(f)
7.3
upper integral of f

TABLE OF NOTATION
379
Notation
Section
Deﬁnition
I∗(f)
7.3
lower integral of f
R
f dα
7.3
Riemann-Stieltjes integral
V f
7.4
total variation of f
fj
8.1
sequence of functions
{fj}
8.1
sequence of functions
limx→x f(x)
8.2
limit of f as x approaches s
P∞
j=1 fj(x)
8.3
series of functions
SN(x)
8.3
partial sum of a series of
functions
p(x)
8.4
a polynomial
P∞
j=0 aj(x −c)j
9.1
a power series
RN
9.1
tail of the power series
ρ
9.2
radius of convergence
f(x) = Pk
j=0 f (j)(a) (x−a)j
j!
9.2
Taylor expansion
+Rk,a(x)
exp(x)
9.3
the exponential function
sin x
9.3
the sine function
cos x
9.3
the cosine function
Sin x
9.3
sine with restricted domain
Cos x
9.3
cosine with restricted
domain
ln x
9.4
the natural logarithm
function
dy/dx = F(x, y)
10.1
ﬁrst-order diﬀerential
equation
y(x) = y0 +
R x
x0 F(t, y(t)) dt
10.1
integral equation equivalent
of ﬁrst order ODE
yj+1(x) = y0 +
R x
x0 F(t, yj(t)) dt
10.1
Picard iteration technique
(j + 1)aj+1 + (j −p)aj = 0
10.2
a recursion
−2m(m −1) −m + 1 = 0
10.2
indicial equation
cn
11.1
Fourier coeﬃcient
bf(n)
11.2
nth Fourier coeﬃcient
Sf
11.2
Fourier series
SNf
11.2
partial sum of Fourier series
DN
11.2
Dirichlet kernel
bf(ξ)
11.3
Fourier transform of f
C0(R)
11.3
continuous functions
which vanish at ∞
an
11.4
Fourier cosine coeﬃcient
bn
11.4
Fourier sine coeﬃcient
△
11.4
Laplacian
w(r, θ) = 1
2a0
solving the Dirichlet
+ P∞
j=1 rj(aj cos jθ + bj sin jθ)
11.4
problem

380
TABLE OF NOTATION
Notation
Section
Deﬁnition
Rk
12.1
multidimensional
Euclidean space
x = (x1, x2, x3)
12.1
a point in
multidimensional space
B(x, r)
12.1
an (open) ball in
multidimensional space
B(x, r)
12.1
a closed ball in multidimensional
space
limx→P f(x)
12.1
limit in multidimensional space
f(P + h) = f(P)
+MP · th + RP(f, h)
12.1
f is diﬀerentiable at P
MP
12.1
the derivative of f at P
RP
12.2
remainder term for the derivative
Jf
12.3
Jacobian matrix
(X, ρ)
13.1
metric space
ρ
13.1
a metric
B(P, r)
13.1
(open) ball in a metric space
B(P, r)
13.1
closed ball in a metric space
U
13.2
open set in a metric space
E
13.2
closed set in a metric space
{Oα}
13.2
open covering
F
13.4
an equicontinuous family
C([0, 1])
14.2
the continuous functions on [0, 1]
∥∥
14.2
a norm
X
14.2
a normed linear space
B(x, r)
14.2
(open) ball in a normed linear space
B(P, r)
14.2
closed ball in a normed linear space
ℓp
14.2
space of p-summable series
Λ
14.4
linear operator
∥Λ∥X,Y
14.4
norm of a linear operator
Gδ
14.5
countable intersection of open sets
bλ
14.5
extension of the linear functional λ
Lp
14.6
space of pth-power integrable
functions
χ
14.6
a characteristic function
∥∥X×Y
14.6
product metric
π1
14.6
projection mapping
π2
14.6
projection mapping
G
14.6
Green’s function
Ω
14.6
smoothly bounded domain
Ω
14.6
closure of domain
∂Ω
14.6
boundary of domain

TABLE OF NOTATION
381
Notation
Section
Deﬁnition
µz
14.6
a boundary measure
Pr
14.6
the Poisson kernel
N
A1.1
the natural numbers
bx
A1.1
successor
Q(n)
A1.1
inductive statement
 n
k

A1.1
choose function
Z
A1.2
the integers
[(a, b)]
A1.2
an integer
Q
A1.3
the rational numbers
[(c, d)]
A1.3
a rational number
A
A2.1
an atomic sentence
∧
A2.1
the connective “and”
∨
A2.1
the connective “or”
∼
A2.2
the connective “not”
⇒
A2.2
the connective “if-then”
{ }
A2.5
a set
⇔
A2.3
the connective “if and only if”
iﬀ
A2.3
the connective “if and only if”
∀
A2.4
the quantiﬁer “for all”
∃
A2.4
the quantiﬁer “there exists”
∈
A2.5
is an element of
⊂
A2.5
subset of
̸∈
A2.5
is not an element of
∩
A2.5
intersection
∪
A2.5
union
∅
A2.5
the empty set
\
A2.5
set-theoretic diﬀerence
cS
A2.5
complement of the set S
(a, b)
A2.6
a relation
f(x)
A2.6
a function
f ◦g
A2.6
composition of functions
car(A)
A2.7
the cardinality of A
|A|
A2.7
the cardinality of A
E
A2.7
the even integers
O
A2.7
the odd integers
×
A2.7
set-theoretic product
u = (u1, . . . , un)
A3.1
a multidimensional vector
det
A3.1
determinant
M = (mpq) p=1,...,k
q=1,...,ℓ
A3.1
k × ℓmatrix
A · B
A3.1
matrix multiplication
M(i, j)
A3.1
deleted matrix
tM
A3.1
matrix transpose
x · y
A3.1
vector dot product


GLOSSARY
Abel’s convergence test
A test for convergence of series that is based on
summation by parts.
absolutely convergent series
A series for which the absolute values of the
terms form a convergent series.
absolute maximum
A number M is the absolute maximum for a function f
if f(x) ≤f(M) for every x.
absolute minimum
A number m is the absolute minimum for a function f
if f(x) ≥f(m) for every x.
absolute value
Given a real number x, its absolute value is the distance of x
to 0.
accumulation point
A point x is an accumulation point of a set S if every
neighborhood of x contains inﬁnitely many distinct elements of S.
algebraic number
A number which is the solution of a polynomial equation
with integer coeﬃcients.
alternating series
A series of real terms which alternate in sign.
alternating series test
If an alternating series has terms tending to zero
then it converges.
“and”
The connective which is used for conjunction.
atomic sentence
A sentence with a subject and a verb, and sometimes an
object, but no connectives.
383

384
GLOSSARY
Archimedean Property
If a and b are positive real numbers then there is a
positive integer n so that na > b.
Ascoli-Arzela Theorem
A compactness theorem for spaces of continuous
functions.
Baire Category Theorem
The result that says that a complete metric space
cannot be written as the countable union of nowhere dense sets.
Banach-Steinhaus Theorem
A result that gives suﬃcient conditions for a
family of linear operators to be uniformly bounded.
Bessel’s inequality
An inequality for Fourier coeﬃcients having the form
PN
n=−N | bfn|2 ≤R 2π
0
|f(t)|2 dt.
bijection
A one-to-one, onto function.
binomial expansion
The expansion, under multiplication, of the expression
(a + b)n.
Bolzano-Weierstrass Theorem
Every bounded sequence of real numbers
has a convergent subsequence.
boundary point
The point b is in the boundary of S if each neighborhood
of b contains both points of S and points of the complement of S.
boundary of a set
The set of boundary points for the set.
bounded above
A subset S ⊂R is bounded above if there is a real number
b such that s ≤b for all s ∈S.
bounded below
A subset S ⊂R is bounded below if there is a real number
c such that s ≥c for all s ∈S.
bounded linear operator
A linear operator T : X →Y that satisﬁes
∥T x∥Y ≤C∥x∥X.
bounded sequence
A sequence aj with the property that there is a number
M so that |aj| ≤M for every j.
bounded set
A set S with the property that there is a number M with
|s| ≤M for every s ∈S.

GLOSSARY
385
bounded variation
A function having bounded total oscillation.
Cantor set
A compact set which is uncountable, has zero length, is perfect,
is totally disconnected, and has many other unusual properties.
cardinality
Two sets have the same cardinality when there is a one-to-one
correspondence between them.
Cauchy Condensation Test A series of decreasing, nonnegative terms con-
verges if and only if its dyadically condense series converges.
Cauchy criterion
A sequence aj is said to be Cauchy if, for each ǫ > 0, there
is an N > 0 so that, if j, k > N, then |aj −ak| < ǫ.
Cauchy criterion for a series
A series satisﬁes the Cauchy criterion if and
only if the sequence of partial sums satisﬁes the Cauchy criterion for a sequence.
Cauchy product
A means for taking the product of two series.
Cauchy’s Mean Value Theorem
A generalization of the Mean Value The-
orem that allows the comparison of two functions.
Chain Rule
A rule for diﬀerentiating the composition of functions.
change of variable
A method for transforming an integral by subjecting the
domain of integration to a one-to-one function.
closed ball
The set of points at distance less than or equal to some r > 0
from a ﬁxed point P.
closed set
The complement of an open set.
closure of a set
The set together with its boundary points.
common reﬁnement of two partitions
The union of the two partitions.
compact set A set E is compact if every sequence in E contains a subsequence
that converges to an element of E.
comparison test for convergence
A series converges if it is majorized in
absolute value by a convergent series.

386
GLOSSARY
comparison test for divergence
A series diverges if it majorizes a divergent
series.
complement of a set
The set of points not in the set.
complete space
A space in which every Cauchy sequence has a limit.
complex conjugate
Given a complex number z = x + iy, the conjugate is
the number z = x −iy.
complex numbers
The set C of ordered pairs of real numbers equipped with
certain operations of addition and multiplication.
composition
The composition of two functions is the succession of one func-
tion by the other.
conditionally convergent series
A series which converges, but not abso-
lutely.
connected set
A set which cannot be separated by two disjoint open sets.
connectives
The words which are used to connect atomic sentences. These
are “and,” “or,” “not,” “if-then,” and “if and only if.”
continuity at a point
The function f is continuous at P if the limit of f at
P equals the value of f at P. Equivialently, given ǫ > 0, there is a δ > 0 so
that |x −P| < δ implies |f(x) −f(P)| < ǫ.
continuous function
A function for which the inverse image of an open set
is open.
continuously diﬀerentiable function
A function which has a derivative at
every point, and so that the derivative function is continuous.
convergence of a series
A series converges if and only if its sequence of
partial sums converges.
convergence of a sequence (of scalars)
A sequence aj with the property
that there is a limiting element ℓso that, for any ǫ > 0, there is a positive
integer N so that, if j > n, then |aj −ℓ| < ǫ.

GLOSSARY
387
converse
For a statement “A
implies
B”, the converse statement is “B
implies A”.
contrapositive
For a statement “A implies B”, the contrapositive state-
ment is “∼B implies ∼A”.
cosine function
The function cos x = P∞
j=0(−1)jx2j/(2j)!.
countable set
A set that has the same cardinality as the natural numbers.
Cramer’s Rule
A device in linear algebra for solving systems of linear equa-
tions.
decreasing sequence
The sequence of real numbers aj is decreasing if
a1 ≥a2 ≥a3 ≥· · · .
Dedekind cut
A rational half line. Used to construct the real numbers.
de Morgan’s Laws The identities c(A∪B) = cA∩cB and c(A∩B) = cA∪cB.
Density Property
If c < d are real numbers then there is a rational number
q with c < q < d.
denumerable set
A set that is either empty, ﬁnite, or countable.
derivative
The limit limt→x(f(x) −f(t))/(t −x) for a function f on an open
interval.
derived power series
The series obtaind by diﬀerentiating a power series
term by term.
determinant
The signed sum of products of elements of a matrix.
diﬀerence quotient
The quotient (f(t) −f(x))/(t −x) for a function f on
an open interval.
diﬀerentiable
A function that possesses the derivative at a point. This will
be written diﬀerently in one variable and in several variables.
Dirichlet function A function, taking only the values 0 and 1, which is highly
discontinuous.

388
GLOSSARY
Dirichlet problem on the disc
The problem of ﬁnding a harmonic function
on the disc with speciﬁed boundary values.
Dirichlet kernel
A kernel that represents the partial sum of a Fourier series.
The kernel has the form DN(t) = (sin(N + 1
2)t)/(sin 1
2t).
disconnected set
A set which can be separated by two disjoint open sets.
discontinuity of the ﬁrst kind
A point at which a function f is discontin-
uous because the left and right limits at the point disagree.
discontinuity of the second kind
A point at which a function f is discon-
tinuous because either the left limit or the right limit at the point does not exist.
diverge to inﬁnity
A sequence with elements that become arbitrarily large.
domain of a function
See function.
domain of integration The interval over which the integration is performed.
dummy variable
A variable whose role in an argument or expression is for-
mal. A dummy variable can be replaced by any other variable with no logical
consequences.
empty set
The set with no elements.
equibounded family of functions
A family F = {fα}α∈A of functions so
that there is a constant M with |fα(x)| ≤M for all x and all α.
equicontinuous family of functions
A family F = {fα}α∈A of functions
such that, if ǫ > 0, then there is a δ > 0 so that if s and t are distance less than
δ then |fα(s) −fα(t)| < ǫ for every α.
equivalence classes
The pairwise disjoint sets into which an equivalence re-
lation partitions a set.
element of
A member of a given set.
equivalence relation
A relation that partitions the set in question into pair-
wise disjoint sets, called equivalence classes.

GLOSSARY
389
Euler’s number
This is the number e = 2.71828 . . . which is known to be
irrational, indeed transcendental.
Euler’s formula
The identity eiy = cos y + i sin y.
exponential function
The function exp(z) = P∞
j=0 zj/j!.
ﬁeld
A system of numbers equipped with operations of addition and multipli-
cation and satisfying eleven natural axioms.
ﬁnite-dimensional space
A linear space with a ﬁnite basis.
ﬁnite set
A set that can be put in one-to-one correspondence with a set of
the form {1, 2, . . ., n} for some positive integer n.
ﬁnite subcovering
An open covering U = {Uj}k
j=1 is a ﬁnite subcovering of
E if each element of U is an element of a larger covering V.
ﬁrst category
A set is of ﬁrst category if it can be written as the countable
union of nowhere dense sets.
ﬁrst-order diﬀerential equation (ODE)
An equation of the form dy/dx =
F(x, y).
“for all” The quantiﬁer ∀for making a statement about all objects of a certain
kind.
Fourier coeﬃcient
The coeﬃcient bf(n) = (1/[2π]
R 2π
0
f(t)e−int dt of the
Fourier series for the function f.
Fourier series
A series of the form f(t) ∼P
j cjeijt which decomposes
the function f as a sum of sines and cosines.
We sometimes write Sf ∼
P∞
j=−∞bf(j)eijt.
Fourier transform
Given a function f on the real line, its Fourier transform
is bf(ξ) = R
R f(t)eitξ dt.
function
A function from a set A to a set B is a relation f on A and B such
that for each a ∈A there is one and only one pair (a, b) ∈f. We call A the
domain and B the range of the function.
Fundamental Theorem of Calculus
A result relating the values of a func-
tion to the integral of its derivative: f(x) −f(a) = R x
a f ′(t) dt.

390
GLOSSARY
geometric series
This is a series of powers.
greatest lower bound
The real number c is the greatest lower bound for the
set S ⊂R if b is a lower bound and if there is no lower bound that is greater
than c.
Green’s function
A function G(x, y) that is manufactured from the fun-
damental solution for the Laplacian and is useful in solving partial diﬀerential
equations.
Hahn-Banach Theorem
The result that says that a linear functional on a
linear subspace Y can always be extended to a linear functional on the super-
space X with no increase in norm.
harmonic function
A function that is annihilated by the Laplacian.
Hausdorﬀspace
A topological space in which distinct points p, q are sepa-
rated by disjoint neighborhoods.
Hilbert transform The singular integral operator f 7→
R
f(t)/(x−t) dt which
governs convergence of Fourier series and many other important phenomena in
analysis.
i
The square root of −1 in the complex number system.
identity matrix
The square matrix with 1s on the diagonal and 0s in the
other entries.
if
An alternative phrase for converse implication.
“if and only if”
The connective which is used for logical equivalence.
“if-then”
The connective which is used for implication.
image of a function
See function. The image of the function f is Image f =
{b ∈B : ∃a ∈A such that f(a) = b}.
image of a set
If f is a function then the image of E under f is the set
{f(e) : e ∈E}.
imaginary part
Given a complex number z = x + iy, its imaginary part is
y.

GLOSSARY
391
implicit function theorem
A result that gives suﬃcient conditions, in terms
of the derivative, on an equation of several variables to be able to solve for one
variable in terms of the others.
increasing sequence
The sequence of real numbers aj is increasing if a1 ≤
a2 ≤a3 ≤· · · .
inﬁmum
See greatest lower bound.
inﬁnite set
A set is inﬁnite if it is not ﬁnite.
initial condition For a ﬁrst-order diﬀerential equation, this is a side condition
of the form y(x0) = y0.
integers
The natural numbers, the negatives of the natural numbers, and
zero.
integral equation equivalent of a ﬁrst-order ODE
An equation of the
form y(x) = y0 +
R x
x0 F(t, y(t)) dt.
integration by parts
A device for integrating a product.
interior of a set
The collection of interior points of the set.
interior point
A point of the set S which has a neighborhood lying in S.
intermediate value theorem
The result that says that a continuous func-
tion does not skip values.
intersection of sets
The set of elements common to two or more given sets.
interval
A subset of the reals that contains all its intermediate points.
interval of convergence of a power series
An interval of the form (c −
ρ, c + ρ) on which the power series converges (uniformly on compact subsets of
the interval).
inverse function theorem
A result that gives suﬃcient conditions, in terms
of the derivative, for a function to be locally invertible.

392
GLOSSARY
inverse of a matrix
Given a square matrix A, we say that B is its inverse if
AB = BA = I, where I is the identity matrix.
invertible matrix
A matrix that has an inverse.
irrational number
A real number which is not rational.
isolated point of a set
A point of the set with a neighborhood containing
no other point of the set.
Jacobian matrix
The matrix of partial derivatives of a mapping from Rk to
Rk.
k times continuously diﬀerentiable A function that has k derivatives, each
of which is continuous.
Lambert W function
A transcendental function W with the property that
any of the standard transcendental functions (sine, cosine, exponential, loga-
rithm) can be expressed in terms of W.
Laplacian
The partial diﬀerential operator given by △= ∂2/∂x2
1 + ∂2/∂x2
2 +
· · · + ∂2/∂x2
k.
least upper bound
The real number b is the least upper bound for the set
S ⊂R if b is an upper bound and if there is no other upper bound that is less
than b.
Least Upper Bound Property
The important deﬁning property of the real
numbers.
left limit
A limit of a function at a point P that is calculated with values of
the function that are to the left of P.
higher derivatives
The derivative of a derivative.
Legendre’s equation
The ODE (1 −x2)y′′ −2xy′ + p(p + 1)y = 0.
l’Hˆopital’s Rule
A rule for calculating the limit of the quotient of two func-
tions in terms of the quotient of the derivatives.
limit
The value ℓthat a function approaches at a point of or an accumulation
point P of the domain. Equivalently, given ǫ > 0, there is a δ > 0 so that

GLOSSARY
393
|f(x) −ℓ| < ǫ whenever |x −P| < δ.
limit inﬁmum
The least limit of any subsequence of a given sequence.
limit supremum
The greatest limit of any subsequence of a given sequence.
linear combination
If v1, v2, . . . , vk are vectors then a linear combination
is an expression of the form c1v1 + c2v2 + · · · ckvk for scalar coeﬃcients cj.
linear functional
A linear operator taking values in a scalar ﬁeld R or C.
linearly dependent set
In a linear space, a set that is not linearly indepen-
dent.
linearly independent set
In a linear space, a set that has no nontrivial
linear combination giving 0.
linear operator
A function between linear spaces that satisﬁes the linearity
condition T (cx + dy) = cT (x) + dT (y).
Lipschitz function
A function that satisﬁes a condition of the form |f(s) −
f(t)| ≤C|s −t| or |f(s) −f(t)| ≤|s −t|α for 0 < α ≤1.
local extrema
Either a local maximum or a local minimum.
local maximum
The point x is a local maximum for the function f if
f(x) ≥f(t) for all t in a neighborhood of x.
local minimum
The point x is a local minimum for the function f if
f(x) ≤f(t) for all t in a neighborhood of x.
logically equivalent
Two statements are logically equivalent if they have the
same truth table.
logically independent
Two statements are logically independent if neither
one implies the other.
lower bound
A real number c is an lower bound for a subset S ⊂R if s ≥c
for all s ∈S.
lower Riemann sum
A Riemann sum devised for deﬁning the Riemann-
Stieltjes integral.

394
GLOSSARY
Mean Value Theorem
If f is a continuous function on [a, b], diﬀerentiable
on the interior, then the slope of the segment connecting (a, f(a)) and (b, f(b))
equals the derivative of f at some interior point.
m × n matrix
A matrix with m rows and n columns.
mesh of a partition
The maximum length of any interval in the partition.
metric
The distance function on a metric space.
metric space
A space X equipped with a distance function ρ.
modulus
The modulus of a complex number z = x + iy is |z| =
p
x2 + y2.
monotone sequence
A sequence that is either increasing or decreasing.
monotonic function
A function that is either monotonically increasing or
monotonically decreasing.
monotonically decreasing function
A function whose graph goes downhill
when moving from left to right: f(s) ≥f(t) when s < t.
monotonically increasing function
A function whose graph goes uphill
when moving from left to right: f(s) ≤f(t) when s < t.
natural logarithm function
The inverse function to the exponential func-
tion.
natural numbers
The counting numbers 1, 2, 3, . . ..
necessary for
An alternative phrase for converse implication.
neighborhood of a point
An open set containing the point.
Neumann series
A series of the form 1/(1 −α) = P∞
j=0 αj for |α| < 1.
Newton quotient
The quotient (f(t) −f(x))/(t −x) for a function f on an
open interval.
non-terminating decimal expansion
A decimal expansion for a real num-
ber that has inﬁnitely many nonzero digits.

GLOSSARY
395
norm
The notion of distance on a normed linear space.
normed linear space A linear space equipped with a norm that is compatible
with the linear structure.
“not”
The connective which is used for negation.
one-to-one function
A function that takes diﬀerent values at diﬀerent points
of the domain.
onto
A function whose image equals its range.
only if
An alternative phrase for implication.
open ball
The set of points at distance less than some r > 0 from a ﬁxed
point P.
open covering
A collection {Uα}α∈A of open sets is an open covering of a
set S if ∪αUα ⊃S.
Open Mapping Principle
The result that says that a bounded, surjective
linear mapping is open.
open set
A set which contains a neighborhood of each of its points.
“or”
The connective which is used for disjunction.
ordered ﬁeld
A ﬁeld equipped with an order relation that is compatible with
the ﬁeld structure.
ordinary diﬀerential equation (ODE)
An equation involving a function
of one variable and some of its derivatives.
partial derivative
For a function of several variables, this is the derivative
calculated in just one variable, with the other variables held ﬁxed.
partial sum of a Fourier series
The sum of the terms of a Fourier series
having index between −N and N.
partial sum (of scalars)
The sum of the ﬁrst N terms of a series of scalars.

396
GLOSSARY
partial sum of functions
The sum of the ﬁrst N terms of a series of func-
tions.
partition of the interva [a, b] A ﬁnite, ordered set of points P = {x0, x1, x2, . . . ,
xk−1, xk} such that
a = x0 ≤x1 ≤x2 ≤· · · ≤xk−1 ≤xk = b .
Peano axioms
An axiom system for the natural numbers.
perfect set
A set which is closed and in which every point is an accumulation
point.
Picard iteration technique
An iteration scheme for solving a ﬁrst-order
ODE using the steps yj+1(x) = y0 +
R x
x0 F(t, yj(t)) dt.
Pinching Principle
A criterion for convergence of a sequence that involves
bounding it below by a convergent sequence and bounding it above by another
convergent sequence with the same limit.
pointwise convergence of a sequence of functions
A sequence fj of
functions converges pointwise if fj(x) convergence for each x in the common
domain.
Poisson kernel
The reproducing kernel for harmonic functions.
polar form of a complex number
The polar form of a complex number z
is reiθ, where r is the modulus of z and θ is the angle that the vector from 0 to
z subtends with the positive x-axis.
power series expanded about the point c A series of the form P∞
j=0 aj(x−
c)j.
power set
The collection of all subsets of a given set.
Principle of Induction
A proof technique for establishing a statement Q(n)
about the natural numbers.
quantiﬁer
A logical device for making a quantitative statement. Our stan-
dard quantiﬁers are “for all” and “there exists.”

GLOSSARY
397
radius of convergence of a power series
Half the length ρ of the interval
of convergence.
range of a functon
See function.
rational numbers
Numbers which may be represented as quotients of inte-
gers.
Ratio Test for Convergence
A series converges if the limit of the sequence
of quotients of summands is less than 1.
Ratio Test for Divergence
A series diverges if the limit of the sequence of
quotients of summands is greater than 1.
real analytic function
A function with a convergent power series expansion
about each point of its domain.
real numbers
An ordered ﬁeld R containing the rationals Q so that every
nonempty subset with an upper bound has a least upper bound.
real part
Given a complex number z = x + iy, its real part is x.
rearrangement of a series
A new series obtained by permuting the sum-
mands of the original series.
relation
A relation on sets A and B is a subset of A × B.
remainder term for the Taylor expansion The term Rk,a(x) in the Taylor
expansion.
Riemann integrable
A function for which the Riemann integral exists.
Riemann integral
The limit of the Riemann sums.
Riemann-Lebesgue Lemma The result that says that the Fourier transform
of an integrable function vanishes at inﬁnity.
Riemann’s lemma
A result guaranteeing the existence of the Riemann-
Stieltjes integral in terms of the proximity of the upper and lower Riemann
sums.

398
GLOSSARY
Riemann-Stieltjes integral
A generalization of the Riemann integral which
allows measure of the length of the interval in the partition by a function α.
Riemann sum
The approximate integral based on a partition.
right limit
A limit of a function at a point P that is calculated with values
of the function to the right of P.
Rolle’s Theorem
The special case of the Mean Value Theorem when f(a) =
f(b) = 0.
Root Test for Convergence
A series converges if the limit of the nth roots
of the nth terms is less than one.
Root Test for Divergence
A series is divergent if the limit of the nth roots
of the nth terms is greater than one.
scalar
An element of either R or C.
Schroeder-Bernstein Theorem
The result that says that if there is a one-
to-one function from the set A to the set B and a one-to-one function from the
set B to the set A then A and B have the same cardinality.
Schwarz inequality
The inequality
|v · w| ≤∥v∥∥w∥.
second category
A space that cannot be written as the countable union of
nowhere dense sets.
sequence of functions
A function from N into the set of functions on some
space.
sequence (of scalars)
A function from N into R or C or a metric space. We
often denote the sequence by aj.
series (of scalars)
An inﬁnite sum of scalars.
series of functions
An inﬁnite sum of functions.
set
A collection of objects.
setbuilder notation
The notation {x : P(x)} for specifying a set.

GLOSSARY
399
set-theoretic diﬀerence
The set-theoretic diﬀerence A \ B consists of those
elements that lie in A but not in B.
set-theoretic isomorphism
A one-to-one, onto function.
set-theoretic product
If A and B are sets then their set-theoretic product
is the set of ordered pairs (a, b) with a ∈A and b ∈B.
sine function
The function sin x = P∞
j=0(−1)jx2j+1/(2j + 1)!.
smaller cardinality
The set A has smaller cardinality than the set B if there
is a one-to-one mapping of A to B but none from B to A.
Stone-Weierstrass Theorem
A generalization of the Weierstrass Approxi-
mation Theorem to algebras more general than the polynomials.
strictly monotonically decreasing function
A function whose graph goes
strictly downhill when moving from left to right: f(s) > f(t) when s < t.
monotonically increasing function
A function whose graph goes strictly
uphill when moving from left to right: f(s) < f(t) when s < t.
subcovering
A covering which is a subcollection of a larger covering.
subﬁeld
Given a ﬁeld k, a subﬁeld m is a subset of k which is also a ﬁeld with
the induced ﬁeld structure.
subsequence
A sequence that is a subset of a given sequence with the ele-
ments occurring in the same order.
subset of
A subcollection of the members of a given set.
successor
The natural number which follows a given natural number.
suﬃces for
An alternative phrase for implication.
summation by parts
A discrete analogue of integration by parts.
supremum
See least upper bound.

400
GLOSSARY
Taylor’s expansion
The expansion f(x) = Pk
j=0 f (j)(a) (x−a)j
j!
+ Rk,a(x) for
a given function f.
terminating decimal
A decimal expansion for a real number that has only
ﬁnitely many nonzero digits.
“there exists”
The quantiﬁer ∃for making a statement about some objects
of a certain kind.
totally disconnected set
A set in which any two points can be separated
by two disjoint open sets.
transcendental number
A real number which is not algebraic.
transpose of a matrix Given a matrix A = {aij}, the transpose is the matrix
obtained by replacing aij with aji.
triangle inequality
The inequality
|a + b| ≤|a| + |b|
for real numbers or
∥v + w∥≤∥v∥+ ∥w∥
in a normed space or
ρ(x, y) ≤ρ(x, z) + ρ(z, y)
in a metric space.
truth table
An array which shows the possible truth values of a statement.
uncountable set
A set that does not have the same cardinality as the natural
numbers.
Uniform Boundedness Principle
A result that gives suﬃcient conditions
for a family of linear operators to be uniformly bounded.
uniform convergence of a sequence of functions
The sequence fj of
functions converges uniformly to a function f if, given ǫ > 0, there is an N > 0
so that, if j > N, then |fj(x) −f(x)| < ǫ for all x.
uniform convergence of a series of functions
A series of functions such
that the sequence of partial sums converges uniformly.

GLOSSARY
401
uniformly Cauchy sequence of functions
A sequence of functions fj with
the property that, for ǫ > 0, there is an N > 0 so that, if j, k > N, then
|fj(x) −fk(x)| < ǫ for all x in the common domain.
uniformly continuous A function f is uniformly continuous if, for each ǫ > 0,
there is a δ > 0 so that |f(s) −f(t)| < ǫ whenever |s −t| < δ.
union of sets
The collection of objects that lie in any one of a given collection
of sets.
universal set
The set of which all other sets are a subset.
upper bound
A real number b is an upper bound for a subset S ⊂R if s ≤b
for all s ∈S.
upper Riemann sum
A Riemann sum devised for deﬁning the Riemann-
Stieltjes integral.
Venn diagram
A pictorial device for showing relationships among sets.
Weierstrass Approximation Theorem
The result that any continuous
function on [0, 1] can be uniformly approximated by polynomials.
Weierstrass M-Test
A simple scalar test that guarantees the uniform con-
vergence of a series of functions.
Weierstrass nowhere diﬀerentiable function
A function that is continu-
ous on [0, 1] that is not diﬀerentiable at any point of [0, 1].
well deﬁned
An operation on equivalence classes is well deﬁned if the result
is independent of the representatives chosen from the equivalence classes.
Zero Test
If a series converges then its summands tend to zero.


Bibliography
[BOA1] R. P. Boas, A Primer of Real Functions, Carus Mathematical Monograph
No. 13, John Wiley & Sons, Inc., New York, 1960.
[BIR] G. Birkhoﬀand G.-C. Rota, Ordinary Diﬀerential Equations, John Wiley
& Sons, New York, 1978.
[BUC] R. C. Buck, Advanced Calculus, 2d ed., McGraw-Hill Book Company, New
York, 1965.
[COL] E. Coddington and N. Levinson, Theory of Ordinary Diﬀerential Equa-
tions, McGraw-Hill, New York, 1955.
[DUS] N. Dunford and J. Schwartz, Linear Operators, Interscience Publishers,
New York, 1958–1971.
[FED] H. Federer, Geometric Measure Theory, Springer-Verlag, New York, 1969.
[FOU] J. Fourier, The Analytical Theory of Heat, G. E. Stechert & Co., New
York, 1878.
[HOF] K. Hoﬀman, Analysis in Euclidean Space, Prentice Hall, Inc., Englewood
Cliﬀs, NJ, 1962.
[KAK] S. Kakutani, Some characterizations of Euclidean space, Japan. J. Math.
16(1939), 93–97.
[KAT] Y. Katznelson, Introduction to Harmonic Analysis, John Wiley and Sons,
New York, 1968.
[KEL] J. L. Kelley, Banach spaces with the extension property, Trans. AMS
72(1952), 323–326.
[KOL] A. N. Kolmogorov, Grundbegriﬀe der Wahrscheinlichkeitsrechnung, Spring-
er-Verlag, Berlin, 1933.
403

404
BIBLIOGRAPHY
[KRA1] S. G. Krantz, The Elements of Advanced Mathematics, 2nd ed., CRC Press,
Boca Raton, FL, 2002.
[KRA2] S. G. Krantz, A Panorama of Harmonic Analysis, Mathematical Associ-
ation of America, Washington, DC, 1999.
[KRA3] S. G. Krantz, Partial Diﬀerential Equations and Complex Analysis, CRC
Press, Boca Raton, FL, 1992.
[KRA4] S. G. Krantz, Handbook of Logic and Proof Techniques for Computer Sci-
entists, Birkh¨auser, Boston, 2002.
[KRA5] S. G. Krantz, Real Analysis and Foundations, 1st ed., CRC Press, Boca
Raton, FL, 1992.
[KRA6] S. G. Krantz, Function Theory of Several Complez Variables, 2nd ed.,
American Mathematical Society, Providence, RI, 2001.
[KRP] S. G. Krantz and H. R. Parks, A Primer of Real Analytic Functions, 2nd
ed., Birkh¨auser Publishing, Boston, 2002.
[KRS] S. G. Krantz and G. Simmons, Ordinary Diﬀerential Equations, McGraw-
Hill, New York, 2006.
[LAX] P. D. Lax, On the existence of Green’s functions, Proc. Amer. Math. Soc.
3(1952), 526–531.
[LOS] L. Loomis and S. Sternberg, Advanced Calculus, Addison-Wesley, Reading,
MA, 1968.
[NIV] I. Niven, Irrational Numbers, Carus Mathematical Monograph No. 11,
John Wiley & Sons, Inc., New York, 1956.
[RES] M. Reed and B. Simon, Methods of Modern Mathematical Physics, Aca-
demic Press, New York, 1972.
[ROY] H. Royden, Real Analysis, Macmillan, New York, 1963.
[RUD1] W. Rudin, Principles of Mathematical Analysis, 3rd ed., McGraw-Hill
Book Company, New York, 1976.
[RUD2] W. Rudin, Real and Complex Analysis, McGraw-Hill Book Company, New
York, 1966.
[RUD3] W. Rudin, Functional Analysis, McGraw-Hill, New York, 1973.
[SOB] A. Sobczyk, On the extension of linear transformations, Trans. Amer.
Math. Soc. 55(1944), 153–169.
[STG] E. M. Stein and G. Weiss, Introduction to Fourier Analysis on Euclidean
Spaces, Princeton University Press, Princeton, NJ, 1971.

BIBLIOGRAPHY
405
[STRO] K. Stromberg, An Introduction to Classical Real Analysis, Wadsworth
Publishing, Inc., Belmont, CA, 1981.
[YOS] K. Yosida, Functional Analysis, 6th ed., Springer-Verlag, New York, 1980.


K20338
TEXTBOOKS in MATHEMATICS
Back by popular demand, Real Analysis and Foundations, Third Edition 
bridges the gap between classic theoretical texts and less rigorous ones, 
providing a smooth transition from logic and proofs to real analysis. Along 
with the basic material, the text covers Riemann-Stieltjes integrals, Fourier 
analysis, metric spaces and applications, and differential equations.
Offering a more streamlined presentation, this edition moves elementary 
number systems and set theory and logic to appendices and removes 
the material on wavelet theory, measure theory, differential forms, and the 
method of characteristics. It also adds a chapter on normed linear spaces 
and includes more examples and varying levels of exercises.
Features
•	
Presents a clear, thorough treatment of the theorems and concepts of 
real analysis
•	
Includes a new chapter on normed linear spaces
•	
Provides more examples throughout the text and additional exercises 
at the end of each section
•	
Designates challenging exercises with an asterisk
With extensive examples and thorough explanations, this best-selling book 
continues to give you a solid foundation in mathematical analysis and its 
applications. It prepares you for further exploration of measure theory, 
functional analysis, harmonic analysis, and beyond.
Real Analysis  
and Foundations
T H I R D  E D I T I O N
Mathematics

