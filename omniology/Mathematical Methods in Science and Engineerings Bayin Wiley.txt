
MATHEMATICAL 
METHODS IN SCIENCE 
AND ENGINEERING 

This Page Intentionally Left Blank

MATHEMATICAL 
METHODS IN SCIENCE 
AND ENGINEERG 
S. SELCUK BAYIN 
Middle East Technical University 
Ankara, Turkey 
@K&CIENCE 
A JOHN WILEY & SONS, INC., PUBLICATION 

Copyright 0 2006 by John Wiley L Sons, Inc. All rights reserved. 
Published by John Wiley & Sons, Inc., Hoboken, New Jersey. 
Published simultaneously in Canada. 
No part of this publication may be reproduced, slored in a mtrieval system, or transmitted in any form 
or by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as 
permitted under Section 107 or 108 of the 1976 United States Copyright Act, without either the prior 
written permission of the Publisher, or authorization through paymcnt of tbe appropriate pcr-copy fee to 
the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax 
(978) 750-4470, or on the web at www.copyright.com. Requests to the Publisher for permission should 
be addressed to the Permissions Department, John Wiley & Sons, Inc., 11 1 River Street, Hoboken, NJ 
07030, (201) 748-601 1, fax (201) 748-6008, or online at h t t p : / / ~ . w i l e y . c o ~ g o ~ s ~ o n .  
Limit of LiabilityDisclaimer of Warranty: While the publisher and author have used theirbest efforts in 
preparing this book, they make no rcpresentations or warranties with respect to the accuracy or 
completeness of the contents of this book and spccificalty disclaim any implied warranties of 
merchantability or fitness for a particular purpose. No warranty may be created or extended by sales 
representatives or written sales materials. The advice and strategies contained henin may not be 
suitable for your situation. You should consult with a professional wherc appropriate. Neither the 
publisher nor author shall be liable for any loss ofprofit or any other commercial damages, including 
but not limited to special, incidental, consequential, or other damages. 
For general information on our other products and services or for technical support, please contact our 
Customer Care Depment within the United States at (800) 762-2974, outside the United States at 
(317)572-3993 or fax(317)572-4002. 
Wiley also publishes its books in a variety of electronic formats. Some content that appem in print may 
not be available in electronic format. For information about Wiley products, visit our web site at 
www.wiley.com 
Libmv of Congress ~ i n g 4 n - P u M i c a t i o n  
Data is ~~. 
ISBN-I3 978-0-470-04142-0 
ISBN-10 0-470-04142-0 
Printed in the United States of America 
1 0 9 8 7 6 5 4 3 2 1  

Contents 
Preface 
xxz 
Acknowledgments 
xxuii 
1 NATURE and MATHEMATICS 
1 
1.1 
Mathematics and Nature 
3 
1.2 
Laws of Nature 
4 
1.3 
Mathematics and Mind 
5 
1.4 
Is Mathematics the Only Language for Nature? 
6 
1.5 
Nature and Mankind 
7 
2 LEGENDRE EQUATION and POLYNOMIALS 
2.1 
Legendre Equation 
2.2 
2.3 
Legendre Polynomials 
2.1.1 
Method of Separation of Variables 
Series Solution of the Legendre Equation 
2.2.1 
Fro benius Method 
2.3.1 
Rodriguez Formula 
2.3.2 
Generating Function 
2.3.3 Recursion Relations 
2.3.4 
Special Values 
9 
10 
12 
13 
16 
17 
19 
19 
21 
22 
V 

vi 
CONTENTS 
3 
2.3.5 
Special Integrals 
2.9.6 
Orthogonality and Completeness 
Associated Legendre Equation and its Solutions 
2.4.1 
Associa,ted Legendre Polynomials 
2.4.2 
Orthogonality of the Associated Legendre 
Polynomials 
2.4 
2.5 
Spherical Harmonics 
Problems 
LAGUERRE POLYNOMIALS 
3.1 
Laguerre Equa,tion and Polynomials 
3.2 
Other Definitions of Laguerre Polynomials 
3.2.1 
Generating Function of Laguerre 
3.2.2 
Polynomials 
Rodriguez Formula for the Laguerre 
Polynomials 
3.3 
Orthogonality of Laguerre Polynomials 
3.4 
Other Properties of Laguerre Polynomials 
3.4.1 
Recursion Relations 
3.4.2 Special Values of Laguerre Polynomials 
Associated Laguerre Equation and Polynomials 
Properties of Associated Laguerre Polynomials 
3.6.1 
Generating Function 
3.6.2 
Rodriguez Formula and Orthogonality 
3.6.3 
Recursion Relations 
Problems 
3.5 
3.6 
4 HERMITE POLYNOMIALS 
4.1 
Hermite Equation and Polynomials 
4.2 
Other Definitions of Hermite Polynomials 
4.2.1 
Generating Function 
4.2.2 Rodriguez Formula 
Problems 
4.3 
Recursion Relations and Orthogonality 
5 
GEGENBAUER and CHEBYSHEV POLYNOMIALS 
Gegenbauer Equation and its Solutions 
5.1 
Cosmology and Gegenbauer Polynomials 
5.2 
23 
24 
28 
30 
31 
33 
36 
43 
45 
46 
47 
48 
50 
50 
50 
51 
52 
52 
53 
53 
53 
57 
58 
60 
60 
61 
62 
66 
7f 
71 
75 

CONTENTS 
vh' 
5.2.1 
Orthogonality and the Generating 
Function 
75 
5.3 
Chebyshev Equation and Polynomials 
75 
5.3.1 
Chebyshev Polynomials of the First Kind 
75 
5.3.2 
Relation of Chebyshev and Gegenbauer 
Polynomials 
76 
5.3.3 
Chebyshev Polynomials of the Second 
Kind 
76 
5.3.4 
Orthogonality and the Generating 
Function of Chebyshev Polynomials 
78 
5.3.5 
Another Definition for the Chebyshev 
Polynomials of the Second Kind 
78 
Problems 
79 
6 BESSEL FUNCTIONS 
6.1 
Bessel's Equation 
6.2 
Solutions of Bessel's Equation 
6.2.1 
6.2.2 
Bessel Functions J*tm(x), Nm(x), and 
Modified Bessel Functions Im(x) and K,(x) 
H
y
 
(x) 
6.2.3 Spherical Bessel Functions jl(x), nl(x), and 
hi'72)(x) 
6.3 
Other Definitions of the Bessel Functions 
6.3.1 
Generating Function 
6.3.2 Integral Definitions 
Recursion Relations of the Bessel Functions 
Orthogonality and the Roots of the Bessel 
Functions 
Boundary Conditions for the Bessel Punctions 
Wronskians of Pairs of Solutions 
Problems 
6.4 
6.5 
6.6 
6.7 
7 
HYPER GEOME TRIC FUNCTIONS 
7.1 
Hypergeometric Series 
83 
85 
86 
86 
88 
88 
89 
89 
90 
90 
90 
91 
95 
97 
99 
99 
7.2 
Hypergeometric Representations of Special 
Functions 
103 
Problems 
105 
7.3 
Con& en t Hype rg eome tric Equation 
104 

viii 
CON TEN TS 
8 STURM-LIOUVILLE THEORY 
8.1 
Self-Adjoint Digerential Operators 
8.2 
Sturm-Liouville Systems 
8.3 
Hermitian Operators 
8.4 
Properties of Hermitian Operators 
8.4.1 
Real Eigenvalues 
8.4.2 
Orthogonality of Eigenfunctions 
8.4.3 
Completeness of the Set of Eigenfunctions 
{urn (x>) 
8.5 
Generalized Fourier Series 
8.6 
Trigonometric Fourier Series 
8.7 
Hermitian Operators in Quantum Mechanics 
Problems 
107 
107 
I 08 
110 
110 
111 
111 
112 
113 
114 
115 
118 
9 STURM-LIOUVILLE SYSTEMS and the FACTORIZATION 
METHOD 
121 
9.1 
Another Form for the Sturm-Liouville Equation 
122 
9.2 
Method of Factorization 
123 
9.3 
Theory of Factorization and the Ladder Operators 124 
9.4 
Solutions via the Factorization Method 
130 
9.4.1 
Case I ( m > 0 and p ( m )  is an increasing 
function) 
130 
9.4.2 
Case 11 m > 0 and p ( m )  is a decreasing 
function I 
131 
9.5 
Technique and the Categories of Factorization 
132 
9.5.1 
Possible Forms for Ic(z,m) 
1 33 
9.6 
Associated Legendre Equation (Type A )  
137 
9.6.1 
Determining the Eigenvalues XL 
139 
9.6.3 
9.6.2 
Construction of the Eigenfunctions 
140 
Harmonics 
141 
9.6.4 
Interpretation of the L* Operators 
143 
Ladder Operators for the Spherical 
9.6.5 
Ladder Operators for the 1 Eigenvalues 
145 
9.7 
Schrodinger Equation for a Single-Electron Atom 
and the Factorization Method (Type F) 
I51 
9.8 
Gegenbauer Functions (Type A )  
1 53 
9.10 Bessel Functions (Type C) 
155 
9.11 Harmonic Oscillator (Type D) 
156 
9.9 
Symmetric Top (Type A )  
154 

CONTENTS 
ix 
Problems 
157 
10 COORDINATES and TENSORS 
10.1 Cartesian Coordinates 
10.1.1 Algebra of Vectors 
10.1.2 Diflerentiation of Vectors 
10.2 Orthogonal Transformations 
10.2.1 Rotations About Cartesian Axes 
10.3 Formal Properties of the Rotation Matrix 
10.4 Euler Angles and Arbitrary Rotations 
10.5 Active and Passive Interpretations of Rotations 
10.6 Infinitesimal Transformations 
10.6.1 Infinitesimal Transformations Commute 
10.7 Cartesian Tensors 
10.7.1 Operations with Cartesian Tensors 
10.7.2 Tensor Densities or Pseudotensors 
10.8 Generalized Coordinates and General Tensors 
10.8.1 Contravariant and Covariant Components 
10.8.2 Metric Tensor and the Line Element 
10.8.3 Geometric Interpretation of Covariant 
and Contravariant Components 
10.9 Operations with General Tensors 
10.9.1 Einstein Summation Convention 
10.9.2 Contraction of Indices 
10.9.3 Multiplication of Tensors 
10.9.4 The Quotient Theorem 
10.9.5 Equality of Tensors 
10.9.6 Tensor Densities 
10.9.7 Diflerentiation of Tensors 
10.9.8 Some Covariant Derivatives 
10.9.9 Riemann Curvature Tensor 
10.9.10 Geodesics 
10.9.11 Invariance and Covariance 
10.10 Spacetime and Four- Tensors 
10.10.1 Minkowski Spacetime 
10.10.2 Lorentz Transformation and the Theory 
10.20.3 Time Dilation and Length Contraction 
10.10.4 Addition of Velocities 
of Special Relativity 
163 
1 63 
166 
166 
1 70 
1 70 
1 72 
1 74 
175 
177 
1 78 
1 78 
179 
180 
181 
183 
164 
186 
188 
188 
188 
189 
189 
189 
189 
190 
193 
195 
196 
197 
197 
197 
199 
801 
201 

x 
CONTENTS 
10.10.5 Four- Tensors in Minkowski Spacetime 
10.10.6 Four- Velocity 
10.10.7 Four-Momentum and Conservation Laws 
10.10.8 Mass of a Moving Particle 
10.10.9 Wave Four- Vector 
10.10.10 Derivative Operators in Spacetime 
10.10.11 Relative Orientation of Axes in R and 
10.10.12 Maxwell’s Equations in Minkowski 
10.10.13 Transformation of Electromagnetic 
10.10.14 Maxwell’s Equations in Terms of 
10.10.15 Covariance of Newton’s Dynamical 
Problems 
K Frames 
Space time 
Fields 
Potentials 
Theory 
11 CONTINUOUS GROUPS and REPRESENTATIONS 
11.1 Definition of a Group 
11.1.1 Terminology 
11.2 Infinitesimal Ring or Lie Algebra 
11.3 Lie Algebra of the Rotation Group R(3) 
11.3.1 Another Approach to TR(3) 
11.4 Group Invariants 
11.4.1 Lorentz Transformation 
11.5 Unitary Group in Two Dimensions: U(2) 
11.6 Special Unitary Group SU(2) 
11.7 Lie Algebra of sU(2) 
I I .  7.1 Another Approach to ‘SU(2) 
11.8 Lorentz Group and its Lie Algebra 
11.9 Group Representations 
1 I .  9.1 Schur ’s Lemma 
11.9.2 Group Character 
11.9.3 Unitary Representation 
11.10 Representations of R(3) 
1 I .  11 Spherical Harmonics and Representations of R(3) 
11.11.1 Angular Momentum in Quantum 
Mechanics 
202 
204 
205 
207 
208 
208 
209 
21 1 
213 
214 
21 5 
21 6 
223 
224 
224 
226 
227 
228 
231 
232 
234 
236 
237 
239 
24 1 
24 6 
24 7 
24 7 
248 
248 
249 
249 

CONTENTS 
xi 
11.11.2 Rotation of the Physical System 
11.11.3 Rotation Operator in Terms of the Euler 
11.11.4 Rotation Operator in Terms of the 
1 1.1 1.5 Eigenvalue Equations for L,, L k ,  and L2 
11.11.6 Generalized Fourier Expansion in 
11.11.7 Matrix Elements ofL,,Lv, and L, 
11.11.8 Rotation Matrices for the Spherical 
11.11.9 Evaluation of the di,m(,f?) Matrices 
11.19.10 Inverse of the d i r m ( p )  Matrices 
11.11.11 Differential Equation for dk,m(/3) 
11.11.12 Addition Theorem for Spherical 
11.11.13 Determination of I, in the Addition 
Angles 
Original Coordinates 
Spherical Harmonics 
Harmonics 
Harmonics 
Theorem 
11.12 Irreducible Representations of SU(2) 
11.13 Relation of SU(2) and R(3) 
11.14 Group Spaces 
11.14.1 Real Vector Space 
11.14.2 Inner Product Space 
11.14.3 Four- Vector Space 
11.14.4 Complex Vector Space 
11.14.5 Function Space and Hilbert Space 
11.14.6 Completeness of the Set of Eigenfunctions 
(urn (XI} 
11.15 Hilbert Space and Quantum Mechanics 
11.16 Continuous Groups and Symmetries 
11.16.1 One-Parameter Point Groups and Their 
11.16.2 Transformation of Generators and 
11.16.3 The Case of Multiple Parameters 
11.16.4 Action of Generators on Functions 
1 1.16.5 Infinitesimal Transformation of 
Derivatives: Extension of Generators 
11.16.6 Symmetries of Differential Equations 
Generators 
Normal Forms 
250 
251 
251 
255 
255 
257 
258 
260 
261 
262 
264 
266 
268 
269 
272 
272 
273 
274 
274 
274 
275 
276 
277 
278 
279 
281 
281 
282 
285 
Problems 
288 

xi; 
CONTENTS 
12 COMPLEX VARIABLES and FUNCTIONS 
12.1 Complex Algebra 
12.2 Complex Functions 
12.3 Complex Derivatives and Analytic Functions 
12.3. I Analytic Functions 
12.3.2 Harmonic Functions 
12.4.1 Conformal Mappings 
12.4.2 Electrostatics and Conformal Mappings 
12.4.3 Fluid Mechanics and Conformal Mappings 
12.4.4 Schwarz- Christ0 ffel Trans formations 
Problems 
12.4 Mappings 
13 COMPLEX INTEGRALS and SERIES 
13.1 Complex Integral Theorems 
13.2 Taylor Series 
13.3 Laurent Series 
13.4 Classification of Singular Points 
13.5 Residue Theorem 
13.6 Analytic Continuation 
13.7 Complex Techniques in Taking Some Definite 
Integrals 
13.8 Gamma and Beta Functions 
13.8.1 Gamma Function 
13.8.2 Beta Function 
13.8.3 Useful Relations of the Gamma Functions 
13.8.4 Incomplete Gamma and Beta Functions 
13.9 Cauchy Principal Value Integral 
13.10 Contour Integral Representations of Some Special 
Functions 
13.10.1 Legendre Polynomials 
13.10.2 Laguerre Polynomials 
Problems 
14 FRA CTIO N A  L DERIVATIVES and INTEGRA LS: 
“DIFFER INTEGR A LS” 
14.1 Unified Expression of Derivatives and Integrals 
14.1.1 Notation and Definitions 
14.1.2 The nth Derivative of a Function 
293 
293 
295 
296 
297 
299 
300 
313 
314 
318 
322 
329 
335 
335 
339 
340 
34 7 
34 7 
349 
352 
360 
360 
362 
364 
364 
365 
369 
369 
371 
373 
379 
381 
381 
382 

CON TENTS 
xiii 
14.2.3 Successive Integrals 
384 
14.1.4 Unification of Derivative and Integral 
Operations for Integer Orders 
385 
14.2 Differint egrals 
385 
14.2.1 Griinwald’s Definition of Differintegrals 
385 
14.2.2 Riemann-Liouville Definition of Differintegrals 
387 
14.3 Other Definitions of Diflerintegrals 
390 
14.3.1 Cauchy Integral Formula 
390 
14.3.3 Diflerintegrals via Laplace Transforms 
396 
14.3.2 Ri emann Formula 
395 
14.4 Properties of Differintegrals 
399 
14.4.1 Linearity 
399 
14.4.2 Homogeneity 
399 
14.4.3 Scale Transformation 
400 
14.4.4 Differintegral of a Series 
400 
14.4.5 Composition of Diflerintegrals 
4 00 
14.4.6 Leibniz’s Rule 
407 
14.4.7 Right- and Left-Handed Diflerintegrals 
407 
14.4.8 Dependence on the Lower Limit 
4 08 
14.5 Differintegrals of Some Functions 
4 09 
14.5.1 Differintegral of a Constant 
409 
14.5.2 Differintegral of [x - u] 
410 
14.5.3 Differintegral of 
[x -u]p ( p  > -1) 
411 
14.5.4 Differintegral of [I -XI* 
412 
14.5.5 Diflerintegral of exp( fx) 
412 
14.5.6 Differintegral of In(x) 
412 
14.6 Mathematical Techniques with Differintegrals 
413 
14.6.1 Laplace Transform of Differintegrals 
413 
14.6.2 Extraordinary Diflerential Equations 
427 
14.6.3 Mittag-LefJler Functions 
418 
14.6.4 Semidifferential Equations 
419 
14.5.7 Some Semiderivatives and Semi-integrals 
413 
14.6.5 Evaluating Definite Integrals by Differintegrals 
14.6.6 Evaluation of Sums of Series by 
14.6.7 Special Functions Expressed as Diflerintegrals 
421 
Differint egrals 
423 
424 

xiv 
CONTENTS 
14.7 Applications of Diflerintegrals in Science and 
Engineering 
424 
14.7.2 Fractional Fokker-Planck Equations 
427 
Problems 
429 
14.7.1 Continuous Time Random Walk (CTRW) 424 
15 INFINITE SERIES 
431 
15.1 Convergence of Infinite Series 
431 
15.2 Absolute Convergence 
432 
15.3 Convergence Tests 
433 
15.3.1 Comparison Test 
433 
15.3.2 Ratio Test 
433 
15.3.3 Cuuchy Root Test 
433 
15.3.4 Integral Test 
434 
15.3.5 Raabe Test 
435 
15.3.6 Cauchy Theorem 
435 
15.3.7 Gauss Test and Legendre Series 
436 
15.3.8 Alternating Series 
439 
15.4 Algebra of Series 
439 
15.4.1 Rearrangement of Series 
440 
15.5 Useful Inequalities About Series 
442 
15.6 Series of Functions 
442 
15.6.1 Uniform Convergence 
443 
15.6.2 Weierstrass M-Test 
443 
15.6.3 Abel Test 
444 
15.7 Taylor Series 
445 
15.7. I Maclaurin Theorem 
446 
15.7.2 Binomial Theorem 
44 7 
Variables 
44s 
15.8 Power Series 
449 
15.8.1 Convergence of Power Series 
450 
15.8.2 Continuity 
450 
Series 
450 
15.8.4 Uniqueness Theorem 
451 
15.8.5 Inversion of Power Series 
451 
15.9 Summation of Infinite Series 
452 
15.6.4 Properties of Uniformly Convergent Series 445 
15.7.3 Taylor Series for Functions with Multiple 
15.8.3 Differentiation and Integration of Power 

CONTENTS 
xv 
15.9.1 Bernoulli Polynomials and Their 
Properties 
452 
15.9.2 Euler-Maclaurin Sum Formula 
454 
15.9.3 Using Residue Theorem to Sum Infinite 
Series 
458 
15.9.4 Evaluating Sums of Series by Digerintegrals 
4 61 
15.9.5 Asymptotic Series 
4 62 
15.10 Divergent Series in Physics 
4 65 
15.10.1 Casimir Eflect and Renormalization 
4 65 
15.10.2 Casimir Egect and MEMS 
468 
15.11 Infinite Products 
4 68 
15.11.1 Sine, Cosine, and the Gamma Functions 
470 
Problems 
4 72 
1 6 INTEGRAL T R A  NSFORMS 
4 77 
16. 1 Some Commonly Encountered Integral Transforms 
4 78 
16.2 Derivation of the Fourier Integral 
16.2.1 Fourier Series 
16.2.2 Dirac-Delta Function 
16.3 Fourier and Inverse Fourier Transforms 
16.3.1 Fourier Sine and Cosine Transforms 
16.3.2 Fourier Transform of a Derivative 
16.3.3 Convolution Theorem 
16.3.4 Existence of Fourier Transforms 
16.3.5 Fourier Transforms in Three Dimensions 
16.4 Some Theorems on Fourier Transforms 
16.5 Laplace Transforms 
16.6 Inverse Laplace Transforms 
16.6.1 Bromwich Integral 
16.6.2 Elementary Laplace Transforms 
16.6.3 Theorems About Laplace Transforms 
16.6.4 Method of Partial Fractions 
16.7 Laplace Transform of a Derivative 
16.7.1 Laplace Transforms in n Dimensions 
16.8 Relation Between Laplace and Fourier Transforms 
51 1 
16.9 Mellin Transforms 
4 79 
4 79 
481 
481 
482 
484 
485 
486 
486 
487 
490 
491 
492 
492 
494 
501 
503 
51 1 
51 2 

xvi 
CONTENTS 
Problems 
17 VARIATIONAL ANALYSIS 
17.1 Presence of One Dependent and One Independent 
Variable 
17.1.1 Euler Equation 
17.1.2 Another Form of the Euler Equation 
17.1.3 Applications of the Euler Equation 
17.2 Presence of More Than One Dependent Variable 
17.3 Presence of More Than One Independent 
Variable 
17.4 Presence of More Than One Dependent and 
Independent Variables 
17.5 Presence of Higher-Order Derivatives 
17.6 Isoperimetric Problems and the Presence of 
Constraints 
17.7 Application to Classical Mechanics 
17,8 Eigenvalue Problem and Variational Analysis 
17.9 Rayleigh-Ritz Method 
Problems 
18 INTEGRAL EQUATIONS 
18.1 Classification of Integral Equations 
18.2 Integral and Differential Equations 
18.3 How to Convert Some Differential Equations 
into Integral Equations 
18.4 How to Convert Some Integral Equations into 
Differen tial Equations 
18.5 Solution of Integral Equations 
18.5.1 Method of Successive Iterations: 
Neumann Series 
18.5.2 Error Calculation in Neumann Series 
512 
51 7 
518 
518 
520 
520 
523 
524 
526 
527 
529 
533 
535 
539 
543 
54 7 
548 
548 
550 
552 
553 
554 
556 
18.5.3 Solution for the Case of Separable Kernels 556 
18.5.4 Solution of Integral Equations by Integral 
18.6 Integral Equations and Eigenvalue Problems 
(Hilbert-Schmidt Theory) 
560 
18.6.1 Eigenvalues Are Real for Hermitian 
Ope rat o rs 
560 
18.6.2 Orthogonality of Eigenfunctions 
562 
Transforms 
559 

CONTENTS 
18.6.3 Completeness of the Eigenfunction Set 
Kernels 
Problems 
18.7 Eigenvalue Problem for the Non-Hermitian 
19 GREEN’S FUNCTIONS 
19.1 Time-Independent Green’s Functions 
19.1.1 Green’s Functions in One Dimension 
19.1.2 Abel’s Formula 
19.1.3 How to Construct a Green’s Function 
19.1.4 The Differential Equation That the 
Green’s Function Satisfies 
19.1.5 Single-Point Boundary Conditions 
19.1.6 Green’s Function for the Operator d2/dx2 
19.1.7 Green’s Functions for Inhomogeneous 
Boundary Conditions 
19.1.8 Green’s Functions and the Eigenualue 
Problems 
19.1.9 Green’s Function for the Helmholtz 
Equation in One Dimension 
19.1.10 Green’s Functions and the Dirac-Delta 
Function 
19.1.11 Green’s Function for the Helmholtz 
Equation for All Space- Continuum Limit 
19.1.12 Green’s Function for the Helmholtz 
Equation in Three Dimensions 
19.1.13 Green’s Functions in Three Dimensions 
with a Discrete Spectrum 
19.1.14 Green’s Function for the Laplace Operator 
Inside a Sphere 
19.1.15 Green’s Functions for the Helmholtz 
Equation for All Space-Poisson and 
Schrodinger Equations 
19.1.16 General Boundary Conditions and 
Applications to Electrostatics 
19.2.1 Green’s Functions with First-Order Time 
Dependence 
19.2.2 Propagators 
19.2 Time-Dependent Green’s Functions 
xvii 
562 
564 
565 
567 
567 
567 
569 
569 
572 
572 
573 
575 
579 
582 
583 
584 
593 
594 
596 
597 
603 
606 
606 
609 
19.2.3 Compounding Propagators 
609 

xviii 
CONTENTS 
19.2.4 Propagator for the Digusion Equation 
19.2.5 Propagator for the Digusion Equation in 
19.2.6 Green’s Functions in the Presence of 
19.2.7 Green’s Function for the Schrodinger 
19.2.8 Green’s Function for the Schrodinger 
19.2.9 Second-Order Time-Dependent Green’s 
19.2.10 Propagators for the Scalar Wave 
19.2.11 Advanced and Retarded Green’s Functions 
19.2.12 Advanced and Retarded Green’s Functions 
Problems 
with Periodic Boundary Conditions 
the Continuum Limit 
Sources or Interactions 
Equation for Free Particles 
Equation in the Presence of Interactions 
Functions 
Equation 
for the Scalar Wave Equation 
20 GREEN’S FUNCTIONS and PATH INTEGRALS 
20.1 Brownian Motion and the Digusion Problem 
20.2 Wiener Path Integral Approach to Brownian 
Motion 
20.3 The Feynman-Kac Formula and the Perturbative 
Solution of the Bloch Equation 
20.4 Derivation of the Feynman-Kac Formula 
20.5 Interpretation of V ( x )  in the Bloch Equation 
20.6 Methods of Calculating Path Integrals 
20.6.1 Method of Time Slices 
20.6.2 Evaluating Path Integrals with the ESKC 
20.6.3 Path Integrals by the Method of Finite 
20.6.4 Path Integrals by the “Semiclassical” 
20.7 Feynman Path Integral Formulation of Quantum 
Relation 
Elements 
Method 
Mechanics 
20.7.1 Schrodinger Equation for a Free Particle 
20.7.2 Schrodinger Equation in the Presence of 
Interactions 
20.8 Feynman Phase Space Path Integral 
61 0 
61 1 
61 3 
61 5 
61 5 
61 6 
61 8 
621 
624 
626 
633 
633 
635 
64 9 
650 
650 
655 
655 
658 
659 

CONTENTS 
xix 
20.9 Feynman Phase Space Path Integral in 
the Presence of Quadratic Dependence on 
Momentum 
660 
Problems 
663 
References 
Index 
665 
669 

This Page Intentionally Left Blank

Preface 
Courses on mathematical methods of physics are among the essential courses 
for graduate programs in physics, which are also offered by most engineering 
departments. Considering that the audience in these coumes comes from all 
subdisciplines of physics and engineering, the content and the level of math- 
ematical formalism has to be chosen very carefully. Recently the growing in- 
terest in interdisciplinary studies has brought scientists together from physics, 
chemistry, biology, economy, and finance and has increased the demand for 
these courses in which upper-level mathematical techniques are taught. It is 
for this reason that the mathematics departments, who once overlooked these 
courses, are now themselves designing and offering them. 
Most of the available books for these courses are written with theoretical 
physicists in mind and thus are somewhat insensitive to the needs of this new 
multidisciplinary audience. Besides, these books should not only be tuned 
to the existing practical needs of this multidisciplinary audience but should 
also play a lead role in the development of new interdisciplinary science by 
introducing new techniques to students and researchers. 
About the Book 
We give a coherent treatment of the selected topics with a style that makes 
advanced mathematical tools accessible to a multidisciplinary audience. The 
book is written in a modular way so that each chapter is actually a review of 
mi 

mii 
PREFACE 
its subject and can be read independentIy. This makes the book very useful 
as a reference for scientists. We emphasize physical motivation and the mul- 
tidisciplinary nature of the methods discussed. 
The entire book contains enough material for a three-semester course meet- 
ing three hours a week. However, the modular structure of the book gives 
enough flexibility to adopt the book for several different advanced undergrad- 
uate and graduatelevel courses. Chapter 1 is a philosophical prelude about 
physics, mathematics, and mind for the interested reader. It is not a part 
of the curriculum for courses on mathematical methods of physics. Chapters 
2-8, 12, 13 and 15-19 have been used for a tw+semester compulsory gradu- 
ate course meeting three hours a week. Chapters 16-20 can be used for an 
introductory graduate course on Green’s functions. For an upper-level un- 
dergraduate course on special functions, colleagues have used Chapters 1-8. 
Chapter 14 on fractional calculus can be expanded into a one-term elective 
course supported by projects given to students. Chapters 2-11 can be used 
in an introductory graduate course, with emphasis given to Chapters 8-11 
on Stunn-Liouville theory, factorization method, coordinate transformations, 
general tensors, continuous groups, Lie algebras, and representations. 
Students are expected to be familiar with the topics generally covered dur- 
ing the first three years of the science and engineering undergraduate curricu- 
lum. These basically comprise the contents of the books Advanced Calculus by 
Kaplan, Introductory Complex Analysis by Brown and Churchill, and Difler- 
ential Equations by Ross, or the contents of books like Mathematicab Methods 
in Physical Sciences by Boas, Mathematical Methods: for Students of Physics 
and Related Fields by Hassani, and Essential Mathematical Methods for Physi- 
cists by Arfken and Weber. Chapters (10 and 11) on coordinates, tensors, and 
groups assume that the student has already seen orthogonal transformations 
and various coordinate systems. These are usually covered during the third 
year of the undergraduate physics curriculum at the level of Classical Me- 
chanics by Marion or Theoreticab Mechanics by Bradbury. For the sections 
on special relativity (in Chapter 10) we assume that the student is familiar 
with basic special relativity, which is usually covered during the third year 
of undergraduate curriculum in modern physics courses with text books like 
Concepts of Modern Physics by Beiser. 
Three very interesting chapters on the method of factorization, fractional 
calculus, and path integrals are included for the first time in a text book on 
mathematical methods. These three chapters are also extensive reviews of 
these subjects for beginning researchers and advanced graduate students. 
Summary of the Book 
In Chapter 1 we start with a philosophical prelude about physics, mathemat- 
ics, and mind. 
In Chapters 2-6 we present a detailed discussion of the most frequently 

PREFACE 
xviii 
encountered special functions in science and engineering. This is also very 
timely, because during the first year of graduate programs these functions 
are used extensively. We emphasize the fact that certain second-order par- 
tial differential equations are encountered in many different areas of science, 
thus allowing one to use similar techniques. First we approach these partial 
differential equations by the method of separation of variables and reduce 
them to a set of ordinary differential equations. They are then solved by the 
method of series, and the special functions are constructed by imposing appro- 
priate boundary conditions. Each chapter is devoted to a particular special 
function, where it is discussed in detail. Chapter 7 introduces hypergeometric 
equation and its solutions. They are very useful in parametric representations 
of the commonly encountered second-order differential equations and their so- 
lutions. Finally our discussion of special functions climaxes with Chapter 8, 
where a systematic treatment of their common properties is given in terms of 
the Sturm-Liouville theory. The subject is now approached as an eigenvalue 
problem for second-order linear differential operators. 
Chapter 9 is one of the special chapters of the book. It is a natural extension 
of the chapter on Sturm-Liouville theory and approaches second-order differ- 
ential equations of physics and engineering from the viewpoint of the theory 
of factorization. After a detailed analysis of the basic theory we discuss spe- 
cific cases. Spherical harmonics, Laguerre polynomials, Hermite polynomials, 
Gegenbauer polynomials, and Bessel functions are revisited and studied in 
detail with the factorization method. This method is not only an interesting 
approach to solving Sturm-Liouville systems, but also has deep connections 
with the symmetries of the system. 
Chapter 10 presents an extensive treatment of coordinates, their transfor- 
mations, and tensors. We start with the Cartesian coordinates, their trans- 
formations, and Cartesian tensors. The discussion is then extended to general 
coordinate transformations and general tensors. We also discuss Minkowski 
spacetime, coordinate transformations in spacetime, and four-tensors in de- 
tail. We also write Maxwell’s equations and Newton’s dynamical theory in 
covariant form and discuss their transformation properties in spacetime. 
In Chapter 11 we discuss continuous groups, Lie algebras, and group rep- 
resentations. Applications to the rotation group, special unitary group, and 
homogeneous Lorentz group are discussed in detail. An advanced treatment 
of spherical harmonics is given in terms of the rotation group and its repre 
sentations. We also discuss symmetry of differential equations and extension 
(prolongation) of generators. 
Chapters 12 and 13 deal with complex analysis. We discuss the theory of 
analytic functions, mappings, and conformal and Schwarz-Christoffel trans- 
formations with interesting examples like the fringe effects of a parallel plate 
capacitor and fluid flow around an obstacle. We also discuss complex inte- 
grals, series, and analytic continuation along with the methods of evaluating 
some definite integrals. 
Chapter 14 introduces the basics of fractional calculus. After introducing 

xxiv 
PREFACE 
the experimental motivation for why we need fractional derivatives and inte- 
grals, we give a unified representation of the derivative and integral and extend 
it to fractional orders. Equivalency of different definitions, examples, prop 
erties, and techniques with fractional derivatives are discussed. We conclude 
with examples from Brownian motion and the Fokker-Planck equation. This 
is an emerging field with enormous potential and with applications to physics, 
chemistry, biology, engineering, and finance. For beginning researchers and 
instructors who want to add something new and interesting to their course, 
this self-contained chapter is an excellent place to start. 
Chapter 15 contains a comprehensive discussion of infinite series: tests of 
convergence, properties, power series, and uniform convergence along with 
the methods of evaluating sums of infinite series. An interesting section on 
divergent series in physics is added with a discussion of the Casimir effect. 
Chapter 16 treats integral transforms. We start with the general defini- 
tion, and then the two most commonly used integral transforms, Fourier and 
Laplace transforms, are discussed in detail with their various applications and 
techniques. 
Chapter 17 is on variational analysis. Cases with different numbers of de- 
pendent and independent variables are discussed. Problems with constraints, 
variational techniques in eigenvalue problems, and the Rayleigh-Ritz method 
are among other interesting topics covered. 
In Chapter 18 we introduce integral equations. We start with their classifi- 
cation and their relation to differential equations and vice versa. We continue 
with the methods of solving integral equations and conclude with the eigen- 
value problem for integral operators, that is, the Hilbert-Schmidt theory. 
In Chapter 19 (and 20) we present Green’s functions, and this is the second 
climax of this book, where everything discussed so far is used and their con- 
nections seen. We start with the timeindependent Green’s functions in one 
dimension and continue with three-dimensional Green’s functions. We discuss 
their applications to electromagnetic theory and the Schrijdinger equation. 
Next we discuss first-order time-dependent Green’s functions with applica- 
tions to diffusion problems and the timedependent Schrodinger equation. We 
introduce the propagator interpretation and the compounding of propagators. 
We conclude this section with second-order time-dependent Green’s functions, 
and their application to the wave equation and discuss advanced and retarded 
soh tions. 
Chapter 20 is an extensive discussion of path integrals and their relation 
to Green’s functions. During the past decade or so path integrals have found 
wide range of applications among many different fields ranging from physics 
to finance. We start with the Brownian motion, which is considered a pro- 
totype of many different processes in physics, chemistry, biology, finance etc. 
We discuss the Wiener path integral approach to Brownian motion. After the 
Feynman-Kac formula is introduced, the perturbative solution of the Bloch 
equation is given. Next an interpretation of V ( z )  in the Bloch equation is 
given, and we continue with the methods of evaluating path integrals. We 

PREFACE 
xxv 
also discuss the Feynman path integral formulation of quantum mechanics 
along with the phase space approach to Feynman path integrals. 
Story of the Book 
Since 1989, I have been teaching the graduate level ‘Methods of Mathematical 
Physics I & 11’ courses at the Middle East Technical University in Ankara. 
Chapters 2-8 with 12 and 13 have been used for the first part and Chapters 
15-19 for the second part of this course, which meets three hours a week. 
Whenever possible I prefer to introduce mathematical techniques through 
physical applications. Examples are often used to extend discussions of spe- 
cific techniques rather than as mere exercises. Topics are introduced in a 
logical sequence and discussed thoroughly. Each sequence climaxes with a 
part where the material of the previous chapters is unified in terms of a gen- 
eral theory, as in Chapter 8 (and 9) on the Sturm-Liouville theory, or with a 
part that utilizes the gains of the previous chapters, as in Chapter 19 (and 
20) on Green’s functions. Chapter 9 is on factorization method, which is a 
natural extension of our discussion on the Sturm-Liouville theory. It also 
presents a different and advanced treatment of special functions. Similarly, 
Chapter 20 on path integrals is a natural extension of our chapter on Green’s 
functions. Chapters 10 and 11 on coordinates, tensors, and continuous groups 
have been located after Chapter 9 on the Sturm-Liouville theory and the fac- 
torization method. Chapters 12 and 13 are on complex techniques, and they 
are self-contained. Chapter 14 on fractional calculus can either be integrated 
into the curriculum of the mathematical methods of physics courses or used 
independently. 
During my lectures and first reading of the book I recommend that readers 
view equations as statements and concentrate on the logical structure of the 
discussions. Later, when they go through the derivations, technical details 
become understood, alternate approaches appear, and some of the questions 
are answered. Sufficient numbers of problems are given at the back of each 
chapter. They are carefully selected and should be considered an integral part 
of the learning process. 
In a vast area like mathematical methods in science and engineering, there 
is always room for new approaches, new applications, and new topics. In fact, 
the number of books, old and new, written on this subject shows how dynamic 
this field is. Naturally this book carries an imprint of my style and lectures. 
Because the main aim of this book is pedagogy, occasionally I have followed 
other books when their approaches made perfect sense to me. Sometimes 
I indicated this in the text itself, but a complete list is given at the back. 
Readers of this book will hopefully be well prepared for advanced graduate 
studies in many areas of physics. In particular, as we use the same terminol- 
ogy and style, they should be ready for full-term graduate courses based on 
the books: The Fractional Calculus by Oldham and Spanier and Path Inte- 

xxvi 
PREFACE 
gmls in Physics, Volumes I and 11 by Chaichian and Demichev, or they could 
jump into the advanced sections of these books, which have become standard 
references in their fields. 
I recommend that students familiarize themselves with the existing litera- 
ture. Except for an isolated number of instances I have avoided giving refer- 
ences within the text. The references at the end should be a good first step in 
the process of meeting the literature. In addition to the references at the back, 
there are also three websites that are invaluable to students and researchers: 
For original research, http://lanl.arxiv.org/ and the two online encyclope- 
dias: http://en.wikipedia.org and http://scienceworld.wolfram.com/ are very 
useful. For our chapters on special functions these online encyclopedias are 
extremely helpful with graphs and additional information. 
A precursor of this book (Chapters 1-8, 12, 13, and 1519) was published in 
Turkish in 2000. With the addition of two new chapters on fractional calculus 
and path integrals, the revised and expanded version appeared in 2004 as 440 
pages and became a widely used text among the Turkish universities. The pos- 
itive feedback from the Turkish versions helped me to prepare this book with a 
minimum number of errors and glitches. For news and communications about 
the book we will use the website http://www.physics.metu.edu.tr/- bayin, 
which will also contain some relevant links of interest to readers. 
S. BAYIN 
OD TU 
Ankam/TURKE Y 
April 2006 

Acknowledgments 
I would like to pay tribute to all the scientists and mathematicians whose 
works contributed to the subjects discussed in this book. I would also like 
to compliment the authors of the existing books on mathematical methods of 
physics. I appreciate the time and dedication that went into writing them. 
Most of them existed even before I was a graduate student. I have benefitted 
from them greatly. I am indebted to Prof. K.T. Hecht of the University of 
Michigan, whose excellent lectures and clear style had a great influence on me. 
I am grateful to Prof. P.G.L. Leach for sharing his wisdom with me and for 
meticulously reading Chapters 1 and 9 with 14 and 20. I also thank Prof. N. 
K. Pak for many interesting and stimulating discussions, encouragement, and 
critical reading of the chapter on path integrals. I thank Wiley for the support 
by a grant during the preparation of the camera ready copy. My special 
thanks go to my editors at Wiley, Steve Quigley, Susanne Steitz, and Danielle 
Lacourciere for sharing my excitement and their utmost care in bringing this 
book into existence. 
I finally thank my wife, Adalet, and daughter, Sumru, for their endless 
support during the long and strenuous period of writing, which spanned over 
several years. 
3.S.B. 
xxvii 

This Page Intentionally Left Blank

NATURE and 
MATHEMATICS 
The most incomprehensible thing about this universe is that it is comprehensible 
- 
Albert Einstein 
When man first opens his eyes into this universe, he encounters an endless 
variety of events and shivers as he wonders how he will ever survive in this 
enormously complex system. However, as he contemplates he begins to realize 
that the universe is not hostile and there is some order among all this diversity. 
As he wanders around, he inadvertently kicks stones on his path. As the 
stones tumble away, he notices that the smaller stones not only do not hurt his 
feet, but also go further. Of course, he quickly learns to avoid the bigger ones. 
The sun, to which he did not pay too much attention at first, slowly begins to 
disappear; eventually leaving him in cold and dark. At first this scares him 
a lot. However, what a joy it must be to witness the sun slowly reappearing 
in the horizon. As he continues to explore, he realizes that the order in this 
universe is also dependable. Small stones, which did not hurt him, do not hurt 
him another day in another place. Even though the sun eventually disappears, 
leaving him in cold and dark, he is now confident that it will reappear. In 
time he learns to live in communities and develops languages to communicate 
with his fellow human beings. Eventually the quality and the number of 
observations he makes increase. In fact, he even begins to undertake projects 
that require careful recording and interpretation of data that span over several 
generations. As in Stonehenge he even builds an agricultural computer to find 
the crop times. A similar version of this story is actually repeated with every 
newborn. 
1 

2 
NATURE AND MATHEMATICS 
For man to understand nature and his place in it has always been an in- 
stinctive desire. Along this endeavour he eventually realizes that the everyday 
language developed to communicate with his fellow human beings is not suf- 
ficient. For further understanding of the law and order in the universe, a 
new language, richer and more in tune with the inner logic of the universe, 
is needed. At this point physics and mathematics begin to get acquainted. 
With the discovery of coordinate systems, which is one of the greatest con- 
structions of the free human mind, foundations of this relation become ready. 
Once a coordinate system is defined, it is possible to reduce all the events in 
the universe to numbers. Physical processes and the law and order that ex- 
ists among these events can now be searched among these numbers and could 
be expressed in terms of mathematical constructs much more efficiently and 
economically. From the motion of a stone to the motions of planets and stars, 
it can now be understood and expressed in terms of the dynamical theory of 
Newton: 
87 
T = m -  dt2 
and his law of gravitation 
Newton’s theory is full of the success stories that very few theories will ever 
have for years to come. Among the most dramatic is the discovery of Nep 
tune. At the time small deviations from the calculated orbit of Uranus were 
observed. At first the neighboring planets, Saturn and Jupiter, were thought 
to be the cause. However, even after the effects of these planets were sub- 
tracted, a small unexplained difference remained. Some scientists questioned 
even the validity of Newton’s theory. However, astronomers, putting their 
trust in Newton’s theory, postulated the existence of another planet as the 
source of these deviations. From the amount of the deviations they calculated 
the orbit and the mass of this proposed planet. They even gave a name to it: 
Neptune. Now the time had come to observe this planet. When the telescopes 
were turned into the calculated coordinates: Hello! Neptune was there. In 
the nineteenth century, when Newton’s theory was joined by Maxwell’s the- 
ory of electromagnetism, there was a time when even the greatest minds like 
Bertrand Russell began to think that physics might have come to an end, that 
is, the existing laws of nature could in principle explain all physical phenom- 
ena. 
Actually, neither Newton’s equations nor Maxwell’s equations are laws in 
the strict sense. They are based on some assumptions. Thus it is proba- 
bly more appropriate to call them theories or models. We frequently make 
assumptions in science. Sometimes in order to concentrate on a special but 
frequently encountered case, we keep some of the parameters constant to avoid 

MATHEMATICS AND NATURE 
3 
unnecessary complications. At other times, because of the complexity of the 
problem, we restrict our treatment to certain domains like small velocities, 
high temperatures, weak fields, etc. However, the most important of all are 
the assumptions that sneak into our theories without our awareness. Such as- 
sumptions are actually manifestations of our prejudices about nature. They 
come so naturally to us that we usually do not notice their presence. In fact, it 
sometimes takes generations before they are recognized as assumptions. Once 
they are identified and theories are reformulated, dramatic changes take place 
in our understanding of nature. 
Toward the beginning of the twentieth century the foundations of Newton’s 
dynamical theory are shaken by the introduction of new concepts like the 
waveparticle duality and the principle of uncertainty. It eventually gives way 
to quantum mechanics. Similarly, Galilean relativity gives way to the special 
theory of relativity when it is realized that there is an upper limit to velocities 
in nature, which is the speed of light. Newton’s theory of gravitation also gives 
way to Einstein’s theory of gravitation when it is realized that absolute space 
and flat geometry are assumptions valid only for slowly moving systems and 
near small masses. 
However, the development of science does not take place by leaving the 
successful theories of the past in desolation either. Yes, the wave-particle 
duality, the principle of uncertainty, and a new type of determinism are all es- 
sential elements of quantum mechanics, which are all new to Newton’s theory. 
However, it is also true that in the classical limit, fi -+ 0, quantum mechanics 
reduces to Newton’s theory and for many important physical and astronomi- 
cal phenomena, quantum mechanical treatment is not practical. In such cases 
Newton’s theory is still the economical theory to use. Similarly, even though 
there is an upper limit to velocity, for many practical problems speed of light 
can be taken as infinity, thus making Galilean relativity still useful. Even 
though Newton’s theory of gravitation has been replaced by Einstein’s t h e  
ory, for a large class of astronomical problems the curvature of spacetime can 
be neglected. For these problems Newton’s theory still remains an excellent 
working theory. 
1.1 MATHEMATICS AND NATURE 
As time goes on, the mathematical techniques and concepts used to under- 
stand nature develop and increase in number. Today we have been rather 
successful in representing physical processes in terms of mathematics, but one 
thing has never changed. Mathematics is a world of numbers, and, if we have 
to understand nature by mathematics, we have to transform it into numbers 
first. However, aside from integers all the other numbers are constructs of the 
free human mind. Besides, mathematics has a certain logical structure to it, 
thus implying a closed or complete system. Considering that our knowledge 
of the universe is far too limited to be understood by logic, one naturally 

4 
NATURE AND MATHEMATICS 
wonders why mathematics is so successful as a language. What is the secret 
of this mysterious relation between physics and mathematics? 
In 1920 Hilbert suggested that mathematics be formulated on a solid and 
complete logical foundation such that all mathematics can be derived from 
a finite and consistent system of axioms. This philosophy of mathematics 
is usually called formalism. In 1931 Gijdel shattered the foundations of the 
formal approach to mathematics with his famous incompleteness theorem. 
This theorem not only showed that Hilbert’s goal is impossible but also proved 
to be only the first in a series of deep and counterintuitive statements about 
rigor and provability of mathematics. Could Godel’s incompleteness theorem 
be the source of this mysterious relation between mathematics and nature? 
It is true that certain mathematical models have been rather successful in 
expressing the law and order in the universe. However, this does not mean 
that all possible mathematical models and concepts will somehow find a place 
in science. If we could have extended our understanding of nature by logi- 
cal extensions of the existing theories, physics would have been rather ea5y. 
Sometimes physicists are almost hypnotized by the mathematical beauty and 
the sophistication of their theories, so that they begin to lose contact with 
nature. We should not get upset if it happens that nature has not preferred 
our way. 
1.2 LAWS OF NATURE 
At first we had only the dynamical theory of Newton and his theory of gravi- 
tation. Then came Maxwell’s theory of electromagnetism. After the discovery 
of quantum mechanics in the early twentieth century, there was a brief period 
when it was thought that everything in nature could in principle be explained 
in terms of the three elementary particles; electron, proton, and neutron, and 
the electromagnetic and gravitational interactions between them. Not for 
long; The discovery of strong and weak interactions along with a prolifera- 
tion of new particles complicated the picture. Introduction of quarks as the 
new elementary constituents of these particles did not help, either. Today 
string theorists are trying to build a theory of everything in which all known 
interactions are unified. 
What is a true law of nature? In my opinion genuine laws of nature are 
relatively simple and in general expressed as inequalities like the uncertainty 
principle: 
AxAp 2 h 
and the second law of entropy: 
SS( total entropy of the universe) 2 0. 
(1.4) 
Others, which are expressed in terms of equalities, are theories or models 
based on certain assumptions and subject to change in time. 

MATHEMATICS AND MIND 
5 
1.3 
MATHEMATICS AND MIND 
Almost, everywhere mathematics is a very useful and powerful language in 
expressing the law and order in the universe. However, mathematics is also 
a world of ideas, and these ideas occur as a result of some physical processes 
at the cellular and molecular level in our brain. Today not just our physical 
properties like the eye and hair colors but also the human psyche is thought to 
be linked to our genes. We have taken important strides in identifying parts 
of our genes that are responsible for certain properties. Research is ongoing 
in developing technologies that will allow to us to remove or replace parts 
of our genes that may represent a potential hazard to our health. Scientists 
are working on mechanisms to silence or turn off bad genes in a cell. This 
mechanism will eventually lead to the development of new medicines for p r e  
tecting cells from hostile genes and treating diseases. Even though we still 
have a long way to go, we have covered important distance in understanding 
and controlling our genetic code. 
To understand and codify ideas in terms of some basic physical processes 
naturally requires a significantly deeper level of understanding of our brain 
and its processes. If ideas could be linked to certain physical processes at the 
molecular and cellular level, then there could also exist a finite upper limit 
to the number of ideas, no matter how absurd they may be, that we could 
ever devise. This limit basically implies that one’s brain has a finite phase 
space, which allows only a finite number of configurations corresponding to 
ideas. This also means that there is an upper limit to all the mathematical 
statements, theorems, concepts, etc. that we could ever imagine. We simply 
cannot think of anything that requires a process that either violates some 
of the fundamental laws of nature or requires a brain with a larger phase 
space. A quick way to improve this limit is to have a bigger brain. In fact, 
to some extent nature has already utilized this alternative. It is evidenced 
in fossils that, as humans evolved, brain size increased dramatically. The 
average brain size of Homo habilis, who lived approximately 2 million years 
ago, was approximately 750 cc. Homo erectus, who lived 1.7-1 million years 
ago, averaged 900 cc in brain size. The modern human skull holds a brain of 
around 1400 cc. 
However, brain size and intelligence are only correlated loosely. A much 
more stringent limit to our mental capacity naturally comes from the inner 
efficiency of our brain. Research on subjects like brain stimulators, hard 
wiring of our brain, and mind reading machines are all aiming at a faster and 
much more efficient use of our brain. A better understanding of our brain 
may also bring a more efficient way of using our creativity, much needed at 
times of crisis or impasses, the working of which is now left to chance. The 
possibility of tracing ideas to their origins in terms of physical processes at 
the molecular and cellular level and also the possibility of codifying them with 
respect to some finite, probably small, number of key processes implies that 
the relation between mathematics and nature may actually work both ways. 

6 
NATURE AND MATHEMATICS 
1.4 IS MATHEMATICS THE ONLY LANGUAGE FOR NATURE? 
We have been extremely successful with mathematics in understanding and 
expressing the law and order in the universe. However, can there be other 
languages? Can the universe itself serve as its own language? It is known 
that intrinsically different phenomena occasionally satisfy similar mathemat- 
ical equations. For example, in two-dimensional electrostatic problems the 
potential satisfies 
where cfi is the electrostatic potential, p is the charge density, and EO is the 
constant permittivity of vacuum. Now consider an elastic sheet stretched 
over a cylindrical frame like a drum head with uniform tension T. If we push 
this sheet by small amounts, its displacement from its equilibrium position, 
u(z,y), satisfies 
where f(z,y) is 
the equation 
the applied force. If we make the identification 
all the electrostatics problems with infinite charged sheets, long parallel wires, 
or charged cylinders have a representation in terms of a stretched membrane. 
In fact, this method has been used to solve complex electrical problems. By 
pushing rods and bars at various heights against a membrane corresponding 
to the potentials of a set of electrodes, we can obtain the electric potential 
by simply reading the displacement of the membrane. The analogy can even 
be carried further. If we put little balls on the membrane, their motion is 
approximately the corresponding motion of electrons in the corresponding 
electric field. This method has actually been used to obtain the complicated 
geometry of many photomultipliers. 
The limitation of this method is that Equation (1.6) is valid only for small 
displacements of the membrane. Also, the difficulty in preparing a mem- 
brane with uniform tension restricts the accuracy. However, the beauty of the 
method is that we can find the solution of a complex boundary value problem 
without actually solving a partial differential equation. Note that even though 
we have not solved the boundary value problem explicitly, we have still used 
mathematics to link the two phenomena. 
Recently scientists have been intrigued by the uncanny similarity between 
the propagation of light in curved spacetime and the propagation of sound 
in uneven flow. Scientists are now trying to exploit these similarities to gain 

NATURE AND MANKIND 
7 
insight into the microscopic structure of spacetime. Even black holes have 
acoustic counterparts. Acoustic analogs of the Casimir effect, which is usu- 
ally introduced as a purely quantum mechanical phenomenon, are now being 
investigated with technological applications in mind. The development of fast 
computers has slowed the development of this approach. However, the fact 
that nature could also be its own language is something to keep in mind. 
1.5 
NATURE AND MANKIND 
What is our place in this universe? What is our role? Why does this universe 
exist? Man has probably asked questions like these since the beginning of time. 
Are we any closer to the answers? If we discover the theory of everything, 
will at least some of these questions be answered? Scientist or not, everybody 
has wondered about these issues. 
Let us now imagine a civilization the entire universe of which is all the 
existing novels. Members of this civilization are amazed by the events depicted 
in these novels and wonder about the reason behind all the drama and the 
intricate relations among the characters. One day, one of their scientists 
comes up with a model, claims that all these novels are composed of a finite 
number of words, and prepares a dictionary. They all get excited, and the 
experimentalists begin to search every sentence and every paragraph that they 
can find. In time a few additions and subtractions are made to this dictionary, 
but one thing does not change: Their universe is made up of a finite number 
of words. As they are happy with this theory, a new scientist comes along 
and claims that all these words in the dictionary and the novels themselves 
are actually made up of a small number of letters, numbers, and punctuation 
marks. After intense testing, this theory also finds enormous support and its 
author is hailed with their greatest honors. Naturally this story goes on and as 
the quality of their observations increases, they begin to discover grammatical 
rules. The rules of grammar are actually the laws of nature in this universe. It 
is clear that grammar rules alone cannot tell us why a novel is written, but it 
is not possible to understand a novel properly without knowing the grammar 
rules, either. 
As we said, scientist or not, everybody has wondered why this universe 
exists and what our place in this magnificent system is. Even though no 
simple answers exist, it is incredible that almost everybody has somehow 
come to a peaceful coexistence with such questions. What we should realize 
is that such questions do not have a single answer. With analogies like the 
one we just gave, one may only get a glimpse of one of the many facets of 
truth. Somebody else may come up with another analogy that may be as 
intriguing as this one. Starting from the success of simulation experiments it 
has been argued that the universe acts like a giant computer, where matter is 
its hardware and the laws of nature are its software. Now the question to be 
answered becomes: Who built this computer, and for what is it being used? 

This Page Intentionally Left Blank

LEGENDRE 
E UATION and 
P 8 L YNOMIA LS 
Many of the second-order partial differential equations of physics and engi- 
neering can be written as 
7% 
(z, y, z) + k2* (z, Y, z) = F (z, y, .) , 
(2.1) 
where k in general is a function of coordinates. 
equations are: 
Some examples for these 
1. If k and F (z, y, z )  are zero, Equation (2.1) becomes the Laplace equation 
v2* 
(x, 
y, z )  = 0, 
(2.2) 
which is encountered in many different areas of science like electrostatics, 
magnetostatics, laminar (irrotational) flow, surface waves, heat transfer, 
and gravitation. 
2. When the right-hand side of the Laplace equation is different from zero, 
we have the Poisson equation: 
v2* 
= F(z, y, z), 
(2.3) 
where F (2, y, z )  represents sources in the system. 
3. The Helmholtz wave equation is given as 
v2* 
(z, 
y, 2 )  * k@ (z, y, 2 )  = 0, 

10 
LEGENDRE EQUATION AND POLYNOMIALS 
where ko is a constant. 
4. Another important example is the timeindependent Schrodinger equa- 
tion 
where F ( z ,  y, z) in Equation (2.1) is zero and k is now given as 
All these equations are linear and second-order partial differential equa- 
tions. Separation of variables, Green's functions, and integral transforms are 
among the most frequently used techniques for obtaining analytic solutions. 
In addition to these there are also numerical techniques like Runge-Kutta. 
Appearance of similar differential equations in different areas of science al- 
lows one to adopt twhniques developed in one area into another. Of course, 
the variables and interpretation of the solutions will be very different. Also, 
one has to be aware of the fact that boundary conditions used in one area 
may not be appropriate for another. For example, in electrostatics charged 
particles can only move perpendicular to the conducting surfaces, whereas in 
laminar (irrotational) flow fluid elements follow the contours of the surfaces; 
thus even though the Laplace equation is to be solved in both cases, solutions 
obtained in electrostatics may not always have meaningful counterparts in 
laminar flow. 
2.1 
LEGENDRE EQUATION 
We now solve Equation (2.1) in spherical polar coordinates by using the 
method of separation of variables. We consider cases where k is only a function 
of the radial coordinate, and also we take F as zero. The time-independent 
Schrodinger Equation (2.5) written for central force problems, where 
(2.7) 
is an important example for such cases. We first separate T and the (@,+) 
variables and write the solution, 9 (T, @,+) , as 
This basically assumes that the radial dependence of the solution is indepen- 
dent of the (@,qt~) dependence and vice versa. Substituting this in Equation 

LEGENDRE EQUATION 
11 
(2.1) we get 
1 
-- 
I d  [r2-R(r)Y 
d 
(Q,q5)] + 2
2
 
[sinQ-R(r)Y 
a 
(8,+) 
r2dr 
dr 
r2 sin Q dQ 
ae 
(2.9) 
1 
82 
r2 sin2 Q 84’ 
+--R 
(r) Y (Q, 4) + k2 (r) R (r) Y (8,4) = 0. 
After multiplying the above equation by 
r2 
(2. lo) 
and collecting the (Q,4) dependence on the right-hand side we obtain 
Since r and (Q,4) are independent variables, this equation can be satisfied for 
all r and (Q, 4) only when both sides of the equation are equal to the same 
constant. We show this constant with A, which is also called the separation 
constant. Now Equation (2.11) reduces to the following two equations: 
(2.12) 
and 
(” ’) + XY (Q, 4) = 0. 
(2.13) 
sin 8 dQ [sin0 
dl9 
Equation (2.12) for R(r) is now an ordinary differential equation. We also 
separate the Q and the (b variables in Y (Q,4) as 
and call the new separation constant m2, and write 
(2.15) 
-- 
sin8 d [sin@%] +Xsin2Q= 
1 d2@(4) = m  
2 . 
0 (8) dd 
@(4) 
We now obtain the differential equations to be solved for 0 (Q) and 
(4) as 
dO (Q) 
d8 
+cosQsinQ- 
+ [Xsin2Q-m2] O(8) = 0 
sin2 Q- 
(2.16) 
d20 (0) 
d d 2  

12 
LEGENDRE EQUATION AND POLYNOMIALS 
and 
(2.17) 
In summary, using the method of separation of variables we have reduced the 
partial differential Equation (2.9) to three ordinary differential Equations, 
(2.12), (2.16), and (2.17). During this process two constant parameters, X 
and m, called the separation constants have entered into our equations, which 
so far have no restrictions on them. 
2.1.1 
In the above discussion the fact that we are able to separate the solution 
is closely related to our use of the spherical polar coordinates, which reflect 
the symmetry of the central potential best. If we had used the Cartesian 
coordinates, the potential would be given as V(z, y, z )  and the solution would 
not be separable, that is 
Method of Separation of Variables 
Q(Z,Y, 2) # x(z)Y(Y)w). 
Whether a given partial differential equation is separable or not is closely 
related to the symmetries of the physical system. Even though a proper dis- 
cussion of this point is beyond the scope of this book, we refer the reader to 
Stephani (p. 193) and suffice by saying that if a partial differential equation 
is not separable in a given coordinate system it is possible to check the ex- 
istence of a coordinate system in which it would be separable, and if such a 
coordinate system exists it is possible to construct it with the generators of 
the symmetries. 
Among the three ordinary differential Equations (2.12), (2.16), and (2.17), 
Equation (2.17) can be solved immediately with the general solution 
(4) = Aeim+ + Be-imd, 
(2.18) 
where m is still unrestricted. Using the periodic boundary condition 
' ( 4  + 2 r )  = '(41, 
(2.19) 
it is seen that m could only take integer values: O,&l, 3 ~ 2 ,  ... . Note that 
in anticipation of applications to quantum mechanics we have taken the two 
linearly independent solutions as e*im@. For other problems sin m& and cmm4 
is preferred. 
For the differential equation to be solved for 0 (Q) we define a new inde 
pendent variable 
= cOSe, 
(Q E [0,4, J: E [-1,1]) 
(2.20) 

SERIES SOLUTION OF THE LEGENDRE EQUATION 
13 
and write 
m2 
(2.21) 
(1 -x2) - 
d2Z (x) - 
x--]z(x)=o. 
dx2 
dx 
( 1 - 2 2 )  
For m = 0 this equation is called the Legendre equation, and for m # 0 it 
is known as the associated Legendre equation. 
2.2 
SERIES SOLUTION OF THE LEGENDRE EQUATION 
Starting with the 
m=O 
case we write the Legendre equation as 
d x 2  
dx 
(2.22) 
This has two regular singular points at x = f l .  Since these points are at the 
end points of our interval, using the Frobenius method we can try a series 
solution about 
x = o  
(2.23) 
as 
Substituting this into Equation (2.22) we get 
m 
We write the first two terms of first series in the above equation explicitly as 
and make the variable change 
k’ = k + 2, 
(2.27) 

14 
LEGENDRE EQUATION AND POLYNOMIALS 
to write Equation (2.25) as 
UQa (a - 1) zap2 + a1 (a + 1) 
00 
{ a k + 2  (k f 2  +(Y) ( k f  1 f a) - a k  [(k +a) ( k +  
1) - A]} = 0. 
k=O 
(2.28) 
From the uniqueness of power series this equation cannot be satisfied for all 
z, unless the coefficients of all the powers of 3: vanish simultaneously, which 
gives us the following relations among the coefficients: 
aoa (a - 1) = 0, 
UQ # 0, 
a] (a + 1) a = 0, 
(2.29) 
(2.30) 
(2.31) 
Equation (2.29), obtained by setting the coefficient of the lowest power of x 
to zero, is called the indicial equation. Assuming a0 # 0, the two roots of 
the indicial equation give the values of a as 
a = 0 and a = 1. 
(2.32) 
The remaining Equations (2.30) and (2.31) give us the recursion relation 
among the remaining coefficients. Starting with a = 1 we obtain 
, k = 0 , 1 , 2  .... 
(k + 1) ( k  + 2) - x 
( k  + 2) (k + 3) 
ak+2 = a k  
(2.33) 
For a = 1 Equation (2.30) implies 
a1 = 0, 
(2.34) 
hence all the remaining nonzero coefficients are obtained as 
(2 - 4 
a 2  = ao- 
6
’
 
(6 - 4 - o, 
a3 = a1- 
- 
12 
(2.35) 
(2.36) 
(12 - A )  
20 
l 
a4 = aq- 
(2.37) 

SERIES SOLUTION OF THE LEGENDRE EQUATION 
15 
This gives the series solution for a = 1 as 
Similarly for the cy = 0 value, Equations (2.29) and (2.30) @ve us 
a. # O  and a1 # O .  
(2.39) 
Now the recursion relation becomes 
k=O,1,2 ,.'., 
k ( k +  1) - A  
( k  + 1) ( k  + 2) ' 
a k i 2  = a k  
which gives the remaining nonzero coefficients as 
12 - x 
a5 = a3 ( T), 
(2.40) 
(2.41) 
Now the series solution for the cy = 0 value is obtained as 
The Legendre equation is a second-order linear ordinary differential equation, 
and in general it will have two linearly independent solutions. Since a0 and 
a1 take arbitraIy values, the solution for the a = 0 root also contains the 
solution for the cy = 1 root; hence the general solution can be written as 
Z(z)=C0[l- (;)x2- ($) 
( ! g ) z 4 + . . . ]  
where CO and Cl are two integration constants to be determined from the 
boundary conditions. These series are called the Legendre series. 

16 
LEGENDRE EQUATION AND POLYNOMIALS 
2.2.1 
Frobenius Method 
We have used the Frobenius method to find the Legendre series. A second- 
order linear homogeneous ordinary differential equation' with two linearly in- 
dependent solutions may be put in the form 
d2Y 
dY 
- 
+ P(x)- + Q(x) = 0. 
dx2 
dx 
If xo is no worse then a regular singular point, that is, if 
lim (z - zo)P(x) + finite 
(2.45) 
X'ZO 
and 
lim (z - ~co)~Q(z) 
+ finite, 
(2.46) 
2-10 
then we can seek a series solution of the form 
CO 
(2.47) 
Substituting this series into the above differential equation and setting the 
coefficient of the lowest power of (z - 20) with a0 # 0 gives us a quadratic 
equation for a called the indicia1 equation. For almost all the physically in- 
teresting cases the indicia1 equation has two real roots. This gives us the 
following possibilities for the two linearly independent solutions of the differ- 
ential equation (Ross): 
1. If the two roots (a1 > a2) differ by a noninteger, then the two linearly 
independent solutions are given as 
Y1 (z) = 1% - 20la1 xzo ak(z - XO)', 
a0 # 0 
and 
(2.48) 
2. If (al - 0 2 )  = N, 
where a1 > a2 and N is a positive integer, then the 
two linearly independent solutions are given as 
00 
y1 (z) = 12 - x0Ia1 c ak(z - ZO)', 
@I 
# 0, 
(2.49) 
k=O 
and 
00 
Y2(z) = tz - zoIQ2 
b ( 3 :  - Zo)' + cy~(z) 
In 12 - xo 1 , bo # 0. 
(2.50) 
k=O 

LEGENDRE POLYNOMIALS 
17 
The second solution contains a logarithmic singularity, where C is a constant 
that may or may not be zero. Sometimes a2 will contain both solutions; 
hence it is advisable to start with the smaller root with the hopes that it 
might provide the general solution. 
3. If the indicia1 equation has a double root, that is, a1 = a2, then the 
Frobenius method yields only one series solution. In this case the two linearly 
independent solutions can be taken as 
(2.51) 
where the second solution diverges logarithmically as z -+ zo. In the presence 
of a double root the Frobenius method is usually modified by taking the two 
linearly independent solutions as 
In all these cases the general solution is written as 
(2.53) 
2.3 LEGENDRE POLYNOMIALS 
Legendre series are convergent in the interval (-1,l). This can easily be 
checked by the ratio test. To see how they behave at the end points, z = =tl, 
we take the k --f 03 limit of the recursion relation, Equation (2.40), to obtain 
ak 
(2.54) 
For sufficiently large k values this means that both series behave as 
z(%) 
= . . . + akzk (1 f X 2  + z4 + . . .) . 
(2.55) 
The series inside the parentheses is nothing but the geometric series: 
(2.56) 
Hence both of the Legendre series diverge at the end points as 1/(1 - z2). 
However, the end points correspond to the north and the south poles of a 

18 
LEGENDRE EQUATION AND POLYNOMIALS 
sphere. Because the problem is spherically symmetric, there is nothing special 
about these points. Any two diametrically opposite points can be chosen to 
serve as the end points. Hence we conclude that the physical solution should 
be finite everywhere on a sphere. To avoid the divergence at the end points, we 
terminate the Legendre series after a finite number of terms. We accomplish 
this by restricting the separation constant X to integer values given by 
X = 1(1+ I ) ,  
1 = 0,1,2, ... . 
(2.57) 
With this restriction on A, one of the Legendre series in Equation (2.43) 
terminates after a finite number of terms while the other one still diverges at 
the end points. Choosing the coefficient of the divergent series in the general 
solution as zero, we obtain the polynomial solutions of the Legendre equation 
as 
2 (z) = PL (22) , 1 = 0, 1,2, ... . 
Legendre Polynomials 
Po (z) = 1 
PI (z) = Ic 
P2 (.) 
= (2) [ 3 2  - 11 
P3 (z) = (k) [5z3 - 3x1 
P4(z) = (i) [35z4 - 30x2 + 31 
(2.58) 
P5(z) = (t) [63z5 - 70x3 + 15.1. 
P6(.) = (A) [231z6 - 3 1 5 ~ ~  
+ 1 0 5 ~ ~  
- 51. 
These polynomials are called the Legendre polynomials, and they are finite 
everywhere on a sphere. They are defined so that their value at 3: = 1 is one. 
In general they can be expressed as 
(2.59) 
where [i] 
means thegreatest integer in theinterval ( $, t-l]. Restriction of X 
to certain integer values for finite solutions everywhere is a physical (bound- 
ary) condition and has very significant physical consequences. In quantum 
mechanics it means that magnitude of the angular momentum is quantized. 
In wave mechanics, like the standing waves on a string fixed at both ends, it 
means that waves on a sphere can only have certain wavelengths. 

LEGENDRE POLYNOMIALS 
19 
2.3.1 
Rodriguez Formula 
Another definition of the Legendre polynomials is given as 
(2.60) 
To show that this is equivalent to 
1 dl 
1 
9 (x) = -- 
(2 - 1) , 
2'1! dxl 
which is called the Rodriguez formula. 
Equation (2.59) we use the binomial formula (Dwight) 
to write Equation (2.60) as 
1 d' 
l!(-l)n x21-2n 
a (x) = --c 
2"! dx' 
n! (1 - n)! 
n=O 
We now use the formula 
to obtain 
(2.61) 
(2.62) 
(2.63) 
(2.64) 
thus proving the equivalence of Equations (2.60) and (2.59). 
2.3.2 
Generating Function 
Another way to define the Legendre polynomials is by using a generating 
function, T (x, 
t), which is defined as 
00 
= cfi (x)t', 
It1 < 1 . 
(2.65) 
1 
T (z,t) = dl - 2xt + t 2  
l=o 
To show that T (x, 
t) generates the Legendre polynomials we write it as 
1 
T (x, t )  = [l - t (22 - t)]a 
and use the binomial expansion 
(2.66) 
(2.67) 

20 
LEGENDRE EQUATION AND POLYNOMIALS 
< 
We derive the useful relation: 
(- 1)l [ (;) ( f + 1) ( f + 2) . . . (-a - 1 )  (- f - 1 - 1) . . . ] 
[ ( - ; - 1 )  
( - f - I - l ) . . . ]  
- 
- 
I = (-1)' [ (;) (f + 1) (a + 2) . . . (; + I - l)] 
[ 1-3-5-.-(21-1) 
= (-1) 
21 
= (-1) 1 ( 2 1 ) !  
2211! ' 
to write Equation (2.67) as 
We use this in Equation (2.66) to write 
1 
(22-t) . 
1 
(2I)! (-1)21 t' 
1 =c 
(1 - t (2x - t ) ) 2  
I=O 
22' ( l ! ) 2  
Using the binomial formula again, we expand the factor 
1 
(2x - t) 
to write 
1 
I! 
( 2 2 y  (-ty 
2 (2I)! (-1)21 t l  
221 (q2 k=O c 
k! ( I  - k)! 
1=0 
1=0 k=O 
(2.68) 
(2.69) 
(2.70) 
(2.71) 
(2.72) 
(2.73) 

LEGENDRE POLYNOMIALS 
21 
We now rearrange the double sum by the substitutions 
k i n  and 2 4 2 - n  
(2.74) 
to write 
(2.75) 
n=O 
C 2 1 ( 2  - n)!n! 
( 1  - 2n)! 
Comparing this with the right-hand side of Equation (2.65), which is 
we obtain 
(2.76) 
(2.77) 
2.3.3 
Recursion Relations 
We differentiate the generating function for the Legendre polynomials with 
respect to t to get 
We rewrite this as 
03 
03 
( . - t ) C f i ( 2 ) t ~ = C P 1 ( . ) E  
tl-’ (1-2xt+t2) 
1=0 
I= 1 
and expand in powers o f t  to get 
03 
03 
03 
Ct‘ (21 + 1 ) z f i  (.) 
= Cfirl’t’’-’ + Ctl”+l(P 
+ l)fi!?(Z) 
l=O 
1’=l 
1“=0 
We now make the substitutions 
l ’ = I + l  
and 2 ” = 2 - 1  
and collect equal powers of t’ to write 
@a c [(21+ 1).9 (.) 
- 4 + 1  (.) 
( 2  + 1) - 1 s - 1  (%)It‘ = 0. 
1 =o 
( 2.78) 
(2.79) 
(2.80) 
(2.81) 
(2.82) 

22 
LEGENDRE EQUATION AND POLYNOMIALS 
This equation can only be satisfied for all values of t if the expression inside 
the square brackets is zero for all I ,  thus giving the recursion relation 
(21 + 1) xl3 (x) = (1 + 1) Pl+l(.> + 18-1 (x). 
(2.83) 
Another recursion relation is obtained by differentiating T (z, t )  with respect 
to z and following similar steps as 
9 (32) = q!+, 
(z-) + q’] (z-) - 2xp; (z). 
(2.84) 
It is possible to find other recursion relations, which are very useful in manip 
ulations with the Legendre polynomials. 
2.3.4 
Special Values 
In various applications one needs special values of the Legendre polynomials 
at the points x = f l  and z = 0. If we write x = f l  in the generating function 
Equation (2.65) we find 
(2.85) 
Expanding the left-hand side by using the binomial formula and comparing 
equal powers oft, we obtain 
9 (1) = 1 
8 
(-1) = (-1) . 
and 
1 
Similarly, we write x = 0 in the generating function to get 
00 
(2.86) 
(2.87) 
(2.88) 
This leads us to the special values: 
and 
(-$ 
(21)! 
p21 (O) = 221 (1!)2 . 
(2.90) 

LEGENDRE POLYNOMIALS 
23 
2.3.5 
Special Integrals 
1. In applications we frequently encounter the integral 
(2.91) 
Using the recursion relation Equation (2.84) we can write this integral 
as 
The right hand side can be integrated as 
This is simplified by using the special values and leads to 
I' dxq (x) = A+l(O) + A-1 (0) 
and 
(2.94) 
0 
1 _> 2 and even 
1 
l = Q  
1 
P2s(0), 1 = 2 s + 1 ,  s = O , l ,  ... 
2 (s + 1) 
L'dxPl (x) = 
(2.95) 
2. Another integral useful in dipole calculations is 
(2.96) 
Using the recursion relation, Equation (2.83), we can write this as 
(2.97) 

24 
LEGENDRE EQUATION AND POLYNOMIALS 
which leads to 
0, 
k # l f l ,  
In general one can show the integral: 
2.3.6 Orthogonality and Completeness 
We can also write the Legendre equation [Eq. (2.22)] as 
dfi ( 5 7  + 2 ( I  + 1) fi (x) = 0. 
d x  
(2.100) 
Multiplying this equation with Pp (z) and integrating over z in the interval 
[-I, 11, we get 
/ ' P p ( x ) { &  [ ( 1 - x 2 ) w ]  
d x  
+2(1+1)fi(z) 
dx=O. 
(2.101) 
-1 
Using integration by parts this can be written as 
1' [ (z2 - 1) -9 
+ 1 ( 1 +  1)fit (z)fi (z) dx = 0. 
(2.102) 
-1 
dx 
dx 
Interchanging 1 and 2' in Equation (2.102) and subtracting the result from 
Equation (2.102) we get 
1 
[2 (1 + 1) - 2' (2' + l)] / fif (z) 4 (x) 
CliE = 0. 
-1 
For 1 # 2' this equation gives 
(2.103) 
(2.104) 

LEGENDRE POLYNOMIALS 
25 
and for 1 = 1' it gives 
(2.105) 
where Nl is a finite normalization constant. We can evaluate the value of Nl 
by using the Rodriguez formula [Eq. (2.60)]. We write 
1 
Ni = 1, 
q2 (x) dx 
(2.106) 
(2.107) 
1 d' 
1 
- 
-- 
- 
(x2 - 1) - 
(x2 - 1) dx, 
dxl 
and after 1-fold integration by parts we obtain 
i d21 
dx2' 
(2.108) 
Nl = - 
(2 - 1) - 
(x2 - 1)l dz. 
Using the Leibniz formula 
m! 
d " A P - " B  
m 
(2.109) 
-- 
dm 
dxm 
- A ( x ) B ( x ) = C  
s! (m - s)! dxs dxm-s ' 
s=o 
we evaluate the 21-fold derivative of (x2 - 1)l as (21)!. Thus Equation (2.108) 
becomes 
(2.110) 
1 
We now write (1 - x2) as 
(1 - 2) 
1 = (1 - x2) (1 - x
y
 
= (1 - x y  + -- 
x d  (1 - .")' 
(2.111) 
21 dx 
to obtain 
This gives 
or 
(21 - 'i! l l x d  [(1 - x'),'] 
(21 - 1) 
N[ = - 
N1-1+ - 
21 
221 ( l ! )  
(21 - 1) 
1 
Ni = 
~ 
"-1 - -Nl 
21 
21 
(2.112) 
(2.113) 
(2.114) 

26 
LEGENDRE EQUATION AND POLYNOMIALS 
which means that the value of 
(21 + I) Ni 
(2.115) 
is a constant independent of 1. Evaluating Equation (2.115) for 1 = 0 gives 2, 
which determines the normalization constant as 
2 
Ni = - 
(2.116) 
(21 + 1)' 
Using N, we can now define set of polynomials {Ui (z)} as 
u, 
(z) 
= v'+ 
(.) 
, 
which satisfies the orthogonality relation 
F 1  
( 2.1 17) 
(2.118) 
At this point we suffice by saying that this set is also complete, that is in 
terms of this set any sufficiently well-behaved and at least piecewise continuous 
function 9 (z) can be expressed as an infinite series in the interval [-1,1] as 
00 
(2.119) 
We will be more specific about what is meant by sufficiently well-behaved 
when we discuss the Sturm-Liouville theory in Chapter 8. To evaluate the 
constants Cl we multiply both sides by Up (z) and integrate over [--1, I] : 
Using the orthogonality relation [Eq. (2.118)] we can free the constants Cl 
under the summation sign and obtain 
r l  
(2.121) 
Orthogonality and the completeness of the Legendre polynomials are very 
useful in applications. 
Example 2.1. Legendre polynomials and electrostatics problems: . 
To find the electric potential 9 in vacuum one has to solve the Laplace 
equation 
329 ( F )  = 0. 
(2.122) 

LEGENDRE POLYNOMIALS 
27 
For problems with azimuthal symmetry in spherical polar coordinates 
potential does not have any 4 dependence, hence in the +dependent 
part of the solution [Eq. (2.18)] we set 
m = 0. 
(2.123) 
The differential equation to be solved for the r-dependent part is now 
found by taking 
k2 = 0 
(2.124) 
in Equation (2.12) as 
R(r) = 0. 
(2.125) 
Linearly independent solutions of this equation are easily found as r' 
and Tl+ll 
thus giving the general solution of Equation (2.122) as 
1 
e ( r , 6 ) = x  Air +.r+l Ej(z=cos6). 
(2.126) 
1=0 - [  
" I  
We now calculate the electric potential outside a spherical conductor 
with radius a, where the upper hemisphere is held at potential VO and 
the lower hemisphere is held at potential -VO and that are connected by 
an insulator at the center. Since the potential cannot diverge at infinity, 
we set the coefficients A1 to zero and write the potential for the outside 
as 
(2.127) 
To find the coefficients B1, we use the boundary conditions at r = a as 
We multiply both sides by P ~ J  
(z) and integrate over z and use the 
orthogonality relation to get 
Bi 
2 
e (a,z) E j  (z) dx = -___ 
a"+' (21 + 1) ' 
(2.129) 

28 
LEGENDRE EQUATiON AND POLYNOMIALS 
(2.131) 
(21 + 1) al+l 
2 
Bl = 
For the even values of 1 the expansion coefficients are zero. For the odd 
values of 1 we use the result Equation (2.95) to write 
&s+l = - 
(4s + 3, - 
p2s (O) U2S+2( avo), s = 0,1,2, ... 
2 
(2s+2) 
(2.132) 
Substituting these in Equation (2.127) we finally obtain the potential 
outside the sphere as 
00 
@ (T, 0) = vo c 
(4s + 3) -- 
p2s (O) a2s+2 
(cw8). 
(2.133) 
(2s + 2) T2S+2 
s=o 
Potential inside can be found similarly. 
2.4 
ASSOCIATED LEGENDRE EQUATION AND ITS SOLUTIONS 
We now consider the associated Legendre Equation (2.21) for the 
values and try a series solution around x = 0 of the form 
(2.134) 
(2.135) 
k=O 
Now the recursion relation becomes 
Compared with the recursion relation for Legendre Equation (2.33) this has 
three terms, which is not very practical to use. In such situations, in order 
to get a two-term recursion relation we study the behavior of the differential 
equation near the end points. For the points near x = 1 we introduce a new 
variable 
y = ( 1 - 2 ) .  
(2.137) 
Now Equation (2.21) becomes 
m2 
+ X - -1 
Z(y) = 0. 
(2.138) 
(2 - Y ) Y - - -  
dz(y) [ 
y(2- y) 

ASSOCIATED LEGENDRE EQUATION AND ITS SOLUTIONS 
29 
In the limit as y -+ 0 this equation can be approximated by 
(2.139) 
To find the solution, we try a power dependence of the form Z(y) = y" to 
determine n as &m. Hence the two linearly independent solutions are 
ym/2 and y-m/2. 
(2.140) 
For m 2 0 the solution that remains finite as y --t 0 is yf. Similarly for 
points near x = -1, we use the substitution 
y = (1 +x) 
(2.141) 
and obtain the finite solution in the limit y -+ 0 as Y"/~. We now substitute 
in the associated Legendre Equation (2.21) a solution of the form 
2 (x) = (1 + x)m/2 (1 - z y 2  
f (x) 
(2.142) 
= (1 - x y 2  
f (z) , 
which gives the differential equation to be solved for f (x) as 
z2) d2 f - 22 (m + 1) - 
df (.) 
+ [A - 
dx 
dx 
m (m + I)] f (z) = 0. 
(2.143) 
Note that this equation is valid for both the positive and the negative values 
of m. We now try a series solution in this equation: 
f (x) = Ca,xk+a 
k 
and obtain a two-term recursion relation 
[(k + m) (k + m + 1) - A] 
( k  + 2) (k + 1) 
ak+2 = ak 
(2.144) 
(2.145) 
ak+2 
Since in the limit as k goes to infinity the ratio of two successive terms, -, 
goes to one, this series also diverges at the end points; thus to get a finite 
solution we restrict the separation constant A to the values 
ak 
(k + m) [(k + m) + 11 - A = 0, 
(2.146) 
X = ( k  + m) [(k + m) + 11. 
(2.147) 
Defining a new integer 
l = k + m  
(2.148) 

30 
LEGENDRE EQUATION AND POLYNOMIALS 
we obtain 
x = 1 ( 1 +  1) 
(2.149) 
and 
k = l - m .  
(2.150) 
Since Ic takes only positive integer values, m can only take the values 
m = -1, ..., 0, ..., 1 . 
(2.151) 
2.4.1 
Associated Legendre Polynomials 
To obtain the associated Legendre polynomials we write the equation that the 
Legendre polynomials satisfy as 
(1 - x2) - 
fP9 
- 22- 
+ l ( l +  1 ) A  ( 2 )  = 0. 
dx2 
dx 
(2.152) 
Using the Leibniz formula 
we differentiate Equation (2.152) m times to obtain 
2m(m- 1) (m) 
(1 - x2) P/"+~) ( x )  - 2 z m ~ f ~ + ' )  
(x) - 
2 
Pl 
(2) 
= 2 x ~ / ~ + ' )  
( 2 )  + 2m~,(") 
( x )  - i(1+ I) P / ~ )  
(x) . 
(2.154) 
After simplification this becomes 
(1 - x2) l+m+2) (x) - 22 (m + 1) I+m+l) 
( x )  
+ [i (1 + I) - m (m + I)] 
( x )  = 0, 
(2.155) 
where 
(2.156) 
Comparing Equation (2.155) with Equation (2.143) we obtain f ( x )  as 
(2.157) 
(1" 
dxm 
f (.) 
= -4 
(.). 

ASSOCIATED LEGENDRE EQUATION AND ITS SOLUTIONS 
31 
Using Equation (2.142), we can now write the finite solutions of the associ- 
ated Legendre equation (2.21) as 
m 
- P  
dxm 
(2.158) 
These polynomials, Plm (x) , are called the associated Legendre polyno- 
mials. 
For the negative values of m, associated Legendre polynomials are defined 
as 
Z(X) 
= PF (x) = (1 - x2) 2 -9 
(z), m 2 0. 
( I  - m)! 
P; 
(x) = (-1)"- 
(1 + m)! P?(x), m 2 0 .  
m 
(2.159) 
2.4.2 
To derive the orthogonality relation of the associated Legendre polynomials 
we use the Rodriguez formula [Eq. (2.60)] for the Legendre polynomials to 
write 
Orthogonality of the Associated Legendre Polynomials 
1 
1 
dl+m 
dl'+rn 
, 
1, Py (.)Ply (z)dx = (-l)m 
Xm-X'-X' 
dz, 
(2.160) 
2'+' l!P! ll dxl+m 
dxl +m 
where 
x = z2 - 1, 
(2.161) 
(2.162) 
em(z)= (1-z2)m'2-R(x) 
dn 
dxm 
and 
1 d' 
1 
fi (x) = -- 
(x2 - 1) . 
2'1! dxl 
(2.163) 
The integral in Equation (2.160) after (I' + m)-fold integration by parts be- 
comes 
(2.164) 
Using the Leibniz formula, Equation (2.153), we get 
Since the highest power in Xm is x2m and the highest power in X' is x2', the 
summation is empty unless the inequalities 
1' + m - X 5 2m 
(2.166) 

32 
LEGENDRE EQUATION AND POLYNOMIALS 
and 
1 + m + X 5 21 
(2.167) 
are simultaneously satisfied. The first inequality gives 
X 2 1' - m, 
while the second one gives 
(2.168) 
Xsl-m. 
(2.169) 
For m 2 0, if we assume I < I' the summation [Eq. (2.165)] does not contain 
any term that is different from zero; hence the integral is zero. Since the 
expression in Equation (2.160) is symmetric with respect to 1' and I ,  this 
result is also valid for I > 1'. When 1 = I' these inequalities can be satisfied 
only for the single value of X = 1 - m. Now the summation contains only one 
term, and Equation (2.165) becomes 
This integral can be evaluated as 
1 
1: X'dx = 1, 
(x2 - 1)* d z  = 2 (-1)l 
- (4)*21+'1! 
- 
3.5 ... (21 + 1) 
- (4)* 
221+' 
( I ! ) 2  
- 
(21 f l)! 
Since the binomial coefficients are given as 
( I  + m)! 
(i "3 
= (1 - m)! (2m)!' 
(2.170) 
(2.171) 
(2.172) 
the orthogonality relation of the associated Legendre polynomials is obtained 
as 
1 
(-1y (1 +m)! (-l)l+m 
(-1) ' 2 21+1 ( q
2
 
. 6,1,, 
Pirn (x) P*Y (x) & = - 
(2I)! (2m)! 
1, 
221 ( q 2  ( 1  - m)! (am)! 
(21 + 1)! 

SPHERICAL HARMONICS 
33 
2 
- 
- w 2 2  [-] 
all,. 
( I  - m)! (21 + 1) 
(2.173) 
Associated Legendre Polynomials 
Po"(.) = 1 
P;(Z) 
= (I -x')~/' = sin8 
Pi(z) = 3z(1 --z')~/' = 3cosBsinB 
P,"(z) = 3( 1 - z') = 3 sin' 8 
P,'(z) = -(52 - 1)(1- z')'/' 
= -(5c0s26 - 1)sinB 
P,"(z) = 152(1 -z') = 15cos8sin'B 
Pi(.) 
= 15( 1 - z')~/' = 15sin3 8. 
3 
3 
2 
2 
2.5 
SPHERICAL HARMONICS 
We have seen that the solution of Equation (2.17) with respect to the inde 
pendent variable 4 is given as 
(4) = Aeim4 + Be-im@. 
(2.174) 
Imposing the periodic boundary condition am(4 + 2 ~ )  
= am(+), 
it is seen 
that the separation constant m has to take finteger values. However, in 
Section 2.4 we have also seen that m must be restricted further to the integer 
values -1, ..., 0, ..., 1. We can now define another complete and orthonormal 
set as 
1 
{am($) 
= -eim@} 
, m = -1, ..., 0, ..., 1. 
(2.175) 
6 
This set satisfies the orthogonality relation 
2T 
Jd 
d4amt (4)*~(4) 
= fimmf. 
(2.176) 
We now combine the two sets {am(4)} 
and {F;r"(8)} to define a new com- 
plete and orthonormal set called the spherical harmonics as 
21 + 1 ( I  - m)! 
47r 
(1 +m)! 
--elm+ 
P,"(cosB), m 2 0. 
(2.177) 

34 
LEGENDRE EQUATION AND POLYNOMIALS 
In conformity with applications to quantum mechanics and atomic spec- 
troscopy, we have introduced the factor (-l)m. It is also called the Condon- 
Shortley phase. 
The definition of spherical harmonics can easily be ex- 
tended to the negative m values as 
Y-"(6,4) = (-1)mqm*(Q,4), 
m 2 0. 
(2.178) 
The orthogonality relation of Ym(8, 
4) is given as 
Since they also form a complete set, any sufficiently well-behaved and at least 
piecewise continuous function g(B,$) can be expressed in terms of qm(8, 4) 
as 
1=0 m=-1 
where the expansion coefficients Akare given as 
(2.180) 
(2.181) 
Looking back at Equation (2.13), we see that the spherical harmonics sat- 
isfy the differential equation 
(2.182) 
If we rewrite this equation as 
the left-hand side is nothing but the square of the angular momentum operator 
(aside from a factor of ti) in quantum mechanics, which is given as 
(2.184) 
In quantum mechanics the fact that the separation constant X is restricted 
to integer values means that the magnitude of the angular momentum is 

SPHERlCAL HARMONlCS 
35 
quantized. From Equation (2.183) it is seen that the spherical harmonics are 
also the eigenfunctions of the 3' operator. 
Spherical Harmonics q"(8, $) 

36 
LEGENDRE EQUATION AND POLYNOMIALS 
1 = 3  
Problems 
2.1 
tial equations: 
i) Laguerre equation: 
Locate and classify the singular points of each of the following differen- 
ii) Harmonic oscillator equation: 
d2Q& (.) 
+ (. - x2) IFE (X) = 0 
dx2 
iii) Bessel equation: 
2 J L ( X )  + Z J L ( X )  + (2 - r n 2 ) J m ( X )  = 0 
iv) 
d2Y 
dY 
2 
(x4 - 2X3 + X2)- 
+ (. - 1) - + 2x 
= 0 
dx2 
d x  

PROBLEMS 
37 
vi) Chebyshev equation: 
&Y 
dY 
- 
- 2- dx +n2y = 0 
vii) Gegenbauer equation: 
gc; 
dCX (x) 
dx2 
dx 
( 1 - 2 ) -  
-(2X+l)x-”---++(n+2X)C~(x)=O 
viii) Hypergeometric equation: 
d2y(z) + [c - (a + b + 1)x]- dy(x) - uby(x) = 0 
z- d2y(z) + [c - 21- 
- .y(z) = 0 
dx 
2(1-x)- 
dx2 
ix) Confluent Hypergeometric equation: 
dYk) 
dz2 
dz 
2.2 
find solutions about x = 0: 
For the following differential equations use the Frobenius method to 
i> 
2x 3 -++x2-++3y=O 
d2Y 
dY 
d x 2  
dx 
ii) 
iii) 
iv) 
v) 
vi) 
3 d2Y 
2 dY 
8 
x -++x 
-+(x3+-x)y=O 
9 
dx2 
dx 
3 d2Y 
2 dY 
3 
x - + f x  
-+(x3+-x)y=O 
dx2 
dx 
4 
2d2Y 
dY 
x - 
+ 3x- + (22 + 1)y = 0 
dx2 
dx 
&Y 
ZdY 
x3- 
+ 2 - + (8z3 - 9x)y = 0 
dx2 
dx 
2 2d2Y 
-+x-+x2y=o 
dY 
dx2 
dx 

38 
LEGENDRE EQUATION AND POLYNOMIALS 
vii) 
d2Y 
dY 
Z- 
+ (1 -I.) - 
+4y = 0 
dX2 
dx 
viii) 
3 d2Y 
2 dY 
2% - 
+ 5 2  - + (x3 - 2x)y = 0 
dx2 
dx 
2.3 
Find finite solutions of the equation 
d2Y 
dY 
(1 - 2)- - 2- + n2y = 0 
dx2 
dx 
in the interval 3: E [-1,1] for n = integer. 
2.4 
Consider a spherical conductor with radius a, with the upper hemisphere 
held at potential Vo and the lower hemisphere held at potential -Vo, which 
are connected by an insulator at the center. Show that the electric potential 
inside the sphere is given as 
2.5 
solutions of 
Using the Frobenius method, show that the two linearly independent 
R = 0, 
are given as 
2.6 
The amplitude of a scattered wave is given as 
00 
f ( 0 )  = y C ( 2 1 +  l)(ei6[ sinGl)e(cosB), 
1 =o 
where B is the scattering angle, 1 is the angular momentum, and 61 is the 
phase shift caused by the central potential causing the scattering. If the total 
scattering cross section is 

PROBLEMS 
39 
show that 
2.7 
Prove the following recursion relations: 
4 (z) = P;+l (z) + 
(x) - 2x4' (.> 
P(,l (z) - xP( (z) = (1 + l)q (x) 
2.8 
Use the Rodriguez formula to prove 
P; (z) = zP;-, (x) + 14-1 (z) 
where 1 = 1,2, ... . 
2.9 
Show that the Legendre polynomials satisfy the following relations: 
9 
d - 
dx [(l - z2)P/(iC)] + 1 ( 1 +  1)9(x) = 0 
2.10 
Derive the normalization constant, Ni, in the orthogonality relation 
1 s_, P1) (z) A (x) &E = "b 
of the Legendre polynomials by using the generating function. 
2.11 
Show the integral 

40 
LEGENDRE EQUATION AND POLYNOMIALS 
where 
(1 - n) = (even integer] . 
2.12 
are given as 
Show that the associated Legendre polynomials with negative m values 
( I  - m)! 
(1 + m)! 
PFrn(Z) = (-1)rn- 
P;"(z), m 2 0. 
2.13 
in the interval [-1,1]. 
2.14 A metal sphere is cut into sections that are separated by a very thin 
insulating material. One section extending from 6 = 0 to 8 = 8, at potential 
Vo and the second section extending from 6 = 60 to 8 = 7r is grounded. Find 
the electrostatic potential outside the sphere. 
2.15 
Expand the Dirac delta function in a series of Legendre polynomials 
The equation for the surface of a liquid drop (nucleus) is given by 
2
2
 
2 2  
2 4  
T = a  ( I + E ~ - + E ~ - ) ,  
T2 
r4 
where 2, €2, and €4 are given constants. Express this in terms of the Legendre 
polynomials as 
2.16 
can be expressed in terms of the Legendre polynomials as 
Show that the inverse distance between two points in three dimensions 
1 
1 
where r< and r, denote the lesser and the greater of r and r', respectively. 
2.17 
Evaluate the sum 
&+1 
03 
s = c 
- f i ( Z ) .  
l=O 1 + 1  
Hint: Try using the generating function for the Legendre polynomials. 
2.18 
Wronskian 
If two solutions yl(z) and y 2 ( z )  are linearly dependent, then their 
W[Yl(Z),Y2(Z)I = Yl(Z)Y2Z) - d ( Z ) Y 2 ( Z )  

PROBLEMS 
41 
vanishes identically. What is the Wronskian of two solutions of the Legendre 
equation? 
2.19 The Jacobi polynomials P p ' b ) ( ~ ~ ~ 8 ) ,  
where n = positive integer and 
a, b are arbitrary real numbers, are defined by the Rodriguez formula 
d" 
2"n!(l - x)"(l+ x)b dx" 
P..b'(x) = 
(-1" 
- 
[( 1 - ,)"+a( 
1 + Z)"+b] , 1x1 < 1. 
Show that the polynomial can be expanded as 
n 
P 2 7 b ) ( ~ ~ ~ 6 )  
= 
A(n, a, b, k) 
ks0 
Determine the coefficients A(n, a, b, k) for the special case, where a and b are 
both integers. 
2.20 
Find solutions of the differential equation 
d2Y 
2 ~ ( x  
- 1)- 
+ ( 1 0 ~  
- 
dx2 
d x  
satisfying the condition 
y ( x )  = finite 
in the entire interval z E [0,1]. Write the solution explicitly for the third 
lowest value of A. 

This Page Intentionally Left Blank

3 
LAGUERRE 
POL YNOMIA LS 
For the central force problems, solutions of the time-independent Schrodinger 
equation can be separated as 
R(T)Y,YQ, 41, 
(3.1) 
where the angular part is the spherical harmonics and the radial part comes 
from the solutions of the differential equation 
where 
2m 
h2 
it2 = - 
[E - v (r)] 
If we substitute 
(3.3) 
the differential equation to be solved for uE,l(r) becomes 
To indicate that the solutions depend on the energy and the angular momen- 
tum values, we have written 
uE,1 (r)- 
43 

44 
LAGUERRE POLYNOMIALS 
For singleelectron atom models potential energy is given as Coulonib's law: 
Ze2 
r 
V(r) = --, 
(3.5) 
where Z is the atomic number and e is the electron's charge. A series solution 
in Equation (3.4) yields a threeterm recursion relation. To get a two-term 
recursion relation we investigate the behavior of the differential equation near 
the end points, 0 and CQ, which suggests that we try a solution of the form 
where we have defined a dimensionless variable p = r d m .  
electrons in an atom are bounded, their energy values are negative. 
simplify the differential equation for w(p) further by the definitions 
and 
to write 
d2W 
dw 
P
T
 + 2(1 + 1 - P)- 
+ [Po - 2(1+ l)]w(p) = 0. 
dP 
dP 
We now try a series solution 
(3.6) 
Because 
We can 
(3.7) 
(3.10) 
k=O 
which gives us a two-term recursion relation 
ak+l 
UE , goes as L; 
In the limit as k + 00 the ratio of two successive terms, - 
k 
(3.11) 
2 
hence the infinite series in Equation (3.10) diverges as e2P, which also implies 
that RE,l(r) diverges as r
1
e
T
m
.
 
Since 
I 
(r)q"(e, 
'P) l 2  
(3.12) 
represents the probability density of the electron, for physically acceptable 
solutions RE,l(r) must be finite everywhere. In particular, as r + CQ it should 

LAGUERRE EQUATION AND POLYNOMIALS 
45 
go to zero. Hence for a finite solution in the interval [O,m], we terminate the 
series [Eq. (3.10)] by restricting po (energy) to the values 
po = 2 ( N  + 1 + l), N = 0, 1,2, ... . 
(3.13) 
Since 1 takes integer values, we introduce a new quantum number, n, and 
write the energy levels of a singleelectron atom as 
Z2me4 
2fi2n2 ' n = 1,2, ... , 
En = -- 
(3.14) 
which are nothing but the Bohr energy levels. 
equation to be solved for w ( p )  as 
Substituting Equation (3.13) in Equation (3.9) we obtain the differential 
(3.15) 
solutions of which can be expressed in term of the associated Laguerre 
polynomials. 
3.1 
LAGUERRE EQUATION AND POLYNOMIALS 
The Laguerre equation is defined as 
d2Y 
dY 
~2 
d x  + (1 - x )  - 
d x  + n y  = 0, 
(3.16) 
where n is a constant. Using the Frobenius method, we substitute a series 
solution about the regular singular point x = 0 as 
r=O 
and obtain a two-term recursion relation 
(S + T - n) 
( s + r + q 2 '  
ar+l = a, 
In this case the indicia1 equation has a double root, 
s = 0, 
where the two linearly independent solutions are given as 
(3.17) 
(3.18) 
(3.19) 
(3.20) 

46 
LAGUERRE POLYNOMIALS 
The second solution diverges logarithmically as x + 0. Hence for finite s- 
lutions everywhere we keep only the first solution, y (z, 0) which has the 
recursion relation 
(3.21) 
This gives us the infinite series solution as 
,y-+... 
n(n--1)x2+...+ (-l)? n (n - 1) ... (n - T + 1) 
y ( 2 ) = a o  
1 - - +  
{ 
l2 
(2!)2 
(r!l2 
(3.22) 
From the recursion relation [Eq. (3.21)], it is seen that in the limit as T + co 
the ratio of two successive terms has the limit ar+l/ar --f l/r; hence this 
series diverges as e" for large x. We now restrict n to integer values to obtain 
finite polynomial solutions as 
n 
n(n- l ) . . - ( n - r +  1) 
X *  
(?-!)2 
y (x) = a o z  
r=O 
n 
n!xr 
= a0C 
r=O 
(n - T ) !  ( T ! ) 2 .  
(3.23) 
Laguerre polynomials are defined by setting a0 = 1 in Equation (3.23) as 
3.2 OTHER DEFINITIONS OF LAGUERRE POLYNOMIALS 
3.2.1 
The generating function of the Laguerre polynomials is defined as 
Generating Function of Laguerre Polynomials 
-xt 
(3.24) 
(3.25) 
To see that this gives the same polynomials as Equation (3.24), we expand 
the left-hand side as power series: 
-xt 
1
-
 
1 
" 1  
-,(I 
- 4  = - 
( 1 - t )  
(1 - t )  r=o c, 
[-&Ir 
zrtr 
r = O  
(3.26) 

OTHER D€F/N/T/ONS OF LAGUERRE POLYNOMIALS 
47 
Using the binomial formula 
1 
(r + 1) (r + 2)t2 +. . . 
= l + ( r + l ) t +  
2! 
(1 - ty+' 
OC) (r + s)! 
= c r  
tS, 
s=o 
(3.27) 
Equation (3.26) becomes 
Defining a new dummy variable as 
n = r + s ,  
we now write 
(3.29) 
and compare equal powers of t. Since 
s = n - r > O ,  
r 5 n; thus we obtain the Laguerre polynomials L, ( x )  as 
(3.31) 
(3.32) 
3.2.2 
Another definition of the Laguerre polynomials is given in terms of the Ro- 
driguez formula: 
Rodriguez Formula for the Laguerre Polynomials 
(3.33) 
To show the equivalence of this formula with the other definitions we use the 
Leibniz formula 
(3.34) 
to write 
n 
n! 
dnPrxn dre-" 
(3.35) 
-- 
ex dn 
ex 
-- (xne-x 
n! dxn 
)=,!C (n-r)!T! dxn-r 
dxr . 
r=O 

48 
LAGUERRE POLYNOMIALS 
We now use 
dPXq 
dxp 
-- - q ( q  - I). . . (q - p +  1)xq-p 
to obtain 
n! 
n! 
n. 
(n - r)!r! r! 
n!xT 
-zT 
epx 
ex dn 
ex 
n! dxn 
-- (xne-") = -i-c 
r=O 
n 
= c 
2 
r=O 
(r!) (n -r)! 
(3.36) 
(3.37) 
= L, (x). 
3.3 
ORTHOGONALITY OF LAGUERRE POLYNOMIALS 
To show that the Laguerre polynomials form an orthogonal set, we evaluate 
the integral 
(3.38) 
Using the generating function definition of the Laguerre polynomials we write 
03 
= E L n  
(z) tn 
n=O 
1-t 
and 
OL) 
xs 
1 
= E L m  
(z) sm. 
n=O 
1-s 
(3.39) 
(3.40) 
We first multiply Equations (3.39) and (3.40) and then the result with ep" to 
write 
(3.41) 

ORTHOGONALiTY OF LAGUERRE POLYNOMlALS 
49 
Interchanging the integral and the summation signs and integrating with re- 
spect to x gives us 
2 [ ~ W e ~ x L n ( x ) L m ( x ) d x  
1 tnsm 
n,m=O 
It is now seen that the value of the integral in Equation (3.38) can be obtained 
by expanding 
in powers of t and s and then by comparing the equal powers of tnsm with 
the left-hand side of Equation (3.42). If we write I as 
t 
S 
I =  
JWexp { -x (1 + - 
1-t + -)} 
1-s 
dx, 
(3.44) 
( 1 - 9 ( 1 - 4  
0 
the integral can be taken to yield 
00 
-exp { -x (1 + A + e)} 
I =  
1 
(3.45) 
r 
1 
1 
1 - st 
- 
-- 
W 
= C s n t n .  
n=O 
(3.46) 
(3.47) 
(3.48) 
This leads us to the orthogonality relation for the Laguerre polynomials as 
e-"Ln ( x )  L, ( x )  dx = 6 nm. 
Compared with the Legendre polynomials, we say that the Laguerre polyno- 
mials are orthogonal with respect to the weight function e-". 

50 
LAGUERRE POLYNOMIALS 
3.4 
OTHER PROPERTIES OF LAGUERRE POLYNOMIALS 
3.4.1 
Recursion Relations 
Using the method we have used for the Legendre polynomials, we can obtain 
two recursion relations for the Laguerre polynomials. We first differentiate 
the generating function with respect to t to obtain 
(n+I)L,+1 (z) =(2n+l-z)Ln(z)--Ln-1(z). 
(3.49) 
Differentiating the generating function with respect to x gives us the second 
recursion relation 
zLL (5) = nLn (z) - nL-1 (z) 
Another useful recursion relation is given as 
11-1 
r=O 
Laguerre Polynomials 
Lo (x) = 
1 
L1 (x) = 
L2 (XI = 
-x + 1 
(1/3!) (-x3 + 9z2 - 18% +6) 
(1/4!) (z4 - 16x3 + 722’ - 962 + 24) 
(1/2!) (9 
- 42 + 2) 
L3 (x) = 
L4 (x) = 
L5(x) = (1/5!) (-z5 + 25x4 - 200x3 + 600~’ - 600x + 120) 
3.4.2 
Taking x = 0 in the generating function we find 
Special Values of Laguerre Polynomials 
1 
1-t 
00 
ELn (0)t” = - 
n=O 
00 
= Ct’” 
n=O 
This gives us the special value 
L, (0) = 1. 
(3.50) 
(3.51) 
(3.52) 
(3.53) 
(3.54) 
(3.55) 
Another special value is obtained by writing the Laguerre equation at x = 0 
as 

ASSOCIATED LAGUERRE EQUATION AND POLYNOMIALS 
51 
which gives 
Lk (0) = -n. 
(3.57) 
3.5 
ASSOCIATED LAGUERRE EQUATION AND POLYNOMIALS 
The associated Laguerre equation is given as 
d2Y 
dY 
x- 
+ ( k  + 1 -x)- 
+ n y  = 0, 
dx2 
dx 
(3.58) 
which reduces to the Laguerre equation for k = 0. Solution of Equation (3.58) 
can be found by the following theorem: 
Theorem: Let Z ( x )  be a solution of the Laguerre equation of order (n + k )  , 
dkZ (x) 
d x k  
then - 
satisfies the associated Laguerre equation. 
Proof: We write the Laguerre equation of order (n + k )  as 
d2Z 
dZ 
dx2 
dx 
5- 
+ (1 - x )  - + (n+ k ) Z ( x )  = 0. 
(3.59) 
Using the Leibniz formula [Eq. (3.34)], k-fold differentiation of Equation 
(3.59) gives 
dki2Z 
dk++'z 
dk+'Z 
dkZ 
dkZ 
dx 
dxk 
dxk++l +k(-1) 
+ ( n + k )  - 
= 0. 
X-+k- 
dxk+2 
&k+l + - - 
(3.60) 
Rearranging this, we obtain the desired result as 
=O. 
(3.61) 
Using the definition of the Laguerre polynomials [Eq. (3.32)], we can now 
write the associated Laguerre polynomials as 
dk 
(n + k)!xr 
L; ( x )  = (-1) 7- 
(-1y 
(3.62) 
dx r=O 
(n + k - T ) !  (T!)2. 
Since k-fold differentiation of x' 
is going to give zeroes for the T < k values, 
we can write 
d k  n+k 
(n + k)!x' 
dxk r=k 
(n+k-T)!(T!)2' 
L; (x) = (-1) -x (-1y 
(3.63) 

52 
LAGUERRE POLYNOMIALS 
(3.64) 
(n + k)! 
r! 
xr..k 
n+k 
L; (2) = (-1y c (-1y 
r=k 
(n + IC - r)! (r!)2 (r - k)! 
Defining a new dummy variable s as 
s = r - k ,  
(3.65) 
we find the final form of the associated Laguerre polynomials as 
(n + k)!x" 
(n - s)! (k + s)!s!. 
n 
L; ( x )  = c (-1y 
s=o 
(3.66) 
3.6 
PROPERTIES OF ASSOCIATED LAGUERRE POLYNOMIALS 
3.6.1 Generating Function 
The generating function of the associated Laguerre polynomials is defined as 
To prove this we write the generating function of the Laguerre polynomials 
as 
r 
xt 1 
M 
(1 - t)"l 
n=O 
(3.68) 
which gives us 
This can also be written as 
kexp [-*I 
O3 dk 
- t )  = c s L n + k  (x)tn+k. 
(3.70) 
[&I 
( I - t )  
n=O 
We now use the relation 
(3.71) 

PROBLEMS 
53 
to write 
00 
zt 
= c (-l)k Lk (z)tn+k, 
(3.72) 
t k  
(1 -t)"+l exp [-m] 
n=O 
which leads us to the desired result 
M 
= E L :  (z)t". 
(1 - t)k+' 
n=O 
(3.73) 
3.6.2 
Rodriguez Formula and Orthogonality 
The Rodriguez formula for the associated Laguerre polynomials is given as 
[e-xzn+k]. 
eXxPk 6" 
n! dxn 
Lk (z) = -- 
Their orthogonality relation is: 
where the weight function is given as 
(e-"zk). 
(3.74) 
(3.75) 
(3.76) 
3.6.3 
Recursion Relations 
Some frequentIy used recursion relations of the associated Laguerre polyno- 
mials are given as 
(72 + 1) Lk+] (z) = (2n + k + 1 - z) L: (z) - (n + k)Lk-, (z) 
(3.77) 
d 
x-L:(z)= 
dx 
n L : ( z ) - ( n + k ) L : _ l ( z )  
(3.78) 
(3.79) 
k 
(z) -I- L:-I (z) = Lk (z). 
Problems 
3.1 
is written as 
We have seen that the Schrodinger equation for a single-electron atom 

54 
LAGUERRE POLYNOMIALS 
i) Without any substitutions, convince yourself that the above equation gives 
a three-term recursion relation and then derive the substitution 
which leads to a differential equation with a two-term recursion relation for 
w(p). We have defined a dimensionless variable p = r d m .  
Hint: 
Study the asymptotic forms and the solutions of the differential equation at 
the end points of the interval [0, m]. 
ii) Show that the differential equation for w(p) has the recursion relation 
a k + l  - 2 ( k f I + 1 ) - p O  
-- 
a k  
( k f  1)(k+21+2)' 
where 
Po = /&-. 
2 m  Ze2 
3.2 Derive the recursion relations 
zLL (z) = nLn (z) - nLn-l (z), 
and 
n- I 
3.3 
relation 
Show that the associated Laguerre polynomials satisfy the orthogonality 
(n + k)! 
n! 
(z) LL (z) dx = ___ Snm. 
3.4 
the spherical harmonics and the associated Laguerre polynomials. 
3.5 
Using the generating function 
Write the normalized wave function of the hydrogen atom in terms of 

PROBLEMS 
55 
derive the Rodriguez formula for Lk (x) . 
3.6 
polynomials. 
3.7 Show the special value 
Find the expansion of exp(-kx) in terms of the associated Laguerre 
(n + k)! 
n!k! 
Lk(0) = 
~ 
for the associated Laguerre polynomials. 
3.8 
i) Using the Frobenius method, find a series solution about x = 0 to the 
differential equation 
&C 
dC 
X 
dx2 
dx 
4 
2- 
+-+(A- 
-)C= 0, 
x € [O,m]. 
ii) Show that solutions regular in the entire interval [0, m] must be of the form 
c,(x) 
= e-z/2T,n(x), 
with X = n+1/2, n = 0,1,2, ..., where En(.) satisfies the differential equation 
d2En 
dz, 
dx2 
dx 
x- 
+ (1 -x) - 
+nEn = 0. 
iii) With the integration constant 
a, = (-l),, 
find the general expression for the coefficients a,-j of z,(z). 
iv) Show that this polynomial can also be defined by the generating function 
exP[-&] 
03 - 
T (x, t )  = 
= c Ln 
tn 
n! 
( 1 - t )  
-0 
or the Rodriguez formula 
v) Derive two recursion relations connecting 
-
-
 
Ln+1, Ln and I n - 1  
and 
- -  
-I L, with L,, L,-1. 

56 
LAGUERRE POLYNOMIALS 
vi) Show that Cn(x) form an orthogonal set, that is, 
and calculate the integral 
Note: Some books use Zrn for their definition of Laguerre polynomials. 
3.9 
Starting with the generating function definition 
-xt 
derive the Rodriguez formula 
ex dn 
L, (x) = -- (xnepz) 
n! dxn 
for the Laguerre polynomials. 
3.10 
Using the series definition of the Laguerre polynomials, show that 
LL(0) = -n, 
1 
Ll(O) = -n(n - 1). 
2 
3.11 
the three-dimensional harmonic oscillator is given as 
In quantum mechanics the radial part of Schriidinger’s equation for 
+ E-x -- 
&R(x) 2dR(x) 
dx2 
x dx 
+-- 
( 
where x and t are defined in terms of the radial distance r and the energy E 
as 
r 
E 
x = -  
and 
E =  - 
Ifi 
hw/2’ 
limw 
1 takes the integer values 1 = 0,1,2 ... . Show that the solutions of this equation 
can be expressed in terms of the associated Laguerre polynomials of argument 
2 2 .  

HERMITE 
POL YNOMIA LS 
The operator form of the time-independent Schriidinger equation is given as 
H @ ( T ) = E @ ( T ) ,  
(4.1) 
where @(?) is the wave function, H is the Hamiltonian operator, and E 
stands for the energy eigenvalues. H is usually obtained from the classi- 
cal Hamiltonian by replacing 33'' (position) and 
(momentum) with their 
operator counterparts: 
Z - Z ,  
(4.2) 
For the one-dimensional harmonic oscillator, the Hamiltonian operator is ob- 
tained from the classical Hamiltonian 
p2 
m d x 2  
H = -  
+- 
2m 
2 
as 
fi2 d2 
mu2$ 
H(z) = 
+ - 
2m d x 2  
2 
This leads us to the following Schrodinger equation: 
d2@(x) 
2m ( 
dx2 
h2 
mu22x2) \k (z) = 0. 
+- 
E-- 
(4.3) 
(4.4) 
(4.5) 
57 

58 
HERMITE POLYNOMIALS 
Defining two dimensionless variables 
and dropping the prime in x', we obtain the differential equation to be solved 
for the wave function as 
d2Q (x) 
dx2 + (. -x2) Q ( x )  = 0, x E [O,CQ], 
(4.7) 
which is closely related to the Hermite equation, and its solutions are given 
in terms of the Hermite polynomials. 
4.1 
HERMITE EQUATION A N D  POLYNOMIALS 
We need to find a finite solution to differential Equation (4.7) in the entire 
interval [0, CQ] . However, direct application of the Frobenius method gives us 
a threeterm recursion relation. To get a two-term recursion relation we again 
look at the behavior of the solution near the singularity at infinity. 
First we make the substitution 
which transforms the differential equation into the form 
It is clear that the singularity at infinity is essential. Because it is at the end 
point of our interval it does not pose any difficulty in finding a series solution 
about the origin. We now consider differential Equation (4.7) in the limit as 
x -+ CQ, where it behaves as 
-- 
@* 
( X I  
2% ( x )  = 0. 
dx2 
(4.10) 
This has two solutions, exp(-$) 
and exp($). 
Since exp($) blows up at 
infinity, we use the first solution and substitute into Equation (4.7) a solution 
of the form 
X 2  
Q 
= h (x> exP(-+ 
(4.11) 
which leads to the following differential equation for h(x): 
d2h 
d h  
dx2 
dx 
- 
- 2s- + ( E  - 1) h (x) = 0. 
(4.12) 

HERMITE EQUATION AND POLYNOMIALS 
59 
We now try a series solution of the form 
03 
h (z) = C a k z k ,  
k=O 
which gives a tweterm recursion relation: 
(2k + 1 - &) 
( k + 2 ) ( k + l ) '  
ak+2 = a k  
(4.13) 
(4.14) 
Since the ratio of two successive terms has the limit limk,, 
series asymptotically behaves as ex'. 
Thus the wave function diverges as 
--+ 2k, this 
(4.15) 
A physically meaningful solution must be finite in the entire interval [O,w]; 
hence we terminate the series after a finite number of terms. This is ac- 
complished by restricting the energy of the system to certain integer values 
as 
~ - 1 = 2 n ,  n = 0 , 1 , 2  .... 
(4.16) 
Now the recursion relation [Eq. (4.14)] becomes 
(2k - an) 
( k  + 2) (k + 1)' 
ak+2 = a k  
Thus we obtain the polynomial solutions of Equation (4.12) as 
(4.17) 
n= 0 ho(z) = a0 
n= 1 hl (z) = alz 
n= 2 h2(z) = Uo(1-2Z2) . 
(4.18) 
From the recursion relation [Eq. (4.17)] we can write the coefficients of the 
decreasing powers of 5 for the nth-order polynomial as 
(4.19) 
' n(n - 1) (n - 2) (n - 3 ) - - - ( n  - 2 j  + 1) 
u,-2j = (-1)J 
an 7 
232.4 ... (2j) 
When we take a, as a, = 2" we obtain the Hermite polynomials 
(4.20) 
(4.21) 

60 
HERMITE POLYNOMIALS 
which satisfy the differential equation 
H: (2) - 22HL (x) + 2nHn (x) = 0. 
Hermite Polynomials 
HO(2) = 1 
HI (2) = 22 
H2(z) = -2 + 4x2 
H&) = -122 + 823 
H4(2) = 12 - 48x2 + 16x4 
HS(2) = 1202 - 1 6 0 ~ ~  
+ 3 2 ~ ~ .  
Going back to the energy parameter E, we find 
hw 
2 
E = -&, 
E = hw (n + ;) , n = 0,1,2,.. 
(4.22) 
(4.23) 
(4.24) 
This means that in quantum mechanics a one-dimensional harmonic oscillator 
can only oscillate with the energy values given above. 
4.2 
OTHER DEFINITIONS OF HERMITE POLYNOMIALS 
4.2.1 
Generating Function 
The generating function for the Hermite polynomials is given as 
(4.25) 
To show that this is equivalent to our former definition, Equation (4.21), we 
write the left-hand side as 
et(2z-t) = Ft" (22 - t)" 
n! 
n=O 
(4.26) 
(4.27) 
%n-m n+m 
0 0 0 0  
t
.
 
n=Om=O 
Making the replacement 
n+m+n' 
and dropping primes, we obtain 
(4.28) 
(4.29) 

OTHER DEFINITIONS OF HERMITE POLYNOMIALS 
61 
Comparing this with the right-hand side of Equation (4.25), which is 
(4.30) 
we see that H, (x) is the same as given in Equation (4.21). 
4.2.2 
Rodriguez Formula 
Another definition for the Hermite polynomials is given by the Rodriguez 
formula 
(4.31) 
To see that this is equivalent to the generating function [Eq. (4.25)] we write 
the Taylor series expansion of an arbitrary function F (t) as 
Comparing this with Equation (4.25) we obtain 
(4.32) 
(4.33) 
(4.34) 
(4.35) 
For an arbitrary differentiable function we can write 
(4.36) 
a 
a 
at 
ax 
--f(x - t) = ---f(x - t ) ,  
hence 
an 
an 
--f 
(x - t )  = (-1)"-f 
(x - t ) .  
dt" 
a X n  
Applying this to Equation (4.35), we obtain the Rodriguez formula as 
(4.37) 

62 
HERMITE POLYNOMIALS 
4.3 
RECURSION RELATIONS AND ORTHOGONALITY 
Differentiating the generating function of the Hermite polynomials, first with 
respect to x aad-then with respect to t ,  we obtain two recursion relations: 
Hn+l ( x )  = 2xHn ( x )  - 2nHn_1 ( x ) ,  (72 3 l), Hl(X) = 2XHO(X) (4.39) 
and 
H:, (z) = 2nHn-1 (z), (n > l), Hh(X) = 0. 
(4.40) 
To show the orthogonality of the Hermite polynomials we evaluate the integral 
00 
I,, 
= 
dze-x2H, ( x )  H, (z) , 
(n 2 m). 
(4.41) 
J-00 
Using the Rodriguez formula, we write Equation (4.41) as 
After n-fold integration by parts and since n > m, we obtain 
(4.43) 
Since the z dependence of the mth-order Hermite polynomial goes as 
H, (z) = 2,xm + um-2xm-2 + . . . , 
(4.44) 
we obtain 
0 
, n > m  
2"n!Jii 
, n = m  
Inm= { 
7 
(4.45) 
where we have used 

RECURSION RELATIONS AND ORTHOGONALITY 
63 
We now write the orthogonality relation as 
03 
&e-Z2Hn(z)Hm 
(2) = 2"n!J;;Sn,. 
(4.46) 
Using Equation (4.46) we can define a set of polynomials, {& (IC)}, 
where 
(Pn (z) are defined as 
1, 
(4.47) 
and which satisfies the orthogonality relation 
00 
S_ 
dz4n (z) 4m (z) = Snm. 
Since this set is also complete, any sufficiently well-behaved function in the 
interval [-m,m] can be expanded in terms of {4n (z)} as 
(4.48) 
n=O 
where the coefficients Cn are given as 
03 
cn = S_, 
dz'f (z/) 4n (z'). 
(4.49) 
Example 4.1. Gaussian and the Hermite polynomials: In quantum me- 
chanics the wave function of a particle localized around z o  can be given 
as a Gaussian: 
where A is the normalization constant, which is determined by requiring 
the area under f(z) to be unity. Let us find the expansion of this 
function in terms of the Hermite polynomials as 
(4.51) 
This expansion corresponds to the representation of the wave function of 
a particle under the influence of a harmonic oscillator potential in terms 
of the harmonic oscillator energy eigenfunctions. Expansion coefficients 
Cn are determined from the integral 
Cyexp [-"-?' -- 
2 Hn([). 
(4.52) 
'I 
A 

64 
HERMl TE POLYNOMIALS 
Writing this as 
(4.53) 
and defining a new parameter 
(4.54) 
5 0  - 
= t, 
2 
and using the generating function [Eq. (4.25)], we obtain 
(4.55) 
We now use the orthogonality relation [Eq. (4.46)] of the Hermite poly- 
nomials to obtain 
(4.57) 
(4.58) 
Probability of finding a particle in the nth energy eigenstate is given as 
ICnI2. 
Example 4.2. Dipole calculations in quantum mechanics: In quantum 
mechanics and in electric dipole calculations we encounter integrals like 
where e is the electric charge. Let us write this as 
We now use the generating function definition of the Hermite polyne 
mials to write 
J-00 
(4.61) 
I 
0 0 0 0  
= xx& [ ~ ~ & e - x z H n ( z ) H m ( z ) z  
tnsm. 
n = h = O  

RECURSION RELATIONS AND ORTHOGONALITY 
65 
If we show the expression inside the square brackets on the right-hand 
side as J,, 
, integral I,, 
will be given as 
e 
Jnm. 
In,= &GKFhGqK 
Writing the left-hand side of Equation (4.61) explicitly we get 
00 
&e-t2+2tx 
- 2 + 2 s x  
- 1 2  
e 
e
x
 
(4.62) 
= e2st (s + t )  ,h, 
(4.63) 
where we have defined 
u = x - ( s + t ) .  
(4.64) 
Expanding this in power series oft and s gives us 
(4.65) 
Finally, by comparing with 
1 7 
[ ~ n r n l t ~ s ~ ,  
n.m. 
n=Om=O 
(4.66) 
we obtain the desired result as 
J,, 
= 0 
=+ rn,=o 
for 
m # n F l  
Jn,n+l = ,/F2"(n + I)! 
=+ 
= e [(n + 1)/21"~ for 
m = 7~ + I 
Jn,nP1 = ,/FT-'n! 
* ~
~
,
~
-
l
 
= e J n 7 2  
for 
m =  n -  1. 
We can also write this result as 

66 
HERMITE POLYNOMIALS 
Problems 
4.1 For the Hermite polynomials given the recursion relation 
(2k - 2n) 
(k + 2) ( k  + 1) ' 
ak+2 = a k  
show that one can write the coefficients of the decreasing powers of x for the 
R. t h-order polynomial as 
. n(n - 1) (n - 2) (n - 3 ) - . -  (n - 2 j  + 1) 
a,-2j 
= (-1)' 
an 
8 2 4 .  . f 2 j  
or 
4.2 
given as 
For a three-dimensional harmonic oscillator the Schrodinger equation is 
fi2 
1 
2m 
2 
--?@(7) 
+ -w2r2\k(?'f) = E @ ( 7 ) .  
Using the separation of variables technique find the ordinary differential equa- 
tions to be solved for r,Q,and 4. 
4.3 Quantum mechanics of thethree dimensional harmonic oscillator leads 
to the following differential equation for the radial part of the wave function: 
+ E-x -- 
&R(X) 2 d R ( x )  
+-- 
[ 
dx2 
x dx 
where x and E are defined in terms of the radial distance r and the energy E 
as 
r 
E 
x = -  
and 
E =  - 
Iri 
hW/2 
vmw 
and 1 takes integer values 1 = 0,1,2 ... . 
i) Examine the nature of the singular point at z = 00 . 
ii) Show that in the limit as x --f 00, the solution goes as 
iii) Using the Frobenius method, find an infinite series solution about x = 0 
in the interval [0, m]. Check the convergence of your solution. Should your 
solution be finite everywhere, including the end points of your interval? why? 

PROBLEMS 
67 
iv) For finite solutions everywhere in the interval [0, co], 
what restrictions do 
you have to impose on the physical parameters of the system. v) For 1 = 0,1, 
and 2 find explicitly the solutions corresponding to the three smallest values 
of E .  
4.4 
Show the integral 
4.5 
Prove the orthogonality relation 
00 
e-x2Hm(z)Hn(x)dx 
= 2"n!fi6,, 
J-00 
by using the generating function definition of Hn(x). 
4.6 
k = 0, 1,2 ..., to establish the results 
Expand z2k and z2k+1 
in terms of the Hermite polynomials, where 
z2fi - - 
(2k)! 
H2n ( X) 
- 22k C (2n)!(k - n)! 
n=O 
and 
4.7 Show the following integrals: 
00 
27rn!/(n/a)! }for { n even } 
1, e-x2/2Hn(z)dz 
= { 
nodd 
. 
4.8 
Show that 
4.9 
For positive integers k, m, and n, show that 
J - 0 0  

68 
HERMITE POLYNOMIALS 
4.10 
Prove that 
where 
Rea' > 0 and n = 0, 1,2, ... . 
4.11 
Prove the expansions 
and 
Note that these can be regarded as the generating functions for the even and 
the odd Hermite polynomials. 
4.12 
Show that the integral 
xm 
Hn(x)dx = 0 
- x 2  
is true for m integer and 
0 6 m ,< n- 1. 
4.13 
The hypergeometric equation is given as 
@Y 
dY 
2( 1 - z)- 
+ [y - (a + p + 1 ) 4 -  - aPy(z) = 0, 
da:2 
dx 
where a, P, and y are arbitrary constants, (y # integer and y # 0). 
i) Show that it has the general solution 
y(2) = CoF(a, P, y; 
.) + ClF(Q - y + 1, P - y + 1,2 - 7; 
x), 
valid for the region 1x1 < 1 and CO and C1 are arbitrary integration constants, 
and the hypergeometric function is defined by 
with (a),=a(a+l)(a+2)--.(a+k-l). 
ii) If a regular series solution is required for the entire interval [-1,1], the 

PROBLEMS 
69 
above series will not serve as the solution. What conditions do you have to 
impose on a, to ensure a regular solution in this case? 
iii) Show that Legendre polynomials can be expressed as 
1-2 
2 
P ~ ( z )  
= F(-l,l+ 1,l; -). 
4.14 
guerre polynomials: 
Establish the following connections between the Hermite and the La- 
4.15 
Derive the following recursion relations: 
Ifn+, (z) = 2xH, (z) - 2nH,-1 (z) 
and 

This Page Intentionally Left Blank

5 
GEGENBAUER and 
CHEBYSHEV 
POL YNOMIA LS 
In the study of oscillations and waves, sine and cosine functions play a cen- 
tral role. They come from the solutions of the wave (Helmholtz) equation 
in Cartesian coordinates with the appropriate boundary conditions. They 
also form a basis for representing general waves and oscillations of various 
types, shapes, and sizes. Solutions of the angular part of the Helmholtz equa- 
tion in spherical polar coordinates are the spherical harmonics. Analogous 
to the oscillations of a piece of string, spherical harmonics correspond to the 
oscillations of a two-sphere. Spherical harmonics also form a complete set 
of orthonormal functions; hence they are very important in many theoreti- 
cal and practical applications. To represent the oscillations of a threesphere 
(hypersphere), along with the spherical harmonics we need the Gegenbauer 
polynomials. They are very useful in cosmology and quantum field theory in 
curved backgrounds. Both the spherical harmonics and the Gegenbauer poly- 
nomials are combinations of sines and cosines. Chebyshev polynomials form 
another complete and orthonormal set of functions, which are closely related 
to the Gegenbauer polynomials. 
5.1 COSMOLOGY AND GEGENBAUER POLYNOMIALS 
Standard models in cosmology are generally accepted as accurately describing 
the global properties of the universe like homogeneity, isotropy, and expansion. 
Among the standard models, closed universes correspond to the surface of a 
71 

72 
GEGENBAUER AND CHEBYSHEV POLYNOMIALS 
hypersphere (three-sphere), where the line element is given as 
ds2 = dt2 - &(t)2[dX2 +sin2xd2 +sin2xsin26dq52], (we set c=1). (5.1) 
Angular coordinates x, 8, and 4 have the ranges 
x E [O, TI 7 Q E [O, TI i 4 E [0,274, 
(5.2) 
t is the universal time, and &(t) is the radius of the hypersphere. We now 
consider the wave equation for the massless conformal scalar field in a closed 
static universe, 
1 
w t ,  x, 694) + -+(4 
x, Q, 4) = 0, 
R, 
(5.3) 
where 
is the d’Alembert (wave) operator, 
I3 = g,,a,a,, 
(5.4) 
with 8, standing for the covariant derivative. Explicit evaluation of Equation 
(5.3) is beyond the scope of this chapter (see Chapter 10); hence we suffice by 
saying that a separable solution of the form 
w, 
x,6, 4) = W)X(X)Y(Q, 4) 
(5.5) 
reduces Equation (5.3) to 
- 
1 [-y 
R: sin2 x Y(@, 4) 
Since t, x, 8, and 4 are independent coordinates, differential equations to be 
solved for T, X and Y are easily found as 
- -W2, 
1 d2T(t) 
T(t) dC2 
(5.7) 

COSMOLOGY AND GEGENBAUER POLYNOMIALS 
73 
w and X are two separation constants. For wave problems w corresponds to 
the angular frequency. 
Two linearly independent solutions of Equation (5.7) can be immediately 
written as 
T(t) = eiwt and e-iwt, 
(5.10) 
while the Second Equation (5.8) is nothing but the differential equation [Eq. 
(2.182)] that the spherical harmonics satisfy with X and m given as 
X = - 1 ( 1 + 1 ) ,  
I=O,1,2 ,..., and m = O , f l ,  ..., f l .  
(5.11) 
Before we try a series solution in Equation (5.9) we make the substitution 
X ( X )  = Co sin' ~ ~ ( c o s x ) ,  
(5.12) 
where 
z = cosx, x E [-I, 11 
(5.13) 
and obtain the following differential equation for C(x): 
Substitution (5.12) is needed to ensure a two-term recursion relation with the 
Frobenius method. This equation has two regular singular points at the end 
points 2 = 3~1. We now try a series solution of the form 
(5.15) 
to get 
uQcr(a - l)z"-2 + U l c u ( Q  + 1)Zf-l 
03 
f 
-y{uk+2(k + Q + 2)(k + Q + 1) 
k=O 
- U k [ ( k  f @)(k + (Y - 1) + (21 4- 3)(k fa) - A]}&" 
= 0. 
(5.16) 
In this equation A is defined as 
(5.17) 
1 
A = -1(1+ 
2) + (w2 - -)@. 
% 

74 
GEGENBAUER AND CHEBYSHEV POLYNOMIALS 
Equation (5.16) cannot be satisfied for all x unless the coefficients of all the 
powers of x are zero, that is 
(5.18) 
(IOQ((Y - 1) = 0, a0 # 0, 
ala(a + 1) = 0, 
(5.19) 
a)(k + (Y - 1) + (21 + 3)(k + a) - A 
ak+2 = a k  [@+ 
( k + ( Y + 2 ) ( k + a + l )  
k=O,1,2 ,..‘. 
(5.21) 
The indicia1 Equation (5.18) has two roots, 0 and 1. Starting with the smaller 
root, (Y = 0, we obtain the general solution as 
(5.22) 
L 
where a0 and a1 are two integration constants and the recursion relation for 
the coefficients is given as 
, 
k = 0 , 1 , 2  ,.” 
k(k - 1) + (2l+ 3)k - A 
a k + 2  = a k  
From the limit 
(5.23) 
(5.24) 
1 
we see that both of these series diverge at the end points, x = 3z1, as -. 
To avoid this divergence we terminate the series by restricting W& to integer 
values given by 
1 - 2 2 ’  
(5.25) 
Polynomial solutions obtained in this way can be expressed in terms of the 
Gegenbauer polynomials. Note that these frequenck mean that one can only 
fit integer multiples of full wavelengths around the circumference, 2 ~ & ,  of 
the universe, that is, 
(IfN)XN=2T&, 
N=0,1,2 ,... . 
(5.26) 
Using the relation 
W N  = 
we easily obtain the frequencies of Equation (5.25). 

GEGENBAUER EQUATION AND 1TS SOLUTlONS 
75 
5.2 
GEGENBAUER EQUATION AND ITS SOLUTIONS 
The Gegenbauer equation is in general written as 
d2CX (x) 
dCx (x) 
dx2 
dx 
(1 - x
2
)
L
 
- (2X + 1
)
x
Z
 + n(n + 2X)C;(z) 
= 0. 
(5.27) 
For X = 1/2, this equation reduces to the Legendre equation. For the integer 
values of n, its solutions reduce to the Gegenbauer or the Legendre polyno- 
mials as: 
(5.28) 
5.2.1 
The orthogonality relation of the Gegenbauer polynomials is given as 
Orthogonality and the Generating Function 
The generating function of the Gegenbauer polynomials is defined as 
M 
= x C ; ( ~ ) t " ,  It1 < 1, 1x1 5 1, X > -1/2. 
(5.30) 
1 
(1 - 2xt + t 2 ) X  
n=O 
We can now write the solution of Equation (5.14) in terms of the Gegenbauer 
polynomials as C:!,(x), and the complete solution for the wave Equation 
(5.3) becomes 
(5.31) 
+(t,x,O,4) = (cleiWNt + C Z e - i u N t  )(sin' x ) C ~ ~ , ( c o s x ) ~ m ( 8 ,  
4) 
5.3 
CHEBYSHEV EQUATION AND POLYNOMIALS 
5.3.1 
Polynomials defined as 
Chebyshev Polynomials of the First Kind 
Tn(cosx) = cos(nx), n = 0,1,2 ... 
(5.32) 
are called the Chebyshev polynomials of first kind, and they satisfy the Cheby- 
shev equation 
where we have defined 
x = cosx. 
(5.33) 
(5.34) 

76 
GEGENBAUER AND CHEBYSHEV POLYNOMIALS 
5.3.2 
The Chebyshev equation after (1 + 1)-fold differentiation yields 
Relation of Chebyshev and Gegenbauer Polynomials 
d1+3 (cm nx) 
d'+2 (cos nx) 
( l - x 2 )  
- (21 + 3)" 
dx1+3 
dx1+2 
(5.35) 
d'+l (cos nx) 
+ [-12 - 21 - 1 + n2] 
= 0, 
dxl+l 
where n = 1,2, ... . We now rearrange this as 
dL 
d 
dx 
{ (1 - x2)s - [2(1+ 1) + I] x- + (n - 1 - 1) [(n - 1 - 1) + 2(1+ l)] 
(5.36) 
L 
J 
and compare with Equation (5.27) to obtain the following relation between 
the Gegenbauer and the Chebyshev polynomials of the first kind 
d'+lTn ( X )  , n = 1 , 2  ,.... 
- 
- 
dxl+I 
(5.37) 
(5.38) 
5.3.3 
Chebyshev polynomials of the second kind are defined as 
Chebyshev Polynomials of the Second Kind 
Un(x) = sin(nX), n = O,1,2 ... , 
(5.39) 
where x = cosx. Chebyshev polynomials of the first and second kinds are 
linearly independent, and they both satisfy the Chebyshev Equation (5.33). 
In terms of x the Chebyshev polynomials are written as 
and 

CHEBYSHEV EQUATION AND POLYNOMIALS 
77 
For some n values Chebyshev polynomials are given as 
Chebyshev Polynomials of the First Kind 
TI(.) = s 
2 
T2(z) = 22 - 1 
T3(2) = 4z3 - 32 
T ~ ( Z )  
= 8x4 - 8s2 + 1 
Chebyshev Polynomials of the Second Kind 
u, = 0 
U2(z) = J r n ( 2 x )  
U3(2) = J-(4Z2 
- I) 
U4(2) = J r n ( 8 s 3  - 4s) 
(5.42) 
(5.43) 
U5(z) = J m ( 1 6 z 4  - 12z2 + 1) 

78 
GEGENBAUER AND CHEBYSHEV POLYNOMIALS 
5.3.4 
Orthogonality and the Generating Function of Chebyshev 
Polynomials 
The generating functions of the Chebyshev polynomials are given as 
and 
(5.45) 
Their orthogonality relations are 
and 
5.3.5 
Another Definition for the Chebyshev Polynomials of the Second 
Kind 
Sometimes the polynomials defined as 
- 
U,(x) = 1 
- 
U3(Z) = 823 - 452 
- 
U4(x) = 16x4 - 12x2 + 1 
(5.48) 
are also referred to as the Chebyshev polynomials of the second kind. They 
are related to Un(z) by 
= un+l(x), 
n = 0,1,2, ... . 
(5.49) 

PROBLEMS 
79 
- 
U,(x) satisfy the differential equation - 
dun(z) + n(n + 2)v,(x) = 0, 
(5.50) 
d2cn (x) 
(1 - 2)- 
- 3z- 
dx2 
dx 
and their orthogonality relation is given as 
(5.51) 
Note that even though gm(x) are polynomials, Um(z) are not. The generating 
function for flm(x) is given as 
Tn(x) and un(x) 
satisfy the recursion relations 
(1 -2)TA(x) = -nxT,(z) +nTn-l(x) 
(1 - x2)u;(z) = -nxcn(x) + (n + 1)Vn-l(S). 
(5.53) 
and 
(5.54) 
Special Values of the Chebyshev Polynomials 
Problems 
5.1 Observe that the equation 

80 
GEGENBAUER AND CHEBYSHEV POLYNOMIALS 
gives a three-term recursion relation and then drive the transformation 
which gives a differential equation for C ( c 0 s x )  with a two-term recursion 
relation. 
5.2 
Using the line element 
ds2 = c2dt2 - &(t)2[dX2 + sin2 xdB2 + sin2 Xsin2 13d4~], 
find the spatial volume of a closed universe. What is the circumference? 
5.3 Show that the solutions of 
(1-z2)--(21+3)xF 
d 2 C ( x )  
[ 
1 
dC(x) + -1(1+ 
2) + (u; - - 
dx2 
R?i 
can be expressed in terms of Gegenbauer polynomials as 
c? 
1 (x) , 
where 
5.4 
Show the orthogonality relation of the Gegenbauer polynomials: 
5.5 
Show that the generating function 
1 
= CC2(X)t", 
n=O 
(1 - 2xt + t 2 ) X  
can be used to define the Gegenbauer polynomials. 
5.6 
equation 
Using the Frobenius method, find a series solution to the Chebyshev 
d 2 W  
dY(X) 
2 
( 1 - x2) - 
- z- 
+ n y (x) = 0, z E [- 1, I] . 
dx2 
dx 
For finite solutions in the entire interval [-1,1] do you have to restrict n to 
integer values? 

PROBLEMS 
81 
5.7 Show the following special values: 
and 
5.8 
Show the relations 
5.9 Using the generating function 
show that 
5.10 Show that Tn(z) and Un(z) 
satisfy the recursion relations 
(1 -z2)T;(2) = -nzTn(z) +nTn_l(z) 
and 
(1 - 22)u;(z) = -nzU,(z) + nUn-l(.). 
5.11 Using the generating function 
00 
1 
= EC2(z)t", 111 < 1, 1x1 5 1, x > -1/2, 
n=O 
(1 - 22t + t2)X 

82 
GEGENBAUER AND CHEBYSHEV POLYNOMIALS 
show 
5.12 Let x = cos x and find a series expansion of 
dl+’ (cos nx) 
d(cos x)‘+’ 
C(z) = 
in terms of z. 
5.13 Using 
show that for X = 1/2 Gegenbauer polynomials reduce to the Legendre poly- 
nomials, that is 
CA’2(2) = Pn(z). 
5.14 Prove the recursion relations 
Tn+l(~)-2~Tn(z) 
+Tn-~(z) 
= O  
and 
Un+1 
(z) - 2zUn(z) + un- 1 (z) = 0. 
5.15 
Show the relations 
Chebyshev polynomials Tn(z) and Un(z) can be related to each other. 
(1 - z”)’/2Tn(z) = Un+l(z) - zUn(z) 
(1 - z2)”2Un(z) = zTn(z) - T,+l(S). 
and 
5.16 Obtain the Chebyshev expansion 
1 
03 
- 1)-1T2s(~) . 

BESSEL FUNCTIONS 
The important role that trigonometric and hyperbolic functions play in the 
study of oscillations is well known. The equation of motion of a uniform rigid 
rod of length 21 suspended from one end and oscillating freely in a plane is 
given as 
IB = -mglsint?. 
(6.1) 
In this equation I is the moment of inertia, m is the mass of the rod, g is the 
acceleration of gravity, and 6 is the angular displacement of the rod from its 
equilibrium position. For small oscillations we can approximate sin B with 6; 
thus the general solution is given in terms of trigonometric functions as 
6(t) = Acoswot + Bsinwot , 
(wi = mgl/I) . 
(6.2) 
Suppose the rod is oscillating inside a viscous fluid exerting a drag force 
proportional to 8. Now the equation of motion will be given as 
13 = --ke - mglo, 
(6.3) 
where k is the drag coefficient. For low viscosity the general solution is still 
expressed in terms of trigonometric functions albeit an exponentially decaying 
amplitude. However, for high viscosity, (k/21)2 > wg, we need the hyperbolic 
functions, where the general solution is now given as 
q t )  = e - ( k / 2 W  [Acosh qot + B sinh got] , 
(9: = ( l ~ / 2 1 ) ~  
- wi) . 
(6.4) 
83 

84 
BESSEL FUNCTIONS 
Fig. 6.1 Flexible chain 
We now consider small oscillations of a flexible chain with uniform density 
po(g/cm) and length 2. We assume that the loops are very small compared 
to the length of the chain. We show the distance measured upwards from the 
free end of the chain with x and use y(z,t) to represent the displacement of 
the chain from its equilibrium position (Fig. 6.1). For small oscillations we 
assume that the change in y with x is small; hence ay/ax << 1. We can write 
the y-component of the tension along the chain as Ty(x) = pogx(ay/dx). This 
gives the restoring force on a mass element of length Ax as 
We can now write the equation of motion of a mass element of length Ax as 
Since Ax is small but finite, we obtain the differential equation to be solved 
for y(x,t) as 
We separate the variables as 

BESSEL’S EQUATJON 
85 
to obtain 
where w is a separation constant. Solution for v(t) can be written immediately 
as 
v(t) = cocos(wt - 6), 
(6.9) 
while u(z) satisfies the differential equation 
d2u 
du 
w2 
dx2 
ds 
g 
z- 
+ - + -?A(.) 
= 0. 
After defining a new independent variable 
z = 2 E ,  
the differential equation to be solved for u(z) becomes 
d2u 
l d u  
dz2 
z d z  
- 
+ -- + w2u(z) = 0. 
(6.10) 
(6.11) 
(6.12) 
To express the solutions of this equation we need a new type of function 
called the Bessel function. This problem was first studied by Bernoulli in 
1732, however, he did not recognize the general nature of these functions. As 
we shall see, this equation is a special case of Bessel’s equation. 
6.1 BESSEL’S EQUATION 
If we write the Laplace equation in cylindrical coordinates as 
8 2 9  
I d 9  
l a 2 9  
8 2 9  
- 
+--+--+- 
= o  
ap2 
p dp 
p2 a42 
dz2 
and try a separable solution of the form 
(6.13) 
W P ,  4 , 4  = %)@(4)Z(z), 
(6.14) 
we obtain three ordinary differential equations to be solved for R(p), @(4), 
and Z(z): 
(6.15) 
(6.16) 

86 
BESSEL FUNCTIONS 
(6.17) 
Solutions of the first two equations can be written immediately as 
Z ( z )  = Zlekz + F2e-kP 
(6.18) 
and 
@(4) = cleimb + cae-im@. 
(6.19) 
The remaining Equation (6.17) is known as the Bessel equation and, with the 
definitions 
z = k p  and R(p) = Jm(z), 
(6.20) 
can be written as 
1 
m2 
J L ( z )  + -J:,(z) + (1 - -+Jm(z) 
= 0. 
X 
X 
(6.21) 
Solutions of this equation are called the Bessel functions of order m, and they 
are shown as Jrn(z). 
6.2 
SOLUTIONS OF BESSEL’S EQUATION 
6.2.1 Bessel Functions J i r n ( z ) ,  Nrn(z), 
and H2y2)(z) 
Series solution of Bessel’s equation is given as 
(6.22) 
which is called the Bessel function of the first kind of order m. A second 
solution can be written as 
00 
J-m(z) = c 
r=O 
(6.23) 
However, the second solution is independent of the first solution only for the 
noninteger values of m. For the integer values of m the two solutions are 
related by 
L m ( z )  
= (-l)mJrn(z). 
(6.24) 
When m takes integer values, the second and linearly independent solution 
can be taken as 
(6.25) 

SOLUTIONS O f  BESSEL’S EQUATION 
87 
which is called the Neumann function or the Bessel function of the second 
kind. Note that N,(z) and Jm(z) are linearly independent even for the 
integer values of m. Hence it is common practice to take N,(z) and Jm(z) 
as the two linearly independent solutions for all n. 
Other linearly independent solutions of Bessel’s equation are given as the 
Hankel functions: 
H:)(z) = J,(Lc) + iN,(z), 
(6.26) 
HZ’(2) = Jm(z) - iN,(z). 
(6.27) 
They are also called the Bessel functions of the third kind. 
as 
In the limit as z -+ 0 Bessel function Jm(z) is finite for m 2 0 and behaves 
lim Jm(z) + 
(C)? 
x-0 
r ( m f 1 )  2 
(6.28) 
All the other functions diverge as 
where y = 0.5772 ... . In the limit as z + co functions J,(z), N,(z), H:)(z), 
and Hg’(z) behave as 
(6.30) 
(6.31) 
(6.32) 
(6.33) 

88 
BESSEL FUNC JIONS 
6.2.2 
If we take the argument of the Bessel functions Jm(x) and Hc)(x) as imagi- 
nary we obtain the modified Bessel functions 
Modified Bessel Functions I,(Z) 
and K , ( Z )  
(6.34) 
Jm (ax) 
Im(x) = - 
2” 
and 
(6.35) 
These functions are linearly independent solutions of the differential equation 
(6.36) 
7ra . 
2 
K,(X) = -(qW$(Zz). 
m2 
(1 + y ) R ( X )  = 0. 
d2R(x) 
1 dR(x) 
+ -- 
- 
dx2 
x dx 
X 
Their z -+ 0 and z -+ 
00 limits are given as (real m 2 0) 
(6.37) 
X m  
lim Im(x) -+ 
x-0 
2”r(m + 1) ’ 
and 
(6.39) 
6.2.3 
Spherical Bessel functions jl(x), ni(x), and h1(”2)(x) are defined as 
Spherical Bessel Functions j ,  ( z), nl( z), and 
( Z) 
(6.40) 
(6.41) 

OTHER DEFINITIONS OF THE BESSEL FUNCTIONS 
89 
Bessel functions with half integer indices, J1++(x) and N,++(x), satisfy the 
differential equation 
while the spherical Bessel functions, jl(x), nl(x), and hi1'2)(x) satisfy 
Spherical Bessel functions can also be defined as 
1
.
 
j[(X) = (-.)"'A) 
-, 
sin x 
xdx 
x 
n1(.) = (-x), (;g(---) 
cos x 
Asymptotic forms of the spherical Bessel functions are given as 
X1 
2 2  +.-), x < 1 ,  
jdx) --+ 
(21 + l)!! (1 - 2(2l+ 1) 
(21 - l)!! 
2 2  
--f - xl+l 
(1 - 2(1- 21) +---), x < 1 ,  
1 
LIT 
jl(x) = ;sin(x - -), 
x >> 1, 
X 
1 
171. 
ndx) = -- COS(X - -), 
x >> 1, 
X 
X 
(6.42) 
(6.43) 
(6.44) 
(6.45) 
(6.46) 
where (21 + l)!! = (21 + 1)(21- l)(2l- 3) . .. 5 . 3  . 1. 
6.3 OTHER DEFINITIONS OF THE BESSEL FUNCTIONS 
6.3.1 Generating Function 
Base1 function Jn(x) can be defined by a generating function T(x,t) as 
(6.47) 
n=--03 

90 
BESSEL FUNCTIONS 
6.3.2 
Integral Definitions 
Bessel function J,(x) also has the following integral definitions: 
(6.48) 
and 
1 
2 
(1 - t2)n-6 cosztdt, 
(n > --). 
(6.49) 
Jn(IL.1 = 
6.4 
RECURSION RELATIONS OF THE BESSEL FUNCTIONS 
Using the series definitions of the Bessel functions we can obtain the following 
recursion relations 
and 
First by adding and then by subtracting these equations we also obtain the 
relations 
m 
J m - l ( X )  = -Jm(IL.) 
+ J:,(X) 
(6.52) 
X 
and 
(6.53) 
Other Bessel functions, N,, Hi1’, and Hi2), satisfy the same recursion rela- 
t ions. 
6.5 
ORTHOGONALITY AND THE ROOTS OF THE BESSEL 
FUNCTIONS 
From the asymptotic form [Eq. (6.30)j of the Bessel function it is clear that 
it has infinitely many roots: 
J,(Z,~) = 0, 
1 = 1,2,3,. . . . 
(6.54) 

BOUNDARY CONDITIONS FOR THE BESSEL FUNCTIONS 
91 
%,I 
stands for the Ith root of the nth order Bessel function. When n takes 
integer values the first three roots are given as 
n = 0 
x01 = 2.405 
5.520 8.654 
. . . 
n= 2 
221 =5.136 
8.417 
11.620 ... 
=z 1 
2 1 1  = 3.832 
7.016 
10.173 ... 
(6.55) 
Higher-order roots are approximately given by the formula 
17r 
Znl ?2 l7r+ (n - -)- 
2 2' 
(6.56) 
The Bessel functions' orthogonality relation in the interval [0, u] is given as 
(6.57) 
Since Bessel functions also form a complete set, any sufficiently smooth func- 
tion, f(p), in the interval 
can be expanded as 
(6.59) 
where the expansion coefficients A,l are found from 
6.6 BOUNDARY CONDITIONS FOR THE BESSEL FUNCTIONS 
For the roots given in Equation (6.55) we have used the Dirichlet boundary 
condition, that is, 
R(a) = 0. 
(6.61) 
In terms of the Bessel functions this condition implies 
Jn(ka) = 0 
(6.62) 
and gives us the infinitely many roots [Eq. (6.55)] shown as 
xn1. 
(6.63) 

92 
BESSEL FUNCTIONS 
Now the functions 
P 
{Jn(Xnl,)}, 
n 2 0 
(6.64) 
form a complete and orthogonal set with respect to the index 1. The same 
conclusion holds for the Neumann boundary condition 
TIpEa 
= 0 
and the general boundary condition 
p=a 
(6.65) 
In terms of the Bessel function Jn(kr), Neumann and general boundary con- 
ditions are written as 
dx 
x=ka = O  
and 
(6.67) 
(6.68) 
respectively. For the Neumann boundary condition [Eq. (6.67)] there exist 
infinitely many roots, which can be found from tables. However, for the 
general boundary condition roots depend on the values that A0 and Bo take; 
thus each case must be handled separately by numerical analysis. From all 
three types of boundary conditions we obtain a complete and orthogonal set 
as 
r 
a 
{Jn(xnl-)} , 1 = 1,2,3, ... . 
(6.69) 
Example 6.1. Flexible chain problem: 
We now return to the flexible 
chain problem, where the equation of motion was written as 
d2u 
l d u  
dz2 
z d z  
- 
+ -- + w2u = 0. 
(6.70) 
General solution of this equation is given as 
Since No(wz) diverges at the origin, we choose a1 as zero and obtain the 
displacement of the chain from its equilibrium position as (Fig. 6.2) 
y(x, t) = aoJ0(2w&)cos(wt 
- 6). 
(6.72) 

BOUNDARY CONDITIONS FOR THE BESSEL FUNCTIONS 
93 
Fig. 6.2 Jo and No functions 
If we impose the condition 
y(4 t) = J o ( 2 w n m )  = 0, 
we find the normal modes of the chain as 
X r 
2 w n a  = 2.405, 5.520, ... , (n = 1,2, ...). 
(6.73) 
If the shape of the chain at t = 0 is given as f(z), 
we can write the 
solution as 
co 
y ( z , t )  = C AnJo(2wnJ&) 
ca(wnt - S), 
(6.74) 
n=l 
where the expansion coefficients are given as 
Example 6.2. Tsunamis and wave motion in a channel: Theequation 
of motion for one dimensional waves in a channel with breadth b(z) and 
depth h(z) is given as 
(6.75) 

94 
BESSEL FUNCTIONS 
where ~ ( x ,  
t) is the displacement of the water surface from its equilib- 
rium position and g is the acceleration of gravity. If the depth of the 
channel varies uniformly from the end of the channel, x = 0, to the 
mouth (x = u) as h(x) = b z / u  we can try a separable solution of the 
form 
~ ( x ,  
t )  = A(x) cos(wt + a) 
(6.76) 
to find the differential equation that A(z) satisfies as 
f (22) 
+ kA = 0, 
(6.77) 
where k = w2a/gho. 
obtained as 
Solution that is finite at x = 0 can easily be 
(6.78) 
or as 
A( X )  = A&( 2k1l22 
1'2). 
(6.79) 
After evaluating the constant & we write the final solution as 
(6.80) 
With an appropriate normalization a snapshot of this wave is shown 
in Fig. 6.3. Note how the amplitude increases and the wavelength d e  
creases as shallow waters is reached. If hb is constant or at least a 
slow varying function of position, we can take it outside the brackets 
in Equation (6.75), thus obtaining the wave velocity as &. This is 
characteristic of tsunamis, which are wave trains caused by sudden dis- 
placement of large amounts of water by earthquakes, volcanos, meteors, 
etc. Tsunamis have wavelengths in excess of 100 km and their period 
is around one hour. In the Pacific Ocean, where typical water depth is 
4000 m, tsunamis travel with velocities over 700 km/h. Since the en- 
ergy loss of a wave is inversely proportional to its wavelength, tsunamis 
could travel transoceanic distances with little energy loss. Because of 
their huge wavelengths they are imperceptible in deep waters; however, 
in reaching shallow waters they compress and slow down. Thus to con- 
serve energy their amplitude increases to several or tens of meters in 
height as they reach the shore. 
When both the breadth and the depth vary as b(x) = box/u and h(z) = 
hox/u, respectively, the differential equation to be solved for A( z)  b e  
comes 
&A 
dA 
dx2 
dx 
z- 
f2- + k A  =o, 
(6.81) 

WRONSKIANS OF PAIRS OF SOLUTIONS 
95 
I Y  
Fig. 6.3 Channel waves 
where k = w2a/gho as before. The solution is now obtained as 
- - - - ) c o s ( w ~ + ~ ) ,  (6.82) 
kX 
k2X2 
v ( ~ , t )  
= Ao(1- - 
(1.2) + (1.2). (2.4) 
which is 
(6.83) 
6.7 
WRONSKIANS OF PAIRS OF SOLUTIONS 
The Wronskian of a pair of solutions of a second-order linear differential equa- 
tion is defined by the determinant 
(6.84) 
= ulu; - u2u:. 
The two solutions are linearly independent if and only if their Wronskian does 
not vanish identically. We now calculate the Wronskian of a pair of solutions 
of Bessel’s equation 
m2 
1 
2 
X2 
(6.85) 
u”(z) + -u’(x) + (1 - -)u(x) = 0, 

96 
BESSEL FUNCTIONS 
thus obtaining a number of formulas that are very helpful in various calcula- 
tions. For two solutions u1 and 212 we write 
d 
m2 
-(mi) 
+ ( 1  - - ) u 1 ( x )  
= 0, 
dx 
X 2  
-(zu;) 
d 
+ (1 - - ) ) " 2 ( 2 )  
m2 
= 0. 
dx 
2 2  
(6.86) 
(6.87) 
We multiply the second equation by u 1  and subtract the result from the first 
equation multiplied by u 2  to get 
(6.88) 
d 
dx 
- 
{ZW [u1 (x), 
..2(.)1} 
= 0. 
This means 
(6.89) 
where C is a constant independent of x but depends on the pair of functions 
whase Wronskian is calculated. For example, 
C 
w [u1 ( X I ,  u2(x)1 = ;
>
 
(6.90) 
(6.91) 
(6.92) 
Since C is independent of x it can be calculated by using the asymptotic forms 
of these functions in the limit x -+ 0 as 
2 
w [ J m b ) ,  xTl(xc>I = G, 
w pm(x),H,2)(x)] = -- 
w [H:)(x),H,2)(z)] = --&. 42 
22 
T X '  
C = lim XW 
[ u 1  (z), u 2 ( x ) ] .  
(6.93) 
x i 0  

PROBLEMS 
97 
Problems 
6.1 
Drive the following recursion relations: 
and 
Jm-l(z) - Jm+l(x) = 2Jk(x), m = 1,2,. . . 
Use the first equation to express a Bessel function of arbitrary order (m = 
0, 1,2, ...) in terms of JO and 51. Show that for m = 0 the second equation is 
replaced by 
6.2 
Write the wave equation 
in spherical polar coordinates. Using the method of separation of variables 
show that the solutions for the radial part are given in terms of the spherical 
Bessel functions. 
6.3 
antenna. On the surface, T = a, take the solution as 
Use the result in Problem 6.2 to find the solutions for a spherically split 
and assume that in the limit as T -+ 00 solution behaves as 
6.4 
Solve the wave equation 
1 a2* 
W 
212 a t 2  
C 
- -- = 0, k = - = wave number, 
for the oscillations of a circular membrane with radius a and clamped at the 
boundary. What boundary conditions did you use? What are the lowest three 
modes? 
6.5 
Verify the following Wronskians: 
n 

98 
BESSEL FUNCTIONS 
6.6 
Find the constant C in the Wronskian 
6.7 
Show that the stationary distribution of temperature, T(p, z), in a cylin- 
der of length 2 and radius a with one end held at temperature TO while the 
rest of the cylinder is held at zero is given as 
Hint: Use cylindrical coordinates and solve the Laplace equation, 
a‘”(p, 
2 )  = 0, 
by the method of separation of variables. 
6.8 
temperature f(p). Solve the heat transfer equation 
Consider the cooling of an infinitely long cylinder heated to an initial 
with the boundary condition 
and the initial condition 
T ( P ,  0) = f(P) (finite). 
T(p,t) is the temperature distribution in the cylinder and the physical pa- 
rameters of the problem are defined as 
Ic - thermal conductivity 
c - heat capacity 
po - density 
X - emissivity 
and h = X/k. Hint: Use the method of separation of variables and show that 
the solution can be expressed as 
then find C, so that the initial condition T(p,O) = f(p) is satisfied. Where 
does z, 
come from? 

7 
HYPER GEOMETRIC 
FUNCTIONS 
The majority of the second-order linear ordinary differential equations of sci- 
ence and engineering can be conveniently expressed in terms of the three 
parameters (a, b, c) of the hypergeometric equation: 
z(l - x)- d y ( z ) + [ c - ( a + b + l ) x ] -  dY (XI -aby(x)=O. 
(7.1) 
dx2 
dx 
Solutions of the hypergeometric equation are called the (Gauss’s) hypergeo- 
metric functions, and they are shown as F(a, b, c; x). 
7.1 HYPERGEOMETRIC SERIES 
The hypergeometric equation has three regular singular points at z = 0 , l  and 
00; hence we can find a series solution about the origin by using the Frobenius 
method. Substituting the series 
03 
y = CarxJ+T, a0 # 0, 
r=O 

100 
HYPERGEOMETRlCFUNCTtONS 
into Equation (7.1) gives us 
00 
x(1- 
r=O 
03 
+{c-(u+b+ 
l ) s ) x u r ( s + T ) z S + r p l  
r=O 
r=O 
which we write as 
00 
x u ,  ( s  + T )  ( s  + T - 1) zs+-l 
r=O 
03 
-Cur (s + ?-) ( s  + T - 1) 2S+r 
r = O  
03 
+cCu, (s + T )  zs+- 
r=O 
00 
00 
- (u + b + 1) x u ,  (s + T )  xs+r - ubxurZs*r = 0. 
(7.4) 
r=O 
r=O 
After rearranging we obtain 
00 x 
[ ( S + T )  ( s  +r - 1 )  +C(S+T)]urzs+r-l 
r=O 
03 -x 
[ ( s + T  - 1 )  ( S + T  - 2) + (a+ b+ 1) ( S  + T  - 1) + ~ b ] ~ , - 1 z ~ + ~ - '  
- 
- 0. 
r=l 
(7.5) 
Writing the first term explicitly this becomes 
Is (s - 1) + sc] u0xs-l 
M 
+ C { [ ( s + r ) ( s + r -  l)+c(s+r)]u, 
r-1 
-u,_l[(s+r- 
1 ) ( s + r - 2 ) + ~ b + ( u + b + 1 ) ( s + ~ - l ) ] } z ~ + ~ - ' -  
- 0. 
(7.6) 
Setting the coefficients of all the equal powers of x to zero gives us the indicia1 
equation 
[s (s - 1) + sc] a0 = 0, 
# 0 
(7.7) 

HYPERGEOMETRIC SERIES 
101 
and the recursion relation 
( s + r -  l + a ) ( s + r -  1+b) 
a, = 
a,-l, 
r 2 1. 
(7.8) 
(s + r )  (s + r - 1 + c) 
Roots of the indicia1 equation are 
s = 0  and s = l - c .  
(7.9) 
For s = 0 we write the recursion relation as 
(T - 1 + a )  (7- - 1 + b) 
(T - 1 + c ) r  
a, = 
ar-1, 
T 2 1 
and obtain the following coefficients for the series: 
ab 
a1 = --a@ 
a2 = 
a1 1 
a3 = 
a2 , 
C 
(a + 1) ( b  + 1) 
( c +  1)2 
(a + 2) ( b  + 2) 
(a + 3) ( b  + 3) 
(c + 3) 4 
(c+2)3 
a4 = 
a3, 
(7.10) 
where the general term is 
a (a + 1) (a+ 2). . . (a + k - 1)b ( b  + 1). . . (b + k - 1) 
ak = a0 
. 
(7.11) 
c ( c +  1) ... ( c +  k - 1) 1 . 2 . 3 - * - k  
Now the series solution can be written explicitly as 
1, 
[ 
c 1 .  
c(c+ l)2! 
2! 
ab x 
a (a + 1) b (b + 1) 22 
y1 (x) = a0 1 + -7 + 
-+... 
where 
c # 0, -1, -2, ... . 
Similarly for the other root, 
s = l - c ,  
(7.12) 
(7.13) 
(7.14) 

102 
HYPERGEOMETRIC FUNCTIONS 
the recursion relation becomes 
(r + a - c) (T + b - c) 
a, = a,-1 
1 
r L 1 ,  
r(1 - c + r )  
which gives the following coefficients for the second series: 
(7.15) 
( a  - c +  1) (b - c + 1) 
(2 - 4 
(a - c + 2) (b - c + 2) 
2 (3 - c) 
3 (4 - c) 
a1 = a0 
I 
a2 = a1 
a3 = a2 
9 
(a - c + 3) ( b  - c + 3) 
7 
where the general term can be written as 
I -  
(a - c +  1) (a - c +  2 ) - - .  (a - c + k )  (b - c +  I)... (b - c +  k )  
(2 - c) (3 - c ) .  . . ( k  + 1 - c) k! 
(7.16) 
ak = a0 
Now the second series solution becomes 
00 
(7.17) 
k=O 
(7.18) 
( a  + 1 - c) (1 + b - c) z 
(2 - c) 
l! 
..+... 
where c # 2,3,4 ... . If we set a0 to 1, y1 (z) becomes the hypergeometric 
function (or series): 
w(.) = F ( a , b , c ; z ) .  
(7.19) 
The hypergeometric function is convergent in the interval 1x1 < 1. For con- 
vergence at the end point z = 1 one needs c > a + b, and for convergence at 
z = -1 one needs c > a + b - 1. Similarly the second solution, y2 (z) , can be 
expressed in term of the hypergeometric function as 
9 2  (x) = ~
~
~
~
8
'
 
(a - c + 1, b - c + 1,2 - 
C ;  Z) , 
c # 2,3,4, __. 
. 
(7.20) 
Thus the general solution of the hypergeometric equation is 
(z) = AF(a, b,c;z) + Bz'-"F(a - c + I, b - C +  1,2 - C; z). 
(7.21) 
Hypergeometric functions are also written as 2F1 (a, b, C; z). 

HYPERGEOMETRIC REPRESENTATIONS OF SPECIAL FUNCTIONS 
103 
Similarly, one can find series solutions about the regular singular point 
z = l a s  
Y 3 ( Z ) = F ( a , b , a + b - c ; l - z ) ,  
(7.22) 
y&) = (1 - z)C-a-bF(c - a, c - b, c - a - b + 1; 1 - z). 
(7.23) 
The interval of convergence of these series is 0 < z < 2. Series solutions 
appropriate for the singular point at infinity are given as 
y&) = C F ( a , u  - c +  l , a  - b + lp-l), 
(7.24) 
96(2) = z-bF(b,b-c+ 1,b-a+ l;z-*), 
(7.25) 
which converge for 1x1 > 1. These constitute the six solutions found by Kum- 
mer. Since the hypergeometric equation can only have two linearly indepen- 
dent solutions, there are linear relations among them like; 
(7.26) 
The basic integral representation of hypergeometric functions is: 
This integral, which can be proven by expanding (1 - tz)-. in binomial series 
and integrating term by term, transforms into an integral of the same type 
by Euler’s hypergeometric transformations: 
t 
+ t, 
t 
--+ 
1-t, 
t 
--t 
t/(l--z+tz), 
t + (I - t)/( I - tz). 
(7.28) 
Applications of the 4 Euler transformations to the 6 Kummer solutions give 
all the possible 24 forms of the solutions of hypergeometric equation. These 
solutions and a list of 20 relations among them can be found in Erdelyi et.al. 
7.2 
HYPERGEOMETRIC REPRESENTATIONS OF SPECIAL 
FUNCTIONS 
The majority of the special functions can be represented in terms of hyper- 
geometric functions. If we change the independent variable in Equation (7.1) 

104 
H YPERGEOMETRK FUNCTtONS 
to 
(7.29) 
the hypergeometric equation becomes 
(1 -t2) 7 
d2Y +[(a+b+ 1 - 2c) - (a+b+ 1)<]- 
dY - d r y  =O. 
(7.30) 
4 
Choosing the parameters a, b, and c as 
a=-v, b = v + l ,  and c = l ,  
(7.31) 
Equation (7.30) becomes 
&Y 
dY 
26- + Y(Y + 1) y = 0. 
d t  
(1 --t7 p - 
(7.32) 
This is nothing but the Legendre equation, finite solutions of which are given 
as the Legendre polynomials: 
YY (t) 
= PY (6). 
(7.33) 
Thus the Legendre polynomials can be expressed in terms of the hypergew 
metric functions as 
P, (6) = F 
-v, Y + 1,l; - 
Y = 0,1,2 )". . 
(7.34) 
( 
-9 
2
'
 
Similarly, we can write the associated Legendre polynomials as 
m-n,m+n+ l,m+l;- I-,) 
(7.35) 
2 
(n + m)! (1 - x y 2  
P," (x) = (n-m)! 
2mm! 
and the Gegenbauer polynomials as 
(7.36) 
1 . 1 - x  
2
2
 
c; (x) = 
-n,n+2X,X+-, 
The main reason for our interest in hypergeometric functions is that so many of 
the second-order linear ordinary differential equations encountered in physics 
and engineering can be expressed in terms of F(a, b, c; z). 
7.3 
CONFLUENT HYPERGEOMETRIC EQUATION 
The hypergeometric equation: 
z(1 - z)- d2y(z) + [c - (a + b + l)z]- dY(Z) - aby(z) = 0, 
dz2 
dz 
(7.37) 

PROBLEMS 
105 
has three regular singular points at z = 0,1, and 03. By setting z = z / b  and 
taking the limit as b + M we can merge the singularities at b and infinity. 
This gives us the confluent hypergeometric equation as 
d2Y 
dY 
z- 
+ (c - z) - - ay = 0, 
dx2 
dz 
(7.38) 
solutions of which are the confluent hypergeometric functions, which are 
shown as M(a,c;z). The Confluent hypergeometric equation has a regular 
singular point at z = 0 and an essential singularity at infinity. Bessel func- 
tions, J, (z) , and the Laguerre polynomials, L, (z) , can be written in terms 
of the solutions of the confluent hypergeometric equation as 
(7.39) 
L, (z) 
= A4 (-n, 1; z) . 
(7.40) 
Linearly independent solutions of Equation (7.38) are given as 
a 
a(a + 1) z2 
a(a + i)(a + 2) z3 
c l! 
c(c+ 1) 2! 
c(c+ l)(c+ 2) 3! 
y1(z) = M(a,c,z) = 1 + -- + ___- + 
-+... 
(7.41) 
c # 0, -1, -2, ... 
and 
y2(%) = z'-"M(a + 1 - C ,  2 - c;z), 
c # 2,3,4, ._. 
(7.42) 
Integral representation of the confluent hypergeometric functions, which are 
also shown as 1 F1 (a, 6; z), can be given as 
dteZtta-l(l -t)c-apl, (reale> reala > O ) .  
(7.43) 
M(a,c;z) = 
Problems 
7.1 Show that the Hermite polynomials can be expressed as 
(an)! 
1 
2(2n + I)! 
3 
H~,(z) = (-1),-M(-n, 
5;z2), 
n! 
zM(-n, -; z2). 
n! 
2 
HZ,+l(S) = (-I), 

106 
H YPERGEOM E TRlC FUNCTIONS 
7.2 Show that associated Legendre polynomials can be written as 
m - n,m +n + l , m +  1; 
(n+m)! (1 - 2 ) Y  
P? 
(2) = 
~ (n-m)! 2"m! 
7.3 Derive the Kummer formula 
M(a, c, z) = e"M(c - a, c; -x). 
7.4 
Show that the associat,ed Laguerre polynomials could be written as 
7.5 
Show that the modified Bessel functions can be expressed as 
n! 
7.6 
tions. 
7.7 
Write the Chebyshev polynomials in terms of the hypergeometric func- 
Show that Gegenbauer polynomials can be expressed as 
-n,n + 2x, x + -; - 
2
2
'
 
c," (x) = n!r (W) 
7.8 Express the solutions of 
8 Y  
1 
1 
dY 
t( 1 - 9)- + 2[y - - - (a + p + -)PI- - 4apty(t) = 0 
dt 2 
2 
2 
dt 
in terms of the hypergeometric functions. Hint: Try the substitution z = t2. 
7.9 Show the following relations: 
(a) (I - z ) - ~  = F(a,P,p;z) (b) In(1 -x) = -zF(1,1,2;z) 
7.10 
tion: 
Derive the following integral representation of the hypergeometric func- 
Use the relation between the beta and the gamma functions: 
1 
where the beta function is defined as B(p, q )  = 
t p - ' ( l  - t)q-'dt, p > 0, 
q > 0. 

ST URM- LIO U VIL LE 
THEORY 
The majority of the frequently encountered partial differential equations in 
physics and engineering can be solved by the method of separation of variables. 
This method helps us to reduce a second-order partial differential equation 
into a set of ordinary differential equations, which includes some new param- 
eters called the separation constants. We have seen that solutions of these 
equations with the appropriate boundary conditions have properties remi- 
niscent of an eigenvalue problem. In this chapter we study these properties 
systematically in terms of the Sturm-Liouville theory. 
8.1 SELF-ADJOINT DIFFERENTIAL OPERATORS 
We define a second-order linear differential operator in the interval [a, b] as 
dL 
d 
dx 
dx 
2 = Po (x) 2 
+ Pl (x) - + P2 (x) , 
(8.1) 
where Pi (x) are real functions with the first (2 - i) derivatives continuous. 
Also, in the open interval (a, 
b), Po (x) does not vanish even though it could 
have zeroes at the end points. We now define the adjoint operator 2 as 

108 
STURM-LIOUVILLE THEORY 
The sufficient and necessary condition for an operator k' to be self-adjoint, 
that is, 
k'=2 
(8.4) 
is, 
PA (z) = PI (z). 
(8.5) 
A self-adjoint operator can also be written in the form 
d 
2u(z)=k'u(z)=- 
dx 
(8.6) 
where 
This is also called the first canonical form. A non-self-adjoint operator can 
always be put into self-adjoint form by multiplying it with 
- 
1 
exp [lZ 
-dx] 
PO(.> 
Among the equations we have seen, the Legendre equation is self adjoint, 
whereas the Hermite and the Laguerre equations are not. 
8.2 
STURM-LIOUVILLE SYSTEMS 
The operator k' defined in Equation (8.6) is called the Sturm-Liouville 
operator. Using this operator we can define a differential equation as 
Lu (z) = -xw (z) u (z) , 
(8.9) 
which is called the Sturm-Liouville equation. This equation defines an 
eigenvalue problem for the operator L', with the eigenvalue -A, eigenfunction 
u(z), and w (z) as the weight function. The weight function satisfies the 
condition w ( z )  > 0 except for a finite number of isolated points, where it 
could have zeroes. 
It is clear that a differential equation alone can not be a complete descrip 
tion of a physical problem. One also needs the boundary conditions to d e  
termine the integration constants. We now supplement the above differential 
equation with the following boundary conditions: 

STURM-LIOUVILLE SYSTEMS 
109 
(8.10) 
(8.11) 
where ~ ( x )  
and ~ ( x )  
are any two solutions of Equation (8.9) with the same or 
different X values. Now the differential equation [Eq. (8.9)] plus the boundary 
conditions [Eqs. (8.10) and (8.11)] is called a Sturm-Liouville system. 
However, we could also work with something less restrictive as 
v(x)P(x)u'(x)lx=a = v ( ~ ) ~ ( ~ ) ~ ~ ( ~ ) l x = ~  
7 
(8.12) 
In general this boundary condition corresponds to one of the following: 
1. Cases where the solutions u ( x )  and the v(x) are zero at the end points; 
x = a and x = b. Such conditions are called the (homogeneous) Dirich- 
let conditions. Boundary conditions for the vibrations of a string fixed 
at both ends are of this type. 
2. Cases where the derivatives - 
du(x) and 9 
are zero at the end points; 
x = a and x = b. Acoustic wave problems require this type of boundary 
conditions, and they are called the (homogeneous) Neumann condi- 
tions. 
3. Cases where u(x) fa- ':!' 
lx=a = 0 and v(x) + /3- 
/i=b = 0, where 
a and /3 are constants independent of the eigenvalues. An example for 
this type of boundary conditions, which are called general unmixed, 
is the vibrations of a string with elastic connections. 
dx 
dx 
4. Cases where one type of boundary conditions is satisfied at x = a and 
another type at x = b. 
du(x) and 
A common property of all these conditions is that the value of - 
dx 
the value of u ( x )  at the end point a are independent of their values at the 
other end point b; hence they are called unmixed boundary conditions. 
Depending on the problem, it is also possible to impose more complicated 
boundary conditions. 
Even though the .~2 operator is real, solutions of Equation (8.9) could 
involve complex functions; thus we write Equation (8.12) as 
and take its complex conjugate: 

110 
STURM-LIOUVILLE THEORY 
Since all the eigenfunctions satisfy the same boundary conditions, we inter- 
change u and u to write 
8.3 
HERMITIAN OPERATORS 
We now show that the self-adjoint operator L and the differential equation 
LEU (x) + xw (x) u (z) = 0, 
(8.16) 
along with the boundary conditions [Eqs. (8.13) and (8.15)] have an interest- 
ing property. We first multiply 
L 4 x )  
from the left with v’ and integrate over [a, b]: 
b 
v*Lu& = 
U* (pu‘)’dx + l u*qudx. 
(8.17) 
Lb 
I” 
Integrating the first term on the right-hand side by parts gives us 
(8.18) 
Using the boundary condition (8.13) the integrated term is zero. Integrating 
the second term in Equation (8.18) by parts again and using the boundary 
condition (8.15) we see that the integrated term is again zero, thus obtaining 
l 
l b u *  (pu’)’dx 
= 
u(p*’)’dx. 
Substituting this result in Equation (8.17) we obtain 
(8.19) 
(8.20) 
Operators that satisfy this relation are called Hermitian with respect to 
the functions u and u satisfying the boundary conditions (8.13) and (8.15). 
In other words, hermiticity of an operator is closely tied to the boundary 
conditions imposed. 
8.4 
PROPERTIES OF HERMITIAN OPERATORS 
Hermitian operators have the following very useful properties: 

PROPERTIES OF HERMITIAN OPERATORS 
111 
1. Eigenvalues are real 
2. Eigenfunctions are orthogonal with respect to a weight function w(z). 
3. Eigenfunctions form a complete set. 
8.4.1 
Real Eigenvalues 
Let us write the eigenvalue equations for the eigenvalues X i  and X j  as 
EUi + Xi# (z) uz = 0, 
E U j  + xjw (x) uj = 0. 
(8.21) 
(8.22) 
In these equations even though the E operator and the weight function w (x) 
are real, the eigenfunctions and the eigenvalues could be complex. Taking the 
complex conjugate of Equation (8.22) we write 
Eu; + X;w(x)u; = 0. 
(8.23) 
We multiply Equation (8.21) by u; and Equation (8.23) by ui and subtract 
to get 
u;Luz-U~Eu; = (A;-Ai)w(z)uiu;. 
(8.24) 
We now integrate both sides: 
~hu;.€uidx - 
uiEujtdx = (A; - Xi) 
uiu,tc~(z)dx. 
(8.25) 
For Hermitian operators the left-hand side of the above equation is zero, thus 
we obtain 
I’ 
Ib 
h 
(A; - Xi) 
uiu;w(z)dx = 0. 
(8.26) 
Since w ( x )  # 0 except for a finite number of isolated points, for i = j we 
conclude that 
X,r = xi, 
(8.27) 
that is, the eigenvalues of Hermitian operators are real. In quantum mechanics 
eigenvalues correspond to precisely measured quantities; thus observables like 
energy and momentum are represented by Hermitian operators. 
8.4.2 
Orthogonality of Eigenfunctions 
When i # j and when the eigenfunctions are distinct, X i  # Xj, Equation 
(8.26) gives us 
,-h 
J.- ui (z) u; (z) w (z) dz = 0, 
i # j. 
(8.28) 

112 
STURM-LIOUVILLE THEORY 
We say that the eigenfunctions ui are orthogonal with respect to the weight 
function w (z) in the interval (a, b]. In the case of degenerate eigenvalues, that 
is, when two different eigenfunctions have the same eigenvalue (i # j but 
X i  = X j  ), then the integral 
uiuj*wdx 
Ib 
does not have to vanish. However, in such cases we can always use the Gram- 
Schmidt orthogonalization method to choose the eigenfunctions as orthogonal. 
In summary, in any case we can normalize the eigenfunctions to define an 
orthonormal set with respect to the weight function ~ ( z )  
as 
(8.29) 
8.4.3 
Proof of completeness of the set of eigenfunctions is rather technical and can 
be found in Courant and Hilbert. What is important in most applications is 
that any sufficiently well-behaved and at least piecewise continuous function 
can be expressed as an infinite series in terms of {urn (z)} as 
Completeness of the Set of Eigenfunctions { 21, (x)} 
03 
F (z) = C amum 
(8.30) 
m=O 
For a Sturm-Liouville system using variational analysis it can be shown that 
the limit 
is true (Mathews and Walker p. 338). This means that in the interval [a, b] 
the series 
(8.32) 
converges to F (z) in the mean. However, convergence in the mean does not 
imply uniform (or pointwise) convergence, which requires 
N 
(8.33) 
m=O 
For most practical situations convergence in the mean accompanies uniform 
convergence and is sufficient. Note that uniform convergence also implies 

GENERALIZED FOURIER SERIES 
113 
pointwise convergence but not vice versa. We conclude this section by stating 
a theorem from Courant and Hilbert (p. 427, vol. I). 
The expansion theorem: Any piecewise continuous function defined in the 
fundamental interval [a, b] with a square integrable first derivative (i.e., 
sufficiently smooth) could be expanded in an eigenfunction series: 
m=O 
which converges absolutely and uniformly in all subintervals free of 
points of discontinuity. At the points of discontinuity this series r e p  
resents (as in the Fourier series) the arithmetic mean of the right- and 
the left-hand limits. 
In this theorem the function F (x) does not have to satisfy the boundary 
conditions. This theorem also implies convergence in the mean and point- 
wise convergence. That the derivative is square integrable means that the 
integral of the square of the derivative is finite for all the subintervals of the 
fundamental domain [a, b] in which the function is continuous. 
8.5 
GENERALIZED FOURIER SERIES 
Series expansion of a sufficiently smooth F (z) in terms of the eigenfunction 
set {urn (3)) can now be written as 
00 
F (x) = C amurn (XI, 
(8.34) 
which is called the generalized Fourier series of F ( z) . Expansion coefficients, 
urn, are found using the orthogonality relation of {um (x)} as 
m=O 
- 
- am. 
Substituting this in Equation (8.34) we get 
(8.36) 

114 
STURM-LIOUVILLE THEORY 
Using the basic definition of the Dirac-delta function, that is, 
g(x) = 1 g(x’)6(x - x’)dx’, 
we can now give a formal expression of the completeness of the set {$m (x)} 
as 
00 c u:, (x’) w (x’) urn ( x )  = s ( x  - x’) . 
(8.37) 
m=O 
It is needless to say that this is not a proof of completeness. 
8.6 
TRIGONOMETRIC FOURIER SERIES 
Trigonometric Fourier series are defined with respect to the eigenvalue pro& 
lem 
(8.38) 
with the operator given as k‘ = @/dx2. This could correspond to a vibrating 
string. Using the periodic boundary conditions 
we find the eigenfunctions as 
u, = cosnx, n = 0,1,2, ... 
urn = sinmx, m = 1,2, .__ 
. 
Orthogonality of the eigenfunctions is expressed as 
sin mx sin nxdx = A,&,, 
cos mx cos nxdx = B,S,,, 
(8.39) 
(8.41) 
sin mx cos nxdx = 0, 

HERMITIAN OPERATORS IN QUANTUM MECHANICS 
115 
where 
(8.42) 
(8.43) 
7 i  n # O  
?r 
n#O 
27r n = O '  
An= { 0 n = o  ' 
Bn= { 
Now the trigonometric Fourier series of any sufficiently well-behaved function 
becomes 
00 
a0 
2 
f(z) = - + C [a,cosnz + b, sinnz] , 
n= 1 
(8.44) 
where the expansion coefficients are given as 
1
"
 
a, = ; 
1 f (t) cos ntdt , n = 0, 1 ,2, 
. . . 
(8.45) 
and 
(8.46) 
Example 8.1. Trigonometric Fourier series: Trigonometric Fourier s e  
1
"
 
bn = ; 
1, f (t)sinntdt, 
n = 1,2 ,... . 
ries of a square wave 
can now be written as 
2d O0 sin (2n + 1) 3: 
f (z) = ,c 
(2n + 1) ' 
n=O 
where we have substituted the coefficients 
a, = 0 
d 
n = even 
n?r 
n = odd 
b, = - 
(1 -cosn?r) = 
(8.48) 
(8.49) 
8.7 
HERMITIAN OPERATORS IN QUANTUM MECHANICS 
In quantum mechanics the state of a system is completely described by a 
complex valued function, @(z), in terms of the real variable z. Observable 

116 
STURM-LIOUVKLE THEORY 
quantities are represented by differential operators (not necessarily second 
order) acting on the wave functions. These operators are usually obtained 
from their classical expressions by replacing position, momentum, and energy 
with their operator counterparts as 
(8.50) 
a 
at 
E + ih- 
For example, the angular momentum operator is obtained from its classical 
expression L = 7 x 9 
as 
--+ 
i 
L = - i h ( T + x v + ) .  
Similarly, the Hamiltonian operator is obtained from its classical expression 
H = p2/2m + V ( X )  as 
1 
2m 
H = --v2 + V(Z). 
The observable value of a physical property is given by the expectation value 
of the corresponding operator L as 
( L )  = /@*L@dx. 
(8.51) 
Because (L) corresponds to a measurable quantity it has to be real; hence 
observable properties in quantum mechanics are represented by Hermitian 
operators. For the real Sturm-Liouville operators Hermitian property [Eq. 
(8.20)] was defined with respect to the eigenfunctions u and v, which sat- 
isfy the boundary conditions (8.13) and (8.15). To accommodate complex 
operators in quantum mechanics we modify this definition as 
/ 9;L@adz = 
(L@1)*92dx, 
(8.52) 
J 
where 9land 9 2  do not have to be the eigenfunctions of the operator L. The 
fact that Hermitian operators have real expectation values can be seen from 
= /(L@)*@dx 
= (L)* 
(8.53) 

HERMITIAN OPERATORS /N QUANTUM MECHANICS 
117 
A Hermitian Sturm-Liouville operator must be second order. However, 
in quantum mechanics order of the Hermitian operators is not restricted. 
Remember that the momentum operator is first order, but it is Hermitian 
because of the presence of a in its definition: 
a 
ax 
rm 
( p )  = / 9*(-itz-)9dZ 
=Irm 
ax 
= itz 9'91:00 - 1, **(itz-)*dx 
ax 
= s_, 
**(-ili-)*dx. 
dX 
-rm 
00 
a 
(-&-9)**dX 
a 
00 
a 
00 
(8.54) 
(8.55) 
(8.56) 
(8.57) 
In proving that the momentum operator is Hermitian we have imposed the 
boundary condition that 9 is sufficiently smooth and vanishes at large dis- 
tances. 
A general boundary condition that all wave functions must satisfy is that 
they have to be square integrable, and thus normalizable. Space of all square 
integrable functions actually forms an infinite dimensional vector space called 
L 2  or the Hilbert space. Functions in this space can be expanded as general- 
ized Fourier series in terms of the complete and orthonormal set of eigenfunc- 
tions, {urn (z)}, of a Hermitian operator. Eigenfunctions satisfy the eigenvalue 
equation 
Lum(z> = Amum(z), 
(8.58) 
where A, 
represents the eigenvalues. In other words, {urn(.)} spans the 
infinite dimensional vector space of square integrable functions. The inner 
product (analog of dot product) in Hilbert space is defined as 
(8.59) 
which has the following properties: 
( 9 1 ,  a 9 2 )  = 4 9 1 ,  9 2 ) ,  
("*1,@2) 
= "*(91,*2), 
( 9 1 ,  * 2 ) *  = (*2, *l), 
( 9 1  f * 2 > * 3 )  = ( 9 1 ,  9 3 )  f (*2, 9 3 ) ,  
where (Y is a complex number. The inner product also satisfies the 
triangle inequality: 
(8.60) 

118 
STURM-LIOUVILLE THEORY 
and the 
Schwartz inequality: 
1911 I%l L I ( ~ l , * Z ) l .  
(8.62) 
An important consequence of the Schwartz inequality is that convergence of 
(@I, 9 2 )  follows from the convergence of (@I, 91) 
and ( 9 2 ,  @2). 
Problems 
8.1 Show that the Laguerre equation 
d2Y 
dY 
x- 
+ (1 -x) - 
+ny = 0 
dx2 
dx 
can be brought into the self-adjoint form by multiplying it with e-" . 
8.2 Write the Chebyshev equation 
(1 - X2)Tl(X) - XTL(X) +n2Tn(x) = 0 
in the self-adjoint form. 
8.3 
Find the weight function for the associated Laguerre equation 
8 Y  
dY 
5- 
+ ( k +  1 - x) - 
+ny = 0. 
dx2 
dx 
8.4 
A function y(x) is to be a finite solution of the differential equation 
(2 + 5~ - x') 
dx 
4 ~ (  
1 - X) 
in the entire interval x E [O, 11. )a Show that this condition can only be 
satisfied for certain values of X and write the solutions explicitly for the lowest 
three values of A. b) Find the weight function ~ ( x ) .  
c) Show that the solution 
set {yx(x)} is orthogonal with respect to the w(x) found above. 
8.5 
Show that the Legendre equation can be written as 
d 
dx 
-[(l - x">4] + l(Z+ 1)9 = 0. 
8.6 
For the Sturm-Liouville equation 
with the boundary conditions 
Y(0) = 0 
Y(..) 
- Y ' ( 4  = 0, 

PROBLEMS 
119 
find the eigenvalues and the eigenfunctions. 
8.7 
tem 
Find the eigenvalues and the eigenfunctions of the Sturm-Liouville sys- 
Y(0) = 0, 
y( 1) = 0. 
Hint: 73-y the substitution x = tant. 
8.8 
Show that the Hermite equation can be written as 
8.9 
Given the Sturm-Liouville equation 
If yn(x) and y,(x) are two orthogonal solutions and satisfy the appropriate 
boundary conditions, then show that &(x) and yA(x) are orthogonal with 
the weight function p(x). 
8.10 
as 
Show that the Bessel equation can be written in the self-adjoint form 
d 
n2 
dx 
X 
-[xJ;] + (x - -)Jn = 0. 
8.11 
Find the trigonometric Fourier expansion of 
f(x)=7r 
-7r<X<O 
= x  
O < X < T .  
8.12 
Show that the angular momentum operator 
--+ 
L = - i h ( T i x T )  
and its square are Hermitian. 
8.13 
show that they have the same eigenfunctions. 
a) What are their eigenvalues? 
b) Write the L, and L, operators in spherical polar coordinates. 
Write the operators t2, 
and L, in spherical polar coordinates and 

120 
STURM-LIOUVILLE THEORY 
8.14 For a Sturm-Liouville operator 
let u(z) 
be a nontrivial solution satisfying Xu = 0 with the boundary condition 
at z = a, and let V ( X )  be another nontrivial solution satisfying Lu = 0 with 
the boundary condition at x = b. Show that the Wronskian 
is equal to A / p ( z ) ,  where A is a constant. 
8.15 For the inner product defined as 
(*I, * 2 )  = J * ; ( x ) * 2 ( X ) d X 7  
prove the following properties, where a is a complex number: 
8.16 Prove the triangle inequality: 
and the Schwartz inequality: 
1*i1 I*2\ 2 l(*i7*2)l. 
8.17 Show that the differential equation 
Y” +Pl(X)Y’ + [132(x) + Wx)ly(x) = 0 
can be put into self-adjoint form as 

9 
ST URM- LIO U VILLE 
SYSTEMS and the 
FACTORIZATION 
METHOD 
The factorization method allows us to replace a Sturm-Liouville equation, 
which is a second-order differential equation, with a pair of first-order differ- 
ential equations. For a large class of problems satisfying certain boundary 
conditions the method immediately yields the eigenvalues and allows us to 
write the ladder or the step-up/-down operators for the problem. These o p  
erators are then used to construct the eigenfunctions from a base function. 
Once the base function is normalized, the manufactured eigenfunctions are 
also normalized and satisfy the same boundary conditions as the base func- 
tion. First we introduce the method of factorization and its features in terms 
of five basic theorems. Next, we show how eigenvalues and eigenfunctions 
are obtained and introduce six basic types of factorization. In fact, factor- 
ization of a given second-order differential equation is reduced to identifying 
the type it belongs to. To demonstrate the usage of the method we discuss 
the associated Legendre equation and spherical harmonics in detail. We also 
discuss the radial part of Schradinger’s equation for the hydrogen-like atoms, 
Gegenbauer polynomials, the problem of the symmetric top, Bessel functions, 
and the harmonic oscillator problem via the factorization method. Further 
details and an extensive table of differential equations that can be solved by 
this technique can be found in Infeld and Hull (1951), where this method was 
introduced for the first time. 
121 

122 
STURM-LIOUVILLE SYSTEMS AND THE FACTORIZATION METHOD 
9.1 ANOTHER FORM FOR THE STURM-LIOUVILLE EQUATION 
The Sturm-Liouville equation is usually written in the first canonical form 
as 
d -& [ P ( X ) F ]  + q(z)*(z) + AW(X)*(Z) = 0, 
2 E [alp], 
(9.1) 
where p(z) is different from zero in the open interval (a, p); however, it could 
have zeroes at the end points of the interval. We also impose the boundary 
conditions 
and 
where 
eigenvalue. Solutions also satisfy the orthogonality relation 
and Ik are any two solutions corresponding to the same or different 
If p(z) and w(.) 
are never negative and w ( ~ ) / p ( ~ )  
exists everywhere in (a, p), 
using the transformations 
and 
(9.5) 
we can cast the Sturm-Liouville equation into another form, also known as 
the second canonical form 
2
m
 2.'") 
+ {A + T ( Z ,  m ) } y y ( z )  = 0, 
where 
2 
r(z,m)=-+- 
--+-- 
:6[:2 
:El 
2 dpdw 
ld2w 
+ -- 
(9.7) 
m and X are two constant parameters that usually enter into our equations 
through the process of separation of variables. Their values are restricted by 
the boundary conditions and in most cases take discrete (real) values like 

METHOD OF FACTORlZATlON 
123 
and 
m = mo,mo + 1,mo + 2, ... . 
(9.10) 
However, we could take mo = 0 without any loss of generality. The orthogw 
nality relation is now given as 
(9.11) 
9.2 
METHOD OF FACTORIZATION 
We can also write Equation (9.7) in operator form as 
-+,m)Y:(z) 
= -ALY;(4, 
(9.12) 
where 
(9.13) 
d2 
dz2 
E(z,m) = - 
+ T ( Z ,  m). 
We now define two operators O*(z,m) as 
d 
dz 
(9.14) 
O*(z,m) = f- - k ( z , m )  
so that 
E ( z , m )  = O+(z,m)O-(z,m). 
(9.15) 
We say that Equation (9.7) is factorized if we could replace it by either of the 
equations 
O+k, m)O- (2, m)Y:(z) 
= [A - P ( m ) l Y m  
(9.16) 
or 
0 4 2 ,  m + l)O+(z, m + l ) Y E ( Z )  = [A - pL(m + 111 YX”;(Z). 
(9.17) 
Substituting the definitions of O+(z,m) and 0- (z,m) into Equations (9.16) 
and (9.17), we obtain two equations that k ( z , m )  and p ( m )  should satisfy 
simultaneously as 
-- dk(z,m) + k  2 (z,m)= -r(z,m)-p(m), 
(9.18) 
dz 
+k2(z,m+1) = --T(z,m)-p(m+l). 
(9.19) 
dk(z, m + 1) 
dz 

124 
STURM-LIOUVILLE SYSTEMS AND THE FACTORIZATION METHOD 
9.3 THEORY OF FACTORIZATION AND THE LADDER 
OPERATORS 
We now summarize the fundamental ideas of the factorization method in terms 
of five basic theorems. The first theorem basically tells us how to generate 
solutions with different m given yc(z). 
Theorem I: If yc(z) is a solution of Equation (9.12) corresponding to the 
eigenvalues X and m, then 
O+(z,m + I)YE(Z) = Y:+'(z) 
(9.20) 
and 
o-(z,m)yg(z) = y:-W 
(9.21) 
are also solutions corresponding to the same X but different m as indi- 
cated. 
ProoE Multiply Equation (9.17) by O+(m + 1) : 
O+(z,m+ 1) [ O - ( Z , ~ +  
l)O+(z,m+ l)yg(z)] 
(9.22) 
= O+(z, m + 1) - cl(m + 1>1 Y C ( 4 .  
This can be written as 
O+(z,m+ 1)0-(z,m+ 1) [O+(z,m+ l ) ~ c ( z ) ]  
(9.23) 
= IX - A m  + 111 [O+(w 
+ l)YE(4] . 
We now let 
m + m + l  
(9.24) 
in Equation (9.16) to write 
O+(.~,m+l)O-(z,m+ l)yE+'(~)= [X-p(m+l)]~E+'(z) (9.25) 
and compare this with Equation (9.23) to get Equation (9.20). Thus 
the theorem is proven. Proof of Equation (9.21) is accomplished by 
multiplying Equation (9.16) with O_(z,m) and by comparing it with 
the equation obtained by letting 
m - + m - l  
in Equation (9.17). 
This theorem says that if we know the solution y?( z), we can use O+(z, m+ 
1) to generate the solutions corresponding to the eigenvalues 
(m + l), (rn + 2), (m + 3), ... . 
(9.26) 

THEORY OF FACTORIZATION AND THE LADDER OPERATORS 
125 
Similarly, 0- ( z ,  m) can be used to generate the solutions with the eigenvalues 
".) (m - 3), (m - 2), (m - 1). 
(9.27) 
O*(z, m) are also called the step-up/-down or ladder operators. 
Theorem 11: If yl(z) and y2(z) are two solutions satisfying the boundary 
condition 
then 
We say that 0- and O+ are Hermitian, that is 0- = 0; with respect to 
yl(z) and y2(z). Note that the boundary condition [Eq. (9.28)] needed 
for the factorization method is more restrictive than the boundary con- 
ditions [Eqs. (9.2) and (9.3)] used for the Sturm-Liouville problem. 
Condition (9.28) includes the periodic boundary conditions as well as 
the cases where the solutions vanish at the end points. 
Proof: Proof can easily be accomplished by using the definition of the ladder 
operators and integration by parts: 
(9.30) 
Finally, using the boundary condition [Eq. (9.28)]) we write this as 
(9.31) 

126 
STURM-LIOUVILLE SYSTEMS AND THE FACTORIZATION METHOD 
Theorem III: If 
(9.32) 
J a  
exists and if p(m) is an increasing function of m (rn > 0), then 
(9.33) 
also exists. If p(m) is a decreasing function of m (and m > 0), then 
l b d z  [o- ( v 4 Y i W l 2  
(9.34) 
also exists. O+(z,m+l)yE(z) and O-(z,m)yT(z) alsosatisfy thesame 
boundary condition as 
(z). 
Proof: We take 
Y2 = YEk) 
(9.35) 
and 
Y1 = Y y k )  
(9.36) 
in Theorem I1 to write 
(9.37) 
Solution 0- (z,m)yE(z) in Equation (9.21) is equal toyE-'(z) only up 
to a constant factor. Similarly, o+(z, m)yE-l(z) is only equal to yg(z) 
up to another constant factor. Thus we can write 
b 
b 
J, W W Y Y X 4 "  = C(4m) 1 dzY;T"-'(z)Y;-'(z) 
(9.38) 
or 
b 
b 
.id dz [ Y 3 4 l 2  = c(1,m)J' dz [Y:-'(4I2, 
(9.39) 
a 
where C(1, m) is a constant independent of z but dependent on 1 and m. 
We are interested in differential equations the coefficients of which may 
have singularities only at the end points of our interval. Square inte 
grability of a solution actually depends on the behavior of the solution 
near the end points. Thus it is itself a boundary condition. Hence, for 

THEORY OF FACTORIZATION AND THE LADDER OPERATORS 
127 
a given square integrable eigenfunction yT (z), the manufactured eigen- 
function yc-'(z) is also square integrable as long as C(I, m) is different 
from zero. Because we have used Theorem 11, yz-'(z) also satisfies the 
same boundary condition as yc(z). A parallel argument is given for 
yz+'(z). In conclusion, if yc(z) is a square integrable function satisfy- 
ing the boundary condition [Eq. (9.28)], then all other eigenfunctions 
manufactured from it by the ladder operators O+(z,m) are square inte- 
grable and satisfy the same boundary condition. For a complete proof 
C(I, m) must be studied separately for each factorization type. For our 
purposes it is sufficient to say that C(1, m) is different from zero for all 
physically meaningful cases. 
Theorem IV If p(m) is an increasing function and m > 0, then there exists 
a maximum value form, say mmax = 1, and X is given as X = p(1+ 1). If 
p ( m )  is a decreasing function and m > 0, then there exists a minimum 
value for m, say mmin = l', and X is X = p(l'). 
Proof: Assume that we have some function yx";(z), where m > 0 , which 
satisfies the boundary condition [Eq. (9.28)]. We can then write 
(9.40) 
If p(m) is an increasing function of m, eventually we are going to reach 
a value of m, say mmax = 1, that leads us to the contradiction 
unless 
y y (  
2) = 0, 
(9.43) 

128 
STURM-LIOUVILLE SYSTEMS AND THE FACTORIZATION METHOD 
= P (1) 
h = p (1+1) 
m = I  
m 
\ 
m’o 
mn 
m*= 
I 
m 
1 
fk. 9.1 Different cases for p(m) 
that is, 
O+( 2,1 + 1)!/i2 ( 2 )  = 0. 
(9.44) 
2 
Since Jab& 
[!/i,(z)] # 0, using the last equation in (9.40) with m = 1 
we determine X as 
x = xi = p(1 + 1). 
(9.45) 
Similarly, it could be shown that if p ( m )  is a decreasing function of m, 
then there exists a minimum value of m, say mmin = I, such that 
0- ( Z , l ) &  
( 2 )  = 0. 
(9.46) 
A in this case is determined as 
X = 
= p(l). 
(9.47) 
Cases for m < 0 are also shown in Figure 9.1. 
We have mentioned that the square integrability of the solutions is itself 
a boundary condition, which is usually related to the symmetries of the 

THEORY OF FACTORIZATION AND THE LADDER OPERATORS 
1% 
problem. For example, in the case of the associated Legendre equation 
the end points of our interval correspond to the north and south poles 
of a sphere. For a spherically symmetric problem, location of the poles 
is arbitrary. Hence useful solutions should be finite everywhere on a 
sphere. In the Frobenius method this forces us to restrict X to certain 
integer values (Chapter 2). In the factorization method we also have 
to restrict A, this time through equation (9.40) to ensure the square 
integrability of the solutions for a given p(m). 
Theorem V: When Theorem I11 holds, we can arrange the ladder operators 
to preserve not just the square integrability but also the normalization 
of the eigenfunctions. When p(m) is an increasing function of m, we 
can define new normalized ladder operators 
which ensures us the normalization of the manufactured solutions. 
When p(m) is a decreasing function, normalized ladder operators are 
defined as 
Proof: Using the last equation in Equation (9.40) we write 
Since 
we write 
(9.51) 
Define a new operator ,E+(z, I ,  m); then Equation (9.51) becomes 

130 
STURM-LIOUVILLE SYSTEMS AND THE FACTORIZATION METHOD 
Thus, if yc (z) is normalized, then the eigenfunction manufactured from 
yc(z) by the operator -E+ is also normalized. Similarly, one could show 
that 
(9.52) 
In conclusion, once y z  (2) is normalized, the manufactured eigenfunc- 
tions 
YY+l(4 = X+(z, 1,m + Q Y g 4  
Y K - w  = -c- (z, 4 m)Yc(4 
(9.53) 
and 
are also normalized. Depending on the functional forms of p(m), L*( z, I ,  m) 
are given in Equations (9.48) and (9.49). 
9.4 
SOLUTIONS VIA THE FACTORIZATION METHOD 
We can now manufacture the eigenvalues and the eigenfunctions of an equa- 
tion once it is factored, that is, once the k ( z , m )  and the p ( m )  functions cor- 
responding to a given r(z, m) are known. For m > 0, depending on whether 
p ( m )  is an increasing or a decreasing function, there are two cases. 
9.4.1 
In this case, from Theorem IV there is a maximum value for m, 
Case I ( m > 0 and p ( m )  is an increasing function) 
m=0,1,2 ,..., 1, 
(9.54) 
and the eigenvalues 
are given as 
x = x1 = p(2 + 1). 
(9.55) 
Since there is no eigenstate with m > 1, we can write 
0 + ( z , 1 +  l)yl'(z) = 0. 
(9.56) 

SOLUTIONS VIA THE FACTORIZATION METHOD 
131 
Thus we obtain the differential equation 
{; 
-k(z,l+ 1) y:(z) = 0. 
1 
(9.57) 
Note that we have written & ( z )  = y:(z). Integrating Equation (9.57) we get 
- 
= k(z,l+ l)dz, 
Yl 
(9.58) 
(9.59) 
or 
C is a constant to be determined from the normalization condition 
(9.60) 
(9.61) 
For a given 1, once y;“”(z) 
is found, all the other normalized eigenfunctions with 
m = 1,l- 1,l- 2, ..., 2,1,0, can be constructed by repeated applications of the 
step down operator L- (z,l, m) as 
9.4.2 
In this case, from Theorem IV there is a minimum value for m, where 
Case I I  (m > 0 and p(m) is a decreasing function) 
m= 1,1+1,1 + 2  ,... . 
(9.64) 
For this case we can write 
0- (z, l)Y:(Z) 
= 0, 
(9.65) 
{-$ 
k(z, 1 )  } yl‘(z) = 0. 
Thus 
(9.66) 
(9.67) 

132 
STURM-LIOUVILLE SYSTEMS AND THE FACTORlZATlON METHOD 
C is again determined from the normalization condition 
(9.68) 
Now all the other normalized eigenfunctions for m = 1,l + 1,1 + 2, ... are 
obtained from y,"(z) by repeated applications of the formula 
Cases with m < 0 are handled similarly. In Section 9.6 we see how such a 
case is treated with spherical harmonics. 
9.5 
TECHNIQUE AND THE CATEGORIES OF FACTORIZATION 
In Section 9.2 we saw that in order to accomplish factorization we need to 
determine the two functions k ( z , m )  and p(m), which satisfy the two equations 
dk(z,m+ 1) 
(9.71) 
dz 
+ k ( z , m  + 1) = -r(z,m) - p ( m +  l), 
(9.72) 
~ ( z , m )  
is known from the equation the factorization of which is sought, that 
is, from 
[$ 
+r(z,m) Y E ( 4  = -XlYE(z)- 
1 
(9.73) 
However, following Infeld and Hull (1951) we subtract Equation (9.72) from 
Equation (9.71) to obtain the difference equation 
(9.74) 
dk(z,m) + dk(z,m+ 1) 
- k2(z, m) + P ( z ,  m + 1) + - 
= p(m) - p(m + 1). 
dz 
dz 
This is the necessary equation that k(z, m) and p(m) should satisfy. This is 
also a sufficient condition, because k(z, m) and p(m) satisfying this equation 
give a unique ~ ( z ,  
m) from Equation (9.71) or (9.72). We now categorize all 
possible forms of k ( z , m )  and p(m) that satisfy Equation (9.74). 

TECHNIQUE AND THE CATEGORIES OF FACTORIZATION 
133 
9.5.1 
9.5.1.1 
dependence given as 
Possible Forms for k ( Z ,  m) 
Positive powers of m: We first consider k(z,m) with the m 
k(2,m) = b ( z )  +mk1(z). 
(9.75) 
To find p(m) we write Equation (9.74) for successive values of m, as (we 
suppress the z dependence of k(z,m)) 
k2(m) - k2(m - 1) + k’(m) + k’(m - 1) = p ( m  - 1) - p ( m )  
k2(m - 1) - k2(m - 2) + k’(m - 1) + k’(m - 2) = p ( m  - 2) - p ( m  - 1) 
k 2 ( m  - 2) - k2(m - 3) + k’(m - 2) + k’(m - 3) = p ( m  - 3) - p ( m  - 2) 
k2(1) - k2(0) + k’(1) + k’(0) = p(0) - p(1). 
(9.76) 
Addition of these equations gives us 
T m  
m-1 
1 
We have used 
k’(z,m) = kb(z) +mki(z). 
(9.78) 
Also using 
(9.79) 
m(m + 1) 
m(m - 1) 
m 
m- 1 
m’=O 
2 
+
2
 
C m’+ C m‘= 
m‘=l 
= m2 
and, since from Equation (9.75) we can write 
P(m) - k2(0) = [b 
+ mk1I2 - k& 
(9.80) 
we finally obtain 
p ( m )  - p(0) = -mZ(k? + k i )  - 2m(kOlc1 + kh). 
(9.81) 
Since p(m) is only a function of m, this could only be satisfied if the coefficients 
of m are constants. 
IC? + r~i = const. = -a 2 
(9.82) 
and 
kokl+ Ic:, = const. = -a2c if a # o 
kokl + k; = const. = b 
if a = 0. 
(9.83) 
(9.84) 

134 
STURM-LIOUVILLE SYSTEMS AND THE FACTORIZATION METHOD 
This determines p ( m )  as 
p ( m )  = p(0) + a2(m2 + 2mc) for a + o 
(9.85) 
and 
p ( m )  = p(0) - 2mb for a = 0. 
(9.86) 
In these equations we could take p(0) = 0 without any loss of generality. 
Using these results we now obtain the following categories: 
A) For a # 0 Equation (9.82) gives 
(9.87) 
Ic* =acota(z+p). 
(9.88) 
Substituting this into Equation (9.83) and integrating gives us 
ko(z) = cacota(z + p )  + . 
d 
sin+ + p )  ’ 
(9.89) 
where p and d are integration constants. 
With these Ico and Icl functions in Equation (9.75) and the p(m) given 
in Equation (9.85) we obtain r(z,m) from Equation (9.71) or (9.72) as 
a2(m + c)(m + c + 1) + d2 + 2ad(m + c + a) cos a(z + p )  
sin2 a(z + p )  
+,m) = - 
(9.90) 
We now obtain our first factorization type as 
(9.91) 
d 
sina(z+p)’ 
Ic(z,m)= (m+c)acota(z+p)+ . 
p ( m )  = a2(m + c ) ~ ,  
we set p(0) = a2c2. 
(9.92) 
kl = const. = ia 
k~ = ica + de-iaz 
(9.93) 
(9.94) 
For this type, after writing a instead of ia and adding -a2c2 to p ( m )  
we get 
~ ( z ,  
m) = -d2e2az + 2ad m + c + - eaz, 
( 
1) 
(9.95) 
(9.97) 
(9.96) 
k(z, m) = deaz - m - c, 
p ( m )  = -a2(rn + c) 2 . 

TECHNIQUE AND THE CATEGORIES OF FACTORIZATION 
135 
1 
k 1 = - ,  
a=O 
b
d
 
ko = - z +  -. 
2
2
 
z 
(9.98) 
(9.99) 
After writing c for d and adding b/2 to p(m) we obtain 
(9,100) 
(9.101) 
(9.102) 
(m + c)(m + c + 1) 
22 
b2z2 
4 + b(m - c), 
-- 
?-(z,m) = - 
k(z, m) = (m + c)/z + bz/2, 
p(m) = -2bm + b/2. 
kl =o, a = O  
ko = bz + d. 
(9.103) 
(9.104) 
In this case, the operators O+ are independent of m. ~ ( z , m ) ,  
k(z,m), 
and p(m) are now given as 
~ ( z , m ) =  
-(bz+d)2+b(2m+1), 
(9.105) 
k(z, m) = bz + d, 
(9.106) 
p(m) = -2bm. 
(9.107) 
We can also try higher positive powers of m in k(z, m) as 
k(z,m) = ~(z)+mkl(z)+m2k2(z)+... . 
(9.108) 
However, no new categories result (see Problems 9.5 and 9.6). Also note that 
the types B, C, and D can be viewed as the limiting forms of type A. 
9.5.1.2 Negative powers of m: We now try negative powers of m as 
k(z,m) = - 
k-l(z) + ko(z) + k,(z)m. 
m 
(9.109) 
We again write Equation (9.74) for successive values of m as (we suppress the 
z dependence of k(z, m)) 
P ( m )  - k2(m - 1) + k’(m) + k’(m - 1) = p(m - 1) - p(m) 
k2(m - 1) - k2(m - 2) + k’(m - 1) + k / ( m  - 2) = p(m - 2) - p(m - 1) 
k2(m - 2) - lcym - 3) + k’(m - 2) + k’(m - 3) = p(m - 3) - p(m - 2) 
P(2) - P(1) + lc’(2) + k’(1) = p( 1) - p(2). 
(9.110) 

136 
STURM-LIOUVILLE SYSTEMS AND THE FACTORIZATION METHOD 
Adding these equations and using 
(9.11 1) 
give 
(9.112) 
m 
+F;:,[2m-21+1ci 
= P(1) - P(m)- 
Cz,=2 f + Em-’ 
m’=l 1 1  
m’ , which is the coefficient of k l  1 ,  con- 
tains a logarithmic dependence on m, we set k-1 to a constant 
k-1 = q # 0. 
(9.113) 
Also using 
m- 1 
2 m’+ c m‘=m2-1 
m’=2 
m’= 1 
(9.114) 
and Equation (9.109) we write 
k 2 ( m )  - k2(1) 
(9.115) 
Now Equation (9.112) becomes 
2 k, 2 
2 
2k-lkO 
- + f l m  
+- 
+ 2k0k1 m 
m2 
m 
- k2 1 - k? - 2 k  
1 ko - 2kok1 
+ kh [2m - 21 
+ ki [m2 - 11 
= P(1) - f4m). 
(9.116) 
After some simplification and setting p( 1) = 0, which we can do without any 
loss of generality, Equation (9.116) gives 
(9.117) 
kZ1 
2kok-1 
- 
m2 +- 
+ m(2kokl+ 2%) + m2(kp + IC:) 
+ [-(k? + k i )  - kC2, - 2kI, - 2(kl+ ~ c - l ) h ]  = -p(m). 
m 

ASSOCIATED LEGENDRE EQUATlON (TYPE A) 
137 
We know have two new categories corresponding to the cases a # 0 and a = 0 
with 
(9.118) 
(9.119) 
(9.120) 
kl=acota(z+p), b = O ,  k - l = q  fora#O. 
(9.121) 
~ ( z , m ) ,  
k(z,m), and p(m) are now given as 
m(m + l)a2 
sin2 a( z + p )  
~ ( z ,  
m) = - 
-2aqcota(z+p), 
k(z,m) = macota(z+p)+q/m, 
p(m) = u2m2 - q2/m2. 
(9.122) 
F) Our final category is obtained for a = 0 as 
kl = l/z, ko = 0, k-1 = q, 
(9.123) 
where 
T(z,m) = -2q/z - m(m + 1)/z2, 
k(z, m) = m / z  + q/m, 
(9.124) 
(9.125) 
p(m) = -q2/m2. 
(9.126) 
Further generalization of these cases by considering higher negative powers 
of m leads to no new categories as long as we have a finite number of terms 
with negative powers in k(z,rn). Type F can also be viewed as the limiting 
form of type E with a --+ 0. Entries in the table of factorizations given by 
Infeld and Hull (1951) can be used, with our notation with the replacements 
2 -+ z and L(m) = p(m). 
9.6 
The Legendre equation is given as 
ASSOCIATED LEGENDRE EQUATION (TYPE A) 
Bo (6) 
dO (6) 
&2 
+cot$- d6 
(9.127) 

138 
SJURM-LIOUVILLE SYSTEMS AND THE FACTORlZATlON METHOD 
where 0 E [0,7r] 
and m = 0, fl, f 2 ,  ... . We can put this into the first canonical 
form by the substitution 
x = cos8, 0 (6) = P(x), x E [-I, 11, 
(9.128) 
as 
m2 ] P ( x )  = 0, 
(9.129) 
d2P (x) 
(1-x2)-- dx2 
dx 
dx 
(9.130) 
We now first make the substitutions 
2 1/4 
dx 
w(x) = 1, p(x) = (1 - x’) , dz = 
1/2’ Y(Z) = P(X)(l- z ) , 
(I - x2) 
which in terms of 0 means that 
W ( X )  = 1, p(x) = sin20, dz = -dQ, y(8) = P(cos8)sin’/2Q, 
and thus leads us to the second canonical form 
y(8) = 0. 
I 
d2y0 
d82 + [ (A, +-)- 
4 
(m2- 
sin28 3 
1 
If we call 
1 
4 
= ( A +  -) 
and compare with 
2 m  y) 
+ {A + T ( Z ,  m))yx”(z) = 0, 
we obtain 
(m2 - 4) 
T ( Z , r n )  = sin2z . 
(9.131) 
(9.132) 
(9.133) 
(9.134) 
(9.135) 
(9.136) 
This is exactly type A with the coefficients read from Equation (9.90) as 
a = 1, c = -112, d = 0, p = 0, z = 8. 
(9.137) 
Thus from Equations (9.91) and (9.92) we obtain the factorization of the 
associated Legendre equation as 
1 
2 
k ( ~ ,  
m) = (m - -)cot 8, 
(9.138) 
1 
2 
p(172) = (m - -)2. 
(9.139) 
For convenience we have taken p(0) = a2c2 rather than zero in Equation 
(9.92). 

ASSOCIATED LEGENDRE EQUATION (TYPE A) 
139 
9.6.1 Determining the Eigenvalues 
For m > 0 
p ( m )  = (m- -) 
1 2  . 
(9.140) 
Thus p(m) is an increasing function of m and from Theorem IV we know that 
there exists a maximum value for m, say mmax = 1. This determines X as 
X = p(l + 1) 
(9.141) 
2 
= ( 1 + $ .  
1
2
 
On the other hand, for m < 0 we could write 
1 
44 = (Iml+ $2. 
(9.142) 
Again from the conclusions of Theorem IV there exists a minimum value, 
mmin, thus determining X as 
X = mmin 
(9.143) 
To find mmin we equate the two expressions [Eqs. (9.141) and (9.143)] for X 
to obtain 
(9.144) 
mmin = -1. 
(9.146) 
Since m changes by integer amounts, we could write 
h
i
n
 = mmax - integer 
-1 = 1 - integer 
21 = integer. 
(9.147) 
This equation says that 1 could only take integer values 1 = 0,1,2, ... . We 
can now write the eigenvalues XI as 
1 
4 
X t + - = X  
(9.148) 
X l + L ( l + ; )  
2 
4 
(9.149) 
Xt + - 
1 = 1 2 + 1  +- 
1 
(9.150) 
4 
4 
XI = 1(1+ 1). 
(9.151) 

140 
STURM-LlOUVlLLE SYSTEMS AND THE FACTORIZATION METHOD 
Note that Equation (9.147) also has the solution 1 = integer /2. We will elab- 
orate this case in the next chapter in Problem 11.11. 
9.6.2 Construction of the Eigenfunctions 
Since mmax = 1, there are no states with m > 1. Thus 
(9.152) 
(9.153) 
This gives 
= (1+ ;) 
Hence the state with mmax = 1 is determined as 
yi, (8) = N(sin Q)(’++). 
(9.155) 
N is a normalization constant to be determined from 
which g i v s  
[ (22 + l)!] 
N = (-1)L - 
221+11!2 
. 
(9.156) 
(9.157) 
(9.158) 
The factor of (-l)’, which is called the Condon-Shortley phase, is intro- 
duced for convenience. Thus the normalized eigenfunction corresponding to 
mmax = 1 is 
(9.159) 
Using this eigenfunction (eigenstate) we can construct the remaining eigen- 
states by using the normalized ladder operators [Eqs.(9.48) and (9.49)]. For 

ASSOCtATED LEGENDRE EQUATION (TYPE A} 
141 
moving down the ladder we use 
- 
- 
1 
[-dB-(m-i)cot~] 
d 
2 
J(l + 4) - (m - t )  
- 
- 
1 
[-$ - (m - ;) cotO] 
J(l+ m ) ( ~  
- m + 1) 
and for moving up the ladder 
(9.160) 
(9.161) 
(m + -) cot 0 
2 l
l
 
[S - 
1 
- 
- 
J(l + ;)2 - (m + &)2 
(m+-)cote . 
[" - 
2 l
l
 
1 
- 
- 
J(l - m)(l+ m + 1) 
Needless to say, the eigenfunctions generated by the operators k'* are also 
normalized (Theorem V). 
Now the normalized associated Legendre polynomials are related to yiL (6) 
by 
9.6.3 
Spherical harmonics are defined as 
Ladder Operators for the Spherical Harmonics 
Using Equation (9.162) we write 
Using 
(9.162) 
(9.163) 
(9.164) 
(9.165) 

142 
STURM-LIOUVILLE SYSTEMS AND THE FACTORIZATION METHOD 
and Equation (9.160) we could also write 
- 
L 
- 
J(l + m)(l - m + 1) 
a
e
c
i
4
5
 [-$ -mcotO F;~"(o) 
J(l + m)(2 - rn + 1) 
J c l +  m)(l- m + 1) 
- 
I 
- 
- 
m
e
-
 
[-A - mcot 61 (
P
r
(
H
)
S
)
 
- 
Cancelling m 
on both sides and noting that 
(9.166) 
(9.167) 
and using Equation (9.164) we finally write 
Similarly 
We now define the ladder operators L+ and L- for the m index of the spherical 
harmonics as 
(9,170) 
(9.171) 

ASSOCIATED LEGENDRE EQUATION (TYPE A) 
143 
where 
and 
We can now construct the spherical harmonics from the eigenstate, 
by successive operations of the ladder operators as 
21+ 1(1 -m)! 1 
Y,"(Q,qb) = J--- 2 
( I +  l)! 27r [L+1" 9 
(cos Q) 
and 
(9.172) 
(9.173) 
(9.174) 
(9.175) 
21 + 1 ( I  -m)! 1 
-___- 
[L-I" fi(cose). 
2 
( I f  I)! 27r 
(9.176) 
PLm=o(cm~) 
= PL(cos6) is the Legendre polynomial. Note that 
[L_]* = - [L,] 
(9.177) 
and 
Y,*"(Q,$) = (-l)mq-"(Q, 4). 
(9.178) 
9.6.4 
In quantum mechanics the angular momentum operator (we set ti = 1) is 
given as 
Interpretation of the & Operators 
(9.179) 
-+ 
L = -47 
x 3. 
We write this in spherical polar coordinates to get 
A 
A 
,.- 
e, 
ee 
r
0
 
ar 
r d 8  
rsinQd4 
(9.180) 
a 
i a  
- _- 
-- 

144 
STURM-LIOUVILLE SYSTEMS AND THE FACTORIZATION METHOD 
(9.181) 
The basis vectors gg and g+ in spherical polar coordinates are written in terms 
of the basis vectors (Gx,G,,6,) 
of the Cartesian coordinates as 
e0 = (cos 6 cos c))& + (cos 6 sin 4)Gy - (sin Q)Gz, 
e+ = -(sinB)P, + (cos 4)Sy. 
(9.182) 
(9.183) 
A 
A 
Thus the angular momentum operator in Cartesian coordinates becomes 
(9.184) 
--+ 
L = LxPx + LySy + L,G, 
a 
icotQcosq5-++sinq5- 
34) 
It is now clearly seen that 
L+ = L, + ZL,, 
L- = L, - ZL,, 
and 
a 
34 
L --i-. 
z -  
Also note that 
t2 
=L:+L;+L: 
1 
2 
= - (L+L- + L- L+) + L: 
(9.185) 
(9.186) 
From the definition of L, it is seen that 
L,&" = m&", 
m = -1, ..., 0, ..., 1 . 
(9.187) 
Also, using the L& operators defined in Equations (9.170-171) and Equations 
(9.172-173) we can write 
(9.188) 
1 
2 
T2 
5" = - (L, L- + L- L,) y," + Lf y," 
= 1(1+ 1)qm, 
1 = 0, 1,2,3 ... . 
--+ 
Thus qrn 
are the simultaneous eigenfunctions of the L and the L, operators. 
To understand the physical meaning of the angular momentum operators, con- 
sider a scalar function @(T, 0, 4), which may represent some physical system 

ASSOCIATED LEGENDRE EQUATlON (TYPE A) 
145 
(could be a wave function). We now operate on this function with an opera- 
tor R the effect of which is to rotate a physical system by a counterclockwise 
about the z-axis. R9(r, 8,4) is now a new function representing the physical 
system after it has been rotated. This is equivalent to replacing 4 by 4 + a 
in *(r, 8,4). After making a Taylor series expansion about a = 0 we get 
R W ,  
8, 4) 
(9.189) 
= *(r,8,4+a) 
= w, 
@,4') 
In terms of the coordinate system (T, 8, 4), this corresponds to a rotation 
about the z-axis by -a. Thus with the replacement da + -d4 we get 
R W ,  
8,4> 
(9.190) 
= [exp(-ZcuL,)] *(r, 8, (6). 
For a rotation about an arbitrary axis along the unit vector 6 this becomes 
R@(r,8,4) = [exp(-iaT.ii) 3 q(r,O,b). 
(9.191) 
+ 
Thus the angular momentum operator L is related to the rotation operator 
R by 
-+ 
R = exp(-ia L . G). 
(9.192) 
9.6.5 
We now write XE = 1(1+ 1) and -m2 = X in Equation (9.127) to obtain 
Ladder Operators for the 1 Eigenvalues 
i ( ~  
+ 1) + 
(9.193) 
d 2 0  (0) 
d82 
+cote--- 
d8 
We can put this equation into the second canonical form by the transforma- 
tion 
, 8 (8) = V(Z), z E [-w, 4 
(9.194) 

146 
STURM-LIOUVILLE SYSTEMS AND THE FACTORIZATION METHOD 
as 
(9.195) 
Because the roles of 1 and m are interchanged, we can vary 1 for fixed m. 
Comparing Equation (9.195) with 
d 2 V ( z )  
dZ2 + [A + r(z, l ) ]  V ( z )  = 0 
(9.196) 
and Equation (9.90) we see that this is of type A with 
a = i, c = 0, p = i71/2, and d = 0. 
Its factorization is therefore obtained as 
O+(z, 110- (2, OpW = [Am - P(l)lr.;xm(z) 
(9.197) 
with 
k(z, I )  = 1 tanh z, 
(9.198) 
p(l) = -12. 
Thus the ladder operators are 
(9.199) 
d 
dz 
O&, 
1) = +-- - 1 tanh z. 
(9.200) 
Because p(I) is a decreasing function, from Theorem IV we obtain the top of 
the ladder for some minimum value of 1, say m, thus 
(9.201) 
2 
A = - m .  
We can now write 
O+(z, 2)O- (2, 
l)yX"(z) = [-m2 + P]i+(z) 
(9.202) 
0-(z,1+l)O+(z,I+ l ) ~ X m ( z )  
= [-m2+(1+1)2]1/Ixm(.z). 
(9.203) 
Using 
(9.204) 

ASSOCIATED LEGENDRE EQUATION (TYPE A) 
147 
We again see that lmin = m, so that 
0- 
(z, l)VA- ( 2 )  = 0. 
(9.205) 
Because we do not have a state lower than 1 = m, using the definition of 
0- (z, l ) ,  we can use Equation (9.66) to find yx' ( z )  as 
(9.206) 
sinh z 
Je=-mJ
cosh z dz 
(9.207) 
Vd-(z, = "- 1 
coshm z ' 
(9.208) 
where N' is a normalization constant in the z-space. Using the transformation 
given in Equation (9.194) and, since 1 = m, we write VA- ( z )  as 
VE(~) = ~ ' ( 6 )  
= Nsin'O. 
(9.209) 
From Equations (9.162) and (9.155) we note that for m = 1 
yf(8) = m e '  0: (sinB)(";), 
(9.210) 
y1(q Yf(e)/&G. 
Thus for a general m 
(9.211) 
C', is needed to ensure normalization in the &space. Using Equation (9.49) 
of Theorem V and Equation (9.20) we now find the step-up operator for the 
1 index as 
( I  + 1) tanh z} p. 
(9.213) 
sin 6 
Taking tanh of both sides in Equation (9.194), we write 
tanh z = - cos 8, 
d 
- sin8- 
d 
dz 
d6 
_ -  
(9.214) 

148 
STURM-LIOUVILLE SYSTEMS AND THE FACTORIZATION METHOD 
and obtain 
- 
Clm 
- 
J(1 + 1 + m)(1+ 1 - m) 
Similarly for the stepdown operator, we find 
!/p1(Q)cl-I,m 
(9.216) 
Using our previous results [Eqs. (9.160) and (9.161)], ladder operators for the 
m index in yT(6) can be written as 
1 
yy+l(e) = 
J(1 - m)(l + m + 1) 
x {-&(m+;)cots)Yl'"(6), 
1 
y y ( 8 )  = 
J(1 + m)(l- m + 1) 
(9.2 17) 
(9.2 18) 
x { -f 
- (m - i) ~otB}y;L(@). 
To evaluate the normalization constant in 6-space, first we show that the 
ratio Cim/Cl+l,m is independent of m. Starting with the state (1,m) we can 
reach (1 + 1, m + 1) in two ways. 
Path I (1, m) + (1, m + 1) -+ 
( 1  + 1, m + 1) : For this path, using Equations 
(9.215) and (9.217) we write 
(9.219) 
yy(e) 
J(1 - m)2(1 + m + 1)(1+ m + 2) 
- 
- 
The numerator on the right-hand side is 

ASSOCIATED LEGENDRE EQUATION (TYPE A) 
149 
Using Equation (9.133) with A1 = 1 ( 1 +  1) and simplifying, we obtain 
Y,m,ll (0) 
(9.221) 
- Cl,m+l 
1 
(1 - m) 
- 
Cl+l,m+l (1 - m) J(I + m + 1)(1+ m + 2) 
. {crises - a 
+ f - (i + 1) sine} yr(e). 
Path I1 (1, m) -+ (1 + 1, m) -+ 
( 1  + 1, m + 1) : Following the same procedure 
as in the first path we obtain 
Yln;'(f3 
CL 
m 
1 
(1+1-m) 
=
.
 
Cl+l,m (1 + 1 - m) d(i + m + 1)(1+ m + 2) 
case- - - 
- 
(9.222) 
do 
sin8 
Thus we obtain 
which means that 
(9.224) 
C1,WI 
Ci+l,m 
is independent of m. 
Using this result, we can now evaluate C~m/C~+l,m. 
First using Equation 
(9.159) we write 
YI+I(Q) 
Using Equations (9.159) and (160) we can also write 
1+1 
Y:+l(e) = J- (e,l+ I)%+, ( 1 
(9.225) 
(9.226) 

150 
STURM-LIOUVILLE SYSTEMS AND THE FACTORIZATION METHOD 
Comparing these we get 
Finally, using 
yy(Q) eim@ 
&"(B,4) = -- 
&a&' 
(9.227) 
(9.228) 
we now write the complete set of normalized ladder operators of the spherical 
harmonics for the indices 1 and m as 
(21 +3) 
Tde7 
dl = d (21 + 1)(1+ 1 + m)(l + 1 - m) 
(21 - 1) 
y,"l((e,4)= J (21+1)(l-m)(1+m) 
(9.229) 
(9.230) 
and 
q"+'(6,4) = 
J(1 - m)(l + m + 1) 
Adding Equations (9.229) and (9.230) we also obtain a useful relation 
(1 + 1 + m)(1+ 1 - m) 
= \i 
(21 + 1)(2l + 3) 
&Y1 P,4) 
(9.232) 
(9.233) 

SCHRODlNGER EQUATION FOR A SINGLE-ELECTRON ATOM AND THE FACTORlZATlON METHOD (TYPE F) 
151 
9.7 
SCHRODINGER EQUATION FOR A SINGLE-ELECTRON ATOM 
AND THE FACTORIZATION METHOD (TYPE F) 
The radial part of the Schrdinger equation for a single-electron atom is given 
as 
+ r2t2 (r) R1 (r) - 1(1+ 1)Rt (r) = 0, 
(9.234) 
dr 
where 
(9.235) 
2 is the atomic number and e is the electron’s charge. Because the electrons 
in an atom are bounded, their energy values should satisfy E < 0. In this 
equation if we change the dependent variable as 
(9.236) 
uE,l (.) 
r 
&(r) = 
the differential equation to be solved for U E , ~ ( T )  becomes 
We have seen in Chapter 3 that the conventional method allows us to express 
the solutions of this equation in terms of the Laguerre polynomiaIs. To solve 
this problem with the factorization method we first write Equation (9.237) as 
Taking the unit of length as 
(9.239) 
h2 
mZe2 
and defining 
2h2 E 
A=- 
mZ2e4’ 
Equation (9.238) becomes 
2 
1(1+ 1) 
(9.240) 
(9.241) 

152 
STURM-LIOUVILLE SYSTEMS AND THE FACTORIZATION METHOD 
This is Type F with 
q = -1 and m = 1. 
Thus we determine k(r, 1) and p(1) as 
1
1
 
r
I
 
k(r,l) = - - -, 
1 
1 2 .  
p(I) = -- 
(9.242) 
(9.243) 
Because p(1) is an increasing function, we have l,,, 
say n'; thus we obtain X 
as 
n' = O,1,2,3, ..., 
(9.244) 
1 
(n' + 1)2 ' 
A = -  
or 
1 
n2 
A=--, 
n =  1,2,3 ,... . 
Note that 1 5 n = 1,2,3, __. 
. We also have 
where 
uL-1 = [L 
(T, 
I ) ]  ZL: 
(9.246) 
and 
Ul+l 
n = [ x + ( r , l + l ) l c -  
(9.247) 
The normalized ladder operators are defined by Equation (9.48) as 
Using (9.240) the energy levels are obtained as 
mZ2e4 
2ii2n2 ' 
E 
n =  1,2,3 ,..., 
n -  
(9.249) 
which are the quantized Bohr energy levels. 

GEGENBAUER FUNCTIONS (TYPE A) 
153 
9.8 
GEGENBAUER FUNCTIONS (TYPE A) 
The Gegenbauer equation in general is given as 
d2C;' (x) 
dC2' (x) 
dx2 
d x  
- (2X' + 1)x- 
+ n(n + 2X')C,"'(x) = 0. 
(9.250) 
(1 - x2) 
For X = 1/2 this equation reduces to the Legendre equation. 
values of n its solutions reduce to the Gegenbauer or Legendre polynomials: 
For integer 
(9.251) 
In the study of surface oscillations of a hypersphere one encounters the equa- 
tion 
- (2m + 3)x- dU,"(x) + Xurn 
A (  > = o ,  
(9.252) 
d2U," (x) 
dx2 
dx 
(1 -x2) 
solutions of which could be expressed in terms of the Gegenbauer polynomials 
as 
where 
X = ( 1  - m)(l+ m + 2). 
(9.254) 
Using 
x = -cos6 
U T ( X )  = Z?(Q)(sinQ)-rn-l 
we can put Equation (9.252) into the second canonical form as 
(9.255) 
(9.256) 
(9.257) 
m(m + 1) 
dQ2 
On the introduction of 
A" = x + (m + I ) ~ ,  
(9.258) 
and comparing with, Equation (9.90), this is of type A with c = p = d = 0, 
a = 1, and z = 8, and its factorization is given by 
k(6, m) = m cot B 
p(m) = m2. 
(9.259) 
(9.260) 

154 
STURM-LIOUVILLE SYSTEMS AND THE FACTORIZATION METHOD 
The solutions are found by using 
and the formulas 
(9.261) 
(9.262) 
Note that Z[n is the eigenfunction corresponding to the eigenvalue 
A"= (2+112, 
1 - m = 0 , 1 , 2  ,..., 
(9.263) 
that is, to 
x = (1 + 1)2 - (m + 1)2 
= ( 2  - m)(l+ m + 2). 
(9.264) 
9.9 
SYMMETRIC TOP (TYPE A) 
The wave equation for a symmetric top is encountered in the study of simple 
molecules. If we separate the wave function as 
U = @(U) exp(iK4) exp(im+), 
(9.265) 
where 8,4, and + are the Euler angles and K and m are integers, O(8) satisfies 
the second-order ordinary differential equation 
dO(8) 
(m - KCOs8)2 @(e) + a@(U) = 0, 
(9.266) 
&O(U) 
de2 
+cotu---- 
- 
dB 
sin2 u 
where 
(9.267) 
A, W, C, and h are other constants that come from the physics of the problem. 
With the substitution 
Y = O(U) sin'/2 U ,  
(9.268) 
Equation (9.266) becomes 
Y + (a + K~ + 1/4)Y = 0. 
(9.269) 
( m -  1/2)(m+ 1/2)+rc2-2rn~cosU 
sin2 u 

BESSEL FUNCTIONS (TYPE C) 
155 
This equation is of type A, and we identify the parameters in Equation (9.90) 
as 
a = 1, c = -1/2, 
d = -6, p = 0. 
The factorization is now given by 
k(0, m) = (m - 1/2) cot e - K /  sin 8, 
p ( m )  = (m - 1/2)2. 
Eigenfunctions can be obtained from 
SinJ-n+l/2 
COSJ+n+l/2 - 
e 
2 
2 
by using 
2 1r2 
1 
YE-’ = ( J  + -)2 - (m - -)2 
L 
The corresponding eigenvalues are 
c7 + K + 1/4 = ( J  + 1/2)2 
J - Iml and J - 1.1 
= 0,1,2, ... 
so that 
(9.270) 
(9.271) 
(9.272) 
(9.273) 
(9.274) 
(9.275) 
(9.276) 
9.10 BESSEL FUNCTIONS (TYPE C) 
Bessel’s equation is given as 
z2J$(z) +zJL(z) + (A22 - m2)Jm(.) = 0. 
(9.277) 
Multiplying this equation by l/z, we obtain the first canonical form as 
(9.278) 
where 
p(z) = z, and ~ ( z )  
= 2. 
(9.279) 

156 
STURM-LIOUVILLE SYSTEMS AND THE FACTORIZATION METHOD 
A second transformation, 
(9.280) 
(9.281) 
gives us the second canonical form 
9 = 0. 
1 
d21k 
(m2 - 1/4) 
dx2 
2 2  
-+ [x- 
(9.282) 
This is type C, and its factorization is given as 
(9.283) 
p ( m )  = 0. 
(9.284) 
(m- f) 
k(x,m) = 
~ 
x
'
 
Because p ( m )  is neither a decreasing nor an increasing function of m, we have 
no limit (upper or lower) to the ladder. We have only the recursion relations 
and 
where 
9, = X W m ( A 1 / 2 X ) .  
9.11 HARMONIC OSCILLATOR (TYPE D) 
The Schrodinger equation for the harmonic oscillator is given as 
(9.285) 
(9.286) 
(9.287) 
(9.288) 
where 
equation can be written in either of the two forms (See Problem 9.14) 
= ( h / p ~ ) * / ~ x  
and A = 2E/hw in terms of the physical variables. This 
O-O,@x = (A + 1)Qx 
(9.289) 
and 
0+0_9x 
= (A - l)Ikx, 
(9.290) 

PROBLEMS 
157 
where 
(9.291) 
Operating on Equation (9.289) with Of and on Equation (9.290) with 0- 
we obtain the analog of Theorem I as 
*A,, 
0: o+*x 
(9.292) 
and 
Q A - 2  a o-*x. 
(9.293) 
Moreover, corresponding to Theorem IV, we find that we can not lower the 
eigenvalue X indefinitely. Thus we have a bottom of the ladder 
A = 2nf 1, n = 0,1,2 ,"' . 
(9.294) 
Thus the ground state must satisfy 
o-qo = 0, 
(9.295) 
(9.296) 
Now the other eigenfunctions can be obtained from 
\kn+l = [an + 2]-'/20+*11,, 
(9.297) 
*,_I 
= [2n]-"20_*,. 
(9.298) 
Problems 
9.1 
Starting from the first canonical form of the Sturm-Liouville equation: 
d x  [ P ( Z ) F ]  + q(2)9(2) + XW(Z)*(Z) = 0, x E [a, b] , 
derive the second canonical form: 
where 
d2p1 
2 d p d w  
1 d2w 
p d z  d z  
w dz2 
p d z 2  I 
---+--+-- 

158 
STURM-LIOUVILLE SYSTEMS AND THE FACTORlZATlON METHOD 
by using the transformations 
Y(Z) = w [ W ( ~ ) P ( ~ ) I ~ ~ ~  
and 
W ( X )  
dz = dx [m] 
9.2 
Derive the normalization constants in 
W+I" fl(cos6) 
and 
21 + 1 ( 1  -m)! 1 
y,-"(e,$> = --- 
[L-1" p,(cos6). 
J 2 
(i+l)! 27r 
9.3 Derive the normalization constant in 
9.4 
Derive Equation (9.195), which is given as 
9.5 
The general solution of the differential equation 
is given as the linear combination 
y(x) = C, sin f i x  + C, cos A x .  
Show that factorization of this equation leads to the trivial result with 
k(x,m) = 0, 
p(m) = 0, 
and the corresponding ladder operators just produce other linear combinations 
of sin A x  
and cos dz. 
9.6 
Show that taking 
k(z, m) = h ( z )  + kl(z)m + k2(z)m2 

PROBLEMS 
159 
does not lead to any new categories, except the trivial solution given in Prob 
lem 9.5. A similar argument works for higher powers of m. 
9.7 
in k(z, m), no new factorization types appear. 
9.8 Show that 
Show that as long as we admit a finite number of negative powers of m 
is a periodic function of m with the period one. 
Use this result to verify 
9.9 Derive the stepdown operator in 
9.10 
the equation 
Follow the same procedure used in Path I in Section 9.6.5 to derive 
ct m 
1 
(1+1-m) 
yln,?’(8) = - 
C,+i,m (1 + 1 - m) J(l + m + 1)(1+ m + 2) 
C O S ~ - - -  7- 
(1+;)sin6’}yY(B). 
d8 
sin8 
9.11 
tions of the first kind: 
Use the factorization method to show that the spherical Hankel func- 
h p  = j ,  + in, 
can be expressed as 
Hint: Introduce 
in 
yj‘ + [ 1 - - 
”1 y1 = 0. 

160 
STURM-LIOUVILLE SYSTEMS AND THE FACTORIZATION METHOD 
9.12 
normalized eigenfunctions y(n, E ,  T )  of the differential equation 
Using the factorization method, find a recursion relation relating the 
to the eigenfunctions with 1 f 
1. 
Hint: First show that 
1 = n - 1,n - 2, ..., 1 = integer 
and the normalization is 
9.13 The harmonic oscillator equation 
d2 9 
d x 2  - 
+ ( E  - x2)*(x) = 0 
is a rather special case of the factorization method because the operators O& 
are independent of any parameter. 
i) Show that the above equation factorizes as 
d 
dx 
o,=--x 
and 
d 
dx 
0- = -- -x. 
ii) In particular, show that if 9&(z) 
is a solution for the energy eigenvalue E, 
then 
is a solution for E + 2, while 
is a solution for E - 2. 
iii) Show that E has a minimum 
with 
Emin = 1, 
En = 2n + 1, 
n = 0,1,2, . . . 

PROBLEMS 
161 
and show that the E < 0 eigenvalues are not allowed. 
to €,in 
and then use it to express all the remaining eigenfunctions. 
iv) Using the factorization technique, find the eigenfunction corresponding 
Hint: Use the identity 
9.14 
Show that the standard method for the harmonic oscillator problem 
leads to a single ladder with each function on the ladder corresponding to a 
different eigenvalue A. This follows from the fact that ~ ( z ,  
m) is independent of 
m. The factorization we have introduced in Section 9.11 is simpler, and in fact 
the method of factorization originated from this treatment of the problem. 
9.15 The spherical Bessel functions jl(2) are related to the solutions of 
d2Yl 
l(1 + 1) 
- 
& 2 +  [ I-- 
x2 ] Y d 2 )  =o, 
(regular at x = 0) by 
Y1 ( X I  
j&) = -. 
2 
Using the factorization technique, derive recursion formulae 
i) Relating j ~ ( z )  
to j,+,(z) and j~-l(z). 
ii) Relating j i ( x )  to j,+,(x) and jl-l(z) . 

This Page Intentionally Left Blank

I0 
COORDINATES and 
TENSORS 
Starting with a coordinate system is probably the quickest way to introduce 
mathematics into the study of nature. There are many different ways to 
choose a coordinate system. Depending on the symmetries of the physical 
system, a suitable choice not only simplifies the problem but also makes the 
interpretation of the solution easier. Once a coordinate system is chosen, we 
can start studying physical processes in terms of mathematical constructs like 
scalars, vectors, etc. Naturally the true laws of nature do not depend on the 
coordinate system we use; thus we need a way to express them in coordinate 
independent formalism. In this regard tensor equations, which preserve their 
form under general coordinate transformations, have proven to be very useful. 
In this chapter we start with the Cartesian coordinates, their transforma- 
tions, and Cartesian tensors. We then generalize our discussion to generalized 
coordinates and general tensors. The next stop in our discussion is the coor- 
dinate systems in Minkowski spacetime and their transformation properties. 
We also introduce four-tensors in spacetime and discuss covariance of laws 
of nature. We finally discuss Maxwell’s equations and their transformation 
properties. 
10.1 CARTESIAN COORDINATES 
In threedimensional Euclidean space a Cartesian coordinate system can be 
constructed by choosing three mutually orthogonal straight lines. 
A point is 
defined by giving its coordinates, ( q , z 2 , q ) ,  or by using the position vector 
163 

164 
COORDINATES AND TENSORS 
fig. 10.1 Cartesian coordinate system 
--+ r as 
---f- 
r - IL& 
+ z2G2 + ~ 3 G 3  
(10.1) 
= (XI 7 2 2 , 2 3 ) ,  
(10.2) 
where G; are unit basis vectors along the coordinate axis (Fig. 10.1). Similarly, 
an arbitrary vector in Euclidean space can be defined as 
+ 
u = U,ZI + a2Z2 + a323, 
(10.3) 
where the magnitude is given as 
IZi'l = a  
(10.4) 
10.1.1 
Algebra of Vectors 
i) Multiplication of a vector with a constant c is done by multiplying each 
component with that constant: 
c - 2  = C U l G ,  + ca2Gp + cu3S3, 
(10.5) 
= (cal,caz, ca3). 

CARTESIAN COORDINATES 
165 
t i?=izx* 
Fig. 10.2 Scalar and vector products 
ii) Addition or subtraction is done by adding or subtracting the correspond- 
ing components of two vectors: 
i?*T= (a1 k b l , a z f b 2 , a s f b 3 ) .  
iii) Multiplication of vectors. 
There are two types of vector multiplication: 
a) Dot or scalar product is defined as 
(10.6) 
( 10.7) 
(a, b) = i?. f = abcos@ab 
= aibi + a 2 b 2  + asbs, 
where gab is the angle between the two vectors. 
b) Vector product is defined as 
(10.8) 
-+ 
-+. C = Z X  
b 
= ( @ b 3  - a 3 b 2 ) s l  + ( ~ 3 b l  - alba)& + ( a l b z  - azbl)Z3 . 
Using the permutation symbol, we can also write the components of a vector 
product as 
3 
Ci = 
Q j k U j b k ,  
(10.9) 
j , k = l  
where the permutation symbol takes the values 
+1 for cyclic permutations 
t i j k  = 
0 
when any two indices are equal . 
- 1 for anticyclic permutations 
c = UbSin6ab , 
(10.10) 
{ 
The vector product of two vectors is again a vector with the magnitude 
where the direction is conveniently found by the right-hand rule (Fig. 10.2). 

166 
COORDINATES AND TENSORS 
Fig. 10.3 Motion in Cartesian coordinates 
10.1.2 
Differentiation of Vectors 
In a Cartesian coordinate system motion of a particle can be described by 
giving its position in terms of a parameter, which is usually taken as the time 
(Fig. 10.3), that is, 
?(t) = ( Z l ( t ) ,  zz(t), 
5 3 ( t ) ) -  
(10.11) 
We can now define velocity 3, 
and acceleration 3 
as 
T+(t + At) - T+(t) 
At 
- lim 
d 7  
-- 
dt 
At-0 
7 
d 3  
?(t + At) - T(t) 
At 
- 
= lim 
d2 ?;' 
dt 
At-0 
7 
dt2 ' 
(10.12) 
(10.13) 
(10.14) 
(10.15) 
The derivative of a general vector is defined similarly. Generalization of these 
equations to n dimensions is obvious. 
10.2 ORTHOGONAL TRANSFORMATIONS 
There are many ways to chose the orientation of the Cartesian axes. Symme- 
tries of the physical system often make certain orientations more advantageous 
than others. In general, we need a dictionary to translate the coordinates 

ORTHOGONAL TRANSFORMATIONS 
167 
Fig. 10.4 Direction cosines 
assigned in one Cartesian system to another. A connection between the coor- 
dinates of the position vector assigned by the two sets of Cartesian axes with 
a common origin can be obtained as (Fig. 10.4) 
(10.16) 
(10.17) 
where 
This can also be written as 
where cos 6ij are called the direction cosines defined as 

168 
COORDINATES AND TENSORS 
h 
cos eij = isi . sj. 
(10.20) 
Note that the first unit basis vector is always taken as the barred system, that 
is, 
h 
cosej, =isj .si. 
(10.21) 
The transformation equations obtained for the position vector are also true 
for an arbitrary vector 3 
as 
- 
al = (cosell) al + (cose12)a2 + (cose13)a3 
a2 = (cosQ21) a1 + (cosQ22)az + (cosQ23)a3 
a3 = (cose3,) al + (cos~32)a2 + (COS~33)a3 . 
(10.22) 
- 
- 
The transformation equations given in Equation (10.22) are the special case 
of general linear transformation, which can be written as 
- 
21 = allxl f a1222 + a13x3 
2 2  = a2121 + a2222 + a2323 
x3 = a31x1 + a3222 + (333x3 . 
(10.23) 
- 
- 
aij are constants independent of 7 
and 7. 
A convenient way to write Equa- 
tion (10.23) is 
(10.24) 
where we have used the Einstein summation convention, which implies sum- 
mation over the repeated (dummy) indices, that is, Equation (10.24) means 
- 
z. - a , . % .  
z - t2 3 ,  i , j =  1,273, 
3 
= aijxj, 
i , j  = 1,2,3. 
(10.25) 
(10.26) 
Unless otherwise stated, we use the Einstein summation convention. Magni- 
tude of 7 
in this notation is shown as 
r = m. 
(10.27) 
Using matrices, transformation Equations (10.23) can also be written as 
r = Ar, 
(10.28) 
- 
where r and f are represented by the column matrices 
r =  [ ii] a n d F =  [ ii], 
(10.29) 

ORTHOGONAL TRANSFORMATIONS 
169 
and the transformation matrix A is represented by the square matrix 
(10.30) 
We use both boldface letter r and ?;’ to denote a vector. Generalization of 
these formulas to n dimensions is again obvious. Transpose of a matrix is 
obtained by interchanging its rows and columns as 
(10.31) 
- 
r =  [ z1 zz 
2 3  3 
and 
We can now write the magnitude of a vector as 
- 
rr= [ z1 
2 2  
2 3  1 [ 
=z,q+.g+z;. 
(10.32) 
(10.33) 
The magnitude off is now given as 
- 
(10.34) 
_ &  
r r  =F(xA>r, 
where we have used the matrix property 
D = B X .  
(10.35) 
From Equation (10.34) it is seen that linear transformations that preserve the 
length of a vector must satisfy the condition 
XA = I, 
(10.36) 
where I is the identity matrix 
I = [ :  
s] 
(10.37) 
Such transformations are called orthogonal transformations. In terms of com- 
ponents the orthogonality condition [Eq. (10.36)] can be written as 

170 
COORDINATES AND TENSORS 
Taking the determinant of the orthogonality relation, we see that the deter- 
minant of transformations that preserve the length of a vector satisfies 
[DetAI2 = 1, 
(10.39) 
thus 
DetA = f l .  
(10.40) 
Orthogonal transformations are basically transformations among Cartesian 
coordinates without a scale change. Transformations with DetA = 1 are 
called proper transformations. They are composed of rotations and trans 
lations. Transformations with DetA = -1 are called improper transfor- 
mations, and they involve reflections. 
10.2.1 Rotations About Cartesian Axes 
For rotations about the xa-axis the rotation matrix takes the form 
R3 = 
(10.41) 
0
1
 
Using the direction cosines we can write &(0) for counterclockwise rotations 
as (Fig. 10.5) 
(10.42) 
1 
i 0  0
1
 
0 
C O S ~  s i n 4 ] a n d R 2 ( + ) = [  
sin+ 
0 
0 1 
cos$ 
0 
COSB 
sin8 0 
Rs(0) = 
-sin0 
cos0 0 
. 
Similarly, the rotation matrices corresponding to counterclockwise rotations 
about the 21- and xa-axis can be written, respectively, as 
1
0
 0 
cos+ 0 -sin+ 
0 -sin4 
C O S ~  
(10.43) 
10.3 FORMAL PROPERTIES OF THE ROTATION MATRIX 
i) Two sequentially performed rotations, say A and B, is equivalent to 
another rotation C as 
C = AB. 
(10.44) 
ii) Because matrix multiplications do not commute, the order of rotations 
is important, that is, in general 
AB f B A .  
(10.45) 

FORMAL PROPER TIES OF THE 170 
JA JlON MATRIX 
171 
- 
3 
NX1 
fig. 10.5 Direction cosines 
However, the associative law, 
A(BC) = (AB)C, 
(10.46) 
holds between any three rotations A, B, and C. 
nality relation [Eq. (lo.%)], it is equal to the transpose of A, that is, 
iii) The inverse transformation matrix A-' exists, and from the orthogo- 
A - l = ; i .  
(10.47) 
Thus for orthogonal transformations we can write 
AA = AX = I. 
(10.48) 

172 
COORD/NATES AND TENSORS 
10.4 
EULER ANGLES AND ARBITRARY ROTATIONS 
The most general rotation matrix has nine components (10.30). However, the 
orthogonality relation AA = I, written explicitly as 
- 
(10.49) 
gives six relations among these components. Hence, only three of them can be 
independent. In the study of rotating systems to describe the orientation of a 
system it is important to define a set of three independent parameters. There 
are a number of choices. The most common and useful are the three Euler 
angles. They correspond to three successive rotations about the Cartesian 
axes so that the final orientation of the system is obtained. The convention we 
follow is the most widely used one in applied mechanics, in celestial mechanics, 
and frequently, in molecular and solid-state physics. For different conventions, 
we refer the reader to Goldstein et al. 
The sequence starts with a counterclockwise rotation by q5 about the x3-axis 
of the initial state of the system as 
This is followed by a counterclockwise rotation by 8 about the xi of the 
intermediate axis as 
Finally, the desired orientation is achieved by a counterclockwise rotation 
about the x!-axis 
by $I as 

EULER ANGLES AND ARBITRARY ROTATIONS 
173 
A(+), B(6), and C(+) are the rotation matrices for the corresponding trans- 
formations, which are given as 
(10.53) 
(10.54) 
1 
[
o
 
0
1
 
" 1  
1 
[
o
 
0
1
 
cos+ 
sin+ 0 
B(+)= 
-sin+ 
cosq5 0 
, 
0 -sin8 
cos8 
1
0
 
(10.55) 
0 
cos8 
sin8 , 
cos+ 
sin$ 
0 
D(+) = 
-sin+ 
cos+ 
0 . 
In terms of the individual rotations, elements of the complete transformation 
matrix can be written as 
A = DCB, 
(10.56) 
A =  
(10.57) 
1 
cos+cos + - cos8 sin +sin + 
- sin + cos + - cos 6sin +cos + 
cos+ sin + + cos8cos+sin + 
- sin + sin + + cos 6cos +cos + 
sin+sin6 
cos +sin 8 
sin 8 sin + 
-sin 8cos q5 
cos 8 
A-l = x. 
(10.58) 
We can also consider the elements of the rotation matrix as a function of 
The inverse of A is 
some single parameter t and write 
q5 = w+t, w = wet, $ = w&. 
If t is taken as time, w can be interpreted as the constant angular velocity 
about the corresponding axis. Now, in general the rotation matrix can be 
written as 
I 
all(t) al2(t) al3(t) 
a3l(t) a32(t) a33(t) 
a21(t) a22(t) a23(t) . 
(10.59) 
Using trigonometric identities it can be shown that 
A(t2 + t i )  = A(t2)A(ti). 
(10.60) 
Differentiating with respect to t2 and putting t2 = 0 and tl = t, we obtain a 
result that will be useful to us shortly as 
A'(t) = A'(O)A(t). 
(10.61) 

174 
COORDINATES AND TENSORS 
2 
+ 
r /' 
-* 
r 
f 
Fig. 10.6 Passive and active views of the rotation matrix 
10.5 
ACTIVE AND PASSIVE INTERPRETATIONS OF ROTATIONS 
It is possible to view the rotation matrix A in 
F=Ar 
(10.62) 
as an operator acting on r and rotating it in the opposite direction, while 
keeping the coordinate axes fixed (Fig. 
This is called the active 
view. The case where the coordinate axes are rotated is called the passive 
view. In principle both the active and passive views lead to the same result. 
However, as in quantum mechanics, sometimes the active view may offer some 
advantages in studying the symmetries of a physical system. 
In the case of the active view, we also need to know how an operator A 
transforms under coordinate transformations. Considering a transformation 
represented by the matrix B, we multiply both sides of Equation (10.62) by 
B to write 
10.6) . 
BI; = BAr. 
(10.63) 
Using 
BB-I 
= B - ~ B  
= I, 
(10.64) 
we now write Equation (10.63) as 
BF = BAB-lBr, 
- 
r' = A'r'. 
In the new coordinate system T and r are related by 
(10.65) 
(10.66) 
(10.67) 
- 
r' = BF 

INFINITESIMAL TRANSFORMATIONS 
175 
and 
rl = Br. 
(10.68) 
Thus the operator A' becomes 
A' = BAB-l. 
(10.69) 
This is called similarity transformation. If B is an orthogonal transfor- 
mation, we then write 
A' = BAB. 
(10.70) 
In terms of components this can also be written as 
a! v 
' = b2kbljUbl. 
(10.71) 
10.6 
INFINITESIMAL TRANSFORMATIONS 
A proper orthogonal transformation depending on a single continuous param- 
eter t can be shown as 
r(t) = A(t)r(O). 
(10.72) 
Differentiating and using Equation (10.61) we obtain 
-= 
dr(t) 
A'(t)r(O) 
dt 
= A'(O)A(t)r(O) 
= Xr(t), 
(10.73) 
( 10.74) 
( 10.75) 
where 
X = A'(0). 
(10.76) 
Differentiating Equation (10.75) we can now obtain the higher-order deriva- 
tives as 
(10.77) 
Using these in the Taylor series expansion of r(t) about t = 0 we write 
(10.78) 

176 
COORDINATES AND TENSORS 
thus obtaining 
(10.79) 
1 
r(t) = (I + X t + z X 2 t 2  + . . . )r(O) . 
This series converges, yielding 
r ( t )  = exp(Xt)r(O) . 
(10.80) 
This is called the exponential form of the transformation matrix. For infinites 
imal transformations t is small; hence we can write 
r(t) N (I + Xt)r(O), 
(10.81) 
(10.82) 
Sr ~ l i  
Xtr(O), 
(10.83) 
where X is called the generator of the infinitesimal transformation. 
Using the definition of X in Equation (10.76) and the rotation matrices 
[Eqs. (10.42) and (10.43)] we obtain the generators of infinitesimal rotations 
about the z1- ,z2- , and z~-axes, respectively as 
r ( t )  - r(0) N Xtr(O), 
0
0
0
 
0 0 -1 
0 
1 0  
(10.84) 
An arbitrary infinitesimal rotation by the amounts t l ,  t2, and t3 about their 
respective axes can be written as 
r = (I + X3t3)(I + X2t2)(I + Xltl)r(O) 
= (I + X3t3 + X2t2 + X,t,)r(O). 
(10.85) 
Defining the vector 
x = XIS, + X2S2 + X3S3 
= ( X l ,  x2, X3) 
(10.86) 
and the unit vector 
h 
1 
n =  dwi 
[ i,] 
(10.87) 
we can write Equation (10.85) as 
r ( t )  = (I + X.iit)r(O), 
(10.88) 
where 
t =  Jm. 
(10.89) 
This is an infinitesimal rotation about an axis in the direction i? by the amount 
t. For finite rotations we write 
r(t) = ex-%(0). 
(10.90) 

INFINITESIMAL TRANSFORMATIONS 
177 
10.6.1 Infinitesimal Transformations Commute 
Two successive infinitesimal transformations by the amounts tiand t2 can be 
written as 
r = (I + X2t2)(I+ Xltl)r(O) , 
= [I + (tlXl+t2X2)] r(0) . 
(10.91) 
Because matrices commute with respect to addition and subtraction, infinites- 
imal transformations also commute, that is 
For finite rotations this is clearly not true. Using Equation (10.43) we can 
write the rotation matrix for a rotation about the xz-axis followed by a rota- 
tion about the xl-axis as 
1 
0 
- sin $ 
cosCp 
sin4cos$ 
cosdsin+ 
-sin4 
cos~cos$ 
(10.93) 
Reversing the order we get 
cos $ 
(10.94) 
sin $ sin Cp 
- sin $ cos Cp 
R2R1 = 
0 
cos Cp 
sin 4 
[ sin $ - cos $J sin q5 
cos $ cos 4 
It is clear that for finite rotations these two matrices are not equal: 
RiR2 # R2R1. 
(10.95) 
However, for small rotations, say by the amounts Sic, and 64, we can use the 
approximations 
sin 6$ N S+, sin 6Cp N 6Cp 
(10.96) 
cos6$ N 1, cos6Cp _N 1 
to find 
1
0
 
R1R2 = [ 6+ 
1 
=R2R,. 
(10.97) 
6$ 
-64 
Note that in terms of the generators [Eq. (10.84)] we can also write this as 
1
0
0
 
0 0 -1 
0
0
0
 
0
1
0
 + 6 $ 0 0  
0 
+64 0 
0 
R1R2 = [ o  0 
0 
0 ]  
[ o  -1 A] 
= I + S$Xl+ 64x2 
= I + 64x2 + 6+Xl 
= R2R1, 
(10.98) 

178 
COORDINATES AND TENSORS 
which again proves that infinitesimal rotations commute. 
10.7 CARTESIAN TENSORS 
Certain physical properties like temperature and mass can be described com- 
pletely by giving a single number. They are called scalars. Under orthogonal 
transformations scalars preserve their value. Distance, speed, and charge are 
other examples of scalars. On the other hand, vectors in three dimensions 
require three numbers for a complete description, that is, their ~ 1 ~ x 2 ,  
and z 3  
components. Under orthogonal transformations we have seen that vectors 
transform as 
a! 
2 = A .  
e3 .a. 
3' 
(10.99) 
There are also physical properties that in three dimensions require nine 
components for a complete description. For example, stresses in a solid have 
nine components that can be conveniently represented as a 3 x 3 matrix: 
t . .  
23 - 
- [ ::: ::: 2 ] 
(10. 100) 
t31 
t 3 2  
t 3 3  
Components t i j  correspond to the forces acting on a unit area element, that 
is, t i j  is the ith component of the force acting on a unit area element when 
its normal is pointing along the jth axis. Under orthogonal transformations 
stresses transform as 
Stresses, vectors, and scalars are special cases of a more general type of objects 
called tensors. 
Cartesian tensors in general are defined in terms of their transformation 
properties under orthogonal transformations as 
All indices take the values 1,2,3, ..., n, where n is the dimension of space. An 
important property of tensors is their rank, which is equal to the number 
of free indices. In this regard, scalars are tensors of zeroth rank, vectors are 
tensors of first rank, and stress tensor is a second-rank tensor. 
10.7.1 
Operations with Cartesian Tensors 
i) Multiplication with a constant is accomplished by multiplying each com- 
ponent of the tensor with that constant. 

CARTESIAN TENSORS 
179 
ii) Addition/subtraction of tensors of equal rank can be done by addinglsubtracting 
iii) Rank of a composite tensor is equal to the number of its free indices. 
the two tensors term by term. 
For example, 
AikjBjlm 
(10.102) 
is a fourth-rank tensor, 
A , .  
23k B.. 
23k 
(10.103) 
is a scalar, and 
A i j k i B j k i  
(10.104) 
is a vector. 
iv) We can obtain a lower-rank tensor by contracting some of the indices 
of a tensor or by contracting the indices of a tensor with another tensor. For 
example, 
(10.105) 
For a second-rank tensor, by contracting the two indices we obtain a scalar 
called the trace 
A = Aii = All + A22 + A33 +. . . + Ann- 
v) In a tensor equation, rank of both sides must match 
(10.106) 
Aij ... n = Bij ... n 
(10.107) 
vi) We have seen that tensors are defined with respect to their transfor- 
mation properties. For example, from two vectors ai and bj we can form a 
second-rank tensor t i j  as 
This is also called the outer product of two vectors. The fact that t i j  is 
a second-rank tensor can easily be verified by checking its transformation 
properties under orthogonal transformations. 
10.7.2 
Tensor Densities or Pseudotensors 
Let us now consider the Kronecker delta, which is defined in all coordinates 
as 
1 for i = j  
0 f o r i f j  
sij = { 
(10.109) 

180 
COORDlNATES AND TENSORS 
To see that it is a second-rank tensor we check how it transforms under or- 
thogonal transformations, that is, 
qj = a i k a j l 6 k l  
= a l k a k j .  
(10.1 lo) 
a!. 
13 = 6.. 
13. 
(10.111) 
From the orthogonality relation [Eq. (10.3831 this gives 
Hence the Kronecker delta is a second-rank tensor. 
Civita symbol. It is defined in all coordinates as 
+1 for cyclic permutations 
{ -1 
for anticyclic permutations 
Let us now investigate the tensor property of the permutation or the Levi- 
t i j k  = 
0 
when any two indices are equal . 
(10.112) 
For Eijk to be a third-rank tensor it must transform as 
(10.113) 
However, using the definition of a determinant, one can show that the right- 
hand side is c i j k  det a; thus if we admit improper transformations where det a = 
-1, Eijk is not a tensor. A tensor that transforms according to the law 
T i j k  ... = a i i a j m a k n  . . . x m n  ... det a 
( 10.114) 
is called a pseudotensor or a tensor density. 
The cross product of two vectors 
--+ 
--+ c = Z X  
b ,  
which in terms of coordinates can be written as 
Ci = E i j k a j b k ,  
is a pseudovector, whereas the triple product 
--+ 
7. 
(2 
X b ) = EijkCi a j b k  
is a pseudoscalar. 
(10.115) 
(10.116) 
(10.117) 
10.8 GENERALIZED COORDINATES AND GENERAL TENSORS 
So far we have confined our discussion to Cartesian tensors, which are defined 
with respect to their transformation properties under orthogonal transforma- 
tions. However, the presence of symmetries in the physical system often makes 

GENERALIZED COORDINATES AND GENERAL TENSORS 
181 
other coordinate systems more practical. For example, in central force prob- 
lems it is advantageous to work with the spherical polar coordinates, which 
reflect the spherical symmetry of the system best. For axially symmetric 
problems use of the cylindrical coordinates simplifies equations significantly. 
Usually symmetries indicate which coordinate system to use. However, in less 
obvious cases, discovering the symmetries and their generators can help us to 
construct the most advantageous coordinate system for the problem at hand. 
We now extend our discussion of Cartesian coordinates and Cartesian tensors 
to generalized coordinates and general tensors. These definitions can also be 
used for defining tensors in spacetime and also for tensors in curved spaces. 
A general coordinate transformation can be defined as 
2 = * ( X I ,  2 2 ,  ...) xn), 2 = 1, ..., 12. 
(10.118) 
In short, we write this as 
i 
IC =zi(zk), 
i,k = I ,..., n. 
(10.119) 
xk = X k ( * ) ,  
2, k = 1, ..., n. 
(10.120) 
The inverse transformation is defined as 
For reasons to become clear later we have written all the indices as super- 
scripts. Differentiating Equation (10.119) we can write the transformation 
law for infinitesimal displacements as 
(10.121) 
We now consider a scalar function, &xi), and differentiate with respect to Ti 
to write 
= 2 [S] 
g. 
k = l  
(10.122) 
(10.123) 
Until we reestablish the Einstein summation convention for general tensors, 
we write the summation signs explicitly. 
10.8.1 Contravariant and Covariant Components 
Using the transformation properties of the infinitesimal displacements and 
the gradient of a scalar function we now define contravariant and covariant 

182 
COORDINATES AND TENSORS 
components. A contravariant component is defined with respect to the trans- 
formation rule 
where the inverse transformation is defined as 
dxk 
n 
a' 
= x [ z] 
a .  
a= 1 
(10.124) 
(10.125) 
(10.126) 
We also define a covariant component according to the transformation rille 
(10.127) 
where the components are now shown as subscripts. The inverse transforma- 
tion is written as 
a,, = 2 [ $1 
i i z .  
i= 1 
(10.128) 
A second-rank tensor can be contravariant, covariant, or with mixed indices 
with the following transformation properties: 
Similarly, a general tensor can be defined with mixed indices as 
(10.129) 
(10.130) 
(10.131) 
(10.132) 

GENERALIZED COORDINATES AND GENERAL TENSORS 
183 
Using Equations (10.128) and (10.127) we write 
(10.133) 
(10.134) 
(10.135) 
(10.136) 
where 6:' 
is the Kronecker delta, which is a second-rank tensor with the 
transformation property 
= 6,. 
(10.137) 
(10.138) 
It is the only second-rank tensor with this property. 
10.8.2 
Let us now see how the distance between two infinitesimally close points 
transforms under general coordinate transformations. We take our unbarred 
coordinate system as the Cartesian coordinates; hence the line element that 
gives the square of the distance between two infinitesimally close points is 
Metric Tensor and the Line Element 
n 
ds2 = c dxkdxk. 
(10.139) 
Because distance is a scalar, its value does not change under general coordinate 
k=l 
transformations; thus we can write 
&2 = ds2 
(10.140) 
(10.141) 
j = 1  
(10.142) 
(10.143) 

184 
COORDINATES AND TENSORS 
where gij is a second rank-symmetric tensor defined as 
dxkdxk 
m 853. 
9 . .  - c -- 
23 - 
k= 1 
(10.144) 
It is called the metric tensor or the fundamental tensor. The metric 
tensor is very important in the study of curved spaces and spacetimes. 
If we write the line element [Eq. (10.139)] in Cartesian coordinates as 
n
n
 
we see that the metric tensor is the identity matrix 
gij=I=6.. 
23' 
Given an arbitrary contravariant vector u', 
transforms. We first write C:==, 
[gijd] as 
(10.145) 
(10.146) 
let us see how 
Comparing with Equation (10.127), we see that the expression 
1 
(10.147) 
(10.148) 
(10.149) 
transforms like a covariant vector; thus we define the covariant components 
of ui 
as 
j=1 
(10.150) 

GENERALIZED COORDINATES AND GENERAL TENSORS 
185 
Similarly, we can define the metric tensor with contravariant components 
as 
where 
n
n
 
= 6;'. 
Using the symmetry of the metric tensor we can write 
n 
(10.151) 
(10.152) 
(10.153) 
k= 1 
We see that the metric tensor can be used to lower and raise indices of a given 
tensor. Thus a given vector 3 
can be expressed in terms of either its covariant 
or its contravariant components. In general the two types of components are 
different, and they are related by 
(10.154) 
j=l 
j = 1  
For the Cartesian coordinates the metric tensor is the Kronecker delta; thus 
we can write 
(10.155) 
Hence both the covariant and the contravariant components are equal in 
Cartesian coordinates, and there is no need for distinction between them. 
Contravariant components of the metric tensor are also given as (Gant- 
macher) 
(10.156) 

186 
COORDINATES AND TENSORS 
where 
A3'= cofactor of gji 
and 
(10.157) 
g = det g i j .  
(10.158) 
10.8.3 Geometric Interpretation of Covariant and Contravariant 
Components 
Covariant and contravariant indices can be geometrically interpreted in terms 
of oblique axis. A vector 3 
in the coordinate system shown in Figure 10.7 
can be written as 
+ 
a = a%+ + a%2, 
(10.159) 
where i?$ 
are the unit basis vectors along the coordinate axes. As seen, the 
contravariant components are found by drawing parallel lines to the coordinate 
axes. However, we can also define components by dropping perpendiculars to 
the coordinate axes as 
ai = 3. 
Gi, 
i = 1,2. 
( 10.160) 
The scalar product of two vectors is given as 
+ 
3. 
b = (a16 + a264 . (b1Gl + b2G2) 
( 10.161) 
= alb' (21 . GI) + a1b2 (GI . G2) + a2b' ( G 2 .  GI) + a2b2 (G2 . &) . 
Defining a symmetric matrix 
(10.162) 
A
h
 
yij = ei . ej, i , j  = 1,2 
we can write Equation (10.161) as 
2
2
 
2.7;'= 
C&aib7. 
(10.163) 
i=l j=1 
We can also write 
(10.164) 

GENERALIZED COORDINATES AND GENERAL TENSORS 
187 
fig. 10.7 Covariant and contravariant components 
All these remind us tensors. To prove that 3-T is a tensor equation we have 
to prove that it has the same form in another coordinate system. It is clear 
that in another coordinate system with the basis vectors 6; and &$, 2. 
7 
will have the same form as 
2
2
 
2
2
 
(10.165) 
--+ 
where gLl = a;- GI, thus proving its tensor character. Because ?i’ and b are 
arbitrary vectors, we can take them as the infinitesimal displacement vector 
as 
thus 
2
2
 
gives the line element with the metric 
A
A
 
g;j = ei - e j ,  
i , j  = 1,2. 
(10.167) 
(10.168) 

188 
COORDINATES AND TENSORS 
Hence aa and ai are indeed the contravariant and the covariant components 
of an arbitrary vector, and the difference between the covariant and the con- 
travariant components is real. 
In curved spaces dxi corresponds to the coordinate increments on the sur- 
face. The metric tensor gij can now be interpreted as the product i3i . i3j of 
the unit tangent vectors along the coordinate axis. 
10.9 OPERATIONS WITH GENERAL TENSORS 
10.9.1 
Einstein Summation Convention 
Algebraic operations like addition, subtraction, and multiplication are accom- 
plished the same way as in Cartesian tensors. For general tensors the Ein- 
stein summation convention, which implies summation over repeated indices, 
is used by writing one of the indices as covariant and the other as contravari- 
ant. For example, the line element can be written in any one of the following 
forms: 
or 
From now on, unless otherwise stated, we use this version of the Einstein 
summation convention. 
10.9.2 Contraction of Indices 
We can lower the rank of a tensor by contracting some of its indices as 
(10.171) 
(10.172) 
We can also lower the rank of a tensor by contracting it with another tensor 
as 
(10.173) 
(10.174) 

OPERATIONS WlTH GENERAL TENSORS 
189 
10.9.3 
Multiplication of Tensors 
We can obtain tensors of higher-rank by multiplying two lower rank tensors: 
(10.175) 
(10.176) 
(10.177) 
This is also called the outer product. 
10.9.4 
The Quotient Theorem 
A very useful theorem in tensor operations is the quotient theorem. Suppose 
is a given matrix and AI::;’,’Z?,” 
is an arbitrary tensor. Suppose that 
it is also known that 
TII...i- 
31 ..-.3n 
is a tensor. Then, by the quotient theorem, 
(10.178) 
(10.179) 
is also a tensor. This could be easily checked by using the transformation 
properties of tensors. 
10.9.5 
Equality of Tensors 
Two tensors are equal if and only if all their corresponding components are 
equal, that is, 
Aij - 
- B” , for all i , j ,  and lc. 
(10.180) 
As a consequence of this, a tensor is not zero unless all of its components 
vanish. 
10.9.6 
Tensor Densities 
A tensor density of weight w transforms according to the law 
(10.181) 

190 
where 
COORDINATES AND TENSORS 
is the Jacobian of the transformation, that is, 
(10.182) 
The permutation symbol 6ijk is a third-rank tensor density of weight -1. The 
volume element 
dnx = dx'dx 2...dxn 
(10.183) 
transforms as 
hence it is a scalar density of weight -1. 
The metric tensor is a second-rank tensor that transforms as 
(10.184) 
(10.185) 
Using matrix multiplication determinant of the metric tensor transforms as 
or as 
(10.186) 
(10.187) 
In the last equation we have used absolute values in anticipation of applica- 
tions to relativity, where the metric has signature (- + ++) or (+ - --). 
From Equations (10.184) and (10.187) it is seen that 
f i d " z  = d@.. 
(10.188) 
Thus, APa: is a scalar. 
10.9.7 
Differentiation of Tensors 
We start by taking the derivative of the transform of a covariant vector 

OPERATIONS WITH GENERAL TENSORS 
191 
as 
If we write this as 
(10.189) 
(10.190) 
and if the first term on the right-hand side was absent, then the derivative of 
uj would simply be a second-rank tensor. Rearranging this equation as 
(10.191) 
(10.192) 
we see that the problem is due to the fact that in general the transformation 
matrix [ u i ]  changes with position. For transformations between the Cartesian 
coordinates the transformation matrix is independent of coordinates; thus this 
problem does not arise. However, we can still define a covariant derivative 
that transforms like a tensor. 
We first consider the metric tensor, which transforms as 
(10.193) 
and differentiate it with respect to P 
as 
Permuting the indices, that is, (ijm) -+ (mij) + (jmi), we can obtain two 
more equations: 
axk 8%' 8%" agkl 
gkl f ---- (10.195) 
a2xk ax' 
axk 82x1 
- p & Z g " + - -  rn * i l E j  
P 
*i 
z
j
 axn 
and 
Adding the first two equations and subtracting the last one from the result 
and after some rearrangement of indices we obtain 
(10.197) 

192 
COORDINATES AND TENSORS 
Defining Christoffel symbols of the first kind as 
we write Equation (10.197) as 
where 
We can easily solve this equation for the second derivative to obtain 
(10.198) 
(10.1%) 
(10.200) 
(10.201) 
where we have defined the Christoffel symbols of the second kind as 
(10.202) 
Substituting Equation (10.201) in Equation (10.190), we get 
Rearranging, and using the symmetry property of the Christoffel symbol of 
the second kind: 
(10.204) 
this becomes 
The above equation shows that [ - 
2 - {;}urn] transforms like a covariant 
second-rank tensor. Thus we define the covariant derivative of a covariant 
vector ui as 
(10.207) 

OPERATIONS WITH GENERAL TENSORS 
193 
Similarly, the covariant derivative of a contravariant vector is defined as 
(10.208) 
The covariant derivative is also shown as a,, that is, ajui = ui;j. The covariant 
derivative of a higher-rank tensor is obtained by treating each index at a time 
as 
(10.209) 
Covariant derivatives distribute like ordinary derivatives, that is, 
(AB)., = A,;B + AB,i 
(10.210) 
and 
(uA + bB);i = u A ; ~  + bB,i 
(10.211) 
where A and B are tensors of arbitrary rank and a and b are scalars. 
10.9.8 Some Covariant Derivatives 
In the following we also show equivalent ways of writing these operations 
commonly encountered in the literature. 
1. Using definition Equation (10.123) we can write the covariant derivative 
of a scalar function @ as an ordinary derivative: 
This is also the covariant component of the gradient 
(9.); 
. 
(10.212) 
(10.213) 
2. Using the symmetry of Christoffel symbols, the curl of a vector field 3 
can be defined as the second-rank tensor 
(bx 3). 
, = aiv, - a,vj = vi;j - vj;i 
(10.214) 
23 
(10.215) 

194 
COORDINATES AND TENSORS 
Note that because we have used the symmetry of the Christoffel symbols, 
the curl operation can only be performed on the covariant components 
of a vector. 
3. The covariant derivative of the metric tensor is zero: 
a k g i j  = &;k = 0, 
(10.216) 
with Equation (10.209) and the definition of Christoffel symbols the 
proof is straightforward. 
4. A frequently used property of the Christoffel symbol of the second kind 
is 
In the derivation we use the result 
from the theory of matrices, where g = det gij. 
5. We can now define covariant divergence as 
7.3 
= diUi = u:. 
7 %  
(10.217) 
(10.218) 
(10.219) 
(10.220) 
(10.221) 
If vz is a tensor density of weight +1, divergence becomes 
V.v+==U!Z (= d i d ) ,  
(10.222) 
which is again a scalar density of weight fl. 
6. Using Equation (10.213) we write the contravariant component of the 
gradient of a scalar function as 
We can now define the Laplacian as a scalar field: 
(10.223) 
(10.224) 

OPERATIONS WITH GENERAL TENSORS 
195 
10.9.9 Riemann Curvature Tensor 
Let us take the covariant derivative of ui twice. The difference 
u i ; j k  - Ui;kj 
can be written as 
(10.226) 
where Rijk is the fourth-rank Riemann curvature tensor, which plays a 
central role in the structure of Riemann spaces: 
Three of the symmetries of the Riemann curvature tensor can be summarized 
as 
(10.229) 
(10.230) 
(10.231) 
Actually, there is one more symmetry that we will not discuss. The signifi- 
cance of the Riemann curvature tensor is, that all of its components vanish 
only in flat space, that is we cannot find a coordinate system where 
Rijkl = 0 
(10.232) 
unless the space is truly flat. 
which is obtained from Rijkl by contracting its indices as 
An important scalar in Riemann spaces is the Riemann curvature scalar, 
.
.
 
R == y'lgikR.. 
ajkl = j L R i . .  
221 = Ra.,3 
32 . 
(10.233) 
Note that &jkl = 0 implies R = 0, but not vice versa. 
Example 10.1. Laphcian as a scalar field: We consider the line element 
ds2 = dr2 + r2d2 + r2 sin2 Bd$, 
(10.234) 
where 
x1 = r, x2 = 8, x3 = 4 
(10.235) 
and 
911 = 1, g22 = r2, 933 = r 2 sin28. 
(10.236) 

196 
COORDINATES AND TENSORS 
Contravariant components 9'3 are: 
(10.237) 
Using Equation (10.225) and g = r4 sin2 0, we can write the Laplacian 
as 
(10.238) 
- 
- 1 
[" 
( r 2 s i n o g )  +ae 
d (TaB) 
r2sinOaW +a 
( W E ) ]  
After simplifying, the Laplacian is obtained as 
r2sin6 dr 
34 r2sin28 a4 
' 
(10.239) 
Here we have obtained a well-known formula in a rather straightfor- 
ward manner, demonstrating the advantages of the tensor formalism. 
Note that even though the components of the metric tensor depend on 
position [Eq. (10.236)], the curvature tensor is zero, 
R i j k i  = 0; 
(10.240) 
thus the space of the line element [Eq. (10.234)] is flat. However, for 
the metric 
it can be shown that not all the components of R i j k l  vanish. In fact, this 
line element gives the distance between two infinitesimally close points 
on the surface of a hypersphere (S-3) with constant radius &. 
10.9.10 
Geodesics 
Geodesics are defined as the shortest paths between two points in a given 
geometry. In flat space they are naturally the straight lines. We can gener- 
alize the concept of straight lines as curves whose tangents remain constant 
along the curve. However, the constancy is now with respect to the covariant 
derivative. If we parametrize an arbitrary curve in terms of arclength s as 

SPACETIME AND FOUR-TENSORS 
197 
its tangent vector will be given as 
. 
dxi 
t a  = -_ 
ds 
(10.243) 
For geodesics the covariant 
equation of geodesics as 
dX-3 
t"- 
J d s  
or as 
derivative of ti must be zero; thus we obtain the 
= [-$ + {31i}t"] g = 0 
- 
&xi + { } d x j  -- 
dx" = 0. 
ds2 
j k  d s  ds 
(10.244) 
(10.245) 
10.9.11 
lnvariance and Covariance 
We have seen that scalars preserve their value under general coordinate trans 
formations. Certain other properties like the magnitude of a vector and the 
trace of a second-rank tensor also do not change under general coordinate 
transformations. Such properties are called invariants. They are very im- 
portant in the study of the coordinate-independent properties of a system. 
An important property of tensors is that tensor equations preserve their 
form under coordinate transformations. For example, the tensor equation 
transforms into 
(10.247) 
This is called covariance. Under coordinate transformations individual com- 
ponents of tensors change; however, the form of the tensor equation remains 
the same. One of the early uses for tensors in physics was in searching and 
expressing the coordinate independent properties of crystals. However, the 
covariance of tensor equations reaches its full potential only wit$h the intro- 
duction of the spacetime concept and the special and the general theories of 
relativity. 
10.10 
SPACETIME AND FOUR-TENSORS 
10.10.1 
Minkowski Spacetime 
In Newton's theory, the energy of a freely moving particle is given by the 
well-known expression for kinetic energy: 
E = - m u .  
1
2
 
(10.248) 
2 

198 
COORDINATES AND TENSORS 
fig. 10.8 Minkowski spacetime 
Because there is no limit to the energy that one could pump into a system, this 
formula implies that in principle one could accelerate particles to any desired 
velocity. In classical physics this makes it possible to construct infinitely 
fast signals to communicate with the other parts of the universe. Another 
property of Newton’s theory is that time is universal (or absolute), that is, 
identical clocks carried by moving observers, uniform or accelerated, run at 
the same rate. Thus once two observers synchronize their clocks, they will 
remain synchronized for ever. In Newton’s theory this allows us to study 
systems with moving parts in terms of a single (universal) time parameter. 
With the discovery of the special theory of relativity it became clear that 
clocks carried by moving observers run at different rates; thus using a single 
time parameter for all observers is not possible. 
After Einstein’s introduction of the special theory of relativity another 
remarkable contribution toward the understanding of time came with the 
introduction of the spacetime concept by Minkowski. Spacetime not only 
strengthened the mathematical foundations of special relativity but also paved 
the way to Einstein’s theory of gravitation . 
Minkowski spacetime is obtained by simply adding a time axis orthogonal 
to the Cartesian axis, thus treating time as another coordinate (Fig. 10.8). A 
point in spacetime corresponds to an event. However, space and time are also 
fundamentally different and cannot be treated symmetrically. For example, it 
is possible to be present at the same place at two different times; however, if 
we reverse the roles of space and time, and if space and time were symmetric, 
then it would also mean that we could be present at two different places at the 

SPACETIME AND FOUR-TENSORS 
199 
same time. So far there is no evidence for this, neither in the micro- nor in the 
macro-realm. Thus, in relativity even though space and time are treated on 
equal footing as independent coordinates, they are not treated symmetrically. 
This is evident in the Minkowski line element: 
ds)’ = c2dt2 - dx)’ - dy2 - dZ2, 
(10.249) 
where the signs of the spatial and the time coordinates are different. It is 
for this reason that Minkowski spacetime is called pseudo-Euclidean. In 
this line element c is the speed of light representing the maximum velocity 
in nature. An interesting property of the Minkowski spacetime is that two 
events connected by light rays, like the emission of a photon from one galaxy 
and its subsequent absorption in another, have zero distance between them 
even though they are widely separated in spacetime. 
10.10.2 
In Minkowski spacetime there are many different ways to chotlse the orienta- 
tion of the coordinate axis. However, a particular group of coordinate systems, 
which are related to each other by linear transformations of the form 
Lorentz Transformation and the Theory of Special Relativity 
9 = ugzo + a
y
 + a&)’ + 4 . 3  
z1 = u;zo + a;21 + u
p
 + 4 x 3  
2)’ = 
+ uqd + a;x2 + a3r3 
z3 = u;.o 
+ a;z1 + u ; 2  + 4 . 3  
(10.250) 
and which also preserve the quadratic form 
(2))’ 
- (d))’ 
- (2))’- 
( 2 3 ) ) ’ ,  
(10.251) 
have been extremely useful in special relativity. In these equations we have 
written zo = ct to emphasize the fact that time is treated as another coordi- 
nate. 
In 1905 Einstein published his celebrated paper on the special theory of 
relativity, which is based on two postulates: 
First postulate of relativity: It is impossible to detect or measure uniform 
translatory motion of a system in free space. 
Second postulate of relativity: 
The speed of light in free space is the 
maximum velocity in the universe, and it is the same for all uniformly 
moving observers. 
In special relativity two inertial observers K and E, where 
is moving 
uniformly with the velocity 21 along the common direction of the d- 
and 

200 
COORDINATES AND TENSORS 
x3 
2 3  
fig. 10.9 Lorenta transformations 
?$-axes 
are related by the Lorentz transformation (Fig. 10.9): 
1 
V 
2J = J--- 
[." - (,) 
x'] 
1 - u2/c2 
1 
V 
-1 z - 
- J--- 
[-(,)."+x'] 
1 - u2/c2 
(10.252) 
(10.253) 
(10.254) 
(10.255) 
-2 - 2 
x - x  
2 = x .  
3 
Inverse transformation is obtained by replacing u with -v as 
V 
zo = d- 
[ TO+ (;) 
2'1 
1 - v2/c2 
z 1 = d- 
1 
[(--)3?+"1] 
U 
1 - v2/c2 
If the axis in K and R remain parallel but the velocity ?i' of .. 
(10.256) 
(10.257) 
(10.258) 
(10.259) 
ame ?T in frame 
K is arbitrary in direction, then the Lorentz transformation is generalized as 
(10.260) 
(10.261) 
8 
= y [xo- (3.34 

SPACETIME AND FOUR-TENSORS 
201 
We have written y = l/Jm 
and 3 
= 3 / c .  
10.10.3 
Two immediate and important consequences of the Lorentz transformation 
equations [Eqs. (10.252-10.255)] are the time dilation and length contraction 
formulas, which are given as 
Time Dilation and Length Contraction 
(10.262) 
212 
C2 
AT = At(1- -)1/2 
and 
respectively. These formulas relate the time and the space intervals measured 
by two inertial observers ?7 and K .  The second formula is also known as the 
Lorentz contraction. The time dilation formula indicates that clocks carried 
by moving observers run slower compared to the clocks of the observer at 
rest. Similarly, the Lorentz contraction indicates that meter sticks carried by 
a moving observers appear shorter to the observer at rest. 
10.10.4 
Addition of Velocities 
Another important consequence of the Lorentz transformation is the formula 
for the addition of velocities, which relates the velocities measured in the K 
and 1T frames by the formula 
(10.264) 
dx 
where u1 = - 
and a' = 
are the velocities measured in the K and the 
- 
dt 
dt 
K frames, respectively. In the limit as c ---f 03, this formula reduces to the 
well-known Galilean result 
u1 =ti' +v. 
(10.265) 
It is clear from Equation (10.264) that even if we go to a frame moving with 
the speed of light, it is not possible to send signals faster than c. 
If the axes in K and ?? remain parallel, but the velocity 3 
of frame 1T 
in frame K is arbitrary in direction, then the parallel and the perpendicular 
components of velocity transform as 
(10.266) 
(10.267) 

202 
COORDINATES AND TENSORS 
In this notation U I I  and 31 
refer to the parallel and perpendicular components 
with respect to d and y = (1 - Y ~ / c ~ ) - ~ / ~ .  
10.10.5 
Four-Tensors in Minkowski Spacetime 
From the second postulate of relativity, the invariance of the speed of light 
means 
3 
3 
(10.268) 
This can also be written as 
7japdEadZp = gapdxadxB = 0, 
( 10.269) 
where the metric of the Minkowski spacetime is 
1
0
 0 
- 
ga(3 = gap = [ i ; 
[I i]- 
We use the notation where the Greek indices take the values 0,1,2,3 and the 
Latin indices run through 1,2,3. Note that even though the Minkowski space 
time is flat, because of the reversal of sign for the spatial components it is not 
Euclidean; thus the covariant and the contravariant indices differ in space 
time. Contravariant metric components can be obtained using (Gantmacher) 
(10.270) 
(10.271) 
as 
1
0
 0 
0 
gap= [ 
1. 
(10.272) 
Similar to the position vector in Cartesian coordinates we can define a position 
vector r in Minkowski spacetime as 
r = xa = (xo,x',x2,x3) 
(10.273) 
= (xO,T), 
where r defines the time and the position of an event. In terms of linear 
transformations [Eq. (10.250)] xa transforms as 
(10.274) 
-a x =a;xP. 

SPACETIME AND FOUR-TENSORS 
203 
For the Lorentz transformations [Eqs. (10.252-10.255) and (10.260-10.261)], 
a$ are given respectively as 
and 
a; = 
(10.275) 
. (10.276) 
For the general linear transformation [Eq. (10.250)] matrix elements a$ can 
be obtained by using 
dZa 
dxp 
a; = -. 
(10.277) 
In Minkowski spacetime the distance between two infinitesimally close points 
(events) can be written as 
ds2 = dxadxa 
= (dx')' - (d~')~ 
- ( d ~ ' ) ~  
- (dz3)' 
= gaodxadxP. 
(10.278) 
In another inertial frame this becomes 
Cts2 = g a o e d E @ .  
(10.279) 
Using Equations (10.270) and (10.274) we can write this as 
~2 = [gaoa~ag] d x ~ d z 6  . 
(10.280) 
If we restrict ourselves to transformations that preserve the length of a vector 
we obtain the relation 
[&p";'L?j] 
= gra- 
(10.281) 
This is the analog of the orthogonality relation [Eq. (10.38)) The position 
vector in Minkowski spacetime is called a four-vector, and its components 
transform as Zn = agxo, where its magnitude is a four-scalar. 

204 
COORDINATES AND TENSORS 
An arbitrary four-vector 
A =A" = (Ao, A', A2,A3), 
(10.282) 
is defined as a vector that transforms like the posit,ion vector x" as 
-a 
A =a;AP. 
(10.283) 
For two four-vectors A" and B" their scalar product is a four-scalar, which 
is defined as 
In general all tensor operations defined for the general tensors are valid in 
Minkowski spacetime with the Minkowski metric [Eq. (10.270)]. Higher-rank 
four-tensors can also be defined as 
-a1 
"2.. . 
To1 Pz . . . 
(10.285) 
10.10.6 
Four-Velocity 
Paths of observers in spacetime are called worldlines (Fig. 10.10). Because 
spacetime increments form a four-vector dx", which transforms as 
dii? = J
-
 
1 
jdxo - (9> dx'] 
1 - v2/c2 
&' = J--- 1 
[- (;) 2, dxo + dx'] 
1 - v2/c2 
(10.286) 
(10.287) 
(10.288) 
(10.289) 
ds 
we divide dx" with a scalar d r  = -, called the proper time, to obtain the 
four-velocity vector as 
C 
dx" 
d r  
U" = -. 
(10.290) 

SPACETIME AND FOUR-TENSORS 
205 
Fig. 10.10 Worldlines and four-velocity 
Similarly we can define four-acceleration as 
du" 
d r  
aa = - 
d2xa 
d.r2 ' 
- 
-- 
From the line element [Eq. (10.278)], it is seen that the proper time 
&=-= 
ds ( I - -  $&, 
C 
is the time that the clocks carried by moving observers measure. 
10.10.7 
Four-Momentum and Conservation Laws 
Using four-velocity, we can define a four-momentum as 
pa = mOua 
dx, 
d r  
= mo-, 
(10.291) 
(10.292) 
(10.293) 
(10.294) 
where ~ T Q  is the invariant rest mass of the particle. We can now express the 
energy and momentum conservation laws covariantly as the invariance of the 
magnitude of the four-momentum as 
pap, = muZLaua 
= const. 
(10.295) 

206 
COORDINATES AND TENSORS 
To evaluate the constant value of pupu we use the line element and the defi- 
nition of the proper time to find uUuu as 
ds2 = c2dt2 - ( d ~ ’ ) ~  
- (
d
~
~
)
~
 
- ( d ~ ~ ) ~ ,  (10.296) 
(10.297) 
c2 = uau,. 
Thus. 
(10.298) 
( 10.299) 
U 
2 2  
P pU = m0c . 
Writing the left-hand side of Equation (10.299) explicitly we get 
1 
(10.300) 
(10.301) 
0 
P Po + P Pl + P2P2 + P3P3 = m;c2 
(pol2 - (p1l2 - (p212 - (p3))” = mgc2. 
Spatial components of the four-momentum are 
dxi 
p z  = mo-, 
dT 
i = 1,2,3 
(10.302) 
(10.303) 
U 1  
= 
Using this in Equation (10.301) we obtain 
(1 - u2/c2) 
or 
(1 - 
?l2lc2 
U”C2) 1 l? 
i 
po=moc 1+ 
In order to interpret po, we take its classical limit as 
(10.304) 
( 10.305) 
(10.306) 
( 10.307) 
(10.308) 

SPACETIME AND FOUR-TENSORS 
207 
The second term inside the square brackets is the classical expression for 
the kinetic energy of a particle; however, the first term is new to Newton's 
mechanics. It indicates that free particles, even when they are at rest, have 
energy due to their rest mass. This is the Einstein's famous formula 
E = W C ,  
2 
(10.309) 
which indicates that mass and energy could be converted into each other. We 
can now interpret the time component of the four-momentum as E/c, where 
E is the total energy of the particle; thus the components of p" become 
E
.
 
p" = (1, 
mothZ). 
(10.310) 
We now write the conservation of four-momentum equation as 
E2 
m;u2 
2 2  
=mot. 
p"p, = - 
- - 
c2 
(I - $) 
Defining 
(10.31 1) 
(10.312) 
and calling 
p i =mu', 
(10.313) 
we obtain a relation between the energy and the momentum of a relativistic 
particle as 
E2 = m8c4 +p2c2. 
(10.314) 
10.10.8 
Another important consequence of the special theory of relativity is Equation 
(10.312), that is, 
Mass of a Moving Particle 
(10.315) 
This is the mass of a particle moving with velocity w. It says that as the speed 
of a particle increases its mass (inertia) also increases, thus making it harder 
to accelerate. As the speed of a particle approaches the speed of light, its 
inertia approaches infinity, thus making it impossible to accelerate beyond c. 

208 
COORDINATES AND TENSORS 
10.10.9 
Wave Four-Vector 
The phase of a wave 
4 = wt - kixi, 
(10.316) 
where we sum over z, is an invariant. This is so because it is merely a number 
equal to the number of wave crests getting past a given point; thus we can 
write 
This immediately suggests a wave four-vector as 
k" = (k0, ki) 
(10.318) 
w 2T 
c' x 
= ( -  
+> 
(10.319) 
where Ai is the wavelength along xi. Because k" is a four-vector, it transforms 
as 
--++ 
(10.320) 
(10.321) 
-0 k =y(kO- p .  k )  
- 
kll = Y(kll - PkO>. 
We have written y = l/d- 
and 3 
= $/c 
For light waves 
(10.322) 
thus we obtain the familiar equations for the Doppler shift: 
= y ~ ( i  - pcose) 
(10.323) 
tang = sinB/y(cosB - p), 
(10.324) 
+
=
+
 
where 8 and 3 are the angles of 
k and k with respect to b, 
respectively. 
Note that because of the presence of y there is Doppler shift even when B = 
~ / 2 ,  
that is, when light is emitted perpendicular to the direction of motion. 
10.10.10 
Derivative Operators in Spacetime 
Let us now consider the derivative operator 
(10.325) 
frame. In terms of another inertial frame K it will be 
d 
m' 
- 
calculated in the 
given as 
(10.326) 

SPACETIME AND FOUR-TENSORS 
209 
a 
thus - 
transforms like a covariant four-vector. In general we write the 
four-gradient operator as 
f3XB. 
a 
a"=-- 8%" - (&> 
-") 
or 
8" = (&,d). 
(10.327) 
(10.328) 
Four-divergence of a four-vector is a four-scalar: 
The wave (d'Alembert) operator in space time is written as 
(10.330) 
10.10.11 
Analogous to the orthogonal coordinates, any four-vector in Minkowski space 
time can be written in terms of basis vectors as 
Relative Orientation of Axes in K and K Frames 
A = (Ao,A1,A2,A3) 
(10.331) 
(10.332) 
In terms of another Minkowski frame, the same four-vector can be written as 
(10.333) 
A = B , A  , 
where & are the new basis vectors of the frame ??, which is moving with 
respect to K with velocity w along the common direction of the xl- 
and 
??-axes. 
Both g, 
and Ga are unit basis vectors along their axes in their 
respective frames. Because A represents some physical property in Minkowski 
spacetime, Equations (10.332) and ( 10.333) are just different representations 
of A; hence we can write 
A 
= e,AQ. 
- --a 
A -"' 
(10.334) 
h 
e,A* =&A 
. 
Using the transformation property of four-vectors we write 
(10.335) 
-a' 
A = a;'AP, 
thus Equation (10.334) becomes 
(10.336) 
A e, A" = sat a;' AO. 

210 
COORDINATES AND TENSORS 
Fig. 10.11 Orientation of the 
axis with respect to the K frame 
We rearrange this as 
A%, = AB (&a$). 
(10.337) 
Since a and p are dummy indices, we can replace p with a to write 
A%, = A" (&a:') 
, 
(10.338) 
which gives us the transformation law of the basis vectors as 
( 10.339) 
e, = e,raz . 
Note that thisjs not a component transformation. It gives i3, as a linear 
A
h
'
 
combination of Gar. Using 
we obtain 
(10.340) 
(10.341) 
(10.342) 

0 
X \ 
I I I I 
I 
SPACETIME AND FOUR-TENSORS 
211 
xo 
Fig. 10.12 Orientation of the K axis with respect to the 5? frame 
and its inverse as 
(10.343) 
(10.344) 
The second set gives the orientation of the R axis in terms of the K axis. 
Since ,L? < 1, relative orientation of the 
axis with respect to the K axis can 
be shown as in Figure 10.11. 
Similarly, using the first set, we can obtain the relative orientation of the 
K axis with respect to the IT axis as shown in Figure 10.12. 
10.10.12 
Before the spacetime formulation of special relativity, it was known that 
Maxwell's equations are covariant (form-invariant) under Lorentz transfor- 
mations. However, their covariance can be most conveniently expressed in 
terms of four-tensors. 
First let us start with the conservation of charge, which can be expressed 
Maxwell's Equations in Minkowski Spacetime 
as 
(10.345) 

212 
COORDINATES AND TENSORS 
where p is the charge density and f is the current density in space. Defining 
a four-current density J" as 
J" = ( P C ,  3, 
(10.346) 
we can write Equation (10.345) in covariant form as 
8, J" = 0, 
(10.347) 
where 8, stands for covariant derivative [Eq. (10.327)]. Maxwell's field equa- 
tions, which are given as 
3.3 
= 471-p 
( 10.348) 
(10.349) 
3 . 3 = 0  
(10.350) 
= 0, 
1 8 3  
VXZ+-- 
c a t  
(10.351) 
determine the electric and magnetic fields for a given charge, and current 
distribution. We now introduce the field-strength tensor FaB as 
(10.352) 
0 
-El 
-E2 
-E3 
El 
0 
-B3 
B2 
Ez 
B3 
0 
-Bl 
I 
E3 
-B2 
B1 
0 
Fa@ = 
where the covariant components of the field-strength tensor are given as 
Fag = ga7gs@FY6 = 
(10.353) 
Using Fa@, the first two Maxwell's equations can be expressed in covariant 
form as 
(10.354) 
4?r 
8, Fa@ = - 
JB. 
C 
For the remaining iwo Maxwell's equations we introduce the dual field- 
strength tensor FOB, which is related to the field strength tensor FaP 
through 
(10.355) 

SPACETIME AND FOUR-TENSORS 
213 
where 
for even permutations 
for odd permutations 
@Y6 
= [ ;] { when any of the two indices are equal . 
(10.356) 
Now the remaining two Maxwell's equations can be written as 
a p f l  = 0. 
(10.357) 
The motion of charged particles in an electromagnetic field is determined by 
the Lorentz force equation: 
(10.358) 
where 
is the spatial momentum and T is the velocity of the charged 
particle. We can write this in covariant form by introducing four-momentum 
(10.359) 
(10.360) 
where mo is the rest mass, urn is the four-velocity, and po = E/c. Using the 
derivative in terms of invariant proper time we can write Equation (10.358) 
as 
(10.361) 
10.10.13 
Transformation of Electromagnetic Fields 
Because Fa@ is a second-rank four-tensor, it transforms as 
(10.363) 
Given the values of Fys in an inertial frame K, we can find it in another 
inertial frame 17 as 
(10.364) 
--a@ 
a B y6 
F 
= aya6F . 
If IT corresponds to an inertial frame moving with respect to I( with velocity 
21 along the common Z1- and 21-axes, the new components of 3 and B are 
--+ 
(10.365) 
(10.366) 
(10.367) 

214 
COORDINATES AND TENSORS 
and 
( 10.368) 
(10.369) 
(10.370) 
If 
given as 
is moving with respect to K with 3 
the transformation equations are 
(10.371) 
(10.372) 
+ 
where y = I/( 1 - P2)'I2 and 
obtained by interchanging 
with -d. 
= 3,'~. 
Inverse transformations are easily 
10.10.14 
Maxwell's Equations in Terms of Potentials 
The Electric and magnetic fields can also be expressed in terms of the poten- 
tials -A' and 4 as 
In the Lorentz gauge 
2 and 4 satisfy 
and 
(10.373) 
(10.374) 
(10.375) 
(10.376) 
(10.377) 
respectively. Defining a four-potential as 
A" = (4, a, 
(10.378) 
we can write Equations (10.376) and (10.377) in covariant form as 
(10.379) 

SPACETIME AND FOUR-TENSORS 
215 
where the d'Alembert operator 0 
is defined as 0 - 
a2 
- v2. 
Now the 
d ( ~ 0 ) ~  
covariant form of the Lorentz gauge [Eq. (10.375)] becomes 
aaAa = 0. 
(10.380) 
Field-strength tensor in terms of the four-potential can be written as 
= a"A@ - @Aa. 
(10.381) 
10.10.15 
The concept of relativity was not new to Newton. In fact, it was known that 
the dynamical equation of Newton: 
Covariance of Newton's Dynamical Theory 
d T  
- 
= 3, 
dt 
(10.382) 
is covariant for all uniformly moving (inertial) observers. However, the iner- 
tial observers in Newton's theory are related to each other by the Galilean 
transformation 
- t = t  
z1 = [x' -?It] 
-2 - 2 
x - x  
-3 - 3 
x - x .  
(10.383) 
(10.384) 
(10.385) 
(10.386) 
Note that the Lorentz transformation actually reduces to the Galilean trans- 
formation in the limit c +. 03, or 'u << c. Before the special theory of rela- 
tivity it was already known that Maxwell's equations are covariant not under 
Galilean but under Lorentz transformation. Considering the success of New- 
ton's theory this was a conundrum, which took Einstein's genius to solve by 
saying that Lorentz transformation is the correct transformation between in- 
ertial observers and that all laws of nature should be covariant with respect 
to it. In this regard we also need to write Newton's dynamical equation as a 
four-tensor equation in spacetime. 
Using the definition of four-momentum 
pa = m& 
= (E/c, p2) 
(10.387) 
and differentiating it with respect to invariant proper time, we can write the 
Newton's dynamical equation in covariant form as 
(10.388) 

216 
COORDINATES AND TENSORS 
where Fa is now the four-force. Note that the conservation of energy and m e  
mentum is now expressed covariantly as the conservation of four-momentum, 
that is, 
Problems 
10.1 For rotations about the z-axis the transformation matrix is given as 
1 
[
o
 
0
1
 
C O S ~  sin0 0 
R,(0) = 
-sin@ cos@ 0 
. 
Show that for two successive rotations by the amounts 81 and 82 about the 
XI- and x2-axes, respectively, 
R, 
(@I + 62) = R,, (&)R, (01) 
is true. 
10.2 
10.3 
delta, prove the following identities in tensor notation: 
Show that the rotation matrix R,(@) is a second-rank tensor. 
Using the properties of the permutation symbol and the Kronecker 
i) 
ii) 
[ Z X  [ S x b ] ] + [ 7 3 ' x  [ r l x 7 f ] ] + [ c x  [Z.3]]=0, 
iii) 
Z x  [3xd]=S(7f.d)-d(;i'.B*). 
10.4 The trace of a second-rank tensor is defined as 
tr(A) = A:. 
Show that trace is invariant under general coordinate transformations. 
10.5 
ment 
Under general coordinate transformations show that the volume ele- 
dnx = dx'dx '... dx" 

PROBLEMS 
217 
transforms as 
where - is the Jacobian of the transformation, which is defined as 
IEI 
10.6 
Kronecker delta: 
Show the following relations between the permutation symbol and the 
and 
3
3
 
10.7 Evaluate 
i j k  lmn 
where T is an arbitrary matrix. 
10.8 
a vector 3 
can be written as 
Using the symmetry of the Christoffel symbols show that the curl of 
10.9 
is, 
Prove that the covariant derivative of the metric tensor is zero, that 
gij;j = 0. 
10.10 
Verify that 
transforms like a second-rank tensor. 

218 
COORDINATES AND TENSORS 
show that the elasticity tensor &jkl has 21 independent components. 
10.12 
second kind: 
Prove the following useful relation of the Christoffel symbol of the 
10.13 
gij = 0 unless i = j :  
Show the following Christoffel symbols for a diagonal metric, where 
a 
{ ;z} 
= -
$
-
-
$
n
 
&I. 
In these equations summation convention is not used and different letters 
imply different indices. 
10.14 Show that the tensor equation 
transforms as 
10.15 
lowing metrics: 
Find the expressions for the div and the grad operators for the fol- 
i) 
ds2 = dr2 + p2dB2 + dz2 
ii) 
ds2 = [ 
] dr2 + r 2 a 2  + r2 sin2 Odd2, 
1 - kr2/R2 
where k takes the values k = 0,1, -1. 

PROBLEMS 
219 
10.16 Write the Laplacian operator for the following metrics: 
i) 
ds2 = R2(dX2 + sin2 xd6' + sin2 xsin2 SdQ,'), 
where x E [0, T I ,  6 E [O,T], Q, E [0, 27r]. 
ii) 
ds2 = R2(dx2 + sinh2 xd02 + sinh2Xsin2 6d42), 
where x E [0, co], 
6 E [0, T I ,  Q, E [0,27r]. 
10.17 
What geometries do these metrics represent? 
Write the line element for the elliptic cylindrical coordinates (u, v, z) : 
x = acoshucosv 
y = asinhusinv 
z = z. 
10.18 
tensor for the parabolic cylindrical coordinates (u, v, z )  : 
Write the covariant and the contravariant components of the metric 
x = (1/2)(u2 - u2) 
y = uv 
z = 2. 
10.19 Write the Laplacian in the parabolic coordinates (u,v, Q,) 
x = uv cos Q, 
y = uvsinQ, 
z = (1/2)(u2 - v2). 
10.20 
the metric in the line element 
Calculate all the nonzero components of the Christoffel symbols for 
ds2 = dr2 + r 2 d 2  + r2 sin2 BdQ,', 
where T E [O,co], 
6 E [O,n-], Q, E [ O , ~ T ] ,  
10.21 
coordinates . 
10.22 
10.23 
10.24 
as 
Write the contravariant gradient of a scalar function in spherical polar 
Write the divergence operator in spherical polar coordinates. 
Write the Laplace operator in cylindrical coordinates. 
In four dimensions spherical polar coordinates (r, x, 
6,Q,) are defined 
x = rsinxsinBcosQ, 
y 
= rsinXsinBsinq5 
z 
= rsinxcos6 
w
=
 r cos x. 

220 
COORDINATES AND TENSORS 
i) Write the line element 
ds2 = dx2 + dy2 + dz2 + dw2 
in (T, x, 6,'). 
ii) What are the ranges of (T, x, 6, ')? 
iii) Write the metric for the three dimensional surface (S-3) of a hyper- 
sphere. 
10.25 Which one of the following matrices are Cartesian tensors: 
i) 
[ -xy 
y2 
-xy 
2 2  I ' 
10.26 In cosmology the line element for a closed universe is given as 
ds2 = c2dt2 - R~(t)~[dx' 
+sin2 xdB2 + sin2 Xsin2 f?d+'], 
where t is the universal time and x, 6, and (p are the angular coordinates with 
the ranges 
x E [0,4 , 6 E [0,4 
i ' 
E [0,24. 
For a static universe with constant radius &, the wave equation for the 
massless conformal scalar field is given as 
1 
o w ,  x, 6, (6) + - y W i  X,Bi '> 
= 0. 
R, 
0 = g,,apa,, 
is the d'Alembert (wave) operator: 
where 3, stands for the covanant derivative. 
Using a separable solution of the form 
w, x, 
8,') 
= T(t)X(X)Y@, '), 
show that the wave equation for the massless conformal scalar field can be 
written as 
1 

PROBLEMS 
221 
10.27 
Using the four-current 
+ 
J" = (pc, J )  
and the field-strength tensor 
r o 
- E ~  - E ~  -E3 1 
show that Maxwell's field equations: 
1 a" 
Ttx x+-- 
= 0 
c a t  
can be written in covariant form as 
and 
h 
aQFQP = 0. 
The dual field-strength tensor @"o is defined as 
where ta@y6 is the permutation symbol. 
10.28 If 
corresponds to an inertial frame moving with respect to K w i s  
velocity v along the 21-axis, show that the new components of 3 
and B 
become 

222 
COORDINATES AND TENSORS 
and 
10.29 
Show that the field-strength tensor can also be written as 
Fa@ = d"AP - 
, 
where the four-potential is defined as 
A" = (4,T) 
and 

CONTINUOUS 
GROUPS and 
REPRESENTATIONS 
In everyday language the word “symmetry” is usually associated with “beau- 
tiful”. It is for this reason that it has been used extensively in architecture 
and art. Symmetry also allows us to build complex structures or patterns by 
distributing relatively simple building blocks according to a rule. Most of the 
symmetries around us are with respect to rotations and reflections. Symmetry 
in science usually means invariance of a given system under some operation. 
As in crystals and molecules, symmetries can be discrete, where applications 
of certain amounts of rotation, translation, or reflections produce the same 
structure. After the discovery of the Lagrangian formulation of mechanics it 
became clear that the conservation laws are also due to symmetries in nature. 
For example, conservation of angular momentum follows from the symmetry 
of a given system with respect to rotations, whereas the conservation of lin- 
ear momentum follows from symmetry with respect to translations. In these 
symmetries a system is carried from one identical state to another continu- 
ously; hence they are called continuous (Lie) symmetries. With the discovery 
of quantum mechanics the relation between conservation laws and symnie- 
tries has even become more important. Conservation of isospin and flavor in 
nuclear and particle physics are important tools in building theories. Gauge 
symmetry has become an important guide in constructing new models. 
Group theory allows us to study symmetries in a systematic way. In this 
chapter we discuss continuous groups and Lie algebras, which allow us to 
study symmetries of physical systems and their relation to coordinate trans- 
formations. We also discuss representation theory and its applications. In 
particular, we concentrate on the representations of the rotation group R(3) 
and the special unitary group SU(2) and their relation. We also discuss the 
223 

224 
CONTINUOUS GROUPS AND REPRESENTATIONS 
inhomogeneous Lorentz group and introduce its Lie algebra. An advanced 
treatment of spherical harmonics is given in terms of the rotation group and 
its representations. We also discuss symmetry of differential equations and 
the extension (prolongation) of generators. 
Even though this chapter could be read independently, occasionally we 
refer to results from Chapter 10. In particular, we recommend reading the 
sections on orthogonal transformations and Lorentz transformations before 
reading this chapter. 
11.1 DEFINITION OF A GROUP 
The basic properties of rotations in three dimensions are just the properties 
that make a group. A group is an ensemble of elements 
G E {90,91, 9 2 ,  ..-I 
> 
(11.1) 
with the following properties: 
that 
i) For any two elements, ga, 96 E G, a rule of composition is defined such 
gag6 E G. 
(1 1.2) 
ii) With the composition rule defined above, for any three elements, ga, gb, gc E 
G, the associative rule 
(ga9b)gc = ga (gbgc) 
(1 1.3) 
is obeyed. 
iii) G contains the unit element 90 such that for any g E G, 
990 = 909 = 9. 
iv) For every g E G, there exists an inverse element, 9-l E G, such that 
99-1 = 9-19 = go. 
(1 1.4) 
(11.5) 
11.1.1 
Terminology 
In n dimensions the set {A} of all linear transformations with det A #O forms 
a group called the general linear group in n dimensions: 
GL(n). 
We use the letter A for the transformation and its operator or matrix rep 
resentation. Matrix elements of A could be real or complex; thus we also 
write 
GL(n, R) or GL(n, C )  

DEFINITION OF A GROUP 
225 
The rotation group in two dimensions is shown as 
Elements of R(2) are characterized by a single continuous parameter 8, which 
is the angle of rotation. A group whose elements are characterized by a 
number of continuous parameters is called a continuous or Lie Group. In 
a continuous group the group elements can be generated continuously from 
the identity element. The rotation group in three dimensions is shown as 
R(3)- 
Elements of R(3) are characterized in terms of three independent parameters, 
which are usually taken as the three Euler angles. R(n) is a subgroup of 
GL(n). R(n) is also a subgroup of the group of n-dimensional orthogonal 
transformations, which is shown as 
Elements of O(n) satisfy ldet AI2 = 1. The set of all linear transformations 
with det A = 1 forms a group called the special linear group: 
SL(n, R) or SL(n, C). 
Elements of O(n) satisfying det A = 1 form the special orthogonal group 
shown as 
which is also a subgroup of SL(n,R). The group of linear transformations 
acting on vectors in n-dimensional complex space and satisfying ldet A[ = 1 
is called the unitary group: 
2 
If the elements of the unitary group also satisfy det A = 1 we have the special 
unitary group: 
SU(n). 
SU(n) is a subgroup of U(n). Groups with infinite number of elements like 
R(n) are called infinite groups. A group with finite number of elements is 
called a finite group, where the number of elements in a finite group is called 
the order of the group. Elements of a group in general do not commute, 
that is, gagb for any two elements need not be equal to g&. 
If in a group for 
every pair gagb = gbga holds, then the group is said to be commutative or 
Abelian. 

226 
CONTINUOUS GROUPS AND REPRESENTATIONS 
11.2 INFINITESIMAL RING OR LIE ALGEBRA 
For a continuous (Lie) group G if A(t) E G, we have seen that its generator 
[Eq. (10.76)] is given as X = A’(0). The ensemble (A’(0)) of transformations is 
called the infinitesimal ring or Lie algebra of G, and it is denoted by ‘G. 
Differentiating A(at) E G we get A’(&) = aA’(at), where a is a constant. 
Substituting t = 0 we see that 
aA’(0) = aX E‘ G. 
(11.6) 
Also, if A(t) and B(t) are any two elements of G, then 
C(t) = A(t)B(t) E G. 
(11.7) 
Differentiating this and substituting t = 0 and using the fact that A(0) = 
B(0) = I, we obtain 
C’(0) = A’(0) + B’(O), 
=X+Y. 
(11.8) 
Hence, X + Y E ‘G if X,Y E ‘G. Lie has proven some very interesting 
theorems about the relations between continuous groups and their generators. 
One of these is the relation 
[Xi, 
Xj] = xixj - xjxi 
(1 1.9) 
n 
= c 
CFjXk, 
k= 1 
which says that the commutator of two generators is always a linear combi- 
nation of generators. The constants c$ are called the structure constants 
of the group G, and n is the dimension of G. 
We have so far shown the following properties of ‘G : 
If X,Y 
E ‘G, then 
i> 
aX E ‘G, 
where a is a real number 
ii) 
X + Y = Y + X E  ‘G 
iii) 
[Xi, 
Xj] = xixj - xjxi 
n 
= x c $ &  
E ’G 
k=l 
(I 1.10) 
(11.11) 
(1 1.12) 

LIE ALGEBRA OF THE ROTATION GROUP R(3) 
227 
Thus, ‘G is a vector space with the multiplication defined in (iii). The di- 
mension of this vector space is equal to the number n of the parameters of 
the group G; thus it has a basis: XI, X2, ..., X, and every element X of ‘G 
can be expressed as a linear combination as 
x = ZlXl + z2x2 + . . . + z,x,. 
( 1 1.13) 
From these it is clear that a continuous group completely determines the 
structure of its Lie algebra. Lie has also proved the converse, that is, the 
local structure in some neighborhood of the identity of a continuous group is 
completely determined by the structure constants cfj. 
11.3 LIE ALGEBRA OF THE ROTATION GROUP R(3) 
We have seen that the generators of the rotation group are given as [Eq. 
(10.84)] 
0
0
0
 
0 0 -1 
0 
1
0
 
x1= 0 
0 
1 
x2= 0 0 
0 
x3= -1 
0 0 . 
[ o - l o ] ,  
[ l o  0 1 .  
[ o  0 0 1  
(11.14) 
These generators satisfy the commutation relation 
[xi, 
x j ]  = -CijkXk, 
(11.15) 
where 6ijk is the permutation (Levi-Civita) symbol. Using these generators 
we can write an arbitrary infinitesimal rotation as 
r = (I + XIEI + X 2 ~ 2  + X3~3)r(O), 
(11.16) 
Defining two vectors, that is, 0 with the components 
o= ““1 
E3 
and 
x = X& + x2-22 + x3-23, 
(1 1.18) 
(11.19) 
(11.20) 
we can write 
r =(I + X . e). 

228 
CONTINUOUS GROUPS AND REPRESENTATIONS 
The operator for finite rotations, where 0 has now the components ((?I,&, 83), 
can be constructed by successive infinitesimal rotations as 
1 
1 
1 
r = lim (I+-X . @)(I + -X .Q). . . (I+zX. O)r(O) 
N + w  
N 
N 
= e x.er(0). 
(11.21) 
Euler's theorem (Goldstein et al.) allows us to look at Equation (11.16) as an 
infinitesimal rotation about a single axis along the unit normal 
by the amount 
46) = (I + X.^ndB)r(O). 
For finite rotations (Fig. 11.1) we write 
4 6 )  = ex."r(0). 
(11.22) 
(1 I .23) 
(11.24) 
11.3.1 Another Approach to 'R(3) 
Let us approach 'R(3) from the operator (active) point of view. We now look 
for an operator 0, which acts on a function f(r) and rotates it clockwise, while 
keeping the coordinate axis fixed (Fig. 11.2). f(r) could be representing a 
physical system or a physical property. Instead of the Euler angles we use 
81,82,83, which represent rotations about the XI- ,x2- , z3-axes, respectively. 
For a counterclockwise rotation of the coordinate system about the xs-axis 
we write 
(11.25) 
- 
r = R3r. 
This induces the following change in f(r) : 
If O3 is an operator acting on f(r), and since both views should agree, we 
write 
(11.27) 

LIE ALGEBRA OF THE ROTATION GROUP R(3) 
229 
- 
x1 
Fig. 11.1 Rotation by 6 about an axis along ii 
Fig. 11.2 Effect of 0 3  on f(r) 

230 
CONTINUOUS GROUPS AND REPRESENTATIONS 
We now look for the generator of infinitesimal rotations of T(r) about the 
z~-axis, which we show by ?T3. Using Equation (10.42) we write the rotation 
matrix RY1 as 
RS’(0) = R3(-0). 
(1 1.28) 
For infinitesimal rotations we write 03 = 63 and 
0 3  = (I-XSE~). 
(11.29) 
The minus sign in O3 indicates that the physical system is rotated clockwise 
(Fig. 11.2), thus 
(I-?&y)f(r) 
= ~ ( z ~ c O S E ~  
-x2sin~g, 1c1 s i n ~ 3  
f Z 2 C O S E 3 ,  23), 
(11.30) 
Using Taylor series expansion about the point (x1,22, z3) and taking the limit 
as €3 -+ 0 we obtain 
Thus 
(1 1.33) 
(1 1.34) 
Similarly, or by cyclic permutations of 2 1 ,  2 2 ,  and z3 we obtain the other 
operators as 
and 
(1 1.35) 
(11.36) 
Note that aside from a minus sign, ?zi satisfy the same commutation relations 
as Xi, that is, 
[?zi,Xj] = E i j k X k .  
(11.37) 

GROUP INVARIANTS 
231 
An arbitrary infinitesimal rotation of f (r)can now be written as 
- 
f(r) = (I-XISB~ - X2682 - X&h)f(r) 
(1 1.38) 
= (1-X. ;is@) f(r), 
(11.39) 
where fi and SB are defined as in Equation (11.23). Now the finite rotation 
operator becomes 
- 
oj(r) = e-x "'f(r). 
( 1 1.40) 
For applications in quantum mechanics it is advantageous to adopt the view 
that the operator 0 still rotates the state function f(r) counterclockwise, so 
that the direction of fi is positive when 8 is measured with respect to the 
right-hand rule (Merzbacher, p. 174). In this regard we write 
- 
of(r) = ex " f(4 
(11.41) 
for the operator that rotates the physical system counterclockwise. We will 
come back to this point later when we discuss angular momentum and quan- 
tum mechanics. 
11.4 GROUP INVARIANTS 
It is obvious that for R(3) the magnitude of a vector 
(1 1.42) 
=x:+x;+x;, 
is not changed through a rotation. A vector function F(r) that remains un- 
changed by all g E G, that is, 
F(r) =F(I), 
(11.43) 
is called a group invariant. We now determine a group whose invariant is 
x ; + x ; .  
( 1 1.44) 
This group will naturally be a subgroup of GL(2, R). An element of this group 
can be represented by the transformation 
(1 1.45) 

232 
CONTINUOUS GROUPS AND REPRESENTATIONS 
From the group invariant 
it follows that the transformation matrix elements must satisfy the relations 
2
2
 
a + c  = 1 ,  
b 2 + d 2 =  1 ,  
ab + cd = 0 . 
(11.47) 
(I 1.48) 
( 1 1.49) 
This means that only one of (a, b, c, d )  could be independent. Choosing a new 
parameter as 
a = case, 
( 1 1.50) 
we see that the transformation matrix has the following possible two forms: 
(1 1.51) 
cos8 
sin6 ] and [ cos8 
-sin8 
-sin8 
cos8 
The first matrix is familiar; it corresponds to rotations, that is, R(2). However 
the second matrix has 
j = - 1  
-sin8 
-cos8 
(I 1.52) 
and can be written as 
[ case 
-sin81 = [ -sin8 
cOse 
cos6 
sine ] [ A :l 
1. 
-sin8 
-cos8 
(11.53) 
This is reflection, that is, 
(1 1.54) 
followed by a rotation. The group which leaves z: + 
invariant is called 
the orthogonal group 0 ( 2 ) ,  where R(2) is its subgroup with the determinant 
of all of its elements equal to one. R(2) is also a subgroup of S0(2), that 
includes rotations and translations. 
11.4.1 
Lorentz Transformation 
As another example for a group invariant let us take 
2
2
 
2 - - y .  

GROUP INVARIANTS 
233 
We can write this as 
For a linear transformation between (Z, g) and (z, y) we write 
[;I=[: 
:][;I- 
Invariance of (x2 - y2> can now be expressed as 
(11.55) 
(11.56) 
(11.57) 
a2-c2 
ab-cd 
=Iz 
' ] [ a b - c d  
b z - d 2 ] [ ; ]  
2 
= x  -y? 
From above we see that for (z2 - y') to remain invariant under the transfor- 
mation [Eq. (1 1.56)], components of the transformation matrix must satisfy 
(11.58) 
This means that only one of (a, b, c, d )  can be independent. Defining a new 
parameter x as 
a = coshx, 
( 1 1.59) 
we see that the transformation matrix in Equation (11.56) can be written as 
sinhx coshx I ' 
coshx sinhx 
Introducing 
cosh x = y 
sinhx = -70 
tanh x = -0, 
(11.60) 
(11.61) 
(1 1.62) 
(1 1.63) 

234 
CONTINUOUS GROUPS AND REPRESENTATIONS 
where 
along with the identification 
x=ct 
Y = X? 
we obtain 
[;I=[ 
-Pr 
7 -"][:I 
r 
(1 1.64) 
This is nothing but the Lorentz transformation [Eqs. (10.252-10.255): 
(11.65) 
- 
1 
(ct - wx/c) 
c t =  d
w
 
which leaves distances in spacetime, that is, 
( C V  - XZ) , 
(11.66) 
(11.67) 
(11.68) 
invariant. 
11.5 
UNITARY GROUP IN TWO DIMENSIONS: u(2) 
Quantum mechanics is formulated in complex space. Hence the components 
of the transformation matrix are in general complex numbers. The scalar or 
inner product of two vectors in mdimensional complex space is defined as 
( 1 1.69) 
(x, 
Y> = x;y1 + x;?& + . . . + x*y 
n n
7
 
where x* means the complex conjugate of x. Unitary transformations are 
linear transformations, which leaves 
(1 1.70) 
invariant. All such transformations form the unitary group U(n). An element 
of U(2) can be written as 
2 
(x, 
x) = 1x1 = .;XI + 4.2 
+ . . . + x;zn 
A
B
 
u=[. 
D ] ,  
(11.71) 

UNITARY GROUPIN TWO DIMENSIONS: u(2) 
235 
where A, B ,  C, and D are in general complex numbers. Invariance of (x, 
x) 
gives the unitarity condition as 
utu = uut = I , 
(11.72) 
where 
ut = :* 
(1 1.73) 
is called the Hermitian conjugate of u. Using the unitarity condition we can 
write 
which gives 
A* C" 
A
B
 
u t u = [  B* .*I.[ 
C D ]  
IAI2 + ICI2 A'B + C*D ] 
= [ AB* + D'C 
[BI2+ IDI2 
[AI2 + ICI2 = 1 
[BI2 + 1Ol2 = 1 
A"B + C * D  = 0 
(1 1.74) 
(1 1.75) 
(1 1.76) 
(11.77) 
From elementary matrix theory (Boas), the inverse of u can be found as 
(11.78) 
Because for SU(2) the inverse of u is also equal to ut, we write 
u-1= ,t 
(1 1.79) 
[ -; 
-f ] = [ ,": ;: ] 
This gives D = A* and C = -B*; thus u becomes 
( 1 1.80) 
(1 1.81) 
Taking the determinant of the unitarity condition [Eq. (11.71)] and using the 
fact that det ut = det u, we obtain 
(1 1.82) 
ldetul 2 = 1 . 

236 
CONTINUOUS GROUPS AND REPRESENTATIONS 
11.6 SPECIAL UNITARY GROUP su(2) 
In quantum mechanics we are particularly interested in SU(2), a subgroup of 
U(2), where the group elements satisfy the condition 
det u = 1. 
For SU(2), A and B in the transformation matrix 
(11.83) 
(1 1.84) 
satisfy 
(11.85) 
detu=(A( 
2 +IBI2= 1. 
Expressing A and l3 as 
A = a + i d  
B = c + i b ,  
we see that the unitary matrix has the form 
1 
u = [  a+zd 
c+ib 
-c+ib 
a-id 
(11.86) 
( 1 1.87) 
(I 1.88) 
This can be written as 
where o, are the Pauli spin matrices: 
which satisfy 
(1 1.91) 
(1 1.92) 
where (i, j ,  k )  are cyclic permutations of (1,2,3). Condition (11.83) on the 
determinant u gives 
+ b2 + c2 + d2 = 1. 
This allows us to choose (a, 6, c, d) as 
(11.93) 
u = cos w, b2 + c2 + d2 = sin2 w, 
(1 1.94) 

LIE ALGEBRA OF su(2) 
237 
thus Equation (11.89) becomes 
u(w) = Icosw+iSsinw, 
where we have defined 
s =a01 + pa2 + yo3 
and 
Note that u in 
(1 1.95) 
(1 1.96) 
(1 1.97) 
;quation (11.71) has in general eight parameters. 
Iowever, 
among these eight parameters we have five relations, four of which come from 
the unitarity condition (11.72). We also have the condition fixing the value 
of the determinant (11.83) for SU(2); thus SU(2) can only have three in- 
dependent parameters. These parameters can be represented by a point on 
the three-dimensional surface (S-3) of a unit hypersphere defined by Equation 
(11.93). In Equation (11.95) we represent the elements of SU(2) in terms of 
w7 and (a, P, 7) 
7 
(1 1.98) 
where (a, P, y) satisfies 
a 2 + p + y 2 =  1 .  
(1 1.99) 
(1 1. loo) 
By changing (a, p, y) on S-3 we can vary w in 
- 
u(w) = I cos w+X sin w, 
where we have defined 
- 
x = is, 
hence 
- 
x2 = 4 3 2 .  
(1 1.101) 
(1 1.102) 
11.7 
LIE ALGEBRA OF su(2) 
In the previous section we have seen that the elements of the SU(2) group 
are given as 
- 
u(w) = I cos w+X sin w. 
(11.103) 

238 
CONTINUOUS GROUPS AND REPRESENTATIONS 
The 2 x 2 transformation matrix, u(w), transforms complex vectors 
v = [  Ir:] 
( 1 1.104) 
as 
(1 1.105) 
Infinitesimal transformations of SU(2), analogous to R(3), can be written as 
- 
v = u(w)v. 
v(w) = (I+XGw)v(O) 
sv = Xv(0)sw 
v’(w) = %v(O), 
(11.106) 
(11.107) 
(1 1.108) 
where the generator X is obtained in terms of the generators XI, 
%2, %3 as 
I 
x = u’(0) = is 
(1 1.109) 
(1 1.1 lo) 
x , =  
- 
[; g ] ,  xa= 
- 
0
1
 
o ] ,  
x 3 =  [; 3 (11.111) 
- 
X ,  satisfy the following commutation relation: 
- 
x,,xj = - 2 E y k X k .  
( 1 1.1 12) 
[- - 1  
For R(3) we have seen that the generators satisfy Ekluation (11.15) 
[x,,xj] 
= - C t j k X k ,  
(11.113) 
and the exponential form of the transformation matrix for finite rotations was 
[Eq. (11.24)] 
r(t) = ex ”r(0). 
(11.114) 
If we make the correspondence 
- 
2x2 c-$ xi, 
( 1 1.1 15) 

11E ALGEBRA OF s u ( 2 )  
239 
the two algebras are identical and the groups SU(2) and R(3) are called 
isomorphic. Defining a unit normal vector 
i3 = (a,P,y), 
( 1 1.1 16) 
we can now use Equation (11.114) to write the exponential form of the trans- 
formation matrix for finite rotations in SU(2) as 
- 
v(t) = e+X.'ev(0). 
(1 1.117) 
Since 
- 
x=is, 
(1 1.118) 
This gives us the exponential form of the transformation matrix for SU(2) as 
v(t) = 
'Qv(~). 
(11.119) 
In quantum mechanics the active view, where the vector is rotated coun- 
terclockwise, is preferred; thus the operator is taken as 
1 
( 1 1.120) 
,-+is ;ie 
where S corresponds to the spin angular momentum operator. 
s =a01 + 002 + 703. 
(11.121) 
In Section 11.13 we will see that the presence of the factor 1/2 in operator 
(10.120) is very important and it actually indicates that the correspondence 
between SU(2) and R(3) is two-to-one. 
11.7.1 Another Approach to .Su(2) 
Using the generators (11.111) and (11.103) we can write 
- 
x = ax1 + p x 2  +yx 
(11.122) 
and 
u(a, p, y) = (I cos w+X sin w) 
cos w + iy sin w 
(-0 + ia) sin w 
(1 1.123) 
(1 1.124) 
1 -  
(/3 + ia) sin w 
cos w - iy sin w 
The transformation 
(11.125) 
- 
v = u(w)v 

240 
CONTINUOUS GROUPS AND REPRESENTATIONS 
induces the following change in a function f(v1, ~ 2 ) :  
- 
f(V) = f Mff, P, Y)VI' 
(1 1.126) 
Taking the active view we define an operator 0, which acts on f(v). Since 
both views should agree, we write 
OfW = 7(.) 
(11.127) 
( 11.128) 
(11.129) 
= f [u-l(ff, 0, 
r,r] 
= f [U(-ff, -P, -7)rI. 
For a given small w we can write u(-a, -p, -7) in terms of a, p, y as 
I 
1 - iyw 
(p - i f f ) w  
(-p - i f f ) w  
1 + iyw 
i 
4 - ff, -P, -7) = 
(1 1.130) 
Thus we obtain 
- 
v1 = (1 - iyw)v] + (-p - iff)wvz 
(11.131) 
(11.132) 
- 
ug = (p - iff)wv1 + (1 + iyLJ)v2. 
Writing Svi = Vi - vi this becomes 
sv1 = -2ywVlf 
(-p - iff)wv2 
sv2 = (p - icu)wvl + iywv2. 
( 11.133) 
(11.134) 
We now write the effect of the operator 0 1 ,  which induces infinitesimal 
changes in a function f(vl,v2) as 
This gives the generator 0 1  as 
( 11.136) 
Similarly, we write 

LORENTZ GROUP AND ITS LIE ALGEBRA 
241 
and 
These give us the remaining generators as 
and 
(11.138) 
(11.139) 
(11.140) 
Oi satisfy the commutation relation 
[Oi, Oj] = 2ti3kOk . 
(11.141) 
The sign difference with Equation (11.112) is again due to the fact that in 
the passive view axes are rotated counterclockwise, while in the active view 
vectors are rotated clockwise. 
11.8 
LORENTZ GROUP AND ITS LIE ALGEBRA 
The ensemble of objects [a;], which preserve the length of four-vectors in 
Minkowski spacetime and which satisfy the relation 
!?ff0a7a6 
a 0 -  - 976, 
(11.142) 
form the Lorentz group. If we exclude reflections and consider only the 
transformations that can be continuously generated from the identity trans- 
formation we have the homogeneous Lorentz group. The group that 
includes reflections as well as the translations is called the inhomogeneous 
Lorentz group or the Poincare group. From now on we consider the 
homogeneous Lorentz group and omit the word homogeneous. 
Given the coordinates of the position four-vector xa in the K frame, ele- 
ments of the Lorentz group, 
, give us the components, To, 
in the fi; frame 
as 
--a x =a;zP. 
(11.143) 

242 
CONTINUOUS GROUPS AND REPRESENTATIONS 
In matrix notation we can write this as 
X =  AX, 
(1 1.144) 
where 
For transformations preserving the magnitude of four-vectors we write 
I 
( 1 I. 146) 
and after substituting Equation (11.144) we obtain the analogue of the or- 
thogonality condition as 
- -  
xgx = xgx, 
- 
AgA = g. 
(11.147) 
Elements of the Lorentz group are 4 x 4 matrices, which means they have 16 
components. From the orthogonality condition (11.147), which is a symmetric 
matrix, we have 10 relations among these 16 components; thus only 6 of them 
are independent. In other words, the Lorentz group is a six-parameter group. 
These six parameters can be conveniently thought of as the three Euler angles 
specifying the orientation of the spatial axis and the three components of p 
specifying the relative velocity of the two inertial frames. 
Guided by our experience with R(3), to find the generators of the Lorentz 
group we start with the ansatz that A can be written in exponential form as 
A = 8, 
(1 1.148) 
where L is a 4 x 4 matrix. From the theory of matrices we can write (Gant- 
macher) 
-+ 
det A = det eL = eTrL . 
(11.149) 
Using this equation and considering only the proper Lorentz transformations, 
where det A =1, we conclude that L is traceless. Thus the generator of the 
proper Lorentz transformations is a real 4 x 4 traceless matrix. 
We now multiply Equation (11.147) from the left by gpl and from the right 
by A-' to write 
g-lzg [AA-'I = g-'gA-', 
( 11.150) 
which gives 
- 
g-'Ag = Ap'. 
(11.151) 

LORENTZ GROUP AND ITS LIE ALGEBRA 
243 
Since for the Minkowski metric 
g - l = g ,  
(11.152) 
this becomes 
- 
gAg = A-.’. 
(11.153) 
-
-
 
Using Equation (11.153) and the relations g2 = I ,  A = eL, and A-l = ecL 
we can also write 
- 
- 
gAg = egLg = ePL; 
(11.154) 
thus 
- 
gLg = - L. 
(11.155) 
Since 
= g we obtain 
- 
g L  = -gL. 
(1 1.156) 
This equation shows that g L  is an antisymmetric matrix. Considering that g 
is the Minkowski metric and L is traceless, we can write the general form of 
L as 
(11.157) 
I- 
0 
-LO1 
-LO2 
-LO3 
-hl 
0 
‘512 
L 13 
-LO2 
- L l 2  
0 
L 2 3  
-LO3 
- L 1 3  
- L 2 3  
0 
L =  1 
Introducing six independent parameters (PI, 0 2 ,  j33) and (01, 02, 0 3 ) ,  this can 
also be written as 
L = PiV1 + P 2 V 2  + P 3 V 3  + & X I  + 0 2 x 2  + 0 3 x 3 ,  
(11.158) 
where 
-1 
0 0 
0 
0 - 1 0  
0 
0 0 - 1  
0 
0
0
 0 
- 1 0 0  
0 
(11.159) 
and 
0
0
 0 
0 
0
0
0
 0 
0
0
 0 
0 
0 0 0 - 1  
0 0 
0 -1 
0 
0 1  
1 
, x 2 =  [:;: :I.”- 
0 - 1 0 0 .  
0 
0 
0
0
 
(11.160) 

244 
CONTINUOUS GROUPS AND REPRESENTATIONS 
x’ 
Fig. 11.3 Boost and boost plus rotation 
Note that (XI, Xz, X3) are the generators of the infinitesimal rotations about 
the d-, z2-, z3-axes [Eq. (10.84)], respectively, and (Vl,Vz,V3) are the 
generators of the infinitesimal Lorentz transformations or boosts from one 
inertial observer to another moving with respect to each other with velocities 
(Pl,pz, p3) along the d-, 
z2-, z3-axes, respectively. These six generators 
satisfy the commutation relations 
(11.161) 
(11.162) 
(11.163) 
The first of these three commutators is just the commutation relation for the 
rotation group R(3); thus the rotation group is also a subgroup of the Lorentz 
group. The second commutator shows that Vi transforms under rotation 
like a vector. The third commutator indicates that boosts in general do not 
commute, but more important than this, two successive boosts is equal to a 
boost plus a rotation (Fig. 11.3), that is, 
Thus boosts alone do not form a group. An important kinematic consequence 
of this is known as the Thomas precession. 
We now define two unit bvectors: 
(11.165) 

LORENTZ GROUP AND ITS LIE ALGEBRA 
245 
and 
and introduce the parameters 
(1 1.166) 
8 =  vf8:+8;+8,2 
and 
(11.167) 
(1 1.168) 
so that we can summarize these results as 
L = X.68 + v-pp 
(11.169) 
and 
A = ,X ii6-1-V 
(1 1.170) 
For pure rotations this reduces to the rotation matrix in Equation (11.24) 
,X ii6 
A d .  = 
For pure boosts it is equal to Equation (10.276) 
Aboost(P) = ev BS 
(11.171) 
- 
- 
where 
(11.172) 
211 
212 
v2 
PI = -, 02 = -, 
0 2  = -. 
C 
C 
C 
For a boost along the xldirection P2 = P3 = 0 and ,# = PI, thus Equation 
(11.172) reduces to 
Y 
-PY 0 0 
(11.173) 
AbOOst(P1)= [ -Pr ; Y ; 0 0 y 1 . 

246 
CONTINUOUS GROUPS AND REPRESEN JAJIONS 
Using the parametrization 
-PI = tanhx 
y = cosh x 
-y& = sinhx 
( 11.174) 
( 11.175) 
( 11.176) 
Equation (11.173) becomes 
( 11.177) 
coshx sinhx 0 0 
Aboost(fil)=[ 
sinhx ; coshx ; 0 ; 
0 ;], 
which is reminiscent of the rotation matrices [Eqs. (10.42-43)] with hyper- 
bolic functions instead of the trigonometric. Notice that in accordance with 
our previous treatment in Section 11.2, the generator V1 can also be obtained 
from 
Vl = A L ( P 1  = 0). 
(11.178) 
The other generators can also be obtained similarly. 
1 1.9 G RO U P REP R ES E N TAT 10 N S 
As defined in Section 11.1, a group with its general element shown with g is an 
abstract concept. It gains practical meaning only when G is assigned physical 
operations, D(g), to its elements that act in some space of objects called the 
representation space. These objects could be functions, vectors, and in 
general tensors. As in the rotation group R(3) group representations can be 
accomplished by assigning matrices to each element of G, which correspond to 
rotation matrices acting on vectors. Given a particular representation D(g), 
another representation can be constructed by a similarity transformation as 
D'(g) = s-'D(g)s. 
( 11.179) 
Representations that are connected by a similarity transformation are called 
equivalent representations. Given two representations D(') (9) and D(2) (9) 
we can construct another representation: 
D(g) = D q g )  €B D(l)(g) = 
( 11.180) 
where D(g) is called the product of D(')(g) and D(2)(g). If D(')(g) has dimen- 
sion nl, that is, composed of 721 x n1 matrices, and D(2)(g) has dimension 722, 
the product representation has the dimension n1 + 722. D(g) is also called a 

GROUP REPRESENTATIONS 
247 
reducible representation. If D(g) cannot be split into the sums of smaller 
representations by similarity transformations, it is called an irreducible rep- 
resentation. Irreducible representations are very important and they form 
the building blocks of representation theory. A matrix that commutes with 
every element of an irreducible representation is a multiple of the unit ma- 
trix. We now present without proof an important lemma due to Schur for the 
criterion of irreducibility of a group representation. 
11.9.1 Schur's Lemma 
Let D(')(g) and D(')(g) be two irreducible representations with dimensions 
n1 and n 2 ,  and suppose that a matrix A exists such that 
AD(')(g) = D(2)(g)A 
(11.181) 
for all g in G. Then either A = 0, or n1 = n 2  and det A # 0, and the two 
representations D(') ( g )  and d2) 
(9) are equivalent. 
By a similarity transformation if D(g) can be written as 
( 1 1.182) 
we write 
D(g) = D(')(g) CB 2D(2)(g) 
@ D(3)(g). 
(11.183) 
If D(')(g), D(')(g), and D(3)(g) 
cannot be reduced further, they are irreducible 
and D(g) is called a completely reducible representation. 
Every group has a trivial one-dimensional representation, where each group 
element is represented by the number one. In an irreducible representation, 
say D(2)(g) 
as in the above case, then every element of the representation space 
is transformed into another element of that space by the action of the group el- 
ements D(')(g). For example, for the rotation group R(3) a three-dimensional 
representation is given by the rotation matrices and the representation space 
is the Cartesian vectors. In other words, rotation of Cartesian vectors always 
results in another Cartesian vector. 
11.9.2 Group Character 
The characterization of representations by explicitly giving the matrices that 
represent the group elements is not possible, because by a similarity transfor- 
mation one could obtain a different set of matrices. Thus we need to identify 
properties that remain invariant under similarity transformations. One such 

248 
CONTINUOUS GROUPS AND REPRESENTATIONS 
property is the trace of a matrix. We now define character ~ ( ~ ) ( g )  
as the trace 
of the matrices d i ) ( g ) ,  that is, 
n; 
( 11.184) 
11.9.3 
Unitary Representation 
Representations of a group by unitary (transformation) matrices are called 
unitary representations. Unitary transformations leave the quadratic form 
invariant, which is equivalent to the inner product 
n 
(11.185) 
(11.186) 
in complex space. 
11.10 
REPRESENTATIONS OF R(3) 
We now construct the representations of the rotation group. Using Cartesian 
tensors we can easily construct the irreducible representations as 
(11.187) 
where D(l)(g) is the trivial representation, the number one, that acts on 
scalars. D(3)(g) are given as the 3 x 3 rotation matrices that act on vec- 
tors. The superscript 3 indicates the degrees of freedom, in this case the 
three independent components of a vector. D(5)(g) is the representation cor- 
responding to the transformation matrices for the symmetric second-rank 
Cartesian tensors. In this case the dimension of the representation comes 
from the fact that a second-rank symmetric tensor has six independent com- 
ponents; removing the trace leaves five. In general a symmetric tensor of rank 
n has (2n+ 1) independent components; thus the associated representation is 
(2n + 1)-dimensional. 

SPHERlCAL HARMONICS AND REPRESENTATIONS OF R(3) 
249 
11.11 SPHERICAL HARMONICS AND REPRESENTATIONS OF 
R(3) 
An elegant and also useful way of obtaining representations of R(3) is to con- 
struct them through the transformation properties of the spherical harmon- 
ics. The trivial representation D(’)(g) simply consists of the transformation 
of Yo0 onto itself. d 3 ) ( g )  describes the transformations of ql=1)m(Q,4). 
The 
three spherical harmonics (Yl- 
1 ,  Y ~ o ,  
Y11) under rotations transform into lin- 
ear combinations of each other. In general, the transformation properties of 
the (2l+ 1) components of x,(e, 4) generate the irreducible representations 
D(21+1)(g) 
of R(3). 
11.11.1 
In quantum mechanics angular momentum, L, is a differential operator acting 
on a wave function q(x, y, 2). It is obtained from the classical expression for 
the angular momentum, 
Angular Momentum in Quantum Mechanics 
+ 
L = ? ; ’ x T ,  
(11.188) 
by replacing position and momentum with their operator counterparts, that 
is, 
?+?, 
as 
L = 4i-P x a‘. 
(11.189) 
(1 1,190) 
Writing L in Cartesian coordinates we find its components as (we set fi = 1) 
(1 1.191) 
(1 1.192) 
(1 1.193) 
In Section 11.3.1 we have seen that xi satisfy the commutation relation 
pZi,Xj] = EijklZk, 
(11.194) 
thus Li satisfy 
[Li, Lj] = ZGjkLk, 
(1 1.195) 
where the indices i, j and lc take the values 1,2,3 and they correspond to x, y, z, 
respectively. 

250 
CONTINUOUS GROUPS AND REPRESENTATIONS 
Fig. 11.4 Counterclockwise rotation of the physical system by 6, about fi 
11.11.2 
Rotation of the Physical System 
We have seen that the effect of the operator [Eq.(11.40)] 
- 
( 1 I. 196) 
,-x he, 
is to rotate a function clockwise about an axis pointing in the fi direction by 
On. In quantum mechanics we adhere to the right-handed screw convention, 
that is, when we curl the fingers of our right hand about the axis of rotation 
and in the direction of rotation, our thumb points along fi. Hence we work 
with the operator 
- 
> 
(11.197) 
,x fie, 
which rotates a function counterclockwise by 8, 
(Fig. 11.4). Using Equations 
(11.191-11.193) the quantum mechanical counterpart of the rotation operator 
now becomes 
R =e-iL 66, 
( 11.198) 
For a rotation about the z-axis this gives 
R9(r,6,4) = [e-iLzd] @(T, 8,4). 
(11.199) 
R@(z,Y,z) = e-iL6en@(z,y,z). 
(11.2oo) 
For a general rotation about an axis in the fi direction by 8, we write 

SPHERICAL HARMONICS AND REPRESENTATIONS OF R(3) 
251 
11.11.3 
Using the Euler angles we can write the rotation operator 
Rotation Operator in Terms of the Euler Angles 
R = e - i ~  iie, 
f 
(11.201) 
(11.202) 
In this expression we have used another convention commonly used in modern- 
day quantum mechanical discussions of angular momentum. It is composed 
of the sequence of rotations, which starts with a counterclockwise rotation by 
Q about the z-axis of the initial state of the system: 
e-ioL, : (GY, 
z> -+ (zl,YI,zl). 
(1 1.203) 
about y1 of the interme 
This is followed by a counterclockwise rotation by 
diate axis as 
e - i p L y l :  
(z1,y1,z1) + (Z2,Y2,Z2). 
( 1 1.204) 
Finally the desired orientation is reached by a counterclockwise rotation about 
the q-axis by y as 
e-i7Lz, 
~ (z2,y2, z2) --t (z’, Y’, 
2’). 
(1 1.205) 
11.11.4 
One of the disadvantages of the rotation operator expressed as 
Rotation Operator in Terms of the Original Coordinates 
(1 1.206) 
R =e- iL.;ie, - 
- e- i y ~ , ,  e- i p ~ , ,  e - i a ~ z  
is that, except for the initial rotation about the z-axis, the remaining two 
rotations are performed about different sets of axis. Because we are interested 
in evaluating 
RWz,y, z )  = WZ’,Y’, 4, 
( 1 1.207) 
where (z, y, z )  and (z’, y’, z’) are two points in the same coordinate system, 
we need to express R as rotations entirely in terms of the original coordinate 
axis. 
For this we first need to find how the operator R transforms under co- 
ordinate transformations. We now transform to a new coordinate system 
(zn, 
yn, zn), where the +axis 
is aligned with the fi direction. We show the 
matrix of this coordinate transformation with the letter R. We are interested 
in expressing the operator R in terms of the ( z ~ ,  
yn, zn) coordinates. Action 
of R on the coordinates induces the following change in @(z, y, z )  : 

252 
CONTINUOUS GROUPS AND REPRESENTATIONS 
Fig. 11.5 Transformation to the (z,, g,, 2,)-axis 
Similarly for another point we write 
R@(z’, 
y’, z’) = \k(z;, 
y;, 
zk). 
Inverse transformations are naturally given as (Fig. 11.5) 
R-l*(z,,ym,zn) 
= @(z,y,z) 
R-’*(z;,y;,z;) 
= @(z’,y’,z/). 
RR-’*(~,,y,,zn) 
= RQ(z,y,z). 
and 
Operating on Equation (11.210) with R we get 
Using Equation (11.207), this becomes 
We now operate on this with R to get 
where 
(11.209) 
(11.210) 
(11.211) 
(11.212) 
(11.213) 
(11.214) 
( 1 1.2 15) 
( 11.2 16) 

SPHERICAL HARMONICS AND REPRESENTATIONS OF R(3) 
253 
We now observe that (This may take a while to convince oneself. We recom- 
mend that the reader first plot all the axes in Equations (11.203) to (11.205) 
and then, operate on a radial vector drawn from the origin with (11.217). 
Finally, trace the orbit of the tip separately for each rotation while preserving 
the order of rotations.) 
e-iYLz, = e-iPLy, e-i7L,1 eiPLyl 
( 11 217) 
to write 
R ,e-iPLgl 
e-i’YLzl [eiPLyl e-iPLgl] e-iaLz. 
( 11 218) 
The operator inside the square brackets is the identity operator; thus 
R ,e-iPLgl 
e - i 7 L z 1 e - i a L ~  
(1 1.219) 
We now note the transformation 
e- iPL,, = e- i a L ,  e-- iPLY eiaL, 
(1 1.220) 
to write 
(1 1.221) 
R = e - i a L ~  e-iPLyeiaL.e-i’YL.l 
e-iaL, 
Since z1 = z, this becomes 
(11.222) 
R ,e-iaLze-iflLy 
[ i a L z e - i a L ,  ] e-iyL,- 
Again the operator inside the square brackets is the identity operator, thus 
giving R entirely in terms of the original coordinate system (x, 
y, 
z )  as 
(11.223) 
R =e-i0.L,e-i0Lye-i7Lz 
We can now find the effect of R(a7 P, y) on @(z, y, 
z) as 
R(a,P,y)qz,!Az) = Wx’,Y’,z’) 
( 1 1.224) 
e-iaL,e-iPLye-i7L, 
\[I ( ,Y,Z) = Wz’,y’,z’). 
In spherical polar coordinates this becomes 
R(a, P7 Y)W, 0, $1 = w-, 
8,’ 4’). 
(1 1.225) 
Expressing the components of the angular momentum operator in spherical 
polar coordinates: 
x + zy = r sin &+a6 
and 
z = rcosf?, 
(1 1.226) 

254 
CONTINUOUS GROUPS AND REPRESENTATIONS 
Y’ 
Fig. 11.6 (z,y,z) and the (z‘,y’,z‘) coordinates 
we obtain (Fig. 11.6) 
L,= 
(1 1.227) 
d 
icotOsin4- 
84 
a 
a 
ae 
34 
L* = L, * ZL, = e*;q*- 
+ icot 0-), 
L2 = L: + L; + Lq 
(11.228) 
(11.229) 
(11.230) 
(11.231) 
Using Equations (11.227-11.229) we can now write Equation (11.224) as 
which is now ready for applications to spherical harmonics &(O, 
4). 

SPHERICAL HARMONICS AND REPRESENTATIONS OF R(3) 
255 
11.11.5 
In Chapter 9 we have established the following eigenvalue equations [Eqs. 
(9.172-173) and (9.187-188)]: 
Eigenvalue Equations for L,, Lk, and L2 
LzKm(Q, 4) = mXm(Q7 4)> 
L - K , ( Q , ~ )  = J(i+m)(i -m+ 1)x,m-1(Q74)7 
L+xm(Q, 4) = JQ - m)(i+ m + l ) x , m + l ( ~ ,  
417 
L2Km(@, 4) = 1(1+ 1)Xm(Q, 4). 
(11.233) 
(11.234) 
(11.235) 
(11.236) 
Using these and the definition L* = L, * zLy we can also write 
(11.237) 
11.11.6 
W e  can expand a sufficiently smooth function, F(B, @)7 in terms of spherical 
harmonics, which forms a complete and orthonormal set as 
Generalized Fourier Expansion in Spherical Harmonics 
co m‘=l’ 
F(o,4) = C C C L ~ ~ I K ( ~ ~ ( Q ,  
4)7 
( 1 1.239) 
l’=O m’=- 1’ 
where the expansion coefficients are given as 
cL’mt = / / dQqfml 
(@7 4)F(B7 4)- 
Spherical harmonics satisfy the orthogonality relation 
1 1 
dQY,:,, 
(Q74)Km(Q, 4) = 4P fimmf 
and the completeness relation 
(1 1.240) 
( 1 1.24 1) 
c c 
Y,L(Q’,4’)Km(B,4) 
= G(cosQ-cosQ’)6(4-4’), 
I=O m=-I 
(11.242) 
where dQ = sin Qdsdq5. In the study of angular momentum in quantum physics 
we frequently need expansions of expressions like 
&z(Q, 4) = f(Q7 
4>Xm(Q7 4) 
(1 1.243) 

256 
CONTINUOUS GROUPS AND REPRESENTATIONS 
and 
(11.244) 
a
a
 
Glrn(e,4) = o(- -,Q,4)Krn(Q,4), 
a6 ' a4 
where O($, &, 8,4) is some differential operator. For &,(6,4) we can write 
For Gtrn(6,4) we can write 
where 
Based on these we can also write the expansion 
(11.250) 
(11.252) 
where 

SPHERICAL HARMONICS AND REPRESENTATIONS OF R(3) 
257 
11.11.7 
Using the result [Eq. (11.249)] of the previous section we can now evaluate 
LyY(l=I)rn as 
Matrix Elements of L,, Ly, 
and 5, 
m'=l 
L y q l = l ) m  = C C~fnz~,(l=l)mK~ml(Q, 
4)- 
This gives the following matrix elements for the angular momentum operator 
Ly(l = 1) as 
(11.254) 
m'= - 1 
(Kl=1mt, LyX=Im) = Cf'=lm',t=lm 
( 1 1.255) 
= // XLlm{(Q, 4)LyK=lm(Q, 4). 
We have dropped brackets in the 1 indices. We now use Equation (11.238): 
to write 
(1 1.257) 
Operating on Equation (11.254) with Ly and using Equation (11.257) we can 
write 
m'= 1 
L;K=lm = C LyKf=lm/(Q, 4) [ ~ y ( i  
= l)lmJm 
(1 1.258) 
m'=- 1 
to obtain the matrix elements of Lz as 
[L;Q = 1)lmrn, 
( 1 1.259) 
0 -5 0 
0 
1/2 
0 -1/2 
-1/2 
0 
1/2 
= [  0 
1 
0 1. 

258 
CONTINUOUS GROUPS AND REPRESENTATIONS 
(11.260) 
and 
11.11.8 
Because the effect of the rotation operator R(a, ,B, y) on the spherical har- 
monics is to rotate them from (8,$) to new values (0,’ d’)) we write 
Rotation Matrices for the Spherical Harmonics 
In spherical polar coordinates this becomes 

SPHERICAL HARMONICS AND REPRESENTATIONS OF R(3) 
259 
We now express Km(6,’4’) in terms of the original xm(B, 
4) as 
Km(8,’ 4’) = C Yitmf(0, 
d)Ct~m~,tm~ 
(11.269) 
l’m’ 
where 
dQY,?mr (6, 4)R(a, P, y)Km(Q, 4)- 
(1 1.270) 
Since the spherical harmonics are defined as 
(1 1.271) 
R does not change their 1 value. Hence only the coefficients with 1 = 1’ are 
nonzero in Equation (11.270), thus giving 
where 
m’=l 
kim(8,’ 4’) = C KmJ(e, 4)~Al,(a, P, 7). 
D k , m ( ~ ,  
P, y) is called the rotation matrix of the spherical harmonics. Using 
the definition [Eq. (11.223)] of R(a, P, y) we can construct the rotation matrix 
as 
(1 1.274) 
m’=-l 

260 
CONTINUOUS GROUPS AND REPRESEN TATIONS 
m'= 1 
m' = 0 
m' = -1 
- 
- 
We have used the fact that L, is a Hermitian operator, that is, 
q L , q z d o  = 
( L z q l ) * q z d o .  
J 
Defining the reduced rotation matrix dA,m(,8) as 
~ L ( ~ ( P )  
= J J d ~ q h l  
(Q, 4) e-ipLyxm(g, d), 
(1 1.276) 
we finally obtain 
Dmtm(a, 
1 
P, y) = e-iQm'di,m(,B)e-iym. 
(11.277) 
- 
- 
.- 
! 
sin ,B 
g(l+cosp) -- 
$(l-COSP) 
Jz 
i(1-cosP) - 
g(1 +cosP) 
sin P 
c m p  
-- Jz 
sin P 
sin P 
fi 
JZ 
11.11.9 
For the low values of 1 it is relatively easy to evaluate di,,(P). 
For example, 
for 1 = 0 : 
Evaluation of the dk,,(p) Matrices 
do,fm(P) = 1, 
which is the trivial 1 x 1 matrix. 
For 1 = 1 we can write Equation (11.276) as 
(11.278) 
(11.279) 
Using the matrix elements of (Ly)n obtained in Section 11.11.7, we write this 
as 
(11.280) 
dm,,(P) 
1 
= Jmmg - i ( L g ) m m ,  sinp+ ( L ~ ) m m ~ ( c o ~ P -  
1) 
i 4 
=[: 0
0
1
 
:I--isinP[ i 
-;I 0 
f 
1/2 
0 -1/2 
-l/2 
0 
1/2 
Finally adding these we find 
dklm (PI 
m = l  
m=O 
m=-1 
(11.281) 

SPHERICAL HARMONICS AND REPRESENTATIONS OF R(3) 
261 
11.11.10 
To find the inverse matrices we invert 
Inverse of the d;,,(p) 
Matrices 
Km(Q’, 4’) = R(a, P, Y)Km(Q, 4) 
(1 1.282) 
to write 
Km(Q94) = R-l(a,p,~)Krn(Q’, 
4’) 
(11.283) 
( 1 1.284) 
= R(-Y, -P, -a)Km(Q’, 4’)- 
Note that we have reversed the sequence of rotations because 
R-’(a,p,r) = [R(cY)R(P)R(T)]~’ 
= R(-y)R(-P)R(-a). 
(11.285) 
We can now write Km(Q, 4) in terms of Km(Q’, 4’) as 
Km 
(1 1.286) 
Using the fact that L, is Hermitian, this can be written as 
This leads to 
= C Kmlt (el, 4’) [DLm”(a, P, Y)] * > 
( 1 1.288) 
where we have used the fact that L, is Hermitian and Li = -L,. 
This result 
can also be written as 
(11.289) 
m” 
Km(Q,d) = C KmJl (Q’, 4’) DLllm(-T, -P, -a)> 
m“ 
which implies 
Dmrtm(R-’) 
1 
= [DL,,,(R)]-’ = [Dim,,(R)]*. 

262 
CONTINUOUS GROUPS AND REPRESENTATIONS 
11.11.11 
From the definition of the Euler angles (Section 11.11.3) it is clear that the 
rotations (a, p, y) are all performed about different sets of axes. Only the first 
rotation is about the z-axis of our original coordinates, that is, 
Differential Equation for d;,, (p) 
z ,  (we set ti = 1). 
(11.2W) 
. a  
aa 
-2- 
= L 
Similarly, we can write the components of the angular momentum vector 
about the other intermediate axes, that is, y1 and the z2-axis, in terms of the 
components of the angular momentum about the 2-, y-, and z-axes as: 
(11.291) 
. a  
dB 
L,, = -2- 
= -sinaL, + cosaL, 
and 
Inverting these we obtain 
a ] 
(11.293) 
a 
cosa a 
-sina- 
+ -- - cosacotp- 
sin@ ay 
aa 
aa 
cosa- + -- -sinacotp- 
d 
sina d 
dp 
sinP ay 
(11.294) 
a 
da 
L --i-. 
2 -  
(11.295) 
We now construct L2 as 
L2 = L: + L; + Li 
(1 1.296) 
Wecould usethe L2 operatoreitherin termsof (a,p,y) as L2(&, q, 
a
a
 
q l a , p l y )  
and act on DL,,(a,p,y), or in terms of (B,q%) as L2(&, &]B,d) and act on 
&(6,4). We first write (we suppress derivatives in L2) 
L2(@, 4)Km(@, 4’) = L2(a, P, r)Krn(O/, 47 
(11.297) 
and use Equation (1 1.274) and 

SPHERICAL HARMONICS AND REPRESENTATIONS OF R(3) 
263 
to write 
Since xml (8,q5) are linearly independent, this gives the differential equation 
that DLrm(a, P,r) satisfies as: 
Using Equation (11.296) for L2(&, $, &,a,p,y) and the derivatives 
- 
d2 
1 
12 
1 
aa2 Dml m = -m Dml m 
dY2 
(1 1.301) 
-Dmrm 
a2 
1 
= -TTL 2
1
 
D,,, 
which follow from Equation (11.277), we obtain the differential equation for 
dLlm (PI as 
m2 + mf2 - 2mm' cosp 
{ $ 
+cotp- + [ 1(1+ 1) - ( 
sin2p 
) ] } drnf m (P) = 0. 
( 1 1.302) 
dP 
Note that for 
m'=O o r m = O  
( 1 1.303) 
this reduces to the associated Legendre equation, which has the following 
solutions: 
Dkrn a xL(P, Y), 
DLYl a Kd (P, a). 
( 11.304) 
( 1 1.305) 
. Using 
1 
Also note that some books call DLm, (R) what we call [Dim( (R)] 
the transformation 
(11.306) 

264 
CONTlNUOUS GROUPS AND REPRESENTATlONS 
we can put Equation (11.302) in the second canonical form of Chapter 9 as 
(11.307) 
11.11.12 
We have seen that the spherical harmonics transform as 
Addition Theorem for Spherical Harmonics 
m'=l 
Km(@,'4') = C K m ~ ( 8 , 4 ) D L ~ m ( ~ , P ,  
71, 
m'=-l 
with the inverse transformation given as 
(11.308) 
(11.309) 
where 
We now prove an important theorem about spherical harmonics, which says 
that the sum 
m=l 
( 11.31 1) 
m=-l 
is an invariant. This is the generalization of rl . r 2  and the angles are defined 
as in Figure 11.7. 
Before we prove this theorem let us consider the special case 1 = 1, where 
and 
Using Cartesian coordinates we can write also these as 
(11.312) 
(11.313) 
(1 1.314) 

SPHERICAL HARMONICS AND REPRESENTATIONS OF R(3) 
265 
F;g. 11.7 Definition of the angles in the addition theorem of the spherical harmonics 
and 
We now evaluate I1 as 
To prove the invariance for a general 1 we write the expression 
(1 1.315) 
(11.316) 
(1 1.317) 
(1 1.318) 
(1 1.319) 
as 

266 
CONTINUOUS GROUPS AND REPRESENTATIONS 
( 11.320) 
m=-l 
m 
11.11.13 
Because I1 is an invariant we can choose our axis, and the location of the 
points PI and P 2  conveniently as shown in Figure 11.8. Thus we can write 
Determination of 11 in the Addition Theorem 
(11.322) 
(1 1.323) 
(11.324) 

SPHERICAL HARMONICS AND REPRESENTATIONS OF R(3) 
267 
Fig. 11.8 Evaluation of 4 
Using the value e(0) = 1, we complete the derivation of the addition theorem 
of the spherical harmonics as 
Example 11.1. Multipole expansion: We now consider the electrostatic 
potential of an arbitrary charge distribution at (r,O,Cp) as shown in 
Figure 11.9. Given the charge density p(r’,B’, 4’) we can write the elec- 
trostatic potential as 
The integral is to be taken over the source variables (r’, O’, Cp’), 
while 
(r, 0,$) denotes the field point. For a field point outside the source we 
define a new variable, t = r’/r, to write 
Using the generating function definition for the Legendre polynomials, 
which is given as 
M 
T (x, t) = 
1 
= CPj (x)t’ , It1 < 1 , 
(11.328) 
Jl + 12 - 2tx 
I=o 

268 
CONTINUOUS GROUPS AND REPRESENTAT/ONS 
11. 
Fig. 11.9 Multipole expansion 
equation (11.327) becomes 
Using the addition theorem this can now be written as 
(1 1.330) 
0
0
1
 
where 
= 
. The expression 
is called the (1m)th multipole moment 
2 
IRREDUCIBLE REPRESENTATIONS OF s u(2) 
(11.331) 
From the physical point of view a very important part of the group theory is 
representing each element of the group with a linear transformation acting in 
a vector space. We now introduce the irreducible matrix representations of 
SU(2). There is again the trivial on+dimensional representation dl), 
where 

RELATION OF su(2) AND R(3) 
269 
(1 1.337) 
I- 
- D(1) 
0 
0 
. 
0 
0 
D(2) 
0 
.. 
0 
0 
0 
D(3) 
1.. 
0 
... 
... 
0 
- 0 
0 
0 
0 
each group element is represented by the number one. 
two-dimensional representation D(2) provided by the matrices (1 1.84) 
Next we have the 
(11.332) 
where A and B satisfy 
( 1 1.333) 
detu = / A [  + IBI = 1. 
These act on two-dimensional vectors in the complex plane, which we show 
as 
2 
2 
(1 1.334) 
or 
w =we, a = 1,2. 
(1 1.335) 
For the higher-order representations we need to define tensors, such that each 
element of the group corresponds to transformations of the various compo- 
nents of a tensor into each other. Such a representation is called generated by 
tensors. In this regard, D(') is generated by scalars, D(2) is generated by vec- 
tors, and d3) 
is generated by symmetric second-rank tensors wep. In general, 
D(") is generated by completely symmetric tensors with (n - 1) indices, 
WLYla2....an-l, 
( 1 1.336) 
as 
11.13 RELATION OF su(2) AND R(3) 
We have seen that the general element, u, of SU(2) is given as Equation 
(11.332). We now define a matrix operator in this space as 
1 
z 
x-iy 
x + i y  
--z 
' 
P =  [ 
( 1 1.338) 
RELATION OF s u ( 2 )  AND R(3) 
269 
each group element is represented by the number one. 
twcdmensional representation D(2) provided by the matrices (1 1.84) 
Next we have the 
(1 1.332) 
where A and B satisfy 
detu=IAl 2 +lBl 
2 = l .  
(1 1.333) 
These act on two-dimensional vectors in the complex plane, which we show 
as 
(11.334) 
or 
w =war a = 1,2. 
(11.335) 
For the higher-order representations we need to define tensors, such that each 
element of the group corresponds to transformations of the various compe 
nents of a tensor into each other. Such a representation is called generated by 
tensors. In this regard, D(l) is generated by scalars, D(2) is generated by vec- 
tors, and d3) 
is generated by symmetric second-rank tensors wap. In general, 
D(") is generated by completely symmetric tensors with (n - 1) indices, 
(1 1.336) 
WO,O.l. ... On - 1 1 
as 
(1 1.337) 
If walaz,..a,-l is not symmetric with respect to any of the two indices, then we 
can contract those two indices and obtain a symmetric tensor of rank two less 
than the original one; thus wala2.,,a,-1 is not irreducible because it contains 
the smaller representation generated by the contracted tensor. 
11.13 RELATION OF su(2) AND R(3) 
We have seen that the general element, U, of SU(2) is given as Equation 
(11.332). We now define a matrix operator in this space as 
1 
z 
x-iy 
x f i y  
-2 
' 
P =  [ 
(1 1.338) 

270 
CONTINUOUS GROUPS AND REPRESEN TATIONS 
where (2, 
y, 
z) are real quantities. However, we will interpret them as the 
coordinates of a point. Under the action of u, P transforms as 
P’ = UPu-1, 
( 11.339) 
which is nothing but a similarity transformation. For unitary operators u 
satisfies 
u-l - u  
- t - 
- G * .  
(11.340) 
Note that P is Hermitian, that is, 
P+ = P 
(11.341) 
and traceless. Because the Hermitian property, trace, and the determinant of 
a matrix are invariant under similarity transformations, we can write 
(11.342) 
where (x’, 
y’, z’) are again real and satisfy 
- det P’ = ( X ’ ~  + Y ‘ ~  
+ z ’ ~ )  
= (x2 + y2 + z2) = - det P. 
(11.343) 
This is just the orthogonality condition, which requires that the magnitude 
of a vector, 
(11.344) 
remain unchanged. In summary, for every element of SU(2) we can associate 
an orthogonal transformation in three dimensions. 
We have seen that the orientation of a systeni in three dimensions can be 
completely specified by the three Euler angles (#, 6, +). A given orientation 
can be obtained by three successive rotations (Section 10.4). We now find the 
corresponding operators in SU(2). For convenience we first define 
x+ =z+iy 
2- = x - zy. 
(11.345) 
(11.346) 
This allows us to write the first transformation, which corresponds to rotation 
about the z-axis as 
(11.347) 
z‘ = z. 

RELATION O F S U ( 2 )  AND R(3) 
271 
In SU(2) this corresponds to the transformation 
z' 
x
'
 
p'= [ 
-z' ] 
On performing the multiplications we get 
x'+ = -2B*A*z - B*'x-. + A*'x+ 
X
'
 
= -2ABzf A'x- - R'x+ 
Z' = (lAI2 - IBI2)z + AB'x- + BA*x+. 
Comparing this with Equation (11.347) gives 
Thus 
Similarly, we obtain the other matrices as 
1 
cos 012 
i sin 812 
u@= [ i sin 0/2 
cos 012 
and 
For the complete sequence we can write 
which is 
(1 1.348) 
(11.349) 
(1 1.350) 
(11.351) 
(1 1.352) 
(1 1.353) 
( 1 1.354) 
(1 1.355) 
(11.356) 
( 1 1.357) 
In terms of the three Euler angles the four independent parameters of u [Eq. 
(Il.SS)] are now given as 
A = a + id = el(++@)/' cos 012 
B = c + ib = iei(*-@)/' sin $12. 
(1 1.358) 
( 1 1.359) 

272 
CONTINUOUS GROUPS AND REPRESENTATIONS 
The presence of half-angles in these matrices is interesting. If we examine 
ub, for $J = 0 it becomes 
(11.360) 
which corresponds to the identity matrix in R(3). However, for 4 = 27r, which 
also gives the identity matrix in R(3), u+ corresponds to 
(11.361) 
in SU(2). Hence the correspondence (isomorphism) between SU(2) and R(3) 
is twc+tc+one. The matrices (u, -u) in SU(2) correspond to a single matrix 
in R(3). 
The complex two-dimensional vector space is called the spinor space. It 
turns out that in quantum mechanics the wave function, at least parts of it, 
must be composed of spinors. The double-valued property and the half-angles 
are associated with the fact that spin is half-integer. 
11.14 GROUP SPACES 
11.14.1 
Real Vector Space 
We have seen that the elements of R(3) act in a real vector space and transform 
vectors into other vectors. A real vector space V is defined as a collection of 
objects (vectors) with the following properties: 
Let 3 1 , 3 2 , 3 3  be any three elements of V. 
1. Addition of vectors results in another vector: 
$1 + 3
2
 E V. 
2. Addition is commutative: 
3. Addition is associative: 
($1 + 3 2 )  + 3
3
 = $1 + ($2 + $3). 
4. There exists a null vector 3 
such that for any 3 
E V 
$+3=b. 

GROUP SPACES 
273 
5. For each 3 
E V there exists an inverse (-3) 
such that 
+ 
21 + (-3) 
= 0. 
6. Multiplication of a vector 3 
with the number one leaves it unchanged: 
1 3  = 3. 
7. A vector multiplied with a scalar is another vector: 
C
3
€
V
 
A set of vectors 3; 
g V, i = 1,2, ..., n is said to be linearly independent 
( 1 1.362) 
if the equality 
c 1  + 
u 
1 + c 2 3 2  + . . . + c n z n  = 0 
can only be satisfied for the trivial case 
c1 = cg =. . . = cn = 0. 
(1 1.363) 
In an N-dimensional vector space we can find N linearly independent unit 
basis vectors G; E V, i = 1,2, ..., n, such that any vector in V can be expressed 
as a linear combination of these vectors as 
i -  
21 - ClP, + czG2 + . . ' + cnGn . 
(1 1.364) 
11.14.2 
Inner Product Space 
Adding to the above properties a scalar or an inner product enriches the 
vector space concept significantly and makes physical applications easier. In 
Cartesian coordinates the inner product, also called the dot product, is defined 
as 
( 1 1.365) 
Generalization to arbitrary dimensions is obvious. The inner product makes 
it possible to define the norm or magnitude of a vector as 
131 = (3. 
3 p 2 ,  
( 11.366) 
( 3 1 , 7 7 2 )  = 3
1
 
. 3 2  = 2)112)22. +211,212* 
+211,212,. 
where the angle between two vectors is defined as 
( 1 1.367) 
Basic properties of the inner product are: 
- 8 1 . 3 2  = 3 2 . 3 1  
(1 1.368) 
and 
3 1 .  ( a 3 2  + b 3 3 )  = a ( 3 1 . 3 2 )  +b(Z+iT'1.33), 
( 1 1.369) 
where a and b are real numbers. A vector space with the definition of an inner 
product is also called an inner product space. 

274 
CONTlNUOUS GROUPS AND REPRESENTATlONS 
11.14.3 
Four-Vector Space 
In Section 10.10 we have extended the vector concept to Minkowski spacetime 
as four-vectors, where the elements of the Lorentz group act on four-vectors 
and transform them into other four-vectors. For four-vector spaces properties 
(1)-(7) still hold; however, the inner product of two four-vectors A" and B" 
is now defined as 
where goo is the Minkowski metric. 
11.14.4 
Complex Vector Space 
Allowing complex numbers, we can also define complex vector spaces in the 
complex plane. For complex vector spaces properties (1)-(7) still hold; how- 
ever, the inner product is now defined as 
(1 1.371) 
where the complex conjugate must be taken to ensure a real value for the 
norm (magnitude) of a vector, that is, 
131 = (3. 
$)1/2 
= (gv:vi)1'2. ( 1  1.372) 
Note that the inner product in the complex plane is no longer symmetric, that 
is, 
- 8 1 . 3 2  # 3.2.31, 
(11.373) 
however, 
(11.374) 
is true. 
11.14.5 
We now define a vector space L2, whose elements are complex valued functions 
of a real variable IL', which are square integrable in the interval [a, b]. L 2  is also 
called the Hilbert space. By square integrable it is meant that the integral 
Function Space and Hilbert Space 
(11.375) 

GROUP SPACES 
275 
exists and is finite. Proof of the fact that the space of square integrable 
functions satisfies the properties of a vector space is rather technical, and we 
refer to books like Courant and Hilbert, and Morse and Feshbach. The inner 
product in L2 is defined as 
b 
(fl, f2) = 
fi*(z)f2(z)dz- 
(1 1.376) 
In the presence of a weight function ~ ( z )  
the inner product is defined as 
6 
( f 1 , f Z )  = h f;(.)f2(.)w(.>dx. 
(11.377) 
Analogous to choosing a set of basis vectors in ordinary vector space, a major 
problem in L2 is to find a suitable complete and orthonormal set of functions, 
{u,(z)}, such that a given f(z) 
E L2 can be expanded as 
00 
f(z) 
= c cm.llm(z). 
(1 1.378) 
m=O 
Orthogonality of {u,(z)} is expressed as 
(urntun) = 
uL(z)un(z)dz 
= &n,, 
(11.379) 
where we have taken ~ ( z )  
= 1 for simplicity. Using the orthogonality relation 
we can free the expansion coefficients under the summation sign in Equation 
(11.378) to express them as 
Lb 
(1 1.380) 
In physical applications {urn(.)} is usually taken as the eigenfunction set of 
a Hermitian operator. Substituting Equation (11.380) back into Equation 
(11.378) a formal expression for the completeness of the set {um (z)} is ob- 
tained as 
00 c u; (z’) u, (z) = qz - z’). 
( 1 1.381) 
m=O 
11.14.6 
Proof of the completeness of the eigenfunction set is rather technical for our 
purposes and can be found in Courant and Hilbert (p. 427, vol. 1). What is 
important for us is that any sufficiently well-behaved and at least piecewise 
Completeness of the Set of Eigenfunctions {Urn (s)) 

276 
CONTINUOUS GROUPS AND REPRESENTATIONS 
continuous function, F (x) , can be expressed as an infinite series in terms of 
the set {urn (z)} as 
00 
(11.382) 
m=O 
Convergence of this series to F (z) could be approached via the variation 
technique, and it could be shown that for a Sturm-Liouville system the limit 
(Mathews and Walker, p. 338) 
2 
b 
N 
lim / [. 
(z) - ~ a m u ,  
(z)] w (z) dz -+ 0 
N-oo 
a 
m=O 
(1 1.383) 
is true. In this case we say that in the interval [a, b] the series 
(I 1.384) 
m=O 
converges to F (z) in the mean. Convergence in the mean does not imply 
point-tepoint (uniform) convergence: 
N 
(11.385) 
m=O 
However, for most practical situations convergence in the mean will accom- 
pany point-to-point convergence and will be sufficient. We conclude this sec- 
tion by quoting a theorem from Courant and Hilbert (p. 427). 
Expansion Theorem: Any piecewise continuous function defined in the 
fundamental domain [a, b] with a square integrable first derivative could 
be expanded in an eigenfunction series F (z) = 
amum (z), which 
converges absolutely and uniformly in all subdomains free of points of 
discontinuity. At the points of discontinuity it represents the arithmetic 
mean of the right- and the left-hand limits. 
00 
m=O 
In this theorem the function does not have to satisfy the boundary con- 
This theorem also implies convergence in the mean; however, the 
ditions. 
converse is not true. 
11.15 HILBERT SPACE AND QUANTUM MECHANICS 
In quantum mechanics a physical system is completely described by giving its 
state or wave function, @(z), in Hilbert space. To every physical observable 

CONTINUOUS GROUPS AND SYMMETRIES 
277 
there corresponds a Hermitian differential operator acting on the functions in 
Hilbert space. Because of their Hermitian nature these operators have real 
eigenvalues, which are the allowed physical values of the corresponding observ- 
able. These operators are usually obtained from their classical definitions by 
replacing position, momentum, and energy with their operator counterparts. 
In position space the replacements 
F ---f 7, 
y + -ativ, 
( 1 1.386) 
a 
E ---$ iti- at 
have been rather successful. Using these, the angular momentum operator is 
obtained as 
(1 1.387) 
-+ 
L = ? x Y  
= -ah? 
x a. 
--f 
In Cartesian coordinates components of L are given as 
where Li satisfies the commutation relation 
[Li, Lj] = ihEijkLk 
(1 1.388) 
(1 1.389) 
(11.390) 
(11.391) 
11.16 CONTINUOUS GROUPS AND SYMMETRIES 
In everyday language the word symmetry is usually associated with familiar 
operations like rotations and reflections. In scientific applications we have a 
broader definition in terms of general operations performed in the parame- 
ter space of a given system. Now, symmetry mezlns that a given system is 
invariant under a certain operation. A system could be represented by a La- 
grangian, a state function, or a differential equation. In our previous sections 
we have discussed examples of continuous groups and their generators. The 
theory of continuous groups was invented by Lie when he was studying sym- 
metries of differential equations. He also introduced a method for integrating 
differential equations once the symmetries are known. In what follows we dis- 
cuss extension (prolongation) of generators of continuous groups so that they 
could be applied to differential equations. 

278 
CONTINUOUS GROUPS AND REPRESENTATIONS 
11.16.1 
In two dimensions general point transformations can be defined as 
One-Parameter Point Groups and Their Generators 
- 
z = 2(z, y) 
B = Sb, Y), 
(11.392) 
where x and y are two variables that are not necessarily the Cartesian coordi- 
nates. All we require is that this transformation form a continuous group so 
that finite transformations can be generated continuously from the identity 
element. We assume that these transformations depend on at least on one 
parameter, E ;  hence we write 
- 
z = z(z, y; E )  
(11.393) 
- 
Y = %(x, Y; 
E). 
An example is the orthogonal transformation 
- 
z = zcasE+ysinE 
y = -zsinE + ~ C O S E ,  
- 
(11.394) 
which corresponds to counterclockwise rotations about the z-axis by the amount 
E .  If we expand Equation (11.394) about E = 0 we get 
- 
z(z7 y; E )  = z + E(Y(z,y) +. . . 
3 . 7  
Y; 
E )  = Y + E P k 7  Y) + . . . 7 
(11.395) 
where 
and 
If we define the operator 
we can write Equation (11.395) as 
- 
z(z, y; &) = 2 + EXZ + . . . 
(11.396) 
(1 1.397) 
(11.398) 
(11.399) 

CONTINUOUS GROUPS AND SYMMETRIES 
279 
Operator X is called the generator of the infinitesimal point transformation. 
For infinitesimal rotations about the z-axis this agrees with our previous result 
[Eq. (11.34)] as 
a
a
 
x, = y--x-. 
ax 
ay 
Similarly, the generator for the point transformation 
- 
x = x + &  
- 
Y = Y, 
which corresponds to translation along the x-axis, is 
( 1 1.400) 
(1 1.401) 
(11.402) 
11.16.2 
We have given the generators in terms of the (x,y) 
variables [Eq. (11.398)]. 
However, we would also like to know how they look in another set of variables, 
Say 
Transformation of Generators and Normal Forms 
u = u(x, Y) 
2, = u(x, 
y). 
For this we first generalize [Eq. (11.398)] to n variables as 
a 
dX' 
x = a;($)- 
2 = 1,2, "', 72. 
(11.403) 
( 1 1.404) 
Note that we used the Einstein summation convention for the index Z. Defining 
new variables by 
Ti = *(.")' 
(1 1.405) 
we obtain 
(11.406) 
When substituted in Equation (11.404) this gives the generator in terms of 
the new variables as 
x =  az- - 
[ 
L3 
(1 1.407) 
(11.408) 

280 
CONTINUOUS GROUPS AND REPRESENTATIONS 
where 
. 
- 
a3 = %a'. 
( 1 1.409) 
Note that if we operate on xj with X we get 
Similarly, 
(11.410) 
. 
a E j  
LEE' 
X? =
~
-
 
= $  
(11.411) 
In other words, the coefficients in the definition of the generator can be found 
by simply operating on the coordinates with the generator; hence we can write 
x = (Xxi), d = (X?)--. d 
32% 
rn 
(11.412) 
We now consider the generator for rotations about the z-axis [Eq. (11.400)] 
in plane polar coordinates: 
2 112 
4 = arctan(y/z). 
P = ( x 2 + 9 )  , 
Applying Equation (11.412) we obtain the generator as 
d 
a 
x = (Xp)- + (X4)- 
dr 
84 
( 1 1.4 13) 
( 11.4 14) 
(11.415) 
d 
d 
= [O] - + [-11 - 
dr 
a 
d 
_ _  
- 
- 
84. 
Naturally, the plane polar coordinates in two dimensions or in general the 
spherical polar coordinates are the natural coordinates to use in rotation prob- 
lems. This brings out the obvious question: Is it always possible to find a new 
definition of variables so that the generator of the oneparameter group of 
transformations looks like 
( 11.4 16) 
We will not go into the proof, but the answer to this question is yes, where 
the above form of the generator is called the normal form. 

CONTINUOUS GROUPS AND SYMMETRIES 
281 
11.16.3 
Transformations can also depend on multiple parameters. 
transformations with m parameters we write 
The Case of Multiple Parameters 
For a group of 
- 
xi=Zi(&;~,), i , j =  1,2 ,..., n a n d p =  1,2,-..,m. 
( 11.417) 
We now associate a generator for each parameter as 
‘ a  
X, = ah(x3)- dxi ’ 
i = 1,2, ..., n, 
( 1 1.41 8) 
where 
The generator of a general transformation can now be given as a linear com- 
bination of the individual generators as 
(1 1.4 19) 
We have seen examples of this in R(3) and SU(2). In fact X, forms the Lie 
algebra of the m-dimensional group of transformations. 
X = c,Xpl p = 1,2, ..., m. 
11.16.4 
We have already seen that the action of the generators of the rotation group 
R(3) on a function f(r) are given as 
Action of Generators on Functions 
where the generators are given as 
- 
d 
d 
x2 = - 23- 
-XI-) 
( 8x1 
3x3 
(11.420) 
(1 1.421) 
(1 1.422) 
The minus sign in Equation (11.421) means that the physical system is rotated 
clockwise by 0 about an axis pointing in the fi direction. Now the change in 
f(r) is given as 
sf(r) = - (X .;i) 
f(r)se. 
(11.423) 

282 
CONTINUOUS GROUPS AND REPRESENTATIONS 
If a system represented by f ( r )  is symmetric under the rotation generated by 
(x. 
6) , that is, it does not change, then we have 
(X-6) 
f(r) = 0. 
(11.424) 
For rotations about the z-axis, in spherical polar coordinates this means 
(11.425) 
that is, f(r) does not depend on 4 explicitly. 
For a general transformation we can define two vectors 
(11.426) 
where E @  are small. so that 
(11.427) 
where 
is a unit vector in the direction of e and the generators are defined as in 
Equation (11.418). 
11.16.5 
Infinitesimal Transformation of Derivatives: Extension of 
Generators 
To find the effect of infinitesimal point transformations on a differential equa- 
tion 
D(z, y',"', ..., 9'"') = 0, 
(11.429) 
we first need to find how the derivatives y(n) transform. For the point trans- 
formation 
(11.430) 

CONTINUOUS GROUPS AND SYMMETRIES 
283 
we can write 
(1 1.431) 
Other derivatives can also be written as 
-// y = - 
at = gtf(x7 
y, y!, yf/; €) 
& 
(11.432) 
What we really need is the generators of the following infinitesimal transfor- 
mations: 
where 
and 
( 11.434) 
(11.435) 
For reasons to become clear shortly we have used X for all the generators in 
Equation (11.433). Also note that ,dn] 
is not the nth derivative of p. 
We now define the extension (prolongation) of the generator 
(11.436) 
a 
d 
x = 4 x 7  Y ) z  + P(x7 Y)- aY 
as 
( 1  1.437) 

284 
CONTINUOUS GROUPS AND REPRESENTATIONS 
To find the coefficients /3rnl we can use Equation (11.433) 
in F4uation (11.431) 
and then Equation (11.432) to obtain 
dP 
Ida 
= y' +€(- - y -) + . 
dx 
dx 
We can now write P['] as 
Similarly, we write 
(11.438) 
.. 
and obtain 
This can also be written as 
which for the first two terms gives us 
=-+y'(-&-z)-y 
ap 
ap 
aa 
I2 - 
aa 
dX 
aY 
and 
(1 1.439) 
(1 1.440) 
(11.441) 
(11.442) 
(11.443) 
(11.444) 

CONTINUOUS GROUPS AND SYMMETRIES 
285 
For the infinitesimal rotations about the z-axis the extended generator can 
now be written as 
/2 a 
/ //a 
(11.445) 
a
a
 
3,’’ 
x = y- 
-z- 
- (1 + y )? - 3y y 
ax 
Py 
aY 
a 
- (3y”Z + 4y’y”’)- 
+ . . . 
ay,” 
For the extension of the generator for translations along the z-axis we 
obtain 
(11.446) 
11.16.6 
Symmetries of Differential Equations 
We are now ready to discuss symmetry of differential equations under point 
transformations, which depend on at least one parameter. To avoid some 
singular cases (Stephani) we confine our discussion to differential equations, 
D(z,y’, y”, ..., 9‘”)) = 0, 
(11.447) 
which can be solved for the highest derivative as 
- 
D = y(n) - D(x, y’, y”, ..., y(np ’)) = 0. 
(1 1.448) 
For example, the differential equation 
D = 2y” + yt2 + y = 0 
(11.449) 
satisfies this property, whereas 
D = (y” - y’ + z)’ = 0 
(1 1.450) 
does not. For the point transformation 
(11.451) 
we say the differential equation is symmetric if the solutions, y(z), of Equation 
(1 1.448) are mapped into other solutions, B = g(Z), 
of 
- 
D = g(n) - D(-,-/ 
2 Y , Y  
--)I ,.-*, g(n-1)) = 0. 
(11.452) 
Expanding D with respect to E about E = 0 we write 
D(Z”’,S’’, ...,y(”); 
E) = 

286 
CONTINUOUS GROUPS AND REPRESEN JATIONS 
For infinitesimal transformations we keep only the linear terms in E: 
In the presence of symmetry Equation (11.452) must be true for all E ;  thus the 
left-hand side of Equation (11.454) is zero, and we obtain a formal expression 
for symmetry as 
XD = 0. 
(11.455) 
Note that the symmetry of a differential equation is independent of the choice 
of variables used. Using an arbitrary point transformation only changes the 
form of the generator. We now summarize these results in terms of a theorem 
(for special cases and alternate definitions of symmetry we refer the reader to 
Stephani) 
Theorem: An ordinary differential equation, which could be written as 
D = g(") - G(z,$,$', ...,g("-')) 1 
0, 
(1 1.456) 
admits a group of symmetries with the generator X if and only if 
X D r O  
(1 1.457) 
holds. 
Note that we have written XD I 0 instead of X D  = 0 to emphasize the 
fact that Equation (11.457) must hold for every solution y(z) of D = 0. For 
example, the differential equation 
D = 9" + UOY' + boy = 0 
(11.458) 
admits the symmetry transformation - 
x = o  
( 11.459) 
since D does not change when we multiply y (also y' and y") with a constant 
factor. Using Fquation (11.437) the generator of this transformation can be 
written as 
(11.460) 

CONTINUOUS GROUPS AND SYMMETRIES 
287 
which gives 
(1 1.461) 
(1 1.462) 
d 
(V” + aOY‘ + boy) 
= (y” + soy/ + boy). 
Considered with 
D=O 
(1 1.463) 
this gives 
X D  = 0. 
(1 1.464) 
We stated that one can always find a new variable, say 2, where a generator 
appears in its normal form as 
(1 1.465) 
Hence if X generates a symmetry of a given differential equation, which can 
be solved for its highest derivative as 
then we can write 
d D  
dZ 
XD=-=O, 
( 11.467) 
which means that in normal coordinates D does not depend explicitly on the 
independent variable E. 
Note that restricting our discussion to differential equations that could be 
solved for the highest derivative guards us from singular cases where all the 
first derivatives of D are zero. For example, for the differential equation 
D = (y” - y’ + x)’ = 0, 
all the first-order derivatives are zero for D = 0 
dD 
,,,, 
d D  
- 
= -2(y” - y/ + 2) = 0, 
dY 
-= 
2(Y” - y/ + 2 )  = 0, 
- 
= 0, 
f3D 
aY 
d D  
- _  
az - 2(y” - y/ + z) = 0. 

288 
CONTINUOUS GROUPS AND REPRESENTATlONS 
Thus XD = 0 holds for any linear operator, and in normal coordinates even 
= 0, we can no longer say that D does not depend on 5 explicitly. 
Problems 
11.1 
Consider the linear group in two dimensions 
x' = ax + by 
y' = cx +dy. 
Show that the four infinitesimal generators are given as 
and find their commutators. 
11.2 Show that 
det A = det eL = eTrL , 
where L is an n x n matrix. Use the fact that the determinant and the 
trace of a matrix are invariant under similarity transformations. Then make 
a similarity transformation that puts L into diagonal form. 
11.3 Verify the transformation matrix 
- 
- 
where 
V1 
v2 
u2 
P1= -, 
C 0 2  = - 
c - ,  p.2 = -. 
C 
11.4 Show that the generators Vi [Eq. (11.59)] can also be obtained from 
vz = ALOO,,(Pi = 0). 
11.5 Given the charge distribution 
p( F )  = r2e-' sin2 6, 

PROBLEMS 
289 
make a multipole expansion of the potential and evaluate all the nonvanishing 
multipole moments. What is the potential for large distances? 
11.6 
Show that di,m(P) satisfies the differential equation 
m2 + mI2 - 2mm‘cosp 
I 
{ & +cotp- ap 
a + [ 1(1+ 1) - ( 
sin2p 
)] } dmfm (P) = 0- 
11.7 
Using the substitution 
in Problem 11.6 show that the second canonical form of the differential equa- 
tion for d&,m(,B) (Chapter 9) is given as 
a2Y(A, m’, m, P) + 
w2 
11.8 Using the result of Problem 11.7, solve the differential equation for 
d i m ,  (P) by the factorization method. 
a) Considering m as a parameter, find the normalized stepup and s t e p  
down operators O+ (m + 1) and 0- (m), which change the index m while 
keeping the index m’ fixed. 
b)Considering m‘ as a parameter, find the normalized stepup and step 
down operators Oi(m’ + 1) and OL(m’), which change the index m‘ while 
keeping the index m fixed. Show that Irnl 5 1 and lm’l 5 1. 
c) Find the normalized functions with m = m’ = 2. 
d) For 1 = 2, construct the full matrix &mtm(,B). 
e) By transforming the differential equation for dk,, (p) into an appropriate 
form, find the step-up and stepdown operators that shift the index 1 for fixed 
m and m’, giving the normalized functions d i m ,  (p) . 
That is, express this as a combination of dkm,(p) with 1’ = 1 f 1, ... . 
discussed in Chapter 9.) 
11.9 
Show that 
f)Using the result of Problem 11.8.5, derivea recursion relation for (cosp) dA,,(P). 
(Note. This is a difficult problem and requires knowledge of the material 
a) 
and 

290 
CONTINUOUS GROUPS AND REPRESEN TATIONS 
Hint. Use the invariant 
11.10 For I = 2 construct the matrices 
for L = 0,1,2,3,4, .__ 
and show that the matrices with L 2 5 can be expressed 
as linear combinations of these. Use this result to check the result of Problem 
11.8.4. 
11.11 We have studied spherical harmonics x,(6,4), which are single- 
valued functions of (0, #) for 1 = 0,1,2, ... . However, the factorization method 
also gave us a second family of solutions corresponding to the eigenvalues 
x = J ( J  + 1) 
with 
M = J, ( J  - l), ..., 0, ..., -(J - I), -J, 
where J = 0,1/2,3/2, ... . 
For J = 1/2, find the 2 x 2 matrix of the y component of the angular 
momentum operator, that is, the generalization of our [LY],,#. Show that 
the matrices for Li, L;, Li, ... are simply related to the 2 x 2 unit matrix and 
the matrix [LYIMM,. 
Calculate the &function for J = 1/2: 
dJ='/2 (P) 
M M '  
with M and M' taking values +l/2 or -1/2. 
11.12 Using the following definition of Hermitian operators: 
J IIr;Lc92dx = 
(LWI)*c92dx, 
J 

PROBLEMS 
291 
show that 
11.13 Convince yourself that the relations 
e -iOL,, = e-iaL,e-iBLueiaL, 
and 
e-iTLz, = ,-iBLu, 
e-i7Lz,eiPL,, 
9 
used in the derivation of the rotation matrix in terms of the original set of 
axes are true. 
11.14 Show that the Di,,,(R) matrices satisfy the relation 
c 
[DAt,,,(R)] [DA,,,(K 1 )] = fimJm. 
m” 
11.15 Show that the extended generator of 
a
a
 
x = 2- 
+y- 
ax 
ay 
is given as 
11.16 Find the extension of 
a 
2
3
 
X = x y - + y  - 
ax 
ay 
up to third order. 
11.17 Express the generator 
in terms of 
21 = y/x 
w = xy. 

292 
CONTINUOUS GROUPS AND REPRESEN TATlONS 
11.18 
Using induction, show that 
can be written as 
11.19 Does the following transformation form a group? 
- 
{ 
x = x  
} >  
g = uy + u2y2 
where a is a constant. 

12 
COMPLEX 
VARIABLES and 
FUNCTIONS 
Even though the complex numbers do not exist directly in nature, they are 
very useful in physics and engineering applications: 
1. In the theory of complex functions there are pairs of functions called 
conjugate harmonic functions, which are very useful in finding solutions 
of Laplace equation in two dimensions. 
2. The method of analytic continuation is very useful in finding solutions 
of differential equations and evaluating some definite integrals. 
3. Infinite series, infinite products, asymptotic solutions, and stability cal- 
culations are other areas, in which complex techniques are very useful. 
4. Even though complex techniques are very helpful in certain problems 
of physics and engineering, which are essentially problems defined in 
the real domain, complex numbers in quantum mechanics appear as an 
essential part of the physical theory. 
12.1 COMPLEX ALGEBRA 
A complex number is defined by giving a pair of real numbers 
(12.1) 
293 
which could also be written as 

294 
COMPLEX VARIABLES AND FUNCT/ONS 
A z-plane 
Z 
w 
X 
Fig. 12.1 A point in the complex z-plane 
u f i b ,  i=a. 
(12.2) 
A convenient way to represent a complex number is to use the concept of the 
complex z-plane (Fig. 12.1), where a point is shown as 
z =  (z,y)=x+iy. 
Using plane polar coordinates we can also write a complex number as (Fig. 
12.1) 
x = TCOSO, 
y = rsin0 
and 
z=r(cosO+isinO) or z=rei*. 
(12.3) 
The modulus of z is defined as 
T = IzI = JFQ, 
(12.4) 
and 0 is the argument of a complex number. Algebraic manipulations with 
complex numbers can be done according to the following rules: 
i) 
21 + 22 = ( 2 1  + iy,) + (22 + iy2), 
= (21 + z2) + 2 (y1 + y2). 
(12.5) 
(12.6) 

COMPLEX FUNCTIONS 
295 
ii) 
cz = c (z + iy) 
= cx + icy, 
where c is a complex number. 
iii) 
iv) 
_ -  
z1 
(a +iYl) 
22 
(22 + i Y Z ) ’  
- 
- (21 + iYl) (z2 - iY2) 
( 2 2  + iyz) ( 2 2  - iyz) 
- [(2122 + YlY2) + i (YlQ - Z1YZ)l 
(4 + Y,”) 
z* = z - iy. 
JzI = zz* = x2 +y2. 
- 
- 
The conjugate of a complex number is defined as 
Thus the modulus of a complex number is given as 
De Moivre’s formula 
einO - 
- (cos6+isin6)n =cosn6+isinnB 
and the relations 
1211 - 14 5 121 + z21 I 
IZll + 1z21 7 
I21z21 = 1211 1221 7 
arg (21 2 2 )  = arg z1 + arg 22 
are also very useful in calculation with complex numbers. 
12.2 COMPLEX FUNCTIONS 
We can define a complex function (Fig. 12.2) as 
w = f (z) = u (2, y) + iv (z, y) . 
(12.7) 
(12.8) 
(12.9) 
(12.10) 
(12.11) 
(12.12) 
(12.13) 
(12.14) 
(12.15) 
(12.16) 
(12.17) 

296 
COMPLEX VARIABLES AND FUNCTIONS 
Fig. 12.2 w-plane 
As an example for complex functions we can give polynomials like 
f ( z )  = 22 = (x+zy)2 = (x2 -92) +2(2xy), 
f ( ~ )  
= 3z4 + 2z3 + 2i~. 
(12.18) 
(12.19) 
Trigonometric functions and some other well-known functions can also be 
defined in the complex plane as 
sinz, cosz, lnz, sinhz. 
(12.20) 
However, one must be very careful with multivaluedness. 
12.3 COMPLEX DERIVATIVES AND ANALYTIC FUNCTIONS 
As in real analysis we can define the derivative of a complex function as 
(12.21) 
nu 
.nu 
= lim 
- + a -  
At-0 [a, a,] 
However, for this derivative to be meaningful it must be independent of the 
direction in which the limit A z  + 0 is taken. If we first approach z parallel 
to the real axis, that is, when 
a z  = ax, 
(12.22) 
we find the derivative as 
dJ 
d u  
.dv 
- + 2-. 
dz 
dx 
dx 
_ -  
- 
(12.23) 

COMPLEX DERIVATIVES AND ANALYTIC FUNCTIONS 
297 
On the other hand, if we approach z parallel to the imaginary axis, that is, 
when 
Az = iAy, 
(12.24) 
the derivative becomes 
(12.25) 
For the derivative to exist these two expressions must agree; thus we obtain 
the conditions for the derivative to exist at some point z as 
and 
(12.26) 
(12.27) 
These conditions are called the Cauchy-Riemann conditions, and they are 
necessary and sufficient for the derivative of f ( z )  to exist. 
12.3.1 Analytic Functions 
If the derivative of a function, f ( z )  , exists not only at 
but also at every 
other point in some neighborhood of zo, then we say that f (2) is analytic at 
20. 
Example 12.1. Analytic functions: The function 
f ( 2 )  = z2 + 523, 
(12.28) 
like all other polynomials, is analytic in the entire z-plane. On the other 
hand, even though the function 
f ( z )  = [z21 
(12.29) 
satisfies the Cauchy-Riemann conditions at z = 0, it is not analytic at 
any other point in the z-plane. 
If a function is analytic in the entire z-plane it is called an entire function. 
All polynomials are entire functions. If a function is analytic at every point in 
the neighborhood of a except at zo, we call 
an isolated singular point. 
Example 12.2. Analytic functions: If we take the derivative of 
1 
f (4 = ; 
(12.30) 

298 
COMPLEX VARIABLES AND FUNCTIONS 
we find 
(12.31) 
1 
22 ' 
f ' ( 2 )  = -- 
which means that z = 0 is an isolated singular point of this function. 
At all other points, this function is analytic. 
Theorem: Iff (z) is analytic in some domain of the z-plane, then the partial 
derivatives of all orders of u 
(2, y) and u (2, y) exist. The u (x, 
y) and 
v (2, y) functions of such a function satisfy the Laplace equations 
and 
q , v  (2, y) = 0. 
(12.33) 
Proof. We use the first Cauchy-Riemann condition [Eq. (12.26)] and differ- 
entiate with respect to x to get 
(12.34) 
(12.35) 
Similarly, we write the second condition [Eq. (12.27)] and differentiate 
with respect t o y  to get 
av 
du 
_ -  _- 
- 
a x  
ay 
a2U 
ay2 
ayax- 
8% 
- 
- 
- -- 
Adding Equations (12.35) and (12.37) gives us 
3% 
a2u 
a2u 
3% 
axay = 0. 
dz2 + dy2 = axay 
(12.36) 
(12.37) 
(12.38) 
One can show Equation (12.33) in exactly the same way. The func- 
tions u (x, y) and the v (x, 
y) are called harmonic functions, whereas 
the pair of functions (u 
(x, 
y) , v (x, 
y)) are called conjugate harmonic 
functions. 

COMPLEX DERIVATIVES AND ANALYTIC FUNCTIONS 
2% 
12.3 - 2 
Harmonic Functions 
Harmonic functions have very useful properties in applications: 
1. The two families of curves defined as u = ci and v = di (ci and di are 
real numbers) are orthogonal to each other. 
Proof. 
auav 
auav 
axax 
ayay 
Vu-dv=-- + --, 
vu. VW = 0, 
where we have used the Cauchy-Riemann conditions. 
2. If we differentiate an analytic function ui = w ( z )  we get 
2 = (2 + 2%) 
av -& 
dx + ($ + 2;) 
(2) 
(-22), 
& + idy 
dw 
au 
.au 
dz 
ax 
ay 
- 2--. 
- 
- -  
- 
The modulus of this gives us 
(12.39) 
(12.40) 
(12.41) 
(12.42) 
(12.43) 
(12.44) 
(12.45) 
Harmonic functions are very useful in electrostatics. If we take u (x, 
y) 
as the potential energy, the electric field will be given by 
3 
= -3u. 
(12.46) 
Thus the modulus we have found in Equation (12.45) gives the magni- 
tude of the electric field as 
(12.47) 

300 
COMPLEX VARIABLES AND FUNCTIONS 
Fig. 12.3 It is not interesting to look at real functions as mappings 
3. If Ik (u,v) satisfies the Laplace equation in the w-plane, 
d%(u, v) a2qu, v) 
aU2 
+ 
av2 
= 0, 
(12.48) 
where u and v are conjugate harmonic functions, then Ik (x, y) will sat- 
isfy the Laplace equation in the z-plane as 
(12.49) 
12.4 
MAPPINGS 
A real function 
Y = f (x) 
7 
(12.50) 
which defines a curve in the xy-plane, can be interpreted as an operator that 
maps a point on the x-axis to a point on the y-axis (Fig. 12.3), which is not 
very interesting. However, in the complex plane a function, 
(12.51) 
maps a point (x, y) in the z-plane to another point (u, 
v) in the w-plane, 
which implies that curves and domains in the z-plane are mapped to other 
curves and domains in the w-plane. This has rather interesting consequences 
in applications. 
Example 12.3. Translation: Let us consider the function 
w = z + z o .  
(12.52) 

MAPPINGS 
301 
Since this means 
u = z + z o  
and 
2) = y +yo, 
(12.53) 
(12.54) 
a point (z, y) in the z-plane is mapped int,o the translated point (Z + 20, 9 + yo) 
in the w-plane. 
Example 12.4. Rotation: Let us consider the function 
w = zq). 
Using 
we write w in plane polar coordinates as 
= rToei(@+Qo) 
In the w-plane this means 
p = TTO 
q!)=e+Bo. 
Two things have changed: 
i. Modulus T has increased or decreased by a factor TO. 
(12.55) 
(12.56) 
(12.57) 
(12.58) 
(12.59) 
ii. 6 has changed by 60. 
If we take a = i, this mapping (function) corresponds to a pure rotation 
by 4. 
Example 12.5. Inversion: The function 
1 
w ( 2 )  = - 
2 
can be written as 
(12.60) 
(12.61) 
(12.62) 

302 
COMPLEX VARIABLES AND FUNCTIONS 
Fig. 12.4 Inversion maps circles to circles 
This gives 
1 
p =  - 
r 
d =  -e, 
(12.63) 
(12.64) 
which means that a point inside the unit circle in the z-plane is mapped 
to a point outside the unit circle, plus a reflection about the u-axis in 
the w-plane (Fig. 12.4). 
Example 12.6. Inversion function: Let us now see how inversion, that 
is, 
1 
w(z) = - 
2 
maps curves in the z-plane to the w-plane. We first write 
w = u + i v  
1 
- 
- 
x + iy 
1 
2-iy 
x + iy'x - iy 
- 
X 
Y 
-- 
- 
- 
- 
( 5 9  + y2) - Z(Z2 + y2)' 
(12.65) 
(12.66) 
(12.67) 
(12.68) 
(12.69) 

MAPPINGS 
303 
This gives us the transformation (x,y) -+ 
( U , V )  : 
X 
u = -- 
x 2  + y 2  
-?I 
2, = J- 
2 2  + y2 
and its inverse as 
(12.70) 
(12.71) 
(12.72) 
(12.73) 
We are now ready to see how a circle in the z-plane, 
z2 + y 2  = r2, 
(12.74) 
is mapped to the w-plane by inversion. Using Equations (12.72) and 
(12.73) we see that this circle is mapped to 
U2 
V 2  
= r2, 
( u 2  + v 2 ) 2  + ( u 2  + .2)2 
(12.75) 
(12.76) 
= P2, 
(12.77) 
1 
r 2  
212 + 212 = - 
which is another circle with the radius l/r. 
Next, let us consider a straight line in the z-plane as 
y = c1. 
(12.78) 
Using Equation (12.73) this becomes 
or 
(12.79) 
(12.80) 
1 
2Cl 
This is nothing but a circle with the radius - 
and with its center 
; thus the inversion maps straight lines in the 
z-plane to circles in the w-plane (Fig. 12.5). 

304 
COMPLEX VARIABLES AND FUNCTIONS 
fig. 12.5 Inversion maps straight lines to circles 
All the mappings we have discussed so for are one-to-one mappings, that 
is, a single point in the z-plane is mapped to a single point in the w-plane. 
Example 12.7. Two-to-one mapping: We now consider the function 
w = z  2 
(12.81) 
and write it in plane polar coordinates as 
w = peie. 
Using 
z = reiB, 
p and 4 become 
p = r2, 
(12.82) 
(12.83) 
(12.84) 
4 = 28. 
(12.85) 
The factor of two in front of the 0 is crucial. This means that the first 
quarter in the z-plane, 0 5 8 5 $, is mapped to the upper half of the 
w-plane, 0 5 4 < T .  On the other hand, the upper half of the z-plane, 
0 5 8 < T ,  is mapped to the entire w-plane, 0 5 4 < 27r. In other words, 

MAPPINGS 
305 
branchpoint 
I 
Fig. 12.6 Cut line ends at a branch point 
the lower half of the z-plane is mapped to the already covered (used) 
entire w-plane. Hence, in order to cover the z-plane once we have to 
cover the w-plane twice. This is called a two-to-one mapping. Two 
different points in the z-plane, 
zo 
(12.86) 
and 
are mapped to the same point in the w-plane as 
w = 20. 
2 
(12.88) 
We now consider 
w = ez. 
(12.89) 
Writing 
where 
and 
p = ex 
(12.91) 
4 = y ,  
(12.92) 
we see that in the z-plane the 0 5 y < 2a band is mapped to the entire 
w-plane; thus in the z-plane all the other parallel bands given as 
2 + i (y + 2 n ~ ) ,  
n integer, 
(12.93) 

306 
COMPLEX VARIABLES AND FUNCTIONS 
are mapped to the already covered w-plane. In this case we say that we have 
a many-to-one mapping. 
Let us now consider the function 
w = 6. 
(12.94) 
In plane polar coordinates we can write 
and 
2 4 =  e. 
In this case the point 
r = r0, 6 = 0, 
(12.96) 
(12.97) 
is mapped to 
while the point 
r = rot 0 = 27r, 
(12.98) 
is mapped to 
w = fie'" 
= -6 
(12.99) 
in the w-plane. However the coordinates (12.97) and (12.98) represent the 
same point in the z-plane. In other words, a single point in the z-plane is 
mapped to two different points, except at the origin, in the w-plane. This is 
called a one-to-two mapping. 
To define a square root as a single-valued function so that for a given value 
of z a single value of w results, all we have to do is to cut out the t9 = 27~ 
line from the z-plane. This line is called the cut line or the branch cut, 
and the point z = 0, where this line ends, is called the branch point (Fig. 
12.6). 
What is important here is to find a region in the z-plane where our 
function is single valued and then extend this region over the entire z-plane 
without our function becoming multivalued. As seen from Figure 12.7a and 
Figure 12.7b the problem is at the origin: 
z = 0. 
(12.100) 
For any region that does not include the origin our function will be single 
valued. However, for any region that includes the origin, where 8 changes 
between [0,27r] we will run into the multivaluedness problem. In order to 

MAPPINGS 
307 
t' 
t" 
fig. 12.7 For every region R that does not include the origin 20 = 2
'
'
'
 
is single valued 
extend the region in which our function is single valued we start with a region 
R, where our function is single valued, and then extend it without including 
the origin so that we cover a maximum of the z-plane (Fig. 12.7b, c, d, e, 
and f ). The only way to do this is to exclude the points on a curve (usually 
taken as a straight line), that starts from the origin and then extends all the 
way to infinity. 

308 
COMPLEX VARIABLES AND FUNCTIONS 
As seen from Figure 12.8, for the square root, f(z) = &, for any path that 
does not cross the cut line our function is single valued and the value it takes 
is called the branch I value: 
I. branch 
wI(z) = fiee/', 
o 5 e < 2T. 
For the range 2~ 5 8 < 47r, since the cut line is crossed once, our function 
will take the branch I1 value given as 
11. branch 
w2(z) = 
2T 5 8 < 4T. 
Square root function has two branch values. In cases where 8 increases contin- 
uously, as in rotation problems, we switch from one branch value to another 
each time we cross over the cut line. This situation can be conveniently shown 
by the Riemann sheets (Fig. 12.9). 
Riemann sheets for this function are two parallel sheets sewn together 
along the cut line. As long as we remain in one of the sheets, our function is 
single valued and takes only one of the branch values. Whenever we cross the 
cut line we find ourselves on the other sheet and the function switches to the 
other branch value. 
Example 12.8. w(z)=Znz function: In the complex plane the In function 
is defined as 
w ( z ) = l n z = l n r + i 6 .  
(12.101) 
It has infinitely many branches; thus infinitely many Riemann sheets as 
branch 0 
branch 1 
branch 2 
wo ( z )  = In r + 26 
w1(z) = l n r  + z (8 + 1 . 2 ~ )  
w2 ( z )  = l n r  + i (0 + 2 . 2 ~ )  , 
(12.102) 
branch n w, ( 2 )  = l n r  + z (8 + n . 2 ~ )  
where 0 5 6 < 2n. 
Example 12.9. w
(
z
)
=
~
~
 
function: To investigate the branches of 
the function 
w ( 2 )  = JE, 
(12.103) 
we define 
(12.104) 

MAPPINGS 
31)9 
t Z  
fig. 12.8 
value to another 
Each time we cross the cut line w = zl/' function changes from one branch 

310 
COMPLEX VARIABLES AND FUNCTIONS 
I e' L 
II. sheet 
Fig. 12.9 Riemann sheets for the 20 = z'I2 function 

MAPPlNGS 
311 
. .  
E
F
 
0
.
 
G
H
 
~ i g .  
12.10 Cut lines for. &F-i 
fig. 12.11 A different Choice for the cut lines of 
and write 
W ( Z )  = pei@ 
(12.105) 
=-- 
(12.106) 
== f i e i ( @ 1 + @ 2 ) / 2 .  
(12.107) 
This function has two branch points located at x = f l  and x = -1. 
We place the cut lines along the real axis and to the right of the branch 
points. This choice gives the ranges of Q, and 62 as 
o 5 e, < 2x, 
(12.108) 
0 5 62 < 2 ~ .  
(12.109) 
We now investigate the limits of the points A, B, C, D, F, G, and H in 
the z-plane as they approach the real axis and the corresponding points 
in the w-plane (Fig. 12.10): 

312 
COMPLEX VARIABLES AND FUNCTIONS 
I 
A 
I 0 I 0 I 0 
I single valued I 
I 
H I 271. I 271. I 
27r 
I single valued I 
I B 
I 7r I 0 I n-/2 I double valued I 
I G 
I 7r I 27r I 3 ~ / 2  I double valued 1 
I D I 7r I 
n- I 
7r 
[ single valued I 
I E I n- I n- I 
7r 
I single valued I 
(12.110) 
Points A and H, which approach the same point in the z-plane, also go 
to the same point in the w-plane. In other words, where the two cut 
lines overlap our function is single valued. For pairs (B, G) and (C, F) 
even though the corresponding points approach the same point in the 
z-plane, they are mapped to different points in the w-plane. For points 
D and E the function is again single valued. For this case the cut lines 
are now shown as in Figure 12.10. The first and second branch values 
for this function are given as 
Riemann sheets for this function will be two parallel sheets sewn together 
in the middle between points -1 and fl. 
For this function another choice for the cut lines is given as in Figure 
12.11. where 
0 5 $1 < 27r, 
(12.113) 
-n- 5 $2 < 7r. 
(12.114) 

MAPPINGS 
313 
Fig. 12.12 Conformal mapping 
12.4.1 
Conformal Mappings 
To see an interesting property of analytic functions we differentiate 
w = f 
( 12.115) 
at zo, where the modulus and the arguments. of the derivative are given as 
I $ I 
and a, respectively. We now use polar coordinates to write the modulus 
20 
lim 
At-0 
and the argument (Fig. 12.12) as 
a = lim arg[Azu] - lim arg[Az] 
Az-0 
Ar-0 
(12.116) 
( 12.1 17) 
(12.118) 
(12.119) 
Since this function, f ( z )  , maps a curve c, in the z-plane into another curve 
c, in the w-plane, from the arguments [&. 
(12.119)] it is seen that if the 
slope of c, at 
is 00, then the slope of cw at wo is a+&. For a pair of curves 
intersecting at a 
the angle between their tangents in the w- and z-planes will 
be equal, that is, 
4'2 - 41 = (02 + a )  - (0, + a ) ,  
( 12.120) 
= e2 -el. 
(12.121) 
Hence analytic functions preserve angles between the curves they map (Fig. 
12.12). For this reason they are also called conformal mappings or transfor- 
mations. 

314 
COMPLEX VARIABLES AND FUNCTIONS 
fig. 12.13 Two plates with hyperbolic cross sections 
12.4.2 
Electrostatics and Conformal Mappings 
Conformal mappings are very useful in electrostatic and laminar (irrotational) 
flow problems, where the Laplace equation must be solved. Even though the 
method is restricted to cases with one translational symmetry, it allows one 
to solve analytically some complex boundary value problems. 
Example 12.10. Conformal mappings and electrostatics: Let us con- 
sider two conductors held at potentials Vi and V2 with hyperbolic cross 
sections 
x2 - 9’ = c1 and x2 - y2 = c2. 
(12.122) 
We want to find the equipotentials and the electric field lines. In the 
complex z-plane the problem can be shown as in Figure 12.13. We use 
the conformal mapping 
(12.123) 
=x2-$+2(2Xy) 
( 12.124) 
2 
W = Z  
to map these hyperbolae to the straight lines 
u = c1 and u = c2 
(12.125) 
in the w-plane (Fig. 12.14). The problem is now reduced to finding 
the equipotentials and the electric field lines between two infinitely long 

MAPPINGS 
315 
fig. 12.14 Equipotentials and electric field lines in the w-plane 
parallel plates held at potentials Vl and .V2, where the electric field lines 
are given by the family of lines 
2, = c3 
(12.126) 
and the equipotentials are given by the lines perpendicular to these as 
u = ci. 
(12.127) 
Because the problem is in the z-plane, we make the inverse transforma- 
tion to obtain the electric field lines as 
(v =) 2zy = cj 
(12.128) 
and the equipotentials as 
(u =) z2 - y2 = cz. 
(12.129) 
In three dimensions, to find the equipotential surfaces these curves must 
be extended along the direction of the normal to the plane of the paper. 
Example 12.11. Electrostatics and conformal mappings: We now find 
the equipotentials and the electric field lines inside two conductors with 
semicircular cross sections separated by an insulator and held at poten- 
tials +V, and -V& respectively (Fig. 12.15). The equation of a circle 

316 
COMPLEX VARIABLES AND FUNCTIONS 
+ z-plane 
Fig. 12.15 Two conductors with semicircular cross sections 
in the z-plane is given as 
22+y2= 1. 
We use the conformal mapping 
w (2) = In (-) 
l + z  
1 - 2  ' 
(12.130) 
(12.131) 
to map these semicircles into straight lines in the w-plane (Fig. 12.16). 
Using Equation (12.131) we write 
(12.132) 
l + z + i y  
1-2-zy 
u + iu = In 
1 
1 - 2 2  - y2 + 2iy 
1 -22+22+y2 
= I n [  
and express the argument of the In function as Reia: 
u+zv=InR+icu. 
Now the u function is found as 
U = L y  
2Y 
1 - (22fy2)' 
= tan-' 
(12.133) 
(12.134) 
(12.135) 

MAPPINGS 
317 
4 
U 
v = -d2 
6 
Fig. 12.16 Two semicircular conductors in the w-plane 
From the limits 
and 
(12.136) 
we see that the two semicircles in the z-plane are mapped to two straight 
lines given as 
Equipotential surfaces in the w-plane cam now be written easily as 
av,, 
V(v) = ---?I. 
7r 
(12.139) 
Using Equation (12.135) we transform this into the z-plane to find the 
equipotentials as 
- 
- 
R 
(12.140) 
(I 2.14 1) 
Because this problem has translational symmetry perpendicular to the 
plane of the paper, equipotential surfaces in three dimensions can be 

318 
COMPLEX VARIABLES AND FUNCTIONS 
found by extending these curves in that direction. The solution to this 
problem has been found rather easily and in closed form. Compare this 
with the separation of variables method, where the solution is given 
in terms of the Legendre polynomials as an infinite series. However, 
applications of conformal mapping are limited to problems with one 
translational symmetry, where the problem can be reduced to two di- 
mensions. Even though there are tables of conformal mappings, it is not 
always easy as in this case to find an analytic expression for the needed 
mapping. 
12.4.3 
For laminar (irrotational) and frictionless flow, conservation of mass is given 
as 
Fluid Mechanics and Conformal Mappings 
g + 7. 
(p-i') = 0, 
(12.142) 
where p(?",) 
and -i'(?",t) represent the density and the velocity of a fluid 
element. For stationary flow we write 
aP - 
= 0, 
at 
(12.143) 
thus Equation (12.142) becomes 
3. 
(p-i') = 0. 
(12.144) 
Also, a lot of realistic situations can be approximated by the incompressible 
fluid equation of state, that is, 
p = const. 
(12.145) 
This further reduces Equation (12.144) to 
V.3=O0. 
(12.146) 
This equation alone is not sufficient to determine the velocity field *(?",t). 
If the flow is irrotational, it will also satisfy 
? X T = O ,  
(12.147) 
thus the two equations 
V - 3 = 0  
(12.148) 
and 
V x - i ' = O  
(12.149) 

MAPPINGS 
319 
Fig. 12.17 Flow around a wall of height h 
completely specify the kinematics of laminar, frictionless flow of incompress- 
ible fluids. These equations are also the expressions of linear and angular 
momentum conservations for the fluid elements. Fluid elements in laminar 
flow follow streamlines, where the velocity g(?",t) 
at a given point is tan- 
gent to the streamline at that point. 
Equations (12.148) and (12.149) are the sarme as Maxwell's equations in 
electrostatics. Following the definition of electrostatic potential, we use Equa- 
tion (12.149) to define a velocity potential as 
(12.150) 
+ +  
21 ( T  ,t) = Tkq7,t). 
Substituting this into Equation (12.148) we obtain the Laplace equation 
V2@(7, 
t )  = 0. 
(12.151) 
We should note that even though a(?", t )  is known as the velocity potential 
it is very different from the electrostatic potential. 
Example 12.12. Flow around an obstacle of height h: Let us consider 
laminar flow around an infinitely long and thin obstacle of height h. Since 
the problem has translational symmetry, we can show it in two dimen- 
sions as in Figure 12.17, where we search for a solution of the Laplace 
equation in the region R. 
Even though the velocity potential satisfies the Laplace equation like 
the electrostatic potential, we have to be careful with the boundary 
conditions. In electrostatics, electric field lines are perpendicular to the 
equipotentials; hence the test particles can only move perpendicular to 
the conducting surfaces. In the laminar flow case, motion perpendicular 

320 
COMPLEX VARIABLES AND FUNCTIONS 
to the surfaces is not allowed because fluid elements follow the contours 
of the bounding surfaces. For points far away from the obstacle, we take 
the flow lines as parallel to the z-axis. As we approach the obstacle, the 
flow lines follow the contours of the surface. For points away from the 
obstacle, we set 
v, = 1. 
(12.152) 
We now look for a transformation that maps the region R in the z-plane 
to the upper half of the w-plane. Naturally, the lower boundary of the 
region R in Figure 12.17 will be mapped to the real axis of the w-plane. 
We now construct this transformation in three steps: We first use 
w1= z 2 
(12.153) 
to map the region R to the entire wl-plane. Here the obstacle is between 
0 and -h2. As our second step, we translate the obstacle to the interval 
between 0 and h2 by 
~2 = z2 + h2. 
(12.154) 
Finally we map the w2-plane to the upper half of the w-plane by 
w = 6. 
(12.155) 
The complete transformation from the z-plane to the w-plane can be 
written as (Fig. 12.18) 
w = JW. 
The Laplace equation can now be easily solved in the upper half of the 
w-plane, and the streamlines are obtained as 
21 = cj. 
Curves perpendicular to these will give the velocity equipotentials as 
U =  b j .  
Finally transforming back to the z-plane we find the streamlines as the 
curves 
cj = I r n [ J 2 T P ] ,  
and the velocity of the fluid elements that are tangents to the streamlines 
(Fig. 12.19) are given as 

MAPPINGS 
321 
wz= w , + h2 
I 
fig. 12.18 Transition from the z-plane to the w-plane 

322 
COMPLEX VARIABLES AND FUNCTIONS 
h 
T’ 
4 z-plane 
fig. 12.20 
upper half of the w-plane 
Schwara-Christoffel transformation maps the inside of a polygon to the 
12.4.4 
Schwarz-Christoffel Transformations 
We have seen that analytic transformations are also conformal mappings, 
which preserve angles. We now introduce the Schwarz-Christoffel transfor- 
mations, where the transformation is not analytic at an isolated number of 
points. Schwarz-Christoffel transformations map the inside of a polygon in 
the z-plane to the upper half of the w-plane (Fig. 12.20). To construct the 
Schwarz-Christoffel transformations let us consider the function 
(12.156) 

MAPPINGS 
323 
where A is complex, kl is real, and w1 is a point on the u-axis. Comparing 
the arguments of both sides in Equation (12.156) we get 
arg (2) 
= lim [arg Az - arg Awl 
Aw-0 
lim [arg Az - arg Awl = 
A w 4 0  
w > W l  
As we move along the positive u-axis 
lim arg Aw = arg [dw] 
= 0, 
Aw-0 
hence we can write 
lim [arg Az] = arg[dz] = 
A w 4 0  
w > w1 
(12.157) 
(12.158) 
(12.159) 
For a constant A this means that the transforwation [Eq. (l2.156)] maps the 
parts of the u-axis; w < w1 and w > w1, to two line segments meeting at zo 
in the z-plane. Thus 
A (w - W I ) - ~ '  
(12.160) 
corresponds to one of the vertices of a polygon with the exterior angle k l ~  
and located at z1. For a polygon with n-vert.ices we can write the Schwarz- 
Christoffel transformation as 
dz - 
= A (W - ~
1
)
~
~
'
 
(W - w2)-IC2.. . (w - w,)-~" 
. 
dw 
(12.161) 
Because the exterior angles of a polygon add up to 21r, powers ki should satisfy 
the condition 
c 
ki = 2. 
(12.162) 
i=l 
Integrating Equation (12.161) we get 
z = A / w  (w - w ~ ) - ~ '  
(w - WZ)-~' .. . (w - w,)-ICn 
dw + B, 
where B is a complex integration constant. In1 this equation A determines the 
direction and B determines the location of the polygon in the z-plane. In a 
Schwarz-Christoffel transformation there are all together 2n + 4 parameters, 
that is, n wis, n kis, and 4 parameters from the complex constants A and B. 
A polygon can be specified by giving the coordinates of its n vertices in the 
z-plane. Along with the constraint [Eq. (12.162)] this determines the 2 n f l  of 
the parameters in the transformation. This means that we have the freedom 
to choose the locations of the three wi on the real axis of the w-plane. 

324 
COMPLEX VARIABLES AND FUNCTIONS 
fig. 12.21 Region we map in Example (12.13) 
Example 12.13. Schwarz-ChristofSel transformation: We now construct 
a Schwarz-Christoffel transformation that maps the region shown in Fig- 
ure 12.21 to the upper half of the w-plane. Such transformations are 
frequently needed in applications. To construct the Schwarz-Christoffel 
transformation we define a polygon whose inside, in the limit as z3 + 
-00, 
goes to the desired region (Fig. 12.22). 
Using the freedom in 
defining the Schwarz-Christoffel transformation we map the points z1 , 
2 2 ,  and z3 to the points 
w3--+--00, w1=-1, 
w2=+1 
(12.163) 
in the w-plane. We now write the Schwarz-Christoffel transformation as 
(12.164) 
Powers lcl, l c g ,  and lc3 are determined from the figure as f ,  f ,  and 1, 
respectively. Note how the signs of lc; are chosen as plus because of the 
counterclockwise directions shown in Figure 12.22. Because the constant 
c is still arbitrary, we define a new finite complex number A as 
C 
-+ A, 
lim 
___ 
(--W3)k3 
W3-'-00 
so that the SchwarzrChristoffel transformation becomes 
dz - 
= A ( w + l ) - f ( w - l ) - f ,  
dw 
(12.165) 
(12.166) 
(12.167) 

MAPPINGS 
325 
fig. 12.22 
the limit z3 -+ 
00 
The polygon whose interior goes to the desired region in Example 12.13 in 
This can be integrated as 
z = A cosh-' w + B, 
(12.168) 
where the constants A and B are found from the locations of the vertices, 
that is. 
as 
Example 12.1. 
d 
A = -  and B=id 
T 
(12.169) 
(12.170) 
(12.171) 
Semi-infinite parallel plate capacitor: V - now calcu- 
late the fringe effects in a semi-infinite parallel plate capacitor. Making 
use of the symmetry of the problem we can concentrate on the region 
shown in Figure 12.23. To find a Schwarz-Christoffel transformation 
that maps this region into the upper half of the w-plane we choose the 
points on the real w-axis as 
1 
I z4 
-+ w4+ +a 
z1 
-+ w1--+ -m 
(12.172) 

326 
COMPLEX VARIABLES AND FUNCTIONS 
, z-plane 
Fig. 12.23 Semi-infinite parallel plate capacitor 
Since kz = -1 and Ic3 = 1, we can write 
d.z 
dw - 
= c(w + i)pk2 (w - 
- (w + 1) 
- c- 
W 
1 
= c ( l +  --). 
Integrating this we get 
z = c(w + Inw) + D. 
If we substitute 
20 = lwl eib, 
Equation (12.174) becomes 
z = c [1w[ ei+ +In lzul+24] + D. 
Considering the limit in Figure 12.24 we can write 
z,PPer - z p w e r  - 
- zd. 
. 
Using Equation (12.176) this becomes 
u p p e r  - $wer 
= [O + i ( 4 ; p p e r  - &wer)] 
23 
= Ci(n-O), 
(12.173) 
(12.174) 
(12.175) 
( 12.176) 
(12.177) 

MAPPINGS 
327 
fig. 12.24 Limit of the point z3 
thus determining the constant c as 
d 
c =  -. 
(12.178) 
n- 
On the other hand, considering that the vertex 
22 = id 
(12.179) 
is mapped to the point -1 in the w-plane, we write 
d 
id = - (-1 + i ~ )  
+ D 
( 1 2.1 80) 
lr 
and determine D as 
d 
D = - .  
(12.181) 
n- 
This determines the Schwarz-Christoffel transformation 
d 
z =  -[w+Inui+I], 
7r 
(12.182) 
which maps the region shown in Figure 12.23 to the upper half w-plane 
shown in Figure 12.25. We now consider the transformation 
d 
(12.183) 
z = - In w or w = ezx/d, 
which maps the region in Figure 12.25 to the region shown in Figure 
12.26 in the %plane. In the 2-plane equipotentials are easily written as 
jj = const. = -d 
or V (jj) = 3 g .  
(12.184) 
- 
lr 
V 
VO 
d 
Using the inverse transformation in Equation (12.182), we write 
z = x + z y  
(12.185) 

328 
COMPLEX VARIABLES AND FUNCTIONS 
fig. 12.25 w-Plane for the semi-infinite parallel plate capacitor 
Fig. 12.26 Z-Plane for the semi-infinite parallel plate capacitor 

PROBLEMS 
329 
This gives us the parametric expression of the equipotentials in the z- 
plane (Fig. 12.27) as 
sin (:T) 
+ q d .  
V 
y =  ?re 
(12.186) 
(12.187) 
Similarly, the electric field lines in the ?-plane are written as 
Z = const. 
(12.188) 
Transforming back to the z-plane, with the definitions 
fig. 12.27 Equipotentials for the semi-infinite parallel plate capacitor 
- 
(12.189) 
3 3  
YX 
- = K  
and Q = -  
d 
d '  
we get 
d 
d 
x = -  [e" cos6 + I.] + K--, 
7r 
7r 
(12.190) 
(12.191) 
d 
y =  -[e"sinQ+8]. 
T 

330 
COMPLEX VARIABLES AND FUNCTIONS 
Problems 
12.1 
equation 
For conjugate harmonic pairs show that if q (u,u) satisfies the Laplace 
82*(u, u) a2qu, u) 
aU2 
+ 
au2 
= O  
in the w-plane, then q (2, y) will satisfy 
in the z-plane. 
12.2 Show that 
u(2, 
y) = sin z cosh y + x2 - y2 + 4xy 
is a harmonic function and find its conjugate. 
12.3 Show that 
u(z, 
y) = sin 2z/(cosh 2y + cos 2z) 
can be the real part of an analytic function f ( z ) .  Find its imaginary part and 
express f( z) explicitly as a function of z. 
12.4 Using cylindrical coordinates and the method of separation of variables 
find the equipotentials and the electric field lines inside two conductors with 
semi-circular cross sections separated by an insulator and held at potentials 
+VO and -VO, respectively (Fig. 12.15). Compare your result with Example 
12.11 and show that the two methods agree. 
12.5 With aid of a computer program plot the equipotentials and the elec- 
tric field lines found in Example 12.14 for the semi-infinite parallel plate ca- 
paci t or. 
12.6 In a two-dimensional potential problem the surface ABCD is at poten- 
tial VO and the surface EFG is at potential zero. Find the transformation (in 
differential form) that maps the region R into the upper half of the w-plane 
(Fig. 12.28). Do not integrate but determine all the constants. 
12.7 Given the following twc+dimensional potential problem in Figure 12.29, 
The surface ABC is held at potential VO and the surface DEF is at potential 
zero. Find the transformation that maps the region R into upper half of the 
w-plane. Do not integrate but determine all the constants in the differential 
form of the transformation 
12.8 Find the Riemann surface on which 
J(z - 1)(z - 2)(z - 3) 

PROBLEMS 
331 
4 2- plane 
Fig. 12.28 Two-dimensional equipotential problem 
-m 
-
m
t
 
E 
V = O  F 
X 
Fig. 12.29 Schwartz-Christoffel !.ransformation 
8. Find the Riemann surface on which 
d(z - l)(z - 2)( z - 3) 
is single valued and analytic except at z := 1,2,3. 
9. Find the singularities of 
f( z )  = tanh L. 
10. Show that the transformation 

332 
COMPLEX VARIABLES AND FUNCTIONS 
t 
v=o --
fig. 12.30 Rectangular region surrounded by metallic plates 
or 
maps the 21 =const. lines into circles in the z-plane. 
12.11 Use the transformation given in Problem 12.10 to find the equipoten- 
tials and the electric field lines for the electrostatics problem of two infinite 
parallel cylindrical conductors, each of radius R and separated by a distance 
of d, and held at potentials +VO and -Vo, respectively. 
12.12 Consider the electrostatics problem for the rectangular region sur- 
rounded by metallic plates as shown in Figure 12.30. The top plate is held 
at potential VO, 
while the bottom and the right sides are grounded (V = 0). 
The two plates are separated by an insulator. Find the equipotentials and the 
electric field lines and plot. 
12.13 
in the limit as 
Map the real w-axis into the triangular region shown in Figure 12.31, 
2 5  
--f 
03 
and 
2 3  
---f 
-03 
12.14 Find the equipotentials and the electric field lines for a conducting 
circular cylinder held at potential VO and parallel to a grounded infinite con- 
ducting plane (Fig. 12.32). Hint: Use the transformation z = a tanhiw/2. 

PROBLEMS 
333 
- 
- 
fig. 12.31 %angular region 
fig. 12.32 Conducting circular cylinder parallel to infinite metallic plate 

This Page Intentionally Left Blank

13 
COMPLEX 
INTEGRALS and 
SERIES 
In this chapter we first introduce the complex integral theorems. Using ana- 
lytic continuation we discuss how these theorenis can be used to evaluate some 
frequently encountered definite integrals. In conjunction with our discussion 
of definite integrals, we also introduce the gamma and beta functions. We 
also introduce complex series and discuss classification of singular points. 
13.1 COMPLEX INTEGRAL THEOREMS 
I. Cauchy-Goursat Theorem 
Let C be a closed contour in a simply connected domain (Fig. 13.1). If 
a given function, f (z), is analytic in and on this contour, then the integral 
is true. 
Proof. We write the function f (2) as 
f (2) = '11 + 217. 
(13.2) 
335 

336 
COMPLEX INTEGRALS AND SERIES 
f ”  n 
Fig. 13.1 Contour for the Cauchy-Goursat theorem 
Integral (13.1) becomes 
(u + iv) ( d z  + idy) 
= f ( u d x  - v d y )  + i 
( v d x  + u d y )  . 
(13.3) 
f 
Using the Stokes theorem 
we can write integral (13.3) as 
(u + iv) ( d z  + i d y )  
= SS, (-& - ”> d s  + SJ, (2 - $) ds, 
da: 
dY 
(13.5) 
where 5’ is an oriented surface bounded by the closed path C. Because 
the Cauchy-Riemann conditions are satisfied in and on the closed path 
C, the right-hand side of Equation (13.5) is zero, thus proving the the- 
orem. 
11. Cauchy Integral Theorem 
If f ( z )  is analytic in and on a closed path C in a simply connected domain 
13.2) and if ~0 is a point inside the path C, then we can write the 
(Fig. 
integral 
(13.6) 

COMPLEX IN JEGRAL THEOREMS 
337 
Fig. 13.2 Contour for the Cauchy integral theorem 
Proof. To prove this theorem we modify th'e path in Figure 13.2 and use 
that in Figure 3.3, where we can use the Cauchy-Goursat theorem to 
write 
(13.7) 
This integral must be evaluated in the liniit as the radius of the path Co 
goes to zero. Integrals over L1 and L2 cancel each other. Also noting 
that the integral over Co is taken clockwise, we write 
(13.8) 
where both integrals are now taken counterclockwise. The integral on 
the left-hand side is what we want. For the integral on the right-hand 
side we can write 
Using the substitution z - 
hand side can be evaluated easily, giving us 
= b e i e ,  the first integral on the right- 
The second integral in Equation (13.9), which we call I,, can be bounded 

338 
COMPLEX INTEGRALS AND SERIES 
Fig. 13.3 A different path for the Cauchy integral theorem 
from above as 
where M is the maximum value of 1 ('i I i(zo) 
1 on CO and L is the 
circumference of CO, which is 
L = 2TR@ 
(13.12) 
Now let E be a given small number such that on CO 
If ( z )  - f (%)I 
< 6 
(13.13) 
is satisfied. Because f(z) is analytic in C, no matter how small an t is 
chosen, we can always find a sufficiently small radius &, 
Iz - zol I 
& = 6, 
(13.14) 
such that condition (13.13) is satisfied; thus we can write 
I2 5 M . L = 2 m .  
From the limit 
lime + 0, 
6-0 
it follows that Z2 + 0; thus the desired result is obtained as 
(13.15) 
(13.16) 
(13.17) 

TAYLOR SERIES 
339 
/ (  
\ \ 
\ \ \ \ ‘. 
0 
0 
----/ 
Fig. 13.4 Path for Ta:ylor series 
Note that the limit lim 
(’) - (’O) 
is actually the definition of the 
derivative f ’ ( z )  evaluated at zo. Because f ( z )  is analytic in and on the 
contour C, it exists and hence M in Equation (13.11) is finite. Thus, 
1121 -+ O as & --+ 0. 
z-zo 
z - & )  
111. Cauchy Theorem 
Because the position of the point 
is arbitrary in the Cauchy integral 
theorem, we can treat it as a parameter and differentiate Equation (13.6) 
with respect to zo as 
After n-fold differentiation, we obtain a very useful formula: 
13.2 
TAYLOR SERIES 
(13.18) 
(13.19) 
Let us expand a function f ( z )  about a, 
where it is analytic. Also, let z1 be 
the nearest singular point of f (2) to a. If .f ( z )  is analytic on and inside a 

340 
COMPLEX INTEGRALS AND SERIES 
closed contour C, we can use the Cauchy theorem to write 
f ( z )  = - 
2x2 f 
c ( z ’ - z )  
(z’)dz‘ ’ 
(13.20) 
where z’ is a point on the contour and z is a point inside the contour C (Fig. 
13.4). We can now write Equation (13.20) as 
f (2) dz’ 
= ki j6, [(z’ - a) 
- ( z  - zo)] 
(13.21) 
1 
f (2’) dz’ 
- 
- 
Since the inequality Iz - 
the binomial formula 
< Iz’ - 
is satisfied in and on C, we can use 
00 
to write 
Interchanging the integral and the summation signs we find 
which gives us the Taylor series expansion of f ( 2 )  as 
00 
(13.22) 
(13.23) 
(13.24) 
(13.25) 
n = O  
Using Equation (13.19) we can write the expansion coefficients as 
(13.26) 
< 121 - % I ,  
where 
1 
n! 
An = - f‘”’ (a). 
This expansion is unique and valid in the region Iz - 
f ( z )  is analytic. 
13.3 
LAURENT SERIES 
Sometimes f ( z )  is analytic inside an annular region as shown in Figure 13.5. 
For a closed contour in the region where our function is analytic (Fig. 13.5), 

LAURENT SERIES 
341 
Fig. 13.5 Lament series are defined in an annular region 
integrals over L1 and L2 cancel each other, thus we can write 
(13.27) 
f (2’) dz‘ 
Since the inequality 12’ - 
Iz - 201 is satisfied on Cz, we can write the above equation as 
> Iz - 201 is satisfied on C1 and Iz’ - 
< 
1 
f (2’)dz’ 
= 2ni i, 
[(z’ - a) - ( z  - a)] 
(13.28) 
(13.29) 

342 
COMPLEX INTEGRALS AND SERIES 
Fig. 13.6 Another contour for the Laurent series 
We now use the binomial formula and interchange the integral and the sum- 
mation signs to obtain the Laurent expansion as 
Using the contour in Figure 13.6 we can also write the Laurent series as 
n=--00 
where 
an = - 
Example 13.1. Taylor series: We find the series expansion of 
(1 3.31) 
(13.32) 
(13.33) 

LAUREN T SERIES 
343 
Fig. 13.7 For the 
function we write the Taylor series in the region Iz[ < I 
JT 
in the interval IzI < 1 about the origin. Since this function is analytic 
inside the unit circle (Fig. 13.7), we need the Taylor series 
OL) 
f (z) = cpz-. 
(13.34) 
n. 
n=O 
Using 
we write the Taylor series as 
f ( z ) =  T I +  
z " 
Example 13.2. Laurent series: 
(13.35) 
We now expand the same function, 
(13.36) 
(13.37) 
in the region IzI > 1. We place the cutline outside our region of interest 
between the points -1 and 1 (Fig. 13.8). The outer boundary of the 
annular region in which f (2) is analytic could be taken as a circle with 
infinite radius, while the inner boundary is a circle with radius infinites- 
imally larger than 1. We now write the Laurent series about z = 0 

344 
COMPLEX INTEGRALS AND SERIES 
z -plane 
T7k 
~ 
- _  - 
fig. 13.8 For the 
function we write the Laurent series in the region Izl > 1 
as 
m 
n=-m 
where the expansion coefficients are given as 
1 
dz' 
(13.38) 
(13.39) 
In this integral z' is a point on the contour C, which could be taken as 
any closed path inside the annular region where f ( z )  is analytic. To 
evaluate the coefficients with n 2 0, we first deform our contour so that 
it hugs the outer boundary of our annular region, which is a circle with 
infinite radius. For points on this contour we write 
and evaluate the coefficients a, (n 2 0) in the limit as R -+ 03 we as 
(13.42) 
= 0. 
(13.43) 

LAURENT SERIES 
345 
To pick the coefficients with the negative values of n, we take our con- 
tour as a circle with radius infinitesimally larger than 1. Because f(z) is 
analytic everywhere except the cutline, these coefficients can be evalu- 
ated by shrinking the contour to a bone-shape so that it hugs the cutline 
as shown in Figure 13.8; thus 
* -  
(3 +++--+o 
c, 11 
fz co 
(16.44) 
We evaluate the integrals over CO and C1 in the limit as their radiuses 
go to zero. First, let us consider the integral over C, and take 
z’ - 1 = h e i Q o  
(13.45) 
The contribution of this to a, is zero: 
Similarly, the contribution of C1 is also zero, thus leaving us with 
dz‘. 
f-- 1 
Un(n<O) = - 
2Fa 
z’n+l Jn 
(13.47) 
Integrals over 11 and 12 can be evaluated by defining the parameters 
and writing 
(13.49) 
(13.50) 

346 
COMPLEX INTEGRALS AND SERIES 
We finally obtain the coefficients as 
(13.52) 
(13.53) 
This gives us the Laurent expansion for the region IzI > 1 and about 
the origin as 
1 
1 
3 1  
5 1  
d
n
 
- 
2z3 
8 z5 
16z7 
+-+--+--+... 
. 
1 
-- 
(13.54) 
Example 13.3. Laurent series-a short cut: In the previous example we 
found the Laurent expansion of the function 
(13.55) 
1 
P(z) = - 
4- 
about the origin and in the region 121 > 1. We used the contour integral 
definition of the coefficients. However, using the uniqueness of power 
series and appropriate binomial expansions, we can also evaluate the 
same series. First, we write f (2) as 
(1 3.56) 
1 
f ( 4  = 
1 
1 
~~ 
- 
- 
( z  + I)+ ( z  - 1)+ 
(13.57) 
(13.59) 
Since for the region IzI > 1 the inequality 1/z < 1 is satisfied, we can use 
the binomial formula for the factors (1 + 4) - ' 
and (1 - ;) -'to write 
the Laurent expansion as 
- I +  -+-+-+...I 
1
3
 5 
[I--+---+-- 
1
3
 
f ( z ) =  [ 
22 
822 
16z3 
22 
8z2 
16z3 
z 
(13.60) 
1
1
 3 
z 
2z3 
8z3 
f (2) = - + - 
+ - 
+ . . . , 
(13.61) 
which is the same as our previous result [Eq. (13.54)]. 

CLASSIFICATION OF SINGULAR POINTS 
347 
13.4 
CLASSIFICATION OF SINGULAR POINTS 
Using Laurent the series we can classify singular points of a function. 
Definition I 
Isolated singular point: If a function is not analytic at a but analytic 
is called an isolated 
at every other point in some neighborhood of a, 
then 
singular point. 
Definition I1 
Essential singular point: In the Laurent series of a function: 
00 
(13.62) 
n 
f(z) = C a n ( Z - * )  
7 
n=--M 
if for n < - Iml < 0, 
a, = 0 
and 
a-lrnl # 0, 
then 
is called a singular point of order m. 
Definition I11 
Essential singular point: If m is infinity, then a is called an essential 
singular point. 
Definition IV 
Simple Pole: In Definition 11, if m = 1, then zo is called a simple pole. 
Definition V 
Entire function:When a function is analytic in the entire z-plane it is 
called an entire function. 
13.5 
RESIDUE THEOREM 
If a function f ( z )  is analytic in and on the closed contour C except for a finite 
number of isolated singular points (Fig. 13.9), then we can write the integral 
(13.63) 

348 
COMPLEX INTEGRALS AND SERIES 
t" 
Fig. 13.9 Residue theorem 
where R, is the residue off ( z )  at the nth isolated singular point. The residue 
term in the Laurent expansion of 
1 
is defined as the coefficient of the ____ 
(. - zn) 
f (2). 
Proof: We change the contour C as shown in Figure 13.10 and use the 
Cauchy-Goursat theorem [Eq. (13.1)] to write 
= 0. 
(13.64) 
Straight line segments of the integral cancel each other. Integrals over 
the small circles are evaluated clockwise and in the limit as their radius 
goes to zero. Since the integral over the closed path C' is equal to the 
integral over the closed path C, we write 
(13.65) 
where the integrals over c, are now evaluated counterclockwise. Using 
the Laurent series expansion of f(z) about %, the integral of the terms 
with the positive powers of (z - zo) gives 
( z  - 
dz = 0, 
n 2 0. 
lo 
(1366) 

ANALYTIC CONTINUATION 
349 
4 "  
fig. 13.10 Contour for the residue theorem 
On the other hand, for the negative powers of ( z  - 20) we have 
0 
n=2,3, ... 
27ri 
n =  1. 
We repeat this for all the other poles to get 
N 
= 2niCRn. 
n=O 
(13.67) 
(13.68) 
(13.69) 
(13.70) 
(13.71) 
13.6 
ANALYTIC CONTINUATION 
When we discussed harmonic functions and mappings, we saw that analytic 
functions have very interesting properties. It is for this reason that it is 
very important to determine the region where a function is analytic and, if 
possible, to extend this region to other parts of the z-plane. This process 
is called analytic continuation. Sometimes functions like polynomials and 

350 
COMPLEX INTEGRALS AND SERIES 
trigonometric functions, which are defined on the real axis as 
f (z) = a0 + a, 2 + a 2 2  + . . . + anzn, 
f (z) = sin z, 
(13.72) 
(13.73) 
can be analytically continued to the entire z-plane by simply replacing the 
real variable z with z, that is, 
f ( z )  = ao+alz+a~z2+-..+anzn, 
(13.74) 
f ( z )  = sin z. 
(13.75) 
However, analytic continuation is not always this easy. Let us now consider 
different series expansions of the function 
(13.76) 
This function has two isolated singular points at z = 1 and z = 2 . We first 
make a Taylor series expansion about z = 0. We write 
(13.77) 
and use the binomial formula 
00 
(1 -.)-I 
= Cz" 
n=O 
to obtain 
03 
f ( z )  = c (1 + $) zn, 
IzI < 1. 
n=O 
(13.78) 
(13.79) 
This expansion is naturally valid up to the nearest singular point at z = 1. 
Similarly, we can make another expansion, this time valid in the interval 
I < IzI < 2 as 
1 
1 
f ( z ) =  - (i> - 
+- 
(1-$) 
(1-5) 
n=O 
n=O 
03 
(13.80) 
(13.81) 
(13.82) 

ANALMlC CON TIN UA TlON 
351 
23 
Fk. 13.11 Analytic continuation 
Finally for IzI > 2, we obtain 
1
1
 
1 
fk) 
= -; (q) 
- (I) 
zn 
z" 
n= 1 
(13.83) 
(13.84) 
These three expansions of the same function [Eq. (13.77)] are valid for the 
intervals IzI < 1, 1 < IzI < 2, and IzI > 2 , respectively. Naturally it is not 
practical to use these series definitions, where each one is valid in a different 
part of the z-plane, when a closed expression like 
exists for the entire z-plane. However, it is not always possible to find a closed 
expression like this. Let us assume that we have a function with a finite num- 
ber of isolated singular points at z1,z2, ..., z,. 
Taylor series expansion of this 
function about a regular point zo will be valid only up to the nearest singular 
point zl(Fig. 13.11). In such cases we can accomplish analytic continuation 
by successive Taylor series expansions, where each expansion is valid up to 
the nearest singular point (Fig. 13.12). We should make a note that during 
this process we are not making the function analytic at the points where it is 
not analytic. 

352 
COMPLEX INTEGRALS AND SERIES 
fig. 13.12 How to accomplish analytic continuation 
13.7 COMPLEX TECHNIQUES IN TAKING SOME DEFINITE 
INTEGRALS 
Many of the definite integrals encountered in physics and engineering can be 
evaluated by using the complex integral theorems and analytic continuation: 
I. Integrals of the form I = Jc R (cos 8, sin 8) do. 
In this integral R is a rational function of the form 
al cos 8 + a2 sine + a3 cos2 8 + . . . 
R =  
(13.85) 
These integrals can be converted into a complex contour integral over 
the unit circle by the substitutions 
b, cos 8 + b2 sin8 + b3 cos28 + b4 sin2 8 + 
, s i n e = -  ( 
z - -  :> 
22 
(13.86) 
and 
as 
I = -2 
R [; 
(2 + i) , ; 
(2 - 31 t. 
(13.87) 
(13.88) 
Example 13.4. Complex contour integration technique: Let us evalu- 
ate the integral 

COMPLEX TECHNIQUES IN TAKING SOME DEFINITE INTEGRALS 
353 
a >  1. 
d8 
'7r 
I = J ~  a+cose' 
Using Equations (13.86) and (13.87) we can write this integral as 
I =  -i 
dz 
(13.89) 
(13.90) 
The denominator can be factorized as 
(2 - a) ( z  - P) i 
(13.91) 
where 
a = -a + (2 - I) 4 , 
(13.92) 
p = -a - (a2 - 1) . 
(13.93) 
1 
For a > 1 we have la1 < 1 and 101 > 1; thus only the root z = a 
is present inside the unit circle. We can now use the Cauchy integral 
theorem to find 
1 
I = -2i ( 2 7 4  - 
a - P  
(13.94) 
(13.95) 
Example 13.5. Cornplea: contour integml technique: We now consider 
the integral 
We can use Equations (13.86) and (13.87) to write I as a contour integral 
over the unit circle as 
(13.96) 
We can now evaluate this integral by using the residue theorem as 
I=-- (-')' 
(-2'2~2 [ residue of : 
( z  - :) '' at z = 0 ] . 
(13.97) 
2a 
22' 

354 
COMPLEX INTEGRALS AND SERIES 
Using the binomial formula we can write 
(13.98) 
z 
k=O 
where the residue we need is the coefficient of the 1/z term. This can 
be easily found as 
and the result of the definite integral I becomes 
(21)! 
221 ( l ! ) 2 .  
I =  - 
fig. 13.13 Contour for the type I1 integrals 
11. Integrals of the type I = s_”, d x R  ( x )  , 
where R ( x )  is a rational function of the form 
ao + a*x+ U2Z2 +. . . + a,xn 
R ( x )  = bo + biz + b2x2 +. . . + bmxm ’ 
a ) With no singular points on the real axis, 
b ) IR (z)l goes to zero at least as - 
in the limit as IzI + 00 . 
1 .  
1z21 
(13.99) 
(13.100) 
(13.101) 
Under these conditions I has the same value with the complex contour 
integral 
I = 
R ( z )  dz, 

COMPLEX TECHNIQUES IN TAKING SOME DEFINITE INTEGRALS 
355 
fig. 13.14 Contour for Example 13.6 
where C is a semicircle in the upper half of the z-plane considered in 
the limit as the radius goes to infinity (Fig. 13.13). Proof is fairly 
straightforward if we write I as 
I = h  R ( z ) d z  = l m R ( x ) d z + i  R(z)dz 
(13.102) 
and note that the integral over the semicircle vanishes in the limit as 
the radius goes to infinity. We can now evaluate I using the residue 
theorem. 
03 
Example 13.6. Complex contour integral technique: Let us evaluate 
the integral 
d x  
n = 1,2, ... 
( 1  f X 2 ) "  
(13.103) 
Since the conditions of the above technique are satisfied, we write 
I = f  
dz 
c (z+2)n(z-2)n- 
(13.104) 
Only the singular point z = 2 is inside the contour C (Fig. 13.14); thus 
we can write I as 
) at z = 2 1 .  
(13.105) 
( 2  + 2)" ( z  - 2)" 
To find the residue we write 
m 
(13.106) 
_ _  
(13.107) 
k 
= X A k  ( z  - 2) 
k=O 

356 
COMPLEX INTEGRALS AND SERIES 
fig. 13.15 Contour C in the limit R -+ 00 for type I11 integrals 
and extract the An-l coefficient as 
(13.108) 
n(n+ 1) (n + 2). .. (2n - 2) 
(- l)n- 
1 
- 
-- 
(n- I)! 
( z  + i)2n- 
I=&. 
This gives the value of the integral I as 
(13.109) 
27ri 
(-1)- ' (2n - 2)!i 
I=--- (n - I)! 
22n-1 (n - I)! 
111. Integrals of the type I = s-ma dxR (z) einz, 
where K. is a real parameter and R (x) is a rational function with 
a ) No singular points on the real axis, 
b ) In the limit as IzI + 00, IR (.)I 
-+ 0 independent of 8. 
Under these conditions we can write the integral I as the contour integral 
I = 
R ( z )  einzdz, 
(13.110) 
where the contour C is shown in Figure 13.15. To show that this is true, 
we have to show the limit 
R ( z )  einzdz + 0. 
(13.111) 
We start by taking the moduli of the quantities in the integrand to put 
an upper limit to this integral as 
I IpieiOI a. 
(13.112) 

COMPLEX TECHNIQUES IN JAKtNG SOME DEFINITE INTEGRALS 
357 
fig. 13.16 Upper limit calculation 
We now call the maximum value that R(z) takes in the interval [0,2w] 
M (P) = m= IR (211 
(13.113) 
and improve this bound as 
(13.115) 
Since the straight line segment shown in Figure 13.16, in the interval 
[0,7r/2] , is always less than the sin 6 function, we can also write Equation 
(13.115) as 
IA 5 2pM (p) 1% 
e-2np$d3. 
(13.116) 
0 
This integral can easily be taken to yield 
(13.117) 
(13.118) 
From here we see that in the limit as p --t (
~
f
 
the value of the integral 
IA goes to zero, that is, 
7F 
IA 5 2pM (p) - 
(1 - ePnp) , 
ZA 5 M (p) lc (1 - epnp). 
2KP 
?r 
This result is also called Jordan's lemma. 

358 
COMPLEX INTEGRALS AND SERIES 
Example 13.7. Complex contouy integral technique: In calculating dis- 
persion relations we frequently encounter integrals like 
l
a
 
f (z) = - 1 dkg (k)eikx. 
6 
-a 
Let us consider a case where g ( k )  is given as 
i ) For x > 0 we can write 
(13.119) 
(13.120) 
(13.121) 
In this integral k is now a point in the complex k-plane. Because we 
have a pole (k = ip) inside our contour, we use the Cauchy integral 
theorem [Eq. (13.6)] to find 
ii ) For z < 0, we complete our contour C from below to find 
(13.122) 
(13.123) 
(13.124) 
(13.125) 
IV. Integrals of the type I = s," dzzX-l R (z), where 
a) X # integer, 
b) R ( z )  is a rational function with no poles on the positive real axis and 
the origin, 
c )  In the limit as 121 -+ 0, lzXR (z)I -+ 0 and 
d) In the limit as 121 -+ 00 , IzXR(z)l --+ 0 .  

COMPLEX TECHNIQUES IN TAKING SOME DEFINITE INTEGRALS 
359 
Fig. 13.17 Contour for the integrals of type IV 
Under these conditions we can evaluate the integral I as 
(13.126) 
7r ( - 1 y  
residues of [zA- ' R (z)] , 
- 
- 
sin 7rA 
inside C 
where C is the closed contour shown in Figure 13.17 
Proof: Let us write the integral I as a complex contour integral: 
i 
zX-'R ( z )  dz. 
In the limit as the radius of the small circle 
(13.127) 
goes to zero the integral 
over the contour Ci goes to zero because of c. Similarly, in the limit as 
the radius of the large circle goes to infinity the integral over Co goes to 
zero because of d. This leaves us with 
We can now evaluate the integral on the left-hand side by using the 
residue theorem. On the other hand, the right-hand side can be written 

360 
COMPLEX INTEGRALS AND SERIES 
as 
f 
zX-'R(z)dz 
*L1++L2 
= 
xX-l R (x) 
d~ 
(13.128) 
Thus we obtain 
27ri 
residues of [z'-'R(z)] 
inside C 
dxxx-' R (x) . 
(13.130) 
Rearranging this, we write the final result as 
7r ( - 1 y  
residues of [zX-'R(z)] . 
sin 7rX 
inside C 
(13.131) 
13.8 GAMMA AND BETA FUNCTIONS 
13.8.1 
Gamma Function 
For an important application of the type IV integrals we now introduce the 
gamma and beta functions, which are frequently encountered in applications. 
The gamma function is defined for all x values as 
I- 
N! N" 
X[Z + 1 ] [ ~  + 21 . . . [X + N ]  
r(x) = lim 
(13.132) 
Integral definition of the gamma function, even though restricted to x > 0, is 
also very useful: 
r (x) = Lmyz-' exp(-y)dy. 
(13.133) 
Using integration by parts we can write this as 

GAMMA AND BETA FUNCTIONS 
361 
P
W
 
(13.134) 
(13.135) 
This gives us the formula 
r 
= (. - i ) r  (x- I), 
( 1 3.136) 
which is one of the most important properties of the gamma function. For 
the positive integer values of x, this formula gives us 
(13.137) 
(13.138) 
(13.139) 
Besides, if we write 
we can also define the gamma function for the negative integer arguments. 
Even though this expression gives infinity for the values of r (0) , r (-1) and 
for all the other negative integer arguments, their ratios are finite: 
-- 
r(-n) - [-N] [-N+ 11.. . [-N - 21 [-N - 11 
r ( - N )  
For some n values, the gamma function takes the values: 
I r(-$)= 
QJiF I r(i)=i I 
I r(-1) = *OO 
I r($) 
= $& I 
The inverse of the 
finite with the limit 
(13.140) 
gamma function, l/r (x) , is single valued and always 
(13.141) 

362 
COMPLEX INTEGRALS AND SERIES 
13.8.2 
Beta Function 
Let us write the multiplication of two gamma functions as 
r ( n  + 1) r (m + 1) = 
e-"u"d~]~ e-"vmdv. 
l o  
Using the transformation 
u = x2 and v = y2, 
we can write 
13.142) 
13.143) 
In plane polar coordinates this becomes 
r ( n + i ) r ( m + i )  
(13.145) 
The first term on the right-hand side is r (m + n + 2) and the second term is 
called the beta function B (m + 1, n + 1). The beta function is related to the 
gamma function through the relation 
(13.146) 
Another definition of the beta function is obtained by the substitutions 
sin2 8 = t 
(13.147) 
and 
as 
(13.148) 
X 
t = -  1 - 2  
xmdx 
00 .I (1 + x)m+n+2. 
B ( m +  l , n +  1) = 
(13.149) 

GAMMA AND BETA FUNCJIONS 
363 
Using the substitution 
Y 
x=- 1-y' 
(13.150) 
we can also write 
,,I 
To calculate the value of B(;,$) we have to evaluate the integral 
1 1  
Using formula (13.131) we can evaluate this as 
(13.152) 
(- 1)- W(- 
1) - 1/2 
-7r 
- 
- 
sin 7r/2 
= 7r. 
(13.153) 
From here we obtain 
1 
r($ = 6' 
(13.154) 
(2n)! J;; 
4"n! ' 
1 
2 
r(- + n) = 
~ 
1 
(-4)"n!fi 
r(- - n) = 
2 
(2n)! 
. 
Another useful function related to the gamma function is given as 
(13.155) 
(13.156) 
(13.157) 
The function 9(z) satisfies the recursion relation 
@(x + 1) = 9 ( z )  + 2 - 1 ,  
(13.158) 
from which we obtain 
(13.159) 
@ ( n + 1 ) = @ ( 1 ) + C 7 .  
" 1  
j = 1  3 
The value of @(l) is given in terms of the Euler constant y as 
-9(l) = 7 = 0.5772157. 
(13.160) 

364 
COMPLEX INTEGRALS AND SERIES 
13.8.3 
Among the useful relations of the gamma function we can write 
Useful Relations of the Gamma Functions 
-7r csc(7rx) 
r(x + 1) ’ 
r(-x) = 
~ T ( x ) ~ ( x  
+ 3) 
2
6
 
’ 
r(2~) 
= 
In calculating ratios like 
the ratio 
(13.161) 
(13.162) 
(13.163) 
(13.164) 
(13.165) 
is very useful. 5’:”’ are the Stirling numbers of the first type: 
S(”) 
3+1 = s(m-1) 
3 
-jsy4, $0) = 1 
(13.166) 
and for the others 
sp = sy = 0. 
(13.167) 
In terms of the binomial coefficients this ratio can also be written as 
(13.168) 
13.8.4 
Both the beta and the gamma functions have their incomplete forms. The 
definition of the incomplete beta function with respect to x is given as 
Incomplete Gamma and Beta Functions 
(13.169) 

CAUCHY PRINCIPAL VALUE INTEGRAL 
365 
On the other hand, the incomplete gamma function is defined by 
y* 
(c, X )  = - y("-') exp( -y)dy 
r ( x )  
c-x IC 
0 
(13.170) 
(13.171) 
In this equation y* (c, z) is a single-valued analytic function of c and z. Among 
the useful relations of y*(c, z) we can give 
(13.172) 
(13.173) 
13.9 
CAUCHY PRINCIPAL VALUE INTEGRAL 
Sometimes we encounter integrals with poles on the real axis, such as the 
integral 
(13.174) 
which is undefined (divergent) at z = a. However, because the problem is 
only at x = a, we can modify this integral by first integrating up to an 
infinitesimally close point, (a - a), to a and then continue integration on the 
other side from an arbitrarily close point, (a + S), to infinity, that is, define 
the integral I as 
(13.175) 
This is called taking the Cauchy principal value of the integral, and it is 
shown as 
If f ( z )  is analytic in the upper half z-plane, that is 
as IzI + 00, 
f(z) -+ 
0 for y > 0, 
(13.176) 

366 
COMPLEX INTEGRALS AND SERIES 
t' 
fig. 13.18 Contour G for the Cauchy principal value integral 
we can evaluate the Cauchy principal value of the integral (13.174) by using 
the contour in Figure 13.18. In this case we write 
(13.177) 
and evaluate this integral by using the residue theorem as 
dz = 27~2 
residues of [ z] 
. 
(13.178) 
If f ( z ) / ( z  - u )  does not have any isolated singular points inside the closed 
contour C [Fig. 13.181, the left-hand side of Equation (13.177) is zero, thus 
giving the Cauchy principal value of the integral (13.175) as 
inside C 
(13.179) 
f -  
From the condition f (z) --+ 0 as IzI -+ 00 for y > 0, the second integral over 
CR on the right-hand side is zero. To evaluate the integral over the small arc 
c6 we write 
(13.180) 
(13.181) 

CAUCHY PRINCIPAL VALUE INTEGRAL 
367 
tz 
Fig. 13.19 Another path for the Cauchy principal value calculation 
and find the Cauchy principal value as 
(13.182) 
(13.183) 
Another contour that we can use to find the Cauchy principal value is given 
in Figure 13.19. In this case the pole at x = u is inside our contour. Using 
the residue theorem we obtain 
= -27rf (u) + 2nif (u) 
= i?rf (u) . 
(13.184) 
As expected, the Cauchy principal value is the same for both choices of detour 
about z = u . 
If f (z) is analytic in the lower half of the z-plane, that is, 
f(z) + 0 as IzI -+ 
03 for y < 0, 
then the Cauchy principal value is given as 
(13.185) 
In this case we again have two choices for the detour around the singular 
point on the real axis. Again the Cauchy principal value is -ixf(u) for both 
choices. 

368 
COMPLEX INTEGRALS AND SERIES 
Z 
-kr 
kr 
fig. 13.20 Contour for 11 
Example 13.8. Cauchy principal value integral: Let us now evaluate the 
integral 
(13.186) 
We write I as 
I = I1 + 1 2 ,  
where 
xeixdx 
(13.187) 
(13.188) 
(x - kr) (x + kr)' 
For I1 we choose our path in the z-plane as in Figure 13.20 to obtain 
lr 
= - cos kr. 
2 
t = - k r  11 
(13.189) 
For the integral I2 we use the path in Figure 13.21 to obtain 
m 
= 1 
cos kr. 
(13.190) 
2 

CONTOUR INTEGRAL REPRESENTATIONS OF SOME SPECIAL FUNCTIONS 
369 
Fig. 13.21 Contour for 12 
x sin xdx 
Hence the divergent integral 
its Cauchy principal value as 
can now be replaced with 
13.10 CONTOUR INTEGRAL REPRESENTATIONS OF SOME 
SPECIAL FUNCTIONS 
13.10.1 
Legendre Polynomials 
Let us write the Rodriguez formula for the Legendre polynomials: 
(13.191) 
1 d‘ 
1 
fi (x) = -- 
(x2 - 1) . 
2l1! dxl 
Using the Cauchy formula [Eq. (13.19)) 
1 
and taking zo = x and f (2) = (z2 - 1) we obta,in 
(13.192) 
d‘ 
(z’ - 1)‘ dz‘ 
(13.193) 
t = x  

370 
COMPLEX INTEGRALS AND SERIES 
Fig. 13.22 Contour for the Schlijfli formula 
This gives us the complex contour representation of the Legendre polynomials 
as 
1 1 
(2'- 
1)ldz' 
fi (z) = -- 
27rz2' c @ I  +l+l 
. 
(13.194) 
This is also called the Schl8fli integral formula, where the contour is given 
in Figure 13.22. 
Using the Schlofli formula [Eq. (13.194)] and the residue 
theorem, we can obtain the Legendre polynomials as 
9 (z) = 
[residue of [ ((z2 - tyl] at z] . 
(13.195) 
z-x) 
We use the binomial formula to write (z2 - 1)' in terms of powers of ( z  - z) 
as 
1 
(2 - 1)' = c l! 
z2(1-k) 
k! (1 - k)! 
k=O 
1 
1! (-l)k 
21-2k 
[z - z + z] 
- 
- Ck! 
(1 - k)! 
k=O 
. (13.196) 
(21 - 2k)! 
( z  - z)j 
%21-2k-j 
1 I! 
(-1)k 
21-2k 
- 
- c k! (1 - k)! c 
(21 - 2k - j ) ! j !  
k=O 
1=0 
1 
For the residue we need the coefficient of ( z  - z) ; hence we need the j = 1 
term in the above series, which is 
(13.197) 
['I 
l !  
(21 - 2k)! z1-2k 
coefficient of ( z  - z)' = C k! (1 - k)! (1 - 2k)!l! 
. 
k=O 

CONTOUR INTEGRAL REPRESENTATIONS OF SOME SPECIAL FUNCTIONS 
371 
Using this in Equation (13.195) we finally obtain P' (x) as 
(-qk (22 - 2k)! z'-2k 
k!(2 -k)! (2 - 2k)! 
2' 
- 
9 (.I 
= c 
k=O 
13.10.2 
Laguerre Polynomials 
The generating function of the Laguerre polynomials is defined as 
(13.198) 
(13.199) 
The Taylor expansion in the complex t-plane of the function 
about the origin for a contour with unit radius is given as 
O 0 1  
n! 
f ( t )  = c 
-f'"'(O)tn, 
n=O 
where 
(13.201) 
(13.202) 
Since f ( t )  is analytic in and on the contour, where C includes the origin but 
excludes t = 1, we use the above derivatives to write 
n=O 
to obtain 
Ln(x) = - 
dt. 
27rz f 
c (1 - t)tn+l 
(13.204) 
(13.205) 

372 
COMPLEX INTEGRALS AND SERIES 
Note that this is valid for a region enclosed by a circle centered at the origin 
with unit radius. To obtain L,(z) valid for the whole complex plane one might 
expand f ( t )  about t = 1 in Laurent series. 
Another contour integral representation of the Laguerre polynomials can 
be obtained by using the Rodriguez formula 
ex d" 
L,(x) = --(x"e-.). 
n! dxn 
Using the formula 
d(xne-") - n! f f ( z ) d z  
dxn 
2Ti c ( z  - %)"+' 
(13.206) 
(13.207) 
and taking 
as a point on the real axis and 
f(z) = zne-' 
(13.208) 
we can write 
2 K i  
z"ec"dz 
n! 
( z  - X)"+l' 
where C is a circle centered at some point z = x ,  thus obtaining 
(13.209) 
(13.210) 

PROBLEMS 
373 
Problems 
13.1 Use the contour integral representation of the Laguerre polynomials: 
L ( X )  = 1 
27rz f ( z  
znex-zdz 
-x)n+l 
to obtain the coefficients ck in the expansion 
k=O 
13.2 
polynomials: 
Establish the following contour integral representation for the Hermite 
where C encloses the point x, and use it to derive the series expansion 
13.3 Using Taylor series prove the Cauchy-Goursat theorem 
where f ( z )  is an analytic function in and on the closed contour C in a simply 
connected domain. 
13.4 Find the Laurent expansions of the function 
about the origin for the regions 
IzI < 1, 
121 > 2, and 1 < IzI < 2. 
Use two different methods and show that the results agree with each other. 
13.5 Using the path in Figure 13.23 evaluate the integral 
13.6 Evaluate the following integrals: 

374 
COMPLEX INTEGRALS AND SERIES 
Fig. 13.23 Contour for problem 13.5 
2 x  (cos 36) dB 
1 5-4cos6 
ii) 
sin xdx 
x2 + 42 + 5 
iii) 
iv) 
4 
vi) 
dx 

PROBLEMS 
375 
vii) 
viii) 
ix) 
x2 dx 
00 .I, (z + 1)(x2 + 22 + 2) 
dx 
2?r sin2fldfl 
1 a+bcos6 
sinxdx 
J -, 
x(a2 + x2) 
13.7 Evaluate the following Cauchy principal value integral: 
13.8 Using the generating function for the polynomials Pnm (z) 
-xt 
e(1-t) 
= Cpnm 
( Z I P ,  
< 1, m = positive, 
(1 - t)m+' 
n=O 
establish a contour integral representation in the complex t-plane. Use this 
representation to find A(n, m, k )  in 
n 
Pnm (x) = C A ( n , m ,  k)xk. 
k=O 
13.9 Use contour integral techniques to evaluate 
O3 
sin'xdx 
J 
-,x2(1+22)' 
13.10 
a, b are arbitrary real numbers are defined by the Rodriguez formula 
The Jacobi polynomials P27b)(~~s8), 
where n = positive integer and 
dn - 
[( 1 - x)n+"( 1 + Z)rn+b] , 1x1 < 1. 
p p q x )  = 
(-W 
2%!( 1 - z)"( 1 + x ) ~  
dzn 

376 
COMPLEX INTEGRALS AND SERIES 
Find a contour integral representation for this polynomial valid for 1x1 < 1 
and use this to show that the polynomial can be expanded as 
B 
n 
P 2 7 b ) ( ~ ~ ~ 6 )  
= 
A(n, a, b, k)(sin -) ' 
2n-2k (cos 2)2k 
2 
k=O 
Determine the coefficients A(n, a, b, k )  for the special case, where a and b are 
both integers. 
13.11 
on the real axis with the property 
For a function F(z) analytic everywhere in the upper half plane and 
F(z) -+ b as IzI -+ 00 , b is a real constant, 
show the following Cauchy principal value integrals: 
1 
Fl(x')dz' 
FR(z) = b + -P 
lr s_, 
x'-x 
and 
13.12 
function of the first kind 
Given the following contour integral definition of spherical Hankel 
(1) 
where the contour C encloses the point 3: = -1, show that h, 
written as 
(z) can be 
that is, 
i) Show that this series breaks of at the k = Ith term. 
ii) By using the contour integral definition given above, find explicitly the 
constants A(k, I ) ,  and p(l, k). 
13.13 Another definition for the gamma function is given as 
r(z) = z z - ~ e - x ~ e e ( x ) ~ 1 2 x  
, -2 > 0, 
where '(z) is a function satisfying 0 < B(z) < 1. Using the above definition 
show the limit 
= 1. 
q - 2  + 1) 
lim 
5'00 
z"++e-x& 

PROBLEMS 
377 
When x is an integer this gives us the Stirling's approximation to x! as x -+ 
00: 
13.14 Show that 
r(x + 1) = xr(z), for x > 0 
and 
r(n + 1) = n! for n = integer > 0. 
13.15 
Show that 
x 
x2 
23 
n=O 
where the double factorial means 
13.16 
Hankel functions of the first kind, 
Use the factorization method (Chapter 9) to show that the spherical 
(1) - . 
hl 
-Ji fin1, 
can be expressed as 
Hint. First define 
in 

378 
COMPLEX INTEGRALS AND SERIES 
Using this result, define hil)(z) 
as a contour integral in the complex j’-plane 
(j’ = t’ + zs’), where 
d - I d  
dt 
xdx‘ 
Indicate your contour by clearly showing the singularities that must be avoided. 
13.17 
- _ _  
- 
If f (2) is analytic in the lower half of the z-plane, that is, 
f ( z )  + 0 as IzI + 00 for y < 0, 
then show that the Cauchy principal value is given as 
(13.211) 
Identify your two choices for the detour around the singular point on the real 
axis and show that the Cauchy principal value is -z.rrf(a) for both choices. 

FRA CTIONAL 
DERIVATIVES and 
INTEGRALS. 
WIFFERINTEGRALS~~
The diffusion equation in integral form is given as 
(14.1) 
where c ( 7 , t )  is the concentration of particles and f ( 7 , t )  is the current 
density. The left-hand side gives the rate of change of the number of particles 
in volume V, and the right-hand side gives the number of particles flowing 
past the boundary S of this volume per unit time. In the absence of sources 
or sinks, these terms are naturally equal. Using the Gauss theorem we can 
write this equation as 
(14.3) 
This gives us a partial differential equation to be solved for concentration as 
d 
-c(+,t) + 3~7(7,t) 
= 0. 
(14.4) 
at 
In order to solve this equation, we also need a relation between c( T", t )  and 
f ( 7 , t ) .  Because particles have a tendency to flow from regions of high to 
low concentration, as a first approximation we can aSsume a linear relation 
between the current density and the gradient of concentration as 
J = -Icq)~( 
7, 
t). 
-+ 
(14.5) 
379 

380 
FRA CTIONA L DERIVATIVES AND IN TEGRA 1 S: "DIFFERIN TEGRA LS " 
The proportionality constant k is called the diffusion constant. We can now 
write the diffusion equation as 
a 
at 
-c( 7, 
t )  - k P C (  ?, t) = 0, 
(14.6) 
which is also called Fick's equation. 
Einstein noticed that in a diffusion process concentration is also propor- 
tional to the probability, P( ?, t), of finding a diffusing particle at position 
7' and time t. Thus the probability distribution satisfies the same differential 
equation as the concentration. For a particle starting its motion from the 
origin, probability distribution can be found as 
1 
(47rkt)q 
P ( 7 , t )  = 
~ 
(14.7) 
This means that even though the average displacement of a particle is zero 
(< 7' >= 0), mean square displacement is nonzero and is given as 
< T2 >=< T2 > - < 7' 
>2 
= 
r2P(7', t)d3r 
= 6kt. 
(14.8) 
What is important in this equation is the 
<F2>C(t 
(14.9) 
relation. For the particle to cover twice the distance, time must be increased 
by a factor of four. This scaling property results from the diffusion equation 
where the time derivative is of first and the space derivative is of second order. 
However, it has been experimentally determined that for some systems this 
relation goes as 
< T 2  
>K ta, where Q # 1. 
(14.10) 
In terms of the diffusion equation this would imply 
d" 
atQ 
However, what does this mean? Is a fractional 
-P(?,t) 
- kQ32P(7',t) 
= 0, 
k # 1 .  
(14.11) 
derivative possible? If a 
fractional derivative is possible, can we also have a fractional integral? Ac- 
tually, the geometric interpretation of derivative as the slope and integral as 
the area are so natural that most of us have not even thought of the possibil- 
ity of fractional derivatives and integrals. On the other hand, the history of 
fractional calculus dates back as far as Leibniz (1695), and results have been 
accumulated over the past years in various branches of mathematics. The 

UNIFIED EXPRESSION OF DERIVATIVES AND INTEGRALS 
381 
situation on the applied side of this branch of mathematics is now changing 
rapidly, and there are now a growing number of research areas in science and 
engineering that make use of fractional calculus. Chemical analysis of flu- 
ids, heat transfer, diffusion, the Schrodinger equation, and material science 
are some areas where fractional calculus is used. Interesting applications to 
economy, finance, and earthquake science should also be expected. It is well 
known that in the study of nonlinear situations and in the study of processes 
away from equilibrium fractal curves and surfaces are encountered, where or- 
dinary mathematical techniques are not sufficient. In this regard the relation 
between fractional calculus and fractals is also being actively investigated. 
Fractional calculus also offers us some useful mathematical techniques in 
evaluating definite integrals and finding sums of infinite series. In this chapter, 
we introduce some of the basic properties of fractional calculus along with 
some mathematical techniques and their applications. 
14.1 UNIFIED EXPRESSION OF DERIVATIVES AND INTEGRALS 
14.1.1 
Notation and Definitions 
In our notation we follow Oldham and Spanier, where a detailed treatment 
of the subject along with a survey of the history and various applications can 
be found. Unless otherwise specified we use n and N for positive integers, q 
and Q for any number. The nth derivative of a function is shown as 
flf - 
dxn ' 
Since an integral is the inverse of a derivative, we write 
Successive integrations will be shown as 
(14.12) 
(14.13) 
(14.14) 
d-n f 
- 
= I" dxnPl LXn-' 
dxnP2.. . lz2 
dxl 1" f (zo)dzo. 
d [XI-" 
(14.15) 
When the lower limit differs from zero, we will write 
d-'f 
[d(x - u)]-l = Jk" f (X0)dXO 
(14.16) 

382 
FRACTIONAL DERIVATIVES AND INTEGRALS: "DIFFERINTEGRALS" 
d-nf 
= LX 
dxn-, L X n - l  dxnP2 ---lx2 
d q  Lzl f(zo)dzo. (14.17) 
[d(z - a)]-" 
We should remember that even though the equation 
d" 
- 
-- 
dn 
[d(x - a)]" 
[dx]" 
is true for derivatives, it is not true for integrals, that is, 
d-" 
d-- n 
[d(z - a)]-n # w' 
The nth derivative is frequently written as 
(14.18) 
(14.19) 
f (n) (x). 
(14.20) 
Hence for n successive integrals we will also use 
f'-"' 
= L- &,-I 
L;-;l 
dzn- 2 . . . Ly dz1 LI1 f (z0)dxO. 
(14.21) 
When there is no room for confusion, we write 
f ' " ( X >  
The value of a differintegral at x = b is shown as 
Other commonly used expressions for differintegrals are: 
14.1.2 
Before we introduce the differintegral, we derive a unified expression for the 
derivative and integral for integer orders. We first write the definition of a 
derivative as 
The nth Derivative of a Function 

UNIFIED EXPRESSION OF DERIVATIVES AND INTEGRALS 
383 
Similarly, the second- and third-order derivatives can be written as 
and 
- 
d3f = lim {/6z]-3[f(z) 
- 3f(z -6z) + 3f(z - 2 6 ~ )  - f ( ~  
- ~SZ)]}. 
dX3 
6 x 1 0  
(14.24) 
Since the coefficients in these equations are the binomial coefficients, for the 
nth derivative we can write 
In these equations we have assumed that all the derivatives exist. In addition, 
we have assumed that [6z] goes to zero continuously, that is, by taking all 
values on its way to zero. For a unified representation with the integral, we 
are going to need a restricted limit. For this we divide the interval [z - a] into 
N equal segments; 
S N X  = [ z - a ] / N ,  
N = 1,2,3 ,... . 
(14.26) 
In this expression a is a number smaller than z. 
becomes 
Thus Equation (14.25) 
Since the binomial coefficients 
also write 
are zero for the j > n values, we can 
Now, assuming that this limit is also valid in the continuum limit, we write 
the nth derivative as 
- n N - l  
-- 
[dz]" 
d"f - ~
+
m
 
lim { [y] 
[-l]'( '3" ) f ( z - j  [y])}. 
(14.29) 
3 =O 

384 
FRACTIONAL DERfVAJIVES AND INTEGRALS: "DIFFERINTEGRALS" 
14.1.3 Successive Integrals 
We now concentrate on the expression for n successive integrations of f(z). 
Because an integral of integer order is defined as area, we express it as a 
Riemann sum: 
(14.30) 
(14.31) 
(14.32) 
As above, we have taken SNX = [z - a ] / N .  We also write the Riemann sum 
for the double integral as 
and for the triple integral as 
(14.34) 
Similarly for n successive integrals we write 
N-1 
d-" f 
j = O  
[d(z 
-a)]-" 
~ N X - 0  
(14136) 

DIFFERINTEGRALS 
385 
Compared to Equation (14.29), the binomial coefficients in this equation are 
going as 
and all the terms are positive. 
14.1.4 
Unification of Derivative and Integral Operations for Integer 
Orders 
Using Equations (14.29) and (14.36) and also making use of the relation 
(14.37) 
we can write a single expression for both the derivative and integral of order 
nas 
In this equation n takes integer values of both signs. 
14.2 
DIFFERINTEGRALS 
14.2.1 
Griinwald's Definition of Differintegrals 
Considering that the gamma function in the above formula is valid for all 
n, we obtain the most general and basic definition of differintegral given by 
Griinwald as 
In this expression q can take all values. A major advantage of this defini- 
tion (also called the Griinwald-Letnikov definition) is that the differintegral 
is found by using only the values of the function without the need for its 
derivatives or integrals. On the other hand, evaluation of the infinite series 
could pose practical problems in applications. In this formula even though 
the gamma function r(-q) is infinite for the pcxsitive values of q, their ratio 
' ( j  - 9) is finite. 
r( -4 

386 
FRACTIONAL DERIVATIVES AND INTEGRALS: "DIFFERINTEGRALS" 
We now show that for a positive integer n and for all 4 values the following 
relation is true: 
(14.40) 
Using S N X  = [X - a]/N, we can write 
If we further divide the interval a 5 x' 5 x - S N X  into N - 1 equal pieces we 
can write 
(14.43) 
Taking the derivative of Equation (14.41), and using Equation (14.43) gives 
us 
d 
dqf 
- 
dx [d(z - a)]q 
We use the following relation among gamma functions: 
to write this as 
- 
dq+'f 
- 
[d(x - a)]"" 
(14.47) 
The general formula can be shown by assuming this to be true for (n - 1) and 
then showing it for n. 

DIFFERINTEGRALS 
387 
14.2.2 
Riemann-Liouville Definition of Differintegrals 
Another commonly used definition of the differintegral is given by Riemann 
and Liouville. Assume that the following integral is given: 
In(%) = L z ( x -  ~n-lf(t)@, 
(14.48) 
where n is an integer greater than zero and a is a constant. Using the formula 
we find the derivative of I, as 
- 
dIn = (n - 1) S Z ( Z  - E)n-2f(odE + [(x - O"-'f(Ol,=, . 
dx 
a 
For n > 1 this gives us 
and for n = 1 
dIl - 
= f(x). 
dx 
Differentiating Equation (14.50) k times we find 
dk I, 
dxk 
- 
= (n - l)(n - 2). . . (n - k)I,-k, 
which gives us 
dn- I, 
dxn- 
-- - (n - l)!Il(X) 
or 
-- - (n - l)!f(x). 
d" In 
dx" 
(14.49) 
(14.50) 
(14.51) 
(14.52) 
(14.53) 
(14.54) 
(14.55) 
Using the fact that In(a) = 0 for n 2 1, from Equations (14.54) and (14.55) 
we see that In(x) and all of its (n- 1) derivatives evaluated at x = a are zero. 
This gives us 
(14.56) 

388 
FRACTIONAL DERIVATIVES AND INTEGRALS: "DIFFERINTEGRALS" 
and in general 
I&) = (n - l)! J," lXn 
. . . LX3 s,' f(zl)dzldzz -..dz,-ld~,. (14.58) 
From here we obtain a very useful formula also known as the Cauchy for- 
mula: 
f ( z 1 ) d q d z z .  . . dz,_ 1dz, 
(14.59) 
To obtain the Riemann-Liouville definition of the differintegral, we write 
the above equation for all q < 0 as 
However, this formula is valid only for the q < 0 values. In this definition, 
[..]R-L denotes the fact that differintegral is being evaluated by the Riemann- 
Liouville definition. Later, when we show that this definition agrees with the 
Grunwald definition for all q, we drop the subscript. 
We first show that for q < 0 and for a finite function f(z) 
in the interval 
a 5 x' 5 x, the two definitions agree. We now calculate the difference between 
the two definitions as 
(14.61) 
Using definitions (14.39) and (14.60), and changing the range of the integral 
(14.60), we write A as 
(14.62) 
We write the integral in the second term as a Riemann sum to get 
(14.63) 
Taking b ~ x  
= (z - a)/N, this becomes 

DIFFERINTEGRALS 
389 
We now write the sum on the right-hand side as two terms, the first from 
0 to ( j  - 1) and the other from j to (n - 1). Also, assuming that j is suf- 
ficiently large so that we can use the approximation r(j - q)/r(j + 1) = 
j f - q  [1+ q(q + 1)/2j + 0(jf2)] , we obtain 
A =  
(14.65) 
In the first sum, for q < -1, the quantity inside the parentheses is finite and 
in the limit as N -+ 
00, because of the Nq factor it goes to zero. Similarly, for 
q 5 -2, the second term also goes to zero as N + co . Thus we have shown 
that in the interval a 5 x' 5 x, for a finite function f and for q 5 -2, the 
two definitions agree: 
(14.66) 
To see that the Riemann-Liouville definition agrees with the Griinwald 
definition [Eq. (14.39)] for all q, as in the Griinwald definition we require the 
Riemann-Liouville definition to satisfy Equation (14.40): 
In the above formula, for a given q, if we choose n as q - n 5 -2 and use 
Equation (14.66) to write 
(14.68) 
we see that the Griinwald definition and the Riemann-Liouville definition 
agree with each other for all q values: 
(14.69) 

390 
FRACTIONAL DERIVATIVES AND INTEGRALS- “DIFFERIN TEGRALS” 
We can now drop the subscript R-L. 
14.2.2.1 Riemann-Liouville Definition: We now summarize the Riemann- 
Liouville definition: 
For q < 0 the differintegral is evaluated by using the formula 
f ( d ) d d ,  
q < 0. 
(14.70) 
dq f 
1
”
 
[ [d(z - a)]q] = r(-4) ‘. 
- z’1-4-1 
For q 2 0 we use 
where the integer n must be chosen such that ( q  - n) < 0. The Riemann- 
Liouville definition has found widespread application. In this definition the 
integral in Equation (14.70) is convergent only for the q < 0 values. However, 
for the q 2 0 values the problem is circumvented by imposing the condition 
n > q in Equation (14.71). The fact that we have to evaluate an n-fold 
derivative of an integral somewhat reduces the practicality of the Riemann- 
Liouville definition for the q 2 0 values. 
14.3 
OTHER DEFINITIONS OF DIFFERINTEGRALS 
The Griinwald and Riemann-Liouville definitions are the most baqic defini- 
tions of differintegral, and they have been used widely. In addition to these, 
we can also define differintegral via the Cauchy integral formula and by us- 
ing integral transforms. Even though these definitions are not as useful as 
the Griinwald and Riemann-Liouville definitions, they are worth discussing 
to show that other definitions are possible and when they are implemented 
properly they agree with the basic definitions. In the literature sometimes 
fractional derivatives and fractional integrals are treated separately. How- 
ever, the unification of two approaches as the “differintegral” brings these 
two notions closer than one usually assumes and avoids confusion between 
different definitions. 
14.3.1 
Cauchy Integral Formula 
We have seen that for a function f(z) analytic on and inside a closed contour 
C, the nth derivative is given as 
n 2 0 and an integer, 
(14.72) 
d“f(z) 
n! 
where z’ denotes a point on the contour C and z is a point inside C (Fig. 

OTHER DEFINITIONS OF DIFFERINTEGRALS 
391 
Fig. 14.1 Contour C for the Cauchy integral formula 
14.1). We rewrite this formula for an arbitrary q and take z as a point on the 
real axis: 
(14.73) 
For the path shown in Figure 14.1 this formula is valid only for the positive 
integer values of q. For the negative integer values of q it is not defined because 
I‘(q + 1) diverges. However, it can still be used to define differintegrals for 
the negative but different than integer values of q. Now, x is a branch point; 
hence we have to be careful with the direction of the cut line. Thus our 
path is no longer as shown in Figure 14.1. We choose our cut line along the 
real axis and to the left of our branch point. We now modify the contour as 
shown in Figure 14.2 and write our definition of differintegral for the negative, 
noninteger values of q as 
The integral is evaluated over the contour C in the limit as the radius goes 
to infinity. 
Evaluating the integral in Equation (14.74), as it stands, is not easy. Thus 
we modify our contour to C‘ as shown in Figure 14.3. Since the function 
(14.75) 

392 
FRACTIONAL DERIVATIVES AND INTEGRALS: "DIFFERINTEGRALS" 
z-plane 
I 
fig. 14.2 Contour C in the differintegral formula 
is analytic in and on the closed contour C', we can write 
(14.76) 
where the contour C' has the parts 
o 
C' =o c+ 0 co+ + Ll+ -+ L2. 
( 14.77) 
We see that the integral we need to evaluate in Equation (14.74) is equal to 
the negative of the integral (Fig. 14.4) 
f (z')dz' 
f 
oco++LI++L* 
(z' - Z>q+l. 
Part of the integral over CO is taken in the limit as the radius goes to zero. 
For a point on the contour we write 
z' - x = Soeie. 
(14.78) 
Thus for q < 0 and noninteger, the integral jc0 
e
l
 
becomes 

OTHER DEFINITIONS OF DIFFERINTEGRALS 
393 
z-phe 
t 
Fig. 14.3 Contour C' = C + C o  + LI + Lz in the differintegral formula 
which goes to zero in the limit 60 + 0. For the CO integral to be zero in the 
limit 6, 4 0, we have taken q as negative. Using this result we can write 
Equation (14.74) as 
Now we have to evaluate the [ f+L, - f 
+Lz 3 integral. we first evaluate the 
parts of the integral for [-m, 01, which gives zero as 
= 0. 

394 
FRACTIONAL DERIVATIVES AND INTEGRALS: "DIFFfRlNTEGRALS" 
Fig. 14.4 Contours for the $ + L , ,  $+,,, , and jC integrals 
Writing the remaining part of the $, 
dz integral we get 
(
:
!
$
I
 
(14.82) 
After taking the limit we substitute this into the definition [Eq. (14.74)] to 
obtain 
(14.83) 
Simplifying this we can write 
(14.84) 
(14.85) 
To see that this agrees with the Riemarin-Liouville definition we use the fol- 
lowing relation of the gamma function: 
and write 
(14.86) 
-- 
d q f ( x )  
'(' 
Ids 
q < 0 and noninteger. 
(14.87) 
dxq ----.I 
r(-q) 
(x-6)4+" 

OTHER DEF/N/T/ONS OF DIFFERINTEGRALS 
395 
This is nothing but the Riemann-Liouville definition. Using Equation (14.71) 
we can extend this definition to positive values of q. 
14.3.2 
Riemann Formula 
We now evaluate the differintegral of 
f (x) = xp, 
(14.88) 
which is very useful for finding differintegrals of functions the Taylor series of 
which can be given. Using formula (14.84) we write 
SP d6 
-- 
(14.89) 
dxq 
?I- 
s 
0 (6-x)4+1 
dqxp -- 
r(q + l) sin(?I-q)(-1)9 
and 
We define 
- 
- s  
6 
- 
X 
so that Equation (14.90) becomes 
Remembering the definition of the beta function: 
we can write Equation (14.92) as 
Also using the relation (14.86) and 
between the beta and the gamma functions, we obtain the result as 
dqxp 
r ( p  + 1)xP-q 
dxq 
p > -1 and q < 0. 
-- - 
r ( p  + 1 - q) ' 
(14.90) 
(14.91) 
(14.92) 
(14.93) 
(14.94) 
(14.95) 
(14.96) 

396 
FRACTIONAL DERIVATIVES AND INTEGRALS: "DIFFERINTEGRALS" 
Limits on the parameters p and q follow from the conditions of convergence 
for the beta integral. 
For q 2 0, as in the Riemann-Liouville definition, we write 
(14.97) 
and choose the integer n as q - n < 0 . We now evaluate the differintegral 
inside the square brackets using formula (14.71) as 
-- 
(14.98) 
Combining this with the results in Equations (14.96) and (14.98) we obtain a 
formula valid for all q as 
dqxP 
r(p + 1)xP-q 
-- - 
p > - 1 .  
dxq 
r ( p  - q + 1) ' 
(14.99) 
This formula is also known as the Riemann formula. It is a generalization of 
the formula 
m! 
-- - 
xrn-", 
6"X" 
dxn 
(m-n)! 
(14.100) 
for p > -1, where m and n are positive integers. For p 5 -1 the beta function 
is divergent. Thus a generalization valid for all p values is yet to be found. 
14.3.3 
Differintegrals via Laplace Transforms 
For the negative values of q we can define differintegrals by using Laplace 
transforms as 
-- 
dqf - -E-'[sq&] 
, q < 0, 
dxq 
(14.101) 
where F(s) is the Laplace transform of f(x). To see that this agrees with the 
Riemann-Liouville definition we make use of the convolution theorem 
In this equation we take g(x) as 
(14.103) 

OTHER DEFINITIONS OF DIFFERINTEGRALS 
397 
where its Laplace transform is 
(14.104) 
= r(--q)s*, 
(14.105) 
and also write the Laplace transform of f(x) as 
For q < 0 we obtain 
["'I 
= -c-"sq&)] 
, q < o .  
dxq 
(14.106) 
(14.107) 
(14.108) 
The subscripts L and R-L denote the method used in evaluating the differin- 
tegral. Thus the two methods agree for y < 0. 
For q > 0, the differintegral definition by the Laplace transforms is given 
as (Section 14.6.1) 
or 
dq-lf 
dxg- 
sqF(~) - -(o) 
- . . . - sn-'-(O)] 
dxq-n 
. 
(14.110) 
In this definition q > 0 and the integer n must be chosen such that the 
inequality n - 1 < q 5 n is satisfied. The differintegrals on the right-hand 
side are all evaluated via the L method. To show that the methods agree we 
write 
and use the convolution theorem to find its Laplace transform as 
(14.112) 
= ~ q - ~ F ( s ) ,  
q - n < 0. 
(14.113) 

398 
FRACTIONAL DERIVATIVES AND INTEGRALS: "DIFFERINTEGRALS" 
- 
This gives us the sqf(s) = snx(s) relation. 
definition [Eqs. (14.7O-71)] we can write 
Using the Riemann-Liouville 
Since q - n < 0 and because of Equation (14. 108)' we can write 
From the definition of A ( z ) we can also write 
A ( z )  = - 
q - n < O ,  
r(n - q) Jx 
,, 
(z - 
f(r)dr 
T ) Q - " + ~  ' 
(14.114) 
(14.115) 
(14.116) 
As in the Griinwald and Riemann-Liouville definitions we assume that the 
[..]L definition also satisfies the relation [Eq. (14.40)] 
( 14.117) 
where n a is positive integer and q takes all values. We can now write 
which gives us 
Similarly we find the other terms in Ekpation (14.110) to write 
(14.118) 
(14.119) 
(14.120) 

PROPERTIES OF DIFFERINTEGRALS 
399 
Using Equation (14.111) we can now write 
(14.122) 
which shows that for q > 0, too, both definitions agree. 
In formula (14.1 lo), if the function f(x) satisfies the boundary conditions 
(14.123) 
we can write a differintegral definition valid for all q values via the Laplace 
transform as 
-= 
d q f  
-E-l[sQ~(s)]. 
dxq 
(14.124) 
However, because the boundary conditions (14.123) involve fractional deriva- 
tives this will create problems in interpretation and application. (See Problem 
14.7 on the Caputo definition of fractional derivatives.) 
14.4 
PROPERTIES OF DIFFERINTEGRALS 
In this section we see the basic properties of differintegals. These properties 
are also useful in generating new differintegrals from the known ones. 
14.4.1 Linearity 
We express the linearity of differintegrals as 
d9f2 
+ 
d 9 [ f l  + f 2 l  - 
d4f1 
- 
[ d ( x  - ~ ) ] q  [d(x - ~ ) ] q  [d(X - ~ ) ] q *  
(14.125) 
14.4.2 
Homogeneity 
Homogeneity of differintegrals is expressed as 
Co is any constant. 
(14.126) 
d Q ( C o f )  =Co 
d q f  
[ d ( z  - ~ ) ] q  
[ d ( x  - 
~ ) ] q  ' 
Both of these properties could easily be seen from the Griinwald definition 
[Eq. (14.39)) 

400 
FRACTIONAL DERIVATIVES AND INTEGRALS. "DIFFERIN TEGRALS" 
14.4.3 
Scale Transformation 
We express the scale transformation of a function with respect to the lower 
limit a as 
f 
+ f(rz - ya + 4, 
(14.127) 
where y is a constant scale factor. If the lower limit is zero, this means that 
f ( 4  
-+ f(r.)- 
(14.128) 
If the lower limit differs from zero, the scale change is given as 
d q f ( y X )  
x = z + [a - ay]/y 
(14.129) 
d Q f ( y X )  - 
- 
[d(z - a)]q 
" [ d ( y X  - a)]Q' 
This formula is most useful when a is zero: 
(14.130) 
14.4.4 
Differintegral of a Series 
Using the linearity of the differintegral operator we can find the differintegral 
of a uniformly convergent series for all q values as 
(14.131) 
Differintegrated series are also uniformly convergent in the same interval. For 
functions with power series expansions, using the Riemann formula we can 
write 
dQ c 
O0 
- a ] P + ( j / n )  = 
I- (pn +: + 
[. - a]P-q+(.i/n) 
00 
(14.132) 
where q can take any value, but p + (j/n) > -1, a0 # 0, and n is a positive 
integer. 
) 
[d(z - .)I" 
j=o 
z
a
j
 I- ( p n  - q;+ 
j + n 
14.4.5 
Composition of Differintegrals 
When working with differintegrals one always has to remember that operations 
like 
dqd& = dQdQ, 
dQ& = dq+Q and 
d9f = g +  f =d-qg 
(14.133) 

PROPERTIES OF DIFFERINTEGRALS 
401 
are valid only under certain conditions. In these operations problems are not 
just restricted to the noninteger values of q and Q. 
When n and N are positive integer numbers, from the properties of deriva- 
tives and integrals we can write 
d" 
dN f 
dn+N f 
[d(z - a)]" { [d(z - a,].} 
= [d(z - a)]n+N 
(14.134) 
- 
- 
and 
f 
(14.135) 
d-n-N 
- 
However, if we look at the operation 
[d(z d*n 
- a)]*" { [ d ( ~  
diNf 
- .)ITN 1, 
(14.136) 
the result is not always 
d * n i N  f 
[d(z - u)]*"?" 
( 14.137) 
Assume that the function f (z) has continuous Nth-order derivative in the 
interval [a, b] and let us take the integral of this Nth-order derivative as 
We integrate this once more: 
and repeat the process n times to get 
(14.140) 
(. 
- a)"-' 
1 -  
f ( N -  y u ) .  
(n - l)! 

402 
FRACTIONAL DERIVATIVES AND INTEGRALS- "DIFFERINTEGRALS" 
Since 
we write 
(14.142) 
Writing Equation (14.142) for N = 0 gives us 
n- 1 
k! 
k=O 
[d(z - a)]-" 
(14.143) 
We differentiate this to get 
f("-")(a). 
(14.144) 
[x - a]k- 
n- 1 
( k  - l)! 
k= 1 
After N-fold differentiation we obtain 
f('"-")(u). (14.145) 
I. - 
n- 1 
(k - N ) !  
k = N  
For N 2 n, remembering that differentiation does not depend on the lower 
limit and also observing that in this case the summation in Equation (14.145) 
is empty, we write 
d N - n f  
= f(N-")(z). (14.146) 
On the other hand for N < n, we use Equation (14.143) to write 
d N - n  
n - N - 1  
(a). 
(14.147) 
k! 
[d(z - f 3) lN - n  
k=O 
This equation also contains Equation (14.146). In Equation (14.145) we now 
make the transformation 
k + k + N  
(14.148) 
to write 
n - N - 1  
(a)- 
k! 
(14.149) 

PROPERTIES OF DIFFERINTEGRALS 
403 
Because the right-hand sides of Equations (14.149) and (14.147) are identical, 
we obtain the composition rule for n successive integrations followed by N 
differentiations as 
(14.150) 
To find the composition rule for the cases where the differentiations are 
performed before the integrations, we turn to Equation (14.142) and write 
the sum in two pieces as 
Comparing this with Equation (14.147), we now obtain the composition rule 
for the cases where N-fold differentiation is performed before n successive 
integrations as 
n- 1 
k 
(a). 
- 
( N + k - n )  
f 
k! 
k=n- N 
(14.152) 
Example 14.1. Composition of differintegrak: For the function f (x) = 
, we first calculate 
e -3x 
For this case we use Equations (14.150) and (14.143) to find 
d - 3  f ( 2 )  
d-2 f (x) 
&{F>=w 
e- 3x  
X
I
 
---+---. 
9 
3
9
 
- 
- 
(14.153) 
On the other hand, for 
we have to use formula (14.152). Since N = 1 and n = 3, k takes only 
the value two, thus giving 
(14.154) 

404 
FRACTIONAL DERIVATIVES AND INTEGRALS: “DIFFERINTEGRALS” 
14.4.5.1 
any value, composition of differintegrals as 
Composition Rule for General q and Q: When q and Q take 
(14.155) 
dq+Q f 
[d(z dq - ~ ) ] q  [d(z dQf 
- a)]& 1 = [d(z - a)]q+Q 
is possible only under certain conditions. It is needless to say that we assume 
all the required differintegrals exist. Assuming that a series expansion for 
f (z) can be given as 
W 
f (z) = 
uj[z - aIp+j, p is a noninteger such that p + j > -1, 
(14.156) 
j=O 
it can be shown that the composition rule [Eq. 
functions satisfying the condition 
(14.155)] is valid only for 
(14.157) 
In general, for functions that can be expanded as Equation (14.156) differin- 
tegrals are composed as (Oldham and Spanier) 
- 
- 
(14.158) 
For such functions violation of condition (14.157) can be shown to result from 
the fact that & 
vanishes even though f (x) is different from zero. From 
here we see that, even though the operators 6
0
 
and &
a
 
are in 
general inverses of each other, this is not always true. 
In practice it is difficult to apply the composition rule as given in Equation 
(14.158). Because the violation of Equation (14.157) is equivalent to the 
d Q f ( x )  
vanishing of the derivative Q
‘
,
 
let us first write the differintegral (for 
&I 
simplicity we set a = 0) of f(z) 
as 
Because the condition p + j > -1 (or p > -1), the gamma function in the 
numerator is always different from zero and finite. For the Q < p + 1 values, 
gamma function in the denominator is always finite; thus condition (14.157) 
is satisfied. For the remaining cases condition (14.157) is violat,&. We now 

PROPERTIES OF DtFFERlNTEGRALS 
405 
check the equivalent condition 
= 0 to identify the terms responsible 
for the violation of condition (14.157). For the derivative 
to vanish, 
from Equation (14.159) it is seen that the gamma function in the denominator 
must diverge for all uj # 0, that is, 
[dxl 
p + j  - Q + 1 = 0, -1, -2, ... . 
For a given p (> -1) and positive Q, j will eventually make ( p  - Q + j + 1) 
positive; therefore we can write 
p + j  = Q - l , Q  - 2, ..., Q - m 
(14.160) 
where m is an integer satisfying 
O <  Q < m <  Q+1. 
(14.161) 
For the j values that make ( p  - Q + j + 1) positive, the gamma function 
in the denominator is finite, and the corresponding terms in the series satisfy 
condition (14.157). Thus the problem is located to the terms with the j values 
satisfying Equation (14.160). Now, in general for an arbitrary diffferintegrable 
function we can write the expression 
d-Q 
f (z) - - 
[ 51 = coxQ-' + clzQ-2 + .. . + cmzQ-,, 
(14.162) 
[dzl-Q 
[&]Q 
where c1, c2, ...) c, are arbitrary constants. Note that the right-hand side of 
Equation (14.162) is exactly composed of the terms that vanish when 
# 
0, that is, when Equation (14.157) is satisfied. This formula, which IS very 
useful in finding solutions of extraordinary differential equations can now be 
used in Equation (14.158) to compose differintegrals. 
Another useful formula is obtained when Q takes integer values N in Equa- 
tion (14.158). We apply the composition rule [Eq. (14.158)] with Equation 
(14.142) written for n = N ,  and use the generalization of the Riemann for- 
mula: 
1"11 
(14.163) 
to obtain 
- 
dq+N f 
- 
- 
[d(z - U)]"+" 
(14.164) 

406 
FRACTIONAL DERIVATIVES AND INTEGRALS: "DIFFERINTEGRALS" 
Example 14.2. Composition of diffeerintegmls: As another exampie we 
consider the function 
f = x-w 
(14.165) 
for the values a = 0, Q = 1/2, and q = -1/2. Since condition (14.157) 
is not satisfied, that is, 
(14.166) 
# 0, 
(14.167) 
- 
- x- 1/2 - 0 
we have to use Equation (14.158): 
(14.168) 
Since 
we have 
which leads to 
(14.169) 
(14.170) 
(14.171) 
1 
Contrary to what we expect 
d-' 
is not the inverse of 
d z  for x-lI2. 
a 
3 
Example 14.3. Inverse of differintegmk: We now consider the function 

PROPERTIES OF DIFFERINTEGRALS 
407 
f = x  
(14.174) 
for the values Q = 2 and a = 0. Since 
d2 x 
- = 0  
[d5Cl2 
is true, contrary to our expectations we find 
d-' 
d2x 
-- 
= 0. 
[ d ~ ] - ~  
[dxI2 
(14.175) 
( 14.176) 
The problem is again that the function f = x does not satisfy condition 
(14.157). 
14.4.6 
Leibniz's Rule 
The differintegral of the qth order of the multiplication of two functions f and 
g is given by the formula 
where the binomial coefficients are to be calculated by replacing the factorials 
with the corresponding gamma functions. 
14.4.7 
Right- and Left-Handed Differintegrals 
The Riemann-Liouville definition of differintegral was given as 
where k is an integer satisfying 
k = O  
for 
q < 0 
k - l < q < k  
for 
4 2 0 .  
( 14.179) 
This is also called the right-handed Riemann-Liouville definition. If f (t) is a 
function representing a dynamic process, in general t is a timelike variable. 
The principle of causality justifies the usage of the right-handed derivative 
because the present value of a differintegral is determined from the past values 
off (t) starting from an initial time t = a. Similar to the advanced potentials, 
it is also possible to define a left-handed Riemann-Liouville differintegral as 

408 
FRACTIONAL DERIVATIVES AND INTEGRALS: "DIFFERINTEGRALS" 
where k is again an integer satisfying Equation (14.179). Even though for 
dynamic processes it is difficult to interpret the left-handed definition] in 
general the boundary or the initial conditions determine which definition is 
to be used. It is also possible to give a left-handed version of the Griinwald 
definition. In this chapter we confine ourselves to the right-handed definition. 
14.4.8 
We now discuss the dependence of 
Dependence on the Lower Limit 
dq f fx) 
- .)I" 
(14.181) 
on the lower limit. For q < 0, using Equation (14.178) we write the difference 
d Q f ( 4  - dQf 
6 =  
[d(x - u)]Q [d(. - b)]Q 
as 
(14.182) 
For the binomial coefficients we write 
( - " i q  ) = 
to obtain 
d- 
( see Section 14.5.1) 
03 
- 
- 
I =o 
(14.184) 
(14.185) 

DIFFERINTEGRALS OF SOME FUNCTIONS 
409 
Even though we have obtained this expression for q < 0, it is also valid for all 
q (Oldham and Spanier, Section 3.2). For q = 0,1,2, ..., that is, for ordinary 
derivatives, we have 
S = 0  
(14.186) 
as expected. For q = -1 the above equation simplifies to 
(14.187) 
For all other values of q, S not only depends on a and b but also on x. This is 
due to the fact that the differintegral, except when it reduces to an ordinary 
derivative, is a global operator and requires a knowledge of f over the entire 
space. This is apparent from the Riemann-Liouville definition [Eq. (14.178)], 
which is given as an integral, and the Griinwald definition [Eq. (14.39)] which 
is given as an infinite series. 
14.5 
DIFFERINTEGRALS OF SOME FUNCTIONS 
In this section we discuss differintegrals of some selected functions. For an 
extensive list and discussion of the differintegrals of functions of mathematical 
physics we refer the reader to Oldham and Spanier. 
14.5.1 
Differintegral of a Constant 
First we take the number one and find its differintegral using the Griinwald 
definition [Eq. (14.39)] as 
Using the properties of gamma functions; Cy=il r(j - q)/I'(-q)I'(j + I) = 
r ( N  - q)/r(l- q ) r ( N ) ,  and limN,oo[N*r(N - q) / r( N ) ]  = 1, we find 
(14.189) 
When q takes integer values, this reduces to the expected result. 
arbitrary constant C, including zero, the differintegral is (see Problem 14.7) 
For an 
(14.190) 

410 
FRACTIONAL DERIVATIVES AND INTEGRALS: "DIFFERINTEGRALS" 
14.5.2 
For the differintegral of [z - a] , we again use Equation (14.39) and write 
Differintegral of [Z - a] 
q N - l  
dq[x - U] 
r(j - q) 
[,v, -; 
+ j a  
[d(z -a)]" 
N+cc 
(14.191) 
In addition to the properties used in Section 14.5.1, we also use the fol- 
lowing relation between the gamma functions: C,"='r(j - q)/r(-q)r(j) 
= 
(-q)r(N - q)/r(2 - q)r(N - l), to obtain 
dq[z - u] - [z - 4 - q  
[d(z - u)]q - 
r(2 - q) ' 
(14.193) 
(14.194) 
We now use the Riemann-Liouville formula to find the same differintegral. 
We first write 
d q [ ~  - U ]  
[z' - a]dz' 
- 
r(-d 
[z - z ' ] q + l  
For y < 0 values we make the transformation y = z - z' and write 
dQ[x - U ]  
[d(z - .>1q 
rY-4 
(14.195) 
(14.196) 
which leads us to 
(14.198) 
(14.199) 
(14.200) 

DIFFERINTEGRALS OF SOME FUNCTIONS 
411 
For the other values of q we use formula (14.40) to write 
1 
(14.201) 
and choose n such that q - n < 0 is satisfied. We use the Riemann formula 
[Eq. (14.99)] to write 
(14.202) 
which leads to the following result: 
- r(2 - + n) [Z - 
- 
r(2 - q) r(2 - + 
- [x - u
p
 
- 4) . 
- 
(14.204) 
(14.205) 
This is now valid for all q. 
14.5.3 
Here there is no restriction on p other than p > -1. 
We start with the 
Riemann-Liouville definition and write 
Differintegral of [Z - u]” ( p  > -1) 
(14.206) 
When we use the transformation z’ - a = v, this becomes 
Now we make the transformation v = ( x  - a)u to write 
Using the definition of the beta function [Eq. (13.151)] and its relation with 
the gamma functions, we finally obtain 
(14.209) 
(14.210) 
where q < 0 and p > -1. Actually, we could remove the restriction on q and 
use Equation (14.210) for all q (see the derivation of the Riemann formula 
with the substitution x -+ x - a ). 

412 
FRACTIONAL DERIVATIVES AND INTEGRAlSr"DIFFERINTEGRA1S" 
14.5.4 
To find a formula valid for all p and q values we write 
Differintegral of [1 - z ] ~  
1 - z = 1 - u - (z - u) 
and use the binomial formula to write 
(14.211) 
M 
( 1 -  
p -  
r(pf ') 
(-l)j(l - u)p-j(z - a)j. 
(14.212) 
- r(j + i)r(p - j + i) 
We now use Equation (14.132) and the Riemann formula (14.99), along with 
the properties of gamma and the beta functions to find 
where B, is the incomplete beta function. 
14.5.5 
Differintegral of exp(fz) 
We first write the Taylor series of the exponential function as 
(14.213) 
(14.214) 
and use the Riemann formula (14.99) to obtain 
where y* is the incomplete gamma function. 
14.5.6 
Differintegral of In( Z) 
For all values of q the differintegral of ln(z) is given as 
(14.216) 
where y is the Euler constant, the value of which is 0.5772157, and the $(x) 
function is defined as 
(14.217) 

MATHEMATICAL TECHNIQUES WITH DIFFERINTEGRALS 
413 
14.5.7 
Some Semiderivatives and Semi-integrals 
We conclude this section with a table of the frequently used semiderivatives 
and semi-integrals of some functions: 
I 
f 
I 
d4 f /[dx] 
3 
I 
d - i  f / [ & ] - $  
I 
14.6 
MATHEMATICAL TECHNIQUES WITH DIFFERINTEGRALS 
14.6.1 
Laplace Transform of Differintegrals 
The Laplace transform of a differintegral is defined as 
(14.218) 
When q takes integer values, the Laplace transforms of derivatives and inte- 
grals are given as 
(14.219) 
dxq 
k=O 
E - =SqE{f},q=0,-1,-2 
,.... 
{ Z }  
We can unify these equations as 
(14.220) 
n- 1 
(0), n = O,fl,&2,f3, .._ 
k=O 
(14.221) 

414 
FRACTIONAL DERIVATIVES AND INTEGRALS: "DIFFERINTEGRALS" 
In this equation we can replace the upper limit in the sum by any number 
greater than n-1. We are now going to show that this expression is generalized 
for all q values as 
(14.222) 
where n is an integer satisfying the inequality n - 1 < q 5 n . 
as 
We first consider the q < 0 case. We write the Riemann-Liouville definition 
and use the convolution theorem 
where we take 
f l ( z )  = x - ~ - '  and f ~ ( x )  
= f ( x )  
to write 
(14.223) 
(14.224) 
(14.225) 
= sQL{f}. 
For the q < 0 values the sum in Equation (14,222) 
is empty. Thus we see that 
the expression in Quation (14.222) is valid for all q < 0 values. 
For the q > 0 case we write the condition [Eq. (14.40)] 
that the Griinwald 
and Riemann-Liouville definitions satisfy as 
(14.226) 
where n is positive integer, and choose n as 
n - l < q < n .  
(14.227) 
We now take the Laplace transform of Equation (14.226) 
to find 
dq-nf 
n-l 
= S n L { - } - ~ s k ~  [z] 
(0), q - n < 0 .  
(14.228) 
k=O 
dxqpn 

MATHEMATICAL TECHNlQUES WITH DIFFERINTEGRALS 
415 
Since q - n < 0, from Equations (14.223-225) the first term on the right-hand 
side becomes sqE{f}. When n - 1 - k takes integer values, the term, 
dn- 1- k - 
&n-I-k [-I dxq-n 
(O), 
under the summation sign, with the q - n < 0 condition and the composition 
formula [Eq. (14.226)], can be written as 
dq-1-k 
dxq- 1-k ' 
(O), 
which leads us to 
n- 1 
dq-1-k 
k=O 
'(O), 
0 < q # 1,2,3 ... . 
(14.229) 
dxq-1-k 
We could satisfy this equation for the integer values of q by taking the condi- 
tion n - 1 < q 5 n instead of Equation (14.227). 
Example 14.4. Heat transfer equation: We consider the heat transfer 
equation for a semi-infinite slab: 
(1 4.230) 
K is the heat transfer coefficient, which depends on conductivity, den- 
sity, and the specific heat of the slab. We take T(z,t) as the difference 
of the local temperature from the ambient temperature; t is the time, 
and x is the distance from the surface of interest. As the boundary 
conditions we take 
T(x,O) = 0 
(14.231) 
and 
T(m,t) = 0. 
(14.232) 
Taking the Laplace transform of Equation (14.230) with respect to t we 
get 
a q x ,  s) 
sF(x, s) - T(x, 0) = K 
ax2 
' 
(14.233) 
(14.234) 

416 
FRACTIONAL DERIVATIVES AND INTEGRALS: "DIFFERINTEGRALS" 
- 
a2F(x, s) 
sT(x, s) = K 
ax2 
. 
(14.235) 
Using the boundary condition [Eq. (14.232)] we can immediately write 
the solution, which is finite for all x as 
F(x, s) = F ( s ) e - " r n ,  
(14.236) 
In this solution F(s) is the Laplace transform of the boundary condition 
T(0,t) : 
F(s) = ' 
{T(O,t)) 
? 
(14.237) 
which remains unspecified. In most of the engineering applications we 
are interested in the heat flux, which is given as 
(14.238) 
where k is the conductivity. In particular, the surface flux given by 
(14.239) 
For the surface flux we differentiate Equation (14.236) with respect to 
X a S  
and eliminate F( s) by using Equation (14.236) to get 
& F T ( x ,  s). 
(14.240) 
(14.241) 
We now use Equation (14.229) and choose n = 1: 
Using the other boundary condition [Eq. (14.231)] the second term on 
the right-hand side is zero; thus we write 
(14.243) 
= s'/2F(z, s). 
Substituting Equation (14.241) into this equation and taking the inverse 
Laplace transform we get 
(14.244) 

MATHEMATICAL TECHNIQUES WlTH DIFFERINTEGRALS 
417 
Using this in the surface heat flux expression we finally obtain 
J(0, t )  = -k - 
"2 t, 
(14.245) 
(14.246) 
The importance of this result is that the surface heat flux is given in 
terms of the surface temperature distribution, that is T(0, t), which is 
experimentally easier to measure. 
14.6.2 
Extraordinary Differential Equations 
An equation composed of the differintegrals of an unknown function is called 
an extraordinary differential equation. Naturally, solutions of such equations 
involve some constants and integrals. A simple example of such an equation 
can be given as 
(14.247) 
Here Q is any number, F(x) is a given function, and f(x) is the unknown 
function. For simplicity we have taken the lower limit a as zero. We would 
like to write the solution of this equation simply as 
(14.248) 
dQ 
dx-Q 
dxQ 
and - 
are not the inverses 
However, we have seen that the operators - 
of each other, unless condition 
d-Q 
(14.249) 
is satisfied. It is for this reason that extraordinary differential equations are 
in general much more difficult to solve. 
A commonly encountered equation in science is 
(14.250) 
For n = 1 the solution is given as an exponential function 
x(t) = zoexp(-at). 
(14.251) 
For n # 1 solutions are given with a power dependence as 

418 
FRACTIONAL DERIVATIVES AND INTEGRALS: "DIFFERINTEGRALS" 
Solutions of 
dnz 
dt" - 
= (Fa)%, n = 1,2' ... 
(14.253) 
are the Mittag-Lef€ler functions 
which correspond to extrapolations between exponential and power depen- 
dence. A fractional generalization of Equation (14.253) as 
is frequently encountered in kinetic theory, and its solutions are given in terms 
of the Mittag-Leffler functions as 
N ( t )  = NoE,(-aQtQ). 
14.6.3 
Mittag-Leffler Functions 
Mittag-Leffler functions are encountered in many different branches of science 
such as; biology, chemistry, kinetic theory, and Brownian motion. They are 
defined by the series (Fig. 14.5) 
(14.255) 
For some a values Mittag-Leffler functions are given as 
1 
1 - 2  
El&) = - 
El (z) = exp(z) 
&(z) = cosh(& 
(14.256) 
E~(z) 
= -[exp(*) 
1 
+ 2exp(-$i/2)cos(y \/5 %)] 
3 
1 
2 
Ed(%) = -[COS( $6) +cash( s)] 
A frequently encountered Mittag-Leffler function is given for the 4 = 1/2 
value and can be written in terms of the error function as 
E1p(.t&) = exp(z) [I +erf(&&] 
, z > 0. 
(14.257) 

MATHEMATICAL TECHNIQUES WITH DIFFERINTEGRALS 
419 
Fig. 14.5 Mittag-Leffler functions 
14.6.4 Semidifferential Equations 
In applications we frequentIy encounter extraordinary differential equations 
like 
d3 f 
d3f2 f 
- 
+ sin(x)- 
= exp(2x), 
dx3 
dx3f 
(14.258) 
(14.259) 
which involves semiderivatives of the unknown function. However, an equation 
d3j2F 
+5f=- 
d4f 
d3f 
dx4 
dx3 
dxV 2 ' 
--- 
(14.260) 
where F ( x )  is a known function is not considered to be a semidifferential 
equation. 
Example 14.5. Semidifferential equation solution: Consider the folIow- 
ing semidifferential equation: 
d1f2 
- 
f + af = 0, a = constant. 
dx'f2 
(14.261) 
d'f2 
Applying the - 
operator to this equation and using the composition 
rule [Eq. (14.158)] with Equation (14.162), and with m taken as one we 
dx1/2 

420 
FRACTIONAL DERIVATIVES AND INTEGRALS: “DIFFERIN TEGRALS” 
Using Equation (14.261) again we find 
(14.262) 
(14.263) 
This is a first-order ordinary differential equation the solution of which 
is given as 
f(x) = Cexp(a2z) + Cl exp(a2z) 
exp(-~~x’)x’-~/~dz’ 
. (14.264) 
What is new is that the solution involves two integration constants and 
a divergent integral. However, this integral can be defined by using the 
incomplete gamma function y*(c, x), which is defined as 
-y*(c,x) = - x’”-l exp(-x’)dx’ 
(14.265) 
W )  
c-x 1‘; 
0 
(14.266) 
where y*(c, x) is a singlevalued and analytic function of c and x. Using 
the relations 
y*(c- 1,x) = zy*(c,z) + - 
eXP(-X) 
(14.267) 
r(c) 
and 
(14.268) 
we can determine the value of the divergent integral: 
I = 
e~p(--a~x’)z‘-~/~d& 
(14.269) 
to be 
exp(-u2x) 
&
.
 
I = -2aJ;;erf(&G) 
- 2a 
(14.270) 
Substituting this into Equation (14.264), we find the solution 
= Cexp(a2z) - 
(14.272) 

MATHEMATICAL TECHNIQUES WITH DIFFERINTEGRALS 
421 
This solution still contains two arbitrary constants. To check that it sat- 
isfies the semidifferential Equation (14.261), we first find its semideriva- 
tive as 
where we have used the scale transformation formula [Eq. 14.130)] and 
the semiderivative given in Section 14.5.7. Substituting the above equa- 
tion into Equation (14.261) gives 
+ Cexp(a2z) erf(&) 
- 2a&C1 exp(a2x) 
(14.273) 
I 
C 
thus we obtain a relation between C and C'l as 
r( 
L, - 
= 2aC1. 
J?-; 
Now the final solution is obtained as 
(14.274) 
(14.275) 
14.6.5 
We have seen how analytic continuation and complex integral theorems can 
be used to evaluate some definite integrals. Fractional calculus can also be 
used for evaluating some definite integrals. Using the transformation 
2' = 2 - zx 
(14.276) 
and the Riemann-Liouville definition Equations (14.70-71), we can write the 
differintegral of the function xq as 
Evaluating Definite Integrals by Differintegrals 
(14.277) 
= r(Q + I), 
where -1 < q < 0 and we have used Equation (14.210) to write dQzQ/dxq = 
r(q + 1). Making one more transformation, 
t = - ln(X), 
(14.278) 
we obtain the following definite integral: 
(14.279) 
= r(-4)r(q + 11, 
= -ncsc(q7r), - 1 < q < 0. 
(14.280) 

422 
FRA CTIONA L D ERlVA TIVES AND INTEGRALS: "DIFFERIN TEGRA LS " 
We can also use the transformation [&. (14.276)] in the Riemann-Liouville 
definition for an arbitrary function to write (Oldham and Spanier) 
(14.281) 
If we also make the replacements A-4 --+ t and -l/q 
-+ p ( p  is positive but 
does not have to be an integer) to obtain the formula 
this is very useful in the evaluation of some definite integrals. As a special 
case we may choose x = 1 to write 
(14.283) 
Example 14.6. Evaluation of some definite integrals by diflerintegrals: 
Using differintegrals we evaluate 
l ' e x p ( 2  - 2t2I3)dt. 
(14.284) 
Using formula (14.281) with x = 2 and p = 2/3 along with Equation 
(14.215) we find 
n 
(14.285) 
In 1972 Osler gave the integral version of the Leibniz rule [Eq. (14.177)], 
which can be useful in evaluating some definite integrals as 
where y is any constant. 
Example 14.7. Evaluation of definite integrals by differintegrals: 
In the Osler formula we may choose f = xa, y = xp, y = 0 to write 
oo 
qq + i)qa + i)r(p + i)x-+X+P-Xdx 
r(q - x + q r ( x  + i ) r ( a  - q+ x + i ) r ( p  - x + 1)' 
dxq 

MATHEMATICAL TECHNIQUES WITH DIFFERINTEGRALS 
423 
Using the derivative [Eq. (14.210)] 
dq[xa+4] - r(a + ,# + l)z"+B-q 
-- 
dxq 
r(a + p - q + 1) 
and after simplification, we obtain the definite integral 
r(q + i ) r ( a  + i)r(p + i ) d x  
(14.287) 
Furthermore, if we set ,# = 0 and a - q + 1 = 1 so that we can use the 
relation 
to obtain the following useful result: 
(14.288) 
14.6.6 
In 1970 Osler gave the summation version of the Leibniz rule, which is very 
useful in finding sums of infinite series: 
Evaluation of Sums of Series by Differintegrals 
(14.289) 
dP-Y-nU 
-- 
r(q + 1) 
00 
= 
r(q - y - n + l)r(y + n + 1) d ~ q - y - ~  
d ~ y + ~ '  
n=-00 
where y is any constant.. 
Example 14.8. Evaluation of sums of series by dzfferintegmls: In the 
above formula, we choose u = xa, v = zp, y = 0 and use Equation 
(14.210) to obtain the sum 
- r(a+p+ 1) 
- r(a+P-q+ 1)' 
Furthermore, we set (Y = -1/2, /3 = l/2, q = -1/2 to get 
2 
- -  
- 
OC) 
[(2n)!I2 
24n(n!)4(1 -2n) 
?r' 
n=O 
(14.290) 

424 
FRACTIONAL DERIVATIVES AND INTEGRALS: "DIFFERINTEGRALS" 
14.6.7 
Using (14.289) we can also express hypergeometric functions and some special 
functions as differintegrals (Osler 1970): 
Special Functions Expressed as Differintegrals 
Hypergeometric Functions : 
Confluent hypergeometric Functions 
Bessel Functions : 
Legendre Polynomials 
(1 - x2)V 
1 
d" 
pV(x) = r(v + 1)2" d( 1 - 
Incomplete gamma Function : 
dPaex 
r*(a,z) = r(a)ecX- 
dx- 
14.7 
APPLICATIONS OF DIFFERINTEGRALS IN SCIENCE AND 
ENGINEERING 
14.7.1 
Continuous Time Random Walk (CTRW) 
We have seen that the diffusion equation is given as 
dc( 7, 
t )  
-- 
- -3 . b(7, 
t), 
at 
(14.291) 
where T(?",t) 
represents the current density and c(?",t) is the concentra- 
tion. As a first approximation we can assume a linear relation between f 
and the gradient of the concentration as 
f = - k v c ,  k is the diffusion constant. 
(14.292) 
This gives the partial differential equation to be solved for c( 7, 
t) as 
(14.293) 
To prove the molecular structure of matter, Einstein studied the random m e  
tion of particles in suspension in a fluid. This motion is also known as Brown- 
ian motion and results from the random collisions of the fluid molecules with 
L
=
k
p
 
a C ( T  t) 
+ 
c( r ,t)- 
at 

APPLlCATlONS OF DlFFERlNTEGRALS IN SClENCE AND ENGlNEERlNG 
425 
the particles in suspension. Diffusion is basically many particles undergoing 
Brownian motion at the same time. Hence, division of the concentration C(T, t) 
by the total number of particles gives us the probability of finding a particle 
at position 7 
and time t as 
I 
P( 7, 
t) = zp( F, t). 
Thus P ( 7 ,  t) satisfies the same differential equation as the concentration: 
(14.294) 
In d dimensions and for a particle initially at the origin, the solution of Equa- 
tion (14.294) is a Gaussian: 
(14.295) 
In Brownian motion, even though the mean distance covered is zero 
< 7 ( t )  >= 
7P(7, 
t)d? = 0, 
(14.296) 
s 
the mean square distance is given as 
< ?(t) >= p ( T + , t ) d ? "  = 2kclt. 
(14.297) 
This equation sets the scale of the process as 
< 2 ( t )  >a t. 
(14.298) 
Hence the root mean square of the distance covered by a particle is 
VfZqjT 
a t'/2. 
( 14.299) 
In Figure 14.6, the first figure shows the distance covered by a Brown particle. 
In Brownian motion or Einstein random walk, even though the particles are 
hit by the fluid particles symmetrically, they slowly drift away from the origin 
with the relation (14.299). 
In Einstein's theory of random walk steps are taken with equal intervals. 
Recently theories in which steps are taken according to a waiting distribution 
3 ( t )  have been developed. This distribution function essentially carries infor- 
mation about the delays and the traps present in the system. Thus, in a way, 
memory effects are introduced to the random walk process. These theories 
are called continuous time random walk (CTRW) theories. In CTRW, if the 
integral 
r = S t q ( t ) d t ,  
(14.300) 

426 
FRACTIONAL DERIVATIVES AND INTEGRALS: "DIFFERINTEGRALS" 
r~ 
. 3  
'2 
Fig. 14.6 Random walk and CTRW 
that gives the average waiting time of the system is finite, we can study the 
problem by taking the diffusion constant in Equation (14.294) as a2/2r. If the 
average waiting time is divergent, as in 
(14.301) 
the situation changes dramatically. In CTRW theories < r 2  > in general 
grows as 
< r2 >a t'. 
( 14.302) 
Cases with cy < 1 are called subdiffusive and as shown in the second figure in 
Figure 14.6 the distance covered is less than Einstein's theory. On the other 
hand, cy > 1 cases are called superdiffusive and more distance is covered. 
In CTRW cases, waiting times between steps changes (Sokolov, Klafter, and 
Blumen, 2002). This is reminiscent of stock markets or earthquakes, where 
there could be long waiting times before the systems make the next move. 
For the a = 1/2 value, the root mean square distance covered is given by 
J2-7-7 a t1I4 
(14.303) 
and the probability distribution P(T',t) behaves like the second curve in 
Figure 14.7, which has a cusp compared to a Gaussian. 

APPLICATIONS OF DIFFERINTEGRALS IN SCIENCE AND ENGINEERING 
427 
Fig. 14.7 Probability distribution in random walk and CTRW 
An important area of application for fractional derivatives is that the ex- 
traordinary diffusion phenomenon, studied in CTRW, can also be studied by 
the differintegral form of Equation (14.294) as 
(14.304) 
Another advantage of this approach is that known solutions for simple cases 
can be used as seeds to generate solutions for more complicated cases. 
14.7.2 Fractional Fokker-Planck Equations 
In standard diffusion problems particles move because of their random colli- 
sions with the molecules. However, there could also exist a deterministic force 
due to some external agent like gravity, external electromagnetic fields, etc. 
Effects of such forces can be included by taking the current density as 
The diffusion equation now becomes 
which is also called the Fokker-Planck equation. 
If we consider particles moving under the influence of a harmonic oscillator 
potential U = $bx2, the probability distribution for particles initially concen- 
trated at some point zo is given as shown in Figure 14.8 by the thin curves. 
When we study the same phenomenon using the fractional Fokker-Planck 
equation 
with 
= l/2, the general behavior of the probability distribution looks like 
the thick curves in Figure 14.8. Both distributions become Gaussian for large 

428 
FRACTIONAL DERIVATIVES AND IN TEGRALS: “DIFFERINTEGRALS” 
0.6 
t=3 
1‘ 
1‘ 
t=1.25 
0.6 
O 
xo 
fig. 14.8 Evolution of probability distribution with harmonic oscillator potential 
times. However, for the fractional Fokker-Planck case it not only takes longer 
but also initially it is very different from a Gaussian and shows CTRW char- 
acteristics (Sokolov, Klafter, and Blumen, 2002). For the standard diffusion 
case the distribution is always a Gaussian. 
For the cases known as superdiffusive (a > l), use of fractional derivatives 
in the Fokker-Planck equation is not restricted to time derivatives, either. 
Chaotic diffusion and Levy processes, which relate far away points and regions, 
are also active areas of research where the use of fractional space derivatives 
is being investigated. 

PROBLEMS 
429 
Problems 
14.1 Show that the following differintegral is valid for all q values: 
r ( p  + 1)[x - uIp-q 
dq[x - u]" 
p > -1. 
- 
- 
[d(x - allq 
I ' ( p - q + l )  
' 
14.2 Derive the formula [Eq. (14.213)] 
14.3 Show that the differintegral of an exponential function is given as 
14.4 Show that the upper limit (q - 1) in the summation 
can be replaced by any number. 
14.5 Show that the solution of the extraordinary differential equation 
df 
d1I2 f 
dx 
dx'/2 
- + - 
- 2f = 0 
is given as 
C 
3 
f(x) = -(2exp(ilx) e r f c ( 2 6 )  + exp(x)erfc(-&)), 
where 
erf c(x) = 1 - erf(x). 
14.6 Show the integral 
1' sin( d-)dt 
= 0.69123 
by using differintegrals. 
14.7 Caputo fractional derivative: Another definition for the fractional 
derivative was given in the late 1960s by Caputo, for modeling dissipation 
effects in linear viscoelasticity problems as 

430 
FRACTIONAL DERIVATIVES AND INTEGRALS: "DIFFERINTEGRALS" 
where C stands for the Caputo derivative. 
i) As in the Riemann-Liouville and Griinwald definitions, impose the condition 
to show that the Riemann-Liouville and Caputo derivatives are related by 
ii) Using the above result, show that with the Caputo definition the fractional 
derivative of a constant is zero. 
iii) Show that the Laplace transform of the Caputo derivative is 
L {  [gf],-} 
= S q ~ ( s ) - S q - ' f ( O + ) ,  
where Y(S) stands for the Laplace transform of f (t). 
iv) Also show that the Laplace transform of the Griinwald (or the Riemann- 
Liouville) definition of differintegral is 
{ [21R-,} 
= s"(s) - - 
dq-lf(o+), 
1 
0 < q < 1. 
Compare your result with the Laplace transform of the Caputo derivative 
found above. Because of the difficulty in experimentally defining the value of 
(O+), the Caputo definition has also found some 
the initial condition - 
use in the literature. 
14.8 Show the differintegral 
dq-l f 
dxq 

15 
INFINITE SERIES 
In physics and engineering applications sometimes physical properties are ex- 
pressed in terms of infinite sums. We also frequently encounter differential 
or integral equations, which can only be solved by the method of infinite s e  
ries. Given an infinite series, we first need to check its convergence. In this 
chapter we start by introducing convergence tests for series of numbers and 
then extend our discussion to series of functions and in particular to power 
series. We then introduce some analytic techniques for finding infinite sums. 
We also discuss asymptotic series and infinite products. In conjunction with 
the Casimir effect, we show how finite and meaningful results can be obtained 
from some divergent series in physics by the methods of regularization and 
renormalization. 
15.1 CONVERGENCE OF INFINITE SERIES 
We write an infinite series with the general term an as 
(15.1) 
n=l 
Summation of the first N terms is called the Nth partial sum of the series. If 
the Nth partial sum of a series has the limit 
(15.2) 
431 

432 
INFINITE SERIES 
we say the series is convergent and write the infinite series as 
C an = S. 
n=l 
(15.3) 
When S is infinity we say the series is divergent. When a series is not con- 
vergent, it is divergent. The nth term of a convergent series always satisfies 
the limit 
lim an ---f 0. 
n+ 00 
(15.4) 
However, the converse is not true. 
Example 15.1. Harmonic series: Even though the nth term of the har- 
monic series, 
0O 
(15.5) 
n=l 
goes to zero as n -+ 03, the series diverges. 
15.2 
ABSOLUTE CONVERGENCE 
If a series constructed by taking the absolute values of the terms of a given 
series as 
(15.6) 
is convergent, we say the series is absolutely convergent. An absolutely con- 
vergent series is also convergent, but the converse is not true. Series that are 
convergent but not absolutely convergent are called conditionally conver- 
gent series. In working with series absolute convergence is a very important 
property. 
Example 15.2. Conditionally convergent series: The series 
. .  
00 
(15.7) 
converges to In 2. 
only conditionally 
However, since it is not absolutely convergent it is 
convergent. 

CONVERGENCE TESTS 
433 
15.3 
CONVERGENCE TESTS 
There exist a number of tests for checking the convergence of a given series. In 
what follows we give some of the most commonly used tests for convergence. 
The tests are ordered in increasing level of complexity. In practice one starts 
with the simplest test and, if the test fails, moves on to the next one. In 
the following tests we either consider series with positive terms or take the 
absolute value of the terms; hence we check for absolute convergence. 
15.3.1 
Comparison Test 
The simplest test for convergence is the comparison test. We compare a given 
series term by term with another series convergence or divergence of which has 
been established. Let two series with the general terms a, and b, be given. 
For all n 2 1 if la,l 5 Ib,l 
is true and if the series c,"==, 
lbnl is convergent, 
then the series Cr=p=I 
a, is also convergent. Similarly, if xr=, 
a, is divergent, 
then the series C,"=l lbnl is also divergent. 
Example 15.3. Comparison test: Consider the series with the general term 
a, = n-P where p = 0.999, We compare this series with the harmonic 
series which has the general term b, = n-'. Since for n 2 1 we can 
write n-' < n-0.999 
and since the harmonic series is divergent, we also 
conclude that the series xr=l 
n-p is divergent. 
15.3.2 
Ratio Test 
For the series c,"==, 
a,, let a, # 0 for all n 2 1. When we find the limit 
an+ 1 
lim - 
n - w l  
a, 
(15.8) 
for r < 1 the series is convergent, for T > 1 the series is divergent, and for r = 1 
the test is inconclusive. 
15.3.3 
Cauchy Root Test 
For the series x,"=l 
a,, when we find the limit 
lim 
= 1, 
n - w  
(15.9) 
for 1 < 1 the series is convergent, for 1 > 1 the series is divergent, and for 1 = 1 
the test is inconclusive. 

434 
INFINITE SERIES -< 
I f(4) f(5) 
; 
I
l
l
1
 
! 
I
I
I
I
 
I
I
I
I
 
I 
I
I
I
I
 
- 
1
2
3
4
5
 
X 
fig. 15.1 Integral test 
15.3.4 
Integral Test 
Let a, = f (n) be the general term of a given series with positive terms. If 
for n > 1, f (n) is continuous and a monotonic decreasing function, that 
is, f (n+ 1) < f (n), then the series converges or diverges with the integral 
J;” f (x) fh. 
Pro0 f 
As shown in Figure 15.1, we can put a lower and an upper bound 
to the series C,”==, 
a, as 
(15.10) 
(15.11) 
From here it is apparent that in the limit as N -+ 
co, if the integral 
J: 
f (x) 
dx is finite, then the series CT=l an is convergent. If the inte- 
gral diverges, then the series also diverges. 
Example 15.4. Integral test: Let us consider the Riemann zeta function 
1
1
 
2” 
35 
<(s)= I + - + - + .  
(15.12) 
To use the ratio test we make use of the binomial formula and write 
S 
- - I - - + -  n 
(15.13) 

CONVERGENCE TESTS 
435 
---f 1; thus the ratio test fails. 
an+ 1 
In the limit as n + 
this gives - 
an 
However, using the integral test we find 
1 
s > 1 
+ 
series is convergent 
0;) 
s < 1 
+ 
series is divergent 
(15.14) 
15.3.5 Raabe Test 
For a series with positive terms, a, > 0, when we find the limit 
lim n (L 
- 1) = m, 
(15.15) 
for m > 1 the series is convergent and for m < 1 the series is divergent. For 
m = 1 the Raabe test is inconclusive. 
The Raabe test can also be expressed as follows: Let N be a positive 
integer independent of n. For all n 2 N ,  if n (e 
- 1) 2 P > 1 is true, 
then the series is convergent and if n (e 
- 1) 5 1 is true, then the series 
is divergent. 
Example 15.5. Raabe test: For the series c,"==, 
5 the ratio test is incon- 
nioo 
an+] 
clusive. However, using the Raabe test we see that it converges: 
lim n (5 
- 1) = lim n (% 
n+ 112 - 1) 
(15.16) 
n-m 
,+03 
an+] 
n-cc 
Example 15.6. Raabe test: The second form of the Raabe test shows that 
is divergent. This follows from the fact that 
the harmonic series C,"xl 
for all n values, 
(15.17) 
When the available tests fail, we can also use theorems like the Cauehy 
theorem. 
15.3.6 Cauchy Theorem 
A given series C,"==, 
a, with positive decreasing terms (a, 2 a,+l 
2 . . . 2 0) 
converges or diverges with the series 
00 
(c an integer). 
(15.18) 
2 
c cnacn = ca, + c a,2 + c3ac3 + . . . 
n= 1 

436 
INFINITE SERIES 
Example 15.7. Cuwhy theorem; Let us check the convergence of the se- 
ries 
1 
nlna n' 
03 
1 
1 f T + . ' . =  
1 
c- 
+- 
n= 2 
21na2 
3ln"3 
4111 4 
(15.19) 
by using the Cauchy theorem for (Y 2 0. Choosing the value of c as two, 
we construct the series xr=l 
2 " ~ "  = 2a2 + 4a4 + 8as +. . . , where the 
general term is given as 
(15.20) 
Since the series 
C,"=* -& converges for a > 1, our series is also 
convergent for (Y > 1. On the other hand, for (Y 5 1, both series are 
divergent. 
15.3.7 
Legendre series are given as 
Gauss Test and Legendre Series 
Cn=Oa2nz2n 
00 
and C~=oa2n+lz2n+1, 3: E [-I, 11. 
(15.21) 
Both series have the same recursion relation 
, n=O,1, ... . 
(n - I) (I + n + 1) 
(n + 1) (n + 2) 
an+2 = an 
(15.22) 
For 121 < 1, convergence of both series can be established by using the ratio 
test. For the even series the general term is given as un = a2nz2n; hence we 
write 
(an - I )  (an + I + 1) z 2  
Un 
QnX2n 
(an + 1) (an + 2 )  ' 
-- 
un+1 - a2n+1x2n+1 - 
- 
(15.23) 
(15.24) 
Using the ratio test we conclude that the Legendre series with the even terms 
is convergent for the interval z E (-1,l). The argument and the conclusion 
for the other series are exactly the same. However, at the end points the ratio 
test fails. For these points we can use the Gauss test: 
Gauss test: 
Let C,"==, 
u, be a series with positive terms. If for n 2 N ( N  is a given 
constant) we can write 
(15.25) 

CONVERGENCE TESTS 
437 
where 0 (5) means that for a given function f (n) thelimit limn+OO{.f (n) /$} 
is finite, then the C,"==, 
un series converges for p > 1 and diverges for p 5 1. 
Note that there is no case here where the test fails. 
Example 15.8. Legendre series: We now investigate the convergence of 
the Legendre series at the end points, z = fl, 
by using the Gauss test. 
We find the required ratio as 
- 
(15.26) 
21, - (2n+1)(2n+2) 
un+l 
4n2 + 6n + 2 
4n2 + 2n - 1 (I + I)' 
- 
- 
- (2n - 1) (272 + 1 + 1) 
(15.27) 
Un 
1 
1(1+ 1) (1 f n )  
- N  
[4n2 + 2n - I ( 1 f  l)]n' 
-I+;+ 
Un+1 
From the limit 
(15.28) 
I ( l + l ) ( l + n )  
1 
1 ( l + l )  
lim 
n+m [4n2 + 2n - 1 ( I  + l)] n " 2 )  = 
4 
' 
we see that this ratio is constant and goes as O ( 3 ) .  Since p = 1 in 
-, 
we conclude that the Legendre series (both the even and the odd 
series) diverge at the end points. 
Un 
un+ 1 
Example 15.9. Chebyshev series: The Chebyshev equation is given as 
d2Y 
dY 
(1 - 2)- - z- + n2y = 0. 
d x 2  
dx 
(15.29) 
Let us find finite solutions of this equation in the interval z E [-1,1] by 
using the Frobenius method. We substitute the following series and its 
derivatives into the Chebyshev equation: 
W 
(15.30) 
(15.31) 
k=O 
00 
y" = 
a k ( k  f C?)(k f (Y - 1)xk++"p2 
(15.32) 
k=O 
to get 

438 
/NF/N/TE SERIES 
After rearranging we first get 
03 
(a - 1 )  ZQ-2 f 
a](Y (a f l)xa-' f 
ak(k f a)(k f a - 1 ) X k + a - 2  
k=2 
00 
f 
akxk+a [n2 - ( k  f O)'] = 0 
(15.34) 
k-0 
and then 
03 
UOQ. (Q. - 1) Za-2 + a]a (a + 1) Zap' f 
ak+2(k f 
(Y f 2)(k f 
a f I)%"+" 
k=O 
03 
+ 
akZk+a [n2 - ( k  f 
a)2] = 0. 
(15.35) 
k=O 
This gives the indicial equation as 
aoa ( a  - 1) = 0, a0 # 0. 
(15.36) 
The remaining coefficients are given by 
a1a (a + 1 )  = 0 
(15.37) 
and the recursion relation 
(15.38) 
Since a0 # 0, roots of the indicial equation are 0 and 1. Choosing the 
smaller root gives the general solution with the recursion relation 
Ic2 - n2 
(k f 2)(k + qUk 
ak+2 = 
(15.39) 
and the series solution of the Chebyshev equation is obtained as 
n 2  
n2 (22 -n2 
4 - 3 - 2  
( 1  - n 2 ) Z 3  + (32 - n2) ( 1  - n2) 
5 . 4 . 3 . 2  
+a1 
X f -  
( 
3 . 2  
We now investigate the convergence of these series. Since the argument 
for both series is the same, we study the series with the general term 
u k  = a2kx2k and write 
(15.41) 

ALGEBRA OF SERlES 
439 
This gives us the limit 
Using the ratio test it is clear that this series converges for the interval 
(-1,l). However, at the end points the ratio test fails, where we now 
use the Raabe test. We first evaluate the ratio 
(15.43) 
= lim k [ 
] = 5 > 1 ,  
(15.44) 
- l1 
(2k + 2)(2lc + 1) 
lim k - 
- 1 = lim k 
k-cc 
[ U z t t 2  
] 
k+oo [ 
(2k)2-n2 
6 k + 2 + n 2  
3 
k-co 
(21C)Z - n2 
which indicates that the series is convergent at the end points as well. 
This means that for the polynomial solutions of the Chebyshev equation, 
restricting n to integer values is an additional assumption, which is not 
required by the finite solution condition at the end points. The same 
conclusion is valid for the series with the odd powers. 
15.3.8 Alternating Series 
For a given series of the form Cr=’=, 
(-l),+’ 
a,, if a, is positive for all n, then 
the series is called an alternating series. In an alternating series for sufficiently 
large values of n, if a, is monotonic decreasing or constant and the limit 
lim a, = 0 
n-cc 
(15.45) 
is true, then the series is convergent. This is also known as the Leibniz rule. 
Example 15.10. Leibnix rule: In the alternating series 
since $ > 0 and $ -+ 0 as n -+ 00, the series is convergent. 
15.4 ALGEBRA OF SERIES 
Absolute convergence is very important in working with series. It is only for 
absolutely convergent series that ordinary algebraic manipulations (addition, 
subtraction, multiplication, etc.) can be done without problems: 
1. An absolutely convergent series can be rearranged without affecting the 
sum. 

440 
INFINITE SERlES 
2. Two absolutely convergent series can be multiplied with each other. 
The result is another absolutely convergent series, which converges to 
the multiplication of the individual series sums. 
All these operations look very natural; however, when applied to condi- 
tionally convergent series they may lead to erroneous results. 
Example 15.11. Conditionally convergent series: The following condi- 
tionally convergent series: 
1
1
 1
1
 
2
3
 4
5
 
= 1 - (- - -) - (- - -) -. .. 
(15.47) 
= 1-0.167-0.05-.-- 
, 
(15.48) 
obviously converges to some number less than one, actually to In 2 = 
0.693. We now rearrange this sum as 
1
1
 1
1
1
1
 1
1
 1 
3
5
 
7 
9 
11 
(If - +-)- ($+(- +- + - + E+ 
15) - (2) 
1 
1 
1 
1 
1 
1 
17 
25 
6 
27 
35 
8 
+ (-++..+-) 
- (-) + ( - + + - . * +  -) - (-) f-.. , 
(15.49) 
and consider each term in parenthesis as the terms of a new series. 
Partial sums of this new series are 
~1 = 1.5333, 
~3 = 1.5218, 
~2 = 1.0333, 
~4 = 1.2718, 
Sg = 1.3853, 
$10 = 1.4078, 
S5 = 1.5143, 
Sg = 1.3476, . . . . 
(15.50) 
S7 = 1.5103, 
~g = 1.5078, 
It is now seen that this alternating series added in this order converges 
to 3/2. What we have done is very simple. First we added positive terms 
until the partial sum was equal or just above 3/2 and then subtracted 
negative terms until the partial sum fell just below 3/2. In this process 
we have neither added nor subtracted anything from the series; we have 
simply added its terms in a different order. 
By a suitable arrangement of its terms a conditionally convergent series 
can be made to converge to any desired value or even to diverge. This 
result is also known as the Riemann theorem. 
15.4.1 
Rearrangement of Series 
Let us write the partial sum of a double series as 
(15.51) 

ALGEBRA OF SERIES 
441 
If the limit 
lim s,, 
= s 
71'00 
m-cc 
exists, then we can write 
(15.52) 
(15.53) 
and say that the double series CG=, aij is convergent and has the sum s. 
When a double sum 
(15.54) 
converges absolutely, that is, when Cz0C', 
laijl is convergent, then we 
can rearrange its terms without affecting the sum. 
Let us define new dummy variables q and p as 
i = q 2 0 a n d j  = p  - q 2 0. 
(15.55) 
Now the sum CEO 
~~o 
aij becomes 
Writing both sums explicitly we get 
(15.56) 
(15.57) 
Another rearrangement can be obtained by the definitions 

442 
as 
15.5 
INFINITE SERIES 
r 
i = s > O a n d j = r - 2 ~ > 0 ,  (ss $, 
(15.58) 
0 0 0 0  
03 [a1 
(15.60) 
- 
- a00 + a01 + a02 + +alo + ao3 + all + . . . 
USEFUL INEQUALITIES ABOUT SERIES 
Let + = 1; then we can state the following useful inequalities about series: 
H8lder’s Inequality: If an 2 0, b, 2 0, p > 1, then 
cx) c 
anbn 5 (2 
u;) I”. (g 
b;) ‘Iq. 
(15.61) 
n= 1 
n=l 
n=l 
Minkowski’s Inequality: If an 2.0, b, 2. 0 and p 2 1, then 
[ n= 2 
1 (an + ha)’] 
I 
(2 
n=l a;) 
+ (5 
n=l K) . 
(15.62) 
Schwarz-Cauchy Inequality: If a, 2 0, and bn 2 0, then 
( F a n b n ) 2  I 
( F a : ) .  
n= 1 
( E b i ) .  
n=l 
(15.63) 
n= 1 
Thus, if the series C,“==, 
a: and xT=l 
b i  converges, then the series 
Cr=l anbn also converges. 
15.6 
SERIES OF FUNCTIONS 
We can also define series of functions with the general term un = un (z). In 
this case the partial sums Sn are also functions of z : 
S ~ ( Z )  
= u ~ ( z )  
+ua(z)+...+un(z). 
(15.64) 
If lim Sn(z) + S(Z) is true, then we can write 
n- 
n= 1 
(15.65) 

SERIES OF FUNCTIONS 
443 
a 
b 
fig. 15.2 Uniform convergence is very import.ant 
In studying the properties of series of functions we need a new concept called 
the uniform convergence. 
15.6.1 Uniform Convergence 
For a given positive small number E ,  if there exists a number N independent 
of z for z E [a,b], and if for all n 2 N we can say the inequality 
I.(.) 
- .%&)I 
< E 
(15.66) 
is true, then the series with the general term un(z) 
is uniformly convergent in 
the interval [a, b]. This also means that for a uniformly convergent series and 
for a given error margin E ,  we can always find N number of terms independent 
of z such that when added the remainder of the series, that is 
(15.67) 
is always less than E for all z in the interval [a, b] . Uniform convergence can 
also be shown as in Figure 15.2. 
15.6.2 Weierstrass M-Test 
For uniform convergence the most commonly used test is the Weierstrass 
M or in short the M-test: Let us say that we found a series of numbers 

444 
INFINITE SERIES 
xzl Mi, such that for all 3: in [a, 61 the inequality M; 2 Iui(x)l is true. Then 
the uniform convergence of the series of functions czl ui(z), 
in the interval 
[a, b] , follows from the convergence of the series of numbers xzl Mi. Note 
that because the absolute values of ui(z) are taken, the M-test also checks 
absolute convergence. However, it should be noted that absolute convergence 
and uniform convergence are two independent concepts and neither of them 
implies the other. 
Example 15.12 M-test: The following series are uniformly convergent, but 
not absolutely convergent: 
(15.68) 
while the series (the so-called Riemann zeta function) 
(15.69) 
converges uniformly and absolutely in the interval [a,m), where a is 
any number greater than one. Because the M-test checks for uniform 
and absolute convergence together, for conditionally convergent series 
we can use the Abel test. 
15.6.3 Abel Test 
Let a series with the general term u,(z) = a,f,(z) be given. If the series 
of numbers X u ,  = A is convergent and if the functions f,(x) are bounded, 
0 5 f,(x) 5 M ,  and monotonic decreasing, fn+l(z) 5 f,(x), in the interval 
[a, b] , then the series C u,(z) is uniformly convergent in [a, 61. 
Example 15.13 Unaform convergence: 
The series 
is absolutely convergent but not uniformly convergent in [0,1]. 
From the definition of uniform convergence it is clear that any series 
00 
(15.71) 
rL= 1 
where all u, (z) are continuous functions, cannot be uniformly convergent in 
any interval containing a discontinuity of f (x). 

TAYLOR SERIES 
445 
15.6.4 
For a uniformly convergent series the following are true: 
Properties of Uniformly Convergent Series 
1. If u,(z) for all n are continuous, then the series 
(15.72) 
n= 1 
is also continuous. 
2. Provided un(z) are continuous for all n in [a, b], then the series can be 
integrated as 
where the integral sign can be interchanged with the summation sign. 
3. If for all n in the interval [a, b] , ~ ( x )  
and -&(x) 
are continuous, and 
the series C,"==, gun(.) is uniformly convergent, then we can differen- 
tiate the series term by term as 
(15.74) 
(15.75) 
15.7 
TAYLOR SERIES 
Let us assume that a function has a continuous nth derivative, f(n)(x), 
in the 
interval [a, b]. Integrating this derivative we get 
Integrating again, 
- 
- f'"-2'(z) 
- j'"-2'(.) 
- (x - a)f'"-"(a) 
(15.77) 

446 
/NNN/Tf S€R/fS 
and after n-fold integrations we get 
lZ 
f ..IZ 
f'"'(x)(dz)" = f ( x )  - f ( u )  - (x - u)f'(u) 
(15.78) 
f (n- 1) (u). 
(z - u)n-l 
..._ 
(n - I)! 
We now solve this equation for f(x) to write 
(15.79) 
(x - u)n- ' 
(n - l)! 
+ 
In this equation 
Rn = l Z - - - J f l Z f ( n ) ( ~ ) ( d x ) n  
(15.80) 
is called the remainder, and it can also be written as 
Note that Equation (15.79) is exact. When the limit 
lim R, = 0 
(15.82) 
n-oo 
is true, then we have a series expansion of the function f ( x )  in terms of the 
positive powers of (x - u) as 
00 
f (n) (u). 
f(.) = c - 
( x  - a)" 
n! 
n=O 
(15.83) 
This is called the Taylor series expansion of f ( z )  about the point x = a. 
15.7.1 
Maclaurin Theorem 
In the Taylor series if we take the point of expansion as the origin, we obtain 
the Maclaurin series: 
(15.84) 

TAYLOR SERIES 
447 
15.7.2 
Binomial Theorem 
We now write the Taylor series for the function 
f(x) = (1 + x)" 
about x = 0 as 
( I + X ) ~ =  I + m x +  m(m - 1Ix2 + 
2! 
... 
(15.85) 
+&I 
(15.86) 
with the remainder term 
(15.87) 
X" 
Rn = 
(1 + [)"-" m(m - I ) - - -  (m- n+ I), 
where m can be negative and noninteger and [ is a point such that 0 5 [ < x. 
Since for n > m the function (1 + [)"-" 
takes its maximum value for < = 0, 
we can write the following upper bound for the remainder term: 
(15.88) 
R, 5 --m(m- 
l ) . - - ( m - n +  1). 
From Equation (15.88) it is seen that in the interval 0 1. x < 1 the remainder 
goes to zero as n -+ 00; thus we obtain the binomial formula as 
Xn 
n! 
00 
(15.89) 
m! 
(1 +x)" - 
n=O 
- C n!(m - n)! 
n=O 
It can be easily shown that this series is convergent in the interval -1 < x < 
1. Note that for m = n (integer) the sum automatically terminates after a 
finite number of terms, where the quantity (z) = m!/n!(m - n)! is called the 
binomial coefficient. 
Example 15.14. Relativistic kinetic energy: The binomial formula is prob- 
ably one of the most widely used formulas in science and engineering. 
An important application of the binomial formula was given by Einstein 
in his celebrated paper where he announced his famous formula for the 
energy of a freely moving particle of mass m as 
E = m c .  
2 
(15.90) 
In this equation c is the speed of light and m is the mass of the moving 
particle, which is related to the rest mass % by 
m0 
m =  
(15.91) 

448 
INFINITE SERIES 
where v is the velocity. Relativistic kinetic energy can be defined by 
subtracting the rest energy from the energy in motion: 
K.E. = mc2 - -c2. 
(15.92) 
Since v < c, we can use the binomial formula to write the kinetic energy 
as 
2 
1 
3 
v2 
5 
2 v2 2 
K.E. = moc2 + - m u 2  + -mow2( -) + -mow (7) 
+. . . - moc 
2 
8 
c2 
16 
(15.93) 
and after simplifying we obtain 
1 
3 
112 
5 
2 u2 2 
K.E. = -mov2 + -mou2(-) + -mow 
(-) +. 
2 
8 
c2 
16 
C2 
(15.94) 
horn here we see that in the nonrelativistic limit, that is, v/c << 1 
or when c + 00, the above formula reduces to the well-known classical 
expression for kinetic energy: 
K . E . E - w v  
1
2
 
. 
(15.95) 
2 
15.7.3 
For a function with two independent variables, f (2, 
y), the Taylor series is 
given as 
Taylor Series for Functions with Multiple Variables 
af 
a f  
f (x, Y) = f (a, b) + (x - u)- + (z - b)- 
ax 
aY 
(. - u) - 
+ 2(x - .)(y - b)- 
+ (y - b) 
2 a2f 
a2f 
+- 2! [ 
ax2 
axay 
3 a3f 
a3f 
+- 
3! (x - u) - 
+ 3(x - u)2(y - b)- a x v y  
[ 
ax3 
+(y-b) -7j- +
-
-
a
 
(15.96) 
3a3f1 
aY 
a3.f 
+3(x - u)(y - b)2- axay2 
All the derivatives are evaluated at the point (u,b). In the presence of m 
independent variables Taylor series becomes 
1101~20. ..., I n 0  
(15.97) 
f (Xl,X2, "', Z m )  = 
n! 
n=o 

POWER SERIES 
449 
15.8 POWER SERIES 
Series with their general term given as un(x) = a,xn are called power series: 
00 
f ( x )  = a0 + a1x + a222 + . . . = c 
anxn, 
(15.98) 
n=O 
where the coefficients a, are independent of x. To use the ratio test we write 
and find the limit 
(15.99) 
(15.100) 
Hence the condition for the convergence of a power series is obtained as 
1x1 < R*-R< 
x < R, 
( 15.10 1) 
where R is called the radius of convergence. At the end points the ratio test 
fails; hence these points must be analyzed separately. 
Example 15.14. Power series: For the power series 
2 2  
5 3  
X n  
l + x + - + - + . . . + -  
+.-. , 
(15.102) 
2
3
 
n 
the radius of convergence R is one; thus the series converges in the 
interval -1 < x < 1 . On the other hand, at the end point x = 1 it is 
divergent, while at the other end point, z = -1, it is convergent. 
Example 15.15. Power series: The radius of convergence can also be zero. 
For the series 
1 + x + 2!x2 + 3!x3 + ... + n!xn + ... , 
(15.103) 
the ratio 
gives 
1 
lim (n + 1) = - 
n+m 
R-)O0. 
(15.104) 
(15.105) 
Thus the radius of convergence is zero. Note that this series converges 
only for x = 0. 

450 
INFINITE SERIES 
Example 15.16. Power series: For the power series 
2 2  
2 3  
Xn 
2! 
3! 
n! 
l+z+ - +-+-..+-+.- 
we find 
an+l 
n! 
1 
-=-=- 
a, 
(n+l)! 
n + l  
and 
1 
1 
n--tcon+l 
R 
lim - 
= - -+ 0. 
(15.106) 
(15.107) 
(15.108) 
Hence the radius of convergence is infinity. This series converges for all 
3: values. 
15.8.1 
Convergence of Power Series 
If a power series is convergent in the interval -R < x < R, then it is uniformly 
and absolutely convergent in any subinterval S: 
-S 5 x 5 S, where 0 < S < R. 
(15.109) 
This can be seen by taking Mi = /ail Sz in the M-test. 
15.8.2 
Continuity 
In a power series, since every term, that is, u,(x) = unlcn, is a continuous 
function and since in the interval -S 5 2 5 S the series f(x) = Canzn 
is uniformly convergent, f(x) is a continuous function. Considering that in 
Fourier series even though the u,(z) functions are continuous we expand dis- 
continuous functions shaped like a saw tooth, this is an important property. 
15.8.3 
In the interval of uniform convergence a power series can be differentiated and 
integrated as often as desired. These operations do not change the radius of 
convergence. 
Differentiation and Integration of Power Series 

POWER SERIES 
451 
15.8.4 
Uniqueness Theorem 
Let us assume that a function has two power series expansions about the 
origin with overlapping radii of convergence, that is, 
00 
f(x) = C a n x n  3 -R, < z < R, 
(15.110) 
n=O 
00 
= c 
bnxn 3 - R b  < z < R b ,  
n=O 
then b, = a, is true for all n. Hence the power series is unique. 
Proof: Let us write 
m 
oc 
.. c anxn = 
b,xn 3 -R < x < R, 
n=O 
n=O 
where R is equal to the smaller of the two radii R, and R b .  If we set 
x = 0 in this equation we find a0 = bo. Using the fact that a power 
series can be differentiated as often as desired, we differentiate the above 
equation once to write 
00 
00 
c 
annxn-l = c bnnxn-’. 
n=l 
n= 1 
We again set x = 0, this time to find a1 = bl. Similarly, by repeating 
this process we show that a, = b, for all n. 
15.8.5 
Inversion of Power Series 
Consider the power series expansion of the function y(x) - yo in powers of 
(2 - 20) as 
y - yo = a1 (x - 20) + aa(z - 20) 2 + . . . , 
(15.11 1) 
that is, 
,=I 
Sometimes it is desirable to express this series as 
m 
( 15.112) 
(15.113) 
n=l 

452 
INFlNlTE SERlES 
For this we can substitute Equation (15.113) into Equation (15.112) and com- 
pare equal powers of (y - yo) to get the new coefficients b, as 
1
2
 
b 3  = J(2U2 
al 
- 0 1 0 3 ) ,  
( 15.114) 
A closed expression for these coefficients can be found by using the residue 
theorem as 
1 
dn-’ 
= 2 [P 
( & ) n ] t = 0 7  
(15.115) 
where ~ ( t )  
= c,”=, 
antn. 
15.9 SUMMATION OF INFINITE SERIES 
After we conclude that a given series is convergent, the next and most impor- 
tant thing we need in applications is the value or the function that it converges 
to. For uniformly convergent series it is sometimes possible to identify an un- 
known series as the derivatives or the integrals of a known series. In this 
section we introduce some analytic techniques to evaluate the sums of infinite 
series. We start with the Euler-Maclaurin sum formula, which has important 
applications in quantum field theory and Green’s function calculations. Next 
we discuss how some infinite series can be summed by using the residue t h e  
orem. Finally, we show that differintegrals can also be used to sum infinite 
series. 
15.9.1 
In deriving the Euler-Maclaurin sum formula we make use of the properties of 
the Bernoulli polynomials, B, (x), where their generating function definition 
Bernoulli Polynomials and Their Properties 

SUMMATlON OF INFINITE SERIES 
453 
is given as 
(15.116) 
Some of the Bernoulli polynomials can be written as 
z--l 
Z ( X  - +)(z - 1)(x2 - z - 4) 
1 
Bl(X) = 
2 
Bz(x> = 
x2-x+g 1 
B3(2) = 
z(x - $)(x - 1) 
Bo(x) = 
B4(z) = 
& ( Z )  = 
z4 - 2x3 + z2 - 3o 
X6 - 3Z5 + 4Z4 - +Z2 + & 
B ~ ( z )  
= 
( 15.117) 
Values of the Bernoulli polynomials at x = 0 are known as the Bernoulli 
numbers, 
Bs = Bs(O), 
(15.118) 
where the first nine of them are given as 
Bo=1 
B1 =-; 
B2=B 1 
B3=O 
B 4 z - Z  
1 
B5=O 
Bg= & 
B7=O 
B s = - s  1 
B g = O  
... . 
(15.119) 
Some of the important properties of the Bernoulli polynomials can be listed 
as follows: 
1. 
B, (z) = f: 
(s) B,-jzj. 
j = O  
3 
(15.120) 
2. 
B,(l-z)= (-1)"BS(z). 
(15.122) 
Note that when we write B, (1 - z) we mean the Bernoulli polynomial 
with the argument (1 - z). We show the Bernoulli numbers as B,. 

454 
INFINITE SERIES 
4. 
n 
5. 
6. 
(15.124) 
(15.125) 
7. In the interval [O, 11 and for s 2 1, the only zeroes of &+1(z) are 0, 4, 
and 1. In the same interval 0 and 1 are the only zeroes of (Bzs(z) 
-l3zS). 
Bernoulli polynomials also satisfy the inequality 
IB2s(5)1 5 IBzsI, 0 I 
5 I 1 . 
(15.126) 
8. The Bernoulli periodic function, which is continuous and has the period 
one, is defined as 
Ps(z) = BSb - [4>, 
(15.127) 
The 
where [z] means the greatest integer in the interval (z - 1,z]. 
Bernoulli periodic function also satisfies the relations 
P ~ ( z )  
= sP,-l(Z), 
s = 1,2,3 ,... 
(15.128) 
and 
Ps(l) = (-l)'PS(O), 
s = 0,1,2,3 ,... . 
15.9.2 
Euler-Maclaurin Sum Formula 
We first write the integral 
(15.129) 
(15.130) 
by using the properties of the Bernoulli polynomials. Since the first, Bernoulli 
polynomial is 
Bo(z) = 1, 
(15.131) 

SUMMATION OF INFINITE SERIES 
455 
we can write this integral as 
Using the following property of Bernoulli polynomials: 
Bi(2) = Bo(z) = 1, 
(15.133) 
we can write Equation (15.132) as 
I’ 
f(z)dz = s,’ f(z)Bo(z)dz = 
(15.134) 
Integrating this by parts we obtain 
where we have used Bl(1) = a and Bl(0) = -4. In the above integral we now 
use 
(15.137) 
1 
Blk) = 
and integrate by parts again to obtain 
1 
1 
1 
f(z)dz = 5 [f(l) + f(0)l- 3 
[f’(l)Ba(l) - f’(O)Bz(O>I 
1 
+ f 1 f”(z)Bz(z)dz. 
(15.138) 
Using the values 
Ban(l) = 
Bzn(O) = Ban 
n = 0,1,2 ,..., 
B2n+l(l) = Ban+l(0) = O  
n= 1,2,37...7 
(15.139) 
and continuing like this we obtain 
1 
r l  
(15.140) 

456 
INFINITE SERIES 
This equation is called the Euler-Maclaurin sum formula. We have assumed 
that all the necessary derivatives of f(z) exist and q is an integer greater than 
one. 
We now change the limits of the integral from 0 to 1 to 1 to 2. We write 
and repeat the same steps in the derivation of the Euler-Maclaurin sum for- 
mula for f(y + 1) to obtain 
We have now used the Bernoulli periodic function [Eq. (15.127)]. Making the 
transformation 
y + l = 2 ,  
we write 
(15.143) 
(15.144) 
(15.145) 
1 
2 
= - [f(2) + f0)l 
Repeating this for the interval [2,3] we can write 
(15.146) 

SUMMATION OF INFINITE SERIES 
457 
Integrals for the other intervals can be written similarly. Since the integral 
for the interval [O,n] can be written as 
n 
f(z)dz = I' f(z)dz + [ 
f(z)dz + . . . + J,, f ( x ) d z ,  
I" 
(15.147) 
we substitute the formulas found above in the right-hand side to obtain 
(15.148) 
We have used the fact that the function P ~ , ( x )  
is periodic with the period 
one. Rearranging this, we write 
(15.149) 
The last two terms on the right-hand side can be written under the same 
integral sign, which gives us the final form of the Euler-Maclaurin sum formula 
as 
( 15.150) 
In this derivation we have assumed that f(z) is continuous and has all the 
required derivatives. This is a very versatile formula that can be used in 
several ways. When q is chosen as a finite number it allows us to evaluate a 
given series as an integral plus some correction terms. When q is chosen as 
infinity it could allow us to replace a slowly converging series with a rapidly 
converging one. If we take the integral to the left-hand side, it can be used 
for numerical evaluation of integrals. 

458 
fNFlNITE SERIES 
(N+ 1/2) (-1 +I) 
I 
I 
I 
I 
I 
I 
-N-1 
-N \ 
- 2  
- 1  
(N+ In) (-1 - i) 
A Y  
CN 
(N+ 1/2) (1 +i) 
I 
I 
I 
I
)
 
1 
2
Y
 
N 
N+1 
(N+ In) (1 -I) 
Fig. 15.3 Contour for finding series sums using the residue theorem 
15.9.3 
Some of the infinite series can be summed by using the residue theorem. First 
we take a rectangular contour C, in the z-plane with the corners as shown 
in Figure 15.3. We now prove a property that will be useful to us shortly. 
Using Residue Theorem to Sum infinite Series 
Lemma: On the contour CN the inequality ]cot xzl < A is always satisfied, 
We prove this by considering the parts of C, with y > f, -$ I y 5 3, 
where A is a constant independent of N .  
and y < -; 
separately. 
1. Case: (y > i) : We write a complex number as z = 2 + zy; thus 
ei?rz-7ry + e - i x z + x y  
Using the triangle inequality 
1.11 - 14 I 1.1 + .zl I l.11 + 1.21 
(15.152) 
and considering that y > 2 we find 
1 + e-?r 
1 - e c x  
- 
<-- 
- A1. 
(15.153) 

SUMMATION OF INFINlTE SERIES 
459 
2. Case: (y < -$) : Following the procedure of the first case we firid 
(15.154) 
3. Case: (-f 5 y 5 4) : A point on the right-hand side of CN can be 
written as z = N + $ + iy; thus for -$ 5 y 5 $ we obtain 
1 
/cot 7 T 4  = /rot 7T (N + 5 + iy) 1 = (cot (; + iay) I 
= ltanhryl 5 tanh (z) = A2. 
(15.155) 
Similarly, a point on the left-hand side of C, is written as 2 = -N - 
4 + iy, which gives us 
= ltanhxyl 5 tanh (5) = A2. 
(15.156) 
Thus choosing the greater of the Aland A2 and calling it A proves that 
on CN the inequality ]cot 7~21 < A is satisfied. We also note that A is 
a constant independent of N .  Actually, since A2 < A1 we could also 
write 
lr 
/cot ~ T Z I  5 A, = cot -. 
(15.157) 
2 
We now state the following useful theorem: 
M 
Theorem: If a function f ( z )  satisfies the inequality \ f ( z ) \  5 7 
on the 
contour CN, where k > 1 and M is a constant independent of N ,  then 
the sum of the series C,"=-, f ( j )  is given as 
I4 
(15.158) 
Cz-,f(j) = -{residues of the function ?rcoti?rzf(z) at 
the isolated singular points of f ( z ) } .  
Proof: 
1. Case: Let us assume that f ( z )  has a finite number of isolated singular 
points. In this case we choose the number N such that the closed contour 
CN encloses all of the singular points of f(z). On the other hand, cot 7 ~ 2  
has poles at the points 
2 = n, n = 0, fl, *2, ..', 

460 
INFINITE SERIES 
where the residues of the function  cot ~zf(z) 
at these points are given 
as 
( z  - n) f( z) cos TZ 
lim ( z  - n) xcot x z f ( z )  = lim T 
= f (n). 
z - m  
p
i
n
 
sin ZT 
(15.159) 
For this result we have used the L’Hopital’s rule and assumed that f(z) 
has no poles at the points z = n. Using the residue theorem we can now 
write 
N 
xcot ~ z f ( z ) d z  
= C f(n) + S, 
(15.160) 
kN 
n=-N 
where S represents the finite number of residues of  cot ~ z f ( z )  at the 
poles of f(z). We can put an upper bound to the integral on the left as 
TCOt 7rzf(z)dz 5 liN 
TC0t nzf(z)dzl I 
kN 
7rlcot 7rzl If(.)l 
ldzl. 
kN 
M 
Since f(z) satisfies If(z)l 5 
on the contour, this becomes 
I4 
(15.161) 
where (8N + 4) is the length of C,. 
From here we see that as N + 0;) 
value of the integral in Equation (15.160) goes to zero: 
We can now write 
f(n) = -s. 
(15.163) 
2. Case: Iff( z )  has infinitely many singular points the result can be obtained 
similarly by an appropriate limiting process. 
Example 15.17. Series sum by the residue theorem: In quantum field 
theory and in Green’s function calculations we occasionally encounter 
series like 
1 
00 
n=O 
(15.164) 

SUMMATION OF fNfINfTE SERIES 
461 
where 
1 
f ( z )  = 
(15.165) 
has two isolated singular points located at z = &ia and satisfies the 
conditions of the above theorem. The residue of 
7r cot 7rz 
z2 + a2 
at z = ia is found as 
n- cot ria 
- 
7r cot n-2 
lim ( z  - ia) 
- 
z-za 
( z  + ia) ( z  - ia) 
2ia 
(15.166) 
(15.167) 
7r 
= _- cothxa. 
2a 
7r 
Similarly, the residue at z = -ia is -- 
coth 7ra; thus using the conclu- 
sion of the above theorem [Eq. (15.158)] we can write 
2a 
(15.168) 
n- 
- - coth 7ra. 
1 
03 
n=-m 
C - - a  
1 
From this result we obtain the sum cT='=o as 
1 
1
-
 1 
- 1  
- 
1 
03 c w- 
n=-m c w + > + C m ,  
n=l 
n=-m 
1 7 r  
a2 
a 
+ - = - cothra, 
1 
03 
n= 1 
1 
7r 
1 
a3 
= Z c o t h r a f -  2a2 ' 
n=O 
(15.169) 
15.9.4 
Evaluating Sums of Series by Differintegrals 
In 1970 Osler gave the following summation version of the Leibniz rule, which 
is very useful in finding sums of infinite series: 
d4-Y-nu dY+nv 
dxq 
d X q - 7 - n  &Y+n 
where y is any constant. 

462 
INFINITE SERIES 
Example 15.18. Evaluating sums of series by dafierintegrals: In the 
above formula if we choose u = xa, v = xb, and y = 0, and use the 
dqxp 
r(p + 1)zP-q 
differintegral - 
- 
- 
, where p > -1, we find the sum 
dxq 
r ( p - q +  1) 
15.9.5 
Asymptotic Series 
Asymptotic series are frequently encountered in applications. They are gen- 
erally used in numerical evaluation of certain functions approximately. Two 
typical functions where asymptotic series are used for their evaluation are 
given as Il(z) and I2(x) : 
(15.172) 
(15.173) 
In astrophysics we frequently work on gasses obeying the Maxwell-Boltzman 
distribution, where we encounter gamma functions defined as 
We now calculate I(z,p) for large values of x. We first start by integrating 
the above integral by parts twice to get 
and then 
(15.175) 
(15.176) 
We keep on integrating by parts to obtain the series 

SUMMATION OF INFINITE SERIES 
463 
This is a rather interesting series, if we apply the ratio test we find 
( p f n ) !  
1 
lim - 
l%+ll - 
- lim 
.- 
n'w 
IunI 
n+w ( P + n  - I)! x 
+ 03. 
p + n  
= lim - 
n-w 
3: 
(15.177) 
(15.178) 
Thus the series diverges for all finite values of x. Before we discard this series 
as useless in calculating the values of the function I(z,p), let us write the 
absolute value of the difference of I(z,p) and the nth partial sum as 
Using the transformation u = v + 3: we can write the above integral as 
For the large values of z we find the limit 
(15.182) 
and the remainder term R, is 
(15.183) 
which shows that for sufficiently large values of x we can use Sn for evaluating 
the values of the I(xl p )  function to sufficient accuracy. Naturally, the Rn value 

464 
INFINITE SERIES 
of the partial sum depends on the desired accuracy. For this reason such series 
are sometimes called asymptotic or semi-convergent series. 
Example 15.19. Asymptotic ezpamiom: We now consider the integral 
I = ix 
e- t2dt. 
Using the expansion 
(15.184) 
(15.185) 
where r is the radius of convergence we write 
x3 
2 5  
5 7  
3.1! 
5.2! 
7.3! 
I = L Z e - ' ? d t  = z -  - 
+ - 
- - 
f - - - ,  (r =m). 
(15.186) 
For small values of z this series can be used to evaluate I to any desired 
level of accuracy. However, even though this series is convergent for all 
x, it is not practical to use for large x. For the large values of z we can 
use the method of asymptotic expansions. Writing 
I = s,' eCt2dt 
and integrating by parts we obtain 
(15.187) 
Repeated application of integration by parts, after n times, yields 
(15.189) 
1 
1.3 
1 . 3 . 5 . .  . (2n - 3) 
+ (-1)n-l 
2x 
(2x2)"- 1 
where 
(15.190) 

DIVERGENT SERIES IN PHYSICS 
465 
As n ---f 00 this series diverges for all x. However, using the inequalities 
and 
e- x2 
l " e - " ' d t  
< - 
22 ' 
we see that the remainder satisfies 
( 15.19 1) 
(15.192) 
(15.193) 
Hence lRnl can be made sufficiently small by choosing n sufficiently 
large, thus the series (15.189) can be used to evaluate I as 
1.3.5- .. (2n- 3) 
2 
22 
1.3 
+ (-1)n-l 
(2x2)"- 1 
]-a. 
1 
I = - - -  
(15.194) 
For x = 5 if we choose n = 13, we have 
< lo-". 
15.10 
DIVERGENT SERIES IN PHYSICS 
So far we have seen how to test a series for convergence and introduced some 
techniques for evaluating infinite sums. In quantum field theory we occa- 
sionally encounter divergent series corresponding to physical properties like 
energy, mass, etc. These divergences are naturally due to some pathologies 
in our theory, which are expected not to exist in the next generation of field 
theories. However, even within the existing theories it is sometimes possible 
to obtain meaningful results, which agree with experiments to an incredibly 
high degree of accuracy. The process of obtaining finite and meaningful r e  
sults from divergent series is accomplished in two steps. The first step is called 
regularization, where the divergent pieces are written out explicitly, and the 
second step is called renormalization, where the divergent pieces identified 
in the first part are subtracted by suitable physical arguments. Whether a 
given theory is renormalizable or not is very important. In 1999 Gerardus't 
Hooft and J. G. Martinus Veltman received the Nobel Prize for showing that 
Salam and Weinberg's theory of unified electromagnetic and weak interactions 
is renormalizable. On the other hand, quantum gravity is nonrenormalizable 
because it contains infinitely many divergent pieces. 
15.10.1 
Casimir Effect and Renormalization 
To demonstrate the regularization and renormalization techniques we consider 
a massless (conformal) scalar field in a onedimensional box with length L . 

466 
INFINITE SERIES 
Using the periodic boundary conditions we can find the eigenfrequencies as 
(15.195) 
where each frequency is two-fold degenerate. In quantum field theory vacuum 
energy is a divergent expression given by 
(15.196) 
where gn stands for the degeneracy of the nth eigenstate. 
dimensional box problem this gives 
For the o n e  
(15.197) 
Because the high frequencies are reason for the divergence of the vacuum 
energy, we have to suppress them for a finite result. Let us multiply Equation 
(15.197) with a regularization (cutoff) function like e-OWn and write 
- 
27rcfi 
O0 
Eo = - c ne-2XCnalL 
' 
n=O 
L 
(15.198) 
where a is a cutoff parameter. This sum is now convergent and can he eval- 
uated easily by using the geometric series as 
The final and finite result is naturally going to be obtained in the limit where 
the effects of the regularization function disappear, that is, when a -+ 0. We 
now expand Equation (15.199) in terms of the cutoff parameter a to write 
- 
L
?
r
 
Eo=--- 
+ (terms in positive powers of a). 
27ra2 
6 L  
(15.200) 
Note that in the limit as a + 0 vacuum energy is still divergent; however, the 
regularization function has helped us to identify the divergent piece explicitly 
as 
(15.201) 
The second term in EO is finite and independent of a, while the remaining 
terms are all proportional to the positive powers of a, which disappears in the 
limit a -+ 0. 
The second part of the process is renormalization, which is subtracting the 
divergent piece by a physical argument. We now look at the case where the 

DIVERGENT SERIES IN PHYSICS 
467 
walls are absent, or taken to infinity. In this case the eigenfrequencies are 
continuous; hence we write the vacuum energy in terms of an integral as 
(15.202) 
This integral is also divergent. We regularize it with the same function and 
evaluate its value as 
(15.203) 
(15.204) 
which is identical to the divergent term in the series (15.200). 
To be consistent with our expectations, we now argue that in the absence of 
walls the quantum vacuum energy should be zero, thus we define the renor- 
malized quantum vacuum energy, Eo, by subtracting the divergent piece 
[Eq. (15.204)] from the unrenorrnalized energy, Eo, and then by taking the 
limit a -+ 0 as 
(15.205) 
For the renormalized quantum vacuum energy between the walls this pre- 
scription gives 
L
T
 
L 
EO = lim[- 
- - + (terms in positive powers of a )  - - 
] 
a+O 2
~
a
~
 
6L 
27ra2 
m 
(15.206) 
The minus sign means that the force between the walls is attractive. In 
three dimensions this method gives the renormalized electromagnetic vacuum 
energy between two perfectly conducting neutral plates held at absolute zero 
and separated by a distance L as 
(15.207) 
where S is the surface area of the plates and we have inserted c and fi. This 
gives the attractive force per unit area between the plates as 
~ E o  7?Ch 
F'= -- 
= - 
d L  
240L4' 
In quantum field theory this interesting effect is known as the Casimir effect, 
and it has been verified experimentally. The Casimir effect has also been 
calculated for plates with different geometries and also in curved background 

468 
/NF/N/ JE SER/fS 
spacetimes. More powerful and covariant techniques like the point splitting 
method, which are independent of cutoff functions, have confirmed the results 
obtained by the simple mode sum method used here. Note that in the classical 
limit, that is, as fi -+ 0, the Casimir effect disappears, that is, it is a pure 
quantum effect. 
One should keep in mind that in the regularization and renormalization 
process we have not cured the divergence problem of the quantum vacuum 
energy. In the absence of gravity only the energy differences are observable; 
hence all we have done is to define the renormalized quantum vacuum energy 
in the absence of plates as zero and then scaled all the other energies with 
respect to it. 
15.10.2 
Casimir Effect and MEMS 
The Casimir force between two neutral metal plates is very small and goes 
as A/d4. For plates with a surface area of 1 cm2 and a separation of 1 pm, 
the Casimir force is around 10-7N . This is roughly the weight of a water 
drop. When we reduce the separation to 1 nm, roughly 100 times the size 
of a typical atom, pressure on the plates becomes 1 atm. The Casimir effect 
plays an important role in microelectromechanical devices, in short, MEMS. 
These are systems with moving mechanical parts embedded in silicon chips 
at micro- and submicroscales. Examples of MEMS are microrefrigerators, 
actuators, sensors, and switches. In the production of MEMS, the Casimir 
effect can sometimes produce unwanted effects like sticking between parts, but 
it can also be used to produce mechanical effects like bending and twisting. A 
practical use for the Casimir effect in our everyday lives is the pressure sensors 
of airbags in cars. Casimir energy is bound to make significant changes in our 
concept of vacuum. 
15.11 INFINITE PRODUCTS 
Infinite products are closely related to infinite series. Most of the known func- 
tions can be written as infinite products, which are also useful in calculating 
some of the transcendental numbers. We define the Nth partial product of 
an infinite product of positive terms as 
N 
(15.208) 
n= 1 
If the limit 
N 
(15.209) 

INFINITE PRODUCTS 
469 
exists, then we say the infinite product is convergent and write 
M 
(15.210) 
n= 1 
Infinite products satisfying the condition lim fn > 1 are divergent. When the 
condition 0 < lim fn < 1 is satisfied it is advantageous to write the product 
as 
n-m 
n-oo 
(15.211) 
The condition an + 0 as n + 00 is necessary, but not sufficient] for conver- 
gence. Using the In function we can write an infinite product as an infinite 
sum as 
m 
(15.212) 
n= 1 
n= 1 
Theorem: When the inequality 0 5 an < 1 is true, then the infinite prod- 
ucts nr=,(l+un) and n ~ = , ( l - u n )  converge or diverge with the infinite 
series 
Proof: Since 1 + an 5 ean is true, we can write 
4 
can = 1 +an + - + - - -  
. 
2! 
Thus the inequality 
N 
N 
P N  = 0 
(1 + an) 5 0 
ean = exp { 5 
an} = esN 
n=l 
n= 1 
n=1 
is also true. Since in the limit as N + co we can write 
(15.213) 
(15.214) 
(15.215) 
(15.216) 
we obtain an upper bound to the infinite product. For a lower bound 
we write the Nth partial sum as 
N 
N
N
 
P N  = 1 fxai +F,y,(Liaj 
+... . 
i=l 
i = l j = I  
(15.217) 

470 
INFINITE SERIES 
Since ai 2 0, we obtain the lower bound as 
03 
m 
Both the upper and the lower bounds to the infinite product Ilr=l(l 
+ 
a,) depend on the series c,”=l 
a,; thus both of them converge or diverge 
together. Proof for the product IIrZl 
(1 - a,) is done similarly. 
15.11.1 
An nth order polynomial with n real roots can be written as a product: 
Sine, Cosine, and the Gamma Functions 
n 
P,(.) 
= (z - q)(z - z2). . . (z - 2,) = IT(. - Xi). 
(15.219) 
i=l 
Naturally a function with infinitely many roots can be expressed as an infinite 
product. We can find the infinite product representations of the sine and 
cosine functions using complex analysis: 
In the z-plane a function, h(z), with simple poles at z = U, 
(0 < ]all < 
la21 < -..) can be written as 
(15.220) 
where b, is the residue of the function at the pole a,. 
This is also known 
as the Mittag-Leffler theorem. We have seen that a function analytic on the 
entire z-plane is called an entire function. For such a function its logarithmic 
derivative, f’/f, has poles and its Laurent expansion must be given about the 
poles. If an entire function f ( z )  has a simple zero at z = a,, then we can 
write 
f(z) = ( 2  - a,)g(z). 
(15.221) 
g(z) is again an analytic function satisfying g(z) # g(a,). 
Using the above 
equation we can write 
(15.222) 
Since a, is a simple pole of f’/f, we can take b, = 1 and h(z) = f’/f in 
Equation (15.220) to write 
(15.223) 

INFINITE PRODUCTS 
471 
Integrating Equation (15.223) gives 
and finally the general expression is obtained as 
(15.225) 
Applying this formula with z = x to the sine and cosine functions we obtain 
2 2  
00 
s i n z = z n  (I---) nW 
n=l 
(15.226) 
and 
(15.227) 
These products are finite for all the finite values of x. For sin x this can easily 
be seen by taking an = x2/n27rz. Since the series Cr==, 
an is convergent, the 
infinite product is also convergent: 
(2n - 
4x2 
1)27r2 ) . 
cosx= fi (1- 
n= 1 
In the sinx expression if we take x = 4 we obtain 
CO 
n= 1 
n=l 
Writing this as 
2 . 2 4 . 4 6 . 6  
00 
7r 
n= 1 
we obtain Wallis' famous formula for 7r/2. 
Infinite products can also be used to write the r function as 
where y is the Euler-Masheroni constant 
y = 0.577216 ... 
(15.228) 
(15.229) 
(15.230) 
(15.231) 
(15.232) 

472 
INFINITE SERIES 
Using Equation (15.231) we can write 
r(-X)r(x) 
(15.233) 
which is also equal to 
(15.234) 
Problems 
15.1 Show that the sum of the series 
is given as 
Expand the result in powers of Q to obtain 
- 
L 7 1 .  
Eo=--- 
+ (terms in positive powers of a). 
271.~2 6L 
15.2 
in Problem 15.1, that is, 
Using the Euler-Maclaurin sum formula find the sum of the series given 
and then show that it agrees with the expansion given in the same problem. 
15.3 Find the Casimir energy for the massless conformal scalar field on the 
surface of a sphere (S-2) with constant radius &. The divergent vacuum 
energy is given as (we set c=fi=l) 

PROBLEMS 
473 
where the degeneracy, gn, and the eigenfrequencies, wn, are given as 
Note: Interested students can obtain the eigenfrequencies and the degen- 
eracy by solving the wave equation for the massless conformal scalar field: 
1 ( n - 2 )  
4 ( n - 1 )  
O @ ( f , t )  + -~ 
R @ ( 7 , t )  
= 0, 
where n is the dimension of spacetime, R is the scalar curvature, and 0 
is the 
d' Alembert (wave) operator 
!J = 9pvap3v, 
(15.235) 
where a, stands for the covariant derivative. Use the separation of variables 
method and impose the boundary condition Q, = finite on the sphere. For this 
problem spacetime dimension n is 3 and for a sphere of constant radius, &, 
the curvature scalar is 2/R& 
15.4 Using asymptotic series evaluate the logarithmic integral 
dt 
O < z < l .  
Hint: Use the substitutions t = e-" and a = -lnx, a > 0, and integrate by 
parts successively to write the series 
1 
I !  
21 
(n - I ) !  
a 
a2 
a3 
an 
- --+- 
-... +(-I)"-'- 
where 
so that 
15.5 
massless conformal scalar field with thermal spectrum can be written as 
In a closed Einstein universe the renormalized energy density of a 

474 
INFINITE SERIES 
where & is the constant radius of the universe, T is the temperature of 
the radiation, and (2x21i$) is the volume of the universe. The second term 
(-) 
inside the square brackets is the well-known renormalized quantum 
vacuum energy, that is, the Casimir energy for the Einstein universe. 
First find the high and low temperature limits of (p}ren. and then obtain 
the flat spacetime limit & -+ 
03. 
15.6 
places: 
tic 
240& 
Without using a calculator evaluate the following sum to five decimal 
0
0
.
 
n=6 
How many terms did you have to add? 
15.7 Check the convergence of the series 
15.8 Find the interval of convergence for the series 
15.9 Evaluate the sums cr=o 
an cos ne 
(b) C,"==, 
an sin d, 
a is a constant 
Hint: Try using complex variables. 
15.10 Verify the following Taylor series: 
X" 
00 
ex = C 12? for all z 
n=O 
and 

PROBLEMS 
475 
15.11 Find the first three nonzero terms of the following Taylor series: 
a) 
f(x) = x3 + 2x + 2 about z = 2 
b) 
f(x) = e2= cos x about x = 0 
15.12 Another important consequence of the Lorentz transformation is the 
formula for the addition of velocities, where the velocities measured in the K 
and R frames are related by the formula 
dx 
&1 
dt 
di 
where u1 = - 
and El = - 
are the velocities measured in the K and I? 
frames, respectively, and R is moving with respect to K with velocity u along 
the common direction of the x- and Z-axes. Using the binomial formula find 
an appropriate expansion of the above formula and show that in the limit of 
small velocities this formula reduces to the well-known Galilean result 
15.13 
as 
In Chapter 10 we have obtained the formulas for the Doppler shift 
w = rw’(1 - PCOS8) 
tan@ = sinQ/y(cose -p), 
where 8, 8’ are the angles of the wave vectors k and k with respect to the 
relative velocity 37’ of the source and the observer. Find the nonrelativistic 
limit of these equations and interpret your results. 
15.14 Given a power series 
- - i -  
show that the differentiated and integrated series will have the same radius 
of convergence. 
15.15 Expand 
1 
h(x) = tanhz - - 
2 

476 
INFINITE SERIES 
as a power series of x. 
15.16 Find the sum 
1 
X 
x2 
x4 
1 - 2  2 - 3  3 . 4  
4 . 5  
g(x) = - 
+ - 
+ - 
+ - 
+ -. 
Hint: First try to convert into geometric series. 
h ( 1 - x )  . 
1 
1-z 
g(x) = - + - 1 
Answer: [ 
x 
2 2  
15.17 Using the geometric series evaluate the sum 
W C n3xn 
n= 1 
exactly for the interval 1x1 < 1, then expand your answer in powers of X. 
15.18 By using the Euler-Maclaurin sum formula evaluate the sum 
W C n3xn 
n=l 
Show that it agrees with the expansion found in Problem 15.17. 

16 
INTEGRAL 
TRANSFORMS 
Integral transforms are among the most versatile mathematical tools. Their 
applications range from solution of differential equations to evaluation of def- 
inite integrals and from solution of systems of coupled differentia1 equations 
to integral equations. They can even he used for defining differintegrals, that 
is, fractional derivatives and integrals (Chapter 14). In this chapter, after a 
general introduction we mainly discuss two of the most frequently used inte- 
gral transforms, the Fourier and the Laplace transforms, their properties, and 
techniques. 
Commonly encountered integral transforms allow us to relate two functions 
through the integral 
(16.1) 
where g(a) is called the integral transform of f ( t )  with respect to the kernel 
~ ( a ,  
t). These transformations are also linear, that is, if the transforms 
exist, then one can write 
(16.3) 
4 77 

478 
INTEGRAL TRANSFORMS 
and 
b 
C 9 l  (a) = 1 I d 1  (t>l4a, 
t ) d t ,  
(16.4) 
where c is a constant. Integral transforms can also be shown as an operator: 
where the operator =€(a,t) 
is defined as 
(16.6) 
We can now show the inverse transform as 
16.1 
SOME COMMONLY ENCOUNTERED INTEGRAL 
TRANSFORMS 
Fourier transforms are among the most commonly encountered integral trans- 
forms. They are defined as 
l
o
o
 
(16.8) 
g(a) = - 1 f(t)ei"tdt. 
Because the kernel of the Fourier transform is also used in defining waves, 
they are generally used in the study of wave phenomena. Scattering of X-rays 
from atoms is a typical example. The Fourier transform of the amplitude of 
the scattered waves gives the electron distribution. Fourier cosine and sine 
transforms are defined as 
d% 
-cc 
(16.10) 
Other frequently used kernels are 
e-at, tJn(at), 
and ta-'. 
(16.11) 
The Laplace transform is defined as 
( 16.12) 

DERIVATION OF THE FOURIER INTEGRAL 
479 
and it is very useful in finding solutions of systems of ordinary differential 
equations by converting them into a system of algebraic equations. The Han- 
kel or Fourier-Bessel transform is defined as 
and it is usually encountered in potential energy calculations in cylindrical 
coordinates. Another useful integral transform is the Mellin transform: 
(16.14) 
The Mellin transform is useful in the reconstruction of 
functions" from power series expansions. Weierstrass function is defined as 
"Weierstrass-type 
00 
(16.15) 
n=O 
where a and b are constants. It has been proven that, provided 0 < b < 1, 
a > 1, and ab > 1, the Weierstrass function has the interesting property of 
being continuous but nowhere differentiable. These interesting functions have 
found widespread use in the study of earthquakes, rupture, financial crashes, 
etc. (Gluzman and Sornette). 
16.2 
DERIVATION OF THE FOURIER INTEGRAL 
16.2.1 
Fourier Series 
Fourier series are very useful in representing a function in a finite interval, 
like [0,27r] or [-L, L], or a periodic function in the infinite interval (-CO,CO). 
We now consider a nonperiodic function in the infinite interval (-o,co). 
Physically this corresponds to expressing an arbitrary signal in terms of sine 
and cosine waves. We first consider the trigonometric Fourier expansion of a 
sufficiently smooth function in the finite interval [-L, L] as 
Fourier expansion coefficients a, and b, are given as 
(16.17) 
(16.18) 

480 
[NTEGRAL TRANSFORMS 
Substituting an and b, explicitly into the Fourier series and using the trigone 
metric identity 
cos(a - b) = cos a cos b + sin a sin b, 
(16.19) 
we get 
Since the eigenfrequencies are given as w = y, 
where n = 0,1,2,. . . , the 
distance between two neighboring eigenfrequencies is 
(16.21) 
R 
aw=-. 
L 
Using Equation (16.21) we can write 
f(z) = IL 
f ( t ) d t  + 12 
A w I W  f(t)ccsw(t - x ) d t .  
(16.22) 
-00 
n = ~  
2L 
- L  
We now take the continuum limit, L + 03, where we can make the replace 
ment 
00 
A w ---t l m d w .  
n=l 
(16.23) 
Thus the Fourier integral is obtained as 
f(.) 
= a 1°0 
dw 1: 
f ( t )  cosw(t - z)dt. 
(16.24) 
In this expression we have assumed the existence of the integral 
00 1, f 
(16.25) 
For the Fourier integral of a function to exist, it is sufficient for the integral 
I-", If(t)l dt to be convergent. 
We can also write the Fourier integral in exponential form. Using the fact 
that sin w ( t  - x) is an odd function with respect to w, 
we can write 
03 
(16.26) 
Also since cosw(t - x )  is an even function with respect to w, 
we can extend 
the range of the w integral in the Fourier integral to (-00, 00) as 
1
"
 
l, 
dw 1, f ( t )  sinw(t - x ) d t  = 0. 
00 
f(.) 
= & ./" dw .I_, f ( t )  cosw(t - z)dt. 
(16.27) 
-~ 00 

FOURIER AND INVERSE FOURIER TRANSFORMS 
481 
We now multiply Equation (16.26) by z and then add Equation (16.27) to 
obtain the exponential form of the Fourier integral as 
f(.) 
= 2 1 dwe-iWx 1, f weiwt& 
(16.28) 
where w is a parameter; however, in applications to waves it is the angular 
frequency. 
W 
03 
27r 
--oo 
16.2.2 Dirac-Delta Function 
Let us now write the Fourier integral as 
where we have interchanged the order of integration. The expression inside 
the curly brackets is nothing but the Dirac-delta function: 
(16.30) 
which has the following properties: 
6(. - u) = 0, ( 5 # a), 
(16.31) 
6(z - a)& = 1, 
(16.32) 
- a)f(.)d. 
= f(a), 
(16.33) 
00 1, 
where f(z) is continuous at 2 = a. 
16.3 FOURIER AND INVERSE FOURIER TRANSFORMS 
We write the Fourier integral theorem [Eq. (16.28)] as 
We now define the Fourier transform of f ( t )  as 
1 
P o 0  
where the inverse Fourier transform is defined as 
(16.34) 
(16.35) 
1
"
 
f ( t )  = - / g(w)eciwtdw. 
6 
--co 

482 
INTEGRAL TRANSFORMS 
Fig. 16.1 Wave train with N = 5 
16.3.1 Fourier Sine and Cosine Transforms 
When f ( t )  is an even function we can write 
fc(-.) 
= f c ( z ) .  
Using the identity 
(16.36) 
eiWt - 
- cos wt + i sin wt, 
(16.37) 
we can also write 
gc(w> = - fc(t) (cos wt + i sin wt) dt. 
(16.38) 
Considering that sin wt is an odd function with respect to t, the Fourier cosine 
transform is obtained as 
gc(w) = &yfc(I)cosLltdt. 
(16.39) 
& 1, 
The inverse Fourier cosine transform is given as 
f c ( t )  = Ely 
gc(w) coswtdw. 
Similarly, for an odd function we can write 
f3(-.) 
= -fs(.). 
From the Fourier integral we obtain its Fourier sine transform as 
gs(w) = Ely 
f,(t)sinwtdt, 
and its inverse Fourier sine transform is 
fs(z) 
= EJr(mgs(w)sinwzdw. 
(16.40) 
(16.41) 
(16.42) 
(16.43) 

FOURIER A N D  INVERSE FOURIER TRANSFORMS 
483 
Example 16.1. Fourier analysis of finite wave train: We now find the 
Fourier transform of a finite wave train, which is given as 
(16.44) 
For N = 5 this wave train is shown in Figure 16.1. 
Since f ( t )  is an odd function we find its Fourier sine transform as 
(16.45) 
gs(w) = & [ 2 (WO - W )  
2(wo+w) I . 
2 sin (wO - w) 
EL 
sin (wo + w) 
wo - 
For frequencies w - wo only the first term in Equation (16.45) domi- 
nates. Thus gs(w) 
is given as in Figure 16.2. 
This is the diffraction pattern for a single slit. It has zeroes at 
Go-w 
nw 
1
2
 
-- - - =*- +-,... . 
WO 
wo 
N’ N 
(16.46) 
Because the contribution coming from the central maximum dominates 
the others, to form the wave train [Eq. (16.44)] it is sufficient to take 
waves with the spread in their frequency distribution as 
WO 
N 
aw = -. 
(16.47) 
For a longer wave train, naturally the spread in frequency is less. 
fig. 16.2 g9(w) function 

484 
INTEGRAL TRANSFORMS 
16.3.2 
Fourier Transform of a Derivative 
First we find the Fourier transform of - 
d f ( x )  as 
d x  
(16.48) 
Using integration by parts we write 
Assuming that f(x) 
---f 0 as x --f &m we obtain the Fourier transform of the 
first derivative as 
g1(w) = -iwg(w). 
(16.50) 
Assuming that all the derivatives 
f " - W ,  fnP2(4, 
f"-3(x),. . . , f(x) 
(16.51) 
go to zero as 5 ---f f m ,  we write the Fourier transform of the nth derivative 
as 
sn(w) = (-iw)ng(w). 
(16.52) 
Example 16.2. Partial differential equations and Fourier transforms: 
One of the many uses of integral transforms is solving partial differential 
equations. Consider vibrations of an infinitely long wire. The equation 
to be solved is the wave equation, which is given as 
(16.53) 
where v is the velocity of the wave and y ( x ,  t) is the displacement of the 
wire from its equilibrium position as a function of position and time. As 
our initial condition we take the shape of the wire at t = 0 as 
Y ( 5 ,  0) = f(4. 
(16.54) 
We now take the Fourier transform of the wave equation with respect 
to x as 
2 
1 d 2 Y ( a , t )  
(-ia) Y(a,t) = - 
v2 
dt2 
' 
(16.56) 

FOURIER AND INVERSE FOURIER TRANSFORMS 
485 
where Y(a, t )  represents the Fourier transform of y(z, t): 
Y(a,t) = - 1, y(z,t)ei""dz. 
(16.57) 
6 
-00 
From Equation (16.56) we see that the effect of the integral transform on 
the partial differential equation is to reduce the number of independent 
variables. Thus the differential equation to be solved for Y ( a ,  t )  is now 
an ordinary differential equation, solution of which can be written easily 
as 
Y (a, t )  = F(a)e*iuat. 
(16.58) 
F ( a )  is the Fourier transform of the initial condition 
which gives 
F ( a )  = Y(a, 
0) 
(16.59) 
(16.60) 
1
*
 
- 
- 1, f(x)ei""dx. 
To be able to interpret this solution we must go back to y(z, t )  by taking 
the inverse Fourier transform of Y ( a ,  t) as 
l
a
 
- 
- [, 
F(a)e-ia(xjvt)da. 
Because the last expression is nothing but the inverse Fourier transform 
of F(a), we can write the final solution as 
This represents a wave moving to the right or left with the velocity 
and with its shape unchanged. 
16.3.3 Convolution Theorem 
Let F(t) and G(t) be the Fourier transforms of two functions f(z) 
and g(z), 
respectively. Convolution of f(z) and g(z) is defined as 

486 
JNTEGRAL TRANSFORMS 
Using the definition of Fourier transforms we can write the right-hand side as 
03 
l
o
”
 
- 
- 
J, @(t)e-it” 1, ~zJg(y)eitY, 
03 
= 1, dtF(t)G(t)e-itx, 
(16.64) 
which is nothing but the convolution of f(z) 
and g ( z ) .  For the special cme 
with x = 0 we get 
03 
00 
S, 
~ ( t ) ~ ( t ) d t  
= 1, 
g(y)f(-y)dy. 
(16.65) 
16.3.4 
Existence of Fourier Transforms 
We can show the Fourier transform of f(x) in terms of an integral operator 
3 as 
(16.66) 
For the existence of the Fourier transform of f(x), a sufficient but not neces- 
sary condition is the convergence of the integral 
(16.67) 
16.3.5 
Fourier Transforms in Three Dimensions 
Fourier transforms can also be defined in three dimensions as 
Substituting Equation (16.68) back in Equation (16.69) and interchanging the 
order of integration we obtain the three dimensional Dirac-delta function as 
These formulas can easily be extended to n dimensions. 

SOME THEOREMS ON FOURER TRANSFORMS 
487 
16.4 SOME THEOREMS ON FOURIER TRANSFORMS 
(16.71) 
J-00 
J -00 
Parseval Theorem I1 
00 
00 
F(k)G(-k)dk = .I_, 
g(z)f(x)h, 
(16.72) 
where F ( k )  and G(k) are the Fourier transforms of f(x) and g(z), respec- 
Proof: To prove these theorems we make the k + -k change in the Fourier 
1, 
tively. 
transform of g(x): 
G(-k) = - 
Srn g(z)e-i"h. 
(16.73) 
Multiplying the integral in Equation (16.73) with F ( k )  and integrating it over 
k in the interval (-m, co) we get 
6 
Poi) 
00 
00 
dkF(k)G(-k) = / dkF(k)- 1" hg(z)e-i". 
(16.74) 
la 
-00 
6 
-00 
Assuming that the integrals 
00 
00 
lf(x>I h and[_ 
Ig(41 dx 
(16.75) 
.I_, 
converge, we can change the order of the k and x integrals as 
Assuming that the inverse Fourier transform of F ( k )  exists, the second Parce- 
Val theorem is proven. 
If we take 
f(.) 
= 
(16.77) 
in Equation (16.72), remembering that 
G(-k) = G(k)*, 
(16.78) 
we can write 
(16.79) 
J --M 
J - C C  

488 
INTEGRAL TRANSFORMS 
which is the first Parceval theorem. From this proof it is seen that pointwise 
existence of the inverse Fourier transform is not necessary; that is, as long as 
the value of the integral 
does not change, the value of the integral 
(16.80) 
(16.81) 
can be different from the value of f(z) 
at some isolated singular points. In 
quantum mechanics wave functions in position and momentum spaces are 
each others’ Fourier transforms. The significance of Parseval’s theorems is 
that normalization in one space ensures normalization in the other. 
Example 16.3. Diffusion problem in one dimension: Let us consider 
a long thin pipe filled with water and with M g of salt located at XO. We 
would like to find the concentration of salt as a function of position and 
time. Because we have a thin pipe, we can neglect the change in concen- 
tration acrms the width of the pipe. The density (concentrationxmass) 
satisfies the diffusion equation: 
(16.83) 
Because at t = 0, the density is zero everywhere except at XO, we take 
our initial condition as 
(16.84) 
In addition, for all times the limits 
Iim p(z,t) = p(fco7t) = 0 
(16.85) 
must be satisfied. Because we have an infinite pipe and the density 
vanishes at the end points, we have to use Fourier transforms rather 
than the Fourier series. Because the total amount of salt is conserved, 
we have 
X i i W  
(16.86) 

SOME THEOREMS ON FOURIER TRANSFORMS 
489 
which is sufficient for the existence of the Fourier transform. Taking the 
Fourier transform of the diffusion equation with respect to z we get 
(16.87) 
dR(k t )  
- 
= -Dlc2R(k,t). 
dt 
This is an ordinary differential equation, where R(k,t) is the Fourier 
transform of the density. The initial condition for R(k,t) is the Fourier 
transform of the initial condition for the density, that is, 
The solution of Equation (16.87) can easily be written as 
R(k,t) = R(b,0)e-Dk2t. 
(16.89) 
To find the density we have to find the inverse Fourier transform of 
llil 
eikxo -Dk2t 
R(k,t) = - 
e 
A f i  
(16.90) 
(16.91) 
(16.92) 

490 
INTEGRAL TRANSFORMS 
Check that this solution satisfies the diffusion equation with the initial 
condition 
16.5 LAPLACE TRANSFORMS 
The Laplace transform of a function is defined as 
e-stF(t)dt. 
s > 0 and real. 
(16.93) 
(16.94) 
For this transformation to exist we do not need the existence of the integral 
Lcc 
F(t)dt. 
(16.95) 
In other words, F(t) could diverge exponentially for large values oft. However, 
if there exists a constant SO and a pmitive constant C, such that for sufficiently 
large t, that is t > to, the inequality 
le-sOtF(t)l 5 C 
(16.96) 
is satisfied, then the Laplace transform of this function exists for s > SO. An 
example is the 
F(t) = e2t2 
(16.97) 
function. For this function we cannot find a suitable SO and a C value that 
satisfies Equation (16.96); hence its Laplace transform does not exist. The 
Laplace transform may also fail to exist if the function F(t) has a sufficiently 
strong singularity as t + 0. The Laplace transform of t" 
fcc 
.€ {t"} = lo e-sttndt 
(16.98) 
does not exist for n 5 -1 values, because it has a singular point at the origin. 
On the other hand, for s > 0 and n > -1, the Laplace transform is given as 
n! 
.€ {t"} = - 
Sn+ 1 
(16.99) 

INVERSE LAPLACE TRANSFORMS 
491 
. 
Single point 
t 
Fig. 16.3 Null function 
16.6 
INVERSE LAPLACE TRANSFORMS 
Using operator language we can show the Laplace transform of a function as 
The inverse transform of f(s) is now shown with L-' as 
2-l { f ( s ) }  = F(t). 
(16.101) 
In principle, the inverse transform is not unique. Two functions Fl(t) and 
Fz(t) could have the same Laplace transform; however, in such cases the 
difference of these functions is 
where for all to values N ( t )  satisfies 
lo 
N(t)dt = 0. 
(16.103) 
N ( t )  is called a null function, and this result is also known as the Lerch 
theorem. In practice we can take N ( t )  as zero, thus making the inverse 
Laplace transform unique. In Figure 16.3 we show a null function. 

492 
INTEGRAL TRANSFORMS 
16.6.1 
Bromwich Integral 
A formal expression for the inverse Laplace transform is given in terms of the 
Bromwich integral as 
(16.104) 
where y is real and s is now a complex variable. The contour for the above 
integral is an infinite straight line passing through the point y and parallel 
to the imaginary axis in the complex s-plane. y is chosen such that all the 
singularities of estf(s) are to the left of the straight line. For t > 0 we can 
close the contour with an infinite semicircle to the left-hand side of the line. 
The above integral can now be evaluated by using the residue theorem to find 
the inverse Laplace transform. 
The Bromwich integral is a powerful tool for inverting complicated Laplace 
transforms when other means prove inadequate. However, in practice using 
the fact that Laplace transforms are linear and with the help of some basic 
theorems we can generate many of the inverses needed from a list of elementary 
Laplace transforms. 
16.6.2 
Elementary Laplace Transforms 
1. Many of the discontinuous functions can be expressed in terms of the 
Heavyside step function (Fig. 16.4) 
0 t < a  
{ 1 t > a ’  
U ( t  - a) = 
the Laplace transform of which is given as 
e- as 
x {U(t - u)} = -, S 
s > 0. 
2. For F(t) = 1, the Laplace transform is given as 
1 
~ { 1 }  
= Jowe-stdt = -, s > 0. 
S 
3. The Laplace transform of F ( t )  = elCt for t > 0 is 
4. Laplace transforms of hyperbolic functions 
(16.105) 
(16.106) 
(16.107) 
( 16.108) 
1 
2 
F ( t )  = coshkt = - (ekt + e-lCt) 

INVERSE LAPLACE TRANSFORMS 
493 
Fig. 16.4 Heavyside step function 
and 
1 
2 
F(t) = sinh kt = - (elct - e-lct) 
can be found by using the fact that X is a linear operator as 
S 
L {cosh k t }  = - 
k 
s2 - k2 ’ 
L {sinh kt} = 
~ 
(16.109) 
(16.110) 
where s > k for both. 
5. Using the relations 
cos kt = cosh ikt 
and 
sin kt = -i sinh kt, 
we can find the Laplace transforms of the cosine and the sine functions 
as 
S 
L {cos kt} = - 
s > 0, 
s2 + k2 ’ 
k 
s2+k2 ’ 
L {sin kt} = 
~ 
s > 0. 
6. For F ( t )  = tn we have 
(16.111) 
(16.112) 
n! 
L { P }  = - 
Sn+l, 
s > 0 ,  n >  -1. 
(16.113) 

494 
INTEGRAL TRANSFORMS 
16.6.3 Theorems About Laplace Transforms 
By using the entries in a list of transforms, the following theorems are very 
useful in finding inverses of unknown transforms: 
Theorem I: First Translation Theorem. 
If the function f ( t )  has the Laplace transform 
L {f(t>} 
= F(s), 
then the Laplace transform of eatf(t) is given as 
L { e a t f ( t ) }  = F(S - u). 
Similarly, if L-' {F(s)} = f ( t )  is true, then we can write 
L-' { F(S - u ) }  = eatf(t). 
Proof: 
(16.114) 
(16.115) 
(16.116) 
(16.117) 
Theorem 11: Second Translation Theorem. 
If F(s) is the Laplace transform of f ( t )  and the Heavyside step function 
is shown as U ( t  - a), we can write 
L {V(t - u)f(t - u ) }  = e-"'F(s). 
(16.118) 
Similarly, if L-' {F(s)} = f ( t )  is true, then we can write 
L-l { e-""F(s)} = ~ ( t  
- a ) f ( t  - u). 
(16.119) 
Proof: Since the Heavyside step function is defined as 
0 t < u  
{ 1 t > u  
U ( t  - u) = 
(16.120) 
we can write 

INVERSE LAPLACE TRANSFORMS 
495 
Changing the integration variable to u = t - a we obtain 
r m  
(16.122) 
Theorem 111: If L { f ( t ) }  = F(s) is true, then we can write 
(16.123) 
1
s
 
L {$(at)} = -F( -). 
a
a
 
If Ep' {F(s)} = f ( t )  is true, then we can write the inverse as 
.L-'{F(:)} = uf(at). 
(16.124) 
a 
Proof: Using the definition of the Laplace transform we write 
Changing the integration variable to u = at we find 
1
s
 
= -F(--). 
U 
Theorem I V  Derivative of a Laplace Transform. 
If the Laplace transform of f ( t )  is F(s), then the Laplace transform of 
t"f(t) is given as 
(16.127) 
where n = 0,1,2,3 ... . 
Similarly, if E-' {F(s)} = f ( t )  is true, then we can write 
(16.128) 
Proof: Since E { f ( t ) }  = F(s), we write 
r m  
(16.129) 

496 
INTEGRAL TRANSFORMS 
Taking the derivative of both sides with respect to s we get 
If we keep on differentiating we find 
and eventually the nth derivative as 
P o 3  
(16.133) 
Theorem V: Laplace Tkansform of Periodic Functions. 
If f ( t )  is a periodic function with the period p > 0, that is, f ( t  + p )  = 
f ( t ) ,  then we can write 
(16.134) 
On the other hand, if X-' {F(s)} = f(t) is true, then we can write 
ProoE We first write 
(16.135) 
(16.136) 
(16.137) 
(16.138) 

INVERSE LAPLACE TRANSFORMS 
497 
Making the variable change u --+ t and using the fact that f (t) is periodic 
we get 
(16.139) 
Theorem VI: Laplace Transform of an Integral. 
If the Laplace transform of f ( t )  is F(s), then we can write 
(16.142) 
(16.143) 
Similarly, if L-' {F(s)} = f ( t )  is true, then the inverse will be given 
as 
Proof: Let us define the G(t) function as 
r t  
Now we have G'(t) = f ( t )  and G(0) = 0; thus we can write 
E {G'(t)} = sL {G(t)} - G(0) 
= S E  {G(t)) 
7 
which gives 
L {G(t)} = E { L t f ( a ) d u }  = ;"E 1 { f ( t ) }  = -. F ( s )  
S 
(16.144) 
(16.145) 
(16.146) 
(16.147) 
(16.148) 
Theorem VII: If the limit l i m y  exists and if the Laplace transform of 
t i 0  
f ( t )  is F(s), then we can write 
(16.149) 

498 
INTEGRAL TRANSFORMS 
Similarly, if f-' 
{F(s)} = f (t) is true, then we can write 
( 16.150) 
Proof: If we write g ( t )  = y, 
we can take f ( t )  = tg(t). Hence we can write 
F ( s )  = f {f(t)} 
(16.151) 
dG(s) 
(16.152) 
d 
ds 
ds ' 
= f 
{tg(t)} = --f { g ( t ) }  = -- 
where we have used theorem VI. Thus we can write 
G(s) = - 1' F(u)du. 
(16.153) 
From the limit lims+rn G(s) = 0 we conclude that c = co . We finally 
obtain 
(16.154) 
Theorem VIII: Convolution Theorem. 
If the Laplace transforms of f (t) and g ( t )  are given as F(s) and G(s), 
respectively, we can write 
f {it 
f (u)g(t - u)du 
(16.155) 
Similarly, if the inverses E-' {F(s)} = f ( t )  
exist, then we can write 
and f-'{G(s)} = g ( t )  
r t  
L-' {F(s)G(s)} 
= 
(16.156) 
The above integral is called the convolution of f ( t )  and g(t), and it is 
shownas f * g :  
r t  
f * 9 = 
f(..>g(t - u)cI'IL. 
The convolution operation has the following properties: 
(16.157) 
f * 9 = 9 * f ,  
f * (9 * h) = ( f  * 9) * h- 
f * ( g f h )  = f * g + f  * h ,  
(16.158) 

INVERSE LAPLACE TRANSFORMS 
499 
Proof: We first form the convolution of the following transforms: 
F(s)G(s) = [la 
e-suf(u)du] [lei) e ~ ~ ~ g ( u ) d v ]  (16.159) 
(16.163) 
Note that with the t = u + z1 transformation, we have gone from the 
uv-plane to the ut-plane. 
Example 16.4. Inverse Laplace transforms: . 
1. We now find the function with the Laplace transform 
se-- 2s 
s2 + 16' 
(16.164) 
Since AC { *} 
= cos4t we can use theorem 11, which says 
L {U(t - u)f(t - u ) }  = e-""F(s). 
(16.165) 
Using the inverse 
AC-' 
{e-""F(s} = U ( t  - a)f(t - a), 
(16.166) 
we find 
= U(t - 2)c0s4 (t - 2, 
(16.167) 
0, 
< 2' 
(16.168) 
= { cos4(t-2), 
t >  2. 
2. To find the inverse Laplace transform of In 1 + - we write 
( 3 
~ ( s )  
= In (1 + :) 
(16.169) 

500 
INTEGRAL TRANSFORMS 
and find its derivative as 
1
1
 
s + l  
s 
F'(s) = __ - -_ 
(16.170) 
Using theorem IV we write 
L-' {"(")(")} 
= (-l)"t"f(t). 
(16.171) 
Applying this to our case we find 
(16.174) 
3. The inverse Laplace transform of 
1 
(16.175) 
S J s i  
can be found by making use of theorem VI. Since 
theorem VI allows us to write 
(16.176) 
(16.177) 
(16.178) 
We now make the transformation u = v 2  to write the resuit in 
terms of the error function as 
(16.180) 

INVERSE LAPLACE TRANSFORMS 
501 
16.6.4 
Method of Partial Fractions 
We frequently encounter Laplace transforms, which are expressed in terms of 
rational functions as 
f Y s )  = g(s)/h(s), 
(16.181) 
where g(s) and h(s) are two polynomials with no common factor and the order 
of g(s) is less than h(s). 
We have the following cases: 
i) When all the factors of h(s) are linear and distinct we can write f(s) as 
where ci are constants independent of s. 
ii) When one of the roots of h(s) is mth order we write f(s) as 
n 
(16.183) 
iii) When one of the factors of h(s) is quadratic like (sz f p s  + q) , we add 
ci 
+E,,. 
i=2 
a term to the partial fractions with two constants as 
us+b 
(16.184) 
To find the constants we usually compare equal powers of s. In the first case, 
we can also use the limit 
lim ( s  - ai) f ( s )  = ci 
(16.185) 
s-al 
to evaluate the constants. 
Example 16.5. Method of partial fractions: We use the method of par- 
tial fractions to find the inverse Laplace transform of 
We write f ( s )  as 
C 
u s f b  
fb) 
= sf2 + 
and equate both expressions as 
(16.186) 
(16.187) 
c (s2 + 2k2) + ( s  + 2) (as + b) . 
(16.188) 
- 
k2 
( s  + 2) (s2 + 2k2) - 
(s + 2) (s2 + 2k2) 

502 
INTEGRAL TRANSFORMS 
Comparing equal powers of s, we obtain three equations to be solved for 
a, b, and c as 
coefficient of s2 
coefficient of s , 
(16.189) 
coefficient of so 
(16.190) 
1 
c+a=O 
b + 2 a = O  
2b + 2ck2 = k2 
which gives 
c = -a, 
b = -2a, 
a = -k2/(2k2 + 4). 
We now have 
2 
a(s-2) 
f(3) = -- 
+ 
~ 
52 + 2k2' 
(s + 2) 
(16.191) 
inverse Laplace transform of which can be found easily as 
L-' {f(s)} = -a 
e-2t + cos f i k t  - - 
sin h k t  , a = -k2/((2k2 + 4). 
k 
(16.192) 
"
I
 
Example 16.6. Definite integrals and Laplace transforms: We can also 
use integral transforms to evaluate some definite integrals. Let us con- 
sider 
(16.193) 
Taking the Laplace transform of both sides we get 
= 
[la 
dte-st sin(tx) dx. 
1 
The quantity inside the square brackets is the Laplace transform of 
sintx. Thus we find 
dx 
(16.195) 
(16.196) 
O0 sintx 
7r 
L {F(t)} = -. 
(16.197) 
2s 

LAPLACE TRANSFORM OF A DERIVATIVE 
503 
Finding the inverse Laplace transform of this gives us the value of the 
definite integral as 
(16.198) 
ll 
F(t) = -, t > 0. 
2 
16.7 LAPLACE TRANSFORM OF A DERIVATIVE 
One of the main applications of Laplace transforms is to differential equa- 
tions. In particular, systems of ordinary linear differential equations with 
constant coefficients can be converted into systems of linear algebraic equa- 
tions, which are a lot easier to solve both analytically and numerically. The 
Laplace transform of a derivative is given as 
= SL {F(t)} - F(0). 
(16.201) 
To be precise, we mean that F(0) = F(f0) and dF(t)/dt is piecewise continu- 
ous in the interval 0 5 t < m. Similarly, the Laplace transform of higher-order 
derivatives can be written as 
.€ {F(Z)(t)) = s2L {F(t)} - sF(+O) - F'(+O), 
(16.202) 
L F(n)(t) = snL {F(t)} - sn-'F(+O) - s"-2F'(+O) - 
...-F("-')(+O). 
(16.203) 
with a simple example; simple harmonic oscillator with the equation of 
motion given as 
{
}
 
Example 16.7. Laplace transforms and differential equations: We start 
m- dt2 
Let us find a solution satisfying the boundary conditions 
~ ( 0 )  
= 20 and - 
lo = 0. 
(16.204) 
(16.205) 
Taking the Laplace transform of the equation of motion we obtain the 
Laplace transform of the solution as 
S 
X ( s )  = 20- 
S 2 f W ; '  
(16.206) 

504 
INTEGRAL TRANSFORMS 
X 
Fig. 16.5 Nutation of Earth 
We have written wz = k / m  . We now take the inverse Laplace transform 
to obtain the solution as 
S 
S 
z(t> = .€-I 
{XO-} 
= XOL-' { m} 
= xocoswot. (16.207) 
Example 16.8. Nutation of Earth: For the force-free rotation of Earth 
(Fig. 16.5), the Euler equations are given as 
= -aY 
- 
= ax. 
(16.208) 
This is a system of coupled ordinary differential equations with constant 
coefficients where we have defined a as 
a =  [9],, 
(16.2OS) 
and X and Y as 
x = w + ,  Y=w,. 
(16.210) 
I, is the moment of inertia about the z-axis, and because of axial sym- 
metry we have set I, = Iv. Taking the Laplace transform of this system 

LAPLACE TRANSFORM OF A DERIVATIVE 
505 
we obtain a set of coupled algebraic equations: 
sz(s) - X ( 0 )  = -uy(s) 
(16.211) 
and 
sy(s) - Y(0) = uz(s). 
The solution for z(s) can be obtained easily as 
(16.212) 
S 
X ( 5 )  = X(0)- 
- 
52 + u2 
(16.213) 
Taking the inverse Laplace transform we find the solution as 
X(t) = X(O)cosut - Y(O)sinut. 
(16.214) 
Similarly, the Y (t) solution is found as 
Y(t) =X(O)sinut+Y(O)cosat. 
(16.215) 
Example 16.9. Damped harmonic oscillator: Equation of motion for the 
damped harmonic oscillator is given as 
m?(t) + b i ( t )  + kz(t) = 0. 
(16.216) 
Let us solve this equation with the initial conditions z(0) = xo and 
2(0) = 0. Taking the Laplace transform of the equation of motion, we 
obtain the Laplace transform of the solution as 
m [s2X(s) - SXO] + b [sX(s) - 4 + kX(s) = 0, 
(16.217) 
ms+b 
ms2 + bs + k .  
X(s) = zo 
Completing the square in the denominator we write 
m
m
 
(16.218) 
(16.219) 

506 
INTEGRAL TRANSFORMS 
For weak damping, b2 < 4km, the last term is positive. Calling this w:, 
we find 
b 
S+-& 
X (  s) = xo 
(16.220) 
(s+ &J2 
+w; 
b
b
 
s+-+- 
2m 
2m 
2 
= xo 
(s+&) 
+w,2 
S+- 
- 
= xo 
2m 
+W; 
Taking the inverse Laplace transform of X ( s )  we find the final solution 
as 
(16.221) 
Check that this solution satisfies the given initial conditions. 
Example 16.10. Laplace transform of the tekt function: Usingtheel- 
ementary Laplace transform 
(16.222) 
and theorem IV, we can obtain the desired transform by differentiation 
with respect to s as 
s > k. 
1 
f {te"} = - 
( s  - k)2' 
(16.223) 
Example 16.11. Electromagnetic waves: For a transverse electromagnetic 
wave propagating along the x-axis, 
E = Ez or Ev 
satisfies the wave equation 
We take the initial conditions as 
E(x,O) = 0 and 
= 0. 
(16.224) 
(16.225) 

LAPLACE TRANSFORM OF A DERIVATIVE 
507 
Taking the Laplace transform of the wave equation with respect to t we 
obtain 
Using the initial conditions this becomes 
(16.227) 
which is an ordinary differential equation for L {E(z, 
t ) }  and can be 
solved easily as 
L {E(z,t)} 
= C I , C ( + ) ~  + cze(+)2, 
(16.228) 
where c1 and c2 are constants independent of x but could depend on s. 
In the limit as x + co, we expect the wave to be finite; hence we choose 
c2 as zero. If we are also given the initial shape of the wave as 
E(0, t )  = W), 
(16.229) 
we determine c1 as 
L(E(0,t)) = C ]  = f ( s ) .  
(16.230) 
Thus, with the given initial conditions, the Laplace transform of the 
solution is given as 
L {E(x,t)} = e - 
xf(s). 
(16.231) 
Using theorem I1 we can find the inverse Laplace transform, and the 
final solution is obtained as 
This is a wave moving along the positive z-axis with velocity u and 
without distortion. Note that the wave still has not reached the region 
2 > vt. 
Example 16.12. Bessel’s equation: We now consider Bessel’s equation, 
which is an ordinaly differential equation with variable coefficients: 
2 y ” ( z )  + xy’(z) + z2g(x) = 0. 
(16.233) 

508 
INTEGRAL TRANSFORMS 
Dividing this by x we get 
xy”(z) + y’(z) + xy(x) = 0. 
(16.234) 
Using Laplace transforms we can find a solution satisfying the boundary 
condition 
y(0) = 1. 
(16.235) 
From the differential equation (16.234), this also means that y’(+O) = 0. 
Assuming that the Laplace and the inverse Laplace transforms of the 
unknown function exist, that is, 
(16.236) 
x { Y k ) )  = f (317 x-’ { f ( s ) )  = Y(Z), 
we write the Laplace transform of Equation (16.234) as 
- - 
d [s2 f (s) - s] + s f (s) - 1 - --f(s) 
d 
= 0 
(16.237) 
ds 
ds 
(2 + l)f’(s) + sf ( 5 )  = 0 
After integration, we find f (s) as 
( 16.238) 
(16.239) 
To find the inverse we write the binomial expansion of f (s) as 
(16.240) 
C 
f(s) = 
1 
1.3 
= -  1--+ 
S [ 
2s2 
222!s4 
..+ (- 1)”( 2n)! +-.I. 
(2nn!)2 s2n 
(16.241) 
Using the fact that Laplace transforms are linear, we find the inverse as 
(16.242) 
Using the condition y(0) = 1, we determine the constant as c as one. 
This solution is nothing but the zeroth-order Bessel function JO(Z). 
Thus we have determined the Laplace transform of .lo($) as 
(16.243) 

LAPLACE TRANSFORM OF A DERIVATIVE 
509 
In general one can show 
In this example we see that the Laplace transforms can also be used for 
finding solutions of ordinary differential equations with variable coeffi- 
cients, however, there is no guarantee that they will work in general. 
Example 16.13. Solution of y" + (1/2)y = (a0/2) sint - (1/2)~(~"): 
This 
could be interpreted as a harmonic oscillator with a driving force d e  
pending on the fourth derivative of displacement as (ao/2) sin t-( 1/2)y(Z"). 
We write this equation as 
y(iw) + 2y" + y = 
sin t 
(16.245) 
and use the following boundary conditions (a0 is a constant): 
y(0) = 1, y'(0) = - 2 ,  y"(0) = 3, y"'(0) = 0. 
Taking the Laplace transform and using partial fractions we write 
[ s 4 ~  - s3(1) - s2(-2) - 4 3 )  - 01 
(16.246) 
2 
a0 
+ 2 [s Y - s(1) - (-2)] + Y = - 
s 2 + i 7  
where Y ( s )  is the Laplace transform of y(z). We solve this for Y to 
obtain 
+ s3 - 2s2 + 5s - 4, 
(16.247) 
a0 
(s4 + 2s2 + 1) Y = - 
s2 + 1 
s3 - 2 2  + 5s - 4 
+ 
a0 
Y =  
(s2 + q3 
(92 + q2 
' 
(16.248) 
uo 
( s ~ + s )  - 2 ( s 2 + 1 ) + 4 s - 2  
I 
(16.249) 
- 
- 
(.2 
+ 113 + 
(s2 + 1)2 
Using the theorems we have introduced the following inverses can be 
found: 
L-'{ (s2Tl)3} 
=a0 [ i s i n t -  
L - l {  ( s 2 + l ) 2 }  
4s - 2 
=2tsint-sint+tcost. 
(16.252) 

510 
INTEGRAL TRANSFORMS 
Fig. 16.6 Pendulums connected by a spring 
Finally, the solution is obtained as 
3 
+ 11 cost + [$(3 - t2) - 3 + 2t] sint. 
(16.253) 
Note that the solution is still oscillatory but the amplitude changes with 
time. 
Example 16.14. Two Pendlums interucting through a spring: Consider 
two pendulums connected by a vertical spring as shown in Figure 16.6. 
We investigate small oscillations of this system. 
As our initial conditions we take 
q(0) = ZZ(0) = 0, illo = 21, 
i21" = 0. 
(16.254) 
For this system and for small oscillations, equations of motion are given 
as 
(16.255) 
(16.256) 
m.9 
1 
m.9 
1 
m21 = --z1 
+ k(x2 - zl), 
mx2 = --x2 
+ k(zl - x2). 
We show the Laplace transforms of z1 and 22 as 
.€{Zi(t)} = X i ( S ) ,  i = 1,2 
(16.257) 
and take the Laplace transform of both equations as 
(16.258) 
m.9 
1 + k(X2 - Xl), 
m(s X] -.) 
= --x 
2 

RELATION BETWEEN LAPLACE AND FOURIER TRANSFORMS 
511 
ms 
2 X, = -
3
~
2
 
+ IC(X~ 
- ~ 2 ) .  
(16.259) 
This gives us two coupled algebraic equations. We first solve them for 
X I  (s) to get 
1 
(16.260) 
2, 
x1 
(s) = - [(s2 + g / i  + 2k/m)p1 + (s2 + g/l)-'] . 
2 
Taking the inverse Laplace transforni of X I  (s) gives us xi (t) as 
(16.261) 
In this solution 
(16.262) 
are the normal modes of the system. 
obtained similarly. 
The solution for x2(t) can be 
16.7.1 
Laplace transforms are defined in two dimensions as 
Laplace Transforms in n Dimensions 
dxdy. 
(16.263) 
This can also be generalized to n dimensions: 
E('LL1, 
U2, . . . ,4 
(16.264) 
= im lm.. 
. loo 
f(xl, 
22,. . . , x,)e-u1~1-~2~2- - u n x n d ~ l d ~ 2 . .  
. dx,. 
16.8 RELATION BETWEEN LAPLACE AND FOURIER 
TRANSFORMS 
The Laplace transform of a function is defined as 
roo 
We now use f (x) to define another function: 
(16.265) 
(16.266) 

512 
INTEGRAL TRANSFORMS 
The Fourier transform of this function is given as 
(16.267) 
Thus we can write the relation between the Fourier and Laplace transforms 
as 
F(p) = dGF+(ip). 
(16.268) 
16.9 MELLIN TRANSFORMS 
Another frequently encountered integral transform is the Mellin transform: 
P W  
(16.269) 
The Mellin transform of exp(--z) is the gamma function. We write 
x = ez 
(16.270) 
in the Mellin transform to get 
w 
~ , ( s )  = 1, f(ez)eszdz 
(16.271) 
Comparing this with 
(16.272) 
We get the relation between the Fourier and Mellin transforms as 
F,(s) = &G(-is). 
(16.273) 
Now all the properties we have discussed for the Fourier transforms can also 
be adopted to the Mellin transforms. 
Problems 
16.1 Show that the Fourier transform of a Gaussian, 
is again a Gaussian. 

PROBLEMS 
513 
16.2 Show that the Fourier transform of 
is given as 
16.3 
ing second-order inhomogeneous differential equation: 
Using the Laplace transform technique, find the solution of the follow- 
with the boundary conditions 
y(0) = 2 and y’(0) = -1. 
16.4 Solve the following system of differential equations: 
2z(t) - y(t) - y’(t) = 4(1 - exp(-t)) 
2z’(t) + y ( t )  = 2(1 +3exp(-2t)) 
with the boundary conditions 
z(0) = y(0) = 0. 
16.5 One end of an insulated semi-infinite rod is held at temperature 
T(t, 0) = To, 
with the initial conditions 
T(0, z) = 0 and T(t, m) = 0. 
Solve the heat transfer equation 
where k is the thermal conductivity, c is the heat capacity, and p is the 
density. 

514 
INTEGRAL TRANSFORMS 
Hint: The solution is given in terms of erf c as 
T(t,x) = Toerfc [IT] 
-- 
, 
where the erf c is defined in terms of erf as 
erf c(x) = 1 - erf x 
16.6 
t ion 
Find the current, I ,  for the IF1 circuit represented by differential equa- 
d I  
dt 
L- i- 
RI = E, 
with the initial condition 
I(0) = 0. 
E is the electromotive force and L, R, and E are constants. 
16.7 
of differential equations 
Using the Laplace transforms find the solution of the following system 
d x  - 
+y = 3e2t 
dt 
-+z=O, 
dY 
dt 
subject to the initial conditions 
x(0) = 2, v(0) = 0. 
16.8 Using the Fourier sine transform show the integral 
* s3sinsx 
e - x c o s x = i l  
ds, x > 0. 
16.9 
Using the Fourier cosine transform show the integral 
s2 + (cos sx)ds, x 2 0. 
16.10 
the end at the origin fixed. The shape of the string at t = 0 is given as 
Let a semi-infinite string be extended along the positive x-axis with 
Y(X, 0) = f(xL 

PROBLEMS 
515 
where y(x, t )  represents the displacement of the string perpendicular to the 
x-axis and satisfies the wave equation 
a is a constant. 
- 
a2Y 
2 a2Y 
at2 = a  G’ 
Show that the solution is given as 
dscas(sat)sin(sz) 
16.11 
Establish the Fourier sine integral representation 
-- 
Hint: First show that 
16.12 
Show that the Fourier sine transform of 
xe-ax 
is given as 
16.13 
Establish the result 
16.14 
Use the convolution theorem to show that 
k?’ { (s2 fh2,.} 
= f cos ht + -sin 
1 
bt. 
2h 
16.15 
of differentia1 equations: 
Use Laplace transforms to find the solution of the following system 
- -wy1 
dYl 
-- 
dx 
- -a2yz - Q3Y3, 
dY3 
-- 
dx 

516 
INTEGRAL TRANSFORMS 
with the boundary conditions yl(0) = CO, yz(0) = y3(0) = 0. 
16.16 Laguerre polynomials satisfy 
zLK + (1 - t)L:, + nL,(z) = 0. 
Show that L'{L,(az)} = (s - 
s > 0. 

17 
VARIATIONAL 
ANALYSIS 
Variational analysis is basically the study of changes. We are often interested 
in finding how a system reacts to small changes in its parameters. It is for this 
reason that variational analysis hes found a wide range of applications not just 
in physics and engineering but also in finance and economics. In applications 
we frequently encounter caees where a physical property is represented by an 
intwal, the extremum of which is desired. Compared to ordinary calculus, 
where we deal with functions of numbers, these integrals are functions of 
some unknown function and its derivatives; thus, they are called functionals. 
Search for the extremum of a function yields the point at which the function is 
extremum. In the caee of functionals, variational analysis gives us a differential 
equation, which is to be solved for the extremizing function. 
After Newton’s formulation of mechanics mange developed a new a p  
pmch, where the equations of motion are obtained from a variational integral 
called action. This new formulation makes applications of Newton’s theory 
to many particles and continuous systems poesible. Today in making the 
transition to quantum mechanics and to quantum field theories w
a
n
 
formulation is a must. 
Geodesics are the shortest paths between two points in a given geametry 
and constitute one of the main applications of variational analysis. In Ein- 
stein’s theory of gravitation geodesics play a central role tu the paths of freely 
moving particles in curved spacetime. Variational techniques also form the 
mathematical basis for the finite elements method, which is a powerful tool for 
solving complex boundary value problems, and stability analysis. Variational 
analysis and the Rayleigh-Ritz method ale0 allows us to find approximate 
eijpnvalues and eigenfunctions of a Sturm-Liouville system. 
517 

518 
VARIATIONAL ANALYSIS 
I 
I 
fig. 17.1 Variation of paths 
17.1 PRESENCE OF ONE DEPENDENT AND ONE INDEPENDENT 
VARIABLE 
17.1.1 
Euler Equation 
A majority of the variational problems encountered in physics and engineering 
are expressed in terms of an integral: 
(17.1) 
where y(x) is the desired function and f is a known function depending on 
y, its derivative with respect to x, that is yx, and x. Because the unknown of 
this problem is a function, J is called a functional and we write it as 
J [Y (XI1 . 
(17.2) 
Usually the purpose of these problems is to find a function, which is a path in 
the xy-plane between the points ( 2 1 ,  y1) and (zz, yz), which makes the func- 
tional J [y (z)] an extremum. In Figure 17.1 we have shown two potentially 
possible paths; actually, there are infinitely many such paths. The difference 
of these paths from the desired path is called the variation of y, and we show 
it as Sy. Because Sy depends on position, we use ~ ( z )  
for its position depen- 
dence and use a scalar parameter a as a measure of its magnitude. Paths 
close to the desired path can now be parametrized in terms of LY as 
Y(X, a )  = y(x, 0) + ar](x) + O(O2), 
(17.3) 

PRESENCE OF ONE DEPENDENT AND ONE INDEPENDENT VARIABLE 
519 
where y(z, a = 0) is the desired path, which extremizes the functional J[Y(X)]. 
We can now express Sy as 
SY = Y(Z, a )  - Y(Z,O) = arl(z) 
(17.4) 
and write J as a function of a as 
J ( a )  = L; f [ Y ( Z , ~ ) , Y X ( ~ , ~ ) , ~ l d X .  
(17.5) 
Now the extremum of J can be found as in ordinary calculus by impwing the 
condition 
(17.6) 
In this analysis we assume that T?(Z) is a differentiable function and the vari- 
ations at the end points are zero, that is, 
Now the derivative of J with respect to cy is 
Using equation (17.3) we can write 
and 
a Y x ( z ,  a) 
d ? 7 ( 4  
- 
aa 
& 
Substituting these in Equation (17.8) we obtain 
Integrating the second term by parts gives 
(17.7) 
(17.8) 
(17.9) 
(17.10) 
(17.11) 
(17.12) 
Using the fact that the variation at the end points are zero, we can write 
Equation (17.11) as 
(17.13) 

520 
VARlAT/ONAL ANALYSIS 
Because the variation ~ ( x )  
is arbitrary, the only way to satisfy this equation 
is by setting the expression inside the brackets to zero, that is, 
(17.14) 
In conclusion, variational analysis has given us a second-order differential 
equation to be solved for the path that extremizes the functional J[y(z)]. 
This differential equation is called the Euler equation. 
17.1.2 
To find another version of the Euler equation we write the total derivative of 
the function f (y, y,, x) as 
Another Form of the Euler Equation 
df - 8.f 
af dYx 
af 
-y, 
+ -- 
+ -. 
dx 
8y 
ay, dx 
dx 
- _  
Using the Euler equation [Eq. (17.14)] we write 
af 
d af 
ay 
dx a ~ ,  
- 
= -- 
and substitute into Equation (17.15) to get 
This can also be written as 
f-yx- 
=o. 
af 
d 
---[ 
ax 
dx 
(17.15) 
(17.16) 
(17.17) 
(17.18) 
This is another version of the Euler equation, which is extremely useful when 
f (y, yx, x) does not depend on the independent variable x explicitly. In such 
cases we can immediately write the first integral as 
8.f 
aYx 
f - yx- 
= constant, 
(17.19) 
which reduces the problem to the solution of a first-order differential equation. 
17.1.3 
Example 17.1. Shortest path between two points: To find the shortest 
Applications of the Euler Equation 
path between two points in two dimensions we 
ds = [(dx)' + ( d ~ ) ~ ] '  
write the line element as 
(17.20) 

PRESENCE OF ONE DEPENDENT AND ONE INDEPENDENT VARIABLE 
521 
The distance between two points is now given as a functional of the path 
and in terms of the integral 
(17.21) 
= l: [I +YE]' 
dx. 
(17.22) 
To find the shortest path we must solve the Euler equation for 
Because f(y, yz, x) does not depend on the independent variable ex- 
plicitly, we use the second form of the Euler equation [Eq. (17.19)] to 
write 
(17.23) 
where c is a constant. This is a first-order differential equation for y(x), 
and its solution can easily be found as 
y = ax + b. 
( 17.24) 
This is the equation of a straight line, where the integration constants 
a and b are to be determined from the coordinates of the end points. 
The shortest paths between two points in a given geometry are called 
geodesics. Geodesics in spacetime play a crucial role in Einstein's theory 
of gravitation as the paths of free particles. 
Example 17.2. Shape of a soap film between two'rings: Let us find the 
shape of a soap film between two rings separated by a distance of 2x0. 
Rings pass through the points (x1,yl) and (x2,yz) as shown in Figure 
17.2. Ignoring gravitation, the shape of the film is a surface of revolu- 
tion; thus it is sufficient to find the equation of a curve, y(x), between 
two points ( 2 1 ,  y1) and (x2, yz). Because the energy of a soap film is 
proportional to its surface area, y(x) should be the one that makes the 
area a minimum. 
We write the infinitesimal area element of the soap film as 
dA = 2nyds 
= 2ny [l + y:]' 
dx. 
The area, aside from a factor of 2n, is given by the integral 
(17.25) 
( 17.26) 
(17.27) 

522 
VARIATIONAL ANALYSIS 
fig. 17.2 Soap film between two circles 
Since f(y, yz, 
z) is given as 
f(Y,Yz,x) = Y [1 + Y p  
1 
which does not depend on x explicitly, we write the Euler equation as 
(17.28) 
= c1, 
[l + y3p 
(17.29) 
where c1 is a constant. Taking the square of both sides we write 
Y2 
-- 
[l + y?] - + 
This leads us to the first-order differential equation 
(17.30) 
(17.31) 
which on integration gives 
x = c1 cash-’ 
+ c2. 
(17.32) 
c1 
Thus the function y(x) is determined as 
x - c;? 
y(z) = cl cosh (7) 
. 
(17.33) 

PRESENCE OF MORE THAN ONE DEPENDENT VARIABLE 
523 
Integration constants cland c2 are to be determined so that y(x) passes 
through the points (x1, 
y1) and ( x ~ ,  
y ~ ) .  
Symmetry of the problem gives 
c2 = 0. For two rings with unit radius and xo = 1/2 we obtain 
1 = c1 cash (&) 
(17.34) 
as the equation to be solved for c1. This equation has two solutions. 
One of these is c1 = 0.2350, which is known as the “deep curve,’’ and 
the other one is c1 = 0.8483, which is known as the YIat curve.” To find 
the correct shape we have to check which one of these makes the area, 
and hence the energy, a minimum. Using Equations (17.27) and (17.29) 
we write the surface area as 
Substituting the solution (17.33) into Equation (17.35) we get 
A = TC; [ sinh (23+3 
- 
(17.35) 
(17.36) 
For 20 = a we obtain 
~1 = 0.2350 } ---$ { A = 6.8456 
~1 = 0.8483 
A = 5.9917 
This means that the correct value of c1 is 0.8483. If we increase the 
separation between the rings beyond a certain point we expect the film 
to break. In fact, the transcendental equation 
(17.37) 
(17.38) 
XO 
C1 
1 = ~1 cash(-) 
does not have a solution for 
xo 2 1. 
17.2 
PRESENCE OF MORE THAN ONE DEPENDENT VARIABLE 
In the variational integral if the function f depends on more than one depen- 
dent variable 
and one independent variable x, then the functional J is written as 
r“2 

524 
VARlATlONAL ANALYSIS 
where yix = i3y,/6'x, i = 1,2, .., n. We can now write small deviations from 
the desired paths, yi (x,O), which makes the functional J an extremum as 
yi (2, a) = y, ( x , ~ )  
+ avi(x) + o(a2), i = 1,2, ..., n, 
(17.41) 
where a is again a small parameter and the functions qi(x) are independent 
of each other. We again take the variation at the end points as zero: 
rli(Z1) = 774x2) = 0. 
(17.42) 
Taking the derivative of J(a) with respect to Q and setting a to zero we get 
(17.43) 
Integrating the second term by parts and using the fact that at the end points 
variations are zero, we write Equation (17.43) as 
I:' 
(% - Z G )  
a f  
vi(x)dx = 0. 
(17.44) 
Because the variations ~ { ( z )  
are independent, this equation can only be sat- 
isfied if all the coefficients of Q ~ ( x )  
vanish simultaneously, that is, 
af 
d af 
@i 
d X a Y i x  
- - -- = 0, 
i = 1,2 ,..., n. 
(17.45) 
We now have a system of n Euler equations to be solved simultaneously for 
the n dependent variables. An important example for this type of variational 
problems is the Lagrangian formulation of classical mechanics. 
17.3 
PRESENCE OF MORE THAN ONE INDEPENDENT VARIABLE 
Sometimes the unknown function a and f in the functional J depend on more 
than one independent variable. For example, in threedimensional problems 
J may be given as 
(17.46) 
where us denotes the partial derivative with respect to E. We now have to find 
a function u(z, y, z )  such that J is an extremum. We again let u(z, y, z, dy = 0) 
be the function that extremizes J and write the variation about this function 
as 

PRESENCE OF MORE THAN ONE INDEPENDENT VARIABLE 
525 
where Q(Z, y, z) is a differentiable function. We take the derivative of Equation 
(17.46) with respect to (Y and set a = 0, that is, 
(17.48) 
af 
a.U, 
We then integrate terms like -Q* 
by parts and use the fact that variation 
at the end points are zero to write 
~ ( x ,  
y, z)dxdydz = 0. (17.49) 
a af 
a af 
au axau, ayau, azau, 
Because the variation ~ ( x ,  
y, z) is arbitrary, the expression inside the paren- 
theses must be zero; thus yielding 
= 0. 
af 
a af 
a af a af 
au 
axau, 
ayau, azau, 
~ 
(17.50) 
This is the Euler equation for one dependent and three independent variables. 
Example 17.3. Laplace equation: In electrostatics energy density is given 
as 
1 
2 
p = -cE2, 
(17.51) 
where E is the magnitude of the electric field. Because the electric field 
can be obtained from a scalar potential as 
3 
= -$a, 
(17.52) 
we can also write 
2 
p = L (fia) 
2 
(17.53) 
Ignoring the 4. factor, let us find the Euler equation for the functional 
Since 
f is given as 
J = / J S, (a@)' 
dxdydz. 
(17.54) 
(17.55) 

526 
VARIATIONAL ANALYSIS 
Writing the Euler equation [Eq. (17.50)] for this f ,  we obtain 
-2 
(@XZ + @yy + @zz) = 0, 
(17.57) 
which is the Laplace equation 
a'2@(x, y, z) = 0. 
(17.58) 
A detailed investigation will show that this extremum is actually a min- 
imum. 
17.4 
PRESENCE OF MORE THAN ONE DEPENDENT AND 
IN DE P E N D E NT VARl AB L ES 
In general, if the f function depends on three dependent and three indepen- 
dent variables as 
f = f b, P5, py, P,, 9, qx, gy, qz , r, T X ,  TY 
3 r z ,  x, Y, 4 , 
(17.59) 
we can parametrize the variation in terms of three scalar parameters cr, P, and 
Y as 
P(X, Y, z; (-y) = P(X, Y, 2, (-y = 0) + (-y% 
Y, z )  + o w  
r ( x , Y , z ; Y )  = + , Y , z , Y =  
o ) + r + ( x , Y , ~ ) + 0 ( Y 2 ) .  
Y k ,  Y, 2; P) = q(x, Y, z, P = 0) + P?7(x, Y, z) + 0(P2) 
(17.60) 
Now, the p,y, and the r functions that extremize J = j j s  fdxdydz will be 
obtained from the solutions of the following system of three Euler equations: 
(17.61) 
(17.62) 
(17.63) 
If we have more than three dependent and three independent variables, we can 
use yi to denote the dependent variables and xj for the independent variables 
and write the Euler equations as 
-----=o, 
8.f 
a 3.f 
i =  1,2 ,..., 
axj ay;j 
j 
a Y i  
(17.64) 
where 
(1 7.65) 

PRESENCE OF HIGHER-ORDER DERIVATIVES 
527 
Fig. 17.3 Deformation of an elastic beam 
17.5 
PRESENCE OF HIGHER-ORDER DERIVATIVES 
Sometimes in engineering problems we encounter functionals given as 
(17.66) 
where y(") stands for the nth order derivative, the independent variable x 
takes values in the closed interval [a,b], and the dependent variable y ( z )  
satisfies the boundary conditions 
(n- 
1) 
(17.67) 
Using the same method that we have used for the other cases, we can show 
that the Euler equation that y(z) satisfies is 
d.1 = Yo, !/'(a) = Y&, . . . , y(n-l)(a) = yyo 
, 
d b )  = Y1, Y'(b) = Yi, . . . , y(n-l)(b) = &-'). 
This equation is also known as the Euler-Poisson equation. 
Example 17.4. Deformation of an elastic beam: Let us consider a ho- 
mogeneous elastic beam supported from its end points at ( 4 1 , O )  and 
( 0 , l I )  as shown in Figure 17.3. Let us find the shape of the centerline 
of this beam. 
From elasticity theory the potential energy E of the b a n i  is given as 

528 
VARIATIONAL ANALYSIS 
where p and p are parameters that characterize the physical properties 
of the beam. Assuming that the deformation is small, we can take 
1 +y’2 M 1. 
(17.70) 
Now the energy becomes 
11 
-11 
E = / [ ; ~ ( y ” ) ~  
3- py] dx. 
(17.71) 
For stable equilibrium the energy of the beam must be a minimum. 
Thus we have to minimize the energy integral with the conditions 
y(Z1) = ~ ( 4 1 )  
= 0 and y’(Z1) = ~ ’ ( 4 1 )  = 0. 
(17.72) 
Using 
(17.73) 
1 
F(z, Y, Y’, Y”) = ZP (Y/”>2 + m, 
we write the Euler-Poisson equation as 
py(4) + p = 0. 
(17.74) 
Solution of the Euler-Poisson equation is easily obtained as 
y = ax3 + px2 + yx + s - -x 
P
4
 
. 
(17.75) 
Using the boundary conditions given in Equation (17.72) we can deter- 
mine a, 0, 
y, 6 and find y(x) as 
24P 
y = - 
P [-z4 + 21;x2 - it] . 
For the cases where there are m dependent variables we can generalize the 
(17.76) 
24P 
variational problem in Equation (17.66) as 
and the Euler-Poisson equations become 
(17.77) 
(17.78) 
(17.79) 
dk 
n1 C ( - I ) ~  g ~ y t ( k )  = 0, 
i = 1,2, ...., m. 
k=O 

ISOPERIMETRIC PROBLEMS AND THE PRESENCE OF CONSTRAINTS 
529 
17.6 ISOPERIMETRIC PROBLEMS AND THE PRESENCE OF 
CONSTRAINTS 
In some applications we search for a function that not only extremizes a given 
functional 
but also keeps another functional 
(17.80) 
(17.81) 
at a fixed value. To find the Euler equation for such a function satisfying the 
boundary conditions 
g ( z A )  = YA and Y(zB) = YE 
(17.82) 
we parametrize the possible paths in terms of two parameters €1 and ~2 as 
y(z, €1 ~ 2 ) .  These paths also have the following properties: 
i) For all values of €1 and ~2 they satisfy the boundary conditions 
Y ( Z A , E l , E 2 ) = Y A  
and Y ( ~ B , E I , E 2 ) = Y B -  
(17.83) 
ii) y(z, 0,O) = ~ ( z )  
is the desired path. 
iii) y(z, EI, €2) has continuous derivatives with respect to all variables to 
We now substitute these paths into Equations (17.80) and (17.81) to get 
second order. 
two integrals depending on two parameters E I  and €2 as 
(17.85) 
While we are extremizing I ( E I , E ~ )  
with respect to €1 and €2, we are also 
going to ensure that J ( E I , E ~ )  
takes a fixed value; thus €1 and ~2 cannot be 
independent. Using Lagrange undetermined multiplier X we form 
K ( E 1 , E z )  = I ( € ] ,  
E 2 )  + 
1.2). 
(17.86) 
The condition for K ( E I ,  €2) to be an extremum is now written as 
(17.87) 

530 
VARIATIONAL ANALYSIS 
In integral form this becomes 
(17.88) 
where the h function is defined as 
h = f + A y .  
(17.89) 
Differentiating with respect to these parameters and integrating by parts and 
using the boundary conditions we get 
Taking the variations as 
(17.91) 
and using Equation (17.87) we write 
qj(z)dz=O, 
j =  1,2. 
(17.92) 
Because the variations q j  are arbitrary, we set the quantity inside the square 
brackets to zero and obtain the differential equation 
= 0. 
d h  
d ah 
dy 
dxdy’ 
- 
(17.93) 
Solutions of this differential equation contain two integration constants and 
a Lagrange undetermined multiplier A. The two integration constants come 
from the boundary conditions [Eq. (17.82)], and X comes from the constraint 
that fixes the value of J ,  thus completing the solution of the problem. 
Another way to reach this conclusion is to consider the variation of the two 
functionals (17.80) and (17.81) as 
and 
We now require that for all Sy that makes SJ = 0, S I  should also vanish. This 
is possible if and only if 

ISOPERIMETRIC PROBLEMS AND THE PRESENCE OF CONSTRAINTS 
531 
are constants independent of X, that is, 
(g) 
/ (2) 
= -X(const.). 
This is naturally equivalent to extremizing the functional 
with respect to arbitrary variations 6y. 
generalized by taking h as 
When we have m constraints like J1, . . . , J,, 
the above method is easily 
m 
h =  f + c x i g i  
(17.94) 
i= 1 
with m Lagrange undetermined multipliers. Constraining integrals now b e  
come 
J~ = 1: gi (x, 
y, y’) dz = const., i = 1,2, ..., m. 
(17.95) 
If we also have n dependent variables, we have a system of n Euler equations 
given as 
=o, 
i = l ,  ..., n, 
d h  
d dh 
- 
- _ _  
dyi 
dx dyi 
(17.96) 
where h is given by Equation (17.94). 
Example 17.5. Isoperimetric problems: Let us find the maximum area 
that can be enclosed by a closed curve of fixed perimeter L on a plane. 
We can define a curve on a plane in terms of a parameter t by giving its 
z(t) and y ( t )  functions. Now the enclosed area is 
(17.97) 
1 
t B  
A = LA (zy’ - x’y) dt, 
and the fixed perimeter condition is expressed as 
(17.98) 
where the prime denotes differentiation with respect to the independent 
variable t, and x and y are the two dependent variables. Our only 
constraint is given by Equation (17.98); thus we have a single Lagrange 
undetermined multiplier and the h function is written as 
(17.99) 
1 
h = 5 (zy’ - x’y) +Ad- 

532 
VARIATIONAL ANALYSIS 
Writing the Euler equation for x(t) we get 
1 
d
1
 
2’ 
2 
dt 
2 
dx- 
-y’ - -(--y 
+ x 
= 0, 
X’ 
) = 0  
d 
and similarly for y(t) : 
I,+d(- 
dt 
,/- 
I/’ 
) = o .  
(17.100) 
(17.101) 
The first integral of this system of equations [Eqs. (17.100) and (17.101)) 
can easily be obtained as 
X’ 
y--x=y
2’2 + y’2 
and 
Solutions of these are given as 
2’ 
Jm- 
y - y o = x  
and 
Y’ 
x-xo = -A VGFTp’ 
(17.102) 
(17.103) 
(17.104) 
(17.105) 
which can be combined to obtain the equation of the closed curve as 
( x  - 2 0 )  2 + (y - y o y  = x2. 
(17.106) 
This is the equation of a circle with its center at (XO, yo) and radius A. 
Because the circumference is L, we determine X as 
L 
A = -  
2n’ 
(17.107) 
Example 17.6. Shape of a freely hanging wire with fixed length: We 
now find the shape of a wire with length L and fixed at both ends at 
( x ~ , y ~ )  
and ( x ~ , y ~ ) .  
The potential energy of the wire is 
yds=pg 
9J-d~. 
(17.108) 
11 

APPLlCATlON TO CLASSlCAL MECHANlCS 
533 
Because we take its length as fixed, we take our constraint as 
L = IxB 
d m d z .  
(17.109) 
For simplicity we use a Lagrange undetermined multiplier defined as 
X = -pgyo and write the h function as 
X A  
(17.110) 
where g is the acceleration of gravity and p is the density of the wire. 
We change our dependent variable to 
Y + r ) = Y - Y O ,  
(17.11 1) 
which changes our h function to 
h = pgr)(x)dl +v‘~. 
After we write the Euler equation we find the solution as 
2 - xo 
Y = yo + bcosh ( T )  . 
(17.112) 
(17.113) 
Using the fact that the length of the wire is L and the end points are 
at (XA,YA) and (XB, 
y~), we can determine the Lagrange multiplier yo 
and the other constants xo and b. 
17.7 
APPLICATION TO CLASSICAL MECHANICS 
With the mathematical techniques developed in the previous sections, we can 
conveniently express a fairly large part of classical mechanics as a variational 
problem. If a classical system is described by the generalized coordinates 
qi(t), i = 1,2,. . . , n and has a potential V(qi, t), then its Lagrangian can be 
written as 
where T is the kinetic energy and a dot denotes differentiation with respect 
to time. We now show that the equations of motion follow from Hamilton’s 
principle: 
Hamilton’s principle: As a system moves from some initial time tl to t 2 ,  
with prescribed initial values qi(t1) and q i ( t 2 ) ,  the actual path followed 
by the system is the one that makes the integral 
(17.115) 

534 
VARIATIONAL ANALYSIS 
an extremum. I is called the action. 
From the conclusions of Section 17.2 the desired path comes from the so- 
lutions of 
---(-)=o, 
d L  
d 
d L  
i = 1 , 2  ,..., n, 
dt 
aqi 
(17.116) 
which are now called the Lagrange (or Euler-Lagrange) equations. They are n 
simultaneous second-order differential equations to be solved for qi (t), where 
the 2n arbitrary integration constants are determined from the initial condi- 
tions qi(t1) and qi(t2). 
For a particle of mass m and moving in an arbitrary potential V ( Z ~ , X ~ ,  
z3) 
the Lagrangian is written as 
(17.117) 
1 
2 
2
.
2
 
2 
L = -m(k, +i, + X 3 )  - V(Z1,X2,Xg). 
Lagrange equations now become 
dV 
mi& = --, 
d X i  
2 = 1,2,3, 
(17.118) 
which are nothing but Newton’s equations of motion. 
The main advantage of the Lagrangian formulation of classical mechanics is 
that it makes applications to many particle systems and continuous systems 
possible. It is also a must in making the transition to quantum mechanics 
and quantum field theories. For continuous systems we define a Lagrangian 
density L as 
L = 
Ld3?;’, 
(17.119) 
where V is the volume. Now, the action in Hamilton’s principle becomes 
I = .6 Ldt 
(17.120) 
For a continuous timedependent system with n independent fields, &(T’, t), 
a = 1,2, ..., n, the Lagrangian density is given as 
q42, (bit, 4iz, ( b i g ,  (biz, ?,t), 
(17.121) 
where 
(17.122) 

EIGENVALUE PROBLEM AND VARIATIONAL ANALYSIS 
535 
We can now use the conclusions of Section 17.4 to write the n Lagrange 
equations as 
= 0. 
(17.123) 
For time-independent fields, 4;(7), 
i = 1,2, ...., n, the Lagrange equations 
ax a ax 
a ax 
a ax 
a a l  
a$; at Wit 
ax ahz 
8y a&, 
az &iz 
-- ----- - ----- 
become 
( 17.124) 
As an example, consider the Lagrange density 
= f [(2)2+ 
(g)2+ 
(g)2] 
+m2& 
where the corresponding Lagrange equation is the Laplace equation 
V24(?;t) 
- m2&(T) 
= 0. 
(17.126) 
17.8 
EIGENVALUE PROBLEM AND VARIATIONAL ANALYSIS 
For the variational problems we have considered the end product was a dif- 
ferential equation to be solved for the desired function. We are now going to 
approach the problem from the other direction and ask the question: Given 
a differential equation, is it always possible to obtain it as the Euler equation 
of a variational integral such as 
6 
6 J = 6  [ fdt = O ?  
(17.127) 
J a  
When the differential equation is an equation of motion, then this question 
becomes: Can we drive it from a Lagrangian? This is a rather subtle point. 
Even though it is possible to write theories that do not follow from a varia- 
tional principle, they eventually run into problems. 
We have seen that solving the Laplace equation within a volume V is 
equivalent to extremizing the functional 
with the appropriate boundary conditions. Another frequently encountered 
differential equation in science and engineering is the Sturm-Liouville equation 
- ~(Z)U(.) + X ~ ( X ) U ( X )  = 0, x E [a, b] . 
(17.129) 
dx 

536 
VARIATIONAL ANALYSIS 
It can be obtained by extremizing the functional 
b 
I [u 
(z)] = 
[pu12 + (4 - Ap) u2] dx. 
( 17.1 30) 
However, because the eigenvalues X are not known a priori, this form is not 
very useful. It is better to extremize 
nb 
I [u 
(z)] = J, [ P d 2  + qu2] dz, 
(17.131) 
subject to the constraint 
b 
J [u 
(.)I 
= 1 p u 2 h  = const. 
(17.132) 
In this formulation eigenvalues appear as the Lagrange multipliers. Note that 
the constraint [Eq. (17.132)] is also the normalization condition of ~ ( 2 ) ;  
thus 
we can also extremize 
(17.133) 
If we multiply the Sturm-Liouville equation by u(z) and then integrate by 
parts from a to b, we see that the extremums of I( [u 
(z)] correspond to the 
eigenvalues A. In a Sturm-Liouville problem (Morse and Feshbach, Section 
6.3) 
i) There exists a minimum eigenvalue. 
ii) A, 
-+ 00 as n -+ 
00 . 
iii) To be precise, A, 
N n2 as n -+ co. 
Thus the minimums of Equation (17.133) give the eigenvalues A,. 
In fact, 
from the first property the absolute minimum of K is the lowest eigenvalue 
Xo. This is very useful in putting an upper bound to the lowest eigenvalue. 
To estimate the lowest eigenvalue we choose a trial function u(z) and ex- 
pand in terms of the exact eigenfunctions, ui(z), which are not known: 
u = U g + c 1 u 1  
+ C 2 U 2 + . . .  
. 
(17.134) 
Depending on how close our trial function is to the exact eigenfunction, the 
coefficients c 1 ,  c2, ... will be small numbers. Before we evaluate K [u 
(z)] , let 
us substitute our trial function into Equation (17.131): 
)"I dz. (17.135) 
I* 
[p(u~+c~El:+c2u;+...) 
2 + q (  u o + c l u l + C 2 u 2 + . . .  
Since the set {ui} is orthonormal, using the relations 
(17.136) 

EIGENVALUE PROBLEM AND VARIATIONAL ANALYSIS 
537 
Fig. 17.4 sin(.rrz) could be approximated by z( 1 - z) 
and 
we can write 
as 
(17.137) 
(17.138) 
(17.139) 
Because c1, c2, ... are small numbers, K gives us the approximate value of the 
lowest eigenvalue as 
K c2 A0 + c; (A, - A,) + c; (A2 - XO) +.. . . 
(17.140) 
What is significant here is that even though our trial function is good to the 
first order, our estimate of the lowest eigenvalue is good to the second order. 
This is also called the Hylleraas-Undheim theorem. Because the eigenvalues 
are monotonic increasing, this estimate is also an upper bound to the lowest 
eigenvalue. 
Example 17.7. How to estimate lowest eigenvalue: Let us estimate the 
lowest eigenvalue of 
d2u 
dx2 - 
+xu = 0, 
(1 7.14 1) 

538 
VARIATIONAL ANALYSIS 
with the boundary conditions u(0) = 0 and u(1) = 0. As shown in 
Figure 17.4 we can take our trial function as 
u = z(1- .). 
(17.142) 
This gives us 
(17.143) 
This is already close to the exact eigenvalue 7r2. For a better upper 
bound we can improve our trial function as 
u = .( 
1 - .)( 1 + c1. f.. 
.) 
(17.144) 
and determine ci by extremizing K. For this method to work our trial 
function 
i) Must satisfy the boundary conditions. 
ii) Should reflect the general features of the exact eigenfunction. 
iii) Should be sufficiently simple to allow analytic calculations. 
Example 17.8. Vibrations of a drumhead: We now consider the wave 
equation 
3% + k2u = 0, 
k2 = - 
W 2  
C2 
(17.145) 
in two dimensions and in spherical polar coordinates. We take the radius 
as a and use u(a) = 0 as our boundary condition. This suggests the trial 
function 
(17.146) 
r 
a 
u=l--. 
Now the upper bound for the lowest eigenvalue k i  is obtained from 
as 
IT 
6 
7ra2/6 
a2' 
ki<-=- 
Compare this with the exact eigenvalue 
5.78 
a2 
ko = -. 
(17.147) 
(17.148) 

RAYLNGH-RITZ METHOD 
539 
Example 17.9. Harmonic oscilhtor problem: The Schrodinger equa- 
tion can be driven from the functional 
(17.149) 
where 
the Schrodinger equation is written as 
. q 2  means s_", GiIZI2h. For the harmonic oscillator problem 
d2q 
h
2
 
H @  = -- + z21ZI = E q ,  x E (--00, 
-00). 
For the lowest eigenvalue we take our trial function as 
Q = (1 + f f 2 2 ) e - ~ 2 .  
For an upper bound this gives 
5 
ff 
43a2 
(17.150) 
(17.151) 
(17.152) 
To find its minimum we solve 
23a2 + 56cu - 48 = 0 
(17.153) 
to find 
CY = 0.6718. 
(17.154) 
Thus the upper bound to the lowest energy is obtained as 
Eo 5 1.034, 
where the exact eigenvalue is 1.0. This method can also be used for the 
higher-order eigenvalues. However, one must make sure that the chosen 
trial function is orthogonal to the eigenfunctions corresponding to the 
lower eigenvalues. 
17.9 
RAYLEIGH-RITZ METHOD 
In this method we aim to find an approximate solution to a differential equa- 
tion satisfying certain boundary conditions. We first write the solution in 
terms of suitably chosen &(z) functions as 
Y(2) = cpo(2) + c141(z) + c242(2) + c3433(2) + ... + G d n ( 2 ) ,  
(17.155) 

540 
VARIATIONAL ANALYSIS 
where c1, c2, ..., c, are constants to be determined. &(z) are chosen functions 
so that y(z) satisfies the boundary conditions for any choice of the c values. 
In general 40(z) is chosen such that it satisfies the boundary conditions at 
the end points of our interval, and 41 (z), 42(z), ..., &(z) are chosen such that 
they vanish at the end points. 
Example 17.10. Loaded cable fixed between two points: We consider a 
cable fixed between the points (0,O) and (1, h). The cable carries a load 
along the y-axis distributed as 
(17.156) 
To find the shape of this cable we have to solve the variational problem 
(17.157) 
with the boundary conditions 
y(0) = 0 and y(1) = h, 
(17.158) 
where TO and qo are constants. Using the Rayleigh-Ritz method we 
choose &(x) such that it satisfies the above boundary conditions and 
choose 41, ..., 4, such that they vanish at both end points: 
h 
560 = 'tx, 
41 = z(x - l ) ,  
4 2  = z2(z - l ) ,  
(17.159) 
4, = z,(z - 1). 
Now the approximate solution y(z) becomes 
h 
I 
y(z) N -z + z(z - 1 )  (c1 + c2z + . . . + Gzn-1) . 
(17.160) 
For simplicity we choose n = 1 so that y(z) becomes 
(17.161) 
h 
1 
y(z) N -z + z(2 - I)Cl. 
Substituting this into the variational integral we get 
ZTO - +(2z - l ) C 1  +q 
dz+z(z-l)cl 
dz = 0, 
*l[' 
(? 
l2 
z ( h  
)I 
(17.162) 

RAYlEiGH-RiTZ METHOD 
541 
(17.163) 
(17.165) 
Because the variation 6cl is arbitrary, the quantity inside the brackets 
must vanish, thus giving 
(17.166) 
40 
c1 = - 
4% 
and 
(17.167) 
h 
Qo 
y(-z) E2 --2 + -z(z 
- 1). 
1 
4To 
The Euler equation for the variational problem [Eq. (17.157)] can easily 
be written as 
(17.168) 
Q0-z 
Toy/' - I 
- 
- 0, 
where the exact solution of this problem is 
(17.169) 
y(z) = --z 
h + ----z(-z2 
90 
- 12). 
1 
6Tol 
As we will see in the next example, an equivalent approach is to start 
with the Euler equation (17.168), which results from the variational 
integral 
(17.170) 
Substituting Equation (17.161) into the above equation, we write 
(17.171) 
which after integration yields 
(17.172) 
Since Sc1 is arbitrary, we again obtain c1 = q0/4To. 

542 
VARIATIONAL ANALYSIS 
Example 17.11. Rayleigh Ritz Method: We now find the solution of the 
differential equation 
- 
d2Y 
d22 +xy = -x 
(17.173) 
with the boundary conditions y(0) = 0 and y( 1) = 0 by using the Rayleigh- 
Ritz method. The variational problem corresponding to this differential equa- 
tion can be written as 
1’ (y” + icy + z) 6ydx = 0. 
(17.174) 
We take the approximate solution as 
y(x) N x( 1 - z) (Cl + c2z + . . . ) , 
(17.175) 
and substitute this in Equation (17.174) to obtain 
i;’ [(-2 + z2 - z3) c1 + (2 - 63: + z3 - z4) cz + ... + x] 
x [ ~ C I  (x - x2) + 6 ~ 2  
(z2 - x 3 )  + . . .] dx = 0. 
(17.176) 
Solution with one term is given as 
(17.177) 
5 
19 
y(l) = C,Z(l - z), 
c1 = -, 
while the solution with two terms is given as 
y(2) = c1z( 1 - .) + c2x2 (1 - z) , 
(17.178) 
where 
~1 = 0.177, ~2 = 0.173 . 
(17.179) 

PROBLEMS 
543 
Problems 
17.1 For the variational problem 
show that the Euler equation is given as 
P 
d 
d2 
d x  
dx2 ’” 
- ... 
dxn 
+ (-1y ---Fy(=) 
= 0. 
Fy - -Fyt + -F 
Assume that the variation at the end points is zero. 
17.2 For the Sturm-Liouville system 
Y’’(Xc) = -XY(X), Y(0) = Y(1) = 0, 
find the approximate eigenvalues to first and second order. 
Compare your results with the exact eigenvalues. 
17.3 
potential V ( 7 ) ,  
as 
Given the variational problem for the massive scalar field, with the 
S L d 3 7 d t  =O, 
J 
where 
1
2
 
2 
2 
L ( 7 , t )  = -(@ - (VQ) - m2@2) - V ( 7 ) .  
Find the equation of motion for 
Q(7, 
t). 
17.4 
density 
’Iteat q ( 7 , t )  and W*(?,t) 
as independent fields in the Lagrangian 
where 
J L d 3 7 d t  = 0. 
Show that the corresponding Euler equations are the Schrdinger equations 
fi2 
a@ 
2m 
at 
HW = (--T? 
+ V)W = iti - 

544 
VARIATIONAL ANALYSIS 
and 
17.5 
along the y-axis, distributed as 
Consider a cable fixed at the points (0,O) and (l,h). It carries a load 
X 
f(X) = -4-. 
1 
To find the shape of this cable we have to solve the variational problem 
with the boundary conditions 
y(0) = 0 and y(l) = h. 
Find the shape of the wire accurate to second order. 
Hint: See Example 17.10. 
17.6 
Show that the exact solution in Problem 17.5 is given as 
h 
Qo 
y(x) = -X + -x(z2 
- P). 
1 
6T01 
17.7 
tion 
Find an upper bound for the lowest eigenvalue of the differential equa- 
d2Y 
- 
+ Xsy = 0 
dx2 
with the boundary conditions 
y(0) = y(1) = 0. 
17.8 
points: 
For a flexible elastic string, with constant tension and fixed at the end 
do, t> = Y(L, t> = 0, 
Show that the Lagrangian density is given as 
where p is the density and T is the tension. Show that the Lagrange equation 
is 
d2Y(X, t> - E
m
 
= 0. 
8x2 
7 
at2 

PROBLEMS 
545 
17.9 For a given Lagrangian representing a system with TZ degrees of free- 
dom, show that adding a total time derivative to the Lagrangian does not 
effect the equations of motion, that is, L and L’ related by 
~ F ( Y I , Y ~ , . - . , Q ~ , ~ )  
dt 
L’= L+ 
7 
where F is an arbitrary function, have the same Lagrange equations. 
17.10 
For a given Lagrangian L(yi, ii,t), where i = 1,2, .... n, show that 
d 
8L 
dt 
This means that if the Lagrangian does not depend on time explicitly, then 
the quantity, H ,  defined as 
d L  
8L 
H(qa, -, t )  = c 
qi- 
- L 
8% 
8% 
is conserved. Using Cartesian coordinates, interpret H. 
17.11 The brachistochrone problem: Find the shape of the curve join- 
ing two points, along which a particle, initially at rest, falls freely under 
the influence of gravity from the higher point to the lower point in the least 
amount of time. 
17.12 
In an expanding flat universe the metric is given as 
ds2 = -dt2 + a2(t)( dx2 + dy2 + dz2) 
= -dt2 + a2(t)&dxidxj, 
where i = 1,2,3, and a(t) is the scale factor. Given this metric, consider the 
following variational integral for the geodesics: 
where r is the proper time. For the dependent variables t(r) and xi(.) 
show 
that the Euler equations for the geodesics are: 
d2t 
dxi dxj 
- 
+ aa& - - 
= 0 
dr2 
d r  d r  
and 
d2xi 
a dt dx’ 
dr2 
a d r  d r  
-+2--- 
= 0, 

546 
VARIATIONAL ANALYSIS 
where a = da/dt. 
17.13 
17.14 
double pendulum in uniform gravitational field. 
17.15 
in curved background spacetimes: 
Using cylindrical coordinates, find the geodesics on a cone. 
Write the Lagrangian and the Lagrange equations of motion for a 
Consider the following Lagrangian density for the massive scalar field 
1 
2 
L(z) = - [- det gap(z)]b {gp”(z)a,@(z)av@(z) 
- [m2 + tR(z)] a’(.)} 
, 
where @(z) is the scalar field, m is the mass of the field quanta, and z stands 
for (zo, d, 
x2, z3). 
Coupling between the scalar field and background geome- 
try is represented by the term 
<R(x)@2(x)> 
where [ is called the coupling constant and R(z) is the curvature (Ricci) 
scalar. The corresponding action is 
S = 
L(z)dz, (dz 
= d~~dz’dz’d~~). 
S 
By setting the variation of the action with respect to @(z) to zero, show that 
the scalar field equation is given as 
[O + m2 + [ ~ ( z ) ]  
@(z) = 0, 
where 0 
= a,% 
is the d’Alembert wave operator, 8, stands for the covariant 
derivarive, and take the signature of the metric as (+ - --). 
17.16 
Find the extremals of the problem 
6l: [a(z)y’I2 - p ( ~ ) y ’ ~  
+ q(z)y2] dz = 0 
subject to the constraint 
where y(zl), y’(q), y(zz), y’(z2) are prescribed. 

INTEGRAL 
EQUATIONS 
We have been rather successful with differential equations in representing 
physical processes. They are composed of the derivatives of an unknown 
function. Because derivatives are defined in terms of ratios of differences in 
the neighborhood of a point, differential equations are local. In mathematical 
physics there are also integral equations, where the unknown function appears 
under an integral sign. Because integral equations involve integrals of the 
unknown function over the entire space, they are global and in general much 
more difficult to solve. 
An important property of differential equations is that to describe a phys- 
ical problem completely, they must be supplemented with boundary condi- 
tions. Integral equations, on the other hand, constitute a complete descrip 
tion of a given problem, where extra conditions are neither needed nor could 
be imposed. Because the boundary conditions can be viewed as a convenient 
way of including global effects into a system, a connection between differential 
and integral equations is to be expected. In fact, under certain conditions in- 
tegral and differential equations can be transformed into each other. Whether 
an integral or a differential equation is more suitable for expressing laws of 
nature is still an interesting problem, with some philosophical overtones that 
Einstein once investigated. Sometimes the integral equation formulation of a 
given problem may offer advantages over its differential equation description. 
At other times, as in some diffusion or transport phenomena, we may have no 
choice but to use integral equations. 
In this chapter we discuss the basic properties of linear integral equations 
and introduce some techniques for obtaining their solutions. We also discuss 
54 7 

548 
INTEGRAL EQUATlONS 
the Hilbert-Schmidt theory, where an eigenvalue problem is defined in terms 
of linear integral operators. 
18.1 CLASSIFICATION OF INTEGRAL EQUATIONS 
Linear integral equations are classified under two general categories. Equa- 
tions that can be written (LS 
+)Y(4 
= F(4 + A J 4% 
<)Y(OdC 
(18.1) 
are called the Fredholm equations, where cr(z), F(z), and ~ ( 2 ,  
<) are known 
functions and y(s) is the unknown function, while A, a, and b are known 
constants. 
K ( z , ~ )  is called the kernel, which is closely related to Green's 
function. When the upper limit of the integral in a Redholm equation is a 
variable, we have the Volterra equation: 
4 4 Y ( 4  = F(4 + A LZ 
K(z,§)Y(o@. 
b 
(18.2) 
The W h o l m  a d  Volterra equations also have the following kin&. 
a#O 
kind1 
cy = 1 
kind I1 
cr = a(%) kind I11 
When F(z) is zero, the integral equation is called homogeneous. Integral 
equations can also be defined in higher ciimen%ions. In two dimensions we can 
write a linear integral equation as 
18.2 
INTEGRAL AND DIFFERENTIAL EQUATIONS 
Some integral equations can be obtained from differential equations. To see 
this connection we first derive a useful formula. We fimt consider the integral 
(18.4) 
(18.5) 

INTEGRAL AND DIFFERENTIAL EQUATIONS 
549 
we take the derivative of In(.) 
to write 
For n > 1 this gives 
and for n = 1 we have 
Differentiating I,(x) k times gives 
dk I, 
-= 
(n- I ) ( n - Z ) - - - ( n - k ) I n - k ,  
dxk 
which can be used to write 
dn- I, 
dxn- 
-- - (n - 1)!11(x) 
(18.7) 
(18.8) 
(18.9) 
(18.10) 
or 
-- - ( n -  
C I n  
dxn 
Since In(.) 
= 0 for n 2 1 and from Equations (18.10) and (18.11), we see 
that In(%) and all of its derivatives up to order (n- 1) are zero at x = a. This 
gives us 
Il(X) = J,' f ( z l ) d x l ,  
(18.12) 
I2(x) = ~ x I l ~ z z ~ d ~ z  
= LXLX2 
f(Xl)dXld%Z 
(18.13) 
and in general 
In(.) 
= (n - I)! LX LXn 
. . . LX3 LX2 
f ( ~ l ) d ~ l d ~ z . . . d % ~ -  
idx,. 
(18.14) 
Using the above equation we can now write the following useful formula, which 
is also known as the Cauchy formula: 
[ 
LX* 
. . . LX3 
J X 2  f ( x I ) ~ X  
1 d
~
.
 
. .d%,- 1 dxn 
(18.15) 

550 
INTEGRAL EQUATIONS 
18.3 HOW TO CONVERT SOME DIFFERENTIAL EQUATIONS 
INTO INTEGRAL EQUATIONS 
We now consider the following second-order ordinary differential equation with 
variable coefficients: 
(18.16) 
which is frequently encountered in physics and engineering applications. Let 
the boundary conditions be given as y(a) = yo and y’(u) = y& Integrating 
this differential equation once gives us 
lz 
A(zl)y’(z~)dz~ 
- 
B ( ~ I ) Y ( ~ I ) &  
(18.17) 
We integrate the first term on the right-hand side by parts and then solve for 
y’(z) to write 
LX 
?J’(z) - y; = - 
+ lX 
f (X1)dXl. 
~ ’ ( z )  
= -A(z)y(z) - Iz 
[B(zl) - A’(zI)]Y(zI)~zI 
a 
(18.18) 
(18.21) 

HOW TO CONVERTSOME DIFFERENTIAL EQUATIONSINTOINTEGRAL EQUATIONS 
551 
This is an inhomogeneous Volterra equation of the second kind. This integral 
Equation (18.22) is equivalent to the differential equation (18.16) plus the 
boundary conditions y(u) = yo and y'(u) = y;. 
Example 18.1. Conversion of difleerential equations into integral equations: 
Using (18.22) we can convert the differential equation 
(18.23) 
and the boundary conditions 
into an integral equation as 
Example 18.2. Conversion of diffeerential equations into integral equations: 
In the previous example we had a single-point boundary condition. We 
now consider the differential equation 
d2Y 
- + x y = o  
dx2 
(18.26) 
with a two-point boundary condition 
y(0) = 0 and y(l) = 0. 
(18.27) 
Integrating Equation (18.26) between (0, z) we get 
(18.28) 
C is an integration constant that is equal to y'(O), which is not given. 
A second integration gives 
F X  

552 
INTEGRAL EQUATIONS 
where we have used the Cauchy formula [Eq. (18.15)] and the boundary 
condition at x = 0. We now use the remaining boundary condition, 
y(l) = 0, to determine C as 
(18.30) 
Substituting this back in Equation (18.29) we write the result as 
or 
This is a homogeneous Fredholm equation of the second kind: 
1 
Y(.) 
= 1 K ( Z ,  OY(t)@> 
(18.33) 
where the kernel is given as 
18.4 
HOW TO CONVERT SOME INTEGRAL EQUATIONS INTO 
DIFFERENTIAL EQUATIONS 
Volterra equations can sometimes be converted into differential equations. 
Consider the following integral equation 
y(x) = x2 - 2 I" ly(t)dt. 
(18.35) 
We define f(x) as 
where the derivative of f(x) is 
(18.36) 
(18.37) 

SOLUTION OF INTEGRAL EQUATIONS 
553 
Using f(z) in Equation (18.35) we can also write 
Y(z) = z2 - 2f(z), 
(18.38) 
which when substituted back into Equation (18.37) gives a differential equa- 
tion to be solved for f(z): 
(18.39) 
the solution of which is 
Finally substituting this into Equation (18.38) gives us the solution for the 
integral equation as 
y(z) = 1 - c e - x z .  
(18.40) 
Because an integral equation also contains the boundary conditions, constant 
of integration is found by substituting this solution [Eq. (18.40)] into the 
integral Equation (18.35) as C = 1. 
We now consider the Volterra equation 
and differentiate it with respect to z as 
r *  
(18.41) 
(18.42) 
where we have used Equation (18.5). Eliminating the integral between these 
two formulas we obtain 
Y’@) - (A + l)y(z) = 9 ’ b )  - 9(z>- 
(18.43) 
The boundary condition to be imposed on this differential equation follows 
from integral equation (18.41) as y(0) = g(0). 
18.5 
SOLUTION OF INTEGRAL EQUATIONS 
Because the unknown function appears under an integral sign, integral equa- 
tions are in general more difficult to solve than differential equations. How- 
ever, there are also quite a few techniques that one can use in finding their 
solutions. In this section we introduce some of the most commonly used tech- 
niques. 

554 
INTEGRAL EQUATIONS 
18.5.1 Method of Successive Iterations: Neumann Series 
Consider a Fredholm equation given as 
b 
f(.) = g(.) 
+ J’ K(z, t ) f ( W .  
(18.44) 
a 
We start the Neumann sequence by taking the first term as 
fo(.) 
= d.). 
(18.45) 
Using this as the approximate solution of Equation (18.44) we write 
b 
fl(Z) = dz) + / K(., 
t)fo(t)dt. 
(18.46) 
a 
We keep iterating like this to construct the Neumann sequence as 
f o b )  = dz) 
(18.47) 
(18.50) 
This gives us the Neumann series solution as 
f(.) 
= g(z) + x 
K(z, z’)g(.’)d.’ 
+ x2 lb 
dz’ lb 
&’)K(z,z’)K(.’, .”)g(d’) +.. . 
1” 
(18.51) 
If we take 

SOLUTION OF INTEGRAL EQUATIONS 
555 
and if the inequality 
(18.53) 
1 
B 
is true, where 1x1 < - , and C is a constant the same for all x in the interval 
[a, b], then the following sequence is uniformly convergent in the interval [a, b]: 
{ f z }  = fo,f1,f2,.-- , f n , . - -  -+ f(x). 
(18.54) 
The limit of this sequence, that is, f(z), is the solution of Equation (18.44) 
and it is unique. 
Example 18.3. Neumann sequence: For the integral equation 
(18.55) 
we start the Neumann sequence by taking So(.) 
= x2 and continue to 
write: 
f](x)=x2+-S_l(t-x)t2dr 
1
'
 
2 
- x 2 - -  
- 
3' 
X 
2
1
'
 
t 
f2(x) = x + - 
(t - X)(t2 - $dt 
2 1' 
x
1
 
3
9
 
- 
- 22 - - - - 
1
'
 
t
1
 
f3(x) = 2 2  + 2 s , ( t  - x)(t2 - - - -)& 
3
9
 
(18.56) 
Obviously, in this case the solution is of the form 
f(x) = x2 + C ' X  + c2. 
(18.57) 
Substituting this [Eq. (18.57)] into Equation (18.55) and comparing the 
coefficients of equal powers of x we obtain C1 = -4 and C2 = -&; thus 
the exact solution in this case is given as 
1 
4 
f(X) = x2 - --z - 1 
12' - 
(18.58) 

556 
INTEGRAL EQUATIONS 
18.5.2 
By using the nth term of the Neumann sequence as our solution we will have 
committed ourselves to the error given by 
Error Calculation in Neumann Series 
Example 18.4. E m r  calculation an Neumann series: For the integral 
equation 
(18.60) 
x 
O < x S t  
t 
t l x l l ,  
{ 
I((., 
t) = 
since 
Equations (18.51-18.54) tell us that the Neumann sequence is conver- 
gent. Taking fo(z) = 1, we find the first three terms as 
fo(x) = 1, 
fi (x) = 1 + (1/10)2 - (1/20)2, 
f 2 ( ~ )  
= 1 + (31/300)~ - (1/20)x2 - 
If we take the solution as 
f ( x )  = f 2 b )  
(18.62) 
1/600)z3 + ( 1/2400)x4. 
(18.63) 
the error in the entire interval will be less than 
= 0.0001. 
(18.64) 
18.5.3 
When the kernel is given in the form 
Solution for the Case of Separable Kernels 
n 
K(x,t) = 
Mj(x)Nj(t), 
n is a finite number, 
(18.65) 
3=1 

SOLUTION OF INTEGRAL EQUATIONS 
557 
it is called separable or degenerate. In such cases we can reduce the solution 
of an integral equation to the soliition of a linear system of equations. Let us 
write a Fredholm equation with a separable kernel as 
n 
r " h  
1 
If we define the quantity inside the square brackets as 
lbN3(t)Y(t)dt 
= C j ,  
Equation (18.66) becomes 
n 
d . ) = f ( 4 f X C c & w .  
j = 1  
(18.66) 
(18.67) 
(18.68) 
After the coefficients cj are evaluated, this will give us the solution y(z). To 
find these constants we multiply Equation (18.68) with N;(z) and integrate 
to get 
n 
where 
and 
b 
azj = 1 Ni(Z)Mj(Z)dZ. 
We now write Equation (18.69) as a matrix equation: 
b = C-XAC, 
b = (1-XA)c. 
(A = ~ i j )  
(18.69) 
(18.70) 
(18.71) 
(18.72) 
(18.73) 
This gives us a system of n linear equations to be solved for the n coefficients 
cj a3 
(1 - X U l l ) C l  - X a 1 2 ~ 2  - X a 1 3 ~  - . . . - XU~,C, 
= bl 
- X C L ~ ~ C ~  
+ (1 - X C L ~ ~ ) C ~  
- X ~ 2 3 C 3  - . . . - XU~,C, 
= b2 
C1 - Xan2c2 - X U ~ ~ C : ~  
- . . . + (1 - Xann)cn = b, . 
(18.74) 

558 
INTEGRAL EQUATIONS 
When the Fredholm equation is homogeneous ( f ( z )  = 0) all bi are zero; thus 
for the solution to exist we must have 
det[I-XA] = 0. 
(18.75) 
Solutions of this equation give the eigenvalues Xi. Substituting these eigen- 
values into Equation (18.74) we can solve for the values of ci. 
Example 18.5. The case of sepamble kernels: Consider the homogeneous 
Fredholm equation given as 
(18.76) 
where 
MI(%) = 1, M2(z) = %, 
Nl(t) = 2t, N2(t) = 1 
(18.77) 
and with A written as 
0 4/3 
A = [ 2  
0 1- 
Using Equation (18.75) we write 
to find the eigenvalues as 
(18.78) 
= 0, 
(18.79) 
x1,2 = f- 
(18.80) 
Substituting these into Equation (18.74) we find two relations between 
the c1 and the c2 values as 
c1 fc2g 
=o. 
(18.81) 
As in the eigenvalue problems in linear algebra, we have only obtained 
the ratio, cI/cz, of these constants. Because Equation (18.76) is homo- 
geneous, normalization is arbitrary. Choosing c1 as one, we can write 
the solutions of Equation (18.76) as 
y2(z) = --J 
1
3
 
(1 - gz) for 
= -- 'J" 
(18.83) 
2
5
 
2 2' 

SOLUTION OF INTEGRAL EQUATIONS 
559 
When Equation (18.74) is inhomogeneous, the solution can still be found 
by using the techniques of linear algebra. We will come back to the 
subject of integral equations and eigenvalue problems shortly. 
18.5.4 
Sometimes it may be possible to free the unknown function under the integral 
sign, thus making the solution pcssible. 
Solution of Integral Equations by Integral Transforms 
18.5.4.1 
When the kernel is a function of 
(Z -t) and the range of the integral is from --co to +m we can use the Fourier 
transform method. 
Fourier Transform Method: 
Example 18.6. Fourier transform method: Consider the integral equa- 
tion 
We take the Fourier transform of this equation to write 
where tilde means the Fourier transform, which is defined as 
(18.84) 
(18.85) 
(18.86) 
In writing Equation (18.85) we have also used the convolution theorem: 
J - 0 0  
J-00 
which indicates that the Fourier transform of the convolution, f * g, of 
two functions is the product of their Fourier transforms. We now solve 
(18.85) for F(k) to find 
(18.87) 
which after taking the inverse transform will give us the solution in 
terms of a definite integral: 
(1 8.88) 

560 
INTEGRAL EQUATIONS 
18.5.4.2 Laplace Transform Method: The Laplace transform method 
is useful when the kernel is a function of (z - t )  and the range of the integral 
is from 0 to X. For example, consider the integral equation 
y(z) = 1 + 
y(u)sin(a - u)du. 
(18.89) 
L‘ 
We take the Laplace transform of this equation to write 
L [y(z)] = E [I] + E 
y(u)sin(a: - u)du . 
(18.90) 
[I’ 
1 
After using the convolution theorem: 
r P X  
1 
(18.91) 
where F(s) and G(s) indicate the Laplace transforms of $(z) and g(z), r e  
spectively, we obtain the Laplace transform of the solution as 
1 +s2 
Y ( s )  = - 
53 . 
Taking the inverse Laplace transform, we obtain the solution: 
X 2  
y(z) = 1 + T .  
(18.92) 
(18.93) 
(18.94) 
18.6 INTEGRAL EQUATIONS AND EIGENVALUE PROBLEMS 
(HILBERT-SCHMIDT THEORY) 
In the Sturm-Liouville theory we have defined eigenvalue problems using linear 
differential operators. We are now going to introduce the Hilbert-Schmidt 
theory, where an eigenvalue problem is defined in terms of linear integral 
operators. 
18.6.1 
Using the Fredholm equation of the second kind, we can define an eigenvalue 
problem as 
Eigenvalues Are Real for Hermitian Operators 
(18.95) 

INTEGRAL EQUATIONS AND ElGEN VAL UE PROBLEMS (HIL BERT-SCHMID T Tff EOR Y) 
561 
For the eigenvalue X i  we write 
(18.96) 
where yi(t) denotes the corresponding eigenfunction. Similarly, we write 
Equation (18.95) for another eigenvalue X j  and take its complex conjugate 
as 
(18.97) 
Multiplying Equation (18.96) by Xjy;(z) 
and Equation (18.97) by Xiyi(z), 
and integrating over x in the interval [a, b] we obtain two equations 
and 
If the kernel satisfies the relation 
K*(z,t) = K(t,z), 
Equation (18.99) becomes 
Subtracting Equations (18.98) and (18.101) we obtain 
(18.98) 
(18.99) 
(18.100) 
(18.101) 
(18.102) 
Kernels satisfying relation (18.100) are called Hermitian. For i = j Equation 
(18.102) becomes 
(18.103) 
6 
Since J, l y i ( ~ ) 1 ~  
dz # 0, Hermitian operators have real eigenvalues. 

562 
INTEGRAL EQUATIONS 
18.6.2 
Orthogonality of Eigenfunctions 
Using the fact that eigenvalues are real, for z # j Equation (18.102) becomes 
b 
( X j  - Xi)/ y,*(z)y;(s)& = 0. 
a 
(18.104) 
For distinct (nondegenerate) eigenvalues this gives 
JdbY;(z)Yi(z)dz 
= 0, ( X j  # Xi). 
(18.105) 
This means that the eigenfunctions for the distinct eigenvalues are orthogonal. 
In the case of degenerate eigenvalues, using the Gram-Schmidt orthogonaliza- 
tion method we can always choose the eigenvectors as orthogonal. Thus we 
can write 
Summary: For a linear integral operator 
b 
E = 
dtK(x,t), 
(18.106) 
(18.107) 
we can define an eigenvalue problem as 
b 
Y4Z) = xi 
K ( z ,  t)Yi(t)dt. 
(18.108) 
For Hermitian kernels satisfying K * ( z ,  t )  = K(t, z), eigenvalues are real 
and the eigenfunctions are orthogonal; hence after a suitable normaliza- 
tion we can write: 
(18.109) 
18.6.3 Completeness of the Eigenfunction Set 
Proof of the completeness of the eigenfunction set is rather technical for our 
purposes and can be found in Courant and llilbert (chapter 3, vol. 1, p. 136). 
We simply quote the following theorem: 
Expansion theorem: Every continuous function F( z) , which can be repre- 
sented as the integral transform of a piecewise continuous function G(z) 
and with respect to the real and symmetric kernel K ( z ,  2’) as 
F ( z )  = 1 K ( z ,  z’)G(z’)dx’, 
(18.110) 

INTEGRAL EQUATIONS AND EIGENVALUE PROBLEMS (HILBERT-SCHMIDT THEORY) 
563 
can be expanded in a series in the eigenfunctions of K(z, 2’); this series 
converges uniformly and absolutely. 
This conclusion is also true for Hermitian kernels. We can now write 
(18.111) 
where the coefficients a,, are found by using the orthogonality relation as 
s,” F (z) Y
:
 
(x) 
cia: = c J: anYn (x) Y
:
 
(x> 
dx, 
Substituting these coefficients back into Equation (18.111) we get 
(18.113) 
(18.114) 
This gives us a formal expression for the completeness of {ym (z)} as 
(18.115) 
Keep in mind that in general {yi(z)} do not form a complete set. Not just 
any function, but only the functions that can be generated by the integral 
transform [Eq. (18.1 lo)] can be expanded in terms of them. 
Let us now assume that a given Hermitian kernel can be expanded in terms 
of the eigenfunction set {yi(x)} 
as 
~ ( x , x ’ )  
= c 
Ci(z)Yi(Z’), 
( 18.116) 
i 
where the expansion coefficients ci carry the x dependence. From Equation 
(18.112) ci(z) are written as 
which after multiplying by A; becomes 
A;.;(.) 
= xi 
K ( z ,  z’)yf(x’)dx’. 
J 
(18.117) 
(18.118) 

564 
INTEGRAL EQUATIONS 
We now take the Hermitian conjugate of the eigenvalue equation 
yi (z) = xi J K(z, z’)yi (z’)dz’, 
(18.119) 
t,o write 
yt*(z) = xi 
yf(z’)K*(.’,z)dz’ 
(18.120) 
(18.121) 
(18.122) 
We now suhstitute Equation (18.122) into Equation (18.118) and solve for 
J 
s 
J 
= xi 
yz*(z’)K(z, 
z’)dd 
= xi 
K(z, .’)yz*(z/)dz’. 
C i ( x ) :  
(18.123) 
Finally, substituting Equation (18.123) into Equation (18.116) we obtain an 
elegant expression for the Hermitian kernels in terms of the eigenfunctions as 
18.7 EIGENVALUE PROBLEM FOR THE NON-HERMITIAN 
KERNELS 
In most of the important cases a non-Hermitian kernel 
can be written as 
b 
yd.1 
= xi 1 V(z, t)w(t)] Yi(t)dt, 
a 
where F(z, t )  satisfies the relation 
- 
K(z,t) = E*(t,2). 
We multiply Equation (18.125) h
y
m
 
and define 
(18.124) 
in Equation (18.95) 
(18.125) 
(18.126) 
(18.127) 

PROBLEMS 
565 
Now the kernel, ? 7 ( x , t ) d m ,  
in this equation is Hermitian and the 
eigenfunctions, q$ (z), are orthogonal with respect to the weight function W(Z) 
as 
(18.129) 
Problem 
18.1 
Find the solution of the integral equation 
y(t) = 1 + 
y(u)sin(t - u)du. 
l 
Check your answer by substituting into the above integral equation. 
18.2 
Show that the following differential equation and boundary conditions: 
y”(z) - y(z) = 0, y(0) = 0 and y’(0) = I, 
are equivalent to the integral equation 
y(5) = z + lz(5 
- z’)y(z’)dd. 
18.3 
an integral equation: 
Write the following differential equation and boundary conditions as 
Y”(2) - 51(2) = 0, 
y(1) = 0 and y(-I) = 1. 
18.4 
Using the Neumann series method solve the integral equation 
18.5 
functions: 
For the following integral equation find the eigenvalues and the eigen- 
2T 
y(5) = x 1 cos(5 - z’)y(z’)d5’ 
18.6 To show that the solution of the integral equation 
F Z  
y(5) = 1 + x2 
(5 - z’)y(z’)dz’ 
.I0 

566 
INTEGRAL EQUATIONS 
is given as 
y(z) = cosh AX. 
a) First convert the integral equation into a differential equation and then 
solve. 
b) Solve by using Neumann series. 
c) Solve by using the integral transform method. 
18.7 
integral equation 
By using different methods of your choice find the solution of the 
y(z) = z + X 
zz’y(d)dz’. 
.I’ 
Answer: y(z) = 32/(3 - A). 
18.8 
of motion is given as 
Consider the damped harmonic oscillator problem, where the equation 
a) Using the boundary conditions z(0) = zo and Z(0) = 0 show that z(t) 
satisfies the integral equation 
2 2 0 E  . 
z(t) = zo cos wot + - 
sin wot + 2~ 
~ ( t ‘ )  
cos wo(t - f.’)dt’ 
WO 
b) Iterate this equation several times and show that it agrees with the exact 
solution expanded to the appropriate order. 
18.9 
equation of motion and the boundary conditios are given as 
Obtain an integral equation for the anharmonic oscillator, where the 
d2x(t) 
dt2 + w i z ( t )  = -b23(t), 
z(0) = zo and k(0) = 0. 
18.10 
Consider the integral equation 
Y(Z) = z + 2 
[ZS(Z’ - Z) + z’B(z - z’)] y ( z ’ ) d d .  
J,’ 
First show that a Neumann series solution exists and then find it. 
18.11 
Using the Neumann series method find the solution of 
1 
y(z) = x2 + 6 1 (z + t)y(t)dt. 

I9 
GREEN’S FUNCTIONS 
Green’s functions are among the most versatile mathematical tools. They 
provide a powerful tool in solving differential equations. They are also very 
useful in transforming differential equations into integral equations, which are 
preferred in certain cases like the scattering problems. Propagator interpre- 
tation of Green’s functions is also very useful in quantum field theory, and 
with their path integral representation they are the starting point of modern 
perturbation theory. In this chapter, we introduce the basic features of both 
the time-dependent and the timeindependent Green’s functions, which have 
found a wide range of applications in science and engineering. 
19.1 TIME-INDEPENDENT GREEN’S FUNCTIONS 
19.1.1 
Green’s Functions in One Dimension 
We start with the differential equation 
where L is the Sturm-Liouville operator 
(19. I) 
(19.2) 
567 

568 
GREEN’S F UNCTlONS 
with p ( z )  and q(z) as continuous functions defined in the interval [a, b]. Along 
with this differential equation we use the homogeneous boundary conditions 
and 
(19.3) 
where (Y and P are constants. Because d(z) could also depend on the unknown 
function explicitly, we will also write it as 
d(X,Y(X)). 
Note that even though the differential operator L is linear, the differential 
equation [Eq. (19. l)] could be nonlinear. 
We now define a function G(z, 0, which for a given [ E [a, b] reduces to 
Gl(z) when z < [ and to G2(z) when z > [, and also has the following 
properties: 
i) Both Gl(z) and G ~ ( x )  
satisfy 
EG (z) = 0, 
(19.4) 
in their intervals of definition, that is: 
LGI (z) = 0, 
E G ~ ( x )  = 0, 
x < [, 
z > [. 
(19.5) 
ii) GI(%) satisfies the boundary condition at z = a, and G2(2) satisfies the 
iii) G(x,<) is continuous at x = [: 
boundary condition at 3: = b. 
G2(J) = GI([). 
(19.6) 
1 
iv) G(z,<) is discontinuous by the amount - 
at z = [: 
P ( 0  
(19.7) 
We also assume that p(z) is finite in the interval (a, b); thus the discontinuity 
is of finite order. 
We are now going to prove that if such a function can be found, then the 
problem defined by the differential equation plus the boundary conditions 
[Eqs. (19.1-19.3)] is equivalent to the equation 
(19.8) 

TIME-INDEPENDENT GREEN ‘5 FUNCTIONS 
569 
where G(z,I) is called the Green’s function. If c)(z,y([)) does not depend 
on y(x) explicitly, then finding the Green’s function is tantamount to solv- 
ing the problem. For the cases where 4(z,y(I)) depends explicitly on y(x), 
then Equation (19.8) becomes the integral equation version of the problem de- 
fined by the differential equation plus the homogeneous boundary conditions 
[Eqs. (19.1-19.3)]. Before we prove the equivalence of Equations (19.8) and 
(19.1-19.3), we show how a Green’s function can be constructed. However, 
we first drive a useful result called Abel’s formula. 
19.1.2 
Abel’s Formula 
Let u(z) 
and ~ ( x )  
be two linearly independent solutions of Q ( x )  = 0, so that 
we can write 
and 
respectively. Multiplying the first equation by v and the second by u and then 
subtracting gives us 
After expanding and rearranging, we can write this as 
d 
dx 
- 
Ip(z) ( U d  - 4
1
 
= 0, 
which implies 
A 
(uv’ 
- vu’) 
= - 
P(X) ’ 
(19.9) 
where A is a constant. This result is known as Abel’s formula. 
19.1.3 
Let y = u(x) be a nontrivial solution of -Ey = 0 satisfying the boundary 
condition at z = a and let y = v(z) be another nontrivial solution of -Ey = 0 
satisfying the boundary condition at x = b. We now define a Green’s function 
as 
How to Construct a Green’s Function 
c14x), z < I, 
c2+), 
z > I. 
(19.10) 
G ( x , I )  = 

570 
GREEN'S FUNCTIONS 
This Green's function satisfies conditions (i) and (ii). For conditions (iii) and 
(iv) we require c1 and c2 to satisfy the equations 
c 2 4 E )  - ClU(F) = 0 
(19.11) 
and 
1 
cpu'(J) - c*u'([) = -. 
P(F) 
(19.12) 
For a unique solution of these equations we have to satisfy the condition 
where W [ u , ~ ]  
is called the Wronskian of the solutions u(z) 
and ~ ( z ) .  
When 
these solutions are linearly independent, W [ u , ~ ]  
is different from zero and 
according to Abel's formula W [u, 
u] is equal to -, 
where A is a constant 
independent of [. Equations (19.11) and (19.12) can now be solved for c1 and 
c2 to yield 
A 
P(E) 
(19.14) 
Now the Green's function becomes 
xu (.I. 
( F )  , 5 < E, 
; i " ( E ) " ( " ) ,  
z > F. 
(19.15) 
b i: 
G(x,E) = 
Evidently, this Green's function is symmetric and unique. We now show that 
the integral 
Y(Z) = l G(z,l)4@)4 
(19.16) 
is equivalent to the differential equation [Eq. (19. l)] plus the boundary con- 
ditions [Eq. (19.3)]. We first write equation Equation (19.16) explicitly as 
b 
Y b )  = ; 
[ l Z v ( . , . i o y i 0 d E + /  
v ( F ) u ( . ) m @ ]  
(19.17) 
and evaluate its first- and second-order derivatives: 

TIME-INDEPENDENT GREEN'S FUNCTIONS 
571 
where we have used the formula 
we get 
A 
(19.20) 
A 
Since u(z) 
and ~ ( x )  
satisfy 
Lu(x) = 0 and Lv(z) = 0, 
(19.21) 
respectively, we obtain 
JEy(Z) = (P(Z). 
To see which boundary conditions y(x) satisfies we write 
and 
(19.22) 
(19.23) 
1 
condition with ~ ( z )  
at 
(19.24) 
(19.25) 
With the homogeneous boundary conditions this is equivalent to the integral 
equation 
(19.26) 

572 
GREEN’S FUNCTIONS 
19.1.4 
To find the differential equation that the Green’s function satisfies, we operate 
on y(x) in Equation (19.16) with .€ to write 
The Differential Equation That the Green’s Function Satisfies 
b 
= .1: .€G(x, t)4 (0 @. 
Because the operator E [Eq. (19.2)] acts only on z, we can write this as 
b 
4 
= 
ILG(x, 01 4 
@, 
(19.27) 
which is the defining equation for the Dirac-delta function 6 (x - 0. Hence 
we obtain the differential equation for the Green’s function as 
.LG(z, t) = 6 
(Z - [) . 
(19.28) 
Along with the homogeneous boundary conditions 
and 
(19.29) 
Equation (19.28) is the defining equation for G(z, I). 
19.1.5 Single- Point Boundary Conditions 
We have so far used the boundary conditions in Equation (19.3), which are also 
called the twepoint boundary conditions. In mechanics we usually encounter 
single-point boundary conditions, where the position and the velocity are 
given at some initial time. We first write the Green’s function satisfying the 
homogeneous singlepoint boundary conditions G(z0, x’) = 0 and G’(z0, x’) = 
0 as 
G(x,x’) = ciyi(z) + ~2~2(x), > x’, 
G(z,x’) = 
0, 
x < x’, 
(19.30) 
where yl(x) and y2(x) are two linearly independent solutions of 
Ey(x) = 0. 

TlME-INDEPENDENT GREEN 5 FUNCTIONS 
573 
Following the steps of the method used for two-point boundary conditions 
(see Problem 19.4), we can find the constants c1 and c2, and construct the 
Green’s function as 
where W[yl (x’), 
yz(z’)] is the Wronskian. 
Now the differential equation 
-CY(Z) = +(.>, 
Y(Z0) = Yo and Y’(Z0) = YA 
with the given singlepoint boundary conditions 
is equivalent to the integral equation 
142) = CIYI(Z) + C2~2(5) 
+ 1’ G(z, x’)@(x’W’. 
(19.32) 
The first two terms come from the solutions of the homogeneous equation. 
Because the integral term and its derivative vanish at z = 20, we use C l  and 
C2 to satisfy the singlepoint boundary conditions. 
‘ 0  
19.1.6 
Green’s Function for the Operator d2/dx2 
The Helmholtz equation in one dimension is written as 
(19.33) 
where l e ~  
is a constant. Using the homogeneous boundary conditions 
y(0) = O  
and 
y(L) =0, 
(19.34) 
we integrate Equation (19.33) between (0, x) to write 
(19.35) 
where C is an integration constant corresponding to the unknown value of the 
derivative at x = 0. A second integration yields 
r x  
where we have used one of the boundary conditions, that is, y(0) = 0. Using 
the second boundary condition, we can now evaluate C as 
(19.37) 

574 
GREEN'S FUNCTIONS 
This leads us to the following integral equation for y(x): 
(19.38) 
d2 
dx2 
To identify the Green's function for the operator L = -, 
we rewrite this as 
(19.39) 
and compare with 
L 
Y(Z> = Jo G(X1 "-&AF)ldF. 
(19.41) 
d'" 
dx2 
This gives the Green's function for the L = - 
operator as 
- - p - F h  
x < F ,  
(19.42) 
i: 
- z ( L - x ) ,  
2 > [ .  
G ( x , l )  = 
Now the integral equation (19.41) is equivalent to the differential equation 
(19.43) 
with the boundary conditions 
y(0) = y(L) = 0. 
(19.44) 
As long as the boundary conditions remain the same we can use this Green's 
function to express the solution of the differential equation 
as 
(19.45) 
(19.46) 

TIME-INDEPENDENT GREEN’S FUNCTIONS 
575 
For a different set of boundary conditions one must construct a new Green’s 
function. 
Example 19.1. Green’s function for the f = & operator: Wehaveob 
tained the Green’s function [Eq. (19.42)] for the operator L = d2/dx2 
with the boundary conditions y(0) = y(L) = 0. Ransverse waves on 
a uniform string of fixed length L with both ends clamped rigidly are 
described by 
where f ( z ,  y) represents external forces acting on the string. Using the 
Green’s function for the d2/dx2 operator we can convert this into an 
integral equation as 
PL 
OL 
19.1.7 
In the presence of inhomogeneous boundary conditions we can still use the 
Green’s function obtained for homogeneous boundary conditions and modify 
the solution [Eq. (19.8)] as 
Green’s Functions for lnhomogeneous Boundary Conditions 
b 
Y k )  = P(.> + 1 G(.’ 0 4  (0 4’ 
(19.49) 
where y(z) now satisfies 
&dx) = 4(.) 
(19.50) 
with the inhomogeneous boundary conditions. Operating on Equation (19.49) 
with f and using the relation between the Green’s functions and the Dirac- 
delta function [Eq. (19.28)], we obtain a differential equation to be solved for 
P(x) as 
(19.51) 
fP(x) = 0. 
(19.53) 
Because the second term in Equation (19.49) satisfies the homogeneous bound- 
ary conditions, P( .) 
must satisfy the inhomogeneous boundary conditions. 

576 
GREEN’S FUNCTIONS 
Existence of P(z) is guaranteed by the existence of G(z, E). The equivalence 
of this approach with our previous method can easily be seen by defining a 
new unknown function 
which satisfies the homogeneous boundary conditions. 
Example 19.2. Inhomogeneow boundary conditions: Equation of m e  
tion of a simple plane pendulum of length 1 is given as 
d28(t) 
- 
= -wisino, 
dt2 
W; = g / l ,  
(19.55) 
where g is the acceleration of gravity and 8 represents the angle from the 
equilibrium position. We use the inhomogeneous boundary conditions: 
8(0) = 0 and 8(tl) = 81. 
(19.56) 
We have already obtained the Green’s function for the 8 / d x 2  operator 
for the homogeneous boundary conditions [Eq. (19.42)]. We now solve 
d2 
dt2 
-P(t) = 0 
(19.57) 
with the inhomogeneous boundary conditions 
P(0) = 0 and P(tl) = el, 
(19.58) 
to find 
@ I t  
P(t) = -. 
tl 
(19.59) 
Because Cp( t )  is 
4(t) = -wi sin e(t), 
(19.60) 
we can write the differential equation [Eq. (19.55)] plus the inhomoge 
neous boundary conditions [Eq. (19.56)] as an integral equation: 
Example 19.3. Green’s function: We now consider the differential equa- 
tion 
2 8 Y  
dY 
x - 
+ x- + (k2x2 - 1) y = 0 
dx2 
dx 
(19.62) 

TIME-INDEPENDENT GREENS FUNCTIONS 
577 
with the boundary conditions given as 
y(0) = 0 and y(L) = 0. 
(19.63) 
We write this differential equation in the form 
and define the L operator as 
(19.64) 
(19.65) 
where 
p(z) = z, q(2) = --, 1 r(z) = 2. 
(19.66) 
X 
The general solution of 
Ly=O 
y = c12 + c 2 z - I  
Y (0) = 0, 
!I(.) 
= +), 
is given as 
Using the first boundary condition 
we find ~ ( z )  
as 
= z. 
(19.67) 
(19.68) 
(19.69) 
(19.70) 
Similarly, using the second boundary condition 
Y(L) = 0, 
(19.71) 
we find ~ ( z )  
as 
(19.72) 
L2 
V ( X )  = - - X .  
X 
We now evaluate the Wronskian of the u and the u solutions as 
w [u, 
w] = u (2) 
w/ 
( X )  - 0 (z) u) 
( X )  
(19.73) 
2 L 2  
- -- 
- 
X 
(19.74) 

578 
GREEN’S FUNCTIONS 
which determines A as -2L2. Putting all these together we obtain the 
Green’s function as 
Using this Green’s function we can now write the integral equation 
(19.76) 
which is equivalent to the differential equation plus the boundary con- 
ditions given in Equations (19.62) and (19.63). 
Note that the differential equation in this example is the Bessel equation 
and the only useful solutions are those with the eigenvalues k, satisfying 
the characteristic equation 
JI(k,L) = 0. 
(19.77) 
In this care the solution is given as 
where C is a constant. The same conclusion is valid for the integral 
equation (19.76). 
Note that we could have arranged the differential equation (19.62) as 
where the operator L is now defined as 
(19.79) 
(19.80) 
If the new L and the corresponding Green’s function are compatible 
with the boundary conditions, then the final answer, y(x,Ic,), will be 
the same. In the above example, Green’s function for the new operator 
[Eq. (19.80)] has a logarithmic singularity at the origin. We will explore 
these points in Problems 19.11 and 19.12. In physical applications form 
of the operator is usually dictated to us by the physics of the problem. 
For example, in quantum mechanics L represents physical properties 
with well-defined expressions with their eigenvalues corresponding to 
observables like angular momentum and energy. 

TIME-INDEPENDENT GREEN'S FUNCTIONS 
579 
19.1.8 
Consider the differential equation 
Green's Functions and the Eigenvalue Problems 
with the appropriate boundary conditions, where L is the Sturm-Liouville 
operator 
dx 
(19.82) 
We have seen that the L operator has a complete set of eigenfunctions defined 
by the equation 
L4n(x) = &dbn(z), 
(19.83) 
where An are the eigenvalues. Eigenfunctions &(x) satisfy the orthogonality 
relation 
/ &(zMrn(z)dx = Snm 
(19.84) 
and the completeness relation 
x4:(z)&(z')dx = 6 (x - x') . 
In the interval z E [a, b ] ,  we can expand y(z) and f(z) 
in terms of the set 
(19.85) 
n 
{4n(.)) as 
(19.86) 
1, 
Yb) = E," an4n(-c) 
f(.) 
= c," Pn4n(z) 
where an and fin are the expansion coefficients: 
Operating on y(z) with L we get 
m 
(19.87) 
(19.88) 

580 
GREEN’S FUNCTIONS 
Using Equation (19.88) with the eigenvalue equation [Eq. (19.83)] and the 
Equation (19.86) we can write 
LY(.> 
= f(.) 
(19.89) 
as 
00 C [anAn - ~ n ]  
4n(x) = 0- 
(19.90) 
n 
Because (pn are linearly independent, the only way to satisfy this equation for 
all n is to set the expression inside the square brackets to zero, thus obtaining 
an = -. 
(19.91) 
Pn 
An 
We use this in Equation (19.86) to write 
After substituting the Pn given in Equation (19.87) this becomes 
Using the definition of the Green’s function, that is, 
we obtain 
(19.92) 
(19.93) 
(19.94) 
(19.95) 
Usually we encounter differential equations given as 
LEY(Z) - Adz) = f @ ) ,  
(19.96) 
where the Green’s function for the operator ( L  - A) can be written as 
Note that in complex spaces Green’s function is Hermitian: 
G(z, z’) = G*(z’, z). 
(19.97) 

TlME-INDEPENDENT GREEN’S FUNCTIONS 
581 
Example 19.4. Eigenfunctions and the Green’s function for L = &: 
Let us reconsider the L = & operator in the interval x E [0, L]. The 
corresponding eigenvalue equation is 
Using the boundary conditions 
dn(0) = 0 and &(L) = 0, 
(19.99) 
we find the eigenfunctions and the eigenvalues as 
We now construct the Green’s function as 
00 sin (yz) 
sin (Yz’) 
(19.101) 
2 
L n 
-n2r2/L2 
G(x, x’) = - C 
For the same operator, using the Green’s function in Equation (19.42), 
we have seen that the inhomogeneous equation 
_ -  
d2y - F(x, y) 
dx2 
(19.102) 
and the boundary conditions 
Y(0) = Y(L) = 0 
can be written as an integral equation: 
y(x) = lz 
(X - x’) F(x’)dx’ - - 
( L  - x‘) F ( d ) d d .  
(19.103) 
lL 
Using the step function 0 (X - x’) we can write this as 
L 
y ( x )  = 1 ( x  - x‘) 0 (X - x‘) F(z’)dx’ - 
( L  - x‘) F(z’)dd, 
(19.104) 
or 
X 
L 
Y ( Z )  = 
[ ( z - x ’ ) O ( ~ - d ) -  -(L-x’)] F(z’)dz’. 
(19.105) 
L 

582 
GREEN’S FUNCTIONS 
This also gives the Green’s function for the L = d2/dx2 operator as 
X 
G(x, d) 
= [(x - 2’) 
0 (. - x’) - - ( L  - 41 . 
(19.106) 
L 
One can easily show that the Green’s function given in Equation (19.101) 
is the generalized Fourier expansion of the Equation (19.1%) in terms 
of the complete and orthonormal set [Eq. (19. loo)]. 
19.1.9 
Let us now consider the inhomogeneous Helmholtz equation 
Green’s Function for the Helmholtz Equation in One Dimension 
(19.107) 
with the boundary conditions y(0) = 0 and y(L) = 0. Using Equations (19.96) 
and (19.97) we can write the Green’s function as 
( 19.108) 
Using this Green’s function, solution of the inhomogeneous Helmholtz equa- 
tion (19.107) is written as 
where f(x) represents the driving force in wave motion. Note that in this case 
the operator is defined as 
d2 
dx2 
o- 
L = - + k 2  
Green’s function for this operator can also he obtained by direct construction, 
that is, by determining the u and the 
solutions in Equation (19.15) as 
sin b x  and sin ko(x - L), 
respectively. We can now obtain a closed expression for G(z, d) 
as 
sin kox sin ICg(x’ - L )  
b sin ko L 
sin kox’ sin ko(x - L) 
b sin ko L 
, x <XI, 
, x > 2’. 
(19.109) 
G(x, 
x‘) = 

TIME-INDEPENDENT GREEN’S FUNCTIONS 
583 
19.1.10 
Green’s Functions and the Dirac-Delta Function 
Let us operate on the Green’s function [Eq. (19.95)] with the d: operator: 
(19.110) 
Because E is a linear operator acting on the variable x, we can write 
(19.11 1) 
Using the eigenvalue equation E&(z) = An&(z) we obtain 
For a given function f(x) we write the integral 
(19.113) 
n 
For a complete and orthonormal set the right-hand side is the generalized 
Fourier expansion of f(z); 
thus we can write 
J I ( z ,  z’)j(x’)dz’ = f(x). 
(19.114) 
Hence I ( z ,  d) 
is nothing but the Dirac-delta function: 
I(z, 2’) = EG(2, z’) = S (Z - 2 ’ ) .  
(19.115) 
Summary: A differential equation 
LY@) = f(z,y) 
defined with the Sturm-Liouville operator E (Eq. (19.2)] and with the 
homogeneous boundary conditions [Eq. (19.3)] is equivalent to the in- 
tegral equation 
where G(x, d) 
is the Green’s function satisfying 
LG(z, d) 
= S (X - z’) , 
with the same boundary conditions. 

584 
GREENS FUNCTIONS 
19.1.11 
Green's Function for the Helmholtz Equation far All 
Space-Continuum Limit 
d2 
dx2 
We now consider the operator J = - 
+kz in the continuum limit with 
(19.116) 
Because the eigenvalues are continuous we use the Fourier transforms of y(z) 
and f ( z )  as 
d2Y 
2 + kiy = f(z), 2 E (-m, 00). 
1
"
 
f(z) 
= - 1 dk'g(k')eikfZ 
V
G
 -" 
and 
Their inverse Fourier transforms are 
and 
Using these in Equation (19.116) we get 
which gives us 
Substituting this in Equation (19.118) we obtain 
Writing g(k') explicitly this becomes 
( 19.117) 
(19.118) 
(19.119) 
(19.120) 
(19.121) 
(19.122) 
(19.123) 
(19.124) 

TIME-INDEPENDENT GREENS FUNCTIONS 
585 
which allows us to define the Green's function as 
J-00 
where 
G(z,z') = -- 
(19.125) 
Using one of the representations of the Dirac-delta function: 
it is easy to see that G(z, d) 
satisfies the equation 
EG(x, d) 
= S(Z - 2'). 
(19.126) 
The integral in Equation (19.125) is undefined at k' = fb. 
However, we 
can use the Cauchy principal value: 
00 
d x f o  = f i 7 r  f (a), 
.I, 
(.-a) 
(19.127) 
to make it well defined. The + or - signs depend on whether the contour is 
closed in the upper or lower z-planes, respectively. There are also other ways 
to treat these singular points in the complex plane, thus giving us a collection 
of Green's functions each satisfying a different boundary condition, which we 
study in the following example. 
Example 19.5. Helmholtz equation in the continuum limit: We now 
evaluate the Green's function given in Equation (19.125) by using the 
Cauchy principal value and the complex contour integral techniques. 
Case I. Using the contours in Figures 19.1 and 19.2 we can evaluate the 
integral 
(19.128) 
For (z - 2') > 0 we use the contour in Figure 19.1 to find 
(19.129) 

586 
GREEN’S FUNCTIONS 
k’-plane 
Fig. 19.1 Contour for Case I : (z - 2’) > 0 
I k‘-plane 
Fig. 19.2 Contour for Case I : (z - x’) < 0 
For (x - x r )  < 0 we use the contour in Figure 19.2 to find 
1
.
 
G(x, x‘) = -- sin ko (x - z’) 
2 b  
1 
= -ssinb(z’-x). 
2kO 
(19.130) 
Note that for the (x - x’) < 0 case the Cauchy principal value is -z~f(u). 
In the following cases we add small imaginary pieces, &ZE, to the two 
roots, fko and -ko, of the denominator in Equation (19.125), thus mov- 
ing them away from the real axis. We can now use the Cauchy integral 
theorems to evaluate the integral (19.125) and then obtain the Green’s 
function in the limit E -+ 0. 

TIME-INDEPENDENT GREEN’S FUNCTIONS 
587 
Fig. 19.3 Contours for Case I1 
Case 11: Using the contours shown in Figure 19.3 we obtain the following 
Green’s function: 
For (x - d) > 0 we use the contour in the upper half complex k’-plane 
to find 
(19.131) 
(19.132) 
For (a: - d) < 0 we use the contour in the lower half-plane to get 
(19.133) 
Note that there is an extra minus sign coming from the fact that the 
contour for the (z - d) 
< 0 case is clockwise; thus we obtain the Green’s 
function as 
(19.134) 

588 
GREENS FUNCTIONS 
fig. 19.4 Contours for Case 111 
Case 111: Using the contours shown in Figure 19.4, Green’s function is now 
given as the integral 
(19.135) 
For (z - z’) > 0 we use the upper contour in Figure 19.4 to find 
while for (z - z’) < 0 we use the lower contour to find 
2.rr2 e-iklJ(2-2’) 
2n 
-2ko 
G(z,d) = -(-)- 
Combining these we write the Green’s function as 
(19.136) 
(19.137) 
eiko (2 - z’ ) 
-ik*( z- z’) 
G(z,z’) = 
0 (x - z’) + 
2koi 
0 (d - z) . 
(19.138) 
2koi 

TIME-INDEPENDENT GREEN’S FUNCTIONS 
589 
Fig. 19.5 Contours for Case IV 
Case IV: Green’s function for the contours in Figure 19.5: 
For (z - z’) > 0 we use the upper contour to find 
G(z, z’) 
= 0. 
(19.139) 
Similarly, for (z - z’) < 0 we use the lower contour to obtain 
1 
ei( k o - i ~ ) ( z - z ’ )  
ei( - ko- i~)( z- z’) 
2 (-ko - ZE) 
+ 
2kO 1 
= z [  
2kl 
+ 
1 
27r 
G(z,z’) = --(-)27rZ 
lim 
ezko (z-z’) 
e- i k o ( z - z ’ )  
sin ko (z - 2’) 
k0 
- 
- 
- 
The combined result becomes 
(19.140) 
sin ko (z - d) 
ko 
G(z,z’) = - 
0 (2’ - z) . 
(19.141) 
This Green’s function is good for the boundary conditions given as 
G(z, z’) + 0 
G’(z, z’) + 0 
1-02 
lim { 
}. 
(19.142) 

590 
GREEN‘S FUNCTIONS 
K-plane 
I 
Fig. 19.6 Contours for Case V 
Case V: Green’s function using the contours in Figure 19.6: 
For (z - d) 
> 0 we use the upper contour to find 
sin ko (Z - x’) 
Ice 
- 
- 
Similarly, for (z - z’) < 0 we use the lower contour to find 
G(z, z’) = 0. 
The combined result becomes 
sin ICO (x - d) 
b 
8 (z - d) 
, 
G(z,z’) = 
which is useful for the cases where 
(19.143) 
(19.144) 
(19.145) 

TIME-INDEPENDENT GREEN 5 FUNCTIONS 
591 
w-plane 
I 
Fig. 19.7 Contours for the harmonic oscillato~ 
Example 19.6. Green’s function for the harmonic oscillator: For the 
damped driven harmonic oscillator the equation of motion is written as 
d2x 
dx 
- 
+ 2E- 
+ wix(t) = f ( t ) ,  
dt2 
dt 
6 > 0. 
(19.146) 
In terms of a Green’s function the solution can be written as 
00 
z(t) = C l ~ i ( t )  
+ C 2 ~ ( t )  
+ 
(19.147) 
where xl(t) and ~ ( t )  
are the solutions of the homogeneous equation. 
Assuming that all the necessary Fourier transforms and their inverses 
exist, we take the Fourier transform of the equation of motion to write 
the Green’s function as 
Since the denominator has zeroes at 
2 i E  ‘f J- 
4
2
 = 
2 
(19.148) 
(19.149) 

592 
GREEN’S FUNCTIONS 
we can write G(t, t’) as 
l o o  
eiw’( t- t ’ )  
G(t,t’) = -G Loo 
dw’ (w’ - w;) 
(w’ - wb)’ 
(19.150) 
We can evaluate this integral by going to the complex w-plane. For 
(t -t’) > 0 we use the upper contour in Figure 19.7 to write the Green’s 
function as 
1 
q t ,  t’) = -- 
27r i
+
 
(w; 
-wb) 
(Wh -wi) 
2T2 
p J ; ( t - t ’ )  
eiw;(t-t’) 
(19.151) 
For (t - t’) < 0 we use the lower contour in Figure 19.7. Because there 
are no singularities inside the contour, Green’s function is now given as 
G(t, t’) = 0. 
Combining these results we write the Green’s function as 
or 
It is easy to check that this Green’s function satisfies the equation 
G(t,t’) = S (t - t’) . 
(19.154) 
Example 19.7. Damped driven harmonic oscillator: In the previous ex- 
ample let us take the driving force as 
f ( t )  = 
(19.155) 
where LY is a constant. For sinosoidal driving forces we could take LY as 
iwl, where w1 is the frequency of the driving force. If we start the system 

TIME-INDEPENDENT GREENS FUNCTIONS 
593 
with the initial conditions z(0) = k(0) = 0, C1 and C2 in Equation 
(19.147) is zero, hence the solution will be written as 
where we have defined 
(19.156) 
One can easily check that s(t) satisfies the differential equation 
d'z(t) 
d z ( t )  
2 
dt2 + 2E- 
+ woz(t) = & - a t .  
dt 
(19.157) 
For weak damping the solution reduces to 
As expected, in the t + 00 limit this becomes 
FO sin [wot - 71 
z(t) = - 
wo JW' 
19.1.12 
Green's Function for the Helmholtz Equation in Three 
Dimensions 
The Helmholtz equation in three dimensions is given as 
We now look for a Green's function satisfying 
+ ko G(?, F') = S ( 7  - 7'). 
("' 
2, 
(19.159) 
(19.160) 
We multiply the first equation by G(?,7') and the second by $(7) 
and 
then subtract, and integrate the result over the volume V to get 
- ///v 
F(?)G(7, 7')d3?;t. 
(19.161) 

594 
GREEN’S FUNCTIONS 
Using Green’s theorem 
JJJ, ( F V ~ G  
- G V ~ F )  
d3F = JJ (PVG 
- GVF) 
. iids, 
(19.162) 
S 
where S is a closed surface enclosing the volume V with the outward unit 
normal ii, we obtain 
Interchanging the primed and the unprimed variables and assuming that the 
Green’s function is symmetric in anticipation of the corresponding boundary 
conditions to be imposed later, we obtain the following remarkable formula: 
Boundary conditions: 
The most frequently used boundary conditions are: 
i) Dirichlet boundary conditions, where G is zero on the boundary. 
ii) Neumann boundary conditions, where the normal gradient of G on the 
surface is zero: 
TG.61 
= O .  
boundary 
iii) General boundary conditions: 
= 0, 
boundary 
T G  + ??(?“)GI 
where T ( F ’ )  
is a function of the boundary point 7‘. 
surface term in the above equation vanishes, thus giving 
For any one of these cases, the Green’s function is symmetric and the 
(19.165) 
19.1.13 
Green’s Functions in Three Dimensions with a Discrete 
Spectrum 
Consider the inhomogeneous equation 
H@(?;’) = F(?;‘), 
(19.166) 

TIME-INDEPENDENT GREEN 5 FUNCTIONS 
595 
where H is a linear differential operator. H has a complete set of orthonormal 
eigenfunctions, {$A(?)), which are determined by the eigenvalue equation 
where X stands for the eigenvalues and the eigenfunctioris satisfy the homoge- 
neous boundary conditions given in the previous section. We need a Green's 
function satisfying the equation 
H G ( 7 ,  ?') = S(? - 7'). 
(19.167) 
Expanding @(?) 
and F(?) in terms of this complete set of eigenfunctions 
we write 
(19.168) 
@(-i-.i> = Ex axdx(?;') 
F(?) = Ex cx$x(?") 
where the expansion coefficients are 
(19.169) 
ax = JJj", 43?)@(?)d3? 
cx = JJJ, $1(?)F(?)d3? 
(19.170) 
ax = -. 
Using this ax and the explicit form of cx in Elpation (19.169) we can write 
Q(7) 
as 
CA 
X 
Substituting these into Equation (19.166) we obtain 
This gives the Green's function as 
(19.172) 
This Green's function can easily be generalized to the equation 
(H -A,) 
@(?) = F(?), 
(19.173) 
for the operator (H - A,) 
as 
(19.174) 

596 
GREENS FUNCTlONS 
We now find the Green’s function for the three-dimensional Helmholtz 
equation 
(“2 + k;) $(?) = F(?) 
in a rectangular region bounded by six planes: 
x=O, 
z = a  
y = O ,  
y = b  
z = o ,  
z = c  
(19.175) 
i 
and with the homogeneous Dirichlet boundary conditions. The corresponding 
eigenvalue equation is 
T241mn(T) + k12,,4lmn(T) = 0- 
The normalized eigenfunctions are easily obtained as 
where the eigenvalues are 
L2x2 m2x2 n2r2 
klmn = - 
+ - 
+ - 
a2 
b2 
c2 ’ 
(1, m, n = positive integer). 
(19.177) 
Using these eigenfunctions [Eq. (19.176)] we can now write the Green’s func- 
tion as 
(19.178) 
19.1.14 
Green’s function for the Laplace operator V2 satisfies 
Green’s Function for the Laplace Operator Inside a Sphere 
q 2 G (  7, 
?’) = S( ?, ?’). 
(19.179) 
Using spherical polar coordinates this can be written as 
T2G(?, 7’) 
= 
~ S ( r  - r ’ )  S(cm e - cos8’)6(4 - 4’) 
(19.180) 
r ’2 

TIME-INDEPENDENT GREEN’S FUNCTIONS 
597 
where we have used the completeness relation of the spherical harmonics. For 
the Green’s function inside a sphere, we use the boundary conditions 
G ( 0 , T ’ )  = finite, 
(19.182) 
G(u, 7’) 
= 0. 
(19.183) 
In spherical polar coordinates we can separate the angular part and write the 
Green’s function as 
(19.184) 
1=0 m=-l 
We now substitute Equation (19.184) into Equation (19.181) to find the dif- 
ferential equation that gl(r, r’) satisfies as 
1 
gl(r,r’) = -6(r - r’). 
r ‘2 
1 d2 
1 ( 1 +  1) 
- - 
[Tgl (T, ?-’)I - 7 
r dr2 
A general solution of the homogeneous equation 
can be obtained by trying a solution as 
~ r ‘  
+ clr-(l+l). 
(19.185) 
(19.186) 
(19.187) 
We can now construct the radial part of the Green’s function for the inside of 
a sphere by finding the appropriate u and the u solutions as 
r < r‘, 
r >r’. 
(19.188) 
Now the complete Green’s function can be written 
into Equation (19.184). 
by substituting this result 
19.1.15 
Green’s Functions for the Helmholtz Equation for All 
Space-Poisson and Schrdinger Equations 
We now consider the operator 
H o = q 2 + X  
(19.189) 
in the continuum limit. Using this operator we can write the following differ- 
ential equation: 
Ho@(?;’) = F’(?). 
(19.190) 

598 
GREENS FUNCTIONS 
- - +  
*--+ 
Let us assume that the Fourier transforms @( k ) and F( k ) of @(?) and 
F(F) exists: 
(19.191) 
(19.192) 
Taking the Fourier transform of Equation (19,190) we get 
Using the Green's theorem [Eq. 
Equation (19.193) as 
(19.162)] we can write the first term in 
(19.194) 
where S is a surface with an outward unit normal 2 enclosing the volume V. 
We now take our region of integration as a sphere of radius R and consider 
the limit R -+ 
00. In this limit the surface term becomes 
where 6 = ^er and dR = sin0dOd4. If the function *I(?) 
goes to zero suffi- 
ciently rapidly as 14 -+ 00, that is, when @(?) 
goes to zero faster than :, 
then the surface term vanishes, thus leaving us with 
in Equation (19.194). Consequently, Equation (19.193) becomes 
" i  F( T )  
* ( k ) =  
( 4 2  + A)' 
(19.196) 
(19.197) 
In this equation we have to treat the cases X > 0 and X 5 0 separately. 

TIME-INDEPENDENT GREEN’S FUNCTIONS 
5% 
Casel: X S O :  
In this case we can write X = - K ~ ;  thus the denominator (k2 + K
~
)
 
in 
- 4  
F ( 2 )  
* ( k ) = - -  k2 + K 2  
(19.198) 
never vanishes. Taking the inverse Fourier transform of this, we write 
the general solution of Equation (19.190) as 
where [(?) denotes the solution of the homogeneous equation 
Hot(?) = (T2 - K
~
)
 
[(T) 
= 0. 
(19.200) 
Defining a Green’s function G(?;‘,?:”) as 
we can express the general solution of Equation (19.190) as 
@(?) = [ ( F )  + /// G(?,7:”)F(?:”)d3?, 
(19.202) 
The integral in the Green’s function can be evaluated by using complex 
contour integral techniques. Taking the k vector as 
V 
--+ 
we write 
(19.203) 
(19.204) 
where d 3 x  = k2 sin BdkdBd4. We can take the #I and 0 integrals imme 
diately, thus obtaining 
(19.205) 

600 
GREEN’S FUNCTIONS 
Using Jordan’s lemma (Section 13.7) we can show that the integral over 
the circle in the upper half complex k-plane goes to zero as the radius 
goes to infinity; thus we obtain I as 
keikI-‘-+ 
2 ~ 2  residues of { k2 + K2 ’ } 
(19.206) 
2T 
I = .  
2 1 7 - ? ; t q  
k>O 
Using this in (19.201) we obtain the Green’s function as 
(19.207) 
(19.208) 
(19.209) 
To complete the solution [Eq. (19.202)] we also need [(F), 
which is 
easily obtained as 
7 
(19.210) 
[(T) 
= Coe*~lXef?2Ve*~3~ 
IE2 = K 4  + 6; + K;. 
Because this solution diverges for Irl + co, for a finite solution every- 
where we set CO = 0 and write the general solution as 
In this solution if F ( 7 ’ )  goes to zero sufficiently rapidly as lr’l -+ (x, or 
if F(?) 
is zero beyond some lr’l = ro, we see that for large r, q ( 7 )  
decreases exponentially as 
(19.212) 
This is consistent with the neglect of the surface term in our derivation 
in Equation (19.195). 
ePnr 
r 
@(?) 
--f c-. 
Example 19.8. Green’s function for the Poisson equation: Using the 
above Green’s function [Eq. (19.209)] with K = 0, we can now convert 
the Poisson equation 
V%$(T+) 
= -4Tp(T+) 
(19.213) 
into an integral equation. In this case X = 0; thus the solution is given 
as 
4(7) 
= -4~/// 
G ( 7 ,  ?;f’)p(?’)d3F’, 
(19.214) 
V 

TIME-INDEPENDENT GREEN'S FUNCTIONS 
601 
where 
(19.215) 
Example 19.9. Green's function for the Schrodinger equation-E < 0: 
Another application for Green's function [Eq. 
independent Schrodinger equation: 
(19.209)] is the time- 
For central potentials and bound states ( E  < 0) K~ is given as 
2m PI 
K2 = -__ 
f i 2  . 
Thus the solution of Equation (19.216) can be written as 
(19.216) 
(19.217) 
This is also the integral equation version of the time-independent Shrdinger 
equation for bound states. 
CaseII: X > O :  
In this case the denominator in the definition [Eq. (19.197)] of $(c) has 
zeroes at k = kfi. 
To eliminate this problem we add a small imaginary 
piece ZE to the X values as 
X = ( q * i & ) ,  
E > O .  
(19.219) 
Substituting this in Equation (19.197) we get 
(19.220) 
which is now well defined everywhere on the real k-axis. Taking the 
inverse Fourier transform of this we get 
We can now evaluate this integral in the complex k-plane using the 
complex contour integral theorems and take the limit as E + 0 to obtain 
the final result. Because our integrand has poles at 
k = (q f 
ZE), 

602 
GREEN5 FUNCTlONS 
we use the Cauchy integral theorem. However, as before, we first take 
the 8 and q3 integrals to write 
1’ 
- 
(k - q F is) (k + q f 
ZE) 
(19.222) 
For the first integral we close the contour in the upper half complex 
k-plane and get 
03 
?‘I 
I. (19.223) 
lcdk 
- 
- 7rie+iq] r’- -+-+ 
s, (k - q3= i E )  ( k  + q&iiE) 
Similarly, for the second integral we close our contour in the lower half 
complex k-plane to get 
(19.224) 
Combining these we obtain the Green’s function 
and the solution as 
The choice of the f 
sign is very important. In the limit as /?“I -+ 00 
this solution behaves as 
or 
e- iqr 
K(*)+E(?’f)+C-, 
(19.228) 
where C is a constant independent of r, but it could depend on 6 and 
4. The f 
signs physically correspond to incoming and outgoing waves. 
We now look at the solutions of the homogeneous equation: 
(“2 
+ 9’) t(7) = 0, 
(19.229) 

TIME-INDEPENDENT GREEN 5 FUNCTIONS 
603 
’+ i 
which are now given as plane waves, ez 
becomes 
’ ; thus the general solution 
The constant A and the direction of the 7 
vector come from the initial 
conditions. 
Example 19.10. Green’s function for the Schrodinger equation-E 2 0: 
An important application of the X > 0 case is the Schriidinger equa- 
tion for the scattering problems, that is, for states with E 2 0 .  Using 
the Green’s function we have found [Eq. (19.225)] we can write the 
Schrodinger equation, 
2m 
pty) 
*(?;’)= - V ( 7 ) * ( 7 ) ,  
h2 
(19.231) 
as an integral equation for the scattering states as 
(19.232) 
The magnitude of Ti is given as 
(19.233) 
Equation (19.232) is known as the Lipmann-Schwinger equation. 
For bound state problems it is easier to work with the differential equa- 
tion version of the Schodinger equation, hence it is preferred. How- 
ever, for the scattering problems, the Lipmann-Schwinger equation is 
the starting point of modern quantum mechanics. Note that we have 
written the result free of E in anticipation that the c -+ 0 limit will not 
cause any problems. 
19.1.16 
General Boundary Conditions and Applications to 
Electrostatics 
In the problems we have discussed so far the Green’s function and the solution 
were required to satisfy the same homogeneous boundary conditions (Section 
19.1.12). However, in electrostatics we usually deal with cases in which we 
are interested in finding the potential of a charge distribution in the presence 

604 
GREEN 5 FUNCTIONS 
of conducting surfaces held at constant potentials. The question we now ask 
is: Can we still use the Green’s function found from 
L‘G(7,?’) = S ( 7 - ? ‘ )  
(19.234) 
with the homogeneous boundary conditions? To answer this question we start 
with a general second-order linear operator of the form 
L = V . [.p(?)V] + q(r), 
(19.235) 
which covers a wide range of interesting cases. The corresponding inhomoge 
neous differential equation is now given as 
La(?) = F(?), 
(19.236) 
where the solution a(?) is required to satisfy more complex boundary con- 
ditions than the usual homogeneous boundary conditions that the Green’s 
function is required to satisfy. Let us first multiply Equation (19.236) with 
G(?,?‘) 
and Equation (19.234) with a(?), and then subtract and integrate 
the result over V to write 
a(?’) = /// F(?)G(?,7’)d3? 
(19.237) 
+ / / / 1 [ @ ( 7 ) L G ( 7 , 7 ’ )  - G(?,?’)L@(7)]d3?. 
We now write L explicitly and use the following property of the ? operator: 
3. 
[ f ( 7 ) 3 ( ? ) ]  = 5 f ( 7 ) .  3(7) 
+ f(?)5. 
a(?), 
to write 
+ /// 3 [p(?’)@(?)qG(?,7’) 
- G(T’,?’)p(7)?S(T’)] d3?. 
V 
Using the fact that for homogeneous boundary conditions the Green’s function 
is symmetric we interchange 7’ 
and ? : 
@(7) 
= /// F(-r”’)G(7,?’)d37;” 
V 
+ //I 3’. [p(?’)@(?’)q’G(?,?’) 
- G(?”,T”)p(?.’)?’@(?’)] 
d3?. 
V 
We finally use the Gauss theorem to write 
a(?) = /// F(?’)G(?,7’)d37’ 
(19.238) 
V 
+ // p(F“) k(-r“’)d’G(?,?’) 
- G(?,?’)g’@(?’)] 
efids’, 
S 

TIME-INDEPENDENT GREEN'S FUNCTIONS 
605 
where 6 is the outward unit normal to the surface S bounding the volume 
V. If we impcse the same homogeneous boundary conditions on @( ?") and 
G(T+,-F"), the surface term vanishes and we reach the conclusions of Section 
19.1.12. 
In general, in order to evaluate the surface integral we have to know the 
function @(7) 
and its normal derivative on the surface. As boundary con- 
ditions we can fix the value of @(?), its normal derivative, or even their 
linear combination on the surface S, but not @(?) and its normal deriva- 
tive at the same time. In practice, this difficulty is circumvented by choosing 
the Green's function such that it vanishes on the surface. In such cases the 
solution becomes 
a(?) =//I 
F(T+')G(?",?"')d3? 
+ //, [~(?')a(?~)~'G(?,T+')] 
. Gds'. 
V 
(19.239) 
As an example, consider electrostatics problem where we have 
F( ?") = -47rp( ?"), 
P F )  =I, 
i q( 7) 
= 0. 1 
(19.240) 
The potential inside a region bounded by a conducting surface held at constant 
potential VO is now given as 
a(?) = - 
47rp(T+)G(7,7')d3?;f' + Vo 
V'G(?,T+'). 
fids', 
(19.241) 
where G( ?',?;") 
comes from the solution of Equation (19.234) subject to the 
(homogeneous) boundary condition, which requires it to vanish on the surface. 
The geometry of the surface bounding the volume V could in principle be 
rather complicated, and a(?"') in the surface integral does not have to be a 
constant. 
Similarly, if we fix the value of the normal derivative q@(?;t) 
. ii on the 
surface, then we use a Green's function with a normal derivative vanishing on 
the surface. Now the solution becomes 
@(?) =//I P(?"')G(T+,T')d3?' - 
V 
(19.242) 

606 
GREEN 5 FUNCTIONS 
19.2 TIME-DEPENDENT GREEN’S FUNCTIONS 
19.2.1 Green’s Functions with First-Order Time Dependence 
We now consider differential equations, which could be written as 
(19.243) 
where T is a timelike variable, and H is a linear differential operator indepen- 
dent of T ,  which also has a complete set of orthonormal eigenfunctions. In 
applications we frequently encounter differential equations of this type. For 
example, the heat transfer equation is given as 
c aT(7,t) 
V2T(?.,t) = - 
k 
at 
(19.244) 
where T ( 7 , t )  is the temperature, c is the specific heat per unit volume, and 
5 is conductivity. Comparing this with Equation (19.243) we see that 
Another example for the first-order timedependent equations is the Schrodinger 
equation: 
alIr(T,t) 
at 
HlIr(7,t) = iti 
(19.245) 
where H is the Hamiltonian operator. For a particle moving under the influ- 
ence of a central potential V ( T ) ,  
H is given as 
Hence in Equation (19.243) 
fi2 
2m 
-v2 + V ( 7 ) .  
( 19.246) 
The diffusion equation is given as 
(19.247) 

TIME-DEPENDENT GREEN’S FUNCTIONS 
607 
where p(r, t )  is the density (or concentration) and u is the diffusion coefficient. 
In this case, 
Since H has a complete and orthonormal set of eigenfunctions, we can write 
the corresponding eigenvalue equation as 
H4m = Am4rn, 
(19.248) 
where Am are the eigenvalues and dm are the eigenfunctions. We now write 
the solution of Equation (19.243) as 
@ ( ~ , r )  
= x A m ( r ) 4 m ( T ) ,  
(19.249) 
where the time dependence is carried in the expansion coefficients Am(r). 
Operating on @(T,T) 
with H and remembering that H is independent of 7, 
we obtain 
m 
I 
m 
m 
Using Equation (19.250) and the time derivative of Equation (19.249) in Equa- 
tion (19.243) we get 
(19.251) 
Because {q5m} is a set of linearly independent functions, this equation cannot 
he satisfied unless all the coefficients of 4m vanish simultaneously, that is, 
dAm(r) -t AmAm(~) 
= 0 
d r  
(19.252) 
for all m. Solution of this differential equation can be written immediately 
as 
A,(T) = Am(0)e-XmT, 
(19.253) 
thus giving @(?,r) as 
@(+,T) = CArn(0)4m(?;’)e-Xm’. 
(19.254) 
m 

608 
GREEN’S FUNCTIONS 
To complete the solution we need an initial condition. Assuming that the 
solution at 7 = 0 is given as e(T,O), we write 
*(T,o) = C Am(O)$m(-i;f)- 
m 
Because the eigenfunctions satisfy the orthogonality relation 
and the completeness relation 
-y4k(T”)Cjn(T’) 
= 6(7 - T”), 
we can solve Equation (19.254) for A,(O) as 
(19.255) 
(19.2%) 
(19.257) 
A,(o) = SJS 4 3 + ’ ) e ( ~ ’ , o ) d 3 7 ’ .  
(19.258) 
V 
Substituting these Am(0) functions back into Equation (19.254) we obtain 
Rearranging this expression as 
@(T’,7) = 
~~~ 
G1(?”,T’,7)9(?’’’,0)c137’1’, 
(19.260) 
V 
we obtain a function 
where the subscript 1 denotes the fact that we have first-order time depen- 
dence. Note that GI (T,T”, 
7) satisfies the relation 
G~(”,T”, 
0) = C 4m(T)4h(T’) 
(19.262) 
m 
= 63 (7-7’) 
and the differential equation 
(19.263) 

TIME-DEPENDENT GREEN’S FUNCTIONS 
609 
Because Gl(?,?’, 
T )  does not satisfy the basic equation for Green’s func- 
tions, that is, 
(19.264) 
it is not yet the Green’s function for this problem. However, as we shall see 
shortly, it is very closely related to it. 
Note that if we take the initial condition as 
@(?,O) 
= s3 (?-?;to), 
(19.265) 
which is called the point source initial condition, GI becomes the solution 
of the differential equation (19.243), that is, 
@(?,T) = G~(?,$,T), T 2 0 . 
(19.266) 
19.2.2 
Propagators 
Because our choice of initial time as T’ = 0 was arbitrary, for a general initial 
time T’, 
@(?,T) and the G1 functions become 
(19.268) 
m 
From Equation (19.267) it is seen that, given the solution at (-?’,T’) 
as 
@(?’,T’), we can find the solution at a later time, Q(?,T > T’), by using 
Gl(?,?’,~,~’). It is for this reason that Gl(?;t,?;”,~,i’) is also called the 
propagator. In quantum field theory and perturbation calculations, prop 
agator interpretation of GI is very useful in the interpretation of Feynman 
diagrams. 
19.2.3 
Compounding Propagators 
Given a solution at TO, let us propagate it first to 7 1  > TO and then to 72 > TI 
as (from now on we use j d 3 T  instead of sljd3’?;’ ) 

610 
GREEN'S FUNCTlONS 
(19.271) 
Using the definition of propagators [Eq. (19.268)] we can also write this as 
(19.272) 
Using the orthogonality relation 
Equation (19.272) becomes 
(19.273) 
(19.274) 
Using this in Equation (19.271) we obtain the propagator, G1(7'),7')", T ~ , T o ) ,  
that takes us from TO to 7 2  in a single step in terms of the propagators, that 
take us from 70 to 7 1  and from 7 1  to 7 2 ,  respectively, as 
(19.275) 
19.2.4 
Propagator for the Diffusion Equation with Periodic Boundary 
Conditions 
As an important example of the first-order time-dependent equations, we now 
consider the diffusion or heat transfer equations, which are both in the form 
(19.276) 

TIME-DEPENDENT GREEN’S FUNCTIONS 
611 
To simplify the problem we consider only one dimension with 
and use the periodic boundary conditions: 
(19.277) 
Because the H operator for this problem is 
(19.278) 
we easily write the eigenvalues and the eigenfunctions as 
(19.279) 
If we define 
(19.280) 
we obtain GI (2, x’, 
7) as 
( 19.28 1) 
19.2.5 
We now consider the continuum limit of the propagator [Eq. (19.281)]. Be- 
cause the difference of two neighboring eigenvalues is 
Propagator for the Diffusion Equation in the Continuum Limit 
(19.282) 
we can write GI (x, 
x’, 
T )  as 
(19.283) 
In the continuum limit, L -+ 00, the difference between two neighboring eigen- 
values becomes infinitesimally small; thus we may replace the summation with 
an integral as 
(19.284) 

612 
GREENS FUNCTlONS 
This gives us the propagator as 
Completing the square: 
Zk(z - 2’) - Ic2T = -7 
(19.286) 
and defining 
we can write GI (2, z’, r) as 
This integral can be taken easily, thus giving us the propagator as 
1 
r-r‘)’ 
G l ( z , d , ~ )  
= - e - b .  
& 
(19.287) 
(19.288) 
Note that GI is symmetric with respect to z and z’. In the limit as r -+ 0 it 
becomes 
r-r’ 2 
(19.289) 
1 
lim ~ l ( z ,  
z’, r) = lim -e-* 
r-0 
T+O & 
= I(z, z’), 
which is one of the definitions of the Dirac-delta function; hence 
I($, z’) = S(z - z’). 
(19.290) 
Plotting Equation (19.288) we see that it is a Gaussian (Fig. 19.8). 
Because the area under a Gaussian is constant, that is, 
(19.291) 
the total amount of the diffusing material is conserved. Using GI (z, d, 
T )  
and given the initial concentration 8(z’,O), we can find the concentration at 
subsequent times as 
Note that our solution satisfies the relation 
(19.292) 
m 
00 
@(Z,T)dZ = [ 8(z’,O)dz’. 
( 19.293) 
J-00 
J-CC 

TIME-DEPENDENT GREEN’S FUNCTIONS 
613 
Fig. 19.8 Gaussian 
19.2.6 
First-order time-dependent equations frequently appear with an inhomoge- 
neous term: 
Green’s Functions in the Presence of Sources or Interactions 
(19.294) 
where F(7’),7) represents sources or interactions in the system; thus we need 
a Green’s function which allows us to express the solution as 
O( 7,~) 
= Q ~ ( ? , T )  + 1 G ( 7 ,  ?’”,7,7’)F(T+’,T’)d3?;tlCE71, (19.295) 
where @~(T,T) 
represents the solution of the homogeneous part of Equation 
(19.294). We have seen that the propagator GI(?”, ?’,T,T’) satisfies the 
equation 
(19.296) 
(II + g) 
GI( + 
T , 
+ I  T ,T,T’) 
= 0. 
However, the Green’s function we need in Equation (19.295) satisfies 
( H  + g) 
G(T+, ?if’,T,T/) = P(* - T+’)s( 7-T’). 
(19.297) 
It is clear that even though GI(?, T’,T,T’) 
is not the Green’s function, it is 
closely related to it. After all, except for the point 7 
= 7’ 
it satisfies the 

614 
GREEN 5 FUNCTIONS 
differential equation (19.297). Considering that GI (?, ?’,T,T’) 
satisfies the 
relation 
lim GI( 7, 
7’,r,r’) = 63( f - ?’), 
(19.298) 
we can expect to satisfy Equation (19.297) by introducing a discontinuity at 
T = T’. Let us start with 
T+T‘ 
G ( 7 ,  ?’,T,T/) = GI(?, ?’,T,T’)~~(T-T’), 
(19.299) 
so that 
(19.300) 
1 
G = GI, 
T>T’, 
{ G = 0, 
r<r’. 
Substituting this in Equation (19.297), we get 
H + - G( 7, 
?’,T,T’) 
(19.301) 
a 
a7 
( 
a”T) 
= HGI (?, 
?’,T,T’)Q(T-T’) + - 
[GI ( f ,  T+’,T,T’)Q(T-T’)] 
, 
= O(T-T’)HG~(?, ?’,T,T’) + Q(T-T’)-GI(?, 
?’,T,T’) 
a 
ar 
a 
+ GI(?, ?;f’,r,r’)-Q(~--r’), 
= Q(T-7’) H + - GI(?, ?’,T,T’) + G1 (7, 
?’,T,T’)~( T-T’). 
( 
We have used the relation 
(19.302) 
d 
d r  
--S(T-T’) 
= 6( 7 4 ) .  
Considering the fact t,hat G1 satisfies Equation (19.296), we obtain 
( H  + -$) G(?, 
?j,T,+) 
= G~ (7, 
? / , T , ~ / ) s (  7-r’). 
(19.303) 
Because the Dirac-delta function is zero except at T=T’, we only need the 
value of G1 at r = T’, which is equal to S3( ? - 7’); 
thus we can write 
Equation (19.303) as 
H + - G(?, ?“,T,T’) = J3(?;’ - ?’)a( 
7-70. 
(19.304) 
( 3 
From here we see that the Green’s function for Equation (19.294) is 
G ( 7 ,  T”,T,T’) 
= GI(?, ?’,T,T’)-S( 
T-7’) 
(19.305) 

TIME-DEPENDENT GREEN’S FUNCTIONS 
615 
and the general solution of Equation (19.294) is now written as 
19.2.7 Green’s Function for the Schrdinger Equation for Free Particles 
To write the Green’s function for the Schrdinger equation for a free particle, 
we can use the similarity between the Schrdinger and the diffusion equations. 
Making the replacement 7 + - 
in Equation (19.288) gives us the propagator 
for a free particle as 
iiit . 
2m 
Now the solution of the Schrodinger equation 
h2 a2 
d 
2m 8x2 @(z,t) 
= ih-Q(z,t), 
at 
(19.307) 
(19.308) 
with the initial condition @ ( d , O ) ,  can he written as 
@(z,t) 
= 
G, (2, 2’, t)@(d,O)dz’. 
(19.309) 
J 
19.2.8 Green’s Function for the Schrdinger Equation in the Presence 
of Interactions 
When a particle is moving under the influence of a potential V(z), 
the Schrodinger 
equation becomes 
2m d 
2m 
a2 
3 2 2  
2ii at 
ii2 
@(z, t )  + --@(z, 
t )  = --V(z)@(z, 
t), 
-- 
(19.310) 
For an arbitrary initial time t’, Green’s function is given as 
G(Z,Z’, t,t’) = G,(z, z’,t,t’)8( t-t’) 
(19.311) 
and the solution becomes 

616 
GREEN5 FUNCTIONS 
19.2.9 Second-Order Time-Dependent Green’s Functions 
Most of the frequently encountered time-dependent equations with second- 
order time dependence can be written as 
[. + $1 
* ( 7 , 7 )  = 0, 
(19.313) 
where r is a timelike variable and H is a linear differential operator inde- 
pendent of T. We again assume that H has a complete set of orthonormal 
eigenfunctions satisfying 
H+n( 7) 
= An& (*) 
7 
(19.314) 
where A, 
are the eigenvalues. We expand *(7,7) 
in terms of this complete 
and orthonormal set as 
*(T+,T) = C An(T)+nF), 
(19.315) 
where the coefficients A,(T) carry the 7 dependence. Substituting this in 
Equation (19.313) we obtain 
n 
(19.316) 
Because 4, 
are linearly independent, we set the quantity inside the square 
brackets to zero to obtain the differential equation that the coefficients An(7) 
satisfy as 
 an(^) + XnAn(7) = 0. 
(19.317) 
The solution of this equation can be written immediately as 
An (7) = uneiV%T 
+ bne-i&T. 
(19.318) 
Substituting these coefficients into Equation (19.315), we write Q(?,T) 
as 
(19.319) 
n 
where the integration constants a, and b, are now to be determined from the 
initial conditions. Assuming that e(?’,O) and @(?,O) 
are given, we write 
and 
@(7,0) = Z C J X n [ a n - b n ] & ( T ) .  
n 
(19.321) 

TIME-DEPENDEN T GREEN’S FUNCTIONS 
617 
Using the orthogonality relation [Eq. (19.256)] of &(?) 
we obtain two rela- 
tions between a, and b, as 
[a, + b,] = 1 (b3;i;)’)@(?;f’,0)d3?;f’ 
(19.322) 
and 
[a, - b,] = -/(bp+’)i~(?’,O)d~?’. 
-2 6 
Solving these for a, and b, we obtain the coefficients as 
(19.323) 
(19.324) 
and 
We write this as 
(19.327) 
and define two functions G2 and G 2  as 
and 
(19.329) 

618 
GREENS FUNCTIONS 
Among these functions G2 acts on @(?.’,O) 
and G 2  acts on 6(?’,0). They 
both satisfy homogeneous equation 
G2(?, ?’,T) } =o. 
(19.330) 
Thus 9 ( 7 , r )  is a solution of the differential equation (19.313). Note G2 and 
G2 are related to each other by 
[,,+GI 
{ G,(7, 7 , r )  
G2(?, ?,T) = ZGz(7, 
?.’,r). 
(19.331) 
Hence we can obtain G 2 ( 7 ,  T”,r) from e2(?., ?,T) 
by differentiation with 
respect to 7. Using Equation (19.328) and the completeness relation we can 
write 
d r  
G2(7,7’,0) = x(bn(?)4i(7’) 
= b3(? - 7’). 
(19.332) 
n 
Using the completeness relation (19.257) in Equation (19.326), one can easily 
check that @(?, T )  satisfies the initial conditions. 
- 
For an arbitrary initial time T’, ly(?”,r), Gz and G2 are written as 
(19.333) 
and 
(19.334) 
d -  
G 2 ( 7 ,  ?’,T,T’) = -G2(F, ?’,T,T’) 
dt 
19.2.10 
An important example of the second-order timedependent equations is the 
scalar wave equation: 
Propagators for the Scalar Wave Equation 
09(?,“,t) = 0, 
(19.335) 

TIME-DEPENDENT GREEN'S FUNCTIONS 
619 
where the wave (d'Alembert) operator is defined as 
Comparing with Equation (19.313) we have 
Considering a rectangular region with the dimensions (151, L 2 ,  L 3 )  and using 
periodic boundary conditions, eigenfunctions and the eigenvalues of the H 
operator are written as 
(19.336) 
and 
2nn3 
L 3  
k --. 
, ni = finteger and # 0. (19.337) 
27rnl 
2 ~ n 2  
kx = - 
> h=r 
2
-
 
L1 
Eigenvalues satisfy the relation 
Xnl,n2,7L3 = kE + k i  + lc:. 
(19.338) 
Using these eigenfunctions we can construct G2(?', ?',T) as 
G,(T, T',7) 
(19.339) 
'1. 
-- 
00 
sin (J-) 
T
~
~
~
,
(
~
-
~
 
' ) e i k v  ( g - y ' ) e i k z  ( 2 -  z 
l c  
- 
'1'2'3 
nx,nz,n3 Jm 
We now consider the continuum limit, where we make the replacements 
(19.340) 
(19.341) 
(19.342) 

620 
GREEN 5 FUNCTIONS 
Thus G 2  (?, T", r) becomes 
where 
F= (7 - 7'). 
(19.344) 
Defining a wave vector k = (kx, 
ky, k z ) ,  and using polar coordinates we can 
write 
-+ 
(19.345) 
Choosing the direction of the 7 
vector along the z-axis we write 
(19.346) 
--$ 
k . y=kpcos 0k 
(19.347) 
After taking the e k  and 4 k  integrals G2(?, ?',r) becomes 
dk sin k r  . sin kp 
- 
- 
(19.348) 
- 
- 
dk[cosk ( p  - r )  - cosk ( p +  r)]. 
8 T P  -m 
Using one of the definitions of the Dirac-delta function, that is, 
we can write G~(T+, 
T",T) as 
Going back to our original variables, G 2 ( 7 ,  ?,t) becomes 

TIME-DEPENDENT GREEN’S FUNCTIONS 
621 
[6(17;’ - 7’1 
- ct) - S( 17;’ - 7’1 
+ d)] . 
1 
4 ~ 1 7 -  ?’I 
G 2 ( 7 , 7 ; ” , t )  = 
(19.351) 
We write this for an arbitrary initial time t’ to obtain the final form of the 
propagator as 
G 2 ( 7 ,  ?’,t,t’) 
(19.352) 
[S (17 
- 7’1 
- c (t - t’)) - 6 
(I? 
- 7’1 
+ c (t - t’))] . 
1 
4 ~ 1 7 -  7’1 
- 
- 
19.2.11 
In the presence of a source, p ( 7 ,  T ) ,  Equation (19.313) becomes 
Advanced and Retarded Green’s Functions 
To solve this equation we need a Green’s function satisfying the equation 
(19.354) 
However, the propagators G2( 7, 
7;’’,~, 
7’) and G2(?, 7’,7, 
7’) both satisfy 
a 2  
( H + B , ~ )  G(?”,?;)’,T,T’)=S3(?-7)6(7--’). 
(19.355) 
Guided by our experience in G I ,  to find the Green’s function we start by 
introducing a discontinuity in either G2 or G2 as 
~ ~ ( 7 ,  
T + ’ , ~ ,  = G,(T, ?;fl,T,T’)e (7 - 7’). 
(19.356) 
Gc stands for G2 or G 2 ,  while the subscript R will be explained later. Oper- 
ating on GR( 7, 
7’,r, 7’) 
with 
(19.357) 

622 
GREEN’S FUNCTIONS 
Since Gz(?”, ?S’,T, 7 ’ )  and G2(?, 
?,7,7’) both satisfy 
[. + $1 
G, = 0, 
(19.358) 
this becomes 
a 2  
a7 
+ G,+ 
(T - T ’ ) .  
(19.359) 
Using the fact that the derivative of a step function is a Wac-delta function, 
(19.360) 
a 
ar 
-0 
(T - 7’) = 6 (T - 7’) , 
we can write 
(19.361) 
a 
a7 
= 26(7-~’)-Gc(7, 
~ ’ , T , T ’ ) +  
Using the following properties of the Dirac-delta function : 
(19.362) 
a 
aT 
6 
(T - 7’) -G<(Tf, 7;”,T, 7’) 
and 
[ $6 
(T - T ’ ) ]  G, (?, 
?’,T, T ’ )  
(19.363) 
we can write Equation (19.361) as 
(19.364) 
If we take G2 as G,, the right-hand side becomes zero; thus it is not useful 
for our purposes. However, taking G 2  we find 
[ H +  f] G1~(7,7’,7,T’) 
= s ( T - T ‘ ) s 3 ( ? S - ? ’ ) ,  
(19.365) 

TIME-DEPENDENT GREEN’S FUNCTIONS 
623 
which means that the Green’s function we need is 
GR(?, T+’,T,T’) = Gz(?, 
? ’ , T , T ’ ) ~  (r - T ’ ) .  
(19.366) 
The general solution can now be expressed as 
@R(7is1T) 
= qo(?,T) + 1 ~~T’JI:, 
dT’Gp(7, +,T, 
+ ) p ( ~ ’ ,  
7’). 
(19.367) 
There is also another choice for the Green’s function, which is given as 
GA(?,T+’,T, T ’ )  = - G 2 ( T ,  T‘,T, 
~ ’ ) 6  
(7’ - 7 ) .  
(19.368) 
Following similar steps: 
= -6 (7’ - T )  HG2 - 
?‘,T, 7‘)6 (7’ - T ) ]  
d -  
- 
3 2  
d r  
dr2 
(7’ - T )  -G2 - G2-6 
(7’ - T )  
= - [$&‘.I 
$6 (r’ - 7) = -G2 
-6 
(7’ - T )  
[:T 
- ] iJ”,’ 
1 
= [ -G2(7, 7 ’ , T ,  7’) 5 (7’ - T )  
a 
d r  
we see that GA (?, ?’,r, 7’) also satisfies the defining equation for the Green’s 
function as 
, T , T ’ ) = ~ ( T - ~ ‘ ) S ~ ( ~ - ~ ’ ) .  (19.369) 
Now the general solution of Equation (19.353) can be written as 
From Equation (19.367) it is seen the solution @ B ( ~ , T )  
is determined by the 
past behavior of the source, that is, with source times 7’ < T, while @~(7’,r) 
is determined by the behavior of the source in the future, that is, with source 
times 7’ > T. We borrowed the subscripts from relativity, where R and A 
stand for the “retarded” and the “advanced” solutions, respectively. These 
terms acquire their true meaning with the relativistic wave equation discussed 
in the next section. 

624 
GREEN’S FUNCTIONS 
19.2.12 
Advanced and Retarded Green’s Functions for the Scalar Wave 
Equation 
In the presence of sources or sinks the scalar wave equation is given as 
(19.371) 
We have already found the propagator G 2  for the scalar wave equation as 
G:2(7, 7’,t,t’) 
(19.372) 
[6([7 - 7’1 
- c ( t  -t’)) -a([?” - 7’1 
+ c(t - t’))]. 
1 
4x17- 7’1 
- 
- 
Using Equation (19.366) we now write the Green’s function for t > t’ as 
GR (7, 
7 ’ , t ,  t’) = [&(IT- 
T + ’ I - c ( t - t ’ ) ) - S ( p + -  
7 ’ \ + c ( t - t ’ ) ) ]  0(t - t’). 
4x17- 7’1 
For t < t’ the Green’s function is 
GR = 0. 
(19.373) 
For t > t’ the argument of the second Dirac-delta function never vanishes; 
thus the Green’s function becomes 
s [I 7 - 7” 
- c (t - t’)] . 
(19.374) 
1 
4x17”- 7’1 
G R ( ~ ,  
7”’,t, t’) = 
Now the general solution with this Green’s function is expressed as 
where WO(?;’,T) is the solution of the homogeneous equation. Taking the t‘ 
integral we find 
where 
(19.376) 
(19.377) 
means that the solution 9 R  at ( 7 , t )  is found by using the values of the source 
p(?’,t’) evaluated at the retarded times: 
(19.378) 

TIME-DEPENDEN T GREENS FUNCTIONS 
625 
We show the source at the retarded times as 
(19.379) 
and the solution found by using [p(T”,t’)lR is shown as @~(?,t). 
The phys- 
ical interpretation of this solution is that whatever happens at the source 
point shows its effect at the field point later by the amount of time that sig- 
nals (light) take to travel from the source to the field point. In other words, 
causes precede their effects. 
Retarded solutions are of basic importance in electrodynamics, where the 
scalar potential (a( 7, t), and the vector potential A (7, 
t )  satisfy the equa- 
tions 
-+ 
[P 
- 
@(T,t) 
= -4ap(?,t), 
(19.380) 
(19.381) 
where p ( 7 , t )  and T(?,t) stand for the charge and the current densities, 
respectively. 
In search of a Green’s function for Equation (19.371) we have added a dis- 
continuity to & as Gz(7, ?’,T, T’)Q (T - T’). However, there is also another 
alternative, where we take 
GA(?;I, ?,T, 
T ’ )  = -Gz(?, 
? ’ , T , T ’ ) ~  (T’ - T ) .  
(19.382) 
Solution of the wave equation with this Green’s function is now given as 
(19.383) 
In this solution A stands for advanced times: that is, t’ = t + 17 - 7’1 
/c. In 
other words, whatever “happens” at the source point shows its effect at the 
field point before its happening by the amount of time 17 - 7’1 
/c, which is 
again equal to the amount of time that light takes to travel from the source 
to the field point. In summary, in advanced solutions effects precede their 
causw. 
We conclude this section by saying that the wave equation (19.371) is 
covariant with c standing for the speed of light; hence the two solutions 
@~(?;t,t), 
and @A(?$) 
are both legitimate solutions of the relativistic wave 
equation. Thus the general solution is in principle their linear combination: 

626 
GREEN’S FUNCTIONS 
However, Because we have no evidence of a case where causes precede their 
effects, as a boundary condition we set c2 to zero, and take the retarded solu- 
tion as the physically meaningful solution. This is also called the principle 
of causality. 
Problems 
19.1 Given the Bessel equation 
d 
dx [xg] 
+ (kx - $) y(x) = 0 
and its general solution 
y(x) = AoJrn(x) + BoN?z(x), 
find the Green’s function satisfying the boundary conditions 
y(0) = 0 and y’(a) = 0. 
19.2 
y(L) = 0 we have found the Green’s function as 
For the operator L = &/dx2 and with the boundary conditions y(0) = 
X 
G(z, d) 
= (x - z’) B(x - d )  - - ( L  - d)] 
. 
[ 
L 
Show that the trigonometric Fourier expansion of this is 
G(z, x’) = -- 
2 
sin knx sin knx’ 
L n 
k: 
19.3 Show that the Green’s function for the differential operator 
with the boundary conditions 
y(0) = 0 and y(L) = 0. 
is given as 
sin h x s i n  h ( x ’  - L) 
sin b x ’  sin ~co(x - L )  
x < 2’ 
x > x’ 
{ 
1 
G(x, d) 
= 
ko sin koL 
Show that this is equivalent to the eigenvalue expansion 
. n7rx . n7rx‘ 
O0 sin ~ 
sin ~ 
2 
L 
G ( z , d )  = - C 
L n=l 
g -(n7r/L)2 
‘ 

PROBLEMS 
627 
19.4 
tion Ly(z) = ~ ( I c ) ,  
where .€ is the Sturm-Liouville operator 
Single-point boundary condition: Consider the differential equa- 
Construct the Green’s function satisfying the singlepoint boundary conditions 
Y ( ~ o )  = YO and Y’(ZO) = Y& 
Hint: First write the Green’s function as 
G(z, z’) = Ayl (z) + Bya(z), z > x’, 
where yl(z) and y2(2) are two linearly independent solutions of Ly(z) = 0. 
Because the Green’s function is continuous at 2 = Z’ and its derivative has a 
discontinuity of magnitude l / p ( z )  at 1c = J:’, find the constants A, B, C, and 
I), thus obtaining the Green’s function as 
G(z, z’) = CYI (z) + Dy2(~), J: < z’, 
where W[yl(z),92(z)] is the Wronskian defined as W[91,y2] = ylya - y2y/i. 
Now impose the single-point boundary conditions 
G(z0, d) 
= 0 and G’(z0,z’) = 0 
to show that C = D = 0. Finally show that the differential equation 
.Y(Z) 
= 4 b )  
with the singlepoint boundary conditions ~(zo) 
= 90 and ~ ’ ( z o )  = y; 
is 
equivalent to the integral equation 
Y( Z ) = ClYl(Z) + C2Y2(Z) + 
19.5 
Consider the differential operator 
For the singlepoint boundary conditions 
~ ( 0 )  
= zo and k(0) = 0. 
Show that the Green’s function is given as 
sin wo(t - t’) 
WO 
G(t, t’) = 
6(t - t’) 

628 
GREEN'S FUNCTIONS 
and write the solution for %(t) + ~&?(t) 
= F(t). 
19.6 
Find a Green's function for the Sturm-Liouville operator 
d3 
d2 
d 
= . 3 ( 4 2  + a2(x)- dx2 + @(X)- d x  + ao(x); 
satisfying the boundary conditions 
in the interval [a, 
b]. 
19.7 
Find the Green's function for the differential equation 
with the boundary conditions 
y(0) = y'(0) = y( 1) = y'( 1) = 0. 
19.8 For the scalar wave equation 
take the Green's function as 
GA(?il, ?"',T, 7') = -G2(?, 
?',T, T')O (T' - T )  
and show that the solution is given as 
What does [p(?;fr, tr)IA stand for? Discuss your answer. (Read Chapter 28 of 
The Feynman Lectures on Physics.) 
19.9 
Consider the partial differential equation 
with the boundary conditions 
Y(0, t )  = 0, Y(L7 4 = Yo. 
If y ( x ,  0) represents the initial solution, find the solution at subsequent times. 

PROBLEMS 
629 
19.10 
Using the Green’s function technique solve the differential equation 
-Cy(x) = -AXY(X>, x E [O, LI, 
where 
d 
d 
n‘ 
dx dx 
~Ey(x) 
= [-(.-I 
- s] 
y(x), n = constant, 
with the boundary conditions 
y(0) = 0 and y(L) = 0. 
What is the solution of Ly = -Ax” with the above boundaly conditions? 
19.11 Find the Green’s function for the problem 
= F(x), 
E 10, LI, 
where 
d
d
 
dx dx 
L = -((.-). 
Use the boundary conditions 
y(0) = finite and y(L) = 0. 
Write Green’s theorem [Eq. (19.162)] in one dimension. Does the surface 
term in (19.164) vanish? 
19.12 Given the differential equation 
y”(t) - 3y’(t) + 2y(t) = 2e-t 
and the boundary conditions y(0) = 2, y’(0) = -1. 
d2 
d 
dx2 
dx 
i) Defining the operator in (19.1) as L = - 
- 3- + 2 find the solution 
ii) Confirm your answer by solving the above problem using the Laplace 
iii) Using a different definition for L show that you get the same answer. 
by using the Green’s function method. 
trans form technique . 
19.13 Consider the wave equation 
-_--- I d2y - F(x, t )  with y(0, t) = y(L, t )  = 0. 
d2y 
8x2 
c2 at2 
Find the Green’s functions satisfying 
- 6(x - x’)6(t - t’) 
d2G 
1 d2G 
ax2 
c2 dt2 
--_-- 

630 
GREEN 5 FUNCTIONS 
and the initial conditions: 
i) 
ii) 
19.14 Consider the partial differential equation 
---+ 
T%(T+) = F(?-). 
Show that the Green's function for the inside of a sphere satisfying the bound- 
ary conditions that G(?", ?"') be finite at the origin and zero on the surface 
T = a is given as 
where 
19.15 Consider the Helmholtz equation, 
v%(?) + k;@(?") = F F ) ,  
for the forced oscillations of a twcxlimensional circular membrane (drumhead) 
with radius a, and with the boundary conditions 
e(0) = finite, and @(a) = 0. 
Show that the Green's function obeying 
q2G(?, 7') 
+ k:G(?", ?') = 6(? - ?') 
is given as 
03 
G ( 7 ,  ?"') = C cosm(Q - 6') x 
m=O 

PROBLEMS 
631 
where 
2 :  
m = 0 
1 :  
rn= 1,2,3,.. 
Hint: use 
6(8 - 8’), 
+I 
- 6(r-r’) 
S ( 7 -  r )-- 
r 
and separate the Green’s function as 
One also needs the identity 
and E ,  is introduced when we combined the f r n  terms to get cm m(S - S’). 
19.16 In the previous forced drumhead problem (19.15), first find the a p  
propnate eigenfunctions and then show that the Green’s function can also be 
written as 
where the normalization constant N,, 
is given as 
Compare the two results. 
19.17 
Consider the differential equation 
L @ ( 7 )  
= F(+) 
L = 3. 
Lp(T))?] + q(r). 
with the operator 
Show that the solution 
a(?’) = /// F ( 7 ) G ( T ) , 7 ’ ) d 3 7  
V 
+ //Iv 
[@(T))LG(7,+’) - G(7,7’)-C@(7’)] 
d 3 7  

632 
GREEN’S FUNCTIONS 
can be expressed as 
@(7) 
= Iv F ( 7 ‘ ) G ( 7 , 7 ‘ ) d 3 7 ’  
+ f ~ ( 7 ’ )  
F(Ff)?G(7,7’) - G ( 7 , 7 ’ ) 3 @ ( 7 ’ ) ]  . fids’, 
S 
where 5 is the outward normal to the surface S bounding V .  
19.18 
equation 
Find the Green’s function G(p, #, p’, #’) for the two-dimensional Helmholtz 
for the full region outside a cylindrical surface p = a, which is appropriate for 
the following boundary conditions: 
i) @ is specified everywhere on p = a. 
,i “ P  
./is 
ii) As p -+ 00, 9 -+ -f(d) 
(outgoing cylindrical wave). Note that @ is 
independent of z. 
19.19 
tion 
Find the Green’s function for the three-dimensional Helmholtz equa- 
[ P + K 2 ] @ ( 7 ) = 0  
for the region bounded by two spheres of radii a and b (a > b) and which 
is appropriate for the boundary condition where 9(?) is specified on the 
spheres of radius r = a and r = b. 
19.20 Find the Green’s function for the operator 
with the boundary conditions y(0) = 0 and y(L) = y ~ .  
19.21 In Example 19.2 show that the solution for small oscillations is 
sin wot 
sin wot 1 
B = 8,-. 
Show that this result satisfies the integral equation (19.61) in the small oscil- 
lations limit. 

20 
GREEN'S FUNCTIONS 
and PATH INTEGRALS 
In 1827 Brown investigates the random motions of pollen suspended in wa- 
ter under a microscope. The irregular movements of the pollen particles are 
due to their random collisions with the water molecules. Later it becomes 
clear that many small objects interacting randomly with their environment 
behave the same way. Today this motion is known as Brownian motion and 
forms the prototype of many different phenomena in diffusion, colloid chem- 
istry, polymer physics, quantum mechanics, and finance. During the years 
1920- 1930 Wiener approaches Brownian motion in terms of path integrals. 
This opens up a whole new avenue in the study of many classical systems. 
In 1948 Feynman gives a new formulation of quantum mechanics in terms of 
path integrals. In addition to the existing Schrodinger and Heisenberg formu- 
lations, this new approach not only makes the connectlion between quantum 
and classical physics clearer, but also leads to many interesting applications in 
field theory. In this Chapter we introduce the basic features of this technique, 
which has many interesting existing applications and tremendous potential 
for future uses. 
20.1 BROWNIAN MOTION AND THE DIFFUSION PROBLEM 
Starting with the principle of conservation of matter, 
equation as 
we can write the diffusion 
(20.1) 
633 

634 
GREEN’S FUNCTIONS AND PATH INTEGRALS 
where p ( T ‘ , t )  is the density of the diffusing material and D is the diffusion 
constant, which depends on the characteristics of the medium. Because the 
diffusion process is also many particles undergoing Brownian motion at the 
same time, division of p ( 7 , t )  by the total number of particles gives the 
probability, w(+,t), of finding a particle at 7 
and t as 
(20.2) 
1 
N 
w ( 7 , t )  = - p ( 7 , t ) .  
Naturally, w ( 7 ,  t )  also satisfies the diffusion equation: 
(20.3) 
For a particle starting its motion from 7 
= 0, we have to solve Equation 
(20.3) with the initial condition 
l i m w ( 7 , t )  + S(?). 
(20.4) 
t-0 
In one dimension we write Equation (20.3) as 
(20.5) 
and by using the Fourier transform technique we can obtain its solution as 
1 
Z U ( X , t )  = 
~ 
{ -& } . 
(20.6) 
Note that, consistent with the probability interpretation, W(X, t) is always 
positive. Because it is certain that the particle is somewhere in the interval 
(-co, co), 
W ( X ,  t )  also satisfies the normalization condition 
= 1. 
(20.7) 
For a particle starting its motion from an arbitrary point, (zo,t~), 
we write 
the probability distribution as 
where W ( X ,  
t ,  20, t o )  is the solution of 
(20.9) 

WIENER PATH INTEGRAL APPROACH TO BROWNIAN MOTION 
635 
satisfying the initial condition 
lim W ( X ,  
t, zo, to) -+ S(X - ZO) 
(20.10) 
t-to 
and the normalization condition 
&W(z, t, X o ,  to) = 1. 
(20.11) 
.la_ 
From our discussion of Green’s functions in Chapter 19 we recall that 
W ( X ,  
t, XO, to) is also the propagator of the operator 
(20.12) 
Thus, given the probability at some initial point and time, w(z0, to), we can 
find the probability at subsequent times, w(z, t), by using W(z, 
t, so, to) as 
00 
w(z,t) 
= 
d50W(z,t)X~,to)w(20,tO)) t > to. 
(20.13) 
s, 
L 
Combination of propagators gives us the Einstein-Smoluchowski-Kolmogorov- 
Chapman (ESKC) equation: 
00 
W ( X , ~ , X O , ~ O )  
= 
&’W(X,t,z’,t’)W(z’,t’,ico,to), 
t > t’ >to. 
(20.14) 
The significance of this equation is that it gives the causal connection of events 
in Brownian motion as in the Huygens-Fresnel equation. 
20.2 
WIENER PATH INTEGRAL APPROACH TO BROWNIAN 
MOTION 
In Equation (20.13) we have seen how to find the probability of finding a 
particle at (z,t) from the probability at (zo,to) by using the propagator 
W(z, 
t, XO, to). We now divide the interval between to and t into N + 1 equal 
segments: 
At, = ti - ti-1 
t - to 
N-i-1’ 
- 
- 
(20.15) 
which is covered by the particle in N steps. The propagator of each step is 
given as 
W ( X i ,  ti, 2i-1, t i - 1 )  = 
1 
}. (20.16) 
J47rD(ti -ti-,) 
4D(ti - ti-1) 

636 
GREEN’S FUNCTIONS AND PATH INTEGRALS 
fig. 20.1 Paths C[zo,o,to;z,t] 
for the pinned Wiener measure 
Assuming that each step is taken independently, we combine propagators N 
times by using the ESKC relation to get the propagator that takes us from 
(20, to) to (z, t )  in a single step as 
This equation is valid for N > 0. Assuming that it is also valid in the limit as 
N -+ 
00, that, is as At; -+ 0, we write 
W(2, t, 20, to) = 
(20.18) 
Here, T is a time parameter (Fig. 20.1) introduced to parametrize the paths 
as ~ ( 7 ) .  
We can also write W(z, t, zo,to) in short as 
W(z,t,zc),to) 
= Njexp{-& 
p ( T ) d T }  i)z(7), 
(20.20) 

WIENER PATH INTEGRAL APPROACH TO BROWNIAN MOTION 
637 
where N is a normalization constant and Dx(T) indicates that the integral 
should be taken over all paths starting from (z0,to) and end at (z,t). This 
expression can also be written as 
W(z, t, zo,to) = 1 
&&), 
(20.2 1) 
C[zo.to;~,tl 
where d,z(~) is called the Wiener measure. Because dwz(r) 
is the measure 
for all paths starting from (zo, to) and ending at (z, t), it is called the pinned 
(conditional) Wiener measure (Fig. 20.1). 
Summary: For a particle starting its motion from (zo,to), the propagator 
W(z, t, zo, to) is given as 
This satisfies the differential equation 
with the initial condition limt4to W(z,t, 
zo, to) + b(z - zo). 
In terms of the Wiener path integral the propagator W(z, t, 20, to) is 
also expressed as 
W ( z ,  
t, 20, to) = .i’ 
d W 4 7 ) .  
(20.24) 
C [ ~ O , t O ; Z . J l  
The measure of this integral is 
Because the integral is taken over all continuous paths from (20, to) to 
(3, t), which are shown as C[zo, to; z, t], this measure is also called the 
pinned Wiener measure (Fig. 20.1). 
For a particle starting from (zo,to) the probability of finding it in the 
interval Ax at time t is given by 
(20.26) 
In this integral, because the position of the particle at time t is not fixed, 
d , z ( ~ )  is called the unpinned (or unconditional) Wiener measure. At 

638 
GREEN’S FUNCTIONS AND PATH INTEGRALS 
Fig. 20.2 Paths C[zo,lo;t] 
for the unpinned Wiener measure 
time t, because it is certain that the particle is somewhere in the interval 
z E [-oo,oo], 
we write (Fig. 20.2) 
The average of a functional, F[z(t)], found over all paths C[zo, to; t] at time 
t is given by the formula 
In terms of the Wiener measure we can express the ESKC relation as 
(20.28) 

THE FEYNMAN-KAC FORMULA AND THE PERTURBATIVESOLUTION OF THE BLOCH EQUATION 
639 
20.3 T H E  FEYNMAN-KAC FORMULA AND THE PERTURBATIVE 
SOLUTION OF THE BLOCH EQUATION 
We have seen that the propagator of the diffusion equation, 
aw(z,t) 
a2w(z, t )  = 0, 
-- at 
8x2 
(20.30) 
can be expressed as a path integral [Fq. (20.24)]. However, when we have a 
closed expression as in Equation (20.22), it is not clear what advantage this 
new representation has. In this section we study the diffusion equation in the 
presence of interactions, where the advantages of the path integral approach 
begin to appear. In the presence of a potential V(z), the diffusion equation 
can be written as 
aw(x, t )  
82w(z, t) = -V(z, t)w(z, t). 
ax2 
-- at 
(20.3 1) 
We now need a Green’s function, WD, 
that satisfies the inhomogeneous equa- 
tion 
- 
awD(Z, t, Z‘, 
t’) 
at 
z’)6(t - t’), 
(20.32) 
so that we can express the general solution of (20.31) as 
~ ( 2 ,  
t )  = WO(X, t )  - 
W ~ ( Z ,  
t, z’, 
t’)V(z’, 
~’)w(z’, t’)&’dt’, 
(20.33) 
where wo(z, t )  is the solution of the homogeneous part of Equation (20.31), 
that is, Equation (20.5). We can construct WD(Z, 
t, z’, t’) by using the prop 
agator, W(z, t, z’, t’), that satisfies the homogeneous equation (Chapter 19) 
11 
dW(z,t,x’,t’) d2W(z,t,z’,t’) 
at 
a x 2  
- D  
= 0, 
(20.34) 
as 
WD(z,t,z’,t’) = W(z,t,Z’,t‘)e(t - t’). 
(20.35) 
Because the unknown function also appears under the integral sign, Equation 
(20.33) is still not the solution, that is, it is just the integral equation version 
of Equation (20.31). On the other hand, WB(Z, 
t, x’, t’), which satisfies 

640 
GREEN'S FUNCTIONS AND PATH INTEGRALS 
The first term on the right-hand side is the solution of the homogeneous 
equation [Eq. (20.34)], which is W. However, because t > to we could also 
write it as W,. 
A very useful formula called the Feynman-Kac formula (theorem) is 
given as 
1 
t 
W B ( Z ,  t, Zo, 0) = J' 
ci,z(T) exp { - 
ciTv[x(T), 
7-1 
. 
(20.38) 
This is a solution of Equation (20.36), which is also known as the Bloch 
equation, with the initial condition 
Iim WB(x, 
t, XI, t') = 6(z - d). 
(20.39) 
The Feynman-Kac theorem constitutes a very important step in the develop 
ment of path integrals. We leave its proof to the next section and continue 
by writing the path integral in Equation (20.38) as a Riemann sum: 
G[zo,O;z,t] 
t+ t' 
We have taken 
E = ti - ti-1 
t -to 
N f l '  
- 
-- 
(20.41) 
The first exponential factor in Equation (2.40) is the solution [&. (2.18)] of 
the homogeneous equation. After expanding the second exponential factor as 
(20.42) 
N 
. 
N
N
 
we integrate over the intermediate x variables and rearrange to obtain 
W B ( Z ,  t ,  xo, to) = W(x, t, xo, to) 
(20.43) 
j=1 

DERIVATION OF THE FEYNMAN-KAC FORMULA 
641 
In the limit as E -+ 0 we make the replacement E X ~  
-+ 
h”,tj. 
We also 
suppress the factors of factorials, (l/n!), because they are multiplied by E
~
,
 
which also goes to zero as E -+ 0. Besides, because times are ordered in 
Equation (20.43) as 
we can replace W with WD in the above equation and write WB as 
(20.44) 
Now WB(z,t,~o,tO) 
no longer appears on the right-hand side of this equa- 
tion. Thus it is the perturbative solution of Equation (20.37) by the itera- 
tion method. Note that W~(x,t,xo,to) 
satisfies the initial condition given in 
Equation (20.39). 
20.4 
DERIVATION OF THE FEYNMAN-KAC FORMULA 
We now show that the Feynman-Kac formula, 
is identical to the iterative solution to all orders of the following integral 
equation: 
which is equivalent to the differential equation 
with the initial condition given in Equation (20.39). 
We first show that the Feynman-Kac formula satisfies the ESKC [Eq. 
(20.14)] relation. Note that we write V[Z(T)] instead of V[Z(T),T] 
when there 

642 
GREEN'S FUNCTIONS AND PATH INTEGRALS 
(20.48) 
In this equation x, denotes the position at t, and x denotes the position at t. 
Because C[ZO, 0; x,, t,; z, t] denotes all paths starting from (xo,O), passing 
through (x,,t,) and then ending up at (x,t), 
we can write the right hand-side 
of the above equation as 
dwx(7) exp { - Lts d~v[z(~)]} (20.49) 
1: dxs ~xo,ox*,ts;x,tl 
(20.50) 
= W B ( Z ,  4 z0,O). 
(20.51) 
From here, we see that the Feynman-Kac formula satisfies the ESKC relation 
as 
00 
dx, W B  (z, t, zs, tS)WB ( x s ,  t s ,  2 0 , O )  = W B  
( 2 7 4  xo, 0). 
(20.52) 
With the help of Equations (20.21) and (20.22), we see that the Feynman- 
.I_, 
Kac formula satisfies the initial condition 
lim WB(x, t, xo, 0) + 6(z - zg) 
(20.53) 
t-0 
and the functional in the Feynman-Kac formula satisfies the equality 
(20.54) 
We can easily show that this is true by taking the derivative of both sides. 
Because this equality holds for all continuous paths x(s), we take the integral 
of both sides over the paths C[zo, 0; z, t] via the Wiener measure to get 
(20.55) 

INTERPRETATION OF v ( X )  IN THE BLOCH EQUATION 
643 
The first term on the right-hand side is the solution of the homogeneous part 
of Equation (20.36). Also, for t > 0, we can write WD(ZO,O,Z,~) 
instead of 
W(zo,O, 
z, t). Because the integral in the second term involves exponentially 
decaying terms, it converges. Thus we interchange the order of the integrals 
to write 
(20.56) 
where we have used the ESKC relation. We now substitute this result into 
Equation (20.55) and use Equation (20.45) to write 
= W D ( Z ,  t, zo, 0) 
(20.58) 
- 
dx’ It 
dt’WD(2, t, z’, t’)V(%’, t’)WB(%’, 
t’, 2 0 ,  o), 
-03 
thus proving the Feynman-Kac formula. Generalization to arbitrary initial 
time to is obvious. 
20.5 
INTERPRETATION OF V(z) IN THE BLOCH EQUATION 
We have seen that the solution of the Bloch equation 
with the initial condition 
WB(z,t,ZO,tO)lt=to = S(z - X o ) ,  
is given by the Feynman-Kac formula 
(20.60) 

644 
GREEN’S FUNCTIONS AND PATH INTEGRALS 
In these equations, even though V ( x )  is not exactly a potential, it is closely 
related to the external forces acting on the system. 
In fluid mechanics the probability distribution of a particle undergoing 
Brownian motion and under the influence of an external force satisfies the 
differential equation 
(20.62) 
where ?;I is the friction coefficient in the drag force, which is proportional to 
the velocity. In Equation (20.62), if we try a solution of the form 
- 
we obtain a differential equation to be solved for W(z, 
t; X O ,  to): 
where we have defined V ( x )  
as 
1 
1 d F ( x )  
V ( x )  = - - P ( Z )  
+ 
4q2D 
2?;1 dx 
(20.65) 
Using the Feynman-Kac formula as the solution of Equation (20.64), we can 
write the solution of Equation (20.62) as 
d w 4 7 )  exp { - 1; 
V[x(7)Id7} 
. 
(20.66) 
W ( z ,  
t; 20, to) = exp 
Using the Wiener measure, Equation (20.25), we write t.his equation as 
(20.67) 
Finally, using the equality 
(20.68) 

INTERPRETATION OF v(Z) IN THE BLOCH EQUATION 
645 
this becomes 
(20.69) 
(20.70) 
In the last equation we have defined 
D d F  
L[X(T)] = (j: - ;) 
f2-- 
77 dx 
(20.7 1) 
and used Equation (20.65). 
As we see from here, V(z) is not quite the potential, nor is L[z(r)] the 
Lagrangian. In the limit as D i 0 fluctuations in the Brownian motion 
disappear and the argument of the exponential function goes to infinity. Thus 
only the path satisfying the condition 
or 
(20.72) 
(20.73) 
contributes to the path integral in Equation (20.70). Comparing this with 
m, = -772 + F(z), 
(20.74) 
we see that it is the deterministic equation of motion of a particle with negli- 
gible mass, moving under the influence of an external force F ( x )  and a friction 
force -72 (Pathria, p. 463). 
When the diffusion constant differs from zero, the solution is given as the 
path integral 
(20.75) 
In this case all the continuous paths between (zo,to) and (z,t) will contribute 
to the integral. It is seen from equation Equation (20.75) that each path 
contributes to the propagator W(z, t, 20, to) with the weight factor 

646 
GREEN’S FUNCTIONS AND PATH INTEGRALS 
Naturally, the majority of the contribution comes from places where the paths 
with comparable weights cluster. These paths are the ones that make the 
functional in the exponential an extremum, that is, 
6 lot 
dTL[X(T)] = 0. 
(20.76) 
These paths are the solutions of the Euler-Lagrange equation: 
--P[ 
d L  
d L  1 4 .  
az 
d7 a(dz/dT) 
(20.77) 
At this point we remind the reader that L[E(T)] 
is not quite the Lagrangian 
of the particle undergoing Brownian motion. It is interesting that V(z) and 
L[z(T)] gain their true meaning only when we consider applications of path 
integrals to quantum mechanics. 
20.6 
METHODS OF CALCULATING PATH INTEGRALS 
We have obtained the propagator of 
dw(z,t) 
d2w(z,t) 
___- 
= -V(q t)m(z, t )  
at 
ax2 
(20.78) 
as 
(20.79) 
W ( z ,  
t; Ico, to) = L i r  
In term of the Wiener measure this can also be written as 
where d,z(~) is defined as 
The average of a functional F [ ~ ( T ) ]  
over the paths C[ZO, 
to; z, t] is defined as 
(F[dT)l)c = 1 
FI4711 exP { - 1; V[z(.)lrl.} 
dw4T), (20.82) 
C[zo,to;r,tl 
where C[zo, to; 2, t] denotes all continuous paths starting from (20, to) and 
ending at ( 2 ,  t). Before we discuss techniques of evaluating path integrals, we 

METHODS OF CALCULATING PATH INTEGRALS 
647 
should talk about a technical problem that exists in Equation (20.80). In this 
expression, even though all the paths in C[ZO, to; X, t] are continuous, because 
of the nature of the Brownian motion they zig zag. The average distance 
squared covered by a Brown particle is given as 
oc) 
(2) 
= S _ _ m ( z , l ) 2 d x  a t. 
(20.83) 
From here we find the average distance covered during time t as 
which gives the velocity of the particle at any point as 
4 
lim - 
-+ 00. 
t i 0  t 
(20.84) 
(20.85) 
Thus j: appearing in the propagator [Eq. (20.79)] is actually undefined for all t 
values. However, the integrals in Equations (20.80) and (20.81) are convergent 
for V ( z )  2 c, where c is some constant. In this expression W(Z, t, XO, to) is 
always positive and thus consistent with its probability interpretation and 
satisfies the ESKC relation [Eq. (20.14)], and the normalization condition 
(20.86) 
In summary: If we look at the propagator [Eq. (20.80)] as a probability 
distribution, it is Equation (20.79) written as a path integral, evaluated over 
all Brown paths with a suitable weight factor depending on the potential V(z). 
The zig zag motion of the particles in Brownian motion is essential in 
the fluid exchange process of living cells. In fractal theory, paths of Brown 
particles are two-dimensional fractal curves. The possible connections between 
fractals, path integrals, and differintegrals are active areas of research. 
20.6.1 
Method of Time Slices 
Let us evaluate the path integral of the functional F/z(T)] with the Wiener 
measure. We slice a given path X(T) into N equal time intervals and approx- 
imate the path in each slice with a straight line I N ( T )  as 
l,v(ti) =  ti) = xi, 
i = 1,2,3, ..., N. 
(20.87) 
This means that for a given path, z(T), and a small number E we can always 
find a number N = N ( E )  independent of T such that 
147) - lN(7)l < E 
(20.88) 

648 
GREEN'S FUNCTIONS AND PATH INTEGRALS 
Fig. 20.3 Paths for the time slice method 
is true. Under these conditions for smooth functionals (Fig. 20.3) the inequal- 
ity 
IJ%(41 - W N ( 7 ) l I  < 
(20.89) 
is satisfied such that the limit lim,,o 
6(~) i 0 is true. Because all the infor- 
mation about E N ( T )  
is contained in the set 2 1  = ~ ( t l ) ,  
..., z~ = z ( t ~ ) ,  
we can 
also describe the functional F [ ~ N  
(7)] by 
which means that 
(20.91) 

METHODS OF CALCULATING PATH INTEGRALS 
649 
Because for N = 1, 2,3, ..., the function set FN(z~, 
2 2 ,  ..., X N )  forms a Cauchy 
set approaching F [ X ( ~ ) ] ,  
for a suitably chosen N we can use the integral 
1 
N 
1 
(Xi -xi-1)2 
40 i=l 
ti - ti- 1 
x exp { -- c 
to evaluate the path integral 
(20.92) 
(20.93) 
For a given E the difference between the two approaches can always be kept 
less than a small number, S(E), by choosing a suitable N ( E ) .  In this approach 
a Wiener path integral &jo,o;tl d,z(’r)F[x(7)] will be converted into an N- 
dimensional integral [Eq. (20.92)]. 
20.6.2 
We introduce this method by evaluating the path integral of a functional 
F[x(T)] = z(T), in the interval [O,t] via the unpinned Wiener measure. Let 
7 be any time in the interval [O,t]. Using Equation (20.28) and the ESKC 
relation, we can write the path integral ~ClxO,O;tl 
~,x(T)z(T) 
as 
Evaluating Path Integrals with the ESKC Relation 
(20.94) 

650 
GREEN’S FUNCTIONS AND PATH INTEGRALS 
From Equation (20.27), t,he value of the last integral is one. Finally, using 
Equations (20.24) and (20.22), we obtain 
= xo. 
(20.95) 
20.6.3 
We now evaluate the path integral we have found above for the functional 
F[x(-r)] = x(r) by using the formula [Eq. (20.17)]: 
Path Integrals by the Method of Finite Elements 
(20.96) 
(20.97) 
(20.98) 
= xo. 
(20.99) 
In this calculation we have assumed that 7 lies in the last time slice denoted 
by N + 1. Complicated functionals can be handled by Equation (20.92). 
20.6.4 
We have seen that the propagator of the Bloch equation in the presence of a 
nonzero diffusion constant is given as 
Path Integrals by the “Semiclassical” Method 
(20.100) 

METHODS OF CALCULATING PATH INTEGRALS 
651 
Naturally, the major contribution to this integral comes from the paths that 
satisfy the Euler-Lagrange equation 
(20.101) 
We show these “classical” paths by 2,(7). These paths also make the integral 
Ld7 an extremum, that is, 
6 Ldr=0. 
(20.102) 
s 
However, we should also remember that in the Bloch equation V ( x )  is not 
quite the potential and L is not the Lagrangian. Similarly, S~5d-r in Equa- 
tion (20.102) is not the action, S[Z(T)], 
of classical physics. These expressions 
gain their conventional meanings only when we apply path integrals to the 
Schrdinger equation. It is for this reason that we have used the term “semi- 
classical”. 
When the diffusion constant is much smaller than the functional S, that is, 
D / S  << 1, we write an approximate solution to Equation (20.100) as 
where $(t - to) is called the fluctuation factor. Even though methods 
of finding the fluctuation factor are beyond our scope (see Chaichian and 
Demichev), we give two examples for its appearance and evaluation. 
Example 20.1. Evaluation of &zo,O;z,tl d,z(r): To find the propagator 
W(z, 
t, z0,O) we write 
(20.104) 
and the Euler-Lagrange equation 
2Jr) = 0, Zc(O) = 20, z(t) = z, 
(20.105) 
with the solution 
7 
ZC(7-) = 20 + -(. - 20). 
(20.106) 
t 
We show the deviation from the classical path z,(T) as ~ ( r )  
so that we 
write X ( T )  = z,(7-) + ~ ( 7 ) .  
At the end points ~ ( r )  
satisfies (Fig. 20.4) 
q(0) = T ( t )  = 0. 
(20.107) 

652 
GREEN’S FUNCTIONS AND PATH INTEGRALS 
In terms of V ( r ) ,  W(x, 
t,xo, 
0) is given as 
W(x, t, XO, 0) = exp { -& J,’drx: } 
(20.108) 
We have to remember that the paths z(r) do not have to satisfy the 
Euler-Lagrange equation. Because we can write 
Equation (20.108) is 
w(x, t, xo, 0) = exp { --& 
drx: } 
(20.109) 
Because xc = (x - xo)/t is independent of r, we can evaluate the factor 
in front of the integral on the right-hand side as 
exp { -$ drx: } = exp { -40 
1 (x -x0)2 }. 
(20.110) 
Because the integral 
only depends on t, we show it as d(t) and write the propagator as 
The probability density interpretation of the propagator gives us the 
condition 
00 
dxW(x, t, XO,O) = 1, 
(20.113) 
.I_, 
which leads us to the 4(t) function as 
(20.114) 

METHODS OF CALCULATING PATH INTEGRALS 
653 
Fig. 20.4 Path and deviation in the “semiclassical” method 
Finally the propagator is obtained as 
1 
(x - .o)2 
W(Z, t, xo, 0) = 
~ eexp{- 
4Dt } 
(20.115) 
In this case the ‘‘semiclassical’’ method has given us the exact result. 
For more complicated cases we could use the method of time slices to 
find the factor 4(t - to). In this example we have also given an explicit 
derivation of Equation (20.22) for to = 0, from Equation (20.24). 
Example 20.2. Evaluation of p(t) by the method of time slices: Because 
our previous example is the prototype of many path integral applica- 
tions, we also evaluate the integral 
by using the method of time slices. We divide the interval [O,t] into 
( N  + 1) equal segments: 
tz - t i - 1  = E 
t 
- 
-- 
i =  1,2 ,..., ( N f l ) .  
(Nf 1) 
Now the integral (20.116) becomes 
(20.117) 
(20.118) 

654 
GREEN'S FUNCTIONS AND PATH INTEGRALS 
The argument of the exponential function (aside from a minus sign) is 
a quadratic of the form 
N
N
 
1 
4
0
~
 
A = -  
(20.119) 
' 2 
-1 
0 
0 
...... 
0 
-1 
2 
-1 
0 
...... 0 
0 
-1 
2 
-1 
0 
... 
0 
0 
... 
0 
-1 
2 
-1 
0 
0 
. . . . . .  
0 
-1 
2 
-1 
, o  . . . . . . . . .  
0 
-1 
2 
. 
(20.120) 
1 
Using the techniques of linear algebra we can evaluate the integral 
as (Problem 20.7) 
(20.122) 
Using the last column of A, we find a recursion relation that detAN 
satisfies: 
detAN = 2 d e t A ~ ~ 1  
-detAN-~. 
(20.123) 
For the first two values of N, det AN is found as 
det A1 = 2 
(20.124) 
and 
det A2 = 3. 
This can be generalized to N - 1 as 
det AN-1 = N. 
(20.125) 
(20.126) 

FEYNMAN PATH INTEGRAL FORMULATION OF QUANTUM MECHANICS 
655 
Using the recursion relation [Eq. (20.123)], this gives 
detAN = N f  1, 
(20.127) 
which leads us to the q5(t) function 
(20.128) 
Another way to calculate the integral in Equation (20.116) is to evaluate 
the 7 integrals one by one using the formula 
dqexp { -a(q - v ' ) ~  
- b(7 - q'')') 
1: 
ab 
a f b  
a f b  
(20.129) 
20.7 
FEYNMAN PATH INTEGRAL FORMULATION OF QUANTUM 
MECHANICS 
20.7.1 
We have seen that the propagator for a particle undergoing Brownian motion 
with its initial position at ($0, to) is given as 
Schriidinger Equation for a Free Particle 
This satisfies the diffusion equation 
with the initial condition limt,t, 
W(z, t, 50, to) + &(a: - xo). We have also 
seen that this propagator can also be written as a Wiener path integral: 
~ ( z , t , x o , t o )  
= J 
d W X ( 7 ) .  
(20.132) 
In this integral C[zo, to; z, t] denotes all continuous paths starting froni (20, to) 
and ending at (2, t), where ~,z(T) 
is called the Wiener measure and is given 
as 
C[zo,to;z,tl 
(20.133) 

656 
GREEN’S FUNCTIONS AND PATH INTEGRALS 
For a free particle of mass m Schrodinger’s equation is given as 
a*(z,t) - ifi 32*(z,t) 
dt 
2m 
8x2 
. 
For this equation, propagator K(z, t, z’, t’) satisfies the equation 
(20.134) 
(20.135) 
at 
2 m  
8x2 
Given the solution at (z’, t’), we can find the solution at another point (z, t )  
by using this propagator as 
aK(z, t, x’, t’) 
ifi d2K(z, t, z’, t’) 
- 
- 
- 
q x ,  
t) = 
K(z,t, z’, t’)*(z’, t’)drc’, (t > t’). 
(20.136) 
Because the diffusion equation becomes the Schrijdinger equation by the re- 
placement 
J 
iti 
D+- 2 m  ’ 
(20.137) 
we can immediately write the propagator of the Schrodinger equation by mak- 
ing the same replacement in Equation (20.130): 
}. 
(20.138) 
1 
m ( x  - ~
0
)
~
 
K ( z ,  t, z’, t’) = 
-(t 
-to) 
Even though this expression is mathematically correct, at this point we begin 
to encounter problems and differences between the two cases. For the diffusion 
phenomena, we have said that tshe solution of the diffusion equation gives the 
probability of finding a Brown particle at (z,t). Thus the propagator, 
is always positive and satisfies the normalization condition 
00 
dzW(z,t,zo,to) = 1. 
(20.140) 
For the Schriidinger equation the argument of the exponential function is pro- 
portional to i, which makes K ( z ,  t, x’, t’) oscillate violently; hence K ( z ,  t, d, 
t’) 
cannot be normalized. This is not too surprising, because the solutions of the 
Schrodinger equation are the probability amplitudes, which are more funda- 
mental, and thus carry more information than the probability density. In 
s, 

FEYNMAN PATH 1NTEGRAL FORMULATION OF QUANTUM MECHANICS 
657 
Fig. 20.5 Rotation by -$ in the complex-t plane 
quantum mechanics probability density, p(z, t), is obtained from the solutions 
of the Schrijdinger equation by 
p(x,t) = Wx,tP*(z,t) 
(20.141) 
= lWz,t)l2 , 
where p(z, t )  is now positive definite and a Gaussian, which can be normalized. 
Can we also write the propagator of the Schrodinger equation as a path 
integral? Making the D -+ - 
replacement in Equation (20.132) we get 
2h 
2m 
K(x,t,d,t/) = 
(20.142) 
where 
This definition was given first by Feynman, and d F x ( 7 )  is known as the Feyn- 
man measure. The problem in this definition is again the fact that the ar- 
gument of the exponential, which is responsible for the convergence of the 
integral, is proportional to i, and thus the exponential factor oscillates. An 
elegant solution to this problem comes from noting that the Schrijdinger equa- 
tion is analytic in the lower half complex t-plane. Thus we make a rotation by 
-7r/2 and write -it instead oft in the Schrodinger equation (Fig. 20.5). This 
reduces the Schrodinger equation to the diffusion equation with the diffusion 
constant D = fi/2m. Now the path integral in Equation (20.142) can be taken 
as a Wiener path integral, and then going back to real time, we can obtain 
the propagator of the Schrijdinger equation as Equation (20.138). 

658 
GREEN’S FUNCTIONS AND PATH INTEGRALS 
20.7.2 
In the presence of interactions the Schrdinger equation is given as 
Schrodinger Equation in the Presence of Interactions 
a*(x,t) 
ih a%(z,t) 
i 
- 
- -V(x)@(x,t) . 
~- 
- 
at 
2m 
8x2 
R 
(20.144) 
Making the transformation t --f -at, we obtain the Bloch equation as 
(20.145) 
Using the Feynman-Kac theorem, we write the propagator and then transform 
back to real time to get 
K(z,t,zo,to) = 1 
di.z(i)exp{-i/td7-V[z(7)]} 
t o  
(20.146) 
C[zo,to;z,tl 
or 
(20.147) 
This propagator was first given by Feynman. Using this propagator we can 
write the solution of the Schrodinger equation as 
@(z,t) = 
K(x,t,z’,t’)*(x’,t’)dx‘. 
(20.148) 
1 
Today the path integral formulation of quantum mechanics, after the Schrodinger 
and the Heisenberg formulations, has become the foundation of modern quan- 
tum mechanics. Writing the propagator [Eq. (20.147)] as 
we see that, in contrast to the Bloch equation, S[z(.)] 
in the propagator is 
the classical action: 
t 
5[47)1 = lo 
L[x(7T)ld7, 
(20.150) 
where L[z(7)] is the classical Lagrangian: 
(20.151) 

FEYNMAN PHASE SPACE PATH INTEGRAL 
659 
In the Feynman propagator (20.149) we should note that C[ZO, 
to; Z, t] in- 
cludes not only the paths that satisfy the Euler-Lagrange equation, but all 
the continuous paths that start from (zo,to) and end at (z,t). In theclassical 
limit, that is, 
fi -+ 0, 
(20.152) 
the exponential term 
(20.153) 
in the propagator oscillates violently. In this case the major contribution to 
the integral comes from the paths with comparable weights bunched together. 
These paths are naturally the ones that make S[z] an extremum, that is, the 
paths that satisfy the Euler-Lagrange equation 
d 
d L  
d L  
z (z) 
- dz = 0. 
(20.154) 
In most cases this extremum is a minimum (Morse and Feshbach, p. 281). 
As in the applications of path integrals to neural networks, sometimes a 
system can have more than one extremum. In such cases, a system could find 
itself in a local maximum or minimum. Is it then possible for such systems 
to reach the desired global minimum? If possible, how is this achieved and 
how long will it take? These are all very interesting questions and potential 
research topics, indicating that path integral formalism still has a long way 
to go. 
20.8 
The propagator of the Schrodinger equation expressed as a path integral, 
FEYNMAN PHASE SPACE PATH INTEGRAL 
is useful if the Lagrangian can be expressed as T - 
1/ 
of the Lagrangian of a free relativistic particle, 
I >  
1 
. 2  
-mx ( ~ ) - V ( Z )  d7 , 
2 
(20.155) 
However, as in the case 
(20.156) 
where the Lagrangian cannot be written as T - V, it is not much of a help. 
For this reason in 1951 Feynman introduced the phase space version of the 

660 
GREEN’S FUNCTIONS AND PATH INTfGRALS 
path integral: 
This integral is to be taken over t, where t E [t’,t’’]. Dq means that the 
integral is taken over the paths q(t), fixed between q”(t”) = q” and q’(t’) = q’ 
and which make S[z] an extremum. The integral over momentum p is taken 
over the same time interval but without any restrictions. 
To bring this integral into a form that can be evaluated in practice, we 
introduce the phase space lattice by dividing the time interval t E [t’, t”] into 
N + 1 slices as 
(20.158) 
Now the propagator becomes 
K(q”, t”, q’, t’) 
(20.159) 
In this expression, except for the points at qN+1 = q” and qo = q’, we have 
to integrate over all q and p. Because the Heisenberg uncertainty principle 
forbids us from determining the momentum and position simultaneously at 
the same point, we have taken the monientum values at the center of the time 
slices as p1+1/2. In this equation one extra integral is taken over p. It is easily 
seen that this propagator satisfies the ESKC relation: 
K(q”’, t”’, q’, t’) = 
K(q”’, t”’, q”, t”)K(q”, t”, q’, t’)dq”. 
(20.160) 
I 
20.9 
FEYNMAN PHASE SPACE PATH INTEGRAL IN THE 
PRESENCE OF QUADRATIC DEPENDENCE ON MOMENTUM 
In phase space, the exponential function in the Feynman propagator [Eq. 
(20.159)] is written as 

FEYNMAN PHASESPACE PATH INTEGRAL IN THE PRESENCE OF QUADRATIC DEPENDENCE ON MOMENTUM 
661 
When the Hamiltonian has quadratic dependence on p as in 
(20.161) 
this exponential function becomes 
(20.162) 
Completing the square in the expression inside the brackets we can write this 
as 
ex.{ (i) 
5 s  
1=0 
x [-$ 
( P W  - (Ql+l - d m ) 2  + ( ails- V L ) 2  - (ql +;+I 
, t l ) ] }  
(20.163) 
Substituting this in Equation (20.159) and taking the momentum integral, we 
find the propagator as 
K(q", t", q', t') = lim 
film 
[ 
dql ] exp{ is}, (20.164) 
N + -  
d
m
 
E'O 
where S is given as 
N 
)] 
(20.165) 
1 =o 
In the continuum limit this becomes 
where 
is the classical action. In other words, the phase space path integral reduces 
to the standard Feynman path integral. 

662 
GREEN'S FUNCTIONS AND PATH INTEGRALS 
We can write the free particle propagator in terms of the phase space path 
integral as 
BpDxexp { 
d~ [p2 - f] 
} . (20.167) 
s 
K(x, t, zo, to) = fl 
C[zo,to;z,t] 
After we take the momentum integral and after putting all the new constants 
coming into D, Equation (20.167) becomes 
Dxexp { l: 
d~ ( imX2)}. 
(20.168) 
s 
K(z, t, 50, to) = fl 
c 
[zo $0; =, tl 
We can convert this into a Wiener path integral by the t --+ -it rotation, and 
after evaluating it, we return to real time to obtain the propagator as 
(20.169) 
i m(z - xo)2 
2(t -to) . 
exp - 
1 
K(x, t, zo, to) = 4 27Tiqt -to)/m 
We conclude by giving the following useful rules for path integrals with 
For the pinned Wiener measure: 
N + 1 segments [Eq.. (20.15)]: 
For the unpinned Wiener measure: 
Also, 
N + l  
(20.172) 

PROBLEMS 
663 
Problems 
20.1 
Show that 
satisfies the normalization condition 
00 
&W(z, t, xo, to) = 1. 
L 
20.2 
equation is true: 
By differentiating both sides with respect to t show that the following 
20.3 
Show that V(z) 
in Equation (20.64): 
is defined as 
1 
1 dF(x) 
4q2 D 
27 dx . 
V ( x )  = -F2(x) + -- 
20.4 
Show that the propagator 
satisfies the ESKC relation [Eq. (20.14)]. 
20.5 
Derive equation 

664 
GREEN’S FUNCTlONS AND PATH 1NTEGRALS 
given in Section 20.3. 
20.6 
integral 
Using the semiclassical method show that the result of the Wiener 
W(z,t, 
20, 
to) = 1 
d,z(T) exp { -k2 lot 
d m 2  } 
C [ l O , O ; W ]  
is given as 
(22 + 2;) cosh(2kJiS(t - to)) - 2202 
2v%sinh(Zkfi(t 
-to)) 
20.7 
By diagonalizing the real synimetric matrix, A, show that 
20.8 
Use the formula 
dqexp { -a(q - v ’ ) ~  - b(q - v ” ) ~ }  
I-, 
to evaluate the integral 
20.9 
propagator Equation (20.164): 
By taking the momentum integral in Equation (20.159) derive the 
where S is given as 
N 
S=C. 
1 =o 

Ref e r e  n ces 
. 
. 
Akhiezer, N.I., The Calculus of Variations, Blaisdell, New York, 1962 
Arfken, G. B., and H. J. Weber, Essential Mathematical Methods for 
Physicists, Academic Press, 2003. 
Arfken, G. B., and H. J. Weber, Mathematical Methods of Physics, Aca- 
demic Press, sixth edition, 2005. 
Artin, E., The Gamma Function, Holt, Rinehart and Winston, New York, 
1964. 
. 
. 
. 
. 
Beiser, A., Concepts of Modern Physics, McGraw-Hill, sixth edition, 2002. 
Bell, W.W., Special Functions for Scientists and Engineers, Dover Publi- 
cations, 2004. 
Bluman, W. B., and Kumei, S., Symmetries and Differential Equations, 
Springer Verlag, New York, 1989. 
Boas, M.L., Mathematical Methods in the Physical Sciences, Wiley, third 
edition, 2006. 
. Bradbury, T.C., Theoretical Mechanics, Wiley, international edition, 
1968. 
. Bromwich, T. J.I., Infinite Series, Chelsea Publishing Company, 1991. 
665 

666 
REFERENCES 
. 
Brown, J.W., and R.V. Churchill, Complex Variables and Applications, 
McGraw-Hill, New York, 1995. 
Butkov, E., Mathematical Physics, Addison-Wesley, New York, 1968. 
Byron, W. Jr., and R.W. Fuller, Mathematics of Classical and Quantum 
Physics, Dover Publications, New York, 1970. 
Chaichian, M., and A. Dernichev, Path Integrals in Physics, Volume I and 
11, Institute of Physics Publishing, 2001. 
Churchill, R.V., Fourier Series and Boundary Value Problems, McGraw- 
Hill, New York, 1963. 
Courant, E., and D. Hilbert, Methods of Mathematical Physics, Volume I 
and 11, Wiley, New York, 1991. 
Dennery, P., and A. Krzywicki, Mathematics for Physics, Dover Publica- 
tions, New York, 1995. 
Doniach, S., and E.H. Sondheimer, Green’s hnctions for Solid State 
Physics, World Scientific, 1998. 
Dwight, H.B., Tables of Integrals and Other Mathematical Data, Prentice 
Hall, fourth edition, 1961. 
Erdelyi, A., Asymptotic Expansions, Dover Publications, New York, 1956. 
Erdelyi, A., Oberhettinger, M.W., and Tricomi. F.G., Higher Tmnscen- 
dental Functions, Krieger, vol. I, New York,1981. 
Feynman, R., R.B. Leighton, and M. Sands, The Feynman Lectures on 
Physics, Addison-Wesley, 1966. 
Feynman, R., and Hibbs, A.R., Quantum Mechanics and Path Integrals, 
McGraw-Hill, 1965. 
Gantmacher, F.R., The Theory of Matrices, Chelsea Publishing Company, 
New York, 1960. 
Gluzman, S., and D. Sornette, Log Periodic Route to Fractal Functions, 
Physical Review, E65, 036142, (2002). 
Goldstein, H., C. Poole, and J. Safko, Classical Mechanics, Addison- 
Wesley, third edition, 2002. 
Hamermesh, M., Group Theory and its Application to Physical Problems, 
Addison-Wesley, 1962. 
Hartle, J.B., An Introduction to Einstein’s General Relativity, Addison- 
Wesley, 2003. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 

REFERENCES 
667 
Hassani, S., Mathematical Methods: for Students of Physics and Related 
Fields, Springer Verlag, 2000. 
Hassani, S., Mathematical Physics, Springer Verlag, second edition, 2002. 
Hildebrand, F.B., Methods of Applied, Mathematics, Dover Publications, 
second reprint edition, 1992. 
Hilfer, R., Applications of Fkactional Calculus, World Scientific, 2000. 
Hydon, P. E., Symmetry Methods for Differential Equations: A Beginner’s 
Guide, Cambridge, 2000. 
Ince, E.L., Ordinary Digerential Equations, Dover Publications, New 
York, 1958. 
Infeld, L., and T.E. Hull, The Factorization Method, Reviews of Modern 
Physics, 23, 21-68 (1951). 
Jackson, J.D., Classical Electrodynamics, Wiley, third edition, 1999. 
Jacobson, T.A., and R. Parentani, An Echo of Black Holes, Scientific 
American, December, 48-55 (2005). 
Kaplan, W., Advanced Calculus, Addison- Wesley, New York, 1973. 
Kleinert, H., Path Integrals in Quantum Mechanics, Statistics, Polymer 
Physics and Financial Markets, World Scientific, third edition, 2003. 
Lamhrecht, A., The Casimir Effect: 
World, September, 29-32 (2002). 
Lebedev, N.N., Special Functions and their Applications, Prentice-Hall, 
1965. 
Lebedev, N.N., I.P. Skolskaya, and Uflyand, Problems of Mathematical 
Physics, Prentice-Hall, Englewood Cliffs, 1965. 
Marion, J. B., Classical Dynamics of Particles and Systems, Academic 
Press, second edition, 1970. 
Mathews, J., and R.W. Walker, Mathematical Methods of Physics, 
Addison-Wesley, Marlo Park, second edition, 1970. 
McCollum, P.A., and B.F. Brown, Laplace Il-ansform Tables and Theo- 
rems, Holt, Rinehart and Winston, New York, 1965. 
Milton, K.A., The Casimir Effect, World Scientific, 2001. 
Morse, P. M., and H. Feshbach, Methods of Theoretical Physics, McGraw- 
Hill, 1953. 
A Force from Nothing, Physics 

668 
REFERENCES 
Oldham, B.K., and J. Spanier, The Fractional Calculus, Academic Press, 
1974. 
Osler, T.J., Leibniz Rule for Fractional Derivatives and an Application 
to Infinite Series, SIAM, Journal of Applied Mathematics, 18, 658-674 
(1970). 
Osler, T.J., The Integral Analogue of the Leibniz Rule, Mathematics of 
Computation, 26, 903-915 (1972). 
Pathria, R. K., Statistical Mechanics, Pergamon Press, 1984. 
Podlubny, I., Fractional Differential Equations, Academic Press, 1999. 
Rektorys, K., Survey of Applicable Mathematics Volumes I and II, 
Springer, second revised edition, 1994. 
Roach, G. F., Green's Functions, Cambridge University Press, second 
edition, 1982. 
Ross, S.L. , Differential Equations, Wiley, New York, third edition, 1984. 
Samko, S.G., A.A. Kilbas, and 0.1. Marichev, Fkactional Integrals and 
Derivatives, Gordon and Breach Science Publishers, 1993. 
Schulman, L.S. , Techniques and Applications of Path Integration, Dover 
Publications, 2005. 
Sokolov, I.M., J. Klafter, and A. Blumen, Fractional Kinetics, Physics 
Today, November 2002, pgs.48-54. 
Spiegel, M.R., Advanced Mathematics for Engineers and Scientists: 
Schaum 's Outline Series in Mathematics, McGraw-Hill, 1971. 
Stephani, H., Differential Equations- Their Solutions Using Symmetries, 
Cambridge University Press, 1989. 
Szekerez, P., A Course in Modern Mathematical Physics: Group, Halbert 
Space and Differential Geometry, Cambridge University Press, 2004. 
Titchmarsh, E.C., The Theory of finctions, Oxford University Press, 
New York, 1939. 
Wan, F.Y.M., Introduction to the Calculus of Variataons and its Applica- 
tions, ITP, 1995. 
Whittaker, E.T., and G.N. Watson, A Course on Modern Analysis, Cam- 
bridge University Press, New York, 1958. 
Wyld, H. W., Mathematical Methods for Physics, Addison-Wesley, New 
York, 1976. 

Index: 
Abel test, 444 
Abel’s formula, 569 
Absolute convergence, 432 
Active and passive views, 174 
Addition of velocities, 201 
Addition theorem 
spherical harmonics, 264 
Advanced Green’s functions, 624 
Algebra of vectors, 164 
Alternating series 
Leibniz rule, 439 
Analytic continuation, 350 
A naIytic functions 
Angular momentum, 116 
Cauchy-Riemann conditions, 297 
factorization method, 143 
quantum mechanics, 249 
Angular momentum operators 
eigenvalue equations 
matrix elements 
quantum mechanics, 255 
quantum mechanics, 257 
Argument, 294 
Associated Laguerre polynomials, 
45, 51 
generating function, 52 
orthogonality and completeness, 
recursion relations, 53 
Rodriguez formula, 53 
53 
Associated Legendre equation, 13, 
factorization method, 137 
Associated Legendre polynomials, 
28 
30 
31 
orthogonality and completeness, 
Asymptotic series, 462 
Bernoulli numbers, 453 
Bernoulli periodic function, 454 
Bernoulli polynomials 
Bessel functions 
generating function, 453 
boundary conditions, 91 
channel waves 
factorization method, 155 
tsunamis, 93 
669 

670 
lNDEX 
first kind, 86 
flexible chain problem, 92 
generating functions, 89 
integral definitions, 90 
modified Bessel functions, 88 
orthogonality and completeness, 
recursion relations, 90 
second kind, 87 
spherical, 88 
third kind, 87 
Wronskians, 95 
Laplace transforms, 507 
90 
Bessel's equation, 86 
Beta function, 362 
Binomial coefficient, 447 
Binomial formula 
Binomial theorem, 447 
Bloch equation, 640 
Bohr energy levels, 45 
Boosts 
Boundary conditions 
relativistic energy, 447 
Lorentz transformation, 244 
Dirichlet, 109 
Green's functions, 572, 594 
Hermitian operators, 110 
inhomogeneous 
Green's functions, 575 
Neumann, 109 
single point 
Green's functions, 572 
Sturm-Liouville system, 108 
unmixed 
mixed, 109 
Branch cut 
Branch line, 306 
Branch point, 306 
Bromwich integral 
Riemann sheet, 306 
inverse Laplace transform 
Laplace transform, 492 
Caputo derivative, 429 
Cartesian coordinates, 163 
Cartesian tensors, 178 
contraction, 179 
pseudotensor 
rank, 178 
trace, 179 
Casimir effect, 466 
MEMS, 468 
Cauchy formula, 388 
Cauchy integral formula 
fractional derivative, 390 
Cauchy integral theorem, 336 
Cauchy principal value, 365 
Cauchy theorem, 339 
convergence tests, 435 
Cauchy-Goursat theorem, 335 
Cauchy-Riemann conditions, 297 
Chebyshev equation, 75 
second kind, 76 
Chebyshev polynomials 
first kind, 75, 76 
Gegenbauer polynomials, 76 
generating function, 78 
orthogonality and completeness, 
second kind, 76 
tensor density, 180 
78 
another definition, 78 
Chebyshev series 
Raabe test, 437 
Christoffel symbols 
first kind, 192 
second kind, 192 
Commutation relations 
angular momentum, 249 
Completeness of eigenfunctions, 276 
Complex algebra, 293 
Complex conjugate, 295 
Complex derivative, 296 
Complex functions, 295 
Complex numbers 
argument, 294 
conjugate, 295 
modulus, 294 
Complex plane, 294 
Complex techniques 

INDEX 
671 
definite integrals, 352 
Conditional convergence, 432 
Abel test, 444 
Condon-Shortley phase, 140 
spherical harmonics, 34 
Confluent Gauss equation, 104 
Conformal mappings, 313 
electrostatics, 3 14 
fluid mechanics, 318 
Conjugate harmonic functions, 299 
Continuous groups 
generators, 278 
Lie groups, 224, 278 
Continuous random walk 
fractional derivatives, 424 
Contour integral 
complex, 335 
Contour integral techniques, 352 
Contour integrals 
special functions, 369 
Contraction of indices, 188 
Contravariant/covariant components, 
182 
Convergence 
absolu te 
Convergence tests 
conditional, 432 
Cauchy root test, 433 
comparison, 433 
Gauss test, 436 
integral test, 434 
Raabe test, 435 
ratio test, 433 
Fourier transforms, 485 
Laplace transforms, 498 
Convolution theorem 
Covariance, 197 
Covariant divergence, 194 
Covariant/contravariant components, 
182 
nents, 186 
contravariant/covariant compe 
Curl, 193 
Cut line, 306 
d’Alembert operator, 72, 209, 215, 
473,619 
De Moivre’s formula, 295 
Derivative 
Derivative and integral 
385 
Differential equations 
550 
n-fold, 382 
unification for integer orders, 
conversion to integral equations, 
Differentiation of vectors, 166 
Differintegrals 
composition, 400 
CTRW 
dependence on the lower limit, 
evaluation of definite integrals, 
extraordinary differential equa- 
Fokker-Planck equation, 427 
heat transfer equation, 415 
homogeneity, 399 
Leibniz rule, 407 
linearity, 399 
properties, 399 
right and left handed, 407 
scale transformation, 400 
semidifferential equations, 419 
series, 400 
some examples, 409 
special functions, 424 
techniques, 413 
Diffusion equation, 379 
Brownian motion 
path integrals, 633 
Feynman-Kac formula, 639 
Fourier transforms, 488 
propagator, 610 
Dipoles, 23 
Dirac-Delta function, 481 
Direction cosines, 167 
Divergence, 194 
Brownian motion, 424 
408 
421 
tions, 417 

672 
INDEX 
Divergent series, 465 
Casimir effect, 466 
quantum vacuum energyy, 467 
Doppler shift, 208 
Dot product, 165 
Double factorial, 377 
Dual field strength tensor, 212 
Eigenvalue problems 
Einstein summation convention, 188 
Elastic beam 
deformation, 527 
Electrostatics 
Green’s functions, 604 
Entire function, 297, 347 
Equivalent representations, 246 
ESKC relation, 635 
Essential singular point, 347 
Euler angles, 172 
Euler equation, 518 
Euler’s theorem, 228 
Euler-Maclaurin sum formula, 454 
Euler-Masheroni constant, 471 
Expansion theorem, 113 
eigenfunctions, 276 
Extension 
prolongat ion 
Green’s functions, 579 
another form, 520 
generators, 282 
Extraordinary differential equations, 
417 
Factorization method 
137 
associated Legendre equation, 
Bessel functions, 155 
Gegenbauer polynomials, 153 
harmonic wcillator, 156 
single electron atom, 151 
solutions, 130 
spherical harmonics, 141 
Sturm-Liouville equation, 123 
symmetric top problem, 154 
technique and categories, 132 
theory, 124 
momentum space, 659 
quadratic momentum depen- 
Schrodinger equation, 655 
derivation, 641 
Feynman path integral 
dence, 661 
Feynman-Kac formula, 639 
Fick’s equation, 380 
Field strength tensor, 212 
First canonical form 
tor 
self-adjoint differential opera- 
S t urm- Liou ville operat or, 108 
Flexible chain 
Bessel’s equation, 84 
Flow around an obstacle 
conformal mappings, 319 
Fokker-Planck equation 
fractional derivatives, 427 
Four-momentum 
conservation, 205 
Four-scalars, 204 
Four-tensors, 202 
Four-vector space, 274 
Four-vectors, 204 
Four-velocity, 204 
Fourier integral, 479 
Fourier transforms, 481 
convolution theorem, 485 
cosine 
sine, 482 
diffusion equation, 488 
existence, 486 
in three dimensions, 486 
Parceval theorems, 487 
partial differential equations, 
transform of a derivative, 484 
Caputo definition, 429 
Cauchy integral formula, 390 
Griinwald definition 
differintegrals, 385 
Laplace transforms, 396 
484 
Fractional derivatives 

INDEX 
673 
notation, 381 
Riemann formula, 395 
Riemann-Liouville definition, 387 
Fredholm equation, 548 
Frobenius method, 13, 16 
Function spaces 
Fundamental tensor, 184 
Hilbert space, 274 
Galilean transformation, 2 15 
Gamma function, 360, 462 
infinite product, 471 
Gauss equation 
special functions, 104 
Gegenbauer equation, 75 
factorization method, 153 
Gegenbauer polynomials, 75 
Chebyshev polynomials, 76 
cosmology, 72 
generating function, 75 
orthogonality and completeness, 
75 
Generalized Fourier series, 114 
Generating function 
associated Laguerre polynomi- 
Bessel functions, 89 
Chebyshev polynomials, 78 
Gegenbauer polynomials, 75 
Hermite polynomials, 60 
Laguerre polynomials, 46 
Legendre polynomials, 19 
continuous groups 
Lie groups, 278 
ex tension 
prolongation, 282 
normal form, 280 
R(3), 227 
als, 52 
Generators 
commutation relations, 227 
differential, 228 
transformations, 279 
Geodesics, 197 
Griinwald, 385 
Gradient, 193 
Green's functions, 10 
advanced and retarded, 621 
boundary conditions, 568 
compounding propagators, 609 
construction, 569 
defining equation, 572 
differential equations, 572 
integral equations, 568 
Dirac-delta function, 583 
eigenfunction expansions, 579 
first-order time dependence, 606 
general boundary conditions, 
harmonic oscillator, 591 
Helmholtz equation, 582 
all space, 584 
three-dimensional, 593 
604 
inhomogeneous boundary con- 
ditions, 575 
Laplace operator, 597 
Lippmann-Schwinger equation, 
one-dimensional, 567 
point source, 609 
Poisson equation, 597 
propagators, 609 
wave equation, 618 
Schrodinger's equation, 597 
second-order time dependence, 
three-dimensional 
603 
6 16 
continuum limit, 594 
Group 
definition, 224 
terminology, 224 
Group invariants, 231 
Group representations, 246 
R(3), 248 
SU(2), 269 
Group spaces, 272 
Group theory 
group character, 248 
invariants, 231 
Lorentz group, 232, 241 
Poincare group, 241 

674 
lNDEX 
Holder inequality, 442 
Hamilton’s principle, 533 
Hankel function, 87 
Harmonic functions, 299 
Harmonic oscillator 
damped 
Laplace transforms, 505 
factorization method, 156 
Green’s functions, 591 
quantum mechanical 
three dimensional, 56 
Hermite polynomials, 57 
Harmonic series, 432 
Heat transfer equation 
differintegrals, 415 
Helmholtz equation, 9 
continuum limit, 584 
Green’s functions, 582 
three dimensions, 593 
Hermite equation, 58, 60 
Hermite polynomials, 59 
contour integral, 373 
dipole calculations, 64 
Gaussian, 63 
generating function, 60 
harmonic oscillator, 57 
orthogonality and completeness, 
recursion relations, 62 
Rodriguez formula, 61 
Hermitian operators 
boundary conditions, 110 
eigenvalues 
eigenfunctions, 110 
quantum mechanics, 116 
Sturm-Liouville operator, 110 
function spaces, 274 
inner product, 117 
quantum mechanics, 277 
Hilbert-Schmidt theory, 560 
completeness of eigenfunctions, 
nonhermitian operators, 564 
Homogeneous Lorentz group, 241 
62 
Hilbert space 
563 
Hypergeometric equation, 99 
Hypergeometric functions, 99 
Improper transformations, 170 
Incomplete beta function, 364 
Incomplete gamma function, 364 
Indicia1 equation, 14 
double root, 45 
roots, 16 
cosine function, 471 
gamma function, 471 
sine function, 470 
Infinite series 
convergence, 431 
Infinitesimal ring 
Lie algebra, 226 
Infinitesimal transformations 
orthogonal transformations, 175 
Inhomogeneous boundary conditions 
Green’s functions, 575 
Inhomogeneous Lorentz group, 241 
Inner product 
Inner product space, 273 
Integral 
Integral equations 
Infinite products, 468 
Hilhert space, 117 
n-fold, 384 
Cauchy formula, 549 
classification, 548 
eigenvalue problems 
Fredholm equation, 548 
Green’s functions, 568 
homogeneous, 548 
methods of solution 
Hilbert-Schmidt theory, 560 
Neumann series, 554 
separable kernels, 556 
successive iterations, 554 
via integral transforms, 559 
nonhermitian kernels, 564 
Volterra equation, 548 
vs. differential equations, 548 
Fourier transforms, 478 
Integral transforms, 10 

INDEX 
675 
general, 477 
Hankel transform 
integral equations, 559 
Laplace transforms, 478 
Mellin transform, 479 
relations, 51 1 
Fourier-Bessel transform, 479 
Invariance, 197 
Inverse Laplace transforms 
Bromwich integral, 492 
Lerch theorem, 491 
Inversion of power series, 451 
Irreducible representation, 247 
Isolated singular point, 297, 347 
Isomorphism, 239 
Isoperimetric problems, 529 
Jacobi polynomials, 41 
Jacobian of transformation, 190 
Jordan’s lemma, 357 
contour integral, 375 
Kronecker delta, 179 
Kummer formula, 106 
Ladder operators 
step up/down operators, 124, 
125 
Laguerre equation, 45 
Laguerre polynomials, 46 
contour integral, 371, 372 
generating function, 46 
orthogonality and completeness, 
recursion relations, 50 
Rodriguez formula, 47 
special values, 50 
48 
Laguerre series, 46 
Laplace equation, 9 
Laplace transforms, 490 
variational analysis, 525 
basic, 492 
Bessel’s equation, 507 
damped oscillator, 505 
definite integrals, 502 
derivatives, 503 
differintegrals, 413 
electromagnetic waves, 506 
Fourier transforms 
Mellin transforms, 51 1 
fractional derivatives, 396 
in n dimensions, 511 
inverses 
partial fractions, 501 
theorems, 494 
Laplacian 
covariant, 194 
Laurent series, 341 
short cut, 346 
Legendre equation, 13 
Legendre polynomials, 18 
Bromwich integral, 492 
generating function, 19 
normalization constant, 26 
orthogonality and completeness, 
recursion relations, 21 
Rodriguez formula, 19 
Schlofli formula, 370 
special integrals, 23 
special values, 22 
convergence 
24 
Legendre series, 15 
Gauss test, 436 
Leibniz formula, 25 
Letnikov, 385 
Levi-Civita symbol, 180 
Lie algebra 
generators of SU(2) 
differential, 240 
group 
differential operators, 228 
infinitesimal ring, 226 
rotation group R(3), 227 
SU(2), 237 
continuous groups, 224 
Lie groups 
Line element, 184, 199 
Linear independence 
Wronskian, 41 

676 
INDEX 
Lorentz contraction 
Lorentz group 
length contraction, 201 
commutation relations, 244 
generators, 244 
homogeneous 
inhomogeneous, 241 
Lorentz transformation, 199 
boost, 244 
group invariants, 232 
orientation of axis, 209 
M-test 
Weierstrass M-test, 444 
Maclaurin series, 446 
Mappings, 300 
conformal, 313 
inversion, 301, 302 
many-to-one, 306 
one-to-one, 304 
one-to-two, 306 
rotation, 301 
Schwarz-Christoffel transforma- 
translation, 300 
two-to-one, 304 
Maxwell’s equations, 21 1 
potentials, 214 
transformations, 213 
tions, 322 
Mean square displacement, 380 
Mellin transforms, 512 
MEMS 
Casimir effect, 468 
Metric tensor, 184 
covariant derivative, 194 
Minkowski metric, 202 
Minkowski spacetime, 198 
Minkowski’s inequality, 442 
Mittag-Leffler functions, 418 
Mittag-Leffler theorem 
infinite products, 470 
Modified Bessel functions, 88 
Modulus, 294 
Multipole expansion, 267 
Neumann function, 87 
Neumann series 
Newton’s equations 
Normal form 
error calculation, 556 
covariant, 215 
generators, 280 
Orthogonal transformations, 167, 170 
Orthogonality and completeness 
associated Laguerre polynomi- 
associated Legendre polynomi- 
Bessel functions, 90 
Chebyshev polynomials, 78 
Gegenbauer polynomials, 75 
Hermite polynomials, 62 
Hermitian operators 
Laguerre polynomials, 48 
Legendre polynomials, 24 
als, 53 
als, 31 
Sturm-Liouville operators, 111 
Outer product, 179, 189 
Parceval theorems, 487 
Partial fractions 
Partial sum, 431 
Path integrals 
Laplace transforms, 501 
Bloch formula, 640 
interpretation, 643 
ESKC relation, 635, 649 
Feynman path integral, 655 
Feynman phase space path in- 
Feynman-Kac formula, 639 
finite elements method, 650 
methods of calculation, 646 
Schrodinger equation, 658 
semiclassical method, 650 
time slice method, 647 
Wiener path integral, 635 
tegral, 659 
Pauli spin matrices, 236 
Permutation symbol, 190 
Pinned Wiener measure, 637 

INDEX 
677 
Poincare group, 241 
Point groups, 278 
Point source initial condition 
Poisson equation 
Power series, 449 
Prolongation 
extension 
generators, 282 
Propagators, 609 
Proper time, 204, 205 
Proper transformations, 170 
Pseudo-Euclidean , 199 
Pseudotensor, 180 
Green’s functions, 609 
Green’s functions, 597 
Quantum mechanics 
Quotient theorem, 189 
Hermitian operators, 116 
relation to SU( 2), 269 
R(3) 
R(3) and SU(2), 269 
Rank, 178 
Rayleigh-Ritz met hod 
Recursion relation 
variational integrals, 539 
associated Laguerre polynomi- 
Bessel functions, 90 
Hermite polynomials, 62 
Laguerre polynomials, 50 
Legendre polynomials, 21 
Reducible representation, 247 
Regular singular point 
Frobenius method, 16 
Regularization 
Renormalization, 465 
Relativistic energy 
binomial formula, 447 
Relativistic mass, 207 
Renormalization, 465 
Representation space, 246 
Residue theorem, 347 
Rest mass, 205 
als, 53 
Retarded Green’s functions, 624 
Riemann curvature scalar, 195 
Riemann curvature tensor, 195 
Riemann formula, 395 
Riemann sheets 
Riemann theorem, 440 
Riemann zeta function, 434 
Riemann-Liouville 
derivative, 387 
Rodriguez formula 
associated Laguerre polynomi- 
Hermite polynomials, 61 
Laguerre polynomials, 47 
Legendre polynomials, 19 
representation, 248 
branch cuts, 308 
als, 53 
Rotation group 
spherical harmonics, 249 
Rotation matrix 
differential equation, 262 
evaluation, 260 
inverse, 261 
orthogonal transformations, 170 
spherical harmonics, 258 
Euler angles, 251 
Rotation operator 
Schlofli formula, 370 
Schlofli integral formula 
Schrodinger equation, 10, 43 
Legendre polynomials, 370 
bound states, 601 
factorization method 
single electron atom, 151 
Feynman path integral, 658 
Green’s function, 615 
propagator 
free particle, 615 
Schur’s lemma, 247 
Schwartz inequality, 118 
Schwaris-Cauchy inequality, 442 
Schwarz-Christoffel transformations, 
324 
fringe effects, 325 

678 
INDEX 
Second canonical form 
Self-adjoint differential operator, 107 
Semi-infinite parallel plate 
Sturm-Liouville operator, 122 
mappings 
Semi-integrals, 413 
Semiderivatives, 413 
Semidifferential equations, 419 
Separation of variables, 10 
Series 
fringe fields, 325 
algebra, 439 
inequalities, 442 
rearrangement, 440 
Similarity transformations, 175 
Simple pole, 347 
Singleelectron atom models, 44 
Singular points 
classification, 347 
essential, 347 
isolated, 347 
simple pole, 347 
Soap film, 521 
Spacetime 
derivatives, 208 
Minkowski, 198 
confluent hypergeometric func- 
contour integrals, 369 
differintegral representations, 424 
hypergeometric functions, 104 
postulates, 199 
SU(2), 236 
Special functions 
tions, 104 
Special relativity 
Special unitary group 
Spherical Bessel functions, 88 
Spherical Hankel functions, 377 
contour integral, 376 
Spherical harmonics, 33, 249 
addition theorem, 264 
Condon-Shortley phase, 34 
expansions, 255 
factorization method, 141 
Gegenbauer polynomials, 73 
ladder operators, 141, 150 
Spinor space 
SU(2), 272 
Step up/down operators 
ladder operators, 125 
Stirling’s approximation, 377 
Structure constants, 226 
Sturm-Liouville operator 
completeness, 113 
Sturm-Liouville equation, 108 
expansion theorem 
first canonical form, 108 
Green’s functions, 567 
hermitian operators, 110 
second canonical form, 122 
boundary conditions, 109 
variational integral, 535 
generators, 237, 238 
commutation relations, 238 
differential, 240 
irreducible representation, 269 
relation to R(3), 269 
spinor space, 272 
Summation convention 
Einstein, 188 
Summation of series, 452 
Euler-Maclaurin sum formula, 
using differintegrals, 423, 462 
using the residue theorem, 458 
factorization method, 154 
differential equations, 285 
Sturm-Liouville system 
SUP) 
454 
Symmetric top 
Symmetries 
Taylor series, 339 
with multiple variables, 448 
with the remainder, 445 
pseudotensor, 180 
Cartesian, 178 
covariant divergence, 194 
Tensor density, 179, 189 
Tensors 

INDEX 
679 
covariant gradiant, 193 
curl, 193 
differentiation, 19 1 
equality, 189 
general, 181 
Laplacian, 194 
some covariant derivatives, 193 
Time dilation, 201 
Trace, 179 
Triangle inequality, 117 
Trigonometric Fourier series, 479 
generalized Fourier series, 114 
Uniform convergence, 443 
properties, 445 
Unitary group 
U(2), 234 
Unitary representations, 248 
Unpinned Wiener measure, 638 
Variational integrals 
eigenvalue problems, 535 
elastic beam, 527 
Euler equation, 518 
geodesics, 520 
Hamilton’s principle, 533 
Lagrangian, 533 
loaded cable, 540 
presence of constraints, 529 
presence of higher-order deriva- 
several dependent and indepen- 
several dependent variables, 523 
several independent variables, 
524 
soap film, 521 
upper bound to eigenvalues, 537 
tives, 527 
dent variables, 526 
Vector product, 165 
Vector spaces 
complex, 274 
inner product, 273 
Minkowski, 274 
real, 272 
Volterra equation, 548 
Wallis’s formula, 471 
Wave four-vector, 208 
Weierstrass function, 479 
Weierstrass M-test, 444 
Weight of a tensor, 189 
Wiener measure 
pinned 
unpinned, 638 
Brownian motion, 635 
unpinned, 637 
Wiener path integral 
Worldline, 204 
Wronskian 
Bessel functions, 95 
linear independence, 41 


